{
    "hands_on_practices": [
        {
            "introduction": "本练习将引导你推导翻译后修饰循环的经典动力学模型。通过从质量作用定律出发，应用准稳态近似得到米氏方程形式的反应速率，你将构建描述底物磷酸化水平动态变化的常微分方程。这个练习是理解细胞信号通路中超敏性和双稳态等关键行为的基础。",
            "id": "3339093",
            "problem": "一种蛋白质底物在激酶 $E_k$ 和磷酸酶 $E_p$ 的催化下，在未修饰状态 $S$ 和磷酸化状态 $S^{\\ast}$ 之间经历一个共价修饰循环。磷酸化和去磷酸化过程遵循带有催化的双分子结合与解离方案：\n- 激酶臂：$E_k + S \\rightleftharpoons C_k \\rightarrow E_k + S^{\\ast}$，正向结合速率为 $k_{1,k}$，解离速率为 $k_{-1,k}$，催化速率为 $k_{\\mathrm{cat},k}$。\n- 磷酸酶臂：$E_p + S^{\\ast} \\rightleftharpoons C_p \\rightarrow E_p + S$，正向结合速率为 $k_{1,p}$，解离速率为 $k_{-1,p}$，催化速率为 $k_{\\mathrm{cat},p}$。\n\n假设在一个固定体积的均匀混合区室中，遵循质量作用定律，并且以下总量守恒：$S^{\\mathrm{tot}} = S + S^{\\ast} + C_k + C_p$，$E_k^{\\mathrm{tot}} = E_k + C_k$，以及 $E_p^{\\mathrm{tot}} = E_p + C_p$。令 $V_k = k_{\\mathrm{cat},k} E_k^{\\mathrm{tot}}$，$K_k = \\frac{k_{-1,k} + k_{\\mathrm{cat},k}}{k_{1,k}}$，$V_p = k_{\\mathrm{cat},p} E_p^{\\mathrm{tot}}$，以及 $K_p = \\frac{k_{-1,p} + k_{\\mathrm{cat},p}}{k_{1,p}}$。\n\n任务：\n1. 从完整的酶-底物-复合物系统的质量作用常微分方程（ODE）出发，对复合物 $C_k$ 和 $C_p$ 应用准稳态近似（QSSA），以推导磷酸化和去磷酸化通量的 Michaelis-Menten（MM）速率形式。\n2. 使用推导出的 MM 速率和底物守恒，写出关于 $S^{\\ast}(t)$ 的单个 ODE，并用 $S^{\\mathrm{tot}}$，$V_k$，$K_k$，$V_p$ 和 $K_p$ 表示。\n3. 对 ODE 施加稳态条件，并精确求解稳态分数 $f^{\\ast} = \\frac{S^{\\ast}}{S^{\\mathrm{tot}}}$，得到一个用 $V_k$，$V_p$，$K_k$，$K_p$ 和 $S^{\\mathrm{tot}}$ 表示的闭式解析表达式。假设 $V_k \\neq V_p$，以确保二次解是非简并的。\n\n最终答案应提供为 $f^{\\ast}$ 的单个閉式表达式。无需进行数值计算。",
            "solution": "## 问题验证\n\n### 第1步：提取已知条件\n问题提供了以下信息：\n- **反应方案：** 一种底物存在于未修饰状态 $S$ 和磷酸化状态 $S^{\\ast}$。\n- **激酶臂：** $E_k + S \\rightleftharpoons C_k \\rightarrow E_k + S^{\\ast}$\n  - 结合速率：$k_{1,k}$\n  - 解离速率：$k_{-1,k}$\n  - 催化速率：$k_{\\mathrm{cat},k}$\n- **磷酸酶臂：** $E_p + S^{\\ast} \\rightleftharpoons C_p \\rightarrow E_p + S$\n  - 结合速率：$k_{1,p}$\n  - 解离速率：$k_{-1,p}$\n  - 催化速率：$k_{\\mathrm{cat},p}$\n- **守恒定律：**\n  - 总底物：$S^{\\mathrm{tot}} = S + S^{\\ast} + C_k + C_p$\n  - 总激酶：$E_k^{\\mathrm{tot}} = E_k + C_k$\n  - 总磷酸酶：$E_p^{\\mathrm{tot}} = E_p + C_p$\n- **定义：**\n  - $V_k = k_{\\mathrm{cat},k} E_k^{\\mathrm{tot}}$\n  - $K_k = \\frac{k_{-1,k} + k_{\\mathrm{cat},k}}{k_{1,k}}$\n  - $V_p = k_{\\mathrm{cat},p} E_p^{\\mathrm{tot}}$\n  - $K_p = \\frac{k_{-1,p} + k_{\\mathrm{cat},p}}{k_{1,p}}$\n- **任务：**\n  1. 使用准稳态近似（QSSA）推导磷酸化和去磷酸化通量的 Michaelis-Menten（MM）速率形式。\n  2. 使用 MM 速率和底物守恒写出关于 $S^{\\ast}(t)$ 的单个 ODE。\n  3. 求解稳态分数 $f^{\\ast} = \\frac{S^{\\ast}}{S^{\\mathrm{tot}}}$ 的闭式表达式。\n- **约束条件：** 假设 $V_k \\neq V_p$。\n\n### 第2步：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n- **科学基础：** 该问题描述了共价修饰循环的 Goldbeter-Koshland 模型，这是计算系统生物学和细胞信号转导理论的基石。反应方案、质量作用动力学、QSSA 和 Michaelis-Menten 形式体系都是生物化学和化学动力学中的标准、公认的概念。\n- **良定的：** 该问题陈述清晰，包含了所有必要的定义、常数和约束。任务是序列性的，导向一个唯一确定的分析目标。条件 $V_k \\neq V_p$ 确保了得到的二次方程不是简并的，从而得到一个良定义的解。\n- **客观的：** 语言形式化、精确，没有任何主观性或歧义。\n\n该问题没有任何缺陷。它在科学上是合理的，结构上是形式化的，自洽且客观。\n\n### 第3步：结论和行动\n该问题被认为是**有效的**。将提供完整的解法。\n\n## 解法\n\n### 第1部分：Michaelis-Menten (MM) 速率的推导\n\n我们首先写出酶-底物复合物 $C_k$ 和 $C_p$ 浓度的质量作用常微分方程（ODE）。令物种 $X$ 的浓度用符号 $X$ 表示。\n\n对于激酶-底物复合物 $C_k$：\n$$ \\frac{dC_k}{dt} = k_{1,k} E_k S - k_{-1,k} C_k - k_{\\mathrm{cat},k} C_k = k_{1,k} E_k S - (k_{-1,k} + k_{\\mathrm{cat},k}) C_k $$\n准稳态近似（QSSA）假设复合物的浓度变化远慢于底物和产物的浓度变化，即 $\\frac{dC_k}{dt} \\approx 0$。\n$$ k_{1,k} E_k S \\approx (k_{-1,k} + k_{\\mathrm{cat},k}) C_k $$\n我们使用总激酶守恒 $E_k^{\\mathrm{tot}} = E_k + C_k$ 来表示游离激酶浓度为 $E_k = E_k^{\\mathrm{tot}} - C_k$。将此代入 QSSA 方程：\n$$ k_{1,k} (E_k^{\\mathrm{tot}} - C_k) S = (k_{-1,k} + k_{\\mathrm{cat},k}) C_k $$\n求解 $C_k$：\n$$ k_{1,k} E_k^{\\mathrm{tot}} S - k_{1,k} C_k S = (k_{-1,k} + k_{\\mathrm{cat},k}) C_k $$\n$$ k_{1,k} E_k^{\\mathrm{tot}} S = (k_{-1,k} + k_{\\mathrm{cat},k} + k_{1,k} S) C_k $$\n$$ C_k = \\frac{k_{1,k} E_k^{\\mathrm{tot}} S}{k_{-1,k} + k_{\\mathrm{cat},k} + k_{1,k} S} $$\n分子和分母同除以 $k_{1,k}$：\n$$ C_k = \\frac{E_k^{\\mathrm{tot}} S}{\\frac{k_{-1,k} + k_{\\mathrm{cat},k}}{k_{1,k}} + S} $$\n磷酸化通量（或速率）$v_k$ 是 $S^{\\ast}$ 的生成速率，即 $v_k = k_{\\mathrm{cat},k} C_k$。\n$$ v_k = k_{\\mathrm{cat},k} \\frac{E_k^{\\mathrm{tot}} S}{\\frac{k_{-1,k} + k_{\\mathrm{cat},k}}{k_{1,k}} + S} $$\n使用给定的定义 $V_k = k_{\\mathrm{cat},k} E_k^{\\mathrm{tot}}$ 和 $K_k = \\frac{k_{-1,k} + k_{\\mathrm{cat},k}}{k_{1,k}}$，我们得到磷酸化通量的 MM 速率形式：\n$$ v_k = \\frac{V_k S}{K_k + S} $$\n对于磷酸酶臂的推导是对称的。磷酸酶-底物复合物 $C_p$ 的 ODE 为：\n$$ \\frac{dC_p}{dt} = k_{1,p} E_p S^{\\ast} - (k_{-1,p} + k_{\\mathrm{cat},p}) C_p $$\n应用 QSSA（$\\frac{dC_p}{dt} \\approx 0$）并代入 $E_p = E_p^{\\mathrm{tot}} - C_p$：\n$$ k_{1,p} (E_p^{\\mathrm{tot}} - C_p) S^{\\ast} = (k_{-1,p} + k_{\\mathrm{cat},p}) C_p $$\n求解 $C_p$ 得：\n$$ C_p = \\frac{E_p^{\\mathrm{tot}} S^{\\ast}}{\\frac{k_{-1,p} + k_{\\mathrm{cat},p}}{k_{1,p}} + S^{\\ast}} $$\n去磷酸化通量 $v_p$ 是 $S^{\\ast}$ 的消耗速率，即 $v_p = k_{\\mathrm{cat},p} C_p$。使用定义 $V_p = k_{\\mathrm{cat},p} E_p^{\\mathrm{tot}}$ 和 $K_p = \\frac{k_{-1,p} + k_{\\mathrm{cat},p}}{k_{1,p}}$，我们找到去磷酸化通量的 MM 速率形式：\n$$ v_p = \\frac{V_p S^{\\ast}}{K_p + S^{\\ast}} $$\n\n### 第2部分：$S^{\\ast}(t)$ 的 ODE\n\n磷酸化底物 $S^{\\ast}$ 的浓度变化率是其生成速率（$v_k$）与降解速率（$v_p$）之差。\n$$ \\frac{dS^{\\ast}}{dt} = v_k - v_p = \\frac{V_k S}{K_k + S} - \\frac{V_p S^{\\ast}}{K_p + S^{\\ast}} $$\n为了将其写成关于 $S^{\\ast}(t)$ 的单个 ODE，我们必须用 $S^{\\ast}$ 和常数来表示 $S$。QSSA 在总酶浓度远小于总底物浓度时（$E_k^{\\mathrm{tot}}, E_p^{\\mathrm{tot}} \\ll S^{\\mathrm{tot}}$）是有效的。这意味着复合物 $C_k$ 和 $C_p$ 的浓度与 $S^{\\mathrm{tot}}$ 相比可以忽略不计。因此，底物守恒定律 $S^{\\mathrm{tot}} = S + S^{\\ast} + C_k + C_p$ 可以简化为 $S^{\\mathrm{tot}} \\approx S + S^{\\ast}$。这是在 MM 框架内分析此类循环时的标准假设。\n使用此近似，我们有 $S = S^{\\mathrm{tot}} - S^{\\ast}$。将其代入 $\\frac{dS^{\\ast}}{dt}$ 的方程中：\n$$ \\frac{dS^{\\ast}}{dt} = \\frac{V_k (S^{\\mathrm{tot}} - S^{\\ast})}{K_k + (S^{\\mathrm{tot}} - S^{\\ast})} - \\frac{V_p S^{\\ast}}{K_p + S^{\\ast}} $$\n这就是所求的关于 $S^{\\ast}(t)$ 的单个 ODE。\n\n### 第3部分：稳态分数 $f^{\\ast}$\n\n在稳态下，$\\frac{dS^{\\ast}}{dt} = 0$。令 $S^{\\ast}_{ss}$ 为 $S^{\\ast}$ 的稳态浓度。\n$$ \\frac{V_k (S^{\\mathrm{tot}} - S^{\\ast}_{ss})}{K_k + S^{\\mathrm{tot}} - S^{\\ast}_{ss}} = \\frac{V_p S^{\\ast}_{ss}}{K_p + S^{\\ast}_{ss}} $$\n我们需要求解稳态分数 $f^{\\ast} = \\frac{S^{\\ast}_{ss}}{S^{\\mathrm{tot}}}$。将 $S^{\\ast}_{ss} = f^{\\ast} S^{\\mathrm{tot}}$ 代入稳态方程：\n$$ \\frac{V_k (S^{\\mathrm{tot}} - f^{\\ast}S^{\\mathrm{tot}})}{K_k + S^{\\mathrm{tot}} - f^{\\ast}S^{\\mathrm{tot}}} = \\frac{V_p f^{\\ast}S^{\\mathrm{tot}}}{K_p + f^{\\ast}S^{\\mathrm{tot}}} $$\n$$ \\frac{V_k S^{\\mathrm{tot}}(1 - f^{\\ast})}{K_k + S^{\\mathrm{tot}}(1 - f^{\\ast})} = \\frac{V_p f^{\\ast}S^{\\mathrm{tot}}}{K_p + f^{\\ast}S^{\\mathrm{tot}}} $$\n交叉相乘并消去 $S^{\\mathrm{tot}}$（假设 $S^{\\mathrm{tot}}>0$）：\n$$ V_k (1 - f^{\\ast})(K_p + f^{\\ast}S^{\\mathrm{tot}}) = V_p f^{\\ast}(K_k + S^{\\mathrm{tot}}(1 - f^{\\ast})) $$\n展开两侧：\n$$ V_k (K_p + f^{\\ast}S^{\\mathrm{tot}} - f^{\\ast}K_p - (f^{\\ast})^2 S^{\\mathrm{tot}}) = V_p (f^{\\ast}K_k + f^{\\ast}S^{\\mathrm{tot}} - (f^{\\ast})^2 S^{\\mathrm{tot}}) $$\n$$ V_k K_p + (V_k S^{\\mathrm{tot}} - V_k K_p)f^{\\ast} - V_k S^{\\mathrm{tot}}(f^{\\ast})^2 = (V_p K_k + V_p S^{\\mathrm{tot}})f^{\\ast} - V_p S^{\\mathrm{tot}}(f^{\\ast})^2 $$\n整理成标准二次形式 $a(f^{\\ast})^2 + b(f^{\\ast}) + c = 0$：\n$$ (V_p S^{\\mathrm{tot}} - V_k S^{\\mathrm{tot}})(f^{\\ast})^2 + (V_k S^{\\mathrm{tot}} - V_k K_p - V_p K_k - V_p S^{\\mathrm{tot}})f^{\\ast} + V_k K_p = 0 $$\n同除以 $S^{\\mathrm{tot}}$（因为 $S^{\\mathrm{tot}} \\neq 0$）：\n$$ (V_p - V_k)(f^{\\ast})^2 + \\left(V_k - V_p - \\frac{V_k K_p}{S^{\\mathrm{tot}}} - \\frac{V_p K_k}{S^{\\mathrm{tot}}}\\right)f^{\\ast} + \\frac{V_k K_p}{S^{\\mathrm{tot}}} = 0 $$\n二次方程的系数为：\n$$ a = V_p - V_k $$\n$$ b = V_k(1 - \\frac{K_p}{S^{\\mathrm{tot}}}) - V_p(1 + \\frac{K_k}{S^{\\mathrm{tot}}}) $$\n$$ c = \\frac{V_k K_p}{S^{\\mathrm{tot}}} $$\n$f^{\\ast}$ 的解由二次公式给出，$f^{\\ast} = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$。\n为了选择物理上正确的根（$0 \\le f^{\\ast} \\le 1$），我们分析系统的行为。详细分析表明，通过在分子中取负号可以一致地获得正确的物理 C 解。例如，在酶饱和的极限情况下（$S^{\\mathrm{tot}} \\gg K_k, K_p$），系统表现出开关样行为，即如果 $V_p > V_k$，则 $f^{\\ast} \\to 0$；如果 $V_k > V_p$，则 $f^{\\ast} \\to 1$。带有负号的根正确地捕捉了整个参数空间内的这种双稳态特性。\n\n因此，$f^{\\ast}$ 的闭式解析表达式为：\n$$ f^{\\ast} = \\frac{-b - \\sqrt{b^2 - 4ac}}{2a} $$\n代入 $a$，$b$ 和 $c$ 的表达式：\n$$ f^{\\ast} = \\frac{-\\left(V_k(1 - \\frac{K_p}{S^{\\mathrm{tot}}}) - V_p(1 + \\frac{K_k}{S^{\\mathrm{tot}}})\\right) - \\sqrt{\\left(V_k(1 - \\frac{K_p}{S^{\\mathrm{tot}}}) - V_p(1 + \\frac{K_k}{S^{\\mathrm{tot}}})\\right)^2 - 4(V_p - V_k)\\left(\\frac{V_k K_p}{S^{\\mathrm{tot}}}\\right)}}{2(V_p - V_k)} $$\n这可以改写为：\n$$ f^{\\ast} = \\frac{V_p(1 + \\frac{K_k}{S^{\\mathrm{tot}}}) - V_k(1 - \\frac{K_p}{S^{\\mathrm{tot}}}) - \\sqrt{\\left(V_p(1 + \\frac{K_k}{S^{\\mathrm{tot}}}) - V_k(1 - \\frac{K_p}{S^{\\mathrm{tot}}})\\right)^2 - 4(V_p - V_k)\\frac{V_k K_p}{S^{\\mathrm{tot}}}}}{2(V_p - V_k)} $$",
            "answer": "$$ \\boxed{\\frac{V_p(1 + \\frac{K_k}{S^{\\mathrm{tot}}}) - V_k(1 - \\frac{K_p}{S^{\\mathrm{tot}}}) - \\sqrt{\\left(V_p(1 + \\frac{K_k}{S^{\\mathrm{tot}}}) - V_k(1 - \\frac{K_p}{S^{\\mathrm{tot}}})\\right)^2 - 4(V_p - V_k)\\frac{V_k K_p}{S^{\\mathrm{tot}}}}}{2(V_p - V_k)}} $$"
        },
        {
            "introduction": "在确定性模型的平均行为之上，细胞过程还存在固有的随机波动。本练习介绍了一种强大的分析工具——线性噪声近似（LNA），用于量化PTM循环中底物分子数量的涨落。通过推导系统在稳态下的均值和方差，你将学会如何评估随机噪声对系统行为的影响，这对于理解细胞信号的可靠性至关重要。",
            "id": "3339103",
            "problem": "单个真核细胞含有一种蛋白质底物，该底物会经历磷酸化和去磷酸化的翻译后修饰。令未修饰的底物表示为 $S$，磷酸化的底物表示为 $S^{*}$。假设总底物拷贝数 $N_{T}$ 是守恒的，因此 $S + S^{*}$ 是一个常数。激酶和磷酸酶的活性是组成性的且丰度很高，因此修饰和去修饰的有效动力学对底物而言是伪一级反应：$S \\to S^{*}$ 的发生速率常数为 $k_{f}$，$S^{*} \\to S$ 的发生速率常数为 $k_{r}$。令 $n$ 表示 $S^{*}$ 的拷贝数。该系统是充分混合的，并在固定体积 $\\Omega$ 中根据化学主方程 (Chemical Master Equation, CME) 演化。\n\n从 CME 和 van Kampen 的系统尺寸展开（该展开可得到线性噪声近似，LNA）出发，基于第一性原理推导 $S^{*}$ 的确定性稳态平均拷贝数以及 LNA 下 $n$ 的稳态方差。您的推导应从 $N_{T}$ 的守恒定律、两个反应的化学计量关系以及相关的倾向函数开始，然后推导至宏观速率方程和线性化的涨落动力学。解释 LNA 对稳态均值的预测与确定性稳态预测的比较，并根据倾向函数的线性特性来证明您所得到的任何相等关系。最后，将稳态时 $S^{*}$ 拷贝数的法诺因子 $F$（定义为 $F = \\mathrm{Var}(n)/\\mathbb{E}[n]$）用 $k_{f}$ 和 $k_{r}$ 表示。\n\n答案要求：将最终答案以 $F$ 关于 $k_{f}$ 和 $k_{r}$ 的单个闭式解析表达式的形式报告。不需要数值近似或四舍五入。不需要单位。",
            "solution": "该问题陈述经评估具有科学依据、问题明确、客观且自洽。它描述了计算系统生物学中翻译后修饰的一个典型模型。指定用于分析的工具，即化学主方程 (CME) 和线性噪声近似 (LNA)，是标准且适用于所描述系统的。不存在矛盾、歧义或不合理的假设。该问题是有效的。\n\n该问题描述了一个包含两种化学物质的系统：未修饰的底物 $S$ 和磷酸化的底物 $S^*$。分子总数 $N_{T}$ 是守恒的。令 $n$ 为 $S^*$ 的拷贝数，则 $S$ 的拷贝数为 $N_T - n$。系统根据两个反应进行演化：\n1.  磷酸化：$S \\to S^*$。此反应产生一个 $S^*$ 分子，因此 $n$ 的变化为 $\\nu_1 = +1$。倾向函数表示该反应在单位时间内发生的概率，根据伪一级动力学给出，为 $a_1(n) = k_f (N_T - n)$。\n2.  去磷酸化：$S^* \\to S$。此反应消耗一个 $S^*$ 分子，因此 $n$ 的变化为 $\\nu_2 = -1$。倾向函数为 $a_2(n) = k_r n$。\n\n宏观速率方程描述了分子平均数随时间的演化，在确定性极限下我们同样用 $n$ 表示。它通过对所有反应的化学计量变化与倾向函数的乘积求和得到：\n$$\n\\frac{dn}{dt} = \\sum_{j=1}^{2} \\nu_j a_j(n) = (+1) \\cdot a_1(n) + (-1) \\cdot a_2(n)\n$$\n代入倾向函数的表达式得到：\n$$\n\\frac{dn}{dt} = k_f(N_T - n) - k_r n\n$$\n在稳态时，净变化率为零，即 $\\frac{dn}{dt} = 0$。我们可以求解确定性稳态拷贝数，记为 $n_{ss}$：\n$$\nk_f(N_T - n_{ss}) - k_r n_{ss} = 0\n$$\n$$\nk_f N_T - k_f n_{ss} - k_r n_{ss} = 0\n$$\n$$\nk_f N_T = (k_f + k_r) n_{ss}\n$$\n$$\nn_{ss} = \\frac{k_f N_T}{k_f + k_r}\n$$\n\n接下来，我们应用线性噪声近似 (LNA)，它是由 CME 的 van Kampen 系统尺寸展开推导出来的。LNA 提供了分子数均值 $\\mathbb{E}[n]$ 和方差 $\\mathrm{Var}(n)$ 随时间演化的方程。\n\n均值的方程为：\n$$\n\\frac{d\\mathbb{E}[n]}{dt} = \\mathbb{E}\\left[ \\sum_{j=1}^{2} \\nu_j a_j(n) \\right] = \\mathbb{E}[k_f(N_T - n) - k_r n]\n$$\n因为两个倾向函数 $a_1(n) = k_f N_T - k_f n$ 和 $a_2(n) = k_r n$ 都是状态变量 $n$ 的线性函数，所以期望算子可以分配：$\\mathbb{E}[a(n)] = a(\\mathbb{E}[n])$。\n$$\n\\frac{d\\mathbb{E}[n]}{dt} = k_f(N_T - \\mathbb{E}[n]) - k_r \\mathbb{E}[n]\n$$\n这个均值方程在形式上与宏观速率方程相同。因此，LNA 下的稳态均值 $\\mathbb{E}[n]_{ss}$ 与确定性稳态值 $n_{ss}$ 相同：\n$$\n\\mathbb{E}[n]_{ss} = \\frac{k_f N_T}{k_f + k_r}\n$$\n\nLNA 为方差 $V(t) = \\mathrm{Var}(n(t))$ 提供了一个动力学方程，称为李雅普诺夫方程 (Lyapunov equation)：\n$$\n\\frac{dV}{dt} = 2 J V + D\n$$\n在这里，$J$ 是确定性速率向量的雅可比矩阵（在此一维情况下为标量），$D$ 是扩散矩阵（也为标量），两者均在稳态均值处求值。\n\n确定性速率函数为 $F(n) = k_f(N_T - n) - k_r n$。雅可比矩阵 $J$ 是它对 $n$ 的一阶导数：\n$$\nJ = \\frac{dF}{dn} = \\frac{d}{dn} (k_f N_T - (k_f + k_r)n) = -(k_f + k_r)\n$$\n雅可比矩阵是一个常数，不依赖于 $n$。\n\n扩散项 $D$ 定义为 $D = \\sum_{j} \\nu_j^2 a_j(\\mathbb{E}[n]_{ss})$：\n$$\nD = (+1)^2 a_1(\\mathbb{E}[n]_{ss}) + (-1)^2 a_2(\\mathbb{E}[n]_{ss}) = a_1(\\mathbb{E}[n]_{ss}) + a_2(\\mathbb{E}[n]_{ss})\n$$\n在稳态时，平均正向通量必须等于平均反向通量，因此 $a_1(\\mathbb{E}[n]_{ss}) = a_2(\\mathbb{E}[n]_{ss})$。我们可以计算其中一个：\n$$\na_2(\\mathbb{E}[n]_{ss}) = k_r \\mathbb{E}[n]_{ss} = k_r \\left( \\frac{k_f N_T}{k_f + k_r} \\right) = \\frac{k_f k_r N_T}{k_f + k_r}\n$$\n因此，扩散项为：\n$$\nD = 2 \\cdot a_2(\\mathbb{E}[n]_{ss}) = \\frac{2 k_f k_r N_T}{k_f + k_r}\n$$\n在稳态时，方差是恒定的，所以 $\\frac{dV}{dt} = 0$。我们求解稳态方差 $V_{ss} = \\mathrm{Var}(n)_{ss}$：\n$$\n0 = 2 J V_{ss} + D\n$$\n$$\nV_{ss} = -\\frac{D}{2J} = - \\frac{ \\frac{2 k_f k_r N_T}{k_f + k_r} }{ 2(-(k_f + k_r)) } = \\frac{k_f k_r N_T}{(k_f + k_r)^2}\n$$\n\n最后一步是计算法诺因子 $F$，它定义为方差与均值的比值，$F = \\mathrm{Var}(n)/\\mathbb{E}[n]$。使用稳态结果：\n$$\nF = \\frac{V_{ss}}{\\mathbb{E}[n]_{ss}} = \\frac{ \\frac{k_f k_r N_T}{(k_f + k_r)^2} }{ \\frac{k_f N_T}{k_f + k_r} }\n$$\n通过消去公因子（$k_f N_T$ 和一个 $(k_f + k_r)$ 因子）来简化表达式：\n$$\nF = \\frac{k_r}{k_f + k_r}\n$$\n该表达式以动力学速率常数 $k_f$ 和 $k_r$ 的形式给出了稳态下磷酸化底物 $S^*$ 拷贝数的法诺因子。对于这个具有线性倾向函数的特定系统，LNA 提供了精确的前两阶矩，且 $n$ 的稳态分布是二项分布，$n \\sim \\mathrm{Binomial}(N_T, p)$，其中 $p = k_f / (k_f + k_r)$。因此法诺因子为 $1 - p = k_r/(k_f + k_r)$，这证实了我们的推导。",
            "answer": "$$\\boxed{\\frac{k_{r}}{k_{f} + k_{r}}}$$"
        },
        {
            "introduction": "现代计算系统生物学严重依赖于从大规模数据集中训练出的预测模型。本编码练习提供了一个关键但常被忽视的步骤的实践经验：评估和校准机器学习分类器的概率输出。你将学习如何通过可靠性图和Brier分数等指标来诊断模型的校准性能，并应用校准技术来确保预测概率能真实地反映PTM事件的发生可能性。",
            "id": "3339086",
            "problem": "您的任务是评估和改进一个翻译后修饰位点分类器的概率校准，该分类器为二元结果输出预测概率。目标是在留出的评估数据上计算校准诊断指标，如果检测到未校准，则应用并比较两种后处理校准方法。您的程序必须以可复现和数值稳健的方式实现完整的流程。所有概率值都是无量纲的量，不涉及物理单位。\n\n基础科学背景：在计算系统生物学中，翻译后修饰位点预测器通常输出概率，这些概率应反映真实的事件频率。概率校准量化了预测概率与经验结果频率的吻合程度。在此背景下，广泛使用且经过充分测试的指标包括布里尔分数（Brier score）、通过对预测概率进行分箱构建的可靠性图（reliability diagrams），以及诸如期望校准误差（Expected Calibration Error）之类的汇总统计量。通过参数化S型映射（通常称为普拉特缩放，Platt scaling）或非参数单调映射（保序回归，isotonic regression）进行的后处理校准常被用于改善校准效果。\n\n您的任务是：\n\n- 确定性地生成合成数据集，以模拟翻译后修饰位点预测器概率输出的不同校准情况。对于每个数据集，从Beta分布中抽取每个样本的潜在真实概率，然后根据这些概率进行独立的伯努利试验，抽取二元结果。通过使用潜在概率本身，或使用指定斜率的对数几率的逻辑斯蒂变换对潜在概率进行单调失真，来构建模型的预测概率。每个数据集使用固定的伪随机种子以确保可复现性。\n- 通过将前一半样本（按生成顺序）作为校准子集，后一半作为评估子集，来划分每个数据集。不允许进行随机打乱。\n- 仅在评估子集上计算：\n  - 布里尔分数（Brier score），即预测概率与二元结果之间的均方误差。将其表示为无量纲标量。\n  - 基于单位区间上等宽分箱的可靠性图摘要。使用恰好 $K=10$ 个分箱，将区间 $[0,1]$ 划分为等宽的子区间。对于每个非空分箱，计算正例的经验比例和平均预测概率。使用这些值计算期望校准误差（ECE），定义为经验比例与平均预测概率之间分箱级绝对差的加权平均值，其中权重为分箱样本比例。将ECE表示为无量纲标量。\n\n- 应用在校准子集上训练的两种后处理校准方法：\n  - 逻辑斯蒂S型校准：学习一个仿射变换，其参数为 $a$ 和 $b$，将原始预测概率 $s$ 映射到校准后的概率 $\\sigma(a \\cdot \\operatorname{logit}(\\max(\\epsilon,\\min(1-\\epsilon,s))) + b)$，其中 $\\sigma$ 是逻辑斯蒂S型函数，$\\operatorname{logit}$ 是其反函数，数值稳定性常数 $\\epsilon$ 设为 $10^{-15}$。通过在校准子集上最大化伯努利对数似然来估计 $a$ 和 $b$。优化必须是确定性的，并且对 $a$ 和 $b$ 无约束。\n  - 保序回归校准：通过使用池邻近违规者算法（pool-adjacent-violators algorithm）在单调性约束下求解加权最小二乘问题，学习一个从原始预测概率到校准后概率的非递减、分段常数映射。\n\n- 在校准子集上拟合两种校准器后，将每种校准器应用于评估子集，并为校准后的预测重新计算布里尔分数和ECE。\n\n- 对于每个数据集，通过选择在评估子集上具有较低布里尔分数的校准器来决定优先选择哪一种。如果在数值舍入误差范围内出现平局，则优先选择保序回归。\n\n- 数值计算说明：\n  - 可靠性计算使用固定数量的分箱 $K=10$。\n  - 使用上述拆分协议进行严格的对半拆分；如果样本数 $N$ 为奇数，则校准子集必须有 $\\lfloor N/2 \\rfloor$ 个样本，评估子集必须有 $N - \\lfloor N/2 \\rfloor$ 个样本。\n  - 计算任何概率值 $p$ 的 $\\operatorname{logit}$ 时，在应用 $\\operatorname{logit}$ 之前将 $p$ 裁剪到 $[\\epsilon, 1-\\epsilon]$ 范围内，其中 $\\epsilon = 10^{-15}$；同样，在为了对数的数值稳定性而必要时，将S型函数的输出裁剪到 $[\\epsilon, 1-\\epsilon]$ 范围内。\n  - 将所有浮点输出四舍五入到 $6$ 位小数。\n\n测试套件：您的程序必须实现以下四个数据集。对于每个数据集，按照指定方式生成数据，使用给定的种子、Beta分布参数、失真斜率和数据集大小 $N$。\n\n- 数据集A（良好校准的基线）：\n  - 种子：$1$\n  - $N = 1000$\n  - 潜在概率 $p \\sim \\operatorname{Beta}(\\alpha=2,\\ \\beta=8)$\n  - 标签 $y \\sim \\operatorname{Bernoulli}(p)$\n  - 原始模型预测 $s = p$（无失真）\n\n- 数据集B（过度自信的预测）：\n  - 种子：$2$\n  - $N = 1000$\n  - 潜在概率 $p \\sim \\operatorname{Beta}(\\alpha=2,\\ \\beta=8)$\n  - 标签 $y \\sim \\operatorname{Bernoulli}(p)$\n  - 原始模型预测 $s = \\sigma(c \\cdot \\operatorname{logit}(p))$，其中 $c=2$\n\n- 数据集C（置信度不足的预测）：\n  - 种子：$3$\n  - $N = 1000$\n  - 潜在概率 $p \\sim \\operatorname{Beta}(\\alpha=2,\\ \\beta=8)$\n  - 标签 $y \\sim \\operatorname{Bernoulli}(p)$\n  - 原始模型预测 $s = \\sigma(c \\cdot \\operatorname{logit}(p))$，其中 $c=0.5$\n\n- 数据集D（稀有正例，严重不平衡伴随过度自信）：\n  - 种子：$4$\n  - $N = 4000$\n  - 潜在概率 $p \\sim \\operatorname{Beta}(\\alpha=1,\\ \\beta=39)$\n  - 标签 $y \\sim \\operatorname{Bernoulli}(p)$\n  - 原始模型预测 $s = \\sigma(c \\cdot \\operatorname{logit}(p))$，其中 $c=2$\n\n评估和输出规范：\n\n- 对于每个数据集，在评估子集上计算：\n  - 使用原始模型预测 $s$ 的未校准布里尔分数和ECE。\n  - 经逻辑斯蒂校准的布里尔分数和ECE。\n  - 经保序回归校准的布里尔分数和ECE。\n  - 首选校准器索引，其中 $0$ 表示逻辑斯蒂S型校准，$1$ 表示保序回归，根据上述较低布里尔分数的规则选择。\n\n- 最终输出格式：\n  - 您的程序必须生成单行输出，其中包含一个由四个列表组成的列表，每个列表对应一个数据集，顺序为A、B、C、D。每个内部列表必须按以下顺序包含七个值：\n    - 未校准的布里尔分数，\n    - 经逻辑斯蒂校准的布里尔分数，\n    - 经保序回归校准的布里尔分数，\n    - 未校准的ECE，\n    - 经逻辑斯蒂校准的ECE，\n    - 经保序回归校准的ECE，\n    - 首选校准器索引。\n  - 所有浮点值必须四舍五入到 $6$ 位小数。首选校准器索引必须是整数 $0$ 或 $1$。\n  - 输出必须严格按照Python风格的列表字面量打印，例如：\"[[uA,lA,iA,eA_l,eA_log,eA_iso,kA],[uB,lB,iB,eB_l,eB_log,eB_iso,kB],[uC,lC,iC,eC_l,eC_log,eC_iso,kC],[uD,lD,iD,eD_l,eD_log,eD_iso,kD]]\"，前后无额外空格，也无附加文本。\n\n约束和假设：\n\n- 所有计算必须是确定性的，并且在给定固定种子的情况下是可复现的。\n- 所有概率都是无量纲的，不需要进行单位转换。\n- 不涉及角度。\n- 如果在可靠性计算中任何分箱为空，则必须通过为其分配零权重将其从ECE聚合中排除，这等同于使用分箱样本比例作为权重。\n\n您的程序在执行时无需任何用户输入或外部文件，应能生成上述单行输出。",
            "solution": "该问题要求实现一个计算流程，以评估和改进一个二元分类器的概率校准，背景设定为翻译后修饰位点的预测。这包括生成合成数据，计算校准诊断指标，应用并比较两种后处理校准方法（逻辑斯蒂回归和保序回归），并根据在留出评估集上的性能选择更优的方法。\n\n每个步骤背后的科学和算法原理如下：\n\n**1. 数据生成与划分**\n\n为了创建可复现和可控的测试场景，我们生成合成数据集。对于一个大小为 $N$ 的数据集，过程如下：\n- **潜在概率 ($p$)**：每个样本的真实、未观察到的概率从Beta分布中抽取，$p_i \\sim \\operatorname{Beta}(\\alpha, \\beta)$。Beta分布是模拟概率的自然选择，因为其支撑集在区间 $[0, 1]$ 上。\n- **二元结果 ($y$)**：真实类别标签（例如，是否为修饰位点）从由潜在概率决定的独立伯努利试验中抽取，$y_i \\sim \\operatorname{Bernoulli}(p_i)$。\n- **预测概率 ($s$)**：模拟分类器的原始输出被建模为完美校准的（$s_i = p_i$）或真实概率的单调失真。失真是通过 $s_i = \\sigma(c \\cdot \\operatorname{logit}(p_i))$ 在对数几率空间中应用的，其中 $\\sigma(z) = (1 + e^{-z})^{-1}$ 是逻辑斯蒂S型函数，$\\operatorname{logit}(p) = \\log(p/(1-p))$，而 $c$ 是一个失真斜率。$c > 1$ 的值模拟了过度自信的预测（被推向 $0$ 或 $1$），而 $c  1$ 则模拟了置信度不足的预测（被推向 $0.5$）。为了在计算logit时保持数值稳定性，概率被裁剪到一个小区间 $[\\epsilon, 1-\\epsilon]$ 内，其中 $\\epsilon=10^{-15}$。\n- **数据划分**：生成的 $N$ 个样本的数据集被确定性地划分为两个相等的部分。前 $\\lfloor N/2 \\rfloor$ 个样本构成校准集，用于训练校准器；剩下的 $N - \\lfloor N/2 \\rfloor$ 个样本构成评估集，用于性能评估。这种严格的、不打乱的划分确保了可复现性。\n\n**2. 校准诊断**\n\n我们使用两个标准指标在评估集上量化校准质量：\n- **布里尔分数（Brier Score）**：这是预测概率 $s_i$ 和二元结果 $y_i$ 之间的均方误差。它是一个既衡量校准度又衡量判别能力的正常评分规则。\n$$\n\\text{Brier Score} = \\frac{1}{N_{\\text{eval}}} \\sum_{i=1}^{N_{\\text{eval}}} (s_i - y_i)^2\n$$\n- **期望校准误差 (ECE)**：该指标专门衡量未校准的程度。它通过将预测概率划分为 $K=10$ 个等宽的分箱来计算。对于每个分箱 $m$，我们计算平均预测概率（置信度, $\\text{conf}_m$）和正例的比例（准确度, $\\text{acc}_m$）。ECE是所有分箱中置信度和准确度之间绝对差异的加权平均值。\n$$\n\\text{ECE} = \\sum_{m=1}^{K} \\frac{|B_m|}{N_{\\text{eval}}} |\\text{acc}_m - \\text{conf}_m|\n$$\n其中 $B_m$ 是预测概率落入分箱 $m$ 的样本集合。空分箱对总和没有贡献。\n\n**3. 后处理校准方法**\n\n实现了两种方法来校正原始预测，并在校准集上进行训练。\n- **逻辑斯蒂校准（普拉特缩放，Platt Scaling）**：此方法学习原始分数对数几率的参数化S型变换。对于原始分数 $s$，校准后的概率 $s'_{\\text{logistic}}$ 由下式给出：\n$$\ns'_{\\text{logistic}} = \\sigma(a \\cdot \\operatorname{logit}(s) + b)\n$$\n参数 $a$ 和 $b$ 通过在校准数据 $(s_{\\text{calib}}, y_{\\text{calib}})$ 上最小化伯努利分布的负对数似然（或最大化对数似然）来找到。这是一个凸优化问题，我们使用L-BFGS-B算法来解决，从恒等变换（$a=1, b=0$）开始以确保确定性。\n- **保序回归（Isotonic Regression）**：这是一种非参数方法，它找到一个最佳拟合的非递减、分段常数函数，将原始分数映射到校准后的概率。该拟合是通过在单调性约束 $\\theta_1 \\le \\theta_2 \\le \\dots \\le \\theta_n$ 下最小化加权平方误差和来获得的。对此的标准算法是池邻近违规者算法（PAVA）。首先，在校准分数 $s_{\\text{calib}}$ 的唯一值上拟合保序函数，使用每个唯一分数处正例的经验频率作为目标值，并使用其出现次数作为权重。这定义了一个阶跃函数，然后用它将评估分数映射到新的校准概率。\n\n**4. 评估与选择**\n\n将两个训练好的校准器应用于评估集的原始分数（$s_{\\text{eval}}$），以产生新的校准概率集 $s'_{\\text{logistic}}$ 和 $s'_{\\text{isotonic}}$。对每组校准后的概率重新计算布里尔分数和ECE。最后一步是选择首选的校准器。决策规则是选择在评估集上产生较低布里尔分数的方法。如果布里尔分数相等，则优先选择保序回归。\n\n整个流程对四个指定的数据集中的每一个都执行一遍，收集并格式化七个结果指标以供输出。实现使用 `numpy` 进行数值计算，使用 `scipy` 进行优化和插值任务，并遵循指定的库版本。PAVA算法是根据第一性原理实现的，因为它在指定的 `scipy` 版本的公共API中不可用。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.interpolate import interp1d\n\n# Define global constants as per problem description\nEPSILON = 1e-15\nK_BINS = 10\n\ndef logit(p: np.ndarray) - np.ndarray:\n    \"\"\"Computes the logit function with numerical stability clipping.\"\"\"\n    p_clipped = np.clip(p, EPSILON, 1 - EPSILON)\n    return np.log(p_clipped / (1 - p_clipped))\n\ndef sigma(x: np.ndarray) - np.ndarray:\n    \"\"\"Computes the logistic sigmoid function.\"\"\"\n    return 1 / (1 + np.exp(-x))\n\ndef generate_data(seed: int, n_samples: int, alpha: float, beta: float, distortion_c: float = None) - tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Generates a synthetic dataset.\"\"\"\n    rng = np.random.default_rng(seed)\n    # Generate latent probabilities from a Beta distribution\n    p = rng.beta(alpha, beta, size=n_samples)\n    # Generate binary outcomes from Bernoulli trials\n    y = rng.binomial(1, p)\n\n    # Generate model predictions s\n    if distortion_c is None:\n        s = p\n    else:\n        s = sigma(distortion_c * logit(p))\n    \n    return p, y, s\n\ndef compute_metrics(s: np.ndarray, y: np.ndarray) - tuple[float, float]:\n    \"\"\"Computes Brier score and Expected Calibration Error (ECE).\"\"\"\n    # Brier Score\n    brier_score = np.mean((s - y)**2)\n\n    # Expected Calibration Error (ECE)\n    bin_edges = np.linspace(0.0, 1.0, K_BINS + 1)\n    # np.digitize maps values to bins [0, K-1]\n    bin_indices = np.digitize(s, bin_edges[1:-1])\n\n    ece = 0.0\n    for m in range(K_BINS):\n        in_bin = (bin_indices == m)\n        n_m = np.sum(in_bin)\n        \n        if n_m  0:\n            acc_m = np.mean(y[in_bin])  # Empirical fraction of positives\n            conf_m = np.mean(s[in_bin]) # Mean predicted probability\n            ece += (n_m / len(y)) * np.abs(acc_m - conf_m)\n            \n    return brier_score, ece\n\ndef fit_logistic_calibration(s: np.ndarray, y: np.ndarray) - np.ndarray:\n    \"\"\"Fits a logistic calibration model (Platt scaling).\"\"\"\n    s_logit = logit(s)\n    \n    def nll(params: np.ndarray, s_logit: np.ndarray, y: np.ndarray) - float:\n        \"\"\"Negative log-likelihood for logistic calibration.\"\"\"\n        a, b = params\n        p_cal = sigma(a * s_logit + b)\n        p_cal_clipped = np.clip(p_cal, EPSILON, 1 - EPSILON)\n        return -np.sum(y * np.log(p_cal_clipped) + (1 - y) * np.log(1 - p_cal_clipped))\n\n    # Initial guess: a=1, b=0 (identity transformation) for determinism\n    initial_guess = np.array([1.0, 0.0])\n    result = minimize(nll, initial_guess, args=(s_logit, y), method='L-BFGS-B')\n    \n    return result.x\n\ndef apply_logistic_calibration(s: np.ndarray, params: np.ndarray) - np.ndarray:\n    \"\"\"Applies a trained logistic calibration model.\"\"\"\n    a, b = params\n    return sigma(a * logit(s) + b)\n\ndef pava(y: np.ndarray, w: np.ndarray) - np.ndarray:\n    \"\"\"Pool-Adjacent-Violators Algorithm for weighted isotonic regression.\"\"\"\n    n = len(y)\n    x = np.zeros(n)\n    active_set_indices = []\n    active_set_y = []\n    active_set_w = []\n\n    for i in range(n):\n        active_set_indices.append([i])\n        active_set_y.append(y[i])\n        active_set_w.append(w[i])\n\n        while len(active_set_y)  1 and active_set_y[-2] = active_set_y[-1]:\n            # Merge the last two pools\n            merged_indices = active_set_indices[-2] + active_set_indices[-1]\n            merged_weight = active_set_w[-2] + active_set_w[-1]\n            \n            numerator = active_set_y[-2] * active_set_w[-2] + active_set_y[-1] * active_set_w[-1]\n            new_y = numerator / merged_weight if merged_weight  0 else 0\n\n            # Update the second-to-last pool\n            active_set_indices[-2] = merged_indices\n            active_set_y[-2] = new_y\n            active_set_w[-2] = merged_weight\n            \n            # Pop the last pool\n            active_set_indices.pop()\n            active_set_y.pop()\n            active_set_w.pop()\n\n    for i, indices in enumerate(active_set_indices):\n        x[indices] = active_set_y[i]\n        \n    return x\n\ndef fit_isotonic_calibration(s: np.ndarray, y: np.ndarray) - tuple[np.ndarray, np.ndarray]:\n    \"\"\"Fits an isotonic regression model.\"\"\"\n    # Sort data by scores\n    sorted_indices = np.argsort(s)\n    s_sorted, y_sorted = s[sorted_indices], y[sorted_indices]\n\n    # Aggregate y for unique scores\n    unique_s, s_indices = np.unique(s_sorted, return_inverse=True)\n    weights = np.bincount(s_indices)\n    y_means = np.bincount(s_indices, weights=y_sorted) / weights\n\n    # Apply PAVA\n    p_isotonic = pava(y_means, weights)\n    \n    return unique_s, p_isotonic\n\ndef apply_isotonic_calibration(s: np.ndarray, calib_map: tuple[np.ndarray, np.ndarray]) - np.ndarray:\n    \"\"\"Applies a trained isotonic regression model.\"\"\"\n    unique_s, p_isotonic = calib_map\n    \n    # Use interpolation to create a step function from the PAVA result\n    iso_fn = interp1d(unique_s, p_isotonic, kind='previous', \n                      bounds_error=False, fill_value=(p_isotonic[0], p_isotonic[-1]))\n                      \n    return iso_fn(s)\n\ndef solve():\n    \"\"\"Main function to run the full pipeline and print results.\"\"\"\n    test_cases = [\n        # Dataset A: Well-calibrated\n        {'seed': 1, 'N': 1000, 'alpha': 2, 'beta': 8, 'c': None},\n        # Dataset B: Over-confident\n        {'seed': 2, 'N': 1000, 'alpha': 2, 'beta': 8, 'c': 2.0},\n        # Dataset C: Under-confident\n        {'seed': 3, 'N': 1000, 'alpha': 2, 'beta': 8, 'c': 0.5},\n        # Dataset D: Imbalanced, over-confident\n        {'seed': 4, 'N': 4000, 'alpha': 1, 'beta': 39, 'c': 2.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        p, y, s = generate_data(\n            seed=case['seed'], n_samples=case['N'],\n            alpha=case['alpha'], beta=case['beta'], distortion_c=case['c']\n        )\n        \n        # Split data\n        n_calib = case['N'] // 2\n        s_calib, y_calib = s[:n_calib], y[:n_calib]\n        s_eval, y_eval = s[n_calib:], y[n_calib:]\n\n        # 1. Uncalibrated metrics\n        brier_uncal, ece_uncal = compute_metrics(s_eval, y_eval)\n        \n        # 2. Logistic calibration\n        log_params = fit_logistic_calibration(s_calib, y_calib)\n        s_eval_log = apply_logistic_calibration(s_eval, log_params)\n        brier_log, ece_log = compute_metrics(s_eval_log, y_eval)\n\n        # 3. Isotonic calibration\n        iso_map = fit_isotonic_calibration(s_calib, y_calib)\n        s_eval_iso = apply_isotonic_calibration(s_eval, iso_map)\n        brier_iso, ece_iso = compute_metrics(s_eval_iso, y_eval)\n        \n        # 4. Preferred calibrator selection\n        # Prefer isotonic (1) in case of a tie\n        preferred_idx = 1 if brier_iso = brier_log else 0\n\n        results.append([\n            round(brier_uncal, 6), round(brier_log, 6), round(brier_iso, 6),\n            round(ece_uncal, 6), round(ece_log, 6), round(ece_iso, 6),\n            preferred_idx\n        ])\n\n    # Final formatting and printing\n    output_str_parts = []\n    for row in results:\n        formatted_row = [f\"{v:.6f}\" for v in row[:-1]] + [str(int(row[-1]))]\n        output_str_parts.append(f\"[{','.join(formatted_row)}]\")\n    \n    print(f\"[{','.join(output_str_parts)}]\")\n\nsolve()\n```"
        }
    ]
}