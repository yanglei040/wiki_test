{
    "hands_on_practices": [
        {
            "introduction": "This exercise delves into the theoretical heart of Approximate Bayesian Computation, exploring the critical bias-variance trade-off. By analyzing the asymptotic behavior of the Mean Squared Error ($MSE$), you will derive an optimal tolerance $\\epsilon^{*}$ that maximizes the statistical efficiency of your inference, quantified by the Effective Sample Size. This practice provides a formal footing for one of the most crucial tuning decisions in any ABC workflow .",
            "id": "3288593",
            "problem": "A stochastic biochemical reaction network model of a gene regulatory circuit is calibrated by Approximate Bayesian Computation (ABC). Let $S \\in \\mathbb{R}^{d}$ denote a vector of $d$ summary statistics computed from a simulated trajectory, and let $s_{\\text{obs}}$ be the observed summary. The ABC rejection scheme accepts a simulation if the Euclidean distance satisfies $\\rho(S, s_{\\text{obs}}) \\le \\epsilon$, where $\\epsilon > 0$ is the tolerance. Assume the following asymptotic regime for small $\\epsilon$:\n\n- The acceptance probability satisfies $\\alpha(\\epsilon) \\approx k\\,\\epsilon^{d}$, where $d$ is the dimension of $S$ and $k>0$ is a constant determined by the sampling distribution of $S$ at $s_{\\text{obs}}$ and the volume of the $d$-dimensional unit ball.\n- The estimator $\\widehat{m}_{\\epsilon}$ of the posterior mean of a fixed scalar functional $\\phi(\\theta)$, computed from the accepted samples without regression adjustment, has mean squared error $\\operatorname{MSE}(\\epsilon) \\approx \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}$ for small $\\epsilon$, where $\\beta>0$ and $\\gamma>0$ are constants that depend on the smoothness of the data-generating mechanism and the posterior variability of $\\phi(\\theta)$, and $B$ is the total computational budget, i.e., the total number of simulator runs.\n\nDefine the Effective Sample Size (ESS) of the ABC estimator for $\\phi(\\theta)$ as the size of an independent and identically distributed sample from the exact posterior that yields the same mean squared error, namely $\\text{ESS}(\\epsilon) := \\sigma_{\\text{post}}^{2}/\\operatorname{MSE}(\\epsilon)$, where $\\sigma_{\\text{post}}^{2}$ is the exact posterior variance of $\\phi(\\theta)$ (a constant that does not depend on $\\epsilon$).\n\n1. Starting from first principles of small-ball probabilities and kernel neighborhoods in $\\mathbb{R}^{d}$, derive the functional relationship among $\\epsilon$, $\\alpha(\\epsilon)$, and $B$, and express $\\text{ESS}(\\epsilon)$ in terms of $\\epsilon$, $B$, and the constants $d$, $k$, $\\beta$, $\\gamma$, and $\\sigma_{\\text{post}}^{2}$. Clearly state any regularity assumptions you use.\n\n2. For a two-dimensional summary ($d = 2$) with $k = 0.4$, $\\beta = L^{2}$ with $L = 1.5$, $\\gamma = 0.81$, and computational budget $B = 10^{6}$, choose the tolerance $\\epsilon^{*}$ that maximizes $\\text{ESS}(\\epsilon)$. Report $\\epsilon^{*}$ as a dimensionless number, rounded to four significant figures.\n\nYour final answer must be a single real number: the value of $\\epsilon^{*}$.",
            "solution": "The user has provided a problem statement regarding the optimization of tolerance in Approximate Bayesian Computation (ABC). I will first validate the problem's integrity and then, if it is valid, proceed to a full solution.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   Summary statistics vector: $S \\in \\mathbb{R}^{d}$.\n-   Observed summary statistics: $s_{\\text{obs}}$.\n-   ABC acceptance criterion: $\\rho(S, s_{\\text{obs}}) \\le \\epsilon$, where $\\rho$ is the Euclidean distance and $\\epsilon > 0$ is the tolerance.\n-   Asymptotic acceptance probability: $\\alpha(\\epsilon) \\approx k\\,\\epsilon^{d}$ for small $\\epsilon$, with $k > 0$.\n-   Estimator of a posterior mean: $\\widehat{m}_{\\epsilon}$.\n-   Asymptotic Mean Squared Error of the estimator: $\\operatorname{MSE}(\\epsilon) \\approx \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}$ for small $\\epsilon$. Here, $\\beta > 0$, $\\gamma > 0$, and $B$ is the total computational budget.\n-   Definition of Effective Sample Size: $\\text{ESS}(\\epsilon) := \\sigma_{\\text{post}}^{2}/\\operatorname{MSE}(\\epsilon)$, where $\\sigma_{\\text{post}}^{2}$ is the exact posterior variance, a constant.\n-   Part 1 Task: Derive the relationship among $\\epsilon$, $\\alpha(\\epsilon)$, and $B$, and express $\\text{ESS}(\\epsilon)$ in terms of the given constants. State regularity assumptions.\n-   Part 2 Task: For $d = 2$, $k = 0.4$, $\\beta = L^{2}$ with $L = 1.5$, $\\gamma = 0.81$, and $B = 10^{6}$, find the tolerance $\\epsilon^{*}$ that maximizes $\\text{ESS}(\\epsilon)$ and report it rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is scientifically well-grounded in the theory of Approximate Bayesian Computation. The expressions for the acceptance probability and the Mean Squared Error are standard results in the literature on the asymptotic analysis of ABC methods. The MSE reflects the classic bias-variance trade-off, where the bias term is related to the tolerance $\\epsilon$ (here, squared bias $\\propto \\epsilon^4$) and the variance term is inversely proportional to the number of accepted samples, which itself depends on $\\epsilon$. The problem is well-posed, as maximizing the ESS is equivalent to minimizing a well-behaved function (a sum of positive and negative powers of $\\epsilon$), which has a unique minimum for $\\epsilon > 0$. The problem is objective, self-contained, and all parameters for the numerical part are provided. There are no scientific flaws, contradictions, or ambiguities.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed **valid**. I will proceed with a full solution.\n\n### Solution\n\nThe solution is presented in two parts as requested.\n\n**Part 1: Derivation and Functional Relationships**\n\nThe acceptance probability, $\\alpha(\\epsilon)$, is the probability that a simulated summary statistic vector $S$ falls within a $d$-dimensional ball of radius $\\epsilon$ centered at the observed data $s_{\\text{obs}}$. Let $p(s) = \\int p(s|\\theta)\\pi(\\theta) d\\theta$ be the marginal or prior predictive probability density function of the summary statistics. The acceptance probability is the integral of this density over the acceptance region:\n$$ \\alpha(\\epsilon) = P(\\rho(S, s_{\\text{obs}}) \\le \\epsilon) = \\int_{\\{s \\in \\mathbb{R}^d \\,|\\, \\rho(s, s_{\\text{obs}}) \\le \\epsilon\\}} p(s) \\, ds $$\nFor this derivation, we must state a key **regularity assumption**: the density function $p(s)$ must be continuous in a neighborhood of $s_{\\text{obs}}$. For small $\\epsilon$, we can approximate $p(s)$ by its value at the center of the ball, $p(s_{\\text{obs}})$, over the entire integration volume. This is justified by the mean value theorem for integrals.\n$$ \\alpha(\\epsilon) \\approx p(s_{\\text{obs}}) \\int_{\\{s \\in \\mathbb{R}^d \\,|\\, \\rho(s, s_{\\text{obs}}) \\le \\epsilon\\}} \\, ds $$\nThe integral is simply the volume of a $d$-dimensional ball of radius $\\epsilon$, which is given by $V_d \\epsilon^d$, where $V_d = \\frac{\\pi^{d/2}}{\\Gamma(d/2 + 1)}$ is the volume of the unit $d$-ball. Therefore, the acceptance probability is approximately:\n$$ \\alpha(\\epsilon) \\approx p(s_{\\text{obs}}) V_d \\epsilon^d $$\nComparing this with the given functional form $\\alpha(\\epsilon) \\approx k\\,\\epsilon^{d}$, we identify the constant $k$ as $k = p(s_{\\text{obs}}) V_d$. This derivation from first principles grounds the given relationship.\n\nThe functional relationship among $\\epsilon$, $\\alpha(\\epsilon)$, and the total computational budget $B$ is statistical. $B$ is the total number of simulations performed. Each simulation is an independent trial with a probability of success (acceptance) equal to $\\alpha(\\epsilon)$. The number of accepted samples, $N_{\\text{acc}}$, follows a binomial distribution, $N_{\\text{acc}} \\sim \\text{Binomial}(B, \\alpha(\\epsilon))$. The expected number of accepted samples is therefore:\n$$ E[N_{\\text{acc}}] = B \\cdot \\alpha(\\epsilon) $$\nThis equation describes the relationship: for a given budget $B$, the choice of $\\epsilon$ determines the acceptance rate $\\alpha(\\epsilon)$ and thus the expected size of the approximate posterior sample, $E[N_{\\text{acc}}]$.\n\nNext, we express the Effective Sample Size, $\\text{ESS}(\\epsilon)$, in terms of the given quantities. By definition, $\\text{ESS}(\\epsilon) = \\frac{\\sigma_{\\text{post}}^{2}}{\\operatorname{MSE}(\\epsilon)}$. Substituting the provided asymptotic expression for the Mean Squared Error, we get:\n$$ \\text{ESS}(\\epsilon) \\approx \\frac{\\sigma_{\\text{post}}^{2}}{\\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}} $$\nThis expression captures the trade-off inherent in ABC: decreasing $\\epsilon$ reduces the bias term ($\\beta\\epsilon^4$) but also decreases the number of accepted samples, which inflates the variance term ($\\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}$).\n\n**Part 2: Optimization of Tolerance $\\epsilon$**\n\nWe are tasked with finding the tolerance $\\epsilon^{*}$ that maximizes $\\text{ESS}(\\epsilon)$. Maximizing $\\text{ESS}(\\epsilon)$ is equivalent to minimizing its denominator, the Mean Squared Error, $\\operatorname{MSE}(\\epsilon)$. Let us define the function $f(\\epsilon) = \\operatorname{MSE}(\\epsilon)$:\n$$ f(\\epsilon) = \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}} = \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k}\\,\\epsilon^{-d} $$\nTo find the minimum of $f(\\epsilon)$ for $\\epsilon > 0$, we compute its first derivative with respect to $\\epsilon$ and set it to zero.\n$$ \\frac{df}{d\\epsilon} = \\frac{d}{d\\epsilon} \\left( \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k}\\,\\epsilon^{-d} \\right) = 4\\beta\\epsilon^3 - d \\frac{\\gamma}{B\\,k} \\epsilon^{-d-1} $$\nSetting the derivative to zero to find the optimal tolerance $\\epsilon^{*}$:\n$$ 4\\beta(\\epsilon^{*})^3 - d \\frac{\\gamma}{B\\,k} (\\epsilon^{*})^{-d-1} = 0 $$\n$$ 4\\beta(\\epsilon^{*})^3 = d \\frac{\\gamma}{B\\,k} (\\epsilon^{*})^{-d-1} $$\nNow, we solve for $\\epsilon^{*}$:\n$$ (\\epsilon^{*})^{3} (\\epsilon^{*})^{d+1} = \\frac{d\\gamma}{4\\beta B k} $$\n$$ (\\epsilon^{*})^{d+4} = \\frac{d\\gamma}{4\\beta B k} $$\n$$ \\epsilon^{*} = \\left( \\frac{d\\gamma}{4\\beta B k} \\right)^{\\frac{1}{d+4}} $$\nTo confirm that this critical point corresponds to a minimum, we examine the second derivative:\n$$ \\frac{d^2f}{d\\epsilon^2} = \\frac{d}{d\\epsilon} \\left( 4\\beta\\epsilon^3 - d \\frac{\\gamma}{B\\,k} \\epsilon^{-d-1} \\right) = 12\\beta\\epsilon^2 + d(d+1) \\frac{\\gamma}{B\\,k} \\epsilon^{-d-2} $$\nSince all constants ($\\beta, d, \\gamma, B, k$) are positive, and $\\epsilon > 0$, both terms in the second derivative are strictly positive. Thus, $\\frac{d^2f}{d\\epsilon^2} > 0$, which confirms that $\\epsilon^{*}$ corresponds to a local and global minimum for $\\operatorname{MSE}(\\epsilon)$.\n\nNow we substitute the given numerical values:\n-   $d = 2$\n-   $k = 0.4$\n-   $\\beta = L^{2} = (1.5)^{2} = 2.25$\n-   $\\gamma = 0.81$\n-   $B = 10^{6}$\n\nPlugging these into the expression for $\\epsilon^{*}$:\n$$ \\epsilon^{*} = \\left( \\frac{(2)(0.81)}{4(2.25)(10^{6})(0.4)} \\right)^{\\frac{1}{2+4}} $$\n$$ \\epsilon^{*} = \\left( \\frac{1.62}{4(2.25)(0.4)(10^{6})} \\right)^{\\frac{1}{6}} $$\n$$ \\epsilon^{*} = \\left( \\frac{1.62}{(9)(0.4)(10^{6})} \\right)^{\\frac{1}{6}} $$\n$$ \\epsilon^{*} = \\left( \\frac{1.62}{3.6 \\times 10^{6}} \\right)^{\\frac{1}{6}} $$\nThe fraction simplifies as:\n$$ \\frac{1.62}{3.6} = 0.45 $$\nSo the expression becomes:\n$$ \\epsilon^{*} = \\left( \\frac{0.45}{10^{6}} \\right)^{\\frac{1}{6}} = \\left( 0.45 \\times 10^{-6} \\right)^{\\frac{1}{6}} $$\n$$ \\epsilon^{*} = (0.45)^{\\frac{1}{6}} \\times (10^{-6})^{\\frac{1}{6}} = (0.45)^{\\frac{1}{6}} \\times 10^{-1} $$\nWe now compute the numerical value:\n$$ (0.45)^{\\frac{1}{6}} \\approx 0.875438 $$\n$$ \\epsilon^{*} \\approx 0.875438 \\times 10^{-1} = 0.0875438 $$\nRounding to four significant figures as required by the problem statement, we obtain:\n$$ \\epsilon^{*} \\approx 0.08754 $$\nThis is the value of the tolerance that maximizes the Effective Sample Size by optimally balancing the trade-off between the bias and the variance of the ABC estimator.",
            "answer": "$$\\boxed{0.08754}$$"
        },
        {
            "introduction": "A central challenge in systems biology is to accurately model heterogeneity within a population of cells. This practice explores three fundamental statistical philosophies for this task: assuming all cells are identical (full pooling), treating each cell independently (no pooling), or viewing them as related draws from a common distribution (partial pooling). By implementing these strategies within an ABC framework and comparing their predictive accuracy on synthetic data, you will gain hands-on experience with the power of hierarchical models to balance bias and variance when analyzing heterogeneous systems .",
            "id": "3288570",
            "problem": "You are tasked with implementing and comparing three Approximate Bayesian Computation (ABC) calibration strategies—full pooling, no pooling, and partial pooling (hierarchical)—for a simple stochastic single-cell gene expression model that captures intercellular heterogeneity. Your implementation must be a complete, runnable program that takes no input and prints a single line of results, as specified at the end.\n\nFundamental base and model assumptions:\n- The system is modeled as a birth-death process where, for each cell $i$, the measured messenger ribonucleic acid (mRNA) copy number at a given time is modeled as a Poisson random variable with rate $k_i$, that is, $Y_{i,t} \\sim \\mathrm{Poisson}(k_i)$, independent across times $t$ and cells $i$.\n- Under this model, the expected per-cell mean is $\\mathbb{E}[Y_{i,t}] = k_i$, and the per-cell sample mean over $T$ replicates provides an unbiased estimate of $k_i$.\n\nABC setup and definitions:\n- Approximate Bayesian Computation (ABC) seeks to approximate a Bayesian posterior $p(\\theta \\mid y)$ when the likelihood is intractable but model simulation is available. ABC generates parameter draws $\\theta^{(j)} \\sim p(\\theta)$ from the prior, simulates synthetic data $z^{(j)} \\sim p(\\cdot \\mid \\theta^{(j)})$, computes a distance $d(S(z^{(j)}), S(y))$ between summary statistics $S(\\cdot)$ of simulated and observed data, and accepts draws with sufficiently small distance.\n- You must use rejection ABC with an acceptance rule defined by keeping the top fraction of parameter draws with the smallest distances. Specifically, if there are $M$ draws and the acceptance fraction is $\\alpha \\in (0,1]$, then you must accept the $K = \\max\\{1, \\lceil \\alpha M \\rceil\\}$ draws with the smallest distances.\n\nPooling strategies (to be implemented and compared):\n1. Full pooling: All cells share one common rate $k$, i.e., $k_i \\equiv k$ for all $i$. Prior: $k \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$. For ABC simulation, for each draw $k^{(j)}$, simulate $Y_{i,t}^{(j)} \\sim \\mathrm{Poisson}(k^{(j)})$ for all $i$ and $t$, compute per-cell means $S^{(j)}_i = \\frac{1}{T} \\sum_t Y_{i,t}^{(j)}$, define distance $d^{(j)} = \\left( \\sum_{i=1}^{N} (S^{(j)}_i - \\bar{Y}_i)^2 \\right)^{1/2}$ where $\\bar{Y}_i$ is the observed per-cell mean, then accept the top $K$ draws. The posterior predictive per-cell mean vector is given by $\\hat{m}^{\\mathrm{full}} = \\left(\\overline{k}_{\\mathrm{acc}}\\right) \\cdot \\mathbf{1}_N$, where $\\overline{k}_{\\mathrm{acc}}$ is the average of accepted $k^{(j)}$ and $\\mathbf{1}_N$ is the $N$-dimensional vector of ones.\n2. No pooling: Each cell has its own rate $k_i$, independently with prior $k_i \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$. Perform ABC separately for each cell $i$ using the scalar distance $d_i^{(j)} = \\left| S_i^{(j)} - \\bar{Y}_i \\right|$, where $S_i^{(j)} = \\frac{1}{T} \\sum_t Y_{i,t}^{(j)}$ with $Y_{i,t}^{(j)} \\sim \\mathrm{Poisson}(k_i^{(j)})$. For each cell, accept the top $K_i = \\max\\{1, \\lceil \\alpha M \\rceil\\}$ draws and compute the posterior predictive mean $\\hat{m}^{\\mathrm{no}}_i = \\overline{k_{i,\\mathrm{acc}}}$. The posterior predictive per-cell mean vector is $\\hat{m}^{\\mathrm{no}} = (\\hat{m}^{\\mathrm{no}}_1, \\dots, \\hat{m}^{\\mathrm{no}}_N)$.\n3. Partial pooling (hierarchical): A hierarchical prior couples cells by hyperparameters: $k_i \\sim \\mathrm{LogNormal}(\\mu, \\sigma^2)$, with hyperpriors $\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$ and $\\sigma \\sim \\mathrm{HalfNormal}(\\tau)$, where the HalfNormal distribution has density proportional to $\\exp\\left( -\\frac{\\sigma^2}{2\\tau^2} \\right)$ for $\\sigma \\ge 0$. For ABC, draw $(\\mu^{(j)}, \\sigma^{(j)})$, then $k_i^{(j)} \\sim \\mathrm{LogNormal}(\\mu^{(j)}, (\\sigma^{(j)})^2)$ for all $i$, simulate $Y_{i,t}^{(j)} \\sim \\mathrm{Poisson}(k_i^{(j)})$, compute per-cell means $S^{(j)}_i$, define $d^{(j)} = \\left( \\sum_{i=1}^{N} (S^{(j)}_i - \\bar{Y}_i)^2 \\right)^{1/2}$, accept the top $K$ draws, and compute posterior predictive per-cell means $\\hat{m}^{\\mathrm{partial}}_i = \\overline{k_{i,\\mathrm{acc}}}$.\n\nEvaluation metric:\n- For each scenario below, you will be provided with synthetic observed data generated from a known ground-truth vector $\\mathbf{k}^{\\ast} = (k^{\\ast}_1,\\dots,k^{\\ast}_N)$ and two disjoint sets of replicates per cell: a fit set and a hold-out set.\n- Let $\\bar{Y}_i$ be the per-cell mean of the fit set and $\\bar{Y}^{\\mathrm{hold}}_i$ be the per-cell mean of the hold-out set.\n- For any method that yields a per-cell predictive mean vector $\\hat{m}$, quantify predictive accuracy by the root mean squared error (RMSE)\n$$\n\\mathrm{RMSE}(\\hat{m}, \\bar{\\mathbf{Y}}^{\\mathrm{hold}}) = \\left( \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\hat{m}_i - \\bar{Y}^{\\mathrm{hold}}_i \\right)^2 \\right)^{1/2}.\n$$\n- For each test case, report which method yields the smallest RMSE, with ties broken by preferring the smaller index in the ordering full pooling $= 0$, no pooling $= 1$, partial pooling $= 2$.\n\nPriors, hyperparameters, and ABC configuration:\n- Use $\\mu_0 = \\log(6.0)$ and $\\sigma_0 = 1.0$ for the LogNormal prior parameters and the Normal hyperprior parameters.\n- Use $\\tau = 1.0$ for the HalfNormal scale of $\\sigma$.\n- For full pooling, use $M_{\\mathrm{full}} = 8000$ draws and acceptance fraction $\\alpha_{\\mathrm{full}} = 0.05$.\n- For no pooling, use $M_{\\mathrm{no}} = 5000$ draws per cell and acceptance fraction $\\alpha_{\\mathrm{no}} = 0.10$.\n- For partial pooling, use $M_{\\mathrm{partial}} = 16000$ draws and acceptance fraction $\\alpha_{\\mathrm{partial}} = 0.05$.\n\nData generation for the test suite:\n- For each test case, simulate ground-truth per-cell rates from a LogNormal distribution: $k_i^{\\ast} \\sim \\mathrm{LogNormal}(\\mu_{\\mathrm{true}}, \\sigma_{\\mathrm{true}}^2)$. For each cell $i \\in \\{1,\\dots,N\\}$, first generate $2T$ independent replicates $Y_{i,1}, \\dots, Y_{i,2T} \\sim \\mathrm{Poisson}(k_i^{\\ast})$; use the first $T$ to compute $\\bar{Y}_i$ (fit set) and the last $T$ to compute $\\bar{Y}^{\\mathrm{hold}}_i$ (hold-out set).\n- Use independent pseudorandom number generator states initialized by the provided integer seeds for each scenario to ensure reproducibility.\n\nTest suite:\n- Case A (low heterogeneity, small per-cell sample size): $N = 8$, $T = 3$, $\\mu_{\\mathrm{true}} = \\log(6.0)$, $\\sigma_{\\mathrm{true}} = 0.05$, random seed $s = 12345$.\n- Case B (high heterogeneity, larger per-cell sample size): $N = 8$, $T = 15$, $\\mu_{\\mathrm{true}} = \\log(6.0)$, $\\sigma_{\\mathrm{true}} = 0.8$, random seed $s = 23456$.\n- Case C (moderate heterogeneity, very small per-cell sample size): $N = 8$, $T = 2$, $\\mu_{\\mathrm{true}} = \\log(6.0)$, $\\sigma_{\\mathrm{true}} = 0.4$, random seed $s = 34567$.\n\nImplementation requirements:\n- Use the distance and acceptance rules exactly as defined.\n- For the full pooling method’s predictive mean, use the average of accepted $k$ values and set the per-cell predictive vector to be constant across cells. For the no pooling method’s predictive means, use the average of accepted $k_i$ values per cell. For the partial pooling method’s predictive means, use the average across accepted draws of $k_i$ for each cell $i$.\n- Compute the RMSEs against the hold-out per-cell means and determine the best method per test case using the specified index ordering.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one integer per test case corresponding to the best method’s index in the ordering full pooling $= 0$, no pooling $= 1$, partial pooling $= 2$. For example, a valid final output line has the form $[x_1,x_2,x_3]$ where $x_j \\in \\{0,1,2\\}$.\n\nNumerical output:\n- There are no physical units involved, and all final reported quantities are dimensionless integers. The single output line must be exactly in the required format, with no additional text.",
            "solution": "The problem statement is valid. It is scientifically grounded in established principles of computational systems biology and Bayesian statistics, well-posed with all necessary parameters and procedures defined, and objective in its formulation. The task is to implement and compare three Approximate Bayesian Computation (ABC) strategies for parameter inference in a stochastic single-cell gene expression model.\n\nThe core of the problem addresses a fundamental concept in statistical modeling: the trade-off between bias and variance, managed through different levels of \"pooling\" or information sharing across related groups (in this case, cells). The model assumes that for each cell $i$, the messenger RNA (mRNA) count $Y_{i,t}$ follows a Poisson distribution with a cell-specific rate parameter $k_i$, i.e., $Y_{i,t} \\sim \\mathrm{Poisson}(k_i)$. The goal is to estimate the vector of rates $\\mathbf{k} = (k_1, \\dots, k_N)$ and evaluate the predictive accuracy of each strategy.\n\nThe three ABC strategies embody distinct assumptions about the cellular population:\n\n1.  **Full Pooling**: This strategy operates under the restrictive assumption of cellular homogeneity, asserting that all cells share a single, common rate parameter $k$, such that $k_i \\equiv k$ for all $i \\in \\{1, \\dots, N\\}$. A single prior, $k \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$, is defined for this common rate. This approach maximally borrows statistical strength across all cells by using all data to inform the estimate of the single parameter $k$. However, this introduces significant bias if the cells are, in reality, heterogeneous, as the model is misspecified. The ABC procedure involves sampling a scalar $k^{(j)}$, simulating data for all $N$ cells from $\\mathrm{Poisson}(k^{(j)})$, and computing a single distance $d^{(j)} = \\left( \\sum_{i=1}^{N} (S^{(j)}_i - \\bar{Y}_i)^2 \\right)^{1/2}$, where $S^{(j)}_i$ are the simulated per-cell means and $\\bar{Y}_i$ are the observed means. The posterior predictive mean for every cell is the average of the accepted $k^{(j)}$ values, $\\overline{k}_{\\mathrm{acc}}$.\n\n2.  **No Pooling**: At the opposite extreme, this strategy assumes complete independence among cells. Each cell $i$ is treated as a separate experiment with its own rate parameter $k_i$, which is assigned an independent prior $k_i \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$. This approach is highly flexible and can capture arbitrary heterogeneity. However, by failing to share information across cells, the parameter estimate for each cell relies solely on its own, often limited, data. This can lead to high variance (overfitting), especially when the number of observations per cell, $T$, is small. The ABC procedure is performed separately for each cell, using a scalar distance $d_i^{(j)} = |S_i^{(j)} - \\bar{Y}_i|$. The posterior predictive mean for each cell, $\\hat{m}^{\\mathrm{no}}_i$, is the average of its own set of accepted $k_{i, \\mathrm{acc}}^{(j)}$ values.\n\n3.  **Partial Pooling (Hierarchical Model)**: This strategy provides a principled compromise. It posits that the cell-specific rates $k_i$ are related but not identical. They are assumed to be drawn from a common population distribution, $k_i \\sim \\mathrm{LogNormal}(\\mu, \\sigma^2)$. The parameters of this population distribution, $(\\mu, \\sigma^2)$, are themselves unknown and are given priors, known as hyperpriors: $\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$ and $\\sigma \\sim \\mathrm{HalfNormal}(\\tau)$. By jointly inferring the $k_i$ and the hyperparameters $(\\mu, \\sigma)$, the model allows the data to determine the degree of similarity among cells. Information is shared (\"pooled\") across cells through the estimation of these shared hyperparameters, leading to an adaptive regularization effect where individual cell estimates are \"shrunk\" towards the estimated population mean. This typically offers the best trade-off between bias and variance. The ABC procedure for this model involves sampling hyperparameters $(\\mu^{(j)}, \\sigma^{(j)})$, then sampling a full vector of rates $\\mathbf{k}^{(j)}$, simulating data, and computing a single distance $d^{(j)}$ as in the full pooling case. The posterior predictive mean for each cell $i$, $\\hat{m}^{\\mathrm{partial}}_i$, is the average of the $k_i^{(j)}$ components from the accepted parameter vectors.\n\nThe implementation proceeds by first generating synthetic \"observed\" data for each test case using the provided random seed. This includes a `fit set` for running the ABC algorithms and a `hold-out set` for evaluation. The per-cell sample means of these sets are denoted $\\bar{\\mathbf{Y}}$ and $\\bar{\\mathbf{Y}}^{\\mathrm{hold}}$, respectively.\n\nFor each test case and for each of the three pooling strategies, the corresponding ABC algorithm is executed according to its specific simulation and distance calculation rules. The number of accepted parameter draws, $K$, is determined by the total number of draws $M$ and the acceptance fraction $\\alpha$ as $K = \\max\\{1, \\lceil \\alpha M \\rceil\\}$. After identifying the accepted set of parameters, the posterior predictive mean vector $\\hat{\\mathbf{m}}$ is calculated for each strategy.\n\nFinally, predictive accuracy is quantified by the Root Mean Squared Error (RMSE) between the predicted means and the hold-out data:\n$$\n\\mathrm{RMSE}(\\hat{\\mathbf{m}}, \\bar{\\mathbf{Y}}^{\\mathrm{hold}}) = \\left( \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\hat{m}_i - \\bar{Y}^{\\mathrm{hold}}_i \\right)^2 \\right)^{1/2}\n$$\nFor each test case, the method yielding the minimum RMSE is chosen as the best-performing strategy, with ties broken by preferring the method with the lower index ($0$ for full, $1$ for no, $2$ for partial). The final output is a list of these winning indices. This comparative analysis is expected to highlight the strengths and weaknesses of each pooling strategy under different conditions of cellular heterogeneity and data availability, as defined by the test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Implements and compares full pooling, no pooling, and partial pooling ABC strategies\n    for a single-cell gene expression model.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'name': 'A', 'N': 8, 'T': 3, 'mu_true': np.log(6.0), 'sigma_true': 0.05, 'seed': 12345},\n        {'name': 'B', 'N': 8, 'T': 15, 'mu_true': np.log(6.0), 'sigma_true': 0.8, 'seed': 23456},\n        {'name': 'C', 'N': 8, 'T': 2, 'mu_true': np.log(6.0), 'sigma_true': 0.4, 'seed': 34567},\n    ]\n\n    # Global prior and hyperprior parameters\n    MU0 = np.log(6.0)\n    SIGMA0 = 1.0\n    TAU = 1.0\n    \n    results = []\n\n    for case in test_cases:\n        rng = np.random.default_rng(case['seed'])\n        N, T = case['N'], case['T']\n\n        # Generate synthetic observed data\n        k_true = rng.lognormal(mean=case['mu_true'], sigma=case['sigma_true'], size=N)\n        \n        y_bar_fit = np.zeros(N)\n        y_bar_holdout = np.zeros(N)\n        for i in range(N):\n            all_replicates = rng.poisson(lam=k_true[i], size=2 * T)\n            y_bar_fit[i] = np.mean(all_replicates[:T])\n            y_bar_holdout[i] = np.mean(all_replicates[T:])\n\n        # Run each ABC method and calculate RMSE\n        rmse_full = run_full_pooling(rng, y_bar_fit, y_bar_holdout, N, T, MU0, SIGMA0)\n        rmse_no = run_no_pooling(rng, y_bar_fit, y_bar_holdout, N, T, MU0, SIGMA0)\n        rmse_partial = run_partial_pooling(rng, y_bar_fit, y_bar_holdout, N, T, MU0, SIGMA0, TAU)\n\n        rmses = [rmse_full, rmse_no, rmse_partial]\n        best_method_idx = np.argmin(rmses)\n        results.append(best_method_idx)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_rmse(m_hat, y_bar_holdout):\n    return np.sqrt(np.mean((m_hat - y_bar_holdout)**2))\n\ndef run_full_pooling(rng, y_bar_fit, y_bar_holdout, N, T, mu0, sigma0):\n    M = 8000\n    alpha = 0.05\n    K = int(max(1, np.ceil(alpha * M)))\n\n    k_draws = rng.lognormal(mean=mu0, sigma=sigma0, size=M)\n    distances = np.zeros(M)\n    \n    for j in range(M):\n        k_j = k_draws[j]\n        sim_data = rng.poisson(lam=k_j, size=(N, T))\n        s_j = np.mean(sim_data, axis=1)\n        distances[j] = np.sqrt(np.sum((s_j - y_bar_fit)**2))\n        \n    accepted_indices = np.argsort(distances)[:K]\n    k_accepted = k_draws[accepted_indices]\n    \n    k_bar_acc = np.mean(k_accepted)\n    m_hat_full = np.full(N, k_bar_acc)\n    \n    return calculate_rmse(m_hat_full, y_bar_holdout)\n\ndef run_no_pooling(rng, y_bar_fit, y_bar_holdout, N, T, mu0, sigma0):\n    M = 5000\n    alpha = 0.10\n    K = int(max(1, np.ceil(alpha * M)))\n\n    m_hat_no = np.zeros(N)\n    \n    for i in range(N):\n        ki_draws = rng.lognormal(mean=mu0, sigma=sigma0, size=M)\n        distances_i = np.zeros(M)\n        for j in range(M):\n            ki_j = ki_draws[j]\n            sim_data_i = rng.poisson(lam=ki_j, size=T)\n            si_j = np.mean(sim_data_i)\n            distances_i[j] = np.abs(si_j - y_bar_fit[i])\n            \n        accepted_indices = np.argsort(distances_i)[:K]\n        ki_accepted = ki_draws[accepted_indices]\n        m_hat_no[i] = np.mean(ki_accepted)\n        \n    return calculate_rmse(m_hat_no, y_bar_holdout)\n\ndef run_partial_pooling(rng, y_bar_fit, y_bar_holdout, N, T, mu0, sigma0, tau):\n    M = 16000\n    alpha = 0.05\n    K = int(max(1, np.ceil(alpha * M)))\n\n    mu_draws = rng.normal(loc=mu0, scale=sigma0, size=M)\n    sigma_draws = np.abs(rng.normal(loc=0, scale=tau, size=M))\n\n    k_draws_all = np.zeros((M, N))\n    distances = np.zeros(M)\n\n    for j in range(M):\n        mu_j = mu_draws[j]\n        sigma_j = sigma_draws[j]\n        \n        k_vec_j = rng.lognormal(mean=mu_j, sigma=sigma_j, size=N)\n        k_draws_all[j, :] = k_vec_j\n        \n        # Vectorized simulation for the N cells\n        lam_expanded = np.repeat(k_vec_j[:, np.newaxis], T, axis=1)\n        sim_data = rng.poisson(lam=lam_expanded)\n        s_j = np.mean(sim_data, axis=1)\n        \n        distances[j] = np.sqrt(np.sum((s_j - y_bar_fit)**2))\n\n    accepted_indices = np.argsort(distances)[:K]\n    k_accepted = k_draws_all[accepted_indices, :]\n    \n    m_hat_partial = np.mean(k_accepted, axis=0)\n    \n    return calculate_rmse(m_hat_partial, y_bar_holdout)\n\nsolve()\n```"
        },
        {
            "introduction": "As models grow in complexity, the computational cost of ABC can become a major bottleneck, often requiring millions of simulations. This exercise transitions from statistical theory to computational practice, challenging you to design an efficient algorithm for parallelizing ABC simulations. You will develop a strategy to allocate computational tasks across a heterogeneous set of workers to maximize the yield of scientifically valuable results—the accepted posterior samples—within a fixed time budget .",
            "id": "3288582",
            "problem": "Consider a computational systems biology setting where Approximate Bayesian Computation (ABC) is used to infer parameters of a two-stage gene expression model from observed data. The biological model consists of messenger ribonucleic acid (mRNA) and protein species governed by transcription, translation, and degradation. Assume the following widely used steady-state approximations for the protein summary statistic used in ABC:\n\n- The protein mean at steady state for a given parameter vector $\\theta_i = (k_{\\mathrm{tx},i}, k_{\\mathrm{tl},i}, \\gamma_{\\mathrm{m},i}, \\gamma_{\\mathrm{p},i})$ (transcription rate $k_{\\mathrm{tx},i}$ in $\\mathrm{s}^{-1}$, translation rate $k_{\\mathrm{tl},i}$ in $\\mathrm{s}^{-1}$, mRNA degradation rate $\\gamma_{\\mathrm{m},i}$ in $\\mathrm{s}^{-1}$, and protein degradation rate $\\gamma_{\\mathrm{p},i}$ in $\\mathrm{s}^{-1}$) is\n$$\n\\mu_i = \\frac{k_{\\mathrm{tx},i} \\, k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{m},i} \\, \\gamma_{\\mathrm{p},i}}.\n$$\n\n- Under a linear noise or burst approximation, the protein variance is taken as\n$$\n\\sigma_i^2 = \\mu_i \\left(1 + \\frac{k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{p},i}}\\right),\n$$\nwhich captures super-Poisson variability due to translational bursting.\n\nIn ABC, a simulated summary $s$ is accepted if the absolute discrepancy with the observed summary $s_{\\mathrm{obs}}$ is at most a threshold $\\varepsilon$. Assume the summary statistic $s$ is approximately Gaussian under the model for each $\\theta_i$, i.e., $s \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$, and define the acceptance event as $\\{|s - s_{\\mathrm{obs}}| \\le \\varepsilon\\}$. Under these assumptions, the acceptance probability for parameter $\\theta_i$ is the integral of the Gaussian density over the acceptance region.\n\nYou are given a fixed wall-clock time budget $T$ (in seconds) and a set of $W$ workers indexed by $j \\in \\{1,\\dots,W\\}$. Each worker $j$ has a speed multiplier $r_j$ (dimensionless) relative to a baseline simulation time and incurs a one-time overhead $h_j$ (in seconds) if used. A single simulation for parameter $\\theta_i$ has a baseline runtime $t_i$ (in seconds), so the runtime on worker $j$ is $t_i / r_j$ (in seconds). Each parameter $\\theta_i$ also has a maximum number of allowed simulations $N_i^{\\max} \\in \\mathbb{N}$. If a worker $j$ is employed, its usable time capacity is $C_j = T - h_j$ (in seconds), and if $C_j \\le 0$ the worker cannot perform any simulation.\n\nYour task is to design an allocation of integer numbers of simulations $n_{ij} \\in \\mathbb{N}_0$ per parameter $\\theta_i$ and worker $j$ to maximize the expected total number of accepted ABC simulations, which is\n$$\n\\sum_{i} \\sum_{j} n_{ij} \\, p_i,\n$$\nsubject to the per-worker time constraints\n$$\n\\sum_{i} n_{ij} \\frac{t_i}{r_j} \\le C_j \\quad \\text{for all } j,\n$$\nand the per-parameter maximum constraints\n$$\n\\sum_{j} n_{ij} \\le N_i^{\\max} \\quad \\text{for all } i.\n$$\nHere $p_i$ denotes the acceptance probability for parameter $\\theta_i$ under the Gaussian approximation described above.\n\nFor the purpose of this exercise, implement an algorithm that computes $p_i$ from the Gaussian model and then constructs an allocation that maximizes the expected accepted count under the constraints. The algorithm should be correct, efficient, and implementable as a deterministic program. The final outputs must be expressed as real numbers (floats) representing the expected total number of accepted simulations for each test case, rounded to six decimal places.\n\nUse the following test suite of parameter sets. All rates are specified in $\\mathrm{s}^{-1}$, times in seconds, and counts are dimensionless integers. The observed summary is in molecular counts (dimensionless).\n\n- Test case $1$ (general multi-worker case):\n  - Observed summary: $s_{\\mathrm{obs}} = 10$.\n  - Threshold: $\\varepsilon = 2$.\n  - Parameters (each entry is $(k_{\\mathrm{tx}}, k_{\\mathrm{tl}}, \\gamma_{\\mathrm{m}}, \\gamma_{\\mathrm{p}}, t, N^{\\max})$):\n    - $\\theta_1$: $(0.01, 2.0, 0.02, 0.1, 1.5, 20)$.\n    - $\\theta_2$: $(0.04, 3.0, 0.04, 0.15, 1.0, 50)$.\n    - $\\theta_3$: $(0.015, 4.0, 0.03, 0.1, 0.8, 50)$.\n  - Workers: $(r_j, h_j)$:\n    - Worker $1$: $(1.0, 0.3)$.\n    - Worker $2$: $(0.6, 0.4)$.\n    - Worker $3$: $(2.0, 0.2)$.\n  - Budget: $T = 5.0$.\n\n- Test case $2$ (zero-threshold edge case):\n  - Observed summary: $s_{\\mathrm{obs}} = 10$.\n  - Threshold: $\\varepsilon = 0$.\n  - Same parameters and workers as test case $1$.\n  - Budget: $T = 5.0$.\n\n- Test case $3$ (worker overhead renders one worker unusable):\n  - Observed summary: $s_{\\mathrm{obs}} = 10$.\n  - Threshold: $\\varepsilon = 4$.\n  - Parameters:\n    - $\\theta_1$: $(0.01, 2.0, 0.02, 0.1, 1.3, 40)$.\n    - $\\theta_2$: $(0.04, 3.0, 0.04, 0.15, 1.1, 40)$.\n    - $\\theta_3$: $(0.015, 4.0, 0.03, 0.1, 0.9, 40)$.\n  - Workers:\n    - Worker $1$: $(1.0, 1.0)$.\n    - Worker $2$: $(0.5, 6.0)$.\n  - Budget: $T = 5.0$.\n\n- Test case $4$ (binding per-parameter maxima force mixed allocation):\n  - Observed summary: $s_{\\mathrm{obs}} = 10$.\n  - Threshold: $\\varepsilon = 3$.\n  - Parameters:\n    - $\\theta_1$: $(0.01, 2.0, 0.02, 0.1, 1.2, 2)$.\n    - $\\theta_2$: $(0.04, 3.0, 0.04, 0.15, 1.0, 3)$.\n    - $\\theta_3$: $(0.015, 4.0, 0.03, 0.1, 0.8, 5)$.\n  - Workers:\n    - Worker $1$: $(1.2, 0.2)$.\n    - Worker $2$: $(1.0, 0.2)$.\n  - Budget: $T = 8.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $\\texttt{[result1,result2,result3,result4]}$). Each $resultk$ must be a float rounded to six decimal places corresponding to the expected total accepted count for test case $k$ in the order given.",
            "solution": "The problem involves designing an allocation strategy for Approximate Bayesian Computation (ABC) simulations under parallelization and resource constraints. The context is a two-stage gene expression model and the summary statistic is the steady-state protein count. The solution proceeds from fundamental and well-tested principles, and integrates them into an algorithmic framework.\n\nFoundational modeling principles:\n\n1. From standard birth-death process approximations in gene expression, the steady-state protein mean under parameters $\\theta_i = (k_{\\mathrm{tx},i}, k_{\\mathrm{tl},i}, \\gamma_{\\mathrm{m},i}, \\gamma_{\\mathrm{p},i})$ is given by\n$$\n\\mu_i = \\frac{k_{\\mathrm{tx},i} \\, k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{m},i} \\, \\gamma_{\\mathrm{p},i}}.\n$$\nThis is a widely accepted steady-state mean expression derived from balancing production and degradation rates in the two-stage model.\n\n2. The protein variance under a linear noise or burst approximation is\n$$\n\\sigma_i^2 = \\mu_i \\left(1 + \\frac{k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{p},i}}\\right).\n$$\nThis is a well-tested formula capturing super-Poisson variability due to translation bursts, frequently used in computational systems biology when exact distributions are intractable.\n\n3. The ABC acceptance is defined by the discrepancy threshold criterion. For each parameter $\\theta_i$, a simulated summary $s$ is modeled as Gaussian $s \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$, and the acceptance event is $\\{|s - s_{\\mathrm{obs}}| \\le \\varepsilon\\}$. The acceptance probability is thus\n$$\np_i = \\mathbb{P}\\left(|s - s_{\\mathrm{obs}}| \\le \\varepsilon \\,\\middle|\\, \\theta_i \\right) = \\int_{s_{\\mathrm{obs}} - \\varepsilon}^{s_{\\mathrm{obs}} + \\varepsilon} \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}} \\exp\\left(-\\frac{(x - \\mu_i)^2}{2\\sigma_i^2}\\right) \\, dx.\n$$\nBy the fundamental properties of the Gaussian cumulative distribution function, this integral equals\n$$\np_i = \\Phi\\!\\left(\\frac{s_{\\mathrm{obs}} + \\varepsilon - \\mu_i}{\\sigma_i}\\right) - \\Phi\\!\\left(\\frac{s_{\\mathrm{obs}} - \\varepsilon - \\mu_i}{\\sigma_i}\\right),\n$$\nwhere $\\Phi(\\cdot)$ is the standard normal cumulative distribution function. This derivation uses classical probability theory without shortcuts beyond Gaussian integral properties.\n\nParallel resource allocation principles:\n\n4. Each simulation for parameter $\\theta_i$ has a baseline runtime $t_i$ (in seconds). On worker $j$ with speed multiplier $r_j$, the runtime is $t_i / r_j$ (in seconds). If the worker is used, it incurs a one-time overhead $h_j$ (in seconds), leaving effective capacity\n$$\nC_j = T - h_j.\n$$\nA worker with $C_j \\le 0$ cannot perform simulations.\n\n5. The objective is to maximize the expected number of accepted simulations,\n$$\n\\sum_{i} \\sum_{j} n_{ij} \\, p_i,\n$$\nsubject to constraints\n$$\n\\sum_{i} n_{ij} \\frac{t_i}{r_j} \\le C_j \\quad \\text{for all } j, \\qquad \\sum_{j} n_{ij} \\le N_i^{\\max} \\quad \\text{for all } i,\n$$\nwith integer $n_{ij} \\ge 0$.\n\nPrinciple-based optimization design:\n\n6. Define the efficiency ratio for parameter $\\theta_i$ as expected accepted per unit baseline time:\n$$\ne_i = \\frac{p_i}{t_i}.\n$$\nOn worker $j$, the expected accepted per unit worker time for parameter $\\theta_i$ scales as\n$$\ne_{ij}^{\\mathrm{worker}} = \\frac{p_i}{t_i / r_j} = r_j \\, e_i.\n$$\nSince $r_j$ is constant across all parameters for worker $j$, the ordering of parameters by $e_{ij}^{\\mathrm{worker}}$ is the same as the global ordering by $e_i$. Therefore, for any worker $j$, allocating time to parameters in decreasing order of $e_i$ maximizes expected accepted under the worker's capacity constraint. This conclusion can be justified by a standard exchange argument in knapsack-like resource allocation: if two parameters $i$ and $k$ satisfy $e_i > e_k$, any feasible allocation that spends time on $k$ before exhausting tasks for $i$ can be improved by swapping equal amounts of time from $k$ to $i$, increasing expected accepted without violating constraints.\n\n7. Activation overhead $h_j$ simply reduces usable capacity. The decision to use a worker emerges naturally: if $C_j \\le 0$, skip the worker; otherwise, allocate according to the greedy order. If all $p_i = 0$, then $e_i = 0$ for all $i$, and the expected accepted is $0$ regardless of allocation; in that degenerate case, one can choose not to schedule any simulations.\n\n8. Integer feasibility is enforced by rounding down the number of simulations that fit within capacity. For a worker $j$, the maximum number of simulations of parameter $\\theta_i$ that can be run, given remaining capacity $C_j^{\\mathrm{rem}}$ and remaining per-parameter allowance $N_i^{\\mathrm{rem}}$, is\n$$\nn_{ij}^{\\max} = \\left\\lfloor \\min\\left(N_i^{\\mathrm{rem}}, \\frac{C_j^{\\mathrm{rem}}}{t_i / r_j}\\right) \\right\\rfloor = \\left\\lfloor \\min\\left(N_i^{\\mathrm{rem}}, \\frac{C_j^{\\mathrm{rem}} \\, r_j}{t_i}\\right) \\right\\rfloor.\n$$\nAllocate $n_{ij} = n_{ij}^{\\max}$ before moving to the next parameter in the efficiency-ordered list and update capacities and $N_i^{\\mathrm{rem}}$.\n\nAlgorithmic steps:\n\n9. For each test case:\n- Compute $\\mu_i$ and $\\sigma_i^2$ from the given rates for each parameter $\\theta_i$.\n- Compute $\\sigma_i = \\sqrt{\\sigma_i^2}$ and then the acceptance probability $p_i$ via the Gaussian cumulative distribution function, $p_i = \\Phi\\!\\left((s_{\\mathrm{obs}} + \\varepsilon - \\mu_i)/\\sigma_i\\right) - \\Phi\\!\\left((s_{\\mathrm{obs}} - \\varepsilon - \\mu_i)/\\sigma_i\\right)$.\n- Compute $e_i = p_i / t_i$.\n- Sort parameters by decreasing $e_i$.\n- For each worker $j$, compute $C_j = T - h_j$; if $C_j \\le 0$, skip. Otherwise, iterate over parameters in sorted order and allocate $n_{ij}$ as the integer floor of the feasible number given remaining capacity and $N_i^{\\mathrm{rem}}$, update $C_j$ and $N_i^{\\mathrm{rem}}$, continue until capacity is exhausted or all parameters have zero $N_i^{\\mathrm{rem}}$.\n- Accumulate expected accepted $\\sum_{i,j} n_{ij} p_i$.\n- Round the final expected accepted to six decimal places.\n\n10. The above procedure is computationally efficient because it avoids combinatorial search by using a principled greedy ordering based on $e_i$, justified by linearity of expectation and additive time constraints. It respects all constraints and is robust to edge conditions ($\\varepsilon = 0$, invalid workers with $C_j \\le 0$, and binding per-parameter maxima forcing mixed allocations).\n\nThe program will implement these steps for the four specified test cases and print a single line containing a list of the four expected totals, rounded to six decimal places, in the order given.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef compute_mu_sigma2(params):\n    \"\"\"\n    Compute steady-state protein mean (mu) and variance (sigma^2) for each parameter tuple.\n    params: list of tuples (k_tx, k_tl, gamma_m, gamma_p, t, Nmax)\n    Returns: arrays mu, sigma2, baseline_times, Nmax\n    \"\"\"\n    mu = []\n    sigma2 = []\n    baseline_times = []\n    nmax = []\n    for (k_tx, k_tl, gamma_m, gamma_p, t, Nmax) in params:\n        mu_i = (k_tx * k_tl) / (gamma_m * gamma_p)\n        sigma2_i = mu_i * (1.0 + (k_tl / gamma_p))\n        mu.append(mu_i)\n        sigma2.append(sigma2_i)\n        baseline_times.append(t)\n        nmax.append(int(Nmax))\n    return np.array(mu), np.array(sigma2), np.array(baseline_times), np.array(nmax, dtype=int)\n\ndef compute_acceptance_probs(mu, sigma2, s_obs, eps):\n    \"\"\"\n    Compute acceptance probabilities for Gaussian summaries:\n    p_i = Phi((s_obs + eps - mu)/sigma) - Phi((s_obs - eps - mu)/sigma)\n    \"\"\"\n    sigma = np.sqrt(sigma2)\n    # Handle potential zero variance edge cases by returning zero acceptance (though not expected here)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        upper = (s_obs + eps - mu) / sigma\n        lower = (s_obs - eps - mu) / sigma\n        # Where sigma is zero, set probability to 1 if s_obs within eps of mu, else 0\n        p = norm.cdf(upper) - norm.cdf(lower)\n        # Replace NaNs due to zero sigma with deterministic outcomes\n        zero_sigma_idx = np.where(sigma == 0)[0]\n        for idx in zero_sigma_idx:\n            if abs(s_obs - mu[idx]) <= eps:\n                p[idx] = 1.0\n            else:\n                p[idx] = 0.0\n    # Ensure probabilities are within [0,1] numerically\n    p = np.clip(p, 0.0, 1.0)\n    return p\n\ndef allocate_expected_accepted(s_obs, eps, params, workers, T):\n    \"\"\"\n    Allocate simulations across workers to maximize expected accepted count.\n\n    params: list of tuples (k_tx, k_tl, gamma_m, gamma_p, t, Nmax)\n    workers: list of tuples (r_j, h_j)\n    T: time budget\n    Returns: expected_accepted (float)\n    \"\"\"\n    mu, sigma2, t_i, Nmax = compute_mu_sigma2(params)\n    p_i = compute_acceptance_probs(mu, sigma2, s_obs, eps)\n    # Efficiency ratios e_i = p_i / t_i\n    e_i = p_i / t_i\n\n    # Order parameters by decreasing efficiency\n    order = np.argsort(-e_i)  # descending\n    p_i_ord = p_i[order]\n    t_i_ord = t_i[order]\n    Nrem = Nmax[order].copy()\n\n    expected_accepted = 0.0\n\n    # If all p_i == 0, skip allocation (no benefit)\n    if np.all(p_i_ord == 0.0):\n        return 0.0\n\n    # Iterate over workers\n    for (r_j, h_j) in workers:\n        C_j = T - h_j\n        if C_j <= 0.0:\n            continue  # worker unusable\n        # Allocate greedily by e_i order\n        for idx in range(len(order)):\n            if C_j <= 0.0:\n                break\n            if Nrem[idx] <= 0:\n                continue\n            # Max number of sims for this param on worker j given remaining capacity\n            # n_ij_max = floor( min(Nrem, C_j * r_j / t_i) )\n            cap_count = int(np.floor((C_j * r_j) / t_i_ord[idx]))\n            if cap_count <= 0:\n                continue\n            n_ij = min(Nrem[idx], cap_count)\n            # Update expected accepted and capacities\n            expected_accepted += n_ij * p_i_ord[idx]\n            # Reduce worker capacity by time spent\n            time_spent = n_ij * (t_i_ord[idx] / r_j)\n            C_j -= time_spent\n            # Update remaining per-parameter allowance\n            Nrem[idx] -= n_ij\n\n    return expected_accepted\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: dict with s_obs, eps, params, workers, T\n    test_cases = [\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 2.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.5, 20),\n                (0.04, 3.0, 0.04, 0.15, 1.0, 50),\n                (0.015, 4.0, 0.03, 0.1, 0.8, 50),\n            ],\n            \"workers\": [\n                (1.0, 0.3),\n                (0.6, 0.4),\n                (2.0, 0.2),\n            ],\n            \"T\": 5.0,\n        },\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 0.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.5, 20),\n                (0.04, 3.0, 0.04, 0.15, 1.0, 50),\n                (0.015, 4.0, 0.03, 0.1, 0.8, 50),\n            ],\n            \"workers\": [\n                (1.0, 0.3),\n                (0.6, 0.4),\n                (2.0, 0.2),\n            ],\n            \"T\": 5.0,\n        },\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 4.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.3, 40),\n                (0.04, 3.0, 0.04, 0.15, 1.1, 40),\n                (0.015, 4.0, 0.03, 0.1, 0.9, 40),\n            ],\n            \"workers\": [\n                (1.0, 1.0),\n                (5.0, 6.0),  # This worker was 0.5 in the prompt, correcting to a more realistic value to avoid confusion. But the logic handles both. Let's use the original 0.5\n                (0.5, 6.0) # unusable due to overhead > T\n            ],\n            \"T\": 5.0,\n        },\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 3.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.2, 2),\n                (0.04, 3.0, 0.04, 0.15, 1.0, 3),\n                (0.015, 4.0, 0.03, 0.1, 0.8, 5),\n            ],\n            \"workers\": [\n                (1.2, 0.2),\n                (1.0, 0.2),\n            ],\n            \"T\": 8.0,\n        },\n    ]\n\n    # Correcting the third test case's worker as per original prompt\n    test_cases[2][\"workers\"] = [(1.0, 1.0), (0.5, 6.0)]\n\n\n    results = []\n    for case in test_cases:\n        s_obs = case[\"s_obs\"]\n        eps = case[\"eps\"]\n        params = case[\"params\"]\n        workers = case[\"workers\"]\n        T = case[\"T\"]\n        expected = allocate_expected_accepted(s_obs, eps, params, workers, T)\n        results.append(f\"{expected:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}