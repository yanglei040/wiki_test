{
    "hands_on_practices": [
        {
            "introduction": "近似贝叶斯计算（ABC）的核心权衡由容差参数 $\\epsilon$ 控制。本练习提供了一个动手实践的机会，旨在从数学上形式化估计器偏差和方差之间的这种权衡，并推导出能够最大化计算统计效率的最优容差 。理解这种平衡对于进行任何严谨的ABC分析都是至关重要的。",
            "id": "3288593",
            "problem": "一个基因调控回路的随机生物化学反应网络模型通过近似贝叶斯计算（ABC）进行校准。令 $S \\in \\mathbb{R}^{d}$ 表示从一个模拟轨迹中计算出的 $d$ 个总结性统计量的向量，并令 $s_{\\text{obs}}$ 为观测到的总结性统计量。ABC 拒绝方案接受一个模拟，如果其欧几里得距离满足 $\\rho(S, s_{\\text{obs}}) \\le \\epsilon$，其中 $\\epsilon > 0$ 是容差。假设对于小的 $\\epsilon$ 存在以下渐近机制：\n\n- 接受概率满足 $\\alpha(\\epsilon) \\approx k\\,\\epsilon^{d}$，其中 $d$ 是 $S$ 的维度，$k>0$ 是一个由 $S$ 在 $s_{\\text{obs}}$ 处的采样分布以及 $d$ 维单位球的体积决定的常数。\n- 对于一个固定的标量泛函 $\\phi(\\theta)$，其后验均值的估计量 $\\widehat{m}_{\\epsilon}$（从未经回归调整的已接受样本中计算得出）在 $\\epsilon$ 很小时，其均方误差为 $\\operatorname{MSE}(\\epsilon) \\approx \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}$，其中 $\\beta>0$ 和 $\\gamma>0$ 是取决于数据生成机制的光滑性以及 $\\phi(\\theta)$ 的后验变异性的常数，而 $B$ 是总计算预算，即模拟器运行的总次数。\n\n将 ABC 估计量对 $\\phi(\\theta)$ 的有效样本量（ESS）定义为：从精确后验分布中抽取的、能够产生相同均方误差的独立同分布样本的大小，即 $\\text{ESS}(\\epsilon) := \\sigma_{\\text{post}}^{2}/\\operatorname{MSE}(\\epsilon)$，其中 $\\sigma_{\\text{post}}^{2}$ 是 $\\phi(\\theta)$ 的精确后验方差（一个不依赖于 $\\epsilon$ 的常数）。\n\n1. 从 $\\mathbb{R}^{d}$ 中小球概率和核邻域的第一性原理出发，推导 $\\epsilon$、$\\alpha(\\epsilon)$ 和 $B$ 之间的函数关系，并用 $\\epsilon$、$B$ 以及常数 $d$、$k$、$\\beta$、$\\gamma$ 和 $\\sigma_{\\text{post}}^{2}$ 表示 $\\text{ESS}(\\epsilon)$。清晰地陈述你所使用的任何正则性假设。\n\n2. 对于一个二维总结性统计量（$d = 2$），其中 $k = 0.4$，$\\beta = L^{2}$ 且 $L = 1.5$，$\\gamma = 0.81$，计算预算 $B = 10^{6}$，选择使 $\\text{ESS}(\\epsilon)$ 最大化的容差 $\\epsilon^{*}$。将 $\\epsilon^{*}$ 报告为一个无量纲数，并四舍五入到四位有效数字。\n\n你的最终答案必须是单个实数：$\\epsilon^{*}$ 的值。",
            "solution": "用户提供了一个关于近似贝叶斯计算（ABC）中容差优化的问题陈述。我将首先验证问题的完整性，如果问题有效，则继续进行完整解答。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n-   总结性统计量向量：$S \\in \\mathbb{R}^{d}$。\n-   观测到的总结性统计量：$s_{\\text{obs}}$。\n-   ABC 接受准则：$\\rho(S, s_{\\text{obs}}) \\le \\epsilon$，其中 $\\rho$ 是欧几里得距离，$\\epsilon > 0$ 是容差。\n-   渐近接受概率：对于小的 $\\epsilon$，$\\alpha(\\epsilon) \\approx k\\,\\epsilon^{d}$，其中 $k > 0$。\n-   后验均值的估计量：$\\widehat{m}_{\\epsilon}$。\n-   估计量的渐近均方误差：对于小的 $\\epsilon$，$\\operatorname{MSE}(\\epsilon) \\approx \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}$。其中 $\\beta > 0$，$\\gamma > 0$，且 $B$ 是总计算预算。\n-   有效样本量的定义：$\\text{ESS}(\\epsilon) := \\sigma_{\\text{post}}^{2}/\\operatorname{MSE}(\\epsilon)$，其中 $\\sigma_{\\text{post}}^{2}$ 是精确后验方差，为一个常数。\n-   任务1：推导 $\\epsilon$、$\\alpha(\\epsilon)$ 和 $B$ 之间的关系，并用给定的常数表示 $\\text{ESS}(\\epsilon)$。陈述正则性假设。\n-   任务2：对于 $d = 2$，$k = 0.4$，$\\beta = L^{2}$ 且 $L = 1.5$，$\\gamma = 0.81$，$B = 10^{6}$，找到使 $\\text{ESS}(\\epsilon)$ 最大化的容差 $\\epsilon^{*}$，并将其报告为四舍五入到四位有效数字的值。\n\n**步骤2：使用提取的已知条件进行验证**\n\n该问题在近似贝叶斯计算的理论中有坚实的科学基础。接受概率和均方误差的表达式是关于 ABC 方法渐近分析文献中的标准结果。MSE 反映了经典的偏差-方差权衡，其中偏差项与容差 $\\epsilon$ 相关（此处，偏差平方 $\\propto \\epsilon^4$），而方差项与接受样本的数量成反比，该数量本身又依赖于 $\\epsilon$。该问题是适定的，因为最大化 ESS 等价于最小化一个良态函数（$\\epsilon$ 的正幂次和负幂次之和），该函数对于 $\\epsilon > 0$ 有唯一的最小值。该问题是客观的、自洽的，并且数值计算部分的所有参数都已提供。没有科学缺陷、矛盾或歧义。\n\n**步骤3：结论与行动**\n\n问题被判定为**有效**。我将继续进行完整解答。\n\n### 解答\n\n解答按要求分为两部分。\n\n**第1部分：推导与函数关系**\n\n接受概率 $\\alpha(\\epsilon)$ 是模拟的总结性统计量向量 $S$ 落入以观测数据 $s_{\\text{obs}}$ 为中心、半径为 $\\epsilon$ 的 $d$ 维球内的概率。令 $p(s) = \\int p(s|\\theta)\\pi(\\theta) d\\theta$ 为总结性统计量的边际或先验预测概率密度函数。接受概率是该密度在接受区域上的积分：\n$$ \\alpha(\\epsilon) = P(\\rho(S, s_{\\text{obs}}) \\le \\epsilon) = \\int_{\\{s \\in \\mathbb{R}^d \\,|\\, \\rho(s, s_{\\text{obs}}) \\le \\epsilon\\}} p(s) \\, ds $$\n对于此推导，我们必须陈述一个关键的**正则性假设**：密度函数 $p(s)$ 必须在 $s_{\\text{obs}}$ 的一个邻域内是连续的。对于小的 $\\epsilon$，我们可以在整个积分体积上用球心处的值 $p(s_{\\text{obs}})$ 来近似 $p(s)$。这可以通过积分中值定理来证明。\n$$ \\alpha(\\epsilon) \\approx p(s_{\\text{obs}}) \\int_{\\{s \\in \\mathbb{R}^d \\,|\\, \\rho(s, s_{\\text{obs}}) \\le \\epsilon\\}} \\, ds $$\n该积分就是半径为 $\\epsilon$ 的 $d$ 维球的体积，由 $V_d \\epsilon^d$ 给出，其中 $V_d = \\frac{\\pi^{d/2}}{\\Gamma(d/2 + 1)}$ 是单位 $d$ 维球的体积。因此，接受概率近似为：\n$$ \\alpha(\\epsilon) \\approx p(s_{\\text{obs}}) V_d \\epsilon^d $$\n将此与给定的函数形式 $\\alpha(\\epsilon) \\approx k\\,\\epsilon^{d}$ 进行比较，我们确定常数 $k$ 为 $k = p(s_{\\text{obs}}) V_d$。这个从第一性原理出发的推导为给定的关系提供了基础。\n\n$\\epsilon$、$\\alpha(\\epsilon)$ 和总计算预算 $B$ 之间的函数关系是统计性的。$B$ 是执行的模拟总数。每次模拟都是一个独立的试验，其成功（接受）的概率等于 $\\alpha(\\epsilon)$。接受的样本数量 $N_{\\text{acc}}$ 服从二项分布，$N_{\\text{acc}} \\sim \\text{Binomial}(B, \\alpha(\\epsilon))$。因此，接受样本的期望数量为：\n$$ E[N_{\\text{acc}}] = B \\cdot \\alpha(\\epsilon) $$\n这个方程描述了它们之间的关系：对于给定的预算 $B$，$\\epsilon$ 的选择决定了接受率 $\\alpha(\\epsilon)$，从而决定了近似后验样本的期望大小 $E[N_{\\text{acc}}]$。\n\n接下来，我们用给定的量来表示有效样本量 $\\text{ESS}(\\epsilon)$。根据定义，$\\text{ESS}(\\epsilon) = \\frac{\\sigma_{\\text{post}}^{2}}{\\operatorname{MSE}(\\epsilon)}$。代入所提供的均方误差的渐近表达式，我们得到：\n$$ \\text{ESS}(\\epsilon) \\approx \\frac{\\sigma_{\\text{post}}^{2}}{\\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}} $$\n这个表达式捕捉了 ABC 中固有的权衡：减小 $\\epsilon$ 会降低偏差项（$\\beta\\epsilon^4$），但同时也会减少接受的样本数量，这会增大方差项（$\\frac{\\gamma}{B\\,k\\,\\epsilon^{d}}$）。\n\n**第2部分：容差 $\\epsilon$ 的优化**\n\n我们的任务是找到使 $\\text{ESS}(\\epsilon)$ 最大化的容差 $\\epsilon^{*}$。最大化 $\\text{ESS}(\\epsilon)$ 等价于最小化其分母，即均方误差 $\\operatorname{MSE}(\\epsilon)$。让我们定义函数 $f(\\epsilon) = \\operatorname{MSE}(\\epsilon)$：\n$$ f(\\epsilon) = \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k\\,\\epsilon^{d}} = \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k}\\,\\epsilon^{-d} $$\n为了找到 $f(\\epsilon)$ 在 $\\epsilon > 0$ 时的最小值，我们计算它关于 $\\epsilon$ 的一阶导数并令其为零。\n$$ \\frac{df}{d\\epsilon} = \\frac{d}{d\\epsilon} \\left( \\beta\\,\\epsilon^{4} + \\frac{\\gamma}{B\\,k}\\,\\epsilon^{-d} \\right) = 4\\beta\\epsilon^3 - d \\frac{\\gamma}{B\\,k} \\epsilon^{-d-1} $$\n将导数设为零以找到最优容差 $\\epsilon^{*}$：\n$$ 4\\beta(\\epsilon^{*})^3 - d \\frac{\\gamma}{B\\,k} (\\epsilon^{*})^{-d-1} = 0 $$\n$$ 4\\beta(\\epsilon^{*})^3 = d \\frac{\\gamma}{B\\,k} (\\epsilon^{*})^{-d-1} $$\n现在，我们求解 $\\epsilon^{*}$：\n$$ (\\epsilon^{*})^{3} (\\epsilon^{*})^{d+1} = \\frac{d\\gamma}{4\\beta B k} $$\n$$ (\\epsilon^{*})^{d+4} = \\frac{d\\gamma}{4\\beta B k} $$\n$$ \\epsilon^{*} = \\left( \\frac{d\\gamma}{4\\beta B k} \\right)^{\\frac{1}{d+4}} $$\n为确认此临界点对应于一个最小值，我们检查其二阶导数：\n$$ \\frac{d^2f}{d\\epsilon^2} = \\frac{d}{d\\epsilon} \\left( 4\\beta\\epsilon^3 - d \\frac{\\gamma}{B\\,k} \\epsilon^{-d-1} \\right) = 12\\beta\\epsilon^2 + d(d+1) \\frac{\\gamma}{B\\,k} \\epsilon^{-d-2} $$\n由于所有常数（$\\beta, d, \\gamma, B, k$）均为正，且 $\\epsilon > 0$，二阶导数中的两项都严格为正。因此，$\\frac{d^2f}{d\\epsilon^2} > 0$，这证实了 $\\epsilon^{*}$ 对应于 $\\operatorname{MSE}(\\epsilon)$ 的一个局部和全局最小值。\n\n现在我们代入给定的数值：\n-   $d = 2$\n-   $k = 0.4$\n-   $\\beta = L^{2} = (1.5)^{2} = 2.25$\n-   $\\gamma = 0.81$\n-   $B = 10^{6}$\n\n将这些值代入 $\\epsilon^{*}$ 的表达式中：\n$$ \\epsilon^{*} = \\left( \\frac{(2)(0.81)}{4(2.25)(10^{6})(0.4)} \\right)^{\\frac{1}{2+4}} $$\n$$ \\epsilon^{*} = \\left( \\frac{1.62}{4(2.25)(0.4)(10^{6})} \\right)^{\\frac{1}{6}} $$\n$$ \\epsilon^{*} = \\left( \\frac{1.62}{(9)(0.4)(10^{6})} \\right)^{\\frac{1}{6}} $$\n$$ \\epsilon^{*} = \\left( \\frac{1.62}{3.6 \\times 10^{6}} \\right)^{\\frac{1}{6}} $$\n分数可以简化为：\n$$ \\frac{1.62}{3.6} = 0.45 $$\n所以表达式变为：\n$$ \\epsilon^{*} = \\left( \\frac{0.45}{10^{6}} \\right)^{\\frac{1}{6}} = \\left( 0.45 \\times 10^{-6} \\right)^{\\frac{1}{6}} $$\n$$ \\epsilon^{*} = (0.45)^{\\frac{1}{6}} \\times (10^{-6})^{\\frac{1}{6}} = (0.45)^{\\frac{1}{6}} \\times 10^{-1} $$\n我们现在计算数值：\n$$ (0.45)^{\\frac{1}{6}} \\approx 0.875438 $$\n$$ \\epsilon^{*} \\approx 0.875438 \\times 10^{-1} = 0.0875438 $$\n按照问题陈述的要求，四舍五入到四位有效数字，我们得到：\n$$ \\epsilon^{*} \\approx 0.08754 $$\n这就是通过优化平衡 ABC 估计量的偏差和方差之间的权衡，从而最大化有效样本量的容差值。",
            "answer": "$$\\boxed{0.08754}$$"
        },
        {
            "introduction": "为ABC运行复杂的生物学模拟在计算上是昂贵的，通常需要并行计算资源。这个实践将你置于计算科学家的角色，任务是在一个异构的计算机集群中优化分配模拟任务 。通过基于计算效率制定贪心分配策略，你将学到一种在固定计算预算下最大化科学回报的实用方法。",
            "id": "3288582",
            "problem": "考虑一个计算系统生物学情境，其中使用近似贝叶斯计算 (ABC) 从观测数据中推断两阶段基因表达模型的参数。该生物模型包含信使核糖核酸 (mRNA) 和蛋白质种类，其受转录、翻译和降解过程的调控。假设在 ABC 中使用的蛋白质汇总统计量采用以下广泛使用的稳态近似：\n\n- 对于给定的参数向量 $\\theta_i = (k_{\\mathrm{tx},i}, k_{\\mathrm{tl},i}, \\gamma_{\\mathrm{m},i}, \\gamma_{\\mathrm{p},i})$（转录速率 $k_{\\mathrm{tx},i}$ 单位为 $\\mathrm{s}^{-1}$，翻译速率 $k_{\\mathrm{tl},i}$ 单位为 $\\mathrm{s}^{-1}$，mRNA 降解速率 $\\gamma_{\\mathrm{m},i}$ 单位为 $\\mathrm{s}^{-1}$，以及蛋白质降解速率 $\\gamma_{\\mathrm{p},i}$ 单位为 $\\mathrm{s}^{-1}$），稳态下的蛋白质均值为\n$$\n\\mu_i = \\frac{k_{\\mathrm{tx},i} \\, k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{m},i} \\, \\gamma_{\\mathrm{p},i}}.\n$$\n\n- 在线性噪声或爆发近似下，蛋白质方差取为\n$$\n\\sigma_i^2 = \\mu_i \\left(1 + \\frac{k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{p},i}}\\right),\n$$\n这捕捉了由翻译爆发引起的超泊松变异性。\n\n在 ABC 中，如果模拟的汇总统计量 $s$ 与观测的汇总统计量 $s_{\\mathrm{obs}}$ 之间的绝对差异最多为一个阈值 $\\varepsilon$，则该模拟被接受。假设对于每个 $\\theta_i$，模型下的汇总统计量 $s$ 近似服从高斯分布，即 $s \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$，并将接受事件定义为 $\\{|s - s_{\\mathrm{obs}}| \\le \\varepsilon\\}$。在这些假设下，参数 $\\theta_i$ 的接受概率是高斯密度在接受区域上的积分。\n\n给定一个固定的挂钟时间预算 $T$（单位为秒）和一组由 $j \\in \\{1,\\dots,W\\}$ 索引的 $W$ 个工作单元。每个工作单元 $j$ 相对于基准模拟时间有一个速度乘数 $r_j$（无量纲），如果使用该工作单元，则会产生一次性开销 $h_j$（单位为秒）。参数 $\\theta_i$ 的单次模拟具有基准运行时间 $t_i$（单位为秒），因此在工作单元 $j$ 上的运行时间为 $t_i / r_j$（单位为秒）。每个参数 $\\theta_i$ 还有一个允许的最大模拟次数 $N_i^{\\max} \\in \\mathbb{N}$。如果使用工作单元 $j$，其可用时间容量为 $C_j = T - h_j$（单位为秒），如果 $C_j \\le 0$，则该工作单元无法执行任何模拟。\n\n您的任务是为每个参数 $\\theta_i$ 和每个工作单元 $j$ 设计一个整数模拟次数 $n_{ij} \\in \\mathbb{N}_0$ 的分配方案，以最大化接受的 ABC 模拟的总期望数量，即\n$$\n\\sum_{i} \\sum_{j} n_{ij} \\, p_i,\n$$\n该分配需满足每个工作单元的时间约束\n$$\n\\sum_{i} n_{ij} \\frac{t_i}{r_j} \\le C_j \\quad \\text{对所有 } j,\n$$\n以及每个参数的最大次数约束\n$$\n\\sum_{j} n_{ij} \\le N_i^{\\max} \\quad \\text{对所有 } i.\n$$\n此处，$p_i$ 表示在上述高斯近似下参数 $\\theta_i$ 的接受概率。\n\n为完成此练习，请实现一个算法，该算法根据高斯模型计算 $p_i$，然后构建一个在约束条件下最大化期望接受数的分配方案。该算法应正确、高效，并可实现为确定性程序。最终输出必须表示为实数（浮点数），代表每个测试用例的期望接受模拟总数，并四舍五入到六位小数。\n\n使用以下参数集测试套件。所有速率单位为 $\\mathrm{s}^{-1}$，时间单位为秒，计数为无量纲整数。观测的汇总统计量单位为分子数（无量纲）。\n\n- 测试用例 1 (通用多工作单元情况):\n  - 观测汇总统计量: $s_{\\mathrm{obs}} = 10$。\n  - 阈值: $\\varepsilon = 2$。\n  - 参数 (每个条目为 $(k_{\\mathrm{tx}}, k_{\\mathrm{tl}}, \\gamma_{\\mathrm{m}}, \\gamma_{\\mathrm{p}}, t, N^{\\max})$):\n    - $\\theta_1$: $(0.01, 2.0, 0.02, 0.1, 1.5, 20)$。\n    - $\\theta_2$: $(0.04, 3.0, 0.04, 0.15, 1.0, 50)$。\n    - $\\theta_3$: $(0.015, 4.0, 0.03, 0.1, 0.8, 50)$。\n  - 工作单元: $(r_j, h_j)$:\n    - 工作单元 1: $(1.0, 0.3)$。\n    - 工作单元 2: $(0.6, 0.4)$。\n    - 工作单元 3: $(2.0, 0.2)$。\n  - 预算: $T = 5.0$。\n\n- 测试用例 2 (零阈值边界情况):\n  - 观测汇总统计量: $s_{\\mathrm{obs}} = 10$。\n  - 阈值: $\\varepsilon = 0$。\n  - 与测试用例 1 相同的参数和工作单元。\n  - 预算: $T = 5.0$。\n\n- 测试用例 3 (工作单元开销导致一个工作单元不可用):\n  - 观测汇总统计量: $s_{\\mathrm{obs}} = 10$。\n  - 阈值: $\\varepsilon = 4$。\n  - 参数:\n    - $\\theta_1$: $(0.01, 2.0, 0.02, 0.1, 1.3, 40)$。\n    - $\\theta_2$: $(0.04, 3.0, 0.04, 0.15, 1.1, 40)$。\n    - $\\theta_3$: $(0.015, 4.0, 0.03, 0.1, 0.9, 40)$。\n  - 工作单元:\n    - 工作单元 1: $(1.0, 1.0)$。\n    - 工作单元 2: $(0.5, 6.0)$。\n  - 预算: $T = 5.0$。\n\n- 测试用例 4 (严格的每参数最大值约束强制混合分配):\n  - 观测汇总统计量: $s_{\\mathrm{obs}} = 10$。\n  - 阈值: $\\varepsilon = 3$。\n  - 参数:\n    - $\\theta_1$: $(0.01, 2.0, 0.02, 0.1, 1.2, 2)$。\n    - $\\theta_2$: $(0.04, 3.0, 0.04, 0.15, 1.0, 3)$。\n    - $\\theta_3$: $(0.015, 4.0, 0.03, 0.1, 0.8, 5)$。\n  - 工作单元:\n    - 工作单元 1: $(1.2, 0.2)$。\n    - 工作单元 2: $(1.0, 0.2)$。\n  - 预算: $T = 8.0$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，`[result1,result2,result3,result4]`）。每个 $resultk$ 必须是一个浮点数，四舍五入到六位小数，按给定顺序对应于测试用例 $k$ 的期望接受总数。",
            "solution": "该问题涉及在并行化和资源约束下为近似贝叶斯计算 (ABC) 模拟设计一种分配策略。背景是一个两阶段基因表达模型，汇总统计量是稳态蛋白质数量。解决方案从基础且经过充分检验的原理出发，并将它们整合到一个算法框架中。\n\n基础建模原理：\n\n1. 根据基因表达中的标准生灭过程近似，在参数 $\\theta_i = (k_{\\mathrm{tx},i}, k_{\\mathrm{tl},i}, \\gamma_{\\mathrm{m},i}, \\gamma_{\\mathrm{p},i})$ 下的稳态蛋白质均值由下式给出\n$$\n\\mu_i = \\frac{k_{\\mathrm{tx},i} \\, k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{m},i} \\, \\gamma_{\\mathrm{p},i}}.\n$$\n这是一个被广泛接受的稳态均值表达式，通过平衡两阶段模型中的生产和降解速率推导得出。\n\n2. 在线性噪声或爆发近似下，蛋白质方差为\n$$\n\\sigma_i^2 = \\mu_i \\left(1 + \\frac{k_{\\mathrm{tl},i}}{\\gamma_{\\mathrm{p},i}}\\right).\n$$\n这是一个经过充分检验的公式，用于捕捉由翻译爆发引起的超泊松变异性，在精确分布难以处理时，常用于计算系统生物学。\n\n3. ABC 的接受条件由差异阈值标准定义。对于每个参数 $\\theta_i$，模拟的汇总统计量 $s$ 被建模为高斯分布 $s \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$，接受事件为 $\\{|s - s_{\\mathrm{obs}}| \\le \\varepsilon\\}$。因此，接受概率为\n$$\np_i = \\mathbb{P}\\left(|s - s_{\\mathrm{obs}}| \\le \\varepsilon \\,\\middle|\\, \\theta_i \\right) = \\int_{s_{\\mathrm{obs}} - \\varepsilon}^{s_{\\mathrm{obs}} + \\varepsilon} \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}} \\exp\\left(-\\frac{(x - \\mu_i)^2}{2\\sigma_i^2}\\right) \\, dx.\n$$\n根据高斯累积分布函数的基本性质，该积分等于\n$$\np_i = \\Phi\\!\\left(\\frac{s_{\\mathrm{obs}} + \\varepsilon - \\mu_i}{\\sigma_i}\\right) - \\Phi\\!\\left(\\frac{s_{\\mathrm{obs}} - \\varepsilon - \\mu_i}{\\sigma_i}\\right),\n$$\n其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。此推导使用经典概率论，除了高斯积分性质外，没有使用任何捷径。\n\n并行资源分配原理：\n\n4. 参数 $\\theta_i$ 的每次模拟都有一个基准运行时间 $t_i$（单位为秒）。在速度乘数为 $r_j$ 的工作单元 $j$ 上，运行时间为 $t_i / r_j$（单位为秒）。如果使用该工作单元，会产生一次性开销 $h_j$（单位为秒），剩余的有效容量为\n$$\nC_j = T - h_j.\n$$\n$C_j \\le 0$ 的工作单元无法执行模拟。\n\n5. 目标是最大化期望接受的模拟次数，\n$$\n\\sum_{i} \\sum_{j} n_{ij} \\, p_i,\n$$\n并受以下约束\n$$\n\\sum_{i} n_{ij} \\frac{t_i}{r_j} \\le C_j \\quad \\text{对所有 } j, \\qquad \\sum_{j} n_{ij} \\le N_i^{\\max} \\quad \\text{对所有 } i,\n$$\n其中整数 $n_{ij} \\ge 0$。\n\n基于原理的优化设计：\n\n6. 将参数 $\\theta_i$ 的效率比定义为单位基准时间内期望接受的次数：\n$$\ne_i = \\frac{p_i}{t_i}.\n$$\n在工作单元 $j$ 上，参数 $\\theta_i$ 的单位工作单元时间内期望接受的次数按如下比例变化\n$$\ne_{ij}^{\\mathrm{worker}} = \\frac{p_i}{t_i / r_j} = r_j \\, e_i.\n$$\n由于对于工作单元 $j$ 来说 $r_j$ 对所有参数都是常数，因此按 $e_{ij}^{\\mathrm{worker}}$ 对参数排序与按 $e_i$ 进行全局排序的结果相同。因此，对于任何工作单元 $j$，按 $e_i$ 的降序为参数分配时间，可以在该工作单元的容量约束下最大化期望接受次数。这个结论可以通过类似背包问题的资源分配中的标准交换论证来证明：如果两个参数 $i$ 和 $k$ 满足 $e_i > e_k$，任何在耗尽参数 $i$ 的任务之前花费时间在参数 $k$ 上的可行分配，都可以通过将等量时间从 $k$ 交换到 $i$ 来改进，从而在不违反约束的情况下增加期望接受次数。\n\n7. 激活开销 $h_j$ 只是减少了可用容量。是否使用一个工作单元的决定是自然而然的：如果 $C_j \\le 0$，则跳过该工作单元；否则，根据贪心顺序进行分配。如果所有的 $p_i = 0$，那么对所有 $i$ 都有 $e_i = 0$，无论如何分配，期望接受次数都为 $0$；在这种退化情况下，可以选择不安排任何模拟。\n\n8. 通过对能在容量内完成的模拟次数向下取整来强制实现整数可行性。对于一个工作单元 $j$，给定剩余容量 $C_j^{\\mathrm{rem}}$ 和剩余的每参数限额 $N_i^{\\mathrm{rem}}$，可以运行的参数 $\\theta_i$ 的最大模拟次数是\n$$\nn_{ij}^{\\max} = \\left\\lfloor \\min\\left(N_i^{\\mathrm{rem}}, \\frac{C_j^{\\mathrm{rem}}}{t_i / r_j}\\right) \\right\\rfloor = \\left\\lfloor \\min\\left(N_i^{\\mathrm{rem}}, \\frac{C_j^{\\mathrm{rem}} \\, r_j}{t_i}\\right) \\right\\rfloor.\n$$\n在移动到按效率排序列表中的下一个参数之前，分配 $n_{ij} = n_{ij}^{\\max}$，并更新容量和 $N_i^{\\mathrm{rem}}$。\n\n算法步骤：\n\n9. 对每个测试用例：\n- 根据给定速率为每个参数 $\\theta_i$ 计算 $\\mu_i$ 和 $\\sigma_i^2$。\n- 计算 $\\sigma_i = \\sqrt{\\sigma_i^2}$，然后通过高斯累积分布函数计算接受概率 $p_i$，即 $p_i = \\Phi\\!\\left((s_{\\mathrm{obs}} + \\varepsilon - \\mu_i)/\\sigma_i\\right) - \\Phi\\!\\left((s_{\\mathrm{obs}} - \\varepsilon - \\mu_i)/\\sigma_i\\right)$。\n- 计算 $e_i = p_i / t_i$。\n- 按 $e_i$ 降序对参数进行排序。\n- 对于每个工作单元 $j$，计算 $C_j = T - h_j$；如果 $C_j \\le 0$，则跳过。否则，按排序顺序遍历参数，并根据剩余容量和 $N_i^{\\mathrm{rem}}$ 将 $n_{ij}$ 分配为可行数量的整数下取整，更新 $C_j$ 和 $N_i^{\\mathrm{rem}}$，继续直到容量耗尽或所有参数的 $N_i^{\\mathrm{rem}}$ 为零。\n- 累积期望接受次数 $\\sum_{i,j} n_{ij} p_i$。\n- 将最终的期望接受次数四舍五入到六位小数。\n\n10. 上述过程在计算上是高效的，因为它通过使用基于 $e_i$ 的有原则的贪心排序避免了组合搜索，这一点由期望的线性性质和可加的时间约束所证明。它遵守所有约束，并且对边界条件（$\\varepsilon = 0$、因 $C_j \\le 0$ 而无效的工作单元，以及强制混合分配的严格的每参数最大值约束）具有鲁棒性。\n\n程序将为四个指定的测试用例实现这些步骤，并打印单行，其中包含按给定顺序排列的四个期望总数列表，四舍五入到六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef compute_mu_sigma2(params):\n    \"\"\"\n    Compute steady-state protein mean (mu) and variance (sigma^2) for each parameter tuple.\n    params: list of tuples (k_tx, k_tl, gamma_m, gamma_p, t, Nmax)\n    Returns: arrays mu, sigma2, baseline_times, Nmax\n    \"\"\"\n    mu = []\n    sigma2 = []\n    baseline_times = []\n    nmax = []\n    for (k_tx, k_tl, gamma_m, gamma_p, t, Nmax) in params:\n        mu_i = (k_tx * k_tl) / (gamma_m * gamma_p)\n        sigma2_i = mu_i * (1.0 + (k_tl / gamma_p))\n        mu.append(mu_i)\n        sigma2.append(sigma2_i)\n        baseline_times.append(t)\n        nmax.append(int(Nmax))\n    return np.array(mu), np.array(sigma2), np.array(baseline_times), np.array(nmax, dtype=int)\n\ndef compute_acceptance_probs(mu, sigma2, s_obs, eps):\n    \"\"\"\n    Compute acceptance probabilities for Gaussian summaries:\n    p_i = Phi((s_obs + eps - mu)/sigma) - Phi((s_obs - eps - mu)/sigma)\n    \"\"\"\n    sigma = np.sqrt(sigma2)\n    # Handle potential zero variance edge cases by returning zero acceptance (though not expected here)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        upper = (s_obs + eps - mu) / sigma\n        lower = (s_obs - eps - mu) / sigma\n        # Where sigma is zero, set probability to 1 if s_obs within eps of mu, else 0\n        p = norm.cdf(upper) - norm.cdf(lower)\n        # Replace NaNs due to zero sigma with deterministic outcomes\n        zero_sigma_idx = np.where(sigma == 0)[0]\n        for idx in zero_sigma_idx:\n            if abs(s_obs - mu[idx]) = eps:\n                p[idx] = 1.0\n            else:\n                p[idx] = 0.0\n    # Ensure probabilities are within [0,1] numerically\n    p = np.clip(p, 0.0, 1.0)\n    return p\n\ndef allocate_expected_accepted(s_obs, eps, params, workers, T):\n    \"\"\"\n    Allocate simulations across workers to maximize expected accepted count.\n\n    params: list of tuples (k_tx, k_tl, gamma_m, gamma_p, t, Nmax)\n    workers: list of tuples (r_j, h_j)\n    T: time budget\n    Returns: expected_accepted (float)\n    \"\"\"\n    mu, sigma2, t_i, Nmax = compute_mu_sigma2(params)\n    p_i = compute_acceptance_probs(mu, sigma2, s_obs, eps)\n    # Efficiency ratios e_i = p_i / t_i\n    with np.errstate(divide='ignore', invalid='ignore'):\n        e_i = np.nan_to_num(p_i / t_i)\n\n    # Order parameters by decreasing efficiency\n    order = np.argsort(-e_i)  # descending\n    p_i_ord = p_i[order]\n    t_i_ord = t_i[order]\n    Nrem = Nmax[order].copy()\n\n    expected_accepted = 0.0\n\n    # If all p_i == 0, skip allocation (no benefit)\n    if np.all(p_i_ord == 0.0):\n        return 0.0\n\n    # Iterate over workers\n    for (r_j, h_j) in workers:\n        C_j = T - h_j\n        if C_j = 0.0:\n            continue  # worker unusable\n        # Allocate greedily by e_i order\n        for idx in range(len(order)):\n            if C_j = 0.0:\n                break\n            if Nrem[idx] == 0:\n                continue\n            # Max number of sims for this param on worker j given remaining capacity\n            # n_ij_max = floor( min(Nrem, C_j * r_j / t_i) )\n            if t_i_ord[idx] == 0:\n                cap_count = Nrem[idx] if C_j > 0 else 0\n            else:\n                cap_count = int(np.floor((C_j * r_j) / t_i_ord[idx]))\n\n            if cap_count == 0:\n                continue\n            n_ij = min(Nrem[idx], cap_count)\n            # Update expected accepted and capacities\n            expected_accepted += n_ij * p_i_ord[idx]\n            # Reduce worker capacity by time spent\n            if r_j > 0:\n                time_spent = n_ij * (t_i_ord[idx] / r_j)\n                C_j -= time_spent\n            # Update remaining per-parameter allowance\n            Nrem[idx] -= n_ij\n\n    return expected_accepted\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: dict with s_obs, eps, params, workers, T\n    test_cases = [\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 2.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.5, 20),\n                (0.04, 3.0, 0.04, 0.15, 1.0, 50),\n                (0.015, 4.0, 0.03, 0.1, 0.8, 50),\n            ],\n            \"workers\": [\n                (1.0, 0.3),\n                (0.6, 0.4),\n                (2.0, 0.2),\n            ],\n            \"T\": 5.0,\n        },\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 0.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.5, 20),\n                (0.04, 3.0, 0.04, 0.15, 1.0, 50),\n                (0.015, 4.0, 0.03, 0.1, 0.8, 50),\n            ],\n            \"workers\": [\n                (1.0, 0.3),\n                (0.6, 0.4),\n                (2.0, 0.2),\n            ],\n            \"T\": 5.0,\n        },\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 4.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.3, 40),\n                (0.04, 3.0, 0.04, 0.15, 1.1, 40),\n                (0.015, 4.0, 0.03, 0.1, 0.9, 40),\n            ],\n            \"workers\": [\n                (1.0, 1.0),\n                (0.5, 6.0),  # unusable due to overhead > T\n            ],\n            \"T\": 5.0,\n        },\n        {\n            \"s_obs\": 10.0,\n            \"eps\": 3.0,\n            \"params\": [\n                (0.01, 2.0, 0.02, 0.1, 1.2, 2),\n                (0.04, 3.0, 0.04, 0.15, 1.0, 3),\n                (0.015, 4.0, 0.03, 0.1, 0.8, 5),\n            ],\n            \"workers\": [\n                (1.2, 0.2),\n                (1.0, 0.2),\n            ],\n            \"T\": 8.0,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        s_obs = case[\"s_obs\"]\n        eps = case[\"eps\"]\n        params = case[\"params\"]\n        workers = case[\"workers\"]\n        T = case[\"T\"]\n        expected = allocate_expected_accepted(s_obs, eps, params, workers, T)\n        results.append(f\"{expected:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "系统生物学的一个关键挑战是解释细胞间的变异性。本练习探讨了如何使用ABC实现不同的建模理念——将细胞视为相同的（完全汇集）、完全独立的（无汇集），或作为一个群体中相关的成员（部分汇集）。通过在合成数据上比较这些分层建模策略，你将深入了解在研究异构生物系统时，如何选择合适的模型来平衡偏差和方差。",
            "id": "3288570",
            "problem": "您的任务是实现并比较三种近似贝叶斯计算（ABC）校准策略——完全池化、无池化和部分池化（层次化）——用于一个能够捕捉细胞间异质性的简单随机单細胞基因表达模型。您的实现必须是一个完整的、可运行的程序，该程序不接受任何输入，并按末尾指定的方式打印单行结果。\n\n基本和模型假设：\n- 系统被建模为一个生死过程，其中对于每个细胞 $i$，在给定时间测量的信使核糖核酸（mRNA）拷贝数被建模为一个率参数为 $k_i$ 的泊松随机变量，即 $Y_{i,t} \\sim \\mathrm{Poisson}(k_i)$，在时间 $t$ 和细胞 $i$ 之间相互独立。\n- 在此模型下，每个细胞的期望均值为 $\\mathbb{E}[Y_{i,t}] = k_i$，而在 $T$ 次重复中每个细胞的样本均值提供了 $k_i$ 的一个无偏估计。\n\nABC 设置和定义：\n- 近似贝叶斯计算（ABC）旨在当似然函数难以处理但模型模拟可用时，近似贝叶斯后验 $p(\\theta \\mid y)$。ABC 从先验 $p(\\theta)$ 中生成参数抽取 $\\theta^{(j)}$，模拟合成数据 $z^{(j)} \\sim p(\\cdot \\mid \\theta^{(j)})$，计算模拟数据和观测数据的概要统计量 $S(\\cdot)$ 之间的距离 $d(S(z^{(j)}), S(y))$，并接受距离足够小的抽取。\n- 您必须使用拒绝 ABC，其接受规则定义为保留具有最小距离的参数抽取中的顶部比例。具体来说，如果有 $M$ 次抽取且接受分数为 $\\alpha \\in (0,1]$，那么您必须接受具有最小距离的 $K = \\max\\{1, \\lceil \\alpha M \\rceil\\}$ 次抽取。\n\n池化策略（待实现和比较）：\n1. 完全池化：所有细胞共享一个共同的率 $k$，即对于所有 $i$，$k_i \\equiv k$。先验：$k \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$。对于 ABC 模拟，对于每次抽取 $k^{(j)}$，为所有 $i$ 和 $t$ 模拟 $Y_{i,t}^{(j)} \\sim \\mathrm{Poisson}(k^{(j)})$，计算每细胞均值 $S^{(j)}_i = \\frac{1}{T} \\sum_t Y_{i,t}^{(j)}$，定义距离 $d^{(j)} = \\left( \\sum_{i=1}^{N} (S^{(j)}_i - \\bar{Y}_i)^2 \\right)^{1/2}$，其中 $\\bar{Y}_i$ 是观测到的每细胞均值，然后接受前 $K$ 次抽取。后验预测的每细胞均值向量由 $\\hat{m}^{\\mathrm{full}} = \\left(\\overline{k}_{\\mathrm{acc}}\\right) \\cdot \\mathbf{1}_N$ 给出，其中 $\\overline{k}_{\\mathrm{acc}}$ 是接受的 $k^{(j)}$ 的平均值，$\\mathbf{1}_N$ 是 $N$ 维全一向量。\n2. 无池化：每个细胞有其自身的率 $k_i$，独立地服从先验 $k_i \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$。对每个细胞 $i$ 单独执行 ABC，使用标量距离 $d_i^{(j)} = \\left| S_i^{(j)} - \\bar{Y}_i \\right|$，其中 $S_i^{(j)} = \\frac{1}{T} \\sum_t Y_{i,t}^{(j)}$ 且 $Y_{i,t}^{(j)} \\sim \\mathrm{Poisson}(k_i^{(j)})$。对于每个细胞，接受前 $K_i = \\max\\{1, \\lceil \\alpha M \\rceil\\}$ 次抽取并计算后验预测均值 $\\hat{m}^{\\mathrm{no}}_i = \\overline{k_{i,\\mathrm{acc}}}$。后验预测的每细胞均值向量是 $\\hat{m}^{\\mathrm{no}} = (\\hat{m}^{\\mathrm{no}}_1, \\dots, \\hat{m}^{\\mathrm{no}}_N)$。\n3. 部分池化（层次化）：一个层次化先验通过超参数将细胞耦合起来：$k_i \\sim \\mathrm{LogNormal}(\\mu, \\sigma^2)$，带有超先验 $\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$ 和 $\\sigma \\sim \\mathrm{HalfNormal}(\\tau)$，其中半正态分布的密度在 $\\sigma \\ge 0$ 时与 $\\exp\\left( -\\frac{\\sigma^2}{2\\tau^2} \\right)$ 成正比。对于 ABC，抽取 $(\\mu^{(j)}, \\sigma^{(j)})$，然后对所有 $i$ 抽取 $k_i^{(j)} \\sim \\mathrm{LogNormal}(\\mu^{(j)}, (\\sigma^{(j)})^2)$，模拟 $Y_{i,t}^{(j)} \\sim \\mathrm{Poisson}(k_i^{(j)})$，计算每细胞均值 $S^{(j)}_i$，定义 $d^{(j)} = \\left( \\sum_{i=1}^{N} (S^{(j)}_i - \\bar{Y}_i)^2 \\right)^{1/2}$，接受前 $K$ 次抽取，并计算后验预测的每细胞均值 $\\hat{m}^{\\mathrm{partial}}_i = \\overline{k_{i,\\mathrm{acc}}}$。\n\n评估指标：\n- 对于下面的每种情景，您将获得从已知的真实值向量 $\\mathbf{k}^{\\ast} = (k^{\\ast}_1,\\dots,k^{\\ast}_N)$ 生成的合成观测数据，以及每个细胞的两组不相交的重复集：一个拟合集和一个留出集。\n- 令 $\\bar{Y}_i$ 为拟合集的每细胞均值，$\\bar{Y}^{\\mathrm{hold}}_i$ 为留出集的每细胞均值。\n- 对于任何产生每细胞预测均值向量 $\\hat{m}$ 的方法，通过均方根误差（RMSE）来量化预测准确性\n$$\n\\mathrm{RMSE}(\\hat{m}, \\bar{\\mathbf{Y}}^{\\mathrm{hold}}) = \\left( \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\hat{m}_i - \\bar{Y}^{\\mathrm{hold}}_i \\right)^2 \\right)^{1/2}.\n$$\n- 对于每个测试案例，报告哪种方法产生最小的 RMSE，若出现平局，则优先选择排序中索引较小者：完全池化 = 0，无池化 = 1，部分池化 = 2。\n\n先验、超参数和 ABC 配置：\n- 对数正态先验参数和正态超先验参数使用 $\\mu_0 = \\log(6.0)$ 和 $\\sigma_0 = 1.0$。\n- 半正态分布的 $\\sigma$ 尺度使用 $\\tau = 1.0$。\n- 对于完全池化，使用 $M_{\\mathrm{full}} = 8000$ 次抽取和接受分数 $\\alpha_{\\mathrm{full}} = 0.05$。\n- 对于无池化，每个细胞使用 $M_{\\mathrm{no}} = 5000$ 次抽取和接受分数 $\\alpha_{\\mathrm{no}} = 0.10$。\n- 对于部分池化，使用 $M_{\\mathrm{partial}} = 16000$ 次抽取和接受分数 $\\alpha_{\\mathrm{partial}} = 0.05$。\n\n测试套件的数据生成：\n- 对于每个测试案例，从对数正态分布中模拟真实的每细胞率：$k_i^{\\ast} \\sim \\mathrm{LogNormal}(\\mu_{\\mathrm{true}}, \\sigma_{\\mathrm{true}}^2)$。对于每个细胞 $i \\in \\{1,\\dots,N\\}$，首先生成 $2T$ 次独立的重复 $Y_{i,1}, \\dots, Y_{i,2T} \\sim \\mathrm{Poisson}(k_i^{\\ast})$；使用前 $T$ 次计算 $\\bar{Y}_i$（拟合集），后 $T$ 次计算 $\\bar{Y}^{\\mathrm{hold}}_i$（留出集）。\n- 使用由提供的整数种子初始化的独立伪随机数生成器状态，以确保每种情景的可复现性。\n\n测试套件：\n- 案例 A（低异质性，小每细胞样本量）：$N = 8$, $T = 3$, $\\mu_{\\mathrm{true}} = \\log(6.0)$, $\\sigma_{\\mathrm{true}} = 0.05$, 随机种子 $s = 12345$。\n- 案例 B（高异质性，较大每细胞样本量）：$N = 8$, $T = 15$, $\\mu_{\\mathrm{true}} = \\log(6.0)$, $\\sigma_{\\mathrm{true}} = 0.8$, 随机种子 $s = 23456$。\n- 案例 C（中等异质性，极小每细胞样本量）：$N = 8$, $T = 2$, $\\mu_{\\mathrm{true}} = \\log(6.0)$, $\\sigma_{\\mathrm{true}} = 0.4$, 随机种子 $s = 34567$。\n\n实现要求：\n- 严格按照定义使用距离和接受规则。\n- 对于完全池化方法的预测均值，使用接受的 $k$ 值的平均值，并将每细胞预测向量设置为在所有细胞中保持不变。对于无池化方法的预测均值，对每个细胞使用其接受的 $k_i$ 值的平均值。对于部分池化方法的预测均值，对每个细胞 $i$ 使用其接受的 $k_i$ 抽取的平均值。\n- 计算与留出集每细胞均值的 RMSE，并根据指定的索引顺序确定每个测试案例的最佳方法。\n- 您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个测试案例一个整数，对应于最佳方法在排序中的索引：完全池化 = 0，无池化 = 1，部分池化 = 2。例如，一个有效的最终输出行格式为 $[x_1,x_2,x_3]$，其中 $x_j \\in \\{0,1,2\\}$。\n\n数值输出：\n- 不涉及物理单位，所有最终报告的量都是无量纲整数。单行输出必须严格遵循所需格式，不含任何额外文本。",
            "solution": "该问题陈述是有效的。它在科学上基于计算系统生物学和贝叶斯统计的既定原则，定义了所有必要的参数和程序，是良定的，并且其表述是客观的。任务是在一个随机单细胞基因表达模型中，实现并比较三种用于参数推断的近似贝叶斯计算（ABC）策略。\n\n问题的核心涉及统计建模中的一个基本概念：偏差与方差之间的权衡，通过在相关组（在此案例中为细胞）之间不同程度的“池化”或信息共享来管理。模型假设对于每个细胞 $i$，信使RNA（mRNA）计数 $Y_{i,t}$ 服从一个具有细胞特异性率参数 $k_i$ 的泊松分布，即 $Y_{i,t} \\sim \\mathrm{Poisson}(k_i)$。目标是估计率向量 $\\mathbf{k} = (k_1, \\dots, k_N)$ 并评估每种策略的预测准确性。\n\n这三种 ABC 策略体现了关于细胞群体的不同假设：\n\n1.  **完全池化**：该策略在细胞同质性的限制性假设下运作，断言所有细胞共享一个单一、共同的率参数 $k$，使得对于所有 $i \\in \\{1, \\dots, N\\}$，$k_i \\equiv k$。为这个共同的率定义了一个单一的先验，$k \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$。这种方法通过使用所有数据来为单个参数 $k$ 的估计提供信息，从而最大限度地借鉴了所有细胞的统计强度。然而，如果细胞实际上是异质的，由于模型设定错误，这会引入显著的偏差。ABC 过程涉及抽样一个标量 $k^{(j)}$，从 $\\mathrm{Poisson}(k^{(j)})$ 为所有 $N$ 个细胞模拟数据，并计算一个单一距离 $d^{(j)} = \\left( \\sum_{i=1}^{N} (S^{(j)}_i - \\bar{Y}_i)^2 \\right)^{1/2}$，其中 $S^{(j)}_i$ 是模拟的每细胞均值，$\\bar{Y}_i$ 是观测均值。每个细胞的后验预测均值是接受的 $k^{(j)}$ 值的平均值，即 $\\overline{k}_{\\mathrm{acc}}$。\n\n2.  **无池化**：在另一个极端，该策略假设细胞之间完全独立。每个细胞 $i$ 被视为一个拥有自身率参数 $k_i$ 的独立实验，并为其分配一个独立的先验 $k_i \\sim \\mathrm{LogNormal}(\\mu_0, \\sigma_0^2)$。这种方法高度灵活，可以捕捉任意的异质性。然而，由于未能在细胞间共享信息，每个细胞的参数估计完全依赖其自身通常有限的数据。这可能导致高方差（过拟合），特别是当每个细胞的观测次数 $T$ 很小时。ABC 过程是为每个细胞单独执行的，使用标量距离 $d_i^{(j)} = |S_i^{(j)} - \\bar{Y}_i|$。每个细胞的后验预测均值 $\\hat{m}^{\\mathrm{no}}_i$ 是其自身接受的 $k_{i, \\mathrm{acc}}^{(j)}$ 值集合的平均值。\n\n3.  **部分池化（层次化模型）**：该策略提供了一个有原则的折衷方案。它假定细胞特异性率 $k_i$ 是相关但不相同的。它们被假定是从一个共同的总体分布中抽取的，$k_i \\sim \\mathrm{LogNormal}(\\mu, \\sigma^2)$。这个总体分布的参数 $(\\mu, \\sigma^2)$ 本身是未知的，并被赋予了先验，称为超先验：$\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$ 和 $\\sigma \\sim \\mathrm{HalfNormal}(\\tau)$。通过联合推断 $k_i$ 和超参数 $(\\mu, \\sigma)$，模型允许数据决定细胞间的相似程度。信息通过估计这些共享的超参数在细胞间共享（“池化”），从而产生一种自适应正则化效应，即单个细胞的估计值向估计的总体均值“收缩”。这通常能在偏差和方差之间提供最佳的权衡。此模型的 ABC 过程涉及抽样超参数 $(\\mu^{(j)}, \\sigma^{(j)})$，然后抽样一个完整的率向量 $\\mathbf{k}^{(j)}$，模拟数据，并像完全池化情况一样计算单一距离 $d^{(j)}$。每个细胞 $i$ 的后验预测均值 $\\hat{m}^{\\mathrm{partial}}_i$ 是来自接受的参数向量中 $k_i^{(j)}$ 分量的平均值。\n\n实现首先通过使用提供的随机种子为每个测试案例生成合成的“观测”数据来进行。这包括一个用于运行 ABC 算法的`拟合集`和一个用于评估的`留出集`。这些集合的每细胞样本均值分别表示为 $\\bar{\\mathbf{Y}}$ 和 $\\bar{\\mathbf{Y}}^{\\mathrm{hold}}$。\n\n对于每个测试案例和三种池化策略中的每一种，都会根据其特定的模拟和距离计算规则执行相应的 ABC 算法。接受的参数抽取数量 $K$ 由总抽取次数 $M$ 和接受分数 $\\alpha$ 确定，即 $K = \\max\\{1, \\lceil \\alpha M \\rceil\\}$。在确定了接受的参数集之后，为每种策略计算后验预测均值向量 $\\hat{\\mathbf{m}}$。\n\n最后，通过预测均值和留出数据之间的均方根误差（RMSE）来量化预测准确性：\n$$\n\\mathrm{RMSE}(\\hat{\\mathbf{m}}, \\bar{\\mathbf{Y}}^{\\mathrm{hold}}) = \\left( \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\hat{m}_i - \\bar{Y}^{\\mathrm{hold}}_i \\right)^2 \\right)^{1/2}\n$$\n对于每个测试案例，选择产生最小 RMSE 的方法作为表现最佳的策略，若出现平局则优先选择索引较低的方法（完全池化为0，无池化为1，部分池化为2）。最终输出是这些获胜索引的列表。这种比较分析旨在突显每种池化策略在测试案例所定义的不同细胞异质性和数据可用性条件下的优势和劣势。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Implements and compares full pooling, no pooling, and partial pooling ABC strategies\n    for a single-cell gene expression model.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'name': 'A', 'N': 8, 'T': 3, 'mu_true': np.log(6.0), 'sigma_true': 0.05, 'seed': 12345},\n        {'name': 'B', 'N': 8, 'T': 15, 'mu_true': np.log(6.0), 'sigma_true': 0.8, 'seed': 23456},\n        {'name': 'C', 'N': 8, 'T': 2, 'mu_true': np.log(6.0), 'sigma_true': 0.4, 'seed': 34567},\n    ]\n\n    # Global prior and hyperprior parameters\n    MU0 = np.log(6.0)\n    SIGMA0 = 1.0\n    TAU = 1.0\n    \n    results = []\n\n    for case in test_cases:\n        rng = np.random.default_rng(case['seed'])\n        N, T = case['N'], case['T']\n\n        # Generate synthetic observed data\n        k_true = rng.lognormal(mean=case['mu_true'], sigma=case['sigma_true'], size=N)\n        \n        y_bar_fit = np.zeros(N)\n        y_bar_holdout = np.zeros(N)\n        for i in range(N):\n            all_replicates = rng.poisson(lam=k_true[i], size=2 * T)\n            y_bar_fit[i] = np.mean(all_replicates[:T])\n            y_bar_holdout[i] = np.mean(all_replicates[T:])\n\n        # Run each ABC method and calculate RMSE\n        rmse_full = run_full_pooling(rng, y_bar_fit, y_bar_holdout, N, T, MU0, SIGMA0)\n        rmse_no = run_no_pooling(rng, y_bar_fit, y_bar_holdout, N, T, MU0, SIGMA0)\n        rmse_partial = run_partial_pooling(rng, y_bar_fit, y_bar_holdout, N, T, MU0, SIGMA0, TAU)\n\n        rmses = [rmse_full, rmse_no, rmse_partial]\n        best_method_idx = np.argmin(rmses)\n        results.append(best_method_idx)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_rmse(m_hat, y_bar_holdout):\n    return np.sqrt(np.mean((m_hat - y_bar_holdout)**2))\n\ndef run_full_pooling(rng, y_bar_fit, y_bar_holdout, N, T, mu0, sigma0):\n    M = 8000\n    alpha = 0.05\n    K = int(max(1, np.ceil(alpha * M)))\n\n    k_draws = rng.lognormal(mean=mu0, sigma=sigma0, size=M)\n    distances = np.zeros(M)\n    \n    for j in range(M):\n        k_j = k_draws[j]\n        sim_data = rng.poisson(lam=k_j, size=(N, T))\n        s_j = np.mean(sim_data, axis=1)\n        distances[j] = np.sqrt(np.sum((s_j - y_bar_fit)**2))\n        \n    accepted_indices = np.argsort(distances)[:K]\n    k_accepted = k_draws[accepted_indices]\n    \n    k_bar_acc = np.mean(k_accepted)\n    m_hat_full = np.full(N, k_bar_acc)\n    \n    return calculate_rmse(m_hat_full, y_bar_holdout)\n\ndef run_no_pooling(rng, y_bar_fit, y_bar_holdout, N, T, mu0, sigma0):\n    M = 5000\n    alpha = 0.10\n    K = int(max(1, np.ceil(alpha * M)))\n\n    m_hat_no = np.zeros(N)\n    \n    for i in range(N):\n        ki_draws = rng.lognormal(mean=mu0, sigma=sigma0, size=M)\n        distances_i = np.zeros(M)\n        for j in range(M):\n            ki_j = ki_draws[j]\n            sim_data_i = rng.poisson(lam=ki_j, size=T)\n            si_j = np.mean(sim_data_i)\n            distances_i[j] = np.abs(si_j - y_bar_fit[i])\n            \n        accepted_indices = np.argsort(distances_i)[:K]\n        ki_accepted = ki_draws[accepted_indices]\n        m_hat_no[i] = np.mean(ki_accepted)\n        \n    return calculate_rmse(m_hat_no, y_bar_holdout)\n\ndef run_partial_pooling(rng, y_bar_fit, y_bar_holdout, N, T, mu0, sigma0, tau):\n    M = 16000\n    alpha = 0.05\n    K = int(max(1, np.ceil(alpha * M)))\n\n    mu_draws = rng.normal(loc=mu0, scale=sigma0, size=M)\n    sigma_draws = np.abs(rng.normal(loc=0, scale=tau, size=M))\n\n    k_draws_all = np.zeros((M, N))\n    distances = np.zeros(M)\n\n    for j in range(M):\n        mu_j = mu_draws[j]\n        sigma_j = sigma_draws[j]\n        \n        k_vec_j = rng.lognormal(mean=mu_j, sigma=sigma_j, size=N)\n        k_draws_all[j, :] = k_vec_j\n        \n        # Vectorized simulation for the N cells\n        lam_expanded = np.repeat(k_vec_j[:, np.newaxis], T, axis=1)\n        sim_data = rng.poisson(lam=lam_expanded)\n        s_j = np.mean(sim_data, axis=1)\n        \n        distances[j] = np.sqrt(np.sum((s_j - y_bar_fit)**2))\n\n    accepted_indices = np.argsort(distances)[:K]\n    k_accepted = k_draws_all[accepted_indices, :]\n    \n    m_hat_partial = np.mean(k_accepted, axis=0)\n    \n    return calculate_rmse(m_hat_partial, y_bar_holdout)\n\nsolve()\n```"
        }
    ]
}