{
    "hands_on_practices": [
        {
            "introduction": "生物系统本质上是随机的，这意味着纯粹的确定性模型（如常微分方程，ODEs）可能无法完全捕捉其动态。此练习介绍了一种基本方法，通过将确定性模型扩展为随机微分方程（SDEs）来为动态模型引入不确定性。您将应用欧拉-丸山（Euler-Maruyama）方法来推导离散时间转移密度，这是为动态系统时间序列数据构建似然函数的核心步骤。掌握这项技能对于构建动态系统的概率模型至关重要，使我们能够从确定性预测转向概率性预测 。",
            "id": "3357568",
            "problem": "给定一个生物状态向量 $x(t) \\in \\mathbb{R}^d$ 的连续时间确定性常微分方程 (ODE) 模型，该模型由 $x'(t) = f(x(t), \\theta)$ 控制，其中 $f$ 是漂移函数，$\\theta$ 是一个参数向量。为了量化动力学不确定性，考虑伊藤随机微分方程 (SDE) $dx(t) = f(x(t), \\theta)\\,dt + \\Sigma^{1/2}\\,dW_t$，其中 $W_t$ 是一个标准的 $d$ 维维纳过程，$\\Sigma \\in \\mathbb{R}^{d \\times d}$ 是一个常数、对称、半正定的扩散矩阵。在已知时间 $t_k$ 进行测量，其中 $t_{k+1} - t_k = \\Delta t_k > 0$，状态值 $x_k = x(t_k)$ 被视为无测量噪声的直接观测状态。您的任务是构建由欧拉-丸山格式所隐含的离散时间转移密度，并用它为提供的测试用例计算给定 $x_k$ 时 $x_{k+1}$ 的条件对数密度。\n\n从伊藤 SDE 和维纳过程的标准定义开始，以及在 $f$ 的全局李普希茨连续性和线性增长条件下的存在性和唯一性条件。在步长为 $\\Delta t_k$ 的欧拉-丸山近似下，区间 $[t_k,t_{k+1}]$ 上的增量被近似为一个高斯随机变量。推导由欧拉-丸山所隐含的条件转移密度 $p(x_{k+1}\\,|\\,x_k,\\theta,\\Sigma,\\Delta t_k)$ 的形式，并用 $x_k$、$f(x_k,\\theta)$、$\\Delta t_k$ 和 $\\Sigma$ 显式表示它。然后实现一个程序，为以下每个测试用例计算转移密度的自然对数。此外，在您的书面论证中，列出所有为使此构建有效所需的随机性假设。\n\n您编写的程序必须实现以下两种确定性漂移模型，它们是计算系统生物学中常见的抽象：\n\n- 状态为 $x \\in \\mathbb{R}$ 的一维逻辑斯谛增长模型：\n  - $f(x,\\theta) = r\\,x\\,(1 - x/K)$，\n  - 参数 $\\theta = (r, K)$，其中 $r > 0$ 且 $K > 0$。\n\n- 针对信使核糖核酸 (mRNA) $m$ 和蛋白质 $p$ 的二维基因调控模型，状态为 $x = (m,p) \\in \\mathbb{R}^2$：\n  - $f_m(x,\\theta) = \\dfrac{\\alpha}{1 + (p/K)^n} - \\delta_m\\, m$，\n  - $f_p(x,\\theta) = \\beta\\, m - \\delta_p\\, p$，\n  - 参数 $\\theta = (\\alpha, K, n, \\delta_m, \\beta, \\delta_p)$，其中 $\\alpha > 0$，$K > 0$，$n \\ge 1$，$\\delta_m > 0$，$\\beta > 0$ 且 $\\delta_p > 0$。\n\n对于每个测试用例，您将获得：\n- 模型类型，\n- 参数向量 $\\theta$，\n- 扩散矩阵 $\\Sigma$（对于一维模型是标量，对于二维模型是对角矩阵），\n- 步长 $\\Delta t_k$，\n- 在时间 $t_k$ 的状态 $x_k$，\n- 以及在时间 $t_{k+1}$ 的后续状态 $x_{k+1}$。\n\n为每个测试用例计算欧拉-丸山转移密度 $p(x_{k+1}\\,|\\,x_k,\\theta,\\Sigma,\\Delta t_k)$ 的自然对数并输出结果。自然对数是无量纲的，必须以无单位的实数形式报告。\n\n测试套件：\n- 案例 1（一维逻辑斯谛增长，一般情况）：$\\theta = (r, K) = (0.5, 100.0)$; $\\Sigma = [0.04]$; $\\Delta t_k = 0.1$; $x_k = [50.0]$; $x_{k+1} = [52.0]$。\n- 案例 2（一维逻辑斯谛增长，极小步长边界）：$\\theta = (r, K) = (0.5, 100.0)$; $\\Sigma = [0.01]$; $\\Delta t_k = 10^{-6}$; $x_k = [50.0]$; $x_{k+1} = [50.00001]$。\n- 案例 3（二维基因调控，中等噪声）：$\\theta = (\\alpha, K, n, \\delta_m, \\beta, \\delta_p) = (10.0, 50.0, 2.0, 1.0, 5.0, 0.2)$; $\\Sigma = \\text{diag}([1.0, 4.0])$; $\\Delta t_k = 0.5$; $x_k = [5.0, 40.0]$; $x_{k+1} = [5.8, 49.0]$。\n- 案例 4（二维基因调控，高度各向异性噪声）：$\\theta = (\\alpha, K, n, \\delta_m, \\beta, \\delta_p) = (10.0, 50.0, 2.0, 1.0, 5.0, 0.2)$; $\\Sigma = \\text{diag}([0.01, 9.0])$; $\\Delta t_k = 0.2$; $x_k = [2.0, 10.0]$; $x_{k+1} = [3.4, 11.7]$。\n\n程序要求：\n- 实现推导过程以获得欧拉-丸山高斯转移密度，并为每个案例计算其自然对数。\n- 使用双精度浮点数运算。\n- 输出一行，其中包含一个 Python 风格的列表，内含四个对数密度值，每个值四舍五入到小数点后六位。\n- 最终输出格式必须是 $[v_1,v_2,v_3,v_4]$ 形式的单行，其中每个 $v_i$ 是一个定点格式的浮点数，小数点后有六位数字，无单位。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[v_1,v_2,v_3,v_4]$）。输出要求为浮点数，小数点后精确到六位，按上面列出的顺序对应四个测试用例。",
            "solution": "该问题要求在伊藤随机微分方程（SDE）的欧拉-丸山离散化下，推导并实现状态转移的条件对数密度。该问题具有科学依据、问题明确，并且所有必要数据均已提供。我们着手解决。\n\n### 1. 基本原理和随机性假设\n\n此问题的基础是伊藤 SDE，这是一种标准的数学工具，用于为随时间连续演化且受随机波动影响的系统建模。该 SDE 如下所示：\n$$\ndx(t) = f(x(t), \\theta)\\,dt + \\Sigma^{1/2}\\,dW_t\n$$\n其中 $x(t) \\in \\mathbb{R}^d$ 是状态向量，$f(x, \\theta)$ 是确定性漂移项，$\\Sigma$ 是常数扩散矩阵，$W_t$ 是一个 $d$ 维标准维纳过程。转移密度的构建依赖于几个关键原理和假设：\n\n1.  **存在性和唯一性**：为使 SDE 具有唯一的、非爆炸的解，漂移函数 $f$ 和扩散系数（此处为常数 $\\Sigma^{1/2}$）必须满足某些正则性条件。问题陈述中提到了标准的充分条件：$f$ 的全局李普希茨连续性和线性增长界。\n2.  **马尔可夫性**：过程 $x(t)$ 是一个马尔可夫过程。这意味着系统从状态 $x_k = x(t_k)$ 的未来演化仅取决于 $x_k$，而不取决于该过程之前的历史 $\\{x(t) | t  t_k\\}$。这是由此类 SDE 描述的系统的基本属性。\n3.  **高斯维纳过程增量**：标准维纳过程 $W_t$ 的定义性特征是，其在不重叠时间区间上的增量是独立且服从正态分布的。具体来说，对于任何 $t_{k+1} > t_k$，增量 $\\Delta W_k = W_{t_{k+1}} - W_{t_k}$ 是一个高斯随机向量，其均值为 $\\mathbb{E}[\\Delta W_k] = 0$，协方差矩阵为 $\\mathrm{Cov}(\\Delta W_k) = (t_{k+1} - t_k)I_d$，其中 $I_d$ 是 $d \\times d$ 的单位矩阵。我们将时间步长表示为 $\\Delta t_k = t_{k+1} - t_k$。因此，$\\Delta W_k \\sim \\mathcal{N}(0, \\Delta t_k I_d)$。\n4.  **时间齐次性**：漂移函数 $f(x, \\theta)$ 和扩散矩阵 $\\Sigma$ 假定为不随时间变化的。这意味着系统的动力学是平稳的。\n5.  **扩散矩阵的可逆性**：为了在 $\\mathbb{R}^d$上定义概率密度函数，所得分布的协方差矩阵必须是非奇异的。这要求扩散矩阵 $\\Sigma$ 是严格正定的，而不仅仅是半正定的。所提供的测试用例使用了正定矩阵。\n\n### 2. 欧拉-丸山转移密度的推导\n\n欧拉-丸山方法为 SDE 的解提供了一阶数值近似。将 SDE 从 $t_k$ 积分到 $t_{k+1}$ 得：\n$$\nx(t_{k+1}) = x(t_k) + \\int_{t_k}^{t_{k+1}} f(x(s), \\theta) \\,ds + \\int_{t_k}^{t_{k+1}} \\Sigma^{1/2} \\,dW_s\n$$\n欧拉-丸山格式的核心近似是假设漂移和扩散系数在小时间区间 $[t_k, t_{k+1}]$ 内是常数，取其在区间起点 $t_k$ 处的值。这得到：\n$$\nx_{k+1} \\approx x_k + f(x_k, \\theta) \\int_{t_k}^{t_{k+1}} ds + \\Sigma^{1/2} \\int_{t_k}^{t_{k+1}} dW_s\n$$\n这简化为离散更新规则：\n$$\nx_{k+1} \\approx x_k + f(x_k, \\theta) \\Delta t_k + \\Sigma^{1/2} \\Delta W_k\n$$\n其中 $x_k = x(t_k)$ 且 $\\Delta W_k = W_{t_{k+1}} - W_{t_k}$。\n\n该近似将下一状态 $x_{k+1}$ 建模为一个随机变量，其分布以当前状态 $x_k$ 为条件。由于给定 $t_k$ 时刻的状态，$x_k$、$f(x_k, \\theta)$、$\\Delta t_k$ 和 $\\Sigma$ 都是确定性的，因此 $x_{k+1}$ 的随机性完全来自维纳增量 $\\Delta W_k$。如前所述，$\\Delta W_k$ 是一个高斯随机向量。高斯随机向量的线性变换仍然是高斯分布的。因此，以 $x_k$ 为条件的 $x_{k+1}$ 是一个高斯随机向量。\n\n我们现在确定其均值和协方差。\n\n**均值：**\n$$\n\\mathbb{E}[x_{k+1} | x_k] = \\mathbb{E}[x_k + f(x_k, \\theta)\\Delta t_k + \\Sigma^{1/2}\\Delta W_k | x_k]\n$$\n利用期望的线性性质以及 $\\mathbb{E}[\\Delta W_k] = 0$：\n$$\n\\mu = \\mathbb{E}[x_{k+1} | x_k] = x_k + f(x_k, \\theta)\\Delta t_k\n$$\n\n**协方差矩阵：**\n$$\n\\mathrm{Cov}(x_{k+1} | x_k) = \\mathrm{Cov}(x_k + f(x_k, \\theta)\\Delta t_k + \\Sigma^{1/2}\\Delta W_k | x_k)\n$$\n由于 $x_k$ 和 $f(x_k, \\theta)\\Delta t_k$ 相对于条件是常数，它们对协方差没有贡献。\n$$\n\\mathbf{C} = \\mathrm{Cov}(x_{k+1} | x_k) = \\mathrm{Cov}(\\Sigma^{1/2}\\Delta W_k) = \\Sigma^{1/2} \\mathrm{Cov}(\\Delta W_k) (\\Sigma^{1/2})^T\n$$\n给定 $\\mathrm{Cov}(\\Delta W_k) = \\Delta t_k I_d$ 且 $\\Sigma$ 是对称的（因此 $(\\Sigma^{1/2})^T = \\Sigma^{1/2}$）：\n$$\n\\mathbf{C} = \\Sigma^{1/2} (\\Delta t_k I_d) \\Sigma^{1/2} = \\Delta t_k \\Sigma^{1/2}\\Sigma^{1/2} = \\Delta t_k \\Sigma\n$$\n\n因此，条件转移密度 $p(x_{k+1} | x_k, \\theta, \\Sigma, \\Delta t_k)$ 是多元正态分布的概率密度函数 (PDF)：\n$$\nx_{k+1} | x_k \\sim \\mathcal{N}\\left(\\mu, \\mathbf{C}\\right) \\quad \\text{其中} \\quad \\mu = x_k + f(x_k, \\theta)\\Delta t_k \\quad \\text{且} \\quad \\mathbf{C} = \\Delta t_k \\Sigma\n$$\n\n### 3. 对数密度公式\n\n一个 $d$ 维正态分布 $\\mathcal{N}(\\mu, \\mathbf{C})$ 的概率密度函数 (PDF) 是：\n$$\np(y) = \\frac{1}{\\sqrt{(2\\pi)^d \\det(\\mathbf{C})}} \\exp\\left(-\\frac{1}{2} (y-\\mu)^T \\mathbf{C}^{-1} (y-\\mu)\\right)\n$$\n该密度的自然对数，即对数密度，是：\n$$\n\\ln p(y) = -\\frac{1}{2} \\ln\\left((2\\pi)^d \\det(\\mathbf{C})\\right) - \\frac{1}{2} (y-\\mu)^T \\mathbf{C}^{-1} (y-\\mu)\n$$\n展开对数项：\n$$\n\\ln p(y) = -\\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(\\mathbf{C})) - \\frac{1}{2} (y-\\mu)^T \\mathbf{C}^{-1} (y-\\mu)\n$$\n代入 $y = x_{k+1}$、$\\mu = x_k + f(x_k, \\theta)\\Delta t_k$ 和 $\\mathbf{C} = \\Delta t_k \\Sigma$：\n$$\n\\ln(\\det(\\mathbf{C})) = \\ln(\\det(\\Delta t_k \\Sigma)) = \\ln((\\Delta t_k)^d \\det(\\Sigma)) = d\\ln(\\Delta t_k) + \\ln(\\det(\\Sigma))\n$$\n$$\n\\mathbf{C}^{-1} = (\\Delta t_k \\Sigma)^{-1} = \\frac{1}{\\Delta t_k} \\Sigma^{-1}\n$$\n将这些代回对数密度表达式，得到需要实现的最终公式：\n$$\n\\ln p(x_{k+1}|\\dots) = -\\frac{d}{2} \\ln(2\\pi) -\\frac{d}{2}\\ln(\\Delta t_k) - \\frac{1}{2}\\ln(\\det(\\Sigma)) - \\frac{1}{2\\Delta t_k} (x_{k+1} - \\mu)^T \\Sigma^{-1} (x_{k+1} - \\mu)\n$$\n此公式将应用于每个测试用例。对于一维模型，$d=1$，矩阵变为标量。对于二维模型，$d=2$，并使用标准矩阵运算。在所提供的测试用例中，$\\Sigma$ 是对角矩阵，这简化了行列式和逆的计算，但通用实现更为稳健。\n具体来说，对于对角矩阵 $\\Sigma = \\mathrm{diag}(\\sigma_1^2, \\dots, \\sigma_d^2)$，我们有 $\\det(\\Sigma) = \\prod_i \\sigma_i^2$ 和 $\\Sigma^{-1} = \\mathrm{diag}(1/\\sigma_1^2, \\dots, 1/\\sigma_d^2)$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating the conditional log-density for four test cases\n    based on the Euler-Maruyama approximation of SDEs.\n    \"\"\"\n\n    def f_logistic(x, theta):\n        \"\"\"Drift function for the one-dimensional logistic growth model.\"\"\"\n        r, K = theta\n        return r * x[0] * (1 - x[0] / K)\n\n    def f_gene_reg(x, theta):\n        \"\"\"Drift function for the two-dimensional gene regulation model.\"\"\"\n        alpha, K, n, delta_m, beta, delta_p = theta\n        m, p = x\n        f_m = alpha / (1 + (p / K)**n) - delta_m * m\n        f_p = beta * m - delta_p * p\n        return np.array([f_m, f_p])\n\n    def compute_log_density(d, x_k, x_k1, delta_t, f_val, Sigma):\n        \"\"\"\n        Computes the natural logarithm of the Euler-Maruyama transition density.\n\n        Args:\n            d (int): Dimension of the state space.\n            x_k (np.ndarray): State at time t_k.\n            x_k1 (np.ndarray): State at time t_k+1.\n            delta_t (float): Time step size.\n            f_val (np.ndarray): Drift function evaluated at x_k.\n            Sigma (np.ndarray): Diffusion matrix.\n\n        Returns:\n            float: The conditional log-density ln(p(x_{k+1}|x_k)).\n        \"\"\"\n        # Calculate the mean of the transition density\n        mu = x_k + f_val * delta_t\n        \n        # Deviation of the observed state from the mean\n        deviation = x_k1 - mu\n\n        # Calculate the components of the log-density formula:\n        # ln p = -d/2*ln(2*pi*delta_t) - 1/2*ln(det(Sigma)) - 1/(2*delta_t) * dev^T * Sigma^-1 * dev\n        \n        # Term 1: Normalization constant part\n        log_norm_const = -0.5 * d * (np.log(2 * np.pi) + np.log(delta_t))\n\n        # Term 2: Log-determinant of Sigma part\n        # Use slogdet for numerical stability, which returns (sign, log(abs(det)))\n        # Since Sigma is positive definite, sign is 1.\n        sign, log_det_Sigma = np.linalg.slogdet(Sigma)\n        log_det_term = -0.5 * log_det_Sigma\n        if sign == 0: # Should not happen for positive definite Sigma\n            return -np.inf\n\n        # Term 3: Mahalanobis distance part\n        Sigma_inv = np.linalg.inv(Sigma)\n        mahalanobis_sq = deviation.T @ Sigma_inv @ deviation\n        mahalanobis_term = -0.5 * mahalanobis_sq / delta_t\n\n        return log_norm_const + log_det_term + mahalanobis_term\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"model\": \"logistic\",\n            \"theta\": (0.5, 100.0),\n            \"Sigma\": np.array([[0.04]]),\n            \"delta_t\": 0.1,\n            \"x_k\": np.array([50.0]),\n            \"x_k1\": np.array([52.0]),\n            \"d\": 1,\n            \"drift_func\": f_logistic\n        },\n        {\n            \"model\": \"logistic\",\n            \"theta\": (0.5, 100.0),\n            \"Sigma\": np.array([[0.01]]),\n            \"delta_t\": 1e-6,\n            \"x_k\": np.array([50.0]),\n            \"x_k1\": np.array([50.00001]),\n            \"d\": 1,\n            \"drift_func\": f_logistic\n        },\n        {\n            \"model\": \"gene_reg\",\n            \"theta\": (10.0, 50.0, 2.0, 1.0, 5.0, 0.2),\n            \"Sigma\": np.diag(np.array([1.0, 4.0])),\n            \"delta_t\": 0.5,\n            \"x_k\": np.array([5.0, 40.0]),\n            \"x_k1\": np.array([5.8, 49.0]),\n            \"d\": 2,\n            \"drift_func\": f_gene_reg\n        },\n        {\n            \"model\": \"gene_reg\",\n            \"theta\": (10.0, 50.0, 2.0, 1.0, 5.0, 0.2),\n            \"Sigma\": np.diag(np.array([0.01, 9.0])),\n            \"delta_t\": 0.2,\n            \"x_k\": np.array([2.0, 10.0]),\n            \"x_k1\": np.array([3.4, 11.7]),\n            \"d\": 2,\n            \"drift_func\": f_gene_reg\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Evaluate the drift function f at the current state x_k\n        f_val = case[\"drift_func\"](case[\"x_k\"], case[\"theta\"])\n        \n        # Ensure f_val is a numpy array for consistent calculations\n        if not isinstance(f_val, np.ndarray):\n            f_val = np.array([f_val])\n            \n        # Compute the log-density for the case\n        log_p = compute_log_density(\n            case[\"d\"],\n            case[\"x_k\"],\n            case[\"x_k1\"],\n            case[\"delta_t\"],\n            f_val,\n            case[\"Sigma\"]\n        )\n        results.append(log_p)\n\n    # Format the results to exactly six decimal places\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一旦我们有了概率模型和实验数据，下一个关键问题就是如何量化模型参数的不确定性。本练习将引导您完成一个完整的贝叶斯参数推断任务，应用于一个具有隐藏构象状态的酶变构动力学模型。通过在离散的参数网格上结合先验知识和从数据导出的似然函数，您将计算出参数的后验分布，该分布代表了我们更新后的知识状态。这项实践提供了一个从模型设定到后验统计计算的完整贝叶斯工作流程的坚实示例，具体展示了参数不确定性是如何被形式化推断的 。",
            "id": "3357655",
            "problem": "您的任务是为具有隐藏构象的酶变构动力学模型构建一个贝叶斯不确定性量化程序。该任务的基础包括配体结合的质量作用动力学、构象转换的双态马尔可夫过程动力学，以及在高斯观测模型下进行参数推断的贝叶斯定理。隐藏状态由活性构象的连续变化概率表示，该模型将此隐藏状态与产物形成耦合。三角函数中出现的所有角度必须以弧度处理。所有物理量必须使用指定的明确单位进行处理，并且所有输出必须以适当的单位报告。\n\n模型规范：\n- 令 $L$ 表示恒定的配体浓度（单位：$\\mu\\mathrm{M}$），令 $K_d$ 表示解离常数（单位：$\\mu\\mathrm{M}$）。在快速平衡近似下，配体结合酶的比例为 $p_L = \\dfrac{L}{K_d + L}$。\n- 令 $z(t)$ 表示一个隐藏的双态构象，其中活性状态的占据概率为 $x(t)$，非活性状态的占据概率为 $1 - x(t)$。$x(t)$ 的连续时间马尔可夫过程由以下常微分方程建模：\n$$\n\\frac{dx}{dt} = k_{\\text{on}}\\, p_L \\, (1 - x) - k_{\\text{off}}\\, (1 - p_L) \\, x,\n$$\n其中 $k_{\\text{on}}$ 和 $k_{\\text{off}}$ 是构象转换速率常数（单位：$\\mathrm{s}^{-1}$）。初始条件为 $x(0) = 0$。\n- 定义 $V_{\\max}$（单位：$\\mu\\mathrm{M}/\\mathrm{s}$）为在底物饱和条件下的有效最大产物形成速率，并假设产物浓度 $P(t)$ 遵循\n$$\n\\frac{dP}{dt} = V_{\\max} \\, x(t), \\quad P(0) = 0.\n$$\n- 观测模型：在离散时间 $t_i$，可获得 $P(t)$ 的带噪声的观测值 $y_i$。测量噪声是已知标准差 $\\sigma$（单位：$\\mu\\mathrm{M}$）的高斯噪声，因此 $y_i \\sim \\mathcal{N}(P(t_i), \\sigma^2)$。\n\n恒定 $L$ 下的解析解：\n- 令 $\\alpha = k_{\\text{on}}\\, p_L$ 和 $\\beta = k_{\\text{off}}\\, (1 - p_L)$。则\n$$\nx_{\\mathrm{eq}} = \\frac{\\alpha}{\\alpha + \\beta}, \\quad x(t) = x_{\\mathrm{eq}} + (x(0) - x_{\\mathrm{eq}})\\, e^{-(\\alpha + \\beta)\\, t}.\n$$\n当 $x(0) = 0$ 时，产物浓度为\n$$\nP(t) = V_{\\max} \\left( x_{\\mathrm{eq}}\\, t + \\frac{(x(0) - x_{\\mathrm{eq}})\\, \\left(1 - e^{-(\\alpha + \\beta)\\, t}\\right)}{\\alpha + \\beta} \\right) = V_{\\max} \\left( x_{\\mathrm{eq}}\\, t - \\frac{x_{\\mathrm{eq}} \\left(1 - e^{-(\\alpha + \\beta)\\, t}\\right)}{\\alpha + \\beta} \\right).\n$$\n\n贝叶斯推断目标：\n- 给定观测值 $\\{(t_i, y_i)\\}_{i=1}^n$，推断参数向量 $\\theta = (k_{\\text{on}}, k_{\\text{off}}, K_d)$ 的后验分布，其中每个参数在指定界限内具有对数均匀先验。对于参数 $u \\in [u_{\\min}, u_{\\max}]$，其先验密度在该区间上为 $p(u) \\propto 1/u$，在区间外为零。\n- 根据贝叶斯定理，后验分布与先验和似然的乘积成正比：\n$$\np(\\theta \\mid \\{y_i\\}) \\propto p(\\theta)\\, \\prod_{i=1}^{n} \\exp\\left( -\\frac{(y_i - P(t_i; \\theta))^2}{2 \\sigma^2} \\right),\n$$\n其中 $P(t_i; \\theta)$ 是在给定 $\\theta$ 的情况下，模型在时间 $t_i$ 预测的产物浓度。\n\n计算任务：\n- 对 $k_{\\text{on}}$、$k_{\\text{off}}$ 和 $K_d$ 的每一个，在测试套件提供的界限内使用对数间隔的离散化参数网格。\n- 计算每个网格点上的未归一化后验权重，作为对数均匀先验密度和高斯似然的乘积（您可以省略所有网格点共有的乘法常数）。\n- 归一化权重以获得网格上的离散后验分布，然后为每个参数计算后验均值和后验方差。报告后验标准差（后验方差的平方根）。\n\n测试数据的测量构建：\n- 对于每个测试用例，合成观测值是确定性地生成的：\n$$\ny_i = P(t_i; \\theta_{\\text{true}}) + \\delta(t_i),\n$$\n其中\n$$\n\\delta(t) = \\sigma \\left( 0.3 \\sin(0.7\\, t) + 0.2 \\cos(1.3\\, t) \\right),\n$$\n其中 $t$ 以 $\\mathrm{s}$ 为单位，三角函数参数以弧度为单位。\n\n测试套件和单位：\n- 通用设置：$x(0) = 0$，$P(0) = 0$，$\\sigma = 0.05$ $\\mu\\mathrm{M}$，$V_{\\max} = 1.2$ $\\mu\\mathrm{M}/\\mathrm{s}$，观测时间 $t_i$ 从 $t = 0$ $\\mathrm{s}$ 到 $t = 20$ $\\mathrm{s}$ 均匀间隔，步长为 $0.5$ $\\mathrm{s}$。\n- 所有情况的参数网格界限：$k_{\\text{on}} \\in [0.01, 2.0]$ $\\mathrm{s}^{-1}$，$k_{\\text{off}} \\in [0.01, 2.0]$ $\\mathrm{s}^{-1}$，$K_d \\in [1.0, 200.0]$ $\\mu\\mathrm{M}$。每个参数使用 $21$ 个对数间隔点。\n- 测试用例（每个用例指定 $(k_{\\text{on}}, k_{\\text{off}}, K_d, L)$）：\n    1.  用例 A（一般情景）：$(0.5, 0.2, 5.0, 10.0)$，单位为 $(\\mathrm{s}^{-1}, \\mathrm{s}^{-1}, \\mu\\mathrm{M}, \\mu\\mathrm{M})$。\n    2.  用例 B（慢激活边界）：$(0.05, 0.5, 20.0, 5.0)$，单位为 $(\\mathrm{s}^{-1}, \\mathrm{s}^{-1}, \\mu\\mathrm{M}, \\mu\\mathrm{M})$。\n    3.  用例 C（弱结合边缘）：$(1.0, 0.05, 100.0, 40.0)$，单位为 $(\\mathrm{s}^{-1}, \\mathrm{s}^{-1}, \\mu\\mathrm{M}, \\mu\\mathrm{M})$。\n\n要求的输出：\n- 对于每个测试用例，在指定的基于网格的贝叶斯方案下，计算 $k_{\\text{on}}$（单位：$\\mathrm{s}^{-1}$）、$k_{\\text{off}}$（单位：$\\mathrm{s}^{-1}$）和 $K_d$（单位：$\\mu\\mathrm{M}$）的后验标准差。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表包含三个嵌套列表，每个测试用例一个，每个嵌套列表包含三个浮点数，分别对应于 $k_{\\text{on}}$（单位为 $\\mathrm{s}^{-1}$）、$k_{\\text{off}}$（单位为 $\\mathrm{s}^{-1}$）和 $K_d$（单位为 $\\mu\\mathrm{M}$）的后验标准差，并严格按此顺序排列。例如：$[[s_{1,\\text{on}}, s_{1,\\text{off}}, s_{1,K_d}], [s_{2,\\text{on}}, s_{2,\\text{off}}, s_{2,K_d}], [s_{3,\\text{on}}, s_{3,\\text{off}}, s_{3,K_d}]]$，其中每个 $s$ 是一个浮点数。",
            "solution": "构建过程从质量作用动力学和贝叶斯推断的基本原理出发。首先，我们定义配体结合的快速平衡。在此近似下，结合酶的比例为\n$$\np_L = \\frac{L}{K_d + L},\n$$\n这源于质量作用结合平衡，其中结合比例随配体浓度增加而增加，随解离常数升高而降低。\n\n接下来，我们将构象动力学建模为双态连续时间马尔可夫过程。假设活性构象受配体结合青睐，其转换速率与 $k_{\\text{on}}$ 和 $p_L$ 成正比，而逆向转换的速率与 $k_{\\text{off}}$ 和 $(1 - p_L)$ 成正比。处于活性构象的概率 $x(t)$ 满足线性常微分方程\n$$\n\\frac{dx}{dt} = k_{\\text{on}}\\, p_L\\, (1 - x) - k_{\\text{off}}\\, (1 - p_L)\\, x,\n$$\n该方程是通过平衡进入活性状态的流量和流出活性状态的流量推导出来的。定义 $\\alpha = k_{\\text{on}}\\, p_L$ 和 $\\beta = k_{\\text{off}}\\, (1 - p_L)$ 得\n$$\n\\frac{dx}{dt} = \\alpha - (\\alpha + \\beta)\\, x.\n$$\n这是一个一阶线性非齐次常微分方程，其解为\n$$\nx(t) = x_{\\mathrm{eq}} + (x(0) - x_{\\mathrm{eq}}) e^{-(\\alpha + \\beta)\\, t}, \\quad x_{\\mathrm{eq}} = \\frac{\\alpha}{\\alpha + \\beta}.\n$$\n当 $x(0) = 0$ 时，这简化为\n$$\nx(t) = x_{\\mathrm{eq}} \\left( 1 - e^{-(\\alpha + \\beta)\\, t} \\right).\n$$\n\n假设产物形成与活性状态的占据率成正比，在底物饱和并给出有效速率 $V_{\\max}$ 的假设下：\n$$\n\\frac{dP}{dt} = V_{\\max}\\, x(t), \\quad P(0) = 0.\n$$\n积分得，\n$$\nP(t) = \\int_0^t V_{\\max}\\, x(\\tau)\\, d\\tau = V_{\\max} \\int_0^t \\left[ x_{\\mathrm{eq}} + (x(0) - x_{\\mathrm{eq}}) e^{-(\\alpha + \\beta)\\, \\tau} \\right] d\\tau.\n$$\n代入 $x(0) = 0$ 并计算积分，\n$$\nP(t) = V_{\\max} \\left( x_{\\mathrm{eq}}\\, t - \\frac{x_{\\mathrm{eq}} \\left(1 - e^{-(\\alpha + \\beta)\\, t}\\right)}{\\alpha + \\beta} \\right).\n$$\n\n对于参数推断，我们使用贝叶斯定理。对于在时间 $t_i$ 的观测值 $y_i$ 和已知标准差 $\\sigma$ 的高斯噪声，在独立噪声下的似然为\n$$\n\\mathcal{L}(\\theta) = \\prod_{i=1}^{n} \\exp\\left( -\\frac{(y_i - P(t_i; \\theta))^2}{2 \\sigma^2} \\right),\n$$\n在比例计算中，可以省略诸如 $(2\\pi \\sigma^2)^{-n/2}$ 之类的常数。在指定的界限上为每个参数选择对数均匀先验，表示对数量级的无知：\n$$\np(k_{\\text{on}}) \\propto \\frac{1}{k_{\\text{on}}}, \\quad p(k_{\\text{off}}) \\propto \\frac{1}{k_{\\text{off}}}, \\quad p(K_d) \\propto \\frac{1}{K_d},\n$$\n在它们的界限内，界限外为零。联合先验为 $p(\\theta) \\propto \\frac{1}{k_{\\text{on}}\\, k_{\\text{off}}\\, K_d}$。\n\n因此，后验分布为\n$$\np(\\theta \\mid \\{y_i\\}) \\propto \\left( \\frac{1}{k_{\\text{on}}\\, k_{\\text{off}}\\, K_d} \\right) \\prod_{i=1}^{n} \\exp\\left( -\\frac{(y_i - P(t_i; \\theta))^2}{2 \\sigma^2} \\right).\n$$\n为了计算后验摘要，我们在界限内将 $\\theta$ 离散化到对数间隔的网格上。在每个网格点，我们计算未归一化的后验权重\n$$\nw(\\theta) = \\left( \\frac{1}{k_{\\text{on}}\\, k_{\\text{off}}\\, K_d} \\right) \\exp\\left( -\\sum_{i=1}^{n} \\frac{(y_i - P(t_i; \\theta))^2}{2 \\sigma^2} \\right).\n$$\n为了数值稳定性，我们使用对数权重，\n$$\n\\log w(\\theta) = -\\log k_{\\text{on}} - \\log k_{\\text{off}} - \\log K_d - \\sum_{i=1}^{n} \\frac{(y_i - P(t_i; \\theta))^2}{2 \\sigma^2}.\n$$\n我们减去整个网格上的最大对数权重，然后取指数以获得归一化权重，\n$$\n\\tilde{w}(\\theta) = \\frac{\\exp(\\log w(\\theta) - \\max_{\\theta'} \\log w(\\theta'))}{\\sum_{\\theta''} \\exp(\\log w(\\theta'') - \\max_{\\theta'} \\log w(\\theta'))}.\n$$\n后验期望通过离散求和得出：\n$$\n\\mathbb{E}[k_{\\text{on}}] = \\sum_{\\theta} \\tilde{w}(\\theta)\\, k_{\\text{on}}, \\quad \\mathbb{E}[k_{\\text{on}}^2] = \\sum_{\\theta} \\tilde{w}(\\theta)\\, k_{\\text{on}}^2,\n$$\n后验方差为\n$$\n\\mathrm{Var}[k_{\\text{on}}] = \\mathbb{E}[k_{\\text{on}}^2] - \\left(\\mathbb{E}[k_{\\text{on}}]\\right)^2,\n$$\n对于 $k_{\\text{off}}$ 和 $K_d$ 也有类似的公式。后验标准差是这些方差的平方根。\n\n每个测试用例的合成数据都是确定性生成的。对于真实参数 $\\theta_{\\text{true}}$，使用 $x(0) = 0$ 的解析公式计算 $P(t_i; \\theta_{\\text{true}})$。观测值为\n$$\ny_i = P(t_i; \\theta_{\\text{true}}) + \\delta(t_i), \\quad \\delta(t) = \\sigma \\left( 0.3 \\sin(0.7\\, t) + 0.2 \\cos(1.3\\, t) \\right).\n$$\n这种确定性构造允许对似然进行可重复的评估，同时仍然表示与高斯尺度参数 $\\sigma$ 一致的结构化偏差。\n\n算法步骤：\n1.  对于每个测试用例，设置 $L$、$V_{\\max}$、$\\sigma$，并构建从 $t = 0$ $\\mathrm{s}$ 到 $t = 20$ $\\mathrm{s}$、步长为 $0.5$ $\\mathrm{s}$ 的时间网格 $\\{t_i\\}$。\n2.  使用 $\\theta_{\\text{true}}$ 和确定性偏移量 $\\delta(t_i)$ 计算 $y_i$。\n3.  为 $k_{\\text{on}}$、$k_{\\text{off}}$ 和 $K_d$ 在界限 $[0.01, 2.0]$ $\\mathrm{s}^{-1}$、$[0.01, 2.0]$ $\\mathrm{s}^{-1}$ 和 $[1.0, 200.0]$ $\\mu\\mathrm{M}$ 内分别构建对数间隔的网格，每个参数 21 个点。\n4.  对于每个网格点，计算 $p_L$、$\\alpha$、$\\beta$、$x_{\\mathrm{eq}}$ 和 $P(t_i; \\theta)$；然后计算 $\\log w(\\theta)$。\n5.  使用 log-sum-exp 技巧归一化权重，并为每个参数计算后验期望和方差。\n6.  以要求的单行输出格式报告后验标准差：$[[s_{1,\\text{on}}, s_{1,\\text{off}}, s_{1,K_d}], [s_{2,\\text{on}}, s_{2,\\text{off}}, s_{2,K_d}], [s_{3,\\text{on}}, s_{3,\\text{off}}, s_{3,K_d}]]$，其中每个 $s$ 是一个浮点数，单位分别为 $(\\mathrm{s}^{-1}, \\mathrm{s}^{-1}, \\mu\\mathrm{M})$。\n\n该方法将质量作用动力学和贝叶斯推断的基本原理与基于离散后验近似的计算算法相结合，确保了对动力学模型的科学真实的不确定性量化。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_times(t_start=0.0, t_end=20.0, dt=0.5):\n    # Generate time points from t_start to t_end inclusive.\n    n = int(round((t_end - t_start) / dt)) + 1\n    return np.linspace(t_start, t_end, n)\n\ndef x_eq_alpha_beta(kon, koff, Kd, L):\n    # Compute p_L, alpha, beta, and x_eq for constant L\n    pL = L / (Kd + L)\n    alpha = kon * pL\n    beta = koff * (1.0 - pL)\n    denom = alpha + beta\n    # Avoid division by zero; denom>0 for positive rates and bounded pL\n    xeq = alpha / denom if denom > 0 else 0.0\n    return pL, alpha, beta, xeq, denom\n\ndef P_t(t, Vmax, xeq, denom):\n    # Analytical P(t) for x(0)=0: P(t) = Vmax*( xeq*t - xeq*(1 - exp(-denom*t))/denom )\n    if denom == 0.0:\n        # If denom == 0, then x(t)=xeq constant; xequation reduces to Vmax*xeq*t\n        return Vmax * xeq * t\n    return Vmax * (xeq * t - xeq * (1.0 - np.exp(-denom * t)) / denom)\n\ndef synthetic_observations(theta_true, L, Vmax, sigma, times):\n    # Generate deterministic observations y_i = P(t_i; theta_true) + delta(t_i)\n    kon_true, koff_true, Kd_true = theta_true\n    pL, alpha, beta, xeq, denom = x_eq_alpha_beta(kon_true, koff_true, Kd_true, L)\n    P = P_t(times, Vmax, xeq, denom)\n    # Deterministic offset delta(t) with angles in radians\n    delta = sigma * (0.3 * np.sin(0.7 * times) + 0.2 * np.cos(1.3 * times))\n    y = P + delta\n    return y\n\ndef log_posterior_weights(y, times, Vmax, sigma, L, kon_grid, koff_grid, Kd_grid):\n    # Compute log-weights over the 3D grid: log w = log prior + log likelihood\n    # Prior: log-uniform => log p(theta) = -log(kon) - log(koff) - log(Kd) (up to constant)\n    # Likelihood: sum over i of -(y_i - P(t_i; theta))^2 / (2 sigma^2)\n    logw_list = []\n    theta_list = []\n    # Precompute constants\n    inv2sigma2 = 1.0 / (2.0 * sigma * sigma)\n    # Loop over grid points\n    for kon in kon_grid:\n        log_prior_kon = -np.log(kon)\n        for koff in koff_grid:\n            log_prior_koff = -np.log(koff)\n            for Kd in Kd_grid:\n                log_prior_Kd = -np.log(Kd)\n                # Model computation\n                pL, alpha, beta, xeq, denom = x_eq_alpha_beta(kon, koff, Kd, L)\n                P = P_t(times, Vmax, xeq, denom)\n                resid = y - P\n                ll = -np.sum((resid * resid) * inv2sigma2)\n                logw = log_prior_kon + log_prior_koff + log_prior_Kd + ll\n                logw_list.append(logw)\n                theta_list.append((kon, koff, Kd))\n    logw_arr = np.array(logw_list)\n    theta_arr = np.array(theta_list)  # shape (N, 3)\n    return logw_arr, theta_arr\n\ndef posterior_stats(logw_arr, theta_arr):\n    # Normalize weights using log-sum-exp trick and compute posterior means and stds\n    max_logw = np.max(logw_arr)\n    w = np.exp(logw_arr - max_logw)\n    w_sum = np.sum(w)\n    if w_sum == 0.0:\n        # Degenerate case: return NaNs\n        return np.array([np.nan, np.nan, np.nan]), np.array([np.nan, np.nan, np.nan])\n    w_norm = w / w_sum\n    # Compute means\n    means = np.sum(theta_arr * w_norm[:, None], axis=0)\n    # Compute second moments\n    second_moments = np.sum((theta_arr ** 2) * w_norm[:, None], axis=0)\n    variances = second_moments - means ** 2\n    variances = np.maximum(variances, 0.0)  # Numerical safety\n    stds = np.sqrt(variances)\n    return means, stds\n\ndef solve():\n    # Define common settings\n    sigma = 0.05  # in uM\n    Vmax = 1.2    # in uM/s\n    times = generate_times(0.0, 20.0, 0.5)  # seconds\n\n    # Define parameter grids (logarithmically spaced)\n    kon_grid = np.logspace(np.log10(0.01), np.log10(2.0), 21)    # s^-1\n    koff_grid = np.logspace(np.log10(0.01), np.log10(2.0), 21)   # s^-1\n    Kd_grid = np.logspace(np.log10(1.0), np.log10(200.0), 21)    # uM\n\n    # Test cases: (kon_true, koff_true, Kd_true, L)\n    test_cases = [\n        (0.5, 0.2, 5.0, 10.0),   # Case A\n        (0.05, 0.5, 20.0, 5.0),  # Case B\n        (1.0, 0.05, 100.0, 40.0) # Case C\n    ]\n\n    results = []\n    for kon_true, koff_true, Kd_true, L in test_cases:\n        theta_true = (kon_true, koff_true, Kd_true)\n        # Generate synthetic observations\n        y = synthetic_observations(theta_true, L, Vmax, sigma, times)\n        # Compute log posterior weights over grid\n        logw_arr, theta_arr = log_posterior_weights(y, times, Vmax, sigma, L, kon_grid, koff_grid, Kd_grid)\n        # Compute posterior statistics\n        means, stds = posterior_stats(logw_arr, theta_arr)\n        # Append posterior standard deviations in required units [kon sd (1/s), koff sd (1/s), Kd sd (uM)]\n        # Round for readability\n        results.append([float(f\"{stds[0]:.6f}\"), float(f\"{stds[1]:.6f}\"), float(f\"{stds[2]:.6f}\")])\n\n    # Final print statement in the exact required format.\n    # Single line with nested lists for the three test cases.\n    print(f\"[{','.join(['['+','.join(map(str, r))+']' for r in results])}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "量化不确定性的最终目标之一是利用这些知识来指导未来的行动，例如设计更具信息量的实验。本练习探讨了D-最优实验设计（D-optimal experimental design），这是一种强大的前瞻性方法，它利用参数敏感性分析来确定哪些测量时间点能够最有效地减小参数的后验不确定性。通过解决这个问题，您将学习如何利用动态模型来主动指导数据收集，确保实验资源能够最有效地用于增进对系统的理解。这构成了建模和实验之间的一个闭环，展示了不确定性量化在实践中的强大应用 。",
            "id": "3357652",
            "problem": "给定一个非线性动力学模型，该模型代表了计算系统生物学中一个简化的昼夜节律振荡器。状态向量是二维的，$x(t) = [x_1(t), x_2(t)]^\\top$，其动力学由一个 Stuart–Landau 振荡器控制：\n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\nx_1 \\\\\nx_2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n(\\mu - \\kappa (x_1^2 + x_2^2)) x_1 - \\omega x_2 \\\\\n(\\mu - \\kappa (x_1^2 + x_2^2)) x_2 + \\omega x_1\n\\end{bmatrix},\n$$\n其中 $\\theta = [\\mu, \\kappa, \\omega]^\\top$ 是参数向量，$\\mu$ 和 $\\kappa$ 是实值振幅/阻尼参数，$\\omega$ 是角频率。初始条件是固定的且与 $\\theta$ 无关：$x(0) = [1.0, 0.0]^\\top$。测量模型是在第一个状态分量上的加性高斯噪声，\n$$\ny(t) = x_1(t) + \\varepsilon(t), \\quad \\varepsilon(t) \\sim \\mathcal{N}(0,\\sigma^2),\n$$\n在不同的采样时间点上噪声是独立的。\n\n不确定性量化在 $\\theta$ 的高斯先验 $\\theta \\sim \\mathcal{N}(\\theta_0, \\Sigma_0)$ 下进行，并使用在 $\\theta_0$ 处评估的灵敏度 $\\partial x_1(t;\\theta)/\\partial \\theta$ 对似然函数在 $\\theta_0$ 周围进行局部（一阶）近似。在此近似下，后验不确定性可以通过灵敏度和测量噪声方差，使用基于曲率的更新来表示。$D$-最优实验设计准则是选择能够最小化 $\\theta$ 的后验熵的采样时间。您必须使用通过测量函数的局部线性化和高斯先验得到的标准曲率近似来实现此准则，并在资源约束下，在一个离散的候选网格上计算采样时间。\n\n基本原理：\n- Bayes 法则以及多元正态分布的性质。\n- 常微分方程的灵敏度分析：对于一个自治系统 $\\dot{x} = f(x,\\theta)$，当初始条件不依赖于 $\\theta$ 时，参数灵敏度矩阵 $S(t) = \\partial x(t;\\theta)/\\partial \\theta$ 满足一个一阶线性非齐次系统 $\\dot{S}(t) = (\\partial f/\\partial x)\\,S(t) + \\partial f/\\partial \\theta$，且 $S(0)=0$。\n- 对于独立的高斯测量噪声，跨采样时间的局部曲率聚合由测量函数相对于参数的导数决定。\n\n您的程序必须：\n1. 对于给定网格上的每个候选采样时间 $t$，通过对增广灵敏度系统进行积分，计算灵敏度向量 $\\partial x_1(t;\\theta_0)/\\partial \\theta$。\n2. 使用这些灵敏度和噪声方差，为每个时间点构建适当的曲率贡献。\n3. 在一个将样本数量限制为 $k$ 的离散资源约束下，并且任意两个选定的采样时间之间存在最小间隔 $\\Delta$，对大小为 $k$ 的所有有效候选时间子集进行穷举搜索，以找到在上述定义的局部高斯近似下，能够最小化 $\\theta$ 的后验熵的子集。\n4. 将所有选定的采样时间以小时为单位表示，并四舍五入到三位小数。\n\n测试套件：\n您必须对以下四种情况分别解决 $D$-最优选择问题。在每种情况下，角频率 $\\omega$ 的单位是弧度/小时，所有时间的单位都是小时。\n- 情况 A (理想情况)：\n  - $\\theta_0 = [0.5, 0.5, 2\\pi/24]^\\top$, $\\Sigma_0 = \\mathrm{diag}([0.3^2, 0.3^2, 0.1^2])$, $\\sigma = 0.1$。\n  - 候选时间：$t \\in \\{0, 3, 6, \\dots, 48\\}$ (含边界)。\n  - 预算：$k = 5$ 个样本。\n  - 最小间隔：$\\Delta = 6.0$ 小时。\n- 情况 B (边界情况：不允许采样)：\n  - $\\theta_0 = [0.5, 0.5, 2\\pi/24]^\\top$, $\\Sigma_0 = \\mathrm{diag}([0.3^2, 0.3^2, 0.1^2])$, $\\sigma = 0.1$。\n  - 候选时间：$t \\in \\{0, 3, 6, \\dots, 48\\}$ (含边界)。\n  - 预算：$k = 0$ 个样本。\n  - 最小间隔：$\\Delta = 6.0$ 小时。\n- 情况 C (边缘情况：高噪声和稀疏采样)：\n  - $\\theta_0 = [0.8, 1.2, 2\\pi/20]^\\top$, $\\Sigma_0 = \\mathrm{diag}([0.5^2, 0.5^2, 0.2^2])$, $\\sigma = 1.5$。\n  - 候选时间：$t \\in \\{0, 2, 4, \\dots, 24\\}$ (含边界)。\n  - 预算：$k = 3$ 个样本。\n  - 最小间隔：$\\Delta = 12.0$ 小时。\n- 情况 D (边缘情况：强信息先验)：\n  - $\\theta_0 = [1.2, 0.7, 2\\pi/26]^\\top$, $\\Sigma_0 = \\mathrm{diag}([0.1^2, 0.1^2, 0.05^2])$, $\\sigma = 0.15$。\n  - 候选时间：$t \\in \\{0, 6, 12, \\dots, 36\\}$ (含边界)。\n  - 预算：$k = 4$ 个样本。\n  - 最小间隔：$\\Delta = 6.0$ 小时。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素都是对应情况（按 A, B, C, D 的顺序）的选定采样时间列表（以小时为单位，四舍五入到三位小数）。例如，一个有效的输出格式是：\n$$\n[\\,[t_{A,1}, t_{A,2}, \\dots, t_{A,5}],\\,[\\,],\\,[t_{C,1}, t_{C,2}, t_{C,3}],\\,[t_{D,1}, t_{D,2}, t_{D,3}, t_{D,4}]\\,].\n$$\n所有数值答案必须是浮点数或浮点数列表；不允许使用百分号。角度以弧度为单位；时间必须以小时表示。",
            "solution": "用户提供的问题是一个适定且有科学依据的贝叶斯最优实验设计练习，这是计算系统生物学中动力学模型不确定性量化的核心课题。该问题是有效的，因为它基于已建立的数学和统计学原理，提供了一个完整且一致的设置。我们将进行完整的求解。\n\n目标是从一个离散的候选网格中选择一组 $k$ 个采样时间 $\\{t_1, t_2, \\dots, t_k\\}$，使其在 $D$-最优性准则的意义下是最优的。该准则旨在最小化参数后验分布的广义方差，这等同于最小化后验协方差矩阵的行列式。\n\n### 1. 贝叶斯框架和后验近似\n\n解决方案的基础是 Bayes 法则，它将给定数据 $y$ 时参数 $\\theta$ 的后验概率与数据的似然和参数的先验概率联系起来：\n$$\np(\\theta | y) \\propto p(y | \\theta) p(\\theta)\n$$\n问题指定了参数向量 $\\theta = [\\mu, \\kappa, \\omega]^\\top$ 的高斯先验：\n$$\n\\theta \\sim \\mathcal{N}(\\theta_0, \\Sigma_0) \\implies p(\\theta) \\propto \\exp\\left(-\\frac{1}{2}(\\theta - \\theta_0)^\\top \\Sigma_0^{-1} (\\theta - \\theta_0)\\right)\n$$\n在一组离散时间点 $\\{t_1, \\dots, t_k\\}$ 上的测量模型由 $y(t_i) = x_1(t_i; \\theta) + \\varepsilon_i$ 给出，其中噪声项 $\\varepsilon_i$ 是独立同分布的，服从 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。完整数据向量 $y = [y(t_1), \\dots, y(t_k)]^\\top$ 的似然函数是：\n$$\np(y|\\theta) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^k (y(t_i) - x_1(t_i; \\theta))^2\\right)\n$$\n由于模型 $x_1(t_i; \\theta)$ 是 $\\theta$ 的一个非线性函数，因此得到的后验分布是非高斯的。问题指定使用围绕先验均值 $\\theta_0$ 的局部近似。我们将模型输出相对于参数进行线性化：\n$$\nx_1(t; \\theta) \\approx x_1(t; \\theta_0) + \\left(\\frac{\\partial x_1(t; \\theta)}{\\partial \\theta}\\bigg|_{\\theta_0}\\right)^\\top (\\theta - \\theta_0)\n$$\n将此近似代入对数后验，会得到一个关于 $\\theta$ 的二次型，这意味着后验分布近似为高斯分布，$p(\\theta|y) \\approx \\mathcal{N}(\\theta_N, \\Sigma_N)$。后验精度矩阵（协方差的逆）$\\Sigma_N^{-1}$ 由先验精度与从测量中获得的信息之和给出：\n$$\n\\Sigma_N^{-1} = \\Sigma_0^{-1} + \\frac{1}{\\sigma^2} \\sum_{i=1}^k s(t_i) s(t_i)^\\top\n$$\n其中 $s(t) = \\frac{\\partial x_1(t; \\theta)}{\\partial \\theta}\\big|_{\\theta_0}$ 是测量值相对于参数的灵敏度 $3 \\times 1$ 向量，在标称参数值 $\\theta_0$ 处计算。每一项 $\\frac{1}{\\sigma^2} s(t_i) s(t_i)^\\top$ 代表了在时间 $t_i$ 的单次测量所贡献的费雪信息 (Fisher information)。\n\n### 2. D-最优性准则\n\n$D$-最优性准则旨在最小化后验不确定性椭球的体积，该体积与 $\\sqrt{\\det(\\Sigma_N)}$ 成正比。这等价于最小化 $\\det(\\Sigma_N)$，或者更方便地，最大化其逆 $\\det(\\Sigma_N^{-1})$。因此，设计问题是选择一组 $k$ 个采样时间，以最大化后验精度矩阵的行列式：\n$$\n\\underset{\\{t_1, \\dots, t_k\\}}{\\text{argmax}} \\quad \\det\\left( \\Sigma_0^{-1} + \\frac{1}{\\sigma^2} \\sum_{i=1}^k s(t_i) s(t_i)^\\top \\right)\n$$\n此选择受限于总样本数 $k$ 和最小时间间隔 $\\Delta$ 的约束。\n\n### 3. 动力学系统的灵敏度分析\n\n为了计算灵敏度向量 $s(t)$，我们必须求解与主常微分方程（ODE）系统相关的灵敏度方程。令状态为 $z(t) = [x_1(t), x_2(t)]^\\top$，动力学为 $\\dot{z} = f(z, \\theta)$。参数灵敏度矩阵 $S(t) = \\frac{\\partial z(t)}{\\partial \\theta}$ 是一个 $2 \\times 3$ 矩阵，其演化遵循以下线性非齐次常微分方程：\n$$\n\\frac{d}{dt}S(t) = J_z(t) S(t) + J_\\theta(t)\n$$\n其中 $J_z = \\frac{\\partial f}{\\partial z}$ 是动力学关于状态的雅可比矩阵（Jacobian），而 $J_\\theta = \\frac{\\partial f}{\\partial \\theta}$ 是关于参数的雅可比矩阵。初始条件为 $S(0) = \\mathbf{0}$，因为初始状态 $z(0)$ 与 $\\theta$ 无关。\n\n雅可比矩阵为：\n$$\nJ_z = \\frac{\\partial f}{\\partial z} = \\begin{bmatrix}\n\\mu - \\kappa(3x_1^2 + x_2^2)  -2\\kappa x_1 x_2 - \\omega \\\\\n-2\\kappa x_1 x_2 + \\omega  \\mu - \\kappa(x_1^2 + 3x_2^2)\n\\end{bmatrix}\n$$\n$$\nJ_\\theta = \\frac{\\partial f}{\\partial \\theta} = \\begin{bmatrix}\nx_1  -(x_1^2+x_2^2)x_1  -x_2 \\\\\nx_2  -(x_1^2+x_2^2)x_2  x_1\n\\end{bmatrix}\n$$\n我们构建一个增广常微分方程（ODE）系统，其状态向量为 $8$ 维：$Y(t) = [x_1, x_2, S_{11}, S_{12}, S_{13}, S_{21}, S_{22}, S_{23}]^\\top$。该系统从 $t=0$ 开始进行数值积分，初始条件为 $Y(0)=[1.0, 0.0, 0, 0, 0, 0, 0, 0]^\\top$。所需的测量灵敏度向量是灵敏度子矩阵的第一行：$s(t) = [S_{11}(t), S_{12}(t), S_{13}(t)]^\\top$。\n\n### 4. 算法流程\n\n针对每个测试用例，通过以下算法实现解决方案：\n1.  **初始化**：定义参数 $\\theta_0$、$\\Sigma_0$、$\\sigma$、候选时间 $T_{\\text{cand}}$、预算 $k$ 和间隔 $\\Delta$。计算先验精度矩阵 $\\Sigma_0^{-1}$。对于 $k=0$ 的特殊情况，最优集为空。\n2.  **灵敏度计算**：使用 `scipy.integrate.solve_ivp` 对 $8$ 维增广常微分方程系统进行数值求解。在 $T_{\\text{cand}}$ 中的所有时间点上评估解，以获得每个点的状态 $z(t)$ 和灵敏度矩阵 $S(t)$。提取所需的灵敏度向量 $s(t) = [S_{11}(t), S_{12}(t), S_{13}(t)]^\\top$。\n3.  **搜索最优时间**：对所有有效的采样时间组合进行穷举搜索。\n    a. 使用 `itertools.combinations`，生成 $T_{\\text{cand}}$ 的所有大小为 $k$ 的子集。\n    b. 对每个子集进行最小间隔约束的检验：对于任意两个选定的时间 $t_i, t_j$（其中 $i \\ne j$），必须满足 $|t_i - t_j| \\ge \\Delta$。\n    c. 对于每个有效的子集 $\\{t_1, \\dots, t_k\\}$，计算后验精度矩阵的行列式 $\\det(\\Sigma_N^{-1})$。\n    d. 选择产生最大行列式值的时序子集，作为 $D$-最优设计。\n4.  **输出格式化**：将选定的时间四舍五入到三位小数，并按要求格式化。\n\n该流程保证在指定的离散搜索空间内，以及在给定的局部线性化近似下，找到全局最优设计。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom itertools import combinations\n\ndef augmented_ode(t, y, mu, kappa, omega):\n    \"\"\"\n    Defines the augmented ODE system for the Stuart-Landau oscillator and its parameter sensitivities.\n    \n    The state vector `y` has 8 components:\n    y = [x1, x2, S11, S12, S13, S21, S22, S23]\n    where Sij = d(xi)/d(theta_j) and theta = [mu, kappa, omega].\n    The sensitivity matrix S is flattened in row-major order.\n    \"\"\"\n    x1, x2 = y[0], y[1]\n    S = y[2:].reshape((2, 3))\n\n    # Original system dynamics (f)\n    r_sq = x1**2 + x2**2\n    d_x1_dt = (mu - kappa * r_sq) * x1 - omega * x2\n    d_x2_dt = (mu - kappa * r_sq) * x2 + omega * x1\n    \n    # Jacobian of f with respect to state x (J_z)\n    Jz = np.zeros((2, 2))\n    Jz[0, 0] = mu - kappa * (3 * x1**2 + x2**2)\n    Jz[0, 1] = -2 * kappa * x1 * x2 - omega\n    Jz[1, 0] = -2 * kappa * x1 * x2 + omega\n    Jz[1, 1] = mu - kappa * (x1**2 + 3 * x2**2)\n    \n    # Jacobian of f with respect to parameters theta (J_theta)\n    J_theta = np.zeros((2, 3))\n    J_theta[0, 0] = x1          # df1/dmu\n    J_theta[1, 0] = x2          # df2/dmu\n    J_theta[0, 1] = -r_sq * x1  # df1/dkappa\n    J_theta[1, 1] = -r_sq * x2  # df2/dkappa\n    J_theta[0, 2] = -x2         # df1/domega\n    J_theta[1, 2] = x1          # df2/domega\n\n    # Sensitivity dynamics: dS/dt = J_z * S + J_theta\n    dS_dt = Jz @ S + J_theta\n    \n    # Combine derivatives into a single flat vector\n    derivatives = np.concatenate(([d_x1_dt, d_x2_dt], dS_dt.flatten()))\n    \n    return derivatives\n\ndef find_optimal_times(params):\n    \"\"\"\n    Finds the D-optimal sampling times for a given experimental setup.\n    \"\"\"\n    theta0, Sigma0, sigma, t_candidates, k, delta_t = params\n    \n    if k == 0:\n        return []\n\n    mu0, kappa0, omega0 = theta0\n    \n    # 1. Compute prior precision matrix\n    Sigma0_inv = np.diag(1 / np.diag(Sigma0))\n\n    # 2. Integrate ODE system to get sensitivities at all candidate times\n    y0 = np.array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # x(0)=[1,0], S(0)=0\n    t_span = [0, max(t_candidates)] if t_candidates else [0, 0]\n    \n    sol = solve_ivp(\n        fun=augmented_ode,\n        t_span=t_span,\n        y0=y0,\n        t_eval=t_candidates,\n        args=(mu0, kappa0, omega0),\n        method='LSODA', \n        rtol=1e-6, \n        atol=1e-8\n    )\n\n    if not sol.success:\n        raise RuntimeError(f\"ODE integration failed for case with theta0={theta0}\")\n\n    # 3. Pre-compute curvature contributions for each candidate time\n    curvature_contributions = {}\n    for i, t in enumerate(sol.t):\n        # Sensitivity of measurement y=x1 w.r.t. theta: s(t) = [S11, S12, S13]\n        s_t = sol.y[2:5, i]\n        C_t = (1 / sigma**2) * np.outer(s_t, s_t)\n        curvature_contributions[t] = C_t\n\n    # 4. Exhaustive search for the optimal combination of times\n    best_determinant = -1.0\n    best_times = []\n    \n    candidate_indices = list(range(len(t_candidates)))\n\n    for index_combo in combinations(candidate_indices, k):\n        time_combo = [t_candidates[i] for i in index_combo]\n        \n        # Check separation constraint. Assumes time_combo is sorted, which it is.\n        is_valid = all(time_combo[i] - time_combo[i-1] >= delta_t for i in range(1, len(time_combo)))\n        \n        if not is_valid:\n            continue\n            \n        # Calculate posterior precision for this combination\n        posterior_precision = Sigma0_inv.copy()\n        for t in time_combo:\n            posterior_precision += curvature_contributions[t]\n            \n        # Calculate determinant (our objective function)\n        det = np.linalg.det(posterior_precision)\n        \n        if det > best_determinant:\n            best_determinant = det\n            best_times = time_combo\n\n    return [round(t, 3) for t in best_times]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        (\n            [0.5, 0.5, 2 * np.pi / 24],\n            np.diag([0.3**2, 0.3**2, 0.1**2]),\n            0.1,\n            np.arange(0, 48 + 3, 3).tolist(),\n            5,\n            6.0\n        ),\n        # Case B\n        (\n            [0.5, 0.5, 2 * np.pi / 24],\n            np.diag([0.3**2, 0.3**2, 0.1**2]),\n            0.1,\n            np.arange(0, 48 + 3, 3).tolist(),\n            0,\n            6.0\n        ),\n        # Case C\n        (\n            [0.8, 1.2, 2 * np.pi / 20],\n            np.diag([0.5**2, 0.5**2, 0.2**2]),\n            1.5,\n            np.arange(0, 24 + 2, 2).tolist(),\n            3,\n            12.0\n        ),\n        # Case D\n        (\n            [1.2, 0.7, 2 * np.pi / 26],\n            np.diag([0.1**2, 0.1**2, 0.05**2]),\n            0.15,\n            np.arange(0, 36 + 6, 6).tolist(),\n            4,\n            6.0\n        ),\n    ]\n\n    results = []\n    for case in test_cases:\n        optimal_times = find_optimal_times(case)\n        results.append(optimal_times)\n\n    # Final print statement in the exact required format.\n    # The default str() for a list includes spaces, which is acceptable.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}