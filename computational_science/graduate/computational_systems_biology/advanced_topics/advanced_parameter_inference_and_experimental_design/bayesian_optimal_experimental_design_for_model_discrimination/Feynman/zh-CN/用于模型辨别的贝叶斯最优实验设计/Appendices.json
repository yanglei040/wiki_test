{
    "hands_on_practices": [
        {
            "introduction": "要掌握用于模型判别的贝叶斯优化实验设计（OED），第一步是理解其核心效用函数——期望信息增益，即互信息。这个练习将带你从基本原理出发，通过计算来最大化模型与实验数据之间的互信息，从而设计出最优实验。你将通过选择最佳的光暗周期，来区分两个关于生物钟节律的竞争模型，一个是包含转录反馈抑制的模型，另一个则不包含。这个实践的核心在于应用数值积分（高斯-埃尔米特求积法）直接计算互信息，这为你后续更复杂的OED问题打下坚实的基础。",
            "id": "3290038",
            "problem": "考虑一个细胞群中昼夜节律生物发光报告基因的两个竞争性机理模型：一个没有转录反馈抑制的模型和一个有转录反馈抑制的模型。设二元模型指示器为 $M \\in \\{0,1\\}$，其中 $M=0$ 表示无抑制模型，$M=1$ 表示有抑制模型。一个光暗（LD）周期由一个设计向量 $d=(T,\\delta)$ 指定，其中 $T$ 是以小时为单位的LD周期，$\\delta \\in [0,1]$ 是占空比（光照开启时间占周期的比例，以小数表示）。实验产生一个平均生物发光读数 $Y$，该读数是在固定的LD周期 $d$ 下进行的 $n$ 次重复测量的样本均值，其中每次重复都是对底层确定性平均响应的一次带噪声的观测。\n\n假设模型的先验分布为 $p(M)$，其中 $p(M=0)=p_0$ 且 $p(M=1)=1-p_0$。假设一个与中心极限定理一致的高斯噪声模型用于样本均值：在给定 $M$ 和 $d$ 的条件下，读数 $Y$ 服从高斯分布，其均值为 $\\mu_M(T,\\delta)$，方差为 $\\sigma^2/n$，即 $Y \\mid M,d \\sim \\mathcal{N}(\\mu_M(T,\\delta), \\sigma^2/n)$，其中 $\\sigma^2$ 是重复测量层级的方差。这两个模型的平均响应编码了对昼夜节律共振的同步以及对光的不同敏感性：\n- 共振因子为 $R(T) = \\exp\\left(-\\frac{1}{2}\\left(\\frac{T-\\tau_0}{\\sigma_T}\\right)^2\\right)$，其中 $\\tau_0$ 是内在周期（以小时为单位），$\\sigma_T$ 是一个尺度参数（以小时为单位），表示同步共振的宽度。\n- 对于 $M=0$（无抑制），均值为 $\\mu_0(T,\\delta) = A_0 \\, R(T) \\, \\delta$，其中 $A_0$ 是一个敏感性参数（单位任意）。\n- 对于 $M=1$（有抑制），均值为 $\\mu_1(T,\\delta) = A_1 \\, R(T) \\, \\frac{\\delta}{1 + k \\delta}$，其中 $A_1$ 是一个敏感性参数（单位任意），$k0$ 控制抑制强度（无量纲）。\n\n设实验设计的目标为预期信息增益（Expected Information Gain），在贝叶斯最优实验设计中，这即为模型指示器 $M$ 和观测读数 $Y$ 在给定 $d$ 下的互信息（MI），记作 $U(d)=I(M;Y \\mid d)$。该量由核心的香non互信息恒等式定义：\n$$\nI(M;Y \\mid d) = \\mathbb{E}_{p(m,y \\mid d)}\\left[\\log \\frac{p(m \\mid y,d)}{p(m)}\\right],\n$$\n其中 $p(m,y \\mid d) = p(m) \\, p(y \\mid m,d)$，$p(m \\mid y,d)$ 表示在给定观测读数和设计下的模型后验分布。\n\n您的任务是实现一个程序，对于每个提供的参数集，评估一组有限的候选设计 $d=(T,\\delta)$ 的目标函数 $U(d)$，并选出具有最大 $U(d)$ 的设计。程序必须根据互信息的基本定义精确计算 $U(d)$，不使用任何快捷公式，通过对由 $M$ 的先验和条件分布 $p(y \\mid m,d)$ 导出的预测分布 $p(y \\mid d)$ 进行正确的边缘化，并按要求对 $y$ 取期望。程序应使用科学上现实的参数值，采用数值稳定的方法来计算所需的期望，并遵守下文的单位和输出格式规范。\n\n单位和量：\n- LD周期 $T$ 必须以小时表示。\n- 占空比 $\\delta$ 必须以小数形式表示（无百分号）。\n- 互信息 $U(d)$ 必须使用自然对数计算，因此以奈特（nats）为单位。\n- 最终报告的 $T$ 值必须以小时为单位，最终报告的 $U(d)$ 值必须以奈特为单位。\n- 在最终输出中，将 $T$ 和 $\\delta$ 四舍五入到三位小数，将 $U(d)$ 四舍五入到六位小数。\n\n测试套件：\n对于每个测试用例，您将获得 $(p_0, \\tau_0, \\sigma_T, A_0, A_1, k, \\sigma, n)$ 和一个有限的候选集 $\\mathcal{D} = \\{(T_i, \\delta_j)\\}$，该候选集由指定的 $T$ 值列表（以小时为单位）和占空比（以小数形式）构建。对于每个用例，评估所有 $d \\in \\mathcal{D}$ 的 $U(d)$，然后返回具有最大 $U(d)$ 的单个设计以及该最大值 $U(d)$。\n\n- 测试用例1（一般情况，均衡先验）：\n  - 参数：$p_0=0.5$, $\\tau_0=24.0 \\, \\text{hours}$, $\\sigma_T=2.0 \\, \\text{hours}$, $A_0=1.0$, $A_1=1.2$, $k=2.0$, $\\sigma=0.2$, $n=50$。\n  - 候选周期：$T \\in \\{20.0, 24.0, 28.0\\}$ 小时。\n  - 候选占空比：$\\delta \\in \\{0.3, 0.5, 0.8\\}$。\n- 测试用例2（边界占空比，弱光条件）：\n  - 参数：$p_0=0.5$, $\\tau_0=24.0 \\, \\text{hours}$, $\\sigma_T=2.0 \\, \\text{hours}$, $A_0=1.0$, $A_1=1.2$, $k=2.0$, $\\sigma=0.2$, $n=50$。\n  - 候选周期：$T \\in \\{22.0, 24.0, 26.0\\}$ 小时。\n  - 候选占空比：$\\delta \\in \\{0.01, 0.05, 0.1\\}$。\n- 测试用例3（几乎无法区分的模型）：\n  - 参数：$p_0=0.5$, $\\tau_0=24.0 \\, \\text{hours}$, $\\sigma_T=2.0 \\, \\text{hours}$, $A_0=1.0$, $A_1=1.0$, $k=0.0$, $\\sigma=0.2$, $n=50$。\n  - 候选周期：$T \\in \\{20.0, 24.0, 28.0\\}$ 小时。\n  - 候选占空比：$\\delta \\in \\{0.3, 0.5, 0.8\\}$。\n\n最终输出规范：\n- 对于每个测试用例，返回三元组 $[T^\\star, \\delta^\\star, U^\\star]$，其中 $(T^\\star, \\delta^\\star)$ 是在候选集中最大化 $U(d)$ 的设计（单位如上所述），$U^\\star = \\max_{d \\in \\mathcal{D}} U(d)$（以奈特为单位）。\n- 您的程序应生成一行输出，其中包含三个结果，格式完全如下：一个由方括号括起来的逗号分隔列表，其中每个元素本身就是一个列表 $[T^\\star,\\delta^\\star,U^\\star]$，并应用了舍入规则，例如：$\\big[ [T^\\star_1,\\delta^\\star_1,U^\\star_1],[T^\\star_2,\\delta^\\star_2,U^\\star_2],[T^\\star_3,\\delta^\\star_3,U^\\star_3] \\big]$。",
            "solution": "本问题要求从一个有限的候选集 $\\mathcal{D}$ 中识别一个最优实验设计 $d^{\\star}=(T^{\\star},\\delta^{\\star})$。最优性准则是最大化预期信息增益，这等价于在给定设计 $d=(T,\\delta)$ 的情况下，模型指示器 $M$ 与实验读数 $Y$ 之间的香non互信息 $U(d) = I(M;Y \\mid d)$。\n\n互信息的基本定义由期望给出：\n$$\nU(d) = I(M;Y \\mid d) = \\mathbb{E}_{p(m,y \\mid d)}\\left[\\log \\frac{p(m \\mid y,d)}{p(m)}\\right]\n$$\n该期望是对模型指示器 $M$ 和数据 $Y$ 的联合分布 $p(m,y \\mid d) = p(m) p(y \\mid m, d)$ 求得的。我们可以将期望展开为对离散模型变量 $M \\in \\{0,1\\}$ 的求和以及对连续数据变量 $Y$ 的积分：\n$$\nU(d) = \\sum_{m \\in \\{0,1\\}} \\int_{-\\infty}^{\\infty} p(m) p(y \\mid m, d) \\log \\frac{p(m \\mid y,d)}{p(m)} \\, dy\n$$\n使用后验概率的定义 $p(m \\mid y,d) = \\frac{p(y \\mid m,d) p(m)}{p(y \\mid d)}$，其中 $p(y \\mid d) = \\sum_{m'} p(m') p(y \\mid m', d)$ 是数据的边缘预测分布，我们可以重写对数内的项：\n$$\n\\frac{p(m \\mid y,d)}{p(m)} = \\frac{p(y \\mid m,d) p(m)}{p(y \\mid d) p(m)} = \\frac{p(y \\mid m,d)}{p(y \\mid d)}\n$$\n将此代入 $U(d)$ 的表达式中，得到：\n$$\nU(d) = \\sum_{m \\in \\{0,1\\}} p(m) \\int_{-\\infty}^{\\infty} p(y \\mid m, d) \\log \\frac{p(y \\mid m,d)}{p(y \\mid d)} \\, dy\n$$\n这种形式揭示了互信息是边缘预测分布 $p(y \\mid d)$ 到模型条件分布 $p(y \\mid m, d)$ 的预期库尔贝克-莱布勒散度，并在模型先验概率上取平均。\n\n此问题的具体组成部分是：\n1.  **模型先验概率**：$p(M=0) = p_0$ 和 $p(M=1) = 1-p_0$。\n2.  **条件数据分布（似然）**：读数 $Y$ 是 $n$ 次重复测量的样本均值。根据中心极限定理，其分布近似为高斯分布。问题中将其指定为精确的：$Y \\mid M=m, d \\sim \\mathcal{N}(y; \\mu_m(d), \\sigma^2/n)$。让我们将有效方差表示为 $\\sigma_{\\text{eff}}^2 = \\sigma^2/n$。平均响应为：\n    $$\n    \\mu_0(d) = \\mu_0(T,\\delta) = A_0 \\, R(T) \\, \\delta\n    $$\n    $$\n    \\mu_1(d) = \\mu_1(T,\\delta) = A_1 \\, R(T) \\, \\frac{\\delta}{1 + k \\delta}\n    $$\n    其中共振因子为 $R(T) = \\exp\\left(-\\frac{1}{2}\\left(\\frac{T-\\tau_0}{\\sigma_T}\\right)^2\\right)$。\n3.  **边缘预测分布**：这是一个高斯混合模型（GMM）：\n    $$\n    p(y \\mid d) = p_0 \\cdot \\mathcal{N}(y; \\mu_0(d), \\sigma_{\\text{eff}}^2) + (1-p_0) \\cdot \\mathcal{N}(y; \\mu_1(d), \\sigma_{\\text{eff}}^2)\n    $$\n\n目标函数可以写成两项之和：\n$U(d) = p_0 \\cdot \\text{Term}_0 + (1-p_0) \\cdot \\text{Term}_1$，其中\n$$\n\\text{Term}_0 = \\int_{-\\infty}^{\\infty} \\mathcal{N}(y; \\mu_0, \\sigma_{\\text{eff}}^2) \\log \\frac{\\mathcal{N}(y; \\mu_0, \\sigma_{\\text{eff}}^2)}{p(y \\mid d)} \\, dy = \\mathbb{E}_{Y \\sim \\mathcal{N}(\\mu_0, \\sigma_{\\text{eff}}^2)}\\left[ \\log \\frac{\\mathcal{N}(Y; \\mu_0, \\sigma_{\\text{eff}}^2)}{p(Y \\mid d)} \\right]\n$$\n$$\n\\text{Term}_1 = \\int_{-\\infty}^{\\infty} \\mathcal{N}(y; \\mu_1, \\sigma_{\\text{eff}}^2) \\log \\frac{\\mathcal{N}(y; \\mu_1, \\sigma_{\\text{eff}}^2)}{p(y \\mid d)} \\, dy = \\mathbb{E}_{Y \\sim \\mathcal{N}(\\mu_1, \\sigma_{\\text{eff}}^2)}\\left[ \\log \\frac{\\mathcal{N}(Y; \\mu_1, \\sigma_{\\text{eff}}^2)}{p(Y \\mid d)} \\right]\n$$\n这些积分没有通用的闭式解，必须进行数值计算。一种用于形如 $\\int_{-\\infty}^{\\infty} e^{-x^2}g(x)dx$ 积分的标准且数值稳定的方法是高斯-埃尔米特求积。上述期望的形式为 $\\mathbb{E}_{Z \\sim \\mathcal{N}(0,1)}[f(\\mu + \\sigma Z)]$，可以使用求积法进行评估。我们使用概率论学家的埃尔米特多项式，它们对于权重函数 $e^{-z^2/2}$ 是正交的，这与标准正态分布的核相匹配。期望 $\\mathbb{E}_{Z \\sim \\mathcal{N}(0,1)}[f(Z)] = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} f(z) dz$ 可以近似为 $\\frac{1}{\\sqrt{2\\pi}} \\sum_{i=1}^{N_q} w_i f(z_i)$，其中 $(z_i, w_i)$ 是权重函数 $e^{-z^2/2}$ 的求积点和权重。\n\n让我们定义期望内的被积函数。对于 $\\text{Term}_0$，对数的参数是：\n$$\n\\frac{\\mathcal{N}(y; \\mu_0, \\sigma_{\\text{eff}}^2)}{p_0 \\mathcal{N}(y; \\mu_0, \\sigma_{\\text{eff}}^2) + (1-p_0) \\mathcal{N}(y; \\mu_1, \\sigma_{\\text{eff}}^2)} = \\frac{1}{p_0 + (1-p_0) \\frac{\\mathcal{N}(y; \\mu_1, \\sigma_{\\text{eff}}^2)}{\\mathcal{N}(y; \\mu_0, \\sigma_{\\text{eff}}^2)}}\n$$\n高斯概率密度函数的比值可以简化为：\n$$\n\\frac{\\mathcal{N}(y; \\mu_1, \\sigma_{\\text{eff}}^2)}{\\mathcal{N}(y; \\mu_0, \\sigma_{\\text{eff}}^2)} = \\exp\\left( \\frac{(\\mu_1-\\mu_0)(y - (\\mu_0+\\mu_1)/2)}{\\sigma_{\\text{eff}}^2} \\right)\n$$\n这种表述方式通过避免计算单个PDF值时可能出现的下溢或上溢，显著提高了数值稳定性。然后，使用求积法对包含此指数项的函数进行计算，从而得到期望值。\n\n一个重要的特殊情况是当模型在参数上不可区分时。在测试用例3中，参数 $A_1=1.0$ 和 $k=0.0$ 导致模型 $M=1$ 的平均响应与模型 $M=0$ 的完全相同：\n$$\n\\mu_1(d) = A_1 R(T) \\frac{\\delta}{1+k\\delta} = 1.0 \\cdot R(T) \\frac{\\delta}{1+0 \\cdot \\delta} = R(T) \\delta = A_0 R(T) \\delta = \\mu_0(d)\n$$\n当 $\\mu_0(d) = \\mu_1(d)$ 时，条件分布 $p(y \\mid M=0,d)$ 和 $p(y \\mid M=1,d)$ 完全相同。因此，边缘分布 $p(y \\mid d)$ 也是同一个分布。比率 $\\frac{p(y \\mid m,d)}{p(y \\mid d)}$ 变为 $1$，其对数为 $0$，因此互信息 $U(d)$ 必然为 $0$。任何实验都无法区分两个相同的模型，所以预期信息增益为零。\n\n总体算法如下：\n1. 对于每个测试用例，定义模型参数和候选设计集 $\\mathcal{D}$。\n2. 初始化变量以存储最优设计 $(T^{\\star}, \\delta^{\\star})$ 和最大效用 $U^{\\star}=-\\infty$。\n3. 对于 $\\mathcal{D}$ 中的每个设计 $d=(T, \\delta)$：\n    a. 计算平均响应 $\\mu_0(d)$ 和 $\\mu_1(d)$。\n    b. 如果 $\\mu_0(d) = \\mu_1(d)$，则 $U(d) = 0$。否则，继续。\n    c. 使用足够高阶的高斯-埃尔米特求积法计算两个期望积分以确保精度。\n    d. 计算 $U(d) = p_0 \\cdot \\text{Term}_0 + (1-p_0) \\cdot \\text{Term}_1$。\n    e. 如果 $U(d) > U^{\\star}$，则更新 $U^{\\star} = U(d)$，$T^{\\star} = T$ 和 $\\delta^{\\star} = \\delta$。\n4. 在评估完 $\\mathcal{D}$ 中的所有设计后，最终的 $(T^{\\star}, \\delta^{\\star}, U^{\\star})$ 即为该测试用例的结果。\n5. 将所有测试用例的结果整理成指定的输出格式，并按要求对值进行舍入。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_hermitenorm\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian optimal experimental design problem for model discrimination.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"params\": (0.5, 24.0, 2.0, 1.0, 1.2, 2.0, 0.2, 50),\n            \"T_candidates\": [20.0, 24.0, 28.0],\n            \"delta_candidates\": [0.3, 0.5, 0.8],\n        },\n        {\n            \"params\": (0.5, 24.0, 2.0, 1.0, 1.2, 2.0, 0.2, 50),\n            \"T_candidates\": [22.0, 24.0, 26.0],\n            \"delta_candidates\": [0.01, 0.05, 0.1],\n        },\n        {\n            \"params\": (0.5, 24.0, 2.0, 1.0, 1.0, 0.0, 0.2, 50),\n            \"T_candidates\": [20.0, 24.0, 28.0],\n            \"delta_candidates\": [0.3, 0.5, 0.8],\n        },\n    ]\n\n    all_results = []\n    \n    # Quadrature points and weights for numerical integration\n    # Using probabilist's Hermite polynomials (weight func exp(-x^2/2))\n    # A degree of 100 provides high accuracy.\n    quad_deg = 100\n    z_i, w_i = roots_hermitenorm(quad_deg)\n\n    for case in test_cases:\n        p0, tau0, sigma_T, A0, A1, k, sigma, n = case[\"params\"]\n        T_candidates = case[\"T_candidates\"]\n        delta_candidates = case[\"delta_candidates\"]\n\n        best_T = -1.0\n        best_delta = -1.0\n        max_U = -1.0\n\n        sigma_eff_sq = sigma**2 / n\n        sigma_eff = np.sqrt(sigma_eff_sq)\n\n        for T in T_candidates:\n            for delta in delta_candidates:\n                # Calculate resonance factor\n                R_T = np.exp(-0.5 * ((T - tau0) / sigma_T)**2)\n\n                # Calculate mean responses for the two models\n                mu0 = A0 * R_T * delta\n                mu1 = A1 * R_T * (delta / (1.0 + k * delta))\n                \n                # If models are indistinguishable, information gain is zero\n                if np.isclose(mu0, mu1):\n                    U_d = 0.0\n                else:\n                    # Define integrands for expectation calculation\n                    # The value y for the integrands will be sampled from the respective Gaussians\n                    # via change of variables in the quadrature.\n                    \n                    # Log-integrand for the expectation with respect to model 0\n                    def log_integrand_0(y):\n                        exponent = ((mu1 - mu0) * (y - (mu0 + mu1) / 2.0)) / sigma_eff_sq\n                        # Use log-sum-exp trick for stability, though direct computation is fine here\n                        # log(1 / (p0 + (1-p0) * exp(exponent))) = -log(p0 + (1-p0) * exp(exponent))\n                        return -np.log(p0 + (1.0 - p0) * np.exp(exponent))\n\n                    # Log-integrand for the expectation with respect to model 1\n                    def log_integrand_1(y):\n                        exponent = ((mu0 - mu1) * (y - (mu0 + mu1) / 2.0)) / sigma_eff_sq\n                        return -np.log(p0 * np.exp(exponent) + (1.0 - p0))\n\n                    # Perform numerical integration using Gauss-Hermite quadrature\n                    # E[f(Y)] where Y ~ N(mu, sigma^2) is E[f(mu + sigma*Z)] where Z ~ N(0,1)\n                    # The quadrature points z_i are effectively samples of Z.\n                    \n                    # Expectation w.r.t. model 0\n                    y_samples_0 = mu0 + sigma_eff * z_i\n                    integrand_vals_0 = log_integrand_0(y_samples_0)\n                    term_0 = np.sum(w_i * integrand_vals_0) / np.sqrt(2.0 * np.pi)\n\n                    # Expectation w.r.t. model 1\n                    y_samples_1 = mu1 + sigma_eff * z_i\n                    integrand_vals_1 = log_integrand_1(y_samples_1)\n                    term_1 = np.sum(w_i * integrand_vals_1) / np.sqrt(2.0 * np.pi)\n                    \n                    U_d = p0 * term_0 + (1.0 - p0) * term_1\n\n                if U_d > max_U:\n                    max_U = U_d\n                    best_T = T\n                    best_delta = delta\n\n        # Round to specified precision for output\n        T_star = round(best_T, 3)\n        delta_star = round(best_delta, 3)\n        U_star = round(max_U, 6)\n        \n        all_results.append(f\"[{T_star:.3f},{delta_star:.3f},{U_star:.6f}]\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在理论基础上，我们进一步考虑现实世界实验的复杂性，特别是资源分配的权衡。这个练习模拟了一个在单分子荧光原位杂交（smFISH）实验中常见的情景：在有限的预算下，我们应如何在测量数量（即细胞复现数 $N$）和测量质量（即分子计数灵敏度 $q$）之间做出最优分配？你的任务是在区分两种不同的转录本计数统计模型（泊松分布与负二项分布）时，最大化总的信息收益。此问题将使用杰森-香农散度作为效用函数，它与互信息密切相关，让你能够在一个实际的生物学场景中，练习如何在约束条件下进行优化决策。",
            "id": "3290026",
            "problem": "考虑如何区分两种相互竞争的观测模型，这两个模型用于描述在单细胞中通过单分子荧光原位杂交（smFISH）技术测量的转录本计数。这两个模型在期望计数上一致，但在方差上有所不同。设随机选取的一个细胞的潜在真实转录本计数为 $X$，其群体均值为 $\\mu$。smFISH 测量被建模为二项式稀疏化过程，其中分子计数灵敏度为 $q \\in (0,1)$，因此观测到的计数 $Y$ 是检测到的转录本数量。针对 $Y$ 的两个候选观测模型是：\n\n- 模型 $\\mathcal{M}_P$（Poisson稀疏化）：$X \\sim \\mathrm{Poisson}(\\mu)$ 且 $Y \\mid X \\sim \\mathrm{Binomial}(X,q)$，这意味着 $Y \\sim \\mathrm{Poisson}(q\\mu)$，其 $\\mathbb{E}[Y] = q\\mu$ 且 $\\mathrm{Var}[Y] = q\\mu$。\n- 模型 $\\mathcal{M}_{NB}$（负二项稀疏化）：$X \\sim \\mathrm{Negative\\ Binomial}(\\mu,k)$，其中 $k$ 是离散（大小）参数，且 $Y \\mid X \\sim \\mathrm{Binomial}(X,q)$。在负二项（NB）模型下，通过 Poisson-Gamma 混合稀疏化，$Y$ 仍然服从负二项分布，其 $\\mathbb{E}[Y] = q\\mu$ 且 $\\mathrm{Var}[Y] = q\\mu + \\frac{q^2\\mu^2}{k}$。\n\n假设先验概率相等 $\\pi(\\mathcal{M}_P) = \\pi(\\mathcal{M}_{NB}) = 1/2$。对于单个细胞，模型边际预测分布为：\n- 在模型 $\\mathcal{M}_P$ 下，概率质量函数（pmf）为 $p_P(y \\mid q,\\mu) = \\frac{e^{-q\\mu}(q\\mu)^y}{y!}$，对于 $y \\in \\{0,1,2,\\dots\\}$。\n- 在均值为 $q\\mu$、离散参数为 $k$ 的模型 $\\mathcal{M}_{NB}$ 下，pmf 为\n$$\np_{NB}(y \\mid q,\\mu,k) = \\frac{\\Gamma(y+k)}{\\Gamma(k)\\,\\Gamma(y+1)}\\left(\\frac{k}{k+q\\mu}\\right)^{k}\\left(\\frac{q\\mu}{k+q\\mu}\\right)^{y},\\quad y \\in \\{0,1,2,\\dots\\}.\n$$\n\n你需要分配独立重复实验的次数 $N \\in \\mathbb{N}$（测量的细胞数），并从一个离散网格中选择分子计数灵敏度 $q$，以便在预算约束下最大化一个贝叶斯模型区分标准。设总成本为\n$$\nC(N,q) = c_r N + c_s \\frac{q}{1-q},\n$$\n其中 $c_r$ 是每次重复实验的成本，$c_s \\frac{q}{1-q}$ 模拟了实现更高灵敏度 $q$ 所带来的急剧增加的成本（例如，使用更多的探针对）。给定预算 $B$，可行设计需满足 $C(N,q) \\le B$ 且 $N \\ge 1$。\n\n作为模型区分的贝叶斯效用函数，我们使用在等先验概率下模型指示符 $M \\in \\{\\mathcal{M}_P,\\mathcal{M}_{NB}\\}$ 和数据 $Y$ 之间的互信息，对于单次重复实验，这等同于 $p_P$ 和 $p_{NB}$ 之间的 Jensen-Shannon 散度：\n$$\nI_1(q) = \\sum_{y=0}^{\\infty} \\left[ \\frac{1}{2}\\, p_P(y\\mid q,\\mu) \\log \\frac{p_P(y\\mid q,\\mu)}{\\frac{1}{2}p_P(y\\mid q,\\mu)+\\frac{1}{2}p_{NB}(y\\mid q,\\mu,k)} + \\frac{1}{2}\\, p_{NB}(y\\mid q,\\mu,k) \\log \\frac{p_{NB}(y\\mid q,\\mu,k)}{\\frac{1}{2}p_P(y\\mid q,\\mu)+\\frac{1}{2}p_{NB}(y\\mid q,\\mu,k)} \\right].\n$$\n对于 $N$ 次独立重复实验，互信息呈线性扩展：\n$$\nI_N(q) = N\\, I_1(q).\n$$\n\n你的任务是编写一个完整的、可运行的程序。对于每个指定的测试用例，该程序应在给定的 $q$ 值网格上进行搜索，通过对 $y$ 的级数求和来计算 $I_1(q)$，求和至一个足够大的截断值以确保尾部概率可以忽略不计，然后根据预算和选定的 $q$ 选择可行的最大整数 $N$（因为 $I_N(q)$ 随 $N$ 线性增长）。对于每个测试用例，程序应输出三元组 $[N^*, q^*, I_N(q^*)]$，其中 $[N^*, q^*, I_N(q^*)]$ 是在可行 $q$ 网格中满足 $C(N,q) \\le B$ 和 $N \\ge 1$ 约束下 $I_N(q)$ 的最大化者。\n\n使用以下测试套件。在每个案例中，$q$ 必须从网格 $\\{0.3,0.5,0.7,0.85,0.95\\}$ 中选择。\n\n- 测试用例1：$B=50$, $c_r=1.0$, $c_s=10.0$, $\\mu=8.0$, $k=20.0$。\n- 测试用例2：$B=8$, $c_r=1.0$, $c_s=10.0$, $\\mu=8.0$, $k=20.0$。\n- 测试用例3：$B=50$, $c_r=2.0$, $c_s=5.0$, $\\mu=5.0$, $k=2.0$。\n- 测试用例4：$B=50$, $c_r=1.0$, $c_s=10.0$, $\\mu=10.0$, $k=10^6$。\n- 测试用例5：$B=50$, $c_r=0.5$, $c_s=50.0$, $\\mu=12.0$, $k=5.0$。\n\n算法要求：\n- 为保证数值稳定性，使用自然对数和对数伽马函数计算 pmf 的对数值，然后取幂以获得概率。\n- 将关于 $y$ 的无穷级数在 $y_{\\max}$ 处截断，其选择方式为\n$$\ny_{\\max} = \\left\\lceil q\\mu + 10 \\sqrt{\\max\\left(q\\mu, q\\mu + \\frac{q^2\\mu^2}{k}\\right)} + 10 \\right\\rceil\n$$\n并强制要求 $y_{\\max} \\ge 100$ 以确保对于所有网格值，尾部贡献都可以忽略不计。\n- 对于每个可行的 $q$，计算 $N_{\\max} = \\left\\lfloor \\frac{B - c_s \\frac{q}{1-q}}{c_r} \\right\\rfloor$。如果 $N_{\\max} \\ge 1$，则设 $N=N_{\\max}$；否则，将 $q$ 视为不可行而舍弃。\n- 在所有可行的 $q$ 中，选择具有最大 $I_N(q)$ 的设计 $[N^*, q^*, I_N(q^*)]$，若出现平局，则优先选择较大的 $N$，其次是较大的 $q$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素本身是一个形如 $[N^*, q^*, I_N(q^*)]$ 的列表，对应于上面列出的相应测试用例。\n- 将 $N^*$ 打印为整数，$q^*$ 四舍五入到三位小数，$I_N(q^*)$ 四舍五入到六位小数。",
            "solution": "该问题要求我们找到最优的实验设计，该设计由重复实验次数（细胞数）$N$ 和测量灵敏度 $q$ 定义，目的是区分两种用于单细胞转录本计数的竞争性统计模型。该设计必须在总预算约束下最大化一个贝叶斯效用函数。\n\n问题的核心在于用于模型区分的贝叶斯最优实验设计（OED）。效用函数是模型指示符 $M \\in \\{\\mathcal{M}_P, \\mathcal{M}_{NB}\\}$ 与观测数据 $Y$ 之间的互信息 $I(M; Y)$。对于 $N$ 个独立同分布的观测值，该效用为 $I_N(q) = N \\cdot I_1(q)$，其中 $I_1(q)$ 是单个观测值的互信息。如问题所述，对于两个具有相等先验概率 $\\pi(\\mathcal{M}_P) = \\pi(\\mathcal{M}_{NB}) = 1/2$ 的模型，这种单次重复实验的效用等价于模型边际预测分布 $p_P(y)$ 和 $p_{NB}(y)$ 之间的 Jensen-Shannon 散度（JSD）：\n$$\nI_1(q) = \\mathrm{JSD}(p_P, p_{NB}) = \\sum_{y=0}^{\\infty} \\left[ \\frac{1}{2}p_P(y) \\ln \\frac{p_P(y)}{p_{\\text{mix}}(y)} + \\frac{1}{2}p_{NB}(y) \\ln \\frac{p_{NB}(y)}{p_{\\text{mix}}(y)} \\right]\n$$\n其中 $p_{\\text{mix}}(y) = \\frac{1}{2}p_P(y) + \\frac{1}{2}p_{NB}(y)$ 是数据在所有模型上的边际分布。按规定使用自然对数。\n\n优化目标是在一个离散的 $q$ 值网格和所有可行的整数 $N \\ge 1$ 上最大化总效用 $I_N(q)$。约束由总预算 $B$ 定义，成本为 $C(N,q) = c_r N + c_s \\frac{q}{1-q}$。\n\n算法步骤如下：\n1.  对于选定的灵敏度 $q$，实验装置的成本为 $C_s(q) = c_s \\frac{q}{1-q}$。用于重复实验的剩余预算为 $B - C_s(q)$。\n2.  由于效用 $I_N(q) = N \\cdot I_1(q)$ 随 $N$ 线性增加，对于固定的 $q$，我们应始终选择预算允许的最大重复次数。这由 $N = N_{\\max}(q) = \\left\\lfloor \\frac{B - C_s(q)}{c_r} \\right\\rfloor$ 给出。\n3.  只有当 $C_s(q) \\le B$ 且 $N_{\\max}(q) \\ge 1$ 时，设计 $(N,q)$ 才是可行的。\n4.  因此，问题简化为在所提供的离散 $q$ 值网格上进行搜索。对于每个可行的 $q$，我们计算其对应的 $N_{\\max}(q)$ 和总效用 $I_N(q) = N_{\\max}(q) \\cdot I_1(q)$。\n5.  最优设计 $(N^*, q^*)$ 是在所有可行设计中产生最大总效用的设计。问题指定了平局处理规则：如果两个设计产生相同的最大效用，则优先选择重复次数 $N$ 较大的设计，其次是灵敏度 $q$ 较大的设计。\n\n主要的计算挑战是计算 $I_1(q)$，这涉及一个无穷级数。问题指定了一个稳健的截断策略。级数在由两个分布的均值和方差决定的上界 $y_{\\max}$ 处被截断：\n$$\ny_{\\max} = \\left\\lceil q\\mu + 10 \\sqrt{\\max\\left(\\mathrm{Var}_P[Y], \\mathrm{Var}_{NB}[Y]\\right)} + 10 \\right\\rceil, \\quad \\text{with } y_{\\max} \\ge 100\n$$\n其中 $\\mathrm{Var}_P[Y] = q\\mu$ 且 $\\mathrm{Var}_{NB}[Y] = q\\mu + \\frac{q^2\\mu^2}{k}$。这确保了求和覆盖了分布具有显著概率质量的区域。\n\n为了保持数值稳定性，特别是对于小概率和大的组合（如在负二项 PMF 中），所有的概率质量函数（PMF）都在对数空间中计算。Poisson PMF $p_P(y \\mid q,\\mu)$ 和负二项 PMF $p_{NB}(y \\mid q,\\mu,k)$ 使用它们的对数-PMF 公式进行计算，这涉及对数伽马函数（来自 SciPy 的 `gammaln`）。\n混合概率的对数 $\\ln(p_{\\text{mix}}(y))$ 使用 `logsumexp` 函数进行稳定计算：\n$$\n\\ln(p_{\\text{mix}}(y)) = \\ln\\left(\\frac{1}{2}e^{\\ln p_P(y)} + \\frac{1}{2}e^{\\ln p_{NB}(y)}\\right) = \\ln(0.5) + \\mathrm{logsumexp}(\\ln p_P(y), \\ln p_{NB}(y))\n$$\n然后将 JSD 项在 $y$ 从 $0$ 到 $y_{\\max}$ 的范围内求和，以得到 $I_1(q)$。\n\n整体算法遍历每个测试用例的参数。对于每个案例，它评估给定网格中的所有可行设计 $(N_{\\max}(q), q)$，存储它们的效用，然后根据指定的标准（最大效用，然后是最大的 $N$，再然后是最大的 $q$）选择最优设计。最终输出格式化为三元组列表 $[N^*, q^*, I_{N^*}(q^*)]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln, logsumexp\n\ndef calculate_log_pmfs(y_values, q, mu, k):\n    \"\"\"\n    Calculates the log-PMFs for Poisson and Negative Binomial distributions\n    in a numerically stable and vectorized way.\n    \"\"\"\n    lam = q * mu\n    ys = np.asarray(y_values, dtype=np.float64)\n\n    # Poisson log PMF: log(e^(-lam) * lam^y / y!) = y*log(lam) - lam - lgamma(y+1)\n    if lam == 0:\n        log_pmf_p = np.full_like(ys, -np.inf)\n        log_pmf_p[ys == 0] = 0.0\n    else:\n        log_pmf_p = ys * np.log(lam) - lam - gammaln(ys + 1)\n\n    # Negative Binomial log PMF from the problem statement\n    # log(pmf) = lgamma(y+k) - lgamma(k) - lgamma(y+1) + k*log(k/(k+lam)) + y*log(lam/(k+lam))\n    if lam == 0:\n        log_pmf_nb = np.full_like(ys, -np.inf)\n        log_pmf_nb[ys == 0] = 0.0\n    else:\n        log_term_k = k * (np.log(k) - np.log(k + lam))\n        log_term_y = ys * (np.log(lam) - np.log(k + lam))\n        log_pmf_nb = gammaln(ys + k) - gammaln(k) - gammaln(ys + 1) + log_term_k + log_term_y\n        \n    return log_pmf_p, log_pmf_nb\n\ndef calculate_i1(q, mu, k):\n    \"\"\"\n    Calculates the single-replicate mutual information I_1(q), which is the\n    Jensen-Shannon divergence between the two predictive distributions.\n    \"\"\"\n    # Determine truncation limit y_max\n    mean_val = q * mu\n    var_p = mean_val\n    var_nb = mean_val + (q**2 * mu**2) / k\n    \n    y_max = np.ceil(mean_val + 10 * np.sqrt(max(var_p, var_nb)) + 10)\n    y_max = int(max(y_max, 100))\n    \n    y_values = np.arange(0, y_max + 1)\n    \n    log_p_p_vals, log_p_nb_vals = calculate_log_pmfs(y_values, q, mu, k)\n    \n    I1 = 0.0\n    for i in range(len(y_values)):\n        log_p_p = log_p_p_vals[i]\n        log_p_nb = log_p_nb_vals[i]\n        \n        # log of the mixture probability: log(0.5 * (p_p + p_nb))\n        log_p_mix = np.log(0.5) + logsumexp([log_p_p, log_p_nb])\n        \n        # Add JSD term for model P, handling p_p = 0 case\n        p_p = np.exp(log_p_p)\n        if p_p > 0:\n            term_p = 0.5 * p_p * (log_p_p - log_p_mix)\n            I1 += term_p\n            \n        # Add JSD term for model NB, handling p_nb = 0 case\n        p_nb = np.exp(log_p_nb)\n        if p_nb > 0:\n            term_nb = 0.5 * p_nb * (log_p_nb - log_p_mix)\n            I1 += term_nb\n            \n    return I1\n\ndef find_optimal_design(B, cr, cs, mu, k, q_grid):\n    \"\"\"\n    Finds the optimal design (N*, q*) that maximizes total utility I_N(q)\n    subject to budget and feasibility constraints.\n    \"\"\"\n    candidates = []\n\n    for q in q_grid:\n        if q >= 1.0: continue\n        \n        cost_q = cs * q / (1.0 - q)\n        \n        if cost_q > B:\n            continue\n            \n        N_max = np.floor((B - cost_q) / cr)\n        \n        if N_max  1:\n            continue\n        \n        N = int(N_max)\n        i1_q = calculate_i1(q, mu, k)\n        i_total = N * i1_q\n        \n        candidates.append({'N': N, 'q': q, 'I': i_total})\n        \n    if not candidates:\n        return [0, 0.0, 0.0]\n\n    # Find the best candidate according to the tie-breaking rules:\n    # 1. Maximize utility 'I'\n    # 2. Maximize number of replicates 'N'\n    # 3. Maximize sensitivity 'q'\n    candidates.sort(key=lambda x: (-x['I'], -x['N'], -x['q']))\n    \n    best_design = candidates[0]\n    return [best_design['N'], best_design['q'], best_design['I']]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'B': 50, 'cr': 1.0, 'cs': 10.0, 'mu': 8.0, 'k': 20.0},\n        {'B': 8, 'cr': 1.0, 'cs': 10.0, 'mu': 8.0, 'k': 20.0},\n        {'B': 50, 'cr': 2.0, 'cs': 5.0, 'mu': 5.0, 'k': 2.0},\n        {'B': 50, 'cr': 1.0, 'cs': 10.0, 'mu': 10.0, 'k': 1e6},\n        {'B': 50, 'cr': 0.5, 'cs': 50.0, 'mu': 12.0, 'k': 5.0},\n    ]\n    q_grid = [0.3, 0.5, 0.7, 0.85, 0.95]\n\n    results = []\n    for params in test_cases:\n        result = find_optimal_design(\n            params['B'], params['cr'], params['cs'], params['mu'], params['k'], q_grid\n        )\n        results.append(result)\n\n    # Format the results for the final print statement\n    formatted_results = []\n    for N_star, q_star, I_star in results:\n        formatted_results.append(f\"[{N_star},{q_star:.3f},{I_star:.6f}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "许多科学探索本质上是序贯的：我们根据当前所知设计下一个实验，并不断迭代。本练习将引导你进入序贯实验设计的世界，构建一个“单步前瞻”策略，这在自适应实验设计中至关重要。你将不再设计一个一次性的终极实验，而是要制定一个策略，用于选择*下一个*能最大化模型不确定性（熵）期望减少量的实验。这个过程将让你学会如何动态地选择实验，以最有效的方式从一系列竞争的动态假设中区分出最有可能的模型。",
            "id": "3290046",
            "problem": "考虑一个生物调控机制的一组有限的竞争性动力学假设，表示为一个离散模型变量 $M \\in \\{1,\\dots,K\\}$，在给定先验数据 $\\mathcal{D}$ 的情况下，其当前的贝叶斯后验概率为 $p(M=m \\mid \\mathcal{D})$。一项新实验包括从一个有限的候选集 $\\mathcal{A}$ 中选择一个设计 $d$，然后观察一个离散的计数结果 $Y \\in \\{0,1,2,\\dots\\}$。对于每个模型 $m$ 和设计 $d$，$Y$ 的预测抽样分布是泊松分布，其速率参数 $\\lambda_{m}(d)$ 特定于模型和设计，因此对于所有非负整数 $y$，$p(Y=y \\mid M=m, d) = \\mathrm{Poisson}(y; \\lambda_{m}(d))$。假设模型后验概率 $p(M \\mid \\mathcal{D})$ 和模型内预测分布 $p(Y \\mid M=m, d)$ 是已知的。令 $H(\\cdot)$ 表示以自然单位（nats）计算的香农熵，对于一个有限集上的离散分布 $q$，定义为 $H(q) = -\\sum_{i} q_{i} \\log q_{i}$，并约定 $0 \\log 0 = 0$。\n\n您的任务是为序贯模型判别构建一个单步前瞻的贝叶斯最优实验设计策略，通过选择 $d \\in \\mathcal{A}$ 来最大化观察到 $Y$ 后关于 $M$ 的不确定性的预期减少量。对于一个固定的 $d$，选择目标是预期熵减\n$$\n\\mathbb{E}_{Y \\sim p(\\cdot \\mid \\mathcal{D}, d)} \\big[ H(M \\mid \\mathcal{D}) - H(M \\mid \\mathcal{D} \\cup \\{(d,Y)\\}) \\big],\n$$\n其中，根据贝叶斯法则，$p(y \\mid \\mathcal{D}, d) = \\sum_{m=1}^{K} p(M=m \\mid \\mathcal{D}) \\, p(y \\mid M=m, d)$ 且 $p(M=m \\mid \\mathcal{D} \\cup \\{(d,y)\\}) \\propto p(M=m \\mid \\mathcal{D}) \\, p(y \\mid M=m, d)$。因为 $H(M \\mid \\mathcal{D})$ 不依赖于 $d$，所以最大化预期减少量等价于最小化预期后验熵 $\\mathbb{E}_{Y} \\big[ H(M \\mid \\mathcal{D} \\cup \\{(d,Y)\\}) \\big]$。\n\n实现一个程序，为每个测试用例计算每个设计 $d \\in \\mathcal{A}$ 的预期熵减，并返回最大化设计方案的索引及其预期熵减值。泊松分布的结果是可数无限的；为了进行数值评估，通过对非负整数求和来近似期望值，直到剩余的预测尾部概率低于指定的容差 $\\varepsilon$。使用自然对数，以便熵以 nats 为单位报告。如果多个设计的最大值之差的绝对值小于一个持平阈值 $\\delta$，则通过选择最小的索引来打破平局。\n\n所有计算的实现方式必须与任何物理单位无关。不涉及任何物理单位。不使用角度。所有概率必须是有效的（非负且在数值容差范围内总和为 $1$）。最终输出必须是数值。\n\n测试套件和所需的数值参数：\n- 对每个设计的预测尾部使用截断容差 $\\varepsilon = 10^{-8}$。在比较不同设计的预期熵减时，使用持平阈值 $\\delta = 10^{-12}$。\n- 对于每个测试用例，候选设计集 $\\mathcal{A}$ 的索引为 $\\{0,1,\\dots, D-1\\}$，其中 $D$ 是该用例中的设计数量。通过其索引报告所选的设计。\n\n提供以下四个测试用例。每个测试用例指定了模型数量 $K$、模型的先验概率以及每个设计 $d$ 和模型 $m$ 的泊松速率矩阵 $\\lambda_{m}(d)$。在每个用例中，计算并报告由所选设计索引和相应的预期熵减（四舍五入到恰好 $6$ 位小数）组成的数对。\n\n- 测试用例 A（顺利路径，两个模型，三个设计）：\n  - 模型数量 $K = 2$。\n  - 先验概率 $p(M \\mid \\mathcal{D}) = [0.5, 0.5]$。\n  - 设计集 $\\mathcal{A} = \\{0,1,2\\}$，速率为\n    - $d=0$: $(\\lambda_{1}(0), \\lambda_{2}(0)) = (2.0, 8.0)$,\n    - $d=1$: $(\\lambda_{1}(1), \\lambda_{2}(1)) = (5.0, 5.0)$,\n    - $d=2$: $(\\lambda_{1}(2), \\lambda_{2}(2)) = (1.0, 9.0)$。\n\n- 测试用例 B（边界先验，两个模型，三个设计）：\n  - 模型数量 $K = 2$。\n  - 先验概率 $p(M \\mid \\mathcal{D}) = [0.95, 0.05]$。\n  - 设计集 $\\mathcal{A} = \\{0,1,2\\}$，速率与测试用例 A 相同。\n\n- 测试用例 C（持平情况，两个模型，三个设计）：\n  - 模型数量 $K = 2$。\n  - 先验概率 $p(M \\mid \\mathcal{D}) = [0.5, 0.5]$。\n  - 设计集 $\\mathcal{A} = \\{0,1,2\\}$，速率为\n    - $d=0$: $(\\lambda_{1}(0), \\lambda_{2}(0)) = (4.0, 6.0)$,\n    - $d=1$: $(\\lambda_{1}(1), \\lambda_{2}(1)) = (4.0, 6.0)$,\n    - $d=2$: $(\\lambda_{1}(2), \\lambda_{2}(2)) = (5.0, 5.0)$。\n\n- 测试用例 D（三个模型，四个设计）：\n  - 模型数量 $K = 3$。\n  - 先验概率 $p(M \\mid \\mathcal{D}) = [0.2, 0.3, 0.5]$。\n  - 设计集 $\\mathcal{A} = \\{0,1,2,3\\}$，速率为\n    - $d=0$: $(\\lambda_{1}(0), \\lambda_{2}(0), \\lambda_{3}(0)) = (3.0, 3.5, 3.2)$,\n    - $d=1$: $(\\lambda_{1}(1), \\lambda_{2}(1), \\lambda_{3}(1)) = (2.0, 6.0, 10.0)$,\n    - $d=2$: $(\\lambda_{1}(2), \\lambda_{2}(2), \\lambda_{3}(2)) = (8.0, 4.0, 6.0)$,\n    - $d=3$: $(\\lambda_{1}(3), \\lambda_{2}(3), \\lambda_{3}(3)) = (1.0, 3.0, 9.0)$。\n\n算法要求：\n- 对于每个设计 $d$，计算混合预测质量函数 $p(y \\mid \\mathcal{D}, d)$ 和相应的后验模型概率 $p(M \\mid \\mathcal{D} \\cup \\{(d,y)\\})$，其中非负整数 $y$ 在一个截断范围 $\\{0,1,\\dots,y_{\\max}\\}$ 内，该范围的选择需满足 $\\sum_{y=0}^{y_{\\max}} p(y \\mid \\mathcal{D}, d) \\ge 1 - \\varepsilon$。\n- 使用恒等式 $p(M=m \\mid \\mathcal{D} \\cup \\{(d,y)\\}) \\propto p(M=m \\mid \\mathcal{D}) \\, p(y \\mid M=m, d)$ 来计算每个 $y$ 的后验概率，然后计算熵 $H(M \\mid \\mathcal{D} \\cup \\{(d,y)\\})$。\n- 计算预期后验熵 $\\sum_{y=0}^{y_{\\max}} p(y \\mid \\mathcal{D}, d) \\, H(M \\mid \\mathcal{D} \\cup \\{(d,y)\\})$，并将其从 $H(M \\mid \\mathcal{D})$ 中减去，以获得该设计 $d$ 的预期熵减。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个元素对应一个测试用例（按 A、B、C、D 的顺序），且本身是一个双元素列表 $[d^{\\star}, u^{\\star}]$，其中 $d^{\\star}$ 是所选设计的索引，$u^{\\star}$ 是四舍五入到恰好 $6$ 位小数的预期熵减。例如，一个有效的整体输出可能看起来像 $[[0,0.123456],[2,0.000321],[0,0.045678],[1,0.234567]]$。",
            "solution": "该问题要求我们为模型判别设计一个单步前瞻的最优实验设计策略。我们给定一个包含 $K$ 个竞争模型的有限集，索引为 $m \\in \\{1, \\dots, K\\}$，以及它们的先验概率分布 $p(M=m \\mid \\mathcal{D})$。目标是从一个有限集 $\\mathcal{A}$ 中选择一个实验设计 $d$，期望它能提供最多的信息来区分这些模型。实验结果 $Y$ 是一个离散计数，由泊松分布建模，其速率 $\\lambda_m(d)$ 取决于真实模型 $m$ 和所选设计 $d$。\n\n该策略的核心目标是最大化模型分布的香农熵的预期减少量。对于给定的设计 $d$，该效用函数 $U(d)$ 定义为：\n$$\nU(d) = \\mathbb{E}_{Y \\sim p(\\cdot \\mid \\mathcal{D}, d)} \\big[ H(M \\mid \\mathcal{D}) - H(M \\mid \\mathcal{D} \\cup \\{(d,Y)\\}) \\big]\n$$\n这个量代表了从设计为 $d$ 的实验中获得的关于 $M$ 的预期信息增益。初始熵 $H(M \\mid \\mathcal{D})$ 是根据给定的模型概率 $p(M=m \\mid \\mathcal{D})$ 计算的，并且对于所有候选设计都是一个常数。因此，最大化 $U(d)$ 等价于最小化预期后验熵 $\\mathbb{E}_{Y}[H(M \\mid \\mathcal{D} \\cup \\{(d,Y)\\})]$。\n\n针对每个设计 $d \\in \\mathcal{A}$ 的计算策略包括以下步骤：\n\n1.  **先验熵**：初始熵是根据先验（或当前后验）分布 $p(M \\mid \\mathcal{D})$ 计算的：\n    $$\n    H(M \\mid \\mathcal{D}) = - \\sum_{m=1}^{K} p(M=m \\mid \\mathcal{D}) \\log p(M=m \\mid \\mathcal{D})\n    $$\n    使用自然对数，因此熵的单位是 nats。\n\n2.  **预测分布和贝叶斯更新**：对于每个可能的结果 $y \\in \\{0, 1, 2, \\dots\\}$，我们必须评估每个模型的后验概率。这需要两个部分：\n    -   观察到 $y$ 的边际预测概率，通过对所有模型进行边缘化得到：\n        $$\n        p(y \\mid \\mathcal{D}, d) = \\sum_{m=1}^{K} p(M=m \\mid \\mathcal{D}) \\, p(y \\mid M=m, d)\n        $$\n        其中 $p(y \\mid M=m, d)$ 是泊松概率质量函数（PMF），$\\mathrm{Poisson}(y; \\lambda_m(d)) = \\frac{\\lambda_m(d)^y e^{-\\lambda_m(d)}}{y!}$。\n    -   给定结果 $y$ 后，每个模型 $m$ 的更新后验概率，通过贝叶斯法则计算：\n        $$\n        p(M=m \\mid \\mathcal{D}, d, y) = \\frac{p(M=m \\mid \\mathcal{D}) \\, p(y \\mid M=m, d)}{p(y \\mid \\mathcal{D}, d)}\n        $$\n\n3.  **预期后验熵**：期望值是关于所有非负整数 $y$ 的无穷级数。为了进行数值计算，该级数在一个值 $y_{\\max}$ 处被截断，使得剩余的尾部概率可以忽略不计。我们找到最小的 $y_{\\max}$，使得 $\\sum_{y=0}^{y_{\\max}} p(y \\mid \\mathcal{D}, d) \\ge 1 - \\varepsilon$，容差为 $\\varepsilon = 10^{-8}$。然后，预期后验熵近似为：\n    $$\n    \\mathbb{E}_{Y}[H(M \\mid \\dots)] \\approx \\sum_{y=0}^{y_{\\max}} p(y \\mid \\mathcal{D}, d) \\left( - \\sum_{m=1}^{K} p(M=m \\mid \\mathcal{D}, d, y) \\log p(M=m \\mid \\mathcal{D}, d, y) \\right)\n    $$\n\n4.  **效用和最优设计**：预期熵减 $U(d)$ 计算为 $U(d) = H(M \\mid \\mathcal{D}) - \\mathbb{E}_{Y}[H(M \\mid \\dots)]$。对每个设计 $d \\in \\mathcal{A}$ 重复此过程。最优设计 $d^\\star$ 是具有最高效用 $U(d)$ 的设计。如果多个设计的最大效用值在容差 $\\delta = 10^{-12}$ 内相等，则通过选择索引最小的设计来打破平局。\n\n为确保数值稳定性，特别是在处理涉及阶乘和幂的泊松 PMF 时，所有中间概率计算都在对数域中执行。使用 `log-sum-exp` 技巧来稳定地对指数化后的值进行求和。最终算法计算所有 $d$ 的 $U(d)$，并选择最优的一个 $d^\\star$，报告 $d^\\star$ 及其效用 $U(d^\\star)$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln, logsumexp\nfrom scipy.stats import entropy\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian optimal experimental design problem for model discrimination\n    for a series of test cases.\n    \"\"\"\n    test_cases = [\n        {  # Test case A\n            \"prior\": np.array([0.5, 0.5]),\n            \"lambdas\": np.array([\n                [2.0, 8.0],\n                [5.0, 5.0],\n                [1.0, 9.0]\n            ])\n        },\n        {  # Test case B\n            \"prior\": np.array([0.95, 0.05]),\n            \"lambdas\": np.array([\n                [2.0, 8.0],\n                [5.0, 5.0],\n                [1.0, 9.0]\n            ])\n        },\n        {  # Test case C\n            \"prior\": np.array([0.5, 0.5]),\n            \"lambdas\": np.array([\n                [4.0, 6.0],\n                [4.0, 6.0],\n                [5.0, 5.0]\n            ])\n        },\n        {  # Test case D\n            \"prior\": np.array([0.2, 0.3, 0.5]),\n            \"lambdas\": np.array([\n                [3.0, 3.5, 3.2],\n                [2.0, 6.0, 10.0],\n                [8.0, 4.0, 6.0],\n                [1.0, 3.0, 9.0]\n            ])\n        }\n    ]\n\n    EPSILON = 1e-8\n    DELTA = 1e-12\n    \n    results = []\n\n    for case in test_cases:\n        prior = case[\"prior\"]\n        all_lambdas = case[\"lambdas\"]\n        \n        # Pre-calculate log prior and prior entropy\n        log_prior = np.log(prior)\n        prior_entropy = entropy(prior, base=np.e)\n        \n        design_utilities = []\n        \n        for lambdas_d in all_lambdas:\n            expected_posterior_entropy = 0.0\n            y = 0\n            cumulative_prob = 0.0\n            \n            # The loop determines y_max implicitly by summing until the tail is negligible\n            while cumulative_prob  1.0 - EPSILON:\n                # Use log scale for numerical stability\n                # log(y!) = log(Gamma(y+1))\n                log_y_factorial = gammaln(y + 1)\n                \n                # log P(y | M=m, d) for all m\n                log_likelihoods = y * np.log(lambdas_d) - lambdas_d - log_y_factorial\n                \n                # log P(M=m, y | d) = log P(M=m) + log P(y | M=m, d)\n                log_joints = log_prior + log_likelihoods\n                \n                # log P(y | d) = log(sum_m(exp(log_joints_m)))\n                log_marginal_y = logsumexp(log_joints)\n                marginal_y = np.exp(log_marginal_y)\n\n                if marginal_y > 1e-30:  # Avoid operations on near-zero probabilities\n                    # log P(M=m | y, d) = log_joint - log_marginal\n                    log_posteriors = log_joints - log_marginal_y\n                    posteriors = np.exp(log_posteriors)\n                    \n                    # H(M | y,d)\n                    posterior_entropy_y = entropy(posteriors, base=np.e)\n                    \n                    # Accumulate expected posterior entropy\n                    expected_posterior_entropy += marginal_y * posterior_entropy_y\n\n                cumulative_prob += marginal_y\n                y += 1\n                \n                # Safety break for pathologically large lambdas not in test cases\n                # The y_max for given test cases is well below this.\n                if y > 1000:\n                    break\n\n            utility = prior_entropy - expected_posterior_entropy\n            design_utilities.append(utility)\n            \n        # Determine the best design based on utility and tie-breaking rule\n        max_utility = -np.inf\n        if design_utilities:\n            max_utility = np.max(design_utilities)\n\n        best_design_index = -1\n        # Find the smallest index of designs that are close to the max utility\n        for i, u in enumerate(design_utilities):\n            if max_utility - u  DELTA:\n                best_design_index = i\n                break\n        \n        best_utility = design_utilities[best_design_index]\n        results.append(f\"[{best_design_index},{best_utility:.6f}]\")\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}