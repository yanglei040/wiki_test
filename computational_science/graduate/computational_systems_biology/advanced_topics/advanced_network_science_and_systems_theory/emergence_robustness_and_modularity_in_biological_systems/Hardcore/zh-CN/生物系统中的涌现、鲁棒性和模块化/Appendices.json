{
    "hands_on_practices": [
        {
            "introduction": "生物系统的核心过程，如基因表达，并非确定性的，而是充满了内在的随机性。为了理解这种变异的来源，系统生物学将总噪声分解为内在噪声（源于生化反应本身的随机性）和外在噪声（源于细胞环境的波动）。本练习将通过一个经典的基因表达模型，探索转录过程中的“脉冲式”合成为何是细胞间差异的一个关键驱动因素。\n\n通过从化学主方程（Chemical Master Equation）出发，您将亲手推导出一个关键的噪声度量——法诺因子（Fano factor）。这项实践不仅能加深您对基因表达随机性的理解，还能锻炼您使用矩生成函数等数学工具来分析随机生物过程的基本技能。",
            "id": "3305386",
            "problem": "考虑一个信使核糖核酸 (mRNA) 的单基因表达模块，其中合成为随机脉冲式，降解为一阶过程。脉冲以速率 $k$ (单位时间的脉冲数) 的齐次泊松过程到达。一次脉冲会增加随机数量 $M$ 个 mRNA 分子，其中 $M$ 在不同脉冲之间是独立同分布的，服从支撑集为 $\\{0,1,2,\\dots\\}$、概率质量函数为 $\\Pr(M=m)=p(1-p)^{m}$ 的几何分布；每个 mRNA 分子以速率 $\\gamma$ (每个分子) 独立降解。定义法诺因子 $F$ 为 $F=\\frac{\\operatorname{Var}(n)}{\\mathbb{E}[n]}$，其中 $n$ 是稳态 mRNA 拷贝数。几何分布的脉冲大小均值为 $\\mathbb{E}[M]=\\frac{1-p}{p}$，方差为 $\\operatorname{Var}(M)=\\frac{1-p}{p^{2}}$，因此平均脉冲大小 $b$ 满足 $b=\\frac{1-p}{p}$。\n\n您的任务是：\n- 使用全方差定律，并通过对在细胞群体中波动的环境或参数变量进行条件化，精确区分基因表达中的内在噪声和外在噪声。\n- 从化学主方程 (CME) 和跳跃过程期望值的生成元公式出发，为此脉冲式生灭模型推导 $\\mathbb{E}[n]$ 和 $\\operatorname{Var}(n)$ 的稳态闭式表达式，然后计算法诺因子 $F$。\n\n请用仅含 $b$ 的单个闭式解析表达式表示您的最终答案。不需要数值近似，由于 $F$ 是无量纲的，因此也不需要单位。",
            "solution": "该问题提出了两个任务：第一，在基因表达的背景下，使用形式化的统计框架区分内在噪声和外在噪声；第二，为一个特定的 mRNA 表达随机模型推导法诺因子。\n\n在细胞群体中，某个分子种类拷贝数 $n$ 的总噪声或变异性，可以通过其方差 $\\operatorname{Var}(n)$ 来量化。通过应用全方差定律，这个总方差可以分解为两个不同的分量，分别称为内在噪声和外在噪声。设 $\\mathbf{Z}$ 是一个随机变量向量，代表细胞环境或背景的状态，该状态在不同细胞间波动。这些变量可能包括聚合酶、核糖体、代谢酶的浓度、细胞体积或细胞周期阶段。全方差定律表述为：\n$$\n\\operatorname{Var}(n) = \\mathbb{E}[\\operatorname{Var}(n | \\mathbf{Z})] + \\operatorname{Var}(\\mathbb{E}[n | \\mathbf{Z}])\n$$\n右边的两项分别对应内在噪声和外在噪声。\n\n1.  **内在噪声**：项 $\\mathbb{E}[\\operatorname{Var}(n | \\mathbf{Z})]$ 量化了内在噪声。条件方差 $\\operatorname{Var}(n | \\mathbf{Z}=\\mathbf{z})$ 表示在共享完全相同外在状态 $\\mathbf{z}$ 的细胞亚群中，拷贝数 $n$ 的变异性。这种变异性源于基因表达生化反应（例如，转录起始、mRNA 降解）固有的随机性，即使在完全恒定的环境中，单个反应事件发生的时间也是一个随机过程。内在噪声是该条件方差的期望值，即对群体中存在的所有可能的外在状态 $\\mathbf{Z}$ 进行平均的结果。\n\n2.  **外在噪声**：项 $\\operatorname{Var}(\\mathbb{E}[n | \\mathbf{Z})]$ 量化了外在噪声。条件期望 $\\mathbb{E}[n | \\mathbf{Z}=\\mathbf{z}]$ 是处于特定外在状态 $\\mathbf{z}$ 的细胞中 $n$ 的平均拷贝数。这个平均水平可能依赖于状态 $\\mathbf{z}$。外在噪声是该条件均值的方差，它捕捉了当外在状态 $\\mathbf{Z}$ 在细胞群体中变化时，平均表达水平本身是如何波动的。它是由细胞间在细胞机制和环境上的差异对总方差造成的贡献。\n\n接下来，我们为给定模型推导法诺因子。该模型包含两个控制 mRNA 拷贝数 $n$ 的过程：\n- **脉冲式生成**：新的 mRNA 分子以脉冲方式产生，脉冲以速率 $k$ 的泊松过程到达。每次脉冲增加 $M$ 个分子，其中 $M$ 是一个服从几何分布的随机变量，对于 $m \\in \\{0, 1, 2, \\dots\\}$ 有 $\\Pr(M=m) = p(1-p)^m$。这些脉冲是独立同分布的。\n- **一阶降解**：每个 mRNA 分子以速率常数 $\\gamma$ 独立降解。$n$ 个分子的总降解速率为 $\\gamma n$。\n\n状态的任意函数 $f(n)$ 的期望值随时间的演化可以从化学主方程 (CME) 出发，使用生成元方法推导得出。$\\mathbb{E}[f(n)]$ 的变化率由 $\\frac{d\\mathbb{E}[f(n)]}{dt} = \\mathbb{E}[\\mathcal{L}f(n)]$ 给出，其中 $\\mathcal{L}$ 是该过程的生成元。对于此模型，作用于 $f(n)$ 的生成元是：\n$$\n\\mathcal{L}f(n) = \\gamma n [f(n-1) - f(n)] + k \\sum_{m=0}^{\\infty} \\Pr(M=m)[f(n+m) - f(n)]\n$$\n为了求稳态矩，我们令 $\\frac{d\\mathbb{E}[f(n)]}{dt} = 0$。\n\n首先，我们通过设 $f(n)=n$ 来推导稳态均值 $\\mathbb{E}[n]$。\n$$\n\\frac{d\\mathbb{E}[n]}{dt} = \\mathbb{E}[\\gamma n ((n-1) - n) + k \\sum_{m=0}^{\\infty} \\Pr(M=m)((n+m) - n)]\n$$\n$$\n\\frac{d\\mathbb{E}[n]}{dt} = \\mathbb{E}[-\\gamma n + k \\sum_{m=0}^{\\infty} m \\Pr(M=m)]\n$$\n求和项是脉冲大小的期望值 $\\mathbb{E}[M]$ 的定义。\n$$\n\\frac{d\\mathbb{E}[n]}{dt} = -\\gamma \\mathbb{E}[n] + k \\mathbb{E}[M]\n$$\n在稳态下，$\\frac{d\\mathbb{E}[n]}{dt}=0$，这给出了稳态均值：\n$$\n\\mathbb{E}[n] = \\frac{k}{\\gamma} \\mathbb{E}[M]\n$$\n\n接下来，我们通过设 $f(n)=n^2$ 来推导稳态二阶矩 $\\mathbb{E}[n^2]$。\n$$\n\\frac{d\\mathbb{E}[n^2]}{dt} = \\mathbb{E}[\\gamma n ((n-1)^2 - n^2) + k \\sum_{m=0}^{\\infty} \\Pr(M=m)((n+m)^2 - n^2)]\n$$\n我们计算方括号内的项：\n- 降解：$\\gamma n(n^2-2n+1-n^2) = \\gamma n(-2n+1) = -2\\gamma n^2 + \\gamma n$。\n- 生成：$k \\sum_{m=0}^{\\infty} \\Pr(M=m)(n^2+2nm+m^2-n^2) = k \\sum_{m=0}^{\\infty} \\Pr(M=m)(2nm+m^2) = k (2n \\sum_{m=0}^{\\infty} m \\Pr(M=m) + \\sum_{m=0}^{\\infty} m^2 \\Pr(M=m)) = k(2n\\mathbb{E}[M] + \\mathbb{E}[M^2])$。\n取期望值得到 $\\mathbb{E}[n^2]$ 的演化方程：\n$$\n\\frac{d\\mathbb{E}[n^2]}{dt} = \\mathbb{E}[-2\\gamma n^2 + \\gamma n + k(2n\\mathbb{E}[M] + \\mathbb{E}[M^2])]\n$$\n$$\n\\frac{d\\mathbb{E}[n^2]}{dt} = -2\\gamma \\mathbb{E}[n^2] + \\gamma \\mathbb{E}[n] + 2k\\mathbb{E}[M]\\mathbb{E}[n] + k\\mathbb{E}[M^2]\n$$\n在稳态下，$\\frac{d\\mathbb{E}[n^2]}{dt}=0$。我们使用稳态关系 $k\\mathbb{E}[M] = \\gamma \\mathbb{E}[n]$ 并代入 $\\mathbb{E}[n^2] = \\operatorname{Var}(n) + (\\mathbb{E}[n])^2$：\n$$\n0 = -2\\gamma (\\operatorname{Var}(n) + (\\mathbb{E}[n])^2) + \\gamma \\mathbb{E}[n] + 2(\\gamma\\mathbb{E}[n])\\mathbb{E}[n] + k\\mathbb{E}[M^2]\n$$\n$$\n0 = -2\\gamma\\operatorname{Var}(n) - 2\\gamma(\\mathbb{E}[n])^2 + \\gamma\\mathbb{E}[n] + 2\\gamma(\\mathbb{E}[n])^2 + k\\mathbb{E}[M^2]\n$$\n包含 $(\\mathbb{E}[n])^2$ 的项相互抵消，方程简化为：\n$$\n2\\gamma\\operatorname{Var}(n) = \\gamma\\mathbb{E}[n] + k\\mathbb{E}[M^2]\n$$\n求解方差 $\\operatorname{Var}(n)$：\n$$\n\\operatorname{Var}(n) = \\frac{1}{2}\\mathbb{E}[n] + \\frac{k}{2\\gamma}\\mathbb{E}[M^2]\n$$\n法诺因子 $F$ 定义为 $F = \\frac{\\operatorname{Var}(n)}{\\mathbb{E}[n]}$。代入均值和方差的表达式：\n$$\nF = \\frac{\\frac{1}{2}\\mathbb{E}[n] + \\frac{k}{2\\gamma}\\mathbb{E}[M^2]}{\\mathbb{E}[n]} = \\frac{1}{2} + \\frac{k\\mathbb{E}[M^2]}{2\\gamma\\mathbb{E}[n]}\n$$\n现在，将 $\\mathbb{E}[n] = \\frac{k}{\\gamma}\\mathbb{E}[M]$ 代入法诺因子的表达式：\n$$\nF = \\frac{1}{2} + \\frac{k\\mathbb{E}[M^2]}{2\\gamma(\\frac{k}{\\gamma}\\mathbb{E}[M])} = \\frac{1}{2} + \\frac{\\mathbb{E}[M^2]}{2\\mathbb{E}[M]}\n$$\n这是一个适用于任何脉冲大小分布的通用结果。问题指定了脉冲大小服从几何分布，其均值为 $b=\\mathbb{E}[M]=\\frac{1-p}{p}$，方差为 $\\operatorname{Var}(M)=\\frac{1-p}{p^2}$。我们必须只用 $b$ 来表示 $F$。\n首先，我们用 $b$ 来表示 $\\operatorname{Var}(M)$。由 $b=\\frac{1-p}{p}=\\frac{1}{p}-1$，我们得到 $\\frac{1}{p}=b+1$。\n$$\n\\operatorname{Var}(M) = \\frac{1-p}{p^2} = \\left(\\frac{1-p}{p}\\right)\\frac{1}{p} = b(b+1)\n$$\n接下来，我们使用关系式 $\\operatorname{Var}(M) = \\mathbb{E}[M^2] - (\\mathbb{E}[M])^2$ 来求 $\\mathbb{E}[M^2]$：\n$$\n\\mathbb{E}[M^2] = \\operatorname{Var}(M) + (\\mathbb{E}[M])^2 = b(b+1) + b^2 = b^2+b+b^2 = 2b^2+b\n$$\n最后，我们将 $\\mathbb{E}[M]=b$ 和 $\\mathbb{E}[M^2]=2b^2+b$ 代入 $F$ 的表达式中：\n$$\nF = \\frac{1}{2} + \\frac{2b^2+b}{2b}\n$$\n假设这是一个非平凡过程，即 $b>0$，我们可以简化为：\n$$\nF = \\frac{1}{2} + \\frac{b(2b+1)}{2b} = \\frac{1}{2} + \\frac{2b+1}{2} = \\frac{1}{2} + b + \\frac{1}{2} = 1+b\n$$\n这个结果表明，法诺因子（一个相对于均值的噪声度量）由一个泊松分量（$1$）和一个与平均脉冲大小（$b$）成线性比例的项组成。",
            "answer": "$$\n\\boxed{1+b}\n$$"
        },
        {
            "introduction": "生物功能通常不是由单个分子完成的，而是由相互作用的分子组成的网络模块涌现出来的。然而，如何在复杂的调控网络中客观地识别这些功能模块是一个重大的挑战。谱图论（spectral graph theory）为此提供了一个强大的数学框架，它利用图拉普拉斯算子（Graph Laplacian）的谱（即特征值和特征向量）来揭示网络的社群结构。\n\n在本练习中，您将应用谱聚类算法来剖析一个加权调控网络。您将学习如何通过分析“特征间隙”（eigen-gap）来确定网络中的模块数量，并进一步将这种结构属性与功能鲁棒性联系起来。这项实践旨在让您掌握一种核心的计算方法，用于从连接组数据中发现生物系统的模块化设计原则。",
            "id": "3305369",
            "problem": "给定一个对称、非负加权的图族，用于模拟调控网络。每个图有 $n$ 个节点、一个邻接矩阵 $W \\in \\mathbb{R}^{n \\times n}$（其中 $W_{ij} = W_{ji} \\ge 0$ 且 $W_{ii} = 0$）、一个由 $d_i = \\sum_{j=1}^n W_{ij}$ 定义的度向量 $d \\in \\mathbb{R}^{n}$，以及一个对角度矩阵 $D = \\mathrm{diag}(d_1,\\dots,d_n)$。定义对称归一化图拉普拉斯算子（Graph Laplacian (GL)）为 $L_{\\mathrm{sym}} = I - D^{-1/2} W D^{-1/2}$，其中 $I$ 是单位矩阵，$D^{-1/2}$ 是对角矩阵，其对角线元素为 $D^{-1/2}_{ii} = d_i^{-1/2}$（当 $d_i > 0$ 时）；如果 $d_i = 0$，则将对应的行和列解释为零项的孤立行列。谱聚类方法选择簇的数量 $k$，并使用 $L_{\\mathrm{sym}}$ 的前 $k$ 个特征向量对节点进行划分。对于一个有序谱 $0 \\le \\lambda_1 \\le \\lambda_2 \\le \\dots \\le \\lambda_n$，连续特征值之间的特征间隙定义为 $\\Delta_i = \\lambda_{i+1} - \\lambda_i$。选择的 $k$ 是使 $\\Delta_k$ 最大的索引（若有多个，则选择最小的 $k$），约束条件为 $1 \\le k \\le n-1$。\n\n从这些基本定义出发，为每个测试实例实现以下内容：\n- 计算 $L_{\\mathrm{sym}}$ 的有序特征值 $\\lambda_1,\\dots,\\lambda_n$ 和相应的标准正交特征向量，计算所有 $i \\in \\{1,\\dots,n-1\\}$ 的间隙 $\\Delta_i$，并如上所述选择 $k$。报告特征间隙的大小 $g^\\star = \\Delta_k$。\n- 将前 $k$ 个特征向量作为列堆叠，形成矩阵 $U \\in \\mathbb{R}^{n \\times k}$。对 $U$ 进行行归一化，使每一行的欧几里得范数为 $1$。然后通过 $k$-均值算法将 $U$ 的 $n$ 行聚为 $k$ 个簇，以最小化簇内平方欧几里得距离之和。\n- 使用以下定义计算聚类的加权模块度 $Q$\n$$\nQ = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left( W_{ij} - \\frac{d_i d_j}{2m} \\right) \\mathbf{1}\\{c_i = c_j\\},\n$$\n其中 $m = \\tfrac{1}{2} \\sum_{i=1}^n d_i$ 是总边权，$c_i \\in \\{1,\\dots,k\\}$ 是节点 $i$ 的簇标签，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数。将 $Q$ 报告为一个实数。\n- 为模块化结构定义一个鲁棒性测试：将所有簇间边的权重置零，生成 $\\widetilde{W}$，其中若 $c_i = c_j$ 则 $\\widetilde{W}_{ij} = W_{ij}$，否则 $\\widetilde{W}_{ij} = 0$。对于每个簇 $\\mathcal{C}$，考虑其邻接矩阵为 $W^{(\\mathcal{C})}$ 的导出子图及其组合拉普拉斯算子 $L^{(\\mathcal{C})} = D^{(\\mathcal{C})} - W^{(\\mathcal{C})}$，其中 $D^{(\\mathcal{C})}_{uu} = \\sum_{v \\in \\mathcal{C}} W^{(\\mathcal{C})}_{uv}$。对每个大小至少为 $2$ 的簇，计算 $L^{(\\mathcal{C})}$ 的第二小特征值 $\\lambda_2^{(\\mathcal{C})}$（即代数连通度）。定义一个小数阈值 $\\tau = 10^{-6}$，如果 $k \\ge 2$ 且对于所有大小至少为 $2$ 的簇都有 $\\lambda_2^{(\\mathcal{C})} > \\tau$（大小为 $1$ 的簇被认为是平凡连通的，在此测试中可以忽略），则返回布尔值 $\\mathrm{robust}$ 为真；否则返回假。\n\n此外，请仅从 $W$、$D$、$L_{\\mathrm{sym}}$ 的定义以及使用前 $k$ 个特征向量进行聚类的概念出发，从算法和数学上证明为何特征间隙 $g^\\star$ 的大小预示着能够增强功能鲁棒性的模块化结构。\n\n测试套件和图构建规则：\n每个测试实例由参数 $(n, \\{\\mathcal{C}_\\ell\\}_{\\ell=1}^r, w_{\\mathrm{intra}}, w_{\\mathrm{inter}})$ 定义，其中 $n$ 是节点数，$\\{\\mathcal{C}_\\ell\\}$ 是将 $\\{1,\\dots,n\\}$ 划分为 $r$ 个非空簇的划分（仅用于构建 $W$；算法必须重新发现结构），$w_{\\mathrm{intra}} \\ge 0$ 是分配给同一构造簇内边的权重，$w_{\\mathrm{inter}} \\ge 0$ 是分配给不同构造簇之间边的权重。邻接矩阵通过以下方式构建\n$$\nW_{ij} = \\begin{cases}\n0  \\text{ if } i=j, \\\\\nw_{\\mathrm{intra}}  \\text{ if } i \\neq j \\text{ and } \\exists \\ell \\text{ with } i \\in \\mathcal{C}_\\ell, j \\in \\mathcal{C}_\\ell, \\\\\nw_{\\mathrm{inter}}  \\text{ if } i \\neq j \\text{ and } \\exists \\ell \\neq \\ell' \\text{ with } i \\in \\mathcal{C}_\\ell, j \\in \\mathcal{C}_{\\ell'}.\n\\end{cases}\n$$\n\n为以下五个测试实例提供结果：\n- 测试 $1$：$n = 6$，构造簇 $\\mathcal{C}_1 = \\{1,2,3\\}$, $\\mathcal{C}_2 = \\{4,5,6\\}$, $w_{\\mathrm{intra}} = 1.0$, $w_{\\mathrm{inter}} = 0.05$。\n- 测试 $2$：$n = 6$，构造簇 $\\mathcal{C}_1 = \\{1,2,3\\}$, $\\mathcal{C}_2 = \\{4,5,6\\}$, $w_{\\mathrm{intra}} = 1.0$, $w_{\\mathrm{inter}} = 0.35$。\n- 测试 $3$：$n = 6$，构造簇 $\\mathcal{C}_1 = \\{1,2,3,4,5,6\\}$, $w_{\\mathrm{intra}} = 0.9$, $w_{\\mathrm{inter}} = 0.9$。\n- 测试 $4$：$n = 6$，构造簇 $\\mathcal{C}_1 = \\{1,2\\}$, $\\mathcal{C}_2 = \\{3,4\\}$, $\\mathcal{C}_3 = \\{5,6\\}$, $w_{\\mathrm{intra}} = 1.0$, $w_{\\mathrm{inter}} = 0.02$。\n- 测试 $5$：$n = 6$，构造簇 $\\mathcal{C}_1 = \\{1,2,3\\}$, $\\mathcal{C}_2 = \\{4,5,6\\}$, $w_{\\mathrm{intra}} = 1.0, w_{\\mathrm{inter}} = 0.0$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[[k_1, g^\\star_1, Q_1, \\mathrm{robust}_1], [k_2, g^\\star_2, Q_2, \\mathrm{robust}_2], \\dots ]$）。每个 $k_i$ 必须是整数，每个 $g^\\star_i$ 和 $Q_i$ 必须是浮点数，每个 $\\mathrm{robust}_i$ 必须是布尔值。不应打印任何其他输出。",
            "solution": "该问题要求使用谱方法对图结构进行多步分析，以识别模块性并评估其鲁棒性。该分析基于对称归一化图拉普拉斯算子 $L_{\\mathrm{sym}}$ 的性质。我们将首先提供该方法的数学和算法论证，然后详细说明实现步骤。\n\n### 数学和算法论证\n\n问题的核心在于使用图拉普拉斯算子的谱来理解网络结构。对称归一化拉普拉斯算子 $L_{\\mathrm{sym}} = I - D^{-1/2} W D^{-1/2}$ 是谱图理论中的核心对象。它的特征值 $0 \\le \\lambda_1 \\le \\lambda_2 \\le \\dots \\le \\lambda_n \\le 2$ 及其对应的特征向量编码了由邻接矩阵 $W$ 表示的图的深层结构信息。\n\n**1. 特征间隙与模块化结构：**\n\n要最好地理解特征间隙和模块性之间的联系，可以从一个理想情况入手。考虑一个由 $k$ 个不连通分量组成的图。在这种情况下，邻接矩阵 $W$ 可以（在重新排序节点后）排列成块对角形式。拉普拉斯算子 $L_{\\mathrm{sym}}$ 也将是块对角的。块对角矩阵的谱是其各个块的谱的并集。对于一个连通图，其拉普拉斯算子的最小特征值为 $\\lambda_1 = 0$，对应的特征向量的元素与 $d_i^{1/2}$ 成正比。对于一个有 $k$ 个连通分量的图，其拉普拉斯算子有一个重数为 $k$ 的特征值 $0$。也就是说，$\\lambda_1 = \\lambda_2 = \\dots = \\lambda_k = 0$，且 $\\lambda_{k+1} > 0$。与零特征值对应的特征空间由在各连通分量上分段常数的向量张成。具体来说，对于每个分量 $\\mathcal{C}$，一个向量 $v$（如果节点 $i \\in \\mathcal{C}$，则其元素 $v_i = d_i^{1/2}$，否则 $v_i=0$）是 $\\lambda=0$ 的一个特征向量。\n\n这导致了一个大的特征间隙 $\\Delta_k = \\lambda_{k+1} - \\lambda_k = \\lambda_{k+1} > 0$。构成矩阵 $U$ 的前 $k$ 个特征向量可以选择成这样：对于任何节点 $i$，其在 $U$ 中对应的行仅在一个位置上非零。同一分量内的所有节点都被映射到 $k$ 维嵌入空间中的同一点。对这些点进行聚类是微不足道的，并且可以完美地恢复这些分量。\n\n现在，考虑一个近可分解图：一个具有 $k$ 个密集簇（模块）的图，这些簇之间连接稀疏。这样的图是 $k$ 个不连通分量理想情况的一个小扰动。由 $w_{\\mathrm{inter}}$ 加权的簇间边充当了扰动。根据矩阵扰动理论，受扰动的拉普拉斯算子 $L_{\\mathrm{sym}}$ 的谱将接近于未受扰动（块对角）的谱。前 $k$ 个特征值 $\\lambda_1, \\dots, \\lambda_k$ 会很小（接近 $0$），而 $\\lambda_{k+1}$ 会明显更大。这导致了一个大的特征间隙 $g^\\star = \\Delta_k = \\lambda_{k+1} - \\lambda_k$。相应的特征向量 $v_1, \\dots, v_k$ 不再是完美的分段常数，而是在这些模块上*近似*分段常数。\n\n当我们用这些特征向量构成矩阵 $U \\in \\mathbb{R}^{n \\times k}$ 时，$U$ 的行（代表节点）将在 $\\mathbb{R}^k$ 中形成紧密且分离良好的束。每个束对应于原始图中的一个模块。这些束很容易被像 $k$-均值这样的聚类算法分开，从而揭示底层的模块化结构。间隙 $g^\\star$ 越大，模块之间的分离就越好，模块化结构也越明显。\n\n**2. 模块性与功能鲁棒性：**\n\n生物网络中的功能鲁棒性通常与功能模块对抗扰动的稳定性有关。该问题通过测试所识别模块的内部连通性来将此概念形式化。在找到一个划分 $\\{c_i\\}$ 后，鲁棒性测试涉及概念上切断所有簇间连接。如果由此产生的孤立子图保持强连通，则认为该模块是鲁棒的。\n\n图的代数连通度由其组合拉普拉斯算子的第二小特征值 $\\lambda_2$ 给出，它量化了图的连通性。$\\lambda_2 > 0$ 的值意味着图是连通的，而更大的 $\\lambda_2$ 值对应于一个“更鲁棒”的连通图，该图更难通过移除边或节点来断开。\n\n该过程为每个已识别的簇 $\\mathcal{C}$（大小至少为2）计算 $\\lambda_2^{(\\mathcal{C})}$。对于一个小的阈值 $\\tau$，条件 $\\lambda_2^{(\\mathcal{C})} > \\tau$ 检查每个模块是否至少是连通的。一个大的特征间隙 $g^\\star$ 意味着该图可以很好地被不连通分量所近似。由于模块是由密集的内部连接定义的（$w_{\\mathrm{intra}}$ 通常远大于 $w_{\\mathrm{inter}}$），每个发现的簇 $\\mathcal{C}$ 预计都是一个密集连接的子图。密集连接的图具有高代数连通度。因此，一个大的特征间隙 $g^\\star$ 预示着一种模块化结构，其中每个模块内部都具有内聚性，因此对于移除其与其他模块的连接具有鲁棒性。这在模块性的谱特征（$g^\\star$）和结构鲁棒性的可量化度量（$\\lambda_2^{(\\mathcal{C})}$）之间建立了直接联系。\n\n### 算法实现步骤\n\n对于每个由 $(n, \\{\\mathcal{C}_\\ell\\}, w_{\\mathrm{intra}}, w_{\\mathrm{inter}})$ 定义的测试用例：\n1.  **构建邻接矩阵 $W$**：创建一个 $n \\times n$ 矩阵，如果节点 $i$ 和 $j$ 在同一个构造簇中，则 $W_{ij}$ 设为 $w_{\\mathrm{intra}}$；如果在不同簇中，则设为 $w_{\\mathrm{inter}}$；如果 $i=j$，则设为 $0$。\n2.  **计算图拉普拉斯算子**：通过对 $W$ 的行求和来计算度向量 $d$。形成对角度矩阵 $D$。对称归一化拉普拉斯算子计算为 $L_{\\mathrm{sym}} = I - D^{-1/2} W D^{-1/2}$。对于任何 $d_i=0$ 的节点 $i$，相应的条目 $D^{-1/2}_{ii}$ 被视为 $0$。\n3.  **特征分解与间隙分析**：计算 $L_{\\mathrm{sym}}$ 的特征值 $\\lambda_1, \\dots, \\lambda_n$ 和标准正交特征向量。特征值按升序排序。计算特征间隙 $\\Delta_i = \\lambda_{i+1} - \\lambda_i$（对于 $i=1, \\dots, n-1$）。簇的数量 $k$ 被确定为使该间隙最大化的索引，即 $k = \\mathrm{arg\\,max}_{i \\in \\{1, \\dots, n-1\\}} \\Delta_i$。若有多个，则选择最小的 $k$。最大间隙大小为 $g^\\star = \\Delta_k$。\n4.  **谱嵌入与聚类**：使用前 $k$ 个特征向量作为列，形成矩阵 $U \\in \\mathbb{R}^{n \\times k}$。$U$ 的每一行都被归一化，使其欧几里得范数为 $1$。然后使用 $k$-均值算法将这 $n$ 个行向量聚为 $k$ 个组。为确保聚类的稳定性和最优性，多次运行带有随机初始化的 $k$-均值算法，并选择最小化总簇内平方距离和的划分。\n5.  **模块度计算**：使用以下公式计算所得划分 $\\{c_i\\}$ 的加权模块度 $Q$：\n    $$\n    Q = \\frac{1}{2m} \\sum_{i,j} \\left( W_{ij} - \\frac{d_i d_j}{2m} \\right) \\mathbf{1}\\{c_i = c_j\\}\n    $$\n    其中 $m=\\frac{1}{2}\\sum_i d_i$ 是所有边的总权重。\n6.  **鲁棒性测试**：确定布尔值 $\\mathrm{robust}$。如果 $k  2$，则将其设置为 `False`。否则，对于每个大小至少为 $2$ 的簇 $\\mathcal{C}$，提取其导出子图。构建该子图的组合拉普拉斯算子 $L^{(\\mathcal{C})}$，并计算其第二小特征值 $\\lambda_2^{(\\mathcal{C})}$（代数连通度）。如果对于任何这样的簇，有 $\\lambda_2^{(\\mathcal{C})} \\le \\tau=10^{-6}$，则 $\\mathrm{robust}$ 设置为 `False`。如果所有这样的簇都通过测试，则 $\\mathrm{robust}$ 为 `True`。\n7.  **存储并报告结果**：为每个测试用例存储元组 $(k, g^\\star, Q, \\mathrm{robust})$。最终输出是这些元组的列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy.cluster.vq import kmeans, vq\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis on all test cases.\n    \"\"\"\n    test_cases = [\n        # Test 1\n        (6, [{0, 1, 2}, {3, 4, 5}], 1.0, 0.05),\n        # Test 2\n        (6, [{0, 1, 2}, {3, 4, 5}], 1.0, 0.35),\n        # Test 3\n        (6, [{0, 1, 2, 3, 4, 5}], 0.9, 0.9),\n        # Test 4\n        (6, [{0, 1}, {2, 3}, {4, 5}], 1.0, 0.02),\n        # Test 5\n        (6, [{0, 1, 2}, {3, 4, 5}], 1.0, 0.0),\n    ]\n\n    all_results = []\n    for n, clusters_def, w_intra, w_inter in test_cases:\n        # Step 1: Construct Adjacency Matrix W\n        W = np.zeros((n, n))\n        node_to_cluster_map = {node: i for i, cl in enumerate(clusters_def) for node in cl}\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                if node_to_cluster_map[i] == node_to_cluster_map[j]:\n                    W[i, j] = W[j, i] = w_intra\n                else:\n                    W[i, j] = W[j, i] = w_inter\n\n        # Step 2: Compute Graph Laplacian L_sym\n        d = np.sum(W, axis=1)\n        D = np.diag(d)\n        \n        D_inv_sqrt_vals = np.zeros(n)\n        d_positive_mask = d > 0\n        D_inv_sqrt_vals[d_positive_mask] = 1.0 / np.sqrt(d[d_positive_mask])\n        D_inv_sqrt = np.diag(D_inv_sqrt_vals)\n        \n        I = np.identity(n)\n        L_sym = I - D_inv_sqrt @ W @ D_inv_sqrt\n\n        # Step 3: Eigendecomposition and Gap Analysis\n        e_vals, e_vecs = np.linalg.eigh(L_sym)\n        \n        # Round eigenvalues to handle numerical precision issues\n        e_vals = np.round(e_vals, 10)\n        \n        gaps = e_vals[1:] - e_vals[:-1]\n        \n        # Find k, constrained to 1 = k = n-1. \n        # Gap indices are 0 to n-2, mapping to k=1 to n-1.\n        if n > 1:\n            k_idx = np.argmax(gaps[:n-1])\n            k = k_idx + 1\n            g_star = gaps[k_idx]\n        else: # single node graph\n            k = 1\n            g_star = 0.0\n\n        # Step 4: Spectral Embedding and Clustering\n        U = e_vecs[:, :k]\n        \n        # Row-normalize U\n        row_norms = np.linalg.norm(U, axis=1, keepdims=True)\n        U_norm = np.zeros_like(U)\n        non_zero_rows = row_norms.flatten() > 0\n        U_norm[non_zero_rows] = U[non_zero_rows] / row_norms[non_zero_rows]\n        \n        # k-means clustering with restarts for stability\n        best_distortion = np.inf\n        best_centroids = None\n        num_restarts = 20\n        # If there's only 1 cluster, results are trivial\n        if k == 1:\n            labels = np.zeros(n, dtype=int)\n        else:\n            for _ in range(num_restarts):\n                centroids, distortion = kmeans(U_norm, k, iter=10)\n                if distortion  best_distortion:\n                    best_distortion = distortion\n                    best_centroids = centroids\n            labels, _ = vq(U_norm, best_centroids)\n        \n        # Step 5: Modularity Calculation\n        m = 0.5 * np.sum(d)\n        if m == 0:\n            Q = 0.0\n        else:\n            Q = 0.0\n            for i in range(n):\n                for j in range(n):\n                    if labels[i] == labels[j]:\n                        Q += (W[i, j] - (d[i] * d[j]) / (2 * m))\n            Q /= (2 * m)\n\n        # Step 6: Robustness Test\n        tau = 1e-6\n        is_robust = False\n        if k >= 2:\n            is_robust = True\n            unique_labels = np.unique(labels)\n            for label in unique_labels:\n                cluster_nodes = np.where(labels == label)[0]\n                if len(cluster_nodes) >= 2:\n                    W_c = W[np.ix_(cluster_nodes, cluster_nodes)]\n                    d_c = np.sum(W_c, axis=1)\n                    D_c = np.diag(d_c)\n                    L_c = D_c - W_c\n                    \n                    if L_c.shape[0] > 1:\n                        c_e_vals = np.linalg.eigh(L_c)[0]\n                        lambda_2_c = c_e_vals[1]\n                        if lambda_2_c = tau:\n                            is_robust = False\n                            break\n        \n        all_results.append([k, g_star, Q, is_robust])\n\n    # Final print statement\n    result_str = ','.join([f\"[{r[0]},{r[1]:.8f},{r[2]:.8f},{str(r[3]).lower()}]\" for r in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "生物系统并非总是稳定不变的，它们可能会在特定参数变化下经历剧烈的状态转变，即“临界转换”（critical transition）或分岔（bifurcation）。理解系统何时接近这些“引爆点”对于预测疾病发生或生态系统崩溃至关重要。“临界慢化”（critical slowing down）是系统接近分岔点时普遍出现的一种现象，它为我们提供了预警信号。\n\n本练习利用一个描述分岔点附近动态的经典随机微分方程模型，让您推导方差和自相关这两个关键的统计预警信号。通过这项实践，您将理解当系统恢复平衡的速度变慢时，其状态的波动（方差）和时间记忆（自相关）会如何相应地增大，从而揭示系统内在稳定性的丧失和鲁棒性的降低。",
            "id": "3305415",
            "problem": "考虑一个靠近鞍结分岔的单基因调控模块，其在稳定平衡点周围的线性化动力学由以下带加性白噪声的随机微分方程 (SDE) 建模：$$\\mathrm{d}x(t) = -k(\\mu)\\, x(t)\\,\\mathrm{d}t + \\sigma\\, \\mathrm{d}W_t,$$ 其中 $x(t)$ 是与平衡点的偏差，$W_t$ 是一个标准维纳过程（布朗运动），$\\sigma  0$ 是噪声振幅，而 $k(\\mu) = k_0\\left(\\mu_c - \\mu\\right)$ 是恢复速率，它线性地依赖于与临界参数值 $\\mu_c$ 的距离，其中 $k_0  0$ 且 $\\mu  \\mu_c$ 以确保稳定性。该设定是计算系统生物学中临界慢化和预警信号的经典模型，其中通过动力系统和随机过程来研究涌现性和鲁棒性。\n\n从这个 SDE 和由白噪声驱动的线性系统的稳态性定义出发，用参数 $k(\\mu)$、$\\sigma$ 和采样间隔 $\\Delta t$ 表示，推导出稳态自协方差函数、在采样间隔 $\\Delta t$ 下的滞后-1自相关（定义为滞后 $\\Delta t$ 的自协方差除以零滞后自协方差）以及稳态方差。展示当 $\\mu \\to \\mu_c^{-}$（等价于 $k(\\mu) \\to 0^{+}$）时这些量如何标度变化，并解释为什么它们的行为构成了生物系统中脆弱性、鲁棒性及模块性丧失的预警信号。\n\n实现一个程序，使用推导出的表达式，为以下每组参数计算滞后-1自相关和稳态方差。对时间和状态使用无量纲单位。然后，仅使用前三种情况，通过对 $\\log$-方差 与 $\\log k(\\mu)$ 拟合一条直线（通过最小二乘法）来计算标度指数，并返回其斜率。此外，仅使用按 $\\mu$ 递增顺序排列的前三种情况，如果当 $\\mu$ 接近 $\\mu_c$ 时（即当 $k(\\mu)$ 减小时），滞后-1自相关和稳态方差都单调增加，则返回布尔值 $\\mathrm{True}$，否则返回 $\\mathrm{False}$。\n\n测试套件（每种情况为 $(\\mu, \\mu_c, k_0, \\sigma, \\Delta t)$）：\n- 情况 1：$(0.2, 1.0, 1.0, 0.5, 0.1)$\n- 情况 2：$(0.99, 1.0, 1.0, 0.5, 0.1)$\n- 情况 3：$(0.0, 1.0, 1.0, 0.5, 0.1)$\n- 情况 4：$(0.99, 1.0, 1.0, 0.0, 0.1)$\n- 情况 5：$(0.99, 1.0, 1.0, 0.5, 10.0)$\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按顺序包含：对于五种情况中的每一种，首先是滞后-1自相关，然后是稳态方差，接着是仅使用情况1-3估算的标度指数，最后是仅使用按 $\\mu$ 递增顺序排列的情况1-3计算的预警布尔值。例如，格式应为 $$[\\rho_1^{(1)}, \\operatorname{Var}^{(1)}, \\rho_1^{(2)}, \\operatorname{Var}^{(2)}, \\rho_1^{(3)}, \\operatorname{Var}^{(3)}, \\rho_1^{(4)}, \\operatorname{Var}^{(4)}, \\rho_1^{(5)}, \\operatorname{Var}^{(5)}, s, \\mathrm{EWS}],$$ 其中每个 $\\rho_1^{(i)}$ 和 $\\operatorname{Var}^{(i)}$ 是一个浮点数，$s$ 是一个浮点数，而 $\\mathrm{EWS}$ 是一个布尔值。不允许有其他输出。",
            "solution": "该问题的核心在于分析单基因调控模块的随机微分方程 (SDE)，它是Ornstein-Uhlenbeck过程的一种形式：\n$$ \\mathrm{d}x(t) = -k(\\mu)\\, x(t)\\,\\mathrm{d}t + \\sigma\\, \\mathrm{d}W_t $$\n此处，$x(t)$ 是状态与平衡点的偏差，$k(\\mu) = k_0(\\mu_c - \\mu)$ 是稳定性或恢复速率，其中 $k_0 > 0$ 且 $\\mu  \\mu_c$ 确保 $k(\\mu)>0$ 从而保证稳定性。$\\sigma$ 是加性白噪声的强度，由维纳过程的微分 $\\mathrm{d}W_t$ 表示。\n\n这是一个线性SDE，其解是高斯过程。在稳态下，该过程的均值为 $\\mathbb{E}[x(t)]=0$。我们首先推导稳态方差 $\\operatorname{Var}(x) = \\mathbb{E}[x(t)^2]$。这可以通过求解相应的福克-普朗克方程的稳态解，或更直接地通过求解SDE的方差演化方程得到。$\\operatorname{Var}(x)$ 的动态演化由以下方程描述：\n$$ \\frac{d\\operatorname{Var}(x)}{dt} = -2k(\\mu)\\operatorname{Var}(x) + \\sigma^2 $$\n在稳态下，$\\frac{d\\operatorname{Var}(x)}{dt} = 0$，我们得到稳态方差：\n$$ \\operatorname{Var}(x) = \\frac{\\sigma^2}{2k(\\mu)} $$\n接下来，我们推导自协方差函数 $\\gamma(\\tau) = \\mathbb{E}[x(t)x(t+\\tau)]$。对于Ornstein-Uhlenbeck过程，稳态自协方差函数为：\n$$ \\gamma(\\tau) = \\operatorname{Var}(x) e^{-k(\\mu)|\\tau|} $$\n滞后-$\\Delta t$的自协方差为 $\\gamma(\\Delta t) = \\frac{\\sigma^2}{2k(\\mu)} e^{-k(\\mu)\\Delta t}$。\n\n滞后-1自相关 $\\rho_1$ 定义为滞后 $\\Delta t$ 的自协方差除以零滞后自协方差（即方差）：\n$$ \\rho_1 = \\frac{\\gamma(\\Delta t)}{\\gamma(0)} = \\frac{\\operatorname{Var}(x) e^{-k(\\mu)\\Delta t}}{\\operatorname{Var}(x)} = e^{-k(\\mu)\\Delta t} $$\n\n当系统接近临界点，即 $\\mu \\to \\mu_c^{-}$ 时，恢复速率 $k(\\mu) = k_0(\\mu_c - \\mu) \\to 0^{+}$。这导致：\n1.  **稳态方差**：$\\operatorname{Var}(x) = \\frac{\\sigma^2}{2k(\\mu)} \\to \\infty$。方差以 $k(\\mu)^{-1}$ 的标度发散。\n2.  **滞后-1自相关**：$\\rho_1 = e^{-k(\\mu)\\Delta t} \\to e^0 = 1$。\n\n这种方差的增加和自相关趋向于1的现象被称为“临界慢化”。系统恢复到平衡点的速度变得极慢，导致扰动在系统中的记忆时间变长（高自相关），累积的波动幅度也更大（高方差）。因此，这两个统计量的增加构成了系统鲁棒性丧失和接近临界转换的通用预警信号。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by deriving and calculating early-warning signals\n    for a single-gene regulatory module near a saddle-node bifurcation.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (mu, mu_c, k0, sigma, delta_t)\n    test_cases = [\n        (0.2, 1.0, 1.0, 0.5, 0.1),  # Case 1\n        (0.99, 1.0, 1.0, 0.5, 0.1), # Case 2\n        (0.0, 1.0, 1.0, 0.5, 0.1),  # Case 3\n        (0.99, 1.0, 1.0, 0.0, 0.1), # Case 4\n        (0.99, 1.0, 1.0, 0.5, 10.0),# Case 5\n    ]\n\n    all_results = []\n    case_data = {}  # Dictionary to store results for post-processing\n\n    # Process all five cases\n    for i, case in enumerate(test_cases, 1):\n        mu, mu_c, k0, sigma, delta_t = case\n        \n        # Calculate the restoring rate k(mu)\n        k_val = k0 * (mu_c - mu)\n\n        # Calculate stationary variance: Var = sigma^2 / (2*k)\n        # This holds for k > 0. If sigma is 0, Var is 0.\n        if k_val > 0:\n            variance = (sigma**2) / (2 * k_val)\n        else:\n            # Handle the case k_val = 0. Not expected by problem constraints (mu  mu_c)\n            # but included for robustness.\n            variance = float('inf') if sigma != 0 else 0\n\n        # Calculate lag-1 autocorrelation: rho_1 = exp(-k * delta_t)\n        lag1_autocorr = np.exp(-k_val * delta_t)\n\n        all_results.extend([lag1_autocorr, variance])\n        \n        # Store results for later use in scaling and monotonicity checks\n        case_data[i] = {\n            'mu': mu,\n            'k': k_val,\n            'var': variance,\n            'rho1': lag1_autocorr\n        }\n\n    # Part 2: Compute the scaling exponent using Cases 1, 2, and 3\n    # The theoretical relationship is Var = C * k^(-1), so log(Var) = log(C) - 1*log(k).\n    # The slope of log(Var) vs log(k) should be -1.\n    k_vals_fit = [case_data[1]['k'], case_data[2]['k'], case_data[3]['k']]\n    var_vals_fit = [case_data[1]['var'], case_data[2]['var'], case_data[3]['var']]\n\n    log_k = np.log(k_vals_fit)\n    log_var = np.log(var_vals_fit)\n\n    # Perform a linear fit (degree 1 polynomial) to find the slope\n    slope, _ = np.polyfit(log_k, log_var, 1)\n    scaling_exponent = slope\n    all_results.append(scaling_exponent)\n\n    # Part 3: Compute the early-warning signal (EWS) boolean\n    # Check if both variance and lag-1 autocorrelation increase monotonically\n    # as mu approaches mu_c for Cases 1, 2, 3.\n    # Order cases by increasing mu: Case 3 (mu=0.0), Case 1 (mu=0.2), Case 2 (mu=0.99)\n    ordered_indices = sorted([1, 2, 3], key=lambda i: case_data[i]['mu'])\n    \n    variances_ordered = [case_data[i]['var'] for i in ordered_indices]\n    rhos_ordered = [case_data[i]['rho1'] for i in ordered_indices]\n    \n    # Check for strict monotonicity\n    var_is_monotonic = all(variances_ordered[j]  variances_ordered[j+1] for j in range(len(variances_ordered) - 1))\n    rho_is_monotonic = all(rhos_ordered[j]  rhos_ordered[j+1] for j in range(len(rhos_ordered) - 1))\n\n    ews_boolean = var_is_monotonic and rho_is_monotonic\n    all_results.append(ews_boolean)\n\n    # Final print statement in the exact required format.\n    # The boolean `True` will be converted to the string `True`.\n    # Using a list comprehension to format and then joining.\n    formatted_results = [f\"{x:.15f}\" if isinstance(x, (float, np.floating)) else str(x) for x in all_results[:-1]]\n    formatted_results.append(str(all_results[-1]).lower())\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}