{
    "hands_on_practices": [
        {
            "introduction": "在轨迹推断中，首要任务之一是从高维单细胞数据构建一个能代表细胞状态流形的图结构。本练习将引导你亲手实践一个常用的流程：从点云数据构建一个k-近邻（k-NN）图，将其简化为最小生成树（MST），并利用节点度和介数中心性等图论属性来识别分叉点等关键拓扑特征。这项实践对于理解如何将抽象的数据点转化为具有生物学意义的谱系结构至关重要。",
            "id": "3356218",
            "problem": "给定二维欧几里得空间中的小点云，这些点云旨在表示具有潜在谱系拓扑的简化单细胞状态流形。您必须基于这些点，构建一个对称联合 $k$-近邻 (k-NN) 图，使用欧几里得距离作为边权重计算最小生成树 (MST)，利用节点度和介数中心性识别分支点，并根据第一性原理提供拓扑分类。您的程序必须从图、最短路径、生成树和中心性的基本定义开始实现以下内容，除了通用的稀疏线性代数库外，不得依赖任何专门的图库。\n\n定义和要求：\n- 设 $X \\in \\mathbb{R}^{n \\times d}$ 表示 $d$ 维欧几里得空间中 $n$ 个点的坐标，其中 $d = 2$。对于每个数据集：\n  - 计算所有 $i,j \\in \\{0,\\dots,n-1\\}$ 的成对欧几里得距离 $d_{ij} = \\lVert x_i - x_j \\rVert_2$。\n  - 构建一个对称联合 k-NN 图 $G = (V,E)$，其中 $V = \\{0,\\dots,n-1\\}$，加权邻接矩阵为 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$，具体方法如下：对于每个节点 $i$，找到其 $k$ 个最近邻（不包括 $i$ 本身）的索引集合 $N_k(i)$。如果 $i \\in N_k(j)$ 或 $j \\in N_k(i)$，则包含一条无向边 $\\{i,j\\}$，并为此类边设置 $W_{ij} = W_{ji} = d_{ij}$，否则 $W_{ij} = 0$。\n  - 在图 $G$ 上计算一个最小生成树 $T$，该树最小化总权重 $\\sum_{\\{i,j\\} \\in T} W_{ij}$，且 $T$ 是由 $G$ 导出的连通图上的一棵生成树。\n  - 计算 MST $T$ 中每个节点 $v$ 的度 $\\deg_T(v)$。\n  - 计算 MST $T$ 中每个节点 $v$ 的（未归一化）介数中心性 $C_B(v)$，其定义为\n    $$C_B(v) = \\sum_{\\substack{s \\ne v \\ne t \\\\ s \\ne t}} \\frac{\\sigma_{st}(v)}{\\sigma_{st}},$$\n    其中 $\\sigma_{st}$ 是 $s$ 和 $t$ 之间的最短路径数量，$\\sigma_{st}(v)$ 是其中经过 $v$ 的路径数量。对于一个边权重严格为正的树，任意两个不同节点 $s$ 和 $t$ 之间存在唯一的简单路径，因此 $\\sigma_{st} = 1$，该总和计算的是其唯一路径经过 $v$ 的无序点对的数量。\n  - 识别分支点集合\n    $$B = \\left\\{ v \\in V \\;:\\; \\deg_T(v) \\ge 3 \\;\\wedge\\; C_B(v) \\ge \\overline{C_B} \\right\\},$$\n    其中 $\\overline{C_B}$ 是 $T$ 中所有节点的 $C_B$ 值的算术平均值。\n  - 定义拓扑分类代码 $c$ 如下：\n    - $c = 0$ 如果没有分支，即 $\\max_v \\deg_T(v) \\le 2$（线性轨迹）。\n    - $c = 1$ 如果存在单个分支事件，且只有一个分支点，并且 $\\max_v \\deg_T(v) = 3$（单分叉样拓扑）。\n    - $c = 2$ 对于其他情况（多分叉或多个分支事件）。\n\n您的程序必须为下面测试套件中的每个数据集实现上述过程，并生成汇总结果。\n\n测试套件：\n对于每种情况，给定一个点集 $X$ 和一个邻域大小 $k$。点以有序对及其从零开始的索引形式列出。请完全按照指定的坐标使用。\n\n- 情况 1（预期的单分叉）：\n  - $k = 2$。\n  - 点集 $X \\subset \\mathbb{R}^2$ 及其索引：\n    - $0$: $(0,-2)$,\n    - $1$: $(0,-1)$,\n    - $2$: $(0,0)$,\n    - $3$: $(1,1)$,\n    - $4$: $(2,2)$,\n    - $5$: $(3,3)$,\n    - $6$: $(-1,1)$,\n    - $7$: $(-2,2)$,\n    - $8$: $(-3,3)$。\n\n- 情况 2（预期的线性轨迹）：\n  - $k = 2$。\n  - 点集 $X \\subset \\mathbb{R}^2$ 及其索引：\n    - $0$: $(0,0)$,\n    - $1$: $(1,0)$,\n    - $2$: $(2,0)$,\n    - $3$: $(3,0)$,\n    - $4$: $(4,0)$。\n\n- 情况 3（预期的从原点发出三臂的单分支）：\n  - $k = 2$。\n  - 点集 $X \\subset \\mathbb{R}^2$ 及其索引：\n    - $0$: $(0,0)$,\n    - $1$: $(1,0)$,\n    - $2$: $(2,0)$,\n    - $3$: $(3,0)$,\n    - $4$: $(-0.5,0.866)$,\n    - $5$: $(-1,1.732)$,\n    - $6$: $(-1.5,2.598)$,\n    - $7$: $(-0.5,-0.866)$,\n    - $8$: $(-1,-1.732)$,\n    - $9$: $(-1.5,-2.598)$。\n\n每种情况所需的最终输出：\n- 一个包含四个元素的列表 $[b, m, c, I]$，其中：\n  - $b$ 是识别出的分支点数量 $|B|$（一个整数）。\n  - $m$ 是最大度 $\\max_v \\deg_T(v)$（一个整数）。\n  - $c$ 是如上定义的分类代码（一个整数）。\n  - $I$ 是识别出的分支点 $B$ 的从零开始的索引的排序列表。\n\n程序的最终输出格式：\n- 您的程序应生成单行输出，其中包含所有情况的结果，形式为一个无空格的、由方括号括起来的逗号分隔列表，其中每种情况的结果都是上面描述的四元素列表。例如，输出格式必须与此完全一样\n  $$[[b_1,m_1,c_1,[i_{1,1},\\dots]],[b_2,m_2,c_2,[i_{2,1},\\dots]],[b_3,m_3,c_3,[i_{3,1},\\dots}]]$$\n打印行中没有任何空白字符。\n\n此问题不要求物理单位、角度单位或百分比。",
            "solution": "用户提供了一个单细胞轨迹推断领域的计算问题。我将首先验证问题陈述，然后提供一个遵循指定约束的完整解决方案。\n\n### 问题验证\n\n**步骤 1：提取给定信息**\n\n- **输入数据**：点集 $X \\in \\mathbb{R}^{n \\times 2}$ 和一个整数 $k$。\n- **流程**：\n    1.  **距离矩阵**：计算成对欧几里得距离 $d_{ij} = \\lVert x_i - x_j \\rVert_2$。\n    2.  **对称 k-NN 图**：构建一个图 $G=(V, E)$，其边权重为 $W_{ij} = d_{ij}$。如果节点 $i$ 在节点 $j$ 的 $k$ 个最近邻集合 $N_k(j)$ 中，或者 $j \\in N_k(i)$，则存在一条无向边 $\\{i,j\\}$。\n    3.  **最小生成树 (MST)**：在图 $G$ 上计算一个 MST，记为 $T$。\n    4.  **节点度**：计算 MST 中每个节点 $v$ 的度 $\\deg_T(v)$。\n    5.  **介数中心性**：计算 $T$ 中每个节点 $v$ 的未归一化介数中心性 $C_B(v) = \\sum_{s \\ne v \\ne t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}$。在树中，这计算了经过 $v$ 的节点对 $(s,t)$ 之间的唯一路径数量。\n    6.  **分支点识别**：如果节点 $v$ 属于集合 $B = \\{ v \\in V \\mid \\deg_T(v) \\ge 3 \\wedge C_B(v) \\ge \\overline{C_B} \\}$，则它是一个分支点，其中 $\\overline{C_B}$ 是所有 $C_B(v)$ 值的平均值。\n    7.  **拓扑分类**：根据以下规则分配一个代码 $c$：\n        - $c = 0$ 如果 $\\max_v \\deg_T(v) \\le 2$。\n        - $c = 1$ 如果 $|B| = 1$ 并且 $\\max_v \\deg_T(v) = 3$。\n        - $c = 2$ 其他情况。\n- **测试用例**：提供了三个不同的数据集，每个数据集都有一个点集 $X$ 和一个 $k$ 值。\n- **输出格式**：对于每种情况，生成一个列表 $[b, m, c, I]$，其中 $b=|B|$，$m=\\max_v \\deg_T(v)$，$c$ 是分类代码，$I$ 是分支点索引的排序列表。最终输出必须是包含这些结果列表的单行，格式化为无空格。\n\n**步骤 2：使用提取的给定信息进行验证**\n\n- **科学依据**：该问题在计算系统生物学领域有充分的科学依据，特别是它反映了从单细胞数据进行轨迹推断的常见流程。所使用的方法（k-NN 图、MST、中心性）是像 Monocle 和 TSCAN 这类算法中的标准方法。该问题在科学上是有效且相关的。\n- **定义明确**：该问题以数学精度进行了规定。所有术语如“对称联合 k-NN 图”、“MST”、“介数中心性”以及“分支点”和“拓扑分类”的标准都得到了明确的定义。给定输入，该过程是确定性的，并将产生唯一且有意义的解决方案。\n- **客观性**：问题陈述是形式化和定量的，没有任何主观或基于意见的语言。\n- **完整性和一致性**：所有必要的数据（点坐标, $k$）和定义都已提供。定义在逻辑上是一致的，分类方案是详尽的。该问题是自包含的。\n- **可行性**：数据集很小，计算量完全在标准数值库的处理能力之内，即使按要求从头实现核心算法也是如此。该设置是生物状态流形的一个简化但现实的表示。\n\n**步骤 3：结论和行动**\n\n- **结论**：问题是有效的 (VALID)。\n- **行动**：我现在将继续提供一个完整的解决方案。\n\n### 解决方案\n\n该解决方案将作为一个 Python 程序实现，根据指定的流程处理每个测试用例。核心算法——用于 MST 的 Kruskal 算法和树上的中心性计算——将按要求从第一性原理开始实现。\n\n**1. 成对距离计算**\n对于给定的 $X \\in \\mathbb{R}^{n \\times 2}$ 中的 $n$ 个点，我们首先计算对称的 $n \\times n$ 成对欧几里得距离矩阵 $D$，其中 $D_{ij} = \\lVert x_i - x_j \\rVert_2$。\n\n**2. 对称联合 k-NN 图构建**\n我们用零初始化一个 $n \\times n$ 的邻接矩阵 $W$。对于每个点 $i$，我们通过对 $D$ 的第 $i$ 行中的距离进行排序来确定其 $k$ 个最近邻的索引。设 $N_k(i)$ 为这个索引集合（不包括 $i$ 本身）。对称联合规则规定，如果 $i \\in N_k(j)$ 或 $j \\in N_k(i)$，则存在一条边 $\\{i,j\\}$。这可以通过遍历所有点 $i$，找到它们的邻居 $N_k(i)$，并对每个 $j \\in N_k(i)$，将 $W_{ij}$ 和 $W_{ji}$ 都设置为距离 $D_{ij}$ 来实现。这个过程能正确地形成联合。\n\n**3. 最小生成树 (MST) 计算**\n我们使用 Kruskal 算法来找到由 $W$ 表示的图的 MST。\n- 首先，我们创建一个包含所有唯一边 $\\{i,j\\}$ 及其权重 $W_{ij} > 0$ 的列表。\n- 我们按权重的非递减顺序对此边列表进行排序。\n- 我们使用一个不相交集联合 (DSU) 或并查集数据结构，初始化为 $n$ 个集合，每个节点一个。\n- 我们遍历排序后的边。对于每个权重为 $w$ 的边 $(u,v)$，如果包含 $u$ 和 $v$ 的集合的代表（通过 `find(u)` 和 `find(v)` 找到）不同，我们就将该边添加到我们的 MST 中，并使用 `union(u,v)` 合并这两个集合。\n- 一旦我们累积了 $n-1$ 条边，就停止，这样就完成了生成树。生成的 MST 作为邻接表存储，以便进行高效遍历。\n\n**4. 度和介数中心性计算**\n- **度**：MST 中节点 $v$ 的度 $\\deg_T(v)$ 就是连接到它的边的数量，也就是它在邻接表中的条目长度。最大度 $m$ 是通过对所有节点取最大值找到的。\n- **介数中心性**：对于一棵树，节点 $v$ 的中心性 $C_B(v)$ 是指其他节点对 $(s,t)$ 中，从 $s$ 到 $t$ 的唯一简单路径经过 $v$ 的数量。这可以被高效地计算。移除节点 $v$ 会将 MST 分割成 $\\deg_T(v)$ 个连通分量（子树）。设这些分量的大小为 $s_1, s_2, \\dots, s_{\\deg_T(v)}$。任何从分量 $i$ 中的节点到分量 $j$ （其中 $i \\ne j$）中的节点的路径都必须经过 $v$。此类路径的数量是分量大小两两配对的乘积之和：\n$$ C_B(v) = \\sum_{1 \\le i  j \\le \\deg_T(v)} s_i s_j $$\n为了实现这一点，我们首先任意地将树定根（例如，在节点0处）。我们执行一次图遍历（例如，广度优先搜索或深度优先搜索）来确定父子关系，然后进行一次后序遍历来计算以每个节点为根的子树的大小。有了子树的大小，就可以确定任何被移除节点 $v$ 的各连通分量的大小，从而可以计算出 $C_B(v)$。\n\n**5. 分支点识别和拓扑分类**\n- 我们计算所有中心性值的算术平均值 $\\overline{C_B}$。\n- 我们通过选择所有满足 $\\deg_T(v) \\ge 3$ 和 $C_B(v) \\ge \\overline{C_B}$ 的节点 $v$ 来识别分支点集合 $B$。我们计算分支点的数量 $b = |B|$，并创建一个它们的索引的排序列表 $I$。\n- 最后，我们应用所提供的分类规则：\n    - 如果最大度 $m \\le 2$，则拓扑是线性的 ($c=0$)。\n    - 如果只有一个分支点 ($b = 1$) 且最大度恰好为 $3$ ($m = 3$)，则拓扑是单分叉 ($c=1$)。\n    - 在所有其他情况下（例如，多个分支点，或度大于3的分支点），拓扑被分类为复杂的 ($c=2$)。\n\n这整个过程被封装在一个函数中，对每个测试用例调用该函数，然后将结果汇总并以指定格式打印。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport sys\n\n# Increase recursion limit for deep DFS traversals, a good practice for graph algorithms.\nsys.setrecursionlimit(2000)\n\nclass DSU:\n    \"\"\"Disjoint Set Union (Union-Find) data structure for Kruskal's algorithm.\"\"\"\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.num_sets = n\n\n    def find(self, i):\n        if self.parent[i] == i:\n            return i\n        self.parent[i] = self.find(self.parent[i])\n        return self.parent[i]\n\n    def union(self, i, j):\n        root_i = self.find(i)\n        root_j = self.find(j)\n        if root_i != root_j:\n            self.parent[root_j] = root_i\n            self.num_sets -= 1\n            return True\n        return False\n\ndef process_case(X, k):\n    \"\"\"\n    Processes a single point cloud to determine its lineage topology.\n    \"\"\"\n    n = X.shape[0]\n\n    # 1. Compute pairwise Euclidean distance matrix\n    # Using broadcasting for efficiency.\n    diff = X[:, np.newaxis, :] - X[np.newaxis, :, :]\n    dist_matrix = np.linalg.norm(diff, axis=-1)\n\n    # 2. Construct symmetric union k-NN graph\n    adj_matrix = np.zeros((n, n))\n    for i in range(n):\n        # np.argsort is stable, which aids reproducibility in case of distance ties.\n        # We take indices [1:k+1] to exclude the point itself (distance 0).\n        neighbors = np.argsort(dist_matrix[i, :])[1:k + 1]\n        for j in neighbors:\n            # Symmetric union: add edge if i is neighbor of j or j is neighbor of i.\n            # This implementation correctly builds the union.\n            adj_matrix[i, j] = dist_matrix[i, j]\n            adj_matrix[j, i] = dist_matrix[j, i]\n\n    # 3. Compute Minimum Spanning Tree (MST) using Kruskal's algorithm\n    edges = []\n    for i in range(n):\n        for j in range(i + 1, n):\n            if adj_matrix[i, j] > 0:\n                edges.append((adj_matrix[i, j], i, j))\n    \n    edges.sort()\n\n    dsu = DSU(n)\n    mst_adj = {i: [] for i in range(n)}\n    mst_edges_count = 0\n    for weight, u, v in edges:\n        if dsu.union(u, v):\n            mst_adj[u].append(v)\n            mst_adj[v].append(u)\n            mst_edges_count += 1\n            if mst_edges_count == n - 1:\n                break\n    \n    # 4. Compute MST node degrees\n    degrees = np.array([len(mst_adj[i]) for i in range(n)])\n\n    # 5. Compute betweenness centrality for each node in the MST\n    centrality = np.zeros(n)\n    \n    # Handle the case of an empty or single-node graph\n    if n = 1:\n        return [0, 0 if n == 0 else degrees[0], 0, []]\n\n    # Root the tree arbitrarily at node 0 for traversal\n    root = 0\n    parent = {i: None for i in range(n)}\n    children = {i: [] for i in range(n)}\n    \n    # Build parent/child relationships using BFS\n    q = [root]\n    visited = {root}\n    head = 0\n    while head  len(q):\n        u = q[head]\n        head += 1\n        for v in mst_adj[u]:\n            if v not in visited:\n                visited.add(v)\n                parent[v] = u\n                children[u].append(v)\n                q.append(v)\n\n    # Compute subtree sizes using a post-order traversal\n    subtree_size = {}\n    nodes_post_order = []\n    visited_post = set()\n    \n    def build_post_order(u):\n        visited_post.add(u)\n        for v_child in children[u]:\n            if v_child not in visited_post:\n                build_post_order(v_child)\n        nodes_post_order.append(u)\n    \n    if root not in visited_post:\n      build_post_order(root)\n\n    for u in nodes_post_order:\n        size = 1 + sum(subtree_size[v_child] for v_child in children[u])\n        subtree_size[u] = size\n\n    # Compute centrality based on component sizes\n    for v in range(n):\n        if degrees[v] = 1:\n            centrality[v] = 0\n            continue\n        \n        component_sizes = []\n        for child in children[v]:\n            component_sizes.append(subtree_size[child])\n        if parent[v] is not None:\n            component_sizes.append(n - subtree_size[v])\n        \n        # Centrality is the sum of products of component sizes taken pairwise\n        cb_v = 0\n        total_sum = sum(component_sizes)\n        sum_of_squares = sum(s**2 for s in component_sizes)\n        cb_v = (total_sum**2 - sum_of_squares) / 2\n        centrality[v] = cb_v\n        \n    # 6. Identify branchpoints\n    mean_centrality = np.mean(centrality)\n    branchpoint_indices = []\n    for v in range(n):\n        if degrees[v] >= 3 and centrality[v] >= mean_centrality:\n            branchpoint_indices.append(v)\n    \n    b = len(branchpoint_indices)\n    I = sorted(branchpoint_indices)\n    \n    # 7. Classify topology\n    m = int(np.max(degrees)) if n > 0 else 0\n    \n    c = 0\n    if m = 2:\n        c = 0\n    elif b == 1 and m == 3:\n        c = 1\n    else:\n        c = 2\n        \n    return [b, m, c, I]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the analysis, and print results.\n    \"\"\"\n    test_cases = [\n        (\n            2, # k\n            np.array([\n                [0,-2], [0,-1], [0,0], [1,1], [2,2], [3,3], [-1,1], [-2,2], [-3,3]\n            ])\n        ),\n        (\n            2, # k\n            np.array([\n                [0,0], [1,0], [2,0], [3,0], [4,0]\n            ])\n        ),\n        (\n            2, # k\n            np.array([\n                [0,0], [1,0], [2,0], [3,0], \n                [-0.5,0.866], [-1,1.732], [-1.5,2.598],\n                [-0.5,-0.866], [-1,-1.732], [-1.5,-2.598]\n            ])\n        ),\n    ]\n\n    results = []\n    for k, X in test_cases:\n        result = process_case(X, k)\n        results.append(result)\n\n    # Format the final output string precisely as required, with no spaces.\n    results_str = [str(r).replace(\" \", \"\") for r in results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了在图上测量几何距离，我们还可以用一种更强大的随机过程方法来形式化伪时间。我们可以将细胞间的状态转换建模为随机游走，并将一个细胞的伪时间定义为它到达某个“根”或祖先状态所需的期望时间。本练习通过要求从第一性原理推导控制方程，并将其应用于一个简单的系统，从而巩固这一概念，将马尔可夫链理论与生物建模紧密联系起来。",
            "id": "3356213",
            "problem": "在单细胞转录组学的轨迹推断中，一种伪时间（pseudotime）的形式化方法是，为每个细胞分配一个在细胞-细胞图上进行随机游走首次到达指定祖先（根）状态的期望步数。考虑一个有限、时间齐次的马尔可夫链（MC），其状态空间被划分为一个暂态集 $\\mathcal{T}$ 和一个吸收根 $\\mathcal{R}$。设其转移矩阵的规范分块形式为\n$$\nP \\;=\\; \\begin{pmatrix}\nQ  S \\\\\n0  I\n\\end{pmatrix},\n$$\n其中，$Q$ 是暂态到暂态的子矩阵，$S$ 是暂态到吸收态的子矩阵，$0$ 是一个零矩阵，$I$ 是吸收类（此处为单个根状态）上的单位矩阵。对于每个暂态 $i \\in \\mathcal{T}$，定义到达根 $\\mathcal{R}$ 的首次到达时间为 $\\tau \\equiv \\inf\\{t \\geq 0 : X_t \\in \\mathcal{R}\\}$，期望到达时间为 $h_i \\equiv \\mathbb{E}_i[\\tau]$。在 $\\mathcal{T}$ 上的向量 $\\mathbf{h}$ 产生了一个伪时间，该伪时间在根处为零，并随着到达吸收态的期望步数的增加而严格增加。\n\n任务A（推导）：仅从马尔可夫性质和全期望定律出发，推导出暂态满足的、用 $Q$ 表示的关于 $\\mathbf{h}$ 的线性系统，不得假定任何已有公式。\n\n任务B（在简单链上计算）：考虑一个简单的谱系链，其暂态为 $\\{S_1,S_2,S_3\\}$，吸收根为 $R$，排序为 $(S_1,S_2,S_3,R)$。其转移概率为\n$$\nP \\;=\\; \\begin{pmatrix}\n\\frac{1}{4}  \\frac{1}{4}  0  \\frac{1}{2} \\\\\n\\frac{1}{2}  \\frac{1}{4}  \\frac{1}{4}  0 \\\\\n0  \\frac{1}{2}  \\frac{1}{2}  0 \\\\\n0  0  0  1\n\\end{pmatrix}.\n$$\n精确计算暂态的期望到达时间向量 $\\mathbf{h} = (h_{S_1}, h_{S_2}, h_{S_3})$。将最终答案表示为单个行向量，使用 $\\LaTeX$ 的 $\\verb|pmatrix|$ 并用精确的有理数表示。无需四舍五入，不涉及单位。",
            "solution": "本问题提出了在单细胞转录组学中，使用吸收马尔可夫链理论对伪时间进行形式化。问题分为两部分：一是期望到达时间方程组的理论推导，二是在一个给定的小型系统上进行具体计算。该问题提法明确，科学上可靠，并包含唯一解所需的所有信息。\n\n任务A：推导期望到达时间的线性系统。\n\n设时间齐次马尔可夫链的状态空间被划分为一个暂态集 $\\mathcal{T}$ 和一个吸收态集 $\\mathcal{R}$。在本问题中，$\\mathcal{R}$ 只包含一个根状态。设 $X_t$ 为过程在时间 $t$ 的状态。到达集合 $\\mathcal{R}$ 的首次到达时间定义为 $\\tau \\equiv \\inf\\{t \\geq 0 : X_t \\in \\mathcal{R}\\}$。我们需要求出从每个暂态 $i \\in \\mathcal{T}$ 出发的期望到达时间 $h_i$，其定义为 $h_i \\equiv \\mathbb{E}_i[\\tau] = \\mathbb{E}[\\tau | X_0 = i]$。\n\n根据定义，如果过程从吸收态 $j \\in \\mathcal{R}$ 开始，到达时间为 $0$，因此 $h_j = 0$。如果过程从暂态 $i \\in \\mathcal{T}$ 开始，它至少需要一步，因此 $\\tau \\geq 1$。我们可以使用全期望定律，以第一步的结果为条件。时间 $t=1$ 时的状态是 $X_1$。\n\n一步分析法（First-step analysis）得出以下关于 $h_i$ 的关系：\n$$\nh_i = \\mathbb{E}_i[\\tau] = 1 + \\mathbb{E}_i[\\text{additional time to reach } \\mathcal{R} \\text{ after the first step}]\n$$\n设过程从 $X_0=i$ 开始。经过一步后，它以概率 $P_{ij} = P(X_1=j | X_0=i)$ 转移到状态 $j$。根据马尔可夫性质，从状态 $j$ 到达吸收态的剩余时间，与从状态 $j$ 开始的总到达时间具有相同的分布。因此，在给定 $X_1=j$ 的条件下，期望的额外时间就是 $h_j$。\n\n使用全期望定律，我们可以将期望的额外时间写为：\n$$\n\\mathbb{E}_i[\\text{additional time}] = \\sum_{j \\in \\mathcal{T} \\cup \\mathcal{R}} P(X_1 = j | X_0 = i) \\mathbb{E}[\\tau | X_0 = j] = \\sum_{j \\in \\mathcal{T} \\cup \\mathcal{R}} P_{ij} h_j\n$$\n因此，对于任何暂态 $i \\in \\mathcal{T}$，我们有以下关系：\n$$\nh_i = 1 + \\sum_{j \\in \\mathcal{T} \\cup \\mathcal{R}} P_{ij} h_j\n$$\n我们可以将求和分为对暂态集 $\\mathcal{T}$ 和吸收态集 $\\mathcal{R}$ 的求和：\n$$\nh_i = 1 + \\sum_{j \\in \\mathcal{T}} P_{ij} h_j + \\sum_{j \\in \\mathcal{R}} P_{ij} h_j\n$$\n如前所述，对于任何 $j \\in \\mathcal{R}$，$h_j = 0$。该方程可简化为：\n$$\nh_i = 1 + \\sum_{j \\in \\mathcal{T}} P_{ij} h_j\n$$\n暂态 $i, j \\in \\mathcal{T}$ 之间的转移概率由子矩阵 $Q$ 给出，其中 $Q_{ij} = P_{ij}$。所以，对于每个 $i \\in \\mathcal{T}$：\n$$\nh_i = 1 + \\sum_{j \\in \\mathcal{T}} Q_{ij} h_j\n$$\n这代表一个线性方程组，每个暂态 $i$ 对应一个方程。设 $|\\mathcal{T}| = k$。设 $\\mathbf{h}$ 是一个 $k \\times 1$ 的列向量，其元素为 $i \\in \\mathcal{T}$ 的期望到达时间 $h_i$；设 $\\mathbf{1}$ 是一个元素全为1的 $k \\times 1$ 列向量。该方程组可以写成矩阵形式：\n$$\n\\mathbf{h} = \\mathbf{1} + Q \\mathbf{h}\n$$\n整理各项以合并未知数 $\\mathbf{h}$，我们得到：\n$$\n\\mathbf{h} - Q \\mathbf{h} = \\mathbf{1}\n$$\n$$\n(I - Q) \\mathbf{h} = \\mathbf{1}\n$$\n其中 $I$ 是 $k \\times k$ 的单位矩阵。这就是暂态的期望到达时间向量 $\\mathbf{h}$ 所满足的线性系统。其解由 $\\mathbf{h} = (I - Q)^{-1} \\mathbf{1}$ 给出，前提是矩阵 $(I - Q)$ 是可逆的。在任何吸收马尔可夫链中，只要所有暂态都能到达一个吸收态，这个逆矩阵（称为基本矩阵 $N = (I-Q)^{-1}$）就总是存在的。\n\n任务B：在一个简单的谱系链上进行计算。\n\n给定的马尔可夫链在状态 $\\{S_1, S_2, S_3, R\\}$ 上的转移矩阵为：\n$$\nP \\;=\\; \\begin{pmatrix}\n\\frac{1}{4}  \\frac{1}{4}  0  \\frac{1}{2} \\\\\n\\frac{1}{2}  \\frac{1}{4}  \\frac{1}{4}  0 \\\\\n0  \\frac{1}{2}  \\frac{1}{2}  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n$$\n暂态为 $\\mathcal{T} = \\{S_1, S_2, S_3\\}$，吸收根为 $\\mathcal{R}=\\{R\\}$。暂态到暂态的转移子矩阵 $Q$ 是 $P$ 的左上角 $3 \\times 3$ 分块：\n$$\nQ = \\begin{pmatrix}\n\\frac{1}{4}  \\frac{1}{4}  0 \\\\\n\\frac{1}{2}  \\frac{1}{4}  \\frac{1}{4} \\\\\n0  \\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n$$\n我们需要求解系统 $(I-Q)\\mathbf{h} = \\mathbf{1}$，其中 $\\mathbf{h} = (h_{S_1}, h_{S_2}, h_{S_3})^T$。首先，我们计算矩阵 $I-Q$：\n$$\nI - Q = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} - \\begin{pmatrix}\n\\frac{1}{4}  \\frac{1}{4}  0 \\\\\n\\frac{1}{2}  \\frac{1}{4}  \\frac{1}{4} \\\\\n0  \\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix} = \\begin{pmatrix}\n\\frac{3}{4}  -\\frac{1}{4}  0 \\\\\n-\\frac{1}{2}  \\frac{3}{4}  -\\frac{1}{4} \\\\\n0  -\\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n$$\n我们记 $h_1 = h_{S_1}$，$h_2 = h_{S_2}$ 以及 $h_3 = h_{S_3}$。线性系统为：\n$$\n\\begin{pmatrix}\n\\frac{3}{4}  -\\frac{1}{4}  0 \\\\\n-\\frac{1}{2}  \\frac{3}{4}  -\\frac{1}{4} \\\\\n0  -\\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n\\begin{pmatrix}\nh_1 \\\\\nh_2 \\\\\nh_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\\n1 \\\\\n1\n\\end{pmatrix}\n$$\n这对应于以下三个方程：\n1. $\\frac{3}{4}h_1 - \\frac{1}{4}h_2 = 1$\n2. $-\\frac{1}{2}h_1 + \\frac{3}{4}h_2 - \\frac{1}{4}h_3 = 1$\n3. $-\\frac{1}{2}h_2 + \\frac{1}{2}h_3 = 1$\n\n由方程(3)，我们可以用 $h_2$ 表示 $h_3$：\n$h_3 - h_2 = 2 \\implies h_3 = h_2 + 2$。\n\n由方程(1)，我们可以用 $h_1$ 表示 $h_2$：\n$3h_1 - h_2 = 4 \\implies h_2 = 3h_1 - 4$。\n\n现在我们可以用 $h_1$ 表示 $h_3$：\n$h_3 = (3h_1 - 4) + 2 = 3h_1 - 2$。\n\n将 $h_2$ 和 $h_3$ 的这些表达式代入方程(2)。首先，将方程(2)乘以 $4$ 以消去分数：\n$-2h_1 + 3h_2 - h_3 = 4$。\n现在代入：\n$-2h_1 + 3(3h_1 - 4) - (3h_1 - 2) = 4$。\n$-2h_1 + 9h_1 - 12 - 3h_1 + 2 = 4$。\n合并包含 $h_1$ 的项：\n$(-2+9-3)h_1 - 10 = 4$。\n$4h_1 = 14$。\n$h_1 = \\frac{14}{4} = \\frac{7}{2}$。\n\n求得 $h_1$ 后，我们可以求出 $h_2$ 和 $h_3$：\n$h_2 = 3h_1 - 4 = 3\\left(\\frac{7}{2}\\right) - 4 = \\frac{21}{2} - \\frac{8}{2} = \\frac{13}{2}$。\n$h_3 = h_2 + 2 = \\frac{13}{2} + 2 = \\frac{13}{2} + \\frac{4}{2} = \\frac{17}{2}$。\n\n暂态的期望到达时间为 $h_{S_1} = \\frac{7}{2}$，$h_{S_2} = \\frac{13}{2}$ 和 $h_{S_3} = \\frac{17}{2}$。问题要求答案为单个行向量。\n因此，向量 $\\mathbf{h} = (h_{S_1}, h_{S_2}, h_{S_3})$ 为 $\\left(\\frac{7}{2}, \\frac{13}{2}, \\frac{17}{2}\\right)$。\n这些值代表分配给每个细胞状态的伪时间，数值越大对应于在随机游走步数上平均“更远”离根状态的状态。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{7}{2}  \\frac{13}{2}  \\frac{17}{2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "最后，一个关键步骤是将相对的伪时间排序与绝对的、可测量的真实时间联系起来。虽然伪时间捕捉了生物过程的进展，但它是一个没有内在单位的潜在变量。本练习展示了如何利用一部分细胞已知的实验时间点，通过保序回归（isotonic regression）构建一个单调校准函数，从而将推断出的轨迹锚定在真实世界的动态过程中。",
            "id": "3356274",
            "problem": "给定沿分化轨迹的单个细胞的伪时间值 $t$（无量纲），以及其中一部分细胞的捕获时间 $\\tau$（单位为小时）。目标是通过求解以下约束最小二乘问题，构建一个校准函数 $f:[0,1]\\to\\mathbb{R}$，将伪时间 $t$ 映射到真实时间 $\\tau$：\n$$\n\\min_{f} \\sum_{i=1}^{n} \\big(f(t_i)-\\tau_i\\big)^2\n$$\n约束条件为 $f$ 在 $t$ 上是单调非递减的。该问题定义了一维保序回归，即在单调函数锥上的一个凸投影。\n\n基于以下基本依据和定义：\n- 伪时间 $t$ 是一个从高维单细胞分子状态中推导出的潜在排序变量，它保留了生物过程中的相对进程。\n- 真实捕获时间 $\\tau$ 是实验中观测到细胞被测量时的时间点（单位为小时）。\n- 平方误差目标函数 $\\sum_{i=1}^{n} \\big(f(t_i)-\\tau_i\\big)^2$ 量化了校准函数 $f$ 在伪时间点上的取值与已知捕获时间之间的差异。\n- 如果对于任意 $t_a \\le t_b$ 都有 $f(t_a) \\le f(t_b)$，则函数 $f$ 是单调非递减的。\n\n开发一个程序，该程序能够：\n1. 仅使用给定的训练数据对 $\\{(t_i,\\tau_i)\\}$，在单调性约束下构建使上述目标函数最小化的校准函数 $f$。\n2. 将 $f$ 定义为一个在按升序排序后的训练伪时间上的左连续、分段常数函数。对于新的伪时间 $t^{\\star}$ 的评估，使用以下规则：\n   - 若 $t^{\\star} \\le \\min_i t_i$，则 $f(t^{\\star}) = f(\\min_i t_i)$。\n   - 若 $t^{\\star} \\ge \\max_i t_i$，则 $f(t^{\\star}) = f(\\max_i t_i)$。\n   - 否则，对于位于训练伪时间之间的 $t^{\\star}$，将 $f(t^{\\star})$ 的值设为与小于或等于 $t^{\\star}$ 的最大训练伪时间相关联的值。\n3. 通过在留出的测试集 $\\{(t_j^{\\text{test}},\\tau_j^{\\text{test}})\\}$ 上计算均方误差（单位为平方小时）来验证校准结果：\n$$\n\\text{MSE} \\;=\\; \\frac{1}{m} \\sum_{j=1}^{m} \\big(f(t_j^{\\text{test}})-\\tau_j^{\\text{test}}\\big)^2,\n$$\n其中 $m$ 是留出的测试点的数量。\n\n单位与格式：\n- 所有捕获时间 $\\tau$ 的单位均为小时。\n- 以十进制浮点数报告均方误差，单位为平方小时。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$。\n\n测试套件：\n使用以下四个测试用例，每个用例都包含训练集和测试集。在所有用例中，伪时间是无量纲的，捕获时间的单位是小时。\n\n用例 $1$（带噪声的总体递增趋势）：\n- 训练伪时间：$[0.04,0.12,0.25,0.40,0.55,0.70,0.85,0.95]$\n- 训练捕获时间（小时）：$[1.92,2.41,3.70,4.60,6.05,6.90,8.35,9.05]$\n- 测试伪时间：$[0.10,0.30,0.60,0.90]$\n- 测试捕获时间（小时）：$[2.30,3.90,6.30,8.70]$\n\n用例 $2$（起始处有重复的伪时间，需要插值和外推）：\n- 训练伪时间：$[0.20,0.20,0.20,0.50,0.70]$\n- 训练捕获时间（小时）：$[3.10,2.90,3.00,5.20,6.90]$\n- 测试伪时间：$[0.20,0.40,0.80]$\n- 测试捕获时间（小时）：$[3.20,4.40,6.80]$\n\n用例 $3$（训练伪时间内的真实时间为常数）：\n- 训练伪时间：$[0.10,0.20,0.50,0.90]$\n- 训练捕获时间（小时）：$[4.00,4.00,4.00,4.00]$\n- 测试伪时间：$[0.00,1.00,0.30]$\n- 测试捕获时间（小时）：$[4.00,4.00,4.00]$\n\n用例 $4$（非单调的带噪声训练目标，需要校正为单调）：\n- 训练伪时间：$[0.15,0.30,0.45,0.60,0.75,0.90]$\n- 训练捕获时间（小时）：$[2.20,3.80,3.70,5.50,5.40,7.60]$\n- 测试伪时间：$[0.20,0.50,0.88]$\n- 测试捕获时间（小时）：$[2.40,4.50,7.16]$\n\n您的程序必须：\n- 仅使用训练数据，实现一个用于一维单调最小二乘校准的精确求解器。\n- 应用上述针对 $f$ 的分段常数、左连续的评估规则，并进行端点截断。\n- 计算并单行打印四个用例的均方误差列表（单位为平方小时），格式为 $[\\text{mse}_1,\\text{mse}_2,\\text{mse}_3,\\text{mse}_4]$。",
            "solution": "该问题要求开发一个程序，通过执行保序回归，将单细胞伪时间校准为真实捕获时间。任务是找到一个单调非递减函数 $f$，将伪时间 $t$ 映射到真实时间 $\\tau$，并最小化给定训练集上的平方误差和。然后使用该函数预测测试集的捕获时间，并计算均方误差 (MSE)。\n\n问题的核心是求解约束最小二乘问题：\n$$\n\\min_{f} \\sum_{i=1}^{n} \\big(f(t_i)-\\tau_i\\big)^2 \\quad \\text{subject to} \\quad t_a \\le t_b \\implies f(t_a) \\le f(t_b)\n$$\n这是一个经典的一维保序回归问题。使用邻近合并算法 (Pool Adjacent Violators Algorithm, PAVA) 可以高效地找到解。得到的函数 $f$ 是一个分段常数函数。问题还规定了如何对新的伪时间值评估此函数。\n\n整个过程可分解为三个主要步骤：\n1.  **预处理训练数据**：PAVA 算法作用于与有序预测变量序列 $x_1  x_2  \\ldots  x_k$ 相对应的值序列 $y_1, y_2, \\ldots, y_k$。所提供的训练数据 $\\{(t_i, \\tau_i)\\}$ 必须首先被处理以适应此结构。具体来说，我们必须处理具有相同伪时间值的多个数据点。在某个伪时间 $t$ 处观测到多个捕获时间 $\\tau$ 时，$f(t)$ 的最优估计是这些捕获时间的平均值。这是因为平均值能够最小化该组点的平方误差和。因此，第一步是按伪时间 $t$ 对训练数据进行排序，对每个唯一的伪时间将其对应的捕获时间 $\\tau_i$ 分组，并计算它们的均值。我们还需要记录每组中的点数，因为这在 PAVA 算法中用作每个唯一数据点的权重。\n\n2.  **使用 PAVA 进行保序回归**：预处理后，我们得到一组唯一的、已排序的伪时间 $t'_1, t'_2, \\ldots, t'_k$、它们对应的平均捕获时间 $\\tau'_1, \\tau'_2, \\ldots, \\tau'_k$ 以及权重 $w_1, w_2, \\ldots, w_k$。然后将 PAVA 算法应用于带权重 $\\boldsymbol{w}$ 的平均捕获时间序列 $\\boldsymbol{\\tau'}$。PAVA 会迭代地识别并解决任何违反非递减约束的情况（即某个值小于其前一个值）。它通过合并违规的相邻点块，并用它们的加权平均值替换其值来实现。重复此过程，直到整个序列变为单调非递减。PAVA 的活动集实现提供了一种高效的线性时间解法。它逐个处理数据点，维护一组单调有序的“块”（合并点）。当一个新点造成违规时，它会与前面的一个或多个块合并，直到恢复单调性。\n\n3.  **预测与评估**：PAVA 算法产生校准后的、单调非递减的捕获时间，我们称之为 $\\hat{\\tau}'_1, \\hat{\\tau}'_2, \\ldots, \\hat{\\tau}'_k$，它们对应于唯一的训练伪时间 $t'_1, t'_2, \\ldots, t'_k$。这些数据对 $(t'_j, \\hat{\\tau}'_j)$ 定义了分段常数校准函数 $f$。要在新的测试伪时间 $t^{\\star}$ 上评估此函数，我们遵循指定的规则：\n    -   该函数是分段常数且左连续的。这意味着对于任何 $t^{\\star}$，我们找到满足 $t'_j \\le t^{\\star}$ 的最大训练伪时间 $t'_j$，而 $f(t^{\\star})$ 的值即为 $\\hat{\\tau}'_j$。\n    -   对于超出训练伪时间范围的 $t^{\\star}$ 值，函数值将被截断。如果 $t^{\\star}$ 小于最小的训练伪时间，则函数值为第一个点的值。如果 $t^{\\star}$ 大于最大的训练伪时间，则函数值为最后一个点的值。\n    -   这个评估逻辑可以使用二分搜索高效实现，`numpy.searchsorted` 函数非常适合此任务。\n    -   一旦对测试集中的所有点做出预测 $f(t_j^{\\text{test}})$，均方误差 (MSE) 就按如下方式计算：\n        $$\n        \\text{MSE} = \\frac{1}{m} \\sum_{j=1}^{m} \\big(f(t_j^{\\text{test}})-\\tau_j^{\\text{test}}\\big)^2\n        $$\n将此完整流程应用于提供的四个测试用例中的每一个。\n\n实现将包括三个部分：\n- 一个用于遍历所有测试用例的主函数。\n- 一个用于预处理训练数据的例程，处理排序和重复的伪时间。\n- 一个 PAVA 活动集实现的例程，用于寻找保序拟合。\n- 一个应用指定的分段常数评估规则的预测函数。\n\n例如，在用例 4 中，初始捕获时间 `[2.20, 3.80, 3.70, 5.50, 5.40, 7.60]` 不是单调的。PAVA 首先识别出违规点 $3.70  3.80$，并将这两个值合并为其平均值 $3.75$。序列变为 `[2.20, 3.75, 3.75, 5.50, 5.40, 7.60]`。然后，它识别出违规点 $5.40  5.50$，并将它们合并为其平均值 $5.45$。最终的单调序列是 `[2.20, 3.75, 3.75, 5.45, 5.45, 7.60]`，该序列定义了校准函数 $f$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef pava_solver(y, w):\n    \"\"\"\n    Solves a 1D isotonic regression problem using the Pool Adjacent Violators Algorithm (PAVA).\n    This implementation uses the active-set method, which has O(n) complexity.\n\n    Args:\n        y (np.ndarray): The initial values to be fitted.\n        w (np.ndarray): The weights corresponding to each value in y.\n\n    Returns:\n        np.ndarray: The monotonically non-decreasing fitted values.\n    \"\"\"\n    n = len(y)\n    if n == 0:\n        return np.array([])\n\n    # active_blocks is a list of tuples: (value, weight, start_index)\n    active_blocks = []\n\n    for i in range(n):\n        # Add the current point as a new block\n        active_blocks.append((y[i], w[i], i))\n        \n        # Merge with previous blocks if monotonicity is violated\n        while len(active_blocks) > 1 and active_blocks[-1][0]  active_blocks[-2][0]:\n            # Pop the last two blocks\n            val2, w2, _ = active_blocks.pop()\n            val1, w1, idx1 = active_blocks.pop()\n            \n            # Merge them into a new block\n            new_w = w1 + w2\n            new_val = (val1 * w1 + val2 * w2) / new_w\n            \n            # Add the merged block back\n            active_blocks.append((new_val, new_w, idx1))\n\n    # Unpack the blocks into the final solution array\n    solution = np.zeros(n)\n    for i in range(len(active_blocks)):\n        val, _, start_idx = active_blocks[i]\n        # Determine the end index of the current block\n        end_idx = n\n        if i + 1  len(active_blocks):\n            end_idx = active_blocks[i+1][2]\n        \n        solution[start_idx:end_idx] = val\n        \n    return solution\n\ndef predict_isotonic(t_predict, t_train_unique, f_fit):\n    \"\"\"\n    Predicts values for new data points using a trained isotonic regression model.\n    The function is piecewise constant and left-continuous.\n\n    Args:\n        t_predict (np.ndarray): Pseudotime values for which to predict capture times.\n        t_train_unique (np.ndarray): The unique, sorted training pseudotimes.\n        f_fit (np.ndarray): The fitted monotonic values from PAVA.\n\n    Returns:\n        np.ndarray: The predicted capture times.\n    \"\"\"\n    if t_train_unique.size == 0:\n        return np.full_like(t_predict, np.nan, dtype=float)\n\n    # Find insertion points for t_predict in t_train_unique\n    # 'right' side means if t_predict[i] == t_train_unique[j], index j+1 is returned.\n    indices = np.searchsorted(t_train_unique, t_predict, side='right')\n\n    # The rule is to use the greatest training pseudotime = t_predict.\n    # This corresponds to the index before the insertion point.\n    # For t_predict  t_train_unique[0], index is 0, so we get -1.\n    # For t_predict >= t_train_unique[-1], index is len, so we get len-1.\n    # np.clip handles the boundaries correctly.\n    clipped_indices = np.clip(indices - 1, 0, len(t_train_unique) - 1)\n    \n    return f_fit[clipped_indices]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"train_t\": [0.04, 0.12, 0.25, 0.40, 0.55, 0.70, 0.85, 0.95],\n            \"train_tau\": [1.92, 2.41, 3.70, 4.60, 6.05, 6.90, 8.35, 9.05],\n            \"test_t\": [0.10, 0.30, 0.60, 0.90],\n            \"test_tau\": [2.30, 3.90, 6.30, 8.70]\n        },\n        {\n            \"train_t\": [0.20, 0.20, 0.20, 0.50, 0.70],\n            \"train_tau\": [3.10, 2.90, 3.00, 5.20, 6.90],\n            \"test_t\": [0.20, 0.40, 0.80],\n            \"test_tau\": [3.20, 4.40, 6.80]\n        },\n        {\n            \"train_t\": [0.10, 0.20, 0.50, 0.90],\n            \"train_tau\": [4.00, 4.00, 4.00, 4.00],\n            \"test_t\": [0.00, 1.00, 0.30],\n            \"test_tau\": [4.00, 4.00, 4.00]\n        },\n        {\n            \"train_t\": [0.15, 0.30, 0.45, 0.60, 0.75, 0.90],\n            \"train_tau\": [2.20, 3.80, 3.70, 5.50, 5.40, 7.60],\n            \"test_t\": [0.20, 0.50, 0.88],\n            \"test_tau\": [2.40, 4.50, 7.16]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        t_train = np.array(case[\"train_t\"])\n        tau_train = np.array(case[\"train_tau\"])\n        t_test = np.array(case[\"test_t\"])\n        tau_test = np.array(case[\"test_tau\"])\n\n        # Step 1: Preprocess training data\n        # Sort data pairs by pseudotime\n        sorted_indices = np.argsort(t_train, kind='mergesort') # stable sort\n        t_sorted = t_train[sorted_indices]\n        tau_sorted = tau_train[sorted_indices]\n        \n        # Group by unique pseudotimes and calculate mean capture time and weights\n        unique_t, first_indices, counts = np.unique(\n            t_sorted, return_index=True, return_counts=True\n        )\n        \n        # Split tau_sorted into blocks corresponding to unique_t\n        tau_blocks = np.split(tau_sorted, first_indices[1:])\n        initial_tau = np.array([np.mean(block) for block in tau_blocks])\n        weights = counts\n\n        # Step 2: Perform isotonic regression using PAVA\n        pava_fit = pava_solver(initial_tau, weights)\n\n        # Step 3: Predict on test set and calculate MSE\n        predicted_tau = predict_isotonic(t_test, unique_t, pava_fit)\n        mse = np.mean((predicted_tau - tau_test) ** 2)\n        \n        results.append(mse)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.7f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}