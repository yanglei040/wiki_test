{
    "hands_on_practices": [
        {
            "introduction": "Before integrating multimodal datasets, we must first ensure that the data from each modality is of high quality. For single-cell Assay for Transposase-Accessible Chromatin using sequencing (scATAC-seq), this involves verifying that the chromatin accessibility signal is concentrated in biologically meaningful regions, such as promoters and enhancers, rather than being distributed randomly across the genome. This exercise will guide you through the fundamental process of quality control by having you implement two of the most critical metrics from first principles: Transcription Start Site (TSS) enrichment and the Fraction of Reads in Peaks (FRiP). ",
            "id": "3330229",
            "problem": "You are tasked with formalizing and computing two standard single-cell Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) quality control metrics, then deciding quality control pass or fail for multiple threshold regimes. These metrics are Transcription Start Site (TSS) enrichment and Fraction of Reads in Peaks (FRiP), used prior to multimodal integration with Cellular Indexing of Transcriptomes and Epitopes by sequencing (CITE-seq) and ATAC-seq. The problem is deliberately defined on a toy genome with discrete integer coordinates to emphasize first principles.\n\nAll intervals below are closed intervals on the integer line. A closed interval $[a,b]$ is the set $\\{x \\in \\mathbb{Z} \\mid a \\le x \\le b\\}$. Two closed intervals $[a,b]$ and $[c,d]$ overlap if and only if $\\max(a,c) \\le \\min(b,d)$.\n\nDefinitions to implement:\n\n- Base coverage. Given a cell with a multiset of fragments $\\mathcal{F} = \\{[s_i,e_i]\\}$ and a position $p \\in \\mathbb{Z}$, define the per-base coverage function\n$$\n\\operatorname{cov}(p;\\mathcal{F}) = \\sum_{[s_i,e_i]\\in \\mathcal{F}} \\mathbf{1}\\{s_i \\le p \\le e_i\\},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator of the condition.\n\n- Aggregated TSS profile and TSS enrichment. Let the set of TSS positions be $G = \\{g_1,\\dots,g_{|G|}\\}$ on a single chromosome. Fix a symmetric window radius $W \\in \\mathbb{N}$. For each offset $o \\in \\{-W, -W+1, \\dots, -1, 0, 1, \\dots, W\\}$, define the aggregated offset coverage\n$$\nC(o) = \\sum_{g \\in G} \\operatorname{cov}(g+o;\\mathcal{F}).\n$$\nDefine the central set $S_{\\text{center}} = \\{-1,0,1\\}$ and the background set $S_{\\text{bg}} = \\{-W,\\dots,-2,2,\\dots,W\\}$. Define the mean coverages\n$$\n\\overline{C}(S) = \\frac{1}{|S|} \\sum_{o\\in S} C(o).\n$$\nDefine TSS enrichment\n$$\nE = \\begin{cases}\n\\frac{\\overline{C}(S_{\\text{center}})}{\\overline{C}(S_{\\text{bg}})} & \\text{if } \\overline{C}(S_{\\text{bg}}) > 0, \\\\\n+\\infty & \\text{if } \\overline{C}(S_{\\text{bg}}) = 0 \\text{ and } \\overline{C}(S_{\\text{center}}) > 0, \\\\\n0 & \\text{if } \\overline{C}(S_{\\text{bg}}) = 0 \\text{ and } \\overline{C}(S_{\\text{center}}) = 0.\n\\end{cases}\n$$\n\n- Fraction of Reads in Peaks (FRiP). Let the set of peak intervals be $\\mathcal{P} = \\{[u_j,v_j]\\}$. Let $N_{\\text{frag}} = |\\mathcal{F}|$ be the number of fragments in the cell. Let $N_{\\text{in\\_peaks}}$ be the number of fragments in $\\mathcal{F}$ that overlap at least one peak in $\\mathcal{P}$. Define\n$$\nF = \\begin{cases}\n\\frac{N_{\\text{in\\_peaks}}}{N_{\\text{frag}}} & \\text{if } N_{\\text{frag}} > 0, \\\\\n0 & \\text{if } N_{\\text{frag}} = 0.\n\\end{cases}\n$$\nExpress $F$ as a decimal.\n\n- Quality control pass rule. For thresholds $\\tau_F \\in \\mathbb{R}_{\\ge 0}$, $\\tau_E \\in \\mathbb{R}_{\\ge 0}$, and $\\tau_n \\in \\mathbb{N}_0$, a cell passes if and only if all three conditions hold:\n$$\nN_{\\text{frag}} \\ge \\tau_n,\\quad F \\ge \\tau_F,\\quad E \\ge \\tau_E.\n$$\n\nUse the following fixed toy dataset for all test cases:\n\n- TSS set $G = \\{1000, 2000\\}$.\n\n- Window radius $W = 5$.\n\n- Peak set $\\mathcal{P} = \\{[990,1010], [1990,2005], [3000,3010]\\}$.\n\n- Three cells with fragment sets:\n\n    - Cell $1$: $\\mathcal{F}_1 = \\{[995,1005], [999,1002], [1998,2002], [2999,3001], [4000,4003]\\}$.\n\n    - Cell $2$: $\\mathcal{F}_2 = \\{[985,988], [1008,1012], [1993,1994], [2006,2008], [3005,3005]\\}$.\n\n    - Cell $3$: $\\mathcal{F}_3 = \\{\\}$ (no fragments).\n\nTest suite of threshold triples $(\\tau_F,\\tau_E,\\tau_n)$:\n\n- Test $1$: $(0.5, 2.0, 1)$.\n\n- Test $2$: $(0.8, \\frac{24}{11}, 5)$.\n\n- Test $3$: $(0.0, 0.0, 0)$.\n\n- Test $4$: $(0.9, 3.0, 6)$.\n\nYour program must, for each test case in the order above, compute the number of cells that pass quality control under the given thresholds. Your program should produce a single line of output containing these four integers as a comma-separated list enclosed in square brackets, for example, $[x_1,x_2,x_3,x_4]$ where each $x_i$ is the count of passing cells for test $i$.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of single-cell genomics quality control, is mathematically well-posed, and provides a complete, self-contained set of definitions and data. The use of a toy integer genome is a standard pedagogical simplification to focus on the first-principles implementation of the QC metrics.\n\nThe task is to compute three quality control (QC) metrics for three different single-cell ATAC-seq profiles and then determine, for four different sets of thresholds, how many cells pass QC. The metrics are the number of unique fragments ($N_{\\text{frag}}$), the Fraction of Reads in Peaks ($F$, or FRiP), and the Transcription Start Site (TSS) enrichment score ($E$).\n\nThe overall procedure will be to first calculate the triplet of QC metrics $(N_{\\text{frag}}, F, E)$ for each of the three cells. Subsequently, for each of the four test cases, we will compare the metrics of each cell against the given thresholds $(\\tau_n, \\tau_F, \\tau_E)$ to determine the number of cells that pass.\n\nThe fixed parameters for all calculations are:\n- TSS set $G = \\{1000, 2000\\}$.\n- Window radius $W = 5$.\n- Peak set $\\mathcal{P} = \\{[990,1010], [1990,2005], [3000,3010]\\}$.\n\n**Step 1: Computation of QC Metrics for Each Cell**\n\nWe will compute $(N_{\\text{frag}}, F, E)$ for Cell $1$, Cell $2$, and Cell $3$.\n\n**Cell 1: $\\mathcal{F}_1 = \\{[995,1005], [999,1002], [1998,2002], [2999,3001], [4000,4003]\\}$**\n\n1.  **Number of Fragments ($N_{\\text{frag},1}$):**\n    The number of fragments is the size of the multiset $\\mathcal{F}_1$.\n    $$N_{\\text{frag},1} = |\\mathcal{F}_1| = 5$$\n\n2.  **Fraction of Reads in Peaks ($F_1$):**\n    We count the number of fragments in $\\mathcal{F}_1$ that overlap with at least one peak in $\\mathcal{P}$.\n    - $[995,1005]$ overlaps with $[990,1010]$.\n    - $[999,1002]$ overlaps with $[990,1010]$.\n    - $[1998,2002]$ overlaps with $[1990,2005]$.\n    - $[2999,3001]$ overlaps with $[3000,3010]$.\n    - $[4000,4003]$ does not overlap with any peak in $\\mathcal{P}$.\n    The number of fragments in peaks is $N_{\\text{in\\_peaks},1} = 4$.\n    $$F_1 = \\frac{N_{\\text{in\\_peaks},1}}{N_{\\text{frag},1}} = \\frac{4}{5} = 0.8$$\n\n3.  **TSS Enrichment ($E_1$):**\n    We need to compute the aggregated offset coverage $C(o) = \\sum_{g \\in G} \\operatorname{cov}(g+o;\\mathcal{F}_1)$ for offsets $o \\in \\{-5, \\dots, 5\\}$.\n    The TSSs are at positions $g_1 = 1000$ and $g_2 = 2000$.\n    For a given offset $o$, $C(o) = \\operatorname{cov}(1000+o;\\mathcal{F}_1) + \\operatorname{cov}(2000+o;\\mathcal{F}_1)$.\n\n    The coverages at positions near the TSSs are:\n    - For $o = -5$: $C(-5) = \\operatorname{cov}(995) + \\operatorname{cov}(1995) = 1 + 0 = 1$.\n    - For $o = -4$: $C(-4) = \\operatorname{cov}(996) + \\operatorname{cov}(1996) = 1 + 0 = 1$.\n    - For $o = -3$: $C(-3) = \\operatorname{cov}(997) + \\operatorname{cov}(1997) = 1 + 0 = 1$.\n    - For $o = -2$: $C(-2) = \\operatorname{cov}(998) + \\operatorname{cov}(1998) = 1 + 1 = 2$.\n    - For $o = -1$: $C(-1) = \\operatorname{cov}(999) + \\operatorname{cov}(1999) = 2 + 1 = 3$.\n    - For $o = 0$: $C(0) = \\operatorname{cov}(1000) + \\operatorname{cov}(2000) = 2 + 1 = 3$.\n    - For $o = 1$: $C(1) = \\operatorname{cov}(1001) + \\operatorname{cov}(2001) = 2 + 1 = 3$.\n    - For $o = 2$: $C(2) = \\operatorname{cov}(1002) + \\operatorname{cov}(2002) = 2 + 1 = 3$.\n    - For $o = 3$: $C(3) = \\operatorname{cov}(1003) + \\operatorname{cov}(2003) = 1 + 0 = 1$.\n    - For $o = 4$: $C(4) = \\operatorname{cov}(1004) + \\operatorname{cov}(2004) = 1 + 0 = 1$.\n    - For $o = 5$: $C(5) = \\operatorname{cov}(1005) + \\operatorname{cov(2005)} = 1 + 0 = 1$.\n\n    The mean coverage over the central set $S_{\\text{center}}=\\{-1,0,1\\}$ is:\n    $$\\overline{C}(S_{\\text{center}}) = \\frac{C(-1) + C(0) + C(1)}{3} = \\frac{3+3+3}{3} = 3$$\n    The mean coverage over the background set $S_{\\text{bg}}=\\{-5,-4,-3,-2,2,3,4,5\\}$ is:\n    $$\\overline{C}(S_{\\text{bg}}) = \\frac{C(-5)+C(-4)+C(-3)+C(-2)+C(2)+C(3)+C(4)+C(5)}{8} = \\frac{1+1+1+2+3+1+1+1}{8} = \\frac{11}{8}$$\n    Since $\\overline{C}(S_{\\text{bg}}) > 0$, the enrichment is:\n    $$E_1 = \\frac{\\overline{C}(S_{\\text{center}})}{\\overline{C}(S_{\\text{bg}})} = \\frac{3}{11/8} = \\frac{24}{11}$$\n    The metrics for Cell $1$ are $(N_{\\text{frag},1}, F_1, E_1) = (5, 0.8, \\frac{24}{11})$.\n\n**Cell 2: $\\mathcal{F}_2 = \\{[985,988], [1008,1012], [1993,1994], [2006,2008], [3005,3005]\\}$**\n\n1.  **Number of Fragments ($N_{\\text{frag},2}$):**\n    $$N_{\\text{frag},2} = |\\mathcal{F}_2| = 5$$\n\n2.  **Fraction of Reads in Peaks ($F_2$):**\n    - $[985,988]$: No overlap.\n    - $[1008,1012]$ overlaps with $[990,1010]$.\n    - $[1993,1994]$ overlaps with $[1990,2005]$.\n    - $[2006,2008]$: No overlap.\n    - $[3005,3005]$ overlaps with $[3000,3010]$.\n    The number of fragments in peaks is $N_{\\text{in\\_peaks},2} = 3$.\n    $$F_2 = \\frac{N_{\\text{in\\_peaks},2}}{N_{\\text{frag},2}} = \\frac{3}{5} = 0.6$$\n\n3.  **TSS Enrichment ($E_2$):**\n    For Cell $2$, none of the fragments in $\\mathcal{F}_2$ cover any position $p$ in the ranges $[995, 1005]$ or $[1995, 2005]$. These are the positions $g+o$ for $g \\in G$ and $o \\in \\{-5, \\dots, 5\\}$. Therefore, $\\operatorname{cov}(g+o;\\mathcal{F}_2) = 0$ for all relevant $g$ and $o$.\n    This results in $C(o) = 0$ for all $o \\in \\{-5, \\dots, 5\\}$.\n    Consequently, $\\overline{C}(S_{\\text{center}}) = 0$ and $\\overline{C}(S_{\\text{bg}}) = 0$.\n    According to the definition for this case:\n    $$E_2 = 0$$\n    The metrics for Cell $2$ are $(N_{\\text{frag},2}, F_2, E_2) = (5, 0.6, 0)$.\n\n**Cell 3: $\\mathcal{F}_3 = \\{\\}$**\n\n1.  **Number of Fragments ($N_{\\text{frag},3}$):**\n    $$N_{\\text{frag},3} = |\\mathcal{F}_3| = 0$$\n\n2.  **Fraction of Reads in Peaks ($F_3$):**\n    By definition, if $N_{\\text{frag}}=0$, then $F=0$.\n    $$F_3 = 0$$\n\n3.  **TSS Enrichment ($E_3$):**\n    With no fragments, the coverage is $0$ everywhere. Thus, as with Cell $2$, $\\overline{C}(S_{\\text{center}}) = 0$ and $\\overline{C}(S_{\\text{bg}}) = 0$.\n    $$E_3 = 0$$\n    The metrics for Cell $3$ are $(N_{\\text{frag},3}, F_3, E_3) = (0, 0, 0)$.\n\n**Step 2: Evaluation of Test Cases**\n\nWe use the QC rule: a cell passes if $N_{\\text{frag}} \\ge \\tau_n$, $F \\ge \\tau_F$, and $E \\ge \\tau_E$.\n\n**Summary of Cell Metrics:**\n- Cell $1$: $(5, 0.8, \\frac{24}{11} \\approx 2.18)$\n- Cell $2$: $(5, 0.6, 0)$\n- Cell $3$: $(0, 0, 0)$\n\n**Test 1: $(\\tau_F, \\tau_E, \\tau_n) = (0.5, 2.0, 1)$**\n- Cell $1$: $5 \\ge 1$ (Pass), $0.8 \\ge 0.5$ (Pass), $24/11 \\ge 2.0$ (Pass). $\\implies$ **Pass**\n- Cell $2$: $5 \\ge 1$ (Pass), $0.6 \\ge 0.5$ (Pass), $0 \\ge 2.0$ (Fail). $\\implies$ **Fail**\n- Cell $3$: $0 \\ge 1$ (Fail). $\\implies$ **Fail**\nNumber of passing cells = $1$.\n\n**Test 2: $(\\tau_F, \\tau_E, \\tau_n) = (0.8, \\frac{24}{11}, 5)$**\n- Cell $1$: $5 \\ge 5$ (Pass), $0.8 \\ge 0.8$ (Pass), $24/11 \\ge 24/11$ (Pass). $\\implies$ **Pass**\n- Cell $2$: $5 \\ge 5$ (Pass), $0.6 \\ge 0.8$ (Fail). $\\implies$ **Fail**\n- Cell $3$: $0 \\ge 5$ (Fail). $\\implies$ **Fail**\nNumber of passing cells = $1$.\n\n**Test 3: $(\\tau_F, \\tau_E, \\tau_n) = (0.0, 0.0, 0)$**\n- Cell $1$: $5 \\ge 0$ (Pass), $0.8 \\ge 0.0$ (Pass), $24/11 \\ge 0.0$ (Pass). $\\implies$ **Pass**\n- Cell $2$: $5 \\ge 0$ (Pass), $0.6 \\ge 0.0$ (Pass), $0 \\ge 0.0$ (Pass). $\\implies$ **Pass**\n- Cell $3$: $0 \\ge 0$ (Pass), $0.0 \\ge 0.0$ (Pass), $0.0 \\ge 0.0$ (Pass). $\\implies$ **Pass**\nNumber of passing cells = $3$.\n\n**Test 4: $(\\tau_F, \\tau_E, \\tau_n) = (0.9, 3.0, 6)$**\n- Cell $1$: $5 \\ge 6$ (Fail). $\\implies$ **Fail**\n- Cell $2$: $5 \\ge 6$ (Fail). $\\implies$ **Fail**\n- Cell $3$: $0 \\ge 6$ (Fail). $\\implies$ **Fail**\nNumber of passing cells = $0$.\n\nThe final results are the counts of passing cells for each of the four tests.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes ATAC-seq QC metrics for a toy dataset and determines the number of passing cells\n    for several QC thresholds.\n    \"\"\"\n\n    # --- Fixed Dataset ---\n    G = [1000, 2000]  # TSS set\n    W = 5             # Window radius\n    P = [[990, 1010], [1990, 2005], [3000, 3010]]  # Peak set\n\n    cells_fragments = [\n        # Cell 1\n        [[995, 1005], [999, 1002], [1998, 2002], [2999, 3001], [4000, 4003]],\n        # Cell 2\n        [[985, 988], [1008, 1012], [1993, 1994], [2006, 2008], [3005, 3005]],\n        # Cell 3\n        []\n    ]\n\n    test_cases = [\n        (0.5, 2.0, 1),\n        (0.8, 24/11, 5),\n        (0.0, 0.0, 0),\n        (0.9, 3.0, 6),\n    ]\n    \n    def compute_metrics(fragments, tss_set, peak_set, window_radius):\n        \"\"\"\n        Computes N_frag, FRiP (F), and TSS Enrichment (E) for a single cell.\n        \"\"\"\n        N_frag = len(fragments)\n\n        # Handle the case of an empty cell\n        if N_frag == 0:\n            return (0, 0.0, 0.0)\n\n        # --- Compute Fraction of Reads in Peaks (FRiP) ---\n        N_in_peaks = 0\n        for s_frag, e_frag in fragments:\n            in_any_peak = False\n            for s_peak, e_peak in peak_set:\n                if max(s_frag, s_peak) = min(e_frag, e_peak):\n                    in_any_peak = True\n                    break\n            if in_any_peak:\n                N_in_peaks += 1\n        F = N_in_peaks / N_frag\n\n        # --- Compute TSS Enrichment (E) ---\n        C = {o: 0 for o in range(-window_radius, window_radius + 1)}\n        \n        # Calculate aggregated offset coverage C(o)\n        for g in tss_set:\n            for s_frag, e_frag in fragments:\n                # The offsets o relative to g covered by the fragment are in [s_frag - g, e_frag - g]\n                o_start = s_frag - g\n                o_end = e_frag - g\n                \n                # Iterate through offsets in the intersection of the covered range and the window [-W, W]\n                # to increment the aggregated coverage counts.\n                start_offset = max(-window_radius, o_start)\n                end_offset = min(window_radius, o_end)\n                for o in range(start_offset, end_offset + 1):\n                    C[o] += 1\n        \n        # Calculate mean coverages for center and background\n        s_center_offsets = [-1, 0, 1]\n        s_bg_offsets = list(range(-window_radius, -1)) + list(range(2, window_radius + 1))\n        \n        C_center_values = [C[o] for o in s_center_offsets]\n        C_bg_values = [C[o] for o in s_bg_offsets]\n        \n        mean_C_center = np.mean(C_center_values) if C_center_values else 0.0\n        mean_C_bg = np.mean(C_bg_values) if C_bg_values else 0.0\n        \n        # Apply definition of TSS enrichment E\n        if mean_C_bg > 0:\n            E = mean_C_center / mean_C_bg\n        elif mean_C_center > 0:\n            E = np.inf\n        else:  # mean_C_bg == 0 and mean_C_center == 0\n            E = 0.0\n            \n        return (N_frag, F, E)\n\n    # Calculate metrics for all cells once\n    cell_metrics = []\n    for frags in cells_fragments:\n        metrics = compute_metrics(frags, G, P, W)\n        cell_metrics.append(metrics)\n\n    # Evaluate each test case\n    final_results = []\n    for tau_F, tau_E, tau_n in test_cases:\n        passed_count = 0\n        for n_frag, f, e in cell_metrics:\n            if n_frag >= tau_n and f >= tau_F and e >= tau_E:\n                passed_count += 1\n        final_results.append(passed_count)\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A core challenge in integrating Cellular Indexing of Transcriptomes and Epitopes by sequencing (CITE-seq) and ATAC-seq is that they measure fundamentally different features: gene expression and chromatin accessibility at genomic peaks, respectively. To bridge this gap, a common and powerful technique is to transform the peak-based ATAC-seq data into a gene-centric view by computing \"gene activity scores\". This practice walks you through a standard method for calculating these scores by aggregating accessibility signals from peaks near a gene's promoter, weighted by distance, and then asks you to assess their biological validity by correlating them with matched gene expression data. ",
            "id": "3330201",
            "problem": "Consider the task of integrating Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) chromatin accessibility with Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq) messenger ribonucleic acid (mRNA) expression to assess concordance at the single-cell level. You are given a small peak-by-cell accessibility matrix, peak genomic coordinates, two gene Transcription Start Site (TSS) positions, and a genomic window size in base pairs. Assume the following foundations: chromatin accessibility proximal to a gene’s TSS contributes to its transcriptional activity, and regulatory influence decays with genomic distance from the TSS according to an exponential kernel. You must compute gene activity scores per cell by aggregating accessibility signals from peaks within a symmetric window around the TSS, weight them by the exponential kernel, and then compute the Pearson correlation coefficient between these activity scores and mRNA expression across cells for each gene to assess concordance.\n\nData and parameters:\n1. Peaks are on a single chromosome and represented by closed intervals in base pairs (bp). Peak intervals are:\n$$\nP_1 = [1000,1100],\\quad\nP_2 = [1500,1600],\\quad\nP_3 = [2000,2100],\\quad\nP_4 = [2600,2700],\\quad\nP_5 = [3000,3100].\n$$\nDefine the peak center $c_p$ as the midpoint of its interval.\n\n2. The peak-by-cell accessibility matrix $X \\in \\mathbb{R}^{5 \\times 4}$ (rows are peaks $P_1, \\dots, P_5$; columns are cells $C_1,\\dots,C_4$) is:\n$$\nX = \\begin{bmatrix}\n2  0  1  0 \\\\\n3  1  0  0 \\\\\n0  2  2  0 \\\\\n0  1  0  3 \\\\\n1  0  3  2\n\\end{bmatrix}.\n$$\n\n3. Two genes, with TSS positions (in bp) on the same chromosome, are:\n$$\ng_A: t_A = 1550,\\quad g_B: t_B = 3050.\n$$\n\n4. Messenger ribonucleic acid (mRNA) expression across the same $4$ cells for these genes is provided as:\n$$\ny_A = [5,2,3,0], \\quad y_B = [0,1,0,2].\n$$\n\n5. The exponential decay kernel parameter (length scale) is specified as:\n$$\n\\tau = 500\\ \\text{bp}.\n$$\n\nGene activity computation:\n- For a gene $g$ with TSS $t_g$, and a symmetric window size $w$ (in base pairs), select peaks whose centers satisfy $|c_p - t_g| \\le w$. If no peaks are selected, the activity score vector for $g$ is the zero vector.\n- Define the weight for a selected peak $p$ at distance $d_p = |c_p - t_g|$ as:\n$$\nK(d_p) = \\exp\\left(-\\frac{d_p}{\\tau}\\right).\n$$\n- The gene activity score for gene $g$ in cell $i$ is:\n$$\nA_{g,i}(w) = \\sum_{p:\\ |c_p - t_g| \\le w} X_{p,i}\\, K(|c_p - t_g|).\n$$\n\nConcordance computation:\n- Let $A_g(w) \\in \\mathbb{R}^4$ be the activity scores across the $4$ cells, and $y_g \\in \\mathbb{R}^4$ be the mRNA expression across the same $4$ cells. The Pearson correlation coefficient is defined as:\n$$\nr_g(w) = \n\\begin{cases}\n0,  \\text{if}\\ \\sum_{i=1}^{4} \\left(A_{g,i}(w) - \\bar{A}_g(w)\\right)^2 = 0\\ \\text{or}\\ \\sum_{i=1}^{4} \\left(y_{g,i} - \\bar{y}_g\\right)^2 = 0, \\\\\n\\displaystyle \\frac{\\sum_{i=1}^{4} \\left(A_{g,i}(w) - \\bar{A}_g(w)\\right)\\left(y_{g,i} - \\bar{y}_g\\right)}{\\sqrt{\\sum_{i=1}^{4} \\left(A_{g,i}(w) - \\bar{A}_g(w)\\right)^2}\\ \\sqrt{\\sum_{i=1}^{4} \\left(y_{g,i} - \\bar{y}_g\\right)^2}},  \\text{otherwise},\n\\end{cases}\n$$\nwhere $\\bar{A}_g(w)$ and $\\bar{y}_g$ denote the means of $A_g(w)$ and $y_g$, respectively.\n\nTest suite:\n- Use the following window sizes (in base pairs): \n$$\nw_1 = 600,\\quad w_2 = 0,\\quad w_3 = 400.\n$$\nFor each $w_j$, compute $r_{g_A}(w_j)$ and $r_{g_B}(w_j)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the $6$ correlation results for the test suite, ordered as:\n$$\n\\left[r_{g_A}(w_1), r_{g_B}(w_1), r_{g_A}(w_2), r_{g_B}(w_2), r_{g_A}(w_3), r_{g_B}(w_3)\\right],\n$$\nprinted as a comma-separated list enclosed in square brackets, with the values as floating-point numbers without units (dimensionless).",
            "solution": "We begin from the principle that in eukaryotic gene regulation, open chromatin regions (accessible DNA measured by Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq)) near a gene’s Transcription Start Site (TSS) facilitate transcription initiation, and their regulatory influence declines with genomic distance from the TSS. To model this distance-dependent influence, we adopt a widely used exponential kernel reflecting a decaying contribution of distal regulatory elements. For single-cell concordance assessment, we compare chromatin-derived gene activity scores with messenger ribonucleic acid (mRNA) expression measured by Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq).\n\nDefinitions and derivations:\n1. Peak representation and centers: Each chromatin accessibility peak $p$ is an interval $[s_p, e_p]$ in base pairs (bp) on a chromosome. Its center is:\n$$\nc_p = \\frac{s_p + e_p}{2}.\n$$\nThis center provides a consistent scalar representation for distance computations relative to a gene’s TSS.\n\n2. Window-based selection: For a gene $g$ with TSS at position $t_g$, and a symmetric window size $w$ (in bp), we include peaks whose centers satisfy:\n$$\n|c_p - t_g| \\le w.\n$$\nThis condition enforces a physically meaningful locality constraint around the TSS. The inclusion is defined to be inclusive of the boundary to ensure well-defined behavior at $|c_p - t_g| = w$.\n\n3. Exponential decay kernel: Regulatory influence decays with distance $d_p = |c_p - t_g|$ according to:\n$$\nK(d_p) = \\exp\\left(-\\frac{d_p}{\\tau}\\right),\n$$\nwhere $\\tau > 0$ is a length-scale parameter (in bp). This kernel is consistent with biophysical intuition that the probability of interaction and functional effect of accessible regions decreases approximately exponentially with genomic distance.\n\n4. Gene activity aggregation: Given the peak-by-cell matrix $X \\in \\mathbb{R}^{m \\times n}$ (here $m = 5$, $n = 4$), the gene activity score for gene $g$ in cell $i$ for window size $w$ is:\n$$\nA_{g,i}(w) = \\sum_{p:\\ |c_p - t_g| \\le w} X_{p,i}\\, \\exp\\left(-\\frac{|c_p - t_g|}{\\tau}\\right).\n$$\nIf the selection set is empty, we define $A_g(w)$ to be the zero vector in $\\mathbb{R}^n$, reflecting no accessible regulatory evidence within the window.\n\n5. Concordance via Pearson correlation: To quantify the linear concordance between chromatin-derived activity $A_g(w)$ and mRNA expression $y_g$, the Pearson correlation coefficient is:\n$$\nr_g(w) = \n\\begin{cases}\n0,  \\text{if}\\ \\sum_{i=1}^{n} \\left(A_{g,i}(w) - \\bar{A}_g(w)\\right)^2 = 0\\ \\text{or}\\ \\sum_{i=1}^{n} \\left(y_{g,i} - \\bar{y}_g\\right)^2 = 0, \\\\\n\\displaystyle \\frac{\\sum_{i=1}^{n} \\left(A_{g,i}(w) - \\bar{A}_g(w)\\right)\\left(y_{g,i} - \\bar{y}_g\\right)}{\\sqrt{\\sum_{i=1}^{n} \\left(A_{g,i}(w) - \\bar{A}_g(w)\\right)^2}\\ \\sqrt{\\sum_{i=1}^{n} \\left(y_{g,i} - \\bar{y}_g\\right)^2}},  \\text{otherwise},\n\\end{cases}\n$$\nwith $n = 4$ in this setup, and where $\\bar{A}_g(w)$ and $\\bar{y}_g$ denote the means across cells. The zero-case safeguard handles degenerate scenarios where either vector is constant.\n\nAlgorithmic steps aligned with the above principles:\n- Compute peak centers $c_p$ from the given intervals $[s_p,e_p]$ using $c_p = (s_p + e_p)/2$.\n- For each gene $g \\in \\{g_A,g_B\\}$ and each window size $w \\in \\{w_1, w_2, w_3\\}$, form the selection mask for peaks whose centers satisfy $|c_p - t_g| \\le w$.\n- For selected peaks, compute weights $K(d_p) = \\exp(-d_p/\\tau)$, with $d_p = |c_p - t_g|$ and $\\tau = 500$.\n- Aggregate the activity per cell using the weighted sum across selected peaks:\n$$\nA_{g,i}(w) = \\sum_{p} \\left(\\mathbf{1}\\{|c_p - t_g| \\le w\\}\\, X_{p,i}\\, K(|c_p - t_g|)\\right).\n$$\n- Compute $r_g(w)$ according to the Pearson correlation formula above, including the zero-case handling when standard deviations vanish.\n- Produce the final results as a single list in the order:\n$$\n\\left[r_{g_A}(w_1), r_{g_B}(w_1), r_{g_A}(w_2), r_{g_B}(w_2), r_{g_A}(w_3), r_{g_B}(w_3)\\right].\n$$\n\nThis procedure operationalizes the integration of ATAC-seq accessibility with CITE-seq mRNA expression by deriving an interpretable gene activity score that reflects local chromatin context modulated by distance, and then quantifies concordance via a standard correlation measure. The test suite covers a general case ($w_1$), a boundary case capturing exact TSS-matching peaks ($w_2$), and an edge case testing inclusive window boundaries ($w_3$).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_peak_centers(starts, ends):\n    return (np.array(starts, dtype=float) + np.array(ends, dtype=float)) / 2.0\n\ndef exponential_kernel(distances, tau):\n    return np.exp(-np.abs(distances) / float(tau))\n\ndef compute_activity(X, centers, tss, window, tau):\n    distances = np.abs(centers - float(tss))\n    mask = distances = float(window)\n    if not np.any(mask):\n        # No peaks in window: return zero activity vector\n        return np.zeros(X.shape[1], dtype=float)\n    weights = exponential_kernel(distances[mask], tau)  # shape (k,)\n    X_sel = X[mask, :]  # shape (k, n_cells)\n    # Weighted sum across peaks -> activity per cell\n    activity = (weights[:, None] * X_sel).sum(axis=0)\n    return activity\n\ndef pearson_correlation(x, y):\n    x = np.asarray(x, dtype=float)\n    y = np.asarray(y, dtype=float)\n    # Center\n    x_dev = x - x.mean()\n    y_dev = y - y.mean()\n    ssx = np.dot(x_dev, x_dev)\n    ssy = np.dot(y_dev, y_dev)\n    if ssx == 0.0 or ssy == 0.0:\n        return 0.0\n    num = np.dot(x_dev, y_dev)\n    den = np.sqrt(ssx * ssy)\n    return float(num / den)\n\ndef solve():\n    # Define data from the problem statement.\n    # Peak intervals (bp)\n    starts = [1000, 1500, 2000, 2600, 3000]\n    ends   = [1100, 1600, 2100, 2700, 3100]\n    centers = compute_peak_centers(starts, ends)  # shape (5,)\n\n    # Peak-by-cell ATAC accessibility matrix X (5 peaks x 4 cells)\n    X = np.array([\n        [2, 0, 1, 0],\n        [3, 1, 0, 0],\n        [0, 2, 2, 0],\n        [0, 1, 0, 3],\n        [1, 0, 3, 2]\n    ], dtype=float)\n\n    # Gene TSS positions (bp)\n    tss_A = 1550\n    tss_B = 3050\n\n    # CITE-seq mRNA expression across 4 cells\n    y_A = np.array([5, 2, 3, 0], dtype=float)\n    y_B = np.array([0, 1, 0, 2], dtype=float)\n\n    # Exponential kernel length scale (bp)\n    tau = 500\n\n    # Test suite: window sizes (bp)\n    test_windows = [600, 0, 400]\n\n    results = []\n    for w in test_windows:\n        # Gene A\n        A_A = compute_activity(X, centers, tss_A, w, tau)\n        r_A = pearson_correlation(A_A, y_A)\n        results.append(r_A)\n        # Gene B\n        A_B = compute_activity(X, centers, tss_B, w, tau)\n        r_B = pearson_correlation(A_B, y_B)\n        results.append(r_B)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once data is quality-controlled and features are harmonized, the final step is to perform the integration itself. The Weighted Nearest Neighbor (WNN) algorithm provides a principled framework for this task by learning cell-specific weights that balance the information from each modality. This hands-on exercise deconstructs the WNN algorithm, allowing you to implement its core logic: calculating modality-specific neighborhoods, using cross-modal prediction to derive modality weights, and combining them to construct a single, unified nearest-neighbor graph representing the integrated cellular state. ",
            "id": "3330226",
            "problem": "You are given three synthetic low-dimensional embeddings for a shared set of single cells measured with three modalities: messenger ribonucleic acid (RNA), Antibody-Derived Tags (ADT) from Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq), and chromatin accessibility from Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq). Let the set of modalities be $\\mathcal{M} = \\{\\mathrm{RNA}, \\mathrm{ADT}, \\mathrm{ATAC}\\}$, and let the number of cells be $N$, shared across modalities. For each modality $m \\in \\mathcal{M}$, you are given an embedding matrix $X^{(m)} \\in \\mathbb{R}^{N \\times d_m}$ where row $i$ stores the embedding of cell $i$.\n\nStarting from fundamental definitions, you will implement the following pipeline for a focal cell $c$ and a neighborhood size $k$:\n- Compute modality-specific $k$-nearest neighbors in each modality using Euclidean distance in the embedding space, excluding the focal cell.\n- For each modality, compute a cross-modal prediction error for the focal cell by predicting the focal cell’s embeddings in all modalities from the mean of its $k$-nearest neighbors selected in that source modality.\n- Convert prediction errors into normalized weights via inverse-error normalization to obtain modality weights that sum to one.\n- Form a weighted nearest neighbor score by combining modality-specific similarity kernels using the modality weights, restricted to the union of candidates from all modality-specific neighbor sets. Return the final weighted nearest neighbor list of indices.\n\nUse the following core definitions as the base:\n- The Euclidean distance between vectors $u, v \\in \\mathbb{R}^{d}$ is $d(u,v) = \\lVert u - v \\rVert_2 = \\sqrt{\\sum_{j=1}^{d} (u_j - v_j)^2}$.\n- For a focal cell $c$ and modality $m \\in \\mathcal{M}$, let $d_{c,i}^{(m)} = \\lVert X_c^{(m)} - X_i^{(m)} \\rVert_2$ denote the distance between cell $c$ and another cell $i$ in modality $m$.\n- The $k$-nearest neighbors set $N_c^{(m)}$ consists of the $k$ indices $i \\neq c$ with the smallest $d_{c,i}^{(m)}$. Ties in distance must be resolved by choosing lower cell indices first. The set $N_c^{(m)}$ is ordered by ascending distance (ties broken by increasing index).\n- For each source modality $m \\in \\mathcal{M}$ and each target modality $t \\in \\mathcal{M}$, define the neighbor-mean predictor of the focal cell’s embedding in modality $t$ as\n$$\n\\widehat{X}_{c}^{(t \\mid m)} \\;=\\; \\frac{1}{k} \\sum_{i \\in N_c^{(m)}} X_i^{(t)}.\n$$\n- Define the modality-specific prediction error for the focal cell as the sum of squared Euclidean errors across all modalities:\n$$\nE_c^{(m)} \\;=\\; \\sum_{t \\in \\mathcal{M}} \\left\\lVert X_c^{(t)} \\;-\\; \\widehat{X}_{c}^{(t \\mid m)} \\right\\rVert_2^2.\n$$\n- Convert prediction errors into positive weights via inverse-error normalization with a small numerical stability constant $\\varepsilon$:\n$$\nw_c^{(m)} \\;=\\; \\frac{1}{E_c^{(m)} + \\varepsilon}, \\quad\n\\alpha_c^{(m)} \\;=\\; \\frac{w_c^{(m)}}{\\sum_{r \\in \\mathcal{M}} w_c^{(r)}}.\n$$\n- For each modality $m$, define a similarity kernel between the focal cell $c$ and any candidate neighbor $i$ as\n$$\ns_{c,i}^{(m)} \\;=\\; \\exp\\!\\left( - \\frac{d_{c,i}^{(m)}}{\\sigma_c^{(m)}} \\right),\n$$\nwhere $\\sigma_c^{(m)}$ is the distance to the $k$-th nearest neighbor in modality $m$ for focal cell $c$ (i.e., the largest distance among the $k$ neighbors in $N_c^{(m)}$). If $\\sigma_c^{(m)} \\le \\varepsilon$, use $\\sigma_c^{(m)} = \\varepsilon$ to avoid division by zero.\n- Let the candidate set be the union of the modality-specific neighbors:\n$$\nU_c \\;=\\; N_c^{(\\mathrm{RNA})} \\;\\cup\\; N_c^{(\\mathrm{ADT})} \\;\\cup\\; N_c^{(\\mathrm{ATAC})}.\n$$\n- Define the aggregated weighted similarity score for candidate $i \\in U_c$ as\n$$\nS_{c,i} \\;=\\; \\sum_{m \\in \\mathcal{M}} \\alpha_c^{(m)} \\, s_{c,i}^{(m)}.\n$$\n- The final weighted nearest neighbor list is the list of the top $k$ indices from $U_c$ sorted by descending $S_{c,i}$; ties in $S_{c,i}$ are broken by choosing lower indices first.\n\nYou must use $\\varepsilon = 10^{-8}$. All floating-point outputs must be rounded to six decimal places and expressed as decimals.\n\nDataset. There are $N = 6$ cells shared across modalities with the following embeddings:\n- RNA embedding $X^{(\\mathrm{RNA})} \\in \\mathbb{R}^{6 \\times 3}$:\n  - Cell $0$: $(0.0, 0.0, 0.0)$\n  - Cell $1$: $(0.1, 0.0, 0.0)$\n  - Cell $2$: $(5.0, 0.0, 0.0)$\n  - Cell $3$: $(5.1, 0.1, 0.0)$\n  - Cell $4$: $(10.0, 0.0, 0.0)$\n  - Cell $5$: $(10.1, 0.1, 0.0)$\n- ADT embedding $X^{(\\mathrm{ADT})} \\in \\mathbb{R}^{6 \\times 2}$:\n  - Cell $0$: $(1.0, 1.0)$\n  - Cell $1$: $(1.1, 0.9)$\n  - Cell $2$: $(2.0, 2.0)$\n  - Cell $3$: $(2.1, 2.1)$\n  - Cell $4$: $(1.0, 1.0)$\n  - Cell $5$: $(5.0, 5.0)$\n- ATAC embedding $X^{(\\mathrm{ATAC})} \\in \\mathbb{R}^{6 \\times 4}$:\n  - Cell $0$: $(0.0, 0.0, 1.0, 0.0)$\n  - Cell $1$: $(0.0, 0.0, 0.9, 0.1)$\n  - Cell $2$: $(0.0, 1.0, 0.0, 0.0)$\n  - Cell $3$: $(0.0, 1.1, 0.0, 0.0)$\n  - Cell $4$: $(1.0, 0.0, 0.0, 0.0)$\n  - Cell $5$: $(1.1, 0.0, 0.0, 0.0)$\n\nTest suite. For each parameter pair $(c,k)$ in the following set, compute:\n- the modality-specific neighbor lists $N_c^{(\\mathrm{RNA})}$, $N_c^{(\\mathrm{ADT})}$, $N_c^{(\\mathrm{ATAC})}$;\n- the prediction errors $E_c^{(\\mathrm{RNA})}$, $E_c^{(\\mathrm{ADT})}$, $E_c^{(\\mathrm{ATAC})}$;\n- the normalized weights $\\alpha_c^{(\\mathrm{RNA})}$, $\\alpha_c^{(\\mathrm{ADT})}$, $\\alpha_c^{(\\mathrm{ATAC})}$; and\n- the final weighted nearest neighbor list (top $k$ indices from $U_c$ sorted by descending $S_{c,i}$ with ties broken by increasing index).\n\nUse the test cases:\n- $(c,k) = (2,2)$\n- $(c,k) = (2,3)$\n- $(c,k) = (3,3)$\n\nComputational rules and constraints:\n- All distances must use Euclidean distance as defined.\n- Exclude the focal cell $c$ from all neighbor lists.\n- Ties in distances for $k$-nearest neighbor selection must be resolved by increasing cell index.\n- For the aggregated weighted similarity scoring, ties in $S_{c,i}$ must be resolved by increasing cell index.\n- Use $\\varepsilon = 10^{-8}$ wherever specified.\n- Round all floating-point outputs to six decimal places and express as decimals (no percentages).\n\nFinal output format:\n- For each test case $(c,k)$, produce a list of the form\n$$\n[\\;N_c^{(\\mathrm{RNA})},\\; N_c^{(\\mathrm{ADT})},\\; N_c^{(\\mathrm{ATAC})},\\; [E_c^{(\\mathrm{RNA})}, E_c^{(\\mathrm{ADT})}, E_c^{(\\mathrm{ATAC})}],\\; [\\alpha_c^{(\\mathrm{RNA})}, \\alpha_c^{(\\mathrm{ADT})}, \\alpha_c^{(\\mathrm{ATAC})}],\\; \\mathrm{WNN}_c\\;],\n$$\nwhere each $N_c^{(\\cdot)}$ and $\\mathrm{WNN}_c$ is a list of cell indices, and the error and weight vectors are lists of rounded decimals.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\mathrm{result1},\\mathrm{result2},\\mathrm{result3}]$).",
            "solution": "The problem presents a detailed and self-contained pipeline for multimodal single-cell data integration using a Weighted Nearest Neighbor (WNN) approach. The provided input consists of three synthetic low-dimensional embeddings for a set of $N=6$ cells, corresponding to RNA, ADT (protein), and ATAC (chromatin accessibility) modalities. The task is to compute modality-specific neighbors, cross-modal prediction errors, normalized modality weights, and a final integrated list of nearest neighbors for specified focal cells and neighborhood sizes.\n\nThe problem statement is validated as follows:\n- **Scientific Grounding**: The methodology is a simplified but conceptually correct representation of the WNN algorithm, a widely accepted technique in computational systems biology for integrating multimodal single-cell datasets. The use of Euclidean distance, k-nearest neighbors, cross-modal prediction, and weighted kernel summation are all standard components.\n- **Well-Posedness**: The problem is computationally well-posed. All steps are defined with mathematical precision. Crucially, explicit tie-breaking rules are provided for both the k-nearest neighbor selection (lower cell index first) and the final weighted similarity score sorting (lower cell index first), ensuring a unique solution. The introduction of a numerical stability constant $\\varepsilon$ prevents division by zero.\n- **Objectivity and Completeness**: The problem is stated in objective, formal language. All necessary data, including the embedding matrices $X^{(m)}$, parameters ($c, k, \\varepsilon$), and a complete set of procedural definitions, are provided. The problem is self-contained and free of ambiguity.\n\nThe problem is deemed valid as it is scientifically sound, mathematically rigorous, and fully specified. The solution proceeds by implementing the defined pipeline step-by-step for each of the three test cases.\n\nLet us denote the set of modalities as $\\mathcal{M} = \\{\\mathrm{RNA}, \\mathrm{ADT}, \\mathrm{ATAC}\\}$. We are given the embedding matrices $X^{(\\mathrm{RNA})}$, $X^{(\\mathrm{ADT})}$, and $X^{(\\mathrm{ATAC})}$. The following steps are executed for each test case $(c, k)$:\n\n**1. Modality-Specific $k$-Nearest Neighbors ($N_c^{(m)}$)**\nFor each modality $m \\in \\mathcal{M}$, we compute the Euclidean distance $d_{c,i}^{(m)} = \\lVert X_c^{(m)} - X_i^{(m)} \\rVert_2$ from the focal cell $c$ to every other cell $i \\neq c$. The cells are then ranked by this distance in ascending order. Ties are broken by choosing the cell with the smaller index first. The set $N_c^{(m)}$ contains the indices of the top $k$ cells from this sorted list. We also record $\\sigma_c^{(m)}$, the distance to the $k$-th neighbor in this list, which will be used as a bandwidth parameter.\n\n**2. Cross-Modal Prediction Error ($E_c^{(m)}$)**\nFor each source modality $m$, we use its nearest neighbor set $N_c^{(m)}$ to predict the focal cell's embedding in every target modality $t \\in \\mathcal{M}$. The prediction, $\\widehat{X}_{c}^{(t \\mid m)}$, is the arithmetic mean of the embeddings of the cells in $N_c^{(m)}$ in the target modality $t$:\n$$\n\\widehat{X}_{c}^{(t \\mid m)} \\;=\\; \\frac{1}{k} \\sum_{i \\in N_c^{(m)}} X_i^{(t)}\n$$\nThe total prediction error for source modality $m$, denoted $E_c^{(m)}$, is the sum of the squared Euclidean errors between the true embedding $X_c^{(t)}$ and the predicted embedding $\\widehat{X}_{c}^{(t \\mid m)}$ across all target modalities:\n$$\nE_c^{(m)} \\;=\\; \\sum_{t \\in \\mathcal{M}} \\left\\lVert X_c^{(t)} \\;-\\; \\widehat{X}_{c}^{(t \\mid m)} \\right\\rVert_2^2\n$$\n\n**3. Modality Weight Calculation ($\\alpha_c^{(m)}$)**\nThe prediction errors $\\{E_c^{(m)}\\}_{m \\in \\mathcal{M}}$ are transformed into weights that are inversely proportional to the error. A smaller error for a given source modality implies that its local neighborhood structure is more informative for predicting the cell's state across all measurement types. An intermediate weight $w_c^{(m)}$ is first calculated using a small constant $\\varepsilon = 10^{-8}$ for numerical stability:\n$$\nw_c^{(m)} \\;=\\; \\frac{1}{E_c^{(m)} + \\varepsilon}\n$$\nThese weights are then normalized to sum to one, yielding the final modality weights $\\alpha_c^{(m)}$:\n$$\n\\alpha_c^{(m)} \\;=\\; \\frac{w_c^{(m)}}{\\sum_{r \\in \\mathcal{M}} w_c^{(r)}}\n$$\n\n**4. Weighted Nearest Neighbor (WNN) Integration**\nFirst, a candidate set of neighbors $U_c$ is formed by taking the union of all modality-specific neighbor sets: $U_c = \\bigcup_{m \\in \\mathcal{M}} N_c^{(m)}$.\n\nFor each modality $m$, a similarity kernel $s_{c,i}^{(m)}$ between the focal cell $c$ and each candidate neighbor $i \\in U_c$ is computed using a Gaussian kernel. The distance is scaled by $\\sigma_c^{(m)}$, the distance to the $k$-th nearest neighbor in that modality, which acts as a local bandwidth:\n$$\ns_{c,i}^{(m)} \\;=\\; \\exp\\!\\left( - \\frac{d_{c,i}^{(m)}}{\\sigma_c^{(m)}} \\right)\n$$\nIf $\\sigma_c^{(m)}$ is smaller than $\\varepsilon$, it is set to $\\varepsilon$.\n\nThe final integrated similarity score $S_{c,i}$ for each candidate neighbor $i$ is a weighted sum of these modality-specific similarity kernels, using the weights $\\alpha_c^{(m)}$:\n$$\nS_{c,i} \\;=\\; \\sum_{m \\in \\mathcal{M}} \\alpha_c^{(m)} \\, s_{c,i}^{(m)}\n$$\nThe candidates in $U_c$ are sorted in descending order based on their scores $S_{c,i}$. Ties are resolved by choosing the cell with the smaller index. The final WNN list consists of the top $k$ indices from this sorted list.\n\nThese steps are implemented for each provided test case, with all floating-point results rounded to six decimal places as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the WNN pipeline for multimodal single-cell data integration based on the problem description.\n    \"\"\"\n    # Define the datasets as per the problem statement\n    X_rna = np.array([\n        [0.0, 0.0, 0.0],\n        [0.1, 0.0, 0.0],\n        [5.0, 0.0, 0.0],\n        [5.1, 0.1, 0.0],\n        [10.0, 0.0, 0.0],\n        [10.1, 0.1, 0.0],\n    ])\n\n    X_adt = np.array([\n        [1.0, 1.0],\n        [1.1, 0.9],\n        [2.0, 2.0],\n        [2.1, 2.1],\n        [1.0, 1.0],\n        [5.0, 5.0],\n    ])\n\n    X_atac = np.array([\n        [0.0, 0.0, 1.0, 0.0],\n        [0.0, 0.0, 0.9, 0.1],\n        [0.0, 1.0, 0.0, 0.0],\n        [0.0, 1.1, 0.0, 0.0],\n        [1.0, 0.0, 0.0, 0.0],\n        [1.1, 0.0, 0.0, 0.0],\n    ])\n\n    modalities = {\n        'RNA': X_rna,\n        'ADT': X_adt,\n        'ATAC': X_atac,\n    }\n    \n    num_cells = X_rna.shape[0]\n    modality_keys = ['RNA', 'ADT', 'ATAC']\n    epsilon = 1e-8\n\n    test_cases = [\n        (2, 2),\n        (2, 3),\n        (3, 3),\n    ]\n\n    all_results = []\n\n    for c, k in test_cases:\n        focal_cell_idx = c\n        \n        # Step 1: Compute modality-specific k-nearest neighbors\n        nn_sets = {}\n        sigmas = {}\n        all_distances = {}\n\n        for m_key in modality_keys:\n            X_m = modalities[m_key]\n            focal_vec = X_m[focal_cell_idx]\n            \n            distances = []\n            for i in range(num_cells):\n                if i == focal_cell_idx:\n                    continue\n                dist = np.linalg.norm(focal_vec - X_m[i])\n                distances.append((dist, i))\n            \n            # Sort by distance, then by index for tie-breaking\n            distances.sort()\n            \n            nn_sets[m_key] = [i for dist, i in distances[:k]]\n            sigmas[m_key] = distances[k-1][0] if k > 0 else epsilon\n            \n            # Store all distances for later use\n            all_distances[m_key] = {i: dist for dist, i in distances}\n\n        # Step 2: Compute cross-modal prediction errors\n        errors = {}\n        for m_source_key in modality_keys:\n            total_error = 0.0\n            neighbor_indices = nn_sets[m_source_key]\n\n            for m_target_key in modality_keys:\n                X_target = modalities[m_target_key]\n                \n                # Calculate the mean embedding of neighbors\n                if k > 0:\n                    neighbor_embeddings = X_target[neighbor_indices]\n                    predicted_embedding = np.mean(neighbor_embeddings, axis=0)\n                else: \n                    predicted_embedding = np.zeros(X_target.shape[1])\n                \n                # Get the true embedding of the focal cell\n                true_embedding = X_target[focal_cell_idx]\n                \n                # Calculate squared Euclidean error\n                squared_error = np.sum((true_embedding - predicted_embedding)**2)\n                total_error += squared_error\n            \n            errors[m_source_key] = total_error\n\n        # Step 3: Convert prediction errors to normalized weights\n        raw_weights = {m_key: 1.0 / (errors[m_key] + epsilon) for m_key in modality_keys}\n        sum_raw_weights = sum(raw_weights.values())\n        \n        if sum_raw_weights > 0:\n            norm_weights = {m_key: w / sum_raw_weights for m_key, w in raw_weights.items()}\n        else: # Handle case of all zero weights (unlikely)\n            norm_weights = {m_key: 1.0/len(modality_keys) for m_key in modality_keys}\n\n        # Step 4: Form a weighted nearest neighbor score\n        candidate_set = set()\n        for m_key in modality_keys:\n            candidate_set.update(nn_sets[m_key])\n        \n        candidate_list = sorted(list(candidate_set))\n\n        weighted_scores = []\n        if k > 0:\n            for i in candidate_list:\n                total_score = 0.0\n                for m_key in modality_keys:\n                    # Retrieve the distance to candidate i\n                    dist_ci_m = np.linalg.norm(modalities[m_key][c] - modalities[m_key][i])\n                    \n                    sigma_m = max(sigmas[m_key], epsilon)\n                    \n                    # Similarity kernel\n                    s_cim = np.exp(-dist_ci_m / sigma_m)\n                    \n                    total_score += norm_weights[m_key] * s_cim\n                \n                # Store with negative score for descending sort\n                weighted_scores.append((-total_score, i))\n        \n        # Sort by score (desc), then index (asc)\n        weighted_scores.sort()\n        \n        wnn_list = [i for score, i in weighted_scores[:k]]\n\n        # Format results for output\n        result_Nc = [nn_sets[key] for key in modality_keys]\n        result_E = [round(errors[key], 6) for key in modality_keys]\n        result_alpha = [round(norm_weights[key], 6) for key in modality_keys]\n\n        # Use repr to get the exact list format like [1, 2]\n        formatted_result = (\n            f\"[{repr(result_Nc[0])}, {repr(result_Nc[1])}, {repr(result_Nc[2])}, \"\n            f\"[{result_E[0]:.6f}, {result_E[1]:.6f}, {result_E[2]:.6f}], \"\n            f\"[{result_alpha[0]:.6f}, {result_alpha[1]:.6f}, {result_alpha[2]:.6f}], \"\n            f\"{repr(wnn_list)}]\"\n        )\n        all_results.append(formatted_result)\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        }
    ]
}