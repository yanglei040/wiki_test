{
    "hands_on_practices": [
        {
            "introduction": "The first step in network inference is choosing a measure to quantify the relationship between genes. While Pearson correlation is computationally simple, it only captures linear dependencies. This practice explores a crucial limitation of correlation and highlights the strength of mutual information for detecting the complex, nonlinear interactions often found in biological regulatory systems. By working through this conceptual exercise , you will solidify your understanding of why zero correlation does not imply independence and when a more general measure is required.",
            "id": "3331801",
            "problem": "In computational systems biology, gene regulatory network inference often starts from basic statistical dependencies between gene expression variables. The Pearson correlation coefficient between two random variables $X$ and $Y$ is defined as $\\rho_{XY} = \\dfrac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}$, where $\\operatorname{Cov}(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])]$. Mutual information (MI) is defined for continuous random variables by $I(X;Y) = \\int \\int p_{X,Y}(x,y) \\log \\left( \\dfrac{p_{X,Y}(x,y)}{p_X(x)p_Y(y)} \\right) \\, dx \\, dy$, where $p_{X,Y}$ is the joint density and $p_X$, $p_Y$ are marginals. By definition, $I(X;Y) = 0$ if and only if $X$ and $Y$ are independent, and $I(X;Y) > 0$ when $Y$ probabilistically depends on $X$.\n\nYou are asked to construct a pair of variables that have identical Pearson correlation but different mutual information and to interpret what this means biologically in terms of nonlinear regulation. Consider the following options, each proposing a construction and an interpretation. Select the single option that correctly constructs such a pair and provides a scientifically sound interpretation within gene regulatory network inference.\n\nA. Let $X \\sim \\mathcal{N}(0,1)$ and $\\epsilon \\sim \\mathcal{N}(0,1)$ independent. Define $Y_1 = \\epsilon$ and $Y_2 = X + \\epsilon$. Claim: $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ and $I(X;Y_1) = I(X;Y_2)$ because correlation fully determines mutual information. Biological interpretation: correlation suffices to infer regulation in these cases.\n\nB. Let $X \\sim \\mathcal{N}(0,1)$ and $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ independent, with $\\sigma^2 \\in (0,\\infty)$. Define $Y_1 = \\epsilon$ and $Y_2 = X^2 + \\epsilon$. Claim: $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ while $I(X;Y_1) = 0$ and $I(X;Y_2) > 0$. Biological interpretation: a nonlinear regulatory relationship (e.g., thresholding or cooperative activation) can produce zero correlation but positive mutual information, so relying solely on correlation may miss true regulatory interactions that mutual information can detect.\n\nC. Let $X \\sim \\mathcal{N}(0,1)$. Construct two pairs $(X,Y_1)$ and $(X,Y_2)$ with $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0.6$. Take $Y_1 = X + \\epsilon_1$ and $Y_2 = \\operatorname{sign}(X) + \\epsilon_2$, where $\\epsilon_1,\\epsilon_2$ are independent zero-mean noises chosen so that the correlations match. Claim: $I(X;Y_1) = I(X;Y_2)$ by the data processing inequality, so equal correlation implies equal mutual information. Biological interpretation: both interactions are linear in effect and equally strong.\n\nD. Let $X$ be a symmetric zero-mean continuous variable (for example, $X \\sim \\mathcal{N}(0,1)$), and let $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ be independent with $\\sigma^2 \\in (0,\\infty)$. Define $Y_1 = |X| + \\epsilon$ and $Y_2 = \\epsilon$. Claim: $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ and $I(X;Y_1) = I(X;Y_2) = 0$. Biological interpretation: when correlations are zero, there is no regulation to infer, so mutual information adds nothing.\n\nWhich option is correct?",
            "solution": "### Step 1: Problem Validation\n\n**1.1. Extract Givens:**\n*   **Pearson Correlation Coefficient**: $\\rho_{XY} = \\dfrac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}$\n*   **Covariance**: $\\operatorname{Cov}(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])]$\n*   **Mutual Information (MI) for continuous variables**: $I(X;Y) = \\int \\int p_{X,Y}(x,y) \\log \\left( \\dfrac{p_{X,Y}(x,y)}{p_X(x)p_Y(y)} \\right) \\, dx \\, dy$\n*   **Property of MI**: $I(X;Y) = 0$ if and only if $X$ and $Y$ are independent. $I(X;Y) > 0$ if $Y$ probabilistically depends on $X$.\n*   **Task**: Construct a pair of variables that have identical Pearson correlation but different mutual information and interpret what this means biologically in terms of nonlinear regulation.\n*   **Context**: Computational systems biology, gene regulatory network inference.\n\n**1.2. Validate Using Extracted Givens:**\n*   **Scientifically Grounded**: The definitions of Pearson correlation and mutual information are standard and correct. The problem's premise—that correlation and MI are used in network inference and can give different results—is a central concept in computational biology. The concepts are mathematically and statistically sound.\n*   **Well-Posed**: The task is to find an example that illustrates a known property of correlation vs. MI. The question asks to select the correct construction and interpretation from a list of options. A unique correct option is expected. The problem is well-posed.\n*   **Objective**: The problem is stated using standard mathematical and statistical definitions. The language is precise and unbiased.\n*   **Completeness**: The problem provides all necessary definitions and context to evaluate the options. It's self-contained.\n*   **Realism**: The context of gene regulatory networks is realistic. The use of statistical measures like correlation and MI is standard practice. The models proposed in the options (e.g., $Y = f(X) + \\text{noise}$) are common simplified models for such relationships.\n*   **No other flaws detected**: The problem is not trivial, metaphorical, or contradictory. It addresses a core conceptual point in the field.\n\n**1.3. Verdict and Action:**\nThe problem statement is **valid**. I will proceed with the solution and option evaluation.\n\n### Step 2: Solve the Problem and Evaluate Options\n\nThe core idea is to find a scenario where correlation is zero, but a dependency still exists. Correlation measures *linear* dependency. If the dependency is purely non-linear, correlation can be zero. Mutual information, on the other hand, captures *any* kind of statistical dependency, linear or non-linear.\n\nSo, I need to look for an option where:\n1.  Two pairs of variables are constructed, say $(X, Y_1)$ and $(X, Y_2)$.\n2.  $\\rho_{X,Y_1} = \\rho_{X,Y_2}$. A common choice is $\\rho=0$.\n3.  $I(X;Y_1) \\neq I(X;Y_2)$.\n4.  The interpretation correctly explains why this happens and what it means for network inference.\n\nLet's analyze each option.\n\n---\n\n**Option A:**\n*   **Construction:** $X \\sim \\mathcal{N}(0,1)$, $\\epsilon \\sim \\mathcal{N}(0,1)$ independent. $Y_1 = \\epsilon$, $Y_2 = X + \\epsilon$.\n*   **Analysis of claims:**\n    *   **Correlation for $(X, Y_1)$**: $Y_1 = \\epsilon$. $X$ and $Y_1$ are independent by definition. Therefore, $\\operatorname{Cov}(X, Y_1) = 0$, which implies $\\rho_{X,Y_1} = 0$.\n    *   **Correlation for $(X, Y_2)$**: $Y_2 = X + \\epsilon$.\n        *   $\\mathbb{E}[X] = 0$, $\\mathbb{E}[Y_2] = \\mathbb{E}[X+\\epsilon] = \\mathbb{E}[X] + \\mathbb{E}[\\epsilon] = 0 + 0 = 0$.\n        *   $\\operatorname{Cov}(X, Y_2) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y_2 - \\mathbb{E}[Y_2])] = \\mathbb{E}[X \\cdot Y_2] = \\mathbb{E}[X(X+\\epsilon)] = \\mathbb{E}[X^2 + X\\epsilon] = \\mathbb{E}[X^2] + \\mathbb{E}[X\\epsilon]$.\n        *   Since $X$ and $\\epsilon$ are independent, $\\mathbb{E}[X\\epsilon] = \\mathbb{E}[X]\\mathbb{E}[\\epsilon] = 0 \\cdot 0 = 0$.\n        *   $\\mathbb{E}[X^2] = \\operatorname{Var}(X) + (\\mathbb{E}[X])^2 = 1 + 0^2 = 1$.\n        *   So, $\\operatorname{Cov}(X, Y_2) = 1$.\n        *   $\\operatorname{Var}(X) = 1$.\n        *   $\\operatorname{Var}(Y_2) = \\operatorname{Var}(X+\\epsilon) = \\operatorname{Var}(X) + \\operatorname{Var}(\\epsilon)$ (since $X, \\epsilon$ are independent) $= 1 + 1 = 2$.\n        *   $\\rho_{X,Y_2} = \\dfrac{\\operatorname{Cov}(X, Y_2)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y_2)}} = \\dfrac{1}{\\sqrt{1 \\cdot 2}} = \\dfrac{1}{\\sqrt{2}}$.\n    *   **Conclusion on correlations:** The claim $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ is **false**. We have $\\rho_{X,Y_1} = 0$ and $\\rho_{X,Y_2} = 1/\\sqrt{2}$. The correlations are not identical.\n    *   **Analysis of MI claim:** The claim $I(X;Y_1) = I(X;Y_2)$ because correlation fully determines mutual information is fundamentally **false**. For Gaussian variables, there is a direct relationship ($I = -0.5 \\log(1-\\rho^2)$), but this doesn't hold in general. Here, $Y_2$ is not jointly Gaussian with $X$ in a simple way, rather $(X, Y_2)$ is a bivariate Gaussian.\n        *   $I(X;Y_1) = I(X;\\epsilon) = 0$ since $X$ and $\\epsilon$ are independent.\n        *   For the pair $(X, Y_2)$, since they are correlated, they are not independent, so $I(X;Y_2) > 0$.\n        *   Thus $I(X;Y_1) \\neq I(X;Y_2)$. But the reason given in the option, and the correlation calculation, are wrong.\n*   **Interpretation:** \"correlation suffices to infer regulation in these cases\" is wrong. It contradicts the entire premise of the question.\n*   **Verdict for A:** Incorrect. The calculations are wrong, and the core claim is false.\n\n---\n\n**Option B:**\n*   **Construction:** $X \\sim \\mathcal{N}(0,1)$, $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ independent. $Y_1 = \\epsilon$, $Y_2 = X^2 + \\epsilon$.\n*   **Analysis of claims:**\n    *   **Pair 1: $(X, Y_1)$** where $Y_1=\\epsilon$.\n        *   Since $X$ and $Y_1$ are independent, $\\operatorname{Cov}(X,Y_1) = 0$, so $\\rho_{X,Y_1} = 0$.\n        *   Since $X$ and $Y_1$ are independent, $I(X;Y_1) = 0$.\n    *   **Pair 2: $(X, Y_2)$** where $Y_2=X^2 + \\epsilon$.\n        *   **Correlation:**\n            *   $\\mathbb{E}[X] = 0$.\n            *   $\\mathbb{E}[Y_2] = \\mathbb{E}[X^2 + \\epsilon] = \\mathbb{E}[X^2] + \\mathbb{E}[\\epsilon]$.\n            *   $\\mathbb{E}[\\epsilon] = 0$.\n            *   $\\mathbb{E}[X^2] = \\operatorname{Var}(X) + (\\mathbb{E}[X])^2 = 1 + 0^2 = 1$.\n            *   So, $\\mathbb{E}[Y_2] = 1$.\n            *   $\\operatorname{Cov}(X, Y_2) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y_2 - \\mathbb{E}[Y_2])] = \\mathbb{E}[X(Y_2 - 1)] = \\mathbb{E}[X(X^2 + \\epsilon - 1)] = \\mathbb{E}[X^3 + X\\epsilon - X]$.\n            *   $\\operatorname{Cov}(X, Y_2) = \\mathbb{E}[X^3] + \\mathbb{E}[X\\epsilon] - \\mathbb{E}[X]$.\n            *   Since $X \\sim \\mathcal{N}(0,1)$, it is a symmetric distribution around $0$. All odd moments are zero. So, $\\mathbb{E}[X] = 0$ and $\\mathbb{E}[X^3] = 0$.\n            *   Since $X$ and $\\epsilon$ are independent and $\\mathbb{E}[\\epsilon]=0$, $\\mathbb{E}[X\\epsilon] = \\mathbb{E}[X]\\mathbb{E}[\\epsilon] = 0 \\cdot 0 = 0$.\n            *   Therefore, $\\operatorname{Cov}(X, Y_2) = 0 + 0 - 0 = 0$.\n            *   This implies $\\rho_{X,Y_2} = 0$.\n        *   **Mutual Information:**\n            *   $Y_2$ is defined as a function of $X$ plus some noise. $Y_2 = f(X) + \\epsilon$ with $f(X) = X^2$.\n            *   Are $X$ and $Y_2$ independent? If they were independent, then $p(y_2|x) = p(y_2)$.\n            *   The conditional density of $Y_2$ given $X=x$ is the density of $x^2 + \\epsilon$. Since $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$, this means $Y_2|X=x \\sim \\mathcal{N}(x^2, \\sigma^2)$.\n            *   The conditional density $p(y_2|x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_2-x^2)^2}{2\\sigma^2}\\right)$.\n            *   This density clearly depends on $x$. So $X$ and $Y_2$ are NOT independent.\n            *   Since they are not independent, from the definition of MI provided, $I(X;Y_2) > 0$.\n    *   **Conclusion on claims:**\n        *   We have $\\rho_{X,Y_1} = 0$ and $\\rho_{X,Y_2} = 0$. So the claim $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ is **correct**.\n        *   We have $I(X;Y_1) = 0$ (from independence) and $I(X;Y_2) > 0$ (from dependence). So the claim $I(X;Y_1) = 0$ and $I(X;Y_2) > 0$ is **correct**.\n        *   The two pairs have identical Pearson correlation ($0$) but different mutual information ($0$ vs. $>0$). This fulfills the problem's requirement.\n*   **Interpretation:** \"a nonlinear regulatory relationship (e.g., thresholding or cooperative activation) can produce zero correlation but positive mutual information, so relying solely on correlation may miss true regulatory interactions that mutual information can detect.\"\n    *   The relationship $Y_2 = X^2 + \\epsilon$ is a classic example of a nonlinear relationship. The quadratic term $X^2$ could model a symmetric activation or repression where the regulator $X$ has the same effect whether its concentration is high positive or high negative (relative to its mean). Biologically, a term proportional to the square of a concentration often models the formation of a homodimer which then acts as the regulator.\n    *   The interpretation that zero correlation does not imply lack of interaction, and that MI is sensitive to such nonlinear interactions, is the central point of using MI in network inference. This interpretation is scientifically sound and directly relevant.\n*   **Verdict for B:** Correct.\n\n---\n\n**Option C:**\n*   **Construction:** $X \\sim \\mathcal{N}(0,1)$. $Y_1 = X + \\epsilon_1$, $Y_2 = \\operatorname{sign}(X) + \\epsilon_2$. The noises are chosen so that $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0.6$. The feasibility of this construction has been shown to be plausible in preliminary thought, but the central claims are the main issue.\n*   **Analysis of claims:** `Claim: $I(X;Y_1) = I(X;Y_2)$ by the data processing inequality, so equal correlation implies equal mutual information.`\n    *   The statement `equal correlation implies equal mutual information` is fundamentally **false**. This is the precise misconception the problem is designed to address. The relationship between mutual information and Pearson correlation is, in general, complex. Only for bivariate Gaussian variables does a simple monotonic relationship exist: $I(X;Y) = -\\frac{1}{2} \\log(1 - \\rho_{XY}^2)$.\n    *   The pair $(X, Y_1)$ with $Y_1=X+\\epsilon_1$ (where $\\epsilon_1$ is Gaussian noise) would be bivariate Gaussian. The pair $(X, Y_2)$ with $Y_2=\\operatorname{sign}(X)+\\epsilon_2$ is not. The function $\\operatorname{sign}(X)$ is strongly nonlinear. Therefore, there is no reason to expect $I(X;Y_1) = I(X;Y_2)$ just because their correlations are matched.\n    *   The invocation of the `data processing inequality` is incorrect. The inequality states that for a Markov chain $A \\to B \\to C$, $I(A;C) \\le I(A;B)$. It does not apply to a comparison between two different systems, $(X, Y_1)$ and $(X, Y_2)$.\n*   **Interpretation:** `both interactions are linear in effect and equally strong.` This is false. The relationship $Y_2 = \\operatorname{sign}(X) + \\epsilon_2$ is manifestly non-linear due to the step-function nature of $\\operatorname{sign}(X)$.\n*   **Verdict for C:** Incorrect.\n\n---\n\n**Option D:**\n*   **Construction:** $X$ is a symmetric zero-mean continuous variable, $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ independent. $Y_1 = |X| + \\epsilon$, $Y_2 = \\epsilon$.\n*   **Analysis of claims:**\n    *   **Pair 1: $(X, Y_2)$** with $Y_2=\\epsilon$. As $X$ and $Y_2$ are independent, $\\rho_{X,Y_2} = 0$ and $I(X;Y_2) = 0$.\n    *   **Pair 2: $(X, Y_1)$** with $Y_1=|X| + \\epsilon$.\n        *   **Correlation:** $\\mathbb{E}[X]=0$ by definition. $\\operatorname{Cov}(X, Y_1) = \\mathbb{E}[X(|X|+\\epsilon)] - \\mathbb{E}[X]\\mathbb{E}[|X|+\\epsilon] = \\mathbb{E}[X|X|] + \\mathbb{E}[X\\epsilon] - 0$. Since $X$ and $\\epsilon$ are independent and have zero mean, $\\mathbb{E}[X\\epsilon]=\\mathbb{E}[X]\\mathbb{E}[\\epsilon]=0$. The term $\\mathbb{E}[X|X|]$ is the expectation of an odd function ($g(x)=x|x|$) with respect to a symmetric probability density function $p_X(x)$, which is zero. Thus, $\\operatorname{Cov}(X, Y_1) = 0$ and $\\rho_{X,Y_1} = 0$. The claim $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ is correct.\n        *   **Mutual Information:** The claim is that $I(X;Y_1) = I(X;Y_2) = 0$. This implies $I(X;Y_1) = 0$. For $I(X;Y_1)$ to be zero, $X$ and $Y_1$ must be independent. However, they are not. The conditional distribution of $Y_1$ given $X=x$ is a normal distribution with mean $|x|+\\mathbb{E}[\\epsilon]=|x|$ and variance $\\sigma^2$. The mean clearly depends on $x$. For instance, given $X=1$, $Y_1$ is centered at $1$, while given $X=5$, $Y_1$ is centered at $5$. Since the conditional distribution of $Y_1$ depends on $X$, the variables are not independent, and thus $I(X;Y_1) > 0$. The claim that $I(X;Y_1)=0$ is **false**.\n*   **Interpretation:** `when correlations are zero, there is no regulation to infer, so mutual information adds nothing.` This is contradicted by the calculation that $I(X;Y_1)>0$. This interpretation is the very fallacy the problem seeks to expose.\n*   **Verdict for D:** Incorrect.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Inferring a network from genome-wide data involves testing thousands or millions of potential interactions simultaneously, creating a massive multiple-hypothesis testing problem. This computational practice  guides you through building a complete inference pipeline from first principles. You will implement a robust, non-parametric method using permutation testing to generate null distributions and then apply the Benjamini-Hochberg procedure to control the false discovery rate ($FDR$), a critical step for ensuring the statistical integrity of your inferred network.",
            "id": "3331730",
            "problem": "Consider a gene expression dataset represented by a matrix with $n$ samples and $p$ genes. The goal is to infer an undirected network among genes by testing pairwise independence, where an edge between gene $i$ and gene $j$ is declared if the null hypothesis of independence is rejected. The network inference should be based on the following foundations:\n\n1. The Pearson product–moment correlation coefficient between two genes $i$ and $j$ is defined on standardized data as a sample statistic of their linear association.\n2. Under the null hypothesis that two genes are independent, sample labels for one gene are exchangeable. A permutation-based null model can be constructed by randomly permuting sample labels for one gene and recomputing the correlation.\n3. A $p$-value for each pairwise test should be defined as the probability, under the null model, of observing a test statistic at least as extreme as the observed statistic.\n4. When multiple hypotheses are tested simultaneously, the false discovery rate (FDR) is the expected proportion of false rejections among all rejections. The Benjamini–Hochberg procedure is a method to control FDR at a specified level $\\alpha$.\n\nYour task is to implement a program that performs the following steps from first principles:\n\n- Use the definition of the Pearson correlation coefficient between two variables to compute the observed absolute correlation for each pair of genes.\n- Construct a permutation-based null model for each pair by permuting the sample labels of one gene $B$ times while preserving the marginal distribution of each gene. Use these permutations to approximate the null distribution of the absolute correlation under independence.\n- Define a $p$-value for each pair as the tail probability of the null distribution exceeding or matching the observed absolute correlation. Use a finite-sample adjustment to avoid zero $p$-values in the discrete permutation setting.\n- Starting from the definition of false discovery rate and the properties of order statistics of valid $p$-values under the null hypothesis, derive the Benjamini–Hochberg procedure to determine which hypotheses to reject at a nominal FDR level $\\alpha$.\n- Evaluate the empirical false discovery proportion for the inferred network by comparing rejected hypotheses to the known ground truth set of truly correlated gene pairs.\n\nUse the following test suite. For each test case, simulate gene expression data as follows: generate an $n \\times p$ matrix of standard normal random variables. For each planted edge $(i,j,\\rho)$, overwrite the expression of gene $j$ as $x_j = \\rho \\, x_i + \\sqrt{1 - \\rho^2} \\, \\epsilon_j$, where $\\epsilon_j$ is an independent standard normal vector, so that the population correlation between $i$ and $j$ is approximately $\\rho$. Assume distinct indices across planted edges. Use $0$-based indexing for gene indices.\n\n- Test case $1$ (general case): $p=20$, $n=60$, $B=200$, $\\alpha=0.1$, random seed $7$, planted edges\n  $(0,1,0.8)$, $(2,3,0.7)$, $(4,5,0.75)$, $(6,7,0.6)$, $(8,9,0.65)$.\n- Test case $2$ (all-null edge case): $p=15$, $n=50$, $B=200$, $\\alpha=0.1$, random seed $13$, planted edges none.\n- Test case $3$ (boundary case with mixed effect sizes): $p=18$, $n=40$, $B=300$, $\\alpha=0.05$, random seed $29$, planted edges\n  moderate $(0,10,0.5)$, $(1,11,0.5)$, $(2,12,0.5)$, $(3,13,0.5)$ and weak $(4,14,0.3)$, $(5,15,0.3)$, $(6,16,0.3)$, $(7,17,0.3)$.\n\nImplementation details to adhere to:\n\n- Compute the sample Pearson correlation coefficient using standardized variables with sample standard deviation.\n- For each pair $(i,j)$, approximate the null distribution by permuting the sample labels of $j$ exactly $B$ times, recomputing the absolute correlation after each permutation, and computing the $p$-value as $(1 + \\text{number of permuted absolute correlations greater than or equal to the observed absolute correlation}) / (1 + B)$.\n- Apply the Benjamini–Hochberg procedure derived from the definition of false discovery rate to select significant pairs at level $\\alpha$ across the total number of tests $m = p(p-1)/2$ in each test case.\n\nFinal output specification:\n\n- For each test case, compute two quantities: the total number of rejected hypotheses (an integer) and the empirical false discovery proportion defined as the number of rejected hypotheses that are not in the planted edge set divided by the total number of rejected hypotheses, with the convention that the proportion is $0$ when there are no rejections. Express the proportion as a decimal, not as a percentage.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is a two-element list of the form $[D, F]$ with $D$ the integer number of rejections and $F$ the decimal false discovery proportion. For example, the output format should be like $[[D_1,F_1],[D_2,F_2],[D_3,F_3]]$.",
            "solution": "The objective is to infer edges in a gene co-expression network by testing the null hypothesis of independence for each pair of genes using the Pearson correlation coefficient and a permutation-based null model, and to control the false discovery rate using the Benjamini–Hochberg procedure.\n\nFundamental base and definitions:\n\n1. Let $X \\in \\mathbb{R}^{n \\times p}$ be the gene expression matrix with $n$ samples and $p$ genes. For gene $i$ and gene $j$, denote the sample vectors by $(x_{1i}, \\ldots, x_{ni})$ and $(x_{1j}, \\ldots, x_{nj})$. The sample mean of gene $i$ is $\\bar{x}_i = \\frac{1}{n} \\sum_{t=1}^n x_{ti}$ and the sample standard deviation is $s_i = \\sqrt{\\frac{1}{n-1} \\sum_{t=1}^n (x_{ti} - \\bar{x}_i)^2}$. The standardized variables are $z_{ti} = \\frac{x_{ti} - \\bar{x}_i}{s_i}$ and analogously for $j$.\n2. The Pearson product–moment correlation coefficient between genes $i$ and $j$ is\n$$\nr_{ij} = \\frac{1}{n-1} \\sum_{t=1}^n z_{ti} z_{tj}.\n$$\nWe use the absolute observed correlation $|r_{ij}|$ as the test statistic for two-sided testing of independence.\n3. Under the null hypothesis $H_{0,ij}$ that genes $i$ and $j$ are independent, the joint distribution of $(x_{ti}, x_{tj})$ exhibits exchangeability of sample labels for one gene when the samples are independent and identically distributed. Specifically, permuting the sample labels of gene $j$ produces realizations consistent with $H_{0,ij}$ while preserving the marginal distribution of $x_{tj}$. This is a well-tested approach to construct a nonparametric null distribution when analytic forms are inconvenient or unknown.\n4. A $p$-value for the test of $H_{0,ij}$ is defined as the probability, under the null model, of observing a test statistic at least as extreme as the observed statistic. In a permutation setting with $B$ permutations, the empirical $p$-value with a finite-sample correction is\n$$\np_{ij} = \\frac{1 + \\sum_{b=1}^B \\mathbf{1}\\left\\{ \\left|r_{ij}^{(b)}\\right| \\ge \\left|r_{ij}\\right| \\right\\}}{1 + B},\n$$\nwhere $r_{ij}^{(b)}$ is the correlation computed after permuting the sample labels of gene $j$ according to the $b$-th permutation. The numerator adds $1$ and the denominator adds $1$ to avoid zero values due to discreteness.\n5. When testing $m$ hypotheses concurrently, the false discovery rate (FDR) is defined as\n$$\n\\mathrm{FDR} = \\mathbb{E}\\left[ \\frac{V}{R \\vee 1} \\right],\n$$\nwhere $V$ is the number of false rejections and $R$ is the total number of rejections, and $R \\vee 1$ denotes $\\max(R, 1)$ to avoid division by zero. A valid $p$-value under $H_0$ is stochastically greater than or equal to a Uniform$(0,1)$ random variable; under independence or certain forms of positive dependence of $p$-values, the ordering of $p$-values can be used to threshold rejections to control FDR.\n\nDerivation of the Benjamini–Hochberg procedure:\n\nStarting from the definition of FDR and the property that under $H_0$ valid $p$-values are super-uniform, consider ordering the $m$ computed $p$-values as $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$ with corresponding indices $(i_{(1)}, j_{(1)}), \\ldots, (i_{(m)}, j_{(m)})$. The expected number of false discoveries among the first $k$ ordered $p$-values under independence is approximately $\\alpha k$ if we choose a threshold that scales as $\\frac{\\alpha k}{m}$, because the probability that a null $p$-value falls below a threshold $t$ is at most $t$. To ensure that the proportion of false to total rejections remains bounded by $\\alpha$ in expectation, we select the largest index $k$ such that\n$$\np_{(k)} \\le \\frac{\\alpha k}{m}.\n$$\nThen, all hypotheses corresponding to $p_{(1)}, \\ldots, p_{(k)}$ are rejected. This adaptive thresholding sets a data-driven cutoff on $p$-values that compensates for the multiplicity $m$ and the rank $k$, controlling the expected ratio $V / (R \\vee 1)$ at level $\\alpha$ under independence or certain positive dependence structures. This is the Benjamini–Hochberg procedure.\n\nAlgorithmic design integrating the principles:\n\n- Standardize each gene across samples using the sample mean and sample standard deviation to obtain $z_{ti}$ for every gene $i$.\n- For each pair $(i,j)$ with $i < j$, compute the observed absolute correlation $|r_{ij}|$ using the standardized variables and the sample correlation formula. There are $m = \\frac{p(p-1)}{2}$ such pairs.\n- Construct a permutation-based null distribution: generate $B$ random permutations of the sample indices. For each permutation, reorder the standardized vector of gene $j$ and recompute the absolute correlation with gene $i$. Collect the $B$ permuted absolute correlations and compute the permutation $p$-value using the finite-sample correction specified above.\n- Collect the $m$ $p$-values across all pairs and apply the Benjamini–Hochberg procedure as derived: sort the $p$-values, find the largest $k$ satisfying the inequality displayed above, and reject all hypotheses with $p$-values less than or equal to the adaptive threshold $\\frac{\\alpha k}{m}$. If there is no such $k$, reject none.\n- Using the known planted edges in each test case, compute the empirical false discovery proportion as $V / (R \\vee 1)$, where $V$ is the number of rejected pairs not in the planted set and $R$ is the total number of rejected pairs.\n- Aggregate the results for the test suite into a single list $[[D_1,F_1],[D_2,F_2],[D_3,F_3]]$, where $D_c$ is the number of rejections and $F_c$ is the empirical false discovery proportion for test case $c$. The proportion should be expressed as a decimal.\n\nThis solution is scientifically grounded: Pearson correlation quantifies linear association; the permutation-based null model relies on exchangeability under independence, a well-tested nonparametric method; and the Benjamini–Hochberg procedure is derived from the definition of FDR and order statistics of valid $p$-values, providing control of the false discovery rate at level $\\alpha$ under standard conditions. While mutual information provides a complementary measure for nonlinear dependencies in computational systems biology, this problem focuses on permutation-based inference with correlation to align with the specified thumbnail and to maintain a clear derivation from the foundational definitions presented.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate_data(p, n, planted_edges, seed):\n    \"\"\"\n    Simulate gene expression data with planted correlated edges.\n    Args:\n        p (int): number of genes\n        n (int): number of samples\n        planted_edges (list of tuples): [(i, j, rho), ...] with 0-based indices and correlation strength rho\n        seed (int): random seed\n    Returns:\n        X (np.ndarray): n x p data matrix\n        true_edges_set (set): set of (min(i,j), max(i,j)) tuples representing true correlated pairs\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = rng.standard_normal((n, p))\n    true_edges_set = set()\n    for (i, j, rho) in planted_edges:\n        # Ensure distinct indices and valid rho\n        assert 0 <= i < p and 0 <= j < p and i != j\n        assert 0.0 <= rho < 1.0\n        # Overwrite gene j to be correlated with gene i\n        eps = rng.standard_normal(n)\n        X[:, j] = rho * X[:, i] + np.sqrt(1.0 - rho**2) * eps\n        a, b = (i, j) if i < j else (j, i)\n        true_edges_set.add((a, b))\n    return X, true_edges_set\n\ndef standardize_columns(X):\n    \"\"\"\n    Standardize each column to zero mean and unit sample standard deviation.\n    \"\"\"\n    X_centered = X - X.mean(axis=0, keepdims=True)\n    std = X_centered.std(axis=0, ddof=1, keepdims=True)\n    # Avoid division by zero: add tiny epsilon if needed\n    std = np.where(std == 0, 1.0, std)\n    X_std = X_centered / std\n    return X_std\n\ndef permutation_pvalues(X_std, B, seed):\n    \"\"\"\n    Compute permutation-based p-values for absolute Pearson correlations for all pairs.\n    Args:\n        X_std (np.ndarray): n x p standardized data\n        B (int): number of permutations\n        seed (int): random seed for permutations\n    Returns:\n        pvals (np.ndarray): array of length m with p-values\n        pairs (list): list of (i, j) pairs in the same order as pvals\n        obs_abs_corrs (np.ndarray): observed absolute correlations for each pair\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    n, p = X_std.shape\n    pairs = [(i, j) for i in range(p) for j in range(i + 1, p)]\n    m = len(pairs)\n\n    # Precompute B permutations of indices\n    perms = np.array([rng.permutation(n) for _ in range(B)], dtype=np.int64)\n\n    pvals = np.empty(m, dtype=float)\n    obs_abs_corrs = np.empty(m, dtype=float)\n    denom = float(n - 1)\n\n    # Compute p-values for each pair\n    for idx, (i, j) in enumerate(pairs):\n        xi = X_std[:, i]\n        yj = X_std[:, j]\n        # Observed absolute correlation\n        obs = abs(np.dot(xi, yj) / denom)\n        obs_abs_corrs[idx] = obs\n        # Permuted correlations: permute yj by each permutation\n        # Vectorized: build matrix of shape (B, n) for yj permuted, then dot with xi\n        yj_perm = yj[perms]  # shape (B, n)\n        perm_corrs = (yj_perm @ xi) / denom  # shape (B,)\n        perm_abs = np.abs(perm_corrs)\n        count_ge = np.sum(perm_abs >= obs)\n        # Finite-sample correction to avoid zero p-values\n        pval = (count_ge + 1.0) / (B + 1.0)\n        pvals[idx] = pval\n\n    return pvals, pairs, obs_abs_corrs\n\ndef benjamini_hochberg(pvals, alpha):\n    \"\"\"\n    Apply the Benjamini–Hochberg procedure to control FDR at level alpha.\n    Args:\n        pvals (np.ndarray): p-values of length m\n        alpha (float): target FDR level\n    Returns:\n        reject_indices (np.ndarray): indices (into pvals) of rejected hypotheses\n        threshold (float): BH threshold used (0 if no rejections)\n    \"\"\"\n    m = pvals.size\n    order = np.argsort(pvals)\n    p_sorted = pvals[order]\n    ranks = np.arange(1, m + 1, dtype=float)\n    thresholds = (ranks / m) * alpha\n    # Find largest k such that p_(k) <= (k/m)*alpha\n    valid = np.where(p_sorted <= thresholds)[0]\n    if valid.size == 0:\n        return np.array([], dtype=int), 0.0\n    k = valid.max() + 1  # convert index to count\n    bh_threshold = thresholds[k - 1]\n    reject_mask = pvals <= bh_threshold\n    reject_indices = np.where(reject_mask)[0]\n    return reject_indices, bh_threshold\n\ndef evaluate_fdp(rejected_pairs, true_edges_set):\n    \"\"\"\n    Compute number of rejections and empirical false discovery proportion (FDP).\n    Args:\n        rejected_pairs (list of tuples): list of (i, j) for rejected hypotheses\n        true_edges_set (set of tuples): ground-truth correlated edges\n    Returns:\n        D (int): total number of rejections\n        fdp (float): false discovery proportion (0.0 if D == 0)\n    \"\"\"\n    D = len(rejected_pairs)\n    if D == 0:\n        return 0, 0.0\n    rejected_set = set((min(i, j), max(i, j)) for (i, j) in rejected_pairs)\n    false_discoveries = len(rejected_set - true_edges_set)\n    fdp = false_discoveries / D\n    return D, fdp\n\ndef run_test_case(p, n, B, alpha, seed, planted_edges):\n    \"\"\"\n    Execute the full pipeline for one test case.\n    Returns:\n        [D, fdp] for the test case.\n    \"\"\"\n    X, true_edges_set = simulate_data(p, n, planted_edges, seed)\n    X_std = standardize_columns(X)\n    pvals, pairs, _ = permutation_pvalues(X_std, B, seed + 12345)  # separate seed for permutations\n    reject_indices, _ = benjamini_hochberg(pvals, alpha)\n    rejected_pairs = [pairs[idx] for idx in reject_indices]\n    D, fdp = evaluate_fdp(rejected_pairs, true_edges_set)\n    return [int(D), float(fdp)]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: p=20, n=60, B=200, alpha=0.1, seed=7, planted edges given\n        {\n            \"p\": 20, \"n\": 60, \"B\": 200, \"alpha\": 0.1, \"seed\": 7,\n            \"planted_edges\": [(0, 1, 0.8), (2, 3, 0.7), (4, 5, 0.75), (6, 7, 0.6), (8, 9, 0.65)]\n        },\n        # Test case 2: p=15, n=50, B=200, alpha=0.1, seed=13, no planted edges\n        {\n            \"p\": 15, \"n\": 50, \"B\": 200, \"alpha\": 0.1, \"seed\": 13,\n            \"planted_edges\": []\n        },\n        # Test case 3: p=18, n=40, B=300, alpha=0.05, seed=29, mixed effect sizes\n        {\n            \"p\": 18, \"n\": 40, \"B\": 300, \"alpha\": 0.05, \"seed\": 29,\n            \"planted_edges\": [\n                (0, 10, 0.5), (1, 11, 0.5), (2, 12, 0.5), (3, 13, 0.5),\n                (4, 14, 0.3), (5, 15, 0.3), (6, 16, 0.3), (7, 17, 0.3)\n            ]\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(case[\"p\"], case[\"n\"], case[\"B\"], case[\"alpha\"], case[\"seed\"], case[\"planted_edges\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Once a network is inferred, we must rigorously evaluate its performance. However, standard metrics can be misleading in the context of biological networks, which are characteristically sparse. This practice  demonstrates how the severe class imbalance between true and false interactions affects common evaluation tools, revealing why the Area Under the Precision-Recall Curve ($AUPRC$) is often a more informative metric than the Area Under the ROC Curve ($AUROC$) in this domain.",
            "id": "3331731",
            "problem": "In a gene regulatory network inference task, one ranks all gene-pair candidates by an information-theoretic edge score $s$ derived from estimated Mutual Information (MI). Consider two populations of pairs: true regulatory interactions (positives) and non-interactions (negatives). Suppose that, conditional on class, the score $s$ falls into three ordered bins, High ($H$), Medium ($M$), and Low ($L$), with the following class-conditional probabilities:\n- For positives: $\\mathbb{P}(H \\mid \\text{positive}) = 0.3$, $\\mathbb{P}(M \\mid \\text{positive}) = 0.5$, $\\mathbb{P}(L \\mid \\text{positive}) = 0.2$.\n- For negatives: $\\mathbb{P}(H \\mid \\text{negative}) = 0.05$, $\\mathbb{P}(M \\mid \\text{negative}) = 0.15$, $\\mathbb{P}(L \\mid \\text{negative}) = 0.8$.\n\nA thresholding procedure declares a predicted edge if and only if $s$ is at least as large as the threshold. As the threshold is lowered across $\\{H, M, L\\}$, the set of predicted edges is monotone increasing. You evaluate the ranked predictions by Receiver Operating Characteristic (ROC) and Precision-Recall (PR) analysis. Let $\\pi \\in (0,1)$ denote the prevalence of true edges (the fraction of positives among all candidate pairs), which reflects network sparsity.\n\nUsing only fundamental definitions of True Positive Rate (TPR), False Positive Rate (FPR), Precision, and Recall, and the standard area interpretations of the Area Under the ROC curve (AUROC) and the Area Under the PR curve (AUPRC), do the following:\n\n1. Starting from the definitions\n   - $\\mathrm{TPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{positive})$,\n   - $\\mathrm{FPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{negative})$,\n   - $\\mathrm{Precision}(\\tau) = \\dfrac{\\pi\\, \\mathrm{TPR}(\\tau)}{\\pi\\, \\mathrm{TPR}(\\tau) + (1-\\pi)\\, \\mathrm{FPR}(\\tau)}$,\n   - $\\mathrm{Recall}(\\tau) = \\mathrm{TPR}(\\tau)$,\n   explain, without invoking any unproven shortcut formulas, why $\\mathrm{AUROC}$ depends only on the class-conditional score distributions and is independent of $\\pi$, while $\\mathrm{AUPRC}$ depends on $\\pi$. Your explanation must explicitly identify the source of any $\\pi$-dependence or $\\pi$-independence in the definitions.\n\n2. For the discrete three-threshold setting implied by the bins $\\{H, M, L\\}$, compute the exact $\\mathrm{AUROC}$ using the trapezoidal area between the points obtained at thresholds $\\tau \\in \\{+\\infty, H, M, L\\}$, where $\\tau = +\\infty$ yields $\\mathrm{TPR} = 0$ and $\\mathrm{FPR} = 0$, and $\\tau = L$ yields $\\mathrm{TPR} = 1$ and $\\mathrm{FPR} = 1$.\n\n3. Compute $\\mathrm{AUPRC}$ under the same three-threshold procedure for two different prevalences: a sparse network with $\\pi = 0.01$ and a balanced evaluation with $\\pi = 0.5$. Use the standard stepwise area convention for discrete rankings, namely summing, over thresholds in order of decreasing $s$, the product of each recall increment and the precision at that level.\n\nFinally, report the numerical value of the ratio\n$$\nr \\;=\\; \\frac{\\mathrm{AUPRC}\\; \\text{at}\\; \\pi = 0.01}{\\mathrm{AUPRC}\\; \\text{at}\\; \\pi = 0.5}\n$$\nrounded to four significant figures. Express your final answer as a pure number with no units.",
            "solution": "The problem statement is validated as scientifically sound, well-posed, and complete. It describes a standard classification evaluation scenario within computational systems biology and provides all necessary data and definitions to derive a unique solution. We may proceed with the analysis.\n\nThe problem asks for three tasks: first, an explanation of the dependence of Area Under the Receiver Operating Characteristic curve (AUROC) and Area Under the Precision-Recall curve (AUPRC) on the class prevalence $\\pi$; second, the calculation of AUROC for the given discrete score distribution; and third, the calculation of AUPRC for two specified values of $\\pi$. Finally, a ratio of the two AUPRC values is required.\n\n**1. Dependence of AUROC and AUPRC on Prevalence $\\pi$**\n\nThe Receiver Operating Characteristic (ROC) curve is a plot of the True Positive Rate (TPR) against the False Positive Rate (FPR) for varying decision thresholds $\\tau$. The definitions provided are:\n$$\n\\mathrm{TPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{positive})\n$$\n$$\n\\mathrm{FPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{negative})\n$$\nThese definitions are probabilities conditioned on the true class of an instance (positive or negative). They depend solely on the distribution of the score $s$ within each class. The prevalence $\\pi = \\mathbb{P}(\\text{positive})$, which is the prior probability of an instance being positive, does not appear in these definitions. Consequently, the set of points $(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))$ that constitute the ROC curve is invariant with respect to changes in $\\pi$. Since the AUROC is the area under this curve, it is determined entirely by the geometry of the curve. Therefore, AUROC is a performance metric that is independent of the class prevalence $\\pi$.\n\nThe Precision-Recall (PR) curve is a plot of Precision against Recall for varying thresholds $\\tau$. The definitions provided are:\n$$\n\\mathrm{Recall}(\\tau) = \\mathrm{TPR}(\\tau)\n$$\n$$\n\\mathrm{Precision}(\\tau) = \\dfrac{\\pi\\, \\mathrm{TPR}(\\tau)}{\\pi\\, \\mathrm{TPR}(\\tau) + (1-\\pi)\\, \\mathrm{FPR}(\\tau)}\n$$\nWhile Recall is identical to TPR and thus independent of $\\pi$, the definition of Precision explicitly incorporates the prevalence $\\pi$. The formula for Precision is derived from Bayes' theorem, $\\mathrm{Precision}(\\tau) = \\mathbb{P}(\\text{positive} \\mid s \\ge \\tau)$, and its value is a function of $\\pi$, $\\mathrm{TPR}(\\tau)$, and $\\mathrm{FPR}(\\tau)$. Because the $y$-axis (Precision) of the PR curve is a function of $\\pi$, the curve's shape and position in the Recall-Precision space change as $\\pi$ changes. The AUPRC, being the area under this curve, is therefore fundamentally dependent on the class prevalence $\\pi$.\n\n**2. Calculation of AUROC**\n\nThe discrete score bins are ordered $H > M > L$. We evaluate the performance at thresholds corresponding to these score levels. The problem specifies thresholds $\\tau \\in \\{+\\infty, H, M, L\\}$. We first compute the (FPR, TPR) coordinates for each threshold.\n\nLet $P(+) = \\text{positive}$ and $P(-) = \\text{negative}$.\nThe cumulative probabilities are:\n$\\mathbb{P}(s \\ge H \\mid P(+)) = \\mathbb{P}(s=H \\mid P(+)) = 0.3$\n$\\mathbb{P}(s \\ge M \\mid P(+)) = \\mathbb{P}(s=H \\mid P(+)) + \\mathbb{P}(s=M \\mid P(+)) = 0.3 + 0.5 = 0.8$\n$\\mathbb{P}(s \\ge L \\mid P(+)) = \\mathbb{P}(s=H \\mid P(+)) + \\mathbb{P}(s=M \\mid P(+)) + \\mathbb{P}(s=L \\mid P(+)) = 0.3 + 0.5 + 0.2 = 1.0$\n\n$\\mathbb{P}(s \\ge H \\mid P(-)) = \\mathbb{P}(s=H \\mid P(-)) = 0.05$\n$\\mathbb{P}(s \\ge M \\mid P(-)) = \\mathbb{P}(s=H \\mid P(-)) + \\mathbb{P}(s=M \\mid P(-)) = 0.05 + 0.15 = 0.20$\n$\\mathbb{P}(s \\ge L \\mid P(-)) = \\mathbb{P}(s=H \\mid P(-)) + \\mathbb{P}(s=M \\mid P(-)) + \\mathbb{P}(s=L \\mid P(-)) = 0.05 + 0.15 + 0.8 = 1.0$\n\nThis yields the following points $(x,y) = (\\mathrm{FPR}, \\mathrm{TPR})$ on the ROC curve:\n- For $\\tau = +\\infty$: $(\\mathrm{FPR}, \\mathrm{TPR}) = (0, 0)$. Let this be $p_0$.\n- For $\\tau = H$: $(\\mathrm{FPR}, \\mathrm{TPR}) = (\\mathbb{P}(s \\ge H \\mid P(-)), \\mathbb{P}(s \\ge H \\mid P(+))) = (0.05, 0.3)$. Let this be $p_1$.\n- For $\\tau = M$: $(\\mathrm{FPR}, \\mathrm{TPR}) = (\\mathbb{P}(s \\ge M \\mid P(-)), \\mathbb{P}(s \\ge M \\mid P(+))) = (0.20, 0.8)$. Let this be $p_2$.\n- For $\\tau = L$: $(\\mathrm{FPR}, \\mathrm{TPR}) = (\\mathbb{P}(s \\ge L \\mid P(-)), \\mathbb{P}(s \\ge L \\mid P(+))) = (1.0, 1.0)$. Let this be $p_3$.\n\nThe AUROC is computed using the trapezoidal rule on the area under the segments connecting $p_0, p_1, p_2, p_3$.\nArea = $\\sum_{i=1}^{3} \\frac{1}{2} (y_{i-1} + y_i) (x_i - x_{i-1})$\n- Area of trapezoid between $p_0=(0,0)$ and $p_1=(0.05, 0.3)$:\n  $A_1 = \\frac{1}{2} (0 + 0.3) (0.05 - 0) = 0.5 \\times 0.3 \\times 0.05 = 0.0075$\n- Area of trapezoid between $p_1=(0.05, 0.3)$ and $p_2=(0.20, 0.8)$:\n  $A_2 = \\frac{1}{2} (0.3 + 0.8) (0.20 - 0.05) = 0.5 \\times 1.1 \\times 0.15 = 0.0825$\n- Area of trapezoid between $p_2=(0.20, 0.8)$ and $p_3=(1.0, 1.0)$:\n  $A_3 = \\frac{1}{2} (0.8 + 1.0) (1.0 - 0.20) = 0.5 \\times 1.8 \\times 0.8 = 0.72$\n\nThe total AUROC is the sum of these areas:\n$\\mathrm{AUROC} = A_1 + A_2 + A_3 = 0.0075 + 0.0825 + 0.72 = 0.81$\n\n**3. Calculation of AUPRC**\n\nThe AUPRC is calculated using the stepwise area convention: $\\mathrm{AUPRC} = \\sum_{k} \\mathrm{Precision}(k) \\times \\Delta \\mathrm{Recall}(k)$, where the sum is over thresholds $k$ in order of decreasing score.\nThe Recall values are simply the TPR values: $\\mathrm{Recall}(H)=0.3$, $\\mathrm{Recall}(M)=0.8$, $\\mathrm{Recall}(L)=1.0$.\nThe recall increments are:\n- $\\Delta \\mathrm{Recall}(H) = \\mathrm{Recall}(H) - 0 = 0.3$\n- $\\Delta \\mathrm{Recall}(M) = \\mathrm{Recall}(M) - \\mathrm{Recall}(H) = 0.8 - 0.3 = 0.5$\n- $\\Delta \\mathrm{Recall}(L) = \\mathrm{Recall}(L) - \\mathrm{Recall}(M) = 1.0 - 0.8 = 0.2$\n\nWe now calculate Precision for each threshold $\\tau \\in \\{H, M, L\\}$ at $\\pi=0.01$ and $\\pi=0.5$.\n\nCase 1: Sparse network, $\\pi = 0.01$\n- $\\mathrm{Precision}(H) = \\frac{0.01 \\times \\mathrm{TPR}(H)}{0.01 \\times \\mathrm{TPR}(H) + 0.99 \\times \\mathrm{FPR}(H)} = \\frac{0.01 \\times 0.3}{0.01 \\times 0.3 + 0.99 \\times 0.05} = \\frac{0.003}{0.003 + 0.0495} = \\frac{0.003}{0.0525} = \\frac{2}{35}$\n- $\\mathrm{Precision}(M) = \\frac{0.01 \\times \\mathrm{TPR}(M)}{0.01 \\times \\mathrm{TPR}(M) + 0.99 \\times \\mathrm{FPR}(M)} = \\frac{0.01 \\times 0.8}{0.01 \\times 0.8 + 0.99 \\times 0.20} = \\frac{0.008}{0.008 + 0.198} = \\frac{0.008}{0.206} = \\frac{4}{103}$\n- $\\mathrm{Precision}(L) = \\frac{0.01 \\times \\mathrm{TPR}(L)}{0.01 \\times \\mathrm{TPR}(L) + 0.99 \\times \\mathrm{FPR}(L)} = \\frac{0.01 \\times 1.0}{0.01 \\times 1.0 + 0.99 \\times 1.0} = 0.01$\n\n$\\mathrm{AUPRC}(\\pi=0.01) = \\mathrm{Prec}(H) \\Delta \\mathrm{Rec}(H) + \\mathrm{Prec}(M) \\Delta \\mathrm{Rec}(M) + \\mathrm{Prec}(L) \\Delta \\mathrm{Rec}(L)$\n$\\mathrm{AUPRC}(\\pi=0.01) = (\\frac{2}{35})(0.3) + (\\frac{4}{103})(0.5) + (0.01)(0.2)$\n$= \\frac{0.6}{35} + \\frac{2}{103} + 0.002 = \\frac{3}{175} + \\frac{2}{103} + \\frac{1}{500}$\nNumerically, this is $\\frac{13901}{360500} \\approx 0.03856033$\n\nCase 2: Balanced evaluation, $\\pi = 0.5$\n- $\\mathrm{Precision}(H) = \\frac{0.5 \\times 0.3}{0.5 \\times 0.3 + 0.5 \\times 0.05} = \\frac{0.3}{0.3 + 0.05} = \\frac{0.3}{0.35} = \\frac{6}{7}$\n- $\\mathrm{Precision}(M) = \\frac{0.5 \\times 0.8}{0.5 \\times 0.8 + 0.5 \\times 0.20} = \\frac{0.8}{0.8 + 0.2} = \\frac{0.8}{1.0} = 0.8 = \\frac{4}{5}$\n- $\\mathrm{Precision}(L) = \\frac{0.5 \\times 1.0}{0.5 \\times 1.0 + 0.5 \\times 1.0} = 0.5 = \\frac{1}{2}$\n\n$\\mathrm{AUPRC}(\\pi=0.5) = (\\frac{6}{7})(0.3) + (\\frac{4}{5})(0.5) + (\\frac{1}{2})(0.2)$\n$= \\frac{1.8}{7} + 0.4 + 0.1 = \\frac{1.8}{7} + 0.5 = \\frac{9}{35} + \\frac{1}{2} = \\frac{18+35}{70} = \\frac{53}{70}$\nNumerically, this is $\\approx 0.75714286$\n\n**Final Ratio Calculation**\n\nFinally, we compute the ratio $r = \\frac{\\mathrm{AUPRC}(\\pi=0.01)}{\\mathrm{AUPRC}(\\pi=0.5)}$:\n$$\nr = \\frac{13901/360500}{53/70} = \\frac{13901}{360500} \\times \\frac{70}{53} = \\frac{13901}{5150 \\times 53} = \\frac{13901}{272950}\n$$\n$r \\approx 0.0509287415...$\nRounding to four significant figures, we get $r = 0.05093$.",
            "answer": "$$\\boxed{0.05093}$$"
        }
    ]
}