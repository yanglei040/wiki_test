{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of quantitative NMR analysis is the conversion of raw instrument integrals into chemically meaningful proton ratios. This first exercise walks you through the fundamental normalization procedure using a clear, idealized dataset. Mastering this simple calculation  is the essential first step toward interpreting any $^{1}\\mathrm{H}$ NMR spectrum quantitatively.",
            "id": "3717971",
            "problem": "A proton Nuclear Magnetic Resonance (NMR) experiment is conducted under quantitative conditions: a $90^{\\circ}$ excitation pulse, a relaxation delay $d_{1}$ chosen such that $d_{1} \\geq 5 T_{1}$ for all resonances, and a uniform receiver gain across the acquisition. Under these conditions, the integrated area $I_{i}$ of each resolved proton signal $i$ is proportional to the number of chemically equivalent protons $n_{i}$ contributing to that signal, with a proportionality factor $k$ common to all signals. The proportionality is asserted by the widely accepted fact that, for fully relaxed proton magnetization and linear detection, the time integral of the free induction decay Fourier-transformed peak is proportional to the population of spins, so that $I_{i} = k\\,n_{i}$.\n\nAn unknown organic compound exhibits three non-overlapping signals in its $^{1}\\mathrm{H}$ NMR spectrum with integrated areas reported as $I_{1} = 1.00$, $I_{2} = 1.00$, and $I_{3} = 2.00$ in arbitrary units. Assume there is no baseline offset and no saturation, and that each of the three signals arises from a unique set of equivalent protons without overlap or differential Nuclear Overhauser Effect (NOE).\n\nStarting only from the stated quantitative-NMR proportionality and the definition that relative proton counts are given by ratios of integrated areas when detection is linear and magnetization is fully relaxed, derive the normalization procedure that yields the smallest integer ratio consistent with the data. Then compute the normalized smallest integer ratio and infer the relative proton counts for the three signals.\n\nCompute any intermediate normalized ratios to four significant figures before mapping them to integers. Report the final normalized relative proton counts as integers. No physical units are required.",
            "solution": "The fundamental base is the quantitative behavior of proton Nuclear Magnetic Resonance (NMR) signal integration under fully relaxed conditions. For a set of resolved signals indexed by $i$, the integrated area $I_{i}$ satisfies\n$$\nI_{i} = k\\,n_{i},\n$$\nwhere $n_{i}$ is the number of chemically equivalent protons contributing to signal $i$ and $k$ is a constant that embodies the instrumental sensitivity and excitation/detection efficiency. This proportionality follows from the fact that the longitudinal magnetization $M_{z}$ recovers to its equilibrium value between scans when the relaxation delay $d_{1}$ is chosen such that $d_{1} \\geq 5 T_{1}$ for all resonances, and a $90^{\\circ}$ pulse converts $M_{z}$ to transverse magnetization $M_{xy}$ linearly with $M_{z}$. The detected free induction decay (FID) area and its Fourier-transform integrated peak area are linear in the number of spins when receiver gain is fixed and the response is linear. Thus, ratios of integrated areas equal ratios of proton counts:\n$$\n\\frac{I_{i}}{I_{j}} = \\frac{n_{i}}{n_{j}}.\n$$\n\nGiven $I_{1} = 1.00$, $I_{2} = 1.00$, and $I_{3} = 2.00$, the unknown scale factor $k$ cancels in ratios. To produce a smallest integer ratio consistent with the data, one applies normalization by dividing all integrals by a common factor that yields the minimal integer set. A standard method is to divide by the smallest nonzero integral, which preserves integer relationships when one signal is a unit reference. Let\n$$\nI_{\\min} = \\min\\{I_{1}, I_{2}, I_{3}\\} = 1.00.\n$$\nDefine normalized ratios\n$$\nr_{i} = \\frac{I_{i}}{I_{\\min}}.\n$$\nCompute these ratios to four significant figures as required:\n$$\nr_{1} = \\frac{1.00}{1.00} = 1.000,\\quad r_{2} = \\frac{1.00}{1.00} = 1.000,\\quad r_{3} = \\frac{2.00}{1.00} = 2.000.\n$$\n\nUnder the linear, fully relaxed conditions with no baseline offset, these normalized ratios $r_{i}$ equal the ratios of proton counts $n_{i}/n_{\\min}$. Mapping each $r_{i}$ to the nearest integer consistent with the four-significant-figure values yields\n$$\nn_{1} : n_{2} : n_{3} = 1 : 1 : 2.\n$$\nThis is the smallest integer ratio because any further common factor reduction would require non-integer values (there is no common integer divisor larger than $1$ for $1$, $1$, and $2$). Therefore, the inferred relative proton counts for the three signals are $1$, $1$, and $2$.",
            "answer": "$$\\boxed{\\begin{pmatrix}1 & 1 & 2\\end{pmatrix}}$$"
        },
        {
            "introduction": "Moving beyond simple ratios, integration can be used as a powerful tool to validate a proposed molecular formula against spectral data. This practice simulates a common task in structure elucidation, where you must reconcile the total integral intensity with the expected number of protons. You will learn to perform a crucial consistency check by calculating a calibration constant that connects the observed integrals to the absolute proton count , accounting for practical details like exchangeable protons.",
            "id": "3718023",
            "problem": "A quantitative $^{1}\\mathrm{H}$ Nuclear Magnetic Resonance ($^{1}\\mathrm{H}$ NMR) experiment was performed at $400 \\ \\mathrm{MHz}$ in deuterated chloroform with a relaxation delay $d_{1} = 12 \\ \\mathrm{s}$ and $90^{\\circ}$ pulses, under conditions ensuring full relaxation and linear response for all resonances. A drop of deuterium oxide was added prior to acquisition to suppress exchangeable protons. The proposed structure has the molecular formula $\\mathrm{C}_{12}\\mathrm{H}_{16}\\mathrm{N}\\mathrm{O}_{3}$ and contains exactly one exchangeable $\\mathrm{N}\\!-\\!\\mathrm{H}$ proton, which is not observed after the deuterium oxide treatment.\n\nThe $^{1}\\mathrm{H}$ NMR spectrum shows the following signals assigned to the compound (chemical shift in $\\mathrm{ppm}$ with multiplicity and coupling constant where applicable, followed by the integral in arbitrary units):\n- $7.92$ (d, $J = 8.7 \\ \\mathrm{Hz}$), integral $12.36$\n- $6.89$ (d, $J = 8.7 \\ \\mathrm{Hz}$), integral $12.28$\n- $4.21$ (q, $J = 7.1 \\ \\mathrm{Hz}$), integral $11.98$\n- $3.84$ (s), integral $17.95$\n- $2.73$ (s), integral $17.88$\n- $1.33$ (t, $J = 7.1 \\ \\mathrm{Hz}$), integral $17.85$\n\nThe spectrum also contains signals annotated as residual solvent or minor impurities that must be excluded from quantitative analysis: $7.26$ (s, residual $\\mathrm{CHCl}_{3}$), integral $1.00$; $1.56$ (br s, water), integral $0.43$; $0.88$ (t, hexanes), integral $0.67$; $1.26$ (m, hexanes), integral $1.08$.\n\nUsing only the peaks assigned to the compound above, test the consistency of the proposed formula by computing the scale factor $k$ defined as the number of hydrogens per integral-unit that reconciles the measured total integral for the compound with the number of non-exchangeable hydrogens implied by the formula and conditions. Round your answer to four significant figures. Express $k$ in hydrogens per integral-unit.",
            "solution": "The core principle of quantitative $^{1}\\mathrm{H}$ NMR is that, under conditions of full relaxation, the integrated area of a resonance signal is directly proportional to the number of protons giving rise to that signal. The problem states that such conditions were ensured. The constant of proportionality, which we are asked to find, can be determined by relating the total number of observed protons to the total measured integral.\n\nFirst, we determine the number of protons, $H_{\\text{obs}}$, that contribute to the observed spectrum. The molecular formula of the compound is given as $\\mathrm{C}_{12}\\mathrm{H}_{16}\\mathrm{N}\\mathrm{O}_{3}$, which indicates a total of $H_{\\text{total}} = 16$ hydrogen atoms. The problem states that the compound possesses exactly one exchangeable $\\mathrm{N}\\!-\\!\\mathrm{H}$ proton, and that this proton's signal is not observed due to exchange with deuterium from the added deuterium oxide ($\\mathrm{D}_{2}\\mathrm{O}$). Therefore, the number of protons observed in the spectrum is the total number of hydrogens minus the number of exchangeable hydrogens.\n$$H_{\\text{obs}} = H_{\\text{total}} - H_{\\text{exch}}$$\nGiven $H_{\\text{total}} = 16$ and $H_{\\text{exch}} = 1$, the number of non-exchangeable, observed protons is:\n$$H_{\\text{obs}} = 16 - 1 = 15$$\n\nNext, we must calculate the total integrated area, $I_{\\text{total}}$, corresponding to these $15$ protons. The problem provides the integral values for the six signals assigned to the compound. We must sum these values, explicitly excluding signals from residual solvent and impurities as instructed.\nThe given integrals for the compound are:\n$I_1 = 12.36$\n$I_2 = 12.28$\n$I_3 = 11.98$\n$I_4 = 17.95$\n$I_5 = 17.88$\n$I_6 = 17.85$\n\nThe total integral is the sum of these individual integrals:\n$$I_{\\text{total}} = I_1 + I_2 + I_3 + I_4 + I_5 + I_6$$\n$$I_{\\text{total}} = 12.36 + 12.28 + 11.98 + 17.95 + 17.88 + 17.85$$\n$$I_{\\text{total}} = 90.30$$\n\nThe scale factor, $k$, is defined as the number of hydrogens per integral-unit. This is the ratio of the total number of observed protons to the total observed integral.\n$$k = \\frac{H_{\\text{obs}}}{I_{\\text{total}}}$$\nSubstituting the calculated values for $H_{\\text{obs}}$ and $I_{\\text{total}}$:\n$$k = \\frac{15}{90.30}$$\nCalculating the numerical value:\n$$k \\approx 0.16611295681...$$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $1$, $6$, $6$, and $1$. The fifth digit is $1$, which is less than $5$, so we round down.\n$$k \\approx 0.1661$$\nThe units of this scale factor are hydrogens per integral-unit. This result confirms the consistency between the observed spectral data and the proposed molecular formula under the specified experimental conditions.",
            "answer": "$$\\boxed{0.1661}$$"
        },
        {
            "introduction": "In many real spectra, multiplets overlap, making simple integration by summation inaccurate. This advanced hands-on exercise introduces lineshape deconvolution, a powerful computational method for extracting individual integrals from overlapping signals. By building a mathematical model of the spectrum and fitting it to data, you will not only determine accurate integrals but also learn how to quantify the uncertainty of your measurement , a key skill in rigorous scientific analysis.",
            "id": "3717984",
            "problem": "You are given a synthetic Nuclear Magnetic Resonance (NMR) one-dimensional frequency-domain spectrum consisting of two partially overlapping multiplets with known scalar coupling constants (J values). The goal is to recover the individual multiplet integrals (areas) and quantify their uncertainties by fitting a physically motivated model to the data. Work entirely in the frequency domain, in hertz (Hz), and assume Lorentzian line shapes.\n\nFundamental base and definitions:\n- Nuclear Magnetic Resonance (NMR) multiplets arise from scalar spin-spin coupling. For a first-order multiplet coupled to $n$ equivalent protons, the multiplet contains $n+1$ lines separated by the coupling constant $J$, with binomial intensity weights.\n- A normalized Lorentzian line centered at frequency $\\nu_0$ with half-width at half-maximum $\\Gamma$ is defined as\n$$\nL(\\nu; \\nu_0, \\Gamma) = \\frac{1}{\\pi} \\frac{\\Gamma}{(\\nu - \\nu_0)^2 + \\Gamma^2},\n$$\nso that $\\int_{-\\infty}^{\\infty} L(\\nu; \\nu_0, \\Gamma) \\, d\\nu = 1$.\n- A first-order multiplet profile is the weighted sum of discrete Lorentzians located at the multiplet line positions determined by the known $J$ values and the multiplet center, with binomial weights normalized to sum to $1$.\n- The total spectrum model over a finite window is the sum of two multiplet profiles, each scaled by its unknown integral, plus a baseline described by a constant offset and a linear slope. That is, for data at discrete frequencies $\\nu_i$,\n$$\nS(\\nu_i) = I_A \\, M_A(\\nu_i) + I_B \\, M_B(\\nu_i) + b_0 + b_1 \\, \\nu_i,\n$$\nwhere $I_A$ and $I_B$ are the unknown multiplet integrals (areas), $M_A$ and $M_B$ are known multiplet profile vectors constructed from Lorentzians given centers, coupling constants $J$, multiplicities, and line widths $\\Gamma$, and $(b_0, b_1)$ are unknown baseline coefficients.\n- Assume additive, independent, zero-mean Gaussian noise with known standard deviation $\\sigma$ at each $\\nu_i$.\n\nFitting-based deconvolution and uncertainty estimation:\n- Formulate the model as a linear weighted least-squares problem in the unknown parameter vector $\\mathbf{x} = [I_A, I_B, b_0, b_1]^\\top$:\n$$\n\\mathbf{y} = \\mathbf{X} \\mathbf{x} + \\boldsymbol{\\epsilon},\n$$\nwhere $\\mathbf{y}$ is the measured spectrum vector, $\\mathbf{X}$ is the design matrix with columns $\\mathbf{M}_A$, $\\mathbf{M}_B$, $\\mathbf{1}$, and $\\boldsymbol{\\nu}$, and $\\boldsymbol{\\epsilon}$ is Gaussian noise with variance $\\sigma^2$.\n- The weighted least-squares estimator is\n$$\n\\hat{\\mathbf{x}} = (\\mathbf{X}^\\top \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{W} \\mathbf{y},\n$$\nwhere $\\mathbf{W} = \\sigma^{-2} \\mathbf{I}$ when all points have the same noise standard deviation $\\sigma$.\n- The parameter covariance matrix is\n$$\n\\mathrm{Cov}(\\hat{\\mathbf{x}}) = (\\mathbf{X}^\\top \\mathbf{W} \\mathbf{X})^{-1}.\n$$\nThe standard uncertainties of the recovered integrals are $\\sigma_{I_A} = \\sqrt{\\mathrm{Cov}_{11}}$ and $\\sigma_{I_B} = \\sqrt{\\mathrm{Cov}_{22}}$.\n- The relative proton ratio estimate can be obtained from the ratio $r = \\hat{I}_A / \\hat{I}_B$. Approximating uncertainty by first-order error propagation:\n$$\n\\sigma_r = \\sqrt{\\begin{bmatrix} \\frac{\\partial r}{\\partial I_A} & \\frac{\\partial r}{\\partial I_B} & 0 & 0 \\end{bmatrix}\n\\mathrm{Cov}(\\hat{\\mathbf{x}})\n\\begin{bmatrix} \\frac{\\partial r}{\\partial I_A} \\\\ \\frac{\\partial r}{\\partial I_B} \\\\ 0 \\\\ 0 \\end{bmatrix}},\n\\quad\n\\frac{\\partial r}{\\partial I_A} = \\frac{1}{\\hat{I}_B}, \\quad \\frac{\\partial r}{\\partial I_B} = -\\frac{\\hat{I}_A}{\\hat{I}_B^2}.\n$$\n\nProgramming task:\n- Implement a program that, for each test case specified below, constructs the synthetic spectrum by summing two known multiplet profiles with specified centers, $J$ values, multiplicities, Lorentzian half-widths $\\Gamma$, and true integrals $(I_A^{\\mathrm{true}}, I_B^{\\mathrm{true}})$, adds a baseline $b_0 + b_1 \\nu$, and adds Gaussian noise with standard deviation $\\sigma$. Then perform weighted least-squares fitting to recover $\\hat{I}_A$, $\\hat{I}_B$, their standard uncertainties $(\\sigma_{I_A}, \\sigma_{I_B})$, and the ratio $r = \\hat{I}_A / \\hat{I}_B$ with its uncertainty $\\sigma_r$ using the covariance matrix. Use only the known $J$ values, multiplicities, centers, and widths to construct $M_A$ and $M_B$; treat $(I_A, I_B, b_0, b_1)$ as unknowns.\n- Angle units are not applicable; frequency must be treated in hertz. Express integrals and uncertainties in arbitrary area units (unitless). Express the ratio $r$ and its uncertainty $\\sigma_r$ as decimal floats.\n- For reproducibility, use a fixed pseudorandom seed.\n\nTest suite:\n- Case $1$ (moderate overlap, equal $J$):\n  - Frequency window: $\\nu \\in [90, 125]\\,\\mathrm{Hz}$ sampled at step $\\Delta \\nu = 0.1\\,\\mathrm{Hz}$.\n  - Multiplet $A$: doublet centered at $\\nu_A = 100\\,\\mathrm{Hz}$, coupling $J_A = 7\\,\\mathrm{Hz}$, Lorentzian half-width $\\Gamma_A = 1.2\\,\\mathrm{Hz}$, true integral $I_A^{\\mathrm{true}} = 2.0$.\n  - Multiplet $B$: triplet centered at $\\nu_B = 104\\,\\mathrm{Hz}$, coupling $J_B = 7\\,\\mathrm{Hz}$, Lorentzian half-width $\\Gamma_B = 1.2\\,\\mathrm{Hz}$, true integral $I_B^{\\mathrm{true}} = 3.0$.\n  - Baseline: $b_0 = 0.0$, $b_1 = 0.0$.\n  - Noise: $\\sigma = 0.02$.\n- Case $2$ (strong partial overlap, sloping baseline):\n  - Frequency window: $\\nu \\in [195, 207]\\,\\mathrm{Hz}$ sampled at step $\\Delta \\nu = 0.1\\,\\mathrm{Hz}$.\n  - Multiplet $A$: doublet centered at $\\nu_A = 200\\,\\mathrm{Hz}$, coupling $J_A = 6\\,\\mathrm{Hz}$, Lorentzian half-width $\\Gamma_A = 1.5\\,\\mathrm{Hz}$, true integral $I_A^{\\mathrm{true}} = 1.0$.\n  - Multiplet $B$: doublet centered at $\\nu_B = 203\\,\\mathrm{Hz}$, coupling $J_B = 6\\,\\mathrm{Hz}$, Lorentzian half-width $\\Gamma_B = 1.5\\,\\mathrm{Hz}$, true integral $I_B^{\\mathrm{true}} = 1.0$.\n  - Baseline: $b_0 = 0.0$, $b_1 = 0.002$.\n  - Noise: $\\sigma = 0.05$.\n- Case $3$ (asymmetric overlap, different $J$ and widths, baseline offset):\n  - Frequency window: $\\nu \\in [296, 308]\\,\\mathrm{Hz}$ sampled at step $\\Delta \\nu = 0.1\\,\\mathrm{Hz}$.\n  - Multiplet $A$: doublet centered at $\\nu_A = 300\\,\\mathrm{Hz}$, coupling $J_A = 2\\,\\mathrm{Hz}$, Lorentzian half-width $\\Gamma_A = 1.0\\,\\mathrm{Hz}$, true integral $I_A^{\\mathrm{true}} = 3.0$.\n  - Multiplet $B$: quartet centered at $\\nu_B = 302\\,\\mathrm{Hz}$, coupling $J_B = 7\\,\\mathrm{Hz}$, Lorentzian half-width $\\Gamma_B = 0.8\\,\\mathrm{Hz}$, true integral $I_B^{\\mathrm{true}} = 2.0$.\n  - Baseline: $b_0 = 0.1$, $b_1 = 0.0$.\n  - Noise: $\\sigma = 0.03$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case contributes a sublist in the form $[\\hat{I}_A, \\hat{I}_B, \\sigma_{I_A}, \\sigma_{I_B}, r, \\sigma_r]$. All numbers must be floats rounded to six decimal places. For example, a valid output shape is $[[i_{A,1}, i_{B,1}, s_{A,1}, s_{B,1}, r_1, s_{r,1}],[i_{A,2}, i_{B,2}, s_{A,2}, s_{B,2}, r_2, s_{r,2}], [i_{A,3}, i_{B,3}, s_{A,3}, s_{B,3}, r_3, s_{r,3}]]$ with no spaces in the printed string.",
            "solution": "The solution implements a computational approach to deconvolve the overlapping NMR signals by performing a linear least-squares fit. The methodology for each test case is as follows:\n\n1.  **Model Construction**:\n    *   A helper function generates a normalized Lorentzian lineshape.\n    *   Another function, `create_multiplet_profile`, constructs the basis function for each multiplet (e.g., doublet, triplet). It does this by summing normalized Lorentzian lines at positions determined by the multiplet center ($\\nu_0$) and coupling constant ($J$), with relative intensities given by binomial coefficients. The entire multiplet profile is normalized to have a unit area.\n\n2.  **Synthetic Data Generation**:\n    *   For each case, a frequency vector $\\boldsymbol{\\nu}$ is created for the specified spectral window.\n    *   The \"true,\" noiseless spectrum is generated by summing the two multiplet profiles (scaled by their true integrals $I_A^{\\mathrm{true}}$ and $I_B^{\\mathrm{true}}$) and adding the specified baseline ($b_0 + b_1 \\nu$).\n    *   Additive Gaussian noise with the specified standard deviation $\\sigma$ is generated using a seeded pseudorandom number generator and added to the true spectrum to create the final \"measured\" data vector $\\mathbf{y}$.\n\n3.  **Linear Least-Squares Fitting**:\n    *   The problem is formulated as a linear system $\\mathbf{y} = \\mathbf{X}\\mathbf{x}$, where $\\mathbf{x} = [I_A, I_B, b_0, b_1]^\\top$ is the vector of unknown parameters.\n    *   The design matrix $\\mathbf{X}$ is constructed. Its columns are the basis functions: the two multiplet profiles, a vector of ones (for the constant offset $b_0$), and the frequency vector $\\boldsymbol{\\nu}$ (for the linear slope $b_1$).\n    *   The system is solved for the parameter estimates $\\hat{\\mathbf{x}}$ using `numpy.linalg.lstsq`.\n\n4.  **Uncertainty Quantification**:\n    *   The parameter covariance matrix is calculated using the formula $\\mathrm{Cov}(\\hat{\\mathbf{x}}) = \\sigma^2 (\\mathbf{X}^\\top \\mathbf{X})^{-1}$, where $\\sigma$ is the known noise standard deviation.\n    *   The standard uncertainties of the estimated integrals, $\\sigma_{I_A}$ and $\\sigma_{I_B}$, are extracted as the square roots of the corresponding diagonal elements of the covariance matrix.\n    *   The ratio of the integrals, $r = \\hat{I}_A / \\hat{I}_B$, is calculated. Its uncertainty, $\\sigma_r$, is determined by propagating the errors using the full covariance matrix and the gradient of the ratio function, following the formula $\\sigma_r^2 = \\mathbf{g}^\\top \\mathrm{Cov}(\\hat{\\mathbf{x}}) \\mathbf{g}$.\n\nFinally, the estimated integrals, their uncertainties, the ratio, and its uncertainty are collected and formatted for each test case as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\n\ndef solve():\n    \"\"\"\n    Solves for multiplet integrals and their uncertainties from synthetic NMR data.\n    \n    The process involves:\n    1. Generating synthetic spectra for three test cases, including two overlapping\n       multiplets, a baseline, and Gaussian noise.\n    2. Constructing a linear model where the multiplet shapes are known basis functions\n       and their integrals (amplitudes) are unknown parameters.\n    3. Performing a weighted least-squares fit (which simplifies to OLS for this problem)\n       to estimate the integrals and baseline coefficients.\n    4. Calculating the covariance matrix of the estimated parameters.\n    5. Propagating uncertainties to find the standard errors of the integrals and\n       their ratio.\n    \"\"\"\n    # Use a fixed pseudorandom seed for reproducibility as requested.\n    rng = np.random.default_rng(42)\n\n    def lorentzian(nu, nu_0, gamma):\n        \"\"\"\n        Calculates a normalized Lorentzian lineshape vector.\n        L(v; v0, G) = (1/pi) * G / ((v - v0)^2 + G^2)\n        \"\"\"\n        return (1.0 / np.pi) * (gamma / ((nu - nu_0)**2 + gamma**2))\n\n    def create_multiplet_profile(nu_vector, center, J, gamma, multiplicity):\n        \"\"\"\n        Creates a normalized first-order multiplet profile as a sum of Lorentzians.\n        The profile's total integral is normalized to 1.\n        \"\"\"\n        multi_map = {'doublet': 1, 'triplet': 2, 'quartet': 3}\n        n = multi_map.get(multiplicity)\n        if n is None:\n            raise ValueError(f\"Unknown multiplicity: {multiplicity}\")\n\n        # Binomial coefficients give the relative line intensities.\n        coeffs = np.array([comb(n, k, exact=True) for k in range(n + 1)])\n        # Normalize weights to sum to 1.\n        coeffs = coeffs / np.sum(coeffs)\n\n        # Line positions are determined by the center and J-coupling.\n        # For a multiplet of n+1 lines (k=0...n), positions are center + J*(n/2 - k).\n        line_positions = center + J * (n / 2.0 - np.arange(n + 1))\n\n        # The final profile is the weighted sum of Lorentzian components.\n        profile = np.zeros_like(nu_vector, dtype=float)\n        for i in range(n + 1):\n            profile += coeffs[i] * lorentzian(nu_vector, line_positions[i], gamma)\n        \n        return profile\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Moderate overlap, equal J\n        {\n            'nu_range': (90.0, 125.0), 'delta_nu': 0.1,\n            'multiplet_A': {'center': 100.0, 'J': 7.0, 'gamma': 1.2, 'multiplicity': 'doublet', 'I_true': 2.0},\n            'multiplet_B': {'center': 104.0, 'J': 7.0, 'gamma': 1.2, 'multiplicity': 'triplet', 'I_true': 3.0},\n            'baseline': {'b0': 0.0, 'b1': 0.0},\n            'noise_sigma': 0.02\n        },\n        # Case 2: Strong partial overlap, sloping baseline\n        {\n            'nu_range': (195.0, 207.0), 'delta_nu': 0.1,\n            'multiplet_A': {'center': 200.0, 'J': 6.0, 'gamma': 1.5, 'multiplicity': 'doublet', 'I_true': 1.0},\n            'multiplet_B': {'center': 203.0, 'J': 6.0, 'gamma': 1.5, 'multiplicity': 'doublet', 'I_true': 1.0},\n            'baseline': {'b0': 0.0, 'b1': 0.002},\n            'noise_sigma': 0.05\n        },\n        # Case 3: Asymmetric overlap, different J and widths\n        {\n            'nu_range': (296.0, 308.0), 'delta_nu': 0.1,\n            'multiplet_A': {'center': 300.0, 'J': 2.0, 'gamma': 1.0, 'multiplicity': 'doublet', 'I_true': 3.0},\n            'multiplet_B': {'center': 302.0, 'J': 7.0, 'gamma': 0.8, 'multiplicity': 'quartet', 'I_true': 2.0},\n            'baseline': {'b0': 0.1, 'b1': 0.0},\n            'noise_sigma': 0.03\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # 1. Generate frequency axis and basis functions (multiplet profiles)\n        nu_min, nu_max = case['nu_range']\n        delta_nu = case['delta_nu']\n        nu = np.arange(nu_min, nu_max + 1e-9, delta_nu) # Add small epsilon for float endpoint\n        \n        pA = case['multiplet_A']\n        pB = case['multiplet_B']\n        baseline = case['baseline']\n        sigma = case['noise_sigma']\n\n        M_A = create_multiplet_profile(nu, pA['center'], pA['J'], pA['gamma'], pA['multiplicity'])\n        M_B = create_multiplet_profile(nu, pB['center'], pB['J'], pB['gamma'], pB['multiplicity'])\n\n        # 2. Generate synthetic measured data y = Xx + noise\n        y_true = (pA['I_true'] * M_A + \n                  pB['I_true'] * M_B + \n                  baseline['b0'] + \n                  baseline['b1'] * nu)\n        noise = rng.normal(loc=0.0, scale=sigma, size=nu.shape)\n        y_measured = y_true + noise\n\n        # 3. Construct the design matrix X for the linear model y = Xx\n        X = np.stack([M_A, M_B, np.ones_like(nu), nu], axis=1)\n\n        # 4. Perform least-squares fitting to find parameters x_hat = [I_A, I_B, b0, b1]\n        x_hat = np.linalg.lstsq(X, y_measured, rcond=None)[0]\n        I_A_hat, I_B_hat = x_hat[0], x_hat[1]\n        \n        # 5. Calculate the parameter covariance matrix: Cov(x_hat) = sigma^2 * (X^T X)^-1\n        XTX_inv = np.linalg.inv(X.T @ X)\n        cov_x = sigma**2 * XTX_inv\n        \n        # 6. Extract standard uncertainties for I_A and I_B\n        std_errs = np.sqrt(np.diag(cov_x))\n        sigma_IA = std_errs[0]\n        sigma_IB = std_errs[1]\n\n        # 7. Calculate the ratio r = I_A/I_B and its uncertainty via error propagation\n        r_hat = I_A_hat / I_B_hat\n        \n        # Gradient (Jacobian) of r with respect to parameters [I_A, I_B, b0, b1]\n        grad_r = np.array([1 / I_B_hat, -I_A_hat / I_B_hat**2, 0, 0])\n        var_r = grad_r @ cov_x @ grad_r.T\n        sigma_r = np.sqrt(var_r)\n\n        # 8. Store results, formatted to six decimal places\n        case_result = [\n            I_A_hat, I_B_hat, sigma_IA, sigma_IB, r_hat, sigma_r\n        ]\n        all_results.append(f\"[{','.join([f'{val:.6f}' for val in case_result])}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        }
    ]
}