{
    "hands_on_practices": [
        {
            "introduction": "奇异值分解 (Singular Value Decomposition, SVD) 是诊断线性系统中不适定性的一个强有力的数学工具。本练习将引导你通过 SVD 推导最小范数解，并精确地揭示微小的奇异值如何放大观测数据中的噪声，从而将 Jacques Hadamard 提出的稳定性准则与系统的代数性质直接联系起来 ()。这个过程对于理解不适定问题的核心机理至关重要。",
            "id": "3387743",
            "problem": "设 $K \\in \\mathbb{R}^{m \\times n}$ 是一个秩为 $r \\leq \\min\\{m,n\\}$ 的实矩阵，其奇异值分解 (singular value decomposition, SVD) 为 $K = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是对角矩阵，其非负对角元按 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{r} > 0$ 排序，其余为零。考虑线性反问题 $K x = y$，其中 $y \\in \\mathbb{R}^{m}$，以及最小范数解 $x^{\\dagger} := \\arg\\min \\{\\|x\\|_{2} : K x = y\\}$。\n\n仅从核心定义（正交性、奇异值分解 (SVD)、欧几里得 $2$-范数以及最小范数解的定义）出发，执行以下操作：\n\n- 推导 $x^{\\dagger}$ 关于奇异三元组 $\\{(u_{i}, \\sigma_{i}, v_{i})\\}_{i=1}^{r}$ 的表达式。\n- 使用 Hadamard 准则（存在性、唯一性、对数据的连续依赖性），确定在何种关于 $y$ 和 $\\sigma_{r}$ 的条件下，从数据到解的映射是适定的。然后，对于扰动 $y^{\\delta} = y + \\varepsilon$，推导在欧几里得 $2$-范数下，限制于 $y \\in \\operatorname{range}(K)$ 的数据到解映射 $y \\mapsto x^{\\dagger}$ 的 Lipschitz 常数 $L$。\n- 在右奇异向量基下，解释 $x^{\\dagger}$ 的每个系数如何依赖于比率 $1/\\sigma_{i}$，并说明为什么最小的正奇异值 $\\sigma_{r}$决定了最坏情况下的噪声放大。\n\n将你的最终答案表示为 Lipschitz 常数 $L$ 关于奇异值的精确解析表达式。无需四舍五入。仅报告所要求的 $L$ 的表达式作为最终答案。",
            "solution": "问题有效。我们按要求进行推导和分析。\n\n任务是分析线性反问题 $Kx=y$，其中 $K \\in \\mathbb{R}^{m \\times n}$ 是一个秩为 $\\operatorname{rank}(K) = r \\leq \\min\\{m,n\\}$ 的实矩阵。给定 $K$ 的奇异值分解 (SVD) 为 $K = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是奇异值的对角矩阵，$\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{r} > 0$ 且当 $i > r$ 时 $\\sigma_i = 0$。$U$ 的列向量记为 $\\{u_i\\}_{i=1}^m$，$V$ 的列向量记为 $\\{v_i\\}_{i=1}^n$。\n\n### 最小范数解 $x^{\\dagger}$ 的推导\n\n我们寻求定义为 $x^{\\dagger} := \\arg\\min \\{\\|x\\|_{2} : K x = y\\}$ 的解 $x^{\\dagger}$。该定义要求解集 $\\{x : Kx = y\\}$ 非空，这意味着我们假设 $y \\in \\operatorname{range}(K)$。\n\n我们首先将 SVD 代入方程 $Kx = y$：\n$$U \\Sigma V^{\\top} x = y$$\n由于 $U$ 是正交矩阵，其逆矩阵等于其转置，即 $U^{-1} = U^{\\top}$。我们在等式两边左乘 $U^{\\top}$：\n$$U^{\\top} (U \\Sigma V^{\\top} x) = U^{\\top} y$$\n$$(U^{\\top} U) \\Sigma V^{\\top} x = U^{\\top} y$$\n$$I_m \\Sigma V^{\\top} x = U^{\\top} y$$\n$$\\Sigma (V^{\\top} x) = U^{\\top} y$$\n让我们为解 $x \\in \\mathbb{R}^n$ 和数据 $y \\in \\mathbb{R}^m$ 引入基变换。我们定义新坐标 $\\alpha \\in \\mathbb{R}^n$ 和 $\\beta \\in \\mathbb{R}^m$ 如下：\n$$\\alpha = V^{\\top} x \\quad (\\text{因此 } x = V \\alpha \\text{，因为 } V \\text{ 是正交的})$$\n$$\\beta = U^{\\top} y \\quad (\\text{因此 } y = U \\beta \\text{，因为 } U \\text{ 是正交的})$$\n这些向量的分量是 $\\alpha_i = v_i^{\\top} x$ 和 $\\beta_i = u_i^{\\top} y$。方程 $\\Sigma (V^{\\top} x) = U^{\\top} y$ 简化为：\n$$\\Sigma \\alpha = \\beta$$\n以分量形式，该方程写作 $\\sigma_i \\alpha_i = \\beta_i$，其中 $i=1, \\dots, \\min\\{m, n\\}$。\n\n我们必须分析关于索引 $i$ 的两种情况：\n1.  对于 $i=1, \\dots, r$，奇异值为正，$\\sigma_i > 0$。因此，系数 $\\alpha_i$ 是唯一确定的：\n    $$\\alpha_i = \\frac{\\beta_i}{\\sigma_i} = \\frac{u_i^{\\top} y}{\\sigma_i}$$\n2.  对于 $i > r$，奇异值为零，$\\sigma_i = 0$。方程变为 $0 \\cdot \\alpha_i = \\beta_i$。\n    为了使解存在，必须对于所有 $i > r$ 都有 $\\beta_i = u_i^{\\top} y = 0$。这个条件等价于 $y$ 必须与向量集 $\\{u_{r+1}, \\dots, u_m\\}$ 正交，而这些向量构成了 $K^{\\top}$ 的零空间 $\\operatorname{null}(K^{\\top})$ 的一组基。这与我们最初假设的条件 $y \\in \\operatorname{range}(K)$ 相同。\n    对于这些索引 $i > r$，系数 $\\alpha_i$ 并未由方程确定，可以是任意实数。\n\n任何解 $x$ 都可以写在基 $\\{v_i\\}$ 下，形式为 $x = \\sum_{i=1}^{n} \\alpha_i v_i$。代入推导出的系数，得到解的一般形式：\n$$x = \\sum_{i=1}^{r} \\left(\\frac{u_i^{\\top} y}{\\sigma_i}\\right) v_i + \\sum_{i=r+1}^{n} \\alpha_i v_i$$\n第二个求和项代表了来自 $K$ 的零空间的任意向量，因为对于 $i>r$，有 $K v_i = \\sigma_i u_i = 0$。\n\n现在，我们通过最小化 $\\|x\\|_2$ 来找到最小范数解 $x^{\\dagger}$。由于 $V$ 是正交矩阵，它保持欧几里得范数不变：\n$$\\|x\\|_{2}^{2} = \\|V\\alpha\\|_{2}^{2} = \\alpha^{\\top}V^{\\top}V\\alpha = \\alpha^{\\top}\\alpha = \\|\\alpha\\|_{2}^{2}$$\n范数的平方是：\n$$\\|x\\|_{2}^{2} = \\sum_{i=1}^{n} \\alpha_i^2 = \\sum_{i=1}^{r} \\left(\\frac{u_i^{\\top} y}{\\sigma_i}\\right)^2 + \\sum_{i=r+1}^{n} \\alpha_i^2$$\n为了最小化此范数，我们必须选择对于 $i > r$ 的任意系数 $\\alpha_i$ 为零。即，对于 $i=r+1, \\dots, n$，$\\alpha_i = 0$。这个选择消除了来自 $K$ 的零空间的任何分量，使得解与 $\\operatorname{null}(K)$ 正交。\n因此，最小范数解为：\n$$x^{\\dagger} = \\sum_{i=1}^{r} \\frac{u_i^{\\top} y}{\\sigma_i} v_i$$\n这就是 $x^{\\dagger}$ 关于奇异三元组 $\\{(u_{i}, \\sigma_{i}, v_{i})\\}_{i=1}^{r}$ 的表达式。\n\n### Hadamard 适定性与 Lipschitz 常数\n\n一个适定问题的 Hadamard 准则包括存在性、唯一性以及解对数据的连续依赖性。\n1.  **存在性**：$Kx=y$ 的解存在当且仅当 $y \\in \\operatorname{range}(K)$。对于任意 $y \\in \\mathbb{R}^m$，解可能不存在。因此，该问题在存在性上是不适定的。\n2.  **唯一性**：如果 $\\operatorname{rank}(K) = r  n$，$K$ 的零空间非平凡。在这种情况下，如果解存在，则有无穷多个解。因此，该问题在唯一性上是不适定的。\n\n然而，如果我们把问题重新表述为对任何数据 $y \\in \\mathbb{R}^m$ 寻找唯一的最小范数解 $x^{\\dagger}$，这个新问题就有一个唯一的解，由 $x^{\\dagger} = K^{\\dagger} y$ 给出，其中 $K^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top}$ 是 Moore-Penrose 伪逆，$\\Sigma^{\\dagger}$ 是一个 $n \\times m$ 矩阵，其元素在 $i=1,\\dots,r$ 时为 $1/\\sigma_i$，其余为零。我们推导出的 $x^{\\dagger}$ 公式在 $y \\in \\operatorname{range}(K)$ 的情况下与此等价。对于 $y \\notin \\operatorname{range}(K)$，$K^{\\dagger}y$ 产生最小范数最小二乘解。寻找 $x^{\\dagger}$ 的问题在存在性和唯一性上总是适定的。\n\n3.  **连续依赖性（稳定性）**：我们考察映射 $G: y \\mapsto x^{\\dagger}$ 在 $y \\in \\operatorname{range}(K)$ 上的稳定性。设 $y_1, y_2 \\in \\operatorname{range}(K)$，并令 $x_1^{\\dagger} = G(y_1)$, $x_2^{\\dagger} = G(y_2)$。该映射是线性的，因为 $x^{\\dagger}$ 是 $y$ 的线性函数。我们想要找到这个映射的 Lipschitz 常数 $L$，对于线性映射来说，它就是其算子范数。\n$$L = \\sup_{y \\in \\operatorname{range}(K), y \\neq 0} \\frac{\\|G(y)\\|_2}{\\|y\\|_2} = \\sup_{y \\in \\operatorname{range}(K), y \\neq 0} \\frac{\\|x^{\\dagger}\\|_2}{\\|y\\|_2}$$\n在各自的奇异基下使用 $x^{\\dagger}$ 和 $y$ 的表达式：\n$x^{\\dagger} = \\sum_{i=1}^{r} \\frac{u_i^{\\top} y}{\\sigma_i} v_i$。由于 $\\{v_i\\}$ 是标准正交的，$\\|x^{\\dagger}\\|_2^2 = \\sum_{i=1}^{r} \\left(\\frac{u_i^{\\top} y}{\\sigma_i}\\right)^2$。\n由于 $y \\in \\operatorname{range}(K)$，$y$ 可以写为 $y = \\sum_{i=1}^{r} (u_i^{\\top} y) u_i$。由于 $\\{u_i\\}_{i=1}^r$ 是标准正交的，$\\|y\\|_2^2 = \\sum_{i=1}^{r} (u_i^{\\top} y)^2$。\n\n范数平方的比值为：\n$$\\frac{\\|x^{\\dagger}\\|_2^2}{\\|y\\|_2^2} = \\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2 / \\sigma_i^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2}$$\n由于 $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r > 0$，我们有对于所有 $i=1, \\dots, r$，都有 $1/\\sigma_i^2 \\leq 1/\\sigma_r^2$。\n$$\\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2 / \\sigma_i^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2} \\leq \\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2 / \\sigma_r^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2} = \\frac{1}{\\sigma_r^2} \\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2} = \\frac{1}{\\sigma_r^2}$$\n这表明 $\\frac{\\|x^{\\dagger}\\|_2}{\\|y\\|_2} \\leq \\frac{1}{\\sigma_r}$。为了证明上确界恰好是 $1/\\sigma_r$，我们必须找到一个向量 $y$ 使此界可以达到。我们选择 $y = u_r$。这个向量在 $\\operatorname{range}(K)$ 中。对于此选择：\n$u_i^{\\top} y = u_i^{\\top} u_r = \\delta_{ir}$ (Kronecker δ)。\n那么 $\\|y\\|_2^2 = \\|u_r\\|_2^2 = 1$。\n并且 $\\|x^{\\dagger}\\|_2^2 = \\sum_{i=1}^{r} (\\delta_{ir}/\\sigma_i)^2 = (1/\\sigma_r)^2$。\n因此，对于 $y = u_r$，我们有 $\\frac{\\|x^{\\dagger}\\|_2}{\\|y\\|_2} = \\frac{1/\\sigma_r}{1} = \\frac{1}{\\sigma_r}$。\n既然我们找到了一个达到上界的向量，那么上确界就是这个值。限制在 $y \\in \\operatorname{range}(K)$ 上的数据到解映射 $y \\mapsto x^{\\dagger}$ 的 Lipschitz 常数是：\n$$L = \\frac{1}{\\sigma_r}$$\n只要 $\\sigma_r > 0$，该映射就是连续的。然而，如果 $\\sigma_r$ 非常小，Lipschitz 常数 $L$ 就会非常大，这表明数据 $y$ 中的小扰动可能导致解 $x^{\\dagger}$ 的巨大变化。这是一个不适定（或者更准确地说，病态）问题的典型特征。\n\n### 噪声放大分析\n\n解 $x^{\\dagger}$ 在右奇异向量基 $\\{v_1, \\dots, v_n\\}$ 下表示为：\n$$x^{\\dagger} = \\sum_{i=1}^{r} \\alpha_i v_i, \\quad \\text{其中系数为 } \\alpha_i = \\frac{u_i^{\\top} y}{\\sigma_i}$$\n解的每个系数 $\\alpha_i$ 由数据 $y$ 在相应左奇异向量 $u_i$ 上的投影，并按奇异值的倒数 $1/\\sigma_i$ 进行缩放而确定。\n\n现在，考虑受扰动的数据 $y^{\\delta} = y + \\varepsilon$，其中 $\\varepsilon$ 是某种噪声或误差。新的最小范数解是 $x^{\\delta\\dagger} = K^{\\dagger} y^{\\delta}$。解的误差为 $\\Delta x = x^{\\delta\\dagger} - x^{\\dagger} = K^{\\dagger}(y+\\varepsilon) - K^{\\dagger}y = K^{\\dagger}\\varepsilon$。\n使用伪逆作用的公式：\n$$\\Delta x = \\sum_{i=1}^{r} \\frac{u_i^{\\top} \\varepsilon}{\\sigma_i} v_i$$\n解误差沿方向 $v_i$ 的系数是 $\\frac{u_i^{\\top} \\varepsilon}{\\sigma_i}$。这表明数据噪声在方向 $u_i$ 上的分量 $u_i^{\\top} \\varepsilon$，被因子 $1/\\sigma_i$ 放大，从而产生解误差在方向 $v_i$ 上的相应分量。\n\n放大因子为 $\\{1/\\sigma_1, 1/\\sigma_2, \\dots, 1/\\sigma_r\\}$。由于 $\\sigma_1 \\geq \\dots \\geq \\sigma_r > 0$，这些因子中最大的一个是 $1/\\sigma_r$。因此，最小的正奇异值 $\\sigma_r$ 决定了最坏情况下的噪声放大。任何在 $u_r$ 上有非零投影的噪声分量 $\\varepsilon$ 都将被最大因子 $1/\\sigma_r$ 放大。如果 $\\sigma_r$ 接近于零，这种放大可能是巨大的，从而完全破坏解的稳定性。这说明了为什么最小非零奇异值的大小是衡量反问题病态程度的关键指标。",
            "answer": "$$\\boxed{\\frac{1}{\\sigma_{r}}}$$"
        },
        {
            "introduction": "将视角从有限维矩阵扩展到无限维的函数空间，不适定性的挑战变得更加微妙。本练习将分析一个看似简单的乘法算子，通过构造一个具体的函数序列，来证明算子的单射性和值域的稠密性并不足以保证解的稳定性 ()。这一结论是泛函分析中理解不适定算子的一个关键见解，它强调了为何连续依赖性是 Hadamard 适定性定义中一个不可或缺的独立条件。",
            "id": "3387707",
            "problem": "考虑在勒贝格空间 $L^{2}(0,1)$ 上提出的线性反问题 $T f = g$，其中正算子 $T : L^{2}(0,1) \\to L^{2}(0,1)$ 定义为 $(T f)(x) = x f(x)$，对于 $x \\in (0,1)$。在阿达玛适定性的意义上，稳定性指的是解对数据的连续依赖性，这对于线性反问题等价于逆算子 $T^{-1}$ 在 $T$ 的值域 $\\operatorname{Ran}(T)$ 上的有界性。\n\n从单射性、稠密值域和稳定性的核心定义出发，并且仅使用 $L^{2}(0,1)$ 和 $L^{2}$-范数的标准性质，完成以下任务：\n\n- 证明 $T$ 在 $L^{2}(0,1)$ 上是单射的。\n- 证明 $\\operatorname{Ran}(T)$ 在 $L^{2}(0,1)$ 中是稠密的。\n- 通过构造一个具体的序列 $\\{f_{n}\\}_{n\\in\\mathbb{N}} \\subset L^{2}(0,1)$ 来证明稳定性不成立，该序列对应的资料 $g_{n} = T f_{n}$ 满足 $\\|g_{n}\\|_{L^{2}(0,1)} \\to 0$，同时 $\\|f_{n}\\|_{L^{2}(0,1)} \\to \\infty$。您的构造必须是明确的，并从第一性原理出发进行论证。\n\n对于由 $f_{n}(x) = n \\,\\chi_{(0,1/n)}(x)$ 给出的特定序列，其中 $\\chi_{(0,1/n)}$ 是区间 $(0,1/n)$ 的指示函数，计算放大因子\n$$\nA_{n} \\equiv \\frac{\\|f_{n}\\|_{L^{2}(0,1)}}{\\|T f_{n}\\|_{L^{2}(0,1)}}\n$$\n的精确解析表达式，作为 $n$ 的封闭形式。提供 $A_{n}$ 的表达式；不需要四舍五入。",
            "solution": "该问题在泛函分析和反问题领域是适定的且有科学依据的。我们开始解题。\n\n问题要求分析线性算子 $T: L^{2}(0,1) \\to L^{2}(0,1)$，其定义为对 $x \\in (0,1)$ 有 $(Tf)(x) = xf(x)$。空间 $L^{2}(0,1)$ 是区间 $(0,1)$ 上的平方可积函数空间，配备内积 $\\langle f,g \\rangle = \\int_0^1 f(x)\\overline{g(x)}dx$ 和相关联的范数 $\\|f\\|_{L^2} = \\left(\\int_0^1 |f(x)|^2 dx\\right)^{1/2}$。\n\n首先，我们证明算子 $T$ 是单射的。一个算子 $T$ 是单射的，如果它的零空间（或核）只包含零元素。对于线性算子，这等价于证明 $Tf = 0$ 蕴含 $f = 0$。\n设 $f \\in L^2(0,1)$ 使得 $Tf = 0$。根据定义，这意味着对于几乎所有的 $x \\in (0,1)$，有 $(Tf)(x) = 0$。\n代入算子 $T$ 的定义，我们有对于几乎所有的 $x \\in (0,1)$，$x f(x) = 0$。\n对于开区间 $(0,1)$ 中的任何 $x$，我们有 $x \\neq 0$。因此，为了使乘积 $xf(x)$ 为零，必须有 $f(x)=0$。这对几乎所有的 $x \\in (0,1)$ 都成立。一个在其定义域上几乎处处为零的函数是 $L^2(0,1)$ 空间中的零元素。因此，在 $L^2(0,1)$ 中 $f = 0$。\n$T$ 的零空间是 $\\ker(T) = \\{0\\}$，这证明了 $T$ 是单射的。\n\n其次，我们证明 $T$ 的值域，记作 $\\operatorname{Ran}(T)$，在 $L^2(0,1)$ 中是稠密的。为了证明这一点，我们必须表明对于任意函数 $h \\in L^2(0,1)$ 和任意 $\\epsilon > 0$，都存在一个函数 $g \\in \\operatorname{Ran}(T)$ 使得 $\\|h - g\\|_{L^2}  \\epsilon$。\n设 $h \\in L^2(0,1)$ 是任意的。对于任意 $\\delta \\in (0,1)$，我们定义一个函数 $g_{\\delta}$ 为 $g_{\\delta}(x) = h(x) \\chi_{(\\delta,1)}(x)$，其中 $\\chi_{(\\delta,1)}$ 是区间 $(\\delta,1)$ 的指示函数。\n我们希望证明 $g_{\\delta} \\in \\operatorname{Ran}(T)$。这需要找到一个函数 $f_{\\delta} \\in L^2(0,1)$ 使得 $(T f_{\\delta})(x) = g_{\\delta}(x)$，即 $x f_{\\delta}(x) = g_{\\delta}(x)$。我们可以定义 $f_{\\delta}(x) = \\frac{g_{\\delta}(x)}{x} = \\frac{h(x)}{x} \\chi_{(\\delta,1)}(x)$。\n我们必须验证这个 $f_{\\delta}$ 确实在 $L^2(0,1)$ 中。我们计算它的范数：\n$$\n\\|f_{\\delta}\\|_{L^2}^2 = \\int_0^1 |f_{\\delta}(x)|^2 dx = \\int_0^1 \\left|\\frac{h(x)}{x} \\chi_{(\\delta,1)}(x)\\right|^2 dx = \\int_{\\delta}^1 \\frac{|h(x)|^2}{x^2} dx\n$$\n在积分区间 $[\\delta,1]$ 上，我们有 $x \\ge \\delta > 0$，这意味着 $\\frac{1}{x^2} \\le \\frac{1}{\\delta^2}$。因此，\n$$\n\\|f_{\\delta}\\|_{L^2}^2 \\le \\int_{\\delta}^1 \\frac{|h(x)|^2}{\\delta^2} dx = \\frac{1}{\\delta^2} \\int_{\\delta}^1 |h(x)|^2 dx \\le \\frac{1}{\\delta^2} \\int_0^1 |h(x)|^2 dx = \\frac{1}{\\delta^2} \\|h\\|_{L^2}^2\n$$\n由于 $h \\in L^2(0,1)$，其范数 $\\|h\\|_{L^2}$ 是有限的。对于任何固定的 $\\delta > 0$，$\\|f_{\\delta}\\|_{L^2}^2$ 是有限的，所以 $f_{\\delta} \\in L^2(0,1)$。这证实了对于任何 $\\delta \\in (0,1)$，$g_{\\delta} \\in \\operatorname{Ran}(T)$。\n现在我们考察 $h$ 和我们的近似函数 $g_{\\delta}$ 之间的距离：\n$$\n\\|h - g_{\\delta}\\|_{L^2}^2 = \\int_0^1 |h(x) - g_{\\delta}(x)|^2 dx = \\int_0^1 |h(x) - h(x)\\chi_{(\\delta,1)}(x)|^2 dx = \\int_0^1 |h(x)(1 - \\chi_{(\\delta,1)}(x))|^2 dx\n$$\n由于对于 $x \\in [0,1]$，有 $1 - \\chi_{(\\delta,1)}(x) = \\chi_{[0,\\delta]}(x)$，我们得到：\n$$\n\\|h - g_{\\delta}\\|_{L^2}^2 = \\int_0^1 |h(x)\\chi_{[0,\\delta]}(x)|^2 dx = \\int_0^{\\delta} |h(x)|^2 dx\n$$\n函数 $F(y) = \\int_0^y |h(x)|^2 dx$ 是 $y$ 的一个绝对连续函数。因为 $|h|^2$ 是一个可积函数（由于 $h \\in L^2$），我们有 $\\lim_{\\delta \\to 0^+} \\int_0^{\\delta} |h(x)|^2 dx = 0$。\n因此，对于任何给定的 $\\epsilon > 0$，我们可以选择一个足够小的 $\\delta > 0$ 使得 $\\|h - g_{\\delta}\\|_{L^2}^2  \\epsilon^2$，这意味着 $\\|h - g_{\\delta}\\|_{L^2}  \\epsilon$。我们找到了 $\\operatorname{Ran}(T)$ 中的一个元素 $g_{\\delta}$，它可以任意地接近 $h$。这证明了 $\\operatorname{Ran}(T)$ 在 $L^2(0,1)$ 中是稠密的。\n\n第三，我们证明该反问题缺乏稳定性。在此背景下，稳定性意味着逆算子 $T^{-1}: \\operatorname{Ran}(T) \\to L^2(0,1)$ 是有界的。一个算子是有界的，如果存在一个常数 $C$ 使得对于所有 $g \\in \\operatorname{Ran}(T)$，都有 $\\|T^{-1}g\\|_{L^2} \\le C \\|g\\|_{L^2}$。我们将通过构造一个函数序列 $\\{f_n\\}_{n\\in\\mathbb{N}}$ 来表明 $T^{-1}$ 是无界的，使得比率 $\\frac{\\|f_n\\|_{L^2}}{\\|Tf_n\\|_{L^2}}$ 是无界的。\n设 $f_n(x) = n \\chi_{(0,1/n)}(x)$，其中 $n \\in \\mathbb{N}$ 且 $n \\ge 2$。\n我们计算 $f_n$ 的 $L^2$-范数：\n$$\n\\|f_n\\|_{L^2}^2 = \\int_0^1 |f_n(x)|^2 dx = \\int_0^{1/n} n^2 dx = n^2 [x]_0^{1/n} = n^2 \\left(\\frac{1}{n}\\right) = n\n$$\n所以，$\\|f_n\\|_{L^2} = \\sqrt{n}$。当 $n \\to \\infty$ 时，$\\|f_n\\|_{L^2} \\to \\infty$。\n\n接下来，我们计算相应的数据 $g_n = Tf_n$ 及其范数。\n$$\ng_n(x) = (Tf_n)(x) = x f_n(x) = x(n \\chi_{(0,1/n)}(x)) = nx \\chi_{(0,1/n)}(x)\n$$\n$g_n$ 的 $L^2$-范数是：\n$$\n\\|g_n\\|_{L^2}^2 = \\|Tf_n\\|_{L^2}^2 = \\int_0^1 |g_n(x)|^2 dx = \\int_0^{1/n} (nx)^2 dx = n^2 \\int_0^{1/n} x^2 dx\n$$\n$$\n\\|Tf_n\\|_{L^2}^2 = n^2 \\left[\\frac{x^3}{3}\\right]_0^{1/n} = n^2 \\left(\\frac{(1/n)^3}{3}\\right) = n^2 \\left(\\frac{1}{3n^3}\\right) = \\frac{1}{3n}\n$$\n所以，$\\|Tf_n\\|_{L^2} = \\sqrt{\\frac{1}{3n}} = \\frac{1}{\\sqrt{3n}}$。当 $n \\to \\infty$ 时，$\\|Tf_n\\|_{L^2} \\to 0$。\n\n我们构造了一个序列 $\\{f_n\\}$，其范数趋于无穷大，而数据 $\\{Tf_n\\}$ 的范数趋于零。这表明数据中的小扰动可能导致解中任意大的扰动，这是不稳定性的标志。算子 $T^{-1}$ 是无界的，因为当 $n \\to \\infty$ 时，比率 $\\frac{\\|f_n\\|_{L^2}}{\\|Tf_n\\|_{L^2}}$ 无界增长。\n\n最后，我们计算放大因子 $A_n$ 的精确解析表达式：\n$$\nA_n \\equiv \\frac{\\|f_n\\|_{L^2}}{\\|T f_n\\|_{L^2}}\n$$\n使用我们之前计算的范数：\n$$\nA_n = \\frac{\\sqrt{n}}{\\frac{1}{\\sqrt{3n}}} = \\sqrt{n} \\cdot \\sqrt{3n} = \\sqrt{3n^2} = n\\sqrt{3}\n$$\n当 $n \\to \\infty$ 时，$A_n \\to \\infty$，这明确地证实了逆算子的无界性。",
            "answer": "$$\n\\boxed{n\\sqrt{3}}\n$$"
        },
        {
            "introduction": "将理论概念带入实际的计算场景中，是检验和深化理解的必经之路。本练习聚焦于在气象预报等领域广泛应用的集合卡尔曼滤波 (Ensemble Kalman Filter) 方法。你将通过编写代码，亲身体验预报误差协方差的秩亏损如何导致分析步骤的矩阵病态，并探索协方差膨胀和局域化等标准技术如何作为有效的正则化手段，恢复系统的数值稳定性 ()。",
            "id": "3387787",
            "problem": "考虑一个使用集成卡尔曼滤波器 (EnKF) 的线性高斯数据同化问题，其中分析步通过求解观测空间线性系统来得到分析均值。设预报（背景）状态的维数为 $n$，观测数量为 $m$，集成大小为 $N_e$，预报误差协方差为 $P^f \\in \\mathbb{R}^{n \\times n}$，线性观测算子为 $H \\in \\mathbb{R}^{m \\times n}$，观测误差协方差为 $R \\in \\mathbb{R}^{m \\times m}$。典范分析公式引入了对称正定 (SPD) 矩阵 $$S = H P^f H^\\top + R,$$ 其逆将新息映射到观测空间中的分析增量。在 Hadamard 适定性（解的存在性、唯一性和稳定性）的意义上，分析步的数值稳定性由谱条件数 $$\\kappa(S) = \\frac{\\lambda_{\\max}(S)}{\\lambda_{\\min}(S)}$$ 来量化，其中 $\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 分别表示最大和最小特征值。大的 $\\kappa(S)$ 表示病态，意味着数据中的小扰动可能导致分析增量产生大扰动。\n\n两种标准的修正方法是在形成 $S$ 之前修改 $P^f$：\n- 使用参数 $\\beta \\ge 0$ 的加性协方差膨胀，$$\\widetilde{P}^f_{\\text{add}} = P^f + \\beta I_n.$$\n- 使用一个相关矩阵 $L(\\ell) \\in \\mathbb{R}^{n \\times n}$ 进行协方差局地化，该矩阵由长度尺度为 $\\ell  0$ 的高斯相关函数构建，并通过 Schur (Hadamard) 积作用，$$\\widetilde{P}^f_{\\text{loc}} = L(\\ell) \\circ P^f,$$ 其中 $[L(\\ell)]_{ij} = \\exp\\!\\left(-\\left(\\frac{d_{ij}}{\\ell}\\right)^2\\right)$，$d_{ij}$ 是在 $[0,1]$ 上的均匀一维网格上点 $i$ 和 $j$ 之间的欧几里得距离，$\\circ$ 表示逐元素乘法。对于 $\\ell \\le 0$，定义 $L(\\ell)$ 为全一矩阵，此时局地化不起作用。结合两者可得 $$\\widetilde{P}^f_{\\text{both}} = \\left(L(\\ell) \\circ P^f\\right) + \\beta I_n.$$\n\n您的任务是实现一个确定性的、可复现的实验，该实验构造合成的 $P^f$ 并形成 $$S_{\\text{base}} = H P^f H^\\top + R,\\quad S_{\\text{add}} = H \\widetilde{P}^f_{\\text{add}} H^\\top + R,\\quad S_{\\text{loc}} = H \\widetilde{P}^f_{\\text{loc}} H^\\top + R,\\quad S_{\\text{both}} = H \\widetilde{P}^f_{\\text{both}} H^\\top + R,$$ 然后量化条件数改善因子 $$\\rho_{\\text{add}} = \\frac{\\kappa(S_{\\text{base}})}{\\kappa(S_{\\text{add}})},\\quad \\rho_{\\text{loc}} = \\frac{\\kappa(S_{\\text{base}})}{\\kappa(S_{\\text{loc}})},\\quad \\rho_{\\text{both}} = \\frac{\\kappa(S_{\\text{base}})}{\\kappa(S_{\\text{both}})}.$$ $\\rho  1$ 的值表示条件数得到改善（条件数变小），这反映了稳定性的提高，从而使分析步向适定性恢复。\n\n使用以下基本基础和构造：\n- 分析步由线性高斯最小二乘代价函数定义：$$J(x) = \\frac{1}{2}\\|x - x^f\\|_{(P^f)^{-1}}^2 + \\frac{1}{2}\\|y - H x\\|_{R^{-1}}^2.$$ 观测空间中的正规方程涉及 $S = H P^f H^\\top + R$，其可逆性和条件数控制着解的稳定性。\n- 观测算子是选择矩阵 $H = [I_m, 0] \\in \\mathbb{R}^{m \\times n}$，它精确观测前 $m$ 个状态分量。\n- 观测误差协方差为 $R = \\sigma_R^2 I_m$，其中给定一个标量 $\\sigma_R^2  0$。\n- 预报协方差 $P^f$ 根据下文规定，由合成集成或结构化低秩形式确定性地构造。当使用集成时，通过对列进行中心化并除以 $\\sqrt{N_e - 1}$ 进行缩放，形成集成异常矩阵 $A \\in \\mathbb{R}^{n \\times N_e}$，然后设 $P^f = A A^\\top$。\n\n在均匀网格点 $x_i = \\frac{i}{n-1}$（其中 $i \\in \\{0,1,\\dots,n-1\\}$）上实现高斯局地化 $L(\\ell)$，距离为 $d_{ij} = |x_i - x_j|$。对于 $\\ell \\le 0$，设 $L(\\ell) = \\mathbf{1}\\mathbf{1}^\\top$。\n\n测试套件：\n对于下面的每个测试用例，根据指定的模式构造 $P^f$。如果模式为“ensemble”，则使用给定的种子确定性地抽取异常，通过对角缩放 $D = \\mathrm{diag}(s)$（其中对于 $i = 0,\\dots,n-1$，$s_i = \\exp\\!\\left(g \\cdot \\left(\\frac{i}{n-1} - \\frac{1}{2}\\right)\\right)$）应用参数为 $g$ 的各向异性剖面，并在形成 $P^f = A A^\\top$ 之前设置 $A \\leftarrow D A$。如果模式为“rank1”，则使用给定的种子确定性地抽取一个向量 $u \\in \\mathbb{R}^n$，将其归一化为 $\\|u\\|_2 = 1$，并设置 $P^f = \\sigma_r^2 u u^\\top + \\epsilon I_n$。\n\n- 测试用例 1（理想情况，具有小 $R$ 的离散不足的低秩集成）：\n  - $n=40$, $m=40$, $N_e=8$, $\\sigma_R^2 = 10^{-4}$, $\\beta = 10^{-2}$, $\\ell = 0.15$, seed $=42$, mode $=$ “ensemble”, $g = \\log(10^5)$。\n\n- 测试用例 2（边界情况，具有极小 $R$ 的极端秩亏）：\n  - $n=60$, $m=30$, $N_e=3$, $\\sigma_R^2 = 10^{-6}$, $\\beta = 10^{-3}$, $\\ell = 0.2$, seed $=123$, mode $=$ “ensemble”, $g = \\log(10^8)$。\n\n- 测试用例 3（边缘情况，已是良态，不加修正）：\n  - $n=40$, $m=40$, $N_e=80$, $\\sigma_R^2 = 10^{-1}$, $\\beta = 0$, $\\ell = 0$, seed $=7$, mode $=$ “ensemble”, $g = \\log(10)$。\n\n- 测试用例 4（边缘情况，凸显局地化在强伪长程相关下的优势）：\n  - $n=50$, $m=50$, $N_e=10$ (未使用), $\\sigma_R^2 = 10^{-3}$, $\\beta = 0$, $\\ell = 0.25$, seed $=99$, mode $=$ “rank1”, $\\sigma_r = 5$, $\\epsilon = 10^{-8}$。\n\n计算与输出：\n- 对于每个测试用例，通过特征值（使用对称特征值例程）计算 $\\kappa(S_{\\text{base}})$、$\\kappa(S_{\\text{add}})$、$\\kappa(S_{\\text{loc}})$、$\\kappa(S_{\\text{both}})$，然后计算 $\\rho_{\\text{add}}$、$\\rho_{\\text{loc}}$、$\\rho_{\\text{both}}$。\n- 您的程序应生成单行输出，其中包含按顺序排列的 4 个测试用例的 3 个改善因子组成的平坦列表，每个值四舍五入到 6 位小数，格式如下\n  $$[\\rho_{\\text{add}}^{(1)},\\rho_{\\text{loc}}^{(1)},\\rho_{\\text{both}}^{(1)},\\rho_{\\text{add}}^{(2)},\\rho_{\\text{loc}}^{(2)},\\rho_{\\text{both}}^{(2)},\\rho_{\\text{add}}^{(3)},\\rho_{\\text{loc}}^{(3)},\\rho_{\\text{both}}^{(3)},\\rho_{\\text{add}}^{(4)},\\rho_{\\text{loc}}^{(4)},\\rho_{\\text{both}}^{(4)}].$$\n- 程序不应读取任何输入；所有参数均如上所述，程序必须是自包含且确定性的。\n\n所有数学符号必须遵循标准线性代数惯例，此问题不涉及任何物理单位或角度。将所有最终数值输出表示为四舍五入到小数点后六位的十进制浮点数。",
            "solution": "用户要求对两种标准技术——加性协方差膨胀和协方差局地化——进行定量评估。这两种技术用于改善集成卡尔曼滤波器 (EnKF) 中分析步的数值稳定性。稳定性由出现在正规方程中的矩阵 $S = H P^f H^\\top + R$ 的谱条件数来衡量。在 Hadamard 的意义上，较低的条件数表示系统更稳定，或称更适定。该问题在科学上是有效的，是自包含的，并且在算法上是明确定义的。\n\n解决方案首先定义所有数学组件，然后概述计算每个测试用例所需的条件数改善因子的计算步骤。\n\n**1. 数学公式**\n\n数据同化分析步的核心是构建和求逆矩阵 $S \\in \\mathbb{R}^{m \\times m}$，其定义为：\n$$S = H P^f H^\\top + R$$\n其中 $P^f \\in \\mathbb{R}^{n \\times n}$ 是预报误差协方差，$H \\in \\mathbb{R}^{m \\times n}$ 是观测算子，$R \\in \\mathbb{R}^{m \\times m}$ 是观测误差协方差。对于此问题，这些矩阵按如下方式构造：\n\n- **观测算子 $H$**：该算子是一个选择矩阵 $H = [I_m, 0] \\in \\mathbb{R}^{m \\times n}$，它观测 $n$ 个状态变量中的前 $m$ 个。一个关键的推论是，对于任何矩阵 $M \\in \\mathbb{R}^{n \\times n}$，矩阵乘积 $H M H^\\top$ 等效于选择 $M$ 的左上角 $m \\times m$ 子块。\n- **观测误差协方差 $R$**：此矩阵假定为对角且均匀的，由 $R = \\sigma_R^2 I_m$ 给出，其中 $\\sigma_R^2  0$ 是观测误差方差，$I_m$ 是 $m \\times m$ 的单位矩阵。\n- **预报误差协方差 $P^f$**：$P^f$ 的构造取决于指定的模式。\n    - **模式 \"ensemble\"**：$P^f$ 由一个合成集成生成。从标准正态分布中抽取一个原始的状态集成 $X \\in \\mathbb{R}^{n \\times N_e}$，并使用种子以保证可复现性。通过对 $N_e$ 个成员（列）求平均来计算集成平均状态 $\\bar{x} \\in \\mathbb{R}^n$。然后异常矩阵为 $A' = X - \\bar{x}$。问题描述中关于“中心化列”的说法存在歧义；此处采用创建集成异常的科学标准解释，即从每个集成成员向量中减去平均状态向量（即 `mean(axis=1)`）。公式 $P^f = A A^\\top$ 中使用的矩阵 $A \\in \\mathbb{R}^{n \\times N_e}$ 定义为 $A = \\frac{1}{\\sqrt{N_e - 1}} A'$。这与样本协方差的定义一致。通过一个对角缩放矩阵 $D = \\mathrm{diag}(s)$ 引入各向异性剖面，其中 $s_i = \\exp(g \\cdot (\\frac{i}{n-1} - \\frac{1}{2}))$。最终的异常被转换为 $A \\rightarrow D A$，得到 $P^f = (D A)(D A)^\\top = D A A^\\top D^\\top$。\n    - **模式 \"rank1\"**：$P^f$ 被构造为一个秩为 1 的矩阵加上一个小的正则化项。从标准正态分布中抽取一个向量 $u \\in \\mathbb{R}^n$ 并将其归一化，使其欧几里得范数为 $1$。然后协方差为 $P^f = \\sigma_r^2 u u^\\top + \\epsilon I_n$。这种结构模拟了一个由单一误差模式主导，并带有少量各向同性背景误差的系统。\n\n- **稳定性度量**：数值稳定性由 $S$ 的谱条件数 $\\kappa(S) = \\frac{\\lambda_{\\max}(S)}{\\lambda_{\\min}(S)}$ 来量化，其中 $\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 分别是 $S$ 的最大和最小特征值。由于 $P^f$ 是对称半正定的，$R$ 是对称正定的，所以 $S$ 是对称正定的，这确保了其特征值为实数且为正。\n\n**2. 协方差修正技术**\n\n在用 $P^f$ 形成 $S$ 之前，应用了两种技术来修正 $P^f$。\n\n- **加性膨胀**：将一个缩放后的单位矩阵加到 $P^f$ 上，以增加其方差并确保其是良态的。 $$\\widetilde{P}^f_{\\text{add}} = P^f + \\beta I_n \\quad (\\beta \\ge 0)$$ 这会直接将 $P^f$ 的所有特征值增加 $\\beta$，进而增加 $H P^f H^\\top$ 的特征值。\n\n- **协方差局地化**：通过与相关矩阵 $L(\\ell)$进行逐元素相乘，来抑制由小集成规模引起的伪长程相关。$$\\widetilde{P}^f_{\\text{loc}} = L(\\ell) \\circ P^f$$\n矩阵 $L(\\ell)$ 是在一个均匀一维网格 $x_i = \\frac{i}{n-1}$（其中 $i=0, \\dots, n-1$）上由高斯相关函数构造的。其元素为 $[L(\\ell)]_{ij} = \\exp(-\\frac{d_{ij}^2}{\\ell^2})$，其中 $d_{ij} = |x_i - x_j|$ 是网格点之间的距离，$\\ell  0$ 是局地化长度尺度。对于 $\\ell \\le 0$，$L(\\ell)$ 是全一矩阵，不产生任何修正，即 $L(0) \\circ P^f = P^f$。\n\n- **组合方法**：可以相继应用这两种技术。 $$\\widetilde{P}^f_{\\text{both}} = (L(\\ell) \\circ P^f) + \\beta I_n$$\n\n**3. 算法实现**\n\n对于四个测试用例中的每一个，执行以下步骤：\n1.  定义参数 $n, m, N_e, \\sigma_R^2, \\beta, \\ell$ 以及构造 `mode` 及其特定参数。\n2.  根据指定的 `mode` 和 `seed`，确定性地构造基础预报协方差 $P^f$。\n3.  基于维度 $n$ 的网格构造局地化矩阵 $L(\\ell)$。\n4.  计算四种版本的 $S$ 矩阵：\n    - $S_{\\text{base}} = H P^f H^\\top + R$\n    - $S_{\\text{add}} = H (P^f + \\beta I_n) H^\\top + R$\n    - $S_{\\text{loc}} = H (L(\\ell) \\circ P^f) H^\\top + R$\n    - $S_{\\text{both}} = H ((L(\\ell) \\circ P^f) + \\beta I_n) H^\\top + R$\n    矩阵乘积 $H M H^\\top$ 通过对 $M$ 的左上角 $m \\times m$ 子块进行切片来高效实现。\n5.  使用专门针对对称矩阵的数值例程（例如 `scipy.linalg.eigh`）计算每个对称矩阵 $S$ 的特征值。\n6.  每个 $S$ 矩阵的条件数计算为 $\\lambda_{\\max} / \\lambda_{\\min}$。\n7.  三个条件数改善因子计算为基准条件数与修正后条件数的比率：\n    - $\\rho_{\\text{add}} = \\kappa(S_{\\text{base}}) / \\kappa(S_{\\text{add}})$\n    - $\\rho_{\\text{loc}} = \\kappa(S_{\\text{base}}) / \\kappa(S_{\\text{loc}})$\n    - $\\rho_{\\text{both}} = \\kappa(S_{\\text{base}}) / \\kappa(S_{\\text{both}})$\n8.  收集并格式化得到的十二个浮点数（四个案例各三个因子）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef get_condition_number(matrix):\n    \"\"\"\n    Computes the spectral condition number of a real, symmetric matrix.\n    Uses scipy.linalg.eigh for numerical stability and efficiency.\n    \"\"\"\n    # eigh is designed for symmetric/Hermitian matrices and guarantees real eigenvalues.\n    eigenvalues = eigh(matrix, eigvals_only=True)\n    \n    # In theory, S should be positive definite, so all eigenvalues > 0.\n    # We handle potential numerical noise by considering only positive eigenvalues.\n    min_eig = np.min(eigenvalues)\n    max_eig = np.max(eigenvalues)\n\n    # If min_eig is non-positive due to rank deficiency or numerical error,\n    # the condition number is effectively infinite.\n    if min_eig = 1e-15: # Use a small tolerance\n        return np.inf\n        \n    return max_eig / min_eig\n\ndef compute_factors_for_case(params: dict) -> list[float]:\n    \"\"\"\n    Runs a single test case to compute the conditioning improvement factors.\n    \"\"\"\n    n = params['n']\n    m = params['m']\n    Ne = params['Ne']\n    sigma_R_sq = params['sigma_R_sq']\n    beta = params['beta']\n    l_scale = params['l']\n    seed = params['seed']\n    mode = params['mode']\n    \n    rng = np.random.default_rng(seed)\n\n    # --- 1. Construct Forecast Error Covariance Pf ---\n    if mode == \"ensemble\":\n        g = params['g']\n        \n        # Draw a raw ensemble from a standard normal distribution.\n        ensemble = rng.standard_normal((n, Ne))\n        \n        # Center the ensemble to get anomalies. The standard interpretation is to\n        # subtract the ensemble mean state (mean across members, i.e., axis=1).\n        ensemble_mean = ensemble.mean(axis=1, keepdims=True)\n        anomalies_prime = ensemble - ensemble_mean\n        \n        # Scale to form the matrix A such that Pf = A @ A.T. This requires\n        # dividing by sqrt(Ne-1) to be consistent with sample covariance.\n        if Ne > 1:\n            A = anomalies_prime / np.sqrt(Ne - 1)\n        else:\n            A = np.zeros((n, Ne))\n\n        # Apply anisotropy profile.\n        grid_points = np.linspace(0, 1, n)\n        s = np.exp(g * (grid_points - 0.5))\n        D = np.diag(s)\n        A_aniso = D @ A\n        \n        Pf = A_aniso @ A_aniso.T\n\n    elif mode == \"rank1\":\n        sigma_r = params['sigma_r']\n        epsilon = params['epsilon']\n        \n        u_raw = rng.standard_normal(n)\n        u = u_raw / np.linalg.norm(u_raw)\n        \n        Pf = sigma_r**2 * np.outer(u, u) + epsilon * np.eye(n)\n\n    # --- 2. Construct other components: R, L and H (implicitly) ---\n    # The action of H @ M @ H.T is to select the top-left m x m sub-block.\n    H_select = lambda M: M[:m, :m]\n    \n    R = sigma_R_sq * np.eye(m)\n    \n    if l_scale = 0:\n        L = np.ones((n, n))\n    else:\n        grid_points = np.linspace(0, 1, n)\n        dist_matrix = np.abs(grid_points[:, None] - grid_points)\n        L = np.exp(-(dist_matrix / l_scale)**2)\n\n    # --- 3. Construct modified Pf matrices ---\n    Pf_add = Pf + beta * np.eye(n)\n    Pf_loc = L * Pf  # Schur (element-wise) product\n    Pf_both = Pf_loc + beta * np.eye(n)\n\n    # --- 4. Construct S matrices ---\n    S_base = H_select(Pf) + R\n    S_add = H_select(Pf_add) + R\n    S_loc = H_select(Pf_loc) + R\n    S_both = H_select(Pf_both) + R\n    \n    # --- 5. Compute condition numbers ---\n    kappa_base = get_condition_number(S_base)\n    kappa_add = get_condition_number(S_add)\n    kappa_loc = get_condition_number(S_loc)\n    kappa_both = get_condition_number(S_both)\n    \n    # --- 6. Compute improvement factors ---\n    rho_add = kappa_base / kappa_add if kappa_add > 0 else np.inf\n    rho_loc = kappa_base / kappa_loc if kappa_loc > 0 else np.inf\n    rho_both = kappa_base / kappa_both if kappa_both > 0 else np.inf\n    \n    return [rho_add, rho_loc, rho_both]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the experiment, and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {'n': 40, 'm': 40, 'Ne': 8, 'sigma_R_sq': 1e-4, 'beta': 1e-2, 'l': 0.15, \n         'seed': 42, 'mode': \"ensemble\", 'g': np.log(10**5)},\n        # Test case 2\n        {'n': 60, 'm': 30, 'Ne': 3, 'sigma_R_sq': 1e-6, 'beta': 1e-3, 'l': 0.2, \n         'seed': 123, 'mode': \"ensemble\", 'g': np.log(10**8)},\n        # Test case 3\n        {'n': 40, 'm': 40, 'Ne': 80, 'sigma_R_sq': 1e-1, 'beta': 0, 'l': 0, \n         'seed': 7, 'mode': \"ensemble\", 'g': np.log(10)},\n        # Test case 4\n        {'n': 50, 'm': 50, 'Ne': 10, 'sigma_R_sq': 1e-3, 'beta': 0, 'l': 0.25, \n         'seed': 99, 'mode': \"rank1\", 'sigma_r': 5, 'epsilon': 1e-8}\n    ]\n\n    all_results = []\n    for case in test_cases:\n        rhos = compute_factors_for_case(case)\n        all_results.extend(rhos)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.6f}\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}