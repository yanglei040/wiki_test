{
    "hands_on_practices": [
        {
            "introduction": "在将 Cholesky 分解应用于复杂问题之前，理解其基本计算过程至关重要。这个练习提供了一个基础性的、循序渐进的计算实践。我们将首先根据一个常见的空间相关模型（指数核函数）构建一个协方差矩阵，这是地球物理学和机器学习中的常见任务，然后逐步应用 Cholesky 分解算法求得其下三角因子 $L$。通过掌握这个过程，你将为理解和调试更复杂的应用建立必要的直觉 。",
            "id": "950018",
            "problem": "考虑一条直线上的三个不同点，其位置分别为 $x_1 = 0$、$x_2 = 1$ 和 $x_3 = 3$。任意两点 $x_i$ 和 $x_j$ 之间的协方差由核函数 $k(x_i, x_j) = \\exp(-|x_i - x_j|)$ 给出。为这些点构成 $3 \\times 3$ 协方差矩阵 $A$，并计算其 Cholesky 分解，即求下三角矩阵 $L$ 使得 $A = LL^\\top$。将 $L$ 的所有元素表示为精确的简化形式。",
            "solution": "我们寻求\n$$A=\\bigl[a_{ij}\\bigr]=\\begin{pmatrix}\n1  e^{-1}  e^{-3}\\\\\ne^{-1}  1  e^{-2}\\\\\ne^{-3}  e^{-2}  1\n\\end{pmatrix}$$\n的 Cholesky 因子 $L$，使得 $A=LL^\\top$ 成立，其中\n$$L=\\begin{pmatrix}\n\\ell_{11}  0  0\\\\\n\\ell_{21}  \\ell_{22}  0\\\\\n\\ell_{31}  \\ell_{32}  \\ell_{33}\n\\end{pmatrix}.$$\n1. 由 $a_{11}=\\ell_{11}^2=1$ 可得\n   $$\\ell_{11}=1.$$\n2. 由 $a_{21}=\\ell_{21}\\ell_{11}=e^{-1}$ 和 $a_{31}=\\ell_{31}\\ell_{11}=e^{-3}$ 可得\n   $$\\ell_{21}=e^{-1},\\quad\\ell_{31}=e^{-3}.$$\n3. 由 $a_{22}=\\ell_{21}^2+\\ell_{22}^2=1$ 可得\n   $$\\ell_{22}=\\sqrt{1-e^{-2}}.$$\n4. 由 $a_{32}=\\ell_{31}\\ell_{21}+\\ell_{32}\\ell_{22}=e^{-2}$ 解得\n   $$\\ell_{32}=\\frac{e^{-2}-e^{-3}e^{-1}}{\\sqrt{1-e^{-2}}}\n              =\\frac{e^{-2}-e^{-4}}{\\sqrt{1-e^{-2}}}\n              =e^{-2}\\sqrt{1-e^{-2}}.$$\n5. 最后，由\n   $$a_{33}=\\ell_{31}^2+\\ell_{32}^2+\\ell_{33}^2=1$$\n   可得\n   $$\\ell_{33}\n     =\\sqrt{1-e^{-6}-\\bigl(e^{-2}\\sqrt{1-e^{-2}}\\bigr)^2}\n     =\\sqrt{1-e^{-4}}.$$\n因此，Cholesky 因子为\n$$L=\\begin{pmatrix}\n1  0  0\\\\\ne^{-1}  \\sqrt{1-e^{-2}}  0\\\\\ne^{-3}  e^{-2}\\sqrt{1-e^{-2}}  \\sqrt{1-e^{-4}}\n\\end{pmatrix}.$$",
            "answer": "$$\\boxed{\\begin{pmatrix}\n1  0  0\\\\\ne^{-1}  \\sqrt{1-e^{-2}}  0\\\\\ne^{-3}  e^{-2}\\sqrt{1-e^{-2}}  \\sqrt{1-e^{-4}}\n\\end{pmatrix}}$$"
        },
        {
            "introduction": "Cholesky 分解最强大的应用之一是在统计模拟中，它能有效地从具有特定协方差结构的多维高斯分布中生成随机样本。本练习将引导你从手动计算转向一项实用的编码任务。你将利用一个核心原理：对标准正态向量 $z$ 进行仿射变换 $x = m + Lz$ 可以生成一个服从分布 $x \\sim \\mathcal{N}(m, C)$ 的相关多维正态向量，其中 $C = LL^\\top$。通过这个练习，你将学会如何构建一个采样器来生成能够正确反映给定协方差结构的样本集合，这是蒙特卡洛方法和数据同化中的一项基本技能 。",
            "id": "3373513",
            "problem": "考虑为线性高斯逆问题和序贯数据同化生成系综，其中必须从具有指定均值和协方差的多元正态分布中抽取样本。设 $m \\in \\mathbb{R}^n$ 为给定的均值向量，设 $C \\in \\mathbb{R}^{n \\times n}$ 为对称正定协方差矩阵。一个基本事实是，如果 $F \\in \\mathbb{R}^{n \\times n}$ 满足 $F F^\\top = C$，并且如果 $z \\in \\mathbb{R}^n$ 是一个分量独立同分布的标准正态向量，则形式为 $x = m + F z$ 的仿射变换是从均值为 $m$、协方差为 $C$ 的高斯分布中抽取的一个样本。$F$ 的两种显著选择是 Cholesky 因子（它是一个下三角矩阵 $L$，满足 $C = L L^\\top$）和对称平方根（它满足 $C^{1/2} C^{1/2} = C$ 且 $C^{1/2} = (C^{1/2})^\\top$）。对称平方根可以通过谱定理，利用 $C$ 的特征值分解来构造。\n\n您的任务是实现一个用于多元正态分布的采样器，该采样器通过使用下三角 Cholesky 因子和对称平方根来变换标准正态向量，并通过一阶矩和二阶矩的蒙特卡洛估计来比较它们的经验性能。推导和实现必须从以下基本事实出发：期望的线性性、协方差的定义、对称矩阵的谱定理，以及高斯向量的仿射像仍然是高斯的性质。\n\n对于下文定义的每个测试用例，请执行以下操作：\n- 按规定构造协方差矩阵 $C$。\n- 计算下三角 Cholesky 因子 $L$，使得 $C = L L^\\top$。\n- 使用 $C$ 的特征值分解计算对称平方根 $C^{1/2}$。\n- 在 $\\mathbb{R}^n$ 中生成 $N$ 个独立同分布的标准正态向量 $z$，在给定的测试用例中为两种方法使用相同的固定种子以确保可复现性。对两种方法使用相同的标准正态抽样矩阵，以减少比较中的方差。\n- 构建两组样本：\n  - $x_L = m + L z$，\n  - $x_S = m + C^{1/2} z$，\n  其中 $z$ 被理解为一个 $n \\times N$ 矩阵，并且 $m$ 是按列相加的。\n- 使用已知的真实均值 $m$ 计算经验矩误差，以避免在协方差中使用样本均值所带来的偏差：\n  - 经验均值误差 $e_{m,L} = \\lVert \\hat{m}_L - m \\rVert_2$ 和 $e_{m,S} = \\lVert \\hat{m}_S - m \\rVert_2$，其中 $\\hat{m}_\\bullet$ 表示相应样本矩阵的列式样本均值。\n  - 相对于真实均值 $m$ 的经验协方差矩阵：$\\hat{C}_L = \\frac{1}{N}\\sum_{k=1}^N (x_{L,k} - m)(x_{L,k} - m)^\\top$ 和 $\\hat{C}_S = \\frac{1}{N}\\sum_{k=1}^N (x_{S,k} - m)(x_{S,k} - m)^\\top$。\n  - 经验协方差误差 $e_{C,L} = \\lVert \\hat{C}_L - C \\rVert_F$ 和 $e_{C,S} = \\lVert \\hat{C}_S - C \\rVert_F$。\n- 对于每个测试用例，报告单个浮点数 $r = \\frac{e_{C,L}}{e_{C,S}}$。数量 $r$ 比较了基于 Cholesky 的采样器和基于对称平方根的采样器在二阶矩蒙特卡洛估计上的准确性。接近 $1$ 的 $r$ 值表示性能相似。\n\n测试套件。使用以下四个测试用例。在所有情况下，于处理测试套件开始时，将标准正态抽样的随机数生成器种子设置为 $1729$，并在给定的测试用例中对两种采样方法使用相同的抽样结果。当需要一个随机矩阵 $A$ 来构造 $C$ 时，请使用为该测试用例指定的独立固定种子来构造 $A$，并且在处理主标准正态抽样时不要更改它。\n\n- 测试用例 1（理想情况，非对角，良态）：\n  - 维度 $n = 4$。\n  - 均值 $m = [1, -1, 0.5, 2]^\\top$。\n  - 通过使用种子 $0$ 抽取独立同分布的标准正态项来构造 $A \\in \\mathbb{R}^{4 \\times 4}$（根据您所用语言的默认设置，按列主序或行主序填充），并设置 $C = A A^\\top + \\alpha I$，其中 $\\alpha = 0.5$。\n  - 样本数量 $N = 200000$。\n\n- 测试用例 2（边界情况，标量）：\n  - 维度 $n = 1$。\n  - 均值 $m = [0.0]^\\top$。\n  - 协方差 $C = [2.5]$。\n  - 样本数量 $N = 500000$。\n\n- 测试用例 3（病态对角协方差）：\n  - 维度 $n = 5$。\n  - 均值 $m = [-2.0, 0.1, 0.0, 1.5, 0.0]^\\top$。\n  - 协方差 $C = \\operatorname{diag}(2.0, 10^{-3}, 5 \\cdot 10^{-2}, 3.0, 10^{-6})$。\n  - 样本数量 $N = 250000$。\n\n- 测试用例 4（更高维度，近奇异正则化协方差）：\n  - 维度 $n = 8$。\n  - 均值 $m = [0, 0, 0, 0, 0, 0, 0, 0]^\\top$。\n  - 通过使用种子 $123$ 抽取独立同分布的标准正态项来构造 $A \\in \\mathbb{R}^{8 \\times 8}$，并设置 $C = A A^\\top + \\varepsilon I$，其中 $\\varepsilon = 10^{-6}$。\n  - 样本数量 $N = 200000$。\n\n最终输出格式。您的程序应生成单行输出，其中包含与四个测试用例相对应的四个结果，按顺序排列，格式为方括号括起来的逗号分隔列表，例如 $[r_1,r_2,r_3,r_4]$。每个 $r_j$ 都必须是按上述规定计算的浮点数。不应打印任何其他文本。",
            "solution": "该问题要求实现并比较两种从多元正态分布 $N(m, C)$ 生成样本的方法，其中 $m \\in \\mathbb{R}^n$ 是均值向量，$C \\in \\mathbb{R}^{n \\times n}$ 是对称正定协方差矩阵。比较是基于从有限数量样本中经验估计的二阶矩的准确性。\n\n生成多元正态样本的一个关键原则是高斯分布的仿射变换性质。如果 $z \\in \\mathbb{R}^n$ 是一个随机向量，其分量是独立同分布 (i.i.d.) 的标准正态变量（即 $z \\sim N(0, I)$，其中 $I$ 是单位矩阵），那么对于某个矩阵 $F \\in \\mathbb{R}^{n \\times n}$，变换后的向量 $x = m + Fz$ 也呈正态分布。其均值和协方差由以下公式给出：\n- 均值：$E[x] = E[m + Fz] = m + F E[z] = m + F \\cdot 0 = m$。这源于期望算子的线性性。\n- 协方差：$\\text{Cov}(x) = E[(x - E[x])(x - E[x])^\\top] = E[(m + Fz - m)(m + Fz - m)^\\top] = E[(Fz)(Fz)^\\top] = E[Fzz^\\top F^\\top]$。由于期望算子是线性的，我们可以将其写为 $F E[zz^\\top] F^\\top$。$z$ 的协方差矩阵是 $E[zz^\\top] - E[z]E[z]^\\top = E[zz^\\top] = I$。因此，$\\text{Cov}(x) = F I F^\\top = FF^\\top$。\n\n要从目标分布 $N(m, C)$ 生成样本，我们必须找到一个矩阵 $F$，使得 $FF^\\top = C$。问题指定了 $F$ 的两种选择：\n\n1.  **Cholesky 因子 ($L$)**：对于任何对称正定矩阵 $C$，都存在一个唯一的、对角线元素为正的下三角矩阵 $L$，使得 $C = LL^\\top$。这就是 Cholesky 分解。第一种采样方法使用这个因子，通过 $x_L = m + Lz$ 生成样本。\n\n2.  **对称平方根 ($C^{1/2}$)**：对于任何对称正定矩阵 $C$，都存在一个唯一的对称正定矩阵，记作 $C^{1/2}$，使得 $C = C^{1/2}C^{1/2}$。由于 $C^{1/2}$ 是对称的，所以 $(C^{1/2})^\\top = C^{1/2}$，因此 $C = C^{1/2}(C^{1/2})^\\top$ 也成立。这个矩阵可以通过谱定理来构造。对称矩阵 $C$ 有一个特征分解 $C = VDV^\\top$，其中 $V$ 是一个正交矩阵，其列是 $C$ 的特征向量，$D$ 是由相应特征值 $\\lambda_i$ 组成的对角矩阵。由于 $C$ 是正定的，所有 $\\lambda_i  0$。对称平方根则由 $C^{1/2} = VD^{1/2}V^\\top$ 给出，其中 $D^{1/2}$ 是对角线上元素为 $\\sqrt{\\lambda_i}$ 的对角矩阵。第二种采样方法使用这个因子，通过 $x_S = m + C^{1/2}z$ 生成样本。\n\n对于有限数量的样本 $N$，我们可以估计分布的矩。问题指定了计算相对于真实均值 $m$ 的经验协方差矩阵，这是一个无偏估计量：\n$$\n\\hat{C}_\\bullet = \\frac{1}{N}\\sum_{k=1}^N (x_{\\bullet,k} - m)(x_{\\bullet,k} - m)^\\top\n$$\n其中 $\\bullet$ 是 $L$ (Cholesky) 或 $S$ (Symmetric) 的占位符。这些估计的准确性通过误差矩阵 $E_\\bullet = \\hat{C}_\\bullet - C$ 的弗罗贝尼乌斯范数来衡量：\n$$\ne_{C,\\bullet} = \\lVert \\hat{C}_\\bullet - C \\rVert_F = \\sqrt{\\sum_{i=1}^n \\sum_{j=1}^n (E_{\\bullet, ij})^2}\n$$\n问题的核心是通过计算比率 $r = e_{C,L} / e_{C,S}$ 来计算和比较这些误差。两种方法使用同一组 $N$ 个标准正态向量 $\\{z_k\\}_{k=1}^N$，以确保公平比较。\n\n采样误差与 $F$ 的选择之间的关系可以通过将 $x_k - m = F z_k$ 代入 $\\hat{C}$ 的估计量中看出：\n$$\n\\hat{C} = \\frac{1}{N} \\sum_{k=1}^N (F z_k)(F z_k)^\\top = F \\left( \\frac{1}{N} \\sum_{k=1}^N z_k z_k^\\top \\right) F^\\top = F \\hat{C}_z F^\\top\n$$\n其中 $\\hat{C}_z$ 是标准正态样本的经验协方差。因此，误差为：\n$$\n\\hat{C} - C = F \\hat{C}_z F^\\top - F F^\\top = F (\\hat{C}_z - I) F^\\top\n$$\n因此，问题比较的是 $\\lVert L(\\hat{C}_z - I)L^\\top \\rVert_F$ 和 $\\lVert C^{1/2}(\\hat{C}_z - I)(C^{1/2})^\\top \\rVert_F$。虽然 $L$ 和 $C^{1/2}$ 通常是不同的矩阵，但在特殊情况下它们是相同的。对于标量协方差 $C=[\\sigma^2]$，$L=C^{1/2}=[\\sigma]$。对于对角协方差矩阵 $C=\\operatorname{diag}(\\sigma_1^2, \\dots, \\sigma_n^2)$，$L$ 和 $C^{1/2}$ 都等于 $\\operatorname{diag}(\\sigma_1, \\dots, \\sigma_n)$。在这些情况下，我们预计误差将是相同的，比率 $r$ 将为 $1.0$。对于一般的非对角矩阵 $C$，$L \\neq C^{1/2}$，比率 $r$ 可能会偏离 $1.0$，这反映了 $L$（下三角）和 $C^{1/2}$（稠密对称）的不同结构如何传播有限样本误差 $(\\hat{C}_z - I)$。\n\n实现过程是遍历四个测试用例。对于每个用例：\n1.  设置指定的参数 $n, m, N$，并按定义构造协方差矩阵 $C$。\n2.  使用 `numpy.linalg.cholesky` 计算下三角 Cholesky 因子 $L$。\n3.  使用 `scipy.linalg.sqrtm` 计算对称平方根 $C^{1/2}$。\n4.  使用固定的随机种子生成一个包含 $N$ 个标准正态抽样的矩阵 $Z \\in \\mathbb{R}^{n \\times N}$，以确保可复现性。\n5.  创建两组样本 $X_L = m + LZ$ 和 $X_S = m + C^{1/2}Z$。使用广播将均值向量 $m$ 添加到每一列。\n6.  高效地计算经验协方差矩阵 $\\hat{C}_L$ 和 $\\hat{C}_S$，公式为 $\\frac{1}{N}(X_\\bullet - m)(X_\\bullet - m)^\\top$。\n7.  使用 `numpy.linalg.norm` 计算误差矩阵的弗罗贝尼乌斯范数 $e_{C,L} = \\lVert \\hat{C}_L - C \\rVert_F$ 和 $e_{C,S} = \\lVert \\hat{C}_S - C \\rVert_F$。\n8.  计算并存储比率 $r = e_{C,L} / e_{C,S}$。\n\n最后，将收集到的所有测试用例的比率按指定格式打印出来。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import sqrtm\n\ndef solve():\n    \"\"\"\n    Implements and compares Cholesky and symmetric square root samplers \n    for multivariate normal distributions across four test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Case 1: Well-conditioned\",\n            \"n\": 4,\n            \"m\": np.array([1.0, -1.0, 0.5, 2.0]),\n            \"N\": 200000,\n            \"ctype\": \"random_regularized\",\n            \"cparams\": {\"seed\": 0, \"reg\": 0.5},\n        },\n        {\n            \"name\": \"Case 2: Scalar\",\n            \"n\": 1,\n            \"m\": np.array([0.0]),\n            \"N\": 500000,\n            \"ctype\": \"scalar\",\n            \"cparams\": {\"val\": 2.5},\n        },\n        {\n            \"name\": \"Case 3: Ill-conditioned diagonal\",\n            \"n\": 5,\n            \"m\": np.array([-2.0, 0.1, 0.0, 1.5, 0.0]),\n            \"N\": 250000,\n            \"ctype\": \"diag\",\n            \"cparams\": {\"diag_vals\": np.array([2.0, 1e-3, 5e-2, 3.0, 1e-6])},\n        },\n        {\n            \"name\": \"Case 4: Near-singular regularized\",\n            \"n\": 8,\n            \"m\": np.array([0.0] * 8),\n            \"N\": 200000,\n            \"ctype\": \"random_regularized\",\n            \"cparams\": {\"seed\": 123, \"reg\": 1e-6},\n        },\n    ]\n\n    # Master random number generator for standard normal draws (z).\n    # Seeded once for reproducibility across all test cases.\n    rng_z = np.random.default_rng(1729)\n\n    results = []\n\n    for case in test_cases:\n        n = case[\"n\"]\n        m = case[\"m\"]\n        N = case[\"N\"]\n\n        # Construct covariance matrix C based on test case specs.\n        if case[\"ctype\"] == \"random_regularized\":\n            # Use an independent RNG for constructing C to not affect the main draws.\n            rng_A = np.random.default_rng(case[\"cparams\"][\"seed\"])\n            A = rng_A.standard_normal((n, n))\n            C = A @ A.T + case[\"cparams\"][\"reg\"] * np.eye(n)\n        elif case[\"ctype\"] == \"scalar\":\n            C = np.array([[case[\"cparams\"][\"val\"]]])\n        elif case[\"ctype\"] == \"diag\":\n            C = np.diag(case[\"cparams\"][\"diag_vals\"])\n\n        # Compute the lower-triangular Cholesky factor L.\n        L = np.linalg.cholesky(C)\n\n        # Compute the symmetric square root C^(1/2).\n        # For a symmetric positive definite matrix, sqrtm returns the unique\n        # symmetric positive definite root, which is real.\n        C_sqrt = sqrtm(C)\n        if np.iscomplexobj(C_sqrt):\n            C_sqrt = C_sqrt.real\n\n        # Generate N i.i.d. standard normal vectors z.\n        # This same set of draws is used for both methods.\n        Z = rng_z.standard_normal((n, N))\n\n        # Reshape mean vector for broadcasting (n, 1).\n        m_col = m.reshape(-1, 1)\n\n        # Generate samples using Cholesky factor.\n        X_L = m_col + L @ Z\n        # Generate samples using symmetric square root.\n        X_S = m_col + C_sqrt @ Z\n\n        # Compute empirical covariance matrices relative to the true mean m.\n        # Deviation matrix: X - m (broadcasting m_col to each column of X)\n        Dev_L = X_L - m_col\n        # C_hat = (1/N) * Sum[(x_k-m)(x_k-m)^T] = (1/N) * Dev @ Dev.T\n        C_hat_L = (Dev_L @ Dev_L.T) / N\n\n        Dev_S = X_S - m_col\n        C_hat_S = (Dev_S @ Dev_S.T) / N\n\n        # Compute covariance error using the Frobenius norm.\n        e_C_L = np.linalg.norm(C_hat_L - C, 'fro')\n        e_C_S = np.linalg.norm(C_hat_S - C, 'fro')\n\n        # Compute the ratio of errors.\n        # e_C_S should be non-zero for any finite N with random draws.\n        if e_C_S == 0.0:\n            # This case is highly improbable. If it occurs, the errors are identical.\n            r = 1.0\n        else:\n            r = e_C_L / e_C_S\n        \n        results.append(r)\n\n    # Print the final results in the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Cholesky 分解不仅用于采样，它还是确保高级统计模型数值稳定性的关键工具。这个练习将探讨其在贝叶斯推断中的核心作用，特别是在模型选择和超参数优化方面。我们将推导并实现一种稳定的方法来计算对数边际似然 $\\log p(y | \\theta)$，该表达式涉及一个对数行列式项 $\\log(\\det S)$ 和一个二次型项 $y^\\top S^{-1} y$。如果直接计算，这两项都可能导致数值不稳定，但利用 Cholesky 因子 $L$ (其中 $S=LL^\\top$)，我们可以优雅地解决这个问题。这项实践将教会你如何将复杂的数学公式转化为稳健的数值算法，这对于任何从事计算统计学研究的人员来说都是一项至关重要的技能 。",
            "id": "3373567",
            "problem": "给定一个具有分层协方差模型的线性高斯数据同化设置。设状态向量为 $x \\in \\mathbb{R}^{5}$，其高斯先验为 $x \\sim \\mathcal{N}(m_{0}, B(\\theta))$，线性观测模型为 $y \\in \\mathbb{R}^{4}$，定义为 $y = H x + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, R(\\theta))$ 且独立于 $x$。先验均值为 $m_{0} = 0 \\in \\mathbb{R}^{5}$。协方差矩阵由超参数 $\\theta = (\\sigma, \\ell, \\tau)$ 参数化，如下所示：\n- 先验协方差 $B(\\theta) \\in \\mathbb{R}^{5 \\times 5}$ 是在固定状态位置 $\\{x_{i}\\}_{i=1}^{5}$ 上的平方指数核，其中 $x_{i} \\in \\mathbb{R}$，由下式给出\n$$\nB(\\theta)_{ij} = \\sigma^{2} \\exp\\left(-\\frac{(x_{i} - x_{j})^{2}}{2 \\ell^{2}}\\right), \\quad 1 \\leq i,j \\leq 5.\n$$\n- 观测误差协方差为 $R(\\theta) = \\tau^{2} I_{4} \\in \\mathbb{R}^{4 \\times 4}$。\n\n观测算子 $H \\in \\mathbb{R}^{4 \\times 5}$、状态位置 $\\{x_{i}\\}_{i=1}^{5}$ 以及观测数据 $y \\in \\mathbb{R}^{4}$ 是固定的，并由下式给出\n$$\nH = \\begin{bmatrix}\n1  0  0  0  0 \\\\\n0  \\tfrac{1}{2}  \\tfrac{1}{2}  0  0 \\\\\n0  0  0  1  0 \\\\\n0  0  0  0  1 \\\\\n\\end{bmatrix}, \\quad\n[x_{1}, x_{2}, x_{3}, x_{4}, x_{5}] = [0, 1, 2, 3, 4],\n$$\n$$\ny = \\begin{bmatrix}\n1.0 \\\\\n0.5 \\\\\n-0.25 \\\\\n0.25\n\\end{bmatrix}.\n$$\n\n任务：\n- 仅从多元正态分布的基本性质和线性代数恒等式出发，推导对数边际似然 $\\log p(y \\mid \\theta)$ 的一个数值稳定的表达式，该表达式通过积分消去状态 $x$。您的表达式必须基于评估一个由 $H$、$B(\\theta)$ 和 $R(\\theta)$ 构成的对称正定矩阵，并且必须使用 Cholesky 分解来稳定地计算相关的二次型和对数行列式。\n- 然后，实现一个程序，使用 Cholesky 分解作为求解线性系统和评估对数行列式的核心数值基元，为一组超参数测试用例计算此对数边际似然。不要使用任何直接的矩阵求逆。\n\n测试套件：\n为以下每个超参数设置计算对数边际似然，其中每个参数都严格为正：\n- 情况 1：$(\\sigma, \\ell, \\tau) = (1.2, 1.3, 0.1)$。\n- 情况 2（接近低噪声边界）：$(\\sigma, \\ell, \\tau) = (1.0, 5.0, 10^{-6})$。\n- 情况 3（短相关长度）：$(\\sigma, \\ell, \\tau) = (0.8, 0.2, 0.5)$。\n- 情况 4（高方差，小噪声）：$(\\sigma, \\ell, \\tau) = (5.0, 1.0, 0.01)$。\n\n要求：\n- 您的程序必须将对数边际似然值计算为实数，并按上述 4 种情况的指定顺序返回它们。\n- 为确保一致的比较，请将每个结果四舍五入到 6 位小数。\n- 最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[r_{1},r_{2},r_{3},r_{4}]$）。\n\n注意：\n- 本问题中没有物理单位。\n- 不使用角度。\n- 不使用百分比。",
            "solution": "## 问题验证\n\n### 步骤1：提取给定信息\n问题提供了以下信息：\n- 状态向量：$x \\in \\mathbb{R}^{5}$\n- 状态的先验分布：$x \\sim \\mathcal{N}(m_{0}, B(\\theta))$，先验均值 $m_{0} = 0 \\in \\mathbb{R}^{5}$。\n- 观测向量：$y \\in \\mathbb{R}^{4}$\n- 观测模型：$y = H x + \\varepsilon$，其中观测误差 $\\varepsilon \\sim \\mathcal{N}(0, R(\\theta))$ 独立于 $x$。\n- 超参数：$\\theta = (\\sigma, \\ell, \\tau)$，均为严格正值。\n- 先验协方差矩阵：$B(\\theta) \\in \\mathbb{R}^{5 \\times 5}$ 由平方指数核定义：$B(\\theta)_{ij} = \\sigma^{2} \\exp\\left(-\\frac{(x_{i} - x_{j})^{2}}{2 \\ell^{2}}\\right)$，其中 $1 \\leq i,j \\leq 5$。\n- 观测误差协方差矩阵：$R(\\theta) = \\tau^{2} I_{4} \\in \\mathbb{R}^{4 \\times 4}$，其中 $I_{4}$ 是 $4 \\times 4$ 的单位矩阵。\n- 固定的状态位置：$[x_{1}, x_{2}, x_{3}, x_{4}, x_{5}] = [0, 1, 2, 3, 4]$。\n- 固定的观测算子：$H = \\begin{bmatrix} 1  0  0  0  0 \\\\ 0  \\tfrac{1}{2}  \\tfrac{1}{2}  0  0 \\\\ 0  0  0  1  0 \\\\ 0  0  0  0  1 \\\\ \\end{bmatrix}$。\n- 固定的观测数据：$y = \\begin{bmatrix} 1.0 \\\\ 0.5 \\\\ -0.25 \\\\ 0.25 \\end{bmatrix}$。\n- 任务：使用 Cholesky 分解推导对数边际似然 $\\log p(y \\mid \\theta)$ 的数值稳定表达式，并实现一个程序来为四个指定的测试用例计算它。\n- $(\\sigma, \\ell, \\tau)$ 的测试用例：\n    1. $(1.2, 1.3, 0.1)$\n    2. $(1.0, 5.0, 10^{-6})$\n    3. $(0.8, 0.2, 0.5)$\n    4. $(5.0, 1.0, 0.01)$\n\n### 步骤2：使用提取的给定信息进行验证\n根据验证标准评估问题：\n- **科学性**：该问题是贝叶斯推断在线性高斯设置中的一个标准应用，这是数据同化、反问题和机器学习（特别是高斯过程）中的一个基本主题。使用平方指数核作为先验协方差和线性观测模型是常见且成熟的做法。\n- **良构性**：定义模型和计算所需量的所有组件都已提供。超参数 $(\\sigma, \\ell, \\tau)$ 均为严格正值，确保了协方差矩阵 $B(\\theta)$ 和 $R(\\theta)$ 是对称正定（SPD）的。因此，和 $S(\\theta) = H B(\\theta) H^T + R(\\theta)$ 也是对称正定的，这保证了其 Cholesky 分解、行列式和逆矩阵都是良定义的。这确保了每个测试用例都存在唯一、稳定且有意义的对数边际似然解。\n- **客观性**：问题使用精确的数学语言和定义陈述。所有量都经过正式定义，没有主观解释的余地。\n\n问题没有表现出任何列出的缺陷：\n1. 它是科学合理的。\n2. 它是一个可形式化的问题，与指定主题直接相关。\n3. 它是完整和一致的。\n4. 所要求的计算在数值上是可行的，模型是物理系统的标准简化表示。\n5. 它是良构的。\n6. 推导和实现需要对概率论和数值线性代数原理的非平凡应用。\n7. 结果是可进行数值验证的。\n\n### 步骤3：结论和行动\n问题是有效的。将提供完整的解决方案。\n\n## 推导和求解\n\n目标是计算对数边际似然 $\\log p(y \\mid \\theta)$，这涉及到从联合分布 $p(y, x \\mid \\theta)$ 中积分掉状态向量 $x$。\n$$\np(y \\mid \\theta) = \\int p(y, x \\mid \\theta) \\, dx = \\int p(y \\mid x, \\theta) \\, p(x \\mid \\theta) \\, dx\n$$\n该问题由一个线性高斯模型定义：\n1.  先验：$p(x \\mid \\theta) = \\mathcal{N}(x \\mid m_0, B(\\theta))$。\n2.  似然：$p(y \\mid x, \\theta) = \\mathcal{N}(y \\mid Hx, R(\\theta))$。\n\n鉴于两个分布都是高斯的，并且 $x$ 和 $y$ 之间的关系是线性的， $y$ 的边际分布也是高斯的，$p(y \\mid \\theta) = \\mathcal{N}(y \\mid \\mu_y, S(\\theta))$。我们需要找到它的均值 $\\mu_y$ 和协方差 $S(\\theta)$。\n\n根据全期望定律， $y$ 的均值为：\n$$\n\\mu_y = \\mathbb{E}[y \\mid \\theta] = \\mathbb{E}[\\mathbb{E}[y \\mid x, \\theta] \\mid \\theta] = \\mathbb{E}[Hx \\mid \\theta] = H \\mathbb{E}[x \\mid \\theta] = H m_0\n$$\n由于给定的先验均值为 $m_0 = 0$，边际分布的均值为 $\\mu_y = 0$。\n\n根据全协方差定律， $y$ 的协方差为：\n$$\nS(\\theta) = \\text{Cov}(y \\mid \\theta) = \\mathbb{E}[\\text{Cov}(y \\mid x, \\theta) \\mid \\theta] + \\text{Cov}(\\mathbb{E}[y \\mid x, \\theta] \\mid \\theta)\n$$\n$$\nS(\\theta) = \\mathbb{E}[R(\\theta) \\mid \\theta] + \\text{Cov}(Hx \\mid \\theta) = R(\\theta) + H \\, \\text{Cov}(x \\mid \\theta) \\, H^T\n$$\n用先验协方差 $B(\\theta)$ 替代 $\\text{Cov}(x \\mid \\theta)$，我们得到边际或证据协方差：\n$$\nS(\\theta) = H B(\\theta) H^T + R(\\theta)\n$$\n因此，观测 $y$ 的边际分布为 $\\mathcal{N}(y \\mid 0, S(\\theta))$。\n\n对于一个 $k$ 维多元正态分布 $\\mathcal{N}(z \\mid \\mu, \\Sigma)$，其概率密度函数为：\n$$\np(z \\mid \\mu, \\Sigma) = (2\\pi)^{-k/2} (\\det \\Sigma)^{-1/2} \\exp\\left(-\\frac{1}{2}(z - \\mu)^T \\Sigma^{-1} (z - \\mu)\\right)\n$$\n该密度的对数即为对数似然：\n$$\n\\log p(z \\mid \\mu, \\Sigma) = -\\frac{k}{2} \\log(2\\pi) - \\frac{1}{2} \\log(\\det \\Sigma) - \\frac{1}{2}(z - \\mu)^T \\Sigma^{-1} (z - \\mu)\n$$\n对于我们的问题，向量是 $y$，其维度是 $k=4$，均值是 $\\mu_y=0$，协方差是 $S(\\theta)$。因此，对数边际似然是：\n$$\n\\log p(y \\mid \\theta) = -\\frac{4}{2} \\log(2\\pi) - \\frac{1}{2} \\log(\\det S(\\theta)) - \\frac{1}{2} y^T S(\\theta)^{-1} y\n$$\n$$\n\\log p(y \\mid \\theta) = -2 \\log(2\\pi) - \\frac{1}{2} \\left[ \\log(\\det S(\\theta)) + y^T S(\\theta)^{-1} y \\right]\n$$\n为了按要求稳定地计算这个表达式，我们使用对称正定矩阵 $S(\\theta)$ 的 Cholesky 分解。设 $S(\\theta) = L L^T$，其中 $L$ 是一个下三角矩阵。\n\n1.  **对数行列式项**：$\\log(\\det S(\\theta))$\n    $S(\\theta)$ 的行列式是 $\\det(L L^T) = (\\det L)^2$。由于 $L$ 是三角矩阵，其行列式是其对角元素的乘积，即 $\\det L = \\prod_i L_{ii}$。\n    $$\n    \\log(\\det S(\\theta)) = \\log\\left(\\left(\\prod_i L_{ii}\\right)^2\\right) = 2 \\log\\left(\\prod_i L_{ii}\\right) = 2 \\sum_i \\log(L_{ii})\n    $$\n    这避免了在取对数前直接计算行列式可能产生的大数值。\n\n2.  **二次型项**：$y^T S(\\theta)^{-1} y$\n    我们必须避免直接计算逆矩阵 $S(\\theta)^{-1}$。可以使用 Cholesky 因子重写二次型：\n    $$\n    y^T S(\\theta)^{-1} y = y^T (L L^T)^{-1} y = y^T (L^T)^{-1} L^{-1} y = (L^{-1} y)^T (L^{-1} y)\n    $$\n    令 $w = L^{-1} y$。向量 $w$ 可以通过使用前向替换法求解三角系统 $Lw = y$ 来找到，这种方法数值稳定且高效。然后二次型就变成了 $w$ 的 L2 范数的平方：\n    $$\n    y^T S(\\theta)^{-1} y = w^T w = \\|w\\|_2^2\n    $$\n最终的算法如下：\n1.  对于给定的 $\\theta = (\\sigma, \\ell, \\tau)$，构造矩阵 $B(\\theta)$ 和 $R(\\theta)$。\n2.  计算边际协方差矩阵 $S(\\theta) = H B(\\theta) H^T + R(\\theta)$。\n3.  计算 Cholesky 分解 $S(\\theta) = L L^T$。\n4.  计算对数行列式项为 $2 \\sum_i \\log(L_{ii})$。\n5.  通过前向替换法求解线性系统 $Lw = y$ 得到 $w$。\n6.  计算二次型项为 $w^T w$。\n7.  组合这些分量得到对数边际似然：$\\log p(y \\mid \\theta) = -2 \\log(2\\pi) - \\frac{1}{2} (\\text{对数行列式项} + \\text{二次型项})$。\n\n此过程将为每个提供的测试用例实现。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_triangular\n\ndef calculate_log_marginal_likelihood(theta, H, x_locs, y):\n    \"\"\"\n    Computes the log marginal likelihood for a linear Gaussian model.\n\n    The model is:\n    x ~ N(0, B(theta))\n    y = Hx + e, e ~ N(0, R(theta))\n\n    The log marginal likelihood is:\n    log p(y|theta) = -k/2*log(2*pi) - 1/2*(log|S| + y^T*S^-1*y)\n    where S = H*B*H^T + R and k is the dimension of y.\n\n    Args:\n        theta (tuple): A tuple of hyperparameters (sigma, l, tau).\n        H (np.ndarray): The observation operator matrix.\n        x_locs (np.ndarray): The fixed locations of the state variables.\n        y (np.ndarray): The observation vector.\n\n    Returns:\n        float: The computed log marginal likelihood.\n    \"\"\"\n    sigma, l_corr, tau = theta\n    n_state = len(x_locs)\n    n_obs = len(y)\n\n    # 1. Construct the prior covariance matrix B(theta)\n    # B_ij = sigma^2 * exp(-(x_i - x_j)^2 / (2 * l^2))\n    dist_sq_matrix = np.subtract.outer(x_locs, x_locs)**2\n    B = sigma**2 * np.exp(-dist_sq_matrix / (2 * l_corr**2))\n\n    # 2. Construct the observation error covariance matrix R(theta)\n    # R = tau^2 * I\n    R = tau**2 * np.identity(n_obs)\n\n    # 3. Compute the marginal covariance S(theta) = H*B*H^T + R\n    S = H @ B @ H.T + R\n\n    # 4. Compute the Cholesky factorization S = L*L^T.\n    # np.linalg.cholesky returns the lower triangular matrix L.\n    try:\n        L = np.linalg.cholesky(S)\n    except np.linalg.LinAlgError:\n        # This occurs if S is not positive-definite. Given the problem setup\n        # (sigma, l, tau  0), this should not happen.\n        return np.nan\n\n    # 5. Compute the log-determinant of S using the Cholesky factor.\n    # log|S| = 2 * sum(log(diag(L)))\n    log_det_S = 2 * np.sum(np.log(np.diag(L)))\n\n    # 6. Compute the quadratic form y^T * S^-1 * y.\n    # First solve Lw = y for w using forward substitution.\n    w = solve_triangular(L, y, lower=True, check_finite=False)\n    # The quadratic form is then w^T * w.\n    quad_form = w.T @ w\n\n    # 7. Assemble the log marginal likelihood.\n    # k is the dimension of y (n_obs).\n    log_ml = -0.5 * n_obs * np.log(2 * np.pi) - 0.5 * (log_det_S + quad_form)\n\n    return log_ml\n\ndef solve():\n    \"\"\"\n    Sets up the problem and computes the log marginal likelihood for all test cases.\n    \"\"\"\n    # Define the fixed model parameters from the problem statement.\n    H = np.array([\n        [1.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.5, 0.5, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 1.0, 0.0],\n        [0.0, 0.0, 0.0, 0.0, 1.0]\n    ])\n    x_locs = np.array([0.0, 1.0, 2.0, 3.0, 4.0])\n    y = np.array([1.0, 0.5, -0.25, 0.25])\n\n    # Define the test cases for the hyperparameters (sigma, l, tau).\n    test_cases = [\n        (1.2, 1.3, 0.1),\n        (1.0, 5.0, 1e-6),\n        (0.8, 0.2, 0.5),\n        (5.0, 1.0, 0.01)\n    ]\n\n    results = []\n    for theta in test_cases:\n        log_ml = calculate_log_marginal_likelihood(theta, H, x_locs, y)\n        # Round the result to 6 decimal places as required.\n        results.append(round(log_ml, 6))\n\n    # Print the results in the specified format: [r1,r2,r3,r4]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}