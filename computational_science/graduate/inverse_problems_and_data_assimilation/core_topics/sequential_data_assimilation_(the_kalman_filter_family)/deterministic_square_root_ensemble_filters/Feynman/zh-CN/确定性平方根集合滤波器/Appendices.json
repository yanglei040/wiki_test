{
    "hands_on_practices": [
        {
            "introduction": "掌握确定性平方根集合滤波器的第一步是理解其核心更新机制。本练习将指导你从基本原理出发，推导并实现两种关键的确定性平方根更新方案：一种是基于变换矩阵右乘集合异常（如集合变换卡尔曼滤波器 ETKF），另一种是基于状态空间中的左乘算子。通过在标准化的测试套件上实现和验证这两种方法 ，你将对这些滤波器背后的代数结构和数值行为建立坚实的理解。",
            "id": "3376040",
            "problem": "考虑一个线性高斯数据同化问题，其状态向量为 $\\mathbf{x} \\in \\mathbb{R}^{d}$，观测向量为 $\\mathbf{y} \\in \\mathbb{R}^{m}$，线性观测算子为 $\\mathbf{H} \\in \\mathbb{R}^{m \\times d}$，以及加性高斯观测噪声 $\\mathbf{v} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R})$，其中 $\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$ 是对称正定矩阵。先验信息由一个包含 $N$ 个状态实现的集合 $\\{\\mathbf{x}^{b}_{i}\\}_{i=1}^{N}$ 表示，其样本均值为 $\\bar{\\mathbf{x}}^{b}$，样本协方差为 $\\mathbf{B}$。您必须从标准线性高斯贝叶斯更新（等价于 Kalman 滤波器更新）这一基本出发点开始，该更新指出分析（后验）均值 $\\bar{\\mathbf{x}}^{a}$ 和协方差 $\\mathbf{B}^{a}$ 由以下经过充分检验的公式给出：\n$$\n\\bar{\\mathbf{x}}^{a} = \\bar{\\mathbf{x}}^{b} + \\mathbf{K}\\,(\\mathbf{y} - \\mathbf{H}\\,\\bar{\\mathbf{x}}^{b}), \\quad \\mathbf{K} = \\mathbf{B}\\,\\mathbf{H}^{\\top}\\,(\\mathbf{H}\\,\\mathbf{B}\\,\\mathbf{H}^{\\top} + \\mathbf{R})^{-1},\n$$\n和\n$$\n\\mathbf{B}^{a} = (\\mathbf{I} - \\mathbf{K}\\,\\mathbf{H})\\,\\mathbf{B}\\,(\\mathbf{I} - \\mathbf{K}\\,\\mathbf{H})^{\\top} + \\mathbf{K}\\,\\mathbf{R}\\,\\mathbf{K}^{\\top}.\n$$\n您需要从这些基础和集合表示及样本协方差的核心定义出发，为扰动矩阵推导两种确定性平方根集合分析更新方法。当这些方法与上述均值更新相结合时，能产生一个分析集合，其样本协方差等于目标 $\\mathbf{B}^{a}$。设先验扰动矩阵为 $\\mathbf{A} = [\\mathbf{x}^{b}_{1} - \\bar{\\mathbf{x}}^{b}, \\dots, \\mathbf{x}^{b}_{N} - \\bar{\\mathbf{x}}^{b}] \\in \\mathbb{R}^{d \\times N}$，因此 $\\mathbf{B} = \\frac{1}{N-1}\\,\\mathbf{A}\\,\\mathbf{A}^{\\top}$。\n\n您的任务是：\n\n- 推导一个右乘确定性平方根更新（在文献中通常称为集合变换 Kalman 滤波器 (ETKF)，但您必须在此重新推导），该更新找到一个对称正定变换 $\\mathbf{T}_{r} \\in \\mathbb{R}^{N \\times N}$，使得分析扰动 $\\mathbf{A}^{a} = \\mathbf{A}\\,\\mathbf{T}_{r}$ 满足 $\\frac{1}{N-1}\\,\\mathbf{A}^{a}\\,\\mathbf{A}^{{a}\\top} = \\mathbf{B}^{a}$。\n- 推导一个左乘对称平方根更新，该更新从 $\\mathbf{B}$ 和 $\\mathbf{B}^{a}$ 的对称平方根构造一个线性算子 $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$（在秩亏情况下酌情使用 Moore–Penrose 伪逆），使得 $\\mathbf{A}^{a} = \\mathbf{L}\\,\\mathbf{A}$ 也满足 $\\frac{1}{N-1}\\,\\mathbf{A}^{a}\\,\\mathbf{A}^{{a}\\top} = \\mathbf{B}^{a}$。\n\n利用这两个推导，实现一个单一程序，该程序：\n- 使用上述 Kalman 滤波器方程计算分析均值，其中 $\\mathbf{B}$ 取自给定先验集合的样本协方差。\n- 通过您推导的两种确定性平方根更新方法计算两组分析扰动。\n- 通过将它们的扰动加到分析均值上，形成两个分析集合。\n- 对每种方法，验证样本分析协方差是否等于 $\\mathbf{B}^{a}$，以及分析集合均值是否等于 Kalman 分析均值。\n\n您的程序必须在以下确定性测试套件上实现并评估这些方法。对于每种情况，您必须在为该情况生成任何随机量之前将随机种子设置为指定的整数。对于每种情况：\n- 按如下方式生成 $\\mathbf{B}_{\\text{true}}$：抽取一个元素为独立标准正态分布的矩阵 $\\mathbf{G} \\in \\mathbb{R}^{d \\times d}$，并设置 $\\mathbf{B}_{\\text{true}} = \\frac{1}{d}\\mathbf{G}\\,\\mathbf{G}^{\\top} + 0.5\\,\\mathbf{I}_{d}$。\n- 通过抽取一个元素为独立标准正态分布的向量 $\\mathbb{R}^{d}$ 来生成先验均值 $\\bar{\\mathbf{x}}^{b}$。\n- 通过首先计算 $\\mathbf{B}_{\\text{true}}$ 的 Cholesky 因子 $\\mathbf{L}_{\\text{true}}$（下三角），抽取一个元素为独立标准正态分布的矩阵 $\\mathbf{Z} \\in \\mathbb{R}^{d \\times N}$，并设置 $\\mathbf{X}^{b} = \\bar{\\mathbf{x}}^{b}\\,\\mathbf{1}^{\\top} + \\mathbf{L}_{\\text{true}}\\,\\mathbf{Z}$ 来生成一个集合，其中 $\\mathbf{1} \\in \\mathbb{R}^{N}$ 表示全为 1 的向量。\n- 抽取一个元素为独立标准正态分布的矩阵 $\\mathbf{H} \\in \\mathbb{R}^{m \\times d}$。\n- 通过首先抽取一个元素为独立标准正态分布的向量 $\\mathbf{r} \\in \\mathbb{R}^{m}$ 并设置 $\\mathbf{R} = \\mathrm{diag}(0.1 + |\\mathbf{r}|)$ 来抽取一个对角矩阵 $\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$。\n- 抽取一个“真实”状态 $\\mathbf{x}^{\\dagger} \\in \\mathbb{R}^{d}$，其元素为独立标准正态分布。抽取一个噪声 $\\boldsymbol{\\epsilon} \\in \\mathbb{R}^{m}$，其独立元素的方差等于 $\\mathbf{R}$ 的对角线元素，并设置 $\\mathbf{y} = \\mathbf{H}\\,\\mathbf{x}^{\\dagger} + \\boldsymbol{\\epsilon}$。\n\n测试套件包括以下情况 $(d, N, m, \\text{seed})$：\n- 情况 A: $(5, 20, 4, 42)$。\n- 情况 B: $(10, 6, 7, 7)$。\n- 情况 C: $(8, 8, 8, 202)$。\n- 情况 D: $(12, 30, 3, 99)$。\n\n对于每种情况和每种方法（右乘和左乘），计算两个相对误差：\n- 相对均值误差 $e_{\\text{mean}} = \\frac{\\lVert \\bar{\\mathbf{x}}^{a}_{\\text{ens}} - \\bar{\\mathbf{x}}^{a} \\rVert_{2}}{\\max(1, \\lVert \\bar{\\mathbf{x}}^{a} \\rVert_{2})}$，其中 $\\bar{\\mathbf{x}}^{a}_{\\text{ens}}$ 是分析集合的样本均值。\n- 相对协方差误差 $e_{\\text{cov}} = \\frac{\\lVert \\mathbf{B}^{a}_{\\text{ens}} - \\mathbf{B}^{a} \\rVert_{F}}{\\max(1, \\lVert \\mathbf{B}^{a} \\rVert_{F})}$，其中 $\\mathbf{B}^{a}_{\\text{ens}}$ 是分析集合的样本协方差。\n\n对于每种情况下的每种方法，报告一个等于 $\\max(e_{\\text{mean}}, e_{\\text{cov}})$ 的单一浮点数误差。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[result\\_1,result\\_2,\\dots]$），顺序如下：\n$$\n[\\text{err}_{\\text{right},A}, \\text{err}_{\\text{left},A}, \\text{err}_{\\text{right},B}, \\text{err}_{\\text{left},B}, \\text{err}_{\\text{right},C}, \\text{err}_{\\text{left},C}, \\text{err}_{\\text{right},D}, \\text{err}_{\\text{left},D}].\n$$\n所有量都是无量纲的；不涉及物理单位或角度。最终输出必须是浮点数。该问题要求通过使用所述基础从第一性原理出发推导确定性平方根变换，并在可能秩亏的先验协方差情况下，在需要时使用适当的伪逆进行鲁棒实现。在您的解决方案中，任何快捷公式都不能未经推导就被假定。选择的集合大小和维度旨在包括理想情况、秩亏先验协方差、方形观测算子和欠定观测场景。",
            "solution": "用户提供的问题被评估为**有效**。这是一个在数据同化和集合 Kalman 滤波领域内适定、有科学依据且客观的任务。问题陈述提供了一套完整且一致的定义、基本方程和目标，允许进行严谨的推导和实现。\n\n解决方案分三部分进行：首先，基于提供的 Kalman 滤波器方程建立一个通用框架。其次，推导右乘平方根变换。第三，推导左乘平方根变换。\n\n### 1. 预备知识与分析方程\n\n设先验集合由矩阵 $\\mathbf{X}^{b} = [\\mathbf{x}^{b}_{1}, \\dots, \\mathbf{x}^{b}_{N}] \\in \\mathbb{R}^{d \\times N}$ 表示。样本均值和扰动矩阵为：\n$$\n\\bar{\\mathbf{x}}^{b} = \\frac{1}{N} \\mathbf{X}^{b} \\mathbf{1}\n$$\n$$\n\\mathbf{A} = \\mathbf{X}^{b} - \\bar{\\mathbf{x}}^{b} \\mathbf{1}^{\\top}\n$$\n其中 $\\mathbf{1} \\in \\mathbb{R}^{N}$ 是一个全为 1 的向量。根据构造，$\\mathbf{A}$ 的列和为零，即 $\\mathbf{A}\\mathbf{1} = \\mathbf{0}$。先验样本协方差为 $\\mathbf{B} = \\frac{1}{N-1}\\mathbf{A}\\mathbf{A}^{\\top}$。\n\n分析（后验）均值 $\\bar{\\mathbf{x}}^{a}$ 和协方差 $\\mathbf{B}^{a}$ 由标准的 Kalman 更新方程给出：\n$$\n\\bar{\\mathbf{x}}^{a} = \\bar{\\mathbf{x}}^{b} + \\mathbf{K}\\,(\\mathbf{y} - \\mathbf{H}\\,\\bar{\\mathbf{x}}^{b})\n$$\n其中 Kalman 增益 $\\mathbf{K}$ 为：\n$$\n\\mathbf{K} = \\mathbf{B}\\,\\mathbf{H}^{\\top}\\,(\\mathbf{H}\\,\\mathbf{B}\\,\\mathbf{H}^{\\top} + \\mathbf{R})^{-1}\n$$\n问题指定使用 Joseph 形式计算分析协方差，该形式具有鲁棒性且构造上是对称的：\n$$\n\\mathbf{B}^{a} = (\\mathbf{I} - \\mathbf{K}\\,\\mathbf{H})\\,\\mathbf{B}\\,(\\mathbf{I} - \\mathbf{K}\\,\\mathbf{H})^{\\top} + \\mathbf{K}\\,\\mathbf{R}\\,\\mathbf{K}^{\\top}\n$$\n当 $\\mathbf{K}$ 是最优 Kalman 增益时，此形式在数学上等价于更简单的形式 $\\mathbf{B}^{a} = (\\mathbf{I} - \\mathbf{K}\\mathbf{H})\\mathbf{B}$。我们将按照要求使用 Joseph 形式进行数值计算，并在方便时使用更简单的形式进行代数推导。\n\n分析集合 $\\{\\mathbf{x}^{a}_{i}\\}_{i=1}^{N}$ 由分析均值 $\\bar{\\mathbf{x}}^{a}$ 和一个新的分析扰动矩阵 $\\mathbf{A}^{a}$ 构造成 $\\mathbf{X}^{a} = \\bar{\\mathbf{x}}^{a}\\mathbf{1}^{\\top} + \\mathbf{A}^{a}$。为使该集合保持一致，它必须满足两个条件：\n1.  **正确的均值**：样本均值必须是 $\\bar{\\mathbf{x}}^{a}$。这意味着 $\\mathbf{A}^{a}\\mathbf{1} = \\mathbf{0}$。\n2.  **正确的协方差**：样本协方差必须是 $\\mathbf{B}^{a}$。这意味着 $\\frac{1}{N-1}\\mathbf{A}^{a}(\\mathbf{A}^{a})^{\\top} = \\mathbf{B}^{a}$。\n\n### 2. 右乘更新的推导\n\n我们寻求一个对称正定变换 $\\mathbf{T}_{r} \\in \\mathbb{R}^{N \\times N}$，使得分析扰动 $\\mathbf{A}^{a} = \\mathbf{A}\\,\\mathbf{T}_{r}$ 满足协方差条件。\n将 $\\mathbf{A}^{a} = \\mathbf{A}\\,\\mathbf{T}_{r}$ 代入协方差条件可得：\n$$\n\\frac{1}{N-1} (\\mathbf{A}\\mathbf{T}_{r})(\\mathbf{A}\\mathbf{T}_{r})^{\\top} = \\mathbf{B}^{a} \\implies \\frac{1}{N-1} \\mathbf{A}\\mathbf{T}_{r}\\mathbf{T}_{r}^{\\top}\\mathbf{A}^{\\top} = \\mathbf{B}^{a}\n$$\n由于 $\\mathbf{T}_{r}$ 是对称的，$\\mathbf{T}_{r}\\mathbf{T}_{r}^{\\top} = \\mathbf{T}_{r}^2$。因此，我们需要找到 $\\mathbf{T}_{r}$ 使得 $\\frac{1}{N-1} \\mathbf{A}\\mathbf{T}_{r}^2\\mathbf{A}^{\\top} = \\mathbf{B}^{a}$。\n\n为了求解 $\\mathbf{T}_{r}$，我们将 $\\mathbf{B}^{a}$ 表达成一个便于比较的形式。使用等价形式 $\\mathbf{B}^{a} = (\\mathbf{I} - \\mathbf{K}\\mathbf{H})\\mathbf{B}$ 并代入 $\\mathbf{B}$ 和 $\\mathbf{K}$ 的集合表达式：\n$$\n\\mathbf{B}^{a} = \\mathbf{B} - \\mathbf{B}\\mathbf{H}^{\\top}(\\mathbf{H}\\mathbf{B}\\mathbf{H}^{\\top}+\\mathbf{R})^{-1}\\mathbf{H}\\mathbf{B}\n$$\n设 $\\mathbf{Y} = \\mathbf{H}\\mathbf{A}$ 为投影扰动矩阵。那么 $\\mathbf{H}\\mathbf{B}\\mathbf{H}^{\\top} = \\frac{1}{N-1}\\mathbf{Y}\\mathbf{Y}^{\\top}$。\n$$\n\\mathbf{B}^{a} = \\frac{1}{N-1}\\mathbf{A}\\mathbf{A}^{\\top} - \\frac{1}{N-1}\\mathbf{A}\\mathbf{Y}^{\\top}\\left(\\frac{1}{N-1}\\mathbf{Y}\\mathbf{Y}^{\\top}+\\mathbf{R}\\right)^{-1}\\frac{1}{N-1}\\mathbf{Y}\\mathbf{A}^{\\top}\n$$\n对逆项使用 Woodbury 矩阵恒等式，可以将其表示为更小的 $N \\times N$ 空间中的逆：\n$\\left(\\frac{1}{N-1}\\mathbf{Y}\\mathbf{Y}^{\\top}+\\mathbf{R}\\right)^{-1} = \\mathbf{R}^{-1} - \\mathbf{R}^{-1}\\mathbf{Y}\\left((N-1)\\mathbf{I} + \\mathbf{Y}^{\\top}\\mathbf{R}^{-1}\\mathbf{Y}\\right)^{-1}\\mathbf{Y}^{\\top}\\mathbf{R}^{-1}$。\n将其代回会很繁琐。一个更直接的推导表明：\n$$\n\\mathbf{B}^{a} = \\frac{1}{N-1} \\mathbf{A} \\left( \\mathbf{I} + \\frac{1}{N-1}\\mathbf{Y}^{\\top}\\mathbf{R}^{-1}\\mathbf{Y} \\right)^{-1} \\mathbf{A}^{\\top}\n$$\n将此与我们的目标表达式 $\\mathbf{B}^{a} = \\frac{1}{N-1} \\mathbf{A}\\mathbf{T}_{r}^2\\mathbf{A}^{\\top}$ 进行比较，我们可以确定：\n$$\n\\mathbf{T}_{r}^2 = \\left( \\mathbf{I} + \\frac{1}{N-1}\\mathbf{Y}^{\\top}\\mathbf{R}^{-1}\\mathbf{Y} \\right)^{-1}\n$$\n由于 $\\mathbf{Y}^{\\top}\\mathbf{R}^{-1}\\mathbf{Y}$ 是半正定的，括号内的矩阵是对称正定的。因此，我们可以取其唯一的对称正定平方根：\n$$\n\\mathbf{T}_{r} = \\left( \\mathbf{I} + \\frac{1}{N-1}\\mathbf{Y}^{\\top}\\mathbf{R}^{-1}\\mathbf{Y} \\right)^{-1/2}\n$$\n矩阵平方根 $(\\cdot)^{-1/2}$ 通过特征分解计算：如果 $\\mathbf{M} = \\mathbf{U}\\mathbf{D}\\mathbf{U}^{\\top}$，则 $\\mathbf{M}^{-1/2} = \\mathbf{U}\\mathbf{D}^{-1/2}\\mathbf{U}^{\\top}$。\n\n最后，我们检验均值条件。由于 $\\mathbf{A}\\mathbf{1} = \\mathbf{0}$，我们有 $\\mathbf{Y}\\mathbf{1} = \\mathbf{H}\\mathbf{A}\\mathbf{1} = \\mathbf{0}$。设 $\\mathbf{M} = \\mathbf{I} + \\frac{1}{N-1}\\mathbf{Y}^{\\top}\\mathbf{R}^{-1}\\mathbf{Y}$。那么 $\\mathbf{M}\\mathbf{1} = \\mathbf{1} + \\frac{1}{N-1}\\mathbf{Y}^{\\top}\\mathbf{R}^{-1}(\\mathbf{Y}\\mathbf{1}) = \\mathbf{1}$。这表明 $\\mathbf{1}$ 是 $\\mathbf{M}$ 的一个特征向量，其特征值为 $1$。因此，$\\mathbf{1}$ 也是 $\\mathbf{T}_{r} = \\mathbf{M}^{-1/2}$ 的一个特征向量，其特征值为 $1$。所以，$\\mathbf{A}^{a}\\mathbf{1} = \\mathbf{A}\\mathbf{T}_{r}\\mathbf{1} = \\mathbf{A}\\mathbf{1} = \\mathbf{0}$，满足均值条件。\n\n### 3. 左乘更新的推导\n\n我们寻求一个线性算子 $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$，使得 $\\mathbf{A}^{a} = \\mathbf{L}\\mathbf{A}$ 满足协方差条件：\n$$\n\\frac{1}{N-1} (\\mathbf{L}\\mathbf{A})(\\mathbf{L}\\mathbf{A})^{\\top} = \\mathbf{B}^{a} \\implies \\mathbf{L}\\left(\\frac{1}{N-1}\\mathbf{A}\\mathbf{A}^{\\top}\\right)\\mathbf{L}^{\\top} = \\mathbf{B}^{a} \\implies \\mathbf{L}\\mathbf{B}\\mathbf{L}^{\\top} = \\mathbf{B}^{a}\n$$\n问题建议从 $\\mathbf{B}$ 和 $\\mathbf{B}^{a}$ 的对称平方根构造 $\\mathbf{L}$。设 $\\mathbf{B} = \\mathbf{S}_{b}\\mathbf{S}_{b}$ 和 $\\mathbf{B}^{a} = \\mathbf{S}_{a}\\mathbf{S}_{a}$，其中 $\\mathbf{S}_{b}$ 和 $\\mathbf{S}_{a}$ 分别是 $\\mathbf{B}$ 和 $\\mathbf{B}^{a}$ 的唯一对称半正定平方根。$\\mathbf{L}$ 的一个自然候选形式是：\n$$\n\\mathbf{L} = \\mathbf{S}_{a} \\mathbf{S}_{b}^{+}\n$$\n其中 $\\mathbf{S}_{b}^{+}$ 是 $\\mathbf{S}_{b}$ 的 Moore-Penrose 伪逆。将此代入期望的关系式中：\n$$\n\\mathbf{L}\\mathbf{B}\\mathbf{L}^{\\top} = (\\mathbf{S}_{a}\\mathbf{S}_{b}^{+}) \\mathbf{B} (\\mathbf{S}_{a}\\mathbf{S}_{b}^{+})^{\\top} = \\mathbf{S}_{a}\\mathbf{S}_{b}^{+} \\mathbf{S}_{b}^{2} (\\mathbf{S}_{b}^{+})^{\\top} \\mathbf{S}_{a}^{\\top}\n$$\n由于 $\\mathbf{S}_{b}$ 和 $\\mathbf{S}_{b}^{+}$ 是对称的，这简化为 $\\mathbf{S}_{a}(\\mathbf{S}_{b}^{+}\\mathbf{S}_{b}\\mathbf{S}_{b}\\mathbf{S}_{b}^{+})\\mathbf{S}_{a}$。设 $\\mathbf{P} = \\mathbf{S}_{b}\\mathbf{S}_{b}^{+}$。$\\mathbf{P}$ 是到 $\\mathbf{S}_{b}$ 值域（与 $\\mathbf{B}$ 的值域相同）的正交投影算子。表达式变为 $\\mathbf{S}_{a}\\mathbf{P}\\mathbf{S}_{a}$。\n\n从协方差更新公式 $\\mathbf{B}^{a} = (\\mathbf{I}-\\mathbf{K}\\mathbf{H})\\mathbf{B}$ 可以清楚地看到，$\\mathbf{B}^{a}$ 值域中的任何向量都是 $\\mathbf{B}$ 值域中向量的线性变换。因此，$\\text{range}(\\mathbf{B}^{a}) \\subseteq \\text{range}(\\mathbf{B})$。这意味着 $\\mathbf{S}_{a}$ 的列向量位于 $\\mathbf{S}_{b}$ 的值域内。因此，投影算子 $\\mathbf{P}$ 对 $\\mathbf{S}_{a}$ 的列向量的作用相当于单位算子，即 $\\mathbf{P}\\mathbf{S}_{a} = \\mathbf{S}_{a}$。\n表达式因此简化为 $\\mathbf{S}_{a}\\mathbf{S}_{a} = \\mathbf{B}^{a}$，这证实了我们对 $\\mathbf{L}$ 的选择是正确的。\n\n均值条件自然满足：$\\mathbf{A}^{a}\\mathbf{1} = \\mathbf{L}\\mathbf{A}\\mathbf{1} = \\mathbf{L}\\mathbf{0} = \\mathbf{0}$。\n\n平方根 $\\mathbf{S}_b, \\mathbf{S}_a$ 通过特征分解计算（例如，由 $\\mathbf{B}=\\mathbf{U}_b\\mathbf{D}_b\\mathbf{U}_b^\\top$ 得到 $\\mathbf{S}_b = \\mathbf{U}_b \\mathbf{D}_b^{1/2} \\mathbf{U}_b^\\top$）。伪逆 $\\mathbf{S}_{b}^{+}$ 使用 `numpy.linalg.pinv` 计算。",
            "answer": "```python\nimport numpy as np\n\ndef _sqrtm_psd(X):\n    \"\"\"\n    Computes the unique symmetric positive semi-definite square root of a matrix X.\n    This is achieved via eigendecomposition.\n    \"\"\"\n    eigvals, eigvecs = np.linalg.eigh(X)\n    # Clamp small negative eigenvalues that can appear from numerical noise\n    eigvals[eigvals < 0] = 0\n    return eigvecs @ np.diag(np.sqrt(eigvals)) @ eigvecs.T\n\ndef solve():\n    \"\"\"\n    Derives and implements two deterministic square-root ensemble analysis updates,\n    and evaluates their accuracy on a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (d, N, m, seed)\n        (5, 20, 4, 42),   # Case A: d < N-1\n        (10, 6, 7, 7),    # Case B: d > N-1 (rank-deficient B)\n        (8, 8, 8, 202),   # Case C: d = N (rank-deficient B)\n        (12, 30, 3, 99),  # Case D: d < N-1\n    ]\n\n    results = []\n\n    for d, N, m, seed in test_cases:\n        np.random.seed(seed)\n\n        # 1. Generate test data according to problem specification\n        # Generate a \"true\" positive definite covariance matrix\n        G = np.random.standard_normal((d, d))\n        B_true = (G @ G.T) / d + 0.5 * np.eye(d)\n\n        # Generate a prior ensemble with a specified \"true\" mean and covariance\n        # The x_b_dist_mean is the mean of the generating distribution, not the ensemble sample mean.\n        x_b_dist_mean = np.random.standard_normal(d)\n        L_true = np.linalg.cholesky(B_true)\n        Z = np.random.standard_normal((d, N))\n        X_b = x_b_dist_mean[:, np.newaxis] + L_true @ Z\n        \n        # Generate observation model components\n        H = np.random.standard_normal((m, d))\n        r_diag = np.random.standard_normal(m)\n        R = np.diag(0.1 + np.abs(r_diag))\n\n        # Generate a \"true\" state and a corresponding observation\n        x_true = np.random.standard_normal(d)\n        epsilon = np.random.multivariate_normal(np.zeros(m), R)\n        y = H @ x_true + epsilon\n\n        # 2. Compute prior statistics from the generated ensemble\n        # The Kalman filter operates on the sample statistics of the given ensemble.\n        xb_bar = np.mean(X_b, axis=1)\n        A = X_b - xb_bar[:, np.newaxis]\n        B = (A @ A.T) / (N - 1)\n\n        # 3. Compute the theoretical Kalman analysis mean and covariance\n        HBH_T = H @ B @ H.T\n        S = HBH_T + R\n        K = B @ H.T @ np.linalg.inv(S)\n        \n        # This is the target analysis mean\n        xa_bar = xb_bar + K @ (y - H @ xb_bar)\n        \n        # This is the target analysis covariance (Joseph form, as specified)\n        Id = np.eye(d)\n        Ba = (Id - K @ H) @ B @ (Id - K @ H).T + K @ R @ K.T\n\n        # 4. Apply and verify the two deterministic square-root update methods\n\n        # --- Method 1: Right-Multiplying Transform (ETKF-style) ---\n        Y = H @ A\n        R_inv = np.linalg.inv(R)\n        M = np.eye(N) + (Y.T @ R_inv @ Y) / (N - 1)\n        \n        eigvals_M, U_M = np.linalg.eigh(M)\n        eigvals_M[eigvals_M < 0] = 0 # Ensure non-negativity\n        D_inv_sqrt_M = np.diag(1.0 / np.sqrt(eigvals_M))\n        Tr = U_M @ D_inv_sqrt_M @ U_M.T\n        \n        Aa_right = A @ Tr\n        Xa_right = xa_bar[:, np.newaxis] + Aa_right\n\n        # Verification for right-multiplying method\n        xa_bar_ens_right = np.mean(Xa_right, axis=1)\n        Aa_ens_right = Xa_right - xa_bar_ens_right[:, np.newaxis]\n        Ba_ens_right = (Aa_ens_right @ Aa_ens_right.T) / (N - 1)\n        \n        norm_xa_bar = np.linalg.norm(xa_bar)\n        e_mean_right = np.linalg.norm(xa_bar_ens_right - xa_bar) / max(1.0, norm_xa_bar)\n        \n        norm_Ba = np.linalg.norm(Ba, 'fro')\n        e_cov_right = np.linalg.norm(Ba_ens_right - Ba, 'fro') / max(1.0, norm_Ba)\n        \n        err_right = max(e_mean_right, e_cov_right)\n        results.append(err_right)\n\n        # --- Method 2: Left-Multiplying Transform ---\n        Sb_sqrt = _sqrtm_psd(B)\n        Sb_pinv = np.linalg.pinv(Sb_sqrt)\n        Sa_sqrt = _sqrtm_psd(Ba)\n        \n        L = Sa_sqrt @ Sb_pinv\n        Aa_left = L @ A\n        Xa_left = xa_bar[:, np.newaxis] + Aa_left\n\n        # Verification for left-multiplying method\n        xa_bar_ens_left = np.mean(Xa_left, axis=1)\n        Aa_ens_left = Xa_left - xa_bar_ens_left[:, np.newaxis]\n        Ba_ens_left = (Aa_ens_left @ Aa_ens_left.T) / (N - 1)\n        \n        e_mean_left = np.linalg.norm(xa_bar_ens_left - xa_bar) / max(1.0, norm_xa_bar)\n        e_cov_left = np.linalg.norm(Ba_ens_left - Ba, 'fro') / max(1.0, norm_Ba)\n        \n        err_left = max(e_mean_left, e_cov_left)\n        results.append(err_left)\n\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理论知识必须通过实践来检验，尤其是在处理混沌系统时，滤波器的稳定性至关重要。本练习要求你通过蒙特卡洛模拟，在一个具有正李雅普诺夫指数的线性动力学模型中，比较确定性平方根滤波器和随机扰动观测值集合卡尔曼滤波器的性能。你将亲自量化和分析两种滤波器发生“集合坍缩”的概率 ，从而深刻体会确定性更新在维持集合方差和避免滤波器退化方面的优势与挑战。",
            "id": "3375995",
            "problem": "给定一个用于数据同化的线性、时不变、离散时间状态空间模型，该模型使用基于集合的滤波器。状态演化由一个方阵 $M \\in \\mathbb{R}^{d \\times d}$ 指定，观测算子为 $H \\in \\mathbb{R}^{p \\times d}$。观测由 $y_k = H x_k + v_k$ 生成，其中 $v_k \\sim \\mathcal{N}(0, R)$ 是零均值高斯噪声，$R \\in \\mathbb{R}^{p \\times p}$ 是对称正定矩阵。集合大小为 $N_e$，集合异常的定义方式为：对集合进行中心化处理，然后除以 $\\sqrt{N_e - 1}$，使得样本协方差等于异常矩阵的乘积。前向动力学矩阵 $M$ 的选择使得至少有一个 Lyapunov 指数为正，从而系统至少在一个方向上是不稳定的。对于一个常数线性算子 $M$，将其 Lyapunov 指数定义为 $\\lambda_i = \\log \\sigma_i(M)$，其中 $\\sigma_i(M)$ 是 $M$ 的奇异值。分析步由确定性平方根集合滤波器或随机扰动观测集合滤波器执行。定义集合坍缩事件为：在任何分析步 $k$，当前分析异常矩阵的最小奇异值低于一个预设容差 $\\tau$ 乘以从初始异常中获取的参考尺度的值。\n\n您的任务是，通过使用固定伪随机种子的蒙特卡洛模拟，计算对于两种滤波器，集合在固定的分析循环次数 $L$ 内发生坍缩的估计概率：\n(i) 确定性平方根集合变换 Kalman 滤波器（也称为 Ensemble Transform Kalman Filter），它通过一个保留样本分析协方差的确定性右乘变换来更新异常，以及\n(ii) 带有扰动观测的随机 Ensemble Kalman Filter，它使用扰动后的新息来更新每个成员，并在期望意义上匹配分析协方差。\n\n请将您的推导建立在以下基本事实上：\n(i) 线性高斯状态空间模型以及在分析步中均值和协方差的 Kalman 滤波器更新，\n(ii) 通过经 $\\sqrt{N_e - 1}$ 缩放的中心化异常来表示协方差，以及\n(iii) 通过奇异值定义线性算子的 Lyapunov 指数。除了 $R$ 的对称性和正定性之外，不要假设任何特殊结构，也不要引入任何不符合物理的假设。使用弧度作为角度单位。\n\n使用以下精确且自洽的测试套件，该套件旨在测试不同情况，包括一个不稳定方向、中度不稳定性和近中性情况。在所有测试中，将初始真实状态置于原点，即 $x_0 = 0$；从 $\\mathcal{N}(0, \\sigma_0^2 I_d)$（其中 $\\sigma_0 = 1$）中独立抽取初始集合成员；并使用零模式噪声。在所有情况下，如果任何循环中分析异常矩阵的最小奇异值 $s_{\\min}$ 满足 $s_{\\min} < \\tau s_{\\mathrm{ref}}$，则定义为发生坍缩，其中 $s_{\\mathrm{ref}}$ 是该蒙特卡洛实现中初始异常矩阵的平均奇异值。将坍缩概率的蒙特卡洛估计定义为在 $L$ 个循环内发生坍缩的实现所占的比例。\n\n测试用例 1 (具有一个不稳定方向和一个稳定方向的理想情况):\n- 状态维度 $d = 2$，集合大小 $N_e = 10$，循环次数 $L = 20$。\n- 动力学矩阵 $M = Q \\, \\mathrm{diag}(1.5, 0.9) \\, Q^\\top$，其中 $Q$ 是一个角度为 $\\theta = 0.5$ 弧度的旋转矩阵，即 $Q = \\begin{bmatrix} \\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{bmatrix}$。\n- 观测算子 $H = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$，观测噪声协方差 $R = \\sigma_y^2 I_p$，其中 $\\sigma_y = 0.1$，所以 $p = 1$。\n- 容差 $\\tau = 10^{-6}$，蒙特卡洛实现次数 $S = 400$。\n\n测试用例 2 (三维空间中具有两个观测分量的中度不稳定性):\n- 状态维度 $d = 3$，集合大小 $N_e = 12$，循环次数 $L = 20$。\n- 动力学矩阵 $M = Q \\, \\mathrm{diag}(1.8, 1.2, 0.8) \\, Q^\\top$，其中 $Q = R_z(\\alpha) R_y(\\beta) R_x(\\gamma)$，$\\alpha = 0.4$, $\\beta = 0.3$, $\\gamma = 0.2$，且\n$R_x(\\gamma) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\cos \\gamma & -\\sin \\gamma \\\\ 0 & \\sin \\gamma & \\cos \\gamma \\end{bmatrix}$,\n$R_y(\\beta) = \\begin{bmatrix} \\cos \\beta & 0 & \\sin \\beta \\\\ 0 & 1 & 0 \\\\ -\\sin \\beta & 0 & \\cos \\beta \\end{bmatrix}$,\n$R_z(\\alpha) = \\begin{bmatrix} \\cos \\alpha & -\\sin \\alpha & 0 \\\\ \\sin \\alpha & \\cos \\alpha & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$。\n- 观测算子 $H = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}$，观测噪声协方差 $R = \\sigma_y^2 I_p$，其中 $\\sigma_y = 0.05$，所以 $p = 2$。\n- 容差 $\\tau = 10^{-6}$，蒙特卡洛实现次数 $S = 400$。\n\n测试用例 3 (具有完全观测和较大噪声的近中性动力学):\n- 状态维度 $d = 2$，集合大小 $N_e = 8$，循环次数 $L = 15$。\n- 动力学矩阵 $M = Q \\, \\mathrm{diag}(1.0, 0.99) \\, Q^\\top$，其中 $Q$ 是一个角度为 $\\theta = 0.3$ 弧度的旋转矩阵，与测试 1 中类似。\n- 观测算子 $H = I_2$，观测噪声协方差 $R = \\sigma_y^2 I_p$，其中 $\\sigma_y = 0.5$，所以 $p = 2$。\n- 容差 $\\tau = 10^{-6}$，蒙特卡洛实现次数 $S = 400$。\n\n对于每个测试用例，计算两个数值：确定性平方根滤波器的估计坍缩概率和带扰动观测的随机滤波器的估计坍缩概率。为确保可复现性，所有用例均使用相同的固定伪随机种子。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 $[\\text{test1\\_det}, \\text{test1\\_stoch}, \\text{test2\\_det}, \\text{test2\\_stoch}, \\text{test3\\_det}, \\text{test3\\_stoch}]$，其中每个条目都是一个十进制浮点数。不允许有其他输出。",
            "solution": "经评估，用户提供的问题是有效的。这是一个在数据同化领域内适定、有科学依据的数值任务。它自成体系，提供了所有必要的参数、模型和定义。该问题没有矛盾、歧义或伪科学主张。下面将展示一个完整的解决方案。\n\n该问题要求通过蒙特卡洛模拟，计算两种不同类型的集合 Kalman 滤波器（EnKF）的集合坍缩概率。所考虑的系统是一个线性、时不变、离散时间的状态空间模型。\n\n### 1. 数学框架\n\n**状态空间模型**:\n系统在离散时间步 $k$ 的状态 $x_k \\in \\mathbb{R}^d$ 根据线性预报模型演化：\n$$x_k = M x_{k-1}$$\n其中 $M \\in \\mathbb{R}^{d \\times d}$ 是动力学矩阵。假设模型没有过程噪声。\n观测 $y_k \\in \\mathbb{R}^p$ 通过线性观测算子 $H \\in \\mathbb{R}^{p \\times d}$ 与真实状态相关联：\n$$y_k = H x_k + v_k$$\n其中 $v_k$ 是从零均值高斯分布 $v_k \\sim \\mathcal{N}(0, R)$ 中抽取的随机观测噪声向量，其协方差矩阵 $R \\in \\mathbb{R}^{p \\times p}$ 是对称正定的。\n\n**集合表示**:\n基于集合的滤波器使用一组有限的 $N_e$ 个样本（称为集合成员）$\\{x_i\\}_{i=1}^{N_e}$ 来近似状态分布。这些成员的集合构成了集合矩阵 $X \\in \\mathbb{R}^{d \\times N_e}$。状态估计由集合均值给出：\n$$\\bar{x} = \\frac{1}{N_e} \\sum_{i=1}^{N_e} x_i$$\n估计的不确定性由样本协方差矩阵 $P$ 表示：\n$$P = \\frac{1}{N_e-1} \\sum_{i=1}^{N_e} (x_i - \\bar{x})(x_i - \\bar{x})^\\top$$\n该问题定义了一个缩放后的异常矩阵 $A \\in \\mathbb{R}^{d \\times N_e}$，其列为 $a_i = (x_i - \\bar{x})/\\sqrt{N_e-1}$。根据此定义，样本协方差可以紧凑地写为：\n$$P = A A^\\top$$\n\n### 2. 蒙特卡洛模拟\n\n集合坍缩的概率通过运行 $S$ 次独立的模拟（实现）来估计。对于每次实现，我们执行以下步骤：\n\n**初始化**:\n1.  将初始真实状态设置为原点：$x_0 = 0$。\n2.  通过从 $\\mathcal{N}(0, \\sigma_0^2 I_d)$（其中 $\\sigma_0=1$）中独立抽取 $N_e$ 个成员来生成初始集合 $X_0$。\n3.  计算初始集合均值 $\\bar{x}_0$ 和异常矩阵 $A_0$。\n4.  计算参考尺度 $s_{\\mathrm{ref}}$，其值为初始异常矩阵 $A_0$ 的奇异值的平均值。坍缩阈值则为 $\\tau s_{\\mathrm{ref}}$。\n5.  使用相同的初始集合为确定性滤波器和随机滤波器初始化各自的状态。\n\n**时间演化（$L$ 个循环）**:\n在每个循环 $k=1, \\dots, L$ 中：\n1.  **预报**：使用动力学矩阵 $M$ 将真实状态和两个集合向前推进。对于任何集合 $X_{k-1}^a$，预报集合为 $X_k^f = M X_{k-1}^a$。这种线性关系意味着预报均值为 $\\bar{x}_k^f = M \\bar{x}_{k-1}^a$，预报异常矩阵为 $A_k^f = M A_{k-1}^a$。\n2.  **观测**：使用传播后的真实状态 $x_k$ 和一个随机噪声样本 $v_k \\sim \\mathcal{N}(0, R)$ 生成一个合成观测 $y_k$。\n3.  **分析**：使用观测值 $y_k$ 更新每个滤波器的状态（确定性滤波器的均值和异常；随机滤波器的集合成员）。具体的更新算法详述如下。\n4.  **坍缩检查**：对于每个滤波器，计算其新的分析异常矩阵 $A_k^a$ 的奇异值。如果最小奇异值 $s_{\\min}$ 低于阈值 $\\tau s_{\\mathrm{ref}}$，则认为该滤波器的集合已坍缩。该滤波器路径的模拟可以停止。\n\n**聚合**:\n运行 $S$ 次实现后，每个滤波器的坍缩概率被估计为发生坍缩的实现所占的比例。\n$$P_{\\text{collapse}} = \\frac{\\text{Number of collapsed realizations}}{S}$$\n\n### 3. 滤波器算法\n\n两种滤波器使用相同的预报步，它们的不同之处在于分析步。\n\n**A. 确定性平方根滤波器 (ETKF)**\n\nETKF 以确定性的方式更新集合均值和异常。\n1.  **分析均值**：分析均值 $\\bar{x}_k^a$ 使用标准的 Kalman 增益 $K_k$ 进行更新：\n    $$\\bar{x}_k^a = \\bar{x}_k^f + K_k (y_k - H \\bar{x}_k^f)$$\n    其中 $K_k = P_k^f H^\\top (H P_k^f H^\\top + R)^{-1}$。使用异常表示 $P_k^f = A_k^f (A_k^f)^\\top$，上式变为：\n    $$K_k = A_k^f (H A_k^f)^\\top (H A_k^f (H A_k^f)^\\top + R)^{-1}$$\n\n2.  **分析异常**：通过将预报异常 $A_k^f$ 右乘一个变换矩阵 $T$ 来获得分析异常 $A_k^a$：\n    $$A_k^a = A_k^f T$$\n    选择矩阵 $T \\in \\mathbb{R}^{N_e \\times N_e}$ 以确保分析协方差 $P_k^a = A_k^a(A_k^a)^\\top$ 与理论上的 Kalman 分析协方差 $P_k^a = ((P_k^f)^{-1} + H^\\top R^{-1}H)^{-1}$ 相匹配。这导致了以下条件：\n    $$T T^\\top = \\left( I + (H A_k^f)^\\top R^{-1} (H A_k^f) \\right)^{-1}$$\n    $T$ 的一个唯一的、对称正定的解是等式右侧的矩阵平方根。我们将 $T$ 计算为 $T = \\text{sqrtm}\\left( \\left( I + (H A_k^f)^\\top R^{-1} (H A_k^f) \\right)^{-1} \\right)$，其中 $\\text{sqrtm}$ 表示主矩阵平方根。\n\n**B. 带扰动观测的随机 EnKF**\n\n这种滤波器独立更新每个集合成员。\n1.  **Kalman 增益**：使用完整的预报集合统计量一次性计算 Kalman 增益 $K_k$，该增益与 ETKF 的增益相同。\n2.  **成员更新**：对于每个集合成员 $i=1, \\dots, N_e$：\n    a. 为观测生成一个唯一的扰动：$v_{k,i} \\sim \\mathcal{N}(0, R)$。\n    b. 创建一个扰动后的观测：$y_{k,i} = y_k + v_{k,i}$。\n    c. 更新成员：\n    $$x_{k,i}^a = x_{k,i}^f + K_k (y_{k,i} - H x_{k,i}^f)$$\n更新后的成员集合 $\\{x_{k,i}^a\\}_{i=1}^{N_e}$ 构成了新的分析集合 $X_k^a$。然后从 $X_k^a$ 计算坍缩检查所需的分析异常矩阵 $A_k^a$。在更新步骤中引入随机噪声是其与确定性滤波器的关键区别，并影响集合的统计特性和稳定性。",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the simulations for all test cases and print the results.\n    \"\"\"\n    # Use a fixed seed for reproducibility as required by the problem.\n    SEED = 42\n\n    test_cases = [\n        {\n            \"d\": 2, \"Ne\": 10, \"L\": 20, \"S\": 400, \"tau\": 1e-6,\n            \"M_params\": {\"type\": \"rotation_2d\", \"theta\": 0.5, \"diag\": np.array([1.5, 0.9])},\n            \"H\": np.array([[1.0, 0.0]]),\n            \"sigma_y\": 0.1,\n        },\n        {\n            \"d\": 3, \"Ne\": 12, \"L\": 20, \"S\": 400, \"tau\": 1e-6,\n            \"M_params\": {\"type\": \"rotation_3d\", \"angles\": (0.4, 0.3, 0.2), \"diag\": np.array([1.8, 1.2, 0.8])},\n            \"H\": np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]),\n            \"sigma_y\": 0.05,\n        },\n        {\n            \"d\": 2, \"Ne\": 8, \"L\": 15, \"S\": 400, \"tau\": 1e-6,\n            \"M_params\": {\"type\": \"rotation_2d\", \"theta\": 0.3, \"diag\": np.array([1.0, 0.99])},\n            \"H\": np.eye(2),\n            \"sigma_y\": 0.5,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        p_det, p_stoch = run_simulation_for_case(case, SEED)\n        results.extend([p_det, p_stoch])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _create_M_matrix(params):\n    \"\"\"Helper function to create the dynamics matrix M.\"\"\"\n    if params[\"type\"] == \"rotation_2d\":\n        theta = params[\"theta\"]\n        c, s = np.cos(theta), np.sin(theta)\n        Q = np.array([[c, -s], [s, c]])\n        D = np.diag(params[\"diag\"])\n        return Q @ D @ Q.T\n    elif params[\"type\"] == \"rotation_3d\":\n        alpha, beta, gamma = params[\"angles\"]\n        ca, sa = np.cos(alpha), np.sin(alpha)\n        cb, sb = np.cos(beta), np.sin(beta)\n        cg, sg = np.cos(gamma), np.sin(gamma)\n        Rx = np.array([[1, 0, 0], [0, cg, -sg], [0, sg, cg]])\n        Ry = np.array([[cb, 0, sb], [0, 1, 0], [-sb, 0, cb]])\n        Rz = np.array([[ca, -sa, 0], [sa, ca, 0], [0, 0, 1]])\n        Q = Rz @ Ry @ Rx\n        D = np.diag(params[\"diag\"])\n        return Q @ D @ Q.T\n    else:\n        raise ValueError(\"Unknown M_params type\")\n\ndef run_simulation_for_case(case_params, seed):\n    \"\"\"\n    Runs the Monte Carlo simulation for a single test case.\n    \"\"\"\n    d, Ne, L, S, tau = case_params[\"d\"], case_params[\"Ne\"], case_params[\"L\"], case_params[\"S\"], case_params[\"tau\"]\n    M = _create_M_matrix(case_params[\"M_params\"])\n    H = case_params[\"H\"]\n    p = H.shape[0]\n    sigma_y = case_params[\"sigma_y\"]\n    R = (sigma_y**2) * np.eye(p)\n    R_inv = np.linalg.inv(R)\n\n    rng = np.random.default_rng(seed)\n    \n    sigma_0 = 1.0\n\n    collapse_count_det = 0\n    collapse_count_stoch = 0\n\n    for _ in range(S):\n        # --- Initialization for one realization ---\n        x_true_k = np.zeros(d)\n        \n        X0 = rng.normal(loc=0.0, scale=sigma_0, size=(d, Ne))\n\n        x_mean0 = np.mean(X0, axis=1, keepdims=True)\n        A0 = (X0 - x_mean0) / np.sqrt(Ne - 1)\n        \n        s_ref = np.mean(np.linalg.svd(A0, compute_uv=False))\n        collapse_threshold = tau * s_ref\n        \n        # --- Initialize states for both filters ---\n        # Deterministic ETKF state\n        x_mean_det_k = x_mean0.flatten()\n        A_det_k = A0\n        \n        # Stochastic EnKF state\n        X_stoch_k = X0\n\n        has_collapsed_det = False\n        has_collapsed_stoch = False\n\n        for _ in range(L):\n            if has_collapsed_det and has_collapsed_stoch:\n                break\n            \n            # --- Forecast Step ---\n            x_true_k = M @ x_true_k\n            \n            # ETKF Forecast\n            x_mean_f_det = M @ x_mean_det_k\n            A_f_det = M @ A_det_k\n            \n            # Stochastic EnKF Forecast\n            X_f_stoch = M @ X_stoch_k\n\n            # --- Observation Step ---\n            v = rng.multivariate_normal(np.zeros(p), R)\n            y_obs = H @ x_true_k + v\n\n            # --- Analysis Step ---\n            # ETKF Analysis\n            if not has_collapsed_det:\n                HAf_det = H @ A_f_det\n                PfHt_det = A_f_det @ HAf_det.T\n                S_k_inv_det = np.linalg.inv(HAf_det @ HAf_det.T + R)\n                K_det = PfHt_det @ S_k_inv_det\n                \n                x_mean_a_det = x_mean_f_det + K_det @ (y_obs - H @ x_mean_f_det)\n                \n                # Transform matrix T for anomalies\n                T_inv_sq_arg = np.eye(Ne) + HAf_det.T @ R_inv @ HAf_det\n                T_inv = linalg.sqrtm(T_inv_sq_arg)\n                T = np.linalg.inv(T_inv)\n                A_a_det = A_f_det @ T.real\n                \n                # Check for collapse\n                if np.min(np.linalg.svd(A_a_det, compute_uv=False)) < collapse_threshold:\n                    has_collapsed_det = True\n                    collapse_count_det += 1\n                \n                x_mean_det_k = x_mean_a_det\n                A_det_k = A_a_det\n\n            # Stochastic EnKF Analysis\n            if not has_collapsed_stoch:\n                A_f_stoch = (X_f_stoch - np.mean(X_f_stoch, axis=1, keepdims=True)) / np.sqrt(Ne - 1)\n                Pf_stoch = A_f_stoch @ A_f_stoch.T\n                S_k_inv_stoch = np.linalg.inv(H @ Pf_stoch @ H.T + R)\n                K_stoch = Pf_stoch @ H.T @ S_k_inv_stoch\n                \n                obs_perturbations = rng.multivariate_normal(np.zeros(p), R, size=Ne)\n                \n                X_a_stoch = np.zeros_like(X_f_stoch)\n                for i in range(Ne):\n                    y_p = y_obs + obs_perturbations[i]\n                    X_a_stoch[:, i] = X_f_stoch[:, i] + K_stoch @ (y_p - H @ X_f_stoch[:, i])\n                \n                X_stoch_k = X_a_stoch\n                \n                # Check for collapse\n                A_a_stoch = (X_stoch_k - np.mean(X_stoch_k, axis=1, keepdims=True)) / np.sqrt(Ne - 1)\n                if np.min(np.linalg.svd(A_a_stoch, compute_uv=False)) < collapse_threshold:\n                    has_collapsed_stoch = True\n                    collapse_count_stoch += 1\n\n    prob_det = collapse_count_det / S\n    prob_stoch = collapse_count_stoch / S\n    \n    return prob_det, prob_stoch\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "一个高效的滤波器不仅需要正确更新状态，还需要能够诊断其内部的潜在问题，例如集合异常子空间与观测信息的不匹配。本高级练习将引导你探索一个新颖的诊断工具：计算集合异常子空间与后验费雪信息子空间之间的主角度 。通过这个几何视角，你将学会如何量化观测对集合不确定性的约束能力，并在此基础上推导一种修正的变换矩阵，以惩罚与观测信息错位的集合方向。",
            "id": "3376043",
            "problem": "考虑一个线性高斯逆问题，其状态向量在 $\\mathbb{R}^{n}$ 中，由线性观测算子 $H \\in \\mathbb{R}^{p \\times n}$ 观测，观测误差协方差为 $R \\in \\mathbb{R}^{p \\times p}$。设一个确定性平方根集合卡尔曼滤波器（deterministic square-root Ensemble Kalman Filter, EnKF）通过一个由 $m$ 个集合成员组成的异常矩阵 $X^{f} \\in \\mathbb{R}^{n \\times m}$ 来表示预报误差协方差，其中预报协方差为 $P^{f} = \\frac{1}{m-1} X^{f} X^{f \\top}$。后验Fisher信息由半正定矩阵 $F = H^{\\top} R^{-1} H$ 定义，其信息子空间是 $F$ 的列空间。\n\n给定以下具体实例，$n = 3$，$p = 2$，$m = 2$：\n- 预报异常矩阵为\n$$\nX^{f} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & 1 \\\\\n0 & 0\n\\end{pmatrix}.\n$$\n- 观测算子为\n$$\nH = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix},\n$$\n且观测误差协方差为 $R = I_{2}$，即 $\\mathbb{R}^{2 \\times 2}$ 中的单位矩阵。\n\n定义预报异常子空间 $\\mathcal{U}$ 为 $X^{f}$ 的列空间，后验Fisher信息子空间 $\\mathcal{V}$ 为 $F = H^{\\top} R^{-1} H$ 的列空间。两个子空间之间的夹角可以通过它们的主角 $\\{\\theta_{i}\\}$ 来量化，这些主角由 $Q_{\\mathcal{U}}^{\\top} Q_{\\mathcal{V}}$ 的奇异值得出，其中 $Q_{\\mathcal{U}}$ 和 $Q_{\\mathcal{V}}$ 分别是张成 $\\mathcal{U}$ 和 $\\mathcal{V}$ 的具有标准正交列的矩阵。设诊断角为最大主角 $\\theta_{\\max} = \\max_{i} \\theta_{i}$。\n\n任务：\n1. 计算给定 $X^{f}$、$H$ 和 $R$ 时，$\\mathcal{U}$ 和 $\\mathcal{V}$ 之间的最大主角 $\\theta_{\\max}$，以弧度表示。最终答案以弧度表示。无需四舍五入。\n2. 从确定性平方根集合卡尔曼滤波器的协方差匹配约束出发，即分析异常 $X^{a} = X^{f} T$ 必须满足 $\\frac{1}{m-1} X^{f} T T^{\\top} X^{f \\top} = P^{a}$，其中 $P^{a}$ 等于卡尔曼后验协方差 $P^{f} - P^{f} H^{\\top} (H P^{f} H^{\\top} + R)^{-1} H P^{f}$，推导一个变换 $T$，该变换通过收缩那些由 $H$ 提供信息不足的集合方向来惩罚未对准。使用观测空间集合矩阵 $Y = \\frac{1}{\\sqrt{m-1}} H X^{f}$ 的奇异值分解，指定一个变换族 $T_{\\lambda}$，它通过参数 $\\lambda \\in (0,1)$ 来减小与 $Y$ 的小奇异值对应的集合方向上的振幅。提供 $T_{\\lambda}$ 的闭式表达式，并讨论其对于给定数值实例的影响。\n\n你最终报告的答案应该是诊断角的弧度值。",
            "solution": "在尝试解答之前，将对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- 状态空间维度：$n = 3$。\n- 观测空间维度：$p = 2$。\n- 集合大小：$m = 2$。\n- 预报异常矩阵：$X^{f} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\in \\mathbb{R}^{3 \\times 2}$。\n- 观测算子：$H = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\in \\mathbb{R}^{2 \\times 3}$。\n- 观测误差协方差：$R = I_{2} \\in \\mathbb{R}^{2 \\times 2}$，单位矩阵。\n- 预报误差协方差：$P^{f} = \\frac{1}{m-1} X^{f} X^{f \\top}$。\n- 后验Fisher信息矩阵：$F = H^{\\top} R^{-1} H$。\n- 预报异常子空间：$\\mathcal{U} = \\text{col}(X^{f})$。\n- 后验Fisher信息子空间：$\\mathcal{V} = \\text{col}(F)$。\n- 诊断角：$\\theta_{\\max} = \\max_{i} \\theta_{i}$，其中 $\\theta_i$ 是 $\\mathcal{U}$ 和 $\\mathcal{V}$ 之间的主角。\n- 主角由 $Q_{\\mathcal{U}}^{\\top} Q_{\\mathcal{V}}$ 的奇异值 $\\sigma_i$ 通过 $\\cos(\\theta_i)=\\sigma_i$ 获得，其中 $Q_{\\mathcal{U}}$ 和 $Q_{\\mathcal{V}}$ 是分别张成 $\\mathcal{U}$ 和 $\\mathcal{V}$ 的具有标准正交列的矩阵。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据：** 该问题使用了数据同化和线性代数中的标准概念，包括集合卡尔曼滤波器（EnKF）、Fisher信息以及子空间之间的主角。其表述与该领域的既有文献一致。\n- **适定性：** 该问题包含两个任务。第一个是一个具体的计算，所有必要的数据都已提供。第二个是一个推导，基于一个明确定义的起点（协方差匹配约束）和一个清晰的目标（发展一种特定类型的变换 $T_{\\lambda}$）。该问题结构良好，可以找到有意义的解。最终指令要求只报告第一个任务的答案，这是对输出格式的说明，并非问题逻辑上的缺陷。\n- **客观性：** 该问题以精确的数学语言陈述，没有主观性或歧义。\n\n### 步骤 3：结论与行动\n该问题有效。将按要求为两个任务提供解答，最终答案按照指示对应于第一个任务的结果。\n\n### 任务 1：计算最大主角 $\\theta_{\\max}$\n\n首先，我们必须找到子空间 $\\mathcal{U}$ 和 $\\mathcal{V}$ 的标准正交基。\n\n预报异常子空间 $\\mathcal{U}$ 是 $X^{f}$ 的列空间：\n$$\nX^{f} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n$$\n$X^f$ 的列是向量 $(1, 0, 0)^{\\top}$ 和 $(0, 1, 0)^{\\top}$。这些向量已经是标准正交的。因此，我们可以选择 $\\mathcal{U}$ 的标准正交基矩阵为 $Q_{\\mathcal{U}} = X^{f}$。\n$$\nQ_{\\mathcal{U}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n$$\n\n后验Fisher信息子空间 $\\mathcal{V}$ 是 $F = H^{\\top} R^{-1} H$ 的列空间。\n给定 $H = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$ 和 $R = I_{2}$，我们有 $R^{-1} = I_{2}$。$H$ 的转置是 $H^{\\top} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\end{pmatrix}$。\n我们计算 $F$：\n$$\nF = H^{\\top} H = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\n$F$ 的列空间由向量 $(1, 0, 0)^{\\top}$ 和 $(0, 0, 1)^{\\top}$ 张成。这些向量也是标准正交的。所以，$\\mathcal{V}$ 的一个标准正交基由矩阵 $Q_{\\mathcal{V}}$ 的列给出：\n$$\nQ_{\\mathcal{V}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\n在几何上，$\\mathcal{U}$ 是 $\\mathbb{R}^3$ 中的 $xy$-平面，$\\mathcal{V}$ 是 $xz$-平面。\n\n接下来，我们计算矩阵乘积 $Q_{\\mathcal{U}}^{\\top} Q_{\\mathcal{V}}$：\n$$\nQ_{\\mathcal{U}}^{\\top} Q_{\\mathcal{V}} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n主角 $\\{\\theta_i\\}$ 与该矩阵的奇异值 $\\{\\sigma_i\\}$ 通过 $\\cos(\\theta_i) = \\sigma_i$ 相关联。\n矩阵 $\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$ 是一个对角矩阵。其奇异值是其对角线元素的绝对值。\n所以，奇异值为 $\\sigma_1 = 1$ 和 $\\sigma_2 = 0$。\n\n主角为：\n$$\n\\theta_1 = \\arccos(\\sigma_1) = \\arccos(1) = 0 \\text{ 弧度}\n$$\n$$\n\\theta_2 = \\arccos(\\sigma_2) = \\arccos(0) = \\frac{\\pi}{2} \\text{ 弧度}\n$$\n诊断角 $\\theta_{\\max}$ 是最大主角。\n$$\n\\theta_{\\max} = \\max\\left(0, \\frac{\\pi}{2}\\right) = \\frac{\\pi}{2}\n$$\n\n### 任务 2：推导变换 $T_{\\lambda}$\n\n确定性平方根滤波器的协方差匹配约束要求找到一个变换矩阵 $T$，使得分析异常 $X^{a} = X^{f}T$ 能够产生正确的分析误差协方差 $P^a$。\n$$\nP^{a} = \\frac{1}{m-1} X^{a} (X^{a})^{\\top} = \\frac{1}{m-1} X^{f} T T^{\\top} (X^{f})^{\\top}\n$$\n卡尔曼分析协方差为 $P^{a} = P^{f} - P^{f} H^{\\top} (H P^{f} H^{\\top} + R)^{-1} H P^{f}$。\n通过代入 $P^f = \\frac{1}{m-1}X^f(X^f)^\\top$ 并使用 Woodbury 矩阵恒等式，可以证明这等价于\n$$\nP^a = \\frac{1}{m-1} X^f (I_m + Y^\\top R^{-1} Y)^{-1} (X^f)^\\top\n$$\n其中 $Y = \\frac{1}{\\sqrt{m-1}} H X^f$。\n令两个 $P^a$ 的表达式相等，并假设 $X^f$ 具有线性无关的列，我们得到变换矩阵 $T$ 的条件：\n$$\nT T^{\\top} = (I_m + Y^{\\top} R^{-1} Y)^{-1}\n$$\n一个常见的选择是对称平方根，$T = (I_m + Y^{\\top} R^{-1} Y)^{-1/2}$。让我们使用 $Y$ 的奇异值分解（SVD）$Y = U S V^{\\top}$ 来分析其效果。由于 $R=I_2$，这简化为 $T T^{\\top} = (I_m + Y^{\\top} Y)^{-1}$。\n$Y^{\\top}Y = V S^{\\top}U^{\\top}USV^{\\top} = V S^{\\top}SV^{\\top}$。\n因此，$T T^{\\top} = (I_m + V S^{\\top}S V^{\\top})^{-1} = V(I_m + S^{\\top}S)^{-1}V^{\\top}$。\n对称平方根变换是 $T = V(I_m + S^{\\top}S)^{-1/2}V^{\\top}$。矩阵 $I_m + S^{\\top}S$ 是对角矩阵，其对角元素为 $1+\\sigma_i^2$，其中 $\\sigma_i$ 是 $Y$ 的奇异值。该变换通过因子 $s_i = (1+\\sigma_i^2)^{-1/2}$ 来缩放异常模（$X^f V$ 的列）。\n一个小的奇异值 $\\sigma_i \\approx 0$ 对应一个“信息不足”的方向，即一个几乎在 $H$ 的零空间中的集合模。对于这样的模，标准的收缩因子是 $s_i \\approx 1$，这意味着其振幅基本保持不变。这与问题中“减小与小奇异值对应的集合方向上的振幅”的要求相反。\n\n为了推导所要求的变换 $T_{\\lambda}$，我们引入一个正则化项。这可以被构建为在卡尔曼滤波器基础的贝叶斯更新中修改先验。标准公式假设集合权重上为无信息先验。通过假设权重上有一个零均值、协方差为 $\\lambda^2 I_m$ 的高斯先验，我们引入一个正则化项。集合空间中的后验协方差变为 $(\\lambda^{-2} I_m + Y^{\\top} R^{-1} Y)^{-1}$。\n该正则化系统的协方差匹配约束导致：\n$$\nT_{\\lambda} T_{\\lambda}^{\\top} = (\\lambda^{-2} I_m + Y^{\\top} R^{-1} Y)^{-1}\n$$\n取对称平方根并使用 $Y$ 的 SVD（其中 $R=I_2$），我们得到：\n$$\nT_{\\lambda} = (\\lambda^{-2} I_m + V S^{\\top}S V^{\\top})^{-1/2} = V (\\lambda^{-2} I_m + S^{\\top}S)^{-1/2} V^{\\top}\n$$\n这是 $T_\\lambda$ 的闭式表达式。模的缩放因子为 $s_i(\\lambda) = (\\lambda^{-2} + \\sigma_i^2)^{-1/2} = \\lambda(1 + \\lambda^2 \\sigma_i^2)^{-1/2}$。\n对于一个信息不足的方向（$\\sigma_i \\to 0$），缩放因子为 $s_i(\\lambda) \\to \\lambda$。由于 $\\lambda \\in (0,1)$，这引入了收缩，当 $\\lambda \\to 0$ 时收缩更强。这符合要求。对于一个信息充分的方向（$\\sigma_i \\to \\infty$），因子 $s_i(\\lambda) \\to 1/\\sigma_i$，这是强收缩，与标准滤波器中的情况一样。\n\n让我们分析其对给定数值实例的影响。\n$m=2$，所以 $m-1=1$。\n$Y = \\frac{1}{\\sqrt{1}} H X^f = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$。\n$Y$ 的 SVD 是平凡的，因为它已经是 $U S V^\\top$ 的形式，其中 $U=I_2$，$S=Y$，$V=I_2$。\n奇异值为 $\\sigma_1 = 1$ 和 $\\sigma_2 = 0$。\n矩阵 $S^{\\top}S = Y^\\top Y = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$。\n变换 $T_\\lambda$ 是：\n$$\nT_{\\lambda} = I_2 \\left(\\lambda^{-2} I_2 + \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\\right)^{-1/2} I_2^{\\top} = \\begin{pmatrix} \\lambda^{-2}+1 & 0 \\\\ 0 & \\lambda^{-2} \\end{pmatrix}^{-1/2} = \\begin{pmatrix} ( \\lambda^{-2}+1 )^{-1/2} & 0 \\\\ 0 & \\lambda \\end{pmatrix}\n$$\n$$\nT_{\\lambda} = \\begin{pmatrix} \\frac{\\lambda}{\\sqrt{1+\\lambda^2}} & 0 \\\\ 0 & \\lambda \\end{pmatrix}\n$$\n第一个集合异常模 $(1,0,0)^\\top$ 对应于 $\\sigma_1=1$（一个信息充分的方向）。其振幅被缩放为 $\\lambda/\\sqrt{1+\\lambda^2}$。当 $\\lambda \\to 1^-$ 时，该因子趋近于 $1/\\sqrt{2}$，这是标准的卡尔曼更新收缩。\n第二个集合异常模 $(0,1,0)^\\top$ 未被 $H$ 观测到，并对应于 $\\sigma_2=0$（一个信息不足的方向）。其振幅被缩放为 $\\lambda$。对于任何 $\\lambda<1$，这会收缩未观测到的模，而标准更新则不进行收缩（因子为1）。这种正则化有助于防止未观测误差的增长，并可以减轻伪相关的影响，这在集合大小 $m$ 很小时尤其重要。",
            "answer": "$$\n\\boxed{\\frac{\\pi}{2}}\n$$"
        }
    ]
}