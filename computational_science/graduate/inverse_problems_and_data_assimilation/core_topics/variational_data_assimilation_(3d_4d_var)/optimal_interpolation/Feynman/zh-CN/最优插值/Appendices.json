{
    "hands_on_practices": [
        {
            "introduction": "最优插值提供了一个数学框架，用于融合不确定的背景知识和新的、带有噪声的观测。该方法的核心是增益矩阵 $K$，它决定了赋予新数据的相对权重。第一个练习将引导您在一个简化的标量设置中，从第一性原理出发推导最优增益，并分析其在极端情况下的行为，从而为如何最优地平衡信息建立起强大的直觉。",
            "id": "3407588",
            "problem": "考虑最优插值（OI）的线性高斯数据同化设置。设未知状态为 $x \\in \\mathbb{R}^{n}$，其背景（先验）为 $x \\sim \\mathcal{N}(x_{b}, B)$，其中 $x_{b} \\in \\mathbb{R}^{n}$ 是背景均值，$B \\in \\mathbb{R}^{n \\times n}$ 是对称正定的背景误差协方差。观测由 $y = H x + \\varepsilon$ 给出，其中 $H \\in \\mathbb{R}^{m \\times n}$ 是已知的线性观测算子，$\\varepsilon \\sim \\mathcal{N}(0, R)$，$R \\in \\mathbb{R}^{m \\times m}$ 是对称正定的，且独立于背景误差。考虑形式为 $x_{a} = x_{b} + K \\left(y - H x_{b}\\right)$ 的线性估计量的仿射族，其中 $K \\in \\mathbb{R}^{n \\times m}$ 是一个增益矩阵，需要通过在高斯假设下最小化均方分析误差来确定。\n\n1. 特化为标量情况，$n = m = 1$，$H = 1$，$B = b \\in \\mathbb{R}_{>0}$，$R = r \\in \\mathbb{R}_{>0}$。从第一性原理（从分析误差及其方差的定义开始）推导使期望平方分析误差最小化的唯一值 $k \\in \\mathbb{R}$，并用 $b$ 和 $r$ 显式表示。然后，在这种标量情况下，分析当 $b \\to \\infty$（无信息先验）和 $r \\to 0$（无噪声观测）时 $k$ 的极限行为，并解释每个极限的认知意义。\n\n2. 现在考虑对角矩阵情况，$H = I_{n}$，$B = \\operatorname{diag}(b_{1}, \\dots, b_{n})$ 且 $R = \\operatorname{diag}(r_{1}, \\dots, r_{n})$，其中所有 $b_{i}, r_{i} \\in \\mathbb{R}_{>0}$。在相同的最优性准则下，推导显式的对角增益 $K \\in \\mathbb{R}^{n \\times n}$，并分析当所有 $i$ 的 $b_{i} \\to \\infty$ 和所有 $i$ 的 $r_{i} \\to 0$ 时其极限行为。解释每个极限的认知后果。\n\n请以一个包含六个条目的单行矩阵形式提供您的最终答案，顺序如下：\n- 标量最优增益 $k$，\n- 极限 $\\lim_{b \\to \\infty} k$，\n- 极限 $\\lim_{r \\to 0} k$，\n- 对角最优增益 $K$，\n- 极限 $\\lim_{b_{i} \\to \\infty \\ \\forall i} K$，\n- 极限 $\\lim_{r_{i} \\to 0 \\ \\forall i} K$。\n\n不需要数值四舍五入。不包括单位。仅以符号闭合形式表达您的最终答案。",
            "solution": "该问题陈述经评估有效。这是一个适定、有科学依据且客观的问题表述，其根植于数据同化领域最优插值的基本原理。所有必要的数据、定义和条件均已提供，不存在内部矛盾或歧义。因此，我们可以着手求解。\n\n问题要求找到最优增益矩阵 $K$，以最小化均方分析误差。分析状态 $x_a$ 是一个由 $x_{a} = x_{b} + K \\left(y - H x_{b}\\right)$ 给出的仿射估计量。真实状态是 $x$，背景状态 $x_b$ 代表先验估计，其中背景误差 $e_b = x_b - x$ 的均值为零，协方差为 $B = \\mathbb{E}[e_b e_b^T]$。观测值为 $y = H x + \\varepsilon$，其中观测误差 $\\varepsilon$ 的均值为零，协方差为 $R = \\mathbb{E}[\\varepsilon \\varepsilon^T]$。背景误差和观测误差不相关。\n\n分析误差定义为 $e_a = x_a - x$。我们可以用背景误差和观测误差来表示它：\n$$e_a = \\left(x_b + K(y - Hx_b)\\right) - x = (x_b - x) + K(Hx + \\varepsilon - Hx_b) = (x_b - x) - KH(x_b - x) + K\\varepsilon$$\n$$e_a = (I - KH)e_b + K\\varepsilon$$\n分析误差协方差矩阵 $A$ 由 $A = \\mathbb{E}[e_a e_a^T]$ 给出。由于 $e_b$ 和 $\\varepsilon$ 不相关，交叉项消失：\n$$A = \\mathbb{E}[((I - KH)e_b + K\\varepsilon)((I - KH)e_b + K\\varepsilon)^T] = (I - KH)\\mathbb{E}[e_b e_b^T](I - KH)^T + K\\mathbb{E}[\\varepsilon\\varepsilon^T]K^T$$\n$$A = (I - KH)B(I - KH)^T + KRK^T$$\n目标是最小化均方分析误差，即分析误差协方差矩阵的迹，$J(K) = \\operatorname{tr}(A)$。最小化此成本函数的增益矩阵 $K$ 由著名的卡尔曼增益公式给出：\n$$K = BH^T(HBH^T + R)^{-1}$$\n\n**第1部分：标量情况**\n\n在这一部分，我们特化为标量情况，其中 $n=m=1$，$H=1$，$B=b \\in \\mathbb{R}_{>0}$，$R=r \\in \\mathbb{R}_{>0}$。增益矩阵 $K$ 变为标量 $k \\in \\mathbb{R}$。我们被要求从第一性原理推导解。\n\n标量分析误差 $e_a$ 由 $e_a = (1-k)e_b + k\\varepsilon$ 给出，其中 $e_b$ 是标量背景误差，$\\varepsilon$ 是标量观测误差。方差分别为 $\\mathbb{E}[e_b^2] = b$ 和 $\\mathbb{E}[\\varepsilon^2] = r$。\n期望平方分析误差，即分析误差方差 $a$，是需要最小化的成本函数：\n$$J(k) = a = \\mathbb{E}[e_a^2] = \\mathbb{E}[((1-k)e_b + k\\varepsilon)^2]$$\n展开并利用 $e_b$ 和 $\\varepsilon$ 的独立性（$\\mathbb{E}[e_b\\varepsilon] = 0$），我们得到：\n$$J(k) = (1-k)^2\\mathbb{E}[e_b^2] + k^2\\mathbb{E}[\\varepsilon^2] = (1-k)^2 b + k^2 r$$\n为了找到最小化该方差的最优增益 $k$，我们将 $J(k)$ 对 $k$ 求导并令结果为零：\n$$\\frac{dJ}{dk} = \\frac{d}{dk}((1-2k+k^2)b + k^2r) = -2b + 2kb + 2kr = 2k(b+r) - 2b$$\n令导数为零：\n$$2k(b+r) - 2b = 0 \\implies k(b+r) = b \\implies k = \\frac{b}{b+r}$$\n\n现在，我们分析 $k$ 的极限行为：\n1.  当 $b \\to \\infty$（无信息先验）：\n    $$\\lim_{b \\to \\infty} k = \\lim_{b \\to \\infty} \\frac{b}{b+r} = \\lim_{b \\to \\infty} \\frac{1}{1 + \\frac{r}{b}} = \\frac{1}{1+0} = 1$$\n    **认知意义：** 当背景误差方差 $b$ 为无穷大时，先验信息 $x_b$ 被认为是完全不可靠的。最优增益 $k$ 趋近于 $1$。分析更新变为 $x_a = x_b + 1(y-x_b) = y$。这表明背景被完全抛弃，分析完全由观测值 $y$ 决定。\n\n2.  当 $r \\to 0$（无噪声观测）：\n    $$\\lim_{r \\to 0} k = \\lim_{r \\to 0} \\frac{b}{b+r} = \\frac{b}{b+0} = 1$$\n    **认知意义：** 当观测误差方差 $r$ 为零时，观测值 $y$ 是完全准确的。最优增益 $k$ 再次趋近于 $1$，导致 $x_a = y$。这表明完全信任完美的观测，它会覆盖掉任何来自背景的不确定信息。\n\n**第2部分：对角矩阵情况**\n\n这里，我们考虑 $H=I_n$，$B = \\operatorname{diag}(b_{1}, \\dots, b_{n})$，$R = \\operatorname{diag}(r_{1}, \\dots, r_{n})$。我们使用最优增益 $K$ 的通用公式：\n$$K = B H^T (H B H^T + R)^{-1}$$\n代入 $H=I_n$：\n$$K = B I_n^T (I_n B I_n^T + R)^{-1} = B(B+R)^{-1}$$\n矩阵 $B$ 和 $R$ 是对角的，所以它们的和也是一个对角矩阵：\n$$B+R = \\operatorname{diag}(b_1, \\dots, b_n) + \\operatorname{diag}(r_1, \\dots, r_n) = \\operatorname{diag}(b_1+r_1, \\dots, b_n+r_n)$$\n对角矩阵的逆是其对角元素倒数构成的对角矩阵：\n$$(B+R)^{-1} = \\operatorname{diag}\\left(\\frac{1}{b_1+r_1}, \\dots, \\frac{1}{b_n+r_n}\\right)$$\n最后，我们通过将两个对角矩阵相乘来计算 $K$：\n$$K = \\operatorname{diag}(b_1, \\dots, b_n) \\operatorname{diag}\\left(\\frac{1}{b_1+r_1}, \\dots, \\frac{1}{b_n+r_n}\\right)$$\n$$K = \\operatorname{diag}\\left(\\frac{b_1}{b_1+r_1}, \\frac{b_2}{b_2+r_2}, \\dots, \\frac{b_n}{b_n+r_n}\\right)$$\n该问题解耦为 $n$ 个独立的标量问题，状态向量的每个分量对应一个。\n\n现在，我们分析 $K$ 的极限行为：\n1.  当所有 $i$ 的 $b_i \\to \\infty$ 时：\n    对于每个对角元素 $K_{ii} = \\frac{b_i}{b_i+r_i}$，其极限为 $\\lim_{b_i \\to \\infty} \\frac{b_i}{b_i+r_i} = 1$。因此，矩阵的极限是：\n    $$\\lim_{b_i \\to \\infty \\ \\forall i} K = \\operatorname{diag}(1, 1, \\dots, 1) = I_n$$\n    **认知意义：** 当所有状态分量的背景不确定性变为无穷大时，先验是无信息的。增益矩阵变为单位矩阵 $I_n$。分析更新变为 $x_a = x_b + I_n(y - x_b) = y$。分析状态被设为等于观测向量，完全忽略了不可靠的背景。\n\n2.  当所有 $i$ 的 $r_i \\to 0$ 时：\n    对于每个对角元素 $K_{ii} = \\frac{b_i}{b_i+r_i}$，其极限为 $\\lim_{r_i \\to 0} \\frac{b_i}{b_i+r_i} = \\frac{b_i}{b_i} = 1$。矩阵的极限是：\n    $$\\lim_{r_i \\to 0 \\ \\forall i} K = \\operatorname{diag}(1, 1, \\dots, 1) = I_n$$\n    **认知意义：** 当所有分量的观测误差变为零时，观测是完美的。增益矩阵变为单位矩阵 $I_n$，分析更新为 $x_a = y$。同样，分析状态完全由观测决定，因为它们是以绝对的确定性已知的。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{b}{b+r}  1  1  \\operatorname{diag}\\left(\\frac{b_1}{b_1+r_1}, \\frac{b_2}{b_2+r_2}, \\dots, \\frac{b_n}{b_n+r_n}\\right)  I_n  I_n\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "虽然最优插值的增益矩阵公式在计算上很方便，但其真正的威力与合理性源于更深的统计基础。本练习将指导您在一个简单的线性高斯系统中，直接从贝叶斯定理推导出最优插值方程。通过这样做，您将证明最优插值分析正是贝叶斯后验分布的均值，从而为同化过程提供了严谨的概率解释。",
            "id": "3407601",
            "problem": "考虑一个用于二维状态向量 $x \\in \\mathbb{R}^{2}$ 的线性高斯数据同化场景，其具有高斯先验和单个线性观测。先验分布为 $x \\sim \\mathcal{N}(x_{b}, B)$，其中先验均值为 $x_{b} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$，先验协方差为 $B = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}$。观测模型为 $y = H x + v$，其中 $H = \\begin{pmatrix} 1  2 \\end{pmatrix}$，观测误差 $v$ 是高斯的，其分布为 $v \\sim \\mathcal{N}(0, R)$，且 $R = 1$。记录到单个观测值 $y$，其值为 $y=3$。\n\n使用贝叶斯定理和多元正态分布的性质，通过在先验和似然乘积的指数项中进行配方，推导出后验分布 $p(x \\mid y)$。将后验分布表示为具有均值 $x_{a}$ 和协方差 $A$ 的高斯分布的闭式解形式。然后，使用基础的线性代数恒等式，解析地验证得到的后验均值和协方差可以被重写为最优插值 (OI) 中使用的标准增益形式，而无需从任何记忆的公式开始。最后，根据给定的 $x_{b}$、$B$、$H$、$R$ 和 $y$，数值计算 $x_{a}$ 和 $A$。\n\n为便于评分，请报告分析均值 $x_{a}$ 的第一个分量的值，以精确的有理数形式表示。无需四舍五入，不涉及物理单位。",
            "solution": "线性高斯数据同化模型指定了高斯先验和高斯似然。根据贝叶斯定理，后验密度与先验和似然的乘积成正比：\n$$\np(x \\mid y) \\propto p(y \\mid x) p(x).\n$$\n对于 $x \\sim \\mathcal{N}(x_{b}, B)$ 和 $y \\mid x \\sim \\mathcal{N}(H x, R)$，我们有\n$$\np(x) \\propto \\exp\\!\\left( -\\tfrac{1}{2} (x - x_{b})^{\\top} B^{-1} (x - x_{b}) \\right),\n\\quad\np(y \\mid x) \\propto \\exp\\!\\left( -\\tfrac{1}{2} (y - H x)^{\\top} R^{-1} (y - H x) \\right).\n$$\n因此，\n$$\np(x \\mid y) \\propto \\exp\\!\\left( -\\tfrac{1}{2} \\left[ (x - x_{b})^{\\top} B^{-1} (x - x_{b}) + (y - H x)^{\\top} R^{-1} (y - H x) \\right] \\right).\n$$\n展开二次型并合并关于 $x$ 的项，我们得到标准二次型\n$$\n-\\tfrac{1}{2}\\left[ x^{\\top} \\left( B^{-1} + H^{\\top} R^{-1} H \\right) x - 2 x^{\\top} \\left( B^{-1} x_{b} + H^{\\top} R^{-1} y \\right) + \\text{const} \\right].\n$$\n配方后得到一个高斯后验分布，其精度为\n$$\nS \\equiv B^{-1} + H^{\\top} R^{-1} H,\n$$\n后验协方差为\n$$\nA = S^{-1},\n$$\n以及后验均值为\n$$\nx_{a} = A \\left( B^{-1} x_{b} + H^{\\top} R^{-1} y \\right).\n$$\n这些表达式是直接通过对高斯分布的指数项进行配方得到的，代表了贝叶斯解。\n\n接下来，我们展示如何将这些表达式重写为与最优插值 (OI) 相关联的增益形式。考虑矩阵求逆引理（也称为 Woodbury 恒等式）：\n$$\n\\left( B^{-1} + H^{\\top} R^{-1} H \\right)^{-1}\n= B - B H^{\\top} \\left( R + H B H^{\\top} \\right)^{-1} H B.\n$$\n定义增益\n$$\nK \\equiv B H^{\\top} \\left( H B H^{\\top} + R \\right)^{-1}.\n$$\n那么\n$$\nA = \\left( B^{-1} + H^{\\top} R^{-1} H \\right)^{-1} = B - B H^{\\top} \\left( R + H B H^{\\top} \\right)^{-1} H B = \\left( I - K H \\right) B.\n$$\n对于均值，使用 $x_{a} = A \\left( B^{-1} x_{b} + H^{\\top} R^{-1} y \\right)$ 和 $A = \\left( I - K H \\right) B$，我们有\n\\begin{align*}\nx_{a}\n= \\left( I - K H \\right) B \\left( B^{-1} x_{b} + H^{\\top} R^{-1} y \\right) \\\\\n= \\left( I - K H \\right) x_{b} + \\left( I - K H \\right) B H^{\\top} R^{-1} y.\n\\end{align*}\n因为 $K = B H^{\\top} \\left( H B H^{\\top} + R \\right)^{-1}$ 且 $R$ 是对称正定的，可以通过代数运算证明\n$$\n\\left( I - K H \\right) B H^{\\top} R^{-1} = K,\n$$\n这意味着\n$$\nx_{a} = x_{b} + K \\left( y - H x_{b} \\right).\n$$\n这就是与最优插值 (OI) 相关联的增益形式，它是从标准的贝叶斯表达式推导出来的，而没有在一开始就援引任何快捷公式。\n\n现在我们根据给定的 $x_{b}$、$B$、$H$、$R$ 和 $y$ 来数值计算 $x_{a}$ 和 $A$。\n\n首先计算\n$$\nB^{-1} = \\begin{pmatrix} \\tfrac{1}{4}  0 \\\\ 0  1 \\end{pmatrix}, \\quad\nH^{\\top} R^{-1} H = H^{\\top} H = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} 1  2 \\end{pmatrix}\n= \\begin{pmatrix} 1  2 \\\\ 2  4 \\end{pmatrix}.\n$$\n因此，\n$$\nS = B^{-1} + H^{\\top} R^{-1} H\n= \\begin{pmatrix} \\tfrac{1}{4}  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 1  2 \\\\ 2  4 \\end{pmatrix}\n= \\begin{pmatrix} \\tfrac{5}{4}  2 \\\\ 2  5 \\end{pmatrix}.\n$$\n$S$ 的行列式是\n$$\n\\det(S) = \\left( \\tfrac{5}{4} \\right) \\cdot 5 - 2 \\cdot 2 = \\tfrac{25}{4} - 4 = \\tfrac{9}{4}.\n$$\n因此，\n$$\nA = S^{-1} = \\frac{1}{\\det(S)} \\begin{pmatrix} 5  -2 \\\\ -2  \\tfrac{5}{4} \\end{pmatrix}\n= \\frac{4}{9} \\begin{pmatrix} 5  -2 \\\\ -2  \\tfrac{5}{4} \\end{pmatrix}\n= \\begin{pmatrix} \\tfrac{20}{9}  -\\tfrac{8}{9} \\\\ -\\tfrac{8}{9}  \\tfrac{5}{9} \\end{pmatrix}.\n$$\n接下来计算后验均值：\n$$\nB^{-1} x_{b} = \\begin{pmatrix} \\tfrac{1}{4}  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n= \\begin{pmatrix} \\tfrac{1}{4} \\\\ -1 \\end{pmatrix}, \\quad\nH^{\\top} R^{-1} y = H^{\\top} y = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\cdot 3 = \\begin{pmatrix} 3 \\\\ 6 \\end{pmatrix}.\n$$\n于是\n$$\nB^{-1} x_{b} + H^{\\top} R^{-1} y = \\begin{pmatrix} \\tfrac{1}{4} + 3 \\\\ -1 + 6 \\end{pmatrix} = \\begin{pmatrix} \\tfrac{13}{4} \\\\ 5 \\end{pmatrix}.\n$$\n乘以 $A$ 得到\n\\begin{align*}\nx_{a}\n= A \\begin{pmatrix} \\tfrac{13}{4} \\\\ 5 \\end{pmatrix}\n= \\begin{pmatrix} \\tfrac{20}{9}  -\\tfrac{8}{9} \\\\ -\\tfrac{8}{9}  \\tfrac{5}{9} \\end{pmatrix}\n\\begin{pmatrix} \\tfrac{13}{4} \\\\ 5 \\end{pmatrix} \\\\\n= \\begin{pmatrix}\n\\tfrac{20}{9} \\cdot \\tfrac{13}{4} - \\tfrac{8}{9} \\cdot 5 \\\\\n- \\tfrac{8}{9} \\cdot \\tfrac{13}{4} + \\tfrac{5}{9} \\cdot 5\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\tfrac{260}{36} - \\tfrac{40}{9} \\\\\n- \\tfrac{104}{36} + \\tfrac{25}{9}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\tfrac{65}{9} - \\tfrac{40}{9} \\\\\n- \\tfrac{26}{9} + \\tfrac{25}{9}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\tfrac{25}{9} \\\\\n- \\tfrac{1}{9}\n\\end{pmatrix}.\n\\end{align*}\n或者，使用增益形式计算\n$$\nH B H^{\\top} = H \\left( B H^{\\top} \\right) = \\begin{pmatrix} 1  2 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 2 \\end{pmatrix} = 8,\n\\quad\nK = B H^{\\top} \\left( H B H^{\\top} + R \\right)^{-1} = \\begin{pmatrix} 4 \\\\ 2 \\end{pmatrix} \\cdot \\frac{1}{9} = \\begin{pmatrix} \\tfrac{4}{9} \\\\ \\tfrac{2}{9} \\end{pmatrix},\n$$\n以及新息\n$$\nd = y - H x_{b} = 3 - \\begin{pmatrix} 1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = 3 - (1 - 2) = 4.\n$$\n然后\n$$\nx_{a} = x_{b} + K d = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} \\tfrac{4}{9} \\\\ \\tfrac{2}{9} \\end{pmatrix} \\cdot 4 = \\begin{pmatrix} 1 + \\tfrac{16}{9} \\\\ -1 + \\tfrac{8}{9} \\end{pmatrix} = \\begin{pmatrix} \\tfrac{25}{9} \\\\ - \\tfrac{1}{9} \\end{pmatrix},\n$$\n这与通过贝叶斯配方法得到的结果相符。对于协方差，\n$$\nA = \\left( I - K H \\right) B\n= \\left( I - \\frac{1}{9} \\begin{pmatrix} 4 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} 1  2 \\end{pmatrix} \\right) \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}\n= \\left( I - \\frac{1}{9} \\begin{pmatrix} 4  8 \\\\ 2  4 \\end{pmatrix} \\right) \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 1 - \\tfrac{4}{9}  - \\tfrac{8}{9} \\\\ - \\tfrac{2}{9}  1 - \\tfrac{4}{9} \\end{pmatrix} \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}\n= \\begin{pmatrix} \\tfrac{5}{9}  - \\tfrac{8}{9} \\\\ - \\tfrac{2}{9}  \\tfrac{5}{9} \\end{pmatrix} \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}\n= \\begin{pmatrix} \\tfrac{20}{9}  - \\tfrac{8}{9} \\\\ - \\tfrac{8}{9}  \\tfrac{5}{9} \\end{pmatrix},\n$$\n这等于上面计算的 $S^{-1}$。这解析地验证了从贝叶斯原理推导出的后验均值和协方差与最优插值 (OI) 的增益形式是一致的。\n\n所要求的最终量是 $x_{a}$ 的第一个分量，即 $\\tfrac{25}{9}$，以精确的有理数形式表示。",
            "answer": "$$\\boxed{\\frac{25}{9}}$$"
        },
        {
            "introduction": "为了将最优插值应用于现实世界的问题（例如天气预报），我们必须将物理测量转化为数学形式。这涉及到构建一个观测算子 $H$，它将模型的状态空间映射到观测空间。最后一个练习提供了一个在网格上布置传感器的具体情景，要求您使用线性插值构建算子 $H$，然后用它来计算观测空间影响矩阵——一个用于诊断观测对分析影响的工具。",
            "id": "3407564",
            "problem": "考虑一个一维空间域，其中网格节点均匀分布在位置 $x_{0}=0$、$x_{1}=1$、$x_{2}=2$ 和 $x_{3}=3$ 处。模型状态是一个向量 $x \\in \\mathbb{R}^{4}$，其分量是这些网格节点上的场值。两个点传感器测量位于 $s_{1}=0.4$ 和 $s_{2}=2.3$ 位置的场。每个观测值等于传感器位置处的真实场值加上一个独立的、零均值的高斯误差。假设相邻网格节点之间的线性插值表示由离散状态 $x$ 所隐含的连续场。\n\n1. 使用点测量的物理定义和均匀网格上的标准线性插值法则，定义将 $x$ 映射到观测向量 $y \\in \\mathbb{R}^{2}$ 的线性观测算子 $H$。为给定的传感器位置 $s_{1}$ 和 $s_{2}$ 显式写出 $H$。\n\n2. 在线性高斯最优插值框架中，假设背景误差协方差为 $B=\\sigma_{b}^{2} I_{4}$（其中 $\\sigma_{b}=1.2$），观测误差协方差为 $R=\\operatorname{diag}(\\sigma_{o,1}^{2},\\sigma_{o,2}^{2})$（其中 $\\sigma_{o,1}^{2}=0.04$ 且 $\\sigma_{o,2}^{2}=0.09$）。从形式为 $x^{a}=x^{b}+K\\left(y-H x^{b}\\right)$ 的分析 $x^{a}$ 的最小方差线性估计量出发，推导增益 $K$ 和相关的观测空间影响矩阵 $S$ 的表达式，其中 $S$ 定义为从观测新息到观测空间中分析等效新息的线性映射，$S=H K$。然后，对于在此配置中得到的具体 $H$、$B$ 和 $R$，计算 $S$ 的 $(1,1)$ 元素。\n\n报告 $S$ 的 $(1,1)$ 元素的数值，并将答案四舍五入到四位有效数字。",
            "solution": "该问题被认为是有效的，因为它具有科学依据、内容自洽，并且在既定的最优插值框架内是适定的。\n\n解答按要求分两部分进行。首先，我们推导观测算子 $H$。其次，我们推导最优增益 $K$ 和影响矩阵 $S$，并计算特定元素 $S_{11}$。\n\n第1部分：观测算子 $H$ 的推导\n\n模型状态是一个向量 $x \\in \\mathbb{R}^{4}$，其中分量 $x_i$ 表示在网格节点 $x_i$ 上的场值（$i \\in \\{0, 1, 2, 3\\}$）。网格节点位于 $x_0=0$、$x_1=1$、$x_2=2$ 和 $x_3=3$。网格间距是均匀的，$\\Delta x = 1$。问题陈述，连续场由相邻网格节点之间的线性插值表示。\n\n对于位于两个网格节点 $x_i$ 和 $x_{i+1}$ 之间的一个点 $s$，插值 $v(s)$ 是这些节点上场值 $x(x_i)$ 和 $x(x_{i+1})$ 的加权平均值。线性插值的通用公式为：\n$$v(s) = x(x_i) \\frac{x_{i+1} - s}{x_{i+1} - x_i} + x(x_{i+1}) \\frac{s - x_i}{x_{i+1} - x_i}$$\n给定 $\\Delta x = x_{i+1} - x_i = 1$，上式简化为：\n$$v(s) = x(x_i) (x_{i+1} - s) + x(x_{i+1}) (s - x_i)$$\n观测算子 $H$ 是一个 $2 \\times 4$ 的矩阵，它将状态向量 $x = [x(x_0), x(x_1), x(x_2), x(x_3)]^T$ 映射到观测向量 $y = [v(s_1), v(s_2)]^T$。$H$ 的每一行对应一个传感器。\n\n第一个传感器位于 $s_1 = 0.4$。该位置在网格节点 $x_0 = 0$ 和 $x_1 = 1$ 之间。应用插值公式：\n$$v(s_1) = x(x_0) (1 - 0.4) + x(x_1) (0.4 - 0) = 0.6 \\cdot x(x_0) + 0.4 \\cdot x(x_1)$$\n状态向量的其他分量 $x(x_2)$ 和 $x(x_3)$ 对此观测值没有影响。因此，$H$ 的第一行是 $[0.6, 0.4, 0, 0]$。\n\n第二个传感器位于 $s_2 = 2.3$。该位置在网格节点 $x_2 = 2$ 和 $x_3 = 3$ 之间。应用插值公式：\n$$v(s_2) = x(x_2) (3 - 2.3) + x(x_3) (2.3 - 2) = 0.7 \\cdot x(x_2) + 0.3 \\cdot x(x_3)$$\n分量 $x(x_0)$ 和 $x(x_1)$ 没有影响。因此，$H$ 的第二行是 $[0, 0, 0.7, 0.3]$。\n\n组合这两行，线性观测算子 $H$ 为：\n$$H = \\begin{pmatrix} 0.6  0.4  0  0 \\\\ 0  0  0.7  0.3 \\end{pmatrix}$$\n\n第2部分：$K$、$S$ 的推导及 $S_{11}$ 的计算\n\n分析状态 $x^a$ 由最优插值方程给出：\n$$x^{a}=x^{b}+K(y-H x^{b})$$\n其中 $x^b$ 是背景状态。使分析误差方差最小化的最优增益矩阵 $K$ 由下式给出：\n$$K = B H^T (H B H^T + R)^{-1}$$\n此处，$B$ 是背景误差协方差矩阵，$R$ 是观测误差协方差矩阵。\n\n观测空间影响矩阵 $S$ 定义为 $S=HK$。代入 $K$ 的表达式：\n$$S = H \\left( B H^T (H B H^T + R)^{-1} \\right) = (H B H^T) (H B H^T + R)^{-1}$$\n\n给定以下协方差矩阵：\n- 背景误差协方差：$B = \\sigma_b^2 I_4$，其中 $\\sigma_b = 1.2$。所以，$B = 1.2^2 I_4 = 1.44 I_4$。\n- 观测误差协方差：$R = \\operatorname{diag}(\\sigma_{o,1}^2, \\sigma_{o,2}^2) = \\operatorname{diag}(0.04, 0.09)$，即矩阵 $\\begin{pmatrix} 0.04  0 \\\\ 0  0.09 \\end{pmatrix}$。\n\n为了计算 $S$，我们首先计算矩阵乘积 $H B H^T$。\n因为 $B = 1.44 I_4$，其中 $I_4$ 是 $4 \\times 4$ 的单位矩阵，我们有：\n$$H B H^T = H (1.44 I_4) H^T = 1.44 H H^T$$\n我们来计算 $H H^T$：\n$$H H^T = \\begin{pmatrix} 0.6  0.4  0  0 \\\\ 0  0  0.7  0.3 \\end{pmatrix} \\begin{pmatrix} 0.6  0 \\\\ 0.4  0 \\\\ 0  0.7 \\\\ 0  0.3 \\end{pmatrix}$$\n$$H H^T = \\begin{pmatrix} (0.6)^2 + (0.4)^2  0 \\\\ 0  (0.7)^2 + (0.3)^2 \\end{pmatrix} = \\begin{pmatrix} 0.36 + 0.16  0 \\\\ 0  0.49 + 0.09 \\end{pmatrix} = \\begin{pmatrix} 0.52  0 \\\\ 0  0.58 \\end{pmatrix}$$\n现在，我们求 $H B H^T$：\n$$H B H^T = 1.44 \\begin{pmatrix} 0.52  0 \\\\ 0  0.58 \\end{pmatrix} = \\begin{pmatrix} 1.44 \\times 0.52  0 \\\\ 0  1.44 \\times 0.58 \\end{pmatrix} = \\begin{pmatrix} 0.7488  0 \\\\ 0  0.8352 \\end{pmatrix}$$\n接下来，我们计算需要求逆的矩阵 $H B H^T + R$：\n$$H B H^T + R = \\begin{pmatrix} 0.7488  0 \\\\ 0  0.8352 \\end{pmatrix} + \\begin{pmatrix} 0.04  0 \\\\ 0  0.09 \\end{pmatrix} = \\begin{pmatrix} 0.7888  0 \\\\ 0  0.9252 \\end{pmatrix}$$\n由于该矩阵是对角矩阵，其逆矩阵很容易计算：\n$$(H B H^T + R)^{-1} = \\begin{pmatrix} \\frac{1}{0.7888}  0 \\\\ 0  \\frac{1}{0.9252} \\end{pmatrix}$$\n最后，我们计算 $S$：\n$$S = (H B H^T) (H B H^T + R)^{-1} = \\begin{pmatrix} 0.7488  0 \\\\ 0  0.8352 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{0.7888}  0 \\\\ 0  \\frac{1}{0.9252} \\end{pmatrix}$$\n$$S = \\begin{pmatrix} \\frac{0.7488}{0.7888}  0 \\\\ 0  \\frac{0.8352}{0.9252} \\end{pmatrix}$$\n问题要求计算 $S$ 的 $(1,1)$ 元素，即 $S_{11}$：\n$$S_{11} = \\frac{0.7488}{0.7888} \\approx 0.949289934...$$\n将此值四舍五入到四位有效数字，得到 $0.9493$。\n元素 $S_{11}$ 表示来自第一个观测的新息被投影回第一个观测位置的分析场上的比例。一个接近 $1$ 的值意味着与观测相比，背景的误差相对较大，因此该位置的分析非常信任观测值。",
            "answer": "$$\\boxed{0.9493}$$"
        }
    ]
}