{
    "hands_on_practices": [
        {
            "introduction": "在许多物理和工程应用中，我们通常将测量误差理想化为连续时间的高斯白噪声。然而，实际的测量总是在有限的时间区间内进行平均或积分得到的。本练习旨在揭示理论模型与实际测量之间的重要联系，通过严格推导，您将理解为何对白噪声进行时间平均会导致测量方差与平均时长成反比，这是一个在信号处理和数据同化中至关重要的基本原理。",
            "id": "3402401",
            "problem": "考虑一个连续时间测量误差模型，其中加性误差过程被理想化为均值为$0$的高斯白噪声。具体来说，设 $\\varepsilon(t)$ 表示一个均值为$0$的过程，其协方差分布为 $\\mathbb{E}[\\varepsilon(t)\\varepsilon(s)] = \\sigma^{2}\\delta(t-s)$，其中 $\\delta(\\cdot)$ 是狄拉克δ分布，$\\sigma^{2} > 0$ 是一个常数噪声强度参数。假设通过对固定宽度 $\\Delta > 0$ 的不相交时间区间 $I_{i} = [t_{i}, t_{i} + \\Delta)$ 上的误差进行平均来收集测量值，得到区间平均误差\n$$\n\\bar{y}_{i} = \\frac{1}{\\Delta}\\int_{I_{i}} \\varepsilon(t)\\,dt.\n$$\n仅从方差和协方差的定义以及狄拉克δ分布的定义性质出发，推导 $\\mathrm{Var}(\\bar{y}_{i})$ 作为 $\\sigma^{2}$ 和 $\\Delta$ 函数的精确表达式。此外，请基于原理对这种对 $\\Delta$ 的依赖性是如何以及为何源于过程的协方差结构进行解释。用封闭形式的解析表达式表示你的最终答案。不需要数值近似或四舍五入。",
            "solution": "所述问题具有科学依据，是适定的、客观的且内部一致的。它提出了一个随机过程研究中的标准理论练习，特别是关于时间平均高斯白噪声的性质。所有必要的定义和参数都已给出，以获得唯一且有意义的解。因此，我们可以进行推导。\n\n问题要求推导 $\\mathrm{Var}(\\bar{y}_{i})$，其中区间平均误差 $\\bar{y}_{i}$ 定义为：\n$$\n\\bar{y}_{i} = \\frac{1}{\\Delta}\\int_{I_{i}} \\varepsilon(t)\\,dt = \\frac{1}{\\Delta}\\int_{t_{i}}^{t_{i} + \\Delta} \\varepsilon(t)\\,dt\n$$\n误差过程 $\\varepsilon(t)$ 被指定为均值为$0$的高斯白噪声过程，其特征由其一阶矩和二阶矩决定：\n$$\n\\mathbb{E}[\\varepsilon(t)] = 0\n$$\n$$\n\\mathbb{E}[\\varepsilon(t)\\varepsilon(s)] = \\sigma^{2}\\delta(t-s)\n$$\n其中 $\\mathbb{E}[\\cdot]$ 表示期望算子，$\\sigma^2$ 是常数噪声强度，$\\delta(\\cdot)$ 是狄拉克δ分布。\n\n我们从随机变量 $X$ 的方差的基本定义开始：\n$$\n\\mathrm{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2]\n$$\n首先，我们必须计算 $\\bar{y}_i$ 的期望值。利用期望算子的线性和富比尼定理来交换期望和积分的顺序，我们得到：\n$$\n\\mathbb{E}[\\bar{y}_{i}] = \\mathbb{E}\\left[\\frac{1}{\\Delta}\\int_{t_{i}}^{t_{i} + \\Delta} \\varepsilon(t)\\,dt\\right] = \\frac{1}{\\Delta}\\int_{t_{i}}^{t_{i} + \\Delta} \\mathbb{E}[\\varepsilon(t)]\\,dt\n$$\n由于该过程是均值为$0$的，即对所有 $t$ 都有 $\\mathbb{E}[\\varepsilon(t)] = 0$，所以积分为零：\n$$\n\\mathbb{E}[\\bar{y}_{i}] = \\frac{1}{\\Delta}\\int_{t_{i}}^{t_{i} + \\Delta} 0 \\,dt = 0\n$$\n由于均值为 $0$，方差简化为变量平方的均值：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\mathbb{E}[(\\bar{y}_{i} - 0)^2] = \\mathbb{E}[\\bar{y}_{i}^2]\n$$\n代入 $\\bar{y}_{i}$ 的定义：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\mathbb{E}\\left[\\left(\\frac{1}{\\Delta}\\int_{t_{i}}^{t_{i} + \\Delta} \\varepsilon(t)\\,dt\\right)^2\\right]\n$$\n为清晰起见，我们使用不同的积分变量 $t$ 和 $s$，将积分的平方表示为两个相同积分的乘积：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\frac{1}{\\Delta^2} \\mathbb{E}\\left[\\left(\\int_{t_{i}}^{t_{i} + \\Delta} \\varepsilon(t)\\,dt\\right)\\left(\\int_{t_{i}}^{t_{i} + \\Delta} \\varepsilon(s)\\,ds\\right)\\right]\n$$\n这个积分的乘积可以写成在方形域 $[t_i, t_i+\\Delta) \\times [t_i, t_i+\\Delta)$ 上的二重积分：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\frac{1}{\\Delta^2} \\mathbb{E}\\left[\\int_{t_{i}}^{t_{i} + \\Delta} \\int_{t_{i}}^{t_{i} + \\Delta} \\varepsilon(t)\\varepsilon(s)\\,ds\\,dt\\right]\n$$\n再次，我们交换期望和积分算子：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\frac{1}{\\Delta^2} \\int_{t_{i}}^{t_{i} + \\Delta} \\int_{t_{i}}^{t_{i} + \\Delta} \\mathbb{E}[\\varepsilon(t)\\varepsilon(s)]\\,ds\\,dt\n$$\n现在，我们代入给定的协方差分布 $\\mathbb{E}[\\varepsilon(t)\\varepsilon(s)] = \\sigma^{2}\\delta(t-s)$：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\frac{1}{\\Delta^2} \\int_{t_{i}}^{t_{i} + \\Delta} \\int_{t_{i}}^{t_{i} + \\Delta} \\sigma^{2}\\delta(t-s)\\,ds\\,dt\n$$\n我们计算关于 $s$ 的内层积分。常数 $\\sigma^2$ 可以被提出来。这一步的核心是应用狄拉克δ分布的筛选性质，即对于一个函数 $f(x)$，如果积分区间包含 $c$，则 $\\int f(x)\\delta(x-c)\\,dx = f(c)$。在这里，积分变量是 $s$，函数是 $1$，δ分布的“尖峰”出现在 $s=t$ 处。\n$$\n\\int_{t_{i}}^{t_{i} + \\Delta} \\delta(t-s)\\,ds\n$$\n关于 $t$ 的外层积分范围是从 $t_{i}$ 到 $t_{i} + \\Delta$。对于此范围内的任何 $t$ 值，点 $s=t$ 都位于内层积分的区间 $[t_{i}, t_{i} + \\Delta)$ 内。因此，筛选性质对外部积分域中的每个 $t$ 都适用，内层积分的值为 $1$：\n$$\n\\int_{t_{i}}^{t_{i} + \\Delta} \\delta(t-s)\\,ds = 1 \\quad \\text{for } t \\in [t_{i}, t_{i} + \\Delta)\n$$\n将此结果代回方差的表达式中：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\frac{\\sigma^{2}}{\\Delta^2} \\int_{t_{i}}^{t_{i} + \\Delta} (1)\\,dt\n$$\n剩下的积分很容易计算：\n$$\n\\int_{t_{i}}^{t_{i} + \\Delta} 1\\,dt = [t]_{t_{i}}^{t_{i} + \\Delta} = (t_{i} + \\Delta) - t_{i} = \\Delta\n$$\n最后，我们将各部分组合起来，得到方差的精确表达式：\n$$\n\\mathrm{Var}(\\bar{y}_{i}) = \\frac{\\sigma^2}{\\Delta^2} \\cdot \\Delta = \\frac{\\sigma^2}{\\Delta}\n$$\n方差对平均时间 $\\Delta$ 的依赖性是一种反比关系，$\\mathrm{Var}(\\bar{y}_{i}) \\propto 1/\\Delta$。这直接源于白噪声过程的协方差结构。定义性质 $\\mathbb{E}[\\varepsilon(t)\\varepsilon(s)] = \\sigma^{2}\\delta(t-s)$ 意味着噪声过程在任意两个不同的时间点上是完全不相关的，无论它们有多接近。该过程没有“记忆”。\n\n因此，将过程在一个时间间隔 $\\Delta$ 上平均，类似于计算多个独立同分布随机抽样的样本均值。对于一组 $N$ 个独立的随机变量，其均值的方差以 $1/N$ 的速率减小。在连续时间的情况下，平均窗口的持续时间 $\\Delta$ 扮演着类似于 $N$ 的角色。随着 $\\Delta$ 的增加，我们实际上是在对更多数量的噪声过程的独立波动进行平均。这些波动是随机且不相关的，在更长的时间内倾向于更有效地相互抵消。这导致平均值的方差减小。\n\n$\\delta$-相关性是零相关时间过程的数学理想化。正是这种特定的结构导致了 $1/\\Delta$ 标度律。如果噪声在某个有限时间尺度上是相关的（即“有色”噪声过程），那么时间平均信号的方差随 $\\Delta$ 的减小会更慢，因为在更长的窗口上平均不会按比例引入同样多的新的独立信息。计算形式上证明了这一点：协方差在 $\\Delta \\times \\Delta$ 方形区域上的二重积分仅在 $t=s$ 的无穷细的对角线上非零。因此，积分中的总“功率”与该对角线的长度成线性比例，而该对角线的长度与 $\\Delta$ 成正比。当用平均定义中的 $\\Delta^2$ 因子进行归一化时，积分协方差的这种线性标度关系产生了最终的 $1/\\Delta$ 依赖性。",
            "answer": "$$\\boxed{\\frac{\\sigma^{2}}{\\Delta}}$$"
        },
        {
            "introduction": "从连续信号转向离散事件计数时，例如光子探测或事件发生率的测量，泊松分布成为一个自然的误差模型。然而，泊松模型“方差等于均值”的严格假设在现实数据中常常不成立，导致所谓的“过度离势”或“低度离势”问题。本练习将引导您应用皮尔逊卡方检验来诊断模型失配，并进一步构建准似然框架，这是一种无需指定完整分布即可调整方差模型的强大统计工具。",
            "id": "3402406",
            "problem": "考虑在一数据同化背景中产生的独立计数观测值 $\\{Y_{i}\\}_{i=1}^{n}$，其中一个正向算子将参数向量 $\\theta \\in \\mathbb{R}^{p}$ 映射到预期的探测器强度，而 $Y_{i}$ 的均值由 $\\mu_{i}(\\theta)$ 给出。假设计数数据使用规范对数连接，因此对于已知的协变量 $a_{i} \\in \\mathbb{R}^{p}$，有 $\\mu_{i}(\\theta) = \\exp(a_{i}^{\\top}\\theta)$。其基本依据如下：对于一个泊松测量误差模型，$Y_{i} \\sim \\text{Poisson}(\\mu_{i})$ 相互独立，且 $\\mathbb{E}[Y_{i}] = \\mu_{i}$ 和 $\\operatorname{Var}(Y_{i}) = \\mu_{i}$。\n\n1. 从泊松对数似然及其得分函数出发，利用大样本理论构建一个基于标准化残差的离散度检验。具体来说，推导 Pearson 卡方统计量\n$$\nX^{2} = \\sum_{i=1}^{n} \\frac{(Y_{i}-\\mu_{i})^{2}}{\\mu_{i}},\n$$\n在最大似然估计 (MLE) $\\hat{\\theta}$ 处进行评估，并说明为什么在正确设定的泊松方差下，$X^{2}$ 近似服从自由度为 $n-p$ 的卡方分布，其中 $p$ 是通过最大似然估计 (MLE) 估计的参数数量。解释 $X^{2}/(n-p)$ 与 $1$ 的偏差如何为相对于泊松模型的过度离散或低度离散提供证据。\n\n2. 当离散度不为 $1$ 时，假设一个拟似然框架，其方差模型为 $\\operatorname{Var}(Y_{i}\\,|\\,\\theta) = \\phi\\,\\mu_{i}(\\theta)$，其中 $\\phi > 0$ 是一个标量离散参数。仅使用均值-方差关系和拟似然的定义属性——即拟得分与按 $\\operatorname{Var}(Y_{i})$ 缩放的 $(Y_{i}-\\mu_{i})$ 成正比——来推导：\n   - 当 $\\operatorname{Var}(Y_{i}) = \\phi\\,\\mu_{i}$ 时，在对数连接下 $\\theta$ 的拟得分。\n   - 在相差一个关于 $\\phi$ 的加性常数的意义下，$\\mu_{i}$ 的拟似然。\n   - 在泊松均值模型下，用 $\\phi$ 和期望 Fisher 信息表示的 $\\hat{\\theta}$ 的渐近协方差调整。\n\n3. 现在，考虑 $n = 8$ 个计数和 $p = 3$ 个拟合参数。假设拟合均值（基于正向算子和 MLE $\\hat{\\theta}$）为\n$$\n\\mu = \\big(10.5,\\; 4.8,\\; 7.9,\\; 18.6,\\; 13.2,\\; 3.1,\\; 6.5,\\; 9.7\\big),\n$$\n观测到的计数为\n$$\ny = \\big(12,\\; 5,\\; 8,\\; 20,\\; 15,\\; 3,\\; 7,\\; 9\\big).\n$$\n计算基于 Pearson 的离散度估计量\n$$\n\\hat{\\phi}_{\\text{Pearson}} = \\frac{X^{2}}{n-p}.\n$$\n将你的答案四舍五入到四位有效数字。以一个无单位的实数形式给出你的最终答案。",
            "solution": "该问题被认为是有效的，因为它在科学上基于统计理论（广义线性模型、拟似然），是适定的，有足够的信息得到唯一解，并且陈述客观、没有歧义。\n\n解答将分三部分呈现，对应问题陈述中的三个项目。\n\n第 1 部分：Pearson 卡方统计量的推导与解释\n\n我们从一组 $n$ 个独立计数观测值 $\\{Y_{i}\\}_{i=1}^{n}$ 开始。该模型假设 $Y_{i} \\sim \\text{Poisson}(\\mu_{i})$，其中均值 $\\mu_{i}$ 通过对数连接函数 $\\mu_{i}(\\theta) = \\exp(a_{i}^{\\top}\\theta)$ 与参数向量 $\\theta \\in \\mathbb{R}^{p}$ 相关联。单个观测值的概率质量函数为 $P(Y_i = y_i) = \\frac{\\mu_i^{y_i} \\exp(-\\mu_i)}{y_i!}$。整个数据集 $\\mathbf{y} = (y_1, \\dots, y_n)$ 的对数似然是各个对数似然之和：\n$$\nl(\\theta; \\mathbf{y}) = \\sum_{i=1}^{n} \\left( y_i \\ln(\\mu_i(\\theta)) - \\mu_i(\\theta) - \\ln(y_i!) \\right)\n$$\n得分函数 $\\mathbf{U}(\\theta)$ 是对数似然关于参数 $\\theta_j$（$j=1, \\dots, p$）的一阶偏导数向量：\n$$\nU_j(\\theta) = \\frac{\\partial l}{\\partial \\theta_j} = \\sum_{i=1}^{n} \\frac{\\partial l_i}{\\partial \\mu_i} \\frac{\\partial \\mu_i}{\\partial \\theta_j}\n$$\n我们有 $\\frac{\\partial l_i}{\\partial \\mu_i} = \\frac{y_i}{\\mu_i} - 1 = \\frac{y_i - \\mu_i}{\\mu_i}$。对于对数连接，$\\frac{\\partial \\mu_i}{\\partial \\theta_j} = \\frac{\\partial}{\\partial \\theta_j}\\exp(a_{i}^{\\top}\\theta) = \\exp(a_{i}^{\\top}\\theta) \\cdot a_{ij} = \\mu_i a_{ij}$。\n将这些代入得分方程可得：\n$$\nU_j(\\theta) = \\sum_{i=1}^{n} \\left( \\frac{y_i - \\mu_i}{\\mu_i} \\right) (\\mu_i a_{ij}) = \\sum_{i=1}^{n} (y_i - \\mu_i) a_{ij}\n$$\n最大似然估计 (MLE) $\\hat{\\theta}$ 通过将得分函数设为零来找到，即 $\\mathbf{U}(\\hat{\\theta}) = \\mathbf{0}$。这得到 $p$ 个方程：对于 $j=1, \\dots, p$，有 $\\sum_{i=1}^{n} (Y_i - \\hat{\\mu}_i) a_{ij} = 0$，其中 $\\hat{\\mu}_i = \\mu_i(\\hat{\\theta})$。\n\n观测值 $i$ 的 Pearson 残差定义为原始残差除以观测值的标准差：\n$$\nr_{P,i} = \\frac{Y_i - \\mathbb{E}[Y_i]}{\\sqrt{\\operatorname{Var}(Y_i)}} = \\frac{Y_i - \\mu_i}{\\sqrt{\\mu_i}}\n$$\nPearson 卡方统计量 $X^2$ 是 Pearson 残差的平方和，在 MLE $\\hat{\\mu}_i$ 处进行评估：\n$$\nX^2 = \\sum_{i=1}^{n} \\frac{(Y_i - \\hat{\\mu}_i)^2}{\\hat{\\mu}_i}\n$$\n对于大样本容量 $n$，如果泊松模型设定正确，每一项 $(Y_i - \\mu_i)/\\sqrt{\\mu_i}$ 近似为一个标准正态随机变量。$n$ 个独立标准正态变量的平方和服从自由度为 $n$ 的卡方分布，即 $\\chi^2_n$。然而，均值 $\\mu_i$ 是未知的，并被其估计值 $\\hat{\\mu}_i$ 替代。这些估计值依赖于同一个 $p$ 维参数向量 $\\hat{\\theta}$，该向量是通过满足 $p$ 个线性约束 $\\sum_{i=1}^{n} (Y_i - \\hat{\\mu}_i) a_{ij} = 0$ 获得的。这些对残差的约束减少了系统的有效自由度。根据渐近统计学的一个通用定理（与 Wilks 定理和拟合优度检验相关），估计 $p$ 个参数会使卡方统计量的自由度减少 $p$。因此，在泊松模型正确的原假设下，$X^2$ 近似服从自由度为 $n-p$ 的卡方随机变量：\n$$\nX^2 \\sim \\chi^2_{n-p} \\quad (\\text{近似地})\n$$\n一个 $\\chi^2_k$ 随机变量的期望值为 $k$。因此，如果模型正确，我们期望 $X^2$ 接近 $n-p$。这引出了离散参数估计量的定义：$\\hat{\\phi} = \\frac{X^2}{n-p}$。我们期望 $\\hat{\\phi} \\approx 1$。\n- 如果 $\\hat{\\phi} \\gg 1$，意味着 $X^2 \\gg n-p$。这表明由残差平方捕获的观测变异性远大于泊松模型（其中方差等于均值）的预测。这是**过度离散**的证据。\n- 如果 $\\hat{\\phi} \\ll 1$，意味着 $X^2 \\ll n-p$。这表明观测变异性远小于泊松模型的预测。这是**低度离散**的证据。\n- 如果 $\\hat{\\phi} \\approx 1$，则数据与泊松方差假设一致。\n\n第 2 部分：拟似然框架\n\n我们现在假设一个更一般的方差结构 $\\operatorname{Var}(Y_i) = \\phi \\mu_i(\\theta)$，其中 $\\phi$ 是一个常数离散参数。拟似然方法不要求完整的分布假设，而只依赖于均值和方差结构。\n\n- **$\\theta$ 的拟得分**：$\\theta_j$ 的拟得分函数定义为对所有观测值的求和，其中每一项都与按 $\\operatorname{Var}(Y_i)$ 缩放的 $(Y_i-\\mu_i(\\theta))$ 成正比：\n$$\nU_{Q,j}(\\theta) = \\sum_{i=1}^n \\frac{Y_i - \\mu_i(\\theta)}{\\operatorname{Var}(Y_i)} \\frac{\\partial \\mu_i(\\theta)}{\\partial \\theta_j}\n$$\n代入 $\\operatorname{Var}(Y_i) = \\phi \\mu_i(\\theta)$ 和 $\\frac{\\partial \\mu_i}{\\partial \\theta_j} = \\mu_i a_{ij}$（来自对数连接），我们得到：\n$$\nU_{Q,j}(\\theta) = \\sum_{i=1}^n \\frac{Y_i - \\mu_i(\\theta)}{\\phi \\mu_i(\\theta)} (\\mu_i(\\theta) a_{ij}) = \\frac{1}{\\phi} \\sum_{i=1}^n (Y_i - \\mu_i(\\theta)) a_{ij}\n$$\n这是 $\\theta_j$ 的拟得分。完整的拟得分向量是 $\\mathbf{U}_Q(\\theta) = \\frac{1}{\\phi} \\mathbf{A}^\\top(\\mathbf{Y}-\\boldsymbol{\\mu})$，其中 $\\mathbf{A}$ 是由协变量 $a_i^\\top$ 构成的 $n \\times p$ 矩阵。\n\n- **$\\mu_i$ 的拟似然**：拟似然 $Q(\\mu_i; y_i)$ 是一个函数，其关于 $\\mu_i$ 的导数可以得到该观测值的类得分项：\n$$\n\\frac{\\partial Q(\\mu_i; y_i)}{\\partial \\mu_i} = \\frac{y_i - \\mu_i}{\\operatorname{Var}(Y_i)} = \\frac{y_i - \\mu_i}{\\phi \\mu_i}\n$$\n对 $\\mu_i$ 积分得到拟似然函数（在相差一个加性常数的意义下）：\n$$\nQ(\\mu_i; y_i) = \\int \\frac{y_i - t}{\\phi t} dt = \\frac{1}{\\phi} \\int \\left(\\frac{y_i}{t} - 1\\right) dt = \\frac{1}{\\phi} (y_i \\ln(\\mu_i) - \\mu_i) + \\text{常数}\n$$\n请注意，这恰好是单个观测值的泊松对数似然，按 $1/\\phi$ 进行了缩放。\n\n- **$\\hat{\\theta}$ 的渐近协方差调整**：估计值 $\\hat{\\theta}$ 是通过求解 $\\mathbf{U}_Q(\\hat{\\theta})=\\mathbf{0}$ 得到的。这类 M-估计量的渐近协方差由三明治公式 $\\operatorname{Cov}(\\hat{\\theta}) \\approx \\mathcal{J}^{-1} \\mathcal{K} (\\mathcal{J}^{-1})^\\top$ 给出，其中 $\\mathcal{J} = -\\mathbb{E}\\left[\\frac{\\partial \\mathbf{U}_Q}{\\partial \\theta^\\top}\\right]$ 且 $\\mathcal{K} = \\mathbb{E}[\\mathbf{U}_Q \\mathbf{U}_Q^\\top]$。\n首先，我们计算 $\\mathcal{J}$：\n$$\n\\frac{\\partial \\mathbf{U}_Q}{\\partial \\theta^\\top} = \\frac{1}{\\phi} \\frac{\\partial}{\\partial \\theta^\\top} \\left(\\sum_{i=1}^n(Y_i - \\mu_i) \\mathbf{a}_i\\right) = -\\frac{1}{\\phi} \\sum_{i=1}^n \\mathbf{a}_i \\frac{\\partial \\mu_i}{\\partial \\theta^\\top} = -\\frac{1}{\\phi} \\sum_{i=1}^n \\mathbf{a}_i (\\mu_i \\mathbf{a}_i^\\top) = -\\frac{1}{\\phi} \\mathbf{A}^\\top \\mathbf{D} \\mathbf{A}\n$$\n其中 $\\mathbf{D} = \\operatorname{diag}(\\mu_1, \\dots, \\mu_n)$。所以，$\\mathcal{J} = \\frac{1}{\\phi} \\mathbf{A}^\\top \\mathbf{D} \\mathbf{A}$。\n接下来，我们计算 $\\mathcal{K}$：\n$$\n\\mathcal{K} = \\mathbb{E}[\\mathbf{U}_Q \\mathbf{U}_Q^\\top] = \\mathbb{E}\\left[ \\left(\\frac{1}{\\phi} \\mathbf{A}^\\top(\\mathbf{Y}-\\boldsymbol{\\mu})\\right) \\left(\\frac{1}{\\phi} \\mathbf{A}^\\top(\\mathbf{Y}-\\boldsymbol{\\mu})\\right)^\\top \\right] = \\frac{1}{\\phi^2} \\mathbf{A}^\\top \\mathbb{E}[(\\mathbf{Y}-\\boldsymbol{\\mu})(\\mathbf{Y}-\\boldsymbol{\\mu})^\\top] \\mathbf{A}\n$$\n矩阵 $\\mathbb{E}[(\\mathbf{Y}-\\boldsymbol{\\mu})(\\mathbf{Y}-\\boldsymbol{\\mu})^\\top]$ 是 $\\mathbf{Y}$ 的协方差矩阵，即 $\\operatorname{Cov}(\\mathbf{Y}) = \\operatorname{diag}(\\operatorname{Var}(Y_i)) = \\operatorname{diag}(\\phi \\mu_i) = \\phi\\mathbf{D}$。\n$$\n\\mathcal{K} = \\frac{1}{\\phi^2} \\mathbf{A}^\\top (\\phi\\mathbf{D}) \\mathbf{A} = \\frac{1}{\\phi} \\mathbf{A}^\\top \\mathbf{D} \\mathbf{A}\n$$\n泊松信息矩阵是 $I_P(\\theta) = \\mathbf{A}^\\top \\mathbf{D} \\mathbf{A}$。所以我们有 $\\mathcal{J} = \\frac{1}{\\phi}I_P(\\theta)$ 和 $\\mathcal{K} = \\frac{1}{\\phi}I_P(\\theta)$。\n渐近协方差为：\n$$\n\\operatorname{Cov}(\\hat{\\theta}) \\approx \\left(\\frac{1}{\\phi}I_P(\\theta)\\right)^{-1} \\left(\\frac{1}{\\phi}I_P(\\theta)\\right) \\left(\\frac{1}{\\phi}I_P(\\theta)\\right)^{-1} = \\left(\\phi I_P(\\theta)^{-1}\\right) \\left(\\frac{1}{\\phi}I_P(\\theta)\\right) \\left(\\phi I_P(\\theta)^{-1}\\right) = \\phi I_P(\\theta)^{-1}\n$$\n调整在于，来自泊松模型的朴素渐近协方差 $I_P(\\theta)^{-1}$ 被离散参数 $\\phi$ 缩放。\n\n第 3 部分：数值计算\n\n给定 $n=8$ 个计数，$p=3$ 个参数，拟合均值 $\\boldsymbol{\\mu}$，以及观测计数 $\\mathbf{y}$。我们被要求计算基于 Pearson 的离散度估计量，$\\hat{\\phi}_{\\text{Pearson}} = \\frac{X^2}{n-p}$。\n拟合均值为 $\\boldsymbol{\\mu} = (10.5, 4.8, 7.9, 18.6, 13.2, 3.1, 6.5, 9.7)$。\n观测计数为 $\\mathbf{y} = (12, 5, 8, 20, 15, 3, 7, 9)$。\n自由度为 $n-p = 8-3=5$。\n\n首先，我们计算 Pearson 卡方统计量 $X^2 = \\sum_{i=1}^n \\frac{(y_i - \\mu_i)^2}{\\mu_i}$。\n\\begin{align*}\nX^2 = \\frac{(12-10.5)^2}{10.5} + \\frac{(5-4.8)^2}{4.8} + \\frac{(8-7.9)^2}{7.9} + \\frac{(20-18.6)^2}{18.6} \\\\\n\\quad + \\frac{(15-13.2)^2}{13.2} + \\frac{(3-3.1)^2}{3.1} + \\frac{(7-6.5)^2}{6.5} + \\frac{(9-9.7)^2}{9.7} \\\\\n= \\frac{1.5^2}{10.5} + \\frac{0.2^2}{4.8} + \\frac{0.1^2}{7.9} + \\frac{1.4^2}{18.6} + \\frac{1.8^2}{13.2} + \\frac{(-0.1)^2}{3.1} + \\frac{0.5^2}{6.5} + \\frac{(-0.7)^2}{9.7} \\\\\n= \\frac{2.25}{10.5} + \\frac{0.04}{4.8} + \\frac{0.01}{7.9} + \\frac{1.96}{18.6} + \\frac{3.24}{13.2} + \\frac{0.01}{3.1} + \\frac{0.25}{6.5} + \\frac{0.49}{9.7} \\\\\n\\approx 0.21428571 + 0.00833333 + 0.00126582 + 0.10537634 + 0.24545455 + 0.00322581 + 0.03846154 + 0.05051546 \\\\\n\\approx 0.66691856\n\\end{align*}\n现在，我们计算离散度估计量：\n$$\n\\hat{\\phi}_{\\text{Pearson}} = \\frac{X^2}{n-p} = \\frac{0.66691856}{5} \\approx 0.13338371\n$$\n四舍五入到四位有效数字，我们得到 $0.1334$。",
            "answer": "$$\\boxed{0.1334}$$"
        },
        {
            "introduction": "在数据同化和反演问题中，选择正确的误差模型至关重要。但是，如果我们有意或无意地使用了错误的模型，会带来什么后果？本练习通过一个经典案例——用高斯模型处理泊松数据——来量化这种模型误设的代价。您将推导并使用在模型误设下仍然稳健的“三明治”方差估计量（Godambe信息），并将其与正确模型下的方差进行比较，从而精确计算出因模型选择不当而导致的估计效率损失。",
            "id": "3402423",
            "problem": "考虑一个单参数线性逆问题，其中，一个未知的标量参数 $\\theta_{0} \\in (0,\\infty)$ 通过一个已知的非负设计序列 $\\{a_{i}\\}_{i=1}^{n}$ 进行观测，其中对所有 $i$ 都有 $a_{i} > 0$。真实的数据生成机制产生独立的计数 $Y_{i}$，其中 $Y_{i} \\sim \\text{Poisson}(a_{i}\\,\\theta_{0})$。然而，一个数据同化算法错误地假设了一个高斯白噪声模型，该模型具有已知的恒定方差 $\\tau^{2} \\in (0,\\infty)$ 和均值 $a_{i}\\,\\theta$，即 $Y_{i} \\stackrel{\\text{model}}{\\sim} \\mathcal{N}(a_{i}\\,\\theta,\\tau^{2})$，并使用此高斯模型下的最大似然估计量来估计 $\\theta$。\n\n从得分函数、其协方差以及对数似然的负海森矩阵期望的核心定义出发，推导在该模型设定错误的情况下 $\\theta$ 的 Godambe（三明治）信息，并求出高斯伪最大似然估计量的相应大样本渐近方差。然后，从正确设定的泊松模型的费雪信息出发，求出泊松最大似然估计量的大样本渐近方差。最后，通过给出错误设定模型的渐近方差与正确设定模型的渐近方差之比，来量化方差膨胀。\n\n请将您的最终答案表示为仅含 $\\{a_{i}\\}_{i=1}^{n}$ 的单个闭式解析表达式。无需进行数值计算，也无需四舍五入。最终答案必须是单个表达式，而非不等式或方程。",
            "solution": "用户希望在一个简单的单参数估计问题中分析模型设定错误的影响。\n\n### 步骤 1：提取已知条件\n-   **真实数据生成模型**：观测值 $Y_i$（其中 $i=1, \\dots, n$）是独立的随机变量，且 $Y_i \\sim \\text{Poisson}(a_i \\theta_0)$。\n-   **真实参数**：$\\theta_0 \\in (0, \\infty)$ 是未知的标量参数。\n-   **设计序列**：$\\{a_i\\}_{i=1}^n$ 是一个已知的正常数序列，$a_i > 0$。\n-   **假设（错误设定）的模型**：数据同化算法假设 $Y_i \\stackrel{\\text{model}}{\\sim} \\mathcal{N}(a_i \\theta, \\tau^2)$，即一个均值为 $a_i \\theta$、已知恒定方差为 $\\tau^2 \\in (0, \\infty)$ 的高斯模型。\n-   **错误设定下的估计量**：从假设的高斯模型中推导出伪最大似然估计量（pseudo-MLE）。\n-   **正确设定下的估计量**：从真实的泊松模型中推导出最大似然估计量（MLE）。\n-   **目标 1**：使用 Godambe（三明治）信息形式，推导高斯伪最大似然估计量的大样本渐近方差。\n-   **目标 2**：使用费雪信息，推导泊松最大似然估计量的大样本渐近方差。\n-   **目标 3**：计算错误设定模型的方差与正确设定模型的方差之比，并仅用 $\\{a_i\\}_{i=1}^n$ 表示。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在科学上和数学上都是合理的。这是统计理论中的一个标准练习，具体涉及 M-估计量和模型设定错误的后果。泊松分布、高斯分布、最大似然估计、伪最大似然、费雪信息和 Godambe（三明治）信息等概念都是统计学中成熟的支柱。该问题表述清晰，提供了推导所需量所需的所有信息。语言精确客观。整个设定是自洽的，没有矛盾或不科学的前提。\n\n### 步骤 3：结论与行动\n该问题有效。将提供一个完整的、有理有据的解答。\n\n### 解题推导\n\n解答过程分为三部分。首先，我们分析来自错误设定的高斯模型的伪最大似然估计量。其次，我们分析来自正确设定的泊松模型的最大似然估计量。第三，我们计算它们的渐近方差之比。术语“大样本渐近方差”将被解释为估计量的精确有限样本方差，因为对于这两个估计量，该量是易于处理的，并且其比率等同于由中心极限定理得出的渐近方差的比率。\n\n**第 1 部分：高斯伪最大似然估计量的渐近方差**\n\n假设的模型是 $Y_i \\sim \\mathcal{N}(a_i\\theta, \\tau^2)$。在此错误设定的模型下，对数似然函数 $\\ell_n(\\theta; \\mathbf{Y})$ 为：\n$$ \\ell_n(\\theta; \\mathbf{Y}) = \\sum_{i=1}^{n} \\log\\left( \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left( -\\frac{(Y_i - a_i\\theta)^2}{2\\tau^2} \\right) \\right) $$\n$$ \\ell_n(\\theta; \\mathbf{Y}) = -\\frac{n}{2}\\ln(2\\pi\\tau^2) - \\frac{1}{2\\tau^2} \\sum_{i=1}^{n} (Y_i - a_i\\theta)^2 $$\n得分函数 $S_n(\\theta)$ 是 $\\ell_n(\\theta; \\mathbf{Y})$ 关于 $\\theta$ 的导数：\n$$ S_n(\\theta) = \\frac{\\partial \\ell_n}{\\partial \\theta} = -\\frac{1}{2\\tau^2} \\sum_{i=1}^{n} 2(Y_i - a_i\\theta)(-a_i) = \\frac{1}{\\tau^2} \\sum_{i=1}^{n} a_i(Y_i - a_i\\theta) $$\n通过令 $S_n(\\hat{\\theta}_G) = 0$ 可以求得伪最大似然估计量（记为 $\\hat{\\theta}_G$）：\n$$ \\frac{1}{\\tau^2} \\sum_{i=1}^{n} a_i(Y_i - a_i\\hat{\\theta}_G) = 0 \\implies \\sum_{i=1}^{n} a_i Y_i - \\hat{\\theta}_G \\sum_{i=1}^{n} a_i^2 = 0 $$\n$$ \\hat{\\theta}_G = \\frac{\\sum_{i=1}^{n} a_i Y_i}{\\sum_{i=1}^{n} a_i^2} $$\n伪最大似然估计量的渐近方差由“三明治”公式 $J_n(\\theta_0)^{-1} I_n(\\theta_0) J_n(\\theta_0)^{-1}$ 给出，其中 $J_n(\\theta_0) = -E_{\\theta_0}\\left[\\frac{\\partial^2 \\ell_n}{\\partial \\theta^2}\\right]_{\\theta=\\theta_0}$ 且 $I_n(\\theta_0) = \\text{Var}_{\\theta_0}[S_n(\\theta_0)]$。期望和方差是在真实数据生成过程下计算的，即 $Y_i \\sim \\text{Poisson}(a_i\\theta_0)$。\n\n首先，我们求 $J_n(\\theta_0)$：\n$$ \\frac{\\partial^2 \\ell_n}{\\partial \\theta^2} = \\frac{\\partial S_n(\\theta)}{\\partial \\theta} = \\frac{1}{\\tau^2} \\sum_{i=1}^{n} a_i(-a_i) = -\\frac{1}{\\tau^2} \\sum_{i=1}^{n} a_i^2 $$\n由于该表达式不依赖于数据 $Y_i$ 或 $\\theta$，其期望是平凡的：\n$$ J_n(\\theta_0) = - \\left( -\\frac{1}{\\tau^2} \\sum_{i=1}^{n} a_i^2 \\right) = \\frac{1}{\\tau^2} \\sum_{i=1}^{n} a_i^2 $$\n接下来，我们求 $I_n(\\theta_0)$，即在真实参数 $\\theta_0$ 处求值的得分函数的方差：\n$$ I_n(\\theta_0) = \\text{Var}_{\\theta_0}[S_n(\\theta_0)] = \\text{Var}_{\\theta_0}\\left[\\frac{1}{\\tau^2} \\sum_{i=1}^{n} a_i(Y_i - a_i\\theta_0)\\right] $$\n由于 $Y_i$ 是独立的，和的方差等于方差的和：\n$$ I_n(\\theta_0) = \\frac{1}{(\\tau^2)^2} \\sum_{i=1}^{n} \\text{Var}_{\\theta_0}[a_i Y_i] = \\frac{1}{\\tau^4} \\sum_{i=1}^{n} a_i^2 \\text{Var}_{\\theta_0}[Y_i] $$\n在真实的泊松模型下，$\\text{Var}_{\\theta_0}[Y_i] = a_i\\theta_0$。\n$$ I_n(\\theta_0) = \\frac{1}{\\tau^4} \\sum_{i=1}^{n} a_i^2 (a_i\\theta_0) = \\frac{\\theta_0}{\\tau^4} \\sum_{i=1}^{n} a_i^3 $$\n$\\hat{\\theta}_G$ 的大样本渐近方差，记为 $V_G(\\hat{\\theta}_G)$，是：\n$$ V_G(\\hat{\\theta}_G) = J_n(\\theta_0)^{-1} I_n(\\theta_0) J_n(\\theta_0)^{-1} = \\left(\\frac{1}{\\tau^2}\\sum_{i=1}^{n} a_i^2\\right)^{-1} \\left(\\frac{\\theta_0}{\\tau^4}\\sum_{i=1}^{n} a_i^3\\right) \\left(\\frac{1}{\\tau^2}\\sum_{i=1}^{n} a_i^2\\right)^{-1} $$\n$$ V_G(\\hat{\\theta}_G) = \\frac{\\tau^2}{\\sum_{i=1}^{n} a_i^2} \\frac{\\theta_0 \\sum_{i=1}^{n} a_i^3}{\\tau^4} \\frac{\\tau^2}{\\sum_{i=1}^{n} a_i^2} = \\frac{\\theta_0 \\sum_{i=1}^{n} a_i^3}{\\left(\\sum_{i=1}^{n} a_i^2\\right)^2} $$\n对于这个线性估计量，该渐近方差与精确的有限样本方差相同，这可以通过直接计算来验证：$\\text{Var}_{\\theta_0}(\\hat{\\theta}_G) = \\text{Var}_{\\theta_0}\\left(\\frac{\\sum_i a_i Y_i}{\\sum_i a_i^2}\\right) = \\frac{\\sum_i a_i^2 \\text{Var}_{\\theta_0}(Y_i)}{(\\sum_i a_i^2)^2} = \\frac{\\sum_i a_i^2 (a_i\\theta_0)}{(\\sum_i a_i^2)^2} = \\frac{\\theta_0 \\sum_i a_i^3}{(\\sum_i a_i^2)^2}$。\n\n**第 2 部分：泊松最大似然估计量的渐近方差**\n\n真实模型是 $Y_i \\sim \\text{Poisson}(a_i\\theta)$。对数似然函数 $L_n(\\theta; \\mathbf{Y})$ 为：\n$$ L_n(\\theta; \\mathbf{Y}) = \\sum_{i=1}^{n} \\log\\left( \\frac{(a_i\\theta)^{Y_i} e^{-a_i\\theta}}{Y_i!} \\right) = \\sum_{i=1}^{n} (Y_i\\log(a_i) + Y_i\\log(\\theta) - a_i\\theta - \\log(Y_i!)) $$\n得分函数为：\n$$ \\frac{\\partial L_n}{\\partial \\theta} = \\sum_{i=1}^{n} \\left(\\frac{Y_i}{\\theta} - a_i\\right) = \\frac{1}{\\theta}\\sum_{i=1}^{n} Y_i - \\sum_{i=1}^{n} a_i $$\n通过将得分函数设为零，可以求得最大似然估计量（记为 $\\hat{\\theta}_P$）：\n$$ \\frac{1}{\\hat{\\theta}_P}\\sum_{i=1}^{n} Y_i - \\sum_{i=1}^{n} a_i = 0 \\implies \\hat{\\theta}_P = \\frac{\\sum_{i=1}^{n} Y_i}{\\sum_{i=1}^{n} a_i} $$\n最大似然估计量的渐近方差由费雪信息的逆 $I_P(\\theta_0)^{-1}$ 给出。费雪信息为 $I_P(\\theta_0) = -E_{\\theta_0}\\left[\\frac{\\partial^2 L_n}{\\partial \\theta^2}\\right]_{\\theta=\\theta_0}$。\n对数似然的二阶导数为：\n$$ \\frac{\\partial^2 L_n}{\\partial \\theta^2} = -\\frac{1}{\\theta^2}\\sum_{i=1}^{n} Y_i $$\n在真实模型下（其中 $E_{\\theta_0}[Y_i] = a_i\\theta_0$）求期望：\n$$ E_{\\theta_0}\\left[\\frac{\\partial^2 L_n}{\\partial \\theta^2}\\right]_{\\theta=\\theta_0} = E_{\\theta_0}\\left[-\\frac{1}{\\theta_0^2}\\sum_{i=1}^{n} Y_i\\right] = -\\frac{1}{\\theta_0^2}\\sum_{i=1}^{n} E_{\\theta_0}[Y_i] = -\\frac{1}{\\theta_0^2}\\sum_{i=1}^{n} a_i\\theta_0 = -\\frac{1}{\\theta_0}\\sum_{i=1}^{n} a_i $$\n费雪信息为：\n$$ I_P(\\theta_0) = - \\left(-\\frac{1}{\\theta_0}\\sum_{i=1}^{n} a_i\\right) = \\frac{1}{\\theta_0}\\sum_{i=1}^{n} a_i $$\n$\\hat{\\theta}_P$ 的大样本渐近方差，记为 $V_P(\\hat{\\theta}_P)$，是费雪信息的逆：\n$$ V_P(\\hat{\\theta}_P) = [I_P(\\theta_0)]^{-1} = \\left(\\frac{1}{\\theta_0}\\sum_{i=1}^{n} a_i\\right)^{-1} = \\frac{\\theta_0}{\\sum_{i=1}^{n} a_i} $$\n与之前一样，这与 $\\hat{\\theta}_P$ 的精确有限样本方差相同。\n\n**第 3 部分：方差之比（方差膨胀）**\n\n最后一步是计算错误设定模型的方差与正确设定模型的方差之比。该比率量化了因使用不正确的高斯模型而导致的效率损失。\n$$ \\text{比率} = \\frac{V_G(\\hat{\\theta}_G)}{V_P(\\hat{\\theta}_P)} = \\frac{\\frac{\\theta_0 \\sum_{i=1}^{n} a_i^3}{\\left(\\sum_{i=1}^{n} a_i^2\\right)^2}}{\\frac{\\theta_0}{\\sum_{i=1}^{n} a_i}} $$\n真实参数 $\\theta_0$ 被消掉了：\n$$ \\text{比率} = \\frac{\\sum_{i=1}^{n} a_i^3}{\\left(\\sum_{i=1}^{n} a_i^2\\right)^2} \\cdot \\left(\\sum_{i=1}^{n} a_i\\right) = \\frac{\\left(\\sum_{i=1}^{n} a_i\\right) \\left(\\sum_{i=1}^{n} a_i^3\\right)}{\\left(\\sum_{i=1}^{n} a_i^2\\right)^2} $$\n该表达式仅依赖于设计序列 $\\{a_i\\}$，符合要求。根据应用于向量 $(\\sqrt{a_1}, ..., \\sqrt{a_n})$ 和 $(\\sqrt{a_1^3}, ..., \\sqrt{a_n^3})$ 的柯西-施瓦茨不等式，我们有 $\\left(\\sum_{i=1}^n a_i^2\\right)^2 \\le \\left(\\sum_{i=1}^n a_i\\right)\\left(\\sum_{i=1}^n a_i^3\\right)$，这证实了该比率总是大于或等于 1，表示方差的膨胀。",
            "answer": "$$\n\\boxed{\\frac{\\left(\\sum_{i=1}^{n} a_{i}\\right) \\left(\\sum_{i=1}^{n} a_{i}^{3}\\right)}{\\left(\\sum_{i=1}^{n} a_{i}^{2}\\right)^{2}}}\n$$"
        }
    ]
}