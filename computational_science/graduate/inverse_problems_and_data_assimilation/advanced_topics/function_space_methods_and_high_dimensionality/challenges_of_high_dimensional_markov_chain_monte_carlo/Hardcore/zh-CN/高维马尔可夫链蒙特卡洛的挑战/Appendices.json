{
    "hands_on_practices": [
        {
            "introduction": "“维度灾难”是一个众所周知的概念，但它对MCMC效率的量化影响可能很抽象。本练习将引导您完成一次第一性原理的推导，使这一概念具体化。通过为一个典型的高维高斯目标计算有效样本量（ESS）如何随维度$d$扩展，您将对为何简单的MCMC方法在问题规模增大时会遇到困难获得严谨的理解。",
            "id": "3370964",
            "problem": "考虑一个线性高斯数据同化问题，其中离散化状态的后验分布在通过先验预处理和观测算子线性化进行适当的白化后，是一个 $d$ 维标准正态目标 $\\mathcal{N}(0, I_{d})$。您运行一个随机游走 Metropolis (RWM) 马尔可夫链蒙特卡洛 (MCMC) 算法，其高斯提议为 $y = x + \\sigma_{d} \\,\\xi$，其中 $\\xi \\sim \\mathcal{N}(0, I_{d})$ 独立于当前状态 $x$，且提议方差按 $\\sigma_{d}^{2} = \\ell^{2}/d$ 进行缩放，其中 $\\ell  0$ 为一固定值。假设链从平稳状态开始。设 $f(x) = v^{\\top} x$ 是一个标量线性泛函，且 $\\|v\\|_{2} = 1$。\n\n仅使用基本原理和经过充分检验的事实作为出发点，包括：\n- 具有对称提议的 Metropolis-Hastings 接受概率。\n- 在上述缩放条件下，高维 $d$ 的大数定律。\n- 针对独立同分布乘积测度的随机游走 Metropolis 算法的经典扩散极限，在按 $d$ 进行时间重缩放后，对于任何固定坐标或固定单位方向投影，该极限产生一个 Ornstein–Uhlenbeck (OU) 过程。\n- 有效样本量 (ESS) 的定义：对于一个滞后-$k$ 自相关为 $\\rho_{k}$ 的平稳标量时间序列，其积分自相关时间为 $\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_{k}$，而 $n$ 次迭代的有效样本量为 $\\mathrm{ESS}_{n} = n/\\tau_{\\mathrm{int}}$。\n\n从这些基础出发，推导 $f(x)$ 的滞后-$k$ 自相关，然后计算 $\\mathrm{ESS}_{n}$ 作为 $n$、$d$ 和 $\\ell$ 的显式函数。您的推导过程应：\n- 以标准正态累积分布函数 $\\Phi(\\cdot)$ 的形式确定高维接受率。\n- 通过匹配极限中的无穷小漂移和方差，从第一性原理出发确定 OU 极限生成元系数 $g(\\ell)$。\n- 利用该系数获得滞后-$k$ 自相关 $\\rho_{k}$ 的闭式表达式，然后对得到的几何级数求和以计算 $\\tau_{\\mathrm{int}}$。\n- 仅使用 $n$、$d$、$\\ell$、初等函数和 $\\Phi(\\cdot)$，以闭式形式表示最终的 $\\mathrm{ESS}_{n}(d,\\ell)$。\n\n答案形式：为 $\\mathrm{ESS}_{n}(d,\\ell)$ 提供一个单一的闭式解析表达式。无需数值近似或四舍五入。使用标准数学符号，并定义您引入的任何特殊函数。不包括物理单位。假设角度是无量纲的。",
            "solution": "该问题定义严谨、内容自洽，并且在马尔可夫链蒙特卡洛 (MCMC) 方法及其高维扩散极限的既有理论中有坚实的科学基础。所有提供的数据和定义在该领域内都是标准的。问题陈述是有效的。\n\n目标是为一个在随机游走 Metropolis (RWM) 算法下演化的状态的标量线性泛函 $f(x) = v^{\\top} x$ 推导有效样本量 $\\mathrm{ESS}_{n}$。目标分布是 $d$ 维标准正态分布，$\\pi(x) \\propto \\exp(-\\frac{1}{2} x^{\\top}x)$。\n\n步骤 1：高维接受率\nRWM 提议为 $y = x + \\sigma_{d} \\xi$，其中 $\\xi \\sim \\mathcal{N}(0, I_{d})$ 且提议方差为 $\\sigma_{d}^{2} = \\ell^{2}/d$。由于提议分布是对称的，即 $q(y|x) = q(x|y)$，Metropolis-Hastings 接受概率为 $\\alpha(x, y) = \\min\\left(1, \\frac{\\pi(y)}{\\pi(x)}\\right)$。\n\n目标密度之比为：\n$$ \\frac{\\pi(y)}{\\pi(x)} = \\frac{\\exp(-\\frac{1}{2}y^{\\top}y)}{\\exp(-\\frac{1}{2}x^{\\top}x)} = \\exp\\left(-\\frac{1}{2}(y^{\\top}y - x^{\\top}x)\\right) $$\n代入 $y = x + \\sigma_d \\xi$：\n$$ y^{\\top}y = (x + \\sigma_d \\xi)^{\\top}(x + \\sigma_d \\xi) = x^{\\top}x + 2\\sigma_d x^{\\top}\\xi + \\sigma_d^2 \\xi^{\\top}\\xi $$\n因此，指数的参数变为：\n$$ \\log\\left(\\frac{\\pi(y)}{\\pi(x)}\\right) = -\\sigma_d x^{\\top}\\xi - \\frac{1}{2}\\sigma_d^2 \\xi^{\\top}\\xi $$\n我们分析在极限 $d \\rightarrow \\infty$ 时指数中各项的行为。假设链处于平稳状态，因此 $x \\sim \\mathcal{N}(0, I_{d})$。\n第二项是 $\\frac{1}{2}\\sigma_d^2 \\xi^{\\top}\\xi = \\frac{1}{2} \\frac{\\ell^2}{d} \\sum_{i=1}^{d} \\xi_i^2$。根据大数定律，当 $d \\to \\infty$ 时，$\\frac{1}{d}\\sum_{i=1}^{d} \\xi_i^2 \\to \\mathbb{E}[\\xi_1^2] = 1$。该项依概率收敛于 $\\frac{1}{2}\\ell^2$。\n第一项是 $\\sigma_d x^{\\top}\\xi = \\frac{\\ell}{\\sqrt{d}} \\sum_{i=1}^{d} x_i \\xi_i$。由于 $x$ 和 $\\xi$ 是独立的标准正态变量，项 $x_i \\xi_i$ 是独立同分布的，其均值为 $\\mathbb{E}[x_i\\xi_i]=\\mathbb{E}[x_i]\\mathbb{E}[\\xi_i]=0$，方差为 $\\mathrm{Var}(x_i\\xi_i) = \\mathbb{E}[(x_i\\xi_i)^2] - (\\mathbb{E}[x_i\\xi_i])^2 = \\mathbb{E}[x_i^2]\\mathbb{E}[\\xi_i^2] = 1 \\cdot 1 = 1$。根据中心极限定理，和 $\\frac{1}{\\sqrt{d}} \\sum_{i=1}^{d} x_i \\xi_i$ 依分布收敛于一个标准正态变量 $U \\sim \\mathcal{N}(0, 1)$。因此，$\\sigma_d x^{\\top}\\xi$ 依分布收敛于 $\\mathcal{N}(0, \\ell^2)$。令 $Z \\sim \\mathcal{N}(0, \\ell^2)$。\n\n在高维极限中，接受概率变得与具体状态 $x$ 无关，平均接受率 $\\bar{\\alpha}(\\ell)$ 由对数比率的极限分布的期望给出：\n$$ \\bar{\\alpha}(\\ell) = \\mathbb{E}_{Z}\\left[\\min\\left(1, \\exp\\left(-Z - \\frac{\\ell^2}{2}\\right)\\right)\\right] $$\n其中 $Z \\sim \\mathcal{N}(0, \\ell^2)$。令 $Z = \\ell U$，其中 $U \\sim \\mathcal{N}(0, 1)$。令 $\\phi(u)$ 为标准正态概率密度函数 (PDF)。\n$$ \\bar{\\alpha}(\\ell) = \\int_{-\\infty}^{\\infty} \\min\\left(1, \\exp\\left(-\\ell u - \\frac{\\ell^2}{2}\\right)\\right) \\phi(u) du $$\n当项 $\\exp(-\\ell u - \\ell^2/2)$ 的参数为正时，该项大于 $1$，即 $-\\ell u - \\ell^2/2  0$，这意味着 $u  -\\ell/2$。因此我们将积分拆分为：\n$$ \\bar{\\alpha}(\\ell) = \\int_{-\\infty}^{-\\ell/2} 1 \\cdot \\phi(u) du + \\int_{-\\ell/2}^{\\infty} \\exp\\left(-\\ell u - \\frac{\\ell^2}{2}\\right) \\phi(u) du $$\n第一个积分是标准正态累积分布函数 (CDF) $\\Phi(-\\ell/2)$ 的定义。\n对于第二个积分，我们代入 $\\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-u^2/2)$ 并在指数中配方：\n$$ -\\ell u - \\frac{\\ell^2}{2} - \\frac{u^2}{2} = -\\frac{1}{2}(u^2 + 2\\ell u + \\ell^2) = -\\frac{1}{2}(u+\\ell)^2 $$\n第二个积分变为 $\\int_{-\\ell/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{1}{2}(u+\\ell)^2) du$。令 $v=u+\\ell$，则 $dv=du$。积分限从 $u=-\\ell/2 \\to v=\\ell/2$ 和 $u \\to \\infty \\to v \\to \\infty$。\n$$ \\int_{\\ell/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{v^2}{2}\\right) dv = P(V  \\ell/2) = 1 - \\Phi(\\ell/2) $$\n其中 $V \\sim \\mathcal{N}(0, 1)$。由于标准正态分布的对称性，$1 - \\Phi(z) = \\Phi(-z)$，所以这个积分是 $\\Phi(-\\ell/2)$。\n结合两部分，渐近接受率为：\n$$ \\bar{\\alpha}(\\ell) = \\Phi(-\\ell/2) + \\Phi(-\\ell/2) = 2\\Phi(-\\ell/2) $$\n\n步骤 2：Ornstein-Uhlenbeck (OU) 极限与自相关\n问题陈述，在时间重缩放 $t=k/d$ 下，任何固定单位方向投影的过程都收敛到一个 OU 过程。令 $F_t = f(x_{\\lfloor dt \\rfloor}) = v^{\\top}x_{\\lfloor dt \\rfloor}$。由于目标分布 $\\mathcal{N}(0, I_d)$ 是各向同性的且 $\\|v\\|_2=1$，我们可以选择一个坐标系使得 $v = (1, 0, ..., 0)^{\\top}$，因此 $F_t$ 就是状态向量的第一个坐标。\n\n坐标过程的极限随机微分方程 (SDE) 形式为 $dF_t = -\\theta F_t dt + \\sigma dW_t$。该过程的平稳分布是 $\\mathcal{N}(0, \\sigma^2/(2\\theta))$。我们要求它与 $f(x) = v^{\\top}x$ 的平稳分布 $\\mathcal{N}(0, v^{\\top}I_d v) = \\mathcal{N}(0,1)$ 相匹配。因此，我们必须有 $\\sigma^2=2\\theta$。\n\n扩散系数 $\\sigma^2$ 通过计算重缩放的期望平方跳跃距离得到：\n$$ \\sigma^2 = \\lim_{d \\to \\infty} d \\cdot \\mathbb{E}[ (f(x_{k+1}) - f(x_k))^2 | x_k=x ] $$\n变化量为 $f(x_{k+1}) - f(x_k) = v^{\\top}(x_{k+1}-x_k)$。状态更新为 $x_{k+1} = x_k + \\sigma_d \\xi \\cdot \\mathbb{I}(\\text{accept})$，其中 $\\mathbb{I}$ 是接受指示函数。\n$$ \\mathbb{E}[(v^{\\top}(\\sigma_d \\xi \\cdot \\mathbb{I}(\\text{accept})))^2 | x] = \\sigma_d^2 \\mathbb{E}[(v^{\\top}\\xi)^2 \\alpha(x, x+\\sigma_d \\xi) | x] $$\n在极限 $d \\to \\infty$ 下，$\\alpha$ 收敛于常数 $\\bar{\\alpha}(\\ell)$。因此：\n$$ \\sigma^2 \\approx d \\cdot \\sigma_d^2 \\mathbb{E}[(v^{\\top}\\xi)^2] \\bar{\\alpha}(\\ell) = d \\cdot \\frac{\\ell^2}{d} \\cdot \\mathrm{Var}(v^{\\top}\\xi) \\cdot \\bar{\\alpha}(\\ell) $$\n由于 $\\xi \\sim \\mathcal{N}(0, I_d)$ 且 $\\|v\\|_2=1$，$\\mathrm{Var}(v^{\\top}\\xi) = v^{\\top}\\mathrm{Var}(\\xi)v = v^{\\top}I_d v = \\|v\\|_2^2=1$。\n因此，$\\sigma^2 = \\ell^2 \\bar{\\alpha}(\\ell) = 2\\ell^2 \\Phi(-\\ell/2)$。\n根据平稳性条件 $\\sigma^2 = 2\\theta$，漂移系数为 $\\theta = \\frac{1}{2}\\sigma^2 = \\ell^2 \\Phi(-\\ell/2)$。\n这对应于问题隐含框架中的系数 $g(\\ell)$。该 SDE 为 $dF_t = -(\\ell^2 \\Phi(-\\ell/2)) F_t dt + \\sqrt{2\\ell^2 \\Phi(-\\ell/2)} dW_t$。\n\n对于漂移系数为 $\\theta$ 的 OU 过程，其自相关函数为 $\\rho(\\tau) = \\exp(-\\theta \\tau)$。对于离散 MCMC 链，时间滞后 $\\tau$ 对应于 $k/d$ 步。滞后-$k$ 自相关为：\n$$ \\rho_k = \\rho(k/d) = \\exp(-\\theta k/d) = \\exp\\left(-k \\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right) $$\n\n步骤 3：积分自相关时间 ($\\tau_{\\mathrm{int}}$) 与 ESS\n积分自相关时间定义为 $\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_{k}$。该和是一个几何级数。令 $r = \\rho_1 = \\exp\\left(-\\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right)$。\n$$ \\sum_{k=1}^{\\infty} \\rho_k = \\sum_{k=1}^{\\infty} r^k = \\frac{r}{1-r} $$\n将此代入 $\\tau_{\\mathrm{int}}$ 的表达式中：\n$$ \\tau_{\\mathrm{int}} = 1 + 2\\frac{r}{1-r} = \\frac{(1-r) + 2r}{1-r} = \\frac{1+r}{1-r} $$\n代入 $r$ 的表达式：\n$$ \\tau_{\\mathrm{int}} = \\frac{1 + \\exp\\left(-\\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right)}{1 - \\exp\\left(-\\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right)} $$\n该表达式可以用双曲余切函数 $\\coth(z) = \\frac{\\exp(z)+\\exp(-z)}{\\exp(z)-\\exp(-z)} = \\frac{\\exp(2z)+1}{\\exp(2z)-1}$ 来书写。令 $z = \\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}$。则 $\\tau_{\\mathrm{int}} = \\coth(z)$。\n$$ \\tau_{\\mathrm{int}} = \\coth\\left(\\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}\\right) $$\n对于 $n$ 次迭代，有效样本量为 $\\mathrm{ESS}_n = n/\\tau_{\\mathrm{int}}$。\n$$ \\mathrm{ESS}_{n}(d,\\ell) = \\frac{n}{\\coth\\left(\\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}\\right)} = n \\tanh\\left(\\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}\\right) $$\n这提供了 $\\mathrm{ESS}_{n}$ 作为 $n$、$d$ 和 $\\ell$ 的函数的最终闭式表达式，使用了初等函数和标准正态 CDF $\\Phi$。",
            "answer": "$$\n\\boxed{n \\tanh\\left(\\frac{\\ell^{2} \\Phi(-\\ell/2)}{2d}\\right)}\n$$"
        },
        {
            "introduction": "在许多反演问题中，数据仅能告知参数空间的某个低维子空间。这造成了异质的混合速率，可能会欺骗标准的收敛诊断。这项动手编程练习将挑战您构建一个正展现此行为的采样器，并探索由此产生的“假性收敛”。通过在似然信息子空间上实现和分析采样器，您将学会如何在天真地相信诊断可能是危险的高维环境中，批判性地评估收敛性。",
            "id": "3370944",
            "problem": "考虑一个 $d$ 维线性高斯逆问题，其具有高斯先验和高斯观测噪声。设未知参数为 $x \\in \\mathbb{R}^d$，其先验为 $x \\sim \\mathcal{N}(0, I_d)$。设观测值满足 $y = A x + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times d}$ 是一个已知矩阵，$\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$ 是独立的观测噪声。负对数似然为 $\\Phi(x) = \\frac{1}{2 \\sigma^2} \\lVert y - A x \\rVert_2^2$。后验密度与 $\\exp\\left(-\\frac{1}{2}\\lVert x \\rVert_2^2 - \\Phi(x)\\right)$ 成正比。\n\n对于这个具有单位先验协方差的线性问题，似然信息子空间 (LIS) 可以取为对称矩阵 $H = A^\\top \\Gamma^{-1} A$（其中 $\\Gamma = \\sigma^2 I_m$，即 $H = \\frac{1}{\\sigma^2} A^\\top A$）的主特征向量所张成的空间。给定一个阈值 $\\tau  0$，将 LIS 基 $U \\in \\mathbb{R}^{d \\times r}$ 定义为 $H$ 对应于严格大于 $\\tau$ 的特征值的标准正交特征向量矩阵，因此 $r = \\mathrm{rank}_\\tau(H)$ 是高于 $\\tau$ 的特征值的数量。正交补子空间的维度为 $d - r$。\n\n为从后验中抽样，考虑使用 $K$ 条独立的并行马尔可夫链，采用一种分块预处理的 Crank–Nicolson (pCN) 提议，该提议在 LIS 及其正交补上以不同方式混合。设 $P = U U^\\top$ 是到 LIS 上的正交投影算子，$Q = I_d - P$ 是到正交补上的投影算子。对于当前状态 $x \\in \\mathbb{R}^d$，定义提议\n$$\nx' = \\sqrt{1 - \\beta_{\\mathrm{LIS}}^2}\\, P x + \\beta_{\\mathrm{LIS}}\\, \\xi_{\\mathrm{LIS}} \\;+\\; \\sqrt{1 - \\beta_{\\perp}^2}\\, Q x + \\beta_{\\perp}\\, \\xi_{\\perp},\n$$\n其中 $\\xi_{\\mathrm{LIS}} \\sim \\mathcal{N}(0, P)$ 和 $\\xi_{\\perp} \\sim \\mathcal{N}(0, Q)$ 是分别支撑在各自子空间上的独立高斯向量。使用接受概率执行 Metropolis–Hastings 接受/拒绝步骤\n$$\n\\alpha(x, x') = \\min\\left(1, \\exp(-\\Phi(x') + \\Phi(x))\\right),\n$$\n从而使先验不变的提议结合此接受步骤，以该后验为目标分布。\n\n每条链使用 $n_{\\mathrm{tot}}$ 个步骤，并舍弃 $n_{\\mathrm{burn}}$ 个步骤的老化期（burn-in）。用 $\\{x_{j,t}\\}_{t=1}^{n}$（$j=1,\\dots,K$）表示老化期后的样本，其中 $n = n_{\\mathrm{tot}} - n_{\\mathrm{burn}}$。定义 LIS 坐标 $z_{j,t} = U^\\top x_{j,t} \\in \\mathbb{R}^r$ 和正交补坐标 $w_{j,t} = Q_{\\perp}^\\top x_{j,t} \\in \\mathbb{R}^{d-r}$，其中 $Q_{\\perp} \\in \\mathbb{R}^{d \\times (d-r)}$ 是正交补的任意标准正交基，满足 $Q_{\\perp}^\\top U = 0$ 和 $Q_{\\perp}^\\top Q_{\\perp} = I_{d-r}$。\n\n为评估收敛性，对 LIS 坐标使用多元潜在尺度缩减因子（多元 $\\hat{R}$）进行计算，并对正交补坐标逐坐标地计算通常的单变量 $\\hat{R}$。根据 $K$ 组 $n$ 个 $z \\in \\mathbb{R}^r$ 样本的链内协方差和链间协方差构建 LIS 的多元 $\\hat{R}$，并根据 $K$ 组 $n$ 个样本的链内方差和链间方差为 $w \\in \\mathbb{R}^{d-r}$ 的每个坐标构建单变量 $\\hat{R}$。精确地：\n- 对于任何 $p$ 维坐标 $v_{j,t} \\in \\mathbb{R}^p$，为每条链 $j$ 定义样本均值 $\\bar{v}_j = \\frac{1}{n}\\sum_{t=1}^n v_{j,t}$ 和样本协方差 $S_j$（对于 $p=1$，这是标量样本方差），除数为 $n-1$。设 $\\bar{v} = \\frac{1}{K} \\sum_{j=1}^K \\bar{v}_j$。链内协方差为 $W = \\frac{1}{K} \\sum_{j=1}^K S_j$。链间协方差为 $B = n \\cdot \\mathrm{Cov}(\\bar{v}_1,\\dots,\\bar{v}_K)$，其中协方差是基于 $K$ 个链均值计算的；对于 $p=1$，$B = n$ 乘以 $K$ 个链均值的样本方差。\n- 使用这些矩阵形成尺度比较诊断。对于 $p=1$，单变量 $\\hat{R}$ 将一个合并方差估计量与 $W$进行比较。对于 $p1$，定义一个在 $p=1$ 时可退化为单变量情况的多元模拟，该模拟基于从链内到链间的离散度相对扩大。\n\n定义一个停止规则：对于一个阈值 $t  1$，当且仅当 LIS 的多元 $\\hat{R} \\le t$ 时，宣告收敛。如果同时正交补坐标的最大单变量 $\\hat{R}$ 满足 $\\max_{1 \\le k \\le d-r} \\hat{R}_k \\ge 1.1$，则称之为一个伪收敛事件。\n\n您的任务是编写一个完整的、可运行的程序，该程序：\n1. 合成问题，使用给定参数运行 $K$ 链的分块 pCN 采样器，构建 LIS 及其正交补，并从样本（协）方差的第一性原理出发计算上述所需的诊断指标。\n2. 对于下面的每个测试用例和每个阈值 $t \\in \\{1.1, 1.05, 1.01\\}$，返回一个布尔值，指示停止规则是否会产生伪收敛事件。\n\n使用以下测试套件。在所有情况下，生成 $A$，其条目独立分布于 $\\mathcal{N}(0, d^{-1})$，生成一个真实状态 $x^\\star \\sim \\mathcal{N}(0, I_d)$，并生成观测值 $y = A x^\\star + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$。使用 $K=4$ 条链，并从先验 $\\mathcal{N}(0, I_d)$ 中独立设置每条链的初始状态。使用固定的随机种子，以使结果具有确定性。\n\n- 测试用例 1（正交补混合不佳的理想路径）：\n  - 维度 $d = 128$，观测值数量 $m = 48$，噪声标准差 $\\sigma = 1$，LIS 特征阈值 $\\tau = 0.18$。\n  - pCN 步长：$\\beta_{\\mathrm{LIS}} = 0.5$，$\\beta_{\\perp} = 0.02$。\n  - 总步数 $n_{\\mathrm{tot}} = 1200$，老化期 $n_{\\mathrm{burn}} = 300$，因此保留 $n = 900$ 步。\n\n- 测试用例 2（所有方向上混合良好）：\n  - 与测试用例 1 相同的 $d, m, \\sigma, \\tau$。\n  - pCN 步长：$\\beta_{\\mathrm{LIS}} = 0.5$，$\\beta_{\\perp} = 0.5$。\n  - 总步数 $n_{\\mathrm{tot}} = 1200$，老化期 $n_{\\mathrm{burn}} = 300$，因此保留 $n = 900$ 步。\n\n- 测试用例 3（无正交补的边界情况）：\n  - 维度 $d = 32$，观测值数量 $m = 32$，噪声标准差 $\\sigma = 1$，LIS 特征阈值 $\\tau = -0.1$（确保 $r = d$ 几乎必然成立）。\n  - pCN 步长：$\\beta_{\\mathrm{LIS}} = 0.5$，$\\beta_{\\perp} = 0.02$。\n  - 总步数 $n_{\\mathrm{tot}} = 900$，老化期 $n_{\\mathrm{burn}} = 200$，因此保留 $n = 700$ 步。\n\n对于每个测试用例和每个阈值 $t \\in \\{1.1, 1.05, 1.01\\}$（按此顺序），输出一个布尔值，指示是否发生伪收敛事件。将这九个布尔值（三个测试用例各对应三个阈值，按顺序排列）聚合到一个列表中。\n\n最终输出格式：您的程序应生成一行输出，其中包含一个方括号内以逗号分隔的结果列表（例如，\"[true,false,true,false,...]\"）。条目应为小写布尔值（\"true\" 或 \"false\"）。",
            "solution": "用户提供了一个问题陈述，在尝试解决方案之前需要对其进行验证。\n\n### 第 1 步：提取已知信息\n- **问题类型**：$d$ 维线性高斯逆问题。\n- **模型参数**：$x \\in \\mathbb{R}^d$ 是未知参数。\n- **先验分布**：$x \\sim \\mathcal{N}(0, I_d)$，其中 $I_d$ 是 $d \\times d$ 单位矩阵。\n- **观测模型**：$y = A x + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times d}$ 是一个已知矩阵，$\\eta \\in \\mathbb{R}^m$ 是观测噪声。\n- **噪声模型**：$\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，其中 $I_m$ 是 $m \\times m$ 单位矩阵。\n- **负对数似然**：$\\Phi(x) = \\frac{1}{2 \\sigma^2} \\lVert y - A x \\rVert_2^2$。\n- **后验密度**：$\\pi(x|y) \\propto \\exp\\left(-\\frac{1}{2}\\lVert x \\rVert_2^2 - \\Phi(x)\\right)$。\n- **似然信息子空间 (LIS)**：由矩阵 $H = \\frac{1}{\\sigma^2} A^\\top A$ 对应于严格大于阈值 $\\tau  0$ 的特征值的特征向量所张成的空间。该子空间的标准正交基为 $U \\in \\mathbb{R}^{d \\times r}$。\n- **投影算子**：$P = U U^\\top$（到 LIS 上）和 $Q = I_d - P$（到正交补上）。\n- **MCMC 采样器**：一种带 Metropolis-Hastings 校正的分块预处理 Crank–Nicolson (pCN) 算法。\n- **pCN 提议**：$x' = \\sqrt{1 - \\beta_{\\mathrm{LIS}}^2}\\, P x + \\beta_{\\mathrm{LIS}}\\, \\xi_{\\mathrm{LIS}} \\;+\\; \\sqrt{1 - \\beta_{\\perp}^2}\\, Q x + \\beta_{\\perp}\\, \\xi_{\\perp}$。\n- **提议噪声**：$\\xi_{\\mathrm{LIS}} \\sim \\mathcal{N}(0, P)$ 和 $\\xi_{\\perp} \\sim \\mathcal{N}(0, Q)$ 是独立的。\n- **接受概率**：$\\alpha(x, x') = \\min\\left(1, \\exp(-\\Phi(x') + \\Phi(x))\\right)$。\n- **模拟参数**：$K$ 条并行链，每条链总步数为 $n_{\\mathrm{tot}}$，老化期步数为 $n_{\\mathrm{burn}}$。\n- **坐标系**：LIS 坐标 $z_{j,t} = U^\\top x_{j,t} \\in \\mathbb{R}^r$ 和正交补坐标 $w_{j,t} = Q_{\\perp}^\\top x_{j,t} \\in \\mathbb{R}^{d-r}$，其中 $Q_\\perp$ 是补空间的一个标准正交基。\n- **收敛诊断**：用于 LIS 坐标的多元潜在尺度缩减因子 (m$\\hat{R}$) 和用于正交补每个坐标的单变量 $\\hat{R}$。\n- **诊断定义（$p$ 维坐标 $v_{j,t}$）**：\n    - 链内协方差：$W = \\frac{1}{K} \\sum_{j=1}^K S_j$，其中 $S_j$ 是链 $j$ 的样本协方差，除数为 $n-1 = (n_{\\mathrm{tot}}-n_{\\mathrm{burn}})-1$。\n    - 链间协方差：$B = n \\cdot \\mathrm{Cov}(\\bar{v}_1,\\dots,\\bar{v}_K)$，其中 $\\bar{v}_j$ 是链均值。\n- **伪收敛事件**：对于给定的阈值 $t  1$，定义为两个条件同时发生：\n    1. LIS 的多元 $\\hat{R} \\le t$。\n    2. 正交补坐标上的最大单变量 $\\hat{R}$，$\\max_{k} \\hat{R}_k \\ge 1.1$。\n- **数据生成**：$A$ 的条目来自 $\\mathcal{N}(0, d^{-1})$；真实状态 $x^\\star \\sim \\mathcal{N}(0, I_d)$；观测值 $y = A x^\\star + \\eta$；MCMC 链的初始状态从先验 $\\mathcal{N}(0, I_d)$ 中抽取。必须使用固定的随机种子。\n- **测试用例**：提供了三个具体的测试用例，包含参数 $(d, m, \\sigma, \\tau)$、$(\\beta_{\\mathrm{LIS}}, \\beta_{\\perp})$ 和 $(n_{\\mathrm{tot}}, n_{\\mathrm{burn}})$。\n- **任务**：对于每个测试用例和每个阈值 $t \\in \\{1.1, 1.05, 1.01\\}$，确定是否发生伪收敛事件。\n\n### 第 2 步：使用提取的已知信息进行验证\n根据验证标准对问题陈述进行严格审查。\n\n1.  **科学基础**：该问题牢固地植根于贝叶斯逆问题理论和 MCMC 方法。线性高斯模型、pCN 采样器和 LIS 分解是计算统计学和科学计算中标准的、有据可查的技术。收敛诊断（$\\hat{R}$ 及其多元扩展）是评估 MCMC 性能的基础工具。没有违反科学或事实之处。\n2.  **可形式化性**：问题以数学精度进行了规定。从模型到采样器和诊断的所有组件都经过了形式化定义，允许直接和明确的实现。\n3.  **完整性与一致性**：\n    - 问题为每个测试用例提供了所有必要的参数。\n    - 对收敛诊断的定义进行了规定。虽然多元 $\\hat{R}$ 的确切公式是功能性地描述的（“退化为单变量情况...”），但这唯一地指向了文献中的一个标准定义，该定义基于链间和链内协方差矩阵的广义特征值。这不构成致命的模糊性，但要求解决者知道或推导出标准形式，这对于教授级别的专家是合适的。\n    - LIS 定义中有一个微小的不一致，即 $\\tau  0$，但测试用例 3 使用了 $\\tau = -0.1$。然而，问题陈述立即澄清了其意图：“确保 $r=d$ 几乎必然成立”。这解决了不一致性；对非负特征值使用负阈值仅意味着所有维度都包含在 LIS 中。\n    - 在测试用例 3 中，由于 $r = d$，正交补的维度为 0。条件 $\\max_{k} \\hat{R}_k \\ge 1.1$ 必须在一个空集上进行评估。逻辑上，这个条件是假的，因此伪收敛事件是不可能发生的。这不是一个缺陷，而是一个需要由实现来处理的明确定义的边界情况。\n4.  **现实性与可行性**：该问题虽然是一个合成基准，但使用的参数值和维度在计算上是可行的，并且代表了在实际应用中遇到的挑战。\n5.  **适定性**：如上所述，对多元 $\\hat{R}$ 的标准解释以及对测试用例 3 中边界情况的逻辑处理使问题成为适定的，承认一个唯一且有意义的解。\n6.  **琐碎性**：该问题非同小可，需要实现一个完整的 MCMC 模拟和分析流程，包括数值线性代数和统计计算。所测试的核心概念——子空间相关的收敛率导致误导性诊断——是 MCMC 理论中的一个复杂主题。\n7.  **可验证性**：要求使用固定的随机种子确保了整个模拟是确定性的，其结果是完全可验证和可复现的。\n\n### 第 3 步：结论与行动\n该问题被判定为**有效**。它规范良好，科学上合理，并且计算上可行。微小的模糊之处可以通过该领域的标准解释来解决。我现在将继续进行解决方案。\n\n### 解决方案设计与原则\n\n该解决方案涉及模拟一个贝叶斯推断过程并分析其收敛特性。其核心思想是展示一个采样器在观察特定“重要”子空间（LIS）时可能看起来已经收敛，而在互补的“不重要”子空间中混合仍然很差。这可能导致过早地宣告收敛，问题中称之为“伪收敛事件”。\n\n**1. 后验与采样器**\n后验分布是多元高斯分布。pCN 采样器非常适合此问题，因为其提议是从先验分布中生成的。这一特性，被称为“先验可逆性”，将 Metropolis-Hastings 接受率简化为仅依赖于似然，如 $\\alpha(x, x') = \\min(1, \\exp(-\\Phi(x') + \\Phi(x)))$ 所示。提议的分块性质允许在 LIS 及其补空间中使用不同的步长（$\\beta_{\\mathrm{LIS}}$, $\\beta_{\\perp}$），使我们能够模拟差异化混合率的情景。\n\n**2. 子空间分解**\n似然信息子空间由矩阵 $H = \\frac{1}{\\sigma^2} A^\\top A$ 的特征向量构建。该矩阵与后验精度（协方差的逆）的数据信息部分有关。其主导特征向量对应于参数空间中受数据 $y$ 信息最强的方向。算法将使用 `scipy.linalg.eigh` 对对称矩阵 $H$ 进行稳定高效的特征分解。特征值大于 $\\tau$ 的特征向量将构成 LIS 的基 $U$，其余特征向量将构成其正交补的基 $Q_\\perp$。\n\n**3. 收敛诊断 (PSRF)**\n潜在尺度缩减因子 $\\hat{R}$ 是一种比较并行链内部方差与链间方差的诊断工具。如果链已收敛到平稳分布，这些方差应相似，$\\hat{R}$ 将接近 1。\n\n- **单变量 $\\hat{R}_k$**：对于正交补空间的每个坐标 $k$，我们计算标准的 Gelman-Rubin 诊断。对于 $n$ 个样本和 $K$ 条链，其平方值为：\n$$\n\\hat{R}_k^2 = \\frac{\\widehat{\\mathrm{Var}}_k}{W_k} = \\frac{\\frac{n-1}{n}W_k + \\frac{1}{n}B_k}{W_k} = \\frac{n-1}{n} + \\frac{B_k}{n W_k}\n$$\n其中 $W_k$ 是平均链内方差，$B_k$ 是坐标 $k$ 的链间方差的 $n$ 倍。\n\n- **多元 $\\hat{R}$**：对于 $r$ 维 LIS 坐标，需要一个多元泛化。遵循它应退化为单变量情况并代表最大相对方差膨胀的原则，我们基于涉及链内 ($W_z$) 和链间 ($B_z$) 协方差矩阵的广义特征值问题来定义它：\n$$\n(\\text{m}\\hat{R})^2 = \\frac{n-1}{n} + \\frac{1}{n} \\lambda_{\\max}(W_z^{-1} B_z)\n$$\n其中 $\\lambda_{\\max}(W_z^{-1} B_z)$ 是 $W_z^{-1} B_z$ 的最大特征值。这通过求解广义特征值问题 $B_z v = \\lambda W_z v$ 来实现，以避免矩阵求逆。\n\n**4. 实现策略**\n将开发一个 Python 脚本来执行完整的模拟和分析流程。\n- 一个主函数将管理测试用例并整理结果。\n- 一个核心函数将处理单个测试用例的模拟：生成数据、执行 LIS 分解、运行 $K$ 条 MCMC 链并存储样本。\n- 辅助函数将根据 MCMC 样本计算多元和单变量 $\\hat{R}$ 值，封装统计公式。\n- 对于测试用例 3，其中正交补的维度为零，最大单变量 $\\hat{R}$ 被认为不满足 $\\ge 1.1$ 的条件，正确地产生没有伪收敛的情况。\n- 所有随机过程都将使用种子以确保确定性输出。最终结果将格式化为小写布尔值的列表。\n\n这种系统化方法确保了正确性、对问题规范的遵守以及与 MCMC 诊断既定科学原则的一致性。",
            "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef _compute_mle_r_hat(samples, n, K):\n    \"\"\"\n    Computes the multivariate potential scale reduction factor (m-R-hat).\n    \n    Args:\n        samples (np.ndarray): MCMC samples of shape (K, n, p).\n        n (int): Number of post-burn-in samples.\n        K (int): Number of chains.\n        \n    Returns:\n        float: The multivariate R-hat value.\n    \"\"\"\n    p = samples.shape[2]\n    if p == 0:\n        return 1.0\n\n    # Chain means (shape K, p)\n    chain_means = np.mean(samples, axis=1)\n\n    # Within-chain covariance matrix W (shape p, p)\n    # S_j variable is not explicitly needed, can compute W directly\n    W = np.zeros((p, p))\n    for j in range(K):\n        # np.cov expects (p, n)\n        W += np.cov(samples[j, :, :], rowvar=False, ddof=1)\n    W /= K\n\n    # Check for singularity of W\n    if np.linalg.cond(W)  1e12:\n        return np.inf\n\n    # Between-chain covariance matrix B (shape p, p)\n    B = n * np.cov(chain_means, rowvar=False, ddof=1)\n    \n    # Generalized eigenvalue problem: B v = lambda W v\n    # This is more stable than computing inv(W) @ B\n    try:\n        eigvals = scipy.linalg.eig(B, W, right=True, left=False)\n        # We need the largest real part of the eigenvalues\n        lambda_max = np.max(np.real(eigvals))\n    except (np.linalg.LinAlgError, ValueError):\n        return np.inf\n\n    # Multivariate R-hat squared\n    mR_hat_sq = (n - 1) / n + lambda_max / n\n    \n    if mR_hat_sq  0: # Should not happen with well-behaved chains\n        return np.inf\n        \n    return np.sqrt(mR_hat_sq)\n\ndef _compute_uni_r_hats_max(samples, n, K):\n    \"\"\"\n    Computes the maximum of univariate R-hats over all given dimensions.\n    \n    Args:\n        samples (np.ndarray): MCMC samples of shape (K, n, p).\n        n (int): Number of post-burn-in samples.\n        K (int): Number of chains.\n        \n    Returns:\n        float: The maximum R-hat value, or -inf if p=0.\n    \"\"\"\n    d_perp = samples.shape[2]\n    if d_perp == 0:\n        return -np.inf\n\n    max_r_hat = 0.0\n    for k in range(d_perp):\n        samples_1d = samples[:, :, k]  # Shape (K, n)\n        \n        # Within-chain variances\n        within_chain_vars = np.var(samples_1d, axis=1, ddof=1)\n        W = np.mean(within_chain_vars)\n\n        # Between-chain variance\n        chain_means = np.mean(samples_1d, axis=1)\n        B = n * np.var(chain_means, ddof=1)\n\n        if W  1e-20:\n             # Chains are stuck, if at different points, R-hat is infinite\n            r_hat = 1.0 if B  1e-20 else np.inf\n        else:\n            r_hat_sq = (n - 1) / n + B / (n * W)\n            r_hat = np.sqrt(r_hat_sq)\n        \n        if r_hat  max_r_hat:\n            max_r_hat = r_hat\n            \n    return max_r_hat\n\ndef run_single_case(d, m, sigma, tau, beta_lis, beta_perp, n_tot, n_burn, K, rng):\n    \"\"\"\n    Runs one full test case simulation and analysis.\n    \"\"\"\n    n = n_tot - n_burn\n    \n    # 1. Synthesize problem\n    A = rng.normal(loc=0.0, scale=1.0/np.sqrt(d), size=(m, d))\n    x_star = rng.normal(loc=0.0, scale=1.0, size=d)\n    eta = rng.normal(loc=0.0, scale=sigma, size=m)\n    y = A @ x_star + eta\n\n    # 2. LIS decomposition\n    H = (1 / sigma**2) * (A.T @ A)\n    eigvals, eigvecs = scipy.linalg.eigh(H)\n    \n    lis_indices = eigvals  tau\n    r = np.sum(lis_indices)\n    U = eigvecs[:, lis_indices]\n    Q_perp = eigvecs[:, ~lis_indices]\n    d_perp = d - r\n\n    # 3. Run MCMC chains\n    x_chains = rng.normal(loc=0.0, scale=1.0, size=(K, d))\n    all_samples = np.zeros((K, n_tot, d))\n    \n    def neg_log_likelihood(x_vec):\n        return (0.5 / sigma**2) * np.linalg.norm(y - A @ x_vec)**2\n\n    for j in range(K):\n        x_current = x_chains[j]\n        phi_current = neg_log_likelihood(x_current)\n        for t in range(n_tot):\n            z_current = U.T @ x_current\n            w_current = Q_perp.T @ x_current\n\n            xi_z = rng.standard_normal(size=r)\n            xi_w = rng.standard_normal(size=d_perp)\n            \n            z_prop = np.sqrt(1 - beta_lis**2) * z_current + beta_lis * xi_z\n            w_prop = np.sqrt(1 - beta_perp**2) * w_current + beta_perp * xi_w\n            \n            x_prop = U @ z_prop + Q_perp @ w_prop\n            \n            phi_prop = neg_log_likelihood(x_prop)\n            \n            log_alpha = phi_current - phi_prop\n            \n            if np.log(rng.uniform())  log_alpha:\n                x_current = x_prop\n                phi_current = phi_prop\n\n            all_samples[j, t, :] = x_current\n\n    # 4. Compute diagnostics\n    post_burn_samples = all_samples[:, n_burn:, :]\n    \n    z_samples = post_burn_samples @ U\n    w_samples = post_burn_samples @ Q_perp\n    \n    mR_hat_lis = _compute_mle_r_hat(z_samples, n, K)\n    max_R_hat_perp = _compute_uni_r_hats_max(w_samples, n, K)\n    \n    return mR_hat_lis, max_R_hat_perp\n\n\ndef solve():\n    # Use a fixed random seed for reproducibility\n    rng = np.random.default_rng(42)\n    \n    # Fixed parameters\n    K = 4\n    \n    test_cases = [\n        # TC 1: Poor mixing in orthogonal complement\n        dict(d=128, m=48, sigma=1.0, tau=0.18, \n             beta_lis=0.5, beta_perp=0.02, \n             n_tot=1200, n_burn=300),\n        # TC 2: Good mixing everywhere\n        dict(d=128, m=48, sigma=1.0, tau=0.18,\n             beta_lis=0.5, beta_perp=0.5,\n             n_tot=1200, n_burn=300),\n        # TC 3: No orthogonal complement\n        dict(d=32, m=32, sigma=1.0, tau=-0.1,\n             beta_lis=0.5, beta_perp=0.02,\n             n_tot=900, n_burn=200),\n    ]\n\n    thresholds = [1.1, 1.05, 1.01]\n    results = []\n\n    for case_params in test_cases:\n        mR_hat_lis, max_R_hat_perp = run_single_case(**case_params, K=K, rng=rng)\n        \n        for t in thresholds:\n            converged_lis = mR_hat_lis = t\n            unconverged_perp = max_R_hat_perp = 1.1\n            \n            is_false_convergence = converged_lis and unconverged_perp\n            results.append(is_false_convergence)\n\n    # Format output as a list of lowercase boolean strings\n    output_str = f\"[{','.join(map(lambda b: str(b).lower(), results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}