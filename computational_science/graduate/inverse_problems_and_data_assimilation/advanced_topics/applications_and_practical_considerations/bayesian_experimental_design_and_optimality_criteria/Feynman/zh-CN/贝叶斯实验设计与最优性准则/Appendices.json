{
    "hands_on_practices": [
        {
            "introduction": "本次练习将探讨实验设计中的一个基本困境：是重复相同的测量以降低噪声，还是尝试不同的测量以获得新类型的信息？通过计算两种情况下的预期信息增益，您将为“为何多样化测量对于有效学习多个未知参数至关重要”建立起定量的直觉。这个问题提供了一个清晰具体的切入点，帮助您理解如何使用互信息作为设计准则。",
            "id": "3367120",
            "problem": "考虑一个线性逆问题，其参数向量为二维向量 $\\theta \\in \\mathbb{R}^{2}$，用高斯先验 $p(\\theta) = \\mathcal{N}(0,\\Sigma_{0})$ 建模，其中 $\\Sigma_{0} = \\operatorname{diag}(\\alpha,\\beta)$。您可以进行 $N$ 次实验，每次实验产生一个标量观测值，其模型为 $y = X \\theta + \\varepsilon$，其中 $X \\in \\mathbb{R}^{N \\times 2}$ 是设计矩阵，其行是所选的设计向量，而 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2} I)$ 是独立高斯噪声。正在考虑两种可行的设计方案：\n\n- 设计 $\\mathrm{A}$ (重复)：选择相同的设计向量 $v_{1} = e_{1}$ 两次，因此 $X_{\\mathrm{A}}$ 的行为 $e_{1}^{\\top}$ 和 $e_{1}^{\\top}$。\n- 设计 $\\mathrm{B}$ (多样化)：选择正交设计向量 $v_{1} = e_{1}$ 和 $v_{2} = e_{2}$，因此 $X_{\\mathrm{B}}$ 的行为 $e_{1}^{\\top}$ 和 $e_{2}^{\\top}$。\n\n采用贝叶斯实验设计效用，即从 $\\theta$ 的后验分布到先验分布的期望 Kullback–Leibler 散度 (KLD)，也就是在指定的线性高斯模型下，$\\theta$ 和数据 $y$ 之间的互信息。从基本原理和核心定义出发，推导两种设计方案各自的效用，并针对特定参数和噪声设置 $\\alpha = 9$, $\\beta = 1$ 及 $\\sigma^{2} = 1$ 计算其差值\n$$\\Delta U = U_{\\mathrm{B}} - U_{\\mathrm{A}}$$\n请用一个包含自然对数的单一闭式解析表达式给出您的最终答案，不进行四舍五入，也不带单位。",
            "solution": "该问题是有效的，因为它具有科学依据、良定、客观、自洽且一致。它代表了线性逆问题的贝叶斯实验设计中的一个标准问题。我们开始求解。\n\n实验设计（由设计矩阵 $X$ 表示）的效用由参数 $\\theta$ 的后验分布到其先验分布的期望 Kullback–Leibler 散度 (KLD) 给出。这个量等价于参数 $\\theta$ 和数据 $y$ 之间的互信息。\n对于给定的设计 $X$，效用为 $U(X) = I(\\theta; y | X)$。\n互信息可以用微分熵表示为 $I(\\theta; y) = H(\\theta) - H(\\theta|y)$。\n\n$\\theta \\in \\mathbb{R}^{k}$ 的先验分布为 $p(\\theta) = \\mathcal{N}(\\mu_0, \\Sigma_0)$。多元高斯分布的微分熵为 $H(\\theta) = \\frac{1}{2} \\ln \\det(2\\pi e \\Sigma_0)$。在本问题中，$\\theta$ 的维度为 $k=2$，先验均值为 $\\mu_0 = 0$。\n\n观测模型为 $y = X\\theta + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I)$。似然函数为 $p(y|\\theta) = \\mathcal{N}(y | X\\theta, \\sigma^2 I)$。\n在此线性高斯模型下，后验分布 $p(\\theta|y)$ 也是高斯分布，$p(\\theta|y) = \\mathcal{N}(\\mu_{\\text{post}}, \\Sigma_{post})$。后验协方差矩阵 $\\Sigma_{post}$ 由先验协方差的逆与来自数据的费雪信息之和的逆矩阵给出：\n$$ \\Sigma_{post}^{-1} = \\Sigma_0^{-1} + \\frac{1}{\\sigma^2} X^{\\top}X $$\n关键在于，$\\Sigma_{post}$ 不依赖于具体的数据实现 $y$。后验分布的熵为 $H(p(\\theta|y)) = \\frac{1}{2} \\ln \\det(2\\pi e \\Sigma_{post})$。\n条件熵 $H(\\theta|y)$ 是 $H(p(\\theta|y))$ 在所有可能的数据 $y$ 上的期望：\n$$ H(\\theta|y) = \\mathbb{E}_{y}[H(p(\\theta|y))] $$\n由于 $H(p(\\theta|y))$ 与 $y$ 无关，期望的计算是平凡的，结果为 $H(\\theta|y) = \\frac{1}{2} \\ln \\det(2\\pi e \\Sigma_{post})$。\n\n将熵代入互信息公式：\n$$ U(X) = H(\\theta) - H(\\theta|y) = \\frac{1}{2} \\ln \\det(2\\pi e \\Sigma_0) - \\frac{1}{2} \\ln \\det(2\\pi e \\Sigma_{post}) $$\n$$ U(X) = \\frac{1}{2} \\left[ \\ln(\\det(\\Sigma_0)) - \\ln(\\det(\\Sigma_{post})) \\right] = \\frac{1}{2} \\ln\\left(\\frac{\\det(\\Sigma_0)}{\\det(\\Sigma_{post})}\\right) = \\frac{1}{2} \\ln(\\det(\\Sigma_0 \\Sigma_{post}^{-1})) $$\n代入 $\\Sigma_{post}^{-1}$ 的表达式：\n$$ U(X) = \\frac{1}{2} \\ln\\left(\\det\\left(\\Sigma_0 \\left(\\Sigma_0^{-1} + \\frac{1}{\\sigma^2} X^{\\top}X\\right)\\right)\\right) = \\frac{1}{2} \\ln\\left(\\det\\left(I + \\frac{1}{\\sigma^2} \\Sigma_0 X^{\\top}X\\right)\\right) $$\n这个表达式给出了任何设计 $X$ 的效用。我们现在将此公式应用于两种指定的设计，并使用给定的参数值：$\\Sigma_0 = \\operatorname{diag}(\\alpha, \\beta) = \\operatorname{diag}(9, 1)$ 和 $\\sigma^2=1$。效用简化为：\n$$ U(X) = \\frac{1}{2} \\ln(\\det(I + \\Sigma_0 X^{\\top}X)) $$\n\n对于设计 A (重复)，设计矩阵 $X_{\\mathrm{A}}$ 有两个相同的行 $e_1^{\\top} = \\begin{pmatrix} 1  0 \\end{pmatrix}$。\n$$ X_{\\mathrm{A}} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\end{pmatrix} $$\n我们计算矩阵乘积 $X_{\\mathrm{A}}^{\\top}X_{\\mathrm{A}}$：\n$$ X_{\\mathrm{A}}^{\\top}X_{\\mathrm{A}} = \\begin{pmatrix} 1  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  0 \\end{pmatrix} = \\begin{pmatrix} 2  0 \\\\ 0  0 \\end{pmatrix} $$\n现在我们可以计算效用 $U_{\\mathrm{A}}$：\n$$ U_{\\mathrm{A}} = \\frac{1}{2} \\ln\\left(\\det\\left( \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 9  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  0 \\end{pmatrix} \\right)\\right) $$\n$$ U_{\\mathrm{A}} = \\frac{1}{2} \\ln\\left(\\det\\left( \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 18  0 \\\\ 0  0 \\end{pmatrix} \\right)\\right) $$\n$$ U_{\\mathrm{A}} = \\frac{1}{2} \\ln\\left(\\det\\begin{pmatrix} 19  0 \\\\ 0  1 \\end{pmatrix}\\right) = \\frac{1}{2} \\ln(19) $$\n\n对于设计 B (多样化)，设计矩阵 $X_{\\mathrm{B}}$ 的行为 $e_1^{\\top} = \\begin{pmatrix} 1  0 \\end{pmatrix}$ 和 $e_2^{\\top} = \\begin{pmatrix} 0  1 \\end{pmatrix}$。\n$$ X_{\\mathrm{B}} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = I_2 $$\n矩阵乘积 $X_{\\mathrm{B}}^{\\top}X_{\\mathrm{B}}$ 是：\n$$ X_{\\mathrm{B}}^{\\top}X_{\\mathrm{B}} = I_2^{\\top} I_2 = I_2 = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} $$\n现在我们可以计算效用 $U_{\\mathrm{B}}$：\n$$ U_{\\mathrm{B}} = \\frac{1}{2} \\ln\\left(\\det\\left( I_2 + \\Sigma_0 I_2 \\right)\\right) = \\frac{1}{2} \\ln(\\det(I_2 + \\Sigma_0)) $$\n$$ U_{\\mathrm{B}} = \\frac{1}{2} \\ln\\left(\\det\\left( \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 9  0 \\\\ 0  1 \\end{pmatrix} \\right)\\right) $$\n$$ U_{\\mathrm{B}} = \\frac{1}{2} \\ln\\left(\\det\\begin{pmatrix} 10  0 \\\\ 0  2 \\end{pmatrix}\\right) = \\frac{1}{2} \\ln(20) $$\n\n最后，我们计算效用差 $\\Delta U = U_{\\mathrm{B}} - U_{\\mathrm{A}}$：\n$$ \\Delta U = \\frac{1}{2} \\ln(20) - \\frac{1}{2} \\ln(19) $$\n使用对数性质 $\\ln(a) - \\ln(b) = \\ln(a/b)$，我们得到：\n$$ \\Delta U = \\frac{1}{2} \\left( \\ln(20) - \\ln(19) \\right) = \\frac{1}{2} \\ln\\left(\\frac{20}{19}\\right) $$\n这就是最终的闭式解析表达式。",
            "answer": "$$\\boxed{\\frac{1}{2} \\ln\\left(\\frac{20}{19}\\right)}$$"
        },
        {
            "introduction": "“更多数据未必带来同等比例的收益”是高效实验的核心理念。本次练习为理解“收益递减”原则提供了一种严谨的方法。您将推导信息增益作为实验投入的函数，并分析其曲率，从而在数学上证明为何随着知识的增长，每次额外实验的价值会随之下降。",
            "id": "3367052",
            "problem": "考虑一个线性高斯贝叶斯逆问题，其参数向量为 $\\theta \\in \\mathbb{R}^{d}$，赋予高斯先验 $\\theta \\sim \\mathcal{N}(0, \\Gamma_{\\text{prior}})$，以及一个线性观测模型 $y = H \\theta + \\eta$。观测噪声是高斯的，协方差为 $\\Gamma_{\\eta}/u$，其中 $u > 0$ 是一个标量努力参数（例如，与独立重复实验的次数成正比），并且 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta}/u)$。在此模型下，对于给定的努力 $u$，期望信息增益（从后验到先验的Kullback–Leibler散度）可以表示为后验与先验协方差行列式的比值。在本问题中，使用以下数据：\n- 维度 $d = 2$。\n- 先验协方差 $\\Gamma_{\\text{prior}} = \\begin{pmatrix} 2  0.6 \\\\ 0.6  1.2 \\end{pmatrix}$。\n- 前向模型矩阵 $H = \\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix}$。\n- 噪声协方差 $\\Gamma_{\\eta} = \\begin{pmatrix} 1.0  0.2 \\\\ 0.2  1.5 \\end{pmatrix}$。\n\n从高斯条件化和互信息的对数行列式恒等式的核心定义出发，推导标量D-最优设计目标 $J(u)$ 作为 $u$ 的函数，并计算其关于 $u$ 的二阶导数以表征曲率（这捕捉了收益递减的特性）。然后，对于特定值 $u = 1$，使用所提供的矩阵数值计算曲率 $J''(1)$。\n\n将您的答案四舍五入到 $4$ 位有效数字。将最终答案表示为一个无量纲的实数。",
            "solution": "本问题要求推导和评估一个线性高斯贝叶斯逆问题的D-最优设计目标函数 $J(u)$ 的曲率。目标函数是期望信息增益 (EIG)，对于此模型，它是从后验到先验的Kullback-Leibler散度，在所有可能的数据上取平均。\n\n参数向量 $\\theta \\in \\mathbb{R}^{d}$ 的先验分布为 $\\theta \\sim \\mathcal{N}(0, \\Gamma_{\\text{prior}})$。观测模型为 $y = H \\theta + \\eta$，其中噪声 $\\eta$ 的分布为 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta}/u)$。此处，$u$ 是一个标量努力参数。\n\n在给定观测值 $y$ 的情况下，$\\theta$ 的后验分布也是一个高斯分布，$p(\\theta|y) = \\mathcal{N}(\\mu_{\\text{post}}, \\Gamma_{\\text{post}})$。后验精度（逆协方差）矩阵是先验精度与来自似然的数据依赖精度的和：\n$$ \\Gamma_{\\text{post}}^{-1} = \\Gamma_{\\text{prior}}^{-1} + H^T (\\Gamma_{\\eta}/u)^{-1} H = \\Gamma_{\\text{prior}}^{-1} + u H^T \\Gamma_{\\eta}^{-1} H $$\n\nEIG，我们记为 $J(u)$，是参数 $\\theta$ 和数据 $y$ 之间的互信息。对于线性高斯系统，这个量与具体的观测值 $y$ 无关，可以表示为先验和后验协方差的形式：\n$$ J(u) = \\frac{1}{2} \\ln \\left( \\frac{\\det(\\Gamma_{\\text{prior}})}{\\det(\\Gamma_{\\text{post}})} \\right) = \\frac{1}{2} \\ln \\left( \\det(\\Gamma_{\\text{post}}^{-1} \\Gamma_{\\text{prior}}) \\right) $$\n代入 $\\Gamma_{\\text{post}}^{-1}$ 的表达式：\n$$ J(u) = \\frac{1}{2} \\ln \\left( \\det\\left( (\\Gamma_{\\text{prior}}^{-1} + u H^T \\Gamma_{\\eta}^{-1} H) \\Gamma_{\\text{prior}} \\right) \\right) = \\frac{1}{2} \\ln \\left( \\det(I + u H^T \\Gamma_{\\eta}^{-1} H \\Gamma_{\\text{prior}}) \\right) $$\n使用Sylvester行列式恒等式 $\\det(I + AB) = \\det(I + BA)$，我们可以将其写为：\n$$ J(u) = \\frac{1}{2} \\ln \\left( \\det(I + u \\Gamma_{\\text{prior}} H^T \\Gamma_{\\eta}^{-1} H) \\right) $$\n让我们定义矩阵 $\\mathcal{I} = \\Gamma_{\\text{prior}} H^T \\Gamma_{\\eta}^{-1} H$。虽然 $\\mathcal{I}$ 通常不是对称的，但其特征值是实的、非负的，并且与对称矩阵 $\\mathcal{I}_s = \\Gamma_{\\text{prior}}^{1/2} H^T \\Gamma_{\\eta}^{-1} H \\Gamma_{\\text{prior}}^{1/2}$ 的特征值相同。设 $\\mathcal{I}$ (以及 $\\mathcal{I}_s$) 的特征值为 $\\{\\lambda_i\\}_{i=1}^{d}$。那么行列式可以表示为特征值的乘积：\n$$ J(u) = \\frac{1}{2} \\ln \\left( \\prod_{i=1}^{d} (1 + u \\lambda_i) \\right) = \\frac{1}{2} \\sum_{i=1}^{d} \\ln(1 + u \\lambda_i) $$\n这就是推导出的目标函数。\n\n为了求曲率，我们计算 $J(u)$ 关于 $u$ 的二阶导数。一阶导数是：\n$$ J'(u) = \\frac{dJ}{du} = \\frac{1}{2} \\sum_{i=1}^{d} \\frac{\\lambda_i}{1 + u \\lambda_i} $$\n二阶导数，即曲率，是：\n$$ J''(u) = \\frac{d^2J}{du^2} = \\frac{1}{2} \\sum_{i=1}^{d} \\frac{-(\\lambda_i)(\\lambda_i)}{(1 + u \\lambda_i)^2} = -\\frac{1}{2} \\sum_{i=1}^{d} \\left( \\frac{\\lambda_i}{1 + u \\lambda_i} \\right)^2 $$\n$J''(u)$ 的这个表达式总是非正的，这正确地捕捉了努力 $u$ 投资的收益递减原理。\n\n现在我们使用所提供的矩阵来评估 $J''(1)$。维度是 $d=2$。\n- $\\Gamma_{\\text{prior}} = \\begin{pmatrix} 2  0.6 \\\\ 0.6  1.2 \\end{pmatrix}$\n- $H = \\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix}$\n- $\\Gamma_{\\eta} = \\begin{pmatrix} 1.0  0.2 \\\\ 0.2  1.5 \\end{pmatrix}$\n\n首先，我们计算矩阵 $\\mathcal{I} = \\Gamma_{\\text{prior}} H^T \\Gamma_{\\eta}^{-1} H$ 并求其特征值。\n\n1.  计算 $\\Gamma_{\\eta}^{-1}$：\n    $\\det(\\Gamma_{\\eta}) = (1.0)(1.5) - (0.2)(0.2) = 1.5 - 0.04 = 1.46$。\n    $$ \\Gamma_{\\eta}^{-1} = \\frac{1}{1.46} \\begin{pmatrix} 1.5  -0.2 \\\\ -0.2  1.0 \\end{pmatrix} $$\n\n2.  计算费雪信息矩阵 $H^T \\Gamma_{\\eta}^{-1} H$：\n    由于 $H$ 是对称的，所以 $H^T = H$。\n    $$ H^T \\Gamma_{\\eta}^{-1} H = \\frac{1}{1.46} \\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix} \\begin{pmatrix} 1.5  -0.2 \\\\ -0.2  1.0 \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix} $$\n    $$ = \\frac{1}{1.46} \\begin{pmatrix} 1.3  0.8 \\\\ 1.1  1.8 \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix} = \\frac{1}{1.46} \\begin{pmatrix} 2.1  2.9 \\\\ 2.9  4.7 \\end{pmatrix} $$\n\n3.  计算 $\\mathcal{I} = \\Gamma_{\\text{prior}} (H^T \\Gamma_{\\eta}^{-1} H)$：\n    $$ \\mathcal{I} = \\begin{pmatrix} 2  0.6 \\\\ 0.6  1.2 \\end{pmatrix} \\left( \\frac{1}{1.46} \\begin{pmatrix} 2.1  2.9 \\\\ 2.9  4.7 \\end{pmatrix} \\right) $$\n    $$ \\mathcal{I} = \\frac{1}{1.46} \\begin{pmatrix} (2)(2.1) + (0.6)(2.9)  (2)(2.9) + (0.6)(4.7) \\\\ (0.6)(2.1) + (1.2)(2.9)  (0.6)(2.9) + (1.2)(4.7) \\end{pmatrix} $$\n    $$ \\mathcal{I} = \\frac{1}{1.46} \\begin{pmatrix} 4.2 + 1.74  5.8 + 2.82 \\\\ 1.26 + 3.48  1.74 + 5.64 \\end{pmatrix} = \\frac{1}{1.46} \\begin{pmatrix} 5.94  8.62 \\\\ 4.74  7.38 \\end{pmatrix} $$\n\n4.  求 $\\mathcal{I}$ 的特征值。特征值 $\\lambda$ 是特征方程 $\\det(\\mathcal{I} - \\lambda I) = 0$ 的根。令 $A = \\begin{pmatrix} 5.94  8.62 \\\\ 4.74  7.38 \\end{pmatrix}$，那么 $\\mathcal{I}$ 的特征值是 $A$ 的特征值的 $\\frac{1}{1.46}$ 倍。$A$ 的特征方程为 $\\Lambda^2 - \\text{tr}(A)\\Lambda + \\det(A) = 0$。\n    $\\text{tr}(A) = 5.94 + 7.38 = 13.32$。\n    $\\det(A) = (5.94)(7.38) - (8.62)(4.74) = 43.8372 - 40.8588 = 2.9784$。\n    所以，$\\Lambda^2 - 13.32 \\Lambda + 2.9784 = 0$。\n    使用二次公式，$\\Lambda = \\frac{13.32 \\pm \\sqrt{13.32^2 - 4(2.9784)}}{2} = \\frac{13.32 \\pm \\sqrt{165.5088}}{2}$。\n    $\\sqrt{165.5088} \\approx 12.864983$。\n    $\\Lambda_1 = \\frac{13.32 + 12.864983}{2} \\approx 13.0924915$。\n    $\\Lambda_2 = \\frac{13.32 - 12.864983}{2} \\approx 0.2275085$。\n    $\\mathcal{I}$ 的特征值为：\n    $\\lambda_1 = \\Lambda_1 / 1.46 \\approx 13.0924915 / 1.46 \\approx 8.967460$。\n    $\\lambda_2 = \\Lambda_2 / 1.46 \\approx 0.2275085 / 1.46 \\approx 0.155828$。\n\n5.  在 $u=1$ 处评估 $J''(u)$：\n    $$ J''(1) = -\\frac{1}{2} \\left[ \\left( \\frac{\\lambda_1}{1 + \\lambda_1} \\right)^2 + \\left( \\frac{\\lambda_2}{1 + \\lambda_2} \\right)^2 \\right] $$\n    $$ J''(1) \\approx -\\frac{1}{2} \\left[ \\left( \\frac{8.967460}{1 + 8.967460} \\right)^2 + \\left( \\frac{0.155828}{1 + 0.155828} \\right)^2 \\right] $$\n    $$ J''(1) \\approx -\\frac{1}{2} \\left[ \\left( \\frac{8.967460}{9.967460} \\right)^2 + \\left( \\frac{0.155828}{1.155828} \\right)^2 \\right] $$\n    $$ J''(1) \\approx -\\frac{1}{2} \\left[ (0.899679)^2 + (0.134819)^2 \\right] $$\n    $$ J''(1) \\approx -\\frac{1}{2} [ 0.809422 + 0.018176 ] $$\n    $$ J''(1) \\approx -\\frac{1}{2} [ 0.827598 ] \\approx -0.413799 $$\n\n四舍五入到 $4$ 位有效数字，曲率为 $-0.4138$。",
            "answer": "$$\\boxed{-0.4138}$$"
        }
    ]
}