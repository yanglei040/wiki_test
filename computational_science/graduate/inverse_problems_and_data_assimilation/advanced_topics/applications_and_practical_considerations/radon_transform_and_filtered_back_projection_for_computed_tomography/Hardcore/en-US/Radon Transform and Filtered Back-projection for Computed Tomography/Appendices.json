{
    "hands_on_practices": [
        {
            "introduction": "Before we can reconstruct an image, we must first acquire the data. This exercise goes to the heart of CT system design by asking a fundamental question: how finely must we sample our data to avoid losing information? Starting from first principles like the Nyquist criterion and the Fourier Slice Theorem, you will derive the essential sampling conditions for both the detector spacing and the angular step size . This theoretical practice provides the crucial link between an object's physical size, the desired resolution, and the design of the data acquisition geometry.",
            "id": "3416093",
            "problem": "Consider a parallel-beam two-dimensional computed tomography acquisition of a compactly supported object $f(x,y)$, with $f(x,y)=0$ for $x^{2}+y^{2}>R^{2}$, where $R>0$ is the known object support radius. Let $p(s,\\theta)$ denote the Radon transform of $f(x,y)$, where $s$ is the signed detector coordinate along the projection line and $\\theta \\in [0,\\pi)$ is the projection angle. Assume a filtered back-projection reconstruction that uses a ramp filter truncated to a known angular spatial-frequency cutoff $\\omega_{c}>0$ (in radians per unit length), meaning the projection data are effectively bandlimited in detector coordinate to $|\\omega|\\leq \\omega_{c}$ when transformed with respect to $s$.\n\nStarting from the definitions of the Radon transform and the two-dimensional Fourier transform, and invoking the conceptually appropriate sampling requirement embodied by the Nyquist criterion, derive the maximum allowable detector bin width $\\Delta s_{\\max}$ and the maximum allowable angular sampling step $\\Delta \\theta_{\\max}$ that avoid aliasing in filtered back-projection for all projection angles $\\theta$ and all radial frequencies $|\\omega|\\leq \\omega_{c}$. Express the final detector bin width in millimeters and the final angular step in radians. Provide your final answer as two closed-form analytic expressions in terms of $R$ and $\\omega_{c}$.\n\nThe final answer must be a single row matrix whose two entries are $\\Delta s_{\\max}$ and $\\Delta \\theta_{\\max}$, respectively, with no units included in the matrix.",
            "solution": "The problem requires the derivation of the maximum allowable detector bin width, $\\Delta s_{\\max}$, and the maximum allowable angular sampling step, $\\Delta \\theta_{\\max}$, for a two-dimensional computed tomography system to avoid aliasing. The derivation will be based on the Nyquist-Shannon sampling theorem applied to the spatial and angular dimensions of the sinogram data, $p(s, \\theta)$.\n\nThe object to be imaged, $f(x,y)$, is compactly supported on a disk of radius $R>0$, meaning $f(x,y)=0$ for $x^{2}+y^{2}>R^{2}$. The projection data, $p(s, \\theta)$, are the line integrals of $f(x,y)$, where $s$ is the detector coordinate and $\\theta \\in [0, \\pi)$ is the projection angle. The reconstruction process involves a ramp filter that is truncated at a maximum angular spatial frequency $\\omega_c > 0$. This implies that the projection data $p(s, \\theta)$, for any given angle $\\theta$, are effectively bandlimited in the spatial coordinate $s$ to the frequency interval $[-\\omega_c, \\omega_c]$.\n\n**Derivation of the Maximum Detector Bin Width, $\\Delta s_{\\max}$**\n\nThe sampling requirement for the detector coordinate $s$ is determined by the bandwidth of the projections $p(s, \\theta)$ with respect to $s$. Let $\\omega$ be the angular frequency variable conjugate to $s$. The problem states that the data are effectively bandlimited such that their Fourier transform with respect to $s$, denoted $P(\\omega, \\theta)$, is zero for $|\\omega| > \\omega_c$. The maximum angular frequency present in the signal $p(s, \\theta)$ is therefore $\\omega_{\\max} = \\omega_c$.\n\nThe Nyquist-Shannon sampling theorem states that to perfectly reconstruct a bandlimited signal, the sampling frequency must be strictly greater than twice its maximum frequency. In terms of angular frequencies, the sampling frequency $\\omega_s$ must satisfy $\\omega_s \\ge 2 \\omega_{\\max}$ to avoid aliasing (with the equality representing the limiting case).\n\nThe sampling interval in the spatial domain is the detector bin width, $\\Delta s$. The angular sampling frequency $\\omega_s$ is related to $\\Delta s$ by $\\omega_s = \\frac{2\\pi}{\\Delta s}$.\n\nApplying the Nyquist criterion:\n$$ \\omega_s \\ge 2 \\omega_c $$\n$$ \\frac{2\\pi}{\\Delta s} \\ge 2 \\omega_c $$\nSolving for $\\Delta s$, we find the constraint on the detector bin width:\n$$ \\Delta s \\le \\frac{\\pi}{\\omega_c} $$\nThe maximum allowable detector bin width is the upper bound of this inequality.\n$$ \\Delta s_{\\max} = \\frac{\\pi}{\\omega_c} $$\nIf $\\omega_c$ is given in units of radians per millimeter, then $\\Delta s_{\\max}$ will be in millimeters, as requested.\n\n**Derivation of the Maximum Angular Sampling Step, $\\Delta \\theta_{\\max}$**\n\nThe sampling requirement for the projection angle $\\theta$ is more subtle. It depends on how rapidly the projection data $p(s, \\theta)$ change as a function of $\\theta$. This rate of change is dictated by the spatial extent of the object $R$ and the spatial frequencies $\\omega$ being considered. The most rapid changes, and thus the most stringent sampling requirement, occur for the highest spatial frequency, $\\omega_c$, and for features at the edge of the object, at radius $R$.\n\nWe utilize the Fourier Slice Theorem, which connects the 1D Fourier transform of a projection, $P(\\omega, \\theta)$, to the 2D Fourier transform of the object, $F(k_x, k_y)$:\n$$ P(\\omega, \\theta) = F(k_x, k_y) \\quad \\text{where} \\quad k_x = \\omega \\cos\\theta, \\; k_y = \\omega \\sin\\theta $$\nTo find the bandwidth of the signal with respect to $\\theta$, we analyze the behavior of $P(\\omega, \\theta)$ for a fixed $\\omega = \\omega_c$. The \"worst-case\" signal, which exhibits the fastest variation with $\\theta$, corresponds to an object with a point-like feature at its periphery. Let us model this with a delta function at the edge of the support disk, for instance, $f(x,y) = \\delta(x-R, y-0)$.\n\nThe Radon transform of this object is:\n$$ p(s,\\theta) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} \\delta(x'-R, y'-0) \\delta(s - x'\\cos\\theta - y'\\sin\\theta) \\,dx'dy' = \\delta(s - R\\cos\\theta) $$\nThe 1D Fourier transform of this projection with respect to $s$ is:\n$$ P(\\omega, \\theta) = \\int_{-\\infty}^{\\infty} \\delta(s - R\\cos\\theta) e^{-i\\omega s} \\,ds = \\exp(-i\\omega R\\cos\\theta) $$\nWe are interested in the frequency content of this signal as a function of $\\theta$ at the highest radial frequency, $\\omega = \\omega_c$. Let this signal be $g(\\theta) = P(\\omega_c, \\theta) = \\exp(-i\\omega_c R\\cos\\theta)$.\n\nTo find the frequency content of $g(\\theta)$, we express it as a Fourier series in the variable $\\theta$. We use the Jacobi-Anger expansion:\n$$ \\exp(iz\\cos\\theta) = \\sum_{n=-\\infty}^{\\infty} i^n J_n(z) e^{in\\theta} $$\nwhere $J_n(z)$ is the Bessel function of the first kind of order $n$.\nFor our signal $g(\\theta)$, we set $z = -\\omega_c R$. The expansion is:\n$$ g(\\theta) = \\sum_{n=-\\infty}^{\\infty} i^n J_n(-\\omega_c R) e^{in\\theta} $$\nThe integer $n$ represents the angular frequency (harmonic number) of each component in the series. A fundamental property of Bessel functions is that $J_n(z)$ becomes negligibly small for $|n| > |z|$. This means that the signal $g(\\theta)$ is effectively bandlimited in the angular domain, with a maximum significant harmonic (angular frequency) of:\n$$ n_{\\max} \\approx |\\omega_c R| = \\omega_c R $$\nThis maximum frequency $n_{\\max}$ represents the number of oscillations over an angular interval of $2\\pi$ radians. To avoid aliasing when sampling in $\\theta$, the Nyquist criterion requires that the number of samples over a $2\\pi$ interval, $N_{2\\pi}$, must be greater than twice the highest frequency component: $N_{2\\pi} > 2 n_{\\max}$.\n\nThe number of samples is related to the angular step $\\Delta\\theta$ by $N_{2\\pi} = \\frac{2\\pi}{\\Delta\\theta}$. Substituting this and $n_{\\max}$ into the Nyquist criterion:\n$$ \\frac{2\\pi}{\\Delta\\theta} > 2 (\\omega_c R) $$\nSolving for $\\Delta\\theta$:\n$$ \\Delta\\theta < \\frac{\\pi}{\\omega_c R} $$\nThe maximum allowable angular step is therefore the upper bound:\n$$ \\Delta\\theta_{\\max} = \\frac{\\pi}{\\omega_c R} $$\nThis expression gives the angular step in radians, as the product $\\omega_c R$ is dimensionless (in units of `(rad/length) * length = rad`, and radians are dimensionless).\n\nCombining the two results, we have the maximum allowable sampling intervals for detector spacing and projection angle.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{\\pi}{\\omega_c} & \\frac{\\pi}{\\omega_c R} \\end{pmatrix} } $$"
        },
        {
            "introduction": "Moving from theory to practice, this exercise guides you through the implementation of the core computational tools for tomography. You will build a discrete model of the Radon transform and, critically, its adjoint operator—the back-projection . The correctness of your implementation will be verified using the adjoint test, an indispensable technique in computational inverse problems, and you will confirm the linearity of the complete filtered back-projection operator.",
            "id": "3416112",
            "problem": "You are to implement a fully discrete model of the Radon transform and its adjoint for parallel-beam two-dimensional computed tomography, together with a ramp-filtered back-projection mapping. You will use this discrete model to perform two validation tasks: an adjoint test and a differentiability test. The adjoint test verifies numerically that the discrete back-projection is the adjoint of the discrete Radon transform under specified inner products. The differentiability test verifies the Fréchet differentiability of the filtered back-projection operator.\n\nStart from the following foundational base:\n- The Radon transform maps a compactly supported integrable image function in two dimensions, denoted by $f(\\mathbf{x})$ with $\\mathbf{x} \\in \\mathbb{R}^2$, to its line integrals indexed by angle $\\theta \\in [0,\\pi)$ and signed distance $s \\in \\mathbb{R}$ from the origin, defined by the integral of $f$ over the line $\\{\\mathbf{x} \\in \\mathbb{R}^2 : \\mathbf{x} \\cdot \\boldsymbol{\\nu}(\\theta) = s\\}$, where $\\boldsymbol{\\nu}(\\theta) = (\\cos \\theta, \\sin \\theta)$.\n- The filtered back-projection combines a one-dimensional convolution in detector space with the ramp kernel and back-projection across angles to obtain a reconstruction from sinogram data.\n- The adjoint operator is defined by the equality of inner products $\\langle A x, y \\rangle = \\langle x, A^{\\ast} y \\rangle$ for all elements $x$ and $y$ in the respective Hilbert spaces, where $A^{\\ast}$ denotes the adjoint of $A$ and $\\langle \\cdot, \\cdot \\rangle$ denotes the inner product.\n\nYou must implement a discrete approximation of these operators by adhering to the following, without using any closed-form inversion formulas as a shortcut:\n\n1. Discrete image grid and coordinates.\n   - Work on a square image grid of size $N \\times N$ representing a compactly supported function on the square $[-1,1] \\times [-1,1]$.\n   - Use pixel centers at coordinates $x_i = -1 + \\left(i + \\tfrac{1}{2}\\right)\\Delta$, $y_j = -1 + \\left(j + \\tfrac{1}{2}\\right)\\Delta$ for $i,j \\in \\{0,\\dots,N-1\\}$ with $\\Delta = \\tfrac{2}{N}$.\n\n2. Projection geometry and sampling.\n   - Use $K$ projection angles uniformly spaced in $[0,\\pi)$ in radians, i.e., $\\theta_k = \\tfrac{k \\pi}{K}$ for $k \\in \\{0,\\dots,K-1\\}$.\n   - Use $M$ detector bins with signed distances $s_m$ uniformly spanning $[-L,L]$, where $L = \\sqrt{2}$, i.e., $s_m = -L + \\tfrac{2 L m}{M-1}$ for $m \\in \\{0,\\dots,M-1\\}$.\n   - Approximate each line integral at $(\\theta_k, s_m)$ by numerical integration along the in-line coordinate $v \\in [-L,L]$ using $N_v$ equally spaced samples $v_n = -L + \\tfrac{2 L n}{N_v-1}$ for $n \\in \\{0,\\dots,N_v-1\\}$ with step size $\\mathrm{d}v = \\tfrac{2 L}{N_v-1}$.\n\n3. Coordinate transforms and interpolation.\n   - Use the rotated coordinate system $(u,v)$ defined by $u = x \\cos \\theta + y \\sin \\theta$ and $v = - x \\sin \\theta + y \\cos \\theta$. For a fixed angle $\\theta_k$ and detector coordinate $s_m$, the line is parameterized by $u = s_m$ and $v \\in [-L,L]$. Convert back to Cartesian coordinates by $x = u \\cos \\theta - v \\sin \\theta$ and $y = u \\sin \\theta + v \\cos \\theta$.\n   - Use bilinear interpolation on the image grid to evaluate image values at off-grid points $(x,y)$. Only include contributions for $(x,y)$ within the image square $[-1,1] \\times [-1,1]$.\n   - Define the discrete Radon transform $R$ by approximating each line integral for $(\\theta_k, s_m)$ as the sum over $v_n$ of bilinear samples multiplied by $\\mathrm{d}v$.\n\n4. Discrete adjoint.\n   - Define the discrete back-projection $B$ as the exact algorithmic transpose of the implementation described for $R$ with respect to the standard Euclidean inner products on the discretized spaces, i.e., it must be implemented by reversing the accumulation: where $R$ reads from the image and writes to the sinogram, $B$ must read from the sinogram and write to the image using the same bilinear weights and the same $\\mathrm{d}v$ factors. This ensures that, in exact arithmetic, $\\langle R f, y \\rangle = \\langle f, B y \\rangle$ holds for all discretized $f$ and $y$ when using the standard Euclidean inner products defined below.\n\n5. Inner products.\n   - Use the standard Euclidean inner product on the image grid: for images $x,z \\in \\mathbb{R}^{N \\times N}$, $\\langle x,z \\rangle_{\\mathrm{img}} = \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} x_{ij} z_{ij}$.\n   - Use the standard Euclidean inner product on the sinogram: for sinograms $p,q \\in \\mathbb{R}^{K \\times M}$, $\\langle p,q \\rangle_{\\mathrm{sin}} = \\sum_{k=0}^{K-1} \\sum_{m=0}^{M-1} p_{km} q_{km}$.\n\n6. Filtered back-projection operator.\n   - Define a discrete ramp filter $H$ acting along the detector coordinate for each angle independently by multiplying the discrete Fourier transform of each angle’s detector samples by a discrete ramp $|\\omega|$ and then inverting the transform. You may use the discrete Fourier transform; angles are in radians, and no physical units are required.\n   - Define the filtered back-projection mapping $F$ by $F(y) = B(H(y))$.\n\n7. Validation tasks to compute.\n   - Adjoint test. For a given image $f$ and sinogram $y$, compute the relative adjoint mismatch\n     $$E_{\\mathrm{adj}} = \\frac{\\left|\\langle R f, y \\rangle_{\\mathrm{sin}} - \\langle f, B y \\rangle_{\\mathrm{img}} \\right|}{\\left|\\langle R f, y \\rangle_{\\mathrm{sin}} \\right| + \\left|\\langle f, B y \\rangle_{\\mathrm{img}} \\right| + 10^{-12}}.$$\n   - Differentiability test. For a given base sinogram $y_0$, a direction $v$, and a step size $\\varepsilon$, compute the relative linearization error for $F$:\n     $$E_{\\mathrm{diff}} = \\frac{\\left\\| F(y_0 + \\varepsilon v) - F(y_0) - \\varepsilon F(v) \\right\\|_F}{\\left\\| \\varepsilon F(v) \\right\\|_F + 10^{-16}},$$\n     where $\\|\\cdot\\|_F$ denotes the Frobenius norm.\n\nAngles must be in radians. No physical units are required.\n\nTest suite. Your program must compute the two errors above for each of the following three test cases, using the specified parameters and pseudorandom seeds. For all random draws, use independent standard normal random variables with zero mean and unit variance.\n- Case A (general case): $N = 32$, $K = 30$, $M = 45$, $N_v = 201$, $\\varepsilon = 10^{-5}$, random seed $1$ for all random objects in this case.\n- Case B (boundary geometry with a single angle): $N = 16$, $K = 1$, $M = 23$, $N_v = 121$, $\\varepsilon = 10^{-5}$, random seed $2$ for all random objects in this case.\n- Case C (coarser sampling, non-square sizes): $N = 28$, $K = 19$, $M = 29$, $N_v = 151$, $\\varepsilon = 10^{-5}$, random seed $3$ for all random objects in this case.\n\nFor each case:\n- For the adjoint test, generate $f \\in \\mathbb{R}^{N \\times N}$ with the specified seed and generate $y \\in \\mathbb{R}^{K \\times M}$ with the same seed.\n- For the differentiability test, generate $y_0 \\in \\mathbb{R}^{K \\times M}$ and direction $v \\in \\mathbb{R}^{K \\times M}$ with the same seed and the given parameters.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$[E_{\\mathrm{adj}}^{A}, E_{\\mathrm{diff}}^{A}, E_{\\mathrm{adj}}^{B}, E_{\\mathrm{diff}}^{B}, E_{\\mathrm{adj}}^{C}, E_{\\mathrm{diff}}^{C}],$$\nwhere the superscripts $A,B,C$ respectively refer to Cases A, B, and C. The outputs must be real-valued floating-point numbers. Angles are in radians and no units are required for the outputs.",
            "solution": "The problem requires the implementation and validation of a discrete model for two-dimensional parallel-beam computed tomography (CT). The core components are the discrete Radon transform, its adjoint (the back-projection operator), and the ramp-filtered back-projection operator. The implementation is validated through an adjoint test and a differentiability test.\n\nThe discretization of the continuous problem is performed as follows. The image, represented by a function $f(\\mathbf{x})$, is defined on the square $\\mathbf{x} \\in [-1, 1] \\times [-1, 1]$ and sampled on a grid of $N \\times N$ pixels. The center of the pixel $(i, j)$, for $i,j \\in \\{0, \\dots, N-1\\}$, is at Cartesian coordinates $(x_i, y_j)$ where $x_i = -1 + (i + \\frac{1}{2})\\Delta$ and $y_j = -1 + (j + \\frac{1}{2})\\Delta$, with pixel size $\\Delta = \\frac{2}{N}$. The sinogram data is sampled at $K$ projection angles $\\theta_k = \\frac{k \\pi}{K}$ for $k \\in \\{0, \\dots, K-1\\}$ and $M$ detector bins (signed distances from the origin) $s_m$ uniformly spaced in $[-L, L]$, where $L = \\sqrt{2}$ is the half-diagonal of the image domain. Specifically, $s_m = -L + \\frac{2Lm}{M-1}$ for $m \\in \\{0, \\dots, M-1\\}$.\n\nThe discrete Radon transform, denoted by the operator $R$, maps an $N \\times N$ discrete image $f$ to a $K \\times M$ sinogram $p$. Each element $p_{km}$ of the sinogram is an approximation of the line integral of the image function along the line defined by $\\mathbf{x} \\cdot \\boldsymbol{\\nu}(\\theta_k) = s_m$, where $\\boldsymbol{\\nu}(\\theta_k) = (\\cos \\theta_k, \\sin \\theta_k)$. This line is parameterized by a coordinate $v \\in [-L, L]$, such that a point $\\mathbf{x}$ on the line is given by $\\mathbf{x} = s_m \\boldsymbol{\\nu}(\\theta_k) + v \\boldsymbol{\\nu}(\\theta_k)^{\\perp}$, where $\\boldsymbol{\\nu}(\\theta_k)^{\\perp} = (-\\sin\\theta_k, \\cos\\theta_k)$. The integral is approximated by a Riemann sum over $N_v$ points $v_n$ along the line, with step size $\\mathrm{d}v = \\frac{2L}{N_v-1}$. At each point $(x(v_n), y(v_n))$ along the line, the image value is calculated using bilinear interpolation from the four nearest pixel values on the discrete image grid. The value of the sinogram at $(\\theta_k, s_m)$ is then given by:\n$$\np_{km} = (R f)_{km} \\approx \\sum_{n=0}^{N_v-1} f_{\\text{interp}}(s_m \\cos\\theta_k - v_n \\sin\\theta_k, s_m \\sin\\theta_k + v_n \\cos\\theta_k) \\cdot \\mathrm{d}v\n$$\nwhere $f_{\\text{interp}}$ represents the bilinear interpolation process. Contributions are included only if the point $(x,y)$ lies within the image domain $[-1,1]^2$.\n\nThe back-projection operator, denoted by $B$, is defined as the adjoint of the Radon transform operator $R$ with respect to the standard Euclidean inner products on the image and sinogram spaces. The adjoint relationship is given by $\\langle R f, y \\rangle_{\\mathrm{sin}} = \\langle f, B y \\rangle_{\\mathrm{img}}$ for any discrete image $f$ and sinogram $y$. This property dictates the algorithmic implementation of $B$. The operator $R$ can be seen as a \"gather\" operation, where for each sinogram point, values are read and weighted from the image grid. The adjoint operator $B$ is therefore a \"scatter\" or \"splatting\" operation. For each sinogram value $y_{km}$, its contribution $y_{km} \\cdot \\mathrm{d}v$ is distributed back onto the image grid along the same line of integration. At each point along the line, the value is distributed to the four nearest pixels using the same bilinear weights as in the forward projection.\n\nThe filtered back-projection operator, $F$, provides a reconstruction of the image from its sinogram. It is defined by the composition $F(y) = B(H(y))$, where $H$ is a ramp filtering operator. The ramp filter $H$ acts on each row of the sinogram (i.e., for each fixed angle $\\theta_k$) independently. It is implemented in the Fourier domain by applying a one-dimensional discrete Fourier transform ($\\mathcal{F}$) to the detector samples, multiplying by a discrete ramp function $|\\omega|$, and then applying the inverse discrete Fourier transform ($\\mathcal{F}^{-1}$). The frequency variable $\\omega$ corresponds to the spatial frequency along the detector coordinate $s$. The operation for a single row $y_k(s)$ of the sinogram is $H(y_k) = \\mathcal{F}^{-1}\\{|\\omega| \\mathcal{F}\\{y_k(s)\\}\\}$.\n\nTwo validation tasks are performed. The first is the adjoint test, which numerically verifies the adjoint relationship between the implemented operators $R$ and $B$. The relative adjoint mismatch,\n$$\nE_{\\mathrm{adj}} = \\frac{\\left|\\langle R f, y \\rangle_{\\mathrm{sin}} - \\langle f, B y \\rangle_{\\mathrm{img}} \\right|}{\\left|\\langle R f, y \\rangle_{\\mathrm{sin}} \\right| + \\left|\\langle f, B y \\rangle_{\\mathrm{img}} \\right| + 10^{-12}}\n$$\nis computed for randomly generated $f$ and $y$. Due to the construction of $B$ as the exact algorithmic transpose of $R$, this error is expected to be on the order of machine floating-point precision.\n\nThe second task is a differentiability test for the filtered back-projection operator $F$. Since both the ramp filter $H$ and the back-projection $B$ are linear operators, their composition $F = B \\circ H$ is also linear. For a linear operator, the Fréchet derivative is the operator itself. This is verified by computing the relative linearization error:\n$$\nE_{\\mathrm{diff}} = \\frac{\\left\\| F(y_0 + \\varepsilon v) - F(y_0) - \\varepsilon F(v) \\right\\|_F}{\\left\\| \\varepsilon F(v) \\right\\|_F + 10^{-16}}\n$$\nFor a perfectly linear implementation, the numerator $F(y_0 + \\varepsilon v) - F(y_0) - \\varepsilon F(v) = (F(y_0) + \\varepsilon F(v)) - F(y_0) - \\varepsilon F(v)$ would be zero. Thus, $E_{\\mathrm{diff}}$ is also expected to be near machine precision, confirming the linearity of the implementation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and validates a discrete 2D Radon transform model.\n    \"\"\"\n\n    class TomographyModel:\n        \"\"\"\n        Encapsulates the discrete operators for parallel-beam tomography.\n        \"\"\"\n        def __init__(self, N: int, K: int, M: int, N_v: int):\n            self.N, self.K, self.M, self.N_v = N, K, M, N_v\n            \n            self.L = np.sqrt(2.0)\n            self.delta = 2.0 / N\n\n            self.thetas = np.linspace(0, np.pi, K, endpoint=False)\n            self.s_coords = np.linspace(-self.L, self.L, M) if M > 1 else np.array([0.0])\n            self.v_coords = np.linspace(-self.L, self.L, N_v) if N_v > 1 else np.array([0.0])\n            \n            self.dv = (2 * self.L) / (N_v - 1) if N_v > 1 else 2 * self.L\n\n        def _get_pixel_value(self, img: np.ndarray, i: int, j: int) -> float:\n            if 0 <= i < self.N and 0 <= j < self.N:\n                return img[i, j]\n            return 0.0\n\n        def radon(self, img: np.ndarray) -> np.ndarray:\n            \"\"\"Discrete Radon Transform (Forward Projection).\"\"\"\n            sino = np.zeros((self.K, self.M))\n\n            for k, theta in enumerate(self.thetas):\n                ct, st = np.cos(theta), np.sin(theta)\n                for m, s in enumerate(self.s_coords):\n                    line_integral = 0.0\n                    for v in self.v_coords:\n                        x = s * ct - v * st\n                        y = s * st + v * ct\n\n                        if abs(x) > 1.0 or abs(y) > 1.0:\n                            continue\n\n                        ix = (x + 1.0) / self.delta - 0.5\n                        iy = (y + 1.0) / self.delta - 0.5\n                        \n                        ix0 = int(np.floor(ix))\n                        iy0 = int(np.floor(iy))\n                        \n                        tx = ix - ix0\n                        ty = iy - iy0\n\n                        v00 = self._get_pixel_value(img, iy0, ix0)\n                        v01 = self._get_pixel_value(img, iy0, ix0 + 1)\n                        v10 = self._get_pixel_value(img, iy0 + 1, ix0)\n                        v11 = self._get_pixel_value(img, iy0 + 1, ix0 + 1)\n                        \n                        interp_val = (v00 * (1 - tx) * (1 - ty) +\n                                      v01 * tx * (1 - ty) +\n                                      v10 * (1 - tx) * ty +\n                                      v11 * tx * ty)\n                        \n                        line_integral += interp_val\n                    \n                    sino[k, m] = line_integral * self.dv\n            return sino\n\n        def back_project(self, sino: np.ndarray) -> np.ndarray:\n            \"\"\"Discrete Back-Projection (Adjoint of Radon).\"\"\"\n            recon = np.zeros((self.N, self.N))\n            \n            for k, theta in enumerate(self.thetas):\n                ct, st = np.cos(theta), np.sin(theta)\n                for m, s in enumerate(self.s_coords):\n                    val_to_add = sino[k, m] * self.dv\n                    if val_to_add == 0:\n                        continue\n\n                    for v in self.v_coords:\n                        x = s * ct - v * st\n                        y = s * st + v * ct\n\n                        if abs(x) > 1.0 or abs(y) > 1.0:\n                            continue\n\n                        ix = (x + 1.0) / self.delta - 0.5\n                        iy = (y + 1.0) / self.delta - 0.5\n                        \n                        ix0 = int(np.floor(ix))\n                        iy0 = int(np.floor(iy))\n                        \n                        tx = ix - ix0\n                        ty = iy - iy0\n                        \n                        w00 = (1 - tx) * (1 - ty)\n                        w01 = tx * (1 - ty)\n                        w10 = (1 - tx) * ty\n                        w11 = tx * ty\n\n                        ix1 = ix0 + 1\n                        iy1 = iy0 + 1\n                        \n                        if 0 <= iy0 < self.N and 0 <= ix0 < self.N: recon[iy0, ix0] += w00 * val_to_add\n                        if 0 <= iy0 < self.N and 0 <= ix1 < self.N: recon[iy0, ix1] += w01 * val_to_add\n                        if 0 <= iy1 < self.N and 0 <= ix0 < self.N: recon[iy1, ix0] += w10 * val_to_add\n                        if 0 <= iy1 < self.N and 0 <= ix1 < self.N: recon[iy1, ix1] += w11 * val_to_add\n            return recon\n\n        def filter_sinogram(self, sino: np.ndarray) -> np.ndarray:\n            \"\"\"Ramp filtering of the sinogram.\"\"\"\n            if self.M <= 1:\n                return np.zeros_like(sino)\n\n            ds = (2 * self.L) / (self.M - 1)\n            omega = np.fft.fftfreq(self.M, d=ds)\n            ramp = np.abs(omega)\n            \n            filtered_sino = np.zeros_like(sino, dtype=float)\n            for k in range(self.K):\n                row_fft = np.fft.fft(sino[k, :])\n                filtered_row_fft = row_fft * ramp\n                filtered_row = np.fft.ifft(filtered_row_fft)\n                filtered_sino[k, :] = np.real(filtered_row)\n                \n            return filtered_sino\n\n        def fbp(self, sino: np.ndarray) -> np.ndarray:\n            \"\"\"Filtered Back-Projection.\"\"\"\n            return self.back_project(self.filter_sinogram(sino))\n\n    test_cases = [\n        {'N': 32, 'K': 30, 'M': 45, 'N_v': 201, 'eps': 1e-5, 'seed': 1},\n        {'N': 16, 'K': 1, 'M': 23, 'N_v': 121, 'eps': 1e-5, 'seed': 2},\n        {'N': 28, 'K': 19, 'M': 29, 'N_v': 151, 'eps': 1e-5, 'seed': 3},\n    ]\n\n    results = []\n    for case in test_cases:\n        N, K, M, N_v = case['N'], case['K'], case['M'], case['N_v']\n        eps, seed = case['eps'], case['seed']\n        \n        model = TomographyModel(N, K, M, N_v)\n        rng = np.random.default_rng(seed)\n\n        # 1. Adjoint Test\n        f = rng.standard_normal(size=(N, N))\n        y = rng.standard_normal(size=(K, M))\n        \n        Rf = model.radon(f)\n        By = model.back_project(y)\n        \n        inner_prod_sin = np.sum(Rf * y)\n        inner_prod_img = np.sum(f * By)\n        \n        E_adj_num = np.abs(inner_prod_sin - inner_prod_img)\n        E_adj_den = np.abs(inner_prod_sin) + np.abs(inner_prod_img) + 1e-12\n        E_adj = E_adj_num / E_adj_den\n        results.append(E_adj)\n\n        # 2. Differentiability Test\n        y0 = rng.standard_normal(size=(K, M))\n        v = rng.standard_normal(size=(K, M))\n\n        Fy0 = model.fbp(y0)\n        F_y0_eps_v = model.fbp(y0 + eps * v)\n        Fv = model.fbp(v)\n        \n        numerator = np.linalg.norm(F_y0_eps_v - Fy0 - eps * Fv)\n        denominator = np.linalg.norm(eps * Fv) + 1e-16\n        E_diff = numerator / denominator\n        results.append(E_diff)\n        \n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A reconstructed image is only as good as the data it comes from, and real-world data is always noisy. This practice tackles the crucial task of uncertainty quantification by propagating the statistical properties of measurement noise through the FBP reconstruction process . You will derive and implement a method to calculate the per-pixel variance in the final image, providing a map of confidence in the reconstruction, and then validate your analytical results against the empirical variance from Monte Carlo simulations.",
            "id": "3416055",
            "problem": "You are given a linear image reconstruction setting based on the Radon transform and Filtered Back-Projection (FBP) in parallel-beam geometry. Let an unknown image be a real-valued function $f(x,y)$ supported on the square $[-1,1]\\times[-1,1]$. The Radon transform $R f(\\theta,s)$ at angle $\\theta$ and signed detector coordinate $s$ is defined by integrating $f$ along lines orthogonal to the unit direction $\\boldsymbol{n}(\\theta) = (\\cos\\theta,\\sin\\theta)$:\n$$\nR f(\\theta,s) = \\int_{\\mathbb{R}^2} f(x,y)\\,\\delta\\big(s - x\\cos\\theta - y\\sin\\theta\\big)\\,dx\\,dy,\n$$\nwhere $\\delta(\\cdot)$ denotes the Dirac delta distribution. The Filtered Back-Projection (FBP) reconstructs an approximation $\\hat{f}(x,y)$ of $f(x,y)$ by first applying a one-dimensional high-pass filter to $R f(\\theta,\\cdot)$ along $s$ for each fixed $\\theta$, followed by angular back-projection. In the discrete setting, we sample angles $\\{\\theta_k\\}_{k=0}^{K-1}$ uniformly from $[0,\\pi)$ in radians and detector coordinates $\\{s_j\\}_{j=0}^{D-1}$ uniformly covering $[-s_{\\max}, s_{\\max}]$. The discretized sinogram is an array $g_{k,j} \\approx R f(\\theta_k, s_j)$.\n\nAssume additive, zero-mean Gaussian measurement noise with known covariance over the discretized sinogram. Let the measured data be $m_{k,j} = g_{k,j} + \\eta_{k,j}$ with $\\mathbb{E}[\\eta_{k,j}] = 0$ and covariance matrix $\\Sigma \\in \\mathbb{R}^{(K D)\\times(K D)}$. The FBP mapping from $m$ to the reconstruction $\\hat{f}$ is linear, and can be written as a single linear operator from the vectorized sinogram to the vectorized image.\n\nYour task is to derive, implement, and validate uncertainty propagation through FBP, specifically:\n- Derive, from first principles, how the measurement covariance $\\Sigma$ propagates through the FBP linear operator to yield a per-pixel variance map of the reconstruction $\\hat{f}$.\n- Implement a discrete FBP with a ramp-like high-pass filter along the detector coordinate, using Discrete Fourier Transform-based filtering for each angle and periodic interpolation when back-projecting.\n- Predict per-pixel variance maps by propagating the known measurement covariance through the implemented discrete FBP operator.\n- Validate the predicted per-pixel variance maps against Monte Carlo reconstructions by performing repeated FBP reconstructions with independent Gaussian noise realizations and computing sample variances per pixel. Compare the predicted and empirical variance maps using quantitative metrics.\n\nAngle units in all computations must be in radians. Discretization and geometry details:\n- Use a square image grid of size $N\\times N$ with $N$ specified per test case, covering coordinates $(x,y)\\in[-1,1]\\times[-1,1]$ uniformly.\n- Use $K$ uniformly spaced angles $\\theta_k = k\\,\\pi/K$ for $k\\in\\{0,1,\\dots,K-1\\}$.\n- Use $D$ detector samples covering $[-s_{\\max}, s_{\\max}]$ with $s_{\\max} = 1$, uniformly spaced with spacing $\\Delta s = 2 s_{\\max}/(D-1)$.\n- Use periodic interpolation in detector index space when back-projecting filtered projections to pixels.\n\nNoise models to be used:\n- Independently and identically distributed (i.i.d.) Gaussian noise across all $(k,j)$ with variance $\\sigma^2$.\n- Angle-dependent heteroskedastic Gaussian noise with variance $\\sigma_k^2$ that varies with $\\theta_k$ but is constant across detector index $j$ at fixed $k$.\n- A boundary case with zero noise.\n\nYou must use the following test suite with fixed parameters:\n- Test case $1$ (happy path): $N=32$, $K=18$, $D=64$, $\\sigma^2 = 10^{-4}$, Monte Carlo replicates $M=200$.\n- Test case $2$ (heteroskedastic): $N=32$, $K=18$, $D=64$, angle-dependent variance $\\sigma_k^2 = 10^{-4}\\,\\big(1 + 0.5\\,\\sin\\theta_k\\big)$, Monte Carlo replicates $M=200$.\n- Test case $3$ (boundary): $N=32$, $K=18$, $D=64$, $\\sigma^2 = 0$, Monte Carlo replicates $M=50$.\n\nFor scientific realism, implement a nontrivial phantom $f(x,y)$ (for example, a sum of Gaussian bumps) to generate a baseline sinogram $g_{k,j}\\approx R f(\\theta_k,s_j)$ for the Monte Carlo reconstructions. However, note that for a linear FBP operator and additive zero-mean noise, the per-pixel variance of $\\hat{f}$ depends only on the noise statistics and the operator, not on the phantom.\n\nYour program must:\n- Construct the discrete FBP operator implicitly and predict the per-pixel variance map by propagating measurement covariance through the operator, without forming dense matrices larger than necessary.\n- Validate the prediction with Monte Carlo simulations as described, computing two metrics for each test case: the root-mean-square difference (RMSD) between predicted and empirical per-pixel variances over all $N^2$ pixels, and the maximum absolute difference (MAXD).\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order $[\\text{RMSD}_1,\\text{MAXD}_1,\\text{RMSD}_2,\\text{MAXD}_2,\\text{RMSD}_3,\\text{MAXD}_3]$, where subscripts correspond to the test case numbers.\n\nAll answers are pure numerical values. Angles must be in radians, and there are no physical units to report. The final program must be self-contained and executable as is.",
            "solution": "The present problem requires the derivation and implementation of uncertainty propagation for the Filtered Back-Projection (FBP) algorithm in computed tomography. We will first derive the theoretical framework for propagating measurement noise covariance through the linear FBP operator to obtain a per-pixel variance map. Subsequently, we will validate this theoretical prediction against empirical results from Monte Carlo simulations.\n\n### 1. Theoretical Derivation of Variance Propagation\n\nThe Filtered Back-Projection (FBP) algorithm is a linear procedure. Let the discrete, measured sinogram be represented by a vectorized column vector $\\mathbf{m} \\in \\mathbb{R}^{KD}$, where $K$ is the number of projection angles and $D$ is the number of detector elements per angle. Similarly, let the reconstructed image be represented by a vectorized vector $\\hat{\\mathbf{f}} \\in \\mathbb{R}^{N^2}$, where the image is of size $N \\times N$. The linearity of FBP allows us to express the reconstruction process as a matrix-vector product:\n$$\n\\hat{\\mathbf{f}} = \\mathbf{L} \\mathbf{m}\n$$\nwhere $\\mathbf{L} \\in \\mathbb{R}^{N^2 \\times KD}$ is the linear operator representing the entire FBP pipeline (filtering and back-projection).\n\nThe measurement model is given as additive, zero-mean Gaussian noise:\n$$\n\\mathbf{m} = \\mathbf{g} + \\mathbf{\\eta}\n$$\nwhere $\\mathbf{g}$ is the true, noise-free sinogram and $\\mathbf{\\eta}$ is the noise vector with $\\mathbb{E}[\\mathbf{\\eta}] = \\mathbf{0}$. The covariance of the measurement noise is given by the matrix $\\Sigma_m = \\mathbb{E}[\\mathbf{\\eta}\\mathbf{\\eta}^T] \\in \\mathbb{R}^{KD \\times KD}$.\n\nThe reconstructed image can be expressed in terms of the true sinogram and the noise:\n$$\n\\hat{\\mathbf{f}} = \\mathbf{L}(\\mathbf{g} + \\mathbf{\\eta}) = \\mathbf{L}\\mathbf{g} + \\mathbf{L}\\mathbf{\\eta}\n$$\nThe term $\\mathbf{L}\\mathbf{g}$ represents the ideal reconstruction from noise-free data, which we can denote as $\\mathbf{f}_{\\text{ideal}}$. The term $\\mathbf{L}\\mathbf{\\eta}$ represents the noise component in the reconstructed image. The expected value of the reconstruction is $\\mathbb{E}[\\hat{\\mathbf{f}}] = \\mathbf{L}\\mathbf{g} + \\mathbf{L}\\mathbb{E}[\\mathbf{\\eta}] = \\mathbf{f}_{\\text{ideal}}$.\n\nThe covariance of the reconstructed image, $\\Sigma_f \\in \\mathbb{R}^{N^2 \\times N^2}$, is then derived as follows:\n$$\n\\Sigma_f = \\mathbb{E}\\left[ (\\hat{\\mathbf{f}} - \\mathbb{E}[\\hat{\\mathbf{f}}]) (\\hat{\\mathbf{f}} - \\mathbb{E}[\\hat{\\mathbf{f}}])^T \\right] = \\mathbb{E}\\left[ (\\mathbf{L}\\mathbf{\\eta}) (\\mathbf{L}\\mathbf{\\eta})^T \\right]\n$$\n$$\n\\Sigma_f = \\mathbb{E}\\left[ \\mathbf{L}\\mathbf{\\eta}\\mathbf{\\eta}^T\\mathbf{L}^T \\right] = \\mathbf{L} \\mathbb{E}\\left[\\mathbf{\\eta}\\mathbf{\\eta}^T\\right] \\mathbf{L}^T\n$$\nThis yields the central formula for linear covariance propagation:\n$$\n\\Sigma_f = \\mathbf{L} \\Sigma_m \\mathbf{L}^T\n$$\nOur goal is to compute the per-pixel variance of the reconstruction, which corresponds to the diagonal elements of the image covariance matrix $\\Sigma_f$. Let $p$ be the index of a pixel in the vectorized image, running from $0$ to $N^2-1$. The variance of the $p$-th pixel is $(\\Sigma_f)_{pp}$.\n\nThe noise models specified in the problem (i.i.d. and angle-dependent) result in a diagonal measurement covariance matrix $\\Sigma_m$. Let $\\sigma_{k,j}^2$ be the variance of the measurement at angle $\\theta_k$ and detector position $s_j$. Then $\\Sigma_m = \\text{diag}(\\{\\sigma_{k,j}^2\\})$, where the variances are ordered consistently with the vectorization of the sinogram.\n\nThe variance of the $p$-th pixel is:\n$$\n\\text{Var}(\\hat{f}_p) = (\\mathbf{L} \\Sigma_m \\mathbf{L}^T)_{pp} = \\sum_{i=0}^{KD-1} \\sum_{j=0}^{KD-1} L_{pi} (\\Sigma_m)_{ij} L_{pj}\n$$\nSince $\\Sigma_m$ is diagonal, $(\\Sigma_m)_{ij} = \\sigma_i^2 \\delta_{ij}$ (using a single index $i$ for $(k,j)$). The expression simplifies to:\n$$\n\\text{Var}(\\hat{f}_p) = \\sum_{i=0}^{KD-1} L_{pi}^2 \\sigma_i^2\n$$\nReverting to double indices $(k,j)$ for clarity, where $i$ corresponds to $(k,j)$:\n$$\n\\text{Var}(\\hat{f}_p) = \\sum_{k=0}^{K-1} \\sum_{j=0}^{D-1} \\left(L_{p, (k,j)}\\right)^2 \\sigma_{k,j}^2\n$$\nwhere $L_{p, (k,j)}$ is the element of the operator $\\mathbf{L}$ that maps the sinogram value at $(k,j)$ to the image pixel $p$.\n\n### 2. Algorithmic Implementation for Variance Prediction\n\nConstructing the full matrix $\\mathbf{L}$ is computationally prohibitive. A more practical \"matrix-free\" approach is needed. The expression for $\\text{Var}(\\hat{f}_p)$ can be interpreted algorithmically. Let $\\mathbf{c}_{k,j} = \\mathbf{L}\\boldsymbol{\\delta}_{k,j}$ be the $ (k,j) $-th column of the matrix $\\mathbf{L}$. This column vector is precisely the reconstructed image obtained by applying the FBP algorithm to a \"delta sinogram\"—a sinogram that is zero everywhere except for a value of $1$ at projection angle $\\theta_k$ and detector bin $s_j$. The elements of this vector are $ (c_{k,j})_p = L_{p, (k,j)} $.\n\nSubstituting this into the variance formula, the pixel variance becomes a sum over all sinogram bins:\n$$\n\\text{Var}(\\hat{f}_p) = \\sum_{k=0}^{K-1} \\sum_{j=0}^{D-1} \\sigma_{k,j}^2 \\left( (c_{k,j})_p \\right)^2\n$$\nThis formula suggests a direct algorithm to compute the entire variance map $\\mathbf{V}$, where $V_p = \\text{Var}(\\hat{f}_p)$:\n1. Initialize a variance map $\\mathbf{V}$ of size $N \\times N$ to all zeros.\n2. For each sinogram bin $(k,j)$ from $k=0, \\dots, K-1$ and $j=0, \\dots, D-1$:\n    a. Create a delta sinogram $\\boldsymbol{\\delta}_{k,j}$ of size $K \\times D$.\n    b. Apply the FBP reconstruction algorithm to $\\boldsymbol{\\delta}_{k,j}$ to obtain the image $\\mathbf{c}_{k,j}$.\n    c. Square this image element-wise: $\\mathbf{c}_{k,j} \\odot \\mathbf{c}_{k,j}$.\n    d. Multiply by the corresponding noise variance $\\sigma_{k,j}^2$ and add the result to the total variance map: $\\mathbf{V} \\leftarrow \\mathbf{V} + \\sigma_{k,j}^2 (\\mathbf{c}_{k,j} \\odot \\mathbf{c}_{k,j})$.\n\nThis procedure computes the exact theoretical variance map without storing the operator $\\mathbf{L}$, fulfilling the problem's constraint.\n\n### 3. FBP and Monte Carlo Validation\n\nThe implementation will consist of the following components:\n- **FBP Algorithm**: A function that takes a $K \\times D$ sinogram and returns an $N \\times N$ image.\n    - **Filtering**: For each of the $K$ projections, a 1D high-pass ramp filter is applied. This is efficiently implemented in the Fourier domain using the Fast Fourier Transform (FFT). The filter is defined in frequency space as being proportional to the absolute value of the frequency, i.e., $|\\nu|$.\n    - **Back-projection**: The filtered projections are then back-projected onto the image grid. For each pixel $(x,y)$ and angle $\\theta_k$, the corresponding detector coordinate $s' = x\\cos\\theta_k + y\\sin\\theta_k$ is calculated. The value of the filtered projection at $s'$ is found using periodic linear interpolation over the detector indices, as specified. The contributions from all angles are summed up for each pixel, followed by a final normalization constant (we use $\\pi/(2K)$).\n- **Variance Prediction**: The algorithm derived in Section 2 is implemented, which repeatedly calls the FBP function.\n- **Monte Carlo Validation**: To validate the predicted variance, we perform a Monte Carlo simulation.\n    1. A noise-free \"ground truth\" sinogram $\\mathbf{g}$ is generated from an analytical phantom (a sum of Gaussians, whose Radon transform is also a sum of Gaussians).\n    2. A large number ($M$) of independent noise realizations $\\mathbf{\\eta}^{(i)}$ are generated according to the specified noise covariance $\\Sigma_m$.\n    3. For each realization, a noisy sinogram $\\mathbf{m}^{(i)} = \\mathbf{g} + \\mathbf{\\eta}^{(i)}$ is created.\n    4. Each $\\mathbf{m}^{(i)}$ is reconstructed using the same FBP algorithm, yielding a set of $M$ reconstructed images $\\{\\hat{\\mathbf{f}}^{(i)}\\}_{i=1}^M$.\n    5. The sample variance is computed for each pixel across the $M$ reconstructions. This produces an empirical variance map.\n- **Comparison**: The theoretically predicted variance map is compared with the empirical variance map from the Monte Carlo simulation using the Root-Mean-Square Difference (RMSD) and the Maximum Absolute Difference (MAXD) as metrics. The zero-noise test case serves as a crucial sanity check, where both predicted and empirical variances should be identically zero.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for FBP uncertainty propagation.\n    \"\"\"\n\n    def get_fbp_reconstruction(sinogram, N, K, D):\n        \"\"\"\n        Performs Filtered Back-Projection (FBP) reconstruction.\n        \n        Args:\n            sinogram (np.ndarray): The input sinogram of shape (K, D).\n            N (int): The side length of the square output image.\n            K (int): The number of projection angles.\n            D (int): The number of detector bins.\n        \n        Returns:\n            np.ndarray: The reconstructed image of shape (N, N).\n        \"\"\"\n        # Define image and sinogram coordinates\n        image_coords = np.linspace(-1.0, 1.0, N)\n        xx, yy = np.meshgrid(image_coords, image_coords)\n        \n        thetas = np.linspace(0.0, np.pi, K, endpoint=False)\n        detector_spacing = 2.0 / (D - 1) if D > 1 else 0\n\n        # Create ramp filter in Fourier domain\n        # A simple |f| filter. Normalization is handled by using the same FBP\n        # for prediction and MC.\n        ramp_filter = np.abs(np.fft.rfftfreq(D))\n        \n        # Filter projections\n        filtered_sinogram = np.zeros_like(sinogram)\n        for i in range(K):\n            projection = sinogram[i, :]\n            projection_fft = np.fft.rfft(projection)\n            filtered_projection_fft = projection_fft * ramp_filter\n            filtered_sinogram[i, :] = np.fft.irfft(filtered_projection_fft, n=D)\n            \n        # Back-project\n        reconstructed_image = np.zeros((N, N), dtype=np.float64)\n        detector_indices = np.arange(D)\n        \n        for i in range(K):\n            theta = thetas[i]\n            # Coordinates in the detector space for each pixel\n            s_coords = xx * np.cos(theta) + yy * np.sin(theta)\n            \n            # Map s_coords to fractional detector indices for interpolation\n            # s = -1 + j * ds => j = (s + 1) / ds\n            if detector_spacing > 0:\n                j_float = (s_coords + 1.0) / detector_spacing\n            else:\n                j_float = np.full((N,N), (D-1)/2.0)\n\n            # Periodic interpolation\n            interpolated_projection = np.interp(\n                j_float.ravel(),\n                detector_indices,\n                filtered_sinogram[i, :],\n                period=D\n            ).reshape(N, N)\n            \n            reconstructed_image += interpolated_projection\n\n        # Normalization constant for FBP\n        reconstructed_image *= np.pi / (2.0 * K)\n            \n        return reconstructed_image\n\n    def predict_variance(noise_variances, N, K, D):\n        \"\"\"\n        Predicts the per-pixel variance map using the derived formula.\n        \n        Args:\n            noise_variances (np.ndarray): Per-measurement variance, shape (K, D).\n            N (int): Image size.\n            K (int): Number of angles.\n            D (int): Number of detector bins.\n        \n        Returns:\n            np.ndarray: The predicted variance map of shape (N, N).\n        \"\"\"\n        total_variance_map = np.zeros((N, N), dtype=np.float64)\n        \n        for k_in in range(K):\n            for j_in in range(D):\n                if noise_variances[k_in, j_in] == 0:\n                    continue\n                \n                # Create a delta sinogram\n                delta_sino = np.zeros((K, D))\n                delta_sino[k_in, j_in] = 1.0\n                \n                # Reconstruct the image from the delta sinogram -> column of L\n                img_c_kj = get_fbp_reconstruction(delta_sino, N, K, D)\n                \n                # Accumulate variance\n                total_variance_map += noise_variances[k_in, j_in] * (img_c_kj ** 2)\n                \n        return total_variance_map\n\n    def create_phantom_sinogram(K, D):\n        \"\"\"\n        Generates a ground-truth sinogram from an analytical phantom.\n        The phantom is a sum of two Gaussian bumps.\n        \n        Args:\n            K (int): Number of angles.\n            D (int): Number of detector bins.\n        \n        Returns:\n            np.ndarray: The ground-truth sinogram of shape (K, D).\n        \"\"\"\n        thetas = np.linspace(0.0, np.pi, K, endpoint=False)\n        s_coords = np.linspace(-1.0, 1.0, D)\n        \n        # Phantom parameters: (Amplitude, x0, y0, sigma)\n        gaussians = [\n            (1.0, 0.3, 0.2, 0.1),\n            (0.5, -0.5, 0.4, 0.08)\n        ]\n        \n        sinogram = np.zeros((K, D))\n        \n        for A, x0, y0, sigma in gaussians:\n            for i, theta in enumerate(thetas):\n                s0_theta = x0 * np.cos(theta) + y0 * np.sin(theta)\n                # Radon transform of an isotropic Gaussian\n                projection = A * np.sqrt(2 * np.pi) * sigma * np.exp(-(s_coords - s0_theta)**2 / (2 * sigma**2))\n                sinogram[i, :] += projection\n\n        return sinogram\n\n    def run_monte_carlo(base_sinogram, noise_variances, M, N, K, D):\n        \"\"\"\n        Runs Monte Carlo simulation to find the empirical variance map.\n        \n        Args:\n            base_sinogram (np.ndarray): Ground-truth sinogram.\n            noise_variances (np.ndarray): Per-measurement variance.\n            M (int): Number of Monte Carlo replicates.\n            N, K, D (int): Geometry parameters.\n        \n        Returns:\n            np.ndarray: The empirical variance map of shape (N, N).\n        \"\"\"\n        if M == 0 or np.all(noise_variances == 0):\n            return np.zeros((N, N))\n\n        reconstructions = np.zeros((M, N, N))\n        noise_stds = np.sqrt(noise_variances)\n        \n        # for reproducible results\n        rng = np.random.default_rng(seed=42)\n\n        for i in range(M):\n            noise = rng.normal(0.0, noise_stds, size=(K, D))\n            noisy_sinogram = base_sinogram + noise\n            reconstructions[i, :, :] = get_fbp_reconstruction(noisy_sinogram, N, K, D)\n            \n        empirical_variance_map = np.var(reconstructions, axis=0, ddof=1)\n        return empirical_variance_map\n\n    test_cases = [\n        # (N, K, D, M, noise_params, case_type)\n        (32, 18, 64, 200, {'sigma_sq': 1e-4}, 'iid'),\n        (32, 18, 64, 200, {}, 'heteroskedastic'),\n        (32, 18, 64, 50,  {'sigma_sq': 0.0}, 'zero_noise')\n    ]\n\n    results = []\n    \n    # Pre-calculate base sinogram\n    base_sinogram = create_phantom_sinogram(test_cases[0][1], test_cases[0][2])\n\n    for N, K, D, M, params, case_type in test_cases:\n        thetas = np.linspace(0.0, np.pi, K, endpoint=False)\n        \n        if case_type == 'iid':\n            noise_variances = np.full((K, D), params['sigma_sq'])\n        elif case_type == 'heteroskedastic':\n            # Angle-dependent variance: sigma_k^2 = 1e-4 * (1 + 0.5 * sin(theta_k))\n            var_k = 1e-4 * (1.0 + 0.5 * np.sin(thetas))\n            noise_variances = np.tile(var_k[:, np.newaxis], (1, D))\n        elif case_type == 'zero_noise':\n            noise_variances = np.full((K, D), params['sigma_sq'])\n\n        # Predict variance\n        predicted_var = predict_variance(noise_variances, N, K, D)\n        \n        # Run Monte Carlo to get empirical variance\n        empirical_var = run_monte_carlo(base_sinogram, noise_variances, M, N, K, D)\n\n        # Calculate metrics\n        diff = predicted_var - empirical_var\n        rmsd = np.sqrt(np.mean(diff**2))\n        maxd = np.max(np.abs(diff))\n        \n        results.extend([rmsd, maxd])\n        \n    print(f\"[{','.join(f'{r:.8e}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}