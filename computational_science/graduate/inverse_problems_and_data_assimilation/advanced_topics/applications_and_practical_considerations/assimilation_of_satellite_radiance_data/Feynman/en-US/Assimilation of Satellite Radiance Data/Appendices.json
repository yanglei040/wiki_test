{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of modern data assimilation is the linearization of complex, non-linear physical models, such as radiative transfer models (RTMs). This allows us to use the powerful framework of linear-Gaussian estimation theory. However, this simplification is only an approximation. This practice provides a direct, hands-on method to probe the limits of this assumption by exploring the validity of the tangent-linear approximation for a simplified RTM, helping you develop an intuition for when and why nonlinearity becomes significant in radiance assimilation .",
            "id": "3365135",
            "problem": "Consider the assimilation of satellite nadir-view thermal infrared radiances from a single spectral channel over a horizontally homogeneous, clear-sky, isothermal humid layer above a surface. Let the observation operator map the atmospheric state to the Top Of Atmosphere (TOA) monochromatic radiance using the following physically based ingredients:\n\n1. Beer–Lambert law for absorption along the line of sight. For nadir geometry (cosine of zenith angle equal to $1$), the layer transmittance is\n$$\n\\tau(q) = \\exp\\left(- \\kappa_\\nu \\, q \\, M_{\\text{air}}\\right),\n$$\nwhere $q$ is the specific humidity in $\\mathrm{kg}\\,\\mathrm{kg}^{-1}$, $\\kappa_\\nu$ is the mass absorption coefficient for water vapor at the channel wavenumber in $\\mathrm{m}^2\\,\\mathrm{kg}^{-1}$, and $M_{\\text{air}}$ is the layer air mass per unit area in $\\mathrm{kg}\\,\\mathrm{m}^{-2}$.\n\n2. Planck’s law for spectral radiance as a function of absolute temperature, written in the wavenumber domain (spectral radiance per unit wavenumber):\n$$\nB_{\\tilde{\\nu}}(T) = \\frac{2 h c^2 \\tilde{\\nu}^3}{\\exp\\!\\left(\\frac{h c \\tilde{\\nu}}{k_B T}\\right) - 1},\n$$\nwhere $h$ is Planck’s constant in $\\mathrm{J}\\,\\mathrm{s}$, $c$ is the speed of light in $\\mathrm{m}\\,\\mathrm{s}^{-1}$, $k_B$ is Boltzmann’s constant in $\\mathrm{J}\\,\\mathrm{K}^{-1}$, $\\tilde{\\nu}$ is the wavenumber in $\\mathrm{m}^{-1}$, and $T$ is temperature in $\\mathrm{K}$. The units of $B_{\\tilde{\\nu}}$ are $\\mathrm{W}\\,\\mathrm{m}^{-2}\\,\\mathrm{sr}^{-1}\\,(\\mathrm{m}^{-1})^{-1}$.\n\n3. Surface is a Lambertian emitter with emissivity $\\varepsilon_s$ (dimensionless), surface temperature $T_s$, and the layer is isothermal at temperature $T_\\ell$. For nadir view and clear sky, the TOA monochromatic radiance is\n$$\nH(q) = \\varepsilon_s \\, B_{\\tilde{\\nu}}(T_s)\\, \\tau(q) + \\left(1 - \\tau(q)\\right) B_{\\tilde{\\nu}}(T_\\ell).\n$$\n\nYou are asked to test the validity of the Tangent-Linear (TL) approximation of the observation operator in finite-perturbation experiments. Let the background specific humidity be $q_b$. For a perturbation $\\delta q$, define the TL linearization of $H$ around $q_b$ by\n$$\nH(q_b + \\delta q) \\approx H(q_b) + K\\, \\delta q,\n$$\nwhere $K$ is the TL operator (the derivative of $H$ with respect to $q$ evaluated at $q_b$). Your tasks are:\n\n- Starting strictly from the definitions above and standard differentiation rules, derive an analytical expression for $K$ at $q_b$ in terms of the given physical parameters. Do not introduce any unphysical approximations beyond the assumptions stated.\n\n- For each perturbation $\\delta q$, compute the nonlinearity indicator (relative TL error)\n$$\n\\mathcal{E}_{\\text{rel}}(\\delta q) = \\frac{\\left|H(q_b+\\delta q) - H(q_b) - K\\,\\delta q\\right|}{\\left|H(q_b+\\delta q) - H(q_b)\\right|},\n$$\nwith the convention that if the denominator equals zero, then $\\mathcal{E}_{\\text{rel}}(\\delta q)$ is defined to be $0$.\n\n- For each test case below, return a single scalar equal to the maximum of $\\mathcal{E}_{\\text{rel}}(\\delta q)$ over the provided list of perturbations in that test case.\n\nPhysical constants and units:\n- Use $h = 6.62607015\\times 10^{-34}\\ \\mathrm{J}\\,\\mathrm{s}$, $c = 2.99792458\\times 10^{8}\\ \\mathrm{m}\\,\\mathrm{s}^{-1}$, and $k_B = 1.380649\\times 10^{-23}\\ \\mathrm{J}\\,\\mathrm{K}^{-1}$.\n- Use a single channel with wavenumber $\\tilde{\\nu} = 1000\\ \\mathrm{cm}^{-1} = 100000\\ \\mathrm{m}^{-1}$.\n- All temperatures must be expressed in $\\mathrm{K}$, specific humidity $q$ and its perturbations $\\delta q$ in $\\mathrm{kg}\\,\\mathrm{kg}^{-1}$, mass absorption coefficient $\\kappa_\\nu$ in $\\mathrm{m}^2\\,\\mathrm{kg}^{-1}$, layer mass $M_{\\text{air}}$ in $\\mathrm{kg}\\,\\mathrm{m}^{-2}$, and radiances in $\\mathrm{W}\\,\\mathrm{m}^{-2}\\,\\mathrm{sr}^{-1}\\,(\\mathrm{m}^{-1})^{-1}$.\n\nTest suite:\n- Case $1$: $q_b = 0.005$, $T_\\ell = 280$, $T_s = 290$, $\\kappa_\\nu = 0.04$, $M_{\\text{air}} = 4000$, $\\varepsilon_s = 0.98$, $\\delta q \\in \\{10^{-6},\\,10^{-5},\\,10^{-4},\\,5\\times 10^{-4}\\}$.\n- Case $2$: $q_b = 0.015$, $T_\\ell = 270$, $T_s = 300$, $\\kappa_\\nu = 0.05$, $M_{\\text{air}} = 4000$, $\\varepsilon_s = 0.98$, $\\delta q \\in \\{10^{-5},\\,10^{-4},\\,10^{-3},\\,2\\times 10^{-3}\\}$.\n- Case $3$: $q_b = 0.020$, $T_\\ell = 295$, $T_s = 305$, $\\kappa_\\nu = 0.06$, $M_{\\text{air}} = 5000$, $\\varepsilon_s = 0.98$, $\\delta q \\in \\{-10^{-4},\\,-5\\times 10^{-4},\\,5\\times 10^{-4},\\,2\\times 10^{-3}\\}$.\n- Case $4$: $q_b = 0.025$, $T_\\ell = 260$, $T_s = 270$, $\\kappa_\\nu = 0.07$, $M_{\\text{air}} = 6000$, $\\varepsilon_s = 0.98$, $\\delta q \\in \\{10^{-3},\\,3\\times 10^{-3},\\,5\\times 10^{-3}\\}$.\n\nNumerical and output requirements:\n- For each test case, compute the maximum relative TL error across its $\\delta q$ values and round it to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the four cases, for example $[r_1,r_2,r_3,r_4]$, where each $r_i$ is a float rounded to $6$ decimal places.",
            "solution": "The problem is valid as it is scientifically grounded in established principles of atmospheric radiative transfer, is mathematically well-posed, and all necessary parameters and constants are provided for a unique solution. We proceed to solve the problem.\n\nThe solution involves two main parts: first, the analytical derivation of the Tangent-Linear (TL) operator, $K$, and second, the numerical implementation to compute the relative TL error for the given test cases.\n\n**1. Analytical Derivation of the Tangent-Linear Operator**\n\nThe Tangent-Linear operator $K$ is defined as the first derivative of the observation operator $H(q)$ with respect to the state variable $q$, evaluated at the background state $q_b$.\n$$K = \\frac{dH}{dq}\\bigg|_{q=q_b}$$\nThe observation operator for the Top Of Atmosphere (TOA) monochromatic radiance, $H(q)$, is given by:\n$$H(q) = \\varepsilon_s \\, B_{\\tilde{\\nu}}(T_s)\\, \\tau(q) + \\left(1 - \\tau(q)\\right) B_{\\tilde{\\nu}}(T_\\ell)$$\nwhere $\\varepsilon_s$ is the surface emissivity, $T_s$ is the surface temperature, $T_\\ell$ is the layer temperature, and $B_{\\tilde{\\nu}}(T)$ is the Planck function for radiance at wavenumber $\\tilde{\\nu}$ and temperature $T$. The dependence on the specific humidity $q$ is entirely through the layer transmittance, $\\tau(q)$.\n\nFor clarity in differentiation, we can rearrange the expression for $H(q)$:\n$$H(q) = \\tau(q) \\left[ \\varepsilon_s B_{\\tilde{\\nu}}(T_s) - B_{\\tilde{\\nu}}(T_\\ell) \\right] + B_{\\tilde{\\nu}}(T_\\ell)$$\nThe Planck function values, $B_{\\tilde{\\nu}}(T_s)$ and $B_{\\tilde{\\nu}}(T_\\ell)$, are constant with respect to $q$. We apply the chain rule to differentiate $H(q)$ with respect to $q$:\n$$\\frac{dH}{dq} = \\frac{d}{dq} \\left( \\tau(q) \\left[ \\varepsilon_s B_{\\tilde{\\nu}}(T_s) - B_{\\tilde{\\nu}}(T_\\ell) \\right] + B_{\\tilde{\\nu}}(T_\\ell) \\right)$$\n$$\\frac{dH}{dq} = \\left[ \\varepsilon_s B_{\\tilde{\\nu}}(T_s) - B_{\\tilde{\\nu}}(T_\\ell) \\right] \\frac{d\\tau}{dq}$$\nNext, we find the derivative of the transmittance $\\tau(q)$, which is defined by the Beer-Lambert law:\n$$\\tau(q) = \\exp\\left(- \\kappa_\\nu \\, q \\, M_{\\text{air}}\\right)$$\nwhere $\\kappa_\\nu$ is the mass absorption coefficient and $M_{\\text{air}}$ is the layer air mass per unit area. Differentiating $\\tau(q)$ with respect to $q$:\n$$\\frac{d\\tau}{dq} = \\frac{d}{dq} \\exp\\left(- \\kappa_\\nu \\, q \\, M_{\\text{air}}\\right)$$\nUsing the chain rule for the exponential function, where the argument of the exponent is a linear function of $q$:\n$$\\frac{d\\tau}{dq} = \\exp\\left(- \\kappa_\\nu \\, q \\, M_{\\text{air}}\\right) \\cdot \\frac{d}{dq}\\left(- \\kappa_\\nu \\, q \\, M_{\\text{air}}\\right)$$\n$$\\frac{d\\tau}{dq} = \\tau(q) \\cdot (-\\kappa_\\nu M_{\\text{air}})$$\nSubstituting this result back into the expression for $\\frac{dH}{dq}$:\n$$\\frac{dH}{dq} = \\left[ \\varepsilon_s B_{\\tilde{\\nu}}(T_s) - B_{\\tilde{\\nu}}(T_\\ell) \\right] \\cdot \\left[ -\\kappa_\\nu M_{\\text{air}} \\tau(q) \\right]$$\nThis expression can be rearranged as:\n$$\\frac{dH}{dq} = \\kappa_\\nu M_{\\text{air}} \\, \\tau(q) \\, \\left[ B_{\\tilde{\\nu}}(T_\\ell) - \\varepsilon_s B_{\\tilde{\\nu}}(T_s) \\right]$$\nThe Tangent-Linear operator $K$ is this derivative evaluated at the background specific humidity $q_b$:\n$$K = \\frac{dH}{dq}\\bigg|_{q=q_b} = \\kappa_\\nu M_{\\text{air}} \\, \\tau(q_b) \\, \\left[ B_{\\tilde{\\nu}}(T_\\ell) - \\varepsilon_s B_{\\tilde{\\nu}}(T_s) \\right]$$\nwhere $\\tau(q_b) = \\exp\\left(- \\kappa_\\nu \\, q_b \\, M_{\\text{air}}\\right)$. This is the final analytical expression for $K$.\n\n**2. Algorithmic Procedure for Numerical Calculation**\n\nFor each test case, we compute the maximum relative Tangent-Linear error, $\\mathcal{E}_{\\text{rel}}(\\delta q)$, over a list of perturbations $\\{\\delta q_i\\}$. The relative error is defined as:\n$$\\mathcal{E}_{\\text{rel}}(\\delta q) = \\frac{\\left|H(q_b+\\delta q) - H(q_b) - K\\,\\delta q\\right|}{\\left|H(q_b+\\delta q) - H(q_b)\\right|}$$\nThe algorithm proceeds as follows:\n1.  Set the physical constants: $h = 6.62607015\\times 10^{-34}\\ \\mathrm{J}\\,\\mathrm{s}$, $c = 2.99792458\\times 10^{8}\\ \\mathrm{m}\\,\\mathrm{s}^{-1}$, $k_B = 1.380649\\times 10^{-23}\\ \\mathrm{J}\\,\\mathrm{K}^{-1}$, and the wavenumber $\\tilde{\\nu} = 100000\\ \\mathrm{m}^{-1}$.\n2.  For each test case with its specific set of parameters ($q_b, T_\\ell, T_s, \\kappa_\\nu, M_{\\text{air}}, \\varepsilon_s$) and list of perturbations $\\{\\delta q_i\\}$:\n    a.  Calculate the Planck radiances for the layer, $B_\\ell = B_{\\tilde{\\nu}}(T_\\ell)$, and the surface, $B_s = B_{\\tilde{\\nu}}(T_s)$, using the Planck function formula:\n        $$B_{\\tilde{\\nu}}(T) = \\frac{2 h c^2 \\tilde{\\nu}^3}{\\exp\\!\\left(\\frac{h c \\tilde{\\nu}}{k_B T}\\right) - 1}$$\n    b.  Compute the background radiance $H_b = H(q_b)$ using the observation operator formula.\n    c.  Compute the Tangent-Linear operator $K$ using the derived analytical formula evaluated at $q_b$.\n    d.  Initialize an empty list to store the errors for the current case.\n    e.  For each perturbation $\\delta q$ in the list $\\{\\delta q_i\\}$:\n        i.  Calculate the perturbed state $q_p = q_b + \\delta q$.\n        ii. Calculate the true perturbed radiance $H_p = H(q_p)$.\n        iii. Calculate the numerator of the error term: $N = |H_p - H_b - K \\cdot \\delta q|$.\n        iv. Calculate the denominator of the error term: $D = |H_p - H_b|$.\n        v. If $D$ is zero, the relative error $\\mathcal{E}_{\\text{rel}}(\\delta q)$ is $0$. Otherwise, compute the error as $\\mathcal{E}_{\\text{rel}}(\\delta q) = N / D$.\n        vi. Append the calculated error to the list.\n    f.  Determine the maximum value from the list of calculated errors.\n    g.  Round this maximum error to $6$ decimal places and record it as the result for the test case.\n3.  Combine the results from all test cases into a single list and format the output as requested.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem by calculating the maximum relative \n    Tangent-Linear error for a set of test cases in satellite radiance assimilation.\n    \"\"\"\n\n    # Physical constants\n    H = 6.62607015e-34    # Planck's constant in J.s\n    C = 2.99792458e8      # Speed of light in m/s\n    KB = 1.380649e-23     # Boltzmann's constant in J/K\n    NU_TILDE = 100000.    # Wavenumber in m^-1 (from 1000 cm^-1)\n\n    # Pre-calculate constant parts of the Planck function for efficiency\n    C1 = 2 * H * C**2 * NU_TILDE**3\n    C2 = H * C * NU_TILDE / KB\n\n    def planck(T):\n        \"\"\"\n        Calculates the spectral radiance using Planck's law.\n        :param T: Temperature in Kelvin.\n        :return: Spectral radiance in W m^-2 sr^-1 (m^-1)^-1.\n        \"\"\"\n        # The argument to exp can be large, but temperatures are reasonable.\n        return C1 / (np.exp(C2 / T) - 1)\n\n    def transmittance(q, kappa_nu, M_air):\n        \"\"\"\n        Calculates the layer transmittance using the Beer-Lambert law.\n        :param q: Specific humidity in kg/kg.\n        :param kappa_nu: Mass absorption coefficient in m^2/kg.\n        :param M_air: Layer air mass per unit area in kg/m^2.\n        :return: Transmittance (dimensionless).\n        \"\"\"\n        optical_depth = kappa_nu * q * M_air\n        return np.exp(-optical_depth)\n\n    def H_operator(q, B_ell, B_s, kappa_nu, M_air, eps_s):\n        \"\"\"\n        The observation operator H(q).\n        :param q: Specific humidity in kg/kg.\n        :param B_ell: Pre-calculated layer Planck radiance.\n        :param B_s: Pre-calculated surface Planck radiance.\n        :param kappa_nu, M_air, eps_s: Other physical parameters.\n        :return: Top Of Atmosphere (TOA) radiance.\n        \"\"\"\n        tau = transmittance(q, kappa_nu, M_air)\n        return eps_s * B_s * tau + (1 - tau) * B_ell\n\n    def K_operator(q_b, B_ell, B_s, kappa_nu, M_air, eps_s):\n        \"\"\"\n        The Tangent-Linear operator K = dH/dq at q_b.\n        :param q_b: Background specific humidity.\n        :param B_ell, B_s: Pre-calculated Planck radiances.\n        :param kappa_nu, M_air, eps_s: Other physical parameters.\n        :return: Value of the Tangent-Linear operator K.\n        \"\"\"\n        tau_b = transmittance(q_b, kappa_nu, M_air)\n        # B_diff = eps_s * B_s - B_ell\n        # dtau_dq = -kappa_nu * M_air * tau_b\n        # return B_diff * dtau_dq\n        # Alternative form from derivation:\n        return kappa_nu * M_air * tau_b * (B_ell - eps_s * B_s)\n\n    def calculate_max_error(params):\n        \"\"\"\n        Calculates the maximum relative TL error for a single test case.\n        :param params: A tuple containing all parameters for the case.\n        :return: The maximum relative error, rounded to 6 decimal places.\n        \"\"\"\n        q_b, T_ell, T_s, kappa_nu, M_air, eps_s, delta_q_list = params\n        \n        # Pre-calculate Planck radiances for the case\n        B_ell = planck(T_ell)\n        B_s = planck(T_s)\n        \n        # Calculate H for background state and the K operator\n        H_b = H_operator(q_b, B_ell, B_s, kappa_nu, M_air, eps_s)\n        K = K_operator(q_b, B_ell, B_s, kappa_nu, M_air, eps_s)\n        \n        errors = []\n        for delta_q in delta_q_list:\n            q_p = q_b + delta_q  # Perturbed state\n            \n            # Full non-linear model for perturbed state\n            H_p = H_operator(q_p, B_ell, B_s, kappa_nu, M_air, eps_s)\n            \n            # Numerator of the relative error formula: |H_p - (H_b + K*dq)|\n            numerator = abs(H_p - H_b - K * delta_q)\n            \n            # Denominator of the relative error formula: |H_p - H_b|\n            denominator = abs(H_p - H_b)\n            \n            if denominator == 0.0:\n                # Per problem spec, if denominator is 0, error is 0.\n                rel_error = 0.0\n            else:\n                rel_error = numerator / denominator\n            \n            errors.append(rel_error)\n            \n        max_error = max(errors) if errors else 0.0\n        return round(max_error, 6)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (q_b, T_ell, T_s, kappa_nu, M_air, eps_s, [delta_q values])\n        (0.005, 280, 290, 0.04, 4000, 0.98, [1e-6, 1e-5, 1e-4, 5e-4]),\n        (0.015, 270, 300, 0.05, 4000, 0.98, [1e-5, 1e-4, 1e-3, 2e-3]),\n        (0.020, 295, 305, 0.06, 5000, 0.98, [-1e-4, -5e-4, 5e-4, 2e-3]),\n        (0.025, 260, 270, 0.07, 6000, 0.98, [1e-3, 3e-3, 5e-3]),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_max_error(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The analysis step in data assimilation optimally combines a background estimate with new observations. The Kalman gain matrix, $K_a$, acts as the master arbiter, determining how much weight to give each piece of information. This exercise moves from validating the model operators to investigating the statistical components of the assimilation system. By comparing an analysis using uncorrelated observation errors with one using a more realistic correlated error structure, you will quantify how assumptions about the observation error covariance matrix $R$ directly alter the analysis gain and change the perceived impact of each satellite channel .",
            "id": "3365144",
            "problem": "Consider a linearized satellite radiance assimilation problem in the Bayesian linear-Gaussian setting. The unknown state vector $x \\in \\mathbb{R}^n$ represents four layer temperatures in Kelvin. The observation vector $y \\in \\mathbb{R}^m$ represents five infrared brightness temperature channels in Kelvin measured by a satellite instrument. The observation operator $H \\in \\mathbb{R}^{m \\times n}$ is the Jacobian of the radiative transfer mapping from the state to radiances, assumed linear in the vicinity of the background. The background error covariance $B \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite and the observation error covariance $R \\in \\mathbb{R}^{m \\times m}$ is symmetric positive definite.\n\nFundamental base:\n- The prior distribution is Gaussian, $x \\sim \\mathcal{N}(x_b, B)$, where $x_b$ is the background state.\n- The observation model is $y = H x + \\varepsilon$, with $\\varepsilon \\sim \\mathcal{N}(0, R)$.\n- The posterior is obtained by applying Bayes' rule, which yields the linear Gaussian analysis with an optimal linear estimator that minimizes the quadratic Bayesian cost under the given covariances.\n- The Kalman Filter (KF) in the linear-Gaussian case is the standard framework for combining $B$, $H$, and $R$ to form the analysis update.\n\nYou must work in a purely mathematical formulation without external data. All state and observation quantities are in Kelvin to ensure the Kalman gain is dimensionless (Kelvin per Kelvin). Angles are not used. No percentages are required.\n\nSetup:\n- Dimensions: $n = 4$ (state) and $m = 5$ (channels).\n- Observation operator $H$ (dimensionless sensitivity, Kelvin per Kelvin):\n$$\nH = \\begin{bmatrix}\n0.6 & 0.3 & 0.1 & 0.0 \\\\\n0.2 & 0.5 & 0.3 & 0.0 \\\\\n0.1 & 0.2 & 0.5 & 0.2 \\\\\n0.0 & 0.1 & 0.4 & 0.5 \\\\\n0.0 & 0.0 & 0.3 & 0.7\n\\end{bmatrix}.\n$$\n- Background error covariance $B$ in Kelvin$^2$ constructed from a physically plausible exponentially decaying correlation across adjacent layers:\n    - Layer standard deviations $s = [1.0, 0.9, 0.7, 0.6]$ in Kelvin.\n    - Background correlation parameter $r_b = 0.6$.\n    - Correlation matrix $C^{(n)} \\in \\mathbb{R}^{n \\times n}$ with entries $C^{(n)}_{ij} = r_b^{|i-j|}$.\n    - Then $B_{ij} = s_i s_j C^{(n)}_{ij}$.\n- Observation error covariance $R$ depends on per-channel standard deviations $\\sigma_i$ in Kelvin and an inter-channel correlation parameter $\\rho$ via a Toeplitz structure:\n    - Correlation matrix $C^{(m)} \\in \\mathbb{R}^{m \\times m}$ with entries $C^{(m)}_{ij} = \\rho^{|i-j|}$.\n    - For diagonal (uncorrelated) errors, set $\\rho = 0$ so $C^{(m)}$ becomes the identity and $R = \\mathrm{diag}(\\sigma_1^2, \\dots, \\sigma_m^2)$.\n    - For correlated errors, use the Toeplitz structure $R_{ij} = \\sigma_i \\sigma_j C^{(m)}_{ij} = \\sigma_i \\sigma_j \\rho^{|i-j|}$.\n\nTask:\n1. Starting from the linear-Gaussian Bayesian formulation and cost minimization principles, derive the analysis gain matrix $K_a \\in \\mathbb{R}^{n \\times m}$ in terms of $B$, $H$, and $R$. Implement a numerically stable computation of $K_a$ for both the diagonal $R$ (with $\\rho=0$) and the correlated Toeplitz $R$ (with specified $\\rho$).\n2. Define the channel impact score for channel $i$ as the Euclidean norm of column $i$ of $K_a$, i.e., $s_i = \\lVert K_a[:, i] \\rVert_2$. Using zero-based channel indexing, determine the channel impact ranking by sorting channels in descending order of $s_i$, breaking ties by ascending channel index.\n3. Quantify the effect of inter-channel correlations by the Frobenius norm difference $\\Delta = \\lVert K_a^{(\\mathrm{toeplitz})} - K_a^{(\\mathrm{diag})} \\rVert_F$, which is dimensionless under the Kelvin setup.\n\nTest suite:\nFor each parameter set, use the same $H$ and $B$ as above and construct $R$ with the given $\\sigma$ and $\\rho$ values.\n\n- Case A (happy path): $\\sigma = [0.5, 0.6, 0.4, 0.7, 0.5]$ Kelvin, $\\rho = 0.5$.\n- Case B (boundary, no correlation): $\\sigma = [0.5, 0.6, 0.4, 0.7, 0.5]$ Kelvin, $\\rho = 0.0$.\n- Case C (edge, strong positive correlation): $\\sigma = [0.8, 0.8, 0.8, 0.8, 0.8]$ Kelvin, $\\rho = 0.9$.\n- Case D (edge, negative correlation): $\\sigma = [0.5, 0.7, 0.9, 0.7, 0.5]$ Kelvin, $\\rho = -0.3$.\n\nProgram requirements:\n- For each test case, compute:\n    1. The dimensionless Frobenius norm difference $\\Delta$ between $K_a$ using diagonal $R$ (with the same $\\sigma$ but $\\rho=0$) and $K_a$ using the specified Toeplitz $R$.\n    2. The diagonal-$R$ channel ranking list as zero-based indices.\n    3. The Toeplitz-$R$ channel ranking list as zero-based indices.\n    4. The per-channel rank shift list where the shift for channel $i$ equals its position in the Toeplitz ranking minus its position in the diagonal ranking.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be a list of the form $[\\Delta, \\text{diag\\_rank}, \\text{toeplitz\\_rank}, \\text{rank\\_shift}]$, where $\\text{diag\\_rank}$, $\\text{toeplitz\\_rank}$, and $\\text{rank\\_shift}$ are lists of integers. The final output must aggregate the four test cases into a single outer list, for example:\n$[[\\Delta_A,[\\dots],[\\dots],[\\dots]],[\\Delta_B,[\\dots],[\\dots],[\\dots]],[\\Delta_C,[\\dots],[\\dots],[\\dots]],[\\Delta_D,[\\dots],[\\dots],[\\dots]]]$.",
            "solution": "The problem presented is a canonical example of linear-Gaussian data assimilation, specifically the analysis step of a Kalman filter. We are tasked with determining the optimal estimate of a state vector $x \\in \\mathbb{R}^n$ (representing atmospheric layer temperatures) given an observation vector $y \\in \\mathbb{R}^m$ (representing satellite brightness temperatures). The problem is formulated within a Bayesian framework, where prior knowledge of the state is combined with new information from observations to yield an updated, or posterior, estimate.\n\nThe fundamental components are:\n1.  A prior distribution for the state, $x \\sim \\mathcal{N}(x_b, B)$, where $x_b$ is the background (prior mean) state and $B \\in \\mathbb{R}^{n \\times n}$ is the background error covariance matrix.\n2.  A linear observation model, $y = Hx + \\varepsilon$, where $H \\in \\mathbb{R}^{m \\times n}$ is the observation operator (or forward model), and the observation error $\\varepsilon$ is drawn from a zero-mean Gaussian distribution, $\\varepsilon \\sim \\mathcal{N}(0, R)$, with $R \\in \\mathbb{R}^{m \\times m}$ being the observation error covariance matrix.\n\nThe objective is to find the analysis state $x_a$ that maximizes the posterior probability density, which, in the Gaussian case, is equivalent to minimizing a quadratic cost function $J(x)$. This cost function measures the misfit between a candidate state $x$ and both the background information and the observations, weighted by their respective error covariances.\n\nThe cost function $J(x)$ is the sum of the background term $J_b(x)$ and the observation term $J_o(x)$:\n$$ J(x) = \\frac{1}{2}(x - x_b)^T B^{-1} (x - x_b) + \\frac{1}{2}(y - Hx)^T R^{-1} (y - Hx) $$\nTo find the analysis state $x_a$ that minimizes $J(x)$, we compute the gradient of $J(x)$ with respect to $x$ and set it to zero. The gradient is:\n$$ \\nabla_x J(x) = B^{-1}(x - x_b) - H^T R^{-1}(y - Hx) $$\nSetting $\\nabla_x J(x_a) = 0$ for the optimal state $x_a$ yields:\n$$ B^{-1}(x_a - x_b) - H^T R^{-1}(y - Hx_a) = 0 $$\nRearranging the terms to solve for $x_a$:\n$$ (B^{-1} + H^T R^{-1}H)x_a = B^{-1}x_b + H^T R^{-1}y $$\nThis leads to the inverse-form solution for the analysis state:\n$$ x_a = (B^{-1} + H^T R^{-1}H)^{-1} (B^{-1}x_b + H^T R^{-1}y) $$\nWhile correct, this form is often not ideal for numerical computation as it may require multiple matrix inversions, including that of the typically large background error covariance matrix $B$.\n\nA more common and numerically stable form is the gain form, which expresses the analysis state as an update to the background state:\n$$ x_a = x_b + K_a(y - Hx_b) $$\nHere, $K_a \\in \\mathbb{R}^{n \\times m}$ is the analysis gain matrix, often called the Kalman gain. The term $(y - Hx_b)$ is the innovation, or departure, representing the new information provided by the observations. The gain matrix $K_a$ optimally distributes this new information across the components of the state vector.\n\nTo derive an expression for $K_a$, we equate the two forms for $x_a$. By comparing coefficients of $y$, we can identify the expression for $K_a$. From the inverse-form solution, the term multiplying $y$ is $(B^{-1} + H^T R^{-1}H)^{-1} H^T R^{-1}$. Thus,\n$$ K_a = (B^{-1} + H^T R^{-1}H)^{-1} H^T R^{-1} $$\nApplying the Woodbury matrix identity, $(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}$, with $A=B^{-1}$, $U=H^T$, $C=R^{-1}$, and $V=H$, we can transform the term $(B^{-1} + H^T R^{-1}H)^{-1}$ to obtain a more stable expression for $K_a$:\n$$ K_a = [B - BH^T(R+HBH^T)^{-1}HB] H^T R^{-1} $$\n$$ K_a = BH^T R^{-1} - BH^T(R+HBH^T)^{-1}HBH^T R^{-1} $$\n$$ K_a = BH^T (R+HBH^T)^{-1} [ (R+HBH^T) - HBH^T ] R^{-1} $$\n$$ K_a = BH^T (R+HBH^T)^{-1} R R^{-1} $$\nThis simplification yields the standard and numerically preferred expression for the Kalman gain:\n$$ K_a = B H^T (R + H B H^T)^{-1} $$\nThis formulation is advantageous because it requires inversion of the matrix $(R + H B H^T)$, which has dimensions $m \\times m$. In many practical applications, the number of observations $m$ is much smaller than the number of state variables $n$, making this inversion computationally cheaper. In our case, $n=4$ and $m=5$, so the dimensions are comparable, but this form avoids the direct inversion of $B$ and $R$.\n\nThe algorithmic procedure to solve the problem is as follows:\n1.  **Construct Covariance Matrices**:\n    -   The background error covariance $B$ is constructed as $B_{ij} = s_i s_j r_b^{|i-j|}$, where $s$ is the vector of layer standard deviations and $r_b$ is the background correlation parameter.\n    -   The observation error covariance $R$ is constructed as $R_{ij} = \\sigma_i \\sigma_j \\rho^{|i-j|}$, where $\\sigma$ is the vector of channel standard deviations and $\\rho$ is the inter-channel correlation parameter. For the diagonal case, we set $\\rho=0$.\n2.  **Compute Gain Matrices**: For each test case, we compute two gain matrices: $K_a^{(\\mathrm{toeplitz})}$ using the specified $\\rho$, and $K_a^{(\\mathrm{diag})}$ using the same $\\sigma$ but with $\\rho=0$. The computation follows the derived formula $K_a = B H^T (R + H B H^T)^{-1}$.\n3.  **Calculate Channel Impact and Ranking**: The impact of observation channel $i$ is quantified by the Euclidean norm of the $i$-th column of the gain matrix, $s_i = \\lVert K_a[:, i] \\rVert_2$. Channels are then ranked in descending order of their impact scores $s_i$, with ties broken by ascending channel index. This is done for both $K_a^{(\\mathrm{toeplitz})}$ and $K_a^{(\\mathrm{diag})}$.\n4.  **Quantify Correlation Effects**:\n    -   The overall change in the gain matrix due to correlation is measured by the Frobenius norm of the difference: $\\Delta = \\lVert K_a^{(\\mathrm{toeplitz})} - K_a^{(\\mathrm{diag})} \\rVert_F$.\n    -   The shift in rank for each channel is computed as the difference between its position in the Toeplitz-R ranking and its position in the diagonal-R ranking.\n\nThe specified units (Kelvin for temperatures and standard deviations) ensure that the Jacobian $H$ and the resulting gain matrix $K_a$ are dimensionless, as $[K_a] = [B][H^T][(R + H B H^T)^{-1}] = \\text{K}^2 \\cdot (\\text{K}/\\text{K}) \\cdot (\\text{K}^2)^{-1} = \\text{dimensionless}$. Consequently, the impact scores $s_i$ and the norm difference $\\Delta$ are also dimensionless.\nThe implementation will proceed by systematically applying these steps for each of the four test cases provided.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import toeplitz\n\ndef solve():\n    \"\"\"\n    Solves the satellite radiance assimilation problem for the given test cases.\n    \"\"\"\n    \n    # --- Givens (fixed for all cases) ---\n    # State dimension n=4, observation dimension m=5\n    n = 4\n    m = 5\n    \n    # Observation operator H\n    H = np.array([\n        [0.6, 0.3, 0.1, 0.0],\n        [0.2, 0.5, 0.3, 0.0],\n        [0.1, 0.2, 0.5, 0.2],\n        [0.0, 0.1, 0.4, 0.5],\n        [0.0, 0.0, 0.3, 0.7]\n    ])\n\n    # Background error covariance B parameters\n    s_b = np.array([1.0, 0.9, 0.7, 0.6])\n    r_b = 0.6\n\n    # Test suite parameters\n    test_cases = [\n        # Case A\n        {'sigma': np.array([0.5, 0.6, 0.4, 0.7, 0.5]), 'rho': 0.5},\n        # Case B\n        {'sigma': np.array([0.5, 0.6, 0.4, 0.7, 0.5]), 'rho': 0.0},\n        # Case C\n        {'sigma': np.array([0.8, 0.8, 0.8, 0.8, 0.8]), 'rho': 0.9},\n        # Case D\n        {'sigma': np.array([0.5, 0.7, 0.9, 0.7, 0.5]), 'rho': -0.3}\n    ]\n\n    # --- Helper Functions ---\n    def build_B(s_dev, corr_param):\n        \"\"\"Constructs the background error covariance matrix B.\"\"\"\n        dim = len(s_dev)\n        corr_col = np.power(corr_param, np.arange(dim))\n        C = toeplitz(corr_col)\n        D = np.diag(s_dev)\n        B_matrix = D @ C @ D\n        return B_matrix\n\n    def build_R(s_dev, corr_param):\n        \"\"\"Constructs the observation error covariance matrix R.\"\"\"\n        dim = len(s_dev)\n        # Handle the case rho=0 for diagonal R\n        if corr_param == 0.0:\n            return np.diag(s_dev**2)\n        \n        corr_col = np.power(corr_param, np.arange(dim))\n        C = toeplitz(corr_col)\n        D = np.diag(s_dev)\n        R_matrix = D @ C @ D\n        return R_matrix\n\n    def compute_kalman_gain(H_op, B_cov, R_cov):\n        \"\"\"Computes the Kalman gain K_a using the numerically stable formula.\"\"\"\n        H_T = H_op.T\n        S = R_cov + H_op @ B_cov @ H_T  # Innovation covariance\n        S_inv = np.linalg.inv(S)\n        K = B_cov @ H_T @ S_inv\n        return K\n\n    def compute_channel_ranking(K_gain):\n        \"\"\"Computes channel impact scores and returns the ranked channel indices.\"\"\"\n        num_channels = K_gain.shape[1]\n        # Calculate impact score (Euclidean norm of each column)\n        impact_scores = [np.linalg.norm(K_gain[:, i]) for i in range(num_channels)]\n        \n        # Create pairs of (score, channel_index) for sorting\n        # Tie-breaking: ascending channel index\n        score_index_pairs = list(zip(impact_scores, range(num_channels)))\n        \n        # Sort by score descending (-score ascending), then by index ascending\n        score_index_pairs.sort(key=lambda x: (-x[0], x[1]))\n        \n        # Extract the ranked channel indices\n        ranked_indices = [index for score, index in score_index_pairs]\n        return ranked_indices\n    \n    # --- Main Calculation Loop ---\n    \n    # B is constant across test cases\n    B = build_B(s_b, r_b)\n    \n    all_results = []\n    \n    for case in test_cases:\n        sigma_o = case['sigma']\n        rho_o = case['rho']\n        \n        # 1. Compute R for Toeplitz and Diagonal cases\n        R_toeplitz = build_R(sigma_o, rho_o)\n        R_diag = build_R(sigma_o, 0.0) # rho=0 gives diagonal R\n        \n        # 2. Compute gain matrices\n        K_toeplitz = compute_kalman_gain(H, B, R_toeplitz)\n        K_diag = compute_kalman_gain(H, B, R_diag)\n        \n        # 3. Compute Frobenius norm difference\n        delta = np.linalg.norm(K_toeplitz - K_diag, 'fro')\n        \n        # 4. Compute channel rankings\n        diag_rank = compute_channel_ranking(K_diag)\n        toeplitz_rank = compute_channel_ranking(K_toeplitz)\n        \n        # 5. Compute rank shifts\n        # Create maps from channel index to rank position\n        diag_pos_map = {channel: pos for pos, channel in enumerate(diag_rank)}\n        toeplitz_pos_map = {channel: pos for pos, channel in enumerate(toeplitz_rank)}\n        \n        rank_shift = [toeplitz_pos_map[i] - diag_pos_map[i] for i in range(m)]\n        \n        # 6. Aggregate results for the current case\n        case_result = [delta, diag_rank, toeplitz_rank, rank_shift]\n        all_results.append(case_result)\n\n    # --- Format and Print Final Output ---\n    # The output format must exactly match the problem statement, including no spaces after commas.\n    result_strings = []\n    for res in all_results:\n        # Convert each result item to string representation and remove spaces\n        res_str = str(res).replace(\" \", \"\")\n        result_strings.append(res_str)\n        \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "The goal of assimilating satellite data is not just to run an algorithm, but to produce a physically meaningful analysis of the atmospheric state with quantifiable quality. The averaging kernel matrix, $A$, is a fundamental diagnostic tool that reveals how the final analysis at a given point is constructed as a weighted average of the true atmospheric state, thereby defining the effective resolution of the observing system. This practice delves into how our prior knowledge, encoded in the structure of the background error covariance matrix $B$, shapes the rows of the averaging kernel and ultimately controls the vertical resolution of the final analysis product .",
            "id": "3365149",
            "problem": "Consider a one-dimensional vertical column state vector $x \\in \\mathbb{R}^n$ representing atmospheric temperature perturbations in kelvin (K) at discrete altitudes. Infrared satellite radiance observations are linearized around a background state with the relationship $y = K x + \\varepsilon$, where $y \\in \\mathbb{R}^m$ are channel brightness temperature perturbations in kelvin (K), $K \\in \\mathbb{R}^{m \\times n}$ is the Jacobian of the observation operator (also referred to as the weighting functions), and $\\varepsilon \\sim \\mathcal{N}(0, R)$ is the observation error with covariance $R \\in \\mathbb{R}^{m \\times m}$ in $\\text{K}^2$. The background error $e_b = x - x_b$ satisfies $e_b \\sim \\mathcal{N}(0, B)$ with covariance $B \\in \\mathbb{R}^{n \\times n}$ in $\\text{K}^2$.\n\nStarting from the fundamental linear-Gaussian data assimilation principles and the minimum-variance linear estimator under Gaussian assumptions, derive the expression of the averaging kernel matrix $A \\in \\mathbb{R}^{n \\times n}$ that maps the true state $x$ to the analysis $x_a$ and encodes the vertical resolution of the analysis. Your derivation must begin from the conditions on Gaussian priors and linear observation models, and proceed logically to the analysis operator and its sensitivity to the true state. Do not assume any shortcut identities without justification.\n\nThen, implement a numerical experiment that compares how different vertical background covariance structures $B$ affect the vertical resolution of the analysis inferred from $A$. Use a scientifically consistent discretization and channel configuration with the following specifications.\n\n- Vertical grid:\n    - Let $z_i$ be altitudes in kilometers (km) for $i = 0, 1, \\dots, n-1$, with $n = 31$ points uniformly spaced from $z_0 = 0\\,\\text{km}$ to $z_{30} = 15\\,\\text{km}$.\n    - Define $\\Delta z = 0.5\\,\\text{km}$.\n\n- Infrared observation weighting functions (rows of $K$):\n    - Use $m = 6$ channels with centers $z_{c,j} \\in \\{1, 3, 5, 7, 9, 12\\}\\,\\text{km}$ for $j = 1, \\dots, 6$.\n    - For each channel $j$, define a Gaussian weighting function \n$$w_j(z) = \\exp\\left(-\\frac{(z - z_{c,j})^2}{2 \\sigma_w^2}\\right)$$\n with $\\sigma_w = 0.8\\,\\text{km}$.\n    - Discretize $K$ by $$K_{j,i} = \\frac{w_j(z_i)\\,\\Delta z}{\\sum_{p=0}^{n-1} w_j(z_p)\\,\\Delta z}$$ so that each channel integrates to unity over the column. $K$ is dimensionless under this normalization.\n\n- Background covariance $B$ choices:\n    - Exponential kernel (also known as Matérn with smoothness $\\nu = \\tfrac{1}{2}$): for correlation length $L_z$ in kilometers and variance $\\sigma_b^2$ in $\\text{K}^2$, define \n$$B_{ij} = \\sigma_b^2 \\exp\\left(-\\frac{|z_i - z_j|}{L_z}\\right).$$\n    - Matérn kernel with smoothness $\\nu > 0$, correlation length $L_z$ in kilometers, and variance $\\sigma_b^2$ in $\\text{K}^2$: for $i \\neq j$,\n$$B_{ij} = \\sigma_b^2 \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left(\\frac{\\sqrt{2\\nu}\\,|z_i - z_j|}{L_z}\\right)^\\nu K_\\nu\\left(\\frac{\\sqrt{2\\nu}\\,|z_i - z_j|}{L_z}\\right),$$\n      where $\\Gamma(\\cdot)$ is the Gamma function and $K_\\nu(\\cdot)$ is the modified Bessel function of the second kind. Set $B_{ii} = \\sigma_b^2$ for all $i$.\n\n- Observation error covariance $R$:\n    - Use diagonal $R = \\operatorname{diag}(\\sigma_{y}^2, \\dots, \\sigma_{y}^2)$ in $\\text{K}^2$.\n\nFrom the derived $A$, define a quantitative vertical resolution metric at each level $z_i$ as follows. Let $a_i$ be the $i$-th row of $A$. Compute weights $u_i$ by normalizing the absolute values of $a_i$,\n$$u_{i,p} = \\frac{|a_{i,p}|}{\\sum_{q=0}^{n-1} |a_{i,q}|}, \\quad p = 0, \\dots, n-1.$$\nDefine the center of mass $\\bar{z}_i = \\sum_{p=0}^{n-1} u_{i,p} z_p$ and the second central moment $M_i = \\sum_{p=0}^{n-1} u_{i,p} (z_p - \\bar{z}_i)^2$. The effective vertical resolution width at level $z_i$ is $W_i = 2 \\sqrt{M_i}$ in kilometers. For numerical stability, exclude levels with $\\sum_{p=0}^{n-1} |a_{i,p}| \\le 10^{-12}$ from the summary statistics; if all levels are excluded in a test case, return the total grid span $z_{30} - z_0$ as the resolution metric for that case. Aggregate a single resolution metric for each experiment by taking the median of $\\{W_i\\}$ across all included levels, expressed in kilometers.\n\nConstruct the following test suite of parameter sets to probe different aspects of the problem:\n- Case 1 (baseline exponential): exponential $B$ with $L_z = 1.5\\,\\text{km}$, $\\sigma_b^2 = 1.0\\,\\text{K}^2$, and $R$ diagonal with $\\sigma_y^2 = 0.25\\,\\text{K}^2$.\n- Case 2 (short-range exponential): exponential $B$ with $L_z = 0.5\\,\\text{km}$, $\\sigma_b^2 = 1.0\\,\\text{K}^2$, and $R$ diagonal with $\\sigma_y^2 = 0.25\\,\\text{K}^2$.\n- Case 3 (Matérn moderate smoothness): Matérn $B$ with $\\nu = 1.5$, $L_z = 1.5\\,\\text{km}$, $\\sigma_b^2 = 1.0\\,\\text{K}^2$, and $R$ diagonal with $\\sigma_y^2 = 0.25\\,\\text{K}^2$.\n- Case 4 (Matérn higher smoothness and longer correlation): Matérn $B$ with $\\nu = 3.0$, $L_z = 2.0\\,\\text{km}$, $\\sigma_b^2 = 1.0\\,\\text{K}^2$, and $R$ diagonal with $\\sigma_y^2 = 0.25\\,\\text{K}^2$.\n- Case 5 (Matérn with large observation error): Matérn $B$ with $\\nu = 1.5$, $L_z = 1.5\\,\\text{km}$, $\\sigma_b^2 = 1.0\\,\\text{K}^2$, and $R$ diagonal with $\\sigma_y^2 = 4.0\\,\\text{K}^2$.\n\nYour program must:\n- Implement the derivation-derived formula for $A$ using $B$, $K$, and $R$.\n- Compute the median effective vertical resolution width in kilometers for each of the five cases, as defined above.\n- Express the final numerical answers in kilometers, rounded to three decimal places.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[w_1,w_2,w_3,w_4,w_5]$), where each $w_k$ is the median width for case $k$ in kilometers.\n\nNo user input or external files are allowed; all constants and parameters are as specified. Angles do not appear and therefore no angle unit is required. Percentages do not appear and therefore no percentage formatting is required. The problem focuses on purely mathematical and algorithmic derivations consistent with inverse problems and data assimilation for satellite infrared radiance data.",
            "solution": "The starting point is the linear-Gaussian data assimilation framework, where the state $x \\in \\mathbb{R}^n$ and observations $y \\in \\mathbb{R}^m$ satisfy $y = K x + \\varepsilon$, with $\\varepsilon \\sim \\mathcal{N}(0, R)$. The background state $x_b$ is a prior estimate with error $e_b = x - x_b \\sim \\mathcal{N}(0, B)$. Under these assumptions, the analysis $x_a$ that minimizes the expected squared estimation error is the linear minimum-variance estimator, obtained by completing the square in the joint Gaussian posterior or, equivalently, by standard Kalman filter analysis with linear observation operator.\n\nThe analysis increment is given by\n$$x_a - x_b = G \\left(y - K x_b\\right),$$\nwhere the gain $G \\in \\mathbb{R}^{n \\times m}$ is\n$$G = B K^\\top \\left(K B K^\\top + R\\right)^{-1}.$$\nThis expression arises from minimizing the quadratic form $(x - x_b)^\\top B^{-1} (x - x_b) + (y - K x)^\\top R^{-1} (y - K x)$ with respect to $x$, leading to the normal equations $(B^{-1} + K^\\top R^{-1} K) x = B^{-1} x_b + K^\\top R^{-1} y$, and to the solution $x_a = x_b + G (y - K x_b)$ after algebraic manipulation and application of the matrix inversion lemma.\n\nThe sensitivity of the analysis $x_a$ to the true state $x$ is captured by the averaging kernel matrix $A \\in \\mathbb{R}^{n \\times n}$, defined as the Jacobian $\\frac{\\partial x_a}{\\partial x}$. Differentiating $x_a$ with respect to $x$ in the linear setting $y = K x + \\varepsilon$ yields\n$$\\frac{\\partial x_a}{\\partial x} = G K.$$\nCombined with the expression for $G$, the averaging kernel is\n$$A = B K^\\top \\left(K B K^\\top + R\\right)^{-1} K.$$\nThis matrix is dimensionless under the chosen normalization for $K$, and encodes the vertical smoothing inherent to the analysis: the $i$-th row of $A$ gives the weights by which the true profile components contribute to the analysis at level $z_i$.\n\nTo quantify vertical resolution, we require a scalar width metric per level that reflects how concentrated each averaging kernel row is around its center. Because averaging kernel rows can have oscillatory or sign-changing structures, we form nonnegative weights from the absolute values of the row to avoid cancellations:\n- For the $i$-th row $a_i \\in \\mathbb{R}^n$, define $u_{i,p} = \\frac{|a_{i,p}|}{\\sum_{q=0}^{n-1} |a_{i,q}|}$.\n- The center of mass is $\\bar{z}_i = \\sum_{p=0}^{n-1} u_{i,p} z_p$.\n- The second central moment is $M_i = \\sum_{p=0}^{n-1} u_{i,p} (z_p - \\bar{z}_i)^2$.\n- The effective width is $W_i = 2 \\sqrt{M_i}$ in kilometers. The factor of $2$ corresponds to a two-standard-deviation width, which is a robust measure that does not assume Gaussianity yet scales with the spread.\n\nWe exclude levels with $\\sum_p |a_{i,p}| \\le 10^{-12}$ (numerically negligible sensitivity) from summary statistics. If no levels remain, the metric defaults to the full grid span $z_{n-1} - z_0$.\n\nNumerical construction details:\n- Vertical grid $z_i$ is uniform from $0\\,\\text{km}$ to $15\\,\\text{km}$ with $n = 31$ and $\\Delta z = 0.5\\,\\text{km}$.\n- Weighting functions $w_j(z)$ are Gaussian with centers $z_{c,j} \\in \\{1, 3, 5, 7, 9, 12\\}\\,\\text{km}$ and spread $\\sigma_w = 0.8\\,\\text{km}$. Each row $K_{j,\\cdot}$ is normalized to integrate to unity via $K_{j,i} = \\frac{w_j(z_i)\\,\\Delta z}{\\sum_p w_j(z_p)\\,\\Delta z}$.\n- The background covariance $B$ is built using either the exponential kernel $B_{ij} = \\sigma_b^2 \\exp\\left(-\\frac{|z_i - z_j|}{L_z}\\right)$ (stationary, positive definite) or the Matérn kernel\n$$B_{ij} = \\begin{cases}\n\\sigma_b^2, & i = j, \\\\\n\\sigma_b^2 \\dfrac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left(\\dfrac{\\sqrt{2\\nu}\\,|z_i - z_j|}{L_z}\\right)^\\nu K_\\nu\\left(\\dfrac{\\sqrt{2\\nu}\\,|z_i - z_j|}{L_z}\\right), & i \\ne j,\n\\end{cases}$$\nwhich is also stationary and positive definite for $\\nu > 0$. The diagonal $B_{ii}=\\sigma_b^2$ matches the correct variance at zero separation (the Matérn limit).\n- Observation error covariance is $R = \\operatorname{diag}(\\sigma_y^2, \\dots, \\sigma_y^2)$.\n\nAlgorithmic steps for each test case:\n1. Construct $K$ on the specified grid.\n2. Construct $B$ using the chosen kernel type and parameters $(\\sigma_b^2, L_z, \\nu)$.\n3. Construct $R$ using $\\sigma_y^2$.\n4. Compute $S = K B K^\\top + R$, then solve $S X = K$ for $X$.\n5. Compute $A = B K^\\top X$.\n6. For each level $i$, compute $W_i$ using the absolute-normalized row weights and the second central moment; exclude negligible-sensitivity levels.\n7. Report the median of $\\{W_i\\}$ in kilometers, rounded to three decimal places.\n\nQualitative expectations:\n- Larger correlation length $L_z$ in $B$ broadens background correlations, typically increasing the width of averaging kernels and thus reducing vertical resolution (larger $W_i$).\n- Higher smoothness $\\nu$ in the Matérn kernel yields smoother correlations, often broadening averaging kernels compared to exponential for the same $L_z$.\n- Larger observation error variance $\\sigma_y^2$ increases reliance on the background, which tends to broaden $A$ and increase the width metric, again indicating reduced resolution.\n\nThe program implements these computations precisely and outputs a single line containing five comma-separated floats in kilometers, one per test case, enclosed in square brackets.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import kv as besselk, gamma\n\ndef build_vertical_grid(n=31, zmin=0.0, zmax=15.0):\n    z = np.linspace(zmin, zmax, n)\n    dz = z[1] - z[0]\n    return z, dz\n\ndef build_K(z, centers, sigma_w, dz):\n    m = len(centers)\n    n = len(z)\n    K = np.zeros((m, n))\n    for j, zc in enumerate(centers):\n        w = np.exp(-0.5 * ((z - zc) / sigma_w) ** 2)\n        w_int = w * dz\n        s = np.sum(w_int)\n        if s <= 0.0:\n            # Avoid division by zero; unlikely with positive Gaussian\n            K[j, :] = 0.0\n        else:\n            K[j, :] = w_int / s\n    return K\n\ndef build_B_exponential(z, sigma_b2, Lz):\n    # Exponential kernel: B_ij = sigma_b2 * exp(-|z_i - z_j| / Lz)\n    D = np.abs(z[:, None] - z[None, :])\n    B = sigma_b2 * np.exp(-D / Lz)\n    return B\n\ndef build_B_matern(z, sigma_b2, Lz, nu):\n    # Matérn kernel:\n    # For i != j:\n    # B_ij = sigma_b2 * (2^(1-nu) / Gamma(nu)) * (sqrt(2nu) h / Lz)^nu * K_nu(sqrt(2nu) h / Lz)\n    # For i == j: B_ii = sigma_b2\n    D = np.abs(z[:, None] - z[None, :])\n    B = np.zeros_like(D)\n    # Diagonal\n    np.fill_diagonal(B, sigma_b2)\n    # Off-diagonal\n    mask = D > 0\n    h = D[mask]\n    arg = np.sqrt(2.0 * nu) * h / Lz\n    const = sigma_b2 * (2.0 ** (1.0 - nu)) / gamma(nu)\n    # besselk(nu, arg) is modified Bessel function of the second kind\n    B[mask] = const * (arg ** nu) * besselk(nu, arg)\n    return B\n\ndef build_R(m, sigma_y2):\n    return np.eye(m) * sigma_y2\n\ndef averaging_kernel(B, K, R):\n    # Compute A = B K^T (K B K^T + R)^{-1} K\n    S = K @ B @ K.T + R\n    # Solve S X = K for X\n    X = np.linalg.solve(S, K)\n    A = B @ K.T @ X\n    return A\n\ndef effective_resolution(A, z, eps=1e-12):\n    widths = []\n    for i in range(A.shape[0]):\n        row = A[i, :]\n        w = np.abs(row)\n        s = np.sum(w)\n        if s <= eps:\n            continue\n        wn = w / s\n        zbar = np.sum(wn * z)\n        var = np.sum(wn * (z - zbar) ** 2)\n        width = 2.0 * np.sqrt(var)\n        widths.append(width)\n    if len(widths) == 0:\n        return float(z[-1] - z[0])\n    return float(np.median(np.array(widths)))\n\ndef run_case(case_type, params, z, dz, K):\n    sigma_b2 = params[\"sigma_b2\"]\n    sigma_y2 = params[\"sigma_y2\"]\n    if case_type == \"exp\":\n        Lz = params[\"Lz\"]\n        B = build_B_exponential(z, sigma_b2, Lz)\n    elif case_type == \"matern\":\n        Lz = params[\"Lz\"]\n        nu = params[\"nu\"]\n        B = build_B_matern(z, sigma_b2, Lz, nu)\n    else:\n        raise ValueError(\"Unknown case type\")\n    R = build_R(K.shape[0], sigma_y2)\n    A = averaging_kernel(B, K, R)\n    width = effective_resolution(A, z)\n    return width\n\ndef solve():\n    # Grid and weighting functions setup\n    z, dz = build_vertical_grid(n=31, zmin=0.0, zmax=15.0)\n    centers = [1.0, 3.0, 5.0, 7.0, 9.0, 12.0]\n    sigma_w = 0.8\n    K = build_K(z, centers, sigma_w, dz)\n\n    # Define test cases\n    test_cases = [\n        (\"exp\", {\"Lz\": 1.5, \"sigma_b2\": 1.0, \"sigma_y2\": 0.25}),          # Case 1\n        (\"exp\", {\"Lz\": 0.5, \"sigma_b2\": 1.0, \"sigma_y2\": 0.25}),          # Case 2\n        (\"matern\", {\"Lz\": 1.5, \"nu\": 1.5, \"sigma_b2\": 1.0, \"sigma_y2\": 0.25}),  # Case 3\n        (\"matern\", {\"Lz\": 2.0, \"nu\": 3.0, \"sigma_b2\": 1.0, \"sigma_y2\": 0.25}),  # Case 4\n        (\"matern\", {\"Lz\": 1.5, \"nu\": 1.5, \"sigma_b2\": 1.0, \"sigma_y2\": 4.0}),   # Case 5\n    ]\n\n    results = []\n    for case_type, params in test_cases:\n        width = run_case(case_type, params, z, dz, K)\n        results.append(f\"{width:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}