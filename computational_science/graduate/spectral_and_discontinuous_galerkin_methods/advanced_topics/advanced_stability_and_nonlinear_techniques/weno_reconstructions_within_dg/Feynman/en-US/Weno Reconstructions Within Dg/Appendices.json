{
    "hands_on_practices": [
        {
            "introduction": "To effectively use a WENO limiter, one must first understand the behavior of the underlying high-order Discontinuous Galerkin (DG) scheme it is designed to protect. This practice guides you through a fundamental Fourier analysis to quantify the scheme's intrinsic accuracy in terms of numerical dissipation and dispersion. By calculating the modified wavenumber for the linear advection equation, you will establish a crucial baseline for the performance of the DG method in smooth regions, where the limiter should ideally be inactive .",
            "id": "3429573",
            "problem": "Consider the one-dimensional linear advection equation $u_t + a u_x = 0$ with periodic boundary conditions, discretized on a uniform mesh of cells of width $h$ using the Discontinuous Galerkin (DG) method of polynomial degree $p=3$ with upwind numerical flux. Assume that any nonlinear limiter, such as the Weighted Essentially Non-Oscillatory (WENO) limiter or the Total Variation Bounded (TVB) limiter, is inactive in smooth regions, so that the linearized semidiscrete operator coincides with the underlying DG operator. Use a modal basis of Legendre polynomials $\\{\\phi_n(r)\\}_{n=0}^3$ on the reference element $r \\in [-1,1]$ mapped to each cell by $x = x_j + \\tfrac{h}{2} r$, and approximate all inner products by exact quadrature.\n\nStarting from the DG weak form for linear advection with upwind numerical flux, derive the semidiscrete operator symbol for a Fourier mode of dimensionless wavenumber $\\kappa = k h \\in [0,\\pi]$, namely a $4 \\times 4$ matrix $S(\\kappa)$ such that the cellwise modal coefficient vector $c_j \\in \\mathbb{C}^4$ satisfies $c_j'(t) = S(\\kappa) c_j(t)$ for a Fourier mode $c_j(t) = v(t) \\mathrm{e}^{i \\kappa j}$. From $S(\\kappa)$, define:\n- The modified wavenumber $k^\\star(\\kappa)$ by $k^\\star(\\kappa) = -\\mathrm{Im}(\\lambda^\\text{phys}(\\kappa))/a$, where $\\lambda^\\text{phys}(\\kappa)$ is the eigenvalue of $S(\\kappa)$ whose imaginary part matches $-a k$ most closely for small $\\kappa$ (the physical branch).\n- The dissipation rate $\\mathcal{D}(\\kappa)$ by $\\mathcal{D}(\\kappa) = \\mathrm{Re}(\\lambda^\\text{phys}(\\kappa))/a$.\n- The dispersion error $\\mathcal{E}(\\kappa)$ by $\\mathcal{E}(\\kappa) = k^\\star(\\kappa) - k$ with $k = \\kappa/h$.\n\nFor the fully discrete scheme with Strong Stability Preserving Runge–Kutta of order $3$ (SSP-RK3), define the amplification matrix $G(\\kappa,\\nu)$ by $G(\\kappa,\\nu) = R\\!\\left(\\Delta t\\, S(\\kappa)\\right)$ with the stability polynomial $R(z) = 1 + z + \\tfrac{1}{2} z^2 + \\tfrac{1}{6} z^3$ and the Courant–Friedrichs–Lewy (CFL) number $\\nu = a \\Delta t/h$. In smooth regimes, assume that both the WENO-limited DG and the TVB-limited DG reduce to the same linear operator $S(\\kappa)$; consequently, their amplification matrices coincide.\n\nYour tasks are:\n1. Derive the matrices $M$ and $K$ on the reference element using $\\phi_n(r) = P_n(r)$, the Legendre polynomials of degree $n$, with entries\n   $$M_{mn} = \\int_{-1}^1 \\phi_m(r)\\,\\phi_n(r)\\, \\mathrm{d}r,\\quad K_{mn} = \\int_{-1}^1 \\phi'_m(r)\\,\\phi_n(r)\\, \\mathrm{d}r.$$\n   Let $\\Phi(\\pm 1)$ denote the vector of basis evaluations at the faces, and define\n   $$F_R = \\Phi(1)\\,\\Phi(1)^\\top,\\quad G = \\Phi(-1)\\,\\Phi(1)^\\top.$$\n   Show that the semidiscrete DG operator can be written in the linear advection, upwind-flux case as\n   $$c_j'(t) = \\frac{2a}{h} M^{-1}\\Big[ K\\,c_j - F_R\\,c_j + G\\, c_{j-1}\\Big],$$\n   which yields the symbol\n   $$S(\\kappa) = \\frac{2a}{h} M^{-1}\\Big[ K - F_R + \\mathrm{e}^{-i\\kappa} G \\Big].$$\n2. Using the symbol $S(\\kappa)$, compute $\\lambda^\\text{phys}(\\kappa)$ by selecting the eigenvalue whose imaginary part most closely matches $-a k$ with $k=\\kappa/h$.\n3. Compute the dispersion error $\\mathcal{E}(\\kappa)$ and dissipation rate $\\mathcal{D}(\\kappa)$ for selected $\\kappa$.\n4. For SSP-RK3 and CFL values $\\nu$, compute the spectral radius of $G(\\kappa,\\nu)$ for a dense grid of $\\kappa \\in [0,\\pi]$, and report the maximum spectral radius over $\\kappa$. Compare the results for the WENO-limited DG and TVB-limited DG under the smooth-solution linearization assumption.\n\nUse $a=1$ and $h=1$. Angles for $\\kappa$ are dimensionless and in radians. There are no physical units to report.\n\nTest Suite:\n- Wavenumbers $\\kappa \\in \\{0.0,\\ 0.5,\\ 2.5,\\ \\pi\\}$.\n- CFL values $\\nu \\in \\{0.05,\\ 0.10,\\ 0.20,\\ 0.30\\}$.\n- For the fully discrete spectral radii, evaluate the maximum over a uniform grid of $\\kappa$ with at least $200$ points in $[0,\\pi]$.\n\nRequired Final Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n  1. For each test $\\kappa$ in the order above, the dispersion error $\\mathcal{E}(\\kappa)$ followed by the dissipation rate $\\mathcal{D}(\\kappa)$ (floats).\n  2. For each CFL value $\\nu$ in the order above, the maximum spectral radius of $G(\\kappa,\\nu)$ over $\\kappa \\in [0,\\pi]$ (floats).\n  3. For each CFL value $\\nu$, a boolean indicating whether the maximum spectral radius for the WENO-limited DG equals that of the TVB-limited DG within an absolute tolerance of $10^{-12}$ (booleans).\n\nFor example, the output should look like\n$$[\\mathcal{E}(0.0),\\ \\mathcal{D}(0.0),\\ \\mathcal{E}(0.5),\\ \\mathcal{D}(0.5),\\ \\ldots,\\ \\rho_{\\max}(\\nu=0.05),\\ \\rho_{\\max}(\\nu=0.10),\\ \\rho_{\\max}(\\nu=0.20),\\ \\rho_{\\max}(\\nu=0.30),\\ \\text{flag}_{0.05},\\ \\text{flag}_{0.10},\\ \\text{flag}_{0.20},\\ \\text{flag}_{0.30}].$$\n\nThe program must be entirely self-contained and produce these values with no input. All computed answers must be numerical (floats or booleans) and aggregated exactly as specified into a single list printed on one line.",
            "solution": "The user-provided problem is evaluated as scientifically sound, well-posed, objective, and complete. All provided definitions, equations, and tasks are standard within the field of numerical analysis for partial differential equations, specifically the study of Discontinuous Galerkin (DG) methods. The problem is therefore deemed **valid**, and a full solution is provided below.\n\n### Task 1: Derivation of the Semidiscrete Operator and Symbol\n\nWe begin with the one-dimensional linear advection equation, $u_t + a u_x = 0$. The Discontinuous Galerkin weak formulation is derived by multiplying the PDE by a test function $\\phi_m$ from the basis and integrating over a cell $I_j = [x_{j-1/2}, x_{j+1/2}]$.\n\n$$\n\\int_{I_j} \\frac{\\partial u_h}{\\partial t} \\phi_m \\,dx + \\int_{I_j} a \\frac{\\partial u_h}{\\partial x} \\phi_m \\,dx = 0\n$$\n\nHere, $u_h(x,t)$ is the approximate solution, which is a polynomial of degree $p=3$ within each cell. On cell $I_j$, the solution is expanded in the modal basis of Legendre polynomials $\\{\\phi_n(r)\\}_{n=0}^3$ on the reference element $r \\in [-1,1]$ via the mapping $x(r) = x_j + \\frac{h}{2}r$:\n\n$$\nu_h(x(r), t) = \\sum_{n=0}^{p} c_{jn}(t) \\phi_n(r)\n$$\n\nApplying integration by parts to the spatial term in the weak form gives:\n\n$$\n\\int_{I_j} \\frac{\\partial u_h}{\\partial t} \\phi_m \\,dx - a \\int_{I_j} u_h \\frac{\\partial \\phi_m}{\\partial x} \\,dx + [a \\, u_h \\phi_m]_{x_{j-1/2}}^{x_{j+1/2}} = 0\n$$\n\nThe boundary term $[a \\, u_h \\phi_m]_{x_{j-1/2}}^{x_{j+1/2}}$ is replaced by numerical fluxes. For the upwind flux with wave speed $a>0$, the flux at an interface is determined by the value from the upwind (left) cell. Let $\\hat{u}(x_{j+1/2})$ be the numerical flux value at the right boundary of cell $I_j$.\n$\\hat{u}(x_{j+1/2}) = u_h(x_{j+1/2}^-)$, the value from within cell $I_j$.\n$\\hat{u}(x_{j-1/2}) = u_h(x_{j-1/2}^-)$, the value from cell $I_{j-1}$.\nThe flux term becomes:\n\n$$\na \\, \\hat{u}(x_{j+1/2}) \\phi_m(x_{j+1/2}) - a \\, \\hat{u}(x_{j-1/2}) \\phi_m(x_{j-1/2}) = a \\, u_h(x_{j+1/2}^-) \\phi_m(x_{j+1/2}) - a \\, u_h(x_{j-1/2}^-) \\phi_m(x_{j-1/2})\n$$\n\nTransforming to the reference element $r \\in [-1,1]$ using $dx = \\frac{h}{2}dr$ and $\\frac{\\partial}{\\partial x} = \\frac{2}{h}\\frac{\\partial}{\\partial r}$:\n\n$$\n\\frac{h}{2} \\int_{-1}^1 \\left(\\sum_n \\frac{dc_{jn}}{dt} \\phi_n\\right) \\phi_m \\,dr - a \\int_{-1}^1 \\left(\\sum_n c_{jn} \\phi_n\\right) \\left(\\frac{2}{h}\\phi'_m\\right) \\frac{h}{2} \\,dr + a \\left(\\sum_n c_{jn} \\phi_n(1)\\right)\\phi_m(1) - a \\left(\\sum_n c_{j-1,n} \\phi_n(1)\\right)\\phi_m(-1) = 0\n$$\n\nThis equation holds for each basis function $\\phi_m$, $m=0, \\dots, p$. In matrix form, with $c_j = [c_{j0}, \\dots, c_{jp}]^T$:\n\n$$\n\\frac{h}{2} M c'_j(t) = a K c_j(t) - a \\left(\\Phi(1)\\Phi(1)^T\\right) c_j(t) + a \\left(\\Phi(-1)\\Phi(1)^T\\right) c_{j-1}(t)\n$$\n\nwhere the matrices $M$, $K$ and vectors $\\Phi(r)$ are defined on the reference element:\n$M_{mn} = \\int_{-1}^1 \\phi_m(r) \\phi_n(r) dr$, $K_{mn} = \\int_{-1}^1 \\phi'_m(r) \\phi_n(r) dr$, and $\\Phi(r) = [\\phi_0(r), \\dots, \\phi_p(r)]^T$.\nRearranging gives the semidiscrete form stated in the problem:\n\n$$\nc'_j(t) = \\frac{2a}{h} M^{-1} \\left[ K c_j(t) - (\\Phi(1)\\Phi(1)^T) c_j(t) + (\\Phi(-1)\\Phi(1)^T) c_{j-1}(t) \\right]\n$$\n\nFor a single Fourier mode, $c_j(t) = v(t) e^{i\\kappa j}$, we have $c_{j-1}(t) = v(t) e^{i\\kappa(j-1)} = e^{-i\\kappa} c_j(t)$. Substituting this into the semidiscrete form and noting $c'_j(t) = S(\\kappa) c_j(t)$ by definition, we obtain the symbol $S(\\kappa)$:\n\n$$\nS(\\kappa) = \\frac{2a}{h} M^{-1} \\left[ K - \\Phi(1)\\Phi(1)^T + e^{-i\\kappa} \\Phi(-1)\\Phi(1)^T \\right] = \\frac{2a}{h} M^{-1} \\left[ K - F_R + e^{-i\\kappa} G \\right]\n$$\nThis confirms the expression given in the problem.\n\nFor $p=3$, the basis functions are the Legendre polynomials $\\phi_n(r) = P_n(r)$:\n$\\phi_0(r) = 1$, $\\phi_1(r) = r$, $\\phi_2(r) = \\frac{1}{2}(3r^2 - 1)$, $\\phi_3(r) = \\frac{1}{2}(5r^3 - 3r)$.\nThe required matrices are computed as follows:\n- Mass Matrix $M$: Using the orthogonality property $\\int_{-1}^1 P_m(r)P_n(r) dr = \\frac{2}{2n+1}\\delta_{mn}$, $M$ is diagonal:\n  $$M = \\text{diag}\\left(2, \\frac{2}{3}, \\frac{2}{5}, \\frac{2}{7}\\right)$$\n- Stiffness Matrix $K$: With entries $K_{mn} = \\int_{-1}^1 \\phi'_m(r)\\phi_n(r) dr$. Using the property that this integral is $2$ for $n < m$ with $m-n$ odd, and $0$ otherwise:\n  $$K = \\begin{pmatrix} 0 & 0 & 0 & 0 \\\\ 2 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 2 & 0 & 2 & 0 \\end{pmatrix}$$\n- Face evaluation vectors $\\Phi(\\pm 1)$: Using $P_n(1)=1$ and $P_n(-1)=(-1)^n$:\n  $\\Phi(1) = [1, 1, 1, 1]^T$ and $\\Phi(-1) = [1, -1, 1, -1]^T$.\n- Face matrices $F_R$ and $G$:\n  $F_R = \\Phi(1)\\Phi(1)^T = \\begin{pmatrix} 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\end{pmatrix}$, and $G = \\Phi(-1)\\Phi(1)^T = \\begin{pmatrix} 1 & 1 & 1 & 1 \\\\ -1 & -1 & -1 & -1 \\\\ 1 & 1 & 1 & 1 \\\\ -1 & -1 & -1 & -1 \\end{pmatrix}$.\n\n### Task 2 & 3: Physical Eigenvalue, Dispersion, and Dissipation\n\nWith the matrices defined and constants $a=1, h=1$, the symbol $S(\\kappa)$ is a $4\\times 4$ complex matrix for each dimensionless wavenumber $\\kappa$. We compute its four eigenvalues $\\{\\lambda_j(\\kappa)\\}_{j=0}^3$. The analytical solution to the PDE has modes that evolve as $e^{-iak t} = e^{-i\\kappa t}$. The physical eigenvalue branch, $\\lambda^{\\text{phys}}(\\kappa)$, is the one whose imaginary part most closely corresponds to this behavior. We select the eigenvalue that minimizes $|\\text{Im}(\\lambda_j(\\kappa)) - (-a\\kappa/h)| = |\\text{Im}(\\lambda_j(\\kappa)) + \\kappa|$.\n\nFrom $\\lambda^{\\text{phys}}(\\kappa)$, the following quantities are calculated:\n- **Modified wavenumber:** $k^\\star(\\kappa) = -\\mathrm{Im}(\\lambda^\\text{phys}(\\kappa))/a$. This is the effective wavenumber of the numerical scheme.\n- **Dissipation rate:** $\\mathcal{D}(\\kappa) = \\mathrm{Re}(\\lambda^\\text{phys}(\\kappa))/a$. A negative value indicates numerical dissipation (amplitude decay), while a positive value indicates amplitude growth (instability).\n- **Dispersion error:** $\\mathcal{E}(\\kappa) = k^\\star(\\kappa) - k = k^\\star(\\kappa) - \\kappa/h$. This measures the phase error of the scheme.\n\nFor $\\kappa=0$, the solution is a constant in space, which should be propagated exactly. We expect $\\lambda^{\\text{phys}}(0)=0$, leading to $\\mathcal{D}(0)=0$ and $\\mathcal{E}(0)=0$. For other $\\kappa$, non-zero errors are expected.\n\n### Task 4: Fully Discrete Analysis and Limiter Comparison\n\nThe scheme is advanced in time using the three-stage Strong Stability Preserving Runge-Kutta method (SSP-RK3). The evolution of a Fourier mode over one time step $\\Delta t$ is given by $c_j(t+\\Delta t) = G(\\kappa, \\nu) c_j(t)$, where $G(\\kappa, \\nu)$ is the amplification matrix. It is defined by applying the SSP-RK3 stability polynomial $R(z)=1+z+\\frac{1}{2}z^2+\\frac{1}{6}z^3$ to the matrix $Z = \\Delta t S(\\kappa)$:\n\n$$ G(\\kappa, \\nu) = R(\\Delta t S(\\kappa)) = I + \\Delta t S(\\kappa) + \\frac{(\\Delta t S(\\kappa))^2}{2} + \\frac{(\\Delta t S(\\kappa))^3}{6} $$\n\nHere, $\\nu = a\\Delta t/h$ is the CFL number. For stability, the spectral radius of $G$, $\\rho(G) = \\max_j|\\lambda_j(G)|$, must be less than or equal to $1$. We compute the maximum spectral radius over a dense grid of wavenumbers $\\kappa \\in [0, \\pi]$ for each given CFL number $\\nu$.\n\nThe problem states to compare the results for WENO-limited DG and TVB-limited DG. Crucially, it assumes that in smooth regions of the solution, where limiters are inactive, both schemes reduce to the same underlying linear DG operator. Consequently, their semidiscrete symbols $S(\\kappa)$ are identical, their amplification matrices $G(\\kappa, \\nu)$ are identical, and their maximum spectral radii are identical. The comparison is therefore trivial under the problem's assumption, and the equality flag will be `True`.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the DG-p=3 linear advection analysis problem.\n    \"\"\"\n    # Problem parameters\n    p = 3\n    a = 1.0\n    h = 1.0\n\n    # Test cases from the problem statement\n    kappas_test = [0.0, 0.5, 2.5, np.pi]\n    nus_test = [0.05, 0.10, 0.20, 0.30]\n    kappa_grid_points = 201\n\n    # --- Part 1: Construct matrices for p=3 DG ---\n    \n    # Inverse of the mass matrix M\n    # M_mn = integral(P_m * P_n) = 2/(2n+1) * delta_mn\n    # M_inv_nn = (2n+1)/2\n    M_inv = np.diag([(2 * n + 1) / 2.0 for n in range(p + 1)])\n\n    # Stiffness matrix K\n    # K_mn = integral(P'_m * P_n)\n    # This is 2 if n < m and m-n is odd, 0 otherwise.\n    K = np.zeros((p + 1, p + 1))\n    for m in range(p + 1):\n        for n in range(m):\n            if (m - n) % 2 != 0:\n                K[m, n] = 2.0\n\n    # Face evaluation vectors and matrices\n    # Phi(1) = [1, 1, 1, 1]^T\n    # Phi(-1) = [1, -1, 1, -1]^T\n    phi_1 = np.ones(p + 1)\n    phi_m1 = np.array([(-1)**n for n in range(p + 1)])\n    \n    FR = np.outer(phi_1, phi_1)\n    G_face = np.outer(phi_m1, phi_1)\n\n    results = []\n\n    # --- Part 2 & 3: Dispersion and Dissipation Analysis ---\n    for kappa in kappas_test:\n        # Construct the symbol matrix S(kappa)\n        # S(k) = (2a/h) * M^-1 * [K - FR + exp(-i*k) * G]\n        A_kappa = K - FR + np.exp(-1j * kappa) * G_face\n        S_kappa = (2 * a / h) * M_inv @ A_kappa\n\n        # Find the physical eigenvalue\n        eigvals = np.linalg.eigvals(S_kappa)\n        target_imag = -a * kappa / h\n        phys_eig_idx = np.argmin(np.abs(np.imag(eigvals) - target_imag))\n        lambda_phys = eigvals[phys_eig_idx]\n\n        # Calculate dispersion and dissipation\n        # Dissipation rate D(k) = Re(lambda_phys)/a\n        dissipation_rate = np.real(lambda_phys) / a\n        \n        # Modified wavenumber k*(k) = -Im(lambda_phys)/a\n        k_star = -np.imag(lambda_phys) / a\n\n        # Dispersion error E(k) = k* - k\n        k = kappa / h\n        dispersion_error = k_star - k\n\n        results.extend([dispersion_error, dissipation_rate])\n\n    # --- Part 4: Fully discrete spectral radius analysis (SSP-RK3) ---\n    rho_max_results = []\n    kappa_grid = np.linspace(0, np.pi, kappa_grid_points)\n    I = np.identity(p + 1)\n\n    for nu in nus_test:\n        max_rho = 0.0\n        delta_t = nu * h / a\n\n        for kappa in kappa_grid:\n            # Construct S(kappa)\n            A_kappa = K - FR + np.exp(-1j * kappa) * G_face\n            S_kappa = (2 * a / h) * M_inv @ A_kappa\n\n            # Construct amplification matrix G(kappa, nu)\n            # G = R(delta_t * S) with R(z) = 1 + z + z^2/2 + z^3/6\n            Z = delta_t * S_kappa\n            Z2 = Z @ Z\n            Z3 = Z2 @ Z\n            G_amp = I + Z + 0.5 * Z2 + (1/6.0) * Z3\n            \n            # Spectral radius\n            rho = np.max(np.abs(np.linalg.eigvals(G_amp)))\n            if rho > max_rho:\n                max_rho = rho\n        \n        rho_max_results.append(max_rho)\n\n    results.extend(rho_max_results)\n\n    # --- Part 5: WENO vs TVB comparison ---\n    flag_results = []\n    for _ in nus_test:\n        # Per problem statement, in smooth regions, the limited schemes\n        # reduce to the same linear operator. Thus, their spectral\n        # radii are identical. The difference is 0, which is < 1e-12.\n        flag_results.append(True)\n    \n    results.extend(flag_results)\n    \n    # --- Final Output Formatting ---\n    print(f\"[{','.join(f'{x:.12f}' if isinstance(x, float) else str(x).lower() for x in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The effectiveness of a WENO limiter hinges on its nonlinear weights, which are derived from smoothness indicators computed via integrals. This exercise delves into a critical practical aspect: the numerical errors introduced when these integrals are approximated using finite-point quadrature rules. By investigating the discrepancy between limited coefficients calculated with different quadrature accuracies, you will gain insight into the potential for aliasing errors and the importance of selecting a sufficiently accurate quadrature to maintain the method's design order .",
            "id": "3429520",
            "problem": "Consider a one-dimensional Discontinuous Galerkin (DG) representation on the reference cell $I=[-1,1]$ with polynomial degree $p\\in\\mathbb{N}$. Let $\\{L_k(x)\\}_{k=0}^p$ denote the Legendre polynomials on $[-1,1]$, normalized such that $\\int_{-1}^{1} L_m(x)L_n(x)\\,dx=\\frac{2}{2n+1}\\delta_{mn}$. For a given smooth function $u(x)$, define the $L^2$ projection of $u(x)$ onto the polynomial space of degree $\\le p$ by $u_p(x)=\\sum_{k=0}^p a_k L_k(x)$, where the modal coefficients $a_k$ are determined by $a_k=\\frac{2k+1}{2}\\int_{-1}^1 u(x)L_k(x)\\,dx$.\n\nDefine a single-parameter WENO-type modal limiter that leaves the mean mode unchanged and scales all higher modes uniformly by a nonlinear weight. Specifically, let the smoothness indicator be $\\beta=\\int_{-1}^{1} \\left(u_p'(x)\\right)^2\\,dx$. The limiter constructs a limited modal vector $\\tilde{a}=(\\tilde{a}_0,\\tilde{a}_1,\\dots,\\tilde{a}_p)$ via $\\tilde{a}_0=a_0$ and $\\tilde{a}_k=\\omega\\,a_k$ for all $k\\in\\{1,\\dots,p\\}$, where the nonlinear weight $\\omega\\in(0,1)$ is defined by the two-candidate Jiang–Shu form\n$$\n\\alpha_{\\text{keep}}=\\frac{d_{\\text{keep}}}{(\\epsilon+\\beta)^r},\\qquad\n\\alpha_{\\text{zero}}=d_{\\text{zero}},\\qquad\n\\omega=\\frac{\\alpha_{\\text{keep}}}{\\alpha_{\\text{keep}}+\\alpha_{\\text{zero}}}.\n$$\nHere $d_{\\text{keep}}\\in(0,1)$ and $d_{\\text{zero}}\\in(0,1)$ are fixed linear weights with $d_{\\text{keep}}+d_{\\text{zero}}=1$, $\\epsilon>0$ is a small parameter preventing division by zero, and $r\\ge 1$ is a positive integer. In practice, the smoothness indicator integral is approximated by Gauss–Legendre quadrature with $q$ points,\n$$\n\\beta_q=\\sum_{i=1}^{q} w_i\\left(u_p'(x_i)\\right)^2,\n$$\nwhere $\\{(x_i,w_i)\\}_{i=1}^q$ are Gauss–Legendre nodes and weights on $[-1,1]$. The corresponding weight is denoted $\\omega_q$ and the corresponding limited coefficients by $\\tilde{a}^{(q)}$. Define a high-accuracy baseline $\\beta_\\star$ computed by Gauss–Legendre quadrature with $q_\\star$ points, where $q_\\star$ is sufficiently large (take $q_\\star=200$), with associated $\\omega_\\star$ and $\\tilde{a}^{(\\star)}$.\n\nYour objectives are:\n- Starting only from the definitions of $L^2$ projection, Legendre orthogonality, and Gauss–Legendre quadrature, quantify the aliasing error introduced when nonlinear WENO weights are applied to modal coefficients because of using $\\beta_q$ instead of $\\beta_\\star$. Use the coefficient-space Euclidean error\n$$\n\\mathcal{E}(p,q,\\epsilon,r,u)=\\left\\|\\tilde{a}^{(q)}-\\tilde{a}^{(\\star)}\\right\\|_2.\n$$\n- Propose and implement a quadrature rule that uses $q\\ge 2p$ Gauss–Legendre points to preserve the DG design order in the presence of nonlinear modal limiting, and numerically compare with smaller and larger $q$ values.\n- Test sensitivity of $\\mathcal{E}$ with respect to the parameter $\\epsilon$ in the nonlinear weights.\n\nUse the following fundamental base:\n- Orthogonal projection in $L^2([-1,1])$ onto polynomial subspaces.\n- Orthogonality and completeness properties of Legendre polynomials on $[-1,1]$.\n- Polynomial-exactness of Gauss–Legendre quadrature of order $q$ for integrands of degree $\\le 2q-1$.\n\nAlgorithmic requirements:\n- Compute modal coefficients $a_k$ by numerically evaluating $\\int_{-1}^{1} u(x)L_k(x)\\,dx$ using Gauss–Legendre quadrature with $q_\\text{proj}$ points, where $q_\\text{proj}$ is sufficiently large to be effectively exact for the chosen smooth $u(x)$ (take $q_\\text{proj}=200$).\n- Form $u_p(x)=\\sum_{k=0}^p a_k L_k(x)$ and its derivative $u_p'(x)$ via Legendre-basis operations.\n- Compute $\\beta_q$ for the given $q$ and $\\beta_\\star$ for $q_\\star=200$; then compute $\\omega_q$ and $\\omega_\\star$ and the corresponding limited vectors $\\tilde{a}^{(q)}$ and $\\tilde{a}^{(\\star)}$.\n- Report $\\mathcal{E}(p,q,\\epsilon,r,u)$ as a floating-point number for each test.\n\nFunctions to use for $u(x)$:\n- $u_1(x)=\\sin(\\pi x)$.\n- $u_2(x)=\\exp(x)$.\n\nFix $d_{\\text{keep}}=0.99$, $d_{\\text{zero}}=0.01$, and $r=2$ for all tests.\n\nTest suite:\n- Case $1$: $p=3$, $q=6$, $\\epsilon=10^{-6}$, $u=u_1$.\n- Case $2$: $p=3$, $q=3$, $\\epsilon=10^{-6}$, $u=u_1$.\n- Case $3$: $p=3$, $q=9$, $\\epsilon=10^{-6}$, $u=u_1$.\n- Case $4$: $p=4$, $q=8$, $\\epsilon=10^{-12}$, $u=u_2$.\n- Case $5$: $p=4$, $q=8$, $\\epsilon=10^{-3}$, $u=u_2$.\n- Case $6$: $p=1$, $q=2$, $\\epsilon=10^{-6}$, $u=u_1$.\n\nAngle units are not applicable. No physical units are involved. Each test must return a single real number equal to $\\mathcal{E}(p,q,\\epsilon,r,u)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite, for example $[\\mathcal{E}_1,\\mathcal{E}_2,\\dots,\\mathcal{E}_6]$.",
            "solution": "The problem requires an analysis of the numerical error introduced in a Weighted Essentially Non-Oscillatory (WENO) type modal limiter for a Discontinuous Galerkin (DG) method. The source of error under investigation is the use of numerical quadrature with a finite number of points, $q$, to compute a smoothness indicator, $\\beta$, which in turn determines a nonlinear limiting weight, $\\omega$. The error is measured in the Euclidean norm of the difference between the limited modal coefficient vector computed with $q$ points, $\\tilde{a}^{(q)}$, and a high-accuracy baseline vector, $\\tilde{a}^{(\\star)}$, computed with a large number of points, $q_\\star$.\n\nThe solution proceeds in several steps:\n1.  Representation of the function and its projection.\n2.  Formulation of the smoothness indicator and its numerical evaluation.\n3.  Analysis of the conditions for exact quadrature of the smoothness indicator.\n4.  Calculation of the limited modal coefficients and the error metric.\n\n**1. L2 Projection and Polynomial Representation**\n\nGiven a smooth function $u(x)$ on the reference interval $I = [-1, 1]$, its $L^2$ projection onto the space of polynomials of degree at most $p$, $\\mathbb{P}_p$, is given by\n$$\nu_p(x) = \\sum_{k=0}^{p} a_k L_k(x)\n$$\nwhere $\\{L_k(x)\\}_{k=0}^p$ are the Legendre polynomials. The modal coefficients $a_k$ are determined by exploiting the orthogonality property of Legendre polynomials, $\\int_{-1}^{1} L_m(x)L_n(x)\\,dx=\\frac{2}{2n+1}\\delta_{mn}$:\n$$\n\\int_{-1}^{1} u(x) L_k(x) \\,dx = \\sum_{j=0}^{p} a_j \\int_{-1}^{1} L_j(x) L_k(x) \\,dx = a_k \\frac{2}{2k+1}\n$$\nThis gives the formula for the exact modal coefficients:\n$$\na_k = \\frac{2k+1}{2} \\int_{-1}^{1} u(x) L_k(x) \\,dx\n$$\nIn this problem, this integral is computed numerically using Gauss-Legendre quadrature with a sufficiently large number of points, $q_{\\text{proj}}=200$, to ensure high accuracy. Let the quadrature nodes and weights be $\\{(x_j^{\\text{proj}}, w_j^{\\text{proj}})\\}_{j=1}^{q_{\\text{proj}}}$. The computed coefficients are:\n$$\na_k \\approx \\hat{a}_k = \\frac{2k+1}{2} \\sum_{j=1}^{q_{\\text{proj}}} w_j^{\\text{proj}} u(x_j^{\\text{proj}}) L_k(x_j^{\\text{proj}})\n$$\nFor the remainder of this analysis, we will work with the polynomial $\\hat{u}_p(x) = \\sum_{k=0}^p \\hat{a}_k L_k(x)$, which is built from these numerically computed coefficients.\n\n**2. Smoothness Indicator and Numerical Quadrature**\n\nThe WENO limiter's behavior is governed by the smoothness indicator $\\beta$, defined as the squared $L^2$-norm of the derivative of the polynomial approximation:\n$$\n\\beta = \\int_{-1}^{1} (\\hat{u}_p'(x))^2 \\,dx\n$$\nThe derivative $\\hat{u}_p'(x)$ is formed by differentiating the polynomial term by term:\n$$\n\\hat{u}_p'(x) = \\sum_{k=0}^{p} \\hat{a}_k L_k'(x) = \\sum_{k=1}^{p} \\hat{a}_k L_k'(x) \\quad (\\text{since } L_0'(x)=0)\n$$\nSince $L_k'(x)$ is a polynomial of degree $k-1$, $\\hat{u}_p'(x)$ is a polynomial of degree at most $p-1$. Consequently, the integrand $(\\hat{u}_p'(x))^2$ is a polynomial of degree at most $2(p-1)$.\n\nGauss-Legendre quadrature with $q$ points is exact for any polynomial integrand of degree up to $2q-1$. To compute $\\beta$ exactly (up to floating-point precision), we must choose $q$ such that:\n$$\n2q - 1 \\ge 2(p-1) \\implies 2q \\ge 2p - 1 \\implies q \\ge p - \\frac{1}{2}\n$$\nSince $q$ must be an integer, any choice of $q \\ge p$ will result in the exact evaluation of the integral for $\\beta$.\n\nThe problem requires comparing $\\beta_q$, calculated with $q$ points, to a baseline $\\beta_\\star$, calculated with $q_\\star = 200$ points. Given that $p \\ll 200$ for all test cases, the baseline $\\beta_\\star$ can be considered the exact value of the integral. For any test case where $q \\ge p$, theory suggests that $\\beta_q$ should also be exact, and thus $\\beta_q = \\beta_\\star$.\n\n**3. Nonlinear Limiting and Error Analysis**\n\nThe limited modal coefficients $\\tilde{a}_k$ are calculated as:\n$$\n\\tilde{a}_0 = \\hat{a}_0, \\qquad \\tilde{a}_k = \\omega \\cdot \\hat{a}_k \\quad \\text{for } k \\in \\{1, \\dots, p\\}\n$$\nThe nonlinear weight $\\omega$ is a function of $\\beta$:\n$$\n\\omega(\\beta) = \\frac{\\alpha_{\\text{keep}}}{\\alpha_{\\text{keep}}+\\alpha_{\\text{zero}}} = \\frac{d_{\\text{keep}}/(\\epsilon+\\beta)^r}{d_{\\text{keep}}/(\\epsilon+\\beta)^r + d_{\\text{zero}}}\n$$\nThe error metric is the Euclidean distance between the coefficient vector $\\tilde{a}^{(q)}$ (using $\\omega_q = \\omega(\\beta_q)$) and the baseline vector $\\tilde{a}^{(\\star)}$ (using $\\omega_\\star = \\omega(\\beta_\\star)$):\n$$\n\\mathcal{E} = \\left\\|\\tilde{a}^{(q)}-\\tilde{a}^{(\\star)}\\right\\|_2 = \\sqrt{\\sum_{k=0}^p (\\tilde{a}_k^{(q)} - \\tilde{a}_k^{(\\star)})^2}\n$$\nSince $\\tilde{a}_0^{(q)} = \\tilde{a}_0^{(\\star)} = \\hat{a}_0$, the sum starts from $k=1$:\n$$\n\\mathcal{E}^2 = \\sum_{k=1}^p (\\omega_q \\hat{a}_k - \\omega_\\star \\hat{a}_k)^2 = (\\omega_q - \\omega_\\star)^2 \\sum_{k=1}^p \\hat{a}_k^2\n$$\n$$\n\\mathcal{E} = |\\omega_q - \\omega_\\star| \\sqrt{\\sum_{k=1}^p \\hat{a}_k^2}\n$$\nThe error $\\mathcal{E}$ is non-zero only if $\\omega_q \\ne \\omega_\\star$, which implies $\\beta_q \\ne \\beta_\\star$. As established, for $q \\ge p$, both $\\beta_q$ and $\\beta_\\star$ should be exact evaluations of the same integral. However, they are computed using different sets of quadrature nodes and weights, leading to different sequences of floating-point operations. The computed values, $\\beta_q^{\\text{float}}$ and $\\beta_\\star^{\\text{float}}$, can differ by a small amount due to round-off error.\n$$\n\\beta_q^{\\text{float}} - \\beta_\\star^{\\text{float}} \\approx O(\\epsilon_{\\text{machine}})\n$$\nThis small difference can be significantly amplified by the nonlinear function $\\omega(\\beta)$, especially if its derivative, $\\frac{d\\omega}{d\\beta}$, is large. The derivative is:\n$$\n\\frac{d\\omega}{d\\beta} = \\frac{-r \\, d_{\\text{keep}} \\, d_{\\text{zero}}}{(\\epsilon+\\beta)^{r+1} \\left( d_{\\text{keep}}(\\epsilon+\\beta)^{-r} + d_{\\text{zero}} \\right)^2}\n$$\nWhen the smoothness parameter $\\epsilon$ is very small, this derivative can become very large, particularly for small $\\beta$. This explains the sensitivity of the error $\\mathcal{E}$ to $\\epsilon$. Therefore, the problem is an investigation into the numerical stability of the limiter formulation, where what would be zero error in exact arithmetic manifests as non-zero error in finite-precision arithmetic, with the magnitude depending on the specific quadrature rule ($q$) and the parameters ($\\epsilon$).\n\nThe recommendation of $q \\ge 2p$ in the problem description, while not strictly necessary for polynomial exactness in this specific indicator formulation, represents a more conservative rule of thumb often used in DG methods for nonlinear flux terms to ensure robustness and control of aliasing errors in more general contexts. The test suite allows for a numerical exploration of whether such a conservative choice provides better numerical stability here.\n\n**4. Computational Steps**\n\nFor each test case specified by $(p, q, \\epsilon, u)$:\n1.  Set fixed parameters: $r=2$, $d_\\text{keep}=0.99$, $d_\\text{zero}=0.01$, $q_\\text{proj}=200$, $q_\\star=200$.\n2.  Compute the modal coefficients $\\hat{a}_k$ for $k=0, \\dots, p$ by numerically projecting $u(x)$ using $q_\\text{proj}$ Gauss-Legendre points.\n3.  Construct the polynomial representation of the derivative, $\\hat{u}_p'(x) = \\sum_{k=1}^p \\hat{a}_k L_k'(x)$.\n4.  Compute the smoothness indicator $\\beta_q$ by integrating $(\\hat{u}_p'(x))^2$ with $q$ Gauss-Legendre points.\n5.  Compute the reference smoothness indicator $\\beta_\\star$ by integrating $(\\hat{u}_p'(x))^2$ with $q_\\star=200$ Gauss-Legendre points.\n6.  Calculate the corresponding nonlinear weights $\\omega_q = \\omega(\\beta_q)$ and $\\omega_\\star = \\omega(\\beta_\\star)$ using the provided formula.\n7.  Construct the limited coefficient vectors $\\tilde{a}^{(q)}$ and $\\tilde{a}^{(\\star)}$.\n8.  Calculate and report the error $\\mathcal{E} = \\|\\tilde{a}^{(q)} - \\tilde{a}^{(\\star)}\\|_2$.\n\nThis procedure is implemented for each test case to generate the final results.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import legendre\n\ndef compute_error(p, q, epsilon, r, u_func, d_keep, d_zero):\n    \"\"\"\n    Computes the aliasing error for the WENO modal limiter.\n\n    Args:\n        p (int): Polynomial degree.\n        q (int): Number of quadrature points for the test indicator.\n        epsilon (float): Regularization parameter for the WENO weight.\n        r (int): Exponent for the WENO weight.\n        u_func (callable): The smooth function u(x).\n        d_keep (float): Linear weight for the 'keep' stencil.\n        d_zero (float): Linear weight for the 'zero' stencil.\n\n    Returns:\n        float: The coefficient-space Euclidean error E.\n    \"\"\"\n    q_proj = 200\n    q_star = 200\n\n    # 1. Compute modal coefficients a_k by numerical projection\n    x_proj, w_proj = np.polynomial.legendre.leggauss(q_proj)\n    u_vals_proj = u_func(x_proj)\n    a = np.zeros(p + 1)\n    for k in range(p + 1):\n        L_k_poly = legendre(k)\n        L_k_vals_proj = L_k_poly(x_proj)\n        integral = np.sum(w_proj * u_vals_proj * L_k_vals_proj)\n        a[k] = (2 * k + 1) / 2.0 * integral\n\n    # 2. Form the derivative polynomial u_p'(x)\n    # This creates a callable polynomial object for u_p'(x)\n    up_prime_poly = np.poly1d([0.0])\n    if p > 0:\n        for k in range(1, p + 1):\n            if np.abs(a[k]) > 1e-40: # Avoid adding zero polynomials\n                L_k_poly = legendre(k)\n                L_k_prime_poly = L_k_poly.deriv(1)\n                up_prime_poly += a[k] * L_k_prime_poly\n\n    # 3. Compute beta_q and beta_star\n    # Function to compute beta for a given number of quadrature points\n    def calculate_beta(num_points):\n        if num_points == 0:\n            return 0.0\n        x_quad, w_quad = np.polynomial.legendre.leggauss(num_points)\n        up_prime_vals = up_prime_poly(x_quad)\n        beta_val = np.sum(w_quad * up_prime_vals**2)\n        return beta_val\n\n    beta_q = calculate_beta(q)\n    beta_star = calculate_beta(q_star)\n\n    # 4. Compute omega weights\n    def calculate_omega(beta):\n        alpha_keep = d_keep / (epsilon + beta)**r\n        alpha_zero = d_zero\n        # Handle potential division by zero if both are zero.\n        if alpha_keep + alpha_zero == 0:\n            return 0.0\n        return alpha_keep / (alpha_keep + alpha_zero)\n\n    omega_q = calculate_omega(beta_q)\n    omega_star = calculate_omega(beta_star)\n    \n    # 5. Construct limited coefficient vectors\n    a_tilde_q = np.copy(a)\n    a_tilde_star = np.copy(a)\n    \n    a_tilde_q[1:] *= omega_q\n    a_tilde_star[1:] *= omega_star\n\n    # 6. Compute the Euclidean error\n    error = np.linalg.norm(a_tilde_q - a_tilde_star)\n    \n    return error\n\ndef solve():\n    \"\"\"\n    Runs the full test suite and prints the results.\n    \"\"\"\n    # Define functions for u(x)\n    u1 = lambda x: np.sin(np.pi * x)\n    u2 = lambda x: np.exp(x)\n\n    # Fixed parameters for all tests\n    d_keep = 0.99\n    d_zero = 0.01\n    r = 2\n\n    # Test suite from the problem statement\n    test_cases = [\n        # (p, q, epsilon, u_func)\n        (3, 6, 1e-6, u1),   # Case 1\n        (3, 3, 1e-6, u1),   # Case 2\n        (3, 9, 1e-6, u1),   # Case 3\n        (4, 8, 1e-12, u2),  # Case 4\n        (4, 8, 1e-3, u2),   # Case 5\n        (1, 2, 1e-6, u1),   # Case 6\n    ]\n\n    results = []\n    for p, q, eps, u_f in test_cases:\n        error_val = compute_error(p, q, eps, r, u_f, d_keep, d_zero)\n        results.append(error_val)\n    \n    # Format the output exactly as required\n    print(f\"[{','.join(f'{res:.10e}' for res in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond forward simulation, advanced applications like optimization and uncertainty quantification require computing sensitivities, a task efficiently handled by the adjoint method. This practice confronts a core challenge in this domain: the non-differentiability of the WENO limiter, which complicates the derivation of the discrete adjoint. You will implement and compare a simplified \"frozen-limiter\" adjoint against a more rigorous \"almost-everywhere consistent\" version, quantifying the impact of the limiter's non-smoothness on gradient accuracy .",
            "id": "3429546",
            "problem": "Consider the one-dimensional linear advection equation on the periodic domain $[0,1)$ with constant velocity $a>0$. Use a Discontinuous Galerkin (DG) discretization of polynomial degree $0$ (piecewise-constant per cell) on a uniform mesh with $N$ cells of width $\\Delta x = 1/N$, and an explicit forward Euler time integrator with time step $\\Delta t$. The semi-discrete DG update for the cell averages $\\{u_i^n\\}_{i=0}^{N-1}$ at time level $t^n$ is defined using an upwind numerical flux with a reconstruction-limited left state at each cell face.\n\nThe numerical flux at face $i+\\tfrac{1}{2}$ uses the left trace reconstructed from cell $i$:\n- Let the backward difference $s_L = u_i - u_{i-1}$ and the forward difference $s_R = u_{i+1} - u_i$ (with periodic indexing). Define the minmod-limited slope $\\sigma_i = \\operatorname{minmod}(s_L, s_R)$, where $\\operatorname{minmod}(a,b)$ equals $a$ if $ab>0$ and $\\lvert a \\rvert \\le \\lvert b \\rvert$, equals $b$ if $ab>0$ and $\\lvert b \\rvert < \\lvert a \\rvert$, and equals $0$ otherwise.\n- Define a WENO-type weight $\\omega_i(u)$ using the local total variation proxy $S_i = \\lvert u_i - u_{i-1} \\rvert + \\lvert u_{i+1} - u_i \\rvert$ and a positive scale $\\kappa$: $\\omega_i(u) = \\dfrac{S_i}{S_i + \\kappa}$.\n- The limiter strength is a scalar parameter $\\lambda \\in [0,1]$. The reconstructed left state at face $i+\\tfrac{1}{2}$ is\n$$\nu_{i+\\frac{1}{2}}^{-} \\;=\\; u_i \\;+\\; \\tfrac{1}{2}\\,\\lambda\\,\\omega_i(u)\\,\\sigma_i.\n$$\n\nUsing the upwind flux for $a>0$, the fully discrete forward Euler update is\n$$\nu_i^{n+1} \\;=\\; u_i^{n} \\;-\\; \\frac{a\\,\\Delta t}{\\Delta x} \\Big( u_{i+\\frac{1}{2}}^{-}(u^{n}) \\;-\\; u_{i-\\frac{1}{2}}^{-}(u^{n}) \\Big),\n$$\nwith periodic indexing for all cell-centered and face quantities.\n\nLet the objective be the least-squares mismatch of the final-time numerical solution against the exact transported initial condition:\n$$\nJ(u^N) \\;=\\; \\tfrac{1}{2}\\,\\Delta x \\sum_{i=0}^{N-1} \\Big( u_i^{N} \\;-\\; u_i^{\\star} \\Big)^2,\n$$\nwhere $u^{\\star}$ is the initial condition transported exactly by a shift $a\\,T$ over the final time $T = N_t \\Delta t$, sampled at the same cell centers. The exact transport is periodic on $[0,1)$.\n\nYour tasks are:\n1. Starting from the definition of the fully discrete forward Euler map $\\Phi(u^n,\\lambda) = u^n + \\Delta t\\,L(u^n,\\lambda)$, where $L$ is the semi-discrete spatial operator induced by the upwind flux with the limiter specified above, derive the discrete adjoint recursion and the expression for the gradient $\\dfrac{dJ}{d\\lambda}$ via the chain rule and the implicit function theorem for the time-stepping constraints. Explicitly account for the limiter dependence $\\lambda\\,\\omega(u)$ through both $\\lambda$ and $u$.\n2. Construct two discrete adjoint variants:\n   - A \"frozen-limiter\" adjoint that ignores all derivatives of $\\omega(u)$ and $\\sigma(u)$ with respect to $u$ in the Jacobian, i.e., treats limiter-dependent terms as constants when forming the linearization.\n   - An \"almost-everywhere consistent\" adjoint that includes the derivatives $\\dfrac{\\partial \\omega}{\\partial u}$ and $\\dfrac{\\partial \\sigma}{\\partial u}$ using the following conventions at non-differentiable points: use $\\operatorname{sign}(x)$ with $\\operatorname{sign}(0)=0$ for derivatives of absolute values, and for the minmod operator use the active-branch derivative in regions where it is uniquely determined, and set the derivative to $0$ on ties and at switching points.\n3. Quantify the impact of non-differentiable weights on gradient accuracy by comparing both adjoint gradients against a central finite-difference reference computed on the fully discrete forward simulation, using a small symmetric perturbation $h$ in $\\lambda$.\n\nUse the following test suite. For each test, define the initial condition at cell centers $x_i = (i+\\tfrac{1}{2})\\Delta x$ as specified, use periodic boundaries, and choose the time step by a Courant–Friedrichs–Lewy (CFL) condition $\\mathrm{CFL} = 0.4$ via $\\Delta t = \\mathrm{CFL}\\, \\Delta x / a$, and then take $N_t = \\lceil T/\\Delta t \\rceil$ steps with a uniform $\\Delta t = T/N_t$:\n- Test $1$ (smooth): $N=100$, $a=1$, $\\kappa=0.01$, $T=0.1$, $\\lambda=0.4$, $u_0(x)=\\sin(2\\pi x)$.\n- Test $2$ (discontinuous): $N=100$, $a=1$, $\\kappa=0.01$, $T=0.1$, $\\lambda=0.4$, $u_0(x)=1$ if $x \\in [0.3,0.7)$ and $0$ otherwise.\n- Test $3$ (edge $\\lambda=0$ smooth): $N=100$, $a=1$, $\\kappa=0.01$, $T=0.1$, $\\lambda=0.0$, $u_0(x)=\\sin(2\\pi x)$.\n- Test $4$ (edge $\\lambda=1$ discontinuous): $N=100$, $a=1$, $\\kappa=0.01$, $T=0.05$, $\\lambda=1.0$, $u_0(x)=1$ if $x \\in [0.3,0.7)$ and $0$ otherwise.\n\nFor each test, compute:\n- The central finite difference gradient $g_{\\mathrm{fd}} = \\dfrac{J(\\lambda+h) - J(\\lambda-h)}{2h}$ with $h=10^{-6}$.\n- The frozen-limiter adjoint gradient $g_{\\mathrm{frz}}$.\n- The almost-everywhere consistent adjoint gradient $g_{\\mathrm{ae}}$.\n\nReport, for each test, the relative gradient errors\n$$\ne_{\\mathrm{frz}} = \\frac{\\lvert g_{\\mathrm{frz}} - g_{\\mathrm{fd}} \\rvert}{\\max(\\lvert g_{\\mathrm{fd}} \\rvert,\\,10^{-12})}, \\qquad\ne_{\\mathrm{ae}} = \\frac{\\lvert g_{\\mathrm{ae}} - g_{\\mathrm{fd}} \\rvert}{\\max(\\lvert g_{\\mathrm{fd}} \\rvert,\\,10^{-12})}.\n$$\n\nFinal output format:\n- Your program should produce a single line of output containing the errors across all tests as a comma-separated list of floats enclosed in square brackets, ordered as $[e_{\\mathrm{frz}}^{(1)}, e_{\\mathrm{ae}}^{(1)}, e_{\\mathrm{frz}}^{(2)}, e_{\\mathrm{ae}}^{(2)}, e_{\\mathrm{frz}}^{(3)}, e_{\\mathrm{ae}}^{(3)}, e_{\\mathrm{frz}}^{(4)}, e_{\\mathrm{ae}}^{(4)}]$.\n\nAll angles, if any, are to be in radians. No physical units are involved beyond the abstract parameters stated. Ensure all numerical values used in your derivations and computations are consistent with the definitions above. The initial conditions and parameters are mathematically well-posed, and the numerical updates should use the stated discretization choices without introducing external approximations beyond those specified. The program must be self-contained and require no input. The final printed line is the only output.",
            "solution": "The user has provided a well-defined problem in the field of numerical methods for partial differential equations, specifically focusing on adjoint-based sensitivity analysis for a Discontinuous Galerkin (DG) scheme. The problem is to derive, implement, and compare two discrete adjoint models for computing the gradient of a cost function with respect to a limiter parameter.\n\n### Problem Validation\n\nThe problem statement is parsed and validated according to the specified criteria.\n\n**1. Extracted Givens:**\n- **PDE:** One-dimensional linear advection equation $u_t + a u_x = 0$ with $a>0$.\n- **Domain:** $[0, 1)$ with periodic boundary conditions.\n- **Discretization:** DG($P_0$) on a uniform mesh of $N$ cells, width $\\Delta x = 1/N$. Cell centers are $x_i = (i+1/2)\\Delta x$.\n- **Time Integration:** Explicit forward Euler with timestep $\\Delta t$.\n- **Limiter Definition:**\n    - Backward/forward differences: $s_L = u_i - u_{i-1}$, $s_R = u_{i+1} - u_i$.\n    - `minmod` slope: $\\sigma_i = \\operatorname{minmod}(s_L, s_R)$, with $\\operatorname{minmod}(a,b) = a$ if $ab>0$ and $|a| \\le |b|$, $b$ if $ab>0$ and $|b| < |a|$, and $0$ otherwise.\n    - WENO-type weight: $\\omega_i(u) = \\frac{S_i}{S_i + \\kappa}$, where $S_i = |u_i - u_{i-1}| + |u_{i+1} - u_i|$ and $\\kappa > 0$.\n- **Reconstructed State:** $u_{i+1/2}^{-} = u_i + \\frac{1}{2}\\lambda\\omega_i(u)\\sigma_i$, where $\\lambda \\in [0,1]$ is the limiter strength.\n- **Fully Discrete Update:** $u_i^{n+1} = u_i^{n} - \\frac{a\\Delta t}{\\Delta x} ( u_{i+1/2}^{-}(u^{n}) - u_{i-1/2}^{-}(u^{n}) )$.\n- **Objective Function:** $J(u^{N_t}) = \\frac{1}{2}\\Delta x \\sum_{i=0}^{N-1} ( u_i^{N_t} - u_i^{\\star} )^2$.\n- **Exact Solution:** $u^{\\star}$ is the initial condition $u_0$ transported by $aT$ over the final time $T=N_t \\Delta t$.\n- **Tasks:** 1) Derive discrete adjoint recursion and gradient $\\frac{dJ}{d\\lambda}$. 2) Construct a \"frozen-limiter\" and an \"almost-everywhere consistent\" adjoint. 3) Compare gradients to a finite-difference approximation.\n- **Derivative Conventions:** For non-differentiable functions, $\\frac{d|x|}{dx} = \\operatorname{sign}(x)$ with $\\operatorname{sign}(0)=0$, and minmod derivatives are based on the active branch, being zero at switching points or ties.\n- **Test Suite:** Four test cases with specified parameters for $N, a, \\kappa, T, \\lambda,$ and $u_0(x)$.\n- **Time Stepping:** $\\Delta t = \\mathrm{CFL} \\cdot \\Delta x / a$ with $\\mathrm{CFL}=0.4$, and $N_t = \\lceil T/\\Delta t \\rceil$ steps using a fixed $\\Delta t = T/N_t$.\n- **Output:** A list of eight relative error values $[e_{\\mathrm{frz}}^{(1)}, e_{\\mathrm{ae}}^{(1)}, ..., e_{\\mathrm{frz}}^{(4)}, e_{\\mathrm{ae}}^{(4)}]$.\n\n**2. Validation Analysis:**\n- **Scientific Grounding:** The problem is firmly rooted in the theory of numerical analysis, specifically DG methods, slope limiting, and discrete adjoint methods. All concepts are standard in the field.\n- **Well-Posedness:** The problem is well-posed. The numerical scheme is fully specified, the objective function is clearly defined, and the tasks are concrete mathematical derivations and numerical experiments.\n- **Objectivity:** The problem is stated in precise, objective, mathematical language.\nThe problem is found to be free of any flaws listed in the validation criteria (scientific unsoundness, incompleteness, contradiction, etc.).\n\n**3. Verdict:**\nThe problem is **valid**.\n\n### Derivation of the Discrete Adjoint Method\n\nThe objective is to compute the total derivative of the cost function $J$ with respect to the limiter parameter $\\lambda$. The forward propagation of the solution is a sequence of states $\\{u^n\\}_{n=0}^{N_t}$ governed by the discrete-time map $u^{n+1} = \\Phi(u^n, \\lambda)$. The cost function $J$ depends on the final state $u^{N_t}$, which in turn is a function of $\\lambda$. Using the chain rule, the total derivative is $\\frac{dJ}{d\\lambda} = \\frac{\\partial J}{\\partial u^{N_t}} \\frac{du^{N_t}}{d\\lambda}$. The discrete adjoint method provides an efficient way to compute this without forming the sensitivity matrix $\\frac{du^{N_t}}{d\\lambda}$.\n\nWe introduce a discrete Lagrangian $\\mathcal{L}$ by appending the time-stepping constraints with vector Lagrange multipliers (adjoint states) $\\{\\psi^{n+1}\\}_{n=0}^{N_t-1}$:\n$$\n\\mathcal{L}(u^0, \\dots, u^{N_t}, \\psi^1, \\dots, \\psi^{N_t}, \\lambda) = J(u^{N_t}) - \\sum_{n=0}^{N_t-1} (\\psi^{n+1})^T (u^{n+1} - \\Phi(u^n, \\lambda))\n$$\nThe gradient of $J$ is the total derivative of $\\mathcal{L}$ with respect to $\\lambda$, evaluated at a stationary point where $\\frac{\\partial\\mathcal{L}}{\\partial u^n} = 0$ for all $n=1,\\dots,N_t$.\n\n**1. Adjoint Equation:**\nSetting the gradient of $\\mathcal{L}$ with respect to the state $u^n$ to zero yields the adjoint equations.\nFor $n=N_t$:\n$$\n\\frac{\\partial\\mathcal{L}}{\\partial u^{N_t}} = \\frac{\\partial J}{\\partial u^{N_t}} - (\\psi^{N_t})^T = 0 \\quad \\implies \\quad \\psi^{N_t} = \\left(\\frac{\\partial J}{\\partial u^{N_t}}\\right)^T\n$$\nGiven $J = \\frac{1}{2}\\Delta x \\sum_{i=0}^{N-1} (u_i^{N_t} - u_i^{\\star})^2$, the terminal adjoint state is $(\\psi^{N_t})_i = \\Delta x (u_i^{N_t} - u_i^{\\star})$.\n\nFor $n=1, \\dots, N_t-1$:\n$$\n\\frac{\\partial\\mathcal{L}}{\\partial u^n} = (\\psi^{n+1})^T \\frac{\\partial \\Phi(u^n, \\lambda)}{\\partial u^n} - (\\psi^n)^T = 0 \\quad \\implies \\quad \\psi^n = \\left(\\frac{\\partial \\Phi(u^n, \\lambda)}{\\partial u^n}\\right)^T \\psi^{n+1}\n$$\nThis is a linear recursion for the adjoint states, propagating information backward in time from $n=N_t-1$ down to $n=0$. The matrix $\\frac{\\partial \\Phi}{\\partial u^n}$ is the Jacobian of the forward update map.\n\n**2. Gradient Expression:**\nThe gradient of $J$ is then found by differentiating $\\mathcal{L}$ with respect to $\\lambda$:\n$$\n\\frac{dJ}{d\\lambda} = \\frac{\\partial\\mathcal{L}}{\\partial \\lambda} = \\sum_{n=0}^{N_t-1} (\\psi^{n+1})^T \\frac{\\partial \\Phi(u^n, \\lambda)}{\\partial \\lambda}\n$$\nThis expression sums the contributions from each time step, where each contribution is the inner product of the adjoint state from the next time level and the partial derivative of the forward map with respect to $\\lambda$.\n\n**3. Jacobian and Gradient Components:**\nLet $C = \\frac{a\\Delta t}{\\Delta x}$. The forward map $\\Phi_i(u, \\lambda) = u_i^{n+1}$ for cell $i$ is:\n$$\n\\Phi_i(u, \\lambda) = u_i - C \\left[ \\left(u_i + \\frac{\\lambda}{2}\\omega_i\\sigma_i\\right) - \\left(u_{i-1} + \\frac{\\lambda}{2}\\omega_{i-1}\\sigma_{i-1}\\right) \\right]\n$$\nwhere $\\omega_j = \\omega_j(u)$ and $\\sigma_j = \\sigma_j(u)$.\n\nThe derivative with respect to $\\lambda$ is:\n$$\n\\frac{\\partial \\Phi_i(u, \\lambda)}{\\partial \\lambda} = -\\frac{C}{2} (\\omega_i\\sigma_i - \\omega_{i-1}\\sigma_{i-1})\n$$\nThe Jacobian of the forward map is $\\mathbf{A}_{ij} = \\frac{\\partial \\Phi_i}{\\partial u_j}$.\n$$\n\\mathbf{A}_{ij} = \\frac{\\partial}{\\partial u_j} \\left[ u_i - C(u_i - u_{i-1}) - \\frac{C\\lambda}{2}(\\omega_i\\sigma_i - \\omega_{i-1}\\sigma_{i-1}) \\right]\n$$\n$$\n\\mathbf{A}_{ij} = (1-C)\\delta_{ij} + C\\delta_{i-1,j} - \\frac{C\\lambda}{2}\\left( \\frac{\\partial(\\omega_i\\sigma_i)}{\\partial u_j} - \\frac{\\partial(\\omega_{i-1}\\sigma_{i-1})}{\\partial u_j} \\right)\n$$\nThe two adjoint variants arise from different treatments of the terms $\\frac{\\partial(\\omega\\sigma)}{\\partial u}$.\n\n#### Frozen-Limiter Adjoint\nIn this variant, the limiter components $\\omega_i$ and $\\sigma_i$ are treated as constants with respect to $u$. All derivatives of these terms are set to zero. The Jacobian simplifies to:\n$$\n\\mathbf{A}^{\\text{frz}}_{ij} = (1-C)\\delta_{ij} + C\\delta_{i-1,j}\n$$\nThe adjoint update $\\psi^n = (\\mathbf{A}^{\\text{frz}})^T \\psi^{n+1}$ becomes:\n$$\n\\psi_i^n = \\sum_j \\mathbf{A}^{\\text{frz}}_{ji} \\psi_j^{n+1} = \\sum_j \\left( (1-C)\\delta_{ji} + C\\delta_{j-1,i} \\right) \\psi_j^{n+1} = (1-C)\\psi_i^{n+1} + C\\psi_{i+1}^{n+1}\n$$\nThis is a discrete advection operator, corresponding to a backward-in-time integration of the adjoint PDE.\n\n#### Almost-Everywhere Consistent Adjoint\nThis variant includes the derivatives of the limiter terms. We define $K_{k,j} = \\frac{\\partial(\\omega_k\\sigma_k)}{\\partial u_j}$. Using the product rule:\n$K_{k,j} = \\frac{\\partial \\omega_k}{\\partial u_j}\\sigma_k + \\omega_k\\frac{\\partial \\sigma_k}{\\partial u_j}$.\nThe derivatives of $\\omega_k$ and $\\sigma_k$ are derived based on the problem's conventions:\nLet $s_{L,k} = u_k - u_{k-1}$ and $s_{R,k} = u_{k+1} - u_k$.\n- $\\frac{\\partial S_k}{\\partial u_j} = \\frac{\\partial}{\\partial u_j}(|s_{L,k}|+|s_{R,k}|)$, which is non-zero for $j \\in \\{k-1, k, k+1\\}$. Specifically: $\\frac{\\partial S_k}{\\partial u_{k-1}} = -\\text{sign}(s_{L,k})$, $\\frac{\\partial S_k}{\\partial u_k} = \\text{sign}(s_{L,k}) - \\text{sign}(s_{R,k})$, $\\frac{\\partial S_k}{\\partial u_{k+1}} = \\text{sign}(s_{R,k})$.\n- $\\frac{\\partial \\omega_k}{\\partial u_j} = \\frac{\\kappa}{(S_k+\\kappa)^2} \\frac{\\partial S_k}{\\partial u_j}$.\n- Let $D_{a,k}=1$ if $s_{L,k}s_{R,k}>0, |s_{L,k}|\\le|s_{R,k}|$ and $0$ otherwise. Let $D_{b,k}=1$ if $s_{L,k}s_{R,k}>0, |s_{R,k}|<|s_{L,k}|$ and $0$ otherwise.\n- $\\frac{\\partial \\sigma_k}{\\partial u_j} = D_{a,k} \\frac{\\partial s_{L,k}}{\\partial u_j} + D_{b,k} \\frac{\\partial s_{R,k}}{\\partial u_j}$. This is non-zero for $j \\in \\{k-1, k, k+1\\}$. Specifically: $\\frac{\\partial \\sigma_k}{\\partial u_{k-1}}=-D_{a,k}$, $\\frac{\\partial \\sigma_k}{\\partial u_k}=D_{a,k}-D_{b,k}$, $\\frac{\\partial \\sigma_k}{\\partial u_{k+1}}=D_{b,k}$.\n\nThe action of the full Jacobian transpose on an adjoint vector $\\psi^{n+1}$ gives the next state $\\psi^n$. The update for a component $\\psi_k^n$ is found by summing all influences: $\\psi_k^n = \\sum_j \\mathbf{A}_{jk} \\psi_j^{n+1}$.\nThe stencil for $\\Phi_j$ depends on $u$ at indices $\\{j-2, j-1, j, j+1\\}$. Therefore, $\\frac{\\partial \\Phi_j}{\\partial u_k}$ is non-zero only for $j \\in \\{k-1, k, k+1, k+2\\}$.\nThe full adjoint update is:\n$$\n\\psi_k^n = \\frac{\\partial \\Phi_{k-1}}{\\partial u_k}\\psi_{k-1}^{n+1} + \\frac{\\partial \\Phi_k}{\\partial u_k}\\psi_k^{n+1} + \\frac{\\partial \\Phi_{k+1}}{\\partial u_k}\\psi_{k+1}^{n+1} + \\frac{\\partial \\Phi_{k+2}}{\\partial u_k}\\psi_{k+2}^{n+1}\n$$\nSubstituting the expressions for the partial derivatives:\n$\\frac{\\partial \\Phi_{k-1}}{\\partial u_k} = -\\frac{C\\lambda}{2} K_{k-1,k}$\n$\\frac{\\partial \\Phi_{k}}{\\partial u_k} = (1-C) - \\frac{C\\lambda}{2}(K_{k,k}-K_{k-1,k})$\n$\\frac{\\partial \\Phi_{k+1}}{\\partial u_k} = C - \\frac{C\\lambda}{2}(K_{k+1,k}-K_{k,k})$\n$\\frac{\\partial \\Phi_{k+2}}{\\partial u_k} = \\frac{C\\lambda}{2}K_{k+1,k}$\nThis results in a 5-point stencil for the AE-consistent adjoint update, which must be re-evaluated at each backward time step using the stored forward states $u^n$.\n\nThe frozen-limiter adjoint is computationally cheaper and simpler but neglects the feedback of the solution $u$ on the limiter, which can lead to inaccuracies in the gradient. The almost-everywhere consistent adjoint correctly accounts for this feedback where the limiter is differentiable, and is expected to provide a more accurate gradient, especially for solutions with strong variations where the limiter is active. The numerical comparison will quantify this difference.",
            "answer": "```python\nimport numpy as np\nfrom math import ceil\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        # Test 1 (smooth)\n        {'N': 100, 'a': 1.0, 'kappa': 0.01, 'T': 0.1, 'lambda_': 0.4, \n         'u0_func': lambda x: np.sin(2 * np.pi * x), 'name': 'smooth'},\n        # Test 2 (discontinuous)\n        {'N': 100, 'a': 1.0, 'kappa': 0.01, 'T': 0.1, 'lambda_': 0.4, \n         'u0_func': lambda x: np.where((x >= 0.3) & (x < 0.7), 1.0, 0.0), 'name': 'discontinuous'},\n        # Test 3 (edge lambda=0 smooth)\n        {'N': 100, 'a': 1.0, 'kappa': 0.01, 'T': 0.1, 'lambda_': 0.0, \n         'u0_func': lambda x: np.sin(2 * np.pi * x), 'name': 'edge_lambda0_smooth'},\n        # Test 4 (edge lambda=1 discontinuous)\n        {'N': 100, 'a': 1.0, 'kappa': 0.01, 'T': 0.05, 'lambda_': 1.0, \n         'u0_func': lambda x: np.where((x >= 0.3) & (x < 0.7), 1.0, 0.0), 'name': 'edge_lambda1_discontinuous'},\n    ]\n\n    CFL = 0.4\n    h_fd = 1e-6\n    all_errors = []\n\n    for params in test_cases:\n        # Compute finite difference gradient\n        J_plus, _ = run_forward_model({**params, 'lambda_': params['lambda_'] + h_fd}, CFL)\n        J_minus, _ = run_forward_model({**params, 'lambda_': params['lambda_'] - h_fd}, CFL)\n        g_fd = (J_plus - J_minus) / (2 * h_fd)\n\n        # Compute adjoint gradients\n        _, u_history = run_forward_model(params, CFL)\n\n        # Frozen adjoint\n        g_frz = run_adjoint_model(params, CFL, u_history, 'frozen')\n        \n        # Almost-everywhere consistent adjoint\n        g_ae = run_adjoint_model(params, CFL, u_history, 'ae')\n\n        # Calculate relative errors\n        denom = max(abs(g_fd), 1e-12)\n        err_frz = abs(g_frz - g_fd) / denom\n        err_ae = abs(g_ae - g_fd) / denom\n        \n        all_errors.extend([err_frz, err_ae])\n\n    print(f\"[{','.join(f'{e:.8f}' for e in all_errors)}]\")\n\ndef get_limiter_terms(u, kappa):\n    \"\"\"Computes limiter components sigma and omega.\"\"\"\n    N = len(u)\n    u_m1 = np.roll(u, 1)\n    u_p1 = np.roll(u, -1)\n\n    s_L = u - u_m1\n    s_R = u_p1 - u\n    \n    # minmod\n    cond_a = (s_L * s_R > 0) & (np.abs(s_L) <= np.abs(s_R))\n    cond_b = (s_L * s_R > 0) & (np.abs(s_R) < np.abs(s_L))\n    sigma = np.where(cond_a, s_L, np.where(cond_b, s_R, 0.0))\n\n    # WENO-type weight\n    S = np.abs(s_L) + np.abs(s_R)\n    omega = S / (S + kappa)\n    \n    return sigma, omega\n\ndef run_forward_model(params, CFL):\n    \"\"\"\n    Runs the forward simulation and returns the cost function value and state history.\n    \"\"\"\n    N, a, lambda_, T, u0_func = params['N'], params['a'], params['lambda_'], params['T'], params['u0_func']\n    kappa = params.get('kappa', 0.01)\n    \n    dx = 1.0 / N\n    x = (np.arange(N) + 0.5) * dx\n    \n    dt_cfl = CFL * dx / a\n    Nt = ceil(T / dt_cfl)\n    dt = T / Nt\n    \n    u = u0_func(x)\n    u_history = [u.copy()]\n    \n    C = a * dt / dx\n\n    for _ in range(Nt):\n        sigma, omega = get_limiter_terms(u, kappa)\n        \n        u_face_m = u + 0.5 * lambda_ * omega * sigma\n        \n        u_new = u - C * (u_face_m - np.roll(u_face_m, 1))\n        u = u_new\n        u_history.append(u.copy())\n        \n    # Compute cost function\n    x_shifted = (x - a * T) - np.floor(x - a*T)\n    u_star = u0_func(x_shifted)\n    J = 0.5 * dx * np.sum((u - u_star)**2)\n    \n    return J, u_history\n\ndef run_adjoint_model(params, CFL, u_history, mode):\n    \"\"\"\n    Runs the adjoint simulation and computes the gradient dJ/dlambda.\n    \"\"\"\n    N, a, lambda_, T, kappa = params['N'], params['a'], params['lambda_'], params['T'], params['kappa']\n    u0_func = params['u0_func']\n\n    dx = 1.0 / N\n    x = (np.arange(N) + 0.5) * dx\n    \n    dt_cfl = CFL * dx / a\n    Nt = ceil(T / dt_cfl)\n    dt = T / Nt\n\n    C = a * dt / dx\n    \n    # Terminal adjoint state\n    u_final = u_history[-1]\n    x_shifted = (x - a * T) - np.floor(x - a * T)\n    u_star = u0_func(x_shifted)\n    psi = dx * (u_final - u_star)\n    \n    dJ_dlambda = 0.0\n    \n    for n in range(Nt - 1, -1, -1):\n        u_n = u_history[n]\n        \n        # Gradient contribution from this step\n        sigma_n, omega_n = get_limiter_terms(u_n, kappa)\n        \n        grad_contrib_term = omega_n * sigma_n - np.roll(omega_n * sigma_n, 1)\n        dJ_dlambda += -0.5 * C * np.sum(psi * grad_contrib_term)\n        \n        # Adjoint state update\n        if mode == 'frozen':\n            psi = (1 - C) * psi + C * np.roll(psi, -1)\n        elif mode == 'ae':\n            # AE-consistent Jacobian terms\n            u_m1 = np.roll(u_n, 1)\n            u_p1 = np.roll(u_n, -1)\n            \n            s_L = u_n - u_m1\n            s_R = u_p1 - u_n\n            \n            # Derivatives of sigma\n            cond_a = (s_L * s_R > 0) & (np.abs(s_L) <= np.abs(s_R))\n            cond_b = (s_L * s_R > 0) & (np.abs(s_R) < np.abs(s_L))\n            D_a_sigma = np.where(cond_a, 1.0, 0.0)\n            D_b_sigma = np.where(cond_b, 1.0, 0.0)\n            \n            dsigma_du_m1 = -D_a_sigma\n            dsigma_du_c = D_a_sigma - D_b_sigma\n            dsigma_du_p1 = D_b_sigma\n            \n            # Derivatives of omega\n            S = np.abs(s_L) + np.abs(s_R)\n            omega_prime_S = kappa / (S + kappa)**2\n            \n            sign_sL = np.sign(s_L)\n            sign_sR = np.sign(s_R)\n            \n            domega_du_m1 = omega_prime_S * (-sign_sL)\n            domega_du_c = omega_prime_S * (sign_sL - sign_sR)\n            domega_du_p1 = omega_prime_S * (sign_sR)\n            \n            # Derivatives of T_i = omega_i * sigma_i\n            # dT_i/du_j\n            dTdu_m1 = domega_du_m1 * sigma_n + omega_n * dsigma_du_m1\n            dTdu_c  = domega_du_c  * sigma_n + omega_n * dsigma_du_c\n            dTdu_p1 = domega_du_p1 * sigma_n + omega_n * dsigma_du_p1\n            \n            # Jacobian-transpose-vector product\n            # This is dPhi^T/du * psi\n            term = (1 - C) * psi + C * np.roll(psi, -1) # base part\n\n            T_m1_term = dTdu_c - np.roll(dTdu_p1,-1)\n            term += -0.5 * C * lambda_ * psi * T_m1_term\n\n            T_c_term = np.roll(dTdu_m1, 1) - dTdu_c\n            term += -0.5 * C * lambda_ * np.roll(psi, -1) * T_c_term\n            \n            T_p1_term = dTdu_p1 - np.roll(dTdu_c,1)\n            term += -0.5 * C * lambda_ * np.roll(psi,1) * T_p1_term\n            \n            psi = term\n\n        else:\n            raise ValueError(f\"Unknown adjoint mode: {mode}\")\n            \n    return dJ_dlambda\n\n# Custom run for this specific problem\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}