{
    "hands_on_practices": [
        {
            "introduction": "Domain decomposition methods gain much of their flexibility from allowing non-conforming interfaces, where the discretization on one subdomain does not perfectly match its neighbor. Mortar methods are a powerful technique for coupling across such interfaces by enforcing conditions in a weak sense. This first practice  delves into the core of this technique by having you calculate the projection error when transferring data from a high-degree polynomial space to a lower-degree one, connecting the abstract concept of $L^2$ projection to a concrete, quantifiable error.",
            "id": "3381380",
            "problem": "Consider a nonconforming interface (mortar) in a Discontinuous Galerkin (DG) domain decomposition setting for one-dimensional spectral elements. Let the physical interface (face) be the image of the reference interval $[-1,1]$ under an affine mapping with constant Jacobian $J$, so that $J = h/2$ where $h>0$ is the physical face length. The mortar space is the polynomial space $\\mathbb{P}_{q}$ with $q<p$, and the face trace $u(\\xi)$ is a polynomial of degree $p$ expanded in the orthonormal Legendre basis $\\{L_{k}(\\xi)\\}_{k=0}^{p}$ on $[-1,1]$, where $\\int_{-1}^{1} L_{k}(\\xi)L_{m}(\\xi)\\,\\mathrm{d}\\xi = \\delta_{km}$. The $L^{2}$ mortar projection $\\Pi_{q}:L^{2}([-1,1])\\to \\mathbb{P}_{q}$ is defined via the weighted $L^{2}$ inner product on the physical face,\n$$\n(u,v)_{\\Gamma} := \\int_{-1}^{1} u(\\xi)\\,v(\\xi)\\,J\\,\\mathrm{d}\\xi,\n$$\nand its error is measured by the norm $\\|u-\\Pi_{q}u\\|_{L^{2}(\\Gamma)} := \\left((u-\\Pi_{q}u,u-\\Pi_{q}u)_{\\Gamma}\\right)^{1/2}$.\n\nStarting from the definitions of orthonormality and the $L^{2}$ projection as the unique minimizer of the $L^{2}$ norm of the error, derive the exact expression for the mortar projection error $\\|u-\\Pi_{q}u\\|_{L^{2}(\\Gamma)}$ in terms of the tail coefficients of the orthonormal Legendre expansion of $u$ and the best approximation error\n$$\nE_{q}(u) := \\inf_{v\\in \\mathbb{P}_{q}} \\|u-v\\|_{L^{2}([-1,1])}.\n$$\nThen, for the specific case $p=5$, $q=2$, and\n$$\nu(\\xi) = \\sum_{k=0}^{5} a_{k}\\,L_{k}(\\xi), \\quad a_{3} = 2,\\quad a_{4} = -1,\\quad a_{5} = 3,\n$$\ncompute the exact value of $\\|u-\\Pi_{q}u\\|_{L^{2}(\\Gamma)}$ and express your final answer as a single closed-form analytic expression in terms of $h$. No rounding is required, and no physical units should be used in the final answer.",
            "solution": "The problem is well-posed and scientifically grounded in the theory of spectral and Discontinuous Galerkin methods. We proceed with the solution.\n\nThe problem asks for two main results:\n1. A derivation of the exact expression for the mortar projection error $\\|u-\\Pi_{q}u\\|_{L^{2}(\\Gamma)}$ in terms of the tail coefficients of the orthonormal Legendre expansion of $u$ and the best approximation error $E_{q}(u)$.\n2. The computation of this error for a specific case.\n\n**Part 1: General Derivation of the Projection Error**\n\nLet $u(\\xi)$ be a polynomial of degree $p$, $u \\in \\mathbb{P}_{p}$, defined on the reference interval $[-1, 1]$. It has an expansion in the orthonormal Legendre basis $\\{L_{k}(\\xi)\\}_{k=0}^{p}$ given by:\n$$u(\\xi) = \\sum_{k=0}^{p} a_{k}L_{k}(\\xi)$$\nwhere the coefficients are $a_k = \\int_{-1}^{1} u(\\xi) L_k(\\xi) \\,d\\xi$. The orthonormality condition is $\\int_{-1}^{1} L_{k}(\\xi)L_{m}(\\xi)\\,\\mathrm{d}\\xi = \\delta_{km}$.\n\nThe mortar projection $\\Pi_{q}u$ is the $L^{2}$ projection of $u$ onto the polynomial space $\\mathbb{P}_{q}$ for $q<p$. The projection is defined with respect to the weighted inner product on the physical face $\\Gamma$, $(f,g)_{\\Gamma} := \\int_{-1}^{1} f(\\xi)g(\\xi)J\\,\\mathrm{d}\\xi$, where $J = h/2$ is the constant Jacobian.\n\nBy definition, the $L^{2}$ projection $\\Pi_{q}u$ is the unique element in $\\mathbb{P}_{q}$ that minimizes the error in the corresponding norm. This is equivalent to the orthogonality condition that the error $u - \\Pi_{q}u$ is orthogonal to the subspace $\\mathbb{P}_{q}$:\n$$(u - \\Pi_{q}u, v)_{\\Gamma} = 0 \\quad \\forall v \\in \\mathbb{P}_{q}$$\nSince $\\{L_{m}(\\xi)\\}_{m=0}^{q}$ is a basis for $\\mathbb{P}_{q}$, it is sufficient to enforce this for each basis function:\n$$(u - \\Pi_{q}u, L_{m})_{\\Gamma} = 0 \\quad \\text{for } m = 0, 1, \\dots, q$$\nThis implies $(u, L_{m})_{\\Gamma} = (\\Pi_{q}u, L_{m})_{\\Gamma}$.\n\nLet the projection be expressed in the basis of $\\mathbb{P}_q$ as $\\Pi_{q}u(\\xi) = \\sum_{j=0}^{q} c_{j}L_{j}(\\xi)$. Substituting the expansions for $u$ and $\\Pi_q u$ into the orthogonality condition, we get:\n$$\\left(\\sum_{k=0}^{p} a_{k}L_{k}, L_{m}\\right)_{\\Gamma} = \\left(\\sum_{j=0}^{q} c_{j}L_{j}, L_{m}\\right)_{\\Gamma} \\quad \\text{for } m = 0, \\dots, q$$\nUsing the definition of the inner product $(f,g)_{\\Gamma} = J \\int_{-1}^{1} fg \\,d\\xi$:\n$$J \\int_{-1}^{1} \\left(\\sum_{k=0}^{p} a_{k}L_{k}(\\xi)\\right) L_{m}(\\xi) \\,d\\xi = J \\int_{-1}^{1} \\left(\\sum_{j=0}^{q} c_{j}L_{j}(\\xi)\\right) L_{m}(\\xi) \\,d\\xi$$\nSince $J$ is a non-zero constant, it can be canceled. By linearity of the integral:\n$$\\sum_{k=0}^{p} a_{k} \\int_{-1}^{1} L_{k}(\\xi)L_{m}(\\xi) \\,d\\xi = \\sum_{j=0}^{q} c_{j} \\int_{-1}^{1} L_{j}(\\xi)L_{m}(\\xi) \\,d\\xi$$\nUsing the orthonormality relation $\\int_{-1}^{1} L_{k}(\\xi)L_{m}(\\xi)\\,\\mathrm{d}\\xi = \\delta_{km}$:\n$$\\sum_{k=0}^{p} a_{k} \\delta_{km} = \\sum_{j=0}^{q} c_{j} \\delta_{jm}$$\nFor any given $m \\in \\{0, \\dots, q\\}$, the sums collapse to a single term on each side:\n$$a_{m} = c_{m}$$\nThis holds for all $m = 0, \\dots, q$. Therefore, the mortar projection is simply the truncated Legendre series of $u$:\n$$\\Pi_{q}u(\\xi) = \\sum_{k=0}^{q} a_{k}L_{k}(\\xi)$$\nThe projection error is the difference between $u$ and its projection:\n$$u(\\xi) - \\Pi_{q}u(\\xi) = \\sum_{k=0}^{p} a_{k}L_{k}(\\xi) - \\sum_{k=0}^{q} a_{k}L_{k}(\\xi) = \\sum_{k=q+1}^{p} a_{k}L_{k}(\\xi)$$\nThe squared norm of the projection error is:\n$$\\|u-\\Pi_{q}u\\|_{L^{2}(\\Gamma)}^{2} = (u-\\Pi_{q}u, u-\\Pi_{q}u)_{\\Gamma} = \\left(\\sum_{k=q+1}^{p} a_{k}L_{k}, \\sum_{j=q+1}^{p} a_{j}L_{j}\\right)_{\\Gamma}$$\n$$= J \\int_{-1}^{1} \\left(\\sum_{k=q+1}^{p} a_{k}L_{k}(\\xi)\\right) \\left(\\sum_{j=q+1}^{p} a_{j}L_{j}(\\xi)\\right) d\\xi$$\n$$= J \\sum_{k=q+1}^{p} \\sum_{j=q+1}^{p} a_{k}a_{j} \\int_{-1}^{1} L_{k}(\\xi)L_{j}(\\xi) d\\xi$$\n$$= J \\sum_{k=q+1}^{p} \\sum_{j=q+1}^{p} a_{k}a_{j} \\delta_{kj} = J \\sum_{k=q+1}^{p} a_{k}^{2}$$\nTaking the square root gives the error in terms of the tail coefficients $a_k$ for $k > q$:\n$$\\|u-\\Pi_{q}u\\|_{L^{2}(\\Gamma)} = \\sqrt{J \\sum_{k=q+1}^{p} a_{k}^{2}}$$\nNow, we relate this to the best approximation error $E_{q}(u)$, defined as $E_{q}(u) := \\inf_{v\\in \\mathbb{P}_{q}} \\|u-v\\|_{L^{2}([-1,1])}$, where the norm is the standard (unweighted) $L^{2}$ norm on the reference element, $\\|f\\|_{L^{2}([-1,1])} = (\\int_{-1}^{1} (f(\\xi))^2 d\\xi)^{1/2}$.\nThe best approximation in $\\mathbb{P}_{q}$ is given by the orthogonal projection of $u$ onto $\\mathbb{P}_{q}$ with respect to the standard $L^{2}([-1,1])$ inner product. Since the basis $\\{L_k\\}$ is orthonormal for this inner product as well, the best approximation is again the truncated series $\\sum_{k=0}^{q} a_k L_k(\\xi)$.\nThe best approximation error is the norm of the remainder:\n$$E_{q}(u)^{2} = \\left\\| u - \\sum_{k=0}^{q} a_k L_k \\right\\|_{L^{2}([-1,1])}^{2} = \\left\\| \\sum_{k=q+1}^{p} a_k L_k \\right\\|_{L^{2}([-1,1])}^{2}$$\n$$= \\int_{-1}^{1} \\left(\\sum_{k=q+1}^{p} a_{k}L_{k}(\\xi)\\right)^{2} d\\xi = \\sum_{k=q+1}^{p} a_{k}^{2}$$\nThus, the best approximation error is given by the root mean square of the tail coefficients:\n$$E_{q}(u) = \\sqrt{\\sum_{k=q+1}^{p} a_{k}^{2}}$$\nCombining these results, the mortar-projection error can be expressed in terms of both the tail coefficients and the best approximation error as:\n$$\\|u-\\Pi_{q}u\\|_{L^{2}(\\Gamma)} = \\sqrt{J} \\left(\\sum_{k=q+1}^{p} a_{k}^{2}\\right)^{1/2} = \\sqrt{J} E_{q}(u)$$\n\n**Part 2: Specific Calculation**\n\nWe are given the specific case with:\n-   Polynomial degree $p=5$\n-   Mortar space degree $q=2$\n-   Jacobian $J = h/2$\n-   Legendre coefficients $a_{3} = 2$, $a_{4} = -1$, and $a_{5} = 3$.\n\nThe coefficients $a_0, a_1, a_2$ are not needed, as the error only depends on the tail coefficients for $k > q$.\nUsing the formula derived in Part 1, the projection error is:\n$$\\|u-\\Pi_{2}u\\|_{L^{2}(\\Gamma)} = \\sqrt{J \\sum_{k=2+1}^{5} a_{k}^{2}} = \\sqrt{\\frac{h}{2} \\sum_{k=3}^{5} a_{k}^{2}}$$\nWe compute the sum of the squares of the relevant coefficients:\n$$\\sum_{k=3}^{5} a_{k}^{2} = a_{3}^{2} + a_{4}^{2} + a_{5}^{2}$$\n$$\\sum_{k=3}^{5} a_{k}^{2} = (2)^{2} + (-1)^{2} + (3)^{2} = 4 + 1 + 9 = 14$$\nSubstituting this value back into the expression for the error norm:\n$$\\|u-\\Pi_{2}u\\|_{L^{2}(\\Gamma)} = \\sqrt{\\frac{h}{2} \\cdot 14} = \\sqrt{7h}$$\nThis is the exact value of the mortar projection error in terms of $h$.",
            "answer": "$$\\boxed{\\sqrt{7h}}$$"
        },
        {
            "introduction": "In practice, integrals arising from the weak form of a PDE are evaluated using numerical quadrature. For nonlinear problems, the integrand's polynomial degree can be high, and using an inadequate quadrature rule can introduce aliasing errors, a subtle but significant source of inaccuracy. This exercise  provides a concrete scenario to analyze this effect, asking you to compute the exact aliasing error resulting from using a lower-order quadrature rule to integrate a nonlinear flux term at a subdomain interface.",
            "id": "3381360",
            "problem": "Consider a one-dimensional interface arising from domain decomposition in a spectral element discretization of a scalar conservation law, where flux continuity is enforced by a mortar projection in a Discontinuous Galerkin (DG) method. Let the mortar space be the span of Legendre polynomials up to degree $m=2$ on the canonical interval $[-1,1]$, with basis functions $P_{0}(s)$, $P_{1}(s)$, and $P_{2}(s)$, where $P_{2}(s) = \\frac{1}{2}\\left(3 s^{2} - 1\\right)$. Consider the nonlinear flux $F(u) = u^3$ and let the interface trace be the polynomial $u(s) = \\alpha s + \\beta$ with real parameters $\\alpha$ and $\\beta$. The mortar projection coefficient $c_{2}$ is defined by the $L^{2}$ inner product\n$$\nc_{2} = \\int_{-1}^{1} F\\!\\left(u(s)\\right) P_{2}(s) \\, ds.\n$$\nIn practice, this integral is evaluated by quadrature rules. The $3$-point Gauss–Legendre quadrature on $[-1,1]$ is exact for polynomials of degree up to $5$, while the $3$-point Gauss–Lobatto quadrature on $[-1,1]$ with nodes $s \\in \\{-1, 0, 1\\}$ and weights $w \\in \\left\\{\\frac{1}{3}, \\frac{4}{3}, \\frac{1}{3}\\right\\}$ is exact for polynomials of degree up to $3$. Define the aliasing error incurred by using Gauss–Lobatto instead of Gauss–Legendre in the evaluation of $c_{2}$ as\n$$\nE = Q_{\\mathrm{GLob}}\\!\\left(g\\right) - Q_{\\mathrm{Gauss}}\\!\\left(g\\right),\n$$\nwhere $g(s) = F\\!\\left(u(s)\\right) P_{2}(s)$, $Q_{\\mathrm{GLob}}$ denotes the $3$-point Gauss–Lobatto quadrature, and $Q_{\\mathrm{Gauss}}$ denotes the $3$-point Gauss–Legendre quadrature. Compute a closed-form analytic expression for $E$ in terms of $\\alpha$ and $\\beta$. Provide your final answer as a single expression. No rounding is required and no units are associated with the answer.",
            "solution": "The problem requires the computation of the aliasing error, $E$, resulting from the use of a $3$-point Gauss-Lobatto quadrature rule instead of a $3$-point Gauss-Legendre quadrature rule for a specific mortar projection integral in a Discontinuous Galerkin method.\n\nThe problem first passes the validation stage.\n- **Givens**:\n    - Nonlinear flux: $F(u) = u^{3}$\n    - Interface trace: $u(s) = \\alpha s + \\beta$\n    - Legendre polynomial of degree $2$: $P_{2}(s) = \\frac{1}{2}(3s^{2} - 1)$\n    - Integrand: $g(s) = F(u(s)) P_{2}(s)$\n    - Quadratures:\n        - $Q_{\\mathrm{Gauss}}$, $3$-point Gauss-Legendre, exact for polynomials of degree up to $5$.\n        - $Q_{\\mathrm{GLob}}$, $3$-point Gauss-Lobatto with nodes $s \\in \\{-1, 0, 1\\}$ and weights $w \\in \\{\\frac{1}{3}, \\frac{4}{3}, \\frac{1}{3}\\}$, exact for polynomials of degree up to $3$.\n    - Aliasing Error: $E = Q_{\\mathrm{GLob}}(g) - Q_{\\mathrm{Gauss}}(g)$\n\n- **Validation Verdict**: The problem is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. All concepts are standard in numerical analysis for partial differential equations. The problem is deemed valid.\n\nThe solution proceeds as follows.\n\nFirst, we define the integrand $g(s)$.\nThe flux evaluated on the interface trace is:\n$$\nF(u(s)) = (\\alpha s + \\beta)^{3}\n$$\nThe integrand is the product of this flux and the Legendre polynomial $P_{2}(s)$:\n$$\ng(s) = F(u(s)) P_{2}(s) = (\\alpha s + \\beta)^{3} \\left( \\frac{1}{2}(3s^{2} - 1) \\right)\n$$\nThe polynomial $F(u(s))$ has degree $3$, and $P_{2}(s)$ has degree $2$. Therefore, the integrand $g(s)$ is a polynomial of degree $3 + 2 = 5$.\n\nThe aliasing error is defined as $E = Q_{\\mathrm{GLob}}(g) - Q_{\\mathrm{Gauss}}(g)$.\nThe problem states that the $3$-point Gauss-Legendre quadrature, $Q_{\\mathrm{Gauss}}$, is exact for polynomials of degree up to $5$. Since $\\deg(g) = 5$, the quadrature yields the exact value of the integral:\n$$\nQ_{\\mathrm{Gauss}}(g) = \\int_{-1}^{1} g(s) \\, ds\n$$\nThe error expression thus simplifies to:\n$$\nE = Q_{\\mathrm{GLob}}(g) - \\int_{-1}^{1} g(s) \\, ds\n$$\nThis is precisely the quadrature error of the $3$-point Gauss-Lobatto rule when applied to the function $g(s)$.\n\nTo compute $E$, we must calculate both terms on the right-hand side.\n\n**1. Calculation of the exact integral, $\\int_{-1}^{1} g(s) \\, ds$**\n\nFirst, we expand the polynomial $g(s)$:\n$$\nF(u(s)) = (\\alpha s + \\beta)^{3} = \\alpha^{3}s^{3} + 3\\alpha^{2}\\beta s^{2} + 3\\alpha\\beta^{2}s + \\beta^{3}\n$$\nThen, we multiply by $P_{2}(s) = \\frac{3}{2}s^{2} - \\frac{1}{2}$:\n$$\ng(s) = \\left( \\alpha^{3}s^{3} + 3\\alpha^{2}\\beta s^{2} + 3\\alpha\\beta^{2}s + \\beta^{3} \\right) \\left( \\frac{3}{2}s^{2} - \\frac{1}{2} \\right)\n$$\n$$\ng(s) = \\frac{3}{2}\\alpha^{3}s^{5} + \\frac{9}{2}\\alpha^{2}\\beta s^{4} + \\left( \\frac{9}{2}\\alpha\\beta^{2} - \\frac{1}{2}\\alpha^{3} \\right)s^{3} + \\left( \\frac{3}{2}\\beta^{3} - \\frac{3}{2}\\alpha^{2}\\beta \\right)s^{2} - \\frac{3}{2}\\alpha\\beta^{2}s - \\frac{1}{2}\\beta^{3}\n$$\nWhen integrating a polynomial over the symmetric interval $[-1, 1]$, the integrals of all terms with odd powers of $s$ are zero. We only need to consider the even-powered terms:\n$$\n\\int_{-1}^{1} g(s) \\, ds = \\int_{-1}^{1} \\left( \\frac{9}{2}\\alpha^{2}\\beta s^{4} + \\left( \\frac{3}{2}\\beta^{3} - \\frac{3}{2}\\alpha^{2}\\beta \\right)s^{2} - \\frac{1}{2}\\beta^{3} \\right) \\, ds\n$$\nUsing the formula $\\int_{-1}^{1} s^{n} \\, ds = \\frac{2}{n+1}$ for even $n$:\n$$\n\\int_{-1}^{1} s^{4} \\, ds = \\frac{2}{5}, \\quad \\int_{-1}^{1} s^{2} \\, ds = \\frac{2}{3}, \\quad \\int_{-1}^{1} 1 \\, ds = 2\n$$\nSubstituting these into the integral for $g(s)$:\n$$\n\\int_{-1}^{1} g(s) \\, ds = \\frac{9}{2}\\alpha^{2}\\beta \\left(\\frac{2}{5}\\right) + \\left( \\frac{3}{2}\\beta^{3} - \\frac{3}{2}\\alpha^{2}\\beta \\right)\\left(\\frac{2}{3}\\right) - \\frac{1}{2}\\beta^{3}(2)\n$$\n$$\n\\int_{-1}^{1} g(s) \\, ds = \\frac{9}{5}\\alpha^{2}\\beta + (\\beta^{3} - \\alpha^{2}\\beta) - \\beta^{3}\n$$\n$$\n\\int_{-1}^{1} g(s) \\, ds = \\left(\\frac{9}{5} - 1\\right)\\alpha^{2}\\beta = \\frac{4}{5}\\alpha^{2}\\beta\n$$\nSo, $Q_{\\mathrm{Gauss}}(g) = \\frac{4}{5}\\alpha^{2}\\beta$.\n\n**2. Calculation of the Gauss-Lobatto quadrature, $Q_{\\mathrm{GLob}}(g)$**\n\nThe $3$-point Gauss-Lobatto quadrature rule on $[-1, 1]$ is given by:\n$$\nQ_{\\mathrm{GLob}}(g) = w_{1}g(s_{1}) + w_{2}g(s_{2}) + w_{3}g(s_{3})\n$$\nwith nodes $s_{1}=-1$, $s_{2}=0$, $s_{3}=1$ and weights $w_{1}=\\frac{1}{3}$, $w_{2}=\\frac{4}{3}$, $w_{3}=\\frac{1}{3}$.\nWe need to evaluate $g(s)$ at these nodes:\n$$\ng(s) = (\\alpha s + \\beta)^{3} \\left( \\frac{1}{2}(3s^{2} - 1) \\right)\n$$\nAt $s = -1$:\n$$\ng(-1) = (\\beta - \\alpha)^{3} \\left( \\frac{1}{2}(3(-1)^{2} - 1) \\right) = (\\beta - \\alpha)^{3} \\left( \\frac{1}{2}(2) \\right) = (\\beta - \\alpha)^{3}\n$$\nAt $s = 0$:\n$$\ng(0) = (\\beta)^{3} \\left( \\frac{1}{2}(3(0)^{2} - 1) \\right) = \\beta^{3} \\left( -\\frac{1}{2} \\right) = -\\frac{1}{2}\\beta^{3}\n$$\nAt $s = 1$:\n$$\ng(1) = (\\alpha + \\beta)^{3} \\left( \\frac{1}{2}(3(1)^{2} - 1) \\right) = (\\alpha + \\beta)^{3} \\left( \\frac{1}{2}(2) \\right) = (\\alpha + \\beta)^{3}\n$$\nNow, we apply the quadrature formula:\n$$\nQ_{\\mathrm{GLob}}(g) = \\frac{1}{3}g(-1) + \\frac{4}{3}g(0) + \\frac{1}{3}g(1)\n$$\n$$\nQ_{\\mathrm{GLob}}(g) = \\frac{1}{3}(\\beta - \\alpha)^{3} + \\frac{4}{3}\\left(-\\frac{1}{2}\\beta^{3}\\right) + \\frac{1}{3}(\\alpha + \\beta)^{3}\n$$\n$$\nQ_{\\mathrm{GLob}}(g) = \\frac{1}{3} \\left( (\\beta - \\alpha)^{3} + (\\beta + \\alpha)^{3} \\right) - \\frac{2}{3}\\beta^{3}\n$$\nWe use the binomial expansion identity $(x-y)^{3} + (x+y)^{3} = 2x^{3} + 6xy^{2}$. With $x=\\beta$ and $y=\\alpha$:\n$$\n(\\beta - \\alpha)^{3} + (\\beta + \\alpha)^{3} = 2\\beta^{3} + 6\\beta\\alpha^{2}\n$$\nSubstituting this back into the expression for $Q_{\\mathrm{GLob}}(g)$:\n$$\nQ_{\\mathrm{GLob}}(g) = \\frac{1}{3}(2\\beta^{3} + 6\\beta\\alpha^{2}) - \\frac{2}{3}\\beta^{3} = \\frac{2}{3}\\beta^{3} + 2\\beta\\alpha^{2} - \\frac{2}{3}\\beta^{3}\n$$\n$$\nQ_{\\mathrm{GLob}}(g) = 2\\alpha^{2}\\beta\n$$\n\n**3. Final Calculation of the Aliasing Error, $E$**\n\nFinally, we compute the difference:\n$$\nE = Q_{\\mathrm{GLob}}(g) - Q_{\\mathrm{Gauss}}(g) = 2\\alpha^{2}\\beta - \\frac{4}{5}\\alpha^{2}\\beta\n$$\n$$\nE = \\left(2 - \\frac{4}{5}\\right)\\alpha^{2}\\beta = \\left(\\frac{10}{5} - \\frac{4}{5}\\right)\\alpha^{2}\\beta = \\frac{6}{5}\\alpha^{2}\\beta\n$$\nThe aliasing error is $\\frac{6}{5}\\alpha^{2}\\beta$.",
            "answer": "$$\n\\boxed{\\frac{6}{5}\\alpha^{2}\\beta}\n$$"
        },
        {
            "introduction": "After discretization, we are left with a large system of algebraic equations to solve. Static condensation is a key domain decomposition strategy that reduces this system to one involving only the degrees of freedom on the interfaces (the skeleton). This final practice  explores an advanced and practical aspect of this approach: how approximations made during the local elemental solves propagate into the global Jacobian-free solver. You will quantify the consistency error, gaining insight into the trade-offs between computational cost and accuracy when designing efficient preconditioners.",
            "id": "3381372",
            "problem": "Consider a hybridizable interior penalty Discontinuous Galerkin (DG) discretization of a linear symmetric second-order elliptic operator on a conforming partition of the domain into elements indexed by $e \\in \\{1,\\dots,E\\}$. Let the local elemental unknowns be partitioned into interior degrees of freedom $u^{(e)} \\in \\mathbb{R}^{n_u^{(e)}}$ and trace (skeleton/interface) degrees of freedom $\\lambda^{(e)} \\in \\mathbb{R}^{n_\\lambda^{(e)}}$, assembled globally into a skeleton vector $\\lambda \\in \\mathbb{R}^{N_\\lambda}$. The assembled linearized elemental contributions admit the block structure\n$$\n\\begin{pmatrix}\nK_{uu}^{(e)} & K_{u\\lambda}^{(e)} \\\\\nK_{\\lambda u}^{(e)} & K_{\\lambda\\lambda}^{(e)}\n\\end{pmatrix}\n\\begin{pmatrix}\nu^{(e)} \\\\\n\\lambda^{(e)}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nf_u^{(e)} \\\\\nf_\\lambda^{(e)}\n\\end{pmatrix},\n$$\nwith $K_{uu}^{(e)} \\in \\mathbb{R}^{n_u^{(e)} \\times n_u^{(e)}}$ assumed invertible for every $e$. Static condensation eliminates $u^{(e)}$ to define the exact condensed elemental Schur complement action on the skeleton:\n$$\nS^{(e)} := K_{\\lambda\\lambda}^{(e)} - K_{\\lambda u}^{(e)}\\left(K_{uu}^{(e)}\\right)^{-1}K_{u\\lambda}^{(e)},\n\\qquad\nb^{(e)} := f_\\lambda^{(e)} - K_{\\lambda u}^{(e)}\\left(K_{uu}^{(e)}\\right)^{-1}f_u^{(e)}.\n$$\nThe global condensed residual on the skeleton is the assembled mapping $R:\\mathbb{R}^{N_\\lambda} \\to \\mathbb{R}^{N_\\lambda}$ given by\n$$\nR(\\lambda) := \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top}\\left(S^{(e)}\\lambda^{(e)} - b^{(e)}\\right),\n$$\nwhere $\\mathcal{A}_e$ is the Boolean assembly operator that injects local face unknowns into the global skeleton, and $\\lambda^{(e)} := \\mathcal{A}_e \\lambda$.\n\nYou are asked to design a Jacobian-free evaluation of the directional derivative of $R$ at a given $\\lambda$ in direction $v \\in \\mathbb{R}^{N_\\lambda}$ using forward finite differences, while modeling approximate local solves that replace $\\left(K_{uu}^{(e)}\\right)^{-1}$ by a fixed linear operator $M^{(e)} \\approx \\left(K_{uu}^{(e)}\\right)^{-1}$ for each element $e$. Define the corresponding approximate condensed operators\n$$\n\\widetilde{S}^{(e)} := K_{\\lambda\\lambda}^{(e)} - K_{\\lambda u}^{(e)}M^{(e)}K_{u\\lambda}^{(e)},\n\\qquad\n\\widetilde{b}^{(e)} := f_\\lambda^{(e)} - K_{\\lambda u}^{(e)}M^{(e)}f_u^{(e)},\n$$\nand the assembled approximate residual\n$$\n\\widetilde{R}(\\lambda) := \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top}\\left(\\widetilde{S}^{(e)}\\lambda^{(e)} - \\widetilde{b}^{(e)}\\right).\n$$\n\nLet the Jacobian-free directional derivative with step size $\\varepsilon > 0$ be evaluated by\n$$\n\\mathcal{J}_{\\varepsilon}^{\\mathrm{JF}}(\\lambda)[v] := \\frac{\\widetilde{R}(\\lambda + \\varepsilon v) - \\widetilde{R}(\\lambda)}{\\varepsilon}.\n$$\nThe exact directional derivative of $R$ at $\\lambda$ in direction $v$ is $DR(\\lambda)[v]$.\n\nAssume linearity of all operators as specified above and exact assembly (i.e., the only approximation is $M^{(e)}$ in place of $\\left(K_{uu}^{(e)}\\right)^{-1}$). Under these assumptions, determine a closed-form expression for the consistency error\n$$\n\\mathcal{E}[v] := \\lim_{\\varepsilon \\to 0}\\left(\\mathcal{J}_{\\varepsilon}^{\\mathrm{JF}}(\\lambda)[v] - DR(\\lambda)[v]\\right)\n$$\nin terms of $\\{K_{\\lambda u}^{(e)},K_{uu}^{(e)},K_{u\\lambda}^{(e)},M^{(e)},\\mathcal{A}_e\\}_{e=1}^{E}$ and $v$. Your final answer must be a single analytic expression. No rounding is required. Express the final answer without units.",
            "solution": "We begin from the linear block system and its static condensation. For each element $e$, the block equations are\n$$\nK_{uu}^{(e)} u^{(e)} + K_{u\\lambda}^{(e)} \\lambda^{(e)} = f_u^{(e)}, \\qquad\nK_{\\lambda u}^{(e)} u^{(e)} + K_{\\lambda\\lambda}^{(e)} \\lambda^{(e)} = f_\\lambda^{(e)}.\n$$\nAssuming $K_{uu}^{(e)}$ is invertible, exact static condensation eliminates $u^{(e)}$ via\n$$\nu^{(e)} = \\left(K_{uu}^{(e)}\\right)^{-1}\\left(f_u^{(e)} - K_{u\\lambda}^{(e)} \\lambda^{(e)}\\right),\n$$\nand substitution into the second block yields the exact condensed elemental relation\n$$\n\\left(K_{\\lambda\\lambda}^{(e)} - K_{\\lambda u}^{(e)}\\left(K_{uu}^{(e)}\\right)^{-1}K_{u\\lambda}^{(e)}\\right)\\lambda^{(e)} =\nf_\\lambda^{(e)} - K_{\\lambda u}^{(e)}\\left(K_{uu}^{(e)}\\right)^{-1} f_u^{(e)}.\n$$\nDefining $S^{(e)}$ and $b^{(e)}$ as in the problem statement, the assembled global residual mapping is\n$$\nR(\\lambda) = \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top}\\left(S^{(e)}\\lambda^{(e)} - b^{(e)}\\right),\n\\qquad \\lambda^{(e)} = \\mathcal{A}_e \\lambda.\n$$\nSince the setting is linear, $R$ is an affine mapping. Its Fréchet derivative $DR(\\lambda)$ is the linear operator obtained by replacing $\\lambda$ by an increment and dropping constants. Specifically,\n$$\nDR(\\lambda)[v] = \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top} S^{(e)} \\left(\\mathcal{A}_e v\\right).\n$$\nNext, we design a Jacobian-free evaluation using forward differences of the approximate residual $\\widetilde{R}$ formed by replacing $\\left(K_{uu}^{(e)}\\right)^{-1}$ with $M^{(e)}$. The approximate condensed elemental operator and right-hand side are\n$$\n\\widetilde{S}^{(e)} := K_{\\lambda\\lambda}^{(e)} - K_{\\lambda u}^{(e)}M^{(e)}K_{u\\lambda}^{(e)}, \\qquad\n\\widetilde{b}^{(e)} := f_\\lambda^{(e)} - K_{\\lambda u}^{(e)}M^{(e)}f_u^{(e)}.\n$$\nThe assembled approximate residual is\n$$\n\\widetilde{R}(\\lambda) = \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top}\\left(\\widetilde{S}^{(e)}\\lambda^{(e)} - \\widetilde{b}^{(e)}\\right),\n\\qquad \\lambda^{(e)} = \\mathcal{A}_e \\lambda.\n$$\nBecause $\\widetilde{R}$ is also affine in $\\lambda$, the forward finite difference with any $\\varepsilon>0$ produces exactly its linear part:\n$$\n\\mathcal{J}_{\\varepsilon}^{\\mathrm{JF}}(\\lambda)[v] = \\frac{\\widetilde{R}(\\lambda + \\varepsilon v) - \\widetilde{R}(\\lambda)}{\\varepsilon}\n= \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top} \\widetilde{S}^{(e)} \\left(\\mathcal{A}_e v\\right).\n$$\nTherefore, the consistency error, defined as the deviation between this Jacobian-free evaluation and the exact directional derivative, is\n$$\n\\mathcal{E}[v] := \\lim_{\\varepsilon \\to 0}\\left(\\mathcal{J}_{\\varepsilon}^{\\mathrm{JF}}(\\lambda)[v] - DR(\\lambda)[v]\\right)\n= \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top}\\left(\\widetilde{S}^{(e)} - S^{(e)}\\right)\\left(\\mathcal{A}_e v\\right),\n$$\nwhere the limit is trivial because both terms are independent of $\\varepsilon$ in this linear setting. Substituting the definitions of $S^{(e)}$ and $\\widetilde{S}^{(e)}$, we obtain\n$$\n\\widetilde{S}^{(e)} - S^{(e)} = \\left(K_{\\lambda\\lambda}^{(e)} - K_{\\lambda u}^{(e)}M^{(e)}K_{u\\lambda}^{(e)}\\right)\n-\\left(K_{\\lambda\\lambda}^{(e)} - K_{\\lambda u}^{(e)}\\left(K_{uu}^{(e)}\\right)^{-1}K_{u\\lambda}^{(e)}\\right)\n= K_{\\lambda u}^{(e)}\\left(\\left(K_{uu}^{(e)}\\right)^{-1} - M^{(e)}\\right)K_{u\\lambda}^{(e)}.\n$$\nThus, the closed-form consistency error is\n$$\n\\mathcal{E}[v] = \\sum_{e=1}^{E} \\mathcal{A}_e^{\\top}\\, K_{\\lambda u}^{(e)}\\left(\\left(K_{uu}^{(e)}\\right)^{-1} - M^{(e)}\\right)K_{u\\lambda}^{(e)} \\left(\\mathcal{A}_e v\\right).\n$$\nThis expression quantifies, for any direction $v$, the deviation introduced in the Jacobian-free directional derivative by approximate local solves, purely in terms of the element-level block operators, the approximate inverse $M^{(e)}$, and the assembly maps.",
            "answer": "$$\\boxed{\\sum_{e=1}^{E} \\mathcal{A}_e^{\\top}\\, K_{\\lambda u}^{(e)}\\left(\\left(K_{uu}^{(e)}\\right)^{-1} - M^{(e)}\\right)K_{u\\lambda}^{(e)} \\left(\\mathcal{A}_e v\\right)}$$"
        }
    ]
}