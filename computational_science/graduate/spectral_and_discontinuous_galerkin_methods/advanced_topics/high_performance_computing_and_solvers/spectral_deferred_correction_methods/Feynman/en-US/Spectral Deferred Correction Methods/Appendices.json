{
    "hands_on_practices": [
        {
            "introduction": "Spectral Deferred Correction (SDC) methods are built upon the foundation of polynomial collocation. To truly understand how SDC works, one must first grasp how the integral form of an ordinary differential equation is discretized. This practice guides you through the construction of the key component in this process: the quadrature matrix $Q$. By deriving this matrix from first principles and seeing how it is used to define the collocation residual , you will build a solid foundation for understanding the entire SDC framework.",
            "id": "3416873",
            "problem": "Consider the initial value problem for an ordinary differential equation (ODE), $y^{\\prime}(t)=f(t,y(t))$, posed on a single time step $[t_{n},t_{n+1}]$ with step size $h=t_{n+1}-t_{n}$. Introduce the normalized time variable $\\tau\\in[0,1]$ by $t=t_{n}+h\\,\\tau$, so that $y(t_{n}+h\\,\\tau)$ satisfies the integral form $y(t_{n}+h\\,\\tau)=y(t_{n})+\\int_{0}^{\\tau}h\\,f(t_{n}+h\\,s,y(t_{n}+h\\,s))\\,ds$. In a collocation construction that underlies spectral deferred correction (SDC) methods, the right-hand side is approximated by polynomial interpolation at Legendre–Gauss–Lobatto (LGL) nodes on $[0,1]$, which for $M=2$ are the three nodes $\\tau_{0}=0$, $\\tau_{1}=\\tfrac{1}{2}$, and $\\tau_{2}=1$. Let $\\ell_{j}(\\tau)$, $j=0,1,2$, denote the Lagrange basis polynomials associated with these nodes.\n\nStarting from these principles and definitions only, and without invoking any preassembled formulas for the collocation operator, do the following:\n\n1. Construct from first principles the linear operator that maps the vector of nodal function values $\\big(f(t_{n}+h\\,\\tau_{j},y(t_{n}+h\\,\\tau_{j}))\\big)_{j=0}^{2}$ to the vector of approximations of the integrals $\\left(\\int_{0}^{\\tau_{m}}f(t_{n}+h\\,s,y(t_{n}+h\\,s))\\,ds\\right)_{m=0}^{2}$ on $[0,1]$. Express this operator as a quadrature matrix $Q\\in\\mathbb{R}^{(M+1)\\times(M+1)}$ for $M=2$, with entries given explicitly as exact rational numbers.\n\n2. Explain, using the integral form and the collocation interpolation, how this quadrature matrix $Q$ is used to evaluate node-wise residuals during spectral deferred correction (SDC) sweeps for the ODE on a single step, and write the residual vector in terms of $Q$, $h$, the vector of nodal function values, and the vector of nodal solution approximations.\n\nAs a single numerical certificate of correctness, report the exact value of the squared Frobenius norm $\\|Q\\|_{F}^{2}$ of your computed matrix $Q$. Provide the exact value as a single rational number with no rounding.",
            "solution": "The problem is valid as it is a well-posed, scientifically grounded question within the domain of numerical analysis for ordinary differential equations. We can proceed with the solution.\n\nThe problem requires the construction of a quadrature matrix $Q$ associated with a collocation method for the ordinary differential equation (ODE) $y^{\\prime}(t)=f(t,y(t))$. The method is defined on a time interval $[t_n, t_{n+1}]$ of length $h=t_{n+1}-t_n$. The integral form of the ODE, transformed to the normalized time variable $\\tau\\in[0,1]$ via $t=t_n+h\\tau$, is\n$$\ny(t_n+h\\tau) = y(t_n) + h \\int_{0}^{\\tau} f(t_n+hs, y(t_n+hs)) ds\n$$\nLet us denote $F(\\tau) = f(t_n+h\\tau, y(t_n+h\\tau))$ for brevity. The integral is approximated by replacing $F(s)$ with its polynomial interpolant, $P(s)$, of degree $M=2$ at the Legendre-Gauss-Lobatto (LGL) nodes on $[0,1]$. For $M=2$, the $M+1=3$ nodes are given as $\\tau_0=0$, $\\tau_1=\\frac{1}{2}$, and $\\tau_2=1$.\n\nThe interpolating polynomial $P(s)$ is expressed in the Lagrange basis as:\n$$\nP(s) = \\sum_{j=0}^{2} F_j \\ell_j(s)\n$$\nwhere $F_j = F(\\tau_j)$ are the function values at the nodes and $\\ell_j(s)$ are the Lagrange basis polynomials satisfying $\\ell_j(\\tau_k) = \\delta_{jk}$. The basis polynomials are constructed as:\n$$\n\\ell_j(s) = \\prod_{k=0, k\\neq j}^{2} \\frac{s-\\tau_k}{\\tau_j-\\tau_k}\n$$\nFor the given nodes $\\tau_0=0$, $\\tau_1=\\frac{1}{2}$, $\\tau_2=1$:\n\\begin{enumerate}\n    \\item For $j=0$: $\\ell_0(s) = \\frac{(s-\\frac{1}{2})(s-1)}{(0-\\frac{1}{2})(0-1)} = \\frac{s^2-\\frac{3}{2}s+\\frac{1}{2}}{\\frac{1}{2}} = 2s^2 - 3s + 1$.\n    \\item For $j=1$: $\\ell_1(s) = \\frac{(s-0)(s-1)}{(\\frac{1}{2}-0)(\\frac{1}{2}-1)} = \\frac{s^2-s}{-\\frac{1}{4}} = -4s^2 + 4s$.\n    \\item For $j=2$: $\\ell_2(s) = \\frac{(s-0)(s-\\frac{1}{2})}{(1-0)(1-\\frac{1}{2})} = \\frac{s^2-\\frac{1}{2}s}{\\frac{1}{2}} = 2s^2 - s$.\n\\end{enumerate}\n\n**1. Construction of the Quadrature Matrix $Q$**\n\nThe problem asks for the linear operator mapping the vector of nodal function values $(F_j)_{j=0}^2$ to the vector of integral approximations $\\left(\\int_{0}^{\\tau_{m}} F(s) ds\\right)_{m=0}^2$. This operator is the quadrature matrix $Q \\in \\mathbb{R}^{3 \\times 3}$. Its entries $Q_{mj}$ are defined by:\n$$\n\\int_0^{\\tau_m} P(s) ds = \\int_0^{\\tau_m} \\sum_{j=0}^2 F_j \\ell_j(s) ds = \\sum_{j=0}^2 F_j \\left(\\int_0^{\\tau_m} \\ell_j(s) ds\\right)\n$$\nThus, the entries of the matrix $Q$ are given by $Q_{mj} = \\int_{0}^{\\tau_m} \\ell_j(s) ds$, where $m$ is the row index and $j$ is the column index ($m, j \\in \\{0, 1, 2\\}$).\n\nFirst, we find the indefinite integrals of the Lagrange polynomials:\n\\begin{itemize}\n    \\item $\\int \\ell_0(s) ds = \\int (2s^2 - 3s + 1) ds = \\frac{2}{3}s^3 - \\frac{3}{2}s^2 + s$\n    \\item $\\int \\ell_1(s) ds = \\int (-4s^2 + 4s) ds = -\\frac{4}{3}s^3 + 2s^2$\n    \\item $\\int \\ell_2(s) ds = \\int (2s^2 - s) ds = \\frac{2}{3}s^3 - \\frac{1}{2}s^2$\n\\end{itemize}\nWe evaluate these from $0$ to $\\tau_m$ for $m=0, 1, 2$.\n\nFor $m=0$, $\\tau_0=0$. The integral over $[0,0]$ is zero.\n$$Q_{00} = 0, \\quad Q_{01} = 0, \\quad Q_{02} = 0$$\n\nFor $m=1$, $\\tau_1=\\frac{1}{2}$.\n\\begin{itemize}\n    \\item $Q_{10} = \\left[\\frac{2}{3}s^3 - \\frac{3}{2}s^2 + s\\right]_0^{1/2} = \\frac{2}{3}\\left(\\frac{1}{8}\\right) - \\frac{3}{2}\\left(\\frac{1}{4}\\right) + \\frac{1}{2} = \\frac{1}{12} - \\frac{3}{8} + \\frac{1}{2} = \\frac{2-9+12}{24} = \\frac{5}{24}$.\n    \\item $Q_{11} = \\left[-\\frac{4}{3}s^3 + 2s^2\\right]_0^{1/2} = -\\frac{4}{3}\\left(\\frac{1}{8}\\right) + 2\\left(\\frac{1}{4}\\right) = -\\frac{1}{6} + \\frac{1}{2} = \\frac{2}{6} = \\frac{1}{3}$.\n    \\item $Q_{12} = \\left[\\frac{2}{3}s^3 - \\frac{1}{2}s^2\\right]_0^{1/2} = \\frac{2}{3}\\left(\\frac{1}{8}\\right) - \\frac{1}{2}\\left(\\frac{1}{4}\\right) = \\frac{1}{12} - \\frac{1}{8} = \\frac{2-3}{24} = -\\frac{1}{24}$.\n\\end{itemize}\n\nFor $m=2$, $\\tau_2=1$.\n\\begin{itemize}\n    \\item $Q_{20} = \\left[\\frac{2}{3}s^3 - \\frac{3}{2}s^2 + s\\right]_0^1 = \\frac{2}{3} - \\frac{3}{2} + 1 = \\frac{4-9+6}{6} = \\frac{1}{6}$.\n    \\item $Q_{21} = \\left[-\\frac{4}{3}s^3 + 2s^2\\right]_0^1 = -\\frac{4}{3} + 2 = \\frac{2}{3}$.\n    \\item $Q_{22} = \\left[\\frac{2}{3}s^3 - \\frac{1}{2}s^2\\right]_0^1 = \\frac{2}{3} - \\frac{1}{2} = \\frac{1}{6}$.\n\\end{itemize}\n\nCombining these results, the quadrature matrix $Q$ is:\n$$\nQ = \\begin{pmatrix} 0 & 0 & 0 \\\\ \\frac{5}{24} & \\frac{1}{3} & -\\frac{1}{24} \\\\ \\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} \\end{pmatrix}\n$$\n\n**2. Residual Evaluation in Spectral Deferred Correction (SDC)**\n\nIn an SDC method, one seeks to find a numerical solution that satisfies the collocation conditions at all nodes. Let $\\mathbf{y} = (y_0, y_1, ..., y_M)^T$ be the vector of solution approximations at the nodes $\\tau_m$, where $y_m \\approx y(t_n+h\\tau_m)$. The collocation condition requires that the numerical solution satisfy the discrete version of the integral equation at each node:\n$$\ny_m = y_n + h \\int_0^{\\tau_m} P(s) ds, \\quad m=0, ..., M\n$$\nHere, $P(s)$ is the polynomial that interpolates the function values $f(t_n+h\\tau_j, y_j)$ at the nodes. Using the matrix $Q$, the vector of integral approximations $\\mathbf{I} = (\\int_0^{\\tau_m} P(s) ds)_{m=0}^M$ is given by $Q \\mathbf{F}(\\mathbf{y})$, where $\\mathbf{F}(\\mathbf{y}) = (f(t_n+h\\tau_0, y_0), ..., f(t_n+h\\tau_M, y_M))^T$ is the vector of nodal function values.\n\nThe system of collocation equations can be written in vector form:\n$$\n\\mathbf{y} = y_n\\mathbf{1} + h Q \\mathbf{F}(\\mathbf{y})\n$$\nwhere $\\mathbf{1}$ is the vector of ones.\n\nThe residual vector $\\mathbf{r}$ for a given approximation $\\mathbf{y}$ measures the extent to which this equation is not satisfied. It is defined as the difference between the right-hand side and the left-hand side of the collocation equation. This residual drives the correction step in an SDC sweep.\n\nThe quadrature matrix $Q$ is thus used to compute the integral term for all nodes simultaneously. The residual vector is given by:\n$$\n\\mathbf{r} = (y_n\\mathbf{1} + h Q \\mathbf{F}(\\mathbf{y})) - \\mathbf{y}\n$$\nIn SDC, one constructs a sequence of approximations $\\mathbf{y}^{(k)}$ aiming to drive this residual $\\mathbf{r}^{(k)}$ to zero.\n\nFinally, as a numerical certificate, we compute the squared Frobenius norm of $Q$:\n$$\n\\|Q\\|_F^2 = \\sum_{m=0}^2 \\sum_{j=0}^2 |Q_{mj}|^2\n$$\nUsing the computed entries of $Q$, we can write the matrix with a common denominator of 24 to aid calculation:\n$$\nQ = \\begin{pmatrix} 0 & 0 & 0 \\\\ \\frac{5}{24} & \\frac{1}{3} & -\\frac{1}{24} \\\\ \\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 \\\\ \\frac{5}{24} & \\frac{8}{24} & -\\frac{1}{24} \\\\ \\frac{4}{24} & \\frac{16}{24} & \\frac{4}{24} \\end{pmatrix}\n$$\n$$\n\\|Q\\|_F^2 = 0^2+0^2+0^2 + \\left(\\frac{5}{24}\\right)^2 + \\left(\\frac{8}{24}\\right)^2 + \\left(-\\frac{1}{24}\\right)^2 + \\left(\\frac{4}{24}\\right)^2 + \\left(\\frac{16}{24}\\right)^2 + \\left(\\frac{4}{24}\\right)^2\n$$\n$$\n\\|Q\\|_F^2 = \\frac{1}{24^2} \\left(5^2 + 8^2 + (-1)^2 + 4^2 + 16^2 + 4^2\\right)\n$$\n$$\n\\|Q\\|_F^2 = \\frac{1}{576} \\left(25 + 64 + 1 + 16 + 256 + 16\\right)\n$$\n$$\n\\|Q\\|_F^2 = \\frac{378}{576}\n$$\nThis fraction can be simplified by dividing the numerator and denominator by their greatest common divisor, 18 ($378 = 18 \\times 21$, $576 = 18 \\times 32$).\n$$\n\\|Q\\|_F^2 = \\frac{21}{32}\n$$",
            "answer": "$$\n\\boxed{\\frac{21}{32}}\n$$"
        },
        {
            "introduction": "An SDC method solves the underlying collocation equations not directly, but through a series of iterative \"sweeps.\" The efficiency of the method hinges on how quickly these sweeps converge to the correct solution. This practice challenges you to analyze the convergence properties of different sweep strategies, such as Jacobi-like and Gauss-Seidel updates . Investigating how node ordering affects the error propagation will provide deep insight into optimizing SDC methods, particularly for stiff problems where convergence is paramount.",
            "id": "3416897",
            "problem": "Consider the scalar linear ordinary differential equation $u'(t) = \\lambda u(t)$ with $\\operatorname{Re}(\\lambda) < 0$, discretized over a single time step of size $\\Delta t$ using $m$ collocation nodes. Let $Q \\in \\mathbb{R}^{m \\times m}$ denote the quadrature integration matrix associated with the chosen collocation points and polynomial basis, such that the collocation system can be represented as a linear algebraic equation in the nodal unknowns. Spectral Deferred Correction (SDC) methods iterate toward the collocation solution by performing correction sweeps. Two canonical sweep types are considered: forward Gauss–Seidel sweeps, which update nodes sequentially in increasing node index, and Jacobi-like simultaneous updates, which update all nodes based on values from the previous iteration.\n\nNode ordering induces a permutation of the collocation nodes. Let $\\Pi$ be a permutation matrix that reorders the nodes, and denote by $Q' = \\Pi Q \\Pi^{\\top}$ the quadrature matrix in the new ordering. The effect of ordering on convergence can be analyzed through the error-propagation operator of the SDC iteration, which depends on the chosen sweep type and the splitting of $Q'$ into diagonal, strictly lower-triangular, and strictly upper-triangular parts in the imposed node order.\n\nSelect all statements that are correct about how node ordering, forward Gauss–Seidel sweeps, and Jacobi-like simultaneous updates affect the contraction properties of the SDC iteration for the above linear test problem. Here $\\alpha = -\\lambda \\Delta t > 0$ denotes the non-dimensional step stiffness.\n\nA. For small $\\alpha$, the forward Gauss–Seidel SDC error propagator satisfies $E_{\\mathrm{GS}} = \\alpha U' + \\mathcal{O}(\\alpha^2)$, where $U'$ is the strictly upper-triangular part of $Q'$ under the chosen ordering. Consequently, node reorderings that minimize $\\|U'\\|$ improve the contraction of forward Gauss–Seidel sweeps in the small-step regime.\n\nB. For small $\\alpha$, the Jacobi-like SDC error propagator satisfies $E_{\\mathrm{J}} = \\alpha(L' + U') + \\mathcal{O}(\\alpha^2)$, where $L'$ and $U'$ are the strictly lower- and strictly upper-triangular parts of $Q'$ under the chosen ordering. Therefore, for a chosen ordering in which $\\|L'\\|$ is large compared to $\\|U'\\|$, forward Gauss–Seidel sweeps converge faster than Jacobi-like simultaneous updates.\n\nC. Permuting nodes via any permutation matrix $\\Pi$ only produces a similarity transformation of the SDC error propagator, so reordering cannot change its spectral radius and cannot improve contraction.\n\nD. In the stiff regime with $\\alpha \\gg 1$, if the chosen ordering makes $Q'$ nearly lower triangular in the sense that $\\|(I - \\alpha T')^{-1}\\|$ remains bounded and $\\|\\alpha U'\\|$ is sufficiently small, where $T'$ is the lower-triangular part of $Q'$ including its diagonal, then forward Gauss–Seidel sweeps are contractive (spectral radius below $1$), while Jacobi-like updates can fail to contract; therefore, reordering that reduces the strictly upper-triangular coupling yields improved contraction.\n\nE. If the collocation nodes are symmetric Gauss–Legendre points, then $Q$ is symmetric, so no node ordering can improve the contraction of forward Gauss–Seidel sweeps; both methods have identical contraction factors for any ordering.",
            "solution": "The user wants me to critically analyze a problem about Spectral Deferred Correction (SDC) methods.\n\n### Step 1: Problem Validation\n\nFirst, I will extract the givens and validate the problem statement.\n\n**Givens:**\n1.  **ODE:** A scalar linear ordinary differential equation $u'(t) = \\lambda u(t)$ with $\\operatorname{Re}(\\lambda) < 0$.\n2.  **Discretization:** A single time step of size $\\Delta t$ using $m$ collocation nodes.\n3.  **Matrix Representation:** $Q \\in \\mathbb{R}^{m \\times m}$ is the quadrature integration matrix. The collocation system is a linear algebraic equation.\n4.  **Method:** Spectral Deferred Correction (SDC) using correction sweeps.\n5.  **Sweep Types:**\n    *   Forward Gauss–Seidel (GS) sweeps.\n    *   Jacobi-like simultaneous updates.\n6.  **Node Ordering:** A permutation $\\Pi$ reorders the nodes. The new quadrature matrix is $Q' = \\Pi Q \\Pi^{\\top}$.\n7.  **Matrix Splitting:** The reordered matrix $Q'$ is split into diagonal ($D'$), strictly lower-triangular ($L'$), and strictly upper-triangular ($U'$) parts.\n8.  **Parameter:** $\\alpha = -\\lambda \\Delta t > 0$. This implies $\\lambda$ is treated as a real negative number.\n\n**Validation:**\n1.  **Scientific Groundedness:** The problem is set within the standard framework of numerical analysis for ordinary differential equations. The test equation $u'=\\lambda u$, the use of collocation, the formulation of SDC as an iterative method on the resulting linear system, and the analysis of its convergence via error-propagation operators for Jacobi and Gauss-Seidel sweeps are all well-established concepts in the field.\n2.  **Well-Posedness:** The problem asks to evaluate several statements regarding the convergence properties of SDC. This is a well-defined question which can be answered through mathematical derivation.\n3.  **Objectivity:** The problem is phrased in precise, technical language without subjective or ambiguous terminology.\n\n**Verdict:** The problem statement is valid. It presents a standard, albeit advanced, topic in numerical analysis. I will proceed with the solution.\n\n### Step 2: Derivation of SDC Error Propagators\n\nThe collocation method applied to $u'(t) = \\lambda u(t)$ over a time step of size $\\Delta t$ with initial condition $u_0$ yields a system of equations for the solution values $\\mathbf{u} = (u_1, \\dots, u_m)^\\top$ at the $m$ collocation nodes. The integral form of the ODE at node $i$ is $u(t_i) = u_0 + \\int_{t_0}^{t_i} \\lambda u(\\tau) d\\tau$. Approximating the integral using quadrature with weights defined by the matrix $Q$ gives:\n$$\n\\mathbf{u} = u_0 \\mathbf{1} + \\lambda \\Delta t Q \\mathbf{u}\n$$\nwhere $\\mathbf{1}$ is a vector of ones. Using the definition $\\alpha = -\\lambda \\Delta t$, we can write the system as:\n$$\n(I + \\alpha Q) \\mathbf{u} = u_0 \\mathbf{1}\n$$\nA node permutation $\\Pi$ transforms the system to:\n$$\n(I + \\alpha Q') \\mathbf{u}' = u'_0 \\mathbf{1}\n$$\nwhere $Q' = \\Pi Q \\Pi^\\top$ and $\\mathbf{u}' = \\Pi \\mathbf{u}$.\n\nSDC sweeps can be interpreted as iterations of an iterative linear solver applied to this system. Let $A = I + \\alpha Q'$. The system is $A\\mathbf{u}' = \\mathbf{b}$ where $\\mathbf{b} = u'_0 \\mathbf{1}$.\n\n**Jacobi-like Updates:**\nThe Jacobi method splits $A$ as $A = D_A + (L_A + U_A)$, where $D_A, L_A, U_A$ are the diagonal, strictly lower, and strictly upper parts of $A$. The iteration is $D_A \\mathbf{u}'^{(k+1)} = -(L_A + U_A)\\mathbf{u}'^{(k)} + \\mathbf{b}$.\nHere, $A = I + \\alpha Q' = I + \\alpha (D' + L' + U')$. So, $D_A = I + \\alpha D'$, $L_A = \\alpha L'$, and $U_A = \\alpha U'$.\nThe error $\\mathbf{e}^{(k)} = \\mathbf{u}'^{(k)} - \\mathbf{u}'^*$ propagates as $\\mathbf{e}^{(k+1)} = E_J \\mathbf{e}^{(k)}$, where the error propagation operator is:\n$$\nE_J = -D_A^{-1}(L_A + U_A) = -(I + \\alpha D')^{-1} \\alpha(L' + U')\n$$\nFor small $\\alpha$, we can use the Taylor expansion $(I+X)^{-1} \\approx I - X$.\n$$\nE_J = -(I - \\alpha D' + \\mathcal{O}(\\alpha^2)) \\alpha(L' + U') = -\\alpha(L' + U') + \\mathcal{O}(\\alpha^2)\n$$\n\n**Forward Gauss-Seidel Sweeps:**\nThe Gauss-Seidel method splits $A$ as $A = (D_A + L_A) + U_A$. The iteration is $(D_A + L_A)\\mathbf{u}'^{(k+1)} = -U_A \\mathbf{u}'^{(k)} + \\mathbf{b}$.\nThe error propagation operator is:\n$$\nE_{GS} = -(D_A + L_A)^{-1} U_A = -(I + \\alpha D' + \\alpha L')^{-1} \\alpha U' = -(I + \\alpha T')^{-1} \\alpha U'\n$$\nwhere $T' = D' + L'$ is the lower-triangular part of $Q'$ (including the diagonal).\nFor small $\\alpha$:\n$$\nE_{GS} = -(I - \\alpha T' + \\mathcal{O}(\\alpha^2)) \\alpha U' = -\\alpha U' + \\mathcal{O}(\\alpha^2)\n$$\n\n**A Note on Sign Convention:**\nMy derivations, which directly follow from the problem statement $u'=\\lambda u$ and $\\alpha=-\\lambda\\Delta t$, yield error propagators that are first-order in $\\alpha$ with a leading negative sign. However, the formulas presented in options A, B, and D consistently lack this negative sign. This suggests that the options may have been written with a different sign convention in mind, such as for the equation $u' = -\\lambda u$ with $\\operatorname{Re}(\\lambda)>0$. In that case, the system would be $(I - \\alpha Q)\\mathbf{u} = u_0\\mathbf{1}$, and the derived propagators would match the formulas in the options.\n\nRecognizing this common ambiguity in literature and problem-setting, and observing that the errors in C and E are of a more fundamental, conceptual nature, I will evaluate options A, B, and D based on the physical and numerical reasoning they present, assuming the sign discrepancy is a notational artifact.\n\n### Step 3: Option-by-Option Analysis\n\n**A. For small $\\alpha$, the forward Gauss–Seidel SDC error propagator satisfies $E_{\\mathrm{GS}} = \\alpha U' + \\mathcal{O}(\\alpha^2)$, where $U'$ is the strictly upper-triangular part of $Q'$ under the chosen ordering. Consequently, node reorderings that minimize $\\|U'\\|$ improve the contraction of forward Gauss–Seidel sweeps in the small-step regime.**\n\nUnder the likely intended sign convention, the formula $E_{\\mathrm{GS}} \\approx \\alpha U'$ is correct. The spectral radius of the error propagator, which governs the convergence rate, would be $\\rho(E_{\\mathrm{GS}}) \\approx \\rho(\\alpha U') = \\alpha \\rho(U')$. To improve contraction (i.e., to make $\\rho(E_{\\mathrm{GS}})$ as small as possible), one should minimize $\\rho(U')$. Minimizing a norm $\\|U'\\|$ is a practical way to attempt to reduce the spectral radius $\\rho(U')$. Therefore, the conclusion logically follows from the premise.\n\nVerdict: **Correct** (with the understanding of the sign convention inconsistency).\n\n**B. For small $\\alpha$, the Jacobi-like SDC error propagator satisfies $E_{\\mathrm{J}} = \\alpha(L' + U') + \\mathcal{O}(\\alpha^2)$, where $L'$ and $U'$ are the strictly lower- and strictly upper-triangular parts of $Q'$ under the chosen ordering. Therefore, for a chosen ordering in which $\\|L'\\|$ is large compared to $\\|U'\\|$, forward Gauss–Seidel sweeps converge faster than Jacobi-like simultaneous updates.**\n\nUnder the likely intended sign convention, the formula $E_{\\mathrm{J}} \\approx \\alpha(L' + U')$ is correct. To compare the convergence rates, we compare the magnitudes of their respective error propagators. For small $\\alpha$:\n$\\|E_{\\mathrm{GS}}\\| \\approx \\alpha \\|U'\\|$\n$\\|E_{\\mathrm{J}}\\| \\approx \\alpha \\|L' + U'\\|$\nIf an ordering is chosen such that $\\|L'\\|$ is large compared to $\\|U'\\|$, it is highly probable that $\\|L' + U'\\|$ will be significantly larger than $\\|U'\\|$. For example, using the triangle inequality, $\\|L' + U'\\| \\le \\|L'\\| + \\|U'\\|$. If $\\|L'\\| \\gg \\|U'\\|$, then $\\|L' + U'\\|$ will be dominated by $\\|L'\\|$ and thus be much larger than $\\|U'\\|$. A smaller error propagator norm indicates faster convergence. Thus, forward Gauss-Seidel would converge faster. The reasoning is sound.\n\nVerdict: **Correct** (with the understanding of the sign convention inconsistency).\n\n**C. Permuting nodes via any permutation matrix $\\Pi$ only produces a similarity transformation of the SDC error propagator, so reordering cannot change its spectral radius and cannot improve contraction.**\n\nThis statement is fundamentally incorrect. The permutation $\\Pi$ acts on the matrix $Q$ to produce $Q' = \\Pi Q \\Pi^\\top$. The Gauss-Seidel error propagator $E_{GS}$ is constructed from a splitting of $Q$ into $D, L, U$, while the permuted propagator $E'_{GS}$ is constructed from a splitting of $Q'$ into $D', L', U'$. In general, $\\Pi L \\Pi^\\top$ is not the lower part of $Q'$, so $E'_{GS}$ is not a similarity transform of $E_{GS}$ (i.e., $E'_{GS} \\neq \\Pi E_{GS} \\Pi^\\top$). The very purpose of investigating node ordering in SDC is that it *can* and *does* change the spectral radius of the error propagator, thereby affecting the convergence rate.\n\nVerdict: **Incorrect**.\n\n**D. In the stiff regime with $\\alpha \\gg 1$, if the chosen ordering makes $Q'$ nearly lower triangular in the sense that $\\|(I - \\alpha T')^{-1}\\|$ remains bounded and $\\|\\alpha U'\\|$ is sufficiently small, where $T'$ is the lower-triangular part of $Q'$ including its diagonal, then forward Gauss–Seidel sweeps are contractive (spectral radius below $1$), while Jacobi-like updates can fail to contract; therefore, reordering that reduces the strictly upper-triangular coupling yields improved contraction.**\n\nThis statement correctly describes the behavior of SDC in the stiff limit ($\\alpha \\gg 1$).\n1.  **GS Contraction**: Assuming the intended sign convention, the GS error propagator is $E_{GS} = (I - \\alpha T')^{-1} (\\alpha U')$. Its norm is bounded as $\\|E_{GS}\\| \\le \\|(I - \\alpha T')^{-1}\\| \\cdot \\|\\alpha U'\\|$. The condition given in the statement directly implies that the norm of the error propagator can be made less than $1$ if $\\|\\alpha U'\\|$ is sufficiently small, ensuring contraction. Making $Q'$ \"nearly lower triangular\" means making the entries of $U'$ small.\n2.  **Jacobi Failure**: The Jacobi propagator $E_J$ behaves poorly for large $\\alpha$. Its convergence factor depends on $(D')^{-1}(L'+U')$, which is not generally small. It is a known result that Jacobi-based SDC sweeps have poor stability for stiff problems.\n3.  **Conclusion**: The conclusion that reordering to reduce the upper-triangular coupling (i.e., make $U'$ smaller) improves contraction for GS sweeps is the central idea behind optimizing SDC for stiff problems. The entire statement accurately reflects the principles of SDC performance in the stiff regime.\n\nVerdict: **Correct** (with the understanding of the sign convention inconsistency).\n\n**E. If the collocation nodes are symmetric Gauss–Legendre points, then $Q$ is symmetric, so no node ordering can improve the contraction of forward Gauss–Seidel sweeps; both methods have identical contraction factors for any ordering.**\n\nThis statement contains multiple errors.\n1.  The indefinite integration matrix $Q$ (where $Q_{ij} = \\int_0^{c_i} \\ell_j(\\tau)d\\tau$) is generally **not** symmetric, even if the nodes $\\{c_i\\}$ are symmetric. A simple calculation for $m=2$ Gauss-Legendre nodes demonstrates that $Q_{12} \\neq Q_{21}$.\n2.  Even if $Q$ were symmetric, reordering it would still change the splitting $Q' = D' + L' + U'$ in a non-trivial way, thus changing the GS error propagator $E'_{GS}$ and its spectral radius. The conclusion that ordering cannot improve contraction is false, as explained in the analysis of option C.\n3.  The claim that GS and Jacobi methods would have identical contraction factors is also false in general. There is no reason for $\\rho(E_{GS})$ and $\\rho(E_J)$ to be equal.\n\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "The theoretical elegance of numerical methods must ultimately face the practical limitations of computer arithmetic. This exercise explores this interface by analyzing an SDC algorithm implemented with mixed-precision arithmetic—a modern technique for accelerating scientific computations. By applying the concept of SDC as a contraction mapping, you will derive a rigorous bound on the accumulation of roundoff error . This practice develops the essential skill of performing error analysis, ensuring that a numerical method is not just theoretically sound but also robust in practice.",
            "id": "3416879",
            "problem": "Consider the initial value problem on a single time step $[t_n,t_{n+1}]$ of length $h>0$ for the ordinary differential equation $y'(t)=f(y(t))$, where $f:\\mathbb{R}\\to\\mathbb{R}$ is Lipschitz continuous with Lipschitz constant $L>0$. Let $M\\in\\mathbb{N}$ denote the number of collocation nodes used to define the collocation problem on $[t_n,t_{n+1}]$, and let the corresponding spectral deferred correction (SDC) iteration define a sequence of stage vectors $\\{Y^{(m)}\\}_{m\\ge 0}\\in\\mathbb{R}^M$ intended to converge to the collocation solution $Y^{\\star}\\in\\mathbb{R}^M$.\n\nAssume the following standard facts, which hold for sufficiently small $hL$ with common SDC preconditioners: there exists a consistent vector norm $\\|\\cdot\\|$ and a contraction constant $\\sigma\\in(0,1)$ such that one exact SDC sweep, viewed as a mapping $\\mathcal{S}:\\mathbb{R}^M\\to\\mathbb{R}^M$, satisfies the contraction property $\\|\\mathcal{S}(U)-\\mathcal{S}(V)\\|\\le \\sigma \\|U-V\\|$ for all $U,V\\in\\mathbb{R}^M$, and $\\mathcal{S}(Y^{\\star})=Y^{\\star}$. Furthermore, assume an a priori bound $\\|Y^{(m)}\\|\\le B$ for all $m\\ge 0$ for some finite $B>0$.\n\nDesign a mixed-precision SDC sweep that computes:\n- the explicit construction of the collocation residual (that is, the vector formed from function evaluations and quadrature to build the right-hand side for the correction) in a low-precision arithmetic with unit roundoff $u_{\\ell}\\in(0,1)$, and\n- the solution of the linear correction equations and all vector updates in a higher-precision arithmetic with unit roundoff $u_{h}\\in(0,1)$,\n\nunder the standard floating-point model: each elementary arithmetic operation $\\circ\\in\\{+,-,\\times,\\div\\}$ satisfies $\\mathrm{fl}(a\\circ b}=(a\\circ b)(1+\\delta)$ with $|\\delta|\\le u$ in the corresponding unit roundoff $u$ for the arithmetic in which the operation is performed.\n\nSuppose that, per sweep, the low-precision residual construction induces an additive perturbation vector $r_{\\ell}^{(m)}$ with a norm bound $\\|r_{\\ell}^{(m)}\\|\\le \\alpha\\,u_{\\ell}$, and the high-precision correction solve and vector updates induce an additive perturbation vector $r_{h}^{(m)}$ with a norm bound $\\|r_{h}^{(m)}\\|\\le \\beta\\,u_{h}$, where the constants $\\alpha,\\beta\\ge 0$ depend only on $h$, $L$, the quadrature and preconditioner matrices, and the bound $B$, but not on $m$ or the precision parameters $u_{\\ell},u_h$. Assume that $\\{r_{\\ell}^{(m)}\\}$ and $\\{r_{h}^{(m)}\\}$ are adversarial but bounded in this sense.\n\nLet the mixed-precision SDC sweep be applied $k\\in\\mathbb{N}$ times, starting from the exact initial guess $Y^{(0)}=Y^{\\star}$ so that all error arises from finite precision. Using only the contraction property of the exact SDC sweep and the stated floating-point model and bounds on $\\|r_{\\ell}^{(m)}\\|$ and $\\|r_{h}^{(m)}\\|$, derive a rigorous upper bound on the norm of the total roundoff error after $k$ sweeps, $\\|Y^{(k)}-Y^{\\star}\\|$, as a closed-form analytical expression in terms of $\\sigma$, $k$, $\\alpha$, $\\beta$, $u_{\\ell}$, and $u_{h}$. Your final answer must be a single analytical expression. Do not introduce any unstated assumptions. If you make use of geometric series, justify convergence from the given data. Express your answer exactly; no numerical rounding is required.",
            "solution": "The problem requires the derivation of a rigorous upper bound on the total roundoff error after $k$ sweeps of a mixed-precision spectral deferred correction (SDC) method. The analysis will be based on the provided contraction property of the exact SDC sweep and the given model for floating-point perturbations.\n\nLet $\\tilde{Y}^{(m)} \\in \\mathbb{R}^M$ denote the computed stage vector after $m$ sweeps of the mixed-precision SDC algorithm. The exact collocation solution is denoted by $Y^{\\star} \\in \\mathbb{R}^M$. The error vector after $m$ sweeps is defined as $e^{(m)} = \\tilde{Y}^{(m)} - Y^{\\star}$. The problem states that the iteration starts from the exact initial guess, so we have $\\tilde{Y}^{(0)} = Y^{\\star}$, which implies that the initial error is zero: $e^{(0)} = 0$. Our goal is to find an upper bound for $\\|e^{(k)}\\|$ for a given number of sweeps $k \\in \\mathbb{N}$.\n\nA single exact SDC sweep is represented by a mapping $\\mathcal{S}: \\mathbb{R}^M \\to \\mathbb{R}^M$. The problem describes a mixed-precision implementation where each sweep is affected by two sources of roundoff error: an additive perturbation $r_{\\ell}^{(m)}$ from the low-precision residual construction and an additive perturbation $r_{h}^{(m)}$ from the high-precision correction solve and vector updates. We can model the computed result of applying one sweep to the current approximation $\\tilde{Y}^{(m)}$ as the result of the exact sweep operator plus a total perturbation term for that sweep. Let the total additive perturbation for the sweep that computes $\\tilde{Y}^{(m+1)}$ from $\\tilde{Y}^{(m)}$ be $r^{(m)} = r_{\\ell}^{(m)} + r_{h}^{(m)}$. The floating-point iteration is thus modeled by the recurrence relation:\n$$\n\\tilde{Y}^{(m+1)} = \\mathcal{S}(\\tilde{Y}^{(m)}) + r^{(m)} \\quad \\text{for } m = 0, 1, \\dots, k-1\n$$\n\nWe can now derive a recurrence relation for the norm of the error vector, $\\|e^{(m)}\\|$. By definition, $e^{(m+1)} = \\tilde{Y}^{(m+1)} - Y^{\\star}$. Substituting the model for the mixed-precision sweep gives:\n$$\ne^{(m+1)} = \\left( \\mathcal{S}(\\tilde{Y}^{(m)}) + r^{(m)} \\right) - Y^{\\star}\n$$\nThe problem states that $Y^{\\star}$ is a fixed point of the exact sweep operator $\\mathcal{S}$, which means $\\mathcal{S}(Y^{\\star}) = Y^{\\star}$. We can substitute this into the equation:\n$$\ne^{(m+1)} = \\mathcal{S}(\\tilde{Y}^{(m)}) - \\mathcal{S}(Y^{\\star}) + r^{(m)}\n$$\nNow, we take the vector norm of both sides and apply the triangle inequality:\n$$\n\\|e^{(m+1)}\\| = \\| \\mathcal{S}(\\tilde{Y}^{(m)}) - \\mathcal{S}(Y^{\\star}) + r^{(m)} \\| \\le \\| \\mathcal{S}(\\tilde{Y}^{(m)}) - \\mathcal{S}(Y^{\\star}) \\| + \\|r^{(m)}\\|\n$$\nWe are given that $\\mathcal{S}$ is a contraction with constant $\\sigma \\in (0,1)$, meaning $\\|\\mathcal{S}(U) - \\mathcal{S}(V)\\| \\le \\sigma \\|U - V\\|$ for any vectors $U,V \\in \\mathbb{R}^M$. Applying this property with $U = \\tilde{Y}^{(m)}$ and $V = Y^{\\star}$:\n$$\n\\| \\mathcal{S}(\\tilde{Y}^{(m)}) - \\mathcal{S}(Y^{\\star}) \\| \\le \\sigma \\| \\tilde{Y}^{(m)} - Y^{\\star} \\| = \\sigma \\|e^{(m)}\\|\n$$\nSubstituting this into the inequality for $\\|e^{(m+1)}\\|$ yields the following recursive inequality for the error norm:\n$$\n\\|e^{(m+1)}\\| \\le \\sigma \\|e^{(m)}\\| + \\|r^{(m)}\\|\n$$\nNext, we need to bound the perturbation term $\\|r^{(m)}\\|$. We are given that for each sweep $m$, the norm of the low-precision perturbation is bounded by $\\|r_{\\ell}^{(m)}\\| \\le \\alpha u_{\\ell}$ and the norm of the high-precision perturbation is bounded by $\\|r_{h}^{(m)}\\| \\le \\beta u_{h}$. Using the triangle inequality for $\\|r^{(m)}\\| = \\|r_{\\ell}^{(m)} + r_{h}^{(m)}\\|$, we get:\n$$\n\\|r^{(m)}\\| \\le \\|r_{\\ell}^{(m)}\\| + \\|r_{h}^{(m)}\\| \\le \\alpha u_{\\ell} + \\beta u_{h}\n$$\nSince $\\alpha$, $\\beta$, $u_{\\ell}$, and $u_{h}$ are constants, we can define a constant upper bound for the per-sweep perturbation norm, $\\Delta = \\alpha u_{\\ell} + \\beta u_{h}$. The problem statement that the perturbations are adversarial implies we must use this worst-case bound. The recurrence for the error norm becomes:\n$$\n\\|e^{(m+1)}\\| \\le \\sigma \\|e^{(m)}\\| + \\Delta\n$$\nWe can solve this linear recurrence for $\\|e^{(k)}\\|$ by unrolling it, starting from the initial condition $\\|e^{(0)}\\| = 0$:\nFor $m=0$:\n$$\n\\|e^{(1)}\\| \\le \\sigma \\|e^{(0)}\\| + \\Delta = \\sigma(0) + \\Delta = \\Delta\n$$\nFor $m=1$:\n$$\n\\|e^{(2)}\\| \\le \\sigma \\|e^{(1)}\\| + \\Delta \\le \\sigma(\\Delta) + \\Delta = \\Delta(1 + \\sigma)\n$$\nFor $m=2$:\n$$\n\\|e^{(3)}\\| \\le \\sigma \\|e^{(2)}\\| + \\Delta \\le \\sigma(\\Delta(1+\\sigma)) + \\Delta = \\Delta(1 + \\sigma + \\sigma^2)\n$$\nBy induction, after $k$ sweeps (i.e., for the error $e^{(k)}$ which results from iterating from $m=0$ to $m=k-1$), the bound is:\n$$\n\\|e^{(k)}\\| \\le \\Delta \\sum_{j=0}^{k-1} \\sigma^j\n$$\nThe sum is a finite geometric series. The formula for the sum of a finite geometric series is $\\sum_{j=0}^{n-1} r^j = \\frac{1-r^n}{1-r}$, which is valid for any $r \\ne 1$. In our case, the ratio is $\\sigma$, and we are given that $\\sigma \\in (0,1)$, which ensures $\\sigma \\ne 1$. Therefore, we can write:\n$$\n\\sum_{j=0}^{k-1} \\sigma^j = \\frac{1 - \\sigma^k}{1 - \\sigma}\n$$\nSubstituting this back into the bound for $\\|e^{(k)}\\|$ and replacing $\\Delta$ with its definition provides the final upper bound on the total roundoff error after $k$ sweeps:\n$$\n\\|Y^{(k)} - Y^{\\star}\\| = \\|e^{(k)}\\| \\le (\\alpha u_{\\ell} + \\beta u_{h}) \\frac{1 - \\sigma^k}{1 - \\sigma}\n$$\nThis expression is the rigorous upper bound derived solely from the properties and bounds provided in the problem statement.",
            "answer": "$$\n\\boxed{(\\alpha u_{\\ell} + \\beta u_{h}) \\frac{1 - \\sigma^k}{1 - \\sigma}}\n$$"
        }
    ]
}