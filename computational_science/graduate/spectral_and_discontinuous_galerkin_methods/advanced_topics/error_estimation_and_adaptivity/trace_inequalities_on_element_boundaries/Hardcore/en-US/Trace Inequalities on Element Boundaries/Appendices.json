{
    "hands_on_practices": [
        {
            "introduction": "The abstract statement of a trace inequality often involves an unspecified constant. This exercise guides you through finding the *sharpest possible* constant for a foundational one-dimensional case using the calculus of variations. This process is not just a calculation; it reveals the specific function that maximizes the boundary-to-interior norm ratio, providing deep insight into the structure of the Sobolev space $H^{1}(0,1)$ and the nature of trace operators .",
            "id": "3424723",
            "problem": "In the analysis of numerical fluxes and penalty parameters for Spectral and Discontinuous Galerkin (DG) methods, sharp trace inequalities on element boundaries are essential. Consider the one-dimensional reference element $\\Omega = (0,1)$ and the Sobolev space $H^{1}(0,1)$ equipped with the Hilbert norm\n$$\n\\|u\\|_{H^{1}(0,1)}^{2} = \\int_{0}^{1} \\left( |u(x)|^{2} + |u'(x)|^{2} \\right) \\, dx.\n$$\nThe boundary $\\partial \\Omega$ consists of the two points $\\{0,1\\}$. For the singleton face $\\{1\\}$, define the boundary $L^{2}$ norm of the trace by\n$$\n\\|u\\|_{L^{2}(\\{x=1\\})} = |u(1)|,\n$$\nwhich corresponds to the counting measure on the point set and is standard in one-dimensional trace inequalities.\n\nDetermine the exact smallest constant $C > 0$ such that the trace inequality\n$$\n\\|u\\|_{L^{2}(\\{x=1\\})} \\leq C \\, \\|u\\|_{H^{1}(0,1)}\n$$\nholds for all $u \\in H^{1}(0,1)$. Your answer must be a single closed-form analytical expression. No rounding is required and no physical units are involved. Additionally, identify the extremal function that achieves equality and use it to derive the constant without relying on any pre-tabulated formulas.",
            "solution": "The user-provided problem is validated as well-posed, scientifically grounded, and self-contained. It is a standard problem in functional analysis concerning the optimal constant in a Sobolev trace inequality. We may therefore proceed with the solution.\n\nThe problem is to find the smallest constant $C > 0$ such that for all functions $u \\in H^{1}(0,1)$, the following trace inequality holds:\n$$\n|u(1)| \\leq C \\|u\\|_{H^{1}(0,1)}\n$$\nwhere the norm on $H^{1}(0,1)$ is given by\n$$\n\\|u\\|_{H^{1}(0,1)}^{2} = \\int_{0}^{1} \\left( |u(x)|^{2} + |u'(x)|^{2} \\right) \\, dx.\n$$\nBy squaring both sides of the inequality and rearranging, we can define the square of the optimal constant $C$ as the supremum of a Rayleigh quotient:\n$$\nC^2 = \\sup_{u \\in H^{1}(0,1) \\setminus \\{0\\}} \\frac{|u(1)|^2}{\\|u\\|_{H^{1}(0,1)}^2} = \\sup_{u \\in H^{1}(0,1) \\setminus \\{0\\}} \\frac{|u(1)|^2}{\\int_{0}^{1} \\left( |u(x)|^2 + |u'(x)|^2 \\right) \\, dx}\n$$\nWithout loss of generality, we can consider real-valued functions, so $|u(x)|$ becomes $u(x)$. The problem of finding this supremum is a classic problem in the calculus of variations. The function $u(x)$ that maximizes this quotient, known as the extremal function, must satisfy the associated Euler-Lagrange equation.\n\nLet $J(u)$ be the functional to be maximized:\n$$\nJ(u) = \\frac{u(1)^2}{\\int_{0}^{1} \\left( u(x)^2 + u'(x)^2 \\right) \\, dx}\n$$\nThe first variation of $J(u)$ must be zero for the extremal function $u$. For any admissible variation $v \\in H^1(0,1)$, we must have $\\delta J(u;v) = 0$.\nThe Gateaux derivative is:\n$$\n\\delta J(u;v) = \\left. \\frac{d}{d\\epsilon} J(u+\\epsilon v) \\right|_{\\epsilon=0} = \\frac{2u(1)v(1) \\left( \\int_{0}^{1} (u^2 + u'^2)dx \\right) - u(1)^2 \\left( 2\\int_{0}^{1} (uv+u'v')dx \\right)}{\\left(\\int_{0}^{1} (u^2 + u'^2)dx\\right)^2} = 0\n$$\nAssuming $u(1) \\neq 0$ for a non-trivial solution, this simplifies to:\n$$\nu(1)v(1) \\int_{0}^{1} (u^2 + u'^2)dx - u(1)^2 \\int_{0}^{1} (uv+u'v')dx = 0\n$$\n$$\nv(1) \\frac{\\int_{0}^{1} (u^2 + u'^2)dx}{u(1)} - \\int_{0}^{1} (uv+u'v')dx = 0\n$$\nFor the extremal function $u$, the value of the quotient is $C^2$. Thus, $C^2 = \\frac{u(1)^2}{\\int_{0}^{1} (u^2+u'^2)dx}$. This implies $\\frac{\\int_{0}^{1} (u^2+u'^2)dx}{u(1)} = \\frac{u(1)}{C^2}$. Substituting this into the variational equation gives the weak form of the problem:\n$$\n\\int_{0}^{1} \\left( u(x)v(x) + u'(x)v'(x) \\right) \\, dx = \\frac{u(1)}{C^2} v(1) \\quad \\forall v \\in H^1(0,1)\n$$\nTo obtain the strong form (a differential equation with boundary conditions), we apply integration by parts to the term $\\int_{0}^{1} u'(x)v'(x)dx$:\n$$\n\\int_{0}^{1} u'(x)v'(x)dx = [u'(x)v(x)]_{0}^{1} - \\int_{0}^{1} u''(x)v(x)dx = u'(1)v(1) - u'(0)v(0) - \\int_{0}^{1} u''(x)v(x)dx\n$$\nSubstituting this back into the weak form gives:\n$$\n\\int_{0}^{1} u(x)v(x)dx + u'(1)v(1) - u'(0)v(0) - \\int_{0}^{1} u''(x)v(x)dx = \\frac{u(1)}{C^2} v(1)\n$$\nCollecting terms:\n$$\n\\int_{0}^{1} \\left( u(x) - u''(x) \\right) v(x) dx + \\left( u'(1) - \\frac{u(1)}{C^2} \\right) v(1) - u'(0)v(0) = 0\n$$\nThis must hold for all $v \\in H^1(0,1)$.\n1.  By choosing test functions $v$ that vanish at the boundaries ($v \\in H_0^1(0,1)$, i.e., $v(0)=v(1)=0$), the boundary terms are zero. The fundamental lemma of calculus of variations implies that the integrand must be zero, which gives the Euler-Lagrange differential equation:\n    $$\n    u''(x) - u(x) = 0 \\quad \\text{for } x \\in (0,1)\n    $$\n2.  With the differential equation holding, the integral term vanishes for any $v$. The equation reduces to the natural boundary conditions:\n    $$\n    \\left( u'(1) - \\frac{u(1)}{C^2} \\right) v(1) - u'(0)v(0) = 0\n    $$\n    By choosing $v$ such that $v(0)=1$ and $v(1)=0$, we obtain the condition at $x=0$:\n    $$\n    u'(0) = 0\n    $$\n    By choosing $v$ such that $v(0)=0$ and $v(1)=1$, we obtain the condition at $x=1$:\n    $$\n    u'(1) = \\frac{u(1)}{C^2}\n    $$\nThe problem is now reduced to solving this boundary value problem. The general solution to $u'' - u = 0$ is $u(x) = A e^x + B e^{-x}$. The derivative is $u'(x) = A e^x - B e^{-x}$.\nApplying the condition at $x=0$:\n$u'(0) = A - B = 0$, which implies $A=B$.\nThe extremal function must therefore be of the form $u(x) = A(e^x + e^{-x}) = K \\cosh(x)$ for some constant $K=2A$. For a non-trivial solution, $K \\neq 0$.\n\nNow, we use the boundary condition at $x=1$ to determine the constant $C^2$.\nFor $u(x) = K \\cosh(x)$, we have $u(1) = K \\cosh(1)$ and $u'(1) = K \\sinh(1)$.\nSubstituting these into $u'(1) = \\frac{u(1)}{C^2}$:\n$$\nK \\sinh(1) = \\frac{K \\cosh(1)}{C^2}\n$$\nSince $K \\neq 0$, we can divide by it:\n$$\n\\sinh(1) = \\frac{\\cosh(1)}{C^2}\n$$\nSolving for $C^2$, we find:\n$$\nC^2 = \\frac{\\cosh(1)}{\\sinh(1)} = \\coth(1)\n$$\nThe exact smallest constant $C$ is the positive square root of this value:\n$$\nC = \\sqrt{\\coth(1)}\n$$\nThe extremal function that achieves this bound is any non-zero multiple of $u(x) = \\cosh(x)$. We can express $\\coth(1)$ using exponential functions as $\\coth(1) = \\frac{e^1 + e^{-1}}{e^1 - e^{-1}} = \\frac{e^2+1}{e^2-1}$.",
            "answer": "$$\n\\boxed{\\sqrt{\\coth(1)}}\n$$"
        },
        {
            "introduction": "In discontinuous Galerkin methods, stability depends on constants in so-called \"inverse\" trace inequalities, which are specific to the finite-dimensional polynomial space on an element. This exercise explores this crucial dependency by having you compute the exact ratio of boundary-to-interior norms for a representative polynomial basis function. The resulting scaling with polynomial degree $p$ and element size $h$ is a cornerstone for understanding and analyzing the stability of high-order methods .",
            "id": "3424656",
            "problem": "Let $K=(0,h)^{2}\\subset\\mathbb{R}^{2}$ be a square element of side length $h>0$ and consider the function $v:K\\to\\mathbb{R}$ defined by $v(x,y)=L_{p}\\!\\left(\\frac{2x}{h}-1\\right)$, where $L_{p}$ denotes the degree-$p$ Legendre polynomial on $[-1,1]$ with the standard normalization $L_{p}(1)=1$. In the context of spectral methods and the Discontinuous Galerkin (DG) method, trace inequalities compare boundary norms to interior norms with scaling in the polynomial degree $p$ and the element size $h$. Starting from the definitions of the $L^{2}$-norm on $K$ and on $\\partial K$, the orthogonality of Legendre polynomials on $[-1,1]$, and the values $L_{p}(\\pm 1)$, compute the explicit expression in terms of $p$ and $h$ for the ratio\n$$\n\\frac{\\|v\\|_{L^{2}(\\partial K)}^{2}}{\\|v\\|_{L^{2}(K)}^{2}}.\n$$\nThen, briefly compare the resulting $p,h$-scaling with the canonical theoretical inverse-trace bound expected for polynomial spaces on shape-regular elements in two dimensions. Your final answer must be a single closed-form expression in $p$ and $h$; no inequalities are permitted in the final answer.",
            "solution": "The problem statement is determined to be valid as it is scientifically grounded, well-posed, and objective. It is a standard problem in the analysis of spectral and discontinuous Galerkin methods.\n\nThe objective is to compute the ratio $\\frac{\\|v\\|_{L^{2}(\\partial K)}^{2}}{\\|v\\|_{L^{2}(K)}^{2}}$ for the function $v(x,y)=L_{p}\\!\\left(\\frac{2x}{h}-1\\right)$ on the square element $K=(0,h)^{2}$.\n\nFirst, we compute the squared $L^2$-norm of $v$ in the interior of the element $K$. The definition of this norm is:\n$$\n\\|v\\|_{L^{2}(K)}^{2} = \\int_{K} |v(x,y)|^2 \\,dA = \\int_{0}^{h} \\int_{0}^{h} \\left| L_{p}\\!\\left(\\frac{2x}{h}-1\\right) \\right|^2 \\,dx\\,dy\n$$\nSince the integrand is independent of the variable $y$, the integration with respect to $y$ yields a factor of $h$:\n$$\n\\|v\\|_{L^{2}(K)}^{2} = h \\int_{0}^{h} \\left( L_{p}\\!\\left(\\frac{2x}{h}-1\\right) \\right)^2 \\,dx\n$$\nTo evaluate the remaining integral, we perform a change of variables to map the integration domain $[0,h]$ to the standard interval $[-1,1]$ on which Legendre polynomials are defined. Let $\\xi = \\frac{2x}{h}-1$. Then $d\\xi = \\frac{2}{h}dx$, which implies $dx = \\frac{h}{2}d\\xi$. When $x=0$, $\\xi=-1$, and when $x=h$, $\\xi=1$. Substituting this into the integral, we get:\n$$\n\\|v\\|_{L^{2}(K)}^{2} = h \\int_{-1}^{1} \\left( L_{p}(\\xi) \\right)^2 \\frac{h}{2} \\,d\\xi = \\frac{h^2}{2} \\int_{-1}^{1} (L_{p}(\\xi))^2 \\,d\\xi\n$$\nUsing the standard orthogonality property of Legendre polynomials, we have:\n$$\n\\int_{-1}^{1} (L_{p}(\\xi))^2 \\,d\\xi = \\frac{2}{2p+1}\n$$\nTherefore, the squared $L^2$-norm on $K$ is:\n$$\n\\|v\\|_{L^{2}(K)}^{2} = \\frac{h^2}{2} \\left( \\frac{2}{2p+1} \\right) = \\frac{h^2}{2p+1}\n$$\n\nNext, we compute the squared $L^2$-norm of the trace of $v$ on the boundary $\\partial K$. The boundary consists of four edges:\n\\begin{itemize}\n    \\item Edge 1: $\\{ (0, y) : y \\in (0,h) \\}$\n    \\item Edge 2: $\\{ (h, y) : y \\in (0,h) \\}$\n    \\item Edge 3: $\\{ (x, 0) : x \\in (0,h) \\}$\n    \\item Edge 4: $\\{ (x, h) : x \\in (0,h) \\}$\n\\end{itemize}\nThe squared norm on the boundary is the sum of the squared norms over each edge:\n$$\n\\|v\\|_{L^{2}(\\partial K)}^{2} = \\int_{\\partial K} |v(s)|^2 \\,ds = \\int_{y=0}^{h} |v(0,y)|^2 dy + \\int_{y=0}^{h} |v(h,y)|^2 dy + \\int_{x=0}^{h} |v(x,0)|^2 dx + \\int_{x=0}^{h} |v(x,h)|^2 dx\n$$\nWe evaluate the integrand on each edge:\n\\begin{itemize}\n    \\item On Edge 1 ($x=0$): $v(0,y) = L_{p}\\!\\left(\\frac{2(0)}{h}-1\\right) = L_{p}(-1)$. It is a standard property that $L_{p}(-1) = (-1)^p$.\n    \\item On Edge 2 ($x=h$): $v(h,y) = L_{p}\\!\\left(\\frac{2(h)}{h}-1\\right) = L_{p}(1)$. The problem states the normalization $L_{p}(1)=1$.\n    \\item On Edge 3 ($y=0$): $v(x,0) = L_{p}\\!\\left(\\frac{2x}{h}-1\\right)$.\n    \\item On Edge 4 ($y=h$): $v(x,h) = L_{p}\\!\\left(\\frac{2x}{h}-1\\right)$.\n\\end{itemize}\nNow we compute the integrals for each edge:\n\\begin{itemize}\n    \\item Edge 1: $\\int_{0}^{h} |L_{p}(-1)|^2 \\,dy = \\int_{0}^{h} |(-1)^p|^2 \\,dy = \\int_{0}^{h} 1 \\,dy = h$.\n    \\item Edge 2: $\\int_{0}^{h} |L_{p}(1)|^2 \\,dy = \\int_{0}^{h} 1^2 \\,dy = h$.\n    \\item Edge 3: $\\int_{0}^{h} \\left( L_{p}\\!\\left(\\frac{2x}{h}-1\\right) \\right)^2 \\,dx$. This is the same integral we encountered in the calculation of the volume norm, but without the multiplicative factor of $h$.\n    $$ \\int_{0}^{h} \\left( L_{p}\\!\\left(\\frac{2x}{h}-1\\right) \\right)^2 \\,dx = \\int_{-1}^{1} (L_{p}(\\xi))^2 \\frac{h}{2} \\,d\\xi = \\frac{h}{2} \\left( \\frac{2}{2p+1} \\right) = \\frac{h}{2p+1} $$\n    \\item Edge 4: The integral is identical to that of Edge 3, so its value is also $\\frac{h}{2p+1}$.\n\\end{itemize}\nSumming the contributions from all four edges:\n$$\n\\|v\\|_{L^{2}(\\partial K)}^{2} = h + h + \\frac{h}{2p+1} + \\frac{h}{2p+1} = 2h + \\frac{2h}{2p+1}\n$$\nSimplifying this expression:\n$$\n\\|v\\|_{L^{2}(\\partial K)}^{2} = 2h \\left( 1 + \\frac{1}{2p+1} \\right) = 2h \\left( \\frac{2p+1+1}{2p+1} \\right) = \\frac{2h(2p+2)}{2p+1} = \\frac{4h(p+1)}{2p+1}\n$$\nFinally, we compute the desired ratio:\n$$\n\\frac{\\|v\\|_{L^{2}(\\partial K)}^{2}}{\\|v\\|_{L^{2}(K)}^{2}} = \\frac{\\frac{4h(p+1)}{2p+1}}{\\frac{h^2}{2p+1}} = \\frac{4h(p+1)}{2p+1} \\cdot \\frac{2p+1}{h^2} = \\frac{4(p+1)}{h}\n$$\nFor large $p$, this expression behaves as $O(p/h)$.\n\nThe canonical theoretical inverse trace inequality for a polynomial $u_p$ of degree $p$ on a shape-regular 2D element $K$ with characteristic size $h$ is of the form:\n$$\n\\|u_p\\|_{L^2(\\partial K)}^2 \\leq C \\frac{p^2}{h} \\|u_p\\|_{L^2(K)}^2\n$$\nwhere $C$ is a constant independent of $p$ and $h$. This inequality implies that the ratio $\\frac{\\|u_p\\|_{L^{2}(\\partial K)}^{2}}{\\|u_p\\|_{L^{2}(K)}^{2}}$ is bounded above by a term that scales as $O(p^2/h)$.\n\nOur calculated ratio for the specific function $v(x,y)=L_{p}\\!\\left(\\frac{2x}{h}-1\\right)$ scales as $O(p/h)$. The discrepancy in the exponent of $p$ ($1$ versus $2$) arises because the general inequality must hold for all polynomials in the given space, and the $O(p^2/h)$ scaling is a worst-case bound. This bound is typically saturated by polynomials that are specifically constructed to have large values on the boundary relative to their $L^2$-norm in the interior (e.g., functions related to the reproducing kernel of the polynomial space, which are highly \"peaky\" at the boundary). The chosen function $v$, being a single basis function in one direction, is not such an extremizing polynomial, and thus exhibits a more favorable, milder scaling with the polynomial degree $p$.",
            "answer": "$$\n\\boxed{\\frac{4(p+1)}{h}}\n$$"
        },
        {
            "introduction": "Bridging theory and practice, this exercise demonstrates how discrete trace constants are computed in real-world numerical codes. While analytical methods provide scaling laws, practical implementations require the precise value of the maximal boundary-to-interior norm ratio for a given polynomial basis. You will transform this maximization problem into a generalized eigenvalue problem, assemble the necessary matrices using numerical quadrature, and solve it to find the exact constant needed to set penalty parameters and ensure stability .",
            "id": "3424636",
            "problem": "Let $K$ denote a two-dimensional element used in Spectral and Discontinuous Galerkin (DG) methods (Discontinuous Galerkin (DG)). The continuous trace inequality at the level of the element states that there exists a constant $C_{\\mathrm{tr}}$ such that, for sufficiently smooth $u$,\n$$\n\\lVert u \\rVert_{\\partial K} \\leq C_{\\mathrm{tr}} \\, \\lVert u \\rVert_{K},\n$$\nwhere $\\lVert \\cdot \\rVert_{\\partial K}$ is the $L^2$ norm on the boundary $\\partial K$ and $\\lVert \\cdot \\rVert_{K}$ is the $L^2$ norm on the interior $K$. In practical high-order methods, the extremal ratio of boundary-to-interior norms over finite-dimensional polynomial spaces determines discrete trace constants that control stability of numerical fluxes and penalties. Your task is to design and implement a numerical experiment that determines, for a given element size and polynomial degree, the maximal ratio\n$$\n\\sup_{u \\in \\mathcal{V}_p \\setminus \\{0\\}} \\frac{\\lVert u \\rVert_{\\partial K}}{\\lVert u \\rVert_{K}},\n$$\nwhere $\\mathcal{V}_p$ is a tensor-product polynomial space of degree at most $p$ on $K$.\n\nWork on the following scientifically grounded, fully specified setup:\n\n- Geometry and mapping. Use the reference square $K_{\\mathrm{ref}} = [-1,1]^2$ and the affine mapping $F_h : K_{\\mathrm{ref}} \\to K_h$ defined by $x = \\frac{h}{2}\\,\\xi$ and $y = \\frac{h}{2}\\,\\eta$, where $(\\xi,\\eta) \\in [-1,1]^2$ and $h > 0$ is the physical side length of the square $K_h$. The Jacobian determinant satisfies $\\lvert J \\rvert = \\left(\\frac{h}{2}\\right)^2$ and the boundary line element scales as $\\left(\\frac{h}{2}\\right)$.\n\n- Polynomial space. Take $\\mathcal{V}_p = Q_p(K_{\\mathrm{ref}})$, the tensor-product space spanned by Legendre polynomials $\\{P_i(\\xi)\\}_{i=0}^{p}$ and $\\{P_j(\\eta)\\}_{j=0}^{p}$, i.e., basis functions $\\phi_{ij}(\\xi,\\eta) = P_i(\\xi) P_j(\\eta)$ for $0 \\le i,j \\le p$. Legendre polynomials are defined by $P_0(x)=1$, $P_1(x)=x$, and the recurrence $(n+1)P_{n+1}(x) = (2n+1)x P_n(x) - n P_{n-1}(x)$ for $n \\ge 1$.\n\n- Norms. For a function $u \\in \\mathcal{V}_p$ pulled back from $K_h$ to $K_{\\mathrm{ref}}$ by $F_h^{-1}$ (i.e., viewed as $u(\\xi,\\eta)$ on $K_{\\mathrm{ref}}$), define\n$$\n\\lVert u \\rVert_{K_h}^2 = \\int_{K_h} u^2 \\, \\mathrm{d}A = \\int_{K_{\\mathrm{ref}}} u^2 \\, \\left(\\frac{h}{2}\\right)^2 \\, \\mathrm{d}\\xi \\, \\mathrm{d}\\eta,\n$$\n$$\n\\lVert u \\rVert_{\\partial K_h}^2 = \\int_{\\partial K_h} u^2 \\, \\mathrm{d}s = \\int_{\\partial K_{\\mathrm{ref}}} u^2 \\, \\left(\\frac{h}{2}\\right) \\, \\mathrm{d}\\sigma.\n$$\n\n- Optimization target. Consider the Rayleigh quotient\n$$\nR(u) = \\frac{\\lVert u \\rVert_{\\partial K_h}^2}{\\lVert u \\rVert_{K_h}^2},\n$$\nover $u \\in \\mathcal{V}_p \\setminus \\{0\\}$. The square root of its maximum value gives the desired maximal ratio $\\sup \\lVert u \\rVert_{\\partial K_h} / \\lVert u \\rVert_{K_h}$.\n\n- Discretization of integrals. Use tensor-product Gauss–Legendre quadrature with a number of points $n_q = p + 3$ in each direction to assemble:\n  1. The interior symmetric positive-definite mass matrix $M \\in \\mathbb{R}^{N \\times N}$ (with $N=(p+1)^2$) approximating $\\lVert u \\rVert_{K_h}^2$ via quadrature on $K_{\\mathrm{ref}}$ and including the factor $\\left(\\frac{h}{2}\\right)^2$.\n  2. The boundary symmetric mass matrix $B \\in \\mathbb{R}^{N \\times N}$ approximating $\\lVert u \\rVert_{\\partial K_h}^2$ via one-dimensional Gauss–Legendre quadrature along each of the four edges of $K_{\\mathrm{ref}}$ and including the factor $\\left(\\frac{h}{2}\\right)$.\n\n- Computation of the maximal ratio. Formulate the generalized symmetric eigenvalue problem $B \\mathbf{v} = \\lambda M \\mathbf{v}$. The largest eigenvalue $\\lambda_{\\max}$ (which is nonnegative) satisfies $\\sup_{u \\in \\mathcal{V}_p \\setminus \\{0\\}} R(u) = \\lambda_{\\max}$, and the desired maximal ratio is $\\sqrt{\\lambda_{\\max}}$.\n\nFundamental base assumptions for the derivation must start from the definitions of $L^2$ norms, properties of Legendre polynomials, Gauss–Legendre quadrature exactness for polynomials, and the Rayleigh quotient characterization of generalized eigenvalues for symmetric definite pairs.\n\nYou must implement a complete program that:\n- Builds $M$ and $B$ as described,\n- Solves the generalized eigenproblem to find $\\lambda_{\\max}$,\n- Outputs the maximal ratio $\\sqrt{\\lambda_{\\max}}$ for each requested test case.\n\nUnits: Since the ratio $\\lVert u \\rVert_{\\partial K_h} / \\lVert u \\rVert_{K_h}$ has the dimension of inverse square-root length, express each output as a pure floating-point number implicitly measured in $1/\\sqrt{\\text{length}}$ given that $h$ is expressed in consistent length units. No unit strings are to be printed.\n\nTest suite and final output specification:\n- Use the following ordered test suite of pairs $(p,h)$:\n  1. $(0,\\,1.0)$,\n  2. $(1,\\,1.0)$,\n  3. $(3,\\,0.5)$,\n  4. $(6,\\,2.0)$,\n  5. $(10,\\,1.0)$.\n- Your program should produce a single line of output containing the maximal ratios for these test cases as a comma-separated list of decimal numbers rounded to ten digits after the decimal point, enclosed in square brackets. For example, an output line should look like\n$[r_1,r_2,r_3,r_4,r_5]$,\nwhere each $r_i$ is a floating-point number formatted with exactly ten digits after the decimal point.\n\nYour implementation must not read any input and must use only the specified runtime environment.",
            "solution": "We begin with the foundational mathematical definitions. For a function $u \\in L^2(K)$, the $L^2$ norm over the interior $K$ is defined by\n$$\n\\lVert u \\rVert_{K}^2 = \\int_{K} u^2 \\, \\mathrm{d}A.\n$$\nSimilarly, the $L^2$ norm over the boundary $\\partial K$ is defined by\n$$\n\\lVert u \\rVert_{\\partial K}^2 = \\int_{\\partial K} u^2 \\, \\mathrm{d}s.\n$$\nUnder the affine mapping $F_h : (\\xi,\\eta) \\mapsto \\left(\\frac{h}{2}\\xi, \\frac{h}{2}\\eta \\right)$ from the reference square $K_{\\mathrm{ref}} = [-1,1]^2$ to the physical square $K_h$, the area element transforms as $\\mathrm{d}A = \\left(\\frac{h}{2}\\right)^2 \\mathrm{d}\\xi \\mathrm{d}\\eta$ and the boundary line element transforms as $\\mathrm{d}s = \\left(\\frac{h}{2}\\right) \\mathrm{d}\\sigma$, where $\\mathrm{d}\\sigma$ is the line measure on $\\partial K_{\\mathrm{ref}}$. Therefore, for a function $u$ on $K_h$ pulled back to $K_{\\mathrm{ref}}$, we obtain\n$$\n\\lVert u \\rVert_{K_h}^2 = \\int_{K_{\\mathrm{ref}}} u^2 \\, \\left(\\frac{h}{2}\\right)^2 \\mathrm{d}\\xi \\mathrm{d}\\eta,\n\\quad\n\\lVert u \\rVert_{\\partial K_h}^2 = \\int_{\\partial K_{\\mathrm{ref}}} u^2 \\, \\left(\\frac{h}{2}\\right) \\mathrm{d}\\sigma.\n$$\nThe space $\\mathcal{V}_p = Q_p(K_{\\mathrm{ref}})$ is the span of tensor-product basis functions\n$$\n\\phi_{ij}(\\xi,\\eta) = P_i(\\xi) P_j(\\eta), \\quad 0 \\le i,j \\le p,\n$$\nwhere $\\{P_n\\}_{n=0}^{p}$ are Legendre polynomials on $[-1,1]$ defined by $P_0(x) = 1$, $P_1(x) = x$, and the recurrence relation\n$$\n(n+1)P_{n+1}(x) = (2n+1) x \\, P_n(x) - n \\, P_{n-1}(x), \\quad n \\ge 1.\n$$\nLegendre polynomials are orthogonal with respect to the standard $L^2$ inner product on $[-1,1]$, and Gauss–Legendre quadrature with $n_q$ points integrates polynomials exactly up to degree $2n_q - 1$.\n\nTo determine the maximal ratio\n$$\n\\sup_{u \\in \\mathcal{V}_p \\setminus \\{0\\}} \\frac{\\lVert u \\rVert_{\\partial K_h}}{\\lVert u \\rVert_{K_h}},\n$$\nwe consider the squared ratio in the form of a Rayleigh quotient:\n$$\nR(u) = \\frac{\\lVert u \\rVert_{\\partial K_h}^2}{\\lVert u \\rVert_{K_h}^2}.\n$$\nIf we expand $u$ in the basis $\\{\\phi_{ij}\\}$,\n$$\nu(\\xi,\\eta) = \\sum_{i=0}^p \\sum_{j=0}^p c_{ij} \\, \\phi_{ij}(\\xi,\\eta),\n$$\nand collect coefficients into a vector $\\mathbf{c} \\in \\mathbb{R}^{N}$ with $N = (p+1)^2$, then the interior norm squared and boundary norm squared can be approximated via quadrature as quadratic forms\n$$\n\\lVert u \\rVert_{K_h}^2 \\approx \\mathbf{c}^\\top M \\, \\mathbf{c}, \\qquad \\lVert u \\rVert_{\\partial K_h}^2 \\approx \\mathbf{c}^\\top B \\, \\mathbf{c},\n$$\nwhere $M$ is the symmetric positive-definite mass matrix assembled from two-dimensional Gauss–Legendre quadrature over $K_{\\mathrm{ref}}$ incorporating the factor $\\left(\\frac{h}{2}\\right)^2$, and $B$ is the symmetric boundary mass matrix assembled from one-dimensional Gauss–Legendre quadrature along each of the four edges of $K_{\\mathrm{ref}}$ incorporating the factor $\\left(\\frac{h}{2}\\right)$. The choice $n_q = p+3$ in each one-dimensional quadrature ensures exact integration of all polynomial products appearing in the matrix entries because the integrands have degree at most $2p$ in each variable.\n\nThe Rayleigh quotient for the coefficient vector becomes\n$$\nR(\\mathbf{c}) = \\frac{\\mathbf{c}^\\top B \\, \\mathbf{c}}{\\mathbf{c}^\\top M \\, \\mathbf{c}}.\n$$\nBy the fundamental property of Rayleigh quotients for symmetric matrix pairs $(B,M)$ with $M$ symmetric positive-definite, the maximum of $R(\\mathbf{c})$ over $\\mathbf{c} \\neq \\mathbf{0}$ equals the largest generalized eigenvalue $\\lambda_{\\max}$ satisfying\n$$\nB \\mathbf{v} = \\lambda M \\mathbf{v}.\n$$\nHence,\n$$\n\\sup_{u \\in \\mathcal{V}_p \\setminus \\{0\\}} R(u) = \\lambda_{\\max},\n\\quad \\text{and} \\quad\n\\sup_{u \\in \\mathcal{V}_p \\setminus \\{0\\}} \\frac{\\lVert u \\rVert_{\\partial K_h}}{\\lVert u \\rVert_{K_h}} = \\sqrt{\\lambda_{\\max}}.\n$$\n\nAlgorithmic design:\n1. Choose the polynomial degree $p$ and side length $h$. Set $n_q = p + 3$ for quadrature order.\n2. Compute one-dimensional Gauss–Legendre nodes and weights $\\{x_k, w_k\\}_{k=1}^{n_q}$ on $[-1,1]$.\n3. Evaluate Legendre polynomials $P_n(x_k)$ for $n=0,\\dots,p$ at the nodes in both directions ($\\xi$ and $\\eta$), forming matrices $L_x \\in \\mathbb{R}^{(p+1) \\times n_q}$ and $L_y \\in \\mathbb{R}^{(p+1) \\times n_q}$ via the recurrence relation.\n4. Assemble the interior mass matrix $M$:\n   - Form the tensor-product evaluation of each basis function over the two-dimensional quadrature grid by the outer products of $L_x$ and $L_y$.\n   - Construct the two-dimensional quadrature weights as $\\left(\\frac{h}{2}\\right)^2$ times the Kronecker product of the one-dimensional weights, and use them to assemble $M = V_{\\mathrm{int}} \\, \\mathrm{diag}(W_{\\mathrm{int}}) \\, V_{\\mathrm{int}}^\\top$, where $V_{\\mathrm{int}}$ is the basis evaluation matrix on the grid.\n5. Assemble the boundary mass matrix $B$:\n   - For each of the four edges of $K_{\\mathrm{ref}}$, evaluate the basis functions along the edge. For edges with $\\xi = \\pm 1$, use $P_i(\\pm 1)$ for the fixed coordinate and $L_y$ for the variable direction; for edges with $\\eta = \\pm 1$, use $L_x$ for the variable direction and $P_j(\\pm 1)$ for the fixed coordinate.\n   - Multiply the one-dimensional quadrature weights by $\\left(\\frac{h}{2}\\right)$ and assemble contributions $B_{\\mathrm{edge}} = V_{\\mathrm{edge}} \\, \\mathrm{diag}(W_{\\mathrm{edge}}) \\, V_{\\mathrm{edge}}^\\top$; sum all four edges to obtain $B$.\n6. Solve the generalized eigenproblem $B \\mathbf{v} = \\lambda M \\mathbf{v}$ using a symmetric solver to obtain the eigenvalues and take the largest $\\lambda_{\\max}$.\n7. Report the maximal ratio $\\sqrt{\\lambda_{\\max}}$.\n\nSanity checks:\n- For $p=0$ (constant basis only), one can compute exactly that $\\lVert u \\rVert_{\\partial K_h} / \\lVert u \\rVert_{K_h} = \\sqrt{\\frac{\\text{perimeter}(K_h)}{\\text{area}(K_h)}} = \\sqrt{\\frac{4h}{h^2}} = \\frac{2}{\\sqrt{h}}$, which the numerical method reproduces because the quadrature is exact for constants.\n\nNumerical details:\n- Use $n_q = p+3$ to ensure exactness up to degree $2p+5$ in one dimension, which covers all polynomial products encountered.\n- Use a stable Legendre recurrence to evaluate $P_n$ at quadrature nodes including the values $P_n(\\pm 1) = (\\pm 1)^n$ by recurrence (or directly by the known endpoint property).\n- Use a symmetric generalized eigenvalue solver for $(B,M)$ to avoid forming $M^{-1}$ explicitly; the largest eigenvalue is nonnegative due to the positivity of $B$ and $M$.\n\nFinally, apply this procedure to the test suite $(p,h) \\in \\{(0,1.0), (1,1.0), (3,0.5), (6,2.0), (10,1.0)\\}$ and print the maximal ratios in one line as a comma-separated list enclosed in square brackets with each value formatted to ten digits after the decimal point.",
            "answer": "```python\nimport numpy as np\nfrom numpy.polynomial.legendre import leggauss\nfrom scipy.linalg import eigh\n\ndef legendre_matrix(x, p):\n    \"\"\"\n    Compute Legendre polynomials P_n(x) for n=0..p at points x using recurrence.\n    Returns an array L of shape (p+1, len(x)), where L[n, :] = P_n(x).\n    \"\"\"\n    x = np.asarray(x)\n    npts = x.size\n    L = np.zeros((p + 1, npts), dtype=np.float64)\n    L[0, :] = 1.0\n    if p >= 1:\n        L[1, :] = x\n        for n in range(1, p):\n            # (n+1) P_{n+1}(x) = (2n+1) x P_n(x) - n P_{n-1}(x)\n            L[n + 1, :] = ((2 * n + 1) * x * L[n, :] - n * L[n - 1, :]) / (n + 1)\n    return L\n\ndef assemble_matrices(p, h):\n    \"\"\"\n    Assemble interior mass matrix M and boundary mass matrix B for Q_p on the square K_h.\n    Uses Gauss-Legendre quadrature with n_q = p + 3 points in each direction.\n    \"\"\"\n    n_q = p + 3  # sufficient for exactness up to degree 2p+5\n    # 1D Gauss-Legendre nodes and weights on [-1,1]\n    x_nodes, x_weights = leggauss(n_q)\n    y_nodes, y_weights = x_nodes, x_weights  # same quadrature in both directions\n\n    # Evaluate Legendre polynomials at nodes\n    Lx = legendre_matrix(x_nodes, p)  # shape (p+1, n_q)\n    Ly = legendre_matrix(y_nodes, p)  # shape (p+1, n_q)\n\n    # Basis count\n    dim = (p + 1) ** 2\n\n    # Assemble interior evaluation matrix V_int: shape (dim, n_q * n_q)\n    # Each basis phi_{i,j} evaluated at all tensor-product nodes\n    # To build efficiently, we use outer products of 1D evaluations\n    V_int = np.zeros((dim, n_q * n_q), dtype=np.float64)\n    idx = 0\n    for i in range(p + 1):\n        for j in range(p + 1):\n            # Evaluate P_i(x) * P_j(y) over grid\n            # Outer product gives (n_q, n_q), then flatten in row-major or column-major consistently\n            vals = np.outer(Lx[i, :], Ly[j, :]).ravel()  # flatten\n            V_int[idx, :] = vals\n            idx += 1\n\n    # Interior weights (tensor product), scaled by (h/2)^2\n    alpha = h / 2.0\n    W_int = alpha ** 2 * np.kron(x_weights, y_weights)  # shape (n_q * n_q,)\n\n    # Assemble interior mass matrix: M = V_int * diag(W_int) * V_int^T\n    # Using weighted inner product: M[m,n] = sum_k W_int[k] * V_int[m,k] * V_int[n,k]\n    # Implement via matrix multiplication with weighting\n    # Compute V_int * diag(sqrt(W_int))\n    sqrt_W_int = np.sqrt(W_int)\n    Vw_int = V_int * sqrt_W_int[np.newaxis, :]\n    M = Vw_int @ Vw_int.T\n\n    # Assemble boundary mass matrix B: sum over four edges\n    B = np.zeros((dim, dim), dtype=np.float64)\n\n    # One-dimensional weights for edges, scaled by alpha\n    W_edge = alpha * x_weights  # shape (n_q,)\n\n    # Precompute endpoint values P_i(±1)\n    P_at_plus1 = np.ones(p + 1, dtype=np.float64)\n    P_at_minus1 = np.array([(-1) ** n for n in range(p + 1)], dtype=np.float64)\n\n    # Edge xi = +1: (xi, eta) = (1, t), t in [-1,1]\n    V_edge_plus_x = np.zeros((dim, n_q), dtype=np.float64)\n    idx = 0\n    for i in range(p + 1):\n        for j in range(p + 1):\n            V_edge_plus_x[idx, :] = P_at_plus1[i] * Ly[j, :]\n            idx += 1\n    Vw_edge_plus_x = V_edge_plus_x * np.sqrt(W_edge)[np.newaxis, :]\n    B += Vw_edge_plus_x @ Vw_edge_plus_x.T\n\n    # Edge xi = -1: (xi, eta) = (-1, t)\n    V_edge_minus_x = np.zeros((dim, n_q), dtype=np.float64)\n    idx = 0\n    for i in range(p + 1):\n        for j in range(p + 1):\n            V_edge_minus_x[idx, :] = P_at_minus1[i] * Ly[j, :]\n            idx += 1\n    Vw_edge_minus_x = V_edge_minus_x * np.sqrt(W_edge)[np.newaxis, :]\n    B += Vw_edge_minus_x @ Vw_edge_minus_x.T\n\n    # Edge eta = +1: (xi, eta) = (t, 1)\n    V_edge_plus_y = np.zeros((dim, n_q), dtype=np.float64)\n    idx = 0\n    for i in range(p + 1):\n        for j in range(p + 1):\n            V_edge_plus_y[idx, :] = Lx[i, :] * P_at_plus1[j]\n            idx += 1\n    Vw_edge_plus_y = V_edge_plus_y * np.sqrt(W_edge)[np.newaxis, :]\n    B += Vw_edge_plus_y @ Vw_edge_plus_y.T\n\n    # Edge eta = -1: (xi, eta) = (t, -1)\n    V_edge_minus_y = np.zeros((dim, n_q), dtype=np.float64)\n    idx = 0\n    for i in range(p + 1):\n        for j in range(p + 1):\n            V_edge_minus_y[idx, :] = Lx[i, :] * P_at_minus1[j]\n            idx += 1\n    Vw_edge_minus_y = V_edge_minus_y * np.sqrt(W_edge)[np.newaxis, :]\n    B += Vw_edge_minus_y @ Vw_edge_minus_y.T\n\n    return M, B\n\ndef maximal_ratio(p, h):\n    \"\"\"\n    Compute the maximal ratio ||u||_{∂K_h} / ||u||_{K_h} over u in Q_p(K_ref) mapped to K_h.\n    \"\"\"\n    M, B = assemble_matrices(p, h)\n    # Solve the generalized eigenproblem B v = lambda M v\n    # eigh returns eigenvalues in ascending order\n    evals = eigh(B, M, eigvals_only=True)\n    lambda_max = np.max(evals)\n    # Numerical guard: ensure non-negativity\n    if lambda_max < 0 and lambda_max > -1e-12:\n        lambda_max = 0.0\n    ratio = np.sqrt(lambda_max)\n    return float(ratio)\n\ndef solve():\n    test_cases = [\n        (0, 1.0),\n        (1, 1.0),\n        (3, 0.5),\n        (6, 2.0),\n        (10, 1.0),\n    ]\n    results = []\n    for p, h in test_cases:\n        r = maximal_ratio(p, h)\n        results.append(r)\n    # Print with exactly ten digits after the decimal point\n    formatted = \",\".join(f\"{val:.10f}\" for val in results)\n    print(f\"[{formatted}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}