{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握后验误差估计，动手计算是不可或缺的一步。本练习将带领您根据一个假设的二维单元上的已知数据，手动计算局部误差指示子 $\\eta_K$ 。通过这个过程，您将清晰地看到单元内部残差和边界通量跳跃项如何共同构成误差的量度，从而为理解更复杂的自适应算法打下坚实的基础。",
            "id": "3514528",
            "problem": "考虑一个稳态标量扩散模型，它代表了多物理场耦合模拟中的一个单场子问题，由强形式 $-\\nabla \\cdot (\\kappa \\nabla u) = f$ 在一个有界多边形域上控制，并采用协调有限元法（FEM）在二维网格上进行近似，得到 $u_h \\in V_h$。在用于自适应网格加密的基于残差的后验误差估计中，单元指标由单元内部残差及其各边上的通量跳跃残差构成。设单元 $K$ 是形状规则的，其直径为 $h_K$，边长为 $\\{h_{e}\\}_{e \\subset \\partial K}$，单元内部残差大小为 $r_K$，各边上的通量跳跃大小为 $\\{j_e\\}_{e \\subset \\partial K}$。网格质量度量 $h_K$ 和边长 $\\{h_e\\}$ 通过形状规则网格上的标准逆不等式和迹不等式，进入指标的缩放中。\n\n假设单个三角形单元 $K$ 具有以下数据：直径 $h_K = 0.1$，单元内部残差大小 $r_K = 5$，其三条边的长度分别为 $(0.1, 0.1, 0.141)$，对应边上的通量跳跃大小分别为 $(3, 1, 2)$。使用由弱形式和分部积分残差表示所隐含的典范的基于残差的缩放，计算单元 $K$ 的单元指标 $\\eta_K$。请将您的最终答案表示为单个简化的精确表达式。无需四舍五入。",
            "solution": "该问题陈述被评估为有效。它在有限元法（FEM）的既有后验误差估计理论框架内具有科学依据，其给出的条件完整且一致，问题本身是适定的，并以客观、正式的语言表述。不存在违反基本原则、矛盾或含糊之处。因此，我们可以着手求解。\n\n该问题要求计算二维域中单个三角形单元 $K$ 的局部、基于残差的后验误差指标，记为 $\\eta_K$。其背后的物理问题由一个稳态标量扩散方程 $-\\nabla \\cdot (\\kappa \\nabla u) = f$ 描述，其中 $u$ 是标量场，$\\kappa$ 是扩散系数，$f$ 是源项。通过有限元法得到的近似解记为 $u_h$。\n\n误差指标 $\\eta_K$ 的“典范的基于残差的缩放”源自残差方程的弱形式以及在形状规则网格上应用标准迹不等式和逆不等式。指标的平方 $\\eta_K^2$ 由两部分主要贡献构成：一部分来自单元内部的残差，另一部分来自跨单元边的通量跳跃。其一般形式为：\n$$\n\\eta_K^2 = C_{int}^2 h_K^2 \\|R_K\\|_{L_2(K)}^2 + \\sum_{e \\in \\partial K} C_{edge}^2 h_e \\|J_e\\|_{L_2(e)}^2\n$$\n此处，$h_K$ 是单元 $K$ 的直径，$\\{h_e\\}$ 是其各边的长度。项 $R_K = f + \\nabla \\cdot (\\kappa \\nabla u_h)$ 是内部残差，$\\|R_K\\|_{L_2(K)}$ 是其在单元 $K$ 上的 $L_2$ 范数。项 $J_e = \\llbracket\\kappa \\nabla u_h \\cdot \\mathbf{n}\\rrbracket$ 表示通量的法向分量跨越边 $e$ 的跳跃，$\\|J_e\\|_{L_2(e)}$ 是其在边 $e$ 上的 $L_2$ 范数。常数 $C_{int}$ 和 $C_{edge}$ 依赖于插值理论和单元形状规则性，但在指标的标准定义中通常取为 $1$，这一点由“典范”一词所暗示。\n\n问题提供了以下数据，我们将其映射到公式中的各项：\n- 单元直径：$h_K = 0.1$。\n- 单元内部残差的大小（$L_2$范数）：$r_K = \\|R_K\\|_{L_2(K)} = 5$。\n- 该单元是三角形，因此有三条边，此处用 $i \\in \\{1, 2, 3\\}$ 索引。\n- 边长：$h_{e_1} = 0.1$，$h_{e_2} = 0.1$，以及 $h_{e_3} = 0.141$。\n- 对应边上的通量跳跃大小（$L_2$范数）：$j_{e_1} = \\|J_{e_1}\\|_{L_2(e_1)} = 3$，$j_{e_2} = \\|J_{e_2}\\|_{L_2(e_2)} = 1$，以及 $j_{e_3} = \\|J_{e_3}\\|_{L_2(e_3)} = 2$。\n\n当常数 $C_{int}$ 和 $C_{edge}$ 设为 $1$ 时，指标平方的公式变为：\n$$\n\\eta_K^2 = h_K^2 r_K^2 + h_{e_1} j_{e_1}^2 + h_{e_2} j_{e_2}^2 + h_{e_3} j_{e_3}^2\n$$\n我们现在将给定的数值代入此表达式。为按要求保持精确性，我们将使用分数进行计算。\n$h_K = \\frac{1}{10}$, $r_K = 5$\n$h_{e_1} = \\frac{1}{10}$, $j_{e_1} = 3$\n$h_{e_2} = \\frac{1}{10}$, $j_{e_2} = 1$\n$h_{e_3} = \\frac{141}{1000}$, $j_{e_3} = 2$\n\n来自内部残差的贡献是：\n$$\nh_K^2 r_K^2 = \\left(\\frac{1}{10}\\right)^2 (5)^2 = \\frac{1}{100} \\times 25 = \\frac{25}{100} = \\frac{1}{4}\n$$\n来自三条边上通量跳跃的贡献是：\n$$\nh_{e_1} j_{e_1}^2 = \\frac{1}{10} \\times (3)^2 = \\frac{9}{10}\n$$\n$$\nh_{e_2} j_{e_2}^2 = \\frac{1}{10} \\times (1)^2 = \\frac{1}{10}\n$$\n$$\nh_{e_3} j_{e_3}^2 = \\frac{141}{1000} \\times (2)^2 = \\frac{141}{1000} \\times 4 = \\frac{564}{1000} = \\frac{141}{250}\n$$\n现在，我们将这些分量相加来求 $\\eta_K^2$：\n$$\n\\eta_K^2 = \\frac{1}{4} + \\frac{9}{10} + \\frac{1}{10} + \\frac{141}{250}\n$$\n首先合并具有公分母的项：\n$$\n\\eta_K^2 = \\frac{1}{4} + \\left(\\frac{9}{10} + \\frac{1}{10}\\right) + \\frac{141}{250} = \\frac{1}{4} + 1 + \\frac{141}{250} = \\frac{5}{4} + \\frac{141}{250}\n$$\n为了对这些分数求和，我们找到一个公分母，即 $500$：\n$$\n\\eta_K^2 = \\frac{5 \\times 125}{4 \\times 125} + \\frac{141 \\times 2}{250 \\times 2} = \\frac{625}{500} + \\frac{282}{500} = \\frac{625 + 282}{500} = \\frac{907}{500}\n$$\n问题要求的是单元指标 $\\eta_K$，即该值的平方根：\n$$\n\\eta_K = \\sqrt{\\frac{907}{500}}\n$$\n为了提供一个简化的精确表达式，我们可以将分母有理化：\n$$\n\\eta_K = \\frac{\\sqrt{907}}{\\sqrt{500}} = \\frac{\\sqrt{907}}{\\sqrt{100 \\times 5}} = \\frac{\\sqrt{907}}{10\\sqrt{5}}\n$$\n分子和分母同乘以 $\\sqrt{5}$：\n$$\n\\eta_K = \\frac{\\sqrt{907} \\times \\sqrt{5}}{10\\sqrt{5} \\times \\sqrt{5}} = \\frac{\\sqrt{907 \\times 5}}{10 \\times 5} = \\frac{\\sqrt{4535}}{50}\n$$\n数字 $907$ 是一个质数，所以根式 $\\sqrt{4535}$ 无法进一步简化。这就是单元指标的最终精确表达式。",
            "answer": "$$\\boxed{\\frac{\\sqrt{4535}}{50}}$$"
        },
        {
            "introduction": "理论公式的优美需要通过精确的计算来实现。本练习将引导您从第一性原理出发，为一个模型问题实现一个基于残差的后验估计子 。您不仅要推导为保证积分精确性所需的最小高斯求积点数，还要通过编程实践，将单元内部和边界上的多项式残差精确地计算出来。这能让您深刻体会到数值求积理论在确保估计子可靠性中的核心作用。",
            "id": "3412905",
            "problem": "要求您从第一性原理出发，使用张量积高斯-勒让德求积方法，为一个标量模型椭圆问题实现一个逐单元基于残差的后验估计器，并确定为使残差积分对于一个次数为 $p$ 的多项式逼近是精确的，每个轴所需的最小求积点数。计算在二维空间中的单个方形单元 $K = [0,1]^2$ 上进行。假设单位几何尺度，因此所有依赖于网格的权重都等于 $1$。\n\n从以下基础依据开始：\n- 每个坐标方向上次数为 $p$ 的多项式逼近 $u_h$，以及每个坐标方向上次数为 $p$ 的多项式源项 $f$。\n- 对于具有常数扩散的泊松算子，单元上的强残差为 $f + \\Delta u_h$。\n- 一维高斯-勒让德求积使用 $n$ 个点可以精确积分最高次数为 $2n-1$ 的任意多项式；张量积高斯-勒让德求积将这种精确性扩展到多维的每个轴上。\n\n为给定的整数 $p \\ge 0$ 定义逼近和数据如下：\n- 多项式逼近\n$$\nu_h(x,y) \\;=\\; \\sum_{i=0}^{p}\\sum_{j=0}^{p} a_{ij}\\, x^i y^j,\\quad a_{ij} \\;=\\; \\frac{1}{(i+1)(j+1)}.\n$$\n- 多项式源项\n$$\nf(x,y) \\;=\\; \\sum_{i=0}^{p}\\sum_{j=0}^{p} b_{ij}\\, x^i y^j,\\quad b_{ij} \\;=\\; \\frac{(-1)^{i+j}}{i+j+2}.\n$$\n- 四个边界面上的边界数据：\n    - 在 $\\{x=0\\}$ 上：$g_\\text{left}(y) = \\sum_{j=0}^{p} \\frac{1}{j+1}\\,y^j$ 且法向通量为零 $q_\\text{left}(y) = 0$。\n    - 在 $\\{x=1\\}$ 上：$g_\\text{right}(y) = \\sum_{j=0}^{p} \\frac{(-1)^j}{j+1}\\,y^j$ 且法向通量为零 $q_\\text{right}(y) = 0$。\n    - 在 $\\{y=0\\}$ 上：$g_\\text{bottom}(x) = \\sum_{i=0}^{p} \\frac{1}{i+1}\\,x^i$ 且法向通量为零 $q_\\text{bottom}(x) = 0$。\n    - 在 $\\{y=1\\}$ 上：$g_\\text{top}(x) = \\sum_{i=0}^{p} \\frac{(-1)^i}{i+1}\\,x^i$ 且法向通量为零 $q_\\text{top}(x) = 0$。\n\n考虑典型的基于残差的间断伽辽金估计器（在此单单元场景中，所有几何权重均为 $1$）\n$$\n\\eta(p) \\;=\\; \\int_{K} \\big(f(x,y) + \\Delta u_h(x,y)\\big)^2\\,\\mathrm{d}x\\,\\mathrm{d}y \\;+\\; \\sum_{F\\subset \\partial K} \\left[ \\int_{F} \\big(\\partial_n u_h - q_F\\big)^2\\,\\mathrm{d}s \\;+\\; \\int_{F} \\big(u_h - g_F\\big)^2\\,\\mathrm{d}s \\right],\n$$\n其中 $\\partial_n u_h$ 表示在边界面 $F$ 上 $u_h$ 的外法向导数，而 $q_F$ 和 $g_F$ 表示该边界面上规定的边界通量和边界数据。\n\n任务：\n1. 仅使用高斯-勒让德求积的精确性属性和多项式次数计数，推导出精确积分 $\\eta(p)$ 每一项所需的每个轴上最少高斯-勒让德点数。具体来说：\n    - 对于涉及 $\\big(f + \\Delta u_h\\big)^2$ 的单元内部积分 $K$，给出每个坐标所需的最少点数 $n_\\text{elem}$。\n    - 对于每个涉及切向坐标中多项式平方的一维边界面积分，给出最少点数 $n_\\text{face}$。\n2. 实现一个程序，该程序：\n    - 对于给定的 $p$，构造如上定义的 $u_h$、$f$、$g_F$，并使用 $q_F = 0$。\n    - 使用张量积高斯-勒让德求积对单元项进行计算，使用一维高斯-勒让德求积对每个边界面项进行计算，并使用任务1中确定的每个轴的最小点数，从而精确计算估计器 $\\eta(p)$。\n3. 为以下多项式次数 $p$ 的测试套件提供结果：\n    - $p=0$（分段常数逼近的边界情况）。\n    - $p=1$（线性情况）。\n    - $p=3$（中阶情况）。\n    - $p=5$（高阶情况）。\n4. 输出格式要求：\n    - 您的程序应生成单行输出，包含一个结果列表，每个 $p$ 一个结果，按给定顺序排列。\n    - 每个结果必须是 $[n_\\text{elem}, n_\\text{face}, \\eta]$ 形式的列表，其中 $n_\\text{elem}$ 和 $n_\\text{face}$ 是整数，$\\eta$ 是一个浮点值。\n    - 最终输出必须是用方括号括起来的逗号分隔列表。例如，对于两个情况，它看起来会像 $[[n_1,n_1^\\prime,\\eta_1],[n_2,n_2^\\prime,\\eta_2]]$。\n\n不涉及物理单位或角度单位；所有量都是无量纲的纯数学量。您的推导必须从所述的多项式结构和高斯-勒让德求积的精确性属性开始。您的实现必须严格遵守指定的定义和输出格式。确保程序是自包含的，并且不需要用户输入。",
            "solution": "经评估，该问题是**有效的**。它是在偏微分方程数值分析领域内一个定义明确、有科学依据且客观的问题。所有必要信息均已提供，任务定义清晰。\n\n### 1. 最小求积点数的推导\n\n问题要求确定精确积分一个次数为 $d$ 的多项式所需的最小高斯-勒让德求积点数 $n$。高斯-勒让德求积的基本原理是，区间上的 $n$ 个点可以精确积分次数最高为 $2n-1$ 的任意多项式。为了找到一个次数为 $d$ 的多项式所需的最小 $n$，我们必须满足不等式：\n$$\n2n - 1 \\ge d\n$$\n这意味着 $2n \\ge d+1$，或 $n \\ge \\frac{d+1}{2}$。由于 $n$ 必须是整数，所以最小点数为 $n = \\lceil \\frac{d+1}{2} \\rceil$。对于二维中的张量积法则，此分析独立地应用于每个坐标轴。\n\n#### 1.1 单元内部项 ($n_\\text{elem}$)\n单元内部项是 $I_K = \\int_{K} \\big(f(x,y) + \\Delta u_h(x,y)\\big)^2\\,\\mathrm{d}x\\,\\mathrm{d}y$。为了找到每个轴所需的求积点数 $n_\\text{elem}$，我们必须找到被积函数在每个坐标 $x$ 和 $y$ 中的最大多项式次数。\n\n1.  **$u_h(x,y)$ 的次数**：逼近 $u_h$ 定义为 $u_h(x,y) = \\sum_{i=0}^{p}\\sum_{j=0}^{p} a_{ij}\\, x^i y^j$。$u_h$ 在 $x$ 方向的最大次数为 $p$，在 $y$ 方向的最大次数为 $p$。我们将其记为 $\\deg(u_h) = (p, p)$。\n\n2.  **$f(x,y)$ 的次数**：源项 $f$ 定义为 $f(x,y) = \\sum_{i=0}^{p}\\sum_{j=0}^{p} b_{ij}\\, x^i y^j$。同样，$\\deg(f) = (p, p)$。\n\n3.  **$\\Delta u_h(x,y)$ 的次数**：拉普拉斯算子为 $\\Delta u_h = \\frac{\\partial^2 u_h}{\\partial x^2} + \\frac{\\partial^2 u_h}{\\partial y^2}$。\n    -   $\\frac{\\partial^2 u_h}{\\partial x^2} = \\sum_{i=2}^{p}\\sum_{j=0}^{p} a_{ij}\\, i(i-1) x^{i-2} y^j$。在 $x$ 方向的次数是 $p-2$，在 $y$ 方向的次数是 $p$。所以，$\\deg(\\partial_{xx} u_h) = (p-2, p)$。（对于 $p  2$，此项为零）。\n    -   $\\frac{\\partial^2 u_h}{\\partial y^2} = \\sum_{i=0}^{p}\\sum_{j=2}^{p} a_{ij}\\, j(j-1) x^i y^{j-2}$。在 $x$ 方向的次数是 $p$，在 $y$ 方向的次数是 $p-2$。所以，$\\deg(\\partial_{yy} u_h) = (p, p-2)$。（对于 $p  2$，此项为零）。\n    -   和的次数是各项次数的最大值。因此，对于 $p \\ge 2$，$\\Delta u_h$ 在 $x$ 方向的次数是 $\\max(p-2, p) = p$，在 $y$ 方向的次数是 $\\max(p, p-2) = p$。对于 $p  2$，$\\Delta u_h=0$。在所有 $p \\ge 0$ 的情况下，$\\deg(\\Delta u_h) \\le (p,p)$。\n\n4.  **被积函数的次数**：令内部残差为 $R(x,y) = f(x,y) + \\Delta u_h(x,y)$。$R(x,y)$ 的次数最多为 $(p, p)$。由于 $f$ 和 $\\Delta u_h$ 中的最高次项通常不会抵消，因此对于 $p \\ge 2$ 的情况，次数恰好为 $(p, p)$。\n    被积函数是 $R(x,y)^2$。多项式平方的次数是原多项式次数的两倍。\n    -   $\\deg_x(R^2) = 2 \\deg_x(R) = 2p$。\n    -   $\\deg_y(R^2) = 2 \\deg_y(R) = 2p$。\n    对于 $p=0$ 和 $p=1$ 的情况同样适用，此时 $\\Delta u_h=0$，且 $R=f$。$f^2$ 的次数是 $(2p, 2p)$。\n\n5.  **最小点数 $n_\\text{elem}$**：要精确积分每个坐标中次数为 $d = 2p$ 的多项式，我们需要 $n_\\text{elem}$ 个点，使得 $2n_\\text{elem} - 1 \\ge 2p$。可得：\n    $$\n    n_\\text{elem} \\ge p + \\frac{1}{2} \\implies n_\\text{elem} = p+1\n    $$\n    因此，需要一个 $(p+1) \\times (p+1)$ 的张量积高斯-勒让德网格。\n\n#### 1.2 边界面项 ($n_\\text{face}$)\n边界面项是一维积分。我们分析被积函数在切向坐标 $s$ 中的次数。让我们考虑一个垂直边界面，例如 $F=\\{x=1\\}$，其中 $s=y$。对于所有其他边界面，分析是类似的。\n\n1.  **通量项**：被积函数是 $(\\partial_n u_h - q_F)^2$。在 $F=\\{x=1\\}$ 上，外法向导数是 $\\partial_n u_h = \\partial_x u_h(1,y)$，且 $q_F = q_\\text{right}(y)=0$。\n    -   $\\partial_x u_h(x,y) = \\sum_{i=1}^{p}\\sum_{j=0}^{p} a_{ij}\\, i x^{i-1} y^j$。\n    -   在 $x=1$ 处求值得到 $\\partial_x u_h(1,y) = \\sum_{j=0}^{p} \\left(\\sum_{i=1}^{p} i a_{ij}\\right) y^j$，这是一个次数最多为 $p$ 的 $y$ 的多项式。\n    -   被积函数 $(\\partial_x u_h(1,y))^2$ 是一个次数最多为 $2p$ 的多项式。\n\n2.  **狄利克雷项**：被积函数是 $(u_h - g_F)^2$。在 $F=\\{x=1\\}$ 上，我们有 $g_F=g_\\text{right}(y)$。\n    -   $u_h(1,y) = \\sum_{j=0}^{p} \\left(\\sum_{i=0}^{p} a_{ij}\\right) y^j$，一个次数最多为 $p$ 的 $y$ 的多项式。\n    -   $g_\\text{right}(y) = \\sum_{j=0}^{p} \\frac{(-1)^j}{j+1}y^j$，一个次数为 $p$ 的 $y$ 的多项式。\n    -   差 $u_h(1,y) - g_\\text{right}(y)$ 是一个次数最多为 $p$ 的多项式。\n    -   被积函数 $(u_h(1,y) - g_\\text{right}(y))^2$ 是一个次数最多为 $2p$ 的多项式。\n\n3.  **最小点数 $n_\\text{face}$**：边界面上的两个被积函数都是次数最多为 $d = 2p$ 的多项式。为了精确地积分它们，我们需要 $n_\\text{face}$ 个点，满足 $2n_\\text{face} - 1 \\ge 2p$。可得：\n    $$\n    n_\\text{face} \\ge p + \\frac{1}{2} \\implies n_\\text{face} = p+1\n    $$\n\n因此，对于给定的多项式次数 $p$，单元积分每个轴所需的最小求积点数为 $n_\\text{elem} = p+1$，边界面积分所需的最小求积点数为 $n_\\text{face} = p+1$。\n\n### 2. 实现策略\n\n估计器 $\\eta(p)$ 将使用上面推导出的最小求积点数为每个给定的 $p$ 值计算。\n\n1.  **求积法则**：对于给定的 $p$，我们设置 $n=p+1$。我们使用 `scipy.special.roots_legendre(n)` 来获取在区间 $[-1, 1]$ 上的 $n$ 个高斯-勒让德点 $z_k$ 和权重 $w_k$。然后通过变换将它们缩放到积分域 $[0, 1]$：\n    -   点：$x_k = \\frac{1}{2}(z_k + 1)$\n    -   权重：$w'_k = \\frac{1}{2}w_k$\n\n2.  **多项式求值**：实现各种多项式函数（$u_h, f, \\Delta u_h$ 等）。为了效率，对一维多项式使用 `numpy.polyval`，对非可分离的二维源项 $f(x,y)$ 使用 `numpy.polynomial.polynomial.polyval2d`。这些函数的系数根据给定的定义预先计算。\n    -   利用了 $u_h(x,y) = S(x,p)S(y,p)$ 的可分离性，其中 $S(z,p) = \\sum_{k=0}^{p} \\frac{z^k}{k+1}$，以简化 $u_h$ 及其导数的求值。\n    -   注意到左边界面 ($x=0$) 和底边界面 ($y=0$) 上的狄利克雷残差恒为零，因为 $u_h$ 的构造使其在这些边界面上与边界数据 $g_\\text{left}$ 和 $g_\\text{bottom}$ 相匹配。通过观察 $u_h(0,y) = S(0,p)S(y,p) = 1 \\cdot S(y,p) = g_\\text{left}(y)$ 可以证实这一点，底边界面情况类似。\n\n3.  **积分计算**：\n    -   **单元积分**：使用 `numpy.meshgrid` 构建一个 $n_\\text{elem} \\times n_\\text{elem}$ 的求积点网格和相应的权重网格。在此网格上计算被积函数 $(f + \\Delta u_h)^2$，并通过加权和计算积分：$\\sum_{k,l} (f(x_k,y_l) + \\Delta u_h(x_k,y_l))^2 w'_k w'_l$。\n    -   **边界面积分**：对于四个边界面中的每一个，都使用一组一维的 $n_\\text{face}$ 个求积点和权重。在边界面上的这些点处计算通量和狄利克雷残差的被积函数，并将积分作为加权和来计算。总估计器是单元积分与所有八个边界面积分（单元的四个面各有一个通量项和一个狄利克雷项）之和。\n\n4.  **工作流程**：主程序遍历指定的次数 $p \\in \\{0, 1, 3, 5\\}$，为每个 $p$ 计算 $\\eta(p)$，并将结果 $[n_\\text{elem}, n_\\text{face}, \\eta(p)]$ 存储在一个列表中。最后，按规定格式化并打印结果列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef calculate_eta_for_p(p):\n    \"\"\"\n    Calculates the residual-based error estimator eta for a given polynomial degree p.\n    \"\"\"\n    # Task 1: Determine minimal number of quadrature points.\n    # To integrate a polynomial of degree d=2p exactly, we need n points such that\n    # 2n - 1 >= 2p => n >= p + 1/2. Minimal integer n is p+1.\n    n_elem = p + 1\n    n_face = p + 1\n\n    # Get Gauss-Legendre quadrature points and weights for [-1, 1] and scale to [0, 1].\n    z_elem, w_elem_unscaled = roots_legendre(n_elem)\n    xq_elem = 0.5 * (z_elem + 1)\n    wq_elem = 0.5 * w_elem_unscaled\n\n    z_face, w_face_unscaled = roots_legendre(n_face)\n    s_q = 0.5 * (z_face + 1) # Points for face integrals (tangential coordinate)\n    w_q = 0.5 * w_face_unscaled # Weights for face integrals\n\n    # --- Define polynomial coefficients for use with np.polyval ---\n    # np.polyval evaluates p(x) = c[0]*x**n + c[1]*x**(n-1) + ... + c[n]\n    # S(z,p) = sum_{k=0 to p} z^k / (k+1)\n    S_coeffs = 1.0 / (np.arange(p, -1, -1) + 1)\n\n    # S'(z,p) = sum_{k=1 to p} k * z^{k-1} / (k+1), a polynomial of degree p-1\n    if p >= 1:\n        S_prime_coeffs = (np.arange(p, 0, -1)) / (np.arange(p, 0, -1) + 1)\n    else:\n        S_prime_coeffs = []\n\n    # S''(z,p) = sum_{k=2 to p} k(k-1) * z^{k-2} / (k+1), a polynomial of degree p-2\n    if p >= 2:\n        k_vals = np.arange(p, 1, -1)\n        S_prime_prime_coeffs = (k_vals * (k_vals - 1)) / (k_vals + 1)\n    else:\n        S_prime_prime_coeffs = []\n        \n    # f(x,y,p) = sum_{i=0 to p} sum_{j=0 to p} (-1)^{i+j}/(i+j+2) * x^i y^j\n    # Coeffs for numpy.polynomial.polynomial.polyval2d\n    f_coeffs = np.zeros((p + 1, p + 1))\n    for i in range(p + 1):\n        for j in range(p + 1):\n            f_coeffs[i, j] = ((-1)**(i + j)) / (i + j + 2.0)\n\n    # g_right(y, p) = sum_{j=0 to p} (-1)^j/(j+1) * y^j\n    g_right_coeffs = ((-1)**np.arange(p, -1, -1)) / (np.arange(p, -1, -1) + 1)\n    g_top_coeffs = g_right_coeffs # by symmetry\n\n    # --- 1. Element interior integral ---\n    X, Y = np.meshgrid(xq_elem, xq_elem)\n    WX, WY = np.meshgrid(wq_elem, wq_elem)\n\n    f_vals = np.polynomial.polynomial.polyval2d(X, Y, f_coeffs)\n\n    S_X = np.polyval(S_coeffs, X)\n    S_Y = np.polyval(S_coeffs, Y)\n    S_pp_X = np.polyval(S_prime_prime_coeffs, X)\n    S_pp_Y = np.polyval(S_prime_prime_coeffs, Y)\n\n    delta_uh_vals = S_pp_X * S_Y + S_X * S_pp_Y\n    \n    residual_vals = f_vals + delta_uh_vals\n    elem_integral = np.sum((residual_vals**2) * WX * WY)\n\n    # --- 2. Face integrals ---\n    total_face_integral = 0.0\n    q_F = 0.0 # prescribed flux is zero on all faces\n\n    # --- Left face (x=0, n=(-1,0)) ---\n    # Dirichlet term is zero, since u_h(0,y) = g_left(y) by construction.\n    du_dx_at_0 = np.polyval(S_prime_coeffs, 0.0) * np.polyval(S_coeffs, s_q)\n    flux_left = np.sum(((-du_dx_at_0 - q_F)**2) * w_q)\n\n    # --- Right face (x=1, n=(1,0)) ---\n    u_h_at_1 = np.polyval(S_coeffs, 1.0) * np.polyval(S_coeffs, s_q)\n    g_right_vals = np.polyval(g_right_coeffs, s_q)\n    dirichlet_right = np.sum(((u_h_at_1 - g_right_vals)**2) * w_q)\n    \n    du_dx_at_1 = np.polyval(S_prime_coeffs, 1.0) * np.polyval(S_coeffs, s_q)\n    flux_right = np.sum(((du_dx_at_1 - q_F)**2) * w_q)\n\n    # --- Bottom face (y=0, n=(0,-1)) ---\n    # Dirichlet term is zero, since u_h(x,0) = g_bottom(x) by construction.\n    du_dy_at_0 = np.polyval(S_coeffs, s_q) * np.polyval(S_prime_coeffs, 0.0)\n    flux_bottom = np.sum(((-du_dy_at_0 - q_F)**2) * w_q)\n\n    # --- Top face (y=1, n=(0,1)) ---\n    u_h_at_1_top = np.polyval(S_coeffs, s_q) * np.polyval(S_coeffs, 1.0)\n    g_top_vals = np.polyval(g_top_coeffs, s_q)\n    dirichlet_top = np.sum(((u_h_at_1_top - g_top_vals)**2) * w_q)\n\n    du_dy_at_1 = np.polyval(S_coeffs, s_q) * np.polyval(S_prime_coeffs, 1.0)\n    flux_top = np.sum(((du_dy_at_1 - q_F)**2) * w_q)\n    \n    total_face_integral = (flux_left + dirichlet_right + flux_right +\n                           flux_bottom + dirichlet_top + flux_top)\n\n    eta = elem_integral + total_face_integral\n    \n    return [n_elem, n_face, eta]\n\ndef solve():\n    \"\"\"\n    Main function to drive the calculation for the specified test cases.\n    \"\"\"\n    test_cases_p = [0, 1, 3, 5]\n    \n    results = []\n    for p in test_cases_p:\n        result = calculate_eta_for_p(p)\n        # Format the numbers for the final list object\n        # The output format requires a list of lists.\n        # map(str,...) will convert the inner lists to strings.\n        results.append(f\"[{result[0]},{result[1]},{result[2]:.8f}]\")\n    \n    # The final print must be a single string that looks like a list of lists.\n    # The requirement is [[...],[...]], so we join the string-formatted\n    # inner lists with a comma and wrap them in square brackets.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "后验误差估计子的真正威力在于它们能够驱动高效的自适应算法，将计算资源精确地分配到最需要的地方。在这个综合性练习中，您的任务是设计并实现一个 $hp$-自适应标记策略 。您需要利用从残差中提取的信息——特别是内部残差与跳跃残差的相对大小——来智能地决定是进行 $h$-细化（分裂单元）还是 $p$-细化（提升多项式次数）。这个练习是理论与高级算法设计的完美结合，展现了现代数值模拟的核心思想。",
            "id": "3412840",
            "problem": "考虑域 $[0,1]$ 上带齐次狄利克雷边界条件的一维泊松模型问题，由下式给出\n$$\n-\\frac{d^2 u}{dx^2} = f \\quad \\text{in } (0,1), \\qquad u(0)=0, \\quad u(1)=0.\n$$\n在使用网格的每个单元 $K$ 上的分片多项式近似的非连续伽辽金 (DG) 离散化中，离散解 $u_h$ 被允许在单元交界面上是不连续的。对于每个长度为 $h_K$、多项式次数为 $p_K$ 的单元 $K$，定义内部（强）残差\n$$\nR_K(u_h) := f + \\frac{d^2 u_h}{dx^2} \\quad \\text{on } K,\n$$\n以及跨越相邻单元 $K^{-}$ 和 $K^{+}$ 共享的节点 $x_e$ 处的内部面 $e$ 上的跳跃残差\n$$\nJ_e(u_h) := \\left[\\nabla u_h \\cdot n\\right] = \\frac{d u_h}{dx}\\bigg|_{x_e^+} - \\frac{d u_h}{dx}\\bigg|_{x_e^-},\n$$\n在一维情况下，且扩散系数等于 $1$ 时，这与通量跳跃一致。每个单元 $K$ 的一个标准的基于残差的后验估计量是\n$$\n\\eta_K^2 := h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2 \\;+\\; \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, \\| J_e(u_h) \\|_{L^2(e)}^2,\n$$\n其中 $\\mathcal{E}_{\\text{int}}$ 表示内部面的集合，$h_e$ 是与面 $e$ 相关联的特征长度，例如 $h_e := \\tfrac{1}{2}(h_{K^{-}}+h_{K^{+}})$。\n\n您的任务是设计并实现一个由残差 $\\eta_K(h_K,p_K)$ 驱动的 $hp$ 自适应标记策略，该策略为每个单元 $K$ 预测是进行 $h$ 加密（分裂单元）还是 $p$ 加密（提高多项式次数）。该决策必须通过比较跳跃残差 $\\|[\\nabla u_h\\cdot n]\\|$ 和内部残差 $\\|R_K(u_h)\\|$ 的衰减行为来做出。该策略应基于以下基本原则：\n\n- 上述 DG 残差的定义。\n- 多项式空间的逼近性质：对于足够光滑的 $u$，内部残差预计会随着 $p_K$ 的增加而迅速衰减，而跨面的大通量跳跃表明分辨率不足，通常通过 $h$ 加密来改善。\n- 谱系数衰减作为光滑度指标：$u_h$ 在 $K$ 上的高阶模态系数的衰减提供了局部正则性的信号。\n\n实现约束：\n\n- 通过将一个人造精确解 $u$ 局部 $L^2$ 投影到该单元上次数为 $p_K$ 的勒让德多项式空间中，来构造每个单元上的 $u_h$。\n- 通过在 $K$ 上对强残差 $f + \\frac{d^2 u_h}{dx^2}$ 进行数值积分来计算 $\\|R_K(u_h)\\|_{L^2(K)}$。\n- 通过计算 $J_e(u_h)$ 并在每个内部面上计算跳跃残差范数，并将量 $h_e \\, |J_e(u_h)|^2$ 的一半分配给每个相邻单元。\n- 使用 $u_h$ 的勒让德模态系数 $\\{a_\\ell\\}_{\\ell=0}^{p_K}$ 在每个单元 $K$ 上定义一个光滑度指标：使用比率 $|a_{p_K}| / \\sum_{\\ell=0}^{p_K} |a_\\ell|$ 来评估谱尾部的主导性。\n- 根据跳跃残差与内部残差的相对主导性以及光滑度指标，决定每个单元 $K$ 的标记操作：\n  - 如果单元应标记为 $h$ 加密，则输出 $0$。\n  - 如果单元应标记为 $p$ 加密，则输出 $1$。\n  - 如果不需要加密（例如，当 $\\eta_K$ 相对于平均估计量级足够小时），则输出 $2$。\n\n您的程序必须实现以上内容，并将其应用于以下测试套件。在每种情况下，都指定了网格、多项式次数和人造解 $u$（及其对应的右端项 $f = -u''$）。\n\n- 测试用例 1（光滑解，均匀网格）：\n  - 网格节点：$[0, 0.25, 0.5, 0.75, 1]$，因此有 $4$ 个长度为 $h_K = 0.25$ 的单元。\n  - 多项式次数：所有单元上 $p_K = 2$。\n  - 人造解：$u(x) = \\sin(\\pi x)$，因此 $f(x) = \\pi^2 \\sin(\\pi x)$。\n\n- 测试用例 2（网格交界面附近的陡峭变化，均匀网格）：\n  - 网格节点：$[0, 0.25, 0.5, 0.75, 1]$。\n  - 多项式次数：所有单元上 $p_K = 2$。\n  - 人造解：$u(x) = \\arctan(\\beta (x - x_0))$，参数为 $\\beta = 300$ 和 $x_0 = 0.5$，因此\n    $$\n    u'(x) = \\frac{\\beta}{1 + \\beta^2 (x - x_0)^2}, \\qquad\n    u''(x) = -\\frac{2 \\beta^3 (x - x_0)}{\\left(1 + \\beta^2 (x - x_0)^2\\right)^2}, \\qquad\n    f(x) = -u''(x) = \\frac{2 \\beta^3 (x - x_0)}{\\left(1 + \\beta^2 (x - x_0)^2\\right)^2}.\n    $$\n\n- 测试用例 3（混合光滑和局部陡峭特征，非均匀 $p$）：\n  - 网格节点：$[0, 0.2, 0.4, 0.6, 0.8, 1]$，因此有 $5$ 个长度为 $h_K = 0.2$ 的单元。\n  - 多项式次数：$p_K = [1, 3, 2, 1, 4]$。\n  - 人造解：$u(x) = \\sin(3 \\pi x) + 0.1 \\, \\arctan(\\gamma (x - x_1))$，参数为 $\\gamma = 80$ 和 $x_1 = 0.35$。因此，\n    $$\n    u''(x) = -9 \\pi^2 \\sin(3 \\pi x) - \\frac{0.2 \\, \\gamma^3 (x - x_1)}{\\left(1 + \\gamma^2 (x - x_1)^2\\right)^2}, \\qquad\n    f(x) = -u''(x) = 9 \\pi^2 \\sin(3 \\pi x) + \\frac{0.2 \\, \\gamma^3 (x - x_1)}{\\left(1 + \\gamma^2 (x - x_1)^2\\right)^2}.\n    $$\n\n每个单元 $K$ 的标记决策的算法要求：\n\n- 计算内残差范数 $\\|R_K(u_h)\\|_{L^2(K)}$ 以及分配给 $K$ 的聚合跳跃残差范数（分配的面贡献总和的平方根）。\n- 计算谱尾比 $|a_{p_K}| / \\sum_{\\ell=0}^{p_K} |a_\\ell|$。\n- 比较跳跃残差与内部残差的量级以及谱尾比，以决定在增加 $p_K$ 时预期的衰减是否有利（表明 $p$ 加密），或者跳跃项是否占主导地位（表明 $h$ 加密）。如果总估计量 $\\eta_K$ 相对于测试用例中的平均估计量级足够小，则返回不改变的决策。\n\n最终输出规范：\n\n- 对于每个测试用例，返回一个与单元数量等长的整数列表，其中的条目在 $\\{0,1,2\\}$ 中，分别对应于 $h$ 加密、$p$ 加密或不作改变。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个测试用例的列表显示为一个嵌套列表。例如，输出格式应类似于 $[[d_{1,1}, d_{1,2}, \\dots], [d_{2,1}, d_{2,2}, \\dots], [d_{3,1}, d_{3,2}, \\dots]]$，其中 $d_{i,j} \\in \\{0,1,2\\}$。",
            "solution": "该问题要求为应用于泊松方程的一维非连续伽辽金 (DG) 方法设计并实现一个 $hp$ 自适应标记策略。该策略必须为给定网格的每个单元 $K$ 决定是建议进行 $h$ 加密（分裂单元）、$p$ 加密（提高多项式次数）还是不作改变。这个决策将基于从数值解的内部残差和跳跃残差导出的后验误差指示器。\n\n该问题是适定的，并且在偏微分方程数值方法的理论，特别是非连续伽辽金方法的后验误差估计理论中有坚实的科学基础。我将首先概述该策略的理论和算法基础，然后提供实现。\n\n### 1. 理论框架\n\n我们考虑模型问题的 DG 离散化：\n$$\n-\\frac{d^2 u}{dx^2} = f \\quad \\text{in } (0,1), \\qquad u(0)=0, \\quad u(1)=0.\n$$\n数值解 $u_h$ 是在划分域 $[0,1]$ 的网格的每个单元 $K$ 上的次数为 $p_K$ 的分片多项式。DG 方法的一个关键特征是 $u_h$ 不需要在单元交界面上是连续的。这导致了两个主要的误差来源，可以通过残差来衡量：\n\n1.  **内部残差 $R_K(u_h)$**：在每个单元 $K$ 上，偏微分方程的强形式并未被 $u_h$ 精确满足。内部残差定义为：\n    $$\n    R_K(u_h) := f + \\frac{d^2 u_h}{dx^2} \\quad \\text{on } K\n    $$\n    大的内部残差表明多项式 $u_h$ 在单元 $K$ 内部是对真实解 $u$ 的一个较差的近似。\n\n2.  **跳跃残差 $J_e(u_h)$**：在由单元 $K^{-}$ 和 $K^{+}$ 共享的内部面 $e$（一维中的一个节点）处，通量项（这里是 $\\nabla u_h \\cdot n$）可能不连续。跳跃残差衡量了这种不连续性：\n    $$\n    J_e(u_h) := \\left[\\nabla u_h \\cdot n\\right] = \\frac{d u_h}{dx}\\bigg|_{x_e^+} - \\frac{d u_h}{dx}\\bigg|_{x_e^-}\n    $$\n    大的跳跃残差表明解在交界面处没有被网格很好地解析，这通常是由于陡峭的梯度或奇点造成的。\n\n这些残差构成了每个单元 $K$ 的后验误差估计量 $\\eta_K$ 的基础：\n$$\n\\eta_K^2 := h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2 \\;+\\; \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, |J_e(u_h)|^2\n$$\n在这里，$\\| \\cdot \\|_{L^2(e)}$ 在一维中简化为在点 $e$ 处的求值。当对所有单元求和时，这种形式的估计量会重复计算跳跃项。一种定位误差的常见做法是将跳跃贡献的一半分配给两个相邻单元中的每一个。因此，我们将使用一个局部指示器 $\\tilde{\\eta}_K$：\n$$\n\\tilde{\\eta}_K^2 := \\underbrace{h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2}_{\\text{内部贡献}} \\;+\\; \\underbrace{\\frac{1}{2} \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, |J_e(u_h)|^2}_{\\text{跳跃贡献}}\n$$\n\n### 2. $hp$ 标记策略的算法设计\n\n任务的核心是使用 $\\tilde{\\eta}_K$ 和其他可用信息来决定是进行 $h$ 加密还是 $p$ 加密。指导原则如下：\n\n-   **$h$ 加密**对于解析非光滑特征（如陡峭梯度或不连续性）最为有效，这些特征表现为大的跳跃残差。当局部解的正则性较低时，也首选 $h$ 加密，这意味着增加多项式次数会导致收敛缓慢。\n-   **$p$ 加密**对于误差分布在整个单元内的光滑解最为有效。这通常对应于相对于跳跃残差而言较大的内部残差。更高次的多项式可以以指数收敛速度捕捉光滑函数。\n\n为了将其形式化，我们引入一个局部光滑度指标。单元 $K$ 上的数值解 $u_h$ 在勒让德多项式基中表示。模态系数的衰减率提供了局部解正则性的估计。我们将谱光滑度指标 $S_K$ 定义为最高阶系数的量值与所有系数的量值之和的比率：\n$$\nS_K := \\frac{|a_{p_K}|}{\\sum_{\\ell=0}^{p_K} |a_\\ell|}\n$$\n$S_K$ 的小值表示谱衰减快和局部解光滑，而大值则表明解没有被当前的多项式空间很好地表示，这表明需要解析更精细的特征，从而指向 $h$ 加密。\n\n标记策略作为每个单元 $K$ 的多步算法实现：\n\n**步骤 1：构造近似解 $u_h$**\n对于每个具有指定多项式次数 $p_K$ 的单元 $K = [x_i, x_{i+1}]$，局部解 $u_h|_K$ 被构造成人造解 $u$ 的 $L^2(K)$ 投影。通过数值积分计算 $K$ 上勒让德基中的系数 $\\{a_\\ell\\}_{\\ell=0}^{p_K}$。使用从参考区间 $[-1, 1]$ 到 $K$ 的仿射映射 $\\xi \\mapsto x(\\xi)$，系数为：\n$$\na_\\ell = \\frac{\\langle u, \\hat{P}_\\ell \\rangle_{L^2(K)}}{\\| \\hat{P}_\\ell \\|_{L^2(K)}^2} = \\frac{\\int_{-1}^1 u(x(\\xi)) P_\\ell(\\xi) d\\xi}{\\int_{-1}^1 (P_\\ell(\\xi))^2 d\\xi} = \\frac{2\\ell+1}{2} \\int_{-1}^1 u(x(\\xi)) P_\\ell(\\xi) d\\xi\n$$\n其中 $P_\\ell$ 是 $[-1, 1]$ 上的标准勒让德多项式。该积分使用高阶高斯-勒让德积分来近似。有了系数 $\\{a_\\ell\\}$，$K$ 上的 $u_h$ 及其导数就定义好了。\n\n**步骤 2：计算残差和指示器**\n-   内部残差的平方 $L^2$ 范数 $\\|R_K(u_h)\\|_{L^2(K)}^2 = \\int_K (f + u_h'')^2 dx$，使用高斯-勒让德积分计算。\n-   跳跃残差 $J_e(u_h)$ 通过在每个内部节点 $x_e$ 处计算来自左右单元的多项式的导数值来计算。\n-   谱光滑度指标 $S_K$ 从勒让德系数计算得出。\n-   局部误差指示器 $\\tilde{\\eta}_K$ 由内部贡献和跳跃贡献组装而成。\n\n**步骤 3：应用标记逻辑**\n对每个单元 $K_i$ 应用一组基于经验选择但有理论依据的阈值规则：\n1.  **不加密（标记 2）：** 如果一个单元对总误差的贡献可以忽略不计，则不对其进行加密。这是通过将其指示器 $\\tilde{\\eta}_{K_i}$ 与所有单元上的最大指示器值进行比较来决定的：\n    $$\n    \\text{若 } \\tilde{\\eta}_{K_i}  \\theta_{\\text{no-ref}} \\cdot \\max_j(\\tilde{\\eta}_{K_j}), \\quad \\text{则标记为 2}。\n    $$\n    我们使用阈值 $\\theta_{\\text{no-ref}} = 0.1$。\n\n2.  **$h$ 加密 vs. $p$ 加密（标记 0 vs. 1）：** 对于未被标记为不加密的单元，我们在 $h$ 和 $p$ 之间做出决定。\n    -   我们计算跳跃主导比，它衡量跳跃残差项对总局部指示器的相对贡献：\n        $$\n        D_K = \\frac{\\text{跳跃贡献}}{\\tilde{\\eta}_K^2}\n        $$\n    -   我们通过谱指标 $S_K$ 检查光滑度。\n    -   如果跳跃残差占主导地位或局部解被检测为非光滑，则将单元标记为 $h$ 加密（标记 0）：\n        $$\n        \\text{若 } D_K > \\theta_{\\text{jump}} \\text{ 或 } S_K > \\theta_{\\text{spectral}}, \\quad \\text{则标记为 0}。\n        $$\n        我们使用阈值 $\\theta_{\\text{jump}} = 0.5$ 和 $\\theta_{\\text{spectral}} = 0.1$。\n    -   否则，如果内部残差占主导地位且函数看起来是光滑的，则将单元标记为 $p$ 加密（标记 1）。这是需要加密的单元的默认选项。\n\n该算法为指导 $hp$ 自适应网格加密过程提供了一种清晰、果断且合理的方法。它正确地平衡了解析局部尖锐特征的需求与高阶方法对光滑解的效率。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import eval_legendre\nfrom numpy.polynomial.legendre import Legendre, leggauss\n\n# Algorithmic parameters for the marking strategy\nN_QUAD = 30  # Number of quadrature points\nTHETA_NO_REFINEMENT = 0.1  # Threshold for not refining an element\nJUMP_DOMINANCE_THRESHOLD = 0.5  # Threshold for jump residual dominance\nSPECTRAL_DECAY_THRESHOLD = 0.1  # Threshold for slow spectral decay\n\ndef get_l2_projection_coeffs(u_func, interval, p_degree):\n    \"\"\"Computes the coefficients of the L2 projection of u_func onto the space\n    of Legendre polynomials of degree p_degree on the given interval.\"\"\"\n    a, b = interval\n    h = b - a\n    jacobian = h / 2.0\n    \n    # Affine map from reference interval [-1, 1] to element [a, b]\n    map_to_interval = lambda xi: jacobian * xi + (a + b) / 2.0\n    \n    quad_points, quad_weights = leggauss(N_QUAD)\n    \n    coeffs = []\n    for l in range(p_degree + 1):\n        # Integrand for L2 projection coefficient calculation\n        integrand_vals = u_func(map_to_interval(quad_points)) * eval_legendre(l, quad_points)\n        integral_val = np.sum(quad_weights * integrand_vals)\n        \n        # Formula for the l-th coefficient\n        coeff_l = (2 * l + 1) / 2.0 * integral_val\n        coeffs.append(coeff_l)\n        \n    return np.array(coeffs)\n\ndef process_test_case(mesh_nodes, p_degrees, u_func, f_func):\n    \"\"\"\n    Applies the hp-marking strategy to a single test case.\n    \"\"\"\n    num_elements = len(mesh_nodes) - 1\n    elements_data = []\n    \n    quad_points, quad_weights = leggauss(N_QUAD)\n\n    # Step 1: Process each element to compute local properties\n    for i in range(num_elements):\n        interval = (mesh_nodes[i], mesh_nodes[i+1])\n        h_k = interval[1] - interval[0]\n        p_k = p_degrees[i]\n\n        # Compute L2 projection to get u_h\n        coeffs = get_l2_projection_coeffs(u_func, interval, p_k)\n        \n        # Build polynomial representation of u_h and its derivatives\n        u_h_poly = Legendre(coeffs, domain=interval)\n        u_h_poly_d2 = u_h_poly.deriv(2)\n\n        # Compute interior residual norm\n        map_to_interval = lambda xi: (h_k / 2.0) * xi + (interval[0] + interval[1]) / 2.0\n        x_quad = map_to_interval(quad_points)\n        \n        residual_vals = f_func(x_quad) + u_h_poly_d2(x_quad)\n        interior_res_sq_norm = np.sum(quad_weights * (residual_vals**2)) * (h_k / 2.0)\n\n        # Compute spectral smoothness indicator\n        if np.sum(np.abs(coeffs)) > 1e-15:\n            spectral_ratio = np.abs(coeffs[-1]) / np.sum(np.abs(coeffs))\n        else:\n            spectral_ratio = 0.0\n\n        elements_data.append({\n            'interval': interval,\n            'h_k': h_k,\n            'p_k': p_k,\n            'coeffs': coeffs,\n            'u_h_poly_d1': u_h_poly.deriv(1),\n            'interior_res_contrib': h_k**2 * interior_res_sq_norm,\n            'spectral_ratio': spectral_ratio,\n            'jump_res_contrib': 0.0,\n        })\n\n    # Step 2: Compute jump residuals at interior faces\n    for i in range(1, num_elements):\n        # Face at x = mesh_nodes[i]\n        face_loc = mesh_nodes[i]\n        \n        # Element K- to the left\n        elem_minus = elements_data[i-1]\n        # Element K+ to the right\n        elem_plus = elements_data[i]\n        \n        grad_uh_minus = elem_minus['u_h_poly_d1'](face_loc)\n        grad_uh_plus = elem_plus['u_h_poly_d1'](face_loc)\n        \n        jump = grad_uh_plus - grad_uh_minus\n        \n        h_e = 0.5 * (elem_minus['h_k'] + elem_plus['h_k'])\n        \n        jump_term = h_e * jump**2\n        \n        # Distribute jump contribution to neighboring elements\n        elem_minus['jump_res_contrib'] += 0.5 * jump_term\n        elem_plus['jump_res_contrib'] += 0.5 * jump_term\n\n    # Step 3: Finalize indicators and apply marking logic\n    eta_k_list = []\n    for data in elements_data:\n        eta_k_sq = data['interior_res_contrib'] + data['jump_res_contrib']\n        eta_k_list.append(np.sqrt(eta_k_sq))\n    \n    eta_max = np.max(eta_k_list) if eta_k_list else 0.0\n    marks = []\n\n    for i in range(num_elements):\n        data = elements_data[i]\n        eta_k = eta_k_list[i]\n        \n        # Rule 1: No refinement if error is small\n        if eta_k  THETA_NO_REFINEMENT * eta_max:\n            marks.append(2)\n            continue\n            \n        # Rule 2: h- vs p-refinement for elements with significant error\n        total_contrib = data['interior_res_contrib'] + data['jump_res_contrib']\n        if total_contrib > 1e-15:\n            jump_dominance_ratio = data['jump_res_contrib'] / total_contrib\n        else:\n            jump_dominance_ratio = 0.0\n\n        spectral_ratio = data['spectral_ratio']\n\n        if (jump_dominance_ratio > JUMP_DOMINANCE_THRESHOLD or \n            spectral_ratio > SPECTRAL_DECAY_THRESHOLD):\n            marks.append(0)  # h-refinement\n        else:\n            marks.append(1)  # p-refinement\n            \n    return marks\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = []\n\n    # Test Case 1: Smooth solution\n    f1_u = lambda x: np.sin(np.pi * x)\n    f1_f = lambda x: np.pi**2 * np.sin(np.pi * x)\n    case1 = {\n        'mesh_nodes': np.array([0, 0.25, 0.5, 0.75, 1]),\n        'p_degrees': np.array([2, 2, 2, 2]),\n        'u_func': f1_u,\n        'f_func': f1_f\n    }\n    test_cases.append(case1)\n\n    # Test Case 2: Steep gradient\n    beta, x0 = 300.0, 0.5\n    f2_u = lambda x: np.arctan(beta * (x - x0))\n    f2_f = lambda x: (2 * beta**3 * (x - x0)) / (1 + beta**2 * (x - x0)**2)**2\n    case2 = {\n        'mesh_nodes': np.array([0, 0.25, 0.5, 0.75, 1]),\n        'p_degrees': np.array([2, 2, 2, 2]),\n        'u_func': f2_u,\n        'f_func': f2_f\n    }\n    test_cases.append(case2)\n    \n    # Test Case 3: Mixed smooth and steep\n    gamma, x1 = 80.0, 0.35\n    f3_u = lambda x: np.sin(3 * np.pi * x) + 0.1 * np.arctan(gamma * (x - x1))\n    f3_f = lambda x: 9 * np.pi**2 * np.sin(3 * np.pi * x) + (0.2 * gamma**3 * (x - x1)) / (1 + gamma**2 * (x - x1)**2)**2\n    case3 = {\n        'mesh_nodes': np.array([0, 0.2, 0.4, 0.6, 0.8, 1]),\n        'p_degrees': np.array([1, 3, 2, 1, 4]),\n        'u_func': f3_u,\n        'f_func': f3_f\n    }\n    test_cases.append(case3)\n\n    all_results = []\n    for case in test_cases:\n        result = process_test_case(case['mesh_nodes'], case['p_degrees'], case['u_func'], case['f_func'])\n        all_results.append(result)\n\n    print(all_results)\n\nsolve()\n```"
        }
    ]
}