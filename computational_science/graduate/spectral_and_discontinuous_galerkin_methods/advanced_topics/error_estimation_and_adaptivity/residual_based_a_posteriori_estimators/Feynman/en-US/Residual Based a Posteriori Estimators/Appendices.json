{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration, we will start with the fundamental building blocks of a residual-based a posteriori error indicator. This first exercise breaks down the estimator into its core components: the interior residual, which measures how well the equation is satisfied inside an element, and the jump residuals, which measure the mismatch in the solution's flux across element boundaries. By performing a direct calculation, you will gain a concrete understanding of how these distinct sources of error are weighted by local mesh parameters and combined to form a single, quantitative measure of local error, which is the cornerstone of adaptive methods .",
            "id": "3514528",
            "problem": "Consider a stationary scalar diffusion model representative of a single-field subproblem within a multiphysics coupled simulation, governed by the strong form $-\\nabla \\cdot (\\kappa \\nabla u) = f$ on a bounded polygonal domain, with a conforming Finite Element Method (FEM) approximation $u_h \\in V_h$ on a two-dimensional mesh. In residual-based a posteriori error estimation for adaptive mesh refinement, the elementwise indicator is constructed from the element interior residual and the flux jump residuals across its edges. Let an element $K$ be shape-regular, with diameter $h_K$ and edge lengths $\\{h_{e}\\}_{e \\subset \\partial K}$, and let the elementwise interior residual magnitude be $r_K$ and the edgewise flux jump magnitudes be $\\{j_e\\}_{e \\subset \\partial K}$. The mesh quality metric $h_K$ and the edge lengths $\\{h_e\\}$ enter the scaling of the indicator through standard inverse and trace inequalities on shape-regular meshes.\n\nAssume the following data for a single triangular element $K$: the diameter is $h_K = 0.1$, the element interior residual magnitude is $r_K = 5$, and its three edges have flux jump magnitudes $(3, 1, 2)$ on edges of lengths $(0.1, 0.1, 0.141)$, respectively. Using the canonical residual-based scaling implied by the weak form and integration-by-parts residual representation, compute the element indicator $\\eta_K$ for $K$. Express your final answer as a single simplified exact expression. No rounding is required.",
            "solution": "The problem statement is evaluated as valid. It is scientifically grounded within the established theory of a posteriori error estimation for the Finite Element Method (FEM), is well-posed with a complete and consistent set of givens, and is expressed in objective, formal language. There are no violations of fundamental principles, contradictions, or ambiguities. We may therefore proceed with the solution.\n\nThe problem asks for the computation of a local, residual-based a posteriori error indicator, denoted as $\\eta_K$, for a single triangular element $K$ in a two-dimensional domain. The underlying physics is described by a stationary scalar diffusion equation, $-\\nabla \\cdot (\\kappa \\nabla u) = f$, where $u$ is the scalar field, $\\kappa$ is the diffusion coefficient, and $f$ is a source term. The approximate solution obtained via FEM is denoted by $u_h$.\n\nThe \"canonical residual-based scaling\" for the error indicator $\\eta_K$ is derived from the weak form of the residual equation and the application of standard trace and inverse inequalities on a shape-regular mesh. The squared indicator $\\eta_K^2$ is composed of two main contributions: one from the residual within the element's interior and one from the jumps in flux across the element's edges. The general form is:\n$$\n\\eta_K^2 = C_{int}^2 h_K^2 \\|R_K\\|_{L_2(K)}^2 + \\sum_{e \\in \\partial K} C_{edge}^2 h_e \\|J_e\\|_{L_2(e)}^2\n$$\nHere, $h_K$ is the diameter of element $K$, and $\\{h_e\\}$ are the lengths of its edges. The term $R_K = f + \\nabla \\cdot (\\kappa \\nabla u_h)$ is the interior residual, and $\\|R_K\\|_{L_2(K)}$ is its $L_2$-norm over the element $K$. The term $J_e = \\llbracket \\kappa \\nabla u_h \\cdot \\mathbf{n} \\rrbracket$ represents the jump of the normal component of the flux across an edge $e$, and $\\|J_e\\|_{L_2(e)}$ is its $L_2$-norm over the edge $e$. The constants $C_{int}$ and $C_{edge}$ depend on interpolation theory and element shape regularity but are typically taken as $1$ in the standard definition of the indicator, which is implied by the term \"canonical\".\n\nThe problem provides the following data, which we map to the terms in the formula:\n- Element diameter: $h_K = 0.1$.\n- Magnitude of the element interior residual ($L_2$-norm): $r_K = \\|R_K\\|_{L_2(K)} = 5$.\n- The element is a triangle, hence it has three edges, indexed here by $i \\in \\{1, 2, 3\\}$.\n- Edge lengths: $h_{e_1} = 0.1$, $h_{e_2} = 0.1$, and $h_{e_3} = 0.141$.\n- Magnitudes of the flux jumps ($L_2$-norms) on the corresponding edges: $j_{e_1} = \\|J_{e_1}\\|_{L_2(e_1)} = 3$, $j_{e_2} = \\|J_{e_2}\\|_{L_2(e_2)} = 1$, and $j_{e_3} = \\|J_{e_3}\\|_{L_2(e_3)} = 2$.\n\nWith the constants $C_{int}$ and $C_{edge}$ set to $1$, the formula for the squared indicator becomes:\n$$\n\\eta_K^2 = h_K^2 r_K^2 + h_{e_1} j_{e_1}^2 + h_{e_2} j_{e_2}^2 + h_{e_3} j_{e_3}^2\n$$\nWe now substitute the given numerical values into this expression. To maintain exactness as requested, we will perform the calculation using fractions.\n$h_K = \\frac{1}{10}$, $r_K = 5$\n$h_{e_1} = \\frac{1}{10}$, $j_{e_1} = 3$\n$h_{e_2} = \\frac{1}{10}$, $j_{e_2} = 1$\n$h_{e_3} = \\frac{141}{1000}$, $j_{e_3} = 2$\n\nThe contribution from the interior residual is:\n$$\nh_K^2 r_K^2 = \\left(\\frac{1}{10}\\right)^2 (5)^2 = \\frac{1}{100} \\times 25 = \\frac{25}{100} = \\frac{1}{4}\n$$\nThe contributions from the flux jumps across the three edges are:\n$$\nh_{e_1} j_{e_1}^2 = \\frac{1}{10} \\times (3)^2 = \\frac{9}{10}\n$$\n$$\nh_{e_2} j_{e_2}^2 = \\frac{1}{10} \\times (1)^2 = \\frac{1}{10}\n$$\n$$\nh_{e_3} j_{e_3}^2 = \\frac{141}{1000} \\times (2)^2 = \\frac{141}{1000} \\times 4 = \\frac{564}{1000} = \\frac{141}{250}\n$$\nNow, we sum these components to find $\\eta_K^2$:\n$$\n\\eta_K^2 = \\frac{1}{4} + \\frac{9}{10} + \\frac{1}{10} + \\frac{141}{250}\n$$\nCombining the terms with common denominators first:\n$$\n\\eta_K^2 = \\frac{1}{4} + \\left(\\frac{9}{10} + \\frac{1}{10}\\right) + \\frac{141}{250} = \\frac{1}{4} + 1 + \\frac{141}{250} = \\frac{5}{4} + \\frac{141}{250}\n$$\nTo sum these fractions, we find a common denominator, which is $500$:\n$$\n\\eta_K^2 = \\frac{5 \\times 125}{4 \\times 125} + \\frac{141 \\times 2}{250 \\times 2} = \\frac{625}{500} + \\frac{282}{500} = \\frac{625 + 282}{500} = \\frac{907}{500}\n$$\nThe problem asks for the element indicator $\\eta_K$, which is the square root of this value:\n$$\n\\eta_K = \\sqrt{\\frac{907}{500}}\n$$\nTo provide a simplified exact expression, we can rationalize the denominator:\n$$\n\\eta_K = \\frac{\\sqrt{907}}{\\sqrt{500}} = \\frac{\\sqrt{907}}{\\sqrt{100 \\times 5}} = \\frac{\\sqrt{907}}{10\\sqrt{5}}\n$$\nMultiplying the numerator and denominator by $\\sqrt{5}$:\n$$\n\\eta_K = \\frac{\\sqrt{907} \\times \\sqrt{5}}{10\\sqrt{5} \\times \\sqrt{5}} = \\frac{\\sqrt{907 \\times 5}}{10 \\times 5} = \\frac{\\sqrt{4535}}{50}\n$$\nThe number $907$ is a prime number, so the radical $\\sqrt{4535}$ cannot be simplified further. This is the final exact expression for the element indicator.",
            "answer": "$$\\boxed{\\frac{\\sqrt{4535}}{50}}$$"
        },
        {
            "introduction": "Building on the foundational calculation, we now investigate the dynamic behavior of the error estimator within the framework of the Symmetric Interior Penalty Discontinuous Galerkin (SIPG) method. A key feature of SIPG methods is the penalty parameter, denoted by $\\sigma$, which enforces continuity weakly and is critical for the method's stability. This practice guides you to programmatically explore how changing $\\sigma$ affects the different components of the residual estimator, particularly the term associated with the jump in the solution itself, providing deep insight into the practical consequences of tuning this parameter for controlling numerical error .",
            "id": "3412868",
            "problem": "Consider the one-dimensional model elliptic boundary value problem on the interval $[0,1]$: find $u:[0,1]\\to\\mathbb{R}$ such that $-u'' = f$ in $(0,1)$ with homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(1)=0$. Let the exact solution be $u(x) = \\sin(\\pi x)$ so that $f(x) = \\pi^2 \\sin(\\pi x)$. On a fixed, uniform mesh with $N$ elements and mesh size $h = 1/N$, consider a symmetric interior penalty Discontinuous Galerkin (DG) method with piecewise linear trial space and penalty parameter $\\sigma > 0$.\n\nDefine the piecewise linear approximate solution $u_h$ element-wise on each element $K_i = [x_i, x_{i+1}]$, with nodes $x_i = i h$ for $i = 0,1,\\dots,N$, by the following rule: for a given shift amplitude $\\delta \\ge 0$ and sign pattern $s_i = (-1)^i$, let $u_h$ be the unique linear function on $K_i$ that interpolates the values $u_h(x_i) = u(x_i) + \\delta s_i$ and $u_h(x_{i+1}) = u(x_{i+1}) + \\delta s_i$. This construction produces a discontinuous function across faces if $\\delta \\ne 0$, and a continuous function across faces if $\\delta = 0$, while preserving piecewise linearity on each element.\n\nUsing the residual-based a posteriori estimator framework for the symmetric interior penalty DG method, define:\n- the interior (element) residual contribution on each element $K$ as\n$$\n\\eta_K^2 := h^2 \\int_{K} \\big(f(x) + u_h''(x)\\big)^2 \\, dx,\n$$\nand,\n- the face (jump) residual contribution on each face $e$ as follows. For an interior face $e = \\{x_i\\}$, $i=1,\\dots,N-1$, define the jumps\n$$\n[u_h](x_i) := \\lim_{x\\to x_i^+} u_h(x) - \\lim_{x\\to x_i^-} u_h(x), \\quad\n[u_h'](x_i) := \\lim_{x\\to x_i^+} u_h'(x) - \\lim_{x\\to x_i^-} u_h'(x),\n$$\nand set\n$$\n\\eta_e^2 := h \\big([u_h'](x_i)\\big)^2 + \\frac{\\sigma}{h} \\big([u_h](x_i)\\big)^2.\n$$\nFor the boundary faces at $x=0$ and $x=1$, with homogeneous Dirichlet boundary conditions, define the contributions by replacing the exterior traces with the boundary data $u=0$, that is\n$$\n\\eta_{x=0}^2 := h \\big(u_h'(0)\\big)^2 + \\frac{\\sigma}{h} \\big(u_h(0)\\big)^2, \\quad\n\\eta_{x=1}^2 := h \\big(u_h'(1)\\big)^2 + \\frac{\\sigma}{h} \\big(u_h(1)\\big)^2.\n$$\n\nGiven that $u_h$ is piecewise linear, note that $u_h''(x)=0$ for all $x$ in the interior of each element. Therefore, the interior residual reduces to integrals involving $f(x)$ only. The jump residuals involve both jumps in the derivative $u_h'$ and jumps in the function values $u_h$ at faces, the latter scaled by the penalty parameter $\\sigma$.\n\nFor a fixed mesh and fixed $(N,\\delta)$, define the total interior residual and total jump residual by\n$$\nI := \\sum_{K} \\eta_K^2, \\quad J(\\sigma) := \\sum_{e} \\eta_e^2,\n$$\nwhere the sum over faces $e$ includes both interior faces and the two boundary faces.\n\nYour task is to write a program that, for each specified test case $(N,\\delta,\\sigma)$ below:\n- constructs $u_h$ on the uniform mesh as described,\n- computes $I$ and $J(\\sigma)$,\n- computes the ratios\n$$\nR(\\sigma) := \\frac{J(\\sigma)}{I}, \\qquad R(2\\sigma) := \\frac{J(2\\sigma)}{I},\n$$\nand then reports the effect of doubling the penalty parameter by the multiplicative change\n$$\nE := \\frac{R(2\\sigma)}{R(\\sigma)}.\n$$\n\nUse numerical quadrature of at least $16$-point Gauss-Legendre on each element to approximate the interior integrals $\\int_K f(x)^2\\,dx$ accurately. Angles are not involved. All quantities are dimensionless in this formulation. The final answers for each test case must be real numbers.\n\nTest Suite:\n- Case $1$: $(N,\\delta,\\sigma) = (4, 0.05, 10)$.\n- Case $2$: $(N,\\delta,\\sigma) = (8, 0.05, 10)$.\n- Case $3$: $(N,\\delta,\\sigma) = (8, 0, 10)$.\n- Case $4$: $(N,\\delta,\\sigma) = (4, 0.2, 1)$.\n- Case $5$: $(N,\\delta,\\sigma) = (16, 0.05, 5)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each entry is a list of three floats $[R(\\sigma),R(2\\sigma),E]$ for the corresponding test case, in the same order as the test suite. For example, the output should look like\n$$\n\\big[ [R_1(\\sigma),R_1(2\\sigma),E_1], [R_2(\\sigma),R_2(2\\sigma),E_2], \\dots \\big].\n$$",
            "solution": "We begin from the second-order elliptic boundary value problem $-u''=f$ on the interval $[0,1]$ with homogeneous Dirichlet boundary conditions. For the symmetric interior penalty Discontinuous Galerkin (DG) method with piecewise linear trial and test spaces on a uniform partition of $[0,1]$ into $N$ elements of size $h=1/N$, the method balances interior consistency and continuity through jump stabilization terms controlled by the penalty parameter $\\sigma>0$.\n\nA residual-based a posteriori estimator decomposes into elementwise (interior) contributions that measure the local equilibrium of the discrete solution with the data, and facewise (jump) contributions that measure interelement mismatches in both the solution and its flux. In the canonical DG residual estimator for elliptic problems, the interior contributions read\n$$\n\\eta_K^2 = h^2 \\int_K \\big(f(x) + u_h''(x)\\big)^2\\,dx,\n$$\nwhich, for piecewise linear $u_h$, simplify because $u_h''(x)=0$ on each element interior, yielding\n$$\n\\eta_K^2 = h^2 \\int_K f(x)^2\\,dx.\n$$\nThe face contributions on interior faces $e=\\{x_i\\}$ for $i=1,\\dots,N-1$ embody jumps of the derivative and of the solution, scaled respectively by $h$ and by $\\sigma/h$:\n$$\n\\eta_e^2 = h \\big([u_h'](x_i)\\big)^2 + \\frac{\\sigma}{h} \\big([u_h](x_i)\\big)^2,\n$$\nand on boundary faces $x=0$ and $x=1$ with Dirichlet data $u=0$, the analogous terms are\n$$\n\\eta_{x=0}^2 = h \\big(u_h'(0)\\big)^2 + \\frac{\\sigma}{h}\\big(u_h(0)\\big)^2, \\qquad\n\\eta_{x=1}^2 = h \\big(u_h'(1)\\big)^2 + \\frac{\\sigma}{h}\\big(u_h(1)\\big)^2.\n$$\n\nTo study the effect of changing the penalty parameter $\\sigma$ while keeping the mesh fixed, we construct a piecewise linear $u_h$ that isolates the roles of derivative jumps versus function jumps. Consider a uniform partition with nodes $x_i = i h$ for $i=0,1,\\dots,N$, where $h=1/N$. Define on each element $K_i=[x_i,x_{i+1}]$ a linear $u_h$ that interpolates the values $u_h(x_i) = u(x_i) + \\delta s_i$ and $u_h(x_{i+1}) = u(x_{i+1}) + \\delta s_i$, with $s_i = (-1)^i$. This construction means the slope on element $K_{i-1}$ is $u_h'(x)|_{K_{i-1}} = (u_h(x_i)-u_h(x_{i-1}))/h = (u(x_i)+\\delta s_{i-1} - (u(x_{i-1}) + \\delta s_{i-1}))/h = (u(x_i)-u(x_{i-1}))/h$. The slope on element $K_i$ is $u_h'(x)|_{K_i} = (u_h(x_{i+1})-u_h(x_i))/h = (u(x_{i+1})+\\delta s_i - (u(x_i) + \\delta s_i))/h = (u(x_{i+1})-u(x_i))/h$.\n\nThe function jump across an interior face at $x_i$ becomes\n$$\n[u_h](x_i) = u_h(x_i^+) - u_h(x_i^-) = \\big(u(x_i) + \\delta s_i\\big) - \\big(u(x_i) + \\delta s_{i-1}\\big) = \\delta \\big(s_i - s_{i-1}\\big),\n$$\nand the derivative jump across $x_i$ is\n$$\n[u_h'](x_i) = u_h'(x_i^+) - u_h'(x_i^-) = \\frac{u(x_{i+1}) - u(x_i)}{h} - \\frac{u(x_i) - u(x_{i-1})}{h}.\n$$\nAt the boundaries, $u_h(0) = u(0) + \\delta s_0$ and $u_h(1) = u(1) + \\delta s_{N-1}$ (using the definition for $K_{N-1}$), while $u_h'(0)$ and $u_h'(1)$ are the slopes on the first and the last elements, respectively.\n\nWith these definitions, the total interior residual\n$$\nI = \\sum_{i=0}^{N-1} h^2 \\int_{x_i}^{x_{i+1}} f(x)^2\\,dx\n$$\ndepends only on the data $f$ (here $f(x)=\\pi^2\\sin(\\pi x)$). The total jump residual\n$$\nJ(\\sigma) = \\sum_{i=1}^{N-1} \\left( h \\big([u_h'](x_i)\\big)^2 + \\frac{\\sigma}{h} \\big([u_h](x_i)\\big)^2 \\right)\n+ \\left( h \\big(u_h'(0)\\big)^2 + \\frac{\\sigma}{h} \\big(u_h(0)\\big)^2 \\right)\n+ \\left( h \\big(u_h'(1)\\big)^2 + \\frac{\\sigma}{h} \\big(u_h(1)\\big)^2 \\right)\n$$\ncomprises two parts: a component due to derivative jumps scaled by $h$, and a component due to function jumps scaled by $\\sigma/h$. The derivative jump component is unaffected by $\\sigma$, whereas the function jump component grows linearly with $\\sigma$. Therefore, doubling $\\sigma$ leaves the derivative jump contributions invariant and doubles the function jump contributions, which in turn may alter the ratio of the total jump residual to the interior residual:\n$$\nR(\\sigma) := \\frac{J(\\sigma)}{I}, \\qquad R(2\\sigma) := \\frac{J(2\\sigma)}{I}, \\qquad E := \\frac{R(2\\sigma)}{R(\\sigma)}.\n$$\nIf the function jumps vanish (for example, if $\\delta=0$ under the present construction), then $J(\\sigma)$ contains only derivative jump contributions, and doubling $\\sigma$ has no effect, yielding $E=1$. When function jumps are present ($\\delta>0$), the term scaled by $\\sigma$ contributes positively, and doubling $\\sigma$ amplifies the jump residual proportionally to the magnitude of the function jumps, increasing $R$ accordingly.\n\nAlgorithmic procedure:\n- For each test case $(N,\\delta,\\sigma)$, set $h=1/N$ and generate nodes $x_i=i h$.\n- Compute the slopes $b_i$ on each element based on the exact solution values: $b_i := \\frac{u(x_{i+1}) - u(x_i)}{h}$ for $i=0,\\dots,N-1$, where $u(x)=\\sin(\\pi x)$.\n- Compute interior derivative jumps at faces $x_i$ for $i=1,\\dots,N-1$ as $[u_h'](x_i) = b_i - b_{i-1}$.\n- Compute function jumps at interior faces as $[u_h](x_i) = \\delta\\big(s_i - s_{i-1}\\big)$ with $s_i=(-1)^i$.\n- Compute boundary contributions using $u_h(0) = u(0) + \\delta s_0$, $u_h(1) = u(1) + \\delta s_{N-1}$ and $u_h'(0)=b_0$, $u_h'(1)=b_{N-1}$.\n- Assemble $J(\\sigma)$ and $J(2\\sigma)$ using the specified formulas.\n- Compute $I$ via numerical quadrature with at least $16$-point Gauss-Legendre per element for $\\int_{x_i}^{x_{i+1}} f(x)^2\\,dx$ and accumulate to obtain the total interior residual.\n- Form the ratios $R(\\sigma)$ and $R(2\\sigma)$ and the effect $E$.\n\nThe program then applies this to the test suite:\n- Case $1$: $(N,\\delta,\\sigma) = (4, 0.05, 10)$,\n- Case $2$: $(N,\\delta,\\sigma) = (8, 0.05, 10)$,\n- Case $3$: $(N,\\delta,\\sigma) = (8, 0, 10)$,\n- Case $4$: $(N,\\delta,\\sigma) = (4, 0.2, 1)$,\n- Case $5$: $(N,\\delta,\\sigma) = (16, 0.05, 5)$,\n\nand outputs the list of triples $[R(\\sigma),R(2\\sigma),E]$ for each case in the required format.\n\nThis construction respects the foundational principles of DG residual estimators: interior equilibrium measured by the data residual and interelement stability enforced by jump control. It isolates the dependence on the penalty parameter $\\sigma$ to the solution jump contributions, enabling a clear quantitative assessment of how doubling $\\sigma$ affects the relative size of jump versus interior residuals on a fixed mesh.",
            "answer": "```python\n# Python 3.12 program to compute the effect of doubling sigma\n# on the relative sizes of jump versus interior residuals\n# for a 1D SIPG DG residual estimator on a fixed mesh.\n\nimport numpy as np\n\ndef u_exact(x):\n    return np.sin(np.pi * x)\n\ndef f_rhs(x):\n    # f = pi^2 sin(pi x)\n    return (np.pi**2) * np.sin(np.pi * x)\n\ndef gauss_legendre_integral_on_interval(func, a, b, npts=16):\n    # Integrate func over [a,b] using npts-point Gauss-Legendre quadrature\n    xi, wi = np.polynomial.legendre.leggauss(npts)  # nodes and weights on [-1,1]\n    # Map to [a,b]: x = 0.5*(b-a)*xi + 0.5*(a+b)\n    x = 0.5*(b - a) * xi + 0.5*(a + b)\n    w = 0.5*(b - a) * wi\n    return np.sum(func(x) * w)\n\ndef compute_estimator_ratios(N, delta, sigma):\n    h = 1.0 / N\n    # Nodes\n    x = np.linspace(0.0, 1.0, N + 1)\n    # Signs s_i = (-1)^i for shift on K_i\n    s = np.array([(-1)**i for i in range(N)])\n\n    # Piecewise linear interpolant u_h constructed from u\n    # Nodal values for u_h on K_{i-1} are u(x_{i-1})+\\delta s_{i-1} and u(x_i)+\\delta s_{i-1}\n    # Nodal values for u_h on K_i are u(x_i)+\\delta s_i and u(x_{i+1})+\\delta s_i\n    u_vals = u_exact(x)\n    \n    # Slopes b_i on each element [x_i, x_{i+1}]\n    # slope on K_i: ( (u(x_{i+1})+\\delta s_i) - (u(x_i)+\\delta s_i) ) / h = (u(x_{i+1}) - u(x_i)) / h\n    b = (u_vals[1:] - u_vals[:-1]) / h  # length N\n\n    # Interior residual I = sum h^2 * \\int_K f(x)^2 dx\n    I = 0.0\n    for i in range(N):\n        a = x[i]\n        bnd = x[i+1]\n        integral_f2 = gauss_legendre_integral_on_interval(lambda t: f_rhs(t)**2, a, bnd, npts=16)\n        I += (h**2) * integral_f2\n\n    # Jump residual J(sigma)\n    J_sigma = 0.0\n    # Interior faces: derivative jump and function jump\n    for i in range(1, N):\n        # Derivative jump at x_i: [u_h'] = u_h'(x_i^+) - u_h'(x_i^-) = b_i - b_{i-1}\n        jump_du = b[i] - b[i-1]\n        # Function jump at x_i: [u_h] = u_h(x_i^+) - u_h(x_i^-)\n        # u_h(x_i^+) is from K_i, shift s_i. u_h(x_i^+) = u(x_i) + \\delta s_i\n        # u_h(x_i^-) is from K_{i-1}, shift s_{i-1}. u_h(x_i^-) = u(x_i) + \\delta s_{i-1}\n        # [u_h](x_i) = delta * (s_i - s_{i-1})\n        jump_u = delta * (s[i] - s[i-1])\n        J_sigma += h * (jump_du**2) + (sigma / h) * (jump_u**2)\n\n    # Boundary faces contributions with Dirichlet u=0:\n    # Left boundary x=0:\n    # u_h(0) = u(0) + delta*s_0 (from K_0). u_h'(0) = b_0\n    u_h_0 = u_vals[0] + delta * s[0]\n    du_h_0 = b[0]\n    J_sigma += h * (du_h_0**2) + (sigma / h) * (u_h_0**2)\n    # Right boundary x=1:\n    # u_h(1) = u(1) + delta*s_{N-1} (from K_{N-1}). u_h'(1) = b_{N-1}\n    u_h_1 = u_vals[-1] + delta * s[-1]\n    du_h_1 = b[-1]\n    J_sigma += h * (du_h_1**2) + (sigma / h) * (u_h_1**2)\n\n    # J(2*sigma) differs only in the function jump scaling\n    J_2sigma = 0.0\n    # Interior faces\n    for i in range(1, N):\n        jump_du = b[i] - b[i-1]\n        jump_u = delta * (s[i] - s[i-1])\n        J_2sigma += h * (jump_du**2) + ((2.0 * sigma) / h) * (jump_u**2)\n    # Boundary faces\n    J_2sigma += h * (du_h_0**2) + ((2.0 * sigma) / h) * (u_h_0**2)\n    J_2sigma += h * (du_h_1**2) + ((2.0 * sigma) / h) * (u_h_1**2)\n\n    # Ratios\n    R_sigma = J_sigma / I\n    R_2sigma = J_2sigma / I\n    E = R_2sigma / R_sigma if R_sigma != 0.0 else np.inf\n    return R_sigma, R_2sigma, E\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (N, delta, sigma).\n    test_cases = [\n        (4, 0.05, 10.0),\n        (8, 0.05, 10.0),\n        (8, 0.0, 10.0),\n        (4, 0.2, 1.0),\n        (16, 0.05, 5.0),\n    ]\n\n    results = []\n    for N, delta, sigma in test_cases:\n        R_sigma, R_2sigma, E = compute_estimator_ratios(N, delta, sigma)\n        results.append([R_sigma, R_2sigma, E])\n\n    # Final print statement in the exact required format.\n    # Single line: list of lists with three floats each.\n    # Use default string formatting for floats.\n    print(f\"[{','.join(str(item) for item in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Our final practice demonstrates the ultimate purpose of a posteriori error estimators: to intelligently guide an adaptive simulation for maximum efficiency and accuracy. Here, you will design an $hp$-adaptive marking strategy, a sophisticated algorithm that decides whether to refine the mesh by splitting an element (h-refinement) or by increasing the polynomial degree of the approximation (p-refinement). This decision is based on the nature of the local error, which you will diagnose by comparing the relative sizes of the interior and jump residual contributions, a powerful heuristic that lies at the heart of modern adaptive solvers .",
            "id": "3412840",
            "problem": "Consider the one-dimensional Poisson model problem on the domain $[0,1]$ with homogeneous Dirichlet boundary conditions, given by\n$$\n-\\frac{d^2 u}{dx^2} = f \\quad \\text{in } (0,1), \\qquad u(0)=0, \\quad u(1)=0.\n$$\nIn a Discontinuous Galerkin (DG) discretization with piecewise polynomial approximation on each element $K$ of the mesh, the discrete solution $u_h$ is allowed to be discontinuous across element interfaces. For each element $K$ with length $h_K$ and polynomial degree $p_K$, define the interior (strong) residual\n$$\nR_K(u_h) := f + \\frac{d^2 u_h}{dx^2} \\quad \\text{on } K,\n$$\nand the jump residual across an interior face $e$ located at a node $x_e$ shared by neighboring elements $K^{-}$ and $K^{+}$,\n$$\nJ_e(u_h) := \\llbracket \\nabla u_h \\cdot \\mathbf{n} \\rrbracket = \\frac{d u_h}{dx}\\bigg|_{x_e^+} - \\frac{d u_h}{dx}\\bigg|_{x_e^-},\n$$\nwhich, in one dimension and with diffusion coefficient equal to $1$, coincides with the flux jump. A standard residual-based a posteriori estimator for each element $K$ is the quantity\n$$\n\\eta_K^2 := h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2 \\;+\\; \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, \\| J_e(u_h) \\|_{L^2(e)}^2,\n$$\nwhere $\\mathcal{E}_{\\text{int}}$ denotes the set of interior faces, and $h_e$ is a characteristic length associated with the face $e$, for instance $h_e := \\tfrac{1}{2}(h_{K^{-}}+h_{K^{+}})$.\n\nYour task is to design and implement an $hp$-adaptive marking strategy driven by residuals $\\eta_K(h_K,p_K)$ that predicts, for each element $K$, whether to refine $h$ (split the element) or increase $p$ (raise the polynomial degree). The decision must be made by comparing the decay behavior of jump residuals $\\|\\llbracket \\nabla u_h\\cdot \\mathbf{n} \\rrbracket\\|$ and interior residuals $\\|R_K(u_h)\\|$. The strategy should be grounded in the following fundamental bases:\n\n- The DG residual definitions above.\n- The approximation properties of polynomial spaces: for sufficiently smooth $u$, the interior residual is expected to decay rapidly with increasing $p_K$, while large jumps in flux across faces indicate under-resolution that typically benefits from $h$-refinement.\n- Spectral coefficient decay as a smoothness indicator: the decay of higher-order modal coefficients of $u_h$ on $K$ provides a signal of local regularity.\n\nImplementation constraints:\n\n- Construct $u_h$ on each element by the local $L^2$-projection of a manufactured exact solution $u$ onto the space of Legendre polynomials of degree $p_K$ on that element.\n- Compute $\\|R_K(u_h)\\|_{L^2(K)}$ by numerical quadrature of the strong residual $f + \\frac{d^2 u_h}{dx^2}$ on $K$.\n- Compute the jump residual norm on each interior face by evaluating $J_e(u_h)$ and assigning half of the quantity $h_e \\, |J_e(u_h)|^2$ to each neighboring element.\n- Define a smoothness indicator on each element $K$ using the Legendre modal coefficients $\\{a_\\ell\\}_{\\ell=0}^{p_K}$ of $u_h$: use the ratio $|a_{p_K}| / \\sum_{\\ell=0}^{p_K} |a_\\ell|$ to assess spectral tail dominance.\n- Based on the relative dominance of jump versus interior residual and the smoothness indicator, decide the marking action for each element $K$:\n  - Output $0$ if the element should be marked for $h$-refinement,\n  - Output $1$ if the element should be marked for $p$-refinement,\n  - Output $2$ if no refinement is needed (for example, when $\\eta_K$ is sufficiently small compared to an average estimator magnitude).\n\nYour program must implement the above and apply it to the following test suite. In each case, the mesh, polynomial degrees, and manufactured solution $u$ (with its corresponding right-hand side $f = -u''$) are specified.\n\n- Test case $1$ (smooth solution, uniform mesh):\n  - Mesh nodes: $[0, 0.25, 0.5, 0.75, 1]$ so that there are $4$ elements with lengths $h_K = 0.25$.\n  - Polynomial degrees: $p_K = 2$ on all elements.\n  - Manufactured solution: $u(x) = \\sin(\\pi x)$, thus $f(x) = \\pi^2 \\sin(\\pi x)$.\n\n- Test case $2$ (steep variation near a mesh interface, uniform mesh):\n  - Mesh nodes: $[0, 0.25, 0.5, 0.75, 1]$.\n  - Polynomial degrees: $p_K = 2$ on all elements.\n  - Manufactured solution: $u(x) = \\arctan(\\beta (x - x_0))$ with parameters $\\beta = 300$ and $x_0 = 0.5$, thus\n    $$\n    u'(x) = \\frac{\\beta}{1 + \\beta^2 (x - x_0)^2}, \\qquad\n    u''(x) = -\\frac{2 \\beta^3 (x - x_0)}{\\left(1 + \\beta^2 (x - x_0)^2\\right)^2}, \\qquad\n    f(x) = -u''(x) = \\frac{2 \\beta^3 (x - x_0)}{\\left(1 + \\beta^2 (x - x_0)^2\\right)^2}.\n    $$\n\n- Test case $3$ (mixed smooth and localized steep feature, nonuniform $p$):\n  - Mesh nodes: $[0, 0.2, 0.4, 0.6, 0.8, 1]$, so there are $5$ elements with lengths $h_K = 0.2$.\n  - Polynomial degrees: $p_K = [1, 3, 2, 1, 4]$.\n  - Manufactured solution: $u(x) = \\sin(3 \\pi x) + 0.1 \\, \\arctan(\\gamma (x - x_1))$ with parameters $\\gamma = 80$ and $x_1 = 0.35$. Therefore,\n    $$\n    u''(x) = -9 \\pi^2 \\sin(3 \\pi x) - \\frac{0.2 \\, \\gamma^3 (x - x_1)}{\\left(1 + \\gamma^2 (x - x_1)^2\\right)^2}, \\qquad\n    f(x) = -u''(x) = 9 \\pi^2 \\sin(3 \\pi x) + \\frac{0.2 \\, \\gamma^3 (x - x_1)}{\\left(1 + \\gamma^2 (x - x_1)^2\\right)^2}.\n    $$\n\nAlgorithmic requirements for the marking decision on each element $K$:\n\n- Compute the interior residual norm $\\|R_K(u_h)\\|_{L^2(K)}$ and the aggregated jump residual norm assigned to $K$ (square-root of the sum of assigned face contributions).\n- Compute the spectral tail ratio $|a_{p_K}| / \\sum_{\\ell=0}^{p_K} |a_\\ell|$.\n- Compare the magnitude of jump versus interior residuals and the spectral tail ratio to decide whether the expected decay under increasing $p_K$ is favorable (indicating $p$-refinement), or whether the jump terms dominate (indicating $h$-refinement). If the total estimator $\\eta_K$ is sufficiently small relative to the average estimator magnitude in the test case, return the no-change decision.\n\nFinal output specification:\n\n- For each test case, return a list of integers of length equal to the number of elements, with entries in $\\{0,1,2\\}$ corresponding to $h$-refinement, $p$-refinement, or no change, respectively.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test caseâ€™s list appears as a nested list. For example, the output format should be like $[[d_{1,1}, d_{1,2}, \\dots], [d_{2,1}, d_{2,2}, \\dots], [d_{3,1}, d_{3,2}, \\dots]]$ with $d_{i,j} \\in \\{0,1,2\\}$.",
            "solution": "The problem requires the design and implementation of an $hp$-adaptive marking strategy for a one-dimensional Discontinuous Galerkin (DG) method applied to the Poisson equation. The strategy must decide for each element $K$ of a given mesh whether to recommend $h$-refinement (splitting the element), $p$-refinement (increasing the polynomial degree), or no change. This decision is to be based on a posteriori error indicators derived from the interior and jump residuals of the numerical solution.\n\nThe problem is well-posed and scientifically grounded in the theory of numerical methods for partial differential equations, specifically a posteriori error estimation for DG methods. I will first outline the theoretical and algorithmic basis for the strategy, and then provide the implementation.\n\n### 1. Theoretical Framework\n\nWe consider the DG discretization of the model problem:\n$$\n-\\frac{d^2 u}{dx^2} = f \\quad \\text{in } (0,1), \\qquad u(0)=0, \\quad u(1)=0.\n$$\nThe numerical solution $u_h$ is a piecewise polynomial of degree $p_K$ on each element $K$ of a mesh partitioning the domain $[0,1]$. A key feature of DG methods is that $u_h$ is not required to be continuous across element interfaces. This gives rise to two primary sources of error, which can be measured by residuals:\n\n1.  **Interior Residual $R_K(u_h)$**: On each element $K$, the strong form of the PDE is not exactly satisfied by $u_h$. The interior residual is defined as:\n    $$\n    R_K(u_h) := f + \\frac{d^2 u_h}{dx^2} \\quad \\text{on } K\n    $$\n    A large interior residual indicates that the polynomial $u_h$ is a poor approximation of the true solution $u$ within the element $K$.\n\n2.  **Jump Residual $J_e(u_h)$**: At an interior face $e$ (a node in 1D) shared by elements $K^{-}$ and $K^{+}$, the flux term, here $\\nabla u_h \\cdot \\mathbf{n}$, may be discontinuous. The jump residual measures this discontinuity:\n    $$\n    J_e(u_h) := \\llbracket \\nabla u_h \\cdot \\mathbf{n} \\rrbracket = \\frac{d u_h}{dx}\\bigg|_{x_e^+} - \\frac{d u_h}{dx}\\bigg|_{x_e^-}\n    $$\n    A large jump residual suggests that the solution is not well-resolved by the mesh at the interface, often due to a steep gradient or a singularity.\n\nThese residuals form the basis of the a posteriori error estimator $\\eta_K$ for each element $K$:\n$$\n\\eta_K^2 := h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2 \\;+\\; \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, |J_e(u_h)|^2\n$$\nHere, $\\| \\cdot \\|_{L^2(e)}$ reduces to an evaluation at the point $e$ in 1D. This form of the estimator double-counts the jump terms when summed over all elements. A common practice for localizing the error is to assign half of the jump contribution to each of the two adjacent elements. Thus, we will work with a localized indicator $\\tilde{\\eta}_K$:\n$$\n\\tilde{\\eta}_K^2 := \\underbrace{h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2}_{\\text{Interior Contribution}} \\;+\\; \\underbrace{\\frac{1}{2} \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, |J_e(u_h)|^2}_{\\text{Jump Contribution}}\n$$\n\n### 2. Algorithmic Design of the $hp$-Marking Strategy\n\nThe core of the task is to use $\\tilde{\\eta}_K$ and other available information to decide between $h$- and $p$-refinement. The guiding principles are:\n\n-   **$h$-refinement** is most effective for resolving non-smooth features like steep gradients or discontinuities, which manifest as large jump residuals. It is also preferred when the local solution has low regularity, meaning that increasing the polynomial degree would yield slow convergence.\n-   **$p$-refinement** is most effective for smooth solutions where the error is distributed throughout the element. This typically corresponds to a large interior residual relative to the jump residuals. Higher-degree polynomials can capture smooth functions with exponential convergence.\n\nTo formalize this, we introduce a local smoothness indicator. The numerical solution $u_h$ on an element $K$ is represented in a basis of Legendre polynomials. The rate of decay of the modal coefficients provides an estimate of the local solution regularity. We define the spectral smoothness indicator $S_K$ as the ratio of the magnitude of the highest-order coefficient to the sum of the magnitudes of all coefficients:\n$$\nS_K := \\frac{|a_{p_K}|}{\\sum_{\\ell=0}^{p_K} |a_\\ell|}\n$$\nA small value of $S_K$ indicates rapid spectral decay and a locally smooth solution, while a large value suggests the solution is not well-represented by the current polynomial space, indicating a need to resolve finer features, which points to $h$-refinement.\n\nThe marking strategy is implemented as a multi-step algorithm for each element $K_i$:\n\n**Step 1: Construct the Approximate Solution $u_h$**\nFor each element $K = [x_i, x_{i+1}]$ with prescribed polynomial degree $p_K$, the local solution $u_h|_K$ is constructed as the $L^2(K)$ projection of the manufactured solution $u$. The coefficients $\\{a_\\ell\\}_{\\ell=0}^{p_K}$ in the Legendre basis on $K$ are computed via numerical quadrature. Using an affine map $\\xi \\mapsto x(\\xi)$ from the reference interval $[-1, 1]$ to $K$, the coefficients are:\n$$\na_\\ell = \\frac{\\langle u, \\hat{P}_\\ell \\rangle_{L^2(K)}}{\\| \\hat{P}_\\ell \\|_{L^2(K)}^2} = \\frac{\\int_{-1}^1 u(x(\\xi)) P_\\ell(\\xi) d\\xi}{\\int_{-1}^1 (P_\\ell(\\xi))^2 d\\xi} = \\frac{2\\ell+1}{2} \\int_{-1}^1 u(x(\\xi)) P_\\ell(\\xi) d\\xi\n$$\nwhere $P_\\ell$ are the standard Legendre polynomials on $[-1, 1]$. The integral is approximated using high-order Gauss-Legendre quadrature. With the coefficients $\\{a_\\ell\\}$, $u_h$ and its derivatives on $K$ are defined.\n\n**Step 2: Compute Residuals and Indicators**\n-   The squared $L^2$-norm of the interior residual, $\\|R_K(u_h)\\|_{L^2(K)}^2 = \\int_K (f + u_h'')^2 dx$, is computed using Gauss-Legendre quadrature.\n-   The jump residuals $J_e(u_h)$ are computed at each interior node $x_e$ by evaluating the derivatives of the polynomials from the left and right elements.\n-   The spectral smoothness indicator $S_K$ is computed from the Legendre coefficients.\n-   The localized error indicator $\\tilde{\\eta}_K$ is assembled from the interior and jump contributions.\n\n**Step 3: Apply the Marking Logic**\nA set of rules, based on empirically chosen but theoretically motivated thresholds, is applied to each element $K_i$:\n1.  **No Refinement (Mark 2):** If an element's contribution to the total error is negligible, it is not refined. This is decided by comparing its indicator $\\tilde{\\eta}_{K_i}$ to the maximum indicator value over all elements:\n    $$\n    \\text{If } \\tilde{\\eta}_{K_i} < \\theta_{\\text{no-ref}} \\cdot \\max_j(\\tilde{\\eta}_{K_j}), \\quad \\text{mark as 2}.\n    $$\n    A threshold of $\\theta_{\\text{no-ref}} = 0.1$ is used.\n\n2.  **$h$- vs. $p$-Refinement (Marks 0 vs. 1):** For elements not marked for no-refinement, we decide between $h$ and $p$.\n    -   We compute the jump dominance ratio, which measures the relative contribution of the jump residual term to the total local indicator:\n        $$\n        D_K = \\frac{\\text{Jump Contribution}}{\\tilde{\\eta}_K^2}\n        $$\n    -   We check the smoothness via the spectral indicator $S_K$.\n    -   An element is marked for $h$-refinement (Mark 0) if the jump residual is dominant or if the local solution is detected as non-smooth:\n        $$\n        \\text{If } D_K > \\theta_{\\text{jump}} \\text{ or } S_K > \\theta_{\\text{spectral}}, \\quad \\text{mark as 0}.\n        $$\n        We use thresholds $\\theta_{\\text{jump}} = 0.5$ and $\\theta_{\\text{spectral}} = 0.1$.\n    -   Otherwise, if the interior residual dominates and the function appears smooth, the element is marked for $p$-refinement (Mark 1). This is the default for elements needing refinement.\n\nThis algorithm provides a clear, decisive, and justifiable method for guiding an $hp$-adaptive mesh refinement process. It correctly balances the need to resolve local, sharp features with the efficiency of high-order methods for smooth solutions.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import eval_legendre\nfrom numpy.polynomial.legendre import Legendre, leggauss\n\n# Algorithmic parameters for the marking strategy\nN_QUAD = 30  # Number of quadrature points\nTHETA_NO_REFINEMENT = 0.1  # Threshold for not refining an element\nJUMP_DOMINANCE_THRESHOLD = 0.5  # Threshold for jump residual dominance\nSPECTRAL_DECAY_THRESHOLD = 0.1  # Threshold for slow spectral decay\n\ndef get_l2_projection_coeffs(u_func, interval, p_degree):\n    \"\"\"Computes the coefficients of the L2 projection of u_func onto the space\n    of Legendre polynomials of degree p_degree on the given interval.\"\"\"\n    a, b = interval\n    h = b - a\n    jacobian = h / 2.0\n    \n    # Affine map from reference interval [-1, 1] to element [a, b]\n    map_to_interval = lambda xi: jacobian * xi + (a + b) / 2.0\n    \n    quad_points, quad_weights = leggauss(N_QUAD)\n    \n    coeffs = []\n    for l in range(p_degree + 1):\n        # Integrand for L2 projection coefficient calculation\n        integrand_vals = u_func(map_to_interval(quad_points)) * eval_legendre(l, quad_points)\n        integral_val = np.sum(quad_weights * integrand_vals)\n        \n        # Formula for the l-th coefficient\n        coeff_l = (2 * l + 1) / 2.0 * integral_val\n        coeffs.append(coeff_l)\n        \n    return np.array(coeffs)\n\ndef process_test_case(mesh_nodes, p_degrees, u_func, f_func):\n    \"\"\"\n    Applies the hp-marking strategy to a single test case.\n    \"\"\"\n    num_elements = len(mesh_nodes) - 1\n    elements_data = []\n    \n    quad_points, quad_weights = leggauss(N_QUAD)\n\n    # Step 1: Process each element to compute local properties\n    for i in range(num_elements):\n        interval = (mesh_nodes[i], mesh_nodes[i+1])\n        h_k = interval[1] - interval[0]\n        p_k = p_degrees[i]\n\n        # Compute L2 projection to get u_h\n        coeffs = get_l2_projection_coeffs(u_func, interval, p_k)\n        \n        # Build polynomial representation of u_h and its derivatives\n        u_h_poly = Legendre(coeffs, domain=interval)\n        u_h_poly_d2 = u_h_poly.deriv(2)\n\n        # Compute interior residual norm\n        map_to_interval = lambda xi: (h_k / 2.0) * xi + (interval[0] + interval[1]) / 2.0\n        x_quad = map_to_interval(quad_points)\n        \n        residual_vals = f_func(x_quad) + u_h_poly_d2(x_quad)\n        interior_res_sq_norm = np.sum(quad_weights * (residual_vals**2)) * (h_k / 2.0)\n\n        # Compute spectral smoothness indicator\n        if np.sum(np.abs(coeffs)) > 1e-15:\n            spectral_ratio = np.abs(coeffs[-1]) / np.sum(np.abs(coeffs))\n        else:\n            spectral_ratio = 0.0\n\n        elements_data.append({\n            'interval': interval,\n            'h_k': h_k,\n            'p_k': p_k,\n            'coeffs': coeffs,\n            'u_h_poly_d1': u_h_poly.deriv(1),\n            'interior_res_contrib': h_k**2 * interior_res_sq_norm,\n            'spectral_ratio': spectral_ratio,\n            'jump_res_contrib': 0.0,\n        })\n\n    # Step 2: Compute jump residuals at interior faces\n    for i in range(1, num_elements):\n        # Face at x = mesh_nodes[i]\n        face_loc = mesh_nodes[i]\n        \n        # Element K- to the left\n        elem_minus = elements_data[i-1]\n        # Element K+ to the right\n        elem_plus = elements_data[i]\n        \n        grad_uh_minus = elem_minus['u_h_poly_d1'](face_loc)\n        grad_uh_plus = elem_plus['u_h_poly_d1'](face_loc)\n        \n        jump = grad_uh_plus - grad_uh_minus\n        \n        h_e = 0.5 * (elem_minus['h_k'] + elem_plus['h_k'])\n        \n        jump_term = h_e * jump**2\n        \n        # Distribute jump contribution to neighboring elements\n        elem_minus['jump_res_contrib'] += 0.5 * jump_term\n        elem_plus['jump_res_contrib'] += 0.5 * jump_term\n\n    # Step 3: Finalize indicators and apply marking logic\n    eta_k_list = []\n    for data in elements_data:\n        eta_k_sq = data['interior_res_contrib'] + data['jump_res_contrib']\n        eta_k_list.append(np.sqrt(eta_k_sq))\n    \n    eta_max = np.max(eta_k_list) if eta_k_list else 0.0\n    marks = []\n\n    for i in range(num_elements):\n        data = elements_data[i]\n        eta_k = eta_k_list[i]\n        \n        # Rule 1: No refinement if error is small\n        if eta_k  THETA_NO_REFINEMENT * eta_max:\n            marks.append(2)\n            continue\n            \n        # Rule 2: h- vs p-refinement for elements with significant error\n        total_contrib = data['interior_res_contrib'] + data['jump_res_contrib']\n        if total_contrib > 1e-15:\n            jump_dominance_ratio = data['jump_res_contrib'] / total_contrib\n        else:\n            jump_dominance_ratio = 0.0\n\n        spectral_ratio = data['spectral_ratio']\n\n        if (jump_dominance_ratio > JUMP_DOMINANCE_THRESHOLD or \n            spectral_ratio > SPECTRAL_DECAY_THRESHOLD):\n            marks.append(0)  # h-refinement\n        else:\n            marks.append(1)  # p-refinement\n            \n    return marks\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = []\n\n    # Test Case 1: Smooth solution\n    f1_u = lambda x: np.sin(np.pi * x)\n    f1_f = lambda x: np.pi**2 * np.sin(np.pi * x)\n    case1 = {\n        'mesh_nodes': np.array([0, 0.25, 0.5, 0.75, 1]),\n        'p_degrees': np.array([2, 2, 2, 2]),\n        'u_func': f1_u,\n        'f_func': f1_f\n    }\n    test_cases.append(case1)\n\n    # Test Case 2: Steep gradient\n    beta, x0 = 300.0, 0.5\n    f2_u = lambda x: np.arctan(beta * (x - x0))\n    f2_f = lambda x: (2 * beta**3 * (x - x0)) / (1 + beta**2 * (x - x0)**2)**2\n    case2 = {\n        'mesh_nodes': np.array([0, 0.25, 0.5, 0.75, 1]),\n        'p_degrees': np.array([2, 2, 2, 2]),\n        'u_func': f2_u,\n        'f_func': f2_f\n    }\n    test_cases.append(case2)\n    \n    # Test Case 3: Mixed smooth and steep\n    gamma, x1 = 80.0, 0.35\n    f3_u = lambda x: np.sin(3 * np.pi * x) + 0.1 * np.arctan(gamma * (x - x1))\n    f3_f = lambda x: 9 * np.pi**2 * np.sin(3 * np.pi * x) + (0.2 * gamma**3 * (x - x1)) / (1 + gamma**2 * (x - x1)**2)**2\n    case3 = {\n        'mesh_nodes': np.array([0, 0.2, 0.4, 0.6, 0.8, 1]),\n        'p_degrees': np.array([1, 3, 2, 1, 4]),\n        'u_func': f3_u,\n        'f_func': f3_f\n    }\n    test_cases.append(case3)\n\n    all_results = []\n    for case in test_cases:\n        result = process_test_case(case['mesh_nodes'], case['p_degrees'], case['u_func'], case['f_func'])\n        all_results.append(result)\n\n    print(all_results)\n\nsolve()\n```"
        }
    ]
}