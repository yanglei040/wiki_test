{
    "hands_on_practices": [
        {
            "introduction": "Coercivity is a cornerstone of the Lax-Milgram theorem, ensuring the underlying operator is \"positive definite\" in a way that guarantees the variational problem is well-posed. This practice provides a direct, analytical exercise in quantifying the coercivity constant for a canonical reaction-diffusion operator. By working through this problem , you will see precisely how the coercivity constant $\\alpha$ depends on both the physical reaction coefficient $c$ and a fundamental property of the function space, the Poincaré constant $C_P$.",
            "id": "3395434",
            "problem": "Let $\\Omega \\subset \\mathbb{R}^{d}$ be a bounded Lipschitz domain, and let $H^{1}_{0}(\\Omega)$ denote the Sobolev space of functions with square-integrable first derivatives and vanishing trace on $\\partial \\Omega$. Assume the Poincaré inequality holds with the optimal Poincaré constant $C_{P} > 0$, meaning that for all $u \\in H^{1}_{0}(\\Omega)$ one has $\\|u\\|_{L^{2}(\\Omega)} \\leq C_{P}\\,\\|\\nabla u\\|_{L^{2}(\\Omega)}$. Consider the symmetric bilinear form $a : H^{1}_{0}(\\Omega) \\times H^{1}_{0}(\\Omega) \\to \\mathbb{R}$ defined by\n$$\na(u,v) \\;=\\; \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, dx \\;+\\; c \\int_{\\Omega} u\\,v \\, dx,\n$$\nwith a fixed reaction coefficient $c \\geq 0$. In the context of well-posedness for spectral Galerkin and discontinuous Galerkin formulations of linear elliptic Partial Differential Equations (PDEs) via the Lax–Milgram theorem, one fundamental requirement is coercivity of $a(\\cdot,\\cdot)$ with respect to a norm on $H^{1}_{0}(\\Omega)$. Here, take the $H^{1}$-norm\n$$\n\\|u\\|_{H^{1}(\\Omega)}^{2} \\;=\\; \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} \\;+\\; \\|u\\|_{L^{2}(\\Omega)}^{2}.\n$$\nDetermine, in closed form, the largest coercivity constant $\\alpha = \\alpha(c, C_{P})$ such that the inequality\n$$\na(u,u) \\;\\ge\\; \\alpha \\,\\|u\\|_{H^{1}(\\Omega)}^{2} \\quad \\text{for all } u \\in H^{1}_{0}(\\Omega)\n$$\nholds, expressed purely in terms of $c$ and $C_{P}$. Your final answer must be a single closed-form analytic expression in $c$ and $C_{P}$.",
            "solution": "The problem requires finding the largest coercivity constant $\\alpha$, which is a function of the reaction coefficient $c$ and the Poincaré constant $C_{P}$, for the bilinear form $a(\\cdot,\\cdot)$ with respect to the $H^{1}$-norm.\n\nThe problem provides the following definitions:\nThe bilinear form is $a(u,v) = \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, dx + c \\int_{\\Omega} u\\,v \\, dx$ for $u, v \\in H^{1}_{0}(\\Omega)$ and a constant $c \\ge 0$.\nThe squared $L^2$-norm of the gradient is $\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} = \\int_{\\Omega} |\\nabla u|^{2} \\, dx$.\nThe squared $L^2$-norm is $\\|u\\|_{L^{2}(\\Omega)}^{2} = \\int_{\\Omega} u^{2} \\, dx$.\nThus, the bilinear form evaluated at $(u,u)$ is $a(u,u) = \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + c \\|u\\|_{L^{2}(\\Omega)}^{2}$.\n\nThe norm on the space $H^{1}_{0}(\\Omega)$ is the $H^{1}$-norm, with its square defined as $\\|u\\|_{H^{1}(\\Omega)}^{2} = \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + \\|u\\|_{L^{2}(\\Omega)}^{2}$.\n\nThe coercivity condition is $a(u,u) \\ge \\alpha \\|u\\|_{H^{1}(\\Omega)}^{2}$ for all $u \\in H^{1}_{0}(\\Omega)$.\n\nTo find the largest possible value of $\\alpha$, we must find the infimum of the ratio $\\frac{a(u,u)}{\\|u\\|_{H^{1}(\\Omega)}^{2}}$ over all non-zero functions in the space $H^{1}_{0}(\\Omega)$.\n$$\n\\alpha = \\inf_{u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}} \\frac{a(u,u)}{\\|u\\|_{H^{1}(\\Omega)}^{2}}\n$$\nSubstituting the expressions for $a(u,u)$ and $\\|u\\|_{H^{1}(\\Omega)}^{2}$:\n$$\n\\alpha = \\inf_{u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}} \\frac{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + c \\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2} + \\|u\\|_{L^{2}(\\Omega)}^{2}}\n$$\nFor any $u \\in H^{1}_{0}(\\Omega)$ such that $u \\not\\equiv 0$, it must be that $\\|\\nabla u\\|_{L^{2}(\\Omega)} > 0$. If $\\|\\nabla u\\|_{L^{2}(\\Omega)} = 0$, then $u$ is a constant function. Since $u \\in H^{1}_{0}(\\Omega)$, its trace on the boundary $\\partial\\Omega$ is zero, which implies the constant must be zero, so $u \\equiv 0$. Therefore, for any non-zero $u$, we can divide both the numerator and the denominator by $\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}$:\n$$\n\\alpha = \\inf_{u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}} \\frac{1 + c \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}}}{1 + \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}}}\n$$\nLet us define a variable $z = \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}}$. The problem is now reduced to finding the infimum of a function of $z$, where the domain of $z$ is determined by the properties of the space $H^{1}_{0}(\\Omega)$.\n\nThe Poincaré inequality is given as $\\|u\\|_{L^{2}(\\Omega)} \\le C_{P} \\|\\nabla u\\|_{L^{2}(\\Omega)}$ for all $u \\in H^{1}_{0}(\\Omega)$, with $C_{P}$ being the optimal constant. Squaring this inequality gives $\\|u\\|_{L^{2}(\\Omega)}^{2} \\le C_{P}^{2} \\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}$, which implies $z = \\frac{\\|u\\|_{L^{2}(\\Omega)}^{2}}{\\|\\nabla u\\|_{L^{2}(\\Omega)}^{2}} \\le C_{P}^{2}$.\nThe set of all possible values for the ratio $z$ for $u \\in H^{1}_{0}(\\Omega) \\setminus \\{0\\}$ is the interval $[0, C_P^2]$. The value $z=C_P^2$ is achieved for the eigenfunction corresponding to the first eigenvalue of the negative Laplacian with homogeneous Dirichlet boundary conditions. Values of $z$ arbitrarily close to $0$ can be achieved by functions that are highly oscillatory (corresponding to eigenfunctions of the Laplacian with large eigenvalues).\n\nWe must therefore find the infimum of the function $f(z) = \\frac{1+cz}{1+z}$ over the interval $z \\in [0, C_{P}^{2}]$. To do this, we analyze the derivative of $f(z)$:\n$$\nf'(z) = \\frac{d}{dz}\\left(\\frac{1+cz}{1+z}\\right) = \\frac{c(1+z) - (1+cz)(1)}{(1+z)^{2}} = \\frac{c-1}{(1+z)^{2}}\n$$\nThe sign of the derivative depends on the value of $c$, and the problem states $c \\ge 0$. We consider two cases.\n\nCase 1: $c \\ge 1$.\nIn this case, $c-1 \\ge 0$, so $f'(z) \\ge 0$. This implies that $f(z)$ is a non-decreasing function on its domain. The infimum of $f(z)$ on the interval $[0, C_{P}^{2}]$ is thus attained at the left endpoint, $z=0$.\n$$\n\\alpha = f(0) = \\frac{1+c(0)}{1+0} = 1\n$$\n\nCase 2: $0 \\le c < 1$.\nIn this case, $c-1 < 0$, so $f'(z) < 0$. This implies that $f(z)$ is a strictly decreasing function on its domain. The infimum of $f(z)$ on the interval $[0, C_{P}^{2}]$ is thus attained at the right endpoint, $z=C_{P}^{2}$.\n$$\n\\alpha = f(C_{P}^{2}) = \\frac{1+cC_{P}^{2}}{1+C_{P}^{2}}\n$$\n\nWe can combine these two results into a single analytical expression.\nIf $c \\ge 1$, then $c-1 \\ge 0$, which means $cC_P^2 \\ge C_P^2$, so $1+cC_P^2 \\ge 1+C_P^2$. This gives $\\frac{1+cC_{P}^{2}}{1+C_{P}^{2}} \\ge 1$. Thus, for $c \\ge 1$, the result $\\alpha=1$ can be written as $\\min\\left(1, \\frac{1+cC_P^2}{1+C_P^2}\\right)$.\nIf $0 \\le c < 1$, then $c-1 < 0$, which means $cC_P^2 < C_P^2$, so $1+cC_P^2 < 1+C_P^2$. This gives $\\frac{1+cC_{P}^{2}}{1+C_{P}^{2}} < 1$. Thus, for $0 \\le c < 1$, the result $\\alpha=\\frac{1+cC_{P}^{2}}{1+C_{P}^{2}}$ can be written as $\\min\\left(1, \\frac{1+cC_P^2}{1+C_P^2}\\right)$.\n\nTherefore, for all $c \\ge 0$, the largest coercivity constant $\\alpha$ can be expressed in the single closed form:\n$$\n\\alpha(c, C_{P}) = \\min\\left(1, \\frac{1+cC_{P}^{2}}{1+C_{P}^{2}}\\right)\n$$",
            "answer": "$$\n\\boxed{\\min\\left(1, \\frac{1+c C_{P}^{2}}{1+C_{P}^{2}}\\right)}\n$$"
        },
        {
            "introduction": "The power of the Lax-Milgram theorem extends to proving the stability of complex numerical methods, but the application is often non-trivial. This exercise  guides you through the essential analytical machinery required to establish coercivity for the Symmetric Interior Penalty Galerkin (SIPG) method, a widely used discontinuous Galerkin (DG) formulation. You will derive key technical tools like inverse and discrete trace inequalities to understand why penalty terms are essential in DG methods and to calculate the minimum penalty strength required to ensure a stable discretization.",
            "id": "3395438",
            "problem": "Consider the scalar Poisson model problem on a bounded Lipschitz domain $\\Omega \\subset \\mathbb{R}^{d}$, with homogeneous Dirichlet boundary conditions. Let $\\mathcal{T}_{h}$ be a shape-regular mesh of $\\Omega$ into elements $K$, each obtained as the image of a fixed reference element $\\widehat{K}$ under an affine mapping $F_{K}$ with Jacobian matrix $J_{K}$ and determinant $|J_{K}|$. Denote by $h_{K}$ the diameter of $K$ and by $h_{e}$ the diameter of a face (edge in two dimensions, face in three dimensions) $e \\subset \\partial K$. For a fixed polynomial degree $p \\geq 1$, let $V_{h}$ be the space of scalar-valued piecewise polynomials on $\\mathcal{T}_{h}$ of total degree at most $p$, without interelement continuity constraints.\n\nYou will work with the symmetric interior penalty Galerkin (SIPG) bilinear form $a_{h}(\\cdot,\\cdot)$, defined on $V_{h} \\times V_{h}$ by\n$$\na_{h}(u_{h},v_{h}) \\;=\\; \\sum_{K \\in \\mathcal{T}_{h}} \\int_{K} \\nabla u_{h} \\cdot \\nabla v_{h} \\,\\mathrm{d}x \\;-\\; \\sum_{e \\in \\mathcal{E}_{h}} \\int_{e} \\left\\{ \\partial_{n} u_{h} \\right\\} [v_{h}] \\,\\mathrm{d}s \\;-\\; \\sum_{e \\in \\mathcal{E}_{h}} \\int_{e} \\left\\{ \\partial_{n} v_{h} \\right\\} [u_{h}] \\,\\mathrm{d}s \\;+\\; \\sum_{e \\in \\mathcal{E}_{h}} \\int_{e} \\sigma_{e} [u_{h}] [v_{h}] \\,\\mathrm{d}s,\n$$\nwhere $\\mathcal{E}_{h}$ is the set of all mesh faces, $[v_{h}]$ denotes the scalar jump of $v_{h}$ across an interior face $e = \\partial K^{+} \\cap \\partial K^{-}$ defined by $[v_{h}] = v_{h}^{+} - v_{h}^{-}$, and $\\{\\partial_{n} v_{h}\\}$ denotes the average of the normal derivatives, $\\{\\partial_{n} v_{h}\\} = \\tfrac{1}{2}\\left(\\nabla v_{h}^{+} \\cdot n^{+} + \\nabla v_{h}^{-} \\cdot n^{-}\\right)$, with $n^{\\pm}$ the outward unit normals on $\\partial K^{\\pm}$. On boundary faces, interpret these quantities in the standard way consistent with the homogeneous Dirichlet boundary conditions. The penalty parameter is chosen as $\\sigma_{e} = \\gamma \\,\\dfrac{p^{2}}{h_{e}}$, with an undetermined positive constant $\\gamma$.\n\nStarting from fundamental facts on affine mappings and polynomial approximation on the reference element, proceed as follows:\n\n1) Derive a local inverse inequality on each element $K$: for any $v_{h} \\in V_{h}$ restricted to $K$, prove a bound that expresses $\\|\\nabla v_{h}\\|_{L^{2}(K)}$ in terms of $\\|v_{h}\\|_{L^{2}(K)}$, with explicit dependence on the polynomial degree $p$ and the element diameter $h_{K}$. Your derivation must start from a reference-element inequality for polynomials and use scaling under the affine map $F_{K}$ together with shape-regularity.\n\n2) Using the result of step 1) together with a reference-element trace inequality, derive a discrete trace inequality for polynomials that yields, for each face $e \\subset \\partial K$, a bound of the form\n$$\nh_{e}\\,\\|\\partial_{n} v_{h}\\|_{L^{2}(e)}^{2} \\;\\leq\\; C_{\\mathrm{tr}} \\, p^{2} \\, \\|\\nabla v_{h}\\|_{L^{2}(K)}^{2},\n$$\nwhere $C_{\\mathrm{tr}}$ depends only on the shape-regularity of the mesh family and the reference-element constants.\n\n3) Prove the coercivity of $a_{h}(\\cdot,\\cdot)$ in the mesh-dependent norm\n$$\n\\|v_{h}\\|_{1,h}^{2} \\;=\\; \\sum_{K \\in \\mathcal{T}_{h}} \\|\\nabla v_{h}\\|_{L^{2}(K)}^{2} \\;+\\; \\sum_{e \\in \\mathcal{E}_{h}} \\frac{p^{2}}{h_{e}} \\,\\|[v_{h}]\\|_{L^{2}(e)}^{2}.\n$$\nSpecifically, use the discrete trace inequality from step 2) and Young’s inequality on faces, together with shape regularity, to show that there exists a choice of $\\gamma$ such that\n$$\na_{h}(v_{h},v_{h}) \\;\\geq\\; \\frac{1}{2}\\,\\sum_{K \\in \\mathcal{T}_{h}} \\|\\nabla v_{h}\\|_{L^{2}(K)}^{2} \\;+\\; \\frac{1}{2}\\,\\sum_{e \\in \\mathcal{E}_{h}} \\sigma_{e}\\,\\|[v_{h}]\\|_{L^{2}(e)}^{2}\n$$\nfor all $v_{h} \\in V_{h}$. Denote by $N_{f}$ the maximum number of faces per element in $\\mathcal{T}_{h}$. Compute the smallest admissible lower bound $\\gamma_{\\ast}$ as a closed-form analytic expression in terms of $C_{\\mathrm{tr}}$ and $N_{f}$ that guarantees the above coercivity inequality with the factor $\\tfrac{1}{2}$.\n\n4) Explain briefly how the coercivity from step 3), together with continuity of $a_{h}(\\cdot,\\cdot)$ in the same norm, implies well-posedness of the SIPG method by the Lax-Milgram theorem, but do not state or derive any constants other than $\\gamma_{\\ast}$.\n\nYour final answer must be the single closed-form analytic expression for the minimal $\\gamma_{\\ast}$ obtained in step 3). No rounding is required, and no units are involved.",
            "solution": "This problem requires a step-by-step derivation of several key inequalities for the Symmetric Interior Penalty Galerkin (SIPG) method, culminating in a proof of coercivity and the determination of the minimal penalty parameter. The final step is to connect these results to the well-posedness of the numerical method via the Lax-Milgram theorem.\n\n**1) Derivation of the local inverse inequality**\n\nWe begin by stating a standard inverse inequality for polynomials on the reference element $\\widehat{K}$. For any polynomial $\\widehat{v} \\in P^p(\\widehat{K})$, the space of polynomials of total degree at most $p$, there exists a constant $C_{\\text{inv,ref}}$, depending only on the geometry of $\\widehat{K}$, such that:\n$$\n\\|\\widehat{\\nabla} \\widehat{v}\\|_{L^2(\\widehat{K})} \\leq C_{\\text{inv,ref}} \\, p^2 \\, \\|\\widehat{v}\\|_{L^2(\\widehat{K})}\n$$\nThe $p^2$ dependence is a known property for this type of inequality in multiple dimensions.\n\nLet $v_h$ be a polynomial of degree at most $p$ on an element $K \\in \\mathcal{T}_h$. Let $\\widehat{v}$ be its counterpart on the reference element $\\widehat{K}$ via the affine mapping $x = F_K(\\widehat{x}) = J_K \\widehat{x} + b_K$. We have $v_h(x) = \\widehat{v}(\\widehat{x})$. We relate the norms on $K$ and $\\widehat{K}$ through a change of variables.\nFor the $L^2$-norm of the function itself, we have:\n$$\n\\|v_h\\|_{L^2(K)}^2 = \\int_K v_h(x)^2 \\,\\mathrm{d}x = \\int_{\\widehat{K}} \\widehat{v}(\\widehat{x})^2 |J_K| \\,\\mathrm{d}\\widehat{x} = |J_K| \\|\\widehat{v}\\|_{L^2(\\widehat{K})}^2\n$$\nwhere $|J_K|$ is the determinant of the Jacobian matrix $J_K$.\n\nFor the gradient, the chain rule gives $\\widehat{\\nabla} \\widehat{v} = J_K^T \\nabla v_h$, which implies $\\nabla v_h = J_K^{-T} \\widehat{\\nabla} \\widehat{v}$. We can bound the norm of the gradient as follows:\n$$\n\\|\\nabla v_h\\|_{L^2(K)}^2 = \\int_K |\\nabla v_h(x)|^2 \\,\\mathrm{d}x = \\int_{\\widehat{K}} |J_K^{-T} \\widehat{\\nabla} \\widehat{v}(\\widehat{x})|^2 |J_K| \\,\\mathrm{d}\\widehat{x}\n$$\nUsing the definition of the matrix operator norm (spectral norm), we have $|J_K^{-T} \\widehat{\\nabla} \\widehat{v}| \\leq \\|J_K^{-T}\\| |\\widehat{\\nabla} \\widehat{v}| = \\|J_K^{-1}\\| |\\widehat{\\nabla} \\widehat{v}|$.\n$$\n\\|\\nabla v_h\\|_{L^2(K)}^2 \\leq \\|J_K^{-1}\\|^2 \\int_{\\widehat{K}} |\\widehat{\\nabla} \\widehat{v}(\\widehat{x})|^2 |J_K| \\,\\mathrm{d}\\widehat{x} = \\|J_K^{-1}\\|^2 |J_K| \\|\\widehat{\\nabla} \\widehat{v}\\|_{L^2(\\widehat{K})}^2\n$$\nNow we combine these relations. From the reference inverse inequality:\n$$\n\\|\\widehat{\\nabla} \\widehat{v}\\|_{L^2(\\widehat{K})}^2 \\leq (C_{\\text{inv,ref}} p^2)^2 \\|\\widehat{v}\\|_{L^2(\\widehat{K})}^2\n$$\nSubstituting the expressions for the scaled norms:\n$$\n\\|\\nabla v_h\\|_{L^2(K)}^2 \\leq \\|J_K^{-1}\\|^2 |J_K| (C_{\\text{inv,ref}} p^2)^2 \\left( \\frac{1}{|J_K|} \\|v_h\\|_{L^2(K)}^2 \\right) = \\|J_K^{-1}\\|^2 (C_{\\text{inv,ref}} p^2)^2 \\|v_h\\|_{L^2(K)}^2\n$$\nThe family of meshes $\\mathcal{T}_h$ is shape-regular. This property implies that there exists a constant $C_{\\text{sr}}$, independent of $h_K$, such that $\\|J_K^{-1}\\| \\leq C_{\\text{sr}} h_K^{-1}$. Substituting this into the inequality gives:\n$$\n\\|\\nabla v_h\\|_{L^2(K)}^2 \\leq (C_{\\text{sr}} h_K^{-1})^2 (C_{\\text{inv,ref}} p^2)^2 \\|v_h\\|_{L^2(K)}^2\n$$\nTaking the square root of both sides, we obtain the desired local inverse inequality:\n$$\n\\|\\nabla v_h\\|_{L^2(K)} \\leq C_{\\text{inv}} \\frac{p^2}{h_K} \\|v_h\\|_{L^2(K)}\n$$\nwhere the constant $C_{\\text{inv}} = C_{\\text{sr}} C_{\\text{inv,ref}}$ depends only on the shape-regularity of the mesh and the geometry of the reference element.\n\n**2) Derivation of the discrete trace inequality**\n\nWe aim to prove an inequality of the form $h_e \\|\\partial_n v_h\\|_{L^2(e)}^2 \\leq C_{\\text{tr}} p^2 \\|\\nabla v_h\\|_{L^2(K)}^2$. This is a type of trace-inverse inequality. We start from a known result for polynomials on the reference element $\\widehat{K}$: for a vector-valued polynomial $\\widehat{w}$ with components in $P^{p-1}(\\widehat{K})$, there exists a constant $C_{\\text{ref,tr-inv}}$ such that\n$$\n\\|\\widehat{w}\\|_{L^2(\\partial \\widehat{K})}^2 \\leq C_{\\text{ref,tr-inv}} p^2 \\|\\widehat{w}\\|_{L^2(\\widehat{K})}^2\n$$\nThis inequality combines a trace theorem with an inverse inequality on the reference element, and the $p^2$ factor is standard. Let us apply this to $\\widehat{w} = \\widehat{\\nabla} \\widehat{v}_h$, whose components are polynomials of degree at most $p-1$.\n$$\n\\|\\widehat{\\nabla} \\widehat{v}_h\\|_{L^2(\\widehat{e})}^2 \\leq \\|\\widehat{\\nabla} \\widehat{v}_h\\|_{L^2(\\partial \\widehat{K})}^2 \\leq C_{\\text{ref,tr-inv}} p^2 \\|\\widehat{\\nabla} \\widehat{v}_h\\|_{L^2(\\widehat{K})}^2\n$$\nNow, we perform scaling arguments to move from $\\widehat{K}$ and $\\widehat{e}$ to the physical element $K$ and face $e$. We have $\\partial_n v_h = \\nabla v_h \\cdot n$. Then $\\|\\partial_n v_h\\|_{L^2(e)}^2 \\leq \\|\\nabla v_h\\|_{L^2(e)}^2$. Let's bound the latter.\nThe transformation of the surface integral is $\\int_e |\\nabla v_h|^2 \\mathrm{d}s = \\int_{\\widehat{e}} |J_K^{-T} \\widehat{\\nabla} \\widehat{v}_h|^2 \\frac{\\mathrm{d}s}{\\mathrm{d}\\widehat{s}} \\mathrm{d}\\widehat{s}$.\nThe surface element scaling is $\\frac{\\mathrm{d}s}{\\mathrm{d}\\widehat{s}} = |J_K| \\|J_K^{-T} \\widehat{n}\\|$, where $\\widehat{n}$ is the unit normal to $\\widehat{e}$.\nShape regularity ensures $|J_K| \\sim h_K^d$, $\\|J_K^{-1}\\| \\sim h_K^{-1}$. Therefore, $\\frac{\\mathrm{d}s}{\\mathrm{d}\\widehat{s}} \\sim h_K^d h_K^{-1} = h_K^{d-1}$. We use $C_{\\text{sr}}$ to denote generic constants arising from shape regularity.\n$$\n\\|\\nabla v_h\\|_{L^2(e)}^2 \\leq C_{\\text{sr}} h_K^{d-1} \\int_{\\widehat{e}} \\|J_K^{-T}\\|^2 |\\widehat{\\nabla} \\widehat{v}_h|^2 \\mathrm{d}\\widehat{s} \\leq C_{\\text{sr}} h_K^{d-1} h_K^{-2} \\|\\widehat{\\nabla} \\widehat{v}_h\\|_{L^2(\\widehat{e})}^2 = C_{\\text{sr}} h_K^{d-3} \\|\\widehat{\\nabla} \\widehat{v}_h\\|_{L^2(\\widehat{e})}^2\n$$\nNow we use the reference trace-inverse inequality:\n$$\n\\|\\nabla v_h\\|_{L^2(e)}^2 \\leq C_{\\text{sr}} h_K^{d-3} (C_{\\text{ref,tr-inv}} p^2 \\|\\widehat{\\nabla} \\widehat{v}_h\\|_{L^2(\\widehat{K})}^2)\n$$\nFinally, we scale the remaining reference norm back to the physical element. $\\widehat{\\nabla} \\widehat{v}_h = J_K^T \\nabla v_h$.\n$$\n\\|\\widehat{\\nabla} \\widehat{v}_h\\|_{L^2(\\widehat{K})}^2 = \\int_{\\widehat{K}} |J_K^T \\nabla v_h|^2 \\mathrm{d}\\widehat{x} \\leq \\|J_K^T\\|^2 \\int_{\\widehat{K}} |\\nabla v_h|^2 \\frac{1}{|J_K|} \\mathrm{d}x = \\frac{\\|J_K\\|^2}{|J_K|} \\|\\nabla v_h\\|_{L^2(K)}^2\n$$\nUsing shape regularity, $\\|J_K\\| \\sim h_K$ and $|J_K| \\sim h_K^d$, so $\\frac{\\|J_K\\|^2}{|J_K|} \\leq C_{\\text{sr}} \\frac{h_K^2}{h_K^d} = C_{\\text{sr}} h_K^{2-d}$.\nSubstituting this back:\n$$\n\\|\\nabla v_h\\|_{L^2(e)}^2 \\leq (C_{\\text{sr}} h_K^{d-3}) (C_{\\text{ref,tr-inv}} p^2) (C_{\\text{sr}} h_K^{2-d} \\|\\nabla v_h\\|_{L^2(K)}^2) = C' \\frac{p^2}{h_K} \\|\\nabla v_h\\|_{L^2(K)}^2\n$$\nwhere $C'$ combines all constants. Since the mesh is shape-regular, $h_e$ and $h_K$ are equivalent, i.e., $h_K \\leq C_{\\text{sr}} h_e$. This gives $1/h_K \\leq C_{\\text{sr}}/h_e$. Thus, we arrive at the desired discrete trace inequality:\n$$\nh_e \\|\\partial_n v_h\\|_{L^2(e)}^2 \\leq h_e \\|\\nabla v_h\\|_{L^2(e)}^2 \\leq C_{\\text{tr}} p^2 \\|\\nabla v_h\\|_{L^2(K)}^2\n$$\nwhere $C_{\\text{tr}}$ is a constant depending on shape-regularity and reference element properties.\n\n**3) Proof of coercivity and computation of $\\gamma_\\ast$**\n\nThe SIPG bilinear form is given by:\n$$\na_{h}(v_{h},v_{h}) = \\sum_{K \\in \\mathcal{T}_{h}} \\|\\nabla v_{h}\\|_{L^{2}(K)}^{2} - 2\\sum_{e \\in \\mathcal{E}_{h}} \\int_{e} \\left\\{ \\partial_{n} v_{h} \\right\\} [v_{h}] \\,\\mathrm{d}s + \\sum_{e \\in \\mathcal{E}_{h}} \\sigma_{e} \\|[v_{h}]\\|_{L^{2}(e)}^{2}\n$$\nWe focus on the second term. By the Cauchy-Schwarz inequality and Young's inequality ($2ab \\le \\eta a^2 + \\eta^{-1}b^2$ for any $\\eta > 0$), we have for each face $e$:\n$$\n\\left| 2\\int_{e} \\left\\{ \\partial_{n} v_{h} \\right\\} [v_{h}] \\,\\mathrm{d}s \\right| \\leq 2 \\|\\{\\partial_n v_h\\}\\|_{L^2(e)} \\|[v_h]\\|_{L^2(e)} \\leq \\eta_e \\|\\{\\partial_n v_h\\}\\|_{L^2(e)}^2 + \\frac{1}{\\eta_e} \\|[v_h]\\|_{L^2(e)}^2\n$$\nwhere $\\eta_e$ is a positive parameter to be chosen. Summing over all faces and substituting into the bilinear form gives:\n$$\na_h(v_h, v_h) \\geq \\sum_{K} \\|\\nabla v_h\\|_K^2 - \\sum_{e} \\eta_e \\|\\{\\partial_n v_h\\}\\|_e^2 + \\sum_{e} \\left(\\sigma_e - \\frac{1}{\\eta_e}\\right) \\|[v_h]\\|_e^2\n$$\nNow we bound the term $\\sum_e \\eta_e \\|\\{\\partial_n v_h\\}\\|_e^2$. For any face $e$, the average operator satisfies $\\|\\{\\partial_n v_h\\}\\|_e^2 \\leq \\frac{1}{2}(\\|\\partial_n v_h^+\\|_e^2 + \\|\\partial_n v_h^-\\|_e^2)$, where $v_h^\\pm$ are the traces from adjacent elements $K^\\pm$ (for a boundary face, one of these terms is absent).\nApplying the discrete trace inequality from step 2) for each element sharing the face:\n$$\n\\|\\partial_n v_h^\\pm\\|_e^2 \\le C_{\\text{tr}} \\frac{p^2}{h_e} \\|\\nabla v_h^\\pm\\|_{K^\\pm}^2\n$$\nThus,\n$$\n\\sum_{e \\in \\mathcal{E}_h} \\eta_e \\|\\{\\partial_n v_h\\}\\|_e^2 \\leq \\sum_{e \\in \\mathcal{E}_h} \\eta_e \\frac{1}{2} C_{\\text{tr}} \\frac{p^2}{h_e} \\left( \\|\\nabla v_h^+\\|_{K^+}^2 + \\|\\nabla v_h^-\\|_{K^-}^2 \\right)\n$$\nWe choose $\\eta_e = \\alpha \\frac{h_e}{p^2}$ for some constant $\\alpha > 0$.\n$$\n\\sum_e \\eta_e \\|\\{\\partial_n v_h\\}\\|_e^2 \\leq \\sum_{e \\in \\mathcal{E}_h} \\left(\\alpha \\frac{h_e}{p^2}\\right) \\frac{C_{\\text{tr}} p^2}{2h_e} \\left( \\|\\nabla v_h^+\\|_{K^+}^2 + \\|\\nabla v_h^-\\|_{K^-}^2 \\right) = \\frac{\\alpha C_{\\text{tr}}}{2} \\sum_{e \\in \\mathcal{E}_h} \\left( \\|\\nabla v_h^+\\|_{K^+}^2 + \\|\\nabla v_h^-\\|_{K^-}^2 \\right)\n$$\nRewriting the sum over faces as a sum over elements: each element $K$ appears in the sum for each of its faces.\n$$\n\\sum_{e \\in \\mathcal{E}_h} \\left( \\|\\nabla v_h^+\\|_{K^+}^2 + \\|\\nabla v_h^-\\|_{K^-}^2 \\right) = \\sum_{K \\in \\mathcal{T}_h} N_f(K) \\|\\nabla v_h\\|_K^2 \\leq N_f \\sum_{K \\in \\mathcal{T}_h} \\|\\nabla v_h\\|_K^2\n$$\nwhere $N_f(K)$ is the number of faces of element $K$ and $N_f = \\max_K N_f(K)$.\nSo, we have the bound:\n$$\n\\sum_e \\eta_e \\|\\{\\partial_n v_h\\}\\|_e^2 \\leq \\frac{\\alpha C_{\\text{tr}} N_f}{2} \\sum_K \\|\\nabla v_h\\|_K^2\n$$\nPlugging this back into the inequality for $a_h(v_h, v_h)$:\n$$\na_h(v_h, v_h) \\geq \\left(1 - \\frac{\\alpha C_{\\text{tr}} N_f}{2}\\right) \\sum_K \\|\\nabla v_h\\|_K^2 + \\sum_e \\left(\\gamma \\frac{p^2}{h_e} - \\frac{p^2}{\\alpha h_e}\\right) \\|[v_h]\\|_e^2\n$$\nWe want to satisfy the target inequality: $a_h(v_h,v_h) \\geq \\frac{1}{2} \\sum_K \\|\\nabla v_h\\|_K^2 + \\frac{1}{2} \\sum_e \\sigma_e \\|[v_h]\\|_e^2$.\nThis requires two conditions to hold for our choice of $\\alpha$:\n1) $1 - \\frac{\\alpha C_{\\text{tr}} N_f}{2} \\geq \\frac{1}{2} \\implies \\frac{1}{2} \\geq \\frac{\\alpha C_{\\text{tr}} N_f}{2} \\implies \\alpha \\leq \\frac{1}{C_{\\text{tr}} N_f}$.\n2) $\\gamma \\frac{p^2}{h_e} - \\frac{p^2}{\\alpha h_e} \\geq \\frac{1}{2} \\sigma_e = \\frac{\\gamma}{2}\\frac{p^2}{h_e} \\implies \\gamma - \\frac{1}{\\alpha} \\geq \\frac{\\gamma}{2} \\implies \\frac{\\gamma}{2} \\geq \\frac{1}{\\alpha} \\implies \\gamma \\geq \\frac{2}{\\alpha}$.\nTo find the smallest admissible $\\gamma$, we need to choose $\\alpha$ to be as large as possible. From condition 1), the maximum value is $\\alpha = \\frac{1}{C_{\\text{tr}} N_f}$.\nSubstituting this maximal $\\alpha$ into condition 2) gives the minimal required $\\gamma$:\n$$\n\\gamma \\geq \\frac{2}{1/(C_{\\text{tr}} N_f)} = 2 C_{\\text{tr}} N_f\n$$\nTherefore, the smallest admissible lower bound for the penalty parameter constant is $\\gamma_\\ast = 2 C_{\\text{tr}} N_f$.\n\n**4) Well-posedness via the Lax-Milgram theorem**\n\nThe Lax-Milgram theorem states that a variational problem $a(u,v) = L(v)$ for all $v \\in H$, where $H$ is a Hilbert space, has a unique solution $u \\in H$ if the bilinear form $a(\\cdot, \\cdot)$ is continuous and coercive on $H$, and the linear functional $L(\\cdot)$ is continuous on $H$.\n\nFor the SIPG method, the Hilbert space is $H = V_h$ equipped with the mesh-dependent norm $\\|\\cdot\\|_{1,h}$. The bilinear form is $a_h(\\cdot, \\cdot)$, and the linear functional is $L(v_h) = \\int_{\\Omega} f v_h \\mathrm{d}x$.\n\nIn step 3), we proved the coercivity of $a_h(\\cdot, \\cdot)$ for $\\gamma \\ge \\gamma_\\ast$. Specifically, we showed that\n$a_h(v_h, v_h) \\geq \\frac{1}{2} \\sum_K \\|\\nabla v_h\\|_K^2 + \\frac{1}{2} \\sum_e \\sigma_e \\|[v_h]\\|_e^2$.\nUsing $\\sigma_e = \\gamma \\frac{p^2}{h_e}$, this is\n$a_h(v_h, v_h) \\geq \\frac{1}{2} \\sum_K \\|\\nabla v_h\\|_K^2 + \\frac{\\gamma}{2} \\sum_e \\frac{p^2}{h_e} \\|[v_h]\\|_e^2 \\geq \\min\\left(\\frac{1}{2}, \\frac{\\gamma}{2}\\right) \\|v_h\\|_{1,h}^2$.\nSince $\\gamma \\ge \\gamma_\\ast = 2C_{\\text{tr}}N_f > 0$, the coercivity constant $\\min(\\frac{1}{2}, \\frac{\\gamma}{2})$ is positive.\n\nThe continuity of $a_h(\\cdot, \\cdot)$, i.e., $|a_h(u_h, v_h)| \\leq C \\|u_h\\|_{1,h}\\|v_h\\|_{1,h}$ for some $C > 0$, can also be established using the Cauchy-Schwarz inequality and the same trace inequalities. Each term in the definition of $a_h$ is bounded by products of norms that are controlled by $\\|u_h\\|_{1,h}$ and $\\|v_h\\|_{1,h}$.\n\nFinally, the continuity of the linear functional $L(v_h)$ is shown by Cauchy-Schwarz and a discrete Poincaré-Friedrichs inequality, which guarantees that $\\|v_h\\|_{L^2(\\Omega)}$ is bounded by $\\|v_h\\|_{1,h}$ due to the homogeneous Dirichlet boundary conditions enforced weakly by the SIPG scheme.\n\nSince all conditions of the Lax-Milgram theorem are met, the existence and uniqueness of the SIPG solution $u_h \\in V_h$ are guaranteed.",
            "answer": "$$\\boxed{2 C_{\\mathrm{tr}} N_{f}}$$"
        },
        {
            "introduction": "This practice bridges the gap between the abstract framework of functional analysis and the concrete world of computational science. The Lax-Milgram theorem is deeply connected to the Riesz representation theorem, which states that every continuous linear functional on a Hilbert space corresponds to a unique element in that space. This exercise  invites you to numerically explore this connection by framing the solution to a variational problem as the Riesz representer of the right-hand-side functional in the \"energy\" inner product defined by the bilinear form, offering tangible insight into the geometric structure of the solution space.",
            "id": "3395440",
            "problem": "Consider the variational problem on the real interval $[-1,1]$ with the Hilbert space $V = H_0^1(-1,1)$, equipped with a bilinear form $a(\\cdot,\\cdot)$ defined by\n$$\na(u,v) = \\int_{-1}^1 \\left( \\alpha(x)\\, u'(x)\\, v'(x) + \\beta(x)\\, u(x)\\, v(x) \\right)\\, dx,\n$$\nwhere $\\alpha(x)$ and $\\beta(x)$ are given real-valued functions with $\\alpha(x) \\ge \\alpha_0 > 0$ and $\\beta(x) \\ge 0$ for all $x \\in [-1,1]$. Let $f \\in V^\\ast$ be a bounded linear functional, specified by a function $g(x)$ through\n$$\nf(v) = \\int_{-1}^1 g(x)\\, v(x)\\, dx.\n$$\nBy the Lax–Milgram theorem and the Riesz representation theorem, for symmetric and coercive $a(\\cdot,\\cdot)$ the unique solution $u \\in V$ to\n$$\na(u,v) = f(v) \\quad \\text{for all } v \\in V\n$$\ncan be identified as the Riesz representer of $f$ in the energy inner product $a(\\cdot,\\cdot)$, that is, $u = R^{-1} f$ where $R: V \\to V^\\ast$ is the Riesz isomorphism induced by $a(\\cdot,\\cdot)$.\n\nYour task is to implement a numerical probe of this viewpoint within a spectral and discontinuous Galerkin methods setting using the following finite-dimensional subspaces. Let $\\{L_n(x)\\}_{n\\ge 0}$ denote the Legendre polynomials on $[-1,1]$. Define the polynomial basis that enforces homogeneous Dirichlet boundary conditions by\n$$\n\\phi_n(x) = L_{n+1}(x) - L_{n-1}(x), \\quad n = 1,2,\\dots,N,\n$$\nwhich satisfies $\\phi_n(\\pm 1) = 0$, and take $V_N = \\operatorname{span}\\{\\phi_1,\\dots,\\phi_N\\} \\subset V$. You will discretize the bilinear form $a(\\cdot,\\cdot)$ and the linear functional $f(\\cdot)$ on $V_N$, and you will construct an $a(\\cdot,\\cdot)$-orthonormal spectral basis to test the Riesz representer structure.\n\nFundamental base you may assume:\n- Definitions of Hilbert spaces, bilinear forms, and inner products.\n- The Lax–Milgram theorem for symmetric, bounded, coercive bilinear forms on Hilbert spaces.\n- The Riesz representation theorem and the notion of the Riesz isomorphism.\n\nYou must implement the following numerical steps for each test case:\n1. Assemble the Gram matrix $G \\in \\mathbb{R}^{N \\times N}$ with entries $G_{ij} = a(\\phi_i,\\phi_j)$.\n2. Assemble the Hilbert space Gram matrix $S \\in \\mathbb{R}^{N \\times N}$ for the $H^1$ inner product $(u,v)_V = \\int_{-1}^1 \\left(u'(x) v'(x) + u(x) v(x)\\right)\\, dx$, with entries $S_{ij} = (\\phi_i,\\phi_j)_V$.\n3. Assemble the load vector $F \\in \\mathbb{R}^N$ with entries $F_i = f(\\phi_i) = \\int_{-1}^1 g(x)\\, \\phi_i(x)\\, dx$.\n4. Form an $a(\\cdot,\\cdot)$-orthonormal spectral basis $\\{\\psi_j\\}_{j=1}^N$ by computing a linear transformation $U \\in \\mathbb{R}^{N \\times N}$ such that\n$$\n\\psi_j = \\sum_{i=1}^N U_{ij}\\, \\phi_i, \\quad \\text{and} \\quad a(\\psi_i,\\psi_j) = \\delta_{ij}.\n$$\n5. Compute the following diagnostics:\n   - The orthonormality defect in the energy inner product,\n     $$\n     \\delta = \\|U^\\top G U - I\\|_2,\n     $$\n     where $\\|\\cdot\\|_2$ is the spectral norm and $I$ is the identity matrix of size $N$.\n   - The Riesz-representer coefficient consistency defect. Let $c^{(1)} \\in \\mathbb{R}^N$ solve the discrete variational problem $G c^{(1)} = F$ in the basis $\\{\\phi_i\\}$. Let $c^{(2)} = U \\left(U^\\top F\\right)$. Report\n     $$\n     \\varepsilon = \\frac{\\|c^{(1)} - c^{(2)}\\|_2}{\\|c^{(1)}\\|_2}.\n     $$\n   - The variational residual in the energy-orthonormal basis,\n     $$\n     \\rho = \\|U^\\top (G c^{(1)} - F)\\|_2.\n     $$\n   - The discrete coercivity and continuity constants of $a(\\cdot,\\cdot)$ with respect to the $H^1$-inner-product norm on $V_N$, estimated as the extreme generalized eigenvalues of the pair $(G,S)$:\n     $$\n     \\alpha_N = \\min_{\\mathbf{c}\\neq 0} \\frac{\\mathbf{c}^\\top G \\mathbf{c}}{\\mathbf{c}^\\top S \\mathbf{c}}, \\qquad\n     L_N = \\max_{\\mathbf{c}\\neq 0} \\frac{\\mathbf{c}^\\top G \\mathbf{c}}{\\mathbf{c}^\\top S \\mathbf{c}}.\n     $$\n6. Use Gauss–Legendre quadrature of sufficiently high order to approximate all integrals on $[-1,1]$. All trigonometric functions must use angles in radians.\n\nTest Suite:\nImplement the above for the following four test cases, each specified by $(N,\\alpha(x),\\beta(x),g(x))$:\n- Case A (happy path): $N=8$, $\\alpha(x) = 1 + \\tfrac{1}{2} x^2$, $\\beta(x) = 1$, $g(x) = \\sin(\\pi x) + x$.\n- Case B (small dimension; stiffness-dominated): $N=2$, $\\alpha(x) = 1$, $\\beta(x) = 0$, $g(x) = 1 - x^2$.\n- Case C (high contrast coefficients): $N=12$, $\\alpha(x) = 2 + 10 x^2$, $\\beta(x) = 0.1 + 0.5 x^2$, $g(x) = e^{x}$.\n- Case D (oscillatory coefficients and data): $N=10$, $\\alpha(x) = 1 + 0.2 \\cos(3\\pi x)$, $\\beta(x) = 0.5$, $g(x) = \\cos(2\\pi x)$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of four lists, one per test case, in the order A, B, C, D. Each inner list must contain five floating-point numbers in the order $[\\delta,\\varepsilon,\\rho,\\alpha_N,L_N]$.\n- For example, the printed string must look like\n$$\n\\texttt{[[dA,eA,rA,aA,LA],[dB,eB,rB,aB,LB],[dC,eC,rC,aC,LC],[dD,eD,rD,aD,LD]]}\n$$\nwith actual numerical values substituted. No physical units are involved in this problem, and all angles are in radians.",
            "solution": "The problem statement is a valid, well-posed exercise in numerical analysis, specifically within the field of spectral Galerkin methods for solving elliptic partial differential equations. It asks for a numerical implementation to explore the connection between the solution of a variational problem and the Riesz representation theorem. All provided data and definitions are mathematically and scientifically sound. We proceed with the solution.\n\nThe core of the problem is to find a numerical approximation to the solution $u \\in V = H_0^1(-1,1)$ of the variational equation\n$$\na(u,v) = f(v) \\quad \\text{for all } v \\in V,\n$$\nwhere the bilinear form $a(\\cdot,\\cdot)$ and the linear functional $f(\\cdot)$ are given by\n$$\na(u,v) = \\int_{-1}^1 \\left( \\alpha(x)\\, u'(x)\\, v'(x) + \\beta(x)\\, u(x)\\, v(x) \\right)\\, dx,\n$$\n$$\nf(v) = \\int_{-1}^1 g(x)\\, v(x)\\, dx.\n$$\nThe conditions $\\alpha(x) \\ge \\alpha_0 > 0$ and $\\beta(x) \\ge 0$ ensure that $a(\\cdot,\\cdot)$ is a symmetric, coercive, and bounded bilinear form on $V$. Coercivity follows from the Poincaré inequality on $H_0^1(-1,1)$, making $a(\\cdot,\\cdot)$ an inner product, referred to as the energy inner product. The existence and uniqueness of the solution $u$ are guaranteed by the Lax–Milgram theorem.\n\nWe employ a spectral Galerkin method by seeking an approximate solution $u_N$ in a finite-dimensional subspace $V_N \\subset V$. The subspace $V_N$ is spanned by a set of $N$ basis functions $\\{\\phi_n\\}_{n=1}^N$ that satisfy the homogeneous Dirichlet boundary conditions. The chosen basis is\n$$\n\\phi_n(x) = L_{n+1}(x) - L_{n-1}(x), \\quad n=1, \\dots, N,\n$$\nwhere $L_k(x)$ is the Legendre polynomial of degree $k$. The property $L_k(\\pm 1) = (\\pm 1)^k$ ensures that $\\phi_n(\\pm 1) = 0$ for all $n \\ge 1$, so $V_N \\subset H_0^1(-1,1)$. A crucial property for computation is the simple form of the derivative of these basis functions, which follows from a standard recurrence relation for Legendre polynomials:\n$$\n\\phi_n'(x) = \\frac{d}{dx}\\left(L_{n+1}(x) - L_{n-1}(x)\\right) = (2n+1)L_n(x).\n$$\nThis simplification is valid for $n \\ge 1$. For $n=1$, it relies on interpreting the basis function as $\\phi_1(x) = L_2(x)-L_0(x)$, which is consistent with the derivative formula.\n\nThe approximate solution is written as a linear combination of basis functions, $u_N(x) = \\sum_{j=1}^N c_j \\phi_j(x)$. Substituting this into the variational problem and choosing the test functions to be the basis functions themselves, $v = \\phi_i(x)$ for $i=1,\\dots,N$, we obtain the Galerkin system of linear equations:\n$$\n\\sum_{j=1}^N a(\\phi_j, \\phi_i) c_j = f(\\phi_i), \\quad i=1,\\dots,N.\n$$\nThis is a matrix system $G \\mathbf{c}^{(1)} = F$, where $\\mathbf{c}^{(1)} \\in \\mathbb{R}^N$ is the vector of unknown coefficients, $G \\in \\mathbb{R}^{N \\times N}$ is the Gram matrix (or stiffness matrix), and $F \\in \\mathbb{R}^N$ is the load vector. Their entries are given by:\n$$\nG_{ij} = a(\\phi_i, \\phi_j) = \\int_{-1}^1 \\left( \\alpha(x) \\phi_i'(x) \\phi_j'(x) + \\beta(x) \\phi_i(x) \\phi_j(x) \\right) dx,\n$$\n$$\nF_i = f(\\phi_i) = \\int_{-1}^1 g(x) \\phi_i(x) dx.\n$$\nThe problem uses $1$-based indexing for basis functions and matrix entries. In the implementation, we use $0$-based indexing for arrays, so matrix entry $(i,j)$ will correspond to basis functions $\\phi_{i+1}$ and $\\phi_{j+1}$.\n\nThe integrals defining $G$ and $F$ involve non-polynomial functions $\\alpha(x)$, $\\beta(x)$, and $g(x)$, and are computed numerically using Gauss-Legendre quadrature. A quadrature rule with $Q$ points and weights $\\{w_k, x_k\\}_{k=1}^Q$ approximates an integral as $\\int_{-1}^1 h(x) dx \\approx \\sum_{k=1}^Q h(x_k) w_k$. To ensure high accuracy, the number of points $Q$ is chosen to be sufficiently large, e.g., $Q > 2(N+1)$, to handle the polynomial part of the integrands exactly.\n\nThe central task is to relate the direct solution of $G \\mathbf{c}^{(1)} = F$ to the Riesz representation viewpoint. According to the Riesz representation theorem, the solution $u$ is the unique element in $V$ such that $a(u,v) = f(v)$ for all $v \\in V$. This means $u$ is the Riesz representer of the functional $f$ with respect to the energy inner product $a(\\cdot,\\cdot)$. To see this numerically, we construct an $a(\\cdot,\\cdot)$-orthonormal basis $\\{\\psi_j\\}_{j=1}^N$ for $V_N$. Let each new basis function be a linear combination of the old ones: $\\psi_j = \\sum_{i=1}^N U_{ij} \\phi_i$. The orthonormality condition $a(\\psi_i, \\psi_j) = \\delta_{ij}$ imposes the matrix condition $U^\\top G U = I$, where $U$ is the change-of-basis matrix. Since $G$ is symmetric and positive definite, such a matrix $U$ can be constructed from the eigenvalue decomposition of $G = Q \\Lambda Q^\\top$, where $Q$ is orthogonal and $\\Lambda$ is diagonal with positive eigenvalues. The transformation matrix is $U = Q \\Lambda^{-1/2}$.\n\nWith this orthonormal basis, the solution $u_N$ can be expressed as $u_N = \\sum_{j=1}^N d_j \\psi_j$. The coefficients $d_j$ are simply the evaluation of the functional $f$ on the new basis vectors: $d_j = f(\\psi_j)$. In vector form, $\\mathbf{d} = U^\\top F$. To obtain the coefficients in the original basis $\\{\\phi_i\\}$, we transform back: $\\mathbf{c}^{(2)} = U \\mathbf{d} = U(U^\\top F)$. Mathematically, $G^{-1} = UU^\\top$, so $\\mathbf{c}^{(1)} = G^{-1}F$ and $\\mathbf{c}^{(2)} = UU^\\top F$ must be identical. The numerical diagnostics assess the fidelity of this equivalence.\n\nThe required calculations are as follows:\n1.  **Gram Matrices and Load Vector**: Assemble the matrices $G, S$ and vector $F$ using numerical quadrature. $S$ is the Gram matrix for the standard $H^1$ inner product, i.e., with $\\alpha(x)=1, \\beta(x)=1$.\n2.  **Orthonormal Basis**: Compute $U$ from the eigendecomposition of $G$.\n3.  **Diagnostics**:\n    - $\\delta = \\|U^\\top G U - I\\|_2$: This measures the numerical error in constructing the orthonormalizing transformation $U$. It should be close to machine precision.\n    - $\\varepsilon = \\frac{\\|\\mathbf{c}^{(1)} - \\mathbf{c}^{(2)}\\|_2}{\\|\\mathbf{c}^{(1)}\\|_2}$: This compares the coefficient vector from directly solving the linear system, $\\mathbf{c}^{(1)} = G^{-1}F$, with the one obtained via the Riesz representation procedure, $\\mathbf{c}^{(2)} = U U^\\top F$. This demonstrates the numerical equivalence of the two approaches.\n    - $\\rho = \\|U^\\top (G \\mathbf{c}^{(1)} - F)\\|_2$: This is the norm of the residual of the linear system, projected into the energy-orthonormal basis. Since $G \\mathbf{c}^{(1)} - F$ is ideally zero (up to numerical precision of the linear solve), $\\rho$ should be very small.\n    - $\\alpha_N, L_N$: These are the discrete coercivity and continuity constants of the bilinear form $a(\\cdot,\\cdot)$ on the subspace $V_N$ with respect to the $H^1$-norm. They are computed as the minimum and maximum generalized eigenvalues of the matrix pair $(G,S)$, corresponding to the extrema of the Rayleigh quotient $\\frac{\\mathbf{v}^\\top G \\mathbf{v}}{\\mathbf{v}^\\top S \\mathbf{v}} = \\frac{a(v_N, v_N)}{\\|v_N\\|_{H^1}^2}$ for $v_N \\in V_N$. These constants are crucial in the a priori error analysis of the Galerkin method.",
            "answer": "```python\nimport numpy as np\nimport scipy.special\nimport scipy.linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n\n    def compute_diagnostics(N, alpha_func, beta_func, g_func):\n        \"\"\"\n        Performs the numerical tasks for a single test case.\n        \n        Args:\n            N (int): The dimension of the polynomial subspace.\n            alpha_func (callable): The function alpha(x).\n            beta_func (callable): The function beta(x).\n            g_func (callable): The function g(x).\n            \n        Returns:\n            list: A list of five floats: [delta, epsilon, rho, alpha_N, L_N].\n        \"\"\"\n        # 1. Setup Quadrature\n        # A quadrature rule of degree Q is exact for polynomials of degree 2Q-1.\n        # The highest polynomial degree in integrands is roughly 2(N+1).\n        # We need 2Q-1 >= 2N+2, so Q >= N+1.5. A much safer choice is used.\n        Q = 3 * N + 1\n        x_q, w_q = np.polynomial.legendre.leggauss(Q)\n\n        # 2. Evaluate Basis Functions and derivatives at quadrature points\n        L_vals = np.zeros((Q, N + 2))\n        for k in range(N + 2):\n            L_vals[:, k] = scipy.special.eval_legendre(k, x_q)\n\n        PHI = np.zeros((Q, N))\n        DPHI = np.zeros((Q, N))\n        for i in range(N):\n            n = i + 1  # Basis functions are indexed from n=1 to N\n            # phi_n(x) = L_{n+1}(x) - L_{n-1}(x)\n            # For n=1, phi_1(x) = L_2(x) - L_0(x)\n            PHI[:, i] = L_vals[:, n + 1] - L_vals[:, n - 1]\n            \n            # phi'_n(x) = (2n+1)L_n(x)\n            DPHI[:, i] = (2 * n + 1) * L_vals[:, n]\n\n        # Evaluate coefficient functions at quadrature points\n        alpha_vals = alpha_func(x_q)\n        beta_vals = beta_func(x_q)\n        g_vals = g_func(x_q)\n\n        # 3. Assemble G, S, and F using vectorized operations\n        G = DPHI.T @ np.diag(w_q * alpha_vals) @ DPHI + PHI.T @ np.diag(w_q * beta_vals) @ PHI\n        S = DPHI.T @ np.diag(w_q) @ DPHI + PHI.T @ np.diag(w_q) @ PHI\n        F = PHI.T @ (w_q * g_vals)\n\n        # 4. Form the a-orthonormal basis transformation U\n        eigvals_G, eigvecs_G = scipy.linalg.eigh(G)\n        \n        # Guard against non-positive eigenvalues from numerical error\n        if np.any(eigvals_G <= 0):\n             eigvals_G[eigvals_G <= 0] = np.finfo(float).eps\n\n        Lambda_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals_G))\n        U = eigvecs_G @ Lambda_inv_sqrt\n\n        # 5. Compute diagnostics\n        # Orthonormality defect delta\n        I = np.identity(N)\n        delta = np.linalg.norm((U.T @ G @ U) - I, ord=2)\n\n        # Riesz-representer consistency defect epsilon\n        c1 = scipy.linalg.solve(G, F, assume_a='pos')\n        c2 = U @ (U.T @ F)\n        norm_c1 = np.linalg.norm(c1, ord=2)\n        if norm_c1 < 1e-15:\n            epsilon = np.linalg.norm(c1 - c2, ord=2)\n        else:\n            epsilon = np.linalg.norm(c1 - c2, ord=2) / norm_c1\n        \n        # Variational residual rho\n        residual = G @ c1 - F\n        rho = np.linalg.norm(U.T @ residual, ord=2)\n\n        # Discrete coercivity and continuity constants alpha_N, L_N\n        gen_eigvals = scipy.linalg.eigh(G, S, eigvals_only=True)\n        alpha_N = gen_eigvals[0]\n        L_N = gen_eigvals[-1]\n\n        return [delta, epsilon, rho, alpha_N, L_N]\n\n    test_cases = [\n        # Case A: N=8, alpha(x)=1+0.5x^2, beta(x)=1, g(x)=sin(pi*x)+x\n        {'N': 8, 'alpha': lambda x: 1 + 0.5 * x**2, 'beta': lambda x: 1.0, 'g': lambda x: np.sin(np.pi * x) + x},\n        # Case B: N=2, alpha(x)=1, beta(x)=0, g(x)=1-x^2\n        {'N': 2, 'alpha': lambda x: 1.0, 'beta': lambda x: 0.0, 'g': lambda x: 1 - x**2},\n        # Case C: N=12, alpha(x)=2+10x^2, beta(x)=0.1+0.5x^2, g(x)=e^x\n        {'N': 12, 'alpha': lambda x: 2 + 10 * x**2, 'beta': lambda x: 0.1 + 0.5 * x**2, 'g': lambda x: np.exp(x)},\n        # Case D: N=10, alpha(x)=1+0.2cos(3pi*x), beta(x)=0.5, g(x)=cos(2pi*x)\n        {'N': 10, 'alpha': lambda x: 1 + 0.2 * np.cos(3 * np.pi * x), 'beta': lambda x: 0.5, 'g': lambda x: np.cos(2 * np.pi * x)}\n    ]\n    \n    results = []\n    for case in test_cases:\n        res = compute_diagnostics(case['N'], case['alpha'], case['beta'], case['g'])\n        results.append(res)\n    \n    # Format the final output string as specified: [[...],[...],...]\n    print(str(results).replace(' ', ''))\n\nsolve()\n```"
        }
    ]
}