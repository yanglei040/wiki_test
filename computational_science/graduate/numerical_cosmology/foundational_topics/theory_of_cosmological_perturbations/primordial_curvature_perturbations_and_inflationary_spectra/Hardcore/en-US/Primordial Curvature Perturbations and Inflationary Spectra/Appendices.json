{
    "hands_on_practices": [
        {
            "introduction": "The evolution of primordial perturbations from their quantum vacuum origin to classical superhorizon fluctuations is governed by the Mukhanov-Sasaki equation. This first practice provides a direct numerical encounter with this cornerstone of modern cosmology. By solving the equation for a single mode, you will witness the phenomenon of 'freeze-out' as the perturbation exits the horizon and gain a quantitative understanding of the near-conservation of the comoving curvature perturbation $\\mathcal{R}_k$ on superhorizon scales in simple models, as well as how this conservation can be violated in more complex scenarios .",
            "id": "3482626",
            "problem": "You are tasked with constructing a numerical experiment to evolve the comoving curvature perturbation mode $\\mathcal{R}_k$ across horizon exit during inflation for two scenarios: an adiabatic single-field case and a mildly non-adiabatic two-field-inspired case. The goal is to quantify deviations from conservation of $\\mathcal{R}_k$ as a function of the comoving wavenumber $k$, using a scientifically justified toy model that captures the dominant physics near and after horizon exit.\n\nUse the following fundamental base:\n\n- The Mukhanov–Sasaki equation for the canonically normalized variable $u_k = z \\mathcal{R}_k$ in conformal time $\\eta$ for a quasi-de Sitter background is\n$$\nu_k'' + \\left(c_s^2 k^2 - \\frac{z''}{z}\\right) u_k = 0 ,\n$$\nwith primes denoting differentiation with respect to $\\eta$. For canonical single-field slow-roll inflation with constant slow-roll parameter $\\epsilon \\ll 1$ and constant Hubble rate $H$, adopt $c_s = 1$ and $a(\\eta) = -\\frac{1}{H \\eta}$ for $\\eta  0$. In reduced Planck units (reduced Planck mass equal to unity), let\n$$\nz(\\eta) = a(\\eta) \\sqrt{2 \\epsilon}, \\quad \\text{so that} \\quad \\frac{z''}{z} = \\frac{2}{\\eta^2}.\n$$\n\n- Deep inside the horizon ($k |\\eta| \\gg 1$), initialize the mode in the Bunch–Davies vacuum:\n$$\nu_k(\\eta_i) \\approx \\frac{e^{-i k \\eta_i}}{\\sqrt{2 k}}, \\quad u_k'(\\eta_i) \\approx -i k \\, u_k(\\eta_i),\n$$\nat a suitably early initial conformal time $\\eta_i$ satisfying $k |\\eta_i| \\gg 1$.\n\n- Horizon crossing occurs when $k = a H$, which for the adopted background occurs at $\\eta_\\text{cross} = -\\frac{1}{k}$.\n\n- For the adiabatic case, evolve $u_k$ using the homogeneous Mukhanov–Sasaki equation, compute $\\mathcal{R}_k = u_k / z$, and quantify the fractional change in amplitude across horizon exit from $\\eta_\\text{cross}$ to a fixed late time $\\eta_\\text{late}$ after horizon exit:\n$$\n\\Delta_{\\text{ad}}(k) = \\frac{\\left|\\mathcal{R}_k(\\eta_\\text{late})\\right| - \\left|\\mathcal{R}_k(\\eta_\\text{cross})\\right|}{\\left|\\mathcal{R}_k(\\eta_\\text{cross})\\right|}.\n$$\n\n- For the mildly non-adiabatic case, model a small super-horizon transfer from isocurvature to curvature due to a constant turn-rate in field space. After computing $\\left|\\mathcal{R}_k(\\eta_\\text{cross})\\right|$ as above, assume an isocurvature amplitude $S_k(N_\\text{cross}) = \\sigma \\left|\\mathcal{R}_k(\\eta_\\text{cross})\\right|$ at horizon crossing, with $\\sigma \\ll 1$ a small ratio. For $N$ the number of e-folds, use a standard super-horizon phenomenological coupling\n$$\n\\frac{d \\mathcal{R}_k}{dN} \\approx 2 \\Theta \\, S_k, \\quad \\frac{d S_k}{dN} \\approx -\\mu \\, S_k ,\n$$\nwhere $\\Theta$ is the constant turn-rate (in units of the Hubble rate) and $\\mu > 0$ is the entropy decay rate. Over $\\Delta N$ e-folds from $\\eta_\\text{cross}$ to $\\eta_\\text{late}$, this yields an additive change in the amplitude\n$$\n\\delta \\mathcal{R}_k \\approx \\frac{2 \\Theta}{\\mu} S_k(N_\\text{cross}) \\left(1 - e^{-\\mu \\Delta N}\\right),\n$$\nwith $\\Delta N = \\ln\\left(\\frac{a(\\eta_\\text{late})}{a(\\eta_\\text{cross})}\\right) = \\ln\\left(\\frac{|\\eta_\\text{cross}|}{|\\eta_\\text{late}|}\\right)$ for the adopted background. Define the fractional deviation for the non-adiabatic case as\n$$\n\\Delta_{\\text{nonad}}(k) = \\frac{\\left(\\left|\\mathcal{R}_k(\\eta_\\text{late})\\right| + \\delta \\mathcal{R}_k\\right) - \\left|\\mathcal{R}_k(\\eta_\\text{cross})\\right|}{\\left|\\mathcal{R}_k(\\eta_\\text{cross})\\right|}.\n$$\n\nNumerical and modeling instructions:\n\n- Work entirely in reduced Planck units with $H = 1$, so all quantities are dimensionless.\n- Use $\\epsilon = 0.01$, $\\Theta = 0.01$, $\\mu = 0.2$, $\\sigma = 0.05$.\n- For each comoving wavenumber $k$ in the test suite below, integrate the Mukhanov–Sasaki equation from $\\eta_i = -\\frac{50}{k}$ to $\\eta_\\text{cross} = -\\frac{1}{k}$, then continue to $\\eta_\\text{late} = -10^{-3}$. Use the initial conditions given above at $\\eta_i$. Compute $\\Delta_{\\text{ad}}(k)$ and $\\Delta_{\\text{nonad}}(k)$ as defined above.\n- All angles, if any arise, must be in radians. However, the requested outputs are dimensionless floats; no physical units are required in the final answer.\n\nTest suite:\n\n- Use $k \\in \\{0.05, 0.5, 5.0, 50.0\\}$, which probes late crossing, typical crossing, and early crossing, covering a boundary at very small $k$ and an edge at very large $k$.\n\nFinal output specification:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[\\Delta_{\\text{ad}}(0.05), \\Delta_{\\text{nonad}}(0.05), \\Delta_{\\text{ad}}(0.5), \\Delta_{\\text{nonad}}(0.5), \\Delta_{\\text{ad}}(5.0), \\Delta_{\\text{nonad}}(5.0), \\Delta_{\\text{ad}}(50.0), \\Delta_{\\text{nonad}}(50.0)].\n$$\nEach entry must be a floating-point number.",
            "solution": "The algorithm solves the problem by numerically integrating the Mukhanov-Sasaki equation for the complex mode function $u_k(\\eta)$. The second-order ODE, $u_k'' + (k^2 - 2/\\eta^2) u_k = 0$, is decoupled into two identical real-valued ODEs for the real and imaginary parts of $u_k$. Each is converted into a system of two first-order ODEs and solved using a standard adaptive Runge-Kutta integrator. For each wavenumber $k$, the integration starts at a deep sub-horizon time $\\eta_i = -50/k$ with Bunch-Davies initial conditions for $u_k(\\eta_i)$ and $u_k'(\\eta_i)$. The integration proceeds until a late super-horizon time $\\eta_{\\text{late}}$, with the solution being recorded at two key moments: horizon crossing ($\\eta_{\\text{cross}} = -1/k$) and $\\eta_{\\text{late}}$. From the numerical solution for $u_k$, the comoving curvature perturbation $\\mathcal{R}_k = u_k/z$ is calculated using the background function $z(\\eta) = a(\\eta)\\sqrt{2\\epsilon}$. The magnitude $|\\mathcal{R}_k|$ is computed at $\\eta_{\\text{cross}}$ and $\\eta_{\\text{late}}$. The fractional change for the adiabatic case, $\\Delta_{\\text{ad}}(k)$, is then calculated directly from these values. For the non-adiabatic case, an additional contribution $\\delta\\mathcal{R}_k$ is computed based on the provided phenomenological model of isocurvature conversion. This contribution depends on the number of e-folds $\\Delta N = \\ln(|\\eta_{\\text{cross}}|/|\\eta_{\\text{late}}|)$. The final non-adiabatic deviation, $\\Delta_{\\text{nonad}}(k)$, is found by adding the normalized contribution $\\delta\\mathcal{R}_k/|\\mathcal{R}_k(\\eta_{\\text{cross}})|$ to $\\Delta_{\\text{ad}}(k)$. This process is repeated for all specified values of $k$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Solves for the fractional change in the comoving curvature perturbation R_k\n    for both adiabatic and non-adiabatic scenarios across a range of wavenumbers k.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (epsilon, Theta, mu, sigma, H, wavenumbers)\n        (0.01, 0.01, 0.2, 0.05, 1.0, [0.05, 0.5, 5.0, 50.0])\n    ]\n\n    for case in test_cases:\n        epsilon, Theta, mu, sigma, H, k_values = case\n        \n        results = []\n\n        # Pre-compute constants to optimize the loop\n        sqrt_2_epsilon = np.sqrt(2.0 * epsilon)\n        cos50 = np.cos(50.0)\n        sin50 = np.sin(50.0)\n        non_ad_coeff = (2.0 * Theta * sigma) / mu\n\n        def mukhanov_sasaki_system(eta, y, k):\n            \"\"\"\n            Defines the system of first-order ODEs for the Mukhanov-Sasaki equation.\n            y[0] = u_k, y[1] = u_k'\n            The equation is u_k'' + (k^2 - 2/eta^2) * u_k = 0\n            \"\"\"\n            potential = k**2 - 2.0 / eta**2\n            return [y[1], -potential * y[0]]\n\n        for k in k_values:\n            # 1. Define integration and evaluation time points\n            eta_i = -50.0 / k\n            eta_cross = -1.0 / k\n            eta_late = -1.0e-3\n            \n            # 2. Set up initial conditions based on the Bunch-Davies vacuum approximation\n            # The normalization factor 1/sqrt(2k)\n            norm = 1.0 / np.sqrt(2.0 * k)\n            \n            # Real part of u_k and its derivative\n            uR_i = cos50 * norm\n            uR_prime_i = k * sin50 * norm\n            y0_R = [uR_i, uR_prime_i]\n\n            # Imaginary part of u_k and its derivative\n            uI_i = sin50 * norm\n            uI_prime_i = -k * cos50 * norm\n            y0_I = [uI_i, uI_prime_i]\n\n            # 3. Points in time where the solution is to be evaluated\n            t_eval_points = [eta_cross, eta_late]\n\n            # 4. Numerically integrate the ODE for both real and imaginary parts\n            sol_R = solve_ivp(\n                fun=mukhanov_sasaki_system,\n                t_span=(eta_i, eta_late),\n                y0=y0_R,\n                t_eval=t_eval_points,\n                args=(k,),\n                method='RK45',\n                rtol=1e-12,\n                atol=1e-12\n            )\n\n            sol_I = solve_ivp(\n                fun=mukhanov_sasaki_system,\n                t_span=(eta_i, eta_late),\n                y0=y0_I,\n                t_eval=t_eval_points,\n                args=(k,),\n                method='RK45',\n                rtol=1e-12,\n                atol=1e-12\n            )\n\n            # 5. Extract the solutions at eta_cross and eta_late\n            uR_at_eval_points = sol_R.y[0]\n            uI_at_eval_points = sol_I.y[0]\n\n            # 6. Reconstruct the magnitude of u_k\n            u_mag_cross = np.sqrt(uR_at_eval_points[0]**2 + uI_at_eval_points[0]**2)\n            u_mag_late = np.sqrt(uR_at_eval_points[1]**2 + uI_at_eval_points[1]**2)\n\n            # 7. Calculate the magnitude of R_k = u_k / z\n            # |z(eta)| = sqrt(2*epsilon) / |eta| since H=1\n            z_mag_cross = sqrt_2_epsilon / abs(eta_cross)\n            z_mag_late = sqrt_2_epsilon / abs(eta_late)\n            \n            R_k_mag_cross = u_mag_cross / z_mag_cross\n            R_k_mag_late = u_mag_late / z_mag_late\n            \n            # 8. Compute the fractional change for the adiabatic case\n            delta_ad = (R_k_mag_late - R_k_mag_cross) / R_k_mag_cross\n            results.append(delta_ad)\n\n            # 9. Compute the fractional change for the non-adiabatic case\n            # The number of e-folds between horizon crossing and late time\n            delta_N = np.log(abs(eta_cross) / abs(eta_late))\n            \n            # The super-horizon contribution to R_k, normalized by |R_k(cross)|\n            non_ad_term = non_ad_coeff * (1.0 - np.exp(-mu * delta_N))\n            \n            delta_nonad = delta_ad + non_ad_term\n            results.append(delta_nonad)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Accurate numerical simulations hinge on correctly implementing initial conditions. Since the Bunch-Davies vacuum is an asymptotic state in the infinite past, any practical calculation must begin at a finite, subhorizon scale. This exercise delves into this crucial aspect of numerical cosmology, tasking you with quantifying the error introduced by this approximation and establishing a convergence criterion. Through this practice, you will develop a practical feel for the trade-off between computational cost and accuracy, particularly when simulating models with non-trivial features in their dynamics .",
            "id": "3482615",
            "problem": "You are asked to quantify and calibrate the accuracy loss in numerically computing the primordial curvature power spectrum when the Mukhanov–Sasaki mode functions are initialized at a finite subhorizon ratio $X_0 \\equiv k/(aH)$ rather than in the exact infinite-subhorizon limit. Your task is to write a complete, runnable program that, for a prescribed family of background dynamics given by $z''/z(\\tau)$, determines the minimal $X_0$ that achieves less than $0.001$ fractional error in $P_{\\mathcal{R}}(k)$ relative to a high-fidelity reference computed with a much larger $X_{\\mathrm{ref}}$.\n\nBase equations and modeling assumptions:\n- The primordial curvature perturbation mode is defined by $v_k(\\tau)$ satisfying the Mukhanov–Sasaki equation\n$$\nv_k''(\\tau) + \\Big(k^2 - \\frac{z''(\\tau)}{z(\\tau)}\\Big) v_k(\\tau) = 0,\n$$\nwith $'$ denoting derivatives with respect to conformal time $\\tau$.\n- The curvature perturbation is $ \\mathcal{R}_k(\\tau) = v_k(\\tau)/z(\\tau)$, and its power spectrum at freeze-out is\n$$\nP_{\\mathcal{R}}(k) = \\frac{k^3}{2\\pi^2} \\left| \\mathcal{R}_k(\\tau_{\\mathrm{end}}) \\right|^2.\n$$\n- The subhorizon Bunch–Davies initial condition is imposed at a finite $\\tau_0$ where $X_0 \\equiv k/(aH)$ has a specified value. In the deep subhorizon regime, the initial condition is\n$$\nv_k(\\tau_0) = \\frac{e^{-i k \\tau_0}}{\\sqrt{2k}}, \\quad v_k'(\\tau_0) = -i \\sqrt{\\frac{k}{2}} e^{-i k \\tau_0}.\n$$\n- We adopt units in which the reduced Planck mass, the speed of light, and the Hubble constant scale are set to unity: $M_{\\mathrm{Pl}} = c = \\hbar = H_0 = 1$. All quantities in the program are dimensionless.\n- We assume a constant early-time first slow-roll parameter $\\epsilon_0 \\in (0,1)$, and the conformal time to Hubble crossing mapping for constant $\\epsilon_0$,\n$$\naH = -\\frac{1}{(1-\\epsilon_0)\\,\\tau}, \\quad \\Rightarrow \\quad \\frac{k}{aH} = -k(1-\\epsilon_0)\\,\\tau.\n$$\nHence, the initialization time corresponding to a target $X_0$ is\n$$\n\\tau_0 = -\\frac{X_0}{(1-\\epsilon_0)\\,k}.\n$$\nWe evaluate the spectrum at a late time $\\tau_{\\mathrm{end}}$ for which $X_{\\mathrm{end}} \\equiv k/(aH) = 10^{-3}$, i.e.,\n$$\n\\tau_{\\mathrm{end}} = -\\frac{X_{\\mathrm{end}}}{(1-\\epsilon_0)\\,k}.\n$$\n\nBackground specification:\n- Define a baseline background with constant $\\epsilon_0$, for which\n$$\na(\\tau) \\propto (-\\tau)^{p}, \\quad p \\equiv -\\frac{1}{1-\\epsilon_0}.\n$$\n- Define\n$$\nz(\\tau) = (-\\tau)^{p}\\,\\Big(1 + g_b(\\tau)\\Big),\n$$\nwhere the feature function $g_b(\\tau)$ is a localized, log-normal shaped bump in $\\ln(-\\tau)$,\n$$\ng_b(\\tau) = A \\exp\\!\\left[-\\frac{1}{2}\\left(\\frac{s(\\tau)}{\\sigma}\\right)^2\\right], \\quad s(\\tau) \\equiv \\ln\\!\\left(\\frac{-\\tau}{\\tau_f}\\right),\n$$\nwith amplitude $A$ and width $\\sigma$. The feature is centered at $\\tau_f \\equiv 1/k$ so that the feature sits near horizon crossing for mode $k$.\n- For this $z(\\tau)$, one can show\n$$\n\\frac{z''}{z}(\\tau) = \\frac{1}{\\tau^2}\\left[ p(p-1) + \\frac{g_b}{1+g_b}\\left(\\frac{s^2}{\\sigma^4} - \\frac{1-s}{\\sigma^2} - \\frac{2 p s}{\\sigma^2}\\right) \\right],\n$$\nwhere $g_b = g_b(\\tau)$ and $s = s(\\tau)$. When $A=0$, this reduces to $\\frac{z''}{z} = \\frac{p(p-1)}{\\tau^2}$.\n\nNumerical task:\n- For each test case below, you must:\n  1. Compute a high-fidelity reference $P_{\\mathcal{R}}^{\\mathrm{ref}}(k)$ by integrating from $\\tau_{\\mathrm{ref}} = -X_{\\mathrm{ref}}/[(1-\\epsilon_0)k]$ with $X_{\\mathrm{ref}} = 2000$ down to $\\tau_{\\mathrm{end}}$.\n  2. For a set of candidate initialization ratios $X_0 \\in \\{5, 10, 20, 50, 100, 200, 500, 1000\\}$, compute $P_{\\mathcal{R}}(k; X_0)$ and the fractional error\n     $$\n     \\Delta(X_0) \\equiv \\left| \\frac{P_{\\mathcal{R}}(k; X_0) - P_{\\mathcal{R}}^{\\mathrm{ref}}(k)}{P_{\\mathcal{R}}^{\\mathrm{ref}}(k)} \\right|.\n     $$\n  3. Determine the minimal $X_0$ that satisfies $\\Delta(X_0)  0.001$. If none of the candidates satisfies the criterion, return $-1$ for that test case.\n\nScientific basis:\n- Start from the Mukhanov–Sasaki equation, the definition of the curvature perturbation and its power, the subhorizon Bunch–Davies initial condition, and the mapping between $\\tau$ and $k/(aH)$ for constant $\\epsilon_0$.\n- Do not use target shortcuts; integrate the second-order equation as posed.\n- Angles do not appear in this problem.\n- All quantities in the program are dimensionless as specified.\n\nTest suite:\nProvide results for the following four test cases, with the feature center at $\\tau_f = 1/k$ in all cases:\n1. Case 1 (baseline, happy path): $\\epsilon_0 = 0.01$, $A = 0.0$, $\\sigma = 0.5$, $k = 0.1$.\n2. Case 2 (moderate feature near horizon crossing): $\\epsilon_0 = 0.01$, $A = 0.5$, $\\sigma = 0.3$, $k = 0.1$.\n3. Case 3 (larger slow-roll parameter): $\\epsilon_0 = 0.10$, $A = 0.0$, $\\sigma = 0.5$, $k = 1.0$.\n4. Case 4 (sharp feature and long-wavelength mode): $\\epsilon_0 = 0.01$, $A = 0.8$, $\\sigma = 0.1$, $k = 0.01$.\n\nAccuracy and output:\n- Your program must use a robust numerical ordinary differential equation solver with sufficiently tight tolerances to resolve the dynamics and produce a trustworthy reference baseline.\n- Your program should produce a single line of output containing the minimal $X_0$ for each test case, in the order listed above, as a comma-separated list enclosed in square brackets (e.g., \"[x1,x2,x3,x4]\"). Each entry must be an integer from the candidate set or $-1$ if no candidate satisfies the $0.001$ requirement.",
            "solution": "The solution is implemented by first defining a class to encapsulate the physical model, including methods for the background functions $z(\\tau)$ and $z''/z(\\tau)$. The core of the solution is a numerical integration of the complex-valued Mukhanov-Sasaki equation, $v_k'' + (k^2 - z''/z)v_k = 0$, which is treated as a system of two first-order ODEs for the state vector $[v_k, v_k']$. For each set of model parameters, a high-fidelity reference power spectrum, $P_{\\mathcal{R}}^{\\mathrm{ref}}$, is first computed by integrating from a very large initial subhorizon ratio, $X_{\\mathrm{ref}} = 2000$. The Bunch-Davies initial conditions are set at the corresponding initial conformal time $\\tau_{\\mathrm{ref}}$. The integration proceeds to a fixed late time $\\tau_{\\mathrm{end}}$ using a high-precision ODE solver. At $\\tau_{\\mathrm{end}}$, the mode function $v_k$ is used to calculate the curvature perturbation $\\mathcal{R}_k = v_k/z$ and finally the power spectrum $P_{\\mathcal{R}}$. The program then iterates through a set of smaller candidate initialization ratios $X_0$. For each $X_0$, the power spectrum is computed again, and the fractional error relative to the reference value is calculated. The first candidate $X_0$ for which this error falls below the specified threshold of $0.001$ is identified as the minimal required ratio for that test case. If no candidate meets the criterion, a value of -1 is returned. This procedure is repeated for each of the four test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n\n    class PrimordialSpectrumCalculator:\n        \"\"\"\n        A class to encapsulate the physics and numerical methods for computing\n        the primordial power spectrum for a given cosmological model.\n        \"\"\"\n        def __init__(self, epsilon_0, A, sigma, k):\n            self.epsilon_0 = float(epsilon_0)\n            self.A = float(A)\n            self.sigma = float(sigma)\n            self.k = float(k)\n\n            # Derived parameters from the model\n            self.p = -1.0 / (1.0 - self.epsilon_0)\n            self.tau_f = 1.0 / self.k\n            self.X_end = 1e-3\n            self.tau_end = -self.X_end / ((1.0 - self.epsilon_0) * self.k)\n\n        def _zpp_over_z(self, tau):\n            \"\"\"Computes the z''/z term in the Mukhanov-Sasaki equation.\"\"\"\n            if self.A == 0.0:\n                return (self.p * (self.p - 1.0)) / (tau**2)\n\n            s = np.log(-tau / self.tau_f)\n            g_b = self.A * np.exp(-0.5 * (s / self.sigma)**2)\n            \n            term1 = self.p * (self.p - 1.0)\n            \n            # This term can be zero if g_b is zero (as tau - -inf)\n            if g_b  1e-100: # Practically zero\n                 g_ratio_term = 0.0\n            else:\n                g_ratio = g_b / (1.0 + g_b)\n                bracket_term = (s**2 / self.sigma**4) - ((1.0 - s) / self.sigma**2) - (2.0 * self.p * s / self.sigma**2)\n                g_ratio_term = g_ratio * bracket_term\n            \n            potential = (1.0 / tau**2) * (term1 + g_ratio_term)\n            return potential\n\n        def _z_func(self, tau):\n            \"\"\"Computes the value of the background function z(tau).\"\"\"\n            if self.A == 0.0:\n                return (-tau)**self.p\n\n            s = np.log(-tau / self.tau_f)\n            g_b = self.A * np.exp(-0.5 * (s / self.sigma)**2)\n            return (-tau)**self.p * (1.0 + g_b)\n\n        def _ode_system(self, tau, y):\n            \"\"\"The system of first-order ODEs for [v, v'].\"\"\"\n            v, v_prime = y\n            potential_val = self._zpp_over_z(tau)\n            \n            # v'' = -(k^2 - z''/z) * v\n            dv_prime_dtau = -(self.k**2 - potential_val) * v\n            dv_dtau = v_prime\n            \n            return np.array([dv_dtau, dv_prime_dtau], dtype=complex)\n\n        def compute_power_spectrum(self, X_0):\n            \"\"\"\n            Solves the Mukhanov-Sasaki equation and computes the power spectrum\n            for a given initialization ratio X_0.\n            \"\"\"\n            tau_0 = -X_0 / ((1.0 - self.epsilon_0) * self.k)\n            \n            # Bunch-Davies initial conditions for the mode function\n            v0 = np.exp(-1j * self.k * tau_0) / np.sqrt(2.0 * self.k)\n            v0_prime = -1j * np.sqrt(self.k / 2.0) * np.exp(-1j * self.k * tau_0)\n            y0 = np.array([v0, v0_prime], dtype=complex)\n\n            t_span = [tau_0, self.tau_end]\n            \n            # Use a robust, high-precision ODE solver\n            sol = solve_ivp(\n                self._ode_system,\n                t_span,\n                y0,\n                method='DOP853',\n                rtol=1e-12,\n                atol=1e-12\n            )\n\n            # Extract final value of the mode function\n            v_end = sol.y[0, -1]\n            \n            z_at_end = self._z_func(self.tau_end)\n            \n            R_k_end = v_end / z_at_end\n            P_R = (self.k**3) / (2.0 * np.pi**2) * np.abs(R_k_end)**2\n            \n            return P_R\n            \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (epsilon_0, A, sigma, k)\n        (0.01, 0.0, 0.5, 0.1),   # Case 1\n        (0.01, 0.5, 0.3, 0.1),   # Case 2\n        (0.10, 0.0, 0.5, 1.0),   # Case 3\n        (0.01, 0.8, 0.1, 0.01),  # Case 4\n    ]\n\n    # Constants for the numerical task\n    X_ref = 2000.0\n    candidate_X0s = [5, 10, 20, 50, 100, 200, 500, 1000]\n    error_threshold = 0.001\n    \n    results = []\n    for case in test_cases:\n        epsilon_0, A, sigma, k = case\n        calculator = PrimordialSpectrumCalculator(epsilon_0, A, sigma, k)\n\n        # 1. Compute the high-fidelity reference value\n        p_r_ref = calculator.compute_power_spectrum(X_ref)\n\n        # 2. Search for the minimal X_0 that satisfies the error criterion\n        min_X0 = -1\n        for X0_candidate in candidate_X0s:\n            p_r_candidate = calculator.compute_power_spectrum(float(X0_candidate))\n            \n            if p_r_ref == 0:\n                # This case is physically unlikely and indicates a potential issue,\n                # but we handle it robustly.\n                error = np.inf if p_r_candidate != 0 else 0.0\n            else:\n                error = np.abs((p_r_candidate - p_r_ref) / p_r_ref)\n\n            if error  error_threshold:\n                min_X0 = X0_candidate\n                break\n        \n        results.append(min_X0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A numerically computed power spectrum is a discrete dataset, and its interpretation requires care, especially when the underlying theory predicts oscillatory features. This practice introduces a powerful paradigm: treating the power spectrum in logarithmic wavenumber space, $\\ln k$, as a signal to be analyzed. By applying fundamental concepts from signal processing, such as the Nyquist-Shannon sampling theorem and anti-aliasing filters, you will learn to identify and mitigate discretization artifacts, ensuring that the features you observe are physical and not numerical illusions .",
            "id": "3482622",
            "problem": "You are tasked with designing and implementing a complete, runnable program that quantifies and mitigates discretization artifacts in the sampling of a primordial curvature power spectrum. Work entirely in the logarithmic wavenumber variable, and treat the problem as a signal processing exercise over the logarithmic domain. Your program must adhere to the following mathematically precise specification.\n\nConsider the primordial comoving curvature perturbation power spectrum modeled by the oscillatory ansatz\n$$\nP_{\\mathcal{R}}(k) \\;=\\; A_s \\left(\\frac{k}{k_\\star}\\right)^{n_s-1}\\,\\Big[1 + A_{\\mathrm{osc}}\\;\\sin\\big(\\omega\\,\\ln(k/k_\\star) + \\phi\\big)\\Big],\n$$\nwhere $A_s$ is the amplitude, $n_s$ is the scalar tilt, $k_\\star$ is the pivot scale, $A_{\\mathrm{osc}}$ is the oscillation amplitude, $\\omega$ is the logarithmic frequency, and $\\phi$ is the phase. All angles in your calculations must be in radians. Treat all inputs and outputs as dimensionless except for the wavenumber, which you must treat in inverse megaparsecs; however, the program’s outputs will be dimensionless diagnostics.\n\nBase your reasoning and implementation on the following fundamental principles and well-tested facts:\n- In slow-roll inflation, the dimensionless primordial curvature power spectrum $P_{\\mathcal{R}}(k)$ is nearly power-law with small deviations introduced by features, which can be modeled as oscillations in $\\ln k$.\n- The Nyquist–Shannon sampling theorem states that a band-limited signal with maximum angular frequency $\\Omega_{\\max}$ (in radians per unit of the independent variable) can be recovered from uniform samples with spacing $\\Delta$ if and only if $\\Omega_{\\max} \\le \\pi/\\Delta$.\n- Discrete-time linear filtering in a uniformly sampled coordinate is commonly implemented by finite impulse response filters approximating an ideal low-pass response to mitigate aliasing before decimation.\n\nYou must work entirely in the logarithmic variable $x = \\ln k$ so that the oscillatory factor has the form $\\sin(\\omega x + \\phi)$, with angular frequency $\\omega$ measured in radians per unit $x$. Let $x_{\\min} = \\ln k_{\\min}$ and $x_{\\max} = \\ln k_{\\max}$. Let the fine reference grid be uniformly sampled with spacing $\\Delta x_{\\mathrm{ref}}$, and coarse grids be uniformly sampled with spacing $\\Delta x$ for several test cases.\n\nYour tasks:\n1. Define the reference spectrum on a fine uniform grid in $x$ with spacing $\\Delta x_{\\mathrm{ref}}$ across the interval $[x_{\\min}, x_{\\max}]$. This defines the high-fidelity “truth” $P_{\\mathcal{R}}^{\\mathrm{ref}}(x)$ sampled at points $x_i = x_{\\min} + i\\,\\Delta x_{\\mathrm{ref}}$ for integers $i$.\n2. Emulate coarse sampling by uniform decimation with an integer factor $r = \\Delta x / \\Delta x_{\\mathrm{ref}}$. To evaluate discretization effects, construct two reconstructions on a fine grid subset:\n   - A raw decimate-and-interpolate reconstruction $P_{\\mathcal{R}}^{\\mathrm{raw}}(x)$ by taking every $r$-th sample from the fine reference and performing piecewise linear interpolation back onto a fine subset of the domain to allow pointwise comparisons.\n   - An anti-aliased reconstruction $P_{\\mathcal{R}}^{\\mathrm{aa}}(x)$ formed by first applying a low-pass linear convolution filter with passband limited to angular cutoff $\\Omega_c = \\pi/\\Delta x$ (slightly reduced to ensure realizability), then decimating by factor $r$, and finally linearly interpolating back to the same fine subset.\n3. Quantify the reconstruction error in both cases using the relative root-mean-square error\n$$\n\\varepsilon = \\left(\\frac{\\sum_j\\big(P_{\\mathcal{R}}^{\\mathrm{rec}}(x_j) - P_{\\mathcal{R}}^{\\mathrm{ref}}(x_j)\\big)^2}{\\sum_j \\big(P_{\\mathcal{R}}^{\\mathrm{ref}}(x_j)\\big)^2}\\right)^{1/2},\n$$\nwhere the sum is over the fine-grid subset on which the reconstruction is defined.\n4. Estimate aliasing for each coarse sampling using the Nyquist–Shannon condition in the $x$-domain. Let the coarse Nyquist angular frequency be $\\Omega_N = \\pi/\\Delta x$. Predict whether aliasing will occur by checking if $\\omega  \\Omega_N$. Additionally, report the expected aliased angular frequency\n$$\n\\omega_{\\mathrm{alias}} = \\frac{1}{\\Delta x}\\,\\min\\Big(\\big(\\omega\\,\\Delta x \\bmod 2\\pi\\big),\\;2\\pi - \\big(\\omega\\,\\Delta x \\bmod 2\\pi\\big)\\Big),\n$$\nwhich lies in the interval $[0,\\Omega_N]$ and coincides with $\\omega$ when $\\omega \\le \\Omega_N$.\n5. Perform a convergence test by varying $\\Delta x$ at fixed $\\omega$, and a resolvability test by varying $\\omega$ at fixed $\\Delta x$. Demonstrate the benefit of anti-alias filtering by comparing the relative root-mean-square errors with and without prefiltering and report the improvement factor defined by\n$$\n\\mathcal{I} = \\frac{\\varepsilon_{\\mathrm{raw}}}{\\varepsilon_{\\mathrm{aa}}}.\n$$\n\nParameter specification for the spectrum and grids:\n- Use $A_s = 2.1\\times 10^{-9}$, $n_s = 0.965$, $k_\\star = 0.05$ in inverse megaparsecs, $A_{\\mathrm{osc}} = 0.1$, and $\\phi = 0$.\n- Use $k_{\\min} = 10^{-4}$ and $k_{\\max} = 1$ in inverse megaparsecs. All angular quantities are in radians.\n- Use a fine reference spacing $\\Delta x_{\\mathrm{ref}} = 0.001$.\n- Use linear interpolation for reconstruction from coarse to fine.\n- For anti-alias filtering, use a finite impulse response low-pass filter in the $x$-domain designed with a Hamming window. The normalized cutoff frequency relative to the fine-grid Nyquist must be $0.9/r$, and the filter length must be $8r+1$ taps. Apply the filter in zero-phase form before decimation.\n\nTest suite:\nImplement the above for the following set of test cases, where each case is a pair $(\\omega, \\Delta x)$ with $\\omega$ in radians per unit $x$ and $\\Delta x$ in units of $x$:\n- Case 1 (happy path, resolvable): $(\\omega, \\Delta x) = (30.0, 0.05)$.\n- Case 2 (strong aliasing): $(\\omega, \\Delta x) = (80.0, 0.05)$.\n- Case 3 (Nyquist boundary): $(\\omega, \\Delta x) = \\left(\\pi/0.05,\\;0.05\\right)$.\n- Case 4 (converged sampling): $(\\omega, \\Delta x) = (80.0, 0.01)$.\n\nFor each case, your program must produce a list with the following five entries, in order:\n- The relative root-mean-square error for the raw decimate-and-interpolate reconstruction (dimensionless float).\n- The boolean prediction of aliasing based on the Nyquist–Shannon condition (True if $\\omega  \\pi/\\Delta x$, False otherwise).\n- The predicted aliased angular frequency $\\omega_{\\mathrm{alias}}$ in radians per unit $x$ (float).\n- The relative root-mean-square error for the anti-aliased reconstruction (dimensionless float).\n- The improvement factor $\\mathcal{I}$ (dimensionless float).\n\nFinal output format:\nYour program must produce a single line of output containing the results for all four test cases as a comma-separated list of case-lists enclosed in square brackets, with no spaces. Each float must be rounded to six decimal places. For example, the format should be:\n$[ [a_{11},a_{12},a_{13},a_{14},a_{15}],[a_{21},a_{22},a_{23},a_{24},a_{25}],[a_{31},a_{32},a_{33},a_{34},a_{35}],[a_{41},a_{42},a_{43},a_{44},a_{45}] ]$\nbut printed without spaces. Angles are in radians, and errors and improvement factors are dimensionless. The program must not require any input and must run self-contained.\n\nNote: Ensure that all floating-point values in the final printed list are rounded to six decimal places, and adhere strictly to the specified anti-alias prefilter design and reconstruction procedures to guarantee testability and reproducibility.",
            "solution": "The solution is implemented by first generating a high-resolution reference signal of the power spectrum $P_{\\mathcal{R}}(x)$ on a fine, uniform grid in logarithmic wavenumber space, $x = \\ln k$. This signal serves as the ground truth. For each test case, specified by an oscillation frequency $\\omega$ and a coarse grid spacing $\\Delta x$, two reconstruction methods are simulated. The 'raw' reconstruction involves decimating the reference signal by an integer factor $r = \\Delta x / \\Delta x_{\\mathrm{ref}}$ and then using piecewise linear interpolation to reconstruct the signal on a fine grid for comparison. The 'anti-aliased' reconstruction first applies a low-pass Finite Impulse Response (FIR) filter to the high-resolution reference signal before decimation. The FIR filter is designed with a Hamming window and a cutoff frequency just below the Nyquist frequency of the coarse grid, as specified in the problem, to remove high-frequency components that would cause aliasing. The filter is applied in a zero-phase manner to prevent phase distortion. After filtering, the signal is decimated and interpolated in the same way as the raw case. The accuracy of both reconstructions is quantified by calculating the relative root-mean-square error against the reference signal subset. The theoretical aliasing diagnostics—the Nyquist condition check and the predicted aliased frequency $\\omega_{\\mathrm{alias}}$—are also computed. Finally, the improvement factor is calculated as the ratio of the raw error to the anti-aliased error. This entire procedure is executed for each test case to produce the final results.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import signal\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n    # Parameter specification for the spectrum and grids\n    A_s = 2.1e-9\n    n_s = 0.965\n    k_star = 0.05\n    A_osc = 0.1\n    phi = 0.0\n    k_min = 1e-4\n    k_max = 1.0\n    dx_ref = 0.001\n\n    # Test suite\n    test_cases = [\n        (30.0, 0.05),\n        (80.0, 0.05),\n        (np.pi / 0.05, 0.05),\n        (80.0, 0.01)\n    ]\n\n    # --- Helper Functions ---\n\n    def P_R_log(x, omega, As, ns, kstar, Aosc, p):\n        \"\"\"\n        Calculates the power spectrum P_R as a function of logarithmic wavenumber x.\n        \"\"\"\n        x_star = np.log(kstar)\n        power_law_term = As * np.exp((ns - 1) * (x - x_star))\n        oscillation_term = 1 + Aosc * np.sin(omega * (x - x_star) + p)\n        return power_law_term * oscillation_term\n\n    def calculate_rr_mse(y_recon, y_ref):\n        \"\"\"\n        Calculates the relative root-mean-square error.\n        \"\"\"\n        numerator = np.sum((y_recon - y_ref)**2)\n        denominator = np.sum(y_ref**2)\n        if denominator == 0:\n            return 0.0\n        return np.sqrt(numerator / denominator)\n\n    def process_case(omega, dx):\n        \"\"\"\n        Processes a single test case (omega, dx) and returns the required metrics.\n        \"\"\"\n        # 1. Setup grids\n        x_min = np.log(k_min)\n        x_max = np.log(k_max)\n        x_fine = np.arange(x_min, x_max, dx_ref)\n        \n        r = int(round(dx / dx_ref))\n        if not np.isclose(r * dx_ref, dx):\n            raise ValueError(\"dx must be an integer multiple of dx_ref\")\n        \n        # 2. Generate reference spectrum\n        P_ref = P_R_log(x_fine, omega, A_s, n_s, k_star, A_osc, phi)\n        \n        # Define coarse grid and the subset of the fine grid for comparison\n        x_coarse = x_fine[::r]\n        subset_indices = np.where((x_fine >= x_coarse[0])  (x_fine = x_coarse[-1]))\n        x_fine_subset = x_fine[subset_indices]\n        P_ref_subset = P_ref[subset_indices]\n        \n        # 3. Raw reconstruction\n        P_coarse_raw = P_ref[::r]\n        if len(x_coarse) > len(P_coarse_raw):\n             # Ensure last point is captured if grid size is not a perfect multiple\n             x_coarse = x_coarse[:len(P_coarse_raw)]\n\n        P_raw_recon = np.interp(x_fine_subset, x_coarse, P_coarse_raw)\n        err_raw = calculate_rr_mse(P_raw_recon, P_ref_subset)\n        \n        # 4. Anti-aliased reconstruction\n        num_taps = 8 * r + 1\n        normalized_cutoff = 0.9 / r\n        fir_coeffs = signal.firwin(num_taps, cutoff=normalized_cutoff, window='hamming')\n\n        P_filtered = signal.filtfilt(fir_coeffs, 1.0, P_ref)\n        \n        P_coarse_aa = P_filtered[::r]\n        P_aa_recon = np.interp(x_fine_subset, x_coarse, P_coarse_aa)\n        err_aa = calculate_rr_mse(P_aa_recon, P_ref_subset)\n        \n        # 5. Aliasing analysis\n        Omega_N = np.pi / dx\n        alias_prediction = omega > Omega_N\n        \n        mod_val = (omega * dx) % (2 * np.pi)\n        w_alias = (1 / dx) * min(mod_val, 2 * np.pi - mod_val)\n        \n        # 6. Improvement factor\n        if err_aa > 1e-15: # Avoid division by a very small number\n            improvement = err_raw / err_aa\n        else:\n            improvement = np.inf if err_raw > 1e-15 else 1.0\n            \n        return [err_raw, alias_prediction, w_alias, err_aa, improvement]\n\n    # --- Main Execution Logic ---\n    all_results = []\n    for omega_case, dx_case in test_cases:\n        case_result = process_case(omega_case, dx_case)\n        all_results.append(case_result)\n\n    # Format the final output string as per the strict requirements\n    case_strings = []\n    for res in all_results:\n        # res = [err_raw, alias_pred, w_alias, err_aa, improvement]\n        str_res_list = [\n            f\"{res[0]:.6f}\",\n            \"true\" if res[1] else \"false\",\n            f\"{res[2]:.6f}\",\n            f\"{res[3]:.6f}\",\n            f\"{res[4]:.6f}\"\n        ]\n        case_strings.append(f\"[{','.join(str_res_list)}]\")\n    \n    final_output_string = f\"[{','.join(case_strings)}]\"\n    final_output_string = final_output_string.replace(\" \", \"\")\n    \n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}