{
    "hands_on_practices": [
        {
            "introduction": "The semi-empirical mass formula (SEMF) is a cornerstone of nuclear physics, providing a powerful bridge between the macroscopic liquid-drop model and quantum mechanical corrections. A fundamental task for any computational physicist is to connect theoretical models with experimental reality by fitting model parameters to data. This exercise  guides you through the process of deriving a linear model from the SEMF's physical principles and applying ordinary least squares regression to determine its coefficients from a set of atomic masses, a foundational skill in developing and validating nuclear models.",
            "id": "3573765",
            "problem": "You are asked to design and implement a complete numerical pipeline to estimate nuclear binding energy model coefficients from atomic mass data at advanced graduate level, using principle-based reasoning and a reproducible linear regression. The coefficients to be determined are the volume coefficient $a_v$, the surface coefficient $a_s$, the Coulomb coefficient $a_c$, the asymmetry coefficient $a_a$, and the pairing amplitude $a_p$ under a chosen pairing prescription. The derivation must start from foundational principles and scaling laws appropriate to the liquid-drop description and must explicitly construct a linear model whose parameters are fitted by ordinary least squares.\n\nThe fundamental base you must use consists of:\n- The mass-energy equivalence $E = m c^2$.\n- The definition of nuclear binding energy $B$ for a nucleus with proton number $Z$ and neutron number $N$: $B = Z m_p c^2 + N m_n c^2 - M_{\\text{nuc}} c^2$, where $m_p$ and $m_n$ are the free proton and neutron masses and $M_{\\text{nuc}}$ is the nuclear mass.\n- Conversion from atomic mass $M_{\\text{atom}}$ (neutral atom with $Z$ bound electrons) to nuclear mass $M_{\\text{nuc}}$ via removal of $Z$ electron rest masses with addition of total electron binding energy $E_e(Z)$: $M_{\\text{nuc}} = M_{\\text{atom}} - Z m_e + E_e(Z)/c^2$, where $m_e$ is the electron mass. Use a consistent smooth electron binding correction model $E_e(Z)$ for neutral atoms with magnitude that scales plausibly with $Z$; adopt $E_e(Z) = \\alpha Z^2$ with $\\alpha$ specified below.\n\nYou must construct a linear regression model of $B$ in terms of features derived from physically motivated scaling laws. The features should emerge from the following considerations, without shortcut formulas provided in the problem statement:\n- A volume-like contribution that scales with $A = Z + N$.\n- A surface-like contribution that scales with the surface area of a nearly incompressible liquid drop, hence proportional to a power of $A$.\n- A Coulomb self-energy contribution of a finite-size charged distribution, dependent on $Z$ and the nuclear radius scaling.\n- An asymmetry contribution related to the neutron-proton imbalance and Fermi statistics.\n- A pairing contribution that depends on the parity of $Z$ and $N$, with a chosen magnitude scaling function in $A$ and a sign prescription for even-even, odd-odd, and odd-$A$ nuclei.\n\nYou must implement the following pairing prescription: define the signed pairing feature $g(A,Z,N) = s(A,Z,N) A^{-1/2}$, where $s(A,Z,N) = +1$ for even-even nuclei (both $Z$ and $N$ even), $s(A,Z,N) = -1$ for odd-odd nuclei (both $Z$ and $N$ odd), and $s(A,Z,N) = 0$ for odd-$A$ nuclei ($A$ odd). The unknown coefficient $a_p$ multiplies $g(A,Z,N)$.\n\nUnits and constants:\n- Express all energies in megaelectronvolts (MeV).\n- Use the atomic mass unit to energy conversion $u c^2$ equal to $931.49410242$ MeV per atomic mass unit $u$.\n- Use $m_p = 1.007276466621$ $u$, $m_n = 1.00866491588$ $u$, and $m_e = 0.000548579909065$ $u$.\n- Use the electron binding correction model $E_e(Z) = \\alpha Z^2$, with $\\alpha = 14.4381$ electronvolts. Convert $E_e(Z)$ to MeV using $1$ electronvolt $= 10^{-6}$ MeV. Therefore, $E_e(Z) = (1.44381 \\times 10^{-5}) Z^2$ MeV.\n\nData:\nUse the following dataset of neutral atomic masses $M_{\\text{atom}}$ in atomic mass units $u$ for isotopes with $(Z,N,A)$, where $A = Z + N$, and the indicated atomic masses. Every number below is a decimal quantity in $u$.\n- Deuterium: $(Z,N,A) = (1,1,2)$, $M_{\\text{atom}} = 2.01410177812$.\n- Helium-$3$: $(Z,N,A) = (2,1,3)$, $M_{\\text{atom}} = 3.01602932265$.\n- Helium-$4$: $(Z,N,A) = (2,2,4)$, $M_{\\text{atom}} = 4.00260325413$.\n- Carbon-$12$: $(Z,N,A) = (6,6,12)$, $M_{\\text{atom}} = 12.0$.\n- Nitrogen-$14$: $(Z,N,A) = (7,7,14)$, $M_{\\text{atom}} = 14.00307400443$.\n- Oxygen-$16$: $(Z,N,A) = (8,8,16)$, $M_{\\text{atom}} = 15.99491461957$.\n- Calcium-$40$: $(Z,N,A) = (20,20,40)$, $M_{\\text{atom}} = 39.96259098$.\n- Calcium-$48$: $(Z,N,A) = (20,28,48)$, $M_{\\text{atom}} = 47.95252276$.\n- Iron-$56$: $(Z,N,A) = (26,30,56)$, $M_{\\text{atom}} = 55.93493633$.\n- Nickel-$58$: $(Z,N,A) = (28,30,58)$, $M_{\\text{atom}} = 57.9353429$.\n- Zirconium-$90$: $(Z,N,A) = (40,50,90)$, $M_{\\text{atom}} = 89.9047037$.\n- Lead-$208$: $(Z,N,A) = (82,126,208)$, $M_{\\text{atom}} = 207.9766521$.\n\nTasks:\n1. From the fundamental base described, derive a linear model for $B$ in terms of a feature vector that yields a design matrix suitable for ordinary least squares, with unknown parameters $(a_v,a_s,a_c,a_a,a_p)$ each expressed in MeV.\n2. Convert each $M_{\\text{atom}}$ to $M_{\\text{nuc}}$ using the electron binding correction $E_e(Z)$ and compute the experimental binding energies $B$ in MeV for all isotopes.\n3. Implement ordinary least squares to fit $(a_v,a_s,a_c,a_a,a_p)$.\n\nTest suite:\nRun the fitting under three configurations to test the pipeline:\n- Case $1$: Use the full dataset listed above and include the electron binding correction $E_e(Z)$.\n- Case $2$: Use only the even-even subset of the dataset (those with both $Z$ and $N$ even) and include the electron binding correction $E_e(Z)$.\n- Case $3$: Use the full dataset but omit the electron binding correction (equivalently set $E_e(Z) = 0$), while still subtracting $Z m_e$ to convert $M_{\\text{atom}}$ to $M_{\\text{nuc}}$.\n\nFor each case, return the fitted coefficients $(a_v,a_s,a_c,a_a,a_p)$ as floating-point values in MeV along with the root-mean-square error (RMSE) of the residuals in MeV, computed as $\\sqrt{\\frac{1}{n}\\sum_i (B_i - \\hat{B}_i)^2}$ where $n$ is the number of isotopes in the case, $B_i$ are experimental binding energies, and $\\hat{B}_i$ are the model predictions. The RMSE must be expressed in MeV.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated nested list enclosed in square brackets, with one inner list per case in the order Case $1$, Case $2$, Case $3$. Each inner list must contain the six floating-point results in MeV with six digits after the decimal point, in the order $[a_v,a_s,a_c,a_a,a_p,\\text{RMSE}]$. For example, the printed structure must be of the form\n$[[a_v^{(1)},a_s^{(1)},a_c^{(1)},a_a^{(1)},a_p^{(1)},\\text{RMSE}^{(1)}],[a_v^{(2)},a_s^{(2)},a_c^{(2)},a_a^{(2)},a_p^{(2)},\\text{RMSE}^{(2)}],[a_v^{(3)},a_s^{(3)},a_c^{(3)},a_a^{(3)},a_p^{(3)},\\text{RMSE}^{(3)}]]$.",
            "solution": "The problem requires the design and implementation of a numerical pipeline to determine the coefficients of the semi-empirical mass formula (SEMF) from a given dataset of atomic masses. The process involves three main stages: the theoretical derivation of a linear model for nuclear binding energy based on the liquid-drop model, the processing of raw atomic mass data to calculate experimental binding energies, and the application of ordinary least squares (OLS) regression to fit the model coefficients.\n\nFirst, we establish the theoretical foundation for the linear model. The binding energy $B$ of a nucleus with mass number $A$, proton number $Z$, and neutron number $N = A - Z$ is defined as the energy required to disassemble it into its constituent free nucleons. Based on the principle of mass-energy equivalence, $E=mc^2$, this is given by:\n$$B = Z m_p c^2 + N m_n c^2 - M_{\\text{nuc}} c^2$$\nwhere $m_p$ is the proton rest mass, $m_n$ is the neutron rest mass, and $M_{\\text{nuc}}$ is the mass of the nucleus. The provided data are for neutral atoms, $M_{\\text{atom}}$, which include $Z$ electrons. The nuclear mass $M_{\\text{nuc}}$ is obtained by subtracting the mass of these $Z$ electrons and adding back their total binding energy, $E_e(Z)$:\n$$M_{\\text{nuc}} = M_{\\text{atom}} - Z m_e + \\frac{E_e(Z)}{c^2}$$\nHere, $m_e$ is the electron rest mass. The problem specifies a model for the total electron binding energy, $E_e(Z) = \\alpha Z^2$, with $\\alpha = 1.44381 \\times 10^{-5}$ MeV. Combining these, the experimental binding energy in units of MeV is calculated as:\n$$B_{exp} = \\left( Z m_p + N m_n - \\left( M_{\\text{atom}} - Z m_e + \\frac{E_e(Z)}{u c^2} \\right) \\right) u c^2$$\nwhere all masses are expressed in atomic mass units ($u$) and $u c^2 = 931.49410242$ MeV is the energy equivalent of one atomic mass unit.\n\nThe semi-empirical mass formula, derived from the liquid-drop model of the nucleus, expresses the binding energy $B$ as a sum of five terms with coefficients $(a_v, a_s, a_c, a_a, a_p)$ that we aim to determine:\n$$B(A, Z) = a_v f_v - a_s f_s - a_c f_c - a_a f_a + a_p f_p$$\nThe functional forms of the features ($f_v, f_s, f_c, f_a, f_p$) are derived from physical arguments:\n1.  Volume Term ($f_v$): The strong nuclear force is short-ranged and saturates. Thus, each nucleon primarily interacts with its nearest neighbors. The total binding energy is therefore approximately proportional to the total number of nucleons, $A$. This term represents the bulk binding of the nuclear \"liquid\".\n    $$f_v(A, Z) = A$$\n2.  Surface Term ($f_s$): Nucleons on the surface of the nucleus have fewer neighbors than those in the interior, which reduces the total binding energy. This effect is proportional to the surface area of the nucleus. Assuming a spherical nucleus of constant density, the volume $V \\propto A$. Since $V \\propto R^3$, the radius $R \\propto A^{1/3}$. The surface area is proportional to $R^2$.\n    $$f_s(A, Z) = A^{2/3}$$\n3.  Coulomb Term ($f_c$): The electrostatic repulsion between protons also reduces the binding energy. The potential energy of a distribution of $Z$ protons in a sphere of radius $R$ is proportional to the number of proton pairs, $Z(Z-1)/2$, and inversely proportional to the radius $R$. Using $Z(Z-1)$ is more accurate for small $Z$ than the approximation $Z^2$.\n    $$f_c(A, Z) = \\frac{Z(Z-1)}{A^{1/3}}$$\n4.  Asymmetry Term ($f_a$): The Pauli exclusion principle favors a symmetric nucleus with $N=Z$. For a fixed mass number $A$, deviating from this symmetry (i.e., having a neutron excess $N-Z \\neq 0$) requires placing nucleons in higher energy levels, which costs energy and reduces binding. This energy penalty is proportional to the square of the neutron-proton imbalance and inversely proportional to the total volume.\n    $$f_a(A, Z) = \\frac{(N-Z)^2}{A} = \\frac{(A-2Z)^2}{A}$$\n5.  Pairing Term ($f_p$): Nucleons exhibit a tendency to form pairs of identical particles with opposite spins, which increases binding energy. This leads to a correction term that depends on the even-odd character of $Z$ and $N$. The problem specifies the functional form for this feature:\n    $$f_p(A, Z, N) = s(A,Z,N) A^{-1/2}$$\n    where $s(A,Z,N) = +1$ for even-even nuclei, $s(A,Z,N) = -1$ for odd-odd nuclei, and $s(A,Z,N) = 0$ for odd-A nuclei.\n\nThis model is linear in the coefficients $(a_v, a_s, a_c, a_a, a_p)$. For a set of $n$ nuclei, we can write the system of equations in matrix form as $\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta}$, where:\n-   $\\boldsymbol{Y}$ is an $n \\times 1$ column vector of the experimental binding energies, $B_{exp,i}$.\n-   $\\boldsymbol{\\beta}$ is a $5 \\times 1$ column vector of the unknown coefficients to be fitted: $[a_v, a_s, a_c, a_a, a_p]^T$.\n-   $\\mathbf{X}$ is the $n \\times 5$ design matrix, where the $i$-th row corresponds to the $i$-th nucleus and is constructed from the model terms with their conventional signs absorbed:\n    $$\\mathbf{X}_i = \\left[ A_i, \\quad -A_i^{2/3}, \\quad -\\frac{Z_i(Z_i-1)}{A_i^{1/3}}, \\quad -\\frac{(A_i-2Z_i)^2}{A_i}, \\quad s(A_i,Z_i,N_i)A_i^{-1/2} \\right]$$\nThe ordinary least squares (OLS) estimate for the coefficients, $\\hat{\\boldsymbol{\\beta}}$, is the one that minimizes the sum of squared residuals, and is given by the solution to the normal equations:\n$$\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{Y}$$\nThis solution will be computed numerically using a stable linear least-squares solver.\n\nThe pipeline proceeds as follows for each of the three test cases:\n1.  Select the appropriate subset of the isotopic data.\n2.  For each isotope, calculate the experimental binding energy $B_{exp}$ to form the vector $\\boldsymbol{Y}$. This involves applying the electron mass and, where specified, the electron binding energy corrections.\n3.  For each isotope, calculate the five feature values to form the design matrix $\\mathbf{X}$.\n4.  Solve the linear system $\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta}$ for $\\boldsymbol{\\beta}$ using OLS.\n5.  With the fitted coefficients $\\hat{\\boldsymbol{\\beta}}$, calculate the predicted binding energies $\\hat{\\boldsymbol{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$.\n6.  Compute the root-mean-square error (RMSE) of the fit, defined as $\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2}$.\nThe resulting coefficients $(a_v,a_s,a_c,a_a,a_p)$ and the RMSE, all in units of MeV, constitute the final output for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Constants are defined at the module level for clarity and reuse.\nUC2_MEV = 931.49410242\nM_P_U = 1.007276466621\nM_N_U = 1.00866491588\nM_E_U = 0.000548579909065\nALPHA_MEV = 1.44381e-5\n\ndef get_pairing_s(Z, N):\n    \"\"\"\n    Determines the sign coefficient for the pairing term based on proton and neutron numbers.\n    s = +1 for even-even, -1 for odd-odd, 0 for odd-A nuclei.\n    \"\"\"\n    if Z % 2 == 0 and N % 2 == 0:\n        return 1.0\n    elif Z % 2 != 0 and N % 2 != 0:\n        return -1.0\n    else:  # Odd-A nuclei\n        return 0.0\n\ndef run_semf_fit(dataset, use_electron_binding):\n    \"\"\"\n    Constructs the design matrix and target vector, then performs OLS regression.\n\n    Args:\n        dataset (list): A list of tuples, where each tuple contains\n                        (Z, N, A, M_atom_u) for a nucleus.\n        use_electron_binding (bool): Flag to include electron binding\n                                     energy correction.\n\n    Returns:\n        list: A list containing the fitted coefficients [a_v, a_s, a_c, a_a, a_p]\n              and the RMSE of the fit, all in MeV.\n    \"\"\"\n    num_isotopes = len(dataset)\n    # Design matrix X (n_samples, n_features) and target vector Y (n_samples,)\n    X = np.zeros((num_isotopes, 5))\n    Y = np.zeros(num_isotopes)\n\n    for i, datum in enumerate(dataset):\n        Z_f, N_f, A_f, M_atom_u = datum\n        Z, N, A = int(Z_f), int(N_f), int(A_f)\n\n        # 1. Calculate experimental binding energy (target vector Y)\n        E_e_mev = ALPHA_MEV * Z**2 if use_electron_binding else 0.0\n        M_nuc_u = M_atom_u - Z * M_E_U + E_e_mev / UC2_MEV\n        B_mev = (Z * M_P_U + N * M_N_U - M_nuc_u) * UC2_MEV\n        Y[i] = B_mev\n        \n        # 2. Construct features for the design matrix X\n        # The model is B = a_v*f_v + a_s*(-f_s) + a_c*(-f_c) + a_a*(-f_a) + a_p*f_p\n        # where f_v=A, f_s=A^(2/3), etc.\n        # We absorb the signs into the design matrix.\n        f_v = float(A)\n        f_s = -A**(2/3)\n        # Use Z*(Z-1) for Coulomb term, more accurate for small Z\n        f_c = -Z * (Z - 1) / A**(1/3) if A  0 else 0.0\n        # Asymmetry term (N-Z)^2/A = (A-2Z)^2/A\n        f_a = -(A - 2*Z)**2 / A if A  0 else 0.0\n        \n        s = get_pairing_s(Z, N)\n        f_p = s * A**(-1/2) if A  0 else 0.0\n        \n        X[i, :] = [f_v, f_s, f_c, f_a, f_p]\n\n    # 3. Perform Ordinary Least Squares (OLS) regression\n    # np.linalg.lstsq solves Y = X*beta for beta\n    coeffs, residuals, _, _ = np.linalg.lstsq(X, Y, rcond=None)\n    \n    # 4. Calculate Root-Mean-Square Error (RMSE)\n    if residuals.size == 0:\n        # If n_samples = n_features, lstsq may return empty residuals.\n        # In this case, residuals must be computed manually.\n        Y_pred = X @ coeffs\n        res_sum_sq = np.sum((Y - Y_pred)**2)\n        rmse = np.sqrt(res_sum_sq / num_isotopes) if num_isotopes  0 else 0.0\n    else:\n        # residuals[0] contains the sum of squared residuals\n        rmse = np.sqrt(residuals[0] / num_isotopes) if num_isotopes  0 else 0.0\n        \n    return list(coeffs) + [rmse]\n\n\ndef solve():\n    \"\"\"\n    Main orchestrator for the problem. Defines data and test cases,\n    runs the analysis, and prints the final formatted output.\n    \"\"\"\n    # Dataset: (Z, N, A, M_atom_u)\n    # Z, N, A are integers; M_atom_u is float.\n    DATA = [\n        (1, 1, 2, 2.01410177812),   # Deuterium\n        (2, 1, 3, 3.01602932265),   # Helium-3\n        (2, 2, 4, 4.00260325413),   # Helium-4\n        (6, 6, 12, 12.0),           # Carbon-12\n        (7, 7, 14, 14.00307400443), # Nitrogen-14\n        (8, 8, 16, 15.99491461957), # Oxygen-16\n        (20, 20, 40, 39.96259098),  # Calcium-40\n        (20, 28, 48, 47.95252276),  # Calcium-48\n        (26, 30, 56, 55.93493633),  # Iron-56\n        (28, 30, 58, 57.9353429),   # Nickel-58\n        (40, 50, 90, 89.9047037),   # Zirconium-90\n        (82, 126, 208, 207.9766521) # Lead-208\n    ]\n\n    all_results = []\n\n    # Case 1: Full dataset, with electron binding energy correction\n    results_1 = run_semf_fit(DATA, use_electron_binding=True)\n    all_results.append(results_1)\n    \n    # Case 2: Even-even subset, with electron binding energy correction\n    even_even_data = [d for d in DATA if d[0] % 2 == 0 and d[1] % 2 == 0]\n    results_2 = run_semf_fit(even_even_data, use_electron_binding=True)\n    all_results.append(results_2)\n    \n    # Case 3: Full dataset, without electron binding energy correction\n    results_3 = run_semf_fit(DATA, use_electron_binding=False)\n    all_results.append(results_3)\n    \n    # Format the final output string exactly as required.\n    output_parts = []\n    for res_list in all_results:\n        formatted_list = [f\"{val:.6f}\" for val in res_list]\n        output_parts.append(f\"[{','.join(formatted_list)}]\")\n    \n    final_output_str = f\"[{','.join(output_parts)}]\"\n    print(final_output_str)\n\nsolve()\n\n```"
        },
        {
            "introduction": "Moving beyond macroscopic models, microscopic descriptions like Density Functional Theory (DFT) describe the nucleus in terms of single-nucleon orbits in a self-consistent mean field. Within this framework, Koopmans' theorem offers a tempting shortcut, suggesting that the energy to remove a nucleon is simply the negative of its single-particle energy. This practice  provides a hands-on numerical experiment to test this approximation, highlighting the crucial physical effects it neglects—namely, mean-field rearrangement and pairing correlations—and allowing you to quantify their impact.",
            "id": "3573744",
            "problem": "You are asked to design and implement a numerical experiment, using a simplified density functional theory (DFT) analog, to test a Koopmans-style estimator for nucleon separation energies against fully self-consistent finite-difference results. Your task is to formulate the problem starting from fundamental principles and widely tested results, then implement a program that computes and compares neutron and proton separation energies for a small test suite of nuclei.\n\nStart from the following foundational bases:\n\n- Nonrelativistic degenerate Fermi gas at zero temperature: for a uniform species of fermions with number density $\\rho_q$, the Fermi momentum is $k_{F,q} = \\left(3\\pi^2 \\rho_q\\right)^{1/3}$, the Fermi kinetic energy is $T_{F,q} = \\frac{\\hbar^2 k_{F,q}^2}{2m}$, and the kinetic energy per particle equals $\\frac{3}{5} T_{F,q}$.\n\n- Hartree mean-field with double-counting correction: in a Hartree description with a one-body mean field $U_q$, the total potential energy is $\\frac{1}{2} \\sum_q N_q U_q$ when evaluated at self-consistency.\n\n- Koopmans-style removal energy estimator in a frozen mean-field: in an independent-particle picture, the removal energy of the last occupied particle of species $q$ can be approximated by the negative of the single-particle energy at the Fermi surface, $-\\varepsilon_{F,q}$, when neglecting rearrangement of the mean field and derivative discontinuities.\n\nModel assumptions to be used for the computation:\n\n- Consider a uniform finite nucleus at saturation density with two fermion species $q \\in \\{n,p\\}$ (neutrons $n$ and protons $p$). Let the total nucleon number be $A = N + Z$, with species fractions $x_n = N/A$ and $x_p = Z/A$. Assume a constant saturation density $\\rho_0 = 0.16\\,\\text{fm}^{-3}$, so that the species densities are $\\rho_n = x_n \\rho_0$ and $\\rho_p = x_p \\rho_0$.\n\n- Use nonrelativistic nucleons with $\\hbar^2/(2m) = 20.735\\,\\text{MeV}\\,\\text{fm}^2$. Then the Fermi kinetic energies are $T_{F,q} = \\frac{\\hbar^2}{2m} \\left(3\\pi^2 \\rho_q\\right)^{2/3}$.\n\n- Adopt a species-dependent local mean-field potential of the form\n  $$\n  U_n(N,Z) = u_0 + u_{\\text{sym}} \\,\\delta, \\quad U_p(N,Z) = u_0 - u_{\\text{sym}} \\,\\delta + u_c \\frac{Z}{A^{1/3}},\n  $$\n  where $\\delta = \\frac{N-Z}{A}$ is the asymmetry parameter. Use parameters $u_0 = -60\\,\\text{MeV}$, $u_{\\text{sym}} = 50\\,\\text{MeV}$, and $u_c = 1.44\\,\\text{MeV}$.\n\n- Include a schematic pairing correlation energy\n  $$\n  E_{\\text{pair}}(N,Z) = -\\frac{p_0}{\\sqrt{A}} \\left(\\delta_{N \\text{ even}} + \\delta_{Z \\text{ even}}\\right),\n  $$\n  with $p_0 = 12\\,\\text{MeV}$ and $\\delta_{N \\text{ even}}$ equal to $1$ if $N$ is even and $0$ otherwise (similarly for $\\delta_{Z \\text{ even}}$).\n\nDerive, from the above bases, algorithmic expressions for the following quantities:\n\n1) The total ground-state energy for a given $(N,Z)$ in this uniform Thomas-Fermi Hartree model,\n   $$\n   E(N,Z) = \\sum_{q \\in \\{n,p\\}} \\frac{3}{5} N_q T_{F,q} + \\frac{1}{2}\\left(N U_n + Z U_p\\right) + E_{\\text{pair}}(N,Z),\n   $$\n   and the corresponding binding energy $B(N,Z) = -E(N,Z)$, in $\\text{MeV}$.\n\n2) The fully self-consistent one-nucleon separation energies, computed by discrete differences of the binding energies,\n   $$\n   S_n(N,Z) = B(N,Z) - B(N-1,Z), \\quad S_p(N,Z) = B(N,Z) - B(N,Z-1),\n   $$\n   in $\\text{MeV}$, where $N \\ge 1$ and $Z \\ge 1$.\n\n3) The Koopmans-style estimates obtained by freezing the mean field at $(N,Z)$ and evaluating the Fermi single-particle energies,\n   $$\n   \\varepsilon_{F,q}(N,Z) = T_{F,q}(N,Z) + U_q(N,Z), \\quad S_n^{K}(N,Z) \\approx -\\varepsilon_{F,n}(N,Z), \\quad S_p^{K}(N,Z) \\approx -\\varepsilon_{F,p}(N,Z),\n   $$\n   in $\\text{MeV}$.\n\nYou must implement a program that, for the following test suite of nuclei $(N,Z)$, computes $S_n$, $S_n^{K}$, $S_p$, and $S_p^{K}$:\n\n- $(8,8)$, $(20,20)$, $(28,20)$, $(28,28)$, $(82,50)$, $(126,82)$, $(21,20)$, $(83,50)$, $(20,21)$.\n\nThen, over this suite, also compute the following diagnostic metrics to quantify and interpret deviations due to correlations and rearrangement effects:\n\n- Root-mean-square deviations of the Koopmans errors for neutrons and protons,\n  $$\n  \\text{RMS}_n = \\sqrt{\\langle \\left(S_n^{K} - S_n\\right)^2 \\rangle}, \\quad \\text{RMS}_p = \\sqrt{\\langle \\left(S_p^{K} - S_p\\right)^2 \\rangle},\n  $$\n  in $\\text{MeV}$, where $\\langle \\cdot \\rangle$ denotes the average over the test suite.\n\n- An odd-even staggering diagnostic for neutrons and protons, defined as the difference between the mean Koopmans errors for even and odd particle numbers,\n  $$\n  \\text{OES}_n = \\langle S_n^{K} - S_n \\rangle_{N \\text{ even}} - \\langle S_n^{K} - S_n \\rangle_{N \\text{ odd}},\n  $$\n  $$\n  \\text{OES}_p = \\langle S_p^{K} - S_p \\rangle_{Z \\text{ even}} - \\langle S_p^{K} - S_p \\rangle_{Z \\text{ odd}},\n  $$\n  in $\\text{MeV}$.\n\nAll energies must be expressed in $\\text{MeV}$ and rounded to three decimals.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The entries must appear in the following order:\n\n- For each test case in the order listed above, output four numbers: $S_n$, $S_n^{K}$, $S_p$, $S_p^{K}$ (each rounded to three decimals, in $\\text{MeV}$).\n- After all cases, append $\\text{RMS}_n$, $\\text{RMS}_p$, $\\text{OES}_n$, $\\text{OES}_p$ (each rounded to three decimals, in $\\text{MeV}$).\n\nThe final output format is therefore a flat list of floats:\n$[S_{n,1},S_{n,1}^{K},S_{p,1},S_{p,1}^{K},\\dots,S_{n,9},S_{n,9}^{K},S_{p,9},S_{p,9}^{K},\\text{RMS}_n,\\text{RMS}_p,\\text{OES}_n,\\text{OES}_p]$.",
            "solution": "We begin from well-established principles for a nonrelativistic degenerate Fermi gas and Hartree mean-field descriptions. For each species $q \\in \\{n,p\\}$ with number $N_q$ and number density $\\rho_q$, the Fermi momentum is $k_{F,q} = \\left(3\\pi^2 \\rho_q\\right)^{1/3}$ and the Fermi kinetic energy is $T_{F,q} = \\frac{\\hbar^2 k_{F,q}^2}{2m}$. The kinetic energy per particle equals $\\frac{3}{5} T_{F,q}$; therefore the total kinetic energy for species $q$ is $E_{\\text{kin},q} = \\frac{3}{5} N_q T_{F,q}$. Summing over species yields\n$$\nE_{\\text{kin}}(N,Z) = \\frac{3}{5} \\left(N T_{F,n} + Z T_{F,p}\\right),\n$$\nwith $T_{F,q}$ dependent on $\\rho_q$.\n\nWe assume a uniform finite nucleus at saturation density $\\rho_0 = 0.16\\,\\text{fm}^{-3}$ with total nucleon number $A = N+Z$ and species fractions $x_n = \\frac{N}{A}$ and $x_p = \\frac{Z}{A}$. For each species, $\\rho_q = x_q \\rho_0$. Then the Fermi kinetic energies are\n$$\nT_{F,q}(N,Z) = \\frac{\\hbar^2}{2m} \\left(3\\pi^2 x_q \\rho_0\\right)^{2/3}, \\quad \\frac{\\hbar^2}{2m} = 20.735\\,\\text{MeV}\\,\\text{fm}^2.\n$$\n\nIn a Hartree mean-field model, the total potential energy is given by the half-sum over occupied particles of the mean field evaluated at the self-consistent density,\n$$\nE_{\\text{mf}}(N,Z) = \\frac{1}{2}\\left(N U_n(N,Z) + Z U_p(N,Z)\\right).\n$$\nWe posit a mean field consisting of an isoscalar depth $u_0$, an isovector term proportional to the asymmetry parameter $\\delta = \\frac{N-Z}{A}$ with strength $u_{\\text{sym}}$, and a proton Coulomb term scaling as $Z/A^{1/3}$ with strength $u_c$:\n$$\nU_n(N,Z) = u_0 + u_{\\text{sym}} \\,\\delta, \\quad U_p(N,Z) = u_0 - u_{\\text{sym}} \\,\\delta + u_c \\frac{Z}{A^{1/3}}.\n$$\nWe set $u_0 = -60\\,\\text{MeV}$, $u_{\\text{sym}} = 50\\,\\text{MeV}$, and $u_c = 1.44\\,\\text{MeV}$.\n\nTo incorporate pairing correlations at a schematic level, we add a phenomenological term\n$$\nE_{\\text{pair}}(N,Z) = -\\frac{p_0}{\\sqrt{A}} \\left(\\delta_{N \\text{ even}} + \\delta_{Z \\text{ even}}\\right),\n$$\nwith $p_0 = 12\\,\\text{MeV}$, and $\\delta_{N \\text{ even}}$ equals $1$ if $N$ is even and $0$ otherwise (similarly for $\\delta_{Z \\text{ even}}$). This term gives extra binding for even particle numbers and vanishes for odd particle numbers, mimicking odd-even staggering.\n\nThe total energy and binding energy then follow as\n$$\nE(N,Z) = E_{\\text{kin}}(N,Z) + E_{\\text{mf}}(N,Z) + E_{\\text{pair}}(N,Z), \\quad B(N,Z) = -E(N,Z),\n$$\nin $\\text{MeV}$.\n\nThe fully self-consistent separation energies are computed by finite differences of the binding energies:\n$$\nS_n(N,Z) = B(N,Z) - B(N-1,Z), \\quad S_p(N,Z) = B(N,Z) - B(N,Z-1),\n$$\nin $\\text{MeV}$, with $N \\ge 1$ and $Z \\ge 1$. This procedure corresponds to recomputing the densities, Fermi kinetic energies, and mean fields for the $(N-1,Z)$ and $(N,Z-1)$ systems, thereby including rearrangement effects due to the change in $A$, the change in the asymmetry parameter $\\delta$, and the Coulomb contribution.\n\nThe Koopmans-style estimator is based on the frozen mean-field approximation: remove a particle without allowing the mean field to relax. In that case, the removal energy is approximated by the negative of the single-particle energy at the Fermi surface. The Kohn-Sham-like single-particle energy at the Fermi surface equals the sum of the species Fermi kinetic energy and the mean-field potential,\n$$\n\\varepsilon_{F,q}(N,Z) = T_{F,q}(N,Z) + U_q(N,Z).\n$$\nTherefore,\n$$\nS_n^{K}(N,Z) \\approx -\\varepsilon_{F,n}(N,Z) = -\\left[T_{F,n}(N,Z) + U_n(N,Z)\\right], \\quad\nS_p^{K}(N,Z) \\approx -\\varepsilon_{F,p}(N,Z) = -\\left[T_{F,p}(N,Z) + U_p(N,Z)\\right].\n$$\nThis estimator neglects two physically important sources of deviation: (i) mean-field rearrangement (density and field change between $(N,Z)$ and $(N-1,Z)$ or $(N,Z-1)$) and (ii) explicit correlation energies such as pairing, $E_{\\text{pair}}$, which are not represented in the single-particle eigenvalues.\n\nTo quantify the estimator’s performance over a set of nuclei, we compute the Koopmans errors $S_n^{K} - S_n$ and $S_p^{K} - S_p$ for each case, and then report\n$$\n\\text{RMS}_n = \\sqrt{\\left\\langle \\left(S_n^{K} - S_n\\right)^2 \\right\\rangle}, \\quad\n\\text{RMS}_p = \\sqrt{\\left\\langle \\left(S_p^{K} - S_p\\right)^2 \\right\\rangle},\n$$\nas root-mean-square deviations, both in $\\text{MeV}$. To diagnose pairing-driven odd-even effects, we also compute\n$$\n\\text{OES}_n = \\langle S_n^{K} - S_n \\rangle_{N \\text{ even}} - \\langle S_n^{K} - S_n \\rangle_{N \\text{ odd}}, \\quad\n\\text{OES}_p = \\langle S_p^{K} - S_p \\rangle_{Z \\text{ even}} - \\langle S_p^{K} - S_p \\rangle_{Z \\text{ odd}},\n$$\nwhich should be positive if Koopmans tends to overestimate separation energies more strongly for even systems (because $E_{\\text{pair}}$ contributes extra binding that the frozen-field estimator misses).\n\nAlgorithmic implementation details:\n\n- Compute $x_n = N/A$, $x_p = Z/A$, then $\\rho_n = x_n \\rho_0$ and $\\rho_p = x_p \\rho_0$.\n- Compute $T_{F,q} = \\frac{\\hbar^2}{2m} \\left(3\\pi^2 \\rho_q\\right)^{2/3}$ for $q \\in \\{n,p\\}$.\n- Compute $\\delta = \\frac{N-Z}{A}$ and then $U_n$ and $U_p$.\n- Compute $E_{\\text{kin}} = \\frac{3}{5} \\left(N T_{F,n} + Z T_{F,p}\\right)$.\n- Compute $E_{\\text{mf}} = \\frac{1}{2} \\left(N U_n + Z U_p\\right)$.\n- Compute $E_{\\text{pair}} = -\\frac{p_0}{\\sqrt{A}} \\left(\\delta_{N \\text{ even}} + \\delta_{Z \\text{ even}}\\right)$.\n- Compute $E(N,Z)$ and $B(N,Z) = -E(N,Z)$.\n- Compute $S_n$ and $S_p$ via finite differences of $B$.\n- Compute $S_n^{K}$ and $S_p^{K}$ from the negative Fermi single-particle energies at $(N,Z)$.\n- For the test suite $(N,Z) = (8,8), (20,20), (28,20), (28,28), (82,50), (126,82), (21,20), (83,50), (20,21)$, compute and collect $S_n$, $S_n^{K}$, $S_p$, $S_p^{K}$ for each case.\n- Compute $\\text{RMS}_n$, $\\text{RMS}_p$, $\\text{OES}_n$, and $\\text{OES}_p$ across the suite.\n- Express all energies in $\\text{MeV}$, rounded to three decimals, and print a single line output in the specified flat list format.\n\nThis construction is physically and numerically self-consistent: the kinetic energy scales as $A$ in this uniform Thomas-Fermi picture, the mean-field part provides an isoscalar binding depth with isovector symmetry and Coulomb contributions, and pairing induces odd-even staggering that the Koopmans estimator cannot capture. The deviations thus diagnose both mean-field rearrangement and correlation effects.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Physical constants and model parameters\nHBAR2_OVER_2M = 20.735  # MeV fm^2\nRHO0 = 0.16             # fm^-3\nU0 = -60.0              # MeV (isoscalar mean-field depth)\nU_SYM = 50.0            # MeV (isovector strength)\nU_C = 1.44              # MeV (Coulomb strength)\nP0 = 12.0               # MeV (pairing parameter)\n\ndef fermi_kinetic_energy(x_fraction: float) - float:\n    \"\"\"\n    Compute the Fermi kinetic energy T_F for a species with fraction x = N_q / A\n    in a uniform system at saturation density RHO0.\n    T_F = (hbar^2 / 2m) * (3*pi^2 * rho_q)^(2/3), rho_q = x * RHO0\n    \"\"\"\n    rho_q = x_fraction * RHO0\n    # Guard against numerical issues for x=0 (though not relevant for provided test cases)\n    if rho_q = 0.0:\n        return 0.0\n    return HBAR2_OVER_2M * (3.0 * np.pi**2 * rho_q) ** (2.0 / 3.0)\n\ndef mean_fields(N: int, Z: int) - tuple[float, float]:\n    \"\"\"\n    Compute neutron and proton mean fields U_n and U_p at (N,Z):\n      U_n = U0 + U_SYM * delta\n      U_p = U0 - U_SYM * delta + U_C * Z / A^(1/3)\n    where delta = (N - Z) / A\n    \"\"\"\n    A = N + Z\n    if A = 0:\n        return 0.0, 0.0\n    delta = (N - Z) / A\n    Un = U0 + U_SYM * delta\n    Up = U0 - U_SYM * delta + U_C * Z / (A ** (1.0 / 3.0))\n    return Un, Up\n\ndef pairing_energy(N: int, Z: int) - float:\n    \"\"\"\n    Schematic pairing correlation energy:\n      E_pair = - P0 / sqrt(A) * (delta_N_even + delta_Z_even)\n    \"\"\"\n    A = N + Z\n    if A = 0:\n        return 0.0\n    delta_N_even = 1 if (N % 2 == 0) else 0\n    delta_Z_even = 1 if (Z % 2 == 0) else 0\n    return -P0 / np.sqrt(A) * (delta_N_even + delta_Z_even)\n\ndef total_energy(N: int, Z: int) - float:\n    \"\"\"\n    Total energy E(N,Z) = E_kin + E_mf + E_pair.\n    \"\"\"\n    A = N + Z\n    if A = 0:\n        return 0.0\n    xn = N / A\n    xp = Z / A\n    TFn = fermi_kinetic_energy(xn)\n    TFp = fermi_kinetic_energy(xp)\n    Un, Up = mean_fields(N, Z)\n    Ekin = (3.0 / 5.0) * (N * TFn + Z * TFp)\n    Emf = 0.5 * (N * Un + Z * Up)\n    Epair = pairing_energy(N, Z)\n    return Ekin + Emf + Epair\n\ndef binding_energy(N: int, Z: int) - float:\n    \"\"\"\n    Binding energy B = -E.\n    \"\"\"\n    return -total_energy(N, Z)\n\ndef separation_neutron(N: int, Z: int) - float:\n    \"\"\"\n    Neutron separation energy S_n = B(N,Z) - B(N-1,Z), for N = 1.\n    \"\"\"\n    if N = 0:\n        raise ValueError(\"N must be = 1 for neutron separation energy.\")\n    return binding_energy(N, Z) - binding_energy(N - 1, Z)\n\ndef separation_proton(N: int, Z: int) - float:\n    \"\"\"\n    Proton separation energy S_p = B(N,Z) - B(N,Z-1), for Z = 1.\n    \"\"\"\n    if Z = 0:\n        raise ValueError(\"Z must be = 1 for proton separation energy.\")\n    return binding_energy(N, Z) - binding_energy(N, Z - 1)\n\ndef koopmans_estimates(N: int, Z: int) - tuple[float, float]:\n    \"\"\"\n    Koopmans-style estimates:\n      S_n^K = -[ T_Fn(N,Z) + U_n(N,Z) ]\n      S_p^K = -[ T_Fp(N,Z) + U_p(N,Z) ]\n    \"\"\"\n    A = N + Z\n    xn = N / A\n    xp = Z / A\n    TFn = fermi_kinetic_energy(xn)\n    TFp = fermi_kinetic_energy(xp)\n    Un, Up = mean_fields(N, Z)\n    SnK = -(TFn + Un)\n    SpK = -(TFp + Up)\n    return SnK, SpK\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, 8),\n        (20, 20),\n        (28, 20),\n        (28, 28),\n        (82, 50),\n        (126, 82),\n        (21, 20),\n        (83, 50),\n        (20, 21),\n    ]\n\n    results = []\n    errors_n = []\n    errors_p = []\n    parity_n_even = []\n    parity_z_even = []\n\n    for (N, Z) in test_cases:\n        # Compute fully self-consistent separation energies\n        Sn = separation_neutron(N, Z)\n        Sp = separation_proton(N, Z)\n        # Koopmans estimates\n        SnK, SpK = koopmans_estimates(N, Z)\n\n        # Round to three decimals for output\n        results.extend([round(Sn, 3), round(SnK, 3), round(Sp, 3), round(SpK, 3)])\n\n        # Accumulate errors for diagnostics (use unrounded values)\n        err_n = SnK - Sn\n        err_p = SpK - Sp\n        errors_n.append(err_n)\n        errors_p.append(err_p)\n        parity_n_even.append(1 if (N % 2 == 0) else 0)\n        parity_z_even.append(1 if (Z % 2 == 0) else 0)\n\n    # Diagnostics: RMS errors\n    errors_n_arr = np.array(errors_n, dtype=float)\n    errors_p_arr = np.array(errors_p, dtype=float)\n    rms_n = float(np.sqrt(np.mean(errors_n_arr ** 2)))\n    rms_p = float(np.sqrt(np.mean(errors_p_arr ** 2)))\n\n    # Odd-even staggering diagnostics: difference between mean error for even and odd\n    parity_n_even_arr = np.array(parity_n_even, dtype=int)\n    parity_z_even_arr = np.array(parity_z_even, dtype=int)\n\n    # For neutrons\n    even_idx_n = parity_n_even_arr == 1\n    odd_idx_n = parity_n_even_arr == 0\n    mean_err_n_even = float(np.mean(errors_n_arr[even_idx_n])) if np.any(even_idx_n) else 0.0\n    mean_err_n_odd = float(np.mean(errors_n_arr[odd_idx_n])) if np.any(odd_idx_n) else 0.0\n    oes_n = mean_err_n_even - mean_err_n_odd\n\n    # For protons\n    even_idx_p = parity_z_even_arr == 1\n    odd_idx_p = parity_z_even_arr == 0\n    mean_err_p_even = float(np.mean(errors_p_arr[even_idx_p])) if np.any(even_idx_p) else 0.0\n    mean_err_p_odd = float(np.mean(errors_p_arr[odd_idx_p])) if np.any(odd_idx_p) else 0.0\n    oes_p = mean_err_p_even - mean_err_p_odd\n\n    # Append diagnostics to results, rounded to three decimals\n    results.extend([round(rms_n, 3), round(rms_p, 3), round(oes_n, 3), round(oes_p, 3)])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Modern nuclear theory often involves multiple competing models, each with its own strengths and weaknesses, leading to different predictions for exotic nuclei. Instead of choosing one \"best\" model, a more robust approach is to combine their predictions and quantify the resulting uncertainty. This advanced practice  introduces Bayesian Model Averaging (BMA) as a principled statistical method to synthesize information from a diverse set of models, allowing you to estimate epistemic uncertainties and make probabilistic predictions about the limits of nuclear existence.",
            "id": "3573721",
            "problem": "You are tasked with implementing a fully specified and reproducible Bayesian model averaging procedure across a discrete set of nuclear Energy Density Functional (EDF) families to quantify epistemic uncertainty in neutron separation energies and to infer neutron drip-line positions. Your implementation must proceed from first principles and use only the definitions and laws specified below. All physical energies must be reported in megaelectronvolts (MeV). All angles, if any, must be in radians. All final numerical outputs must be rounded as specified.\n\nThe foundational physical quantities are defined as follows.\n\n- The nuclear binding energy model is given by the semi-empirical mass formula (Bethe–Weizsäcker form):\n$$\nB(Z,N; \\boldsymbol{\\theta}) \\equiv a_v A - a_s A^{2/3} - a_c \\frac{Z(Z-1)}{A^{1/3}} - a_a \\frac{(N-Z)^2}{A} + \\delta(Z,N),\n$$\nwhere $A \\equiv Z+N$, $Z$ is the proton number, $N$ is the neutron number, $\\boldsymbol{\\theta} \\equiv (a_v,a_s,a_c,a_a,a_p)$ are model parameters, and the pairing term is\n$$\n\\delta(Z,N) \\equiv \n\\begin{cases}\n+ a_p A^{-1/2},  \\text{if $Z$ and $N$ are even},\\\\\n0,  \\text{if $A$ is odd},\\\\\n- a_p A^{-1/2},  \\text{if $Z$ and $N$ are odd}.\n\\end{cases}\n$$\n\n- The one-neutron separation energy is\n$$\nS_n(Z,N) \\equiv B(Z,N) - B(Z,N-1),\n$$\ndefined only for $N \\ge 1$.\n\n- The two-neutron separation energy is\n$$\nS_{2n}(Z,N) \\equiv B(Z,N) - B(Z,N-2),\n$$\ndefined only for $N \\ge 2$.\n\n- The two-neutron drip-line for a fixed proton number $Z$ is defined here as the largest even neutron number $N_{\\text{drip},2n}(Z)$ in a search interval such that $S_{2n}(Z,N) gt; 0$ and $S_{2n}(Z,N+2) \\le 0$. If no such crossing occurs within the specified search interval, the drip-line is defined as the largest even $N$ in the interval with strictly positive $S_{2n}(Z,N)$; if no even $N$ has strictly positive $S_{2n}$ in the interval, define $N_{\\text{drip},2n}(Z)$ as the smallest even $N$ in the search interval.\n\nYou will consider a discrete model space of three EDF families indexed by $m \\in \\{\\text{Skyrme}, \\text{Gogny}, \\text{Covariant}\\}$, each represented by a fixed parameter vector $\\boldsymbol{\\theta}_m$ in the binding energy formula above:\n- Skyrme: $\\boldsymbol{\\theta}_{\\text{Skyrme}} = (a_v,a_s,a_c,a_a,a_p) = (15.8, 18.3, 0.70, 22.5, 11.0)$.\n- Gogny: $\\boldsymbol{\\theta}_{\\text{Gogny}} = (15.9, 17.5, 0.72, 24.0, 12.0)$.\n- Covariant: $\\boldsymbol{\\theta}_{\\text{Covariant}} = (16.2, 18.0, 0.68, 22.0, 10.5)$.\n\nFor calibration of model weights, you will be given a synthetic “ground-truth” generator, defined by a separate parameter vector:\n- Ground truth: $\\boldsymbol{\\theta}_{\\star} = (15.75, 17.8, 0.711, 23.7, 11.2)$.\n\nFrom this ground truth, you must generate a calibration dataset consisting of measured one- and two-neutron separation energies (noise-free for determinism) for the following nuclei:\n$$\n\\mathcal{D} \\equiv \\{(Z,N)\\} = \\{(8,8),(20,20),(28,30),(50,64),(82,126),(26,30),(28,50),(92,146)\\}.\n$$\nFor each $(Z,N)$ in $\\mathcal{D}$, define the observed values $y^{\\text{obs}}_{n}(Z,N) \\equiv S_n(Z,N;\\boldsymbol{\\theta}_{\\star})$ and $y^{\\text{obs}}_{2n}(Z,N) \\equiv S_{2n}(Z,N;\\boldsymbol{\\theta}_{\\star})$. Assume independent Gaussian likelihoods for each observed datum with a fixed calibration scale $\\sigma_{\\text{cal}} = 1.0$ (in MeV). You must treat all EDF families with equal prior probability, that is, $p(M_m) = 1/3$.\n\nYour first task is to compute Bayesian model posterior probabilities $p(M_m \\mid \\mathcal{D})$ over the three EDF families using the product of Gaussian likelihoods across all observed $S_n$ and $S_{2n}$ values in $\\mathcal{D}$, given the deterministic predictions $y_m$ of each model $M_m$:\n$$\n\\log p(\\mathcal{D} \\mid M_m) = -\\frac{1}{2}\\sum_{i=1}^{N_{\\text{obs}}}\\left( \\frac{(y^{\\text{obs}}_i - y_{m,i})^2}{\\sigma_{\\text{cal}}^2} + \\log(2\\pi \\sigma_{\\text{cal}}^2) \\right),\n$$\nwhere $N_{\\text{obs}}$ is the total number of observed scalars after stacking both $S_n$ and $S_{2n}$ across $\\mathcal{D}$. Use these to compute the posterior model weights\n$$\nw_m \\equiv p(M_m \\mid \\mathcal{D}) \\propto p(M_m)\\, p(\\mathcal{D} \\mid M_m),\n$$\nnormalized so that $\\sum_m w_m = 1$. You must use numerically stable normalization (for example, log-sum-exp).\n\nYour second task is to construct the Bayesian model averaged predictive distribution for $S_n$ and $S_{2n}$ at arbitrary $(Z,N)$, using the posterior model weights. For a scalar observable $Y \\in \\{S_n,S_{2n}\\}$ at a fixed $(Z,N)$, define the model predictions $Y_m$ for each $m$ and compute the Bayesian model averaged mean and variance:\n$$\n\\mu_Y \\equiv \\sum_m w_m\\, Y_m,\\quad \n\\sigma_Y^2 \\equiv \\sum_m w_m\\, \\big(Y_m - \\mu_Y\\big)^2.\n$$\nInterpret $\\sigma_Y$ as epistemic uncertainty arising from model-class disagreement. Do not add the calibration scale $\\sigma_{\\text{cal}}$ to the predictive variance; you are asked to report only the epistemic uncertainty.\n\nYour third task is to compute two-neutron drip-line positions for selected isotopic chains using the Bayesian model averaged means. For each specified $Z$, scan even $N$ from $N_{\\min}(Z)$ to $N_{\\max}(Z)$ inclusive, where\n$$\nN_{\\min}(Z) \\equiv \\max(2,Z),\\quad N_{\\max}(Z) \\equiv Z + 80.\n$$\nDefine $N_{\\text{drip},2n}(Z)$ as in the definition above, using the sign change of $\\mu_{S_{2n}}(Z,N)$ across even $N$.\n\nYour fourth task is to identify nuclei where model disagreement is maximal. For a specified grid $\\mathcal{G}(Z)$ per proton number $Z$, compute for each $(Z,N)$ in the grid the across-model range\n$$\n\\Delta_Y(Z,N) \\equiv \\max_m Y_m(Z,N) - \\min_m Y_m(Z,N),\n$$\nfor $Y \\in \\{S_n,S_{2n}\\}$. Report the $(Z,N)$ pair where $\\Delta_Y(Z,N)$ is maximized over the union of these grids, and report the corresponding maximal range value.\n\nImplementation and test suite.\n\n- Use the EDF parameter vectors given above for the three models and the ground truth.\n- Use calibration set $\\mathcal{D}$ as listed above and $\\sigma_{\\text{cal}} = 1.0$.\n- Target nuclei for epistemic uncertainty estimates (report only the epistemic standard deviations $\\sigma_{S_n}$ and $\\sigma_{S_{2n}}$):\n  - $(Z,N) = (20,20)$,\n  - $(Z,N) = (28,50)$,\n  - $(Z,N) = (8,20)$.\n- Two-neutron drip-line proton numbers (report $N_{\\text{drip},2n}(Z)$):\n  - $Z \\in \\{8,20,28\\}$.\n- Disagreement grids:\n  - For $Z \\in \\{8,20,28\\}$, scan $N$ from $N_{\\min}(Z)$ to $N_{\\max}^{\\text{grid}}(Z)$ inclusive, where $N_{\\max}^{\\text{grid}}(Z) \\equiv Z + 60$.\n  - For each $(Z,N)$ in these grids, compute $\\Delta_{S_{2n}}(Z,N)$ and $\\Delta_{S_n}(Z,N)$ and identify the unique $(Z,N)$ with the maximal value for each observable. In case of ties, choose the smallest $Z$, then the smallest $N$.\n\nNumerical and reporting requirements.\n\n- All separation energies must be computed and interpreted in MeV.\n- All outputs must be rounded as follows:\n  - For epistemic standard deviations $\\sigma_{S_n}$ and $\\sigma_{S_{2n}}$, round to three decimals.\n  - For drip-line neutron numbers $N_{\\text{drip},2n}(Z)$, report as integers.\n  - For maximal disagreement values $\\Delta_{S_{2n}}$ and $\\Delta_{S_n}$, round to three decimals.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the following order:\n  - $\\sigma_{S_n}$ for $(20,20)$,\n  - $\\sigma_{S_{2n}}$ for $(20,20)$,\n  - $\\sigma_{S_n}$ for $(28,50)$,\n  - $\\sigma_{S_{2n}}$ for $(28,50)$,\n  - $\\sigma_{S_n}$ for $(8,20)$,\n  - $\\sigma_{S_{2n}}$ for $(8,20)$,\n  - $N_{\\text{drip},2n}(8)$,\n  - $N_{\\text{drip},2n}(20)$,\n  - $N_{\\text{drip},2n}(28)$,\n  - $Z$ for the maximal $\\Delta_{S_{2n}}$,\n  - $N$ for the maximal $\\Delta_{S_{2n}}$,\n  - the maximal $\\Delta_{S_{2n}}$,\n  - $Z$ for the maximal $\\Delta_{S_n}$,\n  - $N$ for the maximal $\\Delta_{S_n}$,\n  - the maximal $\\Delta_{S_n}$.\n- The output must therefore contain exactly $15$ entries. For example, the output format must look like\n$$\n[\\text{float},\\text{float},\\text{float},\\text{float},\\text{float},\\text{float},\\text{int},\\text{int},\\text{int},\\text{int},\\text{int},\\text{float},\\text{int},\\text{int},\\text{float}],\n$$\nwith the floats rounded as specified and no additional whitespace beyond what is necessary to separate items by commas.\n\nAlgorithmic constraints and guidance.\n\n- Use only the definitions provided above and the principle of Bayesian model averaging over a discrete model set with uniform priors and Gaussian calibration likelihoods.\n- Ensure numerically stable computation of model posterior weights $w_m$ via log-sum-exp normalization.\n- All scans must adhere to the specified bounds $N_{\\min}(Z)$, $N_{\\max}(Z)$, and $N_{\\max}^{\\text{grid}}(Z)$.\n- The program must be deterministic and must not rely on random sampling.\n\nYour program must be a complete, runnable implementation that produces exactly one line of output with the required format and ordering.",
            "solution": "The user has provided a computational nuclear physics problem requiring the implementation of a Bayesian Model Averaging (BMA) procedure to quantify uncertainties in nuclear properties derived from the semi-empirical mass formula (SEMF). The problem is self-contained, scientifically grounded in established (though simplified) nuclear models and statistical methods, and well-posed with all necessary parameters, definitions, and procedures explicitly stated. The problem is therefore deemed **valid**.\n\nThe solution proceeds by implementing the specified models and algorithms in a step-by-step manner.\n\n**1. Implementation of the Nuclear Binding Energy Model**\n\nThe core of the problem is the Bethe–Weizsäcker semi-empirical mass formula for the binding energy $B(Z,N)$ of a nucleus with $Z$ protons and $N$ neutrons.\n$$\nB(Z,N; \\boldsymbol{\\theta}) = a_v A - a_s A^{2/3} - a_c \\frac{Z(Z-1)}{A^{1/3}} - a_a \\frac{(N-Z)^2}{A} + \\delta(Z,N)\n$$\nHere, $A = Z+N$ is the mass number and $\\boldsymbol{\\theta} = (a_v, a_s, a_c, a_a, a_p)$ is the vector of model parameters. The pairing term $\\delta(Z,N)$ depends on the parity of $Z$ and $N$:\n$$\n\\delta(Z,N) = \n\\begin{cases}\n+ a_p A^{-1/2},  \\text{if $Z$ and $N$ are even (even-even nucleus)},\\\\\n0,  \\text{if $A$ is odd (odd-A nucleus)},\\\\\n- a_p A^{-1/2},  \\text{if $Z$ and $N$ are odd (odd-odd nucleus)}.\n\\end{cases}\n$$\nThis function is implemented to accept $Z$, $N$, and the parameter vector $\\boldsymbol{\\theta}$ as inputs and return the binding energy in megaelectronvolts (MeV).\n\n**2. Implementation of Separation Energies**\n\nFrom the binding energy, we define and implement the one-neutron separation energy $S_n$ and two-neutron separation energy $S_{2n}$:\n$$\nS_n(Z,N) \\equiv B(Z,N) - B(Z,N-1), \\quad \\text{for } N \\ge 1\n$$\n$$\nS_{2n}(Z,N) \\equiv B(Z,N) - B(Z,N-2), \\quad \\text{for } N \\ge 2\n$$\nThese functions are implemented by calling the `binding_energy` function with the appropriate arguments.\n\n**3. Bayesian Model Averaging: Posterior Weight Calculation**\n\nThe problem defines a model space of three Energy Density Functional (EDF) families, each represented by a specific parameter set $\\boldsymbol{\\theta}_m$: $\\boldsymbol{\\theta}_{\\text{Skyrme}}$, $\\boldsymbol{\\theta}_{\\text{Gogny}}$, and $\\boldsymbol{\\theta}_{\\text{Covariant}}$. We must determine the posterior probability $p(M_m \\mid \\mathcal{D})$ for each model $M_m$ given an observational dataset $\\mathcal{D}$.\n\nFirst, the dataset $\\mathcal{D}$ is generated using a \"ground-truth\" model with parameters $\\boldsymbol{\\theta}_{\\star}$. For each of the $8$ nuclei $(Z,N)$ in the specified calibration set, we compute the true values $y^{\\text{obs}}_{n}(Z,N) = S_n(Z,N;\\boldsymbol{\\theta}_{\\star})$ and $y^{\\text{obs}}_{2n}(Z,N) = S_{2n}(Z,N;\\boldsymbol{\\theta}_{\\star})$. This results in $N_{\\text{obs}} = 16$ data points.\n\nThe posterior probability is given by Bayes' theorem: $p(M_m \\mid \\mathcal{D}) \\propto p(\\mathcal{D} \\mid M_m) p(M_m)$. The problem specifies uniform model priors, $p(M_m) = 1/3$. The likelihood $p(\\mathcal{D} \\mid M_m)$ is a product of independent Gaussian distributions, one for each observation. The log-likelihood is:\n$$\n\\log p(\\mathcal{D} \\mid M_m) = -\\frac{1}{2}\\sum_{i=1}^{N_{\\text{obs}}}\\left( \\frac{(y^{\\text{obs}}_i - y_{m,i})^2}{\\sigma_{\\text{cal}}^2} + \\log(2\\pi \\sigma_{\\text{cal}}^2) \\right)\n$$\nwhere $y_{m,i}$ are the predictions from model $M_m$ and $\\sigma_{\\text{cal}} = 1.0$ MeV is the fixed calibration scale.\nFor each model $m$, we compute its vector of predictions $\\{y_{m,i}\\}$ and then its log-likelihood.\nThe posterior weights $w_m \\equiv p(M_m \\mid \\mathcal{D})$ are calculated by normalizing the posteriors. To do this in a numerically stable way, we work in the log domain. The unnormalized log-posterior for model $m$ is $\\log p(M_m) + \\log p(\\mathcal{D} \\mid M_m)$. Since the prior is uniform, this is proportional to the log-likelihood (up to an additive constant). We compute the log-likelihood for each model, then use the log-sum-exp transformation to find the normalized weights $w_m$:\n$$\n\\log w_m = \\log p(\\mathcal{D} \\mid M_m) - \\text{logsumexp}_k(\\log p(\\mathcal{D} \\mid M_k))\n$$\n$$\nw_m = \\exp(\\log w_m)\n$$\n\n**4. Predictive Uncertainty Quantification**\n\nWith the posterior weights $w_m$, we can form a BMA prediction for any observable $Y$. For a given nucleus $(Z,N)$, each model $m$ provides a prediction $Y_m = Y(Z,N;\\boldsymbol{\\theta}_m)$. The BMA mean $\\mu_Y$ and epistemic variance $\\sigma_Y^2$ are:\n$$\n\\mu_Y = \\sum_m w_m Y_m\n$$\n$$\n\\sigma_Y^2 = \\sum_m w_m (Y_m - \\mu_Y)^2 = \\left(\\sum_m w_m Y_m^2\\right) - \\mu_Y^2\n$$\nThe problem asks for the epistemic standard deviation $\\sigma_Y = \\sqrt{\\sigma_Y^2}$ for $S_n$ and $S_{2n}$ at specific target nuclei.\n\n**5. Two-Neutron Drip-Line Calculation**\n\nThe two-neutron drip-line for a given $Z$ is found by searching for a sign change in the BMA-averaged two-neutron separation energy, $\\mu_{S_{2n}}(Z,N)$. The search is conducted for even $N$ in the interval $[N_{\\min}(Z), N_{\\max}(Z)]$, where $N_{\\min}(Z) = \\max(2,Z)$ and $N_{\\max}(Z) = Z+80$. The drip-line $N_{\\text{drip},2n}(Z)$ is defined as the largest even $N$ in this interval such that $\\mu_{S_{2n}}(Z,N)  0$ and $\\mu_{S_{2n}}(Z,N+2) \\le 0$. The definition includes fallback cases for when no such crossing occurs or when no nucleus in the chain is stable against two-neutron emission. The algorithm must carefully implement this three-part definition.\n\n**6. Identification of Maximal Model Disagreement**\n\nTo find where the models disagree most, we compute the range of predictions for $S_n$ and $S_{2n}$ for each nucleus $(Z,N)$ in specified grids. The range is defined as:\n$$\n\\Delta_Y(Z,N) = \\max_m Y_m(Z,N) - \\min_m Y_m(Z,N)\n$$\nWe iterate through the grids defined for $Z \\in \\{8, 20, 28\\}$ with $N$ from $N_{\\min}(Z)$ to $Z+60$. We keep track of the maximum $\\Delta_Y$ found for $Y=S_n$ and $Y=S_{2n}$, along with the corresponding $(Z,N)$ coordinates. The specified tie-breaking rule (smallest $Z$, then smallest $N$) is naturally handled by the order of the search loops.\n\n**7. Final Assembly of Results**\n\nThe final step is to collect all computed quantities in the specified order: six epistemic standard deviations, three drip-line neutron numbers, and two sets of $(Z,N,\\Delta)$ for maximal disagreement. These $15$ values are rounded according to the given precision requirements and formatted into a single-line comma-separated list.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Implements the full Bayesian model averaging procedure as specified.\n    \"\"\"\n    \n    # 1. Define constants, parameters, and datasets\n    \n    # Model parameters: (a_v, a_s, a_c, a_a, a_p) in MeV\n    params = {\n        'Skyrme': np.array([15.8, 18.3, 0.70, 22.5, 11.0]),\n        'Gogny': np.array([15.9, 17.5, 0.72, 24.0, 12.0]),\n        'Covariant': np.array([16.2, 18.0, 0.68, 22.0, 10.5]),\n    }\n    model_names = list(params.keys())\n    \n    # Ground-truth parameters\n    params_gt = np.array([15.75, 17.8, 0.711, 23.7, 11.2])\n    \n    # Calibration dataset D\n    calibration_nuclei = [\n        (8, 8), (20, 20), (28, 30), (50, 64), (82, 126),\n        (26, 30), (28, 50), (92, 146)\n    ]\n    \n    # Calibration scale\n    sigma_cal = 1.0\n    \n    # 2. Implement core physics functions\n\n    # Memoization cache for binding energy to speed up repeated calculations\n    be_cache = {}\n\n    def binding_energy(Z, N, p):\n        \"\"\"Calculates binding energy using the semi-empirical mass formula.\"\"\"\n        Z, N = int(Z), int(N)\n        p_tuple = tuple(p)\n        if (Z, N, p_tuple) in be_cache:\n            return be_cache[(Z, N, p_tuple)]\n            \n        if Z  0 or N  0 or Z + N == 0:\n            return 0.0\n\n        A = Z + N\n        a_v, a_s, a_c, a_a, a_p = p\n        \n        vol_term = a_v * A\n        surf_term = -a_s * A**(2/3)\n        coulomb_term = -a_c * Z * (Z - 1) / A**(1/3) if A  0 else 0\n        asym_term = -a_a * (N - Z)**2 / A if A  0 else 0\n        \n        pairing_term = 0.0\n        if Z % 2 == 0 and N % 2 == 0: # a.k.a. A even\n            pairing_term = a_p * A**(-0.5)\n        elif Z % 2 != 0 and N % 2 != 0: # a.k.a. A even\n            pairing_term = -a_p * A**(-0.5)\n        # else A is odd, pairing_term is 0\n\n        B = vol_term + surf_term + coulomb_term + asym_term + pairing_term\n        be_cache[(Z, N, p_tuple)] = B\n        return B\n\n    def s_n(Z, N, p):\n        \"\"\"Calculates one-neutron separation energy.\"\"\"\n        if N  1: return np.nan\n        return binding_energy(Z, N, p) - binding_energy(Z, N - 1, p)\n\n    def s_2n(Z, N, p):\n        \"\"\"Calculates two-neutron separation energy.\"\"\"\n        if N  2: return np.nan\n        return binding_energy(Z, N, p) - binding_energy(Z, N - 2, p)\n\n    # 3. Generate calibration data\n    \n    y_obs = []\n    for Z, N in calibration_nuclei:\n        y_obs.append(s_n(Z, N, params_gt))\n        y_obs.append(s_2n(Z, N, params_gt))\n    y_obs = np.array(y_obs)\n\n    # 4. Calculate posterior model weights\n    \n    log_likelihoods = []\n    for name in model_names:\n        p_model = params[name]\n        y_model = []\n        for Z, N in calibration_nuclei:\n            y_model.append(s_n(Z, N, p_model))\n            y_model.append(s_2n(Z, N, p_model))\n        y_model = np.array(y_model)\n\n        # Sum of squared errors\n        sse = np.sum((y_obs - y_model)**2)\n        # Log-likelihood, ignoring constant terms that cancel in normalization\n        log_L = -0.5 * sse / (sigma_cal**2)\n        log_likelihoods.append(log_L)\n    \n    # Normalize log-likelihoods to get log-weights (uniform prior)\n    log_weights = np.array(log_likelihoods) - logsumexp(log_likelihoods)\n    weights = np.exp(log_weights)\n\n    # 5. BMA prediction helper function\n    \n    def predict_bma(Z, N, sep_energy_func):\n        \"\"\"Calculates BMA mean, epistemic std dev, and individual predictions.\"\"\"\n        predictions = np.array([sep_energy_func(Z, N, params[name]) for name in model_names])\n        mean = np.sum(weights * predictions)\n        variance = np.sum(weights * predictions**2) - mean**2\n        std_dev = np.sqrt(variance) if variance  0 else 0.0\n        return mean, std_dev, predictions\n\n    # 6. Perform the required calculations\n\n    # Task 1: Epistemic uncertainties for target nuclei\n    targets_std = [(20, 20), (28, 50), (8, 20)]\n    std_dev_results = []\n    for Z, N in targets_std:\n        _, std_sn, _ = predict_bma(Z, N, s_n)\n        _, std_s2n, _ = predict_bma(Z, N, s_2n)\n        std_dev_results.extend([std_sn, std_s2n])\n\n    # Task 2: Two-neutron drip-line positions\n    drip_line_Zs = [8, 20, 28]\n    drip_line_results = []\n    for Z in drip_line_Zs:\n        N_min = max(2, Z)\n        # The scan must be over even N\n        if N_min % 2 != 0: N_min += 1\n        N_max = Z + 80\n\n        s2n_means = {N: predict_bma(Z, N, s_2n)[0] for N in range(N_min, N_max + 3, 2)}\n        \n        drip_crossings = []\n        positive_s2n_Ns = []\n        \n        for N in range(N_min, N_max + 1, 2):\n            s2n_current = s2n_means[N]\n            if s2n_current  0:\n                positive_s2n_Ns.append(N)\n                s2n_next = s2n_means[N+2]\n                if s2n_next = 0:\n                    drip_crossings.append(N)\n        \n        if drip_crossings:\n            drip_line_results.append(max(drip_crossings))\n        elif positive_s2n_Ns:\n            drip_line_results.append(max(positive_s2n_Ns))\n        else:\n            drip_line_results.append(N_min)\n\n    # Task 3: Maximal model disagreement\n    disagreement_Zs = [8, 20, 28]\n    max_delta_sn = -1.0\n    zn_max_delta_sn = (-1, -1)\n    max_delta_s2n = -1.0\n    zn_max_delta_s2n = (-1, -1)\n\n    for Z in disagreement_Zs:\n        N_min = max(2, Z)\n        N_max_grid = Z + 60\n        for N in range(N_min, N_max_grid + 1):\n            # S_n\n            if N = 1:\n                _, _, preds_sn = predict_bma(Z, N, s_n)\n                delta_sn = np.max(preds_sn) - np.min(preds_sn)\n                if delta_sn  max_delta_sn:\n                    max_delta_sn = delta_sn\n                    zn_max_delta_sn = (Z, N)\n            \n            # S_2n\n            if N = 2:\n                _, _, preds_s2n = predict_bma(Z, N, s_2n)\n                delta_s2n = np.max(preds_s2n) - np.min(preds_s2n)\n                if delta_s2n  max_delta_s2n:\n                    max_delta_s2n = delta_s2n\n                    zn_max_delta_s2n = (Z, N)\n    \n    disagreement_results_s2n = [zn_max_delta_s2n[0], zn_max_delta_s2n[1], max_delta_s2n]\n    disagreement_results_sn = [zn_max_delta_sn[0], zn_max_delta_sn[1], max_delta_sn]\n\n    # 7. Assemble final output\n    \n    results = [\n        round(std_dev_results[0], 3), round(std_dev_results[1], 3),\n        round(std_dev_results[2], 3), round(std_dev_results[3], 3),\n        round(std_dev_results[4], 3), round(std_dev_results[5], 3),\n        drip_line_results[0], drip_line_results[1], drip_line_results[2],\n        disagreement_results_s2n[0], disagreement_results_s2n[1], round(disagreement_results_s2n[2], 3),\n        disagreement_results_sn[0], disagreement_results_sn[1], round(disagreement_results_sn[2], 3),\n    ]\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}