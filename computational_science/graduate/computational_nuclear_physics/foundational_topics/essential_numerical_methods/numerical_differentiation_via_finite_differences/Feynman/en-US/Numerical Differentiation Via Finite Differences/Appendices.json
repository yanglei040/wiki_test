{
    "hands_on_practices": [
        {
            "introduction": "This exercise serves as the cornerstone of our practical work, connecting the abstract theory of Taylor series to concrete numerical code. You will derive the workhorse of finite differences—the second-order central difference formula—from first principles and then implement it to approximate the derivative of a Gaussian function, which frequently models single-particle wavefunctions. By comparing your numerical results to the exact error terms, you will gain a tangible understanding of truncation error and its dependence on the grid spacing $h$. ",
            "id": "3576237",
            "problem": "Consider the numerical differentiation of a one-dimensional single-particle orbital often modeled by a Gaussian profile in computational nuclear physics, such as those appearing in mean-field approximations and Time-Dependent Hartree-Fock (TDHF) implementations. Let the test function be $f(x) = e^{-x^{2}}$, which is dimensionless. The objective is to construct and analyze the second-order central difference estimator for the first derivative and to relate its observed error to the leading truncation term predicted by Taylor expansion.\n\nStarting from first principles, use the definition of the derivative and the Taylor series expansion of an analytic function about a point $x_{0}$ to derive the second-order central difference approximation of $f'(x_{0})$ and its leading truncation term. Do not start from any pre-stated finite-difference formulas. After deriving the approximation and the leading truncation term, implement a computation of the following quantities for specified values of $x_{0}$ and $h$:\n- The second-order central difference estimate $D(x_{0}, h) = \\dfrac{f(x_{0}+h) - f(x_{0}-h)}{2h}$.\n- The exact derivative $f'(x_{0})$.\n- The measured error $E(x_{0}, h) = D(x_{0}, h) - f'(x_{0})$.\n- The theoretical leading truncation term $T(x_{0}, h)$ obtained by your derivation in terms of derivatives of $f$ evaluated at $x_{0}$ and powers of $h$.\n- The comparison scalar $\\Delta(x_{0}, h) = E(x_{0}, h) - T(x_{0}, h)$.\n\nAll quantities are dimensionless. Angles are not involved. The program must compute $\\Delta(x_{0}, h)$ for each test case listed below and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite.\n\nUse the following test suite covering typical, scaling, and edge conditions:\n1. $x_{0} = 0.0$, $h = 10^{-2}$.\n2. $x_{0} = 0.5$, $h = 10^{-2}$.\n3. $x_{0} = 0.5$, $h = 10^{-3}$.\n4. $x_{0} = 1.5$, $h = 10^{-2}$.\n5. $x_{0} = 0.0$, $h = 10^{-8}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_{1},r_{2},r_{3},r_{4},r_{5}]$), where each $r_{i}$ is the floating-point value of $\\Delta(x_{0}, h)$ for the corresponding test case, evaluated to full double-precision without rounding in the printout.",
            "solution": "The problem is scientifically valid and represents a fundamental verification exercise in numerical methods. It requires the derivation of the central difference formula and its leading error term, followed by a numerical implementation to confirm the theoretical result.\n\n### Derivation of the Central Difference Formula and Truncation Error\n\nWe begin with the Taylor series expansions of a sufficiently smooth function $f(x)$ around a point $x_0$:\n$$ f(x_0 + h) = f(x_0) + hf'(x_0) + \\frac{h^2}{2!}f''(x_0) + \\frac{h^3}{3!}f'''(x_0) + O(h^4) $$\n$$ f(x_0 - h) = f(x_0) - hf'(x_0) + \\frac{h^2}{2!}f''(x_0) - \\frac{h^3}{3!}f'''(x_0) + O(h^4) $$\nSubtracting the second expansion from the first causes the even-powered derivative terms (including $f(x_0)$ and $f''(x_0)$) to cancel, while the odd-powered terms add up:\n$$ f(x_0 + h) - f(x_0 - h) = 2hf'(x_0) + \\frac{2h^3}{6}f'''(x_0) + O(h^5) $$\nRearranging this equation to solve for the derivative $f'(x_0)$ gives:\n$$ f'(x_0) = \\frac{f(x_0 + h) - f(x_0 - h)}{2h} - \\frac{h^2}{6}f'''(x_0) - O(h^4) $$\nFrom this expression, we can identify two key components:\n1.  **The Second-Order Central Difference Approximation:** This is the discrete formula used to estimate the derivative:\n    $$ D(x_0, h) = \\frac{f(x_0 + h) - f(x_0 - h)}{2h} $$\n2.  **The Leading Truncation Term:** This is the dominant term in the error we introduce by \"truncating\" the infinite Taylor series. The error of the approximation is $D(x_0, h) - f'(x_0)$. From our rearranged equation, this error is:\n    $$ E(x_0, h) = D(x_0, h) - f'(x_0) = \\frac{h^2}{6}f'''(x_0) + O(h^4) $$\n    Therefore, the theoretical leading truncation term is:\n    $$ T(x_0, h) = \\frac{h^2}{6}f'''(x_0) $$\n    The error is proportional to $h^2$, making this a second-order accurate method.\n\n### Algorithmic Implementation\n\nFor the numerical part, the program will implement the following for each test case:\n1.  Define the function $f(x) = e^{-x^2}$ and its exact first and third derivatives: $f'(x) = -2xe^{-x^2}$ and $f'''(x) = (12x - 8x^3)e^{-x^2}$.\n2.  Compute the central difference estimate $D(x_0, h)$.\n3.  Compute the exact derivative $f'(x_0)$.\n4.  Compute the measured error $E(x_0, h) = D(x_0, h) - f'(x_0)$.\n5.  Compute the theoretical leading truncation term $T(x_0, h) = \\frac{h^2}{6}f'''(x_0)$.\n6.  Calculate the final comparison scalar $\\Delta(x_0, h) = E(x_0, h) - T(x_0, h)$. This value represents the contribution from higher-order terms in the Taylor series (and floating-point error), and should be much smaller than $E$ or $T$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the difference between the measured error and the theoretical\n    leading truncation term for the central difference approximation of the\n    first derivative of f(x) = exp(-x^2).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 1e-2),\n        (0.5, 1e-2),\n        (0.5, 1e-3),\n        (1.5, 1e-2),\n        (0.0, 1e-8),\n    ]\n\n    results = []\n    \n    # Define the required functions and their derivatives.\n    # f(x) = exp(-x^2)\n    def f(x):\n        return np.exp(-x**2)\n    \n    # f'(x) = -2x * exp(-x^2)\n    def f_prime(x):\n        return -2.0 * x * np.exp(-x**2)\n\n    # f'''(x) = (-8x^3 + 12x) * exp(-x^2)\n    def f_triple_prime(x):\n        return (-8.0 * x**3 + 12.0 * x) * np.exp(-x**2)\n\n    for x0, h in test_cases:\n        # Calculate the second-order central difference estimate D(x0, h).\n        # D(x0, h) = (f(x0 + h) - f(x0 - h)) / (2h)\n        d_val = (f(x0 + h) - f(x0 - h)) / (2.0 * h)\n        \n        # Calculate the exact derivative f'(x0).\n        fp_exact = f_prime(x0)\n        \n        # Calculate the measured error E(x0, h).\n        # E(x0, h) = D(x0, h) - f'(x0)\n        e_val = d_val - fp_exact\n        \n        # Calculate the theoretical leading truncation term T(x0, h).\n        # T(x0, h) = (h^2 / 6) * f'''(x0)\n        t_val = (h**2 / 6.0) * f_triple_prime(x0)\n        \n        # Calculate the comparison scalar Delta(x0, h).\n        # Delta(x0, h) = E(x0, h) - T(x0, h)\n        delta_val = e_val - t_val\n        \n        results.append(delta_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Physical systems are defined not just by their governing equations but also by their boundaries. This practice addresses the critical task of implementing derivative boundary conditions, such as the zero-flux (Neumann) condition at a reflective surface in a nuclear reactor model. You will derive and apply the ghost-cell method, a powerful and widely used technique to extend the use of symmetric stencils to the edge of a computational domain while maintaining the scheme's accuracy. ",
            "id": "3576260",
            "problem": "Consider a one-dimensional uniform grid defined by $x_i = i h$ for integer $i$ and grid spacing $h = 1/N$ on the interval $[0,1]$. Let $f(x)$ denote a sufficiently smooth scalar field, which in computational nuclear physics can represent the one-dimensional neutron scalar flux in a slab with a reflective boundary at $x=0$. A reflective boundary is modeled by a Neumann boundary condition $f'(0)=0$. In order to apply standard second-order central differencing uniformly near the boundary, introduce a single ghost cell located at $x_{-1} = -h$ with value $f_{-1}$ to be determined by extrapolation so that the discrete scheme is consistent with $f'(0)=0$.\n\nStarting from the fundamental definition of the derivative $f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$, and using Taylor series expansions about $x=0$ for $f(h)$ and $f(-h)$ up to an order sufficient to assess the truncation error, derive an extrapolation formula expressing the ghost-cell value $f_{-1}$ in terms of grid values that enforces the Neumann boundary condition $f'(0)=0$ to second-order accuracy. Briefly justify the order of accuracy of your extrapolation.\n\nAfter deriving the formula, write a complete program that:\n- Constructs the grid $x_i = i h$ with $h = 1/N$ for specified integers $N$, evaluates $f(x_i)$ for a set of test functions $f$, and computes the ghost-cell value $f_{-1}$ via your derived extrapolation.\n- Uses the standard second-order central-difference formula to approximate $f'(x)$ at the first interior point $x=h$, namely\n$$\n\\left.\\frac{df}{dx}\\right|_{x=h} \\approx \\frac{f(2h) - f(0)}{2h},\n$$\nand computes the absolute error with respect to the exact derivative $f'(h)$ for each test case.\n- Uses the ghost-cell value to approximate the boundary derivative at $x=0$ via the central-difference formula that references the ghost cell,\n$$\n\\left.\\frac{df}{dx}\\right|_{x=0} \\approx \\frac{f(h) - f(-h)}{2h},\n$$\nand checks whether this approximation satisfies the Neumann boundary condition $f'(0)=0$ to within a tolerance of $10^{-12}$.\n\nUse the following test suite, where the argument of trigonometric functions is in radians:\n1. $f(x) = \\cos(\\pi x)$ with $N = 10$.\n2. $f(x) = e^{-x^2}$ with $N = 100$.\n3. $f(x) = 1 + x^4$ with $N = 2$.\n4. Edge case: $f(x) = x$ with $N = 10$ (this function does not satisfy $f'(0)=0$; include it to probe the behavior of the ghost-cell enforcement).\n\nFor each test case, your program must output three values in the following order:\n- The central-difference approximation of $f'(h)$ as a float.\n- The absolute error $\\left|\\text{approx} - f'(h)\\right|$ as a float.\n- A boolean indicating whether the boundary derivative approximation at $x=0$ computed using the ghost cell satisfies $\\left|\\left.\\frac{df}{dx}\\right|_{x=0}\\right| \\le 10^{-12}$.\n\nFinal output format: Your program should produce a single line of output containing all results concatenated for the four test cases as a comma-separated list enclosed in square brackets. For example, the output should have the form\n$[r_1,e_1,b_1,r_2,e_2,b_2,r_3,e_3,b_3,r_4,e_4,b_4]$,\nwhere $r_k$ are floats, $e_k$ are floats, and $b_k$ are booleans corresponding to the $k$-th test case.",
            "solution": "The problem is valid. It is a well-posed, scientifically grounded problem in numerical analysis, specifically concerning the implementation of a Neumann boundary condition using a ghost-cell technique for finite-difference methods. All necessary information is provided, the task is formalizable, and it is a standard exercise in computational science.\n\n### Part 1: Derivation of the Ghost-Cell Extrapolation Formula\n\nThe central task is to find an extrapolation formula for the value of a function $f(x)$ at a ghost-cell point $x_{-1} = -h$, denoted $f_{-1}$, such that the Neumann boundary condition $f'(0)=0$ is satisfied to second-order accuracy. We use the standard second-order central-difference formula for the first derivative, evaluated at the boundary $x=0$.\n\nThe Taylor series expansions for a sufficiently smooth function $f(x)$ about the point $x=0$ are:\n$$\nf(x) = f(0) + x f'(0) + \\frac{x^2}{2!} f''(0) + \\frac{x^3}{3!} f'''(0) + \\dots\n$$\nEvaluating this expansion at the grid points $x_1 = h$ and $x_{-1} = -h$:\n$$\nf(h) = f(0) + h f'(0) + \\frac{h^2}{2} f''(0) + \\frac{h^3}{6} f'''(0) + O(h^4)\n$$\n$$\nf(-h) = f(0) - h f'(0) + \\frac{h^2}{2} f''(0) - \\frac{h^3}{6} f'''(0) + O(h^4)\n$$\nSubtracting the second expression from the first yields:\n$$\nf(h) - f(-h) = 2h f'(0) + \\frac{h^3}{3} f'''(0) + O(h^5)\n$$\nRearranging this to form an approximation for $f'(0)$ gives the symmetric central-difference formula:\n$$\n\\frac{f(h) - f(-h)}{2h} = f'(0) + \\frac{h^2}{6} f'''(0) + O(h^4)\n$$\nThis formula approximates $f'(0)$ with a truncation error of $O(h^2)$, making it a second-order accurate scheme.\n\nThe problem requires us to enforce the Neumann boundary condition $f'(0)=0$. The standard method for doing this with a ghost cell is to require that the discrete approximation of the derivative at the boundary satisfies the condition. We therefore set our discrete operator, which uses the grid value $f_1 = f(h)$ and the ghost-cell value $f_{-1} = f(-h)$, to zero:\n$$\n\\frac{f_1 - f_{-1}}{2h} = 0\n$$\nSolving for the ghost-cell value $f_{-1}$ gives the desired extrapolation formula:\n$$\nf_{-1} = f_1\n$$\n\n### Part 2: Justification of Accuracy\n\nThe problem asks to justify that this extrapolation enforces the condition to second-order accuracy. The justification lies in the accuracy of the underlying finite-difference operator. As derived above, the central-difference operator $\\frac{f(h) - f(-h)}{2h}$ is a second-order accurate approximation of the true derivative $f'(0)$. By defining the ghost-cell value $f_{-1}$ such that this discrete operator evaluates to exactly zero, we are enforcing the condition $f'(0)=0$ with a method that is formally second-order accurate. That is, the method would converge to the true derivative at a rate of $O(h^2)$ if we were not forcing it to be zero. For a function that truly satisfies $f'(0)=0$, the value that the discrete operator *should* have is not zero, but rather $\\frac{h^2}{6}f'''(0)$. By setting the operator to zero via the choice $f_{-1}=f_1$, we introduce an error proportional to $h^2$ in the representation of the boundary condition, which is consistent with a second-order accurate scheme.\n\n### Part 3: Algorithmic Implementation\n\nThe program will proceed as follows for each test case $(f, f', N)$:\n1.  Define the grid spacing $h = 1/N$.\n2.  Calculate the necessary function values at grid points: $f_0 = f(0)$, $f_1 = f(h)$, and $f_2 = f(2h)$.\n3.  Apply the derived extrapolation formula to find the ghost-cell value: $f_{-1} = f_1$.\n4.  Calculate the approximation of the derivative at the first interior point $x=h$ using the specified central-difference formula:\n    $$\n    f'(h)_{\\text{approx}} = \\frac{f_2 - f_0}{2h}\n    $$\n5.  Calculate the absolute error of this approximation with respect to the exact derivative $f'(h)$.\n    $$\n    \\text{Error}_h = |f'(h)_{\\text{approx}} - f'(h)|\n    $$\n6.  Calculate the approximation of the derivative at the boundary $x=0$ using the central-difference formula that includes the ghost cell:\n    $$\n    f'(0)_{\\text{approx}} = \\frac{f_1 - f_{-1}}{2h}\n    $$\n    With our extrapolation, this value will be exactly zero.\n7.  Verify if the absolute value of this boundary derivative approximation is within the specified tolerance of $10^{-12}$.\n    $$\n    |f'(0)_{\\text{approx}}| \\le 10^{-12}\n    $$\nThe results from each test case—the derivative approximation at $h$, its error, and the boolean verification at the boundary—are collected and formatted into a single output line.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of deriving and applying a ghost-cell extrapolation for a\n    Neumann boundary condition.\n    \"\"\"\n\n    # Define the test suite: a list of tuples, each containing:\n    # 1. The function f(x)\n    # 2. The exact derivative f'(x)\n    # 3. The number of grid intervals N\n    test_cases = [\n        (lambda x: np.cos(np.pi * x), lambda x: -np.pi * np.sin(np.pi * x), 10),\n        (lambda x: np.exp(-x**2), lambda x: -2 * x * np.exp(-x**2), 100),\n        (lambda x: 1.0 + x**4, lambda x: 4 * x**3, 2),\n        (lambda x: x, lambda x: 1.0, 10),\n    ]\n\n    all_results = []\n    TOLERANCE = 1e-12\n\n    for f, f_prime, N in test_cases:\n        # 1. Construct grid and evaluate function at required points\n        h = 1.0 / N\n        x0, x1, x2 = 0.0, h, 2 * h\n        \n        f0 = f(x0)\n        f1 = f(x1)\n        f2 = f(x2)\n\n        # 2. Derive ghost-cell value using f_{-1} = f_1\n        # This formula enforces the discrete derivative (f_1 - f_{-1})/(2h) = 0\n        fm1 = f1\n\n        # 3. Compute the central-difference approximation of f'(h)\n        # Formula: (f(x+h) - f(x-h)) / (2h) evaluated at x=h.\n        # This is (f(2h) - f(0)) / (2h)\n        dfdx_h_approx = (f2 - f0) / (2 * h)\n\n        # 4. Compute the absolute error of the f'(h) approximation\n        dfdx_h_exact = f_prime(x1)\n        abs_error_h = np.abs(dfdx_h_approx - dfdx_h_exact)\n\n        # 5. Compute the boundary derivative at x=0 using the ghost cell\n        # Formula: (f(h) - f(-h)) / (2h)\n        # Using the ghost cell value, this is (f1 - fm1) / (2h)\n        dfdx_0_approx = (f1 - fm1) / (2 * h)\n\n        # 6. Check if the boundary condition is satisfied to within tolerance\n        boundary_check = np.abs(dfdx_0_approx) <= TOLERANCE\n        \n        # Append the three required results for this test case\n        all_results.append(dfdx_h_approx)\n        all_results.append(abs_error_h)\n        all_results.append(boundary_check)\n\n    # Final print statement in the exact required format.\n    # The output format is a single line with a flat list of results.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the 1D foundation, we now scale our methods to three dimensions to construct one of the most important operators in physics: the Laplacian, $\\nabla^{2}$. This final exercise guides you through implementing the 7-point stencil for the Laplacian, an operator central to the Schrödinger, heat, and Poisson equations. You will assess the accuracy of your implementation against an analytical solution and confirm its second-order convergence, a standard verification procedure for any serious computational physics code. ",
            "id": "3576233",
            "problem": "You are to derive, implement, and verify a second-order accurate finite-difference discretization of the three-dimensional Laplacian operator using a seven-point stencil, then measure the discrete error and demonstrate second-order convergence under grid refinement. This exercise is motivated by computational treatments of partial differential equations in computational nuclear physics, such as neutron diffusion or mean-field equations, where accurate and efficient approximations to the Laplacian are critical.\n\nStart from the fundamental definition that the Laplacian of a sufficiently smooth scalar field $f(x,y,z)$ is the sum of its unmixed second partial derivatives, $\\nabla^{2} f = \\frac{\\partial^{2} f}{\\partial x^{2}} + \\frac{\\partial^{2} f}{\\partial y^{2}} + \\frac{\\partial^{2} f}{\\partial z^{2}}$. On a structured Cartesian grid with uniform spacings $h_{x}$, $h_{y}$, and $h_{z}$ along the $x$, $y$, and $z$ directions, respectively, the seven-point stencil approximation uses only nearest-neighbor samples in the coordinate-aligned directions. Derive a consistent, second-order accurate, central-difference discretization for each second derivative using Taylor series expansions and then combine them to form a discrete Laplacian acting on interior grid points. For boundary treatment, impose Dirichlet boundary conditions by sampling the exact analytical function at the domain boundary.\n\nConsider the smooth test function $f(x,y,z) = \\sin x \\,\\cos y \\,\\exp z$, which is representative of separable angular and radial dependences encountered in simplified models of nuclear systems. Angles must be interpreted in radians. Derive the exact Laplacian $\\nabla^{2} f$ analytically for this $f$, and use it as the reference to assess discretization error.\n\nDefine the discrete $L^{2}$ error norm on the interior grid as follows. Let the domain be a rectangular box $[0,L_{x}]\\times[0,L_{y}]\\times[0,L_{z}]$ partitioned by $N_{x}$, $N_{y}$, $N_{z}$ grid points in each direction (including boundaries), with $h_{x} = L_{x}/(N_{x}-1)$, $h_{y} = L_{y}/(N_{y}-1)$, and $h_{z} = L_{z}/(N_{z}-1)$. Let $\\mathcal{I}$ denote the set of interior indices $(i,j,k)$ with $1 \\le i \\le N_{x}-2$, $1 \\le j \\le N_{y}-2$, $1 \\le k \\le N_{z}-2$. If $\\mathcal{L}_{h} f$ denotes your discrete Laplacian applied to the grid samples of $f$, and $(\\nabla^{2}f)_{\\text{exact}}$ denotes the exact analytical Laplacian evaluated at grid nodes, define\n$$\nE_{2}(h_{x},h_{y},h_{z}) \\equiv \\left( \\sum_{(i,j,k)\\in \\mathcal{I}} \\left[ \\mathcal{L}_{h} f - (\\nabla^{2}f)_{\\text{exact}} \\right]^{2} \\, h_{x} h_{y} h_{z} \\right)^{1/2}.\n$$\nDemonstrate second-order convergence by refining the grid in each coordinate direction by a factor of two (which halves each spacing). Given a base grid with $(N_{x},N_{y},N_{z})$, define the refined grid by $(N'_{x},N'_{y},N'_{z})$ with\n$$\nN'_{x} = 2\\,(N_{x}-1) + 1,\\quad N'_{y} = 2\\,(N_{y}-1) + 1,\\quad N'_{z} = 2\\,(N_{z}-1) + 1,\n$$\nso that $h'_{x} = h_{x}/2$, $h'_{y} = h_{y}/2$, $h'_{z} = h_{z}/2$. For each test case, compute the observed order of convergence\n$$\np \\equiv \\log_{2} \\left( \\frac{E_{2}(h_{x},h_{y},h_{z})}{E_{2}(h'_{x},h'_{y},h'_{z})} \\right).\n$$\n\nImplement a complete, runnable program that:\n- Constructs the grids and evaluates $f$ and $(\\nabla^{2}f)_{\\text{exact}}$ at all nodes.\n- Enforces Dirichlet boundary conditions by setting boundary values of $f$ to the exact $f$.\n- Applies your seven-point discrete Laplacian $\\mathcal{L}_{h}$ to interior nodes only.\n- Computes $E_{2}(h_{x},h_{y},h_{z})$ and $E_{2}(h'_{x},h'_{y},h'_{z})$ for each test case.\n- Reports the observed order $p$ for each test case.\n\nAngles must be in radians. There are no physical unit conversions required beyond stating the angles in radians.\n\nUse the following test suite to exercise general and edge-case behavior:\n- Test case A (happy path, cubic-ish grid): $L_{x}=\\pi$, $L_{y}=\\pi/2$, $L_{z}=1$, with base $(N_{x},N_{y},N_{z})=(17,17,17)$ and refined $(33,33,33)$.\n- Test case B (anisotropic spacings and non-cubic counts): $L_{x}=\\pi$, $L_{y}=\\pi$, $L_{z}=1/2$, with base $(N_{x},N_{y},N_{z})=(18,14,10)$ and refined $(35,27,19)$.\n- Test case C (moderate, strongly anisotropic domain extents): $L_{x}=2$, $L_{y}=1$, $L_{z}=1/4$, with base $(N_{x},N_{y},N_{z})=(5,7,9)$ and refined $(9,13,17)$.\n\nYour program must produce a single line of output containing the observed orders $p$ for the three test cases, in the order A, B, C, as a comma-separated list enclosed in square brackets. For reproducibility and comparison, round each reported $p$ to $6$ decimal places. For example, the output format must be of the form\n$$\n[\\text{p\\_A},\\text{p\\_B},\\text{p\\_C}]\n$$\nwhere each entry is a floating-point number with $6$ digits after the decimal point.",
            "solution": "The problem requires the derivation, implementation, and verification of a second-order accurate finite-difference scheme for the three-dimensional Laplacian operator, $\\nabla^2$. The verification will be performed by measuring the convergence rate of the discretization error for a known smooth function.\n\n### 1. Derivation of the Seven-Point Finite-Difference Stencil\n\nThe Laplacian of a scalar field $f(x,y,z)$ is defined as $\\nabla^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} + \\frac{\\partial^2 f}{\\partial z^2}$. We seek a discrete approximation for this operator on a Cartesian grid with points $(x_i, y_j, z_k)$, where $x_i = i h_x$, $y_j = j h_y$, and $z_k = k h_z$ for uniform grid spacings $h_x, h_y, h_z$.\n\nThe core of the method is the central-difference approximation for the second derivative. Consider a one-dimensional function $u(x)$. Its Taylor series expansions around a point $x$ are:\n$$ u(x+h) = u(x) + h u'(x) + \\frac{h^2}{2!} u''(x) + \\frac{h^3}{3!} u'''(x) + \\frac{h^4}{4!} u^{(4)}(x) + O(h^5) $$\n$$ u(x-h) = u(x) - h u'(x) + \\frac{h^2}{2!} u''(x) - \\frac{h^3}{3!} u'''(x) + \\frac{h^4}{4!} u^{(4)}(x) - O(h^5) $$\nAdding these two expressions eliminates the odd-powered derivative terms:\n$$ u(x+h) + u(x-h) = 2u(x) + h^2 u''(x) + \\frac{h^4}{12} u^{(4)}(x) + O(h^6) $$\nSolving for $u''(x)$ yields:\n$$ u''(x) = \\frac{u(x+h) - 2u(x) + u(x-h)}{h^2} - \\frac{h^2}{12} u^{(4)}(x) + O(h^4) $$\nThe finite-difference approximation is the first term on the right-hand side. The truncation error is $-\\frac{h^2}{12}u^{(4)}(x) + O(h^4)$, which is of order $O(h^2)$. The approximation is therefore second-order accurate.\n\nTo discretize the three-dimensional Laplacian, we apply this formula to each second partial derivative. Let $f_{i,j,k} = f(x_i, y_j, z_k)$.\n$$ \\left.\\frac{\\partial^2 f}{\\partial x^2}\\right|_{i,j,k} \\approx \\frac{f_{i+1,j,k} - 2f_{i,j,k} + f_{i-1,j,k}}{h_x^2} $$\n$$ \\left.\\frac{\\partial^2 f}{\\partial y^2}\\right|_{i,j,k} \\approx \\frac{f_{i,j+1,k} - 2f_{i,j,k} + f_{i,j-1,k}}{h_y^2} $$\n$$ \\left.\\frac{\\partial^2 f}{\\partial z^2}\\right|_{i,j,k} \\approx \\frac{f_{i,j,k+1} - 2f_{i,j,k} + f_{i,j,k-1}}{h_z^2} $$\nThe discrete Laplacian, denoted $\\mathcal{L}_h f$, at grid point $(i,j,k)$ is the sum of these approximations:\n$$ (\\mathcal{L}_h f)_{i,j,k} = \\frac{f_{i+1,j,k} - 2f_{i,j,k} + f_{i-1,j,k}}{h_x^2} + \\frac{f_{i,j+1,k} - 2f_{i,j,k} + f_{i,j-1,k}}{h_y^2} + \\frac{f_{i,j,k+1} - 2f_{i,j,k} + f_{i,j,k-1}}{h_z^2} $$\nThis formula is known as the seven-point stencil because it involves the value at a central point and its six nearest neighbors along the coordinate axes. The total truncation error is of order $O(h_x^2, h_y^2, h_z^2)$, confirming the scheme is second-order accurate.\n\n### 2. Analytical Laplacian of the Test Function\n\nTo assess the accuracy of our discrete operator, we require a test function for which the exact Laplacian is known. The problem specifies the function $f(x,y,z) = \\sin x \\, \\cos y \\, e^z$. We compute its second partial derivatives analytically:\n$$ \\frac{\\partial f}{\\partial x} = \\cos x \\, \\cos y \\, e^z \\quad \\implies \\quad \\frac{\\partial^2 f}{\\partial x^2} = -\\sin x \\, \\cos y \\, e^z = -f(x,y,z) $$\n$$ \\frac{\\partial f}{\\partial y} = -\\sin x \\, \\sin y \\, e^z \\quad \\implies \\quad \\frac{\\partial^2 f}{\\partial y^2} = -\\sin x \\, \\cos y \\, e^z = -f(x,y,z) $$\n$$ \\frac{\\partial f}{\\partial z} = \\sin x \\, \\cos y \\, e^z \\quad \\implies \\quad \\frac{\\partial^2 f}{\\partial z^2} = \\sin x \\, \\cos y \\, e^z = f(x,y,z) $$\nSumming these provides the exact analytical Laplacian:\n$$ (\\nabla^2 f)_{\\text{exact}} = (-f) + (-f) + (f) = -f(x,y,z) = -\\sin x \\, \\cos y \\, e^z $$\nThis analytical result serves as the ground truth for measuring the error of our numerical approximation.\n\n### 3. Error Measurement and Convergence Order\n\nThe quality of the approximation is quantified by the discrete $L^2$ error norm, calculated over the set of interior grid points $\\mathcal{I}$. The error is defined as:\n$$ E_{2}(h_{x},h_{y},h_{z}) = \\left( \\sum_{(i,j,k)\\in \\mathcal{I}} \\left[ (\\mathcal{L}_{h} f)_{i,j,k} - (\\nabla^{2}f)_{\\text{exact},i,j,k} \\right]^{2} \\, h_{x} h_{y} h_{z} \\right)^{1/2} $$\nFor a second-order accurate scheme, the error $E_2$ is expected to scale with the square of the grid spacing. That is, $E_2(h) \\approx C h^2$ for some constant $C$ and a characteristic grid spacing $h$. If we refine the grid by halving the spacings ($h' = h/2$), the new error should be $E_2(h') \\approx C (h/2)^2 = E_2(h)/4$. The ratio of errors would therefore be $E_2(h)/E_2(h') \\approx 4$.\n\nThe observed order of convergence, $p$, is calculated from this ratio:\n$$ p = \\log_{2} \\left( \\frac{E_{2}(h)}{E_{2}(h')} \\right) $$\nFor a second-order scheme, we expect $p \\approx \\log_2(4) = 2$. The numerical experiment will compute $p$ for several grid configurations to verify this theoretical prediction.\n\n### 4. Implementation Design\n\nThe implementation will follow a systematic procedure for each test case. A single computational routine will be tasked with calculating the $L^2$ error for a given domain, grid size, and test function.\n1.  **Grid Generation**: For a domain of size $[0,L_x] \\times [0,L_y] \\times [0,L_z]$ and grid point counts $(N_x, N_y, N_z)$, the grid spacings are $h_x = L_x/(N_x-1)$, $h_y = L_y/(N_y-1)$, and $h_z = L_z/(N_z-1)$. Three-dimensional coordinate arrays `X`, `Y`, `Z` are generated using `numpy.meshgrid` with `indexing='ij'` to align with the $(i,j,k)$ index convention.\n2.  **Function Evaluation**: The analytical test function $f(x,y,z)$ and its exact Laplacian $(\\nabla^2 f)_{\\text{exact}} = -f(x,y,z)$ are evaluated at every point on the grid, yielding arrays `F` and `Lap_F_exact`. Populating the `F` array with exact values implicitly enforces the required Dirichlet boundary conditions.\n3.  **Discrete Laplacian Calculation**: The seven-point stencil is applied to the interior points of the `F` array. This is performed efficiently using vectorized `numpy` array slicing. For example, the term $(f_{i+1,j,k} - 2f_{i,j,k} + f_{i-1,j,k})/h_x^2$ is computed for all interior points simultaneously. The sum of the three directional derivative approximations gives the discrete Laplacian array `Lap_F_discrete`.\n4.  **Error Calculation**: The $L^2$ error norm is computed by taking the element-wise difference between `Lap_F_discrete` and the corresponding interior points of `Lap_F_exact`, squaring the result, summing over all interior points, multiplying by the volume element $h_x h_y h_z$, and taking the square root.\n\nThis entire process is executed first for the base grid $(N_x, N_y, N_z)$ to find $E_2(h)$, and then again for the refined grid $(N'_x, N'_y, N'_z)$ to find $E_2(h')$. Finally, the observed order of convergence $p$ is calculated from these two error values. This procedure is repeated for each of the specified test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and verifies a second-order accurate finite-difference \n    discretization of the 3D Laplacian, measuring convergence order.\n    \"\"\"\n    \n    test_cases = [\n        # Test case A: Happy path, cubic-ish grid\n        {\n            \"name\": \"A\",\n            \"L_xyz\": (np.pi, np.pi / 2.0, 1.0),\n            \"N_base\": (17, 17, 17)\n        },\n        # Test case B: Anisotropic spacings and non-cubic counts\n        {\n            \"name\": \"B\",\n            \"L_xyz\": (np.pi, np.pi, 0.5),\n            \"N_base\": (18, 14, 10)\n        },\n        # Test case C: Moderate, strongly anisotropic domain extents\n        {\n            \"name\": \"C\",\n            \"L_xyz\": (2.0, 1.0, 0.25),\n            \"N_base\": (5, 7, 9)\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        L_xyz = case[\"L_xyz\"]\n        N_base = case[\"N_base\"]\n\n        def compute_l2_error(domain_lengths, grid_points):\n            \"\"\"\n            Computes the discrete L2 error of the 7-point Laplacian stencil.\n\n            Args:\n                domain_lengths (tuple): (Lx, Ly, Lz) of the domain.\n                grid_points (tuple): (Nx, Ny, Nz) number of points in each dimension.\n\n            Returns:\n                float: The computed L2 error norm.\n            \"\"\"\n            Lx, Ly, Lz = domain_lengths\n            Nx, Ny, Nz = grid_points\n\n            # Ensure grid points allow for interior points\n            if any(n < 3 for n in grid_points):\n                raise ValueError(\"Grid must have at least 3 points in each dimension for an interior.\")\n\n            # Calculate grid spacings\n            hx = Lx / (Nx - 1)\n            hy = Ly / (Ny - 1)\n            hz = Lz / (Nz - 1)\n            \n            # Create grid coordinates\n            x_vec = np.linspace(0.0, Lx, Nx)\n            y_vec = np.linspace(0.0, Ly, Ny)\n            z_vec = np.linspace(0.0, Lz, Nz)\n            X, Y, Z = np.meshgrid(x_vec, y_vec, z_vec, indexing='ij')\n\n            # Evaluate the test function and its exact Laplacian on the grid\n            # f(x,y,z) = sin(x) * cos(y) * exp(z)\n            # ∇²f = -f(x,y,z)\n            F = np.sin(X) * np.cos(Y) * np.exp(Z)\n            lap_F_exact = -F\n\n            # Apply the 7-point stencil to compute the discrete Laplacian on interior points\n            # F[i, j, k] corresponds to (x_i, y_j, z_k)\n            F_ijk  = F[1:-1, 1:-1, 1:-1]\n            \n            term_x = (F[2:, 1:-1, 1:-1] - 2 * F_ijk + F[:-2, 1:-1, 1:-1]) / hx**2\n            term_y = (F[1:-1, 2:, 1:-1] - 2 * F_ijk + F[1:-1, :-2, 1:-1]) / hy**2\n            term_z = (F[1:-1, 1:-1, 2:] - 2 * F_ijk + F[1:-1, 1:-1, :-2]) / hz**2\n            \n            lap_F_discrete = term_x + term_y + term_z\n\n            # Isolate the exact Laplacian on the same interior grid\n            lap_F_exact_interior = lap_F_exact[1:-1, 1:-1, 1:-1]\n\n            # Calculate the L2 error norm on the interior\n            diff_sq = (lap_F_discrete - lap_F_exact_interior)**2\n            volume_element = hx * hy * hz\n            error_norm = np.sqrt(np.sum(diff_sq) * volume_element)\n            \n            return error_norm\n\n        # Compute error for the base grid\n        E_base = compute_l2_error(L_xyz, N_base)\n\n        # Define and compute error for the refined grid\n        Nx, Ny, Nz = N_base\n        N_refined = (2 * (Nx - 1) + 1, 2 * (Ny - 1) + 1, 2 * (Nz - 1) + 1)\n        E_refined = compute_l2_error(L_xyz, N_refined)\n        \n        # Calculate the observed order of convergence\n        p = np.log2(E_base / E_refined)\n        results.append(p)\n\n    # Format the final output string\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}