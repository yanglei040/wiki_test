{
    "hands_on_practices": [
        {
            "introduction": "The HAL QCD method provides a powerful way to determine a local potential $V(r)$ from a two-particle wavefunction calculated on the lattice. A central step in this method is rearranging the Schrödinger equation to solve for the potential, which requires computing the Laplacian of the wavefunction. This hands-on exercise  lets you explore how the choice of a discrete numerical approximation for the Laplacian operator—a fundamental source of systematic error—affects the extracted potential, particularly at short distances where the interaction is strongest.",
            "id": "3558798",
            "problem": "Design and implement a complete program that quantifies discretization effects in extracting local nuclear potentials within the Hadrons-to-Atomic-nuclei from Lattice Quantum Chromodynamics (HAL QCD) method. Use the following foundational base: the equal-time two-body Schrödinger equation for the relative coordinate wavefunction under a local, central potential, expressed in physical units with explicit Planck constant and speed of light factors to ensure unit consistency. The base is\n$$\n-\\frac{\\hbar^2}{2\\mu}\\nabla^2 \\psi(\\mathbf{r}) + V(r)\\,\\psi(\\mathbf{r}) = E\\,\\psi(\\mathbf{r}),\n$$\nwhere $r = \\lVert \\mathbf{r} \\rVert$, $\\psi(\\mathbf{r})$ is the equal-time Nambu–Bethe–Salpeter (NBS) wavefunction, $V(r)$ is the local potential to be extracted, $\\mu$ is the reduced mass, and $E$ is the energy of the elastic two-body state. You will compare two discrete approximations to the Laplacian operator on a cubic lattice of spacing $a$: the standard $7$-point stencil and an improved $27$-point isotropic stencil.\n\nYour program must:\n\n1. Construct a three-dimensional cubic lattice of side length $2R_{\\max}$ with lattice spacing $a$ (in $\\mathrm{fm}$), centered at the origin, so the grid points are at coordinates $(x_i,y_j,z_k)$ with $x_i,y_j,z_k \\in [-R_{\\max},R_{\\max}]$ and uniform spacing $a$ along each axis. Only use points for which all required neighbors exist for the stencils you implement.\n\n2. Define a spherically symmetric mock equal-time Nambu–Bethe–Salpeter wavefunction (NBS) consistent with a smooth short-range behavior,\n$$\n\\psi(r) = \\exp\\!\\big(-\\alpha\\, r^2\\big),\n$$\nwith $\\alpha$ given in $\\mathrm{fm}^{-2}$. This choice avoids nodes and ensures the ratio $\\nabla^2 \\psi(\\mathbf{r})/\\psi(\\mathbf{r})$ is well-defined throughout the region of interest.\n\n3. Discretize the Laplacian $\\nabla^2 \\psi$ at lattice sites using:\n   - The $7$-point stencil in three dimensions:\n     $$\n     \\nabla^2_{7}\\psi(i,j,k) = \\frac{1}{a^2}\\Big(\\psi_{i+1,j,k}+\\psi_{i-1,j,k}+\\psi_{i,j+1,k}+\\psi_{i,j-1,k}+\\psi_{i,j,k+1}+\\psi_{i,j,k-1}-6\\psi_{i,j,k}\\Big).\n     $$\n   - The improved isotropic $27$-point stencil (sometimes referred to as the Brillouin-type Laplacian), which combines face, edge, and corner neighbors with weights chosen to minimize rotational anisotropy while maintaining second-order consistency:\n     $$\n     \\nabla^2_{27}\\psi(i,j,k) = \\frac{1}{a^2}\\Big(w_0\\,\\psi_{i,j,k} + w_1 \\sum_{\\text{faces}} \\psi + w_2 \\sum_{\\text{edges}} \\psi + w_3 \\sum_{\\text{corners}} \\psi \\Big),\n     $$\n     where the neighbor sets are:\n     - Faces: offsets $(\\pm1,0,0)$, $(0,\\pm1,0)$, $(0,0,\\pm1)$, six in total,\n     - Edges: offsets $(\\pm1,\\pm1,0)$, $(\\pm1,0,\\pm1)$, $(0,\\pm1,\\pm1)$, twelve in total,\n     - Corners: offsets $(\\pm1,\\pm1,\\pm1)$, eight in total,\n     and the weights are\n     $$\n     w_0 = -\\frac{64}{15},\\quad w_1 = \\frac{7}{15},\\quad w_2 = \\frac{1}{10},\\quad w_3 = \\frac{1}{30}.\n     $$\n     This stencil is normalized so that $\\nabla^2_{27}$ annihilates constant fields and provides improved rotational invariance over the standard $7$-point stencil.\n\n4. Using the Schrödinger equation above as the principle-based definition of the HAL QCD local potential, compute the local potentials $V_{7}(r)$ and $V_{27}(r)$ extracted with each Laplacian stencil via the ratio $\\nabla^2 \\psi(\\mathbf{r})/\\psi(\\mathbf{r})$ at lattice sites. Ensure unit consistency by using $(\\hbar c)^2$ with $\\hbar c = 197.3269804\\,\\mathrm{MeV}\\cdot\\mathrm{fm}$, reduced mass $\\mu$ in $\\mathrm{MeV}$, energy $E$ in $\\mathrm{MeV}$, and lengths in $\\mathrm{fm}$. The potential must be expressed in $\\mathrm{MeV}$.\n\n5. Evaluate the change in the extracted potential at short distances by computing the maximum absolute difference\n$$\n\\Delta V_{\\max} = \\max_{r \\le 0.5\\,\\mathrm{fm}} \\big|V_{27}(r)-V_{7}(r)\\big|\n$$\nover all lattice points satisfying $r \\le 0.5\\,\\mathrm{fm}$ and for which all necessary neighbor points exist. Report $\\Delta V_{\\max}$ in $\\mathrm{MeV}$ for each test case.\n\n6. Produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[x_1,x_2,x_3]$), with each $x_n$ corresponding to the $\\Delta V_{\\max}$ in $\\mathrm{MeV}$ for the respective test case.\n\nPhysical units: express all distances in $\\mathrm{fm}$, energies in $\\mathrm{MeV}$, and angles are not used. The output values must be floats in $\\mathrm{MeV}$.\n\nImplement the program for the following test suite, each tuple providing $(a,\\mu,E,\\alpha,R_{\\max})$ in units $(\\mathrm{fm},\\mathrm{MeV},\\mathrm{MeV},\\mathrm{fm}^{-2},\\mathrm{fm})$:\n\n- Test case $1$: $(0.08, 469.5, 10.0, 2.0, 3.20)$, a fine lattice representative of nucleon reduced mass and modest binding energy.\n- Test case $2$: $(0.20, 469.5, 10.0, 2.0, 4.00)$, a coarse lattice probing strong discretization at short distances.\n- Test case $3$: $(0.08, 469.5, 10.0, 8.0, 3.20)$, a sharply varying wavefunction to amplify sensitivity to stencil choice.\n- Test case $4$: $(0.12, 469.5, 0.0, 2.0, 3.60)$, zero energy to isolate the Laplacian-driven contribution to the potential.\n\nYour program should produce a single line of output containing the four $\\Delta V_{\\max}$ values for these test cases as a comma-separated list enclosed in square brackets, in $\\mathrm{MeV}$.",
            "solution": "The problem has been validated and is deemed sound. It is scientifically grounded in the principles of quantum mechanics and numerical analysis, well-posed with a unique and computable solution, and objective in its formulation. All necessary parameters and definitions are provided. We may therefore proceed with the solution.\n\nThe central task is to quantify the discrepancy between two different numerical approximations of the Laplacian operator, $\\nabla^2$, when used to extract a local potential from a mock wavefunction within the context of the HAL QCD method. The choice of the discrete Laplacian operator introduces a systematic error, known as a discretization error, which depends on the lattice spacing $a$ and the properties of the underlying wavefunction. This exercise compares the standard $7$-point stencil with an improved $27$-point stencil to assess the magnitude of this error at short distances.\n\nThe foundation of the method is the time-independent Schrödinger equation for the relative coordinate wavefunction $\\psi(\\mathbf{r})$ of a two-body system:\n$$\n-\\frac{\\hbar^2}{2\\mu}\\nabla^2 \\psi(\\mathbf{r}) + V(r)\\,\\psi(\\mathbf{r}) = E\\,\\psi(\\mathbf{r})\n$$\nHere, $\\mu$ is the reduced mass, $E$ is the system's energy, and $V(r)$ is the local central potential we wish to determine, with $r = \\lVert \\mathbf{r} \\rVert$. In the HAL QCD method, $\\psi(\\mathbf{r})$ corresponds to the equal-time Nambu–Bethe–Salpeter (NBS) wavefunction, which is computed from lattice QCD simulations. By rearranging the Schrödinger equation, we can express the potential $V(r)$ as:\n$$\nV(r) = E - \\frac{\\hbar^2}{2\\mu} \\frac{\\nabla^2 \\psi(\\mathbf{r})}{\\psi(\\mathbf{r})}\n$$\nTo make the units explicit and ready for computation, we use the value of $\\hbar c$ in units of $\\mathrm{MeV}\\cdot\\mathrm{fm}$. The potential is then given by:\n$$\nV(r) = E + \\frac{(\\hbar c)^2}{2\\mu} \\frac{\\nabla^2 \\psi(\\mathbf{r})}{\\psi(\\mathbf{r})}\n$$\nwhere $E$ and $\\mu$ are in units of $\\mathrm{MeV}$, and lengths are in $\\mathrm{fm}$.\n\nFor this analysis, a mock NBS wavefunction is provided:\n$$\n\\psi(r) = \\exp(-\\alpha r^2)\n$$\nThis Gaussian form is analytically tractable and well-behaved, lacking nodes that would cause the ratio $\\nabla^2\\psi/\\psi$ to diverge. The analytical Laplacian of this function is $\\nabla^2\\psi(r) = (4\\alpha^2 r^2 - 6\\alpha) \\exp(-\\alpha r^2)$. Thus, the exact continuum potential corresponding to this wavefunction is $V_{\\text{true}}(r) = E + \\frac{(\\hbar c)^2}{2\\mu}(4\\alpha^2 r^2 - 6\\alpha)$, which is a simple quadratic function of $r^2$.\n\nThe core of the problem lies in replacing the continuum operator $\\nabla^2$ with a discrete approximation on a three-dimensional cubic lattice with spacing $a$. We will implement and compare two such approximations.\n\n1.  **The $7$-point stencil**: This is the standard second-order central difference approximation to the Laplacian in three dimensions. At a lattice site indexed by $(i,j,k)$, it is defined as:\n    $$\n    \\nabla^2_{7}\\psi(i,j,k) = \\frac{1}{a^2}\\Big(\\psi_{i+1,j,k}+\\psi_{i-1,j,k}+\\psi_{i,j+1,k}+\\psi_{i,j-1,k}+\\psi_{i,j,k+1}+\\psi_{i,j,k-1}-6\\psi_{i,j,k}\\Big)\n    $$\n    This stencil uses the nearest neighbors along the Cartesian axes.\n\n2.  **The improved $27$-point stencil**: This stencil incorporates neighbors on the faces, edges, and corners of the cube surrounding the central point $(i,j,k)$ to construct an approximation with better rotational symmetry. Its definition is:\n    $$\n    \\nabla^2_{27}\\psi(i,j,k) = \\frac{1}{a^2}\\Big(w_0\\,\\psi_{i,j,k} + w_1 \\sum_{\\text{faces}} \\psi + w_2 \\sum_{\\text{edges}} \\psi + w_3 \\sum_{\\text{corners}} \\psi \\Big)\n    $$\n    with weights $w_0 = -64/15$, $w_1 = 7/15$, $w_2 = 1/10$, and $w_3 = 1/30$. The sums are over $6$ face, $12$ edge, and $8$ corner neighbors, respectively. The weights are chosen to cancel leading-order rotational anisotropy terms in the stencil's Taylor expansion.\n\nThe algorithmic procedure to solve the problem for each test case is as follows:\n\n-   **Step 1: Lattice Construction**. A 3D lattice is defined spanning the cube $[-R_{\\max}, R_{\\max}]^3$ with a uniform spacing $a$. This is implemented by creating 1D coordinate arrays and using a meshgrid function to generate 3D coordinate arrays $X, Y, Z$.\n\n-   **Step 2: Wavefunction Evaluation**. The mock wavefunction $\\psi(r) = \\exp(-\\alpha r^2)$ is evaluated at every point on the lattice, where $r = \\sqrt{X^2+Y^2+Z^2}$.\n\n-   **Step 3: Laplacian Calculation**. The discrete Laplacians, $\\nabla^2_{7}\\psi$ and $\\nabla^2_{27}\\psi$, are computed. This calculation is restricted to the interior points of the lattice, for which all required neighbors (up to corner neighbors for the $27$-point stencil) exist within the defined grid. This is efficiently achieved using array slicing in `numpy`.\n\n-   **Step 4: Potential Extraction**. Using the results from Step 3, the two versions of the potential, $V_7(r)$ and $V_{27}(r)$, are calculated at each interior lattice point using the formula $V_i(r) = E + \\frac{(\\hbar c)^2}{2\\mu} (\\nabla^2_i \\psi / \\psi)$.\n\n-   **Step 5: Discrepancy Quantification**. The absolute difference $|V_{27}(r) - V_{7}(r)|$ is calculated. A boolean mask is created to select only the points that both lie within the interior calculation volume and satisfy the distance constraint $r \\le 0.5\\,\\mathrm{fm}$. The final result for the test case, $\\Delta V_{\\max}$, is the maximum value of this difference over the selected points.\n\nThis process is repeated for each of the four test cases provided, and the resulting $\\Delta V_{\\max}$ values are collected.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n    \n    # Test cases: (a, mu, E, alpha, R_max)\n    # Units: (fm, MeV, MeV, fm^-2, fm)\n    test_cases = [\n        (0.08, 469.5, 10.0, 2.0, 3.20),\n        (0.20, 469.5, 10.0, 2.0, 4.00),\n        (0.08, 469.5, 10.0, 8.0, 3.20),\n        (0.12, 469.5, 0.0, 2.0, 3.60),\n    ]\n\n    results = []\n    for case in test_cases:\n        delta_v_max = calculate_delta_v_max(*case)\n        results.append(delta_v_max)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\ndef calculate_delta_v_max(a: float, mu: float, E: float, alpha: float, R_max: float) -> float:\n    \"\"\"\n    Calculates the maximum absolute difference between potentials extracted\n    using 7-point and 27-point Laplacian stencils.\n\n    Args:\n        a (float): Lattice spacing in fm.\n        mu (float): Reduced mass in MeV.\n        E (float): Energy in MeV.\n        alpha (float): Wavefunction parameter in fm^-2.\n        R_max (float): Half-side length of the cubic lattice in fm.\n\n    Returns:\n        float: The maximum absolute potential difference Delta V_max in MeV.\n    \"\"\"\n    # Physical and conversion constants\n    hbar_c = 197.3269804  # MeV*fm\n    v_factor = hbar_c**2 / (2 * mu)\n    r_cutoff_sq = 0.5**2 # fm^2\n\n    # 1. Construct the lattice\n    # Determine the number of points from the origin to the edge\n    N_half = int(np.round(R_max / a))\n    # Create a 1D coordinate array centered at the origin\n    coords_1d = np.linspace(-N_half * a, N_half * a, 2 * N_half + 1)\n    # Generate 3D coordinate grids\n    X, Y, Z = np.meshgrid(coords_1d, coords_1d, coords_1d, indexing='ij')\n\n    # 2. Evaluate the mock wavefunction\n    R_sq = X**2 + Y**2 + Z**2\n    psi = np.exp(-alpha * R_sq)\n\n    # 3. Calculate discrete Laplacians on the interior of the grid\n    # The stencils require a 1-point border, so we compute on `psi[1:-1, 1:-1, 1:-1]`.\n    # Slicing the `psi` array allows efficient access to neighbor points.\n    \n    # The core region of psi where the Laplacians will be evaluated\n    interior_psi = psi[1:-1, 1:-1, 1:-1]\n\n    # 7-point stencil calculation\n    # Sum over the 6 face neighbors relative to the interior grid\n    sum_faces = (psi[2:, 1:-1, 1:-1] + psi[:-2, 1:-1, 1:-1] +\n                 psi[1:-1, 2:, 1:-1] + psi[1:-1, :-2, 1:-1] +\n                 psi[1:-1, 1:-1, 2:] + psi[1:-1, 1:-1, :-2])\n    \n    lap_7 = (sum_faces - 6 * interior_psi) / a**2\n\n    # 27-point stencil calculation\n    w0, w1, w2, w3 = -64/15., 7/15., 1/10., 1/30.\n    \n    # Term 0: Central point\n    term0 = w0 * interior_psi\n\n    # Term 1: Face neighbors (same sum as for the 7-point stencil)\n    term1 = w1 * sum_faces\n    \n    # Term 2: Edge neighbors (12 points)\n    sum_edges = (psi[:-2, :-2, 1:-1] + psi[:-2, 2:, 1:-1] +  # xy plane\n                 psi[2:, :-2, 1:-1] + psi[2:, 2:, 1:-1] +\n                 psi[:-2, 1:-1, :-2] + psi[:-2, 1:-1, 2:] +  # xz plane\n                 psi[2:, 1:-1, :-2] + psi[2:, 1:-1, 2:] +\n                 psi[1:-1, :-2, :-2] + psi[1:-1, :-2, 2:] +  # yz plane\n                 psi[1:-1, 2:, :-2] + psi[1:-1, 2:, 2:])\n    term2 = w2 * sum_edges\n    \n    # Term 3: Corner neighbors (8 points)\n    sum_corners = (psi[:-2, :-2, :-2] + psi[:-2, :-2, 2:] +\n                   psi[:-2, 2:, :-2] + psi[:-2, 2:, 2:] +\n                   psi[2:, :-2, :-2] + psi[2:, :-2, 2:] +\n                   psi[2:, 2:, :-2] + psi[2:, 2:, 2:])\n    term3 = w3 * sum_corners\n\n    lap_27 = (term0 + term1 + term2 + term3) / a**2\n    \n    # 4. Compute potentials V7 and V27\n    # The division by `interior_psi` is safe as the Gaussian is never zero.\n    V7 = E + v_factor * (lap_7 / interior_psi)\n    V27 = E + v_factor * (lap_27 / interior_psi)\n\n    # 5. Compute the absolute difference\n    delta_V = np.abs(V27 - V7)\n\n    # 6. Apply mask for r = 0.5 fm and find the maximum difference\n    # We must use the coordinates corresponding to the interior grid\n    interior_R_sq = R_sq[1:-1, 1:-1, 1:-1]\n    mask = interior_R_sq = r_cutoff_sq\n\n    # Ensure there are points within the cutoff radius before taking a max\n    if not np.any(mask):\n        return 0.0\n\n    delta_V_max = np.max(delta_V[mask])\n    \n    return delta_V_max\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "After extracting a potential, a crucial validation step is to check if it reproduces known physical phenomena. At large separations, the nucleon-nucleon interaction is famously dominated by the exchange of a single pion, giving rise to the classic Yukawa potential. In this practice , you will fit the long-range tail of a numerically-derived potential to the Yukawa form and perform statistical tests to verify its consistency with the predictions of one-pion exchange theory.",
            "id": "3558776",
            "problem": "You are given the task of testing whether the long-range central nucleon-nucleon potential extracted from Lattice Quantum Chromodynamics (LQCD) is consistent with single-pion exchange at large separation. At sufficiently large separation, the spectral representation of two-nucleon exchange dominated by the lightest isovector excitation implies a Yukawa decay. In a nonrelativistic static reduction of the Bethe-Salpeter amplitude to a local central potential, the long-range tail is modeled as a Yukawa form\n$$\nV_{\\mathrm{model}}(r) \\equiv -\\frac{A}{r}\\,e^{-\\mu\\, r},\n$$\nwhere $r$ is the separation in $\\mathrm{fm}$, $A$ is an amplitude with units of $\\mathrm{MeV}\\cdot\\mathrm{fm}$, and $\\mu$ is the range parameter in $\\mathrm{fm}^{-1}$ related to the pion mass $m_\\pi$ by\n$$\n\\mu_{\\mathrm{pred}} = \\frac{m_\\pi}{\\hbar c},\n$$\nwith $\\hbar c = 197.3269804\\,\\mathrm{MeV}\\cdot\\mathrm{fm}$. In the one-pion exchange picture, the amplitude scales as $A \\propto g_A^2$ with the nucleon axial coupling $g_A$ when other low-energy constants are held fixed. You will test two independent consistency conditions:\n- $m_\\pi$-consistency: whether the fitted $\\mu$ is statistically consistent with the independently supplied $m_\\pi$ via $\\mu_{\\mathrm{pred}}$.\n- $g_A$-consistency: whether the fitted amplitudes $A$ across multiple ensembles are consistent with a common proportionality to $g_A^2$ (i.e., whether $A_i/g_{A,i}^2$ is consistent with being constant across $i$).\n\nYour program must generate synthetic Lattice Quantum Chromodynamics-like data (central potential values) for $r \\ge 1.2\\,\\mathrm{fm}$ and perform a weighted nonlinear least-squares fit of $V_{\\mathrm{model}}(r)$ to those data. The data generation must follow the underlying Yukawa model with Gaussian noise added. All calculations must be performed in the stated physical units. Angles are not present in this problem. The final output must be a single line with boolean results as specified below.\n\nUse the following fundamental bases:\n- The spectral representation of two-body exchange at long distance is dominated by the lightest mass, which implies an exponential decay $\\propto e^{-m\\, r}$ in coordinate space.\n- The reduction to a static central potential for large $r$ leads to a Yukawa tail $\\propto e^{-\\mu r}/r$ with $\\mu$ set by the mass of the exchanged particle, here $m_\\pi$.\n- In the single-meson exchange picture with fixed couplings except $g_A$, the amplitude scales as $A \\propto g_A^2$.\n\nData generation details:\n- For each test case $i$, draw $N_i$ radii $r_{i,k}$ uniformly spaced in a specified interval with spacing $\\Delta r_i$, restricted to $r_{i,k} \\ge 1.2\\,\\mathrm{fm}$, compute\n$$\nV^{\\mathrm{true}}_{i}(r) = -\\frac{A^{\\mathrm{true}}_i}{r}\\,e^{-\\mu^{\\mathrm{true}}_i r}, \\quad \\mu^{\\mathrm{true}}_i = \\frac{m_{\\pi,i}}{\\hbar c}, \\quad A^{\\mathrm{true}}_i = K \\, g_{A,i}^2,\n$$\nadd independent Gaussian noise $\\epsilon_{i,k} \\sim \\mathcal{N}(0,\\sigma_i^2)$ to obtain observations\n$$\nV^{\\mathrm{obs}}_{i,k} = V^{\\mathrm{true}}_{i}(r_{i,k}) + \\epsilon_{i,k},\n$$\nand assign observational uncertainties $\\sigma_{i,k}=\\sigma_i$.\n- Use a fixed constant $K$ (with units $\\mathrm{MeV}\\cdot\\mathrm{fm}$) common to all test cases, and a fixed random seed so that the data are reproducible.\n\nFitting and statistical tests:\n- For each case, perform a weighted nonlinear least-squares fit of $V_{\\mathrm{model}}(r)$ to $\\{(r_{i,k}, V^{\\mathrm{obs}}_{i,k}, \\sigma_{i,k})\\}_{k}$, with parameters $(A_i,\\mu_i)$ constrained to be positive. Extract parameter uncertainties from the covariance matrix.\n- Define a $z$-score for $m_\\pi$-consistency as\n$$\nz_i = \\frac{|\\mu_i - \\mu_{\\mathrm{pred},i}|}{\\sigma_{\\mu,i}},\n$$\nand declare $m_\\pi$-consistency to hold if $z_i \\le z_{\\mathrm{thr}}$ with threshold $z_{\\mathrm{thr}} = 3.0$.\n- For $g_A$-consistency across all cases, form $K_i \\equiv A_i/g_{A,i}^2$ with uncertainty $\\sigma_{K,i} \\equiv \\sigma_{A,i}/g_{A,i}^2$, compute the inverse-variance weighted mean\n$$\n\\bar{K} = \\frac{\\sum_i K_i/\\sigma_{K,i}^2}{\\sum_i 1/\\sigma_{K,i}^2},\n$$\nthe chi-square\n$$\n\\chi^2 = \\sum_i \\frac{(K_i - \\bar{K})^2}{\\sigma_{K,i}^2},\n$$\nand the survival probability $p = \\Pr(\\chi^2_{\\nu} \\ge \\chi^2)$ with $\\nu = N-1$ degrees of freedom for $N$ cases. Declare $g_A$-consistency to hold if $p  0.05$.\n\nTest suite:\n- Use $\\hbar c = 197.3269804\\,\\mathrm{MeV}\\cdot\\mathrm{fm}$.\n- Use a fixed seed $s = 123456789$ for the pseudorandom number generator.\n- Use a common proportionality constant $K = 30.0\\,\\mathrm{MeV}\\cdot\\mathrm{fm}$.\n- Provide three test cases, each specified by $(m_\\pi\\ \\mathrm{[MeV]}, g_A, r_{\\min}\\ \\mathrm{[fm]}, r_{\\max}\\ \\mathrm{[fm]}, \\Delta r\\ \\mathrm{[fm]}, \\sigma\\ \\mathrm{[MeV]})$:\n    1. Case A: $(140.0, 1.27, 1.2, 3.0, 0.1, 0.8)$.\n    2. Case B: $(200.0, 1.10, 1.2, 2.4, 0.1, 1.0)$.\n    3. Case C: $(300.0, 1.35, 1.2, 1.6, 0.05, 1.5)$.\n\nRequired outputs:\n- For each case $i \\in \\{A,B,C\\}$, output a boolean indicating $m_\\pi$-consistency using the stated $z$-test with $z_{\\mathrm{thr}}=3.0$.\n- After processing all cases, output a final boolean indicating whether $g_A$-consistency holds using the chi-square test at significance level $0.05$.\n- Your program should produce a single line of output containing these four booleans in order $[A\\text{-}m_\\pi\\text{-}\\mathrm{consistency},B\\text{-}m_\\pi\\text{-}\\mathrm{consistency},C\\text{-}m_\\pi\\text{-}\\mathrm{consistency},g_A\\text{-}\\mathrm{consistency}]$ as a comma-separated list enclosed in square brackets, for example, $[{\\tt True},{\\tt True},{\\tt True},{\\tt True}]$.\n\nAll numerical constants, inputs, and outputs must be in the units explicitly specified above. The output is unitless booleans. The program must be fully self-contained, use the specified seed, and not perform any input or output beyond printing the required single line.",
            "solution": "The objective is to validate that synthetically generated nucleon-nucleon potential data, designed to mimic results from Lattice Quantum Chromodynamics (LQCD), are consistent with the long-range behavior predicted by one-pion exchange theory. This validation involves two distinct statistical tests: one for the pion mass dependence ($m_\\pi$-consistency) for each dataset, and another for the dependence on the nucleon axial coupling ($g_A$-consistency) across all datasets. The procedure involves data generation, nonlinear fitting, and statistical hypothesis testing.\n\nFirst, we establish the theoretical framework. The one-pion exchange potential at large nucleon separation $r$ is described by a Yukawa potential:\n$$\nV_{\\mathrm{model}}(r) = -\\frac{A}{r}\\,e^{-\\mu\\, r}\n$$\nHere, $A$ is the amplitude in units of $\\mathrm{MeV}\\cdot\\mathrm{fm}$ and $\\mu$ is the range parameter in $\\mathrm{fm}^{-1}$. The range parameter is directly related to the mass of the exchanged pion, $m_\\pi$, via the fundamental constant $\\hbar c = 197.3269804\\,\\mathrm{MeV}\\cdot\\mathrm{fm}$:\n$$\n\\mu_{\\mathrm{pred}} = \\frac{m_\\pi}{\\hbar c}\n$$\nThe amplitude $A$ is proportional to the square of the nucleon axial coupling, $g_A^2$. We can write this proportionality as $A = K g_A^2$, where $K$ is a constant of proportionality with units $\\mathrm{MeV}\\cdot\\mathrm{fm}$.\n\nThe process begins with the generation of synthetic data for three distinct scenarios (cases A, B, C), each defined by a specific pion mass $m_{\\pi,i}$, axial coupling $g_{A,i}$, and data sampling parameters. For each case $i$, a set of radial separation points $\\{r_{i,k}\\}$ is generated. The \"true\" potential values $V^{\\mathrm{true}}_{i}(r_{i,k})$ are calculated using the Yukawa model with true parameters $A^{\\mathrm{true}}_i = K g_{A,i}^2$ and $\\mu^{\\mathrm{true}}_i = m_{\\pi,i} / (\\hbar c)$, where the common constant is $K = 30.0\\,\\mathrm{MeV}\\cdot\\mathrm{fm}$. To simulate experimental or numerical noise, independent and identically distributed Gaussian noise, $\\epsilon_{i,k} \\sim \\mathcal{N}(0, \\sigma_i^2)$, is added to the true values to produce the \"observed\" data:\n$$\nV^{\\mathrm{obs}}_{i,k} = V^{\\mathrm{true}}_{i}(r_{i,k}) + \\epsilon_{i,k}\n$$\nThe uncertainty for each data point is given as $\\sigma_{i,k} = \\sigma_i$. All data generation uses a fixed pseudorandom number generator seed for reproducibility.\n\nNext, for each of the three datasets $\\{(r_{i,k}, V^{\\mathrm{obs}}_{i,k}, \\sigma_i)\\}$, we perform a weighted nonlinear least-squares fit to the model $V_{\\mathrm{model}}(r; A, \\mu)$. This procedure finds the optimal parameters $(A_i, \\mu_i)$ that minimize the chi-squared function:\n$$\n\\chi^2_{\\mathrm{fit}}(A_i, \\mu_i) = \\sum_{k} \\left( \\frac{V^{\\mathrm{obs}}_{i,k} - V_{\\mathrm{model}}(r_{i,k}; A_i, \\mu_i)}{\\sigma_i} \\right)^2\n$$\nThe fit is constrained such that $A_i  0$ and $\\mu_i  0$. The fitting procedure, implemented via `scipy.optimize.curve_fit`, also yields the covariance matrix for the fitted parameters. The square roots of the diagonal elements of this matrix provide the standard uncertainties on the fitted parameters, $\\sigma_{A,i}$ and $\\sigma_{\\mu,i}$.\n\nWith the fitted parameters and their uncertainties, we perform the two specified consistency tests.\n\nThe first test is for $m_\\pi$-consistency, which is checked for each case individually. It assesses whether the fitted range parameter $\\mu_i$ is statistically consistent with the value predicted from the input pion mass, $\\mu_{\\mathrm{pred},i} = m_{\\pi,i} / (\\hbar c)$. We quantify this using a $z$-score:\n$$\nz_i = \\frac{|\\mu_i - \\mu_{\\mathrm{pred},i}|}{\\sigma_{\\mu,i}}\n$$\nA case is deemed consistent if its $z$-score is less than or equal to a threshold of $z_{\\mathrm{thr}} = 3.0$, corresponding to a $3$-sigma tolerance.\n\nThe second test is for $g_A$-consistency, which is checked across all $N=3$ cases. This test verifies if the fitted amplitudes $A_i$ are consistent with the theoretical scaling $A_i \\propto g_{A,i}^2$. If this scaling holds, the ratio $K_i = A_i/g_{A,i}^2$ should be a constant across all cases, within statistical uncertainties. To test this hypothesis, we first propagate the uncertainty on $A_i$ to $K_i$, which gives $\\sigma_{K,i} = \\sigma_{A,i}/g_{A,i}^2$. Then, we compute the inverse-variance weighted average of the $K_i$ values:\n$$\n\\bar{K} = \\frac{\\sum_{i=1}^N K_i/\\sigma_{K,i}^2}{\\sum_{i=1}^N 1/\\sigma_{K,i}^2}\n$$\nWe then construct a chi-squared statistic, which measures the deviation of the individual $K_i$ values from the weighted mean $\\bar{K}$:\n$$\n\\chi^2 = \\sum_{i=1}^N \\frac{(K_i - \\bar{K})^2}{\\sigma_{K,i}^2}\n$$\nThis statistic should follow a chi-squared distribution with $\\nu = N-1$ degrees of freedom. For our $N=3$ cases, $\\nu=2$. The consistency is evaluated by calculating the $p$-value, which is the probability of obtaining a $\\chi^2$ value at least as large as the one observed, assuming the hypothesis (that all $K_i$ are samples of the same underlying constant) is true. This is given by the survival function of the $\\chi^2$ distribution, $p = \\Pr(\\chi^2_{\\nu} \\ge \\chi^2)$. The set of results is declared consistent if this $p$-value is greater than the significance level of $0.05$.\n\nThe final output collects the boolean results of these four tests: three for $m_\\pi$-consistency (one for each case) and one for the overall $g_A$-consistency.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Generates synthetic lattice QCD data, fits a Yukawa potential,\n    and performs consistency checks based on one-pion exchange theory.\n    \"\"\"\n    # Define physical constants and problem parameters\n    HBARC = 197.3269804  # MeV*fm\n    SEED = 123456789\n    K_TRUE = 30.0  # MeV*fm\n    Z_THRESHOLD = 3.0\n    P_VALUE_THRESHOLD = 0.05\n\n    # Set the seed for reproducibility\n    np.random.seed(SEED)\n\n    # Test cases: (m_pi [MeV], g_A, r_min [fm], r_max [fm], dr [fm], sigma [MeV])\n    test_cases = [\n        (140.0, 1.27, 1.2, 3.0, 0.1, 0.8),  # Case A\n        (200.0, 1.10, 1.2, 2.4, 0.1, 1.0),  # Case B\n        (300.0, 1.35, 1.2, 1.6, 0.05, 1.5), # Case C\n    ]\n\n    # Model function for the Yukawa potential\n    def yukawa_potential(r, A, mu):\n        return -A / r * np.exp(-mu * r)\n\n    mpi_consistency_results = []\n    fitted_params_for_gA_test = []\n\n    for case_params in test_cases:\n        m_pi, gA, r_min, r_max, dr, sigma_obs_val = case_params\n\n        # --- 1. Data Generation ---\n        # Generate radial separation points\n        # Use np.round to avoid float precision issues with the endpoint\n        num_points = int(np.round((r_max - r_min) / dr)) + 1\n        r_vals = np.linspace(r_min, r_max, num_points)\n        \n        # Calculate true model parameters\n        mu_true = m_pi / HBARC\n        A_true = K_TRUE * gA**2\n        \n        # Generate true potential values\n        V_true = yukawa_potential(r_vals, A_true, mu_true)\n        \n        # Add Gaussian noise to create observed data\n        noise = np.random.normal(loc=0.0, scale=sigma_obs_val, size=r_vals.shape)\n        V_obs = V_true + noise\n        \n        # Assign uncertainties for the fit\n        sigma_obs_arr = np.full_like(r_vals, sigma_obs_val)\n\n        # --- 2. Nonlinear Least-Squares Fit ---\n        # Initial guesses for the parameters\n        p0 = [A_true, mu_true]\n        \n        # Parameter bounds (A > 0, mu > 0)\n        bounds = ([0, 0], [np.inf, np.inf])\n\n        # Perform the weighted nonlinear least-squares fit\n        popt, pcov = curve_fit(\n            yukawa_potential,\n            r_vals,\n            V_obs,\n            p0=p0,\n            sigma=sigma_obs_arr,\n            bounds=bounds,\n            absolute_sigma=True  # Treat sigma as absolute standard deviations\n        )\n        \n        A_fit, mu_fit = popt\n        # Uncertainties are the square root of the diagonal of the covariance matrix\n        sigma_A_fit, sigma_mu_fit = np.sqrt(np.diag(pcov))\n\n        # --- 3. m_pi-Consistency Test ---\n        mu_pred = m_pi / HBARC\n        z_score = np.abs(mu_fit - mu_pred) / sigma_mu_fit\n        \n        is_mpi_consistent = (z_score = Z_THRESHOLD)\n        mpi_consistency_results.append(is_mpi_consistent)\n        \n        # Store results for the gA-consistency test\n        fitted_params_for_gA_test.append({\n            'gA': gA,\n            'A_fit': A_fit,\n            'sigma_A_fit': sigma_A_fit\n        })\n\n    # --- 4. gA-Consistency Test ---\n    N_cases = len(test_cases)\n    K_vals = np.zeros(N_cases)\n    sigma_K_vals = np.zeros(N_cases)\n    \n    for i, params in enumerate(fitted_params_for_gA_test):\n        gA_i = params['gA']\n        A_i = params['A_fit']\n        sigma_A_i = params['sigma_A_fit']\n        \n        K_vals[i] = A_i / gA_i**2\n        sigma_K_vals[i] = sigma_A_i / gA_i**2\n\n    # Calculate inverse-variance weighted mean\n    weights = 1.0 / sigma_K_vals**2\n    K_bar = np.sum(K_vals * weights) / np.sum(weights)\n    \n    # Calculate the chi-square statistic\n    chi2_stat = np.sum(((K_vals - K_bar) / sigma_K_vals)**2)\n    \n    # Degrees of freedom is N-1\n    dof = N_cases - 1\n    \n    # Calculate the p-value (survival function)\n    p_value = chi2.sf(chi2_stat, dof)\n    \n    is_gA_consistent = (p_value > P_VALUE_THRESHOLD)\n\n    # --- 5. Final Output ---\n    final_results = mpi_consistency_results + [is_gA_consistent]\n    \n    # Format the final output as a string\n    output_str = f\"[{','.join(map(str, final_results))}]\"\n    \n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Lattice QCD calculations are simulations performed on a discrete spacetime grid, which means the results are subject to discretization artifacts that vanish only in the continuum limit of zero lattice spacing, $a \\to 0$. To obtain a physical prediction, it is essential to perform calculations at multiple lattice spacings and extrapolate the results. This exercise  guides you through this critical process, using weighted linear regression to perform a continuum extrapolation and assess the quality and consistency of the fit.",
            "id": "3558801",
            "problem": "Consider a fixed inter-baryon separation $r^{\\star}$ at which a central two-baryon potential $V_{C}(r^{\\star})$ has been extracted from Lattice Quantum Chromodynamics (LQCD) calculations performed at three lattice spacings $a_{1},a_{2},a_{3}$ in the same physical volume. Under Symanzik effective theory, leading discretization effects for an appropriately improved action appear as even powers of the lattice spacing, so at fixed $r^{\\star}$ it is natural to model the lattice-spacing dependence by an ansatz that is linear in $a^{2}$:\n$$\nV_{C}(a;r^{\\star}) \\;=\\; V_{0} \\;+\\; c\\,a^{2} \\;+\\; \\varepsilon,\n$$\nwhere $V_{0}$ is the continuum-limit value at $a\\to 0$, $c$ is the slope describing leading discretization artifacts, and $\\varepsilon$ denotes statistical fluctuations. Assume that each measurement $V_{i}$ at lattice spacing $a_{i}$ has an independent Gaussian uncertainty with known standard deviation $\\sigma_{i}$. Under these assumptions, maximum-likelihood estimation is equivalent to a weighted least-squares linear fit in the variable $x_{i}=a_{i}^{2}$ with weights $w_{i}=1/\\sigma_{i}^{2}$. From the fit, extract:\n- the continuum-limit estimate $V_{0}$ in megaelectronvolts (MeV),\n- the slope $c$ in megaelectronvolts per square femtometer (MeV/fm$^{2}$),\n- the one-sigma uncertainties $\\sigma_{V_{0}}$ and $\\sigma_{c}$,\n- the goodness of fit quantified by the chi-squared per degree of freedom $\\chi^{2}/\\nu$ with $\\nu = N-2$ where $N$ is the number of points,\n- the $p$-value from the chi-squared distribution,\nand assess whether the three inputs are statistically consistent with the assumed $a^{2}$ scaling at the chosen $r^{\\star}$ by declaring the dataset “consistent” if and only if $p \\geq 0.05$.\n\nAll inputs use physically standard units. Lattice spacings $a_{i}$ are given in femtometers (fm), potentials $V_{i}$ in megaelectronvolts (MeV), and their one-sigma uncertainties $\\sigma_{i}$ in megaelectronvolts (MeV). You must:\n- perform the weighted linear regression of $V_{i}$ versus $x_{i}=a_{i}^{2}$,\n- compute $V_{0}$, $c$, $\\sigma_{V_{0}}$, $\\sigma_{c}$, $\\chi^{2}/\\nu$, and the $p$-value,\n- decide the consistency boolean as specified above.\n\nTest suite. Apply your program to the following four datasets, each at the same fixed $r^{\\star}$ but different measurement qualities. For each dataset, the tuple lists $(a_1, a_2, a_3)$ in fm, $(V_1, V_2, V_3)$ in MeV, and $(\\sigma_1, \\sigma_2, \\sigma_3)$ in MeV:\n- Dataset A (typical consistent case): $(a_1, a_2, a_3) = (0.12, 0.09, 0.06)$, $(V_1, V_2, V_3) = (-7.10, -8.40, -9.30)$, $(\\sigma_1, \\sigma_2, \\sigma_3) = (0.15, 0.15, 0.15)$.\n- Dataset B (inconsistent due to an outlier): $(a_1, a_2, a_3) = (0.12, 0.09, 0.06)$, $(V_1, V_2, V_3) = (-7.10, -9.10, -9.30)$, $(\\sigma_1, \\sigma_2, \\sigma_3) = (0.15, 0.15, 0.15)$.\n- Dataset C (large uncertainties, broadly consistent): $(a_1, a_2, a_3) = (0.12, 0.09, 0.06)$, $(V_1, V_2, V_3) = (-7.20, -8.30, -9.50)$, $(\\sigma_1, \\sigma_2, \\sigma_3) = (1.00, 1.00, 1.00)$.\n- Dataset D (near-zero slope, precise and consistent): $(a_1, a_2, a_3) = (0.12, 0.09, 0.06)$, $(V_1, V_2, V_3) = (-5.02, -4.98, -5.01)$, $(\\sigma_1, \\sigma_2, \\sigma_3) = (0.05, 0.05, 0.05)$.\n\nOutput specification. For each dataset, output a list containing $7$ entries in this exact order:\n$[V_{0}\\text{ (MeV)},\\,\\sigma_{V_{0}}\\text{ (MeV)},\\,c\\text{ (MeV/fm}^{2}\\text{)},\\,\\sigma_{c}\\text{ (MeV/fm}^{2}\\text{)},\\,\\chi^{2}/\\nu,\\,p\\text{-value},\\,\\text{consistent}]$,\nwhere all floating-point numbers must be rounded to three decimal places and the consistency is a boolean using the rule $p \\geq 0.05$. Your program should produce a single line of output containing the results for the four datasets as a comma-separated list of the four per-dataset lists enclosed in square brackets (for example, $[[\\cdots],[\\cdots],[\\cdots],[\\cdots]]$). All $V_{0}$ and $\\sigma_{V_{0}}$ values must be interpreted in MeV, all $c$ and $\\sigma_{c}$ values in MeV/fm$^{2}$, and $\\chi^{2}/\\nu$ and $p$-values are dimensionless. Do not include any units in the printed output. All computations must be carried out in radians where applicable; angles do not appear in this task.",
            "solution": "The user has provided a problem from computational nuclear physics, which requires performing a weighted linear regression to extract physical parameters from simulated lattice QCD data. The problem is to be validated before a solution is attempted.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Model**: The lattice-spacing dependence of the central potential $V_C$ at a fixed separation $r^{\\star}$ is modeled as linear in $a^2$: $V_{C}(a;r^{\\star}) = V_{0} + c\\,a^{2} + \\varepsilon$.\n- **Variables and Parameters**:\n    - $V_0$: Continuum-limit potential at $a \\to 0$.\n    - $c$: Slope describing leading discretization artifacts.\n    - $a$: Lattice spacing.\n    - $\\varepsilon$: Statistical fluctuations, assumed to be independent and Gaussian.\n- **Data per Measurement**: For each measurement $i=1, 2, 3$:\n    - Lattice spacing $a_i$ (in fm).\n    - Measured potential $V_i$ (in MeV).\n    - Standard deviation of the potential $\\sigma_i$ (in MeV).\n- **Method**: Maximum-likelihood estimation, equivalent to a weighted least-squares linear fit of $V_i$ versus $x_i = a_i^2$, with weights $w_i = 1/\\sigma_i^2$.\n- **Quantities to Extract**:\n    1.  Continuum-limit estimate $V_{0}$ (in MeV).\n    2.  Slope $c$ (in MeV/fm$^2$).\n    3.  One-sigma uncertainty $\\sigma_{V_{0}}$ (in MeV).\n    4.  One-sigma uncertainty $\\sigma_{c}$ (in MeV/fm$^2$).\n    5.  Chi-squared per degree of freedom $\\chi^{2}/\\nu$, with $\\nu = N-2$ and $N=3$ data points.\n    6.  The $p$-value from the chi-squared distribution.\n    7.  A boolean assessment of statistical consistency: \"consistent\" if and only if $p \\geq 0.05$.\n- **Test Datasets**: Four datasets (A, B, C, D) are provided, each with tuples for $(a_{1},a_{2},a_{3})$, $(V_{1},V_{2},V_{3})$, and $(\\sigma_{1},\\sigma_{2},\\sigma_{3})$.\n- **Output Format**: A single line containing a list of lists, one for each dataset. Each inner list must contain the 7 extracted quantities, with all floating-point numbers rounded to three decimal places.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded**: The problem is well-grounded in the methodology of lattice field theory. The use of Symanzik effective theory to characterize discretization errors, the leading $a^2$ dependence for improved actions, and the continuum extrapolation via a weighted linear fit are all standard and fundamental techniques in the field.\n- **Well-Posed**: The problem is well-posed. It provides a clear mathematical model and all necessary input data ($a_i, V_i, \\sigma_i$). The procedure of weighted linear regression is a deterministic algorithm that yields a unique solution for the fit parameters and their uncertainties, given the inputs. The number of data points ($N=3$) exceeds the number of model parameters ($k=2$), allowing for a well-defined goodness-of-fit test with $\\nu = N-2 = 1$ degree of freedom.\n- **Objective**: The problem is stated with objective and precise language. All quantities are clearly defined, and the criterion for consistency ($p \\ge 0.05$) is unambiguous.\n\nThe problem does not exhibit any of the flaws listed in the instructions (e.g., scientific unsoundness, incompleteness, ambiguity). All data and units are physically consistent and realistic for the context.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\n\nThe task is to perform a weighted linear regression for the model $y(x) = b + mx$. In the context of this problem, we identify the variables as follows:\n- The dependent variable is the potential, $y_i = V_i$.\n- The independent variable is the square of the lattice spacing, $x_i = a_i^2$.\n- The intercept is the continuum-limit potential, $b = V_0$.\n- The slope is the discretization coefficient, $m = c$.\n\nThe model is therefore $V_i = V_0 + c a_i^2$. Given that each measurement $V_i$ has a Gaussian uncertainty $\\sigma_i$, the optimal parameters $V_0$ and $c$ are found by minimizing the chi-squared function, $\\chi^2$:\n$$\n\\chi^2(V_0, c) = \\sum_{i=1}^{N} \\left( \\frac{V_i - (V_0 + c x_i)}{\\sigma_i} \\right)^2 = \\sum_{i=1}^{N} w_i (V_i - V_0 - c x_i)^2\n$$\nwhere $N=3$ is the number of data points and $w_i = 1/\\sigma_i^2$ are the weights.\n\nTo find the minimum, we set the partial derivatives of $\\chi^2$ with respect to $V_0$ and $c$ to zero:\n$$\n\\frac{\\partial \\chi^2}{\\partial V_0} = -2 \\sum_{i=1}^{N} w_i (V_i - V_0 - c x_i) = 0\n$$\n$$\n\\frac{\\partial \\chi^2}{\\partial c} = -2 \\sum_{i=1}^{N} w_i x_i (V_i - V_0 - c x_i) = 0\n$$\nThis leads to a system of two linear equations for the two unknowns, $V_0$ and $c$, known as the normal equations:\n$$\n\\begin{pmatrix}\n\\sum w_i  \\sum w_i x_i \\\\\n\\sum w_i x_i  \\sum w_i x_i^2\n\\end{pmatrix}\n\\begin{pmatrix}\nV_0 \\\\\nc\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\sum w_i V_i \\\\\n\\sum w_i x_i V_i\n\\end{pmatrix}\n$$\nTo simplify, let's define the following weighted sums:\n- $S_w = \\sum w_i$\n- $S_{wx} = \\sum w_i x_i$\n- $S_{wy} = \\sum w_i V_i$\n- $S_{wxx} = \\sum w_i x_i^2$\n- $S_{wxy} = \\sum w_i x_i V_i$\n\nThe linear system is then solved by inverting the $2 \\times 2$ matrix. The determinant of this matrix is $\\Delta = S_w S_{wxx} - (S_{wx})^2$. The solutions for $V_0$ and $c$ are:\n$$\nV_0 = \\frac{S_{wxx} S_{wy} - S_{wx} S_{wxy}}{\\Delta}\n$$\n$$\nc = \\frac{S_w S_{wxy} - S_{wx} S_{wy}}{\\Delta}\n$$\n\nThe uncertainties in the fitted parameters, $\\sigma_{V_0}$ and $\\sigma_c$, are derived from the covariance matrix of the parameters. The covariance matrix is the inverse of the Hessian matrix of $\\frac{1}{2}\\chi^2$, which is precisely the $2 \\times 2$ matrix from the normal equations.\n$$\n\\text{Cov}(V_0, c) = \\begin{pmatrix} \\sigma_{V_0}^2  \\text{cov}(V_0, c) \\\\ \\text{cov}(V_0, c)  \\sigma_c^2 \\end{pmatrix} = \\begin{pmatrix} S_w  S_{wx} \\\\ S_{wx}  S_{wxx} \\end{pmatrix}^{-1} = \\frac{1}{\\Delta} \\begin{pmatrix} S_{wxx}  -S_{wx} \\\\ -S_{wx}  S_w \\end{pmatrix}\n$$\nThe variances are the diagonal elements of this matrix:\n$$\n\\sigma_{V_0}^2 = \\frac{S_{wxx}}{\\Delta} \\quad \\implies \\quad \\sigma_{V_0} = \\sqrt{\\frac{S_{wxx}}{\\Delta}}\n$$\n$$\n\\sigma_c^2 = \\frac{S_w}{\\Delta} \\quad \\implies \\quad \\sigma_c = \\sqrt{\\frac{S_w}{\\Delta}}\n$$\n\nFinally, we assess the goodness of fit. The value of $\\chi^2$ is calculated using the best-fit parameters $V_0$ and $c$:\n$$\n\\chi^2_{\\text{fit}} = \\sum_{i=1}^{N} w_i (V_i - (V_0 + c x_i))^2\n$$\nThe number of degrees of freedom is $\\nu = N - k$, where $N=3$ is the number of data points and $k=2$ is the number of fitted parameters. Thus, $\\nu = 3-2=1$. The chi-squared per degree of freedom is $\\chi^2/\\nu = \\chi^2_{\\text{fit}}/1$.\n\nThe $p$-value represents the probability of obtaining a $\\chi^2$ value greater than or equal to the observed $\\chi^2_{\\text{fit}}$, assuming the model is correct. It is calculated from the survival function of the $\\chi^2$ distribution with $\\nu$ degrees of freedom:\n$$\np = P(\\chi^2_{\\nu} \\ge \\chi^2_{\\text{fit}})\n$$\nA large $p$-value (typically $p \\ge 0.05$) indicates that the observed scatter of the data points around the fitted line is statistically consistent with their uncertainties, meaning the model is a good fit. The problem defines \"consistent\" as the case where $p \\ge 0.05$.\n\nThe implementation will apply these formulas to each of the four provided datasets.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It processes each dataset, performs a weighted linear regression,\n    and formats the results according to the specification.\n    \"\"\"\n    test_cases = [\n        # Dataset A (typical consistent case)\n        ((0.12, 0.09, 0.06), (-7.10, -8.40, -9.30), (0.15, 0.15, 0.15)),\n        # Dataset B (inconsistent due to an outlier)\n        ((0.12, 0.09, 0.06), (-7.10, -9.10, -9.30), (0.15, 0.15, 0.15)),\n        # Dataset C (large uncertainties, broadly consistent)\n        ((0.12, 0.09, 0.06), (-7.20, -8.30, -9.50), (1.00, 1.00, 1.00)),\n        # Dataset D (near-zero slope, precise and consistent)\n        ((0.12, 0.09, 0.06), (-5.02, -4.98, -5.01), (0.05, 0.05, 0.05)),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = process_dataset(case)\n        all_results.append(result)\n\n    # Format the final output line as a list of lists.\n    # The str() on a list gives the desired '[...]' format.\n    results_as_strings = [str(res).replace(\" \", \"\") for res in all_results]\n    print(f\"[{','.join(results_as_strings)}]\")\n\ndef process_dataset(dataset):\n    \"\"\"\n    Performs weighted linear regression for a single dataset.\n\n    Args:\n        dataset (tuple): A tuple containing three tuples/lists for\n                         (a_i, V_i, sigma_i).\n\n    Returns:\n        list: A list of 7 results: [V0, sigma_V0, c, sigma_c, chi2/nu, p_value, consistent].\n              Floats are rounded to three decimal places.\n    \"\"\"\n    a_vals, v_vals, sigma_vals = dataset\n    \n    # Convert inputs to numpy arrays for vectorized calculations\n    a = np.array(a_vals, dtype=np.float64)\n    V = np.array(v_vals, dtype=np.float64)\n    sigma = np.array(sigma_vals, dtype=np.float64)\n\n    # Independent variable x = a^2 and weights w = 1/sigma^2\n    x = a**2\n    w = 1.0 / sigma**2\n    N = len(a)\n\n    # Calculate the weighted sums required for the fit\n    S_w = np.sum(w)\n    S_wx = np.sum(w * x)\n    S_wy = np.sum(w * V)\n    S_wxx = np.sum(w * x**2)\n    S_wxy = np.sum(w * x * V)\n\n    # Calculate the determinant of the design matrix\n    delta = S_w * S_wxx - S_wx**2\n\n    # Calculate the best-fit parameters (V0: intercept, c: slope)\n    V0 = (S_wxx * S_wy - S_wx * S_wxy) / delta\n    c = (S_w * S_wxy - S_wx * S_wy) / delta\n\n    # Calculate the variances and uncertainties of the parameters\n    var_V0 = S_wxx / delta\n    var_c = S_w / delta\n    sigma_V0 = np.sqrt(var_V0)\n    sigma_c = np.sqrt(var_c)\n\n    # Calculate the goodness of fit\n    V_fit = V0 + c * x\n    chi_squared = np.sum(w * (V - V_fit)**2)\n    nu = N - 2  # Degrees of freedom (N=3 data points, 2 parameters)\n    \n    # Handle the case where nu=0, although not expected for N=3\n    if nu > 0:\n        chi_squared_per_dof = chi_squared / nu\n        p_value = chi2.sf(chi_squared, df=nu)\n    else: \n        # This branch is not hit for the given problem (N=3)\n        chi_squared_per_dof = np.inf if chi_squared > 0 else 0.0\n        p_value = 0.0 if chi_squared > 0 else 1.0\n\n\n    # Determine consistency based on the p-value\n    is_consistent = p_value >= 0.05\n\n    # Format the results into a list, rounding floats to 3 decimal places\n    result_list = [\n        round(V0, 3),\n        round(sigma_V0, 3),\n        round(c, 3),\n        round(sigma_c, 3),\n        round(chi_squared_per_dof, 3),\n        round(p_value, 3),\n        is_consistent\n    ]\n    \n    # Python's default str(list) includes spaces, which might be undesirable.\n    # The prompt doesn't forbid it, but it's cleaner without.\n    # A custom string builder or replacing spaces is an option if needed.\n    # The final print statement will handle this for consistency.\n    return result_list\n\n# Execute the main function\nsolve()\n```"
        }
    ]
}