{
    "hands_on_practices": [
        {
            "introduction": "在包含动力学费米子的格点 QCD 模拟中，计算上最繁重的任务是反复求解涉及狄拉克算符的大型线性方程组。共轭梯度（CG）算法是用于此目的的标准迭代方法。本练习将巩固您对 CG 算法如何从第一性原理构建，以及其收敛速度如何由系统矩阵的谱性质从根本上决定的理解，从而为您提供对 HMC 模拟性能的关键洞察。",
            "id": "3571187",
            "problem": "在采用Wilson型费米子的格点量子色动力学(QCD)的混合蒙特卡罗(HMC)模拟中，人们经常需求解涉及格点狄拉克算符正规方程的线性系统。令$D$表示一个Wilson型格点狄拉克算符，并考虑厄米正定(HPD)矩阵$A \\equiv D^{\\dagger} D$。求解$A x = b$是计算HMC轨迹中赝费米子作用量和力的核心环节。\n\n(a) 从Krylov子空间的定义以及搜索方向需满足$A$-共轭的要求出发，定义用于求解HPD系统$A x = b$的共轭梯度(CG)算法。你的定义必须明确指出初始化、迭代解、残差、搜索方向的递推关系，以及确保$A$-共轭性的标量系数。\n\n(b) 仅使用线性代数和逼近理论的基本事实，根据$A$的谱推导CG误差在$k$次迭代后的$A$-范数的一个界。令$e_k \\equiv x^{\\ast} - x_k$表示误差，其中$x^{\\ast}$是精确解，$x_k$是$k$步后的CG迭代解。用$A$的条件数$\\kappa \\equiv \\lambda_{\\max}/\\lambda_{\\min}$来表示你的界，其中$\\lambda_{\\min}$和$\\lambda_{\\max}$分别表示$A$的最小和最大特征值。你可以使用关于Chebyshev多项式的公认事实，但必须推导它们是如何通过在$A$的谱上的多项式逼近进入CG误差界的。\n\n(c) 从(b)部分得到的界中，提取渐近每次迭代收敛因子$\\rho(\\kappa)$。它被定义为满足以下条件的最小标量$\\rho(\\kappa)$：存在一个与$k$无关的常数$C$，使得对于所有$k \\ge 0$都有\n$$\n\\| e_k \\|_{A} \\le C \\, \\rho(\\kappa)^{\\,k} \\, \\| e_0 \\|_{A} \\quad \\text{for all } k \\ge 0 .\n$$\n将$\\rho(\\kappa)$表示为仅含$\\kappa$的单个简化解析表达式。无需单位。最终答案只提供$\\rho(\\kappa)$的表达式。",
            "solution": "(a) 共轭梯度(CG)算法是一种求解线性系统$A x = b$的迭代方法，其中矩阵$A$是厄米正定(HPD)的。该算法在仿射子空间$x_0 + \\mathcal{K}_k(A, r_0)$中构造第$k$个迭代解$x_k$，其中$x_0$是初始猜测，$r_0 = b - A x_0$是初始残差，而$\\mathcal{K}_k(A, r_0) = \\text{span}\\{r_0, A r_0, \\dots, A^{k-1} r_0\\}$是由$A$和$r_0$生成的第$k$个Krylov子空间。CG的核心原理是找到唯一的$x_k \\in x_0 + \\mathcal{K}_k(A, r_0)$，它能最小化误差的$A$-范数$\\|e_k\\|_A \\equiv \\sqrt{e_k^\\dagger A e_k}$，其中$e_k = x^\\ast - x_k$且$x^\\ast=A^{-1}b$是精确解。\n\n这个最小化是通过生成一系列$A$-共轭的搜索方向$\\{p_0, p_1, \\dots, p_{k-1}\\}$来高效实现的，即对于$i \\neq j$有$p_i^\\dagger A p_j = 0$。这些方向构成了Krylov子空间$\\mathcal{K}_k(A, r_0)$的一个$A$-正交基。迭代解沿着这些方向进行更新：$x_{k+1} = x_k + \\alpha_k p_k$。选择系数$\\alpha_k$以最小化$\\|e_{k+1}\\|_A$。这等价于要求新的残差$r_{k+1} = b - A x_{k+1}$与当前搜索方向$p_k$正交。然后，新的搜索方向$p_{k+1}$由新的残差$r_{k+1}$和前一个搜索方向$p_k$构造，以确保它与所有先前的搜索方向都是$A$-共轭的。由于算法的特性，一个简单的两项递推就足够了。\n\n完整的算法定义如下：\n\n1.  **初始化**:\n    选择一个初始猜测$x_0$。\n    计算初始残差: $r_0 = b - A x_0$。\n    设置初始搜索方向: $p_0 = r_0$。\n    令$k=0$。\n\n2.  **迭代**:\n    当未满足收敛准则时：\n    a.  计算步长$\\alpha_k$:\n        $$ \\alpha_k = \\frac{r_k^\\dagger r_k}{p_k^\\dagger A p_k} $$\n    b.  更新解的迭代:\n        $$ x_{k+1} = x_k + \\alpha_k p_k $$\n    c.  使用短递推更新残差:\n        $$ r_{k+1} = r_k - \\alpha_k A p_k $$\n    d.  检查收敛性（例如，使用$\\|r_{k+1}\\|$）。如果收敛，则停止。\n    e.  计算新搜索方向的系数:\n        $$ \\beta_k = \\frac{r_{k+1}^\\dagger r_{k+1}}{r_k^\\dagger r_k} $$\n    f.  更新搜索方向:\n        $$ p_{k+1} = r_{k+1} + \\beta_k p_k $$\n    g.  增加迭代计数器: $k \\leftarrow k+1$。\n\n(b) 为了推导误差$A$-范数的界，我们利用CG算法的最小化性质。迭代解$x_k$是从Krylov子空间$\\mathcal{K}_k(A, r_0)$中构造的，因此我们可以写出$x_k = x_0 + Q_{k-1}(A) r_0$，其中$Q_{k-1}$是一个次数至多为$k-1$的多项式。\n\n$k$步后的误差是$e_k = x^\\ast - x_k$。使用$r_0 = b - Ax_0 = A(x^\\ast - x_0) = A e_0$，我们可以用初始误差$e_0$表示该误差：\n$$ e_k = x^\\ast - (x_0 + Q_{k-1}(A) r_0) = (x^\\ast - x_0) - Q_{k-1}(A) A e_0 = e_0 - A Q_{k-1}(A) e_0 $$\n令$P_k(\\lambda) = 1 - \\lambda Q_{k-1}(\\lambda)$。$P_k$是一个次数至多为$k$且满足约束$P_k(0) = 1$的多项式。根据这个定义，误差变为：\n$$ e_k = P_k(A) e_0 $$\nCG算法在所有可能的$x_k \\in x_0 + \\mathcal{K}_k(A, r_0)$中找到使$\\|e_k\\|_A$最小化的迭代解$x_k$。这等价于找到一个次数至多为$k$且$P_k(0)=1$的多项式$P_k$，以最小化$\\|P_k(A) e_0\\|_A$。\n\n我们可以通过考虑任何一个有效的多项式来界定这个最小化的范数。令$\\mathcal{P}_k$为所有次数至多为$k$且$P_k(0)=1$的多项式的集合。那么，\n$$ \\|e_k\\|_A = \\min_{P_k \\in \\mathcal{P}_k} \\|P_k(A) e_0\\|_A $$\n为了得到一个上界，我们在$A$的特征基中表示$e_0$。令$A v_j = \\lambda_j v_j$（$j=1, \\dots, n$），其中特征值$\\lambda_j$是正的。令$e_0 = \\sum_{j=1}^n c_j v_j$。那么：\n$$ \\|P_k(A) e_0\\|_A^2 = \\left\\| \\sum_{j=1}^n c_j P_k(\\lambda_j) v_j \\right\\|_A^2 = \\sum_{j=1}^n \\lambda_j |c_j|^2 |P_k(\\lambda_j)|^2 \\le \\left( \\max_{j} |P_k(\\lambda_j)| \\right)^2 \\sum_{j=1}^n \\lambda_j |c_j|^2 $$\n最后的和是$\\|e_0\\|_A^2$。最大值是在$A$的谱$\\sigma(A)$上取。这给出：\n$$ \\|e_k\\|_A \\le \\left( \\min_{P_k \\in \\mathcal{P}_k} \\max_{\\lambda \\in \\sigma(A)} |P_k(\\lambda)| \\right) \\|e_0\\|_A $$\n问题现在简化为一个多项式逼近问题：找到一个在$\\lambda=0$处为1且在$A$的谱上具有最小可能最大幅值的$k$次多项式。由于只知道谱位于区间$[\\lambda_{\\min}, \\lambda_{\\max}]$内，我们在这个连续区间上对最大值进行界定：\n$$ \\min_{P_k \\in \\mathcal{P}_k} \\max_{\\lambda \\in \\sigma(A)} |P_k(\\lambda)| \\le \\min_{P_k \\in \\mathcal{P}_k} \\max_{\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]} |P_k(\\lambda)| $$\n这个经典逼近问题的解由一个经过缩放和平移的第一类Chebyshev多项式$T_k(z)$给出。回忆一下，$T_k(z)$在所有具有固定首项系数的$k$次多项式中，最小化了在$[-1, 1]$上的最大幅值。为了满足$P_k(0)=1$，我们选择多项式：\n$$ P_k(\\lambda) = \\frac{T_k\\left(\\frac{\\lambda_{\\max}+\\lambda_{\\min}-2\\lambda}{\\lambda_{\\max}-\\lambda_{\\min}}\\right)}{T_k\\left(\\frac{\\lambda_{\\max}+\\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\\right)} $$\n分子中$T_k$的自变量将区间$\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]$映射到$[-1, 1]$。在这个区间上，$|T_k(z)| \\le 1$。因此，$P_k(\\lambda)$在$[\\lambda_{\\min}, \\lambda_{\\max}]$上的最大幅值由分母的倒数给出：\n$$ \\max_{\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]} |P_k(\\lambda)| = \\frac{1}{\\left|T_k\\left(\\frac{\\lambda_{\\max}+\\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\\right)\\right|} = \\frac{1}{T_k\\left(\\frac{\\kappa+1}{\\kappa-1}\\right)} $$\n其中$\\kappa = \\lambda_{\\max}/\\lambda_{\\min}$是$A$的条件数。自变量大于1，所以$T_k$是正的。对于$z > 1$，$T_k(z) = \\cosh(k \\cdot \\arccosh(z))$。令$z_0 = \\frac{\\kappa+1}{\\kappa-1}$。那么$\\arccosh(z_0) = \\ln(z_0 + \\sqrt{z_0^2-1})$。\n$$ z_0^2 - 1 = \\left(\\frac{\\kappa+1}{\\kappa-1}\\right)^2 - 1 = \\frac{(\\kappa^2+2\\kappa+1) - (\\kappa^2-2\\kappa+1)}{(\\kappa-1)^2} = \\frac{4\\kappa}{(\\kappa-1)^2} $$\n$$ \\sqrt{z_0^2 - 1} = \\frac{2\\sqrt{\\kappa}}{\\kappa-1} $$\n$$ z_0 + \\sqrt{z_0^2 - 1} = \\frac{\\kappa+1+2\\sqrt{\\kappa}}{\\kappa-1} = \\frac{(\\sqrt{\\kappa}+1)^2}{(\\sqrt{\\kappa}-1)(\\sqrt{\\kappa}+1)} = \\frac{\\sqrt{\\kappa}+1}{\\sqrt{\\kappa}-1} $$\n所以$\\arccosh(z_0) = \\ln\\left(\\frac{\\sqrt{\\kappa}+1}{\\sqrt{\\kappa}-1}\\right)$。使用$T_k(z_0) = \\cosh(k \\ln(\\dots))$以及定义$\\cosh(u) = (e^u + e^{-u})/2$：\n$$ T_k\\left(\\frac{\\kappa+1}{\\kappa-1}\\right) = \\frac{1}{2}\\left[ \\left(\\frac{\\sqrt{\\kappa}+1}{\\sqrt{\\kappa}-1}\\right)^k + \\left(\\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1}\\right)^k \\right] $$\n由于第二项是正的，我们可以建立一个有用的下界：$T_k\\left(\\frac{\\kappa+1}{\\kappa-1}\\right) > \\frac{1}{2}\\left(\\frac{\\sqrt{\\kappa}+1}{\\sqrt{\\kappa}-1}\\right)^k$。\n综合起来，$\\|e_k\\|_A$的误差界是：\n$$ \\|e_k\\|_A \\le \\frac{1}{T_k\\left(\\frac{\\kappa+1}{\\kappa-1}\\right)} \\|e_0\\|_A \\le 2 \\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)^k \\|e_0\\|_A $$\n最终的界，习惯上用常数2表示，为：\n$$ \\|e_k\\|_A \\le 2 \\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)^k \\|e_0\\|_A $$\n\n(c) 渐近每次迭代收敛因子$\\rho(\\kappa)$由不等式$\\| e_k \\|_{A} \\le C \\, \\rho(\\kappa)^{\\,k} \\, \\| e_0 \\|_{A}$定义，其中$C$是与$k$无关的某个常数。将此定义与(b)部分推导出的界\n$$ \\|e_k\\|_A \\le 2 \\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)^k \\|e_0\\|_A $$\n进行比较，我们可以直接确定常数$C=2$和收敛因子$\\rho(\\kappa)$。收敛因子是决定每次迭代误差减小率的指数项的底。因此，$\\rho(\\kappa)$的表达式是：\n$$ \\rho(\\kappa) = \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} $$\n这个表达式量化了CG算法的收敛速度如何随着矩阵$A$的条件数$\\kappa$的增大而恶化。对于$\\kappa \\gg 1$，我们有$\\rho(\\kappa) \\approx 1 - 2/\\sqrt{\\kappa}$，这表明达到一定精度所需的迭代次数大致与$\\sqrt{\\kappa}$成正比。",
            "answer": "$$\\boxed{\\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1}}$$"
        },
        {
            "introduction": "混合蒙特卡罗（HMC）算法通过在一段时间内对一个虚构的哈密顿系统进行积分来生成提议。该算法的有效性关键取决于此时间演化的性质，特别是其时间可逆性和能量守恒性。本动手练习将指导您实现一个可逆性测试，这是一个基础的诊断工具，用于验证您的 HMC 代码，并量化实际中的不完美之处（如不精确的线性求解器）如何影响积分器的质量。",
            "id": "3571194",
            "problem": "您需要实现并验证一个可逆性测试，该测试针对用于格点量子色动力学（Lattice QCD）的混合蒙特卡罗（HMC）分子动力学积分器，通过模拟一个紧致规范场和一个需要迭代线性求解器的玩具赝费米子部分来完成。目标是量化精确可逆性的破坏程度以及微正则能量漂移作为求解器残差容忍度的函数。您的程序必须是一个完整的、可运行的程序，能够执行分子动力学在时间上的前进和后退演化，评估微正则能量漂移，并报告一个小型、完全指定的测试套件的可逆性误差。所有角度必须以弧度为单位。\n\n从以下基本基础开始。用于格点量子色动力学的HMC方法为每个规范自由度引入一个辅助正则动量，并对一个虚构的分子动力学时间积分哈密顿方程。对于一个紧致阿贝尔规范群，考虑一个尺寸为 $L_x \\times L_y$ 的二维周期性格点，其中 $L_x = 2$ 且 $L_y = 2$。每个链变量是一个紧致角 $\\theta_{x,\\mu} \\in (-\\pi,\\pi]$，代表一个 $\\mathrm{U}(1)$ 链 $U_{x,\\mu} = e^{i \\theta_{x,\\mu}}$，其中 $\\mu \\in \\{0,1\\}$ 分别表示 $x$ 和 $y$ 方向。引入与 $\\theta_{x,\\mu}$ 共轭的正则动量 $p_{x,\\mu} \\in \\mathbb{R}$。哈密顿量为\n$$\nH(\\theta,p) = T(p) + S_g(\\theta) + V_f(\\theta),\n$$\n其中 $T(p) = \\tfrac{1}{2} \\sum_{x,\\mu} p_{x,\\mu}^2$ 是动能项，$S_g(\\theta)$ 是 $\\mathrm{U}(1)$ 的威尔逊纯规范作用量，\n$$\nS_g(\\theta) = -\\beta \\sum_{x} \\cos \\phi_x,\n$$\n其中小方块角为 $\\phi_x = \\theta_{x,0} + \\theta_{x+\\hat{0},1} - \\theta_{x,1} - \\theta_{x+\\hat{1},0}$ 并采用周期性边界条件，而 $V_f(\\theta)$ 是一个玩具赝费米子势，其构造为正定的，并且在每次计算力时都需要进行线性求解：\n$$\nV_f(\\theta) = \\tfrac{1}{2} \\, b^\\top A(\\theta)^{-1} b, \\quad A(\\theta) = I + c_0 \\sum_{\\ell=1}^{N_\\ell} \\theta_\\ell^2 \\, B_\\ell.\n$$\n此处 $I$ 是 $n \\times n$ 单位矩阵，其中 $n = 12$，$N_\\ell = 8$ 是 $2 \\times 2$ 格点上的有向链数量，$c_0 = 0.1$ 是一个固定的正常数，每个 $B_\\ell$ 是一个对称半正定矩阵，定义为 $B_\\ell = v_\\ell v_\\ell^\\top$，其中 $v_\\ell \\in \\mathbb{R}^n$ 是一个随机向量。向量 $b \\in \\mathbb{R}^n$ 是一个固定的随机向量。链索引 $\\ell$ 按 $(x,y,\\mu)$ 的字典序排列，其中 $x \\in \\{0,1\\}$ 在最外层，然后是 $y \\in \\{0,1\\}$，再然后是方向 $\\mu \\in \\{0,1\\}$。\n\n分子动力学使用时间可逆的辛蛙跳积分器进行。如果力被精确计算，则映射是保面积和可逆的，并且微正则哈密顿量 $H$ 在由步长控制的积分误差范围内是守恒的。在实践中，对于包含动力学费米子的格点量子色动力学，费米子力需要求解一个大型线性系统，这通常通过共轭梯度法和一个停止容忍度来完成。不精确的求解会破坏精确的可逆性，并可能导致绝对微正则能量漂移的增加。\n\n您的任务是：\n\n- 为紧致 $\\mathrm{U}(1)$ 规范场 $\\theta_{x,\\mu}$ 和正则动量 $p_{x,\\mu}$ 实现蛙跳积分器，使用哈密顿方程 $\\dot{\\theta}_{x,\\mu} = \\partial H / \\partial p_{x,\\mu}$ 和 $\\dot{p}_{x,\\mu} = - \\partial H / \\partial \\theta_{x,\\mu}$。按照标准的蛙跳方案，每次更新使用半步动量更新和全步链更新。\n- 使用来自威尔逊作用量在 $2 \\times 2$ 格点上的精确解析规范力，并采用周期性边界。每次更新后，角度必须被缠绕回 $(-\\pi,\\pi]$。\n- 对于类费米子力项，如上构造 $A(\\theta)$，并使用共轭梯度法计算近似解 $x \\approx A(\\theta)^{-1} b$，求解器需满足基于残差范数的指定容忍度 $\\epsilon$。不要使用预处理器。在给定的力评估过程中，始终使用相同的 $x$ 来一致地计算费米子力。\n- 微正则能量 $H(\\theta,p)$ 必须使用对 $A(\\theta)^{-1}$ 的直接稠密线性求解来高精度地评估（即，不要使用迭代求解器来计算能量）。这将力的不精确性与能量评估分离开来。\n- 执行一个可逆性测试：从一个固定的初始条件 $(\\theta^{(0)}, p^{(0)})$ 开始，以步长 $\\delta \\tau$ 向前积分 $N_{\\text{steps}}$ 步，然后反转动量 $p \\to -p$，再以步长 $\\delta \\tau$ 积分 $N_{\\text{steps}}$ 步。比较后退积分段结束后的 $(\\theta^{(b)}, p^{(b)})$ 与 $(\\theta^{(0)}, -p^{(0)})$。测量最大绝对缠绕角差和最大绝对动量差。\n- 量化前向积分段结束后的绝对微正则能量漂移，$\\Delta H = H(\\theta^{(f)}, p^{(f)}) - H(\\theta^{(0)}, p^{(0)})$，其中 $(\\theta^{(f)}, p^{(f)})$ 是前向积分段结束后的状态。\n\n初始化和数据：\n\n- 使用单一的随机数生成器种子 $s = 314159$ 以使实验可复现。按以下顺序抽取数据：每个 $\\ell = 1,\\dots,N_\\ell$ 的向量 $v_\\ell \\in \\mathbb{R}^{n}$，向量 $b \\in \\mathbb{R}^{n}$，初始链 $\\theta^{(0)}_{x,\\mu}$，以及初始动量 $p^{(0)}_{x,\\mu}$。\n- $v_\\ell$ 和 $b$ 的每个分量都独立地从均值为 $0$、方差为 $1$ 的正态分布中抽样。\n- 每个初始链角度 $\\theta^{(0)}_{x,\\mu}$ 独立地从均值为 $0$、方差为 $\\sigma^2$（其中 $\\sigma = 0.3$）的正态分布中抽样，然后缠绕到 $(-\\pi,\\pi]$ 内。每个初始动量 $p^{(0)}_{x,\\mu}$ 独立地从均值为 $0$、方差为 $1$ 的正态分布中抽样。\n\n积分器和作用量参数：\n\n- 格点尺寸 $L_x = 2$, $L_y = 2$。\n- 规范耦合 $\\beta = 3.0$。\n- 费米子矩阵参数 $c_0 = 0.1$。\n- 赝费米子维度 $n = 12$。\n- 蛙跳步长 $\\delta \\tau = 0.1$ 和步数 $N_{\\text{steps}} = 10$。\n\n共轭梯度求解器的停止准则必须基于相对残差 $\\|r_k\\|_2 / \\|b\\|_2 \\le \\epsilon$，最大迭代次数为 $1000$ 次。线性算子是稠密对称正定矩阵 $A(\\theta)$。不允许使用预处理。\n\n测试套件：\n\n对以下四种求解器容忍度 $\\epsilon$ 运行完整的前向-后向可逆性协议，同时将所有其他参数固定为上述值：\n\n- $\\epsilon = 10^{-12}$。\n- $\\epsilon = 10^{-8}$。\n- $\\epsilon = 10^{-5}$。\n- $\\epsilon = 10^{-3}$。\n\n对于每个求解器容忍度 $\\epsilon$，计算并报告：\n\n- 前向积分段结束后的绝对微正则能量漂移 $|\\Delta H|$，其中 $H$ 使用对 $A(\\theta)^{-1}$ 的稠密直接求解进行评估。\n- 往返行程结束后的最大绝对缠绕角差 $E_\\theta = \\max_{\\ell} \\left| \\operatorname{wrap}\\left(\\theta_\\ell^{(b)} - \\theta_\\ell^{(0)}\\right) \\right|$，角度被缠绕到 $(-\\pi,\\pi]$ 内。\n- 往返行程结束后的最大绝对动量差 $E_p = \\max_{\\ell} \\left| p_\\ell^{(b)} + p_\\ell^{(0)} \\right|$。\n\n角度单位说明：所有角度都以弧度为单位。\n\n最终输出格式：\n\n您的程序应该生成一行输出，其中包含一个逗号分隔的列表，列表被方括号括起来。每个测试用例的结果本身必须是一个三元素列表 $[|\\Delta H|, E_\\theta, E_p]$。所有浮点数必须使用科学记数法格式化，小数点后保留八位数字。例如，输出必须看起来像\n$$\n\\big[ [a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3],[a_4,b_4,c_4] \\big],\n$$\n但使用实际数字且没有空格。输出必须是单行，且无其他内容。",
            "solution": "问题陈述被评估为有效。它具有科学依据，提法明确，客观，并为计算物理学中的一个数值实验提供了一套完整且一致的规范。该模型虽然经过简化，但基于格点量子色动力学（Lattice QCD）和哈密顿动力学的既定原理。任务涉及实现一个标准的混合蒙特卡罗（HMC）积分器并执行可逆性测试，这是该领域中一项常规且有意义的诊断程序。所有参数、初始条件和过程都已明确定义，使得问题完全确定且可验证。\n\n解决方案首先构建模拟所需的组件——哈密顿量、其组成的势能项和动能项，以及从势能导出的力——然后使用指定的蛙跳算法对运动方程进行积分。任务的核心是观察力计算中的不精确性（源于线性系统的迭代解）如何影响积分器的一个基本属性：时间可逆性。\n\n系统的哈密顿量由下式给出\n$$\nH(\\theta,p) = T(p) + S_g(\\theta) + V_f(\\theta)\n$$\n其中 $\\theta = \\{\\theta_{x,\\mu}\\}$ 是 $L_x \\times L_y = 2 \\times 2$ 格点上的紧致链角度，而 $p = \\{p_{x,\\mu}\\}$ 是它们的共轭动量。总链数为 $N_\\ell = L_x \\times L_y \\times 2 = 8$。\n\n动能为 $T(p) = \\tfrac{1}{2} \\sum_{\\ell=1}^{N_\\ell} p_\\ell^2$。势能由纯规范部分 $S_g(\\theta)$ 和赝费米子部分 $V_f(\\theta)$ 组成。\n\n规范作用量是 U(1) 规范群的威尔逊作用量：\n$$\nS_g(\\theta) = -\\beta \\sum_{x} \\cos \\phi_x\n$$\n其中 $\\beta=3.0$ 是耦合常数，求和遍历所有 4 个格点位形 $x=(i_x, i_y)$。在位形 $x$ 处的小方块角 $\\phi_x$ 定义为\n$$\n\\phi_x = \\theta_{x,0} + \\theta_{x+\\hat{0},1} - \\theta_{x,1} - \\theta_{x+\\hat{1},0}\n$$\n具有周期性边界条件，其中 $\\mu=0$ 表示 x 方向，$\\mu=1$ 表示 y 方向。此作用量在链变量 $\\theta_{x,\\mu}$ 上产生的力为 $F_{g,x,\\mu} = -\\partial S_g / \\partial \\theta_{x,\\mu}$。一个给定的链 $\\theta_{x,\\mu}$ 对两个小方块有贡献。对于位形 $x=(i_x,i_y)$ 处的链 $\\theta_{x,0}$，其对力的贡献是\n$$\nF_{g,x,0} = -\\beta (\\sin \\phi_x - \\sin \\phi_{x-\\hat{1}})\n$$\n其中 $x-\\hat{1}$ 是位形 $(i_x, (i_y-1) \\pmod{L_y})$。对于链 $\\theta_{x,1}$，力是\n$$\nF_{g,x,1} = -(-\\sin \\phi_x + \\sin \\phi_{x-\\hat{0}})\n$$\n其中 $x-\\hat{0}$ 是位形 $((i_x-1) \\pmod{L_x}, i_y)$。\n\n赝费米子势 $V_f(\\theta)$ 模拟了费米子行列式的效应，是计算复杂性和不精确性的来源。它被定义为\n$$\nV_f(\\theta) = \\tfrac{1}{2} \\, b^\\top A(\\theta)^{-1} b\n$$\n其中 $b \\in \\mathbb{R}^n$（$n=12$）是一个固定的随机向量，而 $A(\\theta)$ 是一个依赖于规范场构型 $\\theta$ 的 $n \\times n$ 矩阵：\n$$\nA(\\theta) = I + c_0 \\sum_{\\ell=1}^{N_\\ell} \\theta_\\ell^2 \\, B_\\ell\n$$\n其中 $c_0=0.1$ 是一个常数，$\\theta_\\ell$ 是扁平化字典序中的第 $\\ell$ 个链角度，而 $B_\\ell = v_\\ell v_\\ell^\\top$ 是由随机向量 $v_\\ell \\in \\mathbb{R}^n$ 构造的固定对称半正定矩阵。由于 $I$ 是正定的，且每个 $c_0 \\theta_\\ell^2 B_\\ell$ 是半正定的，因此矩阵 $A(\\theta)$ 保证是对称正定（SPD）的，这是共轭梯度（CG）算法稳定性的一个关键属性。\n\n赝费米子力 $F_{f,\\ell} = -\\partial V_f / \\partial \\theta_\\ell$ 使用矩阵微积分导出。通过令 $x(\\theta) = A(\\theta)^{-1}b$，我们有 $V_f(\\theta) = \\tfrac{1}{2} b^\\top x(\\theta)$。其导数为：\n$$\n\\frac{\\partial V_f}{\\partial \\theta_\\ell} = -\\frac{1}{2} b^\\top A^{-1} \\frac{\\partial A}{\\partial \\theta_\\ell} A^{-1} b = -\\frac{1}{2} x^\\top \\left( 2 c_0 \\theta_\\ell B_\\ell \\right) x = -c_0 \\theta_\\ell \\, (x^\\top B_\\ell x)\n$$\n因此，力为\n$$\nF_{f,\\ell} = c_0 \\theta_\\ell \\, (x^\\top B_\\ell x)\n$$\n计算此力需要找到 $x = A(\\theta)^{-1}b$。这是通过使用 CG 算法完成的，当相对残差范数 $\\|A x_k - b\\|_2 / \\|b\\|_2$ 低于指定的容忍度 $\\epsilon$ 时，该算法停止。此解的不精确性是问题的核心焦点。\n\n系统使用标准的二阶蛙跳积分器进行演化，当力被精确计算时，该积分器是时间可逆和辛的。单步 $\\delta\\tau=0.1$ 的积分过程如下：\n1. 将动量更新半步：$p \\to p + F(\\theta) \\frac{\\delta\\tau}{2}$。\n2. 将位置更新一整步：$\\theta \\to \\theta + p \\, \\delta\\tau$。然后将角度缠绕到区间 $(-\\pi, \\pi]$ 内。\n3. 将动量更新最后的半步：$p \\to p + F(\\theta_{new}) \\frac{\\delta\\tau}{2}$。\n此过程重复 $N_{\\text{steps}}=10$ 次。\n\n可逆性测试包括一个 $N_{\\text{steps}}$ 步的时间前向轨迹，接着是动量反转 $p \\to -p$，以及一个 $N_{\\text{steps}}$ 步的时间后向轨迹。将最终状态 $(\\theta^{(b)}, p^{(b)})$ 与初始状态 $(\\theta^{(0)}, -p^{(0)})$进行比较。对每个求解器容忍度 $\\epsilon$ 测量三个量：\n1.  **能量漂移 $|\\Delta H|$**：哈密顿量的绝对变化，即 $|H(\\theta^{(f)}, p^{(f)}) - H(\\theta^{(0)}, p^{(0)})|$，在前向轨迹之后计算。这是能量守恒的一个度量。为了这个计算，$H$ 是通过对 $A(\\theta)^{-1}$ 进行高精度的直接线性求解来计算的，以将积分误差与能量测量误差分离开。\n2.  **角度可逆性误差 $E_\\theta$**：最终角度与初始角度的最大绝对偏差，$\\max_\\ell |\\operatorname{wrap}(\\theta_\\ell^{(b)} - \\theta_\\ell^{(0)})|$。\n3.  **动量可逆性误差 $E_p$**：最终动量与反向初始动量的最大绝对偏差，$\\max_\\ell |p_\\ell^{(b)} + p_\\ell^{(0)}|$。\n\n这个数值实验针对一组容忍度 $\\epsilon \\in \\{10^{-12}, 10^{-8}, 10^{-5}, 10^{-3}\\}$ 的测试套件进行，展示了如预期的那样，一个更宽松（更大的 $\\epsilon$）的求解器容忍度如何导致更显著的可逆性和能量守恒的破坏。所有随机数都由固定的种子生成，以保证可复现性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a reversibility test for a Hybrid Monte Carlo integrator\n    on a toy U(1) lattice gauge theory model.\n    \"\"\"\n    # Problem Parameters\n    L_X, L_Y = 2, 2\n    N_LINKS = L_X * L_Y * 2\n    BETA = 3.0\n    C0 = 0.1\n    N_PF = 12\n    DT = 0.1\n    N_STEPS = 10\n    SIGMA_THETA = 0.3\n    SEED = 314159\n    CG_MAX_ITER = 1000\n    TEST_TOLERANCES = [1e-12, 1e-8, 1e-5, 1e-3]\n\n    # --- Initialization ---\n    rng = np.random.default_rng(SEED)\n\n    # Generate fixed random data for the pseudofermion sector\n    # Vectors v_l used to construct matrices B_l\n    v_vectors = rng.normal(size=(N_LINKS, N_PF))\n    # Matrices B_l = v_l v_l^T\n    B_matrices = np.array([np.outer(v, v) for v in v_vectors])\n    # Fixed pseudofermion source vector b\n    b_vector = rng.normal(size=N_PF)\n    b_norm = np.linalg.norm(b_vector)\n\n    # Generate fixed initial conditions\n    theta_initial = (rng.normal(scale=SIGMA_THETA, size=(L_X, L_Y, 2)) + np.pi) % (2 * np.pi) - np.pi\n    p_initial = rng.normal(size=(L_X, L_Y, 2))\n\n    # --- Helper Functions ---\n    def wrap_angle(angles):\n        \"\"\"Wraps angles to the interval (-pi, pi].\"\"\"\n        return (angles + np.pi) % (2 * np.pi) - np.pi\n\n    def get_plaquettes(theta):\n        \"\"\"Computes plaquette angles for a given gauge field configuration.\"\"\"\n        plaquettes = np.zeros((L_X, L_Y))\n        for ix in range(L_X):\n            for iy in range(L_Y):\n                # phi_x = theta_{x,0} + theta_{x+0,1} - theta_{x,1} - theta_{x+1,0}\n                # with periodic boundary conditions\n                plaquettes[ix, iy] = (\n                    theta[ix, iy, 0]\n                    + theta[(ix + 1) % L_X, iy, 1]\n                    - theta[ix, iy, 1]\n                    - theta[ix, (iy + 1) % L_Y, 0]\n                )\n        return plaquettes\n\n    def cg_solve(A, b, b_norm_val, rel_tol):\n        \"\"\"Solves Ax = b using Conjugate Gradient for a symmetric positive-definite A.\"\"\"\n        x = np.zeros_like(b)\n        r = b.copy()\n        p = r.copy()\n        rs_old = r @ r\n        \n        abs_tol_sq = (rel_tol * b_norm_val)**2\n        if rs_old  abs_tol_sq:\n            return x\n\n        for _ in range(CG_MAX_ITER):\n            Ap = A @ p\n            alpha = rs_old / (p @ Ap)\n            x += alpha * p\n            r -= alpha * Ap\n            rs_new = r @ r\n            if rs_new  abs_tol_sq:\n                break\n            p = r + (rs_new / rs_old) * p\n            rs_old = rs_new\n        return x\n\n    # --- Physics and Integrator Functions ---\n    def compute_A_matrix(theta_flat):\n        \"\"\"Computes the pseudofermion matrix A(theta).\"\"\"\n        A = np.identity(N_PF)\n        theta_sq = theta_flat**2\n        # Sum over links: c0 * theta_l^2 * B_l\n        A += C0 * np.einsum('l,lij->ij', theta_sq, B_matrices)\n        return A\n        \n    def total_force(theta, epsilon):\n        \"\"\"Computes the total force F = -dV/dtheta.\"\"\"\n        # Gauge force\n        plaquettes = get_plaquettes(theta)\n        force_g = np.zeros_like(theta)\n        for ix in range(L_X):\n            for iy in range(L_Y):\n                # F_g,x,0 = -beta * (sin(phi_x) - sin(phi_{x-y_hat}))\n                force_g[ix, iy, 0] = -BETA * (\n                    np.sin(plaquettes[ix, iy]) - np.sin(plaquettes[ix, (iy - 1) % L_Y])\n                )\n                # F_g,x,1 = -(-sin(phi_x) + sin(phi_{x-x_hat}))\n                force_g[ix, iy, 1] = -BETA * (\n                    -np.sin(plaquettes[ix, iy]) + np.sin(plaquettes[(ix - 1) % L_X, iy])\n                )\n        \n        # Pseudofermion force\n        theta_flat = theta.flatten()\n        A = compute_A_matrix(theta_flat)\n        x_sol = cg_solve(A, b_vector, b_norm, epsilon)\n        \n        # F_f,l = c0 * theta_l * (x^T B_l x)\n        xT_B = np.einsum('i,lij->lj', x_sol, B_matrices)\n        xT_B_x = np.einsum('lj,j->l', xT_B, x_sol)\n        force_f_flat = C0 * theta_flat * xT_B_x\n        \n        force_total = force_g.flatten() + force_f_flat\n        return force_total.reshape(L_X, L_Y, 2)\n\n    def calculate_hamiltonian(theta, p):\n        \"\"\"Calculates the Hamiltonian with high precision.\"\"\"\n        # Kinetic energy\n        T = 0.5 * np.sum(p**2)\n        \n        # Gauge action\n        plaquettes = get_plaquettes(theta)\n        S_g = -BETA * np.sum(np.cos(plaquettes))\n        \n        # Pseudofermion potential (high precision solve)\n        theta_flat = theta.flatten()\n        A = compute_A_matrix(theta_flat)\n        x_sol_exact = np.linalg.solve(A, b_vector)\n        V_f = 0.5 * (b_vector @ x_sol_exact)\n        \n        return T + S_g + V_f\n\n    def run_trajectory(theta_start, p_start, epsilon):\n        \"\"\"Integrates the system for N_steps using the leapfrog algorithm.\"\"\"\n        theta, p = theta_start.copy(), p_start.copy()\n        \n        # Standard leapfrog: p(t+dt/2), theta(t+dt), p(t+dt)\n        force_current = total_force(theta, epsilon)\n        p += 0.5 * DT * force_current\n        for _ in range(N_STEPS - 1):\n            theta = wrap_angle(theta + DT * p)\n            force_current = total_force(theta, epsilon)\n            p += DT * force_current\n        \n        # Final full theta step and half p step\n        theta = wrap_angle(theta + DT * p)\n        force_current = total_force(theta, epsilon)\n        p += 0.5 * DT * force_current\n        \n        return theta, p\n\n    # --- Main Test Loop ---\n    results = []\n    H_initial = calculate_hamiltonian(theta_initial, p_initial)\n\n    for epsilon in TEST_TOLERANCES:\n        # Forward trajectory\n        theta_fwd, p_fwd = run_trajectory(theta_initial, p_initial, epsilon)\n        \n        # Energy drift\n        H_final_fwd = calculate_hamiltonian(theta_fwd, p_fwd)\n        delta_H = np.abs(H_final_fwd - H_initial)\n        \n        # Backward trajectory\n        theta_bwd, p_bwd = run_trajectory(theta_fwd, -p_fwd, epsilon)\n        \n        # Reversibility errors\n        E_theta = np.max(np.abs(wrap_angle(theta_bwd - theta_initial)))\n        E_p = np.max(np.abs(p_bwd + p_initial))\n        \n        results.append([delta_H, E_theta, E_p])\n\n    # --- Format and Print Output ---\n    output_str = \",\".join(\n        f\"[{res[0]:.8e},{res[1]:.8e},{res[2]:.8e}]\" for res in results\n    )\n    print(f\"[{output_str}]\")\n\n\nsolve()\n\n```"
        },
        {
            "introduction": "在生成一系列规范场组态之后，格点 QCD 项目的最后阶段是计算物理可观测量及其统计不确定性。由于马尔可夫链蒙特卡罗方法产生的是相关的时间序列数据，因此朴素的误差分析是不正确的。本练习提供基于代码的实践训练，涵盖了分箱（binning）和刀切法（jackknife resampling）等基本技术，这些是处理自相关并为如有效质量等非线性可观测量获得可靠误差估计的标准方法。",
            "id": "3571154",
            "problem": "您需要构建一个完整的、可运行的程序，为格点量子色动力学（Lattice QCD）中常用的非线性估计量——有效质量，实现一种分箱加刀切法（binning plus jackknife）的流程。目标是将通常具有自相关性的马尔可夫链蒙特卡洛（Markov Chain Monte Carlo）数据的统计行为，与分箱和刀切估计量随分箱大小增加时的行为联系起来。您的任务是从马尔可夫链蒙特卡洛和自相关的基本原理出发，实现一个科学上合理的、模拟欧几里得两点关联函数的合成数据生成器，然后为有效质量构建分箱加刀切法的估计流程。随后，您必须在不同的自相关情景下，量化估计的刀切误差是否会随着分箱大小的函数而饱和。\n\n您必须从以下基本依据出发，并用其来证明您的设计和推理的合理性：\n\n- 马尔可夫链蒙特卡洛生成一个按时间排序的样本序列，对于在蒙特卡洛时间间隔 $k$ 测量的可观测量 $\\mathcal{O}$，其自相关函数为 $C_{\\mathcal{O}}(k)$，积分自相关时间为 $\\tau_{\\text{int}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} \\rho_{\\mathcal{O}}(k)$，其中 $\\rho_{\\mathcal{O}}(k) = C_{\\mathcal{O}}(k)/C_{\\mathcal{O}}(0)$。\n- 对于相关样本，在样本量 $N$ 很大的极限下，样本均值的方差满足 $\\sigma^2_{\\bar{\\mathcal{O}}} \\approx \\frac{\\sigma^2_{\\mathcal{O}}}{N} \\, 2 \\, \\tau_{\\text{int}}$。\n- 将相邻样本分组到大小为 $B$ 的非重叠分箱中，可以减少分箱均值之间的自相关性。如果 $B \\gg \\tau_{\\text{int}}$，则分箱均值近似独立同分布。\n- 将删一分箱刀切法（delete-one-bin jackknife）应用于从分箱平均数据计算出的标量估计量 $\\theta$，即使对于非线性的 $\\theta$，也能为其方差提供一个一致估计量。\n\n您必须实现以下组件：\n\n1) 在两个相邻欧几里得时间上的欧几里得两点关联函数的合成模型。对于一个固定的时间片 $t_0$，假设一个具有依赖于组态的振幅的单态关联函数模型。设真实关联函数为 $G(t) = A \\, e^{-m t}$，其质量为 $m$，振幅 $A$ 为正，且因规范噪音而在不同组态间涨落。在蒙特卡洛组态索引 $n$ 处测得的关联函数为：\n$$\nC_t^{(n)} = A^{(n)} e^{-m t_0} \\, \\epsilon_t^{(n)}, \\qquad C_{t+1}^{(n)} = A^{(n)} e^{-m (t_0+1)} \\, \\epsilon_{t+1}^{(n)},\n$$\n其中 $A^{(n)}$ 是一个沿 $n$ 变化的、正的、相关的随机过程，而 $\\epsilon_t^{(n)}$、$\\epsilon_{t+1}^{(n)}$ 是小的、独立的、均值为1的乘性噪音。将 $\\ln A^{(n)}$ 建模为一阶自回归过程（AR(1)），系数为 $\\phi$，即：\n$$\nX_n = \\phi X_{n-1} + \\eta_n, \\quad \\eta_n \\sim \\mathcal{N}(0, \\sigma_\\eta^2), \\quad A^{(n)} = A_0 \\, e^{s X_n},\n$$\n使用稳态归一化 $\\sigma_\\eta^2 = 1 - \\phi^2$，使得当 $|\\phi|  1$ 时 $\\operatorname{Var}(X_n) = 1$。乘性测量噪音满足 $\\epsilon \\sim 1 + \\mathcal{N}(0, \\sigma_{\\text{noise}}^2)$，其中 $\\sigma_{\\text{noise}}$ 很小，并且必须强制保证关联函数严格为正。\n\n2) $t_0$ 处的有效质量的非线性估计量：\n$$\nm_{\\text{eff}}(t_0) = \\ln \\left( \\frac{\\langle C_t \\rangle}{\\langle C_{t+1} \\rangle} \\right),\n$$\n其中 $\\langle \\cdot \\rangle$ 表示对所有组态的系综平均。由于涉及到比值和对数，这是数据的一个非线性函数。\n\n3) 分箱和删一分箱刀切法方差估计。将按时间排序的组态划分为 $N_{\\text{bin}}$ 个大小相等、不重叠的连续分箱，每个分箱大小为 $B$。令 $\\widehat{m}_{\\text{eff}}^{(-i)}$ 为使用除第 $i$ 个分箱之外的所有分箱计算出的有效质量估计量（删一分箱刀切法复制样本）。使用这些复制样本来构建在分箱大小为 $B$ 时 $m_{\\text{eff}}(t_0)$ 的标准误差的刀切估计。您必须确保只有在分箱数至少为8（即 $N_{\\text{bin}} \\ge 8$）的情况下，才使用该分箱大小来计算刀切误差。\n\n4) 饱和检测标准。考虑一个分箱大小的几何序列 $B \\in \\{ 1, 2, 4, \\dots \\}$，其最大值 $B$ 须保证至少有8个分箱。令 $\\sigma(B)$ 表示在分箱大小为 $B$ 时的刀切标准误差。将在两个最大的允许分箱大小 $B_{K-1}$ 和 $B_K$ 处的相对变化定义为：\n$$\nr = \\frac{|\\sigma(B_K) - \\sigma(B_{K-1})|}{\\max(\\sigma(B_K), \\varepsilon)},\n$$\n其中 $\\varepsilon$ 是一个小的正则化项，以避免除以零。如果对于给定的容差 $\\delta$ 有 $r  \\delta$，则声明误差已饱和。\n\n您的程序必须生成合成数据，应用分箱加刀切法流程，并对以下每个测试用例评估饱和标准。在所有情况下，使用相同的指数质量和噪音参数，仅改变序列长度和 AR(1) 系数：\n\n- 测试用例 1（理想情况，中等自相关）：seed $= 12345$, $N = 4096$, $\\phi = 0.8$, $A_0 = 1.0$, $s = 0.2$, $m = 0.5$, $t_0 = 5$, $\\sigma_{\\text{noise}} = 0.02$, 检测容差 $\\delta = 0.07$。\n- 测试用例 2（几乎不相关）：seed $= 54321$, $N = 4096$, $\\phi = 0.0$, $A_0 = 1.0$, $s = 0.2$, $m = 0.5$, $t_0 = 5$, $\\sigma_{\\text{noise}} = 0.02$, 检测容差 $\\delta = 0.07$。\n- 测试用例 3（强自相关，在可用分箱内未饱和）：seed $= 999$, $N = 1024$, $\\phi = 0.995$, $A_0 = 1.0$, $s = 0.2$, $m = 0.5$, $t_0 = 5$, $\\sigma_{\\text{noise}} = 0.02$, 检测容差 $\\delta = 0.07$。\n- 测试用例 4（样本较少但分箱数足够的边界条件）：seed $= 2024$, $N = 256$, $\\phi = 0.9$, $A_0 = 1.0$, $s = 0.2$, $m = 0.5$, $t_0 = 5$, $\\sigma_{\\text{noise}} = 0.02$, 检测容差 $\\delta = 0.07$。\n\n您的程序必须：\n\n- 为每个测试用例，使用指定的种子，完全按照上述描述模拟数据。\n- 枚举分箱大小 $B \\in \\{ 1, 2, 4, \\dots \\}$，使得完整分箱的数量 $N_{\\text{bin}} = \\lfloor N / B \\rfloor$ 满足 $N_{\\text{bin}} \\ge 8$。丢弃末尾不足以填满一个完整分箱的任何剩余组态。\n- 对每个允许的 $B$ 计算刀切标准误差 $\\sigma(B)$。\n- 根据上述容差为 $\\delta$ 的标准，使用 $\\varepsilon = 10^{-16}$，判断在最大分箱大小时误差是否已饱和。\n- 作为唯一输出，生成单行内容，包含一个布尔值列表，按顺序 $[1,2,3,4]$ 对应四个测试用例，如果检测到饱和，则布尔值为 $true$，否则为 $false$。使用确切的字符串表示 $True$ 和 $False$。\n\n最终输出不涉及物理单位，必须是无单位的布尔值。不会出现角度。不会出现百分比。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$[result_1,result_2,result_3,result_4]$）。",
            "solution": "我们通过将马尔可夫链蒙特卡洛的统计物理学与一个用于格点量子色动力学相关非线性可观测量分箱和刀切估计的具体算法构造相结合来展开。\n\n首先，我们确定基本的统计基础。在马尔可夫链蒙特卡洛中，序贯测量 $\\{\\mathcal{O}_n\\}_{n=1}^N$ 通常具有非零的自相关性，这由自协方差 $C_{\\mathcal{O}}(k) = \\mathbb{E}\\left[(\\mathcal{O}_n - \\mu)(\\mathcal{O}_{n+k} - \\mu)\\right]$ 来描述。归一化自相关函数为 $\\rho_{\\mathcal{O}}(k) = C_{\\mathcal{O}}(k)/C_{\\mathcal{O}}(0)$。积分自相关时间，\n$$\n\\tau_{\\text{int}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} \\rho_{\\mathcal{O}}(k),\n$$\n决定了样本均值的方差膨胀，这是一个经过充分检验的事实：对于大的 $N$，\n$$\n\\operatorname{Var}(\\bar{\\mathcal{O}}) \\approx \\frac{\\sigma^2_{\\mathcal{O}}}{N} \\, 2 \\, \\tau_{\\text{int}}.\n$$\n这表明，相关性有效地将独立样本的数量减少了大约一个因子 $2 \\tau_{\\text{int}}$。\n\n其次，我们实施分箱以减少相关性。将相邻样本分组到大小为 $B$ 的非重叠分箱中，形成 $N_{\\text{bin}} = \\lfloor N/B \\rfloor$ 个分箱平均值。如果 $B \\gg \\tau_{\\text{int}}$，分箱均值近似独立同分布。因此，从分箱均值计算出的估计量的误差将不再随 $B$ 的进一步增加而显著变化。估计误差作为 $B$ 的函数出现的这种平台期或饱和现象，是一个经验性指标，表明 $B$ 超过了相关尺度，从而得到去相关的有效样本。\n\n第三，我们定义非线性估计量，即在固定欧几里得时间 $t_0$ 的有效质量：\n$$\nm_{\\text{eff}}(t_0) = \\ln \\left( \\frac{\\langle C_t \\rangle}{\\langle C_{t+1} \\rangle} \\right),\n$$\n其中 $C_t$ 和 $C_{t+1}$ 分别表示在时间 $t_0$ 和 $t_0 + 1$ 的关联函数测量值，而 $\\langle \\cdot \\rangle$ 是系综平均。由于比值和对数的存在，该估计量是数据的非线性函数，因此需要使用尊重非线性的重采样技术来稳健地估计其不确定度。\n\n为了通过这个非线性估计量传播误差，我们采用删一分箱刀切法（delete-one-bin jackknife）。将序贯测量值划分为 $N_{\\text{bin}}$ 个大小相等、不重叠的连续分箱，每个分箱大小为 $B$。对每个分箱 $i \\in \\{1,\\dots,N_{\\text{bin}}\\}$，计算留一法估计量 $\\widehat{m}_{\\text{eff}}^{(-i)}$，其定义为使用除第 $i$ 个分箱之外的所有组态计算出的 $m_{\\text{eff}}(t_0)$ 的值。然后，根据这些复制样本围绕其均值的涨落构建 $m_{\\text{eff}}$ 方差的刀切估计。已知删一分箱刀切法能为均值的平滑非线性泛函提供一致的方差估计。在实践中，我们为每个分箱大小 $B$ 计算刀切标准误差 $\\sigma(B)$。对于小的 $B$，分箱间的残余自相关使得 $\\sigma(B)$ 的膨胀程度低于其渐近值；当 $B$ 增大以至于 $B \\gtrsim \\tau_{\\text{int}}$ 时，$\\sigma(B)$ 会增加并饱和到一个平台区，该平台区对应于考虑了相关性之后的真实误差。如果由于 $N$ 有限，$B$ 永远达不到 $\\tau_{\\text{int}}$，则可能观察不到饱和现象。\n\n为了将此推理与一个受控的环境联系起来，我们生成合成数据。我们通过一阶自回归过程 $X_n = \\phi X_{n-1} + \\eta_n$ 来模拟振幅涨落，其中 $\\eta_n \\sim \\mathcal{N}(0, \\sigma_\\eta^2)$ 且 $\\sigma_\\eta^2 = 1 - \\phi^2$，使得稳态方差为 $\\operatorname{Var}(X_n) = 1$。振幅为 $A^{(n)} = A_0 e^{s X_n}$，确保其为正值。在时间 $t_0$ 和 $t_0 + 1$ 测得的关联函数则为\n$$\nC_t^{(n)} = A^{(n)} e^{-m t_0} \\, \\epsilon_t^{(n)}, \\qquad C_{t+1}^{(n)} = A^{(n)} e^{-m (t_0 + 1)} \\, \\epsilon_{t+1}^{(n)},\n$$\n其中乘性噪音 $\\epsilon \\sim 1 + \\mathcal{N}(0, \\sigma_{\\text{noise}}^2)$。我们通过在一个极小的正数下限处进行截断来约束数据为严格正值，考虑到 $\\sigma_{\\text{noise}}$ 很小，这是一个可以忽略的修正。\n\n算法设计：\n\n- 对于每个测试用例和固定的随机种子，模拟 $N$ 个 $X_n$ 样本，从而得到 $A^{(n)}$，然后生成 $C_t^{(n)}$ 和 $C_{t+1}^{(n)}$。\n- 考虑分箱大小 $B \\in \\{ 1, 2, 4, \\dots \\}$，使得 $N_{\\text{bin}} = \\lfloor N / B \\rfloor \\ge 8$。对于每个这样的 $B$，计算在移除分箱 $i$ 后，由 $C_t$ 和 $C_{t+1}$ 的系综平均值构建的 $m_{\\text{eff}}(t_0)$ 的删一分箱刀切标准误差 $\\sigma(B)$。\n- 将两个最大的允许分箱大小 $B_{K-1}$ 和 $B_K$ 处误差的相对变化定义为 $r = \\frac{|\\sigma(B_K) - \\sigma(B_{K-1})|}{\\max(\\sigma(B_K), \\varepsilon)}$，其中 $\\varepsilon = 10^{-16}$，如果对于指定的 $\\delta$ 有 $r  \\delta$，则声明饱和。\n- 基于基本原理的预期结果是：\n  - 对于中等或弱自相关，$\\sigma(B)$ 将从 $B = 1$ 开始增加，并在达到最大 $B$ 值时进入平台期，因此应能检测到饱和。\n  - 对于几乎不相关的数据，$\\sigma(B)$ 从 $B = 1$ 开始几乎是恒定的，因此由于相对变化很小，饱和标准仍然成立。\n  - 对于具有有限 $N$ 的非常强的自相关， $B$ 可能永远无法达到 $\\tau_{\\text{int}}$ 的尺度，因此 $\\sigma(B)$ 可能在达到最大允许 $B$ 值时仍未进入平台期，此时不应检测到饱和。\n\n我们现在将此程序应用于指定的测试套件：\n\n- 测试用例 1：seed $= 12345$, $N = 4096$, $\\phi = 0.8$, $A_0 = 1.0$, $s = 0.2$, $m = 0.5$, $t_0 = 5$, $\\sigma_{\\text{noise}} = 0.02$, $\\delta = 0.07$。此处 $\\phi = 0.8$ 对应一个中等的积分自相关时间 $\\tau_{\\text{int}} \\approx \\frac{1+\\phi}{2(1-\\phi)} = \\frac{1.8}{0.4} = 4.5$。分箱大小可达 $B = 512$，预期会发生饱和，因此结果为 $True$。\n- 测试用例 2：seed $= 54321$, $N = 4096$, $\\phi = 0.0$ 得到 $\\tau_{\\text{int}} \\approx 0.5$；刀切误差在所有 $B$ 上几乎是恒定的，饱和标准得到满足，结果为 $True$。\n- 测试用例 3：seed $= 999$, $N = 1024$, $\\phi = 0.995$ 给出 $\\tau_{\\text{int}} \\approx \\frac{1+0.995}{2(1-0.995)} \\approx \\frac{1.995}{0.01} \\approx 199.5$。最大允许分箱为 $B = 128$（此时 $N_{\\text{bin}} = 8$），这小于 $\\tau_{\\text{int}}$。因此，不太可能饱和，结果应为 $False$。\n- 测试用例 4：seed $= 2024$, $N = 256$, $\\phi = 0.9$ 给出 $\\tau_{\\text{int}} \\approx \\frac{1+0.9}{2(1-0.9)} = \\frac{1.9}{0.2} = 9.5$。最大允许分箱为 $B = 32$（此时 $N_{\\text{bin}} = 8$），这超过了 $\\tau_{\\text{int}}$，因此应能观察到饱和，结果为 $True$。\n\n程序按顺序收集四个布尔值，并打印单行 $[b_1,b_2,b_3,b_4]$，其中 $b_i \\in \\{\\text{True}, \\text{False}\\}$。这表明，刀切误差随分箱大小增加而饱和是去相关的一个经验性诊断方法：当 $B$ 远大于自相关尺度时，分箱均值实际上是独立的，刀切误差趋于稳定；而如果 $B$ 相对于相关长度仍然太小，估计误差会持续变化，并且检测不到饱和。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef ar1_series(N: int, phi: float, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generate an AR(1) series X_n = phi * X_{n-1} + eta_n with stationary Var(X)=1.\n    eta_n ~ N(0, 1 - phi^2). Start from stationary distribution.\n    \"\"\"\n    sigma_eta = np.sqrt(max(0.0, 1.0 - phi * phi))\n    X = np.empty(N)\n    # Start at stationary distribution\n    X[0] = rng.normal(0.0, 1.0)\n    for n in range(1, N):\n        X[n] = phi * X[n - 1] + rng.normal(0.0, sigma_eta)\n    return X\n\ndef simulate_correlators(seed: int, N: int, phi: float,\n                         A0: float, s_logamp: float,\n                         m: float, t0: int, sigma_noise: float) - tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Simulate C_t and C_{t+1} arrays for a single-state correlator with\n    log-normal amplitude fluctuations following an AR(1) process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = ar1_series(N, phi, rng)\n    A = A0 * np.exp(s_logamp * X)  # positive amplitudes\n    base_t = np.exp(-m * t0)\n    base_tp1 = np.exp(-m * (t0 + 1))\n    # Multiplicative noise around 1 with small sigma\n    eps_t = 1.0 + sigma_noise * rng.standard_normal(N)\n    eps_tp1 = 1.0 + sigma_noise * rng.standard_normal(N)\n    Ct = A * base_t * eps_t\n    Ctp1 = A * base_tp1 * eps_tp1\n    # Enforce strict positivity\n    Ct = np.clip(Ct, 1e-12, None)\n    Ctp1 = np.clip(Ctp1, 1e-12, None)\n    return Ct, Ctp1\n\ndef jackknife_error_effective_mass(Ct: np.ndarray, Ctp1: np.ndarray, bin_size: int) - float:\n    \"\"\"\n    Compute the delete-one-bin jackknife standard error for the nonlinear estimator:\n    m_eff = log( mean(Ct) / mean(Ctp1) ), using contiguous non-overlapping bins of size bin_size.\n    Requires at least 2 bins; caller ensures =8 for robustness.\n    \"\"\"\n    N = len(Ct)\n    n_bins = N // bin_size\n    if n_bins  2:\n        return np.nan\n    keep = n_bins * bin_size\n    Ct_kept = Ct[:keep]\n    Ctp1_kept = Ctp1[:keep]\n    # Reshape into bins\n    Ct_bins = Ct_kept.reshape(n_bins, bin_size)\n    Ctp1_bins = Ctp1_kept.reshape(n_bins, bin_size)\n    # Precompute total sums\n    total_Ct = Ct_kept.sum()\n    total_Ctp1 = Ctp1_kept.sum()\n    total_count = keep\n    # Bin sums\n    bin_sum_Ct = Ct_bins.sum(axis=1)\n    bin_sum_Ctp1 = Ctp1_bins.sum(axis=1)\n    # Jackknife replicates\n    jk_vals = np.empty(n_bins)\n    count_excl = total_count - bin_size\n    for i in range(n_bins):\n        sum_excl_Ct = total_Ct - bin_sum_Ct[i]\n        sum_excl_Ctp1 = total_Ctp1 - bin_sum_Ctp1[i]\n        mean_excl_Ct = sum_excl_Ct / count_excl\n        mean_excl_Ctp1 = sum_excl_Ctp1 / count_excl\n        # Safety: avoid division by zero (should not occur due to positivity)\n        mean_excl_Ct = max(mean_excl_Ct, 1e-300)\n        mean_excl_Ctp1 = max(mean_excl_Ctp1, 1e-300)\n        jk_vals[i] = np.log(mean_excl_Ct / mean_excl_Ctp1)\n    jk_mean = jk_vals.mean()\n    # Standard jackknife variance: (n_bins - 1) * mean((theta_i - mean(theta_i))^2)\n    var_jk = (n_bins - 1) * np.mean((jk_vals - jk_mean) ** 2)\n    return float(np.sqrt(max(var_jk, 0.0)))\n\ndef bin_sizes_geometric(N: int, min_bins: int = 8) - list[int]:\n    \"\"\"\n    Generate powers-of-two bin sizes B = 1,2,4,... such that floor(N/B) = min_bins.\n    \"\"\"\n    sizes = []\n    B = 1\n    while N // B = min_bins:\n        sizes.append(B)\n        B *= 2\n    return sizes\n\ndef detect_saturation(Ct: np.ndarray, Ctp1: np.ndarray, delta_tol: float) - bool:\n    \"\"\"\n    Compute jackknife errors over admissible bin sizes and detect saturation using\n    the relative change criterion at the two largest bin sizes.\n    \"\"\"\n    N = len(Ct)\n    B_list = bin_sizes_geometric(N, min_bins=8)\n    if len(B_list)  2:\n        return False\n    errors = []\n    for B in B_list:\n        err = jackknife_error_effective_mass(Ct, Ctp1, B)\n        errors.append(err)\n    # Relative change at the end\n    eps = 1e-16\n    rel = abs(errors[-1] - errors[-2]) / max(errors[-1], eps)\n    return rel  delta_tol\n\ndef run_case(seed: int, N: int, phi: float,\n             A0: float, s: float,\n             m: float, t0: int, sigma_noise: float,\n             delta_tol: float) - bool:\n    Ct, Ctp1 = simulate_correlators(seed, N, phi, A0, s, m, t0, sigma_noise)\n    return detect_saturation(Ct, Ctp1, delta_tol)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (seed, N, phi, A0, s, m, t0, sigma_noise, delta_tol)\n    test_cases = [\n        (12345, 4096, 0.8,   1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 1: moderate autocorrelation\n        (54321, 4096, 0.0,   1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 2: nearly uncorrelated\n        (999,   1024, 0.995, 1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 3: strong autocorr, no saturation\n        (2024,   256, 0.9,   1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 4: boundary, should saturate\n    ]\n\n    results = []\n    for case in test_cases:\n        seed, N, phi, A0, s, m, t0, sigma_noise, delta_tol = case\n        res = run_case(seed, N, phi, A0, s, m, t0, sigma_noise, delta_tol)\n        results.append(res)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}