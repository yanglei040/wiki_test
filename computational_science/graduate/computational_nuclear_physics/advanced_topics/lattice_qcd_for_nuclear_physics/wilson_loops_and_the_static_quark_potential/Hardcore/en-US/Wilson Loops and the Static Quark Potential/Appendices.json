{
    "hands_on_practices": [
        {
            "introduction": "The Wilson loop is the cornerstone observable for studying the static quark-antiquark potential and confinement in lattice gauge theory. This exercise guides you through the fundamental task of numerically calculating the expectation value of a rectangular Wilson loop, $\\langle W(R,T) \\rangle$, from first principles. By implementing the path-ordered product of gauge links and applying symmetry averaging techniques like spatial and temporal translations, you will develop the core computational skills needed to measure gauge-invariant correlators on the lattice .",
            "id": "3611747",
            "problem": "Consider a four-dimensional Euclidean lattice formulation of Quantum Chromodynamics (QCD) with gauge group Special Unitary group of degree three ($SU(3)$). A gauge configuration assigns to each oriented link from site $x$ in direction $\\mu \\in \\{0,1,2,3\\}$ a matrix $U_{\\mu}(x) \\in SU(3)$ that represents the parallel transporter along that link. The temporal direction is $\\mu=3$ and the spatial directions are $\\mu \\in \\{0,1,2\\}$ corresponding to the $x$, $y$, and $z$ coordinate axes. The Wilson loop $W(R,T)$ associated with a rectangle of spatial extent $R$ and temporal extent $T$ in a fixed spatial direction is defined from the path-ordered product of link variables around the rectangular contour in the corresponding space-time plane. The trace over color indices is normalized by the number of colors $N_c=3$, and the physically relevant observable is the real part of that normalized trace. Periodic boundary conditions are imposed in all directions.\n\nStarting from fundamental lattice gauge theory definitions, design and implement an algorithm that, for a given ensemble of gauge configurations, computes the ensemble-averaged Wilson loop $W(R,T)$ with variance reduction achieved by averaging over:\n- all spatial translations of the loop’s spatial corner,\n- all temporal origins,\n- all cubic rotations restricted to selecting the spatial side along each of the three Cartesian axes ($x$, $y$, $z$).\n\nYour algorithm must implement the closed-loop product explicitly using forward steps along the chosen spatial direction for $R$ links, forward steps along the temporal direction for $T$ links, backward steps along the chosen spatial direction for $R$ links (which must be implemented as multiplication by the Hermitian conjugate $U_{\\mu}^{\\dagger}$ at the appropriately shifted site), and backward steps along the temporal direction for $T$ links (also implemented via $U_{\\mu}^{\\dagger}$). All site indexing should be performed with periodic boundary conditions. The final per-loop observable must be computed as $\\frac{1}{N_c}\\operatorname{Re}\\operatorname{Tr}(\\mathcal{U}_{\\square})$, where $\\mathcal{U}_{\\square}$ is the $SU(3)$ matrix resulting from the ordered product around the rectangle.\n\nFundamental base assumptions you must use:\n- $U_{\\mu}(x)$ are elements of $SU(3)$, so $U_{\\mu}^{\\dagger}(x)=U_{\\mu}^{-1}(x)$ and $\\det U_{\\mu}(x)=1$.\n- The Wilson loop observable at fixed $R$ and $T$ is invariant under spatial translations, temporal translations, and cubic rotations of the spatial axes; hence averaging over these symmetries reduces statistical errors without biasing the estimator.\n- Periodic boundary conditions imply that coordinate updates are done modulo the lattice size in each dimension.\n\nYour program must construct three deterministic ensembles and evaluate the observable for specified $(R,T)$ values. Use the following test suite, with each ensemble defined by its explicit link assignment rule and lattice dimensions:\n\n- Test case $1$ (baseline identity field):\n  - Lattice dimensions: $L_x=L_y=L_z=L_t=4$ (that is, $4\\times 4 \\times 4 \\times 4$).\n  - Ensemble: a single configuration with $U_{\\mu}(x)=\\mathbb{I}_{3}$ for all $x$ and all $\\mu$.\n  - Parameters: $R=2$, $T=3$.\n\n- Test case $2$ (single-axis structured temporal links):\n  - Lattice dimensions: $L_x=8$, $L_y=8$, $L_z=8$, $L_t=6$.\n  - Ensemble: a single configuration with $U_{3}(x)=\\mathrm{diag}\\left(e^{i\\alpha x}, e^{-i\\alpha x}, 1\\right)$ for all sites $x$ with spatial coordinate $x$ along the $x$-axis, and $U_{\\mu}(x)=\\mathbb{I}_{3}$ for $\\mu \\in \\{0,1,2\\}$. Here $\\alpha=\\frac{2\\pi}{L_x}$ and the integer $x$ coordinate used in the phase is understood modulo $L_x$.\n  - Parameters: $R=3$, $T=2$.\n\n- Test case $3$ (symmetric sum-of-coordinates temporal links):\n  - Lattice dimensions: $L_x=6$, $L_y=6$, $L_z=6$, $L_t=4$.\n  - Ensemble: a single configuration with $U_{3}(x)=\\mathrm{diag}\\left(e^{i\\alpha s}, e^{-i\\alpha s}, 1\\right)$ where $s=(x+y+z)\\bmod L_x$, and $U_{\\mu}(x)=\\mathbb{I}_{3}$ for $\\mu \\in \\{0,1,2\\}$. Here $\\alpha=\\frac{2\\pi}{L_x}$ and $x$, $y$, $z$ are the spatial coordinates.\n  - Parameters: $R=1$, $T=2$.\n\n- Test case $4$ (degenerate spatial extent):\n  - Lattice dimensions: $L_x=L_y=L_z=L_t=4$ (that is, $4\\times 4 \\times 4 \\times 4$).\n  - Ensemble: a single configuration with $U_{\\mu}(x)=\\mathbb{I}_{3}$ for all $x$ and all $\\mu$.\n  - Parameters: $R=0$, $T=4$.\n\nFor each test case, your algorithm must:\n- iterate over all spatial starting sites $(x,y,z)$ and all time origins $t$,\n- iterate over the three spatial directions,\n- construct the closed-loop product as described,\n- compute the normalized real trace at each instance,\n- average over all such instances and over all configurations in the ensemble to obtain a single float $W(R,T)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[w_1,w_2,w_3,w_4]$), where $w_k$ is the computed $W(R,T)$ for test case $k$ expressed as a decimal in unitless form.",
            "solution": "The user-provided problem statement has been meticulously reviewed and validated against the required criteria. It is a well-posed, scientifically grounded problem from computational lattice gauge theory. The definitions, parameters, and objectives are specified with sufficient clarity and rigor to permit a unique, verifiable solution. We may therefore proceed with the derivation and implementation.\n\n### Theoretical Framework\n\nLattice Quantum Chromodynamics (QCD) is a non-perturbative approach to solving QCD by discretizing spacetime into a four-dimensional hypercubic lattice. In this formulation, quarks are defined at the lattice sites, while gluons, the mediators of the strong force, are represented by link variables.\n\nA link variable $U_{\\mu}(x)$ is an element of the gauge group, in this case $SU(3)$, that represents the parallel transport of a color vector from lattice site $x$ to the adjacent site $x+\\hat{\\mu}$ in the direction $\\mu$. It is related to the continuum gauge field $A_\\mu$ by $U_{\\mu}(x) \\approx \\exp(iga A_{\\mu}(x))$, where $g$ is the strong coupling constant and $a$ is the lattice spacing.\n\nThe Wilson loop, $W(R,T)$, is a fundamental gauge-invariant observable. It is constructed from the path-ordered product of link variables along a closed rectangular loop $\\mathcal{C}$ of spatial extent $R$ and temporal extent $T$. The loop matrix $\\mathcal{U}_{\\square}$ is given by:\n$$\n\\mathcal{U}_{\\square} = P \\prod_{l \\in \\mathcal{C}} U_l\n$$\nwhere $P$ indicates path ordering, and $U_l$ are the link variables along the loop. The Wilson loop observable is the real part of the normalized trace of this matrix, averaged over all gauge configurations in an ensemble $\\langle \\dots \\rangle$:\n$$\nW(R,T) = \\left\\langle \\frac{1}{N_c} \\operatorname{Re} \\operatorname{Tr}(\\mathcal{U}_{\\square}) \\right\\rangle\n$$\nFor large temporal extent $T$, the Wilson loop expectation value is related to the static potential $V(R)$ between a quark and an antiquark separated by a spatial distance $R$: $\\langle W(R,T) \\rangle \\propto e^{-V(R)T}$.\n\n### Algorithmic Design\n\nThe core of the algorithm is to compute the average Wilson loop value $\\langle W(R,T) \\rangle$ for a given deterministic ensemble. To reduce statistical variance (though the provided ensembles are deterministic, the principle is demonstrated), we average the observable over all possible translations and discrete rotations, as these are symmetries of the underlying theory.\n\nThe algorithm proceeds as follows:\n1.  **Symmetry Averaging:** A set of nested loops iterates over all possible starting positions of the Wilson loop and its spatial orientation.\n    - An outer loop iterates through the three spatial directions, $\\mu \\in \\{0,1,2\\}$, which define the plane of the loop (e.g., the $x-t$ plane, $y-t$ plane, or $z-t$ plane).\n    - Inner loops iterate over all possible starting sites $(x_0, x_1, x_2, x_3)$ on the $L_x \\times L_y \\times L_z \\times L_t$ lattice.\n\n2.  **Loop Construction:** For each specific loop instance (defined by its starting site and orientation), the $SU(3)$ matrix $\\mathcal{U}_{\\square}$ is constructed by multiplying the link matrices along the specified path. The path consists of four segments:\n    1.  $R$ steps forward in the chosen spatial direction, $s_{\\text{dir}}$.\n    2.  $T$ steps forward in the temporal direction, $t_{\\text{dir}}=3$.\n    3.  $R$ steps backward in the spatial direction. A backward step from site $x$ to $x-\\hat{\\mu}$ is accomplished by multiplying with the Hermitian conjugate of the forward link, $U_{\\mu}^{\\dagger}(x-\\hat{\\mu})$.\n    4.  $T$ steps backward in the temporal direction.\n    \n    The path-ordered product is accumulated by sequential left-multiplication, starting from the identity matrix $\\mathbb{I}_3$. Let $U_i$ be the link matrix for the $i$-th step of the path. The final loop matrix after $N=2R+2T$ steps is $\\mathcal{U}_{\\square} = U_N \\dots U_2 U_1$. All coordinate calculations incorporate periodic boundary conditions, implemented via the modulo operator.\n\n3.  **Observable Calculation:** For each computed $\\mathcal{U}_{\\square}$, the observable $\\frac{1}{N_c} \\operatorname{Re}\\operatorname{Tr}(\\mathcal{U}_{\\square})$ is calculated, with $N_c=3$.\n\n4.  **Averaging:** The values of the observable from all loop instances are summed and then divided by the total number of instances to obtain the final average value.\n\n### Analytical Verification of Test Cases\n\nThe provided test cases use deterministic ensembles, allowing for analytical calculation to verify the algorithm's correctness.\n\n-   **Test Case 1 ($U_{\\mu}(x)=\\mathbb{I}_3, R=2, T=3$):** The product of any number of identity matrices is the identity matrix, so $\\mathcal{U}_{\\square} = \\mathbb{I}_3$. The trace is $\\operatorname{Tr}(\\mathbb{I}_3) = 3$. The observable is $\\frac{1}{3}\\operatorname{Re}(3) = 1.0$. This holds for all loops, so the average is $1.0$.\n\n-   **Test Case 4 ($U_{\\mu}(x)=\\mathbb{I}_3, R=0, T=4$):** This is a degenerate loop with zero spatial extent. The path consists of moving $T=4$ steps forward in time and $T=4$ steps backward. Since all links are $\\mathbb{I}_3$, the loop product is again $\\mathbb{I}_3$, and the final result is $1.0$.\n\n-   **Test Case 2 ($L_x=8, R=3, T=2$):** Spatial links are $\\mathbb{I}_3$. Temporal links $U_3$ depend on the $x$-coordinate $c_0$.\n    -   If the loop is in the $y-t$ or $z-t$ plane ($s_{\\text{dir}}=1$ or $2$), the $x$-coordinate is constant throughout the path. The forward temporal product $(U_3(c_0))^T$ is exactly cancelled by the backward temporal product $(U_3(c_0)^\\dagger)^T$, yielding $\\mathcal{U}_{\\square} = \\mathbb{I}_3$ and an observable of $1.0$.\n    -   If the loop is in the $x-t$ plane ($s_{\\text{dir}}=0$), the forward temporal path is at $c_0'=(c_0+R)\\%L_x$ and the backward temporal path is at $c_0$. The loop matrix is $\\mathcal{U}_{\\square} = \\text{diag}(e^{i\\alpha T (c_0' - c_0)}, e^{-i\\alpha T (c_0' - c_0)}, 1)$, where $\\alpha T = (\\frac{2\\pi}{8}) \\cdot 2 = \\frac{\\pi}{2}$. The phase argument $\\alpha T (c_0' - c_0)$ evaluates to $\\frac{3\\pi}{2}$ or $-\\frac{5\\pi}{2}$ depending on $c_0$. In both cases, the cosine is $0$. The observable is $\\frac{1}{3}(2\\cos(\\dots)+1) = \\frac{1}{3}$.\n    -   Averaging over the three orientations gives $\\frac{1.0 + 1.0 + 1/3}{3} = \\frac{7/3}{3} = 7/9$.\n\n-   **Test Case 3 ($L_x=6, R=1, T=2$):** Spatial links are $\\mathbb{I}_3$. Temporal link $U_3$ depends on $s=(c_0+c_1+c_2)\\%L_x$. For any spatial orientation, moving along that direction by $R=1$ changes $s$ by $\\Delta s = 1$ or $\\Delta s=1-L_x=-5$. The phase difference in the loop matrix is $\\alpha T \\Delta s = (\\frac{2\\pi}{6}) \\cdot 2 \\cdot \\Delta s = \\frac{2\\pi}{3}\\Delta s$. For $\\Delta s=1$, the phase is $2\\pi/3$. For $\\Delta s=-5$, the phase is $-10\\pi/3 \\equiv 2\\pi/3 \\pmod{2\\pi}$. The cosine is $\\cos(2\\pi/3)=-1/2$. The observable is always $\\frac{1}{3}(2(-\\frac{1}{2})+1) = 0.0$. Thus, the average is $0.0$.\n\nThe implementation will directly reflect this logic.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem as specified.\n    It iterates through the test cases, computes the averaged Wilson loop for each,\n    and prints the results in the required format.\n    \"\"\"\n\n    def get_link_matrix(case_id, params, coords, mu):\n        \"\"\"\n        Generates the SU(3) link matrix U_mu(x) on-the-fly.\n        \n        Args:\n            case_id (int): The test case number (1-4).\n            params (dict): A dictionary containing case-specific parameters.\n            coords (tuple): A 4-tuple of integer coordinates (x, y, z, t).\n            mu (int): The direction index (0 for x, 1 for y, 2 for z, 3 for t).\n\n        Returns:\n            numpy.ndarray: The 3x3 SU(3) link matrix.\n        \"\"\"\n        if case_id in [1, 4]:\n            return np.identity(3, dtype=np.complex128)\n        \n        # For cases 2 and 3, spatial links are identity matrices.\n        if mu in [0, 1, 2]:\n            return np.identity(3, dtype=np.complex128)\n\n        # Temporal links (mu=3) for cases 2 and 3.\n        if case_id == 2:\n            x_coord = coords[0]\n            alpha = params['alpha']\n            phase = alpha * x_coord\n            return np.diag([np.exp(1j * phase), np.exp(-1j * phase), 1.0 + 0.0j])\n        \n        elif case_id == 3:\n            x, y, z = coords[0], coords[1], coords[2]\n            L_x = params['L'][0]\n            s = (x + y + z) % L_x\n            alpha = params['alpha']\n            phase = alpha * s\n            return np.diag([np.exp(1j * phase), np.exp(-1j * phase), 1.0 + 0.0j])\n        \n        # Fallback, should not be reached with valid inputs.\n        return np.identity(3, dtype=np.complex128)\n\n    def compute_average_wilson_loop(case_id, L, R, T):\n        \"\"\"\n        Computes the ensemble-averaged Wilson loop for a given deterministic ensemble.\n        \n        The averaging is performed over all spatial and temporal translations of the loop,\n        and over the three possible spatial orientations of the loop plane.\n        \n        Args:\n            case_id (int): The test case number.\n            L (tuple): Lattice dimensions (Lx, Ly, Lz, Lt).\n            R (int): Spatial extent of the Wilson loop.\n            T (int): Temporal extent of the Wilson loop.\n\n        Returns:\n            float: The computed average Wilson loop value W(R, T).\n        \"\"\"\n        params = {'L': L}\n        if case_id in [2, 3]:\n            params['alpha'] = 2 * np.pi / L[0]\n            \n        Nc = 3.0\n        total_observable_sum = 0.0\n        total_loop_count = 0\n\n        L_x, L_y, L_z, L_t = L\n        \n        # 1. Average over cubic rotations (orienting the spatial side of the loop)\n        for s_dir in range(3):\n            # 2. Average over all temporal origins\n            for t_start in range(L_t):\n                # 3. Average over all spatial origins\n                for z_start in range(L_z):\n                    for y_start in range(L_y):\n                        for x_start in range(L_x):\n                            start_coords = [x_start, y_start, z_start, t_start]\n                            current_coords = list(start_coords)\n                            \n                            loop_product = np.identity(3, dtype=np.complex128)\n\n                            # Path 1: Forward in spatial direction `s_dir` for R steps\n                            for _ in range(R):\n                                link = get_link_matrix(case_id, params, tuple(current_coords), s_dir)\n                                loop_product = link @ loop_product\n                                current_coords[s_dir] = (current_coords[s_dir] + 1) % L[s_dir]\n\n                            # Path 2: Forward in temporal direction `t_dir=3` for T steps\n                            t_dir = 3\n                            for _ in range(T):\n                                link = get_link_matrix(case_id, params, tuple(current_coords), t_dir)\n                                loop_product = link @ loop_product\n                                current_coords[t_dir] = (current_coords[t_dir] + 1) % L[t_dir]\n\n                            # Path 3: Backward in spatial direction `s_dir` for R steps\n                            for _ in range(R):\n                                current_coords[s_dir] = (current_coords[s_dir] - 1 + L[s_dir]) % L[s_dir]\n                                link = get_link_matrix(case_id, params, tuple(current_coords), s_dir)\n                                link_dagger = link.conj().T\n                                loop_product = link_dagger @ loop_product\n\n                            # Path 4: Backward in temporal direction `t_dir=3` for T steps\n                            for _ in range(T):\n                                current_coords[t_dir] = (current_coords[t_dir] - 1 + L[t_dir]) % L[t_dir]\n                                link = get_link_matrix(case_id, params, tuple(current_coords), t_dir)\n                                link_dagger = link.conj().T\n                                loop_product = link_dagger @ loop_product\n\n                            observable = (1.0 / Nc) * np.trace(loop_product).real\n                            total_observable_sum += observable\n                            total_loop_count += 1\n        \n        if total_loop_count == 0:\n            # This case occurs if the lattice volume is zero, not expected here.\n            return 0.0\n        \n        return total_observable_sum / total_loop_count\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'case_id': 1, 'L': (4, 4, 4, 4), 'R': 2, 'T': 3},\n        {'case_id': 2, 'L': (8, 8, 8, 6), 'R': 3, 'T': 2},\n        {'case_id': 3, 'L': (6, 6, 6, 4), 'R': 1, 'T': 2},\n        {'case_id': 4, 'L': (4, 4, 4, 4), 'R': 0, 'T': 4},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_average_wilson_loop(case['case_id'], case['L'], case['R'], case['T'])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A key challenge in extracting the static potential $V(R)$ from Wilson loops is the contamination from higher-energy excited states, which can obscure the ground-state signal at short time separations. The variational method provides a powerful and systematic way to overcome this by using a basis of operators to diagonalize the transfer matrix. This practice  demonstrates how to construct and solve the resulting Generalized Eigenvalue Problem (GEVP) to isolate the ground state with high precision, a state-of-the-art technique in modern lattice calculations.",
            "id": "3611706",
            "problem": "You are to design and implement a complete program that constructs and solves a variational problem for a set of differently smeared spatial line operators in the Wilson loop $W(R,T)$ to isolate the static quark potential $V_0(R)$ in lattice units. The problem must be framed from first principles and solved through a generalized eigenvalue approach derived from the minimization of a suitable Rayleigh quotient under the transfer matrix interpretation of Euclidean time evolution. The underlying physics context is Lattice Quantum Chromodynamics (LQCD), but the problem is fully specified in mathematical terms that are universally implementable.\n\nBegin from the following fundamental base:\n- The Wilson loop $W(R,T)$ probes the interaction of a static quark-antiquark pair separated by spatial distance $R$ over Euclidean time extent $T$.\n- The transfer matrix formalism implies that Euclidean correlators admit a spectral decomposition in terms of energy eigenstates.\n- For a basis of $N$ independent operators $\\{\\mathcal{O}_i\\}$ constructed from differently smeared spatial lines of the Wilson loop at separation $R$, the correlation matrix at Euclidean time $T$ is a real, symmetric, positive-definite matrix whose elements encode the overlap of the operators with energy eigenstates and their Euclidean time propagation.\n\nUsing these principles, proceed as follows:\n1. Construct a model correlation matrix $C_{ij}(T)$ for a chosen operator basis, expressed through a spectral representation with a finite number of energy eigenstates and fixed overlaps. Concretely, let there be $M$ energy eigenstates at separation $R$ with energies $E_n(R)$ in lattice units (dimensionless), and let the overlaps of the operator $\\mathcal{O}_i$ onto state $n$ be $Z_i^{(n)}$. The correlation matrix elements are defined via a sum over energy eigenstates with Euclidean time dependence. Your program must, for each Euclidean time $T$, construct the matrix $C(T)$ from the given $E_n$ and $Z_i^{(n)}$.\n2. Starting from the variational principle under Euclidean time evolution, derive the generalized eigenvalue problem required to optimally isolate the ground state at fixed $R$. You must set up and solve the generalized eigenvalue problem between correlation matrices at two Euclidean times $T$ and $T_0$ with the same operator basis, and determine the principal generalized eigenvalue $\\lambda_0(T,T_0)$.\n3. Use the principal generalized eigenvalue to estimate the static potential $V_0(R)$ in lattice units via a ratio at successive times. Specifically, for lattice spacing set to $a = 1$ (dimensionless lattice units), define the estimator\n$$\nV_0^{\\text{eff}}(R;T_{\\text{eval}},T_0) \\equiv -\\ln\\left(\\frac{\\lambda_0(T_{\\text{eval}},T_0)}{\\lambda_0(T_{\\text{eval}}-1,T_0)}\\right).\n$$\nYour program must compute this estimator for each provided test case.\n\nAll quantities are in dimensionless lattice units. Energies must be reported as floats. No angles are involved. The final output must be a single line with a comma-separated list enclosed in square brackets. Each entry must be the value of $V_0^{\\text{eff}}(R;T_{\\text{eval}},T_0)$ rounded to six decimal places, in the order of the test cases below.\n\nTest Suite and Parameter Specification:\nFor each test case, you are provided the operator basis dimension $N$, the number of states $M$, the energies $\\{E_n\\}$, and the overlap matrix $Z$ of shape $N \\times M$, together with $T_0$ and $T_{\\text{eval}}$ (both in lattice units). Build $C(T)$ for nonnegative integer $T$ as specified in step $1$, then perform steps $2$ and $3$.\n\n- Test Case $1$ (happy path):\n  - $R = 3$\n  - $N = 3$, $M = 3$\n  - Energies: $\\{E_n\\} = \\{0.5, 0.8, 1.4\\}$\n  - Overlaps:\n    $$\n    Z = \\begin{pmatrix}\n    1.0 & 0.3 & 0.1 \\\\\n    0.9 & 0.5 & 0.2 \\\\\n    0.7 & 0.2 & 0.4\n    \\end{pmatrix}\n    $$\n  - $T_0 = 1$, $T_{\\text{eval}} = 5$\n\n- Test Case $2$ (near-degeneracy in low-lying spectrum):\n  - $R = 5$\n  - $N = 3$, $M = 3$\n  - Energies: $\\{E_n\\} = \\{0.7, 0.71, 1.3\\}$\n  - Overlaps:\n    $$\n    Z = \\begin{pmatrix}\n    1.0 & 0.2 & 0.1 \\\\\n    0.8 & 0.5 & 0.3 \\\\\n    0.6 & 0.4 & 0.2\n    \\end{pmatrix}\n    $$\n  - $T_0 = 2$, $T_{\\text{eval}} = 6$\n\n- Test Case $3$ (operator basis smaller than number of states):\n  - $R = 2$\n  - $N = 2$, $M = 3$\n  - Energies: $\\{E_n\\} = \\{0.4, 0.9, 1.5\\}$\n  - Overlaps:\n    $$\n    Z = \\begin{pmatrix}\n    1.0 & 0.4 & 0.2 \\\\\n    0.7 & 0.3 & 0.1\n    \\end{pmatrix}\n    $$\n  - $T_0 = 0$, $T_{\\text{eval}} = 7$\n\nProgram Requirements:\n- Implement the construction of $C(T)$ from the provided $\\{E_n\\}$ and $Z$ for integer $T \\ge 0$.\n- Derive and solve the appropriate generalized eigenvalue problem between $C(T)$ and $C(T_0)$ to obtain $\\lambda_0(T,T_0)$.\n- Compute $V_0^{\\text{eff}}(R;T_{\\text{eval}},T_0)$ using the ratio defined above.\n- Output a single line containing the results for the three test cases as a comma-separated list of floats in square brackets, each rounded to six decimal places, for example, $[0.123456,0.234567,0.345678]$.\n\nNo external input is allowed; hard-code the test suite parameters exactly as specified. The code must be fully self-contained and runnable in a modern programming language. The final energies extracted must be expressed in lattice units as dimensionless floats, rounded to six decimal places.",
            "solution": "The problem requires the implementation of a variational method to extract the static quark potential, which corresponds to the ground state energy $V_0(R) = E_0(R)$ of a static quark-antiquark system. The methodology is based on the spectral properties of correlation matrices in Euclidean time, a cornerstone of lattice field theory calculations.\n\nThe solution proceeds in three main steps:\n1.  Construction of the correlation matrix $C(T)$.\n2.  Formulation and solution of the generalized eigenvalue problem (GEVP).\n3.  Calculation of the effective potential $V_0^{\\text{eff}}$ from the principal eigenvalues.\n\nLet us first establish the theoretical foundation.\n\n**1. The Correlation Matrix**\n\nIn a quantum field theory formulated in Euclidean spacetime, the two-point correlation function of an operator $\\mathcal{O}$ can be expressed through a spectral decomposition. By inserting a complete set of energy eigenstates $|n\\rangle$ of the Hamiltonian $\\hat{H}$ such that $\\hat{H}|n\\rangle = E_n |n\\rangle$, the correlator becomes:\n$$\n\\langle \\mathcal{O}(T) \\mathcal{O}(0) \\rangle = \\langle \\text{vac} | \\mathcal{O} e^{-\\hat{H}T} \\mathcal{O} | \\text{vac} \\rangle = \\sum_n \\langle \\text{vac} | \\mathcal{O} e^{-\\hat{H}T} | n \\rangle \\langle n | \\mathcal{O} | \\text{vac} \\rangle = \\sum_n |\\langle n | \\mathcal{O} | \\text{vac} \\rangle|^2 e^{-E_n T}\n$$\nwhere $T$ is the Euclidean time separation, and energies $E_n$ are measured relative to the vacuum energy, which is set to zero.\n\nThe problem specifies a basis of $N$ operators, $\\{\\mathcal{O}_i\\}_{i=1...N}$, constructed from smeared spatial lines of a Wilson loop. The cross-correlation matrix elements $C_{ij}(T)$ are given by:\n$$\nC_{ij}(T) = \\langle \\mathcal{O}_i(T) \\mathcal{O}_j(0) \\rangle = \\sum_{n=0}^{M-1} \\langle \\text{vac} | \\mathcal{O}_i | n \\rangle \\langle n | \\mathcal{O}_j | \\text{vac} \\rangle e^{-E_n(R) T}\n$$\nwhere $M$ is the number of mediating states. The problem provides the real overlap coefficients $Z_i^{(n)} = \\langle n | \\mathcal{O}_i | \\text{vac} \\rangle$. The correlation matrix is thus:\n$$\nC_{ij}(T) = \\sum_{n=0}^{M-1} Z_i^{(n)} Z_j^{(n)} e^{-E_n(R) T}\n$$\nIn matrix notation, where $Z$ is the $N \\times M$ matrix of overlaps with elements $Z_{in} = Z_i^{(n)}$ and $D(T)$ is an $M \\times M$ diagonal matrix with elements $D_{nn}(T) = e^{-E_n T}$, the $N \\times N$ correlation matrix is:\n$$\nC(T) = Z D(T) Z^T\n$$\nThis matrix is real and symmetric. For $T \\ge 0$, since $e^{-E_n T} > 0$, it is also positive semi-definite. If the columns of $Z$ are linearly independent and $N \\le M$, $C(T)$ is positive definite.\n\n**2. The Generalized Eigenvalue Problem (GEVP)**\n\nThe variational method seeks an optimal linear combination of basis operators, $\\Phi = \\sum_i v_i \\mathcal{O}_i$, that has the best overlap with a specific energy eigenstate, primarily the ground state $|0\\rangle$. The vector of coefficients is $\\mathbf{v} = (v_1, v_2, \\dots, v_N)^T$.\n\nThe expectation value of a correlator for this optimized operator is $\\langle \\Phi(T) \\Phi(0) \\rangle = \\mathbf{v}^T C(T) \\mathbf{v}$. To isolate the ground state energy, we consider the ratio of correlators at two different times, $T$ and a reference time $T_0 < T$:\n$$\n\\lambda(\\mathbf{v}) = \\frac{\\langle \\Phi(T) \\Phi(0) \\rangle}{\\langle \\Phi(T_0) \\Phi(0) \\rangle} = \\frac{\\mathbf{v}^T C(T) \\mathbf{v}}{\\mathbf{v}^T C(T_0) \\mathbf{v}}\n$$\nThis is a Rayleigh quotient. For large time separations, the ground state term dominates the spectral sum, and this ratio approaches $e^{-E_0 (T-T_0)}$.\n\nTo find the optimal vector $\\mathbf{v}$ that isolates a single energy level, we find the stationary points of $\\lambda(\\mathbf{v})$ by setting its gradient with respect to $\\mathbf{v}$ to zero. This procedure leads to the generalized eigenvalue problem:\n$$\nC(T) \\mathbf{v}_n = \\lambda_n(T, T_0) C(T_0) \\mathbf{v}_n\n$$\nThe $N$ real eigenvalues $\\lambda_n(T, T_0)$ approximate the exponential decay of the $N$ lowest energy states that have non-zero overlap with the operator basis:\n$$\n\\lambda_n(T, T_0) \\approx e^{-E_n (T-T_0)}\n$$\nThe principal eigenvalue, $\\lambda_0(T, T_0)$, is the largest eigenvalue and corresponds to the ground state energy $E_0$.\n\n**3. The Effective Potential Estimator**\n\nFrom the principal eigenvalue, we can form an estimator for the ground state energy $E_0(R)$, which is the static potential $V_0(R)$. An effective energy, or potential in this case, can be extracted. The problem specifies a particular estimator constructed from a ratio of principal eigenvalues at successive time steps:\n$$\nV_0^{\\text{eff}}(R; T_{\\text{eval}}, T_0) \\equiv -\\ln\\left(\\frac{\\lambda_0(T_{\\text{eval}}, T_0)}{\\lambda_0(T_{\\text{eval}}-1, T_0)}\\right)\n$$\nSubstituting the long-time behavior of the eigenvalues, we see why this works:\n$$\n\\frac{\\lambda_0(T_{\\text{eval}}, T_0)}{\\lambda_0(T_{\\text{eval}}-1, T_0)} \\approx \\frac{e^{-E_0 (T_{\\text{eval}}-T_0)}}{e^{-E_0 (T_{\\text{eval}}-1-T_0)}} = e^{-E_0 (T_{\\text{eval}}-T_0 - (T_{\\text{eval}}-1-T_0))} = e^{-E_0}\n$$\nTherefore, $V_0^{\\text{eff}} \\approx - \\ln(e^{-E_0}) = E_0$. This ratio-based estimator is designed to cancel leading-order systematic errors from higher-state contaminations, providing a more stable estimate of the ground state energy.\n\nThe computational procedure is as follows:\nFor each test case with parameters $N$, $M$, $\\{E_n\\}$, $Z$, $T_0$, and $T_{\\text{eval}}$:\n1.  Construct the three $N \\times N$ correlation matrices: $C(T_{\\text{eval}})$, $C(T_{\\text{eval}}-1)$, and $C(T_0)$. The lattice spacing is $a=1$.\n2.  Solve two separate GEVPs:\n    a. $C(T_{\\text{eval}}) \\mathbf{v} = \\lambda C(T_0) \\mathbf{v}$\n    b. $C(T_{\\text{eval}}-1) \\mathbf{v} = \\lambda' C(T_0) \\mathbf{v}$\n3.  From each solution, extract the principal (largest) eigenvalue, which we denote $\\lambda_0(T_{\\text{eval}}, T_0)$ and $\\lambda_0(T_{\\text{eval}}-1, T_0)$, respectively. Since standard numerical solvers for symmetric GEVPs return eigenvalues sorted in ascending order, the principal eigenvalue will be the last element in the returned array.\n4.  Calculate the effective potential using the provided formula.\n5.  Round the final result to six decimal places.\n\nThis procedure constitutes a complete and rigorous solution to the problem as stated.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the solving process for all test cases.\n    It hard-codes the test cases, iterates through them, computes the\n    static potential for each, and prints the formatted results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"R\": 3,\n            \"N\": 3, \"M\": 3,\n            \"energies\": np.array([0.5, 0.8, 1.4]),\n            \"overlaps\": np.array([\n                [1.0, 0.3, 0.1],\n                [0.9, 0.5, 0.2],\n                [0.7, 0.2, 0.4]\n            ]),\n            \"T0\": 1,\n            \"T_eval\": 5\n        },\n        {\n            \"R\": 5,\n            \"N\": 3, \"M\": 3,\n            \"energies\": np.array([0.7, 0.71, 1.3]),\n            \"overlaps\": np.array([\n                [1.0, 0.2, 0.1],\n                [0.8, 0.5, 0.3],\n                [0.6, 0.4, 0.2]\n            ]),\n            \"T0\": 2,\n            \"T_eval\": 6\n        },\n        {\n            \"R\": 2,\n            \"N\": 2, \"M\": 3,\n            \"energies\": np.array([0.4, 0.9, 1.5]),\n            \"overlaps\": np.array([\n                [1.0, 0.4, 0.2],\n                [0.7, 0.3, 0.1]\n            ]),\n            \"T0\": 0,\n            \"T_eval\": 7\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_static_potential(case)\n        results.append(result)\n\n    # Format and print the final results as specified.\n    # The rounding to 6 decimal places is done by the formatting string.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef build_correlation_matrix(T, energies, overlaps):\n    \"\"\"\n    Constructs the correlation matrix C(T) for a given Euclidean time T.\n    \n    The formula is C(T) = Z * D(T) * Z^T, where Z is the NxM overlap matrix\n    and D(T) is an MxM diagonal matrix with elements D_nn = exp(-E_n * T).\n\n    Args:\n        T (int): The Euclidean time separation.\n        energies (np.ndarray): A 1D array of M energy eigenvalues.\n        overlaps (np.ndarray): An NxM matrix of overlap coefficients Z.\n\n    Returns:\n        np.ndarray: The NxN correlation matrix C(T).\n    \"\"\"\n    # Create the diagonal matrix D(T)\n    diag_elements = np.exp(-energies * T)\n    D_T = np.diag(diag_elements)\n    \n    # Calculate C(T) = Z @ D(T) @ Z.T\n    C_T = overlaps @ D_T @ overlaps.T\n    return C_T\n\ndef get_principal_eigenvalue(C_T, C_T0):\n    \"\"\"\n    Solves the generalized eigenvalue problem C(T)v = lambda * C(T0)v and\n    returns the principal (largest) eigenvalue.\n\n    Args:\n        C_T (np.ndarray): The correlation matrix at time T.\n        C_T0 (np.ndarray): The correlation matrix at reference time T0.\n\n    Returns:\n        float: The principal generalized eigenvalue.\n    \"\"\"\n    # The matrices are real and symmetric, C_T0 is positive definite.\n    # scipy.linalg.eigh solves the GEVP for Hermitian matrices,\n    # returning eigenvalues sorted in ascending order.\n    eigenvalues = linalg.eigh(C_T, C_T0, eigvals_only=True)\n    \n    # The principal eigenvalue corresponds to the ground state and is the largest.\n    principal_eigenvalue = eigenvalues[-1]\n    return principal_eigenvalue\n\ndef calculate_static_potential(params):\n    \"\"\"\n    Calculates the effective static potential V_0^eff for a single test case.\n\n    Args:\n        params (dict): A dictionary containing all parameters for the case.\n\n    Returns:\n        float: The calculated effective static potential.\n    \"\"\"\n    energies = params[\"energies\"]\n    overlaps = params[\"overlaps\"]\n    T0 = params[\"T0\"]\n    T_eval = params[\"T_eval\"]\n    \n    # 1. Construct the required correlation matrices\n    C_T_eval = build_correlation_matrix(T_eval, energies, overlaps)\n    C_T_eval_minus_1 = build_correlation_matrix(T_eval - 1, energies, overlaps)\n    C_T0 = build_correlation_matrix(T0, energies, overlaps)\n    \n    # 2. Solve the two GEVPs to find the principal eigenvalues\n    lambda_0_eval = get_principal_eigenvalue(C_T_eval, C_T0)\n    lambda_0_eval_minus_1 = get_principal_eigenvalue(C_T_eval_minus_1, C_T0)\n    \n    # 3. Compute the effective static potential estimator\n    # The formula is V_eff = -ln(lambda_0(T_eval) / lambda_0(T_eval - 1))\n    ratio = lambda_0_eval / lambda_0_eval_minus_1\n    V_eff = -np.log(ratio)\n    \n    return V_eff\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Lattice QCD simulations are performed in dimensionless units, and connecting their results to the physical world requires setting a scale. The Sommer scale, $r_0$, provides a standard and physically intuitive way to determine the lattice spacing by probing the force between static quarks at an intermediate distance. In this exercise , you will implement the robust numerical methods—including shape-preserving interpolation and root-finding—required to extract $r_0$ from a discrete set of potential data, a critical final step in any serious study of the static potential.",
            "id": "3611702",
            "problem": "Consider the extraction of the static quark potential from rectangular Wilson loops in lattice Quantum Chromodynamics (QCD), where the static potential in lattice units is obtained from large temporal extent rectangular loops. In this setting, the static potential is a function of the spatial separation, denoted by $V(R)$ with $R$ measured in lattice-spacing units. The Sommer scale $r_0$ is defined implicitly by the condition $r_0^2 F(r_0) = c$, where $F(r) = \\frac{dV}{dr}$ is the interquark force and $c = 1.65$. The task is to compute $r_0/a$, where $a$ is the lattice spacing, directly in lattice units from discrete measurements of $V(R)$ at integer $R$ values.\n\nStarting only from the core definitions\n- the relationship between Wilson loops and the static potential in the large temporal extent limit,\n- the definition of the force as the spatial derivative $F(r) = \\frac{dV}{dr}$,\n- and the implicit Sommer scale condition $r_0^2 F(r_0) = c$ with $c = 1.65$,\ndesign and implement a stable numerical procedure to estimate $r_0/a$ from discrete data $\\{(R_i, V_i)\\}$.\n\nYour implementation must:\n1. Treat $R$ and $V(R)$ as dimensionless lattice quantities and compute $r_0/a$ as a dimensionless number.\n2. Build a shape-preserving interpolation of the discrete $V(R)$ data that is sufficiently smooth to permit stable numerical differentiation. Use an interpolation approach that avoids spurious oscillations and honors monotonicity of $V(R)$ when present. Then, differentiate the interpolant to obtain a continuous approximation to $F(r)$ on the open interval between the smallest and largest observed separations.\n3. Solve the nonlinear equation $r^2 F(r) - c = 0$ for $r$ within the domain $(R_{\\min}, R_{\\max})$, where $R_{\\min}$ and $R_{\\max}$ are the smallest and largest sampled separations. Use a bracketing strategy to ensure a robust root-finding procedure. If a sign change cannot be located within the interpolation domain due to mild data irregularities, use a physically motivated smooth fit of the potential to regularize the derivative and repeat the root finding on the fitted model.\n4. Return results rounded to six decimal places.\n\nTest Suite:\nFor each of the following five test cases, the input consists of a list of separations $R$ and a list of corresponding potentials $V(R)$, all in lattice units. For each case, compute a single float equal to $r_0/a$ satisfying $r_0^2 F(r_0) = 1.65$. All provided numbers below are in lattice units and should be treated as exact inputs to your program.\n\n- Case A:\n  - $R = [1, 2, 3, 4, 5, 6, 7, 8]$\n  - $V = [0.38, 0.71, 0.94, 1.145, 1.34, 1.53, 1.7171428571, 1.9025]$\n- Case B:\n  - $R = [1, 2, 3, 4, 5, 6, 7, 8]$\n  - $V = [0.3785, 0.713, 0.9355, 1.151, 1.3325, 1.539, 1.7066428571, 1.9145]$\n- Case C:\n  - $R = [2, 3, 4, 5, 6]$\n  - $V = [0.715, 0.9766666667, 1.2175, 1.45, 1.6783333333]$\n- Case D:\n  - $R = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]$\n  - $V = [0.51, 0.72, 0.8966666667, 1.065, 1.23, 1.3933333333, 1.5557142857, 1.7175, 1.8788888889, 2.04]$\n- Case E:\n  - $R = [1, 2, 3, 4, 5, 6, 7]$\n  - $V = [0.54, 0.87, 1.1133333333, 1.345, 1.548, 1.7566666667, 1.9628571429]$\n\nRequirements for numerical method and output:\n- Interpolate $V(R)$ with a shape-preserving scheme suitable for monotone data, then differentiate to approximate $F(r)$ for $r \\in (R_{\\min}, R_{\\max})$.\n- Use a bracketing root finder on $g(r) = r^2 F(r) - 1.65$.\n- If no bracket can be found due to mild irregularities, regularize via a smooth three-parameter fit of $V(R)$ consistent with short-distance attraction and long-distance linear rise, and solve again for $r$.\n- Output a single line containing a comma-separated list with square brackets and no spaces that aggregates the five $r_0/a$ values for the five cases in the order A, B, C, D, E. Each value must be rounded to six decimal places. For example, the format must be \"[x_A,x_B,x_C,x_D,x_E]\" with each $x$ a float rounded to six decimals.",
            "solution": "The problem requires the computation of the Sommer scale, denoted $r_0$, from discrete data of the static quark potential $V(R)$ in lattice Quantum Chromodynamics (QCD). The quantities are given in lattice units, so the spatial separation $R$ is an integer multiple of the lattice spacing $a$, and the potential $V(R)$ is dimensionless. The objective is to calculate the dimensionless ratio $r_0/a$.\n\n### Step 1: Formalization of the Problem\nThe Sommer scale $r_0$ is defined implicitly by the equation:\n$$\nr_0^2 F(r_0) = c\n$$\nwhere $F(r) = \\frac{dV}{dr}$ is the force between the static quarks and $c$ is a constant set to $1.65$. Since all quantities are provided in lattice units, we are solving for $r = r_0/a$. The problem thus reduces to finding the root of the nonlinear function $g(r)$:\n$$\ng(r) = r^2 F(r) - c = 0\n$$\nThe input is a set of discrete data points $\\{(R_i, V_i)\\}$, where $R_i$ are separations and $V_i = V(R_i)$ are the corresponding potential values. To solve the equation, we first need a continuous representation of the force $F(r)$ from the discrete potential data $V_i$. This must be done within the open interval of observed separations $(R_{\\min}, R_{\\max})$.\n\n### Step 2: Numerical Strategy\nA two-pronged numerical strategy is designed to ensure a robust solution, as stipulated by the problem. A primary method based on interpolation is attempted first. If this method fails due to irregularities in the data, a fallback method based on a physical model fit is employed.\n\n#### Primary Method: Interpolation and Root Finding\nThis method involves two stages:\n1.  **Interpolation and Differentiation**: The discrete potential data $(R_i, V_i)$ are interpolated to obtain a continuous function $V_{\\text{interp}}(r)$. The problem specifies a shape-preserving interpolation scheme to avoid spurious oscillations and respect the monotonicity of the data. A Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) is an excellent choice for this purpose. It ensures that the interpolant is monotonic on any interval where the data is monotonic. The `scipy.interpolate.PchipInterpolator` provides such functionality. Once the interpolant $V_{\\text{interp}}(r)$ is constructed, its derivative, $F_{\\text{interp}}(r) = \\frac{dV_{\\text{interp}}}{dr}$, can be computed analytically or numerically. The `PchipInterpolator` object conveniently provides a method to obtain a callable function for its derivative, which is a continuous piecewise quadratic polynomial.\n\n2.  **Root Finding**: With the continuous force function $F_{\\text{interp}}(r)$, we can define $g(r) = r^2 F_{\\text{interp}}(r) - c$. The problem requires a bracketing root-finding algorithm. We will use the Brent-Dekker method, implemented as `scipy.optimize.brentq`. This method requires a bracket $[r_a, r_b]$ such that $g(r_a)$ and $g(r_b)$ have opposite signs. A search for such a bracket is performed by iterating through the intervals $[R_i, R_{i+1}]$ defined by the input data points and checking for a sign change, i.e., $g(R_i) \\cdot g(R_{i+1}) < 0$. If a bracket is found, `brentq` is used to find the root $r = r_0/a$ with high precision.\n\n#### Fallback Method: Regularization via Functional Fit\nIf the primary method fails to locate a sign-change bracket across any interval $[R_i, R_{i+1}]$, it suggests that mild irregularities or noise in the data have produced a numerical derivative $F_{\\text{interp}}(r)$ for which the function $g(r)$ does not cross zero in a way that is detectable by sampling at the grid points $R_i$. In this scenario, we resort to a regularization procedure.\n\n1.  **Physical Model Fit**: The static quark potential is well-described by the Cornell potential model, which incorporates the expected features of short-distance attraction (Coulomb-like) and long-distance linear confinement. The functional form is:\n    $$\n    V_{\\text{fit}}(r) = -\\frac{\\alpha}{r} + \\sigma r + V_0\n    $$\n    The parameters $(\\alpha, \\sigma, V_0)$ are determined by performing a non-linear least-squares fit of this model to the discrete data $(R_i, V_i)$. This is achieved using `scipy.optimize.curve_fit`. This fit provides a smooth, physically motivated representation of the potential that is less sensitive to small local fluctuations in the data.\n\n2.  **Analytical Solution**: For the Cornell potential, the force is given by its derivative:\n    $$\n    F_{\\text{fit}}(r) = \\frac{dV_{\\text{fit}}}{dr} = \\frac{\\alpha}{r^2} + \\sigma\n    $$\n    Substituting this into the Sommer scale equation yields:\n    $$\n    r^2 \\left( \\frac{\\alpha}{r^2} + \\sigma \\right) - c = 0\n    $$\n    This simplifies to $\\alpha + \\sigma r^2 - c = 0$, which can be solved analytically for $r = r_0/a$:\n    $$\n    r = \\sqrt{\\frac{c - \\alpha}{\\sigma}}\n    $$\n    This provides a stable, regularized estimate for the Sommer scale, provided the fitted parameters are physical (i.e., $\\sigma > 0$ and $c > \\alpha$).\n\n### Step 3: Algorithmic Implementation\nThe overall algorithm is implemented in a Python function. For each test case:\n1.  A `try` block attempts the primary method. It initializes the PCHIP interpolator and its derivative. It then iterates through the data intervals $[R_i, R_{i+1}]$, attempting to solve for the root using `brentq`. If a root is found, the function returns the value, rounded to six decimal places.\n2.  If the `brentq` calls all fail, a `ValueError` is raised, triggering the `except` block.\n3.  The `except` block implements the fallback method. It fits the Cornell potential to the data using `curve_fit`, extracts the parameters $\\alpha$ and $\\sigma$, and computes $r_0/a$ using the analytical formula. The result is then returned, rounded to six decimal places.\nThis structured approach robustly handles both clean data, for which the interpolation method is superior, and data with minor irregularities, for which the fitting method provides a necessary regularization.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import PchipInterpolator\nfrom scipy.optimize import brentq, curve_fit\n\ndef solve():\n    \"\"\"\n    Main function to solve for the Sommer scale for all test cases.\n    \"\"\"\n    # The constant c in the Sommer scale definition r_0^2 F(r_0) = c.\n    C_SOMMER = 1.65\n\n    def solve_case(R, V):\n        \"\"\"\n        Computes the Sommer scale r_0/a for a single set of potential data.\n\n        This function implements a two-stage process:\n        1. Primary Method: Uses PCHIP interpolation to get a continuous Force F(r)\n           and finds the root of r^2*F(r) - c = 0 using a bracketing solver.\n        2. Fallback Method: If the primary method fails (due to data irregularities\n           preventing a bracket from being found), it fits the data to a Cornell\n           potential V(r) = -alpha/r + sigma*r + V0 and solves for r_0/a analytically.\n        \"\"\"\n        R_np = np.array(R, dtype=np.float64)\n        V_np = np.array(V, dtype=np.float64)\n\n        # === Primary Method: Interpolation and Root Finding ===\n        try:\n            # 1. Create a shape-preserving interpolator and its derivative (the force)\n            v_interp = PchipInterpolator(R_np, V_np)\n            f_interp = v_interp.derivative(nu=1)\n\n            # 2. Define the function g(r) whose root we need to find\n            def g(r):\n                # The Sommer scale equation: r^2 * F(r) - c = 0\n                return r**2 * f_interp(r) - C_SOMMER\n\n            # 3. Search for a bracket and solve using brentq\n            # Iterate over intervals defined by the data points.\n            for i in range(len(R_np) - 1):\n                r_a, r_b = R_np[i], R_np[i+1]\n                # Brentq will raise a ValueError if g(r_a) and g(r_b) do not have\n                # opposite signs. We catch this and continue to the next interval.\n                try:\n                    root = brentq(g, r_a, r_b)\n                    return round(root, 6)\n                except ValueError:\n                    continue\n            \n            # If the loop completes without finding a root, it means no bracket\n            # was found between adjacent data points. This triggers the fallback.\n            raise ValueError(\"No bracket found for root finding via interpolation.\")\n\n        # === Fallback Method: Regularization via Fit ===\n        except (ValueError, RuntimeError):\n            # 1. Define the Cornell potential model for fitting\n            def cornell_potential(r, alpha, sigma, v0):\n                return -alpha / r + sigma * r + v0\n\n            # 2. Fit the model to the data to get the parameters\n            # Initial guess for [alpha, sigma, v0] based on typical lattice QCD values.\n            p0 = [0.3, 0.2, 0.6]\n            \n            popt, _ = curve_fit(cornell_potential, R_np, V_np, p0=p0, maxfev=10000)\n            alpha, sigma = popt[0], popt[1]\n\n            # 3. Calculate r_0/a using the analytical formula for the Cornell potential\n            # Check for physical parameters to ensure the argument of sqrt is positive.\n            if sigma <= 0 or C_SOMMER - alpha < 0:\n                # Should not happen with the provided data, but is a necessary check.\n                raise RuntimeError(\"Fit resulted in unphysical parameters.\")\n            \n            r0_lat_sq = (C_SOMMER - alpha) / sigma\n            root = np.sqrt(r0_lat_sq)\n            \n            return round(root, 6)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        ([1, 2, 3, 4, 5, 6, 7, 8], [0.38, 0.71, 0.94, 1.145, 1.34, 1.53, 1.7171428571, 1.9025]),\n        # Case B\n        ([1, 2, 3, 4, 5, 6, 7, 8], [0.3785, 0.713, 0.9355, 1.151, 1.3325, 1.539, 1.7066428571, 1.9145]),\n        # Case C\n        ([2, 3, 4, 5, 6], [0.715, 0.9766666667, 1.2175, 1.45, 1.6783333333]),\n        # Case D\n        ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [0.51, 0.72, 0.8966666667, 1.065, 1.23, 1.3933333333, 1.5557142857, 1.7175, 1.8788888889, 2.04]),\n        # Case E\n        ([1, 2, 3, 4, 5, 6, 7], [0.54, 0.87, 1.1133333333, 1.345, 1.548, 1.7566666667, 1.9628571429])\n    ]\n\n    results = []\n    for R_data, V_data in test_cases:\n        result = solve_case(R_data, V_data)\n        # Format to exactly six decimal places for the output string.\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}