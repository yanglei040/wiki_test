{
    "hands_on_practices": [
        {
            "introduction": "在贝叶斯分析中，先验分布的选择是一个基础且关键的步骤，尤其是在数据稀疏的情况下。本实践旨在通过一个在核物理中常见的低计数激活实验场景，让您亲手探索不同先验选择对后验推断的影响。您将通过比较一个简单的均匀先验和一个无信息量更大的对数均匀（Jeffreys）先验，来量化分析在低统计量下后验概率的敏感性，从而深化对贝叶斯工作流程核心思想的理解 。",
            "id": "3544521",
            "problem": "考虑一个核活化计数实验，在某个计数区间内观测到的计数值 $k$ 源于一个均值为 $\\mu = r E + b$ 的泊松过程，其中 $r$ 是待推断的非负反应率，$E$ 是一个已知的有效曝光量（一个已知的正常数，与注量、效率、活时间和靶核数量的乘积成正比），它将反应率 $r$ 映射到期望信号计数值 $rE$，$b$ 是一个已知的期望本底计数贡献（一个已知的非负常数）。假设在给定 $r$ 的条件下 $k$ 的似然函数是均值为 $\\mu = rE + b$ 的泊松概率质量函数。你将比较 $r$ 的两种先验：平坦先验和对数均匀先验，并量化低计数情况下的后验敏感性。任务是纯粹从第一性原理出发，使用贝叶斯法则和数值积分来计算后验概率和可信区间，而不使用任何闭式后验表达式。\n\n将解决方案建立在以下经过充分检验的原则和定义之上：\n- 对于非负整数 $k$ 和 $\\mu \\ge 0$，以均值 $\\mu$ 为条件的 $k$ 的泊松似然函数为 $P(k \\mid \\mu) = \\exp(-\\mu)\\,\\mu^{k}/k!$。\n- 贝叶斯法则指出 $p(r \\mid k) \\propto P(k \\mid r)\\,p(r)$，其中归一化条件为在 $r$ 的支撑集上 $\\int p(r \\mid k)\\,dr = 1$。\n- 在有界支撑集 $[0, r_{\\max}]$ 上的 $r$ 的平坦先验为：当 $r \\in [0, r_{\\max}]$ 时，$p_{\\mathrm{flat}}(r) \\propto 1$，否则为 $0$。\n- 在有界支撑集 $[r_{\\min}, r_{\\max}]$ 上的 $r$ 的对数均匀先验（也称为 Jeffreys 型尺度先验）为：当 $r \\in [r_{\\min}, r_{\\max}]$ 时，$p_{\\log}(r) \\propto 1/r$，否则为 $0$。这等价于在 $\\log r_{\\min}$ 和 $\\log r_{\\max}$ 之间对 $\\log r$ 取均匀先验。\n\n对于下方的每个测试用例，你必须：\n1. 在每种先验下，构建未归一化的后验密度：\n$$p_{\\mathrm{flat}}(r \\mid k) \\propto \\exp\\!\\left(-\\left(rE + b\\right)\\right)\\,\\left(rE + b\\right)^{k}\\,\\mathbf{1}_{[0, r_{\\max}]}(r)$$\n$$p_{\\log}(r \\mid k) \\propto \\exp\\!\\left(-\\left(rE + b\\right)\\right)\\,\\left(rE + b\\right)^{k}\\,\\dfrac{1}{r}\\,\\mathbf{1}_{[r_{\\min}, r_{\\max}]}(r)$$\n   这里 $\\mathbf{1}_{A}(r)$ 是集合 $A$ 的指示函数。\n2. 通过对 $r$ 进行数值积分来归一化每个后验，以确保后验在其支撑集上的积分为 $1$。\n3. 定义阈值 $r_{\\mathrm{thr}} = 1/E$，它对应于在给定曝光量 $E$ 下会产生 $1$ 个期望信号计数的信号率。\n4. 计算以下量值：\n   - 平坦先验下，在 $r_{\\mathrm{thr}}$ 处的后验累积概率：$F_{\\mathrm{flat}}(r_{\\mathrm{thr}}) = \\int_{0}^{\\min(r_{\\mathrm{thr}}, r_{\\max})} p_{\\mathrm{flat}}(r \\mid k)\\,dr$。\n   - 对数均匀先验下，在 $r_{\\mathrm{thr}}$ 处的后验累积概率：$F_{\\log}(r_{\\mathrm{thr}}) = \\int_{r_{\\min}}^{\\min(r_{\\mathrm{thr}}, r_{\\max})} p_{\\log}(r \\mid k)\\,dr$，需要注意的是，如果 $r_{\\mathrm{thr}} \\le r_{\\min}$，此值为 $0$。\n   - 敏感性差异 $S = F_{\\log}(r_{\\mathrm{thr}}) - F_{\\mathrm{flat}}(r_{\\mathrm{thr}})$。\n   - 每种先验下的 $95\\%$ 可信上限，定义为满足 $\\int_{0}^{r^{95}_{\\mathrm{flat}}} p_{\\mathrm{flat}}(r \\mid k)\\,dr = 0.95$ 和 $\\int_{r_{\\min}}^{r^{95}_{\\log}} p_{\\log}(r \\mid k)\\,dr = 0.95$ 的唯一值 $r^{95}_{\\mathrm{flat}}$ 和 $r^{95}_{\\log}$，每个值都约束在各自的支撑区间内。报告比率 $R_{95} = r^{95}_{\\log} / r^{95}_{\\mathrm{flat}}$。\n所有报告的量（$F_{\\mathrm{flat}}(r_{\\mathrm{thr}})$、$F_{\\log}(r_{\\mathrm{thr}})$、$S$、$R_{95}$）都是无量纲的。\n\n数值要求：\n- 所有积分必须通过数值计算，并具有足够的精度，以确保结果至少有 $6$ 位有效数字。\n- 可信区间的求根必须在平坦先验的支撑区间 $[0, r_{\\max}]$ 和对数均匀先验的支撑区间 $[r_{\\min}, r_{\\max}]$ 上使用稳健的区间法（bracketing method）进行。\n\n测试套件：\n使用以下五个测试用例，每个由 $(k, E, b)$ 指定：\n- 用例 1：$(k, E, b) = (0, 10^{5}, 0)$。\n- 用例 2：$(k, E, b) = (1, 10^{5}, 0.5)$。\n- 用例 3：$(k, E, b) = (3, 5\\times 10^{4}, 2)$。\n- 用例 4：$(k, E, b) = (0, 10^{3}, 0)$。\n- 用例 5：$(k, E, b) = (0, 10^{5}, 5)$。\n对所有用例使用相同的有界支撑集：$r_{\\min} = 10^{-12}$ 和 $r_{\\max} = 10^{-3}$。\n\n最终输出规格：\n- 对于每个用例，按给定顺序，计算并输出四个实数的序列：$F_{\\mathrm{flat}}(r_{\\mathrm{thr}})$、$F_{\\log}(r_{\\mathrm{thr}})$、$S$ 和 $R_{95}$。\n- 你的程序应生成单行输出，其中包含所有 5 个用例的结果，按顺序连接成一个用方括号括起来的逗号分隔列表。例如，格式为 $[x_{1,1}, x_{1,2}, x_{1,3}, x_{1,4}, x_{2,1}, \\dots, x_{5,4}]$，其中 $x_{i,j}$ 表示第 $i$ 个用例的第 $j$ 个量。\n- 所有输出必须是十进制数（而非分数），且不得包含任何百分号；例如，95% 的累积概率必须打印为 $0.95$。",
            "solution": "该问题是有效的，因为它在科学上基于贝叶斯统计推断和核物理，问题陈述清晰且提供了所有必要信息，并且在计算上是可行的。该问题要求在一个泊松计数实验中，比较从两种不同先验（平坦先验和对数均匀先验）推导出的反应率参数的后验推断，这是计算物理中的一个标准任务。\n\n解决方案按要求从第一性原理出发。对于由观测计数值 $k$、有效曝光量 $E$ 和本底计数值 $b$ 定义的每个测试用例，我们构建反应率 $r$ 的后验概率密度函数 (PDF)。然后，我们数值计算所需的量：后验累积概率、它们的差值，以及 $95\\%$ 可信上限的比率。\n\n对于均值为 $\\mu = rE + b$ 的泊松过程，观测到 $k$ 个计数的似然函数由下式给出\n$$\nP(k \\mid r, E, b) = \\frac{(rE+b)^k e^{-(rE+b)}}{k!}\n$$\n其中 $r \\ge 0$, $E > 0$, 且 $b \\ge 0$。\n\n根据贝叶斯法则， $r$ 的后验 PDF 与似然函数和先验 PDF 的乘积成正比，即 $p(r \\mid k) \\propto P(k \\mid r) p(r)$。项 $1/k!$ 相对于 $r$ 是一个常数，可以并入归一化常数中。\n\n我们考虑两种不同的反应率 $r$ 的先验。\n\n1.  **平坦先验**：先验在区间 $[0, r_{\\max}]$ 上是均匀的。\n    $$\n    p_{\\mathrm{flat}}(r) = \\begin{cases} C_1  \\text{if } 0 \\le r \\le r_{\\max} \\\\ 0  \\text{otherwise} \\end{cases}\n    $$\n    其中 $C_1$ 是一个归一化常数。未归一化的后验为：\n    $$\n    \\tilde{p}_{\\mathrm{flat}}(r \\mid k) = (rE+b)^k e^{-(rE+b)}, \\quad \\text{for } r \\in [0, r_{\\max}]\n    $$\n\n2.  **对数均匀先验**：先验在区间 $[r_{\\min}, r_{\\max}]$ 上与 $1/r$ 成正比。这对应于对 $\\log r$ 取均匀先验。\n    $$\n    p_{\\log}(r) = \\begin{cases} C_2/r  \\text{if } r_{\\min} \\le r \\le r_{\\max} \\\\ 0  \\text{otherwise} \\end{cases}\n    $$\n    其中 $C_2$ 是一个归一化常数，且 $r_{\\min} > 0$。未归一化的后验为：\n    $$\n    \\tilde{p}_{\\log}(r \\mid k) = \\frac{(rE+b)^k e^{-(rE+b)}}{r}, \\quad \\text{for } r \\in [r_{\\min}, r_{\\max}]\n    $$\n\n为了获得归一化的后验 PDF，我们必须通过在其各自的支撑集上对未归一化的后验进行积分来计算归一化常数：\n$$\nZ_{\\mathrm{flat}} = \\int_0^{r_{\\max}} \\tilde{p}_{\\mathrm{flat}}(r \\mid k) \\, dr = \\int_0^{r_{\\max}} (rE+b)^k e^{-(rE+b)} \\, dr\n$$\n$$\nZ_{\\log} = \\int_{r_{\\min}}^{r_{\\max}} \\tilde{p}_{\\log}(r \\mid k) \\, dr = \\int_{r_{\\min}}^{r_{\\max}} \\frac{(rE+b)^k e^{-(rE+b)}}{r} \\, dr\n$$\n这些积分通过数值方法计算。那么，归一化的后验 PDF 为：\n$$\np_{\\mathrm{flat}}(r \\mid k) = \\frac{1}{Z_{\\mathrm{flat}}} \\tilde{p}_{\\mathrm{flat}}(r \\mid k), \\quad \\text{for } r \\in [0, r_{\\max}]\n$$\n$$\np_{\\log}(r \\mid k) = \\frac{1}{Z_{\\log}} \\tilde{p}_{\\log}(r \\mid k), \\quad \\text{for } r \\in [r_{\\min}, r_{\\max}]\n$$\n对于支撑集为 $[r_a, r_b]$ 的一般后验 $p(r|k)$，其后验累积分布函数 (CDF) 为 $F(r) = \\int_{r_a}^{r} p(r'|k) dr'$。\n\n每个测试用例所需的量计算如下：\n\n1.  **$r_{\\mathrm{thr}}$ 处的后验累积概率**：阈值率为 $r_{\\mathrm{thr}} = 1/E$。我们计算两种后验在此阈值处的 CDF 值。积分上限为 $\\min(r_{\\mathrm{thr}}, r_{\\max})$。\n    $$\n    F_{\\mathrm{flat}}(r_{\\mathrm{thr}}) = \\int_{0}^{\\min(r_{\\mathrm{thr}}, r_{\\max})} p_{\\mathrm{flat}}(r \\mid k) \\, dr\n    $$\n    $$\n    F_{\\log}(r_{\\mathrm{thr}}) = \\int_{r_{\\min}}^{\\min(r_{\\mathrm{thr}}, r_{\\max})} p_{\\log}(r \\mid k) \\, dr\n    $$\n    对于所有给定的测试用例，$r_{\\mathrm{thr}} > r_{\\min}$，因此第二个积分在一个正长度的区间上是良定义的。这些积分也通过数值方法计算。\n\n2.  **敏感性差异**：这是两个累积概率之间的简单算术差。\n    $$\n    S = F_{\\log}(r_{\\mathrm{thr}}) - F_{\\mathrm{flat}}(r_{\\mathrm{thr}})\n    $$\n\n3.  **$95\\%$ 可信上限**：上限 $r^{95}$ 是使 CDF 值为 $0.95$ 的 $r$ 值。我们通过求解以下关于 $r^{95}$ 的方程来找到 $r^{95}_{\\mathrm{flat}}$ 和 $r^{95}_{\\log}$：\n    $$\n    \\int_{0}^{r^{95}_{\\mathrm{flat}}} p_{\\mathrm{flat}}(r \\mid k) \\, dr = 0.95\n    $$\n    $$\n    \\int_{r_{\\min}}^{r^{95}_{\\log}} p_{\\log}(r \\mid k) \\, dr = 0.95\n    $$\n    这些方程使用数值求根算法在 $r^{95}_{\\mathrm{flat}} \\in [0, r_{\\max}]$ 和 $r^{95}_{\\log} \\in [r_{\\min}, r_{\\max}]$ 的范围内求解。具体来说，我们寻找函数 $g(x) = F(x) - 0.95 = 0$ 的根。由于 CDF $F(x)$ 是单调的，像 Brent 方法这样稳健的区间法是合适的。搜索区间是相应先验的支撑集。\n\n4.  **上限比率**：最终的量是这两个可信上限的比率。\n    $$\n    R_{95} = \\frac{r^{95}_{\\log}}{r^{95}_{\\mathrm{flat}}}\n    $$\n\n每个测试用例 $(k, E, b)$ 的总体计算流程是：\n-   定义未归一化的后验函数 $\\tilde{p}_{\\mathrm{flat}}(r \\mid k)$ 和 $\\tilde{p}_{\\log}(r \\mid k)$。\n-   使用数值求积 (`scipy.integrate.quad`) 计算归一化常数 $Z_{\\mathrm{flat}}$ 和 $Z_{\\log}$。\n-   使用数值求积计算 $F_{\\mathrm{flat}}(r_{\\mathrm{thr}})$ 和 $F_{\\log}(r_{\\mathrm{thr}})$。\n-   计算 $S$。\n-   为可信区间建立 CDF 方程，并使用数值求根器 (`scipy.optimize.brentq`) 求解 $r^{95}_{\\mathrm{flat}}$ 和 $r^{95}_{\\log}$。\n-   计算 $R_{95}$。\n\n此过程在提供的 Python 脚本中实现，该脚本遍历指定的测试用例并按要求格式化结果。",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian inference problem for all test cases.\n    \"\"\"\n    \n    # Define the bounded supports for the rate r\n    r_min = 1e-12\n    r_max = 1e-3\n\n    # Define the test cases (k, E, b)\n    test_cases = [\n        (0, 1e5, 0),\n        (1, 1e5, 0.5),\n        (3, 5e4, 2),\n        (0, 1e3, 0),\n        (0, 1e5, 5),\n    ]\n\n    all_results = []\n\n    for k, E, b in test_cases:\n        # Define the threshold rate\n        r_thr = 1.0 / E\n\n        # Define unnormalized posterior functions\n        # The (rE+b)**k term is handled carefully for k=0.\n        # np.power(0, 0) correctly evaluates to 1.\n        def unnormalized_posterior_flat(r, k_val, E_val, b_val):\n            mean_val = r * E_val + b_val\n            # The likelihood is proportional to mean_val**k * exp(-mean_val)\n            # The flat prior is constant, so it's absorbed into normalization\n            return np.power(mean_val, k_val) * np.exp(-mean_val)\n\n        def unnormalized_posterior_log(r, k_val, E_val, b_val):\n            # The log prior is proportional to 1/r\n            if r == 0:\n                # Should not be called at r=0 as support is [r_min, r_max]\n                return 0\n            return unnormalized_posterior_flat(r, k_val, E_val, b_val) / r\n\n        # --- Normalization ---\n        # Integrate the unnormalized posteriors over their supports\n        norm_flat, _ = quad(unnormalized_posterior_flat, 0, r_max, args=(k, E, b))\n        norm_log, _ = quad(unnormalized_posterior_log, r_min, r_max, args=(k, E, b))\n\n        # Define normalized posterior PDFs\n        def pdf_flat(r, k_val, E_val, b_val):\n            return unnormalized_posterior_flat(r, k_val, E_val, b_val) / norm_flat\n\n        def pdf_log(r, k_val, E_val, b_val):\n            return unnormalized_posterior_log(r, k_val, E_val, b_val) / norm_log\n\n        # --- Compute F(r_thr) and S ---\n        integration_upper_bound = min(r_thr, r_max)\n        \n        # F_flat(r_thr)\n        F_flat_thr, _ = quad(pdf_flat, 0, integration_upper_bound, args=(k, E, b))\n        \n        # F_log(r_thr)\n        # Note: Problem states if r_thr = r_min, F_log is 0. Here, r_thr >= r_min for all cases.\n        # quad handles the case where lower bound > upper bound, returning 0.\n        F_log_thr, _ = quad(pdf_log, r_min, integration_upper_bound, args=(k, E, b))\n        \n        # Sensitivity Difference S\n        S = F_log_thr - F_flat_thr\n\n        # --- Compute 95% Upper Credible Bounds and R_95 ---\n        target_quantile = 0.95\n\n        # Function for root-finding: CDF(r) - target_quantile = 0\n        def cdf_minus_target_flat(r_val):\n            integral, _ = quad(pdf_flat, 0, r_val, args=(k, E, b))\n            return integral - target_quantile\n        \n        def cdf_minus_target_log(r_val):\n            integral, _ = quad(pdf_log, r_min, r_val, args=(k, E, b))\n            return integral - target_quantile\n\n        # Use brentq to find the roots (credible bounds)\n        # The function values at the endpoints of the support [a,b] are\n        # F(a)-0.95 = -0.95 and F(b)-0.95 = 1-0.95 = 0.05, so a root is bracketed.\n        r95_flat = brentq(cdf_minus_target_flat, 0, r_max)\n        r95_log = brentq(cdf_minus_target_log, r_min, r_max)\n\n        # Ratio of upper bounds\n        R95 = r95_log / r95_flat\n        \n        # Append results for this case\n        all_results.extend([F_flat_thr, F_log_thr, S, R95])\n\n    # Print results in the specified single-line format\n    print(f\"[{','.join(f'{x:.8f}' for x in all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "真实的实验数据往往是不完美的，其中一个典型挑战是由于仪器探测阈值存在而产生的“删失数据”（censored data）。本练习将引导您处理这类复杂情况，即我们只知道某些测量值低于一个特定阈值，但不知道其确切数值。您将学习如何正确地构建似然函数以包含这些删失信息，这打破了标准共轭模型的简洁性，并要求使用数值方法来展示贝叶斯框架处理复杂真实世界数据结构的灵活性和强大能力 。",
            "id": "3544560",
            "problem": "一个核计数实验在固定的采集门内观测独立发射量子的到达，在源是稳恒的假设下，该过程被建模为泊松过程。设门 $i$ 内的计数为随机变量 $Y_i$，且 $Y_i \\sim \\text{Poisson}(\\lambda_i)$，其中 $\\lambda_i = r\\,t_i$，$r$ 是未知的恒定速率，单位为计数/秒 (s$^{-1}$)，$t_i$ 是门的持续时间，单位为秒。仪器设定了一个探测限，仅当 $Y_i \\ge L_i$ 时记录一个解析计数；否则，它记录一个表示 $Y_i  L_i$ 的删失事件。为使用低计数数据进行校准，我们对速率采用伽马先验，$r \\sim \\text{Gamma}(\\alpha,\\beta)$（形状-速率参数化），其密度为 $p(r) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} r^{\\alpha - 1} e^{-\\beta r}$，当 $r > 0$ 时。给定那些 $Y_i \\ge L_i$ 的门的观测计数和那些 $Y_i  L_i$ 的门的删失观测，推导速率 $r$ 的后验均值的贝叶斯估计量，并计算 $r$ 超过指定校准阈值 $r_0$ 的后验尾部概率。你的推导必须从泊松过程的定义和贝叶斯法则开始，并且不应假设共轭性，因为删失破坏了通常的泊松-伽马共轭性。你必须通过在 $r \\in (0,\\infty)$ 上进行数值积分来获得后验归一化。\n\n你的程序必须：\n$$\np(r \\mid \\text{data}) \\propto p(r)\\,\\prod_{i \\in \\mathcal{O}} \\Pr(Y_i = y_i \\mid r t_i)\\,\\prod_{j \\in \\mathcal{C}} \\Pr(Y_j  L_j \\mid r t_j)\n$$\n- 实现以上未归一化的后验密度，其中 $\\mathcal{O}$ 是 $y_i \\ge L_i$ 的观测计数的索引集，$\\mathcal{C}$ 是删失门的索引集。\n- 使用数值求积法计算后验归一化常数、后验均值 $\\mathbb{E}[r \\mid \\text{data}]$ 和尾部概率 $\\Pr(r > r_0 \\mid \\text{data})$。\n- 将速率的最终答案以计数/秒 (s$^{-1}$) 表示，尾部概率以小数（而非百分比）表示。\n\n基本原理：\n- 速率为 $r$ 的泊松过程意味着，对于持续时间为 $t$ 的门，计数分布为 $Y \\sim \\text{Poisson}(\\lambda)$，其中 $\\lambda = r t$。其概率质量函数为 $\\Pr(Y = y \\mid \\lambda) = e^{-\\lambda}\\frac{\\lambda^y}{y!}$，对于整数 $y \\ge 0$。\n- 对于探测限为 $L$ 的删失门，似然贡献是 $\\Pr(Y  L \\mid \\lambda) = \\sum_{k=0}^{L-1} e^{-\\lambda}\\frac{\\lambda^k}{k!}$，这是在 $L-1$ 处求值的泊松累积分布函数。\n- 贝叶斯法则意味着 $p(r \\mid \\text{data}) \\propto p(r)\\cdot \\text{likelihood}(\\text{data} \\mid r)$。\n\n测试套件：\n提供一组三个科学上合理的测试用例，涵盖典型和边缘情况。对每个用例，指明 $(\\alpha,\\beta)$、阈值 $r_0$（单位 s$^{-1}$）、解析事件的观测计数和门时间，以及删失事件的探测限和门时间。\n\n- 用例1（混合解析和删失，中等速率）：$\\alpha = 2.0$，$\\beta = 10.0$，$r_0 = 0.25$，观测门：$(t, y)$ 对 $[(10.0, 3), (20.0, 6), (15.0, 4)]$，这些门的 $L = 3$；删失门：$(t, L)$ 对 $[(5.0, 3), (2.0, 3)]$。\n- 用例2（全部删失，低速率边界）：$\\alpha = 1.5$，$\\beta = 8.0$，$r_0 = 0.20$，观测门：无；删失门：$(t, L)$ 对 $[(10.0, 2), (10.0, 2), (10.0, 2)]$。\n- 用例3（大部分解析，高速率）：$\\alpha = 3.0$，$\\beta = 5.0$，$r_0 = 1.0$，观测门：$(t, y)$ 对 $[(5.0, 10), (5.0, 14)]$，这些门的 $L = 3$；删失门：$(t, L)$ 对 $[(2.0, 5)]$。\n\n每个用例所需的输出：\n- 后验均值 $\\mathbb{E}[r \\mid \\text{data}]$，单位 s$^{-1}$。\n- 后验尾部概率 $\\Pr(r > r_0 \\mid \\text{data})$，以小数表示。\n\n最终输出格式：\n你的程序应生成单行输出，包含一个由列表组成的逗号分隔列表形式的结果，每个内部列表对应一个用例，其中包含后验均值和尾部概率（按此顺序）。例如，格式必须像 $[[m_1,p_1],[m_2,p_2],[m_3,p_3]]$，其中每个 $m_i$ 和 $p_i$ 都是浮点数。不应打印任何其他文本。",
            "solution": "目标是针对泊松过程的速率参数 $r$ 进行贝叶斯推断，给定一个由完全观测到的计数和删失观测组成的数据集。我们将推导 $r$ 的后验分布，并用它来计算后验均值和尾部概率。\n\n### 1. 贝叶斯框架\n给定观测数据，速率 $r$ 的后验概率密度函数 (PDF) 由贝叶斯法则导出：\n$$\np(r \\mid \\text{data}) = \\frac{p(\\text{data} \\mid r) \\, p(r)}{p(\\text{data})} \\propto p(\\text{data} \\mid r) \\, p(r)\n$$\n其中 $p(r)$ 是速率的先验分布，$p(\\text{data} \\mid r)$ 是在给定速率下观测到数据的似然，分母 $p(\\text{data})$ 是边缘似然或证据，它作为一个归一化常数。我们的分析将集中在未归一化的后验上，$\\tilde{p}(r \\mid \\text{data}) \\propto p(\\text{data} \\mid r) \\, p(r)$。\n\n### 2. 先验分布\n如指定，速率参数 $r$ 被赋予伽马先验分布，$r \\sim \\text{Gamma}(\\alpha, \\beta)$（形状-速率参数化）。其概率密度函数为：\n$$\np(r) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} r^{\\alpha - 1} e^{-\\beta r} \\quad \\text{for } r > 0\n$$\n其中 $\\alpha$ 是形状参数，$\\beta$ 是速率参数。\n\n### 3. 似然函数\n实验数据包括两组不同的独立观测：\n1.  一组解析计数，$\\mathcal{O} = \\{ (t_i, y_i) \\}$，其中在持续时间为 $t_i$ 的门内的计数 $y_i$ 是已知的，且 $y_i \\ge L_i$。\n2.  一组删失门，$\\mathcal{C} = \\{ (t_j, L_j) \\}$，其中在持续时间为 $t_j$ 的门内的计数 $Y_j$ 仅已知小于探测限 $L_j$。\n\n总似然函数 $\\mathcal{L}(\\text{data} \\mid r)$ 是每个独立观测概率的乘积：\n$$\n\\mathcal{L}(\\text{data} \\mid r) = \\left( \\prod_{i \\in \\mathcal{O}} \\Pr(Y_i = y_i \\mid r) \\right) \\left( \\prod_{j \\in \\mathcal{C}} \\Pr(Y_j  L_j \\mid r) \\right)\n$$\n\n对于来自持续时间为 $t_i$ 的门的解析计数 $y_i$，计数 $Y_i$ 服从均值为 $\\lambda_i = r t_i$ 的泊松分布。其概率由泊松概率质量函数 (PMF) 给出：\n$$\n\\Pr(Y_i = y_i \\mid r) = \\frac{(r t_i)^{y_i} e^{-r t_i}}{y_i!}\n$$\n\n对于来自持续时间为 $t_j$、探测限为 $L_j$ 的门的删失观测，我们知道计数 $Y_j  L_j$。此事件的概率是从 $0$ 到 $L_j-1$ 的所有整数计数的泊松概率之和：\n$$\n\\Pr(Y_j  L_j \\mid r) = \\sum_{k=0}^{L_j-1} \\Pr(Y_j = k \\mid r) = \\sum_{k=0}^{L_j-1} \\frac{(r t_j)^k e^{-r t_j}}{k!}\n$$\n这个表达式是均值为 $\\lambda_j = r t_j$ 的泊松分布的累积分布函数 (CDF)，在整数 $L_j-1$ 处求值。我们将其表示为 $F_{\\text{Poisson}}(L_j-1; r t_j)$。\n\n### 4. 未归一化的后验分布\n未归一化的后验密度 $\\tilde{p}(r \\mid \\text{data})$ 与先验和似然的乘积成正比。我们可以舍去任何不依赖于 $r$ 的因子。\n$$\n\\tilde{p}(r \\mid \\text{data}) \\propto (r^{\\alpha - 1} e^{-\\beta r}) \\times \\left( \\prod_{i \\in \\mathcal{O}} (r t_i)^{y_i} e^{-r t_i} \\right) \\times \\left( \\prod_{j \\in \\mathcal{C}} F_{\\text{Poisson}}(L_j-1; r t_j) \\right)\n$$\n为了方便数值计算，使用后验的对数形式更为稳定。对数未归一化后验为：\n$$\n\\ln \\tilde{p}(r \\mid \\text{data}) = \\ln p(r) + \\sum_{i \\in \\mathcal{O}} \\ln \\Pr(Y_i = y_i \\mid r) + \\sum_{j \\in \\mathcal{C}} \\ln \\Pr(Y_j  L_j \\mid r) + \\text{const.}\n$$\n代入表达式并对包含 $r$ 的项进行分组：\n$$\n\\ln \\tilde{p}(r \\mid \\text{data}) = (\\alpha-1)\\ln r - \\beta r + \\sum_{i \\in \\mathcal{O}}(y_i \\ln r - r t_i) + \\sum_{j \\in \\mathcal{C}} \\ln F_{\\text{Poisson}}(L_j-1; r t_j) + \\text{const.}\n$$\n令 $Y_{obs} = \\sum_{i \\in \\mathcal{O}} y_i$ 和 $T_{obs} = \\sum_{i \\in \\mathcal{O}} t_i$。表达式简化为：\n$$\n\\ln \\tilde{p}(r \\mid \\text{data}) = (\\alpha + Y_{obs} - 1)\\ln r - (\\beta + T_{obs})r + \\sum_{j \\in \\mathcal{C}} \\ln F_{\\text{Poisson}}(L_j-1; r t_j)\n$$\n$\\ln F_{\\text{Poisson}}(k; \\lambda)$ 项在科学计算库中作为对数累积分布函数 (log-CDF) 实现，其内部计算 $\\ln(\\sum_{i=0}^k e^{-\\lambda} \\lambda^i/i!) = -\\lambda + \\ln(\\sum_{i=0}^k \\lambda^i/i!)$。因此，通过使用对数累积分布函数，来自删失数据的指数项被正确地纳入计算。\n\n### 5. 后验量的计算\n归一化的后验密度为 $p(r \\mid \\text{data}) = \\tilde{p}(r \\mid \\text{data}) / Z$，其中归一化常数（证据）为 $Z = \\int_0^\\infty \\tilde{p}(r \\mid \\text{data}) \\, dr$。我们感兴趣的量是作为积分之比来计算的，这使得它们与 $\\tilde{p}(r \\mid \\text{data})$ 的归一化无关。\n\n$r$ 的后验均值是其关于后验分布的期望：\n$$\n\\mathbb{E}[r \\mid \\text{data}] = \\int_0^\\infty r \\, p(r \\mid \\text{data}) \\, dr = \\frac{\\int_0^\\infty r \\, \\tilde{p}(r \\mid \\text{data}) \\, dr}{\\int_0^\\infty \\tilde{p}(r \\mid \\text{data}) \\, dr}\n$$\n\n$r$ 超过阈值 $r_0$ 的后验尾部概率是：\n$$\n\\Pr(r > r_0 \\mid \\text{data}) = \\int_{r_0}^\\infty p(r \\mid \\text{data}) \\, dr = \\frac{\\int_{r_0}^\\infty \\tilde{p}(r \\mid \\text{data}) \\, dr}{\\int_0^\\infty \\tilde{p}(r \\mid \\text{data}) \\, dr}\n$$\n\n### 6. 数值策略\n泊松累积分布函数项的存在破坏了伽马-泊松模型的共轭性，并且这些积分没有闭式解。因此，我们采用数值求积法。计算过程是：\n1.  实现一个用于计算对数未归一化后验 $\\ln \\tilde{p}(r \\mid \\text{data})$ 的函数，使用稳健的库函数来计算泊松分布的对数累积分布函数。\n2.  为了增强积分的数值稳定性，特别是为了避免对大的负数取指数时发生下溢，我们对被积函数进行缩放。我们首先通过数值最大化 $\\ln \\tilde{p}(r \\mid \\text{data})$ 来找到后验的众数 $r_{MAP}$。令最大值为 $L_{max} = \\ln \\tilde{p}(r_{MAP} \\mid \\text{data})$。\n3.  定义一个经过缩放的、数值稳定的、未归一化的后验为 $\\tilde{p}_{scaled}(r) = \\exp(\\ln \\tilde{p}(r \\mid \\text{data}) - L_{max})$。该函数保证其最大值为 $1$。\n4.  所需的积分使用 $\\tilde{p}_{scaled}(r)$ 计算。缩放常数 $e^{-L_{max}}$ 在计算后验均值和尾部概率的比率时被抵消。例如，后验均值计算如下：\n$$\n\\mathbb{E}[r \\mid \\text{data}] = \\frac{\\int_0^\\infty r \\, \\tilde{p}_{scaled}(r) \\, dr}{\\int_0^\\infty \\tilde{p}_{scaled}(r) \\, dr}\n$$\n这种方法确保了后验量的精确计算。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import poisson\nfrom scipy.integrate import quad\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Main solver function that processes test cases and prints the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"alpha\": 2.0, \"beta\": 10.0, \"r0\": 0.25,\n            \"observed\": [(10.0, 3), (20.0, 6), (15.0, 4)],\n            \"censored\": [(5.0, 3), (2.0, 3)],\n        },\n        {\n            \"alpha\": 1.5, \"beta\": 8.0, \"r0\": 0.20,\n            \"observed\": [],\n            \"censored\": [(10.0, 2), (10.0, 2), (10.0, 2)],\n        },\n        {\n            \"alpha\": 3.0, \"beta\": 5.0, \"r0\": 1.0,\n            \"observed\": [(5.0, 10), (5.0, 14)],\n            \"censored\": [(2.0, 5)],\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Calculate the posterior mean and tail probability for each case\n        result = _process_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _process_case(case_data):\n    \"\"\"\n    Computes the posterior mean and tail probability for a single case.\n    \"\"\"\n    alpha = case_data[\"alpha\"]\n    beta = case_data[\"beta\"]\n    r0 = case_data[\"r0\"]\n    observed = case_data[\"observed\"]\n    censored = case_data[\"censored\"]\n\n    # Pre-compute sums from the data for efficiency\n    Y_obs = sum(y for t, y in observed)\n    T_obs = sum(t for t, y in observed)\n\n    def log_unnorm_posterior(r):\n        \"\"\"\n        Computes the log of the unnormalized posterior density.\n        The function is proportional to p(r) * L(data|r).\n        Constant terms independent of r are dropped.\n        \"\"\"\n        if r == 0:\n            return -np.inf\n        \n        # Contribution from prior and observed data likelihood\n        log_p = (alpha + Y_obs - 1) * np.log(r) - (beta + T_obs) * r\n        \n        # Contribution from censored data likelihood\n        for t_j, L_j in censored:\n            lambda_j = r * t_j\n            # The likelihood contribution is P(Y  L_j) = CDF(L_j - 1),\n            # which is the Poisson CDF evaluated at L_j - 1.\n            # Using logcdf provides better numerical stability.\n            log_p += poisson.logcdf(L_j - 1, mu=lambda_j)\n            \n        return log_p\n\n    # Find the posterior mode to determine a scaling factor for numerical integration.\n    # This scaling prevents numerical underflow in the integrator.\n    if T_obs > 0 and Y_obs > 0:\n        crude_rate_est = Y_obs / T_obs\n    else:\n        crude_rate_est = alpha / beta\n    \n    # Use a bounded optimizer to find the maximum of the log posterior (minimum of its negative).\n    opt_res = minimize_scalar(\n        lambda r: -log_unnorm_posterior(r),\n        bounds=(0, crude_rate_est * 20 + 1), # A generous but safe upper bound.\n        method='bounded'\n    )\n    \n    log_max_val = -opt_res.fun\n\n    # Define the scaled posterior to have a maximum value of 1.\n    def scaled_posterior(r):\n        val = log_unnorm_posterior(r)\n        if np.isneginf(val):\n            return 0.0\n        return np.exp(val - log_max_val)\n\n    # Define the integrand for calculating the numerator of the posterior mean.\n    def mean_integrand(r):\n        return r * scaled_posterior(r)\n\n    # Perform numerical integrations over r in (0, inf).\n    # The 'limit' parameter is increased for potentially complex integrands.\n    Z, _ = quad(scaled_posterior, 0, np.inf, limit=100)\n    mean_num, _ = quad(mean_integrand, 0, np.inf, limit=100)\n    tail_num, _ = quad(scaled_posterior, r0, np.inf, limit=100)\n\n    # Calculate final results by taking ratios of the integrals.\n    posterior_mean = mean_num / Z\n    tail_probability = tail_num / Z\n\n    return [posterior_mean, tail_probability]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "建立并拟合一个模型仅仅是贝叶斯工作流的第一步，批判性地评估模型的拟合优度和有效性同样至关重要。本实践将带您进入模型检验的核心环节，通过“后验预测检验”（Posterior Predictive Checks, PPCs）来诊断模型可能存在的不足。您将为一个核物理光学模型的代理模型生成模拟数据，并计算一系列诊断统计量，通过将模型的预测与观测数据进行比较，学会如何发现和理解模型的失效之处 。",
            "id": "3544558",
            "problem": "您将要为核子-原子核弹性散射光学模型势在不同实验室能量下的代理模型实现后验预测检验。目标是使用数学上定义的差异度量和均匀性诊断方法，来量化后验预测分布在各个能量范围内的校准度和覆盖率。所有计算必须被完全指定且可复现。\n\n基本基础和模型。假设一个依赖于能量的观测量（例如，固定角度下的微分弹性截面，单位为毫靶/球面度）有一个线性高斯代理模型。设实验室能量为 $E_{j}$（单位为 $\\text{MeV}$），其中 $j \\in \\{1,\\dots,n\\}$。定义能量 $E$ 处的回归向量为\n$$\n\\mathbf{x}(E) = \\begin{bmatrix} 1 \\\\ E^{-1} \\\\ \\exp(-E/E_{0}) \\end{bmatrix},\n$$\n其中 $E_{0} > 0$ 是一个已知尺度。设 $\\boldsymbol{\\theta} \\in \\mathbb{R}^{3}$ 表示未知的回归系数。观测模型为\n$$\ny_{j} = \\mathbf{x}(E_{j})^{\\top} \\boldsymbol{\\theta} + \\varepsilon_{j}, \\quad \\varepsilon_{j} \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^{2}),\n$$\n其中 $\\sigma > 0$ 是已知的，而 $y_{j}$ 是观测到的截面（单位为 $\\text{mb}\\,\\text{sr}^{-1}$）。对 $\\boldsymbol{\\theta}$ 设置一个高斯先验：\n$$\n\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\mathbf{m}_{0}, \\mathbf{V}_{0}),\n$$\n其中 $\\mathbf{V}_{0}$ 是一个对角线元素严格为正的对角协方差矩阵。设 $\\mathbf{X} \\in \\mathbb{R}^{n \\times 3}$ 为设计矩阵，其行向量为 $\\mathbf{x}(E_{j})^{\\top}$，$\\mathbf{y} \\in \\mathbb{R}^{n}$ 为数据向量。在此共轭线性高斯模型下，后验分布为\n$$\n\\boldsymbol{\\theta} \\mid \\mathbf{y} \\sim \\mathcal{N}(\\mathbf{m}_{n}, \\mathbf{V}_{n}), \\quad \\mathbf{V}_{n} = \\left(\\mathbf{V}_{0}^{-1} + \\frac{1}{\\sigma^{2}} \\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1}, \\quad \\mathbf{m}_{n} = \\mathbf{V}_{n} \\left(\\mathbf{V}_{0}^{-1} \\mathbf{m}_{0} + \\frac{1}{\\sigma^{2}} \\mathbf{X}^{\\top} \\mathbf{y}\\right).\n$$\n在能量 $E_{j}$ 处的后验预测分布是高斯分布：\n$$\ny_{j}^{\\ast} \\mid \\mathbf{y} \\sim \\mathcal{N}\\!\\left(\\mu_{j}^{\\text{pred}}, \\, s_{j}^{2,\\text{pred}}\\right), \\quad \\mu_{j}^{\\text{pred}} = \\mathbf{x}(E_{j})^{\\top} \\mathbf{m}_{n}, \\quad s_{j}^{2,\\text{pred}} = \\sigma^{2} + \\mathbf{x}(E_{j})^{\\top} \\mathbf{V}_{n} \\mathbf{x}(E_{j}).\n$$\n\n用于后验预测检验的差异度量。定义一个由参数抽样 $\\boldsymbol{\\theta}$ 索引的差异：\n$$\nT(\\mathbf{y}, \\boldsymbol{\\theta}) = \\sum_{j=1}^{n} \\frac{\\left(y_{j} - \\mathbf{x}(E_{j})^{\\top} \\boldsymbol{\\theta}\\right)^{2}}{\\sigma^{2}},\n$$\n并且，对于在相同能量下抽样的后验预测复制品 $\\tilde{\\mathbf{y}}$，定义\n$$\nT(\\tilde{\\mathbf{y}}, \\boldsymbol{\\theta}) = \\sum_{j=1}^{n} \\frac{\\left(\\tilde{y}_{j} - \\mathbf{x}(E_{j})^{\\top} \\boldsymbol{\\theta}\\right)^{2}}{\\sigma^{2}}.\n$$\n后验预测p值为\n$$\np_{B} = \\mathbb{P}\\!\\left( T(\\tilde{\\mathbf{y}}, \\boldsymbol{\\theta}) \\ge T(\\mathbf{y}, \\boldsymbol{\\theta}) \\mid \\mathbf{y} \\right),\n$$\n通过蒙特卡洛方法近似，即通过抽取 $\\boldsymbol{\\theta}^{(i)} \\sim \\mathcal{N}(\\mathbf{m}_{n}, \\mathbf{V}_{n})$ 和 $\\tilde{\\mathbf{y}}^{(i)} \\mid \\boldsymbol{\\theta}^{(i)} \\sim \\mathcal{N}(\\mathbf{X}\\boldsymbol{\\theta}^{(i)}, \\sigma^{2}\\mathbf{I}_{n})$，然后对指示函数 $\\mathbb{I}\\{T(\\tilde{\\mathbf{y}}^{(i)}, \\boldsymbol{\\theta}^{(i)}) \\ge T(\\mathbf{y}, \\boldsymbol{\\theta}^{(i)})\\}$ 求平均。\n\n跨能量的覆盖率和校准度。对于一个名义中心预测区间水平 $c \\in (0,1)$，定义单侧尾部概率 $\\alpha = (1-c)/2$。在能量 $E_j$ 处的中心预测区间为\n$$\n\\left[\\mu_{j}^{\\text{pred}} - z_{1-\\alpha} s_{j}^{\\text{pred}},\\ \\mu_{j}^{\\text{pred}} + z_{1-\\alpha} s_{j}^{\\text{pred}}\\right],\n$$\n其中 $z_{q}$ 是标准正态分布的 $q$-分位数。水平 $c$ 下的经验覆盖率是指 $y_j$ 落在此区间内的 $j \\in \\{1,\\dots,n\\}$ 的比例。\n\n通过概率积分变换进行校准。为每个能量 $E_j$ 定义概率积分变换为\n$$\nu_{j} = \\Phi\\!\\left(\\frac{y_{j} - \\mu_{j}^{\\text{pred}}}{s_{j}^{\\text{pred}}}\\right),\n$$\n其中 $\\Phi$ 是标准正态累积分布函数。在良好校准的预测下，多重集 $\\{u_{j}\\}_{j=1}^{n}$ 近似独立同分布于 $[0,1]$ 上的均匀分布。使用 Kolmogorov–Smirnov 统计量来量化与均匀性的偏差\n$$\nD_{n} = \\sup_{t \\in [0,1]} \\left| \\hat{F}_{n}(t) - t \\right|,\n$$\n其中 $\\hat{F}_{n}$ 是 $\\{u_{j}\\}_{j=1}^{n}$ 的经验累积分布函数。\n\n数据生成和单位。对于下面的每个测试用例，从一个固定的“真实”参数向量 $\\boldsymbol{\\theta}^{\\text{true}}$ 和指定的噪声水平 $\\sigma$ 生成合成数据。具体来说，对每个用例，定义 $n$ 个从 $E_{\\min}$ 到 $E_{\\max}$（单位均为 $\\text{MeV}$）等距分布的能量 $E_j$，构建 $\\mathbf{X}$，计算无噪声均值 $\\mathbf{X}\\boldsymbol{\\theta}^{\\text{true}}$，并添加标准差为 $\\sigma$ 的高斯噪声以获得 $\\mathbf{y}$。截面 $y_j$ 的单位是 $\\text{mb}\\,\\text{sr}^{-1}$；能量 $E_j$ 的单位是 $\\text{MeV}$。所需的输出是无量纲小数（无物理单位）。角度不出现。所有随机数生成必须使用指定的种子以保证可复现性。\n\n测试套件。使用以下3个用例，每个用例的能量 $E_j$ 均在从 $E_{\\min}$ 到 $E_{\\max}$ 的 $n$ 个点的等距网格上，并使用相同的尺度 $E_0$。对于所有用例，设置 $E_{0} = 20\\,\\text{MeV}$ 和 $\\boldsymbol{\\theta}^{\\text{true}} = \\begin{bmatrix} 10 \\\\ 350 \\\\ 90 \\end{bmatrix}$（这会产生一个随能量增加而物理上合理的下降趋势）。对于 $p_B$ 的蒙特卡洛近似，使用 $M = 8000$ 次后验抽样。数据模拟使用一个带有固定种子的 NumPy 随机数生成器，后验预测模拟则使用另一个指定的固定种子。\n\n- 用例 A (理想路径)：$n = 21$，$E_{\\min} = 5\\,\\text{MeV}$，$E_{\\max} = 40\\,\\text{MeV}$，$\\sigma = 3\\,\\text{mb}\\,\\text{sr}^{-1}$，先验均值 $\\mathbf{m}_{0} = \\begin{bmatrix} 12 \\\\ 300 \\\\ 100 \\end{bmatrix}$，先验标准差 $\\begin{bmatrix} 30 \\\\ 100 \\\\ 50 \\end{bmatrix}$ (因此 $\\mathbf{V}_{0} = \\mathrm{diag}(30^{2}, 100^{2}, 50^{2})$)。数据生成种子 $s_{\\text{data}} = 2468$，后验预测种子 $s_{\\text{ppc}} = 112233$。\n\n- 用例 B (因紧凑且有偏的先验和低噪声导致的边界覆盖不足)：$n = 21$，$E_{\\min} = 5\\,\\text{MeV}$，$E_{\\max} = 40\\,\\text{MeV}$，$\\sigma = 1\\,\\text{mb}\\,\\text{sr}^{-1}$，先验均值 $\\mathbf{m}_{0} = \\begin{bmatrix} 30 \\\\ 150 \\\\ 30 \\end{bmatrix}$，先验标准差 $\\begin{bmatrix} 5 \\\\ 20 \\\\ 5 \\end{bmatrix}$ (因此 $\\mathbf{V}_{0} = \\mathrm{diag}(5^{2}, 20^{2}, 5^{2})$)。数据生成种子 $s_{\\text{data}} = 1357$，后验预测种子 $s_{\\text{ppc}} = 223344$。\n\n- 用例 C (高噪声和扩散先验的边缘情况)：$n = 21$，$E_{\\min} = 5\\,\\text{MeV}$，$E_{\\max} = 40\\,\\text{MeV}$，$\\sigma = 8\\,\\text{mb}\\,\\text{sr}^{-1}$，先验均值 $\\mathbf{m}_{0} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$，先验标准差 $\\begin{bmatrix} 100 \\\\ 300 \\\\ 120 \\end{bmatrix}$ (因此 $\\mathbf{V}_{0} = \\mathrm{diag}(100^{2}, 300^{2}, 120^{2})$)。数据生成种子 $s_{\\text{data}} = 9876$，后验预测种子 $s_{\\text{ppc}} = 334455$。\n\n计算要求。对每个用例，执行以下操作。\n\n- 将 $E_{j}$（其中 $j \\in \\{1,\\dots,n\\}$）构建为从 $E_{\\min}$ 到 $E_{\\max}$（包含两端）的等距网格，单位为 $\\text{MeV}$。用行向量 $\\mathbf{x}(E_{j})^{\\top}$ 构成 $\\mathbf{X}$。使用指定的 $s_{\\text{data}}$、真实参数 $\\boldsymbol{\\theta}^{\\text{true}}$ 和噪声 $\\sigma$ 生成 $\\mathbf{y}$。\n\n- 计算 $(\\mathbf{m}_{n}, \\mathbf{V}_{n})$。\n\n- 为每个 $j$ 计算后验预测均值 $\\mu_{j}^{\\text{pred}}$ 和方差 $s_{j}^{2,\\text{pred}}$。\n\n- 使用 $M$ 次抽样和指定的 $s_{\\text{ppc}}$ 计算后验预测 $p$-值 $p_B$。\n\n- 使用解析高斯预测区间（即使用 $z_{0.95}$）计算中心水平 $c=0.9$ 时的经验覆盖率。\n\n- 使用精确的高斯预测分布，为概率积分变换 $u_j$ 计算 Kolmogorov–Smirnov 统计量 $D_n$。\n\n数值输出规范。您的程序必须生成单行输出，包含以下9个数字\n$$\n\\left[p_{B}^{(A)},\\ \\text{cov}_{0.9}^{(A)},\\ D_{n}^{(A)},\\ p_{B}^{(B)},\\ \\text{cov}_{0.9}^{(B)},\\ D_{n}^{(B)},\\ p_{B}^{(C)},\\ \\text{cov}_{0.9}^{(C)},\\ D_{n}^{(C)}\\right],\n$$\n四舍五入到6位小数，其中上标表示测试用例 A、B 和 C。每个数字都是一个无量纲小数值。程序必须精确地打印这个单一列表，形式为用方括号括起来的逗号分隔序列，不得包含任何额外文本。\n\n角度单位不被使用。能量在内部必须以 $\\text{MeV}$ 为单位处理，截面以 $\\text{mb}\\,\\text{sr}^{-1}$ 为单位处理，但最终输出是如上指定的无量纲小数。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如：$[\\text{result}_{1},\\text{result}_{2},\\text{result}_{3},\\dots]$）。",
            "solution": "该问题要求为核子-原子核弹性散射数据的贝叶斯线性高斯代理模型实现一系列后验预测检验。目标是为三个不同的测试用例计算三个诊断量：后验预测 p 值（$p_B$）、90% 预测区间的经验覆盖率（$\\text{cov}_{0.9}$），以及概率积分变换均匀性的 Kolmogorov-Smirnov 统计量（$D_n$）。该解决方案遵循一个基于所提供模型和定义的、有原则的、分步的计算过程。\n\n其基础模型是一个贝叶斯线性回归。能量 $E_j$ 处的观测量 $y_j$ 被建模为回归向量 $\\mathbf{x}(E_j) = [1, E^{-1}, \\exp(-E/E_0)]^\\top$ 的线性函数，其系数为 $\\boldsymbol{\\theta}$，并加上高斯噪声。模型被指定为：\n$$y_j = \\mathbf{x}(E_j)^\\top \\boldsymbol{\\theta} + \\varepsilon_j, \\quad \\varepsilon_j \\sim \\mathcal{N}(0, \\sigma^2)$$\n对系数 $\\boldsymbol{\\theta}$ 设置一个共轭高斯先验：$\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\mathbf{m}_0, \\mathbf{V}_0)$。该问题提供了后验分布 $\\boldsymbol{\\theta} | \\mathbf{y} \\sim \\mathcal{N}(\\mathbf{m}_n, \\mathbf{V}_n)$ 和后验预测分布 $y_j^* | \\mathbf{y} \\sim \\mathcal{N}(\\mu_j^{\\text{pred}}, s_j^{2, \\text{pred}})$ 的解析形式。\n\n每个测试用例的计算工作流如下：\n\n1.  **数据生成与模型设定**：对于每个用例，我们首先确定实验条件。实验室能量 $E_j$ 作为在 $E_{\\min}=5\\,\\text{MeV}$ 和 $E_{\\max}=40\\,\\text{MeV}$ 之间等距分布的 $n=21$ 个点生成。使用给定的尺度 $E_0 = 20\\,\\text{MeV}$，构建 $n \\times 3$ 的设计矩阵 $\\mathbf{X}$，其中第 $j$ 行为 $\\mathbf{x}(E_j)^\\top$。然后生成截面的合成数据 $\\mathbf{y}$。这是通过使用提供的 $\\boldsymbol{\\theta}^{\\text{true}} = [10, 350, 90]^\\top$ 计算真实均值 $\\mathbf{X}\\boldsymbol{\\theta}^{\\text{true}}$，并添加具有特定于每个用例的标准差 $\\sigma$ 的高斯噪声来实现的。一个固定的随机种子（$s_{\\text{data}}$）确保此数据生成过程是可复现的。\n\n2.  **后验参数推断**：有了数据 $\\mathbf{y}$ 和设计矩阵 $\\mathbf{X}$，我们计算 $\\boldsymbol{\\theta}$ 的后验分布参数。先验均值 $\\mathbf{m}_0$ 和对角协方差矩阵 $\\mathbf{V}_0$（由给定的先验标准差构建）与已知的噪声方差 $\\sigma^2$ 和数据一起使用。后验协方差 $\\mathbf{V}_n$ 和均值 $\\mathbf{m}_n$ 使用提供的公式计算：\n    $$ \\mathbf{V}_n = \\left(\\mathbf{V}_0^{-1} + \\frac{1}{\\sigma^2} \\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1} $$\n    $$ \\mathbf{m}_n = \\mathbf{V}_n \\left(\\mathbf{V}_0^{-1} \\mathbf{m}_0 + \\frac{1}{\\sigma^2} \\mathbf{X}^{\\top} \\mathbf{y}\\right) $$\n    这些计算涉及标准的矩阵运算，包括求逆和乘法。对于对角的先验协方差 $\\mathbf{V}_0$，其逆矩阵 $\\mathbf{V}_0^{-1}$ 可通过对其对角元素求倒数轻易获得。\n\n3.  **诊断量的计算**：\n\n    **a. 后验预测 $p$-值 ($p_B$):** 此量用于评估模型的整体失配。它是根据差异度量 $T(\\mathbf{d}, \\boldsymbol{\\theta})$，一个复制数据集 $\\tilde{\\mathbf{y}}$ 比观测数据集 $\\mathbf{y}$ 更极端的概率。问题指定了一个蒙特卡洛程序来估计 $p_B = \\mathbb{P}(T(\\tilde{\\mathbf{y}}, \\boldsymbol{\\theta}) \\ge T(\\mathbf{y}, \\boldsymbol{\\theta}) \\mid \\mathbf{y})$。实现如下：\n    - 从后验分布 $\\mathcal{N}(\\mathbf{m}_n, \\mathbf{V}_n)$ 中抽取 $M=8000$ 个样本 $\\boldsymbol{\\theta}^{(i)}$。所有后验模拟均使用专用的随机种子（$s_{\\text{ppc}}$）。\n    - 对于每个样本 $\\boldsymbol{\\theta}^{(i)}$，计算观测数据的差异：$T(\\mathbf{y}, \\boldsymbol{\\theta}^{(i)}) = \\sum_{j=1}^n (y_j - \\mathbf{x}_j^\\top \\boldsymbol{\\theta}^{(i)})^2 / \\sigma^2$。\n    - 对于每个 $\\boldsymbol{\\theta}^{(i)}$，通过从 $\\mathcal{N}(\\mathbf{X}\\boldsymbol{\\theta}^{(i)}, \\sigma^2 \\mathbf{I}_n)$ 抽样生成一个复制数据集 $\\tilde{\\mathbf{y}}^{(i)}$。\n    - 对于每对 $(\\tilde{\\mathbf{y}}^{(i)}, \\boldsymbol{\\theta}^{(i)})$，计算复制数据的差异：$T(\\tilde{\\mathbf{y}}^{(i)}, \\boldsymbol{\\theta}^{(i)}) = \\sum_{j=1}^n (\\tilde{y}_j^{(i)} - \\mathbf{x}_j^\\top \\boldsymbol{\\theta}^{(i)})^2 / \\sigma^2$。\n    - $p$-值 $p_B$ 是满足 $T(\\tilde{\\mathbf{y}}^{(i)}, \\boldsymbol{\\theta}^{(i)}) \\ge T(\\mathbf{y}, \\boldsymbol{\\theta}^{(i)})$ 的样本所占的比例。\n\n    **b. 经验覆盖率 ($\\text{cov}_{0.9}$):** 此诊断用于检查预测不确定性是否被正确量化。首先，我们为每个数据点 $j$ 计算解析的后验预测均值 $\\mu_j^{\\text{pred}} = \\mathbf{x}(E_j)^\\top \\mathbf{m}_n$ 和方差 $s_j^{2, \\text{pred}} = \\sigma^2 + \\mathbf{x}(E_j)^\\top \\mathbf{V}_n \\mathbf{x}(E_j)$。对于名义水平 $c=0.9$，尾部概率为 $\\alpha = (1-0.9)/2 = 0.05$。每个 $y_j$ 的 $90\\%$ 中心预测区间为 $[\\mu_j^{\\text{pred}} - z_{0.95} s_j^{\\text{pred}}, \\mu_j^{\\text{pred}} + z_{0.95} s_j^{\\text{pred}}]$，其中 $s_j^{\\text{pred}}$ 是预测标准差，$z_{0.95} \\approx 1.645$ 是标准正态分布的第95百分位数。经验覆盖率是观测数据点 $y_j$ 落在其相应区间内的比例。\n\n    **c. Kolmogorov-Smirnov 统计量 ($D_n$):** 这用于评估预测分布的校准度。对于每个观测值 $y_j$，我们计算概率积分变换（PIT）值 $u_j = \\Phi((y_j - \\mu_j^{\\text{pred}})/s_j^{\\text{pred}})$，其中 $\\Phi$ 是标准正态累积分布函数（CDF）。如果模型完美校准，则值集合 $\\{u_j\\}_{j=1}^n$ 应与从 Uniform$[0,1]$ 分布抽取的样本无法区分。Kolmogorov-Smirnov 统计量 $D_n$ 测量 $\\{u_j\\}$ 的经验累积分布函数与均匀分布的累积分布函数 $F(t)=t$ 之间的最大绝对差。它使用 `scipy.stats.kstest` 进行计算。\n\n这整个计算序列对三个测试用例（A、B和C）中的每一个都执行一遍。得到的九个值（每个用例的 $p_B$、$\\text{cov}_{0.9}$ 和 $D_n$）被收集、格式化为六位小数，并作为单个逗号分隔的列表（用方括号括起）打印出来。该实现使用 `numpy` 进行高效的向量化数值计算，并使用 `scipy.stats` 提供诸如 `norm.ppf`、`norm.cdf` 和 `kstest` 等统计函数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    # Define common parameters across all cases\n    E0 = 20.0\n    theta_true = np.array([10.0, 350.0, 90.0])\n    M = 8000  # Number of Monte Carlo draws for p-value\n    c = 0.9  # Nominal coverage level\n\n    # Define the three test cases\n    test_cases = [\n        # Case A: Happy path with a reasonable prior and moderate noise\n        {\n            'name': 'A', 'n': 21, 'E_min': 5.0, 'E_max': 40.0, 'sigma': 3.0,\n            'm0': np.array([12.0, 300.0, 100.0]),\n            'prior_stds': np.array([30.0, 100.0, 50.0]),\n            's_data': 2468, 's_ppc': 112233\n        },\n        # Case B: Boundary undercoverage due to a tight, biased prior and low noise\n        {\n            'name': 'B', 'n': 21, 'E_min': 5.0, 'E_max': 40.0, 'sigma': 1.0,\n            'm0': np.array([30.0, 150.0, 30.0]),\n            'prior_stds': np.array([5.0, 20.0, 5.0]),\n            's_data': 1357, 's_ppc': 223344\n        },\n        # Case C: Edge case with high noise and a diffuse prior\n        {\n            'name': 'C', 'n': 21, 'E_min': 5.0, 'E_max': 40.0, 'sigma': 8.0,\n            'm0': np.array([0.0, 0.0, 0.0]),\n            'prior_stds': np.array([100.0, 300.0, 120.0]),\n            's_data': 9876, 's_ppc': 334455\n        },\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        # Run the full analysis for one case\n        p_B, cov_09, D_n = run_case(case, E0, theta_true, M, c)\n        all_results.extend([p_B, cov_09, D_n])\n\n    # Format the results to 6 decimal places and print in the specified format\n    formatted_results = [f\"{res:.6f}\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_case(params, E0, theta_true, M, c):\n    \"\"\"\n    Performs the full Bayesian analysis for a single test case.\n\n    Args:\n        params (dict): A dictionary containing all parameters for the case.\n        E0 (float): The energy scale parameter.\n        theta_true (np.ndarray): The true parameter vector for data generation.\n        M (int): Number of Monte Carlo samples.\n        c (float): Nominal coverage level.\n\n    Returns:\n        tuple: A tuple containing (p_B, cov_0.9, D_n) for the case.\n    \"\"\"\n    n, E_min, E_max = params['n'], params['E_min'], params['E_max']\n    sigma, m0, prior_stds = params['sigma'], params['m0'], params['prior_stds']\n    s_data, s_ppc = params['s_data'], params['s_ppc']\n\n    # 1. Data Generation and Model Setup\n    data_rng = np.random.default_rng(s_data)\n    E_j = np.linspace(E_min, E_max, n, dtype=np.float64)\n    \n    # Construct the design matrix X\n    X = np.vstack([np.ones(n), 1.0 / E_j, np.exp(-E_j / E0)]).T\n\n    # Generate synthetic data y\n    y_mean_true = X @ theta_true\n    noise = data_rng.normal(0.0, sigma, n)\n    y = y_mean_true + noise\n\n    # 2. Posterior Parameter Inference\n    V0 = np.diag(prior_stds**2)\n    # Since V0 is diagonal, its inverse is the reciprocal of the diagonal elements\n    V0_inv = np.diag(1.0 / (prior_stds**2))\n    XTX = X.T @ X\n    \n    # Posterior covariance and mean\n    Vn = np.linalg.inv(V0_inv + (1.0 / sigma**2) * XTX)\n    mn = Vn @ (V0_inv @ m0 + (1.0 / sigma**2) * X.T @ y)\n\n    # 3. Analytic Posterior Predictive Mean and Variance\n    mu_pred = X @ mn\n    # Efficient calculation of diag(X @ Vn @ X.T)\n    s2_pred = sigma**2 + np.sum((X @ Vn) * X, axis=1)\n    s_pred = np.sqrt(s2_pred)\n\n    # 4. Compute Diagnostic Quantities\n\n    # 4a. Posterior Predictive p-value (p_B)\n    ppc_rng = np.random.default_rng(s_ppc)\n    # Draw M samples from the posterior distribution of theta\n    theta_samples = ppc_rng.multivariate_normal(mn, Vn, size=M)  # Shape: (M, 3)\n\n    # Predictions for each theta sample, shape: (n, M)\n    mu_pred_samples = X @ theta_samples.T\n    \n    # Discrepancy for observed data for each theta sample\n    residuals_y = y[:, np.newaxis] - mu_pred_samples  # Broadcasting y\n    T_y_samples = np.sum(residuals_y**2 / sigma**2, axis=0)  # Shape: (M,)\n\n    # Replicate data and compute discrepancy for replicated data\n    y_tilde_samples = ppc_rng.normal(loc=mu_pred_samples, scale=sigma)\n    residuals_y_tilde = y_tilde_samples - mu_pred_samples\n    T_y_tilde_samples = np.sum(residuals_y_tilde**2 / sigma**2, axis=0)\n\n    p_B = np.mean(T_y_tilde_samples >= T_y_samples)\n    \n    # 4b. Empirical Coverage (cov_0.9)\n    alpha = (1.0 - c) / 2.0\n    z_q = stats.norm.ppf(1.0 - alpha)  # Quantile for the central interval\n    \n    lower_bound = mu_pred - z_q * s_pred\n    upper_bound = mu_pred + z_q * s_pred\n    \n    # Count how many observed y_j are within their predictive intervals\n    covered_count = np.sum((y >= lower_bound)  (y = upper_bound))\n    cov_09 = covered_count / n\n    \n    # 4c. Kolmogorov-Smirnov Statistic (D_n)\n    # Calculate Probability Integral Transform (PIT) values\n    u_j = stats.norm.cdf((y - mu_pred) / s_pred)\n    \n    # Compute the KS statistic against a uniform distribution\n    D_n = stats.kstest(u_j, 'uniform').statistic\n\n    return p_B, cov_09, D_n\n\nsolve()\n```"
        }
    ]
}