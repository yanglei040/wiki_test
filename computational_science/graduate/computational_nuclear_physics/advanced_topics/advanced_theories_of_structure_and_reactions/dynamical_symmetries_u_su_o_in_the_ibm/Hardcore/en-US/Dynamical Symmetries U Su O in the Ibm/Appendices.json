{
    "hands_on_practices": [
        {
            "introduction": "The energy spectrum of a quantum system directly reflects the symmetries of its Hamiltonian. In the Interacting Boson Model, adding terms corresponding to Casimir operators of subgroups in a dynamical symmetry chain systematically lifts degeneracies in a predictable way. This exercise provides a foundational understanding of how the algebraic structure of the $U(5)$ limit dictates the pattern of energy levels, and by numerically verifying these patterns and diagnosing deviations, you will develop a crucial skill in linking theoretical Hamiltonians to observable spectral features .",
            "id": "3556532",
            "problem": "Consider the Interacting Boson Model (IBM) in the limit of the unitary group of dimension six, denoted by $U(6)$, with the standard dynamical symmetry chain $U(6) \\supset U(5) \\supset O(5) \\supset O(3)$. The relevant degrees of freedom are scalar $s$ bosons with angular momentum $L=0$ and quadrupole $d$ bosons with angular momentum $L=2$, with a fixed total boson number $N$. In the $U(5)$ dynamical symmetry limit, states are labeled by the chain quantum numbers $[N], n_d, \\tau, L$, where $n_d$ is the number of $d$ bosons, $\\tau$ is the $O(5)$ seniority, and $L$ is the total angular momentum.\n\nFundamental base:\n- The number operator for $d$ bosons $n_d$ counts the quadrupole bosons and has eigenvalue $n_d$.\n- The quadratic Casimir operator of $O(5)$ has eigenvalues $\\tau(\\tau+3)$ on $O(5)$ irreducible representations labeled by $\\tau$.\n- The quadratic Casimir operator of $O(3)$ has eigenvalues $L(L+1)$ on angular momentum multiplets labeled by $L$.\n- In the $U(5)$ limit, the Hamiltonian can be modeled as a linear combination of these commuting invariants without loss of generality for the purposes of classifying degeneracy patterns.\n\nLow-lying $U(5)$ multiplets are those with small $n_d$. Using the $U(5)\\to O(5)\\to O(3)$ branching rules for symmetric boson representations, the allowed $(\\tau,L)$ content for low-lying $n_d$ sectors is:\n- For $n_d=0$: $\\tau=0$ with $L=0$.\n- For $n_d=1$: $\\tau=1$ with $L=2$.\n- For $n_d=2$: $\\tau=0$ with $L=0$ and $\\tau=2$ with $L \\in \\{2,4\\}$.\n- For $n_d=3$: $\\tau=1$ with $L=2$ and $\\tau=3$ with $L \\in \\{0,2,3,4,6\\}$.\n\nStarting from these fundamental facts, derive analytically the degeneracy patterns in the energy spectrum implied by a Hamiltonian that depends only on $n_d$, and then show how adding terms proportional to the $O(5)$ and $O(3)$ Casimir operators lifts these degeneracies in predictable ways. Your derivation must proceed from the above base and must not assume or state intermediate shortcut formulas beyond the listed Casimir eigenvalues and branching content. Conclude with concrete counts of how many distinct $(\\tau,L)$ levels are degenerate within each $n_d$ multiplet for the low-lying sectors listed.\n\nThen, implement a numerical verification and diagnostic in a complete, runnable program. Model the Hamiltonian eigenvalues for basis states labeled by $(n_d,\\tau,L)$ as\n$$\nE(n_d,\\tau,L) = \\epsilon\\, n_d + \\alpha\\, \\tau(\\tau+3) + \\beta\\, L(L+1) + \\zeta\\, n_d\\,\\tau,\n$$\nwhere $\\epsilon$, $\\alpha$, $\\beta$, and $\\zeta$ are real coefficients. The last term $ \\zeta\\, n_d\\,\\tau$ encodes a generic hidden symmetry-breaking contribution that is not representable as a linear combination of the three Casimir eigenvalues used above.\n\nYour program must:\n- Enumerate all $(n_d,\\tau,L)$ states for $n_d \\in \\{0,1,2,3\\}$ according to the allowed content listed above, for any $N \\ge 3$.\n- Compute energies $E(n_d,\\tau,L)$ for each state under given model parameters.\n- Verify analytically predicted degeneracy patterns numerically under different parameter sets.\n- Diagnose hidden symmetry breaking by attempting a least-squares fit of the computed energies to the linear model\n$$\nE_{\\text{fit}}(n_d,\\tau,L) = a\\, n_d + b\\, \\tau(\\tau+3) + c\\, L(L+1),\n$$\nand reporting the Euclidean norm of the residuals $||E - E_{\\text{fit}}||_2$. A nonzero residual indicates contributions not captured by the linear Casimir combination and hence hidden symmetry-breaking terms.\n\nAll energies are to be treated in dimensionless units.\n\nTest Suite:\nUse the following parameter sets, each of which must be evaluated and reported by your program:\n1. Case $1$ (pure $U(5)$ number-operator Hamiltonian): $\\epsilon=1.0$, $\\alpha=0.0$, $\\beta=0.0$, $\\zeta=0.0$. Numerically verify that all states within each fixed $n_d$ are exactly degenerate. Report a boolean indicating whether this is satisfied within a tolerance of $10^{-12}$.\n2. Case $2$ ($O(5)$-split without $O(3)$ splitting): $\\epsilon=1.0$, $\\alpha=0.2$, $\\beta=0.0$, $\\zeta=0.0$. Numerically verify that states within each fixed $(n_d,\\tau)$ block are exactly degenerate and that states with different $\\tau$ at the same $n_d$ are split. Report a boolean indicating whether the $(n_d,\\tau)$ degeneracy within tolerance $10^{-12}$ holds.\n3. Case $3$ ($O(3)$-split included): $\\epsilon=1.0$, $\\alpha=0.2$, $\\beta=0.1$, $\\zeta=0.0$. Numerically verify that there are no degeneracies between distinct $(n_d,\\tau,L)$ levels (i.e., all energies are unique within tolerance $10^{-12}$). Report a boolean indicating whether all energies are unique.\n4. Case $4$ (hidden symmetry-breaking diagnostic): $\\epsilon=1.0$, $\\alpha=0.0$, $\\beta=0.0$, $\\zeta=0.05$. Compute the least-squares fit to $E_{\\text{fit}}(n_d,\\tau,L)$ and report the Euclidean norm of the residual vector as a floating-point number.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for the four test cases as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4]$), where $r_1$, $r_2$, and $r_3$ are booleans and $r_4$ is a floating-point number. No other output is permitted.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. The provided quantum numbers and branching rules, which form the basis for the calculation, are taken as definitional for this problem.\n\nThe problem requires an analytical derivation of degeneracy patterns in the $U(5)$ limit of the Interacting Boson Model (IBM) and a subsequent numerical verification. The states are labeled by the quantum numbers $(n_d, \\tau, L)$, where $n_d$ is the number of $d$-bosons, $\\tau$ is the $O(5)$ seniority, and $L$ is the angular momentum. The total boson number $N$ is a constant greater than or equal to $3$.\n\nThe basis of states to be considered, as specified for $n_d \\in \\{0, 1, 2, 3\\}$, is:\n- $n_d=0$: State $(\\tau, L) = (0, 0)$. One state.\n- $n_d=1$: State $(\\tau, L) = (1, 2)$. One state.\n- $n_d=2$: States $(\\tau, L) = (0, 0)$ and $(\\tau, L) = (2, \\{2, 4\\})$. Three states in total: $(2,0,0), (2,2,2), (2,2,4)$.\n- $n_d=3$: States $(\\tau, L) = (1, 2)$ and $(\\tau, L) = (3, \\{0, 2, 3, 4, 6\\})$. Six states in total: $(3,1,2), (3,3,0), (3,3,2), (3,3,3), (3,3,4), (3,3,6)$.\n\nThe model Hamiltonian's eigenvalues are given by the general form:\n$$\nE(n_d,\\tau,L) = \\epsilon\\, n_d + \\alpha\\, \\tau(\\tau+3) + \\beta\\, L(L+1)\n$$\nThis form arises from a Hamiltonian constructed as a linear combination of the number operator for $d$-bosons, $\\hat{n}_d$, and the quadratic Casimir operators of the groups $O(5)$ and $O(3)$, which are $\\hat{C}_2(O(5))$ and $\\hat{C}_2(O(3))$ respectively. Their eigenvalues are $n_d$, $\\tau(\\tau+3)$, and $L(L+1)$.\n\n**Analytical Derivation of Degeneracy Patterns**\n\n1.  **Pure $U(5)$ Number-Operator Hamiltonian:**\n    Let the Hamiltonian be $H_1 = \\epsilon \\hat{n}_d$. The energy eigenvalues are $E(n_d, \\tau, L) = \\epsilon n_d$. The energy depends solely on the number of $d$-bosons, $n_d$. Consequently, all states sharing the same $n_d$ value are degenerate, regardless of their $\\tau$ and $L$ values.\n    -   For $n_d=0$, there is $1$ state, $(0,0,0)$. This forms a singlet.\n    -   For $n_d=1$, there is $1$ state, $(1,1,2)$. This forms a singlet.\n    -   For $n_d=2$, there are $3$ distinct $(\\tau,L)$ states: $(2,0,0)$, $(2,2,2)$, and $(2,2,4)$. All have energy $2\\epsilon$ and are therefore degenerate. The degeneracy count of $(\\tau,L)$ levels is $3$.\n    -   For $n_d=3$, there are $6$ distinct $(\\tau,L)$ states: $(3,1,2)$, $(3,3,0)$, $(3,3,2)$, $(3,3,3)$, $(3,3,4)$, and $(3,3,6)$. All have energy $3\\epsilon$ and are degenerate. The degeneracy count of $(\\tau,L)$ levels is $6$.\n\n2.  **Lifting Degeneracy with the $O(5)$ Casimir Operator:**\n    Let the Hamiltonian be $H_2 = \\epsilon \\hat{n}_d + \\alpha \\hat{C}_2(O(5))$. The energy eigenvalues are $E(n_d, \\tau, L) = \\epsilon n_d + \\alpha \\tau(\\tau+3)$. The energy now depends on both $n_d$ and $\\tau$. The large degeneracies within each $n_d$ multiplet are partially lifted. States with a common pair of values $(n_d, \\tau)$ remain degenerate.\n    -   For $n_d=2$, the states are partitioned by $\\tau$. The state $(2,0,0)$ has energy $2\\epsilon$. The two states $(2,2,2)$ and $(2,2,4)$ both belong to $\\tau=2$ and share the energy $2\\epsilon + \\alpha(2)(2+3) = 2\\epsilon + 10\\alpha$. Thus, the 3-fold degeneracy of the $n_d=2$ multiplet is split into a singlet (for $\\tau=0$) and a doublet (for $\\tau=2$).\n    -   For $n_d=3$, the states are also partitioned by $\\tau$. The state $(3,1,2)$ belongs to $\\tau=1$ and has energy $3\\epsilon + \\alpha(1)(1+3) = 3\\epsilon + 4\\alpha$. The five states $(3,3,0)$, $(3,3,2)$, $(3,3,3)$, $(3,3,4)$, and $(3,3,6)$ all belong to $\\tau=3$ and share the energy $3\\epsilon + \\alpha(3)(3+3) = 3\\epsilon + 18\\alpha$. Thus, the 6-fold degeneracy of the $n_d=3$ multiplet is split into a singlet (for $\\tau=1$) and a quintuplet (for $\\tau=3$).\n\n3.  **Complete Lifting of Degeneracy with the $O(3)$ Casimir Operator:**\n    Let the Hamiltonian be $H_3 = \\epsilon \\hat{n}_d + \\alpha \\hat{C}_2(O(5)) + \\beta \\hat{C}_2(O(3))$. The energy eigenvalues are $E(n_d, \\tau, L) = \\epsilon n_d + \\alpha \\tau(\\tau+3) + \\beta L(L+1)$. The energy now depends on the unique triplet of quantum numbers $(n_d, \\tau, L)$ that labels each state in our basis.\n    -   The degeneracies within common $(n_d, \\tau)$ multiplets are now lifted by the term $\\beta L(L+1)$, as the states within these multiplets have different $L$ values. For example, for $(n_d, \\tau) = (2,2)$, the states with $L=2$ and $L=4$ acquire different energies: $E(2,2,2) = 2\\epsilon+10\\alpha+6\\beta$ and $E(2,2,4) = 2\\epsilon+10\\alpha+20\\beta$.\n    -   For generic, non-zero coefficients $(\\epsilon, \\alpha, \\beta)$, there will be no \"accidental\" degeneracies between states with different $(n_d, \\tau, L)$ triplets. Each of the $11$ states will have a unique energy.\n\n**Diagnosing Hidden Symmetry Breaking**\n\nThe problem introduces a Hamiltonian with an additional term:\n$$\nE(n_d,\\tau,L) = \\epsilon\\, n_d + \\alpha\\, \\tau(\\tau+3) + \\beta\\, L(L+1) + \\zeta\\, n_d\\,\\tau\n$$\nThe term $\\zeta\\, n_d\\,\\tau$ is not a linear combination of the eigenvalues of the Casimir operators of the $U(5) \\supset O(5) \\supset O(3)$ chain. Its presence indicates a source of symmetry breaking not captured by the simple Casimir form of the Hamiltonian.\n\nTo diagnose this, we can compute the energies $E$ using the full formula (with $\\zeta \\neq 0$) and then attempt to fit these energies using a model that omits the non-Casimir term:\n$$\nE_{\\text{fit}}(n_d,\\tau,L) = a\\, n_d + b\\, \\tau(\\tau+3) + c\\, L(L+1)\n$$\nThis is a linear least-squares problem. We seek coefficients $(a, b, c)$ that minimize the sum of squared residuals, $\\sum_i (E_i - E_{\\text{fit},i})^2$. If the term $\\zeta\\, n_d\\,\\tau$ were linearly dependent on the other three terms over the set of basis states, the fit would be perfect and the residuals would be zero. However, it is not. A non-zero value for the Euclidean norm of the residual vector, $||E - E_{\\text{fit}}||_2$, provides a quantitative measure of the \"hidden\" symmetry breaking introduced by the $\\zeta n_d \\tau$ term. A larger norm indicates a greater deviation from the pure dynamical symmetry structure.\n\nThis analytical framework provides clear, testable predictions for the numerical part of the problem.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the computational nuclear physics problem about the U(5) limit of the IBM.\n    \"\"\"\n    \n    # Define the basis states (nd, tau, L) as per the problem statement.\n    # The set of states for nd=3, tau=3 includes L=2 as specified.\n    states = [\n        (0, 0, 0),  # nd=0\n        (1, 1, 2),  # nd=1\n        (2, 0, 0), (2, 2, 2), (2, 2, 4),  # nd=2\n        (3, 1, 2), (3, 3, 0), (3, 3, 2), (3, 3, 3), (3, 3, 4), (3, 3, 6)  # nd=3\n    ]\n\n    # Define the parameters for the four test cases.\n    test_cases = [\n        {'eps': 1.0, 'alpha': 0.0, 'beta': 0.0, 'zeta': 0.0},  # Case 1\n        {'eps': 1.0, 'alpha': 0.2, 'beta': 0.0, 'zeta': 0.0},  # Case 2\n        {'eps': 1.0, 'alpha': 0.2, 'beta': 0.1, 'zeta': 0.0},  # Case 3\n        {'eps': 1.0, 'alpha': 0.0, 'beta': 0.0, 'zeta': 0.05}  # Case 4\n    ]\n\n    results = []\n    tol = 1e-12\n\n    # --- Case 1: Pure U(5) number-operator Hamiltonian ---\n    params = test_cases[0]\n    energies_c1 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n    \n    degeneracy_nd_holds = True\n    # Group states by nd\n    states_by_nd = {}\n    for i, state in enumerate(states):\n        nd = state[0]\n        if nd not in states_by_nd:\n            states_by_nd[nd] = []\n        states_by_nd[nd].append(energies_c1[i])\n    \n    for nd in states_by_nd:\n        if len(states_by_nd[nd]) > 1:\n            group_energies = np.array(states_by_nd[nd])\n            if np.max(group_energies) - np.min(group_energies) > tol:\n                degeneracy_nd_holds = False\n                break\n    results.append(degeneracy_nd_holds)\n\n    # --- Case 2: O(5)-split without O(3) splitting ---\n    params = test_cases[1]\n    energies_c2 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n\n    degeneracy_nd_tau_holds = True\n    # Group states by (nd, tau)\n    states_by_nd_tau = {}\n    for i, state in enumerate(states):\n        key = (state[0], state[1]) # (nd, tau)\n        if key not in states_by_nd_tau:\n            states_by_nd_tau[key] = []\n        states_by_nd_tau[key].append(energies_c2[i])\n\n    for key in states_by_nd_tau:\n        if len(states_by_nd_tau[key]) > 1:\n            group_energies = np.array(states_by_nd_tau[key])\n            if np.max(group_energies) - np.min(group_energies) > tol:\n                degeneracy_nd_tau_holds = False\n                break\n    results.append(degeneracy_nd_tau_holds)\n\n    # --- Case 3: O(3)-split included ---\n    params = test_cases[2]\n    energies_c3 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n    \n    sorted_energies = np.sort(energies_c3)\n    diffs = np.diff(sorted_energies)\n    all_unique = np.all(diffs > tol)\n    results.append(all_unique)\n\n    # --- Case 4: Hidden symmetry-breaking diagnostic ---\n    params = test_cases[3]\n    energies_c4 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n\n    # Construct the matrix A for the least-squares fit\n    # The columns are nd, tau*(tau+3), and L*(L+1)\n    A = np.zeros((len(states), 3))\n    for i, (nd, tau, L) in enumerate(states):\n        A[i, 0] = nd\n        A[i, 1] = tau * (tau + 3)\n        A[i, 2] = L * (L + 1)\n\n    # Perform the least-squares fit: Ax = y\n    # y is the vector of energies_c4\n    y = energies_c4\n    _, residuals, _, _ = np.linalg.lstsq(A, y, rcond=None)\n    \n    # The problem asks for the Euclidean norm of the residual vector\n    # lstsq returns the sum of squared residuals. We need its square root.\n    residual_norm = np.sqrt(residuals[0])\n    results.append(residual_norm)\n\n    # Print results in the specified single-line format\n    print(f\"[{results[0]},{results[1]},{results[2]},{results[3]}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A key goal of a physical model is to use a small set of experimental inputs to determine its free parameters, which then allows for the prediction of other observables. The $SU(3)$ limit of the IBM, describing rotational nuclei, provides a clear example of this process. This practice sharpens your ability to apply the algebraic formalism of the $SU(3)$ symmetry to solve a practical problem, and by determining the Hamiltonian parameters from known energy levels, you will see how the model's predictive power is unlocked to calculate other properties of the nucleus .",
            "id": "3556643",
            "problem": "In the Interacting Boson Model (IBM), consider the Special Unitary group of degree three ($SU(3)$) dynamical symmetry limit with boson number $N=10$. The Hamiltonian is taken to be\n$\nH \\;=\\; a\\,\\hat{C}_{2}\\!\\left[\\mathrm{SU}(3)\\right] \\;+\\; b\\,\\hat{C}_{2}\\!\\left[\\mathrm{O}(3)\\right],\n$\nwhere $\\hat{C}_{2}\\!\\left[\\mathrm{SU}(3)\\right]$ and $\\hat{C}_{2}\\!\\left[\\mathrm{O}(3)\\right]$ are the quadratic Casimir operators of $\\mathrm{SU}(3)$ and $\\mathrm{O}(3)$, respectively. The eigenvalue of $\\hat{C}_{2}\\!\\left[\\mathrm{SU}(3)\\right]$ in an irreducible representation labeled by $(\\lambda,\\mu)$ is\n$\nC_{2}(\\lambda,\\mu) \\;=\\; \\lambda^{2} \\,+\\, \\mu^{2} \\,+\\, \\lambda\\,\\mu \\,+\\, 3(\\lambda+\\mu),\n$\nand the eigenvalue of $\\hat{C}_{2}\\!\\left[\\mathrm{O}(3)\\right]$ in a state of angular momentum $L$ is\n$\nL(L+1).\n$\nIn the $\\mathrm{SU}(3)$ limit of the IBM with $N$ bosons, the ground-state band transforms as $(\\lambda,\\mu)=(2N,0)$, while the lowest $\\beta$ band transforms as $(\\lambda,\\mu)=(2N-4,2)$. Assume the ground-state energy $E(0_{1}^{+})$ is used as the reference $0$ so that any additive constant in $H$ may be neglected for excitation energies.\n\nYou are given two experimental level spacings for a single even-even nucleus:\n- The first excited $2^{+}$ energy is $E(2_{1}^{+})=0.180~\\mathrm{MeV}$.\n- The $\\beta$-band head energy is $E(0_{\\beta}^{+})=1.200~\\mathrm{MeV}$.\n\nUsing only the definitions above and the IBM $\\mathrm{SU}(3)$ band assignments stated, determine the parameters $a$ and $b$ from these two level spacings, and then predict the excitation energy of the $6^{+}$ ground-band state, $E(6_{1}^{+})$, in $\\mathrm{MeV}$. Round your final numerical prediction for $E(6_{1}^{+})$ to four significant figures. Express the final energy in $\\mathrm{MeV}$.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n**Step 1: Extract Givens**\n- Model: Interacting Boson Model (IBM) in the Special Unitary group of degree three, $\\mathrm{SU}(3)$, dynamical symmetry limit.\n- Boson number: $N=10$.\n- Hamiltonian: $H = a\\,\\hat{C}_{2}[\\mathrm{SU}(3)] + b\\,\\hat{C}_{2}[\\mathrm{O}(3)]$.\n- Eigenvalue of $\\hat{C}_{2}[\\mathrm{SU}(3)]$ for irrep $(\\lambda,\\mu)$: $C_{2}(\\lambda,\\mu) = \\lambda^{2} + \\mu^{2} + \\lambda\\,\\mu + 3(\\lambda+\\mu)$.\n- Eigenvalue of $\\hat{C}_{2}[\\mathrm{O}(3)]$ for a state of angular momentum $L$: $L(L+1)$.\n- Ground-state band irrep: $(\\lambda,\\mu)=(2N,0)$.\n- Lowest $\\beta$-band irrep: $(\\lambda,\\mu)=(2N-4,2)$.\n- Energy reference: The ground-state energy $E(0_{1}^{+})$ is set to $0$. All other energies are excitation energies.\n- Experimental data point 1: $E(2_{1}^{+}) = 0.180~\\mathrm{MeV}$.\n- Experimental data point 2: $E(0_{\\beta}^{+}) = 1.200~\\mathrm{MeV}$.\n- Task: Determine parameters $a$ and $b$, and predict the excitation energy $E(6_{1}^{+})$ in $\\mathrm{MeV}$, rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in the Interacting Boson Model, a widely accepted and successful theoretical framework in nuclear structure physics. The use of group theory, specifically the $\\mathrm{U}(6) \\supset \\mathrm{SU}(3) \\supset \\mathrm{O}(3)$ algebraic chain and its associated Casimir operators and quantum numbers, is standard practice in this field. The Hamiltonian form is the standard one for the $\\mathrm{SU}(3)$ dynamical symmetry. The irrep assignments for the ground and $\\beta$ bands are correct for this limit.\n- **Well-Posed:** The problem provides sufficient information ($N$, two energy levels) to determine the two unknown parameters ($a$, $b$) in the model Hamiltonian. The question asks for a specific prediction based on these parameters, for which a unique solution exists.\n- **Objective:** The problem is stated in precise, quantitative terms using standard physics and mathematics nomenclature. It is free of ambiguity or subjective language.\n- **Self-Contained and Consistent:** All necessary formulas and definitions are provided. The given numerical values are physically plausible for an even-even nucleus exhibiting rotational character. There are no internal contradictions.\n\n**Step 3: Verdict and Action**\nThe problem is valid as it is scientifically sound, well-posed, objective, and self-contained. A full solution will be provided.\n\nThe energy eigenvalue of a state characterized by the $\\mathrm{SU}(3)$ irreducible representation $(\\lambda, \\mu)$ and angular momentum $L$ is given by the expectation value of the Hamiltonian:\n$$E(\\lambda, \\mu, L) = a C_{2}(\\lambda, \\mu) + b L(L+1)$$\nwhere $C_{2}(\\lambda, \\mu) = \\lambda^{2} + \\mu^{2} + \\lambda\\mu + 3(\\lambda+\\mu)$.\n\nThe problem states that the ground-state energy $E(0_1^+)$ is the reference energy, so we are concerned with excitation energies, $E_{\\mathrm{ex}}$. The ground state ($0_1^+$) belongs to the ground-state band, which has the $\\mathrm{SU}(3)$ irrep $(\\lambda_g, \\mu_g) = (2N, 0)$ and angular momentum $L=0$. With $N=10$, the ground-state irrep is $(20, 0)$.\n\nThe energy of the ground state is:\n$$E(0_1^+) = E(20, 0, 0) = a C_2(20, 0) + b(0)(0+1)$$\nLet's calculate the Casimir eigenvalue for the ground-state irrep:\n$$C_2(20, 0) = 20^2 + 0^2 + (20)(0) + 3(20+0) = 400 + 60 = 460$$\nSo, the ground-state energy is $E(0_1^+) = 460a$.\n\nThe excitation energy of any state $(\\lambda, \\mu, L)$ is defined as:\n$$E_{\\mathrm{ex}}(\\lambda, \\mu, L) = E(\\lambda, \\mu, L) - E(0_1^+)$$\n$$E_{\\mathrm{ex}}(\\lambda, \\mu, L) = \\left[a C_{2}(\\lambda, \\mu) + b L(L+1)\\right] - a C_2(20, 0)$$\n$$E_{\\mathrm{ex}}(\\lambda, \\mu, L) = a \\left[C_{2}(\\lambda, \\mu) - 460\\right] + b L(L+1)$$\n\nWe are given the energy of the first excited state, $2_1^+$. This state is part of the ground-state band, so it has the same $(\\lambda, \\mu) = (20, 0)$ but with $L=2$. Its excitation energy is given as $E(2_1^+) = 0.180~\\mathrm{MeV}$.\n$$E_{\\mathrm{ex}}(2_1^+) = E_{\\mathrm{ex}}(20, 0, 2) = a \\left[C_{2}(20, 0) - 460\\right] + b (2)(2+1)$$\n$$E_{\\mathrm{ex}}(2_1^+) = a \\left[460 - 460\\right] + 6b = 6b$$\nUsing the given experimental value:\n$$6b = 0.180~\\mathrm{MeV} \\implies b = \\frac{0.180}{6}~\\mathrm{MeV} = 0.030~\\mathrm{MeV}$$\n\nNext, we are given the energy of the $\\beta$-band head, $0_\\beta^+$. This state is the lowest ($L=0$) state of the $\\beta$-band, which has the irrep $(\\lambda_\\beta, \\mu_\\beta) = (2N-4, 2)$. For $N=10$, this is $(16, 2)$. Its excitation energy is given as $E(0_\\beta^+) = 1.200~\\mathrm{MeV}$.\n$$E_{\\mathrm{ex}}(0_\\beta^+) = E_{\\mathrm{ex}}(16, 2, 0) = a \\left[C_{2}(16, 2) - 460\\right] + b (0)(0+1)$$\nWe must first calculate the Casimir eigenvalue for the $(16, 2)$ irrep:\n$$C_2(16, 2) = 16^2 + 2^2 + (16)(2) + 3(16+2) = 256 + 4 + 32 + 3(18) = 292 + 54 = 346$$\nNow substitute this into the energy expression:\n$$E_{\\mathrm{ex}}(0_\\beta^+) = a \\left[346 - 460\\right] = -114a$$\nUsing the given experimental value:\n$$-114a = 1.200~\\mathrm{MeV} \\implies a = -\\frac{1.200}{114}~\\mathrm{MeV} \\approx -0.01053~\\mathrm{MeV}$$\nThe parameters have been determined as $a = -1.200/114~\\mathrm{MeV}$ and $b = 0.030~\\mathrm{MeV}$. The negative sign of $a$ is physically correct, ensuring that the irrep with the larger Casimir eigenvalue, $(20,0)$, corresponds to the ground-state band.\n\nFinally, we need to predict the excitation energy of the $6_1^+$ state. This state belongs to the ground-state band, so its quantum numbers are $(\\lambda, \\mu) = (20, 0)$ and $L=6$.\n$$E_{\\mathrm{ex}}(6_1^+) = E_{\\mathrm{ex}}(20, 0, 6) = a \\left[C_{2}(20, 0) - 460\\right] + b (6)(6+1)$$\n$$E_{\\mathrm{ex}}(6_1^+) = a \\left[460 - 460\\right] + 42b = 42b$$\nThis prediction only depends on the parameter $b$. Substituting the value we found for $b$:\n$$E_{\\mathrm{ex}}(6_1^+) = 42 \\times 0.030~\\mathrm{MeV} = 1.26~\\mathrm{MeV}$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$E(6_1^+) = 1.260~\\mathrm{MeV}$$\nThis result is consistent with the characteristic energy ratio of a rigid rotor, a key feature of the $\\mathrm{SU}(3)$ limit:\n$$\\frac{E(6_1^+)}{E(2_1^+)} = \\frac{42b}{6b} = 7$$\n$$E(6_1^+) = 7 \\times E(2_1^+) = 7 \\times 0.180~\\mathrm{MeV} = 1.26~\\mathrm{MeV}$$\nRounding to four significant figures gives $1.260~\\mathrm{MeV}$.",
            "answer": "$$\\boxed{1.260}$$"
        },
        {
            "introduction": "The distinct dynamical symmetries of the IBM—$U(5)$, $SU(3)$, and $O(6)$—leave characteristic \"fingerprints\" in the patterns of energy ratios and transition strengths. These fingerprints can be used as features to classify real nuclei into their corresponding idealized limits, even with noisy or incomplete experimental data. This exercise bridges nuclear theory with modern data science by tasking you to build a machine learning classifier, teaching you how to handle realistic experimental challenges like noise and missing data using a probabilistic framework .",
            "id": "3556636",
            "problem": "You are asked to build, train, and evaluate a classifier that identifies the dynamical symmetry regime of the Interacting Boson Model (IBM) from limited spectral and quadrupole transition fingerprints. The three regimes are the Unitary group limit $U(5)$ (vibrational), the Special Unitary group limit $SU(3)$ (rotational), and the Orthogonal group limit $O(6)$ (gamma-soft). The goal is to formulate the problem purely in terms of mathematically defined features and a probabilistic classification rule that is robust to additive noise and missing entries in the feature vector.\n\nThe fundamental base for this problem is the accepted limiting behaviors of the Interacting Boson Model (IBM). In the $U(5)$ vibrational limit, excited states are characterized by the number of $d$-bosons $n_d$ and obey an energy pattern $E \\propto n_d$. In the $SU(3)$ rotational limit, the energy levels follow the rigid-rotor relation $E(L) \\propto L(L+1)$ where $L$ is the angular momentum. In the $O(6)$ gamma-soft limit, the relevant quantum number is $\\tau$ and the energy pattern is $E(\\tau) \\propto \\tau(\\tau+3)$ with allowed angular momenta $L = 2\\tau$ in the ground band. These well-tested formulas imply characteristic ratios of low-lying excitation energies, namely the ratio $R_{42} \\equiv E(4^+_1)/E(2^+_1)$ and $R_{62} \\equiv E(6^+_1)/E(2^+_1)$:\n- $U(5)$: $R_{42} = 2.0$, $R_{62} = 3.0$, from $E \\propto n_d$ where $E(2^+_1)$, $E(4^+_1)$, and $E(6^+_1)$ correspond to $n_d = 1,2,3$.\n- $SU(3)$: $R_{42} = 20/6 \\approx 3.333\\ldots$, $R_{62} = 42/6 = 7.0$, from $E(L) \\propto L(L+1)$ with $L=2,4,6$.\n- $O(6)$: $R_{42} = 10/4 = 2.5$, $R_{62} = 18/4 = 4.5$, from $E(\\tau) \\propto \\tau(\\tau+3)$ with $\\tau=1,2,3$ for $L=2,4,6$.\n\nIn addition, the reduced electric quadrupole transition probabilities $B(E2)$ obey characteristic limiting ratios. The electric quadrupole operator in the Interacting Boson Model is $T(E2)=e_B Q$ where $Q$ is the quadrupole operator; the selection rules and group-theoretical reduction determine the intraband ratios. For a $K=0$ rotor ($SU(3)$ limit), the Alaga rules give representative ratios $B_{42}/B_{20} = 10/7 \\approx 1.429$ and $B_{64}/B_{20} = 18/7 \\approx 2.571$ for transitions $4^+_1 \\rightarrow 2^+_1$, $6^+_1 \\rightarrow 4^+_1$, and $2^+_1 \\rightarrow 0^+_1$, respectively. For the $U(5)$ harmonic vibrator, typical ratios are $B_{42}/B_{20} \\approx 2.0$ and $B_{64}/B_{20} \\approx 3.0$, reflecting the ladder structure with $\\Delta n_d = \\pm 1$. The $O(6)$ gamma-soft limit yields intermediate ratios; for the purposes of this classification, adopt $B_{42}/B_{20} \\approx 1.6$ and $B_{64}/B_{20} \\approx 2.4$ as representative large-boson-number fingerprints.\n\nDefine the feature vector as the four-dimensional vector\n$$\n\\mathbf{x} = \\big[ R_{42},\\; R_{62},\\; B_{42}/B_{20},\\; B_{64}/B_{20} \\big].\n$$\nYour program must:\n1. Generate a synthetic training dataset for each regime by sampling $\\mathbf{x}$ from a multivariate normal distribution centered at the regime’s fingerprint mean, with diagonal covariance to reflect finite-boson-number spread and typical experimental variability. Use identical sample sizes for each class and identical class priors.\n2. Train a diagonal-covariance Gaussian classifier. For class $c$, estimate the mean $\\boldsymbol{\\mu}_c$ and diagonal variances $\\boldsymbol{\\sigma}^2_c$ from the synthetic training data. For a test feature vector $\\mathbf{x}$ with some components missing, the classifier must compute the class-conditional log-likelihood using only the observed components. If the set of observed components is empty, the decision must reduce to a prior comparison.\n3. Evaluate the classifier on a test suite of cases that includes clean data, noisy data, and incomplete data. Noise must be modeled as additive Gaussian noise applied to each non-missing component of the test vector, with a specified standard deviation for each test case.\n\nNo physical units are required because all features are dimensionless ratios.\n\nThe probabilistic rule for classification is to pick the class $c$ that maximizes\n$$\n\\log p(c) + \\sum_{i \\in \\mathcal{O}(\\mathbf{x})} \\left( -\\frac{1}{2}\\log(2\\pi \\sigma_{c,i}^2) - \\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2} \\right),\n$$\nwhere $\\mathcal{O}(\\mathbf{x})$ is the index set of observed (non-missing) components, $p(c)$ is the prior for class $c$, $\\mu_{c,i}$ is the mean of feature $i$ for class $c$, and $\\sigma_{c,i}^2$ is the variance of feature $i$ for class $c$.\n\nTraining distribution parameters to be used for sampling (for realism and class separability):\n- $U(5)$ mean $\\boldsymbol{\\mu}_{U5} = [2.0,\\; 3.0,\\; 2.0,\\; 3.0]$, standard deviations $\\boldsymbol{\\sigma}_{U5} = [0.04,\\; 0.06,\\; 0.20,\\; 0.30]$.\n- $SU(3)$ mean $\\boldsymbol{\\mu}_{SU3} = [3.3333333333,\\; 7.0,\\; 1.429,\\; 2.571]$, standard deviations $\\boldsymbol{\\sigma}_{SU3} = [0.03,\\; 0.05,\\; 0.10,\\; 0.12]$.\n- $O(6)$ mean $\\boldsymbol{\\mu}_{O6} = [2.5,\\; 4.5,\\; 1.6,\\; 2.4]$, standard deviations $\\boldsymbol{\\sigma}_{O6} = [0.05,\\; 0.08,\\; 0.18,\\; 0.25]$.\n\nUse an equal number of training samples per class and equal priors $p(U(5))=p(SU(3))=p(O(6))$.\n\nTest suite. The program must classify the following seven test cases. Each test case consists of a feature vector $\\mathbf{x}$, a noise standard deviation $\\sigma_{\\text{noise}}$, and a missingness pattern indicating which entries are missing (to be ignored in classification). Noise must be added independently to each non-missing feature. Represent missing entries in the code with “not-a-number” markers. The seven test cases are:\n1. Clean $U(5)$-like case: $\\mathbf{x} = [2.0,\\; 3.0,\\; 2.0,\\; 3.0]$, $\\sigma_{\\text{noise}} = 0.02$, no missing entries.\n2. Clean $SU(3)$-like case: $\\mathbf{x} = [3.3333333333,\\; 7.0,\\; 1.429,\\; 2.571]$, $\\sigma_{\\text{noise}} = 0.02$, no missing entries.\n3. Clean $O(6)$-like case: $\\mathbf{x} = [2.5,\\; 4.5,\\; 1.6,\\; 2.4]$, $\\sigma_{\\text{noise}} = 0.02$, no missing entries.\n4. Noisy $O(6)$-boundary case: $\\mathbf{x} = [2.4,\\; 4.4,\\; 1.55,\\; 2.35]$, $\\sigma_{\\text{noise}} = 0.20$, no missing entries.\n5. Incomplete $SU(3)$ energies-only case: $\\mathbf{x} = [3.32,\\; 7.01,\\; \\mathrm{missing},\\; \\mathrm{missing}]$, $\\sigma_{\\text{noise}} = 0.05$.\n6. Incomplete $U(5)$ single-feature case: $\\mathbf{x} = [2.02,\\; \\mathrm{missing},\\; \\mathrm{missing},\\; \\mathrm{missing}]$, $\\sigma_{\\text{noise}} = 0.01$.\n7. Contradictory-mix case (energies rotational, $B(E2)$ vibrational): $\\mathbf{x} = [3.33,\\; 6.99,\\; 2.0,\\; 3.0]$, $\\sigma_{\\text{noise}} = 0.03$, no missing entries.\n\nClass labels must be mapped to integers as follows: $U(5) \\mapsto 0$, $SU(3) \\mapsto 1$, $O(6) \\mapsto 2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[r_1, r_2, \\dots, r_7]$, where each $r_k$ is the predicted class label for test case $k$ as an integer in $\\{0,1,2\\}$.\n\nAll computations are dimensionless; there are no physical units or angles required in this task.",
            "solution": "The problem presented is a task in computational pattern recognition applied to nuclear structure physics, specifically the classification of dynamical symmetries within the Interacting Boson Model (IBM). The problem is scientifically sound, well-posed, and all necessary parameters and procedures are explicitly defined. It is therefore deemed valid and a solution can be formulated.\n\nThe core of the problem is to design a classifier that, given a feature vector $\\mathbf{x} \\in \\mathbb{R}^4$, assigns it to one of three classes, $c$, corresponding to the dynamical symmetries $U(5)$, $SU(3)$, and $O(6)$. The feature vector $\\mathbf{x}$ consists of four dimensionless ratios of nuclear observables:\n$$\n\\mathbf{x} = \\big[ R_{42},\\; R_{62},\\; B_{42}/B_{20},\\; B_{64}/B_{20} \\big]\n$$\nwhere $R_{L'L} \\equiv E(L'_1)/E(L_1)$ are ratios of excitation energies of the ground state band and $B_{L'L}/B_{J'J}$ are ratios of reduced electric quadrupole ($E2$) transition probabilities.\n\nThe chosen classification framework is that of a Naive Bayes classifier. We seek to find the class $c$ that maximizes the posterior probability $p(c|\\mathbf{x})$. By Bayes' theorem, this is equivalent to maximizing the product of the likelihood $p(\\mathbf{x}|c)$ and the prior $p(c)$:\n$$\n\\hat{c} = \\underset{c}{\\arg\\max} \\, p(\\mathbf{x}|c) \\, p(c)\n$$\nFor computational stability and convenience, we work with the logarithm of this quantity, the log-posterior:\n$$\n\\hat{c} = \\underset{c}{\\arg\\max} \\, \\left( \\log p(\\mathbf{x}|c) + \\log p(c) \\right)\n$$\nThe problem specifies that the priors are equal for all three classes, i.e., $p(U(5)) = p(SU(3)) = p(O(6)) = 1/3$. Therefore, the $\\log p(c)$ term is a constant with respect to $c$ and can be ignored in the maximization, which simplifies to maximizing the log-likelihood $\\log p(\\mathbf{x}|c)$.\n\nThe model for the class-conditional likelihood $p(\\mathbf{x}|c)$ is a multivariate Gaussian distribution. The \"naive\" aspect of the Naive Bayes classifier corresponds to the assumption that the features are conditionally independent given the class. This implies that the covariance matrix of the Gaussian distribution is diagonal. The likelihood is thus a product of individual Gaussian probabilities for each feature $x_i$:\n$$\np(\\mathbf{x}|c) = \\prod_{i=1}^{4} p(x_i | c) = \\prod_{i=1}^{4} \\frac{1}{\\sqrt{2\\pi \\sigma_{c,i}^2}} \\exp\\left(-\\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2}\\right)\n$$\nwhere $\\mu_{c,i}$ and $\\sigma_{c,i}^2$ are the mean and variance of feature $i$ for class $c$, respectively.\n\nThe corresponding total log-likelihood for a complete feature vector $\\mathbf{x}$ is:\n$$\n\\log p(\\mathbf{x}|c) = \\sum_{i=1}^{4} \\left( -\\frac{1}{2}\\log(2\\pi \\sigma_{c,i}^2) - \\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2} \\right)\n$$\nAn essential requirement of the problem is to handle missing feature values robustly. This is naturally accomplished within this framework. If a component $x_i$ of the feature vector $\\mathbf{x}$ is missing, its contribution to the log-likelihood sum is simply omitted. The sum is taken only over the set of observed components, denoted by $\\mathcal{O}(\\mathbf{x})$. The classification rule is then to choose the class $c$ that maximizes the score:\n$$\nS_c(\\mathbf{x}) = \\log p(c) + \\sum_{i \\in \\mathcal{O}(\\mathbf{x})} \\left( -\\frac{1}{2}\\log(2\\pi \\sigma_{c,i}^2) - \\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2} \\right)\n$$\nThis is precisely the formula provided in the problem statement.\n\nThe classifier must first be trained. The training phase involves estimating the model parameters—the means $\\mu_{c,i}$ and variances $\\sigma_{c,i}^2$—from a training dataset. The problem specifies that this dataset is to be synthetically generated by drawing samples for each class from multivariate normal distributions with population means $\\boldsymbol{\\mu}_c$ and standard deviations $\\boldsymbol{\\sigma}_c$ provided in the statement. For a Gaussian distribution, the Maximum Likelihood Estimates (MLE) for the mean and variance are the sample mean and the (biased) sample variance. We will use the closely related and standard unbiased sample estimators:\n$$\n\\hat{\\mu}_{c,i} = \\frac{1}{N_c} \\sum_{j=1}^{N_c} x_{j,i}^{(c)}\n$$\n$$\n\\hat{\\sigma}_{c,i}^2 = \\frac{1}{N_c-1} \\sum_{j=1}^{N_c} \\left(x_{j,i}^{(c)} - \\hat{\\mu}_{c,i}\\right)^2\n$$\nwhere $N_c$ is the number of training samples for class $c$, and $x_{j,i}^{(c)}$ is the $i$-th feature of the $j$-th sample for that class. A large number of synthetic samples ($N_c \\approx 10^5$) will be used to ensure that the estimated parameters $\\hat{\\boldsymbol{\\mu}}_c$ and $\\hat{\\boldsymbol{\\sigma}}_c^2$ are statistically robust and very close approximations of the true distribution parameters given in the problem.\n\nThe implementation proceeds as follows:\n1.  **Parameter Definition**: The ideal means and standard deviations for the three symmetry classes, as well as the test case specifications, are defined.\n2.  **Training**: For each class ($U(5)$, $SU(3)$, $O(6)$), a large training dataset ($N_c = 100,000$) is generated by drawing random samples from a normal distribution with the specified mean and standard deviation for each of the four features. From this dataset, the sample means and variances are calculated and stored as the classifier's parameters.\n3.  **Classification**: A function implements the classification rule. It takes a test vector $\\mathbf{x}$ as input. Before classification, additive Gaussian noise, with a standard deviation $\\sigma_{\\text{noise}}$ specific to the test case, is applied to each non-missing component of $\\mathbf{x}$. The function then calculates the score $S_c(\\mathbf{x})$ for each class using the trained parameters and handling missing values (represented as `np.nan`) by summing only over observed features. The class with the highest score is chosen as the predicted label.\n4.  **Evaluation**: This process is applied to each of the seven test cases provided. A fixed random seed is used to ensure the noise generation is deterministic, yielding reproducible results. The final integer class labels ($0$ for $U(5)$, $1$ for $SU(3)$, $2$ for $O(6)$) are collected and formatted into the required output string.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Builds, trains, and evaluates a Gaussian Naive Bayes classifier for\n    IBM dynamical symmetries.\n    \"\"\"\n    \n    # Use a fixed random seed for reproducibility of training data and test noise\n    rng = np.random.default_rng(seed=0)\n\n    # 1. Define problem parameters\n    \n    # Class mapping\n    CLASS_LABELS = {'U(5)': 0, 'SU(3)': 1, 'O(6)': 2}\n    CLASS_NAMES = {v: k for k, v in CLASS_LABELS.items()}\n    \n    # Training distribution parameters (means and standard deviations)\n    # These are the \"true\" parameters of the underlying physical models.\n    true_params = {\n        CLASS_LABELS['U(5)']: {\n            'mean': np.array([2.0, 3.0, 2.0, 3.0]),\n            'std_dev': np.array([0.04, 0.06, 0.20, 0.30])\n        },\n        CLASS_LABELS['SU(3)']: {\n            'mean': np.array([3.3333333333, 7.0, 1.429, 2.571]),\n            'std_dev': np.array([0.03, 0.05, 0.10, 0.12])\n        },\n        CLASS_LABELS['O(6)']: {\n            'mean': np.array([2.5, 4.5, 1.6, 2.4]),\n            'std_dev': np.array([0.05, 0.08, 0.18, 0.25])\n        }\n    }\n    \n    n_classes = len(CLASS_LABELS)\n    n_features = len(true_params[0]['mean'])\n    \n    # Use equal priors as specified\n    log_priors = np.log([1.0 / n_classes] * n_classes)\n\n    # 2. Train the classifier on synthetic data\n    \n    N_train_per_class = 100000  # Number of synthetic samples per class for training\n    \n    # These will store the parameters estimated from the training data.\n    trained_params = {\n        'means': np.zeros((n_classes, n_features)),\n        'variances': np.zeros((n_classes, n_features))\n    }\n\n    for c in range(n_classes):\n        # Generate synthetic training data\n        means = true_params[c]['mean']\n        stds = true_params[c]['std_dev']\n        \n        # Draw samples for each feature independently\n        training_data = rng.normal(loc=means, scale=stds, size=(N_train_per_class, n_features))\n        \n        # Estimate parameters (mean and variance) from the data\n        # Using unbiased variance estimator with ddof=1\n        trained_params['means'][c, :] = np.mean(training_data, axis=0)\n        trained_params['variances'][c, :] = np.var(training_data, axis=0, ddof=1)\n\n    # 3. Define the classifier function\n    \n    def classify(x_test):\n        \"\"\"\n        Classifies a single feature vector x_test using the trained model.\n        \n        Args:\n            x_test (np.ndarray): A 1D numpy array of features. May contain np.nan.\n\n        Returns:\n            int: The predicted class label (0, 1, or 2).\n        \"\"\"\n        log_posteriors = np.copy(log_priors)\n        \n        for c in range(n_classes):\n            log_likelihood = 0.0\n            \n            for i in range(n_features):\n                # Skip missing features\n                if np.isnan(x_test[i]):\n                    continue\n                \n                # Get trained parameters for this class and feature\n                mu = trained_params['means'][c, i]\n                var = trained_params['variances'][c, i]\n\n                # Calculate log of the Gaussian PDF\n                # log(p(x|c)) = -0.5*log(2*pi*var) - (x-mu)^2 / (2*var)\n                logp_xi_c = -0.5 * np.log(2 * np.pi * var) - ((x_test[i] - mu)**2) / (2 * var)\n                log_likelihood += logp_xi_c\n            \n            log_posteriors[c] += log_likelihood\n            \n        return np.argmax(log_posteriors)\n\n    # 4. Evaluate the classifier on the test suite\n    \n    # Define test cases: (feature_vector, noise_std_dev)\n    # Use np.nan for missing entries\n    test_cases = [\n        (np.array([2.0, 3.0, 2.0, 3.0]), 0.02),\n        (np.array([3.3333333333, 7.0, 1.429, 2.571]), 0.02),\n        (np.array([2.5, 4.5, 1.6, 2.4]), 0.02),\n        (np.array([2.4, 4.4, 1.55, 2.35]), 0.20),\n        (np.array([3.32, 7.01, np.nan, np.nan]), 0.05),\n        (np.array([2.02, np.nan, np.nan, np.nan]), 0.01),\n        (np.array([3.33, 6.99, 2.0, 3.0]), 0.03)\n    ]\n\n    results = []\n    for x_base, noise_std in test_cases:\n        # Create a copy to add noise to\n        x_noisy = np.copy(x_base)\n        \n        # Add independent Gaussian noise to each non-missing feature\n        for i in range(n_features):\n            if not np.isnan(x_noisy[i]):\n                noise = rng.normal(loc=0.0, scale=noise_std)\n                x_noisy[i] += noise\n        \n        # Classify the noisy vector and store the result\n        prediction = classify(x_noisy)\n        results.append(prediction)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}