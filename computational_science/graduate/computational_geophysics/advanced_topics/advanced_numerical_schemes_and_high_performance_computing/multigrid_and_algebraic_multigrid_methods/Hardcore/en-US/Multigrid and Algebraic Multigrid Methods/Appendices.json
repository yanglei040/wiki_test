{
    "hands_on_practices": [
        {
            "introduction": "Before implementing a complex solver, it is invaluable to predict its performance. Local Fourier Analysis (LFA) is a powerful theoretical tool for analyzing multigrid methods on structured grids, allowing us to compute an expected convergence factor. This practice guides you through using LFA to explore how physical properties like anisotropy impact solver efficiency, providing insight into designing robust algorithms. ",
            "id": "3611417",
            "problem": "Consider the constant-coefficient, two-dimensional anisotropic diffusion operator with a symmetric positive definite diffusion tensor $K \\in \\mathbb{R}^{2 \\times 2}$ given by $K = R(\\theta) \\operatorname{diag}(1,\\epsilon) R(\\theta)^{\\top}$, where $R(\\theta)$ is the rotation matrix $R(\\theta) = \\begin{pmatrix}\\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta\\end{pmatrix}$, the anisotropy ratio is $\\epsilon \\in (0,1]$, and the rotation angle is $\\theta \\in [0,\\pi)$ in radians. The governing partial differential equation is $-\\nabla \\cdot (K \\nabla u) = f$ on a uniform infinite lattice with grid spacing $h>0$. A standard $9$-point finite difference discretization for constant $K$ of $-\\nabla \\cdot (K \\nabla u)$ uses central differences for second derivatives and mixed derivatives. For a grid function $u_{i,j}$, the discrete operator $A$ has the stencil weights\n- Axis-aligned neighbors: $(i \\pm 1, j)$ with weight $K_{xx}/h^2$, $(i, j \\pm 1)$ with weight $K_{yy}/h^2$,\n- Diagonal neighbors: $(i \\pm 1, j \\pm 1)$ with weights $\\pm K_{xy}/(2 h^2)$ with signs chosen so that the discrete mixed derivative approximates $2 K_{xy} \\partial_{xy} u$,\n- Center: $(i,j)$ with weight $(2 K_{xx} + 2 K_{yy})/h^2$.\n\nLet the discrete Fourier symbol of the operator be denoted by $a(\\boldsymbol{\\xi})$, where $\\boldsymbol{\\xi} = (\\xi_x,\\xi_y) \\in \\mathbb{R}^2$. Using the convention that symbols represent positive definite operators, one may derive\n$$\na(\\boldsymbol{\\xi}) = \\frac{2}{h^2}\\Big(K_{xx}(1-\\cos\\xi_x) + K_{yy}(1-\\cos\\xi_y)\\Big) + \\frac{K_{xy}}{h^2}\\Big(\\cos(\\xi_x - \\xi_y) - \\cos(\\xi_x + \\xi_y)\\Big).\n$$\nConsider classical two-grid Local Fourier Analysis (LFA) with full coarsening by a factor of $2$ in each coordinate and standard bilinear interpolation and its adjoint full-weighting restriction. The coarse-grid frequency set indexing uses the four aliases\n$$\n\\mathcal{T}(\\boldsymbol{\\xi}) = \\left\\{ \\boldsymbol{\\xi}, \\boldsymbol{\\xi} + (\\pi,0), \\boldsymbol{\\xi} + (0,\\pi), \\boldsymbol{\\xi} + (\\pi,\\pi) \\right\\}.\n$$\nFor weighted Jacobi smoothing with weight $\\omega \\in (0,1)$, the pointwise smoothing symbol is given by\n$$\ns(\\boldsymbol{\\xi}) = 1 - \\omega \\frac{a(\\boldsymbol{\\xi})}{d},\n$$\nwhere $d = \\frac{2 K_{xx} + 2 K_{yy}}{h^2}$ is the diagonal of $A$. The bilinear interpolation symbol is\n$$\n\\hat{P}(\\boldsymbol{\\xi}) = \\frac{1}{4} \\begin{bmatrix}\n(1 + e^{i \\xi_x})(1 + e^{i \\xi_y}) \\\\\n(1 - e^{i \\xi_x})(1 + e^{i \\xi_y}) \\\\\n(1 + e^{i \\xi_x})(1 - e^{i \\xi_y}) \\\\\n(1 - e^{i \\xi_x})(1 - e^{i \\xi_y})\n\\end{bmatrix},\n$$\nand the full-weighting restriction is the adjoint\n$$\n\\hat{R}(\\boldsymbol{\\xi}) = \\hat{P}(\\boldsymbol{\\xi})^{\\ast \\top}.\n$$\nLet $A_{\\text{diag}}(\\boldsymbol{\\xi}) = \\operatorname{diag}\\big(a(\\boldsymbol{\\eta})\\big)_{\\boldsymbol{\\eta}\\in \\mathcal{T}(\\boldsymbol{\\xi})}$ be the diagonal matrix of fine-grid symbols over the $4$ aliases, and let the coarse-grid symbol be the scalar\n$$\n\\hat{A}_c(\\boldsymbol{\\xi}) = \\hat{R}(\\boldsymbol{\\xi}) \\, A_{\\text{diag}}(\\boldsymbol{\\xi}) \\, \\hat{P}(\\boldsymbol{\\xi}).\n$$\nThe coarse-grid correction symbol acting on the $4$-dimensional alias subspace is\n$$\nC(\\boldsymbol{\\xi}) = I - \\hat{P}(\\boldsymbol{\\xi}) \\, \\hat{A}_c(\\boldsymbol{\\xi})^{-1} \\, \\hat{R}(\\boldsymbol{\\xi}) \\, A_{\\text{diag}}(\\boldsymbol{\\xi}),\n$$\nand one step of pre- and post-smoothing yields the two-grid error-propagation symbol\n$$\nE(\\boldsymbol{\\xi}) = S_{\\text{post}}(\\boldsymbol{\\xi}) \\, C(\\boldsymbol{\\xi}) \\, S_{\\text{pre}}(\\boldsymbol{\\xi}),\n$$\nwith $S_{\\text{pre}}(\\boldsymbol{\\xi}) = \\operatorname{diag}\\big(s(\\boldsymbol{\\eta})\\big)_{\\boldsymbol{\\eta}\\in \\mathcal{T}(\\boldsymbol{\\xi})}$ and $S_{\\text{post}}(\\boldsymbol{\\xi}) = \\operatorname{diag}\\big(s(\\boldsymbol{\\eta})\\big)_{\\boldsymbol{\\eta}\\in \\mathcal{T}(\\boldsymbol{\\xi})}$. The LFA predicted two-grid convergence factor is\n$$\n\\rho_{\\text{TG}} = \\sup_{\\boldsymbol{\\xi} \\in \\mathcal{B}} \\rho\\big(E(\\boldsymbol{\\xi})\\big),\n$$\nwhere $\\rho(\\cdot)$ denotes the spectral radius and $\\mathcal{B} = [-\\pi/2,\\pi/2)^2$ is the low-frequency base region.\n\nStarting from the governing operator and its discretization, perform the following:\n- Derive the discrete symbol $a(\\boldsymbol{\\xi})$ for the rotated tensor $K$ with $K_{xx}=\\cos^2\\theta + \\epsilon \\sin^2\\theta$, $K_{yy}=\\sin^2\\theta + \\epsilon \\cos^2\\theta$, and $K_{xy}=(1-\\epsilon)\\cos\\theta \\sin\\theta$. Show how the two-grid LFA machinery produces $E(\\boldsymbol{\\xi})$ and $\\rho_{\\text{TG}}$ for weighted Jacobi smoothing.\n- Propose a smoother and coarsening rule that is robust as $\\epsilon \\to 0$ for arbitrary $\\theta$, grounded in physical and algebraic properties of anisotropy. Justify the choice from first principles.\n\nImplementation task:\n- Implement a program that, for given $(\\epsilon,\\theta)$, evaluates $\\rho_{\\text{TG}}$ numerically by sampling $\\boldsymbol{\\xi}$ on a uniform grid of the base region $\\mathcal{B}$ with $N$ samples per dimension, using $N=64$, grid spacing $h=1$, and weighted Jacobi with $\\omega = 2/3$. Avoid sampling the exact endpoints to prevent division by zero; sample midpoints in each subinterval.\n- For numerical stability, if $\\hat{A}_c(\\boldsymbol{\\xi})$ is less than a small threshold $10^{-14}$ in magnitude, treat the coarse-grid correction as the identity at that $\\boldsymbol{\\xi}$, that is, set $C(\\boldsymbol{\\xi}) = I$.\n\nTest suite:\n- Case $1$: $(\\epsilon,\\theta) = (1.0,0.0)$.\n- Case $2$: $(\\epsilon,\\theta) = (0.1,0.0)$.\n- Case $3$: $(\\epsilon,\\theta) = (10^{-6},0.0)$.\n- Case $4$: $(\\epsilon,\\theta) = (0.01,\\pi/4)$.\n- Case $5$: $(\\epsilon,\\theta) = (10^{-6},\\pi/3)$.\n\nAngle unit is radians. Express the final numerical answers as floating-point numbers rounded to $6$ decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]$).",
            "solution": "The problem requires a two-part response: first, a derivation and explanation of the Local Fourier Analysis (LFA) for a two-grid method applied to an anisotropic diffusion problem, and second, a proposal for a robust multigrid strategy for such problems.\n\n### Part 1: Two-Grid Local Fourier Analysis\n\nThe governing partial differential equation (PDE) is the anisotropic diffusion equation, $-\\nabla \\cdot (K \\nabla u) = f$, where $K$ is a symmetric positive definite diffusion tensor. The tensor $K$ is defined by its anisotropy ratio $\\epsilon \\in (0,1]$ and rotation angle $\\theta \\in [0, \\pi)$:\n$$\nK = R(\\theta) \\begin{pmatrix} 1 & 0 \\\\ 0 & \\epsilon \\end{pmatrix} R(\\theta)^{\\top} = \\begin{pmatrix}\\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta\\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & \\epsilon \\end{pmatrix} \\begin{pmatrix}\\cos\\theta & \\sin\\theta \\\\ -\\sin\\theta & \\cos\\theta\\end{pmatrix}\n$$\nPerforming the matrix multiplication yields the components of a constant tensor $K$:\n$$\nK_{xx} = \\cos^2\\theta + \\epsilon \\sin^2\\theta\n$$\n$$\nK_{yy} = \\sin^2\\theta + \\epsilon \\cos^2\\theta\n$$\n$$\nK_{xy} = (1-\\epsilon)\\cos\\theta \\sin\\theta\n$$\nA $9$-point finite difference discretization on a uniform grid with spacing $h$ leads to a linear system $Au=b$. The discrete operator $A$ has a Fourier symbol $a(\\boldsymbol{\\xi})$, where $\\boldsymbol{\\xi} = (\\xi_x, \\xi_y)$ is the Fourier-mode frequency vector. As given, the symbol is:\n$$\na(\\boldsymbol{\\xi}) = \\frac{2}{h^2}\\Big(K_{xx}(1-\\cos\\xi_x) + K_{yy}(1-\\cos\\xi_y)\\Big) + \\frac{K_{xy}}{h^2}\\Big(\\cos(\\xi_x - \\xi_y) - \\cos(\\xi_x + \\xi_y)\\Big)\n$$\nThis symbol represents the action of the discrete operator $A$ on a grid-scale Fourier mode $e^{i(i\\xi_x + j\\xi_y)}$, i.e., $A e^{i(i\\xi_x + j\\xi_y)} = a(\\boldsymbol{\\xi}) e^{i(i\\xi_x + j\\xi_y)}$.\n\nThe two-grid LFA proceeds by analyzing how the multigrid components (smoother, restriction, interpolation, coarse-grid operator) act on these Fourier modes.\nThe analysis is performed for a low-frequency mode $\\boldsymbol{\\xi} \\in \\mathcal{B} = [-\\pi/2, \\pi/2)^2$. On a fine grid, this mode is coupled to three other high-frequency modes due to aliasing caused by the coarsening process. The set of four coupled modes is indexed by the alias set $\\mathcal{T}(\\boldsymbol{\\xi}) = \\left\\{ \\boldsymbol{\\xi}, \\boldsymbol{\\xi} + (\\pi,0), \\boldsymbol{\\xi} + (0,\\pi), \\boldsymbol{\\xi} + (\\pi,\\pi) \\right\\}$. The two-grid cycle is then represented by a $4 \\times 4$ matrix acting on the amplitudes of these four modes.\n\nThe steps to construct the two-grid error-propagation symbol $E(\\boldsymbol{\\xi})$ are as follows:\n\n1.  **Operator Symbol Matrix**: The fine-grid operator $A$ acts independently on each of the four modes. Its representation in the $4$-dimensional alias-subspace is a diagonal matrix, $A_{\\text{diag}}(\\boldsymbol{\\xi})$, whose diagonal entries are the operator symbols evaluated at each of the four alias frequencies:\n    $$\n    A_{\\text{diag}}(\\boldsymbol{\\xi}) = \\operatorname{diag}\\big(a(\\boldsymbol{\\eta})\\big)_{\\boldsymbol{\\eta}\\in \\mathcal{T}(\\boldsymbol{\\xi})}\n    $$\n\n2.  **Smoother Symbol Matrix**: The smoother is a weighted Jacobi iteration, $u \\leftarrow u - \\omega D^{-1}(Au-b)$, where $D$ is the diagonal of $A$. The error propagation operator for the smoother is $S = I - \\omega D^{-1}A$. The diagonal of $A$ is constant, $d=(2K_{xx} + 2K_{yy})/h^2$. The smoothing symbol is $s(\\boldsymbol{\\xi}) = 1 - \\omega a(\\boldsymbol{\\xi})/d$. Like the operator, the smoother acts on each mode independently. With one pre-smoothing and one post-smoothing step, the symbol matrices are:\n    $$\n    S_{\\text{pre}}(\\boldsymbol{\\xi}) = S_{\\text{post}}(\\boldsymbol{\\xi}) = \\operatorname{diag}\\big(s(\\boldsymbol{\\eta})\\big)_{\\boldsymbol{\\eta}\\in \\mathcal{T}(\\boldsymbol{\\xi})}\n    $$\n\n3.  **Inter-Grid Transfer Symbol Vectors**: Bilinear interpolation and its adjoint, full-weighting restriction, are used. The interpolation operator maps a single coarse-grid mode to a linear combination of the four fine-grid modes in the alias set. The coefficients of this mapping form the $4 \\times 1$ interpolation symbol vector $\\hat{P}(\\boldsymbol{\\xi})$. The restriction operator maps the four fine-grid modes to a single coarse-grid mode, represented by the $1 \\times 4$ symbol vector $\\hat{R}(\\boldsymbol{\\xi}) = \\hat{P}(\\boldsymbol{\\xi})^{\\ast \\top}$.\n\n4.  **Coarse-Grid Correction Symbol Matrix**: The coarse-grid correction involves restriction, solving on the coarse grid, and interpolation. Its symbol is a $4 \\times 4$ matrix:\n    $$\n    C(\\boldsymbol{\\xi}) = I - \\hat{P}(\\boldsymbol{\\xi}) \\, \\hat{A}_c(\\boldsymbol{\\xi})^{-1} \\, \\hat{R}(\\boldsymbol{\\xi}) \\, A_{\\text{diag}}(\\boldsymbol{\\xi})\n    $$\n    Here, $\\hat{A}_c(\\boldsymbol{\\xi})$ is the scalar coarse-grid operator symbol, formed via the Galerkin principle $\\hat{A}_c = \\hat{R} A_{\\text{diag}} \\hat{P}$:\n    $$\n    \\hat{A}_c(\\boldsymbol{\\xi}) = \\hat{R}(\\boldsymbol{\\xi}) \\, A_{\\text{diag}}(\\boldsymbol{\\xi}) \\, \\hat{P}(\\boldsymbol{\\xi})\n    $$\n\n5.  **Two-Grid Cycle Symbol Matrix**: One V-cycle with pre- and post-smoothing is the composition of these operators. The error-propagation symbol for the entire cycle is:\n    $$\n    E(\\boldsymbol{\\xi}) = S_{\\text{post}}(\\boldsymbol{\\xi}) \\, C(\\boldsymbol{\\xi}) \\, S_{\\text{pre}}(\\boldsymbol{\\xi})\n    $$\n\n6.  **Two-Grid Convergence Factor**: The LFA-predicted convergence factor, $\\rho_{\\text{TG}}$, is the worst-case spectral radius of the error-propagation matrix over all low-frequency modes:\n    $$\n    \\rho_{\\text{TG}} = \\sup_{\\boldsymbol{\\xi} \\in \\mathcal{B}} \\rho\\big(E(\\boldsymbol{\\xi})\\big)\n    $$\n    where $\\rho(\\cdot)$ is the spectral radius.\n\n### Part 2: Proposal for a Robust Multigrid Strategy\n\nThe standard multigrid setup described (pointwise Jacobi smoother, full coarsening, bilinear interpolation) is notoriously inefficient for problems with strong anisotropy ($\\epsilon \\to 0$).\n\n**Analysis of Failure**:\nWhen $\\epsilon \\to 0$, the diffusion is strong in the direction of the first eigenvector of $K$ (at angle $\\theta$) and weak in the orthogonal direction. On the discrete grid, this translates to large matrix entries coupling points along the direction of strong anisotropy and small entries coupling points orthogonally.\n1.  **Smoother Failure**: Pointwise smoothers, such as weighted Jacobi, are local and isotropic in their action. They effectively damp error components that are highly oscillatory in all grid directions. However, they fail to damp \"semi-coarse\" error modes that are smooth (low-frequency) along the direction of strong coupling but oscillatory (high-frequency) in the direction of weak coupling. For the operator, these modes look smooth, and the residual is small, so the smoother has little effect. These modes are the primary cause of slow convergence.\n2.  **Coarsening/Interpolation Failure**: Full coarsening (doubling grid spacing in all directions) is also problematic. It is 'blind' to the anisotropy. Strong connections on the fine grid, especially if not aligned with grid axes (e.g., $\\theta = \\pi/4$), may not have a corresponding strong connection on the coarse grid. Consequently, the coarse-grid operator cannot accurately represent the fine-grid operator's anisotropy, and the coarse-grid correction fails to eliminate the problematic error modes that the smoother missed.\n\n**Proposed Robust Strategy**:\nA robust multigrid method must be designed so that its components are adapted to the anisotropy. The fundamental principle is that coarsening and smoothing should be complementary: error components not efficiently reduced by the smoother must be well approximated on the coarse grid.\n\n1.  **Robust Smoother**: To damp the problematic semi-coarse modes, the smoother must act collectively on unknowns that are strongly coupled. The canonical choice is a **line-implicit smoother**.\n    *   For axis-aligned anisotropy (e.g., $\\theta=0$), one would use an $x$-line smoother (e.g., line-Jacobi or line-Gauss-Seidel), which solves simultaneously for all unknowns on each horizontal grid line. This involves solving a series of tridiagonal systems, which is highly efficient at damping errors that are smooth along the lines.\n    *   For arbitrary $\\theta$, the strong couplings are not grid-aligned. A robust choice is an **alternating-line smoother**, which alternates between $x$-line and $y$-line smoothing passes.\n\n2.  **Robust Coarsening**: The coarsening strategy must ensure that strong connections are preserved on the coarse grid.\n    *   The standard robust choice is **semicoarsening**. Instead of coarsening in all directions, we coarsen *only* in the direction of weak coupling. For example, if anisotropy is strong horizontally ($\\theta \\approx 0$), we coarsen only vertically. This keeps the strongly-coupled horizontal lines intact on the coarse grid, allowing the coarse-grid correction to effectively handle errors that are smooth along these lines.\n    *   For arbitrary $\\theta$, one may apply semicoarsening in the grid direction that is more weakly coupled with the physics.\n\n**Justification from First Principles**:\nThe combination of a line smoother and semicoarsening is robust because it partitions the task. The line smoother (e.g., along $x$-lines) efficiently damps all error modes that are oscillatory along $x$-lines. The error modes that remain are smooth along $x$-lines. Semicoarsening in the $y$-direction preserves the $x$-lines. Thus, the remaining errors, being smooth along these preserved lines, are well-approximated on the coarse grid and can be eliminated by the coarse-grid correction.\n\nFor general anisotropy, this geometric approach becomes complex. **Algebraic Multigrid (AMG)** is a more advanced \"black-box\" approach that automatically implements this philosophy. AMG inspects the matrix entries to identify \"strong connections\" and uses this information algorithmically to choose coarse-grid points (a form of semicoarsening) and to construct interpolation operators that are accurate for the problematic smooth error modes.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the LFA for the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 0.0),          # Case 1: Isotropic\n        (0.1, 0.0),          # Case 2: Moderate axis-aligned anisotropy\n        (1e-6, 0.0),         # Case 3: Strong axis-aligned anisotropy\n        (0.01, np.pi/4),     # Case 4: Strong diagonal anisotropy\n        (1e-6, np.pi/3),     # Case 5: Strong general anisotropy\n    ]\n\n    results = []\n    for epsilon, theta in test_cases:\n        rho_tg = compute_rho_tg(epsilon, theta)\n        results.append(round(rho_tg, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_rho_tg(epsilon, theta, N=64, h=1.0, omega=2/3.0):\n    \"\"\"\n    Computes the two-grid convergence factor rho_TG using Local Fourier Analysis.\n\n    Args:\n        epsilon (float): The anisotropy ratio.\n        theta (float): The rotation angle in radians.\n        N (int): Number of samples per dimension in the Fourier domain.\n        h (float): Grid spacing.\n        omega (float): Weighted Jacobi smoothing parameter.\n\n    Returns:\n        float: The numerically computed two-grid convergence factor.\n    \"\"\"\n    # 1. Define K tensor components\n    c, s = np.cos(theta), np.sin(theta)\n    c2, s2, cs = c*c, s*s, c*s\n    Kxx = c2 + epsilon * s2\n    Kyy = s2 + epsilon * c2\n    Kxy = (1.0 - epsilon) * cs\n    \n    # 2. Define the discrete operator symbol a(xi)\n    h2 = h * h\n    def get_symbol_a(eta_x, eta_y):\n        cos_ex = np.cos(eta_x)\n        cos_ey = np.cos(eta_y)\n        cos_ex_minus_ey = np.cos(eta_x - eta_y)\n        cos_ex_plus_ey = np.cos(eta_x + eta_y)\n        \n        term1 = 2.0 / h2 * (Kxx * (1.0 - cos_ex) + Kyy * (1.0 - cos_ey))\n        term2 = Kxy / h2 * (cos_ex_minus_ey - cos_ex_plus_ey)\n        \n        return term1 + term2\n\n    # 3. Define the smoother symbol s(xi)\n    d = (2.0 * Kxx + 2.0 * Kyy) / h2\n    # Ensure d is not zero, though it shouldn't be for SPD K and epsilon > 0.\n    if abs(d) < 1e-15:\n        d = 1.0\n\n    def get_symbol_s(eta_x, eta_y):\n        a_val = get_symbol_a(eta_x, eta_y)\n        return 1.0 - omega * a_val / d\n\n    # 4. Set up the grid for xi in the base region B = [-pi/2, pi/2)^2\n    d_xi = np.pi / N\n    xi_range = -np.pi / 2.0 + d_xi / 2.0 + np.arange(N) * d_xi\n    xi_x_grid, xi_y_grid = np.meshgrid(xi_range, xi_range, indexing='ij')\n    \n    max_rho = 0.0\n    \n    # 5. Loop over all frequencies in the sampled base region\n    I4 = np.identity(4, dtype=np.complex128)\n\n    for i in range(N):\n        for j in range(N):\n            xi_x = xi_x_grid[i, j]\n            xi_y = xi_y_grid[i, j]\n            \n            # Aliases for the current low frequency xi\n            aliases = [\n                (xi_x, xi_y),\n                (xi_x + np.pi, xi_y),\n                (xi_x, xi_y + np.pi),\n                (xi_x + np.pi, xi_y + np.pi)\n            ]\n            \n            # Fine-grid operator symbol matrix A_diag(xi)\n            a_vec = np.array([get_symbol_a(ex, ey) for ex, ey in aliases], dtype=np.complex128)\n            A_diag = np.diag(a_vec)\n            \n            # Smoothing symbol matrices S_pre(xi) and S_post(xi)\n            s_vec = np.array([get_symbol_s(ex, ey) for ex, ey in aliases], dtype=np.complex128)\n            S_pre_post = np.diag(s_vec)\n\n            # Interpolation symbol vector P_hat(xi) and Restriction R_hat(xi)\n            exp_ix = np.exp(1j * xi_x)\n            exp_iy = np.exp(1j * xi_y)\n            \n            # 4x1 vector\n            P_hat = 0.25 * np.array([\n                (1.0 + exp_ix) * (1.0 + exp_iy),\n                (1.0 - exp_ix) * (1.0 + exp_iy),\n                (1.0 + exp_ix) * (1.0 - exp_iy),\n                (1.0 - exp_ix) * (1.0 - exp_iy)\n            ], dtype=np.complex128).reshape(4, 1)\n\n            # 1x4 vector\n            R_hat = P_hat.conj().T\n            \n            # Scalar coarse-grid symbol A_c(xi)\n            A_c_mat = R_hat @ A_diag @ P_hat\n            A_c_scalar = A_c_mat[0, 0]\n            \n            # Coarse-grid correction symbol C(xi)\n            if np.abs(A_c_scalar) < 1e-14:\n                # Handle singularity for numerical stability\n                C = I4\n            else:\n                C = I4 - (P_hat @ R_hat @ A_diag) / A_c_scalar\n\n            # Two-grid error-propagation symbol E(xi)\n            E = S_pre_post @ C @ S_pre_post\n            \n            # Spectral radius of E(xi)\n            try:\n                eigvals = np.linalg.eigvals(E)\n                rho = np.max(np.abs(eigvals))\n                if rho > max_rho:\n                    max_rho = rho\n            except np.linalg.LinAlgError:\n                # This is unlikely for a 4x4 matrix but is safe to have.\n                pass\n                \n    return max_rho\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "A fast convergence rate is only beneficial if the work per iteration is low. This exercise introduces the concept of a \"work unit\" to provide a hardware-independent measure of the computational cost of a V-cycle. By breaking down the cycle into its constituent parts—smoothing, restriction, prolongation, and coarse-solves—you will learn to calculate total work and predict the actual time-to-solution. ",
            "id": "3611397",
            "problem": "A geophysical inversion is dominated by repeated solutions of an elliptic linear system arising from a three-dimensional diffusion model for subsurface conductivity. The linear system is discretized on an unstructured mesh, and the solver is an algebraic multigrid (AMG) method using a single V-cycle per outer iteration. The goal is to estimate both the computational work per V-cycle in work units and the total wall-clock time needed to reduce the residual norm by a specified factor.\n\nAdopt the following definitions and data:\n- A single work unit (WU) is defined as the cost of one sparse matrix–vector product (SpMV) with the finest-level operator. If an operation is equivalent to an SpMV on level $\\ell$, its cost in WU is scaled by the nonzero ratio $\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0}$, where $\\mathrm{NZ}_{\\ell}$ is the number of nonzeros of the operator on level $\\ell$ and $\\mathrm{NZ}_{0}$ is that on the finest level.\n- The multigrid hierarchy has four levels, $\\ell=0,1,2,3$, with finest level $\\ell=0$ and coarsest level $\\ell=3$. The per-level nonzeros are: $\\mathrm{NZ}_{0}=3.2\\times 10^{8}$, $\\mathrm{NZ}_{1}=7.9\\times 10^{7}$, $\\mathrm{NZ}_{2}=1.9\\times 10^{7}$, $\\mathrm{NZ}_{3}=4.7\\times 10^{6}$.\n- On each non-coarsest level ($\\ell=0,1,2$), the smoother is damped Jacobi with $\\nu_{1}=2$ pre-smoothing sweeps and $\\nu_{2}=2$ post-smoothing sweeps. The cost of one smoother sweep on level $\\ell$ is $\\beta\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU with $\\beta=1.1$.\n- On each non-coarsest level, one residual is formed per visit, with cost $\\delta\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU with $\\delta=1.0$.\n- Restriction and prolongation each cost $\\tau_{R}\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU and $\\tau_{P}\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU, respectively, with $\\tau_{R}=\\tau_{P}=0.25$.\n- The coarsest-level solve at $\\ell=3$ uses $m_{c}=30$ smoother sweeps with the same per-sweep cost model $\\beta\\,(\\mathrm{NZ}_{3}/\\mathrm{NZ}_{0})$ WU.\n- The wall-clock time of one finest-level SpMV is $t_{\\mathrm{spmv}}=0.015$ seconds per WU.\n\nAssume the classical two-grid error-propagation interpretation: the coarse-grid correction removes the low-frequency error modes ideally, and the damped Jacobi smoother attenuates the high-frequency error modes. A measured high-frequency smoothing factor per sweep on the finest level is $\\mu_{h}=0.45$. Treat this $\\mu_{h}$ as representative across levels for estimating the per-V-cycle convergence factor. Ignore startup transients and assume asymptotic behavior from the first cycle.\n\nTask:\n1. Using only the data and definitions above, compute the total work in WU for one V-cycle.\n2. Using the interpretation that one full V-cycle reduces the high-frequency error modes by a factor determined by the cumulative smoother effect, predict the number of V-cycles needed to reduce the residual norm by a factor of $10^{-8}$, then predict the total wall-clock time to solution.\n\nRound both the work per V-cycle and the predicted total time-to-solution to four significant figures. Express the time in seconds.",
            "solution": "The problem statement is critically validated and found to be valid. It is scientifically grounded in the principles of numerical linear algebra and computational science, specifically concerning the analysis of algebraic multigrid (AMG) methods. The problem is well-posed, providing all necessary data and definitions for a unique solution. The language is objective and precise.\n\nThe solution is divided into two parts as requested: computation of the work per V-cycle and prediction of the total time-to-solution.\n\n### Part 1: Computational Work per V-cycle\n\nThe total work for one V-cycle, $W_V$, is the sum of the work performed at each level of the multigrid hierarchy. The hierarchy consists of four levels, $\\ell=0, 1, 2, 3$, from finest to coarsest. A standard V-cycle proceeds as follows:\n1.  On each non-coarsest level $\\ell$ from finest to coarsest ($\\ell=0, 1, 2$), perform $\\nu_1$ pre-smoothing sweeps, compute one residual, and restrict the residual to the next coarser level $\\ell+1$.\n2.  On the coarsest level ($\\ell=3$), solve the system (in this case, by applying $m_c$ smoothing sweeps).\n3.  On each non-coarsest level $\\ell$ from coarsest to finest ($\\ell=2, 1, 0$), prolong the correction from the next coarser level $\\ell+1$, add it to the solution, and perform $\\nu_2$ post-smoothing sweeps.\n\nThe cost of each operation is given in work units (WU), scaled by the ratio of nonzeros on the current level, $\\mathrm{NZ}_{\\ell}$, to the nonzeros on the finest level, $\\mathrm{NZ}_{0}$. Let's define this ratio as $r_{\\ell} = \\frac{\\mathrm{NZ}_{\\ell}}{\\mathrm{NZ}_{0}}$.\n\nThe work for each component on a non-coarsest level $\\ell \\in \\{0, 1, 2\\}$ is:\n- Pre-smoothing: $\\nu_{1}$ sweeps, each costing $\\beta r_{\\ell}$ WU. Total: $\\nu_{1}\\beta r_{\\ell}$.\n- Residual computation: $\\delta r_{\\ell}$ WU.\n- Restriction to level $\\ell+1$: $\\tau_{R} r_{\\ell}$ WU.\n- Prolongation from level $\\ell+1$: $\\tau_{P} r_{\\ell}$ WU.\n- Post-smoothing: $\\nu_{2}$ sweeps, each costing $\\beta r_{\\ell}$ WU. Total: $\\nu_{2}\\beta r_{\\ell}$.\n\nThe work on the coarsest level, $\\ell=3$, is for the solve:\n- Coarse solve: $m_c$ smoother sweeps, each costing $\\beta r_{3}$ WU. Total: $m_{c}\\beta r_{3}$.\n\nSumming the work over all levels gives the total work for one V-cycle, $W_V$:\n$$W_V = \\sum_{\\ell=0}^{2} (\\nu_{1}\\beta r_{\\ell} + \\delta r_{\\ell} + \\tau_{R} r_{\\ell}) + m_{c}\\beta r_{3} + \\sum_{\\ell=0}^{2} (\\tau_{P} r_{\\ell} + \\nu_{2}\\beta r_{\\ell})$$\nWe can combine the terms for the non-coarsest levels:\n$$W_V = \\sum_{\\ell=0}^{2} [(\\nu_{1} + \\nu_{2})\\beta + \\delta + \\tau_{R} + \\tau_{P}] r_{\\ell} + m_{c}\\beta r_{3}$$\n\nFirst, let's calculate the nonzero ratios $r_{\\ell}$:\n- $r_{0} = \\frac{\\mathrm{NZ}_{0}}{\\mathrm{NZ}_{0}} = \\frac{3.2\\times 10^{8}}{3.2\\times 10^{8}} = 1$\n- $r_{1} = \\frac{\\mathrm{NZ}_{1}}{\\mathrm{NZ}_{0}} = \\frac{7.9\\times 10^{7}}{3.2\\times 10^{8}} = \\frac{7.9}{32} = 0.246875$\n- $r_{2} = \\frac{\\mathrm{NZ}_{2}}{\\mathrm{NZ}_{0}} = \\frac{1.9\\times 10^{7}}{3.2\\times 10^{8}} = \\frac{1.9}{32} = 0.059375$\n- $r_{3} = \\frac{\\mathrm{NZ}_{3}}{\\mathrm{NZ}_{0}} = \\frac{4.7\\times 10^{6}}{3.2\\times 10^{8}} = \\frac{4.7}{320} = 0.0146875$\n\nNext, let's substitute the given constants into the formula:\n- $\\nu_{1}=2$, $\\nu_{2}=2$\n- $\\beta=1.1$\n- $\\delta=1.0$\n- $\\tau_{R}=0.25$, $\\tau_{P}=0.25$\n- $m_{c}=30$\n\nThe coefficient for the summation term is:\n$$(\\nu_{1} + \\nu_{2})\\beta + \\delta + \\tau_{R} + \\tau_{P} = (2+2)(1.1) + 1.0 + 0.25 + 0.25 = 4(1.1) + 1.5 = 4.4 + 1.5 = 5.9$$\nThe coefficient for the coarse-grid term is:\n$$m_{c}\\beta = 30 \\times 1.1 = 33$$\nThe formula for $W_V$ becomes:\n$$W_V = 5.9 \\sum_{\\ell=0}^{2} r_{\\ell} + 33 r_{3}$$\nNow, we compute the sum:\n$$\\sum_{\\ell=0}^{2} r_{\\ell} = r_{0} + r_{1} + r_{2} = 1 + 0.246875 + 0.059375 = 1.30625$$\nSubstituting this back into the expression for $W_V$:\n$$W_V = 5.9 \\times 1.30625 + 33 \\times 0.0146875$$\n$$W_V = 7.706875 + 0.4846875 = 8.1915625$$\nRounding to four significant figures, the work per V-cycle is $W_V \\approx 8.192$ WU.\n\n### Part 2: Time-to-solution\n\nTo predict the time-to-solution, we first need to estimate the V-cycle convergence factor, $\\rho_V$. The problem specifies that the coarse-grid correction ideally handles low-frequency errors, so the V-cycle's convergence is determined by the smoother's effectiveness on high-frequency errors. The total number of smoothing sweeps on any single level during one V-cycle is $\\nu_{1} + \\nu_{2}$. With a high-frequency smoothing factor per sweep of $\\mu_{h}=0.45$, the cumulative reduction of high-frequency error per V-cycle is:\n$$\\rho_V \\approx (\\mu_{h})^{\\nu_{1}+\\nu_{2}} = (0.45)^{2+2} = (0.45)^{4} = 0.04100625$$\n\nNext, we determine the number of V-cycles, $k$, required to reduce the residual norm by a factor of $10^{-8}$. We solve for $k$ in the inequality:\n$$(\\rho_V)^{k} \\le 10^{-8}$$\nTaking the natural logarithm of both sides:\n$$k \\ln(\\rho_V) \\le \\ln(10^{-8}) = -8 \\ln(10)$$\nSince $\\rho_V < 1$, its logarithm is negative. Dividing by $\\ln(\\rho_V)$ reverses the inequality:\n$$k \\ge \\frac{-8 \\ln(10)}{\\ln(\\rho_V)}$$\n$$k \\ge \\frac{-8 \\ln(10)}{\\ln(0.04100625)} \\approx \\frac{-8 \\times 2.302585}{-3.194001} \\approx \\frac{-18.42068}{-3.194001} \\approx 5.76727$$\nSince the number of cycles must be an integer, we take the ceiling of this value:\n$$k = \\lceil 5.76727 \\rceil = 6$$\nSo, $6$ V-cycles are required.\n\nFinally, the total wall-clock time, $T_{\\text{total}}$, is the product of the number of cycles, the work per cycle, and the time per work unit.\n$$T_{\\text{total}} = k \\times W_V \\times t_{\\mathrm{spmv}}$$\nUsing the unrounded value of $W_V$ for accuracy, and given $t_{\\mathrm{spmv}}=0.015$ seconds per WU:\n$$T_{\\text{total}} = 6 \\times 8.1915625 \\, \\text{WU} \\times 0.015 \\, \\frac{\\text{s}}{\\text{WU}}$$\n$$T_{\\text{total}} = 0.737240625 \\, \\text{s}$$\nRounding to four significant figures, the total time-to-solution is $T_{\\text{total}} \\approx 0.7372$ seconds.",
            "answer": "$$\\boxed{\\begin{pmatrix} 8.192 & 0.7372 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Many problems in geophysics, such as fluid flow in fractured media, lead to discrete systems with non-trivial nullspaces corresponding to conservation laws. A robust algebraic multigrid solver must preserve this nullspace to maintain correctness and avoid introducing spurious singularities on coarse grids. This coding exercise provides a hands-on method to verify this essential property for a toy problem representing disconnected pore clusters. ",
            "id": "3611418",
            "problem": "Consider discrete diffusion on a pore-network graph with isolated pore clusters and pure Neumann (zero-flux) boundary conditions, a canonical scenario in computational geophysics. The discrete operator is the graph Laplacian, which enforces conservation of flux at every node. Under pure Neumann boundary conditions on a disconnected graph, the nullspace of the Laplacian is spanned by the piecewise constant vectors on each connected component. This leads to an expected nullspace dimension equal to the number of disconnected components. Algebraic Multigrid (AMG) must preserve this nullspace to avoid introducing spurious singularities on coarse levels.\n\nFundamental base and definitions to be used:\n- The discrete conservation law for a graph implies that the sum of fluxes leaving a node equals zero, which yields a graph Laplacian matrix $A \\in \\mathbb{R}^{N \\times N}$ with zero row sums: for each row $i$, $\\sum_{j=1}^{N} A_{ij} = 0$.\n- The graph Laplacian is defined as $A = D - W$, where $W$ is the adjacency (or weight) matrix and $D$ is the diagonal degree matrix with entries $D_{ii} = \\sum_{j=1}^{N} W_{ij}$.\n- Pure Neumann boundary conditions in this discrete setting imply that constant vectors on each connected component lie in the nullspace of $A$, hence the nullspace dimension equals the number of connected components.\n- Algebraic Multigrid (AMG) coarsening by smoothed aggregation constructs a prolongation operator $P \\in \\mathbb{R}^{N \\times n_c}$ (with $n_c$ coarse unknowns) from near-nullspace vectors and aggregates, and forms a coarse operator $A_c = P^{\\top} A P$. Smoothed aggregation employs a Jacobi-type smoother $S = I - \\omega D^{-1} A$ applied to tentative prolongation columns, where $I$ is the identity, $\\omega \\in (0,2)$ is a relaxation parameter, and $D^{-1}$ is the inverse of the diagonal degree matrix (with the convention that entries corresponding to zero diagonal are treated as zero).\n- The goal is to verify that the fine-level nullspace dimension is equal to the number of connected components and that the coarse-level nullspace dimension equals the number of aggregates, thereby demonstrating AMG’s ability to preserve nullspaces and avoid creating singular coarse operators beyond the expected nullspace from Neumann boundary conditions.\n\nYour task is to write a complete program that:\n1. Constructs toy pore-network graphs with disconnected components. For each test case, assemble the symmetric graph Laplacian $A$ using unit edge weights and pure Neumann boundary conditions (i.e., no modification to enforce Dirichlet conditions).\n2. Defines aggregates equal to the disconnected components. For each aggregate, forms a tentative prolongation column equal to the piecewise constant near-nullspace vector for that component, applies a Jacobi smoother $S = I - \\omega D^{-1} A$ with a fixed relaxation parameter $\\omega$ to each tentative column, and normalizes the resulting columns to have unit Euclidean norm. Assemble the prolongation $P$ by stacking these smoothed, normalized columns.\n3. Forms the coarse operator $A_c = P^{\\top} A P$.\n4. Computes the nullspace dimension of $A$ and $A_c$ using eigenvalue analysis, counting eigenvalues less than or equal to a small nonnegative tolerance $\\tau$ as zero. Use a fixed tolerance $\\tau$ across all tests.\n5. For each test case, returns a list $[\\text{fine\\_ok}, \\text{coarse\\_ok}]$ of booleans, where $\\text{fine\\_ok}$ is true if the nullspace dimension of $A$ equals the number of disconnected components, and $\\text{coarse\\_ok}$ is true if the nullspace dimension of $A_c$ equals the number of aggregates (which is set equal to the number of disconnected components).\n\nUse the following test suite, where each cluster is specified by the number of nodes and a list of undirected edges with unit weights:\n- Test case $1$ (happy path): three disconnected clusters.\n  - Cluster $1$: $4$ nodes with edges $(0,1)$, $(1,2)$, $(2,3)$.\n  - Cluster $2$: $5$ nodes with edges $(0,1)$, $(1,2)$, $(2,3)$, $(3,4)$.\n  - Cluster $3$: $3$ nodes with edges $(0,1)$, $(1,2)$.\n- Test case $2$ (boundary condition): a single isolated node (one cluster with $1$ node and no edges).\n- Test case $3$ (edge case with varied connectivity): two disconnected clusters.\n  - Cluster $1$: $3$ nodes with edges $(0,1)$, $(1,2)$.\n  - Cluster $2$: $3$ nodes forming a triangle with edges $(0,1)$, $(1,2)$, $(2,0)$.\n\nNumerical specifications:\n- Use $\\omega = 0.8$ for the Jacobi smoother in $S = I - \\omega D^{-1} A$.\n- Use $\\tau = 10^{-10}$ for eigenvalue-based nullspace detection.\n- All angles (if any were used) must be in radians. There are no physical units required for this task.\n- All arrays are in purely mathematical form; there are no physical units in the output.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a comma-separated list enclosed in square brackets. For example, the output should look like $[[\\text{True},\\text{True}],[\\text{True},\\text{False}],\\ldots]$ with no spaces anywhere in the line.\n\nYour program must be self-contained, perform the above steps for the three specified test cases, and output the boolean results in the exact format described.",
            "solution": "The problem requires the verification of a fundamental property of Algebraic Multigrid (AMG) methods when applied to problems with multiple nullspace vectors, such as those arising from diffusion on disconnected domains with pure Neumann boundary conditions. Specifically, we must confirm that a smoothed aggregation AMG method correctly preserves the nullspace of the discrete operator, ensuring the coarse-grid problem is well-posed and does not introduce spurious singularities. The validation proceeds by constructing the fine-grid operator, applying one step of the AMG setup process to obtain a coarse-grid operator, and then comparing the nullspace dimensions of both operators against their theoretically expected values.\n\nFirst, we model the pore-network graph for each test case. A graph with $N$ total nodes is represented by a symmetric weight matrix $W \\in \\mathbb{R}^{N \\times N}$, where $W_{ij} = W_{ji}$ is the weight of the edge between nodes $i$ and $j$ (here, all weights are $1$), and $W_{ij} = 0$ if no edge exists. The graph Laplacian $A \\in \\mathbb{R}^{N \\times N}$ is then constructed as $A = D - W$. Here, $D$ is the diagonal degree matrix with entries $D_{ii} = \\sum_{j=1}^{N} W_{ij}$, representing the sum of weights of edges connected to node $i$. This construction ensures that the row sums of $A$ are zero, i.e., $\\sum_{j=1}^{N} A_{ij} = 0$ for all $i$. This property is the discrete analogue of a conservation law (e.g., conservation of mass or energy) under pure Neumann (zero-flux) boundary conditions.\n\nFor a disconnected graph with $k$ connected components, the nullspace of the corresponding Laplacian $A$ has a dimension of $k$. The basis vectors for this nullspace are the piecewise constant vectors; that is, vectors that are constant on one connected component and zero elsewhere. Our first verification step, yielding the boolean $\\text{fine\\_ok}$, is to numerically compute the nullspace dimension of the fine-grid operator $A$ and check if it equals the number of disconnected components given in the test case. The nullspace dimension is determined by counting the number of eigenvalues of $A$ that are zero, within a numerical tolerance $\\tau = 10^{-10}$. We use the absolute value of the eigenvalues for this check, i.e., $|\\lambda| \\le \\tau$.\n\nNext, we construct the coarse-grid operator $A_c$ using the principles of smoothed aggregation. The core idea of AMG is to represent the slow-to-converge (smooth) error components on a coarser grid. For Neumann problems, the smoothest components are the nullspace vectors themselves. AMG must preserve these vectors in the coarse representation to be effective.\n\n1.  **Aggregation**: We define the aggregates to be the connected components of the graph. The number of aggregates, $n_c$, is therefore equal to the number of connected components, $k$.\n\n2.  **Tentative Prolongation**: For each of the $n_c$ aggregates, we form a tentative prolongation vector. This vector is the characteristic vector of the aggregate—it has a value of $1$ for all nodes within that aggregate and $0$ for all nodes outside it. These vectors form the basis of the fine-grid nullspace.\n\n3.  **Smoothing**: Each tentative prolongation vector is then smoothed. The specified smoother is a Jacobi-type smoother, defined by the operator $S = I - \\omega D^{-1} A$, where $I$ is the identity matrix, $\\omega = 0.8$ is a relaxation parameter, and $D^{-1}$ is the inverse of the diagonal of $D$. For any isolated node $i$ where $D_{ii} = 0$, the corresponding entry $(D^{-1})_{ii}$ is taken to be $0$. A crucial property of this smoother is that it does not alter vectors in the nullspace of $A$. If $\\mathbf{v}$ is a nullspace vector, then $A\\mathbf{v} = \\mathbf{0}$. Applying the smoother gives $S\\mathbf{v} = (I - \\omega D^{-1} A)\\mathbf{v} = I\\mathbf{v} - \\omega D^{-1}(A\\mathbf{v}) = \\mathbf{v} - \\mathbf{0} = \\mathbf{v}$. Since our tentative prolongators are precisely the nullspace vectors, the smoothing step leaves them unchanged.\n\n4.  **Prolongation Operator $P$**: The columns of the prolongation operator $P \\in \\mathbb{R}^{N \\times n_c}$ are formed by taking each (un-altered) tentative vector and normalizing it to have a unit Euclidean norm.\n\nFinally, the coarse-grid operator $A_c \\in \\mathbb{R}^{n_c \\times n_c}$ is formed using the Galerkin projection: $A_c = P^{\\top} A P$. Since the columns of $P$, denoted $\\mathbf{p}_j$, are linear combinations of the fine-grid nullspace vectors, we have $A\\mathbf{p}_j = \\mathbf{0}$ for each column $j = 1, \\dots, n_c$. Consequently, each entry of the coarse-grid operator is expected to be zero: $(A_c)_{ij} = \\mathbf{p}_i^{\\top} A \\mathbf{p}_j = \\mathbf{p}_i^{\\top} (\\mathbf{0}) = 0$. Thus, $A_c$ should be the zero matrix of size $n_c \\times n_c$. The nullspace of the zero matrix is the entire space, so its dimension is $n_c$. The second verification step, yielding $\\text{coarse\\_ok}$, is to compute the nullspace dimension of $A_c$ (by counting its zero eigenvalues within tolerance $\\tau$) and check if it equals the number of aggregates, $n_c$.\n\nThe following program implements this entire procedure for the three specified test cases. It constructs the matrices $A$ and $P$, computes $A_c$, and performs eigenvalue analysis to determine the nullspace dimensions for verification.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the AMG nullspace preservation test for all cases.\n    \"\"\"\n\n    # Numerical specifications from the problem statement\n    omega = 0.8\n    tau = 1e-10\n\n    # Test case definitions\n    test_cases = [\n        # Test case 1: three disconnected clusters\n        [\n            {'nodes': 4, 'edges': [(0, 1), (1, 2), (2, 3)]},\n            {'nodes': 5, 'edges': [(0, 1), (1, 2), (2, 3), (3, 4)]},\n            {'nodes': 3, 'edges': [(0, 1), (1, 2)]},\n        ],\n        # Test case 2: a single isolated node\n        [\n            {'nodes': 1, 'edges': []},\n        ],\n        # Test case 3: two disconnected clusters with varied connectivity\n        [\n            {'nodes': 3, 'edges': [(0, 1), (1, 2)]},\n            {'nodes': 3, 'edges': [(0, 1), (1, 2), (2, 0)]},\n        ],\n    ]\n\n    all_results = []\n    for clusters in test_cases:\n        num_clusters = len(clusters)\n        \n        # Determine total number of nodes and build node offset map\n        total_nodes = sum(c['nodes'] for c in clusters)\n        node_offsets = np.cumsum([0] + [c['nodes'] for c in clusters[:-1]])\n        \n        # 1. Construct the symmetric graph Laplacian A\n        W = np.zeros((total_nodes, total_nodes))\n        for i, cluster in enumerate(clusters):\n            offset = node_offsets[i]\n            for u, v in cluster['edges']:\n                # Use unit edge weights\n                W[offset + u, offset + v] = 1.0\n                W[offset + v, offset + u] = 1.0\n        \n        d_diag = np.sum(W, axis=1)\n        D = np.diag(d_diag)\n        A = D - W\n        \n        # 4. Compute the nullspace dimension of A\n        eigvals_A = np.linalg.eigh(A)[0]\n        dim_null_A = np.sum(np.abs(eigvals_A) <= tau)\n        \n        fine_ok = (dim_null_A == num_clusters)\n        \n        # 2. Define aggregates and construct prolongation operator P\n        # Aggregates are the disconnected components\n        num_aggregates = num_clusters\n        \n        # Construct the Jacobi smoother S = I - omega * D_inv * A\n        d_inv_diag = np.zeros(total_nodes)\n        non_zero_diag = d_diag > 0\n        d_inv_diag[non_zero_diag] = 1.0 / d_diag[non_zero_diag]\n        D_inv = np.diag(d_inv_diag)\n        S = np.identity(total_nodes) - omega * (D_inv @ A)\n        \n        p_cols = []\n        for i in range(num_clusters):\n            # Form tentative prolongation column (piecewise constant vector)\n            p_tentative = np.zeros(total_nodes)\n            offset = node_offsets[i]\n            num_cluster_nodes = clusters[i]['nodes']\n            p_tentative[offset : offset + num_cluster_nodes] = 1.0\n            \n            # Apply smoother\n            p_smoothed = S @ p_tentative\n            \n            # Normalize the resulting column\n            norm = np.linalg.norm(p_smoothed)\n            if norm > 1e-15: # Avoid division by zero\n                p_col = p_smoothed / norm\n            else:\n                p_col = p_smoothed\n                \n            p_cols.append(p_col)\n            \n        P = np.column_stack(p_cols)\n        \n        # 3. Form the coarse operator Ac\n        Ac = P.T @ A @ P\n        \n        # 4. Compute the nullspace dimension of Ac\n        eigvals_Ac = np.linalg.eigh(Ac)[0]\n        dim_null_Ac = np.sum(np.abs(eigvals_Ac) <= tau)\n        \n        coarse_ok = (dim_null_Ac == num_aggregates)\n        \n        # 5. Store the boolean results for the current test case\n        all_results.append([fine_ok, coarse_ok])\n\n    # Format the final output string as specified: [[...],[...],...]\n    case_strs = [f\"[{'True' if res[0] else 'False'},{'True' if res[1] else 'False'}]\" for res in all_results]\n    print(f\"[{','.join(case_strs)}]\")\n\nsolve()\n```"
        }
    ]
}