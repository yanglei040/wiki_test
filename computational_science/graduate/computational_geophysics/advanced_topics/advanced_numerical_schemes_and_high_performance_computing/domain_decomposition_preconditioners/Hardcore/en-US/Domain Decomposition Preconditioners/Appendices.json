{
    "hands_on_practices": [
        {
            "introduction": "A robust domain decomposition preconditioner must effectively handle the complexities arising from realistic geophysical models, such as high-contrast media and intricate geometries. This can lead to scenarios where a single subdomain is internally disconnected by impermeable features. This conceptual exercise  explores the fundamental requirement for a robust coarse space in such challenging situations. By analyzing the nullspace of the local subdomain operator, you will discover why a simple coarse space fails and what specific enrichment is necessary to guarantee a scalable preconditioner.",
            "id": "3586626",
            "problem": "Consider the heterogeneous scalar diffusion model for steady-state flow in the subsurface, written as the elliptic boundary value problem $\\nabla \\cdot (\\kappa \\nabla u) = f$ in a bounded domain $\\Omega \\subset \\mathbb{R}^d$ with appropriate boundary conditions, where $\\kappa(\\mathbf{x})$ denotes a positive, spatially varying conductivity that may exhibit high contrast and geometric complexity typical of computational geophysics. Discretization by a conforming finite element method leads to a symmetric positive definite linear system $A u = b$ with bilinear form $a(u,v) = \\int_{\\Omega} \\kappa \\nabla u \\cdot \\nabla v \\, d\\mathbf{x}$.\n\nTo precondition $A$, consider a two-level domain decomposition method in which $\\Omega$ is partitioned into $N$ nonoverlapping subdomains $\\{D_i\\}_{i=1}^N$, and the coarse space provides global coupling while local spaces are associated with subdomain solvers. Denote by $A_i$ the local operator corresponding to the subdomain $D_i$ equipped with homogeneous Neumann conditions on internal interfaces. In practice for high-contrast geology, a subdomain interior $D_i$ can be disconnected due to the presence of impermeable inclusions or cavities (e.g., salt bodies, voids), so that $D_i = \\bigcup_{m=1}^{M_i} D_i^{(m)}$ with each $D_i^{(m)}$ a connected open set and $M_i \\ge 2$.\n\nFrom first principles, recall that the local Neumann operator $A_i$ on $D_i$ acts through the restriction of $a(\\cdot,\\cdot)$ to $H^1(D_i)$ and enforces zero normal flux across the interface $\\partial D_i \\cap \\mathrm{int}(\\Omega)$. For each connected component $D_i^{(m)}$, the local energy $a(\\cdot,\\cdot)$ vanishes on constant functions supported on $D_i^{(m)}$; thus, the nullspace $\\ker(A_i)$ contains the span of componentwise constants, with dimension at least $M_i$.\n\nIn two-level Additive Schwarz and Balancing Domain Decomposition by Constraints (BDDC), a robust coarse space must capture global low-energy modes that otherwise degrade the condition number. A similar requirement exists for Finite Element Tearing and Interconnecting - Dual-Primal (FETI-DP). Suppose the current coarse space only includes one average per subdomain or only vertex-based constraints, without accounting for the multiplicity of interior connectivity.\n\nWhich option correctly explains why the coarse space must include modes that couple the disconnected parts and proposes a simple enrichment that ensures a proper coarse correction for the heterogeneous diffusion operator described above?\n\nA. Because the local Neumann problems on $D_i$ possess a nullspace spanned by functions that are constant on each connected component $D_i^{(m)}$, any coarse space that fails to represent all such componentwise constants leaves uncoupled, low-energy modes in $\\ker(A_i)$ that appear as small eigenvalues of the preconditioned operator. A simple enrichment is to add, for every subdomain $D_i$ and each component $D_i^{(m)}$, one coarse basis function that is constant on $D_i^{(m)}$ (and zero elsewhere), equivalently enforcing one primal constraint per connected component (componentwise average) so that $\\ker(A_i) \\subset \\mathrm{Range}$ of the coarse space.\n\nB. Because Krylov methods stall on oscillatory wave solutions, the remedy is to add a damped Jacobi smoother; coarse space enrichment is unnecessary as long as the iterative method is restarted frequently.\n\nC. Because insufficient overlap prevents information transfer, increasing the overlap between subdomains by a factor of $2$ guarantees coupling of disconnected interiors and obviates the need to modify the coarse space.\n\nD. Because disconnected interiors cause rank deficiency only at geometric vertices, it suffices to add one vertex-based coarse degree of freedom per subdomain; there is no need for componentwise constraints or basis functions.\n\nE. Because high permeability contrast induces high-frequency bubble modes, enriching the coarse space with subdomain bubble functions that vanish on all interfaces and average to zero on each $D_i$ is sufficient to couple disconnected components.",
            "solution": "The user wants me to act as a STEM professor. My task is to first validate the problem statement and then, if it is valid, provide a detailed solution by deriving the answer from first principles and evaluating each option.\n\n### Problem Validation\n\nFirst, I will validate the problem statement according to the specified procedure.\n\n**Step 1: Extract Givens**\n\n*   **Governing Equation:** Heterogeneous scalar diffusion model, $\\nabla \\cdot (\\kappa \\nabla u) = f$.\n*   **Domain:** A bounded domain $\\Omega \\subset \\mathbb{R}^d$.\n*   **Boundary Conditions:** \"appropriate boundary conditions\".\n*   **Coefficient:** $\\kappa(\\mathbf{x})$ is a positive, spatially varying conductivity, potentially with high contrast and geometric complexity.\n*   **Discretization:** Conforming finite element method, resulting in a symmetric positive definite linear system $A u = b$.\n*   **Bilinear Form:** $a(u,v) = \\int_{\\Omega} \\kappa \\nabla u \\cdot \\nabla v \\, d\\mathbf{x}$.\n*   **Preconditioner:** A two-level domain decomposition method (e.g., Additive Schwarz, BDDC, FETI-DP).\n*   **Domain Partition:** $\\Omega$ is partitioned into $N$ nonoverlapping subdomains $\\{D_i\\}_{i=1}^N$.\n*   **Method Structure:** A coarse space for global coupling and local spaces for subdomain solvers.\n*   **Local Operator:** $A_i$ is the local operator for subdomain $D_i$ with homogeneous Neumann conditions on internal interfaces ($\\partial D_i \\cap \\mathrm{int}(\\Omega)$). It is derived from the restriction of $a(\\cdot,\\cdot)$ to functions in $H^1(D_i)$.\n*   **Key Scenario:** Subdomain interiors can be disconnected, $D_i = \\bigcup_{m=1}^{M_i} D_i^{(m)}$, with $M_i \\ge 2$ connected components $D_i^{(m)}$.\n*   **Local Nullspace:** The nullspace $\\ker(A_i)$ contains the span of functions that are constant on each component $D_i^{(m)}$, and its dimension is at least $M_i$.\n*   **Deficient Coarse Space:** The assumed coarse space is insufficient, including only one average per subdomain or only vertex-based constraints.\n*   **Question:** Identify the correct explanation for why the coarse space must be enriched to handle this situation and what a simple, proper enrichment would be.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded:** The problem is firmly rooted in the well-established fields of numerical analysis for partial differential equations and scientific computing. The diffusion equation, finite element methods, and domain decomposition preconditioners (Additive Schwarz, BDDC, FETI-DP) are standard, fundamental topics. The specific issue of handling disconnected subdomains arising from complex geometries is a known, practical challenge in applications like computational geophysics. The characterization of the nullspace of local Neumann operators is a standard result in PDE theory. The problem is scientifically and mathematically sound.\n*   **Well-Posed:** The problem is well-posed. It presents a clear, specific question about the design of robust domain decomposition preconditioners under a well-defined set of circumstances. An answer based on the established theory of these methods exists and is expected.\n*   **Objective:** The problem is stated in precise, objective, and technical language. It is free from subjective claims or ambiguity.\n\n**Flaw Checklist:**\n\n1.  **Scientific or Factual Unsoundness:** None. The premises are correct. The nullspace of the Neumann problem on a domain with $M_i$ connected components is indeed $M_i$-dimensional.\n2.  **Non-Formalizable or Irrelevant:** None. The problem is highly formal and directly relevant to the topic.\n3.  **Incomplete or Contradictory Setup:** None. While the global boundary conditions on $\\Omega$ are not specified, they are not necessary for analyzing the internal structure of the domain decomposition preconditioner, which is the focus of the question. The setup is self-contained and consistent.\n4.  **Unrealistic or Infeasible:** None. The physical scenario of impermeable inclusions causing disconnected subdomains is realistic in geophysics and other fields.\n5.  **Ill-Posed or Poorly Structured:** None. The problem logic is clear, uncontaminated by circular reasoning, and uses standard, well-defined terminology.\n6.  **Pseudo-Profound, Trivial, or Tautological:** None. This addresses a key, non-trivial concept for ensuring the robustness of advanced preconditioners.\n7.  **Outside Scientific Verifiability:** None. The principles involved are mathematically provable and numerically verifiable.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. I will proceed to derive the solution.\n\n### Solution Derivation\n\nThe effectiveness of a two-level domain decomposition preconditioner hinges on the proper interaction between the local solvers and the global coarse correction. The preconditioner can be conceptually written as the sum of a coarse correction operator and a set of local correction operators. Iterative methods, such as the Preconditioned Conjugate Gradient (PCG) method, converge rapidly if the spectrum of the preconditioned operator $M^{-1}A$ is favorably clustered, ideally with a condition number independent of discretization parameters ($h$) and the number of subdomains ($N$).\n\nThe core principle is a decomposition of the solution space into a coarse component and a local component. The coarse component handles low-frequency, global-scale error components, while the local solvers handle high-frequency, local-scale error components. The \"energy\" of a function $u$ is given by the bilinear form $a(u,u) = \\int_{\\Omega} \\kappa |\\nabla u|^2 d\\mathbf{x}$. Problematic error modes for a domain decomposition method are those that have low energy but are not well-represented in the coarse space.\n\nIn the context of the problem, the local solvers correspond to inverting (or approximately inverting) the local operators $A_i$. These operators are defined on the subdomain $D_i$ with homogeneous Neumann conditions on the internal boundaries. The energy associated with $A_i$ is $a_i(u_i, u_i) = \\int_{D_i} \\kappa |\\nabla u_i|^2 d\\mathbf{x}$. The nullspace of $A_i$, denoted $\\ker(A_i)$, consists of functions $u_i \\in H^1(D_i)$ for which this energy is zero. Since $\\kappa > 0$, this implies $\\nabla u_i = \\mathbf{0}$ throughout $D_i$.\n\nThe problem states that a subdomain $D_i$ may consist of $M_i$ disjoint connected components, $D_i = \\bigcup_{m=1}^{M_i} D_i^{(m)}$. A function $u_i$ has a zero gradient on $D_i$ if and only if it is constant on each connected component $D_i^{(m)}$. The constant value can differ between components. Let $\\chi_i^{(m)}$ be the characteristic function on component $D_i^{(m)}$. Then, any function in $\\ker(A_i)$ is of the form $\\sum_{m=1}^{M_i} c_m \\chi_i^{(m)}$ for some constants $c_m$. This means the nullspace $\\ker(A_i)$ is an $M_i$-dimensional vector space spanned by these componentwise constant functions. These are the \"floating modes\" of the subdomain.\n\nA fundamental requirement for a robust two-level preconditioner, particularly for methods like BDDC and FETI-DP, is that the coarse space must contain all modes that belong to the nullspace of the local problems. In other words, any function that cannot be \"seen\" by the local solvers (i.e., has zero local energy) must be fully captured and constrained by the coarse solver. If this condition is violated, these nullspace modes are not properly corrected by either the local or the coarse part of the preconditioner. They manifest as error components that are annihilated by the local part of the preconditioner but are uncontrolled by the coarse grid. This leads to eigenvalues of the preconditioned operator that are very close to zero, causing the condition number to become extremely large and severely degrading the convergence of Krylov solvers.\n\nThe \"deficient\" coarse space mentioned in the problem (one average per subdomain, or vertex constraints) fails this test when $M_i > 1$. A single average constraint on $D_i$ only constrains one linear combination of the $M_i$ componentwise constants, leaving $M_i - 1$ floating modes unconstrained. Vertex constraints are also generally insufficient, as a floating component may not contain any of the selected vertices.\n\nThe direct and correct remedy is to enrich the coarse space to ensure it can represent any function in $\\ker(A_i)$ for all $i=1, \\dots, N$. The simplest way to achieve this is to introduce one coarse degree of freedom for each connected component $D_i^{(m)}$ of each subdomain $D_i$. In primal methods like BDDC, this translates to enforcing one constraint per component, such as the average value of the solution on that component. In dual methods like FETI-DP or in the coarse space construction for Additive Schwarz, this corresponds to adding one coarse basis function for each component, where the basis function is typically the characteristic function of that component, $\\chi_i^{(m)}$. This enrichment ensures that the condition $\\ker(A_i) \\subset \\text{Range of Coarse Interpolation}$ is satisfied for all $i$, thereby restoring robustness.\n\n### Option-by-Option Analysis\n\n**A. Because the local Neumann problems on $D_i$ possess a nullspace spanned by functions that are constant on each connected component $D_i^{(m)}$, any coarse space that fails to represent all such componentwise constants leaves uncoupled, low-energy modes in $\\ker(A_i)$ that appear as small eigenvalues of the preconditioned operator. A simple enrichment is to add, for every subdomain $D_i$ and each component $D_i^{(m)}$, one coarse basis function that is constant on $D_i^{(m)}$ (and zero elsewhere), equivalently enforcing one primal constraint per connected component (componentwise average) so that $\\ker(A_i) \\subset \\mathrm{Range}$ of the coarse space.**\n\n*   **Analysis:** This option provides a complete and accurate account. It correctly identifies the nullspace of the local Neumann problem ($M_i$-dimensional space of componentwise constants). It correctly diagnoses the consequence of a deficient coarse space: unconstrained low-energy modes from $\\ker(A_i)$ which result in small eigenvalues of the preconditioned operator. Finally, it proposes the standard and correct enrichment: one coarse degree of freedom per connected component, correctly linking the concepts of coarse basis functions (Schwarz/FETI-DP perspective) and primal constraints (BDDC perspective). The final clause correctly states the mathematical condition for robustness.\n*   **Verdict:** Correct.\n\n**B. Because Krylov methods stall on oscillatory wave solutions, the remedy is to add a damped Jacobi smoother; coarse space enrichment is unnecessary as long as the iterative method is restarted frequently.**\n\n*   **Analysis:** This option is fundamentally flawed. The problem is a diffusion problem, and the problematic modes are low-energy (non-oscillatory), precisely the opposite of what smoothers like Jacobi are designed to handle. A coarse space is essential for handling these low-frequency modes. Restarting a Krylov method does not fix a poor preconditioner that yields a large condition number.\n*   **Verdict:** Incorrect.\n\n**C. Because insufficient overlap prevents information transfer, increasing the overlap between subdomains by a factor of $2$ guarantees coupling of disconnected interiors and obviates the need to modify the coarse space.**\n\n*   **Analysis:** This option is misguided. The problem is stated for nonoverlapping subdomains, a standard setting for BDDC and FETI-DP. Increasing overlap is pertinent to Schwarz methods, but even there, it does not solve the fundamental issue of local nullspace modes. The coarse grid provides global rigidity, a role that cannot be replaced by simply increasing local overlap. Overlap helps propagate information across interfaces, but it does not constrain modes that are fully internal to a subdomain.\n*   **Verdict:** Incorrect.\n\n**D. Because disconnected interiors cause rank deficiency only at geometric vertices, it suffices to add one vertex-based coarse degree of freedom per subdomain; there is no need for componentwise constraints or basis functions.**\n\n*   **Analysis:** This is incorrect. The rank deficiency is a property of the local operator on the entire subdomain $D_i$ if it's disconnected; it is not localized \"at geometric vertices\". A disconnected component (e.g., an internal void) may not touch any vertex, and thus its floating mode would not be constrained by vertex-based degrees of freedom. The problem statement itself indicates that such simple coarse spaces are insufficient.\n*   **Verdict:** Incorrect.\n\n**E. Because high permeability contrast induces high-frequency bubble modes, enriching the coarse space with subdomain bubble functions that vanish on all interfaces and average to zero on each $D_i$ is sufficient to couple disconnected components.**\n\n*   **Analysis:** This option confuses multiple concepts. The problem is about topological disconnection, not high contrast (though they often occur together). The problematic modes are low-frequency constants, not high-frequency bubble modes. Coarse spaces are for low-frequency modes. Bubble functions, which vanish on the boundary, are by definition orthogonal to the constant functions that make up the nullspace of the Neumann operator. This proposed \"enrichment\" would have no effect on the problem at hand.\n*   **Verdict:** Incorrect.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "While understanding the theoretical requirements for a coarse space is crucial, manually constructing one for every complex problem is impractical. Modern methods automate this process by adaptively identifying the problematic modes that need global correction. This hands-on coding practice  demystifies this procedure using the principles of the Generalized Eigenproblems in the Overlap (GenEO) method. You will use a key theoretical bound from GenEO to translate local spectral information into a practical estimate of the coarse space dimension required to achieve a target convergence rate, connecting abstract theory to computational practice.",
            "id": "3586617",
            "problem": "Consider the scalar elliptic operator encountered in subsurface flow modeling, where the governing equation is the heterogeneous diffusion problem $-\\nabla \\cdot (k(\\mathbf{x}) \\nabla u(\\mathbf{x})) = f(\\mathbf{x})$ with heterogeneous permeability $k(\\mathbf{x})$ taken from Society of Petroleum Engineers (SPE) benchmark data. Suppose the data for SPE10 layer $85$ are mapped to a piecewise linear ($P_1$) finite element (FEM) grid on a rectangular domain, and an overlapping domain decomposition is used to precondition the resulting linear system. Focus on two-level additive Schwarz preconditioning augmented by an adaptive spectral coarse space built from Generalized Eigenproblems in the Overlap (GenEO).\n\nStarting from the standard weak form and overlap-based partition of unity, the GenEO approach constructs, for each subdomain $\\Omega_i$, a local generalized eigenproblem whose Rayleigh quotients measure the propensity of functions to be poorly represented by local solvers plus overlap. A practical coarse space is assembled by selecting local eigenvectors whose eigenvalues lie below a chosen threshold, and extending them by the partition of unity. The adaptive threshold balances the cost of the coarse space dimension with the preconditioner quality.\n\nYour task is to estimate the coarse space dimension required to achieve a target preconditioned condition number $ \\kappa \\le 50 $ using an eigenvalue-threshold selection rule. Use the following principle: if, for each subdomain $\\Omega_i$, all local generalized eigenmodes with eigenvalue $ \\lambda \\le \\theta $ are included in the coarse space, then the remaining subspace on which the local Rayleigh quotients satisfy $ \\lambda \\ge \\theta $ yields a global condition number bounded by\n$$\n\\kappa \\le \\frac{C_{\\text{stab}}}{\\theta},\n$$\nwhere $ C_{\\text{stab}} $ is a stability constant that depends on the decomposition geometry, overlap size, and the partition-of-unity weights (but is independent of coefficient contrasts once the coarse space is enriched). To meet the target $ \\kappa_{\\text{target}} = 50 $, choose the threshold\n$$\n\\theta = \\frac{C_{\\text{stab}}}{\\kappa_{\\text{target}}}.\n$$\nThe estimated coarse space dimension is then computed as the sum over subdomains of the counts of local eigenvalues less than or equal to $ \\theta $:\n$$\n\\dim(\\mathcal{V}_{\\text{coarse}}) \\approx \\sum_{i} \\#\\{\\lambda^{(i)}_j \\,|\\, \\lambda^{(i)}_j \\le \\theta\\}.\n$$\nAssume the eigenvalues are dimensionless (the generalized eigenproblems are normalized using overlap weights and finite element mass forms), and the dimension estimate is the integer count indicated above.\n\nImplement a program that, for each test case, takes:\n- A list of local eigenvalue arrays $[\\{\\lambda^{(1)}_j\\}, \\{\\lambda^{(2)}_j\\}, \\ldots]$, one array per subdomain, each sorted in ascending order and containing representative eigenvalues for the SPE10 layer $85$ permeability mapped to a $P_1$ FEM grid.\n- A stability constant $ C_{\\text{stab}} $ for the given overlap configuration.\n\nThe program must:\n- Set $ \\kappa_{\\text{target}} = 50 $ for all cases.\n- Compute $ \\theta = C_{\\text{stab}} / \\kappa_{\\text{target}} $.\n- Count and sum, over all subdomains, the number of eigenvalues $ \\lambda \\le \\theta $.\n- Return this sum as the estimated coarse space dimension for the case.\n\nProvide results for the following test suite, designed to probe different scenarios:\n\n- Case $1$ (moderate heterogeneity, happy path): $ C_{\\text{stab}} = 25 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.012, 0.08, 0.12, 0.42, 1.1, 3.0]$\n  - Subdomain $2$: $[0.038, 0.09, 0.15, 0.5, 0.8, 2.2]$\n  - Subdomain $3$: $[0.02, 0.07, 0.25, 0.6, 1.5, 2.5]$\n  - Subdomain $4$: $[0.01, 0.05, 0.2, 1.0, 2.0, 6.0]$\n- Case $2$ (boundary case: threshold below all local eigenvalues, yielding zero added coarse modes): $ C_{\\text{stab}} = 25 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.6, 0.9, 1.2]$\n  - Subdomain $2$: $[0.7, 1.0, 1.5]$\n  - Subdomain $3$: $[0.55, 0.8, 3.0]$\n- Case $3$ (extreme high contrast, many very small local eigenvalues): $ C_{\\text{stab}} = 5 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.0005, 0.001, 0.005, 0.02, 0.3, 0.9]$\n  - Subdomain $2$: $[0.0003, 0.002, 0.007, 0.015, 0.08, 0.4]$\n  - Subdomain $3$: $[0.0008, 0.004, 0.012, 0.09, 0.2, 1.0]$\n  - Subdomain $4$: $[0.0001, 0.003, 0.01, 0.04, 0.06, 0.08]$\n- Case $4$ (larger overlap constant, allowing a larger threshold): $ C_{\\text{stab}} = 100 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.02, 0.2, 0.9, 1.8, 2.5, 5.0]$\n  - Subdomain $2$: $[0.03, 0.6, 1.4, 2.1, 4.0]$\n  - Subdomain $3$: $[0.05, 0.4, 0.7, 1.3, 2.7]$\n  - Subdomain $4$: $[0.01, 0.08, 0.3, 0.8, 1.6, 3.6]$\n- Case $5$ (mixed behavior across subdomains): $ C_{\\text{stab}} = 50 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[1.2, 1.5, 2.0]$\n  - Subdomain $2$: $[0.09, 0.2, 0.5, 0.9, 1.1]$\n  - Subdomain $3$: $[0.4, 0.7, 1.1, 1.8]$\n\nFinal output format requirement: Your program should produce a single line of output containing the results for Cases $1$ through $5$ in order as a comma-separated list enclosed in square brackets, for example, $[n_1,n_2,n_3,n_4,n_5]$, where each $n_i$ is the estimated coarse space dimension (an integer). No other text should be printed. All quantities in this problem are dimensionless, so no physical units are required. Angles do not appear. Percentages are not used.",
            "solution": "The problem as stated must first undergo a rigorous validation to ensure it is scientifically sound, self-contained, and well-posed.\n\n**Problem Validation**\n\n**1. Extracted Givens**\n- **Governing Equation**: $-\\nabla \\cdot (k(\\mathbf{x}) \\nabla u(\\mathbf{x})) = f(\\mathbf{x})$ with heterogeneous permeability $k(\\mathbf{x})$.\n- **Discretization and Decomposition**: Piecewise linear ($P_1$) finite element (FEM) grid, overlapping domain decomposition.\n- **Preconditioning Method**: Two-level additive Schwarz augmented by an adaptive spectral coarse space from Generalized Eigenproblems in the Overlap (GenEO).\n- **Condition Number Bound**: $\\kappa \\le \\frac{C_{\\text{stab}}}{\\theta}$, where $\\theta$ is an eigenvalue threshold and $C_{\\text{stab}}$ is a stability constant.\n- **Target Condition Number**: $\\kappa_{\\text{target}} = 50$.\n- **Threshold Selection Rule**: $\\theta = \\frac{C_{\\text{stab}}}{\\kappa_{\\text{target}}}$.\n- **Coarse Space Dimension Estimation**: $\\dim(\\mathcal{V}_{\\text{coarse}}) \\approx \\sum_{i} \\#\\{\\lambda^{(i)}_j \\,|\\, \\lambda^{(i)}_j \\le \\theta\\}$.\n- **Test Cases**:\n    - **Case 1**: $C_{\\text{stab}} = 25$. Eigenvalues: $\\{\\lambda^{(1)}_j\\} = [0.012, 0.08, 0.12, 0.42, 1.1, 3.0]$, $\\{\\lambda^{(2)}_j\\} = [0.038, 0.09, 0.15, 0.5, 0.8, 2.2]$, $\\{\\lambda^{(3)}_j\\} = [0.02, 0.07, 0.25, 0.6, 1.5, 2.5]$, $\\{\\lambda^{(4)}_j\\} = [0.01, 0.05, 0.2, 1.0, 2.0, 6.0]$.\n    - **Case 2**: $C_{\\text{stab}} = 25$. Eigenvalues: $\\{\\lambda^{(1)}_j\\} = [0.6, 0.9, 1.2]$, $\\{\\lambda^{(2)}_j\\} = [0.7, 1.0, 1.5]$, $\\{\\lambda^{(3)}_j\\} = [0.55, 0.8, 3.0]$.\n    - **Case 3**: $C_{\\text{stab}} = 5$. Eigenvalues: $\\{\\lambda^{(1)}_j\\} = [0.0005, 0.001, 0.005, 0.02, 0.3, 0.9]$, $\\{\\lambda^{(2)}_j\\} = [0.0003, 0.002, 0.007, 0.015, 0.08, 0.4]$, $\\{\\lambda^{(3)}_j\\} = [0.0008, 0.004, 0.012, 0.09, 0.2, 1.0]$, $\\{\\lambda^{(4)}_j\\} = [0.0001, 0.003, 0.01, 0.04, 0.06, 0.08]$.\n    - **Case 4**: $C_{\\text{stab}} = 100$. Eigenvalues: $\\{\\lambda^{(1)}_j\\} = [0.02, 0.2, 0.9, 1.8, 2.5, 5.0]$, $\\{\\lambda^{(2)}_j\\} = [0.03, 0.6, 1.4, 2.1, 4.0]$, $\\{\\lambda^{(3)}_j\\} = [0.05, 0.4, 0.7, 1.3, 2.7]$, $\\{\\lambda^{(4)}_j\\} = [0.01, 0.08, 0.3, 0.8, 1.6, 3.6]$.\n    - **Case 5**: $C_{\\text{stab}} = 50$. Eigenvalues: $\\{\\lambda^{(1)}_j\\} = [1.2, 1.5, 2.0]$, $\\{\\lambda^{(2)}_j\\} = [0.09, 0.2, 0.5, 0.9, 1.1]$, $\\{\\lambda^{(3)}_j\\} = [0.4, 0.7, 1.1, 1.8]$.\n\n**2. Analysis**\nThe problem is scientifically grounded, deriving its premises from the established theory of domain decomposition preconditioners, specifically the GenEO method, which is a significant research topic in numerical analysis for partial differential equations. The problem is well-posed, as it provides a deterministic procedure with all necessary inputs to compute a unique output. It is objective, using precise mathematical and computational terminology. The problem does not violate any scientific principles, nor does it contain incomplete or contradictory information. It represents a a simplified but fundamentally correct application of the GenEO convergence theory to estimate a crucial parameterâ€”the coarse space dimension.\n\n**3. Verdict**\nThe problem is valid. We may proceed with the solution.\n\n**Solution**\n\nThe objective is to estimate the dimension of the adaptive coarse space, $\\dim(\\mathcal{V}_{\\text{coarse}})$, for a two-level additive Schwarz preconditioner. The coarse space is constructed using the GenEO methodology, which selects local eigenmodes corresponding to small eigenvalues of generalized eigenproblems defined on the subdomain overlaps.\n\nThe core principle is the theoretical bound on the preconditioned system's condition number, $\\kappa$:\n$$\n\\kappa \\le \\frac{C_{\\text{stab}}}{\\theta}\n$$\nHere, $C_{\\text{stab}}$ is a constant dependent on the geometry of the domain decomposition, and $\\theta$ is the threshold used to select eigenmodes for the coarse space. To ensure the condition number remains below a target value, $\\kappa_{\\text{target}}$, we must choose $\\theta$ such that:\n$$\n\\kappa_{\\text{target}} \\ge \\frac{C_{\\text{stab}}}{\\theta} \\implies \\theta \\le \\frac{C_{\\text{stab}}}{\\kappa_{\\text{target}}}\n$$\nTo create the most economical coarse space that meets this bound, we select the largest possible threshold, $\\theta$, which is:\n$$\n\\theta = \\frac{C_{\\text{stab}}}{\\kappa_{\\text{target}}}\n$$\nThe problem specifies a target condition number $\\kappa_{\\text{target}} = 50$.\n\nOnce $\\theta$ is determined for a given $C_{\\text{stab}}$, the estimated dimension of the coarse space is found by summing the number of local eigenvalues $\\lambda^{(i)}_j$ for each subdomain $\\Omega_i$ which are less than or equal to this threshold:\n$$\n\\dim(\\mathcal{V}_{\\text{coarse}}) = \\sum_{i} \\#\\{\\lambda^{(i)}_j \\,|\\, \\lambda^{(i)}_j \\le \\theta\\}\n$$\nWe apply this procedure to each of the five test cases provided.\n\n**Case 1**:\n- Given: $C_{\\text{stab}} = 25$.\n- Compute threshold: $\\theta = \\frac{25}{50} = 0.5$.\n- Count eigenvalues $\\le 0.5$:\n    - Subdomain $1$: $\\{\\lambda^{(1)}_j\\} = [0.012, 0.08, 0.12, 0.42, 1.1, 3.0]$. Count is $4$.\n    - Subdomain $2$: $\\{\\lambda^{(2)}_j\\} = [0.038, 0.09, 0.15, 0.5, 0.8, 2.2]$. Count is $4$.\n    - Subdomain $3$: $\\{\\lambda^{(3)}_j\\} = [0.02, 0.07, 0.25, 0.6, 1.5, 2.5]$. Count is $3$.\n    - Subdomain $4$: $\\{\\lambda^{(4)}_j\\} = [0.01, 0.05, 0.2, 1.0, 2.0, 6.0]$. Count is $3$.\n- Total dimension: $\\dim(\\mathcal{V}_{\\text{coarse}}) = 4 + 4 + 3 + 3 = 14$.\n\n**Case 2**:\n- Given: $C_{\\text{stab}} = 25$.\n- Compute threshold: $\\theta = \\frac{25}{50} = 0.5$.\n- Count eigenvalues $\\le 0.5$:\n    - Subdomain $1$: $\\{\\lambda^{(1)}_j\\} = [0.6, 0.9, 1.2]$. Count is $0$.\n    - Subdomain $2$: $\\{\\lambda^{(2)}_j\\} = [0.7, 1.0, 1.5]$. Count is $0$.\n    - Subdomain $3$: $\\{\\lambda^{(3)}_j\\} = [0.55, 0.8, 3.0]$. Count is $0$.\n- Total dimension: $\\dim(\\mathcal{V}_{\\text{coarse}}) = 0 + 0 + 0 = 0$.\n\n**Case 3**:\n- Given: $C_{\\text{stab}} = 5$.\n- Compute threshold: $\\theta = \\frac{5}{50} = 0.1$.\n- Count eigenvalues $\\le 0.1$:\n    - Subdomain $1$: $\\{\\lambda^{(1)}_j\\} = [0.0005, 0.001, 0.005, 0.02, 0.3, 0.9]$. Count is $4$.\n    - Subdomain $2$: $\\{\\lambda^{(2)}_j\\} = [0.0003, 0.002, 0.007, 0.015, 0.08, 0.4]$. Count is $5$.\n    - Subdomain $3$: $\\{\\lambda^{(3)}_j\\} = [0.0008, 0.004, 0.012, 0.09, 0.2, 1.0]$. Count is $4$.\n    - Subdomain $4$: $\\{\\lambda^{(4)}_j\\} = [0.0001, 0.003, 0.01, 0.04, 0.06, 0.08]$. Count is $6$.\n- Total dimension: $\\dim(\\mathcal{V}_{\\text{coarse}}) = 4 + 5 + 4 + 6 = 19$.\n\n**Case 4**:\n- Given: $C_{\\text{stab}} = 100$.\n- Compute threshold: $\\theta = \\frac{100}{50} = 2.0$.\n- Count eigenvalues $\\le 2.0$:\n    - Subdomain $1$: $\\{\\lambda^{(1)}_j\\} = [0.02, 0.2, 0.9, 1.8, 2.5, 5.0]$. Count is $4$.\n    - Subdomain $2$: $\\{\\lambda^{(2)}_j\\} = [0.03, 0.6, 1.4, 2.1, 4.0]$. Count is $3$.\n    - Subdomain $3$: $\\{\\lambda^{(3)}_j\\} = [0.05, 0.4, 0.7, 1.3, 2.7]$. Count is $4$.\n    - Subdomain $4$: $\\{\\lambda^{(4)}_j\\} = [0.01, 0.08, 0.3, 0.8, 1.6, 3.6]$. Count is $5$.\n- Total dimension: $\\dim(\\mathcal{V}_{\\text{coarse}}) = 4 + 3 + 4 + 5 = 16$.\n\n**Case 5**:\n- Given: $C_{\\text{stab}} = 50$.\n- Compute threshold: $\\theta = \\frac{50}{50} = 1.0$.\n- Count eigenvalues $\\le 1.0$:\n    - Subdomain $1$: $\\{\\lambda^{(1)}_j\\} = [1.2, 1.5, 2.0]$. Count is $0$.\n    - Subdomain $2$: $\\{\\lambda^{(2)}_j\\} = [0.09, 0.2, 0.5, 0.9, 1.1]$. Count is $4$.\n    - Subdomain $3$: $\\{\\lambda^{(3)}_j\\} = [0.4, 0.7, 1.1, 1.8]$. Count is $2$.\n- Total dimension: $\\dim(\\mathcal{V}_{\\text{coarse}}) = 0 + 4 + 2 = 6$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Estimates the GenEO coarse space dimension based on local eigenvalue spectra\n    and a target condition number.\n    \"\"\"\n    # Define the target condition number as per the problem statement.\n    kappa_target = 50.0\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (C_stab, list_of_eigenvalue_arrays)\n    test_cases = [\n        # Case 1\n        (25.0, [\n            np.array([0.012, 0.08, 0.12, 0.42, 1.1, 3.0]),\n            np.array([0.038, 0.09, 0.15, 0.5, 0.8, 2.2]),\n            np.array([0.02, 0.07, 0.25, 0.6, 1.5, 2.5]),\n            np.array([0.01, 0.05, 0.2, 1.0, 2.0, 6.0])\n        ]),\n        # Case 2\n        (25.0, [\n            np.array([0.6, 0.9, 1.2]),\n            np.array([0.7, 1.0, 1.5]),\n            np.array([0.55, 0.8, 3.0])\n        ]),\n        # Case 3\n        (5.0, [\n            np.array([0.0005, 0.001, 0.005, 0.02, 0.3, 0.9]),\n            np.array([0.0003, 0.002, 0.007, 0.015, 0.08, 0.4]),\n            np.array([0.0008, 0.004, 0.012, 0.09, 0.2, 1.0]),\n            np.array([0.0001, 0.003, 0.01, 0.04, 0.06, 0.08])\n        ]),\n        # Case 4\n        (100.0, [\n            np.array([0.02, 0.2, 0.9, 1.8, 2.5, 5.0]),\n            np.array([0.03, 0.6, 1.4, 2.1, 4.0]),\n            np.array([0.05, 0.4, 0.7, 1.3, 2.7]),\n            np.array([0.01, 0.08, 0.3, 0.8, 1.6, 3.6])\n        ]),\n        # Case 5\n        (50.0, [\n            np.array([1.2, 1.5, 2.0]),\n            np.array([0.09, 0.2, 0.5, 0.9, 1.1]),\n            np.array([0.4, 0.7, 1.1, 1.8])\n        ])\n    ]\n\n    results = []\n    for c_stab, subdomain_eigs_list in test_cases:\n        # Calculate the eigenvalue threshold theta.\n        theta = c_stab / kappa_target\n        \n        # Initialize the coarse space dimension for the current case.\n        coarse_space_dim = 0\n        \n        # Iterate over each subdomain's eigenvalue array.\n        for eig_array in subdomain_eigs_list:\n            # Count the number of eigenvalues less than or equal to the threshold.\n            # Since the arrays are sorted, a more efficient search could be used,\n            # but for small arrays, direct comparison is clear and sufficient.\n            count = np.sum(eig_array <= theta)\n            coarse_space_dim += count\n            \n        results.append(int(coarse_space_dim))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The ultimate goal of a preconditioner is to reduce the total time-to-solution, which involves a careful trade-off between the preconditioner's computational cost and the convergence rate it provides. The global coarse correction, though vital for scalability, has its own assembly and solve costs. This analytical exercise  delves into these practical performance trade-offs. You will conduct a cost analysis to quantify the expense of assembling the coarse operator and explore the consequences of using a cheaper, inexact coarse solver on the overall iterative performance.",
            "id": "3586575",
            "problem": "Consider a symmetric positive definite (SPD) linear system $A u = f$ arising from a second-order elliptic partial differential equation model used in computational geophysics. A two-level additive Schwarz preconditioner is used, with $S$ nonoverlapping subdomains, each with $n_{s}$ interior unknowns. On each subdomain $i \\in \\{1,\\dots,S\\}$, the local stiffness matrix is $A_{i} \\in \\mathbb{R}^{n_{s} \\times n_{s}}$, and the coarse space is constructed with $r$ basis functions per subdomain. The global coarse restriction is $R_{0} \\in \\mathbb{R}^{n_{0} \\times n}$, where $n_{0} = r S$, and $R_{0i} \\in \\mathbb{R}^{r \\times n_{s}}$ denotes the block of $R_{0}$ corresponding to subdomain $i$.\n\nThe coarse operator is defined by $A_{0} = R_{0} A R_{0}^{T}$ and can be expressed as a sum of local contributions $B_{i} = R_{0i} A_{i} R_{0i}^{T}$, making it amenable to parallel assembly. Assume a floating-point operation (flop) cost model with the following well-tested facts:\n- The cost to apply a sparse matrix $A_{i}$ to a dense vector of length $n_{s}$ is $2 \\,\\mathrm{nnz}(A_{i})$ flops, where $\\mathrm{nnz}(A_{i})$ is the number of nonzero entries of $A_{i}$.\n- The cost to form an inner product of two dense vectors of length $n_{s}$ is $2 n_{s}$ flops.\n- The average number of nonzeros per row of $A_{i}$ is a constant $\\gamma > 0$, so $\\mathrm{nnz}(A_{i}) \\approx \\gamma n_{s}$.\n- A local subdomain solve (one application of the inverse of $A_{i}$ using a precomputed sparse Cholesky factorization) requires a forward and backward triangular solve whose combined cost is approximately $4\\,\\mathrm{nnz}(L_{i})$ flops, where $\\mathrm{nnz}(L_{i})$ is the number of nonzeros in the Cholesky factor. Assume a fill factor $\\theta > 1$ so that $\\mathrm{nnz}(L_{i}) \\approx \\theta\\,\\mathrm{nnz}(A_{i})$.\n\nAssume each $R_{0i}^{T}$ has $r$ dense columns supported on subdomain $i$, and that for each subdomain, $B_{i}$ is assembled by:\n1. Computing $y_{j} = A_{i} v_{j}$ for $j = 1,\\dots,r$, where $v_{j}$ is the $j$-th column of $R_{0i}^{T}$.\n2. Forming the $r \\times r$ block $B_{i}$ with entries $(B_{i})_{jk} = v_{j}^{T} y_{k}$.\n\nUnder these assumptions:\n1. Derive the parallel assembly expression for $A_{0}$ and compute the total coarse assembly cost per subdomain, $c_{\\mathrm{asm},i}$, in terms of $n_{s}$, $r$, and $\\gamma$.\n2. Compute the ratio $R$ of the total coarse assembly cost to the cost of one local subdomain solve (forward plus backward substitution) using the given model, and simplify $R$ in terms of $r$, $\\gamma$, and $\\theta$.\n\nNow consider the effect of using an inexact coarse solver. Let $\\tilde{A}_{0}^{-1}$ be an approximate inverse of $A_{0}^{-1}$ satisfying the spectral equivalence\n$$(1 - \\epsilon)\\, z^{T} A_{0}^{-1} z \\le z^{T} \\tilde{A}_{0}^{-1} z \\le (1 + \\epsilon)\\, z^{T} A_{0}^{-1} z \\quad \\text{for all } z \\in \\mathbb{R}^{n_{0}},$$\nwith $0 < \\epsilon < 1$. Let $M^{-1}$ denote the exact two-level additive Schwarz preconditioner and $M_{\\epsilon}^{-1}$ the same preconditioner with $A_{0}^{-1}$ replaced by $\\tilde{A}_{0}^{-1}$. Suppose the condition number of the preconditioned operator with exact coarse solve is $\\kappa = \\kappa(M^{-1} A)$. Using well-tested facts about Preconditioned Conjugate Gradient (PCG) for SPD problems, the asymptotic contraction factor per iteration in the $A$-norm is $q = \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}$.\n\n3. Show how the inexact coarse solve modifies the condition number bound to $\\kappa' \\le \\kappa \\,\\frac{1 + \\epsilon}{1 - \\epsilon}$, and write the corresponding contraction factor $q'$ in terms of $\\kappa$ and $\\epsilon$.\n\nDefine the figure-of-merit $\\phi$ to be the product of the cost ratio and the degraded contraction factor, i.e.,\n$$\\phi = R \\, q'.$$\nProvide $\\phi$ as a single closed-form analytic expression in terms of the parameters $r$, $\\gamma$, $\\theta$, $\\epsilon$, and $\\kappa$. Express the answer in dimensionless form. No rounding is required.",
            "solution": "We consider a symmetric positive definite (SPD) linear system $A u = f$ and a two-level additive Schwarz preconditioner. The global coarse operator is defined as $A_{0} = R_{0} A R_{0}^{T}$. In a domain decomposition framework with $S$ subdomains, we partition the vector of unknowns according to subdomains and represent the restriction $R_{0}$ blockwise as $R_{0} = \\begin{pmatrix} R_{0 1} & \\cdots & R_{0 S} \\end{pmatrix}$, with each $R_{0 i} \\in \\mathbb{R}^{r \\times n_{s}}$ mapping subdomain $i$ degrees of freedom to $r$ coarse basis coefficients. The local subdomain stiffness matrix is $A_{i} \\in \\mathbb{R}^{n_{s} \\times n_{s}}$. Under nonoverlapping decomposition, the fine-level matrix $A$ can be viewed as block-assembled from local contributions, and the coarse operator can be assembled as a sum of local contributions\n$$\nA_{0} = \\sum_{i=1}^{S} R_{0 i} A_{i} R_{0 i}^{T}.\n$$\nThis equality follows from linearity and the definition of $R_{0}$ as a block row concatenation, which implies that $R_{0} A R_{0}^{T}$ collects contributions of $A$ restricted to each subdomain and projected to the coarse space.\n\nTo assemble $A_{0}$ in parallel, each subdomain $i$ independently computes its local coarse block\n$$\nB_{i} = R_{0 i} A_{i} R_{0 i}^{T} \\in \\mathbb{R}^{r \\times r},\n$$\nand then these $r \\times r$ blocks are summed over $i$ to produce $A_{0}$. An algorithmic realization on each subdomain $i$ is:\n1. Let $V_{i} = R_{0 i}^{T} \\in \\mathbb{R}^{n_{s} \\times r}$ with columns $v_{1},\\dots,v_{r}$. Compute $y_{j} = A_{i} v_{j}$ for $j = 1,\\dots,r$.\n2. Form the entries of $B_{i}$ via $(B_{i})_{jk} = v_{j}^{T} y_{k}$, for $j,k = 1,\\dots,r$.\n\nWe now compute the flop count of this assembly per subdomain under the given model.\n\nFor step 1, each application of $A_{i}$ to a dense vector costs $2\\,\\mathrm{nnz}(A_{i})$ flops. Since this is done $r$ times, the total cost for step 1 on subdomain $i$ is\n$$\nc_{1,i} = 2 r\\, \\mathrm{nnz}(A_{i}).\n$$\nFor step 2, there are $r^{2}$ inner products of length $n_{s}$ (between $v_{j}$ and $y_{k}$). Each inner product costs $2 n_{s}$ flops, so the total cost is\n$$\nc_{2,i} = 2 n_{s} r^{2}.\n$$\nTherefore, the total coarse assembly cost per subdomain is\n$$\nc_{\\mathrm{asm},i} = c_{1,i} + c_{2,i} = 2 r\\, \\mathrm{nnz}(A_{i}) + 2 n_{s} r^{2}.\n$$\nUsing $\\mathrm{nnz}(A_{i}) \\approx \\gamma n_{s}$, we obtain\n$$\nc_{\\mathrm{asm},i} \\approx 2 r \\gamma n_{s} + 2 n_{s} r^{2} = 2 n_{s} \\left( r \\gamma + r^{2} \\right).\n$$\n\nWe compare this to the cost of one local subdomain solve using a precomputed factorization. Let the Cholesky factor $L_{i}$ have $\\mathrm{nnz}(L_{i}) \\approx \\theta\\, \\mathrm{nnz}(A_{i})$ nonzeros, where $\\theta > 1$ is a fill factor. One application of $A_{i}^{-1}$ via forward and backward substitution costs approximately\n$$\nc_{\\mathrm{solve},i} \\approx 4\\,\\mathrm{nnz}(L_{i}) \\approx 4 \\theta\\, \\mathrm{nnz}(A_{i}) \\approx 4 \\theta \\gamma n_{s}.\n$$\nThe ratio of coarse assembly cost to one local subdomain solve cost, per subdomain, is thus\n$$\nR_{i} = \\frac{c_{\\mathrm{asm},i}}{c_{\\mathrm{solve},i}} \\approx \\frac{2 n_{s} \\left( r \\gamma + r^{2} \\right)}{4 \\theta \\gamma n_{s}} = \\frac{r \\gamma + r^{2}}{2 \\theta \\gamma} = \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma}.\n$$\nAssuming identical subdomains, the global ratio $R$ equals $R_{i}$:\n$$\nR = \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma}.\n$$\n\nWe now quantify the effect of an inexact coarse solver. Define the exact two-level preconditioner by\n$$\nM^{-1} = \\sum_{i=1}^{S} R_{i}^{T} A_{i}^{-1} R_{i} + R_{0}^{T} A_{0}^{-1} R_{0},\n$$\nwhere $R_{i}$ are local restriction operators onto subdomain degrees of freedom. The inexact coarse solver replaces $A_{0}^{-1}$ by $\\tilde{A}_{0}^{-1}$ satisfying\n$$\n(1 - \\epsilon)\\, z^{T} A_{0}^{-1} z \\le z^{T} \\tilde{A}_{0}^{-1} z \\le (1 + \\epsilon)\\, z^{T} A_{0}^{-1} z,\\quad \\forall z \\in \\mathbb{R}^{n_{0}},\n$$\nwith $0 < \\epsilon < 1$. This implies spectral equivalence of the exact and inexact coarse inverses with constants $(1 - \\epsilon)$ and $(1 + \\epsilon)$. Consequently, the preconditioner with inexact coarse solve,\n$$\nM_{\\epsilon}^{-1} = \\sum_{i=1}^{S} R_{i}^{T} A_{i}^{-1} R_{i} + R_{0}^{T} \\tilde{A}_{0}^{-1} R_{0},\n$$\nis spectrally equivalent to $M^{-1}$:\n$$\n(1 - \\epsilon)\\, y^{T} M^{-1} y \\le y^{T} M_{\\epsilon}^{-1} y \\le (1 + \\epsilon)\\, y^{T} M^{-1} y,\\quad \\forall y \\in \\mathbb{R}^{n}.\n$$\nTo see this, decompose any $y$ into local and coarse components via the stable decomposition underpinning two-level methods; the only modified term is the coarse component, which is scaled by $(1 \\pm \\epsilon)$ as per the assumed equivalence for $\\tilde{A}_{0}^{-1}$. Therefore, for the preconditioned operator, the Rayleigh quotient bounds imply\n$$\n\\kappa(M_{\\epsilon}^{-1} A) \\le \\frac{1 + \\epsilon}{1 - \\epsilon}\\, \\kappa(M^{-1} A) = \\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}.\n$$\nLet $\\kappa' = \\kappa(M_{\\epsilon}^{-1} A)$ denote the inexact-coarse condition number bound. Then\n$$\n\\kappa' \\le \\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}.\n$$\nFor Preconditioned Conjugate Gradient (PCG) applied to an SPD system, the asymptotic contraction factor per iteration in the $A$-norm is given by\n$$\nq = \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}.\n$$\nReplacing $\\kappa$ by $\\kappa'$ yields\n$$\nq' = \\frac{\\sqrt{\\kappa'} - 1}{\\sqrt{\\kappa'} + 1} \\le \\frac{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} - 1}{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} + 1}.\n$$\n\nFinally, define the figure-of-merit $\\phi$ as the product of the cost ratio and the degraded contraction factor:\n$$\n\\phi = R \\, q' = \\left( \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma} \\right) \\, \\frac{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} - 1}{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} + 1}.\n$$\nThis expression is dimensionless and reflects how the parallel coarse assembly cost compares to a local subdomain solve and how an inexact coarse solver impacts the asymptotic convergence per iteration.",
            "answer": "$$\\boxed{\\left( \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma} \\right) \\,\\frac{\\sqrt{\\kappa \\,\\frac{1 + \\epsilon}{1 - \\epsilon}} - 1}{\\sqrt{\\kappa \\,\\frac{1 + \\epsilon}{1 - \\epsilon}} + 1}}$$"
        }
    ]
}