{
    "hands_on_practices": [
        {
            "introduction": "The Butcher tableau provides a compact and universal notation for defining any Runge-Kutta method. Before analyzing complex properties like stability or order, it is essential to be able to translate this tableau into a concrete computational algorithm. This foundational exercise () will guide you through the manual calculation of a single time step using the explicit midpoint method, reinforcing your understanding of how stage values are computed and combined to produce the final solution update.",
            "id": "3613997",
            "problem": "In computational geophysics, semi-discrete formulations of time-dependent partial differential equations often yield ordinary differential equations (ODEs). Consider such a local model at a grid point governed by the scalar ODE $y'(t)=t+y(t)$, where $y(t)$ denotes a state variable (for example, a locally linearized prognostic quantity). Let $y_n$ denote the numerical approximation to $y(t_n)$ at time $t_n$, and let $\\Delta t$ be a positive time step such that $t_{n+1}=t_n+\\Delta t$.\n\nYou are to advance $y_n$ to $y_{n+1}$ using a $2$-stage Runge–Kutta method defined by the midpoint method with the Butcher tableau specified by the nodes $c=\\left(0,\\frac{1}{2}\\right)$, the strictly lower-triangular matrix\n$$\nA=\\begin{pmatrix}\n0  0 \\\\\n\\frac{1}{2}  0\n\\end{pmatrix},\n$$\nand the weights $b=\\left(0,1\\right)$.\n\nStarting only from the interpretation that a Butcher tableau defines stage abscissae, internal stage couplings, and final weights in a Runge–Kutta integrator applied to $y'(t)=f(t,y)$ with $f(t,y)=t+y$, derive the one-step update map from $t_n$ to $t_{n+1}=t_n+\\Delta t$ and compute $y_{n+1}$ explicitly in terms of $y_n$, $t_n$, and $\\Delta t$.\n\nProvide your final result as a single closed-form analytical expression for $y_{n+1}$ in terms of $y_n$, $t_n$, and $\\Delta t$. No rounding is required, and no units are to be included in the final expression.",
            "solution": "The user has requested the derivation of the one-step update map for a given ordinary differential equation (ODE) using a specified $2$-stage Runge-Kutta method.\n\nThe problem is first validated.\n**Givens:**\n- ODE: $y'(t) = t + y(t)$, which defines the function $f(t, y) = t + y$.\n- Time discretization: $t_{n+1} = t_n + \\Delta t$ for a time step $\\Delta t  0$.\n- Numerical approximation to $y(t_n)$ is $y_n$.\n- A $2$-stage Runge-Kutta method is defined by the Butcher tableau:\n  - Abscissae: $c = \\begin{pmatrix} c_1 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\frac{1}{2} \\end{pmatrix}$\n  - Matrix: $A = \\begin{pmatrix} a_{11}  a_{12} \\\\ a_{21}  a_{22} \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ \\frac{1}{2}  0 \\end{pmatrix}$\n  - Weights: $b = \\begin{pmatrix} b_1  b_2 \\end{pmatrix} = \\begin{pmatrix} 0  1 \\end{pmatrix}$\n\n**Validation:**\n- **Scientific Grounding**: The problem is a standard application of a well-established numerical method (Runge-Kutta) to a simple linear first-order ODE. All components are mathematically and computationally sound.\n- **Well-Posedness**: The problem provides all necessary information (the ODE, the numerical method's coefficients, and the initial state) to derive a unique analytical expression for the next time step.\n- **Objectivity**: The problem is stated in precise, formal language without ambiguity or subjectivity.\n\nThe problem is valid as it is scientifically grounded, well-posed, and objective. There are no contradictions, missing information, or pseudoscientific claims. We may proceed with the solution.\n\nThe general formula for an $s$-stage Runge-Kutta method for the ODE $y'(t) = f(t, y(t))$ is given by:\n$$\ny_{n+1} = y_n + \\Delta t \\sum_{i=1}^{s} b_i k_i\n$$\nwhere the stage derivatives $k_i$ are computed as:\n$$\nk_i = f\\left(t_n + c_i \\Delta t, y_n + \\Delta t \\sum_{j=1}^{s} a_{ij} k_j\\right)\n$$\nFor this problem, the number of stages is $s=2$. We can write out the equations for the stages $k_1$ and $k_2$.\n\n**Stage 1:**\nFor $i=1$, we use $c_1=0$, $a_{11}=0$, and $a_{12}=0$.\n$$\nk_1 = f\\left(t_n + c_1 \\Delta t, y_n + \\Delta t (a_{11} k_1 + a_{12} k_2)\\right)\n$$\n$$\nk_1 = f\\left(t_n + 0 \\cdot \\Delta t, y_n + \\Delta t (0 \\cdot k_1 + 0 \\cdot k_2)\\right)\n$$\n$$\nk_1 = f(t_n, y_n)\n$$\nSubstituting the given function $f(t, y) = t + y$, we get:\n$$\nk_1 = t_n + y_n\n$$\n\n**Stage 2:**\nFor $i=2$, we use $c_2=\\frac{1}{2}$, $a_{21}=\\frac{1}{2}$, and $a_{22}=0$. The matrix $A$ is strictly lower-triangular, so the method is explicit, and the calculation of $k_2$ depends only on $k_1$.\n$$\nk_2 = f\\left(t_n + c_2 \\Delta t, y_n + \\Delta t (a_{21} k_1 + a_{22} k_2)\\right)\n$$\n$$\nk_2 = f\\left(t_n + \\frac{1}{2} \\Delta t, y_n + \\Delta t \\left(\\frac{1}{2} k_1 + 0 \\cdot k_2\\right)\\right)\n$$\n$$\nk_2 = f\\left(t_n + \\frac{1}{2} \\Delta t, y_n + \\frac{1}{2} \\Delta t \\cdot k_1\\right)\n$$\nNow, we substitute the expression for $k_1 = t_n + y_n$ into the formula for $k_2$:\n$$\nk_2 = f\\left(t_n + \\frac{\\Delta t}{2}, y_n + \\frac{\\Delta t}{2}(t_n + y_n)\\right)\n$$\nUsing $f(t,y) = t+y$, we evaluate the function with its arguments:\n$$\nk_2 = \\left(t_n + \\frac{\\Delta t}{2}\\right) + \\left(y_n + \\frac{\\Delta t}{2}(t_n + y_n)\\right)\n$$\nExpanding and collecting terms:\n$$\nk_2 = t_n + y_n + \\frac{\\Delta t}{2} + \\frac{\\Delta t}{2}t_n + \\frac{\\Delta t}{2}y_n\n$$\n$$\nk_2 = (t_n + y_n)\\left(1 + \\frac{\\Delta t}{2}\\right) + \\frac{\\Delta t}{2}\n$$\n\n**Final Update:**\nThe update formula for $y_{n+1}$ is constructed using the weights $b_1=0$ and $b_2=1$:\n$$\ny_{n+1} = y_n + \\Delta t (b_1 k_1 + b_2 k_2)\n$$\n$$\ny_{n+1} = y_n + \\Delta t (0 \\cdot k_1 + 1 \\cdot k_2)\n$$\n$$\ny_{n+1} = y_n + \\Delta t \\cdot k_2\n$$\nSubstitute the derived expression for $k_2$:\n$$\ny_{n+1} = y_n + \\Delta t \\left[ \\left(t_n + \\frac{\\Delta t}{2}\\right) + \\left(y_n + \\frac{\\Delta t}{2}(t_n + y_n)\\right) \\right]\n$$\nNow, we expand and simplify the expression to obtain $y_{n+1}$ in terms of $y_n$, $t_n$, and $\\Delta t$.\n$$\ny_{n+1} = y_n + t_n \\Delta t + y_n \\Delta t + \\frac{(\\Delta t)^2}{2} + \\frac{t_n (\\Delta t)^2}{2} + \\frac{y_n (\\Delta t)^2}{2}\n$$\nFinally, we group terms by $y_n$, $t_n$, and remaining constants to provide a single closed-form expression.\n$$\ny_{n+1} = y_n \\left(1 + \\Delta t + \\frac{(\\Delta t)^2}{2}\\right) + t_n \\left(\\Delta t + \\frac{(\\Delta t)^2}{2}\\right) + \\frac{(\\Delta t)^2}{2}\n$$\nThis expression can be rearranged to highlight its relationship with the Taylor series expansion of the solution.\n$$\ny_{n+1} = y_n + (t_n + y_n)\\Delta t + \\frac{1}{2}(t_n + y_n + 1)(\\Delta t)^2\n$$\nBoth forms are equivalent. The latter is more compact and explicitly shows the terms up to order $(\\Delta t)^2$. This is the requested closed-form analytical expression for $y_{n+1}$.",
            "answer": "$$\n\\boxed{y_n + (t_n + y_n)\\Delta t + \\frac{1}{2}(t_n + y_n + 1)(\\Delta t)^2}\n$$"
        },
        {
            "introduction": "Many critical problems in geophysics, such as those involving diffusion or viscoelasticity, lead to stiff systems of ordinary differential equations that pose a significant challenge for numerical integrators. This practice () moves beyond basic mechanics to explore the crucial concept of numerical stability in the context of stiffness. By analytically comparing the performance of the explicit RK4 method against the implicit midpoint method on the Dahlquist test equation, you will gain insight into why the choice of integrator is paramount for achieving both stability and efficiency.",
            "id": "3613965",
            "problem": "In computational geophysics, stiff ordinary differential equations (ODEs) arise when semi-discretizing diffusive or viscoelastic partial differential equations (PDEs). Consider the scalar Dahlquist test equation for stiffness, given by $y' = -\\beta y$ with $\\beta \\gg 1$. Suppose one integrates this ODE using two time integrators: the classical explicit fourth-order Runge–Kutta (RK4) method, and the implicit midpoint method (the one-stage Gauss–Legendre Runge–Kutta method). Let the time step be fixed at $\\Delta t = \\beta^{-1}$.\n\nStarting from the definitions of Runge–Kutta methods and their application to the linear test equation $y'=\\lambda y$, derive for each method the one-step amplification factor $R(z)$, where $z = \\lambda \\Delta t$. Evaluate the magnitude of $R(z)$ at $z=-1$, and then determine, for each method, the exact analytic expression (ignoring the integer ceiling) for the number of steps $n$ required to reduce the solution magnitude by a factor $10^{-k}$, that is, to achieve $\\lvert y_n \\rvert \\le 10^{-k} \\lvert y_0 \\rvert$. Express your final answers as functions of $k$ using natural logarithms only, and do not perform any numerical rounding. Provide the pair $\\big(n_{\\mathrm{RK4}}(k),\\, n_{\\mathrm{IM}}(k)\\big)$ as your final answer, where the subscripts denote explicit RK4 and implicit midpoint, respectively.",
            "solution": "The user has provided a problem statement that requires validation before proceeding to a solution.\n\n### Step 1: Extract Givens\n- The ordinary differential equation (ODE) is the Dahlquist test equation for stiffness: $y' = -\\beta y$, with the condition $\\beta \\gg 1$.\n- This is a specific case of the linear test equation $y' = \\lambda y$, where the coefficient $\\lambda = -\\beta$.\n- The time step for integration is fixed at $\\Delta t = \\beta^{-1}$.\n- Two time integration methods are to be analyzed:\n    1. The classical explicit fourth-order Runge–Kutta (RK4) method.\n    2. The implicit midpoint method (one-stage Gauss–Legendre Runge–Kutta method).\n- The task is to derive the one-step amplification factor $R(z)$ for each method, where $z = \\lambda \\Delta t$.\n- Then, evaluate the magnitude of $R(z)$ for the specific value of $z$ given by the problem parameters.\n- Finally, determine the number of steps $n$ required to satisfy the condition $\\lvert y_n \\rvert \\le 10^{-k} \\lvert y_0 \\rvert$. This number $n$ should be an exact analytic expression as a function of $k$, ignoring any integer ceiling function.\n- The final answer should be a pair $\\big(n_{\\mathrm{RK4}}(k),\\, n_{\\mathrm{IM}}(k)\\big)$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in the numerical analysis of ordinary differential equations. The Dahlquist test equation, Runge-Kutta methods, stability functions (amplification factors), and their application to stiff problems are fundamental concepts in this field. The context of computational geophysics is appropriate, as stiff systems are common in that domain. The problem is scientifically sound.\n- **Well-Posed:** The problem provides all necessary information. The ODE, the time step, and the methods are clearly defined. The goal is specific and quantifiable. The value of $z$ is unambiguously determined by the givens: $z = \\lambda \\Delta t = (-\\beta)(\\beta^{-1}) = -1$. A unique, meaningful solution can be derived.\n- **Objective:** The problem is phrased in precise, objective, and technical language, free from any subjectivity or bias.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is scientifically grounded, well-posed, objective, and self-contained. The solution process can proceed.\n\n### Solution Derivation\n\nThe numerical solution of the test equation $y' = \\lambda y$ after one time step $\\Delta t$ using a Runge-Kutta method can be expressed as $y_{n+1} = R(z) y_n$, where $z = \\lambda \\Delta t$ and $R(z)$ is the stability function or amplification factor of the method. After $n$ steps, the solution is given by $y_n = (R(z))^n y_0$.\n\nThe problem requires finding the number of steps $n$ to reduce the solution's magnitude by a factor of $10^{-k}$. This condition is mathematically stated as:\n$$ \\lvert y_n \\rvert \\le 10^{-k} \\lvert y_0 \\rvert $$\nSubstituting the expression for $y_n$:\n$$ \\lvert (R(z))^n y_0 \\rvert \\le 10^{-k} \\lvert y_0 \\rvert $$\n$$ \\lvert R(z) \\rvert^n \\lvert y_0 \\rvert \\le 10^{-k} \\lvert y_0 \\rvert $$\nAssuming $y_0 \\ne 0$, we can divide by $\\lvert y_0 \\rvert$:\n$$ \\lvert R(z) \\rvert^n \\le 10^{-k} $$\nTo solve for $n$, we take the natural logarithm of both sides:\n$$ n \\ln(\\lvert R(z) \\rvert) \\le \\ln(10^{-k}) $$\n$$ n \\ln(\\lvert R(z) \\rvert) \\le -k \\ln(10) $$\nFor a decaying (stable) solution, we must have $\\lvert R(z) \\rvert  1$, which implies that $\\ln(\\lvert R(z) \\rvert)$ is negative. Dividing by this negative quantity reverses the inequality sign:\n$$ n \\ge \\frac{-k \\ln(10)}{\\ln(\\lvert R(z) \\rvert)} = \\frac{k \\ln(10)}{-\\ln(\\lvert R(z) \\rvert)} = \\frac{k \\ln(10)}{\\ln(\\lvert R(z) \\rvert^{-1})} = \\frac{k \\ln(10)}{\\ln(1/\\lvert R(z) \\rvert)} $$\nThe problem asks for the number of steps required, ignoring the integer ceiling, so we take the equality:\n$$ n = \\frac{k \\ln(10)}{\\ln(1/\\lvert R(z) \\rvert)} $$\nFrom the problem statement, $\\lambda = -\\beta$ and $\\Delta t = \\beta^{-1}$, so $z = \\lambda \\Delta t = (-\\beta)(\\beta^{-1}) = -1$. We will use $z=-1$ for both methods.\n\n**1. Classical Explicit Fourth-Order Runge-Kutta (RK4) Method**\n\nThe stability function for the classical RK4 method is the fourth-degree Taylor polynomial of the exponential function:\n$$ R_{\\mathrm{RK4}}(z) = 1 + z + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\frac{z^4}{4!} $$\nWe evaluate this function at $z = -1$:\n$$ R_{\\mathrm{RK4}}(-1) = 1 + (-1) + \\frac{(-1)^2}{2} + \\frac{(-1)^3}{6} + \\frac{(-1)^4}{24} $$\n$$ R_{\\mathrm{RK4}}(-1) = 1 - 1 + \\frac{1}{2} - \\frac{1}{6} + \\frac{1}{24} $$\n$$ R_{\\mathrm{RK4}}(-1) = \\frac{12}{24} - \\frac{4}{24} + \\frac{1}{24} = \\frac{12 - 4 + 1}{24} = \\frac{9}{24} = \\frac{3}{8} $$\nThe magnitude is $\\lvert R_{\\mathrm{RK4}}(-1) \\rvert = \\frac{3}{8}$.\nNow, we find the number of steps $n_{\\mathrm{RK4}}$:\n$$ n_{\\mathrm{RK4}}(k) = \\frac{k \\ln(10)}{\\ln(1/\\lvert R_{\\mathrm{RK4}}(-1) \\rvert)} = \\frac{k \\ln(10)}{\\ln(1/(3/8))} = \\frac{k \\ln(10)}{\\ln(8/3)} $$\n\n**2. Implicit Midpoint Method**\n\nThe implicit midpoint method is a one-stage Runge-Kutta method with Butcher tableau $c_1 = 1/2$, $a_{11} = 1/2$, and $b_1 = 1$. The stability function $R(z)$ for a one-stage implicit Runge-Kutta method is derived as follows:\nThe stage value $k_1$ for the equation $y'=\\lambda y$ is $k_1 = \\lambda(y_n + \\Delta t a_{11} k_1)$.\n$k_1 = \\lambda y_n + a_{11} (\\lambda \\Delta t) k_1 = \\lambda y_n + a_{11} z k_1$.\nSolving for $k_1$: $k_1(1 - a_{11} z) = \\lambda y_n \\implies k_1 = \\frac{\\lambda y_n}{1 - a_{11} z}$.\nThe solution update is $y_{n+1} = y_n + \\Delta t b_1 k_1 = y_n + b_1 (\\lambda \\Delta t) \\frac{y_n}{1 - a_{11} z}$.\nThus, the amplification factor is $R(z) = \\frac{y_{n+1}}{y_n} = 1 + \\frac{b_1 z}{1 - a_{11} z}$.\nFor the implicit midpoint method, with $a_{11} = 1/2$ and $b_1=1$:\n$$ R_{\\mathrm{IM}}(z) = 1 + \\frac{z}{1 - z/2} = \\frac{(1 - z/2) + z}{1 - z/2} = \\frac{1 + z/2}{1 - z/2} $$\nThis is the $[1,1]$-Padé approximant to $\\exp(z)$. We evaluate this function at $z=-1$:\n$$ R_{\\mathrm{IM}}(-1) = \\frac{1 + (-1)/2}{1 - (-1)/2} = \\frac{1 - 1/2}{1 + 1/2} = \\frac{1/2}{3/2} = \\frac{1}{3} $$\nThe magnitude is $\\lvert R_{\\mathrm{IM}}(-1) \\rvert = \\frac{1}{3}$.\nNow, we find the number of steps $n_{\\mathrm{IM}}$:\n$$ n_{\\mathrm{IM}}(k) = \\frac{k \\ln(10)}{\\ln(1/\\lvert R_{\\mathrm{IM}}(-1) \\rvert)} = \\frac{k \\ln(10)}{\\ln(1/(1/3))} = \\frac{k \\ln(10)}{\\ln(3)} $$\n\nCombining the two results into the requested pair format $\\big(n_{\\mathrm{RK4}}(k),\\, n_{\\mathrm{IM}}(k)\\big)$, we have the final expressions.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\frac{k \\ln(10)}{\\ln(8/3)}  \\frac{k \\ln(10)}{\\ln(3)} \\end{pmatrix}} $$"
        },
        {
            "introduction": "In practice, the efficiency and reliability of a time integrator depend on its ability to adapt the step size to the local behavior of the solution. This advanced exercise () bridges the gap between theory and application by tasking you with implementing a single adaptive step of the Dormand-Prince 5(4) method, a workhorse algorithm in modern scientific computing. By using an embedded pair to estimate local error and a controller to adjust the step size, you will build a core component of a production-level ODE solver and master a fundamental technique for robust numerical simulation.",
            "id": "3613947",
            "problem": "You are to implement a single adaptive step of the Dormand–Prince Runge–Kutta $5(4)$ method (abbreviated hereafter as Dormand–Prince (DP) and Runge–Kutta (RK)) for the initial value problem given by the ordinary differential equation (ODE) $y^{\\prime}(t) = f(t,y)$ with $f(t,y) = -y$, starting from $(t_n, y_n)$. The method must use the embedded pair to estimate the local truncation error and decide step acceptance or rejection, and must recommend a new step size according to a standard controller. This task must be solved from first principles: start from the ODE definition $y^{\\prime} = f(t,y)$, the notion of one-step Runge–Kutta methods defined by internal stage evaluations $k_i$, and the definition of an embedded pair that provides two approximations of different orders at the end of the step to estimate the local error.\n\nUse the following Dormand–Prince $5(4)$ Butcher tableau data (these are the well-tested coefficients that define the particular RK method):\n- Nodes $c_i$:\n$$\nc_1 = 0, \\quad c_2 = \\tfrac{1}{5}, \\quad c_3 = \\tfrac{3}{10}, \\quad c_4 = \\tfrac{4}{5}, \\quad c_5 = \\tfrac{8}{9}, \\quad c_6 = 1, \\quad c_7 = 1.\n$$\n- Matrix $a_{ij}$ for stages:\n$$\na_{21} = \\tfrac{1}{5};\n$$\n$$\na_{31} = \\tfrac{3}{40}, \\quad a_{32} = \\tfrac{9}{40};\n$$\n$$\na_{41} = \\tfrac{44}{45}, \\quad a_{42} = -\\tfrac{56}{15}, \\quad a_{43} = \\tfrac{32}{9};\n$$\n$$\na_{51} = \\tfrac{19372}{6561}, \\quad a_{52} = -\\tfrac{25360}{2187}, \\quad a_{53} = \\tfrac{64448}{6561}, \\quad a_{54} = -\\tfrac{212}{729};\n$$\n$$\na_{61} = \\tfrac{9017}{3168}, \\quad a_{62} = -\\tfrac{355}{33}, \\quad a_{63} = \\tfrac{46732}{5247}, \\quad a_{64} = \\tfrac{49}{176}, \\quad a_{65} = -\\tfrac{5103}{18656};\n$$\n$$\na_{71} = \\tfrac{35}{384}, \\quad a_{72} = 0, \\quad a_{73} = \\tfrac{500}{1113}, \\quad a_{74} = \\tfrac{125}{192}, \\quad a_{75} = -\\tfrac{2187}{6784}, \\quad a_{76} = \\tfrac{11}{84}.\n$$\n- Weights $b_i$ for the fifth-order solution $y_{n+1}^{(5)}$:\n$$\nb_1 = \\tfrac{35}{384}, \\quad b_2 = 0, \\quad b_3 = \\tfrac{500}{1113}, \\quad b_4 = \\tfrac{125}{192}, \\quad b_5 = -\\tfrac{2187}{6784}, \\quad b_6 = \\tfrac{11}{84}, \\quad b_7 = 0.\n$$\n- Weights $\\hat{b}_i$ for the embedded fourth-order solution $y_{n+1}^{(4)}$:\n$$\n\\hat{b}_1 = \\tfrac{5179}{57600}, \\quad \\hat{b}_2 = 0, \\quad \\hat{b}_3 = \\tfrac{7571}{16695}, \\quad \\hat{b}_4 = \\tfrac{393}{640}, \\quad \\hat{b}_5 = -\\tfrac{92097}{339200}, \\quad \\hat{b}_6 = \\tfrac{187}{2100}, \\quad \\hat{b}_7 = \\tfrac{1}{40}.\n$$\n\nFor a given trial step size $h$, compute the $7$ stage values $k_i$ according to the RK construction\n$$\nk_i = f\\!\\left(t_n + c_i h,\\, y_n + h \\sum_{j=1}^{i-1} a_{ij} k_j\\right),\n$$\nthen compute both embedded solutions\n$$\ny_{n+1}^{(5)} = y_n + h \\sum_{i=1}^{7} b_i k_i, \\qquad y_{n+1}^{(4)} = y_n + h \\sum_{i=1}^{7} \\hat{b}_i k_i.\n$$\n\nDefine the local error estimate as the difference $e = y_{n+1}^{(5)} - y_{n+1}^{(4)}$. Use a scaled error norm suitable for adaptive time stepping:\n$$\n\\mathrm{err} = \\frac{|e|}{\\mathrm{atol} + \\mathrm{rtol}\\cdot \\max\\!\\left(|y_n|,\\, |y_{n+1}^{(5)}|\\right)}.\n$$\nHere $\\mathrm{rtol}$ and $\\mathrm{atol}$ are the relative and absolute tolerances, respectively. For this problem, you must set $\\mathrm{rtol} = \\mathrm{atol} = \\mathrm{tol}$, where $\\mathrm{tol}$ is the given tolerance parameter in each test case.\n\nAcceptance criterion: accept the step if and only if $\\mathrm{err} \\le 1$. If accepted, advance to $t_{n+1} = t_n + h$ with solution $y_{n+1} = y_{n+1}^{(5)}$. If rejected, do not advance, i.e., keep $t_{n+1} = t_n$ and $y_{n+1} = y_n$.\n\nRecommend a new step size $h_{\\mathrm{new}}$ using a standard controller without proportional-integral filtering:\n$$\nh_{\\mathrm{new}} = h \\cdot \\mathrm{clip}\\!\\left( s \\cdot \\mathrm{err}^{-1/5},\\, f_{\\min},\\, f_{\\max}\\right),\n$$\nwhere $s$ is a safety factor, and the clipping confines the multiplicative step factor to the interval $[f_{\\min}, f_{\\max}]$. Use $s = 0.9$, $f_{\\min} = 0.2$, and $f_{\\max} = 5$. In the degenerate case $\\mathrm{err} = 0$, define the multiplicative factor to be $f_{\\max}$. The exponent $1/5$ corresponds to controlling the local error for a fifth-order method.\n\nImplement this single-step adaptive RK procedure and apply it to the ODE $y^{\\prime} = -y$ for each of the following test cases. In all cases, use $f(t,y) = -y$ exactly, without approximations. The test suite consists of the tuples $(t_n, y_n, h, \\mathrm{tol})$:\n- Case $1$: $(0,\\, 1,\\, 0.1,\\, 10^{-6})$.\n- Case $2$: $(0,\\, 1,\\, 2.0,\\, 10^{-6})$.\n- Case $3$: $(5,\\, e^{-5},\\, 0.5,\\, 10^{-12})$.\n- Case $4$: $(0,\\, 1,\\, 10^{-8},\\, 10^{-6})$.\n\nFor each case, output a list of four items: the boolean step acceptance flag, the advanced time $t_{n+1}$, the advanced solution $y_{n+1}$, and the recommended next step size $h_{\\mathrm{new}}$. Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets. For example, a valid format is\n$[ [\\mathrm{True},\\, t_1,\\, y_1,\\, h_1],\\, [\\mathrm{False},\\, t_2,\\, y_2,\\, h_2],\\, \\ldots ]$\nwith each $t_i$, $y_i$, and $h_i$ as floating-point numbers.",
            "solution": "The problem is valid. It presents a well-defined task in numerical analysis: to implement a single adaptive step of the Dormand–Prince 5(4) Runge–Kutta method for a specified ordinary differential equation (ODE) and a set of initial conditions. All necessary parameters, formulas, and conditions are provided, and they are consistent with established scientific literature on numerical methods for ODEs.\n\nThe task is to compute one adaptive step for the initial value problem defined by the ODE $y'(t) = f(t,y)$ starting from an initial point $(t_n, y_n)$ with a trial step size $h$. The specific ODE to be solved is $y'(t) = -y$, hence $f(t,y) = -y$.\n\nAn explicit Runge–Kutta method is a one-step numerical procedure for approximating the solution of an ODE. It is defined by a set of coefficients organized in a Butcher tableau, which consists of a vector of nodes $c = (c_i)$, a matrix of coefficients $A = (a_{ij})$, and a vector of weights $b = (b_i)$. For an $s$-stage method, the approximation $y_{n+1}$ to the true solution $y(t_n+h)$ is calculated as follows:\nFirst, $s$ intermediate stages $k_i$ are computed sequentially for $i = 1, \\dots, s$:\n$$k_i = f\\left(t_n + c_i h, y_n + h \\sum_{j=1}^{i-1} a_{ij} k_j\\right)$$\nThen, the solution at the next time step is formed as a weighted average of these stages:\n$$y_{n+1} = y_n + h \\sum_{i=1}^{s} b_i k_i$$\n\nThe problem specifies an embedded Runge–Kutta pair, the Dormand–Prince $5(4)$ method, which is a $7$-stage method ($s=7$). This method computes two solutions of different orders, a fifth-order accurate solution $y_{n+1}^{(5)}$ and a fourth-order accurate solution $y_{n+1}^{(4)}$, using the same set of stage values $k_i$.\nThe fifth-order solution uses weights $b_i$:\n$$y_{n+1}^{(5)} = y_n + h \\sum_{i=1}^{7} b_i k_i$$\nThe embedded fourth-order solution uses weights $\\hat{b}_i$:\n$$y_{n+1}^{(4)} = y_n + h \\sum_{i=1}^{7} \\hat{b}_i k_i$$\n\nThe Dormand–Prince $5(4)$ method is defined by the following Butcher tableau coefficients:\nNodes $c_i$:\n$$c = \\left[0, \\tfrac{1}{5}, \\tfrac{3}{10}, \\tfrac{4}{5}, \\tfrac{8}{9}, 1, 1\\right]^T$$\nMatrix $A = (a_{ij})$:\n$$\n\\begin{array}{c|ccccccc}\n0        \\\\\n1/5  1/5       \\\\\n3/10  3/40  9/40      \\\\\n4/5  44/45  -56/15  32/9     \\\\\n8/9  19372/6561  -25360/2187  64448/6561  -212/729    \\\\\n1  9017/3168  -355/33  46732/5247  49/176  -5103/18656   \\\\\n1  35/384  0  500/1113  125/192  -2187/6784  11/84  0\n\\end{array}\n$$\nWeights $b_i$ for $y_{n+1}^{(5)}$:\n$$b = \\left[\\tfrac{35}{384}, 0, \\tfrac{500}{1113}, \\tfrac{125}{192}, -\\tfrac{2187}{6784}, \\tfrac{11}{84}, 0\\right]$$\nWeights $\\hat{b}_i$ for $y_{n+1}^{(4)}$:\n$$\\hat{b} = \\left[\\tfrac{5179}{57600}, 0, \\tfrac{7571}{16695}, \\tfrac{393}{640}, -\\tfrac{92097}{339200}, \\tfrac{187}{2100}, \\tfrac{1}{40}\\right]$$\n\nThe algorithmic procedure for a single adaptive step is as follows:\n\n**1. Stage Calculation**\nGiven $(t_n, y_n)$ and a step size $h$, we compute the $7$ stages $k_1, \\dots, k_7$. For the specific ODE $f(t,y) = -y$, the stages are independent of $t$ and are computed as:\n$k_1 = f(t_n, y_n) = -y_n$\n$k_2 = f(t_n + c_2 h, y_n + h a_{21} k_1) = -(y_n + h a_{21} k_1)$\n$k_3 = f(t_n + c_3 h, y_n + h (a_{31} k_1 + a_{32} k_2)) = -(y_n + h (a_{31} k_1 + a_{32} k_2))$\n...and so on, up to $k_7$:\n$$k_i = -\\left(y_n + h \\sum_{j=1}^{i-1} a_{ij} k_j\\right) \\quad \\text{for } i=1,\\dots,7$$\nHere, the sum is taken to be zero for $i=1$.\n\n**2. Error Estimation**\nThe difference between the two solutions provides an estimate of the local truncation error of the lower-order method:\n$$e = y_{n+1}^{(5)} - y_{n+1}^{(4)} = h \\sum_{i=1}^{7} (b_i - \\hat{b}_i) k_i$$\nTo decide whether the step is accurate enough, this error is compared to a user-defined tolerance. A scaled error norm, $\\mathrm{err}$, is computed:\n$$\\mathrm{err} = \\frac{|e|}{\\mathrm{atol} + \\mathrm{rtol}\\cdot \\max(|y_n|, |y_{n+1}^{(5)}|)}$$\nIn this problem, the relative and absolute tolerances are set equal, $\\mathrm{rtol} = \\mathrm{atol} = \\mathrm{tol}$. Thus, the error scaling term is $\\mathrm{tol} \\cdot (1 + \\max(|y_n|, |y_{n+1}^{(5)}|))$.\n\n**3. Step Acceptance and State Update**\nThe step is accepted if the scaled error is less than or equal to one: $\\mathrm{err} \\le 1$.\n- If the step is accepted, the time and solution are advanced. The higher-order solution is used for propagation (this is known as local extrapolation): $t_{n+1} = t_n + h$ and $y_{n+1} = y_{n+1}^{(5)}$.\n- If the step is rejected, the time and solution are not advanced: $t_{n+1} = t_n$ and $y_{n+1} = y_n$. The step must be retried with a smaller step size.\n\n**4. New Step Size Recommendation**\nRegardless of acceptance or rejection, a new, more appropriate step size $h_{\\mathrm{new}}$ is proposed for the next attempt. A standard proportional controller is used:\n$$h_{\\mathrm{new}} = h \\cdot \\mathrm{clip}\\!\\left( s \\cdot \\mathrm{err}^{-\\frac{1}{p+1}},\\, f_{\\min},\\, f_{\\max}\\right)$$\nHere, $p=4$ is the order of the error estimate, so the exponent is $1/5$. The safety factor $s=0.9$ ensures a conservative choice, and the clipping function limits the change in step size to a factor between $f_{\\min}=0.2$ and $f_{\\max}=5$.\nIn the case where $\\mathrm{err}$ is zero (due to floating-point arithmetic or if the solution is exact), the multiplicative factor is set to its maximum value, $f_{\\max}$.\n\nThe implementation will apply this procedure to each of the four test cases $(t_n, y_n, h, \\mathrm{tol})$ provided, reporting the step acceptance, the next state $(t_{n+1}, y_{n+1})$, and the recommended next step size $h_{\\mathrm{new}}$.\n- Case $1$: $(0,\\, 1,\\, 0.1,\\, 10^{-6})$.\n- Case $2$: $(0,\\, 1,\\, 2.0,\\, 10^{-6})$.\n- Case $3$: $(5,\\, e^{-5},\\, 0.5,\\, 10^{-12})$.\n- Case $4$: $(0,\\, 1,\\, 10^{-8},\\, 10^{-6})$.",
            "answer": "[[True, 0.1, 0.9048374180359595, 0.2185795634563853],[False, 0.0, 1.0, 0.4],[True, 5.5, 0.004086771438464067, 0.7712393351939603],[True, 1e-08, 0.9999999900000001, 5e-08]]"
        }
    ]
}