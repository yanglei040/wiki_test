{
    "hands_on_practices": [
        {
            "introduction": "构建机器学习原子间势（MLIP）的关键第一步，是使用一组数值描述符来表征局部原子环境。Behler-Parrinello 对称函数是一种开创性且被广泛使用的方法，用于生成这些具有旋转、平移和置换不变性的描述符。这个实践练习  旨在巩固这一基本概念，要求您为一个简单立方晶格中的原子计算一个径向对称函数，从而在抽象的数学定义和具体的物理排列之间建立联系。",
            "id": "90953",
            "problem": "在机器学习原子间势领域，Behler-Parrinello对称函数是创建稳健而精确的原子相互作用模型的基石。这些函数以一种在旋转、平移和同类原子置换下保持不变的方式描述了原子的局部化学环境。\n\n一种常见的径向对称函数，记为 $G^i(\\eta, R_s)$，用于量化中心原子 $i$ 周围邻近原子 $j$ 的径向分布。其定义为：\n$$\nG^i(\\eta, R_s) = \\sum_{j \\neq i} e^{-\\eta (R_{ij} - R_s)^2} f_c(R_{ij})\n$$\n在此，$R_{ij}$ 是原子 $i$ 和 $j$ 之间的距离。参数 $\\eta$ 控制高斯函数的宽度，而 $R_s$ 定义了高斯函数中心的径向距离。求和遍及截断半径 $R_c$ 内的所有邻近原子 $j$。该截断由截断函数 $f_c(R_{ij})$ 实现，它使得每个邻近原子的贡献在其距离接近 $R_c$ 时平滑地变为零。一种常用的 $f_c(R_{ij})$ 形式是余弦截断函数：\n$$\nf_c(R_{ij}) = \\begin{cases}\n\\frac{1}{2} \\left( \\cos\\left(\\frac{\\pi R_{ij}}{R_c}\\right) + 1 \\right)  \\text{if } R_{ij} \\le R_c \\\\\n0  \\text{if } R_{ij} > R_c\n\\end{cases}\n$$\n\n考虑一个元素中的单个原子，排列在晶格常数为 $a$ 的理想简单立方 (SC) 晶格中。对于位于该晶格原点的原子，推导径向对称函数 $G^i(\\eta, R_s)$ 值的解析表达式。使用截断半径 $R_c = \\frac{7}{4}a$。你的最终表达式应以晶格常数 $a$ 和对称函数参数 $\\eta$ 和 $R_s$ 表示。",
            "solution": "1. 径向对称函数的定义为\n$$\nG^i(\\eta,R_s)=\\sum_{j\\neq i}e^{-\\eta\\bigl(R_{ij}-R_s\\bigr)^2}f_c(R_{ij})\\,,\n$$\n余弦截断函数为\n$$\nf_c(R)=\\begin{cases}\n\\frac{1}{2}\\bigl(\\cos(\\pi R/R_c)+1\\bigr),  \\text{if } R \\le R_c, \\\\\n0,  \\text{if } R > R_c.\n\\end{cases}\n$$\n\n2. 在常数为 $a$ 的简单立方晶格中，位于原点的原子 $i$ 的邻居位于 $(n_x a, n_y a, n_z a)$ 位置，其中 $n_x, n_y, n_z$ 是整数，且 $(n_x, n_y, n_z) \\neq (0,0,0)$。它们之间的距离是\n$$\nR_{n_x,n_y,n_z}=a\\sqrt{n_x^2+n_y^2+n_z^2}\\,.\n$$\n\n3. 使用截断半径 $R_c=\\tfrac74a=1.75a$，只有满足 $a\\sqrt{n_x^2+n_y^2+n_z^2} \\le R_c$ 或 $n_x^2+n_y^2+n_z^2 \\le (1.75)^2 \\approx 3.06$ 的壳层有贡献：\n- $n^2=1$：6个原子（如(1,0,0)），距离 $R=a$。\n- $n^2=2$：12个原子（如(1,1,0)），距离 $R=a\\sqrt2 \\approx 1.414a$。\n- $n^2=3$：8个原子（如(1,1,1)），距离 $R=a\\sqrt3 \\approx 1.732a$。\n所有这些壳层都在截断半径内。\n\n4. 因此\n$$\nG^i=\\;6\\,e^{-\\eta(a-R_s)^2}f_c(a)\n\\;+\\;12\\,e^{-\\eta(a\\sqrt2-R_s)^2}f_c(a\\sqrt2)\n\\;+\\;8\\,e^{-\\eta(a\\sqrt3-R_s)^2}f_c(a\\sqrt3).\n$$\n\n5. 计算截断因子，例如\n$$\nf_c(a)=\\tfrac12\\bigl(\\cos(\\tfrac{\\pi a}{R_c})+1\\bigr)\n=\\tfrac12\\bigl(\\cos(\\tfrac{4\\pi}{7})+1\\bigr),\n$$\n类似地\n$$\nf_c(a\\sqrt2)=\\tfrac12\\bigl(\\cos(\\tfrac{4\\pi\\sqrt2}{7})+1\\bigr),\\quad\nf_c(a\\sqrt3)=\\tfrac12\\bigl(\\cos(\\tfrac{4\\pi\\sqrt3}{7})+1\\bigr).\n$$\n\n6. 代入并合并因子 $\\tfrac12$ 可得\n$$\nG^i\n=3\\,e^{-\\eta(a-R_s)^2}\\bigl(\\cos(\\tfrac{4\\pi}{7})+1\\bigr)\n+6\\,e^{-\\eta(a\\sqrt2-R_s)^2}\\bigl(\\cos(\\tfrac{4\\pi\\sqrt2}{7})+1\\bigr)\n+4\\,e^{-\\eta(a\\sqrt3-R_s)^2}\\bigl(\\cos(\\tfrac{4\\pi\\sqrt3}{7})+1\\bigr).\n$$",
            "answer": "$$\\boxed{3\\,e^{-\\eta(a-R_s)^2}\\bigl(\\cos\\!\\tfrac{4\\pi}{7}+1\\bigr)\n+6\\,e^{-\\eta(a\\sqrt2-R_s)^2}\\bigl(\\cos\\!\\tfrac{4\\pi\\sqrt2}{7}+1\\bigr)\n+4\\,e^{-\\eta(a\\sqrt3-R_s)^2}\\bigl(\\cos\\!\\tfrac{4\\pi\\sqrt3}{7}+1\\bigr)}$$"
        },
        {
            "introduction": "虽然机器学习模型擅长在其训练数据范围内进行插值，但它们的外推行为可能是不可预测且通常不符合物理规律的。在分子动力学（MD）的背景下，这可能导致灾难性的失败，例如在高能碰撞过程中原子发生坍塌。这个实践练习  直面这一问题，通过比较一个朴素的 MLIP 和一个包含了物理先验知识的模型，展示了一个简单的排斥势垒如何强制实现正确的短程物理行为，从而确保模拟的稳定性。",
            "id": "3462502",
            "problem": "您的任务是为一维、对相互作用系统，在约化的 Lennard-Jones 单位下，构建和评估两种机器学习原子间势 (MLIPs)。其目标是展示如何通过一个参数化先验来施加硬短程排斥（当原子间距离趋近于零时，该先验会发散），从而提高分子动力学 (MD) 模拟的稳定性。您必须实现并比较一个无约束模型和一个包含固定势垒项的约束模型，该势垒项在距离趋于零时会发散。然后，您必须使用每种模型在约化坐标系中模拟双体正面对撞，以量化它们在短距离下的行为。\n\n从以下基本原理和经过充分检验的定义开始：\n\n- 牛顿第二定律：对于相对坐标 $r(t)$ 和约化质量 $\\mu$，运动方程为 $\\mu \\, d^{2} r / dt^{2} = F(r)$，其中 $F(r)$ 是沿中心连线坐标的力。\n- 势能 $E(r)$ 定义了保守力为 $F(r) = - \\, dE(r)/dr$。\n- 一个监督学习回归模型使用基函数 $\\{\\phi_{j}(r)\\}$ 和参数 $\\{w_{j}\\}$ 来表示一个能量模型 $E_{\\theta}(r)$，该模型通过最小化正则化经验风险进行拟合。\n\n您的任务是：\n\n- 从一个在 $r \\to 0$ 时发散的、物理上合理的参考对势 $E_{\\mathrm{ref}}(r)$ 生成一个合成训练数据集。使用参数 $\\epsilon = 1$ 和 $\\sigma = 1$ 的约化 Lennard-Jones 形式，即 $E_{\\mathrm{ref}}(r) = 4 \\left[(\\sigma/r)^{12} - (\\sigma/r)^{6}\\right]$，在训练区间 $r \\in [r_{\\min}, r_{\\max}]$（其中 $r_{\\min} = 0.9$，$r_{\\max} = 3.0$）上进行评估。使用一个包含 $N = 120$ 个点的均匀网格进行训练。\n- 定义一个高斯径向基展开 $g(r) = \\sum_{j=1}^{M} w_{j} \\, \\phi_{j}(r)$，其中高斯基函数为 $\\phi_{j}(r) = \\exp\\left(-\\frac{(r - c_{j})^{2}}{2 s^{2}}\\right)$。使用 $M = 24$ 个基函数中心 $\\{c_{j}\\}$，这些中心均匀分布在 $[0.8, 3.2]$ 区间上，共享宽度为 $s = 0.25$。在通过最小化二次损失来拟合权重 $\\{w_{j}\\}$ 时，使用系数为 $\\lambda = 10^{-6}$ 的 $\\ell_{2}$ 正则化。\n- 训练两个 MLIP：\n  - 无约束模型：$E_{\\mathrm{U}}(r) = g_{\\mathrm{U}}(r)$，直接拟合训练网格上的参考能量，并对权重进行 $\\ell_{2}$ 正则化。\n  - 带硬短程势垒先验的约束模型：$E_{\\mathrm{C}}(r) = g_{\\mathrm{C}}(r) + B(r)$，其中 $B(r) = c_{0} / r^{p}$，$c_{0} = 1.0$ 且 $p = 12$。仅使用相同的基和正则化，将 $g_{\\mathrm{C}}(r)$ 的权重拟合到修改后的目标 $E_{\\mathrm{ref}}(r) - B(r)$。通过这种构造，模型强制要求当 $r \\to 0$ 时 $E_{\\mathrm{C}}(r) \\to \\infty$。\n- 使用高斯基和势垒项的解析导数，推导并实现相应的力表达式 $F_{\\mathrm{U}}(r) = - \\, dE_{\\mathrm{U}}/dr$ 和 $F_{\\mathrm{C}}(r) = - \\, dE_{\\mathrm{C}}/dr$。\n- 使用速度-Verlet算法，在相对坐标中实现一个用于正面对撞的一维约化双体MD。使用约化质量 $\\mu = 0.5$、初始间距 $r_{0} = 1.5$ 以及沿中心连线的初始相对速度 $v_{0}  0$。通过对 $\\mu \\, d^{2}r/dt^{2} = F(r)$ 进行积分来演化标量相对坐标 $r(t)$，时间步长为 $\\Delta t$，总时长固定为 $t_{\\max} = 3.0$。在每一步中，记录遇到的最小间距 $r_{\\min}$。如果模拟遇到 $r \\le r_{\\text{floor}}$（其中 $r_{\\text{floor}} = 0.7$，这被解释为易受数值不稳定性或短程处理不佳影响的短程碰撞区域），您必须停止模拟，并使用截至该点遇到的最小 $r$ 作为报告的 $r_{\\min}$。如果发生数值故障并生成非有限值，您必须报告该情况下的 $r_{\\min} = 0.0$。\n- 所有距离均以约化的Lennard-Jones长度单位表示，时间也采用约化单位。您必须将输出表示为约化长度单位下的无量纲浮点数。\n\n测试套件：\n\n使用以下四个MD案例，每个案例由一对 $(\\Delta t, v_{0})$ 定义，其中负的 $v_{0}$ 表示相互靠近。对于每个案例，运行两次模拟：一次使用无约束模型，另一次使用约束模型。报告每次运行的最小间距 $r_{\\min}$。\n\n- 案例 1：$\\Delta t = 0.005$，$v_{0} = -0.5$。\n- 案例 2：$\\Delta t = 0.010$，$v_{0} = -0.5$。\n- 案例 3：$\\Delta t = 0.020$，$v_{0} = -0.8$。\n- 案例 4：$\\Delta t = 0.040$，$v_{0} = -1.2$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按顺序包含每个案例中无约束模型和约束模型的 $r_{\\min}$ 值。具体来说，输出必须是 $[r_{\\min}^{(1,\\mathrm{U})}, r_{\\min}^{(1,\\mathrm{C})}, r_{\\min}^{(2,\\mathrm{U})}, r_{\\min}^{(2,\\mathrm{C})}, r_{\\min}^{(3,\\mathrm{U})}, r_{\\min}^{(3,\\mathrm{C})}, r_{\\min}^{(4,\\mathrm{U})}, r_{\\min}^{(4,\\mathrm{C})}]$，所有值都是约化长度单位下的浮点数。",
            "solution": "该问题要求为一个一维双体系统构建、训练和评估两种不同的机器学习原子间势 (MLIPs)。核心目标是展示引入物理先验（特别是硬短程排斥）对于确保分子动力学 (MD) 模拟稳定性的重要性。\n\n解决方案主要分为四个阶段：(1) 从已知的物理势生成合成训练数据集。(2) 使用高斯基组和线性回归，定义并训练两种 MLIP 模型——一种是无约束模型，另一种是带有内置排斥势垒的模型。(3) 推导并实现相应的原子间力。(4) 执行和分析正面对撞的 MD 模拟，以比较模型在短原子间距下的行为。\n\n**1. 训练数据生成**\n\n训练 MLIPs 需要一个物理上合理的参考势 $E_{\\mathrm{ref}}(r)$。问题指定了约化单位的 Lennard-Jones (LJ) 势，这是一个用于非键合原子相互作用的标准模型，其参数为 $\\epsilon = 1$ 和 $\\sigma = 1$：\n$$\nE_{\\mathrm{ref}}(r) = 4 \\left[ \\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^{6} \\right] = 4 \\left( \\frac{1}{r^{12}} - \\frac{1}{r^{6}} \\right)\n$$\n该势正确地捕捉了基本的物理特性：由于泡利不相容原理，在短距离（$r \\to 0$）处存在强大的排斥核心；由于范德华力，在长距离处存在较弱的吸引尾部。我们通过在覆盖区间 $r \\in [0.9, 3.0]$ 的 $N=120$ 个点的均匀网格上评估 $E_{\\mathrm{ref}}(r)$ 来生成合成训练数据集。选择此范围是为了覆盖排斥壁、势阱和吸引尾部的起始部分，但它特意排除了势函数急剧发散的极短程区域（$r  0.9$）。\n\n**2. MLIP 模型架构与训练**\n\n两种 MLIP 都基于一个使用高斯基函数线性组合的灵活回归模型。每个模型的核心是一个函数 $g(r)$，定义如下：\n$$\ng(r) = \\sum_{j=1}^{M} w_{j} \\phi_{j}(r)\n$$\n其中 $\\{w_j\\}$ 是可训练的权重，$\\{\\phi_j(r)\\}$ 是高斯基函数：\n$$\n\\phi_{j}(r) = \\exp\\left(-\\frac{(r - c_{j})^{2}}{2 s^{2}}\\right)\n$$\n问题指定了 $M=24$ 个基函数，其中心 $\\{c_j\\}$ 均匀分布在区间 $[0.8, 3.2]$ 内，共享宽度为 $s=0.25$。这组基函数为近似平滑函数提供了一个灵活的框架。两种模型的权重 $\\{w_j\\}$ 都是通过最小化一个正则化的二次损失函数（岭回归）来确定的，其解析解为 $w = (\\Phi^T \\Phi + \\lambda I)^{-1} \\Phi^T y$，其中 $\\Phi$ 是设计矩阵，其元素为 $\\Phi_{ij} = \\phi_j(r_i)$，$y$ 是目标值向量，$\\lambda = 10^{-6}$ 是吉洪诺夫正则化系数。\n\n这两个模型是：\n\n*   **无约束模型 ($E_{\\mathrm{U}}$):** 势能直接由高斯展开表示：\n    $$\n    E_{\\mathrm{U}}(r) = g_{\\mathrm{U}}(r) = \\sum_{j=1}^{M} w_{j}^{(\\mathrm{U})} \\phi_{j}(r)\n    $$\n    权重 $\\{w_{j}^{(\\mathrm{U})}\\}$ 通过在训练网格上将 $g_{\\mathrm{U}}(r)$ 拟合到参考能量 $E_{\\mathrm{ref}}(r)$ 来训练。该模型对其在训练域之外的行为没有显式约束，特别是在 $r \\to 0$ 时。其短程行为纯粹是外推的产物。\n\n*   **约束模型 ($E_{\\mathrm{C}}$):** 该模型以一个固定的、硬排斥势垒项 $B(r)$ 的形式引入了物理先验。总势能为：\n    $$\n    E_{\\mathrm{C}}(r) = g_{\\mathrm{C}}(r) + B(r) = \\left(\\sum_{j=1}^{M} w_{j}^{(\\mathrm{C})} \\phi_{j}(r)\\right) + \\frac{c_{0}}{r^{p}}\n    $$\n    其中 $c_0=1.0$ 且 $p=12$。这个势垒项 $B(r)$ 确保了无论 $g_{\\mathrm{C}}(r)$ 的行为如何，当 $r \\to 0$ 时都有 $E_{\\mathrm{C}}(r) \\to \\infty$。可训练部分 $g_{\\mathrm{C}}(r)$ 的任务是学习残差，即通过拟合到修改后的目标 $E_{\\mathrm{ref}}(r) - B(r)$ 来训练权重 $\\{w_{j}^{(\\mathrm{C})}\\}$。这种策略将已知的物理约束直接嵌入到模型函数形式中。\n\n**3. 力的计算**\n\n保守力 $F(r)$ 通过 $F(r) = -dE(r)/dr$ 从势能 $E(r)$ 推导而来。对我们的模型使用解析导数可以确保力与能量的一致性，这对于 MD 中的能量守恒至关重要。\n\n*   **无约束力 ($F_{\\mathrm{U}}$):**\n    $$\n    F_{\\mathrm{U}}(r) = -\\frac{dE_{\\mathrm{U}}}{dr} = -\\sum_{j=1}^{M} w_{j}^{(\\mathrm{U})} \\frac{d\\phi_{j}}{dr} = -\\sum_{j=1}^{M} w_{j}^{(\\mathrm{U})} \\left( -\\frac{r - c_j}{s^2} \\right) \\phi_j(r) = \\frac{1}{s^2} \\sum_{j=1}^{M} w_{j}^{(\\mathrm{U})} (r - c_j) \\phi_j(r)\n    $$\n\n*   **约束力 ($F_{\\mathrm{C}}$):**\n    $$\n    F_{\\mathrm{C}}(r) = -\\frac{dE_{\\mathrm{C}}}{dr} = -\\left( \\frac{dg_{\\mathrm{C}}}{dr} + \\frac{dB}{dr} \\right)\n    $$\n    势垒项的导数是 $\\frac{dB}{dr} = -p c_0 r^{-(p+1)}$。总力为：\n    $$\n    F_{\\mathrm{C}}(r) = \\left( \\frac{1}{s^2} \\sum_{j=1}^{M} w_{j}^{(\\mathrm{C})} (r - c_j) \\phi_j(r) \\right) + \\frac{p c_0}{r^{p+1}}\n    $$\n    第二项提供了一个强大的、解析的排斥力，在短程范围内占主导地位，防止粒子对坍缩。\n\n**4. 分子动力学模拟**\n\n为了测试模型的高能碰撞行为，我们在质心系中模拟了两个粒子的一维正面对撞。其动力学由相对坐标 $r(t)$ 的牛顿第二定律决定：\n$$\n\\mu \\frac{d^2r}{dt^2} = F(r)\n$$\n其中 $\\mu=0.5$ 是约化质量。我们使用速度-Verlet算法对这个运动方程进行积分，该算法是一种时间可逆的辛积分器，非常适合 MD。从 $r(0)=r_0=1.5$ 和初始接近速度 $v(0)=v_0  0$ 开始，系统状态 $(r, v)$ 随时间演化。关键的可观测量是在模拟过程中遇到的最小间距 $r_{\\min}$。如果达到时间上限 $t_{\\max}=3.0$，或者间距变得不符合物理实际（定义为 $r \\le r_{\\text{floor}}=0.7$），则终止模拟。数值故障（产生非有限值）被视为灾难性的模型失败，并报告 $r_{\\min}$ 为 $0.0$。这种设置直接探测了每种势模型在动态条件下排斥壁的质量。预期约束模型将更加稳健，能够持续产生有限的、物理的转折点（$r_{\\min} > r_{\\text{floor}}$），而无约束模型预计会失败或预测不符合物理实际的相互穿透，尤其是在高能碰撞（更大的 $|v_0|$）和更大的时间步长（$\\Delta t$）下。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Constructs, trains, and evaluates two machine learning interatomic potentials (MLIPs)\n    for a 1D two-body system to demonstrate the effect of a short-range repulsive prior.\n    \"\"\"\n    # 1. Define constants and parameters\n    # System\n    MU = 0.5\n    # Reference Potential (Lennard-Jones)\n    SIGMA = 1.0\n    # Training Data\n    R_TRAIN_MIN = 0.9\n    R_TRAIN_MAX = 3.0\n    N_TRAIN = 120\n    # Basis Set\n    M_BASIS = 24\n    C_MIN = 0.8\n    C_MAX = 3.2\n    S_WIDTH = 0.25\n    # Regularization\n    LAMBDA = 1e-6\n    # Barrier Prior\n    C0_BARRIER = 1.0\n    P_BARRIER = 12\n    # MD Simulation\n    R0 = 1.5\n    T_MAX = 3.0\n    R_FLOOR = 0.7\n\n    # 2. Generate Training Data\n    r_train = np.linspace(R_TRAIN_MIN, R_TRAIN_MAX, N_TRAIN)\n\n    def E_ref(r):\n        inv_r = SIGMA / r\n        inv_r6 = inv_r**6\n        inv_r12 = inv_r6**2\n        return 4.0 * (inv_r12 - inv_r6)\n\n    E_ref_train = E_ref(r_train)\n\n    # 3. Define Basis Set and Models\n    c_centers = np.linspace(C_MIN, C_MAX, M_BASIS)\n\n    def phi_basis(r_vals, centers, width):\n        r_col = np.atleast_1d(r_vals)[:, np.newaxis]\n        centers_row = np.atleast_1d(centers)[np.newaxis, :]\n        return np.exp(-(r_col - centers_row)**2 / (2 * width**2))\n\n    Phi_matrix = phi_basis(r_train, c_centers, S_WIDTH)\n\n    def train_weights(targets):\n        A = Phi_matrix.T @ Phi_matrix + LAMBDA * np.identity(M_BASIS)\n        b = Phi_matrix.T @ targets\n        weights = np.linalg.solve(A, b)\n        return weights\n\n    # Train Unconstrained Model\n    w_U = train_weights(E_ref_train)\n\n    # Train Constrained Model\n    def B_barrier(r):\n        with np.errstate(over='raise', invalid='raise'):\n            try:\n                return C0_BARRIER / r**P_BARRIER\n            except FloatingPointError:\n                # Handle cases where r is extremely small, causing overflow\n                return np.inf\n\n    target_C = E_ref_train - B_barrier(r_train)\n    w_C = train_weights(target_C)\n\n    # 4. Implement Force Functions\n    def get_force_func(weights, is_constrained):\n        def force(r):\n            # r is a scalar\n            if not np.isfinite(r) or r = 0:\n                raise ValueError(\"Non-physical distance in force calculation.\")\n            \n            # Derivative of Gaussian expansion part\n            phi_vals = np.exp(-(r - c_centers)**2 / (2 * S_WIDTH**2))\n            dphi_vals = -(r - c_centers) / S_WIDTH**2 * phi_vals\n            d_g_dr = np.sum(weights * dphi_vals)\n            \n            d_E_dr = d_g_dr\n            if is_constrained:\n                d_B_dr = -P_BARRIER * C0_BARRIER / r**(P_BARRIER + 1)\n                d_E_dr += d_B_dr\n            \n            return -d_E_dr\n        return force\n\n    force_U = get_force_func(w_U, is_constrained=False)\n    force_C = get_force_func(w_C, is_constrained=True)\n\n    # 5. Implement MD Simulation\n    def run_md(force_func, dt, v0):\n        r = R0\n        v = v0\n        min_r_so_far = r\n        \n        try:\n            a = force_func(r) / MU\n            if not np.isfinite(a): return 0.0\n        except (ValueError, FloatingPointError, ZeroDivisionError):\n            return 0.0\n            \n        num_steps = int(T_MAX / dt)\n        \n        for _ in range(num_steps):\n            v_half = v + 0.5 * a * dt\n            r_new = r + v_half * dt\n            \n            if not np.isfinite(r_new):\n                return 0.0\n            \n            min_r_so_far = min(min_r_so_far, r_new)\n            \n            if r_new = R_FLOOR:\n                return min_r_so_far\n            \n            try:\n                a_new = force_func(r_new) / MU\n                if not np.isfinite(a_new):\n                    return 0.0\n            except (ValueError, FloatingPointError, ZeroDivisionError):\n                return 0.0\n                \n            v_new = v_half + 0.5 * a_new * dt\n            \n            r, v, a = r_new, v_new, a_new\n            \n        return min_r_so_far\n\n    # 6. Run Test Cases and Collect Results\n    test_cases = [\n        (0.005, -0.5),\n        (0.010, -0.5),\n        (0.020, -0.8),\n        (0.040, -1.2)\n    ]\n    \n    results = []\n    \n    for dt, v0 in test_cases:\n        r_min_U = run_md(force_U, dt, v0)\n        results.append(r_min_U)\n        \n        r_min_C = run_md(force_C, dt, v0)\n        results.append(r_min_C)\n        \n    # 7. Format and Print Output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "训练 MLIP 通常涉及拟合量子力学计算得出的能量和力，这两者具有不同的单位和噪声水平。对于实践者来说，一个关键问题是如何在训练损失函数中对这些不同类型的数据进行最佳加权，以实现最佳的模型性能。这个高级实践  将引导您进行一次理论分析，以推导最佳的加权方案，揭示该选择如何依赖于训练数据的统计特性，并为做出这一关键建模决策提供严谨的基础。",
            "id": "3462554",
            "problem": "您正在设计一种线性化分析方法，用于使用结合了能量和力的混合损失函数，从密度泛函理论（DFT）数据中训练机器学习原子间势（MLIP）。考虑一个监督回归模型，其参数矢量维度为 $p$，该模型将描述符特征映射到每个构型的标量能量和每个原子自由度的矢量力。假设以下数据生成和学习模型。\n\n1. 训练数据包含 $n$ 个独立构型，每个构型有 $N_{\\text{at}}$ 个原子，因此力的分量总数为 $m = 3 \\, n \\, N_{\\text{at}}$。采用标准简化方法，在最优解附近进行线性化处理，并假设一个各向同性的白化特征空间，在该空间中，每个目标的设计二阶矩都被缩放为单位矩阵。设岭回归正则化系数为 $\\lambda \\ge 0$。\n\n2. 观测噪声模型：\n   - 能量具有加性独立高斯噪声，其均值为零，方差为 $\\sigma_E^2$（单位为电子伏特，记为 $\\mathrm{eV}$）。\n   - 力具有加性独立高斯噪声，其均值为零，方差为 $\\sigma_F^2$（单位为平方电子伏特每平方埃，记为 $(\\mathrm{eV}/\\text{\\AA})^2$）。\n\n3. 训练损失：\n   - 力匹配损失是仅含力的损失，它只使用力的残差和岭回归正则化。\n   - 能量-力混合损失是能量残差和力残差（分别对所有相应目标求和）的加权和，再加上岭回归正则化。设 $w_E \\ge 0$ 和 $w_F \\ge 0$ 分别是能量和力的平方残差总和的标量权重。定义权重比 $\\alpha = w_E / w_F$。不失一般性地，将 $w_F = 1$ 归一化，并将 $\\alpha$ 视为可调超参数。\n\n4. 力的泛化度量：\n   - 考虑一个新的、未见过的力分量，其白化描述符的统计特性与训练数据中的力相匹配。将力的期望泛化均方预测误差（单位为 $(\\mathrm{eV}/\\text{\\AA})^2$）定义为不可约减噪声 $(\\sigma_F^2)$ 与在指定训练损失下由参数估计引起的方差之和。\n\n任务：\n\nA. 仅从线性高斯模型、加权最小二乘法和岭回归的基本原理出发，推导期望力泛化误差作为 $\\alpha$, $n$, $m$, $p$, $\\sigma_E$, $\\sigma_F$, 和 $\\lambda$ 的函数的显式表达式。此推導需基于以下假设：能量和力的设计矩是各向同性且白化的，并且测试时的力具有匹配的白化统计特性。证明该表达式通过包含 $n$, $m$ 和 $\\lambda$ 的有理因子依赖于 $\\alpha$。\n\nB. 在相同假设下，推导使期望力泛化误差最小化的 $\\alpha$ 值。将其与 $\\lambda = 0$ 的特殊情况进行比较，并根据相对噪声水平和力观测值的数量来解释结果。\n\nC. 实现一个程序，该程序为每个测试用例计算以下内容：\n   1. 使混合损失的期望力泛化误差最小化的最优 $\\alpha^\\star$。\n   2. 力匹配的期望力泛化误差（设 $\\alpha = 0$）。\n   3. 混合损失在 $\\alpha^\\star$ 处的期望力泛化误差。\n   4. 混合损失相对于力匹配在期望力泛化误差上的相对改进，计算公式为 $(\\text{FM} - \\text{Mixed})/\\text{FM}$，以小数形式报告（不使用百分号）。\n   5. 一个布尔值，如果混合损失在 $\\alpha^\\star$ 处的表现严格优于（期望误差更低）力匹配，则为真。\n\n所有期望误差必须以 $(\\mathrm{eV}/\\text{\\AA})^2$ 为单位表示。对于每个测试用例，报告四舍五入到 $8$ 位小数的浮点数结果。\n\n实现假设：\n- 对能量和力的设计矩阵的二阶矩使用各向同性白化近似，并假设测试时的力描述符是匹配的白化描述符。\n- 使用给定的岭回归正则化系数 $\\lambda$，其维度通过白化进行了一致性归一化。\n\n测试套件参数：\n- 案例 1：$n = 100$, $N_{\\text{at}} = 10$ (因此 $m = 3 \\cdot 100 \\cdot 10$), $p = 20$, $\\sigma_F = 0.05 \\, \\mathrm{eV}/\\text{\\AA}$, $\\sigma_E = 0.5 \\, \\mathrm{eV}$, $\\lambda = 0$。\n- 案例 2：$n = 100$, $N_{\\text{at}} = 10$, $p = 20$, $\\sigma_F = 0.2 \\, \\mathrm{eV}/\\text{\\AA}$, $\\sigma_E = 0.5 \\, \\mathrm{eV}$, $\\lambda = 0$。\n- 案例 3：$n = 100$, $N_{\\text{at}} = 10$, $p = 20$, $\\sigma_F = 0.05 \\, \\mathrm{eV}/\\text{\\AA}$, $\\sigma_E = 0.5 \\, \\mathrm{eV}$, $\\lambda = 3000$。\n- 案例 4：$n = 100$, $N_{\\text{at}} = 10$, $p = 20$, $\\sigma_F = 0.05 \\, \\mathrm{eV}/\\text{\\AA}$, $\\sigma_E = 0.01 \\, \\mathrm{eV}$, $\\lambda = 0$。\n- 案例 5：$n = 5$, $N_{\\text{at}} = 2$, $p = 40$, $\\sigma_F = 0.05 \\, \\mathrm{eV}/\\text{\\AA}$, $\\sigma_E = 0.5 \\, \\mathrm{eV}$, $\\lambda = 10$。\n- 案例 6：$n = 20$, $N_{\\text{at}} = 1$, $p = 100$, $\\sigma_F = 0.1 \\, \\mathrm{eV}/\\text{\\AA}$, $\\sigma_E = 0.005 \\, \\mathrm{eV}$, $\\lambda = 0$。\n\n程序输出规范：\n- 您的程序应生成单行输出，其中包含每个测试用例的结果列表，每个案例一个条目，每个条目本身是一个形式为 $[\\alpha^\\star, \\text{MSE}_{\\text{FM}}, \\text{MSE}_{\\text{Mixed}}(\\alpha^\\star), \\text{Improvement}, \\text{IsMixedBetter}]$ 的列表。\n- 浮点数必须四舍五入到 $8$ 位小数。布尔值必须表示为编程语言的布尔字面量。\n- 全部输出必须是嵌套列表的单行字符串，例如： \"[[alpha_star_1,mse_fm_1,mse_mixed_1,improvement_1,boolean_1],[alpha_star_2,mse_fm_2,mse_mixed_2,improvement_2,boolean_2],...]\"。",
            "solution": "该问题要求对基于混合损失函数训练的机器学习原子间势（MLIP）模型的泛化误差进行理论推导，然后通过编程实现计算几个测试用例的最优超参数和相关误差。分析将在指定的线性化、白化特征空间框架内进行。\n\n设线性模型的参数矢量为 $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$。训练数据包含 $n$ 个能量目标和 $m = 3 n N_{\\text{at}}$ 个力分量目标。假设数据生成过程如下：\n$$ \\mathbf{E} = X_E \\boldsymbol{\\beta}^* + \\boldsymbol{\\epsilon}_E $$\n$$ \\mathbf{F} = X_F \\boldsymbol{\\beta}^* + \\boldsymbol{\\epsilon}_F $$\n其中 $\\mathbf{E} \\in \\mathbb{R}^n$ 和 $\\mathbf{F} \\in \\mathbb{R}^m$ 分别是观测到的能量和力。$X_E \\in \\mathbb{R}^{n \\times p}$ 和 $X_F \\in \\mathbb{R}^{m \\times p}$ 是相应的设计矩阵（特征矩阵）。$\\boldsymbol{\\beta}^*$ 是真实的、未知的参数矢量。噪声项是独立同分布的高斯变量：$\\boldsymbol{\\epsilon}_E \\sim \\mathcal{N}(0, \\sigma_E^2 I_n)$ 和 $\\boldsymbol{\\epsilon}_F \\sim \\mathcal{N}(0, \\sigma_F^2 I_m)$。\n\n包含岭回归正则化的混合损失目标函数由下式给出：\n$$ L(\\boldsymbol{\\beta}) = \\alpha \\| \\mathbf{E} - X_E \\boldsymbol{\\beta} \\|_2^2 + \\| \\mathbf{F} - X_F \\boldsymbol{\\beta} \\|_2^2 + \\lambda \\|\\boldsymbol{\\beta}\\|_2^2 $$\n此处，$\\alpha = w_E / w_F$ 是能量-力权重比，且 $w_F=1$。为找到使该损失最小化的参数估计值 $\\hat{\\boldsymbol{\\beta}}$，我们计算 $L(\\boldsymbol{\\beta})$ 的梯度并将其设为零：\n$$ \\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta}) = -2\\alpha X_E^T (\\mathbf{E} - X_E \\boldsymbol{\\beta}) - 2X_F^T (\\mathbf{F} - X_F \\boldsymbol{\\beta}) + 2\\lambda \\boldsymbol{\\beta} = \\mathbf{0} $$\n求解 $\\hat{\\boldsymbol{\\beta}}$ 可得：\n$$ (\\alpha X_E^T X_E + X_F^T X_F + \\lambda I_p) \\hat{\\boldsymbol{\\beta}} = \\alpha X_E^T \\mathbf{E} + X_F^T \\mathbf{F} $$\n$$ \\hat{\\boldsymbol{\\beta}} = (\\alpha X_E^T X_E + X_F^T X_F + \\lambda I_p)^{-1} (\\alpha X_E^T \\mathbf{E} + X_F^T \\mathbf{F}) $$\n问题指定了一个各向同性的白化特征空间，其中每个目标的设计二阶矩被缩放为单位矩阵。这是解析研究中的一个标准简化，我们将其解释为 $X_E^T X_E = n I_p$ 和 $X_F^T X_F = m I_p$，其中 $I_p$ 是 $p \\times p$ 的单位矩阵。将这些代入 $\\hat{\\boldsymbol{\\beta}}$ 的表达式中：\n$$ \\hat{\\boldsymbol{\\beta}} = (\\alpha n I_p + m I_p + \\lambda I_p)^{-1} (\\alpha X_E^T \\mathbf{E} + X_F^T \\mathbf{F}) $$\n$$ \\hat{\\boldsymbol{\\beta}} = \\frac{1}{\\alpha n + m + \\lambda} (\\alpha X_E^T \\mathbf{E} + X_F^T \\mathbf{F}) $$\n为了分析 $\\hat{\\boldsymbol{\\beta}}$ 的统计特性，我们代入数据生成模型：\n$$ \\hat{\\boldsymbol{\\beta}} = \\frac{1}{\\alpha n + m + \\lambda} (\\alpha X_E^T (X_E \\boldsymbol{\\beta}^* + \\boldsymbol{\\epsilon}_E) + X_F^T (X_F \\boldsymbol{\\beta}^* + \\boldsymbol{\\epsilon}_F)) $$\n$$ \\hat{\\boldsymbol{\\beta}} = \\frac{\\alpha X_E^T X_E + X_F^T X_F}{\\alpha n + m + \\lambda} \\boldsymbol{\\beta}^* + \\frac{\\alpha X_E^T \\boldsymbol{\\epsilon}_E + X_F^T \\boldsymbol{\\epsilon}_F}{\\alpha n + m + \\lambda} $$\n再次应用白化设计假设：\n$$ \\hat{\\boldsymbol{\\beta}} = \\frac{\\alpha n I_p + m I_p}{\\alpha n + m + \\lambda} \\boldsymbol{\\beta}^* + \\boldsymbol{\\delta} $$\n其中 $\\boldsymbol{\\delta}$ 代表估计量的随机部分。由于 $\\mathbb{E}[\\boldsymbol{\\epsilon}_E]=\\mathbf{0}$ 和 $\\mathbb{E}[\\boldsymbol{\\epsilon}_F]=\\mathbf{0}$，$\\boldsymbol{\\delta}$ 的期望为零。估计量的协方差矩阵为 $\\text{Cov}(\\hat{\\boldsymbol{\\beta}}) = \\mathbb{E}[\\boldsymbol{\\delta}\\boldsymbol{\\delta}^T]$。由于噪声是独立的，我们有：\n$$ \\text{Cov}(\\hat{\\boldsymbol{\\beta}}) = \\frac{1}{(\\alpha n + m + \\lambda)^2} \\mathbb{E}[\\alpha^2 (X_E^T \\boldsymbol{\\epsilon}_E)(\\boldsymbol{\\epsilon}_E^T X_E) + (X_F^T \\boldsymbol{\\epsilon}_F)(\\boldsymbol{\\epsilon}_F^T X_F)] $$\n$$ \\text{Cov}(\\hat{\\boldsymbol{\\beta}}) = \\frac{1}{(\\alpha n + m + \\lambda)^2} (\\alpha^2 \\sigma_E^2 X_E^T X_E + \\sigma_F^2 X_F^T X_F) $$\n$$ \\text{Cov}(\\hat{\\boldsymbol{\\beta}}) = \\frac{\\alpha^2 n \\sigma_E^2 + m \\sigma_F^2}{(\\alpha n + m + \\lambda)^2} I_p $$\n\nA. 问题的定义是，一个力预测的期望泛化误差是不可约减噪声 ($\\sigma_F^2$) 和由参数估计引起的方差之和。这是一个非标准的均方误差（MSE）定义，因为它忽略了由正则化引起的平方偏差项。我们将严格遵循此定义。对于一个具有特征矢量 $\\mathbf{x}_F$ 的新力分量，其预测值为 $\\hat{f} = \\mathbf{x}_F^T \\hat{\\boldsymbol{\\beta}}$。该预测的方差为 $\\text{Var}(\\hat{f}) = \\mathbf{x}_F^T \\text{Cov}(\\hat{\\boldsymbol{\\beta}}) \\mathbf{x}_F$。“白化描述符统计特性与训练力相匹配”的假设意味着一个典型的测试特征矢量 $\\mathbf{x}_F$ 的平方范数等于训练集的平均值，即 $\\frac{1}{m}\\text{Tr}(X_F^T X_F) = \\frac{1}{m}\\text{Tr}(m I_p) = p$。因此，我们取 $\\|\\mathbf{x}_F\\|_2^2=p$。\n由参数估计引起的方差为：\n$$ \\text{Var}(\\hat{f}) = \\frac{\\alpha^2 n \\sigma_E^2 + m \\sigma_F^2}{(\\alpha n + m + \\lambda)^2} \\|\\mathbf{x}_F\\|_2^2 = p \\frac{\\alpha^2 n \\sigma_E^2 + m \\sigma_F^2}{(\\alpha n + m + \\lambda)^2} $$\n总的期望力泛化误差为：\n$$ \\text{MSE}_F(\\alpha) = \\sigma_F^2 + p \\frac{\\alpha^2 n \\sigma_E^2 + m \\sigma_F^2}{(\\alpha n + m + \\lambda)^2} $$\n此表达式是指定变量的函数，并通过有理因子依赖于 $\\alpha$，完成了任务 A。\n\nB. 为找到使 $\\text{MSE}_F(\\alpha)$ 最小化的最优 $\\alpha$，我们对可变部分关于 $\\alpha$ 求导并令其为零。设 $V(\\alpha) = p \\frac{u(\\alpha)}{v(\\alpha)}$，其中 $u(\\alpha) = \\alpha^2 n \\sigma_E^2 + m \\sigma_F^2$ 且 $v(\\alpha) = (\\alpha n + m + \\lambda)^2$。\n$$ \\frac{dV}{d\\alpha} = p \\frac{u'(\\alpha)v(\\alpha) - u(\\alpha)v'(\\alpha)}{v(\\alpha)^2} = 0 $$\n导数为 $u'(\\alpha) = 2\\alpha n \\sigma_E^2$ 和 $v'(\\alpha) = 2n(\\alpha n + m + \\lambda)$。\n$$ (2\\alpha n \\sigma_E^2)(\\alpha n + m + \\lambda)^2 - (\\alpha^2 n \\sigma_E^2 + m \\sigma_F^2)(2n(\\alpha n + m + \\lambda)) = 0 $$\n假设 $\\alpha n+m+\\lambda \\neq 0$，我们可以简化为：\n$$ \\alpha \\sigma_E^2 (\\alpha n + m + \\lambda) - (\\alpha^2 n \\sigma_E^2 + m \\sigma_F^2) = 0 $$\n$$ \\alpha^2 n \\sigma_E^2 + \\alpha(m+\\lambda)\\sigma_E^2 - \\alpha^2 n \\sigma_E^2 - m \\sigma_F^2 = 0 $$\n$$ \\alpha(m+\\lambda)\\sigma_E^2 = m \\sigma_F^2 $$\n因此，最优权重比为：\n$$ \\alpha^\\star = \\frac{m \\sigma_F^2}{(m + \\lambda) \\sigma_E^2} $$\n对于 $\\lambda = 0$ 的特殊情况，该式简化为 $\\alpha^\\star = \\sigma_F^2 / \\sigma_E^2$。这是加权最小二乘法的一个经典结果：损失函数各分量的最优权重与其各自的噪声方差成反比。具体来说，为了最大化似然，能量项应以 $1/\\sigma_E^2$ 加权，力项应以 $1/\\sigma_F^2$ 加权。这些权重的比值为 $\\alpha = (1/\\sigma_E^2)/(1/\\sigma_F^2) = \\sigma_F^2 / \\sigma_E^2$，这证实了我们的结果。正则化项 $\\lambda > 0$ 会降低能量项的最优权重，从而有效地減弱其相对于力和正则化先验的贡献。\n\nC. 需要实现的表达式如下：\n1.  最优 alpha： $\\alpha^\\star = \\frac{m \\sigma_F^2}{(m + \\lambda) \\sigma_E^2}$\n2.  力匹配误差（$\\alpha=0$）： $\\text{MSE}_{\\text{FM}} = \\sigma_F^2 + p \\frac{m \\sigma_F^2}{(m + \\lambda)^2}$\n3.  最优混合损失误差： $\\text{MSE}_{\\text{Mixed}}(\\alpha^\\star) = \\sigma_F^2 + p \\frac{(\\alpha^\\star)^2 n \\sigma_E^2 + m \\sigma_F^2}{(\\alpha^\\star n + m + \\lambda)^2}$\n4.  相对改进： $(\\text{MSE}_{\\text{FM}} - \\text{MSE}_{\\text{Mixed}}(\\alpha^\\star))/\\text{MSE}_{\\text{FM}}$\n5.  布尔值检查： $\\text{MSE}_{\\text{Mixed}}(\\alpha^\\star)  \\text{MSE}_{\\text{FM}}$\n\n现在为指定的测试套件实现这些公式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes optimal training parameters and generalization errors for a\n    linearized Machine Learning Interatomic Potential model.\n    \"\"\"\n    # Test suite parameters:\n    # (n, N_at, p, sigma_F, sigma_E, lambda)\n    test_cases = [\n        (100, 10, 20, 0.05, 0.5, 0.0),\n        (100, 10, 20, 0.2, 0.5, 0.0),\n        (100, 10, 20, 0.05, 0.5, 3000.0),\n        (100, 10, 20, 0.05, 0.01, 0.0),\n        (5, 2, 40, 0.05, 0.5, 10.0),\n        (20, 1, 100, 0.1, 0.005, 0.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, N_at, p, sigma_F, sigma_E, lamb = case\n        \n        m = 3 * n * N_at\n        sigma_F_sq = sigma_F**2\n        sigma_E_sq = sigma_E**2\n\n        # 1. Compute optimal alpha\n        # Handle potential division by zero if sigma_E is zero, though not in test cases.\n        if sigma_E_sq == 0:\n            # If energy noise is zero, we must trust energies infinitely more.\n            # This is a limiting case; for practical purposes, it would be a very large number.\n            alpha_star = np.inf\n        else:\n            alpha_star = (m * sigma_F_sq) / ((m + lamb) * sigma_E_sq)\n\n        # 2. Compute expected force generalization error for force-matching (alpha = 0)\n        # MSE_FM = sigma_F^2 + p * (m * sigma_F^2) / (m + lambda)^2\n        # Ensure m + lamb is not zero.\n        if (m + lamb) == 0:\n            # This case implies no data and no regularization, leading to infinite variance.\n             mse_fm = np.inf\n        else:\n            var_fm = p * (m * sigma_F_sq) / (m + lamb)**2\n            mse_fm = sigma_F_sq + var_fm\n\n        # 3. Compute expected force generalization error for mixed loss at alpha_star\n        # MSE_Mixed = sigma_F^2 + p * ( (alpha*)^2*n*sigma_E^2 + m*sigma_F^2 ) / ( alpha*n + m + lambda )^2\n        if np.isinf(alpha_star):\n            # Limiting case for alpha - infinity\n            var_mixed = p * (n * sigma_E_sq) / n**2\n            mse_mixed = sigma_F_sq + var_mixed\n        else:\n            numerator_var_mixed = alpha_star**2 * n * sigma_E_sq + m * sigma_F_sq\n            denominator_var_mixed = (alpha_star * n + m + lamb)**2\n            \n            if denominator_var_mixed == 0:\n                var_mixed = np.inf\n            else:\n                var_mixed = p * numerator_var_mixed / denominator_var_mixed\n            \n            mse_mixed = sigma_F_sq + var_mixed\n\n        # 4. Compute relative improvement\n        if mse_fm == 0:\n            # If FM error is zero, there can be no improvement.\n            improvement = 0.0\n        elif np.isinf(mse_fm):\n            # If FM error is infinite, any finite error from mixed is 100% improvement.\n            improvement = 1.0 if np.isfinite(mse_mixed) else 0.0\n        else:\n            improvement = (mse_fm - mse_mixed) / mse_fm\n\n        # 5. Determine if mixed loss is strictly better\n        is_mixed_better = mse_mixed  mse_fm\n        \n        # Assemble the results for the current case\n        case_results = [\n            round(alpha_star, 8),\n            round(mse_fm, 8),\n            round(mse_mixed, 8),\n            round(improvement, 8),\n            is_mixed_better\n        ]\n        results.append(case_results)\n\n    # Format the final output string as specified\n    formatted_results = []\n    for res in results:\n        # Format floats to 8 decimal places, booleans to string literals\n        # Example format: [0.01000000,0.00251667,0.00251666,0.00000220,True]\n        formatted_str = (\n            f\"[{res[0]:.8f},\"\n            f\"{res[1]:.8f},\"\n            f\"{res[2]:.8f},\"\n            f\"{res[3]:.8f},\"\n            f\"{'true' if res[4] else 'false'}]\"\n        )\n        # The user's specification shows Python/JS boolean literals, not C++/Java's. So let's use `str(res[4])`.\n        formatted_str = (\n            f\"[{res[0]:.8f},\"\n            f\"{res[1]:.8f},\"\n            f\"{res[2]:.8f},\"\n            f\"{res[3]:.8f},\"\n            f\"{str(res[4])}]\"\n        )\n        formatted_results.append(formatted_str)\n    \n    # Final print statement must be on a single line\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}