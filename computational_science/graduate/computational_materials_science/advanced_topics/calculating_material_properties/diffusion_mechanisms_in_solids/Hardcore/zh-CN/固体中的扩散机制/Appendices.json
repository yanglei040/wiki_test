{
    "hands_on_practices": [
        {
            "introduction": "分子动力学（MD）模拟是研究原子扩散机理的强大工具，它能直接生成原子运动的轨迹。本练习  的核心是应用爱因斯坦关系式，即通过分析粒子均方位移（MSD）随时间的演化来计算示踪扩散系数$D_{\\text{tr}}$。您将亲手编写一个完整的分析流程，从处理周期性边界条件下的轨迹数据，到利用傅里葉变换高效计算MSD，再到识别扩散区域并进行精确的线性拟合。这个实践将使您全面掌握从MD原始数据中提取扩散系数的核心技术与最佳实践。",
            "id": "3444735",
            "problem": "您的任务是编写一个完整、可运行的程序，该程序能根据周期性边界条件下的原子轨迹，估算三维固体中的示踪扩散系数，评估收敛性，通过比较不同的模拟盒子长度来评估有限尺寸效应，并使用分块平均法报告统计不确定性。推导和算法必须基于基本原理和经过充分检验的事实，不依赖任何预先提供的专用快捷方式。程序必须是自包含的，并且只使用标准库和执行环境中允许的库。所有量都必须以具有物理意义的单位进行处理和报告。\n\n您的推导必须基于以下经过充分检验的定义和事实：\n- 在一个具有空间各向同性的三维系统的扩散区域中，时间平均均方位移随延迟时间线性增长，示踪扩散系数由 Einstein 关系式定义：$$D_{\\text{tr}} \\equiv \\lim_{t \\to \\infty} \\frac{\\langle \\Delta r^2(t) \\rangle}{2 d t},$$ 其中 $d=3$ 是空间维度，$\\langle \\Delta r^2(t) \\rangle$ 是延迟时间 $t$ 下的系綜平均方位移。\n- 在长度为 $L$ 的立方盒子的周期性边界条件下，任何位置差都必须使用最小镜像约定进行映射，以使位移的每个分量都位于区间 $[-L/2, L/2)$ 内，然后累加重构展开坐标。\n- 对于离散轨迹，延迟指数为 $\\tau$ 的时间平均均方位移可以计算为 $$\\operatorname{MSD}[\\tau] = \\frac{1}{N-\\tau}\\sum_{t=0}^{N-\\tau-1} \\left\\| \\mathbf{r}(t+\\tau)-\\mathbf{r}(t)\\right\\|^2,$$ 其中 $N$ 是帧数，$\\mathbf{r}(t)$ 是第 $t$ 帧的展开位置。\n- 为了数值稳定性和效率，一个有效的出发点是将 $\\operatorname{MSD}[\\tau]$ 与自相关联系起来的卷积恒等式：$$\\sum_{t=0}^{N-\\tau-1}\\left\\| \\mathbf{r}(t+\\tau)-\\mathbf{r}(t)\\right\\|^2=\\sum_{t=0}^{N-\\tau-1}\\|\\mathbf{r}(t+\\tau)\\|^2+\\sum_{t=0}^{N-\\tau-1}\\|\\mathbf{r}(t)\\|^2-2\\sum_{t=0}^{N-\\tau-1}\\mathbf{r}(t)\\cdot\\mathbf{r}(t+\\tau),$$ 这允许使用基于快速傅里叶变换的方法来计算自相关项。\n- $D_{\\text{tr}}$ 的统计不确定性可以通过分块平均法来估算：将轨迹在时间上划分为 $B$ 个等长的连续块，使用相同的操作定义和时间窗口为每个块计算一个独立的 $D_{\\text{tr}}$ 估计值，并报告块估计值的平均标准误差，该误差等于样本标准差除以 $\\sqrt{B}$。\n\n您的程序必须实现以下内容，从这些基础出发，并自行构建完整的推理步骤：\n- 给定一个边长为 $L$ 的立方模拟盒子，在均匀时间间隔 $\\Delta t$ 下采样的、满足周期性边界条件的原子包裹坐标数组，通过对连续帧之间的差值应用最小镜像约定并进行累加，重构展开坐标。\n- 计算所有示踪粒子和所有时间原点的时间平均均方位移 $\\langle \\Delta r^2(t) \\rangle$，并通过分析局部对数导数 $$\\gamma(t) \\equiv \\frac{\\mathrm{d} \\ln \\langle \\Delta r^2(t) \\rangle}{\\mathrm{d} \\ln t}$$ 来确定一个扩散时间窗口 $[t_{\\min}, t_{\\max}]$。在扩散区域，$\\gamma(t)$ 应该接近于 $1$。选择 $t_{\\min}$ 为 $\\gamma(t)$ 在指定容差范围内持续接近 $1$ 的最早时间，选择 $t_{\\max}$ 为轨迹结束前保持此行为的最新时间。如果无法稳健地找到这样的窗口，则在轨迹的最后一部分选择一个保守的窗口，并标记为不收敛。\n- 在选定的 $[t_{\\min}, t_{\\max}]$ 窗口内，使用加权线性回归估算 $\\langle \\Delta r^2(t) \\rangle$ 相对于 $t$ 的斜率，权重等于对每个延迟时间有贡献的时间原点对的数量，然后将斜率除以 $2d$ 得到 $D_{\\text{tr}}$。\n- 通过比较从轨迹的前一个重要部分和后一个重要部分获得的估算斜率来评估收敛性；只有当检测到清晰的扩散窗口并且这两个斜率估计值在指定的相对容差内一致时，才声明收敛。\n- 使用 $B$ 个连续的时间块进行分塊平均来估算不确定性，为每个块在相同的操作窗口内重新计算完整的 $D_{\\text{tr}}$ 估计值，并报告平均标准误差。如果操作窗口超过了块的可用长度，则调整窗口或舍弃该块。\n- 通过对在相同微观条件下模拟的两种不同立方盒子长度 $L_1$ 和 $L_2$ 重复进行完整分析，来评估有限尺寸效应，并检验不同尺寸之间的 $D_{\\text{tr}}$ 差异是否超过组合标准误差的两倍。报告一个布尔值，指示在此标准下有限尺寸偏差是否具有统计显著性。\n\n单位和报告要求：\n- 模拟输入使用埃（ångström）作为位置单位，皮秒（picosecond）作为时间单位。您必须以平方米/秒为单位报告 $D_{\\text{tr}}$。使用转换因子 $$1\\,\\mathrm{\\AA}^2/\\mathrm{ps}=10^{-8}\\,\\mathrm{m}^2/\\mathrm{s}.$$\n- 所有最终浮点数结果都以十进制浮点形式表示。输出中不要打印任何单位符号。程序不得读取任何输入。\n\n测试套件：\n- 您的程序必须通过合成包裹轨迹来实现以下三个测试用例，这些轨迹描述了独立示踪粒子进行无偏扩散，其高斯增量的均值为零，每个分量的方差等于 $2 D \\Delta t$，其中 $D$ 是真实示踪扩散系数，单位为 $\\mathrm{\\AA}^2/\\mathrm{ps}$，然后包裹到指定的立方盒子中。使用提供的随机种子以保证可复现性。\n    - 用例1（采样良好，单一尺寸）：$D = 1.0\\times 10^{-3}\\,\\mathrm{\\AA}^2/\\mathrm{ps}$，$\\Delta t = 0.005\\,\\mathrm{ps}$，步数 $N=20000$，示踪粒子数 $n=50$，立方盒子列表 $[L]=[12.0]\\,\\mathrm{\\AA}$，随机种子 $42$，块数 $B=5$。\n    - 用例2（采样不佳，单一尺寸）：$D = 1.0\\times 10^{-3}\\,\\mathrm{\\AA}^2/\\mathrm{ps}$，$\\Delta t = 0.005\\,\\mathrm{ps}$，步数 $N=1000$，示踪粒子数 $n=5$，立方盒子列表 $[L]=[12.0]\\,\\mathrm{\\AA}$，随机种子 $123$，块数 $B=4$。\n    - 用例3（有限尺寸评估）：$D = 1.0\\times 10^{-3}\\,\\mathrm{\\AA}^2/\\mathrm{ps}$，$\\Delta t = 0.005\\,\\mathrm{ps}$，步数 $N=15000$，示踪粒子数 $n=30$，立方盒子列表 $[L_1,L_2]=[8.0,16.0]\\,\\mathrm{\\AA}$，随机种子 $7$，块数 $B=5$。\n\n要求的最终输出格式：\n- 对于每个测试用例，生成一个形式为 $[\\text{D\\_list\\_SI}, \\text{converged\\_boolean}, \\text{finite\\_size\\_significant\\_boolean}, \\text{SE\\_list\\_SI}]$ 的结果，其中 $\\text{D\\_list\\_SI}$ 是该用例中每个盒子长度对应的 $D_{\\text{tr}}$ 估计值列表（单位为 $\\mathrm{m}^2/\\mathrm{s}$，对于单一尺寸用例只有一个值），而 $\\text{SE\\_list\\_SI}$ 是通过分块平均得到的相应标准误差列表（单位为 $\\mathrm{m}^2/\\mathrm{s}$）。$\\text{converged\\_boolean}$ 必须为 true 当且仅当检测到扩散窗口并如前述确认了平台稳定性，否则为 false。$\\text{finite\\_size\\_significant\\_boolean}$ 必须为 true 当且仅当尺寸差异通过了双西格玛检验；对于单一尺寸用例，它必须为 false。\n- 您的程序应生成单行输出，其中包含三个用例结果的列表，格式为方括号内用逗号分隔的列表。例如，该行必须看起来像 $[[\\cdots],[\\cdots],[\\cdots]]$，不需要空格，也没有多余文本。\n\n本问题陈述中的所有数值常量、变量和参数均以指定单位给出。在给定上述种子的情况下，您的程序必须是确定性的，并且不得需要任何用户输入或外部数据。科学场景是具有示踪扩散的统计各向同性三维固体；合成生成器模拟测量轨迹仅用于算法验证目的。您实现的算法必须适用于满足这些条件的实际分子动力学轨迹的通用情况。",
            "solution": "任务是开发一个自包含程序，用于根据三维固体在周期性边界条件下的原子轨迹数据估算示踪扩散系数$D_{\\text{tr}}$。该分析必须基于基本原理构建，包括轨迹展开、均方位移（MSD）计算、扩散区域的识别、通过加权线性回归估算$D_{\\text{tr}}$，以及对收斂性、统计不确定性和有限尺寸效应的稳健评估。\n\n该分析的基础是在各向同性$d$维系统中的扩散的 Einstein 关系式，它将示踪扩散系数定义为均方位移的长时间极限：\n$$D_{\\text{tr}} \\equiv \\lim_{t \\to \\infty} \\frac{\\langle \\Delta r^2(t) \\rangle}{2 d t}$$\n对于三维系统，$d=3$。项 $\\langle \\Delta r^2(t) \\rangle$ 表示示踪粒子在延迟时间 $t$ 内的系綜平均方位移。\n\n以下各节详细介绍了分析的每个组成部分的逐步推导和算法设计。\n\n**1. 轨迹合成与预处理**\n\n为验证算法，我们首先合成模拟无偏扩散的轨迹。构建一个随机行走模型，其中每个粒子的位置$\\mathbf{r}(t)$根据$\\mathbf{r}(t+\\Delta t) = \\mathbf{r}(t) + \\delta\\mathbf{r}$演化，其中$\\delta\\mathbf{r}$是一个随机位移向量。对于布朗运动，$\\delta\\mathbf{r}$的分量从零均值的高斯分布中抽取。每个分量的方差$\\sigma^2$与真实扩散系数$D$和时间步长$\\Delta t$相关，关系为$\\sigma^2 = 2 D \\Delta t$。初始位置在长度为$L$的立方模拟盒子内随机分布。然后使用模运算符将所得位置包裹回主模拟盒子$[0, L)^3$中，以模拟从具有周期性边界条件（PBC）的分子动力学模拟中获得的数据。\n\n原子模拟通常将粒子坐标存储在包裹于主模拟盒子中的形式。为了正确计算随时间变化的总位移，必须将这些包裹坐标展开。这是通过逐帧处理轨迹来实现的。设$\\mathbf{r}_{\\text{wrap}}(t)$为时间$t$时的包裹位置。连续帧之间的位移是$\\Delta\\mathbf{r}(t) = \\mathbf{r}_{\\text{wrap}}(t+\\Delta t) - \\mathbf{r}_{\\text{wrap}}(t)$。由于PBC，这个计算出的位移可能不是真实的最短路径位移。我们对$\\Delta\\mathbf{r}(t)$的每个分量应用最小镜像约定：\n$$(\\Delta r_i)_{\\text{mic}} = \\Delta r_i - L \\cdot \\text{round}\\left(\\frac{\\Delta r_i}{L}\\right)$$\n其中 $i \\in \\{x, y, z\\}$，$\\text{round}(\\cdot)$表示四舍五入到最近的整数。这确保每个位移分量都位于区间$[-L/2, L/2)$内。然后通过累加这些校正后的位移来重构展开轨迹$\\mathbf{r}_{\\text{unwrap}}(t)$：\n$$\\mathbf{r}_{\\text{unwrap}}(0) = \\mathbf{r}_{\\text{wrap}}(0)$$\n$$\\mathbf{r}_{\\text{unwrap}}(t+\\Delta t) = \\mathbf{r}_{\\text{unwrap}}(t) + (\\Delta\\mathbf{r}(t))_{\\text{mic}}$$\n\n**2. 均方位移（MSD）计算**\n\n对于一个有$N$个时间帧、间隔为$\\Delta t$的离散轨迹，延迟时间为$t = \\tau \\Delta t$（其中$\\tau$是延迟指数）的时间平均MSD是通过对所有可能的时间原点$t_0 = i \\Delta t$和所有$N_{\\text{tr}}$个示踪粒子进行平均来计算的：\n$$\\operatorname{MSD}(\\tau) = \\frac{1}{N_{\\text{tr}}(N-\\tau)}\\sum_{p=1}^{N_{\\text{tr}}}\\sum_{i=0}^{N-\\tau-1} \\left\\| \\mathbf{r}_p(i+\\tau) - \\mathbf{r}_p(i)\\right\\|^2$$\n其中$\\mathbf{r}_p(i)$是粒子$p$在第$i$帧的展开位置。直接求和的计算成本很高，其复杂度为$\\mathcal{O}(N^2)$。\n\n为了提高效率，我们使用一种基于快速傅里葉变换（FFT）的算法。单个粒子的方位移总和可以展开为：\n$$\\sum_{i=0}^{N-\\tau-1}\\left\\| \\mathbf{r}(i+\\tau)-\\mathbf{r}(i)\\right\\|^2 = \\sum_{i=0}^{N-\\tau-1}\\left( \\|\\mathbf{r}(i+\\tau)\\|^2 + \\|\\mathbf{r}(i)\\|^2 - 2\\mathbf{r}(i)\\cdot\\mathbf{r}(i+\\tau) \\right)$$\n第三项是位置向量的时间自相关。时间序列的自相关可以通过Wiener-Khinchin定理高效计算，该定理将其与功率谱密度联系起来，而功率谱密度可以使用FFT获得。整个轨迹（对所有粒子求和）的计算过程如下：\n1. 对于每个粒子$p$和每个空间坐标$k \\in \\{x, y, z\\}$，使用`numpy.correlate`计算坐标序列$r_{p,k}(i)$的时间自相关。该函数对长序列自动使用基于FFT的方法。\n2. 将这些自相关在所有粒子和所有三个坐标上求和，得到总位置自相关函数，$C_{\\text{tot}}(\\tau) = \\sum_{p,k} \\sum_{i=0}^{N-\\tau-1} r_{p,k}(i) r_{p,k}(i+\\tau)$。\n3. 计算每个时间步长的范数平方和，$S_2(i) = \\sum_{p=1}^{N_{\\text{tr}}} \\|\\mathbf{r}_p(i)\\|^2$。\n4. 恒等式中剩下的两个和是$S_2(i)$的片段之和。通过预先计算$S_2(i)$的累积和，可以对所有$\\tau$高效地计算这些和。\n5. 组合这些项，得到每个延迟$\\tau$的总方位移。\n6. 最后，除以$N_{\\text{tr}}(N-\\tau)$得到最终的$\\operatorname{MSD}(\\tau)$。\n\n**3. 扩散系数的估算**\n\n在扩散区域，MSD随时间线性增长：$\\langle \\Delta r^2(t) \\rangle \\approx 2dD_{\\text{tr}}t + C$。这意味着MSD相对于时间的对数导数趋近于1：\n$$\\gamma(t) \\equiv \\frac{\\mathrm{d} \\ln \\langle \\Delta r^2(t) \\rangle}{\\mathrm{d} \\ln t} \\approx 1$$\n我们通过定位$\\gamma(t)$接近于$1$的稳定平台区来确定一个合适的线性拟合窗口$[t_{\\min}, t_{\\max}]$。在数值上，$\\gamma(t)$是使用对数-对数尺度上的中心有限差分从离散的$\\operatorname{MSD}(\\tau)$数据估算出来的。如果$\\gamma(t)$在一个持续的延迟步数内保持在容差范围内（例如$[0.95, 1.05]$），则该窗口被认为是有效的。为确保统计可靠性，$t_{\\max}$被限制为总模拟时间的一部分，通常为$t_{\\max} \\leq N\\Delta t/3$。如果没有找到这样的稳定窗口，则使用包含可用延迟时间的后半部分的保守窗口，并升起一个不收敛的标志。\n\n在确定的窗口$[t_{\\min}, t_{\\max}]$内，使用加权线性回归估算$\\operatorname{MSD}(t)$对$t$的斜率。每个数据点$(\\tau\\Delta t, \\operatorname{MSD}(\\tau))$的权重设置为$w_{\\tau} = N-\\tau$，这是对该延迟时间的MSD有贡献的独立时间原点的数量。这给予了较短延迟时间的数据更多的重要性，因为它们在统计上更稳健。加权斜率$A$的公式为：\n$$A = \\frac{ S_w S_{wxy} - S_{wx} S_{wy} }{ S_w S_{wxx} - (S_{wx})^2 }$$\n其中$S_w = \\sum w_i$，$S_{wx} = \\sum w_i x_i$，$S_{wy} = \\sum w_i y_i$，$S_{wxy} = \\sum w_i x_i y_i$，$S_{wxx} = \\sum w_i x_i^2$，其中$x_i = \\tau_i \\Delta t$，$y_i=\\operatorname{MSD}(\\tau_i)$。\n然后扩散系数为$D_{\\text{tr}} = A / (2d) = A/6$。\n\n**4. 收敛性、不确定性和有限尺寸效应**\n\n稳健的分析需要评估估计的质量。\n*   **收敛性**：通过比较来自轨迹不同部分的估计值来检查收敛性。我们计算两条独立的MSD曲线：一条使用来自模拟前四分之一的时间原点（$t \\in [0, N/4)$），另一条来自第三个四分之一的时间原点（$t \\in [N/2, 3N/4)$）。然后我们对两者进行$D_{\\text{tr}}$拟合。如果两个估计值之间的相对差异在设定的容差（例如$20\\%$）之内，并且为整个轨迹找到了一个清晰的扩散窗口，则认为模拟已收敛。\n*   **不确定性**：使用分块平均法估算统计不确定性。总时间序列被划分为$B$个连续、不重叠的块。对每个块重复整个分析（MSD计算和加权回归），得到一组$B$个独立的估计值$\\{D_{\\text{tr},b}\\}_{b=1}^B$。每个块的拟合窗口根据块的较短持续时间从全局窗口调整而来。然后计算平均标准误差（SEM）如下：\n$$\\text{SEM} = \\frac{s_D}{\\sqrt{B}}, \\quad \\text{where } s_D = \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B} (D_{\\text{tr},b} - \\bar{D}_{\\text{tr}})^2}$$\n其中$\\bar{D}_{\\text{tr}}$是块估计值的平均值。\n*   **有限尺寸效应**：在周期性模拟中，粒子的運動可能会受到其自身周期性镜像相互作用的人为影响，导致扩散系数与系统尺寸相关。通过比较不同盒子长度$L_1$和$L_2$的模拟结果来评估这种效应。设相应的估计值为$(D_1, \\text{SEM}_1)$和$(D_2, \\text{SEM}_2)$。如果扩散系数的差异超过差异的组合标准误差的两倍，则认为有限尺寸效应具有统计显著性：\n$$|\\,D_1 - D_2\\,| > 2 \\sqrt{\\text{SEM}_1^2 + \\text{SEM}_2^2}$$\n\n**5. 单位转换**\n所有中间计算都使用原生模拟单位（位置单位为埃，时间单位为皮秒），得到的$D_{\\text{tr}}$单位为$\\mathrm{\\AA}^2/\\mathrm{ps}$。最终结果必须以国际单位制（SI）单位（$\\mathrm{m}^2/\\mathrm{s}$）报告。转换使用提供的因子进行：\n$$1\\,\\frac{\\mathrm{\\AA}^2}{\\mathrm{ps}} = 10^{-10 \\times 2} \\, \\frac{\\mathrm{m}^2}{10^{-12} \\, \\mathrm{s}} = 10^{-20} \\cdot 10^{12} \\, \\frac{\\mathrm{m}^2}{\\mathrm{s}} = 10^{-8} \\, \\frac{\\mathrm{m}^2}{\\mathrm{s}}$$\n所有报告的$D_{\\text{tr}}$及其标准误差值都乘以$10^{-8}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import fft, ifft\n\ndef solve():\n    \"\"\"\n    Main solver function that runs all test cases and prints the final result.\n    \"\"\"\n\n    # Define test cases from the problem statement\n    test_cases = [\n        # Case 1: Well-sampled, single size\n        {\n            \"D_true\": 1.0e-3, \"dt\": 0.005, \"n_steps\": 20000, \"n_tracers\": 50,\n            \"L_list\": [12.0], \"seed\": 42, \"n_blocks\": 5\n        },\n        # Case 2: Poor sampling, single size\n        {\n            \"D_true\": 1.0e-3, \"dt\": 0.005, \"n_steps\": 1000, \"n_tracers\": 5,\n            \"L_list\": [12.0], \"seed\": 123, \"n_blocks\": 4\n        },\n        # Case 3: Finite-size assessment\n        {\n            \"D_true\": 1.0e-3, \"dt\": 0.005, \"n_steps\": 15000, \"n_tracers\": 30,\n            \"L_list\": [8.0, 16.0], \"seed\": 7, \"n_blocks\": 5\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        D_list_SI = []\n        SE_list_SI = []\n        converged_list = []\n        \n        # Store results for finite-size check\n        D_estimates_for_fse = []\n        SE_estimates_for_fse = []\n\n        for L in case[\"L_list\"]:\n            # Generate wrapped trajectory\n            rng = np.random.default_rng(case[\"seed\"])\n            wrapped_coords = _generate_trajectory(\n                D=case[\"D_true\"], dt=case[\"dt\"], n_steps=case[\"n_steps\"],\n                n_tracers=case[\"n_tracers\"], L=L, rng=rng\n            )\n\n            # Perform full analysis\n            D_tr, SE, converged = _full_analysis(\n                wrapped_coords, dt=case[\"dt\"], L=L, n_blocks=case[\"n_blocks\"]\n            )\n            \n            # Convert to SI units\n            CONV_FACTOR = 1e-8\n            D_list_SI.append(D_tr * CONV_FACTOR)\n            SE_list_SI.append(SE * CONV_FACTOR)\n            converged_list.append(converged)\n            \n            D_estimates_for_fse.append(D_tr)\n            SE_estimates_for_fse.append(SE)\n\n        # Final convergence status is 'and' over all sizes\n        overall_converged = all(converged_list)\n        \n        # Assess finite-size effects\n        finite_size_significant = False\n        if len(case[\"L_list\"]) > 1:\n            D1, D2 = D_estimates_for_fse[0], D_estimates_for_fse[1]\n            SE1, SE2 = SE_estimates_for_fse[0], SE_estimates_for_fse[1]\n            if SE1 > 0 and SE2 > 0:\n                combined_se = np.sqrt(SE1**2 + SE2**2)\n                if abs(D1 - D2) > 2 * combined_se:\n                    finite_size_significant = True\n\n        all_results.append(\n            f\"[{D_list_SI},{overall_converged},{finite_size_significant},{SE_list_SI}]\"\n        )\n    \n    # Format and print the final output\n    # The string representation of list adds spaces, remove them.\n    final_output_str = f\"[{','.join(all_results)}]\"\n    final_output_str = final_output_str.replace(\" \", \"\")\n    print(final_output_str)\n\ndef _generate_trajectory(D, dt, n_steps, n_tracers, L, rng):\n    \"\"\"Generates a wrapped 3D random walk trajectory.\"\"\"\n    # Variance per component per step\n    sigma_sq = 2 * D * dt\n    # Standard deviation\n    sigma = np.sqrt(sigma_sq)\n    \n    # Initial positions uniformly in [0, L)\n    positions = rng.uniform(0, L, size=(n_tracers, n_steps, 3))\n    \n    # Generate random steps\n    displacements = rng.normal(0, sigma, size=(n_tracers, n_steps - 1, 3))\n    \n    # Accumulate positions (unwrapped)\n    unwrapped_positions = np.cumsum(np.concatenate(\n        (positions[:, 0:1, :], displacements), axis=1), axis=1)\n\n    # Wrap into the box [0, L)\n    return unwrapped_positions % L\n\ndef _unwrap_trajectory(wrapped_coords, L):\n    \"\"\"Reconstructs the unwrapped trajectory using the minimum image convention.\"\"\"\n    n_tracers, n_steps, _ = wrapped_coords.shape\n    # Calculate frame-to-frame displacements\n    displacements = np.diff(wrapped_coords, axis=1)\n    \n    # Apply minimum image convention\n    displacements = displacements - L * np.round(displacements / L)\n    \n    # Reconstruct unwrapped trajectory by accumulating displacements\n    unwrapped_coords = np.zeros_like(wrapped_coords)\n    unwrapped_coords[:, 0, :] = wrapped_coords[:, 0, :]\n    unwrapped_coords[:, 1:, :] = wrapped_coords[:, 0:1, :] + np.cumsum(displacements, axis=1)\n    \n    return unwrapped_coords\n\ndef _calculate_msd_fft(unwrapped_coords, max_lag_frac=1/3):\n    \"\"\"Computes MSD using an FFT-based correlation algorithm.\"\"\"\n    n_tracers, n_steps, _ = unwrapped_coords.shape\n    max_lag = int(n_steps * max_lag_frac)\n    if max_lag  2: return np.array([]), np.array([])\n    \n    # Calculate sum of squared norms at each time step\n    sq_norms = np.sum(unwrapped_coords**2, axis=2)  # Shape: (n_tracers, n_steps)\n    total_sq_norm_t = np.sum(sq_norms, axis=0) # Shape: (n_steps)\n    \n    # FFT-based autocorrelation for each tracer and coordinate\n    fft_len = 2 * n_steps\n    total_corr = np.zeros(n_steps)\n    \n    for p in range(n_tracers):\n        for k in range(3):\n            vec = unwrapped_coords[p, :, k]\n            vec_fft = fft(vec, n=fft_len)\n            acorr = ifft(vec_fft * np.conj(vec_fft)).real\n            total_corr += acorr[:n_steps]\n            \n    # Calculate sum terms for all lags\n    msd = np.zeros(max_lag)\n    # MSD at tau=0 is 0\n    msd[0] = 0.0\n\n    # Using the convolution identity\n    # Sum of squares of positions for each lag τ\n    Q = 2 * np.sum(total_sq_norm_t)\n    S1 = np.zeros(max_lag)\n    \n    for tau in range(1, max_lag):\n        Q -= total_sq_norm_t[tau - 1] + total_sq_norm_t[n_steps - tau]\n        S1[tau] = Q\n        \n        sum_sq_disp = S1[tau] - 2 * total_corr[tau]\n        \n        # Normalize\n        num_samples = n_tracers * (n_steps - tau)\n        if num_samples > 0:\n            msd[tau] = sum_sq_disp / num_samples\n\n    lags = np.arange(max_lag)\n    return lags, msd\n\ndef _find_diffusive_window(lags, msd, dt):\n    \"\"\"Identifies the linear (diffusive) regime of the MSD curve.\"\"\"\n    if len(lags)  5:\n        return 2, len(lags) - 1, False\n\n    t = lags * dt\n    \n    # Avoid log(0)\n    valid_indices = np.where((msd > 0)  (t > 0))[0]\n    if len(valid_indices)  3:\n        # Fallback to a conservative window\n        start_idx = max(2, len(lags) // 2)\n        end_idx = len(lags)-1\n        return start_idx, end_idx, False\n\n    log_t = np.log(t[valid_indices])\n    log_msd = np.log(msd[valid_indices])\n    \n    # Calculate log-derivative gamma using central differences\n    gamma = np.zeros_like(log_t)\n    gamma[1:-1] = (log_msd[2:] - log_msd[:-2]) / (log_t[2:] - log_t[:-2])\n    gamma[0] = (log_msd[1] - log_msd[0]) / (log_t[1] - log_t[0])\n    gamma[-1] = (log_msd[-1] - log_msd[-2]) / (log_t[-1] - log_t[-2])\n    \n    # Search for a stable plateau where gamma is ~1\n    TOL = 0.05\n    SUSTAINED_RUN = 10\n    \n    in_plateau = (gamma > 1 - TOL)  (gamma  1 + TOL)\n    \n    best_start = -1\n    for i in range(len(in_plateau) - SUSTAINED_RUN + 1):\n        if np.all(in_plateau[i:i + SUSTAINED_RUN]):\n            best_start = valid_indices[i]\n            break\n\n    if best_start != -1:\n        # Find end of plateau\n        end_idx = best_start\n        while end_idx  len(valid_indices) and in_plateau[valid_indices.searchsorted(end_idx)]:\n            end_idx += 1\n        \n        t_min_idx = best_start\n        # Make sure window is not too small\n        if end_idx - t_min_idx  5:\n            t_max_idx = t_min_idx + 5\n        else:\n            t_max_idx = end_idx -1\n        return t_min_idx, t_max_idx, True\n    else:\n        # Fallback to a conservative window if no plateau found\n        start_idx = max(2, len(lags) // 2)\n        end_idx = len(lags) -1\n        return start_idx, end_idx, False\n\ndef _fit_diffusion_coefficient(lags, msd, dt, n_steps, fit_window):\n    \"\"\"Performs weighted linear regression on MSD vs. time.\"\"\"\n    start_idx, end_idx = fit_window\n    if start_idx >= end_idx or end_idx >= len(lags):\n        return 0.0\n\n    fit_lags = lags[start_idx:end_idx+1]\n    fit_msd = msd[start_idx:end_idx+1]\n    fit_t = fit_lags * dt\n    \n    # Weights are the number of samples for each lag\n    weights = n_steps - fit_lags\n    \n    w, x, y = weights, fit_t, fit_msd\n    \n    S_w = np.sum(w)\n    S_wx = np.sum(w * x)\n    S_wy = np.sum(w * y)\n    S_wxx = np.sum(w * x**2)\n    S_wxy = np.sum(w * x * y)\n    \n    denominator = S_w * S_wxx - S_wx**2\n    if abs(denominator)  1e-12:\n        return 0.0\n        \n    slope = (S_w * S_wxy - S_wx * S_wy) / denominator\n    \n    # D = slope / (2 * d), where d=3\n    D = slope / 6.0\n    return D\n\ndef _full_analysis(wrapped_coords, dt, L, n_blocks):\n    \"\"\"Performs the complete analysis pipeline for a single trajectory.\"\"\"\n    n_tracers, n_steps, _ = wrapped_coords.shape\n    \n    unwrapped_coords = _unwrap_trajectory(wrapped_coords, L)\n    \n    # ---- 1. Full trajectory analysis ----\n    lags, msd = _calculate_msd_fft(unwrapped_coords)\n    if len(lags) == 0:\n        return 0.0, 0.0, False\n        \n    t_min_idx, t_max_idx, window_found = _find_diffusive_window(lags, msd, dt)\n    \n    D_full = _fit_diffusion_coefficient(lags, msd, dt, n_steps, (t_min_idx, t_max_idx))\n    \n    # ---- 2. Convergence check ----\n    converged = False\n    if window_found:\n        # We need to construct new MSDs limited by time origin\n        # Simple split is easier: compute D from first half and second half runs\n        mid_pt = n_steps // 2\n        \n        # First half\n        coords1 = _unwrap_trajectory(wrapped_coords[:, :mid_pt, :], L)\n        lags1, msd1 = _calculate_msd_fft(coords1)\n        if len(lags1) > 0:\n            win1_min, win1_max, _ = _find_diffusive_window(lags1, msd1, dt)\n            D1 = _fit_diffusion_coefficient(lags1, msd1, dt, len(coords1[0]), (win1_min, win1_max))\n        else:\n            D1 = 0\n        \n        # Second half\n        coords2 = _unwrap_trajectory(wrapped_coords[:, mid_pt:, :], L)\n        lags2, msd2 = _calculate_msd_fft(coords2)\n        if len(lags2) > 0:\n            win2_min, win2_max, _ = _find_diffusive_window(lags2, msd2, dt)\n            D2 = _fit_diffusion_coefficient(lags2, msd2, dt, len(coords2[0]), (win2_min, win2_max))\n        else:\n            D2 = 0\n            \n        if D1 > 1e-9 and D2 > 1e-9:\n            if abs(D1 - D2) / max(D1, D2) = 0.20:\n                converged = True\n\n    # ---- 3. Block averaging for uncertainty ----\n    block_len = n_steps // n_blocks\n    D_blocks = []\n    \n    for i in range(n_blocks):\n        block_coords_wrapped = wrapped_coords[:, i * block_len:(i + 1) * block_len, :]\n        block_coords_unwrapped = _unwrap_trajectory(block_coords_wrapped, L)\n        \n        block_lags, block_msd = _calculate_msd_fft(block_coords_unwrapped)\n        if len(block_lags) == 0: continue\n\n        # Adapt fitting window to shorter block trajectory\n        block_t_max_idx = min(t_max_idx, len(block_lags) - 1)\n        block_t_min_idx = min(t_min_idx, block_t_max_idx-1)\n        \n        D_block = _fit_diffusion_coefficient(block_lags, block_msd, dt, block_len, (block_t_min_idx, block_t_max_idx))\n        if D_block > 0:\n            D_blocks.append(D_block)\n            \n    if len(D_blocks)  2:\n        SE = 0.0\n    else:\n        SE = np.std(D_blocks, ddof=1) / np.sqrt(len(D_blocks))\n        \n    return D_full, SE, converged\n\n# Execute the solver\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在周期性边界条件下进行的分子动力学模拟，其有限的模拟尺寸会引入系统性的误差，使得计算出的扩散系数依赖于模拟盒子的大小$L$。本练习  将带您深入探讨这一现象的物理根源，即由于长波长的流体动力学模式被截断而导致的$1/L$标度律。您将通过推导这一标度关系，并对一系列不同尺寸下的模拟数据进行拟合与外推，来学习如何消除有限尺寸效应，从而获得热力学极限下（即宏观材料）的真实扩散系数$D_\\infty$。这是确保计算结果物理可靠性的关键一步。",
            "id": "3444794",
            "problem": "您的任务是形式化并验证使用三维周期性边界条件进行的固体分子动力学（MD）模拟中计算出的原子扩散系数的前导阶有限尺寸标度。您的任务是，从基本定义出发，推导出一个可以进行数值检验的尺寸依赖关系，然后实现一个算法，该算法使用多个超胞尺寸外推出热力学极限。\n\n基本依据：\n- 示踪剂在 $d$ 维空间中的自扩散系数 $D$ 由爱因斯坦关系 $D = \\lim_{t \\to \\infty} \\frac{1}{2 d} \\frac{d}{dt} \\langle \\lVert \\mathbf{r}(t) - \\mathbf{r}(0) \\rVert^2 \\rangle$ 定义，并等效地由格林-久保关系 $D = \\frac{1}{d} \\int_0^\\infty \\langle \\mathbf{v}(0) \\cdot \\mathbf{v}(t) \\rangle \\, dt$ 定义，其中 $\\mathbf{r}(t)$ 是示踪剂的位置，$\\mathbf{v}(t)$ 是其速度。\n- 在三维空间中，一个线性尺寸为 $L$ 的有限周期性超胞中，长波激发被离散化，其波矢为 $\\mathbf{k} = \\frac{2 \\pi}{L} \\mathbf{n}$，其中 $\\mathbf{n} \\in \\mathbb{Z}^3$，产生一个最小非零波数大小 $k_{\\min} = \\frac{2 \\pi}{L}$。这种离散化截断了由 $|\\mathbf{k}|  k_{\\min}$ 的模式引起的时间相关性贡献。\n\n问题要求：\n- 使用格林-久保形式主义和离散长波模式效应，论证由于周期性边界而缺失的长波贡献导致扩散系数存在一个依赖于 $L$ 的前导阶有限尺寸修正。您的推导必须仅使用上述基本关系、固体中长波声学模的标准性质以及对 $k=0$ 附近的 $k$ 空间积分进行的量纲分析。您不能引入任何关于尺寸依赖性的特设公式；相反，您必须从第一性原理推导出前导阶项的形式，并指明关于 $L$ 的渐近展开中的次前导阶项。\n- 基于您推导出的前导阶依赖关系，设计一个稳健的外推策略，以从多个有限尺寸测量值 $D(L_i)$ 估计无限尺寸扩散系数 $D_\\infty$。您的策略必须处理由于长波模式离散化可能存在的更高阶污染项。\n- 在一个程序中实现您的策略，该程序：\n  1. 拟合前导阶模型，以从列表对 $\\{(L_i, D(L_i))\\}$ 中估计 $D_\\infty$。\n  2. 应用与您的模型一致的后验校正，以从 $D(L_i)$ 中移除前导有限尺寸趋势，并量化校正后的值是否在指定容差内坍缩为一个与尺寸无关的常数。\n  3. 为每个提供的数据集报告估计的 $D_\\infty$ 和一个布尔标志，指示后验校正数据坍缩是否令人满意。\n\n物理和数值细节：\n- 长度 $L$ 必须以米为单位处理，扩散系数 $D$ 必须以平方米/秒为单位处理。您的程序必须以 $\\mathrm{m^2/s}$ 为单位输出 $D_\\infty$，并四舍五入到 $6$ 位有效数字。\n- 在量化移除前导阶趋势后的坍缩时，计算定义为 $c_v = \\sigma / \\mu$ 的变异系数，其中 $\\sigma$ 是校正后 $D$ 值的样本标准差，$\\mu$ 是它们的样本均值。如果 $c_v \\le 0.05$，则将坍缩标志设置为 true，否则设置为 false。\n\n测试套件：\n使用以下四个数据集。每个数据集包含超胞尺寸 $L$（单位：米）和测量的扩散系数 $D(L)$（单位：$\\mathrm{m^2/s}$）。这些数据与高温固态扩散过程的物理上合理的数量级一致，并包括有和没有高阶污染项的情况。\n\n- 数据集 1 (理想的前导阶行为，多个尺寸):\n  - $L = [2.0 \\times 10^{-9},\\, 2.5 \\times 10^{-9},\\, 3.0 \\times 10^{-9},\\, 4.5 \\times 10^{-9},\\, 6.0 \\times 10^{-9}]$\n  - $D(L) = [2.0 \\times 10^{-9},\\, 2.1 \\times 10^{-9},\\, 2.1666666667 \\times 10^{-9},\\, 2.2777777778 \\times 10^{-9},\\, 2.3333333333 \\times 10^{-9}]$\n- 数据集 2 (有次阶污染的前导阶行为):\n  - $L = [2.4 \\times 10^{-9},\\, 3.0 \\times 10^{-9},\\, 4.0 \\times 10^{-9},\\, 6.0 \\times 10^{-9},\\, 8.0 \\times 10^{-9},\\, 12.0 \\times 10^{-9}]$\n  - $D(L) = [4.1008 \\times 10^{-10},\\, 4.5555555558 \\times 10^{-10},\\, 5.09375 \\times 10^{-10},\\, 5.69444444442 \\times 10^{-10},\\, 6.01171875 \\times 10^{-10},\\, 6.33680555582 \\times 10^{-10}]$\n- 数据集 3 (两点边界情况):\n  - $L = [3.0 \\times 10^{-9},\\, 9.0 \\times 10^{-9}]$\n  - $D(L) = [7.0 \\times 10^{-10},\\, 1.03333333333 \\times 10^{-9}]$\n- 数据集 4 (可忽略的有限尺寸效应):\n  - $L = [2.0 \\times 10^{-9},\\, 5.0 \\times 10^{-9},\\, 10.0 \\times 10^{-9}]$\n  - $D(L) = [4.0 \\times 10^{-10},\\, 4.0 \\times 10^{-10},\\, 4.0 \\times 10^{-10}]$\n\n计算任务：\n- 对于每个数据集，使用普通最小二乘法对 $D(L)$ 与 $x = 1/L$ 进行线性拟合，以估计您推导的模型中的截距 $D_\\infty$ 和前导系数 $a$。然后，构造校正值 $D_{\\mathrm{corr}}(L_i) = D(L_i) - a / L_i$，并为 $\\{ D_{\\mathrm{corr}}(L_i) \\}$ 计算 $c_v = \\sigma / \\mu$。\n- 您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素本身应为一个双元素列表：$[D_\\infty, \\text{collapse\\_ok}]$，其中 $D_\\infty$ 以 $\\mathrm{m^2/s}$ 为单位四舍五入到 $6$ 位有效数字，$\\text{collapse\\_ok}$ 是一个布尔值。例如：\"[[1.23456e-09,True],[7.89012e-10,False],...]\"。\n\n您的推导必须建立从格林-久保关系通过长波模式离散化效应到 $L$ 中前导阶标度的逻辑链，并且您的算法必须与该推导一致。数值部分必须使用上面列出的确切数据集，并遵守指定的单位和四舍五入约定。最终输出必须严格遵守上述格式，除了必要的标点符号外，不得有额外的文本或空格。",
            "solution": "该问题被评估为**有效**。它在科学上基于统计力学和计算材料科学的原理，问题设定清晰，目标明确，数据充分，没有歧义或矛盾。因此，我们可以继续提供完整解答。\n\n### 第1部分：有限尺寸标度定律的推导\n\n任务是推导自扩散系数 $D$ 对立方周期性模拟盒子线性尺寸 $L$ 的前导阶依赖关系。推导始于 $d=3$ 维空间中扩散系数的格林-久保关系：\n$$ D = \\frac{1}{3} \\int_0^\\infty \\langle \\mathbf{v}(0) \\cdot \\mathbf{v}(t) \\rangle \\, dt $$\n其中 $\\langle \\mathbf{v}(0) \\cdot \\mathbf{v}(t) \\rangle$ 是速度自相关函数（VACF）。在尺寸为 $L$ 的有限模拟盒子中测量的扩散系数，记为 $D(L)$，与热力学极限下的值 $D_\\infty = \\lim_{L\\to\\infty} D(L)$ 不同。这个差异 $\\Delta D(L) = D(L) - D_\\infty$ 构成了有限尺寸误差。\n\n此误差的根源在于模拟盒子的人为周期性。一个扩散的粒子会与其自身的周期性镜像相互作用，这种效应由周围的介质（固体晶格）介导。在长程和长时间尺度上，这些相互作用可以由连续介质流体动力学精确描述。主要的修正是由粒子运动与介质集体剪切模的耦合产生的。\n\n已建立的流体动力学长时尾理论预测，对于一个在三维介质中的粒子，其VACF在长时间下会以一个特征幂律衰减：\n$$ \\langle \\mathbf{v}(0) \\cdot \\mathbf{v}(t) \\rangle \\propto -t^{-3/2} $$\n负号反映了由移动粒子产生的回流涡所引起的速度反相关性。这种相关性的持续存在是VACF“长时尾”的原因。\n\n在体积为 $V=L^3$ 的有限周期性系统中，连续的波矢谱 $\\mathbf{k}$ 被一个离散集合 $\\mathbf{k} = \\frac{2\\pi}{L}\\mathbf{n}$（其中 $\\mathbf{n} \\in \\mathbb{Z}^3$）所取代。这种离散化施加了一个长波截断，使得可访问的最小非零波数约为 $k_{\\min} \\approx \\frac{2\\pi}{L}$。波长长于 $L$ 的流体动力学模式不被支持。\n\n流体动力学剪切模的衰减是扩散性的，其弛豫时间 $\\tau_k$ 与 $k^{-2}$ 成正比，即 $\\tau_k \\propto k^{-2}$。在 $k_{\\min}$ 处的截断为系统引入了一个最大弛豫时间 $\\tau_{\\max} \\propto k_{\\min}^{-2} \\propto L^2$。这意味着VACF的积分在时间 $t \\gtrsim \\tau_{\\max}$ 时被有效截断，因为超过此时标的相关性没有被正确捕捉。因此，扩散系数的误差 $\\Delta D(L)$ 主要由积分尾部缺失的贡献决定：\n$$ \\Delta D(L) = D(L) - D_\\infty \\propto \\int_{\\tau_{\\max}}^{\\infty} (-t^{-3/2}) \\, dt $$\n计算该积分得到：\n$$ \\int_{L^2}^{\\infty} (-t^{-3/2}) \\, dt = -[-2t^{-1/2}]_{L^2}^{\\infty} = -(0 - (-2(L^2)^{-1/2})) = -2L^{-1} $$\n这表明，扩散系数的前导阶有限尺寸修正与模拟盒子线性尺寸成反比：\n$$ \\Delta D(L) \\propto -\\frac{1}{L} $$\n因此，我们可以将测量的扩散系数 $D(L)$ 表示为 $1/L$ 幂次的渐近展开：\n$$ D(L) = D_\\infty + \\frac{a_1}{L} + O(L^{-2}) $$\n系数 $a_1$ 是负的。基于求解带周期性边界条件的斯托克斯方程的更详细推导，可以得到 $a_1$ 的一个显式表达式：\n$$ a_1 = - \\frac{k_B T \\xi}{6 \\pi \\eta} $$\n其中 $k_B$ 是玻尔兹曼常数，$T$ 是温度，$\\eta$ 是介质的剪切粘度，$\\xi$ 是一个无量纲常数，它取决于周期性盒子的几何形状（对于立方盒子，$\\xi \\approx 2.837297$）。由于右侧所有量均为正，因此 $a_1$ 为负。这意味着 $D(L)  D_\\infty$，并且随着盒子尺寸的增大，测量的扩散系数会向其无限系统值增加。\n\n对于次前导阶项，对立方晶格的对称性考虑导致 $O(L^{-2})$ 项消失。周期性流体动力学张量展开中的下一项出现在 $L^{-3}$ 阶。因此，一个更完整的展开是：\n$$ D(L) = D_\\infty + \\frac{a_1}{L} + \\frac{a_3}{L^3} + O(L^{-4}) $$\n\n### 第2部分：外推与验证策略\n\n基于推导出的前导阶模型 $D(L) \\approx D_\\infty + a_1/L$，我们可以设计一个稳健的外推策略。该模型描述了测量的扩散系数 $D(L)$ 与盒子尺寸倒数 $1/L$ 之间的线性关系。\n\n给定一组测量数据 $\\{(L_i, D(L_i))\\}$，策略如下：\n1.  **线性化**：通过定义 $x_i = 1/L_i$ 和 $y_i = D(L_i)$，将数据转换到线性坐标系中。模型变为 $y_i \\approx D_\\infty + a_1 x_i$。\n2.  **线性回归**：对数据点 $(x_i, y_i)$ 执行普通最小二乘法（OLS）线性拟合。这确定了最佳拟合直线 $y = a x + b$。\n3.  **外推**：拟合的参数直接对应于感兴趣的物理量。$y$轴截距（$x \\to 0$，对应于 $L \\to \\infty$）是无限尺寸扩散系数的估计值，即 $D_\\infty = b$。拟合的斜率是前导阶系数的估计值，即 $a_1 = a$。\n4.  **后验校正与验证**：为了评估线性模型的质量，我们可以从原始数据中移除拟合的前导阶趋势。校正后的扩散系数计算如下：\n    $$ D_{\\mathrm{corr}}(L_i) = D(L_i) - \\frac{a}{L_i} $$\n    如果 $1/L$ 标度是唯一显著的有限尺寸效应，那么校正值集合 $\\{D_{\\mathrm{corr}}(L_i)\\}$ 应该坍缩为一个常数值，约等于估计的 $D_\\infty$。显著的高阶项（如 $a_3/L^3$ 项）或随机噪声的存在将导致校正值表现出残余变化。\n5.  **坍缩量化**：坍缩程度使用校正数据 $\\{D_{\\mathrm{corr}}(L_i)\\}$ 的变异系数（$c_v$）进行量化：\n    $$ c_v = \\frac{\\sigma}{\\mu} $$\n    其中 $\\mu$ 是校正值的样本均值，$\\sigma$ 是样本标准差。一个小的 $c_v$ 表示良好的坍缩，并支持线性模型对给定数据的有效性。问题指定了一个阈值 $c_v \\le 0.05$ 来标记坍缩为满意。\n\n此程序提供了一种系统性的方法，用于外推到热力学极限，并定量评估观察到的有限尺寸效应是否能被前导阶流体动力学修正很好地描述。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Validates and solves the problem of finite-size scaling of diffusion coefficients.\n    \n    The function processes four datasets of diffusion coefficients D(L) measured\n    in simulations with periodic boundary conditions of size L. It derives the\n    infinite-size diffusion coefficient D_inf by fitting the data to the\n    theoretical model D(L) = D_inf + a/L. It then checks the quality of\n    this linear model by calculating the coefficient of variation of the data\n    after correcting for the leading-order finite-size effect.\n    \"\"\"\n\n    # Test suite of four datasets\n    # Each dataset is a tuple of two lists: sizes L (meters) and diffusivities D(L) (m^2/s)\n    test_cases = [\n        (  # Dataset 1: Ideal leading-order behavior\n            np.array([2.0e-9, 2.5e-9, 3.0e-9, 4.5e-9, 6.0e-9]),\n            np.array([2.0e-9, 2.1e-9, 2.1666666667e-9, 2.2777777778e-9, 2.3333333333e-9])\n        ),\n        (  # Dataset 2: Leading-order plus next-order contamination\n            np.array([2.4e-9, 3.0e-9, 4.0e-9, 6.0e-9, 8.0e-9, 12.0e-9]),\n            np.array([4.1008e-10, 4.5555555558e-10, 5.09375e-10, 5.69444444442e-10, 6.01171875e-10, 6.33680555582e-10])\n        ),\n        (  # Dataset 3: Two-point boundary case\n            np.array([3.0e-9, 9.0e-9]),\n            np.array([7.0e-10, 1.03333333333e-9])\n        ),\n        (  # Dataset 4: Negligible finite-size effect\n            np.array([2.0e-9, 5.0e-9, 10.0e-9]),\n            np.array([4.0e-10, 4.0e-10, 4.0e-10])\n        )\n    ]\n\n    results = []\n    \n    for l_values, d_values in test_cases:\n        # Step 1: Linearize the data\n        # x = 1/L, y = D(L)\n        x_values = 1.0 / l_values\n\n        # Step 2: Perform ordinary least squares linear fit (degree 1 polynomial)\n        # The model is D(L) = a * (1/L) + D_inf.\n        # np.polyfit returns [slope, intercept]\n        slope, intercept = np.polyfit(x_values, d_values, 1)\n\n        d_inf = intercept\n        a_coeff = slope\n\n        # Step 3: Apply a posteriori correction\n        # D_corr(L_i) = D(L_i) - a / L_i\n        d_corr = d_values - a_coeff * x_values\n\n        # Step 4: Quantify the collapse using the coefficient of variation\n        # ddof=1 for sample standard deviation\n        if len(d_corr) > 1:\n            mean_d_corr = np.mean(d_corr)\n            std_d_corr = np.std(d_corr, ddof=1)\n            \n            # Handle case where mean is zero to avoid division by zero\n            if np.isclose(mean_d_corr, 0.0):\n                # If mean and std are both zero, data collapses perfectly to zero.\n                # If mean is zero but std is not, variation is infinite.\n                c_v = 0.0 if np.isclose(std_d_corr, 0.0) else np.inf\n            else:\n                c_v = std_d_corr / mean_d_corr\n        else: # Case with a single data point, not present in the test suite\n            c_v = 0.0\n\n        # Step 5: Determine if collapse is satisfactory\n        collapse_threshold = 0.05\n        collapse_ok = c_v = collapse_threshold\n\n        # Step 6: Format the output\n        # Round D_inf to 6 significant figures.\n        # The format specifier \".5e\" provides 1 digit before the decimal\n        # and 5 after, for a total of 6 significant figures.\n        d_inf_formatted = f\"{d_inf:.5e}\"\n\n        results.append([d_inf_formatted, collapse_ok])\n\n    # Final print statement must match the specified format string exactly.\n    formatted_results = [f\"[{res[0]},{str(res[1])}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}