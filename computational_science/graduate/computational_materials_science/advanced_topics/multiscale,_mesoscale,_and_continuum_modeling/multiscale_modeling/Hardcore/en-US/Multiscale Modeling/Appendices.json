{
    "hands_on_practices": [
        {
            "introduction": "Quantum Mechanics/Molecular Mechanics (QM/MM) methods are a cornerstone of multiscale modeling, enabling the study of chemical reactions in large biomolecular systems where quantum effects are localized. The subtractive scheme is a common and intuitive approach for combining these energy scales. This exercise  provides a practical calculation to solidify your understanding of the fundamental energy expression, emphasizing how to correctly combine energy terms to avoid double-counting and interpret the physical meaning of the resulting energy.",
            "id": "3439662",
            "problem": "A triatomic molecular system is partitioned into two regions for a Quantum Mechanics/Molecular Mechanics (QM/MM) treatment: a Quantum Mechanics (QM) region and a Molecular Mechanics (MM) environment. The goal is to obtain a consistent total energy that replaces the MM description of the QM region with a QM description while retaining the MM description of the entire system, avoiding double counting of the QM region. Consider the following energies, each computed under a distinct model:\n\n- $E_{\\mathrm{QM}}(\\mathrm{QM})=-100.0\\,\\mathrm{kcal/mol}$, the energy of the QM region computed at the Quantum Mechanics level.\n- $E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM})=-250.0\\,\\mathrm{kcal/mol}$, the energy of the entire system computed at the Molecular Mechanics level.\n- $E_{\\mathrm{MM}}(\\mathrm{QM})=-120.0\\,\\mathrm{kcal/mol}$, the energy of the QM region computed at the Molecular Mechanics level.\n\nStarting from the conceptual principle that the desired composite energy should reflect the MM description of the entire system with the MM energy of the QM region replaced by its QM energy, derive a suitable subtractive mechanical-embedding expression for the composite energy $E_{\\mathrm{sub}}$ and evaluate it numerically. Then, explain what $E_{\\mathrm{sub}}$ represents physically in the context of subtractive QM/MM embedding and what its value implies about the relative stabilization of the QM region under QM versus MM descriptions. Express the final energy in $\\mathrm{kcal/mol}$. No rounding is required.",
            "solution": "The problem is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe following data and definitions are provided:\n- The energy of the Quantum Mechanics (QM) region computed at the QM level of theory: $E_{\\mathrm{QM}}(\\mathrm{QM}) = -100.0\\,\\mathrm{kcal/mol}$.\n- The energy of the entire system (QM region + Molecular Mechanics (MM) region) computed at the MM level of theory: $E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM}) = -250.0\\,\\mathrm{kcal/mol}$.\n- The energy of the QM region computed at the MM level of theory: $E_{\\mathrm{MM}}(\\mathrm{QM}) = -120.0\\,\\mathrm{kcal/mol}$.\n- The task is to derive the subtractive mechanical-embedding expression for the composite energy $E_{\\mathrm{sub}}$, evaluate it, and interpret its physical meaning.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the required criteria.\n- **Scientifically Grounded**: The problem describes the subtractive scheme for QM/MM calculations, a cornerstone of multiscale modeling in computational chemistry. The formulation and the concept of avoiding double-counting are standard and scientifically sound.\n- **Well-Posed**: The problem provides all necessary energy terms to construct and evaluate the standard two-layer subtractive QM/MM energy. The objective is to calculate a single, uniquely defined value, $E_{\\mathrm{sub}}$, and provide a standard physical interpretation. A unique, stable, and meaningful solution exists.\n- **Objective**: The problem is expressed using precise, standard terminology from the field of computational chemistry ($E_{\\mathrm{QM}}$, $E_{\\mathrm{MM}}$, QM/MM, etc.) and is free from subjective or ambiguous language.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and objective. It is deemed **valid**. Therefore, a full solution will be provided.\n\n### Solution Derivation\nThe objective of a QM/MM calculation is to describe a chemically active region (the QM region) with high-level quantum mechanical theory while treating the rest of the system (the MM environment) with a computationally cheaper molecular mechanics force field. The subtractive scheme is one of the simplest and most common ways to combine these descriptions.\n\nThe core principle, as stated in the problem, is to start with the energy of the entire system calculated at the low level (MM) and then apply a correction. This correction replaces the inaccurate low-level description of the QM region with its accurate high-level description.\n\nLet the entire system be denoted as $\\mathrm{S} = \\mathrm{QM} + \\mathrm{MM}$.\nThe energy of the full system, as calculated by the MM force field, is given as $E_{\\mathrm{MM}}(\\mathrm{S})$, which is equivalent to $E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM})$. This term incorrectly describes the QM region.\n\nTo correct this, we must first subtract the contribution of the QM region as calculated at the MM level. This contribution is given as $E_{\\mathrm{MM}}(\\mathrm{QM})$. Removing this term from the total MM energy eliminates the incorrect description of the QM part.\n\nNext, we must add the energy of the QM region as calculated correctly at the QM level of theory. This term is given as $E_{\\mathrm{QM}}(\\mathrm{QM})$.\n\nCombining these steps yields the general expression for the subtractive QM/MM energy, $E_{\\mathrm{sub}}$:\n$$E_{\\mathrm{sub}} = E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM}) - E_{\\mathrm{MM}}(\\mathrm{QM}) + E_{\\mathrm{QM}}(\\mathrm{QM})$$\nThis expression avoids the double-counting of the QM region's energy. It represents a model where the QM region's internal energy is determined quantum mechanically, while its interaction with the MM environment, and the MM environment's internal energy, are determined classically. This specific formulation corresponds to a mechanical embedding scheme, as the coupling between the QM and MM regions is contained entirely within the $E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM})$ term and is thus described at the MM level only.\n\nNow, we substitute the given numerical values into this expression:\n- $E_{\\mathrm{QM}}(\\mathrm{QM}) = -100.0\\,\\mathrm{kcal/mol}$\n- $E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM}) = -250.0\\,\\mathrm{kcal/mol}$\n- $E_{\\mathrm{MM}}(\\mathrm{QM}) = -120.0\\,\\mathrm{kcal/mol}$\n\n$$E_{\\mathrm{sub}} = (-250.0\\,\\mathrm{kcal/mol}) - (-120.0\\,\\mathrm{kcal/mol}) + (-100.0\\,\\mathrm{kcal/mol})$$\n$$E_{\\mathrm{sub}} = -250.0 + 120.0 - 100.0\\,\\mathrm{kcal/mol}$$\n$$E_{\\mathrm{sub}} = -130.0 - 100.0\\,\\mathrm{kcal/mol}$$\n$$E_{\\mathrm{sub}} = -230.0\\,\\mathrm{kcal/mol}$$\n\n### Physical Interpretation\nThe calculated energy, $E_{\\mathrm{sub}} = -230.0\\,\\mathrm{kcal/mol}$, is the estimated total energy of the system within the subtractive QM/MM framework. It represents an approximation of the system's energy where the QM region is described quantum mechanically, and the MM region and QM-MM interactions are described with a classical force field.\n\nThe formula for $E_{\\mathrm{sub}}$ can be rearranged to highlight the correction term:\n$$E_{\\mathrm{sub}} = E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM}) + \\left[ E_{\\mathrm{QM}}(\\mathrm{QM}) - E_{\\mathrm{MM}}(\\mathrm{QM}) \\right]$$\nThe term in brackets, $E_{\\mathrm{QM}}(\\mathrm{QM}) - E_{\\mathrm{MM}}(\\mathrm{QM})$, represents the energy correction that arises from switching from an MM description of the QM region to a QM description.\nIn this case, the correction is:\n$$\\Delta E_{\\mathrm{correction}} = (-100.0\\,\\mathrm{kcal/mol}) - (-120.0\\,\\mathrm{kcal/mol}) = +20.0\\,\\mathrm{kcal/mol}$$\nThis positive value implies that the MM force field overstabilizes the isolated QM region by $20.0\\,\\mathrm{kcal/mol}$ compared to the more accurate QM calculation. The QM-level calculation finds the QM-region to be intrinsically less stable (higher in energy) than the MM force field predicts. The subtractive QM/MM energy $E_{\\mathrm{sub}}$ incorporates this correction, resulting in a total energy ($ -230.0\\,\\mathrm{kcal/mol}$) that is higher (less stable) than the purely classical calculation of the entire system ($E_{\\mathrm{MM}}(\\mathrm{QM}+\\mathrm{MM}) = -250.0\\,\\mathrm{kcal/mol}$). This adjustment is crucial for obtaining a more physically realistic energy for the composite system.",
            "answer": "$$\n\\boxed{-230.0}\n$$"
        },
        {
            "introduction": "When coupling atomistic and continuum regions concurrently, ensuring a seamless transition is critical for the simulation's physical accuracy. Inconsistent coupling schemes can give rise to spurious, non-physical forces known as \"ghost forces\" at the interface, which violate fundamental mechanical principles. Through this exercise , you will analytically derive the expression for these ghost forces in a model system and explore a correction scheme, gaining insight into the essential \"patch test\" for validating concurrent multiscale methods.",
            "id": "3467957",
            "problem": "Consider a one-dimensional periodic lattice of $N$ nodes with reference spacing $a_0$ and positions $\\{x_i\\}_{i=0}^{N-1}$ indexed modulo $N$. The lattice has harmonic pair interactions up to second-nearest neighbors with stiffnesses $k_1$ and $k_2$, respectively. Define the uniform deformation gradient $F$ such that $x_i = F a_0 i$ for all $i$. The atomistic site energy at node $i$ is constructed by equally splitting the bond energies among adjacent sites:\n$$\nE_i^{\\text{a}}(x) = \\frac{k_1}{4} \\left[(x_i - x_{i-1} - a_0)^2 + (x_{i+1} - x_i - a_0)^2\\right] + \\frac{k_2}{4} \\left[(x_i - x_{i-2} - 2 a_0)^2 + (x_{i+2} - x_i - 2 a_0)^2\\right].\n$$\nThe continuum site energy $E_i^{\\text{cb}}(F)$ is defined via the Cauchy-Born rule (CB) as the atomistic energy of a representative cell under uniform deformation $F$:\n$$\nE_i^{\\text{cb}}(F) = \\frac{k_1}{2} a_0^2 (F - 1)^2 + \\frac{k_2}{2} (2 a_0)^2 (F - 1)^2.\n$$\nConsider concurrent atomistic–continuum coupling with a spatially varying blending weight $w_i \\in [0,1]$, where $w_i = 1$ denotes pure atomistic and $w_i = 0$ denotes pure continuum. The blended energy is\n$$\nE^{\\text{blend}}(x;F,w) = \\sum_{i=0}^{N-1} \\left[ w_i E_i^{\\text{a}}(x) + (1 - w_i) E_i^{\\text{cb}}(F) \\right].\n$$\nUnder a uniform deformation $F = \\text{const}$, the patch test requires that the internal forces vanish. Define the discrete internal force vector by\n$$\nf_i^{\\text{ghost}}(F,w) = - \\frac{\\partial E^{\\text{blend}}(x;F,w)}{\\partial x_i} \\bigg|_{x_i = F a_0 i}.\n$$\nThese nonzero forces under a uniform $F$ are called ghost forces. Define the residual stress vector in one dimension as the same as the force vector under unit cross-sectional area. The residual stress norm is\n$$\n\\|\\boldsymbol{\\sigma}_{\\text{ghost}}\\| = \\left( \\sum_{i=0}^{N-1} \\left( f_i^{\\text{ghost}} \\right)^2 \\right)^{1/2}.\n$$\nYour tasks are:\n1. Starting from the given definitions and classical mechanics (forces are negative gradients of potential energy), compute $f_i^{\\text{ghost}}(F,w)$ for a set of coupling weights $\\{w_i\\}$ under uniform deformation $F$.\n2. Propose a blended energy correction that eliminates ghost forces under uniform deformation. Implement the simplest linear ghost-force correction by adding a term $E^{\\text{corr}}(x)$ such that\n$$\n- \\frac{\\partial}{\\partial x_i} \\left( E^{\\text{blend}}(x;F,w) + E^{\\text{corr}}(x) \\right) \\bigg|_{x_i = F a_0 i} = 0 \\quad \\text{for all } i,\n$$\nand quantify the residual stress norm after correction.\n3. Return, for each test case, the following list: $[G_{\\text{naive}}, G_{\\text{corrected}}, S_{\\text{naive}}, S_{\\text{corrected}}]$, where $G_{\\text{naive}}$ is the Euclidean norm of the ghost force vector without correction, $G_{\\text{corrected}}$ is the same norm with the proposed correction applied, $S_{\\text{naive}} = \\|\\boldsymbol{\\sigma}_{\\text{ghost}}\\|$ without correction, and $S_{\\text{corrected}} = \\|\\boldsymbol{\\sigma}_{\\text{ghost}}\\|$ with correction. Use dimensionless units throughout.\n\nUse the following test suite, where weights are defined on indices $i \\in \\{0,1,\\dots,N-1\\}$ modulo $N$:\n- Case A (smooth blending, small strain): $N = 64$, $a_0 = 1.0$, $k_1 = 1.0$, $k_2 = 0.25$, $F = 1.02$, and a linear ramp $w_i$ with $w_i = 1$ for $i \\leq 16$, $w_i = 0$ for $i \\geq 48$, and for $i \\in (16,48)$, $w_i = 1 - \\frac{i - 16}{48 - 16}$.\n- Case B (smooth blending, larger strain): $N = 64$, $a_0 = 1.0$, $k_1 = 1.0$, $k_2 = 0.25$, $F = 1.10$, with the same linear ramp $w_i$ as Case A.\n- Case C (sharp interface): $N = 64$, $a_0 = 1.0$, $k_1 = 1.0$, $k_2 = 0.25$, $F = 1.05$, and a step blending $w_i = 1$ for $i  32$, $w_i = 0$ for $i \\geq 32$.\n- Case D (small system, mixed interactions): $N = 8$, $a_0 = 1.0$, $k_1 = 1.0$, $k_2 = 0.5$, $F = 1.03$, and a linear ramp $w_i = 1$ for $i \\leq 2$, $w_i = 0$ for $i \\geq 6$, and for $i \\in (2,6)$, $w_i = 1 - \\frac{i - 2}{6 - 2}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of per-case lists, with no spaces, enclosed in square brackets. For example: \"[[rA1,rA2,rA3,rA4],[rB1,rB2,rB3,rB4],...]\". Each $r$ must be a floating-point number in dimensionless units.",
            "solution": "The problem requires an analysis of ghost forces in a one-dimensional, concurrent atomistic-continuum coupled system. First, we must derive an analytical expression for the ghost forces, which are spurious internal forces that arise under a uniform deformation when the coupling scheme does not preserve energy consistency. Second, we must propose and implement a correction to eliminate these forces. Finally, we quantify the magnitude of these forces before and after correction for several test cases.\n\n### 1. Derivation of the Ghost Force Vector\n\nThe total blended energy of the system is given by:\n$$\nE^{\\text{blend}}(x;F,w) = \\sum_{i=0}^{N-1} \\left[ w_i E_i^{\\text{a}}(x) + (1 - w_i) E_i^{\\text{cb}}(F) \\right]\n$$\nThe internal force on atom $i$ is defined as the negative gradient of the potential energy with respect to its position $x_i$. The ghost force, $f_i^{\\text{ghost}}$, is this force evaluated for a configuration where all atoms are displaced according to a uniform deformation gradient $F$, i.e., $x_k = F a_0 k$ for all $k$.\n$$\nf_i^{\\text{ghost}}(F,w) = - \\frac{\\partial E^{\\text{blend}}(x;F,w)}{\\partial x_i} \\bigg|_{x_k = F a_0 k}\n$$\nThe continuum site energy, $E_i^{\\text{cb}}(F)$, depends only on the global deformation parameter $F$ and not on the individual atomic positions $x_k$. Therefore, its partial derivative with respect to any $x_i$ is zero. The calculation simplifies to differentiating only the atomistic portion of the energy:\n$$\nf_i^{\\text{ghost}}(F,w) = - \\frac{\\partial}{\\partial x_i} \\left( \\sum_{j=0}^{N-1} w_j E_j^{\\text{a}}(x) \\right) \\bigg|_{x_k = F a_0 k}\n$$\nThe provided atomistic site energy $E_j^{\\text{a}}(x)$ is constructed by equally splitting bond energies. The total atomistic potential energy, $U^{\\text{a}}(x) = \\sum_j w_j E_j^{\\text{a}}(x)$, can be re-expressed as a sum over bonds. The energy of a bond between atoms $j$ and $j+m$ (where $m=1$ or $m=2$) is distributed to sites $j$ and $j+m$. The term $(x_{j+1}-x_j-a_0)^2$, corresponding to the nearest-neighbor bond, appears in $E_j^{\\text{a}}$ and $E_{j+1}^{\\text{a}}$. Its total contribution to $U^{\\text{a}}(x)$ is modulated by the average of the weights at its endpoints, $(w_j+w_{j+1})/2$. A similar argument holds for second-nearest neighbors. This allows us to write the total atomistic energy more conveniently:\n$$\nU^{\\text{a}}(x) = \\sum_{j=0}^{N-1} \\left[ \\frac{k_1}{4}(w_j + w_{j+1})(x_{j+1} - x_j - a_0)^2 + \\frac{k_2}{4}(w_j + w_{j+2})(x_{j+2} - x_j - 2a_0)^2 \\right]\n$$\nNow, we differentiate $U^{\\text{a}}(x)$ with respect to $x_i$. The variable $x_i$ appears in terms involving its neighbors. For the first-neighbor interactions:\n$$\n\\frac{\\partial}{\\partial x_i} \\left[ \\frac{k_1}{4}(w_{i-1}+w_i)(x_i-x_{i-1}-a_0)^2 + \\frac{k_1}{4}(w_i+w_{i+1})(x_{i+1}-x_i-a_0)^2 \\right] \\\\\n= \\frac{k_1}{2}(w_{i-1}+w_i)(x_i-x_{i-1}-a_0) - \\frac{k_1}{2}(w_i+w_{i+1})(x_{i+1}-x_i-a_0)\n$$\nAnd for the second-neighbor interactions:\n$$\n\\frac{\\partial}{\\partial x_i} \\left[ \\frac{k_2}{4}(w_{i-2}+w_i)(x_i-x_{i-2}-2a_0)^2 + \\frac{k_2}{4}(w_i+w_{i+2})(x_{i+2}-x_i-2a_0)^2 \\right] \\\\\n= \\frac{k_2}{2}(w_{i-2}+w_i)(x_i-x_{i-2}-2a_0) - \\frac{k_2}{2}(w_i+w_{i+2})(x_{i+2}-x_i-2a_0)\n$$\nWe now evaluate these derivatives at the uniformly deformed state $x_k = F a_0 k$. The bond elongations become:\n$x_{i+m} - x_i - m a_0 = F a_0 (i+m) - F a_0 i - m a_0 = m a_0 (F-1)$.\nSubstituting this into the derivatives:\n$$\n\\frac{\\partial U^{\\text{a}}}{\\partial x_i}\\bigg|_{x_k=Fa_0k} = \\frac{k_1}{2}(w_{i-1}+w_i)(a_0(F-1)) - \\frac{k_1}{2}(w_i+w_{i+1})(a_0(F-1)) \\\\\n+ \\frac{k_2}{2}(w_{i-2}+w_i)(2a_0(F-1)) - \\frac{k_2}{2}(w_i+w_{i+2})(2a_0(F-1))\n$$\nFactoring out common terms yields:\n$$\n\\frac{\\partial U^{\\text{a}}}{\\partial x_i}\\bigg|_{x_k=Fa_0k} = \\frac{k_1 a_0(F-1)}{2} (w_{i-1} - w_{i+1}) + k_2 a_0(F-1) (w_{i-2} - w_{i+2})\n$$\nThe ghost force is the negative of this expression:\n$$\nf_i^{\\text{ghost}} = - \\frac{\\partial U^{\\text{a}}}{\\partial x_i}\\bigg|_{x_k=Fa_0k} = a_0(F-1) \\left[ \\frac{k_1}{2}(w_{i+1} - w_{i-1}) + k_2(w_{i+2} - w_{i-2}) \\right]\n$$\nThis formula shows that ghost forces are non-zero only where the weighting function $w_i$ varies, as the force expression resembles a finite difference approximation of the derivative of $w$. In regions where $w_i$ is constant (fully atomistic or fully continuum), the forces vanish as required.\n\n### 2. Ghost Force Correction\n\nThe patch test is passed if the internal forces vanish under a uniform deformation. Our derived $f_i^{\\text{ghost}}$ is generally non-zero in the interface region. To correct this, we introduce a correction energy $E^{\\text{corr}}(x)$ such that the total force is zero:\n$$\nf_i^{\\text{total}} = - \\frac{\\partial}{\\partial x_i} \\left( E^{\\text{blend}}(x;F,w) + E^{\\text{corr}}(x) \\right) \\bigg|_{x_k = F a_0 k} = 0\n$$\nThis implies that the force from the correction term must exactly cancel the ghost force:\n$$\nf_i^{\\text{corr}} = - \\frac{\\partial E^{\\text{corr}}(x)}{\\partial x_i} \\bigg|_{x_k=Fa_0k} = -f_i^{\\text{ghost}}\n$$\nThe problem asks for the simplest linear ghost-force correction. The quantities $f_i^{\\text{ghost}}$ are constants for a given set of parameters $\\{F, w_i, k_1, k_2, a_0\\}$, as they do not depend on the dynamic positions $x_i$. A force that is constant with respect to position is generated by an energy potential that is linear in position. We define the correction energy as:\n$$\nE^{\\text{corr}}(x) = \\sum_{j=0}^{N-1} f_j^{\\text{ghost}} x_j\n$$\nThe corrective force at site $i$ is then:\n$$\nf_i^{\\text{corr}} = - \\frac{\\partial E^{\\text{corr}}}{\\partial x_i} = -f_i^{\\text{ghost}}\n$$\nThe total force on atom $i$ in the corrected system, evaluated at the uniform deformation state, is:\n$$\nf_i^{\\text{total}} = f_i^{\\text{ghost}} + f_i^{\\text{corr}} = f_i^{\\text{ghost}} - f_i^{\\text{ghost}} = 0\n$$\nThus, the corrected system passes the patch test by construction. The ghost forces are identically zero for all atoms.\n\n### 3. Quantification of Norms\n\nWe are asked to compute four quantities for each test case:\n- $G_{\\text{naive}}$: The Euclidean norm of the uncorrected ghost force vector, $\\|\\boldsymbol{f}^{\\text{ghost}}\\|$.\n- $G_{\\text{corrected}}$: The Euclidean norm of the corrected ghost force vector.\n- $S_{\\text{naive}}$: The uncorrected residual stress norm, $\\|\\boldsymbol{\\sigma}_{\\text{ghost}}\\|$.\n- $S_{\\text{corrected}}$: The corrected residual stress norm.\n\nBased on the derivations:\nThe uncorrected ghost force norm is:\n$$\nG_{\\text{naive}} = \\left( \\sum_{i=0}^{N-1} (f_i^{\\text{ghost}})^2 \\right)^{1/2}\n$$\nThe corrected ghost force vector is the zero vector, so its norm is:\n$$\nG_{\\text{corrected}} = 0\n$$\nThe problem states that the residual stress vector is the same as the force vector (assuming unit cross-sectional area). Therefore, the stress norms are numerically identical to the force norms:\n$$\nS_{\\text{naive}} = G_{\\text{naive}}\n$$\n$$\nS_{\\text{corrected}} = G_{\\text{corrected}} = 0\n$$\nThe final output for each case is the list $[G_{\\text{naive}}, 0.0, G_{\\text{naive}}, 0.0]$. We will now implement the calculation of $G_{\\text{naive}}$ for the specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the ghost force norms for several atomistic-continuum coupling scenarios.\n    \"\"\"\n\n    test_cases = [\n        # Case A: Smooth blending, small strain\n        {\n            \"N\": 64, \"a0\": 1.0, \"k1\": 1.0, \"k2\": 0.25, \"F\": 1.02,\n            \"w_type\": \"linear\", \"w_params\": {\"i1\": 16, \"i2\": 48}\n        },\n        # Case B: Smooth blending, larger strain\n        {\n            \"N\": 64, \"a0\": 1.0, \"k1\": 1.0, \"k2\": 0.25, \"F\": 1.10,\n            \"w_type\": \"linear\", \"w_params\": {\"i1\": 16, \"i2\": 48}\n        },\n        # Case C: Sharp interface\n        {\n            \"N\": 64, \"a0\": 1.0, \"k1\": 1.0, \"k2\": 0.25, \"F\": 1.05,\n            \"w_type\": \"step\", \"w_params\": {\"isplit\": 32}\n        },\n        # Case D: Small system, mixed interactions\n        {\n            \"N\": 8, \"a0\": 1.0, \"k1\": 1.0, \"k2\": 0.5, \"F\": 1.03,\n            \"w_type\": \"linear\", \"w_params\": {\"i1\": 2, \"i2\": 6}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        N, a0, k1, k2, F = case[\"N\"], case[\"a0\"], case[\"k1\"], case[\"k2\"], case[\"F\"]\n        \n        # Construct the weight vector w\n        w = np.zeros(N)\n        if case[\"w_type\"] == \"linear\":\n            i1, i2 = case[\"w_params\"][\"i1\"], case[\"w_params\"][\"i2\"]\n            # w_i = 1 for i = i1\n            w[0:i1 + 1] = 1.0\n            # Linear ramp for i in (i1, i2)\n            ramp_indices = np.arange(i1 + 1, i2)\n            w[ramp_indices] = 1.0 - (ramp_indices - i1) / (i2 - i1)\n            # w_i = 0 for i = i2 is already set by np.zeros initialization\n            \n        elif case[\"w_type\"] == \"step\":\n            isplit = case[\"w_params\"][\"isplit\"]\n            w[0:isplit] = 1.0\n            # The rest are already zero\n            \n        # Calculate ghost forces using a vectorized approach for periodic boundaries\n        # w_{i+1} corresponds to rolling the array left by 1\n        w_ip1 = np.roll(w, -1)\n        w_im1 = np.roll(w, 1)\n        w_ip2 = np.roll(w, -2)\n        w_im2 = np.roll(w, 2)\n        \n        # Formula for ghost force:\n        # f_i^ghost = a0*(F-1) * [ k1/2 * (w_{i+1} - w_{i-1}) + k2 * (w_{i+2} - w_{i-2}) ]\n        f_ghost = a0 * (F - 1) * (0.5 * k1 * (w_ip1 - w_im1) + k2 * (w_ip2 - w_im2))\n        \n        # Task 3: Calculate norms\n        # G_naive is the Euclidean norm of the uncorrected ghost force vector\n        g_naive = np.linalg.norm(f_ghost)\n        \n        # G_corrected is 0 by construction of the linear force correction\n        g_corrected = 0.0\n        \n        # S_naive and S_corrected are numerically identical to G_naive and G_corrected\n        # as per the problem statement (unit cross-sectional area)\n        s_naive = g_naive\n        s_corrected = 0.0\n        \n        results.append([g_naive, g_corrected, s_naive, s_corrected])\n\n    # Format the final output string exactly as required\n    case_strings = []\n    for res_list in results:\n        # Using str() for default floating point representation\n        case_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond concurrent coupling, hierarchical modeling offers a powerful strategy where fine-scale information is used to build more accurate coarse-scale models. This practice explores the well-known \"smaller is stronger\" size effect in crystal plasticity, a phenomenon that continuum models alone cannot capture. By bridging discrete dislocation source statistics to a continuum hardening law , you will construct a predictive model that demonstrates how microstructural physics can be systematically upscaled to explain macroscopic mechanical behavior.",
            "id": "3468017",
            "problem": "Consider a face-centered cubic (FCC) micropillar of diameter $D$ compressed under an axial load with a fixed crystal orientation such that the resolved shear stress is related to the axial stress by the Schmid law. The goal is to construct a hierarchical-to-continuum bridge that starts from discrete dislocation source statistics and ends at a continuum hardening law, then use it to predict the dependence of the flow stress on the pillar diameter $D$, demonstrating that the flow stress scales approximately as $1/\\sqrt{D}$ at fixed plastic shear strain. All stresses must be expressed in megapascals (MPa).\n\nStart from the following fundamental basis and definitions, which you must use to build and solve the model:\n\n1. Frank–Read source activation and loop production: a source of characteristic length $L$ produces a loop and contributes dislocation line length to the microstructure. In small volumes, source lengths are geometrically truncated by the pillar diameter $D$.\n\n2. Dislocation storage and recovery are described by a Kocks–Mecking type evolution law for dislocation density $\\rho$ versus plastic shear strain $\\gamma$:\n$$\n\\frac{d \\rho}{d \\gamma} = \\frac{k_s(D)}{b\\, \\ell(D)} - k_a \\rho,\n$$\nwhere $b$ is the Burgers vector magnitude, $\\ell(D)$ is an effective mean free path for dislocations in the pillar, $k_s(D)$ is a dimensionless storage coefficient informed by discrete source statistics, and $k_a$ is a recovery coefficient per unit shear strain.\n\n3. The Taylor relation connects the flow resolved shear stress $\\tau$ to the dislocation density:\n$$\n\\tau = \\alpha\\, G\\, b\\, \\sqrt{\\rho},\n$$\nwhere $\\alpha$ is a dimensionless hardening factor and $G$ is the shear modulus. The axial flow stress $\\sigma$ is related to the resolved shear stress by the Schmid law:\n$$\n\\sigma = \\frac{\\tau}{m},\n$$\nwhere $m$ is the Schmid factor for the given crystal orientation.\n\nModel the discrete source lengths $L$ as Weibull-distributed and truncated by the pillar geometry. Let the raw Weibull probability density be\n$$\nf_{\\text{raw}}(L; \\lambda, k) = \\frac{k}{\\lambda} \\left(\\frac{L}{\\lambda}\\right)^{k-1} \\exp\\left( - \\left(\\frac{L}{\\lambda}\\right)^k \\right),\n$$\nwith scale $\\lambda$ and shape $k$, and consider only source lengths in the interval $[L_{\\min}, D]$. Define the truncated mean source length as\n$$\n\\mathbb{E}[L \\mid L_{\\min} \\le L \\le D] = \\frac{\\int_{L_{\\min}}^{D} L\\, f_{\\text{raw}}(L; \\lambda, k)\\, dL}{F(D;\\lambda,k) - F(L_{\\min};\\lambda,k)},\n$$\nwhere $F(x;\\lambda,k) = 1 - \\exp\\left( - (x/\\lambda)^k \\right)$ is the cumulative distribution function of the raw Weibull.\n\nTo connect discrete source statistics to the continuum storage coefficient, define\n$$\nR(D) = \\frac{\\mathbb{E}[L \\mid L_{\\min} \\le L \\le D]}{D},\n$$\nand select a fixed reference diameter $D_{\\text{ref}}$ to normalize the storage coefficient so that\n$$\nk_s(D) = k_{s0}\\, \\frac{R(D)}{R(D_{\\text{ref}})},\n$$\nwith $k_{s0}$ a constant. Assume an effective mean free path $\\ell(D) = c_\\ell D$, where $c_\\ell$ is a constant capturing geometric constraints and internal obstacles.\n\nUsing the above, you must:\n- Derive the dislocation density $\\rho(\\gamma, D)$ from first principles based on the given law for $d\\rho/d\\gamma$, showing how the dependence on $D$ enters, and then compute the axial flow stress $\\sigma(\\gamma, D)$ via the Taylor relation and the Schmid law.\n- Demonstrate the approximate scaling $\\sigma \\propto 1/\\sqrt{D}$ by computing an empirical scaling exponent $n$ from pairs of diameters using\n$$\nn = -\\frac{\\ln\\left(\\sigma(D_2)/\\sigma(D_1)\\right)}{\\ln\\left(D_2/D_1\\right)}.\n$$\n\nMaterial and model parameters to use (all constants are the same across test cases unless otherwise specified):\n- Shear modulus $G = 48 \\times 10^9$ (Pascal),\n- Burgers vector magnitude $b = 0.256 \\times 10^{-9}$ (meter),\n- Hardening factor $\\alpha = 0.3$ (dimensionless),\n- Recovery coefficient $k_a = 4.0$ (per unit shear strain),\n- Mean free path coefficient $c_\\ell = 0.5$ (dimensionless),\n- Initial dislocation density $\\rho_0 = 1.0 \\times 10^{12}$ (meter$^{-2}$),\n- Storage normalization constant $k_{s0} = 1.0$ (dimensionless),\n- Reference diameter $D_{\\text{ref}} = 2.0$ (micrometer).\n\nUnits and conversions:\n- Diameters $D$, $D_1$, $D_2$, the Weibull scale $\\lambda$, and the minimum source length $L_{\\min}$ are specified in micrometers and must be converted to meters in the computation.\n- Plastic shear strain $\\gamma$ and the Schmid factor $m$ are dimensionless.\n- Final axial flow stresses must be returned in megapascals (MPa).\n\nTest suite:\nCompute the outputs for the following parameter sets. For cases of type “stress,” return the axial flow stress $\\sigma$ in MPa. For the case of type “exponent,” return the exponent $n$ as a float. Each case is independent.\n- Case $1$ (stress, happy path): $D = 2.0$ (micrometer), $\\gamma = 0.2$, $m = 0.5$, $\\lambda = 1.0$ (micrometer), $k = 2.0$, $L_{\\min} = 0.1$ (micrometer).\n- Case $2$ (stress, small diameter boundary): $D = 0.5$ (micrometer), $\\gamma = 0.2$, $m = 0.5$, $\\lambda = 1.0$ (micrometer), $k = 2.0$, $L_{\\min} = 0.1$ (micrometer).\n- Case $3$ (stress, large diameter boundary): $D = 10.0$ (micrometer), $\\gamma = 0.2$, $m = 0.5$, $\\lambda = 1.0$ (micrometer), $k = 2.0$, $L_{\\min} = 0.1$ (micrometer).\n- Case $4$ (stress, orientation variation): $D = 2.0$ (micrometer), $\\gamma = 0.2$, $m = 0.3$, $\\lambda = 1.0$ (micrometer), $k = 2.0$, $L_{\\min} = 0.1$ (micrometer).\n- Case $5$ (stress, source statistics variation): $D = 2.0$ (micrometer), $\\gamma = 0.2$, $m = 0.5$, $\\lambda = 0.5$ (micrometer), $k = 1.0$, $L_{\\min} = 0.1$ (micrometer).\n- Case $6$ (exponent, scaling demonstration): $(D_1, D_2) = (1.0, 4.0)$ (micrometer), $\\gamma = 0.5$, $m = 0.5$, $\\lambda = 1.0$ (micrometer), $k = 2.0$, $L_{\\min} = 0.1$ (micrometer). Compute $n$ using the definition above for these two diameters, keeping all other parameters the same.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example\n$[r_1,r_2,\\dots]$,\nwhere $r_i$ is the float result for case $i$ in the order listed above. Express all axial stresses in MPa. No other text must be printed.",
            "solution": "The problem requires the construction of a hierarchical multiscale model to predict the flow stress $\\sigma$ of a micropillar as a function of its diameter $D$. This model serves as a bridge between discrete dislocation source statistics at the microscale and a continuum description of plastic flow at the macroscale. The derivation and computational solution proceed in four primary steps.\n\n**1. Dislocation Density Evolution**\n\nThe foundation of the continuum model is the Kocks–Mecking evolution law for the total dislocation density $\\rho$ as a function of plastic shear strain $\\gamma$:\n$$ \\frac{d \\rho}{d \\gamma} = \\frac{k_s(D)}{b\\, \\ell(D)} - k_a \\rho $$\nThis is a first-order linear ordinary differential equation for $\\rho(\\gamma)$. Rearranging the terms, we obtain the standard form:\n$$ \\frac{d \\rho}{d \\gamma} + k_a \\rho = \\frac{k_s(D)}{b\\, \\ell(D)} $$\nThe term on the right-hand side is constant with respect to the strain $\\gamma$. We can denote it by $C(D) = k_s(D) / (b\\, \\ell(D))$ for simplicity. The equation is solved using an integrating factor, $I(\\gamma) = \\exp(\\int k_a d\\gamma) = \\exp(k_a \\gamma)$. The general solution is of the form:\n$$ \\rho(\\gamma) = \\frac{C(D)}{k_a} + K e^{-k_a \\gamma} $$\nwhere $K$ is the constant of integration. We determine $K$ by applying the initial condition $\\rho(\\gamma=0) = \\rho_0$. This yields $K = \\rho_0 - C(D)/k_a$. Substituting this back into the general solution gives the specific solution for the dislocation density:\n$$ \\rho(\\gamma, D) = \\frac{k_s(D)}{k_a b\\, \\ell(D)} + \\left(\\rho_0 - \\frac{k_s(D)}{k_a b\\, \\ell(D)}\\right) e^{-k_a \\gamma} $$\nThis equation describes how the dislocation density evolves from an initial state $\\rho_0$ towards a saturation density $\\rho_{\\text{sat}}(D) = k_s(D) / (k_a b\\, \\ell(D))$ as plastic strain accumulates.\n\n**2. From Discrete Sources to the Continuum Storage Coefficient**\n\nThe model's size sensitivity is introduced through the parameters that depend on the pillar diameter $D$: the storage coefficient $k_s(D)$ and the dislocation mean free path $\\ell(D)$.\nThe mean free path is assumed to be directly proportional to the pillar diameter, $\\ell(D) = c_\\ell D$, reflecting geometric confinement.\nThe storage coefficient $k_s(D)$ is derived from the statistics of discrete dislocation Frank-Read sources. The lengths $L$ of these sources are modeled by a Weibull distribution, but are geometrically truncated by the pillar boundaries to the interval $[L_{\\min}, D]$. The key quantity for bridging the scales is the truncated mean source length, $\\mathbb{E}[L \\mid L_{\\min} \\le L \\le D]$, defined as:\n$$ \\mathbb{E}[L \\mid L_{\\min} \\le L \\le D] = \\frac{\\int_{L_{\\min}}^{D} L\\, f_{\\text{raw}}(L; \\lambda, k)\\, dL}{\\int_{L_{\\min}}^{D} f_{\\text{raw}}(L; \\lambda, k)\\, dL} $$\nThe integral in the numerator is the first incomplete moment of the Weibull distribution, and the denominator represents the probability mass within the truncated interval $[L_{\\min}, D]$. The evaluation of this expression is facilitated by using the lower incomplete gamma function, $\\gamma(s,x) = \\int_0^x t^{s-1} e^{-t} dt$. The analytical expression for the mean is:\n$$ \\mathbb{E}[L_D] = \\lambda \\frac{\\gamma\\left(1+\\frac{1}{k}, \\left(\\frac{D}{\\lambda}\\right)^k\\right) - \\gamma\\left(1+\\frac{1}{k}, \\left(\\frac{L_{\\min}}{\\lambda}\\right)^k\\right)}{\\exp\\left(-\\left(\\frac{L_{\\min}}{\\lambda}\\right)^k\\right) - \\exp\\left(-\\left(\\frac{D}{\\lambda}\\right)^k\\right)} $$\nwhere we use the shorthand $\\mathbb{E}[L_D]$ for $\\mathbb{E}[L \\mid L_{\\min} \\le L \\le D]$.\nThe connection to the continuum storage term is then established by defining a dimensionless ratio $R(D) = \\mathbb{E}[L_D] / D$. This ratio captures the deviation of the mean source length from the pillar diameter. $R(D)$ is used to scale a reference storage coefficient $k_{s0}$, which is defined at a reference diameter $D_{\\text{ref}}$:\n$$ k_s(D) = k_{s0}\\, \\frac{R(D)}{R(D_{\\text{ref}})} = k_{s0}\\, \\frac{\\mathbb{E}[L_D]/D}{\\mathbb{E}[L_{D_{\\text{ref}}}]/D_{\\text{ref}}} $$\nThis formulation ensures that as the pillar size $D$ decreases, the truncation of the source length distribution becomes more pronounced, which alters the mean source length and, consequently, the rate of dislocation storage.\n\n**3. Calculation of the Axial Flow Stress**\n\nOnce the dislocation density $\\rho(\\gamma, D)$ is determined for a given strain and diameter, the resolved shear stress $\\tau$ is calculated using the Taylor relation, which connects the microscopic dislocation structure to the macroscopic flow stress:\n$$ \\tau(\\gamma, D) = \\alpha\\, G\\, b\\, \\sqrt{\\rho(\\gamma, D)} $$\nFinally, the axial flow stress $\\sigma$ required to drive the compression is obtained via the Schmid law. This law projects the resolved shear stress on the active slip system onto the loading axis using the Schmid factor $m$:\n$$ \\sigma(\\gamma, D) = \\frac{\\tau(\\gamma, D)}{m} = \\frac{\\alpha\\, G\\, b}{m} \\sqrt{\\rho(\\gamma, D)} $$\nTo perform a numerical calculation, all parameters must be expressed in a consistent system of units, typically SI (meters, Pascals, etc.). The final result for axial stress is then converted from Pascals (Pa) to megapascals (MPa) by dividing by $10^6$.\n\n**4. Analysis of Size-Dependent Scaling**\n\nThe problem postulates an approximate power-law scaling relationship between stress and diameter, $\\sigma \\propto D^{-n}$, with an expected exponent of $n \\approx 0.5$. To verify this prediction within the model, an empirical scaling exponent $n$ is calculated from two stress predictions, $\\sigma_1 = \\sigma(\\gamma, D_1)$ and $\\sigma_2 = \\sigma(\\gamma, D_2)$, at two different diameters $D_1$ and $D_2$. Assuming the power law holds:\n$$ \\sigma_1 = C D_1^{-n} \\quad \\text{and} \\quad \\sigma_2 = C D_2^{-n} $$\nTaking the ratio of these two equations eliminates the constant $C$: $\\sigma_2/\\sigma_1 = (D_2/D_1)^{-n}$. Taking the natural logarithm of both sides and solving for $n$ yields the formula provided:\n$$ n = -\\frac{\\ln\\left(\\sigma_2/\\sigma_1\\right)}{\\ln\\left(D_2/D_1\\right)} $$\nThis calculation provides a quantitative measure of the \"smaller is stronger\" size effect as predicted by the hierarchical model over a specified range of pillar diameters.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammainc, gamma\n\n# --- Model Parameters and Constants ---\n# All values are in base SI units (meters, Pascals, etc.) unless specified otherwise.\nG = 48.0e9  # Shear modulus (Pa)\nb = 0.256e-9  # Burgers vector magnitude (m)\nalpha = 0.3  # Hardening factor (dimensionless)\nka = 4.0  # Recovery coefficient (per unit shear strain)\ncl = 0.5  # Mean free path coefficient (dimensionless)\nrho0 = 1.0e12  # Initial dislocation density (m^-2)\nks0 = 1.0  # Storage normalization constant (dimensionless)\nD_ref = 2.0e-6  # Reference diameter (m)\n\ndef calculate_truncated_mean_L(D_val, L_min_val, lambda_val, k_val):\n    \"\"\"\n    Calculates the truncated mean source length E[L | L_min = L = D].\n    All length inputs must be in meters.\n    \"\"\"\n    if np.isclose(D_val, L_min_val):\n        return L_min_val\n    \n    if D_val  L_min_val:\n        # Physical case of an empty set of possible source lengths.\n        return np.nan\n\n    u_min = (L_min_val / lambda_val)**k_val\n    u_max = (D_val / lambda_val)**k_val\n    s = 1.0 + 1.0 / k_val\n\n    # Numerator is related to the incomplete gamma function.\n    # scipy.special.gammainc is the regularized lower incomplete gamma function P(s, x)\n    # where P(s, x) = gamma(s, x) / Gamma(s).\n    # So, gamma(s, x) = gammainc(s, x) * Gamma(s).\n    gamma_s = gamma(s)\n    gamma_lower_max = gammainc(s, u_max) * gamma_s\n    gamma_lower_min = gammainc(s, u_min) * gamma_s\n    numerator = lambda_val * (gamma_lower_max - gamma_lower_min)\n\n    # Denominator is the probability mass in the truncated interval.\n    denominator = np.exp(-u_min) - np.exp(-u_max)\n    \n    if np.isclose(denominator, 0.0):\n        # This case can occur if u_min and u_max are very large, making both\n        # exponentials numerically zero. This implies L_min  lambda.\n        # This is not expected for the given test cases but is a possible edge case.\n        # Alternatively, if D is very close to L_min, but np.isclose failed.\n        return np.nan\n\n    return numerator / denominator\n\ndef calculate_stress_mpa(D_um, gamma_strain, m, lambda_um, k, L_min_um):\n    \"\"\"\n    Calculates the axial flow stress in MPa for a given set of parameters.\n    \"\"\"\n    # Convert inputs from micrometers to meters\n    D = D_um * 1e-6\n    lambda_val = lambda_um * 1e-6\n    L_min = L_min_um * 1e-6\n\n    # 1. Calculate truncated mean lengths for the given D and the reference D_ref\n    #    The source statistics (lambda, k, L_min) are the same for both calculations.\n    E_L_D = calculate_truncated_mean_L(D, L_min, lambda_val, k)\n    E_L_D_ref = calculate_truncated_mean_L(D_ref, L_min, lambda_val, k)\n    \n    # 2. Calculate the normalized ratios R(D) and R(D_ref)\n    R_D = E_L_D / D\n    R_D_ref = E_L_D_ref / D_ref\n    \n    # 3. Calculate the diameter-dependent storage coefficient ks(D)\n    ks_D = ks0 * (R_D / R_D_ref)\n    \n    # 4. Solve for dislocation density rho\n    ell_D = cl * D\n    rho_sat = ks_D / (ka * b * ell_D)\n    rho = rho_sat + (rho0 - rho_sat) * np.exp(-ka * gamma_strain)\n    \n    # 5. Calculate stresses\n    # Taylor relation for resolved shear stress\n    tau = alpha * G * b * np.sqrt(rho)\n    # Schmid law for axial stress in Pa\n    sigma_pa = tau / m\n    \n    # 6. Convert final axial stress to MPa\n    sigma_mpa = sigma_pa / 1e6\n    \n    return sigma_mpa\n\ndef calculate_exponent(D1_um, D2_um, gamma_strain, m, lambda_um, k, L_min_um):\n    \"\"\"\n    Calculates the empirical scaling exponent n.\n    \"\"\"\n    # Calculate stresses at diameters D1 and D2.\n    # The units of stress (Pa or MPa) do not matter for the ratio.\n    sigma1 = calculate_stress_mpa(D1_um, gamma_strain, m, lambda_um, k, L_min_um)\n    sigma2 = calculate_stress_mpa(D2_um, gamma_strain, m, lambda_um, k, L_min_um)\n    \n    # The units of diameter (um or m) do not matter for the ratio.\n    n = -np.log(sigma2 / sigma1) / np.log(D2_um / D1_um)\n    \n    return n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (stress): D=2.0, γ=0.2, m=0.5, λ=1.0, k=2.0, Lmin=0.1\n        {'type': 'stress', 'params': {'D_um': 2.0, 'gamma_strain': 0.2, 'm': 0.5, 'lambda_um': 1.0, 'k': 2.0, 'L_min_um': 0.1}},\n        # Case 2 (stress): D=0.5, γ=0.2, m=0.5, λ=1.0, k=2.0, Lmin=0.1\n        {'type': 'stress', 'params': {'D_um': 0.5, 'gamma_strain': 0.2, 'm': 0.5, 'lambda_um': 1.0, 'k': 2.0, 'L_min_um': 0.1}},\n        # Case 3 (stress): D=10.0, γ=0.2, m=0.5, λ=1.0, k=2.0, Lmin=0.1\n        {'type': 'stress', 'params': {'D_um': 10.0, 'gamma_strain': 0.2, 'm': 0.5, 'lambda_um': 1.0, 'k': 2.0, 'L_min_um': 0.1}},\n        # Case 4 (stress): D=2.0, γ=0.2, m=0.3, λ=1.0, k=2.0, Lmin=0.1\n        {'type': 'stress', 'params': {'D_um': 2.0, 'gamma_strain': 0.2, 'm': 0.3, 'lambda_um': 1.0, 'k': 2.0, 'L_min_um': 0.1}},\n        # Case 5 (stress): D=2.0, γ=0.2, m=0.5, λ=0.5, k=1.0, Lmin=0.1\n        {'type': 'stress', 'params': {'D_um': 2.0, 'gamma_strain': 0.2, 'm': 0.5, 'lambda_um': 0.5, 'k': 1.0, 'L_min_um': 0.1}},\n        # Case 6 (exponent): (D1,D2)=(1.0,4.0), γ=0.5, m=0.5, λ=1.0, k=2.0, Lmin=0.1\n        {'type': 'exponent', 'params': {'D1_um': 1.0, 'D2_um': 4.0, 'gamma_strain': 0.5, 'm': 0.5, 'lambda_um': 1.0, 'k': 2.0, 'L_min_um': 0.1}},\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'stress':\n            result = calculate_stress_mpa(**case['params'])\n        elif case['type'] == 'exponent':\n            result = calculate_exponent(**case['params'])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}