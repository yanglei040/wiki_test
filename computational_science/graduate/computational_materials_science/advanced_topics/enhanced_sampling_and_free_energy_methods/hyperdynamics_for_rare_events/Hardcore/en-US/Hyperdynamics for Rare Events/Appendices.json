{
    "hands_on_practices": [
        {
            "introduction": "The core promise of hyperdynamics is that it accelerates system evolution without corrupting the long-term kinetics. This first exercise provides a direct, hands-on verification of this principle using a classic one-dimensional double-well potential . By comparing the distribution of first-passage times from a standard simulation with the reweighted physical times from a biased simulation, you will statistically validate that hyperdynamics correctly reproduces the underlying physical process.",
            "id": "3458021",
            "problem": "Consider a one-dimensional quartic double-well potential defined by $V(x)=a x^4 - b x^2$ with $a>0$ and $b>0$, and a configuration-dependent bias potential defined by $V_b(x)=\\lambda\\,\\max\\left(0, x_c^2 - x^2\\right)$ with $\\lambda\\ge 0$. The basin $B$ is the closed interval $[-x_c, x_c]$, and the boundary of the basin is the set of points $\\{|x|=x_c\\}$, where the bias vanishes. The system evolves according to overdamped Langevin dynamics with mobility set to $1$, inverse thermal energy $\\beta$, and diffusion coefficient $D=1/\\beta$, using the Euler–Maruyama integrator. The overbar denotes an ensemble average over the relevant stationary distribution restricted to $B$.\n\nYour tasks are:\n1. Starting from the Boltzmann distribution and the definition of restricted partition functions, derive an expression for the hyperdynamics boost factor $\\alpha$ as an equilibrium average of the factor $e^{\\beta V_b(x)}$ over the biased stationary distribution restricted to $B$. Express $\\alpha$ explicitly in terms of integrals over $B$ involving $V(x)$ and $V_b(x)$, and evaluate $\\alpha$ numerically by quadrature for the given parameter sets.\n2. Implement two first-passage simulations to the boundary $\\{|x|=x_c\\}$ starting from an initial point $x_0$ strictly inside $B$:\n   - Unbiased dynamics with drift $-\\partial_x V(x)$ and diffusion coefficient $D=1/\\beta$, yielding an unbiased first-passage time $t$ in units of the characteristic time $\\tau_0$.\n   - Biased hyperdynamics with drift $-\\partial_x\\left(V(x)+V_b(x)\\right)$ and the same diffusion coefficient, accumulating the physical time via the reweighting rule $t_{\\text{phys}}=\\sum_{n} \\Delta t\\, e^{\\beta V_b(x_n)}$, where $x_n$ is the state at the beginning of the $n$-th time step and $\\Delta t$ is the numerical integration time step. Verify statistically that the distribution of $t_{\\text{phys}}$ matches the distribution of $t$ by using the two-sample Kolmogorov–Smirnov (KS) test. Report a boolean indicating whether the KS test $p$-value is greater than $0.05$.\n3. Use the following test suite. For each case, set $x_0=-x_c/2$, express all times in units of $\\tau_0$, and perform the specified number of independent trajectories for both unbiased and biased simulations. Use a fixed time step $\\Delta t$ and terminate each trajectory upon first reaching $\\{|x| \\ge x_c\\}$.\n   - Case A (happy path): $a=1.0$, $b=4.0$, $\\beta=4.0$, $\\lambda=1.0$, $x_c=0.6$, $\\Delta t=1\\times 10^{-4}$, number of trajectories $N=1200$.\n   - Case B (boundary condition): $a=1.0$, $b=4.0$, $\\beta=4.0$, $\\lambda=0.0$, $x_c=0.6$, $\\Delta t=1\\times 10^{-4}$, number of trajectories $N=1000$.\n   - Case C (edge case with stronger bias and lower temperature): $a=1.0$, $b=6.0$, $\\beta=6.0$, $\\lambda=2.5$, $x_c=0.5$, $\\Delta t=7\\times 10^{-5}$, number of trajectories $N=1200$.\n4. Your program must:\n   - Compute $\\alpha$ for each case via numerical quadrature of integrals over $[-x_c,x_c]$.\n   - Generate unbiased first-passage times $t$ and biased-reweighted physical times $t_{\\text{phys}}$, and perform the two-sample Kolmogorov–Smirnov (KS) test to compare the distributions $t$ and $t_{\\text{phys}}$ for each case, returning a boolean indicating whether the KS test $p$-value exceeds $0.05$.\n   - Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where for each case you output the numerical value of $\\alpha$ (as a float rounded to six decimal places) followed by the boolean KS test decision. The final output must therefore be a list of six items: $[\\alpha_A,\\text{KS}_A,\\alpha_B,\\text{KS}_B,\\alpha_C,\\text{KS}_C]$.\n\nFundamental base to be used:\n- Overdamped Langevin dynamics in one dimension: $dx_t = -\\partial_x U(x_t)\\,dt + \\sqrt{2D}\\,dW_t$, where $U(x)=V(x)$ for unbiased dynamics and $U(x)=V(x)+V_b(x)$ for biased dynamics, $D=1/\\beta$, and $W_t$ is a standard Wiener process.\n- Boltzmann statistics in equilibrium: the stationary density in $B$ is proportional to $e^{-\\beta U(x)}$.\n- The hyperdynamics reweighting rule within the basin $B$: the physical time increment is $d t_{\\text{phys}} = e^{\\beta V_b(x)}\\, dt$.\n- The Kolmogorov–Smirnov (KS) test compares two empirical distribution functions and returns a $p$-value assessing whether the samples can be considered to arise from the same underlying distribution.\n\nAngle units are not applicable. All physical times must be reported in units of $\\tau_0$. The boost factor $\\alpha$ is dimensionless.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5,result6]\").",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It presents a standard application of hyperdynamics theory to a simple one-dimensional system, which is a common pedagogical example in computational statistical physics. All provided parameters and equations are consistent with the principles of statistical mechanics and stochastic dynamics. The ambiguity regarding the characteristic time unit $\\tau_0$ is noted but does not impede the calculation of the required dimensionless boost factor, $\\alpha$, or the scale-invariant Kolmogorov-Smirnov test result. We can therefore proceed with a full solution.\n\nThe solution is divided into two main parts: first, the analytical derivation and numerical calculation of the hyperdynamics boost factor $\\alpha$, and second, the implementation of stochastic simulations to statistically verify the core principle of hyperdynamics.\n\n**1. Derivation and Calculation of the Boost Factor $\\alpha$**\n\nThe stationary probability distribution for a system described by a potential energy $U(x)$ at an inverse temperature $\\beta$ is the Boltzmann distribution, $p(x) \\propto e^{-\\beta U(x)}$.\n\nIn the hyperdynamics simulation, the system evolves under a biased potential $U_b(x) = V(x) + V_b(x)$. The corresponding stationary probability density, when restricted to the basin $B = [-x_c, x_c]$, is given by:\n$$\np_b(x) = \\frac{1}{Z_b} e^{-\\beta (V(x) + V_b(x))} \\quad \\text{for } x \\in B\n$$\nwhere $Z_b$ is the restricted partition function for the biased system, defined by the integral over the basin $B$:\n$$\nZ_b = \\int_{B} e^{-\\beta (V(x) + V_b(x))} dx = \\int_{-x_c}^{x_c} e^{-\\beta (V(x) + V_b(x))} dx\n$$\nThe problem defines the boost factor $\\alpha$ as the ensemble average of the reweighting factor $e^{\\beta V_b(x)}$ over this biased stationary distribution. This average, denoted as $\\overline{e^{\\beta V_b(x)}}_{\\text{biased}}$, is calculated as follows:\n$$\n\\alpha = \\int_{B} e^{\\beta V_b(x)} p_b(x) dx\n$$\nSubstituting the expression for $p_b(x)$ into this integral yields:\n$$\n\\alpha = \\int_{-x_c}^{x_c} e^{\\beta V_b(x)} \\left( \\frac{1}{Z_b} e^{-\\beta (V(x) + V_b(x))} \\right) dx = \\frac{1}{Z_b} \\int_{-x_c}^{x_c} e^{\\beta V_b(x)} e^{-\\beta V(x)} e^{-\\beta V_b(x)} dx\n$$\nThe exponential terms involving the bias potential, $e^{\\beta V_b(x)}$ and $e^{-\\beta V_b(x)}$, cancel each other out, simplifying the expression to:\n$$\n\\alpha = \\frac{1}{Z_b} \\int_{-x_c}^{x_c} e^{-\\beta V(x)} dx\n$$\nWe recognize the integral in the numerator as the restricted partition function of the original, unbiased system, $Z_u = \\int_{-x_c}^{x_c} e^{-\\beta V(x)} dx$. Thus, the boost factor $\\alpha$ is elegantly expressed as the ratio of the unbiased to the biased restricted partition functions:\n$$\n\\alpha = \\frac{Z_u}{Z_b} = \\frac{\\int_{-x_c}^{x_c} e^{-\\beta V(x)} dx}{\\int_{-x_c}^{x_c} e^{-\\beta (V(x) + V_b(x))} dx}\n$$\nGiven the specific forms $V(x) = ax^4 - bx^2$ and $V_b(x) = \\lambda \\max(0, x_c^2 - x^2)$, and noting that for $x \\in [-x_c, x_c]$, the expression simplifies to $V_b(x) = \\lambda(x_c^2 - x^2)$, we obtain the final formula for numerical evaluation:\n$$\n\\alpha = \\frac{\\int_{-x_c}^{x_c} \\exp\\left(-\\beta (ax^4 - bx^2)\\right) dx}{\\int_{-x_c}^{x_c} \\exp\\left(-\\beta (ax^4 - bx^2 + \\lambda(x_c^2 - x^2))\\right) dx}\n$$\nThese one-dimensional integrals are computed using numerical quadrature.\n\n**2. Simulation and Statistical Verification**\n\nThe system's evolution is described by the overdamped Langevin equation, which we discretize using the Euler-Maruyama scheme with a time step $\\Delta t$:\n$$\nx_{n+1} = x_n + F(x_n)\\Delta t + \\sqrt{2D\\Delta t} \\cdot \\mathcal{N}(0,1)\n$$\nHere, $F(x) = -\\partial_x U(x)$ is the force, $D = 1/\\beta$ is the diffusion coefficient, and $\\mathcal{N}(0,1)$ is a standard normal random variable.\n\nFor the **unbiased simulation**, the potential is $U(x) = V(x) = ax^4 - bx^2$, and the force is $F_u(x) = 2bx - 4ax^3$. Each trajectory starts at $x_0 = -x_c/2$ and evolves until it first reaches the boundary $\\{|x| \\ge x_c\\}$. The total elapsed time, $t = N_{\\text{steps}} \\Delta t$, is recorded as the unbiased first-passage time.\n\nFor the **biased (hyperdynamics) simulation**, the potential within the basin is $U(x) = V(x) + V_b(x) = ax^4 - (b+\\lambda)x^2 + \\lambda x_c^2$. The force is $F_b(x) = 2(b+\\lambda)x - 4ax^3$. The trajectory evolves under this modified force, which accelerates the escape from the basin. The physical time is not equivalent to the simulation time. It is reconstructed by accumulating reweighted time steps:\n$$\nt_{\\text{phys}} = \\sum_{n=0}^{N_{\\text{steps}}-1} \\Delta t \\cdot e^{\\beta V_b(x_n)}\n$$\nwhere $x_n$ is the particle's position at the beginning of the $n$-th time step. The accumulated $t_{\\text{phys}}$ upon reaching the boundary is the reweighted first-passage time.\n\nTo **verify the method**, we generate $N$ independent samples of the unbiased first-passage time, $\\{t_i\\}$, and $N$ samples of the biased-reweighted time, $\\{t_{\\text{phys}, i}\\}$. Hyperdynamics theory posits that these two sets of samples should be drawn from the same underlying statistical distribution. We test this hypothesis using the two-sample Kolmogorov-Smirnov (KS) test. The test yields a $p$-value. A $p$-value greater than a chosen significance level (here, $0.05$) indicates that there is no statistical evidence to reject the null hypothesis that the two distributions are identical. The program will report a boolean value (`True` if $p > 0.05$, `False` otherwise) for this test.",
            "answer": "```python\nimport numpy as np\nfrom scipy import integrate, stats\n\ndef calculate_alpha(a, b, beta, lambda_, xc):\n    \"\"\"\n    Calculates the hyperdynamics boost factor alpha via numerical quadrature.\n    alpha = Z_u / Z_b = integral(exp(-beta*V)) / integral(exp(-beta*(V+Vb))).\n    \"\"\"\n\n    def unbiased_integrand(x):\n        \"\"\"Integrand for the unbiased partition function Z_u.\"\"\"\n        V = a * x**4 - b * x**2\n        return np.exp(-beta * V)\n\n    def biased_integrand(x):\n        \"\"\"Integrand for the biased partition function Z_b.\"\"\"\n        V = a * x**4 - b * x**2\n        # Inside the basin [-xc, xc], max(0, xc^2 - x^2) is (xc^2 - x^2)\n        Vb = lambda_ * (xc**2 - x**2)\n        return np.exp(-beta * (V + Vb))\n\n    # Numerical integration over the basin B = [-xc, xc]\n    Z_u, _ = integrate.quad(unbiased_integrand, -xc, xc, limit=200)\n    Z_b, _ = integrate.quad(biased_integrand, -xc, xc, limit=200)\n\n    # Avoid division by zero, though Z_b should always be positive.\n    if Z_b == 0:\n        return np.inf\n    \n    return Z_u / Z_b\n\ndef run_simulations(params):\n    \"\"\"\n    Runs both unbiased and biased simulations to collect first-passage times.\n    \"\"\"\n    a, b, beta, lambda_, xc, dt, N = params['a'], params['b'], params['beta'], params['lambda_'], params['xc'], params['dt'], params['N']\n    \n    D = 1.0 / beta\n    x0 = -xc / 2.0\n    \n    sqrt_2Ddt = np.sqrt(2 * D * dt)\n\n    def simulate_trajectories(is_biased):\n        \"\"\"Helper function to run N trajectories for one type of dynamics.\"\"\"\n        times = np.zeros(N)\n        for i in range(N):\n            x = x0\n            t_physical = 0.0\n            t_simulation = 0.0\n\n            while np.abs(x)  xc:\n                x_n = x  # Position at start of step\n                \n                if is_biased:\n                    force = 2 * (b + lambda_) * x_n - 4 * a * x_n**3\n                else:\n                    force = 2 * b * x_n - 4 * a * x_n**3\n                \n                # Euler-Maruyama step\n                noise_term = sqrt_2Ddt * np.random.randn()\n                x = x_n + force * dt + noise_term\n                \n                # Time accumulation\n                if is_biased:\n                    Vb = lambda_ * (xc**2 - x_n**2)\n                    t_physical += dt * np.exp(beta * Vb)\n                else:\n                    t_simulation += dt\n\n            if is_biased:\n                times[i] = t_physical\n            else:\n                times[i] = t_simulation\n        return times\n\n    unbiased_times = simulate_trajectories(is_biased=False)\n    biased_reweighted_times = simulate_trajectories(is_biased=True)\n    \n    return unbiased_times, biased_reweighted_times\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'a': 1.0, 'b': 4.0, 'beta': 4.0, 'lambda_': 1.0, 'xc': 0.6, 'dt': 1e-4, 'N': 1200},\n        {'a': 1.0, 'b': 4.0, 'beta': 4.0, 'lambda_': 0.0, 'xc': 0.6, 'dt': 1e-4, 'N': 1000},\n        {'a': 1.0, 'b': 6.0, 'beta': 6.0, 'lambda_': 2.5, 'xc': 0.5, 'dt': 7e-5, 'N': 1200},\n    ]\n\n    results = []\n    # Set a seed for reproducibility of the stochastic simulations\n    np.random.seed(42)\n\n    for case in test_cases:\n        # Task 1: Compute boost factor alpha\n        alpha = calculate_alpha(case['a'], case['b'], case['beta'], case['lambda_'], case['xc'])\n        results.append(str(round(alpha, 6)))\n\n        # Task 2  3: Run simulations and perform KS test\n        t_unbiased, t_phys_biased = run_simulations(case)\n        \n        # Two-sample Kolmogorov-Smirnov test\n        _ks_statistic, p_value = stats.ks_2samp(t_unbiased, t_phys_biased)\n        \n        # Report boolean for p-value > 0.05\n        ks_decision = p_value > 0.05\n        results.append(str(ks_decision))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While theory dictates that the bias potential $V_b$ must vanish at the transition state, a practical challenge lies in constructing a function that robustly enforces this. This exercise explores a powerful and common technique: building the bias potential from the local curvature of the energy landscape, as captured by the Hessian's minimum eigenvalue, $\\lambda_{\\min}$ . You will implement a bias based on this idea and, critically, engineer a smooth kernel function to prevent spurious bias in the sensitive saddle region, a crucial step for real-world applications.",
            "id": "3457977",
            "problem": "You are asked to formalize and implement a hyperdynamics bias potential that depends on the smallest eigenvalue of the Hessian matrix along a molecular dynamics trajectory. Begin from the following base: the rate of rare events under Transition State Theory (TST) is unchanged by adding a non-negative bias potential that is identically zero on the transition-state dividing surface. For a trajectory with states indexed by discrete time samples, let the minimal eigenvalue of the Hessian at a sampled configuration be denoted by $\\lambda_{\\min}$, which can be negative in saddle regions and positive in basins. The goal is to construct a bias potential based on a threshold on $\\lambda_{\\min}$ while enforcing that the bias vanishes in a small band around the saddle region to preserve TST consistency.\n\nUsing only fundamental principles and definitions, carry out the following tasks in a single, complete program. All energies must be expressed in electron-volts, written as $\\mathrm{eV}$, and inverse energies as $\\mathrm{eV}^{-1}$. Angles are not used. Your program must use the exact numeric parameter values and test arrays detailed below.\n\n1. Define a naive bias potential for a given sample as $V_b^{\\mathrm{naive}}(\\lambda_{\\min}) = c \\,\\max\\!\\big(0,\\ \\lambda^* - \\lambda_{\\min}\\big)$, where $c$ has units $\\mathrm{eV}$ per unit of $\\lambda_{\\min}$, and $\\lambda^*$ is a chosen threshold for $\\lambda_{\\min}$. This function is non-negative by construction.\n\n2. Recognizing that in anharmonic saddle regions with $\\lambda_{\\min} \\approx 0$ the naive bias is generally nonzero, you must introduce a smoothing kernel $K(\\lambda_{\\min};\\delta)$ that enforces $V_b=0$ for $|\\lambda_{\\min}|\\delta$ while transitioning smoothly to no suppression away from the saddle region. Construct $K$ to be twice continuously differentiable and to satisfy\n   - $K(\\lambda_{\\min};\\delta) = 0$ for $|\\lambda_{\\min}| \\le \\delta$,\n   - $K(\\lambda_{\\min};\\delta) = 1$ for $|\\lambda_{\\min}| \\ge 2\\delta$,\n   - Monotonic increase with respect to $|\\lambda_{\\min}|$ on the interval $\\delta  |\\lambda_{\\min}|  2\\delta$,\n   - Continuous first and second derivatives at $|\\lambda_{\\min}|=\\delta$ and $|\\lambda_{\\min}|=2\\delta$.\n   To achieve this, construct the kernel explicitly by mapping $|\\lambda_{\\min}|$ to a normalized coordinate $t \\in [0,1]$ via $t = \\big(|\\lambda_{\\min}| - \\delta\\big)/\\delta$ and using the minimal-degree polynomial that satisfies $S(0)=0$, $S(1)=1$, $S'(0)=0$, $S'(1)=0$, $S''(0)=0$, $S''(1)=0$. Define $K(\\lambda_{\\min};\\delta) = 0$ for $t \\le 0$, $K(\\lambda_{\\min};\\delta) = 1$ for $t \\ge 1$, and $K(\\lambda_{\\min};\\delta) = S(t)$ for $t \\in (0,1)$.\n\n3. Define the smoothed bias potential as $V_b^{\\mathrm{sm}}(\\lambda_{\\min}) = K(\\lambda_{\\min};\\delta)\\,V_b^{\\mathrm{naive}}(\\lambda_{\\min})$.\n\n4. For a given inverse thermal energy $\\beta$ (with units $\\mathrm{eV}^{-1}$), define the instantaneous hyperdynamics boost factor for a sample as $b = \\exp\\!\\big(\\beta\\,V_b\\big)$, and the time-average across a discrete trajectory segment as the arithmetic mean $\\langle b \\rangle$ over the samples.\n\n5. For each trajectory segment, quantify the spurious bias injected into the saddle band by computing the maximum of $V_b$ over samples with $|\\lambda_{\\min}|\\delta$; define this quantity separately for the naive and smoothed biases.\n\n6. Implement a numerical differentiability check for your kernel: at $x=\\delta$ and $x=2\\delta$, verify two-sided continuity of the first and second derivatives with respect to $x=|\\lambda_{\\min}|$ using one-sided finite differences with step $\\varepsilon=\\delta/1000$. Specifically, compute left and right first derivatives using first-order one-sided differences and left and right second derivatives using second-order one-sided differences, and return a boolean that is true if the absolute differences between left and right derivatives at each point are below $10^{-6}$ for the first derivative and below $10^{-4}$ for the second derivative.\n\nUse the following fixed parameters, which are held constant across all tests:\n- Inverse thermal energy $\\beta = 20.0\\ \\mathrm{eV}^{-1}$ (write the number as $20.0$).\n- Bias scaling $c = 0.02\\ \\mathrm{eV}$ per unit of $\\lambda_{\\min}$ (write the number as $0.02$).\n- Threshold $\\lambda^* = 1.0$ (write the number as $1.0$).\n- Smoothing half-width $\\delta = 0.05$ (write the number as $0.05$).\n\nApply your implementation to the following test suite of four trajectory segments, each given as an ordered list of $\\lambda_{\\min}$ samples:\n- Test A (basin regime away from saddle): $\\big[0.7,\\ 0.8,\\ 0.9,\\ 0.85,\\ 0.75\\big]$.\n- Test B (anharmonic saddle band): $\\big[-0.02,\\ 0.01,\\ -0.03,\\ 0.0,\\ 0.02,\\ -0.01\\big]$.\n- Test C (boundary checks around $\\delta$ and $2\\delta$): $\\big[-0.05,\\ 0.05,\\ -0.10,\\ 0.10,\\ -0.049,\\ 0.049,\\ -0.051,\\ 0.051,\\ -0.099,\\ 0.099,\\ -0.101,\\ 0.101\\big]$.\n- Test D (deep saddle-like region): $\\big[-0.5,\\ -0.2,\\ -0.3,\\ -0.25,\\ -0.4\\big]$.\n\nFor each test segment, produce the following outputs in order:\n- The time-averaged boost factor for the naive bias, $\\langle \\exp(\\beta V_b^{\\mathrm{naive}}) \\rangle$, as a floating-point number.\n- The time-averaged boost factor for the smoothed bias, $\\langle \\exp(\\beta V_b^{\\mathrm{sm}}) \\rangle$, as a floating-point number.\n- The maximum spurious naive bias within the saddle band $|\\lambda_{\\min}|\\delta$, as a floating-point number in $\\mathrm{eV}$.\n- The maximum spurious smoothed bias within the saddle band $|\\lambda_{\\min}|\\delta$, as a floating-point number in $\\mathrm{eV}$.\n- The kernel differentiability check boolean described above.\n\nYour program should produce a single line of output containing the results as a comma-separated list of per-test results, each per-test result being a list with the five entries above, enclosed in square brackets. For example, your final output must look like a single line of the form\n$[ [a_1,a_2,a_3,a_4,a_5], [b_1,b_2,b_3,b_4,b_5], [c_1,c_2,c_3,c_4,c_5], [d_1,d_2,d_3,d_4,d_5] ]$\nwith the placeholders replaced by the computed values. All floating-point outputs must be standard decimal representations. No other text should be printed.",
            "solution": "We construct a bias for hyperdynamics that preserves Transition State Theory (TST) rates by enforcing that the bias vanishes on the transition-state dividing surface. The fundamental base is the TST statement that adding a non-negative bias potential $V_b$ that is identically zero on the dividing surface leaves the crossing probability unchanged, and that accelerated time can be recovered by reweighting with the factor $\\exp(\\beta V_b)$, where $\\beta$ is the inverse thermal energy with units $\\mathrm{eV}^{-1}$. For a discrete time series indexed by $i$, the naive instantaneous boost factor is $b_i^{\\mathrm{naive}}=\\exp(\\beta V_{b,i}^{\\mathrm{naive}})$, and the time-averaged boost factor is the arithmetic mean $\\langle b^{\\mathrm{naive}}\\rangle=\\frac{1}{N}\\sum_{i=1}^N b_i^{\\mathrm{naive}}$, with the same definition for the smoothed counterpart.\n\n1. Given the smallest Hessian eigenvalue $\\lambda_{\\min}$, define a naive bias\n$$\nV_b^{\\mathrm{naive}}(\\lambda_{\\min}) \\;=\\; c\\,\\max\\!\\big(0,\\ \\lambda^*-\\lambda_{\\min}\\big),\n$$\nwith $c$ in $\\mathrm{eV}$ per unit of $\\lambda_{\\min}$. This choice is non-negative because it is a positive constant times a maximum with zero. However, in saddle regions where $\\lambda_{\\min}\\approx 0$ (and may be slightly negative due to anharmonicity), the naive bias remains positive whenever $\\lambda^*-\\lambda_{\\min}>0$, which violates the TST requirement of a vanishing bias at the dividing surface. Therefore, we need a smoothing factor that removes the bias in a small band $|\\lambda_{\\min}|\\delta$ around zero.\n\n2. We require a kernel $K(\\lambda_{\\min};\\delta)$ with the properties\n- $K(\\lambda_{\\min};\\delta)=0$ for $|\\lambda_{\\min}|\\le\\delta$,\n- $K(\\lambda_{\\min};\\delta)=1$ for $|\\lambda_{\\min}|\\ge 2\\delta$,\n- Monotonic increase with respect to $|\\lambda_{\\min}|$ on $\\delta|\\lambda_{\\min}|2\\delta$,\n- Twice continuous differentiability at the junctions $|\\lambda_{\\min}|=\\delta$ and $|\\lambda_{\\min}|=2\\delta$.\n\nTo obtain a minimal-degree polynomial that satisfies smoothness constraints, we introduce the normalized coordinate\n$$\nt \\;=\\; \\frac{|\\lambda_{\\min}| - \\delta}{\\delta},\n$$\nwhich maps $|\\lambda_{\\min}|=\\delta$ to $t=0$ and $|\\lambda_{\\min}|=2\\delta$ to $t=1$. We seek a polynomial $S(t)$ such that\n$$\nS(0)=0,\\quad S(1)=1,\\quad S'(0)=0,\\quad S'(1)=0,\\quad S''(0)=0,\\quad S''(1)=0.\n$$\nThe minimal-degree polynomial satisfying six independent linear conditions is quintic, $S(t)=a_0+a_1 t+a_2 t^2+a_3 t^3+a_4 t^4+a_5 t^5$. Enforcing the conditions yields a linear system for the coefficients. Setting $a_0=0$ from $S(0)=0$ and $a_1=0$, $a_2=0$ from $S'(0)=0$ and $S''(0)=0$, and using the endpoint conditions at $t=1$:\n$$\n\\begin{aligned}\nS(1)=a_3+a_4+a_5=1,\\\\\nS'(1)=3a_3+4a_4+5a_5=0,\\\\\nS''(1)=6a_3+12a_4+20a_5=0,\n\\end{aligned}\n$$\nwe solve for $a_3$, $a_4$, $a_5$. Subtracting twice the second equation from the third gives $(6a_3+12a_4+20a_5) - 2(3a_3+4a_4+5a_5) = 0$, hence $4a_4+10a_5=0$ and $a_4=-\\tfrac{5}{2}a_5$. Substituting into the second equation yields $3a_3+4(-\\tfrac{5}{2}a_5)+5a_5=3a_3-10a_5+5a_5=3a_3-5a_5=0$, so $a_3=\\tfrac{5}{3}a_5$. Using the first equation, $\\tfrac{5}{3}a_5-\\tfrac{5}{2}a_5+a_5=1$ which simplifies to $\\big(\\tfrac{5}{3}-\\tfrac{5}{2}+1\\big)a_5=1$. The coefficient in parentheses is $\\tfrac{10}{6}-\\tfrac{15}{6}+\\tfrac{6}{6}=\\tfrac{1}{6}$, so $a_5=6$. Then $a_3=\\tfrac{5}{3}\\cdot 6=10$ and $a_4=-\\tfrac{5}{2}\\cdot 6=-15$. Therefore\n$$\nS(t) \\;=\\; 10 t^3 - 15 t^4 + 6 t^5 \\;=\\; 6 t^5 - 15 t^4 + 10 t^3,\n$$\nwhich is the well-known quintic smoothstep that is $C^2$-continuous. We then define\n$$\nK(\\lambda_{\\min};\\delta) \\;=\\;\n\\begin{cases}\n0,  t\\le 0,\\\\\nS(t),  0 t 1,\\\\\n1,  t\\ge 1,\n\\end{cases}\n\\qquad\\text{with}\\quad t=\\dfrac{|\\lambda_{\\min}|-\\delta}{\\delta}.\n$$\nBy construction, $K$ is monotonically increasing in $|\\lambda_{\\min}|$ on $\\delta|\\lambda_{\\min}|2\\delta$, and its first and second derivatives match continuously at the endpoints due to $S'(0)=S'(1)=0$ and $S''(0)=S''(1)=0$ with the left and right pieces being constants.\n\n3. The smoothed bias is\n$$\nV_b^{\\mathrm{sm}}(\\lambda_{\\min}) \\;=\\; K(\\lambda_{\\min};\\delta)\\, V_b^{\\mathrm{naive}}(\\lambda_{\\min}).\n$$\nFor $|\\lambda_{\\min}|\\le \\delta$ we have $K=0$ and hence $V_b^{\\mathrm{sm}}=0$, satisfying the TST requirement near the dividing surface. For $|\\lambda_{\\min}|\\ge 2\\delta$, $K=1$ and the bias reduces to the naive form, preserving acceleration deep in basins or far from the immediate saddle-band.\n\n4. For each time series segment with samples $\\{\\lambda_{\\min,i}\\}_{i=1}^N$, we compute the instantaneous boost factors $b_i^{\\mathrm{naive}}=\\exp(\\beta V_{b,i}^{\\mathrm{naive}})$ and $b_i^{\\mathrm{sm}}=\\exp(\\beta V_{b,i}^{\\mathrm{sm}})$, and then the averages\n$$\n\\left\\langle b^{\\mathrm{naive}}\\right\\rangle \\;=\\; \\frac{1}{N}\\sum_{i=1}^N \\exp\\!\\big(\\beta V_{b,i}^{\\mathrm{naive}}\\big),\\qquad\n\\left\\langle b^{\\mathrm{sm}}\\right\\rangle \\;=\\; \\frac{1}{N}\\sum_{i=1}^N \\exp\\!\\big(\\beta V_{b,i}^{\\mathrm{sm}}\\big).\n$$\nThe spurious bias within the saddle band is quantified by\n$$\n\\max_{i:\\ |\\lambda_{\\min,i}|\\delta} V_{b,i}^{\\mathrm{naive}},\\qquad\n\\max_{i:\\ |\\lambda_{\\min,i}|\\delta} V_{b,i}^{\\mathrm{sm}},\n$$\nwith the convention that the maximum over an empty set is $0$.\n\n5. Numerical differentiability check. At $x=\\delta$ and $x=2\\delta$ with $x=|\\lambda_{\\min}|$, we define a step $\\varepsilon=\\delta/1000$ and compute one-sided finite-difference approximations for derivatives. For a function $f(x)=K(x;\\delta)$ with $x\\ge 0$, the left first derivative at $x_0$ is approximated by\n$$\nf'_-(x_0)\\;\\approx\\;\\frac{f(x_0)-f(x_0-\\varepsilon)}{\\varepsilon},\n$$\nand the right first derivative by\n$$\nf'_+(x_0)\\;\\approx\\;\\frac{f(x_0+\\varepsilon)-f(x_0)}{\\varepsilon}.\n$$\nSimilarly, the left second derivative can be approximated with\n$$\nf''_-(x_0)\\;\\approx\\;\\frac{f(x_0)-2f(x_0-\\varepsilon)+f(x_0-2\\varepsilon)}{\\varepsilon^2},\n$$\nand the right second derivative with\n$$\nf''_+(x_0)\\;\\approx\\;\\frac{f(x_0+2\\varepsilon)-2f(x_0+\\varepsilon)+f(x_0)}{\\varepsilon^2}.\n$$\nWe then check that $|f'_+(x_0)-f'_-(x_0)|10^{-6}$ and $|f''_+(x_0)-f''_-(x_0)|10^{-4}$ for $x_0=\\delta$ and $x_0=2\\delta$. Because $K$ is constant on $[0,\\delta]$ and $[2\\delta,\\infty)$ and $S'(0)=S'(1)=0$, $S''(0)=S''(1)=0$, these differences should be near zero within numerical precision.\n\n6. Parameters and tests. We use fixed parameters $\\beta=20.0\\ \\mathrm{eV}^{-1}$, $c=0.02\\ \\mathrm{eV}$ per unit of $\\lambda_{\\min}$, $\\lambda^*=1.0$, and $\\delta=0.05$. The four trajectory segments are\n- Test A: $\\big[0.7,\\ 0.8,\\ 0.9,\\ 0.85,\\ 0.75\\big]$,\n- Test B: $\\big[-0.02,\\ 0.01,\\ -0.03,\\ 0.0,\\ 0.02,\\ -0.01\\big]$,\n- Test C: $\\big[-0.05,\\ 0.05,\\ -0.10,\\ 0.10,\\ -0.049,\\ 0.049,\\ -0.051,\\ 0.051,\\ -0.099,\\ 0.099,\\ -0.101,\\ 0.101\\big]$,\n- Test D: $\\big[-0.5,\\ -0.2,\\ -0.3,\\ -0.25,\\ -0.4\\big]$.\n\n7. Output specification. For each test, output a list with five entries: $\\langle \\exp(\\beta V_b^{\\mathrm{naive}}) \\rangle$, $\\langle \\exp(\\beta V_b^{\\mathrm{sm}}) \\rangle$, $\\max_{|\\lambda_{\\min}|\\delta} V_b^{\\mathrm{naive}}$ in $\\mathrm{eV}$, $\\max_{|\\lambda_{\\min}|\\delta} V_b^{\\mathrm{sm}}$ in $\\mathrm{eV}$, and the differentiability check boolean. Aggregate the four per-test lists into a single list and print that single list on one line, with no additional text.\n\nAlgorithmic steps to implement:\n- Implement $S(t)=6t^5-15t^4+10t^3$ and the piecewise $K(\\lambda_{\\min};\\delta)$ using $t=\\big(|\\lambda_{\\min}|-\\delta\\big)/\\delta$ with clamping for $t\\le 0$ and $t\\ge 1$.\n- Compute $V_b^{\\mathrm{naive}}$ and $V_b^{\\mathrm{sm}}$ for each sample.\n- Compute the averages of $\\exp(\\beta V_b)$.\n- Compute the maximum $V_b$ within the set $\\{i:\\ |\\lambda_{\\min,i}|\\delta\\}$ with $0$ if the set is empty.\n- Implement the one-sided finite-difference checks at $x=\\delta$ and $x=2\\delta$ using $\\varepsilon=\\delta/1000$.\n\nThe numerical outputs are dimensionless for the boost factors and in $\\mathrm{eV}$ for the biases. All required outputs are floating-point numbers or booleans.",
            "answer": "```python\nimport numpy as np\n\ndef smoothstep_quintic(t):\n    # S(t) = 6 t^5 - 15 t^4 + 10 t^3 for t in [0,1]\n    return ((6.0 * t - 15.0) * t + 10.0) * t**3\n\ndef kernel_K(lam, delta):\n    # K depends on |lambda_min|\n    x = abs(lam)\n    if x = delta:\n        return 0.0\n    elif x >= 2.0 * delta:\n        return 1.0\n    else:\n        t = (x - delta) / delta  # in (0,1)\n        return smoothstep_quintic(t)\n\ndef bias_naive(lam, c, lam_star):\n    return c * max(0.0, lam_star - lam)\n\ndef bias_smoothed(lam, c, lam_star, delta):\n    return kernel_K(lam, delta) * bias_naive(lam, c, lam_star)\n\ndef avg_boost(lams, beta, c, lam_star, delta=None):\n    if delta is None:\n        vb = np.array([bias_naive(l, c, lam_star) for l in lams], dtype=float)\n    else:\n        vb = np.array([bias_smoothed(l, c, lam_star, delta) for l in lams], dtype=float)\n    return float(np.mean(np.exp(beta * vb)))\n\ndef max_spurious_bias(lams, c, lam_star, delta, smoothed=False):\n    mask = np.array([abs(l)  delta for l in lams], dtype=bool)\n    if not np.any(mask):\n        return 0.0\n    if smoothed:\n        arr = np.array([bias_smoothed(l, c, lam_star, delta) for l in lams], dtype=float)\n    else:\n        arr = np.array([bias_naive(l, c, lam_star) for l in lams], dtype=float)\n    return float(np.max(arr[mask])) if arr[mask].size > 0 else 0.0\n\ndef kernel_derivative_checks(delta, atol1=1e-6, atol2=1e-4):\n    # Check at x = delta, x = 2*delta using one-sided finite differences\n    eps = delta / 1000.0 if delta > 0 else 1e-9\n\n    def Kx(x):\n        # K as a function of x = |lambda_min|, x >= 0\n        if x = delta:\n            return 0.0\n        elif x >= 2.0 * delta:\n            return 1.0\n        else:\n            t = (x - delta) / delta\n            return smoothstep_quintic(t)\n\n    def first_deriv_left(x0):\n        # (f(x0) - f(x0 - eps)) / eps\n        return (Kx(x0) - Kx(x0 - eps)) / eps\n\n    def first_deriv_right(x0):\n        # (f(x0 + eps) - f(x0)) / eps\n        return (Kx(x0 + eps) - Kx(x0)) / eps\n\n    def second_deriv_left(x0):\n        # (f(x0) - 2 f(x0 - eps) + f(x0 - 2 eps)) / eps^2\n        return (Kx(x0) - 2.0 * Kx(x0 - eps) + Kx(x0 - 2.0 * eps)) / (eps ** 2)\n\n    def second_deriv_right(x0):\n        # (f(x0 + 2 eps) - 2 f(x0 + eps) + f(x0)) / eps^2\n        return (Kx(x0 + 2.0 * eps) - 2.0 * Kx(x0 + eps) + Kx(x0)) / (eps ** 2)\n\n    checks = []\n    for x0 in (delta, 2.0 * delta):\n        dL = first_deriv_left(x0)\n        dR = first_deriv_right(x0)\n        ddL = second_deriv_left(x0)\n        ddR = second_deriv_right(x0)\n        ok1 = abs(dR - dL)  atol1\n        ok2 = abs(ddR - ddL)  atol2\n        checks.append(ok1 and ok2)\n    return all(checks)\n\ndef solve():\n    # Fixed parameters\n    beta = 20.0  # eV^{-1}\n    c = 0.02     # eV per unit of lambda_min\n    lam_star = 1.0\n    delta = 0.05\n\n    # Test suite: lists of lambda_min samples\n    tests = [\n        [0.7, 0.8, 0.9, 0.85, 0.75],  # Test A\n        [-0.02, 0.01, -0.03, 0.0, 0.02, -0.01],  # Test B\n        [-0.05, 0.05, -0.10, 0.10, -0.049, 0.049, -0.051, 0.051, -0.099, 0.099, -0.101, 0.101],  # Test C\n        [-0.5, -0.2, -0.3, -0.25, -0.4],  # Test D\n    ]\n\n    results = []\n    for lams in tests:\n        # Average boost factors\n        avg_boost_naive_val = avg_boost(lams, beta, c, lam_star, delta=None)\n        avg_boost_smoothed_val = avg_boost(lams, beta, c, lam_star, delta=delta)\n        # Spurious bias in saddle band\n        max_spurious_naive = max_spurious_bias(lams, c, lam_star, delta, smoothed=False)\n        max_spurious_smoothed = max_spurious_bias(lams, c, lam_star, delta, smoothed=True)\n        # Kernel differentiability boolean\n        kernel_ok = kernel_derivative_checks(delta)\n        results.append([\n            avg_boost_naive_val,\n            avg_boost_smoothed_val,\n            max_spurious_naive,\n            max_spurious_smoothed,\n            kernel_ok\n        ])\n\n    # Print results as a single-line list of lists\n    # Ensure default string conversion for booleans and floats\n    print(str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "In complex materials systems, multiple escape pathways from a stable state often compete. A key requirement for any accelerated dynamics method is the preservation of the branching probabilities between these exits. This practice investigates this critical feature of hyperdynamics, first by confirming its validity in an ideal two-exit system, and then by exploring a subtle but important failure mode . You will discover how a bias potential's *gradient* near a dividing surface can alter forces and corrupt branching ratios, even when the bias value on the surface itself is zero.",
            "id": "3457997",
            "problem": "Consider a basin region in a two-dimensional configuration space with two distinct exit channels that terminate on two non-overlapping dividing surfaces $S_1$ and $S_2$. Let the physical potential energy be $U(\\mathbf{r})$, with $\\mathbf{r} = (x,y)$, and let temperature be $T$ so that the inverse thermal energy is $\\beta = 1/(k_\\mathrm{B} T)$, where $k_\\mathrm{B}$ is the Boltzmann constant. A hyperdynamics bias potential $V_b(\\mathbf{r})$ is added to the physical potential to accelerate rare-event escape while aiming to preserve the multi-exit branching probabilities. The transition state theory (TST) rate from the basin to exit $i$ is proportional to the reactive flux across $S_i$, and the branching probability $\\pi_i$ is defined by the ratio of that flux to the total flux, $\\pi_i = J_i / \\sum_j J_j$. Energies must be treated in units of $k_\\mathrm{B} T$ (so $\\beta$ is dimensionless), and geometry is dimensionless.\n\nStarting from the canonical equilibrium distribution and the TST definition of reactive flux, derive and implement a numerical scheme to:\n1. Compute the reactive flux $J_i$ to each exit $i$ and the corresponding branching probabilities $\\pi_i$.\n2. Demonstrate that hyperdynamics preserves multi-exit branching when the bias potential $V_b(\\mathbf{r})$ vanishes pointwise on every dividing surface $S_i$, by verifying that $\\sum_i \\pi_i = 1$ and that each $\\pi_i$ is invariant under $V_b$ in this case.\n3. Construct a counterexample in which the bias potential $V_b(\\mathbf{r})$ modulates the forces in a narrow channel adjacent to one dividing surface such that $V_b(\\mathbf{r})$ has a nonzero normal gradient in a thin strip of thickness $\\delta$ immediately interior to $S_1$ (allowing $V_b$ to vanish on $S_1$ itself). Quantify the change $\\Delta \\pi_i$ in terms of the local gradient of $V_b$ along the strip.\n\nYou must use the following mathematically specified test geometry that compresses the multidimensional flux integral into a tractable one-dimensional representation along each dividing surface, together with an interior strip of finite thickness to admit force-modulation effects:\n\n- Two dividing surfaces are taken as vertical line segments at $x=+L$ and $x=-L$, with $y \\in [-W, W]$, denoted $S_1$ and $S_2$, respectively.\n- The physical potential restricted to each dividing surface is\n$$\nU|_{S_1}(y) = E_0 + b_1 y^2, \\quad U|_{S_2}(y) = E_0 + b_2 y^2,\n$$\nwhere $E_0 > 0$ sets the baseline barrier and $b_1, b_2 > 0$ set the local curvature shaping the channel width along $y$, all in units of $k_\\mathrm{B} T$.\n- The TST reactive flux through a finite-thickness strip immediately interior to each dividing surface is approximated by integrating the Boltzmann factor across the strip thickness $\\xi \\in [0, \\delta]$ along the inward normal direction, where $\\xi = L - x$ for $S_1$ and $\\xi = x + L$ for $S_2$. In the absence of any $x$-dependence in $U$ across the strip, the un-biased flux scales with $\\delta$.\n- A hyperdynamics bias $V_b(\\mathbf{r})$ is introduced in two ways:\n  - For the invariance tests, $V_b(\\mathbf{r})$ is chosen to be strictly zero throughout both strips (and on $S_1$ and $S_2$), while possibly nonzero elsewhere in the basin.\n  - For the counterexample, $V_b(\\mathbf{r})$ is defined in the strip adjacent to $S_1$ (with $\\xi \\in [0,\\delta]$) by $V_b(\\xi,y) = g \\, \\xi \\, f(y)$, with $f(y) = \\exp\\!\\left(-y^2/\\sigma_y^2\\right)$, and $V_b(\\mathbf{r}) = 0$ in the strip adjacent to $S_2$. Here $g$ is a constant gradient magnitude in the inward normal direction and $\\sigma_y$ sets the lateral modulation width, both dimensionless. This form ensures $V_b$ vanishes exactly on $S_1$ ($\\xi=0$) but has a nonzero normal gradient across the strip, thereby modulating forces before crossing.\n\nUnder these specifications, the TST strip-integrated reactive flux to exit $i$ is\n$$\nJ_i = \\int_{-W}^{W} \\int_{0}^{\\delta} \\exp\\!\\left(-\\beta \\left[ U|_{S_i}(y) + V_b(\\xi,y) \\right] \\right) \\, d\\xi \\, dy,\n$$\nand the branching probabilities are $\\pi_i = J_i / (J_1 + J_2)$. You must compute:\n- $\\pi_1$ and $\\pi_2$ for the cases described below.\n- Verify $\\sum_i \\pi_i = 1$ in all cases.\n- Verify invariance of $\\pi_i$ under $V_b$ when $V_b$ vanishes throughout the strips.\n- Quantify the counterexample by reporting $\\Delta \\pi_1 = \\pi_1^\\text{biased} - \\pi_1^\\text{unbiased}$ and a first-order gradient-based estimate for $\\Delta \\pi_1$ obtained by expanding the inner strip integral for $S_1$ to leading order in $g$, namely by treating\n$$\n\\int_0^\\delta \\exp\\!\\left(-\\beta g \\xi f(y)\\right) \\, d\\xi \\approx \\delta - \\frac{1}{2} \\beta g \\delta^2 f(y),\n$$\nand propagating this correction into $\\Delta \\pi_1$.\n\nDesign a complete program that implements the above flux computations using numerical quadrature over $y$ with a uniform grid and exact integration or numerical quadrature over $\\xi$ as needed. Work in units where energies are in $k_\\mathrm{B} T$ and $\\beta = 1$.\n\nTest Suite:\n- Case A (asymmetric channels, invariance check): $E_0 = 6$, $b_1 = 4$, $b_2 = 3$, $L = 1$, $W = 2$, $\\delta = 0.05$, $\\sigma_y = 0.4$, $\\beta = 1$, and $V_b(\\mathbf{r}) = 0$ in both strips. Compute $\\pi_1$ and $\\pi_2$ and verify $\\pi_1 + \\pi_2 = 1$. Introduce any interior-only $V_b$ that remains zero throughout both strips and verify the $\\pi_i$ remain identical to the unbiased values (numerically within a tolerance).\n- Case B (counterexample with force modulation near $S_1$): Use the same $E_0$, $b_1$, $b_2$, $L$, $W$, $\\delta$, $\\sigma_y$, and $\\beta$ as Case A. Set $V_b(\\xi,y) = g \\, \\xi \\, \\exp\\!\\left(-y^2/\\sigma_y^2\\right)$ in the strip adjacent to $S_1$ and $V_b = 0$ in the strip adjacent to $S_2$. Use $g = 5.0$. Compute the actual $\\Delta \\pi_1$ and the first-order gradient-based estimate for $\\Delta \\pi_1$ derived from the leading-order expansion in $g$.\n- Case C (strong interior bias that still vanishes in the strips, invariance stress test): Use the same $E_0$, $b_1$, $b_2$, $L$, $W$, $\\delta$, $\\sigma_y$, and $\\beta$ as Case A. Choose a large-amplitude interior $V_b(\\mathbf{r})$ that is identically zero in both strips. Verify that the computed $\\pi_i$ match the unbiased values within the specified numerical tolerance.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order and types:\n- Case A: two booleans, where the first boolean confirms $\\pi_1 + \\pi_2 = 1$ within a tolerance of $10^{-12}$, and the second boolean confirms invariance of $\\pi_i$ under interior-only $V_b$ within a tolerance of $10^{-12}$.\n- Case B: two floats, the actual $\\Delta \\pi_1$ and the first-order gradient-based estimate for $\\Delta \\pi_1$, each reported as a Python float.\n- Case C: one boolean confirming invariance of $\\pi_i$ under the strong interior-only $V_b$ within a tolerance of $10^{-12}$.\n\nThus the final output format must be exactly: \"[bool,bool,float,float,bool]\".",
            "solution": "The problem requires an analysis of hyperdynamics-induced changes to branching probabilities in a two-exit system, based on Transition State Theory (TST). We will first validate the theoretical basis, then derive the expressions for numerical computation for the specified test cases. We work in dimensionless units where energies are expressed in multiples of $k_\\mathrm{B} T$, so the inverse thermal energy $\\beta = 1/(k_\\mathrm{B} T)$ is set to $\\beta=1$.\n\nThe foundation of the calculation is the TST reactive flux $J_i$ through a thin strip of thickness $\\delta$ adjacent to a dividing surface $S_i$. The problem provides the expression for this flux:\n$$\nJ_i = \\int_{-W}^{W} \\int_{0}^{\\delta} \\exp\\!\\left(-\\beta \\left[ U|_{S_i}(y) + V_b(\\xi,y) \\right] \\right) \\, d\\xi \\, dy\n$$\nwhere $\\mathbf{r}=(x,y)$, $U|_{S_i}(y)$ is the physical potential on the dividing surface, $V_b(\\xi,y)$ is the bias potential in the strip, and $\\xi$ is the coordinate normal to the surface, extending from $\\xi=0$ (on the surface) to $\\xi=\\delta$ (into the basin). The branching probability to exit $i$ is $\\pi_i = J_i / \\sum_k J_k$.\n\nThe surfaces $S_1$ and $S_2$ are located at $x=+L$ and $x=-L$ respectively, for $y \\in [-W, W]$. The potentials on these surfaces are given by $U|_{S_1}(y) = E_0 + b_1 y^2$ and $U|_{S_2}(y) = E_0 + b_2 y^2$.\n\n**Case A  C: Invariance of Branching Probabilities**\n\nIn these cases, the hyperdynamics bias potential $V_b(\\mathbf{r})$ is constructed to be identically zero within the reactant strips adjacent to both dividing surfaces. That is, $V_b(\\xi,y) = 0$ for all relevant $\\xi \\in [0, \\delta]$ and $y \\in [-W, W]$ for both $i=1$ and $i=2$. The value of $V_b$ elsewhere in the basin is irrelevant for this TST calculation, as the flux integral's domain is confined to these strips.\n\nWith $V_b(\\xi,y)=0$ and $\\beta=1$, the flux integral for exit $i$ becomes:\n$$\nJ_i^{\\text{unbiased}} = \\int_{-W}^{W} \\int_{0}^{\\delta} \\exp\\!\\left(-(E_0 + b_i y^2)\\right) \\, d\\xi \\, dy\n$$\nThe integrand is independent of $\\xi$, so the inner integral is trivial:\n$$\n\\int_{0}^{\\delta} d\\xi = \\delta\n$$\nThis simplifies the flux to a one-dimensional integral over $y$:\n$$\nJ_i^{\\text{unbiased}} = \\delta \\int_{-W}^{W} \\exp\\!\\left(-E_0 - b_i y^2\\right) \\, dy = \\delta e^{-E_0} \\int_{-W}^{W} e^{-b_i y^2} \\, dy\n$$\nLet's define the integral $G(b, W) = \\int_{-W}^{W} e^{-b y^2} \\, dy$. This integral will be computed using numerical quadrature.\nThe fluxes are $J_1^{\\text{unbiased}} = \\delta e^{-E_0} G(b_1, W)$ and $J_2^{\\text{unbiased}} = \\delta e^{-E_0} G(b_2, W)$.\n\nThe corresponding branching probabilities are:\n$$\n\\pi_1^{\\text{unbiased}} = \\frac{J_1^{\\text{unbiased}}}{J_1^{\\text{unbiased}} + J_2^{\\text{unbiased}}} = \\frac{\\delta e^{-E_0} G(b_1, W)}{\\delta e^{-E_0} (G(b_1, W) + G(b_2, W))} = \\frac{G(b_1, W)}{G(b_1, W) + G(b_2, W)}\n$$\n$$\n\\pi_2^{\\text{unbiased}} = \\frac{G(b_2, W)}{G(b_1, W) + G(b_2, W)}\n$$\nFrom these expressions, it is clear that $\\pi_1^{\\text{unbiased}} + \\pi_2^{\\text{unbiased}} = 1$. This confirms the first part of Case A. The second part of Case A and all of Case C involves a bias potential that is non-zero in the basin interior but zero in the strips. As shown, the TST flux depends only on the potential within the strips, so the resulting branching probabilities must be identical to the unbiased case. This demonstrates the key principle of hyperdynamics: when the bias potential vanishes on the dividing surfaces (and in the pre-surface strips in this model), the TST branching probabilities are preserved.\n\n**Case B: Counterexample with Force Modulation**\n\nThis case demonstrates a scenario where the standard hyperdynamics condition is subtly violated, leading to altered branching probabilities. The bias potential $V_b$ is zero on the dividing surface $S_1$ itself (at $\\xi=0$) but has a non-zero normal gradient within the adjacent strip.\n- Strip at $S_1$: $V_b(\\xi,y) = g \\xi f(y)$ with $f(y) = \\exp(-y^2/\\sigma_y^2)$ and $\\beta=1$.\n- Strip at $S_2$: $V_b(\\xi,y) = 0$.\n\nThe flux for exit $2$ is unchanged: $J_2^{\\text{biased}} = J_2^{\\text{unbiased}}$.\nThe flux for exit $1$ is modified:\n$$\nJ_1^{\\text{biased}} = \\int_{-W}^{W} e^{-(E_0 + b_1 y^2)} \\left( \\int_{0}^{\\delta} e^{-g \\xi f(y)} \\, d\\xi \\right) \\, dy\n$$\nThe inner integral over $\\xi$ can be computed analytically:\n$$\n\\int_{0}^{\\delta} e^{-g \\xi f(y)} \\, d\\xi = \\left[ \\frac{e^{-g \\xi f(y)}}{-g f(y)} \\right]_{\\xi=0}^{\\xi=\\delta} = \\frac{e^{-g \\delta f(y)} - 1}{-g f(y)} = \\frac{1 - e^{-g \\delta f(y)}}{g f(y)}\n$$\nThis expression is numerically evaluated for each $y$ during the outer numerical integration. For stability where $g f(y) \\to 0$, we note the limit is $\\delta$.\n\nThe biased branching probability is $\\pi_1^{\\text{biased}} = J_1^{\\text{biased}} / (J_1^{\\text{biased}} + J_2^{\\text{unbiased}})$, and the change is $\\Delta \\pi_1 = \\pi_1^{\\text{biased}} - \\pi_1^{\\text{unbiased}}$.\n\n**First-Order Estimate for $\\Delta \\pi_1$**\n\nWe are asked to derive a first-order estimate for $\\Delta \\pi_1$ based on expanding the inner integral for small $g$. The problem provides the approximation:\n$$\n\\int_0^\\delta e^{-g \\xi f(y)} \\, d\\xi \\approx \\delta - \\frac{1}{2} g \\delta^2 f(y)\n$$\nUsing this, the approximate flux $J_1^{\\text{approx}}$ is:\n$$\nJ_1^{\\text{approx}} = \\int_{-W}^{W} e^{-(E_0+b_1 y^2)} \\left( \\delta - \\frac{1}{2} g \\delta^2 f(y) \\right) dy\n$$\n$$\nJ_1^{\\text{approx}} = \\delta \\int_{-W}^{W} e^{-(E_0+b_1 y^2)} dy - \\frac{1}{2} g \\delta^2 \\int_{-W}^{W} e^{-(E_0+b_1 y^2)} f(y) \\, dy\n$$\nThe first term is exactly $J_1^{\\text{unbiased}}$. The second term is the first-order correction, $\\Delta J_1$:\n$$\n\\Delta J_1 = -\\frac{1}{2} g \\delta^2 e^{-E_0} \\int_{-W}^{W} e^{-b_1 y^2} e^{-y^2/\\sigma_y^2} \\, dy = -\\frac{1}{2} g \\delta^2 e^{-E_0} \\int_{-W}^{W} e^{-(b_1 + 1/\\sigma_y^2)y^2} \\, dy\n$$\nThe new branching probability is $\\pi_1^{\\text{approx}} = (J_1^{\\text{unbiased}} + \\Delta J_1) / (J_1^{\\text{unbiased}} + \\Delta J_1 + J_2^{\\text{unbiased}})$.\nThe change is $\\Delta \\pi_1 \\approx \\pi_1^{\\text{approx}} - \\pi_1^{\\text{unbiased}}$. For small $\\Delta J_1$, we can use a first-order expansion:\n$$\n\\Delta \\pi_1 \\approx \\frac{\\partial \\pi_1}{\\partial J_1} \\Delta J_1 = \\frac{\\partial}{\\partial J_1} \\left( \\frac{J_1}{J_1+J_2} \\right) \\Delta J_1 = \\frac{(J_1+J_2) - J_1}{(J_1+J_2)^2} \\Delta J_1 = \\frac{J_2}{(J_1+J_2)^2} \\Delta J_1\n$$\nEvaluating this at the unbiased state gives the estimate:\n$$\n\\Delta \\pi_1^{\\text{est}} = \\frac{J_2^{\\text{unbiased}}}{(J_1^{\\text{unbiased}} + J_2^{\\text{unbiased}})^2} \\Delta J_1\n$$\nThis expression, along with the exact computation, will be implemented numerically. The integrals over $y$ will be performed using numerical quadrature.\n\nThe following program implements these calculations for the specified test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Solves the hyperdynamics branching probability problem.\n    \"\"\"\n    # Define parameters for the test cases as a dictionary.\n    params = {\n        'E0': 6.0,\n        'b1': 4.0,\n        'b2': 3.0,\n        'L': 1.0,\n        'W': 2.0,\n        'delta': 0.05,\n        'sigma_y': 0.4,\n        'beta': 1.0,\n        'g': 5.0,\n        'tol': 1e-12,\n    }\n\n    def calculate_flux(b_val, bias_type='none'):\n        \"\"\"\n        Computes the reactive flux J for a given channel.\n\n        Args:\n            b_val (float): The potential curvature parameter b_i for the channel.\n            bias_type (str): 'none' for unbiased or 'force_mod' for force modulation bias.\n\n        Returns:\n            float: The calculated reactive flux J_i.\n        \"\"\"\n        E0 = params['E0']\n        beta = params['beta']\n        W = params['W']\n        delta = params['delta']\n\n        U_on_S = lambda y: E0 + b_val * y**2\n\n        # Inner integral over the strip thickness xi.\n        # This is done analytically.\n        if bias_type == 'force_mod':\n            g = params['g']\n            sigma_y = params['sigma_y']\n            \n            def inner_integral_val(y):\n                fy = np.exp(-y**2 / sigma_y**2)\n                arg_no_delta = beta * g * fy\n                arg_with_delta = arg_no_delta * delta\n                \n                # Use a threshold to switch to the limit to avoid 0/0.\n                # The limit of (1-exp(-ax))/a as a->0 is x.\n                # Here, a is arg_no_delta and x is delta.\n                if np.abs(arg_no_delta)  1e-9:\n                    return delta\n                else:\n                    # Use np.expm1 for better numerical precision with small arguments.\n                    # -expm1(-x) is equivalent to 1-exp(-x).\n                    return -np.expm1(-arg_with_delta) / arg_no_delta\n\n        elif bias_type == 'none':\n            def inner_integral_val(y):\n                return delta\n        else:\n            raise ValueError(\"Unknown bias type specified.\")\n            \n        # The full integrand for the outer y-integral.\n        def integrand(y):\n            return np.exp(-beta * U_on_S(y)) * inner_integral_val(y)\n\n        # Perform numerical quadrature over y.\n        result, _ = integrate.quad(integrand, -W, W)\n        return result\n\n    # --- Case A (Invariance Check for V_b=0 in strips) ---\n    J1_unbiased = calculate_flux(params['b1'], bias_type='none')\n    J2_unbiased = calculate_flux(params['b2'], bias_type='none')\n    \n    J_tot_unbiased = J1_unbiased + J2_unbiased\n    pi1_unbiased = J1_unbiased / J_tot_unbiased\n    pi2_unbiased = J2_unbiased / J_tot_unbiased\n    \n    # 1. Verify sum of probabilities is 1.\n    result_A1 = bool(np.isclose(pi1_unbiased + pi2_unbiased, 1.0, atol=params['tol']))\n    \n    # 2. Verify invariance for an interior-only V_b.\n    # The calculation is identical since V_b=0 in the strips.\n    J1_interior_vb = calculate_flux(params['b1'], bias_type='none')\n    J_tot_interior_vb = J1_interior_vb + J2_unbiased\n    pi1_interior_vb = J1_interior_vb / J_tot_interior_vb\n    result_A2 = bool(np.isclose(pi1_unbiased, pi1_interior_vb, atol=params['tol']))\n\n    # --- Case B (Counterexample) ---\n    # Use unbiased results from Case A.\n    J1_biased = calculate_flux(params['b1'], bias_type='force_mod')\n    J2_biased = J2_unbiased  # Vb is zero in strip 2.\n    \n    J_tot_biased = J1_biased + J2_biased\n    pi1_biased = J1_biased / J_tot_biased\n    \n    # 3. Compute the actual change in branching probability.\n    actual_delta_pi1 = pi1_biased - pi1_unbiased\n    \n    # 4. Compute the first-order gradient-based estimate for the change.\n    beta = params['beta']\n    g = params['g']\n    delta = params['delta']\n    E0 = params['E0']\n    W = params['W']\n    b1 = params['b1']\n    sigma_y = params['sigma_y']\n    \n    def integrand_delta_J1(y):\n        return np.exp(-(b1 + 1.0/sigma_y**2) * y**2)\n    \n    integral_part, _ = integrate.quad(integrand_delta_J1, -W, W)\n    \n    delta_J1 = -0.5 * beta * g * delta**2 * np.exp(-beta * E0) * integral_part\n\n    estimated_delta_pi1 = (delta_J1 * J2_unbiased) / (J_tot_unbiased**2)\n    \n    # --- Case C (Strong Interior Bias, Invariance Stress Test) ---\n    # The setup is mathematically identical to the second part of Case A.\n    # The TST flux calculation is insensitive to any Vb outside the strips.\n    J1_case_c = calculate_flux(params['b1'], bias_type='none')\n    J_tot_case_c = J1_case_c + J2_unbiased\n    pi1_case_c = J1_case_c / J_tot_case_c\n    \n    # 5. Verify invariance.\n    result_C = bool(np.isclose(pi1_unbiased, pi1_case_c, atol=params['tol']))\n    \n    # --- Final Output ---\n    final_results = [\n        result_A1,\n        result_A2,\n        actual_delta_pi1,\n        estimated_delta_pi1,\n        result_C,\n    ]\n    \n    # Print the results in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}