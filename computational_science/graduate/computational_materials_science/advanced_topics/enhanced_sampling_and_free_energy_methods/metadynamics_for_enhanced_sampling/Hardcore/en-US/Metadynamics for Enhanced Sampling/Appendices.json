{
    "hands_on_practices": [
        {
            "introduction": "Many important collective variables, such as the dihedral angles that define molecular conformations, are periodic. This practice addresses the crucial task of constructing a bias potential that respects this periodicity, as a standard Euclidean distance metric would incorrectly treat endpoints like $0$ and $2\\pi$ as far apart. You will derive and apply a periodic Gaussian kernel based on the geodesic distance on a circle, a fundamental technique for accurately biasing simulations with angular degrees of freedom .",
            "id": "3466111",
            "problem": "A single torsional collective variable (CV) on a circle is modeled as an angle $\\theta \\in [0,2\\pi)$ measured in radians. In metadynamics for enhanced sampling, one constructs a bias potential by depositing localized kernels centered at previously visited CV values to discourage revisitation and accelerate exploration. Starting from the standard Euclidean Gaussian kernel in one dimension, and from the definition of the geodesic distance on the circle (the minimal arc length between two angles), derive a periodic Gaussian kernel $K_{\\mathrm{per}}(\\theta,\\theta_i;\\sigma)$ that respects the $2\\pi$ periodicity of the angular CV by replacing the Euclidean distance with a wrapped angular distance. Demonstrate that the resulting kernel is invariant under $\\theta \\mapsto \\theta + 2\\pi$ and hence suitable for bias deposition on a periodic domain.\n\nLet the instantaneous metadynamics bias be the sum of deposited kernels,\n$$\nV(\\theta) \\,=\\, \\sum_{i=1}^{N} w_i \\, K_{\\mathrm{per}}(\\theta,\\theta_i;\\sigma),\n$$\nwhere $w_i$ is the height (an energy parameter) of the $i$-th deposited kernel at center $\\theta_i$, and $\\sigma$ is a common angular width (in radians). Consider three kernels with heights $w_1=2.5\\,\\mathrm{kJ\\,mol^{-1}}$, $w_2=1.8\\,\\mathrm{kJ\\,mol^{-1}}$, and $w_3=2.2\\,\\mathrm{kJ\\,mol^{-1}}$, all sharing width $\\sigma=0.15\\,\\mathrm{rad}$, deposited at angular positions $\\theta_1=0.12\\,\\mathrm{rad}$, $\\theta_2=6.20\\,\\mathrm{rad}$, and $\\theta_3=3.40\\,\\mathrm{rad}$. Using your derived periodic Gaussian kernel, evaluate the bias potential $V(\\theta^{\\star})$ at the query angle $\\theta^{\\star}=6.25\\,\\mathrm{rad}$.\n\nAll angles must be treated in radians. Express the final energy in $\\mathrm{kJ\\,mol^{-1}}$ and round your answer to four significant figures.",
            "solution": "The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution. It is a standard exercise in the field of computational materials science, specifically concerning enhanced sampling methods. We may therefore proceed with a solution.\n\nThe problem is divided into two parts: first, the derivation and validation of a periodic Gaussian kernel, and second, the application of this kernel to calculate a bias potential.\n\n**Part 1: Derivation and Validation of the Periodic Gaussian Kernel**\n\nA standard one-dimensional Gaussian kernel centered at a point $x_i$ with width $\\sigma$ is given by:\n$$\nK(x, x_i; \\sigma) = \\exp\\left(-\\frac{(x - x_i)^2}{2\\sigma^2}\\right)\n$$\nThe term $(x - x_i)^2$ is the squared Euclidean distance between points $x$ and $x_i$ on a line. For a collective variable $\\theta$ defined on a circle, i.e., a periodic domain with period $2\\pi$, the Euclidean distance is inappropriate as it does not recognize that $\\theta = 0$ and $\\theta = 2\\pi$ represent the same point.\n\nWe must replace the Euclidean distance with the geodesic distance on the circle. The geodesic distance is the shortest arc length between two angles, say $\\theta$ and $\\theta_i$. On the circle, there are two paths connecting these points. The lengths of these paths are given by the absolute difference $|\\theta - \\theta_i|$ and the complementary arc length $2\\pi - |\\theta - \\theta_i|$. The geodesic distance, which we denote as $d_{\\mathrm{circ}}(\\theta, \\theta_i)$, is the minimum of these two lengths:\n$$\nd_{\\mathrm{circ}}(\\theta, \\theta_i) = \\min(|\\theta - \\theta_i|, 2\\pi - |\\theta - \\theta_i|)\n$$\nThis definition is valid for angles $\\theta, \\theta_i \\in [0, 2\\pi)$.\n\nBy substituting the squared geodesic distance $d^2_{\\mathrm{circ}}(\\theta, \\theta_i)$ for the squared Euclidean distance $(x - x_i)^2$ in the standard Gaussian formula, we obtain the periodic Gaussian kernel $K_{\\mathrm{per}}$:\n$$\nK_{\\mathrm{per}}(\\theta, \\theta_i; \\sigma) = \\exp\\left(-\\frac{d^2_{\\mathrm{circ}}(\\theta, \\theta_i)}{2\\sigma^2}\\right) = \\exp\\left(-\\frac{\\left(\\min(|\\theta - \\theta_i|, 2\\pi - |\\theta - \\theta_i|)\\right)^2}{2\\sigma^2}\\right)\n$$\n\nNext, we must demonstrate that this kernel is periodic, i.e., $K_{\\mathrm{per}}(\\theta + 2\\pi, \\theta_i; \\sigma) = K_{\\mathrm{per}}(\\theta, \\theta_i; \\sigma)$. The most rigorous way to demonstrate this is to consider the distance between an angle $\\theta$ and all periodic images of $\\theta_i$, which are located at $\\theta_i + 2\\pi k$ for any integer $k \\in \\mathbb{Z}$. The geodesic distance is the minimum of all these distances on the real line:\n$$\nd_{\\mathrm{circ}}(\\theta, \\theta_i) = \\min_{k \\in \\mathbb{Z}} |\\theta - (\\theta_i + 2\\pi k)|\n$$\nNow, let us replace $\\theta$ with $\\theta + 2\\pi$:\n$$\nd_{\\mathrm{circ}}(\\theta + 2\\pi, \\theta_i) = \\min_{k \\in \\mathbb{Z}} |(\\theta + 2\\pi) - (\\theta_i + 2\\pi k)| = \\min_{k \\in \\mathbb{Z}} |\\theta - \\theta_i - 2\\pi (k - 1)|\n$$\nLet us introduce a new integer variable $j = k-1$. As $k$ spans all integers ($\\mathbb{Z}$), $j$ also spans all integers. Thus, we can rewrite the expression by summing over $j$:\n$$\nd_{\\mathrm{circ}}(\\theta + 2\\pi, \\theta_i) = \\min_{j \\in \\mathbb{Z}} |\\theta - \\theta_i - 2\\pi j| = d_{\\mathrm{circ}}(\\theta, \\theta_i)\n$$\nSince the distance function $d_{\\mathrm{circ}}$ is invariant under a shift of $2\\pi$ in its first argument, and the kernel $K_{\\mathrm{per}}$ is a function of $d^2_{\\mathrm{circ}}$, the kernel itself is also periodic with period $2\\pi$. The derivation and validation are complete.\n\n**Part 2: Calculation of the Bias Potential**\n\nThe total bias potential $V(\\theta)$ is the sum of the individual kernels:\n$$\nV(\\theta) = \\sum_{i=1}^{N} w_i K_{\\mathrm{per}}(\\theta, \\theta_i; \\sigma)\n$$\nWe need to evaluate $V(\\theta^\\star)$ at $\\theta^\\star = 6.25 \\text{ rad}$ with $N=3$ kernels. The shared width is $\\sigma = 0.15 \\text{ rad}$, so the denominator in the exponent is $2\\sigma^2 = 2(0.15)^2 = 2(0.0225) = 0.045 \\text{ rad}^2$.\n\nThe potential is:\n$$\nV(\\theta^\\star) = w_1 K_{\\mathrm{per}}(\\theta^\\star, \\theta_1; \\sigma) + w_2 K_{\\mathrm{per}}(\\theta^\\star, \\theta_2; \\sigma) + w_3 K_{\\mathrm{per}}(\\theta^\\star, \\theta_3; \\sigma)\n$$\nWe calculate each term separately.\n\n**Term 1:** $w_1 = 2.5 \\text{ kJ mol}^{-1}$, $\\theta_1 = 0.12 \\text{ rad}$.\nThe angular difference is $|\\theta^\\star - \\theta_1| = |6.25 - 0.12| = 6.13 \\text{ rad}$.\nThe geodesic distance is $d_1 = \\min(6.13, 2\\pi - 6.13) \\approx \\min(6.13, 6.2832 - 6.13) = \\min(6.13, 0.1532) = 0.1532 \\text{ rad}$.\nThe contribution to the potential is:\n$$\nV_1 = w_1 \\exp\\left(-\\frac{d_1^2}{2\\sigma^2}\\right) \\approx 2.5 \\exp\\left(-\\frac{(0.153185...)^2}{0.045}\\right) \\approx 2.5 \\exp(-0.521457) \\approx 2.5 \\times 0.59365 = 1.48413 \\text{ kJ mol}^{-1}\n$$\n\n**Term 2:** $w_2 = 1.8 \\text{ kJ mol}^{-1}$, $\\theta_2 = 6.20 \\text{ rad}$.\nThe angular difference is $|\\theta^\\star - \\theta_2| = |6.25 - 6.20| = 0.05 \\text{ rad}$.\nThe geodesic distance is $d_2 = \\min(0.05, 2\\pi - 0.05) = 0.05 \\text{ rad}$.\nThe contribution to the potential is:\n$$\nV_2 = w_2 \\exp\\left(-\\frac{d_2^2}{2\\sigma^2}\\right) = 1.8 \\exp\\left(-\\frac{(0.05)^2}{0.045}\\right) = 1.8 \\exp\\left(-\\frac{0.0025}{0.045}\\right) = 1.8 \\exp(-0.0555...) \\approx 1.8 \\times 0.94593 = 1.70268 \\text{ kJ mol}^{-1}\n$$\n\n**Term 3:** $w_3 = 2.2 \\text{ kJ mol}^{-1}$, $\\theta_3 = 3.40 \\text{ rad}$.\nThe angular difference is $|\\theta^\\star - \\theta_3| = |6.25 - 3.40| = 2.85 \\text{ rad}$.\nThe geodesic distance is $d_3 = \\min(2.85, 2\\pi - 2.85) \\approx \\min(2.85, 6.2832 - 2.85) = \\min(2.85, 3.4332) = 2.85 \\text{ rad}$ (since $2.85  \\pi$).\nThe contribution to the potential is:\n$$\nV_3 = w_3 \\exp\\left(-\\frac{d_3^2}{2\\sigma^2}\\right) = 2.2 \\exp\\left(-\\frac{(2.85)^2}{0.045}\\right) = 2.2 \\exp\\left(-\\frac{8.1225}{0.045}\\right) = 2.2 \\exp(-180.5)\n$$\nThe value of $\\exp(-180.5)$ is exceedingly small (on the order of $10^{-79}$), so this term's contribution is functionally zero: $V_3 \\approx 0$.\n\n**Total Potential:**\nThe total bias potential at $\\theta^\\star$ is the sum of the individual contributions:\n$$\nV(\\theta^\\star) = V_1 + V_2 + V_3 \\approx 1.48413 + 1.70268 + 0 = 3.18681 \\text{ kJ mol}^{-1}\n$$\nThe problem requires rounding the final answer to four significant figures.\n$$\nV(\\theta^\\star) \\approx 3.187 \\text{ kJ mol}^{-1}\n$$",
            "answer": "$$\n\\boxed{3.187}\n$$"
        },
        {
            "introduction": "In complex systems, unconstrained exploration of collective variables can lead to unphysical configurations, such as atomic clashes or unrealistic material densification. This practice introduces the use of \"soft walls\" to restrain a simulation within a physically meaningful region of the configuration space . Critically, you will derive the corresponding reweighting formula required to remove the effects of both the time-dependent metadynamics bias and the static wall potential, allowing you to recover unbiased thermodynamic observables from the constrained trajectory.",
            "id": "3466145",
            "problem": "You are studying enhanced sampling by metadynamics in computational materials science, focusing on avoiding unphysical densification during zeolite framework rearrangements. Consider a simulation in the canonical ensemble where the system configuration is denoted by $\\mathbf{x}$ and a single collective variable (CV) $s = s(\\mathbf{x})$ encodes the relevant framework-rearrangement coordinate. The unbiased target distribution is the canonical distribution with potential energy $U_0(\\mathbf{x})$, that is $p_0(\\mathbf{x}) \\propto \\exp(-\\beta U_0(\\mathbf{x}))$, where $\\beta = 1/(k_{\\mathrm{B}} T)$, $k_{\\mathrm{B}}$ is the Boltzmann constant, and $T$ is the absolute temperature. In metadynamics, a time-dependent bias $V(s,t)$ is added, and to restrict sampling into physically meaningful regions of the CV that avoid densification, a soft-wall restraint potential $U_{\\mathrm{wall}}(s)$ is added to the Hamiltonian. The simulation therefore samples from a time-dependent biased distribution $p_b(\\mathbf{x},t) \\propto \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)$, where $V'(s,t)$ denotes the actually applied metadynamics bias as it enters the Hamiltonian. In well-tempered metadynamics, there is a time-dependent offset $c(t)$ such that $V'(s,t) = V(s,t) - c(t)$.\n\nTask 1 (derivation): Starting from the canonical ensemble definition $p_0(\\mathbf{x}) \\propto \\exp(-\\beta U_0(\\mathbf{x}))$ and the concept of importance sampling (i.e., changing the sampling distribution and compensating by a weight equal to the ratio of target to proposal densities), derive the normalized reweighting estimator for an arbitrary observable $A(\\mathbf{x})$ that recovers the unbiased expectation $\\langle A \\rangle_0$ from a trajectory sampled under the time-dependent bias $V'(s,t)$ and the soft wall $U_{\\mathrm{wall}}(s)$. Your derivation must explicitly account for the presence of the offset $c(t)$ in well-tempered metadynamics and for the additional restraint $U_{\\mathrm{wall}}(s)$. Express your final estimator in terms of sample values $\\{A_i, s_i, V(s_i,t_i), c(t_i)\\}$ and the wall potential $U_{\\mathrm{wall}}(s_i)$ evaluated at those samples.\n\nTask 2 (algorithm and implementation): Design and implement a program that computes the unbiased estimate of $\\langle A \\rangle_0$ using the estimator derived in Task 1 for the observable $A(s) = s^2$ for each of the following test cases. In all cases, take $k_{\\mathrm{B}} = 0.00831446261815324$ in $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$ and $T = 300$ in $\\mathrm{K}$, so that $\\beta = 1/(k_{\\mathrm{B}} T)$ is computed in $\\mathrm{mol}\\,\\mathrm{kJ}^{-1}$. All energies ($V$, $c$, $U_{\\mathrm{wall}}$) are given or must be computed in $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$, and $s$ is dimensionless. Use the soft-wall restraint\n$$\nU_{\\mathrm{wall}}(s) = \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s - s_{\\max}\\right)\\right]^2 + \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s_{\\min} - s\\right)\\right]^2,\n$$\nwith stiffness $k_{\\mathrm{w}}$ in $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$, and bounds $s_{\\min}$ and $s_{\\max}$. For each test case, compute the unbiased estimate of $\\langle s^2 \\rangle_0$ from the provided samples using your derived weights. Express all final results as dimensionless floats.\n\nTest Suite:\n- Test Case 1 (no walls, constant offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 0.0$. Samples: $s = [-1.2, -0.8, -0.1, 0.3, 0.9, 1.4]$, $V = [1.0, 0.6, -0.2, -0.5, 0.4, 1.2]$, $c = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]$.\n- Test Case 2 (moderate soft walls, varying offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 50.0$. Samples: $s = [-1.5, -1.0, -0.2, 0.7, 1.05, 1.2]$, $V = [0.9, 0.3, -0.1, -0.4, 0.2, 1.1]$, $c = [0.4, 0.4, 0.4, 0.45, 0.5, 0.5]$.\n- Test Case 3 (stiff soft walls, increasing offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 1000.0$. Samples: $s = [-1.3, -1.05, -0.5, 0.0, 1.0, 1.3]$, $V = [0.8, 0.5, 0.0, -0.3, 0.2, 0.9]$, $c = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55]$.\n- Test Case 4 (no walls, strongly varying offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 0.0$. Samples: $s = [-0.9, -0.4, 0.2, 0.8, 1.1]$, $V = [-0.5, -0.1, 0.3, 0.6, 0.9]$, $c = [0.0, 0.2, 0.4, 0.6, 0.8]$.\n\nYour program must:\n- Compute $\\beta = 1/(k_{\\mathrm{B}} T)$ using the given $k_{\\mathrm{B}}$ and $T$.\n- Compute $U_{\\mathrm{wall}}(s_i)$ for each sample in each test case.\n- Compute the correct reweighting factor for each sample derived in Task 1.\n- Output the unbiased estimate of $\\langle s^2 \\rangle_0$ for each test case as a single line containing a comma-separated list enclosed in square brackets, for example, $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$. The values must be plain decimal floats with no units attached.\n\nDesign for coverage:\n- The first case tests the baseline without walls.\n- The second case tests moderate walls that slightly penalize excursions beyond bounds.\n- The third case tests stiff walls that heavily penalize boundary violations, challenging numerical stability of weights.\n- The fourth case tests the effect of varying $c(t)$ without walls.\n\nFinal output format requirement:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$). All numerical answers must be dimensionless floats.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of statistical mechanics and computational science, well-posed with a clear objective and sufficient data, and free of any logical contradictions or ambiguities.\n\n### Task 1: Derivation of the Reweighting Estimator\n\nThe objective is to derive an estimator for the unbiased canonical expectation value of an observable, $\\langle A \\rangle_0$, using data from a biased simulation. The unbiased expectation value is defined as:\n$$\n\\langle A \\rangle_0 = \\frac{\\int A(\\mathbf{x}) p_0(\\mathbf{x}) \\, d\\mathbf{x}}{\\int p_0(\\mathbf{x}) \\, d\\mathbf{x}}\n$$\nwhere $p_0(\\mathbf{x})$ is the probability density of the target unbiased canonical ensemble, given by $p_0(\\mathbf{x}) \\propto \\exp(-\\beta U_0(\\mathbf{x}))$. Here, $U_0(\\mathbf{x})$ is the unbiased potential energy, and $\\beta = 1/(k_{\\mathrm{B}} T)$ is the inverse temperature.\n\nThe simulation trajectory is sampled from a time-dependent biased distribution $p_b(\\mathbf{x}, t)$, which includes both the metadynamics bias and the soft-wall restraint. The probability density for this biased ensemble is:\n$$\np_b(\\mathbf{x}, t) \\propto \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)\n$$\nwhere $V'(s(\\mathbf{x}),t) = V(s(\\mathbf{x}),t) - c(t)$ is the applied metadynamics potential and $U_{\\mathrm{wall}}(s(\\mathbf{x}))$ is the static wall potential.\n\nThe principle of importance sampling allows us to re-express the integrals over the target distribution $p_0(\\mathbf{x})$ as integrals over the sampling distribution $p_b(\\mathbf{x}, t)$. This is achieved by multiplying the integrand by a reweighting factor $w(\\mathbf{x},t) = p_0(\\mathbf{x}) / p_b(\\mathbf{x},t)$.\n$$\n\\langle A \\rangle_0 = \\frac{\\int A(\\mathbf{x}) \\frac{p_0(\\mathbf{x})}{p_b(\\mathbf{x},t)} p_b(\\mathbf{x},t) \\, d\\mathbf{x}}{\\int \\frac{p_0(\\mathbf{x})}{p_b(\\mathbf{x},t)} p_b(\\mathbf{x},t) \\, d\\mathbf{x}}\n$$\nLet us explicitly write out the reweighting factor $w(\\mathbf{x}, t)$. The normalization constants (partition functions) for the two distributions are $Z_0 = \\int \\exp(-\\beta U_0(\\mathbf{x})) \\, d\\mathbf{x}$ and $Z_b(t) = \\int \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s,t) + U_{\\mathrm{wall}}(s)\\right]\\right) \\, d\\mathbf{x}$.\n$$\nw(\\mathbf{x}, t) = \\frac{p_0(\\mathbf{x})}{p_b(\\mathbf{x},t)} = \\frac{Z_b(t) \\cdot \\exp(-\\beta U_0(\\mathbf{x}))}{Z_0 \\cdot \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)}\n$$\nThe term $\\exp(-\\beta U_0(\\mathbf{x}))$ cancels, yielding:\n$$\nw(\\mathbf{x}, t) = \\frac{Z_b(t)}{Z_0} \\exp\\left(\\beta\\left[V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)\n$$\nSubstituting the expression for the applied bias, $V'(s,t) = V(s,t) - c(t)$, we get:\n$$\nw(\\mathbf{x}, t) = \\frac{Z_b(t)}{Z_0} \\exp\\left(\\beta\\left[V(s(\\mathbf{x}),t) - c(t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)\n$$\nIn a simulation, we obtain a discrete trajectory of $N$ configurations $\\{\\mathbf{x}_i\\}$ at discrete times $\\{t_i\\}$. The integrals for the expectation value are thus replaced by sums over these samples. Each sample $\\mathbf{x}_i$ is drawn from the distribution $p_b(\\mathbf{x}, t_i)$ and must be weighted by $w(\\mathbf{x}_i, t_i)$. The estimator for $\\langle A \\rangle_0$ becomes a weighted average over the trajectory:\n$$\n\\langle A \\rangle_0 \\approx \\frac{\\sum_{i=1}^{N} A(\\mathbf{x}_i) w(\\mathbf{x}_i, t_i)}{\\sum_{i=1}^{N} w(\\mathbf{x}_i, t_i)}\n$$\nThe ratio of partition functions $Z_b(t_i)/Z_0$ in each $w(\\mathbf{x}_i, t_i)$ varies with time. However, for a sufficiently long simulation that converges, the average of any observable over the time-dependent bias should converge to the ensemble average. A common and practical assumption in reweighting metadynamics trajectories is that a single reweighting expression can be used across the whole trajectory. The factor containing the partition functions cancels out in the normalized estimator. Let $w_i$ be the un-normalized weight for sample $i$.\n$$\nw_i \\propto \\exp\\left(\\beta\\left[V(s(\\mathbf{x}_i),t_i) - c(t_i) + U_{\\mathrm{wall}}(s(\\mathbf{x}_i))\\right]\\right)\n$$\nThe problem provides sampled values of the collective variable $s_i = s(\\mathbf{x}_i)$, the metadynamics potential at those points $V_i = V(s_i, t_i)$, and the time-dependent offset $c_i = c(t_i)$. The observable $A$ is also a function of $s$, so $A_i = A(s_i)$. The final normalized reweighting estimator for $\\langle A \\rangle_0$ is:\n$$\n\\langle A \\rangle_0 \\approx \\frac{\\sum_{i=1}^{N} A_i \\exp\\left(\\beta\\left[V_i - c_i + U_{\\mathrm{wall}}(s_i)\\right]\\right)}{\\sum_{i=1}^{N} \\exp\\left(\\beta\\left[V_i - c_i + U_{\\mathrm{wall}}(s_i)\\right]\\right)}\n$$\nThis is the required expression. For numerical implementation, to prevent overflow or underflow issues with the exponential function, we define the total biasing energy for each sample as $E_i = V_i - c_i + U_{\\mathrm{wall}}(s_i)$, find the maximum value $E_{\\max} = \\max_i\\{E_i\\}$, and rewrite the estimator in a numerically stable form:\n$$\n\\langle A \\rangle_0 \\approx \\frac{\\sum_{i=1}^{N} A_i \\exp(\\beta (E_i - E_{\\max}))}{\\sum_{i=1}^{N} \\exp(\\beta (E_i - E_{\\max}))}\n$$\nThis form will be used for the implementation in Task 2.\n\n### Task 2: Algorithm and Implementation\n\nThe algorithm proceeds as follows for each test case:\n1.  Define the constants $k_{\\mathrm{B}} = 0.00831446261815324 \\, \\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$ and $T = 300 \\, \\mathrm{K}$. Compute $\\beta = 1/(k_{\\mathrm{B}} T)$.\n2.  For a given set of samples $\\{s_i, V_i, c_i\\}$ and wall parameters $\\{k_{\\mathrm{w}}, s_{\\min}, s_{\\max}\\}$, compute the value of the observable $A_i = s_i^2$ for each sample.\n3.  Compute the wall potential energy $U_{\\mathrm{wall}}(s_i)$ for each sample using the formula:\n$$\nU_{\\mathrm{wall}}(s_i) = \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s_i - s_{\\max}\\right)\\right]^2 + \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s_{\\min} - s_i\\right)\\right]^2\n$$\n4.  For each sample $i$, calculate the argument of the exponent, which is the total biasing energy: $E_i = V_i - c_i + U_{\\mathrm{wall}}(s_i)$.\n5.  To ensure numerical stability, find the maximum value among all exponents, $E_{\\max} = \\max_i\\{E_i\\}$.\n6.  Calculate the stabilized (un-normalized) weights for each sample: $w'_i = \\exp(\\beta (E_i - E_{\\max}))$.\n7.  Compute the numerator of the estimator: $\\text{Num} = \\sum_{i=1}^{N} A_i w'_i$.\n8.  Compute the denominator of the estimator: $\\text{Den} = \\sum_{i=1}^{N} w'_i$.\n9.  The final unbiased estimate is $\\langle s^2 \\rangle_0 = \\text{Num} / \\text{Den}$.\nThis procedure is repeated for all test cases. The implementation will use the `numpy` library for efficient vectorized computations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the unbiased estimate of s^2_0 from metadynamics trajectories\n    with soft-wall restraints using a reweighting method.\n    \"\"\"\n    # Define constants\n    k_B = 0.00831446261815324  # kJ mol^-1 K^-1\n    T = 300.0  # K\n    beta = 1.0 / (k_B * T)  # mol kJ^-1\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 0.0,\n            \"s\": np.array([-1.2, -0.8, -0.1, 0.3, 0.9, 1.4]),\n            \"V\": np.array([1.0, 0.6, -0.2, -0.5, 0.4, 1.2]),\n            \"c\": np.array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n        },\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 50.0,\n            \"s\": np.array([-1.5, -1.0, -0.2, 0.7, 1.05, 1.2]),\n            \"V\": np.array([0.9, 0.3, -0.1, -0.4, 0.2, 1.1]),\n            \"c\": np.array([0.4, 0.4, 0.4, 0.45, 0.5, 0.5]),\n        },\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 1000.0,\n            \"s\": np.array([-1.3, -1.05, -0.5, 0.0, 1.0, 1.3]),\n            \"V\": np.array([0.8, 0.5, 0.0, -0.3, 0.2, 0.9]),\n            \"c\": np.array([0.3, 0.35, 0.4, 0.45, 0.5, 0.55]),\n        },\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 0.0,\n            \"s\": np.array([-0.9, -0.4, 0.2, 0.8, 1.1]),\n            \"V\": np.array([-0.5, -0.1, 0.3, 0.6, 0.9]),\n            \"c\": np.array([0.0, 0.2, 0.4, 0.6, 0.8]),\n        }\n    ]\n\n    def U_wall(s, k_w, s_min, s_max):\n        \"\"\"Computes the soft-wall restraint potential.\"\"\"\n        term1 = 0.5 * k_w * np.maximum(0, s - s_max)**2\n        term2 = 0.5 * k_w * np.maximum(0, s_min - s)**2\n        return term1 + term2\n\n    results = []\n    for case in test_cases:\n        # Extract data for the current case\n        s_vals = case[\"s\"]\n        V_vals = case[\"V\"]\n        c_vals = case[\"c\"]\n        s_min = case[\"s_min\"]\n        s_max = case[\"s_max\"]\n        k_w = case[\"k_w\"]\n        \n        # 1. Compute the observable A = s^2 for each sample\n        A_vals = s_vals**2\n        \n        # 2. Compute the wall potential U_wall for each sample\n        U_wall_vals = U_wall(s_vals, k_w, s_min, s_max)\n        \n        # 3. Compute the total biasing energy (argument of the exponential)\n        # E_i = V_i - c_i + U_wall(s_i)\n        E_vals = V_vals - c_vals + U_wall_vals\n        \n        # 4. Use a numerically stable formulation for the weights\n        # Find the maximum energy to subtract from the exponent\n        if E_vals.size  0:\n            E_max = np.max(E_vals)\n        else:\n            # Handle empty sample case, though not in test data\n            results.append(np.nan)\n            continue\n            \n        # 5. Calculate weights: w'_i = exp(beta * (E_i - E_max))\n        weights = np.exp(beta * (E_vals - E_max))\n        \n        # 6. Compute the numerator and denominator of the estimator\n        numerator = np.sum(A_vals * weights)\n        denominator = np.sum(weights)\n        \n        # 7. Calculate the final unbiased estimate\n        if denominator == 0:\n            # Avoid division by zero, although unlikely with exp\n            result = np.nan\n        else:\n            result = numerator / denominator\n            \n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A key challenge in any enhanced sampling method is ensuring that the chosen collective variables capture all relevant slow motions of the system. This exercise simulates a common failure mode where a slow \"orthogonal\" degree of freedom, not included in the bias, leads to non-equilibrium effects and hysteresis in the reconstructed free energy surface. By modeling and quantifying this hysteresis, you will develop an essential diagnostic skill for assessing the convergence and reliability of your metadynamics simulations .",
            "id": "3466133",
            "problem": "You are given a computational task to assess hysteresis in Free Energy Surface (FES) reconstruction by forward and reverse metadynamics scans across a first-order transition, to define a loop area metric, and to correlate it with insufficient sampling of orthogonal degrees of freedom. The scientific base for the task must originate from the definition of the FES as a potential of mean force and a first-order relaxation model for slow orthogonal variables.\n\nAssume a one-dimensional collective variable $s \\in [0,1]$, dimensionless, along which the system is scanned in forward and reverse directions at speed $v_s$ (in $\\mathrm{s}^{-1}$). The true FES $F_{\\mathrm{true}}(s)$ is modeled as a double-well potential with equal minima at $s=0$ and $s=1$ and a barrier near $s=\\tfrac{1}{2}$:\n$$\nF_{\\mathrm{true}}(s) = H \\left[s(1-s)\\right]^2,\n$$\nwhere $H$ is a barrier amplitude in $\\mathrm{kJ/mol}$. Metadynamics reconstruction is affected by a slow orthogonal degree of freedom, denoted $y$, which relaxes towards an $s$-dependent equilibrium $y_{\\mathrm{eq}}(s)$ according to first-order kinetics:\n$$\n\\frac{dy}{dt} = -\\frac{y - y_{\\mathrm{eq}}(s)}{\\tau_{\\perp}},\n$$\nwhere $t$ is time in $\\mathrm{s}$, $\\tau_{\\perp}$ is the characteristic relaxation time in $\\mathrm{s}$ for the orthogonal degree of freedom, and $y_{\\mathrm{eq}}(s)$ is assumed to be a localized coupling profile centered at $s_c = \\tfrac{1}{2}$:\n$$\ny_{\\mathrm{eq}}(s) = h(s) = \\exp\\left(-\\frac{(s - s_c)^2}{2w^2}\\right),\n$$\nwith width parameter $w$ (dimensionless). The reconstructed FES along the scan gains an offset due to deviation of $y$ from its equilibrium:\n$$\nF_{\\mathrm{rec}}(s) = F_{\\mathrm{true}}(s) + \\alpha \\left[y(s) - h(s)\\right],\n$$\nwhere $\\alpha$ is a coupling amplitude in $\\mathrm{kJ/mol}$ quantifying the magnitude of reconstruction error due to the orthogonal lag. During a forward scan, $s(t)$ increases linearly from $0$ to $1$ at speed $v_s$; during a reverse scan, $s(t)$ decreases linearly from $1$ to $0$ at the same magnitude of speed.\n\nDefine the hysteresis loop area as the integral over the collective variable of the absolute difference between forward and reverse reconstructions:\n$$\nA = \\int_{0}^{1} \\left|F_{\\mathrm{fwd}}(s) - F_{\\mathrm{rev}}(s)\\right| \\, ds,\n$$\nto be computed numerically using the trapezoidal rule over a uniform grid in $s$. The area $A$ must be reported in $\\mathrm{kJ/mol}$.\n\nAs a measure of insufficient sampling of orthogonal degrees of freedom, define the dimensionless quantity\n$$\nR = \\frac{v_s \\, \\tau_{\\perp}}{w},\n$$\nwhich increases when the scan is faster, the relaxation is slower, or the coupling region is narrower.\n\nYour program must:\n- Use a uniform grid of $N=1001$ points over $s \\in [0,1]$ for numerical integration.\n- Simulate the forward and reverse scans by integrating the relaxation equation for $y$ using a piecewise-constant approximation of $h(s)$ over each time step. For each discrete step of $\\Delta s$, use a time increment $\\Delta t = \\Delta s / v_s$ (set $A=0$ and use $F_{\\mathrm{rec}}(s) = F_{\\mathrm{true}}(s)$ if $v_s = 0$).\n- Compute $F_{\\mathrm{fwd}}(s)$ and $F_{\\mathrm{rev}}(s)$ on the same increasing-$s$ grid, and then compute $A$ using the trapezoidal rule $\\int_{0}^{1} \\left|F_{\\mathrm{fwd}}(s) - F_{\\mathrm{rev}}(s)\\right| \\, ds$.\n- Compute $R$ for each test case using $R = v_s \\tau_{\\perp} / w$.\n- Compute the Pearson correlation coefficient between the list of $\\{A_i\\}$ and the list of $\\{R_i\\}$ across the provided test suite.\n\nPhysical and numerical units:\n- $H$ and $\\alpha$ are in $\\mathrm{kJ/mol}$.\n- $\\tau_{\\perp}$ is in $\\mathrm{s}$.\n- $v_s$ is in $\\mathrm{s}^{-1}$.\n- $w$ and $s$ are dimensionless.\n- The hysteresis loop area $A$ must be reported in $\\mathrm{kJ/mol}$.\n- The correlation coefficient is dimensionless.\n\nTest suite:\nProvide the following five parameter sets $(H, \\alpha, \\tau_{\\perp}, v_s, w)$:\n1. $(400.0, 10.0, 5.0, 0.02, 0.06)$\n2. $(400.0, 10.0, 5.0, 0.00, 0.06)$\n3. $(400.0, 10.0, 5.0, 0.20, 0.06)$\n4. $(400.0, 10.0, 50.0, 0.02, 0.06)$\n5. $(400.0, 10.0, 5.0, 0.02, 0.20)$\n\nOutput specification:\n- Your program should produce a single line of output containing the hysteresis loop area for each test case (in $\\mathrm{kJ/mol}$, rounded to six decimal places) followed by the Pearson correlation coefficient across all test cases (rounded to six decimal places), as a comma-separated list enclosed in square brackets. For example: \"[A1,A2,A3,A4,A5,Corr]\".",
            "solution": "The problem requires the calculation of a hysteresis loop area, denoted by $A$, arising from forward and reverse scans across a collective variable $s$ in a system with a slow orthogonal degree of freedom, $y$. We are also asked to compute a dimensionless parameter $R$ that characterizes the degree of non-equilibrium sampling and to determine the Pearson correlation coefficient between the sets of computed $\\{A_i\\}$ and $\\{R_i\\}$ for a given suite of test cases.\n\nThe scientific foundation of this problem lies in the concept of the Free Energy Surface (FES) as a potential of mean force. In enhanced sampling methods like metadynamics, hysteresis between forward and reverse scans along a collective variable (CV) is a key indicator of poor convergence. This often occurs when degrees of freedom orthogonal to the chosen CV(s) relax on timescales comparable to or slower than the sampling timescale. This model provides a quantitative framework to explore this phenomenon.\n\nThe system's true FES along the one-dimensional CV $s \\in [0, 1]$ is given by a double-well potential:\n$$\nF_{\\mathrm{true}}(s) = H \\left[s(1-s)\\right]^2\n$$\nwhere $H$ is the barrier height in $\\mathrm{kJ/mol}$.\n\nThe dynamics of the slow orthogonal degree of freedom, $y$, are modeled by a first-order relaxation process towards an $s$-dependent equilibrium value, $y_{\\mathrm{eq}}(s)$:\n$$\n\\frac{dy}{dt} = -\\frac{y - y_{\\mathrm{eq}}(s)}{\\tau_{\\perp}}\n$$\nHere, $\\tau_{\\perp}$ is the characteristic relaxation time. The equilibrium value $y_{\\mathrm{eq}}(s)$ is defined by a Gaussian-like function $h(s)$ centered at $s_c = \\tfrac{1}{2}$:\n$$\ny_{\\mathrm{eq}}(s) = h(s) = \\exp\\left(-\\frac{(s - s_c)^2}{2w^2}\\right)\n$$\nwhere $w$ is a dimensionless width parameter.\n\nThe non-equilibrium state of the orthogonal variable $y$ introduces an error in the reconstructed FES:\n$$\nF_{\\mathrm{rec}}(s) = F_{\\mathrm{true}}(s) + \\alpha \\left[y(s) - h(s)\\right]\n$$\nwhere $\\alpha$ is a coupling constant in $\\mathrm{kJ/mol}$. The difference between the forward and reverse reconstructed FES at a given $s$ is therefore:\n$$\nF_{\\mathrm{fwd}}(s) - F_{\\mathrm{rev}}(s) = \\left(F_{\\mathrm{true}}(s) + \\alpha \\left[y_{\\mathrm{fwd}}(s) - h(s)\\right]\\right) - \\left(F_{\\mathrm{true}}(s) + \\alpha \\left[y_{\\mathrm{rev}}(s) - h(s)\\right]\\right) = \\alpha \\left(y_{\\mathrm{fwd}}(s) - y_{\\mathrm{rev}}(s)\\right)\n$$\n\nTo solve for the trajectory $y(s)$ during a scan, we discretize the CV $s$ into a uniform grid of $N=1001$ points from $s=0$ to $s=1$. The step size is $\\Delta s = 1/(N-1)$. For a constant scan speed $v_s$, the time step is $\\Delta t = \\Delta s / v_s$. The problem specifies integrating the ODE for $y$ using a piecewise-constant approximation for $h(s)$ over each time step. This means for a step from time $t_i$ to $t_{i+1}$, we assume $h(s(t))$ is constant and equal to $h(s_i)$. The ODE $\\frac{dy}{dt} = -\\frac{y - h_i}{\\tau_{\\perp}}$ becomes a linear first-order ODE with constant coefficients, which can be solved analytically over the interval $\\Delta t$:\n$$\ny(t_{i+1}) = h_i + (y(t_i) - h_i) \\exp\\left(-\\frac{\\Delta t}{\\tau_{\\perp}}\\right)\n$$\nThis update rule allows us to compute the trajectory of $y$ step-by-step.\n\nFor the forward scan ($s: 0 \\to 1$), we assume the system is initially at equilibrium at $s=0$. The initial condition is thus $y_{\\mathrm{fwd}}(s=0) = y_{\\mathrm{eq}}(s=0) = h(0)$. We then iteratively apply the update rule for $i=0, 1, \\dots, N-2$.\n\nFor the reverse scan ($s: 1 \\to 0$), the system is assumed to be initially at equilibrium at $s=1$, so the initial condition is $y_{\\mathrm{rev}}(s=1) = y_{\\mathrm{eq}}(s=1) = h(1)$. We apply the same update rule iteratively but in the reverse direction of the spatial grid, for $i=N-1, N-2, \\dots, 1$.\n\nOnce both $y_{\\mathrm{fwd}}(s)$ and $y_{\\mathrm{rev}}(s)$ are computed on the grid, we calculate the hysteresis loop area $A$ using the trapezoidal rule for numerical integration as specified:\n$$\nA = \\int_{0}^{1} \\left|F_{\\mathrm{fwd}}(s) - F_{\\mathrm{rev}}(s)\\right| \\, ds = \\int_{0}^{1} \\alpha \\left|y_{\\mathrm{fwd}}(s) - y_{\\mathrm{rev}}(s)\\right| \\, ds\n$$\n\nThe dimensionless quantity $R$ is calculated directly from its definition:\n$$\nR = \\frac{v_s \\, \\tau_{\\perp}}{w}\n$$\n$R$ can be interpreted as a Damk√∂hler number, representing the ratio of the characteristic transport time across the coupling region (proportional to $w/v_s$) to the characteristic relaxation time of the system ($\\tau_{\\perp}$). A large $R$ implies the scan is too fast for the system to relax, leading to significant hysteresis.\n\nFor the special case where $v_s = 0$, the scan is infinitely slow, so the system remains in equilibrium at all times. Thus, $y(s) = y_{\\mathrm{eq}}(s)$ for both \"forward\" and \"reverse\" paths, leading to $F_{\\mathrm{fwd}}(s) = F_{\\mathrm{rev}}(s) = F_{\\mathrm{true}}(s)$. Consequently, the hysteresis area $A=0$. The parameter $R$ is also $0$ in this case.\n\nFinally, after computing the pair $(A_i, R_i)$ for each of the five test cases, we calculate the Pearson correlation coefficient, $\\rho_{A,R}$, between the list of $A$ values and the list of $R$ values to quantify the linear relationship between the proposed non-equilibrium metric and the measured hysteresis. This is computed using standard statistical formulas, readily available in the `numpy` library.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the metadynamics hysteresis problem by simulating forward/reverse\n    scans, calculating hysteresis area (A) and a dimensionless ratio (R),\n    and finally computing the Pearson correlation between A and R values\n    across a suite of test cases.\n    \"\"\"\n\n    def _simulate_scan(s_grid, h_s_grid, tau_perp, v_s, direction):\n        \"\"\"\n        Simulates the trajectory of the orthogonal variable y during a scan.\n        \"\"\"\n        N = len(s_grid)\n        ds = s_grid[1] - s_grid[0]\n        dt = ds / v_s\n        exp_term = np.exp(-dt / tau_perp)\n        \n        y_traj = np.zeros(N)\n\n        if direction == 'forward':\n            y_traj[0] = h_s_grid[0]\n            for i in range(N - 1):\n                y_traj[i+1] = h_s_grid[i] + (y_traj[i] - h_s_grid[i]) * exp_term\n        elif direction == 'reverse':\n            y_traj[N-1] = h_s_grid[N-1]\n            for i in range(N - 1, 0, -1):\n                y_traj[i-1] = h_s_grid[i] + (y_traj[i] - h_s_grid[i]) * exp_term\n        \n        return y_traj\n\n    def _calculate_A_and_R(params):\n        \"\"\"\n        Calculates the hysteresis area A and dimensionless ratio R for a given set of parameters.\n        \"\"\"\n        H, alpha, tau_perp, v_s, w = params\n        \n        # Handle the special case of zero scan speed\n        if v_s == 0.0:\n            return 0.0, 0.0\n\n        # Setup the numerical grid\n        N = 1001\n        s = np.linspace(0, 1, N)\n        s_c = 0.5\n        \n        # Calculate the equilibrium profile h(s)\n        h_s = np.exp(-((s - s_c)**2) / (2 * w**2))\n\n        # Simulate forward and reverse scans\n        y_fwd = _simulate_scan(s, h_s, tau_perp, v_s, 'forward')\n        y_rev = _simulate_scan(s, h_s, tau_perp, v_s, 'reverse')\n        \n        # Calculate the difference in reconstructed FES\n        # F_diff = alpha * ( (y_fwd - h_s) - (y_rev - h_s) )\n        F_diff = alpha * (y_fwd - y_rev)\n        \n        # Calculate hysteresis area A using trapezoidal rule\n        integrand = np.abs(F_diff)\n        A = np.trapz(integrand, s)\n        \n        # Calculate the dimensionless ratio R\n        R = (v_s * tau_perp) / w\n        \n        return A, R\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (400.0, 10.0, 5.0, 0.02, 0.06),\n        (400.0, 10.0, 5.0, 0.00, 0.06),\n        (400.0, 10.0, 5.0, 0.20, 0.06),\n        (400.0, 10.0, 50.0, 0.02, 0.06),\n        (400.0, 10.0, 5.0, 0.02, 0.20),\n    ]\n\n    A_values = []\n    R_values = []\n\n    for case in test_cases:\n        A, R = _calculate_A_and_R(case)\n        A_values.append(A)\n        R_values.append(R)\n\n    # Calculate the Pearson correlation coefficient\n    # np.corrcoef returns a 2x2 matrix, the value at [0,1] is the coefficient\n    correlation_matrix = np.corrcoef(A_values, R_values)\n    # Handle case where a variable is constant (std dev is 0), leading to nan\n    if np.isnan(correlation_matrix[0, 1]):\n        correlation_coefficient = 0.0\n    else:\n        correlation_coefficient = correlation_matrix[0, 1]\n\n    # Combine results and format for output\n    final_results = A_values + [correlation_coefficient]\n    formatted_results = [f\"{val:.6f}\" for val in final_results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}