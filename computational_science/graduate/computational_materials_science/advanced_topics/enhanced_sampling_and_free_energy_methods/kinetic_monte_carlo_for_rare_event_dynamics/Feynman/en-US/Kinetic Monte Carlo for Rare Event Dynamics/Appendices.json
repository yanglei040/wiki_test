{
    "hands_on_practices": [
        {
            "introduction": "Before running a kinetic Monte Carlo simulation, one must first determine the rates of all possible events. This foundational practice bridges quantum-mechanical calculations with mesoscale dynamics by having you compute transition rates using the harmonic approximation to transition state theory (hTST) . By implementing the Vineyard formula and analyzing the sensitivity of rates to errors in activation energies and vibrational frequencies, you will gain a deeper appreciation for the physical underpinnings of KMC and the importance of accurate input parameters.",
            "id": "3459864",
            "problem": "A rare event in a solid is modeled as a thermally activated transition between a vibrational minimum and a first-order saddle (transition state) on a potential energy surface computed by Density Functional Theory (DFT). Kinetic Monte Carlo (KMC) requires the transition rate as a function of temperature to propagate the system over long timescales. Starting from classical transition state theory and the harmonic approximation to vibrational motion about stationary points, derive, implement, and evaluate the transition rate for a single rare event. Then analyze the sensitivity of the rate to errors in the vibrational frequencies and in the activation barrier.\n\nAssumptions and requirements:\n- The classical harmonic approximation holds about both the minimum and the transition state.\n- The transition state has exactly one unstable mode, which is excluded from the set of real vibrational frequencies.\n- The vibrational normal-mode frequencies at the minimum and at the transition state are provided and are to be interpreted as regular frequencies in terahertz (THz), not angular frequencies.\n- The activation barrier is provided as the difference in total energy between the transition state and the minimum in electronvolts (eV).\n- Use the Boltzmann constant $k_{\\mathrm{B}} = 8.617333262145\\times 10^{-5}\\ \\mathrm{eV/K}$.\n- Convert terahertz to hertz via $1\\ \\mathrm{THz} = 10^{12}\\ \\mathrm{s^{-1}}$.\n- The transition rate $k(T)$ must be expressed in $\\mathrm{s^{-1}}$ and rounded to six significant figures in the final output.\n\nTasks:\n1. Using only fundamental statistical mechanics and the harmonic approximation, derive an explicit expression for the transition rate $k(T)$ in terms of the vibrational frequencies at the minimum and at the transition state (excluding the unstable mode) and the activation barrier $\\Delta E$, and implement it in code.\n2. Define a uniform multiplicative frequency bias $(1+\\epsilon_{\\nu})$ applied identically to all vibrational frequencies at both the minimum and the transition state, and an additive barrier error $\\epsilon_{E}$ added to $\\Delta E$. For each test case below, compute the following quantities:\n   - The baseline rate $k(T)$ in $\\mathrm{s^{-1}}$.\n   - The frequency-bias sensitivity factor $R_{\\nu} = k(T;\\ (1+\\epsilon_{\\nu})\\times\\{\\nu\\},\\ \\Delta E)\\big/ k(T;\\ \\{\\nu\\},\\ \\Delta E)$.\n   - The barrier-error sensitivity factor $R_{E} = k(T;\\ \\{\\nu\\},\\ \\Delta E+\\epsilon_{E})\\big/ k(T;\\ \\{\\nu\\},\\ \\Delta E)$.\n   - The logarithmic sensitivity of the rate to a uniform frequency scale factor, $S_{\\mathrm{scale}} = \\dfrac{\\partial \\ln k}{\\partial \\ln s}\\bigg|_{s=1}$, where $s$ multiplies every vibrational frequency at both stationary points.\n   - The logarithmic sensitivity of the rate to the barrier, $S_{E} = \\dfrac{\\partial \\ln k}{\\partial \\Delta E}$, in $\\mathrm{eV^{-1}}$.\n3. All final numerical outputs must be floats. Express $k(T)$ in $\\mathrm{s^{-1}}$, $R_{\\nu}$ and $R_{E}$ as unitless ratios, $S_{\\mathrm{scale}}$ as unitless, and $S_{E}$ in $\\mathrm{eV^{-1}}$.\n\nTest suite:\nUse the same vibrational datasets for all cases. The minimum has $6$ real modes and the transition state has $5$ real modes after excluding the single unstable mode. Frequencies are given in $\\mathrm{THz}$:\n- Minimum frequencies: $\\{3.2,\\, 5.1,\\, 7.0,\\, 8.4,\\, 10.0,\\, 12.3\\}$.\n- Transition-state frequencies (real only): $\\{2.9,\\, 4.7,\\, 6.5,\\, 7.9,\\, 11.5\\}$.\n\nThe four test cases are tuples $(\\Delta E\\ \\mathrm{[eV]},\\ T\\ \\mathrm{[K]},\\ \\epsilon_{\\nu}\\ \\mathrm{[dimensionless]},\\ \\epsilon_{E}\\ \\mathrm{[eV]})$:\n- Case $1$: $(0.6,\\ 500,\\ 0.05,\\ 0.05)$\n- Case $2$: $(0.6,\\ 200,\\ 0.05,\\ 0.05)$\n- Case $3$: $(0.6,\\ 1200,\\ 0.05,\\ 0.05)$\n- Case $4$: $(0.05,\\ 500,\\ 0.05,\\ 0.05)$\n\nFinal output format:\n- Your program should produce a single line of output containing a list of per-case results, where each per-case result is a list of five floats in the order $[k(T),\\ R_{\\nu},\\ R_{E},\\ S_{\\mathrm{scale}},\\ S_{E}]$.\n- Each float must be rounded to six significant figures.\n- The final single line must be a valid Python-style list literal, for example: $[[a_1,b_1,c_1,d_1,e_1],[a_2,b_2,c_2,d_2,e_2],\\ldots]$.",
            "solution": "We model a single rare event as a barrier crossing between a vibrational minimum and a first-order saddle point on the potential energy surface. Kinetic Monte Carlo (KMC) requires the transition rate as input, which we obtain from classical transition state theory (TST) under the harmonic approximation.\n\nFundamental starting point: In classical TST, the rate constant is given by the reactive flux across a dividing surface located at the transition state. In the harmonic approximation, the local dynamics near the stationary points are described by independent harmonic oscillators with frequencies derived from the Hessian (mass-weighted second derivative matrix). The canonical partition function for a set of $n$ classical harmonic modes with frequencies $\\{\\nu_{i}\\}$ at temperature $T$ is, up to a multiplicative constant independent of frequency, proportional to $\\prod_{i=1}^{n} \\frac{k_{\\mathrm{B}} T}{h \\nu_{i}}$ when starting from the full quantum expression and taking the high-temperature classical limit, or equivalently the ratio of partition functions reduces to a ratio of frequency products when constants cancel between numerator and denominator. At the transition state, one unstable (imaginary) mode is excluded from the set of real vibrational modes contributing to the partition function of the dividing surface.\n\nFrom these foundations, the Vineyard form of the classical harmonic TST rate emerges by taking the ratio of harmonic partition functions between the minimum and the transition state (excluding the unstable mode) and multiplying by the Boltzmann factor accounting for the activation barrier. The resulting rate constant is\n$$\nk(T) \\;=\\; \\left(\\frac{\\prod_{i=1}^{N_{\\min}} \\nu^{\\min}_{i}}{\\prod_{j=1}^{N_{\\mathrm{ts}}} \\nu^{\\mathrm{ts}}_{j}}\\right) \\exp\\!\\left(-\\frac{\\Delta E}{k_{\\mathrm{B}} T}\\right),\n$$\nwhere $N_{\\min}$ is the number of real vibrational modes at the minimum, $N_{\\mathrm{ts}}$ is the number of real vibrational modes at the transition state after excluding the unstable mode, $\\nu_{i}^{\\min}$ are the minimum frequencies, $\\nu_{j}^{\\mathrm{ts}}$ are the real transition-state frequencies, $k_{\\mathrm{B}}$ is the Boltzmann constant, and $\\Delta E$ is the activation barrier. The frequencies here are the ordinary frequencies in $\\mathrm{s^{-1}}$ (not angular), and the prefactor carries units of $\\mathrm{s^{-1}}$ because $N_{\\min} - N_{\\mathrm{ts}} = 1$ for a first-order saddle, ensuring the ratio of products has units of inverse time.\n\nSensitivity to a uniform frequency scale factor: Consider scaling every vibrational frequency at both stationary points by a common factor $s0$, so $\\nu \\mapsto s \\nu$. The prefactor then scales as\n$$\n\\frac{\\prod_{i=1}^{N_{\\min}} (s \\nu^{\\min}_{i})}{\\prod_{j=1}^{N_{\\mathrm{ts}}} (s \\nu^{\\mathrm{ts}}_{j})}\n= s^{N_{\\min} - N_{\\mathrm{ts}}} \\left(\\frac{\\prod_{i=1}^{N_{\\min}} \\nu^{\\min}_{i}}{\\prod_{j=1}^{N_{\\mathrm{ts}}} \\nu^{\\mathrm{ts}}_{j}}\\right).\n$$\nFor a first-order saddle, $N_{\\min} - N_{\\mathrm{ts}} = 1$, so the prefactor, and hence the rate, scales linearly with $s$. Therefore, the logarithmic sensitivity to a uniform frequency scale factor is\n$$\nS_{\\mathrm{scale}} \\;\\equiv\\; \\frac{\\partial \\ln k}{\\partial \\ln s} \\;=\\; N_{\\min} - N_{\\mathrm{ts}} \\;=\\; 1.\n$$\n\nSensitivity to the barrier: The dependence on the barrier is through the Boltzmann factor,\n$$\n\\ln k(T) \\;=\\; \\ln\\!\\left(\\frac{\\prod_{i=1}^{N_{\\min}} \\nu^{\\min}_{i}}{\\prod_{j=1}^{N_{\\mathrm{ts}}} \\nu^{\\mathrm{ts}}_{j}}\\right) \\;-\\; \\frac{\\Delta E}{k_{\\mathrm{B}} T}.\n$$\nDifferentiating with respect to $\\Delta E$ gives the logarithmic sensitivity\n$$\nS_{E} \\;\\equiv\\; \\frac{\\partial \\ln k}{\\partial \\Delta E} \\;=\\; -\\,\\frac{1}{k_{\\mathrm{B}} T},\n$$\nwhich has units of $\\mathrm{eV^{-1}}$ when $\\Delta E$ is expressed in electronvolts and $k_{\\mathrm{B}} T$ is in electronvolts.\n\nFinite error factors: For a uniform multiplicative frequency bias $(1+\\epsilon_{\\nu})$ applied to all frequencies, the finite sensitivity factor is\n$$\nR_{\\nu} \\;\\equiv\\; \\frac{k(T;\\ (1+\\epsilon_{\\nu})\\times\\{\\nu\\},\\ \\Delta E)}{k(T;\\ \\{\\nu\\},\\ \\Delta E)}\n\\;=\\; (1+\\epsilon_{\\nu})^{N_{\\min} - N_{\\mathrm{ts}}}\n\\;=\\; 1+\\epsilon_{\\nu},\n$$\nfor a first-order saddle. For an additive barrier error $\\epsilon_{E}$, the finite sensitivity factor is\n$$\nR_{E} \\;\\equiv\\; \\frac{k(T;\\ \\{\\nu\\},\\ \\Delta E+\\epsilon_{E})}{k(T;\\ \\{\\nu\\},\\ \\Delta E)}\n\\;=\\; \\exp\\!\\left(-\\frac{\\epsilon_{E}}{k_{\\mathrm{B}} T}\\right).\n$$\n\nAlgorithmic design:\n1. Convert the provided vibrational frequencies from $\\mathrm{THz}$ to $\\mathrm{s^{-1}}$ using $1\\ \\mathrm{THz} = 10^{12}\\ \\mathrm{s^{-1}}$.\n2. Compute the logarithm of the prefactor to maintain numerical stability:\n   $$\n   \\ln A \\;=\\; \\sum_{i=1}^{N_{\\min}} \\ln \\nu^{\\min}_{i} \\;-\\; \\sum_{j=1}^{N_{\\mathrm{ts}}} \\ln \\nu^{\\mathrm{ts}}_{j},\n   \\quad\n   A \\;=\\; e^{\\ln A}.\n   $$\n3. Evaluate the rate\n   $$\n   k(T) \\;=\\; A \\,\\exp\\!\\left(-\\frac{\\Delta E}{k_{\\mathrm{B}} T}\\right).\n   $$\n4. Evaluate $R_{\\nu}$ by recomputing the rate with every frequency multiplied by $(1+\\epsilon_{\\nu})$. Evaluate $R_{E}$ by recomputing the rate with $\\Delta E \\mapsto \\Delta E+\\epsilon_{E}$.\n5. Compute $S_{\\mathrm{scale}} = 1$ (from the mode count difference) and $S_{E} = -1/(k_{\\mathrm{B}} T)$.\n6. Round all reported floats to six significant figures and print the list of per-case results as a single line.\n\nScientific realism and interpretation:\n- The frequencies are typical vibrational scales for adsorbate or defect modes in solids, in the range of a few to tens of $\\mathrm{THz}$.\n- The barrier values are representative of diffusion or reaction activation energies.\n- The analysis highlights that a small absolute error in $\\Delta E$ can dominate the uncertainty in $k(T)$ at low temperature via the exponential dependence, while uniform frequency biases affect $k(T)$ linearly with a sensitivity fixed by the difference in the number of real modes at the minimum and the transition state.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef vineyard_rate(freq_min_thz, freq_ts_thz, deltaE_eV, T_K, kB_eV_per_K=8.617333262145e-5):\n    \"\"\"\n    Compute the harmonic Vineyard TST rate:\n        k(T) = (prod_i nu_i^min / prod_j nu_j^ts) * exp(-DeltaE / (kB T))\n    Frequencies are ordinary frequencies (not angular) in THz and converted to Hz.\n    \"\"\"\n    # Convert THz to Hz\n    freq_min_hz = np.array(freq_min_thz, dtype=float) * 1e12\n    freq_ts_hz = np.array(freq_ts_thz, dtype=float) * 1e12\n\n    # Numerical stability: compute log of product difference\n    lnA = np.sum(np.log(freq_min_hz)) - np.sum(np.log(freq_ts_hz))\n    A = np.exp(lnA)  # s^-1\n\n    beta = 1.0 / (kB_eV_per_K * T_K)  # 1/eV\n    k = A * np.exp(-deltaE_eV * beta)\n    return k\n\ndef format_sigfig(x, sig=6):\n    # Format a float to specified significant figures using general format.\n    # Ensure standard 'inf'/'nan' are handled, but they shouldn't occur here.\n    return f\"{x:.{sig}g}\"\n\ndef solve():\n    # Define vibrational datasets (THz)\n    freq_min_thz = [3.2, 5.1, 7.0, 8.4, 10.0, 12.3]\n    freq_ts_thz  = [2.9, 4.7, 6.5, 7.9, 11.5]\n\n    # Test cases: (DeltaE [eV], T [K], eps_nu [dimensionless], eps_E [eV])\n    test_cases = [\n        (0.6, 500.0, 0.05, 0.05),\n        (0.6, 200.0, 0.05, 0.05),\n        (0.6, 1200.0, 0.05, 0.05),\n        (0.05, 500.0, 0.05, 0.05),\n    ]\n\n    kB_eV_per_K = 8.617333262145e-5\n\n    results = []\n    for deltaE_eV, T_K, eps_nu, eps_E in test_cases:\n        # Baseline rate\n        k_base = vineyard_rate(freq_min_thz, freq_ts_thz, deltaE_eV, T_K, kB_eV_per_K)\n\n        # Frequency-bias sensitivity: scale all frequencies by (1 + eps_nu)\n        scale = 1.0 + eps_nu\n        freq_min_scaled = [scale * f for f in freq_min_thz]\n        freq_ts_scaled  = [scale * f for f in freq_ts_thz]\n        k_freq_bias = vineyard_rate(freq_min_scaled, freq_ts_scaled, deltaE_eV, T_K, kB_eV_per_K)\n        R_nu = k_freq_bias / k_base if k_base != 0.0 else np.nan\n\n        # Barrier-error sensitivity: add eps_E to barrier\n        k_E_bias = vineyard_rate(freq_min_thz, freq_ts_thz, deltaE_eV + eps_E, T_K, kB_eV_per_K)\n        R_E = k_E_bias / k_base if k_base != 0.0 else np.nan\n\n        # Logarithmic sensitivities\n        # For first-order saddle: N_min - N_ts = 1\n        S_scale = 1.0\n        S_E = -1.0 / (kB_eV_per_K * T_K)\n\n        results.append([\n            float(format_sigfig(k_base)),\n            float(format_sigfig(R_nu)),\n            float(format_sigfig(R_E)),\n            float(format_sigfig(S_scale)),\n            float(format_sigfig(S_E)),\n        ])\n\n    # Final print statement in the exact required format.\n    # Print as a single Python-style list literal on one line.\n    # Ensure floats are represented without additional quotes.\n    def list_to_str(lst):\n        return \"[\" + \",\".join(map(str, lst)) + \"]\"\n\n    print(\"[\" + \",\".join(list_to_str(case) for case in results) + \"]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A direct implementation of the KMC algorithm, which requires scanning all $N$ possible events at each step, is computationally prohibitive for realistic systems. This exercise guides you through implementing an efficient solution using a Binary Indexed Tree (BIT) to manage the event catalog . You will implement the two most critical operations—logarithmic-time event selection and rate updates—that form the core of the celebrated Bortz-Kalos-Lebowitz (BKL) algorithm, a standard for efficient KMC.",
            "id": "3459841",
            "problem": "Consider a kinetic Monte Carlo (KMC) process in which a discrete set of events indexed by $i \\in \\{1,2,\\dots,N\\}$ each occurs with a nonnegative rate $r_i$. The KMC method selects the next event according to probabilities proportional to $r_i$, and advances time by an exponentially distributed waiting time with rate parameter equal to the total rate. From the theory of independent Poisson processes and continuous-time Markov chains, the waiting time to the next event is exponentially distributed with parameter $R_{\\mathrm{tot}} = \\sum_{i=1}^{N} r_i$, and the event index is drawn with probability $r_i / R_{\\mathrm{tot}}$. Inverse transform sampling for the discrete event selection proceeds by drawing a uniform random variable $u \\in (0,1)$ and setting $y = u \\cdot R_{\\mathrm{tot}}$; the selected event is the smallest index $k$ such that the cumulative sum $\\sum_{i=1}^{k} r_i$ exceeds $y$.\n\nYour task is to implement event selection and local update operations using a Binary Indexed Tree (BIT; also known as a Fenwick tree) that stores partial sums of rates $\\{r_i\\}$. The BIT must support the following operations in $O(\\log N)$ time:\n\n- Construction from an array of rates $\\{r_i\\}_{i=1}^{N}$ with $r_i \\ge 0$.\n- Event selection via inverse transform sampling: given $u \\in (0,1)$, compute $y = u \\cdot R_{\\mathrm{tot}}$, and find the smallest index $k$ such that $\\sum_{i=1}^{k} r_i  y$. The program must return the zero-based index $k-1$ and count the number of steps used in the BIT search.\n- Local rate update: given an index $j$ and a new rate $r'_j$, update the BIT to reflect the change from $r_j$ to $r'_j$. The program must count and report the total number of BIT update steps performed across all specified updates.\n\nFundamental base to use: define the KMC selection probability for event $i$ as $r_i / R_{\\mathrm{tot}}$; use inverse transform sampling by mapping a uniform $u \\in (0,1)$ to a threshold $y = u \\cdot R_{\\mathrm{tot}}$ and selecting the smallest $k$ with $\\sum_{i=1}^{k} r_i  y$. Use Binary Indexed Tree (BIT) properties for partial sums and binary lifting search, ensuring both selection and updates are $O(\\log N)$ operations through powers-of-two decomposition.\n\nYour program must be self-contained, perform no input/output other than the final print, and compute the following for each test case:\n\n- The selected zero-based event index before any updates.\n- The number of steps used in the BIT search for selection before any updates.\n- The total rate $R_{\\mathrm{tot}}$ before any updates.\n- The total number of BIT update steps aggregated over all specified updates.\n- The selected zero-based event index after applying all updates.\n- The number of steps used in the BIT search for selection after updates.\n- The total rate $R_{\\mathrm{tot}}$ after updates.\n\nAll quantities are dimensionless. Indices in the final output must be zero-based. The BIT step counts are integers. The total rates are floats.\n\nTest Suite:\nProvide three test cases to validate correct operation, different facets, and edge conditions. For each case, specify $N$, the rates $r$, the pre-update uniform $u_{\\mathrm{before}}$, a list of updates specified by $(i, r'_i)$ in one-based indexing, and the post-update uniform $u_{\\mathrm{after}}$.\n\n- Case $1$ (single event, trivial boundary):\n  - $N = 1$\n  - $r = [5.0]$\n  - $u_{\\mathrm{before}} = 0.37$\n  - updates $= [(1, 10.0)]$\n  - $u_{\\mathrm{after}} = 0.37$\n\n- Case $2$ (mixed zero and nonzero rates, multiple updates):\n  - $N = 8$\n  - $r = [0.5, 1.0, 0.0, 1.5, 0.2, 0.0, 3.0, 2.3]$\n  - $u_{\\mathrm{before}} = 0.73$\n  - updates $= [(3, 0.8), (7, 2.4)]$\n  - $u_{\\mathrm{after}} = 0.41$\n\n- Case $3$ (sparse rates, edge selection near the tail and major update):\n  - $N = 16$\n  - $r = [0.0, 4.2, 0.0, 0.0, 0.3, 0.0, 0.0, 1.1, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 2.0]$\n  - $u_{\\mathrm{before}} = 0.99$\n  - updates $= [(2, 0.0), (16, 4.0)]$\n  - $u_{\\mathrm{after}} = 0.25$\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case result is a list of the seven values in the order specified above, for example:\n$[[k_{\\mathrm{b}}, s_{\\mathrm{b}}, R_{\\mathrm{b}}, u\\!s, k_{\\mathrm{a}}, s_{\\mathrm{a}}, R_{\\mathrm{a}}], [\\dots], [\\dots]]$.",
            "solution": "The problem requires the implementation of a data structure to accelerate two core operations in a kinetic Monte Carlo (KMC) simulation: the selection of the next event and the update of event rates. The specified algorithm for event selection is inverse transform sampling, which maps a uniform random number $u \\in (0,1)$ to a selection threshold $y = u \\cdot R_{\\mathrm{tot}}$, where $R_{\\mathrm{tot}} = \\sum_{i=1}^{N} r_i$ is the total rate of all $N$ possible events. The chosen event is the one with the smallest index $k$ such that the cumulative sum of rates $S_k = \\sum_{i=1}^{k} r_i$ is greater than $y$.\n\nA naive implementation would require $O(N)$ time to compute $S_k$ for each potential event $k$, leading to an $O(N)$ selection process. Similarly, updating a single rate $r_j$ and re-computing $R_{\\mathrm{tot}}$ is straightforward but inefficient if many such operations are needed. The problem mandates the use of a Binary Indexed Tree (BIT), also known as a Fenwick tree, to optimize these operations to logarithmic time complexity, i.e., $O(\\log N)$.\n\nA Binary Indexed Tree is a data structure that can efficiently calculate prefix sums and perform updates on the underlying values. It is typically implemented using an array, say `tree`, of size $N+1$. For $1$-based indexing, `tree[idx]` does not store the single value `rates[idx-1]` nor the full prefix sum up to `idx`. Instead, it stores the sum over a specific sub-range of indices. The structure is designed such that any prefix sum $\\sum_{i=1}^{k} r_i$ can be calculated by summing just $O(\\log k)$ entries in the `tree` array. Conversely, updating a single rate $r_j$ requires updating only $O(\\log N)$ entries.\n\nThe core operations of the BIT are as follows, using one-based indexing for clarity:\n\n$1$. **Update Operation (`update(j, delta)`):** To add a value `delta` to the rate $r_j$, we must update all entries in the `tree` array that include $r_j$ in their sum. The indices to be updated are found by starting at $j$ and repeatedly adding the value of the least significant bit of the current index: $j \\to j + (j \\ \\\\ (-j))$, where `` is the bitwise AND operator. This process continues until the index exceeds $N$. The number of nodes visited, and thus the time complexity, is $O(\\log N)$. We will count each node update as one step.\n\n$2$. **Prefix Sum Query (`prefix_sum(k)`):** To calculate $S_k = \\sum_{i=1}^{k} r_i$, we sum entries from the `tree` array by starting at index $k$ and repeatedly subtracting the least significant bit: $k \\to k - (k \\ \\\\ (-k))$, until the index becomes $0$. This also involves visiting $O(\\log k)$ nodes. The total rate $R_{\\mathrm{tot}}$ is simply `prefix_sum(N)`.\n\n$3$. **Event Selection via Search (`find_k(y)`):** The crucial task is to find the smallest index $k$ such that $S_k  y$. A naive binary search on the index $k$ combined with `prefix_sum` calls would result in an $O(\\log^2 N)$ algorithm. A more efficient $O(\\log N)$ search can be performed directly on the BIT. This technique, often called binary lifting or bit-by-bit search, works by determining the bits of the target index from most significant to least significant. We start with the largest power of two, $p$, less than or equal to $N$. We maintain a current index `idx` (initially $0$) and a `current_sum`. At each step, for a power of two $p$, we check if we can \"jump\" forward by $p$. If `idx + p` is a valid index and adding `tree[idx + p]` to `current_sum` does not exceed the threshold $y$, we perform the jump: `current_sum += tree[idx + p]` and `idx += p`. We then proceed to the next smaller power of two, $p/2$. This process resembles a walk down the implicit tree structure represented by the BIT. After checking all powers of two, `idx` will hold the largest index whose prefix sum is less than or equal to $y$. The desired event index is therefore `idx + 1`. The number of steps for this search is the number of powers of two considered, which is $O(\\log N)$.\n\nOur implementation will be encapsulated in a `BIT` class. This class will manage an array for the tree structure and an array to store the original rates, which is necessary to calculate the `delta` for updates. The class provides methods for building the tree from an initial set of rates, updating a specific rate (and counting the steps), and performing the efficient search for event selection (also counting steps). The indices for updates provided in the problem are $1$-based, which we convert to $0$-based for array access in Python, while the internal BIT logic conveniently uses $1$-based indices.\n\nFor each test case, we perform the following sequence:\n$1$. Instantiate and build the `BIT` with the initial rates.\n$2$. Calculate the total rate $R_{\\mathrm{before}}$ and the threshold $y_{\\mathrm{before}} = u_{\\mathrm{before}} \\cdot R_{\\mathrm{before}}$.\n$3$. Use the `find_k` method to determine the selected event index $k_{\\mathrm{before}}$ and the number of search steps $s_{\\mathrm{before}}$.\n$4$. Sequentially apply all specified rate updates, accumulating the total number of BIT update steps, $us$.\n$5$. After all updates, calculate the new total rate $R_{\\mathrm{after}}$ and the new threshold $y_{\\mathrm{after}} = u_{\\mathrm{after}} \\cdot R_{\\mathrm{after}}$.\n$6$. Use `find_k` again to find the new event index $k_{\\mathrm{after}}$ and search steps $s_{\\mathrm{after}}$.\n$7$. Collect these seven quantities: $[k_{\\mathrm{b}}, s_{\\mathrm{b}}, R_{\\mathrm{b}}, us, k_{\\mathrm{a}}, s_{\\mathrm{a}}, R_{\\mathrm{a}}]$ and format them as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass BIT:\n    \"\"\"\n    Binary Indexed Tree (Fenwick Tree) for KMC event selection.\n    This implementation uses 1-based indexing internally for the tree\n    but exposes a 0-based indexing interface for rates.\n    \"\"\"\n    def __init__(self, size: int):\n        if size = 0:\n            raise ValueError(\"Size must be positive.\")\n        self.size = size\n        self.tree = [0.0] * (size + 1)\n        self.rates = [0.0] * size\n\n    def _add(self, index_1based: int, delta: float) - int:\n        \"\"\"\n        Private helper to add a delta to the tree.\n        Counts and returns the number of steps (nodes updated).\n        \"\"\"\n        steps = 0\n        idx = index_1based\n        while idx = self.size:\n            self.tree[idx] += delta\n            steps += 1\n            idx += idx  -idx\n        return steps\n\n    def build(self, initial_rates: list[float]):\n        \"\"\"\n        Builds the BIT from an initial list of rates.\n        This is an O(N log N) construction.\n        \"\"\"\n        self.rates = list(initial_rates)\n        for i, rate in enumerate(self.rates):\n            if rate != 0.0:\n                # Use _add but don't count steps for initial build\n                self._add(i + 1, rate)\n\n    def update_rate(self, index_0based: int, new_rate: float) - int:\n        \"\"\"\n        Updates the rate at a given 0-based index to a new value.\n        Counts and returns the number of steps for this update.\n        \"\"\"\n        delta = new_rate - self.rates[index_0based]\n        self.rates[index_0based] = new_rate\n        return self._add(index_0based + 1, delta)\n\n    def get_total_rate(self) - float:\n        \"\"\"\n        Returns the total sum of all rates, R_tot.\n        This is equivalent to a prefix sum up to N.\n        \"\"\"\n        total = 0.0\n        idx = self.size\n        # This is a prefix sum query, but we don't count steps for this.\n        # A more efficient way is to look at tree nodes corresponding to powers of 2,\n        # but this is general and correct.\n        while idx  0:\n            total += self.tree[idx]\n            idx -= idx  -idx\n        return total\n\n    def find_k(self, y: float) - tuple[int, int]:\n        \"\"\"\n        Finds the smallest 0-based index k-1 such that sum_{i=1 to k} r_i  y.\n        Uses an O(log N) binary lifting search on the BIT.\n        Returns the 0-based index and the number of search steps.\n        \"\"\"\n        idx = 0\n        current_sum = 0.0\n        steps = 0\n        \n        # Determine the largest power of 2 less than or equal to self.size\n        if self.size == 0:\n            return -1, 0\n        p = 1  (self.size.bit_length() - 1)\n\n        while p  0:\n            steps += 1\n            if idx + p = self.size:\n                test_val = self.tree[idx + p]\n                if current_sum + test_val = y:\n                    current_sum += test_val\n                    idx += p\n            p = 1\n            \n        # idx is now the largest index_0based whose cumulative sum is = y.\n        # The first index to exceed y is therefore idx (if we consider idx as the next index).\n        # The result of the search `idx` gives the length of the prefix that is = y.\n        # So, the result is the 0-based index `idx`.\n        # Example: if prefix sums are [2, 5, 8] and y=6, search finds prefix length 2 (sum 5). `idx`=2.\n        # The desired 0-based index is 2 (value 8).\n        # The returned `idx` is already the correct 0-based index.\n        return idx, steps\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (single event, trivial boundary):\n        {\n            \"N\": 1,\n            \"r\": [5.0],\n            \"u_before\": 0.37,\n            \"updates\": [(1, 10.0)],\n            \"u_after\": 0.37\n        },\n        # Case 2 (mixed zero and nonzero rates, multiple updates):\n        {\n            \"N\": 8,\n            \"r\": [0.5, 1.0, 0.0, 1.5, 0.2, 0.0, 3.0, 2.3],\n            \"u_before\": 0.73,\n            \"updates\": [(3, 0.8), (7, 2.4)],\n            \"u_after\": 0.41\n        },\n        # Case 3 (sparse rates, edge selection near the tail and major update):\n        {\n            \"N\": 16,\n            \"r\": [0.0, 4.2, 0.0, 0.0, 0.3, 0.0, 0.0, 1.1, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 2.0],\n            \"u_before\": 0.99,\n            \"updates\": [(2, 0.0), (16, 4.0)],\n            \"u_after\": 0.25\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        r = case[\"r\"]\n        u_before = case[\"u_before\"]\n        updates = case[\"updates\"]\n        u_after = case[\"u_after\"]\n\n        # --- Initial State ---\n        bit_tree = BIT(N)\n        bit_tree.build(r)\n\n        # --- Before updates ---\n        R_before = bit_tree.get_total_rate()\n        y_before = u_before * R_before if R_before  0 else 0\n        k_before, s_before = bit_tree.find_k(y_before)\n\n        # --- Apply updates ---\n        total_update_steps = 0\n        for idx_1based, new_rate in updates:\n            total_update_steps += bit_tree.update_rate(idx_1based - 1, new_rate)\n            \n        # --- After updates ---\n        R_after = bit_tree.get_total_rate()\n        y_after = u_after * R_after if R_after  0 else 0\n        k_after, s_after = bit_tree.find_k(y_after)\n\n        result = [\n            k_before,\n            s_before,\n            R_before,\n            total_update_steps,\n            k_after,\n            s_after,\n            R_after,\n        ]\n        all_results.append(result)\n\n    # Format the final output string exactly as required, avoiding extra spaces.\n    inner_results_str = []\n    for res in all_results:\n        # Manually format each list to control spacing\n        # Example: [0,1,5.0,1,0,1,10.0]\n        inner_str = f\"[{res[0]},{res[1]},{res[2]},{res[3]},{res[4]},{res[5]},{res[6]}]\"\n        inner_results_str.append(inner_str)\n    \n    final_output = f\"[{','.join(inner_results_str)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "While the $O(\\log N)$ scaling of tree-based methods is a significant improvement, certain scenarios allow for even faster, $O(1)$ event selection using the alias method. This advanced practice explores a rejection-based KMC scheme where a static, easy-to-sample majorant rate distribution is used to propose events, which are then accepted or rejected to recover the exact dynamics . Your task involves not just implementing this powerful technique, but also solving a practical optimization problem: determining the ideal frequency for rebuilding the alias tables to minimize total computational cost.",
            "id": "3459874",
            "problem": "Implement a complete program that models the computational cost trade-off of using the alias method for event selection in Kinetic Monte Carlo (KMC) under rate drift, and optimizes the alias-table rebuild frequency. The model must be grounded in first principles of Poisson superposition and thinning to ensure exactness of the stochastic process.\n\nAssume there are $M$ independent events with positive rates $\\{r_i^{(n)}\\}_{i=1}^M$ at discrete Kinetic Monte Carlo step index $n$. Consider a setting where rates scale uniformly in time according to the simple drift model $r_i^{(n)} = r_i^{(0)} (1 + \\lambda n)$ with $\\lambda \\ge 0$ constant and identical for all $i$, while $r_i^{(0)}  0$. At the beginning of each block of $L$ accepted events, you build a dominating (majorant) rate vector $q_i^{\\text{block}} = (1 + \\lambda L) r_i^{(n_0)}$ using the current baseline $r_i^{(n_0)}$, where $n_0$ is the index at the start of the block and $L$ is the planned number of accepted events before the next rebuild. Within that block, you perform composition-rejection (thinning): propose events from the distribution proportional to $\\{q_i^{\\text{block}}\\}$ using the alias method with $O(1)$ selection time, and accept each proposed event $i$ at step $m \\in \\{0,1,\\dots,L-1\\}$ with probability $r_i^{(n_0+m)}/q_i^{\\text{block}}$. Because the rate drift is uniform across $i$, the acceptance probability does not depend on $i$ within the block and equals $(1+\\lambda m)/(1+\\lambda L)$ at step $m$.\n\nAdopt the following abstract operation-count cost model (units are in abstract operation units; you must report only these unitless counts):\n- Building an alias table for a vector of length $M$ costs $c_{\\text{build}} \\cdot M$.\n- Each proposal draw from the alias table costs $c_{\\text{select}}$.\n- Each acceptance-rejection check costs $c_{\\text{check}}$.\n- Each accepted event update costs $c_{\\text{update}}$.\n\nIf you rebuild alias tables after every $K$ accepted events (the rebuild period), a total of $N$ accepted events are to be generated. For a block of length $L$, the expected number of proposals needed to realize $L$ accepted events is the sum over geometric expectations with success probabilities $\\{p_m\\}_{m=0}^{L-1}$, where $p_m = (1+\\lambda m)/(1+\\lambda L)$. The total expected proposals across all blocks add linearly. The total expected cost as a function of $K$ includes the alias-table rebuild cost per block, the per-proposal costs, and the per-accepted-event update costs.\n\nYour tasks are:\n1. Implement the alias-method setup and $O(1)$ sampler for an arbitrary discrete distribution over $M$ events. The setup takes a vector of nonnegative weights and produces the alias tables; the sampler draws according to the normalized weights.\n2. Derive, from first principles, a closed-form expression or algorithm to compute the expected number of proposals for a block of length $L$ under the drift model described. Use this to compute the total expected cost for producing $N$ accepted events with rebuild period $K$, accounting for the last (possibly partial) block by using its actual length.\n3. Given a search range $K \\in \\{K_{\\min}, K_{\\min}+1, \\dots, K_{\\max}\\}$, compute the value of $K$ that minimizes the total expected cost. If multiple $K$ minimize the cost, choose the smallest such $K$.\n\nUse the following test suite, where all symbols are as defined above:\n- Test case $1$: $M=100000$, $N=200000$, $\\lambda=1\\times 10^{-5}$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=5000$.\n- Test case $2$: $M=500000$, $N=100000$, $\\lambda=5\\times 10^{-5}$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=5000$.\n- Test case $3$: $M=100000$, $N=100000$, $\\lambda=0$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=10000$.\n- Test case $4$: $M=100000$, $N=50000$, $\\lambda=1\\times 10^{-3}$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=2000$.\n\nThe required final output format is: your program must produce a single line containing a list of four integers, each the minimizing $K$ for the corresponding test case, as a comma-separated list enclosed in square brackets, for example, \"[3,7,5,2]\". No other text should be printed.\n\nNo physical units are involved; you must report all outputs in unitless abstract operation counts as specified. Angles are not involved. Percentages must not be used anywhere; use only decimal numbers or integers as appropriate.",
            "solution": "A minor ambiguity exists in the problem's description of the rate drift model. The stated global model, $r_i^{(n)} = r_i^{(0)} (1 + \\lambda n)$, where $n$ is the global accepted event index, leads to an acceptance probability $p_m = \\frac{1+\\lambda(n_0+m)}{(1+\\lambda L)(1+\\lambda n_0)}$ for the $(m+1)$-th accepted event in a block of length $L$ starting at global step $n_0$. This contradicts the problem's explicit statement that the acceptance probability is $p_m = \\frac{1+\\lambda m}{1+\\lambda L}$. This latter expression is, however, fully consistent with a local rate drift model where rates evolve as $r_i^{\\text{in-block}}(m) = r_i^{\\text{block-start}} (1 + \\lambda m)$ for $m \\in \\{0, 1, \\dots, L-1\\}$ accepted events within the block. To ensure self-consistency, this solution will proceed by adopting the explicitly provided acceptance probability $p_m = \\frac{1+\\lambda m}{1+\\lambda L}$ as the correct physical basis for the model.\n\nThe solution is structured as follows: first, the total expected computational cost is derived from first principles. Second, an efficient algorithm to find the optimal alias-table rebuild frequency $K$ that minimizes this cost is formulated. The first task listed in the problem, implementing the alias method, involves a standard algorithm (Vose's method), which is included in the final program code for completeness as requested. It is not central to the derivation of the cost function and is thus not detailed in this explanatory section.\n\n**1. Expected Cost for a Single Block**\n\nLet us derive the total expected cost, $C(L)$, to generate a block of $L$ accepted events. This cost comprises three components: the cost to build the alias table, the cost of all proposals (both accepted and rejected), and the cost to process the accepted events.\n\n- **Alias Table Build Cost:** At the beginning of each block, a new alias table is constructed for the $M$ majorant rates. This incurs a fixed cost of $c_{\\text{build}} \\cdot M$.\n\n- **Accepted Event Update Cost:** Each of the $L$ accepted events incurs a cost $c_{\\text{update}}$. The total update cost for the block is $L \\cdot c_{\\text{update}}$.\n\n- **Proposal and Acceptance Check Cost:** The process of generating one accepted event involves one or more proposals. For the $(m+1)$-th accepted event in the block, where $m \\in \\{0, 1, \\dots, L-1\\}$, the probability of a proposal being accepted is given as $p_m = \\frac{1+\\lambda m}{1+\\lambda L}$. The number of proposals required to achieve one success follows a geometric distribution. The expected number of proposals, $E_m$, for an accepted event at step $m$ is therefore $E_m = 1/p_m$.\n\nThe total expected number of proposals for a block of length $L$, denoted $E_{\\text{proposals}}(L)$, is the sum of the expected numbers of proposals for each of the $L$ accepted events:\n$$E_{\\text{proposals}}(L) = \\sum_{m=0}^{L-1} E_m = \\sum_{m=0}^{L-1} \\frac{1}{p_m} = \\sum_{m=0}^{L-1} \\frac{1+\\lambda L}{1+\\lambda m}$$\nFactoring out the term $(1+\\lambda L)$, which is constant with respect to the summation index $m$, we get:\n$$E_{\\text{proposals}}(L) = (1+\\lambda L) \\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m}$$\nEach proposal consists of a selection from the alias table (cost $c_{\\text{select}}$) and an acceptance/rejection check (cost $c_{\\text{check}}$). The total expected cost for all proposals in the block is therefore $(c_{\\text{select}} + c_{\\text{check}}) \\cdot E_{\\text{proposals}}(L)$.\n\nCombining all components, the total expected cost for a block of length $L$, $C(L)$, is:\n$$C(L) = c_{\\text{build}} \\cdot M + (c_{\\text{select}} + c_{\\text{check}}) (1+\\lambda L) \\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m} + L \\cdot c_{\\text{update}}$$\nFor the special case where $\\lambda = 0$, the acceptance probability $p_m = 1$ for all $m$. The sum becomes $\\sum_{m=0}^{L-1} 1 = L$, and the cost function simplifies to:\n$$C(L)|_{\\lambda=0} = c_{\\text{build}} \\cdot M + (c_{\\text{select}} + c_{\\text{check}}) L + L \\cdot c_{\\text{update}}$$\n\n**2. Total Cost and Optimization**\n\nThe goal is to generate a total of $N$ accepted events, rebuilding the alias table every $K$ events. The simulation is thus partitioned into a series of blocks.\n- The number of full blocks of length $K$ is $N_{\\text{full}} = \\lfloor N/K \\rfloor$.\n- The number of events in the final, possibly partial, block is $L_{\\text{final}} = N \\pmod K$.\n\nThe total expected cost for a given rebuild period $K$, denoted $C_{\\text{total}}(K)$, is the sum of the costs of all blocks.\n$$C_{\\text{total}}(K) = N_{\\text{full}} \\cdot C(K) + C(L_{\\text{final}})$$\nwhere $C(K)$ is the cost for a full block of length $K$ and $C(L_{\\text{final}})$ is the cost for the final block of length $L_{\\text{final}}$. We define $C(0)=0$.\n\nThe optimization problem is to find the integer $K$ in the range $[K_{\\min}, K_{\\max}]$ that minimizes $C_{\\text{total}}(K)$.\n$$K_{\\text{opt}} = \\arg\\min_{K \\in \\{K_{\\min}, \\dots, K_{\\max}\\}} C_{\\text{total}}(K)$$\nThe behavior of $C_{\\text{total}}(K)$ represents a trade-off. For small $K$, the rebuild cost ($c_{\\text{build}} \\cdot M$) dominates as it is incurred frequently ($\\lceil N/K \\rceil$ times). For large $K$, the cost per event within a block increases due to lower acceptance probabilities as rates drift significantly from the majorant, increasing the proposal cost. This trade-off implies the existence of an optimal, non-trivial $K$.\n\n**3. Algorithmic Implementation Strategy**\n\nA direct evaluation of $C_{\\text{total}}(K)$ for each $K$ in the search range $[K_{\\min}, K_{\\max}]$ is required. A naive implementation where the sum $\\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m}$ is recomputed for each block within the main loop would be inefficient, potentially leading to an $O(K_{\\max}^2)$ complexity.\n\nA more efficient, $O(K_{\\max})$ algorithm can be achieved through pre-computation. Let $H(L, \\lambda) = \\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m}$. We can pre-compute and store the values of $H(L, \\lambda)$ for all required block lengths $L \\in \\{1, \\dots, K_{\\max}\\}$. This is done iteratively:\n- $H(0, \\lambda) = 0$\n- $H(L, \\lambda) = H(L-1, \\lambda) + \\frac{1}{1+\\lambda(L-1)}$ for $L \\ge 1$.\n\nWith the $H(L, \\lambda)$ values stored in an array, we can then pre-compute the block costs $C(L)$ for $L \\in \\{1, \\dots, K_{\\max}\\}$.\nFinally, we iterate $K$ from $K_{\\min}$ to $K_{\\max}$. In each iteration, we calculate $C_{\\text{total}}(K)$ using the pre-computed block costs $C(K)$ and $C(N \\pmod K)$ in $O(1)$ time. The value of $K$ yielding the minimum cost is tracked, ensuring that the smallest such $K$ is chosen in case of a tie, as per the problem's requirement. This leads to an overall time complexity of $O(K_{\\max})$.",
            "answer": "```python\nimport numpy as np\n\ndef alias_setup(weights):\n    \"\"\"\n    Constructs the probability and alias tables for Vose's Alias Method.\n\n    Args:\n        weights (np.ndarray): A 1D array of non-negative weights.\n\n    Returns:\n        tuple: A tuple containing the probability table (np.ndarray) and the\n               alias table (np.ndarray).\n    \"\"\"\n    m = weights.size\n    if m == 0:\n        return np.array([]), np.array([], dtype=np.int32)\n    \n    total_weight = np.sum(weights)\n    if total_weight == 0.0:\n        # Uniform distribution if all weights are zero.\n        prob_table = np.full(m, 1.0)\n        alias_table = np.arange(m, dtype=np.int32)\n        return prob_table, alias_table\n\n    scaled_probs = weights * (m / total_weight)\n    \n    small_indices = np.where(scaled_probs  1.0)[0].tolist()\n    large_indices = np.where(scaled_probs = 1.0)[0].tolist()\n    \n    prob_table = np.zeros(m)\n    alias_table = np.zeros(m, dtype=np.int32)\n    \n    while small_indices and large_indices:\n        s_idx = small_indices.pop()\n        l_idx = large_indices.pop()\n        \n        prob_table[s_idx] = scaled_probs[s_idx]\n        alias_table[s_idx] = l_idx\n        \n        scaled_probs[l_idx] = (scaled_probs[l_idx] + scaled_probs[s_idx]) - 1.0\n        \n        if scaled_probs[l_idx]  1.0:\n            small_indices.append(l_idx)\n        else:\n            large_indices.append(l_idx)\n\n    # Handle remaining items due to floating-point inaccuracies.\n    while large_indices:\n        l_idx = large_indices.pop()\n        prob_table[l_idx] = 1.0\n    while small_indices:\n        s_idx = small_indices.pop()\n        prob_table[s_idx] = 1.0\n        \n    return prob_table, alias_table\n\ndef alias_draw(prob_table, alias_table):\n    \"\"\"\n    Draws a random index from the distribution defined by the alias tables.\n\n    Args:\n        prob_table (np.ndarray): The probability table from alias_setup.\n        alias_table (np.ndarray): The alias table from alias_setup.\n\n    Returns:\n        int: A random index drawn from the discrete distribution.\n    \"\"\"\n    m = prob_table.size\n    i = np.random.randint(0, m)\n    if np.random.rand()  prob_table[i]:\n        return i\n    else:\n        return alias_table[i]\n\ndef solve():\n    \"\"\"\n    Solves the KMC cost optimization problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        (100000, 200000, 1e-5, 5, 1, 1, 2, 1, 5000),\n        (500000, 100000, 5e-5, 5, 1, 1, 2, 1, 5000),\n        (100000, 100000, 0.0, 5, 1, 1, 2, 1, 10000),\n        (100000, 50000, 1e-3, 5, 1, 1, 2, 1, 2000)\n    ]\n\n    results = []\n    for case in test_cases:\n        m, n, lam, c_build, c_select, c_check, c_update, k_min, k_max = case\n\n        # Pre-compute the sum H(L, lambda) = sum_{m=0}^{L-1} 1/(1+lam*m)\n        # H_vals array will store H(L, lambda) at index L.\n        H_vals = np.zeros(k_max + 1, dtype=np.float64)\n        if lam == 0.0:\n            # Special case for lambda=0, H(L,0) = L\n            H_vals = np.arange(k_max + 1, dtype=np.float64)\n        else:\n            current_sum = 0.0\n            for l_val in range(1, k_max + 1):\n                current_sum += 1.0 / (1.0 + lam * (l_val - 1))\n                H_vals[l_val] = current_sum\n        \n        # Pre-compute the cost C(L) for a single block of length L.\n        # block_costs[L] will store C(L). block_costs[0] = 0.\n        block_costs = np.zeros(k_max + 1, dtype=np.float64)\n        cost_proposal = c_select + c_check\n        \n        for l_val in range(1, k_max + 1):\n            rebuild_cost = c_build * m\n            update_cost = c_update * l_val\n            \n            if lam == 0.0:\n                expected_proposals = float(l_val)\n            else:\n                expected_proposals = (1.0 + lam * l_val) * H_vals[l_val]\n            \n            proposal_total_cost = cost_proposal * expected_proposals\n            block_costs[l_val] = rebuild_cost + proposal_total_cost + update_cost\n\n        # Find the optimal K by iterating through the search range\n        min_total_cost = float('inf')\n        best_k = -1\n\n        for k in range(k_min, k_max + 1):\n            if k == 0:\n                continue\n\n            num_full_blocks = n // k\n            len_last_block = n % k\n\n            cost_full = block_costs[k]\n            cost_last = block_costs[len_last_block]\n\n            total_cost = num_full_blocks * cost_full + cost_last\n\n            if total_cost  min_total_cost:\n                min_total_cost = total_cost\n                best_k = k\n        \n        results.append(best_k)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}