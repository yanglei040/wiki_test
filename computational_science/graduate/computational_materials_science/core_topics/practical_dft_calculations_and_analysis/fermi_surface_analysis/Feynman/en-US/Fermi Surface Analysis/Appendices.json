{
    "hands_on_practices": [
        {
            "introduction": "Understanding how the Fermi surface changes with electron filling is fundamental, and these changes can involve abrupt topological transformations known as Lifshitz transitions. These transitions are driven by van Hove singularities in the band structure, which are saddle points in the energy landscape $E(\\mathbf{k})$. This analytical exercise  will have you identify these critical points for a tight-binding model, providing a foundational skill for connecting a material's dispersion to qualitative shifts in its electronic properties.",
            "id": "3451548",
            "problem": "Consider a three-dimensional nearest-neighbor tight-binding band on a simple cubic lattice with lattice constant $a$ and hopping amplitude $t0$, with dispersion\n$$\nE(\\mathbf{k})=-2t\\left(\\cos(k_x a)+\\cos(k_y a)+\\cos(k_z a)\\right),\n$$\nwhere $\\mathbf{k}$ lies in the first Brillouin zone $k_i\\in[-\\pi/a,\\pi/a]$ for $i\\in\\{x,y,z\\}$. The Fermi surface (FS) is defined by the locus of $\\mathbf{k}$ satisfying $E(\\mathbf{k})=\\mu$, where $\\mu$ is the chemical potential. A van Hove singularity arises at stationary points of $E(\\mathbf{k})$ in the Brillouin zone where the energy dispersion has an indefinite Hessian (saddle point), and a continuous change in the topology of the FS (a Lifshitz transition) occurs when $\\mu$ crosses the corresponding stationary energy.\n\nStarting from the definitions of stationary points and the classification of critical points via the Hessian matrix, determine all saddle-point energies of $E(\\mathbf{k})$ in the first Brillouin zone. Using these, analyze how the topology of the FS evolves as $\\mu$ is tuned from the band bottom to the band top, and identify all distinct chemical potential values at which a Lifshitz transition driven by a van Hove crossing occurs. Express your final answer for the critical chemical potential value(s) in terms of $t$ (use $t$ as the energy unit). The final answer must be given as a symbolic expression. Do not include any units in the final answer.",
            "solution": "The problem asks for the chemical potential values $\\mu$ at which a Lifshitz transition, driven by a van Hove singularity, occurs for a given tight-binding model on a simple cubic lattice. The dispersion relation is given by\n$$\nE(\\mathbf{k}) = -2t\\left(\\cos(k_x a) + \\cos(k_y a) + \\cos(k_z a)\\right)\n$$\nwhere $t0$ is the hopping amplitude, $a$ is the lattice constant, and $\\mathbf{k}=(k_x, k_y, k_z)$ is a wavevector in the first Brillouin zone (BZ), defined by $k_i \\in [-\\pi/a, \\pi/a]$ for $i \\in \\{x,y,z\\}$.\n\nA Lifshitz transition occurs when the chemical potential $\\mu$ crosses the energy of a stationary point of the dispersion $E(\\mathbf{k})$. A van Hove singularity corresponds to such a stationary point. We begin by finding all stationary points $\\mathbf{k}^*$ in the BZ by solving $\\nabla_{\\mathbf{k}} E(\\mathbf{k}) = \\mathbf{0}$.\n\nThe components of the gradient are:\n$$\n\\frac{\\partial E}{\\partial k_x} = 2ta \\sin(k_x a)\n$$\n$$\n\\frac{\\partial E}{\\partial k_y} = 2ta \\sin(k_y a)\n$$\n$$\n\\frac{\\partial E}{\\partial k_z} = 2ta \\sin(k_z a)\n$$\nSetting the gradient to zero gives $\\sin(k_i a) = 0$ for each component $i \\in \\{x,y,z\\}$. Within the first BZ, this condition is satisfied when $k_i a \\in \\{0, \\pi\\}$. We note that points on the BZ boundary like $k_i a = -\\pi$ are equivalent to $k_i a = \\pi$ by a reciprocal lattice vector. This yields $2^3 = 8$ distinct high-symmetry points in the BZ.\n\nTo classify these stationary points, we compute the Hessian matrix, $H_{ij} = \\frac{\\partial^2 E}{\\partial k_i \\partial k_j}$. The second partial derivatives are:\n$$\n\\frac{\\partial^2 E}{\\partial k_x^2} = 2ta^2 \\cos(k_x a)\n$$\n$$\n\\frac{\\partial^2 E}{\\partial k_y^2} = 2ta^2 \\cos(k_y a)\n$$\n$$\n\\frac{\\partial^2 E}{\\partial k_z^2} = 2ta^2 \\cos(k_z a)\n$$\nAll off-diagonal terms $\\frac{\\partial^2 E}{\\partial k_i \\partial k_j}$ for $i \\neq j$ are zero. Thus, the Hessian matrix is diagonal:\n$$\nH(\\mathbf{k}) = 2ta^2 \\begin{pmatrix} \\cos(k_x a)  0  0 \\\\ 0  \\cos(k_y a)  0 \\\\ 0  0  \\cos(k_z a) \\end{pmatrix}\n$$\nThe eigenvalues of $H$ are its diagonal elements. The nature of a stationary point is determined by the signs of these eigenvalues. Since $t0$ and $a0$, the signs are determined by the values of $\\cos(k_i a)$, which are either $\\cos(0)=1$ or $\\cos(\\pi)=-1$.\n\nWe now classify the stationary points and find their energies:\n1.  **Point $\\Gamma$**: $\\mathbf{k}a = (0,0,0)$.\n    Here, $\\cos(k_i a)=1$ for all $i$. The eigenvalues of $H$ are all positive ($2ta^2, 2ta^2, 2ta^2$). This point is a local minimum.\n    The energy is $E_{\\min} = E(0,0,0) = -2t(1+1+1) = -6t$. This is the band bottom.\n\n2.  **Points $X$**: $\\mathbf{k}a = (\\pi,0,0)$ and its two permutations $(0,\\pi,0)$ and $(0,0,\\pi)$.\n    For $\\mathbf{k}a=(\\pi,0,0)$, the cosines are $(-1,1,1)$. The eigenvalues of $H$ have signs $(-,+,+)$. These are saddle points of index $1$.\n    The energy at these points is $E_1 = E(\\pi/a,0,0) = -2t(-1+1+1) = -2t$.\n\n3.  **Points $M$**: $\\mathbf{k}a = (\\pi,\\pi,0)$ and its two permutations $(\\pi,0,\\pi)$ and $(0,\\pi,\\pi)$.\n    For $\\mathbf{k}a=(\\pi,\\pi,0)$, the cosines are $(-1,-1,1)$. The eigenvalues of $H$ have signs $(-,-,+)$. These are saddle points of index $2$.\n    The energy at these points is $E_2 = E(\\pi/a,\\pi/a,0) = -2t(-1-1+1) = 2t$.\n\n4.  **Point $R$**: $\\mathbf{k}a = (\\pi,\\pi,\\pi)$.\n    Here, $\\cos(k_i a)=-1$ for all $i$. The eigenvalues of $H$ are all negative ($-2ta^2, -2ta^2, -2ta^2$). This point is a local maximum.\n    The energy is $E_{\\max}=E(\\pi/a,\\pi/a,\\pi/a) = -2t(-1-1-1) = 6t$. This is the band top.\n\nThe problem asks for the chemical potential values $\\mu$ where Lifshitz transitions are driven by a van Hove crossing. These correspond to the energies of the saddle points, where the Hessian matrix is indefinite. From our analysis, these are the energies $E_1 = -2t$ and $E_2 = 2t$.\n\nThe evolution of the Fermi surface (FS) topology as $\\mu$ increases from $-6t$ to $6t$ confirms these transitions:\n-   For $\\mu$ just above $-6t$, the FS consists of small, closed spherical electron pockets centered at the $\\Gamma$ point.\n-   At $\\mu = -2t$, the FS, which has grown from the $\\Gamma$ point, makes contact with the BZ boundary at the $X$ points. This corresponds to the FS touching its periodic images, causing a topological change from a closed surface to a single, connected, open \"jungle-gym\" structure. This is the first Lifshitz transition.\n-   At $\\mu = 2t$, the open FS undergoes another topological change. This is best viewed from the perspective of hole states near the band top. The previously connected structure of unoccupied states breaks apart. The FS transitions from a single open surface to a set of disjoint, closed hole pockets centered at the $R$ point. This is the second Lifshitz transition.\n-   For $\\mu$ approaching $6t$, the FS consists of small, shrinking hole pockets around the $R$ point, which vanish at $\\mu=6t$.\n\nThe distinct chemical potential values at which these saddle-point-driven Lifshitz transitions occur are therefore the energies of the $X$ and $M$ points.\n$$\n\\mu_1 = -2t\n$$\n$$\n\\mu_2 = 2t\n$$\nThese are the energies of the van Hove singularities associated with saddle points in the band structure.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -2t  2t \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While first-principles calculations provide highly accurate electronic structures, simpler analytical models like the tight-binding approximation are invaluable for physical insight. This hands-on coding practice  simulates the common workflow of parameterizing such a model by fitting its hopping parameters, like $t_1$ and $t_2$, to synthetic `ab initio` energy data. You will gain practical experience in data fitting and, crucially, in assessing the physical plausibility of the resulting model, a key step in building predictive theoretical tools.",
            "id": "3451506",
            "problem": "You are given a task grounded in the analysis of Fermi surfaces in computational materials science. Start from the well-established premise of the Tight-Binding (TB) approximation for a single-band on a two-dimensional square lattice with up to next-next-nearest neighbor hopping. In this framework, the electronic band energy as a function of crystal momentum $\\mathbf{k} = (k_x,k_y)$ can be represented by a Fourier series whose coefficients are hopping amplitudes. For a minimal but expressive model, adopt the following parametric form for the energy:\n$$\nE(\\mathbf{k}) \\equiv E(k_x,k_y) = \\epsilon_0 - 2 t_1 \\left(\\cos k_x + \\cos k_y\\right) - 4 t_2 \\cos k_x \\cos k_y - 2 t_3 \\left(\\cos 2 k_x + \\cos 2 k_y\\right),\n$$\nwhere $\\epsilon_0$ is an onsite energy measured relative to the Fermi energy (set to $0$), and $t_1$, $t_2$, $t_3$ are hopping amplitudes. All energies must be expressed in electronvolts (eV), and all angles must be in radians.\n\nYour task is to write a complete and runnable program that:\n- Generates synthetic \"ab initio\" energy data $E_i$ along specified cuts through momentum space $\\mathbf{k}_i$, using known ground-truth parameters and a Gaussian noise model with a specified pseudorandom seed. The independent variable $\\mathbf{k}$ must be sampled along two orthogonal cuts for each test case: one at fixed $k_y = k_{y,0}$ as $k_x$ varies, and one at fixed $k_x = k_{x,0}$ as $k_y$ varies. The cosine arguments are in radians and the Brillouin-zone range is $[0,\\pi]$ for both $k_x$ and $k_y$.\n- Fits the TB parameters $\\theta = [\\epsilon_0, t_1, t_2, t_3]^T$ by ordinary least squares on the linear form\n$$\nE(\\mathbf{k}) = \\epsilon_0 + t_1 X_1(\\mathbf{k}) + t_2 X_2(\\mathbf{k}) + t_3 X_3(\\mathbf{k}),\n$$\nwhere\n$$\nX_1(\\mathbf{k}) = -2 \\left(\\cos k_x + \\cos k_y\\right), \\quad X_2(\\mathbf{k}) = -4 \\cos k_x \\cos k_y, \\quad X_3(\\mathbf{k}) = -2 \\left(\\cos 2 k_x + \\cos 2 k_y\\right).\n$$\n- Reports the root-mean-square error (RMSE) of the fit in eV, defined as\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\left(E_i - \\widehat{E}_i\\right)^2},\n$$\nrounded to six decimal places.\n- Assesses physical plausibility of the fitted parameters via the following boolean criteria, all of which must simultaneously hold to declare the fit physically plausible:\n    1. Dominant nearest-neighbor hopping: $\\max\\left(|t_2|,|t_3|\\right) \\leq 0.6\\,|t_1|$.\n    2. Small onsite offset relative to the Fermi level: $|\\epsilon_0| \\leq 0.1$ eV.\n    3. Reasonable bandwidth estimate from the model coefficients: $W_{\\mathrm{est}} \\equiv 8|t_1| + 16|t_2| + 8|t_3| \\leq 3.0$ eV.\n- Outputs, for each test case, a list containing the RMSE (as a float rounded to six decimals) and the plausibility decision (as a boolean). The final program output must be a single line containing a list of these per-case results, with no additional text.\n\nUse the following test suite of three cases. In all cases, use $\\pi$ for the Brillouin-zone boundary and sample $k_x$ and $k_y$ linearly over the specified intervals. When generating Gaussian noise, use a zero mean and the specified standard deviation and seed. Energies must be in eV, and angles in radians.\n\n- Case A (general, mildly noisy):\n    - Ground-truth parameters: $\\epsilon_0 = 0.02$ eV, $t_1 = 0.25$ eV, $t_2 = -0.05$ eV, $t_3 = 0.02$ eV.\n    - Cuts: fixed $k_y = \\pi/3$ with $k_x$ sampled at $N_x = 41$ points from $0$ to $\\pi$ inclusive; fixed $k_x = \\pi/5$ with $k_y$ sampled at $N_y = 37$ points from $0$ to $\\pi$ inclusive.\n    - Noise: Gaussian with standard deviation $\\sigma = 0.003$ eV; pseudorandom seed $s = 1$.\n\n- Case B (isotropic nearest-neighbor only, noiseless):\n    - Ground-truth parameters: $\\epsilon_0 = 0.0$ eV, $t_1 = 0.15$ eV, $t_2 = 0.0$ eV, $t_3 = 0.0$ eV.\n    - Cuts: fixed $k_y = \\pi/4$ with $k_x$ sampled at $N_x = 25$ points from $0$ to $\\pi$ inclusive; fixed $k_x = \\pi/2$ with $k_y$ sampled at $N_y = 25$ points from $0$ to $\\pi$ inclusive.\n    - Noise: $\\sigma = 0.0$ eV; pseudorandom seed $s = 2$ (the seed is irrelevant for zero noise but must still be set).\n\n- Case C (near-degenerate anisotropy, mildly noisy):\n    - Ground-truth parameters: $\\epsilon_0 = 0.0$ eV, $t_1 = 0.08$ eV, $t_2 = 0.06$ eV, $t_3 = 0.0$ eV.\n    - Cuts: fixed $k_y = \\pi/6$ with $k_x$ sampled at $N_x = 41$ points from $0$ to $\\pi$ inclusive; fixed $k_x = \\pi/3$ with $k_y$ sampled at $N_y = 41$ points from $0$ to $\\pi$ inclusive.\n    - Noise: Gaussian with standard deviation $\\sigma = 0.002$ eV; pseudorandom seed $s = 3$.\n\nImplementation requirements:\n- Construct the design matrix with one row per data point using the features $X_1(\\mathbf{k})$, $X_2(\\mathbf{k})$, $X_3(\\mathbf{k})$ and an intercept for $\\epsilon_0$.\n- Solve the least-squares problem using a numerically stable method appropriate for linear regression.\n- For each case, compute the RMSE in eV and the plausibility decision as specified above.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact format:\n\"[ [rmse_A,plaus_A], [rmse_B,plaus_B], [rmse_C,plaus_C] ]\"\nwhere each \"rmse_X\" is a float rounded to six decimals and each \"plaus_X\" is a boolean. For example, a structurally correct output would look like \"[[0.001234,True],[0.000000,True],[0.002345,False]]\" but with the actual computed values for the specified test suite.",
            "solution": "The problem presented is a valid and well-posed exercise in computational materials science, specifically in the domain of parameterizing electronic band structures. It requires fitting a Tight-Binding (TB) model to synthetically generated energy data using linear least squares. The validation of the problem statement proceeds as follows.\n\nThe givens are:\n1.  **Energy Model**: The electronic band energy $E(\\mathbf{k})$ for a 2D square lattice is given by:\n    $$\n    E(\\mathbf{k}) \\equiv E(k_x,k_y) = \\epsilon_0 - 2 t_1 \\left(\\cos k_x + \\cos k_y\\right) - 4 t_2 \\cos k_x \\cos k_y - 2 t_3 \\left(\\cos 2 k_x + \\cos 2 k_y\\right)\n    $$\n    where $\\mathbf{k} = (k_x, k_y)$ is the crystal momentum, $\\epsilon_0$ is the onsite energy relative to a Fermi energy of $0$, and $t_1, t_2, t_3$ are hopping amplitudes.\n2.  **Linear Regression Form**: The model is to be fitted in the linear form $E(\\mathbf{k}) = \\epsilon_0 + t_1 X_1(\\mathbf{k}) + t_2 X_2(\\mathbf{k}) + t_3 X_3(\\mathbf{k})$, with coefficients (parameters) $\\theta = [\\epsilon_0, t_1, t_2, t_3]^T$ and basis functions (features):\n    $$\n    X_1(\\mathbf{k}) = -2 \\left(\\cos k_x + \\cos k_y\\right) \\\\\n    X_2(\\mathbf{k}) = -4 \\cos k_x \\cos k_y \\\\\n    X_3(\\mathbf{k}) = -2 \\left(\\cos 2 k_x + \\cos 2 k_y\\right)\n    $$\n3.  **Root-Mean-Square Error (RMSE)**: The fit quality is measured by $\\mathrm{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\left(E_i - \\widehat{E}_i\\right)^2}$, rounded to six decimal places, where $E_i$ are the \"observed\" energies and $\\widehat{E}_i$ are the fitted energies.\n4.  **Physical Plausibility Criteria**: A fit is plausible if and only if all three conditions are met:\n    - Dominant nearest-neighbor hopping: $\\max\\left(|t_2|,|t_3|\\right) \\leq 0.6\\,|t_1|$.\n    - Small onsite offset: $|\\epsilon_0| \\leq 0.1$ eV.\n    - Reasonable bandwidth estimate: $W_{\\mathrm{est}} \\equiv 8|t_1| + 16|t_2| + 8|t_3| \\leq 3.0$ eV.\n5.  **Test Cases**: Three specific cases (A, B, C) are provided with ground-truth parameters, descriptions of momentum-space cuts for data sampling, and specifications for Gaussian noise generation (standard deviation $\\sigma$ and pseudorandom seed $s$).\n\nThe problem is scientifically grounded, well-posed, and objective. It utilizes a standard TB model and a common parameter-fitting technique (ordinary least squares) which is fundamental in this field. All components are clearly defined, including the mathematical model, data generation protocol, error metric, and evaluation criteria. The provided data and constraints are self-consistent and physically reasonable. Therefore, the problem is deemed valid and a solution can be constructed.\n\nThe solution is approached by formulating the task as a linear regression problem. For a set of $N$ data points $(\\mathbf{k}_i, E_i)$, we seek the parameter vector $\\hat{\\theta} = [\\hat{\\epsilon}_0, \\hat{t}_1, \\hat{t}_2, \\hat{t}_3]^T$ that minimizes the sum of squared residuals. This can be expressed in matrix form as minimizing $\\| \\mathbf{E} - A \\theta \\|_2^2$, where $\\mathbf{E}$ is the $N \\times 1$ vector of observed energies, $\\theta$ is the $4 \\times 1$ vector of parameters, and $A$ is the $N \\times 4$ design matrix.\n\nThe columns of the design matrix $A$ correspond to the basis functions of the linear model. For each data point $\\mathbf{k}_i = (k_{x,i}, k_{y,i})$, the corresponding row of $A$ is:\n$$\nA_i = \\begin{bmatrix} 1  X_1(\\mathbf{k}_i)  X_2(\\mathbf{k}_i)  X_3(\\mathbf{k}_i) \\end{bmatrix}\n$$\nThe first column of ones is the regressor for the intercept term, $\\epsilon_0$. The aformentioned basis functions $X_1, X_2, X_3$ constitute the remaining columns.\n\nThe procedure for each test case is as follows:\n1.  **Data Generation**:\n    - The momentum vectors $\\mathbf{k}_i$ are generated by creating two linear grids of points as specified (e.g., using `numpy.linspace`) and concatenating them.\n    - The true energies $E_{\\mathrm{true},i}$ are calculated for each $\\mathbf{k}_i$ using the given ground-truth parameters for that case.\n    - A pseudorandom number generator is seeded, and a vector of Gaussian noise with the specified standard deviation $\\sigma$ is generated.\n    - The final \"observed\" energies are computed as $E_i = E_{\\mathrm{true},i} + \\mathrm{noise}_i$.\n\n2.  **Linear Regression**:\n    - The design matrix $A$ is constructed based on the generated $\\mathbf{k}_i$ vectors.\n    - The ordinary least-squares problem $A\\theta = \\mathbf{E}$ is solved for the parameter vector $\\hat{\\theta}$. This is performed using a numerically stable algorithm, such as one based on QR decomposition or Singular Value Decomposition (SVD), as implemented in `numpy.linalg.lstsq`.\n\n3.  **Analysis**:\n    - The fitted energies are predicted using the determined parameters: $\\widehat{\\mathbf{E}} = A\\hat{\\theta}$.\n    - The RMSE is calculated as the square root of the mean of $(E_i - \\widehat{E}_i)^2$.\n    - The fitted parameters $\\hat{\\epsilon}_0, \\hat{t}_1, \\hat{t}_2, \\hat{t}_3$ are evaluated against the three specified physical plausibility criteria. The overall plausibility is the logical conjunction (AND) of the individual checks.\n\nThis entire process is encapsulated in a program that iterates through the three test cases and formats the results into the required output string.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the Tight-Binding model fitting problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A: General, mildly noisy\n        {\n            \"truth_params\": [0.02, 0.25, -0.05, 0.02],  # [eps0, t1, t2, t3]\n            \"cuts\": [\n                {\"fixed_dim\": \"ky\", \"fixed_val\": np.pi / 3, \"var_dim\": \"kx\", \"n_points\": 41},\n                {\"fixed_dim\": \"kx\", \"fixed_val\": np.pi / 5, \"var_dim\": \"ky\", \"n_points\": 37},\n            ],\n            \"noise_sigma\": 0.003,\n            \"seed\": 1,\n        },\n        # Case B: Isotropic nearest-neighbor only, noiseless\n        {\n            \"truth_params\": [0.0, 0.15, 0.0, 0.0],\n            \"cuts\": [\n                {\"fixed_dim\": \"ky\", \"fixed_val\": np.pi / 4, \"var_dim\": \"kx\", \"n_points\": 25},\n                {\"fixed_dim\": \"kx\", \"fixed_val\": np.pi / 2, \"var_dim\": \"ky\", \"n_points\": 25},\n            ],\n            \"noise_sigma\": 0.0,\n            \"seed\": 2,\n        },\n        # Case C: Near-degenerate anisotropy, mildly noisy\n        {\n            \"truth_params\": [0.0, 0.08, 0.06, 0.0],\n            \"cuts\": [\n                {\"fixed_dim\": \"ky\", \"fixed_val\": np.pi / 6, \"var_dim\": \"kx\", \"n_points\": 41},\n                {\"fixed_dim\": \"kx\", \"fixed_val\": np.pi / 3, \"var_dim\": \"ky\", \"n_points\": 41},\n            ],\n            \"noise_sigma\": 0.002,\n            \"seed\": 3,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n    \n    # Format the final output string exactly as required.\n    # Python's str(True) - \"True\", which matches the example.\n    output_parts = [f\"[{res[0]:.6f},{res[1]}]\" for res in results]\n    print(f\"[{','.join(output_parts)}]\")\n\n\ndef energy_model(k_vectors, params):\n    \"\"\"\n    Calculates energy E(k) based on the TB model.\n    k_vectors is an (N, 2) array of (kx, ky) pairs.\n    params is a list or array of [eps0, t1, t2, t3].\n    \"\"\"\n    kx, ky = k_vectors[:, 0], k_vectors[:, 1]\n    eps0, t1, t2, t3 = params\n    \n    E = (eps0\n         - 2 * t1 * (np.cos(kx) + np.cos(ky))\n         - 4 * t2 * np.cos(kx) * np.cos(ky)\n         - 2 * t3 * (np.cos(2 * kx) + np.cos(2 * ky)))\n    return E\n\n\ndef process_case(case_data):\n    \"\"\"\n    Processes a single test case: generates data, fits model, and evaluates.\n    \"\"\"\n    # 1. Generate k-points\n    all_k_vectors = []\n    for cut in case_data[\"cuts\"]:\n        var_coords = np.linspace(0, np.pi, cut[\"n_points\"])\n        if cut[\"var_dim\"] == \"kx\":\n            kx_coords = var_coords\n            ky_coords = np.full_like(kx_coords, cut[\"fixed_val\"])\n        else: # var_dim == \"ky\"\n            ky_coords = var_coords\n            kx_coords = np.full_like(ky_coords, cut[\"fixed_val\"])\n        all_k_vectors.append(np.stack((kx_coords, ky_coords), axis=1))\n    \n    k_vectors = np.concatenate(all_k_vectors, axis=0)\n    \n    # 2. Generate \"ab initio\" energy data with noise\n    E_true = energy_model(k_vectors, case_data[\"truth_params\"])\n    rng = np.random.default_rng(case_data[\"seed\"])\n    noise = rng.normal(loc=0.0, scale=case_data[\"noise_sigma\"], size=E_true.shape[0])\n    E_observed = E_true + noise\n    \n    # 3. Construct the design matrix\n    kx, ky = k_vectors[:, 0], k_vectors[:, 1]\n    N = k_vectors.shape[0]\n    \n    X0 = np.ones(N)  # Intercept for eps0\n    X1 = -2 * (np.cos(kx) + np.cos(ky))\n    X2 = -4 * np.cos(kx) * np.cos(ky)\n    X3 = -2 * (np.cos(2 * kx) + np.cos(2 * ky))\n    \n    A = np.stack([X0, X1, X2, X3], axis=1)\n\n    # 4. Perform linear least-squares fit\n    fitted_params, _, _, _ = np.linalg.lstsq(A, E_observed, rcond=None)\n    \n    # 5. Calculate RMSE\n    E_predicted = A @ fitted_params\n    rmse = np.sqrt(np.mean((E_observed - E_predicted)**2))\n    \n    # 6. Check physical plausibility\n    eps0_fit, t1_fit, t2_fit, t3_fit = fitted_params\n    \n    # Condition 1: Dominant nearest-neighbor hopping\n    if t1_fit == 0: # Avoid division by zero\n        plaus1 = max(abs(t2_fit), abs(t3_fit)) == 0\n    else:\n        plaus1 = max(abs(t2_fit), abs(t3_fit)) = 0.6 * abs(t1_fit)\n    \n    # Condition 2: Small onsite offset\n    plaus2 = abs(eps0_fit) = 0.1\n    \n    # Condition 3: Reasonable bandwidth\n    W_est = 8 * abs(t1_fit) + 16 * abs(t2_fit) + 8 * abs(t3_fit)\n    plaus3 = W_est = 3.0\n    \n    is_plausible = bool(plaus1 and plaus2 and plaus3)\n    \n    return [round(rmse, 6), is_plausible]\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "Accurate predictions of electronic properties, such as the density of states at the Fermi level $N(E_F)$, depend critically on the numerical convergence of Brillouin zone integrals. This challenge is especially pronounced for metals with complex, high-curvature Fermi surfaces, which require a sufficiently dense mesh of $k$-points to be sampled correctly. This computational exercise  tasks you with implementing a systematic convergence study to determine the minimal $k$-point density needed to obtain reliable results, a skill that is essential for any serious computational materials study.",
            "id": "3451530",
            "problem": "You are given a parametric single-band model for a metal with high-curvature Fermi sheets in reduced lattice units. The Brillouin zone (BZ) is the cube with corners at $(-\\pi,-\\pi,-\\pi)$ and $(\\pi,\\pi,\\pi)$ in reciprocal space. The electronic dispersion is defined by the tight-binding function\n$$\nE(\\mathbf{k}) = -2t\\left(\\cos k_x + \\cos k_y + \\alpha \\cos k_z\\right) - 4t_2\\left(\\cos k_x \\cos k_y + \\cos k_y \\cos k_z + \\cos k_z \\cos k_x\\right),\n$$\nwith parameters $t = 1$, $t_2 = 0.3$, and $\\alpha = 0.5$. All quantities are in reduced lattice units with lattice constant set to $a=1$ and the reduced Planck constant set to $\\hbar = 1$. Angles are in radians.\n\nYour task is to design and implement a program that, given a target absolute tolerance for the density of states at the Fermi energy $N(E_F)$ and an absolute tolerance for the change in the average Fermi velocity magnitude, estimates the minimal uniform $k$-point mesh density $n$ (points per axis) required to satisfy both convergence criteria for the specified metal. The program must be general and proceed from first principles and well-tested definitions, and must not assume precomputed constants.\n\nFundamental base and definitions:\n- The density of states (DOS) is defined as\n$$\nN(E) = \\frac{1}{(2\\pi)^3} \\int_{\\mathrm{BZ}} \\delta\\!\\left(E - E(\\mathbf{k})\\right)\\, d^3k,\n$$\nwhere $\\delta(\\cdot)$ is the Dirac delta distribution. Equivalently, by co-area transformation,\n$$\nN(E) = \\frac{1}{(2\\pi)^3} \\oint_{E(\\mathbf{k})=E} \\frac{dS}{\\left\\lvert \\nabla_{\\mathbf{k}} E(\\mathbf{k}) \\right\\rvert}.\n$$\n- The Fermi velocity is defined by\n$$\n\\mathbf{v}_F(\\mathbf{k}) = \\nabla_{\\mathbf{k}} E(\\mathbf{k}),\n$$\nin the stated reduced units.\n\nNumerical formulation constraints:\n- Use a uniform Monkhorst-Pack style mesh with $n$ points along each axis in the BZ, placed at midpoints of equal subdivisions. That is, for each axis use points $k_i = -\\pi + \\left(i + \\frac{1}{2}\\right)\\Delta$ with $\\Delta = \\frac{2\\pi}{n}$ and $i \\in \\{0,1,\\dots,n-1\\}$.\n- Approximate the Dirac delta by a normalized Gaussian with width $\\sigma$:\n$$\ng_{\\sigma}(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right).\n$$\n- Because the BZ volume equals $(2\\pi)^3$ in these units, the Riemann-sum approximation simplifies to the arithmetic mean over the mesh for the DOS estimator,\n$$\n\\widehat{N}_{n,\\sigma}(E_F) = \\frac{1}{n^3} \\sum_{\\mathbf{k}} g_{\\sigma}\\!\\left(E(\\mathbf{k}) - E_F\\right).\n$$\n- To quantify changes in Fermi velocities in a manner consistent with the DOS sampling, define a Gaussian-weighted mean Fermi velocity magnitude at the Fermi energy as\n$$\n\\widehat{V}_{n,\\sigma}(E_F) = \\frac{\\sum_{\\mathbf{k}} \\left\\lvert \\nabla_{\\mathbf{k}} E(\\mathbf{k}) \\right\\rvert g_{\\sigma}\\!\\left(E(\\mathbf{k}) - E_F\\right)}{\\sum_{\\mathbf{k}} g_{\\sigma}\\!\\left(E(\\mathbf{k}) - E_F\\right)}.\n$$\n\nConvergence protocol and goal:\n- Starting from an initial mesh $n_0$ and increasing by a fixed step $\\Delta n$, determine the smallest $n$ such that both\n$$\n\\left\\lvert \\widehat{N}_{n,\\sigma}(E_F) - \\widehat{N}_{n-\\Delta n,\\sigma}(E_F) \\right\\rvert \\le \\varepsilon_N\n\\quad \\text{and} \\quad\n\\left\\lvert \\widehat{V}_{n,\\sigma}(E_F) - \\widehat{V}_{n-\\Delta n,\\sigma}(E_F) \\right\\rvert \\le \\varepsilon_V\n$$\nhold simultaneously, where $\\varepsilon_N$ is the absolute tolerance target for $N(E_F)$ and $\\varepsilon_V$ is the absolute tolerance for the change in the average Fermi velocity magnitude. If no $n$ up to a specified maximum $n_{\\max}$ satisfies both, return $n_{\\max}$ for that test case.\n- The justification for the velocity-based criterion must be grounded in how the Fermi-surface integral weights contributions by $\\left\\lvert \\nabla_{\\mathbf{k}} E(\\mathbf{k}) \\right\\rvert^{-1}$, making accurate sampling of regions with large curvature and small $\\left\\lvert \\nabla_{\\mathbf{k}} E(\\mathbf{k}) \\right\\rvert$ critical to the stability of $N(E_F)$ estimates. High-curvature Fermi sheets exacerbate this sensitivity, thus the change in the Gaussian-weighted mean $\\left\\lvert \\mathbf{v}_F \\right\\rvert$ serves as a proxy for stabilized Fermi-surface geometry sampling.\n\nTest suite:\nFor each of the following parameter sets, compute and report the minimal $n$ that satisfies both criteria. All energies are in the same reduced units as the dispersion, $\\sigma$ is the Gaussian width in the same energy units, and tolerances are absolute.\n- Case $1$: $E_F = 0.0$, $\\sigma = 0.05$, $\\varepsilon_N = 0.003$, $\\varepsilon_V = 0.002$, $n_0 = 8$, $\\Delta n = 4$, $n_{\\max} = 48$.\n- Case $2$: $E_F = 0.5$, $\\sigma = 0.05$, $\\varepsilon_N = 0.001$, $\\varepsilon_V = 0.0015$, $n_0 = 8$, $\\Delta n = 4$, $n_{\\max} = 48$.\n- Case $3$: $E_F = -2.5$, $\\sigma = 0.05$, $\\varepsilon_N = 0.005$, $\\varepsilon_V = 0.003$, $n_0 = 8$, $\\Delta n = 4$, $n_{\\max} = 48$.\n- Case $4$: $E_F = 1.5$, $\\sigma = 0.03$, $\\varepsilon_N = 0.002$, $\\varepsilon_V = 0.002$, $n_0 = 8$, $\\Delta n = 4$, $n_{\\max} = 48$.\n\nRequired final output format:\nYour program should produce a single line of output containing the minimal mesh sizes for the four cases as a comma-separated list enclosed in square brackets, for example $[n_1,n_2,n_3,n_4]$. The entries $n_1$, $n_2$, $n_3$, and $n_4$ must be integers. No other text should be printed.",
            "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically sound, well-posed, and based on established principles of computational condensed matter physics. It presents a clear, formalizable task with all necessary parameters and definitions provided. We may therefore proceed with a solution.\n\nThe objective is to determine the minimum uniform $k$-point mesh density, represented by the number of points $n$ per reciprocal lattice vector axis, required to achieve convergence for both the density of states at the Fermi energy, $N(E_F)$, and the average Fermi velocity magnitude, $\\widehat{V}(E_F)$. The convergence is defined by specific absolute tolerances.\n\nThe solution is constructed based on the following first principles and numerical methods.\n\n**1. Electronic Structure Model**\n\nThe electronic band structure is described by the single-band tight-binding dispersion relation $E(\\mathbf{k})$ within the first Brillouin zone (BZ), which is a cube defined by $k_x, k_y, k_z \\in [-\\pi, \\pi]$. The energy is given by:\n$$\nE(\\mathbf{k}) = -2t\\left(\\cos k_x + \\cos k_y + \\alpha \\cos k_z\\right) - 4t_2\\left(\\cos k_x \\cos k_y + \\cos k_y \\cos k_z + \\cos k_z \\cos k_x\\right)\n$$\nThe parameters are specified as $t = 1$, $t_2 = 0.3$, and $\\alpha = 0.5$. All quantities are in reduced lattice units where the lattice constant $a=1$ and the reduced Planck constant $\\hbar=1$.\n\nThe Fermi velocity, $\\mathbf{v}_F(\\mathbf{k})$, is the gradient of the dispersion relation with respect to the wavevector $\\mathbf{k}$:\n$$\n\\mathbf{v}_F(\\mathbf{k}) = \\nabla_{\\mathbf{k}} E(\\mathbf{k}) = \\left(\\frac{\\partial E}{\\partial k_x}, \\frac{\\partial E}{\\partial k_y}, \\frac{\\partial E}{\\partial k_z}\\right)\n$$\nThe partial derivatives are calculated analytically:\n$$\n\\frac{\\partial E}{\\partial k_x} = 2t \\sin k_x + 4t_2 \\sin k_x \\left(\\cos k_y + \\cos k_z\\right)\n$$\n$$\n\\frac{\\partial E}{\\partial k_y} = 2t \\sin k_y + 4t_2 \\sin k_y \\left(\\cos k_x + \\cos k_z\\right)\n$$\n$$\n\\frac{\\partial E}{\\partial k_z} = 2t\\alpha \\sin k_z + 4t_2 \\sin k_z \\left(\\cos k_x + \\cos k_y\\right)\n$$\nWe are interested in the magnitude of this vector, $\\left\\lvert \\mathbf{v}_F(\\mathbf{k}) \\right\\rvert = \\sqrt{(\\frac{\\partial E}{\\partial k_x})^2 + (\\frac{\\partial E}{\\partial k_y})^2 + (\\frac{\\partial E}{\\partial k_z})^2}$.\n\n**2. Numerical Estimation of Physical Quantities**\n\nThe continuous integrals over the BZ are approximated by discrete sums over a uniform $k$-point mesh. The problem specifies a Monkhorst-Pack-style grid with points located at midpoints of subdivisions. For a mesh of density $n$, the coordinates along each axis $j \\in \\{x,y,z\\}$ are:\n$$\nk_{j,i} = -\\pi + \\left(i + \\frac{1}{2}\\right)\\frac{2\\pi}{n}, \\quad \\text{for } i \\in \\{0, 1, \\dots, n-1\\}\n$$\nThis generates a total of $n^3$ points $\\mathbf{k}$ in the BZ.\n\nThe density of states (DOS) at an energy $E$, $N(E)$, is defined by an integral involving the Dirac delta distribution, $\\delta(x)$. For numerical evaluation, $\\delta(x)$ is approximated by a narrow normalized Gaussian function $g_{\\sigma}(x)$:\n$$\n\\delta(x) \\approx g_{\\sigma}(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right)\n$$\nwhere $\\sigma$ is the broadening parameter. The BZ integral for the DOS is then approximated by a Riemann sum over the $n^3$ discrete $k$-points. Since the volume of the BZ is $(2\\pi)^3$ and the volume element for each $k$-point is $(2\\pi/n)^3$, the estimator for the DOS at the Fermi energy $E_F$ becomes a simple arithmetic mean:\n$$\n\\widehat{N}_{n,\\sigma}(E_F) = \\frac{1}{(2\\pi)^3} \\sum_{\\mathbf{k}} g_{\\sigma}\\!\\left(E(\\mathbf{k}) - E_F\\right) \\left(\\frac{2\\pi}{n}\\right)^3 = \\frac{1}{n^3} \\sum_{\\mathbf{k}} g_{\\sigma}\\!\\left(E(\\mathbf{k}) - E_F\\right)\n$$\nThis formula matches the one provided in the problem statement.\n\nThe average Fermi velocity magnitude at $E_F$ is calculated as a weighted average. Each $k$-point's contribution is weighted by its proximity to the Fermi surface, as captured by the same Gaussian function $g_{\\sigma}(E(\\mathbf{k}) - E_F)$. The estimator is:\n$$\n\\widehat{V}_{n,\\sigma}(E_F) = \\frac{\\sum_{\\mathbf{k}} \\left\\lvert \\nabla_{\\mathbf{k}} E(\\mathbf{k}) \\right\\rvert g_{\\sigma}\\!\\left(E(\\mathbf{k}) - E_F\\right)}{\\sum_{\\mathbf{k}} g_{\\sigma}\\!\\left(E(\\mathbf{k}) - E_F\\right)}\n$$\nThe denominator is proportional to the DOS estimator, ensuring a properly normalized weighted average.\n\n**3. Convergence Algorithm**\n\nThe core of the task is to find the smallest mesh density $n$ for which the calculated properties are converged. The algorithm proceeds as follows for each test case:\n1.  Initialize the mesh density scan, starting from $n=n_0$ and increasing in steps of $\\Delta n$ up to a maximum of $n_{\\max}$. The sequence of densities is $n_0, n_0+\\Delta n, n_0+2\\Delta n, \\dots$.\n2.  For the initial density $n_0$, compute the baseline values $\\widehat{N}_{n_0,\\sigma}(E_F)$ and $\\widehat{V}_{n_0,\\sigma}(E_F)$. These serve as the reference for the first convergence check.\n3.  Iterate through the subsequent mesh densities $n  n_0$ in the sequence. In each step, corresponding to density $n$, compute the current values $\\widehat{N}_{n,\\sigma}(E_F)$ and $\\widehat{V}_{n,\\sigma}(E_F)$.\n4.  Compare the current values with those from the previous mesh density, $n-\\Delta n$. The convergence is achieved if both of the following conditions are met simultaneously:\n    $$\n    \\left\\lvert \\widehat{N}_{n,\\sigma}(E_F) - \\widehat{N}_{n-\\Delta n,\\sigma}(E_F) \\right\\rvert \\le \\varepsilon_N\n    $$\n    $$\n    \\left\\lvert \\widehat{V}_{n,\\sigma}(E_F) - \\widehat{V}_{n-\\Delta n,\\sigma}(E_F) \\right\\rvert \\le \\varepsilon_V\n    $$\n    where $\\varepsilon_N$ and $\\varepsilon_V$ are the specified absolute tolerances.\n5.  The first value of $n$ that satisfies both conditions is the minimal required density. The search is then terminated for that test case, and this value of $n$ is reported.\n6.  If the loop completes and no $n \\le n_{\\max}$ satisfies the convergence criteria, the result for that test case is $n_{\\max}$.\n\nThis iterative procedure will be implemented for each of the four test cases defined in the problem, yielding the four integer results to be reported. The implementation will utilize vectorized numerical computations for efficiency.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the Fermi surface analysis problem for all test cases.\n    \"\"\"\n\n    # Model parameters from the problem statement\n    t = 1.0\n    t2 = 0.3\n    alpha = 0.5\n\n    def energy(kx, ky, kz):\n        \"\"\"\n        Calculates the electronic dispersion E(k).\n        Args:\n            kx, ky, kz: NumPy arrays of k-vector components.\n        Returns:\n            NumPy array of energy values.\n        \"\"\"\n        cos_kx = np.cos(kx)\n        cos_ky = np.cos(ky)\n        cos_kz = np.cos(kz)\n        \n        term1 = -2.0 * t * (cos_kx + cos_ky + alpha * cos_kz)\n        term2 = -4.0 * t2 * (cos_kx * cos_ky + cos_ky * cos_kz + cos_kz * cos_kx)\n        \n        return term1 + term2\n\n    def grad_energy_mag(kx, ky, kz):\n        \"\"\"\n        Calculates the magnitude of the Fermi velocity |nabla_k E(k)|.\n        Args:\n            kx, ky, kz: NumPy arrays of k-vector components.\n        Returns:\n            NumPy array of Fermi velocity magnitudes.\n        \"\"\"\n        sin_kx = np.sin(kx)\n        sin_ky = np.sin(ky)\n        sin_kz = np.sin(kz)\n        cos_kx = np.cos(kx)\n        cos_ky = np.cos(ky)\n        cos_kz = np.cos(kz)\n\n        grad_x = 2.0 * t * sin_kx + 4.0 * t2 * sin_kx * (cos_ky + cos_kz)\n        grad_y = 2.0 * t * sin_ky + 4.0 * t2 * sin_ky * (cos_kx + cos_kz)\n        grad_z = 2.0 * t * alpha * sin_kz + 4.0 * t2 * sin_kz * (cos_kx + cos_ky)\n        \n        return np.sqrt(grad_x**2 + grad_y**2 + grad_z**2)\n\n    def calculate_properties(n, E_F, sigma):\n        \"\"\"\n        Calculates the DOS and mean Fermi velocity magnitude for a given mesh density.\n        Args:\n            n: Integer, number of k-points per axis.\n            E_F: Float, Fermi energy.\n            sigma: Float, Gaussian broadening width.\n        Returns:\n            A tuple (dos, avg_v_f) containing the calculated properties.\n        \"\"\"\n        # Generate the k-point mesh\n        delta_k = 2.0 * np.pi / n\n        k_1d = -np.pi + (np.arange(n) + 0.5) * delta_k\n        kx, ky, kz = np.meshgrid(k_1d, k_1d, k_1d, indexing='ij')\n\n        # Calculate energies and velocity magnitudes on the mesh\n        E_k = energy(kx, ky, kz)\n        v_f_mag_k = grad_energy_mag(kx, ky, kz)\n        \n        # Calculate Gaussian weights\n        x = E_k - E_F\n        gaussian_weights = (1.0 / (sigma * np.sqrt(2.0 * np.pi))) * np.exp(-x**2 / (2.0 * sigma**2))\n        \n        # Calculate DOS estimator\n        dos_estimator = np.mean(gaussian_weights)\n        \n        # Calculate average Fermi velocity magnitude\n        numerator = np.sum(v_f_mag_k * gaussian_weights)\n        denominator = np.sum(gaussian_weights)\n        \n        # Handle case where denominator is zero to avoid division by zero error\n        if denominator == 0:\n            avg_v_f_estimator = 0.0\n        else:\n            avg_v_f_estimator = numerator / denominator\n            \n        return dos_estimator, avg_v_f_estimator\n\n    def find_converged_n(case_params):\n        \"\"\"\n        Finds the minimal mesh density n that satisfies the convergence criteria.\n        Args:\n            case_params: A tuple containing (E_F, sigma, eps_N, eps_V, n0, dn, n_max).\n        Returns:\n            Integer, the minimal converged n.\n        \"\"\"\n        E_F, sigma, eps_N, eps_V, n0, dn, n_max = case_params\n        \n        n_values = range(n0, n_max + 1, dn)\n        \n        # Calculate for the initial mesh n0\n        N_prev, V_prev = calculate_properties(n0, E_F, sigma)\n        \n        if len(n_values) == 1:\n            return n0\n\n        # Iterate from the second mesh size\n        for n in n_values[1:]:\n            N_curr, V_curr = calculate_properties(n, E_F, sigma)\n            \n            # Check for convergence\n            delta_N = abs(N_curr - N_prev)\n            delta_V = abs(V_curr - V_prev)\n            \n            if delta_N = eps_N and delta_V = eps_V:\n                return n\n            \n            # Update previous values for the next iteration\n            N_prev = N_curr\n            V_prev = V_curr\n            \n        # If loop finishes without convergence, return n_max\n        return n_max\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (E_F, sigma, eps_N, eps_V, n0, dn, n_max)\n        (0.0, 0.05, 0.003, 0.002, 8, 4, 48),    # Case 1\n        (0.5, 0.05, 0.001, 0.0015, 8, 4, 48),  # Case 2\n        (-2.5, 0.05, 0.005, 0.003, 8, 4, 48),  # Case 3\n        (1.5, 0.03, 0.002, 0.002, 8, 4, 48),    # Case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        result = find_converged_n(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}