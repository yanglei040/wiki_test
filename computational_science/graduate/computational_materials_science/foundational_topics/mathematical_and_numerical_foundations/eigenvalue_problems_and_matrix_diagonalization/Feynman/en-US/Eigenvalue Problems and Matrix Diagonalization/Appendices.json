{
    "hands_on_practices": [
        {
            "introduction": "This practice delves into the vibrational analysis of atomic clusters, a cornerstone of computational materials science used to understand thermal properties and spectroscopic signatures. You will construct the stiffness ($K$) and mass ($M$) matrices from first principles and solve the generalized eigenvalue problem $K u = \\lambda M u$. The exercise provides critical hands-on experience in handling zero-frequency rigid-body modes by projecting them out, a necessary step to isolate the true internal vibrational frequencies of the system .",
            "id": "3446833",
            "problem": "Consider a finite cluster of $N$ atoms in three-dimensional space ($\\mathrm{3D}$) with $3N$ displacement Degrees of Freedom (DOF). Let $M \\in \\mathbb{R}^{3N \\times 3N}$ be the diagonal mass matrix with $3 \\times 3$ blocks $m_i I_3$ for atom index $i \\in \\{1,\\dots,N\\}$ and mass $m_i$, and let $K \\in \\mathbb{R}^{3N \\times 3N}$ be the symmetric stiffness (Hessian) matrix arising from linearization of pairwise central spring interactions at mechanical equilibrium. The total potential energy in the small-displacement regime is given by the quadratic form\n$$\n\\Pi(u) = \\frac{1}{2} u^\\top K u,\n$$\nwhere $u \\in \\mathbb{R}^{3N}$ collects Cartesian displacements of all atoms. The generalized eigenvalue problem for undamped free vibrations is\n$$\nK u = \\lambda M u,\n$$\nwhere $\\lambda = \\omega^2$ with $\\omega$ the angular frequency. In the absence of external constraints, the rigid-body subspace is spanned by three translations and three rotations about the center of mass, and $K$ is positive semidefinite with nullspace containing those rigid-body modes.\n\nYour task is to implement, in a self-contained program, a mass-weighted projection that removes rigid-body modes and to compute the generalized spectrum of the projected operator on the non-rigid subspace. From first principles and well-tested facts in linear elasticity and classical mechanics, the rigid-body translation modes are displacements $u_i = t$ at each atom $i$, for $t \\in \\mathbb{R}^3$, and the rigid-body rotation modes about the center of mass position $r_{\\mathrm{cm}}$ are displacements $u_i = \\omega \\times (r_i - r_{\\mathrm{cm}})$ at atom $i$, for angular velocity vector $\\omega \\in \\mathbb{R}^3$. The mass-weighted inner product is defined as\n$$\n\\langle x, y \\rangle_M = x^\\top M y,\n$$\nand the orthogonal projection onto the $M$-orthogonal complement of the rigid-body subspace should be constructed and used to restrict the generalized eigenvalue problem.\n\nImplement the stiffness matrix $K$ for central springs that only resist extension along the interatomic line, using the well-tested per-spring contribution for a spring between atoms $i$ and $j$ with spring constant $k_{ij}$ and unit direction $n_{ij} = \\frac{r_j - r_i}{\\|r_j - r_i\\|}$:\n- The $3 \\times 3$ block contribution is $B_{ij} = k_{ij} \\, n_{ij} n_{ij}^\\top$.\n- Assemble $K$ by adding $B_{ij}$ to diagonal blocks $(i,i)$ and $(j,j)$, and subtracting $B_{ij}$ from off-diagonal blocks $(i,j)$ and $(j,i)$.\n\nUse the following test suite. In all cases, the edges are the complete graph on the atom indices (all pairs $i < j$), the center of mass is computed with the given $m_i$, and rotations are about $r_{\\mathrm{cm}}$. All quantities are dimensionless and should be treated in consistent arbitrary units.\n\n- Test case $1$ (happy path): $N = 4$ atoms at positions\n$$\nr_1 = (1,1,1), \\quad r_2 = (-1,-1,1), \\quad r_3 = (-1,1,-1), \\quad r_4 = (1,-1,-1),\n$$\nwith masses $m = [1,1,1,1]$ and uniform spring constants $k_{ij} = k_0$ with $k_0 = 50$.\n\n- Test case $2$ (heterogeneous masses): same positions as test case $1$, masses $m = [1.0,\\,2.0,\\,3.5,\\,0.8]$ and uniform spring constants $k_{ij} = k_0$ with $k_0 = 10$.\n\n- Test case $3$ (general geometry, heterogeneous parameters): $N = 5$ atoms at positions\n$$\nr_1 = (0.0,\\,0.0,\\,0.0), \\quad r_2 = (1.2,\\,-0.7,\\,0.3), \\quad r_3 = (-0.9,\\,1.1,\\,0.8), \\quad r_4 = (0.5,\\,0.4,\\,-1.5), \\quad r_5 = (-1.3,\\,-0.2,\\,0.9),\n$$\nwith masses $m = [1.0,\\,0.8,\\,1.5,\\,1.2,\\,0.9]$ and spring constants defined by\n$$\nk_{ij} = k_0 \\left(1 + 0.1 (i + j)\\right), \\quad \\text{with } k_0 = 5.0,\n$$\nfor each pair $(i,j)$ with $i < j$.\n\n- Test case $4$ (boundary case with near-singular stiffness): same positions and masses as test case $1$, and uniform spring constants $k_{ij} = k_0$ with $k_0 = 10^{-6}$.\n\nFor each test case, perform the following computational steps:\n1. Assemble $K$ and $M$.\n2. Construct a basis for the rigid-body subspace using three linearly independent translations and three linearly independent rotations about $r_{\\mathrm{cm}}$.\n3. Build the $M$-orthogonal projection onto the complement of the rigid-body subspace and extract an $M$-orthonormal basis for this complement.\n4. Restrict the generalized eigenvalue problem to this complement and compute all eigenvalues $\\lambda$.\n5. Report, for each test case, the smallest eigenvalue and a boolean indicating whether all eigenvalues are strictly positive within a numerical tolerance $\\epsilon = 10^{-10}$; that is, whether $\\lambda > \\epsilon$ for all eigenvalues in the complement.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry corresponds to a test case and is itself a two-element list of the form $[\\text{min\\_eigenvalue}, \\text{all\\_positive}]$. For example, the output format should be\n$$\n[[\\lambda_{\\min}^{(1)}, \\text{True}],[\\lambda_{\\min}^{(2)}, \\text{True}],[\\lambda_{\\min}^{(3)}, \\text{True}],[\\lambda_{\\min}^{(4)}, \\text{True}]]\n$$\nwith the actual numerical values replacing the placeholders.",
            "solution": "The provided problem is a well-posed and scientifically sound exercise in computational materials science, specifically in the area of lattice dynamics for a finite atomic cluster. It is grounded in the principles of classical mechanics and linear algebra. The task is to compute the vibrational spectrum of an atomic cluster after removing the non-vibrational, zero-frequency rigid-body modes. All provided data and definitions are standard, consistent, and sufficient to obtain a unique, meaningful solution. Therefore, the problem is valid, and we proceed with a detailed solution.\n\nThe fundamental physical model is the harmonic approximation of the interatomic potential energy, which is valid for small displacements $u \\in \\mathbb{R}^{3N}$ from a mechanical equilibrium configuration. The potential energy is given by the quadratic form $\\Pi(u) = \\frac{1}{2} u^\\top K u$, where $K \\in \\mathbb{R}^{3N \\times 3N}$ is the symmetric, positive semidefinite stiffness matrix (or Hessian). The kinetic energy is $T(\\dot{u}) = \\frac{1}{2} \\dot{u}^\\top M \\dot{u}$, where $M \\in \\mathbb{R}^{3N \\times 3N}$ is the diagonal, positive definite mass matrix. Applying Lagrange's equations of motion leads to the system of second-order ordinary differential equations $M \\ddot{u} + K u = 0$. Assuming harmonic solutions of the form $u(t) = u_0 e^{i\\omega t}$, we arrive at the generalized eigenvalue problem:\n$$\nK u = \\omega^2 M u\n$$\nLetting $\\lambda = \\omega^2$, we have the standard form $K u = \\lambda M u$. The eigenvalues $\\lambda$ are the squared angular frequencies of the normal modes of vibration, and the eigenvectors $u$ are the corresponding displacement patterns.\n\nThe mass matrix $M$ is a diagonal matrix comprising $N$ blocks of the form $m_i I_3$, where $m_i$ is the mass of the $i$-th atom and $I_3$ is the $3 \\times 3$ identity matrix.\n$$\nM = \\begin{pmatrix} m_1 I_3 & & \\\\ & m_2 I_3 & & \\\\ & & \\ddots & \\\\ & & & m_N I_3 \\end{pmatrix}\n$$\nThe stiffness matrix $K$ is assembled from contributions of pairwise central spring interactions. For a spring with constant $k_{ij}$ connecting atoms $i$ and $j$ at positions $r_i$ and $r_j$, the energy stored is proportional to the square of the change in length. This leads to a $3 \\times 3$ block contribution $B_{ij} = k_{ij} n_{ij} n_{ij}^\\top$, where $n_{ij} = \\frac{r_j - r_i}{\\|r_j - r_i\\|}$ is the unit vector along the line connecting the atoms. The full stiffness matrix $K$ is assembled by adding these blocks to the diagonal submatrices and subtracting them from the off-diagonal submatrices, reflecting the forces on the atoms:\n$$\nK_{ii} = \\sum_{j \\neq i} B_{ij}, \\quad K_{ij} = -B_{ij} \\text{ for } i \\neq j\n$$\n\nFor a finite, unconstrained cluster, there exist modes of motion that do not distort interatomic distances and thus do not store potential energy. These are the rigid-body modes: three translations and three rotations. These modes span the nullspace of the stiffness matrix $K$, meaning $Ku=0$ for any rigid-body mode $u$. Consequently, the generalized eigenvalue problem yields six zero eigenvalues ($\\lambda=0$). To study the internal vibrations of the cluster, these non-vibrational modes must be projected out.\n\nThis projection is performed in the space endowed with the mass-weighted inner product, $\\langle x, y \\rangle_M = x^\\top M y$. This inner product is physically motivated, as the kinetic energy is $\\frac{1}{2} \\langle \\dot{u}, \\dot{u} \\rangle_M$. The procedure to solve the eigenvalue problem on the subspace $M$-orthogonal to the rigid-body modes is as follows:\n\n1.  **Transformation to a Standard Eigenvalue Problem**: The generalized eigenvalue problem $K u = \\lambda M u$ can be converted to a standard eigenvalue problem. Since $M$ is positive definite, its Cholesky decomposition exists. For a diagonal $M$, we can simply define a diagonal matrix $L = M^{1/2}$ such that $M = LL^\\top = L^2$. Substituting $u = L^{-1} \\tilde{u}$ into the equation gives:\n    $$\n    K L^{-1} \\tilde{u} = \\lambda L L^{-1} \\tilde{u}\n    $$\n    Multiplying from the left by $L^{-1}$ (which is $(L^{-1})^\\top$ as $L$ is diagonal) yields:\n    $$\n    (L^{-1} K L^{-1}) \\tilde{u} = \\lambda \\tilde{u}\n    $$\n    This is a standard eigenvalue problem $\\tilde{K} \\tilde{u} = \\lambda \\tilde{u}$ for the transformed stiffness matrix $\\tilde{K} = L^{-1} K L^{-1}$.\n\n2.  **Identification of the Rigid-Body Subspace**: The six rigid-body modes must be constructed.\n    -   **Translations**: Three basis vectors are formed by setting the displacement of every atom to $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$, respectively.\n    -   **Rotations**: First, the center of mass is computed: $r_{\\mathrm{cm}} = \\frac{\\sum_{i=1}^N m_i r_i}{\\sum_{i=1}^N m_i}$. The rotational modes correspond to infinitesimal rotations about $r_{\\mathrm{cm}}$. The displacement of atom $i$ for a rotation by an angular velocity vector $\\omega$ is $u_i = \\omega \\times (r_i - r_{\\mathrm{cm}})$. Three basis vectors are formed by choosing $\\omega$ to be $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$.\n    These six vectors, each of size $3N$, form a basis for the rigid-body subspace. Let's collect them as columns of a matrix $V_{\\mathrm{rigid}} \\in \\mathbb{R}^{3N \\times 6}$.\n\n3.  **Construction of the Projection**: In the transformed coordinates, the rigid-body modes are given by the columns of $\\tilde{V}_{\\mathrm{rigid}} = L V_{\\mathrm{rigid}}$. We need to find the eigenvalues of $\\tilde{K}$ on the subspace orthogonal to the one spanned by the columns of $\\tilde{V}_{\\mathrm{rigid}}$.\n    A numerically robust way to find an orthonormal basis for this orthogonal complement is via Singular Value Decomposition (SVD). Let the SVD of $\\tilde{V}_{\\mathrm{rigid}}$ be $U \\Sigma W^\\top$. The matrix $U \\in \\mathbb{R}^{3N \\times 3N}$ is unitary, and its columns form a complete orthonormal basis for $\\mathbb{R}^{3N}$. If the rank of $\\tilde{V}_{\\mathrm{rigid}}$ is $d$ (which is $6$ for a non-collinear system), the first $d$ columns of $U$ span the same subspace as $\\tilde{V}_{\\mathrm{rigid}}$. The remaining $3N-d$ columns of $U$ form an orthonormal basis for its orthogonal complement. Let this basis be $\\tilde{Q}_{\\mathrm{comp}} = U[:, d:]$.\n\n4.  **Solving the Projected Problem**: Any vector $\\tilde{u}$ in the complement subspace can be written as a linear combination of the basis vectors: $\\tilde{u} = \\tilde{Q}_{\\mathrm{comp}} c$, where $c \\in \\mathbb{R}^{3N-d}$ is a vector of coefficients. Substituting this into the standard eigenvalue problem:\n    $$\n    \\tilde{K} (\\tilde{Q}_{\\mathrm{comp}} c) = \\lambda (\\tilde{Q}_{\\mathrm{comp}} c)\n    $$\n    Projecting onto the basis by multiplying from the left by $\\tilde{Q}_{\\mathrm{comp}}^\\top$:\n    $$\n    (\\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{K} \\tilde{Q}_{\\mathrm{comp}}) c = \\lambda (\\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{Q}_{\\mathrm{comp}}) c\n    $$\n    Since the columns of $\\tilde{Q}_{\\mathrm{comp}}$ are orthonormal, $\\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{Q}_{\\mathrm{comp}} = I_{3N-d}$. The problem reduces to a smaller, standard eigenvalue problem for a $(3N-d) \\times (3N-d)$ matrix $K_{\\mathrm{proj}} = \\tilde{Q}_{\\mathrm{comp}}^\\top \\tilde{K} \\tilde{Q}_{\\mathrm{comp}}$:\n    $$\n    K_{\\mathrm{proj}} c = \\lambda c\n    $$\n    The eigenvalues $\\lambda$ of $K_{\\mathrm{proj}}$ are the squared frequencies of the internal vibrational modes. For a stable cluster, all these eigenvalues must be strictly positive. The numerical implementation will compute these eigenvalues for each test case and report the minimum eigenvalue and whether all are positive within a given tolerance.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svd, eigh\n\ndef solve_vibrational_problem(positions, masses, k_func, N):\n    \"\"\"\n    Solves the vibrational problem for a cluster of N atoms.\n\n    Args:\n        positions (np.ndarray): (N, 3) array of atom positions.\n        masses (np.ndarray): (N,) array of atom masses.\n        k_func (callable): Function k_func(i, j) that returns the spring constant \n                           between atoms i and j (0-indexed).\n        N (int): Number of atoms.\n\n    Returns:\n        tuple: A tuple containing (min_eigenvalue, all_positive_flag).\n    \"\"\"\n    dim = 3\n    total_dof = dim * N\n    tol = 1e-10\n\n    # Step 1: Assemble Stiffness (K) and Mass (M) matrices\n    M_diag = np.repeat(masses, dim)\n    M = np.diag(M_diag)\n    L_inv = np.diag(1.0 / np.sqrt(M_diag))\n    L = np.diag(np.sqrt(M_diag))\n\n    K = np.zeros((total_dof, total_dof))\n    for i in range(N):\n        for j in range(i + 1, N):\n            r_i = positions[i]\n            r_j = positions[j]\n            d_ij = r_j - r_i\n            dist = np.linalg.norm(d_ij)\n            if dist < tol:\n                continue\n            n_ij = d_ij / dist\n            \n            k_ij = k_func(i, j)\n            B_ij = k_ij * np.outer(n_ij, n_ij)\n            \n            s_i, s_j = dim * i, dim * j\n            K[s_i:s_i+dim, s_i:s_i+dim] += B_ij\n            K[s_j:s_j+dim, s_j:s_j+dim] += B_ij\n            K[s_i:s_i+dim, s_j:s_j+dim] -= B_ij\n            K[s_j:s_j+dim, s_i:s_i+dim] -= B_ij\n\n    # Step 2: Construct a basis for the rigid-body subspace\n    # Center of mass calculation\n    total_mass = np.sum(masses)\n    r_cm = np.sum(masses[:, np.newaxis] * positions, axis=0) / total_mass\n    rel_pos = positions - r_cm\n\n    V_rigid = np.zeros((total_dof, dim * 2))\n\n    # 3 translation modes\n    for k in range(dim):\n        V_rigid[k::dim, k] = 1.0\n\n    # 3 rotation modes\n    for k in range(dim):\n        omega = np.zeros(dim)\n        omega[k] = 1.0\n        # rot_disp_k = cross(omega, rel_pos)\n        rot_disp_k = np.cross(omega, rel_pos, axisa=0, axisb=1)\n        V_rigid[:, dim + k] = rot_disp_k.flatten()\n\n    # Step 3: Build an M-orthonormal basis for the complement of the rigid-body subspace\n    # Transform rigid modes to the mass-weighted coordinate system\n    V_rigid_tilde = L @ V_rigid\n    \n    # Use SVD to find an orthonormal basis for the complement space\n    U, s, _ = svd(V_rigid_tilde, full_matrices=True)\n    \n    # The rank of V_rigid_tilde determines the dimension of the rigid subspace\n    rank = np.sum(s > tol)\n    \n    Q_comp_tilde = U[:, rank:]\n\n    # Step 4: Restrict the generalized eigenvalue problem and compute eigenvalues\n    # Transform K to the mass-weighted coordinate system\n    K_tilde = L_inv @ K @ L_inv\n\n    # Project K_tilde onto the complement subspace\n    K_proj = Q_comp_tilde.T @ K_tilde @ Q_comp_tilde\n    \n    # The projected matrix must be symmetric. Enforce it to handle small numerical errors.\n    K_proj = 0.5 * (K_proj + K_proj.T)\n\n    # Compute eigenvalues of the projected problem\n    eigenvalues = eigh(K_proj, eigvals_only=True)\n\n    # Step 5: Report results\n    if len(eigenvalues) == 0:\n        min_eigenvalue = 0.0\n        all_positive = True\n    else:\n        min_eigenvalue = np.min(eigenvalues)\n        all_positive = bool(np.all(eigenvalues > tol))\n\n    return [min_eigenvalue, all_positive]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the solver for each case.\n    \"\"\"\n    r_case1 = np.array([\n        [1.0, 1.0, 1.0],\n        [-1.0, -1.0, 1.0],\n        [-1.0, 1.0, -1.0],\n        [1.0, -1.0, -1.0]\n    ])\n    \n    r_case3 = np.array([\n        [0.0, 0.0, 0.0],\n        [1.2, -0.7, 0.3],\n        [-0.9, 1.1, 0.8],\n        [0.5, 0.4, -1.5],\n        [-1.3, -0.2, 0.9]\n    ])\n\n    test_cases = [\n        {\n            \"N\": 4,\n            \"positions\": r_case1,\n            \"masses\": np.array([1.0, 1.0, 1.0, 1.0]),\n            \"k_func\": lambda i, j: 50.0\n        },\n        {\n            \"N\": 4,\n            \"positions\": r_case1,\n            \"masses\": np.array([1.0, 2.0, 3.5, 0.8]),\n            \"k_func\": lambda i, j: 10.0\n        },\n        {\n            \"N\": 5,\n            \"positions\": r_case3,\n            \"masses\": np.array([1.0, 0.8, 1.5, 1.2, 0.9]),\n            \"k_func\": lambda i, j: 5.0 * (1.0 + 0.1 * ((i + 1) + (j + 1)))\n        },\n        {\n            \"N\": 4,\n            \"positions\": r_case1,\n            \"masses\": np.array([1.0, 1.0, 1.0, 1.0]),\n            \"k_func\": lambda i, j: 1e-6\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_vibrational_problem(case[\"positions\"], case[\"masses\"], case[\"k_func\"], case[\"N\"])\n        results.append(result)\n\n    # Format the results into the required string representation without extra spaces\n    result_strings = []\n    for res in results:\n        # Custom string formatting to match problem specification\n        min_eig_str = f\"{res[0]:.8e}\" if isinstance(res[0], float) else str(res[0])\n        bool_str = 'True' if res[1] else 'False'\n        result_strings.append(f\"[{min_eig_str},{bool_str}]\")\n\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond simply computing eigenvalues, a key skill is extracting physical meaning from them and their corresponding eigenvectors. This exercise explores the celebrated Aubry–André model, a canonical system for studying the localization transition in quasiperiodic structures . By calculating and analyzing the participation ratio of eigenvectors and the statistical properties of eigenvalue spacings, you will directly observe the signature of the transition from delocalized (metallic) to localized (insulating) states, a profound phenomenon in condensed matter physics.",
            "id": "3446844",
            "problem": "Consider the one-dimensional tight-binding Hamiltonian with a quasiperiodic on-site modulation known as the Aubry–André (also called the almost Mathieu) model. In computational materials science, this model is a standard setting to study localization transitions in quasiperiodic lattices using matrix diagonalization and eigenvalue analysis. The model is defined on a chain of length $N$ with open boundary conditions, hopping amplitude $t$ between nearest neighbors, and an on-site modulation of strength $\\lambda$ with an incommensurate frequency approximated by a rational number. The Hamiltonian matrix $\\mathbf{H} \\in \\mathbb{R}^{N \\times N}$ in the site basis $\\{|i\\rangle\\}_{i=0}^{N-1}$ is specified by\n$$\nH_{i,j} = t \\, (\\delta_{i,j+1} + \\delta_{i,j-1}) + \\lambda \\cos\\!\\big(2\\pi \\alpha \\, i + \\phi \\big) \\, \\delta_{i,j},\n$$\nwhere $i \\in \\{0,1,\\dots,N-1\\}$, $t \\in \\mathbb{R}$, $\\lambda \\in \\mathbb{R}$, $\\alpha \\in \\mathbb{R}$ is an irrational number approximated by a rational $p/q$, and $\\phi \\in \\mathbb{R}$ is a phase. Open boundary conditions are enforced by the fact that $H_{-1,0}=H_{N,N-1}=0$, which in practice means only the nearest-neighbor off-diagonal elements within the chain are nonzero. The fundamental base for the computation is the matrix eigenvalue problem,\n$$\n\\mathbf{H} \\, \\psi_n = E_n \\, \\psi_n,\n$$\nwhere $E_n \\in \\mathbb{R}$ are the eigenvalues and $\\psi_n \\in \\mathbb{R}^N$ are the corresponding normalized eigenvectors satisfying $\\sum_{i=0}^{N-1} |\\psi_n(i)|^2 = 1$. To quantify spatial extension versus localization of eigenstates, use the participation ratio defined for a normalized eigenvector by\n$$\nP_n = \\frac{\\Big(\\sum_{i=0}^{N-1} |\\psi_n(i)|^2 \\Big)^2}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4} = \\frac{1}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4},\n$$\nand the normalized participation ratio $p_n = P_n/N \\in (0,1]$. To quantify eigenvalue statistics without unfolding, use the ratio of consecutive level spacings defined for the ordered spectrum $E_0 \\le E_1 \\le \\dots \\le E_{N-1}$. Denoting spacings by $\\delta_k = E_{k+1} - E_k$ for $k \\in \\{0,1,\\dots,N-2\\}$, define for $k \\in \\{0,1,\\dots,N-3\\}$ the ratio\n$$\nr_k = \\frac{\\min(\\delta_k,\\delta_{k+1})}{\\max(\\delta_k,\\delta_{k+1})},\n$$\nand its average $r = \\frac{1}{N-2} \\sum_{k=0}^{N-3} r_k$ after excluding any undefined cases where a denominator would vanish.\n\nYour task is to implement a program that, for each test case below, constructs $\\mathbf{H}$, diagonalizes it numerically to obtain $\\{E_n,\\psi_n\\}$, computes the average normalized participation ratio\n$$\n\\overline{p} = \\frac{1}{N} \\sum_{n=0}^{N-1} \\frac{1}{N \\sum_{i=0}^{N-1} |\\psi_n(i)|^4},\n$$\nand the mean ratio of consecutive level spacings $r$ as defined above. Use $t=1$ in all cases. Angles are dimensionless and measured in radians. There are no physical units in this problem; all quantities are dimensionless.\n\nTest suite parameters are specified as tuples $(N,\\alpha,\\lambda,\\phi)$ with $t=1$ fixed:\n\n- Case A (extended regime candidate): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 1.5,\\, 0.0)$.\n- Case B (critical regime candidate): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 2.0,\\, 0.0)$.\n- Case C (localized regime candidate): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 3.0,\\, 0.0)$.\n- Case D (no modulation baseline): $(N,\\alpha,\\lambda,\\phi) = (144,\\, 89/144,\\, 0.0,\\, 0.0)$.\n- Case E (different approximant and phase, localized): $(N,\\alpha,\\lambda,\\phi) = (89,\\, 55/89,\\, 3.0,\\, 0.3)$.\n\nYour program must output a single line containing a list of results, one per case, in the same order as listed. Each result must be the list $[\\lambda, \\overline{p}, r]$ with all three entries given as decimal numbers rounded to six digits after the decimal point. The entire output must be a single line in the form\n$$\n\\big[\\,[\\lambda_1,\\overline{p}_1,r_1],\\,[\\lambda_2,\\overline{p}_2,r_2],\\,\\dots\\,\\big].\n$$\nNo additional text should be printed.",
            "solution": "We start from the matrix eigenvalue problem for a real symmetric Hamiltonian $\\mathbf{H} \\in \\mathbb{R}^{N \\times N}$, which guarantees a complete set of orthonormal eigenvectors and real eigenvalues. The Aubry–André Hamiltonian on a one-dimensional chain with open boundary conditions is defined by hopping of amplitude $t$ between nearest neighbors and an on-site modulation $\\lambda \\cos(2\\pi \\alpha i + \\phi)$ with a frequency $\\alpha$ that is irrational in the infinite-size limit and approximated by rationals in finite systems. The indices $i$ are taken from $0$ to $N-1$, and $\\delta_{i,j}$ denotes the Kronecker delta.\n\nThe computational workflow is as follows:\n\n1. Matrix construction. For each test case $(N,\\alpha,\\lambda,\\phi)$ with $t=1$, construct $\\mathbf{H}$ by setting:\n   - For $i \\in \\{0,1,\\dots,N-1\\}$, the diagonal element\n     $$\n     H_{i,i} = \\lambda \\cos(2\\pi \\alpha i + \\phi).\n     $$\n   - For $i \\in \\{0,1,\\dots,N-2\\}$, the off-diagonal nearest-neighbor elements\n     $$\n     H_{i,i+1} = H_{i+1,i} = t = 1.\n     $$\n   All other elements are zero, which enforces open boundary conditions.\n\n2. Diagonalization. Solve\n   $$\n   \\mathbf{H}\\,\\psi_n = E_n \\,\\psi_n,\n   $$\n   using a routine for real symmetric matrices, which yields eigenvalues $\\{E_n\\}_{n=0}^{N-1}$ in nondecreasing order and orthonormal eigenvectors $\\{\\psi_n\\}_{n=0}^{N-1}$ satisfying\n   $$\n   \\sum_{i=0}^{N-1} |\\psi_n(i)|^2 = 1.\n   $$\n   The orthonormality ensures numerical stability and allows direct use of the definition of the participation ratio.\n\n3. Participation ratio. For each normalized eigenvector $\\psi_n$, compute the participation ratio using the definition\n   $$\n   P_n = \\frac{\\left(\\sum_{i=0}^{N-1} |\\psi_n(i)|^2\\right)^2}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4} = \\frac{1}{\\sum_{i=0}^{N-1} |\\psi_n(i)|^4}.\n   $$\n   The equality on the right follows from the normalization $\\sum_i |\\psi_n(i)|^2 = 1$. The normalized participation ratio $p_n = P_n/N \\in (0,1]$ measures the fraction of the system effectively occupied by the eigenstate, with $p_n \\approx 1$ indicating a spatially extended state and $p_n \\ll 1$ indicating localization over a small number of sites. Compute the mean normalized participation ratio\n   $$\n   \\overline{p} = \\frac{1}{N} \\sum_{n=0}^{N-1} \\frac{1}{N \\sum_{i=0}^{N-1} |\\psi_n(i)|^4 }.\n   $$\n\n4. Eigenvalue spacing statistics. Sort the eigenvalues in ascending order (the diagonalization routine for symmetric matrices provides them already sorted). Compute spacings $\\delta_k = E_{k+1} - E_k$ for $k \\in \\{0,1,\\dots,N-2\\}$. Then compute the ratio of consecutive gaps\n   $$\n   r_k = \\frac{\\min(\\delta_k, \\delta_{k+1})}{\\max(\\delta_k, \\delta_{k+1})}\n   $$\n   for $k \\in \\{0,1,\\dots,N-3\\}$, excluding any terms where the denominator would be zero to avoid division by zero. The mean ratio\n   $$\n   r = \\frac{1}{M} \\sum_{k} r_k,\n   $$\n   where $M$ is the number of valid $r_k$, is a dimensionless measure of level repulsion: for strongly localized spectra akin to uncorrelated levels, $r$ tends to values characteristic of Poisson statistics, while for extended states with level repulsion, $r$ is typically larger. The use of ratios avoids the need for spectral unfolding.\n\n5. Test suite and output. For each of the provided test cases, perform steps $1$–$4$ to obtain $(\\lambda, \\overline{p}, r)$. Assemble the results in the specified order into a list of lists $[\\,[\\lambda_1,\\overline{p}_1,r_1],\\dots]$ and print as a single line. Round each floating-point number to six digits after the decimal point to produce a concise, testable output.\n\nAlgorithmic design details and numerical considerations:\n- The Hamiltonian is tridiagonal with a cosine diagonal; the dimension $N$ in the test suite is small enough for dense diagonalization with a symmetric solver to be computationally trivial.\n- Because $\\mathbf{H}$ is real symmetric, $\\psi_n$ can be taken real, which simplifies absolute value operations to squares of real entries.\n- The normalization of eigenvectors from the solver guarantees that $P_n$ can be computed robustly as $1/\\sum_i |\\psi_n(i)|^4$, but for numerical safety one can compute the numerator $(\\sum_i |\\psi_n(i)|^2)^2$ and divide by $\\sum_i |\\psi_n(i)|^4$. Both yield the same value within floating-point tolerance.\n- The ratio $r_k$ is bounded in $[0,1]$, providing a well-conditioned statistic without rescaling.\n- The quasiperiodic frequency $\\alpha$ is approximated by Fibonacci ratios $89/144$ and $55/89$, which are standard rational approximants to the inverse golden ratio and provide high-quality incommensurability for finite chains.\n\nThe final program implements this pipeline deterministically and prints the results in the exact required single-line format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_hamiltonian(N: int, alpha: float, lam: float, phi: float, t: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Construct the Aubry–André Hamiltonian matrix for a 1D chain with open boundary conditions.\n\n    H_{i,i}   = lam * cos(2*pi*alpha*i + phi)\n    H_{i,i+1} = H_{i+1,i} = t\n\n    Parameters\n    ----------\n    N : int\n        System size (number of lattice sites).\n    alpha : float\n        Quasiperiodic frequency (rational approximant of an irrational).\n    lam : float\n        Modulation strength lambda.\n    phi : float\n        Phase offset in radians.\n    t : float\n        Nearest-neighbor hopping amplitude (default 1.0).\n\n    Returns\n    -------\n    H : np.ndarray\n        Real symmetric Hamiltonian matrix of shape (N, N).\n    \"\"\"\n    H = np.zeros((N, N), dtype=np.float64)\n    i = np.arange(N, dtype=np.float64)\n    H[np.arange(N), np.arange(N)] = lam * np.cos(2.0 * np.pi * alpha * i + phi)\n    offdiag_indices = np.arange(N - 1)\n    H[offdiag_indices, offdiag_indices + 1] = t\n    H[offdiag_indices + 1, offdiag_indices] = t\n    return H\n\ndef participation_ratio(evecs: np.ndarray) -> float:\n    \"\"\"\n    Compute the mean normalized participation ratio over all eigenvectors.\n\n    Parameters\n    ----------\n    evecs : np.ndarray\n        Eigenvectors as columns, shape (N, N), assumed normalized.\n\n    Returns\n    -------\n    pbar : float\n        Mean of P_n / N over n, where P_n = 1 / sum_i |psi_n(i)|^4.\n    \"\"\"\n    # evecs are real for a real symmetric matrix, but compute generically\n    psi2 = evecs**2  # since real; otherwise use np.abs(evecs)**2\n    denom = np.sum(psi2**2, axis=0)  # sum_i |psi_n(i)|^4 for each n\n    # Avoid division by zero (should not happen for normalized, nonzero vectors)\n    denom = np.where(denom == 0.0, np.finfo(np.float64).tiny, denom)\n    Pn = 1.0 / denom  # since sum_i |psi|^2 = 1 by normalization\n    N = evecs.shape[0]\n    pn_norm = Pn / N\n    return float(np.mean(pn_norm))\n\ndef mean_spacing_ratio(evals: np.ndarray) -> float:\n    \"\"\"\n    Compute the mean ratio of consecutive level spacings, r = <min(delta_k, delta_{k+1}) / max(...)>.\n\n    Parameters\n    ----------\n    evals : np.ndarray\n        Sorted eigenvalues in ascending order.\n\n    Returns\n    -------\n    r_mean : float\n        Mean ratio r over valid k.\n    \"\"\"\n    # Ensure sorted ascending\n    E = np.sort(evals)\n    s = np.diff(E)\n    if s.size < 2:\n        return float('nan')\n    s_left = s[:-1]\n    s_right = s[1:]\n    denom = np.maximum(s_left, s_right)\n    # Exclude zeros to avoid division by zero\n    valid = denom > 0.0\n    if not np.any(valid):\n        return 0.0\n    r_vals = np.minimum(s_left[valid], s_right[valid]) / denom[valid]\n    return float(np.mean(r_vals))\n\ndef analyze_case(N: int, alpha: float, lam: float, phi: float, t: float = 1.0):\n    \"\"\"\n    Build H, diagonalize, and compute average normalized participation ratio and mean spacing ratio.\n    \"\"\"\n    H = build_hamiltonian(N, alpha, lam, phi, t)\n    # eigh returns eigenvalues in ascending order and corresponding eigenvectors as columns\n    evals, evecs = np.linalg.eigh(H)\n    pbar = participation_ratio(evecs)\n    rmean = mean_spacing_ratio(evals)\n    return pbar, rmean\n\ndef solve():\n    # Define the test cases from the problem statement: (N, alpha, lambda, phi)\n    test_cases = [\n        (144, 89/144, 1.5, 0.0),  # Case A\n        (144, 89/144, 2.0, 0.0),  # Case B\n        (144, 89/144, 3.0, 0.0),  # Case C\n        (144, 89/144, 0.0, 0.0),  # Case D\n        (89,  55/89,  3.0, 0.3),  # Case E\n    ]\n\n    results = []\n    for N, alpha, lam, phi in test_cases:\n        pbar, rmean = analyze_case(N, alpha, lam, phi, t=1.0)\n        # Round to 6 decimals as specified\n        lam_s = f\"{lam:.6f}\"\n        pbar_s = f\"{pbar:.6f}\"\n        rmean_s = f\"{rmean:.6f}\"\n        results.append(f\"[{lam_s},{pbar_s},{rmean_s}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "The computational cost of diagonalizing large matrices can be a significant bottleneck in materials simulations. This practice demonstrates how to leverage the underlying symmetry of a physical system—a fundamental concept in physics—to achieve massive computational savings . You will use projection operators from group theory to construct a symmetry-adapted basis that transforms the Hamiltonian into a block-diagonal form, breaking a large, intractable problem into a set of smaller, manageable ones.",
            "id": "3446824",
            "problem": "You are given a finite point group, a basis of functions that transform under this group, and Hamiltonian matrices that are invariant under the group actions. Your task is to construct symmetry-adapted basis functions that block-diagonalize each Hamiltonian and to quantify the computational savings in diagonalization. The setting is purely mathematical: the Hamiltonian is a real symmetric matrix acting on a finite-dimensional vector space, and the point group acts via permutation matrices on the basis functions.\n\nFundamental base: start from the fact that if a matrix $H$ commutes with all representation matrices $D(g)$ for a finite group $G$, i.e., $[H, D(g)] = HD(g) - D(g)H = 0$ for all $g \\in G$, then there exists a change of basis that simultaneously block-diagonalizes $H$ into blocks associated with the irreducible representations of $G$. Constructing this change of basis proceeds by forming symmetry-adapted linear combinations of the original basis functions that transform according to irreducible representations, yielding invariant subspaces on which $H$ acts independently.\n\nUse the following finite group and basis:\n\n- Basis functions $\\{\\phi_0, \\phi_1, \\phi_2, \\phi_3\\}$ located at four sites with coordinates $(0,+1)$, $(+1,0)$, $(0,-1)$, $(-1,0)$, ordered as indices $0,1,2,3$, respectively.\n- The point group is $C_{2v}$ with operations: identity $E$, rotation by $\\pi$ around the origin $C_2$, reflection about the $x$-axis $\\sigma_x$, and reflection about the $y$-axis $\\sigma_y$. Each operation acts by permuting indices:\n  - $E$: $0 \\mapsto 0$, $1 \\mapsto 1$, $2 \\mapsto 2$, $3 \\mapsto 3$.\n  - $C_2$: $0 \\mapsto 2$, $1 \\mapsto 3$, $2 \\mapsto 0$, $3 \\mapsto 1$.\n  - $\\sigma_x$: $0 \\mapsto 2$, $1 \\mapsto 1$, $2 \\mapsto 0$, $3 \\mapsto 3$.\n  - $\\sigma_y$: $0 \\mapsto 0$, $1 \\mapsto 3$, $2 \\mapsto 2$, $3 \\mapsto 1$.\n  These operations define $4 \\times 4$ permutation matrices $D(g)$ acting on the column vector of coefficients of a general basis function combination.\n\nConstruct a program that, given the group action matrices $D(g)$ and a Hamiltonian $H$ satisfying $[H, D(g)] = 0$ for all $g \\in G$, performs the following:\n- Constructs symmetry-adapted basis functions by projecting the original basis onto subspaces that transform irreducibly under $G$.\n- Assembles these basis functions into an orthonormal change-of-basis matrix that block-diagonalizes $H$.\n- Diagonalizes each block and concatenates the eigenvalues.\n- Compares the concatenated block eigenvalues to the eigenvalues of the full Hamiltonian.\n- Quantifies the computational savings of block-diagonalization by the ratio $r = \\left(\\sum_{i} n_i^3\\right) / N^3$, where $N$ is the full dimension and $n_i$ are the block sizes.\n\nYour program must implement and test the above for the following test suite of Hamiltonians, all of which are real symmetric matrices of size $N = 4$:\n\n1. Happy-path case (full $C_{2v}$ invariance):\n   $$H_1 = \\begin{bmatrix}\n   0 & 1 & 0 & 1 \\\\\n   1 & 0 & 1 & 0 \\\\\n   0 & 1 & 0 & 1 \\\\\n   1 & 0 & 1 & 0\n   \\end{bmatrix}.$$\n   This corresponds to equal nearest-neighbor couplings $t = 1$ along the four edges of the square and zero onsite energies, and it commutes with all $D(g)$ for $g \\in C_{2v}$.\n\n2. Distinct interaction types preserving $C_{2v}$:\n   $$H_2 = \\begin{bmatrix}\n   0 & 1 & 0.5 & 1 \\\\\n   1 & 0 & 1 & 0.5 \\\\\n   0.5 & 1 & 0 & 1 \\\\\n   1 & 0.5 & 1 & 0\n   \\end{bmatrix}.$$\n   This adds diagonal couplings $t_d = 0.5$ between opposite sites $\\{0,2\\}$ and $\\{1,3\\}$ while maintaining group invariance.\n\n3. Anisotropic onsite energies preserving $C_{2v}$:\n   $$H_3 = \\begin{bmatrix}\n   2 & 1 & 0 & 1 \\\\\n   1 & 0 & 1 & 0 \\\\\n   0 & 1 & 2 & 1 \\\\\n   1 & 0 & 1 & 0\n   \\end{bmatrix}.$$\n   This has onsite energies $a = 2$ at indices $0$ and $2$, and $b = 0$ at indices $1$ and $3$, with equal nearest-neighbor couplings $t = 1$.\n\n4. Boundary case of a trivial group (no symmetry reduction): The same $H_1$ as in case $1$, but with the group consisting only of the identity operation $E$.\n\nFor each test case, your program should:\n- Construct symmetry-adapted basis functions for the chosen group.\n- Block-diagonalize the Hamiltonian and diagonalize each block.\n- Compute the ratio $r$ of cubic operation counts and the maximum absolute difference $d$ between the sorted eigenvalues from block-diagonalization and the sorted eigenvalues from full diagonalization:\n  $$r = \\frac{\\sum_i n_i^3}{N^3}, \\quad d = \\max_j \\left| \\lambda^{(\\mathrm{full})}_j - \\lambda^{(\\mathrm{block})}_j \\right|.$$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Report for each test case the pair $(r, d)$ in sequence, flattened into a single list. For example, the output for four test cases should be of the form\n$[r_1, d_1, r_2, d_2, r_3, d_3, r_4, d_4]$,\nwith each $r_i$ and $d_i$ represented as a floating-point number. No physical units are involved, and angles are not used. All values must be numerically computed by your program.",
            "solution": "The user's request is to validate and solve a problem centered on the application of group theory to block-diagonalize Hamiltonian matrices in a computational materials science context.\n\n### Step 1: Problem Validation\n\nThe problem statement has been meticulously analyzed against the specified criteria.\n\n- **Extraction of Givens**:\n  - Basis functions: $\\{\\phi_0, \\phi_1, \\phi_2, \\phi_3\\}$ at specific Cartesian coordinates, mapped to indices $0, 1, 2, 3$.\n  - Point group: $C_{2v} = \\{E, C_2, \\sigma_x, \\sigma_y\\}$.\n  - Group action: Defined as permutations of the basis indices, from which $4 \\times 4$ representation matrices $D(g)$ are derived.\n  - Invariance Condition: The Hamiltonians $H$ are stated to satisfy $[H, D(g)] = 0$ for all group operations $g$.\n  - Task: Construct symmetry-adapted basis functions (SAFs) via projection, form a change-of-basis matrix $U$ to block-diagonalize $H$, diagonalize the blocks, and quantify computational savings ($r$) and accuracy ($d$).\n  - Computational savings metric: $r = (\\sum_i n_i^3) / N^3$, where $n_i$ are block sizes and $N$ is the full matrix dimension.\n  - Accuracy metric: $d = \\max_j | \\lambda^{(\\mathrm{full})}_j - \\lambda^{(\\mathrm{block})}_j |$.\n  - Test cases: Four specified pairs of a Hamiltonian matrix and a symmetry group.\n    1. $H_1$ with $C_{2v}$ symmetry.\n    2. $H_2$ with $C_{2v}$ symmetry.\n    3. $H_3$ with $C_{2v}$ symmetry.\n    4. $H_1$ with the trivial group $\\{E\\}$.\n\n- **Validation using Extracted Givens**:\n  1.  **Scientifically Grounded**: The problem is a textbook application of representation theory of finite groups to simplify eigenvalue problems in quantum mechanics and condensed matter physics. Schur's lemma and the Great Orthogonality Theorem provide the theoretical foundation for block-diagonalizing operators that commute with a symmetry group. The group $C_{2v}$, the chosen basis sites, and the structure of the Hamiltonians are standard models. A check confirms that the provided Hamiltonians $H_1, H_2, H_3$ indeed commute with the representation matrices of $C_{2v}$, as asserted. The problem is scientifically and mathematically sound.\n  2.  **Well-Posed**: The problem is well-posed. The decomposition of the representation space into irreducible subspaces is unique, leading to a unique set of block sizes $\\{n_i\\}$ and unique eigenvalues. The procedure to find the symmetry-adapted basis is deterministic. The required outputs, $r$ and $d$, are uniquely determined quantities.\n  3.  **Objective**: All components of the problem are defined with mathematical precision. There is no ambiguity, subjectivity, or reliance on opinion.\n  4.  **Completeness**: The problem is self-contained and provides all necessary data and definitions to proceed to a solution.\n  5.  **Feasibility**: The calculations involve standard linear algebra on small ($4 \\times 4$) matrices and are computationally trivial.\n\n- **Verdict**:\n  The problem is **valid**. It is a well-defined, scientifically grounded problem in computational physics that can be solved algorithmically.\n\n### Step 2: Solution Derivation\n\nThe solution requires implementing the group-theoretical machinery for block diagonalization.\n\n**1. Group Representation and Character Theory**\nThe point group is $C_{2v}$, an abelian group of order $|G|=4$. Its operations and character table are fundamental. The group operations are given as permutations on the basis indices $\\{0, 1, 2, 3\\}$. These permutations define the $4 \\times 4$ representation matrices $D(g)$.\n\n- $E: (0)(1)(2)(3) \\implies D(E) = I_4$.\n- $C_2: (0 \\leftrightarrow 2, 1 \\leftrightarrow 3) \\implies D(C_2)_{ij} = \\delta_{i,C_2(j)}$.\n- $\\sigma_x: (0 \\leftrightarrow 2) \\implies D(\\sigma_x)_{ij} = \\delta_{i,\\sigma_x(j)}$.\n- $\\sigma_y: (1 \\leftrightarrow 3) \\implies D(\\sigma_y)_{ij} = \\delta_{i,\\sigma_y(j)}$.\n\nThe character table for $C_{2v}$ contains its four one-dimensional irreducible representations (irreps): $A_1, A_2, B_1, B_2$.\n| Irrep | $\\chi(E)$ | $\\chi(C_2)$ | $\\chi(\\sigma_x)$ | $\\chi(\\sigma_y)$ |\n|:---:|:---:|:---:|:---:|:---:|\n| $A_1$ | $1$ | $1$ | $1$ | $1$ |\n| $A_2$ | $1$ | $1$ | $-1$ | $-1$ |\n| $B_1$ | $1$ | $-1$ | $1$ | $-1$ |\n| $B_2$ | $1$ | $-1$ | $-1$ | $1$ |\n\n**2. Decomposition of the Reducible Representation**\nThe representation $\\Gamma$ furnished by the basis $\\{\\phi_0, \\phi_1, \\phi_2, \\phi_3\\}$ is reducible. Its characters are $\\chi(g) = \\mathrm{Tr}(D(g))$, which count the number of basis functions left unchanged by the operation $g$.\n- $\\chi(E) = \\mathrm{Tr}(I_4) = 4$.\n- $\\chi(C_2) = 0$ (no fixed points).\n- $\\chi(\\sigma_x) = 2$ (indices $1, 3$ are fixed).\n- $\\chi(\\sigma_y) = 2$ (indices $0, 2$ are fixed).\n\nThe number of times an irrep $\\alpha$ appears in $\\Gamma$ is given by the reduction formula $a_\\alpha = \\frac{1}{|G|} \\sum_{g \\in G} \\chi^{(\\alpha)*}(g) \\chi(g)$.\n- $a_{A_1} = \\frac{1}{4}[1(4) + 1(0) + 1(2) + 1(2)] = 2$.\n- $a_{A_2} = \\frac{1}{4}[1(4) + 1(0) - 1(2) - 1(2)] = 0$.\n- $a_{B_1} = \\frac{1}{4}[1(4) - 1(0) + 1(2) - 1(2)] = 1$.\n- $a_{B_2} = \\frac{1}{4}[1(4) - 1(0) - 1(2) + 1(2)] = 1$.\n\nSo, the reducible representation decomposes as $\\Gamma = 2A_1 \\oplus B_1 \\oplus B_2$. This implies that any Hamiltonian with $C_{2v}$ symmetry will be block-diagonalized into one $2 \\times 2$ block (corresponding to the $A_1$ subspace) and two $1 \\times 1$ blocks (for $B_1$ and $B_2$). The block sizes are therefore $n_1=2, n_2=1, n_3=1$.\n\n**3. Construction of Symmetry-Adapted Basis Functions (SAFs)**\nSAFs are constructed using projection operators, $P^{(\\alpha)} = \\frac{l_\\alpha}{|G|} \\sum_{g \\in G} \\chi^{(\\alpha)*}(g) D(g)$. Since all irreps here are one-dimensional ($l_\\alpha=1$), we project the original basis vectors (standard basis vectors $e_0, ..., e_3$) onto each irreducible subspace.\n- **$A_1$ Subspace**: Projecting $e_0$ and $e_1$ yields two linearly independent vectors: $e_0+e_2$ and $e_1+e_3$. Orthonormalizing these gives the first two SAFs: $\\psi_1 = \\frac{1}{\\sqrt{2}}(e_0+e_2)$ and $\\psi_2 = \\frac{1}{\\sqrt{2}}(e_1+e_3)$.\n- **$B_1$ Subspace**: Projecting the basis vectors yields one independent vector, proportional to $e_1-e_3$. The normalized SAF is $\\psi_3 = \\frac{1}{\\sqrt{2}}(e_1-e_3)$.\n- **$B_2$ Subspace**: Projecting yields one independent vector, proportional to $e_0-e_2$. The normalized SAF is $\\psi_4 = \\frac{1}{\\sqrt{2}}(e_0-e_2)$.\n\n**4. Change of Basis and Block Diagonalization**\nThe SAFs $\\{\\psi_1, \\psi_2, \\psi_3, \\psi_4\\}$ form the columns of the unitary change-of-basis matrix $U$.\n$$ U = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & -1 \\\\ 0 & 1 & -1 & 0 \\end{pmatrix} $$\nThe block-diagonal Hamiltonian is then computed as $H' = U^T H U$. The blocks are extracted from $H'$ according to the decomposition: a $2 \\times 2$ block for $A_1$, a $1 \\times 1$ for $B_1$, and a $1 \\times 1$ for $B_2$.\n\n**5. Algorithm Implementation**\n- For each test case involving the $C_{2v}$ group:\n  1. The matrix $U$ is constructed as described above.\n  2. The block diagonal matrix $H' = U^T H U$ is computed.\n  3. The blocks ($2 \\times 2, 1 \\times 1, 1 \\times 1$) are extracted.\n  4. Each block is diagonalized. For a $1 \\times 1$ block $[b]$, the eigenvalue is $b$. The $2 \\times 2$ block is diagonalized using a standard numerical routine.\n  5. The resulting eigenvalues are collected and sorted.\n  6. The full Hamiltonian $H$ is diagonalized directly for comparison.\n  7. The metrics $r = (2^3+1^3+1^3)/4^3 = 10/64 = 0.15625$ and $d$ (maximum absolute difference in sorted eigenvalues) are computed.\n- For the test case with the trivial group $\\{E\\}$:\n  1. The group has only one irrep, corresponding to the entire $4$-dimensional space. No reduction is possible.\n  2. The \"block\" is the full $4 \\times 4$ matrix. The block size is $n_1=4$.\n  3. The computational savings ratio is $r = 4^3/4^3 = 1$.\n  4. The eigenvalues are computed from the full matrix. The difference $d$ is necessarily zero.\n\nThe program will automate this entire procedure for the provided test cases and format the output as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the symmetry-based block diagonalization problem for a series of Hamiltonians.\n    \"\"\"\n\n    # Define the permutation matrices for the C2v group generators.\n    # D(g) acts on a coefficient vector c as c' = D(g) c.\n    # This corresponds to transforming the basis as g(phi_i) = phi_{g(i)}.\n    # The matrix D(g) has D_ij = 1 if i=g(j), 0 otherwise.\n    \n    # E: (0)(1)(2)(3)\n    D_E = np.identity(4)\n    # C2: 0->2, 1->3, 2->0, 3->1\n    D_C2 = np.array([[0,0,1,0],[0,0,0,1],[1,0,0,0],[0,1,0,0]])\n    # sigma_x (reflection across xz-plane): 0->2, 1->1, 2->0, 3->3\n    D_sigmax = np.array([[0,0,1,0],[0,1,0,0],[1,0,0,0],[0,0,0,1]])\n    # sigma_y (reflection across yz-plane): 0->0, 1->3, 2->2, 3->1\n    D_sigmay = np.array([[1,0,0,0],[0,0,0,1],[0,0,1,0],[0,1,0,0]])\n\n    C2v_group_reps = {'E': D_E, 'C2': D_C2, 'sigmax': D_sigmax, 'sigmay': D_sigmay}\n    \n    # Character table for C2v group\n    # Rows are irreps, columns correspond to E, C2, sigmax, sigmay\n    char_table_C2v = {\n        'A1': {'E': 1, 'C2': 1, 'sigmax': 1, 'sigmay': 1},\n        'A2': {'E': 1, 'C2': 1, 'sigmax':-1, 'sigmay':-1},\n        'B1': {'E': 1, 'C2':-1, 'sigmax': 1, 'sigmay':-1},\n        'B2': {'E': 1, 'C2':-1, 'sigmax':-1, 'sigmay': 1},\n    }\n    \n    # Define test case Hamiltonians\n    H1 = np.array([\n        [0, 1, 0, 1],\n        [1, 0, 1, 0],\n        [0, 1, 0, 1],\n        [1, 0, 1, 0]\n    ], dtype=float)\n\n    H2 = np.array([\n        [0,   1, 0.5, 1],\n        [1,   0, 1,   0.5],\n        [0.5, 1, 0,   1],\n        [1, 0.5, 1,   0]\n    ], dtype=float)\n\n    H3 = np.array([\n        [2, 1, 0, 1],\n        [1, 0, 1, 0],\n        [0, 1, 2, 1],\n        [1, 0, 1, 0]\n    ], dtype=float)\n\n    test_cases = [\n        (H1, 'C2v'),\n        (H2, 'C2v'),\n        (H3, 'C2v'),\n        (H1, 'trivial')\n    ]\n\n    results = []\n    \n    def get_saf_basis(group_name, group_reps, char_table):\n        \"\"\"\n        Constructs the symmetry-adapted basis (SAF) transformation matrix U and block sizes.\n        \"\"\"\n        if group_name == 'trivial':\n            return np.identity(4), [4]\n\n        U_cols = []\n        block_sizes = []\n        \n        N = 4  # Dimension of the basis\n        group_order = len(group_reps)\n        basis_vectors = [np.eye(N)[i] for i in range(N)]\n        \n        # Order of irreps for deterministic U matrix construction\n        irrep_names = ['A1', 'A2', 'B1', 'B2']\n\n        for irrep_name in irrep_names:\n            irrep_chars = char_table[irrep_name]\n            # Projection operator for this irrep\n            # P_alpha = (l_alpha / |G|) * sum_g chi_alpha(g)* D(g)\n            # l_alpha = 1 for all C2v irreps\n            P_alpha = np.zeros((N, N))\n            for g_name, D_g in group_reps.items():\n                P_alpha += irrep_chars[g_name] * D_g\n            P_alpha *= (1.0 / group_order)\n\n            # Project original basis vectors to find vectors spanning the irrep subspace\n            projected_vectors = []\n            for v in basis_vectors:\n                pv = P_alpha @ v\n                # Check if the projected vector is non-zero\n                if not np.allclose(pv, 0):\n                    projected_vectors.append(pv)\n            \n            if not projected_vectors:\n                continue\n\n            # Orthonormalize the collected vectors for this irrep's subspace\n            # Using QR decomposition on matrix of column vectors\n            # This is robust against linear dependencies\n            Q, R = np.linalg.qr(np.array(projected_vectors).T)\n            \n            # The columns of Q form an orthonormal basis for the subspace.\n            # The rank of R tells us the dimension of the subspace.\n            rank = np.sum(np.abs(np.diag(R)) > 1e-9)\n            if rank > 0:\n                U_cols.extend([Q[:, i] for i in range(rank)])\n                block_sizes.append(rank)\n\n        return np.array(U_cols).T, block_sizes\n\n    for H, group_name in test_cases:\n        N = H.shape[0]\n\n        # 1. Construct symmetry-adapted basis functions (SAFs)\n        if group_name == 'C2v':\n            U, block_sizes = get_saf_basis(group_name, C2v_group_reps, char_table_C2v)\n        else: # Trivial group\n             U, block_sizes = get_saf_basis(group_name, None, None)\n\n        # 2. Block-diagonalize the Hamiltonian\n        H_prime = U.T @ H @ U\n        \n        # 3. Diagonalize each block and concatenate eigenvalues\n        block_eigenvalues = []\n        current_idx = 0\n        for size in block_sizes:\n            block = H_prime[current_idx:current_idx+size, current_idx:current_idx+size]\n            if size > 0:\n                # Use eigh for symmetric matrices\n                eigvals = np.linalg.eigh(block)[0]\n                block_eigenvalues.extend(eigvals)\n            current_idx += size\n\n        block_eigenvalues.sort()\n\n        # 4. Compare with eigenvalues of the full Hamiltonian\n        full_eigenvalues = np.linalg.eigh(H)[0]\n        full_eigenvalues.sort()\n        \n        # 5. Quantify computational savings (r) and accuracy (d)\n        r = sum([n**3 for n in block_sizes]) / (N**3)\n        d = np.max(np.abs(np.array(full_eigenvalues) - np.array(block_eigenvalues)))\n\n        results.extend([r, d])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{x:.8f}' for x in results)}]\")\n\nsolve()\n```"
        }
    ]
}