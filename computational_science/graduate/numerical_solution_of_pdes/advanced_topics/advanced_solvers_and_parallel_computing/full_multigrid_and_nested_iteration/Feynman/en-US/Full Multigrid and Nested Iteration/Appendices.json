{
    "hands_on_practices": [
        {
            "introduction": "The central principle of Full Multigrid (FMG) is to solve a discrete system only to the level of its inherent accuracy. This practice lays the foundation by having you derive the truncation error for the standard 5-point Laplacian, which reveals the $\\mathcal{O}(h^2)$ error that FMG aims to match efficiently without over-solving . Understanding this target is the first step in appreciating the algorithm's design.",
            "id": "3396892",
            "problem": "Consider the Poisson partial differential equation (PDE) $-\\Delta u = f$ on the unit square $\\Omega = (0,1)^{2}$ with Dirichlet boundary data $u = g$ on $\\partial \\Omega$, where $u \\in C^{6}(\\overline{\\Omega})$. Let $\\{ \\mathcal{T}_{h} \\}$ be a hierarchy of nested uniform Cartesian grids with mesh size $h$ in both coordinate directions, and suppose one employs Full Multigrid (FMG) with Nested Iteration (NI) to compute an approximation $u_{h}$ on the finest grid. On each grid $\\mathcal{T}_{h}$, the discrete Laplacian is defined at interior points $(x_{i}, y_{j})$ by the standard $5$-point stencil\n$$\n(L_{h} u)_{i,j} := \\frac{u(x_{i}+h, y_{j}) - 2 u(x_{i}, y_{j}) + u(x_{i}-h, y_{j})}{h^{2}} + \\frac{u(x_{i}, y_{j}+h) - 2 u(x_{i}, y_{j}) + u(x_{i}, y_{j}-h)}{h^{2}}.\n$$\nStarting from fundamental definitions and well-tested formulas (specifically, multivariate Taylor series for smooth functions and central-difference consistency arguments), derive the truncation error of $L_{h}$ at a generic interior point $(x_{i}, y_{j})$ in terms of spatial derivatives of $u$ evaluated at $(x_{i}, y_{j})$, and determine the order $p$ such that the consistency error $\\| L_{h} u - \\Delta u \\|_{\\infty} = \\mathcal{O}(h^{p})$ as $h \\to 0$. Your derivation should make clear how the leading error term arises, and how its magnitude informs the accuracy scale targeted by FMG with NI when transferring and refining approximations across levels.\n\nReport your final answer as two quantities: the leading-order truncation error at $(x_{i}, y_{j})$ and the order $p$. No numerical rounding is required, and no physical units are involved. Express the final answer as a single row matrix using the LaTeX $\\texttt{pmatrix}$ environment, with the first entry equal to the leading-order truncation error and the second entry equal to $p$.",
            "solution": "The problem is subjected to validation and is deemed valid as it is scientifically grounded, well-posed, objective, and conforms to all criteria for a solvable problem in numerical analysis.\n\nThe objective is to derive the local truncation error of the standard $5$-point central difference approximation to the Laplacian operator and to determine its order of consistency. The discrete Laplacian operator $L_{h}$ is applied to the exact solution $u$ of the continuous problem at an interior grid point $(x_{i}, y_{j})$. The truncation error $\\tau_{h}$ at this point is defined as the residual obtained by substituting the exact solution into the discrete operator and subtracting the exact differential operator acting on the solution:\n$$\n\\tau_{h}(x_i, y_j) = (L_{h} u)(x_i, y_j) - (\\Delta u)(x_i, y_j)\n$$\nThe operator $L_h$ is given by:\n$$\n(L_{h} u)_{i,j} = \\frac{u(x_{i}+h, y_{j}) - 2 u(x_{i}, y_{j}) + u(x_{i}-h, y_{j})}{h^{2}} + \\frac{u(x_{i}, y_{j}+h) - 2 u(x_{i}, y_{j}) + u(x_{i}, y_{j}-h)}{h^{2}}\n$$\nLet's analyze the two terms on the right-hand side separately. For clarity, we will suppress the indices $(i,j)$ and use $(x,y)$ for the point $(x_i, y_j)$, and denote partial derivatives with subscripts, e.g., $u_x = \\frac{\\partial u}{\\partial x}$, $u_{xx} = \\frac{\\partial^2 u}{\\partial x^2}$.\n\nThe problem states that the solution $u$ is of class $C^{6}(\\overline{\\Omega})$. This smoothness is sufficient to justify Taylor series expansions of $u$ around the point $(x, y)$.\n\nFirst, consider the terms for the $x$-direction. The Taylor expansion of $u(x+h, y)$ and $u(x-h, y)$ around $(x,y)$ are:\n$$\nu(x+h, y) = u(x,y) + h u_{x}(x,y) + \\frac{h^{2}}{2!} u_{xx}(x,y) + \\frac{h^{3}}{3!} u_{xxx}(x,y) + \\frac{h^{4}}{4!} u_{xxxx}(x,y) + \\frac{h^{5}}{5!} u_{xxxxx}(x,y) + \\mathcal{O}(h^{6})\n$$\n$$\nu(x-h, y) = u(x,y) - h u_{x}(x,y) + \\frac{h^{2}}{2!} u_{xx}(x,y) - \\frac{h^{3}}{3!} u_{xxx}(x,y) + \\frac{h^{4}}{4!} u_{xxxx}(x,y) - \\frac{h^{5}}{5!} u_{xxxxx}(x,y) + \\mathcal{O}(h^{6})\n$$\nThe $C^6$ regularity ensures the remainders are of order $\\mathcal{O}(h^6)$. Summing these two expansions, we observe that all odd-power terms in $h$ cancel:\n$$\nu(x+h, y) + u(x-h, y) = 2 u(x,y) + h^{2} u_{xx}(x,y) + \\frac{2h^{4}}{24} u_{xxxx}(x,y) + \\mathcal{O}(h^{6})\n$$\nRearranging this sum to form the central difference for the second derivative gives:\n$$\n\\frac{u(x+h, y) - 2u(x,y) + u(x-h, y)}{h^{2}} = u_{xx}(x,y) + \\frac{h^{2}}{12} u_{xxxx}(x,y) + \\mathcal{O}(h^{4})\n$$\nBy an identical argument for the $y$-direction, we obtain:\n$$\n\\frac{u(x, y+h) - 2u(x,y) + u(x, y-h)}{h^{2}} = u_{yy}(x,y) + \\frac{h^{2}}{12} u_{yyyy}(x,y) + \\mathcal{O}(h^{4})\n$$\nNow, we sum these two expressions to construct the action of the discrete operator $L_{h}$ on $u$:\n$$\n(L_{h} u)(x,y) = \\left( u_{xx}(x,y) + \\frac{h^{2}}{12} u_{xxxx}(x,y) \\right) + \\left( u_{yy}(x,y) + \\frac{h^{2}}{12} u_{yyyy}(x,y) \\right) + \\mathcal{O}(h^{4})\n$$\nGrouping terms, we get:\n$$\n(L_{h} u)(x,y) = \\left( u_{xx}(x,y) + u_{yy}(x,y) \\right) + \\frac{h^{2}}{12} \\left( u_{xxxx}(x,y) + u_{yyyy}(x,y) \\right) + \\mathcal{O}(h^{4})\n$$\nThe first term in parentheses is precisely the Laplacian of $u$, $\\Delta u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$. Therefore, we can write:\n$$\n(L_{h} u)(x,y) = (\\Delta u)(x,y) + \\frac{h^{2}}{12} \\left( \\frac{\\partial^{4} u}{\\partial x^{4}}(x,y) + \\frac{\\partial^{4} u}{\\partial y^{4}}(x,y) \\right) + \\mathcal{O}(h^{4})\n$$\nThe truncation error $\\tau_{h}$ is the difference $(L_{h} u) - (\\Delta u)$:\n$$\n\\tau_{h}(x,y) = \\frac{h^{2}}{12} \\left( \\frac{\\partial^{4} u}{\\partial x^{4}}(x,y) + \\frac{\\partial^{4} u}{\\partial y^{4}}(x,y) \\right) + \\mathcal{O}(h^{4})\n$$\nThe leading-order term of the truncation error is the term with the lowest power of $h$, which is:\n$$\n\\frac{h^{2}}{12} \\left( \\frac{\\partial^{4} u}{\\partial x^{4}} + \\frac{\\partial^{4} u}{\\partial y^{4}} \\right)\n$$\nThe problem asks for the order $p$ of the consistency error, defined by $\\|L_h u - \\Delta u\\|_{\\infty} = \\mathcal{O}(h^p)$. This is the maximum of the absolute value of the local truncation error over all interior grid points. Since $u \\in C^{6}(\\overline{\\Omega})$, the fourth partial derivatives are continuous on a compact set, and are therefore bounded. Let $M$ be a constant such that $\\sup_{(x,y) \\in \\Omega} \\left| \\frac{1}{12} \\left( \\frac{\\partial^{4} u}{\\partial x^{4}} + \\frac{\\partial^{4} u}{\\partial y^{4}} \\right) \\right| \\leq M < \\infty$. Then:\n$$\n\\|L_h u - \\Delta u\\|_{\\infty} = \\sup_{i,j} |\\tau_h(x_i, y_j)| \\leq M h^{2} + \\mathcal{O}(h^{4})\n$$\nThis shows that the consistency error is of order $\\mathcal{O}(h^{2})$. Thus, the order $p$ is $2$.\n\nThe magnitude of this leading error term, and particularly its scaling as $\\mathcal{O}(h^{2})$, is central to the design and efficacy of Full Multigrid (FMG) with Nested Iteration (NI). The goal of FMG is to compute a discrete solution $u_h$ whose error $\\|u - u_h\\|_{\\infty}$ is on the same order as the truncation error, in this case $\\mathcal{O}(h_k^2)$, on the finest grid with mesh size $h_k$. The NI procedure starts on the coarsest grid and obtains a solution. This solution is then interpolated to the next finer grid to serve as an initial guess. For a second-order scheme ($p=2$), a sufficiently accurate interpolation (e.g., bilinear) of the coarse-grid solution provides an initial guess on the fine grid whose error is already $\\mathcal{O}(h^2)$. A small, fixed number of multigrid cycles (e.g., one V-cycle) is then sufficient to reduce the high-frequency components of the algebraic error to a level below that of the discretization error. The result is a solution $u_h$ that is accurate to $\\mathcal{O}(h^2)$ at a computational cost that is linear in the number of unknowns on the finest grid, which is asymptotically optimal. The magnitude of the leading error term $\\frac{h^2}{12}(\\dots)$ sets the scale for the desired accuracy of the algebraic solver on each level of the multigrid hierarchy.\n\nThe two quantities requested are the leading-order truncation error and the order $p$.\n1. Leading-order truncation error at $(x_{i},y_{j})$: $\\frac{h^{2}}{12} \\left( \\frac{\\partial^{4} u}{\\partial x^{4}} + \\frac{\\partial^{4} u}{\\partial y^{4}} \\right)$\n2. Order $p$: $2$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{h^{2}}{12} \\left( \\frac{\\partial^{4} u}{\\partial x^{4}} + \\frac{\\partial^{4} u}{\\partial y^{4}} \\right) & 2 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "With the accuracy target established, we now turn to the engine of the multigrid method itself: the interplay between smoothing and coarse-grid correction. This exercise guides you through a Local Fourier Analysis (LFA) of a simple two-grid cycle, the theoretical toolset used to prove multigrid's efficiency . By calculating the amplification factor, you will gain a rigorous, quantitative understanding of how multigrid damps error across different frequencies.",
            "id": "3396909",
            "problem": "Consider the one-dimensional model problem for the Poisson equation $-u'' = f$ on the unit interval with periodic boundary conditions, discretized on a uniform fine grid with spacing $h$ using the standard second-order central difference operator $A_h$ with stencil $\\{-1, 2, -1\\}/h^2$. Let a two-grid method be defined with the following components:\n- Weighted Jacobi smoothing with weight $\\omega = 2/3$, applied as one pre-smoothing and one post-smoothing step.\n- Grid coarsening by a factor of $2$.\n- Full-weighting restriction from the fine grid to the coarse grid.\n- Linear interpolation (piecewise linear prolongation) from the coarse grid to the fine grid.\n- The coarse-grid operator defined by the Galerkin condition $A_{2h} = R A_h P$, and the coarse problem solved exactly.\n\nUse Local Fourier Analysis (LFA) to analyze the two-grid error-propagation operator. Work on the two-dimensional harmonic subspace spanned by the fine-grid Fourier modes with angles $\\theta$ and $\\theta+\\pi$, and consider the set of low-frequency angles that alias onto the coarse grid, namely $\\Theta_{\\text{low}} = \\{\\theta \\in (-\\pi, \\pi] : |\\theta| \\le \\pi/2\\}$. Starting from the definitions of the Fourier symbols of $A_h$, the weighted Jacobi smoother, the full-weighting restriction, and linear interpolation, derive the two-grid amplification factor $\\rho_{\\text{TG}}(\\theta)$ on this subspace. Then determine the worst-case two-grid amplification factor over $\\Theta_{\\text{low}}$.\n\nExpress your final answer as a single exact real number. No rounding is required, and no units are associated with the amplification factor.",
            "solution": "The user wants to find the worst-case two-grid amplification factor for a specific one-dimensional problem using Local Fourier Analysis (LFA). The analysis is performed on the two-dimensional harmonic subspace spanned by the fine-grid Fourier modes corresponding to frequencies (angles) $\\theta$ and $\\theta' = \\theta+\\pi$. The amplification factor is then maximized over the set of low frequencies $\\Theta_{\\text{low}} = \\{\\theta \\in (-\\pi, \\pi] : |\\theta| \\le \\pi/2\\}$.\n\nFirst, we determine the Fourier symbols for each component of the two-grid method. A discrete Fourier mode on the fine grid is given by $\\phi(\\theta)_j = \\exp(i j \\theta)$, where $j$ is the grid point index and $\\theta$ is the frequency.\n\n1.  **Fine-Grid Operator Symbol $\\tilde{A}_h(\\theta)$**:\n    The operator $A_h$ is the standard second-order central difference discretization of $-u''$ with stencil $\\frac{1}{h^2}[-1, 2, -1]$. Applying $A_h$ to $\\phi(\\theta)_j$:\n    $A_h \\phi(\\theta)_j = \\frac{1}{h^2}(-\\exp(i(j-1)\\theta) + 2\\exp(ij\\theta) - \\exp(i(j+1)\\theta))$\n    $= \\frac{\\exp(ij\\theta)}{h^2}(-e^{-i\\theta} + 2 - e^{i\\theta}) = \\frac{\\exp(ij\\theta)}{h^2}(2 - 2\\cos\\theta)$\n    $= \\frac{4}{h^2}\\sin^2(\\frac{\\theta}{2}) \\phi(\\theta)_j$.\n    The symbol (eigenvalue) is $\\tilde{A}_h(\\theta) = \\frac{4}{h^2}\\sin^2(\\frac{\\theta}{2})$. In LFA, the scaling factor $1/h^2$ can be ignored as it cancels out. We use $\\tilde{A}_h(\\theta) = 4\\sin^2(\\frac{\\theta}{2}) = 2(1-\\cos\\theta)$.\n\n2.  **Smoother Symbol $\\tilde{S}_h(\\theta)$**:\n    The error propagation operator for weighted Jacobi smoothing is $S_h = I - \\omega D_h^{-1} A_h$. The diagonal of $A_h$ is $D_h = 2/h^2$. The symbol of the smoother is:\n    $\\tilde{S}_h(\\theta) = 1 - \\omega \\frac{\\tilde{A}_h(\\theta)}{2/h^2} = 1 - \\omega \\frac{4/h^2 \\sin^2(\\theta/2)}{2/h^2} = 1 - 2\\omega \\sin^2(\\frac{\\theta}{2})$.\n    With the given weight $\\omega = 2/3$:\n    $\\tilde{S}_h(\\theta) = 1 - 2(\\frac{2}{3}) \\sin^2(\\frac{\\theta}{2}) = 1 - \\frac{4}{3} \\frac{1-\\cos\\theta}{2} = 1 - \\frac{2}{3}(1-\\cos\\theta) = \\frac{1}{3} + \\frac{2}{3}\\cos\\theta$.\n\n3.  **LFA on the 2D Subspace**:\n    We work in the basis of fine-grid modes $\\{\\phi(\\theta), \\phi(\\theta')\\}$ where $\\theta'=\\theta+\\pi$. Operators that are diagonal in the Fourier basis become $2 \\times 2$ diagonal matrices on this subspace. Let $c = \\cos\\theta$.\n    $\\tilde{A}_h(\\theta) = 2(1-c)$.\n    $\\tilde{A}_h(\\theta') = 2(1-\\cos(\\theta+\\pi)) = 2(1+c)$.\n    $\\tilde{S}_h(\\theta) = \\frac{1+2c}{3}$.\n    $\\tilde{S}_h(\\theta') = \\frac{1+2\\cos(\\theta+\\pi)}{3} = \\frac{1-2c}{3}$.\n    The matrix symbols are:\n    $$ \\tilde{A}_h(\\theta, \\theta') = \\begin{pmatrix} 2(1-c) & 0 \\\\ 0 & 2(1+c) \\end{pmatrix}, \\quad \\tilde{S}_h(\\theta, \\theta') = \\begin{pmatrix} \\frac{1+2c}{3} & 0 \\\\ 0 & \\frac{1-2c}{3} \\end{pmatrix} $$\n\n4.  **Restriction and Prolongation Symbols**:\n    -   **Full-weighting restriction ($R$)**: The stencil is $\\frac{1}{4}[1, 2, 1]$. Its symbol is a $1 \\times 2$ matrix mapping $(\\phi(\\theta), \\phi(\\theta'))$ to the coarse-grid mode $\\phi(2\\theta)$:\n        $\\tilde{R}(\\theta) = (\\cos^2(\\frac{\\theta}{2}), \\sin^2(\\frac{\\theta}{2})) = (\\frac{1+c}{2}, \\frac{1-c}{2})$.\n    -   **Linear interpolation prolongation ($P$)**: This is the adjoint of full-weighting restriction. Its symbol is a $2 \\times 1$ matrix mapping $\\phi(2\\theta)$ to a linear combination of $\\phi(\\theta)$ and $\\phi(\\theta')$. For this standard pair in 1D, $\\tilde{P}(\\theta) = \\tilde{R}(\\theta)^T$.\n        $$ \\tilde{P}(\\theta) = \\begin{pmatrix} \\cos^2(\\frac{\\theta}{2}) \\\\ \\sin^2(\\frac{\\theta}{2}) \\end{pmatrix} = \\begin{pmatrix} \\frac{1+c}{2} \\\\ \\frac{1-c}{2} \\end{pmatrix} $$\n\n5.  **Coarse-Grid Operator Symbol $\\tilde{A}_{2h}(2\\theta)$**:\n    The coarse-grid operator is defined by the Galerkin condition $A_{2h} = R A_h P$. Its symbol is:\n    $$ \\tilde{A}_{2h}(2\\theta) = \\tilde{R}(\\theta) \\tilde{A}_h(\\theta, \\theta') \\tilde{P}(\\theta) $$\n    $$ \\tilde{A}_{2h}(2\\theta) = \\begin{pmatrix} \\frac{1+c}{2} & \\frac{1-c}{2} \\end{pmatrix} \\begin{pmatrix} 2(1-c) & 0 \\\\ 0 & 2(1+c) \\end{pmatrix} \\begin{pmatrix} \\frac{1+c}{2} \\\\ \\frac{1-c}{2} \\end{pmatrix} $$\n    $$ = \\begin{pmatrix} (1+c)(1-c) & (1-c)(1+c) \\end{pmatrix} \\begin{pmatrix} \\frac{1+c}{2} \\\\ \\frac{1-c}{2} \\end{pmatrix} $$\n    $$ = (1-c^2)\\frac{1+c}{2} + (1-c^2)\\frac{1-c}{2} = (1-c^2) \\left(\\frac{1+c+1-c}{2}\\right) = 1-c^2 = \\sin^2\\theta $$\n\n6.  **Two-Grid Operator Symbol $\\tilde{M}_{\\text{TG}}(\\theta)$**:\n    The error propagation operator for the two-grid cycle is $M_{\\text{TG}} = S_h^{\\nu_2}(I - P A_{2h}^{-1} R A_h)S_h^{\\nu_1}$.\n    With $\\nu_1=1$, $\\nu_2=1$, the symbol is $\\tilde{M}_{\\text{TG}}(\\theta) = \\tilde{S}_h(\\theta, \\theta') \\left( I - \\tilde{P}(\\theta) \\tilde{A}_{2h}(2\\theta)^{-1} \\tilde{R}(\\theta) \\tilde{A}_h(\\theta, \\theta') \\right) \\tilde{S}_h(\\theta, \\theta')$.\n    Let's compute the coarse-grid correction operator symbol $C(\\theta) = I - \\tilde{P}(\\theta) \\tilde{A}_{2h}(2\\theta)^{-1} \\tilde{R}(\\theta) \\tilde{A}_h(\\theta, \\theta')$.\n    First, the projection-like term $K(\\theta)=\\tilde{P}(\\theta) \\tilde{A}_{2h}(2\\theta)^{-1} \\tilde{R}(\\theta) \\tilde{A}_h(\\theta, \\theta')$.\n    $$ \\tilde{P}\\tilde{A}_{2h}^{-1}\\tilde{R} = \\begin{pmatrix} \\frac{1+c}{2} \\\\ \\frac{1-c}{2} \\end{pmatrix} \\frac{1}{1-c^2} \\begin{pmatrix} \\frac{1+c}{2} & \\frac{1-c}{2} \\end{pmatrix} = \\frac{1}{4(1-c^2)} \\begin{pmatrix} (1+c)^2 & 1-c^2 \\\\ 1-c^2 & (1-c)^2 \\end{pmatrix} $$\n    Multiplying by $\\tilde{A}_h(\\theta, \\theta')$:\n    $$ K(\\theta) = \\frac{1}{4(1-c^2)} \\begin{pmatrix} (1+c)^2 & 1-c^2 \\\\ 1-c^2 & (1-c)^2 \\end{pmatrix} \\begin{pmatrix} 2(1-c) & 0 \\\\ 0 & 2(1+c) \\end{pmatrix} $$\n    $$ = \\frac{1}{2(1-c^2)} \\begin{pmatrix} (1+c)^2(1-c) & (1-c^2)(1+c) \\\\ (1-c^2)(1-c) & (1-c)^2(1+c) \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 1+c & 1+c \\\\ 1-c & 1-c \\end{pmatrix} $$\n    So, $C(\\theta) = I - K(\\theta) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\frac{1}{2}\\begin{pmatrix} 1+c & 1+c \\\\ 1-c & 1-c \\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix} 1-c & -(1+c) \\\\ -(1-c) & 1+c \\end{pmatrix}$.\n    Now we assemble $\\tilde{M}_{\\text{TG}}(\\theta) = \\tilde{S}_h C \\tilde{S}_h$:\n    $$ \\tilde{M}_{\\text{TG}}(\\theta) = \\begin{pmatrix} \\frac{1+2c}{3} & 0 \\\\ 0 & \\frac{1-2c}{3} \\end{pmatrix} \\left( \\frac{1}{2}\\begin{pmatrix} 1-c & -(1+c) \\\\ -(1-c) & 1+c \\end{pmatrix} \\right) \\begin{pmatrix} \\frac{1+2c}{3} & 0 \\\\ 0 & \\frac{1-2c}{3} \\end{pmatrix} $$\n    $$ = \\frac{1}{18} \\begin{pmatrix} (1+2c)(1-c) & -(1+2c)(1+c) \\\\ -(1-2c)(1-c) & (1-2c)(1+c) \\end{pmatrix} \\begin{pmatrix} 1+2c & 0 \\\\ 0 & 1-2c \\end{pmatrix}  $$\n    $$ = \\frac{1}{18} \\begin{pmatrix} (1+2c)^2(1-c) & -(1+2c)(1-2c)(1+c) \\\\ -(1+2c)(1-2c)(1-c) & (1-2c)^2(1+c) \\end{pmatrix} $$\n\n7.  **Two-Grid Amplification Factor $\\rho_{\\text{TG}}(\\theta)$**:\n    The amplification factor $\\rho_{\\text{TG}}(\\theta)$ is the spectral radius of $\\tilde{M}_{\\text{TG}}(\\theta)$. The characteristic equation for a $2 \\times 2$ matrix $M$ is $\\lambda^2 - \\text{tr}(M)\\lambda + \\det(M) = 0$.\n    The determinant of $\\tilde{M}_{\\text{TG}}(\\theta)$ is:\n    $$ \\det(\\tilde{M}_{\\text{TG}}) = (\\det(\\tilde{S}_h))^2 \\det(C) $$\n    Since $C = I-K$ and $K$ is a rank-1 projector ($K^2=K$), $C$ is also a projector and has eigenvalues $0$ and $1$. Thus, $\\det(C) = 0$, which implies $\\det(\\tilde{M}_{\\text{TG}}) = 0$.\n    The characteristic equation simplifies to $\\lambda(\\lambda - \\text{tr}(\\tilde{M}_{\\text{TG}})) = 0$. The eigenvalues are $\\lambda_1 = 0$ and $\\lambda_2 = \\text{tr}(\\tilde{M}_{\\text{TG}})$.\n    The spectral radius is $\\rho_{\\text{TG}}(\\theta) = |\\text{tr}(\\tilde{M}_{\\text{TG}}(\\theta))|$.\n    $$ \\text{tr}(\\tilde{M}_{\\text{TG}}) = \\frac{1}{18} \\left[ (1+2c)^2(1-c) + (1-2c)^2(1+c) \\right] $$\n    $$ (1+4c+4c^2)(1-c) = 1+4c+4c^2 - c - 4c^2 - 4c^3 = 1+3c-4c^3 $$\n    $$ (1-4c+4c^2)(1+c) = 1-4c+4c^2 + c - 4c^2 + 4c^3 = 1-3c+4c^3 $$\n    $$ \\text{tr}(\\tilde{M}_{\\text{TG}}) = \\frac{1}{18} \\left[ (1+3c-4c^3) + (1-3c+4c^3) \\right] = \\frac{1}{18} (2) = \\frac{1}{9} $$\n    Thus, the two-grid amplification factor is constant for all $\\theta\n \\in (-\\pi, \\pi]$ where the analysis is valid:\n    $$ \\rho_{\\text{TG}}(\\theta) = \\frac{1}{9} $$\n\n8.  **Worst-Case Amplification Factor**:\n    The problem asks for the worst-case (maximum) amplification factor over the set of low frequencies $\\Theta_{\\text{low}} = \\{\\theta \\in (-\\pi, \\pi] : |\\theta| \\le \\pi/2\\}$. Since $\\rho_{\\text{TG}}(\\theta)$ is constant over this entire range, the maximum value is simply this constant.\n    $$ \\max_{\\theta \\in \\Theta_{\\text{low}}} \\rho_{\\text{TG}}(\\theta) = \\max_{|\\theta| \\le \\pi/2} \\frac{1}{9} = \\frac{1}{9} $$",
            "answer": "$$\\boxed{\\frac{1}{9}}$$"
        },
        {
            "introduction": "While powerful, basic multigrid methods can fail when faced with challenges like anisotropic operators, a common occurrence in practice. This hands-on problem addresses this by tasking you with the design and analysis of a robust line-smoother tailored for anisotropy . Calculating the smoothing factor for this advanced technique demonstrates how to ensure rapid convergence even when the PDE's coefficients are highly varied.",
            "id": "3396899",
            "problem": "Consider the anisotropic diffusion equation on a square domain with periodic boundary conditions,\n$$- \\nabla \\cdot \\left( \\mathrm{diag}(a_x, a_y) \\nabla u \\right) = f,$$\nwhere $a_x$ and $a_y$ are positive constants with $a_x \\ll a_y$. Let the domain be discretized by a uniform Cartesian grid with spacing $h$ in both directions, and approximate the operator by second-order centered finite differences,\n$$A_h u_{i,j} = \\frac{a_x}{h^2}\\left(-u_{i-1,j} + 2 u_{i,j} - u_{i+1,j}\\right) + \\frac{a_y}{h^2}\\left(-u_{i,j-1} + 2 u_{i,j} - u_{i,j+1}\\right).$$\nIn the context of a Full Multigrid (FMG) cycle with nested iteration, you are to design a line relaxation smoother tailored to the anisotropy. Define a vertical-line block Jacobi smoother that inverts exactly, on each fixed $i$, the intra-line couplings in the $y$-direction while treating the inter-line couplings in the $x$-direction explicitly. Using local Fourier analysis with Fourier modes $e_{i,j} = \\exp\\!\\left(\\mathrm{i}(\\theta_x i + \\theta_y j)\\right)$ for $(\\theta_x,\\theta_y) \\in [-\\pi,\\pi]^2$, derive the one-step amplification factor of this line smoother and then compute the smoothing factor restricted to the set of modes oscillatory in $y$, defined here as those with $\\theta_y \\in [\\pi/2,\\pi]$ and arbitrary $\\theta_x \\in [0,\\pi]$. \n\nYour final answer must be the closed-form expression of the resulting smoothing factor as a function of $a_x$ and $a_y$. No numerical approximation or rounding is required. Express your final answer without units.",
            "solution": "The problem is valid as it is a well-posed, scientifically grounded problem in the field of numerical analysis for partial differential equations. We are asked to derive the smoothing factor for a specific line relaxation smoother applied to an anisotropic diffusion equation.\n\nThe discrete operator $A_h$ is given by\n$$A_h u_{i,j} = \\frac{a_x}{h^2}\\left(-u_{i-1,j} + 2 u_{i,j} - u_{i+1,j}\\right) + \\frac{a_y}{h^2}\\left(-u_{i,j-1} + 2 u_{i,j} - u_{i,j+1}\\right).$$\nThis can be rewritten to explicitly separate the diagonal and off-diagonal terms:\n$$A_h u_{i,j} = \\left(\\frac{2a_x + 2a_y}{h^2}\\right)u_{i,j} - \\frac{a_x}{h^2}\\left(u_{i-1,j} + u_{i+1,j}\\right) - \\frac{a_y}{h^2}\\left(u_{i,j-1} + u_{i,j+1}\\right).$$\n\nThe smoother is a vertical-line block Jacobi method. In this scheme, for each vertical line (fixed index $i$), the couplings to other nodes on the same line are treated implicitly, while couplings to nodes on other lines (indices $i-1$ and $i+1$) are treated explicitly. This leads to a splitting of the matrix operator $A_h$ into a block-diagonal part $D_{block}$ and an off-block-diagonal part $N_{block}$ such that $A_h = D_{block} - N_{block}$.\n\nThe block-diagonal operator $D_{block}$ contains all terms that couple unknowns within the same vertical line. For a node $(i,j)$, these are the terms involving $u_{i,j}$, $u_{i,j-1}$, and $u_{i,j+1}$:\n$$D_{block} u_{i,j} = \\left(\\frac{2a_x + 2a_y}{h^2}\\right)u_{i,j} - \\frac{a_y}{h^2}\\left(u_{i,j-1} + u_{i,j+1}\\right).$$\nThe off-block-diagonal operator $N_{block}$ contains the remaining terms, which couple unknowns between different vertical lines:\n$$N_{block} u_{i,j} = \\frac{a_x}{h^2}\\left(u_{i-1,j} + u_{i+1,j}\\right).$$\nThe block Jacobi iteration for the linear system $A_h u = f$ is given by $D_{block} u^{(k+1)} = N_{block} u^{(k)} + f$. The corresponding error $e^{(k)} = u - u^{(k)}$ propagates according to the homogeneous equation $D_{block} e^{(k+1)} = N_{block} e^{(k)}$. The error is amplified at each step by the iteration matrix $S = D_{block}^{-1} N_{block}$.\n\nWe use local Fourier analysis to find the amplification factor of the smoother. We apply the operators to a single Fourier mode $e_{i,j} = \\exp(\\mathrm{i}(\\theta_x i + \\theta_y j))$. The amplification factor $\\lambda(\\theta_x, \\theta_y)$ is the corresponding eigenvalue of the iteration matrix, which is the ratio of the Fourier symbols of $N_{block}$ and $D_{block}$.\n\nThe Fourier symbol of $D_{block}$, denoted $\\hat{D}_{block}(\\theta_y)$, is found by:\n$$D_{block} e_{i,j} = \\left[ \\left(\\frac{2a_x + 2a_y}{h^2}\\right) - \\frac{a_y}{h^2}\\left(\\exp(-\\mathrm{i}\\theta_y) + \\exp(\\mathrm{i}\\theta_y)\\right) \\right] e_{i,j}$$\n$$= \\left[ \\frac{2a_x + 2a_y - 2a_y\\cos(\\theta_y)}{h^2} \\right] e_{i,j}$$\n$$= \\left[ \\frac{2a_x + 4a_y\\sin^2(\\frac{\\theta_y}{2})}{h^2} \\right] e_{i,j}.$$\nThus, $\\hat{D}_{block}(\\theta_y) = \\frac{2a_x + 4a_y\\sin^2(\\frac{\\theta_y}{2})}{h^2}$.\n\nThe Fourier symbol of $N_{block}$, denoted $\\hat{N}_{block}(\\theta_x)$, is found by:\n$$N_{block} e_{i,j} = \\left[ \\frac{a_x}{h^2}\\left(\\exp(-\\mathrm{i}\\theta_x) + \\exp(\\mathrm{i}\\theta_x)\\right) \\right] e_{i,j} = \\left[ \\frac{2a_x\\cos(\\theta_x)}{h^2} \\right] e_{i,j}.$$\nThus, $\\hat{N}_{block}(\\theta_x) = \\frac{2a_x\\cos(\\theta_x)}{h^2}$.\n\nThe one-step amplification factor is the ratio of these symbols:\n$$\\lambda(\\theta_x, \\theta_y) = \\frac{\\hat{N}_{block}(\\theta_x)}{\\hat{D}_{block}(\\theta_y)} = \\frac{\\frac{2a_x\\cos(\\theta_x)}{h^2}}{\\frac{2a_x + 4a_y\\sin^2(\\frac{\\theta_y}{2})}{h^2}} = \\frac{2a_x\\cos(\\theta_x)}{2a_x + 4a_y\\sin^2(\\frac{\\theta_y}{2})} = \\frac{a_x\\cos(\\theta_x)}{a_x + 2a_y\\sin^2(\\frac{\\theta_y}{2})}.$$\n\nThe smoothing factor $\\mu$ is the maximum of the absolute value of the amplification factor over the specified set of high-frequency modes. The problem defines this set as modes with $\\theta_y \\in [\\pi/2, \\pi]$ and $\\theta_x \\in [0, \\pi]$.\n$$\\mu = \\max_{\\substack{\\theta_x \\in [0, \\pi] \\\\ \\theta_y \\in [\\pi/2, \\pi]}} \\left| \\lambda(\\theta_x, \\theta_y) \\right| = \\max_{\\substack{\\theta_x \\in [0, \\pi] \\\\ \\theta_y \\in [\\pi/2, \\pi]}} \\left| \\frac{a_x\\cos(\\theta_x)}{a_x + 2a_y\\sin^2(\\frac{\\theta_y}{2})} \\right|.$$\nSince $a_x > 0$ and $a_y > 0$, the denominator $a_x + 2a_y\\sin^2(\\frac{\\theta_y}{2})$ is always positive. We can write:\n$$\\mu = \\max_{\\substack{\\theta_x \\in [0, \\pi] \\\\ \\theta_y \\in [\\pi/2, \\pi]}} \\frac{a_x |\\cos(\\theta_x)|}{a_x + 2a_y\\sin^2(\\frac{\\theta_y}{2})}.$$\nTo maximize this expression, we must maximize the numerator and minimize the denominator. The variables $\\theta_x$ and $\\theta_y$ are independent.\n\nFirst, we maximize the numerator, $a_x |\\cos(\\theta_x)|$, over $\\theta_x \\in [0, \\pi]$. The maximum value of $|\\cos(\\theta_x)|$ on this interval is $1$, which occurs at $\\theta_x=0$ and $\\theta_x=\\pi$.\n\nSecond, we minimize the denominator, $a_x + 2a_y\\sin^2(\\frac{\\theta_y}{2})$, over $\\theta_y \\in [\\pi/2, \\pi]$. Let $\\phi = \\theta_y/2$. The interval for $\\phi$ is $[\\pi/4, \\pi/2]$. The function $\\sin^2(\\phi)$ is monotonically increasing on this interval. Therefore, its minimum value occurs at the left endpoint, $\\phi = \\pi/4$, which corresponds to $\\theta_y = \\pi/2$.\nThe minimum value of $\\sin^2(\\frac{\\theta_y}{2})$ is $\\sin^2(\\pi/4) = (\\frac{\\sqrt{2}}{2})^2 = \\frac{1}{2}$.\nThe minimum value of the denominator is $a_x + 2a_y(\\frac{1}{2}) = a_x + a_y$.\n\nCombining these results, the maximum value of the expression for $\\mu$ is the ratio of the maximum numerator and the minimum denominator:\n$$\\mu = \\frac{a_x \\cdot 1}{a_x + a_y} = \\frac{a_x}{a_x + a_y}.$$",
            "answer": "$$\\boxed{\\frac{a_x}{a_x + a_y}}$$"
        }
    ]
}