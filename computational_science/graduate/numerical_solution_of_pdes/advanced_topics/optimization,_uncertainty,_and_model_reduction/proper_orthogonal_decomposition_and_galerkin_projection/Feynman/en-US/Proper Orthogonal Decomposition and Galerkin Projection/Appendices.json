{
    "hands_on_practices": [
        {
            "introduction": "The most effective way to build confidence in a numerical method is to test it in a scenario where the exact outcome is known. In this practice, we will do just that by designing a \"manufactured solution\" experiment for the linear diffusion equation. By constructing a case where the system's dynamics are confined to a known, low-dimensional subspace, we can verify the core promise of Proper Orthogonal Decomposition: its ability to identify this subspace and create a reduced-order model with virtually no error . This exercise provides a concrete demonstration of the ideal performance of POD-Galerkin projection.",
            "id": "3435994",
            "problem": "Consider the one-dimensional diffusion partial differential equation (PDE) on the open interval $\\left(0,1\\right)$ with homogeneous Dirichlet boundary conditions and constant diffusivity, and let a standard second-order centered finite-difference semi-discretization be used on $n$ interior grid points. Denote the resulting semi-discrete state vector by $u\\left(t\\right) \\in \\mathbb{R}^{n}$. The semi-discrete model is the linear time-invariant system\n$$\n\\frac{d}{dt} u\\left(t\\right) \\;=\\; A\\,u\\left(t\\right), \\quad A \\;=\\; \\nu\\,L_{h},\n$$\nwhere $\\nu \\in \\mathbb{R}_{+}$ is the diffusivity and $L_{h} \\in \\mathbb{R}^{n \\times n}$ is the tridiagonal discrete Laplacian with entries\n$$\n\\left(L_{h}\\right)_{i,i} \\;=\\; -\\frac{2}{h^{2}}, \\quad \\left(L_{h}\\right)_{i,i+1} \\;=\\; \\left(L_{h}\\right)_{i+1,i} \\;=\\; \\frac{1}{h^{2}}, \\quad h \\;=\\; \\frac{1}{n+1}, \\quad i \\;=\\; 1,\\dots,n-1.\n$$\nThe matrix $A$ is real symmetric negative-definite, hence admits an eigendecomposition $A \\;=\\; V \\Lambda V^{\\top}$ with orthonormal $V \\in \\mathbb{R}^{n \\times n}$ and diagonal $\\Lambda \\in \\mathbb{R}^{n \\times n}$ having strictly negative diagonal entries. The exact solution for any initial condition $u\\left(0\\right)$ is then\n$$\nu\\left(t\\right) \\;=\\; V\\,e^{\\Lambda t}\\,V^{\\top} u\\left(0\\right).\n$$\n\nYou are to design a manufactured-solution experiment in which the full model solution lies exactly in the span of a few chosen eigenmodes, and then verify by computation that Proper Orthogonal Decomposition (POD) combined with a Galerkin projection onto the POD subspace recovers the same span and yields zero projection error when the POD rank is at least as large as the number of active modes. Use the following principle-based steps.\n\n1) Subspace invariance and manufactured solution. Choose a small set of mode indices $\\mathcal{K} \\subset \\left\\{1,\\dots,n\\right\\}$ of size $r_{\\mathrm{true}}$ (the number of active modes). Let $V_{\\mathcal{K}} \\in \\mathbb{R}^{n \\times r_{\\mathrm{true}}}$ denote the matrix whose columns are the corresponding eigenvectors of $A$, ordered by increasing absolute value of the associated eigenvalues. Choose a nonzero coefficient vector $a \\in \\mathbb{R}^{r_{\\mathrm{true}}}$ and set\n$$\nu\\left(0\\right) \\;=\\; V_{\\mathcal{K}}\\,a, \\qquad u\\left(t\\right) \\;=\\; V_{\\mathcal{K}}\\,\\exp\\!\\left(\\Lambda_{\\mathcal{K}} t\\right) a,\n$$\nwhere $\\Lambda_{\\mathcal{K}} \\in \\mathbb{R}^{r_{\\mathrm{true}} \\times r_{\\mathrm{true}}}$ is the diagonal eigenvalue submatrix. By construction, for every $t \\ge 0$, $u\\left(t\\right)$ lies in $\\mathrm{span}\\!\\left(V_{\\mathcal{K}}\\right)$, an $A$-invariant subspace.\n\n2) Snapshot collection and POD. Form the snapshot matrix $X \\in \\mathbb{R}^{n \\times m}$ with columns $u\\left(t_{j}\\right)$ at $m$ distinct times $0 = t_{1} < t_{2} < \\dots < t_{m} = T$. Compute the Singular Value Decomposition (SVD) $X \\;=\\; U \\Sigma W^{\\top}$ with orthonormal $U \\in \\mathbb{R}^{n \\times n}$, diagonal nonnegative $\\Sigma \\in \\mathbb{R}^{n \\times m}$, and orthonormal $W \\in \\mathbb{R}^{m \\times m}$. For a prescribed POD rank $r_{\\mathrm{pod}}$, define the POD basis as the first $r_{\\mathrm{pod}}$ columns of $U$, denoted $\\Phi \\in \\mathbb{R}^{n \\times r_{\\mathrm{pod}}}$.\n\n3) POD projection error. The orthogonal projector onto the POD subspace is $P \\;=\\; \\Phi \\Phi^{\\top}$. The normalized projection error of the snapshots is\n$$\n\\mathcal{E}_{\\mathrm{proj}} \\;=\\; \\frac{\\left\\| X \\;-\\; P X \\right\\|_{F}}{\\left\\| X \\right\\|_{F}},\n$$\nwhere $\\left\\|\\cdot\\right\\|_{F}$ denotes the Frobenius norm. If $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$ and $\\mathrm{rank}\\left(X\\right) = r_{\\mathrm{true}}$, then $\\mathcal{E}_{\\mathrm{proj}}$ must be zero in exact arithmetic.\n\n4) PODâ€“Galerkin reduced model. Form the Galerkin-projected reduced operator\n$$\nA_{r} \\;=\\; \\Phi^{\\top} A \\Phi \\;\\in\\; \\mathbb{R}^{r_{\\mathrm{pod}} \\times r_{\\mathrm{pod}}},\n$$\nand the reduced initial state $c\\left(0\\right) \\;=\\; \\Phi^{\\top} u\\left(0\\right)$. Evolve the reduced model\n$$\n\\frac{d}{dt} c\\left(t\\right) \\;=\\; A_{r}\\,c\\left(t\\right), \\qquad c\\left(t\\right) \\;=\\; e^{A_{r} t} c\\left(0\\right),\n$$\nand reconstruct the reduced state $u_{r}\\left(t\\right) \\;=\\; \\Phi\\,c\\left(t\\right)$. Compute the final-time relative error\n$$\n\\mathcal{E}_{\\mathrm{final}} \\;=\\; \\frac{\\left\\| u\\left(T\\right) - u_{r}\\left(T\\right) \\right\\|_{2}}{\\left\\| u\\left(T\\right) \\right\\|_{2}}.\n$$\nIf $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$, then invariance implies $u_{r}\\left(t\\right) \\equiv u\\left(t\\right)$ in exact arithmetic, hence $\\mathcal{E}_{\\mathrm{final}} = 0$.\n\nImplement a program that constructs $A$ from $\\nu$ and $n$, computes its eigendecomposition, manufactures $u\\left(t\\right)$ from a chosen set of modes and coefficients, builds the POD basis, computes $\\mathcal{E}_{\\mathrm{proj}}$ and $\\mathcal{E}_{\\mathrm{final}}$, and outputs these two errors for each of the following test cases. In all cases, the POD inner product is the Euclidean inner product on $\\mathbb{R}^{n}$, all time values are in the same arbitrary unit, and no physical units are required.\n\nTest suite (each case is a tuple $\\left(n, \\nu, T, \\mathcal{K}, a, m, r_{\\mathrm{pod}}\\right)$):\n- Case $1$: $\\left(n=80, \\nu=0.5, T=0.7, \\mathcal{K}=\\left[1,3\\right], a=\\left[1.0,-0.4\\right], m=6, r_{\\mathrm{pod}}=2\\right)$.\n- Case $2$: $\\left(n=60, \\nu=0.2, T=1.3, \\mathcal{K}=\\left[2,5,7\\right], a=\\left[0.7,-1.0,0.5\\right], m=9, r_{\\mathrm{pod}}=3\\right)$.\n- Case $3$: $\\left(n=64, \\nu=1.0, T=0.3, \\mathcal{K}=\\left[4\\right], a=\\left[1.0\\right], m=4, r_{\\mathrm{pod}}=5\\right)$.\n- Case $4$: $\\left(n=60, \\nu=0.2, T=0.8, \\mathcal{K}=\\left[1,4,6\\right], a=\\left[1.0,-0.5,0.3\\right], m=8, r_{\\mathrm{pod}}=2\\right)$.\n\nImportant implementation details:\n- When constructing $A$, use the tridiagonal $L_{h}$ defined above and multiply by the diffusivity $\\nu$.\n- Compute the eigendecomposition of $A$ as $A \\;=\\; V \\Lambda V^{\\top}$ and order eigenpairs by increasing $\\left|\\lambda\\right|$ so that mode index $k$ denotes the eigenpair with the $k$-th smallest $\\left|\\lambda\\right|$.\n- Manufacture snapshots using only the selected eigenpairs in $\\mathcal{K}$ and the formula $u\\left(t\\right) \\;=\\; \\sum_{j} a_{j}\\,e^{\\lambda_{k_{j}} t}\\,v_{k_{j}}$ to ensure exact subspace invariance.\n- For each test case, output the pair $\\left(\\mathcal{E}_{\\mathrm{proj}}, \\mathcal{E}_{\\mathrm{final}}\\right)$ as two floating-point numbers appended to a single flat output list.\n\nFinal output format:\nYour program should produce a single line of output containing a single list with $2$ floating-point numbers per test case in the order of the cases above, namely\n$$\n\\left[\\mathcal{E}_{\\mathrm{proj}}^{(1)}, \\mathcal{E}_{\\mathrm{final}}^{(1)}, \\mathcal{E}_{\\mathrm{proj}}^{(2)}, \\mathcal{E}_{\\mathrm{final}}^{(2)}, \\mathcal{E}_{\\mathrm{proj}}^{(3)}, \\mathcal{E}_{\\mathrm{final}}^{(3)}, \\mathcal{E}_{\\mathrm{proj}}^{(4)}, \\mathcal{E}_{\\mathrm{final}}^{(4)}\\right],\n$$\nprinted exactly as a comma-separated list enclosed in square brackets. No other text should be printed. All angle measures, percentages, and physical units are not applicable; all numerical outputs must be real numbers.",
            "solution": "The problem statement constitutes a valid and well-posed numerical verification experiment. It is grounded in the established principles of the numerical solution of partial differential equations, linear algebra, and model order reduction via Proper Orthogonal Decomposition (POD) and Galerkin projection. All required parameters and procedures are specified without ambiguity or contradiction, allowing for a unique and meaningful computational result. We will proceed with the solution.\n\nThe core of the problem is to verify a fundamental property of POD-Galerkin reduced-order models (ROMs): if the solution of a full-order model (FOM) evolves within a low-dimensional subspace, a POD-Galerkin ROM of sufficient rank can exactly represent the solution and its dynamics, resulting in zero error.\n\nThe solution is implemented by following the four principle-based steps outlined in the problem description.\n\n**1. System and Manufactured Solution Construction**\n\nFirst, we construct the semi-discrete linear time-invariant system $\\frac{d}{dt} u(t) = A u(t)$ that approximates the one-dimensional diffusion equation. For a spatial domain of length $L=1$ discretized with $n$ interior points, the grid spacing is $h = \\frac{1}{n+1}$. The system matrix is $A = \\nu L_h$, where $\\nu \\in \\mathbb{R}_{+}$ is the diffusivity and $L_h \\in \\mathbb{R}^{n \\times n}$ is the second-order finite-difference approximation of the Laplacian operator with homogeneous Dirichlet boundary conditions. $L_h$ is a real, symmetric, tridiagonal matrix defined by:\n$$\n(L_h)_{ij} = \\frac{1}{h^2} \\begin{cases} -2 & i=j \\\\ 1 & |i-j|=1 \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThe matrix $A$ is symmetric and negative definite. Its eigendecomposition, $A = V \\Lambda V^{\\top}$, provides a basis of orthonormal eigenvectors $V \\in \\mathbb{R}^{n \\times n}$ and a diagonal matrix $\\Lambda \\in \\mathbb{R}^{n \\times n}$ of corresponding real, negative eigenvalues. The problem requires the eigenpairs $(\\lambda_k, v_k)$ to be ordered by increasing absolute value of the eigenvalues, i.e., $|\\lambda_1| \\le |\\lambda_2| \\le \\dots \\le |\\lambda_n|$.\n\nA manufactured solution is then constructed to lie exactly within a predetermined invariant subspace of $A$. We choose a set of $r_{\\mathrm{true}}$ mode indices $\\mathcal{K} \\subset \\{1, \\dots, n\\}$. Let $V_{\\mathcal{K}} \\in \\mathbb{R}^{n \\times r_{\\mathrm{true}}}$ be the matrix whose columns are the selected eigenvectors, and $\\Lambda_{\\mathcal{K}} \\in \\mathbb{R}^{r_{\\mathrm{true}} \\times r_{\\mathrm{true}}}$ be the diagonal matrix of corresponding eigenvalues. For a given coefficient vector $a \\in \\mathbb{R}^{r_{\\mathrm{true}}}$, the initial condition is set to $u(0) = V_{\\mathcal{K}} a$. The exact time-evolved solution is then given by:\n$$\nu(t) = V e^{\\Lambda t} V^{\\top} u(0) = V e^{\\Lambda t} V^{\\top} V_{\\mathcal{K}} a\n$$\nSince the columns of $V$ are orthonormal, $V^{\\top} V_{\\mathcal{K}}$ is zero except for the rows corresponding to the indices in $\\mathcal{K}$. This simplifies the solution to:\n$$\nu(t) = V_{\\mathcal{K}} e^{\\Lambda_{\\mathcal{K}} t} a\n$$\nBy construction, the state vector $u(t)$ remains in the subspace $\\mathrm{span}(V_{\\mathcal{K}})$ for all $t \\ge 0$.\n\n**2. Snapshot Collection and POD Basis**\n\nWe collect $m$ \"snapshots\" of the system state $u(t_j)$ at distinct time instances $t_j$ over the interval $[0, T]$, where $0 = t_1 < t_2 < \\dots < t_m = T$. These snapshots form the columns of the snapshot matrix $X = [u(t_1), u(t_2), \\dots, u(t_m)] \\in \\mathbb{R}^{n \\times m}$.\n\nThe POD basis is a set of orthonormal vectors that optimally capture the energy of the snapshots. It is obtained from the Singular Value Decomposition (SVD) of the snapshot matrix, $X = U \\Sigma W^{\\top}$. Here, $U \\in \\mathbb{R}^{n \\times n}$ contains the left singular vectors (the POD modes), $\\Sigma \\in \\mathbb{R}^{n \\times m}$ is a diagonal matrix of singular values $\\sigma_i \\ge 0$, and $W \\in \\mathbb{R}^{m \\times m}$ contains the right singular vectors. The POD basis of rank $r_{\\mathrm{pod}}$ is the matrix $\\Phi \\in \\mathbb{R}^{n \\times r_{\\mathrm{pod}}}$ formed by the first $r_{\\mathrm{pod}}$ columns of $U$.\n\n**3. POD Projection Error**\n\nThe orthogonal projector onto the POD subspace $\\mathrm{span}(\\Phi)$ is $P = \\Phi \\Phi^{\\top}$. The error incurred by projecting the snapshots onto this subspace is quantified by the normalized Frobenius norm of the residual:\n$$\n\\mathcal{E}_{\\mathrm{proj}} = \\frac{\\| X - P X \\|_{F}}{\\| X \\|_{F}}\n$$\nUsing the properties of the SVD, this error can be computed from the singular values without explicitly forming the matrices:\n$$\n\\mathcal{E}_{\\mathrm{proj}} = \\sqrt{\\frac{\\sum_{i=r_{\\mathrm{pod}}+1}^{k} \\sigma_i^2}{\\sum_{i=1}^{k} \\sigma_i^2}}\n$$\nwhere $k = \\mathrm{rank}(X)$. If the data lies in an $r_{\\mathrm{true}}$-dimensional subspace, then $\\mathrm{rank}(X) = r_{\\mathrm{true}}$ (assuming sufficient snapshots). If $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$, all non-zero singular values are captured, the numerator becomes zero, and thus $\\mathcal{E}_{\\mathrm{proj}}$ must be zero in exact arithmetic.\n\n**4. POD-Galerkin Reduced Model and Final-Time Error**\n\nThe POD-Galerkin method projects the governing equation onto the POD basis $\\Phi$. An approximate solution is sought in the form $u_r(t) = \\Phi c(t)$, where $c(t) \\in \\mathbb{R}^{r_{\\mathrm{pod}}}$ are the reduced coordinates. Substituting this into the FOM and pre-multiplying by $\\Phi^{\\top}$ yields the reduced-order model:\n$$\n\\frac{d}{dt} c(t) = A_r c(t), \\quad \\text{with} \\quad A_r = \\Phi^{\\top} A \\Phi \\in \\mathbb{R}^{r_{\\mathrm{pod}} \\times r_{\\mathrm{pod}}}\n$$\nThe initial condition is also projected: $c(0) = \\Phi^{\\top} u(0)$. The reduced system is evolved in time using the matrix exponential: $c(t) = e^{A_r t} c(0)$. The FOM solution is then reconstructed as $u_r(t) = \\Phi c(t)$.\n\nThe accuracy of the ROM is assessed by comparing its solution to the manufactured FOM solution at the final time $t=T$:\n$$\n\\mathcal{E}_{\\mathrm{final}} = \\frac{\\| u(T) - u_r(T) \\|_{2}}{\\| u(T) \\|_{2}}\n$$\nWhen $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$, the POD subspace $\\mathrm{span}(\\Phi)$ contains the invariant subspace $\\mathrm{span}(V_{\\mathcal{K}})$. Consequently, the projection is exact, $u_r(t)$ will be identical to $u(t)$, and $\\mathcal{E}_{\\mathrm{final}}$ will be zero in exact arithmetic. For cases where $r_{\\mathrm{pod}} < r_{\\mathrm{true}}$, both $\\mathcal{E}_{\\mathrm{proj}}$ and $\\mathcal{E}_{\\mathrm{final}}$ are expected to be non-zero. The following program computes these two error metrics for the specified test cases.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Implements the POD-Galerkin model reduction experiment for the 1D diffusion equation.\n    \"\"\"\n    test_cases = [\n        # (n, nu, T, K, a, m, r_pod)\n        (80, 0.5, 0.7, [1, 3], [1.0, -0.4], 6, 2),\n        (60, 0.2, 1.3, [2, 5, 7], [0.7, -1.0, 0.5], 9, 3),\n        (64, 1.0, 0.3, [4], [1.0], 4, 5),\n        (60, 0.2, 0.8, [1, 4, 6], [1.0, -0.5, 0.3], 8, 2),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        n, nu, T, K, a, m, r_pod = case\n        a_vec = np.array(a)\n\n        # 1. System construction and manufactured solution\n        # Construct the system matrix A\n        h = 1.0 / (n + 1.0)\n        diag_val = -2.0 / (h**2)\n        offdiag_val = 1.0 / (h**2)\n        main_diag = np.full(n, diag_val)\n        off_diag = np.full(n - 1, offdiag_val)\n        L_h = np.diag(main_diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n        A = nu * L_h\n\n        # Compute eigendecomposition and sort by increasing absolute eigenvalue\n        lambdas, V = np.linalg.eigh(A)\n        sort_indices = np.argsort(np.abs(lambdas))\n        lambdas_sorted = lambdas[sort_indices]\n        V_sorted = V[:, sort_indices]\n\n        # Select modes for manufactured solution (convert 1-based K to 0-based indices)\n        mode_indices = [k - 1 for k in K]\n        V_K = V_sorted[:, mode_indices]\n        lambdas_K = lambdas_sorted[mode_indices]\n        \n        # Define initial condition\n        u0 = V_K @ a_vec\n\n        # 2. Snapshot collection and POD basis\n        # Generate snapshots\n        t_space = np.linspace(0.0, T, m)\n        X = np.zeros((n, m))\n        for j, t_j in enumerate(t_space):\n            # u(t) = V_K @ diag(exp(lambda_k * t)) @ a\n            X[:, j] = V_K @ (np.exp(lambdas_K * t_j) * a_vec)\n        \n        # Compute POD basis via SVD. U must be n x n as per problem description.\n        U, s, _ = np.linalg.svd(X, full_matrices=True)\n        Phi = U[:, :r_pod]\n\n        # 3. POD projection error\n        norm_X_sq = np.sum(s**2)\n        if norm_X_sq  1e-15:\n            # Handle trivial case of zero snapshots\n            E_proj = 0.0\n        else:\n            # Sum of squares of truncated singular values\n            norm_err_sq = np.sum(s[r_pod:]**2)\n            E_proj = np.sqrt(norm_err_sq / norm_X_sq)\n\n        # 4. POD-Galerkin reduced model and final-time error\n        # Full (manufactured) solution at the final time T\n        u_T = V_K @ (np.exp(lambdas_K * T) * a_vec)\n        \n        # If r_pod is 0, reduced solution is identically zero\n        if r_pod == 0:\n            u_r_T = np.zeros(n)\n        else:\n            # Construct and evolve the reduced-order model\n            A_r = Phi.T @ A @ Phi\n            c0 = Phi.T @ u0\n            c_T = expm(A_r * T) @ c0\n            \n            # Reconstruct the FOM-space solution from the ROM\n            u_r_T = Phi @ c_T\n\n        # Compute final-time relative error\n        norm_u_T = np.linalg.norm(u_T)\n        if norm_u_T  1e-15:\n            E_final = 0.0\n        else:\n            E_final = np.linalg.norm(u_T - u_r_T) / norm_u_T\n            \n        all_results.extend([E_proj, E_final])\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While linear systems provide a clean starting point, the true power of model reduction is realized when tackling nonlinear dynamics, which are ubiquitous in science and engineering. A key challenge is ensuring the reduced model remains computationally efficient. This exercise  demonstrates how to handle a common quadratic nonlinearity by projecting it onto the POD basis. You will derive how the nonlinear interactions are systematically captured in a constant, third-order tensor, a crucial step that allows for expensive computations to be performed \"offline\" before the fast \"online\" simulation.",
            "id": "3436025",
            "problem": "Consider a spatially semi-discretized nonlinear partial differential equation with $N$ degrees of freedom that yields an ordinary differential equation of the form\n$$\n\\frac{d}{dt} x(t) \\;=\\; A\\,x(t) \\;+\\; B\\big(x(t)\\odot x(t)\\big),\n$$\nwhere $x(t)\\in\\mathbb{R}^N$, $A\\in\\mathbb{R}^{N\\times N}$ is a linear operator, $B\\in\\mathbb{R}^{N\\times N}$ is a linear mapping applied after the Hadamard (componentwise) product, and $\\odot$ denotes the Hadamard product. Suppose a Proper Orthogonal Decomposition (POD) basis $U=\\big[u_1,\\dots,u_r\\big]\\in\\mathbb{R}^{N\\times r}$ with orthonormal columns in the Euclidean inner product is obtained, and the Galerkin projection is performed with the ansatz $x(t)\\approx U\\,a(t)$, where $a(t)\\in\\mathbb{R}^r$ are reduced coordinates. The reduced model is formed by enforcing the Galerkin condition with the Euclidean inner product on $\\operatorname{span}\\{u_1,\\dots,u_r\\}$.\n\nPart $(i)$: Starting from the definition of the Galerkin projection, derive the reduced quadratic term in a form suitable for offline precomputation and fast online evaluation. Your derivation must begin from the substitution $x(t)\\approx U\\,a(t)$ into the full model and the orthogonality (Galerkin) condition. Clearly identify the third-order tensor entries governing the quadratic term, expressed purely in terms of $B$ and the POD basis vectors $\\{u_i\\}_{i=1}^r$. You may assume no special structure of $B$ beyond linearity.\n\nPart $(ii)$: Specialize to $N=4$ and $r=3$ with the following data:\n$$\nB \\;=\\;\n\\begin{pmatrix}\n2  -1  0  0\\\\\n1  \\phantom{-}3  2  0\\\\\n0  -2  1  4\\\\\n0  \\phantom{-}0  3  -1\n\\end{pmatrix},\\quad\nu_1 \\;=\\;\n\\begin{pmatrix}\n1\\\\ 0\\\\ 0\\\\ 0\n\\end{pmatrix},\\quad\nu_2 \\;=\\;\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n0\\\\ 1\\\\ 1\\\\ 0\n\\end{pmatrix},\\quad\nu_3 \\;=\\;\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n0\\\\ 1\\\\ -1\\\\ 0\n\\end{pmatrix}.\n$$\nUsing your result from Part $(i)$, compute the specific reduced tensor entry corresponding to the quadratic term coefficient $C_{1,2,3}$ in the reduced model. Provide your final answer as a single real number. No rounding is required, and no physical units are involved.",
            "solution": "The problem is valid as it is scientifically grounded in the theory of model order reduction, is well-posed with all necessary information provided and no contradictions, and is expressed in objective, formal language. We can proceed with the solution.\n\n### Part (i): Derivation of the Reduced Quadratic Term\n\nWe are given the full-order model, which is a system of ordinary differential equations (ODEs):\n$$\n\\frac{d}{dt} x(t) = A\\,x(t) + B\\big(x(t)\\odot x(t)\\big)\n$$\nwhere $x(t) \\in \\mathbb{R}^N$. We seek a reduced-order model (ROM) using a Galerkin projection onto the subspace spanned by the columns of the POD basis matrix $U = [u_1, \\dots, u_r] \\in \\mathbb{R}^{N\\times r}$. The columns of $U$ are orthonormal, satisfying $u_i^T u_j = \\delta_{ij}$ for $i,j \\in \\{1, \\dots, r\\}$.\n\nThe Galerkin ansatz approximates the high-dimensional state $x(t)$ as a linear combination of the basis vectors:\n$$\nx(t) \\approx x_r(t) = U\\,a(t) = \\sum_{j=1}^{r} a_j(t) u_j\n$$\nwhere $a(t) \\in \\mathbb{R}^r$ is the vector of reduced (or generalized) coordinates.\n\nWe substitute this ansatz into the full-order model. Since $U$ is a constant matrix, the time derivative of the approximation is $\\frac{d}{dt}x_r(t) = U \\frac{d}{dt}a(t) = U \\dot{a}(t)$. The full ODE is not exactly satisfied by the approximation, leaving a residual $R(t)$:\n$$\nR(t) = U \\dot{a}(t) - A(U a(t)) - B\\big((U a(t)) \\odot (U a(t))\\big)\n$$\nThe Galerkin condition requires the residual to be orthogonal to the basis of the projection subspace. This means the Euclidean inner product of the residual with each basis vector $u_i$ must be zero:\n$$\n\\langle R(t), u_i \\rangle = u_i^T R(t) = 0 \\quad \\text{for } i=1, \\dots, r\n$$\nApplying this condition, we have:\n$$\nu_i^T \\left( U \\dot{a}(t) - A U a(t) - B\\big((U a(t)) \\odot (U a(t))\\big) \\right) = 0\n$$\nRearranging the terms gives:\n$$\nu_i^T U \\dot{a}(t) = u_i^T A U a(t) + u_i^T B\\big((U a(t)) \\odot (U a(t))\\big)\n$$\nLet's analyze each term for the $i$-th equation of the reduced system.\n\nFor the left-hand side, we use the orthonormality of the basis vectors:\n$$\nu_i^T U \\dot{a}(t) = u_i^T \\left( \\sum_{k=1}^r \\dot{a}_k(t) u_k \\right) = \\sum_{k=1}^r \\dot{a}_k(t) (u_i^T u_k) = \\sum_{k=1}^r \\dot{a}_k(t) \\delta_{ik} = \\dot{a}_i(t)\n$$\nFor the linear term on the right-hand side:\n$$\nu_i^T A U a(t) = u_i^T A \\left( \\sum_{j=1}^r a_j(t) u_j \\right) = \\sum_{j=1}^r (u_i^T A u_j) a_j(t)\n$$\nThis represents the $i$-th component of the matrix-vector product $A_r a(t)$, where the reduced linear operator is $A_r = U^T A U \\in \\mathbb{R}^{r \\times r}$.\n\nFor the nonlinear term on the right-hand side, we first expand the term inside the operator $B$:\n$$\n(Ua(t)) \\odot (Ua(t)) = \\left(\\sum_{j=1}^r a_j(t) u_j\\right) \\odot \\left(\\sum_{k=1}^r a_k(t) u_k\\right) = \\sum_{j=1}^r \\sum_{k=1}^r a_j(t) a_k(t) (u_j \\odot u_k)\n$$\nNow, we apply the linear operator $B$ and the projection $u_i^T$:\n$$\nu_i^T B\\big((U a(t)) \\odot (U a(t))\\big) = u_i^T B \\left( \\sum_{j=1}^r \\sum_{k=1}^r a_j(t) a_k(t) (u_j \\odot u_k) \\right)\n$$\nBy linearity of $B$ and the projection $u_i^T$:\n$$\nu_i^T B\\big((U a(t)) \\odot (U a(t))\\big) = \\sum_{j=1}^r \\sum_{k=1}^r \\left(u_i^T B(u_j \\odot u_k)\\right) a_j(t) a_k(t)\n$$\nCombining all terms, the $i$-th equation of the reduced system is:\n$$\n\\dot{a}_i(t) = \\sum_{j=1}^r (u_i^T A u_j) a_j(t) + \\sum_{j=1}^r \\sum_{k=1}^r \\left(u_i^T B(u_j \\odot u_k)\\right) a_j(t) a_k(t)\n$$\nThe quadratic term is governed by a third-order tensor $C \\in \\mathbb{R}^{r \\times r \\times r}$, whose entries are given by:\n$$\nC_{i,j,k} = u_i^T B(u_j \\odot u_k)\n$$\nThese tensor entries are constant and depend only on the operator $B$ and the POD basis vectors $\\{u_i\\}_{i=1}^r$. They can be precomputed in an offline stage, allowing for fast online evaluation of the reduced model.\n\n### Part (ii): Computation of the Tensor Entry $C_{1,2,3}$\n\nWe are asked to compute the specific tensor entry $C_{1,2,3}$ for $N=4$ and $r=3$, using the provided data. The formula derived in Part (i) for the tensor entries is $C_{i,j,k} = u_i^T B(u_j \\odot u_k)$. For $(i,j,k) = (1,2,3)$, this becomes:\n$$\nC_{1,2,3} = u_1^T B(u_2 \\odot u_3)\n$$\nThe provided data are:\n$$\nB = \\begin{pmatrix} 2  -1  0  0\\\\ 1  3  2  0\\\\ 0  -2  1  4\\\\ 0  0  3  -1 \\end{pmatrix}, \\quad u_1 = \\begin{pmatrix} 1\\\\ 0\\\\ 0\\\\ 0 \\end{pmatrix}, \\quad u_2 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}, \\quad u_3 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ -1\\\\ 0 \\end{pmatrix}\n$$\nFirst, we compute the Hadamard product $u_2 \\odot u_3$:\n$$\nu_2 \\odot u_3 = \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} \\right) \\odot \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0\\\\ 1\\\\ -1\\\\ 0 \\end{pmatrix} \\right) = \\frac{1}{2} \\begin{pmatrix} 0 \\cdot 0 \\\\ 1 \\cdot 1 \\\\ 1 \\cdot (-1) \\\\ 0 \\cdot 0 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix}\n$$\nLet's denote this resulting vector as $v = u_2 \\odot u_3$. Next, we apply the operator $B$ to $v$:\n$$\nB v = B (u_2 \\odot u_3) = \\begin{pmatrix} 2  -1  0  0\\\\ 1  3  2  0\\\\ 0  -2  1  4\\\\ 0  0  3  -1 \\end{pmatrix} \\left( \\frac{1}{2} \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix} \\right)\n$$\n$$\nB v = \\frac{1}{2} \\begin{pmatrix} 2(0) + (-1)(1) + 0(-1) + 0(0) \\\\ 1(0) + 3(1) + 2(-1) + 0(0) \\\\ 0(0) + (-2)(1) + 1(-1) + 4(0) \\\\ 0(0) + 0(1) + 3(-1) + (-1)(0) \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} -1 \\\\ 1 \\\\ -3 \\\\ -3 \\end{pmatrix}\n$$\nFinally, we compute the dot product of this result with $u_1^T$:\n$$\nC_{1,2,3} = u_1^T (B v) = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} \\left( \\frac{1}{2} \\begin{pmatrix} -1 \\\\ 1 \\\\ -3 \\\\ -3 \\end{pmatrix} \\right)\n$$\nThis operation simply extracts the first component of the vector $Bv$:\n$$\nC_{1,2,3} = \\frac{1}{2} \\times (-1) = -\\frac{1}{2}\n$$\nThus, the value of the specified tensor entry is $-\\frac{1}{2}$.",
            "answer": "$$\\boxed{-\\frac{1}{2}}$$"
        },
        {
            "introduction": "Having witnessed the power and efficiency of POD-Galerkin models, it is equally important to understand their limitations and potential failure modes. Model reduction is not a magic bullet, and a naive application can lead to qualitatively incorrect results. This compelling thought experiment  explores a simple, energy-conserving oscillatory system where a one-dimensional Galerkin projection fails dramatically, predicting static behavior instead of persistent rotation. This cautionary example underscores the critical importance of ensuring the chosen POD basis is rich enough to capture the fundamental physics of the system.",
            "id": "2432084",
            "problem": "Consider a two-dimensional linear Ordinary Differential Equation (ODE) of the form $\\dot{\\boldsymbol{x}}(t) = A \\boldsymbol{x}(t)$ with $A \\in \\mathbb{R}^{2 \\times 2}$ and the standard Euclidean inner product on $\\mathbb{R}^{2}$. Let $A$ be the skew-symmetric matrix\n$$\nA \\;=\\; \\begin{pmatrix} 0  -\\omega \\\\ \\omega  0 \\end{pmatrix},\n$$\nwhere $\\omega  0$ is a fixed real constant. Suppose we collect a continuous-time snapshot ensemble by evolving the system from the initial condition $\\boldsymbol{x}(0) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ over the time interval $[0,\\, 2\\pi/\\omega]$ with uniform time weighting, and we build a one-dimensional basis using Proper Orthogonal Decomposition (POD), defined as the dominant eigenvector of the snapshot correlation operator computed with the Euclidean inner product.\n\nUsing only fundamental definitions of Proper Orthogonal Decomposition (POD) and Galerkin projection, and the standard properties of linear time-invariant systems, derive the one-dimensional Galerkin-reduced model $\\dot{a}(t) = a_r\\, a(t)$ obtained by projecting the full system onto the one-dimensional POD subspace. Then, compute the scalar coefficient $a_r$ as an explicit real number.\n\nYour final answer must be the value of $a_r$. No rounding is required, and no units are needed. Express the final answer as a single real number.",
            "solution": "The objective is to find the scalar coefficient $a_r$ in the one-dimensional reduced-order model $\\dot{a}(t) = a_r a(t)$. This model is obtained by a Galerkin projection of the full system $\\dot{\\boldsymbol{x}} = A \\boldsymbol{x}$ onto a one-dimensional POD basis.\n\nLet the one-dimensional POD basis be denoted by the vector $\\boldsymbol{\\phi} \\in \\mathbb{R}^{2}$. By definition, POD basis vectors are orthonormal, so we have $\\boldsymbol{\\phi}^T \\boldsymbol{\\phi} = 1$.\n\nThe reduced-order model (ROM) seeks an approximation of the state $\\boldsymbol{x}(t)$ in the form $\\boldsymbol{\\hat{x}}(t) = a(t) \\boldsymbol{\\phi}$, where $a(t)$ is the time-varying coordinate in the reduced basis.\n\nThe Galerkin projection method requires the residual of the ODE, when evaluated with the approximation $\\boldsymbol{\\hat{x}}(t)$, to be orthogonal to the basis vector $\\boldsymbol{\\phi}$. The residual is $R(t) = \\dot{\\boldsymbol{\\hat{x}}}(t) - A \\boldsymbol{\\hat{x}}(t)$.\n\nThe orthogonality condition is expressed using the Euclidean inner product:\n$$\n\\boldsymbol{\\phi}^T R(t) = 0\n$$\nSubstituting the expressions for $\\boldsymbol{\\hat{x}}(t)$ and its time derivative $\\dot{\\boldsymbol{\\hat{x}}}(t) = \\dot{a}(t) \\boldsymbol{\\phi}$:\n$$\n\\boldsymbol{\\phi}^T (\\dot{a}(t) \\boldsymbol{\\phi} - A (a(t) \\boldsymbol{\\phi})) = 0\n$$\nBy linearity of the inner product and factoring out the scalar coefficients $\\dot{a}(t)$ and $a(t)$:\n$$\n\\dot{a}(t) (\\boldsymbol{\\phi}^T \\boldsymbol{\\phi}) - a(t) (\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi}) = 0\n$$\nGiven that the basis vector $\\boldsymbol{\\phi}$ is normalized, $\\boldsymbol{\\phi}^T \\boldsymbol{\\phi} = 1$. The equation simplifies to:\n$$\n\\dot{a}(t) = (\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi}) a(t)\n$$\nThis is the one-dimensional Galerkin-reduced model. By comparing this to the required form $\\dot{a}(t) = a_r a(t)$, we identify the coefficient $a_r$ as the Rayleigh quotient of the matrix $A$ with respect to the vector $\\boldsymbol{\\phi}$:\n$$\na_r = \\boldsymbol{\\phi}^T A \\boldsymbol{\\phi}\n$$\nWe can determine the value of $a_r$ by exploiting the properties of the matrix $A$, without needing to explicitly compute the POD basis vector $\\boldsymbol{\\phi}$. The problem states that $A$ is a skew-symmetric matrix. By definition, a matrix is skew-symmetric if its transpose is equal to its negative, i.e., $A^T = -A$.\n\nLet us consider the transpose of the scalar $a_r$. As a scalar, $a_r$ is equal to its own transpose: $a_r^T = a_r$.\nNow, let's compute the transpose of the expression for $a_r$:\n$$\na_r^T = (\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi})^T = \\boldsymbol{\\phi}^T A^T (\\boldsymbol{\\phi}^T)^T = \\boldsymbol{\\phi}^T A^T \\boldsymbol{\\phi}\n$$\nUsing the skew-symmetric property, $A^T = -A$:\n$$\na_r^T = \\boldsymbol{\\phi}^T (-A) \\boldsymbol{\\phi} = -(\\boldsymbol{\\phi}^T A \\boldsymbol{\\phi}) = -a_r\n$$\nWe have thus established two facts: $a_r = a_r^T$ and $a_r^T = -a_r$. Combining these gives:\n$$\na_r = -a_r\n$$\nThis equation implies $2 a_r = 0$, which has the unique real solution:\n$$\na_r = 0\n$$\nThis result is general for any one-dimensional Galerkin projection of a linear system governed by a real skew-symmetric matrix. It is independent of the specific basis vector $\\boldsymbol{\\phi}$ used for the projection. The reduced model is $\\dot{a}(t) = 0$, which correctly captures the energy-conserving nature of the full system, as the reduced \"energy\" $\\frac{1}{2}a(t)^2$ is constant. The degeneracy of the POD problem for this specific circular trajectory (where the correlation matrix is proportional to the identity matrix, and any vector is an eigenvector) does not affect the final result.",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}