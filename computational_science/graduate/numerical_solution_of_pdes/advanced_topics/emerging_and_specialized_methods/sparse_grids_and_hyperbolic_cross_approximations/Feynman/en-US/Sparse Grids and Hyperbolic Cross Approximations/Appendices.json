{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in understanding any approximation method is to characterize the space of functions it can represent. This exercise provides a foundational link between the abstract definition of a hyperbolic cross space and the more familiar total-degree polynomial spaces. By determining the precise conditions under which one space contains the other, you will gain a deeper intuition for the structure and capacity of hyperbolic cross approximations .",
            "id": "3445907",
            "problem": "Consider the tensor-product Chebyshev polynomial basis on the hypercube $[-1,1]^{d}$, where $d \\in \\mathbb{N}$ is fixed. For $k \\in \\mathbb{N}_{0}$, let $T_{k}(x)$ denote the $k$-th Chebyshev polynomial of the first kind in one variable, and consider the multivariate basis elements $\\prod_{i=1}^{d} T_{k_{i}}(x_{i})$ indexed by multi-indices $k=(k_{1},\\dots,k_{d}) \\in \\mathbb{N}_{0}^{d}$. For $N \\in \\mathbb{N}$, define the hyperbolic cross index set\n$$\n\\mathcal{H}_{N} \\,=\\, \\left\\{ k \\in \\mathbb{N}_{0}^{d} \\;:\\; \\prod_{i=1}^{d} (k_{i}+1) \\leq N \\right\\},\n$$\nand the associated hyperbolic cross polynomial space\n$$\nV_{N} \\,=\\, \\operatorname{span}\\left\\{\\prod_{i=1}^{d} T_{k_{i}}(x_{i}) \\;:\\; k \\in \\mathcal{H}_{N}\\right\\}.\n$$\nLet $\\mathbb{P}_{p}^{(d)}$ denote the total-degree polynomial space of all $d$-variate polynomials spanned by monomials $x^{\\alpha}=\\prod_{i=1}^{d} x_{i}^{\\alpha_{i}}$ with multi-indices $\\alpha \\in \\mathbb{N}_{0}^{d}$ satisfying $|\\alpha|_{1}=\\sum_{i=1}^{d} \\alpha_{i} \\leq p$, where $p \\in \\mathbb{N}_{0}$ is given.\n\nUsing only fundamental definitions about the hyperbolic cross, the fact that $T_{k}(x)$ is a polynomial of degree $k$, and that for each $n \\in \\mathbb{N}_{0}$ the set $\\{T_{0},\\dots,T_{n}\\}$ spans the univariate polynomial space of degree at most $n$, determine the minimal integer $N_{\\min}(d,p)$ such that $V_{N}$ contains $\\mathbb{P}_{p}^{(d)}$ whenever $N \\geq N_{\\min}(d,p)$.\n\nYour final answer must be a single closed-form analytic expression in terms of $d$ and $p$. No numerical rounding is required.",
            "solution": "The user wants me to solve a problem about hyperbolic cross approximations.\n\nThe problem asks for the minimal integer $N_{\\min}(d,p)$ such that the hyperbolic cross polynomial space $V_N$ contains the total-degree polynomial space $\\mathbb{P}_p^{(d)}$ for all $N \\geq N_{\\min}(d,p)$.\n\nThe first step is to establish the relationship between the two polynomial spaces, $\\mathbb{P}_p^{(d)}$ and $V_N$. The space $\\mathbb{P}_p^{(d)}$ is defined as the span of all monomials $x^{\\alpha}$ where the sum of the degrees $|\\alpha|_1 = \\sum_{i=1}^d \\alpha_i$ is at most $p$. The space $V_N$ is defined as the span of a set of tensor-product Chebyshev polynomials. To compare these spaces, we must express them in a common basis. The tensor-product Chebyshev basis is the natural choice.\n\nA multivariate polynomial $P(x_1, \\dots, x_d)$ is said to have total degree $p$ if it is a linear combination of monomials $x^\\alpha$ with $|\\alpha|_1 \\le p$, and at least one monomial with $|\\alpha|_1=p$ has a non-zero coefficient. The space $\\mathbb{P}_p^{(d)}$ is the set of all polynomials with total degree at most $p$.\n\nThe problem states that for a single variable, the set of Chebyshev polynomials $\\{T_0(x), \\dots, T_n(x)\\}$ spans the space of polynomials of degree at most $n$. A tensor-product Chebyshev basis function $\\prod_{i=1}^d T_{k_i}(x_i)$ is itself a polynomial. Since each $T_{k_i}(x_i)$ is a polynomial of degree $k_i$, the product $\\prod_{i=1}^d T_{k_i}(x_i)$ is a polynomial of total degree $\\sum_{i=1}^d k_i = |k|_1$.\n\nThis implies that any polynomial in the span of $\\{\\prod_{i=1}^d T_{k_i}(x_i) : |k|_1 \\le p\\}$ must belong to $\\mathbb{P}_p^{(d)}$. Conversely, any polynomial of total degree at most $p$ can be written as a unique linear combination of tensor-product Chebyshev polynomials with total degree at most $p$. Therefore, the space $\\mathbb{P}_p^{(d)}$ is equivalently spanned by the set of Chebyshev basis functions whose multi-indices $k$ satisfy $|k|_1 \\le p$.\nLet us define the total-degree index set:\n$$\n\\mathcal{T}_{p} \\,=\\, \\left\\{ k \\in \\mathbb{N}_{0}^{d} \\;:\\; \\sum_{i=1}^{d} k_{i} \\leq p \\right\\}.\n$$\nThen, we can write $\\mathbb{P}_{p}^{(d)}$ as:\n$$\n\\mathbb{P}_{p}^{(d)} \\,=\\, \\operatorname{span}\\left\\{\\prod_{i=1}^{d} T_{k_{i}}(x_{i}) \\;:\\; k \\in \\mathcal{T}_{p}\\right\\}.\n$$\nThe hyperbolic cross space is given by:\n$$\nV_{N} \\,=\\, \\operatorname{span}\\left\\{\\prod_{i=1}^{d} T_{k_{i}}(x_{i}) \\;:\\; k \\in \\mathcal{H}_{N}\\right\\},\n$$\nwhere $\\mathcal{H}_{N} = \\{ k \\in \\mathbb{N}_{0}^{d} : \\prod_{i=1}^{d} (k_{i}+1) \\leq N \\}$.\n\nThe condition that $V_N$ contains $\\mathbb{P}_p^{(d)}$ is equivalent to requiring that the set of basis functions for $\\mathbb{P}_p^{(d)}$ is a subset of the basis functions for $V_N$. This translates to an inclusion of the corresponding index sets:\n$$\n\\mathcal{T}_{p} \\subseteq \\mathcal{H}_{N}.\n$$\nThis inclusion must hold for the minimal $N_{\\min}(d,p)$ and all $N \\ge N_{\\min}(d,p)$. The condition $\\mathcal{T}_{p} \\subseteq \\mathcal{H}_{N}$ means that for every multi-index $k \\in \\mathcal{T}_{p}$, it must also be in $\\mathcal{H}_{N}$. That is, for every $k=(k_1, \\dots, k_d) \\in \\mathbb{N}_0^d$ such that $\\sum_{i=1}^d k_i \\le p$, the inequality $\\prod_{i=1}^d (k_i+1) \\le N$ must be satisfied.\n\nTo ensure this holds for all $k \\in \\mathcal{T}_p$, the value of $N$ must be at least as large as the maximum value that the product $\\prod_{i=1}^d (k_i+1)$ can take for any $k \\in \\mathcal{T}_p$. The minimal integer $N$ for which this is true is precisely this maximum value.\nTherefore, we must find:\n$$\nN_{\\min}(d,p) = \\max_{k \\in \\mathcal{T}_{p}} \\left\\{ \\prod_{i=1}^{d} (k_{i}+1) \\right\\} = \\max_{\\substack{k_1,\\dots,k_d \\ge 0 \\\\ \\sum_{i=1}^d k_i \\le p \\\\ k_i \\in \\mathbb{N}_0}} \\prod_{i=1}^{d} (k_{i}+1).\n$$\nTo solve this optimization problem, we introduce new integer variables $j_i = k_i+1$. Since $k_i \\ge 0$, we have $j_i \\ge 1$. The objective function becomes $\\prod_{i=1}^d j_i$. The constraint $\\sum_{i=1}^d k_i \\le p$ becomes $\\sum_{i=1}^d (j_i-1) \\le p$, which simplifies to $\\sum_{i=1}^d j_i \\le p+d$.\n\nThe problem is now to maximize the product $\\prod_{i=1}^d j_i$ subject to $\\sum_{i=1}^d j_i \\le p+d$ and $j_i \\in \\{1, 2, 3, \\ldots\\}$. Since each $j_i \\ge 1$, the product is a strictly increasing function of each $j_i$. Thus, the maximum product will be achieved when the sum $\\sum_{i=1}^d j_i$ is maximized, i.e., when $\\sum_{i=1}^d j_i = p+d$.\n\nWe now need to find positive integers $j_1, \\dots, j_d$ that sum to a constant $S = p+d$ and whose product is maximized. A well-known result, stemming from the AM-GM inequality, is that for a fixed sum, the product is maximized when the numbers are as close to each other as possible.\nLet $S = p+d$. We perform integer division of $S$ by $d$:\n$$\np+d = q \\cdot d + r,\n$$\nwhere $q = \\lfloor \\frac{p+d}{d} \\rfloor$ is the quotient and $r = (p+d) \\pmod d$ is the remainder, with $0 \\le r < d$.\nTo make the integers $j_i$ as equal as possible, we must choose $r$ of them to be $q+1$ and the remaining $d-r$ of them to be $q$. The sum is $r(q+1) + (d-r)q = rq + r + dq - rq = dq+r = p+d$, which satisfies the constraint.\n\nThe maximum value of the product is therefore:\n$$\nN_{\\min}(d,p) = (q+1)^r q^{d-r}.\n$$\nWe can express $q$ and $r$ in terms of $p$ and $d$. Let $q_p = \\lfloor p/d \\rfloor$ and $r_p = p \\pmod d$. We have $p = q_p d + r_p$.\nThen $p+d = (q_p d + r_p) + d = (q_p+1) d + r_p$.\nComparing this with $p+d=qd+r$, we can identify $q = q_p+1$ and $r=r_p$.\nSubstituting these into the expression for the maximum product:\n$$\nN_{\\min}(d,p) = ((q_p+1)+1)^{r_p} (q_p+1)^{d-r_p} = (q_p+2)^{r_p} (q_p+1)^{d-r_p}.\n$$\nReplacing $q_p$ and $r_p$ with their definitions in terms of $p$ and $d$, we obtain the final closed-form expression:\n$$\nN_{\\min}(d,p) = \\left(\\lfloor \\frac{p}{d} \\rfloor + 2\\right)^{p \\pmod d} \\left(\\lfloor \\frac{p}{d} \\rfloor + 1\\right)^{d - (p \\pmod d)}.\n$$\nHere, $p \\pmod d$ denotes the remainder of the integer division of $p$ by $d$, which is an integer in $\\{0, 1, \\dots, d-1\\}$.",
            "answer": "$$\\boxed{\\left(\\left\\lfloor \\frac{p}{d} \\right\\rfloor + 2\\right)^{p \\pmod d} \\left(\\left\\lfloor \\frac{p}{d} \\right\\rfloor + 1\\right)^{d - (p \\pmod d)}}$$"
        },
        {
            "introduction": "The primary motivation for employing sparse grids and hyperbolic cross approximations is to overcome the \"curse of dimensionality\" that plagues methods based on full tensor products. This practice offers a powerful theoretical illustration of this advantage by analyzing a function with mixed Sobolev regularity, a class of functions that is common in high-dimensional applications. You will derive and compare the convergence rates of isotropic and hyperbolic cross schemes, quantitatively demonstrating why the latter is far more efficient for this problem class .",
            "id": "3445927",
            "problem": "Consider the $d$-dimensional flat torus $\\mathbb{T}^{d} = [0,1]^{d}$ with periodic boundary conditions, where $d \\ge 2$. Let $r > 0$ and define a one-dimensional periodic function $g : \\mathbb{T}^{1} \\to \\mathbb{C}$ by its Fourier series\n$$\ng(x) = \\sum_{k \\in \\mathbb{Z}} a_{k} \\,\\exp(2\\pi i k x), \\qquad a_{k} := (1+|k|)^{-(r+1)}.\n$$\nDefine the $d$-variate function $f : \\mathbb{T}^{d} \\to \\mathbb{C}$ by the tensor product\n$$\nf(x_{1},\\dots,x_{d}) := \\prod_{i=1}^{d} g(x_{i}).\n$$\nYou may take as known the Fourier–Sobolev characterization: a periodic function $h$ lies in the Sobolev space $H^{s}(\\mathbb{T}^{m})$ if and only if its Fourier coefficients $\\widehat{h}(k)$ satisfy $\\sum_{k \\in \\mathbb{Z}^{m}} (1+|k|^{2})^{s} |\\widehat{h}(k)|^{2} < \\infty$, and the $L^{2}(\\mathbb{T}^{m})$-orthogonal projection error onto a set of Fourier modes equals the square root of the sum of squared omitted Fourier coefficients.\n\nFor $N \\in \\mathbb{N}$, define the isotropic truncation index set\n$$\nK_{N} := \\{ k \\in \\mathbb{Z}^{d} : \\max_{1 \\le i \\le d} |k_{i}| \\le N \\},\n$$\nand for $T \\ge \\mathrm{e}$ define the hyperbolic cross index set\n$$\nH_{T} := \\left\\{ k \\in \\mathbb{Z}^{d} : \\prod_{i=1}^{d} (1+|k_{i}|) \\le T \\right\\}.\n$$\nLet $\\Pi_{S} f$ denote the $L^{2}(\\mathbb{T}^{d})$-orthogonal projection of $f$ onto the span of Fourier modes with indices in a finite set $S \\subset \\mathbb{Z}^{d}$. For a budget of $M$ Fourier modes, define the isotropic error $E_{\\mathrm{iso}}(M)$ and hyperbolic cross error $E_{\\mathrm{hc}}(M)$ by choosing $N$ and $T$ so that $\\# K_{N} \\asymp M$ and $\\# H_{T} \\asymp M$, respectively, and setting\n$$\nE_{\\mathrm{iso}}(M) := \\| f - \\Pi_{K_{N}} f \\|_{L^{2}(\\mathbb{T}^{d})}, \n\\qquad\nE_{\\mathrm{hc}}(M) := \\| f - \\Pi_{H_{T}} f \\|_{L^{2}(\\mathbb{T}^{d})}.\n$$\nStarting from the Fourier characterization of Sobolev spaces and volume-comparison estimates for lattice-point counts and series tails based on integral tests, derive the algebraic decay exponents\n$$\n\\alpha_{\\mathrm{iso}}(d,r) := \\lim_{M \\to \\infty} \\frac{- \\ln E_{\\mathrm{iso}}(M)}{\\ln M},\n\\qquad\n\\alpha_{\\mathrm{hc}}(d,r) := \\lim_{M \\to \\infty} \\frac{- \\ln E_{\\mathrm{hc}}(M)}{\\ln M},\n$$\nand hence determine the simplified symbolic expression for the ratio\n$$\n\\frac{\\alpha_{\\mathrm{iso}}(d,r)}{\\alpha_{\\mathrm{hc}}(d,r)}.\n$$\nYour final answer must be this ratio as a single closed-form expression in terms of $d$ only. No numerical rounding is required.",
            "solution": "The user wants me to solve the problem by following a strict procedure. I have to first validate the problem statement, and if it's valid, provide a complete, reasoned solution.\n\n### Step 1: Extract Givens\n-   **Domain:** $d$-dimensional flat torus $\\mathbb{T}^{d} = [0,1]^{d}$, $d \\ge 2$.\n-   **1D Function:** $g : \\mathbb{T}^{1} \\to \\mathbb{C}$ given by $g(x) = \\sum_{k \\in \\mathbb{Z}} a_{k} \\,\\exp(2\\pi i k x)$.\n-   **1D Fourier Coefficients:** $a_{k} := (1+|k|)^{-(r+1)}$ for $r > 0$.\n-   **d-variate Function:** $f : \\mathbb{T}^{d} \\to \\mathbb{C}$ given by the tensor product $f(x_{1},\\dots,x_{d}) := \\prod_{i=1}^{d} g(x_{i})$.\n-   **Sobolev Space Characterization:** A function $h \\in H^{s}(\\mathbb{T}^{m})$ if and only if its Fourier coefficients $\\widehat{h}(k)$ satisfy $\\sum_{k \\in \\mathbb{Z}^{m}} (1+|k|^{2})^{s} |\\widehat{h}(k)|^{2} < \\infty$.\n-   **Projection Error:** The $L^{2}(\\mathbb{T}^{m})$-orthogonal projection error onto a set of Fourier modes $S$ is $\\|h - \\Pi_{S} h \\|_{L^{2}} = \\left( \\sum_{k \\in \\mathbb{Z}^{m} \\setminus S} |\\widehat{h}(k)|^{2} \\right)^{1/2}$.\n-   **Isotropic Index Set:** $K_{N} := \\{ k \\in \\mathbb{Z}^{d} : \\max_{1 \\le i \\le d} |k_{i}| \\le N \\}$, for $N \\in \\mathbb{N}$.\n-   **Hyperbolic Cross Index Set:** $H_{T} := \\{ k \\in \\mathbb{Z}^{d} : \\prod_{i=1}^{d} (1+|k_{i}|) \\le T \\}$, for $T \\ge \\mathrm{e}$.\n-   **Approximation Errors:** $E_{\\mathrm{iso}}(M) := \\| f - \\Pi_{K_{N}} f \\|_{L^{2}(\\mathbb{T}^{d})}$ with $\\# K_{N} \\asymp M$, and $E_{\\mathrm{hc}}(M) := \\| f - \\Pi_{H_{T}} f \\|_{L^{2}(\\mathbb{T}^{d})}$ with $\\# H_{T} \\asymp M$.\n-   **Decay Exponents:** $\\alpha_{\\mathrm{iso}}(d,r) := \\lim_{M \\to \\infty} \\frac{- \\ln E_{\\mathrm{iso}}(M)}{\\ln M}$ and $\\alpha_{\\mathrm{hc}}(d,r) := \\lim_{M \\to \\infty} \\frac{- \\ln E_{\\mathrm{hc}}(M)}{\\ln M}$.\n-   **Objective:** Derive the symbolic expression for the ratio $\\frac{\\alpha_{\\mathrm{iso}}(d,r)}{\\alpha_{\\mathrm{hc}}(d,r)}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is analyzed against the validation criteria.\n-   **Scientifically Grounded:** The problem is a standard exercise in high-dimensional approximation theory, a subfield of numerical analysis. All concepts, including Sobolev spaces, Fourier series, tensor-product functions, and approximation via isotropic and hyperbolic cross index sets, are well-established mathematical constructs.\n-   **Well-Posed:** The problem is clearly stated with precise mathematical definitions. It asks for the derivation of well-defined asymptotic convergence rates and their ratio, for which a unique solution exists.\n-   **Objective:** The problem statement is written in formal, unambiguous mathematical language.\n-   **Soundness, Completeness, Consistency:** The premises are mathematically sound. The definition of the function `f` via its Fourier coefficients is consistent with the framework of Sobolev spaces. The provided definitions and conditions are sufficient for solving the problem. The conditions $d \\ge 2$, $r>0$, and $T \\ge \\mathrm{e}$ are appropriate and do not introduce contradictions.\n-   **Relevance:** The problem is directly on-topic for the analysis of sparse grids and hyperbolic cross approximations, which are central to the numerical solution of high-dimensional PDEs.\n-   **No Other Flaws:** The problem is not trivial, metaphorical, or unfalsifiable. It requires a rigorous mathematical derivation.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A full solution will be provided.\n\n### Solution\nThe solution proceeds by first determining the Fourier coefficients of the function $f$, then analyzing its smoothness in both the isotropic and mixed Sobolev sense. These smoothness properties directly dictate the convergence rates of the two approximation schemes, from which we can find the desired exponents $\\alpha_{\\mathrm{iso}}$ and $\\alpha_{\\mathrm{hc}}$.\n\n**1. Fourier Coefficients of the Tensor-Product Function**\nThe function $f(x)$ is defined as a tensor product of $d$ identical one-dimensional functions $g(x_i)$. The Fourier coefficient $\\widehat{f}(k)$ for $k = (k_1, \\dots, k_d) \\in \\mathbb{Z}^d$ is the product of the corresponding one-dimensional Fourier coefficients:\n$$\n\\widehat{f}(k) = \\int_{\\mathbb{T}^d} f(x) \\exp(-2\\pi i k \\cdot x) \\,dx = \\int_{[0,1]^d} \\left(\\prod_{j=1}^d g(x_j)\\right) \\left(\\prod_{j=1}^d \\exp(-2\\pi i k_j x_j)\\right) \\,dx_1 \\dots dx_d\n$$\n$$\n= \\prod_{j=1}^d \\left( \\int_0^1 g(x_j) \\exp(-2\\pi i k_j x_j) \\,dx_j \\right) = \\prod_{j=1}^d \\widehat{g}(k_j)\n$$\nGiven that $\\widehat{g}(k_j) = a_{k_j} = (1+|k_j|)^{-(r+1)}$, the Fourier coefficients of $f$ are:\n$$\n\\widehat{f}(k) = \\prod_{j=1}^d (1+|k_j|)^{-(r+1)}.\n$$\n\n**2. Isotropic Approximation Rate**\nThe convergence rate of the isotropic truncation scheme is determined by the isotropic Sobolev regularity of $f$. A function $f$ belongs to the Sobolev space $H^s(\\mathbb{T}^d)$ if its $H^s$-norm is finite, which, according to the provided characterization, means:\n$$\n\\|f\\|_{H^s}^2 = \\sum_{k \\in \\mathbb{Z}^d} (1+|k|^2)^s |\\widehat{f}(k)|^2 < \\infty,\n$$\nwhere $|k|^2 = \\sum_{j=1}^d k_j^2$. Substituting the expression for $|\\widehat{f}(k)|^2$:\n$$\n\\|f\\|_{H^s}^2 = \\sum_{k \\in \\mathbb{Z}^d} (1+\\sum_{j=1}^d k_j^2)^s \\prod_{j=1}^d (1+|k_j|)^{-2(r+1)}.\n$$\nTo determine the maximum value of $s$ for which this series converges, we analyze its asymptotic behavior. The convergence is limited by the slowest decay of the terms, which occurs along the coordinate axes. For instance, let's consider the axis where $k = (k_1, 0, \\dots, 0)$ with $|k_1| \\to \\infty$. The general term of the series for these indices behaves as:\n$$\n(1+k_1^2)^s (1+|k_1|)^{-2(r+1)} \\cdot \\prod_{j=2}^d (1+0)^{-2(r+1)} \\asymp |k_1|^{2s} |k_1|^{-2(r+1)} = |k_1|^{2s - 2(r+1)}.\n$$\nThe sum over $k_1 \\in \\mathbb{Z}$ converges if and only if the exponent is less than $-1$. This is a one-dimensional p-series test.\n$$\n2s - 2(r+1) < -1 \\implies 2s < 2r+1 \\implies s < r + \\frac{1}{2}.\n$$\nThus, $f \\in H^s(\\mathbb{T}^d)$ for all $s < r+1/2$. The limiting Sobolev regularity is $s_{\\mathrm{eff}} = r+1/2$.\n\nFor an isotropic approximation scheme using a set $K_N$, the number of basis functions (degrees of freedom) is $M = \\#K_N = (2N+1)^d \\asymp N^d$. This implies $N \\asymp M^{1/d}$. The standard result for $L^2$ approximation error from $H^s$ is $\\|f - \\Pi_{K_N}f\\|_{L^2} \\asymp N^{-s}$. Combining these, we find the error in terms of $M$:\n$$\nE_{\\mathrm{iso}}(M) \\asymp N^{-s_{\\mathrm{eff}}} \\asymp (M^{1/d})^{-s_{\\mathrm{eff}}} = M^{-s_{\\mathrm{eff}}/d}.\n$$\nSubstituting $s_{\\mathrm{eff}} = r+1/2$, the asymptotic error is:\n$$\nE_{\\mathrm{iso}}(M) \\asymp M^{-(r+1/2)/d}.\n$$\nFrom the definition of $\\alpha_{\\mathrm{iso}}$, if $E(M) \\asymp M^{-\\alpha}$, then $\\alpha = \\lim_{M \\to \\infty} \\frac{-\\ln(C M^{-\\alpha})}{\\ln M} = \\alpha$. Thus,\n$$\n\\alpha_{\\mathrm{iso}}(d,r) = \\frac{r+1/2}{d}.\n$$\n\n**3. Hyperbolic Cross Approximation Rate**\nThe convergence rate of the hyperbolic cross scheme is determined by the mixed Sobolev regularity of $f$. The space of functions with square-integrable mixed derivatives of order $s$, denoted $H^s_{\\mathrm{mix}}(\\mathbb{T}^d)$, is characterized by the convergence of the sum:\n$$\n\\sum_{k \\in \\mathbb{Z}^d} \\left(\\prod_{j=1}^d (1+k_j^2)^s\\right) |\\widehat{f}(k)|^2 < \\infty.\n$$\nSubstituting $|\\widehat{f}(k)|^2$ and using the asymptotic equivalence $(1+k_j^2) \\asymp (1+|k_j|)^2$ for large $|k_j|$, the condition becomes:\n$$\n\\sum_{k \\in \\mathbb{Z}^d} \\prod_{j=1}^d (1+|k_j|)^{2s} (1+|k_j|)^{-2(r+1)} < \\infty\n$$\n$$\n\\sum_{k \\in \\mathbb{Z}^d} \\prod_{j=1}^d (1+|k_j|)^{2(s-r-1)} < \\infty.\n$$\nThis sum is separable:\n$$\n\\left( \\sum_{m \\in \\mathbb{Z}} (1+|m|)^{2(s-r-1)} \\right)^d < \\infty.\n$$\nThe entire expression is finite if and only if the one-dimensional sum converges. Again, by the p-series test, this requires the exponent to be less than $-1$:\n$$\n2(s-r-1) < -1 \\implies 2s - 2r - 2 < -1 \\implies 2s < 2r+1 \\implies s < r + \\frac{1}{2}.\n$$\nThus, $f$ possesses a limiting mixed Sobolev regularity of $s_{\\mathrm{mix}} = r+1/2$.\n\nFor hyperbolic cross approximation, the number of basis functions is $M = \\#H_T \\asymp T (\\ln T)^{d-1}$. The standard result for the $L^2$ error of approximating a function in $H^s_{\\mathrm{mix}}(\\mathbb{T}^d)$ is $E_{\\mathrm{hc}}(M) \\asymp M^{-s}$ up to logarithmic factors. That is, $E_{\\mathrm{hc}}(M) \\asymp M^{-s_{\\mathrm{mix}}} (\\ln M)^{\\beta}$ for some power $\\beta$.\nThe algebraic decay exponent $\\alpha_{\\mathrm{hc}}$ is determined by the main power of $M$:\n$$\n\\alpha_{\\mathrm{hc}}(d,r) = \\lim_{M \\to \\infty} \\frac{-\\ln(C M^{-s_{\\mathrm{mix}}} (\\ln M)^{\\beta})}{\\ln M} = \\lim_{M \\to \\infty} \\frac{s_{\\mathrm{mix}}\\ln M - \\beta\\ln(\\ln M) - \\ln C}{\\ln M} = s_{\\mathrm{mix}}.\n$$\nSubstituting $s_{\\mathrm{mix}} = r+1/2$:\n$$\n\\alpha_{\\mathrm{hc}}(d,r) = r + \\frac{1}{2}.\n$$\nThis rate is independent of the dimension $d$, which is the key advantage of hyperbolic cross/sparse grid methods for this class of functions.\n\n**4. Ratio of the Decay Exponents**\nFinally, we compute the ratio of the two exponents. The parameter $r$, related to the function's smoothness, will cancel.\n$$\n\\frac{\\alpha_{\\mathrm{iso}}(d,r)}{\\alpha_{\\mathrm{hc}}(d,r)} = \\frac{(r+1/2)/d}{r+1/2}.\n$$\nSince $r>0$, the term $r+1/2$ is strictly positive, so we can cancel it from the numerator and denominator:\n$$\n\\frac{\\alpha_{\\mathrm{iso}}(d,r)}{\\alpha_{\\mathrm{hc}}(d,r)} = \\frac{1}{d}.\n$$\nThis result quantifies the \"curse of dimensionality\" affecting the isotropic approximation scheme, whose convergence rate deteriorates as $1/d$, compared to the dimension-independent rate of the hyperbolic cross scheme for this tensor-product function.",
            "answer": "$$\n\\boxed{\\frac{1}{d}}\n$$"
        },
        {
            "introduction": "Beyond the theoretical convergence rates, the practical utility of a numerical method depends on its stability. This exercise delves into a critical aspect of implementing sparse grid quadrature via the Smolyak algorithm: the potential for negative quadrature weights, which can lead to numerical instability. By analyzing how the choice of simple one-dimensional Newton-Cotes rules affects the weights of the resulting two-dimensional Smolyak rule, you will develop an appreciation for the subtle yet vital details of stable algorithm construction .",
            "id": "3445937",
            "problem": "Consider the numerical approximation of bilinear forms arising in the weak formulation of a Partial Differential Equation (PDE) on the unit square. Let the goal be to approximate integrals over $[0,1]^{2}$ by a two-dimensional Smolyak quadrature constructed from one-dimensional rules. The Smolyak construction uses hierarchical increments built from a family of one-dimensional linear functionals $\\{Q_{\\ell}\\}_{\\ell \\geq 1}$ on $C([0,1])$.\n\nAssume the following one-dimensional family is used:\n- Level $\\ell = 1$ is the closed Newton–Cotes (NC) trapezoidal rule, denoted $Q_{1}$, with nodes $\\{0,1\\}$ and weights $\\{ \\tfrac{1}{2}, \\tfrac{1}{2} \\}$.\n- Level $\\ell = 2$ is chosen from a one-parameter family of closed, equispaced, three-node formulas, denoted $Q_{2}^{\\alpha}$, with nodes $\\{0,\\tfrac{1}{2},1\\}$ and symmetric weights $\\{\\tfrac{\\alpha}{2}, 1-\\alpha, \\tfrac{\\alpha}{2}\\}$ for a parameter $\\alpha \\in (0,1]$. This family preserves exactness for constants and linear functions and includes Simpson’s rule at $\\alpha = \\tfrac{1}{3}$.\n\nDefine hierarchical increments $\\Delta Q_{1} := Q_{1}$ and $\\Delta Q_{2} := Q_{2}^{\\alpha} - Q_{1}$. The two-dimensional Smolyak quadrature of level $L=2$ is built from these increments as\n$$\nA(2,2) \\;=\\; \\sum_{|\\boldsymbol{\\ell}|_{1} \\leq L + d - 1} \\;\\bigotimes_{j=1}^{2} \\Delta Q_{\\ell_{j}} \\;=\\; \\Delta Q_{1} \\otimes \\Delta Q_{1} \\;+\\; \\Delta Q_{1} \\otimes \\Delta Q_{2} \\;+\\; \\Delta Q_{2} \\otimes \\Delta Q_{1},\n$$\nwhere $d=2$ and $|\\boldsymbol{\\ell}|_{1} = \\ell_{1} + \\ell_{2}$.\n\nNegative quadrature weights in $A(2,2)$ are known to degrade stability and can impair convergence in sparse-grid discretizations of PDE operators. Determine, in closed form, the minimal value of $\\alpha$ for which every weight of the two-dimensional Smolyak rule $A(2,2)$ constructed above is nonnegative on its full node set. Provide your final answer as a single exact number (no units).",
            "solution": "The user wants to find the minimal value of a parameter $\\alpha$ that ensures all quadrature weights of a specific two-dimensional Smolyak rule are non-negative.\n\n### Step 1: Problem Validation\n\nThe problem is first validated against the specified criteria.\n\n**1. Extract Givens:**\n-   **Domain:** The integrals are over the unit square $[0,1]^2$.\n-   **1D Quadrature Rules:** A family of one-dimensional linear functionals $\\{Q_{\\ell}\\}_{\\ell \\geq 1}$ on $C([0,1])$ is defined.\n    -   $Q_1$: The Level $\\ell=1$ rule is the trapezoidal rule, with nodes $\\{0,1\\}$ and weights $\\{\\frac{1}{2}, \\frac{1}{2}\\}$. For a function $f(x)$, this means $Q_1(f) = \\frac{1}{2}f(0) + \\frac{1}{2}f(1)$.\n    -   $Q_2^{\\alpha}$: The Level $\\ell=2$ rule is from a family of three-node formulas with nodes $\\{0, \\frac{1}{2}, 1\\}$ and symmetric weights $\\{\\frac{\\alpha}{2}, 1-\\alpha, \\frac{\\alpha}{2}\\}$. The parameter $\\alpha$ is in the range $(0,1]$. For a function $f(x)$, this means $Q_2^{\\alpha}(f) = \\frac{\\alpha}{2}f(0) + (1-\\alpha)f(\\frac{1}{2}) + \\frac{\\alpha}{2}f(1)$.\n-   **Hierarchical Increments:**\n    -   $\\Delta Q_1 := Q_1$.\n    -   $\\Delta Q_2 := Q_2^{\\alpha} - Q_1$.\n-   **2D Smolyak Quadrature Rule:** The level $L=2$, dimension $d=2$ rule is given by the formula:\n    $$A(2,2) = \\sum_{|\\boldsymbol{\\ell}|_{1} \\leq L + d - 1} \\bigotimes_{j=1}^{2} \\Delta Q_{\\ell_{j}} = \\Delta Q_1 \\otimes \\Delta Q_1 + \\Delta Q_1 \\otimes \\Delta Q_2 + \\Delta Q_2 \\otimes \\Delta Q_1$$\n    where $|\\boldsymbol{\\ell}|_1 = \\ell_1 + \\ell_2$. The summation indices $\\ell_j$ start from $1$, so the condition $|\\boldsymbol{\\ell}|_1 \\leq 2+2-1=3$ yields the multi-indices $(1,1)$, $(1,2)$, and $(2,1)$.\n-   **Objective:** Find the minimal value of $\\alpha \\in (0,1]$ such that all weights of the quadrature rule $A(2,2)$ are non-negative.\n\n**2. Validate Using Extracted Givens:**\n-   **Scientifically Grounded:** The problem is firmly rooted in the field of numerical analysis, specifically the construction of sparse grid quadrature rules using the Smolyak algorithm. The concepts of hierarchical increments, tensor products of quadrature rules, and the importance of positive weights for numerical stability are standard and well-established.\n-   **Well-Posed:** The problem provides a complete and unambiguous definition of the quadrature rule $A(2,2)$ and a clear objective. The parameter $\\alpha$ is constrained to a specific interval. The problem is structured to have a unique, meaningful solution.\n-   **Objective:** The problem is stated using precise mathematical language, free from any subjective or biased terminology.\n\n**3. Verdict and Action:**\nThe problem is valid as it is scientifically grounded, well-posed, and objective. It contains no contradictions, ambiguities, or unsound premises. Therefore, I will proceed with the full solution.\n\n### Step 2: Solution Derivation\n\nThe solution proceeds by determining the weights of the Smolyak rule $A(2,2)$ as a function of $\\alpha$ and then finding the minimum $\\alpha$ that satisfies the non-negativity constraint for all weights.\n\n**1. Express 1D Hierarchical Increments in terms of function evaluations:**\nLet $f(x)$ be a function defined on $[0,1]$.\nThe Level 1 increment is:\n$$ \\Delta Q_1(f) = Q_1(f) = \\frac{1}{2}f(0) + \\frac{1}{2}f(1) $$\nThis operator has weights $\\{\\frac{1}{2}, \\frac{1}{2}\\}$ on the node set $\\{0, 1\\}$.\n\nThe Level 2 increment is:\n$$ \\Delta Q_2(f) = Q_2^{\\alpha}(f) - Q_1(f) $$\n$$ \\Delta Q_2(f) = \\left( \\frac{\\alpha}{2}f(0) + (1-\\alpha)f(\\frac{1}{2}) + \\frac{\\alpha}{2}f(1) \\right) - \\left( \\frac{1}{2}f(0) + \\frac{1}{2}f(1) \\right) $$\nCombining terms for each evaluation point:\n$$ \\Delta Q_2(f) = \\left(\\frac{\\alpha}{2} - \\frac{1}{2}\\right)f(0) + (1-\\alpha)f(\\frac{1}{2}) + \\left(\\frac{\\alpha}{2} - \\frac{1}{2}\\right)f(1) $$\n$$ \\Delta Q_2(f) = \\frac{\\alpha-1}{2}f(0) + (1-\\alpha)f(\\frac{1}{2}) + \\frac{\\alpha-1}{2}f(1) $$\nThis operator has weights $\\{\\frac{\\alpha-1}{2}, 1-\\alpha, \\frac{\\alpha-1}{2}\\}$ on the node set $\\{0, \\frac{1}{2}, 1\\}$.\n\n**2. Determine the Node Set and Weights of the 2D Smolyak Rule:**\nThe Smolyak quadrature rule $A(2,2)$ is a linear combination of tensor product rules. The weight of a point $(x_i, y_j)$ in the final rule is the sum of its weights from each term in the sum:\n$$ A(2,2) = (\\Delta Q_1 \\otimes \\Delta Q_1) + (\\Delta Q_1 \\otimes \\Delta Q_2) + (\\Delta Q_2 \\otimes \\Delta Q_1) $$\nThe full node set for $A(2,2)$ is the union of the node sets of the individual tensor product rules. Let $X_1 = \\{0,1\\}$ and $X_2 = \\{0, \\frac{1}{2}, 1\\}$. The node set of $A(2,2)$ is $(X_1 \\times X_1) \\cup (X_1 \\times X_2) \\cup (X_2 \\times X_1)$. This results in the set of points $\\{(0,0), (0,1), (1,0), (1,1), (0,\\frac{1}{2}), (1,\\frac{1}{2}), (\\frac{1}{2},0), (\\frac{1}{2},1)\\}$. The point $(\\frac{1}{2},\\frac{1}{2})$ is not included in this sparse grid.\n\nLet $w(x_i, y_j)$ denote the final weight at node $(x_i, y_j)$. We compute this weight for each type of node by symmetry. Let $w_1(x)$ be the weight function for $\\Delta Q_1$ and $w_2(x)$ be the weight function for $\\Delta Q_2$. The weight of a point $(x_i, y_j)$ in a tensor product rule $\\Delta Q_k \\otimes \\Delta Q_m$ is $w_k(x_i) \\cdot w_m(y_j)$.\n\n-   **Corner nodes:** e.g., $(0,0)$. By symmetry, all four corner nodes $(0,0), (0,1), (1,0), (1,1)$ will have the same weight.\n    -   Weight from $\\Delta Q_1 \\otimes \\Delta Q_1$: $w_1(0) \\cdot w_1(0) = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4}$.\n    -   Weight from $\\Delta Q_1 \\otimes \\Delta Q_2$: $w_1(0) \\cdot w_2(0) = \\frac{1}{2} \\cdot \\frac{\\alpha-1}{2} = \\frac{\\alpha-1}{4}$.\n    -   Weight from $\\Delta Q_2 \\otimes \\Delta Q_1$: $w_2(0) \\cdot w_1(0) = \\frac{\\alpha-1}{2} \\cdot \\frac{1}{2} = \\frac{\\alpha-1}{4}$.\n    -   Total weight $w(0,0) = \\frac{1}{4} + \\frac{\\alpha-1}{4} + \\frac{\\alpha-1}{4} = \\frac{1 + \\alpha - 1 + \\alpha - 1}{4} = \\frac{2\\alpha-1}{4}$.\n\n-   **Edge midpoint nodes:** e.g., $(0, \\frac{1}{2})$. By symmetry, the nodes $(0,\\frac{1}{2})$ and $(1,\\frac{1}{2})$ will have one weight value, and $(\\frac{1}{2},0)$ and $(\\frac{1}{2},1)$ will have another (which turns out to be the same).\n    -   For point $(0, \\frac{1}{2})$:\n        -   The node sets for $\\Delta Q_1$ and $\\Delta Q_1 \\otimes \\Delta Q_1$ do not include the coordinate $\\frac{1}{2}$, so $w_1(\\frac{1}{2}) = 0$. The contribution from $\\Delta Q_1 \\otimes \\Delta Q_1$ is $w_1(0) \\cdot w_1(\\frac{1}{2}) = \\frac{1}{2} \\cdot 0 = 0$.\n        -   Weight from $\\Delta Q_1 \\otimes \\Delta Q_2$: $w_1(0) \\cdot w_2(\\frac{1}{2}) = \\frac{1}{2} \\cdot (1-\\alpha) = \\frac{1-\\alpha}{2}$.\n        -   Weight from $\\Delta Q_2 \\otimes \\Delta Q_1$: $w_2(0) \\cdot w_1(\\frac{1}{2}) = \\frac{\\alpha-1}{2} \\cdot 0 = 0$.\n        -   Total weight $w(0,\\frac{1}{2}) = 0 + \\frac{1-\\alpha}{2} + 0 = \\frac{1-\\alpha}{2}$.\n    -   For point $(\\frac{1}{2}, 0)$, by symmetry:\n        -   Weight from $\\Delta Q_1 \\otimes \\Delta Q_1$: $w_1(\\frac{1}{2}) \\cdot w_1(0) = 0 \\cdot \\frac{1}{2} = 0$.\n        -   Weight from $\\Delta Q_1 \\otimes \\Delta Q_2$: $w_1(\\frac{1}{2}) \\cdot w_2(0) = 0 \\cdot \\frac{\\alpha-1}{2} = 0$.\n        -   Weight from $\\Delta Q_2 \\otimes \\Delta Q_1$: $w_2(\\frac{1}{2}) \\cdot w_1(0) = (1-\\alpha) \\cdot \\frac{1}{2} = \\frac{1-\\alpha}{2}$.\n        -   Total weight $w(\\frac{1}{2},0) = 0 + 0 + \\frac{1-\\alpha}{2} = \\frac{1-\\alpha}{2}$.\n\n-   **Center node:** $(\\frac{1}{2}, \\frac{1}{2})$\n    -   The coordinate $\\frac{1}{2}$ is not in the node set of $\\Delta Q_1$, so $w_1(\\frac{1}{2}) = 0$.\n    -   Any tensor product term involving $\\Delta Q_1$ will have zero weight at this point.\n    -   Weight from $\\Delta Q_1 \\otimes \\Delta Q_1$: $w_1(\\frac{1}{2}) \\cdot w_1(\\frac{1}{2}) = 0 \\cdot 0 = 0$.\n    -   Weight from $\\Delta Q_1 \\otimes \\Delta Q_2$: $w_1(\\frac{1}{2}) \\cdot w_2(\\frac{1}{2}) = 0 \\cdot (1-\\alpha) = 0$.\n    -   Weight from $\\Delta Q_2 \\otimes \\Delta Q_1$: $w_2(\\frac{1}{2}) \\cdot w_1(\\frac{1}{2}) = (1-\\alpha) \\cdot 0 = 0$.\n    -   Total weight $w(\\frac{1}{2},\\frac{1}{2}) = 0$. This is non-negative.\n\n**3. Solve for the Minimal Value of $\\alpha$:**\nTo ensure all weights are non-negative, we must satisfy the following inequalities for $\\alpha \\in (0,1]$:\n1.  For corner nodes: $w(0,0) = \\frac{2\\alpha-1}{4} \\geq 0 \\implies 2\\alpha - 1 \\geq 0 \\implies \\alpha \\geq \\frac{1}{2}$.\n2.  For edge midpoint nodes: $w(0,\\frac{1}{2}) = \\frac{1-\\alpha}{2} \\geq 0 \\implies 1-\\alpha \\geq 0 \\implies \\alpha \\leq 1$.\n\nThe problem states that $\\alpha \\in (0,1]$, so the second condition $\\alpha \\leq 1$ is already satisfied.\nThe first condition requires $\\alpha \\geq \\frac{1}{2}$.\nTo satisfy all conditions simultaneously, $\\alpha$ must be in the interval $[\\frac{1}{2}, 1]$.\nThe minimal value of $\\alpha$ in this interval is $\\frac{1}{2}$.",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        }
    ]
}