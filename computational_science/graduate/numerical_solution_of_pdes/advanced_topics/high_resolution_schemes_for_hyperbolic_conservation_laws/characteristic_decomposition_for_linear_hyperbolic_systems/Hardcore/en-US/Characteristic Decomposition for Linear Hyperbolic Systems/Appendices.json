{
    "hands_on_practices": [
        {
            "introduction": "The Riemann problem, which describes the evolution of an initial discontinuity, is a cornerstone of hyperbolic PDE theory. Solving it analytically for a linear system is a fundamental exercise that crystallizes the connection between the abstract eigen-decomposition of the system matrix and the physical behavior of the solution. This practice  requires you to derive the wave speeds and strengths for a classic shallow water system, reinforcing the core principles of how an initial jump is resolved into characteristic waves.",
            "id": "3369623",
            "problem": "Consider the linear hyperbolic system given by the constant-coefficient partial differential equation (PDE)\n$$\n\\partial_{t}\\boldsymbol{u}(x,t) + A\\,\\partial_{x}\\boldsymbol{u}(x,t) = \\boldsymbol{0}, \\quad A = \\begin{pmatrix} 0  1 \\\\ g H  0 \\end{pmatrix},\n$$\nwith gravitational acceleration $g0$ and background depth $H0$. Let the Riemann initial data be\n$$\n\\boldsymbol{u}(x,0) = \\begin{cases}\n\\boldsymbol{u}_{L}  x0\\\\\n\\boldsymbol{u}_{R}  x0\n\\end{cases},\n$$\nwhere $\\boldsymbol{u}_{L},\\boldsymbol{u}_{R}\\in\\mathbb{R}^{2}$ are constant left and right states. Denote the jump by $\\Delta \\boldsymbol{u} = \\boldsymbol{u}_{R} - \\boldsymbol{u}_{L}$ and its components by $\\Delta u_{1}$ and $\\Delta u_{2}$. Using only the foundational definitions of strict hyperbolicity, eigen-decomposition of $A$, and characteristic projection for linear systems, derive the characteristic wave strengths associated with each family and the locations of all discontinuities at time $t0$. Define the wave strengths $\\alpha_{+}$ and $\\alpha_{-}$ by the decomposition of the jump into right eigenvectors of $A$, with $\\alpha_{+}$ corresponding to the right-going characteristic and $\\alpha_{-}$ to the left-going characteristic. Express your final answer as a single row matrix\n$$\n\\left(\\alpha_{+},\\,\\alpha_{-},\\,x_{-}(t),\\,x_{+}(t)\\right),\n$$\nwhere $x_{-}(t)$ and $x_{+}(t)$ are the locations of the left- and right-moving discontinuities at time $t0$, respectively. Provide an exact symbolic expression in terms of $g$, $H$, $t$, $\\Delta u_{1}$, and $\\Delta u_{2}$. No rounding is required and no units should be included in the final answer.",
            "solution": "The problem is valid. It is a well-posed, scientifically grounded problem in the field of partial differential equations, specifically concerning the characteristic decomposition of a linear hyperbolic system. All necessary data and definitions are provided, and there are no contradictions or ambiguities.\n\nThe given linear hyperbolic system is\n$$\n\\partial_{t}\\boldsymbol{u}(x,t) + A\\,\\partial_{x}\\boldsymbol{u}(x,t) = \\boldsymbol{0},\n$$\nwhere $\\boldsymbol{u}(x,t) \\in \\mathbb{R}^{2}$ and the constant coefficient matrix $A$ is\n$$\nA = \\begin{pmatrix} 0  1 \\\\ g H  0 \\end{pmatrix}.\n$$\nThe problem describes a Riemann problem with initial data consisting of two constant states, $\\boldsymbol{u}_{L}$ for $x0$ and $\\boldsymbol{u}_{R}$ for $x0$. The solution to such a problem for a linear hyperbolic system is constructed by decomposing the initial jump, $\\Delta \\boldsymbol{u} = \\boldsymbol{u}_{R} - \\boldsymbol{u}_{L}$, into the eigenvectors of the matrix $A$.\n\nFirst, we must perform the eigen-decomposition of $A$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(A - \\lambda I) = 0$.\n$$\n\\det\\begin{pmatrix} 0-\\lambda  1 \\\\ gH  0-\\lambda \\end{pmatrix} = (-\\lambda)(-\\lambda) - (1)(gH) = \\lambda^{2} - gH = 0.\n$$\nSince $g0$ and $H0$, the eigenvalues are real and distinct:\n$$\n\\lambda_{\\pm} = \\pm\\sqrt{gH}.\n$$\nThe existence of two distinct real eigenvalues confirms that the system is strictly hyperbolic. These eigenvalues represent the characteristic speeds at which information propagates. The positive eigenvalue $\\lambda_{+} = \\sqrt{gH}$ corresponds to a right-going wave, and the negative eigenvalue $\\lambda_{-} = -\\sqrt{gH}$ corresponds to a left-going wave.\n\nNext, we find the corresponding right eigenvectors, $\\boldsymbol{r}_{\\pm}$, by solving $(A - \\lambda_{\\pm} I)\\boldsymbol{r}_{\\pm} = \\boldsymbol{0}$.\n\nFor the eigenvalue $\\lambda_{+} = \\sqrt{gH}$:\n$$\n(A - \\lambda_{+}I)\\boldsymbol{r}_{+} = \\begin{pmatrix} -\\sqrt{gH}  1 \\\\ gH  -\\sqrt{gH} \\end{pmatrix} \\begin{pmatrix} r_{1,+} \\\\ r_{2,+} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\nThis gives the equation $-\\sqrt{gH}r_{1,+} + r_{2,+} = 0$, which implies $r_{2,+} = \\sqrt{gH}r_{1,+}$. We can choose $r_{1,+} = 1$, yielding the eigenvector\n$$\n\\boldsymbol{r}_{+} = \\begin{pmatrix} 1 \\\\ \\sqrt{gH} \\end{pmatrix}.\n$$\nThis eigenvector corresponds to the right-going characteristic family.\n\nFor the eigenvalue $\\lambda_{-} = -\\sqrt{gH}$:\n$$\n(A - \\lambda_{-}I)\\boldsymbol{r}_{-} = \\begin{pmatrix} \\sqrt{gH}  1 \\\\ gH  \\sqrt{gH} \\end{pmatrix} \\begin{pmatrix} r_{1,-} \\\\ r_{2,-} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\nThis gives the equation $\\sqrt{gH}r_{1,-} + r_{2,-} = 0$, which implies $r_{2,-} = -\\sqrt{gH}r_{1,-}$. We can choose $r_{1,-} = 1$, yielding the eigenvector\n$$\n\\boldsymbol{r}_{-} = \\begin{pmatrix} 1 \\\\ -\\sqrt{gH} \\end{pmatrix}.\n$$\nThis eigenvector corresponds to the left-going characteristic family.\n\nThe solution to the Riemann problem is given by a superposition of waves associated with each characteristic family. The jump in the initial data, $\\Delta \\boldsymbol{u} = \\boldsymbol{u}_{R} - \\boldsymbol{u}_{L}$, is decomposed into a linear combination of the right eigenvectors. The coefficients of this decomposition are the characteristic wave strengths, denoted by $\\alpha_{+}$ and $\\alpha_{-}$.\n$$\n\\Delta \\boldsymbol{u} = \\alpha_{+} \\boldsymbol{r}_{+} + \\alpha_{-} \\boldsymbol{r}_{-}.\n$$\nSubstituting the expressions for $\\Delta \\boldsymbol{u} = \\begin{pmatrix} \\Delta u_{1} \\\\ \\Delta u_{2} \\end{pmatrix}$ and the eigenvectors, we obtain a linear system for the wave strengths:\n$$\n\\begin{pmatrix} \\Delta u_{1} \\\\ \\Delta u_{2} \\end{pmatrix} = \\alpha_{+} \\begin{pmatrix} 1 \\\\ \\sqrt{gH} \\end{pmatrix} + \\alpha_{-} \\begin{pmatrix} 1 \\\\ -\\sqrt{gH} \\end{pmatrix} = \\begin{pmatrix} 1  1 \\\\ \\sqrt{gH}  -\\sqrt{gH} \\end{pmatrix} \\begin{pmatrix} \\alpha_{+} \\\\ \\alpha_{-} \\end{pmatrix}.\n$$\nWe solve this system for $\\alpha_{+}$ and $\\alpha_{-}$. From the first row, we have $\\alpha_{+} + \\alpha_{-} = \\Delta u_{1}$. From the second row, we have $\\sqrt{gH}(\\alpha_{+} - \\alpha_{-}) = \\Delta u_{2}$, which gives $\\alpha_{+} - \\alpha_{-} = \\frac{\\Delta u_{2}}{\\sqrt{gH}}$.\n\nAdding these two equations:\n$$\n(\\alpha_{+} + \\alpha_{-}) + (\\alpha_{+} - \\alpha_{-}) = \\Delta u_{1} + \\frac{\\Delta u_{2}}{\\sqrt{gH}} \\implies 2\\alpha_{+} = \\Delta u_{1} + \\frac{\\Delta u_{2}}{\\sqrt{gH}}.\n$$\n$$\n\\alpha_{+} = \\frac{1}{2}\\Delta u_{1} + \\frac{\\Delta u_{2}}{2\\sqrt{gH}}.\n$$\nSubtracting the second new equation from the first:\n$$\n(\\alpha_{+} + \\alpha_{-}) - (\\alpha_{+} - \\alpha_{-}) = \\Delta u_{1} - \\frac{\\Delta u_{2}}{\\sqrt{gH}} \\implies 2\\alpha_{-} = \\Delta u_{1} - \\frac{\\Delta u_{2}}{\\sqrt{gH}}.\n$$\n$$\n\\alpha_{-} = \\frac{1}{2}\\Delta u_{1} - \\frac{\\Delta u_{2}}{2\\sqrt{gH}}.\n$$\nThese are the strengths of the right-going and left-going waves, respectively.\n\nThe locations of the discontinuities, $x_{-}(t)$ and $x_{+}(t)$, are determined by the characteristic speeds. For a linear constant-coefficient system, the discontinuities are contact discontinuities that emanate from the origin $x=0$ and travel at constant speeds equal to the eigenvalues.\nThe location of the right-moving discontinuity at time $t0$ is given by its speed $\\lambda_{+}$ multiplied by time $t$:\n$$\nx_{+}(t) = \\lambda_{+} t = \\sqrt{gH}t.\n$$\nThe location of the left-moving discontinuity at time $t0$ is given by its speed $\\lambda_{-}$ multiplied by time $t$:\n$$\nx_{-}(t) = \\lambda_{-} t = -\\sqrt{gH}t.\n$$\nThe solution $\\boldsymbol{u}(x,t)$ is then piecewise constant, with $\\boldsymbol{u}(x,t) = \\boldsymbol{u}_{L}$ for $x  x_{-}(t)$, $\\boldsymbol{u}(x,t) = \\boldsymbol{u}_{R}$ for $x  x_{+}(t)$, and a constant intermediate state for $x_{-}(t)  x  x_{+}(t)$.\n\nWe now assemble the required quantities into a single row matrix $(\\alpha_{+}, \\alpha_{-}, x_{-}(t), x_{+}(t))$:\n$$\n\\left( \\frac{1}{2}\\Delta u_{1} + \\frac{\\Delta u_{2}}{2\\sqrt{gH}}, \\quad \\frac{1}{2}\\Delta u_{1} - \\frac{\\Delta u_{2}}{2\\sqrt{gH}}, \\quad -\\sqrt{gH}t, \\quad \\sqrt{gH}t \\right).\n$$\nThis expression provides the full characteristic decomposition and the dynamics of the resulting discontinuities as requested.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2}\\Delta u_{1} + \\frac{\\Delta u_{2}}{2\\sqrt{gH}}  \\frac{1}{2}\\Delta u_{1} - \\frac{\\Delta u_{2}}{2\\sqrt{gH}}  -\\sqrt{gH}t  \\sqrt{gH}t\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A critical component of developing reliable numerical solvers is the ability to verify their accuracy, which often requires comparing the numerical output against a known exact solution. This practice  guides you through the construction of a powerful exact-solution generator by ingeniously combining the characteristic decomposition with the properties of the Fourier transform. You will use this tool to validate a high-order numerical scheme, providing a concrete demonstration of how theoretical concepts can be leveraged for practical code verification.",
            "id": "3369531",
            "problem": "Consider the constant-coefficient linear hyperbolic system in one spatial dimension with periodic boundary conditions,\n$$\n\\partial_t \\mathbf{u}(x,t) + A\\,\\partial_x \\mathbf{u}(x,t) = \\mathbf{0}, \\quad x \\in [0,L), \\quad t \\ge 0,\n$$\nwhere $\\mathbf{u}(x,t) \\in \\mathbb{R}^m$, $A \\in \\mathbb{R}^{m \\times m}$ is a constant matrix, and $L0$ is the domain length. A system is hyperbolic when $A$ has real eigenvalues and a complete set of eigenvectors. Let $R \\in \\mathbb{R}^{m \\times m}$ denote the matrix of right eigenvectors and $\\Lambda = \\mathrm{diag}(\\lambda_1,\\dots,\\lambda_m) \\in \\mathbb{R}^{m \\times m}$ the diagonal matrix of eigenvalues, so that $A = R \\Lambda R^{-1}$. Introduce characteristic variables $\\boldsymbol{\\alpha}(x,t) = L^\\top \\mathbf{u}(x,t)$, where $L^\\top = R^{-1}$. \n\nUsing only the fundamental facts that (i) superposition holds for linear systems, (ii) hyperbolicity implies diagonalization into independent characteristic families, and (iii) for periodic domains, Fourier series decouple linear constant-coefficient spatial derivatives mode-by-mode, derive a representation that leads to an exact-solution generator for the system by advancing each characteristic field in time via its advection speed and reconstructing $\\mathbf{u}(x,t)$ from the characteristic variables. Your program must implement this representation in a numerically exact way for trigonometric initial data by combining characteristic decomposition with the Fast Fourier Transform (FFT) to effect periodic translations on $[0,L)$.\n\nAdditionally, to validate high-order methods across multiple wave families, implement a $4$-th order accurate spatial discretization for $\\partial_x$ using the standard centered $5$-point stencil together with the classical $4$-stage, $4$-th order Runge–Kutta time integrator. Use a Courant–Friedrichs–Lewy (CFL) step size restriction based on the maximum wave speed in magnitude. Compute the relative $\\ell^2$ error at a specified final time by comparing the numerical solution against the exact-solution generator constructed from the characteristic–Fourier representation.\n\nThe spatial domain is periodic with $L = 2\\pi$, discretized by a uniform grid of $N$ points with $N = 256$. For each test, determine the time step $\\Delta t$ by\n$$\n\\Delta t = \\mathrm{CFL}\\,\\frac{\\Delta x}{\\max_j|\\lambda_j|}, \\quad \\Delta x = L/N,\n$$\nusing $\\mathrm{CFL} = 0.3$, and integrate exactly to the specified final time by taking $n$ equal steps so that $n\\,\\Delta t = T$ (take $n$ as the smallest positive integer with $n \\ge T/\\Delta t$ and then reset $\\Delta t \\leftarrow T/n$).\n\nYour program must implement the following three test cases. In each case, construct $A$ via $A = R \\Lambda R^{-1}$, define the characteristic initial data $\\alpha_j(x)$, and then set $\\mathbf{u}(x,0) = R\\,\\boldsymbol{\\alpha}(x)$, where $\\boldsymbol{\\alpha}(x) = (\\alpha_1(x),\\dots,\\alpha_m(x))^\\top$. Evolve to time $T$.\n\n- Test $\\#1$ (two-wave acoustic-type system):\n  - $m = 2$, $R = \\begin{bmatrix}1  1\\\\ 1  -1\\end{bmatrix}$, $\\Lambda = \\mathrm{diag}(1,-1)$.\n  - $\\alpha_1(x) = \\sin(3x) + 0.5\\cos(5x)$, $\\alpha_2(x) = 0.3\\cos(2x) - 0.4\\sin(4x)$.\n  - $T = 0.7$.\n\n- Test $\\#2$ (three-wave system with a stationary family):\n  - $m = 3$, $R = \\begin{bmatrix}1  1  0\\\\ 0  1  1\\\\ 1  0  1\\end{bmatrix}$, $\\Lambda = \\mathrm{diag}(-2,0,3)$.\n  - $\\alpha_1(x) = 0.8\\sin(2x) + 0.2\\cos(7x)$, $\\alpha_2(x) = 0.5\\sin(5x)$, $\\alpha_3(x) = 0.4\\cos(3x) - 0.1\\sin(9x)$.\n  - $T = 0.5$.\n\n- Test $\\#3$ (three-wave system with repeated speed but complete eigenbasis):\n  - $m = 3$, $R = \\begin{bmatrix}1  0  1\\\\ 0  1  1\\\\ 0  1  0\\end{bmatrix}$, $\\Lambda = \\mathrm{diag}(1,1,-0.5)$.\n  - $\\alpha_1(x) = \\sin(x) + 0.25\\cos(4x)$, $\\alpha_2(x) = 0.6\\cos(6x)$, $\\alpha_3(x) = 0.3\\sin(3x) - 0.2\\cos(8x)$.\n  - $T = 1.1$.\n\nDefinitions and required computations:\n- The exact-solution generator must implement the characteristic projection $\\boldsymbol{\\alpha}(x,0) = L^\\top \\mathbf{u}(x,0)$, advance each $\\alpha_j$ by periodic translation at speed $\\lambda_j$ using its Fourier series, and reconstruct $\\mathbf{u}(x,T) = R\\,\\boldsymbol{\\alpha}(x,T)$.\n- The high-order numerical scheme must discretize $\\partial_x$ by the $4$-th order centered stencil\n  $$\n  (\\partial_x f)(x_i) \\approx \\frac{-f_{i+2} + 8 f_{i+1} - 8 f_{i-1} + f_{i-2}}{12\\,\\Delta x},\n  $$\n  applied componentwise with periodic indexing, and advance in time using the classical $4$-stage, $4$-th order Runge–Kutta method for the semi-discrete system $\\partial_t \\mathbf{u}_h = -A\\,\\partial_x \\mathbf{u}_h$.\n\nFor each test, report the relative $\\ell^2$ error at time $T$,\n$$\n\\varepsilon = \\frac{\\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_h(x_i,T) - \\mathbf{u}_{\\mathrm{exact}}(x_i,T)\\|_2^2 \\,\\Delta x\\right)^{1/2}}{\\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_{\\mathrm{exact}}(x_i,T)\\|_2^2 \\,\\Delta x\\right)^{1/2}},\n$$\nwhere $\\|\\cdot\\|_2$ is the Euclidean norm in $\\mathbb{R}^m$.\n\nFinal output format:\n- Your program should produce a single line of output containing the three relative errors for tests $\\#1$, $\\#2$, and $\\#3$ as a comma-separated list enclosed in square brackets (for example, $[\\varepsilon_1,\\varepsilon_2,\\varepsilon_3]$). No units are involved; all quantities are dimensionless.",
            "solution": "The problem requires the solution of a one-dimensional constant-coefficient linear hyperbolic system, $\\partial_t \\mathbf{u}(x,t) + A\\,\\partial_x \\mathbf{u}(x,t) = \\mathbf{0}$, on a periodic domain $x \\in [0,L)$. We are asked to develop two solution methodologies: an exact-solution generator based on characteristic decomposition and Fourier transforms, and a high-order numerical scheme using finite differences and a Runge-Kutta integrator. Finally, we must compute the relative $\\ell^2$ error between the two solutions for three specified test cases.\n\n### 1. Characteristic Decomposition\n\nThe core of solving this system lies in its hyperbolicity, which guarantees that the matrix $A$ is diagonalizable with real eigenvalues. This means there exists an invertible matrix $R$, whose columns are the right eigenvectors of $A$, and a diagonal matrix $\\Lambda$ of the corresponding real eigenvalues $\\lambda_j$, such that $A = R \\Lambda R^{-1}$.\n\nWe can leverage this property to decouple the system of $m$ partial differential equations (PDEs). Let's define the characteristic variables $\\boldsymbol{\\alpha}(x,t)$ through the transformation $\\mathbf{u}(x,t) = R\\,\\boldsymbol{\\alpha}(x,t)$. Consequently, $\\boldsymbol{\\alpha}(x,t) = R^{-1}\\,\\mathbf{u}(x,t)$. Substituting this into the original PDE system yields:\n$$\n\\partial_t (R\\,\\boldsymbol{\\alpha}) + A\\,\\partial_x (R\\,\\boldsymbol{\\alpha}) = \\mathbf{0}\n$$\nSince $R$ is a constant matrix, it can be factored out of the derivatives:\n$$\nR\\,\\partial_t \\boldsymbol{\\alpha} + (R \\Lambda R^{-1})\\,R\\,\\partial_x \\boldsymbol{\\alpha} = \\mathbf{0}\n$$\n$$\nR\\,\\partial_t \\boldsymbol{\\alpha} + R \\Lambda\\,\\partial_x \\boldsymbol{\\alpha} = \\mathbf{0}\n$$\nMultiplying from the left by $R^{-1}$ (which exists since $A$ is diagonalizable), we obtain a decoupled system for the characteristic variables $\\boldsymbol{\\alpha}$:\n$$\n\\partial_t \\boldsymbol{\\alpha} + \\Lambda\\,\\partial_x \\boldsymbol{\\alpha} = \\mathbf{0}\n$$\nBecause $\\Lambda$ is a diagonal matrix, $\\Lambda = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_m)$, this vector equation represents $m$ independent scalar advection equations:\n$$\n\\partial_t \\alpha_j + \\lambda_j\\,\\partial_x \\alpha_j = 0, \\quad \\text{for } j = 1, \\dots, m\n$$\nEach equation describes a wave, or characteristic field, $\\alpha_j(x,t)$, that propagates (advects) with a constant speed $\\lambda_j$ without changing its shape.\n\n### 2. Exact Solution via Fourier Transform\n\nThe solution to the scalar advection equation $\\partial_t f + c\\,\\partial_x f = 0$ is a simple translation of the initial profile: $f(x,t) = f(x - c t, 0)$. Thus, the exact solution for each characteristic variable is:\n$$\n\\alpha_j(x,t) = \\alpha_j(x - \\lambda_j t, 0)\n$$\nFor a periodic function on the interval $[0,L)$, this translation can be performed efficiently and without numerical error using the Fourier transform. The Fourier series of a function $f(x)$ is $f(x) = \\sum_k \\hat{f}_k e^{i k_x x}$, where $k_x = 2\\pi k/L$ are the wavenumbers. The translation property of the Fourier transform states that a shift in real space corresponds to a phase modulation in Fourier space:\n$$\nf(x - d) \\quad \\longleftrightarrow \\quad \\hat{f}_k e^{-i k_x d}\n$$\nThis provides a recipe for generating the exact solution at any time $T$:\n1.  **Construct Initial Data**: The initial conditions for the characteristic variables, $\\boldsymbol{\\alpha}(x,0)$, are given for each test case.\n2.  **Evolve in Fourier Space**: For each component $\\alpha_j(x,0)$:\n    a.  Compute its Discrete Fourier Transform (DFT) using the Fast Fourier Transform (FFT) algorithm, yielding coefficients $\\hat{\\alpha}_j(k_n, 0)$ for a discrete set of wavenumbers $k_n$.\n    b.  Multiply each coefficient by the corresponding phase factor $e^{-i k_n \\lambda_j T}$ to obtain the Fourier coefficients at time $T$: $\\hat{\\alpha}_j(k_n, T) = \\hat{\\alpha}_j(k_n, 0) e^{-i k_n \\lambda_j T}$.\n    c.  Compute the Inverse DFT (IFFT) of $\\hat{\\alpha}_j(k_n, T)$ to recover the translated characteristic profile $\\alpha_j(x,T)$ in physical space.\n3.  **Reconstruct Physical Variables**: Combine the evolved characteristic variables to find the final solution for $\\mathbf{u}(x,T)$ using the relation $\\mathbf{u}(x,T) = R\\,\\boldsymbol{\\alpha}(x,T)$.\n\nThis procedure is \"exact\" in the sense that it avoids time-stepping errors and spatial discretization errors, with precision limited only by floating-point arithmetic.\n\n### 3. High-Order Numerical Solution\n\nA numerical solution is computed by discretizing the PDE system in both space and time.\nThe semi-discrete system is $\\frac{d}{dt}\\mathbf{u}_h(t) = -A (\\partial_x \\mathbf{u}_h)(t)$, where $\\mathbf{u}_h$ represents the solution on the spatial grid.\n\n**Spatial Discretization**: The spatial derivative $\\partial_x$ is approximated using a $4$-th order accurate, $5$-point centered finite difference stencil on a uniform grid $x_i = i\\,\\Delta x$ for $i=0,\\dots,N-1$, with $\\Delta x = L/N$. Given a grid function $f_i = f(x_i)$, the derivative is approximated as:\n$$\n(\\partial_x f)(x_i) \\approx \\frac{-f_{i+2} + 8 f_{i+1} - 8 f_{i-1} + f_{i-2}}{12\\,\\Delta x}\n$$\nPeriodic boundary conditions are handled by performing index arithmetic modulo $N$. This operator is applied component-wise to the vector $\\mathbf{u}_h(x_i, t)$.\n\n**Time Integration**: We solve the resulting system of ordinary differential equations (ODEs), $\\frac{d}{dt}\\mathbf{U}(t) = \\mathcal{F}(\\mathbf{U}(t))$, where $\\mathbf{U}$ is the large state vector concatenating all $\\mathbf{u}_h(x_i, t)$ and $\\mathcal{F}$ represents the semi-discretized right-hand side, $-A \\cdot (\\text{stencil operator})$. The integration is performed using the classical $4$-stage, $4$-th order Runge-Kutta (RK4) method. For a single step from time $t_n$ to $t_{n+1} = t_n + \\Delta t$:\n$$\n\\begin{aligned}\n\\mathbf{k}_1 = \\mathcal{F}(\\mathbf{U}(t_n)) \\\\\n\\mathbf{k}_2 = \\mathcal{F}(\\mathbf{U}(t_n) + \\frac{\\Delta t}{2} \\mathbf{k}_1) \\\\\n\\mathbf{k}_3 = \\mathcal{F}(\\mathbf{U}(t_n) + \\frac{\\Delta t}{2} \\mathbf{k}_2) \\\\\n\\mathbf{k}_4 = \\mathcal{F}(\\mathbf{U}(t_n) + \\Delta t \\mathbf{k}_3) \\\\\n\\mathbf{U}(t_{n+1}) = \\mathbf{U}(t_n) + \\frac{\\Delta t}{6} (\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n\\end{aligned}\n$$\nThe time step $\\Delta t$ is selected based on the CFL condition to ensure stability, $\\Delta t = \\mathrm{CFL}\\,\\frac{\\Delta x}{\\max_j|\\lambda_j|}$. To reach the final time $T$ exactly, we find the minimum integer number of steps $n$ such that $n\\,\\Delta t \\ge T$, and then adjust the time step to $\\Delta t' = T/n$.\n\n### 4. Error Calculation\n\nAfter computing the exact solution $\\mathbf{u}_{\\mathrm{exact}}(x_i, T)$ and the numerical solution $\\mathbf{u}_h(x_i, T)$ at the final time $T$ on the grid points $x_i$, the relative $\\ell^2$ error is calculated. The discrete $\\ell^2$ norm of a vector-valued grid function $\\mathbf{v}(x_i)$ is $\\|\\mathbf{v}\\|_{\\ell^2} = \\left(\\sum_{i=0}^{N-1} \\|\\mathbf{v}(x_i)\\|_2^2 \\,\\Delta x\\right)^{1/2}$, where $\\|\\cdot\\|_2$ is the standard Euclidean vector norm in $\\mathbb{R}^m$. The relative error is then:\n$$\n\\varepsilon = \\frac{\\|\\mathbf{u}_h - \\mathbf{u}_{\\mathrm{exact}}\\|_{\\ell^2}}{\\|\\mathbf{u}_{\\mathrm{exact}}\\|_{\\ell^2}} = \\frac{\\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_h(x_i,T) - \\mathbf{u}_{\\mathrm{exact}}(x_i,T)\\|_2^2 \\,\\Delta x\\right)^{1/2}}{\\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_{\\mathrm{exact}}(x_i,T)\\|_2^2 \\,\\Delta x\\right)^{1/2}}\n$$\nThis metric quantifies the accuracy of the numerical scheme by comparing its output to the true solution generated by the characteristic-Fourier method.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_test_case(m, R, Lambda, alpha_funcs, T, N, CFL):\n    \"\"\"\n    Solves a linear hyperbolic system for a single test case.\n\n    This function performs the following steps:\n    1. Sets up the spatial grid and system matrices.\n    2. Constructs the initial condition u(x, 0) from the given characteristic data.\n    3. Computes the \"exact\" solution at time T using characteristic decomposition\n       and the Fast Fourier Transform (FFT) for periodic translation.\n    4. Computes the numerical solution at time T using a 4th-order finite\n       difference scheme for space and the classical 4th-order Runge-Kutta\n       method for time.\n    5. Calculates the relative l2 error between the numerical and exact solutions.\n    \"\"\"\n    # 1. Setup\n    L = 2.0 * np.pi\n    dx = L / N\n    x = np.linspace(0, L, N, endpoint=False)\n    \n    R = np.array(R, dtype=float)\n    Lambda = np.diag(Lambda)\n    A = R @ Lambda @ np.linalg.inv(R)\n\n    # 2. Initial Condition\n    alpha_initial = np.zeros((N, m))\n    for j in range(m):\n        alpha_initial[:, j] = alpha_funcs[j](x)\n    u0 = alpha_initial @ R.T\n\n    # 3. Exact Solution Generator at Time T\n    k = 2 * np.pi * np.fft.fftfreq(N, d=dx)\n    alpha_final = np.zeros_like(alpha_initial, dtype=complex)\n    for j in range(m):\n        alpha_j_0_hat = np.fft.fft(alpha_initial[:, j])\n        lambda_j = Lambda[j, j]\n        phase_shift = np.exp(-1j * k * lambda_j * T)\n        alpha_j_T_hat = alpha_j_0_hat * phase_shift\n        alpha_final[:, j] = np.fft.ifft(alpha_j_T_hat)\n    \n    # The result should be real; take the real part to discard small imaginary noise\n    u_exact_T = (alpha_final @ R.T).real\n\n    # 4. Numerical Solution\n    \n    # Spatial derivative function (4th-order centered difference)\n    def spatial_derivative(u, dx_val):\n        # np.roll implements periodic boundary conditions\n        du_dx = (\n            -np.roll(u, -2, axis=0) + 8 * np.roll(u, -1, axis=0)\n            - 8 * np.roll(u, 1, axis=0) + np.roll(u, 2, axis=0)\n        ) / (12 * dx_val)\n        return du_dx\n\n    # RHS of the semi-discrete system: d_t u = -A * d_x u\n    def rhs(u, dx_val, A_mat):\n        du_dx = spatial_derivative(u, dx_val)\n        # Using u @ A.T is equivalent to (A @ u.T).T but can be more efficient\n        return - (du_dx @ A_mat.T)\n\n    # Time-stepping setup\n    lambda_max = np.max(np.abs(np.diag(Lambda)))\n    if lambda_max == 0: # Handle stationary wave case\n      dt_cfl = T # Avoid division by zero, take one large step\n    else:\n      dt_cfl = CFL * dx / lambda_max\n      \n    num_steps = int(np.ceil(T / dt_cfl))\n    dt = T / num_steps\n\n    # RK4 Integration\n    u_numerical = u0.copy()\n    for _ in range(num_steps):\n        k1 = rhs(u_numerical, dx, A)\n        k2 = rhs(u_numerical + dt/2 * k1, dx, A)\n        k3 = rhs(u_numerical + dt/2 * k2, dx, A)\n        k4 = rhs(u_numerical + dt * k3, dx, A)\n        u_numerical += dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n\n    # 5. Error Calculation\n    diff = u_numerical - u_exact_T\n    \n    # Discrete l2 norm: sqrt(sum(|v_i|^2 * dx))\n    numerator_sq = np.sum(np.linalg.norm(diff, axis=1)**2) * dx\n    denominator_sq = np.sum(np.linalg.norm(u_exact_T, axis=1)**2) * dx\n    \n    if denominator_sq == 0:\n        return 0.0\n    \n    error = np.sqrt(numerator_sq / denominator_sq)\n    return error\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and compute the errors.\n    \"\"\"\n    # Common parameters\n    N = 256\n    CFL = 0.3\n\n    test_cases = [\n        {\n            \"m\": 2, \"T\": 0.7,\n            \"R\": [[1, 1], [1, -1]],\n            \"Lambda\": [1, -1],\n            \"alpha_funcs\": [\n                lambda x: np.sin(3*x) + 0.5*np.cos(5*x),\n                lambda x: 0.3*np.cos(2*x) - 0.4*np.sin(4*x)\n            ]\n        },\n        {\n            \"m\": 3, \"T\": 0.5,\n            \"R\": [[1, 1, 0], [0, 1, 1], [1, 0, 1]],\n            \"Lambda\": [-2, 0, 3],\n            \"alpha_funcs\": [\n                lambda x: 0.8*np.sin(2*x) + 0.2*np.cos(7*x),\n                lambda x: 0.5*np.sin(5*x),\n                lambda x: 0.4*np.cos(3*x) - 0.1*np.sin(9*x)\n            ]\n        },\n        {\n            \"m\": 3, \"T\": 1.1,\n            \"R\": [[1, 0, 1], [0, 1, 1], [0, 1, 0]],\n            \"Lambda\": [1, 1, -0.5],\n            \"alpha_funcs\": [\n                lambda x: np.sin(x) + 0.25*np.cos(4*x),\n                lambda x: 0.6*np.cos(6*x),\n                lambda x: 0.3*np.sin(3*x) - 0.2*np.cos(8*x)\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        error = run_test_case(\n            m=case[\"m\"],\n            R=case[\"R\"],\n            Lambda=case[\"Lambda\"],\n            alpha_funcs=case[\"alpha_funcs\"],\n            T=case[\"T\"],\n            N=N,\n            CFL=CFL\n        )\n        results.append(f\"{error:.16e}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The elegance of characteristic decomposition can sometimes mask numerical fragility. When the system matrix becomes nearly \"defective,\" meaning its eigenvectors are close to being linearly dependent, a naive numerical implementation of the decomposition can become highly unstable. This hands-on coding exercise  confronts this challenge directly by asking you to implement and compare two different upwind flux formulations for a system with a point of degeneracy, providing invaluable insight into the importance of designing numerically robust algorithms.",
            "id": "3369632",
            "problem": "Consider the one-dimensional linear hyperbolic system of partial differential equations\n$$\n\\partial_t \\mathbf{u}(x,t) + A(x)\\,\\partial_x \\mathbf{u}(x,t) = 0,\\quad x\\in[-1,1],\\ t\\ge 0,\n$$\nwith periodic boundary conditions and unknown vector field $\\mathbf{u}:\\mathbb{R}\\times\\mathbb{R}_{\\ge 0}\\to\\mathbb{R}^2$. The coefficient matrix is prescribed as the variable-coefficient system\n$$\nA(x) = \\begin{pmatrix} x  1 \\\\ 0  -x \\end{pmatrix}.\n$$\nThis system is strictly hyperbolic for $x\\neq 0$ with eigenvalues $\\lambda_1(x)=x$ and $\\lambda_2(x)=-x$, and it becomes defective at $x=0$ where the eigenvalues coalesce to $0$ and there is only one linearly independent eigenvector. The ill-conditioning near $x=0$ challenges characteristic-based upwind fluxes that rely on eigenvector decompositions.\n\nYou must implement a first-order finite volume method for this system on a uniform grid with $N$ cells over the domain $[-1,1]$, using periodic boundary conditions. Let the cell width be $\\Delta x = 2/N$, cell centers $x_i=-1+(i+\\tfrac{1}{2})\\Delta x$ for $i=0,\\dots,N-1$, and cell faces $x_{i+\\frac{1}{2}}=-1+(i+1)\\Delta x$ for $i=0,\\dots,N-1$ with periodic indexing. Initialize\n$$\n\\mathbf{u}(x,0) = \\begin{pmatrix} \\sin(2\\pi x) \\\\ \\cos(2\\pi x) \\end{pmatrix}.\n$$\nDefine the semi-discrete first-order conservative update\n$$\n\\mathbf{u}_i^{n+1} = \\mathbf{u}_i^n - \\frac{\\Delta t}{\\Delta x}\\left(\\mathbf{F}_{i+\\frac{1}{2}}^n - \\mathbf{F}_{i-\\frac{1}{2}}^n\\right),\n$$\nwhere $\\mathbf{F}_{i+\\frac{1}{2}}$ denotes the numerical flux at face $x_{i+\\frac{1}{2}}$ and $\\Delta t$ is the time step. Use a uniform time step consistent with a Courant–Friedrichs–Lewy (CFL) condition based on the maximum spectral radius of $A(x)$ over faces, that is $\\Delta t = \\text{CFL} \\cdot \\Delta x / \\max_{i} \\rho(A(x_{i+\\frac{1}{2}}))$, where $\\rho(\\cdot)$ denotes the spectral radius. Since $\\rho(A(x)) = \\max\\{|\\lambda_1(x)|,|\\lambda_2(x)|\\} = |x|$, the global maximum over faces is $1$, so $\\Delta t = \\text{CFL}\\cdot\\Delta x$. Integrate up to time $T$.\n\nImplement and compare two flux constructions at each face $x_{i+\\frac{1}{2}}$:\n\n1. Eigen-based upwind flux (denoted variant U): Let $A=A(x_{i+\\frac{1}{2}})$, compute its eigen-decomposition $A=R\\Lambda R^{-1}$ where $\\Lambda=\\mathrm{diag}(\\lambda_1,\\lambda_2)$. Define $\\Lambda^+$ and $\\Lambda^-$ as the diagonal matrices with entries $(\\max(\\lambda_k,0))$ and $(\\min(\\lambda_k,0))$, respectively. Then set\n$$\nA^+ = R\\Lambda^+ R^{-1},\\quad A^- = R\\Lambda^- R^{-1},\\quad \\mathbf{F}_{i+\\frac{1}{2}} = A^+\\mathbf{u}_i + A^-\\mathbf{u}_{i+1}.\n$$\nNear $x=0$, where the matrix is nearly defective and at $x=0$ defective, a numerical eigen-decomposition may yield ill-conditioned $R$. To avoid breakdown in this implementation, if the condition number of $R$ exceeds a user-specified threshold or the decomposition fails, fall back at that face to the local Lax–Friedrichs flux\n$$\n\\mathbf{F}_{\\mathrm{LF}} = \\frac{1}{2}\\left(A\\,\\mathbf{u}_i + A\\,\\mathbf{u}_{i+1}\\right) - \\frac{s}{2}\\left(\\mathbf{u}_{i+1}-\\mathbf{u}_i\\right),\n$$\nwith $s$ set to a user-specified regularization parameter $\\delta0$. This fallback models the degradation of characteristic upwinding when the decomposition is nearly defective.\n\n2. Projector-based spectral splitting with fallback (denoted variant P): For $A=A(x_{i+\\frac{1}{2}})$ with $x=x_{i+\\frac{1}{2}}$, if $|x|\\ge \\delta$ for a user-specified small regularization parameter $\\delta0$, define the spectral projectors onto the eigenspaces for $\\lambda=x$ and $\\lambda=-x$ by the Lagrange interpolation formula\n$$\nP_+(x) = \\frac{A + x I}{2x},\\quad P_-(x) = \\frac{-A + x I}{2x},\n$$\nwhich are valid for $x\\neq 0$ and yield $P_+ + P_- = I$ and $A = x P_+ - x P_-$. Then set\n$$\nA^+ = \\begin{cases} x\\,P_+(x),  x\\ge 0, \\\\ (-x)\\,P_-(x),  x0,\\end{cases}\n\\quad\nA^- = \\begin{cases} -x\\,P_-(x),  x\\ge 0, \\\\ x\\,P_+(x),  x0,\\end{cases}\n\\quad \\mathbf{F}_{i+\\frac{1}{2}} = A^+\\mathbf{u}_i + A^-\\mathbf{u}_{i+1}.\n$$\nIf $|x|\\delta$, fall back to the local Lax–Friedrichs flux with $s=\\delta$ as above. This construction avoids explicit eigenvector computation and remains well-conditioned away from the coalescence.\n\nFor both variants, measure the following quantitative outputs at time $T$:\n- The ratio of the discrete $L^2$ norm to its initial value, defined by\n$$\nR = \\frac{\\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_i(T)\\|_2^2 \\,\\Delta x\\right)^{1/2}}{\\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_i(0)\\|_2^2 \\,\\Delta x\\right)^{1/2}},\n$$\nfor variant U and for variant P separately. This assesses stability (values significantly greater than $1$ indicate amplification).\n- The discrete $L^2$ difference between the two final solutions,\n$$\nD = \\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_i^{\\mathrm{U}}(T)-\\mathbf{u}_i^{\\mathrm{P}}(T)\\|_2^2 \\,\\Delta x\\right)^{1/2},\n$$\nwhich assesses the impact of near-defectiveness on accuracy and consistency between the two upwind constructions.\n\nTest Suite:\nUse the following parameter sets, which probe different facets:\n- Case 1 (edge case with a face at $x=0$): $N=200$ (even), $\\text{CFL}=0.45$, $T=0.1$, $\\delta=10^{-3}$.\n- Case 2 (happy path without a face exactly at $x=0$): $N=201$ (odd), $\\text{CFL}=0.45$, $T=0.1$, $\\delta=10^{-3}$.\n- Case 3 (more severe near-defectiveness): $N=200$ (even), $\\text{CFL}=0.45$, $T=0.1$, $\\delta=10^{-6}$.\n\nYour program must implement the above scheme and produce, for each test case, a list with three floating-point numbers $[R_\\mathrm{U}, R_\\mathrm{P}, D]$ in the specified order. The final output must be a single line containing the results for all test cases aggregated as a comma-separated list enclosed in square brackets, where each element is itself the list of three floats for the corresponding case, for example\n$$\n[\\,[R_{\\mathrm{U}}^{(1)},R_{\\mathrm{P}}^{(1)},D^{(1)}],\\,[R_{\\mathrm{U}}^{(2)},R_{\\mathrm{P}}^{(2)},D^{(2)}],\\,[R_{\\mathrm{U}}^{(3)},R_{\\mathrm{P}}^{(3)},D^{(3)}]\\,].\n$$",
            "solution": "The user-provided problem statement has been analyzed and is deemed valid, contingent upon a single reasonable assumption to resolve an ambiguity. The problem is a well-posed numerical experiment in the field of computational fluid dynamics, comparing two methods for constructing upwind fluxes for a linear hyperbolic system with a variable coefficient matrix that becomes defective at a point.\n\nThe central ambiguity in the problem statement lies in the fallback condition for the eigen-based upwind flux (Variant U). The statement specifies the fallback should be triggered \"if the condition number of R exceeds a user-specified threshold,\" but no such threshold is provided in the test suite. The condition number of the eigenvector matrix $R(x)$ for the given system matrix $A(x)$ is approximately proportional to $1/|x|$ for small $|x|$. The projector-based method (Variant P) is given an explicit fallback condition of $|x|  \\delta$. To create a meaningful and direct comparison between the two variants' primary flux formulations, it is logical and necessary to assume that the same condition, $|x|  \\delta$, also triggers the fallback for Variant U. This aligns the regions where the methods' core differences are evaluated and where both are regularized, fulfilling the pedagogical intent of the problem. With this assumption, the problem is well-defined and can be solved.\n\nThe solution proceeds by implementing a first-order finite volume scheme as specified. The methodology is broken down into the following steps:\n\n1.  **Spatial and Temporal Discretization**: The domain $x \\in [-1, 1]$ is discretized into $N$ uniform cells of width $\\Delta x = 2/N$. Cell centers are located at $x_i = -1 + (i+1/2)\\Delta x$ and faces at $x_{i+1/2} = -1 + (i+1)\\Delta x$. The time step $\\Delta t$ is determined by the CFL condition, $\\Delta t = \\text{CFL} \\cdot \\Delta x / \\rho_{\\max}$. The global maximum spectral radius of $A(x)$ across all faces is $\\rho_{\\max} = \\max |x_{i+1/2}| = 1$. Thus, $\\Delta t = \\text{CFL} \\cdot \\Delta x$. To ensure the simulation reaches the final time $T$ exactly, the number of steps is calculated as $n_{\\text{steps}} = \\lceil T / \\Delta t \\rceil$, and a new effective time step $\\Delta t_{\\text{eff}} = T / n_{\\text{steps}}$ is used for integration.\n\n2.  **Initial Condition**: The initial state $\\mathbf{u}(x, 0)$ is discretized by evaluating the given functions at the cell centers $x_i$, yielding the initial cell-averaged values $\\mathbf{u}_i(0)$. Two separate solution arrays, $\\mathbf{u}^{\\mathrm{U}}$ and $\\mathbf{u}^{\\mathrm{P}}$, are initialized with this state. The initial discrete $L^2$ norm, required for normalization, is computed as $\\|\\mathbf{u}(0)\\|_{L^2} = \\left(\\sum_{i=0}^{N-1} \\|\\mathbf{u}_i(0)\\|_2^2 \\Delta x\\right)^{1/2}$.\n\n3.  **Flux Implementations**: At each face $x_{i+1/2}$ and for each time step, two numerical fluxes $\\mathbf{F}^{\\mathrm{U}}_{i+1/2}$ and $\\mathbf{F}^{\\mathrm{P}}_{i+1/2}$ are computed. Both methods rely on a fallback to the Lax-Friedrichs flux for regularization near the point of degeneracy, $x=0$.\n    -   **Fallback Flux**: If $|x_{i+1/2}|  \\delta$, both variants use the Local Lax-Friedrichs (or Rusanov) flux: $\\mathbf{F}_{\\mathrm{LF}} = \\frac{1}{2}\\left(A(\\mathbf{u}_i + \\mathbf{u}_{i+1})\\right) - \\frac{s}{2}\\left(\\mathbf{u}_{i+1}-\\mathbf{u}_i\\right)$, with the stabilization parameter $s=\\delta$.\n    -   **Variant U (Eigen-based Upwind)**: For $|x_{i+1/2}| \\ge \\delta$, this method uses a standard characteristic decomposition. The system matrix $A(x_{i+1/2})$ is numerically diagonalized using a standard library routine (`numpy.linalg.eig`) to find its eigenvalues $\\Lambda$ and right eigenvector matrix $R$. The matrix is split into $A^+ = R\\Lambda^+R^{-1}$ and $A^- = R\\Lambda^-R^{-1}$. This implementation is deliberately chosen to reflect a direct application of the theory, which is known to be susceptible to numerical errors from the matrix inversion $R^{-1}$ when $R$ is ill-conditioned (i.e., for small $|x_{i+1/2}|$). The flux is then $\\mathbf{F}^{\\mathrm{U}}_{i+1/2} = A^+\\mathbf{u}_i + A^-\\mathbf{u}_{i+1}$.\n    -   **Variant P (Projector-based Spectral Splitting)**: For $|x_{i+1/2}| \\ge \\delta$, this method uses the provided formulas for the spectral projectors. A crucial step is to algebraically simplify the expressions for $A^+$ and $A^-$ before implementation. The projector formulas involve division by $2x$, which is numerically unstable for small $|x|$. However, the final expressions for $A^+$ and $A^-$ are perfectly well-behaved as $x \\to 0$. For $x \\ne 0$, these are:\n        $$A^+(x) = \\begin{cases} \\begin{pmatrix} x  1/2 \\\\ 0  0 \\end{pmatrix}  \\text{if } x  0 \\\\ \\begin{pmatrix} 0  1/2 \\\\ 0  -x \\end{pmatrix}  \\text{if } x  0 \\end{cases}, \\quad A^-(x) = \\begin{cases} \\begin{pmatrix} 0  1/2 \\\\ 0  -x \\end{pmatrix}  \\text{if } x  0 \\\\ \\begin{pmatrix} x  1/2 \\\\ 0  0 \\end{pmatrix}  \\text{if } x  0 \\end{cases}$$\n        This implementation is numerically robust and avoids the potential instabilities of both the black-box eigendecomposition and a naive implementation of the projector formulas. The flux is $\\mathbf{F}^{\\mathrm{P}}_{i+1/2} = A^+\\mathbf{u}_i + A^-\\mathbf{u}_{i+1}$.\n\n4.  **Time Integration**: A forward Euler method updates the cell averages from time $t_n$ to $t_{n+1}=t_n+\\Delta t_{\\text{eff}}$ according to the conservative formula:\n    $$ \\mathbf{u}_i^{n+1} = \\mathbf{u}_i^n - \\frac{\\Delta t_{\\text{eff}}}{\\Delta x}\\left(\\mathbf{F}_{i+\\frac{1}{2}}^n - \\mathbf{F}_{i-\\frac{1}{2}}^n\\right) $$\n    This is applied independently to $\\mathbf{u}^{\\mathrm{U}}$ and $\\mathbf{u}^{\\mathrm{P}}$ using their respective fluxes. Periodic boundary conditions are handled by wrapping indices for states and fluxes at the domain boundaries.\n\n5.  **Final Metrics**: After integrating up to time $T$, the final solutions $\\mathbf{u}^{\\mathrm{U}}(T)$ and $\\mathbf{u}^{\\mathrm{P}}(T)$ are used to compute the required outputs: the norm ratios $R_\\mathrm{U}$ and $R_\\mathrm{P}$, and the $L^2$ difference $D$.\n\nThis clear separation in the a priori stability of the two flux implementations (Variant U being numerically sensitive, Variant P being robust) is designed to produce a non-zero difference $D$, which quantifies the numerical error introduced by the ill-conditioning of the eigenvector-based approach near the defective point.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_A(x):\n    \"\"\"Returns the matrix A(x).\"\"\"\n    return np.array([[x, 1.0], [0.0, -x]])\n\ndef flux_LF(u_left, u_right, x_face, s):\n    \"\"\"Computes the local Lax-Friedrichs (Rusanov) flux.\"\"\"\n    A = get_A(x_face)\n    return 0.5 * (A @ u_left + A @ u_right) - 0.5 * s * (u_right - u_left)\n\ndef flux_U(u_left, u_right, x_face):\n    \"\"\"Computes the eigen-based upwind flux using numerical decomposition.\"\"\"\n    A = get_A(x_face)\n    lam, R = np.linalg.eig(A)\n    \n    # Sort eigenvalues and eigenvectors to be consistent: lam[0]~=x, lam[1]~=-x\n    # This is important for correctly defining Lambda^+ and Lambda^-.\n    if np.abs(lam[0] - (-x_face))  np.abs(lam[0] - x_face):\n        lam = lam[::-1]\n        R = R[:, ::-1]\n\n    R_inv = np.linalg.inv(R)\n    \n    Lambda_p = np.diag([max(l, 0) for l in lam])\n    Lambda_m = np.diag([min(l, 0) for l in lam])\n    \n    A_p = R @ Lambda_p @ R_inv\n    A_m = R @ Lambda_m @ R_inv\n    \n    return A_p @ u_left + A_m @ u_right\n\ndef flux_P(u_left, u_right, x_face):\n    \"\"\"Computes the projector-based upwind flux using a stable analytic form.\"\"\"\n    x = x_face\n    if x  0:\n        A_p = np.array([[x, 0.5], [0.0, 0.0]])\n        A_m = np.array([[0.0, 0.5], [0.0, -x]])\n    else: # x  0. The case x=0 is handled by the delta-fallback.\n        A_p = np.array([[0.0, 0.5], [0.0, -x]])\n        A_m = np.array([[x, 0.5], [0.0, 0.0]])\n        \n    return A_p @ u_left + A_m @ u_right\n\ndef run_simulation(N, CFL, T, delta):\n    \"\"\"\n    Runs one simulation case for the given parameters.\n    \"\"\"\n    # Grid setup\n    dx = 2.0 / N\n    x_centers = -1.0 + (np.arange(N) + 0.5) * dx\n    x_faces = -1.0 + (np.arange(N + 1)) * dx\n\n    # Time step calculation\n    max_rho = 1.0 # Max spectral radius is max|x| over faces, which is 1.\n    dt_cfl = CFL * dx / max_rho\n    # Ensure final time T is reached exactly\n    num_steps = int(np.ceil(T / dt_cfl))\n    dt = T / num_steps\n    \n    # Initial conditions\n    u0 = np.zeros((N, 2))\n    u0[:, 0] = np.sin(2 * np.pi * x_centers)\n    u0[:, 1] = np.cos(2 * np.pi * x_centers)\n    \n    u_U = u0.copy()\n    u_P = u0.copy()\n\n    # Initial discrete L2 norm\n    norm_u0_sq = np.sum(np.linalg.norm(u0, axis=1)**2) * dx\n    norm_u0 = np.sqrt(norm_u0_sq)\n\n    # Time integration loop\n    for _ in range(num_steps):\n        # --- Variant U Simulation Step ---\n        fluxes_U = np.zeros_like(u_U)\n        for i in range(N):\n            x_face = x_faces[i+1] # Flux at right face of cell i\n            u_left = u_U[i]\n            u_right = u_U[(i + 1) % N]\n            \n            if abs(x_face)  delta:\n                fluxes_U[i] = flux_LF(u_left, u_right, x_face, s=delta)\n            else:\n                fluxes_U[i] = flux_U(u_left, u_right, x_face)\n\n        # --- Variant P Simulation Step ---\n        fluxes_P = np.zeros_like(u_P)\n        for i in range(N):\n            x_face = x_faces[i+1]\n            u_left = u_P[i]\n            u_right = u_P[(i + 1) % N]\n            \n            if abs(x_face)  delta:\n                fluxes_P[i] = flux_LF(u_left, u_right, x_face, s=delta)\n            else:\n                fluxes_P[i] = flux_P(u_left, u_right, x_face)\n\n        # Vectorized update of solutions\n        u_U -= (dt / dx) * (fluxes_U - np.roll(fluxes_U, 1, axis=0))\n        u_P -= (dt / dx) * (fluxes_P - np.roll(fluxes_P, 1, axis=0))\n\n    # --- Final Metrics Calculation ---\n    # Norm Ratio R\n    norm_uT_U_sq = np.sum(np.linalg.norm(u_U, axis=1)**2) * dx\n    R_U = np.sqrt(norm_uT_U_sq) / norm_u0\n    \n    norm_uT_P_sq = np.sum(np.linalg.norm(u_P, axis=1)**2) * dx\n    R_P = np.sqrt(norm_uT_P_sq) / norm_u0\n\n    # L2 Difference D\n    diff_sq = np.sum(np.linalg.norm(u_U - u_P, axis=1)**2) * dx\n    D = np.sqrt(diff_sq)\n    \n    return [R_U, R_P, D]\n\ndef solve():\n    \"\"\"Main solver function to run test cases and print results.\"\"\"\n    test_cases = [\n        # (N, CFL, T, delta)\n        (200, 0.45, 0.1, 1e-3),\n        (201, 0.45, 0.1, 1e-3),\n        (200, 0.45, 0.1, 1e-6),\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = run_simulation(*params)\n        all_results.append(result)\n\n    # Format output as a string representation of a list of lists.\n    # The default np.array2string or list str() might add unwanted whitespace.\n    outer_list_str = []\n    for res in all_results:\n        inner_list_str = f\"[{res[0]},{res[1]},{res[2]}]\"\n        outer_list_str.append(inner_list_str)\n    \n    print(f\"[{','.join(outer_list_str)}]\")\n\nsolve()\n```"
        }
    ]
}