{
    "hands_on_practices": [
        {
            "introduction": "To effectively apply and adapt any numerical algorithm, one must first understand its fundamental computational cost. This exercise grounds our study of Cholesky factorization by analyzing its performance on a dense symmetric positive-definite matrix. By meticulously counting the floating-point operations (flops), you will derive the classic $O(n^3)$ complexity of the algorithm, providing a crucial baseline for evaluating the efficiency of methods for sparse systems .",
            "id": "3370813",
            "problem": "Consider the symmetric positive-definite linear system $A x = b$ that arises from a finite difference discretization of a uniformly elliptic partial differential equation (PDE) such as the two-dimensional Poisson equation on a uniform grid. Suppose $A \\in \\mathbb{R}^{n \\times n}$ is treated as dense and factored by the Cholesky factorization $A = L L^{\\top}$, where $L$ is lower triangular with positive diagonal. Adopt the following arithmetic cost model: each floating-point addition, subtraction, multiplication, division, and square root counts as $1$ floating-point operation (flop).\n\nTasks:\n- Starting from the standard unblocked Cholesky algorithm that computes $L$ column-by-column using inner products, derive from first principles the exact total flop count to factor $A$ as a polynomial in $n$, and thereby show that it is $n^{3}/3 + O(n^{2})$.\n- Using the standard forward substitution for solving $L y = b$ and backward substitution for solving $L^{\\top} x = y$, derive the exact flop count of each triangular solve.\n- Combine your results to obtain a single simplified closed-form expression in $n$ for the exact total number of flops required to factor $A$ by Cholesky and then solve $A x = b$ for a single right-hand side by forward and backward substitution.\n\nReport as your final answer only the exact total flop count from the combined step, simplified to a single polynomial in $n$. No rounding is required.",
            "solution": "The problem statement is scrutinized for validity according to the specified criteria.\n\n### Step 1: Extract Givens\n- The system of equations is a linear system $A x = b$.\n- The matrix $A \\in \\mathbb{R}^{n \\times n}$ is symmetric and positive-definite (SPD), and is treated as dense.\n- The system is to be solved using Cholesky factorization, $A = L L^{\\top}$, where $L$ is a lower triangular matrix with positive diagonal entries.\n- The solution process consists of three stages:\n    1.  Cholesky factorization: $A \\to L$.\n    2.  Forward substitution: Solve $L y = b$ for $y$.\n    3.  Backward substitution: Solve $L^{\\top} x = y$ for $x$.\n- The arithmetic cost model defines a floating-point operation (flop) as one addition, subtraction, multiplication, division, or square root.\n- The tasks are:\n    1.  Derive the exact total flop count for the Cholesky factorization using a standard column-by-column algorithm based on inner products, expressing the result as a polynomial in $n$.\n    2.  Derive the exact flop count for both the forward and backward substitution steps.\n    3.  Combine all counts into a single simplified closed-form expression for the total number of flops to solve $A x = b$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is based on fundamental and standard concepts in numerical linear algebraâ€”Cholesky factorization and triangular solves. The flop count analysis is a canonical exercise in scientific computing.\n- **Well-Posed:** The problem clearly specifies the algorithms, the cost model, and the desired form of the output. This structure ensures that a unique and meaningful solution exists.\n- **Objective:** The problem is stated using precise, unambiguous mathematical language and is free of subjective content.\n\nThe problem does not exhibit any of the flaws listed in the instructions, such as scientific unsoundness, incompleteness, contradiction, or ambiguity. It is a well-defined problem in numerical analysis.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A detailed solution will be provided.\n\n### Solution Derivation\n\nLet $A = (a_{ij})$ and $L = (l_{ij})$ be $n \\times n$ matrices, with $l_{ij}=0$ for $j > i$. The Cholesky factorization is defined by the matrix equation $A = L L^{\\top}$. This corresponds to the scalar equations:\n$$a_{ij} = \\sum_{k=1}^{\\min(i,j)} l_{ik} l_{jk}$$\nWe will derive the flop counts for each of the three required stages.\n\n**1. Flop Count for Cholesky Factorization ($A = L L^{\\top}$)**\n\nThe problem specifies a column-by-column algorithm using inner products. For each column $j = 1, 2, \\dots, n$, we compute the elements $l_{jj}$ and $l_{ij}$ for $i > j$.\n\nFor the diagonal element $l_{jj}$:\nFrom $a_{jj} = \\sum_{k=1}^{j} l_{jk}^2 = \\sum_{k=1}^{j-1} l_{jk}^2 + l_{jj}^2$, we solve for $l_{jj}$:\n$$l_{jj} = \\sqrt{a_{jj} - \\sum_{k=1}^{j-1} l_{jk}^2}$$\n- The summation $\\sum_{k=1}^{j-1} l_{jk}^2$ involves $j-1$ multiplications and $j-2$ additions. (For $j=1$, the sum is empty and its cost is $0$). This is an inner product of a vector of length $j-1$ with itself. The cost is $2(j-1)-1 = 2j-3$ flops for $j>1$.\n- The calculation of $l_{jj}$ requires one subtraction and one square root in addition to the sum.\n- Thus, the flop count to compute $l_{jj}$ is $(2j-3) + 1 + 1 = 2j-1$ flops for $j>1$. For $j=1$, the cost is $1$ flop (a square root). The formula $2j-1$ also yields $1$ for $j=1$, so it is generally applicable.\n\nFor the off-diagonal elements $l_{ij}$ with $i > j$:\nFrom $a_{ij} = \\sum_{k=1}^{j} l_{ik} l_{jk} = \\sum_{k=1}^{j-1} l_{ik} l_{jk} + l_{ij} l_{jj}$, we solve for $l_{ij}$:\n$$l_{ij} = \\frac{1}{l_{jj}} \\left( a_{ij} - \\sum_{k=1}^{j-1} l_{ik} l_{jk} \\right)$$\n- The summation $\\sum_{k=1}^{j-1} l_{ik} l_{jk}$ is an inner product of two vectors of length $j-1$. It requires $j-1$ multiplications and $j-2$ additions, for a total of $2(j-1)-1 = 2j-3$ flops (for $j>1$).\n- The calculation of $l_{ij}$ then requires one subtraction and one division.\n- The flop count to compute a single $l_{ij}$ is $(2j-3) + 1 + 1 = 2j-1$ flops for $j>1$. For $j=1$, the cost is $1$ flop (a division), which is also given by the formula $2j-1$.\n\nThe total flop count for column $j$ is the sum of costs for $l_{jj}$ and the $n-j$ elements $l_{ij}$ for $i=j+1, \\dots, n$.\nCost for column $j$:\n$$C_j = (2j-1) + (n-j)(2j-1) = (1+n-j)(2j-1)$$\n\nThe total flop count for the factorization, $C_{fact}$, is the sum of costs for all columns:\n$$C_{fact} = \\sum_{j=1}^{n} C_j = \\sum_{j=1}^{n} (n-j+1)(2j-1)$$\nLet's expand the term in the sum:\n$(n-j+1)(2j-1) = 2nj - n - 2j^2 + 2j + 2j - 1 = -2j^2 + (2n+3)j - (n+1)$.\nMy previous thought process had a small arithmetic error, the correct expansion is: $(n-j+1)(2j-1) = 2nj - n + 2j - 1 -2j^2 + j = -2j^2 + (2n+3)j - (n+1)$. This calculation appears to be correct.\nLet's perform the summation:\n$$C_{fact} = \\sum_{j=1}^{n} \\left( -2j^2 + (2n+3)j - (n+1) \\right)$$\n$$C_{fact} = -2\\sum_{j=1}^{n} j^2 + (2n+3)\\sum_{j=1}^{n} j - (n+1)\\sum_{j=1}^{n} 1$$\nUsing the standard formulas for sums of powers: $\\sum_{j=1}^{n} 1 = n$, $\\sum_{j=1}^{n} j = \\frac{n(n+1)}{2}$, $\\sum_{j=1}^{n} j^2 = \\frac{n(n+1)(2n+1)}{6}$.\n$$C_{fact} = -2 \\left( \\frac{n(n+1)(2n+1)}{6} \\right) + (2n+3) \\left( \\frac{n(n+1)}{2} \\right) - n(n+1)$$\nFactor out the common term $n(n+1)$:\n$$C_{fact} = n(n+1) \\left[ -\\frac{2n+1}{3} + \\frac{2n+3}{2} - 1 \\right]$$\n$$C_{fact} = n(n+1) \\left[ \\frac{-2(2n+1) + 3(2n+3) - 6}{6} \\right]$$\n$$C_{fact} = n(n+1) \\left[ \\frac{-4n - 2 + 6n + 9 - 6}{6} \\right]$$\n$$C_{fact} = n(n+1) \\left[ \\frac{2n+1}{6} \\right] = \\frac{n(n+1)(2n+1)}{6}$$\nExpanding this polynomial gives:\n$$C_{fact} = \\frac{n(2n^2 + 3n + 1)}{6} = \\frac{2n^3 + 3n^2 + n}{6} = \\frac{n^3}{3} + \\frac{n^2}{2} + \\frac{n}{6}$$\nThis shows that the factorization cost is indeed $\\frac{n^3}{3} + O(n^2)$.\n\n**2. Flop Count for Triangular Solves**\n\n**Forward Substitution ($L y = b$):**\nWe solve for $y_i$ for $i=1, \\dots, n$:\n$$y_i = \\frac{1}{l_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} l_{ij} y_j \\right)$$\nTo find the total flop count, $C_{fwd}$, we sum the operations for each $i$:\n- For $i=1$, $y_1 = b_1 / l_{11}$ requires $1$ division.\n- For each $i > 1$, the sum $\\sum_{j=1}^{i-1} l_{ij} y_j$ requires $i-1$ multiplications and $i-2$ additions. Then, we perform $1$ subtraction and $1$ division.\n- The total cost for computing $y_i$ is $(i-1) + (i-2) + 1 + 1 = 2i-1$ flops for $i > 1$.\nThe total count for forward substitution is:\n$$C_{fwd} = 1 + \\sum_{i=2}^{n} (2i-1) = 1 + \\left( 2\\sum_{i=2}^{n} i - \\sum_{i=2}^{n} 1 \\right)$$\n$$C_{fwd} = 1 + 2\\left(\\frac{n(n+1)}{2} - 1\\right) - (n-1) = 1 + n(n+1) - 2 - n + 1 = n^2+n-n = n^2$$\nAlternatively, counting operation types:\n- Multiplications: $\\sum_{i=2}^{n} (i-1) = \\sum_{k=1}^{n-1} k = \\frac{n(n-1)}{2}$ flops.\n- Additions/Subtractions: $\\sum_{i=2}^{n} ((i-2)+1) = \\frac{n(n-1)}{2}$ flops.\n- Divisions: $\\sum_{i=1}^{n} 1 = n$ flops.\nTotal $C_{fwd} = \\frac{n(n-1)}{2} + \\frac{n(n-1)}{2} + n = n(n-1) + n = n^2-n+n = n^2$.\n\n**Backward Substitution ($L^{\\top} x = y$):**\nWe solve for $x_i$ for $i=n, \\dots, 1$:\n$$x_i = \\frac{1}{l_{ii}} \\left( y_i - \\sum_{j=i+1}^{n} l_{ji} x_j \\right)$$\nThe structure is identical to forward substitution. The number of operations for each row $i$ depends on the number of non-zero entries to the right of the diagonal, which is $n-i$.\nThe total flop count, $C_{bwd}$, is identical by symmetry to the forward substitution case.\n$$C_{bwd} = n^2$$\n\n**3. Total Flop Count**\n\nThe total number of flops to factor $A$ and solve $A x = b$ is the sum of the costs of the three stages:\n$$C_{total} = C_{fact} + C_{fwd} + C_{bwd}$$\n$$C_{total} = \\left( \\frac{2n^3 + 3n^2 + n}{6} \\right) + n^2 + n^2$$\n$$C_{total} = \\frac{2n^3 + 3n^2 + n}{6} + 2n^2$$\nTo combine these into a single expression, we find a common denominator:\n$$C_{total} = \\frac{2n^3 + 3n^2 + n + 12n^2}{6}$$\n$$C_{total} = \\frac{2n^3 + 15n^2 + n}{6}$$\nThis is the simplified closed-form polynomial expression for the exact total number of floating-point operations.",
            "answer": "$$\\boxed{\\frac{2n^3 + 15n^2 + n}{6}}$$"
        },
        {
            "introduction": "While direct factorization is powerful, its computational expense can be prohibitive for the large-scale systems arising from PDE discretizations. A highly effective alternative is to use an approximate factorization as a preconditioner to accelerate an iterative solver like the Conjugate Gradient method. This practice guides you through the construction of an Incomplete Cholesky (IC) factorization for a model problem, allowing you to witness and quantify firsthand the dramatic improvement in convergence that preconditioning provides .",
            "id": "3370799",
            "problem": "Consider the model elliptic boundary value problem $-\\Delta u = f$ on the unit square with homogeneous Dirichlet boundary conditions. Using the standard five-point finite difference stencil on a uniform grid with $2 \\times 2$ interior points in lexicographic (row-wise) ordering, the resulting symmetric positive-definite (SPD) linear system has coefficient matrix $A \\in \\mathbb{R}^{4 \\times 4}$ given by\n$$\nA \\;=\\; \\begin{pmatrix}\n4 & -1 & -1 & 0 \\\\\n-1 & 4 & 0 & -1 \\\\\n-1 & 0 & 4 & -1 \\\\\n0 & -1 & -1 & 4\n\\end{pmatrix}.\n$$\nFor simplicity, the uniform grid spacing scaling is absorbed into $A$; this does not affect the analysis below. Let the right-hand side be $b = (1,0,0,0)^{\\top}$ and the initial guess be $x_0 = 0$. Define the Incomplete Cholesky factorization with zero fill (IC$(0)$) as a lower-triangular matrix $L$ conforming to the sparsity pattern of the lower triangle of $A$ such that the preconditioner $M = L L^{\\top}$ approximates $A$. Use left preconditioning, meaning the Preconditioned Conjugate Gradient (PCG) method applies $M^{-1}$ to residuals.\n\nTasks:\n- Construct $L$ for IC$(0)$ of $A$ under the natural sparsity pattern of the lower triangle of $A$.\n- Perform one iteration of the unpreconditioned Conjugate Gradient (CG) method and one iteration of left-preconditioned CG (PCG) using $M^{-1}$, both starting from $x_0 = 0$. Denote the resulting residuals by $r_1^{\\mathrm{unpre}}$ and $r_1^{\\mathrm{pre}}$, respectively.\n- Compute the Euclidean norms $\\|r_1^{\\mathrm{unpre}}\\|_2$ and $\\|r_1^{\\mathrm{pre}}\\|_2$.\n- Quantify the improvement of PCG over unpreconditioned CG by the single scalar factor $\\mathcal{I} = \\|r_1^{\\mathrm{unpre}}\\|_2 / \\|r_1^{\\mathrm{pre}}\\|_2$.\n\nExpress the final answer as a single exact analytic expression. No rounding is required, and no units are to be included in the final expression.",
            "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information to perform the requested calculations. It is a standard exercise in numerical linear algebra. We proceed to the solution.\n\nThe problem asks for the improvement factor $\\mathcal{I} = \\|r_1^{\\mathrm{unpre}}\\|_2 / \\|r_1^{\\mathrm{pre}}\\|_2$ after one iteration of the unpreconditioned and preconditioned Conjugate Gradient methods. The given matrix is\n$$\nA = \\begin{pmatrix}\n4 & -1 & -1 & 0 \\\\\n-1 & 4 & 0 & -1 \\\\\n-1 & 0 & 4 & -1 \\\\\n0 & -1 & -1 & 4\n\\end{pmatrix}\n$$\nThe right-hand side is $b = \\begin{pmatrix} 1 & 0 & 0 & 0 \\end{pmatrix}^{\\top}$ and the initial guess is $x_0 = \\begin{pmatrix} 0 & 0 & 0 & 0 \\end{pmatrix}^{\\top}$.\n\nFirst, we construct the Incomplete Cholesky factorization with zero fill-in (IC($0$)), $L$. The matrix $L$ must have the same sparsity pattern as the lower triangle of $A$.\n$$\nL = \\begin{pmatrix}\nl_{11} & 0 & 0 & 0 \\\\\nl_{21} & l_{22} & 0 & 0 \\\\\nl_{31} & 0 & l_{33} & 0 \\\\\n0 & l_{42} & l_{43} & l_{44}\n\\end{pmatrix}\n$$\nThe entries of $L$ are computed such that $(LL^{\\top})_{ij} \\approx A_{ij}$. The IC($0$) algorithm gives:\n$l_{11} = \\sqrt{a_{11}} = \\sqrt{4} = 2$.\n$l_{21} = a_{21} / l_{11} = -1 / 2$.\n$l_{31} = a_{31} / l_{11} = -1 / 2$.\n$l_{22} = \\sqrt{a_{22} - l_{21}^2} = \\sqrt{4 - (-1/2)^2} = \\sqrt{4 - 1/4} = \\sqrt{15/4} = \\frac{\\sqrt{15}}{2}$.\n$l_{33} = \\sqrt{a_{33} - l_{31}^2} = \\sqrt{4 - (-1/2)^2} = \\sqrt{15/4} = \\frac{\\sqrt{15}}{2}$.\n$l_{42} = (a_{42} - l_{41}l_{21}) / l_{22} = a_{42}/l_{22}$ (since $l_{41}=0$) $= -1 / (\\frac{\\sqrt{15}}{2}) = -\\frac{2}{\\sqrt{15}}$.\n$l_{43} = (a_{43} - l_{41}l_{31} - l_{42}l_{32}) / l_{33} = a_{43}/l_{33}$ (since $l_{41}=0, l_{32}=0$) $= -1 / (\\frac{\\sqrt{15}}{2}) = -\\frac{2}{\\sqrt{15}}$.\n$l_{44} = \\sqrt{a_{44} - (l_{42}^2 + l_{43}^2)} = \\sqrt{4 - (-\\frac{2}{\\sqrt{15}})^2 - (-\\frac{2}{\\sqrt{15}})^2} = \\sqrt{4 - \\frac{4}{15} - \\frac{4}{15}} = \\sqrt{\\frac{60-8}{15}} = \\sqrt{\\frac{52}{15}} = \\frac{2\\sqrt{13}}{\\sqrt{15}}$.\nSo, the IC($0$) factor is\n$$\nL = \\begin{pmatrix}\n2 & 0 & 0 & 0 \\\\\n-1/2 & \\sqrt{15}/2 & 0 & 0 \\\\\n-1/2 & 0 & \\sqrt{15}/2 & 0 \\\\\n0 & -2/\\sqrt{15} & -2/\\sqrt{15} & 2\\sqrt{13}/\\sqrt{15}\n\\end{pmatrix}\n$$\nThe preconditioner is $M = LL^{\\top}$.\n\nNext, we perform one iteration of unpreconditioned Conjugate Gradient (CG).\nStarting with $x_0 = 0$, the initial residual is $r_0 = b - Ax_0 = b = \\begin{pmatrix} 1 & 0 & 0 & 0 \\end{pmatrix}^{\\top}$.\nThe initial search direction is $p_0 = r_0$.\nThe step size $\\alpha_0$ is $\\alpha_0 = \\frac{r_0^{\\top} r_0}{p_0^{\\top} A p_0}$.\n$r_0^{\\top} r_0 = 1^2 = 1$.\n$A p_0 = A r_0 = \\begin{pmatrix} 4 & -1 & -1 & 0 \\\\ -1 & 4 & 0 & -1 \\\\ -1 & 0 & 4 & -1 \\\\ 0 & -1 & -1 & 4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ -1 \\\\ -1 \\\\ 0 \\end{pmatrix}$.\n$p_0^{\\top} A p_0 = r_0^{\\top} (A r_0) = \\begin{pmatrix} 1 & 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ -1 \\\\ -1 \\\\ 0 \\end{pmatrix} = 4$.\nSo, $\\alpha_0 = 1/4$.\nThe first iterate is $x_1 = x_0 + \\alpha_0 p_0 = \\frac{1}{4} \\begin{pmatrix} 1 & 0 & 0 & 0 \\end{pmatrix}^{\\top}$.\nThe new residual is $r_1^{\\mathrm{unpre}} = r_0 - \\alpha_0 A p_0 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\frac{1}{4} \\begin{pmatrix} 4 \\\\ -1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1/4 \\\\ 1/4 \\\\ 0 \\end{pmatrix}$.\nThe Euclidean norm is $\\|r_1^{\\mathrm{unpre}}\\|_2 = \\sqrt{0^2 + (1/4)^2 + (1/4)^2 + 0^2} = \\sqrt{2/16} = \\sqrt{1/8} = \\frac{1}{2\\sqrt{2}}$.\n\nNow, we perform one iteration of Preconditioned Conjugate Gradient (PCG).\nThe initial residual is $r_0 = b = \\begin{pmatrix} 1 & 0 & 0 & 0 \\end{pmatrix}^{\\top}$.\nWe solve the preconditioning system $M z_0 = r_0$, which is $LL^{\\top}z_0=r_0$.\nFirst, solve $Ly=r_0$ by forward substitution:\n$2y_1 = 1 \\implies y_1=1/2$.\n$-\\frac{1}{2}y_1 + \\frac{\\sqrt{15}}{2}y_2 = 0 \\implies y_2 = \\frac{y_1}{\\sqrt{15}} = \\frac{1}{2\\sqrt{15}}$.\n$-\\frac{1}{2}y_1 + \\frac{\\sqrt{15}}{2}y_3 = 0 \\implies y_3 = \\frac{y_1}{\\sqrt{15}} = \\frac{1}{2\\sqrt{15}}$.\n$-\\frac{2}{\\sqrt{15}}y_2 - \\frac{2}{\\sqrt{15}}y_3 + \\frac{2\\sqrt{13}}{\\sqrt{15}}y_4 = 0 \\implies \\sqrt{13}y_4 = y_2+y_3 = \\frac{1}{\\sqrt{15}} \\implies y_4 = \\frac{1}{\\sqrt{13}\\sqrt{15}}$.\nNext, solve $L^{\\top}z_0=y$ by backward substitution:\n$\\frac{2\\sqrt{13}}{\\sqrt{15}}z_{04} = y_4 = \\frac{1}{\\sqrt{13}\\sqrt{15}} \\implies 2\\sqrt{13}z_{04} = \\frac{1}{\\sqrt{13}} \\implies z_{04} = \\frac{1}{26}$.\n$\\frac{\\sqrt{15}}{2}z_{03} - \\frac{2}{\\sqrt{15}}z_{04} = y_3 = \\frac{1}{2\\sqrt{15}} \\implies 15z_{03}-4z_{04} = 1 \\implies 15z_{03} = 1+4/26 = 15/13 \\implies z_{03} = 1/13$.\nBy symmetry, $z_{02} = 1/13$.\n$2z_{01} - \\frac{1}{2}z_{02} - \\frac{1}{2}z_{03} = y_1 = 1/2 \\implies 2z_{01} = 1/2 + \\frac{1}{2}(1/13) + \\frac{1}{2}(1/13) = 1/2+1/13 = 15/26 \\implies z_{01}=15/52$.\nSo, $z_0 = \\begin{pmatrix} 15/52 & 1/13 & 1/13 & 1/26 \\end{pmatrix}^{\\top} = \\frac{1}{52}\\begin{pmatrix} 15 & 4 & 4 & 2 \\end{pmatrix}^{\\top}$.\nThe initial search direction is $p_0 = z_0$.\nThe step size is $\\alpha_0 = \\frac{r_0^{\\top} z_0}{p_0^{\\top} A p_0}$.\n$r_0^{\\top} z_0 = \\begin{pmatrix} 1 & 0 & 0 & 0 \\end{pmatrix} z_0 = z_{01} = 15/52$.\n$A p_0 = A z_0 = \\frac{1}{52}\\begin{pmatrix} 4 & -1 & -1 & 0 \\\\ -1 & 4 & 0 & -1 \\\\ -1 & 0 & 4 & -1 \\\\ 0 & -1 & -1 & 4 \\end{pmatrix} \\begin{pmatrix} 15 \\\\ 4 \\\\ 4 \\\\ 2 \\end{pmatrix} = \\frac{1}{52}\\begin{pmatrix} 60-4-4 \\\\ -15+16-2 \\\\ -15+16-2 \\\\ -4-4+8 \\end{pmatrix} = \\frac{1}{52}\\begin{pmatrix} 52 \\\\ -1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1/52 \\\\ -1/52 \\\\ 0 \\end{pmatrix}$.\n$p_0^{\\top} A p_0 = z_0^{\\top}(Az_0) = \\frac{1}{52}\\begin{pmatrix} 15 & 4 & 4 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1/52 \\\\ -1/52 \\\\ 0 \\end{pmatrix} = \\frac{1}{52}(15 - \\frac{4}{52} - \\frac{4}{52}) = \\frac{1}{52}(15-\\frac{2}{13}) = \\frac{1}{52}(\\frac{195-2}{13}) = \\frac{193}{676}$.\n$\\alpha_0 = \\frac{15/52}{193/676} = \\frac{15}{52}\\frac{676}{193} = \\frac{15 \\times 13}{193} = \\frac{195}{193}$.\nThe new residual is $r_1^{\\mathrm{pre}} = r_0 - \\alpha_0 A p_0 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\frac{195}{193}\\begin{pmatrix} 1 \\\\ -1/52 \\\\ -1/52 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1-195/193 \\\\ 195/(193 \\cdot 52) \\\\ 195/(193 \\cdot 52) \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -2/193 \\\\ 195/10036 \\\\ 195/10036 \\\\ 0 \\end{pmatrix}$.\nThe norm is $\\|r_1^{\\mathrm{pre}}\\|_2 = \\sqrt{(-\\frac{2}{193})^2 + (\\frac{195}{193 \\cdot 52})^2 + (\\frac{195}{193 \\cdot 52})^2}$.\nSince $\\frac{195}{52} = \\frac{15 \\cdot 13}{4 \\cdot 13} = \\frac{15}{4}$, we have\n$\\|r_1^{\\mathrm{pre}}\\|_2^2 = \\frac{1}{193^2} \\left( (-2)^2 + 2 \\cdot (\\frac{15}{4})^2 \\right) = \\frac{1}{193^2} \\left( 4 + 2 \\frac{225}{16} \\right) = \\frac{1}{193^2} \\left( 4 + \\frac{225}{8} \\right) = \\frac{1}{193^2} \\left( \\frac{32+225}{8} \\right) = \\frac{257}{8 \\cdot 193^2}$.\nSo, $\\|r_1^{\\mathrm{pre}}\\|_2 = \\sqrt{\\frac{257}{8 \\cdot 193^2}} = \\frac{\\sqrt{257}}{193\\sqrt{8}} = \\frac{\\sqrt{257}}{193 \\cdot 2\\sqrt{2}}$.\n\nFinally, we compute the improvement factor $\\mathcal{I}$.\n$\\mathcal{I} = \\frac{\\|r_1^{\\mathrm{unpre}}\\|_2}{\\|r_1^{\\mathrm{pre}}\\|_2} = \\frac{1/(2\\sqrt{2})}{\\sqrt{257}/(193 \\cdot 2\\sqrt{2})} = \\frac{1}{2\\sqrt{2}} \\cdot \\frac{193 \\cdot 2\\sqrt{2}}{\\sqrt{257}} = \\frac{193}{\\sqrt{257}}$.\nThe numbers $193$ and $257$ are prime, so this expression cannot be further simplified.",
            "answer": "$$\\boxed{\\frac{193}{\\sqrt{257}}}$$"
        },
        {
            "introduction": "The prohibitive $O(n^3)$ cost of dense factorization can be overcome for the sparse matrices that typically arise from PDEs by exploiting their underlying structure. This problem introduces the powerful concept of nested dissection, a matrix reordering strategy rooted in graph theory, which minimizes fill-in and exposes massive parallelism. By analyzing a simplified performance model, you will explore how these advanced techniques make direct solves feasible for large-scale problems and predict the potential speedup on parallel architectures .",
            "id": "3370792",
            "problem": "Consider the symmetric positive-definite matrix $A$ arising from the standard five-point finite difference discretization of the Poisson equation on the unit square with homogeneous Dirichlet boundary conditions on an $n \\times n$ interior grid, so the number of unknowns is $N = n^{2}$. We apply the Cholesky factorization of $A$ using a nested dissection ordering defined by recursive bisection with planar separators of cardinality proportional to the grid width. Use graph-theoretic reasoning on the grid graph of the discretization to analyze the elimination tree and to design a parallel schedule.\n\nAdopt the following modeling assumptions, all of which are standard abstractions in the analysis of sparse direct solvers:\n\n- At nested dissection level $l \\in \\{0,1,\\dots,k-1\\}$ with $k = \\log_{2}(n)$ (assume $n$ is a power of two), there are $2^{l}$ disjoint separators, each of size $s_{l} = n / 2^{l}$.\n- The work (total operation count) to factor a separator of order $s$ is proportional to $s^{3}$, and, under fine-grained intra-front parallelism, the span (critical-path time in the Directed Acyclic Graph (DAG) of tasks) for that separator is proportional to $s^{2}$. Take the proportionality constants to be $1$ by choice of time units.\n- Separators at the same level are mutually independent and can be processed concurrently; the next levelâ€™s separators can be processed only after their children are completed, consistent with the elimination tree.\n- With $p$ identical cores and an ideal greedy scheduler with no overhead, the parallel time is $T_{p} = \\max\\{W/p, S\\}$, where $W$ is the total work and $S$ is the span.\n\nTasks:\n\n1. Using graph theory on the grid graph, determine the depth of the elimination tree (measured as the number of nested dissection levels from leaves to the root) under this recursive bisection scheme.\n2. Using the above model, derive closed-form expressions (as finite geometric sums) for the total work $W$ and the span $S$ as functions of $n$.\n3. Design a level-synchronous parallel schedule that minimizes serialization by exploiting both inter-separator and intra-front concurrency, and express the predicted speedup $\\mathrm{Speedup}(p) = W / T_{p}$ in terms of $n$ and $p$.\n4. For $n = 256$ and $p = 1536$, compute the predicted speedup. Provide your final answer as a single exact number (no rounding required).",
            "solution": "The problem statement is first subjected to a validation process.\n\nThe givens extracted from the problem statement are:\n- The matrix $A$ is symmetric positive-definite.\n- The matrix arises from a standard five-point finite difference discretization of the Poisson equation on a unit square grid with homogeneous Dirichlet boundary conditions.\n- The interior grid is of size $n \\times n$, leading to $N = n^{2}$ unknowns.\n- The factorization method is Cholesky factorization with a nested dissection ordering.\n- The parameter $n$ is a power of two, and $k = \\log_{2}(n)$.\n- The nested dissection process consists of levels $l \\in \\{0, 1, \\dots, k-1\\}$.\n- For each level $l$, there are $2^{l}$ disjoint separators, each of size $s_{l} = n / 2^{l}$.\n- The computational work to factor a separator of size $s$ is modeled as $s^{3}$.\n- The parallel span (critical path time) to factor a separator of size $s$ is modeled as $s^{2}$.\n- Separators at the same level can be processed concurrently.\n- The processing order respects the dependencies of the elimination tree (children separators must be eliminated before their parent).\n- The parallel execution time on $p$ identical cores is modeled by $T_{p} = \\max\\{W/p, S\\}$, where $W$ is the total work and $S$ is the total span.\n\nThe problem is evaluated for validity based on these givens.\n1.  **Scientific Grounding**: The problem is well-grounded in the field of numerical linear algebra, specifically the analysis of sparse direct solvers for systems arising from partial differential equations. The nested dissection algorithm, the use of Cholesky factorization for symmetric positive-definite systems, the modeling of work and span as $s^3$ and $s^2$ for a separator of size $s$ in a 2D problem, and the parallel performance model are all standard and established concepts in scientific computing.\n2.  **Well-Posedness and Consistency**: The problem is well-posed. It provides a complete and internally consistent set of assumptions and definitions. The tasks are specific mathematical derivations based entirely on this provided model. A unique solution can be determined for each task. The assumption that $n$ is a power of two simplifies the analysis, which is a common pedagogical technique.\n3.  **Objectivity**: The problem is stated in precise, objective, and formal mathematical language, free of any subjective or ambiguous terms.\n\nThe problem is therefore deemed **valid**, as it describes a standard, albeit simplified, theoretical model used for analyzing the performance of a classical algorithm in computational science. We proceed with the solution.\n\n**Task 1: Depth of the elimination tree**\n\nThe nested dissection algorithm recursively bisects the grid. The problem describes a process with $k = \\log_{2}(n)$ levels of separators, indexed by $l$ from $0$ to $k-1$. Level $l=0$ corresponds to the first and largest separator, which partitions the entire grid. Level $l=k-1$ corresponds to the final set of smallest separators. In the Cholesky factorization process, the elimination order is the reverse of the dissection order. Nodes in the smallest, most deeply nested subdomains are eliminated first, followed by the separators at level $l=k-1$, then level $l=k-2$, and so on, until the root separator at level $l=0$ is eliminated last.\n\nThe elimination tree represents this dependency structure. The nodes of the grid that are not part of any separator form the leaves of the tree. The separators themselves form the internal nodes of the tree. The depth of the elimination tree is the length of the longest path from any leaf node to the root. In this model, the separators are organized into $k$ distinct levels. A path from a leaf to the root must pass through one separator at each of these $k$ levels. Therefore, the depth of the tree, measured as the number of nested dissection levels from the lowest level separators to the root, is $k$.\n\nGiven $k = \\log_{2}(n)$, the depth of the elimination tree is $\\log_{2}(n)$.\n\n**Task 2: Total work $W$ and span $S$**\n\nThe total work $W$ is the sum of the work performed for all separators at all levels. At a given level $l$, there are $2^{l}$ separators, and the size of each is $s_{l} = n / 2^{l}$. The work for a single separator of size $s_{l}$ is $s_{l}^{3}$.\n\nThe total work at level $l$, denoted $W_{l}$, is the number of separators multiplied by the work per separator:\n$$W_{l} = 2^{l} \\times s_{l}^{3} = 2^{l} \\times \\left(\\frac{n}{2^{l}}\\right)^{3} = 2^{l} \\frac{n^{3}}{2^{3l}} = \\frac{n^{3}}{2^{2l}} = n^{3}\\left(\\frac{1}{4}\\right)^{l}$$\nThe total work $W$ is the sum of $W_{l}$ over all levels $l \\in \\{0, 1, \\dots, k-1\\}$:\n$$W = \\sum_{l=0}^{k-1} W_{l} = \\sum_{l=0}^{k-1} n^{3}\\left(\\frac{1}{4}\\right)^{l} = n^{3} \\sum_{l=0}^{k-1} \\left(\\frac{1}{4}\\right)^{l}$$\nThis is a finite geometric series with $k$ terms, first term $a=1$, and ratio $r=1/4$. The sum is $\\frac{1-r^{k}}{1-r}$.\n$$W = n^{3} \\left( \\frac{1 - (1/4)^{k}}{1 - 1/4} \\right) = n^{3} \\left( \\frac{1 - 1/4^{k}}{3/4} \\right) = \\frac{4}{3}n^{3}(1 - 1/4^{k})$$\nSince $k = \\log_{2}(n)$, we have $n = 2^{k}$, so $n^{2} = (2^{k})^{2} = 4^{k}$. Substituting this into the expression for $W$:\n$$W = \\frac{4}{3}n^{3}\\left(1 - \\frac{1}{n^{2}}\\right) = \\frac{4}{3}(n^{3} - n)$$\n\nThe span $S$ is the critical path length of the computation. Due to the dependencies in the elimination tree, the factorization of separators at level $l$ cannot begin until the factorizations for level $l+1$ are complete. The total span is the sum of the spans for one separator at each level along a single path from the leaves to the root. The span for a separator of size $s_l$ is $s_l^2$.\n\nThe span contribution from level $l$, denoted $S_{l}$, is:\n$$S_{l} = s_{l}^{2} = \\left(\\frac{n}{2^{l}}\\right)^{2} = \\frac{n^{2}}{2^{2l}} = n^{2}\\left(\\frac{1}{4}\\right)^{l}$$\nThe total span $S$ is the sum of $S_{l}$ over all levels $l \\in \\{0, 1, \\dots, k-1\\}$:\n$$S = \\sum_{l=0}^{k-1} S_{l} = \\sum_{l=0}^{k-1} n^{2}\\left(\\frac{1}{4}\\right)^{l} = n^{2} \\sum_{l=0}^{k-1} \\left(\\frac{1}{4}\\right)^{l}$$\nUsing the same geometric series sum as before:\n$$S = n^{2} \\left( \\frac{1 - (1/4)^{k}}{1 - 1/4} \\right) = \\frac{4}{3}n^{2}(1 - 1/4^{k}) = \\frac{4}{3}n^{2}\\left(1 - \\frac{1}{n^{2}}\\right) = \\frac{4}{3}(n^{2} - 1)$$\n\nThe closed-form expressions asked for are:\n$W(n) = n^{3} \\sum_{l=0}^{\\log_{2}(n)-1} (1/4)^l = \\frac{4}{3}(n^{3} - n)$\n$S(n) = n^{2} \\sum_{l=0}^{\\log_{2}(n)-1} (1/4)^l = \\frac{4}{3}(n^{2} - 1)$\n\n**Task 3: Parallel schedule and speedup**\n\nThe parallel time on $p$ processors is given by $T_{p} = \\max\\{W/p, S\\}$. The speedup is defined as $\\mathrm{Speedup}(p) = W / T_{p}$. Substituting the expression for $T_{p}$:\n$$\\mathrm{Speedup}(p) = \\frac{W}{\\max\\{W/p, S\\}}$$\nWe can substitute the derived expressions for $W$ and $S$:\n$$\\mathrm{Speedup}(p) = \\frac{\\frac{4}{3}(n^{3} - n)}{\\max\\left\\{\\frac{\\frac{4}{3}(n^{3} - n)}{p}, \\frac{4}{3}(n^{2} - 1)\\right\\}}$$\nThe common factor of $4/3$ can be canceled from the numerator and the terms inside the $\\max$ function:\n$$\\mathrm{Speedup}(p) = \\frac{n^{3} - n}{\\max\\left\\{\\frac{n^{3} - n}{p}, n^{2} - 1\\right\\}}$$\nFactoring the expressions, we note that $n^{3} - n = n(n^{2} - 1)$. For $n>1$, the term $n^{2}-1$ is positive and can be factored out of the $\\max$ function:\n$$\\mathrm{Speedup}(p) = \\frac{n(n^{2} - 1)}{\\max\\left\\{\\frac{n(n^{2} - 1)}{p}, 1 \\cdot (n^{2} - 1)\\right\\}} = \\frac{n(n^{2} - 1)}{(n^{2} - 1) \\max\\left\\{\\frac{n}{p}, 1\\right\\}}$$\nCanceling the $(n^{2} - 1)$ term:\n$$\\mathrm{Speedup}(p) = \\frac{n}{\\max\\{n/p, 1\\}}$$\nThis expression can be interpreted piecewise. If $p \\le n$, then $n/p \\ge 1$, so $\\max\\{n/p, 1\\} = n/p$, and $\\mathrm{Speedup}(p) = n / (n/p) = p$. If $p > n$, then $n/p < 1$, so $\\max\\{n/p, 1\\} = 1$, and $\\mathrm{Speedup}(p) = n/1 = n$.\nThis is equivalent to the expression $\\mathrm{Speedup}(p) = \\min\\{p, n\\}$. The quantity $W/S = \\frac{n(n^2-1)}{n^2-1} = n$ represents the average parallelism of the algorithm.\n\n**Task 4: Compute speedup for $n = 256$ and $p = 1536$**\n\nWe use the derived formula for speedup with the given values $n = 256$ and $p = 1536$.\n$$\\mathrm{Speedup}(1536) = \\min\\{1536, 256\\}$$\nThe minimum of these two values is $256$.\n$$\\mathrm{Speedup}(1536) = 256$$\nThis result indicates that the speedup is limited not by the number of processors, but by the inherent sequential bottleneck (span) of the algorithm. The maximum achievable speedup for this problem, according to the model, is $n$.",
            "answer": "$$\\boxed{256}$$"
        }
    ]
}