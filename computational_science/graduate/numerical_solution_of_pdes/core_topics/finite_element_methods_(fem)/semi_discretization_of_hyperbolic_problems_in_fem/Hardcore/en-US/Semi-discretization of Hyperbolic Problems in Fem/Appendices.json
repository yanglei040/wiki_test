{
    "hands_on_practices": [
        {
            "introduction": "Before assembling global systems for complex problems, it is crucial to master the mechanics of a single finite element. This exercise  guides you through the foundational workflow of the Finite Element Method, from defining basis functions on a simple reference element to mapping them and their gradients to a physical element in the mesh. Understanding this isoparametric concept is the key to implementing and analyzing finite element schemes for any PDE.",
            "id": "3441775",
            "problem": "Consider the constant-coefficient linear hyperbolic partial differential equation (PDE) $u_{t} + \\boldsymbol{c}\\cdot \\nabla u = 0$ on a two-dimensional polygonal domain, where $\\boldsymbol{c} = (a,b)$ is constant. Let a conforming triangulation be given, and consider a single triangular element $K$ with vertices $\\boldsymbol{x}_{1} = (x_{1},y_{1})$, $\\boldsymbol{x}_{2} = (x_{2},y_{2})$, and $\\boldsymbol{x}_{3} = (x_{3},y_{3})$. Assume the vertices are labeled so that the element mapping defined below is orientation preserving.\n\nYou will use the continuous piecewise-linear Lagrange finite element space $\\mathbb{P}_{1}$ on $K$. Let the reference triangle be $\\widehat{K} = \\{(\\xi,\\eta)\\,:\\,\\xi \\ge 0,\\ \\eta \\ge 0,\\ \\xi+\\eta \\le 1\\}$ with vertices at $(0,0)$, $(1,0)$, and $(0,1)$.\n\nTasks:\n1) Construct the canonical nodal Lagrange basis functions on the reference element $\\widehat{K}$ for $\\mathbb{P}_{1}$ and justify their form from first principles (interpolation conditions at reference vertices).\n2) Describe the isoparametric mapping from $\\widehat{K}$ to the physical element $K$ that is affine and nodally exact. Define its Jacobian matrix and interpret it geometrically.\n3) Using only the multivariable chain rule for differentiable mappings as your base principle, state precisely how gradients of basis functions transform under the element mapping and express the physical gradients of the $\\mathbb{P}_{1}$ basis on $K$ in terms of the Jacobian.\n4) In the standard Galerkin semi-discretization of the PDE on $K$, the local advection matrix $A_{e}$ has entries $(A_{e})_{ij} = \\int_{K} (\\boldsymbol{c}\\cdot \\nabla \\varphi_{j})\\,\\varphi_{i}\\, \\mathrm{d}\\boldsymbol{x}$, where $\\{\\varphi_{i}\\}_{i=1}^{3}$ are the physical $\\mathbb{P}_{1}$ basis functions associated with the vertices $\\boldsymbol{x}_{i}$. Using the ingredients from parts 1)–3), derive a closed-form expression for the specific entry $(A_{e})_{12}$ in terms of $a$, $b$, and the vertex coordinates $(x_{1},y_{1})$, $(x_{2},y_{2})$, $(x_{3},y_{3})$ only.\n\nExpress your final answer as a single closed-form analytic expression. No rounding is required and no units are needed.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and self-contained. It presents a standard, multi-part derivation in the field of numerical analysis for partial differential equations, specifically the Finite Element Method (FEM) for linear hyperbolic problems. All terms are standard and unambiguously defined. The problem is therefore valid, and a solution will be furnished. The derivation will proceed through the four specified tasks.\n\nThe governing partial differential equation is the linear advection equation, $u_{t} + \\boldsymbol{c}\\cdot \\nabla u = 0$, where the advection velocity $\\boldsymbol{c}=(a,b)$ is a constant vector in $\\mathbb{R}^{2}$. We analyze the spatial discretization on a single triangular element $K$ with vertices $\\boldsymbol{x}_{1} = (x_{1},y_{1})$, $\\boldsymbol{x}_{2} = (x_{2},y_{2})$, and $\\boldsymbol{x}_{3} = (x_{3},y_{3})$. The finite element space is the space of continuous piecewise-linear polynomials, denoted $\\mathbb{P}_{1}(K)$.\n\n**1) Canonical Nodal Basis Functions on the Reference Element**\n\nThe reference finite element is the triangle $\\widehat{K} = \\{(\\xi,\\eta) \\in \\mathbb{R}^{2} \\,:\\, \\xi \\ge 0,\\ \\eta \\ge 0,\\ \\xi+\\eta \\le 1\\}$, with vertices $\\widehat{\\boldsymbol{x}}_{1}=(0,0)$, $\\widehat{\\boldsymbol{x}}_{2}=(1,0)$, and $\\widehat{\\boldsymbol{x}}_{3}=(0,1)$. A function $\\widehat{\\varphi}(\\xi,\\eta)$ in the space $\\mathbb{P}_{1}(\\widehat{K})$ must be a linear polynomial of the form $\\widehat{\\varphi}(\\xi,\\eta) = C_{1} + C_{2}\\xi + C_{3}\\eta$ for some constants $C_{1}, C_{2}, C_{3} \\in \\mathbb{R}$.\n\nThe canonical nodal basis functions $\\{\\widehat{\\varphi}_{i}\\}_{i=1}^{3}$ are defined by the interpolatory (or \"nodal\") property $\\widehat{\\varphi}_{i}(\\widehat{\\boldsymbol{x}}_{j}) = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. We construct each basis function by solving a small system of linear equations.\n\nFor $\\widehat{\\varphi}_{1}(\\xi,\\eta)$:\n- $\\widehat{\\varphi}_{1}(\\widehat{\\boldsymbol{x}}_{1}) = \\widehat{\\varphi}_{1}(0,0) = 1 \\implies C_{1} + C_{2}(0) + C_{3}(0) = 1 \\implies C_{1}=1$.\n- $\\widehat{\\varphi}_{1}(\\widehat{\\boldsymbol{x}}_{2}) = \\widehat{\\varphi}_{1}(1,0) = 0 \\implies C_{1} + C_{2}(1) + C_{3}(0) = 0 \\implies 1+C_{2}=0 \\implies C_{2}=-1$.\n- $\\widehat{\\varphi}_{1}(\\widehat{\\boldsymbol{x}}_{3}) = \\widehat{\\varphi}_{1}(0,1) = 0 \\implies C_{1} + C_{2}(0) + C_{3}(1) = 0 \\implies 1+C_{3}=0 \\implies C_{3}=-1$.\nThus, $\\widehat{\\varphi}_{1}(\\xi,\\eta) = 1 - \\xi - \\eta$.\n\nFor $\\widehat{\\varphi}_{2}(\\xi,\\eta)$:\n- $\\widehat{\\varphi}_{2}(\\widehat{\\boldsymbol{x}}_{1}) = \\widehat{\\varphi}_{2}(0,0) = 0 \\implies C_{1} = 0$.\n- $\\widehat{\\varphi}_{2}(\\widehat{\\boldsymbol{x}}_{2}) = \\widehat{\\varphi}_{2}(1,0) = 1 \\implies C_{1} + C_{2} = 1 \\implies C_{2}=1$.\n- $\\widehat{\\varphi}_{2}(\\widehat{\\boldsymbol{x}}_{3}) = \\widehat{\\varphi}_{2}(0,1) = 0 \\implies C_{1} + C_{3} = 0 \\implies C_{3}=0$.\nThus, $\\widehat{\\varphi}_{2}(\\xi,\\eta) = \\xi$.\n\nFor $\\widehat{\\varphi}_{3}(\\xi,\\eta)$:\n- $\\widehat{\\varphi}_{3}(\\widehat{\\boldsymbol{x}}_{1}) = \\widehat{\\varphi}_{3}(0,0) = 0 \\implies C_{1} = 0$.\n- $\\widehat{\\varphi}_{3}(\\widehat{\\boldsymbol{x}}_{2}) = \\widehat{\\varphi}_{3}(1,0) = 0 \\implies C_{1} + C_{2} = 0 \\implies C_{2}=0$.\n- $\\widehat{\\varphi}_{3}(\\widehat{\\boldsymbol{x}}_{3}) = \\widehat{\\varphi}_{3}(0,1) = 1 \\implies C_{1} + C_{3} = 1 \\implies C_{3}=1$.\nThus, $\\widehat{\\varphi}_{3}(\\xi,\\eta) = \\eta$.\n\nThese three functions, $\\widehat{\\varphi}_{1}(\\xi,\\eta)=1-\\xi-\\eta$, $\\widehat{\\varphi}_{2}(\\xi,\\eta)=\\xi$, and $\\widehat{\\varphi}_{3}(\\xi,\\eta)=\\eta$, constitute the basis for $\\mathbb{P}_{1}(\\widehat{K})$. They are also known as the barycentric coordinates on the reference element.\n\n**2) Isoparametric Mapping and its Jacobian**\n\nThe isoparametric mapping $\\boldsymbol{F}: \\widehat{K} \\to K$ relates points $\\widehat{\\boldsymbol{x}}=(\\xi,\\eta)$ in the reference element to points $\\boldsymbol{x}=(x,y)$ in the physical element. It uses the same basis functions for mapping the geometry as for representing the solution. The mapping is defined by\n$$\n\\boldsymbol{x} = \\boldsymbol{F}(\\widehat{\\boldsymbol{x}}) = \\sum_{i=1}^{3} \\boldsymbol{x}_{i} \\widehat{\\varphi}_{i}(\\widehat{\\boldsymbol{x}})\n$$\nSubstituting the basis functions from part 1, we obtain\n$$\n\\boldsymbol{x} = \\boldsymbol{x}_{1}(1-\\xi-\\eta) + \\boldsymbol{x}_{2}\\xi + \\boldsymbol{x}_{3}\\eta\n$$\nThis can be rearranged into an affine transformation:\n$$\n\\boldsymbol{x} = \\boldsymbol{x}_{1} + (\\boldsymbol{x}_{2}-\\boldsymbol{x}_{1})\\xi + (\\boldsymbol{x}_{3}-\\boldsymbol{x}_{1})\\eta\n$$\nThe Jacobian matrix of this mapping, $J$, is the matrix of its first-order partial derivatives:\n$$\nJ = \\frac{\\partial \\boldsymbol{x}}{\\partial \\widehat{\\boldsymbol{x}}} = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi}  \\frac{\\partial x}{\\partial \\eta} \\\\ \\frac{\\partial y}{\\partial \\xi}  \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix}\n$$\nFrom the affine form of the mapping, we compute the partial derivatives:\n$\\frac{\\partial \\boldsymbol{x}}{\\partial \\xi} = \\boldsymbol{x}_{2} - \\boldsymbol{x}_{1}$ and $\\frac{\\partial \\boldsymbol{x}}{\\partial \\eta} = \\boldsymbol{x}_{3} - \\boldsymbol{x}_{1}$.\nIn matrix form, this gives the constant Jacobian matrix:\n$$\nJ = \\begin{pmatrix} x_2 - x_1  x_3 - x_1 \\\\ y_2 - y_1  y_3 - y_1 \\end{pmatrix}\n$$\nGeometrically, the columns of the Jacobian matrix $J$ are the vectors that form two of the edges of the physical triangle $K$, specifically the edges originating from vertex $\\boldsymbol{x}_{1}$. The determinant of the Jacobian, $\\det(J)$, is twice the signed area of the triangle $K$. The problem statement specifies that the mapping is orientation-preserving, which implies $\\det(J)  0$.\n\n**3) Transformation of Gradients**\n\nLet $\\varphi$ be a scalar function on the physical element $K$ and let $\\widehat{\\varphi}$ be its corresponding function on the reference element $\\widehat{K}$, such that $\\varphi(\\boldsymbol{x})=\\widehat{\\varphi}(\\boldsymbol{F}^{-1}(\\boldsymbol{x}))$. The gradient of $\\varphi$ with respect to physical coordinates $\\boldsymbol{x}=(x,y)$ is $\\nabla_{\\boldsymbol{x}}\\varphi$, and the gradient of $\\widehat{\\varphi}$ with respect to reference coordinates $\\widehat{\\boldsymbol{x}}=(\\xi,\\eta)$ is $\\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi}$.\n\nBy the multivariable chain rule, the derivatives are related as follows:\n$$\n\\begin{pmatrix} \\frac{\\partial \\widehat{\\varphi}}{\\partial \\xi} \\\\ \\frac{\\partial \\widehat{\\varphi}}{\\partial \\eta} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi}  \\frac{\\partial y}{\\partial \\xi} \\\\ \\frac{\\partial x}{\\partial \\eta}  \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix} \\begin{pmatrix} \\frac{\\partial \\varphi}{\\partial x} \\\\ \\frac{\\partial \\varphi}{\\partial y} \\end{pmatrix}\n$$\nThis is precisely $\\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi} = J^{T} \\nabla_{\\boldsymbol{x}}\\varphi$. To express the physical gradient in terms of the reference gradient, we invert this relation:\n$$\n\\nabla_{\\boldsymbol{x}}\\varphi = (J^{T})^{-1} \\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi} = (J^{-1})^{T} \\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi}\n$$\nFor the $\\mathbb{P}_{1}$ basis functions $\\varphi_i$ on $K$, this formula applies directly. The gradients of the reference basis functions $\\widehat{\\varphi}_i$ are constant vectors:\n$\\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi}_{1} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}$,\n$\\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi}_{2} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$,\n$\\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi}_{3} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\nSince $J$ is constant, the physical gradients $\\nabla_{\\boldsymbol{x}}\\varphi_i$ are also constant vectors over the element $K$.\n\n**4) Derivation of the Advection Matrix Entry $(A_{e})_{12}$**\n\nThe entry $(A_{e})_{12}$ of the local advection matrix is given by the integral:\n$$\n(A_{e})_{12} = \\int_{K} (\\boldsymbol{c}\\cdot \\nabla_{\\boldsymbol{x}} \\varphi_{2})\\,\\varphi_{1}\\, \\mathrm{d}\\boldsymbol{x}\n$$\nWe evaluate the terms in the integrand. First, we compute the physical gradient $\\nabla_{\\boldsymbol{x}}\\varphi_{2}$ using the transformation rule from part 3.\n$$\n\\nabla_{\\boldsymbol{x}}\\varphi_{2} = (J^{-1})^{T} \\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi}_{2}\n$$\nWe need the inverse of the Jacobian $J$.\n$$\nJ^{-1} = \\frac{1}{\\det(J)} \\begin{pmatrix} y_3 - y_1  -(x_3 - x_1) \\\\ -(y_2 - y_1)  x_2 - x_1 \\end{pmatrix}\n$$\nwhere $\\det(J) = (x_2 - x_1)(y_3 - y_1) - (x_3 - x_1)(y_2 - y_1)$.\nThe transpose of the inverse is:\n$$\n(J^{-1})^{T} = \\frac{1}{\\det(J)} \\begin{pmatrix} y_3 - y_1  -(y_2 - y_1) \\\\ -(x_3 - x_1)  x_2 - x_1 \\end{pmatrix}\n$$\nSubstituting $\\nabla_{\\widehat{\\boldsymbol{x}}}\\widehat{\\varphi}_{2} = (1, 0)^{T}$:\n$$\n\\nabla_{\\boldsymbol{x}}\\varphi_{2} = \\frac{1}{\\det(J)} \\begin{pmatrix} y_3 - y_1  -(y_2 - y_1) \\\\ -(x_3 - x_1)  x_2 - x_1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{\\det(J)} \\begin{pmatrix} y_3 - y_1 \\\\ -(x_3 - x_1) \\end{pmatrix}\n$$\nThis gradient is constant on $K$. Now we compute the dot product with $\\boldsymbol{c}=(a,b)$:\n$$\n\\boldsymbol{c} \\cdot \\nabla_{\\boldsymbol{x}}\\varphi_{2} = \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\cdot \\frac{1}{\\det(J)} \\begin{pmatrix} y_3 - y_1 \\\\ -(x_3 - x_1) \\end{pmatrix} = \\frac{a(y_3 - y_1) - b(x_3 - x_1)}{\\det(J)}\n$$\nSince this entire term is a constant, it can be factored out of the integral:\n$$\n(A_{e})_{12} = \\left( \\frac{a(y_3 - y_1) - b(x_3 - x_1)}{\\det(J)} \\right) \\int_{K} \\varphi_{1}\\, \\mathrm{d}\\boldsymbol{x}\n$$\nTo evaluate the remaining integral, we change variables to the reference element, using $\\mathrm{d}\\boldsymbol{x} = \\det(J)\\mathrm{d}\\widehat{\\boldsymbol{x}}$:\n$$\n\\int_{K} \\varphi_{1}\\, \\mathrm{d}\\boldsymbol{x} = \\int_{\\widehat{K}} \\widehat{\\varphi}_{1}(\\widehat{\\boldsymbol{x}})\\, \\det(J) \\, \\mathrm{d}\\widehat{\\boldsymbol{x}} = \\det(J) \\int_{0}^{1}\\int_{0}^{1-\\xi} (1-\\xi-\\eta)\\,\\mathrm{d}\\eta\\,\\mathrm{d}\\xi\n$$\nWe evaluate the inner integral with respect to $\\eta$:\n$$\n\\int_{0}^{1-\\xi} (1-\\xi-\\eta)\\,\\mathrm{d}\\eta = \\left[(1-\\xi)\\eta - \\frac{\\eta^2}{2}\\right]_{0}^{1-\\xi} = (1-\\xi)^2 - \\frac{(1-\\xi)^2}{2} = \\frac{1}{2}(1-\\xi)^2\n$$\nNow we evaluate the outer integral with respect to $\\xi$:\n$$\n\\int_{0}^{1} \\frac{1}{2}(1-\\xi)^2\\,\\mathrm{d}\\xi = \\frac{1}{2} \\left[ -\\frac{(1-\\xi)^3}{3} \\right]_{0}^{1} = \\frac{1}{2}\\left(0 - \\left(-\\frac{1}{3}\\right)\\right) = \\frac{1}{6}\n$$\nTherefore, $\\int_{K} \\varphi_{1}\\, \\mathrm{d}\\boldsymbol{x} = \\frac{1}{6}\\det(J)$. This result corresponds to the general formula that the integral of a barycentric coordinate function over a triangle is one-third of the triangle's area, since $\\text{Area}(K) = \\frac{1}{2}\\det(J)$.\n\nSubstituting this result back into the expression for $(A_{e})_{12}$:\n$$\n(A_{e})_{12} = \\left( \\frac{a(y_3 - y_1) - b(x_3 - x_1)}{\\det(J)} \\right) \\left( \\frac{1}{6}\\det(J) \\right)\n$$\nThe $\\det(J)$ terms cancel, yielding the final closed-form expression:\n$$\n(A_{e})_{12} = \\frac{1}{6} \\left( a(y_3 - y_1) - b(x_3 - x_1) \\right)\n$$\nThis expression depends only on the advection coefficients and the coordinates of vertices $\\boldsymbol{x}_{1}$ and $\\boldsymbol{x}_{3}$, as required.",
            "answer": "$$\n\\boxed{\\frac{a(y_{3} - y_{1}) - b(x_{3} - x_{1})}{6}}\n$$"
        },
        {
            "introduction": "The Discontinuous Galerkin (DG) method offers a powerful framework for hyperbolic problems, primarily due to its inherent local conservation properties. This practice  focuses on a single element to demonstrate a fundamental principle: the semi-discrete DG formulation is constructed such that the rate of change of the solution's cell average is exactly balanced by the net numerical flux across the element's boundary. This exercise provides a direct insight into the conservative nature that makes DG methods so robust.",
            "id": "3441789",
            "problem": "Consider the scalar linear advection equation in one spatial dimension,\n$$\n\\partial_t u(x,t) + a\\,\\partial_x u(x,t) = 0 \\quad \\text{for } x \\in [0,2h],\\ t0,\n$$\nwith constant advection speed $a0$ and prescribed inflow boundary data $u(0,t)=g(t)$. Partition the domain into the simple mesh with two elements $K_1=[0,h]$ and $K_2=[h,2h]$. Let $u_h(\\cdot,t)$ be the discontinuous Galerkin (DG) semi-discrete approximation in the space of polynomials of degree at most $1$ on each element.\n\nAdopt the standard upwind numerical flux for linear advection,\n$$\n\\widehat{f}(u^-,u^+) = a\\,u^{\\text{up}}=\n\\begin{cases}\na\\,u^-  \\text{if } a0,\\\\\na\\,u^+  \\text{if } a0,\n\\end{cases}\n$$\nand use the outward unit normal $n_{K}(x)$ on $\\partial K$ so that, in $1$D, $n_{K_1}(0)=-1$ and $n_{K_1}(h)=+1$. The semi-discrete DG formulation on an element $K$ reads: find $u_h$ such that for all test functions $v_h$ in the local polynomial space,\n$$\n\\int_{K} \\partial_t u_h\\, v_h\\, dx \\;-\\; \\int_{K} a\\, u_h\\, \\partial_x v_h\\, dx \\;+\\; \\int_{\\partial K} \\widehat{f}\\big(u_h^-,u_h^+\\big)\\, v_h\\, n_{K}\\, ds \\;=\\; 0.\n$$\n\nFocus on the left element $K_1$ and the constant test function $v_h \\equiv 1$ on $K_1$. Define the elementwise residual\n$$\nR_{K_1}(t) := \\int_{K_1} \\partial_t u_h(x,t)\\, dx,\n$$\nand the net numerical flux across the boundary $\\partial K_1$,\n$$\nB_{K_1}(t) := \\int_{\\partial K_1} \\widehat{f}\\big(u_h^-(x,t),u_h^+(x,t)\\big)\\, n_{K_1}(x)\\, ds.\n$$\n\nStarting from the semi-discrete DG formulation above and the given numerical flux, evaluate the quantity\n$$\nD(t) := R_{K_1}(t) + B_{K_1}(t)\n$$\nin closed form, expressed purely in terms of $a$ and $g(t)$ if needed, and simplify it completely. Your final answer must be a single real number or a single closed-form analytic expression. No rounding is required, and no units are needed.",
            "solution": "The problem asks for the evaluation of the quantity $D(t) := R_{K_1}(t) + B_{K_1}(t)$. We begin by performing a validation of the problem statement.\n\n### Problem Validation\n**Step 1: Extract Givens**\n-   **Partial Differential Equation (PDE):** $\\partial_t u(x,t) + a\\,\\partial_x u(x,t) = 0$ for $x \\in [0,2h]$, $t0$.\n-   **Advection Speed:** $a0$.\n-   **Boundary Condition:** $u(0,t)=g(t)$.\n-   **Mesh:** Element $K_1=[0,h]$ and $K_2=[h,2h]$.\n-   **Approximation Space:** The space of polynomials of degree at most $1$ on each element.\n-   **Numerical Flux:** $\\widehat{f}(u^-,u^+) = a\\,u^{\\text{up}}$, which for $a0$ is $\\widehat{f}(u^-,u^+) = a\\,u^-$.\n-   **Outward Normals for $K_1$:** $n_{K_1}(0)=-1$ and $n_{K_1}(h)=+1$.\n-   **Semi-discrete DG Formulation:** For an element $K$ and a test function $v_h$ from the local polynomial space, the formulation is:\n    $$\n    \\int_{K} \\partial_t u_h\\, v_h\\, dx \\;-\\; \\int_{K} a\\, u_h\\, \\partial_x v_h\\, dx \\;+\\; \\int_{\\partial K} \\widehat{f}\\big(u_h^-,u_h^+\\big)\\, v_h\\, n_{K}\\, ds \\;=\\; 0.\n    $$\n-   **Definitions:**\n    -   Elementwise residual: $R_{K_1}(t) := \\int_{K_1} \\partial_t u_h(x,t)\\, dx$.\n    -   Net numerical flux: $B_{K_1}(t) := \\int_{\\partial K_1} \\widehat{f}\\big(u_h^-(x,t),u_h^+(x,t)\\big)\\, n_{K_1}(x)\\, ds$.\n-   **Quantity to Evaluate:** $D(t) := R_{K_1}(t) + B_{K_1}(t)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, being a standard exercise in the numerical analysis of PDEs using the Discontinuous Galerkin method. It is well-posed, providing all necessary definitions and equations. The language is objective and formal. The setup is internally consistent and complete for the question being asked. The problem is not trivial, as it requires recognizing the relationship between the defined quantities and the governing discrete equation, testing a fundamental concept rather than rote calculation. Therefore, the problem is deemed valid.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\n### Solution\nThe foundation of the solution lies in the semi-discrete Discontinuous Galerkin (DG) formulation provided in the problem statement. This formulation must hold true for any choice of test function $v_h$ within the specified approximation space.\n\nThe problem specifies that the approximation space for $u_h$ consists of polynomials of degree at most $1$ on each element $K$. The space of test functions $v_h$ is the same. This space, denoted $\\mathcal{P}^1(K)$, includes all constant functions. The problem directs our focus to the specific constant test function $v_h(x) \\equiv 1$ for all $x \\in K_1$.\n\nThe semi-discrete DG formulation on the element $K_1=[0,h]$ is:\n$$\n\\int_{K_1} \\partial_t u_h\\, v_h\\, dx \\;-\\; \\int_{K_1} a\\, u_h\\, \\partial_x v_h\\, dx \\;+\\; \\int_{\\partial K_1} \\widehat{f}\\big(u_h^-,u_h^+\\big)\\, v_h\\, n_{K_1}\\, ds \\;=\\; 0.\n$$\nWe substitute the chosen test function $v_h \\equiv 1$ into this equation. Let's analyze each term separately.\n\n1.  **First Term:** The first integral becomes:\n    $$\n    \\int_{K_1} \\partial_t u_h(x,t) \\cdot 1 \\, dx.\n    $$\n    By the problem's definition, this is precisely the elementwise residual $R_{K_1}(t)$.\n\n2.  **Second Term:** The second integral involves the spatial derivative of the test function, $\\partial_x v_h$:\n    $$\n    -\\int_{K_1} a\\, u_h(x,t)\\, \\partial_x(1)\\, dx.\n    $$\n    Since $v_h(x) = 1$ is a constant function, its derivative is $\\partial_x v_h = 0$. Consequently, this entire term evaluates to zero:\n    $$\n    -\\int_{K_1} a\\, u_h(x,t) \\cdot 0 \\, dx = 0.\n    $$\n\n3.  **Third Term:** The third integral is the boundary term:\n    $$\n    \\int_{\\partial K_1} \\widehat{f}\\big(u_h^-(x,t),u_h^+(x,t)\\big) \\cdot 1 \\cdot n_{K_1}(x)\\, ds.\n    $$\n    By the problem's definition, this is precisely the net numerical flux $B_{K_1}(t)$.\n\nSubstituting these results back into the semi-discrete DG formulation, we obtain:\n$$\nR_{K_1}(t) - 0 + B_{K_1}(t) = 0,\n$$\nwhich simplifies to:\n$$\nR_{K_1}(t) + B_{K_1}(t) = 0.\n$$\nThe problem asks for the evaluation of the quantity $D(t)$, which is defined as:\n$$\nD(t) := R_{K_1}(t) + B_{K_1}(t).\n$$\nFrom our derivation, it is clear that this sum is equal to $0$.\n\nThis result is a direct consequence of the definition of the DG method. By choosing a constant test function, the formulation reduces to a statement about the rate of change of the cell average of $u_h$ being balanced by the numerical fluxes at the cell boundaries. The problem is constructed such that the quantity to be evaluated, $D(t)$, is exactly the left-hand side of this local conservation law, which must be zero by definition of the numerical scheme. The specific form of the numerical flux, the value of the advection speed $a$, and the boundary data $g(t)$ are not required to reach this conclusion.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "A successful spatial semi-discretization is only half the battle; the choice of time integrator is equally critical for obtaining physically meaningful long-term simulations of hyperbolic systems. This computational practice  explores the crucial link between the Hamiltonian structure of the semi-discretized wave equation and the properties of the time-stepping scheme. By comparing a symplectic integrator (Störmer-Verlet) against a classical Runge-Kutta method, you will directly observe the superior energy conservation properties of structure-preserving algorithms in long-time simulations.",
            "id": "3441780",
            "problem": "Consider the one-dimensional linear wave equation posed on the unit interval with homogeneous Dirichlet boundary conditions in dimensionless variables: find a sufficiently smooth displacement field $u(x,t)$ on $x \\in [0,1]$ and $t \\ge 0$ such that $u(0,t) = 0$, $u(1,t) = 0$, and\n$$\n\\frac{\\partial^2 u}{\\partial t^2}(x,t) - \\frac{\\partial^2 u}{\\partial x^2}(x,t) = 0 \\quad \\text{for} \\quad x \\in (0,1), \\ t  0.\n$$\nAdopt the standard Galerkin Finite Element Method (FEM) with continuous, piecewise linear basis functions on a uniform mesh with $n$ elements and remove boundary degrees of freedom to enforce homogeneous Dirichlet boundary conditions. Denote by $M \\in \\mathbb{R}^{m \\times m}$ the symmetric positive-definite mass matrix, by $K \\in \\mathbb{R}^{m \\times m}$ the symmetric positive-definite stiffness matrix, and by $m = n - 1$ the number of interior mesh nodes. The semi-discrete system for the nodal coefficient vector $q(t) \\in \\mathbb{R}^m$ is\n$$\nM \\ddot{q}(t) + K q(t) = 0,\n$$\nwith initial conditions $q(0) = q_0 \\in \\mathbb{R}^m$ and $\\dot{q}(0) = v_0 \\in \\mathbb{R}^m$. Introduce the canonical momentum $p(t) = M \\dot{q}(t)$ and the discrete Hamiltonian (discrete energy)\n$$\nH(q,p) = \\frac{1}{2} \\, p^\\top M^{-1} p + \\frac{1}{2} \\, q^\\top K q,\n$$\nso that the semi-discrete dynamics are Hamiltonian:\n$$\n\\dot{q}(t) = M^{-1} p(t), \\qquad \\dot{p}(t) = - K q(t).\n$$\nStarting from the weak form of the wave equation and the definition of the Galerkin projection, assemble $M$ and $K$ for a uniform mesh with $n$ elements and linear shape functions. Set the initial displacement by sampling the first continuous mode $u(x,0) = \\sin(\\pi x)$ at interior nodes and set the initial velocity $v_0 = 0$. Work entirely with dimensionless quantities; no physical units are required anywhere in this task.\n\nImplement and compare the following two time integrators applied to the semi-discrete Hamiltonian system:\n- A symplectic integrator: the Störmer–Verlet scheme applied to the separable Hamiltonian $H(q,p)$, defined by\n$$\np_{k+\\frac{1}{2}} = p_k - \\frac{\\Delta t}{2} \\, K q_k, \\quad\nq_{k+1} = q_k + \\Delta t \\, M^{-1} p_{k+\\frac{1}{2}}, \\quad\np_{k+1} = p_{k+\\frac{1}{2}} - \\frac{\\Delta t}{2} \\, K q_{k+1}.\n$$\n- A classical non-symplectic integrator: the explicit classical fourth-order Runge–Kutta method (Runge–Kutta of order four, abbreviated as RK4) applied to the first-order system $\\dot{y} = f(y)$ with $y = (q,p)$ and $f(y) = (M^{-1} p, -K q)$.\n\nFor each method, compute the discrete energy $H(q_k,p_k)$ at every time step $t_k = k \\Delta t$ and report the maximum absolute relative energy deviation from the initial energy over the simulated time window,\n$$\n\\max_{0 \\le k \\le N} \\left| \\frac{H(q_k,p_k) - H(q_0,p_0)}{H(q_0,p_0)} \\right|,\n$$\nwhere $N$ is the total number of time steps. Assemble $M$ and $K$ using the standard element-level formulas for piecewise linear basis functions on a uniform mesh with spacing $h = 1/n$ and homogeneous Dirichlet boundary conditions. Your algorithm must use the structure of $M$ and $K$ to solve linear systems of the form $M x = b$ efficiently at every time step.\n\nUse the following test suite of parameter sets to probe different regimes. All quantities are dimensionless. For each case, use the specified number of elements $n$, time step $\\Delta t$, and final time $T$, and compute the maximum absolute relative energy deviation for both Störmer–Verlet and RK4:\n- Case $1$: $n = 50$, $\\Delta t = 0.008$, $T = 20$.\n- Case $2$: $n = 50$, $\\Delta t = 0.009$, $T = 20$.\n- Case $3$: $n = 10$, $\\Delta t = 0.045$, $T = 20$.\n- Case $4$: $n = 200$, $\\Delta t = 0.0015$, $T = 20$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order for Cases $1$ through $4$, the pair $[\\text{err}_{\\text{SV}}, \\text{err}_{\\text{RK4}}]$ for each case, where $\\text{err}_{\\text{SV}}$ is the maximum absolute relative energy deviation for Störmer–Verlet and $\\text{err}_{\\text{RK4}}$ is the same quantity for RK4. For example, the output format should be\n$$\n[ [e_{1,\\text{SV}}, e_{1,\\text{RK4}}], [e_{2,\\text{SV}}, e_{2,\\text{RK4}}], [e_{3,\\text{SV}}, e_{3,\\text{RK4}}], [e_{4,\\text{SV}}, e_{4,\\text{RK4}}] ].\n$$\nOnly print this single line; do not print any additional text.",
            "solution": "The problem statement is a valid and well-posed exercise in the field of numerical analysis for partial differential equations. It is scientifically grounded, employing standard models (the 1D wave equation) and numerical techniques (Finite Element Method, Störmer-Verlet, and RK4 integrators). All necessary data, including geometric parameters, physical model, initial conditions, discretization choices, and specific test cases, are provided without ambiguity or contradiction. The problem is self-contained and asks for the computation of a well-defined metric (maximum relative energy deviation) to compare the qualitative behavior of different numerical schemes, which is a standard and insightful task in computational science. Therefore, we proceed with a complete solution.\n\nThe core of the problem is to solve the one-dimensional linear wave equation\n$$\n\\frac{\\partial^2 u}{\\partial t^2} - \\frac{\\partial^2 u}{\\partial x^2} = 0, \\quad x \\in (0,1), \\ t  0\n$$\nwith homogeneous Dirichlet boundary conditions $u(0,t) = u(1,t) = 0$. The process involves two main stages: spatial discretization to obtain a system of ordinary differential equations (ODEs), and temporal integration of this ODE system.\n\n**1. Spatial Discretization via the Finite Element Method (FEM)**\n\nWe first transform the partial differential equation (PDE) into a system of ODEs using the Galerkin FEM. The solution $u(x,t)$ is approximated by a function $u_h(x,t)$ from a finite-dimensional space $V_h$. For this problem, $V_h$ is the space of continuous piecewise linear functions on a uniform mesh of the interval $[0,1]$ that are zero at $x=0$ and $x=1$.\n\nThe mesh consists of $n$ elements of uniform size $h=1/n$. The nodes are located at $x_i = i \\cdot h$ for $i=0, 1, \\dots, n$. Since the boundary conditions are homogeneous, the degrees of freedom correspond to the $m=n-1$ interior nodes ($i=1, \\dots, n-1$). The approximation takes the form\n$$\nu_h(x,t) = \\sum_{j=1}^{m} q_j(t) \\phi_j(x)\n$$\nwhere $q_j(t)$ are the time-dependent coefficients representing the displacement at node $x_j$, and $\\phi_j(x)$ are the standard \"hat\" basis functions. Each $\\phi_j(x)$ is a continuous, piecewise linear function that is equal to $1$ at node $x_j$ and $0$ at all other nodes.\n\nThe Galerkin method requires the residual of the PDE to be orthogonal to the basis functions. In its weak form, this leads to the semi-discrete system:\n$$\nM \\ddot{q}(t) + K q(t) = 0\n$$\nwhere $q(t) = [q_1(t), \\dots, q_m(t)]^\\top$ is the vector of nodal displacements. The mass matrix $M$ and stiffness matrix $K$ are $m \\times m$ matrices with entries given by:\n$$\nM_{ij} = \\int_0^1 \\phi_i(x) \\phi_j(x) \\, dx\n$$\n$$\nK_{ij} = \\int_0^1 \\frac{d\\phi_i}{dx}(x) \\frac{d\\phi_j}{dx}(x) \\, dx\n$$\nDue to the local support of the basis functions (i.e., $\\phi_i$ and $\\phi_j$ are non-zero on overlapping intervals only if $|i-j| \\le 1$), both matrices are symmetric and tridiagonal. For a uniform mesh with spacing $h$, the entries are:\n- **Mass Matrix $M$**:\n  $$\n  M_{ij} = \\begin{cases} \\frac{2h}{3}  \\text{if } i=j \\\\ \\frac{h}{6}  \\text{if } |i-j|=1 \\\\ 0  \\text{otherwise} \\end{cases}\n  $$\n- **Stiffness Matrix $K$**:\n  $$\n  K_{ij} = \\begin{cases} \\frac{2}{h}  \\text{if } i=j \\\\ -\\frac{1}{h}  \\text{if } |i-j|=1 \\\\ 0  \\text{otherwise} \\end{cases}\n  $$\nBoth $M$ and $K$ are symmetric and positive-definite for $m \\ge 1$. Their tridiagonal structure is crucial for computational efficiency.\n\n**2. Hamiltonian Formulation**\n\nThe second-order ODE system $M\\ddot{q} + K q = 0$ describes a conservative mechanical system. It can be recast as a first-order Hamiltonian system. We introduce the canonical momentum $p(t) = M \\dot{q}(t)$. The time evolution of the state vector $(q,p)$ is then governed by Hamilton's equations:\n$$\n\\dot{q} = \\frac{\\partial H}{\\partial p} = M^{-1} p\n$$\n$$\n\\dot{p} = -\\frac{\\partial H}{\\partial q} = -K q\n$$\nThe Hamiltonian $H(q,p)$, representing the total discrete energy of the system, is the sum of kinetic and potential energy:\n$$\nH(q,p) = \\frac{1}{2} \\dot{q}^\\top M \\dot{q} + \\frac{1}{2} q^\\top K q = \\frac{1}{2} p^\\top M^{-1} p + \\frac{1}{2} q^\\top K q\n$$\nFor the exact solution of the semi-discrete system, this energy $H$ is a conserved quantity.\n\n**3. Initial Conditions**\n\nThe initial displacement is given by sampling $u(x,0) = \\sin(\\pi x)$ at the interior nodes $x_j=jh$ for $j=1, \\dots, m$. Thus, the initial coefficient vector is\n$$\nq_0 = [\\sin(\\pi h), \\sin(2\\pi h), \\dots, \\sin(m\\pi h)]^\\top\n$$\nThe initial velocity is zero, so $\\dot{q}(0) = v_0 = 0$. This implies the initial momentum is also zero: $p(0) = p_0 = M\\dot{q}(0) = 0$.\nThe initial energy is purely potential:\n$$\nH_0 = H(q_0, p_0) = \\frac{1}{2} q_0^\\top K q_0\n$$\nSince $q_0 \\neq 0$ and $K$ is positive-definite, $H_0  0$.\n\n**4. Time Integration Schemes**\n\nWe compare two methods for integrating the Hamiltonian system from $(q_0, p_0)$ over time.\n\n**a) Störmer–Verlet (SV) Integrator**\nThis is a symplectic integrator, meaning it is specifically designed to preserve the geometric structure of Hamiltonian systems. This property leads to excellent long-term energy conservation; the numerical energy does not exhibit secular drift but oscillates around the true conserved value. The scheme is defined by:\n$$\n\\begin{aligned}\np_{k+\\frac{1}{2}} = p_k - \\frac{\\Delta t}{2} \\, K q_k \\\\\nq_{k+1} = q_k + \\Delta t \\, M^{-1} p_{k+\\frac{1}{2}} \\\\\np_{k+1} = p_{k+\\frac{1}{2}} - \\frac{\\Delta t}{2} \\, K q_{k+1}\n\\end{aligned}\n$$\nThe implementation of the second step requires solving a linear system of the form $M x = b$ (where $b = p_{k+1/2}$). Since $M$ is tridiagonal, this can be solved very efficiently in $O(m)$ operations using a banded matrix solver, avoiding the expensive explicit computation of $M^{-1}$.\n\n**b) Classical Fourth-Order Runge–Kutta (RK4) Integrator**\nRK4 is a general-purpose, explicit, single-step method known for its high order of accuracy. For our first-order system $\\dot{y} = f(y)$ where $y=(q,p)$ and $f(y)=(M^{-1}p, -Kq)$, the RK4 update is:\n$$\n\\begin{aligned}\nk_1 = \\Delta t \\, f(y_k) \\\\\nk_2 = \\Delta t \\, f(y_k + \\frac{1}{2} k_1) \\\\\nk_3 = \\Delta t \\, f(y_k + \\frac{1}{2} k_2) \\\\\nk_4 = \\Delta t \\, f(y_k + k_3) \\\\\ny_{k+1} = y_k + \\frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n\\end{aligned}\n$$\nEach evaluation of the function $f$ requires one matrix-vector product with $K$ and one linear solve with $M$. Thus, a single RK4 step requires four linear solves with $M$ and four matrix-vector products with $K$. Despite its high nominal accuracy, RK4 is not symplectic. As a result, the numerical energy is not well-preserved and is expected to drift over long simulation times.\n\n**5. Analysis and Implementation**\n\nFor each method, the simulation is run from $t=0$ to $t=T$. At each step $t_k=k\\Delta t$, the discrete energy $H(q_k, p_k)$ is computed. The term $p^\\top M^{-1}p$ is calculated efficiently as $p^\\top v$ where $v$ is the solution to $Mv=p$. The maximum absolute relative energy deviation over the entire simulation provides a quantitative measure of energy conservation:\n$$\n\\max_{0 \\le k \\le N} \\left| \\frac{H_k - H_0}{H_0} \\right|\n$$\nThe implementation will use a banded solver for the tridiagonal mass matrix $M$ for efficiency. The stiffness matrix $K$ will be represented in a sparse format for efficient matrix-vector products. The code will execute the simulations for the four specified test cases and report the energy deviation for both methods.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\nfrom scipy.sparse import diags\n\ndef assemble_matrices(n):\n    \"\"\"\n    Assembles the FEM mass and stiffness matrices for the 1D wave equation.\n\n    Args:\n        n (int): The number of elements.\n\n    Returns:\n        tuple: A tuple containing:\n            - M_banded (np.ndarray): The mass matrix in banded format (3x(n-1)).\n            - K_sparse (scipy.sparse.csr_matrix): The stiffness matrix in sparse CSR format.\n    \"\"\"\n    m = n - 1\n    h = 1.0 / n\n\n    # Mass matrix M in banded format for solve_banded\n    M_banded = np.zeros((3, m))\n    M_banded[0, 1:] = h / 6.0      # Super-diagonal\n    M_banded[1, :] = 4.0 * h / 6.0 # Main diagonal\n    M_banded[2, :-1] = h / 6.0     # Sub-diagonal\n\n    # Stiffness matrix K in sparse format for mat-vec products\n    sub_diag_K = np.full(m - 1, -1.0 / h)\n    main_diag_K = np.full(m, 2.0 / h)\n    K_sparse = diags([sub_diag_K, main_diag_K, sub_diag_K], [-1, 0, 1], shape=(m, m), format='csr')\n\n    return M_banded, K_sparse\n\ndef compute_energy(q, p, M_banded, K_sparse):\n    \"\"\"\n    Computes the discrete Hamiltonian (energy).\n\n    Args:\n        q (np.ndarray): The displacement vector.\n        p (np.ndarray): The momentum vector.\n        M_banded (np.ndarray): The mass matrix in banded format.\n        K_sparse (scipy.sparse.csr_matrix): The stiffness matrix in sparse format.\n\n    Returns:\n        float: The total discrete energy.\n    \"\"\"\n    # Kinetic energy: 0.5 * p^T * M^-1 * p\n    # Let v = M^-1 * p. Solve M*v = p for v. Then energy is 0.5 * p^T * v.\n    v = solve_banded((1, 1), M_banded, p)\n    kinetic_energy = 0.5 * np.dot(p, v)\n\n    # Potential energy: 0.5 * q^T * K * q\n    Kq = K_sparse @ q\n    potential_energy = 0.5 * np.dot(q, Kq)\n\n    return kinetic_energy + potential_energy\n\ndef solve_sv(n, dt, T):\n    \"\"\"\n    Solves the system using the Störmer-Verlet integrator.\n    \"\"\"\n    m = n - 1\n    M_banded, K_sparse = assemble_matrices(n)\n\n    # Initial conditions\n    x_nodes = np.linspace(0, 1, n + 1)[1:-1]\n    q = np.sin(np.pi * x_nodes)\n    p = np.zeros(m)\n\n    initial_energy = compute_energy(q, p, M_banded, K_sparse)\n    if initial_energy == 0:\n        return 0.0\n\n    max_rel_energy_dev = 0.0\n    num_steps = int(round(T / dt))\n\n    for _ in range(num_steps):\n        # Störmer-Verlet steps\n        p_half = p - (dt / 2.0) * (K_sparse @ q)\n        q = q + dt * solve_banded((1, 1), M_banded, p_half)\n        p = p_half - (dt / 2.0) * (K_sparse @ q)\n\n        current_energy = compute_energy(q, p, M_banded, K_sparse)\n        rel_dev = np.abs((current_energy - initial_energy) / initial_energy)\n        if rel_dev > max_rel_energy_dev:\n            max_rel_energy_dev = rel_dev\n\n    return max_rel_energy_dev\n\ndef solve_rk4(n, dt, T):\n    \"\"\"\n    Solves the system using the classical 4th-order Runge-Kutta integrator.\n    \"\"\"\n    m = n - 1\n    M_banded, K_sparse = assemble_matrices(n)\n\n    # Initial conditions\n    x_nodes = np.linspace(0, 1, n + 1)[1:-1]\n    q = np.sin(np.pi * x_nodes)\n    p = np.zeros(m)\n\n    initial_energy = compute_energy(q, p, M_banded, K_sparse)\n    if initial_energy == 0:\n        return 0.0\n\n    max_rel_energy_dev = 0.0\n    num_steps = int(round(T / dt))\n\n    def f(q_in, p_in):\n        f_q = solve_banded((1, 1), M_banded, p_in)\n        f_p = -1.0 * (K_sparse @ q_in)\n        return f_q, f_p\n\n    for _ in range(num_steps):\n        # RK4 stages\n        k1_q, k1_p = f(q, p)\n        \n        q_temp_2 = q + (dt / 2.0) * k1_q\n        p_temp_2 = p + (dt / 2.0) * k1_p\n        k2_q, k2_p = f(q_temp_2, p_temp_2)\n        \n        q_temp_3 = q + (dt / 2.0) * k2_q\n        p_temp_3 = p + (dt / 2.0) * k2_p\n        k3_q, k3_p = f(q_temp_3, p_temp_3)\n        \n        q_temp_4 = q + dt * k3_q\n        p_temp_4 = p + dt * k3_p\n        k4_q, k4_p = f(q_temp_4, p_temp_4)\n\n        # Update\n        q += (dt / 6.0) * (k1_q + 2*k2_q + 2*k3_q + k4_q)\n        p += (dt / 6.0) * (k1_p + 2*k2_p + 2*k3_p + k4_p)\n\n        current_energy = compute_energy(q, p, M_banded, K_sparse)\n        rel_dev = np.abs((current_energy - initial_energy) / initial_energy)\n        if rel_dev > max_rel_energy_dev:\n            max_rel_energy_dev = rel_dev\n            \n    return max_rel_energy_dev\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # (n, dt, T)\n        (50, 0.008, 20),\n        (50, 0.009, 20),\n        (10, 0.045, 20),\n        (200, 0.0015, 20),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, dt, T = case\n        err_sv = solve_sv(n, dt, T)\n        err_rk4 = solve_rk4(n, dt, T)\n        results.append([err_sv, err_rk4])\n\n    results_str = []\n    for res_pair in results:\n        results_str.append(f\"[{res_pair[0]}, {res_pair[1]}]\")\n    final_output = f\"[[{results[0][0]}, {results[0][1]}], [{results[1][0]}, {results[1][1]}], [{results[2][0]}, {results[2][1]}], [{results[3][0]}, {results[3][1]}]]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}