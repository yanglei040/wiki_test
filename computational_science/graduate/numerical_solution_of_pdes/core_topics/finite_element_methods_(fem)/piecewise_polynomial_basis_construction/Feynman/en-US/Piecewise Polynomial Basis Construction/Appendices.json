{
    "hands_on_practices": [
        {
            "introduction": "In the Finite Element Method (FEM), assembling system matrices requires computing integrals of basis functions. This exercise guides you through the construction of Gaussian quadrature, an essential tool that allows for the exact integration of polynomials using a minimal number of evaluation points. By leveraging the properties of orthogonal polynomials, you will derive the theoretical foundation for one of the most efficient numerical integration schemes used in computational science and engineering. ",
            "id": "3431678",
            "problem": "Consider a one-dimensional finite element discretization for a second-order linear Partial Differential Equation (PDE) on a mesh of intervals, where each element is mapped to the reference element $K=[-1,1]$. On each element, a piecewise polynomial basis of degree at most $p$ is used, i.e., the local trial/test space is $\\mathbb{P}_{p}(K)$, the space of polynomials of degree at most $p$ on $K$. For the purpose of assembling element-wise contributions that require exact integration of basis functions in $\\mathbb{P}_{p}(K)$, you are asked to construct a moment-fitting quadrature rule on $K$ that integrates exactly every polynomial in $\\mathbb{P}_{p}(K)$, and to analyze the minimal number of quadrature points needed per element.\n\nStarting only from the following foundational bases:\n- The definition of exactness of a quadrature rule: a quadrature rule with nodes $\\{x_{i}\\}_{i=1}^{n}\\subset K$ and weights $\\{w_{i}\\}_{i=1}^{n}$ integrates a function $q$ exactly if $\\int_{K} q(x)\\,\\mathrm{d}x=\\sum_{i=1}^{n} w_{i}\\,q(x_{i})$.\n- The definition of the moment-fitting condition: exactness for all polynomials in $\\mathbb{P}_{p}(K)$ means the quadrature must satisfy the above identity for every $q\\in\\mathbb{P}_{p}(K)$.\n- The existence of families of orthogonal polynomials on $[-1,1]$ with respect to the unit weight (the Legendre polynomials), with the well-tested properties of orthogonality and real, simple roots strictly inside $(-1,1)$.\n\nTasks:\n1. Formulate the moment-fitting equations that enforce exactness for all polynomials in $\\mathbb{P}_{p}(K)$, and construct a quadrature rule on $K$ with $n$ nodes and weights satisfying these equations by exploiting orthogonality properties. Establish the degree of exactness of your constructed rule.\n2. Using only the structure of the moment-fitting system and the properties of your constructed rule, derive a necessary lower bound on $n$ in terms of $p$ and combine it with the existence result from your construction to determine the minimal number of quadrature points required per element $K$ to integrate $\\mathbb{P}_{p}(K)$ exactly.\n3. Provide your final result as a single closed-form analytic expression for the minimal number of quadrature points per element in terms of $p$. No numerical rounding is required and no units are involved.\n\nYour final answer must be a single analytic expression.",
            "solution": "The problem is valid. It is a well-posed question in the field of numerical analysis, specifically concerning the theory of numerical integration required for finite element methods. The premises are scientifically sound, and the terminology is precise.\n\nThe problem is addressed in three parts as requested:\n1.  Formulation of the moment-fitting equations and construction of a suitable quadrature rule.\n2.  Derivation of a necessary lower bound on the number of quadrature points and determination of the minimal number.\n3.  The final expression for this minimal number.\n\nLet $K = [-1, 1]$ be the reference element. We seek a quadrature rule with $n$ nodes $\\{x_i\\}_{i=1}^{n}$ and weights $\\{w_i\\}_{i=1}^{n}$ that is exact for all polynomials in $\\mathbb{P}_{p}(K)$, the space of polynomials of degree at most $p$. This means the rule must satisfy\n$$\n\\int_{-1}^{1} q(x) \\, \\mathrm{d}x = \\sum_{i=1}^{n} w_i q(x_i) \\quad \\forall q \\in \\mathbb{P}_{p}(K)\n$$\n\n**1. Formulation and Construction of the Quadrature Rule**\n\nTo enforce exactness for the entire space $\\mathbb{P}_{p}(K)$, it is necessary and sufficient to enforce it for a basis of this space. A convenient basis for this formulation is the monomial basis $\\{x^k\\}_{k=0}^{p}$. This leads to a system of $p+1$ nonlinear equations, known as the moment-fitting equations, for the $2n$ unknowns ($n$ nodes $x_i$ and $n$ weights $w_i$):\n$$\n\\int_{-1}^{1} x^k \\, \\mathrm{d}x = \\sum_{i=1}^{n} w_i x_i^k \\quad \\text{for } k = 0, 1, \\ldots, p\n$$\n\nThe problem statement directs us to use the properties of orthogonal polynomials on $[-1, 1]$, which are the Legendre polynomials, denoted here by $L_k(x)$ for degree $k$. These polynomials are orthogonal with respect to the unit weight function, i.e., $\\int_{-1}^{1} L_j(x) L_k(x) \\, \\mathrm{d}x = c_k \\delta_{jk}$ for some normalization constants $c_k > 0$.\n\nWe construct an $n$-point quadrature rule. The key idea of Gaussian quadrature is to choose the nodes $\\{x_i\\}_{i=1}^{n}$ as the $n$ roots of the Legendre polynomial of degree $n$, $L_n(x)$. From the provided properties, these roots are real, distinct, and lie strictly within the interval $(-1, 1)$.\n\nWith these $n$ nodes fixed, we determine the $n$ weights $\\{w_i\\}_{i=1}^{n}$ by requiring the rule to be exact for polynomials of degree up to $n-1$. This gives a system of $n$ linear equations for the $n$ weights:\n$$\n\\sum_{i=1}^{n} w_i x_i^k = \\int_{-1}^{1} x^k \\, \\mathrm{d}x \\quad \\text{for } k = 0, 1, \\ldots, n-1\n$$\nThis can be written in matrix form as $V \\mathbf{w} = \\mathbf{m}$, where $V$ is the Vandermonde matrix with entries $V_{jk} = x_k^j$ for $j,k \\in \\{0, \\ldots, n-1\\}$, $\\mathbf{w}$ is the vector of weights, and $\\mathbf{m}$ is the vector of moments $\\int_{-1}^{1} x^j \\, \\mathrm{d}x$. Since the nodes $x_i$ (the roots of $L_n(x)$) are distinct, the Vandermonde matrix is non-singular, guaranteeing a unique solution for the weights $\\{w_i\\}_{i=1}^{n}$.\n\nNow, we establish the degree of exactness of this constructed rule. Let $q(x)$ be any polynomial of degree at most $2n-1$. We can perform polynomial division of $q(x)$ by the Legendre polynomial $L_n(x)$, which has degree $n$. This gives:\n$$\nq(x) = s(x) L_n(x) + r(x)\n$$\nwhere the quotient $s(x)$ and remainder $r(x)$ are polynomials of degree at most $n-1$.\n\nIntegrating $q(x)$ over $K$ yields:\n$$\n\\int_{-1}^{1} q(x) \\, \\mathrm{d}x = \\int_{-1}^{1} s(x) L_n(x) \\, \\mathrm{d}x + \\int_{-1}^{1} r(x) \\, \\mathrm{d}x\n$$\nThe Legendre polynomial $L_n(x)$ is orthogonal to all polynomials of degree less than $n$. Since $\\deg(s) \\le n-1$, $s(x)$ can be expressed as a linear combination of $\\{L_0(x), \\ldots, L_{n-1}(x)\\}$. By the property of orthogonality, the first integral on the right-hand side is zero:\n$$\n\\int_{-1}^{1} s(x) L_n(x) \\, \\mathrm{d}x = 0\n$$\nThus, we have $\\int_{-1}^{1} q(x) \\, \\mathrm{d}x = \\int_{-1}^{1} r(x) \\, \\mathrm{d}x$.\n\nNext, we apply the quadrature rule to $q(x)$:\n$$\n\\sum_{i=1}^{n} w_i q(x_i) = \\sum_{i=1}^{n} w_i \\left( s(x_i) L_n(x_i) + r(x_i) \\right)\n$$\nBy construction, the nodes $x_i$ are the roots of $L_n(x)$, so $L_n(x_i) = 0$ for all $i = 1, \\ldots, n$. The expression simplifies to:\n$$\n\\sum_{i=1}^{n} w_i q(x_i) = \\sum_{i=1}^{n} w_i r(x_i)\n$$\nSince $\\deg(r) \\le n-1$, and the rule was constructed to be exact for all polynomials in $\\mathbb{P}_{n-1}(K)$, we have:\n$$\n\\sum_{i=1}^{n} w_i r(x_i) = \\int_{-1}^{1} r(x) \\, \\mathrm{d}x\n$$\nCombining our findings, we see that for any polynomial $q(x)$ of degree at most $2n-1$:\n$$\n\\int_{-1}^{1} q(x) \\, \\mathrm{d}x = \\int_{-1}^{1} r(x) \\, \\mathrm{d}x = \\sum_{i=1}^{n} w_i r(x_i) = \\sum_{i=1}^{n} w_i q(x_i)\n$$\nThis proves that the constructed $n$-point rule (the Gaussian quadrature rule) has a degree of exactness of $2n-1$.\n\n**2. Derivation of the Minimal Number of Quadrature Points**\n\nFirst, we derive a necessary lower bound on $n$. The problem requires the quadrature rule to be exact for all polynomials in $\\mathbb{P}_p(K)$. This means the degree of exactness of the rule must be at least $p$. Let us establish the maximum possible degree of exactness for any $n$-point rule. Consider a polynomial $q(x)$ of degree $2n$ constructed as follows:\n$$\nq(x) = \\prod_{i=1}^{n} (x-x_i)^2\n$$\nwhere $\\{x_i\\}_{i=1}^{n}$ are the nodes of our arbitrary $n$-point rule. The degree of $q(x)$ is $2n$. Since $q(x) > 0$ for all $x \\in [-1, 1]$ except at the nodes, its integral over $K$ is strictly positive:\n$$\n\\int_{-1}^{1} q(x) \\, \\mathrm{d}x > 0\n$$\nHowever, applying the quadrature rule to $q(x)$ gives:\n$$\n\\sum_{i=1}^{n} w_i q(x_i) = \\sum_{i=1}^{n} w_i \\cdot 0 = 0\n$$\nSince the integral and the quadrature sum do not match, no $n$-point rule can be exact for this polynomial of degree $2n$. Therefore, the maximum possible degree of exactness for any $n$-point rule is $2n-1$.\n\nFor our quadrature rule to be exact for all polynomials in $\\mathbb{P}_p(K)$, its degree of exactness, $2n-1$ at best, must be greater than or equal to $p$:\n$$\n2n - 1 \\ge p\n$$\nThis yields a necessary condition on the number of points $n$:\n$$\nn \\ge \\frac{p+1}{2}\n$$\nSince $n$ must be an integer, the number of quadrature points must satisfy:\n$$\nn \\ge \\left\\lceil \\frac{p+1}{2} \\right\\rceil\n$$\nThis establishes a necessary lower bound on $n$.\n\nFrom Part 1, we know that for any integer $n$, we can construct a Gaussian quadrature rule with $n$ points that has a degree of exactness of $2n-1$. To satisfy the problem's requirement (exactness on $\\mathbb{P}_p(K)$), we need to choose $n$ such that $2n-1 \\ge p$. The smallest integer $n$ that satisfies this inequality is precisely $n = \\lceil \\frac{p+1}{2} \\rceil$.\n\nSince this number of points is both necessary (from the lower bound analysis) and sufficient (from the existence of Gaussian quadrature), it is the minimal number of quadrature points required.\n\n**3. Final Expression**\n\nThe minimal number of quadrature points per element, $n_{min}$, needed to integrate exactly every polynomial in $\\mathbb{P}_{p}(K)$ is given by the smallest integer $n$ satisfying $n \\ge \\frac{p+1}{2}$. This is expressed using the ceiling function.\nThe final result is an analytic expression for $n_{min}$ in terms of the polynomial degree $p$.\n$$\nn_{min}(p) = \\left\\lceil \\frac{p+1}{2} \\right\\rceil\n$$\nFor instance, for linear elements ($p=1$), we need $n_{min} = \\lceil \\frac{1+1}{2} \\rceil = 1$ point. For quadratic elements ($p=2$), we need $n_{min} = \\lceil \\frac{2+1}{2} \\rceil = \\lceil 1.5 \\rceil = 2$ points. For cubic elements ($p=3$), we need $n_{min} = \\lceil \\frac{3+1}{2} \\rceil = 2$ points. This aligns with the theory of Gaussian quadrature.",
            "answer": "$$\n\\boxed{\\left\\lceil \\frac{p+1}{2} \\right\\rceil}\n$$"
        },
        {
            "introduction": "Many physical systems exhibit symmetries, and an effective numerical method should exploit this structure to gain efficiency. This practice explores how to construct a \"parity-adapted\" basis of even and odd functions for problems defined on symmetric domains. You will see how this tailored basis construction decouples the discrete system, reducing a large problem into smaller, independent subproblems and aiding in the preservation of physical invariants. ",
            "id": "3431733",
            "problem": "Consider the one-dimensional domain $\\Omega = (-1,1)$ and the reflection operator $R$ defined by $(Ru)(x) = u(-x)$. Let $a(x)$ and $c(x)$ be real-valued coefficient functions satisfying $a(x) > 0$, $a(-x) = a(x)$, $c(x) \\ge 0$, and $c(-x) = c(x)$, and define the linear differential operator $\\mathcal{L} u = -\\dfrac{d}{dx}\\!\\left( a(x)\\, \\dfrac{du}{dx} \\right) + c(x)\\, u$. Assume a conforming mesh of $\\Omega$ that is exactly symmetric with respect to $x=0$, and a continuous piecewise polynomial finite element space $V_h \\subset H_0^1(\\Omega)$ of degree $p \\in \\mathbb{N}$ built on this mesh, with exact quadrature used in all integrals.\n\nDefine the bilinear form $a_h(u,v) = \\int_{-1}^1 \\left( a(x)\\, u'(x)\\, v'(x) + c(x)\\, u(x)\\, v(x) \\right)\\, dx$ and the linear functional $\\ell_f(v) = \\int_{-1}^1 f(x)\\, v(x)\\, dx$, where $f \\in L^2(\\Omega)$.\n\nLet $V_h^{\\mathrm{even}} = \\{ v_h \\in V_h \\,:\\, v_h \\circ R = v_h \\}$ and $V_h^{\\mathrm{odd}} = \\{ v_h \\in V_h \\,:\\, v_h \\circ R = -v_h \\}$ denote the even and odd subspaces of $V_h$. On the symmetric mesh, for each pair of basis functions $\\varphi_i^{+}$ and $\\varphi_i^{-}$ supported on a pair of mirrored elements $K$ and $R K$ (with $\\varphi_i^{-} = \\varphi_i^{+} \\circ R$), consider the parity-adapted combinations $\\psi_i^{\\mathrm{even}} = \\dfrac{1}{\\sqrt{2}}\\left( \\varphi_i^{+} + \\varphi_i^{-} \\right)$ and $\\psi_i^{\\mathrm{odd}} = \\dfrac{1}{\\sqrt{2}}\\left( \\varphi_i^{+} - \\varphi_i^{-} \\right)$. Near $x=0$, adapt the construction consistently with continuity so that a basis of $V_h$ is partitioned into a basis of $V_h^{\\mathrm{even}}$ and a basis of $V_h^{\\mathrm{odd}}$.\n\nYou will assess statements about exploiting parity invariance in the following two problems:\n\n(elliptic) Find $u_h \\in V_h$ such that $a_h(u_h, v_h) = \\ell_f(v_h)$ for all $v_h \\in V_h$.\n\n(parabolic with Neumann) Define $\\mathcal{L}_0 u = -\\dfrac{d}{dx}\\!\\left( a(x)\\, \\dfrac{du}{dx} \\right)$ and consider $u_t + \\mathcal{L}_0 u = 0$ on $\\Omega$ with homogeneous Neumann boundary conditions $a(x)\\, u_x(\\pm 1,t) = 0$, semidiscretized by the Galerkin method in the continuous piecewise polynomial space $W_h \\subset H^1(\\Omega)$ built on the same symmetric mesh, with consistent mass matrix. Assume $a(x)$ is as above and independent of $t$.\n\nWhich of the following statements are correct under the stated hypotheses?\n\nA. In the elliptic problem with $f$ even, assembling and solving in $V_h^{\\mathrm{even}}$ yields the same finite element solution as assembling in $V_h$ and then projecting onto $V_h^{\\mathrm{even}}$, while reducing the number of global degrees of freedom by approximately a factor of $2$ (up to an $O(1)$ correction due to the $x=0$ node). In the parity-adapted basis, the stiffness and load matrices are block-diagonal with respect to the even/odd split.\n\nB. In the elliptic problem with $f$ even, if one assembles and solves in the odd subspace $V_h^{\\mathrm{odd}}$, the unique Galerkin solution is $u_h \\equiv 0$.\n\nC. For the elliptic problem on a symmetric mesh with exact quadrature and even coefficients, the parity-adapted local construction $\\psi_i^{\\mathrm{even}}$ and $\\psi_i^{\\mathrm{odd}}$ produces a global mass matrix and stiffness matrix that exactly decouple the even and odd subspaces, i.e., off-diagonal even–odd coupling blocks vanish identically.\n\nD. For the parabolic Neumann problem with initial data $u_h(\\cdot,0) \\in W_h^{\\mathrm{odd}}$ and consistent mass matrix, the semidiscrete solution $u_h(\\cdot,t)$ remains in $W_h^{\\mathrm{odd}}$ for all $t \\ge 0$, and its discrete total mass $\\int_{-1}^1 u_h(x,t)\\, dx$ is exactly zero for all $t \\ge 0$, independent of the particular choice of time-integration method applied to the semidiscrete system.\n\nE. In a symmetric interior penalty discontinuous Galerkin (DG) discretization with central numerical fluxes on the full domain and the same symmetric mesh, even if coefficients are even and quadrature is exact, the even/odd decoupling is destroyed at the symmetry plane $x=0$ by flux coupling, so no degree-of-freedom reduction via parity is possible without loss of accuracy.\n\nF. In the elliptic problem with $f$ odd, using only the even subspace $V_h^{\\mathrm{even}}$ on the full domain produces the same solution as restricting the problem to the half-domain $[0,1]$ with a homogeneous Dirichlet condition at $x=0$ and then reflecting antisymmetrically.\n\nSelect all correct options.",
            "solution": "The problem statement has been validated and found to be well-posed, scientifically sound, and internally consistent. It describes a standard application of symmetry principles to the finite element method for second-order boundary value problems. We may proceed with the solution.\n\nThe fundamental principle underpinning the analysis is the decomposition of the function space $V_h$ into subspaces of even and odd functions, $V_h = V_h^{\\mathrm{even}} \\oplus V_h^{\\mathrm{odd}}$, and the behavior of the bilinear and linear forms with respect to this decomposition.\n\nLet $v_e \\in V_h^{\\mathrm{even}}$ and $v_o \\in V_h^{\\mathrm{odd}}$. By definition, $v_e(-x) = v_e(x)$ and $v_o(-x) = -v_o(x)$. The derivative of an even function is odd, and the derivative of an odd function is even. Thus, $v_e'(x)$ is an odd function and $v_o'(x)$ is an even function.\n\nThe bilinear form is $a_h(u,v) = \\int_{-1}^1 \\left( a(x)\\, u'(x)\\, v'(x) + c(x)\\, u(x)\\, v(x) \\right)\\, dx$. The coefficients $a(x)$ and $c(x)$ are given to be even functions. Let us evaluate $a_h(v_e, v_o)$. The integrand is $I(x) = a(x) v_e'(x) v_o'(x) + c(x) v_e(x) v_o(x)$.\n- The term $v_e(x) v_o(x)$ is a product of an even and an odd function, which is odd. Since $c(x)$ is even, the product $c(x) v_e(x) v_o(x)$ is odd.\n- The term $v_e'(x) v_o'(x)$ is a product of an odd and an even function, which is odd. Since $a(x)$ is even, the product $a(x) v_e'(x) v_o'(x)$ is odd.\n- The sum of two odd functions is odd, so the integrand $I(x)$ is an odd function.\n- The integral of any odd function over the symmetric domain $[-1,1]$ is identically zero.\nTherefore, we have the crucial orthogonality property:\n$$a_h(v_e, v_o) = 0 \\quad \\forall v_e \\in V_h^{\\mathrm{even}}, \\forall v_o \\in V_h^{\\mathrm{odd}}$$\nThis means the even and odd subspaces are orthogonal with respect to the energy inner product defined by $a_h(\\cdot, \\cdot)$.\n\nSimilarly, for the linear functional $\\ell_f(v) = \\int_{-1}^1 f(x) v(x) dx$:\n- If $f(x)$ is even and $v_o(x) \\in V_h^{\\mathrm{odd}}$, the integrand $f(x) v_o(x)$ is odd, so $\\ell_f(v_o) = 0$.\n- If $f(x)$ is odd and $v_e(x) \\in V_h^{\\mathrm{even}}$, the integrand $f(x) v_e(x)$ is odd, so $\\ell_f(v_e) = 0$.\n\nNow we analyze the discrete problem: Find $u_h \\in V_h$ such that $a_h(u_h, v_h) = \\ell_f(v_h)$ for all $v_h \\in V_h$. We can uniquely decompose the solution $u_h = u_h^{\\mathrm{even}} + u_h^{\\mathrm{odd}}$ where $u_h^{\\mathrm{even}} \\in V_h^{\\mathrm{even}}$ and $u_h^{\\mathrm{odd}} \\in V_h^{\\mathrm{odd}}$. By choosing test functions from the even and odd subspaces separately, the problem decouples into two independent subproblems:\n1. Find $u_h^{\\mathrm{even}} \\in V_h^{\\mathrm{even}}$ such that $a_h(u_h^{\\mathrm{even}}, v_e) = \\ell_f(v_e)$ for all $v_e \\in V_h^{\\mathrm{even}}$.\n2. Find $u_h^{\\mathrm{odd}} \\in V_h^{\\mathrm{odd}}$ such that $a_h(u_h^{\\mathrm{odd}}, v_o) = \\ell_f(v_o)$ for all $v_o \\in V_h^{\\mathrm{odd}}$.\n\nWe now evaluate each statement based on this framework.\n\n**A. In the elliptic problem with $f$ even, assembling and solving in $V_h^{\\mathrm{even}}$ yields the same finite element solution as assembling in $V_h$ and then projecting onto $V_h^{\\mathrm{even}}$, while reducing the number of global degrees of freedom by approximately a factor of $2$ (up to an $O(1)$ correction due to the $x=0$ node). In the parity-adapted basis, the stiffness and load matrices are block-diagonal with respect to the even/odd split.**\n\nIf $f$ is an even function, then $\\ell_f(v_o) = 0$ for all $v_o \\in V_h^{\\mathrm{odd}}$. The second subproblem becomes: Find $u_h^{\\mathrm{odd}} \\in V_h^{\\mathrm{odd}}$ such that $a_h(u_h^{\\mathrm{odd}}, v_o) = 0$ for all $v_o \\in V_h^{\\mathrm{odd}}$. Choosing $v_o = u_h^{\\mathrm{odd}}$, we get $a_h(u_h^{\\mathrm{odd}}, u_h^{\\mathrm{odd}}) = 0$. The bilinear form $a_h(\\cdot, \\cdot)$ is coercive on $V_h \\subset H_0^1(\\Omega)$, meaning $a_h(v,v) \\ge C\\|v\\|_{H^1}^2$ for some $C > 0$. Thus, $a_h(u_h^{\\mathrm{odd}}, u_h^{\\mathrm{odd}}) = 0$ implies $u_h^{\\mathrm{odd}} = 0$.\nThe full solution is therefore $u_h = u_h^{\\mathrm{even}}$, which is found by solving the first subproblem in $V_h^{\\mathrm{even}}$. This is exactly what \"assembling and solving in $V_h^{\\mathrm{even}}$\" means. As the full solution $u_h$ already lies in $V_h^{\\mathrm{even}}$, projecting it onto $V_h^{\\mathrm{even}}$ changes nothing. The dimension of $V_h^{\\mathrm{even}}$ is approximately half that of $V_h$, confirming the reduction in degrees of freedom. The \"parity-adapted basis\" partitions the basis into even and odd functions. Due to the orthogonality property $a_h(v_e, v_o)=0$, the stiffness matrix assembled in this basis will be block diagonal $$\\begin{pmatrix} K_{ee} & 0 \\\\ 0 & K_{oo} \\end{pmatrix}$$. The load vector $b_i = \\ell_f(\\psi_i)$ will have zero entries for all odd basis functions $\\psi_i$, giving a block structure $$\\begin{pmatrix} b_e \\\\ 0 \\end{pmatrix}$$. This corresponds to a block-diagonal system.\n\n**Verdict: Correct.**\n\n**B. In the elliptic problem with $f$ even, if one assembles and solves in the odd subspace $V_h^{\\mathrm{odd}}$, the unique Galerkin solution is $u_h \\equiv 0$.**\n\nThis refers to solving the second subproblem described above: Find $u_h^{\\mathrm{odd}} \\in V_h^{\\mathrm{odd}}$ such that $a_h(u_h^{\\mathrm{odd}}, v_o) = \\ell_f(v_o)$ for all $v_o \\in V_h^{\\mathrm{odd}}$. As established in the analysis for option A, when $f$ is even, the right-hand side $\\ell_f(v_o)$ is zero for all $v_o \\in V_h^{\\mathrm{odd}}$. The problem reduces to $a_h(u_h^{\\mathrm{odd}}, v_o) = 0$. By coercivity of $a_h(\\cdot, \\cdot)$, the only solution is $u_h^{\\mathrm{odd}} = 0$.\n\n**Verdict: Correct.**\n\n**C. For the elliptic problem on a symmetric mesh with exact quadrature and even coefficients, the parity-adapted local construction $\\psi_i^{\\mathrm{even}}$ and $\\psi_i^{\\mathrm{odd}}$ produces a global mass matrix and stiffness matrix that exactly decouple the even and odd subspaces, i.e., off-diagonal even–odd coupling blocks vanish identically.**\n\nThis statement formalizes the matrix structure. A parity-adapted basis is one of the form $\\{\\psi_i^{\\mathrm{even}}\\} \\cup \\{\\psi_j^{\\mathrm{odd}}\\}$.\nThe stiffness matrix entry between an even basis function $\\psi_i^{\\mathrm{even}}$ and an odd basis function $\\psi_j^{\\mathrm{odd}}$ is $K_{ij} = a_h(\\psi_i^{\\mathrm{even}}, \\psi_j^{\\mathrm{odd}})$. As proven in our initial analysis, this is zero.\nThe mass matrix entry is $M_{ij} = \\int_{-1}^1 \\psi_i^{\\mathrm{even}}(x) \\psi_j^{\\mathrm{odd}}(x) dx$. The integrand is an odd function, so its integral over $[-1,1]$ is zero.\nThus, any matrix entry coupling an even basis function with an odd one is zero for both the stiffness and mass matrices. This means the matrices are block-diagonal with respect to the even/odd partition. Exact quadrature is crucial to ensure these integrals evaluate to exactly zero.\n\n**Verdict: Correct.**\n\n**D. For the parabolic Neumann problem with initial data $u_h(\\cdot,0) \\in W_h^{\\mathrm{odd}}$ and consistent mass matrix, the semidiscrete solution $u_h(\\cdot,t)$ remains in $W_h^{\\mathrm{odd}}$ for all $t \\ge 0$, and its discrete total mass $\\int_{-1}^1 u_h(x,t)\\, dx$ is exactly zero for all $t \\ge 0$, independent of the particular choice of time-integration method applied to the semidiscrete system.**\n\nThe semidiscrete system is $M \\frac{d\\mathbf{u}}{dt} + K_0 \\mathbf{u} = 0$, where $M_{ij} = \\int_{-1}^1 \\psi_i \\psi_j dx$ and $(K_0)_{ij} = \\int_{-1}^1 a(x) \\psi_i' \\psi_j' dx$. As established in C, both matrices are block diagonal in a parity-adapted basis. The system decouples into two independent systems of ODEs for the even coefficients $\\mathbf{u}_e$ and odd coefficients $\\mathbf{u}_o$:\n$M_{ee} \\frac{d\\mathbf{u}_e}{dt} + K_{ee} \\mathbf{u}_e = 0$\n$M_{oo} \\frac{d\\mathbf{u}_o}{dt} + K_{oo} \\mathbf{u}_o = 0$\nThe initial condition is $u_h(\\cdot,0) \\in W_h^{\\mathrm{odd}}$, which means $\\mathbf{u}_e(0) = 0$. The first ODE is a homogeneous linear system with a zero initial condition. Its unique solution is $\\mathbf{u}_e(t) = 0$ for all $t \\ge 0$. This implies that the solution $u_h(\\cdot,t)$ has no even component and remains in $W_h^{\\mathrm{odd}}$ for all time. This conclusion depends only on the structure of the semi-discrete system, not on how it is integrated in time.\nThe total mass is the integral $\\int_{-1}^1 u_h(x,t) dx$. Since we have proven that $u_h(x,t)$ is an odd function for all $t \\ge 0$, its integral over the symmetric domain $[-1,1]$ is identically zero for all $t \\ge 0$.\n\n**Verdict: Correct.**\n\n**E. In a symmetric interior penalty discontinuous Galerkin (DG) discretization with central numerical fluxes on the full domain and the same symmetric mesh, even if coefficients are even and quadrature is exact, the even/odd decoupling is destroyed at the symmetry plane $x=0$ by flux coupling, so no degree-of-freedom reduction via parity is possible without loss of accuracy.**\n\nThe SIPG bilinear form includes face integrals. Let's analyze the contribution from the face at $x=0$ when coupling an even function $u \\in V_h^{\\mathrm{even}}$ and an odd function $v \\in V_h^{\\mathrm{odd}}$. At $x=0$:\n- The jump of an even function is $[u](0) = u(0^+) - u(0^-) = 0$.\n- The average of the flux of an even function is $\\{a u'\\}(0) = \\frac{1}{2}( a(0^+)u'(0^+) + a(0^-)u'(0^-) )$. Since $a$ is even and $u'$ is odd, this is $\\frac{1}{2}( a(0)u'(0^+) + a(0)(-u'(0^+)) ) = 0$.\nThe SIPG face integral terms are of the form $\\{a u'\\} [v]$, $[u] \\{a v'\\}$, and $\\frac{\\eta}{h}[u][v]$. At the face $x=0$, for the pair $(u,v)$, the terms become:\n- $\\{a u'\\}(0) [v](0) = 0 \\cdot [v](0) = 0$.\n- $[u](0) \\{a v'\\}(0) = 0 \\cdot \\{a v'\\}(0) = 0$.\n- $\\frac{\\eta}{h}[u](0) [v](0) = \\frac{\\eta}{h} \\cdot 0 \\cdot [v](0) = 0$.\nAll coupling terms at the central face are zero. The standard volume terms also result in zero coupling, as seen previously. Therefore, the even/odd decoupling is perfectly preserved in a standard SIPG method. The statement is factually incorrect.\n\n**Verdict: Incorrect.**\n\n**F. In the elliptic problem with $f$ odd, using only the even subspace $V_h^{\\mathrm{even}}$ on the full domain produces the same solution as restricting the problem to the half-domain $[0,1]$ with a homogeneous Dirichlet condition at $x=0$ and then reflecting antisymmetrically.**\n\nIf $f$ is an odd function, then for any $v_e \\in V_h^{\\mathrm{even}}$, the right-hand side is $\\ell_f(v_e) = \\int_{-1}^1 f(x)v_e(x) dx = 0$. The problem for the even part of the solution is: find $u_h^{\\mathrm{even}} \\in V_h^{\\mathrm{even}}$ such that $a_h(u_h^{\\mathrm{even}}, v_e) = 0$ for all $v_e \\in V_h^{\\mathrm{even}}$. By coercivity, the unique solution is $u_h^{\\mathrm{even}}=0$. So, the procedure \"using only the even subspace\" produces the zero function.\nThe true solution to the problem is purely odd, $u_h = u_h^{\\mathrm{odd}}$, found by solving $a_h(u_h^{\\mathrm{odd}}, v_o) = \\ell_f(v_o)$ for all $v_o \\in V_h^{\\mathrm{odd}}$. An odd function that is continuous must be zero at $x=0$. The procedure of solving on the half-domain $[0,1]$ with a homogeneous Dirichlet condition at $x=0$ and reflecting antisymmetrically is the standard, correct method for computing this odd solution $u_h^{\\mathrm{odd}}$. Unless $f$ is identically zero, this solution will be non-zero.\nThe statement asserts that the zero function (from the first procedure) is equal to the non-zero odd solution (from the second procedure). This is false.\n\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{ABCD}$$"
        },
        {
            "introduction": "Modern numerical techniques like the Virtual Element Method (VEM) provide the flexibility to use general polygonal or polyhedral meshes, where defining basis functions explicitly is often impractical. This advanced practice introduces the core VEM concept of defining basis functions implicitly through their mathematical properties, specifically via a projection operator $\\Pi^{\\nabla}_{k}$. By deriving this operator and applying it to a concrete example, you will gain insight into how these powerful methods maintain mathematical rigor and computability without ever needing to write down the basis functions in full. ",
            "id": "3431682",
            "problem": "Let $K$ be a simply connected polygonal element in $\\mathbb{R}^{2}$ with Lipschitz boundary and diameter $h_{K}$. Consider the local construction of a piecewise polynomial basis inspired by the Virtual Element Method (VEM), where basis functions are implicitly characterized through moments against polynomials up to total degree $k \\in \\mathbb{N}$, and the computable operators rely only on such moments and boundary traces. Work within the Sobolev space $H^{1}(K)$ and the polynomial space $\\mathbb{P}_{k}(K)$.\n\nStarting from first principles for a Galerkin method on polygons:\n- Use the energy inner product induced by the diffusion operator, namely the bilinear form $a_{K}(u,v)=\\int_{K}\\nabla u\\cdot\\nabla v\\,\\mathrm{d}x$, and the requirement of polynomial consistency.\n- Derive, from these principles, the unique linear operator $\\Pi^{\\nabla}_{k}:H^{1}(K)\\to\\mathbb{P}_{k}(K)$, called the $H^{1}$-seminorm projector, characterized by an orthogonality condition with respect to $a_{K}(\\cdot,\\cdot)$ and a constraint that fixes the additive constant, expressed only in terms of quantities that are computable from moments up to degree $k$ and boundary traces.\n\nExplain how to augment the consistent term $a_{K}(\\Pi^{\\nabla}_{k}u,\\Pi^{\\nabla}_{k}v)$ with a stabilization $S_{K}$ acting on the kernel of $\\Pi^{\\nabla}_{k}$ to obtain a computable bilinear form $a_{K}^{h}(\\cdot,\\cdot)$ that is stable, in the sense that it is bounded and coercive on $H^{1}(K)$ uniformly with respect to $h_{K}$ for shape-regular polygonal families. Specify a scaling for $S_{K}$ (in terms of $h_{K}$ and the dimension of $K$) that guarantees spectral equivalence to the $H^{1}$-seminorm on the kernel of $\\Pi^{\\nabla}_{k}$.\n\nThen specialize to $k=1$ and the polygon $K=[0,1]\\times[0,1]$. For the function $f(x,y)=x^{2}+xy+y^{2}$, compute the explicit polynomial $\\Pi^{\\nabla}_{1}f\\in\\mathbb{P}_{1}(K)$ obtained from your characterization. Express your final answer as a single closed-form analytic expression in the variables $x$ and $y$.",
            "solution": "The problem asks for a derivation of the $H^{1}$-seminorm projector central to the Virtual Element Method (VEM), an explanation of the associated stabilization required for a computable bilinear form, and a specific calculation. The problem is validated as scientifically sound, well-posed, objective, and self-contained.\n\n### Part 1: Characterization of the $H^{1}$-seminorm Projector $\\Pi^{\\nabla}_{k}$\n\nLet $u \\in H^{1}(K)$. We seek to define a unique polynomial $\\Pi^{\\nabla}_{k}u \\in \\mathbb{P}_{k}(K)$ that represents the \"best\" polynomial approximation of $u$ in the sense of the energy seminorm. The operator $\\Pi^{\\nabla}_{k}: H^{1}(K) \\to \\mathbb{P}_{k}(K)$ is defined by two conditions that ensure uniqueness and computability within the VEM framework.\n\n1.  **Orthogonality Condition**: The core principle is that the error in the projection, $u - \\Pi^{\\nabla}_{k}u$, must be orthogonal to all polynomials in $\\mathbb{P}_{k}(K)$ with respect to the energy bilinear form $a_{K}(v,w) = \\int_{K} \\nabla v \\cdot \\nabla w \\, \\mathrm{d}x$. This is expressed as:\n    $a_{K}(u - \\Pi^{\\nabla}_{k}u, q) = 0$ for all $q \\in \\mathbb{P}_{k}(K)$.\n    Expanding this condition gives the formulation that is used in practice: find $\\Pi^{\\nabla}_{k}u \\in \\mathbb{P}_{k}(K)$ such that\n    $$\n    \\int_{K} \\nabla(\\Pi^{\\nabla}_{k}u) \\cdot \\nabla q \\, \\mathrm{d}x = \\int_{K} \\nabla u \\cdot \\nabla q \\, \\mathrm{d}x \\quad \\forall q \\in \\mathbb{P}_{k}(K)\n    $$\n    This set of equations determines the gradient $\\nabla(\\Pi^{\\nabla}_{k}u)$ uniquely. Since the gradient of a constant is zero, $\\Pi^{\\nabla}_{k}u$ is determined only up to an additive constant.\n\n2.  **Constraint for Uniqueness**: To fix the additive constant, an additional condition is imposed. This condition must also be computable from the available information (moments of $u$ and its boundary trace). A standard and suitable choice is to enforce the equality of the average value over the element $K$:\n    $$\n    \\int_{K} \\Pi^{\\nabla}_{k}u \\, \\mathrm{d}x = \\int_{K} u \\, \\mathrm{d}x\n    $$\n    The right-hand side, $\\int_{K} u \\cdot 1 \\, \\mathrm{d}x$, is the zeroth-order moment of $u$, which is a computable quantity from the VEM degrees of freedom.\n\nTogether, these two conditions uniquely define the linear projector $\\Pi^{\\nabla}_{k}$. The right-hand side of the orthogonality condition is made computable by applying Green's first identity:\n$$\n\\int_{K} \\nabla u \\cdot \\nabla q \\, \\mathrm{d}x = \\int_{\\partial K} u (\\nabla q \\cdot \\mathbf{n}) \\, \\mathrm{d}s - \\int_{K} u (\\Delta q) \\, \\mathrm{d}x\n$$\nSince $q \\in \\mathbb{P}_{k}(K)$, $\\Delta q$ is a polynomial of degree at most $k-2$, so $\\int_{K} u (\\Delta q) \\, \\mathrm{d}x$ is a linear combination of moments of $u$. The boundary integral is computable from the trace of $u$ on $\\partial K$, which is part of the VEM degrees of freedom.\n\n### Part 2: The Stabilized Bilinear Form $a_{K}^{h}$\n\nThe VEM seeks a computable bilinear form $a_K^h(\\cdot,\\cdot)$ that is stable and consistent. It is composed of two parts:\n$$\na_{K}^{h}(u,v) = a_{K}(\\Pi^{\\nabla}_{k}u, \\Pi^{\\nabla}_{k}v) + S_{K}((I-\\Pi^{\\nabla}_{k})u, (I-\\Pi^{\\nabla}_{k})v)\n$$\n1.  **Consistency Term**: $a_{K}(\\Pi^{\\nabla}_{k}u, \\Pi^{\\nabla}_{k}v)$ is the consistency term. It is computable because $\\Pi^{\\nabla}_{k}u$ and $\\Pi^{\\nabla}_{k}v$ are polynomials of degree $k$ that can be explicitly determined from the degrees of freedom of $u$ and $v$.\n2.  **Stabilization Term**: $S_{K}(\\cdot,\\cdot)$ is the stabilization term. It acts on the component of the functions that is projected out by $\\Pi^{\\nabla}_{k}$. Crucially, the stabilization term itself must be computable from the degrees of freedom, yet approximate the energy of the non-polynomial part of the functions.\n\nFor the overall method to be stable, $a_{K}^{h}$ must be bounded and coercive uniformly with respect to the element diameter $h_K$. This is achieved if $S_K$ is chosen to be spectrally equivalent to the $H^1$-seminorm squared on the space it acts upon. That is, there exist constants $c_1, c_2 > 0$, independent of $h_K$, such that for any $w$ in the stabilized space (here, $(I-\\Pi^{\\nabla}_{k})(H^1(K))$):\n$$\nc_1 a_K(w,w) \\le S_K(w,w) \\le c_2 a_K(w,w)\n$$\nUnder this condition, stability follows. For coercivity, using the orthogonality property $a_K(\\Pi^{\\nabla}_{k}u, (I-\\Pi^{\\nabla}_{k})u) = 0$, we have:\n$|u|_{H^{1}(K)}^{2} = a_K(u,u) = a_K(\\Pi^{\\nabla}_{k}u, \\Pi^{\\nabla}_{k}u) + a_K((I-\\Pi^{\\nabla}_{k})u, (I-\\Pi^{\\nabla}_{k})u)$.\nThen, $a_K^h(u,u) = a_K(\\Pi^{\\nabla}_{k}u, \\Pi^{\\nabla}_{k}u) + S_K((I-\\Pi^{\\nabla}_{k})u, (I-\\Pi^{\\nabla}_{k})u) \\ge \\min(1, c_1) |u|_{H^{1}(K)}^{2}$.\nBoundedness follows a similar argument using the upper bound $c_2$.\n\n### Part 3: Scaling of the Stabilization Term $S_{K}$\n\nThe scaling of the stabilization term is critical for uniformity. For a second-order elliptic problem (like the one with bilinear form $a_K$), the entries of the element stiffness matrix scale with the element size $h_K$ as $h_K^{d-2}$, where $d$ is the spatial dimension. To maintain the correct balance between the consistency and stabilization terms, $S_K$ must have the same scaling.\n\nIn this problem, the domain is a polygon in $\\mathbb{R}^2$, so the dimension is $d=2$. The required scaling is therefore proportional to\n$$\nh_K^{d-2} = h_K^{2-2} = h_K^0 = 1\n$$\nThis implies that the stabilization parameter, which multiplies a dimensionless combination of degrees of freedom, should be a constant independent of the element diameter $h_K$. For families of shape-regular polygons, such a choice guarantees that the spectral equivalence constants $c_1$ and $c_2$ are uniform.\n\n### Part 4: Specific Calculation for $k=1$\n\nWe compute $p(x,y) = \\Pi^{\\nabla}_{1}f(x,y)$ for $f(x,y)=x^{2}+xy+y^{2}$ on the unit square $K=[0,1]\\times[0,1]$. We seek $p(x,y) = c_0 + c_1 x + c_2 y \\in \\mathbb{P}_{1}(K)$.\n\nThe gradients are $\\nabla f = \\langle 2x+y, x+2y \\rangle$ and $\\nabla p = \\langle c_1, c_2 \\rangle$.\nThe orthogonality condition $\\int_K \\nabla p \\cdot \\nabla q \\, \\mathrm{d}A = \\int_K \\nabla f \\cdot \\nabla q \\, \\mathrm{d}A$ is tested for a basis of $\\mathbb{P}_1(K) / \\mathbb{R}$, for instance $\\{x, y\\}$.\n\nFor $q=x$, with $\\nabla q = \\langle 1, 0 \\rangle$:\n$$\n\\int_0^1\\int_0^1 c_1 \\, \\mathrm{d}x\\mathrm{d}y = \\int_0^1\\int_0^1 (2x+y) \\, \\mathrm{d}x\\mathrm{d}y\n$$\nThe left side is $c_1$. The right side is:\n$$\n\\int_0^1 \\left[ x^2+xy \\right]_{x=0}^{x=1} \\, \\mathrm{d}y = \\int_0^1 (1+y) \\, \\mathrm{d}y = \\left[ y+\\frac{y^2}{2} \\right]_0^1 = 1+\\frac{1}{2} = \\frac{3}{2}\n$$\nThus, $c_1 = \\frac{3}{2}$.\n\nFor $q=y$, with $\\nabla q = \\langle 0, 1 \\rangle$:\n$$\n\\int_0^1\\int_0^1 c_2 \\, \\mathrm{d}x\\mathrm{d}y = \\int_0^1\\int_0^1 (x+2y) \\, \\mathrm{d}x\\mathrm{d}y\n$$\nThe left side is $c_2$. The right side is:\n$$\n\\int_0^1 \\left[ xy+y^2 \\right]_{y=0}^{y=1} \\, \\mathrm{d}x = \\int_0^1 (x+1) \\, \\mathrm{d}x = \\left[ \\frac{x^2}{2}+x \\right]_0^1 = \\frac{1}{2}+1 = \\frac{3}{2}\n$$\nThus, $c_2 = \\frac{3}{2}$.\n\nNext, we use the mean value constraint, $\\int_K p \\, \\mathrm{d}A = \\int_K f \\, \\mathrm{d}A$, to find $c_0$:\n$$\n\\int_0^1\\int_0^1 \\left( c_0 + \\frac{3}{2}x + \\frac{3}{2}y \\right) \\mathrm{d}x\\mathrm{d}y = \\int_0^1\\int_0^1 (x^2+xy+y^2) \\, \\mathrm{d}x\\mathrm{d}y\n$$\nThe left-hand side integral is:\n$$\nc_0 + \\frac{3}{2}\\int_0^1 x \\, \\mathrm{d}x + \\frac{3}{2}\\int_0^1 y \\, \\mathrm{d}y = c_0 + \\frac{3}{2}\\left(\\frac{1}{2}\\right) + \\frac{3}{2}\\left(\\frac{1}{2}\\right) = c_0 + \\frac{3}{2}\n$$\nThe right-hand side integral is:\n$$\n\\int_0^1 x^2 \\, \\mathrm{d}x + \\left(\\int_0^1 x \\, \\mathrm{d}x\\right)\\left(\\int_0^1 y \\, \\mathrm{d}y\\right) + \\int_0^1 y^2 \\, \\mathrm{d}y = \\frac{1}{3} + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + \\frac{1}{3} = \\frac{2}{3} + \\frac{1}{4} = \\frac{8+3}{12} = \\frac{11}{12}\n$$\nEquating the two sides gives:\n$$\nc_0 + \\frac{3}{2} = \\frac{11}{12} \\implies c_0 = \\frac{11}{12} - \\frac{18}{12} = -\\frac{7}{12}\n$$\nThe explicit polynomial is $\\Pi^{\\nabla}_{1}f(x,y) = -\\frac{7}{12} + \\frac{3}{2}x + \\frac{3}{2}y$.",
            "answer": "$$\n\\boxed{-\\frac{7}{12} + \\frac{3}{2}x + \\frac{3}{2}y}\n$$"
        }
    ]
}