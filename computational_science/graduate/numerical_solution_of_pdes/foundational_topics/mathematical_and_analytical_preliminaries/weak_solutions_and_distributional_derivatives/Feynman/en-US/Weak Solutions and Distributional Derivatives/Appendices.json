{
    "hands_on_practices": [
        {
            "introduction": "Classical calculus requires functions to be smooth, but many physical models involve sharp interfaces, shocks, or kinks. The theory of distributions provides a powerful framework to extend the concept of differentiation to these non-smooth functions. This first exercise invites you to explore this idea with a fundamental example, the absolute value function $u(x)=|x|$, by directly applying the definition of a distributional derivative to uncover its structure .",
            "id": "3462233",
            "problem": "Consider the function $u:\\mathbb{R}\\to\\mathbb{R}$ defined by $u(x)=|x|$. In the analysis of weak solutions for Partial Differential Equations (PDE), especially when designing numerical schemes for non-smooth solutions, one frequently passes to the sense of distributions to characterize derivatives that may contain measure-valued contributions. Using only the foundational definition of the distributional derivative, namely that for any test function $\\varphi\\in C_{c}^{\\infty}(\\mathbb{R})$ one has\n$$\\langle D u,\\varphi\\rangle=-\\langle u, D\\varphi\\rangle=-\\int_{\\mathbb{R}}u(x)\\, \\varphi'(x)\\, dx,$$\ncompute the distributional derivative $D u$ of $u(x)=|x|$ on $\\mathbb{R}$. Then, interpret $D u$ as a finite signed Radon measure via the Lebesgue–Radon decomposition and identify its singular part concentrated at $x=0$ by determining the coefficient $\\alpha\\in\\mathbb{R}$ in a decomposition of the form\n$$D u = f(x)\\, dx + \\alpha\\, \\delta_{0},$$\nwhere $f$ is a locally integrable function and $\\delta_{0}$ is the Dirac distribution at $x=0$. Provide your final answer as a row matrix containing the explicit expression for $D u$ (as a distribution represented by a function) and the coefficient $\\alpha$. No rounding is required. Express your answer in terms of standard functions and distributions, and use the notation $\\operatorname{sgn}(x)$ for the sign function.",
            "solution": "The problem is to compute the distributional derivative of the function $u(x) = |x|$ and to determine the coefficient $\\alpha$ in its decomposition into a regular part and a singular part concentrated at the origin.\n\nFirst, we validate the problem statement.\n\n**Step 1: Extract Givens**\n- Function: $u(x) = |x|$, with $u:\\mathbb{R} \\to \\mathbb{R}$.\n- Definition of distributional derivative: For any test function $\\varphi \\in C_{c}^{\\infty}(\\mathbb{R})$, the action of the distributional derivative $D u$ on $\\varphi$ is given by $\\langle D u, \\varphi \\rangle = -\\langle u, D\\varphi \\rangle = -\\int_{\\mathbb{R}} u(x) \\varphi'(x) dx$.\n- Task: Compute $D u$.\n- Decomposition form: $D u = f(x) dx + \\alpha \\delta_{0}$, where $f$ is a locally integrable function, $\\delta_{0}$ is the Dirac distribution at $x=0$, and $\\alpha \\in \\mathbb{R}$.\n- Goal: Find the explicit expression for $D u$ and the value of the coefficient $\\alpha$.\n- Notation: Use $\\operatorname{sgn}(x)$ for the sign function.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is mathematically well-posed and scientifically grounded. It addresses a fundamental concept in the theory of distributions, which is a cornerstone of modern analysis of partial differential equations. The function $u(x)=|x|$ is a canonical example used to illustrate the concept of weak or distributional derivatives for functions that are not classically differentiable everywhere. The definitions and objects, such as test functions $C_{c}^{\\infty}(\\mathbb{R})$, the Dirac distribution $\\delta_0$, and the Lebesgue-Radon decomposition, are standard in functional analysis. The problem is self-contained, unambiguous, and does not violate any mathematical principles. It is a standard, non-trivial exercise in this field.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The solution process may proceed.\n\nWe begin by applying the definition of the distributional derivative to the function $u(x) = |x|$. For an arbitrary test function $\\varphi \\in C_{c}^{\\infty}(\\mathbb{R})$, we have:\n$$\n\\langle D u, \\varphi \\rangle = - \\int_{-\\infty}^{\\infty} u(x) \\varphi'(x) dx = - \\int_{-\\infty}^{\\infty} |x| \\varphi'(x) dx\n$$\nThe absolute value function $|x|$ is defined piecewise. We split the integral at the point of non-differentiability, $x=0$:\n$$\n\\langle D u, \\varphi \\rangle = - \\left( \\int_{-\\infty}^{0} |x| \\varphi'(x) dx + \\int_{0}^{\\infty} |x| \\varphi'(x) dx \\right)\n$$\nWe substitute the definition of $|x|$ in each interval: $|x| = -x$ for $x  0$ and $|x| = x$ for $x  0$. The value at the single point $x=0$ does not affect the value of the Lebesgue integrals.\n$$\n\\langle D u, \\varphi \\rangle = - \\left( \\int_{-\\infty}^{0} (-x) \\varphi'(x) dx + \\int_{0}^{\\infty} x \\varphi'(x) dx \\right)\n$$\nWe now apply integration by parts to each integral. For the first integral, $\\int u dv = uv - \\int v du$, we set $u = -x$ and $dv = \\varphi'(x) dx$. This gives $du = -dx$ and $v = \\varphi(x)$.\n$$\n\\int_{-\\infty}^{0} (-x) \\varphi'(x) dx = \\left[(-x) \\varphi(x)\\right]_{-\\infty}^{0} - \\int_{-\\infty}^{0} \\varphi(x) (-dx)\n$$\nThe boundary term is evaluated as $\\lim_{x \\to 0^{-}} (-x \\varphi(x)) - \\lim_{x \\to -\\infty} (-x \\varphi(x))$. Since $\\varphi$ is a test function, it has compact support, meaning it is zero outside some finite interval $[-M, M]$. Thus, $\\lim_{x \\to -\\infty} (-x \\varphi(x)) = 0$. At the other boundary, $\\lim_{x \\to 0^{-}} (-x \\varphi(x)) = 0 \\cdot \\varphi(0) = 0$. So the boundary term vanishes. This leaves:\n$$\n\\int_{-\\infty}^{0} (-x) \\varphi'(x) dx = \\int_{-\\infty}^{0} \\varphi(x) dx\n$$\nFor the second integral, we set $u = x$ and $dv = \\varphi'(x) dx$. This gives $du = dx$ and $v = \\varphi(x)$.\n$$\n\\int_{0}^{\\infty} x \\varphi'(x) dx = \\left[x \\varphi(x)\\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\varphi(x) dx\n$$\nSimilarly, the boundary term $\\left[x \\varphi(x)\\right]_{0}^{\\infty} = \\lim_{x \\to \\infty} (x \\varphi(x)) - \\lim_{x \\to 0^{+}} (x \\varphi(x))$ is zero due to the compact support of $\\varphi$ and the fact that $\\lim_{x \\to 0^{+}} (x \\varphi(x)) = 0$. This leaves:\n$$\n\\int_{0}^{\\infty} x \\varphi'(x) dx = - \\int_{0}^{\\infty} \\varphi(x) dx\n$$\nSubstituting these results back into the expression for $\\langle D u, \\varphi \\rangle$:\n$$\n\\langle D u, \\varphi \\rangle = - \\left( \\int_{-\\infty}^{0} \\varphi(x) dx - \\int_{0}^{\\infty} \\varphi(x) dx \\right) = \\int_{0}^{\\infty} \\varphi(x) dx - \\int_{-\\infty}^{0} \\varphi(x) dx\n$$\nWe can express this result using the sign function, $\\operatorname{sgn}(x)$, which is defined as:\n$$\n\\operatorname{sgn}(x) = \\begin{cases} 1  \\text{if } x  0 \\\\ -1  \\text{if } x  0 \\\\ 0  \\text{if } x = 0 \\end{cases}\n$$\nThe integral can thus be written as:\n$$\n\\langle D u, \\varphi \\rangle = \\int_{0}^{\\infty} (1) \\cdot \\varphi(x) dx + \\int_{-\\infty}^{0} (-1) \\cdot \\varphi(x) dx = \\int_{-\\infty}^{\\infty} \\operatorname{sgn}(x) \\varphi(x) dx\n$$\nThis final expression shows that the action of the distribution $D u$ on any test function $\\varphi$ is equivalent to integrating $\\varphi$ against the function $\\operatorname{sgn}(x)$. The function $\\operatorname{sgn}(x)$ is locally integrable on $\\mathbb{R}$, and therefore defines a regular distribution. Thus, we can identify the distributional derivative $D u$ with the function $\\operatorname{sgn}(x)$.\n$$\nD u = \\operatorname{sgn}(x)\n$$\nThis is the first part of the required answer.\n\nNow we must interpret this result in the context of the decomposition $D u = f(x) dx + \\alpha \\delta_{0}$. This decomposition is a form of the Lebesgue–Radon decomposition of the measure associated with the distribution $D u$. The term $f(x) dx$ represents the absolutely continuous part of the measure with respect to the Lebesgue measure $dx$, while $\\alpha \\delta_{0}$ represents the singular part, concentrated on the set $\\{0\\}$ which has Lebesgue measure zero.\n\nOur result for the distributional derivative is $D u = \\operatorname{sgn}(x)$. This corresponds to the measure $d\\mu = \\operatorname{sgn}(x) dx$. By its very form, this measure is absolutely continuous with respect to the Lebesgue measure $dx$. Its Radon-Nikodym derivative is the function $\\operatorname{sgn}(x)$.\nTherefore, the singular part of this measure is zero.\n\nComparing our derived distribution $D u = \\operatorname{sgn}(x)$ to the given form $D u = f(x) dx + \\alpha \\delta_{0}$, we can make the following identifications:\n1.  The regular part, represented by the locally integrable function $f(x)$, is $f(x) = \\operatorname{sgn}(x)$.\n2.  The singular part, $\\alpha \\delta_0$, must be the zero distribution, as there is no singular component in our result for $D u$.\n\nFor the distribution $\\alpha \\delta_0$ to be the zero distribution, its coefficient $\\alpha$ must be zero.\n$$\n\\alpha = 0\n$$\nThus, the explicit expression for the distributional derivative is $D u = \\operatorname{sgn}(x)$, and the coefficient of the singular part is $\\alpha=0$.\n\nThe final answer is the row matrix containing the expression for $D u$ and the value of $\\alpha$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\operatorname{sgn}(x)  0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Having established how to define derivatives for non-smooth functions, we can now tackle partial differential equations with singular source terms, which are common in physics and engineering. In this practice, you will solve the Poisson equation where the source is an idealized point load, represented by a Dirac delta distribution . This exercise will guide you through constructing the weak solution and analyzing its regularity, revealing a fundamental property of elliptic PDEs: their ability to \"smooth out\" singularities.",
            "id": "3462264",
            "problem": "Let $\\Omega=(0,1)$, and let $x_{0}=\\frac{1}{2}$. Consider the Poisson problem with measure data\n$$\n-\\frac{d^{2}u}{dx^{2}}=\\delta_{x_{0}}\\quad\\text{in }\\Omega,\\qquad u(0)=u(1)=0,\n$$\nwhere $\\delta_{x_{0}}$ denotes the Dirac distribution supported at $x_{0}$. Work within the Sobolev space $H^{1}_{0}(\\Omega)$.\n\nUsing only the following foundational principles:\n- The definition of weak solution for a second-order linear elliptic problem: find $u\\in H^{1}_{0}(\\Omega)$ such that\n$$\n\\int_{0}^{1} u'(x)\\,v'(x)\\,dx=\\langle f,v\\rangle\\quad\\text{for all }v\\in H^{1}_{0}(\\Omega),\n$$\nwhere $\\langle\\cdot,\\cdot\\rangle$ denotes the duality pairing between $H^{-1}(\\Omega)$ and $H^{1}_{0}(\\Omega)$.\n- The elementary distributional identity for the Dirac distribution: $\\langle \\delta_{x_{0}},v\\rangle=v(x_{0})$ for any sufficiently regular $v$.\n- The characterization of distributional derivatives of piecewise $C^{1}$ functions: the distributional derivative of a function whose classical derivative has a jump of magnitude $J$ at a point includes a Dirac distribution of strength $J$ at that point.\n\nPerform the following tasks:\n1. Justify that $\\delta_{x_{0}}$ defines a continuous linear functional on $H^{1}_{0}(\\Omega)$ in one spatial dimension, hence $\\delta_{x_{0}}\\in H^{-1}(\\Omega)$, and conclude that the weak problem admits a unique solution $u\\in H^{1}_{0}(\\Omega)$.\n2. Construct explicitly the weak solution $u\\in H^{1}_{0}(\\Omega)$ by solving the distributional ordinary differential equation and enforcing the boundary conditions. Your construction must make clear the nature of the singularity in the distributional second derivative at $x_{0}$.\n3. Prove that the solution you constructed is not in $H^{2}(\\Omega)$ by identifying its second distributional derivative and explaining why it does not belong to $L^{2}(\\Omega)$.\n4. Provide your final answer as a single closed-form analytic expression for $u(x)$, valid for all $x\\in(0,1)$.\n\nYour final answer must be a single closed-form analytic expression without units. No rounding is required.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard problem in the theory of Sobolev spaces and partial differential equations. No inconsistencies, missing information, or pseudoscientific claims are present. We may proceed with the solution.\n\nThe problem is to find the weak solution $u \\in H^{1}_{0}(\\Omega)$ for the Poisson equation with a point source, given by\n$$\n-\\frac{d^{2}u}{dx^{2}}=\\delta_{x_{0}}\\quad\\text{in }\\Omega=(0,1),\\qquad u(0)=u(1)=0,\n$$\nwhere $x_{0}=\\frac{1}{2}$. The weak formulation requires finding $u \\in H^{1}_{0}(\\Omega)$ such that for all test functions $v \\in H^{1}_{0}(\\Omega)$, the following holds:\n$$\n\\int_{0}^{1} u'(x)v'(x)\\,dx = \\langle \\delta_{x_{0}}, v \\rangle = v(x_{0}).\n$$\n\n**1. Existence and Uniqueness of the Weak Solution**\n\nThe existence and uniqueness of a solution $u \\in H^{1}_{0}(\\Omega)$ are guaranteed by the Lax-Milgram theorem if the bilinear form $a(u,v) = \\int_{0}^{1} u'(x)v'(x)\\,dx$ is continuous and coercive on $H^{1}_{0}(\\Omega)$, and the linear functional $L(v) = \\langle \\delta_{x_{0}}, v \\rangle$ is continuous on $H^{1}_{0}(\\Omega)$.\n\nThe bilinear form $a(u,v)$ is the standard inner product on $H^{1}_{0}(\\Omega)$, whose associated norm is $\\|v\\|_{H^{1}_{0}} = \\left(\\int_{0}^{1} |v'(x)|^{2}\\,dx\\right)^{1/2}$.\n- Continuity: By the Cauchy-Schwarz inequality, $|a(u,v)| = \\left|\\int_{0}^{1} u'(x)v'(x)\\,dx\\right| \\le \\|u'\\|_{L^{2}}\\|v'\\|_{L^{2}} = \\|u\\|_{H^{1}_{0}}\\|v\\|_{H^{1}_{0}}$. Thus, $a(\\cdot,\\cdot)$ is continuous.\n- Coercivity: $a(v,v) = \\int_{0}^{1} |v'(x)|^{2}\\,dx = \\|v\\|_{H^{1}_{0}}^{2}$. Thus, $a(\\cdot,\\cdot)$ is coercive.\n\nNext, we must show that the functional $L(v) = v(x_{0})$ is a continuous linear functional on $H^{1}_{0}(\\Omega)$, which is equivalent to showing that $\\delta_{x_{0}} \\in H^{-1}(\\Omega)$.\nLinearity is straightforward: for any constants $c_{1}, c_{2} \\in \\mathbb{R}$ and functions $v_{1}, v_{2} \\in H^{1}_{0}(\\Omega)$, $L(c_{1}v_{1}+c_{2}v_{2})=(c_{1}v_{1}+c_{2}v_{2})(x_{0}) = c_{1}v_{1}(x_{0}) + c_{2}v_{2}(x_{0}) = c_{1}L(v_{1})+c_{2}L(v_{2})$.\nFor continuity, we must find a constant $C$ such that $|L(v)| \\le C\\|v\\|_{H^{1}_{0}}$ for all $v \\in H^{1}_{0}(\\Omega)$. For any $v \\in H^{1}_{0}(\\Omega)$, we can write $v(x) = \\int_{0}^{x} v'(t)\\,dt$ since $v(0)=0$. Applying this at $x=x_{0}$:\n$$\n|v(x_{0})| = \\left|\\int_{0}^{x_{0}} v'(t)\\,dt\\right| = \\left|\\int_{0}^{1} \\mathbf{1}_{[0, x_{0}]}(t) v'(t)\\,dt\\right|,\n$$\nwhere $\\mathbf{1}_{[0, x_{0}]}$ is the indicator function of the interval $[0, x_{0}]$. By the Cauchy-Schwarz inequality in $L^{2}(\\Omega)$:\n$$\n|v(x_{0})| \\le \\left(\\int_{0}^{1} |\\mathbf{1}_{[0, x_{0}]}(t)|^{2}\\,dt\\right)^{1/2} \\left(\\int_{0}^{1} |v'(t)|^{2}\\,dt\\right)^{1/2} = \\left(\\int_{0}^{x_{0}} 1\\,dt\\right)^{1/2} \\|v'\\|_{L^{2}} = \\sqrt{x_{0}} \\|v\\|_{H^{1}_{0}}.\n$$\nSince $|L(v)| = |v(x_{0})| \\le \\sqrt{x_{0}} \\|v\\|_{H^{1}_{0}}$, the functional $L$ is continuous. The Sobolev embedding theorem for $W^{1,p}(\\Omega) \\hookrightarrow C(\\bar{\\Omega})$ when $p1$ in one dimension confirms that point evaluation is a continuous operation.\nSince $a(\\cdot,\\cdot)$ is continuous and coercive and $L(\\cdot)$ is continuous, the Lax-Milgram theorem guarantees the existence of a unique weak solution $u \\in H^{1}_{0}(\\Omega)$.\n\n**2. Explicit Construction of the Weak Solution**\n\nWe solve the equation $-\\frac{d^{2}u}{dx^{2}} = \\delta_{x_{0}}$ in the sense of distributions. Integrating once with respect to $x$ gives:\n$$\n-\\frac{du}{dx} = H(x-x_{0}) + C_{1},\n$$\nwhere $H$ is the Heaviside step function and $C_{1}$ is a constant of integration. Integrating a second time yields:\n$$\n-u(x) = \\int H(x-x_{0})\\,dx + C_{1}x + C_{2} = (x-x_{0})H(x-x_{0}) + C_{1}x + C_{2}.\n$$\nThis gives the general solution:\n$$\nu(x) = -(x-x_{0})H(x-x_{0}) - C_{1}x - C_{2}.\n$$\nWe can write this in piecewise form:\n$$\nu(x) = \\begin{cases} -C_{1}x - C_{2}  \\text{if } 0  x  x_{0} \\\\ -(x-x_{0}) - C_{1}x - C_{2}  \\text{if } x_{0}  x  1 \\end{cases}\n$$\nNow we apply the boundary conditions $u(0)=0$ and $u(1)=0$.\nFrom $u(0)=0$: $-C_{1}(0) - C_{2} = 0 \\implies C_{2}=0$.\nFrom $u(1)=0$: $-(1-x_{0}) - C_{1}(1) = 0 \\implies C_{1} = -(1-x_{0})$.\nSubstituting the constants back into the piecewise expression for $u(x)$:\nFor $0  x  x_{0}$: $u(x) = -(-(1-x_{0}))x = (1-x_{0})x$.\nFor $x_{0}  x  1$: $u(x) = -(x-x_{0}) - (-(1-x_{0}))x = -x+x_{0}+x-x_{0}x = x_{0}(1-x)$.\nSo, the solution is\n$$\nu(x) = \\begin{cases} (1-x_{0})x  \\text{if } 0 \\le x \\le x_{0} \\\\ x_{0}(1-x)  \\text{if } x_{0} \\le x \\le 1 \\end{cases}\n$$\nThis function is continuous at $x_0$ and satisfies the boundary conditions. It is in $C^{0}(\\bar{\\Omega})$ and is piecewise linear, hence its first derivative $u'$ is in $L^{2}(\\Omega)$, so $u \\in H^{1}_{0}(\\Omega)$. For the specific value $x_{0}=\\frac{1}{2}$:\n$$\nu(x) = \\begin{cases} \\frac{1}{2}x  \\text{if } 0 \\le x \\le \\frac{1}{2} \\\\ \\frac{1}{2}(1-x)  \\text{if } \\frac{1}{2} \\le x \\le 1 \\end{cases}\n$$\nThe singularity is manifest in the derivatives. The classical first derivative is:\n$$\nu'(x) = \\begin{cases} 1-x_{0}  \\text{if } 0  x  x_{0} \\\\ -x_{0}  \\text{if } x_{0}  x  1 \\end{cases}\n$$\nThis function has a jump discontinuity at $x=x_{0}$. The magnitude of the jump is $J = u'(x_{0}^{+}) - u'(x_{0}^{-}) = (-x_{0}) - (1-x_{0}) = -1$.\nThe second distributional derivative is therefore $u'' = J \\cdot \\delta_{x_{0}} = -\\delta_{x_{0}}$. This means $-u'' = \\delta_{x_{0}}$, which is the original differential equation, confirming our constructed solution is correct.\n\n**3. Regularity of the Solution**\n\nTo determine if $u \\in H^{2}(\\Omega)$, we must check if its second weak derivative, $u''$, is in $L^{2}(\\Omega)$. The space $H^{2}(\\Omega)$ is defined as $\\{v \\in L^{2}(\\Omega) \\mid v', v'' \\in L^{2}(\\Omega)\\}$.\nFrom the construction, we found that the second distributional derivative of $u$ is $u'' = -\\delta_{x_{0}}$. We must determine if the distribution $-\\delta_{x_{0}}$ corresponds to a function in $L^{2}(\\Omega)$. A distribution $T$ is in $L^{2}(\\Omega)$ if there exists a function $g \\in L^{2}(\\Omega)$ such that $\\langle T, \\phi \\rangle = \\int_{\\Omega} g(x)\\phi(x)\\,dx$ for all test functions $\\phi \\in C^{\\infty}_{c}(\\Omega)$.\nFor $T = -\\delta_{x_{0}}$, we have $\\langle -\\delta_{x_{0}}, \\phi \\rangle = -\\phi(x_{0})$. Suppose there exists a function $g \\in L^{2}(\\Omega)$ such that $-\\phi(x_{0}) = \\int_{0}^{1} g(x)\\phi(x)\\,dx$ for all $\\phi \\in C^{\\infty}_{c}(\\Omega)$.\nConsider a sequence of non-negative smooth bump functions $\\phi_{n} \\in C^{\\infty}_{c}(\\Omega)$ centered at $x_{0}$, with support shrinking to $\\{x_{0}\\}$ as $n \\to \\infty$, and normalized such that $\\phi_{n}(x_{0})=1$ for all $n$. For instance, let $\\psi$ be a standard bump function with $\\psi(0)=1$ and support in $(-1,1)$, then $\\phi_{n}(x) = \\psi(n(x-x_{0}))$ for $n$ large enough that the support is in $\\Omega$.\nFor each $n$, our hypothesis requires $\\int_{0}^{1} g(x)\\phi_{n}(x)\\,dx = -\\phi_{n}(x_{0}) = -1$.\nHowever, as $n\\to\\infty$, $\\phi_{n}(x) \\to 0$ for all $x \\ne x_{0}$. Since the sequence $\\{\\phi_{n}\\}$ is uniformly bounded (by $\\sup|\\psi|$), and $g \\in L^{2}(\\Omega) \\subset L^{1}(\\Omega)$ on a bounded domain, we can apply the Dominated Convergence Theorem:\n$$\n\\lim_{n\\to\\infty} \\int_{0}^{1} g(x)\\phi_{n}(x)\\,dx = \\int_{0}^{1} g(x) \\lim_{n\\to\\infty} \\phi_{n}(x)\\,dx = \\int_{0}^{1} g(x) \\cdot 0 \\,dx = 0.\n$$\nThis leads to the contradiction $-1=0$. Therefore, no such function $g \\in L^{2}(\\Omega)$ exists. The Dirac distribution $\\delta_{x_{0}}$ is not in $L^{2}(\\Omega)$. Consequently, $u'' \\notin L^{2}(\\Omega)$, which proves that the solution $u$ is not in $H^{2}(\\Omega)$.\n\n**4. Final Expression for the Solution**\n\nThe piecewise expression for $u(x)$ with $x_{0}=\\frac{1}{2}$ is:\n$$\nu(x) = \\begin{cases} \\frac{1}{2}x  \\text{if } 0 \\le x \\le \\frac{1}{2} \\\\ \\frac{1}{2}(1-x)  \\text{if } \\frac{1}{2} \\le x \\le 1 \\end{cases}\n$$\nThis can be written compactly using the absolute value function. The function is a \"tent\" with its peak at $x=\\frac{1}{2}$. The value at the peak is $u(\\frac{1}{2}) = \\frac{1}{4}$. The function can be expressed as a downward-opening absolute value function, shifted and scaled appropriately:\n$$\nu(x) = \\frac{1}{4} - \\frac{1}{2}\\left|x - \\frac{1}{2}\\right| = \\frac{1}{2}\\left(\\frac{1}{2} - \\left|x - \\frac{1}{2}\\right|\\right).\n$$\nThis is the single closed-form analytic expression for the solution $u(x)$.",
            "answer": "$$\n\\boxed{\\frac{1}{2}\\left(\\frac{1}{2} - \\left|x - \\frac{1}{2}\\right|\\right)}\n$$"
        },
        {
            "introduction": "The analytical power of distribution theory is immense, but new challenges emerge when we try to translate these concepts into computer algorithms for solving PDEs. A notoriously difficult problem is defining the product of distributions, which is crucial for handling nonlinearities. This coding exercise provides a hands-on exploration of this issue, asking you to implement and evaluate different discrete versions of the product rule and measure their consistency using the dual Sobolev norm $H^{-1}$ .",
            "id": "3462295",
            "problem": "Consider the one-dimensional domain $[0,1]$ with a uniform mesh of $N$ cells, cell width $h=1/N$, cell indices $i=0,1,\\dots,N-1$, and interfaces (nodes) $x_j=jh$ for $j=0,1,\\dots,N$. Let $u$ and $v$ be cellwise constant functions, represented by arrays $\\{u_i\\}_{i=0}^{N-1}$ and $\\{v_i\\}_{i=0}^{N-1}$ with values evaluated at cell centers $x_i^{\\mathrm{c}}=(i+1/2)h$. In the sense of distributions, the derivative of a piecewise constant function is a sum of Dirac delta distributions at the interfaces. On the discrete mesh, the distributional derivatives are represented by jumps at interior interfaces $j=1,\\dots,N-1$:\n$$\n\\Delta u_j = u_j - u_{j-1}, \\quad \\Delta v_j = v_j - v_{j-1}, \\quad \\Delta(uv)_j = (u v)_j - (u v)_{j-1},\n$$\nwhere $(uv)_i = u_i v_i$ and the notation $u_j$ means the cell value to the right of interface $x_j$ while $u_{j-1}$ is the cell value to the left.\n\nMultiplication of a distribution by a discontinuous function requires a choice of representative value at the point of discontinuity. Define three discrete analogues of the Leibniz rule (product rule) at each interior interface $j$ by specifying how the coefficient is taken at the interface:\n- Left-trace scheme: use $u_{j-1}$ for the coefficient multiplying $\\Delta v_j$ and $v_{j-1}$ for the coefficient multiplying $\\Delta u_j$.\n- Right-trace scheme: use $u_{j}$ for the coefficient multiplying $\\Delta v_j$ and $v_{j}$ for the coefficient multiplying $\\Delta u_j$.\n- Arithmetic-average scheme: use $\\tfrac{1}{2}(u_{j-1}+u_j)$ for the coefficient multiplying $\\Delta v_j$ and $\\tfrac{1}{2}(v_{j-1}+v_j)$ for the coefficient multiplying $\\Delta u_j$.\n\nFor each scheme, define the discrete distributional residual at interface $j$ by\n$$\nr_j = \\Delta(uv)_j - \\alpha_j\\, \\Delta v_j - \\beta_j\\, \\Delta u_j,\n$$\nwhere $(\\alpha_j,\\beta_j)$ are chosen according to the scheme above. This residual is a discrete distribution supported at the interior nodes. To quantitatively assess the residual in the dual Sobolev space $H^{-1}(0,1)$, use the variational characterization: the $H^{-1}$ norm of a distribution $f$ is\n$$\n\\|f\\|_{H^{-1}(0,1)} = \\sup_{\\varphi \\in H_0^1(0,1),\\ \\|\\varphi'\\|_{L^2}=1} \\langle f,\\varphi \\rangle,\n$$\nwhich is equivalent to solving for $w \\in H_0^1(0,1)$ such that\n$$\n\\int_0^1 w'(x)\\, \\psi'(x)\\, dx = \\langle f,\\psi \\rangle \\quad \\text{for all } \\psi \\in H_0^1(0,1),\n$$\nand then $\\|f\\|_{H^{-1}}^2 = \\int_0^1 |w'(x)|^2\\, dx$. Discretize this with the standard one-dimensional Finite Element Method (FEM) using linear hat functions on the mesh nodes with homogeneous Dirichlet boundary conditions at $x=0$ and $x=1$. The stiffness matrix $K \\in \\mathbb{R}^{(N-1)\\times(N-1)}$ is the tridiagonal matrix\n$$\nK = \\frac{1}{h}\\begin{bmatrix}\n2  -1  0  \\dots  0 \\\\\n-1  2  -1  \\ddots  \\vdots \\\\\n0  -1  \\ddots  \\ddots  0 \\\\\n\\vdots  \\ddots  \\ddots  2  -1 \\\\\n0  \\dots  0  -1  2\n\\end{bmatrix}.\n$$\nThe load vector $b \\in \\mathbb{R}^{N-1}$ representing the residual distribution is defined by $b_j = r_j$ for $j=1,\\dots,N-1$ (Dirac distributions at interior nodes pair with nodal test functions by evaluation). Solve $Ku=b$ for $u \\in \\mathbb{R}^{N-1}$ and define the discrete $H^{-1}$ norm by\n$$\n\\|f\\|_{H^{-1}} = \\sqrt{u^\\top b}.\n$$\n\nImplement a program that constructs $u$ and $v$ on the mesh for each test case, forms the residuals $r_j$ for the three schemes, assembles the corresponding load vectors $b$, solves $Ku=b$, and outputs the discrete $H^{-1}$ norms. Use the following test suite of parameter values:\n\n- Test case 1 (general discontinuities, \"happy path\"): $N=64$. Define\n  $$\n  u(x) = \\begin{cases}\n  1.0,  x  0.35, \\\\\n  -0.5,  0.35 \\le x  0.70, \\\\\n  2.0,  0.70 \\le x \\le 1,\n  \\end{cases}\n  \\quad\n  v(x) = \\begin{cases}\n  0.0,  x  0.25, \\\\\n  1.5,  0.25 \\le x  0.80, \\\\\n  -1.0,  0.80 \\le x \\le 1,\n  \\end{cases}\n  $$\n  evaluated at cell centers $x_i^{\\mathrm{c}}$.\n- Test case 2 (aligned discontinuities and multiple jumps): $N=100$. Define\n  $$\n  u(x) = \\begin{cases}\n  2.0,  x  0.50, \\\\\n  -1.0,  0.50 \\le x  0.75, \\\\\n  0.5,  0.75 \\le x \\le 1,\n  \\end{cases}\n  \\quad\n  v(x) = \\begin{cases}\n  1.0,  x  0.25, \\\\\n  0.0,  0.25 \\le x  0.50, \\\\\n  3.0,  0.50 \\le x \\le 1,\n  \\end{cases}\n  $$\n  evaluated at cell centers $x_i^{\\mathrm{c}}$.\n- Test case 3 (constant factor edge case): $N=32$. Define\n  $$\n  u(x) \\equiv 1.0 \\text{ for all } x \\in [0,1],\n  \\quad\n  v(x) = \\begin{cases}\n  -1.0,  x  0.60, \\\\\n  2.0,  0.60 \\le x \\le 1,\n  \\end{cases}\n  $$\n  evaluated at cell centers $x_i^{\\mathrm{c}}$.\n\nFor each test case, compute and report the three discrete $H^{-1}$ norms corresponding to the left-trace scheme, the right-trace scheme, and the arithmetic-average scheme, in that order. Your program should produce a single line of output containing the nine results as a comma-separated list enclosed in square brackets, in the order:\n$$\n[\\|f\\|_{H^{-1}}^{\\mathrm{left}}(\\text{TC1}),\\|f\\|_{H^{-1}}^{\\mathrm{right}}(\\text{TC1}),\\|f\\|_{H^{-1}}^{\\mathrm{avg}}(\\text{TC1}),\\|f\\|_{H^{-1}}^{\\mathrm{left}}(\\text{TC2}),\\|f\\|_{H^{-1}}^{\\mathrm{right}}(\\text{TC2}),\\|f\\|_{H^{-1}}^{\\mathrm{avg}}(\\text{TC2}),\\|f\\|_{H^{-1}}^{\\mathrm{left}}(\\text{TC3}),\\|f\\|_{H^{-1}}^{\\mathrm{right}}(\\text{TC3}),\\|f\\|_{H^{-1}}^{\\mathrm{avg}}(\\text{TC3})].\n$$\nAll outputs are real numbers with no physical units, and the final line must follow the exact specified format.",
            "solution": "The problem requires the computation of a discrete $H^{-1}$ norm for the residual of a discrete product rule applied to piecewise constant functions. The core of the solution involves three main stages: first, simplifying the expressions for the residuals; second, performing the numerical discretization of the functions and calculating the residual vectors; and third, solving the specified linear system to compute the norm.\n\n**1. Simplification of the Residuals**\n\nThe residual at an interior interface $x_j$ (where $j \\in \\{1, \\dots, N-1\\}$) is defined as $r_j = \\Delta(uv)_j - \\alpha_j \\Delta v_j - \\beta_j \\Delta u_j$. Let us analyze this for each scheme. Note the elementary identity: $\\Delta(uv)_j = u_j v_j - u_{j-1} v_{j-1} = u_{j-1} \\Delta v_j + v_j \\Delta u_j$.\n\n*   **Left-trace scheme**: Here, $(\\alpha_j, \\beta_j) = (u_{j-1}, v_{j-1})$.\n    The residual is $r_j^{\\mathrm{left}} = \\Delta(uv)_j - u_{j-1} \\Delta v_j - v_{j-1} \\Delta u_j$.\n    A simple algebraic manipulation shows:\n    $$\n    r_j^{\\mathrm{left}} = (u_j v_j - u_{j-1}v_{j-1}) - u_{j-1}(v_j - v_{j-1}) - v_{j-1}(u_j - u_{j-1})\n    $$\n    $$\n    = u_j v_j - u_{j-1}v_{j-1} - u_{j-1}v_j + u_{j-1}v_{j-1} - v_{j-1}u_j + v_{j-1}u_{j-1}\n    $$\n    $$\n    = u_j v_j - u_{j-1}v_j - u_j v_{j-1} + u_{j-1}v_{j-1} = (u_j - u_{j-1})(v_j - v_{j-1}) = \\Delta u_j \\Delta v_j.\n    $$\n\n*   **Right-trace scheme**: Here, $(\\alpha_j, \\beta_j) = (u_j, v_j)$.\n    The residual is $r_j^{\\mathrm{right}} = \\Delta(uv)_j - u_j \\Delta v_j - v_j \\Delta u_j$.\n    $$\n    r_j^{\\mathrm{right}} = (u_j v_j - u_{j-1}v_{j-1}) - u_j(v_j - v_{j-1}) - v_j(u_j - u_{j-1})\n    $$\n    $$\n    = u_j v_j - u_{j-1}v_{j-1} - u_j v_j + u_j v_{j-1} - u_j v_j + u_{j-1}v_j\n    $$\n    $$\n    = -u_{j-1}v_{j-1} + u_j v_{j-1} + u_{j-1}v_j - u_j v_j = -(u_j - u_{j-1})(v_j - v_{j-1}) = -\\Delta u_j \\Delta v_j.\n    $$\n\n*   **Arithmetic-average scheme**: Here, $(\\alpha_j, \\beta_j) = (\\frac{u_{j-1}+u_j}{2}, \\frac{v_{j-1}+v_j}{2})$. Let $\\bar{u}_j = (\\alpha_j, \\beta_j)_1$ and $\\bar{v}_j = (\\alpha_j, \\beta_j)_2$.\n    The discrete product rule $\\Delta(uv)_j = \\bar{u}_j \\Delta v_j + \\bar{v}_j \\Delta u_j$ holds exactly for piecewise constant functions. This is a standard result for conservative numerical schemes.\n    Thus, the residual is identically zero:\n    $$\n    r_j^{\\mathrm{avg}} = \\Delta(uv)_j - \\bar{u}_j \\Delta v_j - \\bar{v}_j \\Delta u_j = 0.\n    $$\n\nThese simplifications are significant. The load vectors for the three schemes are $b^{\\mathrm{left}} = \\{\\Delta u_j \\Delta v_j\\}_{j=1}^{N-1}$, $b^{\\mathrm{right}} = -b^{\\mathrm{left}}$, and $b^{\\mathrm{avg}} = \\{0\\}_{j=1}^{N-1}$.\n\n**2. $H^{-1}$ Norm Calculation**\n\nFor a given load vector $b \\in \\mathbb{R}^{N-1}$, we must solve $K w = b$ and compute $\\sqrt{w^\\top b}$.\n*   Since $b^{\\mathrm{avg}}$ is the zero vector, the solution is $w^{\\mathrm{avg}}=0$ and its a norm is $\\sqrt{0^\\top 0} = 0$. This will be the case for all test cases.\n*   Since $b^{\\mathrm{right}} = -b^{\\mathrm{left}}$, the corresponding solution is $w^{\\mathrm{right}} = K^{-1}(-b^{\\mathrm{left}}) = -K^{-1}b^{\\mathrm{left}} = -w^{\\mathrm{left}}$. The norm is then:\n    $$\n    \\|f^{\\mathrm{right}}\\|_{H^{-1}} = \\sqrt{(w^{\\mathrm{right}})^\\top b^{\\mathrm{right}}} = \\sqrt{(-w^{\\mathrm{left}})^\\top (-b^{\\mathrm{left}})} = \\sqrt{(w^{\\mathrm{left}})^\\top b^{\\mathrm{left}}} = \\|f^{\\mathrm{left}}\\|_{H^{-1}}.\n    $$\n    Therefore, the norms for the left-trace and right-trace schemes will be identical.\n\nThe algorithm is as follows for each test case:\n1.  Define the mesh with $N$ cells and cell width $h=1/N$.\n2.  Create an array of cell centers $x_i^{\\mathrm{c}} = (i+0.5)h$ for $i=0, \\dots, N-1$.\n3.  Evaluate the functions $u(x)$ and $v(x)$ at these cell centers to obtain discrete arrays $u$ and $v$.\n4.  Compute the interface jumps $\\Delta u_j = u_j - u_{j-1}$ and $\\Delta v_j = v_j - v_{j-1}$ for $j=1, \\dots, N-1$. These form vectors `du` and `dv` of length $N-1$.\n5.  Calculate the load vector $b = \\texttt{du} \\cdot \\texttt{dv}$ (element-wise product).\n6.  If $b$ is the zero vector, the norm is $0$. This occurs if, for every interface, at least one of the functions $u$ or $v$ is continuous ($\\Delta u_j=0$ or $\\Delta v_j=0$).\n7.  If $b$ is non-zero, construct the $(N-1) \\times (N-1)$ stiffness matrix $K$.\n8.  Solve the linear system $Kw = b$ for $w$.\n9.  Compute the norm as $\\sqrt{w^\\top b}$.\n10. The three norms for the test case are $[\\text{norm}, \\text{norm}, 0.0]$.\n\nThis analysis predicts that for Test Case 1 (disjoint discontinuities) and Test Case 3 ($u$ is constant, so $\\Delta u_j = 0$ for all $j$), the load vector $b$ will be zero, resulting in norms of $[0.0, 0.0, 0.0]$. For Test Case 2, where discontinuities are aligned at $x=0.5$, $b$ will be non-zero, yielding a positive norm for the left/right schemes.\n\n**3. Implementation**\n\nThe implementation follows the algorithm above. We define a function to compute the norm for a given load vector $b$ and mesh size $N$. A main function iterates through the test cases, discretizes the functions, computes the simplified residual vector, and calls the norm calculation function. `scipy.linalg.solve` is used for the linear system, as it is robust and efficient for these matrix sizes.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef compute_h_minus_1_norm(N, b):\n    \"\"\"\n    Solves Kw=b and computes the discrete H^-1 norm sqrt(w^T b).\n\n    Args:\n        N (int): The number of cells in the mesh.\n        b (np.ndarray): The load vector of size N-1.\n\n    Returns:\n        float: The computed discrete H^-1 norm.\n    \"\"\"\n    # If the load vector is zero, the norm is zero.\n    if not np.any(b):\n        return 0.0\n\n    h = 1.0 / N\n    dim = N - 1\n\n    # Construct the stiffness matrix K\n    main_diag = np.full(dim, 2.0 / h)\n    off_diag = np.full(dim - 1, -1.0 / h)\n    K = np.diag(main_diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n\n    # Solve Kw = b for w\n    # Problem statement uses `u` as the solution vector, but that's confusing.\n    # We will use `w_sol` to avoid confusion with the input function `u`.\n    w_sol = linalg.solve(K, b)\n\n    # Compute the norm squared: w_sol^T * b\n    # Using np.dot for the inner product of 1D arrays\n    # Problem statement asks for sqrt(u^T b) where Ku=b.\n    norm_sq = np.dot(w_sol, b)\n\n    # Return the norm, ensuring the argument to sqrt is non-negative\n    return np.sqrt(max(0.0, norm_sq))\n\ndef solve_case(N, u_func, v_func):\n    \"\"\"\n    Computes the H^-1 norms for a single test case.\n\n    Args:\n        N (int): The number of cells.\n        u_func (callable): A function defining u(x).\n        v_func (callable): A function defining v(x).\n\n    Returns:\n        list[float]: A list of three norms [left, right, avg].\n    \"\"\"\n    h = 1.0 / N\n    # Cell centers\n    x_c = (np.arange(N) + 0.5) * h\n\n    # Discretize functions on cell centers\n    u = u_func(x_c)\n    v = v_func(x_c)\n\n    # Compute jumps across interfaces j=1,...,N-1\n    # du[j-1] corresponds to jump at interface j\n    du = u[1:] - u[:-1]\n    dv = v[1:] - v[:-1]\n\n    # Based on the analytical simplification:\n    # r_left = du * dv\n    # r_right = -du * dv\n    # r_avg = 0\n    # The load vector b has components b[j-1] = r_j\n    b_left = du * dv\n    \n    # Compute the norm for the left-trace scheme\n    norm_left = compute_h_minus_1_norm(N, b_left)\n    \n    # The right-trace norm is identical to the left-trace norm\n    norm_right = norm_left\n    \n    # The arithmetic-average norm is zero\n    norm_avg = 0.0\n    \n    return [norm_left, norm_right, norm_avg]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Define test cases as tuples: (N, u_function, v_function)\n    test_cases = [\n        (\n            64,\n            lambda x: np.piecewise(x, \n                [x  0.35, (x = 0.35)  (x  0.70)], \n                [1.0, -0.5, 2.0]),\n            lambda x: np.piecewise(x, \n                [x  0.25, (x = 0.25)  (x  0.80)], \n                [0.0, 1.5, -1.0])\n        ),\n        (\n            100,\n            lambda x: np.piecewise(x, \n                [x  0.50, (x = 0.50)  (x  0.75)], \n                [2.0, -1.0, 0.5]),\n            lambda x: np.piecewise(x, \n                [x  0.25, (x = 0.25)  (x  0.50)], \n                [1.0, 0.0, 3.0])\n        ),\n        (\n            32,\n            lambda x: np.full_like(x, 1.0),\n            lambda x: np.piecewise(x, \n                [x  0.60], \n                [-1.0, 2.0])\n        )\n    ]\n\n    all_results = []\n    for N, u_func, v_func in test_cases:\n        case_results = solve_case(N, u_func, v_func)\n        all_results.extend(case_results)\n\n    # Format and print the final output as a single line\n    # Using a high precision format to be safe.\n    print(f\"[{','.join(f'{r:.12f}' for r in all_results)}]\")\n\n# Execute the solver\nsolve()\n```"
        }
    ]
}