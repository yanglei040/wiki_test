{
    "hands_on_practices": [
        {
            "introduction": "The scalability of FETI and BDD methods relies on a robust coarse problem that handles the kernel of the local operators. This practice  delves into the algebraic heart of this mechanism: the projection operator that enforces orthogonality against the coarse space. By deriving the projector and analyzing its numerical properties, you will gain a fundamental understanding of how these methods ensure a well-conditioned and solvable global system.",
            "id": "3565928",
            "problem": "Consider a nonoverlapping finite element domain decomposition of a linear elastic body, where interface compatibility is enforced in the dual space by Lagrange multipliers. In the dual formulation of Finite Element Tearing and Interconnecting (FETI) and Balancing Domain Decomposition (BDD), the interface operator is the dual Schur complement $F \\in \\mathbb{R}^{n \\times n}$, which is symmetric positive semidefinite, and positive definite on the subspace orthogonal (in the sense of the $F$-inner product) to the coarse space. Let $Z \\in \\mathbb{R}^{n \\times m}$ be a full column rank basis for the coarse space of interface modes (e.g., rigid body modes), such that $Z^{T} F Z \\in \\mathbb{R}^{m \\times m}$ is invertible. The goal is to construct a linear projector $P \\in \\mathbb{R}^{n \\times n}$ acting on the dual variables that eliminates coarse components and enforces orthogonality to the coarse modes in the $F$-inner product.\n\nStarting from the first principles of energy orthogonality and the defining properties of oblique projections in an inner-product space determined by $F$, derive an explicit algebraic expression for the projector $P$ onto the $F$-orthogonal complement of $\\mathrm{Range}(Z)$. Prove that this $P$ enforces coarse mode orthogonality in the sense that for every dual vector $\\lambda \\in \\mathbb{R}^{n}$, the coarse component is annihilated and the projected vector is $F$-orthogonal to the coarse space. Then, assess numerical stability under roundoff by analyzing the sensitivity of the $F$-orthogonality condition to finite-precision computation of the inverse of $Z^{T} F Z$.\n\nFor a concrete test, use\n$$\nF \\;=\\; \\begin{pmatrix}\n4 & 1 & 0 \\\\\n1 & 3 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix},\n\\qquad\nZ \\;=\\; \\begin{pmatrix}\n1 \\\\ -1 \\\\ 2\n\\end{pmatrix}.\n$$\nCompute the exact projector $P$ and verify its annihilation and orthogonality properties with respect to the coarse space defined by $Z$. Next, define an approximate projector $P_{r}$ by replacing $(Z^{T} F Z)^{-1}$ with its rounded value $a_{r}$ obtained from the exact scalar $(Z^{T} F Z)^{-1}$ rounded to three significant figures in standard scientific notation, and set\n$$\nP_{r} \\;=\\; I \\;-\\; Z \\, a_{r} \\, Z^{T} F.\n$$\nQuantify the violation of coarse orthogonality introduced by this rounding by evaluating the scalar\n$$\n\\epsilon \\;=\\; \\left\\| Z^{T} F P_{r} \\right\\|_{2}.\n$$\nReport the value of $\\epsilon$ as your final answer. Round your final numerical answer to four significant figures. No physical units are required.",
            "solution": "The problem asks for the derivation of a projector $P$ that enforces orthogonality to a coarse space in a specific inner product, followed by an analysis of its numerical stability and a concrete numerical calculation.\n\nThe problem is first validated.\n**Step 1: Extract Givens**\n- Interface operator: $F \\in \\mathbb{R}^{n \\times n}$, symmetric positive semidefinite, and positive definite on the subspace $F$-orthogonal to the coarse space.\n- Coarse space basis: $Z \\in \\mathbb{R}^{n \\times m}$ with full column rank.\n- Coarse problem matrix: $Z^{T} F Z$ is invertible.\n- Projector: $P \\in \\mathbb{R}^{n \\times n}$ projects onto the $F$-orthogonal complement of $\\mathrm{Range}(Z)$.\n- Concrete test case:\n  $$\n  F \\;=\\; \\begin{pmatrix}\n  4 & 1 & 0 \\\\\n  1 & 3 & 1 \\\\\n  0 & 1 & 2\n  \\end{pmatrix},\n  \\qquad\n  Z \\;=\\; \\begin{pmatrix}\n  1 \\\\ -1 \\\\ 2\n  \\end{pmatrix}.\n  $$\n- Approximate projector: $P_{r} = I - Z a_{r} Z^{T} F$, where $a_{r}$ is $(Z^{T} F Z)^{-1}$ rounded to three significant figures.\n- Error metric: $\\epsilon = \\| Z^{T} F P_{r} \\|_{2}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, situated within the well-established field of numerical methods for partial differential equations (domain decomposition). It is well-posed, with all necessary information provided for both the theoretical derivation and the numerical computation. The given matrix $F$ is symmetric. Its eigenvalues can be shown to be positive, so it is positive definite, which is consistent with the given properties. The matrix $Z$ has full column rank. The product $Z^T F Z$ for the given data is the scalar $9$, which is invertible. The problem is objective, complete, consistent, and mathematically verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n**Part 1: Derivation of the Projector $P$**\nLet $\\mathbb{R}^n$ be the space of dual variables. The problem defines an inner product (or semi-inner product, since $F$ is positive semidefinite) on this space as $\\langle u, v \\rangle_F = u^T F v$ for any $u, v \\in \\mathbb{R}^n$. The coarse space is the subspace $\\mathcal{Z} = \\mathrm{Range}(Z) = \\{ Z\\alpha \\mid \\alpha \\in \\mathbb{R}^m \\}$.\n\nWe seek a projector $P$ onto the $F$-orthogonal complement of $\\mathcal{Z}$, which we denote $\\mathcal{Z}^{\\perp_F}$. Any vector $\\lambda \\in \\mathbb{R}^n$ can be decomposed into a component in $\\mathcal{Z}$ and a component in $\\mathcal{Z}^{\\perp_F}$:\n$$ \\lambda = \\lambda_{\\mathcal{Z}} + \\lambda_{\\perp_F} $$\nwhere $\\lambda_{\\mathcal{Z}} \\in \\mathcal{Z}$ and $\\lambda_{\\perp_F} \\in \\mathcal{Z}^{\\perp_F}$. The projector $P$ acts on $\\lambda$ to yield the component in the $F$-orthogonal complement: $P\\lambda = \\lambda_{\\perp_F}$.\n\nSince $\\lambda_{\\mathcal{Z}} \\in \\mathcal{Z}$, it can be written as $\\lambda_{\\mathcal{Z}} = Z\\alpha$ for some coefficient vector $\\alpha \\in \\mathbb{R}^m$. The projected vector is then $\\lambda_{\\perp_F} = \\lambda - \\lambda_{\\mathcal{Z}} = \\lambda - Z\\alpha$.\n\nThe defining property of $\\lambda_{\\perp_F}$ is its $F$-orthogonality to every vector in the coarse space $\\mathcal{Z}$. This is satisfied if $\\lambda_{\\perp_F}$ is $F$-orthogonal to all basis vectors of $\\mathcal{Z}$, i.e., the columns of $Z$. This condition is expressed as:\n$$ \\langle Z\\beta, \\lambda - Z\\alpha \\rangle_F = 0, \\quad \\forall \\beta \\in \\mathbb{R}^m $$\nWriting this out using the definition of the inner product:\n$$ (Z\\beta)^T F (\\lambda - Z\\alpha) = 0 $$\n$$ \\beta^T Z^T F (\\lambda - Z\\alpha) = 0 $$\nSince this must hold for all $\\beta \\in \\mathbb{R}^m$, the vector term must be zero:\n$$ Z^T F (\\lambda - Z\\alpha) = 0 $$\n$$ Z^T F \\lambda - Z^T F Z \\alpha = 0 $$\n$$ Z^T F Z \\alpha = Z^T F \\lambda $$\nThe problem states that the matrix $Z^T F Z$ is invertible. We can therefore solve for $\\alpha$:\n$$ \\alpha = (Z^T F Z)^{-1} Z^T F \\lambda $$\nSubstituting this expression for $\\alpha$ back into the formula for $\\lambda_{\\mathcal{Z}}$ gives the projection of $\\lambda$ onto the coarse space:\n$$ \\lambda_{\\mathcal{Z}} = Z\\alpha = Z (Z^T F Z)^{-1} Z^T F \\lambda $$\nThe projector onto the coarse space, let's call it $P_{\\mathcal{Z}}$, is thus $P_{\\mathcal{Z}} = Z (Z^T F Z)^{-1} Z^T F$. This is an oblique projector.\n\nThe desired projector $P$ projects onto the complement, so it is given by $P = I - P_{\\mathcal{Z}}$.\n$$ P = I - Z (Z^T F Z)^{-1} Z^T F $$\n\n**Part 2: Proof of Properties**\nWe must prove that for any $\\lambda \\in \\mathbb{R}^{n}$:\n1. The coarse component is annihilated. Any vector in the coarse space, $v = Z\\gamma$, is projected to zero.\n   $$\n   P v = P (Z\\gamma) = \\left(I - Z (Z^T F Z)^{-1} Z^T F\\right) (Z\\gamma) = Z\\gamma - Z (Z^T F Z)^{-1} (Z^T F Z) \\gamma = Z\\gamma - Z I_m \\gamma = Z\\gamma - Z\\gamma = 0\n   $$\n   The property is proven.\n\n2. The projected vector $P\\lambda$ is $F$-orthogonal to the coarse space $\\mathcal{Z}$. We check if $\\langle Z\\gamma, P\\lambda \\rangle_F = 0$ for any $\\gamma \\in \\mathbb{R}^m$. This is equivalent to checking if $Z^T F (P\\lambda) = 0$.\n   $$\n   Z^T F (P\\lambda) = Z^T F \\left(I - Z (Z^T F Z)^{-1} Z^T F\\right) \\lambda = \\left(Z^T F - (Z^T F Z) (Z^T F Z)^{-1} Z^T F\\right) \\lambda = (Z^T F - I_m Z^T F) \\lambda = (Z^T F - Z^T F) \\lambda = 0\n   $$\n   The property is proven.\n\n**Part 3: Assessment of Numerical Stability**\nThe $F$-orthogonality of the projected result depends on the exact cancellation $Z^T F - (Z^T F Z) (Z^T F Z)^{-1} Z^T F = 0$. In finite-precision arithmetic, we compute an approximate inverse, say $\\tilde{G} \\approx G = (Z^T F Z)^{-1}$. The approximate projector is $\\tilde{P} = I - Z \\tilde{G} Z^T F$. The residual of the orthogonality condition is:\n$$ Z^T F \\tilde{P} = Z^T F - (Z^T F Z) \\tilde{G} Z^T F = (Z^T F Z)G Z^T F - (Z^T F Z) \\tilde{G} Z^T F = (Z^T F Z) (G - \\tilde{G}) Z^T F = - (Z^T F Z) (\\delta G) Z^T F $$\nwhere $\\delta G = \\tilde{G} - G$ is the error in the inverse. This shows that the loss of orthogonality is proportional to the error in the inverse of the coarse matrix $Z^T F Z$, pre-multiplied by $Z^T F Z$ itself. The magnitude of this violation will be sensitive to the condition number of the coarse matrix, $\\kappa(Z^T F Z)$. A large condition number can amplify small rounding errors in the inverse computation, leading to a significant loss of $F$-orthogonality.\n\n**Part 4: Concrete Numerical Calculation**\nWe are given the matrices:\n$$\nF \\;=\\; \\begin{pmatrix}\n4 & 1 & 0 \\\\\n1 & 3 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix},\n\\qquad\nZ \\;=\\; \\begin{pmatrix}\n1 \\\\ -1 \\\\ 2\n\\end{pmatrix}.\n$$\nFirst, we compute the components for the projector.\n$$\nF Z = \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 4(1) + 1(-1) + 0(2) \\\\ 1(1) + 3(-1) + 1(2) \\\\ 0(1) + 1(-1) + 2(2) \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 0 \\\\ 3 \\end{pmatrix}\n$$\n$$\nZ^T F = (FZ)^T = \\begin{pmatrix} 3 & 0 & 3 \\end{pmatrix}\n$$\nNext, we compute the scalar coarse problem matrix $Z^T F Z$:\n$$\nZ^T F Z = \\begin{pmatrix} 3 & 0 & 3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix} = 3(1) + 0(-1) + 3(2) = 9\n$$\nThe exact inverse is $(Z^T F Z)^{-1} = \\frac{1}{9}$.\nThe exact projector is $P = I - \\frac{1}{9} Z Z^T F$.\n\nThe problem requires using a rounded value for the inverse. The exact value is $a = \\frac{1}{9} = 0.1111... = 1.111... \\times 10^{-1}$.\nRounding this to three significant figures gives the approximate value $a_r$:\n$$\na_r = 1.11 \\times 10^{-1} = 0.111\n$$\nThe approximate projector is $P_r = I - Z a_r Z^T F$.\n\nWe need to quantify the violation of orthogonality by evaluating $\\epsilon = \\| Z^T F P_r \\|_{2}$.\nLet's first compute the row vector $Z^T F P_r$:\n$$\nZ^T F P_r = Z^T F (I - Z a_r Z^T F) = Z^T F - (Z^T F Z) a_r Z^T F\n$$\nSubstituting the known values:\n$$\nZ^T F P_r = Z^T F - (9) a_r Z^T F = (1 - 9 a_r) Z^T F\n$$\nThe scalar pre-factor is:\n$$\n1 - 9 a_r = 1 - 9(0.111) = 1 - 0.999 = 0.001\n$$\nSo, the row vector is:\n$$\nZ^T F P_r = 0.001 \\times \\begin{pmatrix} 3 & 0 & 3 \\end{pmatrix} = \\begin{pmatrix} 0.003 & 0 & 0.003 \\end{pmatrix}\n$$\nFinally, we compute its Euclidean ($L_2$) norm:\n$$\n\\epsilon = \\| \\begin{pmatrix} 0.003 & 0 & 0.003 \\end{pmatrix} \\|_2 = \\sqrt{0.003^2 + 0^2 + 0.003^2}\n$$\n$$\n\\epsilon = \\sqrt{2 \\times (0.003)^2} = \\sqrt{2} \\times 0.003\n$$\nUsing the value $\\sqrt{2} \\approx 1.41421356...$:\n$$\n\\epsilon \\approx 1.41421356 \\times 0.003 = 0.0042426408...\n$$\nRounding the final answer to four significant figures gives:\n$$\n\\epsilon \\approx 0.004243\n$$",
            "answer": "$$\\boxed{0.004243}$$"
        },
        {
            "introduction": "In large-scale parallel computing, solving subdomain problems exactly is often computationally prohibitive. This exercise  explores the practical consequences of using inexact iterative solvers for these local problems. You will derive a crucial theoretical bound that connects the local solver tolerance to the global preconditioned system's condition number, providing insight into the performance trade-offs inherent in flexible Krylov methods.",
            "id": "3565918",
            "problem": "Consider small-strain, linear elastic equilibrium on a bounded, simply connected polygonal domain $\\Omega \\subset \\mathbb{R}^{2}$ with homogeneous Dirichlet boundary conditions on $\\partial \\Omega$, body force density $\\boldsymbol{f}$, Cauchy stress $\\boldsymbol{\\sigma} = \\mathbb{C} : \\boldsymbol{\\varepsilon}(\\boldsymbol{u})$, and kinematic strain $\\boldsymbol{\\varepsilon}(\\boldsymbol{u}) = \\tfrac{1}{2}(\\nabla \\boldsymbol{u} + \\nabla \\boldsymbol{u}^{\\top})$, where $\\mathbb{C}$ is the fourth-order elasticity tensor for an isotropic material with Lamé parameters $(\\lambda,\\mu)$ satisfying $\\mu > 0$ and $\\lambda + \\mu > 0$. The weak form seeks $\\boldsymbol{u} \\in [H_{0}^{1}(\\Omega)]^{2}$ such that\n$$\n\\int_{\\Omega} \\boldsymbol{\\varepsilon}(\\boldsymbol{u}) : \\mathbb{C} : \\boldsymbol{\\varepsilon}(\\boldsymbol{v}) \\,\\mathrm{d}\\Omega = \\int_{\\Omega} \\boldsymbol{f} \\cdot \\boldsymbol{v} \\,\\mathrm{d}\\Omega \\quad \\text{for all } \\boldsymbol{v} \\in [H_{0}^{1}(\\Omega)]^{2}.\n$$\nA conforming finite element discretization on a quasi-uniform mesh of size $h$ yields a symmetric positive definite (SPD) stiffness matrix $\\boldsymbol{K} \\in \\mathbb{R}^{n \\times n}$ such that the discrete equilibrium is $\\boldsymbol{K}\\boldsymbol{u}=\\boldsymbol{f}$.\n\nPartition $\\Omega$ into $N$ non-overlapping subdomains $\\{\\Omega_{i}\\}_{i=1}^{N}$ of characteristic diameter $H$, and consider a dual-primal Finite Element Tearing and Interconnecting (FETI-DP) interface formulation, which enforces continuity by Lagrange multipliers on dual interface degrees of freedom and primal constraints on a coarse space. The resulting SPD interface problem in the dual space reads\n$$\n\\boldsymbol{S}\\boldsymbol{\\lambda} = \\boldsymbol{g},\n$$\nwhere $\\boldsymbol{S}$ is the assembled Schur complement operator induced by local Dirichlet problems on subdomains, and $\\boldsymbol{g}$ is the dual right-hand side vector. A Balancing Domain Decomposition (BDD) style preconditioner $\\boldsymbol{M}$ is built from local inverses $\\boldsymbol{K}_{i}^{-1}$, scaling, and an exact coarse correction, yielding a preconditioned operator\n$$\n\\boldsymbol{P} := \\boldsymbol{M}^{1/2}\\boldsymbol{S}\\boldsymbol{M}^{1/2}.\n$$\nFor such methods, a well-tested bound for the exact preconditioner gives the spectral condition number\n$$\n\\kappa_{0} := \\frac{\\lambda_{\\max}(\\boldsymbol{P})}{\\lambda_{\\min}(\\boldsymbol{P})} \\leq C\\left(1 + \\ln\\!\\left(\\frac{H}{h}\\right)\\right)^{2},\n$$\nwith a constant $C$ that is independent of $h$ and $H$ for shape-regular subdomains and an appropriate coarse space.\n\nIn practice, each local subdomain inverse $\\boldsymbol{K}_{i}^{-1}$ is applied inexactly by an iterative solver terminated at a uniform local energy-norm relative tolerance $\\tau \\in (0,1)$, producing an operator $\\widehat{\\boldsymbol{K}}_{i}^{-1}$ such that, for all subdomain interface vectors $\\boldsymbol{z}$ in the range of the subdomain trace operator,\n$$\n\\left| \\left( \\left(\\boldsymbol{K}_{i}^{-1} - \\widehat{\\boldsymbol{K}}_{i}^{-1}\\right)\\boldsymbol{z}, \\boldsymbol{z} \\right)_{\\boldsymbol{K}_{i}} \\right| \\leq \\tau \\left( \\boldsymbol{K}_{i}^{-1}\\boldsymbol{z}, \\boldsymbol{z} \\right)_{\\boldsymbol{K}_{i}},\n$$\nwhere $(\\boldsymbol{x},\\boldsymbol{y})_{\\boldsymbol{K}_{i}} := \\boldsymbol{x}^{\\top}\\boldsymbol{K}_{i}\\boldsymbol{y}$. The global inexact preconditioner $\\widehat{\\boldsymbol{M}}$ assembled from $\\{\\widehat{\\boldsymbol{K}}_{i}^{-1}\\}$ and the same coarse correction is SPD but varies per iteration as the inner solves change, necessitating Flexible Krylov methods, such as Flexible Conjugate Gradient (FCG), to preserve convergence with variable preconditioning.\n\nAssuming the exact coarse correction and scaling are unchanged, the above local tolerance model yields uniform spectral equivalence between $\\widehat{\\boldsymbol{M}}$ and $\\boldsymbol{M}$, and hence between the exact and inexact preconditioned operators. Derive, from first principles starting from the weak form, the subdomain Schur complements, and the energy-norm tolerance model above, a sharp upper bound for the effective condition number $\\kappa_{\\mathrm{eff}} := \\lambda_{\\max}(\\widehat{\\boldsymbol{M}}^{1/2}\\boldsymbol{S}\\widehat{\\boldsymbol{M}}^{1/2}) / \\lambda_{\\min}(\\widehat{\\boldsymbol{M}}^{1/2}\\boldsymbol{S}\\widehat{\\boldsymbol{M}}^{1/2})$ in terms of $\\kappa_{0}$ and $\\tau$.\n\nThen, consider a $2$-dimensional square $\\Omega$ split into $N = 16$ equal square subdomains with $H/h = 8$, and take $C = 2$. Let the target effective condition number be $\\kappa^{*} = 30$. Using your derived bound, compute the largest admissible tolerance $\\tau_{\\max}$ such that $\\kappa_{\\mathrm{eff}} \\leq \\kappa^{*}$. Round your answer to four significant figures. Express $\\tau_{\\max}$ as a dimensionless quantity.",
            "solution": "The user has provided a scientifically valid and well-posed problem in computational solid mechanics, specifically concerning the analysis of inexact domain decomposition methods. I will now proceed with the solution.\n\nThe problem is divided into two parts: first, to derive a sharp upper bound for the effective condition number $\\kappa_{\\mathrm{eff}}$ of an inexactly preconditioned system in terms of the exact condition number $\\kappa_{0}$ and a local solver tolerance $\\tau$; second, to apply this bound to compute a specific maximum tolerance $\\tau_{\\max}$.\n\n### Part 1: Derivation of the Bound for the Effective Condition Number\n\nThe goal is to find an upper bound for $\\kappa_{\\mathrm{eff}} := \\lambda_{\\max}(\\widehat{\\boldsymbol{P}})/\\lambda_{\\min}(\\widehat{\\boldsymbol{P}})$, where $\\widehat{\\boldsymbol{P}} = \\widehat{\\boldsymbol{M}}^{1/2}\\boldsymbol{S}\\widehat{\\boldsymbol{M}}^{1/2}$ is the inexactly preconditioned operator. The derivation proceeds by first establishing a spectral relationship between the exact preconditioner $\\boldsymbol{M}$ and the inexact preconditioner $\\widehat{\\boldsymbol{M}}$, and then using this relationship to bound the eigenvalues of $\\widehat{\\boldsymbol{P}}$.\n\n1.  **Analyze the Local Tolerance Condition**\n\nThe inexactness of the subdomain solves is governed by the energy-norm relative tolerance $\\tau$. For each subdomain $\\Omega_i$, the approximate inverse $\\widehat{\\boldsymbol{K}}_{i}^{-1}$ satisfies:\n$$\n\\left| \\left( \\left(\\boldsymbol{K}_{i}^{-1} - \\widehat{\\boldsymbol{K}}_{i}^{-1}\\right)\\boldsymbol{z}, \\boldsymbol{z} \\right)_{\\boldsymbol{K}_{i}} \\right| \\leq \\tau \\left( \\boldsymbol{K}_{i}^{-1}\\boldsymbol{z}, \\boldsymbol{z} \\right)_{\\boldsymbol{K}_{i}}\n$$\nwhere $(\\boldsymbol{x},\\boldsymbol{y})_{\\boldsymbol{K}_{i}} := \\boldsymbol{x}^{\\top}\\boldsymbol{K}_{i}\\boldsymbol{y}$. Let's expand both sides, assuming the matrices $\\boldsymbol{K}_{i}$ and $\\widehat{\\boldsymbol{K}}_{i}^{-1}$ are symmetric, which is standard for these methods.\nThe right-hand side (RHS) is:\n$$\n\\tau \\left( \\boldsymbol{K}_{i}^{-1}\\boldsymbol{z}, \\boldsymbol{z} \\right)_{\\boldsymbol{K}_{i}} = \\tau (\\boldsymbol{K}_{i}^{-1}\\boldsymbol{z})^{\\top} \\boldsymbol{K}_{i} \\boldsymbol{z} = \\tau \\boldsymbol{z}^{\\top} \\boldsymbol{K}_{i}^{-1} \\boldsymbol{K}_{i} \\boldsymbol{z} = \\tau \\boldsymbol{z}^{\\top}\\boldsymbol{z}\n$$\nThe term inside the absolute value on the left-hand side (LHS) is:\n$$\n\\left( (\\boldsymbol{K}_{i}^{-1} - \\widehat{\\boldsymbol{K}}_{i}^{-1})\\boldsymbol{z}, \\boldsymbol{z} \\right)_{\\boldsymbol{K}_{i}} = ((\\boldsymbol{K}_{i}^{-1} - \\widehat{\\boldsymbol{K}}_{i}^{-1})\\boldsymbol{z})^{\\top} \\boldsymbol{K}_{i} \\boldsymbol{z} = \\boldsymbol{z}^{\\top}(\\boldsymbol{K}_{i}^{-1} - \\widehat{\\boldsymbol{K}}_{i}^{-1})\\boldsymbol{K}_{i}\\boldsymbol{z} = \\boldsymbol{z}^{\\top}(\\boldsymbol{I} - \\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i})\\boldsymbol{z}\n$$\nThe tolerance condition thus becomes:\n$$\n|\\boldsymbol{z}^{\\top}(\\boldsymbol{I} - \\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i})\\boldsymbol{z}| \\leq \\tau \\boldsymbol{z}^{\\top}\\boldsymbol{z}\n$$\nThis is equivalent to the two-sided inequality:\n$$\n-\\tau \\boldsymbol{z}^{\\top}\\boldsymbol{z} \\leq \\boldsymbol{z}^{\\top}\\boldsymbol{z} - \\boldsymbol{z}^{\\top}\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i}\\boldsymbol{z} \\leq \\tau \\boldsymbol{z}^{\\top}\\boldsymbol{z}\n$$\nRearranging gives bounds on the quadratic form of the operator $\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i}$:\n$$\n(1 - \\tau) \\boldsymbol{z}^{\\top}\\boldsymbol{z} \\leq \\boldsymbol{z}^{\\top}\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i}\\boldsymbol{z} \\leq (1 + \\tau) \\boldsymbol{z}^{\\top}\\boldsymbol{z}\n$$\nThis establishes that the eigenvalues of the operator $\\boldsymbol{K}_{i}^{1/2}\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i}^{1/2}$ (which is similar to $\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i}$ and symmetric) are contained in the interval $[1-\\tau, 1+\\tau]$. This implies the following spectral inequality for the symmetric operator $\\boldsymbol{K}_{i}^{1/2}\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i}^{1/2}$:\n$$\n(1-\\tau)\\boldsymbol{I} \\preceq \\boldsymbol{K}_{i}^{1/2}\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{K}_{i}^{1/2} \\preceq (1+\\tau)\\boldsymbol{I}\n$$\nBy a change of variables $\\boldsymbol{y} = \\boldsymbol{K}_{i}^{1/2}\\boldsymbol{x}$, this is equivalent to the spectral equivalence of the inverse operators themselves:\n$$\n(1-\\tau)\\boldsymbol{x}^{\\top}\\boldsymbol{K}_{i}^{-1}\\boldsymbol{x} \\leq \\boldsymbol{x}^{\\top}\\widehat{\\boldsymbol{K}}_{i}^{-1}\\boldsymbol{x} \\leq (1+\\tau)\\boldsymbol{x}^{\\top}\\boldsymbol{K}_{i}^{-1}\\boldsymbol{x}\n$$\nfor any vector $\\boldsymbol{x}$ in the appropriate space.\n\n2.  **Global Preconditioner Equivalence**\n\nThe global preconditioners $\\boldsymbol{M}$ and $\\widehat{\\boldsymbol{M}}$ are assembled from the local inverse operators $\\{\\boldsymbol{K}_i^{-1}\\}$ and $\\{\\widehat{\\boldsymbol{K}}_i^{-1}\\}$ respectively, plus an identical coarse correction term. The additive assembly process preserves the spectral bounds. Therefore, the local equivalence relationship extends to the global preconditioners:\n$$\n(1-\\tau)\\boldsymbol{v}^{\\top}\\boldsymbol{M}\\boldsymbol{v} \\leq \\boldsymbol{v}^{\\top}\\widehat{\\boldsymbol{M}}\\boldsymbol{v} \\leq (1+\\tau)\\boldsymbol{v}^{\\top}\\boldsymbol{M}\\boldsymbol{v}\n$$\nfor any vector $\\boldsymbol{v}$ in the dual space. This can be written compactly as $(1-\\tau)\\boldsymbol{M} \\preceq \\widehat{\\boldsymbol{M}} \\preceq (1+\\tau)\\boldsymbol{M}$.\n\n3.  **Bound Eigenvalues of the Inexact Preconditioned Operator**\n\nThe exact and inexact preconditioned operators are $\\boldsymbol{P} = \\boldsymbol{M}^{1/2}\\boldsymbol{S}\\boldsymbol{M}^{1/2}$ and $\\widehat{\\boldsymbol{P}} = \\widehat{\\boldsymbol{M}}^{1/2}\\boldsymbol{S}\\widehat{\\boldsymbol{M}}^{1/2}$. We relate them via a congruence transformation:\n$$\n\\widehat{\\boldsymbol{P}} = \\widehat{\\boldsymbol{M}}^{1/2} \\boldsymbol{M}^{-1/2} (\\boldsymbol{M}^{1/2}\\boldsymbol{S}\\boldsymbol{M}^{1/2}) \\boldsymbol{M}^{-1/2} \\widehat{\\boldsymbol{M}}^{1/2} = (\\widehat{\\boldsymbol{M}}^{1/2}\\boldsymbol{M}^{-1/2}) \\boldsymbol{P} (\\widehat{\\boldsymbol{M}}^{1/2}\\boldsymbol{M}^{-1/2})^{\\top}\n$$\nLet $\\lambda$ be an eigenvalue of $\\widehat{\\boldsymbol{P}}$. The corresponding Rayleigh quotient is:\n$$\n\\lambda = \\frac{\\boldsymbol{y}^{\\top}\\widehat{\\boldsymbol{P}}\\boldsymbol{y}}{\\boldsymbol{y}^{\\top}\\boldsymbol{y}} = \\frac{\\boldsymbol{y}^{\\top}(\\widehat{\\boldsymbol{M}}^{1/2}\\boldsymbol{M}^{-1/2}) \\boldsymbol{P} (\\boldsymbol{M}^{-1/2}\\widehat{\\boldsymbol{M}}^{1/2})\\boldsymbol{y}}{\\boldsymbol{y}^{\\top}\\boldsymbol{y}}\n$$\nLet $\\boldsymbol{x} = (\\boldsymbol{M}^{-1/2}\\widehat{\\boldsymbol{M}}^{1/2})\\boldsymbol{y}$. Then $\\boldsymbol{y} = (\\widehat{\\boldsymbol{M}}^{-1/2}\\boldsymbol{M}^{1/2})\\boldsymbol{x}$.\n$$\n\\lambda = \\frac{\\boldsymbol{x}^{\\top}\\boldsymbol{P}\\boldsymbol{x}}{\\boldsymbol{x}^{\\top}(\\widehat{\\boldsymbol{M}}^{-1/2}\\boldsymbol{M}^{1/2})(\\boldsymbol{M}^{1/2}\\widehat{\\boldsymbol{M}}^{-1/2})\\boldsymbol{x}} = \\frac{\\boldsymbol{x}^{\\top}\\boldsymbol{P}\\boldsymbol{x}}{\\boldsymbol{x}^{\\top}\\widehat{\\boldsymbol{M}}^{-1/2}\\boldsymbol{M}\\widehat{\\boldsymbol{M}}^{-1/2}\\boldsymbol{x}}\n$$\nFrom the preconditioner equivalence $(1-\\tau)\\boldsymbol{M} \\preceq \\widehat{\\boldsymbol{M}} \\preceq (1+\\tau)\\boldsymbol{M}$, we can bound the operator in the denominator. Inverting this relation yields:\n$$\n\\frac{1}{1+\\tau}\\boldsymbol{M}^{-1} \\preceq \\widehat{\\boldsymbol{M}}^{-1} \\preceq \\frac{1}{1-\\tau}\\boldsymbol{M}^{-1}\n$$\nApplying this to the denominator's operator $\\widehat{\\boldsymbol{M}}^{-1/2}\\boldsymbol{M}\\widehat{\\boldsymbol{M}}^{-1/2}$ (which is similar to $\\boldsymbol{M}\\widehat{\\boldsymbol{M}}^{-1}$), its eigenvalues are bounded by $[1/(1+\\tau), 1/(1-\\tau)]$. Therefore:\n$$\n\\frac{1}{1+\\tau}\\boldsymbol{x}^{\\top}\\boldsymbol{x} \\leq \\boldsymbol{x}^{\\top}\\widehat{\\boldsymbol{M}}^{-1/2}\\boldsymbol{M}\\widehat{\\boldsymbol{M}}^{-1/2}\\boldsymbol{x} \\leq \\frac{1}{1-\\tau}\\boldsymbol{x}^{\\top}\\boldsymbol{x}\n$$\nNow we can bound the eigenvalue $\\lambda$:\n$$\n\\lambda_{\\max}(\\widehat{\\boldsymbol{P}}) = \\max_{\\boldsymbol{x}} \\frac{\\boldsymbol{x}^{\\top}\\boldsymbol{P}\\boldsymbol{x}}{\\boldsymbol{x}^{\\top}(\\widehat{\\boldsymbol{M}}^{-1}\\boldsymbol{M})\\boldsymbol{x}} \\leq \\frac{\\max (\\boldsymbol{x}^{\\top}\\boldsymbol{P}\\boldsymbol{x})}{\\min (\\boldsymbol{x}^{\\top}(\\widehat{\\boldsymbol{M}}^{-1}\\boldsymbol{M})\\boldsymbol{x})} = \\frac{\\lambda_{\\max}(\\boldsymbol{P})\\boldsymbol{x}^{\\top}\\boldsymbol{x}}{\\frac{1}{1+\\tau}\\boldsymbol{x}^{\\top}\\boldsymbol{x}} = (1+\\tau)\\lambda_{\\max}(\\boldsymbol{P})\n$$\n$$\n\\lambda_{\\min}(\\widehat{\\boldsymbol{P}}) = \\min_{\\boldsymbol{x}} \\frac{\\boldsymbol{x}^{\\top}\\boldsymbol{P}\\boldsymbol{x}}{\\boldsymbol{x}^{\\top}(\\widehat{\\boldsymbol{M}}^{-1}\\boldsymbol{M})\\boldsymbol{x}} \\geq \\frac{\\min (\\boldsymbol{x}^{\\top}\\boldsymbol{P}\\boldsymbol{x})}{\\max (\\boldsymbol{x}^{\\top}(\\widehat{\\boldsymbol{M}}^{-1}\\boldsymbol{M})\\boldsymbol{x})} = \\frac{\\lambda_{\\min}(\\boldsymbol{P})\\boldsymbol{x}^{\\top}\\boldsymbol{x}}{\\frac{1}{1-\\tau}\\boldsymbol{x}^{\\top}\\boldsymbol{x}} = (1-\\tau)\\lambda_{\\min}(\\boldsymbol{P})\n$$\n\n4.  **Bound the Effective Condition Number**\n\nThe effective condition number $\\kappa_{\\mathrm{eff}}$ is the ratio of the maximum to minimum eigenvalues of $\\widehat{\\boldsymbol{P}}$. Using the bounds derived above:\n$$\n\\kappa_{\\mathrm{eff}} = \\frac{\\lambda_{\\max}(\\widehat{\\boldsymbol{P}})}{\\lambda_{\\min}(\\widehat{\\boldsymbol{P}})} \\leq \\frac{(1+\\tau)\\lambda_{\\max}(\\boldsymbol{P})}{(1-\\tau)\\lambda_{\\min}(\\boldsymbol{P})} = \\frac{1+\\tau}{1-\\tau} \\frac{\\lambda_{\\max}(\\boldsymbol{P})}{\\lambda_{\\min}(\\boldsymbol{P})}\n$$\nRecognizing that $\\kappa_{0} = \\lambda_{\\max}(\\boldsymbol{P}) / \\lambda_{\\min}(\\boldsymbol{P})$, we arrive at the final expression for the bound:\n$$\n\\kappa_{\\mathrm{eff}} \\leq \\frac{1+\\tau}{1-\\tau} \\kappa_{0}\n$$\n\n### Part 2: Calculation of the Maximum Tolerance\n\nWe are asked to find the largest admissible tolerance $\\tau_{\\max}$ such that $\\kappa_{\\mathrm{eff}} \\leq \\kappa^{*}$ for the given parameters. The derived bound must be used to guarantee this condition.\nThe problem provides a bound for the exact condition number $\\kappa_{0}$:\n$$\n\\kappa_{0} \\leq C\\left(1 + \\ln\\left(\\frac{H}{h}\\right)\\right)^{2}\n$$\nTo ensure that $\\kappa_{\\mathrm{eff}} \\leq \\kappa^{*}$ for any specific mesh realizing these parameters, we must use the worst-case scenario for $\\kappa_0$, which corresponds to its upper bound. Let's denote this bound by $\\kappa_{0, \\text{bound}}$.\nGiven $C=2$ and $H/h=8$:\n$$\n\\kappa_{0, \\text{bound}} = 2\\left(1 + \\ln(8)\\right)^{2} = 2\\left(1 + 3\\ln(2)\\right)^{2}\n$$\nThe requirement on $\\kappa_{\\mathrm{eff}}$ becomes:\n$$\n\\kappa_{\\mathrm{eff}} \\leq \\frac{1+\\tau}{1-\\tau} \\kappa_{0} \\leq \\frac{1+\\tau}{1-\\tau} \\kappa_{0, \\text{bound}} \\leq \\kappa^{*}\n$$\nWe must solve the rightmost inequality for $\\tau$:\n$$\n\\frac{1+\\tau}{1-\\tau} \\leq \\frac{\\kappa^{*}}{\\kappa_{0, \\text{bound}}}\n$$\nSince $\\tau \\in (0,1)$, $1-\\tau > 0$. We can multiply without changing the inequality direction.\n$$\n1+\\tau \\leq \\frac{\\kappa^{*}}{\\kappa_{0, \\text{bound}}}(1-\\tau) = \\frac{\\kappa^{*}}{\\kappa_{0, \\text{bound}}} - \\tau \\frac{\\kappa^{*}}{\\kappa_{0, \\text{bound}}}\n$$\n$$\n\\tau \\left(1 + \\frac{\\kappa^{*}}{\\kappa_{0, \\text{bound}}}\\right) \\leq \\frac{\\kappa^{*}}{\\kappa_{0, \\text{bound}}} - 1\n$$\n$$\n\\tau \\left(\\frac{\\kappa_{0, \\text{bound}} + \\kappa^{*}}{\\kappa_{0, \\text{bound}}}\\right) \\leq \\frac{\\kappa^{*} - \\kappa_{0, \\text{bound}}}{\\kappa_{0, \\text{bound}}}\n$$\n$$\n\\tau \\leq \\frac{\\kappa^{*} - \\kappa_{0, \\text{bound}}}{\\kappa^{*} + \\kappa_{0, \\text{bound}}}\n$$\nThe largest admissible tolerance $\\tau_{\\max}$ is therefore:\n$$\n\\tau_{\\max} = \\frac{\\kappa^{*} - \\kappa_{0, \\text{bound}}}{\\kappa^{*} + \\kappa_{0, \\text{bound}}}\n$$\nNow, we substitute the numerical values: $\\kappa^{*} = 30$ and $\\kappa_{0, \\text{bound}} = 2(1 + \\ln(8))^{2}$.\nFirst, calculate $\\kappa_{0, \\text{bound}}$:\n$$\n\\ln(8) \\approx 2.0794415\n$$\n$$\n\\kappa_{0, \\text{bound}} \\approx 2(1 + 2.0794415)^{2} = 2(3.0794415)^{2} \\approx 2(9.48296) \\approx 18.96592\n$$\nNow compute $\\tau_{\\max}$:\n$$\n\\tau_{\\max} \\approx \\frac{30 - 18.96592}{30 + 18.96592} = \\frac{11.03408}{48.96592} \\approx 0.225345\n$$\nRounding to four significant figures, we get $\\tau_{\\max} \\approx 0.2253$.",
            "answer": "$$\\boxed{0.2253}$$"
        },
        {
            "introduction": "Standard domain decomposition methods can struggle with problems involving large variations in material properties, which create challenging modes on subdomain interfaces. This computational practice  guides you through the design of an adaptive BDDC method that automatically identifies and constrains these problematic modes. By implementing a selection algorithm based on local eigenproblems, you will learn how to build a more robust and efficient solver for heterogeneous materials.",
            "id": "3565891",
            "problem": "You are to implement and analyze an adaptive Balanced Domain Decomposition by Constraints (BDDC) coarse space based on local generalized eigenproblems on edges and faces, with a prescribed threshold $ \\tau $, for a three-dimensional ($3$D) channel exhibiting layered stiffness. The goal is to predict the minimal number of added primal constraints needed so that the preconditioned operator’s condition number $ \\kappa $ is guaranteed to satisfy $ \\kappa \\le \\tau $. The final program must compute this number for a given set of test cases that specify the subdomain stiffness distribution and the baseline spectral content on each interface component.\n\nStart from the variational formulation of linear elasticity and the classical substructuring framework: the global finite element equilibrium reads $ \\mathbf{K} \\mathbf{u} = \\mathbf{f} $, where $ \\mathbf{K} $ is the symmetric positive definite stiffness matrix assembled from subdomains. After eliminating interior subdomain degrees of freedom, the interface Schur complement system is posed in terms of the interface trace $ \\mathbf{u}_{\\Gamma} $. In a BDDC preconditioner, one introduces a coarse (primal) space by enforcing continuity constraints across selected interface functionals. In adaptive BDDC, additional constraints are chosen by solving, on each interface component $ c $ (edge or face), a local generalized eigenproblem that compares “jump” and “continuous” energies, typically expressible in the Schur complement energy inner product. Specifically, for each component $ c $, one solves a generalized eigenproblem of the form\n$$\n\\mathbf{S}_c^{\\Delta} \\boldsymbol{\\psi} = \\lambda \\, \\mathbf{S}_c^{\\Pi} \\boldsymbol{\\psi},\n$$\nwhere $ \\mathbf{S}_c^{\\Delta} $ measures the energetic penalty of discontinuous modes and $ \\mathbf{S}_c^{\\Pi} $ measures the energetic contribution of the corresponding continuous counterpart. Modes with eigenvalues $ \\lambda $ larger than a threshold $ \\tau $ are targeted for addition as primal constraints, yielding a guarantee that the global preconditioned operator has a condition number bounded by a constant times $ \\tau $; in the simplified model specified below, this constant is treated as $ 1 $. Therefore, a selection rule “add constraints for all local modes with $ \\lambda > \\tau $” ensures $ \\kappa \\le \\tau $.\n\nTo make the computation concrete and self-contained while retaining scientific realism, adopt the following simplified but widely used spectral scaling model: for a three-dimensional layered channel where each subdomain $ i $ has a homogeneous Young’s modulus $ E_i $ (in Pascals), the local generalized eigenvalues on an interface component $ c $ between adjacent subdomains $ i $ and $ j $ can be approximated as\n$$\n\\lambda_{c,k} \\approx \\rho_c \\, \\mu_{c,k}, \\quad \\text{with} \\quad \\rho_c = \\frac{\\max(E_i,E_j)}{\\min(E_i,E_j)},\n$$\nwhere $ \\{ \\mu_{c,k} \\}_k $ are the baseline eigenvalues for a unit-contrast homogeneous medium on the same geometric interface (that is, $ E_i = E_j $), and $ \\rho_c $ is the stiffness contrast ratio associated with $ c $. This model captures the amplification of problematic interface modes by material contrast in layered configurations and is consistent with established adaptive BDDC/FETI theory in which the local Rayleigh quotients scale with coefficient jumps. You are to assume that each provided $ \\mu_{c,k} $ already excludes the always-present corner constraints; thus, “added constraints” refers solely to the adaptive constraints beyond the standard corner set.\n\nTask. For each test case below:\n- Compute, for every interface component $ c $ with adjacent subdomains $ (i,j) $, the contrast ratio $ \\rho_c $ using the provided subdomain Young’s moduli $ \\{ E_i \\} $.\n- Form the approximate local eigenvalues $ \\lambda_{c,k} = \\rho_c \\, \\mu_{c,k} $ using the given baseline spectra $ \\{ \\mu_{c,k} \\}_k $.\n- Determine the minimal number of added constraints as the total count of all $ \\lambda_{c,k} $ that strictly exceed the threshold $ \\tau $. Eigenvalues equal to $ \\tau $ do not require adding a constraint.\n- Return, for each test case, a single integer: the total number of added constraints across all interface components.\n\nPhysical units. Young’s modulus values $ E_i $ are given in Pascals. No quantity with physical units is requested in the output; only integer counts of constraints are to be returned.\n\nAngle units. No angles are involved.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets, for the test cases in the order presented below. For example, if there are three test cases and the computed counts are $ a $, $ b $, and $ c $, respectively, the output must be exactly $ [a,b,c] $.\n\nTest suite. Implement your program to solve the following five test cases:\n\n- Test Case $ 1 $ (homogeneous channel, no contrast):\n  - Subdomains and moduli (Pascals): $ E = [10^9, 10^9, 10^9] $.\n  - Interface components $ c $ (adjacent pairs) and baseline spectra:\n    - Pair $ (0,1) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.5, 0.2 \\} $.\n    - Pair $ (1,2) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.4, 0.1 \\} $.\n  - Threshold: $ \\tau = 0.6 $.\n\n- Test Case $ 2 $ (three-layer channel with high middle-layer stiffness):\n  - Subdomains and moduli (Pascals): $ E = [10^9, 10^{12}, 10^9] $.\n  - Interface components and baseline spectra as in Test Case $ 1 $.\n  - Threshold: $ \\tau = 300 $.\n\n- Test Case $ 3 $ (same as Test Case $ 2 $, edge threshold):\n  - Subdomains and moduli (Pascals): $ E = [10^9, 10^{12}, 10^9] $.\n  - Interface components and baseline spectra as in Test Case $ 1 $.\n  - Threshold: $ \\tau = 400 $.\n\n- Test Case $ 4 $ (two-by-one-by-two arrangement with top/bottom layers of contrasting stiffness):\n  - Subdomains and moduli (Pascals): $ E = [10^6, 10^6, 10^9, 10^9] $.\n  - Interface components and baseline spectra:\n    - Pair $ (0,2) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.3, 0.25, 0.1 \\} $.\n    - Pair $ (1,3) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.3, 0.25, 0.1 \\} $.\n    - Pair $ (0,1) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.6, 0.55, 0.4 \\} $.\n    - Pair $ (2,3) $: $ \\{ \\mu_{c,k} \\} = \\{ 0.6, 0.55, 0.4 \\} $.\n  - Threshold: $ \\tau = 0.5 $.\n\n- Test Case $ 5 $ (same as Test Case $ 4 $, very permissive threshold):\n  - Subdomains and moduli (Pascals): $ E = [10^6, 10^6, 10^9, 10^9] $.\n  - Interface components and baseline spectra as in Test Case $ 4 $.\n  - Threshold: $ \\tau = 10^4 $.\n\nYour program must hard-code the above test suite, apply the described model and selection rule, and print the final results as a single line in the specified format.",
            "solution": "We begin with linear elasticity in the small-strain regime with homogeneous, isotropic material properties per subdomain. The finite element semi-discrete system can be written as $ \\mathbf{K} \\mathbf{u} = \\mathbf{f} $, where $ \\mathbf{K} $ is symmetric positive definite. In a substructured formulation, each subdomain’s interior degrees of freedom are statically condensed, producing the Schur complement system on the global interface trace $ \\mathbf{u}_{\\Gamma} $,\n$$\n\\mathbf{S} \\, \\mathbf{u}_{\\Gamma} = \\mathbf{g},\n$$\nwith $ \\mathbf{S} $ symmetric positive definite in the energy inner product induced by $ \\mathbf{K} $. Balanced Domain Decomposition by Constraints (BDDC) constructs a preconditioner by enforcing primal continuity on a subset of interface functionals (e.g., corners, averages on edges/faces), and splitting the remainder into dual parts solved locally. The efficiency of the preconditioner is measured by the condition number $ \\kappa $ of the preconditioned operator. \n\nAdaptive BDDC enriches the primal space by identifying “bad” interface modes through local generalized eigenproblems that compare discontinuous and continuous energy measures. On each interface component $ c $ (edge or face), one defines operators $ \\mathbf{S}_c^{\\Delta} $ and $ \\mathbf{S}_c^{\\Pi} $ representing, respectively, the energy of the jump mode and the energy of its corresponding continuous mode, and solves\n$$\n\\mathbf{S}_c^{\\Delta} \\boldsymbol{\\psi} = \\lambda \\, \\mathbf{S}_c^{\\Pi} \\boldsymbol{\\psi}.\n$$\nThe local Rayleigh quotient associated with a mode $ \\boldsymbol{\\psi} $ is $ \\lambda = \\dfrac{\\langle \\boldsymbol{\\psi}, \\mathbf{S}_c^{\\Delta} \\boldsymbol{\\psi} \\rangle}{\\langle \\boldsymbol{\\psi}, \\mathbf{S}_c^{\\Pi} \\boldsymbol{\\psi} \\rangle} $. Established theory for adaptive BDDC and Finite Element Tearing and Interconnecting (FETI) methods shows that, when one augments the primal space with constraints associated to all eigenvectors whose eigenvalues exceed a threshold $ \\tau $, the condition number of the preconditioned global operator satisfies a bound of the form $ \\kappa \\le C \\, \\tau $, where $ C $ is a benign constant depending weakly on shape regularity and scaling choices. In our model and for the purposes of this prediction task, we set $ C = 1 $, so selecting all local modes with $ \\lambda > \\tau $ guarantees $ \\kappa \\le \\tau $.\n\nTo relate the local spectra to material heterogeneity in a layered three-dimensional channel, consider a pair of adjacent subdomains $ (i,j) $ with homogeneous Young’s moduli $ E_i $ and $ E_j $, respectively. For a homogeneous medium ($ E_i = E_j $), the interface generalized eigenvalues for a fixed geometric interface are denoted by $ \\{ \\mu_{c,k} \\}_k $. When a jump in stiffness is present, the local energy of jump modes is amplified in proportion to the contrast ratio. A widely used and well-tested approximation is\n$$\n\\lambda_{c,k} \\approx \\rho_c \\, \\mu_{c,k}, \\quad \\text{with} \\quad \\rho_c = \\frac{\\max(E_i,E_j)}{\\min(E_i,E_j)}.\n$$\nThis follows from the scaling behavior of the Schur complement entries with respect to piecewise constant coefficients and from the observation that the Rayleigh quotient scales linearly with the dominant coefficient in the jump energy while the denominator scales with a representative continuous energy, yielding a factor of the ratio of coefficients across the interface. This model preserves ordering of modes because multiplication by a positive scalar $ \\rho_c $ does not alter relative magnitudes among the $ \\mu_{c,k} $.\n\nAdaptive selection rule. With the above approximation, the minimal number of added constraints on interface $ c $ required to achieve $ \\lambda_{c,k} \\le \\tau $ for all remaining unconstrained modes equals the count of $ k $ for which $ \\lambda_{c,k} > \\tau $, i.e., the cardinality of $ \\{ k : \\rho_c \\, \\mu_{c,k} > \\tau \\} $. Summing over all interface components $ c $ gives the total number of added constraints. Modes with $ \\lambda_{c,k} = \\tau $ are not added because they already satisfy the inequality $ \\lambda \\le \\tau $. The minimality follows because the maximum remaining eigenvalue decreases monotonically as the largest $ \\lambda $ modes are removed, and, under the multiplicative scaling, removing precisely those with $ \\rho_c \\mu_{c,k} > \\tau $ is both necessary and sufficient to enforce that all remaining $ \\lambda \\le \\tau $.\n\nAlgorithm. For each test case:\n1. For each interface component $ c $ connecting subdomains $ (i,j) $, compute $\\rho_c = \\dfrac{\\max(E_i,E_j)}{\\min(E_i,E_j)}$.\n2. For each baseline eigenvalue $ \\mu_{c,k} $ on $ c $, compute $ \\lambda_{c,k} = \\rho_c \\, \\mu_{c,k} $.\n3. Count those with $ \\lambda_{c,k} > \\tau $. Sum over all $ c $ to obtain the total number of added constraints.\n4. Return this total as the test case’s result.\n\nNow we apply this to each provided test case.\n\n- Test Case $ 1 $:\n  - $ E = [10^9, 10^9, 10^9] $. For both pairs $ (0,1) $ and $ (1,2) $, $ \\rho_c = 1 $.\n  - Pair $ (0,1) $: $ \\lambda = \\{ 1 \\cdot 0.5, 1 \\cdot 0.2 \\} = \\{ 0.5, 0.2 \\} $. With $ \\tau = 0.6 $, none exceed $ \\tau $. Count $ 0 $.\n  - Pair $ (1,2) $: $ \\lambda = \\{ 0.4, 0.1 \\} $, none exceed $ \\tau $. Count $ 0 $.\n  - Total added constraints: $ 0 $.\n\n- Test Case $ 2 $:\n  - $ E = [10^9, 10^{12}, 10^9] $. For both pairs $ (0,1) $ and $ (1,2) $, $ \\rho_c = \\dfrac{10^{12}}{10^9} = 10^3 $.\n  - Pair $ (0,1) $: $ \\lambda = \\{ 10^3 \\cdot 0.5, 10^3 \\cdot 0.2 \\} = \\{ 500, 200 \\} $. With $ \\tau = 300 $, only $ 500 > 300 $. Count $ 1 $.\n  - Pair $ (1,2) $: $ \\lambda = \\{ 10^3 \\cdot 0.4, 10^3 \\cdot 0.1 \\} = \\{ 400, 100 \\} $. Only $ 400 > 300 $. Count $ 1 $.\n  - Total added constraints: $ 2 $.\n\n- Test Case $ 3 $:\n  - Same $ E $ and $ \\rho_c = 10^3 $ as Test Case $ 2 $.\n  - Pair $ (0,1) $: $ \\lambda = \\{ 500, 200 \\} $. With $ \\tau = 400 $, only $ 500 > 400 $. Count $ 1 $.\n  - Pair $ (1,2) $: $ \\lambda = \\{ 400, 100 \\} $. Here $ 400 = \\tau $ does not count, $ 100 < \\tau $. Count $ 0 $.\n  - Total added constraints: $ 1 $.\n\n- Test Case $ 4 $:\n  - $ E = [10^6, 10^6, 10^9, 10^9] $.\n  - Pair $ (0,2) $: $ \\rho = \\dfrac{10^9}{10^6} = 10^3 $. $ \\lambda = \\{ 300, 250, 100 \\} $. With $ \\tau = 0.5 $, all three exceed. Count $ 3 $.\n  - Pair $ (1,3) $: same as above. Count $ 3 $.\n  - Pair $ (0,1) $: $ \\rho = 1 $, $ \\lambda = \\{ 0.6, 0.55, 0.4 \\} $. Exceeding $ 0.5 $ are $ 0.6 $ and $ 0.55 $. Count $ 2 $.\n  - Pair $ (2,3) $: same as previous. Count $ 2 $.\n  - Total added constraints: $ 3 + 3 + 2 + 2 = 10 $.\n\n- Test Case $ 5 $:\n  - Same $ E $ and interfaces as Test Case $ 4 $.\n  - Threshold $ \\tau = 10^4 $. All $ \\lambda $ values from Test Case $ 4 $ are at most $ 300 $, so none exceed $ 10^4 $. Total added constraints: $ 0 $.\n\nTherefore, the expected outputs, in order, are the integer list $ [0, 2, 1, 10, 0] $. The program should compute these using the described algorithm and print them as a single line exactly in the format $ [0,2,1,10,0] $.\n\nThis principle-based design ties the computational procedure directly to the energy-based generalized eigenproblems governing adaptive BDDC, uses a contrast-driven scaling consistent with coefficient-jump sensitivity, and yields a quantifiable and verifiable integer output per test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef count_added_constraints(E, interfaces, tau):\n    \"\"\"\n    Count the minimal number of added adaptive BDDC constraints to ensure kappa <= tau,\n    under the spectral scaling model lambda = rho * mu for each interface component.\n    \n    Parameters:\n        E : list of floats\n            Young's modulus per subdomain (Pa).\n        interfaces : list of dicts\n            Each dict has:\n                'pair': (i, j) subdomain indices adjacent at the interface component.\n                'mu': list of baseline eigenvalues for the component in a homogeneous medium.\n        tau : float\n            Eigenvalue threshold.\n    Returns:\n        int : total number of added constraints across all interface components.\n    \"\"\"\n    total = 0\n    for comp in interfaces:\n        i, j = comp['pair']\n        Ei, Ej = E[i], E[j]\n        # Contrast ratio\n        rho = max(Ei, Ej) / min(Ei, Ej)\n        # Count modes that exceed tau after scaling\n        for mu in comp['mu']:\n            lam = rho * mu\n            if lam > tau:\n                total += 1\n    return total\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            'E': [1e9, 1e9, 1e9],\n            'interfaces': [\n                {'pair': (0, 1), 'mu': [0.5, 0.2]},\n                {'pair': (1, 2), 'mu': [0.4, 0.1]},\n            ],\n            'tau': 0.6\n        },\n        # Test Case 2\n        {\n            'E': [1e9, 1e12, 1e9],\n            'interfaces': [\n                {'pair': (0, 1), 'mu': [0.5, 0.2]},\n                {'pair': (1, 2), 'mu': [0.4, 0.1]},\n            ],\n            'tau': 300.0\n        },\n        # Test Case 3\n        {\n            'E': [1e9, 1e12, 1e9],\n            'interfaces': [\n                {'pair': (0, 1), 'mu': [0.5, 0.2]},\n                {'pair': (1, 2), 'mu': [0.4, 0.1]},\n            ],\n            'tau': 400.0\n        },\n        # Test Case 4\n        {\n            'E': [1e6, 1e6, 1e9, 1e9],\n            'interfaces': [\n                {'pair': (0, 2), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (1, 3), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (0, 1), 'mu': [0.6, 0.55, 0.4]},\n                {'pair': (2, 3), 'mu': [0.6, 0.55, 0.4]},\n            ],\n            'tau': 0.5\n        },\n        # Test Case 5\n        {\n            'E': [1e6, 1e6, 1e9, 1e9],\n            'interfaces': [\n                {'pair': (0, 2), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (1, 3), 'mu': [0.3, 0.25, 0.1]},\n                {'pair': (0, 1), 'mu': [0.6, 0.55, 0.4]},\n                {'pair': (2, 3), 'mu': [0.6, 0.55, 0.4]},\n            ],\n            'tau': 1e4\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        E = case['E']\n        interfaces = case['interfaces']\n        tau = case['tau']\n        result = count_added_constraints(E, interfaces, tau)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}