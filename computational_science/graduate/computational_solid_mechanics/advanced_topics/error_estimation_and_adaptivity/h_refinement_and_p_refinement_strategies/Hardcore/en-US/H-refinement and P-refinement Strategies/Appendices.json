{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of the finite element method is the accurate evaluation of system matrices, such as the stiffness matrix. For high-order elements, this requires careful consideration of the numerical integration scheme. This exercise delves into the relationship between the polynomial degree $p$ of the shape functions, the degree $m$ of the geometric mapping, and the required order of Gauss quadrature to integrate the stiffness matrix exactly. Mastering this analysis is a fundamental prerequisite for developing robust and accurate $p$-version and $hp$-version FEM codes .",
            "id": "3569252",
            "problem": "Consider the Finite Element Method (FEM) approximation of a two-dimensional (2D) linear elastic body using isoparametric quadrilateral elements. Let the parent coordinates be denoted by $(\\xi,\\eta)\\in[-1,1]\\times[-1,1]$, and let the mapping from the parent element to the physical element be polynomial of total degree $m$, with components $x(\\xi,\\eta)$ and $y(\\xi,\\eta)$ that are polynomials of total degree $m$. The element displacement interpolation uses tensor-product Lagrange shape functions of degree $p$ in each parent coordinate, so each shape function has the form $N_{a}(\\xi,\\eta)=L_{i}(\\xi)L_{j}(\\eta)$, where $L_{i}$ and $L_{j}$ are one-dimensional Lagrange polynomials of degree $p$. Assume the constitutive (elasticity) tensor $\\mathbf{C}$ is constant.\n\nThe stiffness matrix entry for nodes $a$ and $b$ is given by\n$$\nK_{ab}=\\int_{\\Omega_{e}}\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}\\,\\mathrm{d}\\Omega,\n$$\nwhere $\\mathbf{B}_{a}$ is the strain-displacement matrix for node $a$ and $\\Omega_{e}$ is the physical element domain. Under the isoparametric mapping, this integral is evaluated over the parent domain as\n$$\nK_{ab}=\\int_{-1}^{1}\\int_{-1}^{1}\\mathbf{B}_{a}^{\\mathsf{T}}(\\xi,\\eta)\\,\\mathbf{C}\\,\\mathbf{B}_{b}(\\xi,\\eta)\\,\\det\\mathbf{J}(\\xi,\\eta)\\,\\mathrm{d}\\xi\\,\\mathrm{d}\\eta,\n$$\nwhere $\\mathbf{J}(\\xi,\\eta)$ is the Jacobian of the mapping and $\\det\\mathbf{J}(\\xi,\\eta)$ its determinant.\n\nUse tensor-product Gauss–Legendre quadrature of order $Q$ per coordinate. The one-dimensional Gauss–Legendre rule of order $Q$ integrates exactly any polynomial of degree at most $2Q-1$.\n\nStarting from the foundational definitions of the isoparametric mapping and the strain-displacement relation,\n- derive, for the case of an affine mapping $(m=1)$, the minimal integer quadrature order $Q$ per coordinate that guarantees exact integration of all stiffness matrix entries for the `Q_p` element described above, by determining the maximal polynomial degree that appears in each parent coordinate within the integrand $\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}\\,\\det\\mathbf{J}$.\n- then relate this to the curved mapping case $(m>1)$ by explicitly characterizing the integrand as a rational function in $(\\xi,\\eta)$ and stating the total bivariate polynomial degrees in the numerator and denominator in terms of $p$ and $m$.\n\nProvide your final answer as a single closed-form analytic expression $Q_{\\min}(p)$ giving the minimal quadrature order per coordinate for exact stiffness integration when $m=1$. No rounding is required. No units should be included in the final answer.",
            "solution": "The problem requires the determination of the minimal Gaussian quadrature order for the exact integration of the stiffness matrix of a $Q_p$ isoparametric element, first for an affine mapping ($m=1$) and then a characterization of the integrand for a general curved mapping ($m>1$).\n\nLet us begin by formally defining the components of the integrand for the stiffness matrix entry $K_{ab}$:\n$$\nK_{ab} = \\int_{-1}^{1}\\int_{-1}^{1} \\underbrace{\\mathbf{B}_{a}^{\\mathsf{T}}(\\xi,\\eta)\\,\\mathbf{C}\\,\\mathbf{B}_{b}(\\xi,\\eta)\\,\\det\\mathbf{J}(\\xi,\\eta)}_{I(\\xi, \\eta)} \\,\\mathrm{d}\\xi\\,\\mathrm{d}\\eta\n$$\nThe analysis hinges on determining the polynomial nature of the integrand $I(\\xi, \\eta)$. The elasticity tensor $\\mathbf{C}$ is a constant matrix. We must therefore analyze the strain-displacement matrix $\\mathbf{B}_a$ and the Jacobian determinant $\\det\\mathbf{J}$.\n\nThe displacement field is interpolated using tensor-product Lagrange shape functions $N_a(\\xi, \\eta)$ of degree $p$ in each parent coordinate $\\xi$ and $\\eta$. A generic shape function is of the form $N_a(\\xi, \\eta) = L_i(\\xi) L_j(\\eta)$, where $L_i$ and $L_j$ are one-dimensional Lagrange polynomials of degree $p$.\n\nThe strain vector in 2D is $\\boldsymbol{\\epsilon} = \\left( \\frac{\\partial u}{\\partial x}, \\frac{\\partial v}{\\partial y}, \\frac{\\partial u}{\\partial y} + \\frac{\\partial v}{\\partial x} \\right)^{\\mathsf{T}}$. The strain-displacement matrix $\\mathbf{B}_a$ for a node $a$ is defined such that $\\boldsymbol{\\epsilon} = \\sum_a \\mathbf{B}_a \\mathbf{d}_a$, where $\\mathbf{d}_a$ are the nodal displacements. The matrix for node $a$ is:\n$$\n\\mathbf{B}_a = \\begin{pmatrix}\n\\frac{\\partial N_a}{\\partial x}  0 \\\\\n0  \\frac{\\partial N_a}{\\partial y} \\\\\n\\frac{\\partial N_a}{\\partial y}  \\frac{\\partial N_a}{\\partial x}\n\\end{pmatrix}\n$$\nThe derivatives with respect to physical coordinates $(x,y)$ are related to derivatives in parent coordinates $(\\xi,\\eta)$ via the inverse of the Jacobian matrix $\\mathbf{J}$:\n$$\n\\begin{Bmatrix} \\frac{\\partial N_a}{\\partial x} \\\\ \\frac{\\partial N_a}{\\partial y} \\end{Bmatrix} = \\mathbf{J}^{-1} \\begin{Bmatrix} \\frac{\\partial N_a}{\\partial \\xi} \\\\ \\frac{\\partial N_a}{\\partial \\eta} \\end{Bmatrix}\n\\quad \\text{where} \\quad\n\\mathbf{J} = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi}  \\frac{\\partial y}{\\partial \\xi} \\\\ \\frac{\\partial x}{\\partial \\eta}  \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix}\n$$\nThe derivatives of the shape function $N_a(\\xi, \\eta) = L_i(\\xi) L_j(\\eta)$ are:\n- $\\frac{\\partial N_a}{\\partial \\xi} = L'_i(\\xi) L_j(\\eta)$: This is a polynomial of degree $p-1$ in $\\xi$ and degree $p$ in $\\eta$.\n- $\\frac{\\partial N_a}{\\partial \\eta} = L_i(\\xi) L'_j(\\eta)$: This is a polynomial of degree $p$ in $\\xi$ and degree $p-1$ in $\\eta$.\n\n**Part 1: Affine Mapping ($m=1$)**\n\nFor an affine mapping, the coordinate transformation is linear:\n$x(\\xi, \\eta) = c_0 + c_1 \\xi + c_2 \\eta$\n$y(\\xi, \\eta) = d_0 + d_1 \\xi + d_2 \\eta$\nThis corresponds to a polynomial mapping of total degree $m=1$.\nConsequently, the entries of the Jacobian matrix $\\mathbf{J}$ are constants:\n$\\frac{\\partial x}{\\partial \\xi} = c_1$, $\\frac{\\partial y}{\\partial \\xi} = d_1$, $\\frac{\\partial x}{\\partial \\eta} = c_2$, $\\frac{\\partial y}{\\partial \\eta} = d_2$.\nAs a result, both the Jacobian matrix $\\mathbf{J}$ and its determinant $\\det\\mathbf{J}$ are constant for a valid (non-degenerate) mapping. The inverse Jacobian matrix $\\mathbf{J}^{-1}$ is also a constant matrix.\n\nThe entries of $\\mathbf{B}_a$ are linear combinations of $\\frac{\\partial N_a}{\\partial \\xi}$ and $\\frac{\\partial N_a}{\\partial \\eta}$ with constant coefficients from $\\mathbf{J}^{-1}$. For example:\n$$\n\\frac{\\partial N_a}{\\partial x} = (\\mathbf{J}^{-1})_{11} \\frac{\\partial N_a}{\\partial \\xi} + (\\mathbf{J}^{-1})_{12} \\frac{\\partial N_a}{\\partial \\eta} = (\\mathbf{J}^{-1})_{11} L'_i(\\xi) L_j(\\eta) + (\\mathbf{J}^{-1})_{12} L_i(\\xi) L'_j(\\eta)\n$$\nThe polynomial degree in $\\xi$ of the first term is $p-1$, and of the second term is $p$. Assuming general non-zero coefficients, the degree of $\\frac{\\partial N_a}{\\partial x}$ in $\\xi$ is $p$. By symmetry, its degree in $\\eta$ is also $p$. The same holds for $\\frac{\\partial N_a}{\\partial y}$. Thus, for an affine mapping, each entry of the strain-displacement matrix $\\mathbf{B}_a$ is a polynomial of degree at most $p$ in $\\xi$ and at most $p$ in $\\eta$.\n\nThe kernel of the stiffness integrand is the scalar product $\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}$. This is a sum of products of entries from $\\mathbf{B}_a$ and $\\mathbf{B}_b$. Consider a generic product of two such entries, $P(\\xi, \\eta) \\cdot Q(\\xi, \\eta)$. The degree of the product in a single variable is the sum of the degrees of the factors in that variable.\nWe must find the maximum possible polynomial degree of the full integrand $I(\\xi, \\eta) = \\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}\\,\\det\\mathbf{J}$ in each coordinate direction. Since $\\det\\mathbf{J}$ is constant, we only need to analyze $\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}$.\n\nLet's examine the polynomial degree in the $\\xi$ coordinate. A term in the expansion of $\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}$ involves a product of an entry of $\\mathbf{B}_a$ and an entry of $\\mathbf{B}_b$. For example, a term contributing to the integrand is proportional to $(\\frac{\\partial N_a}{\\partial y})(\\frac{\\partial N_b}{\\partial y})$.\n$$\n\\frac{\\partial N_a}{\\partial y} = (\\mathbf{J}^{-1})_{21} \\frac{\\partial N_a}{\\partial \\xi} + (\\mathbf{J}^{-1})_{22} \\frac{\\partial N_a}{\\partial \\eta} = (\\mathbf{J}^{-1})_{21} L'_i(\\xi) L_j(\\eta) + (\\mathbf{J}^{-1})_{22} L_i(\\xi) L'_j(\\eta)\n$$\nThe degree in $\\xi$ of this polynomial is $p$. The product $(\\frac{\\partial N_a}{\\partial y})(\\frac{\\partial N_b}{\\partial y})$ is formed by multiplying two such polynomials, corresponding to nodes $a$ and $b$. The highest degree term in $\\xi$ arises from the product of the terms with the highest degree in $\\xi$: $(L_i(\\xi) L'_j(\\eta)) \\cdot (L_k(\\xi) L'_l(\\eta))$, where $N_b(\\xi,\\eta)=L_k(\\xi)L_l(\\eta)$. The term $L_i(\\xi) L_k(\\xi)$ has degree $p+p=2p$ in $\\xi$.\nTherefore, the polynomial $\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}$ has a maximum degree of $2p$ in $\\xi$. By symmetry, its maximum degree in $\\eta$ is also $2p$.\n\nA one-dimensional Gauss-Legendre quadrature rule with $Q$ points (order $Q$) integrates a polynomial of degree at most $2Q-1$ exactly. To exactly integrate the stiffness matrix, the quadrature rule must be sufficient for the highest polynomial degree encountered in each coordinate direction.\nFor the $\\xi$-direction, we require:\n$$\n2Q - 1 \\ge 2p\n$$\n$$\n2Q \\ge 2p + 1 \\implies Q \\ge p + \\frac{1}{2}\n$$\nSince the quadrature order $Q$ must be an integer, the minimal required order is $Q_{\\min} = p+1$. The same logic applies to the $\\eta$-direction. Thus, a tensor-product rule of $(p+1) \\times (p+1)$ points is required.\nThe minimal integer quadrature order per coordinate is $Q_{\\min}(p) = p+1$.\n\n**Part 2: Curved Mapping ($m>1$)**\n\nWhen the mapping is curved, the coordinate transformation $x(\\xi,\\eta), y(\\xi,\\eta)$ is given by polynomials of total bivariate degree $m > 1$.\n- The entries of the Jacobian matrix $\\mathbf{J}$ are partial derivatives of these polynomials, so they are polynomials of total degree at most $m-1$.\n- The determinant, $\\det\\mathbf{J} = \\frac{\\partial x}{\\partial \\xi}\\frac{\\partial y}{\\partial \\eta} - \\frac{\\partial y}{\\partial \\xi}\\frac{\\partial x}{\\partial \\eta}$, is a product of such polynomials, so it is a polynomial of total degree at most $(m-1) + (m-1) = 2m-2$.\n- The inverse Jacobian is $\\mathbf{J}^{-1} = (\\det\\mathbf{J})^{-1} \\text{adj}(\\mathbf{J})$. The adjugate matrix entries are polynomials of total degree at most $m-1$. Thus, the entries of $\\mathbf{J}^{-1}$ are rational functions: a numerator polynomial of total degree $\\le m-1$ divided by a denominator polynomial, $\\det\\mathbf{J}$, of total degree $\\le 2m-2$.\n- An entry of the strain-displacement matrix, e.g., $\\frac{\\partial N_a}{\\partial x}$, is given by $\\frac{1}{\\det\\mathbf{J}}(\\frac{\\partial y}{\\partial \\eta}\\frac{\\partial N_a}{\\partial \\xi} - \\frac{\\partial y}{\\partial \\xi}\\frac{\\partial N_a}{\\partial \\eta})$.\n    - The shape function derivatives $\\frac{\\partial N_a}{\\partial \\xi}$ and $\\frac{\\partial N_a}{\\partial \\eta}$ are polynomials of total degree up to $2p-1$.\n    - The numerator of the expression for $\\frac{\\partial N_a}{\\partial x}$ is a sum of products of a polynomial of total degree $\\le m-1$ and a polynomial of total degree $\\le 2p-1$. The resulting numerator is a polynomial of total degree at most $(m-1) + (2p-1) = 2p+m-2$.\n- The full integrand is $I(\\xi, \\eta) = \\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b} \\det\\mathbf{J}$.\n    - A term in $\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}$ is a product of two entries from the B-matrices. This product is a rational function with denominator $(\\det\\mathbf{J})^2$ and a numerator that is a product of two polynomials of total degree $\\le 2p+m-2$. The resulting numerator for this term has total degree $\\le 2(2p+m-2) = 4p+2m-4$.\n    - The sum $\\mathbf{B}_{a}^{\\mathsf{T}}\\mathbf{C}\\,\\mathbf{B}_{b}$ is therefore a rational function $\\frac{P_1(\\xi, \\eta)}{(P_2(\\xi, \\eta))^2}$ where $P_1$ has total degree $\\le 4p+2m-4$ and $P_2=\\det\\mathbf{J}$ has total degree $\\le 2m-2$.\n    - Multiplying by $\\det\\mathbf{J}$ gives the final integrand:\n      $$ I(\\xi, \\eta) = \\frac{P_1(\\xi, \\eta)}{\\det\\mathbf{J}} $$\nIn summary, for the curved mapping case ($m>1$), the integrand is a rational function where:\n- The numerator is a polynomial of total bivariate degree up to $4p+2m-4$.\n- The denominator is a polynomial of total bivariate degree up to $2m-2$.\nBecause the integrand is a rational function, Gauss-Legendre quadrature can no longer guarantee exact integration.\n\nThe final answer requested is for the affine case ($m=1$).",
            "answer": "$$\n\\boxed{p+1}\n$$"
        },
        {
            "introduction": "One of the classic challenges in solid mechanics is modeling nearly incompressible materials, where low-order finite elements often suffer from \"volumetric locking,\" a numerical pathology that produces overly stiff and inaccurate results. This hands-on coding practice explores how $p$-refinement provides a powerful and elegant solution to this problem. By implementing a solver for a hyperelastic material, you will investigate how increasing the polynomial degree of the elements can inherently mitigate locking, and compare its performance to specialized techniques like Selective Reduced Integration (SRI) .",
            "id": "3569277",
            "problem": "Consider a two-dimensional plane-strain hyperelastic block occupying the domain $[0,1]\\times[0,1]$ meters. The material follows a compressible Neo-Hookean model, which in the small-strain limit reduces to linear elasticity with Lamé parameters $\\lambda$ and $\\mu$ given by $\\mu = E/(2(1+\\nu))$ and $\\lambda = \\nu E/((1+\\nu)(1-2\\nu))$, where $E$ is the Young's modulus and $\\nu$ is the Poisson's ratio. Take $E = 1$ Pascal and study the nearly incompressible limit as $\\nu \\to 0.5$. Volumetric locking is a known numerical pathology in the Finite Element Method (FEM) for nearly incompressible materials. One mitigation technique is Selective Reduced Integration (SRI), which evaluates the volumetric contribution to the stiffness with reduced quadrature while keeping the deviatoric contribution fully integrated.\n\nYou will implement a finite element solver on a fixed mesh of $2\\times 2$ quadrilateral elements with a tensor-product Lagrange polynomial basis of degree $p$ per element (denoted $Q_p$). The mesh is built over the unit square domain with straight edges. The geometry mapping is bilinear. The displacement field has two components, and plane-strain is assumed.\n\nBoundary conditions and loading are as follows:\n- The left edge at $x=0$ is clamped: $u_x=0$ and $u_y=0$.\n- A uniform shear traction is applied on the right edge at $x=1$, with traction $\\mathbf{t} = [0, t_0]$ Newton per meter, where $t_0 = 1$. All other edges are traction-free.\n\nThe constitutive law in the small-strain limit is the plane-strain linear elastic tensor $\\mathbf{D}$ acting on the strain vector $\\boldsymbol{\\varepsilon} = [\\varepsilon_{xx}, \\varepsilon_{yy}, \\gamma_{xy}]^T$ such that the stress vector $\\boldsymbol{\\sigma} = \\mathbf{D}\\boldsymbol{\\varepsilon}$. Write\n$$\n\\mathbf{D} = \\mathbf{D}_{\\text{dev}} + \\mathbf{D}_{\\text{vol}},\n$$\nwith\n$$\n\\mathbf{D}_{\\text{dev}} = \\begin{bmatrix} 2\\mu  0  0 \\\\ 0  2\\mu  0 \\\\ 0  0  \\mu \\end{bmatrix}, \\quad\n\\mathbf{D}_{\\text{vol}} = \\begin{bmatrix} \\lambda  \\lambda  0 \\\\ \\lambda  \\lambda  0 \\\\ 0  0  0 \\end{bmatrix}.\n$$\nSelective Reduced Integration (SRI) is implemented by integrating the stiffness contribution from $\\mathbf{D}_{\\text{dev}}$ with a Gauss-Legendre quadrature of sufficient order for $Q_p$, and integrating the contribution from $\\mathbf{D}_{\\text{vol}}$ with a single Gauss point at the element center. Full integration uses the same sufficiently accurate Gauss-Legendre quadrature for the entire $\\mathbf{D}$.\n\nLet $u_{\\text{tip}}(p,\\nu)$ denote the vertical displacement at the top-right corner $(x=1,y=1)$ computed with full integration for polynomial degree $p$ and Poisson's ratio $\\nu$. Let $u_{\\text{tip}}^{\\text{SRI}}(p_{\\max},\\nu)$ denote the same quantity computed using SRI with a high polynomial degree $p_{\\max}$, which will serve as a lock-free reference. Define the relative discrepancy\n$$\n\\delta(p,\\nu) = \\left|\\frac{u_{\\text{tip}}(p,\\nu) - u_{\\text{tip}}^{\\text{SRI}}(p_{\\max},\\nu)}{u_{\\text{tip}}^{\\text{SRI}}(p_{\\max},\\nu)}\\right|.\n$$\nFor a fixed $\\nu$, define the threshold polynomial degree $p_{\\text{lock-free}}(\\nu)$ to be the smallest $p$ in the set $\\{1,2,3,4,5,6\\}$ such that $\\delta(p,\\nu) \\le \\tau$, where the tolerance is $\\tau = 0.02$. If no such $p$ exists in the set, report $-1$.\n\nStarting from the balance of linear momentum in the absence of body forces and the small-strain kinematics,\n$$\n\\nabla\\cdot \\boldsymbol{\\sigma} = \\mathbf{0}, \\quad \\boldsymbol{\\varepsilon} = \\frac{1}{2}(\\nabla \\mathbf{u} + (\\nabla \\mathbf{u})^T),\n$$\nderive the discrete finite element equations and implement the assembly of the global stiffness matrix and load vector for both full integration and SRI on the specified mesh. Use Gauss-Legendre quadrature with $n=p$ points per direction for full integration of $Q_p$ elements. Apply the specified boundary conditions, solve the resulting linear systems, and extract $u_{\\text{tip}}$ and $u_{\\text{tip}}^{\\text{SRI}}$.\n\nExpress any displacements internally in meters, but the final output must be unitless integers as described below. The angle unit is not applicable in this problem.\n\nTest Suite:\n- Case $1$: $\\nu = 0.30$.\n- Case $2$: $\\nu = 0.49$.\n- Case $3$: $\\nu = 0.499$.\n- Case $4$: $\\nu = 0.4999$.\n\nFor all cases use $E = 1$ and $t_0 = 1$ as specified. Use $p_{\\max} = 6$ to compute $u_{\\text{tip}}^{\\text{SRI}}$. For each test case, compute $p_{\\text{lock-free}}(\\nu)$ as defined, with the tolerance $\\tau = 0.02$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order of the test suite, i.e., $[p_{\\text{lock-free}}(0.30), p_{\\text{lock-free}}(0.49), p_{\\text{lock-free}}(0.499), p_{\\text{lock-free}}(0.4999)]$.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of computational solid mechanics, is well-posed, and all necessary parameters and conditions are objectively specified. We will proceed with a detailed solution based on the Finite Element Method (FEM).\n\nThe governing equation for static equilibrium in the absence of body forces is the balance of linear momentum:\n$$\n\\nabla \\cdot \\boldsymbol{\\sigma} = \\mathbf{0} \\quad \\text{in } \\Omega\n$$\nwhere $\\boldsymbol{\\sigma}$ is the Cauchy stress tensor and $\\Omega = [0,1] \\times [0,1]$ is the domain. The problem specifies boundary conditions on the displacement $\\mathbf{u}$ and traction $\\mathbf{t} = \\boldsymbol{\\sigma} \\cdot \\mathbf{n}$.\nThe relationship between strain $\\boldsymbol{\\varepsilon}$ and displacement $\\mathbf{u}$ is given by the small-strain kinematics:\n$$\n\\boldsymbol{\\varepsilon} = \\frac{1}{2}(\\nabla \\mathbf{u} + (\\nabla \\mathbf{u})^T)\n$$\nThe material follows a linear elastic constitutive law $\\boldsymbol{\\sigma} = \\mathbf{D} \\boldsymbol{\\varepsilon}$, where for plane strain, the stress and strain vectors are $\\boldsymbol{\\sigma} = [\\sigma_{xx}, \\sigma_{yy}, \\tau_{xy}]^T$ and $\\boldsymbol{\\varepsilon} = [\\varepsilon_{xx}, \\varepsilon_{yy}, \\gamma_{xy}]^T$. The plane strain stiffness matrix $\\mathbf{D}$ is:\n$$\n\\mathbf{D} = \\begin{bmatrix} \\lambda+2\\mu  \\lambda  0 \\\\ \\lambda  \\lambda+2\\mu  0 \\\\ 0  0  \\mu \\end{bmatrix}\n$$\nwhere $\\lambda$ and $\\mu$ are the Lamé parameters, defined in terms of Young's modulus $E$ and Poisson's ratio $\\nu$.\n\nThe weak form of the governing equation is derived by multiplying by a test function $\\mathbf{v}$ (representing a virtual displacement) and integrating over the domain $\\Omega$:\n$$\n\\int_{\\Omega} (\\nabla \\cdot \\boldsymbol{\\sigma}) \\cdot \\mathbf{v} \\, d\\Omega = 0\n$$\nUsing the divergence theorem and the symmetry of the stress tensor, this leads to the principle of virtual work:\n$$\n\\int_{\\Omega} \\boldsymbol{\\sigma} : \\boldsymbol{\\varepsilon}(\\mathbf{v}) \\, d\\Omega = \\int_{\\Gamma_t} \\mathbf{t} \\cdot \\mathbf{v} \\, d\\Gamma\n$$\nwhere $\\boldsymbol{\\varepsilon}(\\mathbf{v})$ is the strain derived from the test function $\\mathbf{v}$, and the right-hand side represents the work done by external tractions on the boundary $\\Gamma_t$.\n\nIn the finite element method, the domain $\\Omega$ is discretized into elements $\\Omega_e$. Within each element, the displacement field $\\mathbf{u}$ is approximated as:\n$$\n\\mathbf{u}(\\mathbf{x}) \\approx \\mathbf{u}^h(\\mathbf{x}) = \\sum_{a=1}^{N_{en}} N_a(\\mathbf{x}) \\mathbf{d}_a\n$$\nwhere $N_a$ are the shape functions, $\\mathbf{d}_a = [d_{ax}, d_{ay}]^T$ is the vector of nodal displacements for the $a$-th node of the element, and $N_{en}$ is the number of nodes per element. For $Q_p$ elements, $N_{en} = (p+1)^2$. The test function $\\mathbf{v}$ is approximated similarly.\n\nThe strain vector can then be expressed in terms of the nodal displacements:\n$$\n\\boldsymbol{\\varepsilon} = \\sum_{a=1}^{N_{en}} \\mathbf{B}_a \\mathbf{d}_a\n$$\nwhere the matrix $\\mathbf{B}_a$ relates strain to nodal displacement and contains derivatives of the shape functions:\n$$\n\\mathbf{B}_a = \\begin{bmatrix} \\frac{\\partial N_a}{\\partial x}  0 \\\\ 0  \\frac{\\partial N_a}{\\partial y} \\\\ \\frac{\\partial N_a}{\\partial y}  \\frac{\\partial N_a}{\\partial x} \\end{bmatrix}\n$$\nThe derivatives are computed using the chain rule and the Jacobian of the isoparametric coordinate transformation from the reference element $[-1,1]^2$ with coordinates $(\\xi, \\eta)$ to the physical element. For the specified straight-edged rectangular mesh, this Jacobian is constant within each element.\n\nSubstituting the discretized fields into the weak form and noting that it must hold for any valid choice of virtual nodal displacements leads to a system of linear equations for each element:\n$$\n\\mathbf{k}^e \\mathbf{d}^e = \\mathbf{f}^e\n$$\nThe element stiffness matrix $\\mathbf{k}^e$ and force vector $\\mathbf{f}^e$ are given by:\n$$\n\\mathbf{k}^e = \\int_{\\Omega_e} \\mathbf{B}^T \\mathbf{D} \\mathbf{B} \\, d\\Omega, \\quad \\mathbf{f}^e = \\int_{\\Gamma_e} \\mathbf{N}^T \\mathbf{t} \\, d\\Gamma\n$$\nwhere $\\mathbf{B}$ and $\\mathbf{N}$ are matrices collecting the contributions from all nodes in the element.\n\nThe integrals are computed numerically using Gauss-Legendre quadrature. For full integration, the element stiffness matrix is:\n$$\n\\mathbf{k}^e_{\\text{full}} = \\sum_{i=1}^{n_{gp}} w_i (\\mathbf{B}(\\boldsymbol{\\xi}_i))^T \\mathbf{D} \\mathbf{B}(\\boldsymbol{\\xi}_i) |\\mathbf{J}(\\boldsymbol{\\xi}_i)|\n$$\nwhere $\\boldsymbol{\\xi}_i$ are the Gauss points, $w_i$ are the weights, $|\\mathbf{J}|$ is the determinant of the Jacobian, and $n_{gp}=p \\times p$ is the number of Gauss points.\n\nFor Selective Reduced Integration (SRI), the stiffness matrix $\\mathbf{D}$ is split into a deviatoric part $\\mathbf{D}_{\\text{dev}}$ and a volumetric part $\\mathbf{D}_{\\text{vol}}$ as defined in the problem. The element stiffness is computed as:\n$$\n\\mathbf{k}^e_{\\text{SRI}} = \\mathbf{k}^e_{\\text{dev}} + \\mathbf{k}^e_{\\text{vol}}\n$$\n$$\n\\mathbf{k}^e_{\\text{dev}} = \\sum_{i=1}^{p \\times p} w_i (\\mathbf{B}(\\boldsymbol{\\xi}_i))^T \\mathbf{D}_{\\text{dev}} \\mathbf{B}(\\boldsymbol{\\xi}_i) |\\mathbf{J}(\\boldsymbol{\\xi}_i)|\n$$\n$$\n\\mathbf{k}^e_{\\text{vol}} = \\left( \\sum_{j=1}^{1 \\times 1} w_j |\\mathbf{J}(\\boldsymbol{\\xi}_j)| \\right) (\\bar{\\mathbf{B}})^T \\mathbf{D}_{\\text{vol}} \\bar{\\mathbf{B}}\n$$\nwhere the deviatoric part is integrated with the full $p \\times p$ quadrature rule, and the volumetric part is integrated with a single point at the element center $(\\xi_j=(0,0))$. $\\bar{\\mathbf{B}}$ is the $\\mathbf{B}$ matrix evaluated at this center point.\n\nThe global stiffness matrix $\\mathbf{K}$ and force vector $\\mathbf{F}$ are assembled by summing the contributions from all four elements. The specified boundary conditions are then applied. The clamped condition ($u_x=u_y=0$) at $x=0$ is an essential boundary condition, enforced by modifying the linear system. The shear traction at $x=1$ is a natural boundary condition, handled by assembling the element force vectors $\\mathbf{f}^e$ for the elements on that boundary.\n\nAfter enforcing the boundary conditions, the global linear system $\\mathbf{K}\\mathbf{d}=\\mathbf{F}$ is solved for the vector of all nodal displacements $\\mathbf{d}$. The required vertical tip displacement $u_{\\text{tip}}$ is then extracted from $\\mathbf{d}$ at the node corresponding to physical coordinates $(1,1)$.\n\nThe procedure is as follows:\n1. For each $\\nu$ in the test suite, calculate the reference displacement $u_{\\text{tip}}^{\\text{SRI}}(p_{\\max},\\nu)$ by running the FEM solver with $p=p_{\\max}=6$ and SRI.\n2. For the same $\\nu$, loop through $p \\in \\{1, 2, 3, 4, 5, 6\\}$.\n3. In each iteration, compute $u_{\\text{tip}}(p, \\nu)$ using full integration.\n4. Calculate the relative discrepancy $\\delta(p,\\nu)$.\n5. The first value of $p$ for which $\\delta(p, \\nu)$ is less than or equal to the tolerance $\\tau=0.02$ is recorded as $p_{\\text{lock-free}}(\\nu)$. If no such $p$ is found, the result is $-1$.\nThis process is repeated for all values of $\\nu$ in the test suite to generate the final output list.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Main driver function to solve the problem for the given test suite.\n    \"\"\"\n\n    def get_lagrange_basis(p, xi, nodes):\n        \"\"\"\n        Computes 1D Lagrange basis functions of degree p and their derivatives.\n        \"\"\"\n        n_nodes = p + 1\n        N = np.zeros(n_nodes)\n        dN_dxi = np.zeros(n_nodes)\n        \n        for i in range(n_nodes):\n            num = 1.0\n            den = 1.0\n            dnum = 0.0\n            \n            for j in range(n_nodes):\n                if i != j:\n                    num *= (xi - nodes[j])\n                    den *= (nodes[i] - nodes[j])\n            \n            for m in range(n_nodes):\n                if m != i:\n                    term = 1.0\n                    for j in range(n_nodes):\n                        if j != i and j != m:\n                            term *= (xi - nodes[j])\n                    dnum += term\n            \n            N[i] = num / den\n            dN_dxi[i] = dnum / den\n            \n        return N, dN_dxi\n\n    def solve_fem(p, nu, integration_type):\n        \"\"\"\n        A general FEM solver for the 2D plane strain problem.\n        p: polynomial degree of the Q_p element.\n        nu: Poisson's ratio.\n        integration_type: 'full' or 'sri'.\n        \"\"\"\n        E = 1.0\n        t0 = 1.0\n        \n        # Material properties\n        mu = E / (2 * (1 + nu))\n        lmbda = (E * nu) / ((1 + nu) * (1 - 2 * nu))\n\n        D_dev = np.array([[2 * mu, 0, 0], [0, 2 * mu, 0], [0, 0, mu]])\n        D_vol = np.array([[lmbda, lmbda, 0], [lmbda, lmbda, 0], [0, 0, 0]])\n        D_full = D_dev + D_vol\n\n        # Mesh properties\n        nels_x, nels_y = 2, 2\n        domain_size_x, domain_size_y = 1.0, 1.0\n        el_size_x = domain_size_x / nels_x\n        el_size_y = domain_size_y / nels_y\n\n        nnodes_x = nels_x * p + 1\n        nnodes_y = nels_y * p + 1\n        num_nodes = nnodes_x * nnodes_y\n        num_dofs = 2 * num_nodes\n\n        # Node coordinates\n        x_coords = np.linspace(0, domain_size_x, nnodes_x)\n        y_coords = np.linspace(0, domain_size_y, nnodes_y)\n        node_coords = np.array([[x, y] for y in y_coords for x in x_coords])\n\n        # Connectivity\n        num_el_nodes = (p + 1) ** 2\n        connectivity = np.zeros((nels_x * nels_y, num_el_nodes), dtype=int)\n        for el_y in range(nels_y):\n            for el_x in range(nels_x):\n                el_idx = el_y * nels_x + el_x\n                local_node_idx = 0\n                for j in range(p + 1):\n                    for i in range(p + 1):\n                        global_ix = el_x * p + i\n                        global_iy = el_y * p + j\n                        connectivity[el_idx, local_node_idx] = global_iy * nnodes_x + global_ix\n                        local_node_idx += 1\n        \n        # Quadrature points and weights\n        if integration_type == 'full':\n            pts_full, w_full = roots_legendre(p)\n            n_gp_full = p\n        elif integration_type == 'sri':\n            pts_full, w_full = roots_legendre(p)\n            n_gp_full = p\n            pts_red, w_red = np.array([0.0]), np.array([2.0]) # 1 point rule\n            n_gp_red = 1\n        \n        # Basis functions reference nodes\n        basis_nodes = np.linspace(-1, 1, p + 1)\n\n        # Assembly\n        K = np.zeros((num_dofs, num_dofs))\n        F = np.zeros(num_dofs)\n\n        for el_idx in range(nels_x * nels_y):\n            k_e = np.zeros((num_el_nodes * 2, num_el_nodes * 2))\n            \n            # Jacobian (constant for this mesh)\n            J = np.array([[el_size_x / 2, 0], [0, el_size_y / 2]])\n            detJ = np.linalg.det(J)\n            invJ = np.linalg.inv(J)\n\n            def assemble_stiffness(pts, w, D_mat):\n                k_mat = np.zeros((num_el_nodes * 2, num_el_nodes * 2))\n                for pt_y, w_y in zip(pts, w):\n                    for pt_x, w_x in zip(pts, w):\n                        N_1d_xi, dN_dxi_1d = get_lagrange_basis(p, pt_x, basis_nodes)\n                        N_1d_eta, dN_deta_1d = get_lagrange_basis(p, pt_y, basis_nodes)\n                        \n                        B = np.zeros((3, num_el_nodes * 2))\n                        for j in range(p + 1):\n                            for i in range(p + 1):\n                                node_idx = j * (p + 1) + i\n                                \n                                dN_dxi = dN_dxi_1d[i] * N_1d_eta[j]\n                                dN_deta = N_1d_xi[i] * dN_deta_1d[j]\n                                \n                                dN_dxy = invJ @ np.array([dN_dxi, dN_deta])\n                                \n                                B[0, 2 * node_idx] = dN_dxy[0]\n                                B[1, 2 * node_idx + 1] = dN_dxy[1]\n                                B[2, 2 * node_idx] = dN_dxy[1]\n                                B[2, 2 * node_idx + 1] = dN_dxy[0]\n                        k_mat += B.T @ D_mat @ B * detJ * w_x * w_y\n                return k_mat\n\n            if integration_type == 'full':\n                k_e = assemble_stiffness(pts_full, w_full, D_full)\n            elif integration_type == 'sri':\n                k_dev = assemble_stiffness(pts_full, w_full, D_dev)\n                \n                # Reduced integration for volumetric part (B-bar method)\n                # B at center (0,0)\n                N_1d_xi_c, dN_dxi_1d_c = get_lagrange_basis(p, 0.0, basis_nodes)\n                N_1d_eta_c, dN_deta_1d_c = get_lagrange_basis(p, 0.0, basis_nodes)\n                B_bar = np.zeros((3, num_el_nodes * 2))\n                for j in range(p + 1):\n                    for i in range(p + 1):\n                        node_idx = j * (p + 1) + i\n                        dN_dxi = dN_dxi_1d_c[i] * N_1d_eta_c[j]\n                        dN_deta = N_1d_xi_c[i] * dN_deta_1d_c[j]\n                        dN_dxy = invJ @ np.array([dN_dxi, dN_deta])\n                        B_bar[0, 2*node_idx] = dN_dxy[0]\n                        B_bar[1, 2*node_idx+1] = dN_dxy[1]\n                        B_bar[2, 2*node_idx] = dN_dxy[1]\n                        B_bar[2, 2*node_idx+1] = dN_dxy[0]\n                k_vol = B_bar.T @ D_vol @ B_bar * detJ * 4.0 # weight is 2*2=4\n                \n                k_e = k_dev + k_vol\n\n            # Assemble into global K\n            dof_indices = np.array([[2 * n, 2 * n + 1] for n in connectivity[el_idx, :]]).flatten()\n            K[np.ix_(dof_indices, dof_indices)] += k_e\n\n        # Apply traction BC on the right edge (x=1)\n        traction = np.array([0, t0])\n        q_pts_1d, q_w_1d = roots_legendre(p)\n        for el_y in range(nels_y):\n            el_idx = el_y * nels_x + (nels_x - 1)\n            f_e = np.zeros(num_el_nodes * 2)\n            \n            for pt_eta, w_eta in zip(q_pts_1d, q_w_1d):\n                N_1d_xi, _ = get_lagrange_basis(p, 1.0, basis_nodes) # edge at xi=1\n                N_1d_eta, _ = get_lagrange_basis(p, pt_eta, basis_nodes)\n                \n                for j in range(p + 1):\n                    for i in range(p + 1):\n                        node_idx = j * (p + 1) + i\n                        N_val = N_1d_xi[i] * N_1d_eta[j]\n                        f_e[2*node_idx:2*node_idx+2] += N_val * traction * (el_size_y/2) * w_eta\n            \n            dof_indices = np.array([[2 * n, 2 * n + 1] for n in connectivity[el_idx, :]]).flatten()\n            F[dof_indices] += f_e\n\n        # Apply displacement BC on the left edge (x=0)\n        fixed_dofs = []\n        for j in range(nnodes_y):\n            node_id = j * nnodes_x\n            fixed_dofs.append(2 * node_id)\n            fixed_dofs.append(2 * node_id + 1)\n        \n        K_bc = np.copy(K)\n        F_bc = np.copy(F)\n        for dof in fixed_dofs:\n            K_bc[dof, :] = 0\n            K_bc[:, dof] = 0\n            K_bc[dof, dof] = 1\n            F_bc[dof] = 0\n\n        # Solve\n        u = np.linalg.solve(K_bc, F_bc)\n\n        # Extract tip displacement\n        tip_node_id = nnodes_y * nnodes_x - 1\n        tip_dof_y = 2 * tip_node_id + 1\n        return u[tip_dof_y]\n\n    # --- Main Test Execution ---\n    test_cases = [0.30, 0.49, 0.499, 0.4999]\n    p_max = 6\n    tau = 0.02\n    p_values = range(1, 7)\n    \n    results = []\n    \n    for nu in test_cases:\n        p_lock_free = -1\n\n        # Compute reference solution\n        u_ref = solve_fem(p=p_max, nu=nu, integration_type='sri')\n\n        for p in p_values:\n            u_tip = solve_fem(p=p, nu=nu, integration_type='full')\n            \n            if abs(u_ref) > 1e-12:\n                delta = abs((u_tip - u_ref) / u_ref)\n            else: # to handle case where u_ref might be zero\n                delta = abs(u_tip)\n\n            if delta = tau:\n                p_lock_free = p\n                break\n        \n        results.append(p_lock_free)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The ultimate goal of $hp$-FEM is to automate the refinement process, allowing the simulation to adaptively place small, low-order elements in regions of low solution regularity (like singularities) and large, high-order elements where the solution is smooth. This capstone exercise guides you through implementing the core logic of such an adaptive strategy. You will develop an algorithm that analyzes the local solution behavior, decides between $h$- and $p$-refinement, and predicts the computational efficiency of its choice, providing a practical foundation for building intelligent, self-adapting simulation tools .",
            "id": "3569272",
            "problem": "Consider a one-dimensional linear elastic bar problem discretized by the Finite Element Method (FEM) with a hierarchical basis. For each element, you are given the element size $h$, the current polynomial degree $p$, a sequence of hierarchical surplus norms $\\{\\|\\hat{u}_{k}\\|\\}$ for $k$ starting at $p+1$ and increasing by one, and a local residual estimate $R$. The hierarchical surplus norm $\\|\\hat{u}_{k}\\|$ represents the contribution of the hierarchical enrichment mode of order $k$ to the local energy-norm error.\n\nYou must design an adaptive decision and stopping criterion driven by the decay of the hierarchical surplus sequence and the local residual. Use the following rules for each element:\n\n1. Geometric-decay classification. Compute the ratios $r_k = \\|\\hat{u}_{k+1}\\| / \\|\\hat{u}_{k}\\|$ using all consecutive nonnegative $\\|\\hat{u}_{k}\\|$ pairs available in the provided sequence. Define the mean ratio $\\overline{r}$ as the arithmetic mean of all $r_k$ computed. Define the standard deviation of the logarithms as $\\sigma_{\\log} = \\mathrm{std}(\\{\\log(r_k)\\})$, where for a single ratio use $\\sigma_{\\log} = 0$. If no valid ratios are available (for example, the sequence has length less than $2$ or contains only zeros), classify the sequence as non-geometric. Otherwise, classify the element’s surplus sequence as geometrically decaying if $\\overline{r}  r_{\\mathrm{thr}}$ and $\\sigma_{\\log} \\le s_{\\mathrm{thr}}$. The parameters $r_{\\mathrm{thr}}$ and $s_{\\mathrm{thr}}$ are given in the test suite.\n\n2. Refinement selection. If the sequence is geometrically decaying, select $p$-refinement (increase the polynomial degree by one on the element). Otherwise, select $h$-refinement (split the element into two equal subelements of the same polynomial degree).\n\n3. Predicted error reduction. For each element, predict the local error reduction due to the selected refinement as follows:\n   - If $p$-refinement is selected, use the next hierarchical mode magnitude as the first-order estimate of the error reduction: $\\Delta E_{\\mathrm{pred}}^{(p)} = \\|\\hat{u}_{p+1}\\|$ (the first term of the provided surplus sequence for that element).\n   - If $h$-refinement is selected, assume the energy-norm error scales with element size as $E \\sim h^{p+1}$ for smooth regimes, and use the local residual to scale a dimensionless error estimate. Predict the reduction factor from halving $h$ as $1 - 2^{-(p+1)}$, and model the current element error as $E_e \\approx R \\, h$. Then $\\Delta E_{\\mathrm{pred}}^{(h)} = R \\, h \\, \\big(1 - 2^{-(p+1)}\\big)$.\n   All error reductions must be treated as dimensionless.\n\n4. Degrees of freedom (DOF) cost. In one-dimensional continuous Galerkin FEM with hierarchical bases, increasing the polynomial degree by one on a single element introduces approximately one additional global DOF on that element, while splitting one element into two increases the global DOF count by approximately $p$. Therefore, set $\\Delta n^{(p)} = 1$ and $\\Delta n^{(h)} = p$ for the DOF increment associated with the selected refinement on that element.\n\n5. Stopping criterion. For each element, if both $\\max_k \\|\\hat{u}_{k}\\| \\le \\tau_{\\mathrm{sur}}$ and $R \\le \\tau_{\\mathrm{res}}$, then mark the element as satisfying the stopping criterion (no refinement needed). The global stopping flag for the mesh is true if and only if every element satisfies the stopping criterion. The parameters $\\tau_{\\mathrm{sur}}$ and $\\tau_{\\mathrm{res}}$ are given in the test suite.\n\nFor each test case, apply the above rules to all elements, excluding stopped elements from refinement (their predicted error reduction and DOF increment are zero). Aggregate the predicted total error reduction per degree of freedom as\n$$\n\\eta = \\frac{\\sum_{e} \\Delta E_{\\mathrm{pred}, e}}{\\sum_{e} \\Delta n_e},\n$$\nwhere the sums run over all elements that are not stopped. If the denominator is zero, set $\\eta = 0$.\n\nReturn, for each test case, a list $[\\eta, N_p, N_h, \\mathrm{Stop}]$, where $N_p$ is the number of elements assigned $p$-refinement, $N_h$ is the number of elements assigned $h$-refinement, and $\\mathrm{Stop}$ is the global stopping boolean. Express $\\eta$ as a dimensionless float rounded to six decimal places. Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, for example, $[[\\eta_1,N_{p,1},N_{h,1},\\mathrm{Stop}_1],[\\eta_2,N_{p,2},N_{h,2},\\mathrm{Stop}_2]]$.\n\nTest suite. Use the following four test cases, each specified by a list of elements with their parameters and a set of global thresholds $(r_{\\mathrm{thr}}, s_{\\mathrm{thr}}, \\tau_{\\mathrm{sur}}, \\tau_{\\mathrm{res}})$:\n- Test case 1 (smooth regime, geometric decay, all $p$-refinements expected):\n  - Elements:\n    - $h=0.5$, $p=2$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.05, 0.025, 0.0125]$, $R=0.02$.\n    - $h=0.3$, $p=2$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.02, 0.010, 0.005]$, $R=0.01$.\n    - $h=0.2$, $p=3$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.04, 0.020, 0.010]$, $R=0.015$.\n  - Thresholds: $r_{\\mathrm{thr}} = 0.6$, $s_{\\mathrm{thr}} = 0.2$, $\\tau_{\\mathrm{sur}} = 10^{-4}$, $\\tau_{\\mathrm{res}} = 10^{-4}$.\n\n- Test case 2 (non-geometric decay, $h$-refinements expected):\n  - Elements:\n    - $h=0.8$, $p=2$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.10, 0.09, 0.30]$, $R=0.12$.\n    - $h=0.4$, $p=3$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.08, 0.07, 0.06]$, $R=0.15$.\n  - Thresholds: $r_{\\mathrm{thr}} = 0.6$, $s_{\\mathrm{thr}} = 0.2$, $\\tau_{\\mathrm{sur}} = 10^{-4}$, $\\tau_{\\mathrm{res}} = 10^{-4}$.\n\n- Test case 3 (borderline geometric decay, mixed residuals):\n  - Elements:\n    - $h=0.5$, $p=2$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.030, 0.018, 0.0108]$, $R=0.005$.\n    - $h=0.25$, $p=2$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.008, 0.000, 0.000]$, $R=0.002$.\n    - $h=0.25$, $p=1$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.050, 0.030]$, $R=0.200$.\n  - Thresholds: $r_{\\mathrm{thr}} = 0.6$, $s_{\\mathrm{thr}} = 0.2$, $\\tau_{\\mathrm{sur}} = 10^{-4}$, $\\tau_{\\mathrm{res}} = 10^{-4}$.\n\n- Test case 4 (edge case with minimal surplus data and a near-stopped element):\n  - Elements:\n    - $h=1.0$, $p=1$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.200]$, $R=0.300$.\n    - $h=1.0$, $p=1$, $\\{\\|\\hat{u}_{k}\\|\\} = [0.00005]$, $R=0.00002$.\n  - Thresholds: $r_{\\mathrm{thr}} = 0.6$, $s_{\\mathrm{thr}} = 0.2$, $\\tau_{\\mathrm{sur}} = 10^{-4}$, $\\tau_{\\mathrm{res}} = 10^{-4}$.\n\nYour program must implement the above rules and produce the single-line output described. All quantities are dimensionless. Angles do not appear. There are no physical units to convert.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of computational solid mechanics, specifically the Finite Element Method (FEM) and $hp$-adaptive refinement strategies. The problem is well-posed, with a complete and consistent set of rules and data that allows for the derivation of a unique, verifiable solution. The terminology used, such as hierarchical basis, surplus norms, and residual estimates, is standard in the field. The provided rules constitute a deterministic algorithm for making adaptivity decisions.\n\nThe solution is obtained by implementing the prescribed algorithm, which consists of two main stages: an element-wise analysis followed by a global aggregation of results.\n\n### Step I: Element-wise Analysis\n\nFor each element $e$ in a given test case, with properties including element size $h_e$, polynomial degree $p_e$, surplus norm sequence $\\{\\|\\hat{u}_{k}\\|_e\\}$, and local residual $R_e$, the following procedure is applied. The global thresholds for this analysis are $r_{\\mathrm{thr}}$, $s_{\\mathrm{thr}}$, $\\tau_{\\mathrm{sur}}$, and $\\tau_{\\mathrm{res}}$.\n\n#### 1. Stopping Criterion (Rule 5)\nFirst, we determine if the element's solution is locally converged and requires no further refinement. An element is marked as \"stopped\" if both of the following conditions are met:\n- The maximum hierarchical surplus norm is below a tolerance: $\\max_k \\|\\hat{u}_{k}\\|_e \\le \\tau_{\\mathrm{sur}}$. If the surplus sequence is empty, this condition is considered met as the maximum contribution is zero.\n- The local residual estimate is below a tolerance: $R_e \\le \\tau_{\\mathrm{res}}$.\n\nIf an element is stopped, its predicted error reduction $\\Delta E_{\\mathrm{pred}, e}$ and degrees-of-freedom (DOF) cost $\\Delta n_e$ are both set to $0$.\n\n#### 2. Refinement Decision (Rules 1  2)\nIf an element is not stopped, a refinement strategy ($p$- or $h$-refinement) must be selected. This decision is based on the decay characteristics of the surplus norm sequence.\n\n- **Ratio Calculation**: We compute a sequence of ratios $r_k = \\|\\hat{u}_{k+1}\\|_e / \\|\\hat{u}_{k}\\|_e$. These ratios are calculated for all consecutive pairs in the surplus norm sequence where the denominator $\\|\\hat{u}_{k}\\|_e$ is strictly greater than $0$.\n\n- **Geometric Decay Classification**: The sequence is classified as geometrically decaying based on two metrics derived from the computed ratios $\\{r_k\\}$:\n    1.  The arithmetic mean of the ratios, $\\overline{r} = \\mathrm{mean}(\\{r_k\\})$.\n    2.  The standard deviation of the logarithms of the ratios, $\\sigma_{\\log} = \\mathrm{std}(\\{\\log(r_k)\\})$.\n    \n    The classification rules are as follows:\n    - If no valid ratios can be computed (e.g., the surplus sequence has fewer than two terms, or consists of values preventing division), the decay is classified as **non-geometric**.\n    - If a single ratio is computed, $\\sigma_{\\log}$ is defined to be $0$.\n    - The decay is classified as **geometrically decaying** if and only if both $\\overline{r}  r_{\\mathrm{thr}}$ and $\\sigma_{\\log} \\le s_{\\mathrm{thr}}$. Otherwise, it is non-geometric. Note that if a computed ratio $r_k$ is $0$, its logarithm is $-\\infty$, and the standard deviation involving such a term will be `NaN` (Not a Number). In standard floating-point arithmetic, a comparison `NaN = s_thr` evaluates to `False`, correctly classifying the decay as non-geometric.\n\n- **Refinement Selection**:\n    - If the decay is geometric, **$p$-refinement** is selected.\n    - If the decay is non-geometric, **$h$-refinement** is selected.\n\n#### 3. Prediction of Error Reduction and Cost (Rules 3  4)\nOnce a refinement strategy is chosen for a non-stopped element, we predict the resulting local error reduction and the associated increase in DOFs.\n\n- For **$p$-refinement**:\n    - The predicted error reduction is estimated by the norm of the first hierarchical surplus mode: $\\Delta E_{\\mathrm{pred}, e}^{(p)} = \\|\\hat{u}_{p_e+1}\\|_e$. This is the first term in the provided surplus norm sequence.\n    - The DOF cost is $\\Delta n_e^{(p)} = 1$.\n\n- For **$h$-refinement**:\n    - The predicted error reduction is based on the theoretical convergence rate in $h$: $\\Delta E_{\\mathrm{pred}, e}^{(h)} = R_e h_e (1 - 2^{-(p_e+1)})$.\n    - The DOF cost is $\\Delta n_e^{(h)} = p_e$.\n\n### Step II: Global Aggregation\n\nAfter processing all elements in a test case, the global results are aggregated.\n\n- **Total Predicted Reduction and Cost**: The total predicted error reduction $\\sum_{e} \\Delta E_{\\mathrm{pred}, e}$ and total DOF cost $\\sum_{e} \\Delta n_e$ are calculated by summing the contributions from all non-stopped elements.\n\n- **Efficiency Metric**: The overall predicted efficiency of the refinement strategy is computed as:\n$$\n\\eta = \\frac{\\sum_{e} \\Delta E_{\\mathrm{pred}, e}}{\\sum_{e} \\Delta n_e}\n$$\nIf the total DOF cost $\\sum_{e} \\Delta n_e$ is zero (which occurs if all elements are stopped), $\\eta$ is set to $0$.\n\n- **Refinement Counts**: The total number of elements marked for $p$-refinement, $N_p$, and for $h$-refinement, $N_h$, are tallied.\n\n- **Global Stopping Flag**: A global stopping flag, `Stop`, is set to `True` if and only if all elements in the mesh were marked as stopped in Step I. Otherwise, it is `False`.\n\nFinally, for each test case, these aggregated results are compiled into a list $[\\eta, N_p, N_h, \\mathrm{Stop}]$, with $\\eta$ rounded to six decimal places, to form the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"elements\": [\n                {'h': 0.5, 'p': 2, 'u': [0.05, 0.025, 0.0125], 'R': 0.02},\n                {'h': 0.3, 'p': 2, 'u': [0.02, 0.010, 0.005], 'R': 0.01},\n                {'h': 0.2, 'p': 3, 'u': [0.04, 0.020, 0.010], 'R': 0.015},\n            ],\n            \"thresholds\": (0.6, 0.2, 1e-4, 1e-4)\n        },\n        {\n            \"elements\": [\n                {'h': 0.8, 'p': 2, 'u': [0.10, 0.09, 0.30], 'R': 0.12},\n                {'h': 0.4, 'p': 3, 'u': [0.08, 0.07, 0.06], 'R': 0.15},\n            ],\n            \"thresholds\": (0.6, 0.2, 1e-4, 1e-4)\n        },\n        {\n            \"elements\": [\n                {'h': 0.5, 'p': 2, 'u': [0.030, 0.018, 0.0108], 'R': 0.005},\n                {'h': 0.25, 'p': 2, 'u': [0.008, 0.000, 0.000], 'R': 0.002},\n                {'h': 0.25, 'p': 1, 'u': [0.050, 0.030], 'R': 0.200},\n            ],\n            \"thresholds\": (0.6, 0.2, 1e-4, 1e-4)\n        },\n        {\n            \"elements\": [\n                {'h': 1.0, 'p': 1, 'u': [0.200], 'R': 0.300},\n                {'h': 1.0, 'p': 1, 'u': [0.00005], 'R': 0.00002},\n            ],\n            \"thresholds\": (0.6, 0.2, 1e-4, 1e-4)\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case['elements'], case['thresholds'])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef process_case(elements, thresholds):\n    \"\"\"\n    Processes a single test case according to the problem rules.\n    \"\"\"\n    r_thr, s_thr, tau_sur, tau_res = thresholds\n    \n    total_delta_E = 0.0\n    total_delta_n = 0\n    Np = 0\n    Nh = 0\n    stopped_count = 0\n    \n    for el in elements:\n        h, p, u_seq, R = el['h'], el['p'], np.array(el['u']), el['R']\n        \n        # Rule 5: Stopping criterion\n        # An empty surplus sequence has a max contribution of 0.\n        max_u = 0.0 if len(u_seq) == 0 else np.max(u_seq)\n        if max_u = tau_sur and R = tau_res:\n            stopped_count += 1\n            # Predictions for stopped elements are zero.\n            continue\n\n        # Rule 1: Geometric-decay classification\n        is_geometric = False\n        \n        # Ratios are computed for consecutive pairs where the denominator is > 0.\n        ratios = [u_seq[i+1] / u_seq[i] for i in range(len(u_seq) - 1) if u_seq[i] > 0]\n        \n        if len(ratios) == 0:\n            # Non-geometric if sequence is too short or has no valid denominators.\n            is_geometric = False\n        else:\n            r_mean = np.mean(ratios)\n            \n            if len(ratios) == 1:\n                # Special rule for a single ratio.\n                sigma_log = 0.0\n            else:\n                # Suppress log(0) warnings; their effect is handled by NaN propagation.\n                with np.errstate(divide='ignore'):\n                    log_ratios = np.log(ratios)\n                sigma_log = np.std(log_ratios) # ddof=0 by default\n            \n            # The condition `sigma_log = s_thr` will be False if sigma_log is NaN.\n            if r_mean  r_thr and sigma_log = s_thr:\n                is_geometric = True\n\n        # Rules 2, 3, 4: Refinement selection, error prediction, and DOF cost\n        if is_geometric:\n            # p-refinement\n            Np += 1\n            # Predicted error reduction is the first surplus mode's norm.\n            delta_E = u_seq[0] if len(u_seq) > 0 else 0.0\n            delta_n = 1\n        else:\n            # h-refinement\n            Nh += 1\n            delta_E = R * h * (1 - 2**(-(p + 1)))\n            delta_n = p\n        \n        total_delta_E += delta_E\n        total_delta_n += delta_n\n\n    # Aggregation of results for the test case\n    if total_delta_n == 0:\n        eta = 0.0\n    else:\n        eta = total_delta_E / total_delta_n\n        \n    global_stop = (stopped_count == len(elements))\n    \n    return [round(eta, 6), Np, Nh, global_stop]\n\nsolve()\n```"
        }
    ]
}