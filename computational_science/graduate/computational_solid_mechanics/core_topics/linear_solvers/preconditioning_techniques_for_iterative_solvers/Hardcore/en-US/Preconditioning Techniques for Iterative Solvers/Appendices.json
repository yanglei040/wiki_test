{
    "hands_on_practices": [
        {
            "introduction": "We begin with a foundational exercise that illustrates the ideal goal of preconditioning. This problem explores a scenario where an Incomplete Cholesky (IC) factorization, a common preconditioning technique, becomes exact for a specific matrix structure arising from a 1D elasticity problem . By working through the factorization, you will discover that the preconditioner is perfect, transforming the system into one with a condition number of 1, thereby providing a concrete example of optimal preconditioning.",
            "id": "3590218",
            "problem": "Consider the discrete one-dimensional linear elasticity stiffness operator on a uniform mesh with Dirichlet boundary conditions, leading to the symmetric positive definite (SPD) Toeplitz matrix $A \\in \\mathbb{R}^{5 \\times 5}$ given by $A=\\operatorname{tridiag}(-1,2,-1)$. Using the definition of incomplete Cholesky factorization with zero fill (IC(0)) under natural ordering and without any diagonal modification, construct the lower-triangular factor $L$ with the same sparsity pattern as the lower triangle of $A$ and the preconditioner $M = LL^{T}$. Starting from the Cholesky factorization definition for SPD matrices and the sparsity-induced recursion for the bidiagonal $L$, derive the entries of $L$ explicitly. Then, determine the eigenvalues of the preconditioned operator $M^{-1}A$ exactly, and conclude the exact spectral condition number $\\kappa_{2}(M^{-1}A)$.\n\nProvide the exact value of the spectral condition number $\\kappa_{2}(M^{-1}A)$ as your final answer. No rounding is required. Express the final answer as a pure number without units.",
            "solution": "The problem asks for the spectral condition number of a system preconditioned with Incomplete Cholesky factorization with zero fill-in (IC(0)).\n\nFirst, we define the matrix $A$. It is a $5 \\times 5$ matrix representing the 1D discrete Laplacian with Dirichlet boundary conditions. The structure is $A = \\operatorname{tridiag}(-1, 2, -1)$:\n$$\nA = \\begin{pmatrix} 2 & -1 & 0 & 0 & 0 \\\\ -1 & 2 & -1 & 0 & 0 \\\\ 0 & -1 & 2 & -1 & 0 \\\\ 0 & 0 & -1 & 2 & -1 \\\\ 0 & 0 & 0 & -1 & 2 \\end{pmatrix}\n$$\nThis matrix is symmetric and positive definite (SPD).\n\nThe preconditioner $M$ is obtained from the IC(0) factorization, $M = LL^T$. The IC(0) algorithm requires the factor $L$ to have the same sparsity pattern as the lower triangular part of $A$. Since $A$ is tridiagonal, its lower triangular part is bidiagonal. Therefore, $L$ must be a lower bidiagonal matrix.\n$$\nL = \\begin{pmatrix}\nl_{11} & 0 & 0 & 0 & 0 \\\\\nl_{21} & l_{22} & 0 & 0 & 0 \\\\\n0 & l_{32} & l_{33} & 0 & 0 \\\\\n0 & 0 & l_{43} & l_{44} & 0 \\\\\n0 & 0 & 0 & l_{54} & l_{55}\n\\end{pmatrix}\n$$\nA key property of band matrices is that their Cholesky factorization can introduce fill-in outside the original band. However, for a symmetric tridiagonal matrix, the exact Cholesky factor $L$ is also a lower bidiagonal matrix. There is no fill-in generated that would need to be discarded. This means that for a tridiagonal matrix, the Incomplete Cholesky factorization with zero fill-in (IC(0)) is identical to the exact Cholesky factorization.\n\nTherefore, the preconditioner $M = LL^T$ is not an approximation of $A$, but is exactly equal to $A$.\n$$\nM = LL^T = A\n$$\nWith this result, we can analyze the preconditioned operator $M^{-1}A$:\n$$\nM^{-1}A = A^{-1}A = I\n$$\nThe preconditioned operator is the $5 \\times 5$ identity matrix, $I$.\n\nThe eigenvalues of the identity matrix are all equal to $1$.\n$$\n\\lambda_k(M^{-1}A) = 1 \\quad \\text{for } k=1, \\dots, 5.\n$$\nThe spectral condition number of an SPD or normal matrix is the ratio of its largest eigenvalue to its smallest eigenvalue. For the identity matrix:\n$$\n\\kappa_2(M^{-1}A) = \\frac{\\lambda_{\\max}(I)}{\\lambda_{\\min}(I)} = \\frac{1}{1} = 1.\n$$\nThis demonstrates an ideal preconditioning scenario where the preconditioner perfectly inverts the original matrix, leading to a condition number of $1$ and convergence of an iterative solver (like PCG) in a single iteration.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "This practice bridges abstract linear algebra with tangible physical principles from solid mechanics. We analyze a simple finite element model of a bar to understand how ill-conditioning arises from physical phenomena, specifically unconstrained rigid-body motion which manifests as a nullspace in the stiffness matrix . You will investigate how imposing constraints not only makes the problem solvable but also how the choice of where to apply these constraints dramatically impacts the system's spectral condition number, a crucial lesson for designing robust numerical models.",
            "id": "3590165",
            "problem": "A straight, homogeneous, prismatic one-dimensional bar of length $L$, cross-sectional area $A$, and Young’s modulus $E$ is modeled under small-strain, linear elasticity with no external loads. Using two equal linear finite elements, the bar is discretized into three nodes with free–free boundary conditions. Starting from Hooke’s law $\\sigma = E \\varepsilon$ and the total potential energy $\\Pi(u) = \\frac{1}{2}\\int_{0}^{L} E A \\left(\\frac{du}{dx}\\right)^{2} dx$, derive the assembled $3 \\times 3$ global stiffness matrix $A$ for this free–free system using the standard two-node linear shape functions and element-by-element assembly. Explain why $A$ is symmetric positive semi-definite with a one-dimensional nullspace corresponding to rigid-body translation.\n\nTo remove the nullspace, impose a single displacement constraint by pinning exactly one node (i.e., enforce a Dirichlet condition $u_{p}=0$ at node $p$). Form the reduced symmetric positive definite stiffness matrix $A_{p}$ by eliminating the row and column associated with node $p$. Consider two cases: pinning an end node ($p=1$) and pinning the middle node ($p=2$). For each case, compute all eigenvalues of $A_{p}$, and from these compute the spectral condition number $\\kappa_{2}(A_{p}) = \\lambda_{\\max}(A_{p}) / \\lambda_{\\min}(A_{p})$.\n\nFinally, quantify the conditioning improvement due to the placement of the single constraint by computing the ratio\n$$\nR = \\frac{\\kappa_{2}(A_{1})}{\\kappa_{2}(A_{2})}.\n$$\nExpress $R$ exactly in simplest radical form. No rounding is required. In your derivation, clearly connect how the constraint removes the nullspace and shifts the smallest eigenvalue from zero to a positive value, and briefly comment on the implications of constraint placement for preconditioner design in iterative solvers for computational solid mechanics (for example, the Conjugate Gradient method (CG) applied to Symmetric Positive Definite (SPD) systems).",
            "solution": "The problem requires the derivation and analysis of the stiffness matrices for a one-dimensional bar under different boundary conditions. The analysis will proceed in several steps: first, the derivation of the element stiffness matrix; second, the assembly of the global stiffness matrix for the free-free system; third, the analysis of this global matrix's properties; fourth, the imposition of constraints and analysis of the resulting reduced systems; and finally, the calculation of a ratio of condition numbers and a discussion of the implications.\n\nA one-dimensional bar of length $L$ is discretized using two linear finite elements of equal length $h = L/2$. This creates three nodes located at positions $x_1=0$, $x_2=L/2$, and $x_3=L$. The corresponding axial displacements are $u_1$, $u_2$, and $u_3$.\n\nThe strain energy for a single element of length $h$ is given by $\\Pi^{(e)} = \\frac{1}{2}\\int_{0}^{h} E A \\left(\\frac{du}{dx}\\right)^{2} dx$. For a two-node linear element, the displacement field is $u(x) = N_1(x) u_i + N_2(x) u_j$, where $u_i$ and $u_j$ are the nodal displacements. The linear shape functions are $N_1(x) = 1 - x/h$ and $N_2(x) = x/h$. The strain is $\\varepsilon = \\frac{du}{dx} = \\frac{d N_1}{dx} u_i + \\frac{d N_2}{dx} u_j = -\\frac{1}{h} u_i + \\frac{1}{h} u_j$. In matrix form, $\\varepsilon = \\mathbf{B} \\mathbf{u}^{(e)}$, where the strain-displacement matrix is $\\mathbf{B} = \\frac{1}{h} \\begin{pmatrix} -1 & 1 \\end{pmatrix}$ and the nodal displacement vector is $\\mathbf{u}^{(e)} = \\begin{pmatrix} u_i \\\\ u_j \\end{pmatrix}$.\n\nThe element stiffness matrix $\\mathbf{k}^{(e)}$ is defined by the relation $\\Pi^{(e)} = \\frac{1}{2} (\\mathbf{u}^{(e)})^{T} \\mathbf{k}^{(e)} \\mathbf{u}^{(e)}$. Substituting the expression for strain, and assuming constant $E$ and $A$:\n$$\n\\Pi^{(e)} = \\frac{1}{2}\\int_{0}^{h} E A \\left( (\\mathbf{B} \\mathbf{u}^{(e)})^T (\\mathbf{B} \\mathbf{u}^{(e)}) \\right) dx = \\frac{1}{2} (\\mathbf{u}^{(e)})^{T} \\left( \\int_{0}^{h} E A \\mathbf{B}^T \\mathbf{B} dx \\right) \\mathbf{u}^{(e)}\n$$\nSince $\\mathbf{B}$, $E$, and $A$ are constant over the element, the element stiffness matrix is:\n$$\n\\mathbf{k}^{(e)} = E A h \\mathbf{B}^T \\mathbf{B} = E A h \\left( \\frac{1}{h} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} \\right) \\left( \\frac{1}{h} \\begin{pmatrix} -1 & 1 \\end{pmatrix} \\right) = \\frac{EA}{h} \\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}\n$$\nFor our problem, the two elements have length $h = L/2$. Let the constant term be $C = \\frac{EA}{h} = \\frac{EA}{L/2} = \\frac{2EA}{L}$.\nElement $1$ connects nodes $1$ and $2$, so its stiffness matrix is $\\mathbf{k}^{(1)} = C \\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}$.\nElement $2$ connects nodes $2$ and $3$, so its stiffness matrix is $\\mathbf{k}^{(2)} = C \\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}$.\n\nThe $3 \\times 3$ global stiffness matrix $A$ is assembled by summing the contributions from each element into the appropriate global degrees of freedom:\n$$\nA = \\begin{pmatrix}\nk^{(1)}_{11} & k^{(1)}_{12} & 0 \\\\\nk^{(1)}_{21} & k^{(1)}_{22} + k^{(2)}_{11} & k^{(2)}_{12} \\\\\n0 & k^{(2)}_{21} & k^{(2)}_{22}\n\\end{pmatrix}\n= C \\begin{pmatrix}\n1 & -1 & 0 \\\\\n-1 & 1+1 & -1 \\\\\n0 & -1 & 1\n\\end{pmatrix}\n= \\frac{2EA}{L} \\begin{pmatrix}\n1 & -1 & 0 \\\\\n-1 & 2 & -1 \\\\\n0 & -1 & 1\n\\end{pmatrix}\n$$\nThis is the assembled global stiffness matrix for the free-free system.\n\nThe matrix $A$ is symmetric positive semi-definite. Symmetry ($A = A^T$) is evident from its construction. It is positive semi-definite because the quadratic form $\\mathbf{u}^T A \\mathbf{u}$ represents twice the total strain energy $\\Pi$, which is $\\int_{0}^{L} E A (\\frac{du}{dx})^2 dx$. Since $E>0$ and $A>0$, this energy is always non-negative. The energy is zero if and only if the strain $\\frac{du}{dx}$ is zero everywhere. This occurs when $u(x)$ is a constant, which corresponds to a rigid-body translation of the entire bar. For the discrete system, this means $u_1=u_2=u_3=c$ for any constant $c \\neq 0$. This non-zero displacement vector $\\mathbf{u} = c \\begin{pmatrix} 1 & 1 & 1 \\end{pmatrix}^T$ results in zero energy, meaning $\\mathbf{u}^T A \\mathbf{u} = 0$. Therefore, $A$ is positive semi-definite, not positive definite. The nullspace of $A$ consists of all such vectors, and it is a one-dimensional space spanned by the vector $\\mathbf{v} = \\begin{pmatrix} 1 & 1 & 1 \\end{pmatrix}^T$. We can verify this:\n$$\nA \\mathbf{v} = \\frac{2EA}{L} \\begin{pmatrix}\n1 & -1 & 0 \\\\\n-1 & 2 & -1 \\\\\n0 & -1 & 1\n\\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\frac{2EA}{L} \\begin{pmatrix} 1-1+0 \\\\ -1+2-1 \\\\ 0-1+1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe existence of this nullspace (a zero eigenvalue) implies that $A$ is singular.\n\nTo obtain a unique solution, we must apply boundary conditions that remove the rigid-body motion. This is done by pinning a node.\n\nCase $1$: Pinning an end node, $p=1$.\nWe enforce the condition $u_1=0$. The reduced system is obtained by removing the first row and first column from $A$. The reduced stiffness matrix $A_1$ governs the remaining degrees of freedom, $u_2$ and $u_3$:\n$$\nA_1 = \\frac{2EA}{L} \\begin{pmatrix} 2 & -1 \\\\ -1 & 1 \\end{pmatrix}\n$$\nTo find the eigenvalues, let's analyze the matrix part $M_1 = \\begin{pmatrix} 2 & -1 \\\\ -1 & 1 \\end{pmatrix}$. The characteristic equation is $\\det(M_1 - \\lambda I) = 0$:\n$$\n(2-\\lambda)(1-\\lambda) - (-1)(-1) = 0 \\implies \\lambda^2 - 3\\lambda + 2 - 1 = 0 \\implies \\lambda^2 - 3\\lambda + 1 = 0\n$$\nThe roots are $\\lambda = \\frac{3 \\pm \\sqrt{9-4}}{2} = \\frac{3 \\pm \\sqrt{5}}{2}$.\nThe eigenvalues of $A_1$ are these values scaled by $C = \\frac{2EA}{L}$:\n$\\lambda_{\\min}(A_1) = \\frac{2EA}{L} \\left(\\frac{3-\\sqrt{5}}{2}\\right) = \\frac{EA}{L}(3-\\sqrt{5})$\n$\\lambda_{\\max}(A_1) = \\frac{2EA}{L} \\left(\\frac{3+\\sqrt{5}}{2}\\right) = \\frac{EA}{L}(3+\\sqrt{5})$\nBoth eigenvalues are positive, so $A_1$ is symmetric positive definite (SPD). The spectral condition number is:\n$$\n\\kappa_2(A_1) = \\frac{\\lambda_{\\max}(A_1)}{\\lambda_{\\min}(A_1)} = \\frac{3+\\sqrt{5}}{3-\\sqrt{5}} = \\frac{(3+\\sqrt{5})(3+\\sqrt{5})}{(3-\\sqrt{5})(3+\\sqrt{5})} = \\frac{9+6\\sqrt{5}+5}{9-5} = \\frac{14+6\\sqrt{5}}{4} = \\frac{7+3\\sqrt{5}}{2}\n$$\n\nCase $2$: Pinning the middle node, $p=2$.\nWe enforce $u_2=0$. The reduced system is obtained by removing the second row and second column from $A$. The reduced matrix $A_2$ governs degrees of freedom $u_1$ and $u_3$:\n$$\nA_2 = \\frac{2EA}{L} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nThis matrix is diagonal. Its eigenvalues are the diagonal entries.\n$\\lambda_1 = \\lambda_2 = \\frac{2EA}{L}$.\nThus, $\\lambda_{\\min}(A_2) = \\lambda_{\\max}(A_2) = \\frac{2EA}{L}$. Both are positive, so $A_2$ is SPD.\nThe spectral condition number is:\n$$\n\\kappa_2(A_2) = \\frac{\\lambda_{\\max}(A_2)}{\\lambda_{\\min}(A_2)} = \\frac{2EA/L}{2EA/L} = 1\n$$\n\nFinally, we compute the ratio $R$:\n$$\nR = \\frac{\\kappa_2(A_1)}{\\kappa_2(A_2)} = \\frac{\\frac{7+3\\sqrt{5}}{2}}{1} = \\frac{7+3\\sqrt{5}}{2}\n$$\n\nImplications for preconditioning in computational solid mechanics:\nThe unconstrained matrix $A$ is singular ($\\kappa_2(A)=\\infty$) due to its nullspace corresponding to rigid-body motion. Iterative solvers like the Conjugate Gradient (CG) method require a symmetric positive definite (SPD) matrix and would fail on $A$. Imposing a single displacement constraint removes the nullspace, shifting the smallest eigenvalue from $0$ to a positive value, thus making the matrix SPD and the system solvable.\n\nThis analysis demonstrates that the choice of constraint placement has a profound impact on the conditioning of the resulting system matrix. Pinning the central node ($p=2$) results in an ideally conditioned matrix with $\\kappa_2(A_2)=1$. Physically, this decouples the system into two independent bars of length $L/2$, one fixed at $x=L/2$ and free at $x=0$, the other fixed at $x=L/2$ and free at $x=L$, leading to the diagonal matrix $A_2$. An iterative solver would converge in a minimal number of iterations for such a system. Pinning an end node ($p=1$) results in a coupled system with a condition number $\\kappa_2(A_1) \\approx 6.85$, which is well-conditioned but significantly worse than the optimal case.\n\nThis simple example illustrates a crucial principle in advanced preconditioning techniques for large-scale solid mechanics, such as in domain decomposition methods (e.g., FETI, BDD). In these methods, a global \"coarse problem\" is constructed specifically to handle the nullspace modes (rigid body motions) of floating subdomains. The way these subdomains are constrained in the coarse problem is analogous to choosing the pin location in our bar problem. A well-designed coarse problem, which often involves constraining average or central degrees of freedom, leads to a much better conditioned preconditioned system, dramatically accelerating the convergence of iterative solvers. The choice of constraints is not arbitrary but a critical aspect of algorithm design for performant computational mechanics simulations.",
            "answer": "$$\n\\boxed{\\frac{7+3\\sqrt{5}}{2}}\n$$"
        },
        {
            "introduction": "Moving to a more advanced topic, this exercise tackles the challenge of strong anisotropy, a common feature in layered geomaterials or composites that renders simple iterative methods ineffective. Using Local Fourier Analysis (LFA), you will diagnose the failure of a standard point-Jacobi smoother and construct a more sophisticated line smoother that restores convergence by aligning with the problem's physics . This practice is essential for understanding the design principles behind powerful and problem-aware preconditioners like those used in algebraic multigrid (AMG) methods.",
            "id": "3552374",
            "problem": "Consider steady anisotropic diffusion in a layered geomaterial with principal permeabilities aligned to the Cartesian axes, modeled by the operator $-\\nabla \\cdot ( \\mathbf{K} \\nabla u )$ with $\\mathbf{K} = \\operatorname{diag}(K_x, K_y)$, on a rectangular domain discretized by a uniform grid with spacing $h$ in both directions. Assume periodic boundary conditions to enable Local Fourier Analysis (LFA). Let $K_x = 1$ and $K_y = \\epsilon$ with $0 < \\epsilon \\ll 1$, representing an anisotropy ratio $\\kappa = K_x/K_y = 1/\\epsilon$. Using the standard five-point finite-difference discretization, the discrete operator acting on grid function $u_{i,j}$ has the form\n$$\n(Au)_{i,j} = \\frac{1}{h^2}\\Big( 2(1+\\epsilon) u_{i,j} - u_{i-1,j} - u_{i+1,j} - \\epsilon u_{i,j-1} - \\epsilon u_{i,j+1} \\Big).\n$$\nYou will analyze smoothing for high-frequency error components and design an effective line smoother.\n\nTasks:\n1) Starting from the definition of the point-Jacobi iteration $u^{(k+1)} = u^{(k)} + D^{-1}(f - Au^{(k)})$, where $D = \\operatorname{diag}(A)$, derive the error-propagation symbol $\\tilde{S}_J(\\theta_x,\\theta_y)$ by applying $I - D^{-1}A$ to a Fourier mode $e_{i,j} = \\exp(i(\\theta_x i + \\theta_y j))$. Then evaluate the amplification factor for the high-frequency mode with wavenumbers $(\\theta_x,\\theta_y) = (0,\\pi)$. Based on your derived expression, explain its behavior as $\\epsilon \\to 0$, and state whether point-Jacobi adequately smooths this mode.\n\n2) Construct an $x$-line symmetric Gauss–Seidel (GS) smoother as follows: for each row $j$, solve exactly the tridiagonal system in the $x$-direction defined by the $x$-couplings, and sweep forward in $y$ (using newly updated row $j-1$) and then backward in $y$ (using newly updated row $j+1$). Starting from the block form of the discrete equations, derive the LFA error-amplification factor for a generic Fourier mode $e_{i,j} = \\exp(i(\\theta_x i + \\theta_y j))$ after one complete symmetric line-GS sweep. Then evaluate the amplification factor magnitude for the same high-frequency mode $(\\theta_x,\\theta_y) = (0,\\pi)$ with anisotropy ratio $\\kappa = 10^3$ (that is, $\\epsilon = 10^{-3}$). \n\nGive your final answer as the exact value of this amplification factor magnitude; no rounding is required and no units are to be included.",
            "solution": "The problem is well-posed and scientifically grounded, allowing for a complete analysis. We address the two tasks in sequence.\n\nPart 1: Analysis of the Point-Jacobi Smoother\n\nThe point-Jacobi iteration for the linear system $Au = f$ is given by $u^{(k+1)} = u^{(k)} + D^{-1}(f - Au^{(k)})$, where $D$ is the diagonal part of the matrix $A$. The error $e^{(k)} = u - u^{(k)}$ propagates according to the equation $e^{(k+1)} = (I - D^{-1}A) e^{(k)}$. The matrix $S_J = I - D^{-1}A$ is the error propagation matrix for the point-Jacobi method. To perform Local Fourier Analysis (LFA), we analyze the effect of this operator on a single Fourier mode, $e_{i,j} = \\exp(i(\\theta_x i + \\theta_y j))$, where $\\theta_x, \\theta_y \\in [-\\pi, \\pi]$ are the wavenumbers.\n\nThe discrete operator $A$ is given by\n$$\n(Au)_{i,j} = \\frac{1}{h^2}\\Big( 2(1+\\epsilon) u_{i,j} - u_{i-1,j} - u_{i+1,j} - \\epsilon u_{i,j-1} - \\epsilon u_{i,j+1} \\Big).\n$$\nApplying $A$ to the Fourier mode $e_{i,j}$ yields:\n$$\n(Ae)_{i,j} = \\frac{1}{h^2} \\Big( 2(1+\\epsilon) - \\exp(-i\\theta_x) - \\exp(i\\theta_x) - \\epsilon\\exp(-i\\theta_y) - \\epsilon\\exp(i\\theta_y) \\Big) e_{i,j}\n$$\nUsing Euler's formula, $\\exp(i\\phi) + \\exp(-i\\phi) = 2\\cos(\\phi)$, we find the symbol (eigenvalue) $\\tilde{A}(\\theta_x, \\theta_y)$ of the operator $A$:\n$$\n\\tilde{A}(\\theta_x, \\theta_y) = \\frac{1}{h^2} \\Big( 2(1+\\epsilon) - 2\\cos(\\theta_x) - 2\\epsilon\\cos(\\theta_y) \\Big) = \\frac{2}{h^2} \\Big( (1-\\cos(\\theta_x)) + \\epsilon(1-\\cos(\\theta_y)) \\Big).\n$$\nThe diagonal part of $A$, denoted by $D$, is the term that multiplies $u_{i,j}$: $(Du)_{i,j} = \\frac{2(1+\\epsilon)}{h^2} u_{i,j}$. The symbol of $D$ is thus a constant:\n$$\n\\tilde{D} = \\frac{2(1+\\epsilon)}{h^2}.\n$$\nThe error-propagation symbol for point-Jacobi, $\\tilde{S}_J(\\theta_x, \\theta_y)$, is the symbol of $I - D^{-1}A$:\n$$\n\\tilde{S}_J(\\theta_x, \\theta_y) = 1 - \\frac{\\tilde{A}(\\theta_x, \\theta_y)}{\\tilde{D}} = 1 - \\frac{\\frac{2}{h^2} \\Big( (1+\\epsilon) - \\cos(\\theta_x) - \\epsilon\\cos(\\theta_y) \\Big)}{\\frac{2(1+\\epsilon)}{h^2}}.\n$$\nSimplifying the expression, we obtain:\n$$\n\\tilde{S}_J(\\theta_x, \\theta_y) = \\frac{(1+\\epsilon) - \\Big( (1+\\epsilon) - \\cos(\\theta_x) - \\epsilon\\cos(\\theta_y) \\Big)}{1+\\epsilon} = \\frac{\\cos(\\theta_x) + \\epsilon\\cos(\\theta_y)}{1+\\epsilon}.\n$$\nNow, we evaluate this amplification factor for the high-frequency mode with wavenumbers $(\\theta_x, \\theta_y) = (0, \\pi)$. This mode is smooth in the $x$-direction and highly oscillatory in the $y$-direction.\n$$\n\\tilde{S}_J(0, \\pi) = \\frac{\\cos(0) + \\epsilon\\cos(\\pi)}{1+\\epsilon} = \\frac{1 - \\epsilon}{1+\\epsilon}.\n$$\nTo understand the effectiveness of the smoother in the limit of strong anisotropy ($\\epsilon \\to 0$), we examine the behavior of this amplification factor:\n$$\n\\lim_{\\epsilon \\to 0} \\tilde{S}_J(0, \\pi) = \\lim_{\\epsilon \\to 0} \\frac{1 - \\epsilon}{1+\\epsilon} = 1.\n$$\nAn amplification factor of $1$ indicates that the error component corresponding to this mode is not damped at all. Therefore, point-Jacobi is not an adequate smoother for this problem, as its performance degrades catastrophically for modes that are oscillatory in the direction of weak coupling.\n\nPart 2: Analysis of the $x$-line Symmetric Gauss-Seidel Smoother\n\nFor an $x$-line smoother, we group the unknowns by rows (lines). The discrete equations can be written in a block tridiagonal form, $A u = f$. The matrix $A$ can be decomposed as $A = L+D+U$, where $D$ is the block-diagonal matrix whose blocks represent the intra-line couplings, and $L$ and $U$ are the strict block lower and upper triangular matrices representing inter-line couplings.\n$$ A = \\frac{1}{h^2} \\begin{pmatrix} T_x & -\\epsilon I & & \\\\ -\\epsilon I & T_x & -\\epsilon I & \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -\\epsilon I & T_x \\end{pmatrix} $$\nHere, $T_x$ is the tridiagonal matrix for a single line, with entries $(-1, 2(1+\\epsilon), -1)$. The symbol of the operator $h^2 D$ is the symbol of $T_x$, which we denote $\\tilde{T}_x(\\theta_x)$:\n$$\n\\tilde{T}_x(\\theta_x) = 2(1+\\epsilon) - 2\\cos(\\theta_x) = 4\\sin^2(\\frac{\\theta_x}{2}) + 2\\epsilon.\n$$\nThe symbols for the LFA of the block operators $h^2L$ and $h^2U$ are denoted $\\tilde{L}'(\\theta_y)$ and $\\tilde{U}'(\\theta_y)$:\n$$\n\\tilde{L}'(\\theta_y) = -\\epsilon\\exp(-i\\theta_y), \\quad \\tilde{U}'(\\theta_y) = -\\epsilon\\exp(i\\theta_y).\n$$\nThe symmetric Gauss-Seidel (SGS) smoother consists of a forward sweep followed by a backward sweep. The error propagation operator is $S_{SGS} = (D+U)^{-1}L(D+L)^{-1}U$. The corresponding LFA symbol is:\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = (\\tilde{D}' + \\tilde{U}')^{-1} \\tilde{L}' (\\tilde{D}' + \\tilde{L}')^{-1} \\tilde{U}'.\n$$\nSubstituting the symbols for the block operators (scaled by $h^2$):\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{1}{\\tilde{T}_x(\\theta_x) - \\epsilon\\exp(i\\theta_y)} \\cdot \\big(-\\epsilon\\exp(-i\\theta_y)\\big) \\cdot \\frac{1}{\\tilde{T}_x(\\theta_x) - \\epsilon\\exp(-i\\theta_y)} \\cdot \\big(-\\epsilon\\exp(i\\theta_y)\\big).\n$$\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{\\epsilon^2}{\\big(\\tilde{T}_x(\\theta_x)-\\epsilon\\exp(i\\theta_y)\\big)\\big(\\tilde{T}_x(\\theta_x)-\\epsilon\\exp(-i\\theta_y)\\big)}.\n$$\nThe denominator is the product of a complex number and its conjugate, which results in its squared magnitude:\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{\\epsilon^2}{|\\tilde{T}_x(\\theta_x) - \\epsilon\\exp(i\\theta_y)|^2} = \\frac{\\epsilon^2}{(\\tilde{T}_x(\\theta_x) - \\epsilon\\cos(\\theta_y))^2 + (-\\epsilon\\sin(\\theta_y))^2}.\n$$\n$$\n\\tilde{S}_{SGS}(\\theta_x, \\theta_y) = \\frac{\\epsilon^2}{\\tilde{T}_x(\\theta_x)^2 - 2\\epsilon\\tilde{T}_x(\\theta_x)\\cos(\\theta_y) + \\epsilon^2}.\n$$\nWe are asked to evaluate the magnitude of this factor for the mode $(\\theta_x, \\theta_y) = (0, \\pi)$ with $\\kappa = 10^3$, which means $\\epsilon = 10^{-3}$. First, we evaluate the symbols at the specified wavenumbers.\nFor $\\theta_x = 0$:\n$$\n\\tilde{T}_x(0) = 4\\sin^2(0) + 2\\epsilon = 2\\epsilon.\n$$\nFor $\\theta_y = \\pi$:\n$$\n\\cos(\\pi) = -1.\n$$\nSubstituting these into the expression for $\\tilde{S}_{SGS}$:\n$$\n\\tilde{S}_{SGS}(0, \\pi) = \\frac{\\epsilon^2}{(2\\epsilon)^2 - 2\\epsilon(2\\epsilon)(-1) + \\epsilon^2} = \\frac{\\epsilon^2}{4\\epsilon^2 + 4\\epsilon^2 + \\epsilon^2} = \\frac{\\epsilon^2}{9\\epsilon^2} = \\frac{1}{9}.\n$$\nThis amplification factor is a real, positive constant independent of $\\epsilon$ (and thus $\\kappa$). The magnitude of the amplification factor for the mode $(0, \\pi)$ is therefore $|\\frac{1}{9}| = \\frac{1}{9}$. The specific value of $\\kappa = 10^3$ does not affect this result.",
            "answer": "$$\\boxed{\\frac{1}{9}}$$"
        }
    ]
}