{
    "hands_on_practices": [
        {
            "introduction": "To build a robust understanding of unconditional stability, we begin with a foundational exercise that derives stability properties from first principles. This practice involves analyzing the versatile generalized-α method applied to the standard Dahlquist test equation, which serves as a proxy for the behavior of more complex systems . By deriving the amplification factor and using it to determine the conditions for A-stability and L-stability, you will develop the core analytical skills needed to assess any one-step integrator and see how these scalar results extend to guarantee the stability of large-scale matrix systems.",
            "id": "3608611",
            "problem": "Consider the generalized-$\\alpha$ time integrator for first-order systems in computational solid mechanics applied to the Dahlquist test equation $ \\dot{y} = \\lambda y $ with $ \\lambda \\in \\mathbb{C} $. Let $ \\Delta t  0 $, $ z = \\lambda \\Delta t $, and the method be defined by the update and stage relations\n\n$$\ny^{n+1} = y^{n} + \\Delta t \\left[ (1 - \\gamma)\\,\\dot{y}^{n} + \\gamma\\,\\dot{y}^{n+1} \\right],\\quad\n\\dot{y}^{n+\\alpha_m} = (1 - \\alpha_m)\\,\\dot{y}^{n} + \\alpha_m\\,\\dot{y}^{n+1},\\quad\ny^{n+\\alpha_f} = (1 - \\alpha_f)\\,y^{n} + \\alpha_f\\,y^{n+1},\n$$\n\ntogether with the equilibrium at the generalized time level,\n\n$$\n\\dot{y}^{n+\\alpha_m} = \\lambda\\, y^{n+\\alpha_f}.\n$$\n\nAssume $ 0  \\alpha_f \\leq 1 $ and impose the constraint $ \\gamma = \\alpha_m $ to eliminate spurious underdetermination and ensure a one-parameter family of implicit schemes. Starting from these definitions alone (no pre-tabulated stability functions), carry out the following steps:\n\n1) Derive the scalar amplification factor $ R(z) $ defined by $ y^{n+1} = R(z)\\,y^{n} $ as an explicit rational function of $ z $ and $ \\alpha_f $ under the constraint $ \\gamma = \\alpha_m $.\n\n2) Using only the definition of $A$-stability, namely that a one-step method is $A$-stable if $ |R(z)| \\leq 1 $ for all $ z $ with $ \\operatorname{Re}(z) \\leq 0 $, determine the condition on $ \\alpha_f $ ensuring $A$-stability of the derived $ R(z) $.\n\n3) The method is called $L$-stable if it is $A$-stable and $ \\lim_{|z|\\to\\infty,\\, \\operatorname{Re}(z)0} R(z) = 0 $. Determine whether this can occur within the family obtained in step 1), and if so, at which value(s) of $ \\alpha_f $.\n\n4) Lift the scalar analysis to a matrix ordinary differential equation $ \\dot{\\mathbf{y}} = \\mathbf{A}\\,\\mathbf{y} $ with $ \\mathbf{A} \\in \\mathbb{C}^{N\\times N} $ having a Jordan decomposition with at least one defective Jordan block, and all eigenvalues $ \\lambda $ satisfying $ \\operatorname{Re}(\\lambda)  0 $. Show, starting from the functional calculus for Jordan blocks, that unconditional stability (asymptotic decay $ \\mathbf{y}^{n} \\to \\mathbf{0} $ as $ n \\to \\infty $ for any fixed $ \\Delta t  0 $) follows under the same condition on $ \\alpha_f $ you obtained in step 2), even in the presence of nilpotent parts.\n\nYour final task is to compute, in exact closed form, the high-frequency amplification factor (also called the spectral radius at infinity)\n\n$$\n\\rho_{\\infty} \\equiv \\lim_{|z|\\to\\infty,\\, \\operatorname{Re}(z)0} \\big|R(z)\\big|\n$$\n\nfor the family defined by $ \\gamma = \\alpha_m $; express $ \\rho_{\\infty} $ purely in terms of $ \\alpha_f $. Provide this $ \\rho_{\\infty} $ as your final answer. No rounding is required, and no units are involved.",
            "solution": "The problem is subjected to validation and is deemed valid. It is scientifically grounded in the theory of numerical methods for ordinary differential equations, well-posed, objective, and contains no discernible flaws. The solution proceeds as follows.\n\nThe problem asks for an analysis of the generalized-$\\alpha$ method for first-order systems, subject to the constraint $\\gamma = \\alpha_m$. The analysis proceeds in several steps, culminating in the calculation of the high-frequency amplification factor $\\rho_{\\infty}$.\n\n**1) Derivation of the Amplification Factor $R(z)$**\n\nThe method is defined by the following set of equations applied to the Dahlquist test equation $\\dot{y} = \\lambda y$:\n1. Update rule: $y^{n+1} = y^{n} + \\Delta t [ (1 - \\gamma)\\,\\dot{y}^{n} + \\gamma\\,\\dot{y}^{n+1} ]$\n2. Stage value for the derivative: $\\dot{y}^{n+\\alpha_m} = (1 - \\alpha_m)\\,\\dot{y}^{n} + \\alpha_m\\,\\dot{y}^{n+1}$\n3. Stage value for the solution: $y^{n+\\alpha_f} = (1 - \\alpha_f)\\,y^{n} + \\alpha_f\\,y^{n+1}$\n4. Equilibrium at the intermediate point: $\\dot{y}^{n+\\alpha_m} = \\lambda\\, y^{n+\\alpha_f}$\n\nWe begin by substituting the stage values (2) and (3) into the equilibrium equation (4):\n$$\n(1 - \\alpha_m)\\,\\dot{y}^{n} + \\alpha_m\\,\\dot{y}^{n+1} = \\lambda [ (1 - \\alpha_f)\\,y^{n} + \\alpha_f\\,y^{n+1} ]\n$$\nFor the test equation, we have $\\dot{y}^n = \\lambda y^n$. Substituting this into the equation above, we obtain an equation relating the unknowns $y^{n+1}$ and $\\dot{y}^{n+1}$ to the known value $y^n$:\n$$\n(1 - \\alpha_m)\\,\\lambda y^{n} + \\alpha_m\\,\\dot{y}^{n+1} = \\lambda (1 - \\alpha_f)\\,y^{n} + \\lambda \\alpha_f\\,y^{n+1}\n$$\nRearranging to group unknowns on one side:\n$$\n\\alpha_m\\,\\dot{y}^{n+1} - \\lambda \\alpha_f\\,y^{n+1} = \\lambda (1 - \\alpha_f - (1 - \\alpha_m))\\,y^{n} = \\lambda (\\alpha_m - \\alpha_f)\\,y^{n}\n$$\nThis is our first equation for the unknowns. The second is the update rule (1). Let's use the definition $z = \\lambda \\Delta t$ and substitute $\\dot{y}^n = \\lambda y^n = (z/\\Delta t) y^n$:\n$$\ny^{n+1} = y^{n} + \\Delta t (1 - \\gamma)\\,\\lambda y^{n} + \\Delta t \\gamma\\,\\dot{y}^{n+1} = (1 + (1-\\gamma)z)y^n + \\gamma \\Delta t \\dot{y}^{n+1}\n$$\nRearranging this second equation:\n$$\n-y^{n+1} + \\gamma \\Delta t \\dot{y}^{n+1} = -(1 + (1-\\gamma)z)y^n\n$$\nWe now have a $2 \\times 2$ linear system for $\\dot{y}^{n+1}$ and $y^{n+1}$:\n$$\n\\begin{cases}\n\\alpha_m\\,\\dot{y}^{n+1} - \\lambda \\alpha_f\\,y^{n+1} = \\lambda (\\alpha_m - \\alpha_f)\\,y^{n} \\\\\n\\gamma \\Delta t \\dot{y}^{n+1} - y^{n+1} = -(1 + (1-\\gamma)z)y^n\n\\end{cases}\n$$\nWe seek $y^{n+1} = R(z)y^n$, so we eliminate $\\dot{y}^{n+1}$. Multiply the first equation by $\\gamma \\Delta t$ and the second by $\\alpha_m$:\n$$\n\\begin{cases}\n\\alpha_m \\gamma \\Delta t\\,\\dot{y}^{n+1} - \\lambda \\alpha_f \\gamma \\Delta t\\,y^{n+1} = \\lambda (\\alpha_m - \\alpha_f) \\gamma \\Delta t\\,y^{n} \\\\\n\\alpha_m \\gamma \\Delta t \\dot{y}^{n+1} - \\alpha_m y^{n+1} = -\\alpha_m(1 + (1-\\gamma)z)y^n\n\\end{cases}\n$$\nSubtracting the second equation from the first yields:\n$$\n(-\\lambda \\alpha_f \\gamma \\Delta t + \\alpha_m) y^{n+1} = [\\lambda (\\alpha_m - \\alpha_f) \\gamma \\Delta t + \\alpha_m(1 + (1-\\gamma)z)] y^n\n$$\nUsing $z = \\lambda \\Delta t$:\n$$\n(-\\alpha_f \\gamma z + \\alpha_m) y^{n+1} = [(\\alpha_m - \\alpha_f) \\gamma z + \\alpha_m + \\alpha_m(1-\\gamma)z] y^n\n$$\n$$\n(\\alpha_m - \\alpha_f \\gamma z) y^{n+1} = [\\alpha_m + (\\alpha_m \\gamma - \\alpha_f \\gamma + \\alpha_m - \\alpha_m \\gamma)z] y^n\n$$\n$$\n(\\alpha_m - \\alpha_f \\gamma z) y^{n+1} = [\\alpha_m + (\\alpha_m - \\alpha_f \\gamma)z] y^n\n$$\nThe amplification factor is therefore $R(z) = \\frac{\\alpha_m + (\\alpha_m - \\alpha_f \\gamma)z}{\\alpha_m - \\alpha_f \\gamma z}$.\nNow, we apply the constraint $\\gamma = \\alpha_m$:\n$$\nR(z) = \\frac{\\alpha_m + (\\alpha_m - \\alpha_f \\alpha_m)z}{\\alpha_m - \\alpha_f \\alpha_m z} = \\frac{\\alpha_m(1 + (1-\\alpha_f)z)}{\\alpha_m(1 - \\alpha_f z)} = \\frac{1 + (1-\\alpha_f)z}{1 - \\alpha_f z}\n$$\n\n**2) A-stability Analysis**\n\nA method is A-stable if its stability region includes the entire left half-plane of complex numbers, i.e., $|R(z)| \\le 1$ for all $z \\in \\mathbb{C}$ with $\\operatorname{Re}(z) \\le 0$. Since $R(z)$ is a rational function analytic in $\\operatorname{Re}(z) \\le 0$ (its pole is at $z_p = 1/\\alpha_f$, which is on the positive real axis since $\\alpha_f  0$), the maximum modulus principle allows us to check the condition on the boundary of the domain, i.e., for $z = i\\omega$ where $\\omega \\in \\mathbb{R}$.\n$$\n|R(i\\omega)|^2 = \\left| \\frac{1 + (1-\\alpha_f)i\\omega}{1 - \\alpha_f i\\omega} \\right|^2 = \\frac{|1 + (1-\\alpha_f)i\\omega|^2}{|1 - \\alpha_f i\\omega|^2} = \\frac{1^2 + (1-\\alpha_f)^2\\omega^2}{1^2 + (-\\alpha_f)^2\\omega^2} = \\frac{1 + (1-\\alpha_f)^2\\omega^2}{1 + \\alpha_f^2\\omega^2}\n$$\nThe condition $|R(i\\omega)|^2 \\le 1$ translates to:\n$$\n\\frac{1 + (1-\\alpha_f)^2\\omega^2}{1 + \\alpha_f^2\\omega^2} \\le 1\n$$\nSince $1 + \\alpha_f^2\\omega^2  0$, we can multiply both sides by it:\n$$\n1 + (1-\\alpha_f)^2\\omega^2 \\le 1 + \\alpha_f^2\\omega^2 \\implies (1-\\alpha_f)^2\\omega^2 \\le \\alpha_f^2\\omega^2\n$$\nThis inequality must hold for all $\\omega \\in \\mathbb{R}$. This is true if and only if $(1-\\alpha_f)^2 \\le \\alpha_f^2$.\n$$\n1 - 2\\alpha_f + \\alpha_f^2 \\le \\alpha_f^2 \\implies 1 - 2\\alpha_f \\le 0 \\implies 1 \\le 2\\alpha_f \\implies \\alpha_f \\ge \\frac{1}{2}\n$$\nGiven the problem constraint $0  \\alpha_f \\le 1$, the condition for A-stability is $\\frac{1}{2} \\le \\alpha_f \\le 1$.\n\n**3) L-stability Analysis**\n\nA method is L-stable if it is A-stable and, additionally, the amplification factor vanishes at infinity in the left half-plane: $\\lim_{|z|\\to\\infty, \\operatorname{Re}(z)0} R(z) = 0$.\nLet's compute this limit for the derived $R(z)$:\n$$\n\\lim_{|z|\\to\\infty} R(z) = \\lim_{|z|\\to\\infty} \\frac{1 + (1-\\alpha_f)z}{1 - \\alpha_f z} = \\lim_{|z|\\to\\infty} \\frac{1/z + (1-\\alpha_f)}{1/z - \\alpha_f} = \\frac{1-\\alpha_f}{-\\alpha_f} = \\frac{\\alpha_f - 1}{\\alpha_f}\n$$\nFor L-stability, this limit must be zero.\n$$\n\\frac{\\alpha_f-1}{\\alpha_f} = 0 \\implies \\alpha_f-1 = 0 \\implies \\alpha_f = 1\n$$\nThis value lies within the A-stability range $[\\frac{1}{2}, 1]$. Thus, the method is L-stable if and only if $\\alpha_f = 1$. In this case, $R(z) = (1-z)^{-1}$, which is the amplification factor for the backward Euler method, known to be L-stable.\n\n**4) Unconditional Stability for Matrix Systems**\n\nFor a linear system $\\dot{\\mathbf{y}} = \\mathbf{A}\\,\\mathbf{y}$, the numerical scheme can be written as $\\mathbf{y}^{n+1} = R(\\mathbf{A}\\Delta t)\\mathbf{y}^n$, where $R(\\mathbf{A}\\Delta t)$ is the matrix amplification operator, defined through a functional calculus. Let $\\mathbf{z} = \\mathbf{A}\\Delta t$.\n$$\nR(\\mathbf{z}) = (I + (1-\\alpha_f)\\mathbf{z})(I - \\alpha_f \\mathbf{z})^{-1}\n$$\nThe asymptotic behavior of the solution, $\\mathbf{y}^n \\to \\mathbf{0}$ as $n \\to \\infty$, is governed by the spectral radius of the amplification matrix, $\\rho(R(\\mathbf{z}))$. Unconditional stability requires $\\rho(R(\\mathbf{z}))  1$ for any choice of time step $\\Delta t  0$.\n\nLet $\\mathbf{A} = \\mathbf{PJP}^{-1}$ be the Jordan normal form of $\\mathbf{A}$, where $\\mathbf{J}$ is a block-diagonal matrix of Jordan blocks $J_k$. Then $\\mathbf{z} = \\mathbf{P}(\\mathbf{J}\\Delta t)\\mathbf{P}^{-1}$. The amplification matrix is $R(\\mathbf{z}) = \\mathbf{P}R(\\mathbf{J}\\Delta t)\\mathbf{P}^{-1}$.\nThe spectral radius is invariant under similarity transformations, so $\\rho(R(\\mathbf{z})) = \\rho(R(\\mathbf{J}\\Delta t))$. Since $R(\\mathbf{J}\\Delta t)$ is block-diagonal, its spectral radius is the maximum of the spectral radii of its diagonal blocks, $R(J_k \\Delta t)$.\nEach matrix $J_k \\Delta t$ corresponds to an eigenvalue $\\lambda_k$ of $\\mathbf{A}$ and is upper triangular. The matrix function $R(J_k \\Delta t)$ is also upper triangular, and its diagonal entries (which are its eigenvalues) are all equal to $R(\\lambda_k \\Delta t)$. Therefore, the spectral radius of each block is $\\rho(R(J_k \\Delta t)) = |R(\\lambda_k \\Delta t)|$.\nThe overall spectral radius is $\\rho(R(\\mathbf{z})) = \\max_k |R(\\lambda_k \\Delta t)|$.\n\nThe problem states that all eigenvalues $\\lambda_k$ of $\\mathbf{A}$ satisfy $\\operatorname{Re}(\\lambda_k)  0$. Since $\\Delta t  0$, this means $\\operatorname{Re}(\\lambda_k \\Delta t)  0$.\nIn the A-stability analysis, we found that for $\\alpha_f \\ge 1/2$, we have $|R(z)| \\le 1$ for $\\operatorname{Re}(z) \\le 0$. A closer look at the derivation reveals that strict inequality holds when $\\operatorname{Re}(z)  0$.\nSpecifically, we showed that $|R(z)|^2  1$ is equivalent to $2x + (1-2\\alpha_f)(x^2+\\omega^2)  0$ for $z=x+i\\omega$. For $\\alpha_f \\ge 1/2$, we have $1-2\\alpha_f \\le 0$. For $x = \\operatorname{Re}(z)  0$, both terms $2x$ and $(1-2\\alpha_f)(x^2+\\omega^2)$ are non-positive, and their sum is strictly negative (unless $z=0$, which is excluded by $\\operatorname{Re}(z)0$).\nThus, for all eigenvalues $\\lambda_k$ of $\\mathbf{A}$, we have $\\operatorname{Re}(\\lambda_k \\Delta t)  0$, which implies $|R(\\lambda_k \\Delta t)|  1$.\nConsequently, $\\rho(R(\\mathbf{z})) = \\max_k |R(\\lambda_k \\Delta t)|  1$.\n\nA well-known result from matrix theory states that if the spectral radius of a matrix $\\mathbf{M}$ is less than $1$, then $\\lim_{n \\to \\infty} \\mathbf{M}^n = \\mathbf{0}$. Since $\\mathbf{y}^n = (R(\\mathbf{z}))^n \\mathbf{y}^0$, it follows that $\\mathbf{y}^n \\to \\mathbf{0}$ as $n \\to \\infty$. This holds for any $\\Delta t  0$, which is the definition of unconditional stability. The presence of defective Jordan blocks (nilpotent parts) does not alter this conclusion, as the asymptotic convergence is determined solely by the spectral radius being strictly less than one. This stability holds under the same condition as A-stability, $\\alpha_f \\ge 1/2$.\n\n**5) Computation of the High-Frequency Amplification Factor $\\rho_{\\infty}$**\n\nThe final task is to compute the high-frequency amplification factor, defined as $\\rho_{\\infty} \\equiv \\lim_{|z|\\to\\infty, \\operatorname{Re}(z)0} |R(z)|$.\nFrom part (3), we already computed the limit of the function $R(z)$:\n$$\n\\lim_{|z|\\to\\infty} R(z) = \\frac{\\alpha_f - 1}{\\alpha_f}\n$$\nThe limit of the magnitude is the magnitude of the limit:\n$$\n\\rho_{\\infty} = \\left| \\lim_{|z|\\to\\infty} R(z) \\right| = \\left| \\frac{\\alpha_f - 1}{\\alpha_f} \\right|\n$$\nThe problem specifies the constraint $0  \\alpha_f \\le 1$. Within this interval:\n- The denominator $\\alpha_f$ is positive.\n- The numerator $\\alpha_f - 1$ is non-positive (it is zero for $\\alpha_f=1$ and negative for $0  \\alpha_f  1$).\nTherefore, the fraction $\\frac{\\alpha_f - 1}{\\alpha_f}$ is non-positive. Its absolute value is:\n$$\n\\rho_{\\infty} = -\\left( \\frac{\\alpha_f - 1}{\\alpha_f} \\right) = \\frac{1 - \\alpha_f}{\\alpha_f}\n$$\nThis is the final expression for the high-frequency amplification factor in terms of $\\alpha_f$.",
            "answer": "$$\n\\boxed{\\frac{1 - \\alpha_f}{\\alpha_f}}\n$$"
        },
        {
            "introduction": "Having established the theoretical tools for stability analysis, we now apply them to a concrete problem from computational solid mechanics. This exercise examines the time integration of a stiff viscoelastic constitutive model, a common scenario where different physical processes occur on vastly different timescales . By analyzing the popular $\\theta$-method, you will discover how the specific choice of the integrator parameter leads to L-stability, a crucial property for ensuring that stiff, unresolved dynamics are numerically damped out, preventing spurious oscillations and ensuring a robust simulation.",
            "id": "3608579",
            "problem": "Consider a small-strain, linear viscoelastic solid governed by the relaxation-type constitutive ordinary differential equation (ODE)\n$$\n\\dot{\\boldsymbol{\\sigma}}(t) + \\frac{1}{\\tau}\\,\\boldsymbol{\\sigma}(t) = \\frac{E}{\\tau}\\,\\boldsymbol{\\varepsilon}(t),\n$$\nwhere $\\boldsymbol{\\sigma}(t)$ is the Cauchy stress tensor, $\\boldsymbol{\\varepsilon}(t)$ is the strain tensor, $E0$ is the elastic modulus, and $\\tau0$ is the relaxation time. This ODE represents exponential relaxation of $\\boldsymbol{\\sigma}(t)$ toward the instantaneous elastic stress $E\\,\\boldsymbol{\\varepsilon}(t)$.\n\nYou will analyze the unconditional stability properties of an implicit one-parameter time integrator (the generalized midpoint or $\\theta$-method) for advancing the stress over a single time step $[t_n, t_{n+1}]$ of size $\\Delta t = t_{n+1}-t_n$. The method evaluates the right-hand side at the convex combination $t_{n+\\theta} = t_n + \\theta \\Delta t$ with $0 \\le \\theta \\le 1$, and uses\n$$\n\\boldsymbol{\\sigma}_{n+1} = \\boldsymbol{\\sigma}_n + \\Delta t\\left(-\\frac{1}{\\tau}\\,\\boldsymbol{\\sigma}_{n+\\theta} + \\frac{E}{\\tau}\\,\\boldsymbol{\\varepsilon}_{n+\\theta}\\right),\n$$\nwith $\\boldsymbol{\\sigma}_{n+\\theta} = (1-\\theta)\\boldsymbol{\\sigma}_n + \\theta\\boldsymbol{\\sigma}_{n+1}$ and $\\boldsymbol{\\varepsilon}_{n+\\theta} = (1-\\theta)\\boldsymbol{\\varepsilon}_n + \\theta\\boldsymbol{\\varepsilon}_{n+1}$.\n\nStarting from the given ODE and this implicit discretization, perform the following steps:\n\n1. Derive the closed-form update relating $\\boldsymbol{\\sigma}_{n+1}$ to $\\boldsymbol{\\sigma}_n$, $\\boldsymbol{\\varepsilon}_n$, and $\\boldsymbol{\\varepsilon}_{n+1}$, and then subtract the instantaneous elastic stress to obtain a homogeneous recurrence in terms of the relaxation residual $\\boldsymbol{r}_n := \\boldsymbol{\\sigma}_n - E\\,\\boldsymbol{\\varepsilon}_n$.\n\n2. Show that the residual obeys a linear one-step relation of the form $\\boldsymbol{r}_{n+1} = R_{\\theta}(z)\\,\\boldsymbol{r}_n$ when the strain is held constant over the step, where $z := \\Delta t/\\tau$ and $R_{\\theta}(z)$ is the scalar stability function for the stiff decay mode.\n\n3. Using the definition of absolute stability (A-stability), and the criterion for limit-stability (L-stability) that $R_{\\theta}(z) \\to 0$ as $z \\to \\infty$, determine the unique value of $\\theta \\in [0,1]$ for which the method is L-stable. Your final answer must be this value of $\\theta$ as a single real number. No rounding is required and no units should be reported.\n\nAssume small strains and linear material behavior throughout, and that all tensor components decouple for this scalar analysis of the stability function. Define ordinary differential equation (ODE) and absolute stability (A-stability) on their first use as done above; interpret limit-stability (L-stability) as the property that the stability function tends to zero in the infinite stiffness limit $z\\to\\infty$.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is based on standard principles of computational solid mechanics and numerical analysis. All necessary information is provided, and the task is to derive a specific result using a clearly defined procedure.\n\nThe solution proceeds in three steps as requested by the problem statement.\n\n**Step 1: Derivation of the homogeneous recurrence for the relaxation residual.**\n\nThe time-discretized form of the constitutive ordinary differential equation (ODE) using the generalized midpoint rule, or $\\theta$-method, is given as\n$$\n\\boldsymbol{\\sigma}_{n+1} = \\boldsymbol{\\sigma}_n + \\Delta t\\left(-\\frac{1}{\\tau}\\,\\boldsymbol{\\sigma}_{n+\\theta} + \\frac{E}{\\tau}\\,\\boldsymbol{\\varepsilon}_{n+\\theta}\\right)\n$$\nwhere $\\boldsymbol{\\sigma}_{n+\\theta} = (1-\\theta)\\boldsymbol{\\sigma}_n + \\theta\\boldsymbol{\\sigma}_{n+1}$ and $\\boldsymbol{\\varepsilon}_{n+\\theta} = (1-\\theta)\\boldsymbol{\\varepsilon}_n + \\theta\\boldsymbol{\\varepsilon}_{n+1}$. The parameter $\\theta$ is in the range $0 \\le \\theta \\le 1$.\n\nFirst, we substitute the expression for $\\boldsymbol{\\sigma}_{n+\\theta}$ into the integrator equation to obtain an implicit equation for $\\boldsymbol{\\sigma}_{n+1}$:\n$$\n\\boldsymbol{\\sigma}_{n+1} = \\boldsymbol{\\sigma}_n - \\frac{\\Delta t}{\\tau} \\left[ (1-\\theta)\\boldsymbol{\\sigma}_n + \\theta \\boldsymbol{\\sigma}_{n+1} \\right] + \\frac{E \\Delta t}{\\tau} \\boldsymbol{\\varepsilon}_{n+\\theta}\n$$\nWe rearrange the terms to solve for $\\boldsymbol{\\sigma}_{n+1}$ by grouping all $\\boldsymbol{\\sigma}_{n+1}$ terms on the left-hand side:\n$$\n\\boldsymbol{\\sigma}_{n+1} + \\frac{\\theta \\Delta t}{\\tau} \\boldsymbol{\\sigma}_{n+1} = \\boldsymbol{\\sigma}_n - \\frac{(1-\\theta) \\Delta t}{\\tau} \\boldsymbol{\\sigma}_n + \\frac{E \\Delta t}{\\tau} \\boldsymbol{\\varepsilon}_{n+\\theta}\n$$\nFactoring out $\\boldsymbol{\\sigma}_{n+1}$ on the left and $\\boldsymbol{\\sigma}_n$ on the right, we get:\n$$\n\\left(1 + \\frac{\\theta \\Delta t}{\\tau}\\right) \\boldsymbol{\\sigma}_{n+1} = \\left(1 - \\frac{(1-\\theta) \\Delta t}{\\tau}\\right) \\boldsymbol{\\sigma}_n + \\frac{E \\Delta t}{\\tau} \\boldsymbol{\\varepsilon}_{n+\\theta}\n$$\nLet's introduce the dimensionless time step $z := \\Delta t / \\tau$. The equation becomes:\n$$\n(1 + \\theta z) \\boldsymbol{\\sigma}_{n+1} = (1 - (1-\\theta) z) \\boldsymbol{\\sigma}_n + E z \\left[(1-\\theta)\\boldsymbol{\\varepsilon}_n + \\theta\\boldsymbol{\\varepsilon}_{n+1}\\right]\n$$\nSolving for $\\boldsymbol{\\sigma}_{n+1}$ yields the closed-form update:\n$$\n\\boldsymbol{\\sigma}_{n+1} = \\frac{1 - (1-\\theta) z}{1 + \\theta z} \\boldsymbol{\\sigma}_n + \\frac{E z}{1 + \\theta z} \\left[(1-\\theta)\\boldsymbol{\\varepsilon}_n + \\theta\\boldsymbol{\\varepsilon}_{n+1}\\right]\n$$\nNext, we introduce the relaxation residual $\\boldsymbol{r}_n := \\boldsymbol{\\sigma}_n - E\\,\\boldsymbol{\\varepsilon}_n$. From this definition, we have $\\boldsymbol{\\sigma}_n = \\boldsymbol{r}_n + E\\,\\boldsymbol{\\varepsilon}_n$ and $\\boldsymbol{\\sigma}_{n+1} = \\boldsymbol{r}_{n+1} + E\\,\\boldsymbol{\\varepsilon}_{n+1}$. Substituting these into the update rule for $\\boldsymbol{\\sigma}_{n+1}$:\n$$\n\\boldsymbol{r}_{n+1} + E\\,\\boldsymbol{\\varepsilon}_{n+1} = \\frac{1 - (1-\\theta) z}{1 + \\theta z} (\\boldsymbol{r}_n + E\\,\\boldsymbol{\\varepsilon}_n) + \\frac{E z}{1 + \\theta z} \\left[(1-\\theta)\\boldsymbol{\\varepsilon}_n + \\theta\\boldsymbol{\\varepsilon}_{n+1}\\right]\n$$\nIsolating $\\boldsymbol{r}_{n+1}$ gives:\n$$\n\\boldsymbol{r}_{n+1} = \\frac{1 - (1-\\theta) z}{1 + \\theta z} \\boldsymbol{r}_n + \\frac{1 - (1-\\theta) z}{1 + \\theta z} E\\,\\boldsymbol{\\varepsilon}_n + \\frac{E z \\left[(1-\\theta)\\boldsymbol{\\varepsilon}_n + \\theta\\boldsymbol{\\varepsilon}_{n+1}\\right]}{1 + \\theta z} - E\\,\\boldsymbol{\\varepsilon}_{n+1}\n$$\nWe collect the terms multiplying $E$ and put them over a common denominator $1 + \\theta z$:\n$$\n\\boldsymbol{r}_{n+1} = \\frac{1 - (1-\\theta) z}{1 + \\theta z} \\boldsymbol{r}_n + \\frac{E}{1 + \\theta z} \\left\\{ [1 - (1-\\theta)z]\\boldsymbol{\\varepsilon}_n + z[(1-\\theta)\\boldsymbol{\\varepsilon}_n + \\theta\\boldsymbol{\\varepsilon}_{n+1}] - (1+\\theta z)\\boldsymbol{\\varepsilon}_{n+1} \\right\\}\n$$\nNow, we simplify the expression inside the curly braces by grouping terms with $\\boldsymbol{\\varepsilon}_n$ and $\\boldsymbol{\\varepsilon}_{n+1}$:\n$$\n\\{ [1 - z + \\theta z + z - \\theta z]\\boldsymbol{\\varepsilon}_n + [\\theta z - (1 + \\theta z)]\\boldsymbol{\\varepsilon}_{n+1} \\} = \\{ (1)\\boldsymbol{\\varepsilon}_n + (\\theta z - 1 - \\theta z)\\boldsymbol{\\varepsilon}_{n+1} \\} = \\boldsymbol{\\varepsilon}_n - \\boldsymbol{\\varepsilon}_{n+1}\n$$\nThus, the recurrence relation for the residual is:\n$$\n\\boldsymbol{r}_{n+1} = \\frac{1 - (1-\\theta) z}{1 + \\theta z} \\boldsymbol{r}_n + \\frac{E}{1 + \\theta z} (\\boldsymbol{\\varepsilon}_n - \\boldsymbol{\\varepsilon}_{n+1})\n$$\n\n**Step 2: Derivation of the stability function.**\n\nTo analyze the stability of the decay mode, we consider the case where the strain is held constant over the time step, i.e., $\\boldsymbol{\\varepsilon}_n = \\boldsymbol{\\varepsilon}_{n+1}$. In this situation, the forcing term $\\frac{E}{1 + \\theta z} (\\boldsymbol{\\varepsilon}_n - \\boldsymbol{\\varepsilon}_{n+1})$ becomes zero. The recurrence for the residual $\\boldsymbol{r}_n$ becomes homogeneous:\n$$\n\\boldsymbol{r}_{n+1} = \\left( \\frac{1 - (1-\\theta) z}{1 + \\theta z} \\right) \\boldsymbol{r}_n\n$$\nThis is of the form $\\boldsymbol{r}_{n+1} = R_{\\theta}(z)\\,\\boldsymbol{r}_n$, where $R_{\\theta}(z)$ is the scalar stability function:\n$$\nR_{\\theta}(z) = \\frac{1 - (1-\\theta) z}{1 + \\theta z}\n$$\n\n**Step 3: Determination of $\\theta$ for L-stability.**\n\nThe method is defined as A-stable (absolute stability) if $|R_{\\theta}(z)| \\le 1$ for all $z \\ge 0$. This condition ensures that the numerical solution does not grow for a stable physical system, regardless of the time step size. A-stability for the $\\theta$-method applied to this problem holds for $\\theta \\in [1/2, 1]$.\n\nA stronger condition is L-stability (limit-stability), which requires that in the limit of an infinitely stiff system (i.e., infinite decay rate or $z = \\Delta t/\\tau \\to \\infty$), the numerical amplification factor vanishes. This is a desirable property as it ensures that very fast, stiff dynamics are damped out completely in a single large time step. The mathematical condition is:\n$$\n\\lim_{z \\to \\infty} R_{\\theta}(z) = 0\n$$\nWe compute this limit for the derived stability function:\n$$\n\\lim_{z \\to \\infty} R_{\\theta}(z) = \\lim_{z \\to \\infty} \\frac{1 - (1-\\theta) z}{1 + \\theta z}\n$$\nTo evaluate the limit of this rational function of $z$, we divide both the numerator and the denominator by the highest power of $z$, which is $z^1$:\n$$\n\\lim_{z \\to \\infty} \\frac{\\frac{1}{z} - (1-\\theta)}{\\frac{1}{z} + \\theta}\n$$\nAs $z \\to \\infty$, the term $1/z$ approaches $0$. The limit becomes:\n$$\n\\frac{0 - (1-\\theta)}{0 + \\theta} = \\frac{-(1-\\theta)}{\\theta} = \\frac{\\theta - 1}{\\theta}\n$$\nFor L-stability, this limit must be equal to $0$:\n$$\n\\frac{\\theta - 1}{\\theta} = 0\n$$\nThis equation is satisfied if and only if the numerator is zero, which means $\\theta - 1 = 0$. This gives the unique solution $\\theta=1$. This value lies within the prescribed range $\\theta \\in [0, 1]$. This choice of $\\theta=1$ corresponds to the backward Euler integration scheme, which is known to be L-stable.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Unconditional stability guarantees that a numerical solution will not grow without bound, but does it imply that the system's energy must always decrease? This practice addresses that crucial question by presenting a revealing counterexample using the A-stable trapezoidal rule . By analyzing a simple damped oscillator, you will demonstrate that even for a stable method, the discrete energy can experience transient growth, highlighting the important distinction between long-term asymptotic stability and monotonic, per-step dissipation.",
            "id": "3608634",
            "problem": "A single-degree-of-freedom linear elastic oscillator with viscous damping, representative of a small-strain linear solid, satisfies Newton’s second law\n$$\nm\\,\\ddot{x}(t) + c\\,\\dot{x}(t) + k\\,x(t) = 0,\n$$\nwith displacement $x(t)$, velocity $v(t) = \\dot{x}(t)$, mass $m0$, damping $c \\ge 0$, and stiffness $k0$. Introduce the first-order state $y(t) = \\begin{pmatrix} x(t) \\\\ v(t) \\end{pmatrix}$, so that\n$$\n\\dot{y}(t) = A\\,y(t), \\quad A = \\begin{pmatrix} 0  1 \\\\ -\\frac{k}{m}  -\\frac{c}{m} \\end{pmatrix}.\n$$\nConsider the trapezoidal rule (also known as the Crank–Nicolson method or the implicit midpoint rule for linear systems) with time step $\\Delta t  0$,\n$$\ny^{n+1} = y^{n} + \\frac{\\Delta t}{2}\\left(A\\,y^{n} + A\\,y^{n+1}\\right),\n$$\nwhich defines the one-step amplification matrix $G(\\Delta t)$ via\n$$\ny^{n+1} = G(\\Delta t)\\,y^{n}, \\quad G(\\Delta t) = \\left(I - \\frac{\\Delta t}{2}A\\right)^{-1}\\left(I + \\frac{\\Delta t}{2}A\\right).\n$$\nIt is a well-known result from the definition of $A$-stability (absolute stability) that the trapezoidal rule is $A$-stable, meaning its scalar stability function maps the open left-half complex plane into the closed unit disk.\n\nDespite $A$-stability, monotone decay in a given norm (or “energy-like” quadratic functional) is not guaranteed for discrete trajectories. To exhibit this, consider the oscillator with parameters $m = 1$, $c = 10$, $k = 100$, and the time step $\\Delta t = 0.3$. Define the quadratic energy-like functional\n$$\nE_{\\mathrm{euc}}(y) = \\frac{1}{2}\\,y^{\\top} y,\n$$\nwhich corresponds to the Euclidean norm squared.\n\nStarting only from the governing equation, the state-space form, and the trapezoidal rule definition, derive $G(\\Delta t)$ for the given parameters, and then compute the maximal one-step amplification factor of $E_{\\mathrm{euc}}$ under the trapezoidal update, namely\n$$\n\\alpha_{\\max} = \\max_{y \\neq 0}\\frac{E_{\\mathrm{euc}}(y^{n+1})}{E_{\\mathrm{euc}}(y^{n})}.\n$$\nYour derivation must proceed from these fundamentals and must not assume any pre-tabulated energy estimates. Express the final answer as a dimensionless number. Round your answer to four significant figures.",
            "solution": "The problem asks for the maximal one-step amplification factor, $\\alpha_{\\max}$, of the quadratic functional $E_{\\mathrm{euc}}(y) = \\frac{1}{2}y^{\\top}y$ for a linear oscillator discretized by the trapezoidal rule. The parameters are given as mass $m = 1$, damping $c = 10$, stiffness $k = 100$, and time step $\\Delta t = 0.3$.\n\nThe one-step update is given by $y^{n+1} = G(\\Delta t)y^{n}$. The ratio of the energy-like functional between consecutive steps is\n$$\n\\frac{E_{\\mathrm{euc}}(y^{n+1})}{E_{\\mathrm{euc}}(y^{n})} = \\frac{\\frac{1}{2}(y^{n+1})^{\\top}y^{n+1}}{\\frac{1}{2}(y^{n})^{\\top}y^{n}} = \\frac{(G y^{n})^{\\top}(G y^{n})}{(y^{n})^{\\top}y^{n}} = \\frac{(y^{n})^{\\top}G^{\\top}G y^{n}}{(y^{n})^{\\top}y^{n}}.\n$$\nThe quantity to be computed, $\\alpha_{\\max}$, is the maximum value of this ratio over all non-zero state vectors $y^{n}$. This maximum corresponds to the maximum of the Rayleigh quotient for the matrix $G^{\\top}G$. The maximum value of the Rayleigh quotient is the largest eigenvalue of the matrix. Therefore,\n$$\n\\alpha_{\\max} = \\lambda_{\\max}(G^{\\top}G).\n$$\nThe eigenvalues $\\lambda$ of a $2 \\times 2$ matrix $H = G^{\\top}G$ are the roots of its characteristic equation:\n$$\n\\lambda^2 - \\mathrm{tr}(H)\\lambda + \\det(H) = 0.\n$$\nOur strategy is to first compute the amplification matrix $G$ and then find the determinant and trace of $H=G^{\\top}G$ to solve for its eigenvalues.\n\nFirst, we construct the state matrix $A$ with the given parameters $m=1$, $c=10$, and $k=100$:\n$$\nA = \\begin{pmatrix} 0  1 \\\\ -\\frac{k}{m}  -\\frac{c}{m} \\end{pmatrix} = \\begin{pmatrix} 0  1 \\\\ -100  -10 \\end{pmatrix}.\n$$\nThe time step is $\\Delta t = 0.3$, so $\\frac{\\Delta t}{2} = 0.15$. The amplification matrix $G$ is given by\n$$\nG = \\left(I - \\frac{\\Delta t}{2}A\\right)^{-1}\\left(I + \\frac{\\Delta t}{2}A\\right).\n$$\nLet's define $B_{-} = I - \\frac{\\Delta t}{2}A$ and $B_{+} = I + \\frac{\\Delta t}{2}A$.\n$$\n\\frac{\\Delta t}{2}A = 0.15 \\begin{pmatrix} 0  1 \\\\ -100  -10 \\end{pmatrix} = \\begin{pmatrix} 0  0.15 \\\\ -15  -1.5 \\end{pmatrix}.\n$$\nSo,\n$$\nB_{+} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 0  0.15 \\\\ -15  -1.5 \\end{pmatrix} = \\begin{pmatrix} 1  0.15 \\\\ -15  -0.5 \\end{pmatrix}.\n$$\n$$\nB_{-} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} - \\begin{pmatrix} 0  0.15 \\\\ -15  -1.5 \\end{pmatrix} = \\begin{pmatrix} 1  -0.15 \\\\ 15  2.5 \\end{pmatrix}.\n$$\nTo find the determinant of $H = G^{\\top}G$, we use the property $\\det(H) = \\det(G^{\\top})\\det(G) = (\\det(G))^2$.\n$$\n\\det(G) = \\det(B_{-}^{-1}B_{+}) = \\frac{\\det(B_{+})}{\\det(B_{-})}.\n$$\nThe determinants of $B_{+}$ and $B_{-}$ are:\n$$\n\\det(B_{+}) = (1)(-0.5) - (0.15)(-15) = -0.5 + 2.25 = 1.75 = \\frac{7}{4}.\n$$\n$$\n\\det(B_{-}) = (1)(2.5) - (-0.15)(15) = 2.5 + 2.25 = 4.75 = \\frac{19}{4}.\n$$\nThus, the determinant of $G$ is:\n$$\n\\det(G) = \\frac{7/4}{19/4} = \\frac{7}{19}.\n$$\nAnd the determinant of $H = G^{\\top}G$ is:\n$$\n\\det(H) = \\left(\\frac{7}{19}\\right)^2 = \\frac{49}{361}.\n$$\nNext, we compute the trace of $H$. The trace of $G^{\\top}G$ is equal to the square of the Frobenius norm of $G$, i.e., $\\mathrm{tr}(G^{\\top}G) = \\|G\\|_{\\mathrm{F}}^2 = \\sum_{i,j} G_{ij}^2$. To find this, we must first compute the matrix $G$.\nWe need the inverse of $B_{-}$:\n$$\nB_{-}^{-1} = \\frac{1}{\\det(B_{-})} \\begin{pmatrix} 2.5  0.15 \\\\ -15  1 \\end{pmatrix} = \\frac{1}{4.75} \\begin{pmatrix} 2.5  0.15 \\\\ -15  1 \\end{pmatrix} = \\frac{4}{19} \\begin{pmatrix} 2.5  0.15 \\\\ -15  1 \\end{pmatrix}.\n$$\nNow we compute $G = B_{-}^{-1}B_{+}$:\n$$\nG = \\frac{4}{19} \\begin{pmatrix} 2.5  0.15 \\\\ -15  1 \\end{pmatrix} \\begin{pmatrix} 1  0.15 \\\\ -15  -0.5 \\end{pmatrix} = \\frac{4}{19} \\begin{pmatrix} (2.5)(1)+(0.15)(-15)  (2.5)(0.15)+(0.15)(-0.5) \\\\ (-15)(1)+(1)(-15)  (-15)(0.15)+(1)(-0.5) \\end{pmatrix}\n$$\n$$\nG = \\frac{4}{19} \\begin{pmatrix} 2.5 - 2.25  0.375 - 0.075 \\\\ -15 - 15  -2.25 - 0.5 \\end{pmatrix} = \\frac{4}{19} \\begin{pmatrix} 0.25  0.3 \\\\ -30  -2.75 \\end{pmatrix}.\n$$\nTo facilitate exact arithmetic, we convert the decimals to fractions: $0.25=\\frac{1}{4}$, $0.3=\\frac{3}{10}$, $-2.75=-\\frac{11}{4}$.\n$$\nG = \\frac{4}{19} \\begin{pmatrix} \\frac{1}{4}  \\frac{3}{10} \\\\ -30  -\\frac{11}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{19}\\frac{1}{4}  \\frac{4}{19}\\frac{3}{10} \\\\ \\frac{4}{19}(-30)  \\frac{4}{19}(-\\frac{11}{4}) \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{19}  \\frac{6}{95} \\\\ -\\frac{120}{19}  -\\frac{11}{19} \\end{pmatrix}.\n$$\nNow we compute $\\mathrm{tr}(H) = \\|G\\|_{\\mathrm{F}}^2$:\n$$\n\\mathrm{tr}(H) = \\left(\\frac{1}{19}\\right)^2 + \\left(\\frac{6}{95}\\right)^2 + \\left(-\\frac{120}{19}\\right)^2 + \\left(-\\frac{11}{19}\\right)^2.\n$$\nSince $95 = 5 \\times 19$, we have $95^2 = 25 \\times 19^2 = 25 \\times 361 = 9025$.\n$$\n\\mathrm{tr}(H) = \\frac{1}{361} + \\frac{36}{9025} + \\frac{14400}{361} + \\frac{121}{361} = \\frac{1+14400+121}{361} + \\frac{36}{9025}\n$$\n$$\n\\mathrm{tr}(H) = \\frac{14522}{361} + \\frac{36}{9025} = \\frac{14522 \\times 25}{361 \\times 25} + \\frac{36}{9025} = \\frac{363050}{9025} + \\frac{36}{9025} = \\frac{363086}{9025}.\n$$\nThe eigenvalues $\\lambda$ of $H$ satisfy $\\lambda^2 - \\mathrm{tr}(H)\\lambda + \\det(H) = 0$:\n$$\n\\lambda^2 - \\frac{363086}{9025}\\lambda + \\frac{49}{361} = 0.\n$$\nUsing the quadratic formula, $\\lambda = \\frac{-\\beta \\pm \\sqrt{\\beta^2 - 4\\gamma}}{2}$, with $\\beta = -\\frac{363086}{9025}$ and $\\gamma = \\frac{49}{361}$:\n$$\n\\lambda = \\frac{1}{2} \\left(\\frac{363086}{9025} \\pm \\sqrt{\\left(\\frac{363086}{9025}\\right)^2 - 4\\left(\\frac{49}{361}\\right)}\\right).\n$$\nNumerically evaluating the terms:\n$\\mathrm{tr}(H) = \\frac{363086}{9025} \\approx 40.23113573$\n$\\det(H) = \\frac{49}{361} \\approx 0.13573407$\n$$\n\\lambda = \\frac{1}{2} \\left(40.23113573 \\pm \\sqrt{(40.23113573)^2 - 4(0.13573407)}\\right)\n$$\n$$\n\\lambda = \\frac{1}{2} \\left(40.23113573 \\pm \\sqrt{1618.544257 - 0.542936}\\right)\n$$\n$$\n\\lambda = \\frac{1}{2} \\left(40.23113573 \\pm \\sqrt{1618.001321}\\right)\n$$\n$$\n\\lambda = \\frac{1}{2} \\left(40.23113573 \\pm 40.22438708\\right).\n$$\nThe two eigenvalues are:\n$$\n\\lambda_1 = \\frac{1}{2} (40.23113573 + 40.22438708) = \\frac{80.45552281}{2} = 40.227761405.\n$$\n$$\n\\lambda_2 = \\frac{1}{2} (40.23113573 - 40.22438708) = \\frac{0.00674865}{2} = 0.003374325.\n$$\nThe maximal one-step amplification factor is the larger eigenvalue, $\\alpha_{\\max} = \\lambda_{\\max}(G^{\\top}G) = \\lambda_1$.\n$$\n\\alpha_{\\max} \\approx 40.227761405.\n$$\nRounding to four significant figures, we get $40.23$.\nThis result, being significantly greater than $1$, demonstrates that although the trapezoidal rule is $A$-stable (the spectral radius of $G$ is $\\rho(G)=\\sqrt{7/19}  1$), it is not strictly contractive in the Euclidean norm for this choice of time step, and can transiently amplify the energy-like functional $E_{\\mathrm{euc}}$.",
            "answer": "$$\\boxed{40.23}$$"
        }
    ]
}