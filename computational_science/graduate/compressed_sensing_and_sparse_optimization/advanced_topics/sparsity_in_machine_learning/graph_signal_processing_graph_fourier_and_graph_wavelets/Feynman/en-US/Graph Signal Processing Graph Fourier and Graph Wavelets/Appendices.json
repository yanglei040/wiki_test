{
    "hands_on_practices": [
        {
            "introduction": "This exercise serves as a foundational exploration of the Graph Fourier Transform (GFT). By analyzing the cycle graph, a structure whose properties parallel the periodic setting in classical signal processing, you will derive its GFT basis from first principles. This practice is crucial for building intuition on how a graph's topology dictates its spectral properties and how Laplacian eigenvalues quantify the notion of graph frequency .",
            "id": "3448867",
            "problem": "Consider the undirected cycle graph $C_{n}$ on $n$ nodes with node set $\\{0,1,\\dots,n-1\\}$ and edges between $j$ and $(j+1)\\bmod n$. Let $A$ denote the adjacency matrix and $D$ the diagonal degree matrix, and define the combinatorial graph Laplacian $L = D - A$. The Graph Fourier Transform (GFT) of a signal $x \\in \\mathbb{C}^{n}$ on $C_{n}$ is defined with respect to an orthonormal eigenbasis of $L$. The notion of graph frequency is tied to the Dirichlet energy $x^{\\top} L x$, and the eigenvalue associated with a Laplacian eigenvector quantifies its graph frequency.\n\nStarting from the definitions of $A$, $D$, and $L$ for $C_{n}$, derive the Laplacian eigenpairs in closed form and explain why ordering eigenvectors by increasing eigenvalues corresponds to ordering by increasing graph frequency. Then, form the GFT matrix $U$ whose columns are the normalized eigenvectors of $L$, and consider the canonical basis $\\{e_{i}\\}_{i=0}^{n-1}$ of $\\mathbb{C}^{n}$. Define the mutual coherence of these two bases by\n$$\n\\mu \\triangleq \\max_{0 \\leq i \\leq n-1} \\max_{0 \\leq m \\leq n-1} \\left| \\langle e_{i}, u_{m} \\rangle \\right|,\n$$\nwhere $u_{m}$ is the $m$-th column of $U$ and $\\langle \\cdot, \\cdot \\rangle$ is the standard inner product on $\\mathbb{C}^{n}$.\n\nCompute $\\mu$ in exact closed form as a symbolic expression of $n$. No rounding is required, and no units are involved. Provide only the final expression for $\\mu$ as your answer.",
            "solution": "The problem asks for the derivation of Laplacian eigenpairs for the cycle graph $C_{n}$, an explanation of the relationship between eigenvalues and graph frequency, and the computation of the mutual coherence $\\mu$ between the graph Fourier basis and the canonical basis.\n\n### Step 1: Problem Validation\nI will first validate the problem statement.\n\n#### Extracted Givens:\n-   **Graph:** An undirected cycle graph $C_{n}$ on $n$ nodes, with the node set being $\\{0,1,\\dots,n-1\\}$. Edges are defined between node $j$ and node $(j+1)\\bmod n$ for all $j \\in \\{0,1,\\dots,n-1\\}$.\n-   **Matrices:** Adjacency matrix $A$, diagonal degree matrix $D$, and combinatorial graph Laplacian $L = D - A$.\n-   **Graph Fourier Transform (GFT):** Defined with respect to an orthonormal eigenbasis of $L$. The GFT matrix $U$ has the normalized eigenvectors $u_m$ of $L$ as its columns.\n-   **Graph Frequency:** The concept is linked to the Dirichlet energy $x^{\\top} L x$, and the eigenvalue of a Laplacian eigenvector quantifies its frequency.\n-   **Mutual Coherence:** Defined as $\\mu \\triangleq \\max_{0 \\leq i \\leq n-1} \\max_{0 \\leq m \\leq n-1} \\left| \\langle e_{i}, u_{m} \\rangle \\right|$, where $\\{e_i\\}$ is the canonical basis of $\\mathbb{C}^{n}$ and $\\langle \\cdot, \\cdot \\rangle$ is the standard inner product.\n\n#### Validation Using Extracted Givens:\nThe problem is scientifically grounded in the field of graph signal processing. All definitions ($L$, $D$, $A$, GFT, mutual coherence) are standard and correct. The problem is well-posed, objective, and self-contained, requesting specific derivations and a final quantitative result.\n\nA minor ambiguity exists regarding the graph structure for small $n$. The definition of edges between $j$ and $(j+1)\\bmod n$ implies that for $n \\ge 3$, the graph is a simple $2$-regular graph (the standard cycle). For $n=2$, it would be a multigraph with two edges between two nodes, and for $n=1$, a single node with a self-loop. The standard notion of a \"cycle graph $C_n$\" typically implies $n \\ge 3$. Assuming this standard convention, every node has a degree of $2$. This does not invalidate the problem but requires a clarification of the domain of $n$.\n\nThe choice of eigenbasis for degenerate eigenspaces could also introduce ambiguity. However, for the cycle graph $C_n$, the Laplacian is a circulant matrix. As will be shown, all circulant matrices are diagonalized by the Discrete Fourier Transform (DFT) matrix, which provides a canonical and standard choice for the GFT basis. The problem is thus interpreted as using this standard basis.\n\n#### Verdict and Action:\nThe problem is deemed valid, assuming the standard interpretation of $C_n$ as a simple graph ($n \\ge 3$) and the use of the canonical DFT basis for the GFT.\n\n### Step 2: Derivation and Solution\n\n#### Laplacian Eigenstructure of $C_n$\nFor the cycle graph $C_n$ (with $n \\ge 3$), each node is connected to two neighbors. Therefore, the degree of every node is $2$, and the degree matrix is $D = 2I$, where $I$ is the $n \\times n$ identity matrix.\n\nThe adjacency matrix $A$ has elements $A_{ij} = 1$ if node $i$ is adjacent to node $j$, and $A_{ij} = 0$ otherwise. For $C_n$, $A_{ij}=1$ if $|i-j| \\equiv 1 \\pmod{n}$. This matrix is a circulant matrix, where each row is a cyclic shift of the row above it. The first row (for node $0$) is $(0, 1, 0, \\dots, 0, 1)$.\n\nThe Laplacian matrix is $L = D - A = 2I - A$.\n\nA key property of circulant matrices is that they are all diagonalized by the same set of eigenvectors, which are the columns of the Discrete Fourier Transform (DFT) matrix. Let us define the vectors $\\{u_m\\}_{m=0}^{n-1}$ with components:\n$$ (u_m)_j = \\frac{1}{\\sqrt{n}} \\exp\\left(i \\frac{2\\pi mj}{n}\\right) \\quad \\text{for } j=0, 1, \\dots, n-1 $$\nThese vectors form an orthonormal basis for $\\mathbb{C}^n$. Let's verify that they are eigenvectors of $A$. Consider the $j$-th component of the vector $A u_m$:\n$$ (A u_m)_j = \\sum_{k=0}^{n-1} A_{jk} (u_m)_k = (u_m)_{(j-1)\\bmod n} + (u_m)_{(j+1)\\bmod n} $$\n$$ (A u_m)_j = \\frac{1}{\\sqrt{n}} \\exp\\left(i \\frac{2\\pi m(j-1)}{n}\\right) + \\frac{1}{\\sqrt{n}} \\exp\\left(i \\frac{2\\pi m(j+1)}{n}\\right) $$\n$$ (A u_m)_j = \\frac{1}{\\sqrt{n}} \\exp\\left(i \\frac{2\\pi mj}{n}\\right) \\left[ \\exp\\left(-i \\frac{2\\pi m}{n}\\right) + \\exp\\left(i \\frac{2\\pi m}{n}\\right) \\right] $$\n$$ (A u_m)_j = (u_m)_j \\left[ 2\\cos\\left(\\frac{2\\pi m}{n}\\right) \\right] $$\nThus, $u_m$ is an eigenvector of $A$ with eigenvalue $\\lambda_m(A) = 2\\cos\\left(\\frac{2\\pi m}{n}\\right)$.\n\nSince $L = 2I - A$, the eigenvectors of $L$ are the same vectors $u_m$. The corresponding eigenvalues of $L$, denoted $\\lambda_m$, are:\n$$ \\lambda_m = 2 - \\lambda_m(A) = 2 - 2\\cos\\left(\\frac{2\\pi m}{n}\\right) $$\nUsing the half-angle identity $1 - \\cos(2\\theta) = 2\\sin^2(\\theta)$, we find the closed form for the Laplacian eigenvalues:\n$$ \\lambda_m = 2 \\left(1 - \\cos\\left(\\frac{2\\pi m}{n}\\right)\\right) = 4\\sin^2\\left(\\frac{\\pi m}{n}\\right) $$\nThe eigenpairs $(\\lambda_m, u_m)$ of the Laplacian $L$ are therefore given by:\n$$ \\lambda_m = 4\\sin^2\\left(\\frac{\\pi m}{n}\\right), \\quad (u_m)_j = \\frac{1}{\\sqrt{n}} \\exp\\left(i \\frac{2\\pi mj}{n}\\right) $$\nfor $m, j \\in \\{0, 1, \\dots, n-1\\}$.\n\n#### Graph Frequency\nThe Dirichlet energy of a signal $x \\in \\mathbb{C}^n$ on the graph is given by the quadratic form $x^* L x$. For an unweighted graph, this can be expressed as:\n$$ x^* L x = \\sum_{(j,k) \\in E} |x_j - x_k|^2 $$\nwhere $E$ is the set of edges. This quantity measures the total variation of the signal across the edges. A signal is considered \"low frequency\" if its values change slowly across the graph (i.e., $|x_j - x_k|$ is small for connected nodes $j, k$), resulting in a small Dirichlet energy. Conversely, a signal with rapid changes is \"high frequency\" and has a large Dirichlet energy.\n\nIf we take the signal to be a normalized eigenvector $u_m$, its Dirichlet energy is:\n$$ u_m^* L u_m = u_m^* (\\lambda_m u_m) = \\lambda_m (u_m^* u_m) = \\lambda_m (1) = \\lambda_m $$\nThus, the eigenvalue $\\lambda_m$ is precisely the Dirichlet energy of its corresponding eigenvector $u_m$. This directly quantifies the notion of graph frequency for that eigenvector. Ordering the eigenvectors by their eigenvalues in increasing order, $\\lambda_0 \\le \\lambda_1 \\le \\dots \\le \\lambda_{n-1}$, corresponds to ordering them by increasing graph frequency. For $C_n$, the eigenvalues $\\lambda_m = 4\\sin^2(\\pi m/n)$ increase as $m$ goes from $0$ to $\\lfloor n/2 \\rfloor$, corresponding to increasingly oscillatory eigenvectors.\n\n#### Mutual Coherence Calculation\nThe GFT matrix $U$ is formed with the normalized eigenvectors $u_m$ as its columns. As established, the canonical choice for these eigenvectors for $C_n$ are the DFT basis vectors derived above.\n$$ U = \\begin{pmatrix} | & | & & | \\\\ u_0 & u_1 & \\dots & u_{n-1} \\\\ | & | & & | \\end{pmatrix} $$\nThe mutual coherence $\\mu$ between this GFT basis $\\{u_m\\}$ and the canonical basis $\\{e_i\\}$ is defined as:\n$$ \\mu = \\max_{0 \\leq i \\leq n-1} \\max_{0 \\leq m \\leq n-1} \\left| \\langle e_{i}, u_{m} \\rangle \\right| $$\nThe standard inner product on $\\mathbb{C}^n$ is $\\langle x, y \\rangle = y^* x = \\sum_{j=0}^{n-1} \\overline{y_j} x_j$. Let's compute the inner product $\\langle e_i, u_m \\rangle$:\n$$ \\langle e_i, u_m \\rangle = \\sum_{j=0}^{n-1} \\overline{(u_m)_j} (e_i)_j $$\nSince $(e_i)_j = \\delta_{ij}$ (it is $1$ if $j=i$ and $0$ otherwise), the sum collapses to a single term:\n$$ \\langle e_i, u_m \\rangle = \\overline{(u_m)_i} $$\nSubstituting the expression for $(u_m)_i$:\n$$ \\langle e_i, u_m \\rangle = \\overline{\\left(\\frac{1}{\\sqrt{n}} \\exp\\left(i \\frac{2\\pi mi}{n}\\right)\\right)} = \\frac{1}{\\sqrt{n}} \\exp\\left(-i \\frac{2\\pi mi}{n}\\right) $$\nNext, we take the absolute value:\n$$ \\left| \\langle e_i, u_m \\rangle \\right| = \\left| \\frac{1}{\\sqrt{n}} \\exp\\left(-i \\frac{2\\pi mi}{n}\\right) \\right| = \\left| \\frac{1}{\\sqrt{n}} \\right| \\cdot \\left| \\exp\\left(-i \\frac{2\\pi mi}{n}\\right) \\right| $$\nSince $|\\exp(-i\\theta)| = 1$ for any real $\\theta$, this simplifies to:\n$$ \\left| \\langle e_i, u_m \\rangle \\right| = \\frac{1}{\\sqrt{n}} $$\nThis result is a constant, independent of the indices $i$ and $m$. Therefore, the maximum value over all $i$ and $m$ is simply this constant value.\n$$ \\mu = \\max_{0 \\leq i \\leq n-1} \\max_{0 \\leq m \\leq n-1} \\frac{1}{\\sqrt{n}} = \\frac{1}{\\sqrt{n}} $$\nThis value can also be written as $n^{-1/2}$.",
            "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{n}}}\n$$"
        },
        {
            "introduction": "Moving from the spectral to the vertex domain, this practice makes the concept of signal variation tangible. The Laplacian quadratic form, $x^{\\top} L x$, provides a global measure of a signal's smoothness, which is directly linked to its frequency content. This exercise asks you to compute this value for a specific signal on a weighted graph, decomposing it into local contributions to solidify your understanding of how graph structure and signal values combine to define total variation .",
            "id": "3448891",
            "problem": "Consider a connected, undirected, weighted graph with vertex set $\\{1,2,3,4,5\\}$ and symmetric edge weights given by $w_{12}=3$, $w_{23}=1$, $w_{24}=2$, $w_{35}=4$, $w_{45}=1$, and $w_{ij}=0$ otherwise. Let $W$ denote the weighted adjacency matrix with entries $W_{ij}=w_{ij}$, let $D$ be the diagonal degree matrix with $D_{ii}=\\sum_{j} w_{ij}$, and let the combinatorial graph Laplacian be $L=D-W$. Consider the graph signal $x\\in\\mathbb{R}^{5}$ with entries $x=\\begin{pmatrix}2 & -1 & 0 & 3 & -2\\end{pmatrix}^{\\top}$. Define the per-vertex local variation by $V_{i}(x)=\\sum_{j:\\, w_{ij}>0} w_{ij}\\,(x_{i}-x_{j})^{2}$.\n\nStarting only from the definitions above, derive a decomposition of the quadratic form $x^{\\top} L x$ into symmetric contributions associated with edges, and use it to interpret $x^{\\top} L x$ as a sum of vertex-local contributions built from incident edges via $V_{i}(x)$. Then, for the specific graph and signal given, compute $V_{i}(x)$ for each $i\\in\\{1,2,3,4,5\\}$, and use your decomposition to obtain the exact value of $x^{\\top} L x$. Report as your final answer the exact value of $x^{\\top} L x$ (no rounding is required and no units are involved).",
            "solution": "We begin from the fundamental definitions for a weighted, undirected graph: the weighted adjacency matrix $W$ is symmetric with $W_{ij}=w_{ij}\\ge 0$, the diagonal degree matrix is $D$ with diagonal entries $D_{ii}=\\sum_{j} w_{ij}$, and the combinatorial graph Laplacian is $L=D-W$. For any $x\\in\\mathbb{R}^{n}$, the quadratic form is\n$$\nx^{\\top} L x \\;=\\; x^{\\top} D x \\;-\\; x^{\\top} W x \\;=\\; \\sum_{i=1}^{n} D_{ii} x_{i}^{2} \\;-\\; \\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} x_{i} x_{j}.\n$$\nSubstituting $D_{ii}=\\sum_{j} w_{ij}$ and $W_{ij}=w_{ij}$,\n$$\nx^{\\top} L x \\;=\\; \\sum_{i=1}^{n}\\Big(\\sum_{j=1}^{n} w_{ij}\\Big) x_{i}^{2} \\;-\\; \\sum_{i=1}^{n}\\sum_{j=1}^{n} w_{ij} x_{i} x_{j}.\n$$\nBecause the graph is undirected, $w_{ij}=w_{ji}$ and $w_{ii}=0$. Rearranging terms and exploiting symmetry,\n$$\nx^{\\top} L x \\;=\\; \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n} w_{ij}\\big(x_{i}^{2}+x_{j}^{2}-2 x_{i} x_{j}\\big)\n\\;=\\; \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n} w_{ij}\\,(x_{i}-x_{j})^{2}.\n$$\nThis expresses $x^{\\top} L x$ as a symmetric sum over unordered edges $\\{i,j\\}$:\n$$\nx^{\\top} L x \\;=\\; \\sum_{\\{i,j\\}} w_{ij}\\,(x_{i}-x_{j})^{2},\n$$\nwhere the sum is over each undirected edge once. Equivalently, if we aggregate edge contributions at vertices, define the local variation\n$$\nV_{i}(x) \\;=\\; \\sum_{j:\\,w_{ij}>0} w_{ij}\\,(x_{i}-x_{j})^{2}.\n$$\nThen each undirected edge $\\{i,j\\}$ appears exactly twice in $\\sum_{i} V_{i}(x)$, once in $V_{i}(x)$ and once in $V_{j}(x)$. Therefore,\n$$\n\\sum_{i=1}^{n} V_{i}(x) \\;=\\; 2 \\sum_{\\{i,j\\}} w_{ij}\\,(x_{i}-x_{j})^{2} \\;=\\; 2\\, x^{\\top} L x,\n$$\nwhich yields the decomposition\n$$\nx^{\\top} L x \\;=\\; \\frac{1}{2}\\sum_{i=1}^{n} V_{i}(x).\n$$\n\nWe now compute the local variations $V_{i}(x)$ for the given graph and signal. The nonzero weights are $w_{12}=3$, $w_{23}=1$, $w_{24}=2$, $w_{35}=4$, $w_{45}=1$. The signal entries are $x_{1}=2$, $x_{2}=-1$, $x_{3}=0$, $x_{4}=3$, $x_{5}=-2$.\n\n- For $i=1$, the neighbors are $\\{2\\}$:\n$$\nV_{1}(x) \\;=\\; w_{12}\\,(x_{1}-x_{2})^{2} \\;=\\; 3\\,(2-(-1))^{2} \\;=\\; 3\\cdot 3^{2} \\;=\\; 27.\n$$\n\n- For $i=2$, the neighbors are $\\{1,3,4\\}$:\n$$\n\\begin{aligned}\nV_{2}(x) \\;&=\\; w_{12}\\,(x_{2}-x_{1})^{2} \\;+\\; w_{23}\\,(x_{2}-x_{3})^{2} \\;+\\; w_{24}\\,(x_{2}-x_{4})^{2} \\\\\n&=\\; 3\\,(-1-2)^{2} \\;+\\; 1\\,(-1-0)^{2} \\;+\\; 2\\,(-1-3)^{2} \\\\\n&=\\; 3\\cdot (-3)^{2} \\;+\\; 1\\cdot (-1)^{2} \\;+\\; 2\\cdot (-4)^{2} \\\\\n&=\\; 27 \\;+\\; 1 \\;+\\; 32 \\;=\\; 60.\n\\end{aligned}\n$$\n\n- For $i=3$, the neighbors are $\\{2,5\\}$:\n$$\n\\begin{aligned}\nV_{3}(x) \\;&=\\; w_{23}\\,(x_{3}-x_{2})^{2} \\;+\\; w_{35}\\,(x_{3}-x_{5})^{2} \\\\\n&=\\; 1\\,(0-(-1))^{2} \\;+\\; 4\\,(0-(-2))^{2} \\\\\n&=\\; 1\\cdot 1^{2} \\;+\\; 4\\cdot 2^{2} \\\\\n&=\\; 1 \\;+\\; 16 \\;=\\; 17.\n\\end{aligned}\n$$\n\n- For $i=4$, the neighbors are $\\{2,5\\}$:\n$$\n\\begin{aligned}\nV_{4}(x) \\;&=\\; w_{24}\\,(x_{4}-x_{2})^{2} \\;+\\; w_{45}\\,(x_{4}-x_{5})^{2} \\\\\n&=\\; 2\\,(3-(-1))^{2} \\;+\\; 1\\,(3-(-2))^{2} \\\\\n&=\\; 2\\cdot 4^{2} \\;+\\; 1\\cdot 5^{2} \\\\\n&=\\; 32 \\;+\\; 25 \\;=\\; 57.\n\\end{aligned}\n$$\n\n- For $i=5$, the neighbors are $\\{3,4\\}$:\n$$\n\\begin{aligned}\nV_{5}(x) \\;&=\\; w_{35}\\,(x_{5}-x_{3})^{2} \\;+\\; w_{45}\\,(x_{5}-x_{4})^{2} \\\\\n&=\\; 4\\,(-2-0)^{2} \\;+\\; 1\\,(-2-3)^{2} \\\\\n&=\\; 4\\cdot (-2)^{2} \\;+\\; 1\\cdot (-5)^{2} \\\\\n&=\\; 16 \\;+\\; 25 \\;=\\; 41.\n\\end{aligned}\n$$\n\nSumming the local variations,\n$$\n\\sum_{i=1}^{5} V_{i}(x) \\;=\\; 27 \\;+\\; 60 \\;+\\; 17 \\;+\\; 57 \\;+\\; 41 \\;=\\; 202.\n$$\nBy the decomposition $x^{\\top} L x=\\frac{1}{2}\\sum_{i} V_{i}(x)$, we obtain\n$$\nx^{\\top} L x \\;=\\; \\frac{1}{2}\\cdot 202 \\;=\\; 101.\n$$\nAs a consistency check, we can also sum edge contributions once per undirected edge:\n$$\nw_{12}(x_{1}-x_{2})^{2} \\;+\\; w_{23}(x_{2}-x_{3})^{2} \\;+\\; w_{24}(x_{2}-x_{4})^{2} \\;+\\; w_{35}(x_{3}-x_{5})^{2} \\;+\\; w_{45}(x_{4}-x_{5})^{2}\n$$\n$$\n=\\; 3\\cdot 3^{2} \\;+\\; 1\\cdot 1^{2} \\;+\\; 2\\cdot 4^{2} \\;+\\; 4\\cdot 2^{2} \\;+\\; 1\\cdot 5^{2} \\;=\\; 27 \\;+\\; 1 \\;+\\; 32 \\;+\\; 16 \\;+\\; 25 \\;=\\; 101,\n$$\nwhich matches the value computed from vertex-local aggregation.",
            "answer": "$$\\boxed{101}$$"
        },
        {
            "introduction": "This practice explores a critical challenge in applying graph signal processing to real-world problems like signal recovery from incomplete data. Naive sampling of graph signals can fail spectacularly if the signal's structure is not well-suited to the sampling locations, a phenomenon governed by the coherence between the GFT basis and the vertex basis. By constructing a specific counterexample, you will investigate how extreme localization of a GFT eigenvector—a direct consequence of the graph's topology—can undermine sparse signal recovery .",
            "id": "3448904",
            "problem": "Consider an undirected weighted graph with $N \\geq 4$ vertices labeled $\\{1,2,\\dots,N\\}$. Let the edge weights be such that vertex $1$ is isolated, and the induced subgraph on vertices $\\{2,3,\\dots,N\\}$ is a complete graph with unit edge weights. Let $\\mathbf{L} \\in \\mathbb{R}^{N \\times N}$ denote the combinatorial graph Laplacian, and let the Graph Fourier Transform (GFT) be defined as the orthonormal eigenbasis $\\mathbf{U} \\in \\mathbb{R}^{N \\times N}$ of $\\mathbf{L}$, satisfying $\\mathbf{L} \\mathbf{U} = \\mathbf{U} \\boldsymbol{\\Lambda}$ with $\\boldsymbol{\\Lambda}$ diagonal and $\\mathbf{U}^{\\top} \\mathbf{U} = \\mathbf{I}$. Define the naive vertex subsampling operator $\\mathbf{S} \\in \\mathbb{R}^{m \\times N}$ that selects $m$ distinct vertices uniformly at random without replacement and measures a graph signal $\\mathbf{x} \\in \\mathbb{R}^{N}$ only on those sampled vertices, so that the measurement is $\\mathbf{y} = \\mathbf{S} \\mathbf{x}$.\n\nA graph signal $\\mathbf{x}$ is said to be $K$-sparse in the GFT domain if its GFT coefficient vector $\\hat{\\mathbf{x}} \\in \\mathbb{R}^{N}$ has at most $K$ nonzero entries, and $\\mathbf{x} = \\mathbf{U} \\hat{\\mathbf{x}}$. Consider the mutual coherence between the canonical vertex basis and the GFT basis, defined as\n$$\n\\mu(\\mathbf{U}) = \\max_{1 \\leq i \\leq N, \\, 1 \\leq k \\leq N} |U_{i,k}|.\n$$\n\nStarting from the core definitions above and first principles of spectral graph theory and sampling, construct a counterexample to show that naive vertex subsampling can fail for recovery of $K$-sparse GFT signals when the GFT is highly localized on a few vertices. In particular, do the following:\n\n1. Using properties of the combinatorial graph Laplacian on the described graph, identify an eigenvector of $\\mathbf{L}$ that is exactly localized on a single vertex and argue that the corresponding GFT atom is maximally localized in the vertex domain.\n2. For a $1$-sparse GFT signal whose coefficient support is exactly that localized GFT atom, derive the measurement $\\mathbf{y}$ under $\\mathbf{S}$ and formalize the failure mode of naive vertex subsampling when the sampled vertex set excludes the localized vertex.\n3. Compute the mutual coherence $\\mu(\\mathbf{U})$.\n4. Quantify exactly the failure probability of naive vertex subsampling, defined as the probability that the sampled vertex set excludes the localized vertex, under uniform sampling of $m$ vertices without replacement.\n\nProvide your final answer as a single closed-form analytic expression consisting of the pair $\\big(\\mu(\\mathbf{U}), P_{\\mathrm{fail}}\\big)$, where $P_{\\mathrm{fail}}$ is the failure probability derived in item $4$. No numerical approximation is required; do not include units. If you write multiple values, they must be presented as a single row matrix in your final answer.",
            "solution": "The problem asks for the construction of a counterexample to demonstrate the failure of naive vertex subsampling for the recovery of Graph Fourier Transform (GFT) sparse signals on a specific graph. We will proceed by following the four specified steps.\n\nFirst, we must characterize the graph Laplacian $\\mathbf{L}$. The graph has $N$ vertices. Vertex $1$ is isolated, meaning it has no edges. The vertices $\\{2, 3, \\dots, N\\}$ form a complete graph $K_{N-1}$ with unit edge weights.\n\nThe degree matrix $\\mathbf{D}$ is diagonal. The degree of the isolated vertex $1$ is $D_{1,1} = 0$. For any vertex $i \\in \\{2, \\dots, N\\}$, it is connected to all other $N-2$ vertices in the complete subgraph, so its degree is $D_{i,i} = N-2$.\n\nThe adjacency matrix $\\mathbf{A}$ has entries $A_{i,j}=1$ if there is an edge between $i$ and $j$, and $0$ otherwise. Given the graph structure, $A_{1,j} = A_{j,1} = 0$ for all $j$. For $i, j \\in \\{2, \\dots, N\\}$ with $i \\neq j$, $A_{i,j} = 1$.\n\nThe combinatorial graph Laplacian is defined as $\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$. Given the block structure of the graph (a disjoint union of an isolated vertex and a complete graph), the Laplacian matrix $\\mathbf{L}$ is block diagonal:\n$$\n\\mathbf{L} = \\begin{pmatrix} L_{1,1} & \\mathbf{0}_{1 \\times (N-1)} \\\\ \\mathbf{0}_{(N-1) \\times 1} & \\mathbf{L}_{sub} \\end{pmatrix}\n$$\nwhere $L_{1,1} = D_{1,1} - A_{1,1} = 0 - 0 = 0$. The submatrix $\\mathbf{L}_{sub}$ is the Laplacian of the complete graph $K_{N-1}$ on vertices $\\{2, \\dots, N\\}$. For this subgraph, the degree of each of the $N-1$ vertices is $N-2$. The adjacency matrix is $\\mathbf{J}_{N-1} - \\mathbf{I}_{N-1}$, where $\\mathbf{J}$ is the all-ones matrix and $\\mathbf{I}$ is the identity matrix. Thus,\n$$\n\\mathbf{L}_{sub} = (N-2)\\mathbf{I}_{N-1} - (\\mathbf{J}_{N-1} - \\mathbf{I}_{N-1}) = (N-1)\\mathbf{I}_{N-1} - \\mathbf{J}_{N-1}\n$$\n\n**1. Identification of a Localized Eigenvector**\n\nWe need to find an eigenvector of $\\mathbf{L}$ that is localized on a single vertex. Consider the standard basis vector $\\mathbf{e}_1 = [1, 0, \\dots, 0]^{\\top} \\in \\mathbb{R}^N$. We can test if this is an eigenvector of $\\mathbf{L}$:\n$$\n\\mathbf{L} \\mathbf{e}_1 = \\begin{pmatrix} 0 & \\mathbf{0}_{1 \\times (N-1)} \\\\ \\mathbf{0}_{(N-1) \\times 1} & \\mathbf{L}_{sub} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix} = 0 \\cdot \\mathbf{e}_1\n$$\nThis shows that $\\mathbf{e}_1$ is an eigenvector of $\\mathbf{L}$ with corresponding eigenvalue $\\lambda = 0$. This eigenvector is normalized, $\\|\\mathbf{e}_1\\|_2 = 1$, so it is a valid GFT atom (a column of the orthonormal matrix $\\mathbf{U}$). Let's denote this eigenvector as $\\mathbf{u}_k$ for some index $k$. So, $\\mathbf{u}_k = \\mathbf{e}_1$.\n\nThis GFT atom is exactly localized on vertex $1$, as all its entries are zero except for the first one. It is maximally localized in the sense that its support size is $1$, which is the minimum possible for a non-zero vector.\n\n**2. Failure Mode of Naive Vertex Subsampling**\n\nLet's consider a graph signal $\\mathbf{x}$ that is $1$-sparse in the GFT domain, with its single non-zero coefficient corresponding to the localized GFT atom $\\mathbf{u}_k = \\mathbf{e}_1$. The GFT coefficient vector $\\hat{\\mathbf{x}}$ is given by $\\hat{\\mathbf{x}} = \\alpha \\mathbf{e}_k$ for some non-zero scalar $\\alpha \\in \\mathbb{R}$, where $\\mathbf{e}_k$ is the $k$-th standard basis vector in the GFT domain.\n\nThe signal in the vertex domain is obtained by the inverse GFT:\n$$\n\\mathbf{x} = \\mathbf{U} \\hat{\\mathbf{x}} = \\alpha (\\mathbf{U} \\mathbf{e}_k) = \\alpha \\mathbf{u}_k = \\alpha \\mathbf{e}_1\n$$\nSo, the signal is $\\mathbf{x} = [\\alpha, 0, 0, \\dots, 0]^{\\top}$. This signal has energy only on the isolated vertex $1$.\n\nThe measurement process consists of sampling this signal at $m$ vertices, chosen uniformly at random without replacement. Let the set of sampled vertex indices be $\\mathcal{M} \\subset \\{1, 2, \\dots, N\\}$ with $|\\mathcal{M}| = m$. The measurement vector is $\\mathbf{y} = \\mathbf{S} \\mathbf{x}$, which corresponds to the components of $\\mathbf{x}$ indexed by $\\mathcal{M}$.\n\nThe failure mode occurs if the set of sampled vertices $\\mathcal{M}$ does not include vertex $1$. If $1 \\notin \\mathcal{M}$, then for every sampled vertex index $i \\in \\mathcal{M}$, we have $i \\in \\{2, 3, \\dots, N\\}$. For all such indices, the signal value is $x_i = 0$. Consequently, the measurement vector is $\\mathbf{y} = \\mathbf{0} \\in \\mathbb{R}^m$.\n\nFrom a measurement vector $\\mathbf{y} = \\mathbf{0}$, any standard sparse recovery algorithm (e.g., basis pursuit) would reconstruct the sparsest signal consistent with the measurements. The trivial solution $\\mathbf{x}_{\\text{rec}} = \\mathbf{0}$ (which corresponds to $\\hat{\\mathbf{x}}_{\\text{rec}} = \\mathbf{0}$) is always a possibility and is the sparsest possible signal ($0$-sparse). Given $\\mathbf{y} = \\mathbf{0}$, this is the solution that will be found. However, the true signal was $\\mathbf{x} = \\alpha \\mathbf{e}_1 \\neq \\mathbf{0}$. Thus, if vertex $1$ is not sampled, the signal is completely missed, representing a catastrophic failure of the recovery process.\n\n**3. Computation of Mutual Coherence**\n\nThe mutual coherence between the canonical vertex basis (identity matrix $\\mathbf{I}$) and the GFT basis $\\mathbf{U}$ is defined as $\\mu(\\mathbf{U}) = \\max_{1 \\leq i, k \\leq N} |U_{i,k}|$.\nThe matrix $\\mathbf{U}$ is an orthonormal matrix, meaning its columns $\\mathbf{u}_k$ are orthonormal vectors. For any column $\\mathbf{u}_k$, we have $\\|\\mathbf{u}_k\\|_2^2 = \\sum_{i=1}^N U_{i,k}^2 = 1$. From this, it follows that for any entry $U_{i,k}$, we must have $U_{i,k}^2 \\leq 1$, which implies $|U_{i,k}| \\leq 1$. Thus, the mutual coherence $\\mu(\\mathbf{U})$ can be at most $1$.\n\nIn step 1, we identified an eigenvector $\\mathbf{u}_k = \\mathbf{e}_1 = [1, 0, \\dots, 0]^{\\top}$. This vector is a column of the GFT matrix $\\mathbf{U}$. The first entry of this vector is $U_{1,k} = 1$.\nSince we found an entry with an absolute value of $1$, and we know that no entry can exceed $1$, we have found the maximum.\nTherefore, the mutual coherence is\n$$\n\\mu(\\mathbf{U}) = 1.\n$$\n\n**4. Quantification of Failure Probability**\n\nThe failure probability, $P_{\\mathrm{fail}}$, is defined as the probability that the sampled vertex set $\\mathcal{M}$ excludes the localized vertex, which is vertex $1$. The sampling is uniform without replacement from $N$ vertices to choose a set of $m$ vertices.\n\nThe total number of distinct subsets of $m$ vertices that can be chosen from a set of $N$ vertices is given by the binomial coefficient $\\binom{N}{m}$.\n\nFailure occurs if vertex $1$ is not in the chosen subset. This is equivalent to choosing all $m$ vertices from the remaining $N-1$ vertices, i.e., from the set $\\{2, 3, \\dots, N\\}$. The number of ways to do this is $\\binom{N-1}{m}$.\n\nThe failure probability is the ratio of the number of unfavorable outcomes to the total number of possible outcomes:\n$$\nP_{\\mathrm{fail}} = \\frac{\\text{Number of ways to choose } m \\text{ vertices from } \\{2, \\dots, N\\}}{\\text{Total number of ways to choose } m \\text{ vertices from } \\{1, \\dots, N\\}} = \\frac{\\binom{N-1}{m}}{\\binom{N}{m}}\n$$\nWe can simplify this expression using the definition of binomial coefficients:\n$$\n\\binom{N-1}{m} = \\frac{(N-1)!}{m!(N-1-m)!}\n$$\n$$\n\\binom{N}{m} = \\frac{N!}{m!(N-m)!}\n$$\nThe ratio is:\n$$\nP_{\\mathrm{fail}} = \\frac{(N-1)!}{m!(N-1-m)!} \\cdot \\frac{m!(N-m)!}{N!} = \\frac{(N-1)!}{N!} \\cdot \\frac{(N-m)!}{(N-1-m)!}\n$$\nThe first term simplifies to $\\frac{(N-1)!}{N \\cdot (N-1)!} = \\frac{1}{N}$.\nThe second term simplifies to $\\frac{(N-m) \\cdot (N-m-1)!}{(N-m-1)!} = N-m$.\n\nThus, the failure probability is:\n$$\nP_{\\mathrm{fail}} = \\frac{1}{N} \\cdot (N-m) = \\frac{N-m}{N} = 1 - \\frac{m}{N}\n$$\nThis result is valid for $0 \\leq m \\leq N$.\n\nThe final answer requires the pair $(\\mu(\\mathbf{U}), P_{\\mathrm{fail}})$. We have found $\\mu(\\mathbf{U})=1$ and $P_{\\mathrm{fail}}=1 - \\frac{m}{N}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1 & 1 - \\frac{m}{N} \\end{pmatrix}}\n$$"
        }
    ]
}