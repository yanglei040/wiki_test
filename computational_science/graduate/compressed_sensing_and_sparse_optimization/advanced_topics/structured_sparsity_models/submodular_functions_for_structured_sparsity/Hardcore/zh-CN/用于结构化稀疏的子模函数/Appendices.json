{
    "hands_on_practices": [
        {
            "introduction": "本实践将引导您从次模函数的基本定义出发，构建一个具体的结构化稀疏正则项。通过一个重叠组的例子，您将学会如何验证次模性，推导相应的Lovász扩展，并为LASSO类型的问题建立优化条件。这个过程将帮助您连接抽象理论与实际应用，理解次模函数如何自然地编码重叠结构 。",
            "id": "3483776",
            "problem": "考虑基集 $\\{1,2,3,4\\}$ 和重叠群组 $G_{1}=\\{1,2,3\\}$ 与 $G_{2}=\\{2,4\\}$。定义集合函数 $F:2^{\\{1,2,3,4\\}}\\to\\mathbb{R}_{+}$ 如下：\n$$\nF(S)=3\\,\\mathbf{1}\\{S\\cap G_{1}\\neq\\emptyset\\}+2\\,\\mathbf{1}\\{S\\cap G_{2}\\neq\\emptyset\\},\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。仅使用子模性和 Lovász 扩展的核心定义，按如下步骤进行：\n\n1. 从子模性的定义出发，证明 $F$ 是一个非递减子模函数，且 $F(\\emptyset)=0$。\n\n2. 从子模函数的 Lovász 扩展的定义出发，推导 $F$ 的 Lovász 扩展 $f:\\mathbb{R}^{4}\\to\\mathbb{R}$，然后推导其对称化范数 $\\|x\\|_{F}=f(|x|)$，并直接用 $x$ 的坐标表示。你的推导不能依赖于任何预先给出的公式；纯粹地从应用于 $F$ 的 Lovász 扩展定义来推导表达式。\n\n3. 使用对偶范数 $\\|\\cdot\\|_{F}^{*}$ 的定义 $\\|z\\|_{F}^{*}=\\sup\\{z^{\\top}x:\\|x\\|_{F}\\leq 1\\}$，推导在特殊情况 $z=(0,1,0,0)^{\\top}$ 下的对偶范数 $\\|z\\|_{F}^{*}$。\n\n4. 写出无约束凸优化问题\n$$\n\\min_{x\\in\\mathbb{R}^{4}}\\ \\frac{1}{2}\\|y-Ax\\|_{2}^{2}+\\lambda\\|x\\|_{F},\n$$\n的 Karush-Kuhn-Tucker (KKT) 条件，其中 $A\\in\\mathbb{R}^{m\\times 4}$，$y\\in\\mathbb{R}^{m}$，且 $\\lambda>0$；使用 $\\|x\\|_{F}$ 的次微分来指明平稳性条件。\n\n不要对数值进行四舍五入；提供精确表达式。将最终答案表示为单个解析表达式，即步骤 3 中获得的对偶范数值。",
            "solution": "该问题是有效的，因为它是数学上适定的、自包含的，并且基于子模函数和凸优化的成熟理论。我们将依次处理问题的四个部分。\n\n基集为 $V = \\{1, 2, 3, 4\\}$，群组为 $G_1 = \\{1, 2, 3\\}$ 和 $G_2 = \\{2, 4\\}$。集合函数 $F: 2^V \\to \\mathbb{R}_{+}$ 定义为 $F(S) = 3\\,\\mathbf{1}\\{S\\cap G_1 \\neq\\emptyset\\} + 2\\,\\mathbf{1}\\{S\\cap G_2 \\neq\\emptyset\\}$。\n\n1. 我们必须证明 $F$ 是一个非递减子模函数，且 $F(\\emptyset) = 0$。\n\n首先，我们计算 $F$ 在空集 $\\emptyset$ 上的值：\n$$\nF(\\emptyset) = 3\\,\\mathbf{1}\\{\\emptyset \\cap G_1 \\neq \\emptyset\\} + 2\\,\\mathbf{1}\\{\\emptyset \\cap G_2 \\neq \\emptyset\\} = 3\\,\\mathbf{1}\\{\\emptyset \\neq \\emptyset\\} + 2\\,\\mathbf{1}\\{\\emptyset \\neq \\emptyset\\} = 3(0) + 2(0) = 0\n$$\n所以，$F(\\emptyset)=0$ 得以确认。\n\n接下来，我们证明 $F$ 是非递减的。一个集合函数 $F$ 是非递减的，如果对于任意两个集合 $S \\subseteq T \\subseteq V$，我们有 $F(S) \\leq F(T)$。\n令 $S \\subseteq T$。对于任何群组 $G_i$，如果 $S \\cap G_i \\neq \\emptyset$，那么必然有 $T \\cap G_i \\neq \\emptyset$，因为 $S \\cap G_i \\subseteq T \\cap G_i$。这意味着指示函数的值不会减小：对于 $i \\in \\{1, 2\\}$，有 $\\mathbf{1}\\{S \\cap G_i \\neq \\emptyset\\} \\leq \\mathbf{1}\\{T \\cap G_i \\neq \\emptyset\\}$。由于权重 $w_1 = 3$ 和 $w_2 = 2$ 是正数，我们可以写出：\n$$\nF(S) = 3\\,\\mathbf{1}\\{S \\cap G_1 \\neq \\emptyset\\} + 2\\,\\mathbf{1}\\{S \\cap G_2 \\neq \\emptyset\\} \\leq 3\\,\\mathbf{1}\\{T \\cap G_1 \\neq \\emptyset\\} + 2\\,\\mathbf{1}\\{T \\cap G_2 \\neq \\emptyset\\} = F(T)\n$$\n因此，$F$ 是一个非递减函数。\n\n最后，我们证明子模性。一个集合函数 $F$ 是子模的，如果对于任意两个集合 $S, T \\subseteq V$，以下不等式成立：$F(S) + F(T) \\geq F(S \\cup T) + F(S \\cap T)$。\n函数 $F$ 是两个更简单的集合函数 $F_i(S) = \\mathbf{1}\\{S \\cap G_i \\neq \\emptyset\\}$ 的锥组合，$F(S) = 3 F_1(S) + 2 F_2(S)$。由于子模函数的集合是一个凸锥，如果我们能证明 $F_1$ 和 $F_2$ 是子模的，那么 $F$ 也必定是子模的。\n让我们证明对于任意固定的群组 $G \\subseteq V$，形如 $g(S) = \\mathbf{1}\\{S \\cap G \\neq \\emptyset\\}$ 的一般函数是子模的。我们需要证明 $g(S) + g(T) \\geq g(S \\cup T) + g(S \\cap T)$。\n令 $A = S \\cap G$ 和 $B = T \\cap G$。不等式变为：\n$$\n\\mathbf{1}\\{A \\neq \\emptyset\\} + \\mathbf{1}\\{B \\neq \\emptyset\\} \\geq \\mathbf{1}\\{(S \\cup T) \\cap G \\neq \\emptyset\\} + \\mathbf{1}\\{(S \\cap T) \\cap G \\neq \\emptyset\\}\n$$\n使用集合运算的分配律，$(S \\cup T) \\cap G = (S \\cap G) \\cup (T \\cap G) = A \\cup B$，以及 $(S \\cap T) \\cap G = (S \\cap G) \\cap (T \\cap G) = A \\cap B$。因此，不等式为：\n$$\n\\mathbf{1}\\{A \\neq \\emptyset\\} + \\mathbf{1}\\{B \\neq \\emptyset\\} \\geq \\mathbf{1}\\{A \\cup B \\neq \\emptyset\\} + \\mathbf{1}\\{A \\cap B \\neq \\emptyset\\}\n$$\n我们分情况检验：\n- 情况 1：$A = \\emptyset$ 且 $B = \\emptyset$。那么 $A \\cup B = \\emptyset$ 且 $A \\cap B = \\emptyset$。不等式为 $0 + 0 \\geq 0 + 0$，成立。\n- 情况 2：$A \\neq \\emptyset$ 且 $B = \\emptyset$。那么 $A \\cup B = A \\neq \\emptyset$ 且 $A \\cap B = \\emptyset$。不等式为 $1 + 0 \\geq 1 + 0$，成立。$A = \\emptyset$ 且 $B \\neq \\emptyset$ 的情况是对称的。\n- 情况 3：$A \\neq \\emptyset$ 且 $B \\neq \\emptyset$。那么 $A \\cup B \\neq \\emptyset$。不等式为 $1 + 1 \\geq 1 + \\mathbf{1}\\{A \\cap B \\neq \\emptyset\\}$。这可以化简为 $1 \\geq \\mathbf{1}\\{A \\cap B \\neq \\emptyset\\}$，此式恒成立，因为指示函数的值最大为 1。\n由于不等式在所有情况下都成立，函数 $g(S)$ 是子模的。由此可知 $F_1(S)$ 和 $F_2(S)$ 是子模的，因此 $F(S)$ 也是子模的。\n\n2. 我们推导 $F$ 的 Lovász 扩展 $f:\\mathbb{R}^4 \\to \\mathbb{R}$，以及相应的对称化范数 $\\|x\\|_F = f(|x|)$。\n\n对于一个子模函数 $F$ 且 $F(\\emptyset)=0$，其 Lovász 扩展可以为一个向量 $u \\in \\mathbb{R}^n_+$ 定义，方法是将其分量排序为 $u_{\\pi(1)} \\ge u_{\\pi(2)} \\ge \\dots \\ge u_{\\pi(n)} \\ge u_{\\pi(n+1)} = 0$。该扩展由下式给出：\n$$\nf(u) = \\sum_{i=1}^{n} (u_{\\pi(i)} - u_{\\pi(i+1)}) F(S_i)\n$$\n其中 $S_i = \\{\\pi(1), \\dots, \\pi(i)\\}$。Lovász 扩展关于 $F$ 是线性的，所以对于 $F = 3F_1 + 2F_2$，其扩展为 $f(u) = 3f_1(u) + 2f_2(u)$，其中 $f_i$ 是 $F_i(S) = \\mathbf{1}\\{S \\cap G_i \\neq \\emptyset\\}$ 的 Lovász 扩展。\n\n让我们推导一般函数 $F_G(S) = \\mathbf{1}\\{S \\cap G \\neq \\emptyset\\}$ 和 $u \\in \\mathbb{R}^n_+$ 的 Lovász 扩展 $f_G$ 的形式。\n$$\nf_G(u) = \\sum_{i=1}^{n} (u_{\\pi(i)} - u_{\\pi(i+1)}) \\mathbf{1}\\{S_i \\cap G \\neq \\emptyset\\}\n$$\n令 $k$ 为使得 $S_i$ 与 $G$ 有非空交集的第一个索引 $i$。这意味着 $\\pi(k) \\in G$，但对于所有 $j  k$，$\\pi(j) \\notin G$。对于所有 $i \\ge k$，$S_i \\supseteq S_k$，所以 $S_i \\cap G \\neq \\emptyset$ 且 $\\mathbf{1}\\{S_i \\cap G \\neq \\emptyset\\} = 1$。对于 $i  k$，指示函数为 0。该和式成为一个伸缩级数：\n$$\nf_G(u) = \\sum_{i=k}^{n} (u_{\\pi(i)} - u_{\\pi(i+1)}) = (u_{\\pi(k)} - u_{\\pi(k+1)}) + \\dots + (u_{\\pi(n)} - u_{\\pi(n+1)}) = u_{\\pi(k)} - u_{\\pi(n+1)} = u_{\\pi(k)}\n$$\n分量 $u_{\\pi(k)}$ 是所有索引 $j$ 在群组 $G$ 中的分量 $u_j$ 中的最大值。因此，$f_G(u) = \\max_{j \\in G} u_j$。\n\n将此结果应用于我们的函数 $F$ 和一个向量 $u \\in \\mathbb{R}^4_+$：\n$f(u) = 3 f_1(u) + 2 f_2(u) = 3 \\max_{j \\in G_1} u_j + 2 \\max_{j \\in G_2} u_j$。\n对于 $G_1 = \\{1, 2, 3\\}$ 和 $G_2 = \\{2, 4\\}$，我们有：\n$f(u) = 3 \\max(u_1, u_2, u_3) + 2 \\max(u_2, u_4)$。\n\n对称化范数 $\\|x\\|_F$ 定义为在 $x$ 各分量绝对值组成的向量上求值的 Lovász 扩展，即 $\\|x\\|_F = f(|x|)$，其中 $|x| = (|x_1|, |x_2|, |x_3|, |x_4|)^\\top$。\n$$\n\\|x\\|_F = 3 \\max(|x_1|, |x_2|, |x_3|) + 2 \\max(|x_2|, |x_4|)\n$$\n\n3. 我们推导 $z = (0, 1, 0, 0)^\\top$ 的对偶范数 $\\|z\\|_F^*$。\n\n对偶范数定义为 $\\|z\\|_F^* = \\sup\\{z^\\top x : \\|x\\|_F \\leq 1\\}$。对于给定的 $z$，这变为：\n$$\n\\|z\\|_F^* = \\sup \\{ x_2 \\ : \\ 3 \\max(|x_1|, |x_2|, |x_3|) + 2 \\max(|x_2|, |x_4|) \\le 1 \\}\n$$\n我们希望在范数约束下最大化 $x_2$。为此，我们可以假设 $x_2 > 0$，所以 $|x_2| = x_2$。\n我们来找一个 $x_2$ 的上界。范数表达式包含两个含有 $|x_2|$ 的项。我们有以下不等式：\n$\\max(|x_1|, |x_2|, |x_3|) \\ge |x_2|$\n$\\max(|x_2|, |x_4|) \\ge |x_2|$\n使用这些，我们可以建立范数 $\\|x\\|_F$ 的一个下界：\n$$\n\\|x\\|_F = 3 \\max(|x_1|, |x_2|, |x_3|) + 2 \\max(|x_2|, |x_4|) \\ge 3|x_2| + 2|x_2| = 5|x_2|\n$$\n约束 $\\|x\\|_F \\le 1$ 因此意味着 $5|x_2| \\le 1$，即 $|x_2| \\le \\frac{1}{5}$。这为 $x_2$ 提供了一个上界 $\\frac{1}{5}$。\n\n我们现在检查这个上界是否可达。为了最大化 $x_2$，我们应该使其他分量 $|x_1|, |x_3|, |x_4|$ 尽可能小，以放宽范数约束。我们设 $x_1 = 0$，$x_3 = 0$ 和 $x_4 = 0$。约束变为：\n$$\n3 \\max(0, |x_2|, 0) + 2 \\max(|x_2|, 0) \\le 1\n$$\n假设 $x_2 > 0$：\n$$\n3x_2 + 2x_2 \\le 1 \\implies 5x_2 \\le 1 \\implies x_2 \\le \\frac{1}{5}\n$$\n$x_2$ 的最大值是 $\\frac{1}{5}$，在点 $x = (0, \\frac{1}{5}, 0, 0)^\\top$ 处取得。这个值与我们推导出的上界相符。\n因此，上确界是 $\\frac{1}{5}$。\n\n4. 我们写出该优化问题的 Karush-Kuhn-Tucker (KKT) 条件。\n\n问题是 $\\min_{x\\in\\mathbb{R}^{4}}\\ \\frac{1}{2}\\|y-Ax\\|_{2}^{2}+\\lambda\\|x\\|_{F}$。\n令目标函数为 $L(x) = g(x) + h(x)$，其中 $g(x) = \\frac{1}{2}\\|y-Ax\\|_{2}^{2}$ 是光滑且凸的，而 $h(x) = \\lambda\\|x\\|_{F}$ 是凸但非光滑的。这是一个无约束凸优化问题。其充要最优性条件（平稳性）是零向量必须属于目标函数在极小值点 $x^*$ 处的次微分：\n$$\n0 \\in \\partial L(x^*)\n$$\n使用次微分的和法则，由于 $g(x)$ 是可微的，该法则在此适用：\n$$\n\\partial L(x^*) = \\nabla g(x^*) + \\partial h(x^*)\n$$\n最小二乘项 $g(x) = \\frac{1}{2}(y-Ax)^\\top(y-Ax)$ 的梯度是：\n$$\n\\nabla g(x) = -A^\\top(y-Ax) = A^\\top(Ax-y)\n$$\n范数项 $h(x) = \\lambda\\|x\\|_{F}$ 的次微分是：\n$$\n\\partial h(x) = \\lambda \\partial \\|x\\|_F\n$$\n结合这些，解 $x^*$ 处的最优性条件是：\n$$\n0 \\in A^\\top(Ax^*-y) + \\lambda \\partial \\|x^*\\|_F\n$$\n这可以重写为 $A^\\top(y-Ax^*) \\in \\lambda \\partial \\|x^*\\|_F$。令 $s$ 为一个次梯度向量，$s \\in \\partial \\|x^*\\|_F$。则条件为 $A^\\top(y-Ax^*) = \\lambda s$。\n次微分 $\\partial \\|x^*\\|_F$ 是根据对偶范数 $\\|\\cdot\\|_F^*$ 定义的：\n$$\n\\partial \\|x^*\\|_F = \\{ v \\in \\mathbb{R}^4 \\mid \\|v\\|_F^* \\le 1 \\text{ 且 } v^\\top x^* = \\|x^*\\|_F \\}\n$$\n因此，完整的 KKT 条件是，存在一个向量 $s \\in \\mathbb{R}^4$，使得在极小值点 $x^*$ 处：\n1. 平稳性条件：$A^\\top(y-Ax^*) = \\lambda s$\n2. 次梯度条件：$\\|s\\|_F^* \\leq 1$ 且 $s^\\top x^* = \\|x^*\\|_F$。\n这些条件完全刻画了解 $x^*$。",
            "answer": "$$\n\\boxed{\\frac{1}{5}}\n$$"
        },
        {
            "introduction": "当我们用子模正则项构建了优化问题后，下一步就是求解它。本练习将重点推导和应用像ISTA和FISTA这样的近端梯度算法，它们是解决此类复合优化问题的核心工具。您将探索计算Lovász扩展的近端算子这一关键步骤，理解其与几何投影的联系，并学习一种针对重要的基数惩罚项的高效求解算法 。",
            "id": "3483796",
            "problem": "考虑一个复合凸最小化问题，其正则化项是由一个子模函数产生的结构化稀疏性诱导项。给定 $A \\in \\mathbb{R}^{m \\times n}$ 和 $b \\in \\mathbb{R}^{m}$，并设 $f:2^{\\{1,\\dots,n\\}} \\to \\mathbb{R}_{+}$ 是一个归一化的 ($f(\\varnothing)=0$)、非递减的（单调的）子模集函数，其 Lovász 扩展为 $\\hat{f}:\\mathbb{R}^{n} \\to \\mathbb{R}_{+}$。考虑目标函数\n$$\nF(x) \\triangleq \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\,\\hat{f}(x),\n$$\n其中 $\\lambda0$。\n\n任务：\n1. 仅使用凸可微性、梯度利普希茨连续性和近端算子的定义，从第一性原理推导最小化 $F(x)$ 的迭代收缩阈值算法（ISTA）和快速迭代收缩阈值算法（FISTA）的更新规则。您的推导必须从具有 $L$-利普希茨梯度的光滑函数的二次上界以及凸函数的近端映射的定义开始。\n2. 对于一般的单调子模函数 $f$，说明如何高效地评估 Lovász 扩展的近端算子，并用在与 $f$ 关联的多面体上的投影来表示。陈述将近端评估简化为欧几里得投影的关键几何关系，并明确指出该多面体。\n3. 现在，特化为基于基数的单调子模函数 $f$，定义为 $f(S) = \\sum_{k=1}^{|S|} v_{k}$，其中权重 $v_{1} \\geq v_{2} \\geq \\dots \\geq v_{n} \\geq 0$ 是非增的。在这种情况下，Lovász 扩展是有序加权 $\\ell_{1}$ 范数 $\\hat{f}(x) = \\sum_{k=1}^{n} v_{k} |x|_{(k)}$，其中 $|x|_{(1)} \\geq \\dots \\geq |x|_{(n)}$ 表示 $x$ 的绝对值条目的递减重排。解释对于任意 $y \\in \\mathbb{R}^{n}$，在 $\\mathcal{O}(n \\log n)$ 时间内产生近端算子 $\\mathrm{prox}_{\\lambda \\hat{f}}(y)$ 的排序和保序回归过程，并详细说明池邻违规者算法（pool-adjacent-violators algorithm）的作用。\n\n最后，考虑一个具体实例，其中 $n=m=3$, $A=I_{3}$, $\\lambda=1$, 权重 $v=(2,1,0.5)$ 且 $b=(3,1,-2)^{\\top}$。从 $x^{0}=0$ 开始，执行一次 ISTA 迭代，步长等于 $\\nabla \\left(\\frac{1}{2}\\|Ax-b\\|_{2}^{2}\\right)$ 的利普希茨常数的倒数。将结果 $x^{1}$ 表示为一个行向量，使用一个 $1 \\times 3$ 的行矩阵。无需四舍五入，不涉及物理单位。",
            "solution": "该问题是适定的，在凸优化领域有坚实的科学基础，并为得到唯一解提供了所有必要信息。因此，该问题被认定为有效。\n\n待最小化的目标函数是复合形式 $F(x) = g(x) + h(x)$，其中：\n- $g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 是一个光滑、凸且可微的函数。\n- $h(x) = \\lambda \\,\\hat{f}(x)$ 是一个凸函数，但通常不可微。由于 $f$ 是一个归一化的、非递减的子模集函数，其 Lovász 扩展 $\\hat{f}$ 是凸的。因为 $\\lambda  0$，$h(x)$ 也是凸的。\n\n**1. ISTA 和 FISTA 的推导**\n\n近端梯度方法背后的核心原理是通过对光滑部分 $g(x)$ 建立局部二次近似，同时保持非光滑部分 $h(x)$ 的精确形式，来迭代地最小化目标函数。\n\n$g(x)$ 的梯度是 $\\nabla g(x) = A^{\\top}(Ax - b)$。为使 $g(x)$ 具有 $L$-利普希茨连续梯度，对于某个常数 $L  0$，必须满足以下条件：\n$$\n\\|\\nabla g(x) - \\nabla g(y)\\|_{2} \\leq L\\|x-y\\|_{2} \\quad \\forall x, y \\in \\mathbb{R}^{n}\n$$\n计算梯度之差：\n$$\n\\|\\nabla g(x) - \\nabla g(y)\\|_{2} = \\|A^{\\top}(Ax - b) - A^{\\top}(Ay - b)\\|_{2} = \\|A^{\\top}A(x-y)\\|_{2} \\leq \\|A^{\\top}A\\|_{2} \\|x-y\\|_{2}\n$$\n其中 $\\|A^{\\top}A\\|_{2}$ 是 $A^{\\top}A$ 的谱范数。因此，最小的可能利普希茨常数是 $L = \\|A^{\\top}A\\|_{2} = \\sigma_{\\max}(A)^2$，其中 $\\sigma_{\\max}(A)$ 是 $A$ 的最大奇异值。\n\n具有 $L$-利普希茨梯度的函数的一个基本性质是下降引理，它提供了该函数的一个二次上界（一个上函数）：\n$$\ng(x) \\leq g(x^{k}) + \\langle \\nabla g(x^{k}), x - x^{k} \\rangle + \\frac{L}{2}\\|x - x^{k}\\|_{2}^{2}\n$$\n在每次迭代 $k$ 中，我们通过最小化 $g(x)$ 的这个上界加上非光滑项 $h(x)$ 来找到下一个迭代点 $x^{k+1}$：\n$$\nx^{k+1} = \\underset{x}{\\arg\\min} \\left( g(x^{k}) + \\langle \\nabla g(x^{k}), x - x^{k} \\rangle + \\frac{L}{2}\\|x - x^{k}\\|_{2}^{2} + h(x) \\right)\n$$\n我们可以舍去相对于 $x$ 是常数的项（即 $g(x^k)$ 和仅涉及 $x^k$ 的项），并对其余涉及 $x$ 的项进行配方：\n\\begin{align*}\nx^{k+1} = \\underset{x}{\\arg\\min} \\left( \\langle \\nabla g(x^{k}), x \\rangle + \\frac{L}{2}\\|x - x^{k}\\|_{2}^{2} + h(x) \\right) \\\\\n= \\underset{x}{\\arg\\min} \\left( \\frac{L}{2} \\|x\\|_{2}^{2} - L \\langle x, x^{k} \\rangle + \\langle \\nabla g(x^{k}), x \\rangle + h(x) \\right) \\\\\n= \\underset{x}{\\arg\\min} \\left( \\frac{L}{2} \\|x\\|_{2}^{2} - \\langle x, L x^{k} - \\nabla g(x^{k}) \\rangle + h(x) \\right) \\\\\n= \\underset{x}{\\arg\\min} \\left( \\frac{L}{2} \\left\\| x - \\left(x^{k} - \\frac{1}{L}\\nabla g(x^{k})\\right) \\right\\|_{2}^{2} + h(x) \\right)\n\\end{align*}\n这个最小化问题是参数为 $1/L$ 的 $h(x)$ 的近端算子的定义。一个凸函数 $\\phi$ 的近端算子定义为 $\\mathrm{prox}_{\\phi}(y) \\triangleq \\underset{x}{\\arg\\min} \\left( \\frac{1}{2}\\|x-y\\|_{2}^{2} + \\phi(x) \\right)$。\n在我们的例子中，目标函数等价于 $\\underset{x}{\\arg\\min} \\left( \\frac{1}{2}\\left\\| x - \\left(x^{k} - \\frac{1}{L}\\nabla g(x^{k})\\right) \\right\\|_{2}^{2} + \\frac{1}{L}h(x) \\right)$。\n令步长为 $\\eta = 1/L$，则更新规则为：\n$$\nx^{k+1} = \\mathrm{prox}_{\\eta h}\\left(x^{k} - \\eta \\nabla g(x^{k})\\right)\n$$\n代入 $h(x) = \\lambda \\hat{f}(x)$，我们得到**迭代收缩阈值算法 (ISTA)** 的更新规则：\n$$\nx^{k+1} = \\mathrm{prox}_{\\eta \\lambda \\hat{f}}\\left(x^{k} - \\eta A^{\\top}(Ax^{k} - b)\\right)\n$$\n**快速迭代收缩阈值算法 (FISTA)** 引入了一个动量项来加速收敛。它将相同的近端梯度步骤应用于一个外推点 $y^k$，而不是前一个迭代点 $x^{k-1}$。更新规则如下：\n初始化 $x^0$，令 $y^1 = x^0$，$t_1 = 1$。对于 $k \\geq 1$：\n\\begin{enumerate}\n    \\item 在 $y^{k}$ 处执行近端梯度步骤：$x^{k} = \\mathrm{prox}_{\\eta \\lambda \\hat{f}}\\left(y^{k} - \\eta \\nabla g(y^{k})\\right)$\n    \\item 更新动量参数：$t_{k+1} = \\frac{1 + \\sqrt{1 + 4t_k^2}}{2}$\n    \\item 形成下一个外推点：$y^{k+1} = x^{k} + \\frac{t_k - 1}{t_{k+1}}(x^{k} - x^{k-1})$\n\\end{enumerate}\n\n**2. Lovász 扩展的近端算子**\n\n任务是评估 $\\mathrm{prox}_{\\gamma \\hat{f}}(y) = \\underset{x}{\\arg\\min} \\left( \\frac{1}{2}\\|x-y\\|_{2}^{2} + \\gamma \\hat{f}(x) \\right)$，其中 $\\gamma = \\eta\\lambda$。\n子模函数 $f$ 的 Lovász 扩展 $\\hat{f}(x)$ 可以表示为相关联的基多面体 $B(f)$ 的支撑函数，即 $\\hat{f}(x) = \\max_{s \\in B(f)} s^{\\top}x$。基多面体定义为：\n$$\nB(f) = \\left\\{ s \\in \\mathbb{R}^n \\mid \\sum_{i=1}^n s_i = f(\\{1,\\dots,n\\}), \\text{ and } \\forall S \\subseteq \\{1,\\dots,n\\}, \\sum_{i \\in S} s_i \\le f(S) \\right\\}\n$$\n将此代入近端问题，我们得到一个极小极大问题：\n$$\n\\mathrm{prox}_{\\gamma \\hat{f}}(y) = \\underset{x}{\\arg\\min} \\left( \\frac{1}{2}\\|x-y\\|_{2}^{2} + \\gamma \\max_{s \\in B(f)} s^{\\top}x \\right)\n$$\n由于目标函数在 $x$ 上是凸的，在 $s$ 上是凹的（线性的），并且域 $B(f)$ 是紧集，我们可以交换 min 和 max 算子（Sion 极小极大定理）：\n$$\n\\max_{s \\in B(f)} \\min_{x} \\left( \\frac{1}{2}\\|x-y\\|_{2}^{2} + \\gamma s^{\\top}x \\right)\n$$\n关于 $x$ 的内部最小化是无约束的。令梯度为零得到 $x-y+\\gamma s = 0$，这意味着最小化点是 $x^*(s) = y - \\gamma s$。将此代回表达式中：\n$$\n\\max_{s \\in B(f)} \\left( \\frac{1}{2}\\|(y - \\gamma s) - y\\|_{2}^{2} + \\gamma s^{\\top}(y - \\gamma s) \\right) = \\max_{s \\in B(f)} \\left( \\frac{\\gamma^2}{2}\\|s\\|_{2}^{2} + \\gamma s^{\\top}y - \\gamma^2 \\|s\\|_{2}^{2} \\right) = \\max_{s \\in B(f)} \\left( \\gamma s^{\\top}y - \\frac{\\gamma^2}{2}\\|s\\|_{2}^{2} \\right)\n$$\n找到最大化的 $s$ 等价于最小化其负数：\n$$\n\\underset{s \\in B(f)}{\\arg\\min} \\left( \\frac{\\gamma^2}{2}\\|s\\|_{2}^{2} - \\gamma s^{\\top}y \\right) = \\underset{s \\in B(f)}{\\arg\\min} \\frac{\\gamma^2}{2} \\left\\| s - \\frac{y}{\\gamma} \\right\\|_{2}^{2}\n$$\n解，我们称之为 $s^*$，是向量 $y/\\gamma$ 在基多面体 $B(f)$ 上的欧几里得投影：\n$$\ns^* = \\mathrm{proj}_{B(f)}\\left(\\frac{y}{\\gamma}\\right)\n$$\n关键的几何关系是，近端问题的解 $x^*$ 由我们之前找到的原始-对偶关系给出：\n$$\nx^* = y - \\gamma s^* \\quad \\implies \\quad \\mathrm{prox}_{\\gamma \\hat{f}}(y) = y - \\gamma \\, \\mathrm{proj}_{B(f)}\\left(\\frac{y}{\\gamma}\\right)\n$$\n因此，评估 Lovász 扩展的近端算子被简化为在相应的基多面体上的欧几里得投影。\n\n**3. 基于基数的函数的近端算子**\n\n对于特定情况 $f(S) = \\sum_{k=1}^{|S|} v_{k}$，其中 $v_{1} \\geq v_{2} \\geq \\dots \\geq v_{n} \\geq 0$，Lovász 扩展是有序加权 $\\ell_1$ 范数（也称为 OWL 范数）：$\\hat{f}(x) = \\sum_{k=1}^{n} v_{k} |x|_{(k)}$，其中 $|x|_{(k)}$ 是 $x$ 中条目绝对值的第 $k$ 大值。\n\n我们需要计算 $x^* = \\mathrm{prox}_{\\lambda \\hat{f}}(y) = \\underset{x}{\\arg\\min} \\frac{1}{2}\\|x-y\\|_2^2 + \\lambda \\sum_{k=1}^n v_k |x|_{(k)}$。\n由于正则化项的对称性，解 $x^*$ 必须满足对于 $y_i \\ne 0$ 有 $\\mathrm{sign}(x^*_i) = \\mathrm{sign}(y_i)$，并且解的绝对值的排序必须与 $y$ 的绝对值的排序相匹配。也就是说，如果 $|y_i| \\ge |y_j|$，那么 $|x^*_i| \\ge |x^*_j|$。\n\n这使我们可以在对 $y$ 的绝对值进行排序后求解该问题，然后重构解。过程如下：\n1.  令 $u = |y|$ 为 $y$ 的绝对值向量。令 $\\sigma = \\mathrm{sign}(y)$ 为符号向量。\n2.  找到一个置换 $\\pi$，它将 $u$ 按降序排序，使得 $u_{\\pi(1)} \\ge u_{\\pi(2)} \\ge \\dots \\ge u_{\\pi(n)}$。令 $u_{\\text{sorted}} = (u_{\\pi(1)}, \\dots, u_{\\pi(n)})$。\n3.  对于已排序的非负解值 $z=(z_1, \\dots, z_n)$，优化问题变为：\n    $$\n    \\underset{z_1 \\ge \\dots \\ge z_n \\ge 0}{\\min} \\frac{1}{2}\\sum_{k=1}^n (z_k - u_{\\pi(k)})^2 + \\lambda \\sum_{k=1}^n v_k z_k\n    $$\n    这等价于找到一个向量在非负、非增向量锥上的投影。通过配方可以重写目标函数：\n    $$\n    \\underset{z_1 \\ge \\dots \\ge z_n \\ge 0}{\\min} \\frac{1}{2}\\sum_{k=1}^n (z_k - (u_{\\pi(k)} - \\lambda v_k))^2\n    $$\n4.  令 $c_k = u_{\\pi(k)} - \\lambda v_k$。我们想要在约束 $z_1 \\ge \\dots \\ge z_n \\ge 0$ 下找到与向量 $c=(c_1, \\dots, c_n)$ 最接近的向量 $z$。这是一个带有非负约束的保序回归问题。\n5.  这分两步解决。首先，我们找到与 $c$ 最接近的非增向量 $z'$。这是一个标准的保序回归问题，可以使用池邻违规者算法 (PAVA) 在 $\\mathcal{O}(n)$ 时间内解决。PAVA 遍历向量 $c$。如果发现某个分量 $c_{k+1}$ 违反了非增顺序（即 $c_k  c_{k+1}$），它会对违规所涉及的分量块进行平均，并用该平均值替换该块中的每个分量。重复此过程，直到不再有违规为止。\n6.  第二步，施加非负约束 $z_k \\ge 0$。由于一个已经是单调非增的向量在其非负象限上的投影会保持其顺序，所以排序后值的最终解为 $z_k = \\max(0, z'_k)$。\n7.  通过重新应用置换和符号来重构最终解 $x^*$：创建一个向量 $x'_{\\text{abs}}$，使得对于 $k=1, \\dots, n$ 有 $(x'_{\\text{abs}})_{\\pi(k)} = z_k$。那么最终结果是 $x^*_i = \\sigma_i (x'_{\\text{abs}})_i$。\n\n主要的计算成本是初始时对 $|y|$ 的排序，这需要 $\\mathcal{O}(n \\log n)$ 的时间。\n\n**4. 具体实例计算**\n\n给定：$n=m=3$, $A=I_{3}$, $\\lambda=1$, $v=(2,1,0.5)$, $b=(3,1,-2)^{\\top}$ 并且 $x^{0}=(0,0,0)^{\\top}$。我们执行一次 ISTA 迭代。\n\n目标函数是 $F(x) = \\frac{1}{2}\\|x-b\\|_2^2 + \\hat{f}(x)$。\n光滑部分是 $g(x) = \\frac{1}{2}\\|x-b\\|_2^2$，其梯度为 $\\nabla g(x) = x-b$。\n$\\nabla g(x)$ 的利普希茨常数为 $L = \\|I_3\\|_2 = 1$。\n步长为 $\\eta = 1/L = 1$。\n\n第一次 ISTA 迭代是：\n$x^{1} = \\mathrm{prox}_{\\eta \\lambda \\hat{f}}(x^0 - \\eta \\nabla g(x^0))$\n$x^{1} = \\mathrm{prox}_{1 \\cdot 1 \\cdot \\hat{f}}(x^0 - 1 \\cdot (x^0 - b)) = \\mathrm{prox}_{\\hat{f}}(b)$。\n我们需要计算 $\\mathrm{prox}_{\\hat{f}}((3,1,-2)^{\\top})$。令 $y=(3,1,-2)^{\\top}$。\n\n我们使用第 3 部分的步骤：\n1.  绝对值：$u = |y| = (|3|, |1|, |-2|) = (3, 1, 2)$。\n    符号：$\\sigma = \\mathrm{sign}(y) = (1, 1, -1)$。\n2.  排序后的绝对值：$u$ 排序后的值为 $(3, 2, 1)$。对应的原始索引是 $(1, 3, 2)$。所以， $|y|_{(1)} = 3$, $|y|_{(2)} = 2$, $|y|_{(3)} = 1$。\n3.  权重向量是 $v=(v_1, v_2, v_3) = (2, 1, 0.5)$。$\\lambda=1$。\n4.  构成向量 $c = (|y|_{(k)} - \\lambda v_k)_{k=1,2,3}$：\n    $c_1 = |y|_{(1)} - \\lambda v_1 = 3 - 1 \\cdot 2 = 1$。\n    $c_2 = |y|_{(2)} - \\lambda v_2 = 2 - 1 \\cdot 1 = 1$。\n    $c_3 = |y|_{(3)} - \\lambda v_3 = 1 - 1 \\cdot 0.5 = 0.5$。\n    所以，$c = (1, 1, 0.5)$。\n5.  执行保序回归。向量 $c$ 已经是单调非增的（$1 \\ge 1 \\ge 0.5$），所以 PAVA 返回 $c$ 本身。令此为 $z' = (1, 1, 0.5)$。\n6.  投影到非负锥上。$z'$ 的所有条目都是非负的，所以 $z=z'=(1, 1, 0.5)$。这是解的排序后绝对值向量。\n7.  重构解。排序后的值 $z$ 对应于原始索引 $(1, 3, 2)$。\n    - 最大的绝对值 $z_1=1$ 对应于索引 $1$。\n    - 第二大的绝对值 $z_2=1$ 对应于索引 $3$。\n    - 最小的绝对值 $z_3=0.5$ 对应于索引 $2$。\n    所以，解的绝对值向量是 $|x^1| = (1, 0.5, 1)$。\n8.  应用符号 $\\sigma=(1, 1, -1)$：\n    $x^1_1 = 1 \\cdot 1 = 1$。\n    $x^1_2 = 1 \\cdot 0.5 = 0.5$。\n    $x^1_3 = -1 \\cdot 1 = -1$。\n一次 ISTA 迭代的结果是 $x^1 = (1, 0.5, -1)^{\\top}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  0.5  -1\n\\end{pmatrix}\n}\n$$"
        }
    ]
}