## 引言
从[X射线晶体学](@entry_id:153528)到天文学，许多前沿科学和工程领域都面临一个共同的挑战：我们只能测量到波的强度（振幅），而其相位信息却在探测过程中丢失了。这一“相位恢复”问题是信号处理中的一个经典难题，因为相位信息的缺失使得从测量数据中重建原始信号成为一个固有的不适定（ill-posed）问题，充满了模糊性和不确定性。然而，当信号本身具有特定结构，例如[稀疏性](@entry_id:136793)时，唯一重建信号的可能性便得以展现。

本文旨在系统性地解决这一挑战，重点关注现代[非凸优化](@entry_id:634396)方法，特别是[Wirtinger流](@entry_id:756740)及其在相关盲[反卷积](@entry_id:141233)问题中的应用。传统方法或受困于计算复杂度，或缺乏理论收敛保证，而[Wirtinger流](@entry_id:756740)等新兴算法在理论与实践之间取得了卓越的平衡，为处理大规模、高维度的相位恢复问题开辟了新途径。

为了帮助您全面掌握这一领域，本文将分为三个核心部分。在“原理与机制”一章中，我们将从第一性原理出发，剖析相位恢复的数学模型、内在模糊性，并深入探讨以[Wirtinger流](@entry_id:756740)为代表的非凸梯度方法的运作机制及其与凸方法的比较。接着，在“应用与[交叉](@entry_id:147634)学科联系”一章中，我们将这些理论应用于[计算成像](@entry_id:170703)等实际场景，讨论如何通过编码设计来确保可解性，并介绍一系列应对噪声和大规模数据的实用算法增强技术。最后，“动手实践”部分将提供精选的编程练习，引导您亲手实现和分析这些算法，将理论知识转化为实践能力。

## 原理与机制

本章旨在深入探讨[稀疏相位恢复](@entry_id:755116)及相关问题的核心原理与机制。在前一章介绍背景之后，我们将系统性地剖析该领域的基础挑战、关键数学结构，以及主流算法[范式](@entry_id:161181)背后的驱动力。我们将从问题的基本定义出发，揭示其固有的不确定性，阐明[稀疏性](@entry_id:136793)等[先验信息](@entry_id:753750)如何帮助克服这些挑战，并详细分析以[Wirtinger流](@entry_id:756740)为代表的现代[非凸优化](@entry_id:634396)方法的机制、优势与局限性。

### 相位恢复问题：测量模型与内在模糊性

相位恢复的核心任务是从一系列仅包含振幅（或强度）信息的线性测量中重建一个未知信号。这个过程从根本上就充满了挑战，因为信息的丢失——即相位的丢失——会导致解的非唯一性。

#### 二次测量模型

标准的相位恢复问题是在以下二次测量模型下进行的：一个未知的复数信号$x \in \mathbb{C}^{n}$通过$m$个已知的**传感向量** (sensing vectors) $a_{i} \in \mathbb{C}^{n}$进行观测。我们能获取的并非是线性[内积](@entry_id:158127)$\langle a_{i}, x \rangle$，而是其幅值的平方，即**强度** (intensity)：

$y_{i} = |\langle a_{i}, x \rangle|^{2}, \quad i = 1, \dots, m$

这里，$y_i$是实数值的测量结果。这个模型在物理学（如X射线晶体学、相干衍射成像）和工程学（如光学、[声学](@entry_id:265335)）的许多领域中都自然出现。问题的核心挑战在于，从这组[二次方程](@entry_id:163234)中反解出唯一的信号$x$。

#### [全局相位](@entry_id:147947)模糊性

该测量模型存在一个最基本、最普遍的模糊性。对于任意一个解$x$，考虑另一个信号$x' = e^{\mathrm{i}\phi} x$，其中$\phi \in \mathbb{R}$是任意实数相位。我们将$x'$代入测量模型：

$|\langle a_{i}, x' \rangle|^{2} = |\langle a_{i}, e^{\mathrm{i}\phi} x \rangle|^{2} = |e^{\mathrm{i}\phi} \langle a_{i}, x \rangle|^{2} = |e^{\mathrm{i}\phi}|^{2} |\langle a_{i}, x \rangle|^{2} = 1 \cdot y_{i} = y_{i}$

这表明，信号$x$与其任意[全局相位](@entry_id:147947)旋转后的版本$e^{\mathrm{i}\phi}x$在观测上是无法区分的。它们生成了完全相同的测量值。因此，相位恢复的解在最好情况下也只能确定到一个**[全局相位](@entry_id:147947)因子** (global phase factor)的程度。我们称信号$x$与$x'$在此意义下等价，它们属于同一个等价类。在探讨**[可辨识性](@entry_id:194150)** (identifiability)时，我们所寻求的“唯一解”通常指的是在这个等价类意义下的唯一性  。

#### 更深层次的结构性模糊性

除了[全局相位](@entry_id:147947)模糊性，还存在更复杂的结构性模糊性。这些模糊性会导致即使两个信号不满足简单的相位旋转关系，它们也可能产生完全相同的强度测量值。

一个经典的例子出现在一维[离散时间信号](@entry_id:272771)的[傅里叶变换](@entry_id:142120)相位恢复中。考虑一个[实数序列](@entry_id:141090)$x \in \mathbb{R}^{3}$，其Z变换为$X(z)$。我们只测量其[离散时间傅里叶变换](@entry_id:196741)的幅值$|X(e^{\mathrm{i}\omega})|$。假设$X(z)$可以分解为$X(z) = (1 - a z^{-1})(1 - b z^{-1})$，其中$a,b$是实数，且$a > 1, 0  b  1$。这意味着$X(z)$的一个零点$z=a$在单位圆外，另一个零点$z=b$在单位圆内。

我们可以构造一个新的[Z变换](@entry_id:157804)$Y(z)$，方法是“翻转”那个在[单位圆](@entry_id:267290)外的零点。具体来说，我们将零点$z=a$替换为其倒数$z=a^{-1}$，并引入一个缩放因子。考虑$Y(z) = a(1 - a^{-1} z^{-1})(1 - b z^{-1})$。通过代数推导可以证明，对于所有频率$\omega$，其[傅里叶变换](@entry_id:142120)的幅值与原信号完全相同，即$|Y(e^{\mathrm{i}\omega})| = |X(e^{\mathrm{i}\omega})|$。然而，通过展开$Y(z)$得到的信号$y$的系数向量为$\begin{pmatrix} a  -(ab+1)  b \end{pmatrix}$，而原信号$x$的系数向量为$\begin{pmatrix} 1  -(a+b)  ab \end{pmatrix}$。在$a>1$的条件下，显然$y$既不等于$x$也不等于$-x$ 。

这个“零点翻转”的例子揭示了一个深刻的原理：信号的[自相关函数](@entry_id:138327)决定了其[傅里叶变换](@entry_id:142120)的功率谱（即幅值的平方）。不同的信号可能拥有相同的自相关函数，从而导致相同的傅里叶强度。在更一般的情况下，尤其是在使用[傅里叶变换](@entry_id:142120)等结构化测量时，如果两个不同的稀疏支撑集（非零元素的位置集合）具有相同的成对索引[差集](@entry_id:140904)（也称为同度量集，homometric sets），它们也可能变得无法区分。这种现象被称为**支撑集碰撞** (support collisions)，是结构化测量设计中一个必须考虑的难题 。

### 稀疏性与[先验信息](@entry_id:753750)的作用

由于上述模糊性的存在，从任意二次测量中恢复一个稠密信号通常是不可能的。为了使问题变得适定 (well-posed)，我们必须引入关于信号$x$的先验知识。在现代信号处理中，**[稀疏性](@entry_id:136793)** (sparsity) 是最强大和最普遍的先验之一。

#### 定义[稀疏性](@entry_id:136793)

一个信号$x \in \mathbb{C}^{n}$被称为 **$k$-稀疏** ($k$-sparse)，如果它至多有$k$个非零元素。这个非零元素的数量由$\ell_0$**伪范数** (pseudo-norm) $\|x\|_0$给出，它定义为$x$的**支撑集** (support)的基数：
$\|x\|_0 = |\text{supp}(x)| = |\{j \in \{1, \dots, n\} : x_j \neq 0 \}|$
所有$k$-[稀疏信号](@entry_id:755125)的集合记为$\Sigma_k = \{ x \in \mathbb{C}^{n} : \|x\|_0 \leq k \}$ 。

#### 可辨识性与样本复杂度的降低

引入稀疏性先验后，核心问题变为：需要多少测量值（即$m$的大小）才能唯一地（在[全局相位](@entry_id:147947)意义下）从$\Sigma_k$中恢复出$k$-稀疏信号$x$？这个最小的$m$值被称为**样本复杂度** (sample complexity)。

我们可以通过一个**自由度** (degrees of freedom, DoF) 的论证来直观地理解[稀疏性](@entry_id:136793)带来的好处。一个问题若要求唯一解，一个必要条件是观测值的数量必须不少于未知参数的自由度。

考虑一个[多测量向量](@entry_id:752318) (Multiple Measurement Vector, MMV) 的场景，我们有$L$个信号$\{x^{(\ell)}\}_{\ell=1}^L$，每个信号都通过同一组传感向量$\{a_i\}_{i=1}^m$进行测量。

1.  **无结构化 (稠密) 场景**：每个$x^{(\ell)} \in \mathbb{C}^n$是一个稠密信号。一个复数向量$x^{(\ell)}$有$n$个复数分量，对应$2n$个实数参数。每个信号都有一个独立的[全局相位](@entry_id:147947)模糊性，这会移除1个自由度。因此，每个信号的净自由度为$2n-1$。对于$L$个信号，总自由度为$L(2n-1)$。总的实数测量数量为$mL$。因此，必要条件是$mL \ge L(2n-1)$，即每个信号所需的最小测量数$m_{\mathrm{un}}^{\star} = 2n-1$。

2.  **联合 $k$-稀疏场景**：所有$L$个信号共享一个未知的、大小为$k$的支撑集$S$。现在，每个信号$x^{(\ell)}$仅由其在$S$上的$k$个复数值确定，对应$2k$个实数参数。同样，每个信号的相位模糊性移除了1个自由度，所以每个信号的净自由度为$2k-1$。总自由度为$L(2k-1)$。必要条件是$mL \ge L(2k-1)$，即$m_{\mathrm{js}}^{\star} = 2k-1$。

通过比较这两种情况，我们可以量化稀疏性带来的收益。所需测量数的比值为：
$$
\rho = \frac{m_{\mathrm{js}}^{\star}}{m_{\mathrm{un}}^{\star}} = \frac{2k - 1}{2n - 1}
$$
由于$k \ll n$，这个比值远小于1，这意味着稀疏性先验极大地降低了唯一恢复信号所需的测量数量 。这个简单的自由度计数为[稀疏信号恢复](@entry_id:755127)理论提供了坚实的直观基础。

### 相位恢复的算法[范式](@entry_id:161181)

有了[适定性](@entry_id:148590)保证后，下一个问题是如何设计有效的算法来求解$x$。主要存在两种算法[范式](@entry_id:161181)：基于[凸优化](@entry_id:137441)的“提升”方法和直接处理原始非凸问题的迭代方法。

#### 提升方法：[凸松弛](@entry_id:636024) ([PhaseLift](@entry_id:753386))

提升 (lifting) 方法通过将问题从[向量空间](@entry_id:151108)$\mathbb{C}^n$提升到[矩阵空间](@entry_id:261335)$\mathbb{C}^{n \times n}$来实现凸化。其核心思想是定义一个矩阵变量$X = xx^*$。注意到$X$是一个秩为1的[半正定矩阵](@entry_id:155134)。测量方程可以重写为$X$的线性函数：

$y_i = |\langle a_i, x \rangle|^2 = (a_i^* x)(x^* a_i) = \mathrm{Tr}(x^* a_i a_i^* x) = \mathrm{Tr}(a_i a_i^* (xx^*)) = \mathrm{Tr}(A_i X)$

其中$A_i = a_i a_i^*$。现在，测量值是关于矩阵$X$的线性函数。恢复$x$的问题就转化为了寻找一个秩为1的[半正定矩阵](@entry_id:155134)$X$。由于秩约束是非凸的，**[PhaseLift](@entry_id:753386)** 等方法将其松弛，求解以下凸[优化问题](@entry_id:266749)：
$$
\text{寻找 } X \in \mathbb{C}^{n \times n} \text{ 使得 } y_i = \mathrm{Tr}(A_i X) \text{ for all } i, \text{ 且 } X \succeq 0
$$
理论研究表明，在某些条件下（例如，当$m$足够大时），这个凸问题的解确实是秩为1的，从而可以完美恢复$x$。

然而，这种方法的计算代价高昂。求解该问题的一阶算法需要存储和操作一个大小为$n \times n$的矩阵$X$。其内存复杂度为$O(n^2)$。每轮迭代通常涉及一次到半正定锥上的投影，这需要对一个$n \times n$矩阵进行完整的[特征值分解](@entry_id:272091)，计算成本为$O(n^3)$。当测量数$m$的尺度为$O(n \log n)$时，梯度计算的成本为$O(mn^2) = O(n^3 \log n)$。因此，总的**单次迭代计算复杂度**为$O(n^3 \log n)$。对于大规模问题（即$n$很大时），这样的计算和内存需求是难以承受的 。

#### 非凸方法：[Wirtinger流](@entry_id:756740)

与提升方法相反，非凸方法直接在原始的[向量空间](@entry_id:151108)$\mathbb{C}^n$中解决问题。这类方法通常通过最小化一个关于$x$的非凸损失函数来工作。一个典型的损失函数是**强度基损失** (intensity-based loss)：

$f(z) = \frac{1}{2m} \sum_{i=1}^{m} \left( |\langle a_i, z \rangle|^2 - y_i \right)^2$

**[Wirtinger流](@entry_id:756740) (Wirtinger Flow, WF)** 及其变种就是基于对此类非凸[损失函数](@entry_id:634569)进行[梯度下降](@entry_id:145942)的算法。

##### Wirtinger梯度

由于损失函数$f(z)$是一个关于[复变量](@entry_id:175312)$z$的实值函数，但它不是全纯的（因为它依赖于$z$和其共轭$z^*$），我们不能使用标准的复变导数。取而代之的是 **Wirtinger  calculus**。其核心思想是将$z$和$z^*$视为独立的变量。对于一个实值函数$f(z, z^*)$，其梯度方向由对[共轭变量](@entry_id:147843)的导数$\frac{\partial f}{\partial z^*}$给出。这个量被称为**Wirtinger梯度**，记作$\nabla f(z)$。

让我们来推导上述[损失函数](@entry_id:634569)$f(z)$的Wirtinger梯度。首先注意到$|\langle a_i, z \rangle|^2 = (a_i^* z)(z^* a_i)$。应用[链式法则](@entry_id:190743)：

$\nabla f(z) = \frac{\partial f}{\partial z^*} = \frac{1}{2m} \sum_{i=1}^{m} 2 \left( |\langle a_i, z \rangle|^2 - y_i \right) \frac{\partial}{\partial z^*} \left( (a_i^* z)(z^* a_i) \right)$

由于$\frac{\partial}{\partial z^*} (z^* a_i a_i^* z) = a_i a_i^* z$，我们得到：

$\nabla f(z) = \frac{1}{m} \sum_{i=1}^{m} \left( |\langle a_i, z \rangle|^2 - y_i \right) a_i a_i^* z$

这就是[Wirtinger流](@entry_id:756740)算法中[梯度下降](@entry_id:145942)的更新方向 。算法的迭代步骤为$z_{k+1} = z_k - \eta_k \nabla f(z_k)$，其中$\eta_k$是步长。

##### 计算优势

[Wirtinger流](@entry_id:756740)的[计算效率](@entry_id:270255)远高于提升方法。其迭代变量是一个$n$维向量$z$，因此**内存复杂度**仅为$O(n)$。梯度计算的复杂度为$O(mn)$。当$m \sim O(n \log n)$时，**单次迭代计算复杂度**为$O(n^2 \log n)$。与[PhaseLift](@entry_id:753386)相比，[Wirtinger流](@entry_id:756740)在内存和计算复杂度上分别降低了一个$O(n)$的因子，这使得它能够处理更大规模的问题 。

### [非凸优化](@entry_id:634396)版图的挑战与对策

虽然[Wirtinger流](@entry_id:756740)在计算上具有优势，但其非[凸性](@entry_id:138568)带来了独特的挑战：算法可能会陷入**伪局部最小值** (spurious local minima)，即那些不是全局最优解（真实信号）的[稳定点](@entry_id:136617)。

#### 伪局部最小值的存在

[非凸优化](@entry_id:634396)的主要障碍是损失函数的几何形状可能很复杂。一个精心设计的例子可以清晰地揭示这一危险。考虑一个实数[稀疏相位恢复](@entry_id:755116)问题，其中真实信号为$x_{\star} = (1, 0)^{\top}$，并使用一组特定的传感向量$a_i$。我们可以构建一个带$\ell_1$范数正则项的目标函数$F(x) = f_{\mathrm{smooth}}(x) + \tau \|x\|_1$，其中$f_{\mathrm{smooth}}$是强度基损失。通过计算$f_{\mathrm{smooth}}$在原点$x=0$处的梯度和Hessian矩阵，可以证明：
1.  $\nabla f_{\mathrm{smooth}}(0) = 0$。
2.  对于足够小的非零$x$，损失函数的改变量$F(x) - F(0) \approx \tau \|x\|_1 - \frac{1}{2} x^{\top} Q x$，其中$Q$是一个[正定矩阵](@entry_id:155546)。

由于$\|x\|_1$是$O(\|x\|_2)$项，而二次项是$O(\|x\|_2^2)$项，在$x$足够接近原点时，正的线性项$\tau \|x\|_1$会主导负的二次项。这意味着对于任意$\tau > 0$，原点$x=0$都是$F(x)$的一个严格局部最小值。然而，真实解是$x_{\star} \neq 0$。因此，原点成了一个伪局部最小值。一个从原点附近开始的梯度类算法，如[近端梯度下降](@entry_id:637959)，将被“困在”这个错误的解上 。

#### 良性几何景观与截断策略

尽管存在伪局部最小值的风险，但[Wirtinger流](@entry_id:756740)在实践中却出人意料地成功。其背后的关键理论突破在于证明了，对于随机高斯测量向量$a_i$且测量数量$m$足够大（通常是$m \sim O(n \log n)$），[损失函数](@entry_id:634569)的几何景观是**良性的** (benign)。这意味着，除了对应于真实解的[全局最小值](@entry_id:165977)点（及其相位旋转版本），景观中不存在其他的局部最小值。

为了保证算法能利用这种良性景观，通常需要一个足够好的初始点，这个初始点可以通过基于[主成分分析](@entry_id:145395)的[谱方法](@entry_id:141737)得到。

此外，为了[增强算法](@entry_id:635795)在实践中的鲁棒性，研究者们提出了**截断[Wirtinger流](@entry_id:756740)** (Truncated Wirtinger Flow)。其动机是，在梯度计算$\nabla f(z) = \frac{1}{m} \sum_{i} (\dots) a_i a_i^* z$中，某些项可能会对结果产生不成比例的影响：
-   如果$|\langle a_i, z \rangle|$非常小，在某些损失函数（如幅值基损失）中可能导致数值不稳定。
-   如果$|\langle a_i, z \rangle|$非常大，它会产生一个高杠杆的“离群”梯度项，破坏整体的[梯度估计](@entry_id:164549)。

截断策略通过舍弃那些$|\langle a_i, z \rangle|^2$值过大或过小的项来解决这个问题。一个有效的截断规则是：
$T_i(z) = \mathbf{1}\left\{\alpha_{\mathrm{lb}} \|z\|_2^2 \le |\langle a_i, z \rangle|^2 \le \alpha_{\mathrm{ub}} \|z\|_2^2\right\}$
其中$\alpha_{\mathrm{lb}}$和$\alpha_{\mathrm{ub}}$是预设的常数。

这个规则的合理性根植于统计学。对于随机高斯向量$a_i$，[随机变量](@entry_id:195330)$|\langle a_i, z \rangle|^2 / \|z\|_2^2$服从参数为1的[指数分布](@entry_id:273894)。指数分布是**次指数** (sub-exponential)的，意味着它有比[高斯分布](@entry_id:154414)更“重”的尾部，产生极端值的概率更高。截断操作正是通过移除这些来自尾部的罕见但影响巨大的样本，使得梯度的估计更加稳定和集中，从而保证了算法的收敛性 。

### 性能界限与相关问题扩展

最后，我们探讨该领域的两个高级主题：算法性能的理论极限，以及将相位恢复的思想扩展到相关的盲反卷积问题。

#### 性能的根本极限：[克拉默-拉奥下界](@entry_id:154412)

对于任何一个[统计估计](@entry_id:270031)问题，**[克拉默-拉奥下界](@entry_id:154412)** (Cramér-Rao Lower Bound, CRLB) 为所有无偏[估计量的[方](@entry_id:167223)差](@entry_id:200758)（或协方差矩阵）提供了一个理论下限。在带加性高斯噪声$w_i \sim \mathcal{N}(0, \sigma^2)$的相位恢复模型中，我们可以推导其CRLB。

首先，构建参数$\theta \in \mathbb{R}^{2s}$（包含稀疏信号$x_S$的实部和虚部）的**费雪信息矩阵** (Fisher Information Matrix, FIM) $F(\theta)$。对于高斯噪声模型，FIM可以表达为：
$F(\theta) = \frac{1}{\sigma^2} \sum_{i=1}^{m} (\nabla_{\theta} \mu_i(\theta)) (\nabla_{\theta} \mu_i(\theta))^{\top}$
其中$\mu_i(\theta) = |\langle a_i, x_S \rangle|^2$是第$i$个测量的均值。

一个关键发现是，这个FIM矩阵是奇异的。其零空间中存在一个非[零向量](@entry_id:156189)$h(\theta) = [-v, u]^{\top}$，其中$x_S = u + \mathrm{i}v$。这个向量恰好是[全局相位](@entry_id:147947)变换$x_S \mapsto e^{\mathrm{i}\phi} x_S$在$\phi=0$处的[切线](@entry_id:268870)方向。这深刻地揭示了统计性能极限与问题内在几何模糊性之间的联系：由于存在相位模糊性，沿着该方向的信息为零，导致FIM奇异。

为了得到一个有意义的界，我们必须考虑在商空间（即模掉[全局相位](@entry_id:147947)）上的估计。这对应于将FIM投影到与模糊方向$h(\theta)$正交的[子空间](@entry_id:150286)上。修正后的CRLB由FIM的[伪逆](@entry_id:140762)给出，它为任何旨在恢复信号（直到一个相位）的无偏估计器的性能设定了不可逾越的障碍 。

#### 消除模糊性与盲[反卷积](@entry_id:141233)

CRLB的分析表明，模糊性是问题的核心。在算法层面，我们可以通过施加约束来主动消除它们。例如，在相位恢复中，我们可以要求解$x$与某个固定的非零“锚向量”$s$的[内积](@entry_id:158127)$s^*x$是一个正实数。这个约束$\mathrm{Im}(s^* x) = 0, \mathrm{Re}(s^* x) > 0$唯一地从每个相位[等价类](@entry_id:156032)中选择了一个代表，从而打破了$\mathbb{S}^1$对称性。其效果是，在约束[流形](@entry_id:153038)上，损失函数的Hessian矩阵在解点处变得正定，从而形成了一个良好的优化盆地 。

这种思想也可以应用于更复杂的问题，例如**盲反卷积** (blind deconvolution)。其目标是从它们的[循环卷积](@entry_id:147898)$y = x * h$中同时恢复未知的信号$x$和未知的滤波器$h$。根据卷积定理，在傅里叶域中，这对应于 element-wise 的乘积：$\widehat{y}[f] = \widehat{x}[f] \widehat{h}[f]$。

这个问题存在新的模糊性。首先是**尺度模糊性** (scaling ambiguity)：对任何非零复数$\alpha$，对偶$(\alpha x, \alpha^{-1} h)$会产生完全相同的输出$y$。其次，如果观测到的[频谱](@entry_id:265125)$\widehat{y}$在某个频率$f_0$处有零点，即$\widehat{y}[f_0]=0$，那么我们就无法确定这个零点是来自$\widehat{x}[f_0]=0$还是$\widehat{h}[f_0]=0$。这种**[频谱](@entry_id:265125)零点模糊性** (spectral zero ambiguity) 会导致解的严重非唯一性 。

类似于相位恢复，我们可以通过施加约束来解决这些问题。例如，在双[线性模型](@entry_id:178302)$Z = hx^*$中，尺度模糊性$(h,x) \mapsto (\alpha h, \bar{\alpha}^{-1} x)$可以通过对$h$施加范数和相位约束（如$\|h\|_2=1$和锚定）来完全消除，从而为基于[非凸优化](@entry_id:634396)的盲[反卷积](@entry_id:141233)算法的成功奠定基础 。