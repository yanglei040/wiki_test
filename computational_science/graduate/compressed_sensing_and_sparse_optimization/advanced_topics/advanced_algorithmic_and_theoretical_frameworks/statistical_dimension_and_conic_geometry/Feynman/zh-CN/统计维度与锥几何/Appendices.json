{
    "hands_on_practices": [
        {
            "introduction": "本次练习为统计维度概念提供了一个温和的切入点。我们将为最简单但又最基础的凸锥——非负卦限——计算这个量。通过这个实践，我们将建立直观理解，展示统计维度如何从概率视角量化一个锥的“大小”，并揭示其与环境维度之间一个出人意料的简单关系。",
            "id": "3481891",
            "problem": "令 $\\mathbb{R}_{+}^{n} \\subset \\mathbb{R}^{n}$ 表示非负卦限。一个闭凸锥 $C \\subset \\mathbb{R}^{n}$ 的统计维度 $\\delta(C)$ 定义为一个标准正态向量在 $C$ 上的欧几里得投影的欧几里得范数平方的期望值，即 $\\delta(C) = \\mathbb{E}\\!\\left[\\|\\Pi_{C}(\\boldsymbol{g})\\|^{2}\\right]$，其中 $\\boldsymbol{g} \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{I}_{n})$ 是一个具有独立标准正态分量的随机向量，而 $\\Pi_{C}$ 是到 $C$ 上的欧几里得投影。从这个定义出发，且不使用其他专门的公式，推导统计维度 $\\delta(\\mathbb{R}_{+}^{n})$ 关于 $n$ 的一个闭式表达式。此外，解释 $\\delta(\\mathbb{R}_{+}^{n})$ 对 $n$ 的依赖关系是如何由高斯向量的符号分布产生的。将您的最终答案表示为一个关于 n 的单一闭式表达式。无需进行四舍五入。",
            "solution": "该问题是有效的。这是一个基于锥几何和概率论的既定理论的适定数学问题。所有术语都有定义，且前提是自洽和科学合理的。\n\n一个闭凸锥 $C \\subset \\mathbb{R}^{n}$ 的统计维度 $\\delta(C)$ 定义为 $\\delta(C) = \\mathbb{E}\\!\\left[\\|\\Pi_{C}(\\boldsymbol{g})\\|^{2}\\right]$，其中 $\\boldsymbol{g} \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{I}_{n})$ 是 $\\mathbb{R}^{n}$ 中的一个标准正态向量，$\\Pi_{C}$ 是到 $C$ 上的欧几里得投影。我们的任务是求出非负卦限 $C = \\mathbb{R}_{+}^{n}$ 的统计维度。\n\n令 $\\boldsymbol{g} = (g_1, g_2, \\dots, g_n)^T$，其中每个分量 $g_i$ 是一个服从标准正态分布 $g_i \\sim \\mathcal{N}(0, 1)$ 的独立同分布（i.i.d.）随机变量。\n\n非负卦限定义为 $\\mathbb{R}_{+}^{n} = \\{ \\boldsymbol{x} \\in \\mathbb{R}^n \\mid x_i \\ge 0 \\text{ for } i=1, \\dots, n \\}$。由于这个集合是 n 个相同的闭凸区间 $[0, \\infty)$ 的笛卡尔积，向量 $\\boldsymbol{g}$ 到 $\\mathbb{R}_{+}^{n}$ 上的欧几里得投影可以按分量计算。\n令 $\\boldsymbol{p} = \\Pi_{\\mathbb{R}_{+}^{n}}(\\boldsymbol{g})$。那么 $\\boldsymbol{p}$ 的第 i 个分量由 $g_i$ 到区间 $[0, \\infty)$ 上的投影给出。\n这个投影是：\n$$\np_i = \\Pi_{[0, \\infty)}(g_i) = \\begin{cases} g_i  &\\text{if } g_i \\ge 0 \\\\ 0  &\\text{if } g_i  0 \\end{cases}\n$$\n这可以紧凑地表示为 $p_i = \\max(0, g_i)$。\n\n投影向量的欧几里得范数平方为 $\\|\\Pi_{\\mathbb{R}_{+}^{n}}(\\boldsymbol{g})\\|^2 = \\|\\boldsymbol{p}\\|^2 = \\sum_{i=1}^{n} p_i^2$。\n代入 $p_i$ 的表达式：\n$$\n\\|\\Pi_{\\mathbb{R}_{+}^{n}}(\\boldsymbol{g})\\|^2 = \\sum_{i=1}^{n} (\\max(0, g_i))^2\n$$\n我们可以使用指示函数 $\\mathbb{I}(\\cdot)$ 重写 $(\\max(0, g_i))^2$。该项在 $g_i > 0$ 时为 $g_i^2$，否则为 0。由于对于连续分布，$g_i=0$ 的概率为零，我们可以忽略这一点。\n$$\n\\|\\Pi_{\\mathbb{R}_{+}^{n}}(\\boldsymbol{g})\\|^2 = \\sum_{i=1}^{n} g_i^2 \\mathbb{I}(g_i > 0)\n$$\n现在，我们按照统计维度的定义计算期望：\n$$\n\\delta(\\mathbb{R}_{+}^{n}) = \\mathbb{E}\\left[ \\sum_{i=1}^{n} g_i^2 \\mathbb{I}(g_i > 0) \\right]\n$$\n根据期望的线性性质，我们可以将期望移到求和内部：\n$$\n\\delta(\\mathbb{R}_{+}^{n}) = \\sum_{i=1}^{n} \\mathbb{E}\\left[ g_i^2 \\mathbb{I}(g_i > 0) \\right]\n$$\n由于所有分量 $g_i$ 都是独立同分布的，期望项 $\\mathbb{E}\\left[ g_i^2 \\mathbb{I}(g_i > 0) \\right]$ 对所有 $i=1, \\dots, n$ 都是相同的。我们来计算一个泛型的标准正态随机变量 $g \\sim \\mathcal{N}(0, 1)$ 的这个值，其概率密度函数（PDF）为 $\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{x^2}{2})$。\n$$\n\\mathbb{E}\\left[ g^2 \\mathbb{I}(g > 0) \\right] = \\int_{-\\infty}^{\\infty} x^2 \\mathbb{I}(x > 0) \\phi(x) dx = \\int_{0}^{\\infty} x^2 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) dx\n$$\n为了计算这个积分，我们回想一下标准正态变量的方差为 $1$。由于均值为 $0$，方差也等于二阶矩：\n$$\n\\text{Var}(g) = \\mathbb{E}[g^2] - (\\mathbb{E}[g])^2 = \\mathbb{E}[g^2] - 0^2 = \\mathbb{E}[g^2] = 1\n$$\n二阶矩由整个实数线上的积分给出：\n$$\n\\mathbb{E}[g^2] = \\int_{-\\infty}^{\\infty} x^2 \\phi(x) dx = \\int_{-\\infty}^{\\infty} x^2 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) dx = 1\n$$\n被积函数 $f(x) = x^2 \\phi(x)$ 是一个偶函数，因为 $f(-x) = (-x)^2 \\phi(-x) = x^2 \\phi(x) = f(x)$。对于任何偶函数，从 $0$ 到 $\\infty$ 的积分恰好是从 $-\\infty$ 到 $\\infty$ 积分的一半。\n$$\n\\int_{0}^{\\infty} x^2 \\phi(x) dx = \\frac{1}{2} \\int_{-\\infty}^{\\infty} x^2 \\phi(x) dx = \\frac{1}{2} \\mathbb{E}[g^2] = \\frac{1}{2} \\cdot 1 = \\frac{1}{2}\n$$\n因此，我们发现对于每个 $i$，$\\mathbb{E}\\left[ g_i^2 \\mathbb{I}(g_i > 0) \\right] = \\frac{1}{2}$。\n将此代回 $\\delta(\\mathbb{R}_{+}^{n})$ 的求和中：\n$$\n\\delta(\\mathbb{R}_{+}^{n}) = \\sum_{i=1}^{n} \\frac{1}{2} = \\frac{n}{2}\n$$\n$\\delta(\\mathbb{R}_{+}^{n})$ 对 $n$ 的依赖关系源于高斯向量 $\\boldsymbol{g}$ 的符号分布。$\\boldsymbol{g}$ 的总期望范数平方为 $\\mathbb{E}[\\|\\boldsymbol{g}\\|^2] = \\mathbb{E}[\\sum_{i=1}^n g_i^2] = \\sum_{i=1}^n \\mathbb{E}[g_i^2] = \\sum_{i=1}^n 1 = n$。这个总“期望能量”可以根据分量 $g_i$ 的符号进行分解。\n$$\n\\mathbb{E}[\\|\\boldsymbol{g}\\|^2] = \\mathbb{E}\\left[\\sum_{i=1}^n g_i^2\\right] = \\mathbb{E}\\left[\\sum_{i=1}^n g_i^2 (\\mathbb{I}(g_i > 0) + \\mathbb{I}(g_i \\le 0))\\right] = \\mathbb{E}\\left[\\sum_{i=1}^n g_i^2 \\mathbb{I}(g_i > 0)\\right] + \\mathbb{E}\\left[\\sum_{i=1}^n g_i^2 \\mathbb{I}(g_i \\le 0)\\right]\n$$\n第一项恰好是 $\\delta(\\mathbb{R}_{+}^{n})$。对于第二项，我们考虑期望 $\\mathbb{E}[g_i^2 \\mathbb{I}(g_i \\le 0)]$。由于标准正态分布的对称性，随机变量 $-g_i$ 与 $g_i$ 具有相同的分布。因此，$\\mathbb{E}[g_i^2 \\mathbb{I}(g_i \\le 0)] = \\mathbb{E}[(-g_i)^2 \\mathbb{I}(-g_i \\ge 0)]$。令 $h_i = -g_i$，则此为 $\\mathbb{E}[h_i^2 \\mathbb{I}(h_i \\ge 0)]$。由于 $h_i$ 与 $g_i$ 服从相同的 $\\mathcal{N}(0,1)$ 分布，且由于 $P(g_i=0)=0$，我们有 $\\mathbb{E}[g_i^2 \\mathbb{I}(g_i \\le 0)] = \\mathbb{E}[g_i^2 \\mathbb{I}(g_i > 0)] = \\frac{1}{2}$。\n这意味着总期望能量 $n$ 被均等地分配给对应于正号的分量和对应于非正号的分量。投影 $\\Pi_{\\mathbb{R}_{+}^{n}}$ 保留前者并使后者为零。每个分量 $g_i$ 的符号为正的概率是 $\\frac{1}{2}$，为负的概率也是 $\\frac{1}{2}$。因此，平均而言，一半的分量被投影到非零值。这种基于符号的统计能量均分，作为高斯分布对称性的一个直接结果，正是统计维度恰好是环境维度 $n$ 一半的原因。\n$$\nn = \\delta(\\mathbb{R}_{+}^{n}) + \\sum_{i=1}^{n} \\frac{1}{2} = \\delta(\\mathbb{R}_{+}^{n}) + \\frac{n}{2} \\implies \\delta(\\mathbb{R}_{+}^{n}) = \\frac{n}{2}\n$$",
            "answer": "$$\\boxed{\\frac{n}{2}}$$"
        },
        {
            "introduction": "在掌握了基础知识之后，本次练习将处理一个更高级且高度相关的案例：$\\ell_1$ 范数的下降锥。这个锥是分析基追踪（Basis Pursuit）等压缩感知恢复算法的核心。这个推导过程将展示锥几何与高斯期望相互作用的威力，从而产生一个用于预测算法性能的精确分析工具。",
            "id": "3481864",
            "problem": "设 $n \\geq 2$ 且 $s \\in \\{1,2,\\dots,n-1\\}$。考虑一个点 $x_0 \\in \\mathbb{R}^n$，它有恰好 $s$ 个非零项，符号任意。令 $\\|\\cdot\\|_1$ 表示 $\\mathbb{R}^n$ 上的 $\\ell_1$ 范数，并令 $\\mathcal{D}(\\|\\cdot\\|_1, x_0)$ 表示 $\\|\\cdot\\|_1$ 在 $x_0$ 处的下降锥，定义为\n$$\n\\mathcal{D}(\\|\\cdot\\|_1, x_0) \\triangleq \\bigcup_{\\tau  0} \\left\\{ d \\in \\mathbb{R}^n : \\|x_0 + \\tau d\\|_1 \\leq \\|x_0\\|_1 \\right\\}。\n$$\n一个闭凸锥 $\\mathcal{C} \\subset \\mathbb{R}^n$ 的统计维度 $\\delta(\\mathcal{C})$ 定义为\n$$\n\\delta(\\mathcal{C}) \\triangleq \\mathbb{E}\\left[ \\|\\Pi_{\\mathcal{C}}(g)\\|_2^2 \\right] = \\mathbb{E}\\left[ \\mathrm{dist}\\big(g, \\mathcal{C}^{\\circ}\\big)^2 \\right]，\n$$\n其中 $g \\sim \\mathcal{N}(0, I_n)$ 是一个标准高斯向量，$\\Pi_{\\mathcal{C}}$ 是到 $\\mathcal{C}$ 上的欧几里得投影，$\\mathcal{C}^{\\circ}$ 是 $\\mathcal{C}$ 的极锥。$\\ell_1$ 范数在 $x_0$ 处的次微分为\n$$\n\\partial \\|\\cdot\\|_1(x_0) = \\left\\{ z \\in \\mathbb{R}^n : z_i = \\mathrm{sgn}(x_{0,i}) \\text{ for } i \\in S, \\ \\|z_{S^c}\\|_{\\infty} \\leq 1 \\right\\}，\n$$\n其中 $S = \\mathrm{supp}(x_0)$ 且 $\\mathrm{sgn}(\\cdot)$ 是符号函数。定义标准正态概率密度函数和高斯尾函数为\n$$\n\\varphi(t) \\triangleq \\frac{1}{\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{t^2}{2}\\right), \\qquad Q(t) \\triangleq \\int_t^{\\infty} \\varphi(u) \\, \\mathrm{d}u。\n$$\n仅从这些定义以及高斯随机变量和凸锥的基本性质出发，推导统计维度 $\\delta\\big(\\mathcal{D}(\\|\\cdot\\|_1, x_0)\\big)$ 的一个精确的一维变分表达式，该表达式是关于 $n$ 和 $s$ 的函数，并用 $\\varphi$ 和 $Q$ 表示。你的推导应利用高斯投影的对称性以及由支撑集 $S$ 及其补集 $S^c$ 引起的可分离性。将你的最终答案表示为一个包含对一个非负标量的下确界的单一闭式解析表达式。不需要进行数值计算，也不需要四舍五入。最终答案必须是一个不含不等式的单一解析表达式。",
            "solution": "用户希望找到 $\\ell_1$ 范数在一个稀疏点处的下降锥的统计维度。\n\n### 步骤 1：刻画下降锥及其极锥\n设 $f(x) = \\|x\\|_1$。$f$ 在 $x_0$ 处的下降锥由下式给出\n$$ \\mathcal{D}(f, x_0) = \\bigcup_{\\tau  0} \\{d \\in \\mathbb{R}^n : f(x_0 + \\tau d) \\leq f(x_0) \\} $$\n对于凸函数 $f$，此锥等同于非正方向导数的锥，即 $\\{d \\in \\mathbb{R}^n : f'(x_0; d) \\le 0\\}$，其中 $f'(x_0; d) = \\sup_{z \\in \\partial f(x_0)} \\langle z, d \\rangle$。因此，下降锥是次微分集的极锥：\n$$ \\mathcal{C} \\triangleq \\mathcal{D}(\\|\\cdot\\|_1, x_0) = \\{d \\in \\mathbb{R}^n : \\langle z, d \\rangle \\le 0 \\text{ for all } z \\in \\partial \\|\\cdot\\|_1(x_0)\\} = (\\partial \\|\\cdot\\|_1(x_0))^{\\circ} $$\n根据双极锥定理，$\\mathcal{C}$ 的极锥是原始集合的闭凸锥包：\n$$ \\mathcal{C}^{\\circ} = ((\\partial \\|\\cdot\\|_1(x_0))^{\\circ})^{\\circ} = \\mathrm{cl}(\\mathrm{cone}(\\partial \\|\\cdot\\|_1(x_0))) $$\n$\\ell_1$ 范数在 $x_0$ 处的次微分是给定的。设 $S = \\mathrm{supp}(x_0)$ 为 $x_0$ 的支撑集，其中 $|S|=s$。令 $\\sigma = \\mathrm{sgn}(x_0)$。次微分是集合\n$$ \\partial \\|\\cdot\\|_1(x_0) = \\{ z \\in \\mathbb{R}^n : z_S = \\sigma_S, \\|z_{S^c}\\|_{\\infty} \\leq 1 \\} $$\n其中 $z_S$ 是由 $S$ 索引的 $z$ 的子向量。锥包 $\\mathrm{cone}(\\partial \\|\\cdot\\|_1(x_0))$ 由向量 $v = \\alpha z$ 组成，其中 $\\alpha \\geq 0$ 且 $z \\in \\partial \\|\\cdot\\|_1(x_0)$。这样的向量 $v$ 满足 $v_S = \\alpha \\sigma_S$ 和 $v_{S^c} = \\alpha z_{S^c}$，且 $\\|z_{S^c}\\|_{\\infty} \\leq 1$。这意味着 $\\|v_{S^c}\\|_{\\infty} = \\alpha \\|z_{S^c}\\|_{\\infty} \\leq \\alpha$。\n因此，极锥 $\\mathcal{C}^{\\circ}$ 可以被刻画为：\n$$ \\mathcal{C}^{\\circ} = \\{ v \\in \\mathbb{R}^n : \\exists \\lambda \\geq 0 \\text{ s.t. } v_S = \\lambda \\sigma_S \\text{ and } \\|v_{S^c}\\|_{\\infty} \\leq \\lambda \\} $$\n这个集合是闭集，因此不需要闭包运算。\n\n### 步骤 2：构建统计维度的计算公式\n$\\mathcal{C}$ 的统计维度定义为 $\\delta(\\mathcal{C}) = \\mathbb{E}[\\|\\Pi_{\\mathcal{C}}(g)\\|_2^2]$，其中 $g \\sim \\mathcal{N}(0, I_n)$。问题陈述提供了恒等式 $\\delta(\\mathcal{C}) = \\mathbb{E}[\\mathrm{dist}(g, \\mathcal{C}^{\\circ})^2]$，这源于 Moreau 分解定理 $g = \\Pi_{\\mathcal{C}}(g) + \\Pi_{\\mathcal{C}^{\\circ}}(g)$ 以及投影的正交性，这意味着 $\\Pi_{\\mathcal{C}}(g) = g - \\Pi_{\\mathcal{C}^{\\circ}}(g)$。\n我们必须计算：\n$$ \\delta(\\mathcal{C}) = \\mathbb{E}\\left[ \\inf_{v \\in \\mathcal{C}^{\\circ}} \\|g - v\\|_2^2 \\right] $$\n使用 $\\mathcal{C}^{\\circ}$ 的刻画，这变成：\n$$ \\delta(\\mathcal{C}) = \\mathbb{E}\\left[ \\inf_{\\lambda \\geq 0} \\inf_{v_{S^c} : \\|v_{S^c}\\|_{\\infty} \\le \\lambda} \\left( \\|g_S - \\lambda \\sigma_S\\|_2^2 + \\|g_{S^c} - v_{S^c}\\|_2^2 \\right) \\right] $$\n问题分解为两个部分，一个在支撑集 $S$ 上，另一个在其补集 $S^c$ 上。内部的下确界是从 $g_{S^c}$ 到 $\\mathbb{R}^{n-s}$ 中半径为 $\\lambda$ 的 $\\ell_\\infty$ 球（记为 $B_\\infty^{n-s}(\\lambda)$）的欧几里得距离的平方。这个投影在坐标 $i \\in S^c$ 上是可分的。\n$$ \\inf_{v_{S^c} : \\|v_{S^c}\\|_{\\infty} \\le \\lambda} \\|g_{S^c} - v_{S^c}\\|_2^2 = \\sum_{i \\in S^c} \\mathrm{dist}(g_i, [-\\lambda, \\lambda])^2 = \\sum_{i \\in S^c} (\\max(0, |g_i|-\\lambda))^2 $$\n涉及 $g_S$ 的项可以通过将 $g_S$ 投影到 $\\sigma_S$ 的方向来简化。令 $Y = \\frac{\\langle g_S, \\sigma_S \\rangle}{s}$。$g_S$ 到 $\\mathrm{span}(\\sigma_S)$ 上的投影是 $Y\\sigma_S$。\n$$ \\|g_S - \\lambda \\sigma_S\\|_2^2 = \\|g_S - Y\\sigma_S + Y\\sigma_S - \\lambda \\sigma_S\\|_2^2 $$\n由于 $g_S-Y\\sigma_S$ 与 $(Y-\\lambda)\\sigma_S$ 正交，我们有：\n$$ \\|g_S - \\lambda \\sigma_S\\|_2^2 = \\|g_S - Y\\sigma_S\\|_2^2 + \\|(Y-\\lambda)\\sigma_S\\|_2^2 = \\|g_S - Y\\sigma_S\\|_2^2 + s(Y-\\lambda)^2 $$\n项 $\\|g_S - Y\\sigma_S\\|_2^2$ 与 $\\lambda$ 无关。期望内的最小化问题变为：\n$$ \\|g_S - Y\\sigma_S\\|_2^2 + \\inf_{\\lambda \\geq 0} \\left( s(Y-\\lambda)^2 + \\sum_{i \\in S^c} (\\max(0, |g_i|-\\lambda))^2 \\right) $$\n根据期望的线性性，\n$$ \\delta(\\mathcal{C}) = \\mathbb{E}\\left[\\|g_S - Y\\sigma_S\\|_2^2\\right] + \\mathbb{E}\\left[ \\inf_{\\lambda \\geq 0} \\left( s(Y-\\lambda)^2 + \\sum_{i \\in S^c} (\\max(0, |g_i|-\\lambda))^2 \\right) \\right] $$\n第一项是一个标准高斯 $s$-向量投影到一个维度为 $s-1$ 的子空间上的范数平方的期望值。这个期望值是 $s-1$。\n第二项涉及一个下确界的期望。对于这类涉及高斯向量的问题，随机矩阵理论和凸优化中的一个关键结果（与 Gordon 比较不等式或 Stein 方法相关）是，期望和下确界可以互换以得到精确结果。\n$$ \\mathbb{E}\\left[ \\inf_{\\lambda} \\Psi(g, \\lambda) \\right] = \\inf_{\\lambda} \\mathbb{E}\\left[ \\Psi(g, \\lambda) \\right] $$\n应用此结论，我们得到：\n$$ \\delta(\\mathcal{C}) = (s-1) + \\inf_{\\lambda \\geq 0} \\mathbb{E}\\left[ s(Y-\\lambda)^2 + \\sum_{i \\in S^c} (\\max(0, |g_i|-\\lambda))^2 \\right] $$\n\n### 步骤 3：计算高斯期望\n我们计算下确界内部两项的期望。\n1. 第一项：$Y = \\frac{1}{s}\\sum_{i \\in S} g_i \\sigma_i$。由于 $g_i \\sim \\mathcal{N}(0,1)$ 是独立同分布的且 $\\sigma_i^2 = 1$，每个 $g_i \\sigma_i$ 也服从 $\\mathcal{N}(0,1)$ 分布。因此，$Y$ 是 $s$ 个独立同分布的标准正态随机变量的平均值，所以 $Y \\sim \\mathcal{N}(0, 1/s)$。\n$$ \\mathbb{E}[s(Y-\\lambda)^2] = s \\mathbb{E}[(Y-\\lambda)^2] = s (\\mathrm{Var}(Y) + (\\mathbb{E}[Y]-\\lambda)^2) = s (1/s + (0-\\lambda)^2) = 1 + s\\lambda^2 $$\n2. 第二项：设 $G \\sim \\mathcal{N}(0,1)$。我们需要计算 $\\mathbb{E}[(\\max(0, |G|-\\lambda))^2]$。\n\\begin{align*} \\mathbb{E}[(\\max(0, |G|-\\lambda))^2] = \\int_{-\\infty}^{\\infty} (\\max(0, |t|-\\lambda))^2 \\varphi(t) \\, \\mathrm{d}t \\\\ = \\int_{|t|  \\lambda} (|t|-\\lambda)^2 \\varphi(t) \\, \\mathrm{d}t \\\\ = 2 \\int_{\\lambda}^{\\infty} (t-\\lambda)^2 \\varphi(t) \\, \\mathrm{d}t \\quad (\\text{根据对称性}) \\\\ = 2 \\int_{\\lambda}^{\\infty} (t^2 - 2\\lambda t + \\lambda^2) \\varphi(t) \\, \\mathrm{d}t \\\\ = 2 \\int_{\\lambda}^{\\infty} t^2 \\varphi(t) \\, \\mathrm{d}t - 4\\lambda \\int_{\\lambda}^{\\infty} t \\varphi(t) \\, \\mathrm{d}t + 2\\lambda^2 \\int_{\\lambda}^{\\infty} \\varphi(t) \\, \\mathrm{d}t\\end{align*}\n我们使用标准高斯积分：$\\int_{\\lambda}^{\\infty} \\varphi(t) \\, \\mathrm{d}t = Q(\\lambda)$，$\\int_{\\lambda}^{\\infty} t\\varphi(t) \\, \\mathrm{d}t = \\varphi(\\lambda)$，以及 $\\int_{\\lambda}^{\\infty} t^2\\varphi(t) \\, \\mathrm{d}t = \\lambda\\varphi(\\lambda) + Q(\\lambda)$。\n代入这些结果得到：\n$$ \\mathbb{E}[(\\max(0, |G|-\\lambda))^2] = 2(\\lambda\\varphi(\\lambda) + Q(\\lambda)) - 4\\lambda(\\varphi(\\lambda)) + 2\\lambda^2(Q(\\lambda)) = 2(1+\\lambda^2)Q(\\lambda) - 2\\lambda\\varphi(\\lambda) $$\n根据期望的线性性，并且由于对于 $i \\in S^c$，$g_i$ 是独立同分布的：\n$$ \\mathbb{E}\\left[\\sum_{i \\in S^c} (\\max(0, |g_i|-\\lambda))^2\\right] = (n-s) \\left[ 2(1+\\lambda^2)Q(\\lambda) - 2\\lambda\\varphi(\\lambda) \\right] $$\n\n### 步骤 4：整合最终表达式\n合并各项，下确界内部的表达式变为：\n$$ \\mathbb{E}[\\dots] = (1+s\\lambda^2) + (n-s) \\left[ 2(1+\\lambda^2)Q(\\lambda) - 2\\lambda\\varphi(\\lambda) \\right] $$\n最后，加上 $s-1$ 项，我们得到统计维度：\n$$ \\delta(\\mathcal{C}) = s-1 + \\inf_{\\lambda \\geq 0} \\left\\{ 1+s\\lambda^2 + (n-s) \\left[ 2(1+\\lambda^2)Q(\\lambda) - 2\\lambda\\varphi(\\lambda) \\right] \\right\\} $$\n$$ \\delta(\\mathcal{C}) = s + \\inf_{\\lambda \\geq 0} \\left\\{ s\\lambda^2 + (n-s) \\left[ 2(1+\\lambda^2)Q(\\lambda) - 2\\lambda\\varphi(\\lambda) \\right] \\right\\} $$\n这就是所要求的统计维度的一维变分表达式。",
            "answer": "$$\\boxed{s + \\inf_{\\lambda \\ge 0} \\left\\{ s\\lambda^2 + (n-s) \\left[ 2(1+\\lambda^2)Q(\\lambda) - 2\\lambda\\varphi(\\lambda) \\right] \\right\\}}$$"
        },
        {
            "introduction": "我们最后的练习将从解析推导转向计算应用，展示统计维度的实际效用。我们将实现前一个练习中推导出的公式，以数值方式计算 $\\delta$，并用它来预测压缩感知问题中的噪声放大效应。这个练习突显了抽象的几何概念如何能够直接预测实际信号恢复系统的稳定性和性能，尤其是在接近临界性能阈值时。",
            "id": "3481924",
            "problem": "考虑由一个线性模型和一个$\\ell_1$球的交集定义的可行集，即$\\{x \\in \\mathbb{R}^n : A x = y, \\|x\\|_1 \\le \\tau\\}$。设$x_\\star \\in \\mathbb{R}^n$是$\\ell_1$球边界上的一个点，满足$\\|x_\\star\\|_1 = \\tau$，其支撑集为$S \\subset \\{1,\\dots,n\\}$，势为$k = |S|$。并假设测量矩阵$A \\in \\mathbb{R}^{m \\times n}$的各行独立，且服从标准正态分布$N(0, I_n)$。可行集在$x_\\star$附近的锥几何形状由$\\ell_1$范数在$x_\\star$处的下降锥决定，而压缩感知中的恢复性质则由与此锥相关的统计维度和锥限制奇异值控制。\n\n从以下基本定义出发：\n\n- 一个真凸函数$f$在点$x$处的下降锥是$D(f, x) := \\{h \\in \\mathbb{R}^n : \\exists t  0 \\text{ 使得 } f(x + t h) \\le f(x)\\}$。\n\n- $\\ell_1$范数在$x$处的次微分是$\\partial \\| \\cdot \\|_1(x)$，由满足$u_i = \\operatorname{sign}(x_i)$（对于$i \\in \\operatorname{supp}(x)$）和$|u_j| \\le 1$（对于$j \\notin \\operatorname{supp}(x)$）的$u \\in \\mathbb{R}^n$集合给出。\n\n- 一个闭凸锥$C$的统计维度是$\\delta(C) := \\mathbb{E}\\left[\\|\\Pi_C(g)\\|_2^2\\right]$，其中$g \\sim N(0, I_n)$，$\\Pi_C$表示到$C$上的欧几里得投影。\n\n- 矩阵$A$关于锥$C$的锥限制最小奇异值是$\\sigma_{\\min}(A; C) := \\inf\\{\\|A h\\|_2 : h \\in C \\cap S^{n-1}\\}$，其中$S^{n-1} := \\{h \\in \\mathbb{R}^n : \\|h\\|_2 = 1\\}$。\n\n- 锥条件数是$\\kappa(A; C) := 1 / \\sigma_{\\min}(A; C)$，并约定当$\\sigma_{\\min}(A; C) = 0$时，$\\kappa(A; C) = +\\infty$。\n\n利用这些基础知识，推导、实现并数值评估$\\ell_1$范数在$\\mathbb{R}^n$中一个$k$-稀疏点$x_\\star$处的下降锥的以下量：\n\n1. 下降锥$D(\\|\\cdot\\|_1, x_\\star)$的统计维度$\\delta$的计算。该计算用$(n, k)$表示，通过一个依赖于标量参数的期望，并在$t \\ge 0$上最小化。推导应从次微分的表征和统计维度的定义开始，将期望简化为一个关于标准正态分布的积分，然后对$t$进行最小化。\n\n2. 使用高斯比较原理对锥限制最小奇异值$\\sigma_{\\min}(A; D)$进行近似，将其与$\\sqrt{m}$和$D \\cap S^{n-1}$的高斯宽度联系起来。利用高斯宽度和统计维度之间的关系，得出一阶估计$\\sigma_{\\min} \\approx \\max\\{\\sqrt{m} - \\sqrt{\\delta}, 0\\}$。\n\n3. 在阈值区域$m \\approx \\delta$附近，可行性问题中噪声放大的界。在该区域，能量为$\\varepsilon = \\|e\\|_2$的测量扰动$e$产生的误差为$\\|\\Delta x\\|_2 \\gtrsim \\varepsilon / \\sigma_{\\min}$。定义预测放大因子$\\alpha := \\varepsilon / \\sigma_{\\min}$，并约定当$\\sigma_{\\min} = 0$时，$\\alpha = +\\infty$。\n\n您必须实现一个完整、可运行的程序，对$\\delta$进行数值评估（通过在$t \\ge 0$上最小化期望），然后为下面指定的测试套件计算$\\sigma_{\\min}$和$\\alpha$。您的程序不应依赖随机性，并且必须使用数值稳定的计算方法来处理期望及其积分。\n\n测试套件：\n- 情况1（超过阈值的一般情况）：$(n, k, m, \\varepsilon) = (500, 25, 220, 0.01)$。\n- 情况2（接近阈值）：$(n, k, m, \\varepsilon) = (500, 25, 180, 0.01)$。\n- 情况3（中等维度，小噪声）：$(n, k, m, \\varepsilon) = (50, 5, 40, 0.001)$。\n- 情况4（极端稀疏）：$(n, k, m, \\varepsilon) = (1000, 1, 30, 0.05)$。\n\n您的程序应生成单行输出，其中包含测试用例的预测放大因子，形式为方括号括起来的逗号分隔列表（例如，`[result1,result2,result3,result4]`）。所有输出必须是浮点数，如果放大是无界的，则使用表示`\"+inf\"`。此问题不涉及物理单位或角度单位；数值输出是无量纲的浮点数。",
            "solution": "该问题是有效的。这是一个在压缩感知和高维统计领域中，基于已建立的锥几何原理的、适定且有科学依据的问题。我们将继续进行推导和求解。\n\n解决方案需要一个三步的解析推导，然后进行数值实现。首先，我们计算下降锥的统计维度$\\delta$。其次，我们近似锥限制最小奇异值$\\sigma_{\\min}$。第三，我们计算噪声放大因子$\\alpha$。\n\n**第1步：下降锥的表征**\n\n该问题涉及$\\ell_1$范数$f(x) = \\|x\\|_1$在一个$k$-稀疏点$x_\\star \\in \\mathbb{R}^n$处的下降锥，该点的支撑集为$S$，大小为$k$。下降锥$D(f, x_\\star)$是所有方向$h \\in \\mathbb{R}^n$的集合，使得方向导数$f'(x_\\star; h)$为非正数。$\\ell_1$范数的方向导数由以下公式给出：\n$$\nf'(x_\\star; h) = \\lim_{t \\downarrow 0} \\frac{\\|x_\\star + th\\|_1 - \\|x_\\star\\|_1}{t} = \\sum_{i \\in S} \\operatorname{sign}((x_\\star)_i) h_i + \\sum_{j \\notin S} |h_j|\n$$\n设$s \\in \\mathbb{R}^n$是$x_\\star$在其支撑集$S$上的符号向量，即$s_S = \\operatorname{sign}((x_\\star)_S)$且$s_{S^c} = 0$。方向导数可以表示为$\\langle s, h \\rangle + \\|h_{S^c}\\|_1$。因此，我们表示为$C$的下降锥是：\n$$\nC := D(\\|\\cdot\\|_1, x_\\star) = \\{ h \\in \\mathbb{R}^n : \\langle s_S, h_S \\rangle + \\|h_{S^c}\\|_1 \\le 0 \\}\n$$\n请注意，由于$s_{S^c}=0$，因此$\\langle s, h \\rangle = \\langle s_S, h_S \\rangle$。\n\n**第2步：统计维度$\\delta(C)$的推导**\n\n对于一个标准高斯向量$g \\sim N(0, I_n)$，闭凸锥$C$的统计维度定义为$\\delta(C) = \\mathbb{E}_g[\\|\\Pi_C(g)\\|_2^2]$。根据Moreau分解定理，任何向量$g$都可以唯一地分解为$g = \\Pi_C(g) + \\Pi_{C^\\circ}(g)$，其中$\\Pi_C(g)$和$\\Pi_{C^\\circ}(g)$是正交的。因此，$\\|\\Pi_C(g)\\|_2^2 = \\|g - \\Pi_{C^\\circ}(g)\\|_2^2 = \\operatorname{dist}(g, C^\\circ)^2$。统计维度因此由标准高斯向量到极锥$C^\\circ$的期望平方欧几里得距离给出：\n$$\n\\delta(C) = \\mathbb{E}_g[\\operatorname{dist}(g, C^\\circ)^2]\n$$\n极锥$C^\\circ$定义为$C^\\circ = \\{ v \\in \\mathbb{R}^n : \\langle v, h \\rangle \\le 0 \\text{ for all } h \\in C \\}$。对于上面定义的下降锥$C$，其极锥是集合$\\{ (s_S, v_{S^c}) : \\|v_{S^c}\\|_\\infty \\le 1 \\}$的锥包。这可以写成：\n$$\nC^\\circ = \\{ v \\in \\mathbb{R}^n : v_S = t s_S, \\|v_{S^c}\\|_\\infty \\le t \\text{ for some } t \\ge 0 \\}\n$$\n从$g$到$C^\\circ$的平方距离可以通过求解一个最小化问题找到：\n$$\n\\operatorname{dist}(g, C^\\circ)^2 = \\min_{v \\in C^\\circ} \\|g - v\\|_2^2 = \\min_{t \\ge 0, \\|w\\|_\\infty \\le 1} \\|g_S - t s_S\\|_2^2 + \\|g_{S^c} - t w\\|_2^2\n$$\n对于一个固定的$t \\ge 0$，第二项中对$w$的最小化等价于找到$g_{S^c}$到半径为$t$的$\\ell_\\infty$球上的投影，即$\\operatorname{dist}(g_{S^c}, t B_\\infty^{n-k})^2$。这个距离是$\\sum_{j \\in S^c} (\\max(|g_j| - t, 0))^2$。于是到$C^\\circ$的平方距离为：\n$$\n\\operatorname{dist}(g, C^\\circ)^2 = \\min_{t \\ge 0} \\left( \\|g_S - t s_S\\|_2^2 + \\sum_{j \\in S^c} (\\max(|g_j| - t, 0))^2 \\right)\n$$\n该理论中的一个关键结果指出，在这种特定情况下，期望的最小值等于最小值的期望。这允许我们交换期望和最小化算子：\n$$\n\\delta(C) = \\min_{t \\ge 0} \\mathbb{E}_g\\left[ \\|g_S - t s_S\\|_2^2 + \\sum_{j \\in S^c} (\\max(|g_j| - t, 0))^2 \\right]\n$$\n我们将最小值内的期望定义为函数$\\psi(t)$。我们逐项计算期望。\n第一项是：\n$$\n\\mathbb{E}[\\|g_S - t s_S\\|_2^2] = \\mathbb{E}[\\|g_S\\|_2^2] - 2t\\mathbb{E}[\\langle g_S, s_S \\rangle] + t^2\\|s_S\\|_2^2 = k - 0 + t^2 k = k(1+t^2)\n$$\n第二项的期望是$(n-k)$乘以单个标准正态变量$z \\sim N(0, 1)$的期望：\n$$\n(n-k) \\mathbb{E}_z [(\\max(|z| - t, 0))^2]\n$$\n这个期望可以通过积分计算。设$\\phi(z)$和$\\Phi(z)$分别是标准正态分布的概率密度函数（PDF）和累积分布函数（CDF）。\n\\begin{align*}\n\\mathbb{E}_z [(\\max(|z| - t, 0))^2] = \\int_{-\\infty}^{\\infty} (\\max(|z|-t,0))^2 \\phi(z) dz \\\\\n= 2 \\int_t^{\\infty} (z-t)^2 \\phi(z) dz \\\\\n= 2 \\left[ \\int_t^{\\infty} z^2\\phi(z)dz - 2t\\int_t^{\\infty} z\\phi(z)dz + t^2\\int_t^{\\infty} \\phi(z)dz \\right] \\\\\n= 2 \\left[ (t\\phi(t) + 1-\\Phi(t)) - 2t\\phi(t) + t^2(1-\\Phi(t)) \\right] \\\\\n= (1+t^2) \\cdot 2(1-\\Phi(t)) - 2t\\phi(t)\n\\end{align*}\n结合这些结果，需要最小化的函数是：\n$$\n\\psi(t) = k(1+t^2) + (n-k) \\left[ (1+t^2) \\cdot 2(1-\\Phi(t)) - 2t\\phi(t) \\right]\n$$\n统计维度即为$\\delta = \\min_{t \\ge 0} \\psi(t)$。这个最小化必须通过数值方法进行。\n\n**第3步：锥最小奇异值和噪声放大**\n\n问题提供了基于统计维度$\\delta$对锥限制最小奇异值$\\sigma_{\\min}(A; C)$的近似。这个近似源于高斯矩阵的测度集中现象和Gordon比较不等式。\n$$\n\\sigma_{\\min} \\approx \\max\\{\\sqrt{m} - \\sqrt{\\delta}, 0\\}\n$$\n这个公式捕捉了压缩感知中的相变现象：如果测量数量$m$小于统计维度$\\delta$，则矩阵$A$在限制于锥$C$上时很可能具有非平凡零空间，导致$\\sigma_{\\min} = 0$。\n\n预测的噪声放大因子$\\alpha$量化了能量为$\\varepsilon = \\|e\\|_2$的测量扰动下的最坏情况误差放大。它定义为：\n$$\n\\alpha := \\frac{\\varepsilon}{\\sigma_{\\min}}\n$$\n如果$\\sigma_{\\min} = 0$，则放大是无界的，因此$\\alpha = +\\infty$。\n\n数值实现将包括最小化$\\psi(t)$以找到$\\delta$，然后对每个测试用例，将$\\delta$代入$\\sigma_{\\min}$和$\\alpha$的表达式中。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize_scalar\n\ndef calculate_psi(t, n, k):\n    \"\"\"\n    Calculates the function psi(t) whose minimum over t=0 is the \n    statistical dimension delta.\n    \"\"\"\n    if t  0:\n        return np.inf\n\n    # Standard normal PDF phi(t) and CDF Phi(t)\n    phi_t = norm.pdf(t)\n    # Using survival function sf(t) = 1 - cdf(t) for better precision for large t\n    sf_t = norm.sf(t)\n    \n    # E_t = E[(max(|z|-t,0))^2] for z ~ N(0,1)\n    # This is calculated using the pre-derived formula:\n    # (1+t^2) * 2*sf(t) - 2*t*phi(t)\n    E_t = (1 + t**2) * 2 * sf_t - 2 * t * phi_t\n    \n    # Full expression for psi(t)\n    psi_val = k * (1 + t**2) + (n - k) * E_t\n    return psi_val\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, k, m, epsilon)\n        (500, 25, 220, 0.01),\n        (500, 25, 180, 0.01),\n        (50, 5, 40, 0.001),\n        (1000, 1, 30, 0.05),\n    ]\n\n    results = []\n    for n, k, m, eps in test_cases:\n        # Create a lambda function for the specific (n, k) to pass to the optimizer.\n        objective_func = lambda t: calculate_psi(t, n, k)\n        \n        # Numerically minimize psi(t) for t >= 0 to find the statistical dimension.\n        # The minimum of psi(t) is convex. A search bound of [0, 50] is very safe.\n        opt_result = minimize_scalar(objective_func, bounds=(0, 50), method='bounded')\n        delta = opt_result.fun\n        \n        # Approximate the conic restricted minimal singular value, sigma_min.\n        # This is based on the provided formula relating it to m and delta.\n        sqrt_m = np.sqrt(m)\n        sqrt_delta = np.sqrt(delta)\n        sigma_min = max(0.0, sqrt_m - sqrt_delta)\n        \n        # Calculate the noise amplification factor, alpha.\n        # A small tolerance is used to handle floating point inaccuracies near zero.\n        if sigma_min > 1e-12:\n            alpha = eps / sigma_min\n        else:\n            alpha = float('inf')\n        \n        results.append(alpha)\n\n    # Format the final output string as per the problem specification.\n    # Infinity should be represented as '+inf'.\n    formatted_results = []\n    for r in results:\n        if r == float('inf'):\n            formatted_results.append('+inf')\n        else:\n            # The problem asks for float numbers, not scientific notation for small numbers.\n            # Using a reasonable format specifier.\n            formatted_results.append(f\"{r:.7f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\n# The problem requires the code to be runnable, so we call the main function.\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}