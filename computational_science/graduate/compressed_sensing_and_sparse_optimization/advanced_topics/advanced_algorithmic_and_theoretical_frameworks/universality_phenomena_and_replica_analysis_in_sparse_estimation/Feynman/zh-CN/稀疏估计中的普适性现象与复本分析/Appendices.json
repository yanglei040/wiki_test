{
    "hands_on_practices": [
        {
            "introduction": "状态演化（State Evolution, SE）是分析近似消息传递（Approximate Message Passing, AMP）算法性能的基石，它能在高维极限下精确预测算法的行为。本练习将指导您完成一个核心的SE不动点方程的推导。通过对一个基础的去噪器进行计算，您将具体理解这些理论预测在数学上是如何形成的。",
            "id": "3492348",
            "problem": "考虑高维线性模型 $y = A x_{0} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的元素是独立的、零均值、方差为 $1/m$ 的亚高斯随机变量，且 $w \\sim \\mathcal{N}(0,\\sigma_{w}^{2} I_{m})$。假设欠采样率 $\\delta = \\lim_{n \\to \\infty} m/n \\in (0,1)$ 存在。令 $x_{0} \\equiv 0$（零信号），并应用近似消息传递 (AMP) 算法，该算法使用一个来自软阈值族的可分离去噪器，其分量形式定义为 $\\eta(u;\\lambda \\tau) = \\operatorname{sign}(u)\\,\\max\\{|u| - \\lambda \\tau, 0\\}$，其中 $\\lambda > 0$ 是一个固定的阈值乘子，$\\tau$ 是由状态演化预测的有效噪声标准差。根据普适性，渐近均方误差的状态演化递归式成立，其形式为\n$$\nv_{t+1} \\equiv \\tau_{t+1}^{2} \\;=\\; \\sigma_{w}^{2} \\;+\\; \\frac{1}{\\delta}\\,\\mathbb{E}\\!\\left[\\bigl(\\eta(\\tau_{t} Z;\\lambda \\tau_{t}) - 0\\bigr)^{2}\\right],\n$$\n其中 $Z \\sim \\mathcal{N}(0,1)$ 与其他所有变量独立，期望是关于 $Z$ 计算的。在大系统极限下，渐近均方误差的不动点 $v_{\\star}$ 满足 $v_{\\star} = \\sigma_{w}^{2} + \\frac{1}{\\delta}\\,\\mathbb{E}[(\\eta(\\sqrt{v_{\\star}}\\,Z;\\lambda \\sqrt{v_{\\star}}))^{2}]$。\n\n仅从这些原理和定义出发，完成以下任务：\n\n- 通过计算高斯期望，用标准正态概率密度函数 $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^{2}/2)$ 和高斯尾函数 $Q(a) = \\int_{a}^{\\infty} \\phi(z)\\,dz$ 来表示，推导 $v_{\\star}$ 的显式闭式不动点方程。\n- 提出并论证一个基于不动点迭代理论的、以斜率为基础的判据，该判据可用于验证状态演化映射不动点的唯一性或多重性，该判据是与恒等函数交点处斜率的函数。并确定此去噪器族的斜率。\n- 显式求解不动点渐近均方误差 $v_{\\star}$，得到一个关于 $\\delta$、$\\sigma_{w}^{2}$ 和 $\\lambda$ 的闭式解析表达式。\n\n你的最终答案必须是 $v_{\\star}$ 的单一闭式解析表达式。不需要进行数值计算，也不需要四舍五入。最终答案以无单位形式表示。",
            "solution": "在尝试求解之前，首先对问题进行验证，以确保其科学上合理、内容自洽且定义良定。\n\n### 步骤 1：提取已知条件\n- **模型**：高维线性模型 $y = A x_{0} + w$。\n- **矩阵 A**：$A \\in \\mathbb{R}^{m \\times n}$，其元素是独立的、零均值、方差为 $1/m$ 的亚高斯随机变量。\n- **噪声 w**：$w \\sim \\mathcal{N}(0,\\sigma_{w}^{2} I_{m})$。\n- **信号 $x_0$**：$x_{0} \\equiv 0$。\n- **欠采样率**：$\\delta = \\lim_{n \\to \\infty} m/n \\in (0,1)$。\n- **算法**：近似消息传递 (AMP)。\n- **去噪器**：可分离软阈值函数 $\\eta(u;\\alpha) = \\operatorname{sign}(u)\\,\\max\\{|u| - \\alpha, 0\\}$，使用的阈值为 $\\alpha = \\lambda \\tau$。其中 $\\lambda > 0$ 是一个固定的乘子。\n- **状态演化 (SE) 不动点方程**：渐近均方误差 (MSE) $v_{\\star} = \\tau_{\\star}^2$ 是 SE 递归的一个不动点，满足：\n$$v_{\\star} = \\sigma_{w}^{2} + \\frac{1}{\\delta}\\,\\mathbb{E}[(\\eta(\\sqrt{v_{\\star}}\\,Z;\\lambda \\sqrt{v_{\\star}}))^{2}]$$\n其中 $Z \\sim \\mathcal{N}(0,1)$，期望是对 $Z$ 计算的。\n- **标准函数**：标准正态概率密度函数 (PDF) 为 $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^{2}/2)$，高斯尾函数为 $Q(a) = \\int_{a}^{\\infty} \\phi(z)\\,dz$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题陈述进行检验。\n- **科学基础**：该问题是近似消息传递算法理论分析中的一个标准练习，而近似消息传递算法是现代高维统计和压缩感知的基石。状态演化形式体系、软阈值去噪器以及底层的概率模型都是该领域中基本且成熟的概念。该问题在科学上是严谨的。\n- **良定性与客观性**：该问题在数学上是精确的，所有术语和变量都有清晰的定义。它要求进行特定的推导并求解所得方程，这是一个定义明确的数学任务。没有歧义或主观内容。\n- **完整性与一致性**：该问题是自洽的。所有必要的信息，包括模型、算法、关键方程和定义，都已提供。没有矛盾之处。对零信号 ($x_0=0$) 的特化是分析该算法动力学的一个标准简化方法。\n\n### 步骤 3：结论与行动\n该问题是**有效**的。将提供一个完整的、有理有据的解答。\n\n### 不动点方程的推导\n问题的核心是计算状态演化不动点方程中的期望。令 $\\tau_{\\star} = \\sqrt{v_{\\star}}$。需要计算的项是 $\\mathbb{E}[(\\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}))^2]$。\n\n软阈值函数为 $\\eta(u; \\alpha) = \\operatorname{sign}(u)\\max\\{|u|-\\alpha, 0\\}$。当 $u = \\tau_{\\star} Z$ 且 $\\alpha = \\lambda \\tau_{\\star}$ 时，我们有：\n$$ \\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}) = \\operatorname{sign}(\\tau_{\\star} Z) \\max\\{|\\tau_{\\star} Z| - \\lambda \\tau_{\\star}, 0\\} $$\n因为 $\\tau_{\\star} = \\sqrt{v_{\\star}} \\ge 0$，我们可以将其因子分解出来：\n$$ \\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}) = \\tau_{\\star} \\operatorname{sign}(Z) \\max\\{|Z| - \\lambda, 0\\} $$\n将此表达式平方可得：\n$$ (\\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}))^2 = \\tau_{\\star}^2 (\\operatorname{sign}(Z) \\max\\{|Z| - \\lambda, 0\\})^2 = \\tau_{\\star}^2 (\\max\\{|Z| - \\lambda, 0\\})^2 $$\n这个平方项非零当且仅当 $|Z| > \\lambda$。当此条件成立时，其值为 $\\tau_{\\star}^2 (|Z| - \\lambda)^2$。我们可以使用指示函数 $\\mathbf{1}_{|Z|>\\lambda}$ 来表示：\n$$ (\\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}))^2 = \\tau_{\\star}^2 (|Z| - \\lambda)^2 \\mathbf{1}_{|Z|>\\lambda} $$\n现在我们计算关于 $Z \\sim \\mathcal{N}(0,1)$ 的期望：\n$$ \\mathbb{E}[(\\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}))^2] = \\mathbb{E}[\\tau_{\\star}^2 (|Z| - \\lambda)^2 \\mathbf{1}_{|Z|>\\lambda}] = \\tau_{\\star}^2 \\int_{-\\infty}^{\\infty} (|z| - \\lambda)^2 \\mathbf{1}_{|z|>\\lambda} \\phi(z) dz $$\n该积分仅在 $z \\in (-\\infty, -\\lambda) \\cup (\\lambda, \\infty)$ 时非零。我们将积分拆分到这两个区域上：\n$$ \\int_{-\\infty}^{\\infty} (|z| - \\lambda)^2 \\mathbf{1}_{|z|>\\lambda} \\phi(z) dz = \\int_{-\\infty}^{-\\lambda} (-z - \\lambda)^2 \\phi(z) dz + \\int_{\\lambda}^{\\infty} (z - \\lambda)^2 \\phi(z) dz $$\n由于标准正态概率密度函数 $\\phi(z) = \\phi(-z)$ 的对称性，这两个积分是相同的。在第一个积分中通过代换 $u = -z$，我们得到 $\\int_{\\lambda}^{\\infty} (u-\\lambda)^2 \\phi(u) du$。因此，期望简化为：\n$$ \\mathbb{E}[(\\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}))^2] = 2\\tau_{\\star}^2 \\int_{\\lambda}^{\\infty} (z - \\lambda)^2 \\phi(z) dz $$\n我们现在通过展开平方来计算该积分：\n$$ \\int_{\\lambda}^{\\infty} (z - \\lambda)^2 \\phi(z) dz = \\int_{\\lambda}^{\\infty} (z^2 - 2\\lambda z + \\lambda^2) \\phi(z) dz $$\n$$ = \\int_{\\lambda}^{\\infty} z^2 \\phi(z) dz - 2\\lambda \\int_{\\lambda}^{\\infty} z \\phi(z) dz + \\lambda^2 \\int_{\\lambda}^{\\infty} \\phi(z) dz $$\n我们来逐项计算：\n1.  $\\int_{\\lambda}^{\\infty} \\phi(z) dz = Q(\\lambda)$，根据定义。\n2.  对于第二项，我们利用 $\\frac{d}{dz}\\phi(z) = -z\\phi(z)$ 这一事实：\n    $$ \\int_{\\lambda}^{\\infty} z \\phi(z) dz = \\int_{\\lambda}^{\\infty} -\\phi'(z) dz = [-\\phi(z)]_{\\lambda}^{\\infty} = 0 - (-\\phi(\\lambda)) = \\phi(\\lambda) $$\n3.  对于第一项，我们使用分部积分法，令 $u=z$ 和 $dv=z\\phi(z)dz = -\\phi'(z)dz$，所以 $du=dz$ 且 $v=-\\phi(z)$：\n    $$ \\int_{\\lambda}^{\\infty} z^2 \\phi(z) dz = [-z\\phi(z)]_{\\lambda}^{\\infty} - \\int_{\\lambda}^{\\infty} (-\\phi(z)) dz = (0 - (-\\lambda\\phi(\\lambda))) + \\int_{\\lambda}^{\\infty} \\phi(z) dz = \\lambda\\phi(\\lambda) + Q(\\lambda) $$\n结合这些结果，积分为：\n$$ (\\lambda\\phi(\\lambda) + Q(\\lambda)) - 2\\lambda(\\phi(\\lambda)) + \\lambda^2(Q(\\lambda)) = (1+\\lambda^2)Q(\\lambda) - \\lambda\\phi(\\lambda) $$\n将此结果代回期望表达式：\n$$ \\mathbb{E}[(\\eta(\\tau_{\\star} Z; \\lambda \\tau_{\\star}))^2] = 2\\tau_{\\star}^2 \\left[ (1+\\lambda^2)Q(\\lambda) - \\lambda\\phi(\\lambda) \\right] $$\n回顾 $v_{\\star} = \\tau_{\\star}^2$，则 $v_{\\star}$ 的显式不动点方程为：\n$$ v_{\\star} = \\sigma_{w}^{2} + \\frac{1}{\\delta} v_{\\star} \\cdot 2 \\left[ (1+\\lambda^2)Q(\\lambda) - \\lambda\\phi(\\lambda) \\right] $$\n\n### 唯一性判据与斜率推导\n不动点方程的形式为 $v = f(v)$，其中状态演化映射 $f(v)$ 由下式给出：\n$$ f(v) = \\sigma_{w}^{2} + \\frac{v}{\\delta} \\cdot \\underbrace{2 \\left[ (1+\\lambda^2)Q(\\lambda) - \\lambda\\phi(\\lambda) \\right]}_{C(\\lambda)} $$\n这是 $v$ 的一个线性函数：$f(v) = \\sigma_w^2 + v \\cdot \\frac{C(\\lambda)}{\\delta}$。不动点是 $v = f(v)$ 的解。这是关于 $v$ 的一个线性方程：\n$$ v = \\sigma_w^2 + v \\frac{C(\\lambda)}{\\delta} $$\n映射 $f(v)$ 在任意点 $v$ 的斜率是其导数 $f'(v)$。对于这个线性映射，斜率是常数：\n$$ S = f'(v) = \\frac{d}{dv} \\left( \\sigma_w^2 + v \\frac{C(\\lambda)}{\\delta} \\right) = \\frac{C(\\lambda)}{\\delta} = \\frac{2}{\\delta} \\left[ (1+\\lambda^2)Q(\\lambda) - \\lambda\\phi(\\lambda) \\right] $$\n不动点方程 $v = \\sigma_w^2 + S v$ 可以重写为 $v(1-S) = \\sigma_w^2$。\n- 如果 $S \\neq 1$，则存在唯一不动点 $v_{\\star} = \\frac{\\sigma_w^2}{1-S}$。\n- 如果 $S = 1$，方程变为 $0 = \\sigma_w^2$。如果 $\\sigma_w^2 > 0$，则无解（没有不动点）。如果 $\\sigma_w^2 = 0$，则任意 $v \\ge 0$ 都是解，导致存在连续统的不动点（无穷多重性）。\n因此，不动点唯一性的判据是斜率 $S$ 不等于 $1$。\n\n### 不动点均方误差的显式解\n在唯一性条件 $S \\neq 1$ 下，求解线性方程 $v_{\\star}(1-S) = \\sigma_w^2$ 得到 $v_{\\star}$：\n$$ v_{\\star} = \\frac{\\sigma_w^2}{1-S} $$\n代入推导出的斜率 $S$ 的表达式：\n$$ v_{\\star} = \\frac{\\sigma_w^2}{1 - \\frac{2}{\\delta} \\left[ (1+\\lambda^2)Q(\\lambda) - \\lambda\\phi(\\lambda) \\right]} $$\n这就是不动点渐近均方误差 $v_{\\star}$ 关于问题参数 $\\delta$、$\\sigma_w^2$ 和 $\\lambda$ 以及标准高斯函数 $\\phi$ 和 $Q$ 的闭式解析表达式。\n\n为了使均方误差具有物理意义，我们要求 $v_{\\star} \\ge 0$。由于 $\\sigma_w^2 \\ge 0$，这意味着分母必须为正，即 $S  1$。这个条件也保证了在迭代映射 $v_{t+1}=f(v_t)$ 下不动点的稳定性。",
            "answer": "$$\n\\boxed{\\frac{\\sigma_{w}^{2}}{1 - \\frac{2}{\\delta} \\left[ (1+\\lambda^2)Q(\\lambda) - \\lambda\\phi(\\lambda) \\right]}}\n$$"
        },
        {
            "introduction": "普适性原理（universality principle）指出，只要测量矩阵的元素具有匹配的低阶矩，AMP算法的性能就对其具体分布不敏感。然而，这个强大的原理有其适用边界。本计算练习让您能够通过经验性测试来探索普适性的边界，通过模拟使用重尾学生t分布（Student-t）矩阵的AMP算法，并将其性能与基于高斯假设的状态演化预测进行比较，您将亲眼观察到普适性在何种情况下以及如何失效。",
            "id": "3492390",
            "problem": "考虑具有测量矩阵和加性噪声的稀疏线性模型，其描述如下。设 $n$ 和 $m$ 为正整数，其纵横比为 $\\delta = m/n \\in (0,1)$。设未知信号 $x_0 \\in \\mathbb{R}^n$ 具有伯努利-高斯 (BG) 先验：对于每个坐标 $i \\in \\{1,\\dots,n\\}$，其分量 $x_{0,i}$ 独立地服从分布 $(1-\\rho)\\,\\delta_0 + \\rho\\,\\mathcal{N}(0,1)$，其中 $\\rho \\in (0,1)$ 是稀疏度。观测模型为 $y = A x_0 + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的元素是独立同分布的，而 $w \\in \\mathbb{R}^m$ 是加性高斯白噪声 (AWGN)，其分布为 $w \\sim \\mathcal{N}(0,\\sigma_w^2 I_m)$，其中给定了 $\\sigma_w  0$。测量矩阵系综是重尾的：每个元素 $A_{ij}$ 独立地服从自由度为 $\\nu  2$ 的学生t分布 $t_\\nu$，并经过缩放以使方差 $\\operatorname{Var}(A_{ij}) = 1/n$。具体而言，从标准学生t分布中抽取 $T_{ij} \\sim t_\\nu$，并设置 $A_{ij} = \\sqrt{(\\nu - 2)/(\\nu n)} \\, T_{ij}$。\n\n使用带有规范 Onsager 修正项和软阈值去噪器的近似消息传递 (AMP) 算法来估计 $x_0$。定义软阈值去噪器为 $\\eta(u;\\theta) = \\operatorname{sign}(u)\\,\\max(|u| - \\theta, 0)$，其中阈值为 $\\theta \\ge 0$。在 AMP 迭代中，使用一个与逐次迭代的有效噪声水平估计成正比的阈值方案，具体为 $\\theta_t = \\alpha \\,\\tau_t$，其中 $\\alpha  0$ 是一个固定的比例常数，而 $\\tau_t$ 是在第 $t$ 次迭代时根据残差确定的有效噪声标准差的估计值。\n\n在采用与上述相同方差归一化的独立同分布高斯设计下，状态演化 (SE) 递归是一个经过充分检验的分析框架，用于追踪 AMP 迭代过程中的均方误差。特别地，对于 BG 先验和软阈值去噪，SE 递归预测了一个有效噪声水平序列 $\\{\\tau_t\\}_{t \\ge 0}$ 及相关的均方误差序列 $\\{\\mathrm{MSE}_t\\}_{t \\ge 0}$。这些序列可以通过对 BG 先验和标准高斯有效噪声进行蒙特卡洛积分来数值计算，并使用相同的阈值方案 $\\theta_t = \\alpha \\tau_t$。\n\n普适性现象表明，对于具有足够轻尾（例如，存在阶数严格大于2的有限矩）的测量系综，AMP 在此类系综下的性能在大系统极限下与高斯 SE 的预测相匹配。然而，随着学生t系综的自由度参数 $\\nu$ 从上方趋近于2，分布的尾部变得更重，并开始违反 Lindeberg 型条件，这可能导致 AMP 性能与高斯 SE 预测之间出现差异。\n\n你的任务：\n\n- 实现一个程序，对于固定的 $(n,m,\\rho,\\sigma_w,\\alpha)$，评估当学生t分布的自由度 $\\nu$ 从上方趋近于2时，使用重尾矩阵 $A$ 的 AMP 均方误差与高斯 SE 预测的均方误差之间的差异。\n\n- 使用以下建模和算法规范作为基本基础：\n  1. 信号 $x_0$ 的 BG 先验，其稀疏度为 $\\rho$，活跃分量方差为 1。\n  2. 观测模型 $y = A x_0 + w$，其中 $w \\sim \\mathcal{N}(0,\\sigma_w^2 I_m)$。\n  3. 针对独立同分布设计的 AMP 迭代，包含规范的 Onsager 修正项，并使用软阈值去噪器 $\\eta(\\cdot;\\cdot)$，其阈值为 $\\theta_t = \\alpha \\tau_t$，其中 $\\tau_t$ 根据残差估计。\n  4. 针对独立同分布高斯设计的 AMP 的高斯状态演化 (SE) 递归，通过蒙特卡洛方法进行数值评估，以计算固定迭代次数后的预测均方误差。\n\n- 为保证在有限维度下的数值稳定性，你可以在 AMP 更新中应用阻尼。\n\n- 使用以下固定参数：$n = 800$，$\\delta = 0.6$（因此 $m = \\lfloor \\delta n \\rfloor$），$\\rho = 0.1$，$\\sigma_w = 0.05$，$\\alpha = 2.5$，以及总共 $T = 25$ 次 AMP 迭代。学生t系综应如上所述进行缩放，使其方差为 $1/n$。AMP 算法应使用从去噪器的平均散度导出的规范 Onsager 修正因子，并且阈值 $\\theta_t$ 应在每次迭代中根据基于残差的噪声估计按比例更新。\n\n- 将给定 $\\nu$ 下的差异定义为，在 $T$ 次迭代后，学生t系综下的 AMP 均方误差与高斯 SE 预测的均方误差之间的相对误差：$\\mathrm{RelErr}(\\nu) = |\\mathrm{MSE}^{\\mathrm{AMP}}_{\\nu} - \\mathrm{MSE}^{\\mathrm{SE}}| / \\mathrm{MSE}^{\\mathrm{SE}}$。当 $\\mathrm{RelErr}(\\nu)$ 超过容差 $\\varepsilon = 0.2$ 时，宣告失效。\n\n- 对学生t系综使用以下自由度值测试集：$\\nu \\in \\{100.0, 10.0, 4.0, 2.5, 2.1\\}$。对于测试集中的每个 $\\nu$，将 AMP 均方误差在 $R = 2$ 次独立试验中取平均以减小方差。对于每个 $\\nu$，输出一个布尔值，指示失效条件是否成立，即 $\\mathrm{RelErr}(\\nu)  \\varepsilon$ 是否为真。\n\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$\\text{[result1,result2,result3,result4,result5]}$）。结果必须按顺序排列，以对应于 $\\nu$ 值的输入列表。每个结果都必须是一个布尔值。\n\n此问题不涉及物理单位。不出现角度。最终输出是如上指定的布尔值列表，不含任何附加文本。",
            "solution": "该问题是有效的。这是一个在高维统计学和压缩感知领域内定义明确的计算任务，其基础是已确立的科学原理。所有必需的参数和模型都已指定，可以通过数值模拟得到一个唯一的、可验证的解。\n\n目标是研究近似消息传递 (AMP) 算法的普适性原理。具体来说，我们将比较使用重尾学生t测量矩阵进行稀疏信号恢复的 AMP 算法的均方误差 (MSE)，并将其与状态演化 (SE) 的预测进行对比，后者对于高斯矩阵是渐近精确的。\n\n普适性表明，对于具有足够快速衰减尾部的矩阵，AMP 的性能应与 SE 的预测相匹配。我们测试当矩阵尾部变得更重时（即，学生t分布的自由度参数 $\\nu$ 趋近于2时），这种普适性是否会失效。\n\n解决方案涉及两个主要部分：理论 SE 预测的计算和 AMP 算法本身的模拟。\n\n首先，我们从高斯状态演化 (SE) 递归中计算预测的 MSE。SE 追踪的是在独立同分布高斯测量矩阵下，AMP 在大系统极限（$n, m \\to \\infty$ 且 $m/n \\to \\delta$）下的性能。该递归通过一个有效噪声方差 $\\tau_t^2$，将第 $t$ 次迭代的估计均方误差（记为 $\\mathrm{MSE}_t$）与下一次迭代的均方误差 $\\mathrm{MSE}_{t+1}$ 联系起来。该递归定义如下：\n\n设 $x_0 \\in \\mathbb{R}^n$ 是具有伯努利-高斯先验的真实信号，$x_{0,i} \\sim (1-\\rho)\\,\\delta_0 + \\rho\\,\\mathcal{N}(0,1)$。初始估计为 $x^0 = \\mathbf{0}$，因此其 MSE 为 $\\mathrm{MSE}_0 = \\mathbb{E}[\\|x_0 - x^0\\|^2/n] = \\mathbb{E}[\\|x_0\\|^2/n] = \\rho$。\n\n对于每次迭代 $t=0, 1, \\dots, T-1$：\n1.  有效噪声方差由 $\\tau_t^2 = \\sigma_w^2 + \\mathrm{MSE}_t / \\delta$ 给出，其中 $\\sigma_w^2$ 是加性测量噪声的方差，$\\delta=m/n$ 是纵横比。\n2.  下一个估计的 MSE 是通过将去噪器的输入建模为有效观测 $U_t = X_0 + Z_t$ 来计算的，其中 $X_0$ 是一个服从信号先验分布的随机变量，$Z_t \\sim \\mathcal{N}(0, \\tau_t^2)$ 是一个独立的高斯噪声。则下一个 MSE 为：\n    $$\n    \\mathrm{MSE}_{t+1} = \\mathbb{E}\\left[ \\left( \\eta(X_0 + Z_t;\\; \\theta_t) - X_0 \\right)^2 \\right]\n    $$\n    其中 $\\eta(u;\\theta) = \\operatorname{sign}(u)\\max(|u|-\\theta,0)$ 是软阈值去噪器，$\\theta_t = \\alpha \\tau_t$ 是阈值。期望是针对 $X_0$ 和 $Z_t$ 的分布计算的。\n\n此递归迭代 $T=25$ 步。期望使用大规模蒙特卡洛模拟进行数值计算。最终值 $\\mathrm{MSE}_T$ 作为我们的理论基准，即 $\\mathrm{MSE}^{\\mathrm{SE}}$。\n\n其次，我们模拟一个有限尺寸系统（$n=800, m=480$）的 AMP 算法，其测量矩阵 $A$ 为学生t矩阵。$A$ 的元素为 $A_{ij} = \\sqrt{(\\nu - 2)/(\\nu n)} \\, T_{ij}$，其中 $T_{ij} \\sim t_\\nu$，这确保了 $\\operatorname{Var}(A_{ij})=1/n$。为了数值稳定性，特别是在普适性受到挑战时，我们引入了一个阻尼因子 $\\lambda \\in (0,1]$。我们使用固定的阻尼因子 $\\lambda=0.5$。AMP 迭代过程如下：\n\n初始化 $x^0 = \\mathbf{0}$ 和 $z^0 = y = A x_0 + w$。\n对于 $t=0, 1, \\dots, T-1$：\n1.  从残差中估计有效噪声方差：$\\tau_t^2 = \\|z^t\\|^2_2 / m$。\n2.  设置阈值：$\\theta_t = \\alpha \\tau_t$。\n3.  计算有效观测：$u^t = x^t + A^T z^t$。\n4.  应用去噪器和阻尼步骤来更新信号估计：\n    $$\n    x^{t+1} = (1 - \\lambda) x^t + \\lambda \\, \\eta(u^t; \\theta_t)\n    $$\n5.  计算 Onsager 修正项。阻尼更新函数相对于 $u^t$ 的散度是 $\\lambda \\, \\eta'(u^t; \\theta_t)$。Onsager 项的系数是平均散度，并按 $1/\\delta$ 缩放：\n    $$\n    b_t = \\frac{\\lambda}{\\delta} \\cdot \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}_{|u_i^t|  \\theta_t}\n    $$\n6.  更新残差：$z^{t+1} = y - A x^{t+1} + b_t z^t$。\n\n在 $T=25$ 次迭代后，最终的 MSE 计算为 $\\mathrm{MSE}^{\\mathrm{AMP}}_\\nu = \\|x^T - x_0\\|^2_2 / n$。对于给定的每个 $\\nu \\in \\{100.0, 10.0, 4.0, 2.5, 2.1\\}$ 值，此模拟重复 $R=2$ 次，并将结果平均以减少统计涨落。\n\n最后，对于每个 $\\nu$，我们计算相对误差 $\\mathrm{RelErr}(\\nu) = |\\mathrm{MSE}^{\\mathrm{AMP}}_{\\nu} - \\mathrm{MSE}^{\\mathrm{SE}}| / \\mathrm{MSE}^{\\mathrm{SE}}$。如果此误差超过容差 $\\varepsilon = 0.2$，则宣告普适性失效。程序为每个 $\\nu$ 输出一个布尔值，指示此失效条件是否满足。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import t as student_t\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and determine universality breakdown in AMP.\n    \"\"\"\n    # Fixed parameters\n    n = 800\n    delta = 0.6\n    m = int(n * delta)\n    rho = 0.1\n    sigma_w = 0.05\n    alpha = 2.5\n    T = 25\n    R = 2\n    epsilon = 0.2\n    nu_values = [100.0, 10.0, 4.0, 2.5, 2.1]\n    \n    # Damping factor for AMP stability\n    lambd = 0.5\n    \n    # Number of samples for Monte Carlo simulation in SE\n    mc_samples = 200000\n\n    def soft_threshold(u, theta):\n        \"\"\"Soft-thresholding denoiser.\"\"\"\n        return np.sign(u) * np.maximum(np.abs(u) - theta, 0)\n\n    def run_se(rho, delta, sigma_w, alpha, T, mc_samples):\n        \"\"\"\n        Computes the State Evolution prediction for the Mean-Squared Error.\n        \"\"\"\n        sigma_w_sq = sigma_w**2\n        \n        # Generate a large sample of the ground truth signal X0\n        rng_se = np.random.default_rng(seed=42) # Seed for reproducibility of SE\n        is_active = rng_se.binomial(1, rho, size=mc_samples).astype(float)\n        X0 = is_active * rng_se.standard_normal(size=mc_samples)\n\n        # SE recursion starts with MSE of the zero estimate\n        mse = rho\n        \n        for _ in range(T):\n            # Update effective noise variance\n            tau_sq = sigma_w_sq + mse / delta\n            tau = np.sqrt(tau_sq)\n            \n            # Set threshold for the current iteration\n            theta = alpha * tau\n            \n            # Model the effective observation U = X0 + Z, where Z ~ N(0, tau_sq)\n            Z = tau * rng_se.standard_normal(size=mc_samples)\n            U = X0 + Z\n            \n            # Apply denoising to get the next estimate\n            X_next = soft_threshold(U, theta)\n            \n            # Compute the MSE for the next iteration\n            mse = np.mean((X_next - X0)**2)\n            \n        return mse\n\n    def run_amp(n, m, delta, rho, sigma_w, alpha, T, nu, lambd, trial_seed):\n        \"\"\"\n        Runs the AMP algorithm for one trial.\n        \"\"\"\n        rng_amp = np.random.default_rng(trial_seed)\n        \n        # 1. Generate a problem instance (x0, A, w, y)\n        is_active = rng_amp.binomial(1, rho, size=n).astype(float)\n        x0 = is_active * rng_amp.standard_normal(size=n)\n        \n        # Student-t matrix generation\n        A_raw = student_t.rvs(df=nu, size=(m, n), random_state=rng_amp)\n        A = np.sqrt((nu - 2) / (nu * n)) * A_raw\n        \n        # Measurement noise and observation\n        w = sigma_w * rng_amp.standard_normal(size=m)\n        y = A @ x0 + w\n        \n        # 2. AMP algorithm initialization\n        xt = np.zeros(n)\n        zt = np.copy(y)\n        \n        # AMP iterations\n        for _ in range(T):\n            # Estimate effective noise variance from the residual\n            tau_sq = np.mean(zt**2)\n            if tau_sq  1e-20: tau_sq = 1e-20 # for stability\n            tau = np.sqrt(tau_sq)\n            theta = alpha * tau\n            \n            # Denoising input\n            ut = xt + A.T @ zt\n            \n            # Damped update for the signal estimate\n            x_hat = soft_threshold(ut, theta)\n            xt_next = (1 - lambd) * xt + lambd * x_hat\n            \n            # Onsager correction term (divergence of the damped update)\n            div_eta_mean = np.mean(np.abs(ut) > theta)\n            onsager_coeff = lambd * div_eta_mean / delta\n            \n            # Residual update\n            zt_next = y - A @ xt_next + onsager_coeff * zt\n            \n            # State update\n            xt, zt = xt_next, zt_next\n            \n        # 3. Compute final MSE\n        mse = np.mean((xt - x0)**2)\n        return mse\n\n    # Calculate the State Evolution benchmark MSE\n    mse_se = run_se(rho, delta, sigma_w, alpha, T, mc_samples)\n\n    final_results = []\n    # Loop over each value of nu to test for breakdown\n    for nu_idx, nu in enumerate(nu_values):\n        amp_mses = []\n        for r in range(R):\n            # Use a different seed for each trial to ensure independence\n            trial_seed = nu_idx * R + r\n            mse = run_amp(n, m, delta, rho, sigma_w, alpha, T, nu, lambd, trial_seed)\n            amp_mses.append(mse)\n        \n        # Average the MSE over R trials\n        mse_amp_nu = np.mean(amp_mses)\n        \n        # Calculate relative error and check for breakdown\n        if mse_se > 1e-9: # Avoid division by zero\n            rel_err = np.abs(mse_amp_nu - mse_se) / mse_se\n        else:\n            rel_err = np.abs(mse_amp_nu)\n\n        breakdown = rel_err > epsilon\n        final_results.append(breakdown)\n\n    # Print the final results in the required format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "普适性（Universality）的概念并不仅限于具有连续测量的标准线性模型，其预测能力也延伸到了其他具有挑战性的场景，例如测量值被严重量化的单比特压缩感知（1-bit compressed sensing）。本实践旨在展示普适性原理的广泛适用性。通过在一个单比特模型中实现一个简单的恢复算法，并比较不同亚高斯（sub-Gaussian）测量矩阵下的性能临界点，您将亲手验证理论预测在不同矩阵分布下的鲁棒性。",
            "id": "3492304",
            "problem": "考虑单比特压缩感知模型 $y = \\mathrm{sign}(A x_0 + w)$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的元素是来自零均值、单位方差的亚高斯分布的独立同分布随机变量，$x_0 \\in \\mathbb{R}^n$ 是一个单位 $\\ell_2$ 范数的 $k$-稀疏向量，并且 $w \\in \\mathbb{R}^m$ 是独立的测量噪声，其分量 $w_i$ 独立同分布于 $\\mathcal{N}(0,\\sigma^2)$。符号函数 $\\mathrm{sign}(t)$ 在 $t \\ge 0$ 时返回 $+1$，否则返回 $-1$。任务是使用有原则且可复现的计算，通过一个基于第一性原理的代理方法来检验普适性假设，从而实证地检验由副本方法推导出的符号一致性恢复阈值是否对所有亚高斯分布族是普适的。\n\n您的推导和算法必须基于以下基本定义和事实：\n- 如果存在一个常数 $K  0$ 使得对于所有实数 $t$ 都有 $\\mathbb{E}[\\exp(t X)] \\le \\exp(K^2 t^2/2)$，则随机变量 $X$ 是亚高斯的。亚高斯随机变量的尾部行为受类高斯指数衰减控制，并服从测度集中不等式。\n- 对于 $A$ 的独立同分布的行 $a_i^\\top$，各向同性（isotropy）意味着 $\\mathbb{E}[a_i a_i^\\top] = I_n$，其中 $I_n$ 是大小为 $n$ 的单位矩阵。当元素是零均值、单位方差且各坐标间独立时，这些行是各向同性的。\n- 大数定律（LLN）和中心极限定理（CLT）意味着独立同分布随机变量的经验平均值会集中在其期望值附近，其偏差会随着样本数量的增加而缩小，收缩速度由亚高斯尾部界限控制。\n- 在具有各向同性亚高斯矩阵 $A$ 的单比特模型 $y = \\mathrm{sign}(A x_0 + w)$ 中，向量 $s := \\frac{1}{m} A^\\top y$ 是一个经验相关性估计量，在对称性和独立性假设下，其期望值的方向与 $x_0$ 一致。这种一致性是对称性和各向同性的结果：$\\mathbb{E}[y a_{ij}] = c(\\sigma) x_{0,j}$，其中常数 $c(\\sigma)$ 仅依赖于噪声分布，而不依赖于特定的亚高斯分布族，这表明在高维极限下存在普适性现象。\n\n定义符号一致性恢复为同时实现以下两点：\n1. 预测符号与测量符号之间的高度符号一致性，通过以下指标量化：\n$$\n\\mathrm{SC}(A, x_{\\mathrm{hat}}, y) := \\frac{1}{m} \\sum_{i=1}^m \\mathbf{1}\\{y_i = \\mathrm{sign}((A x_{\\mathrm{hat}})_i)\\},\n$$\n以及\n2. $x_{\\mathrm{hat}}$ 和 $x_0$ 之间的高度方向对齐，通过余弦相似度量化：\n$$\n\\mathrm{DC}(x_{\\mathrm{hat}}, x_0) := \\frac{\\langle x_{\\mathrm{hat}}, x_0 \\rangle}{\\|x_{\\mathrm{hat}}\\|_2 \\, \\|x_0\\|_2}.\n$$\n\n您必须实现以下基于第一性原理的、对亚高斯分布族无关的通用 $x_0$ 估计器：\n- 计算 $s := \\frac{1}{m} A^\\top y$。\n- 选择 $|s|$ 中 $k$ 个最大元素的索引集 $S$。\n- 通过设置 $(x_{\\mathrm{hat}})_j = s_j$（对于 $j \\in S$）和 $(x_{\\mathrm{hat}})_j = 0$（对于 $j \\notin S$）来构造 $x_{\\mathrm{hat}}$，然后归一化到单位 $\\ell_2$ 范数。\n\n对于每个测试用例，在固定 $x_0$ 的情况下，通过少量独立重复实验，估计经验临界测量比 $\\alpha^\\star := \\min \\{\\alpha = m/n \\}$，使得\n$$\n\\mathrm{SC}(A, x_{\\mathrm{hat}}, y) \\ge t_{\\mathrm{SC}} \\quad \\text{和} \\quad \\mathrm{DC}(x_{\\mathrm{hat}}, x_0) \\ge t_{\\mathrm{DC}},\n$$\n在平均意义上同时成立，其中 $t_{\\mathrm{SC}}$ 和 $t_{\\mathrm{DC}}$ 是指定的阈值。为了检验普适性，在相同的问题参数下，为 $A$ 的两个不同亚高斯分布族计算 $\\alpha^\\star$，并返回它们的经验阈值之差的绝对值是否在容差 $\\delta$ 之内。\n\n您的程序必须：\n- 为 $A$ 使用以下亚高斯分布族：\n  1. 高斯（Gaussian）：元素独立同分布于 $a_{ij} \\sim \\mathcal{N}(0,1)$。\n  2. Rademacher：元素独立同分布于 $\\{-1,+1\\}$，两者概率相等。\n  3. 稀疏伯努利（Sparse Bernoulli）：元素独立同分布，以概率 $p$ 非零，等可能地取值 $\\pm \\sqrt{1/p}$，否则为 $0$，从而得到单位方差和有界支撑集。\n- 固定一个 $k$-稀疏向量 $x_0$，其非零项从标准正态分布中抽取，然后归一化到单位 $\\ell_2$ 范数。在每个测试用例的所有重复实验中保持 $x_0$ 不变，以分离分布族的影响。\n- 对于指定列表中的每个候选测量比 $\\alpha$，设置 $m = \\lfloor \\alpha n \\rfloor$，生成 $A$ 和 $w$，计算 $y$，估计 $x_{\\mathrm{hat}}$，并在固定次数的重复实验中计算 $\\mathrm{SC}$ 和 $\\mathrm{DC}$。将 $\\alpha^\\star$ 定义为候选列表中最小的 $\\alpha$，其重复实验的平均指标超过阈值。如果没有候选 $\\alpha$ 满足标准，则设置 $\\alpha^\\star = +\\infty$。\n- 对于每个测试用例，为两个分布族计算 $\\alpha^\\star$，并返回布尔值，表示 $|\\alpha^\\star_{\\mathrm{ensemble1}} - \\alpha^\\star_{\\mathrm{ensemble2}}| \\le \\delta$ 是否成立。\n\n测试套件：\n- 使用以下五个测试用例，每个用例指定为 $(n,k,\\sigma,\\text{分布族对},p,t_{\\mathrm{SC}},t_{\\mathrm{DC}},\\delta)$：\n  1. $(200,20,0.3, \\text{Gaussian vs Rademacher}, p=0.1, t_{\\mathrm{SC}}=0.85, t_{\\mathrm{DC}}=0.90, \\delta=0.15)$：中等噪声和中等稀疏度。\n  2. $(200,20,0.0, \\text{Gaussian vs Rademacher}, p=0.1, t_{\\mathrm{SC}}=0.95, t_{\\mathrm{DC}}=0.95, \\delta=0.10)$：无噪声边界情况。\n  3. $(200,10,0.6, \\text{Gaussian vs Sparse Bernoulli}, p=0.1, t_{\\mathrm{SC}}=0.80, t_{\\mathrm{DC}}=0.85, \\delta=0.20)$：较高噪声和较低稀疏度。\n  4. $(120,1,0.2, \\text{Gaussian vs Rademacher}, p=0.1, t_{\\mathrm{SC}}=0.90, t_{\\mathrm{DC}}=0.95, \\delta=0.15)$：单尖峰边界稀疏度。\n  5. $(200,20,1.0, \\text{Gaussian vs Sparse Bernoulli}, p=0.2, t_{\\mathrm{SC}}=0.75, t_{\\mathrm{DC}}=0.80, \\delta=0.25)$：重噪声及更稠密的稀疏伯努利分布。\n\n候选测量比：\n- 使用候选列表 $\\alpha \\in \\{0.20, 0.30, 0.40, 0.50, 0.60, 0.80, 1.00, 1.20\\}$。\n\n重复次数：\n- 对于每个测试用例和候选 $\\alpha$，在 $R=5$ 次独立重复实验中取平均值，其中 $x_0$ 固定，但 $A$ 和 $w$ 重新抽取。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[r_1,r_2,r_3,r_4,r_5]$），其中每个 $r_i$ 是一个布尔值，指示普适性标准对第 $i$ 个测试用例是否成立。不涉及物理单位；角度通过余弦相似度隐式测量，没有明确的单位说明。最终输出是纯布尔值。",
            "solution": "该问题要求对单比特压缩感知中恢复阈值的普适性进行实证研究。我们的任务是设计并执行一个数值实验，以检验一个假设：成功恢复信号所需的临界测量数量与测量矩阵所使用的亚高斯分布的具体类型无关。这一现象是由统计物理学中的副本分析所预测的。\n\n首先，我们建立数学框架。测量过程由以下方程建模\n$$\ny = \\mathrm{sign}(A x_0 + w)\n$$\n其中 $x_0 \\in \\mathbb{R}^n$ 是未知的 $k$-稀疏信号向量，具有单位 $\\ell_2$ 范数，即 $\\|x_0\\|_2 = 1$。矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 是测量矩阵，其元素从零均值、单位方差的亚高斯分布中独立抽取。向量 $w \\in \\mathbb{R}^m$ 表示加性测量噪声，其分量 $w_i$ 独立地从高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取。符号函数定义为，当 $t \\ge 0$ 时 $\\mathrm{sign}(t) = +1$，当 $t  0$ 时 $\\mathrm{sign}(t) = -1$。比率 $\\alpha = m/n$ 是测量比。\n\n普适性假设表明，对于大型系统，某些宏观属性（例如信号恢复的相变边界）仅依赖于矩阵分布族的粗略统计特性（如元素的均值和方差），而不依赖于其分布的精细细节。为了检验这一点，我们将在相同条件下，比较不同矩阵分布族成功恢复所需的临界测量比 $\\alpha^\\star$。待测试的分布族是：\n1.  **高斯（Gaussian）**：元素 $a_{ij} \\sim \\mathcal{N}(0,1)$。\n2.  **Rademacher**：元素 $a_{ij}$ 从 $\\{-1, +1\\}$ 中以相等的概率 $1/2$ 选取。\n3.  **稀疏伯努利（Sparse Bernoulli）**：元素 $a_{ij}$ 分别以 $\\{p/2, 1-p, p/2\\}$ 的概率从 $\\{-\\sqrt{1/p}, 0, +\\sqrt{1/p}\\}$ 中取值。这种构造确保了元素具有零均值和单位方差，因为 $\\mathbb{E}[a_{ij}] = 0$ 且 $\\mathbb{E}[a_{ij}^2] = (p/2)(1/p) + (p/2)(1/p) = 1$。\n\n该问题提供了一个基于第一性原理的简单、通用的 $x_0$ 估计器。该估计器通过一个两步过程构建：相关性计算后进行阈值处理。\n首先，我们计算由下式给出的向量 $s \\in \\mathbb{R}^n$\n$$\ns := \\frac{1}{m} A^\\top y\n$$\n这个向量 $s$ 作为 $A$ 的列与测量向量 $y$ 之间相关性的经验估计量。如问题所述，一个关键的理论见解是 $s_j$ 的期望与 $x_{0,j}$ 成正比，即 $\\mathbb{E}[s_j] = c(\\sigma) x_{0,j}$，其中比例常数 $c(\\sigma)$ 依赖于噪声水平 $\\sigma$，但在高维极限下对所有各向同性亚高斯分布族是普适的。这个性质是大数定律和测度集中现象的结果，它为使用 $s$ 作为 $x_0$ 的代理提供了理论依据。\n\n其次，假设 $s$ 中绝对值最大的分量对应于 $x_0$ 的非零分量（即支撑集），我们通过保留 $s$ 中绝对值最大的 $k$ 个分量并将所有其他分量置零来形成估计 $x_{\\mathrm{hat}}$。这是一个硬阈值操作。设 $S$ 是对应于 $|s_j|$ 的 $k$ 个最大值的索引集合。那么估计器为\n$$\n(x_{\\mathrm{hat}})_j = \n\\begin{cases}\ns_j  \\text{if } j \\in S \\\\\n0  \\text{if } j \\notin S\n\\end{cases}\n$$\n最后，将 $x_{\\mathrm{hat}}$ 归一化为单位 $\\ell_2$ 范数，使得 $\\|x_{\\mathrm{hat}}\\|_2 = 1$，以匹配 $x_0$ 的归一化。\n\n恢复的成功与否由两个指标量化：\n1.  **符号一致性（SC）**：该指标测量预测线性测量的符号与观测符号相匹配的比例。\n    $$\n    \\mathrm{SC}(A, x_{\\mathrm{hat}}, y) := \\frac{1}{m} \\sum_{i=1}^m \\mathbf{1}\\{y_i = \\mathrm{sign}((A x_{\\mathrm{hat}})_i)\\}\n    $$\n2.  **方向相关性（DC）**：该指标使用估计信号 $x_{\\mathrm{hat}}$ 和真实信号 $x_0$ 之间夹角的余弦值来测量它们的方向对齐程度。\n    $$\n    \\mathrm{DC}(x_{\\mathrm{hat}}, x_0) := \\frac{\\langle x_{\\mathrm{hat}}, x_0 \\rangle}{\\|x_{\\mathrm{hat}}\\|_2 \\, \\|x_0\\|_2}\n    $$\n\n数值实验的核心是为每个分布族找到经验临界测量比 $\\alpha^\\star$。$\\alpha^\\star$ 被定义为预定义候选比率列表 $\\{\\alpha_i\\}$ 中的最小值，在该值下恢复被认为是平均成功的。如果在 $R$ 次独立重复实验中平均来看，对于给定的阈值 $t_{\\mathrm{SC}}$ 和 $t_{\\mathrm{DC}}$，$\\mathrm{SC} \\ge t_{\\mathrm{SC}}$ 和 $\\mathrm{DC} \\ge t_{\\mathrm{DC}}$ 同时成立，则在给定的 $\\alpha$ 下恢复是成功的。在每次重复实验中，真实信号 $x_0$ 保持不变，而测量矩阵 $A$ 和噪声向量 $w$ 则重新抽取。如果候选列表中的所有 $\\alpha$ 都不满足标准，我们取 $\\alpha^\\star = +\\infty$。\n\n对于问题中指定的每个测试用例，我们将为一对分布族计算 $\\alpha^\\star_{\\mathrm{ens1}}$ 和 $\\alpha^\\star_{\\mathrm{ens2}}$。如果这些临界比率之间的绝对差在指定的容差 $\\delta$ 之内，则认为普适性假设得到了实证支持：\n$$\n|\\alpha^\\star_{\\mathrm{ens1}} - \\alpha^\\star_{\\mathrm{ens2}}| \\le \\delta\n$$\n最终输出将是每个测试用例的一个布尔值，指示此条件是否成立。模拟将进行 $R=5$ 次重复。每个测试用例的固定真实信号 $x_0$ 是通过从标准正态分布中抽取 $k$ 个非零项，将它们放置在 $n$ 维向量的随机位置，然后将所得向量归一化为单位 $\\ell_2$ 范数来生成的。整个过程被封装在提供的 Python 代码中。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the suite of tests for universality in one-bit compressed sensing.\n    \"\"\"\n    # Set a fixed random seed for reproducibility of the numerical experiment.\n    np.random.seed(42)\n\n    # Candidate measurement ratios to test.\n    alpha_candidates = [0.20, 0.30, 0.40, 0.50, 0.60, 0.80, 1.00, 1.20]\n    \n    # Number of repetitions for averaging.\n    R = 5\n    \n    # Test suite: (n, k, sigma, ensemble_pair, p, t_SC, t_DC, delta)\n    test_cases = [\n        (200, 20, 0.3, ('Gaussian', 'Rademacher'), 0.1, 0.85, 0.90, 0.15),\n        (200, 20, 0.0, ('Gaussian', 'Rademacher'), 0.1, 0.95, 0.95, 0.10),\n        (200, 10, 0.6, ('Gaussian', 'Sparse Bernoulli'), 0.1, 0.80, 0.85, 0.20),\n        (120, 1, 0.2, ('Gaussian', 'Rademacher'), 0.1, 0.90, 0.95, 0.15),\n        (200, 20, 1.0, ('Gaussian', 'Sparse Bernoulli'), 0.2, 0.75, 0.80, 0.25),\n    ]\n\n    results = []\n    for params in test_cases:\n        n, k, sigma, ensemble_pair, p, t_sc, t_dc, delta = params\n        ensemble1, ensemble2 = ensemble_pair\n        \n        # Generate a fixed sparse signal x0 for this test case\n        x0 = np.zeros(n)\n        support = np.random.choice(n, k, replace=False)\n        x0[support] = np.random.randn(k)\n        x0 /= np.linalg.norm(x0)\n\n        # Find the critical alpha for the first ensemble\n        alpha_star1 = find_critical_alpha(n, k, sigma, ensemble1, p, t_sc, t_dc, \n                                           alpha_candidates, R, x0)\n\n        # Find the critical alpha for the second ensemble\n        alpha_star2 = find_critical_alpha(n, k, sigma, ensemble2, p, t_sc, t_dc, \n                                           alpha_candidates, R, x0)\n        \n        # Check if the universality criterion is met\n        universality_holds = np.abs(alpha_star1 - alpha_star2) = delta\n        results.append(universality_holds)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef find_critical_alpha(n, k, sigma, ensemble_type, p, t_sc, t_dc, alpha_candidates, R, x0):\n    \"\"\"\n    Finds the minimum alpha from a candidate list that satisfies the recovery criteria.\n    \"\"\"\n    for alpha in sorted(alpha_candidates):\n        m = int(np.floor(alpha * n))\n        if m == 0:\n            continue\n            \n        avg_sc = 0.0\n        avg_dc = 0.0\n        \n        for _ in range(R):\n            # Generate measurement matrix A\n            A = generate_A(m, n, ensemble_type, p)\n            \n            # Generate noise w\n            w = np.random.normal(0, sigma, m)\n            \n            # Generate measurements y\n            linear_meas = A @ x0 + w\n            y = custom_sign(linear_meas)\n            \n            # Estimate x_hat\n            s = (1.0 / m) * A.T @ y\n            support_hat = np.argsort(np.abs(s))[-k:]\n            x_hat = np.zeros(n)\n            x_hat[support_hat] = s[support_hat]\n            \n            norm_x_hat = np.linalg.norm(x_hat)\n            if norm_x_hat > 0:\n                x_hat /= norm_x_hat\n\n            # Compute metrics\n            sc, dc = compute_metrics(A, x_hat, y, x0)\n            avg_sc += sc\n            avg_dc += dc\n            \n        avg_sc /= R\n        avg_dc /= R\n        \n        if avg_sc >= t_sc and avg_dc >= t_dc:\n            return alpha\n            \n    return np.inf\n\ndef generate_A(m, n, ensemble_type, p):\n    \"\"\"\n    Generates the measurement matrix A based on the specified ensemble type.\n    \"\"\"\n    if ensemble_type == 'Gaussian':\n        return np.random.randn(m, n)\n    elif ensemble_type == 'Rademacher':\n        return np.random.choice([-1.0, 1.0], size=(m, n))\n    elif ensemble_type == 'Sparse Bernoulli':\n        val = 1.0 / np.sqrt(p)\n        return np.random.choice([-val, 0.0, val], size=(m, n), p=[p / 2, 1 - p, p / 2])\n    else:\n        raise ValueError(\"Unknown ensemble type\")\n\ndef custom_sign(v):\n    \"\"\"\n    Implements the sign function as defined in the problem: +1 if t>=0, -1 otherwise.\n    \"\"\"\n    return np.where(v >= 0, 1, -1)\n\ndef compute_metrics(A, x_hat, y, x0):\n    \"\"\"\n    Computes Sign Consistency (SC) and Directional Correlation (DC).\n    \"\"\"\n    # Sign Consistency\n    m = A.shape[0]\n    pred_linear_meas = A @ x_hat\n    pred_y = custom_sign(pred_linear_meas)\n    sc = np.sum(y == pred_y) / m\n\n    # Directional Correlation\n    norm_x_hat = np.linalg.norm(x_hat)\n    norm_x0 = np.linalg.norm(x0) # This is 1 by construction\n    if norm_x_hat > 0:\n      dc = np.dot(x_hat, x0) / (norm_x_hat * norm_x0)\n    else:\n      dc = 0.0\n      \n    return sc, dc\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}