{
    "hands_on_practices": [
        {
            "introduction": "高斯宽度是戈登定理中的核心几何量，它量化了信号集的“大小”并决定了成功恢复所需的测量次数。这项练习将引导你直接根据定义，为一个在压缩感知中至关重要的基本对象——稀疏向量集——计算其高斯宽度的精确解析表达式。通过这个计算 ，你将掌握处理高斯过程期望值的基本技巧，为理解更复杂的场景奠定坚实的数学基础。",
            "id": "3448590",
            "problem": "考虑压缩感知中的一个测量模型，其中随机线性映射通过戈登穿网定理（Gordon’s escape through a mesh theorem）进行分析。令 $n \\in \\mathbb{N}$，并固定一个索引集 $S \\subset \\{1,2,\\dots,n\\}$，其基数 $|S| = s$。定义子集 $T \\subset \\mathbb{R}^{n}$ 为支撑集包含于 $S$ 且欧几里得范数有界的 $s$-稀疏向量的集合：\n$$\nT \\triangleq \\left\\{ x \\in \\mathbb{R}^{n} : \\operatorname{supp}(x) \\subseteq S,\\ \\|x\\|_{2} \\leq 1 \\right\\}.\n$$\n令 $g \\in \\mathbb{R}^{n}$ 为一个标准高斯向量，其分量是独立同分布的 $\\mathcal{N}(0,1)$ 随机变量，并回顾集合 $T$ 的高斯宽度的定义：\n$$\nw(T) \\triangleq \\mathbb{E}\\left[\\,\\sup_{x \\in T} \\langle g, x \\rangle\\,\\right],\n$$\n其中 $\\langle \\cdot, \\cdot \\rangle$ 表示标准欧几里得内积。从高斯向量和径向分布的基本定义与熟知事实出发，推导 $w(T)$ 仅用 $s$ 表示的精确解析表达式。请将最终答案表示为单个闭式符号表达式。不需要数值取整，也不涉及物理单位。",
            "solution": "该问题是有效的，因为它具有科学依据、问题提法得当且客观。这是高维概率论和压缩感知理论中的一个标准计算。我们现在开始推导高斯宽度 $w(T)$ 的解析表达式。\n\n集合 $T$ 的高斯宽度定义为：\n$$\nw(T) \\triangleq \\mathbb{E}\\left[\\,\\sup_{x \\in T} \\langle g, x \\rangle\\,\\right]\n$$\n其中 $T \\triangleq \\left\\{ x \\in \\mathbb{R}^{n} : \\operatorname{supp}(x) \\subseteq S,\\ \\|x\\|_{2} \\leq 1 \\right\\}$，集合 $S$ 的基数为 $|S| = s$，并且 $g \\in \\mathbb{R}^{n}$ 是一个标准高斯向量，其分量 $g_i \\sim \\mathcal{N}(0, 1)$ 是独立同分布的。\n\n我们的第一步是对于 $g$ 的一个固定实现，简化项 $\\sup_{x \\in T} \\langle g, x \\rangle$。条件 $\\operatorname{supp}(x) \\subseteq S$ 意味着对于任何索引 $i \\notin S$，向量 $x \\in T$ 的分量 $x_i$ 均为零。因此，内积 $\\langle g, x \\rangle$可以写成在索引集 $S$ 上的和：\n$$\n\\langle g, x \\rangle = \\sum_{i=1}^{n} g_i x_i = \\sum_{i \\in S} g_i x_i.\n$$\n我们定义 $g_S \\in \\mathbb{R}^{s}$ 为由 $g$ 中索引在 $S$ 内的分量组成的向量，类似地，令 $x_S \\in \\mathbb{R}^{s}$ 为 $x$ 的相应分量组成的向量。那么内积为 $\\langle g, x \\rangle = \\langle g_S, x_S \\rangle_{\\mathbb{R}^s}$。约束条件 $\\|x\\|_{2} \\leq 1$ 变为 $\\|x_S\\|_{2} \\leq 1$，因为 $x$ 的所有其他分量都为零。\n\n因此，期望内的优化问题是：\n$$\n\\sup_{x \\in T} \\langle g, x \\rangle = \\sup_{x_S \\in \\mathbb{R}^s, \\|x_S\\|_2 \\leq 1} \\langle g_S, x_S \\rangle.\n$$\n这个表达式是 $g_S$ 的对偶范数的定义。对于 $\\ell_2$-范数，其对偶范数就是 $\\ell_2$-范数本身。根据柯西-施瓦茨不等式，$\\langle g_S, x_S \\rangle \\leq \\|g_S\\|_2 \\|x_S\\|_2$。由于 $\\|x_S\\|_2 \\leq 1$，我们有 $\\langle g_S, x_S \\rangle \\leq \\|g_S\\|_2$。当 $x_S$ 与 $g_S$ 同向且具有最大可能范数时，即 $x_S = g_S / \\|g_S\\|_2$（对于 $g_S \\neq 0$），达到此最大值。因此，我们有：\n$$\n\\sup_{x \\in T} \\langle g, x \\rangle = \\|g_S\\|_2.\n$$\n现在，我们可以将高斯宽度重写为该范数的期望：\n$$\nw(T) = \\mathbb{E}\\left[ \\|g_S\\|_2 \\right].\n$$\n向量 $g_S$ 是 $g$ 的一个子向量，包含 $s$ 个分量，每个分量都是一个独立的标准正态随机变量。因此，$g_S$ 是 $\\mathbb{R}^s$ 中的一个标准高斯随机向量。我们感兴趣的随机变量是 $g_S$ 的欧几里得范数。\n\n令随机变量 $Z$ 为 $g_S$ 的范数平方：\n$$\nZ = \\|g_S\\|_2^2 = \\sum_{i \\in S} g_i^2.\n$$\n由于 $Z$ 是 $s$ 个独立标准正態随机变量的平方和，它服从自由度为 $s$ 的卡方分布（chi-squared distribution），记作 $Z \\sim \\chi^2(s)$。\n\n当 $z > 0$ 时，$Z$ 的概率密度函数 (PDF) 由下式给出：\n$$\nf_Z(z) = \\frac{1}{2^{s/2} \\Gamma(s/2)} z^{s/2 - 1} \\exp\\left(-\\frac{z}{2}\\right),\n$$\n其中 $\\Gamma(\\cdot)$ 是伽马函数。\n\n我们需要计算 $\\|g_S\\|_2 = \\sqrt{Z}$ 的期望：\n$$\nw(T) = \\mathbb{E}[\\sqrt{Z}] = \\int_{0}^{\\infty} \\sqrt{z} f_Z(z) \\, dz.\n$$\n将 $\\chi^2(s)$ 分布的概率密度函数代入积分中：\n$$\nw(T) = \\int_{0}^{\\infty} z^{1/2} \\left( \\frac{1}{2^{s/2} \\Gamma(s/2)} z^{s/2 - 1} \\exp\\left(-\\frac{z}{2}\\right) \\right) \\, dz.\n$$\n我们可以提出常数项并合并 $z$ 的幂：\n$$\nw(T) = \\frac{1}{2^{s/2} \\Gamma(s/2)} \\int_{0}^{\\infty} z^{1/2 + s/2 - 1} \\exp\\left(-\\frac{z}{2}\\right) \\, dz = \\frac{1}{2^{s/2} \\Gamma(s/2)} \\int_{0}^{\\infty} z^{(s+1)/2 - 1} \\exp\\left(-\\frac{z}{2}\\right) \\, dz.\n$$\n该积分是与伽马函数相关的标准形式。对于形状参数 $k > 0$ 和尺度参数 $\\theta > 0$，以下恒等式成立：\n$$\n\\int_{0}^{\\infty} t^{k-1} \\exp\\left(-\\frac{t}{\\theta}\\right) \\, dt = \\theta^k \\Gamma(k).\n$$\n在我们的例子中，积分变量是 $z$，形状参数是 $k = \\frac{s+1}{2}$，尺度参数是 $\\theta=2$。应用这个恒等式，积分计算结果为：\n$$\n\\int_{0}^{\\infty} z^{(s+1)/2 - 1} \\exp\\left(-\\frac{z}{2}\\right) \\, dz = 2^{(s+1)/2} \\Gamma\\left(\\frac{s+1}{2}\\right).\n$$\n将此结果代回我们关于 $w(T)$ 的表达式中：\n$$\nw(T) = \\frac{1}{2^{s/2} \\Gamma(s/2)} \\left( 2^{(s+1)/2} \\Gamma\\left(\\frac{s+1}{2}\\right) \\right).\n$$\n最后，我们通过合并 $2$ 的幂来简化表达式：\n$$\nw(T) = \\frac{2^{(s+1)/2}}{2^{s/2}} \\frac{\\Gamma\\left(\\frac{s+1}{2}\\right)}{\\Gamma\\left(\\frac{s}{2}\\right)} = 2^{((s+1)/2) - (s/2)} \\frac{\\Gamma\\left(\\frac{s+1}{2}\\right)}{\\Gamma\\left(\\frac{s}{2}\\right)} = 2^{1/2} \\frac{\\Gamma\\left(\\frac{s+1}{2}\\right)}{\\Gamma\\left(\\frac{s}{2}\\right)}.\n$$\n这给出了集合 $T$ 的高斯宽度的精确解析表达式：\n$$\nw(T) = \\sqrt{2} \\frac{\\Gamma\\left(\\frac{s+1}{2}\\right)}{\\Gamma\\left(\\frac{s}{2}\\right)}.\n$$\n如题所求，结果仅取决于稀疏度 $s$。这是自由度为 $s$ 的χ分布（chi distribution）的均值。",
            "answer": "$$\\boxed{\\sqrt{2} \\frac{\\Gamma\\left(\\frac{s+1}{2}\\right)}{\\Gamma\\left(\\frac{s}{2}\\right)}}$$"
        },
        {
            "introduction": "在掌握了高斯宽度的基本计算之后，下一个挑战是应用该理论来理解实际问题中的样本复杂度。这项练习要求你运用“网中逃逸”定理的预测，来评估在低秩矩阵恢复问题中一个常见的“自由度”启发式方法的有效性。通过分析不同测量模型下的理论预测与启发式方法之间的异同 ，你将锻炼批判性思维，并深化对理论适用边界的理解。",
            "id": "3448549",
            "problem": "考虑用于低秩恢复的线性矩阵感知模型。设 $X_{\\star} \\in \\mathbb{R}^{p \\times q}$ 的秩为 $r$，并假设我们观测到 $m$ 个线性测量 $y = \\mathcal{A}(X_{\\star}) \\in \\mathbb{R}^{m}$，其中 $\\mathcal{A}: \\mathbb{R}^{p \\times q} \\to \\mathbb{R}^{m}$ 是一个线性算子，其在标准正交基中的坐标是独立同分布的高斯随机变量，并经过归一化，使得当应用于单位弗罗贝尼乌斯范数矩阵时，每个坐标服从 $\\mathcal{N}(0, 1)$ 分布。考虑在测量一致性约束下最小化核范数的凸恢复规划：\n最小化 $\\|X\\|_{\\ast}$，约束条件为 $\\mathcal{A}(X) = y$。\n穿网逃逸 (Escape Through a Mesh, ETM) 指的是将 Gordon 比较不等式应用于随机子空间不与固定锥相交的事件。在此背景下，记 $\\mathcal{D} := \\mathcal{D}(\\|\\cdot\\|_{\\ast}, X_{\\star})$ 为核范数在 $X_{\\star}$ 处的下降锥。令 $S^{pq-1}$ 为 $\\mathbb{R}^{p q}$ 中在弗罗贝尼乌斯范数下的单位球面，并令 $w(\\mathcal{C}) := \\mathbb{E}\\sup_{u \\in \\mathcal{C}} \\langle g, u \\rangle$ 表示集合 $\\mathcal{C} \\subset \\mathbb{R}^{p q}$ 的高斯宽度，其中 $g \\sim \\mathcal{N}(0, I_{pq})$。对于一个闭凸锥 $\\mathcal{C}$，其统计维度满足 $\\delta(\\mathcal{C}) = \\mathbb{E}\\|\\Pi_{\\mathcal{C}}(g)\\|_{2}^{2}$，并且已知 $w^{2}(\\mathcal{C} \\cap S^{pq-1})$ 和 $\\delta(\\mathcal{C})$ 的值相差一个加性常数。\n仅使用这些基本事实以及核范数和高斯系综的正交不变性，将基于 ETM 的精确恢复样本复杂度阈值与自由度启发式 $\\mathrm{dof} = r(p+q-r)$ 进行比较。选择所有正确的陈述。\n\nA. 在所述的各向同性高斯感知模型中，ETM 预测在 $m \\approx \\delta(\\mathcal{D})$ 处发生相变，并且对于秩为 $r$ 的点上的核范数最小化问题，$\\delta(\\mathcal{D})$ 等于 $r(p+q-r)$；因此，ETM 阈值与自由度计数相匹配。\n\nB. 对于各向同性高斯测量下的 $\\ell_{1}$ 最小化向量稀疏性问题，ETM 预测恢复 $\\mathbb{R}^{n}$ 中一个 $k$-稀疏向量需要 $m \\approx 2k$，这与自由度启发式 $2k$ 相吻合。\n\nC. 如果将感知算子替换为各向同性亚高斯系综（与高斯情况具有相同的协方差），那么基于 ETM 的阈值仍然与下降锥的统计维度成正比；对于核范数，这使得其在不依赖于 $p$ 和 $q$ 的绝对常数范围内与 $\\mathrm{dof} = r(p+q-r)$ 保持一致。\n\nD. 对于元素均匀随机采样和核范数最小化的矩阵补全问题，基于 ETM 的阈值在没有额外假设的情况下仍然是 $m \\approx r(p+q-r)$，因此在这种情况下它总是与自由度启发式一致。\n\nE. 如果 $X_{\\star}$ 具有重复奇异值，则核范数的下降锥会严格增大，并且 ETM 通常会预测一个严格大于 $r(p+q-r)$ 的样本复杂度；因此，自由度启发式可能低估超过一个常数因子。\n\nF. 对于协方差算子 $\\Sigma \\neq I$ 的各向异性高斯测量，ETM 阈值由在 $\\Sigma$ 诱导的几何中计算的统计维度决定，并且可能偏离 $r(p+q-r)$；与自由度启发式的一致性要求各向同性（即 $\\Sigma$ 与单位阵成比例）。",
            "solution": "首先验证问题陈述的科学合理性、一致性和完整性。\n\n### 第一步：提取已知条件\n-   **模型**：用于低秩恢复的线性矩阵感知。\n-   **真实矩阵**：$X_{\\star} \\in \\mathbb{R}^{p \\times q}$，$\\mathrm{rank}(X_{\\star}) = r$。\n-   **测量值**：$y = \\mathcal{A}(X_{\\star}) \\in \\mathbb{R}^{m}$，其中 $\\mathcal{A}: \\mathbb{R}^{p \\times q} \\to \\mathbb{R}^{m}$ 是一个线性算子。\n-   **感知系综**：算子 $\\mathcal{A}$ 在标准正交基中具有独立同分布的高斯坐标，经过归一化，使得当 $\\mathcal{A}$ 应用于单位弗罗贝尼乌斯范数矩阵时，每个测量坐标 $y_i$ 服从 $\\mathcal{N}(0, 1)$ 分布。这描述了标准的各向同性高斯系综，其中 $\\mathcal{A}(X)_i = \\langle A_i, X \\rangle_F$ 且矩阵 $A_i$ 的元素是独立同分布的 $\\mathcal{N}(0, 1)$。\n-   **恢复方法**：一个在测量一致性约束下最小化核范数 $\\|\\cdot\\|_{\\ast}$ 的凸规划：$\\min \\|X\\|_{\\ast}$，约束条件为 $\\mathcal{A}(X) = y$。\n-   **关键概念**：\n    -   **下降锥**：$\\mathcal{D} := \\mathcal{D}(\\|\\cdot\\|_{\\ast}, X_{\\star})$ 是核范数在 $X_{\\star}$ 处的下降锥。\n    -   **高斯宽度**：$w(\\mathcal{C}) := \\mathbb{E}\\sup_{u \\in \\mathcal{C}} \\langle g, u \\rangle$，对于 $\\mathcal{C} \\subset \\mathbb{R}^{p q}$ 和 $g \\sim \\mathcal{N}(0, I_{pq})$。\n    -   **统计维度**：对于一个闭凸锥 $\\mathcal{C}$，$\\delta(\\mathcal{C}) = \\mathbb{E}\\|\\Pi_{\\mathcal{C}}(g)\\|_{2}^{2}$。\n    -   **关系**：$w^{2}(\\mathcal{C} \\cap S^{pq-1})$ 和 $\\delta(\\mathcal{C})$ 的值相差一个加性常数，其中 $S^{pq-1}$ 是单位弗罗贝尼乌斯范数球面。\n-   **待使用的核心原理**：基于 Gordon 不等式的穿网逃逸 (ETM) 预测，当测量数量 $m$ 约等于下降锥的统计维度时，即 $m \\approx \\delta(\\mathcal{D})$，精确恢复会发生相变。\n-   **用于比较的启发式**：自由度启发式，$\\mathrm{dof} = r(p+q-r)$。\n-   **问题**：仅使用这些事实，将基于 ETM 的样本复杂度与自由度启发式进行比较，并从选项中找出所有正确的陈述。\n\n### 第二步：使用提取的已知条件进行验证\n问题陈述根植于压缩感知和高维概率的成熟数学理论。所有术语——核范数、下降锥、统计维度、高斯宽度、穿网逃逸和自由度启发式——都是该领域的标准术语。该问题是适定 (well-posed) 的，要求基于基本结果对理论预测 (ETM) 和已知启发式 (DoF) 进行比较。问题设置是自洽的，并为分析提供了所需的定义。没有科学或逻辑上的矛盾，没有伪深刻的主张，问题是客观且可形式化的。\n\n### 第三步：结论和行动\n问题是**有效的**。开始求解。\n\n### 推导与选项分析\n\n该问题要求我们使用“穿网逃逸”(ETM) 框架来分析低秩矩阵恢复的样本复杂度。ETM 原理为通过凸优化成功恢复所需的测量数量 $m$ 的阈值提供了一个精确的预测。对于一个通用的凸规划和各向同性高斯测量算子 $\\mathcal{A}$，成功与失败之间的相变发生在一个阈值 $m_{\\star}$ 处，由下式给出：\n$$m_{\\star} \\approx \\delta(\\mathcal{D})$$\n其中 $\\mathcal{D}$ 是目标函数在真实信号 $X_{\\star}$ 处的下降锥。锥 $\\mathcal{D}$ 的统计维度 $\\delta(\\mathcal{D})$ 是对其大小的一种度量。问题规定我们必须使用这一事实。\n\n对于一个秩为 $r$ 的矩阵 $X_{\\star} \\in \\mathbb{R}^{p \\times q}$，其自由度启发式为 $\\mathrm{dof} = p r + q r - r^2 = r(p+q-r)$。这计算了指定一个秩为 $r$ 的矩阵所需的自由参数数量，同时考虑了其分解中的冗余性。\n\n问题的核心在于核范数下降锥的 $\\delta(\\mathcal{D})$ 的值。该领域的一个核心结果，由 Amelunxen、Lotz、McCoy 和 Tropp 建立，为许多流行的凸正则化器在各向同性高斯系综假设下，提供了下降锥统计维度的精确公式。对于秩为 $r$ 的矩阵 $X_{\\star} \\in \\mathbb{R}^{p \\times q}$ （具有互不相同的非零奇异值）处的核范数 $\\|\\cdot\\|_\\ast$，其下降锥 $\\mathcal{D}(\\|\\cdot\\|_{\\ast}, X_{\\star})$ 的统计维度恰好是：\n$$\\delta(\\mathcal{D}) = r(p+q-r)$$\n\n有了这些基本结果，我们就可以评估每个选项了。\n\n**A. 在所述的各向同性高斯感知模型中，ETM 预测在 $m \\approx \\delta(\\mathcal{D})$ 处发生相变，并且对于秩为 $r$ 的点上的核范数最小化问题，$\\delta(\\mathcal{D})$ 等于 $r(p+q-r)$；因此，ETM 阈值与自由度计数相匹配。**\n\n-   ETM 的预测由 $m \\approx \\delta(\\mathcal{D})$ 给出。这是问题的一个前提。\n-   关于核范数下降锥的 $\\delta(\\mathcal{D})$ 等于 $r(p+q-r)$ 的陈述是锥几何和随机投影理论中的一个正确且基本的结果。\n-   自由度计数由 $\\mathrm{dof} = r(p+q-r)$ 给出。\n-   因此，ETM 阈值 $m \\approx r(p+q-r)$ 直接与 DoF 启发式相匹配。该陈述是既定事实的逻辑推论。\n\n**结论：正确。**\n\n**B. 对于各向同性高斯测量下的 $\\ell_{1}$ 最小化向量稀疏性问题，ETM 预测恢复 $\\mathbb{R}^{n}$ 中一个 $k$-稀疏向量需要 $m \\approx 2k$，这与自由度启发式 $2k$ 相吻合。**\n\n-   这个选项考虑了使用 $\\ell_1$-范数进行稀疏向量恢复的类似问题。真实信号是一个 $k$-稀疏向量。\n-   $2k$ 的 DoF 启发式是一个合理（尽管非正式）的计数（$k$ 个非零值及其 $k$ 个位置）。\n-   然而，对于 $\\ell_1$ 最小化的样本复杂度，ETM 的预测并非 $m \\approx 2k$。由 Donoho 和 Tanner 确定并通过 ETM 框架严格证明的精确相变更为复杂。在 $n \\to \\infty$ 和 $k/n \\to 0$ 的情况下，所需测量数量的尺度为 $m \\approx 2k \\log(n/k)$，而不是 $2k$。缺少对数因子使得该陈述不正确。\n\n**结论：不正确。**\n\n**C. 如果将感知算子替换为各向同性亚高斯系综（与高斯情况具有相同的协方差），那么基于 ETM 的阈值仍然与下降锥的统计维度成正比；对于核范数，这使得其在不依赖于 $p$ 和 $q$ 的绝对常数范围内与 $\\mathrm{dof} = r(p+q-r)$ 保持一致。**\n\n-   该陈述讨论了相变现象的普适性。Gordon 的 ETM 理论原生于高斯系综。然而，该领域的主要结果已经证实这些相变是普适的，意味着它们适用于更广泛的随机测量系综，包括各向同性亚高斯系综。\n-   对于这类系综，成功恢复的阈值仍然由问题的相同几何特性决定，因此与高斯统计维度 $\\delta(\\mathcal{D})$ 成正比。即，对于某个普适常数 $C$，有 $m \\ge C \\cdot \\delta(\\mathcal{D})$。\n-   由于 $\\delta(\\mathcal{D}) = r(p+q-r)$，样本复杂度仍然与 DoF 启发式成正比。“成正比”和“在绝对常数范围内”的措辞正确地捕捉了这些普适性结果的性质。\n\n**结论：正确。**\n\n**D. 对于元素均匀随机采样和核范数最小化的矩阵补全问题，基于 ETM 的阈值在没有额外假设的情况下仍然是 $m \\approx r(p+q-r)$，因此在这种情况下它总是与自由度启发式一致。**\n\n-   矩阵补全涉及一个特定的、高度结构化的测量算子，对应于对矩阵元素进行采样。这不是一个各向同性高斯或亚高斯系综。\n-   矩阵补全的分析有本质上的不同。至关重要的是，成功恢复不仅需要足够数量的样本，还需要对矩阵 $X_{\\star}$ 的奇异向量有**非相干性假设**。陈述中“没有额外假设”的说法是错误的。一个其质量集中在少数几个元素中的矩阵是无法通过少量随机样本恢复的。\n-   此外，所需的样本复杂度不是 $m \\approx r(p+q-r)$。已知在必要的非相干性条件下，其数量级为 $m \\gtrsim (p+q) r \\log(p+q)$。\n-   适用于高斯系综的 ETM 框架不能直接应用于矩阵补全的采样模型并得出这个简单的结果。\n\n**结论：不正确。**\n\n**E. 如果 $X_{\\star}$ 具有重复奇异值，则核范数的下降锥会严格增大，并且 ETM 通常会预测一个严格大于 $r(p+q-r)$ 的样本复杂度；因此，自由度启发式可能低估超过一个常数因子。**\n\n-   如果 $X_{\\star}$ 有重复奇异值，其次微分 $\\partial \\|X_{\\star}\\|_{\\ast}$ 的结构会发生变化。对称性的存在（在对应于重复奇异值的子空间中的旋转不变性）会扩大次微分集。\n-   下降锥 $\\mathcal{D}$ 由满足对所有次梯度 $S \\in \\partial \\|X_{\\star}\\|_{\\ast}$ 都有 $\\langle S, \\Delta \\rangle \\le 0$ 的方向 $\\Delta$ 组成。如果次梯度集 $\\partial \\|X_{\\star}\\|_{\\ast}$ 变大，这将对 $\\Delta$ 施加更多约束。由更多约束定义的集合会更小。因此，下降锥严格地**缩小**，而不是增大。\n-   一个更小的下降锥具有更小的统计维度 $\\delta(\\mathcal{D})$。根据 ETM 原理，这将预测一个**更低**的恢复样本复杂度，而不是更高。该陈述的前提是错误的。\n\n**结论：不正确。**\n\n**F. 对于协方差算子 $\\Sigma \\neq I$ 的各向异性高斯测量，ETM 阈值由在 $\\Sigma$ 诱导的几何中计算的统计维度决定，并且可能偏离 $r(p+q-r)$；与自由度启发式的一致性要求各向同性（即 $\\Sigma$ 与单位阵成比例）。**\n\n-   各向异性测量意味着感知矩阵的行（向量化的 $A_i$）是从 $\\mathcal{N}(0, \\Sigma)$ 中抽取的，其中 $\\Sigma$ 与单位矩阵 $I$ 不成比例。这打破了测量系综的旋转不变性。\n-   ETM 框架可以适应这种情况。产生的相变阈值由一个修正的统计维度决定，该维度是相对于由 $\\Sigma$ 诱导的几何计算的。这通常表示为 $\\delta_{\\Sigma}(\\mathcal{D})$。\n-   这个新量 $\\delta_{\\Sigma}(\\mathcal{D})$ 取决于锥 $\\mathcal{D}$ 和协方差结构 $\\Sigma$ 之间的相互作用。通常，它不会等于各向同性情况下的结果 $r(p+q-r)$。例如，如果测量的方差在下降锥“薄”的方向上很高，恢复可能会更难（需要更大的 $m$），反之亦然。\n-   简单的公式 $\\delta(\\mathcal{D}) = r(p+q-r)$ 是标准高斯系综的旋转不变性（各向同性）的直接结果。当这种对称性被打破时（$\\Sigma \\neq cI$），这个简单的公式就不再成立。因此，与 DoF 启发式的一致性是各向同性模型的一个特殊特征。\n\n**结论：正确。**",
            "answer": "$$\\boxed{\\text{ACF}}$$"
        },
        {
            "introduction": "理论的最终检验在于实践，这项练习将抽象的数学概念与可观察的经验结果联系起来。你将编写一个程序来模拟稀疏信号的恢复过程，从而亲眼见证戈den定理所预测的急剧相变现象。通过将经验恢复成功率与由统计维度（与高斯宽度密切相关）确定的理论阈值进行比较 ，这项编码实践将使理论预测变得具体化，直观地展示理论在算法性能预测中的强大威力。",
            "id": "3481865",
            "problem": "令 $n \\in \\mathbb{N}$，令 $x^\\star \\in \\mathbb{R}^n$ 是一个 $k$-稀疏信号，意味着 $x^\\star$ 中恰好有 $k$ 个坐标非零。考虑线性测量 $y = A x^\\star$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的元素是独立同分布的标准正态分布。我们关注的锥是凸函数 $\\|\\cdot\\|_1$ 在点 $x^\\star$ 处的下降锥 $K = \\mathcal{D}(\\|\\cdot\\|_1, x^\\star)$，定义为\n$$\n\\mathcal{D}(\\|\\cdot\\|_1, x^\\star) = \\operatorname{cone}\\left\\{h \\in \\mathbb{R}^n : \\|x^\\star + h\\|_1 \\le \\|x^\\star\\|_1 \\right\\}.\n$$\n锥 $K$ 的高斯宽度 $w(K)$ 定义为\n$$\nw(K) = \\mathbb{E}\\left[ \\sup_{u \\in K \\cap \\mathbb{S}^{n-1}} \\langle g, u \\rangle \\right],\n$$\n其中 $\\mathbb{S}^{n-1}$ 是 $\\mathbb{R}^n$ 中的单位球面，$g \\sim \\mathcal{N}(0, I_n)$ 是一个标准高斯向量。Gordon 的“穿网逃逸”定理断言，当余维数 $m$ 大于 $K$ 的高斯宽度的某个函数时，一个随机子空间很可能与 $K$ 不相交；反之，对于较小的 $m$，相交是很有可能的。\n\n你的任务是编写一个完整的、独立的程序，通过以下方式为下降锥 $K = \\mathcal{D}(\\|\\cdot\\|_1, x^\\star)$ 演示这一现象：\n1. 使用锥几何的基本原理，通过下降锥的统计维度来计算高斯宽度平方 $w(K)^2$ 的近似值。统计维度定义为\n$$\n\\delta(K) = \\mathbb{E}\\left[ \\|\\Pi_K(g)\\|_2^2 \\right],\n$$\n其中 $\\Pi_K(g)$ 表示 $g$ 到 $K$ 上的欧几里得投影，并且与 $K \\cap \\mathbb{S}^{n-1}$ 的高斯宽度平方密切相关。\n2. 经验性地估计随机零空间 $\\operatorname{Null}(A)$ 是否与 $K$ 有非平凡交集，这等价于表明 $\\ell_1$-最小化恢复失败。具体来说，对于每次试验，求解以下凸优化问题\n$$\n\\min_{x \\in \\mathbb{R}^n} \\|x\\|_1 \\quad \\text{subject to} \\quad A x = y,\n$$\n如果最小化器在数值容差范围内等于 $x^\\star$，则声明恢复成功，否则声明失败。存在一个非零的 $h \\in \\operatorname{Null}(A) \\cap K$ 表明恢复失败。\n3. 将经验成功率与基于 $m$ 是大于还是小于计算出的 $\\delta(K)$ 的理论预测进行比较。\n\n使用以下经过充分检验的定义和事实作为你的基本依据：\n- 一个真、凸、下半连续函数在某一点的下降锥收集了所有不增加该函数值的方向。\n- 高斯宽度和统计维度是控制高维凸恢复中相变的几何度量。\n- 对于 $\\ell_1$ 范数，在一个 $k$-稀疏点处的下降锥的统计维度可以通过一个涉及次微分和标量参数的期望来刻画，并且可以使用标准正态随机变量绝对值的分布进行数值计算。\n\n程序要求：\n- 实现一个数值程序，通过在非负标量参数上最小化一个从 $|g|$（其中 $g \\sim \\mathcal{N}(0,1)$）的半正态分布推导出的适当期望，来为给定的 $(n,k)$ 近似计算 $\\delta\\!\\left(\\mathcal{D}(\\|\\cdot\\|_1, x^\\star)\\right)$。\n- 对于每个测试用例，生成一个具有独立同分布标准正态元素的矩阵 $A$ 和一个随机的 $k$-稀疏 $x^\\star$（其非零元素从连续分布中抽取），然后使用线性规划公式求解 $\\ell_1$-最小化问题，并记录恢复是否成功。\n- 对于每个测试用例，输出两个数字：预测指标（如果 $m  \\delta(K)$ 则为 $1$，否则为 $0$）和在指定试验次数中的经验恢复成功分数，四舍五入到三位小数。\n\n测试套件：\n- 案例 1（理想路径，高于阈值）：$(n,k,m,T) = (200,10,85,8)$。\n- 案例 2（低于阈值）：$(n,k,m,T) = (200,10,55,8)$。\n- 案例 3（接近阈值）：$(n,k,m,T) = (200,10,70,8)$。\n- 案例 4（边界，零稀疏）：$(n,k,m,T) = (100,0,1,8)$。\n- 案例 5（相对稀疏度较高）：$(n,k,m,T) = (200,60,150,6)$。\n\n最终输出格式：\n- 你的程序应该生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，并且本身是一个 $[\\text{指标}, \\text{分数}]$ 形式的双元素列表。例如，输出应具有以下形式\n$$\n[[i_1,f_1],[i_2,f_2],\\dots,[i_5,f_5]],\n$$\n其中每个 $i_j$ 是整数 $0$ 或 $1$，每个 $f_j$ 是四舍五入到三位小数的小数。",
            "solution": "问题陈述在压缩感知和高维概率领域提出了一个有效且定义明确的任务。我们首先验证该问题，然后提供一个完整的解决方案。\n\n### 问题验证\n\n**第 1 步：提取已知信息**\n\n- **信号与稀疏度**：$x^\\star \\in \\mathbb{R}^n$ 是一个 $k$-稀疏信号，其中 $n \\in \\mathbb{N}$，$k$ 是非零坐标的数量。\n- **测量模型**：$y = A x^\\star$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 具有独立同分布（i.i.d.）的标准正态元素。\n- **下降锥**：$K = \\mathcal{D}(\\|\\cdot\\|_1, x^\\star) = \\operatorname{cone}\\left\\{h \\in \\mathbb{R}^n : \\|x^\\star + h\\|_1 \\le \\|x^\\star\\|_1 \\right\\}$。\n- **高斯宽度**：$w(K) = \\mathbb{E}\\left[ \\sup_{u \\in K \\cap \\mathbb{S}^{n-1}} \\langle g, u \\rangle \\right]$，其中 $g \\sim \\mathcal{N}(0, I_n)$。\n- **统计维度**：$\\delta(K) = \\mathbb{E}\\left[ \\|\\Pi_K(g)\\|_2^2 \\right]$，其中 $\\Pi_K(g)$ 是 $g$ 在 $K$ 上的欧几里得投影。\n- **恢复问题**：$\\min_{x \\in \\mathbb{R}^n} \\|x\\|_1$ 约束于 $A x = y$。\n- **恢复成功条件**：恢复问题的最小化器等于 $x^\\star$。这当且仅当 $A$ 的零空间 $\\operatorname{Null}(A)$ 与下降锥 $K$ 没有非平凡交集时发生。\n- **任务**：对于给定的参数 $(n,k,m,T)$，计算理论成功指标（如果 $m  \\delta(K)$ 则为 $1$，否则为 $0$）和在 $T$ 次试验中的经验成功分数。\n- **测试用例**：\n    1. $(n,k,m,T) = (200,10,85,8)$\n    2. $(n,k,m,T) = (200,10,55,8)$\n    3. $(n,k,m,T) = (200,10,70,8)$\n    4. $(n,k,m,T) = (100,0,1,8)$\n    5. $(n,k,m,T) = (200,60,150,6)$\n\n**第 2 步：使用提取的已知信息进行验证**\n\n- **科学依据**：该问题牢固地植根于现代压缩感知理论。下降锥、统计维度、高斯宽度等概念及其与凸优化中相变现象的联系是该领域的核心、公认成果（参见 Amelunxen, Lotz, McCoy, Tropp, 2014, \"Living on the Edge: Phase Transitions in Convex Programs with Random Data\"）。\n- **适定性**：该问题是适定的。它要求进行数值计算和仿真来验证一个已知的理论结果。任务规定明确，所提供的参数允许产生一组唯一的输出。\n- **客观性**：问题以精确的数学语言陈述，没有主观性。\n- **完整性**：问题提供了所有必要的定义和参数。它隐含地依赖于已知的 $\\ell_1$ 下降锥统计维度的公式，这在此背景下是标准的。\n- **无其他缺陷**：该问题没有矛盾、不切实际（在数学框架内）或结构不良之处。\n\n**第 3 步：结论与行动**\n\n该问题是**有效的**。我们继续提供完整解决方案。\n\n### 解决方案\n\n该问题探讨了压缩感知中的相变现象，即通过 $\\ell_1$-最小化从线性测量 $y=Ax^\\star$ 中恢复稀疏信号 $x^\\star$ 的成功率，随着测量次数 $m$ 的变化而发生急剧改变。这种相变由下降锥 $K = \\mathcal{D}(\\|\\cdot\\|_1, x^\\star)$ 的统计维度 $\\delta(K)$ 精确刻画。\n\n基本原理是，对于一个随机高斯矩阵 $A$，如果 $m  \\delta(K)$，则恢复 $x^\\star$ 的概率很高；如果 $m  \\delta(K)$，则概率很低。点 $m \\approx \\delta(K)$ 标记了相变边界。我们的解决方案包括两部分：首先，计算理论阈值 $\\delta(K)$；其次，通过模拟恢复过程来经验性地验证该预测。\n\n**1. 通过统计维度进行理论预测**\n\n在 $k$-稀疏信号 $x^\\star \\in \\mathbb{R}^n$ 处，$\\ell_1$-范数下降锥的统计维度，记为 $K=\\mathcal{D}(\\|\\cdot\\|_1, x^\\star)$，与 $x^\\star$ 非零项的支撑集位置和符号无关。它由以下公式给出：\n$$\n\\delta(K) = k + \\min_{\\lambda \\ge 0} \\left\\{ (n-k) \\mathbb{E}\\left[(\\lvert Z \\rvert - \\lambda)^2_+\\right] + k\\lambda^2 \\right\\}\n$$\n其中 $Z \\sim \\mathcal{N}(0,1)$ 是一个标准正态随机变量，而 $(t)_+ = \\max(t, 0)$ 是正部函数。期望项可以用涉及标准正态变量的概率密度函数（PDF）$\\phi$ 和累积分布函数（CDF）$\\Phi$ 的闭式形式计算：\n$$\n\\mathbb{E}\\left[(\\lvert Z \\rvert - \\lambda)^2_+\\right] = 2 \\int_{\\lambda}^{\\infty} (z-\\lambda)^2 \\phi(z) dz = 2 \\left[ (1+\\lambda^2)(1-\\Phi(\\lambda)) - \\lambda\\phi(\\lambda) \\right]\n$$\n对于 $\\lambda \\ge 0$。因此，寻找 $\\delta(K)$ 的问题简化为在非负标量 $\\lambda$ 上的一个一维凸优化问题。我们通过数值求解来为测试套件中的每对 $(n,k)$ 找到 $\\delta(K)$ 的值。然后，恢复成功的理论预测由一个指示函数给出：如果 $m  \\delta(K)$ 则为 $1$，否则为 $0$。\n\n一个特殊情况是 $k=0$，此时 $x^\\star = 0$。下降锥为 $K = \\{h : \\|h\\|_1 \\le 0\\} = \\{0\\}$。任何向量在 $\\{0\\}$ 上的投影都是零向量，所以 $\\delta(\\{0\\}) = \\mathbb{E}[\\|\\Pi_{\\{0\\}}(g)\\|_2^2] = 0$。\n\n**2. 通过仿真进行经验验证**\n\n我们执行蒙特卡洛模拟，来为每个测试用例 $(n,k,m,T)$ 估计成功恢复的经验概率。对于 $T$ 次试验中的每一次：\na. 生成一个随机的 $k$-稀疏信号 $x^\\star \\in \\mathbb{R}^n$。随机均匀地选择一个大小为 $k$ 的支撑集，非零项从标准正态分布中抽取。\nb. 生成一个 $m \\times n$ 的测量矩阵 $A$，其元素为独立同分布的 $\\mathcal{N}(0,1)$。\nc. 计算测量向量 $y = Ax^\\star$。\nd. 求解 $\\ell_1$-最小化问题（也称为基追踪）以找到估计值 $\\hat{x}$：\n$$\n\\hat{x} = \\arg\\min_{x \\in \\mathbb{R}^n} \\|x\\|_1 \\quad \\text{subject to} \\quad Ax = y\n$$\n这个凸优化问题通过将 $x$ 表示为两个非负向量的差 $x = u - v$（其中 $u_i, v_i \\ge 0$）来重构为线性规划（LP）。该 LP 为：\n$$\n\\min_{u, v \\in \\mathbb{R}^n} \\sum_{i=1}^n (u_i + v_i) \\quad \\text{subject to} \\quad A(u-v) = y, \\quad u \\ge 0, \\quad v \\ge 0.\n$$\n此 LP 使用标准数值求解器求解。\ne. 如果解 $\\hat{x}$ 在数值上接近原始信号 $x^\\star$，则声明恢复“成功”。我们使用混合的绝对-相对误差容差：对于 $k>0$，成功定义为 $\\|\\hat{x} - x^\\star\\|_2 / \\|x^\\star\\|_2  10^{-6}$；对于 $k=0$，成功定义为 $\\|\\hat{x}\\|_2  10^{-6}$。\n经验成功分数是成功试验的次数除以总试验次数 $T$。将此分数与理论指标进行比较。\n\n针对指定的测试用例实施此程序将展示由统计维度预测的相变的急剧性。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linprog, minimize_scalar\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes theoretical and empirical results for l1 recovery phase transitions.\n    \"\"\"\n    TOLERANCE = 1e-6\n\n    def calculate_statistical_dimension(n, k):\n        \"\"\"\n        Calculates the statistical dimension delta(K) for the l1 descent cone.\n        \n        The formula is:\n        delta(K) = k + min_{lambda >= 0} { (n-k) * E[(|Z|-lambda)^2_+] + k*lambda^2 }\n        where Z ~ N(0,1).\n        \"\"\"\n        if k == 0:\n            return 0.0\n        if k == n:\n            return float(n)\n\n        def expectation_term(lam):\n            \"\"\"Computes E[(|Z|-lambda)^2_+].\"\"\"\n            if lam  0:\n                # The minimization is over lambda >= 0\n                return np.inf\n            # Using the closed-form expression\n            # 2 * [ (1+lam^2)*(1-Phi(lam)) - lam*phi(lam) ]\n            return 2 * ( (1 + lam**2) * (1 - norm.cdf(lam)) - lam * norm.pdf(lam) )\n\n        def objective(lam, n_val, k_val):\n            \"\"\"The function to be minimized over lambda.\"\"\"\n            return (n_val - k_val) * expectation_term(lam) + k_val * lam**2\n\n        # Numerically minimize the objective function to find the minimum value.\n        # The minimization is over lambda >= 0.\n        # 'bounded' method is suitable for box constraints.\n        res = minimize_scalar(\n            objective, \n            args=(n, k), \n            bounds=(0, 10), # lambda is unlikely to be large, 10 is a safe upper bound.\n            method='bounded'\n        )\n        \n        min_val = res.fun\n        return k + min_val\n\n    def run_single_trial(n, k, m, rng):\n        \"\"\"\n        Runs a single trial of sparse recovery.\n        \"\"\"\n        # 1. Generate a random k-sparse signal x_star\n        x_star = np.zeros(n)\n        if k > 0:\n            support = rng.choice(n, k, replace=False)\n            x_star[support] = rng.standard_normal(k)\n\n        # 2. Generate measurement matrix A and measurements y\n        A = rng.standard_normal((m, n))\n        y = A @ x_star\n        \n        # 3. Solve the l1 minimization problem (Basis Pursuit) via Linear Programming\n        # Problem: min ||x||_1 s.t. Ax = y\n        # LP form:   min c.T @ z s.t. A_eq @ z = b_eq, z >= 0\n        # where z = [u, v], x = u - v, ||x||_1 = 1.T @ u + 1.T @ v\n        c_lp = np.ones(2 * n)\n        A_lp = np.hstack([A, -A])\n        b_lp = y\n        \n        # Using 'highs' solver, which is robust and efficient.\n        res = linprog(c=c_lp, A_eq=A_lp, b_eq=b_lp, bounds=(0, None), method='highs')\n\n        if not res.success:\n            return False\n\n        # 4. Reconstruct the solution and check for success\n        x_sol = res.x[:n] - res.x[n:]\n        \n        if k == 0:\n            # Absolute error for the zero vector\n            norm_x_star = 0\n            if np.linalg.norm(x_sol)  TOLERANCE:\n                return True\n        else:\n            # Relative error for non-zero vectors\n            norm_x_star = np.linalg.norm(x_star)\n            if np.linalg.norm(x_sol - x_star) / norm_x_star  TOLERANCE:\n                return True\n        \n        return False\n\n    # Test cases: (n, k, m, T)\n    test_cases = [\n        (200, 10, 85, 8),\n        (200, 10, 55, 8),\n        (200, 10, 70, 8),\n        (100, 0, 1, 8),\n        (200, 60, 150, 6)\n    ]\n    \n    final_results = []\n    rng = np.random.default_rng(seed=42) # Seed for reproducibility\n    \n    # Cache for statistical dimension calculation\n    delta_cache = {}\n\n    for n, k, m, T in test_cases:\n        # Calculate theoretical prediction\n        if (n, k) not in delta_cache:\n            delta_cache[(n, k)] = calculate_statistical_dimension(n, k)\n        \n        delta_K = delta_cache[(n, k)]\n        theoretical_indicator = 1 if m > delta_K else 0\n        \n        # Run empirical simulations\n        success_count = 0\n        if T > 0:\n            for _ in range(T):\n                if run_single_trial(n, k, m, rng):\n                    success_count += 1\n            empirical_fraction = success_count / T\n        else:\n            empirical_fraction = 0.0\n\n        final_results.append(f\"[{theoretical_indicator},{empirical_fraction:.3f}]\")\n\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```"
        }
    ]
}