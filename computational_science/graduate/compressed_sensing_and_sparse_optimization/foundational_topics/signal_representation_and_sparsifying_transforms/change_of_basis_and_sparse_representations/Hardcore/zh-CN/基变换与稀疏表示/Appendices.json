{
    "hands_on_practices": [
        {
            "introduction": "在稀疏信号恢复领域，一个核心问题是表示的唯一性：给定一个信号，其稀疏表示是否是唯一的？“矩阵的火花”（spark）这一概念为此提供了有力的解答，它将字典矩阵列向量的线性相关性与稀疏解的唯一性直接联系起来。通过这个练习 ，您将亲手计算一个字典矩阵的火花，并运用它来论证何种稀疏度的信号可以被唯一表示，从而深入理解稀疏表示理论的基石。",
            "id": "3434598",
            "problem": "设 $\\Phi \\in \\mathbb{R}^{2 \\times 4}$ 是字典矩阵\n$$\n\\Phi=\\begin{bmatrix}\n1  0  1  1\\\\\n0  1  1  -1\n\\end{bmatrix},\n$$\n其列向量 $\\phi_{1},\\phi_{2},\\phi_{3},\\phi_{4} \\in \\mathbb{R}^{2}$ 用于构成稀疏表示 $y=\\Phi x$，其中系数向量 $x \\in \\mathbb{R}^{4}$。向量 $x$ 的非零元素个数称为其 $\\ell_{0}$-“范数”（基数），如果向量 $x$ 最多有 $k$ 个非零元素，则称其为$k$-稀疏的。矩阵的 spark，记作 $\\mathrm{spark}(\\Phi)$，定义为 $\\Phi$ 中线性相关的列的最小数量。\n\n仅使用基本的线性代数定义和事实，完成以下任务：\n- 根据定义和环境维度约束进行推理，计算 $\\mathrm{spark}(\\Phi)$。\n- 基于 spark 的定义和 $k$-稀疏表示的概念，判断每个 $1$-稀疏表示 $y=\\Phi x$ 是否唯一，以及是否存在非唯一的 $2$-稀疏表示。请纯粹从第一性原理出发证明你的结论，并且如果当 $k=2$ 时可能存在非唯一性，请给出同一个 $y$ 的两个明确的不同 $2$-稀疏表示。\n\n请提供 $\\mathrm{spark}(\\Phi)$ 的值作为最终答案。无需四舍五入。",
            "solution": "该问题经检验在科学上是合理的、适定的和客观的。这是稀疏表示理论基础中的一个标准练习。\n\n问题要求三件事：计算给定矩阵 $\\Phi$ 的 spark，分析 $1$-稀疏表示的唯一性，以及分析 $2$-稀疏表示的唯一性，所有论证都需从第一性原理出发。\n\n给定的字典矩阵是 $\\Phi \\in \\mathbb{R}^{2 \\times 4}$，其列向量为 $\\phi_1, \\phi_2, \\phi_3, \\phi_4 \\in \\mathbb{R}^{2}$：\n$$\n\\Phi = \\begin{bmatrix} \\phi_1  \\phi_2  \\phi_3  \\phi_4 \\end{bmatrix} = \\begin{bmatrix}\n1  0  1  1\\\\\n0  1  1  -1\n\\end{bmatrix}\n$$\n\n**第一部分：计算 $\\mathrm{spark}(\\Phi)$**\n\n矩阵 $\\Phi$ 的 spark，记作 $\\mathrm{spark}(\\Phi)$，定义为 $\\Phi$ 中线性相关的列的最小数量。我们将按递增的规模检查列的子集。\n\n1.  **大小为 $1$ 的子集**：单个列向量 $\\phi_i$ 线性相关当且仅当它是零向量。$\\Phi$ 的列向量为：\n    $$\n    \\phi_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad\n    \\phi_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad\n    \\phi_3 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad\n    \\phi_4 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n    $$\n    这些向量中没有一个是零向量。因此，没有大小为 $1$ 的子集是线性相关的。这意味着 $\\mathrm{spark}(\\Phi)  1$。\n\n2.  **大小为 $2$ 的子集**：在 $\\mathbb{R}^2$ 中，当 $i \\neq j$ 时，两个向量的集合 $\\{\\phi_i, \\phi_j\\}$ 线性相关当且仅当其中一个是另一个的标量倍，或者等价地，由这两列组成的矩阵的行列式为零。我们检查所有 $\\binom{4}{2}=6$ 对：\n    -   $\\det(\\begin{bmatrix} \\phi_1  \\phi_2 \\end{bmatrix}) = \\det(\\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}) = 1 \\neq 0$。\n    -   $\\det(\\begin{bmatrix} \\phi_1  \\phi_3 \\end{bmatrix}) = \\det(\\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix}) = 1 \\neq 0$。\n    -   $\\det(\\begin{bmatrix} \\phi_1  \\phi_4 \\end{bmatrix}) = \\det(\\begin{bmatrix} 1  1 \\\\ 0  -1 \\end{bmatrix}) = -1 \\neq 0$。\n    -   $\\det(\\begin{bmatrix} \\phi_2  \\phi_3 \\end{bmatrix}) = \\det(\\begin{bmatrix} 0  1 \\\\ 1  1 \\end{bmatrix}) = -1 \\neq 0$。\n    -   $\\det(\\begin{bmatrix} \\phi_2  \\phi_4 \\end{bmatrix}) = \\det(\\begin{bmatrix} 0  1 \\\\ 1  -1 \\end{bmatrix}) = -1 \\neq 0$。\n    -   $\\det(\\begin{bmatrix} \\phi_3  \\phi_4 \\end{bmatrix}) = \\det(\\begin{bmatrix} 1  1 \\\\ 1  -1 \\end{bmatrix}) = -1 - 1 = -2 \\neq 0$。\n    由于没有一个行列式为零，所以每对列向量都是线性无关的。因此，$\\mathrm{spark}(\\Phi)  2$。\n\n3.  **大小为 $3$ 的子集**：$\\Phi$ 的列向量是环境空间 $\\mathbb{R}^2$ 中的向量。线性代数的一个基本定理指出，在 $m$ 维向量空间中，任何 $p$ 个向量的集合，如果 $p  m$，则是线性相关的。这里，空间的维数是 $m=2$。对于任何 $p=3$ 个列向量的子集，我们有 $3  2$。因此，$\\Phi$ 的任意 $3$ 个列向量的集合都必须是线性相关的。\n\n由于我们已经确定 $\\mathrm{spark}(\\Phi)  2$ 并且任意 $3$ 个列向量的集合都是线性相关的，所以线性相关的列的最小数量必须恰好是 $3$。\n因此，$\\mathrm{spark}(\\Phi) = 3$。\n\n**第二部分：稀疏表示的唯一性**\n\n如果存在两个不同的系数向量 $x_1, x_2$ 使得 $\\Phi x_1 = \\Phi x_2 = y$，则表示 $y = \\Phi x$ 是非唯一的。这等价于 $\\Phi(x_1 - x_2) = 0$，其中 $z = x_1 - x_2$ 是 $\\Phi$ 的零空间中的一个非零向量。向量 $z$ 表示了与它的非零元素相对应的 $\\Phi$ 的列之间的线性相关性。根据 spark 的定义，任何此类向量 $z$ 中非零元素的最小数量恰好是 $\\mathrm{spark}(\\Phi)$。因此，对于任何 $z \\in \\mathrm{null}(\\Phi), z \\neq 0$，我们必须有 $\\|z\\|_0 \\ge \\mathrm{spark}(\\Phi) = 3$。\n\n**$1$-稀疏表示的唯一性 ($k=1$):**\n如果一个向量 $x$ 最多有一个非零元素，即 $\\|x\\|_0 \\le 1$，则称其为$1$-稀疏的。\n为了导出矛盾，我们假设存在两个不同的$1$-稀疏向量 $x_1$ 和 $x_2$，使得 $\\Phi x_1 = \\Phi x_2 = y$。\n由于 $x_1$ 和 $x_2$ 是不同的，它们的差 $z = x_1 - x_2$ 是 $\\Phi$ 的零空间中的一个非零向量。\n$z$ 中非零元素的数量受 $x_1$ 和 $x_2$ 中非零元素数量之和的限制：\n$$\n\\|z\\|_0 = \\|x_1 - x_2\\|_0 \\le \\|x_1\\|_0 + \\|x_2\\|_0\n$$\n由于 $x_1$ 和 $x_2$ 是$1$-稀疏的，所以 $\\|x_1\\|_0 \\le 1$ 且 $\\|x_2\\|_0 \\le 1$。因此，\n$$\n\\|z\\|_0 \\le 1 + 1 = 2\n$$\n然而，如前所述，$\\Phi$ 的零空间中的任何非零向量 $z$ 都必须满足 $\\|z\\|_0 \\ge \\mathrm{spark}(\\Phi) = 3$。这导致了矛盾 $3 \\le \\|z\\|_0 \\le 2$。\n因此，我们的初始假设必定是错误的。不存在两个不同的$1$-稀疏向量可以产生相同的表示 $y$。每个$1$-稀疏表示都是唯一的。\n\n**$2$-稀疏表示的非唯一性 ($k=2$):**\n如果一个向量 $x$ 满足 $\\|x\\|_0 \\le 2$，则称其为$2$-稀疏的。我们研究是否存在非唯一的$2$-稀疏表示。\n我们再次考虑两个不同的$2$-稀疏向量 $x_1, x_2$ 产生相同的 $y$。它们的差 $z = x_1 - x_2$ 必须是 $\\mathrm{null}(\\Phi)$ 中的一个非零向量。\n$z$ 的稀疏度现在的界限是：\n$$\n\\|z\\|_0 \\le \\|x_1\\|_0 + \\|x_2\\|_0 \\le 2 + 2 = 4\n$$\n结合 spark 条件，我们需要一个零空间向量 $z \\neq 0$ 使得 $3 \\le \\|z\\|_0 \\le 4$。这并不矛盾，所以非唯一的$2$-稀疏表示可能存在。为了证实这一点，我们必须给出一个明确的例子。\n\n我们寻找一个非零向量 $z = (z_1, z_2, z_3, z_4)^T$ 使得 $\\Phi z = 0$。这给出了方程组：\n$$\nz_1 + z_3 + z_4 = 0 \\\\\nz_2 + z_3 - z_4 = 0\n$$\n通过观察列之间的线性相关性，可以找到一个简单的非零解。通过观察可知，$\\phi_3 = \\phi_1 + \\phi_2$。这可以重写为 $1 \\cdot \\phi_1 + 1 \\cdot \\phi_2 - 1 \\cdot \\phi_3 + 0 \\cdot \\phi_4 = 0$。这对应于 $\\Phi$ 的零空间中的一个向量 $z = (1, 1, -1, 0)^T$。注意 $\\|z\\|_0=3$，这与 $\\mathrm{spark}(\\Phi)=3$ 一致。\n\n现在我们必须将 $z$ 分解为 $z = x_1 - x_2$，其中 $x_1$ 和 $x_2$ 是不同的$2$-稀疏向量。\n我们根据 $z$ 的正项和负项来定义 $x_1$ 和 $x_2$。\n设 $x_1 = (1, 1, 0, 0)^T$。这个向量是$2$-稀疏的，因为 $\\|x_1\\|_0 = 2$。\n设 $x_2 = (0, 0, 1, 0)^T$。这个向量是$1$-稀疏的，因为 $\\|x_2\\|_0 = 1$。由于 $1 \\le 2$，$x_2$ 也是一个$2$-稀疏向量。\n向量 $x_1$ 和 $x_2$ 是不同的。\n我们检查它们是否生成相同的信号 $y$：\n$$\ny_1 = \\Phi x_1 = 1 \\cdot \\phi_1 + 1 \\cdot \\phi_2 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\ny_2 = \\Phi x_2 = 1 \\cdot \\phi_3 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n由于 $y_1 = y_2$，我们找到了两个不同的$2$-稀疏向量 $x_1$ 和 $x_2$，它们产生了相同的表示 $y = (1, 1)^T$。\n这表明对于这个字典 $\\Phi$，非唯一的$2$-稀疏表示可以并且确实存在。",
            "answer": "$$\n\\boxed{3}\n$$"
        },
        {
            "introduction": "理解了表示的唯一性后，下一个关键问题是如何确保测量过程能有效保留稀疏信号中的信息。受限等距性质（Restricted Isometry Property, RIP）正是为此而生，它通过保证测量矩阵在稀疏向量构成的子空间上近似于一个等距变换，为信号的稳定恢复提供了理论依据。这个实践  要求您直接根据定义，通过计算所有相关子矩阵的奇异值，来精确求解受限等距常数 $\\delta_2$，这能加深您对 RIP 如何量化测量矩阵质量的理解。",
            "id": "3434608",
            "problem": "考虑压缩感知中的线性测量模型，其中一个测量矩阵 $A \\in \\mathbb{R}^{3 \\times 4}$ 和一个表示基 $\\Phi \\in \\mathbb{R}^{4 \\times 4}$ 作用于系数向量 $x \\in \\mathbb{R}^{4}$。设矩阵 $A$ 和基 $\\Phi$ 由下式给出\n$$\nA=\\frac{1}{2}\\begin{bmatrix}\n1  0  1  -1 \\\\\n0  1  1  1 \\\\\n1  1  0  1\n\\end{bmatrix}, \\qquad \\Phi=I_4,\n$$\n其中 $I_4$ 表示 $4 \\times 4$ 的单位矩阵。阶数为 $s$ 的限制等距性质（RIP）通过限制等距常数 $\\delta_s$ 来量化 $A\\Phi$ 在多大程度上保持了 $s$-稀疏向量的欧几里得范数，$\\delta_s$ 定义为满足以下不等式的最小非负数\n$$\n(1-\\delta_s)\\|x\\|_2^2 \\le \\|A\\Phi x\\|_2^2 \\le (1+\\delta_s)\\|x\\|_2^2\n$$\n对于所有 $s$-稀疏向量 $x$ 成立。\n\n专注于 $s=2$ 的情况。枚举由 $|T|=2$ 的支撑集 $T \\subset \\{1,2,3,4\\}$ 导出的 $A\\Phi$ 的所有 $\\binom{4}{2}$ 个两列子矩阵，计算每个这样的 $3 \\times 2$ 子矩阵的最小和最大奇异值，并使用限制等距常数的基本定义，确定 $A\\Phi$ 的 $\\delta_2$ 的一个精确的闭式表达式。将最终答案表示为一个没有舍入的精确解析表达式。",
            "solution": "问题陈述已被解析和验证。问题是科学上合理的、适定的、客观的，并包含了唯一解所需的所有必要信息。这是压缩感知理论中的一个标准练习。因此，我们着手求解。\n\n该问题要求计算给定矩阵 $A\\Phi$ 的限制等距常数（RIC）$\\delta_2$。\n令我们感兴趣的矩阵为 $M = A\\Phi$。输入矩阵由下式给出\n$$\nA=\\frac{1}{2}\\begin{bmatrix}\n1  0  1  -1 \\\\\n0  1  1  1 \\\\\n1  1  0  1\n\\end{bmatrix}, \\qquad \\Phi=I_4\n$$\n其中 $I_4$ 是 $4 \\times 4$ 的单位矩阵。因此，矩阵 $M$ 就是 $A$：\n$$\nM = A = \\frac{1}{2}\\begin{bmatrix}\n1  0  1  -1 \\\\\n0  1  1  1 \\\\\n1  1  0  1\n\\end{bmatrix}\n$$\n限制等距常数 $\\delta_s$ 是满足以下不等式的最小非负数\n$$\n(1-\\delta_s)\\|x\\|_2^2 \\le \\|M x\\|_2^2 \\le (1+\\delta_s)\\|x\\|_2^2\n$$\n对于所有 $s$-稀疏向量 $x \\in \\mathbb{R}^4$。一个 $s$-稀疏向量 $x$ 最多有 $s$ 个非零项。令 $T = \\text{supp}(x)$ 为 $x$ 的非零项的索引集，其中 $|T| \\le s$。令 $x_T$ 为仅包含这些非零项的 $x$ 的子向量，并令 $M_T$ 为由 $T$ 索引的列组成的 $M$ 的子矩阵。那么 $Mx = M_T x_T$。该条件变为\n$$\n(1-\\delta_s)\\|x_T\\|_2^2 \\le \\|M_T x_T\\|_2^2 \\le (1+\\delta_s)\\|x_T\\|_2^2\n$$\n对于所有 $x_T \\in \\mathbb{R}^{|T|}$。这等价于，对于所有索引集 $T$（其中 $|T|=s$），格拉姆矩阵 $M_T^T M_T$ 的所有特征值都必须位于区间 $[1-\\delta_s, 1+\\delta_s]$ 内。\n令 $\\lambda_{\\min}(M_T^T M_T)$ 和 $\\lambda_{\\max}(M_T^T M_T)$ 分别为 $M_T^T M_T$ 的最小和最大特征值。这些特征值等于 $M_T$ 的奇异值的平方。为了对所有 $|T|=s$ 的 $T$ 满足该条件，$\\delta_s$ 必须被选择以满足：\n$$\n\\max_{T:|T|=s} \\lambda_{\\max}(M_T^T M_T) \\le 1 + \\delta_s \\quad \\text{和} \\quad \\min_{T:|T|=s} \\lambda_{\\min}(M_T^T M_T) \\ge 1 - \\delta_s\n$$\n因为我们寻求最小的非负 $\\delta_s \\ge 0$，我们有：\n$$\n\\delta_s = \\max \\left( \\max_{T:|T|=s} \\lambda_{\\max}(M_T^T M_T) - 1, 1 - \\min_{T:|T|=s} \\lambda_{\\min}(M_T^T M_T) \\right)\n$$\n我们对 $s=2$ 的情况感兴趣。有 $\\binom{4}{2} = 6$ 个大小为 2 的可能支撑集 $T$。我们必须构建相应的 $3 \\times 2$ 子矩阵 $M_T$，并计算 $2 \\times 2$ 格拉姆矩阵 $M_T^T M_T$ 的特征值。\n\n令 $M$ 的列为 $m_1, m_2, m_3, m_4$。\n$$\nm_1 = \\frac{1}{2}\\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\quad m_2 = \\frac{1}{2}\\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad m_3 = \\frac{1}{2}\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad m_4 = \\frac{1}{2}\\begin{pmatrix} -1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\n格拉姆矩阵 $M_T^T M_T$ 的元素是内积 $m_i^T m_j$。让我们预先计算所有这些值。完整的格拉姆矩阵 $M^T M$ 是：\n$$\nM^T M = \\begin{pmatrix} m_1^T m_1  m_1^T m_2  m_1^T m_3  m_1^T m_4 \\\\ m_2^T m_1  m_2^T m_2  m_2^T m_3  m_2^T m_4 \\\\ m_3^T m_1  m_3^T m_2  m_3^T m_3  m_3^T m_4 \\\\ m_4^T m_1  m_4^T m_2  m_4^T m_3  m_4^T m_4 \\end{pmatrix}\n$$\n各个内积是：\n$m_1^T m_1 = \\frac{1}{4}(1^2+0^2+1^2) = \\frac{2}{4} = \\frac{1}{2}$\n$m_2^T m_2 = \\frac{1}{4}(0^2+1^2+1^2) = \\frac{2}{4} = \\frac{1}{2}$\n$m_3^T m_3 = \\frac{1}{4}(1^2+1^2+0^2) = \\frac{2}{4} = \\frac{1}{2}$\n$m_4^T m_4 = \\frac{1}{4}((-1)^2+1^2+1^2) = \\frac{3}{4}$\n$m_1^T m_2 = \\frac{1}{4}(1\\cdot 0 + 0\\cdot 1 + 1\\cdot 1) = \\frac{1}{4}$\n$m_1^T m_3 = \\frac{1}{4}(1\\cdot 1 + 0\\cdot 1 + 1\\cdot 0) = \\frac{1}{4}$\n$m_1^T m_4 = \\frac{1}{4}(1\\cdot(-1) + 0\\cdot 1 + 1\\cdot 1) = 0$\n$m_2^T m_3 = \\frac{1}{4}(0\\cdot 1 + 1\\cdot 1 + 1\\cdot 0) = \\frac{1}{4}$\n$m_2^T m_4 = \\frac{1}{4}(0\\cdot(-1) + 1\\cdot 1 + 1\\cdot 1) = \\frac{2}{4} = \\frac{1}{2}$\n$m_3^T m_4 = \\frac{1}{4}(1\\cdot(-1) + 1\\cdot 1 + 0\\cdot 1) = 0$\n\n现在，我们分析这 6 个子矩阵 $M_T^T M_T$。\n\n情况 1：$T = \\{1, 2\\}$\n$M_{\\{1,2\\}}^T M_{\\{1,2\\}} = \\begin{pmatrix} m_1^T m_1  m_1^T m_2 \\\\ m_2^T m_1  m_2^T m_2 \\end{pmatrix} = \\begin{pmatrix} 1/2  1/4 \\\\ 1/4  1/2 \\end{pmatrix}$。\n特征值 $\\lambda$ 满足 $\\det(\\begin{pmatrix} 1/2-\\lambda  1/4 \\\\ 1/4  1/2-\\lambda \\end{pmatrix}) = 0$，所以 $(1/2-\\lambda)^2 - (1/4)^2 = 0$。这得出 $\\lambda - 1/2 = \\pm 1/4$。\n$\\lambda_{\\max} = 1/2 + 1/4 = 3/4$。\n$\\lambda_{\\min} = 1/2 - 1/4 = 1/4$。\n\n情况 2：$T = \\{1, 3\\}$\n$M_{\\{1,3\\}}^T M_{\\{1,3\\}} = \\begin{pmatrix} m_1^T m_1  m_1^T m_3 \\\\ m_3^T m_1  m_3^T m_3 \\end{pmatrix} = \\begin{pmatrix} 1/2  1/4 \\\\ 1/4  1/2 \\end{pmatrix}$。\n这与前一种情况相同。\n$\\lambda_{\\max} = 3/4$，$\\lambda_{\\min} = 1/4$。\n\n情况 3：$T = \\{1, 4\\}$\n$M_{\\{1,4\\}}^T M_{\\{1,4\\}} = \\begin{pmatrix} m_1^T m_1  m_1^T m_4 \\\\ m_4^T m_1  m_4^T m_4 \\end{pmatrix} = \\begin{pmatrix} 1/2  0 \\\\ 0  3/4 \\end{pmatrix}$。\n该矩阵是对角矩阵，所以其特征值是其对角线元素。\n$\\lambda_{\\max} = 3/4$，$\\lambda_{\\min} = 1/2$。\n\n情况 4：$T = \\{2, 3\\}$\n$M_{\\{2,3\\}}^T M_{\\{2,3\\}} = \\begin{pmatrix} m_2^T m_2  m_2^T m_3 \\\\ m_3^T m_2  m_3^T m_3 \\end{pmatrix} = \\begin{pmatrix} 1/2  1/4 \\\\ 1/4  1/2 \\end{pmatrix}$。\n这与第一种情况相同。\n$\\lambda_{\\max} = 3/4$，$\\lambda_{\\min} = 1/4$。\n\n情况 5：$T = \\{2, 4\\}$\n$M_{\\{2,4\\}}^T M_{\\{2,4\\}} = \\begin{pmatrix} m_2^T m_2  m_2^T m_4 \\\\ m_4^T m_2  m_4^T m_4 \\end{pmatrix} = \\begin{pmatrix} 1/2  1/2 \\\\ 1/2  3/4 \\end{pmatrix}$。\n特征方程是 $\\lambda^2 - \\text{tr}(M_T^T M_T)\\lambda + \\det(M_T^T M_T) = 0$。\n$\\text{tr} = 1/2 + 3/4 = 5/4$。\n$\\det = (1/2)(3/4) - (1/2)^2 = 3/8 - 1/4 = 1/8$。\n$\\lambda^2 - \\frac{5}{4}\\lambda + \\frac{1}{8} = 0$。\n$\\lambda = \\frac{5/4 \\pm \\sqrt{(5/4)^2 - 4(1/8)}}{2} = \\frac{5/4 \\pm \\sqrt{25/16 - 1/2}}{2} = \\frac{5/4 \\pm \\sqrt{17/16}}{2} = \\frac{5/4 \\pm \\sqrt{17}/4}{2} = \\frac{5 \\pm \\sqrt{17}}{8}$。\n$\\lambda_{\\max} = \\frac{5 + \\sqrt{17}}{8}$。\n$\\lambda_{\\min} = \\frac{5 - \\sqrt{17}}{8}$。\n\n情况 6：$T = \\{3, 4\\}$\n$M_{\\{3,4\\}}^T M_{\\{3,4\\}} = \\begin{pmatrix} m_3^T m_3  m_3^T m_4 \\\\ m_4^T m_3  m_4^T m_4 \\end{pmatrix} = \\begin{pmatrix} 1/2  0 \\\\ 0  3/4 \\end{pmatrix}$。\n这与情况 3 相同。\n$\\lambda_{\\max} = 3/4$，$\\lambda_{\\min} = 1/2$。\n\n我们总结所有 $s=2$ 子矩阵的特征值：\n- $T = \\{1,2\\}: \\lambda_{\\min}=1/4$, $\\lambda_{\\max}=3/4$。\n- $T = \\{1,3\\}: \\lambda_{\\min}=1/4$, $\\lambda_{\\max}=3/4$。\n- $T = \\{1,4\\}: \\lambda_{\\min}=1/2$, $\\lambda_{\\max}=3/4$。\n- $T = \\{2,3\\}: \\lambda_{\\min}=1/4$, $\\lambda_{\\max}=3/4$。\n- $T = \\{2,4\\}: \\lambda_{\\min}=\\frac{5-\\sqrt{17}}{8}$, $\\lambda_{\\max}=\\frac{5+\\sqrt{17}}{8}$。\n- $T = \\{3,4\\}: \\lambda_{\\min}=1/2$, $\\lambda_{\\max}=3/4$。\n\n现在我们找出总的最小和最大特征值。\n$\\min_{T:|T|=2} \\lambda_{\\min}(M_T^T M_T) = \\min\\{1/4, 1/2, \\frac{5-\\sqrt{17}}{8}\\}$。\n由于 $4  \\sqrt{17}  5$，具体来说 $4.12  \\sqrt{17}  4.13$，我们有 $5-\\sqrt{17}  1$。所以 $\\frac{5-\\sqrt{17}}{8}  1/8$。而 $1/4=2/8$。因此 $\\frac{5-\\sqrt{17}}{8}$ 是最小值。\n$\\min_{T:|T|=2} \\lambda_{\\min}(M_T^T M_T) = \\frac{5-\\sqrt{17}}{8}$。\n\n$\\max_{T:|T|=2} \\lambda_{\\max}(M_T^T M_T) = \\max\\{3/4, \\frac{5+\\sqrt{17}}{8}\\}$。\n$3/4 = 6/8$。由于 $\\sqrt{17}  1$，我们有 $5+\\sqrt{17}  6$。所以 $\\frac{5+\\sqrt{17}}{8}  6/8$。\n$\\max_{T:|T|=2} \\lambda_{\\max}(M_T^T M_T) = \\frac{5+\\sqrt{17}}{8}$。\n\n最后，我们计算 $\\delta_2$：\n$$\n\\delta_2 = \\max \\left( \\frac{5+\\sqrt{17}}{8} - 1, 1 - \\frac{5-\\sqrt{17}}{8} \\right)\n$$\n$$\n\\delta_2 = \\max \\left( \\frac{5+\\sqrt{17}-8}{8}, \\frac{8-(5-\\sqrt{17})}{8} \\right)\n$$\n$$\n\\delta_2 = \\max \\left( \\frac{\\sqrt{17}-3}{8}, \\frac{3+\\sqrt{17}}{8} \\right)\n$$\n由于 $\\sqrt{17}0$，很明显 $3+\\sqrt{17}  \\sqrt{17}-3$。\n因此，限制等距常数为：\n$$\n\\delta_2 = \\frac{3+\\sqrt{17}}{8}\n$$",
            "answer": "$$\\boxed{\\frac{3+\\sqrt{17}}{8}}$$"
        },
        {
            "introduction": "具备了唯一性（spark）和测量质量（RIP）的理论基础，我们便可以探索从压缩测量值中实际恢复稀疏信号的算法。像压缩采样匹配追踪（CoSaMP）这样的迭代贪婪算法，为我们提供了一套从测量数据中逐步逼近真实信号的具体步骤。本练习  将引导您完整地执行一轮 CoSaMP 迭代，包括计算代理、识别支撑集、求解最小二乘问题以及剪枝更新，让您亲身体验稀疏恢复算法的运作机制。",
            "id": "3434637",
            "problem": "考虑一个压缩感知中的线性测量模型，其中信号 $x \\in \\mathbb{R}^{5}$ 在规范基下是$k$-稀疏的（即，基变换矩阵是单位矩阵），测量值由 $y = A x$ 给出，其中 $A \\in \\mathbb{R}^{3 \\times 5}$。令 $A = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix}$，$\\Phi = I_{5}$，且 $x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix}$，因此 $y = A x$。从基本定义出发：线性测量 $y = A x$，信号 $x$ 在单位基下的稀疏性，支撑集为非零项的索引集合，以及最小二乘拟合为最小化残差的欧几里得范数。执行一轮完整的压缩采样匹配追踪（CoSaMP）算法，目标稀疏度为 $k = 2$，从零初始估计 $x^{(0)} = 0$ 和初始残差 $r^{(0)} = y$ 开始。遵循以下基本步骤：\n\n- 计算代理向量 $u = A^{\\top} r^{(0)}$。\n- 识别与 $|u|$ 中幅度最大的 $2k$ 个元素相对应的索引集 $\\Omega$。\n- 与当前支撑集合并，形成 $\\mathcal{T} = \\Omega \\cup \\operatorname{supp}(x^{(0)})$。\n- 求解最小二乘问题 $b = \\arg\\min_{z \\in \\mathbb{R}^{5},\\, \\operatorname{supp}(z) \\subseteq \\mathcal{T}} \\| y - A z \\|_{2}$；如果存在多个最小化子，选择欧几里得范数最小的那个。\n- 对 $b$进行剪枝，保留其幅度最大的 $k$ 个元素，以获得 $x^{(1)}$。\n- 形成更新后的残差 $r^{(1)} = y - A x^{(1)}$。\n\n更新后的残差的欧几里得范数 $\\| r^{(1)} \\|_{2}$ 是多少？请以封闭形式的解析表达式给出最终答案。不要进行近似或四舍五入。",
            "solution": "该问题要求执行一轮完整的压缩采样匹配追踪（CoSaMP）算法，以求出更新后残差的欧几里得范数 $\\| r^{(1)} \\|_{2}$。我们已知线性测量模型 $y = Ax$，其中信号 $x \\in \\mathbb{R}^{5}$ 在规范基下是稀疏的。\n\n给定的数据如下：\n- 测量矩阵: $A = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 5}$\n- 真实信号: $x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^{5}$\n- 算法的目标稀疏度: $k = 2$\n- 初始信号估计: $x^{(0)} = 0 \\in \\mathbb{R}^{5}$\n- 基变换矩阵是单位矩阵 $\\Phi = I_{5}$。\n\n迭代遵循预定的一系列步骤。首先，我们计算测量向量 $y$。\n$$y = Ax = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1(1) + 1(2) \\\\ 1(2) \\\\ 1(1) \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$$\n初始残差为 $r^{(0)} = y = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$。\n\n现在，我们开始执行 CoSaMP 迭代的步骤。\n\n1.  **计算代理向量**: 代理向量 $u$ 由 $u = A^{\\top} r^{(0)}$ 给出。\n    $$A^{\\top} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\\\ 0  0  1 \\end{bmatrix}$$\n    $$u = A^{\\top} r^{(0)} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\\\ 0  0  1 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1(3) + 1(1) \\\\ 1(2) \\\\ 1(3) + 1(2) \\\\ 1(2) + 1(1) \\\\ 1(1) \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 2 \\\\ 5 \\\\ 3 \\\\ 1 \\end{bmatrix}$$\n\n2.  **识别支撑集**: 我们识别与 $|u|$ 中幅度最大的 $2k$ 个元素相对应的索引集 $\\Omega$。这里 $k=2$，所以 $2k=4$。向量 $u$ 的所有元素都是正的，所以 $|u|=u$。$u$ 的元素按幅度降序排列为 $5, 4, 3, 2$，对应的索引为 $3, 1, 4, 2$。\n    $$\\Omega = \\{1, 2, 3, 4\\}$$\n\n3.  **合并支撑集**: 新的候选支撑集 $\\mathcal{T}$ 是 $\\Omega$ 与前一个估计 $x^{(0)}$ 的支撑集的并集。\n    $$\\operatorname{supp}(x^{(0)}) = \\operatorname{supp}(0) = \\emptyset$$\n    $$\\mathcal{T} = \\Omega \\cup \\operatorname{supp}(x^{(0)}) = \\{1, 2, 3, 4\\}$$\n\n4.  **求解最小二乘问题**: 我们必须找到支撑集包含在 $\\mathcal{T}$ 中的向量 $b$，使得 $\\|y - Az\\|_2$ 最小化。这等价于在最小二乘意义下从系统 $A_{\\mathcal{T}} b_{\\mathcal{T}} \\approx y$ 中求解 $b_{\\mathcal{T}}$，其中 $A_{\\mathcal{T}}$ 是由 $A$ 中索引为 $\\mathcal{T}$ 的列组成的子矩阵。\n    $$A_{\\mathcal{T}} = \\begin{bmatrix} 1  0  1  0 \\\\ 0  1  1  1 \\\\ 1  0  0  1 \\end{bmatrix}$$\n    问题规定，如果存在多个最小化子，我们选择欧几里得范数最小的那个。这对应于解 $b_{\\mathcal{T}} = A_{\\mathcal{T}}^{\\dagger} y$，其中 $A_{\\mathcal{T}}^{\\dagger}$ 是 $A_{\\mathcal{T}}$ 的摩尔-彭若斯伪逆。由于 $A_{\\mathcal{T}}$ 是一个秩为 $3$ 的 $3 \\times 4$ 矩阵（它具有满行秩），其伪逆由 $A_{\\mathcal{T}}^{\\dagger} = A_{\\mathcal{T}}^{\\top}(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1}$ 给出。\n    首先，我们计算 $A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top}$：\n    $$A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top} = \\begin{bmatrix} 1  0  1  0 \\\\ 0  1  1  1 \\\\ 1  0  0  1 \\end{bmatrix} \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} = \\begin{bmatrix} 2  1  1 \\\\ 1  3  1 \\\\ 1  1  2 \\end{bmatrix}$$\n    接下来，我们求这个 $3 \\times 3$ 矩阵的逆。行列式为 $\\det(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top}) = 2(6-1) - 1(2-1) + 1(1-3) = 10 - 1 - 2 = 7$。\n    逆矩阵为：\n    $$(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1} = \\frac{1}{7} \\begin{bmatrix} 5  -1  -2 \\\\ -1  3  -1 \\\\ -2  -1  5 \\end{bmatrix}$$\n    现在我们可以计算 $b_{\\mathcal{T}}$：\n    $$b_{\\mathcal{T}} = A_{\\mathcal{T}}^{\\top}(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1} y = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 5  -1  -2 \\\\ -1  3  -1 \\\\ -2  -1  5 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} \\right)$$\n    $$b_{\\mathcal{T}} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 15-2-2 \\\\ -3+6-1 \\\\ -6-2+5 \\end{bmatrix} \\right) = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 11 \\\\ 2 \\\\ -3 \\end{bmatrix} \\right) = \\frac{1}{7} \\begin{bmatrix} 11-3 \\\\ 2 \\\\ 11+2 \\\\ 2-3 \\end{bmatrix} = \\frac{1}{7} \\begin{bmatrix} 8 \\\\ 2 \\\\ 13 \\\\ -1 \\end{bmatrix}$$\n    完整的向量 $b \\in \\mathbb{R}^5$ 是通过将这些值放在 $\\mathcal{T}$ 中的索引位置，并在其他位置置零来构造的：\n    $$b = \\begin{bmatrix} 8/7 \\\\ 2/7 \\\\ 13/7 \\\\ -1/7 \\\\ 0 \\end{bmatrix}$$\n\n5.  **剪枝估计**: 我们通过保留 $b$ 中幅度最大的 $k=2$ 个分量来获得新的信号估计 $x^{(1)}$。$b$ 的非零分量的幅度为 $|8/7|$、$|2/7|$、$|13/7|$ 和 $|-1/7|$，即 $8/7$、$2/7$、$13/7$ 和 $1/7$。最大的两个是 $13/7$（在索引 $3$ 处）和 $8/7$（在索引 $1$ 处）。\n    因此，我们将所有其他分量设置为零：\n    $$x^{(1)} = \\begin{bmatrix} 8/7 \\\\ 0 \\\\ 13/7 \\\\ 0 \\\\ 0 \\end{bmatrix}$$\n\n6.  **更新残差**: 新的残差 $r^{(1)}$ 是 $r^{(1)} = y - Ax^{(1)}$。\n    $$Ax^{(1)} = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\begin{bmatrix} 8/7 \\\\ 0 \\\\ 13/7 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 8/7 + 13/7 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 21/7 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix}$$\n    $$r^{(1)} = y - Ax^{(1)} = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} 3 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 14/7 - 13/7 \\\\ 7/7 - 8/7 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1/7 \\\\ -1/7 \\end{bmatrix}$$\n\n最后，我们计算更新后的残差 $r^{(1)}$ 的欧几里得范数。\n$$\\|r^{(1)}\\|_{2} = \\sqrt{0^2 + (1/7)^2 + (-1/7)^2} = \\sqrt{\\frac{1}{49} + \\frac{1}{49}} = \\sqrt{\\frac{2}{49}} = \\frac{\\sqrt{2}}{7}$$\n经过一次迭代后，残差的欧几里得范数为 $\\frac{\\sqrt{2}}{7}$。",
            "answer": "$$\\boxed{\\frac{\\sqrt{2}}{7}}$$"
        }
    ]
}