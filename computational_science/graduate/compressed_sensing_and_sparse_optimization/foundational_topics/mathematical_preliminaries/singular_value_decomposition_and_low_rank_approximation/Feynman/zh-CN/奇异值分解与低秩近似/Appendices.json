{
    "hands_on_practices": [
        {
            "introduction": "奇异值分解（SVD）的核心应用之一是低秩近似。Eckart–Young–Mirsky 定理为我们提供了在谱范数和弗罗贝尼乌斯范数下获得最佳低秩近似的理论依据，即通过截断SVD来实现。本练习将通过一个具有明确奇异值衰减规律的矩阵，让你亲手计算近似误差，从而直观地理解奇异值的衰减速度如何决定低秩近似的质量。",
            "id": "3475965",
            "problem": "考虑一个实矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其奇异值按非增顺序排列。在压缩感知和稀疏优化的背景下，低秩近似利用奇异值分解（singular value decomposition (SVD)）的结构来构造 $A_{k}$，即在标准矩阵范数下 $A$ 的最佳秩-$k$ 近似。假设 $n = 10$ 且 $A$ 的奇异值明确由下式给出\n$$\n\\sigma_{1} = 1, \\ \\sigma_{2} = \\tfrac{1}{2}, \\ \\sigma_{3} = \\tfrac{1}{4}, \\ \\sigma_{4} = \\tfrac{1}{8}, \\ \\sigma_{5} = \\tfrac{1}{16}, \\ \\sigma_{6} = \\tfrac{1}{32}, \\ \\sigma_{7} = \\tfrac{1}{64}, \\ \\sigma_{8} = \\tfrac{1}{128}, \\ \\sigma_{9} = \\tfrac{1}{256}, \\ \\sigma_{10} = \\tfrac{1}{512}.\n$$\n从矩阵范数和奇异值的基本定义出发，计算当 $k = 4$ 时的相对弗罗贝尼乌斯误差 $\\|A - A_{k}\\|_{F} / \\|A\\|_{F}$ 和相对谱误差 $\\|A - A_{k}\\|_{2} / \\|A\\|_{2}$。然后，根据你的推导，定性地解释奇异值的衰减速率如何影响低秩近似的质量，并将你的推理与压缩感知和稀疏优化中使用的经典思想联系起来。使用 $\\mathrm{pmatrix}$ 环境将你的最终数值结果表示为单行矩阵；无需四舍五入。",
            "solution": "我们从实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的奇异值分解（singular value decomposition (SVD)）开始，它将 $A$ 写为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是对角矩阵，其对角线上的非负元素为 $\\sigma_{1} \\ge \\sigma_{2} \\ge \\cdots \\ge \\sigma_{n} \\ge 0$。弗罗贝尼乌斯范数和谱范数满足以下经过充分检验的恒等式\n$$\n\\|A\\|_{F}^{2} = \\sum_{i=1}^{n} \\sigma_{i}^{2}, \\quad \\|A\\|_{2} = \\sigma_{1}.\n$$\n在弗罗贝尼乌斯范数和谱范数下，最佳秩-$k$ 近似 $A_{k}$ 是通过将 SVD 截断为前 $k$ 个最大的奇异值得出的，这个结果由 Eckart–Young–Mirsky 定理（Eckart–Young–Mirsky (EYM)）确立。具体来说，\n$$\nA_{k} = U \\Sigma_{k} V^{\\top},\n$$\n其中 $\\Sigma_{k}$ 只保留前 $k$ 个最大的奇异值。EYM 定理给出了最优残差范数\n$$\n\\|A - A_{k}\\|_{F}^{2} = \\sum_{i=k+1}^{n} \\sigma_{i}^{2}, \\quad \\|A - A_{k}\\|_{2} = \\sigma_{k+1}.\n$$\n因此，相对误差为\n$$\n\\frac{\\|A - A_{k}\\|_{F}}{\\|A\\|_{F}} = \\sqrt{\\frac{\\sum_{i=k+1}^{n} \\sigma_{i}^{2}}{\\sum_{i=1}^{n} \\sigma_{i}^{2}}}, \\quad \\frac{\\|A - A_{k}\\|_{2}}{\\|A\\|_{2}} = \\frac{\\sigma_{k+1}}{\\sigma_{1}}.\n$$\n对于给定的奇异值，我们有 $n = 10$, $k = 4$ 以及\n$$\n\\sigma_{i} = 2^{-(i-1)} \\quad \\text{for} \\quad i = 1,2,\\dots,10.\n$$\n因此\n$$\n\\sigma_{i}^{2} = 4^{-(i-1)}.\n$$\n计算弗罗贝尼乌斯相对误差的分母：\n$$\n\\sum_{i=1}^{10} \\sigma_{i}^{2} = \\sum_{i=1}^{10} 4^{-(i-1)} = \\sum_{j=0}^{9} 4^{-j} = \\frac{1 - 4^{-10}}{1 - 4^{-1}} = \\frac{1 - 4^{-10}}{1 - \\tfrac{1}{4}} = \\frac{1 - 4^{-10}}{\\tfrac{3}{4}} = \\frac{4}{3}\\left(1 - 4^{-10}\\right).\n$$\n计算弗罗贝尼乌斯相对误差的分子：\n$$\n\\sum_{i=5}^{10} \\sigma_{i}^{2} = \\sum_{i=5}^{10} 4^{-(i-1)} = \\sum_{j=4}^{9} 4^{-j} = 4^{-4} \\sum_{t=0}^{5} 4^{-t} = 4^{-4} \\cdot \\frac{1 - 4^{-6}}{1 - 4^{-1}} = 4^{-4} \\cdot \\frac{1 - 4^{-6}}{\\tfrac{3}{4}} = 4^{-4} \\cdot \\frac{4}{3}\\left(1 - 4^{-6}\\right).\n$$\n因此，平方根内的比值简化为\n$$\n\\frac{\\sum_{i=5}^{10} \\sigma_{i}^{2}}{\\sum_{i=1}^{10} \\sigma_{i}^{2}} = \\frac{4^{-4} \\cdot \\frac{4}{3}\\left(1 - 4^{-6}\\right)}{\\frac{4}{3}\\left(1 - 4^{-10}\\right)} = 4^{-4} \\cdot \\frac{1 - 4^{-6}}{1 - 4^{-10}}.\n$$\n因此相对弗罗贝尼乌斯误差为\n$$\n\\frac{\\|A - A_{k}\\|_{F}}{\\|A\\|_{F}} = \\sqrt{4^{-4} \\cdot \\frac{1 - 4^{-6}}{1 - 4^{-10}}} = 4^{-2} \\sqrt{\\frac{1 - 4^{-6}}{1 - 4^{-10}}} = \\frac{1}{16} \\sqrt{\\frac{1 - 4^{-6}}{1 - 4^{-10}}}.\n$$\n对于相对谱误差，\n$$\n\\frac{\\|A - A_{k}\\|_{2}}{\\|A\\|_{2}} = \\frac{\\sigma_{5}}{\\sigma_{1}} = \\frac{2^{-4}}{2^{0}} = 2^{-4} = \\frac{1}{16}.\n$$\n关于衰减和近似质量的定性讨论：最佳秩-$k$ 近似的残差误差完全取决于尾部的奇异值。在弗罗贝尼乌斯范数下，误差的平方是被丢弃的奇异值的平方和；在谱范数下，误差是下一个奇异值 $\\sigma_{k+1}$。因此，$\\{\\sigma_{i}\\}$ 的更快衰减会导致 $\\sum_{i>k} \\sigma_{i}^{2}$ 中更小的尾部质量和更小的 $\\sigma_{k+1}$，从而在低 $k$ 值下改善弗罗贝尼乌斯和谱近似的质量。在压缩感知和稀疏优化中，这种衰减是秩约束和凸松弛（如核范数最小化）有效性的基础：当奇异值高度集中于顶部模式（快速衰减）时，低秩模型可以用较小的 $k$ 捕获大部分能量，而松弛方法可以准确地恢复或近似 $A$。反之，缓慢的衰减意味着能量显著地分布在许多模式上，因此在较小的 $k$ 处截断会丢弃大量能量，从而降低近似质量，并使低秩恢复或近似变得更具挑战性。",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{16}\\sqrt{\\frac{1 - 4^{-6}}{1 - 4^{-10}}} & \\frac{1}{16}\\end{pmatrix}}$$"
        },
        {
            "introduction": "在鲁棒主成分分析（Robust Principal Component Analysis, RPCA）等应用中，一个关键任务是将观测矩阵分解为一个低秩部分和一个稀疏部分。然而，这种分解的唯一性（即可辨识性）并非总是得到保证，尤其当低秩分量本身也具有稀疏结构时。本练习通过构建一个既是低秩又是稀疏的特殊矩阵，让你深入探究可辨识性失败的根本原因，并分析正则化参数 $\\lambda$ 如何在这种模糊情况下影响模型的选择。",
            "id": "3475943",
            "problem": "考虑如下定义的奇异值分解 (SVD)：对于任意实矩阵 $M \\in \\mathbb{R}^{m \\times n}$，存在正交矩阵 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$，以及一个对角线元素为非负（即奇异值）的对角矩阵 $\\Sigma \\in \\mathbb{R}^{m \\times n}$，使得 $M = U \\Sigma V^{\\top}$。$M$ 的核范数，记作 $\\|M\\|_{*}$，定义为其奇异值之和。$M$ 的逐元素 $\\ell_{1}$ 范数，记作 $\\|M\\|_{1}$，定义为 $M$ 中所有元素绝对值之和。如果一个矩阵的大部分元素为零，则称其为稀疏矩阵；如果其秩远小于 $\\min\\{m,n\\}$，则称其为低秩矩阵。\n\n设 $u \\in \\mathbb{R}^{4}$ 和 $v \\in \\mathbb{R}^{4}$ 为稀疏向量 $u = [1,\\,1,\\,0,\\,0]^{\\top}$ 和 $v = [1,\\,1,\\,0,\\,0]^{\\top}$。通过外积定义矩阵 $M \\in \\mathbb{R}^{4 \\times 4}$ 为 $M = u v^{\\top}$。\n\n仅使用上述核心定义和线性代数的基本原理：\n1. 根据 SVD 的定义推导 $M$ 的奇异值，并计算其核范数 $\\|M\\|_{*}$。\n2. 确定 $M$ 的稀疏模式并计算 $\\|M\\|_{1}$。\n3. 考虑在鲁棒主成分分析 (RPCA) 中使用的凸规划：在约束 $M = L + S$ 下最小化 $\\|L\\|_{*} + \\lambda \\|S\\|_{1}$，其中 $\\lambda > 0$。从低秩矩阵集和稀疏矩阵集的角度，解释为什么对于上面构造的矩阵 $M$，可辨识性会失效。然后，确定使两种分解 $(L,S) = (M,0)$ 和 $(L,S) = (0,M)$ 在此凸规划中产生相同目标函数值的 $\\lambda$ 值。\n\n将你的最终答案表示为单个实数。无需四舍五入。",
            "solution": "该问题要求在低秩和稀疏矩阵分解的背景下，对一个特定的矩阵 $M \\in \\mathbb{R}^{4 \\times 4}$ 进行分析。我们将按要求分三部分进行。\n\n首先，给定向量 $u \\in \\mathbb{R}^{4}$ 和 $v \\in \\mathbb{R}^{4}$：\n$$u = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad v = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$$\n矩阵 $M$ 定义为它们的外积，$M = u v^{\\top}$。\n$$M = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 1 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}$$\n\n第1部分：推导 $M$ 的奇异值并计算核范数 $\\|M\\|_{*}$。\n\n矩阵 $M$ 是两个非零向量的外积，所以其秩为 1。一个秩为 $k$ 的矩阵恰好有 $k$ 个非零奇异值。因此，$M$ 只有一个非零奇异值，我们记作 $\\sigma_1$。其他奇异值为 $\\sigma_2 = \\sigma_3 = \\sigma_4 = 0$。\n\n对于形如 $M = u v^{\\top}$ 的秩-1矩阵，其奇异值分解由 $M = \\sigma_1 \\hat{u} \\hat{v}^{\\top}$ 给出，其中 $\\hat{u} = \\frac{u}{\\|u\\|_2}$ 和 $\\hat{v} = \\frac{v}{\\|v\\|_2}$ 是单位向量，且 $\\sigma_1 = \\|u\\|_2 \\|v\\|_2$。\n\n我们来计算 $u$ 和 $v$ 的欧几里得范数：\n$$\\|u\\|_2 = \\sqrt{1^2 + 1^2 + 0^2 + 0^2} = \\sqrt{2}$$\n$$\\|v\\|_2 = \\sqrt{1^2 + 1^2 + 0^2 + 0^2} = \\sqrt{2}$$\n\n唯一的非零奇异值 $\\sigma_1$ 为：\n$$\\sigma_1 = \\|u\\|_2 \\|v\\|_2 = \\sqrt{2} \\cdot \\sqrt{2} = 2$$\n\n因此，$M$ 的奇异值为 $\\{2, 0, 0, 0\\}$。\n\n核范数 $\\|M\\|_{*}$ 定义为奇异值之和：\n$$\\|M\\|_{*} = \\sum_{i=1}^{4} \\sigma_i = 2 + 0 + 0 + 0 = 2$$\n\n第2部分：确定 $M$ 的稀疏模式并计算 $\\|M\\|_{1}$。\n\n矩阵 $M$ 为：\n$$M = \\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 1 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}$$\n如果一个矩阵的大部分元素为零，则该矩阵是稀疏的。在本例中，$M$ 在总共 16 个元素中有 4 个非零元素和 12 个零元素。其非零元素位于索引 $(1,1), (1,2), (2,1), (2,2)$ 处。根据定义，该矩阵可以被认为是稀疏的。\n\n逐元素 $\\ell_1$ 范数 $\\|M\\|_{1}$ 是其所有元素绝对值之和：\n$$\\|M\\|_{1} = \\sum_{i=1}^{4} \\sum_{j=1}^{4} |M_{ij}| = |1| + |1| + |0| + |0| + |1| + |1| + |0| + |0| + 8 \\times |0|$$\n$$\\|M\\|_{1} = 1 + 1 + 1 + 1 = 4$$\n\n第3部分：解释可辨识性的失效并确定 $\\lambda$ 的值。\n\n鲁棒主成分分析 (RPCA) 的凸规划由下式给出：\n$$\\min_{L,S} \\|L\\|_{*} + \\lambda \\|S\\|_{1} \\quad \\text{subject to} \\quad M = L + S$$\n该规划旨在将矩阵 $M$ 分解为一个低秩分量 $L$ 和一个稀疏分量 $S$。可辨识性指的是唯一地恢复“真实”的 $(L,S)$ 对的能力。\n\n对于给定的矩阵 $M$，可辨识性之所以失效，是因为 $M$ 本身同时拥有分解试图分离的两种性质。如第1部分所示，$M$ 是一个低秩矩阵（秩为1）。如第2部分所示，$M$ 也是一个稀疏矩阵（只有4个非零元素）。\nRPCA 框架在低秩分量和稀疏分量“非相干”时才能保证有效——大致意思是低秩分量不稀疏，而稀疏分量不低秩。在我们的例子中，这两个分量是完全相干的，因为矩阵 $M$ 既可以完全被解释为一个低秩结构，也可以完全被解释为一个稀疏结构。这就产生了一种凸规划无法解决的模糊性。\n\n具体来说，存在两种平凡的分解：\n1.  $(L, S) = (M, 0)$：这里我们将 $M$ 解释为一个纯粹的低秩矩阵，没有稀疏损坏。$L=M$ 是低秩的，$S=0$ 是稀疏的。\n2.  $(L, S) = (0, M)$：这里我们将 $M$ 解释为一个零矩阵（它是低秩的）的纯粹稀疏损坏。$L=0$ 是低秩的，$S=M$ 是稀疏的。\n\n我们需要找到使这两种分解产生相同目标函数值的 $\\lambda$ 值。\n\n我们来计算第一种分解 $(L, S) = (M, 0)$ 的目标函数值：\n$$\\text{Objective}_1 = \\|L\\|_{*} + \\lambda \\|S\\|_{1} = \\|M\\|_{*} + \\lambda \\|0\\|_{1}$$\n根据我们之前的计算，$\\|M\\|_{*} = 2$。零矩阵的 $\\ell_1$ 范数是 $\\|0\\|_{1} = 0$。\n$$\\text{Objective}_1 = 2 + \\lambda(0) = 2$$\n\n现在，我们来计算第二种分解 $(L, S) = (0, M)$ 的目标函数值：\n$$\\text{Objective}_2 = \\|L\\|_{*} + \\lambda \\|S\\|_{1} = \\|0\\|_{*} + \\lambda \\|M\\|_{1}$$\n零矩阵的核范数是 $\\|0\\|_{*} = 0$。根据我们之前的计算，$\\|M\\|_{1} = 4$。\n$$\\text{Objective}_2 = 0 + \\lambda(4) = 4\\lambda$$\n\n为了找到使两种分解同样最优的 $\\lambda$ 值，我们令它们的目标函数值相等：\n$$\\text{Objective}_1 = \\text{Objective}_2$$\n$$2 = 4\\lambda$$\n解出 $\\lambda$，我们得到：\n$$\\lambda = \\frac{2}{4} = \\frac{1}{2}$$\n\n当 $\\lambda = 1/2$ 时，模型在将 $M$ 解释为低秩矩阵还是稀疏矩阵方面没有区别，这突显了可辨识性的失效。",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "理论概念最终需要通过有效的算法来实现。对于涉及核范数最小化的优化问题，交替方向乘子法（Alternating Direction Method of Multipliers, ADMM）是一种强大且流行的求解框架。本练习将指导你为一个典型的低秩矩阵恢复问题推導ADMM的完整迭代格式，让你掌握如何将奇异值分解转化为算法中的核心步驟——奇异值软阈值算子（singular value soft-thresholding）。",
            "id": "3475989",
            "problem": "考虑从线性测量中恢复低秩矩阵的凸优化问题。设 $\\mathcal{A}:\\mathbb{R}^{m \\times n} \\to \\mathbb{R}^{p}$ 是一个已知的线性算子，其伴随算子为 $\\mathcal{A}^{\\ast}:\\mathbb{R}^{p} \\to \\mathbb{R}^{m \\times n}$，设 $b \\in \\mathbb{R}^{p}$ 是观测数据，$\\lambda > 0$ 是一个正则化权重。目标是求解\n$$\n\\min_{X \\in \\mathbb{R}^{m \\times n}} \\; \\frac{1}{2}\\|\\mathcal{A}(X) - b\\|_{2}^{2} + \\lambda \\|X\\|_{\\ast},\n$$\n其中 $\\|X\\|_{\\ast}$ 表示核范数（矩阵 $X$ 的奇异值之和）。引入一个分裂变量 $Z \\in \\mathbb{R}^{m \\times n}$ 并强制 $X = Z$，得到约束问题\n$$\n\\min_{X,Z \\in \\mathbb{R}^{m \\times n}} \\; \\frac{1}{2}\\|\\mathcal{A}(X) - b\\|_{2}^{2} + \\lambda \\|Z\\|_{\\ast} \\quad \\text{subject to} \\quad X = Z.\n$$\n使用交替方向乘子法（ADMM），在其带有惩罚参数 $\\rho > 0$ 的缩放形式下，推导一个交替关于 $X$ 和 $Z$ 进行最小化，然后对缩放对偶变量 $U \\in \\mathbb{R}^{m \\times n}$ 进行对偶上升步骤的迭代方案。您的推导必须从缩放形式的增广拉格朗日函数开始，对 $X$-子问题应用一阶最优性条件（使用伴随算子 $\\mathcal{A}^{\\ast}$），并利用核范数的定义以及奇异值分解（SVD）来表征 $Z$-更新的闭式解。最后，给出以 $\\mathcal{A}$、$\\mathcal{A}^{\\ast}$、$b$、$\\lambda$、$\\rho$ 和当前迭代值表示的 $X^{k+1}$、$Z^{k+1}$ 和 $U^{k+1}$ 的显式更新式。\n\n最后，以单个闭式解析表达式的形式，报告在用于从 $X^{k+1} + U^{k}$ 的SVD计算 $Z^{k+1}$ 的奇异值软阈值步骤中出现的阈值 $\\tau$。最终答案只需提供此表达式。不需要四舍五入。",
            "solution": "我们从变量分裂的重构形式开始\n$$\n\\min_{X,Z \\in \\mathbb{R}^{m \\times n}} \\; \\frac{1}{2}\\|\\mathcal{A}(X) - b\\|_{2}^{2} + \\lambda \\|Z\\|_{\\ast} \\quad \\text{subject to} \\quad X = Z.\n$$\n引入缩放对偶变量 $U \\in \\mathbb{R}^{m \\times n}$ 和惩罚参数 $\\rho > 0$。缩放形式的增广拉格朗日函数为\n$$\n\\mathcal{L}_{\\rho}(X,Z,U) \\;=\\; \\frac{1}{2}\\|\\mathcal{A}(X) - b\\|_{2}^{2} \\;+\\; \\lambda \\|Z\\|_{\\ast} \\;+\\; \\frac{\\rho}{2}\\|X - Z + U\\|_{F}^{2} \\;-\\; \\frac{\\rho}{2}\\|U\\|_{F}^{2},\n$$\n其中 $\\|\\cdot\\|_{F}$ 表示弗罗贝尼乌斯范数。交替方向乘子法（ADMM）在第 $k$ 次迭代时执行以下步骤：\n1. $X$-更新：$X^{k+1} = \\arg\\min_{X} \\mathcal{L}_{\\rho}(X,Z^{k},U^{k})$，\n2. $Z$-更新：$Z^{k+1} = \\arg\\min_{Z} \\mathcal{L}_{\\rho}(X^{k+1},Z,U^{k})$，\n3. 对偶上升：$U^{k+1} = U^{k} + X^{k+1} - Z^{k+1}$。\n\n我们推导每个更新的闭式解。\n\n对于 $X$-更新，我们求解\n$$\nX^{k+1} \\in \\arg\\min_{X} \\; \\frac{1}{2}\\|\\mathcal{A}(X) - b\\|_{2}^{2} + \\frac{\\rho}{2}\\|X - Z^{k} + U^{k}\\|_{F}^{2}.\n$$\n这是一个关于 $X$ 的严格凸二次函数。使用线性算子下梯度的标准法则，$\\frac{1}{2}\\|\\mathcal{A}(X) - b\\|_{2}^{2}$ 相对于 $X$ 的梯度是 $\\mathcal{A}^{\\ast}(\\mathcal{A}(X) - b)$，$\\frac{\\rho}{2}\\|X - C\\|_{F}^{2}$ 相对于 $X$ 的梯度是 $\\rho(X - C)$（对于任意常数 $C$）。将梯度设为零，得到正规方程\n$$\n\\mathcal{A}^{\\ast}(\\mathcal{A}(X^{k+1}) - b) + \\rho\\left(X^{k+1} - Z^{k} + U^{k}\\right) \\;=\\; 0.\n$$\n整理得，\n$$\n\\left(\\mathcal{A}^{\\ast}\\mathcal{A} + \\rho \\mathcal{I}\\right) X^{k+1} \\;=\\; \\mathcal{A}^{\\ast} b + \\rho\\left(Z^{k} - U^{k}\\right),\n$$\n其中 $\\mathcal{I}$ 表示 $\\mathbb{R}^{m \\times n}$ 上的恒等算子。由于当 $\\rho > 0$ 时，$\\mathcal{A}^{\\ast}\\mathcal{A} + \\rho \\mathcal{I}$ 是自伴随且严格正定的，因此它是可逆的，从而得到闭式的算子表达式\n$$\nX^{k+1} \\;=\\; \\left(\\mathcal{A}^{\\ast}\\mathcal{A} + \\rho \\mathcal{I}\\right)^{-1}\\!\\left(\\mathcal{A}^{\\ast} b + \\rho\\left(Z^{k} - U^{k}\\right)\\right).\n$$\n\n对于 $Z$-更新，我们求解\n$$\nZ^{k+1} \\in \\arg\\min_{Z} \\; \\lambda \\|Z\\|_{\\ast} + \\frac{\\rho}{2}\\|X^{k+1} - Z + U^{k}\\|_{F}^{2}.\n$$\n令 $M^{k} = X^{k+1} + U^{k}$。则子问题为\n$$\nZ^{k+1} \\in \\arg\\min_{Z} \\; \\lambda \\|Z\\|_{\\ast} + \\frac{\\rho}{2}\\|Z - M^{k}\\|_{F}^{2}.\n$$\n这是核范数的近端算子，缩放因子为 $\\lambda/\\rho$。为了推导其闭式解，我们利用核范数和弗罗贝尼乌斯范数的酉不变性结构。设 $M^{k}$ 的奇异值分解（SVD）为 $M^{k} = P \\Sigma Q^{\\top}$，其中 $P \\in \\mathbb{R}^{m \\times m}$ 和 $Q \\in \\mathbb{R}^{n \\times n}$ 是正交的（在复数情况下是酉的），且 $\\Sigma = \\operatorname{diag}(\\sigma_{1},\\dots,\\sigma_{r})$，其中 $\\sigma_{i} \\ge 0$ 且 $r = \\operatorname{rank}(M^{k})$。当限制在相同的奇异向量上时，任何候选的 $Z$ 都可以写成 $Z = P \\operatorname{diag}(s) Q^{\\top}$，其中 $s \\in \\mathbb{R}_{\\ge 0}^{r}$；根据 von Neumann 迹不等式和酉不变范数近端映射的特性，最小值点与 $M^{k}$ 共享相同的奇异向量。问题简化为关于奇异值的可分离求和：\n$$\n\\min_{s_{i} \\ge 0} \\; \\sum_{i=1}^{r} \\left( \\lambda s_{i} + \\frac{\\rho}{2}(s_{i} - \\sigma_{i})^{2} \\right).\n$$\n每一项都通过标量软阈值法则最小化\n$$\ns_{i}^{\\star} \\;=\\; \\max\\!\\left(\\sigma_{i} - \\frac{\\lambda}{\\rho}, \\, 0\\right).\n$$\n因此，\n$$\nZ^{k+1} \\;=\\; P \\,\\operatorname{diag}\\!\\left( \\max\\!\\left(\\sigma_{i} - \\frac{\\lambda}{\\rho}, \\, 0\\right) \\right) Q^{\\top},\n$$\n这是对 $M^{k} = X^{k+1} + U^{k}$ 在阈值 $\\tau = \\lambda/\\rho$ 下的奇异值软阈值操作。\n\n最后，缩放对偶上升步骤通过累积残差来强制执行原始可行性：\n$$\nU^{k+1} \\;=\\; U^{k} + X^{k+1} - Z^{k+1}.\n$$\n\n总结起来，ADMM 方案是\n- $X^{k+1} = \\left(\\mathcal{A}^{\\ast}\\mathcal{A} + \\rho \\mathcal{I}\\right)^{-1}\\!\\left(\\mathcal{A}^{\\ast} b + \\rho\\left(Z^{k} - U^{k}\\right)\\right)$,\n- $Z^{k+1} = \\operatorname{SVT}_{\\tau}\\!\\left(X^{k+1} + U^{k}\\right)$，其中 $\\tau = \\lambda/\\rho$，$\\operatorname{SVT}_{\\tau}$ 表示在水平 $\\tau$ 上的奇异值软阈值操作，\n- $U^{k+1} = U^{k} + X^{k+1} - Z^{k+1}$。\n\n所要求的单个解析表达式是奇异值软阈值步骤中的阈值，\n$$\n\\tau \\;=\\; \\frac{\\lambda}{\\rho}.\n$$",
            "answer": "$$\\boxed{\\frac{\\lambda}{\\rho}}$$"
        }
    ]
}