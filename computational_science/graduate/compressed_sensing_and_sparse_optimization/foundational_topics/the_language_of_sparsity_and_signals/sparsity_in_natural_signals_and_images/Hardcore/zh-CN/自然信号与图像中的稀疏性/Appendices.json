{
    "hands_on_practices": [
        {
            "introduction": "为稀疏性建模存在两种主要范式：合成模型（信号是少数几个字典原子的线性组合）和分析模型（信号在经过分析算子变换后有许多零项）。虽然两者相关，但并不等价。本练习将使用一个简单的图像，通过梯度算子（分析）与小波基（合成）的对比，清晰地阐明这一区别，并量化不同模型捕捉图像结构效率的差异。",
            "id": "3478943",
            "problem": "考虑图像的分析模型，其中分析算子 $\\Omega$ 将表示为向量 $x \\in \\mathbb{R}^{n}$ 的图像映射到分析系数 $\\Omega x \\in \\mathbb{R}^{m}$。分析余稀疏度定义为 $\\Omega x$ 中零元素的数量，即 $\\kappa := m - \\|\\Omega x\\|_{0}$，其中 $\\|\\cdot\\|_{0}$ 计算非零元素的数量。相比之下，合成模型将图像表示为 $x = D \\alpha$，其中 $D$ 是一个字典，$\\alpha$ 是一个系数向量；其合成稀疏度为 $s := \\|\\alpha\\|_{0}$。\n\n构造一个明确的例子，说明使用离散图像梯度算子的分析余稀疏度如何编码分段常数结构，而小波字典中的合成稀疏度可能无法同样有效地捕捉这种结构：\n\n- 设图像大小为 $4 \\times 4$，按列向量化为 $x \\in \\mathbb{R}^{16}$。定义前向差分离散梯度分析算子 $\\Omega \\in \\mathbb{R}^{24 \\times 16}$，其包含内部边缘上所有的水平和垂直最近邻差分：对于每个行索引 $i \\in \\{1,2,3,4\\}$ 和列索引 $j \\in \\{1,2,3\\}$，包含一个水平差分 $x_{i,j+1} - x_{i,j}$；对于每个 $i \\in \\{1,2,3\\}$ 和 $j \\in \\{1,2,3,4\\}$，包含一个垂直差分 $x_{i+1,j} - x_{i,j}$。将这 $24$ 个差分堆叠起来形成 $\\Omega x$。\n\n- 考虑分段常数图像 $X \\in \\mathbb{R}^{4 \\times 4}$，其元素在 $(i,j) = (3,3)$ 时为 $X_{i,j} = 1$，否则为 $X_{i,j} = 0$。设 $x \\in \\mathbb{R}^{16}$ 是其按列向量化的形式。\n\n- 对于合成模型，取 $D$ 为 $4 \\times 4$ 图像上的可分正交二维哈尔字典，通过先沿行再沿列应用两次一维正交哈尔变换来实现。长度为 $4$ 的向量 $[a, b, c, d]$ 的一维正交哈尔变换计算如下：形成第一级均值 $s_{1} = (a+b)/\\sqrt{2}$，$s_{2} = (c+d)/\\sqrt{2}$ 和细节 $w_{1} = (a-b)/\\sqrt{2}$，$w_{2} = (c-d)/\\sqrt{2}$，然后形成第二级均值和细节 $S = (s_{1} + s_{2})/\\sqrt{2}$ 和 $W = (s_{1} - s_{2})/\\sqrt{2}$，得到 $[S, W, w_{1}, w_{2}]$。\n\n计算 $x$ 相对于 $\\Omega$ 的分析余稀疏度 $\\kappa$，并通过计算非零的二维离散小波变换（DWT）系数的数量来计算 $x$ 在 $D$ 中的合成稀疏度 $s$。将单一量 $\\kappa - s$ 作为您的最终答案报告。最终答案以整数形式表示；无需四舍五入。",
            "solution": "该问题具有科学依据，提法明确且客观。它提出了稀疏信号表示和压缩感知领域内的一个标准任务，并提供了所有必要的定义和数据，以得出一个唯一的、可验证的解。因此，我们可以进行计算。\n\n问题要求计算两个量：给定图像的分析余稀疏度 $\\kappa$ 和合成稀疏度 $s$，然后报告它们的差值 $\\kappa-s$。\n\n首先，我们计算分析余稀疏度 $\\kappa$。\n图像是一个 $4 \\times 4$ 矩阵 $X$，在位置 $(3,3)$ 处有一个非零元素：\n$$\nX = \\begin{pmatrix}\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  0\n\\end{pmatrix}\n$$\n图像向量 $x \\in \\mathbb{R}^{16}$ 是 $X$ 的按列向量化。\n分析算子 $\\Omega \\in \\mathbb{R}^{m \\times n}$ 计算最近邻差分。这里，图像维度为 $n=16$。算子 $\\Omega$ 是通过堆叠所有水平和垂直差分来定义的。\n水平差分的数量指定为 $4$ 行 $\\times$ 每行 $3$ 个差分，总计 $12$ 个。\n垂直差分的数量指定为每行边缘 $3$ 个差分 $\\times$ $4$ 列，总计 $12$ 个。\n分析系数的总数为 $m = 12 + 12 = 24$。\n分析余稀疏度定义为 $\\kappa = m - \\|\\Omega x\\|_0$，其中 $\\|\\Omega x\\|_0$ 是差分向量 $\\Omega x$ 中非零元素的数量。\n\n$\\Omega x$ 中的一个元素是两个相邻像素的差分，形式为 $x_{i',j'} - x_{i,j}$。由于图像 $X$（及其向量化形式 $x$）仅在位置 $(3,3)$ 有一个非零元素，因此只有当差分是跨越连接到此像素的边缘时，差分才可能非零。位于 $(3,3)$ 的像素是一个内部像素，有四个邻居：$(3,2)$、$(3,4)$、$(2,3)$ 和 $(4,3)$。所有相邻像素的值都为 $0$。\n涉及像素 $X_{3,3}=1$ 的四个差分是：\n1.  水平差分 $X_{3,3} - X_{3,2} = 1 - 0 = 1$。问题将水平差分定义为 $x_{i,j+1} - x_{i,j}$。因此对于 $i=3, j=2$，我们有 $X_{3,3}-X_{3,2}=1$。\n2.  水平差分 $X_{3,4} - X_{3,3} = 0 - 1 = -1$。这是对于 $i=3, j=3$ 的情况。\n3.  垂直差分 $X_{3,3} - X_{2,3} = 1 - 0 = 1$。问题将垂直差分定义为 $x_{i+1,j} - x_{i,j}$。因此对于 $i=2, j=3$，我们有 $X_{3,3}-X_{2,3}=1$。\n4.  垂直差分 $X_{4,3} - X_{3,3} = 0 - 1 = -1$。这是对于 $i=3, j=3$ 的情况。\n\n所有其他差分都是在两个值为 $0$ 的像素之间计算的，因此结果为 $0$。\n因此，$\\Omega x$ 中非零元素的数量为 $\\|\\Omega x\\|_{0} = 4$。\n分析余稀疏度为 $\\kappa = m - \\|\\Omega x\\|_{0} = 24 - 4 = 20$。\n\n其次，我们计算合成稀疏度 $s$。\n合成表示为 $x = D\\alpha$，其中 $D$ 是二维正交哈尔字典。系数向量 $\\alpha$ 是通过对图像 $x$ 应用二维哈尔变换得到的。由于 $D$ 是正交的，所以 $\\alpha = D^T x$。稀疏度 $s$ 是 $\\alpha$ 中非零系数的数量，即 $s = \\|\\alpha\\|_0$。\n二维变换是通过对每行应用一维变换，然后对结果矩阵的每列应用一维变换来计算的。\n问题给出了长度为 $4$ 的向量 $[a, b, c, d]$ 的一维正交哈尔变换。我们来求出相应的变换矩阵 $W$。\n系数为 $c_1 = S = \\frac{1}{2}(a+b+c+d)$，$c_2 = W = \\frac{1}{2}(a+b-c-d)$，$c_3 = w_1 = \\frac{1}{\\sqrt{2}}(a-b)$ 和 $c_4 = w_2 = \\frac{1}{\\sqrt{2}}(c-d)$。\n因此，一维变换矩阵 $W$ 是：\n$$\nW = \\begin{pmatrix}\n1/2   1/2   1/2   1/2 \\\\\n1/2   1/2   -1/2   -1/2 \\\\\n1/\\sqrt{2}   -1/\\sqrt{2}   0   0 \\\\\n0   0   1/\\sqrt{2}   -1/\\sqrt{2}\n\\end{pmatrix}\n$$\n二维哈尔系数是矩阵 $C = W X W^T$ 的元素。\n\n第一步：对 $X$ 的行进行变换。我们称结果为 $X'$。$X'$ 的第 $i$ 行是 $X$ 的第 $i$ 行的变换结果。\n$X$ 的第 $1$、$2$ 和 $4$ 行都是全零向量，因此它们的变换结果也是全零向量。\n$X$ 的第 $3$ 行是 $[0, 0, 1, 0]$。它的变换是 $W [0, 0, 1, 0]^T$，也就是 $W$ 的第三列。\n$$ \\text{变换后的第 3 行} = [1/2, -1/2, 0, 1/\\sqrt{2}] $$\n所以，中间矩阵是：\n$$\nX' = \\begin{pmatrix}\n0   0   0   0 \\\\\n0   0   0   0 \\\\\n1/2   -1/2   0   1/\\sqrt{2} \\\\\n0   0   0   0\n\\end{pmatrix}\n$$\n第二步：对 $X'$ 的列进行变换。最终的系数矩阵 $C$ 是通过对 $X'$ 的列进行变换得到的。\n$X'$ 的第 $1$ 列是 $[0, 0, 1/2, 0]^T$。它的变换是 $W [0, 0, 1/2, 0]^T = \\frac{1}{2} W [0, 0, 1, 0]^T = \\frac{1}{2} \\times (\\text{W 的第 3 列}) = [1/4, -1/4, 0, 1/(2\\sqrt{2})]^T$。\n$X'$ 的第 $2$ 列是 $[0, 0, -1/2, 0]^T$。它的变换是 $-\\frac{1}{2} W [0, 0, 1, 0]^T = [-1/4, 1/4, 0, -1/(2\\sqrt{2})]^T$。\n$X'$ 的第 $3$ 列是 $[0, 0, 0, 0]^T$。它的变换是 $[0, 0, 0, 0]^T$。\n$X'$ 的第 $4$ 列是 $[0, 0, 1/\\sqrt{2}, 0]^T$。它的变换是 $\\frac{1}{\\sqrt{2}} W [0, 0, 1, 0]^T = [1/(2\\sqrt{2}), -1/(2\\sqrt{2}), 0, 1/2]^T$。\n\n最终的系数矩阵 $C$（其元素是 $\\alpha$ 的系数，排列成一个 $4 \\times 4$ 的网格）是：\n$$\nC = \\begin{pmatrix}\n1/4   -1/4   0   1/(2\\sqrt{2}) \\\\\n-1/4   1/4   0   -1/(2\\sqrt{2}) \\\\\n0   0   0   0 \\\\\n1/(2\\sqrt{2})   -1/(2\\sqrt{2})   0   1/2\n\\end{pmatrix}\n$$\n合成稀疏度 $s$ 是该矩阵中非零元素的数量。通过观察，我们统计非零元素的数量：\n- 第 1 行：$3$ 个非零元素。\n- 第 2 行：$3$ 个非零元素。\n- 第 3 行：$0$ 个非零元素。\n- 第 4 行：$3$ 个非零元素。\n非零系数的总数为 $s = 3 + 3 + 0 + 3 = 9$。\n\n最后，我们计算所需的量 $\\kappa - s$：\n$$ \\kappa - s = 20 - 9 = 11 $$",
            "answer": "$$\\boxed{11}$$"
        },
        {
            "introduction": "稀疏性并非信号的固有属性，而是取决于所选择的变换。本计算实践旨在探究信号处理中两种最重要的变换——离散余弦变换（DCT）和哈尔小波变换——在压缩不同类型图像块能量方面的表现。通过在合成但具有代表性的数据（平滑斑块、纹理、边缘）上进行实现和测试，你将对DCT为何是JPEG压缩的基石，以及小波为何对JPEG 2000等现代标准至关重要，获得实践性的理解。",
            "id": "3479024",
            "problem": "令 $x \\in \\mathbb{R}^{n \\times n}$ 表示一个在均匀网格上采样的边长为 $n$ 的方形图像块。考虑在 $\\mathbb{R}^{n \\times n}$ 上的两种正交变换：带正交缩放的二维II型离散余弦变换（DCT），以及带二元多分辨率分解的二维正交哈尔小波变换。对于任意正交变换 $\\mathcal{T}:\\mathbb{R}^{n \\times n} \\to \\mathbb{R}^{n \\times n}$，定义变换系数 $c = \\mathcal{T}(x)$ 以及由 $k$ 个最大幅值系数所捕获的能量分数\n$$\nF_{\\mathcal{T}}(k; x) = \\frac{\\sum_{i \\in S_k} c_i^2}{\\sum_{i=1}^{n^2} c_i^2},\n$$\n其中 $S_k$ 索引了 $|c_i|$ 中最大的 $k$ 个条目，$c_i$ 按任意固定的线性化顺序列举了 $c$ 的条目。因为 $\\mathcal{T}$ 是正交的，根据帕塞瓦尔恒等式，$\\sum_{i=1}^{n^2} c_i^2 = \\sum_{u,v=1}^{n} x_{uv}^2$。\n\n从正交变换、能量和帕塞瓦尔恒等式的定义出发，分析自然图像块在二维DCT与二维哈尔小波变换下的能量集中和稀疏性。使用能量分数度量 $F_{\\mathcal{T}}(k;x)$ 并研究其对 $k$ 的依赖性。\n\n使用 $n=32$ 构建一个确定性图像块测试套件，旨在反映自然图像中的常见结构（分段平滑边缘、纹理和平滑斑点）。每个图像块必须经过均值中心化并缩放到单位 $\\ell_2$ 范数，以使能量分数无量纲且具有可比性。将这三类明确定义如下：\n\n1. 边缘块（卡通式阶跃边缘）：对于角度 $\\theta \\in \\{0, \\pi/6, \\pi/3, \\pi/2\\}$，定义\n$$\nx_{\\text{edge}}(u,v;\\theta) = \\begin{cases}\n1,  \\cos(\\theta)\\left(\\frac{u}{n} - \\frac{1}{2}\\right) + \\sin(\\theta)\\left(\\frac{v}{n} - \\frac{1}{2}\\right) \\ge 0, \\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\n其中 $u,v \\in \\{0,1,\\dots,n-1\\}$，然后减去均值并缩放到单位 $\\ell_2$ 范数。\n\n2. 纹理块（余弦光栅之和）：对于四个预定义的空间频率和相位列表，\n- 频率 $\\{(1,2),(2,1),(3,0),(0,3)\\}$，相位 $\\{0, \\pi/4, \\pi/2, 3\\pi/4\\}$，\n- 频率 $\\{(1,1),(2,0),(0,2),(3,3)\\}$，相位 $\\{\\pi/6, \\pi/3, \\pi/2, 2\\pi/3\\}$，\n- 频率 $\\{(4,1),(1,4),(2,2),(0,1)\\}$，相位 $\\{\\pi/5, 2\\pi/5, 3\\pi/5, 4\\pi/5\\}$，\n- 频率 $\\{(3,2),(2,3),(1,0),(0,1)\\}$，相位 $\\{0.1, 0.7, 1.2, 2.0\\}$，\n定义\n$$\nx_{\\text{tex}}(u,v) = \\sum_{j=1}^{4} \\frac{1}{1 + \\sqrt{f_{x,j}^2 + f_{y,j}^2}} \\cos\\!\\left(2\\pi\\left(f_{x,j}\\frac{u}{n} + f_{y,j}\\frac{v}{n}\\right) + \\phi_j\\right),\n$$\n然后减去均值并缩放到单位 $\\ell_2$ 范数。\n\n3. 平滑斑点块（高斯函数之和）：对于四组中心、标准差和振幅的集合，定义\n$$\nx_{\\text{blob}}(u,v) = \\sum_{j=1}^{3} a_j \\exp\\!\\left(-\\frac{\\left(\\frac{u}{n} - c_{x,j}\\right)^2 + \\left(\\frac{v}{n} - c_{y,j}\\right)^2}{2\\sigma_j^2}\\right),\n$$\n使用以下确定性参数：\n- 中心 $\\{(0.3,0.3),(0.7,0.5),(0.5,0.8)\\}$，$\\sigma \\in \\{0.08,0.12,0.10\\}$，$a \\in \\{1.0,0.6,0.8\\}$；\n- 中心 $\\{(0.2,0.7),(0.6,0.2),(0.8,0.8)\\}$，$\\sigma \\in \\{0.10,0.09,0.11\\}$，$a \\in \\{0.9,0.7,0.5\\}$；\n- 中心 $\\{(0.4,0.4),(0.5,0.6),(0.7,0.3)\\}$，$\\sigma \\in \\{0.07,0.13,0.09\\}$，$a \\in \\{1.1,0.5,0.6\\}$；\n- 中心 $\\{(0.25,0.25),(0.75,0.75),(0.5,0.5)\\}$，$\\sigma \\in \\{0.12,0.12,0.08\\}$，$a \\in \\{0.8,0.8,1.0\\}$；\n然后减去均值并缩放到单位 $\\ell_2$ 范数。\n\n对于DCT，使用沿行和列可分离应用的带正交缩放的二维II型DCT。对于小波，使用二维正交哈尔变换，其二元分解通过在当前的低-低子带上沿行和列重复应用一维正交哈尔变换来实现，直到子带大小变为 $1 \\times 1$。\n\n令 $k$ 值的集合为 $K = \\{0,1,4,16,64,256,n^2\\}$，其中 $n=32$ 因此 $n^2=1024$。对于每个 $k \\in K$，计算在两种变换下整个测试套件的平均能量分数，记为 $\\overline{F}_{\\text{DCT}}(k)$ 和 $\\overline{F}_{\\text{Haar}}(k)$。将每个 $k$ 的比较度量定义为差值\n$$\nD(k) = \\overline{F}_{\\text{DCT}}(k) - \\overline{F}_{\\text{Haar}}(k),\n$$\n它是一个实数。对于每种变换，答案是表示为 $[0,1]$ 范围内小数的无量纲分数，而 $D(k)$ 是实数。\n\n你的程序必须：\n- 按照规定构建12个图像块（4个边缘块、4个纹理块、4个斑点块），并对每个块进行均值中心化和单位范数归一化。\n- 实现二维正交DCT和正交哈尔变换。\n- 对于每个 $k \\in K$，计算12个图像块上的 $\\overline{F}_{\\text{DCT}}(k)$、$\\overline{F}_{\\text{Haar}}(k)$，然后计算 $D(k)$。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按 $K$ 中 $k$ 的顺序排列结果，即 $[D(0),D(1),D(4),D(16),D(64),D(256),D(1024)]$。\n\n该测试套件涵盖了边界条件（$k=0$ 和 $k=n^2$）和不同的稀疏尺度。最终输出为不带物理单位的实数（浮点数）。",
            "solution": "用户提供了一个问题，要求对信号处理中两种著名的正交变换——二维离散余弦变换（DCT）和二维哈尔小波变换——在稀疏表示不同类型图像结构方面的能力进行比较分析。该比较将在一个明确定义的合成图像块测试套件上进行。\n\n该分析基于**能量集中**的概念。在信号处理中，如果一个变换能够用少量变换系数捕获信号的大部分能量，则称该变换为此类信号提供了一种稀疏表示。其度量标准是能量分数 $F_{\\mathcal{T}}(k; x)$，定义为：\n$$\nF_{\\mathcal{T}}(k; x) = \\frac{\\sum_{i \\in S_k} c_i^2}{\\sum_{i=1}^{n^2} c_i^2}\n$$\n此处，$c = \\mathcal{T}(x)$ 是图像块 $x \\in \\mathbb{R}^{n \\times n}$ 在正交变换 $\\mathcal{T}$ 下的系数。集合 $S_k$ 包含了幅值 $|c_i|$ 最大的 $k$ 个系数的索引。由于变换 $\\mathcal{T}$ 是正交的，帕塞瓦尔恒等式表明总能量在信号域和变换域之间是守恒的：$\\sum_{i=1}^{n^2} c_i^2 = \\sum_{u,v=1}^{n} x_{uv}^2 = \\|x\\|_F^2$，其中 $\\|x\\|_F$ 是弗罗贝尼乌斯范数。问题规定每个图像块 $x$ 都被归一化为单位 $\\ell_2$ 范数（对于向量化的矩阵，这等同于弗罗贝尼乌斯范数），意味着 $\\|x\\|_F^2 = 1$。因此，能量分数公式中的分母恒为1，将该度量简化为幅值最大的 $k$ 个系数的平方和：\n$$\nF_{\\mathcal{T}}(k; x) = \\sum_{i \\in S_k} c_i^2\n$$\n\n所考虑的两种变换的基函数具有截然不同的特性，这导致它们在信号表示方面具有不同的优势。\n\n1.  **二维正交离散余弦变换（DCT-II）**：DCT的基函数是不同频率的余弦函数。这些函数是平滑且非局域的（其支撑集覆盖整个图像块）。因此，DCT擅长表示平滑且高度相关的信号，这是自然图像中平滑变化区域的常见特征。二维DCT是可分离的，通过对图像块的行和列分别应用一维DCT来计算。对于正交变换，会应用特定的缩放因子：零频率系数为 $\\sqrt{1/n}$，所有其他频率系数为 $\\sqrt{2/n}$。\n\n2.  **二维正交哈尔小波变换**：哈尔小波系统由分段常数的尺度函数（盒子函数）和分段常数的小波函数（方波）构建而成。其基函数在空间和频率上都是局域化的（尽管频率局域性较差）。这种空间局域性使得哈尔小波变换在表示具有尖锐不连续点（如边缘）的信号时非常有效，这些不连续点可以通过相应位置和尺度上的少数小波系数进行紧凑表示。指定的小波变换是一种二元多分辨率分解，其中一维哈尔变换被可分离地应用，产生四个子带（LL、LH、HL、HH），然后该过程递归地应用于低-低（LL）子带，直到留下一个 $1 \\times 1$ 的LL子带。\n\n该问题要求创建一个由12个大小为 $n=32$ 的图像块组成的确定性测试套件，旨在模拟三种基本的图像结构类型：\n*   **边缘块**：这些是卡通式图像，在不同方向上具有单一、尖锐的阶跃边缘。由于其尖锐、局域化的不连续性，预期哈尔变换会比DCT提供更紧凑的表示。\n*   **纹理块**：这些是通过对余弦光栅求和生成的。由于它们由正弦分量构成，而DCT的基函数是正弦函数，因此预期DCT会提供极其紧凑的表示。\n*   **平滑斑点块**：这些是通过对平滑高斯函数求和生成的。这些图像块的平滑性和高空间相关性使其成为DCT稀疏表示的理想对象。\n\n对于生成的12个图像块中的每一个，我们将执行以下步骤：\n1.  通过减去均值来对图像块 $x$ 进行均值中心化，$x' = x - \\bar{x}$。\n2.  将图像块归一化为单位 $\\ell_2$ 范数，$x_{\\text{norm}} = x' / \\|x'\\|_2$。\n3.  计算变换系数 $c_{\\text{DCT}} = \\mathcal{T}_{\\text{DCT}}(x_{\\text{norm}})$ 和 $c_{\\text{Haar}} = \\mathcal{T}_{\\text{Haar}}(x_{\\text{norm}})$。\n4.  对于集合 $K = \\{0, 1, 4, 16, 64, 256, 1024\\}$ 中的每个 $k$ 值，计算能量分数 $F_{\\text{DCT}}(k; x_{\\text{norm}})$ 和 $F_{\\text{Haar}}(k; x_{\\text{norm}})$。这包括将系数的绝对值按降序排序，并对前 $k$ 个值的平方求和。\n5.  处理完所有12个图像块后，为每个 $k \\in K$ 计算平均能量分数 $\\overline{F}_{\\text{DCT}}(k)$ 和 $\\overline{F}_{\\text{Haar}}(k)$。\n6.  最后，计算差异度量 $D(k) = \\overline{F}_{\\text{DCT}}(k) - \\overline{F}_{\\text{Haar}}(k)$。\n\n$D(k)$ 的正值表示，平均而言，DCT对于幅值最大的 $k$ 个系数实现了更好的能量集中；而负值则表示哈尔变换表现更优。$k=0$ 和 $k=n^2=1024$ 的值用作边界检查。对于 $k=0$，没有捕获任何能量，因此 $F(0)=0$ 且 $D(0)=0$。对于 $k=n^2$，捕获了全部能量，因此 $F(n^2)=1$（根据帕塞瓦尔恒等式和单位范数），从而 $D(n^2)=0$。$D(k)$ 的中间值将揭示两种变换在不同稀疏度级别上的相对性能。基于变换的性质和测试图像块的特点，我们预计对于大多数 $k$，$D(k)$ 将为正值，因为12个图像块中有8个（纹理块和斑点块）本质上是平滑或正弦的，这有利于DCT。边缘块将对总和产生负贡献，但其影响可能会被抵消。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import dct\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the patch generation, transformation, and analysis.\n    \"\"\"\n    n = 32\n    K = [0, 1, 4, 16, 64, 256, 1024]\n    \n    patches = generate_patches(n)\n    \n    num_patches = len(patches)\n    num_k = len(K)\n    \n    F_dct_all = np.zeros((num_patches, num_k))\n    F_haar_all = np.zeros((num_patches, num_k))\n    \n    for i, patch in enumerate(patches):\n        # Apply transforms\n        c_dct = ortho_dct2(patch)\n        c_haar = ortho_haar2(patch)\n        \n        # Calculate energy fractions for each k\n        for j, k in enumerate(K):\n            F_dct_all[i, j] = calculate_energy_fraction(c_dct, k)\n            F_haar_all[i, j] = calculate_energy_fraction(c_haar, k)\n            \n    # Average over all patches\n    F_dct_avg = np.mean(F_dct_all, axis=0)\n    F_haar_avg = np.mean(F_haar_all, axis=0)\n    \n    # Compute the difference metric\n    D = F_dct_avg - F_haar_avg\n    \n    # Format and print the final output\n    print(f\"[{','.join(f'{d:.12f}' for d in D)}]\")\n\ndef _normalize_patch(patch):\n    \"\"\"Mean-centers and scales a patch to unit l2 norm.\"\"\"\n    p = patch - np.mean(patch)\n    norm = np.linalg.norm(p)\n    if norm  1e-9:\n        return p / norm\n    return p\n\ndef generate_patches(n):\n    \"\"\"\n    Generates the test suite of 12 image patches.\n    \"\"\"\n    patches = []\n    \n    # Coordinate grids\n    u = np.arange(n)\n    v = np.arange(n)\n    uu, vv = np.meshgrid(u, v, indexing='ij')\n    \n    # 1. Edge Patches\n    x_coords_centered = uu / n - 0.5\n    y_coords_centered = vv / n - 0.5\n    thetas = [0, np.pi/6, np.pi/3, np.pi/2]\n    for theta in thetas:\n        patch = (np.cos(theta) * x_coords_centered + np.sin(theta) * y_coords_centered = 0).astype(float)\n        patches.append(_normalize_patch(patch))\n\n    u_norm = uu / n\n    v_norm = vv / n\n\n    # 2. Texture Patches\n    tex_params = [\n        ({'freqs': [(1,2),(2,1),(3,0),(0,3)], 'phases': [0, np.pi/4, np.pi/2, 3*np.pi/4]}),\n        ({'freqs': [(1,1),(2,0),(0,2),(3,3)], 'phases': [np.pi/6, np.pi/3, np.pi/2, 2*np.pi/3]}),\n        ({'freqs': [(4,1),(1,4),(2,2),(0,1)], 'phases': [np.pi/5, 2*np.pi/5, 3*np.pi/5, 4*np.pi/5]}),\n        ({'freqs': [(3,2),(2,3),(1,0),(0,1)], 'phases': [0.1, 0.7, 1.2, 2.0]}),\n    ]\n    for params in tex_params:\n        patch = np.zeros((n, n))\n        for j in range(4):\n            fx, fy = params['freqs'][j]\n            phi = params['phases'][j]\n            weight = 1.0 / (1.0 + np.sqrt(fx**2 + fy**2))\n            patch += weight * np.cos(2 * np.pi * (fx * u_norm + fy * v_norm) + phi)\n        patches.append(_normalize_patch(patch))\n\n    # 3. Smooth Blob Patches\n    blob_params = [\n        ({'centers': [(0.3,0.3),(0.7,0.5),(0.5,0.8)], 'sigmas': [0.08,0.12,0.10], 'amps': [1.0,0.6,0.8]}),\n        ({'centers': [(0.2,0.7),(0.6,0.2),(0.8,0.8)], 'sigmas': [0.10,0.09,0.11], 'amps': [0.9,0.7,0.5]}),\n        ({'centers': [(0.4,0.4),(0.5,0.6),(0.7,0.3)], 'sigmas': [0.07,0.13,0.09], 'amps': [1.1,0.5,0.6]}),\n        ({'centers': [(0.25,0.25),(0.75,0.75),(0.5,0.5)], 'sigmas': [0.12,0.12,0.08], 'amps': [0.8,0.8,1.0]}),\n    ]\n    for params in blob_params:\n        patch = np.zeros((n, n))\n        for j in range(3):\n            cx, cy = params['centers'][j]\n            sigma = params['sigmas'][j]\n            a = params['amps'][j]\n            patch += a * np.exp(-((u_norm - cx)**2 + (v_norm - cy)**2) / (2 * sigma**2))\n        patches.append(_normalize_patch(patch))\n        \n    return patches\n\n\ndef ortho_dct2(x):\n    \"\"\"\n    Computes the 2D orthonormal DCT-II.\n    \"\"\"\n    return dct(dct(x, type=2, norm='ortho', axis=1), type=2, norm='ortho', axis=0)\n\ndef ortho_haar2(x):\n    \"\"\"\n    Computes the 2D orthonormal Haar wavelet transform with dyadic decomposition.\n    \"\"\"\n    n = x.shape[0]\n    h = x.copy()\n    L = n\n    sqrt2 = np.sqrt(2.0)\n    \n    while L  1:\n        L_half = L // 2\n        # Operate on the current LL subband\n        subband = h[:L, :L]\n        \n        # 1D Haar on rows\n        rows_avg = (subband[:, 0::2] + subband[:, 1::2]) / sqrt2\n        rows_diff = (subband[:, 0::2] - subband[:, 1::2]) / sqrt2\n        transformed_rows = np.hstack((rows_avg, rows_diff))\n        \n        # 1D Haar on columns of the row-transformed matrix\n        cols_avg = (transformed_rows[0::2, :] + transformed_rows[1::2, :]) / sqrt2\n        cols_diff = (transformed_rows[0::2, :] - transformed_rows[1::2, :]) / sqrt2\n        transformed_cols = np.vstack((cols_avg, cols_diff))\n        \n        # Place the transformed result back into the main matrix\n        h[:L, :L] = transformed_cols\n        \n        L = L_half\n        \n    return h\n\n\ndef calculate_energy_fraction(c, k):\n    \"\"\"\n    Calculates the fraction of energy in the top-k magnitude coefficients.\n    Assumes total energy (denominator) is 1.\n    \"\"\"\n    if k == 0:\n        return 0.0\n    \n    c_flat = c.flatten()\n    # The problem implies that total energy is 1, so the fraction is simply\n    # the sum of squares of the k largest-magnitude coefficients.\n    \n    # Sort absolute values in descending order\n    sorted_abs_coeffs_sq = np.sort(np.abs(c_flat)**2)[::-1]\n    \n    # Sum the k largest squared coefficients\n    energy = np.sum(sorted_abs_coeffs_sq[:k])\n    \n    return energy\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}