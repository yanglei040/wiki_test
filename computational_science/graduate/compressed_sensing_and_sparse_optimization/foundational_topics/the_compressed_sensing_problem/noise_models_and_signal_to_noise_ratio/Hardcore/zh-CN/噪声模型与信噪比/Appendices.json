{
    "hands_on_practices": [
        {
            "introduction": "信噪比（SNR）是评估信号质量和系统性能的基石。本练习将从功率和幅度的基本物理定义出发，巩固您对信噪比的理解，特别是其在对数分贝（dB）尺度上的表示方法。掌握这种转换对于在压缩感知的理论分析和实际实验中正确解读性能至关重要。",
            "id": "3462108",
            "problem": "考虑压缩感知中的线性测量模型 $\\mathbf{y}=\\mathbf{A}\\mathbf{x}+\\mathbf{w}$，其中 $\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$ 的元素 $A_{ij}\\sim\\mathcal{N}(0,1/m)$ 是独立同分布 (i.i.d.) 的，未知信号 $\\mathbf{x}\\in\\mathbb{R}^{n}$ 是 $K$-稀疏的，有且仅有 $K$ 个非零项，每个非零项的幅度均为 $a0$，噪声 $\\mathbf{w}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I}_{m})$ 是加性高斯白噪声 (AWGN)。信噪比 (SNR) 定义为平均信号功率与平均噪声功率之比，分贝 (dB) 是比率的对数度量。\n\n(a) 从以下基本定义出发：(i) 在线性系统中，功率与均方根 (RMS) 幅度的平方成正比；(ii) 贝尔 (bel) 是功率比以10为底的对数，而分贝 (dB) 是贝尔的十分之一，推导信噪比 $\\mathrm{SNR}$ 的分贝表示法。然后，仅使用这些定义，精确解释在涉及功率比或均方根幅度比（例如，$\\ell_{2}$ 能量之比与 $\\ell_{2}$ 范数之比）的压缩感知语境中，何时应使用 $10\\log_{10}(\\cdot)$ 与 $20\\log_{10}(\\cdot)$ 形式的表达式。不要假设任何超出这些定义的专门公式。\n\n(b) 对于上述模型，计算期望线性尺度 $\\mathrm{SNR}$，并用 $K$, $a$, $m$ 和 $\\sigma^{2}$ 表示。\n\n(c) 使用 (b) 部分的结果和 (a) 部分建立的适当的分贝转换，计算在特定参数 $m=200$, $K=10$, $a=0.5$ 和 $\\sigma^{2}=10^{-3}$ 下的信噪比（以分贝为单位）。以 dB 表示最终的信噪比，并将您的答案四舍五入到四位有效数字。",
            "solution": "我们从关于功率、幅度和对数比率度量的基本原理开始。\n\n第 (a) 部分。信噪比 (SNR) 定义为功率之比：\n$$\n\\mathrm{SNR} \\equiv \\frac{P_{\\text{signal}}}{P_{\\text{noise}}}.\n$$\n贝尔 (bel) 定义为功率比以10为底的对数。如果 $R$ 是一个功率比，那么贝尔数就是 $\\log_{10}(R)$。分贝 (dB) 是贝尔的十分之一，所以以 dB 度量的功率比 $R$ 为\n$$\n\\mathrm{dB}(R) = 10\\log_{10}(R).\n$$\n因此，信噪比的分贝表示法是\n$$\n\\mathrm{SNR}_{\\mathrm{dB}} = 10\\log_{10}\\!\\left(\\mathrm{SNR}\\right).\n$$\n现在，考虑一个幅度比，例如均方根幅度比 $r \\equiv A_{\\text{signal,RMS}}/A_{\\text{noise,RMS}}$。在线性系统中，功率与均方根幅度的平方成正比。因此，相应的功率比是 $R = r^{2}$。其分贝表示法变为\n$$\n\\mathrm{dB}(r) = 10\\log_{10}\\!\\left(r^{2}\\right) = 20\\log_{10}(r).\n$$\n因此，$10\\log_{10}(\\cdot)$ 必须用于功率比（例如，$\\ell_{2}$ 能量之比，如 $\\|\\cdot\\|_{2}^{2}$），而 $20\\log_{10}(\\cdot)$ 适用于幅度比（例如，$\\ell_{2}$ 范数之比或均方根幅度）。在压缩感知的实践中，当 SNR 定义为 $\\|\\mathbf{A}\\mathbf{x}\\|_{2}^{2}/\\|\\mathbf{w}\\|_{2}^{2}$ 时，使用 $10\\log_{10}$；而如果使用 $\\|\\mathbf{A}\\mathbf{x}\\|_{2}/\\|\\mathbf{w}\\|_{2}$，则使用 $20\\log_{10}$；这两者是等效的，因为功率和幅度之间存在平方关系。\n\n第 (b) 部分。我们为给定的随机模型计算期望线性尺度信噪比。信号分量为 $\\mathbf{s}=\\mathbf{A}\\mathbf{x}$，噪声为 $\\mathbf{w}$。信号功率是期望的 $\\ell_{2}$ 范数的平方：\n$$\n\\mathbb{E}\\!\\left[\\|\\mathbf{A}\\mathbf{x}\\|_{2}^{2}\\right]\n= \\mathbb{E}\\!\\left[\\mathbf{x}^{\\top}\\mathbf{A}^{\\top}\\mathbf{A}\\mathbf{x}\\right]\n= \\mathbf{x}^{\\top}\\,\\mathbb{E}\\!\\left[\\mathbf{A}^{\\top}\\mathbf{A}\\right]\\mathbf{x}.\n$$\n对于独立同分布的元素 $A_{ij}\\sim\\mathcal{N}(0,1/m)$，一个标准的事实是 $\\mathbb{E}\\!\\left[\\mathbf{A}^{\\top}\\mathbf{A}\\right]=\\mathbf{I}_{n}$，因此\n$$\n\\mathbb{E}\\!\\left[\\|\\mathbf{A}\\mathbf{x}\\|_{2}^{2}\\right] = \\|\\mathbf{x}\\|_{2}^{2}.\n$$\n噪声功率为\n$$\n\\mathbb{E}\\!\\left[\\|\\mathbf{w}\\|_{2}^{2}\\right] = \\sum_{i=1}^{m}\\mathbb{E}[w_{i}^{2}] = m\\sigma^{2}.\n$$\n因此，期望线性尺度信噪比为\n$$\n\\mathrm{SNR} \\equiv \\frac{\\mathbb{E}\\!\\left[\\|\\mathbf{A}\\mathbf{x}\\|_{2}^{2}\\right]}{\\mathbb{E}\\!\\left[\\|\\mathbf{w}\\|_{2}^{2}\\right]}\n= \\frac{\\|\\mathbf{x}\\|_{2}^{2}}{m\\sigma^{2}}.\n$$\n已知 $\\mathbf{x}$ 有且仅有 $K$ 个非零项，每个值都等于 $a$，我们有\n$$\n\\|\\mathbf{x}\\|_{2}^{2} = Ka^{2},\n$$\n所以\n$$\n\\mathrm{SNR} = \\frac{Ka^{2}}{m\\sigma^{2}}.\n$$\n\n第 (c) 部分。将指定参数 $m=200$, $K=10$, $a=0.5$ 和 $\\sigma^{2}=10^{-3}$ 代入线性尺度信噪比：\n$$\n\\mathrm{SNR} = \\frac{10\\cdot(0.5)^{2}}{200\\cdot 10^{-3}} = \\frac{10\\cdot 0.25}{0.2} = \\frac{2.5}{0.2} = 12.5.\n$$\n因为这是一个功率比，所以适当的转换是 $10\\log_{10}(\\cdot)$。因此\n$$\n\\mathrm{SNR}_{\\mathrm{dB}} = 10\\log_{10}(12.5).\n$$\n为了计算数值，注意到 $\\log_{10}(12.5)=\\log_{10}(25)-\\log_{10}(2)$，其中 $\\log_{10}(25)=1.397940\\ldots$ 且 $\\log_{10}(2)=0.301030\\ldots$，可得\n$$\n\\mathrm{SNR}_{\\mathrm{dB}} = 10(1.397940\\ldots - 0.301030\\ldots) = 10(1.096910\\ldots) \\approx 10.96910\\ldots\n$$\n四舍五入到四位有效数字并以分贝 (dB) 表示，结果是 $10.97$ dB。",
            "answer": "$$\\boxed{10.97}$$"
        },
        {
            "introduction": "一旦我们理解了噪声的统计特性，如何利用这些信息来恢复底层稀疏信号？本练习将稀疏支撑集恢复问题置于严谨的多重假设检验框架之下。您将推导出一个能够控制错误发现率的决策阈值，从而将噪声方差与恢复算法的可靠性直接联系起来。",
            "id": "3462105",
            "problem": "考虑一个压缩感知中的线性逆问题，其测量模型为 $y = A x + w$，其中 $y \\in \\mathbb{R}^{m}$，$A \\in \\mathbb{R}^{m \\times n}$，$x \\in \\mathbb{R}^{n}$ 是一个未知的稀疏向量，$w \\in \\mathbb{R}^{m}$ 是加性噪声。假设 $A$ 的列是标准正交的，因此 $A^{\\top} A = I_{n}$，并且噪声是白高斯噪声，$w \\sim \\mathcal{N}(0, \\sigma^{2} I_{m})$，其方差 $\\sigma^{2}  0$ 已知。定义代理统计量 $t = A^{\\top} y \\in \\mathbb{R}^{n}$，并将支撑集恢复问题视为对坐标级原假设 $H_{0,j}: x_{j} = 0$（其中 $j = 1, \\dots, n$）的同步假设检验，使用双边准则，即如果 $|t_{j}| \\geq \\tau$（对于某个阈值 $\\tau  0$），则宣布坐标 $j$ 是活动的。\n\n使用基本原理——高斯噪声模型、多元高斯分布在线性映射下的变换性质以及并集界——将此问题表述为关于 $A^{\\top} y$ 坐标的多重检验问题，并推导出最小的经邦费罗尼(Bonferroni)校准的阈值 $\\tau$，以保证族内错误率（FWER；在所有真实原假设中至少有一次错误拒绝的概率）在所有稀疏支撑集上一致地至多为期望水平 $\\alpha \\in (0,1)$。将您的最终答案表示为关于 $\\sigma$、$\\alpha$ 和 $n$ 的闭式解析表达式。不需要数值近似。",
            "solution": "我们的目标是找到最小的阈值 $\\tau$，使得多重检验问题的族内错误率（FWER）不大于指定水平 $\\alpha$。\n\n首先，我们分析代理统计量 $t = A^{\\top} y$ 的分布。代入测量模型 $y = A x + w$，我们得到：\n$$t = A^{\\top}(A x + w) = A^{\\top} A x + A^{\\top} w$$\n使用给定的条件，$A$ 的列是标准正交的，即 $A^{\\top} A = I_{n}$（$n \\times n$ 单位矩阵），表达式简化为：\n$$t = I_{n} x + A^{\\top} w = x + A^{\\top} w$$\n让我们定义一个新的噪声向量 $v = A^{\\top} w$。由于 $w$ 是一个多元高斯随机向量，$v$ 也是一个多元高斯随机向量，因为它是 $w$ 的线性变换。我们来确定它的分布。$v$ 的均值是：\n$$\\mathbb{E}[v] = \\mathbb{E}[A^{\\top} w] = A^{\\top} \\mathbb{E}[w] = A^{\\top} \\mathbf{0} = \\mathbf{0}$$\n$v$ 的协方差矩阵是：\n$$\\text{Cov}(v) = \\mathbb{E}[v v^{\\top}] - \\mathbb{E}[v]\\mathbb{E}[v]^{\\top} = \\mathbb{E}[(A^{\\top} w)(A^{\\top} w)^{\\top}] = \\mathbb{E}[A^{\\top} w w^{\\top} A] = A^{\\top} \\mathbb{E}[w w^{\\top}] A$$\n鉴于 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{m})$，其协方差矩阵是 $\\mathbb{E}[w w^{\\top}] = \\sigma^{2} I_{m}$。代入这个结果，我们得到：\n$$\\text{Cov}(v) = A^{\\top} (\\sigma^{2} I_{m}) A = \\sigma^{2} (A^{\\top} A) = \\sigma^{2} I_{n}$$\n因此，变换后的噪声向量是 $v \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。这意味着 $v$ 的分量 $v_j$ 是独立同分布 (i.i.d.) 的，即 $v_j \\sim \\mathcal{N}(0, \\sigma^{2})$。\n代理统计量可以按分量写为 $t_j = x_j + v_j$，其中 $j = 1, \\dots, n$。\n\n接下来，我们考虑对每个坐标 $j$ 的假设检验。原假设是 $H_{0,j}: x_j = 0$。在此原假设下，检验统计量 $t_j$ 的分布与噪声分量 $v_j$ 的分布相同：\n$$t_j | H_{0,j} \\sim \\mathcal{N}(0, \\sigma^{2})$$\n如果我们在原假设 $H_{0,j}$ 为真时拒绝它，就会发生第 $j$ 次检验的 I 类错误。拒绝规则是 $|t_j| \\ge \\tau$。这个事件的概率，我们称之为 $p_j$，是：\n$$p_j = P(|t_j| \\ge \\tau | H_{0,j})$$\n为了计算这个概率，我们可以通过将随机变量 $t_j$ 除以其标准差 $\\sigma$ 来对其进行标准化。令 $Z_j = t_j/\\sigma$，其中 $Z_j | H_{0,j} \\sim \\mathcal{N}(0, 1)$。\n$$p_j = P(|Z_j| \\ge \\frac{\\tau}{\\sigma}) = P\\left(Z_j \\ge \\frac{\\tau}{\\sigma}\\right) + P\\left(Z_j \\le -\\frac{\\tau}{\\sigma}\\right)$$\n令 $\\Phi(z)$ 表示标准正态分布 $\\mathcal{N}(0, 1)$ 的累积分布函数 (CDF)。那么 $P(Z_j \\ge z) = 1 - \\Phi(z)$，并且根据对称性，$P(Z_j \\le -z) = \\Phi(-z) = 1 - \\Phi(z)$。因此：\n$$p_j = 2\\left(1 - \\Phi\\left(\\frac{\\tau}{\\sigma}\\right)\\right)$$\n对于所有 $H_{0,j}$ 为真的 $j$，这个概率是相同的。\n\nFWER是犯至少一次 I 类错误的概率。令 $S_0 = \\{j \\mid x_j = 0\\}$ 为真实原假设的索引集。令 $E_j$ 表示 $H_{0,j}$ 被错误拒绝的事件，即 $E_j = \\{|t_j| \\ge \\tau\\}$ 对于 $j \\in S_0$。\n$$\\text{FWER} = P\\left(\\bigcup_{j \\in S_0} E_j\\right)$$\n我们应用并集界（也称为布尔不等式），这是邦费罗尼校正的基础：\n$$\\text{FWER} = P\\left(\\bigcup_{j \\in S_0} E_j\\right) \\le \\sum_{j \\in S_0} P(E_j)$$\n由于对所有 $j \\in S_0$ 都有 $P(E_j) = p_j$，并且这个概率与 $j$ 无关，我们有：\n$$\\text{FWER} \\le \\sum_{j \\in S_0} p_j = |S_0| \\cdot 2\\left(1 - \\Phi\\left(\\frac{\\tau}{\\sigma}\\right)\\right)$$\n其中 $|S_0|$ 是真实原假设的数量。\n\n问题要求 FWER 控制对所有稀疏支撑集一致成立。这意味着我们必须对 $x$ 中零元素和非零元素的任何可能配置，为 FWER 提供一个界。为确保保证是一致的，我们必须考虑此界的最坏情况，即当 $|S_0|$ 尽可能大时。$|S_0|$ 的最大可能值为 $n$（当 $x=0$ 时发生）。\n因此，为保证对任何支撑集都有 $\\text{FWER} \\le \\alpha$，我们必须强制执行最坏情况的界：\n$$n \\cdot 2\\left(1 - \\Phi\\left(\\frac{\\tau}{\\sigma}\\right)\\right) \\le \\alpha$$\n我们现在求解阈值 $\\tau$。为了找到满足此不等式的最小 $\\tau$，我们可以将其视为等式：\n$$n \\cdot 2\\left(1 - \\Phi\\left(\\frac{\\tau}{\\sigma}\\right)\\right) = \\alpha$$\n$$\\implies 1 - \\Phi\\left(\\frac{\\tau}{\\sigma}\\right) = \\frac{\\alpha}{2n}$$\n$$\\implies \\Phi\\left(\\frac{\\tau}{\\sigma}\\right) = 1 - \\frac{\\alpha}{2n}$$\n为了解出 $\\tau$，我们应用标准正态 CDF 的逆函数，即分位数函数，记为 $\\Phi^{-1}$：\n$$\\frac{\\tau}{\\sigma} = \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2n}\\right)$$\n最后，解出 $\\tau$ 得到所需的表达式：\n$$\\tau = \\sigma \\cdot \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2n}\\right)$$\n这就是邦费罗尼校准的阈值，它保证 FWER 对稀疏信号 $x$ 的所有可能支撑集一致地至多为 $\\alpha$。",
            "answer": "$$\\boxed{\\sigma \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2n}\\right)}$$"
        },
        {
            "introduction": "在许多现实应用中，我们会收集到与同一底层现象相关的多个数据集。本问题探讨了一个多任务学习场景，展示了如何通过最优地聚合来自不同测量任务的信息来对抗噪声。通过设计一个联合检测策略，您将亲身体会到数据聚合如何显著提高有效信噪比，即使在单个任务噪声很大的情况下也能实现信号恢复。",
            "id": "3462088",
            "problem": "考虑一个多任务稀疏回归设定，其中有 $T$ 个任务和 $p$ 个候选坐标。对于每个任务 $t \\in \\{1,\\dots,T\\}$，观测是一个 $p$ 维向量，建模为一个具有已知单位测量矩阵的线性高斯系统：$y_t = x_t + w_t$，其中 $x_t \\in \\mathbb{R}^p$ 的非零项仅存在于一个跨任务共享但未知的支撑集 $S \\subset \\{1,\\dots,p\\}$ 上，而 $w_t \\in \\mathbb{R}^p$ 是零均值高斯噪声，其协方差矩阵是任务特定的对角矩阵 $\\Sigma_t = \\mathrm{diag}(\\sigma_{t,1}^2,\\dots,\\sigma_{t,p}^2)$。任务特定的噪声分量在任务之间是独立的，支撑集 $S$ 对所有任务都是相同的，但每个任务在 $S$ 上可能具有不同的系数幅值。\n\n从高斯模型统计检测的第一性原理出发，并从线性模型、高斯似然和假设检验的核心定义开始，推导任务聚合的、逐坐标的检测策略，该策略使用适当的白化来组合跨任务的信息。使用此策略定义一个标量的、逐坐标的聚合检测统计量，其零分布是完全确定的，其备择分布取决于一个作为有效信噪比 (SNR) 代理的任务聚合量。基于此，在 $p$ 个坐标上通过 Bonferroni 校正在指定水平 $\\alpha$ 上施加族系误差率控制，并计算每个被支持的坐标 $j \\in S$ 的最终漏检概率，作为聚合量和决策阈值的函数。\n\n将被支持坐标 $j$ 的有效任务聚合信噪比 (SNR) 提升定义为多任务聚合量与该坐标的最佳单任务量之间的比率。对于每个测试用例，报告在所有 $j \\in S$ 中的最小此类提升，并评估共享支撑集 $S$ 是否可以在指定的保证下被恢复，该保证为：在族系误差率被控制在水平 $\\alpha$ 的同时，每个被支持坐标的漏检概率不超过阈值 $\\beta$。\n\n你的程序必须为以下测试套件实现这些计算。所有数组都按坐标 $j=1,\\dots,p$ 的顺序列出。数组中的索引对应于数学描述中的基于 1 的索引 $j$；在代码中，为实现方便，你可以严格使用基于 0 的索引。\n\n测试用例 1 (理想情况，同质噪声和一致振幅)：\n- $T=3$, $p=5$。\n- 共享支撑集 $S = \\{1,3\\}$。\n- $\\alpha = 0.01$, $\\beta = 0.05$。\n- 噪声协方差：$\\Sigma_1 = \\mathrm{diag}(1,1,1,1,1)$, $\\Sigma_2 = \\mathrm{diag}(1,1,1,1,1)$, $\\Sigma_3 = \\mathrm{diag}(1,1,1,1,1)$，即，对于每个 $t \\in \\{1,2,3\\}$，$(\\sigma_{t,1}^2,\\sigma_{t,2}^2,\\sigma_{t,3}^2,\\sigma_{t,4}^2,\\sigma_{t,5}^2) = (1,1,1,1,1)$。\n- 任务振幅：$x_1 = (1.0,0.0,0.8,0.0,0.0)$, $x_2 = (1.0,0.0,0.8,0.0,0.0)$, $x_3 = (1.0,0.0,0.8,0.0,0.0)$。\n\n测试用例 2 (各向异性、任务特定的方差、中等异质性)：\n- $T=4$, $p=6$。\n- 共享支撑集 $S = \\{2,5\\}$。\n- $\\alpha = 0.01$, $\\beta = 0.05$。\n- 噪声协方差：\n  - $\\Sigma_1$ 对应 $(\\sigma_{1,1}^2,\\sigma_{1,2}^2,\\sigma_{1,3}^2,\\sigma_{1,4}^2,\\sigma_{1,5}^2,\\sigma_{1,6}^2) = (1.0,4.0,1.0,1.0,2.0,1.0)$，\n  - $\\Sigma_2$ 对应 $(1.0,2.0,1.0,1.0,1.0,1.0)$，\n  - $\\Sigma_3$ 对应 $(1.0,10.0,1.0,1.0,1.0,1.0)$，\n  - $\\Sigma_4$ 对应 $(1.0,1.0,1.0,1.0,3.0,1.0)$。\n- 任务振幅：对于 $t=1,2,3,4$, $x_t = (0.0,0.5,0.0,0.0,1.0,0.0)$。\n\n测试用例 3 (边界情况，稀疏活动集中在某些任务上，带有零振幅)：\n- $T=5$, $p=5$。\n- 共享支撑集 $S = \\{4\\}$。\n- $\\alpha = 0.05$, $\\beta = 0.20$。\n- 噪声协方差：对于每个 $t \\in \\{1,\\dots,5\\}$，$(\\sigma_{t,1}^2,\\sigma_{t,2}^2,\\sigma_{t,3}^2,\\sigma_{t,4}^2,\\sigma_{t,5}^2) = (1.0,1.0,1.0,1.0,1.0)$。\n- 任务振幅：$x_1 = (0.0,0.0,0.0,0.0,0.0)$, $x_2 = (0.0,0.0,0.0,0.3,0.0)$, $x_3 = (0.0,0.0,0.0,0.0,0.0)$, $x_4 = (0.0,0.0,0.0,0.4,0.0)$, $x_5 = (0.0,0.0,0.0,0.5,0.0)$。\n\n程序要求：\n- 仅使用给定的定义和基本统计原理来推导聚合检测统计量及其在零假设和备择假设下的分布，量化作为有效信噪比 (SNR) 代理的任务聚合量，然后使用适当的分布形式计算漏检概率。\n- 对于每个测试用例，计算：\n  1. 在 $j \\in S$ 上的最小任务聚合信噪比提升因子，定义为多任务聚合量与该坐标的最佳单任务量之比。将此最小提升因子四舍五入到三位小数。\n  2. 一个布尔值，指示共享支撑集 $S$ 是否可在指定保证下被恢复，定义为：当在 $p$ 个坐标上使用在 $\\alpha$ 水平下进行 Bonferroni 控制的决策阈值时，每个 $j \\in S$ 的漏检概率是否小于或等于 $\\beta$。\n- 最终输出格式：\n  你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表。六个条目应按三个测试用例的顺序排列，每个用例贡献上述两个输出，即 $[\\text{gain}_1,\\text{success}_1,\\text{gain}_2,\\text{success}_2,\\text{gain}_3,\\text{success}_3]$，其中每个 $\\text{gain}_k$ 是一个四舍五入到三位小数的浮点数，每个 $\\text{success}_k$ 是一个布尔值。",
            "solution": "该问题要求推导一种用于识别共享稀疏支撑集的多任务检测策略，随后计算特定测试用例的性能指标。推导将从高斯模型中统计检测理论的第一性原理出发。\n\n### 步骤 1：逐坐标假设检验\n对于每个任务 $t \\in \\{1, \\dots, T\\}$ 和坐标 $j \\in \\{1, \\dots, p\\}$，观测模型由 $y_{t,j} = x_{t,j} + w_{t,j}$ 给出，其中 $w_{t,j} \\sim \\mathcal{N}(0, \\sigma_{t,j}^2)$ 是一个零均值高斯噪声分量。噪声分量在任务 $t$ 和坐标 $j$ 之间是独立的。这意味着每个观测值 $y_{t,j}$ 是一个独立的高斯随机变量，其分布为 $y_{t,j} \\sim \\mathcal{N}(x_{t,j}, \\sigma_{t,j}^2)$。\n\n核心问题是为每个坐标 $j$ 确定它是否属于共享支撑集 $S$。这可以为每个坐标 $j$ 构建为一个假设检验：\n- **零假设 ($H_{0,j}$):** 坐标 $j$ 不在支撑集中，即 $j \\notin S$。在此假设下，其在所有任务中的真实振幅均为零：对于所有 $t \\in \\{1, \\dots, T\\}$，$x_{t,j} = 0$。\n- **备择假设 ($H_{1,j}$):** 坐标 $j$ 在支撑集中，即 $j \\in S$。在此假设下，至少存在一个任务 $t$，其振幅 $x_{t,j}$ 非零。\n\n在 $H_{0,j}$ 下，任务 $t$ 中坐标 $j$ 的观测值为 $y_{t,j} \\sim \\mathcal{N}(0, \\sigma_{t,j}^2)$。\n在 $H_{1,j}$ 下，观测值为 $y_{t,j} \\sim \\mathcal{N}(x_{t,j}, \\sigma_{t,j}^2)$。\n\n### 步骤 2：白化与聚合检测统计量的推导\n为了对给定坐标 $j$ 最优地组合来自 $T$ 个任务的信息，我们必须考虑不同的噪声方差 $\\sigma_{t,j}^2$。这通过对观测值进行白化来实现。对于每个任务 $t$ 和坐标 $j$，我们将白化后的观测值 $z_{t,j}$ 定义为：\n$$\nz_{t,j} = \\frac{y_{t,j}}{\\sigma_{t,j}}\n$$\n$z_{t,j}$ 的分布取决于假设：\n- 在 $H_{0,j}$ 下：$z_{t,j} = \\frac{w_{t,j}}{\\sigma_{t,j}} \\sim \\mathcal{N}(0, 1)$，一个标准正态分布。\n- 在 $H_{1,j}$ 下：$z_{t,j} = \\frac{x_{t,j} + w_{t,j}}{\\sigma_{t,j}} \\sim \\mathcal{N}\\left(\\frac{x_{t,j}}{\\sigma_{t,j}}, 1\\right)$。\n\n在 $H_{0,j}$ 下，对于坐标 $j$，我们有 $T$ 个独立的标准正态观测值 $\\{z_{t,j}\\}_{t=1}^T$。一个用于检测非零均值的强大统计量是它们的平方和。我们将坐标 $j$ 的聚合检测统计量 $L_j$ 定义为：\n$$\nL_j = \\sum_{t=1}^{T} z_{t,j}^2 = \\sum_{t=1}^{T} \\left(\\frac{y_{t,j}}{\\sigma_{t,j}}\\right)^2\n$$\n\n### 步骤 3：聚合统计量的分布\n$L_j$ 的分布由其所基于的假设确定。\n- **在零假设 ($H_{0,j}$) 下：** 由于每个 $z_{t,j}$ 是一个独立的标准正态随机变量，$L_j$ 是 $T$ 个独立标准正态变量的平方和。根据定义，$L_j$ 服从自由度为 $T$ 的中心卡方分布：\n$$\nL_j | H_{0,j} \\sim \\chi^2_T\n$$\n这提供了一个完全确定的、不依赖于任何未知参数的零分布。\n\n- **在备择假设 ($H_{1,j}$) 下：** 每个 $z_{t,j}$ 是一个独立的、均值为 $\\mu_{t,j} = x_{t,j}/\\sigma_{t,j}$ 且方差为 1 的正态随机变量。这些变量的平方和 $L_j$ 服从自由度为 $T$、非中心化参数为 $\\lambda_j$ 的非中心卡方分布。非中心化参数是均值的平方和：\n$$\n\\lambda_j = \\sum_{t=1}^{T} \\mu_{t,j}^2 = \\sum_{t=1}^{T} \\left(\\frac{x_{t,j}}{\\sigma_{t,j}}\\right)^2\n$$\n因此，在备择假设下 $L_j$ 的分布为：\n$$\nL_j | H_{1,j} \\sim \\chi^2_T(\\lambda_j)\n$$\n量 $\\lambda_j$ 表示坐标 $j$ 在所有 $T$ 个任务上聚合的总平方信噪比。它可作为问题描述中提到的有效信噪比代理。\n\n### 步骤 4：带有族系误差率控制的决策规则\n我们对每个坐标执行一次假设检验，共计 $p$ 次。为了将族系误差率 (FWER) 控制在水平 $\\alpha$，我们使用 Bonferroni 校正。这要求每个单独的检验都在一个更严格的显著性水平 $\\alpha' = \\alpha/p$ 下进行。\n\n对于每个坐标 $j$，如果观测到的统计量 $L_j$ 异常大，我们就拒绝零假设 $H_{0,j}$。决策规则是：\n- 如果 $L_j  \\tau$，则判断 $j \\in S$。\n- 如果 $L_j \\leq \\tau$，则判断 $j \\notin S$。\n\n选择阈值 $\\tau$ 以确保 I 型错误（错误地判断 $j \\in S$）的概率为 $\\alpha'$：\n$$\nP(L_j  \\tau | H_{0,j}) = \\alpha' = \\frac{\\alpha}{p}\n$$\n由于 $L_j | H_{0,j} \\sim \\chi^2_T$，阈值 $\\tau$ 是自由度为 $T$ 的中心卡方分布的 $(1-\\alpha')$ 分位数。设 $F_{\\chi^2_T}$ 为此分布的累积分布函数 (CDF)。那么：\n$$\n\\tau = F_{\\chi^2_T}^{-1}\\left(1 - \\frac{\\alpha}{p}\\right)\n$$\n\n### 步骤 5：性能指标的计算\n**漏检概率：** 对于一个确实在支撑集中的坐标 $j \\in S$，如果我们未能拒绝 $H_{0,j}$，即 $L_j \\le \\tau$，则发生漏检（II 型错误）。此事件的概率 $\\beta_j$ 取决于 $L_j$ 在 $H_{1,j}$ 下的分布：\n$$\n\\beta_j = P(L_j \\le \\tau | H_{1,j})\n$$\n使用非中心卡方分布，可得：\n$$\n\\beta_j = F_{\\chi^2_T(\\lambda_j)}(\\tau)\n$$\n其中 $F_{\\chi^2_T(\\lambda_j)}$ 是自由度为 $T$、非中心化参数为 $\\lambda_j$ 的非中心卡方分布的累积分布函数。\n\n**任务聚合信噪比提升：** 问题将一个被支持的坐标 $j \\in S$ 的提升因子定义为多任务聚合量 ($\\lambda_j$) 与最佳单任务量之比。任务 $t$ 的单任务量为 $(x_{t,j}/\\sigma_{t,j})^2$。因此，提升因子 Gain$_j$ 为：\n$$\n\\text{Gain}_j = \\frac{\\lambda_j}{\\max_{t \\in \\{1,\\dots,T\\}} \\left\\{ \\left( \\frac{x_{t,j}}{\\sigma_{t,j}} \\right)^2 \\right\\}} = \\frac{\\sum_{t=1}^{T} (x_{t,j}/\\sigma_{t,j})^2}{\\max_{t} \\left\\{ (x_{t,j}/\\sigma_{t,j})^2 \\right\\}}\n$$\n问题要求计算在支撑集中所有坐标上的最小此类提升，即 $\\min_{j \\in S} \\{\\text{Gain}_j\\}$。\n\n**可恢复性：** 如果对于每个被支持的坐标 $j \\in S$，其漏检概率都不超过给定的阈值 $\\beta$，则认为支撑集 $S$ 在指定的保证下是可恢复的。即，条件为对于所有 $j \\in S$，都有 $\\beta_j \\le \\beta$。\n\n### 每个测试用例的计算步骤总结：\n1.  确定参数 $T$、$p$、$S$、$\\alpha$ 和 $\\beta$。\n2.  计算经 Bonferroni 校正的显著性水平 $\\alpha' = \\alpha/p$。\n3.  确定决策阈值 $\\tau = F_{\\chi^2_T}^{-1}(1-\\alpha')$。\n4.  对于每个坐标 $j \\in S$：\n    a. 计算非中心化参数 $\\lambda_j = \\sum_{t=1}^{T} (x_{t,j}/\\sigma_{t,j})^2$。\n    b. 计算最佳单任务量 $\\max_{t} \\{(x_{t,j}/\\sigma_{t,j})^2\\}$。\n    c. 计算信噪比提升因子 Gain$_j$。\n    d. 计算漏检概率 $\\beta_j = F_{\\chi^2_T(\\lambda_j)}(\\tau)$。\n5.  确定最小信噪比提升因子 $\\min_{j \\in S} \\{\\text{Gain}_j\\}$。\n6.  检查是否对所有 $j \\in S$ 都满足 $\\beta_j \\le \\beta$，以确定可恢复性。\n\n这些步骤将为每个给定的测试用例实现。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2, ncx2\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It orchestrates the calculation for each case and prints the final results.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"T\": 3, \"p\": 5, \"S\": [1, 3], \"alpha\": 0.01, \"beta\": 0.05,\n            \"sigma2_tasks\": [\n                [1.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0]\n            ],\n            \"x_tasks\": [\n                [1.0, 0.0, 0.8, 0.0, 0.0],\n                [1.0, 0.0, 0.8, 0.0, 0.0],\n                [1.0, 0.0, 0.8, 0.0, 0.0]\n            ]\n        },\n        # Test Case 2\n        {\n            \"T\": 4, \"p\": 6, \"S\": [2, 5], \"alpha\": 0.01, \"beta\": 0.05,\n            \"sigma2_tasks\": [\n                [1.0, 4.0, 1.0, 1.0, 2.0, 1.0],\n                [1.0, 2.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 10.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 3.0, 1.0]\n            ],\n            \"x_tasks\": [\n                [0.0, 0.5, 0.0, 0.0, 1.0, 0.0],\n                [0.0, 0.5, 0.0, 0.0, 1.0, 0.0],\n                [0.0, 0.5, 0.0, 0.0, 1.0, 0.0],\n                [0.0, 0.5, 0.0, 0.0, 1.0, 0.0]\n            ]\n        },\n        # Test Case 3\n        {\n            \"T\": 5, \"p\": 5, \"S\": [4], \"alpha\": 0.05, \"beta\": 0.20,\n            \"sigma2_tasks\": [\n                [1.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0]\n            ],\n            \"x_tasks\": [\n                [0.0, 0.0, 0.0, 0.0, 0.0],\n                [0.0, 0.0, 0.0, 0.3, 0.0],\n                [0.0, 0.0, 0.0, 0.0, 0.0],\n                [0.0, 0.0, 0.0, 0.4, 0.0],\n                [0.0, 0.0, 0.0, 0.5, 0.0]\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        gain, success = analyze_case(\n            case[\"T\"], case[\"p\"], case[\"S\"], case[\"alpha\"], case[\"beta\"],\n            np.array(case[\"sigma2_tasks\"]), np.array(case[\"x_tasks\"])\n        )\n        results.extend([f\"{gain:.3f}\", str(success)])\n    \n    # Format the final output string\n    final_output_string = \"[\" + \",\".join(results) + \"]\"\n    print(final_output_string.replace(\"'\",\"\")) # Ensure True/False, not 'True'/'False'\n\n\ndef analyze_case(T, p, S, alpha, beta, sigma2_tasks, x_tasks):\n    \"\"\"\n    Analyzes a single test case based on the derived statistical model.\n    \"\"\"\n    # Convert 1-based support set to 0-based indices for array access\n    S_zero_based = [s - 1 for s in S]\n\n    # Calculate the per-test significance level using Bonferroni correction\n    alpha_prime = alpha / p\n    \n    # The degrees of freedom for the chi-squared distribution is the number of tasks T\n    df = T\n    \n    # Calculate the decision threshold tau from the central chi-squared distribution\n    # This is the (1 - alpha_prime) quantile\n    tau = chi2.ppf(1 - alpha_prime, df)\n\n    gains = []\n    miss_detection_probs = []\n\n    # Iterate over each coordinate j in the true support set S\n    for j in S_zero_based:\n        \n        # Extract signal amplitudes and noise variances for coordinate j across all tasks\n        x_j_all_tasks = x_tasks[:, j]\n        sigma2_j_all_tasks = sigma2_tasks[:, j]\n        \n        # Calculate single-task quantities (squared SNR for each task)\n        # Handle division by zero, though problem data has positive variances\n        single_task_quantities = np.divide(x_j_all_tasks**2, sigma2_j_all_tasks, \n                                           out=np.zeros_like(x_j_all_tasks, dtype=float), \n                                           where=sigma2_j_all_tasks!=0)\n        \n        # Calculate the non-centrality parameter lambda_j (aggregated SNR proxy)\n        lambda_j = np.sum(single_task_quantities)\n        \n        # Find the best single-task quantity\n        best_single_task_quantity = np.max(single_task_quantities)\n        \n        # Calculate the SNR improvement factor (gain)\n        # If the best single-task quantity is 0, it means all x_{t,j} are 0.\n        # This shouldn't happen for j in S, so gain is well-defined.\n        if best_single_task_quantity > 1e-9: # Use a tolerance for floating point\n            gain_j = lambda_j / best_single_task_quantity\n        else:\n            # This case implies x_{t,j}=0 for all t, contradicting j in S.\n            # If it were to happen, the concept of \"improvement\" is ill-defined.\n            # We can set gain to 1.0, as multi-tasking offers no improvement over nothing.\n            gain_j = 1.0\n        gains.append(gain_j)\n        \n        # Calculate the miss-detection probability beta_j\n        # This is the CDF of the non-central chi-squared distribution at the threshold tau\n        beta_j = ncx2.cdf(tau, df, lambda_j)\n        miss_detection_probs.append(beta_j)\n\n    # The required gain is the minimum gain over all coordinates in S\n    min_gain = min(gains)\n\n    # Check for recoverability: all miss-detection probabilities must be = beta\n    is_recoverable = all(prob = beta for prob in miss_detection_probs)\n    \n    return min_gain, is_recoverable\n\n# Run the solver\n# solve()\n```"
        }
    ]
}