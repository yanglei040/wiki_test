{
    "hands_on_practices": [
        {
            "introduction": "Before we can analyze the more complex properties of a random partial Fourier matrix, we must first verify its most basic structural feature. This exercise  confirms that the matrix is properly scaled by computing the norm of its columns, showing they are all of unit length. This normalization is a crucial prerequisite for the Restricted Isometry Property, as it ensures that the energy of any single-element signal is perfectly preserved.",
            "id": "3474316",
            "problem": "Let $N \\in \\mathbb{N}$ and let $F \\in \\mathbb{C}^{N \\times N}$ be the unitary Discrete Fourier Transform (DFT) matrix with entries $F_{\\ell,j} = \\frac{1}{\\sqrt{N}}\\exp\\!\\left(-2\\pi i \\frac{\\ell j}{N}\\right)$ for $\\ell,j \\in \\{0,1,\\dots,N-1\\}$. Let $\\Omega \\subset \\{0,1,\\dots,N-1\\}$ be an index set of size $m$ chosen without replacement, and let $R \\in \\{0,1\\}^{m \\times N}$ denote the row-selection operator that extracts the rows of a vector in $\\mathbb{C}^{N}$ corresponding to indices in $\\Omega$. Define the random partial Fourier sampling matrix $A \\in \\mathbb{C}^{m \\times N}$ by $A = \\sqrt{\\frac{N}{m}}\\,R F^{*}$, where $F^{*}$ denotes the conjugate transpose of $F$. In the context of verifying column normalization as a prerequisite for the Restricted Isometry Property (RIP), compute the exact value of the squared $\\ell_{2}$-norm of the $j$-th column of $A$, namely $\\,\\|A e_{j}\\|_{2}^{2}\\,$, where $e_{j} \\in \\mathbb{C}^{N}$ is the $j$-th canonical basis vector. Your answer must be provided as a single closed-form real number. No rounding is required.",
            "solution": "The user wants to compute the squared $\\ell_2$-norm of the $j$-th column of the matrix $A$. The $j$-th column of any matrix $A$ can be obtained by multiplying $A$ by the $j$-th canonical basis vector, $e_j$. Thus, the quantity to be computed is $\\|A e_j\\|_{2}^{2}$.\n\nThe matrix $A$ is defined as $A = \\sqrt{\\frac{N}{m}}\\,R F^{*}$, where $F^{*}$ is the conjugate transpose of the unitary Discrete Fourier Transform (DFT) matrix $F$, and $R$ is a row-selection operator.\n\nWe begin by substituting the definition of $A$ into the expression for the squared norm:\n$$\n\\|A e_{j}\\|_{2}^{2} = \\left\\| \\sqrt{\\frac{N}{m}} R F^{*} e_j \\right\\|_{2}^{2}\n$$\nThe scalar factor $\\sqrt{\\frac{N}{m}}$ can be moved outside the norm. For any scalar $c \\in \\mathbb{C}$ and vector $v$, the property $\\|c v\\|_{2}^{2} = |c|^2 \\|v\\|_{2}^{2}$ holds. Since $\\frac{N}{m}$ is a positive real number, we have:\n$$\n\\|A e_{j}\\|_{2}^{2} = \\left(\\sqrt{\\frac{N}{m}}\\right)^2 \\|R F^{*} e_j\\|_{2}^{2} = \\frac{N}{m} \\|R F^{*} e_j\\|_{2}^{2}\n$$\nNext, we analyze the vector $F^{*} e_j$. This product represents the $j$-th column of the matrix $F^{*}$. The matrix $F$ is defined with entries $F_{\\ell,k} = \\frac{1}{\\sqrt{N}}\\exp\\left(-2\\pi i \\frac{\\ell k}{N}\\right)$. The entries of its conjugate transpose, $F^{*}$, are given by $(F^{*})_{\\ell,k} = \\overline{F_{k,\\ell}}$.\n$$\n(F^{*})_{\\ell,k} = \\overline{\\left(\\frac{1}{\\sqrt{N}}\\exp\\left(-2\\pi i \\frac{k\\ell}{N}\\right)\\right)} = \\frac{1}{\\sqrt{N}}\\exp\\left(2\\pi i \\frac{k\\ell}{N}\\right)\n$$\nThe vector $F^{*} e_j$ is a column vector in $\\mathbb{C}^{N}$. Its $\\ell$-th entry, for $\\ell \\in \\{0, 1, \\dots, N-1\\}$, is given by the entry in the $\\ell$-th row and $j$-th column of $F^{*}$:\n$$\n(F^{*} e_j)_{\\ell} = (F^{*})_{\\ell,j} = \\frac{1}{\\sqrt{N}}\\exp\\left(2\\pi i \\frac{\\ell j}{N}\\right)\n$$\nThe operator $R$ is a row-selection operator that extracts the rows corresponding to the index set $\\Omega \\subset \\{0, 1, \\dots, N-1\\}$, where $|\\Omega| = m$. When $R$ acts on the vector $F^{*} e_j$, it produces a new vector in $\\mathbb{C}^m$ whose entries are the entries of $F^{*} e_j$ at the indices specified by $\\Omega$.\n\nThe squared $\\ell_2$-norm of the resulting vector, $\\|R F^{*} e_j\\|_{2}^{2}$, is the sum of the squared magnitudes of its entries. The entries of $R F^{*} e_j$ are precisely $(F^{*} e_j)_{\\ell}$ for all $\\ell \\in \\Omega$.\n$$\n\\|R F^{*} e_j\\|_{2}^{2} = \\sum_{\\ell \\in \\Omega} \\left| (F^{*} e_j)_{\\ell} \\right|^2 = \\sum_{\\ell \\in \\Omega} \\left| \\frac{1}{\\sqrt{N}}\\exp\\left(2\\pi i \\frac{\\ell j}{N}\\right) \\right|^2\n$$\nLet's simplify the term inside the summation. For any complex number of the form $c \\cdot z$ where $c$ is real, $|c \\cdot z|^2 = c^2 |z|^2$. Also, for any real number $\\theta$, the complex exponential $\\exp(i\\theta)$ has a magnitude of $1$, since $|\\exp(i\\theta)| = |\\cos(\\theta) + i\\sin(\\theta)| = \\sqrt{\\cos^2(\\theta)+\\sin^2(\\theta)} = 1$.\n$$\n\\left| \\frac{1}{\\sqrt{N}}\\exp\\left(2\\pi i \\frac{\\ell j}{N}\\right) \\right|^2 = \\left(\\frac{1}{\\sqrt{N}}\\right)^2 \\left| \\exp\\left(2\\pi i \\frac{\\ell j}{N}\\right) \\right|^2 = \\frac{1}{N} \\cdot 1^2 = \\frac{1}{N}\n$$\nThe term being summed is a constant value $\\frac{1}{N}$, independent of the summation index $\\ell$. The summation is over the set $\\Omega$, which has $m$ elements. Therefore, the sum is the product of the number of elements and the constant value:\n$$\n\\|R F^{*} e_j\\|_{2}^{2} = \\sum_{\\ell \\in \\Omega} \\frac{1}{N} = m \\cdot \\frac{1}{N} = \\frac{m}{N}\n$$\nFinally, we substitute this result back into our first expression for $\\|A e_{j}\\|_{2}^{2}$:\n$$\n\\|A e_{j}\\|_{2}^{2} = \\frac{N}{m} \\|R F^{*} e_j\\|_{2}^{2} = \\frac{N}{m} \\cdot \\frac{m}{N} = 1\n$$\nThe squared $\\ell_2$-norm of the $j$-th column of $A$ is exactly $1$. This result is independent of the column index $j$ and the specific choice of the row-selection set $\\Omega$, as long as $|\\Omega|=m$. The scaling factor $\\sqrt{\\frac{N}{m}}$ is specifically chosen to ensure this unit-norm property, which is a fundamental requirement for such matrices in compressed sensing applications.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "The \"random\" in \"random partial Fourier matrix\" is not an incidental detail; it is a core ingredient for success. To appreciate why, this practice  challenges you to analyze a deterministic sampling pattern, where Fourier frequencies are chosen in a periodic arithmetic progression. You will discover how this structure creates aliasing artifacts, which can be exploited to construct a sparse signal that is completely annihilated by the measurement process, leading to a catastrophic failure of the RIP with $\\delta_2 = 1$.",
            "id": "3474263",
            "problem": "Let $N \\in \\mathbb{N}$ and $q \\in \\mathbb{N}$ satisfy $q \\geq 2$ and $q \\mid N$. Write $N = m q$ with $m \\in \\mathbb{N}$. Let $F_{N} \\in \\mathbb{C}^{N \\times N}$ denote the unitary discrete Fourier transform matrix with entries\n$$\n(F_{N})_{k,n} \\;=\\; \\frac{1}{\\sqrt{N}} \\exp\\!\\left(-2\\pi i \\frac{k n}{N}\\right), \\quad 0 \\leq k,n \\leq N-1.\n$$\nFix an index $k_{0} \\in \\{0,1,\\dots,N-1\\}$ and define the deterministic arithmetic progression sampling set\n$$\n\\Omega \\;=\\; \\{\\, k_{0} + \\ell q \\ \\bmod N \\;:\\; \\ell = 0,1,\\dots,m-1 \\,\\}.\n$$\nForm the sensing matrix\n$$\nA \\;=\\; \\sqrt{\\frac{N}{m}} \\, R_{\\Omega} F_{N} \\;\\in\\; \\mathbb{C}^{m \\times N},\n$$\nwhere $R_{\\Omega}$ restricts to the rows indexed by $\\Omega$. The scaling $\\sqrt{N/m}$ ensures that every column of $A$ has unit Euclidean norm.\n\nRecall the definition of the order-$s$ restricted isometry constant $\\delta_{s}(A)$ as the smallest nonnegative number $\\delta$ for which, for all $s$-sparse vectors $x \\in \\mathbb{C}^{N}$,\n$$\n(1-\\delta)\\,\\|x\\|_{2}^{2} \\;\\leq\\; \\|A x\\|_{2}^{2} \\;\\leq\\; (1+\\delta)\\,\\|x\\|_{2}^{2}.\n$$\n\nStarting only from the orthogonality of complex exponentials and the definition of the discrete Fourier transform, do the following:\n\n1. Derive the aliasing identity that expresses the measurement vector $y = A x$ as a length-$m$ discrete Fourier transform of $m$ complex numbers, each given by a sum over a residue class modulo $m$ of a modulated version of $x$. Concretely, show that if one writes $n = r + t m$ with $0 \\leq r \\leq m-1$ and $0 \\leq t \\leq q-1$, then the $\\ell$-th measurement can be written in terms of $\\sum_{t=0}^{q-1} x_{r + t m} \\exp\\!\\left(-2\\pi i \\frac{k_{0}(r + t m)}{N}\\right)$.\n\n2. Using this structure, explicitly construct a nonzero $2$-sparse vector $x^{\\star}$ (specifying both its support and its nonzero entries) such that $A x^{\\star} = 0$. Your construction must exploit that $\\Omega$ skips rows in steps of $q$ and that $q \\mid N$.\n\n3. From first principles, use your construction to determine the exact value of the order-$2$ restricted isometry constant $\\delta_{2}(A)$ as a function of $q$. Justify both the lower and upper requirements implicit in the definition of $\\delta_{2}(A)$ by analyzing the $2 \\times 2$ Gram matrices formed by pairs of columns of $A$ that are aligned with your construction.\n\nGive your final answer for $\\delta_{2}(A)$ as a single exact number. No rounding is required and no units are involved.",
            "solution": "### Part 1: Derivation of the Aliasing Identity\n\nLet $y = Ax \\in \\mathbb{C}^{m}$ be the measurement vector for a signal $x \\in \\mathbb{C}^{N}$. The rows of the matrix $A$ are indexed by $\\ell \\in \\{0, 1, \\dots, m-1\\}$, corresponding to the frequencies $k_{\\ell} = k_{0} + \\ell q \\pmod N$ in $\\Omega$. The entries of $A$ are given by\n$$\nA_{\\ell,n} = \\sqrt{\\frac{N}{m}} (F_{N})_{k_{\\ell},n} = \\sqrt{\\frac{N}{m}} \\frac{1}{\\sqrt{N}} \\exp\\left(-2\\pi i \\frac{k_{\\ell} n}{N}\\right) = \\frac{1}{\\sqrt{m}} \\exp\\left(-2\\pi i \\frac{(k_{0} + \\ell q) n}{N}\\right).\n$$\nThe $\\ell$-th component of the measurement vector $y$ is\n$$\ny_{\\ell} = (Ax)_{\\ell} = \\sum_{n=0}^{N-1} A_{\\ell,n} x_{n} = \\frac{1}{\\sqrt{m}} \\sum_{n=0}^{N-1} x_{n} \\exp\\left(-2\\pi i \\frac{(k_{0} + \\ell q) n}{N}\\right).\n$$\nWe use the suggested decomposition of the index $n$ as $n = r + tm$, where $r \\in \\{0, 1, \\dots, m-1\\}$ is the residue modulo $m$, and $t \\in \\{0, 1, \\dots, q-1\\}$. This allows us to rewrite the single sum over $n$ as a double sum over $r$ and $t$:\n$$\ny_{\\ell} = \\frac{1}{\\sqrt{m}} \\sum_{r=0}^{m-1} \\sum_{t=0}^{q-1} x_{r+tm} \\exp\\left(-2\\pi i \\frac{(k_{0} + \\ell q) (r+tm)}{N}\\right).\n$$\nWe can split the exponential term:\n$$\n\\exp\\left(-2\\pi i \\frac{(k_{0} + \\ell q) (r+tm)}{N}\\right) = \\exp\\left(-2\\pi i \\frac{k_{0}(r+tm)}{N}\\right) \\exp\\left(-2\\pi i \\frac{\\ell q (r+tm)}{N}\\right).\n$$\nLet's analyze the second factor. Using $N=mq$:\n$$\n\\exp\\left(-2\\pi i \\frac{\\ell q (r+tm)}{N}\\right) = \\exp\\left(-2\\pi i \\frac{\\ell q r + \\ell q t m}{mq}\\right) = \\exp\\left(-2\\pi i \\left(\\frac{\\ell r}{m} + \\ell t\\right)\\right).\n$$\nSince $\\ell$ and $t$ are integers, $\\exp(-2\\pi i \\ell t) = 1$. The expression simplifies to:\n$$\n\\exp\\left(-2\\pi i \\frac{\\ell r}{m}\\right).\n$$\nThis term notably does not depend on the inner summation index $t$. Substituting this back, we can rearrange the summation:\n$$\ny_{\\ell} = \\frac{1}{\\sqrt{m}} \\sum_{r=0}^{m-1} \\left( \\sum_{t=0}^{q-1} x_{r+tm} \\exp\\left(-2\\pi i \\frac{k_{0}(r+tm)}{N}\\right) \\right) \\exp\\left(-2\\pi i \\frac{\\ell r}{m}\\right).\n$$\nThis is the desired aliasing identity. If we define a vector $z \\in \\mathbb{C}^m$ with components\n$$\nz_{r} = \\sum_{t=0}^{q-1} x_{r+tm} \\exp\\left(-2\\pi i \\frac{k_{0}(r+tm)}{N}\\right),\n$$\nfor $r = 0, 1, \\dots, m-1$, then the measurement vector components $y_{\\ell}$ are\n$$\ny_{\\ell} = \\frac{1}{\\sqrt{m}} \\sum_{r=0}^{m-1} z_{r} \\exp\\left(-2\\pi i \\frac{\\ell r}{m}\\right).\n$$\nThis shows that $y$ is the (scaled) length-$m$ discrete Fourier transform of the aliased and modulated vector $z$.\n\n### Part 2: Construction of a 2-Sparse Vector in the Nullspace\n\nWe seek a non-zero $2$-sparse vector $x^{\\star} \\in \\mathbb{C}^{N}$ such that $Ax^{\\star} = 0$. From the identity in Part 1, we see that if the aliased vector $z$ is the zero vector, then its DFT $y$ will also be the zero vector. Thus, we need to construct a $2$-sparse $x^{\\star}$ such that $z_{r}=0$ for all $r \\in \\{0, 1, \\dots, m-1\\}$.\nThe formula for $z_r$ involves a sum over indices $\\{r, r+m, \\dots, r+(q-1)m\\}$, which form a residue class modulo $m$. For $x^{\\star}$ to be $2$-sparse, its two non-zero entries must belong to the same residue class modulo $m$. If they belonged to different classes, say $n_1 \\in \\{r_1 + tm\\}$ and $n_2 \\in \\{r_2 + tm\\}$ with $r_1 \\ne r_2$, then $z_{r_1}$ would contain only one non-zero term, forcing $x_{n_1}^{\\star}=0$, a contradiction.\n\nLet's fix a residue class by choosing $r_0 \\in \\{0, \\dots, m-1\\}$. Let the support of $x^{\\star}$ be $\\{n_1, n_2\\}$, where $n_1 = r_0 + t_1 m$ and $n_2 = r_0 + t_2 m$ for distinct $t_1, t_2 \\in \\{0, \\dots, q-1\\}$.This is possible since $q \\geq 2$. For any $r \\ne r_0$, $z_r=0$ automatically because no indices in that sum are in the support of $x^\\star$. We only need to ensure $z_{r_0}=0$:\n$$\nz_{r_0} = x^{\\star}_{n_1} \\exp\\left(-2\\pi i \\frac{k_{0}n_1}{N}\\right) + x^{\\star}_{n_2} \\exp\\left(-2\\pi i \\frac{k_{0}n_2}{N}\\right) = 0.\n$$\nTo construct a specific example, let's choose $r_0=0$. Let the support be $S=\\{0, m\\}$ (so $t_1=0$, $t_2=1$). Let $x^{\\star}_0 = c_1$ and $x^{\\star}_m = c_2$. The condition becomes:\n$$\nc_1 \\exp\\left(-2\\pi i \\frac{k_{0} \\cdot 0}{N}\\right) + c_2 \\exp\\left(-2\\pi i \\frac{k_{0} m}{N}\\right) = 0.\n$$\n$$\nc_1 + c_2 \\exp\\left(-2\\pi i \\frac{k_{0} m}{mq}\\right) = 0 \\implies c_1 + c_2 \\exp\\left(-2\\pi i \\frac{k_{0}}{q}\\right) = 0.\n$$\nWe can choose $c_1=1$. This gives $c_2 = -\\exp\\left(2\\pi i \\frac{k_0}{q}\\right)$.\nThus, we define the vector $x^{\\star} \\in \\mathbb{C}^{N}$ as:\n$$\nx^{\\star}_{n} = \\begin{cases} 1  \\text{if } n=0 \\\\ -\\exp(2\\pi i k_{0}/q)  \\text{if } n=m \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nThis vector $x^{\\star}$ is non-zero, $2$-sparse, and by construction satisfies $Ax^{\\star}=0$.\n\n### Part 3: Determination of $\\delta_2(A)$\n\nThe restricted isometry constant $\\delta_s(A)$ is the smallest non-negative $\\delta$ such that for all $s$-sparse vectors $x$,\n$$\n(1-\\delta)\\|x\\|_{2}^{2} \\leq \\|Ax\\|_{2}^{2} \\leq (1+\\delta)\\|x\\|_{2}^{2}.\n$$\nLet's use the vector $x^{\\star}$ constructed in Part 2. Its squared Euclidean norm is\n$$\n\\|x^{\\star}\\|_{2}^{2} = |x^{\\star}_0|^2 + |x^{\\star}_m|^2 = |1|^2 + |-\\exp(2\\pi i k_0/q)|^2 = 1 + 1 = 2.\n$$\nSince $Ax^{\\star}=0$, we have $\\|Ax^{\\star}\\|_{2}^{2}=0$. Plugging this into the left side of the RIP inequality for $s=2$:\n$$\n(1-\\delta_2) \\|x^{\\star}\\|_{2}^{2} \\le \\|Ax^{\\star}\\|_{2}^{2} \\implies (1-\\delta_2) \\cdot 2 \\le 0 \\implies 1-\\delta_2 \\le 0.\n$$\nThis establishes the lower bound $\\delta_2(A) \\ge 1$.\n\nTo determine the exact value, we analyze the Gram matrix $G_S = A_S^*A_S$ for any support set $S=\\{n_1, n_2\\}$ of size $2$. The entries of $G_S$ are inner products of the columns of $A$. Since the columns $a_n$ of $A$ are normalized to unit norm, the Gram matrix is\n$$\nG_S = \\begin{pmatrix} 1  \\langle a_{n_2}, a_{n_1} \\rangle \\\\ \\langle a_{n_1}, a_{n_2} \\rangle  1 \\end{pmatrix}.\n$$\nThe eigenvalues of $G_S$ are $\\lambda = 1 \\pm |\\langle a_{n_1}, a_{n_2} \\rangle|$. The RIP condition requires that for all $S$ of size $2$, these eigenvalues lie in $[1-\\delta_2, 1+\\delta_2]$. This is equivalent to $\\delta_2(A) = \\max_{n_1 \\ne n_2} |\\langle a_{n_1}, a_{n_2} \\rangle|$, which is the coherence of the matrix $A$.\n\nLet's compute the inner product for arbitrary columns $a_{n_1}, a_{n_2}$:\n$$\n\\langle a_{n_1}, a_{n_2} \\rangle = \\sum_{\\ell=0}^{m-1} \\overline{(a_{n_2})_\\ell} (a_{n_1})_\\ell = \\sum_{\\ell=0}^{m-1} \\left(\\frac{1}{\\sqrt{m}} \\exp\\left(2\\pi i \\frac{(k_0+\\ell q)n_2}{N}\\right)\\right) \\left(\\frac{1}{\\sqrt{m}} \\exp\\left(-2\\pi i \\frac{(k_0+\\ell q)n_1}{N}\\right)\\right)\n$$\n$$\n= \\frac{1}{m} \\sum_{\\ell=0}^{m-1} \\exp\\left(2\\pi i \\frac{(k_0+\\ell q)(n_2-n_1)}{N}\\right) = \\frac{1}{m} \\exp\\left(2\\pi i \\frac{k_0(n_2-n_1)}{N}\\right) \\sum_{\\ell=0}^{m-1} \\left(\\exp\\left(2\\pi i \\frac{q(n_2-n_1)}{N}\\right)\\right)^\\ell.\n$$\nUsing $N=mq$, the term in the sum becomes $\\exp\\left(2\\pi i \\frac{n_2-n_1}{m}\\right)$. The sum is a geometric series of $m$ terms. Based on the orthogonality of complex exponentials, this sum evaluates to $m$ if $\\frac{n_2-n_1}{m}$ is an integer, and to $0$ otherwise.\nSo, if $n_2-n_1$ is a non-zero multiple of $m$:\n$$\n|\\langle a_{n_1}, a_{n_2} \\rangle| = \\left|\\frac{1}{m} \\exp\\left(2\\pi i \\frac{k_0(n_2-n_1)}{N}\\right) \\cdot m\\right| = 1.\n$$\nIf $n_2-n_1$ is not a multiple of $m$, then $\\langle a_{n_1}, a_{n_2} \\rangle = 0$.\n\nThe pairs of columns \"aligned with our construction\" are those whose indices $n_1, n_2$ are in the same residue class modulo $m$, i.e., $n_2-n_1$ is a multiple of $m$. For any such pair (e.g., $\\{0, m\\}$), we have $|\\langle a_{n_1}, a_{n_2} \\rangle| = 1$. The eigenvalues of the corresponding $2 \\times 2$ Gram matrix are $1 \\pm 1$, which are $0$ and $2$.\nFor the RIP definition to hold, the interval $[1-\\delta_2, 1+\\delta_2]$ must contain the eigenvalues of all $2 \\times 2$ Gram matrices. In particular, it must contain $\\{0, 2\\}$.\nThe condition $0 \\in [1-\\delta_2, 1+\\delta_2]$ implies $1-\\delta_2 \\le 0$, so $\\delta_2 \\ge 1$.\nThe condition $2 \\in [1-\\delta_2, 1+\\delta_2]$ implies $2 \\le 1+\\delta_2$, so $\\delta_2 \\ge 1$.\nBoth requirements lead to the conclusion that necessarily $\\delta_2(A) \\ge 1$.\n\nNow, we must show this is sufficient. We test if $\\delta_2 = 1$ works. This choice means we must verify that for any $2$-sparse $x$, $\\|Ax\\|_2^2 \\le (1+1)\\|x\\|_2^2 = 2\\|x\\|_2^2$ and $\\|Ax\\|_2^2 \\ge (1-1)\\|x\\|_2^2=0$. The latter is always true. The former is equivalent to requiring that the largest eigenvalue of any $2 \\times 2$ Gram matrix $A_S^*A_S$ is at most $2$.\nThe eigenvalues are $1 \\pm |\\langle a_{n_1}, a_{n_2} \\rangle|$. By the Cauchy-Schwarz inequality, and since columns are unit norm, $|\\langle a_{n_1}, a_{n_2} \\rangle| \\le \\|a_{n_1}\\|_2 \\|a_{n_2}\\|_2 = 1$.\nTherefore, the largest eigenvalue is $1 + |\\langle a_{n_1}, a_{n_2} \\rangle| \\le 1+1=2$. This holds for any pair of columns.\nSo, $\\delta_2=1$ is a sufficient value.\nSince $\\delta_2 \\ge 1$ is necessary and $\\delta_2=1$ is sufficient, the exact value of the restricted isometry constant is $\\delta_2(A)=1$. This result is independent of $q$, as long as the condition $q \\ge 2$ holds.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Having witnessed the failure of deterministic sampling for structured signals, we now turn to the power of randomness. This problem  revisits the same kind of structured signal supports that were problematic before, but now under a random row selection model. By calculating the expected energy of the \"off-block\" components of the Gram matrix, you will quantify how random sampling effectively breaks the coherence between structured sets of columns, ensuring that they become nearly orthogonal on average.",
            "id": "3474283",
            "problem": "Consider the unitary discrete Fourier transform matrix $F_{N} \\in \\mathbb{C}^{N \\times N}$ with entries $[F_{N}]_{t,k} = N^{-1/2} \\exp(-2 \\pi \\mathrm{i} \\, t k / N)$ for $t,k \\in \\{0,1,\\dots,N-1\\}$. In compressed sensing and sparse optimization, one studies the Restricted Isometry Property (RIP) of random partial Fourier matrices, which are formed by sampling rows from $F_{N}$ at random. Let $N$ be divisible by a positive integer $q$, so $N = q L$ with $L \\in \\mathbb{N}$. Construct a random measurement matrix $A \\in \\mathbb{C}^{m \\times N}$ by independently sampling $m$ rows from $F_{N}$ with replacement, and scaling each sampled row by $\\sqrt{N/m}$ so that $A$ has entries $[A]_{i,k} = m^{-1/2} \\exp(-2 \\pi \\mathrm{i} \\, t_{i} k / N)$, where the row indices $t_{i}$ are independent and uniformly distributed on $\\{0,1,\\dots,N-1\\}$.\n\nLet the support $S \\subset \\{0,1,\\dots,N-1\\}$ be a union of $B$ distinct residue classes modulo $q$, i.e., $S = \\bigcup_{b=1}^{B} \\{k \\in \\{0,1,\\dots,N-1\\} : k \\equiv c_{b} \\ (\\mathrm{mod}\\ q)\\}$, with $c_{1},\\dots,c_{B}$ all distinct in $\\{0,1,\\dots,q-1\\}$. Because $N = q L$, each residue class has exactly $L$ indices, so $|S| = B L$. Partition the columns of $A$ indexed by $S$ into $B$ blocks according to the residue classes. Define the empirical Gram on $S$ by $G_{S} = A_{S}^{*} A_{S} \\in \\mathbb{C}^{BL \\times BL}$. Define the off-block component $G_{\\mathrm{off}}$ by setting $[G_{\\mathrm{off}}]_{k,\\ell} = [G_{S}]_{k,\\ell}$ if $k \\in$ block $b$ and $\\ell \\in$ block $b'$ with $b \\neq b'$, and $[G_{\\mathrm{off}}]_{k,\\ell} = 0$ otherwise.\n\nStarting only from the orthogonality of complex exponentials, the unit-modulus property of Fourier characters, and independence of the sampled rows, derive a closed-form expression for the expected squared Frobenius norm $\\mathbb{E}\\big[\\|G_{\\mathrm{off}}\\|_{F}^{2}\\big]$ as a function of $N$, $q$, $B$, and $m$. Express your final answer in the simplest analytic form. Do not provide any inequalities or bounds; provide the exact expression. No numerical approximation is required.",
            "solution": "Our objective is to compute the expected squared Frobenius norm of the off-block component of the Gram matrix, $\\mathbb{E}\\big[\\|G_{\\mathrm{off}}\\|_{F}^{2}\\big]$.\n\nThe squared Frobenius norm of a matrix $M$ is the sum of the squared magnitudes of its entries, $\\|M\\|_{F}^{2} = \\sum_{k,\\ell} |M_{k,\\ell}|^2$. By the definition of $G_{\\mathrm{off}}$, its non-zero entries are precisely the entries $[G_S]_{k,\\ell}$ of the Gram matrix $G_S = A_S^* A_S$ for which the column indices $k$ and $\\ell$ belong to different residue classes modulo $q$. The set of indices $S$ is partitioned into $B$ blocks, $S = \\bigcup_{b=1}^{B} S_b$, where $S_b = \\{j \\in S : j \\equiv c_b \\pmod q\\}$. The size of each block is $|S_b| = L$, since $N=qL$.\n\nThe squared Frobenius norm of $G_{\\mathrm{off}}$ is therefore given by the sum over all pairs of indices $(k,\\ell)$ from different blocks:\n$$\n\\|G_{\\mathrm{off}}\\|_{F}^{2} = \\sum_{b=1}^{B} \\sum_{\\substack{b'=1 \\\\ b' \\neq b}}^{B} \\sum_{k \\in S_b} \\sum_{\\ell \\in S_{b'}} \\left| [G_S]_{k,\\ell} \\right|^2\n$$\nBy the linearity of the expectation operator, we can write:\n$$\n\\mathbb{E}\\big[\\|G_{\\mathrm{off}}\\|_{F}^{2}\\big] = \\sum_{b=1}^{B} \\sum_{\\substack{b'=1 \\\\ b' \\neq b}}^{B} \\sum_{k \\in S_b} \\sum_{\\ell \\in S_{b'}} \\mathbb{E}\\big[\\left| [G_S]_{k,\\ell} \\right|^2\\big]\n$$\nOur first step is to derive an expression for the term $\\mathbb{E}\\big[\\left| [G_S]_{k,\\ell} \\right|^2\\big]$. The entry $[G_S]_{k,\\ell}$ is the inner product of the $k$-th and $\\ell$-th columns of the matrix $A$, which we denote as $a_k$ and $a_\\ell$.\n$$\n[G_S]_{k,\\ell} = a_k^{*} a_\\ell = \\sum_{i=1}^{m} \\overline{[A]_{i,k}} [A]_{i,\\ell}\n$$\nUsing the given expression for the entries of $A$, $[A]_{i,j} = m^{-1/2} \\exp(-2 \\pi \\mathrm{i} \\, t_{i} j / N)$, we have:\n$$\n[G_S]_{k,\\ell} = \\sum_{i=1}^{m} \\left( m^{-1/2} \\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, t_i k}{N}\\right) \\right) \\left( m^{-1/2} \\exp\\left(-\\frac{2 \\pi \\mathrm{i} \\, t_i \\ell}{N}\\right) \\right) = \\frac{1}{m} \\sum_{i=1}^{m} \\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, t_i (k-\\ell)}{N}\\right)\n$$\nThe squared magnitude is $|[G_S]_{k,\\ell}|^2 = [G_S]_{k,\\ell} \\overline{[G_S]_{k,\\ell}}$:\n$$\n\\left| [G_S]_{k,\\ell} \\right|^2 = \\left( \\frac{1}{m} \\sum_{i=1}^{m} \\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, t_i (k-\\ell)}{N}\\right) \\right) \\left( \\frac{1}{m} \\sum_{j=1}^{m} \\exp\\left(-\\frac{2 \\pi \\mathrm{i} \\, t_j (k-\\ell)}{N}\\right) \\right)\n$$\n$$\n\\left| [G_S]_{k,\\ell} \\right|^2 = \\frac{1}{m^2} \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, (t_i - t_j)(k-\\ell)}{N}\\right)\n$$\nWe now compute the expectation of this quantity. The random variables are the row indices $t_1, \\dots, t_m$, which are independent and identically distributed uniformly on $\\{0, 1, \\dots, N-1\\}$.\n$$\n\\mathbb{E}\\big[\\left| [G_S]_{k,\\ell} \\right|^2\\big] = \\frac{1}{m^2} \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\mathbb{E}\\left[ \\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, (t_i - t_j)(k-\\ell)}{N}\\right) \\right]\n$$\nWe partition the sum over $(i,j)$ into two cases.\n\nCase 1: $i=j$.\nThere are $m$ such terms in the double summation. For these terms, $t_i - t_j = 0$, so the argument of the exponential is $0$.\n$$\n\\mathbb{E}\\left[ \\exp(0) \\right] = \\mathbb{E}[1] = 1\n$$\nThe total contribution from these $m$ terms is $m \\times 1 = m$.\n\nCase 2: $i \\neq j$.\nThere are $m(m-1)$ such terms. For these terms, since $t_i$ and $t_j$ are independent random variables, the expectation of the product of functions of $t_i$ and $t_j$ is the product of their individual expectations:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, t_i (k-\\ell)}{N}\\right) \\exp\\left(-\\frac{2 \\pi \\mathrm{i} \\, t_j (k-\\ell)}{N}\\right)\\right] = \\mathbb{E}\\left[\\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, t_i (k-\\ell)}{N}\\right)\\right] \\mathbb{E}\\left[\\exp\\left(-\\frac{2 \\pi \\mathrm{i} \\, t_j (k-\\ell)}{N}\\right)\\right]\n$$\nLet us compute the expectation for a generic-indexed variable $t$:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, t (k-\\ell)}{N}\\right)\\right] = \\sum_{s=0}^{N-1} P(t=s) \\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, s (k-\\ell)}{N}\\right) = \\frac{1}{N} \\sum_{s=0}^{N-1} \\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, s (k-\\ell)}{N}\\right)\n$$\nThis is the sum of all $N$-th roots of unity, weighted by the integer $k-\\ell$. From the orthogonality of complex exponentials (a property of the discrete Fourier transform), this sum equals $N$ if $k-\\ell$ is an integer multiple of $N$, and $0$ otherwise.\n\nThe indices $k$ and $\\ell$ are drawn from different blocks, $S_b$ and $S_{b'}$ with $b \\neq b'$, which means $k \\not\\equiv \\ell \\pmod q$. Since $k, \\ell \\in \\{0, 1, \\dots, N-1\\}$, $k-\\ell$ lies in the range $[-(N-1), N-1]$. The only integer multiple of $N$ in this range is $0$. However, $k-\\ell=0$ would imply $k=\\ell$, which contradicts $k \\not\\equiv \\ell \\pmod q$. Therefore, $k-\\ell$ is never an integer multiple of $N$ for the pairs $(k,\\ell)$ under consideration.\nConsequently, for $i \\neq j$:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{2 \\pi \\mathrm{i} \\, t (k-\\ell)}{N}\\right)\\right] = 0\n$$\nThe expectation for the terms with $i \\neq j$ is thus $0 \\times \\overline{0} = 0$. The total contribution from these $m(m-1)$ terms is $0$.\n\nCombining the two cases, we find the expectation for any pair $(k,\\ell)$ from different blocks:\n$$\n\\mathbb{E}\\big[\\left| [G_S]_{k,\\ell} \\right|^2\\big] = \\frac{1}{m^2} \\left( m \\cdot 1 + m(m-1) \\cdot 0 \\right) = \\frac{m}{m^2} = \\frac{1}{m}\n$$\nNote that the unit-modulus property of the Fourier characters, $\\left| \\exp(i\\theta) \\right| = 1$, was implicitly used in the $i=j$ case, as $|[G_S]_{k,\\ell}|^2$ contains terms like $\\exp(\\dots)\\overline{\\exp(\\dots)} = |\\exp(\\dots)|^2=1$. In our expectation calculation, this appeared as $\\mathbb{E}[\\exp(0)]$.\n\nSince the expected value $\\mathbb{E}\\big[\\left| [G_S]_{k,\\ell} \\right|^2\\big] = 1/m$ is constant for all pairs $(k,\\ell)$ in the sum, we only need to count the number of such pairs. The sum is over $k \\in S_b$ and $\\ell \\in S_{b'}$ for all $b \\neq b'$.\nThe number of choices for block $b$ is $B$.\nThe number of choices for block $b'$ (with $b' \\neq b$) is $B-1$.\nThe number of elements in any block $S_b$ is $|S_b| = L$.\nThe number of elements in any block $S_{b'}$ is $|S_{b'}| = L$.\nThe total number of pairs $(k,\\ell)$ is the product of these counts: $B \\times (B-1) \\times L \\times L = B(B-1)L^2$.\n\nFinally, we compute the total expected squared Frobenius norm:\n$$\n\\mathbb{E}\\big[\\|G_{\\mathrm{off}}\\|_{F}^{2}\\big] = \\left( \\text{Number of terms} \\right) \\times \\left( \\text{Expectation per term} \\right) = B(B-1)L^2 \\times \\frac{1}{m} = \\frac{L^2 B(B-1)}{m}\n$$\nThe problem requires the answer in terms of $N, q, B,$ and $m$. Using the given relation $N=qL$, we have $L=N/q$. Substituting this into our expression yields:\n$$\n\\mathbb{E}\\big[\\|G_{\\mathrm{off}}\\|_{F}^{2}\\big] = \\frac{(N/q)^2 B(B-1)}{m} = \\frac{N^2 B(B-1)}{m q^2}\n$$\nThis is the final, exact expression.",
            "answer": "$$\\boxed{\\frac{N^{2} B(B-1)}{m q^{2}}}$$"
        }
    ]
}