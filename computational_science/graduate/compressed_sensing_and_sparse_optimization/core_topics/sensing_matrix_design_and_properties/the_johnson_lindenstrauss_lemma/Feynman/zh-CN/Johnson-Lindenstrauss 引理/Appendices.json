{
    "hands_on_practices": [
        {
            "introduction": "虽然高斯矩阵是 JL 变换的经典范例，但它们并非唯一的选择。其他矩阵构造，例如基于 Rademacher 变量的矩阵，同样有效且在计算上可能更高效。这项实践  要求你比较和对比两种流行的 JL 矩阵族。通过此分析，你将理解 JL 属性源于更普适的次高斯性概念，而不仅仅是高斯分布的特定性质，并学会这些差异如何影响性能常数。",
            "id": "3488220",
            "problem": "考虑两种被用作 Johnson-Lindenstrauss (JL) 变换的独立同分布 (i.i.d.) 随机矩阵族，它们用于压缩感知和稀疏优化中的降维。令 $A \\in \\mathbb{R}^{m \\times d}$ 的元素 $A_{ij}$ 独立同分布于 $\\mathcal{N}(0, 1/m)$ (高斯族)，并令 $B \\in \\mathbb{R}^{m \\times d}$ 的元素 $B_{ij}$ 以等概率取值于 $\\{\\pm 1/\\sqrt{m}\\}$ (Rademacher 族)。对于任意固定的 $x \\in \\mathbb{R}^{d}$，用 $\\| \\cdot \\|_{2}$ 表示欧几里得 2-范数。如果一个随机线性映射满足对所有 $x \\in \\mathbb{R}^{d}$ 都有 $\\mathbb{E}\\|Mx\\|_{2}^{2} = \\|x\\|_{2}^{2}$，则称该映射是各向同性的 (isotropic)。一个随机变量 $X$ 被称为参数为 $\\sigma$ 的次高斯 (subgaussian) 变量，如果其矩母函数对所有 $t \\in \\mathbb{R}$ 都满足 $\\mathbb{E}[\\exp(tX)] \\le \\exp\\left(\\sigma^{2} t^{2} / 2\\right)$；并且次高斯变量的平方是次指数 (subexponential) 的，这使得独立中心化平方和能够满足 Bernstein 型集中不等式。\n\n仅使用这些基本定义和事实，分析两种矩阵族下失真量 $\\|Mx\\|_{2}^{2}$ 在 $\\|x\\|_{2}^{2}$ 周围的集中情况，并推导在包含 $N$ 个点的有限集合中以至多 $\\delta \\in (0,1)$ 的失败概率保持所有成对距离所需的嵌入维度 $m$ 的标度关系。选择所有正确的陈述。\n\nA. 对于任意固定的 $x \\in \\mathbb{R}^{d}$ 和任意 $\\varepsilon \\in (0,1)$，两种矩阵族都满足形式为 $\\mathbb{P}\\left(\\left|\\|Mx\\|_{2}^{2} - \\|x\\|_{2}^{2}\\right| > \\varepsilon \\|x\\|_{2}^{2}\\right) \\le 2 \\exp\\left(- c m \\varepsilon^{2}\\right)$ 的尾部界，其中 $c > 0$ 是一个绝对常数，其值取决于具体的矩阵族。\n\nB. 为确保以至少 $1 - \\delta$ 的概率将 $N$ 个点中的所有成对距离保持在 $(1 \\pm \\varepsilon)$ 的因子范围内，所需的最小嵌入维度 $m$ 的标度关系为 $m \\ge C \\varepsilon^{-2} \\log(N/\\delta)$，其中对于高斯族和 Rademacher 族，绝对常数 $C$ 是相同的。\n\nC. 高斯族具有旋转不变性，这意味着对于固定的 $x \\in \\mathbb{R}^{d}$，归一化失真 $\\|Ax\\|_{2}^{2}/\\|x\\|_{2}^{2}$ 服从一个自由度为 $m$ 的精确卡方分布律；而 Rademacher 族缺乏旋转不变性，需要对 $\\|Bx\\|_{2}^{2}$ 使用从次高斯到次指数的论证；这会产生相似的集中率，但尾部常数不同。\n\nD. Rademacher 族对于 $(Bx)_{i}$ 不具有次高斯尾部，因此无法实现 $m$ 按 $\\varepsilon^{-2}$ 标度的 JL 型集中；相反，它要求 $m$ 按 $\\varepsilon^{-4}$ 标度（不计对数因子）。\n\nE. 为了实现各向同性，两种矩阵族的元素都必须按 $1/m$ 而不是 $1/\\sqrt{m}$ 进行缩放；否则，当 $m \\to \\infty$ 时，$\\mathbb{E}\\|Mx\\|_{2}^{2}$ 将不等于 $\\|x\\|_{2}^{2}$。",
            "solution": "用户要求对一个关于 Johnson-Lindenstrauss (JL) 随机矩阵族性质的问题进行批判性分析。我将首先验证问题陈述，然后进行详细解答。\n\n### 第一步：提取已知条件\n-   两种 i.i.d. 随机矩阵族：$A \\in \\mathbb{R}^{m \\times d}$ 和 $B \\in \\mathbb{R}^{m \\times d}$。\n-   高斯族 $A$：元素 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$。\n-   Rademacher 族 $B$：元素 $B_{ij} \\in \\{\\pm 1/\\sqrt{m}\\}$，概率相等。\n-   符号：$\\| \\cdot \\|_{2}$ 表示欧几里得 2-范数。\n-   各向同性定义：如果对所有 $x \\in \\mathbb{R}^{d}$ 都有 $\\mathbb{E}\\|Mx\\|_{2}^{2} = \\|x\\|_{2}^{2}$，则随机线性映射 $M$ 是各向同性的。\n-   次高斯性定义：如果随机变量 $X$ 的矩母函数对所有 $t \\in \\mathbb{R}$ 都满足 $\\mathbb{E}[\\exp(tX)] \\le \\exp\\left(\\sigma^{2} t^{2} / 2\\right)$，则称 $X$ 为参数是 $\\sigma$ 的次高斯变量。\n-   已知事实：次高斯随机变量的平方是次指数的。\n-   任务：分析 $\\|Mx\\|_{2}^{2}$ 的集中情况并推导嵌入维度 $m$ 的标度关系。\n\n### 第二步：使用提取的已知条件进行验证\n问题陈述必须基于科学基础，提法得当且客观。\n\n1.  **科学基础和事实准确性**：该问题设定在随机矩阵理论和压缩感知的成熟数学框架内。高斯族和 Rademacher 族、各向同性和次高斯性的定义都是标准的。我们来验证给定的归一化。\n    -   对于矩阵族 $A$，元素 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$。令 $y = Ax$。$y$ 的元素为 $y_i = \\sum_{j=1}^d A_{ij} x_j$。\n        $\\mathbb{E}[y_i] = \\sum_j \\mathbb{E}[A_{ij}] x_j = 0$。\n        由于元素 $A_{ij}$ 是 i.i.d. 的，$\\mathbb{E}[y_i^2] = \\text{Var}(y_i) = \\sum_{j=1}^d \\text{Var}(A_{ij}) x_j^2 = \\sum_{j=1}^d (1/m) x_j^2 = (1/m)\\|x\\|_2^2$。\n        那么 $\\mathbb{E}\\|Ax\\|_2^2 = \\mathbb{E}[\\sum_{i=1}^m y_i^2] = \\sum_{i=1}^m \\mathbb{E}[y_i^2] = \\sum_{i=1}^m (1/m)\\|x\\|_2^2 = m \\cdot (1/m)\\|x\\|_2^2 = \\|x\\|_2^2$。\n        高斯族是各向同性的。\n    -   对于矩阵族 $B$，元素 $B_{ij} \\in \\{\\pm 1/\\sqrt{m}\\}$，概率相等。\n        $\\mathbb{E}[B_{ij}] = 0$。\n        $\\mathbb{E}[B_{ij}^2] = (\\frac{1}{2})(1/\\sqrt{m})^2 + (\\frac{1}{2})(-1/\\sqrt{m})^2 = 1/m$。\n        令 $z = Bx$。类似的计算表明 $\\mathbb{E}\\|Bx\\|_2^2 = \\|x\\|_2^2$。Rademacher 族也是各向同性的。\n    归一化和各向同性的定义是一致且事实准确的。\n2.  **提法得当性和客观性**：问题提法得当。它要求基于所提供的定义对几个精确的数学陈述进行评估。语言是客观和明确的。\n3.  **完整性**：问题提供了所有必要的定义和事实，以便使用高维概率论的标准结果进行分析。\n\n### 第三步：结论和行动\n问题陈述是有效的。我将继续推导解答并评估每个选项。\n\n### 解答推导\n\n问题的核心在于分析平方范数 $\\|Mx\\|_2^2$ 在其期望值周围的集中情况，我们已经确认对于矩阵族 $A$ 和 $B$，该期望值为 $\\mathbb{E}\\|Mx\\|_2^2 = \\|x\\|_2^2$。此性质被称为各向同性。让我们逐一分析每个陈述。\n\n#### 逐项分析\n\n**A. 对于任意固定的 $x \\in \\mathbb{R}^{d}$ 和任意 $\\varepsilon \\in (0,1)$，两种矩阵族都满足形式为 $\\mathbb{P}\\left(\\left|\\|Mx\\|_{2}^{2} - \\|x\\|_{2}^{2}\\right| > \\varepsilon \\|x\\|_{2}^{2}\\right) \\le 2 \\exp\\left(- c m \\varepsilon^{2}\\right)$ 的尾部界，其中 $c > 0$ 是一个绝对常数，其值取决于具体的矩阵族。**\n\n我们来分析每个矩阵族的集中情况。我们感兴趣的是随机变量 $Z = \\|Mx\\|_2^2$ 与其均值 $\\mathbb{E}[Z] = \\|x\\|_2^2$ 的偏差。\n\n-   **高斯族 ($A$)**：令 $x \\in \\mathbb{R}^d$ 固定。令 $y = Ax$。每个分量 $y_i = \\sum_{j=1}^d A_{ij} x_j$ 是独立高斯随机变量的线性组合。因此，$y_i$ 本身也是一个高斯随机变量。其均值为 $\\mathbb{E}[y_i]=0$，方差为 $\\text{Var}(y_i) = \\sum_j \\text{Var}(A_{ij}) x_j^2 = (1/m) \\|x\\|_2^2$。令 $Z_i = y_i / \\sqrt{\\|x\\|_2^2/m}$。变量 $Z_i$（对于 $i=1, \\dots, m$）是 i.i.d. 的标准正态变量，$Z_i \\sim \\mathcal{N}(0,1)$。\n    那么，$\\|Ax\\|_2^2 = \\sum_{i=1}^m y_i^2 = \\sum_{i=1}^m \\frac{\\|x\\|_2^2}{m} Z_i^2 = \\frac{\\|x\\|_2^2}{m} \\sum_{i=1}^m Z_i^2$。\n    和 $\\sum_{i=1}^m Z_i^2$ 是 $m$ 个 i.i.d. 标准正态变量的平方和，根据定义，它服从自由度为 $m$ 的卡方分布，即 $\\chi_m^2$。\n    我们正在考察 $\\frac{1}{m} \\chi_m^2$ 在其均值 $1$ 周围的集中情况。随机变量 $\\chi_m^2$ 是 i.i.d. 次指数变量（高斯变量的平方）的和。关于 $\\chi_m^2$ 变量的著名集中不等式（例如，Laurent-Massart 不等式）给出 $\\mathbb{P}(|\\frac{1}{m}\\chi_m^2 - 1| > \\varepsilon) \\le 2\\exp(-c_G m \\varepsilon^2)$，其中某个常数 $c_G > 0$ 且 $\\varepsilon \\in (0,1)$。这与陈述中的形式相符。\n\n-   **Rademacher 族 ($B$)**：令 $z = Bx$。每个分量 $z_i = \\sum_{j=1}^d B_{ij} x_j$ 是独立、零均值、有界随机变量的和。我们可以证明 $z_i$ 是次高斯的。其矩母函数为 $\\mathbb{E}[e^{t z_i}] = \\prod_{j=1}^d \\mathbb{E}[e^{t B_{ij} x_j}] = \\prod_{j=1}^d \\cosh(t x_j/\\sqrt{m})$。使用 $\\cosh(u) \\le e^{u^2/2}$，我们得到 $\\mathbb{E}[e^{t z_i}] \\le \\prod_{j=1}^d e^{t^2 x_j^2 / (2m)} = e^{t^2 \\|x\\|_2^2 / (2m)}$。这表明 $z_i$ 是次高斯变量，参数为 $\\|x\\|_2/\\sqrt{m}$。\n    变量 $\\|Bx\\|_2^2 = \\sum_{i=1}^m z_i^2$ 是 i.i.d. 次高斯变量平方的和。问题陈述中指出，次高斯变量的平方是次指数的。根据 Bernstein 不等式，独立、中心化的次指数随机变量之和会集中在其均值附近。对于随机变量 $X_i = z_i^2$，和 $\\sum_{i=1}^m X_i$ 集中在其均值 $\\mathbb{E}[\\sum X_i] = \\|x\\|_2^2$ 附近。对于小的 $\\varepsilon$，得到的尾部界形式为 $\\mathbb{P}(|\\sum_i z_i^2 - \\|x\\|_2^2| > \\varepsilon \\|x\\|_2^2) \\le 2\\exp(-c_R m \\varepsilon^2)$，其中某个常数 $c_R > 0$。\n\n常数 $c_G$ 和 $c_R$ 取决于底层随机变量（$y_i^2$ 和 $z_i^2$）的次指数参数，而这些参数对于两种矩阵族是不同的。因此，该陈述是正确的。\n**结论：正确。**\n\n**B. 为确保以至少 $1 - \\delta$ 的概率将 $N$ 个点中的所有成对距离保持在 $(1 \\pm \\varepsilon)$ 的因子范围内，所需的最小嵌入维度 $m$ 的标度关系为 $m \\ge C \\varepsilon^{-2} \\log(N/\\delta)$，其中对于高斯族和 Rademacher 族，绝对常数 $C$ 是相同的。**\n\nJohnson-Lindenstrauss 引理确保对于一个包含 $N$ 个点的集合 $\\{p_1, \\dots, p_N\\}$，我们可以保持所有成对距离。这要求控制所有向量 $x_{ij} = p_i - p_j$（$1 \\le i  j \\le N$）的失真。这样的向量共有 $\\binom{N}{2}$ 个。\n从陈述 A 可知，单个向量 $x$ 的失败概率为 $P_{fail, x} \\le 2\\exp(-c_M m \\varepsilon'^2)$，其中 $c_M$ 是矩阵族 $M$ 的常数，$\\varepsilon'$ 是平方范数的失真参数。将距离保持在 $(1 \\pm \\varepsilon)$ 范围内，大致对应于将平方范数保持在 $1 \\pm 2\\varepsilon$ 的因子范围内，因此 $\\varepsilon' \\propto \\varepsilon$。\n对所有 $\\binom{N}{2}$ 对使用联合界：\n$$ \\mathbb{P}(\\text{任何一对失败}) \\le \\binom{N}{2} \\cdot 2 \\exp(-c_M' m \\varepsilon^2) \\le N^2 \\exp(-c_M' m \\varepsilon^2) $$\n我们要求这个总失败概率小于 $\\delta$：\n$$ N^2 \\exp(-c_M' m \\varepsilon^2) \\le \\delta \\implies \\exp(c_M' m \\varepsilon^2) \\ge N^2/\\delta $$\n两边取对数：\n$$ c_M' m \\varepsilon^2 \\ge \\log(N^2/\\delta) = 2 \\log N + \\log(1/\\delta) $$\n这给出了所需的嵌入维度：\n$$ m \\ge \\frac{1}{c_M'} \\varepsilon^{-2} (2 \\log N + \\log(1/\\delta)) $$\n该表达式可以写为 $m \\ge C_M \\varepsilon^{-2} \\log(N^2/\\delta)$。陈述中的项 $\\log(N/\\delta)$ 是对标度关系的轻微简化，但关键部分是常数 $C_M = 1/c_M'$。根据对陈述 A 的分析，高斯族的集中常数 $c_G'$ 和 Rademacher 族的集中常数 $c_R'$ 是不同的。因此，$m$ 的公式中的前导常数 $C_M \\propto 1/c_M'$ 对于两种矩阵族也必须是不同的。具体来说，标准分析表明，高斯族具有更好（更大）的集中常数 $c_G'$，从而导致所需的维度 $m$ 更小（即 $C_G$ 更小）。\n因此，声称常数 $C$ 对两种矩阵族相同的说法是错误的。\n**结论：不正确。**\n\n**C. 高斯族具有旋转不变性，这意味着对于固定的 $x \\in \\mathbb{R}^{d}$，归一化失真 $\\|Ax\\|_{2}^{2}/\\|x\\|_{2}^{2}$ 服从一个自由度为 $m$ 的精确卡方分布律；而 Rademacher 族缺乏旋转不变性，需要对 $\\|Bx\\|_{2}^{2}$ 使用从次高斯到次指数的论证；这会产生相似的集中率，但尾部常数不同。**\n\n-   **高斯族**：一个具有 i.i.d. $\\mathcal{N}(0, \\sigma^2)$ 元素的随机矩阵 $A$ 具有旋转不变性，意味着其分布在与正交矩阵相乘后保持不变。我们的 $A$ 具有此性质。由于这种不变性，$Ax$ 的分布仅取决于 $\\|x\\|_2$。我们可以分析 $x = \\|x\\|_2 e_1$ 的简单情况。那么 $Ax = \\|x\\|_2 A e_1$，其中 $Ae_1$ 是 $A$ 的第一列。该列由 $m$ 个 i.i.d. 变量 $A_{i1} \\sim \\mathcal{N}(0, 1/m)$ 组成。\n    因此，$\\|Ax\\|_2^2 = \\|x\\|_2^2 \\sum_{i=1}^m A_{i1}^2$。归一化失真为 $\\|Ax\\|_2^2/\\|x\\|_2^2 = \\sum_{i=1}^m A_{i1}^2$。令 $Z_i = \\sqrt{m} A_{i1}$，则 $Z_i \\sim \\mathcal{N}(0,1)$。那么归一化失真为 $\\sum_{i=1}^m (Z_i/\\sqrt{m})^2 = \\frac{1}{m} \\sum_{i=1}^m Z_i^2 = \\frac{1}{m} \\chi_m^2$。陈述说其定律是“一个自由度为 $m$ 的精确卡方分布律”。这略有不精确；它是一个*经过缩放*的 $\\chi_m^2$ 变量。然而，其分布确实由 $\\chi_m^2$ 分布律精确刻画。\n-   **Rademacher 族**：矩阵 $B$ 的元素来自离散集合 $\\{\\pm 1/\\sqrt{m}\\}$。如果我们应用一个旋转，新元素将是原始元素的线性组合，并且不会局限于这个离散集合。因此，Rademacher 族不具有旋转不变性。分析不能通过旋转 $x$ 来简化，必须像 A 部分那样进行，使用通用的集中工具来处理次高斯/次指数变量的和。\n-   **结论**：该陈述正确地指出了 Rademacher 情况下由于缺乏特殊结构（如旋转不变性），需要使用更通用的工具（次高斯集中）。它也正确地得出结论，这导致了 $m$ 的相似渐近标度（集中率），但在尾部界中有不同的常数。关于卡方分布律的不精确之处在这种比较性语境中是次要的。它所做的核心概念区分是准确的。\n**结论：正确。**\n\n**D. Rademacher 族对于 $(Bx)_{i}$ 不具有次高斯尾部，因此无法实现 $m$ 按 $\\varepsilon^{-2}$ 标度的 JL 型集中；相反，它要求 $m$ 按 $\\varepsilon^{-4}$ 标度（不计对数因子）。**\n\n这个陈述在事实上是不正确的。正如在对陈述 A 的分析中所示，变量 $(Bx)_i = \\sum_{j=1}^d B_{ij} x_j$ 是独立、中心化、有界随机变量的和。一个标准结果（Hoeffding 引理）表明，这样的和是次高斯的。我们明确推导了它的矩母函数为 $\\mathbb{E}[e^{t(Bx)_i}] \\le \\exp(t^2\\|x\\|_2^2/(2m))$，证实了它的次高斯性质。由于 $(Bx)_i$ 是次高斯的，其平方是次指数的，和 $\\|Bx\\|_2^2 = \\sum_{i=1}^m ((Bx)_i)^2$ 表现出由 Bernstein 型不等式描述的集中现象。这直接导致标准的 JL 标度关系，其中 $m$ 与 $\\varepsilon^{-2}$ 成正比（以及对数因子）。声称它需要 $m \\sim \\varepsilon^{-4}$ 是错误的，这种结论会源于使用更弱的工具，比如四阶矩方法结合 Chebyshev 不等式，而不是利用次高斯集中的全部威力。\n**结论：不正确。**\n\n**E. 为了实现各向同性，两种矩阵族的元素都必须按 $1/m$ 而不是 $1/\\sqrt{m}$ 进行缩放；否则，当 $m \\to \\infty$ 时，$\\mathbb{E}\\|Mx\\|_{2}^{2}$ 将不等于 $\\|x\\|_{2}^{2}$。**\n\n该陈述混淆了值/标准差的缩放与方差的缩放。各向同性，即 $\\mathbb{E}\\|Mx\\|_{2}^{2} = \\|x\\|_{2}^{2}$，要求每个矩阵元素 $M_{ij}$ 的方差为 $1/m$，假设元素是 i.i.d. 且零均值的。\n$$ \\mathbb{E}\\|Mx\\|_2^2 = \\sum_{i=1}^m \\mathbb{E}[(\\sum_{j=1}^d M_{ij} x_j)^2] = \\sum_{i=1}^m \\sum_{j=1}^d \\mathbb{E}[M_{ij}^2] x_j^2 = \\sum_{i=1}^m \\text{Var}(M_{ij}) \\|x\\|_2^2 $$\n为使此式等于 $\\|x\\|_2^2$，我们需要 $\\sum_{i=1}^m \\text{Var}(M_{ij}) = 1$，对于 i.i.d. 元素，这意味着 $m \\cdot \\text{Var}(M_{ij}) = 1$，即 $\\text{Var}(M_{ij}) = 1/m$。\n\n-   对于高斯变量 $\\mathcal{N}(0, \\sigma^2)$，方差是 $\\sigma^2$。因此我们需要 $\\sigma^2=1/m$，这意味着标准差为 $\\sigma = 1/\\sqrt{m}$。元素的缩放因子是 $1/\\sqrt{m}$。\n-   对于取值为 $\\pm k$ 的 Rademacher 变量，方差是 $k^2$。因此我们需要 $k^2=1/m$，这意味着取值必须是 $\\pm 1/\\sqrt{m}$。\n\n问题陈述给出的正是这些正确的缩放方式。如果我们使用 $1/m$ 的缩放因子来缩放值/标准差，每个元素的方差将是 $1/m^2$。那么期望值将是：\n$$ \\mathbb{E}\\|Mx\\|_2^2 = m \\cdot (1/m^2) \\|x\\|_2^2 = \\frac{1}{m}\\|x\\|_2^2 $$\n这不等于 $\\|x\\|_2^2$。该陈述提出了一个不正确的缩放因子。\n**结论：不正确。**",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "JL 引理的理论威力可转化为显著的实践优势，尤其是在计算成本是主要考量的大规模机器学习中。一个关键应用是使用 JL 变换为海量数据集创建一个“速写”，从而让算法在更小的速写上运行，而非处理全部数据。这个练习  让你扮演一位机器学习理论家的角色，分析如何使用快速 Johnson-Lindenstrauss 变换 (FJLT) 来加速 LASSO 算法。你将推导这种降维如何影响模型的统计保证，从而在 JL 引理的抽象几何与一个广泛应用的估计算法的误差分析之间建立具体的联系。",
            "id": "3488241",
            "problem": "考虑一个数据矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 和一个响应向量 $y \\in \\mathbb{R}^{n}$，它们服从线性模型 $y = X \\beta^{\\star} + w$，其中真实参数 $\\beta^{\\star} \\in \\mathbb{R}^{d}$ 是 $s$-稀疏的，其支撑集为 $S \\subset [d]$，且 $|S| = s$，$w \\in \\mathbb{R}^{n}$ 是噪声。最小绝对收缩和选择算子 (LASSO) 估计量 $\\widehat{\\beta}$ 定义为以下目标函数的最小化子：\n$$\n\\frac{1}{2n}\\|X \\beta - y\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1},\n$$\n对于给定的正则化参数 $\\lambda > 0$。假设 $X$ 在锥 $\\mathcal{C}(S) = \\{h \\in \\mathbb{R}^{d} : \\|h_{S^{c}}\\|_{1} \\leq 3 \\|h_{S}\\|_{1}\\}$ 上满足限制强凸性 (RSC) 和限制平滑性 (RSS)，即存在常数 $\\alpha > 0$ 和 $L > 0$，使得对于所有 $h \\in \\mathcal{C}(S)$，\n$$\n\\alpha \\|h\\|_{2}^{2} \\leq \\frac{1}{n}\\|X h\\|_{2}^{2} \\leq L \\|h\\|_{2}^{2}.\n$$\n假设噪声满足原始设计的对偶可行性条件：$\\left\\|\\frac{1}{n} X^{\\top} w\\right\\|_{\\infty} \\leq \\frac{\\lambda}{4}$。\n\n您应用了一个快速 Johnson-Lindenstrauss 变换 (FJLT)，即一个结构化随机线性映射 $\\Phi \\in \\mathbb{R}^{m \\times n}$，根据 Johnson-Lindenstrauss 引理，该映射能以至少 $1 - \\delta$ 的概率保持集合 $\\{X h : h \\in \\mathcal{C}(S)\\}$ 中所有平方范数，失真度在 $\\varepsilon \\in (0,1)$ 之内，即对于所有 $h \\in \\mathcal{C}(S)$，\n$$\n(1 - \\varepsilon)\\, \\frac{1}{n}\\|X h\\|_{2}^{2} \\leq \\frac{1}{m}\\|\\Phi X h\\|_{2}^{2} \\leq (1 + \\varepsilon)\\, \\frac{1}{n}\\|X h\\|_{2}^{2}.\n$$\n然后您求解预处理的 LASSO 问题：\n$$\n\\widehat{\\beta}_{\\mathrm{FJLT}} \\in \\arg\\min_{\\beta \\in \\mathbb{R}^{d}} \\left\\{ \\frac{1}{2m}\\|\\Phi X \\beta - \\Phi y\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1} \\right\\}.\n$$\n假设投影后的噪声满足 $\\left\\|\\frac{1}{m}(\\Phi X)^{\\top} \\Phi w\\right\\|_{\\infty} \\leq \\frac{\\lambda}{2}$。\n\n仅从限制强凸性与平滑性的定义、LASSO 的凸最优性以及上述 Johnson-Lindenstrauss 范数保持保证出发，推导快速 Johnson-Lindenstrauss 变换如何影响预处理设计的限制条件数和限制强凸性常数。然后，利用这些影响，推导 $\\ell_{2}$-误差 $\\|\\widehat{\\beta}_{\\mathrm{FJLT}} - \\beta^{\\star}\\|_{2}$ 的一个关于 $\\alpha$、$\\varepsilon$、$s$ 和 $\\lambda$ 的紧上界。请将您的最终答案表示为该上界的单一闭式解析表达式。不需要数值近似，也不涉及任何单位。最终答案必须是仅包含 $\\alpha$、$\\varepsilon$、$s$ 和 $\\lambda$ 的单一表达式。",
            "solution": "该问题要求分析快速 Johnson-Lindenstrauss 变换 (FJLT) 对设计矩阵的限制强凸性 (RSC) 和限制条件数的影响，并随后为从预处理数据中获得的 LASSO 估计量推导一个 $\\ell_2$ 误差界。\n\n令原始设计矩阵为 $X \\in \\mathbb{R}^{n \\times d}$，预处理设计矩阵为 $\\tilde{X} = \\Phi X \\in \\mathbb{R}^{m \\times d}$，其中 $\\Phi \\in \\mathbb{R}^{m \\times n}$ 是 FJLT 矩阵。\n\n**第一部分：FJLT 对 RSC 和限制条件数的影响**\n\n假设原始设计矩阵 $X$ 在锥 $\\mathcal{C}(S) = \\{h \\in \\mathbb{R}^{d} : \\|h_{S^{c}}\\|_{1} \\leq 3 \\|h_{S}\\|_{1}\\}$ 上满足限制强凸性 (RSC) 和限制平滑性 (RSS) 性质，存在常数 $\\alpha > 0$ 和 $L > 0$：\n$$\n\\alpha \\|h\\|_{2}^{2} \\leq \\frac{1}{n}\\|X h\\|_{2}^{2} \\leq L \\|h\\|_{2}^{2}, \\quad \\forall h \\in \\mathcal{C}(S).\n$$\n问题陈述 FJLT 矩阵 $\\Phi$ 在集合 $\\{X h : h \\in \\mathcal{C}(S)\\}$ 中保持平方范数，对于给定的 $\\varepsilon \\in (0,1)$：\n$$\n(1 - \\varepsilon)\\, \\frac{1}{n}\\|X h\\|_{2}^{2} \\leq \\frac{1}{m}\\|\\Phi X h\\|_{2}^{2} \\leq (1 + \\varepsilon)\\, \\frac{1}{n}\\|X h\\|_{2}^{2}, \\quad \\forall h \\in \\mathcal{C}(S).\n$$\n我们来分析新设计矩阵 $\\tilde{X} = \\Phi X$ 的 RSC 和 RSS 性质。相关的二次型现在是 $\\frac{1}{m}\\|\\tilde{X} h\\|_{2}^{2} = \\frac{1}{m}\\|\\Phi X h\\|_{2}^{2}$。\n\n对于下界 (RSC)，我们结合这些不等式。对于任意 $h \\in \\mathcal{C}(S)$：\n$$\n\\frac{1}{m}\\|\\Phi X h\\|_{2}^{2} \\geq (1 - \\varepsilon) \\frac{1}{n}\\|X h\\|_{2}^{2} \\geq (1 - \\varepsilon) \\alpha \\|h\\|_{2}^{2}.\n$$\n因此，预处理设计 $\\Phi X$ 在相同的锥 $\\mathcal{C}(S)$ 上满足 RSC，新的常数为 $\\tilde{\\alpha} = \\alpha(1 - \\varepsilon)$。\n\n对于上界 (RSS)，我们有：\n$$\n\\frac{1}{m}\\|\\Phi X h\\|_{2}^{2} \\leq (1 + \\varepsilon) \\frac{1}{n}\\|X h\\|_{2}^{2} \\leq (1 + \\varepsilon) L \\|h\\|_{2}^{2}.\n$$\n新的 RSS 常数是 $\\tilde{L} = L(1 + \\varepsilon)$。\n\n原始问题的限制条件数是 $\\kappa = L/\\alpha$。对于预处理问题，新的限制条件数是 $\\tilde{\\kappa} = \\tilde{L}/\\tilde{\\alpha}$。\n$$\n\\tilde{\\kappa} = \\frac{L(1 + \\varepsilon)}{\\alpha(1 - \\varepsilon)} = \\frac{L}{\\alpha} \\cdot \\frac{1 + \\varepsilon}{1 - \\varepsilon} = \\kappa \\frac{1 + \\varepsilon}{1 - \\varepsilon}.\n$$\n总之，FJLT 使 RSC 常数降低了 $(1-\\varepsilon)$ 倍，并使限制条件数恶化了 $(1+\\varepsilon)/(1-\\varepsilon)$ 倍。\n\n**第二部分：预处理 LASSO 估计量的 $\\ell_2$ 误差界**\n\n令 $\\widehat{\\beta} \\equiv \\widehat{\\beta}_{\\mathrm{FJLT}}$ 是预处理 LASSO 问题的解：\n$$\n\\widehat{\\beta} \\in \\arg\\min_{\\beta \\in \\mathbb{R}^{d}} \\left\\{ \\frac{1}{2m}\\|\\Phi X \\beta - \\Phi y\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1} \\right\\}.\n$$\n令估计误差为 $h = \\widehat{\\beta} - \\beta^{\\star}$。根据 $\\widehat{\\beta}$ 的最优性，它必须满足目标函数不等式 $F(\\widehat{\\beta}) \\leq F(\\beta^{\\star})$：\n$$\n\\frac{1}{2m}\\|\\Phi X \\widehat{\\beta} - \\Phi y\\|_{2}^{2} + \\lambda \\|\\widehat{\\beta}\\|_{1} \\leq \\frac{1}{2m}\\|\\Phi X \\beta^{\\star} - \\Phi y\\|_{2}^{2} + \\lambda \\|\\beta^{\\star}\\|_{1}.\n$$\n代入线性模型 $y = X \\beta^{\\star} + w$：\n$$\n\\frac{1}{2m}\\|\\Phi X \\widehat{\\beta} - \\Phi (X \\beta^{\\star} + w)\\|_{2}^{2} + \\lambda \\|\\widehat{\\beta}\\|_{1} \\leq \\frac{1}{2m}\\|\\Phi X \\beta^{\\star} - \\Phi (X \\beta^{\\star} + w)\\|_{2}^{2} + \\lambda \\|\\beta^{\\star}\\|_{1}.\n$$\n使用 $h = \\widehat{\\beta} - \\beta^{\\star}$，上式简化为：\n$$\n\\frac{1}{2m}\\|\\Phi X h - \\Phi w\\|_{2}^{2} + \\lambda \\|\\widehat{\\beta}\\|_{1} \\leq \\frac{1}{2m}\\|-\\Phi w\\|_{2}^{2} + \\lambda \\|\\beta^{\\star}\\|_{1}.\n$$\n展开左侧的平方范数：\n$$\n\\frac{1}{2m}\\left(\\|\\Phi X h\\|_{2}^{2} - 2\\langle \\Phi X h, \\Phi w \\rangle + \\|\\Phi w\\|_{2}^{2}\\right) + \\lambda \\|\\widehat{\\beta}\\|_{1} \\leq \\frac{1}{2m}\\|\\Phi w\\|_{2}^{2} + \\lambda \\|\\beta^{\\star}\\|_{1}.\n$$\n从两边消去 $\\frac{1}{2m}\\|\\Phi w\\|_{2}^{2}$ 项并重新整理，我们得到标准的“基本不等式”：\n$$\n\\frac{1}{2m}\\|\\Phi X h\\|_{2}^{2} \\leq \\frac{1}{m}\\langle \\Phi X h, \\Phi w \\rangle + \\lambda (\\|\\beta^{\\star}\\|_{1} - \\|\\widehat{\\beta}\\|_{1}).\n$$\n我们来界定右侧的两项。\n\n第一项是噪声项：$\\frac{1}{m}\\langle \\Phi X h, \\Phi w \\rangle = \\langle h, \\frac{1}{m}(\\Phi X)^{\\top}\\Phi w \\rangle$。使用 Hölder 不等式和关于投影噪声的假设 $\\left\\|\\frac{1}{m}(\\Phi X)^{\\top} \\Phi w\\right\\|_{\\infty} \\leq \\frac{\\lambda}{2}$：\n$$\n\\left\\langle h, \\frac{1}{m}(\\Phi X)^{\\top}\\Phi w \\right\\rangle \\leq \\|h\\|_{1} \\left\\|\\frac{1}{m}(\\Phi X)^{\\top}\\Phi w\\right\\|_{\\infty} \\leq \\|h\\|_{1} \\frac{\\lambda}{2}.\n$$\n第二项涉及真实参数 $\\beta^{\\star}$（支撑集为 $S$）和估计值 $\\widehat{\\beta} = \\beta^{\\star} + h$ 的 $\\ell_1$ 范数：\n$$\n\\|\\beta^{\\star}\\|_{1} - \\|\\widehat{\\beta}\\|_{1} = \\|\\beta^{\\star}_{S}\\|_{1} - (\\|\\widehat{\\beta}_{S}\\|_{1} + \\|\\widehat{\\beta}_{S^c}\\|_{1}).\n$$\n注意 $h_{S^c} = \\widehat{\\beta}_{S^c} - \\beta^{\\star}_{S^c} = \\widehat{\\beta}_{S^c}$ 因为 $\\beta^{\\star}_{S^c}=0$。根据三角不等式，$\\|\\beta^{\\star}_{S}\\|_{1} = \\|\\widehat{\\beta}_{S} - h_{S}\\|_{1} \\leq \\|\\widehat{\\beta}_{S}\\|_{1} + \\|h_{S}\\|_{1}$，这意味着 $-\\|\\widehat{\\beta}_{S}\\|_{1} \\leq \\|h_{S}\\|_{1} - \\|\\beta^{\\star}_{S}\\|_{1}$。将此代入表达式可得：\n$$\n\\|\\beta^{\\star}\\|_{1} - \\|\\widehat{\\beta}\\|_{1} \\leq \\|\\beta^{\\star}_{S}\\|_{1} + (\\|h_{S}\\|_{1} - \\|\\beta^{\\star}_{S}\\|_{1}) - \\|h_{S^c}\\|_{1} = \\|h_{S}\\|_{1} - \\|h_{S^c}\\|_{1}.\n$$\n将这些界带回基本不等式：\n$$\n\\frac{1}{2m}\\|\\Phi X h\\|_{2}^{2} \\leq \\frac{\\lambda}{2} \\|h\\|_{1} + \\lambda (\\|h_{S}\\|_{1} - \\|h_{S^c}\\|_{1}).\n$$\n写作 $\\|h\\|_{1} = \\|h_{S}\\|_{1} + \\|h_{S^c}\\|_{1}$：\n$$\n\\frac{1}{2m}\\|\\Phi X h\\|_{2}^{2} \\leq \\frac{\\lambda}{2}(\\|h_{S}\\|_{1} + \\|h_{S^c}\\|_{1}) + \\lambda \\|h_{S}\\|_{1} - \\lambda \\|h_{S^c}\\|_{1} = \\frac{3\\lambda}{2} \\|h_{S}\\|_{1} - \\frac{\\lambda}{2} \\|h_{S^c}\\|_{1}.\n$$\n由于左侧是非负的，右侧也必须是非负的。由于 $\\lambda > 0$，这意味着 $\\frac{3}{2}\\|h_S\\|_1 \\ge \\frac{1}{2}\\|h_{S^c}\\|_1$，简化为 $\\|h_{S^c}\\|_{1} \\leq 3\\|h_S\\|_{1}$。这表明误差向量 $h$ 位于锥 $\\mathcal{C}(S)$ 内。\n\n现在我们可以应用为预处理设计矩阵推导出的 RSC 性质。对于 $h \\in \\mathcal{C}(S)$，我们有 $\\frac{1}{m}\\|\\Phi X h\\|_{2}^{2} \\geq \\tilde{\\alpha} \\|h\\|_{2}^{2} = \\alpha(1-\\varepsilon)\\|h\\|_{2}^{2}$。将此代入我们的不等式：\n$$\n\\frac{\\alpha(1-\\varepsilon)}{2} \\|h\\|_{2}^{2} \\leq \\frac{1}{2m}\\|\\Phi X h\\|_{2}^{2} \\leq \\frac{3\\lambda}{2} \\|h_{S}\\|_{1} - \\frac{\\lambda}{2} \\|h_{S^c}\\|_{1}.\n$$\n去掉非正项 $-\\frac{\\lambda}{2} \\|h_{S^c}\\|_{1}$ 会得到一个更简单的上界：\n$$\n\\frac{\\alpha(1-\\varepsilon)}{2} \\|h\\|_{2}^{2} \\leq \\frac{3\\lambda}{2} \\|h_{S}\\|_{1}.\n$$\n这简化为 $\\alpha(1-\\varepsilon) \\|h\\|_{2}^{2} \\leq 3\\lambda \\|h_{S}\\|_{1}$。\n为了将 $\\|h_S\\|_1$ 与 $\\|h\\|_2$ 联系起来，我们对向量 $h_S$ 使用 Cauchy-Schwarz 不等式，该向量最多有 $s$ 个非零项：\n$$\n\\|h_{S}\\|_{1} \\leq \\sqrt{s} \\|h_{S}\\|_{2}.\n$$\n此外，$\\|h_{S}\\|_{2} \\leq \\|h\\|_{2}$ 因为 $\\|h\\|_{2}^{2} = \\|h_{S}\\|_{2}^{2} + \\|h_{S^c}\\|_{2}^{2}$。\n结合这些不等式：\n$$\n\\alpha(1-\\varepsilon) \\|h\\|_{2}^{2} \\leq 3\\lambda \\sqrt{s} \\|h_{S}\\|_{2} \\leq 3\\lambda \\sqrt{s} \\|h\\|_{2}.\n$$\n如果 $\\|h\\|_{2} = 0$，则该界是平凡的。如果 $\\|h\\|_{2} > 0$，我们可以两边除以 $\\|h\\|_{2}$ 来获得最终的误差界：\n$$\n\\|\\widehat{\\beta}_{\\mathrm{FJLT}} - \\beta^{\\star}\\|_{2} = \\|h\\|_{2} \\leq \\frac{3\\lambda\\sqrt{s}}{\\alpha(1-\\varepsilon)}.\n$$",
            "answer": "$$\n\\boxed{\\frac{3\\lambda\\sqrt{s}}{\\alpha(1-\\varepsilon)}}\n$$"
        }
    ]
}