{
    "hands_on_practices": [
        {
            "introduction": "ADMM 的威力在于其能够将复杂问题分解为更易于处理的子问题。在许多应用中，这涉及求解一个近端算子（proximal operator）来处理非光滑正则项。此练习将引导您推导并计算各向同性总变分（TV）范数的近端算子，这是现代图像处理的基石，通过这种方式加深您对 ADMM 如何处理重要的非光滑、可分离正则项的理解。",
            "id": "3430656",
            "problem": "考虑压缩感知中的各向同性总变分 (TV) 正则化最小二乘问题，\n$$\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\|D x\\|_{2,1},$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个传感矩阵，$b \\in \\mathbb{R}^{m}$ 是测量向量，$D \\in \\mathbb{R}^{2n \\times n}$ 是离散梯度算子，它将每个像素映射到一个二维梯度（水平和垂直差分），$\\|\\cdot\\|_{2,1}$ 表示混合范数，定义为 $\\|z\\|_{2,1} = \\sum_{i=1}^{n} \\|z_{i}\\|_{2}$，其中 $z_{i} \\in \\mathbb{R}^{2}$ 是像素 $i$ 处的梯度块。\n\n使用交替方向乘子法 (ADMM)，引入分裂变量 $z = D x$ 和缩放对偶变量 $u$。$z$ 的更新步骤求解关于混合范数 $\\|\\cdot\\|_{2,1}$ 的近端子问题：\n$$z^{k+1} = \\operatorname{prox}_{\\tau \\|\\cdot\\|_{2,1}}(v),$$\n对于一个合适的正惩罚参数 $\\rho$ 和标量 $\\tau = \\lambda / \\rho$，其中 $v = D x^{k+1} + u^{k}$。\n\n从一个正常、闭、凸函数 $g$ 的近端算子的定义出发，\n$$\\operatorname{prox}_{\\tau g}(v) = \\arg\\min_{z} \\left\\{ \\tau g(z) + \\frac{1}{2}\\|z - v\\|_{2}^{2} \\right\\},$$\n从第一性原理推导 $\\operatorname{prox}_{\\tau \\|\\cdot\\|_{2,1}}(v)$ 的显式分块映射，其中向量 $v$ 被划分为 $n$ 个与各向同性梯度相关的二维块 $v_{i} \\in \\mathbb{R}^{2}$。然后，考虑一个具体实例，其中有 $n = 3$ 个像素，正则化参数 $\\lambda = 1$，惩罚参数 $\\rho = 1$，因此 $\\tau = 1$，以及块向量\n$$v = \\big( v_{1}, v_{2}, v_{3} \\big), \\quad v_{1} = (3, 0), \\quad v_{2} = (\\sqrt{3}, 1), \\quad v_{3} = \\left(\\frac{3}{5}, \\frac{4}{5}\\right).$$\n通过将推导出的分块近端映射应用于每个块 $v_{i}$ 来计算 $z$ 的更新 $z^{k+1} = \\operatorname{prox}_{\\tau \\|\\cdot\\|_{2,1}}(v)$，并将连接后的结果报告为一个包含六个分量 $(z_{1}^{(1)}, z_{1}^{(2)}, z_{2}^{(1)}, z_{2}^{(2)}, z_{3}^{(1)}, z_{3}^{(2)})$ 的单行向量。\n\n最后，从概念上解释这个 $z$ 更新在交替方向乘子法 (ADMM) 中为实现各向同性 TV 正则化所起的作用。\n\n你最终报告的向量必须是精确的；不要四舍五入。",
            "solution": "我们从近端算子的定义开始。对于一个正常、闭、凸函数 $g$，其参数为 $\\tau > 0$ 的近端算子定义为\n$$\\operatorname{prox}_{\\tau g}(v) = \\arg\\min_{z} \\left\\{ \\tau g(z) + \\frac{1}{2}\\|z - v\\|_{2}^{2} \\right\\}.$$\n在我们的问题中，$g(z) = \\|z\\|_{2,1} = \\sum_{i=1}^{n} \\|z_{i}\\|_{2}$，其中 $z_{i} \\in \\mathbb{R}^{2}$ 是每个像素的二维梯度块。由于 $g$ 是各块之和，且二次项在各块之间是可分的，因此最小化问题可以分解为 $n$ 个独立的子问题，每个块一个：\n$$z_{i}^{\\star} = \\arg\\min_{z_{i} \\in \\mathbb{R}^{2}} \\left\\{ \\tau \\|z_{i}\\|_{2} + \\frac{1}{2} \\|z_{i} - v_{i}\\|_{2}^{2} \\right\\}.$$\n我们从第一性原理分析每个块的问题。目标函数仅通过 $z_{i}$ 的欧几里得范数及其与 $v_{i}$ 的欧几里得距离来依赖于 $z_{i}$。这种旋转对称性意味着最优解 $z_{i}^{\\star}$ 位于 $v_{i}$ 的方向上（或者是零向量）。当 $v_{i} \\neq 0$ 时，令 $z_{i} = \\alpha v_{i}$，其中标量 $\\alpha \\geq 0$（符号为非负，因为范数项乘以正数会惩罚大小，而二次项沿着 $v_{i}$ 的方向最小化）。代入后得到关于 $\\alpha$ 的一维问题：\n$$\\min_{\\alpha \\geq 0} \\ \\tau \\|\\alpha v_{i}\\|_{2} + \\frac{1}{2} \\|\\alpha v_{i} - v_{i}\\|_{2}^{2}\n= \\min_{\\alpha \\geq 0} \\ \\tau \\alpha \\|v_{i}\\|_{2} + \\frac{1}{2} (\\alpha - 1)^{2} \\|v_{i}\\|_{2}^{2}.$$\n定义 $r_{i} = \\|v_{i}\\|_{2} > 0$。标量目标函数变为\n$$\\phi(\\alpha) = \\tau \\alpha r_{i} + \\frac{1}{2} (\\alpha - 1)^{2} r_{i}^{2}.$$\n对 $\\alpha$ 求导并令其等于零以求驻点，\n$$\\phi'(\\alpha) = \\tau r_{i} + (\\alpha - 1) r_{i}^{2} = 0 \\quad \\Rightarrow \\quad \\alpha^{\\star} = 1 - \\frac{\\tau}{r_{i}}.$$\n我们必须强制 $\\alpha^{\\star} \\geq 0$。如果 $r_{i} \\leq \\tau$，则 $1 - \\frac{\\tau}{r_{i}} \\leq 0$，最小化点在 $\\alpha^{\\star} = 0$ 处。如果 $r_{i} > \\tau$，则 $\\alpha^{\\star} > 0$ 且有效。因此，最优的块解是\n$$z_{i}^{\\star} =\n\\begin{cases}\n\\left(1 - \\frac{\\tau}{\\|v_{i}\\|_{2}}\\right) v_{i},  & \\text{if } \\|v_{i}\\|_{2} > \\tau, \\\\\n0,  & \\text{if } \\|v_{i}\\|_{2} \\leq \\tau.\n\\end{cases}$$\n这就是分块向量收缩映射，等价地表示为 $z_{i}^{\\star} = \\max\\!\\left(1 - \\frac{\\tau}{\\|v_{i}\\|_{2}}, 0\\right) v_{i}$，对每个块 $i$ 都适用，并约定如果 $v_{i} = 0$，则 $z_{i}^{\\star} = 0$。\n\n我们现在将此映射应用于给定的实例。参数为 $\\lambda = 1$，$\\rho = 1$，因此 $\\tau = \\lambda / \\rho = 1$。各块为\n$$v_{1} = (3, 0), \\quad v_{2} = (\\sqrt{3}, 1), \\quad v_{3} = \\left(\\frac{3}{5}, \\frac{4}{5}\\right).$$\n计算范数：\n- 对于 $v_{1}$，$\\|v_{1}\\|_{2} = \\sqrt{3^{2} + 0^{2}} = 3$。因为 $3 > \\tau$，收缩因子为 $1 - \\frac{\\tau}{\\|v_{1}\\|_{2}} = 1 - \\frac{1}{3} = \\frac{2}{3}$，所以\n$$z_{1}^{\\star} = \\frac{2}{3} (3, 0) = (2, 0).$$\n- 对于 $v_{2}$，$\\|v_{2}\\|_{2} = \\sqrt{(\\sqrt{3})^{2} + 1^{2}} = \\sqrt{3 + 1} = 2$。因为 $2 > \\tau$，收缩因子为 $1 - \\frac{1}{2} = \\frac{1}{2}$，所以\n$$z_{2}^{\\star} = \\frac{1}{2} (\\sqrt{3}, 1) = \\left(\\frac{\\sqrt{3}}{2}, \\frac{1}{2}\\right).$$\n- 对于 $v_{3}$，$\\|v_{3}\\|_{2} = \\sqrt{\\left(\\frac{3}{5}\\right)^{2} + \\left(\\frac{4}{5}\\right)^{2}} = \\sqrt{\\frac{9}{25} + \\frac{16}{25}} = \\sqrt{\\frac{25}{25}} = 1$。因为 $1 \\leq \\tau$，收缩因子为 $0$，所以\n$$z_{3}^{\\star} = (0, 0).$$\n连接各分量 $(z_{1}^{(1)}, z_{1}^{(2)}, z_{2}^{(1)}, z_{2}^{(2)}, z_{3}^{(1)}, z_{3}^{(2)})$ 得到行向量\n$$(2, 0, \\frac{\\sqrt{3}}{2}, \\frac{1}{2}, 0, 0).$$\n\n最后，我们解释此更新在交替方向乘子法 (ADMM) 中的作用。在各向同性 TV 问题的 ADMM 分裂中，$z$ 的更新通过求解关于 $z$ 的近端子问题来分离出非光滑的正则化项 $\\|D x\\|_{2,1}$，其输入为 $v = D x^{k+1} + u^{k}$，参数为 $\\tau = \\lambda / \\rho$。分块向量收缩映射通过减小每个像素梯度向量的模来实现各向同性 TV 正则化：梯度模较小（小于或等于 $\\tau$）的块被精确地设为零，从而促进分段常数结构；而较大的梯度则在不改变其方向的情况下向零收缩，保留了边缘方向。这个近端步骤由于在像素间是可分的，因此计算效率很高，并提供了 ADMM 将 TV 正则化项整合到迭代更新中的机制，从而平衡了数据保真度和图像梯度的稀疏性。",
            "answer": "$$\\boxed{\\begin{pmatrix} 2 & 0 & \\frac{\\sqrt{3}}{2} & \\frac{1}{2} & 0 & 0 \\end{pmatrix}}$$"
        },
        {
            "introduction": "ADMM 的收敛速度对惩罚参数 $\\rho$ 的选择高度敏感，而固定的 $\\rho$ 值往往不是最优的。本练习将带领您从使用固定 $\\rho$ 进步到采用自适应策略，通过实现一种基于原始残差和对偶残差平衡的规则，您将获得构建更鲁棒、更高效的 ADMM 求解器的实践经验。",
            "id": "3364422",
            "problem": "考虑将乘子交替方向法（ADMM）应用于二维凸、二次连续可微二次目标函数的一致性分裂。目标是设计一种残差平衡规则，通过调整增广拉格朗日惩罚参数来平衡原始残差和对偶残差的范数，并分析该规则对一个二维二次测试问题收敛性的影响。您将编写的程序必须是完全自包含的，并计算几个测试用例收敛所需的迭代次数。\n\n从以下基础开始。设优化问题表述为最小化一个可分离的凸函数之和，其等式约束以一致性形式表示：\n$$\n\\min_{\\boldsymbol{x} \\in \\mathbb{R}^2,\\, \\boldsymbol{z} \\in \\mathbb{R}^2} \\; f(\\boldsymbol{x}) + g(\\boldsymbol{z}) \\quad \\text{subject to} \\quad \\boldsymbol{x} = \\boldsymbol{z},\n$$\n其中\n$$\nf(\\boldsymbol{x}) = \\frac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{Q}\\,\\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x}, \\quad g(\\boldsymbol{z}) = \\frac{1}{2}\\boldsymbol{z}^\\top \\boldsymbol{R}\\,\\boldsymbol{z} + \\boldsymbol{r}^\\top \\boldsymbol{z},\n$$\n并且矩阵 $\\boldsymbol{Q}$ 和 $\\boldsymbol{R}$ 是对称正定的，向量 $\\boldsymbol{q}$ 和 $\\boldsymbol{r}$ 属于 $\\mathbb{R}^2$。为惩罚参数 $\\rho > 0$ 和缩放对偶变量 $\\boldsymbol{u}^k \\in \\mathbb{R}^2$ 定义缩放形式的 ADMM 迭代 $(\\boldsymbol{x}^{k+1}, \\boldsymbol{z}^{k+1}, \\boldsymbol{u}^{k+1})$。原始残差为\n$$\n\\boldsymbol{r}^{k+1} = \\boldsymbol{x}^{k+1} - \\boldsymbol{z}^{k+1},\n$$\n对偶残差为\n$$\n\\boldsymbol{s}^{k+1} = \\rho\\left(\\boldsymbol{z}^{k+1} - \\boldsymbol{z}^{k}\\right).\n$$\n\n您的任务是：\n- 从第一性原理和子问题的一阶最优性条件出发，当 $f$ 和 $g$ 是所述的凸二次函数且约束为 $\\boldsymbol{x} = \\boldsymbol{z}$ 时，推导 $\\boldsymbol{x}^{k+1}$ 和 $\\boldsymbol{z}^{k+1}$ 的显式闭式更新公式。\n- 实现具有两种模式的 ADMM：固定惩罚参数模式和自适应残差平衡模式。在自适应模式下，使用以下带有参数 $\\mu > 0$ 和 $\\kappa > 1$ 的残差平衡规则，在迭代期间调整 $\\rho$：\n$$\n\\text{if } \\|\\boldsymbol{r}^{k+1}\\|_2 > \\mu \\|\\boldsymbol{s}^{k+1}\\|_2 \\text{ then set } \\rho \\leftarrow \\kappa \\rho \\text{ and } \\boldsymbol{u}^{k+1} \\leftarrow \\boldsymbol{u}^{k+1}/\\kappa;\n$$\n$$\n\\text{else if } \\|\\boldsymbol{s}^{k+1}\\|_2 > \\mu \\|\\boldsymbol{r}^{k+1}\\|_2 \\text{ then set } \\rho \\leftarrow \\rho/\\kappa \\text{ and } \\boldsymbol{u}^{k+1} \\leftarrow \\boldsymbol{u}^{k+1}\\kappa;\n$$\n否则保持 $\\rho$ 不变。$\\boldsymbol{u}^{k+1}$ 的缩放必须在 $\\rho$ 发生变化时保持未缩放的拉格朗日乘子 $\\boldsymbol{y}^{k+1} = \\rho \\boldsymbol{u}^{k+1}$ 不变。\n- 使用基于绝对和相对容差的停止准则。令 $n = 2$。定义\n$$\n\\varepsilon_{\\mathrm{pri}} = \\sqrt{n}\\,\\varepsilon_{\\mathrm{abs}} + \\varepsilon_{\\mathrm{rel}} \\max\\left(\\|\\boldsymbol{x}^{k+1}\\|_2, \\|\\boldsymbol{z}^{k+1}\\|_2\\right),\n$$\n$$\n\\varepsilon_{\\mathrm{dual}} = \\sqrt{n}\\,\\varepsilon_{\\mathrm{abs}} + \\varepsilon_{\\mathrm{rel}} \\,\\|\\rho\\,\\boldsymbol{u}^{k+1}\\|_2,\n$$\n并在 $\\|\\boldsymbol{r}^{k+1}\\|_2 \\le \\varepsilon_{\\mathrm{pri}}$ 和 $\\|\\boldsymbol{s}^{k+1}\\|_2 \\le \\varepsilon_{\\mathrm{dual}}$ 都满足时终止。仅在检查这些停止准则之后，才应用惩罚参数的自适应调整。\n\n使用以下固定输入和测试套件实现该算法。所有向量都是 $\\mathbb{R}^2$ 中的列向量，所有矩阵都是 $2 \\times 2$ 的。\n\n通用初始条件：\n- $\\boldsymbol{x}^0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\boldsymbol{z}^0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\boldsymbol{u}^0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n- 容差：$\\varepsilon_{\\mathrm{abs}} = 10^{-6}$，$\\varepsilon_{\\mathrm{rel}} = 10^{-6}$。\n- 最大迭代次数：$50000$。\n- 所有残差和阈值计算都必须使用欧几里得范数。\n\n测试套件参数集：\n- 情况 1 (良态，固定 $\\rho$):\n  - $\\boldsymbol{Q} = \\begin{bmatrix} 4 & 1 \\\\ 1 & 2 \\end{bmatrix}$，$\\boldsymbol{R} = \\begin{bmatrix} 3 & 0 \\\\ 0 & 1 \\end{bmatrix}$，\n  - $\\boldsymbol{q} = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$，$\\boldsymbol{r} = \\begin{bmatrix} 0.5 \\\\ -1 \\end{bmatrix}$，\n  - 固定 $\\rho = 1$，禁用自适应模式。\n- 情况 2 (良态，自适应，初始 $\\rho$ 较小):\n  - 与情况 1 相同的 $\\boldsymbol{Q}$、$\\boldsymbol{R}$、$\\boldsymbol{q}$、$\\boldsymbol{r}$，\n  - 初始 $\\rho = 10^{-4}$，启用自适应模式，参数为 $\\mu = 10, \\kappa = 2$。\n- 情况 3 (良态，自适应，初始 $\\rho$ 较大):\n  - 与情况 1 相同的 $\\boldsymbol{Q}$、$\\boldsymbol{R}$、$\\boldsymbol{q}$、$\\boldsymbol{r}$，\n  - 初始 $\\rho = 10^{2}$，启用自适应模式，参数为 $\\mu = 2, \\kappa = 2$。\n- 情况 4 (病态，固定 $\\rho$):\n  - $\\boldsymbol{Q} = \\begin{bmatrix} 1000 & 0 \\\\ 0 & 1 \\end{bmatrix}$，$\\boldsymbol{R} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 100 \\end{bmatrix}$，\n  - $\\boldsymbol{q} = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$，$\\boldsymbol{r} = \\begin{bmatrix} 0.5 \\\\ -1 \\end{bmatrix}$，\n  - 固定 $\\rho = 1$，禁用自适应模式。\n- 情况 5 (病态，自适应，初始 $\\rho$ 非常小):\n  - 与情况 4 相同的 $\\boldsymbol{Q}$、$\\boldsymbol{R}$、$\\boldsymbol{q}$、$\\boldsymbol{r}$，\n  - 初始 $\\rho = 10^{-6}$，启用自适应模式，参数为 $\\mu = 3, \\kappa = 2$。\n\n对于每种情况，计算并返回满足停止准则所需的总迭代次数。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $\\left[ \\text{result}_1, \\text{result}_2, \\text{result}_3, \\text{result}_4, \\text{result}_5 \\right]$，其中每个 $\\text{result}_i$ 是情况 $i$ 的整数迭代次数。",
            "solution": "该问题要求实现ADMM算法，以解决一致性形式下的可分离凸二次优化问题：\n$$\n\\min_{\\boldsymbol{x} \\in \\mathbb{R}^2,\\, \\boldsymbol{z} \\in \\mathbb{R}^2} \\; f(\\boldsymbol{x}) + g(\\boldsymbol{z}) \\quad \\text{subject to} \\quad \\boldsymbol{x} = \\boldsymbol{z},\n$$\n其中 $f(\\boldsymbol{x}) = \\frac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{Q}\\,\\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x}$ 且 $g(\\boldsymbol{z}) = \\frac{1}{2}\\boldsymbol{z}^\\top \\boldsymbol{R}\\,\\boldsymbol{z} + \\boldsymbol{r}^\\top \\boldsymbol{z}$。\n\n**ADMM更新公式推导**\n使用缩放对偶变量 $\\boldsymbol{u}$ 的增广拉格朗日函数为：\n$$\nL_\\rho(\\boldsymbol{x}, \\boldsymbol{z}, \\boldsymbol{u}) = f(\\boldsymbol{x}) + g(\\boldsymbol{z}) + \\frac{\\rho}{2} \\|\\boldsymbol{x} - \\boldsymbol{z} + \\boldsymbol{u}\\|_2^2 - \\frac{\\rho}{2} \\|\\boldsymbol{u}\\|_2^2\n$$\nADMM算法的迭代步骤包括对 $\\boldsymbol{x}$、$\\boldsymbol{z}$ 和 $\\boldsymbol{u}$ 的顺序更新。\n\n**1. $\\boldsymbol{x}$-更新**\n$\\boldsymbol{x}$ 的子问题是最小化关于 $\\boldsymbol{x}$ 的二次函数：\n$$\n\\boldsymbol{x}^{k+1} = \\arg\\min_{\\boldsymbol{x}} \\left( \\frac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{Q}\\,\\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x} + \\frac{\\rho}{2} \\|\\boldsymbol{x} - (\\boldsymbol{z}^k - \\boldsymbol{u}^k)\\|_2^2 \\right)\n$$\n通过将梯度设为零来求解：\n$$\n\\nabla_{\\boldsymbol{x}} (\\cdot) = \\boldsymbol{Q}\\boldsymbol{x} + \\boldsymbol{q} + \\rho(\\boldsymbol{x} - \\boldsymbol{z}^k + \\boldsymbol{u}^k) = 0\n$$\n整理后得到：\n$$\n(\\boldsymbol{Q} + \\rho\\boldsymbol{I})\\boldsymbol{x}^{k+1} = \\rho(\\boldsymbol{z}^k - \\boldsymbol{u}^k) - \\boldsymbol{q}\n$$\n由于 $\\boldsymbol{Q}$ 是正定的且 $\\rho > 0$，矩阵 $(\\boldsymbol{Q} + \\rho\\boldsymbol{I})$ 可逆。因此，$\\boldsymbol{x}$-更新的闭式解为：\n$$\n\\boldsymbol{x}^{k+1} = (\\boldsymbol{Q} + \\rho\\boldsymbol{I})^{-1} \\left( \\rho(\\boldsymbol{z}^k - \\boldsymbol{u}^k) - \\boldsymbol{q} \\right)\n$$\n\n**2. $\\boldsymbol{z}$-更新**\n$\\boldsymbol{z}$ 的子问题同样是二次的，使用更新后的 $\\boldsymbol{x}^{k+1}$：\n$$\n\\boldsymbol{z}^{k+1} = \\arg\\min_{\\boldsymbol{z}} \\left( \\frac{1}{2}\\boldsymbol{z}^\\top \\boldsymbol{R}\\,\\boldsymbol{z} + \\boldsymbol{r}^\\top \\boldsymbol{z} + \\frac{\\rho}{2} \\|\\boldsymbol{z} - (\\boldsymbol{x}^{k+1} + \\boldsymbol{u}^k)\\|_2^2 \\right)\n$$\n将其梯度设为零：\n$$\n\\nabla_{\\boldsymbol{z}} (\\cdot) = \\boldsymbol{R}\\boldsymbol{z} + \\boldsymbol{r} + \\rho(\\boldsymbol{z} - (\\boldsymbol{x}^{k+1} + \\boldsymbol{u}^k)) = 0\n$$\n整理后得到：\n$$\n(\\boldsymbol{R} + \\rho\\boldsymbol{I})\\boldsymbol{z}^{k+1} = \\rho(\\boldsymbol{x}^{k+1} + \\boldsymbol{u}^k) - \\boldsymbol{r}\n$$\n由于 $\\boldsymbol{R}$ 是正定的，矩阵 $(\\boldsymbol{R} + \\rho\\boldsymbol{I})$ 可逆。因此，$\\boldsymbol{z}$-更新的闭式解为：\n$$\n\\boldsymbol{z}^{k+1} = (\\boldsymbol{R} + \\rho\\boldsymbol{I})^{-1} \\left( \\rho(\\boldsymbol{x}^{k+1} + \\boldsymbol{u}^k) - \\boldsymbol{r} \\right)\n$$\n\n**3. $\\boldsymbol{u}$-更新**\n对偶变量的更新为：\n$$\n\\boldsymbol{u}^{k+1} = \\boldsymbol{u}^k + \\boldsymbol{x}^{k+1} - \\boldsymbol{z}^{k+1}\n$$\n\n**算法实现**\n该算法迭代上述更新直至满足停止准则。在每次迭代结束时，如果启用了自适应模式，则根据原始残差 $\\|\\boldsymbol{r}^{k+1}\\|_2$ 和对偶残差 $\\|\\boldsymbol{s}^{k+1}\\|_2$ 的大小关系来调整惩罚参数 $\\rho$，并相应地缩放对偶变量 $\\boldsymbol{u}^{k+1}$，以备下一次迭代使用。该过程在所附的 Python 代码中实现，该代码根据问题描述中的五个测试用例计算收敛所需的迭代次数。",
            "answer": "[41, 61, 60, 1851, 107]"
        },
        {
            "introduction": "在解决如 LASSO 等问题时，我们通常不仅关心单个正则化参数 $\\lambda$ 下的解，而是希望得到整个正则化路径上的解集。本练习将探讨一种更高级的 ADMM 应用，即实现一种同伦方法来追踪 LASSO 的解路径，并集成温启动和自适应惩罚参数调优。这项实践模拟了一个研究级别的任务，展示了如何将 ADMM 作为一个强大的引擎，嵌入到更大规模的计算框架中，以完成模型选择等复杂任务。",
            "id": "3430616",
            "problem": "您的任务是实现一个完整的、可运行的程序，该程序为最小绝对收缩和选择算子 (LASSO) 问题构建一个交替方向乘子法 (ADMM) 求解器，并使用一个通过递减正则化参数来追踪近似稀疏路径的同伦策略。您的实现必须在各个阶段之间采用热启动，并使用自适应的惩罚参数。目标是针对几个压缩感知实例，研究每个同伦阶段需要多少次 ADMM 迭代才能维持路径上支撑集的单调性。\n\n从包含以下核心定义和事实的基础出发：\n- LASSO 问题定义为最小化以下凸目标函数\n$$\n\\min_{x \\in \\mathbb{R}^n} \\; \\tfrac{1}{2}\\|A x - b\\|_2^2 + \\lambda \\|x\\|_1,\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个感知矩阵，其列被缩放到单位 $\\ell_2$ 范数，$b \\in \\mathbb{R}^m$ 是一个观测向量，$\\lambda \\in \\mathbb{R}_{+}$ 是正则化参数，$\\|\\cdot\\|_2$ 是欧几里得范数，$\\|\\cdot\\|_1$ 是 $\\ell_1$ 范数。\n- 变量分裂法引入一个辅助变量 $z \\in \\mathbb{R}^n$ 和约束 $x - z = 0$，将问题重构为在 $x - z = 0$ 的约束下最小化 $f(x) + g(z)$，其中 $f(x) = \\tfrac{1}{2}\\|A x - b\\|_2^2$ 且 $g(z) = \\lambda \\|z\\|_1$。\n- 对于约束 $x - z = 0$，其增广拉格朗日函数为（其中惩罚参数为 $\\rho \\in \\mathbb{R}_{+}$，缩放对偶变量为 $u \\in \\mathbb{R}^n$）：\n$$\n\\mathcal{L}_{\\rho}(x,z,u) = f(x) + g(z) + \\tfrac{\\rho}{2}\\|x - z + u\\|_2^2 - \\tfrac{\\rho}{2}\\|u\\|_2^2.\n$$\n- $\\ell_1$ 范数的近端算子是软阈值（收缩）算子，这是一个经过充分检验的事实：\n$$\n\\operatorname{shrink}(v, \\kappa) = \\mathrm{sign}(v) \\odot \\max\\{|v| - \\kappa, 0\\},\n$$\n逐元素应用。\n\n您的程序必须严格且明确地实现以下内容：\n1. 为给定 $\\lambda$ 的 LASSO 子问题实现 ADMM，使用标准的 $x$-更新、通过软阈值进行的 $z$-更新以及 $u$-更新。通过使用上一阶段 $\\lambda_k$ 的最终 $(x,z,u)$ 来初始化下一阶段 $\\lambda_{k+1}$，在同伦阶段之间使用热启动。\n2. 使用残差平衡为 $\\rho$ 实现自适应惩罚策略。令 $r^{t} = x^{t} - z^{t}$ 和 $s^{t} = \\rho^{t}(z^{t} - z^{t-1})$ 分别表示 ADMM 第 $t$ 次迭代时的原始残差和对偶残差。如果 $\\|r^{t}\\|_2 > \\mu \\|s^{t}\\|_2$，则设置 $\\rho^{t+1} = \\tau \\rho^{t}$；如果 $\\|s^{t}\\|_2 > \\mu \\|r^{t}\\|_2$，则设置 $\\rho^{t+1} = \\rho^{t}/\\tau$；否则保持 $\\rho$ 不变。当 $\\rho$ 从 $\\rho_{\\text{old}}$ 变为 $\\rho_{\\text{new}}$ 时，更新缩放对偶变量为 $u \\leftarrow (\\rho_{\\text{old}}/\\rho_{\\text{new}}) u$。使用 $\\mu = 10$ 和 $\\tau = 2$，并将 $\\rho$ 初始化为 $\\rho_0 = 1$。\n3. 对 $\\lambda$ 使用几何递减的同伦策略：令 $\\lambda_{\\max} = \\|A^{\\top} b\\|_{\\infty}$，并定义 $K$ 个阶段，其中\n$$\n\\lambda_k = \\lambda_{\\max} \\cdot \\left(\\frac{\\lambda_{\\min}}{\\lambda_{\\max}}\\right)^{k/(K-1)}, \\quad k = 0, 1, \\dots, K-1,\n$$\n且 $\\lambda_{\\min} = 0.02 \\cdot \\lambda_{\\max}$，$K = 20$。\n4. 在每个同伦阶段，执行固定次数 $T$ 的 ADMM 迭代（不基于收敛性提早终止）。$T$ 的候选集合为 $\\{1, 2, 3, 5, 8, 13\\}$。对于每个测试实例，您必须在此集合中找到最小的 $T$，使得在每个阶段结束时估计的支撑集形成一个关于集合包含关系单调不减的序列。一个阶段的支撑集定义为 $\\operatorname{supp}(x) = \\{i \\in \\{1,\\dots,n\\} : |x_i| > \\tau_s\\}$，阈值为 $\\tau_s = 10^{-3}$。\n5. 如果在候选集中的所有 $T$ 都不能在全部 $K$ 个阶段产生单调不减的支撑集，则该测试实例返回 $-1$。\n\n数据生成必须遵循压缩感知标准：\n- 构造 $A \\in \\mathbb{R}^{m \\times n}$，其元素为独立同分布的高斯分布，然后将每列缩放到单位 $\\ell_2$ 范数。\n- 构造一个真实稀疏向量 $x^{\\star} \\in \\mathbb{R}^n$，其恰好有 $s$ 个非零元，支撑集是均匀随机选择的，非零值是从 $[0.5, 1.5]$ 区间内均匀抽取并带有随机符号。\n- 构造 $b = A x^{\\star} + \\eta$，其中噪声为高斯噪声 $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$。\n- 每个测试用例的随机数生成必须可以通过固定的种子来复现。\n\n使用 $A^{\\top} A + \\rho I_n$ 的 Cholesky 分解和三角求解来实现 $x$-更新中的线性代数运算。当 $\\rho$ 改变时，相应地更新分解。\n\n测试套件：\n您必须对以下四个测试实例进行评估，每个实例由 $(\\text{seed}, m, n, s, \\sigma, \\text{coherence})$ 指定：\n- 测试 1：$(20240501, 40, 100, 8, 1 \\times 10^{-4}, \\text{低})$。\n- 测试 2：$(20240502, 40, 100, 8, 1 \\times 10^{-4}, \\text{高})$；为引入高相干性，在生成并归一化 $A$ 后，通过 $A_{:,2} \\leftarrow \\frac{A_{:,1} + 0.001 \\cdot \\xi}{\\|A_{:,1} + 0.001 \\cdot \\xi\\|_2}$（其中 $\\xi \\sim \\mathcal{N}(0, I_m)$）将第二列替换为与第一列几乎重复的列，然后重新归一化修改后的列。\n- 测试 3：$(20240503, 40, 100, 12, 2 \\times 10^{-2}, \\text{低})$。\n- 测试 4：$(20240504, 30, 60, 1, 0, \\text{低})$。\n\n对于每个测试实例，确定在 $\\{1, 2, 3, 5, 8, 13\\}$ 中能够使所有 $K = 20$ 个同伦阶段的支撑集都单调不减的最小 $T$。如果不存在这样的 $T$，则输出 $-1$。\n\n最终输出格式要求：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按四个测试的顺序排列：$[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$。每个 $\\text{result}_i$ 必须是如上所述的整数。不得打印任何其他文本。\n\n所有角度（如有）必须以弧度为单位。此问题不涉及任何物理单位。所有报告的标量必须为不带百分号的普通数字形式。程序不得要求任何用户输入，也不得访问外部文件或网络。它必须能直接运行。",
            "solution": "为了解决 LASSO 问题 $\\min_{x} \\frac{1}{2}\\|A x - b\\|_2^2 + \\lambda \\|x\\|_1$，我们采用变量分裂法，将其重构为 ADMM 框架下的约束优化问题：\n$$\n\\min_{x,z} \\; \\frac{1}{2}\\|A x - b\\|_2^2 + \\lambda \\|z\\|_1 \\quad \\text{s.t.} \\quad x - z = 0.\n$$\nADMM 的迭代步骤如下：\n- **$x$-更新：** 求解一个二次规划问题，其正规方程为 $(A^{\\top} A + \\rho I_n) x = A^{\\top} b + \\rho (z - u)$。该线性系统可以通过预先计算 $A^{\\top}A$ 和 $A^{\\top}b$，并对矩阵 $A^{\\top} A + \\rho I_n$ 进行 Cholesky 分解来高效求解。\n- **$z$-更新：** 求解一个 $\\ell_1$ 范数的邻近问题，其解由软阈值算子给出：$z \\leftarrow \\operatorname{shrink}(x + u, \\lambda/\\rho)$。\n- **$u$-更新：** 对缩放对偶变量进行更新：$u \\leftarrow u + x - z$。\n\n为了高效追踪正则化路径，我们采用同伦策略，从一个较大的正则化参数 $\\lambda_{\\max} = \\|A^{\\top} b\\|_{\\infty}$ 开始，逐步递减至一个较小的值 $\\lambda_{\\min}$。在每个同伦阶段，我们仅运行固定次数 $T$ 的 ADMM 迭代，并将上一阶段的解 $(x, z, u)$作为下一阶段的初始值（热启动），以利用解路径的连续性。\n\n为了提高算法的鲁棒性，我们实施了自适应惩罚参数 $\\rho$ 的策略。该策略通过比较原始残差 $\\|r\\|_2$ 和对偶残差 $\\|s\\|_2$ 的大小来动态调整 $\\rho$。如果原始残差过大，则增加 $\\rho$ 以加强约束；如果对偶残差过大，则减小 $\\rho$。当 $\\rho$ 发生变化时，对偶变量 $u$ 也需要相应地重新缩放，以保持未缩放的拉格朗日乘子不变。\n\n对于每个给定的压缩感知问题实例，我们在一组候选值 $\\{1, 2, 3, 5, 8, 13\\}$ 中，寻找能够使整个同伦路径上解的支撑集（非零元素的位置集合）保持单调不减的最小迭代次数 $T$。支撑集的单调性是衡量路径追踪质量的一个重要指标。如果对于某个 $T$，在所有 $\\lambda$ 递减的阶段，$\\operatorname{supp}(x_k) \\subseteq \\operatorname{supp}(x_{k+1})$ 都成立，则认为该 $T$ 是有效的。程序将返回在所有测试用例中有效的最小 $T$ 值。\n\n该方法集成了 ADMM 的核心分解思想、用于高效路径追踪的同伦法、利用解连续性的热启动技术，以及用于提高收敛效率的自适应惩罚机制，从而构成一个用于解决 LASSO 正则化路径问题的先进计算框架。",
            "answer": "[2, 3, 3, 1]"
        }
    ]
}