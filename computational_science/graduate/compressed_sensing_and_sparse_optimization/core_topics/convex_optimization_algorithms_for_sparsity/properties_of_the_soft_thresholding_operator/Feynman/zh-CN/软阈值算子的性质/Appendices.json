{
    "hands_on_practices": [
        {
            "introduction": "软阈值算子的主要作用是产生稀疏性。一个基本的实践任务是选择阈值参数 $\\lambda$ 以达到期望的稀疏水平。本练习将引导你推导 $\\lambda$ 与输出向量支撑集大小之间的直接关系，为校准稀疏恢复算法提供一个至关重要的工具。",
            "id": "3470304",
            "problem": "令 $x \\in \\mathbb{R}^{n}$ 为一个固定向量，其分量的绝对值两两不同，即对所有 $i \\neq j$ 都有 $|x_{i}| \\neq |x_{j}|$。考虑软阈值算子 $S_{\\lambda} : \\mathbb{R}^{n} \\to \\mathbb{R}^{n}$，它被定义为 $\\ell_{1}$ 范数（绝对值之和）在参数 $\\lambda \\geq 0$ 下的邻近映射，即\n$$\n\\big(S_{\\lambda}(x)\\big)_{i} \\;=\\; \\operatorname{sign}(x_{i}) \\,\\max\\!\\big(|x_{i}| - \\lambda,\\, 0\\big), \\quad i = 1,\\dots,n.\n$$\n令 $k \\in \\{0,1,\\dots,n\\}$ 为一个目标支撑集大小。通过将 $\\{|x_{1}|,\\dots,|x_{n}|\\}$ 按严格降序排列，定义有序绝对值 $r_{(1)} > r_{(2)} > \\cdots > r_{(n)}$。从上述 $S_{\\lambda}$ 的基本定义以及顺序统计学和集合基数的基本原理出发，推导出一个闭式表达式，用于计算最小的阈值参数 $\\lambda^{\\star}$，使得软阈值化后的向量 $S_{\\lambda^{\\star}}(x)$ 恰好有 $k$ 个非零项。此外，在给定的 $x$ 各分量绝对值互不相同的假设下，严格证明此 $\\lambda^{\\star}$ 的唯一性。\n\n你的最终答案必须是一个用 $r_{(j)}$ 和 $k$ 表示 $\\lambda^{\\star}$ 的单一闭式解析表达式。不需要进行数值近似或四舍五入。",
            "solution": "问题要求推导一个闭式表达式，用于计算最小的阈值参数 $\\lambda^{\\star}$，使得软阈值化后的向量 $S_{\\lambda^{\\star}}(x)$ 恰好有 $k$ 个非零项。给定一个向量 $x \\in \\mathbb{R}^{n}$，其分量的绝对值两两不同，即对所有 $i \\neq j$ 都有 $|x_{i}| \\neq |x_{j}|$。\n\n首先，我们来分析软阈值算子的结构，它对每个分量 $i \\in \\{1, \\dots, n\\}$ 的定义如下：\n$$\n\\big(S_{\\lambda}(x)\\big)_{i} \\;=\\; \\operatorname{sign}(x_{i}) \\,\\max\\!\\big(|x_{i}| - \\lambda,\\, 0\\big)\n$$\n向量 $S_{\\lambda}(x)$ 中非零项的数目即为其支撑集大小，通常用 $\\ell_0$ 伪范数 $\\|S_{\\lambda}(x)\\|_0$ 表示。分量 $(S_{\\lambda}(x))_{i}$ 非零，当且仅当 $\\max(|x_{i}| - \\lambda, 0) > 0$。该不等式成立，当且仅当 $|x_{i}| - \\lambda > 0$，可简化为 $|x_{i}| > \\lambda$。\n\n因此，$S_{\\lambda}(x)$ 中非零项的数量就是其绝对值 $|x_i|$ 严格大于阈值 $\\lambda$ 的索引 $i$ 的数量。我们可以将这个数量定义为 $\\lambda$ 的函数：\n$$\nN(\\lambda) = \\|S_{\\lambda}(x)\\|_0 = \\left| \\left\\{ i \\in \\{1, \\dots, n\\} \\;\\middle|\\; |x_i| > \\lambda \\right\\} \\right|\n$$\n我们的目标是找到最小的 $\\lambda^{\\star} \\ge 0$ 使得 $N(\\lambda^{\\star}) = k$，其中 $k \\in \\{0, 1, \\dots, n\\}$ 是目标支撑集大小。这可以表述为寻找 $\\lambda^{\\star} = \\inf \\{ \\lambda \\ge 0 \\mid N(\\lambda) = k \\}$。\n\n题目说明绝对值 $|x_i|$ 是两两不同的。我们将这些绝对值的集合记为 $\\mathcal{M} = \\{|x_1|, |x_2|, \\dots, |x_n|\\}$。我们可以按题目要求，将这 $n$ 个不同的正值按严格降序排列：$r_{(1)} > r_{(2)} > \\cdots > r_{(n)} > 0$。严格不等式是给定条件 $|x_{i}| \\neq |x_{j}|$ (对 $i \\neq j$) 的直接结果。为了方便表示，我们用两个约定值来扩充这个序列：$r_{(0)} := \\infty$ 和 $r_{(n+1)} := 0$。\n\n函数 $N(\\lambda)$ 是一个非增、右连续的阶梯函数。在不包含任何绝对值 $r_{(j)}$ 的区间上，其值是恒定的。我们用这些有序绝对值来刻画 $N(\\lambda)$。对于给定的 $\\lambda \\ge 0$，$N(\\lambda)$ 计算了集合 $\\mathcal{M}$ 中有多少个值严格大于 $\\lambda$。\n\n考虑一个形式为 $[r_{(j+1)}, r_{(j)})$ 的区间，其中 $j \\in \\{0, 1, \\dots, n\\}$。对于此区间内的任何 $\\lambda$，我们有 $r_{(j+1)} \\le \\lambda  r_{(j)}$。集合 $\\mathcal{M}$ 中严格大于 $\\lambda$ 的绝对值恰好是 $\\{r_{(1)}, r_{(2)}, \\dots, r_{(j)}\\}$。这些绝对值的数量恰好是 $j$。因此，对于任何 $\\lambda \\in [r_{(j+1)}, r_{(j)})$，非零项的数量为 $N(\\lambda) = j$。\n\n我们正在寻找最小的 $\\lambda^{\\star}$，使得 $N(\\lambda^{\\star}) = k$。根据我们的分析，对于区间 $[r_{(k+1)}, r_{(k)})$ 中的所有 $\\lambda$，条件 $N(\\lambda) = k$ 都成立。我们来验证这一点。\n\\begin{itemize}\n    \\item 对于任何满足 $r_{(k+1)} \\le \\lambda  r_{(k)}$ 的 $\\lambda$，满足 $|x_i| > \\lambda$ 的绝对值 $|x_i|$ 为 $\\{r_{(1)}, \\dots, r_{(k)}\\}$。这样的绝对值恰好有 $k$ 个，所以 $N(\\lambda) = k$。\n    \\item 在左端点 $\\lambda = r_{(k+1)}$ 处，条件变为 $|x_i| > r_{(k+1)}$，这对于 $k$ 个绝对值 $\\{r_{(1)}, \\dots, r_{(k)}\\}$ 成立。所以，$N(r_{(k+1)}) = k$。\n    \\item 在右端点 $\\lambda = r_{(k)}$ 处，条件变为 $|x_i| > r_{(k)}$，这对于 $k-1$ 个绝对值 $\\{r_{(1)}, \\dots, r_{(k-1)}\\}$ 成立。所以，$N(r_{(k)}) = k-1$。\n\\end{itemize}\n因此，所有能产生恰好 $k$ 个非零项的 $\\lambda$ 值的集合是 $\\Lambda_k = \\{\\lambda \\ge 0 \\mid N(\\lambda) = k\\} = [r_{(k+1)}, r_{(k)})$。根据我们对 $r_{(0)}$ 和 $r_{(n+1)}$ 的定义，这对 $k \\in \\{0, 1, \\dots, n\\}$ 均成立。例如，当 $k=n$ 时，$\\Lambda_n = [r_{(n+1)}, r_{(n)}) = [0, r_{(n)})$。当 $k=0$ 时，$\\Lambda_0 = [r_{(1)}, r_{(0)}) = [r_{(1)}, \\infty)$。\n\n题目要求的是最小的此类阈值参数 $\\lambda^{\\star}$。这即是集合 $\\Lambda_k$ 的下确界。\n$$\n\\lambda^{\\star} = \\inf(\\Lambda_k) = \\inf\\big( [r_{(k+1)}, r_{(k)}) \\big) = r_{(k+1)}\n$$\n\n最后，我们必须证明此 $\\lambda^{\\star}$ 的唯一性。量 $\\lambda^{\\star}$ 被定义为实现目标稀疏度 $k$ 的*最小*阈值。根据定义，实数集的任何非空子集的下确界是唯一的。因此，证明的核心在于解释为什么对于 $k \\in \\{0, 1, \\dots, n\\}$ 的任何选择，集合 $\\Lambda_k$ 都保证非空。\n\n这个保证是由一个关键假设提供的，即绝对值 $|x_i|$ 是两两不同的。这意味着有序绝对值是严格递减的：$r_{(1)} > r_{(2)} > \\cdots > r_{(n)}$。随着 $\\lambda$ 的增加，它会逐一穿过这些绝对值阈值。支撑集大小函数 $N(\\lambda)$ 是一个阶梯函数，其值在每个不连续点 $\\lambda = r_{(j)}$ 处恰好减少 1。具体来说，对于任何 $j \\in \\{1,\\dots,n\\}$，$N(\\lambda) = j$ 对 $\\lambda \\in [r_{(j+1)}, r_{(j)})$ 成立，且 $N(r_{(j)}) = j-1$。这意味着当 $\\lambda$ 从 $0$ 扫描到 $\\infty$ 时，$N(\\lambda)$ 会取遍从 $n$ 到 $0$ 的所有整数值。\n\n因此，对于任何目标支撑集大小 $k \\in \\{0, 1, \\dots, n\\}$，总存在一个 $\\lambda$ 值的范围，使得 $N(\\lambda) = k$。这个集合就是非空区间 $\\Lambda_k = [r_{(k+1)}, r_{(k)})$。由于 $\\Lambda_k$ 非空且有下界，它有唯一的下确界。这个唯一的最小值是 $\\lambda^{\\star} = r_{(k+1)}$。\n\n如果不作差异性假设（例如，对于某个 $j$ 有 $r_{(j)} = r_{(j+1)}$），函数 $N(\\lambda)$ 在 $\\lambda=r_{(j)}$ 处会有一个大小为 2 或更大的跳跃，可能会跳过一些整数值。这将意味着对于某些目标大小 $k$，集合 $\\Lambda_k$ 将为空，从而解 $\\lambda^{\\star}$ 不存在。因此，差异性假设对于确保问题对所有 $k$ 都是适定的是至关重要的。\n\n综上所述，唯一的最小阈值参数的闭式表达式是 $\\lambda^{\\star} = r_{(k+1)}$。",
            "answer": "$$\\boxed{r_{(k+1)}}$$"
        },
        {
            "introduction": "在掌握了如何设置阈值之后，我们现在来探讨算子的稳定性。$S_{\\lambda}(x)$ 的输出对阈值参数 $\\lambda$ 的微小扰动有多敏感？本练习通过计算算子的灵敏度来深入探讨这一问题，这对于理解迭代算法中的误差传播以及参数设置不准确所带来的影响至关重要。",
            "id": "3470287",
            "problem": "考虑在压缩感知 (CS) 和稀疏优化中作为 $\\ell_{1}$ 范数的近端映射而产生的软阈值算子 $S_{\\lambda}$，它由标量最小化问题 $S_{\\lambda}(x) = \\underset{u \\in \\mathbb{R}}{\\arg\\min}\\;\\frac{1}{2}(u - x)^{2} + \\lambda |u|$ 定义，其中阈值参数 $\\lambda \\geq 0$，标量输入 $x \\in \\mathbb{R}$。从这个变分定义出发，推导 $S_{\\lambda}(x)$ 关于阈值参数 $\\lambda$ 的敏感度的几乎处处成立的表达式，即，计算 $\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x)$，其中 $x \\in \\mathbb{R}$ 且不包括可能不可微的点。然后，考虑向量情况，其中 $S_{\\lambda}$ 逐分量作用于 $z \\in \\mathbb{R}^{n}$。设给定 $z \\in \\mathbb{R}^{7}$ 为 $z = (1.3, -0.4, 0.9, -2.1, 0.75, 1.6, -0.85)^{\\top}$，并取 $\\lambda_{0} = 0.8$。在一个延拓步骤中，阈值被扰动为 $\\lambda_{1} = \\lambda_{0} + \\delta$，其中小增量 $\\delta = 0.05$。使用您推导出的敏感度，给出一个用 $\\ell_{2}$ 范数衡量的重建漂移 $\\|S_{\\lambda_{1}}(z) - S_{\\lambda_{0}}(z)\\|_{2}$ 的最坏情况上界。将该界表示为单个实数，并将您的答案四舍五入到四位有效数字。",
            "solution": "该问题包含两部分。首先，我们必须推导软阈值算子 $S_{\\lambda}(x)$ 关于阈值参数 $\\lambda$ 的敏感度。其次，我们必须使用这个结果来计算在给定向量和 $\\lambda$ 的小扰动下，算子输出变化的最坏情况上界。\n\n第一部分：敏感度 $\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x)$ 的推导。\n\n软阈值算子 $S_{\\lambda}(x)$ 被定义为最小化问题的解：\n$$S_{\\lambda}(x) = \\underset{u \\in \\mathbb{R}}{\\arg\\min} \\; f(u) = \\underset{u \\in \\mathbb{R}}{\\arg\\min} \\left( \\frac{1}{2}(u - x)^{2} + \\lambda |u| \\right)$$\n其中 $x \\in \\mathbb{R}$ 是输入，$\\lambda \\geq 0$ 是阈值参数。目标函数 $f(u)$ 是凸函数，因此可以通过将其关于 $u$ 的次梯度设为零来找到其最小值。$f(u)$ 的次梯度由下式给出：\n$$\\partial f(u) = u - x + \\lambda \\partial|u|$$\n绝对值函数 $\\partial|u|$ 的次梯度定义为：\n$$\\partial|u| = \\begin{cases} \\{1\\}  \\text{if } u > 0 \\\\ \\{-1\\}  \\text{if } u  0 \\\\ [-1, 1]  \\text{if } u = 0 \\end{cases}$$\n我们寻找使 $0 \\in \\partial f(u)$ 成立的 $u$ 值。我们分析关于 $u$ 的三种情况：\n\n情况1：$u > 0$。次梯度方程变为 $u - x + \\lambda(1) = 0$，解得 $u = x - \\lambda$。为使此解自洽，必须有 $u > 0$，这意味着 $x - \\lambda > 0$，即 $x > \\lambda$。\n\n情况2：$u  0$。次梯度方程变为 $u - x + \\lambda(-1) = 0$，解得 $u = x + \\lambda$。为保持一致性，必须有 $u  0$，这意味着 $x + \\lambda  0$，即 $x  -\\lambda$。\n\n情况3：$u = 0$。次梯度条件变为 $0 \\in 0 - x + \\lambda[-1, 1]$，化简为 $0 \\in -x + [-\\lambda, \\lambda]$。这意味着 $x$ 必须在区间 $[-\\lambda, \\lambda]$ 内，即 $|x| \\leq \\lambda$。\n\n结合这三种情况，我们得到软阈值算子的闭式表达式：\n$$S_{\\lambda}(x) = \\begin{cases} x - \\lambda  \\text{if } x > \\lambda \\\\ 0  \\text{if } |x| \\leq \\lambda \\\\ x + \\lambda  \\text{if } x  -\\lambda \\end{cases}$$\n这也可以紧凑地写成 $S_{\\lambda}(x) = \\text{sgn}(x) \\max(|x| - \\lambda, 0)$。\n\n现在，我们计算 $S_{\\lambda}(x)$ 关于 $\\lambda$ 的敏感度，即偏导数 $\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x)$。我们在 $S_{\\lambda}(x)$ 关于 $\\lambda$ 可微的区域内对其表达式求导。不可微点出现在 $|x| = \\lambda$ 处。我们考虑一个固定的 $x$ 并对 $\\lambda$ 求导。\n\n情况A：$|x| > \\lambda$。\n如果 $x > 0$ 且 $\\lambda  x$，则 $S_{\\lambda}(x) = x - \\lambda$。对 $\\lambda$ 求导得到：\n$$\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x) = \\frac{\\partial}{\\partial \\lambda} (x - \\lambda) = -1$$\n如果 $x  0$ 且 $\\lambda  -x = |x|$，则 $S_{\\lambda}(x) = x + \\lambda$。对 $\\lambda$ 求导得到：\n$$\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x) = \\frac{\\partial}{\\partial \\lambda} (x + \\lambda) = 1$$\n\n情况B：$|x| \\le \\lambda$。\n在这种情况下，$S_{\\lambda}(x) = 0$。对 $\\lambda$ 求导得到：\n$$\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x) = \\frac{\\partial}{\\partial \\lambda} (0) = 0$$\n\n总结导数的结果，我们有（几乎处处成立）：\n$$\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x) = \\begin{cases} -1  \\text{if } x > \\lambda \\\\ 0  \\text{if } |x|  \\lambda \\\\ 1  \\text{if } x  -\\lambda \\end{cases}$$\n这个结果对所有满足 $|x| \\neq \\lambda$ 的 $x, \\lambda$ 成立。通过将其与算子本身的输出联系起来，可以找到一个非常紧凑的敏感度表达式。注意到当 $x > \\lambda$ 时 $S_{\\lambda}(x) > 0$，当 $x  -\\lambda$ 时 $S_{\\lambda}(x)  0$，以及当 $|x| \\leq \\lambda$ 时 $S_{\\lambda}(x) = 0$，我们可以写出（使用约定 $\\text{sgn}(0)=0$）：\n$$\n\\frac{\\partial}{\\partial \\lambda} S_{\\lambda}(x) = -\\text{sgn}(S_{\\lambda}(x))\n$$\n这就是所求的几乎处处成立的敏感度表达式。\n\n第二部分：重建漂移的上界。\n\n给定向量 $z \\in \\mathbb{R}^{7}$，初始阈值 $\\lambda_{0} = 0.8$，新阈值 $\\lambda_{1} = \\lambda_{0} + \\delta = 0.8 + 0.05 = 0.85$。算子 $S_{\\lambda}$ 逐分量作用于 $z$。我们想要找到 $\\|S_{\\lambda_{1}}(z) - S_{\\lambda_{0}}(z)\\|_{2}$ 的一个最坏情况上界。\n\n设 $\\Delta S = S_{\\lambda_{1}}(z) - S_{\\lambda_{0}}(z)$。其第 $i$ 个分量为 $\\Delta S_i = S_{\\lambda_{1}}(z_i) - S_{\\lambda_{0}}(z_i)$。根据微积分基本定理，我们可以将这个差值写成敏感度的积分：\n$$\\Delta S_i = \\int_{\\lambda_{0}}^{\\lambda_{1}} \\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda} d\\lambda$$\n为了找到这个变化幅度的上界，我们使用积分的三角不等式：\n$$|\\Delta S_i| = \\left| \\int_{\\lambda_{0}}^{\\lambda_{1}} \\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda} d\\lambda \\right| \\leq \\int_{\\lambda_{0}}^{\\lambda_{1}} \\left| \\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda} \\right| d\\lambda$$\n敏感度的幅度为 $|\\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda}| \\in \\{0, 1\\}$。我们可以用区间长度乘以被积函数幅度的上确界来界定这个积分：\n$$|\\Delta S_i| \\leq (\\lambda_{1} - \\lambda_{0}) \\sup_{\\lambda \\in (\\lambda_0, \\lambda_1)} \\left| \\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda} \\right| = \\delta \\cdot M_i$$\n其中 $M_i = \\sup_{\\lambda \\in (\\lambda_0, \\lambda_1)} |\\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda}|$。\n\n“最坏情况”上界是通过对每个分量使用此上界得到的。漂移的 $\\ell_2$ 范数则被界定为：\n$$\\|S_{\\lambda_{1}}(z) - S_{\\lambda_{0}}(z)\\|_{2} = \\sqrt{\\sum_{i=1}^{7} (\\Delta S_i)^2} \\leq \\sqrt{\\sum_{i=1}^{7} (\\delta M_i)^2} = \\delta \\sqrt{\\sum_{i=1}^{7} M_i^2}$$\n我们需要为给定向量 $z = (1.3, -0.4, 0.9, -2.1, 0.75, 1.6, -0.85)^{\\top}$ 的每个分量确定 $M_i$。区间为 $(\\lambda_0, \\lambda_1) = (0.8, 0.85)$。\n敏感度 $\\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda}$ 非零当且仅当 $|z_i| > \\lambda$。\n- 如果 $|z_i| \\le \\lambda_0 = 0.8$，那么对于所有 $\\lambda \\in (\\lambda_0, \\lambda_1)$，我们有 $|z_i|  \\lambda$。因此，在整个积分区间上 $\\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda} = 0$，所以 $M_i = 0$。\n- 如果 $|z_i| > \\lambda_0 = 0.8$，那么至少在区间 $(\\lambda_0, \\lambda_1)$ 的一部分上（具体来说，对于 $\\lambda \\in (\\lambda_0, \\min(|z_i|, \\lambda_1))$），我们有 $|z_i| > \\lambda$。在这个区域， $|\\frac{\\partial S_{\\lambda}(z_i)}{\\partial \\lambda}| = 1$。因此，在该区间上幅度的上确界是 $M_i = 1$。\n\n让我们计算每个分量的 $|z_i|$ 并与 $\\lambda_0 = 0.8$ 进行比较：\n- $i=1$: $|z_1| = 1.3 > 0.8 \\implies M_1=1$。\n- $i=2$: $|z_2| = 0.4 \\le 0.8 \\implies M_2=0$。\n- $i=3$: $|z_3| = 0.9 > 0.8 \\implies M_3=1$。\n- $i=4$: $|z_4| = 2.1 > 0.8 \\implies M_4=1$。\n- $i=5$: $|z_5| = 0.75 \\le 0.8 \\implies M_5=0$。\n- $i=6$: $|z_6| = 1.6 > 0.8 \\implies M_6=1$。\n- $i=7$: $|z_7| = 0.85 > 0.8 \\implies M_7=1$。\n\n$M_i=1$ 的分量数量为 $5$ 个。因此，$\\sum_{i=1}^{7} M_i^2 = 1^2 + 0^2 + 1^2 + 1^2 + 0^2 + 1^2 + 1^2 = 5$。\n漂移的 $\\ell_2$ 范数的上界是：\n$$\\|S_{\\lambda_{1}}(z) - S_{\\lambda_{0}}(z)\\|_{2} \\leq \\delta \\sqrt{5} = 0.05 \\sqrt{5}$$\n现在，我们计算其数值并四舍五入到四位有效数字：\n$$0.05 \\times \\sqrt{5} \\approx 0.05 \\times 2.236067977 \\dots = 0.11180339885 \\dots$$\n四舍五入到四位有效数字得到 $0.1118$。",
            "answer": "$$\\boxed{0.1118}$$"
        },
        {
            "introduction": "从理想化的数学模型转向实际应用，我们必须考虑有限精度硬件带来的影响。本练习研究了输入、参数和输出的量化如何引入误差，并影响算子正确识别非零支撑集的能力。理解这些限制对于开发稳健可靠的稀疏信号处理系统是必不可少的。",
            "id": "3470295",
            "problem": "考虑软阈值算子 $S_{\\lambda}:\\mathbb{R}^{n}\\to\\mathbb{R}^{n}$，其定义为对分量 $i\\in\\{1,\\dots,n\\}$ 进行操作 $S_{\\lambda}(x)_{i}=\\operatorname{sign}(x_{i})\\max\\{|x_{i}|-\\lambda,0\\}$，其中 $\\lambda0$。一个有限精度实现对输入和输出使用步长为 $\\Delta0$ 的均匀量化，对阈值使用步长为 $\\Delta_{\\lambda}0$ 的均匀量化。定义量化器 $Q_{\\Delta}:\\mathbb{R}^{n}\\to\\mathbb{R}^{n}$ 为对每个分量 $i$ 进行 $Q_{\\Delta}(x)_{i}=\\Delta\\cdot\\operatorname{round}(x_{i}/\\Delta)$，其中 $\\operatorname{round}(\\cdot)$ 表示四舍五入到最近的整数，当出现平局时舍入到最近的偶数。定义量化阈值 $\\lambda_{q}=Q_{\\Delta_{\\lambda}}(\\lambda)$ 和实现的算子 $\\widehat{S}_{\\lambda}:\\mathbb{R}^{n}\\to\\mathbb{R}^{n}$ 为 $\\widehat{S}_{\\lambda}(x)=Q_{\\Delta}(S_{\\lambda_{q}}(Q_{\\Delta}(x)))$。在此实现中，支撑集识别通过规则 $I_{\\text{hat}}=\\{i\\in\\{1,\\dots,n\\}:\\,|Q_{\\Delta}(x_{i})|\\lambda_{q}\\}$ 进行，而 $S_{\\lambda}(x)$ 的精确支撑集为 $I=\\{i\\in\\{1,\\dots,n\\}:\\,|x_{i}|\\lambda\\}$。\n\n从近端算子是紧非扩张的（因此是 1-利普希茨的）以及函数 $a\\mapsto\\max\\{a,0\\}$ 是 1-利普希茨的这些基本事实出发，推导误差范数 $\\|\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x)\\|_{2}$ 的一个一致上界，该上界对所有 $x\\in\\mathbb{R}^{n}$ 成立，并用 $n$、$\\Delta$ 和 $\\Delta_{\\lambda}$ 表示。然后，评估在不可导点 $|x_{i}|=\\lambda$ 处的舍入如何影响支撑集识别，方法是确定最小的非负容差 $\\delta$，使得对于所有 $i$，蕴涵关系 $\\big||x_{i}|-\\lambda\\big|\\delta$ 能保证 $I_{\\text{hat}}=I$。此过程需基于所述的 $Q_{\\Delta}$ 舍入规则并使用支撑集测试 $|Q_{\\Delta}(x_{i})|\\lambda_{q}$（不要将输出舍入纳入支撑集测试）。将 $\\|\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x)\\|_{2}$ 的一致上界和容差 $\\delta$ 均以闭式解析表达式的形式给出。不需要进行数值计算。",
            "solution": "该问题要求两个与软阈值算子的有限精度实现相关的量。首先是实现误差范数 $\\|\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x)\\|_{2}$ 的一个一致上界。其次是保证正确支撑集识别的最小容差 $\\delta$。\n\n### 第 1 部分：一致误差界\n\n总误差可以分解为来自各个量化步骤的贡献。我们的目标是找到 $\\|\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x)\\|_{2}$ 的一个上界，其中 $\\widehat{S}_{\\lambda}(x) = Q_{\\Delta}(S_{\\lambda_{q}}(Q_{\\Delta}(x)))$。\n使用三角不等式，我们可以写出：\n$$\n\\|\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x)\\|_{2} = \\|Q_{\\Delta}(S_{\\lambda_{q}}(Q_{\\Delta}(x))) - S_{\\lambda}(x)\\|_{2}\n$$\n让我们引入中间项：\n$$\n\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x) = \\left( Q_{\\Delta}(S_{\\lambda_{q}}(Q_{\\Delta}(x))) - S_{\\lambda_{q}}(Q_{\\Delta}(x)) \\right) + \\left( S_{\\lambda_{q}}(Q_{\\Delta}(x)) - S_{\\lambda}(Q_{\\Delta}(x)) \\right) + \\left( S_{\\lambda}(Q_{\\Delta}(x)) - S_{\\lambda}(x) \\right)\n$$\n对这个和的 $\\ell_2$ 范数应用三角不等式，我们得到：\n$$\n\\|\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x)\\|_{2} \\le \\|Q_{\\Delta}(S_{\\lambda_{q}}(Q_{\\Delta}(x))) - S_{\\lambda_{q}}(Q_{\\Delta}(x))\\|_{2} + \\|S_{\\lambda_{q}}(Q_{\\Delta}(x)) - S_{\\lambda}(Q_{\\Delta}(x))\\|_{2} + \\|S_{\\lambda}(Q_{\\Delta}(x)) - S_{\\lambda}(x)\\|_{2}\n$$\n我们现在将对右侧的三个项分别进行界定。\n\n**第 1 项：输出量化误差**\n第一项 $\\|Q_{\\Delta}(y) - y\\|_{2}$（其中 $y = S_{\\lambda_{q}}(Q_{\\Delta}(x))$）表示最终输出量化带来的误差。量化器 $Q_{\\Delta}$ 按分量定义为 $Q_{\\Delta}(y)_i = \\Delta \\cdot \\operatorname{round}(y_i/\\Delta)$。舍入规则（平局取偶）确保对于任何实数 $z$，都有 $|\\operatorname{round}(z) - z| \\le \\frac{1}{2}$。\n因此，对每个分量 $i$：\n$$\n|Q_{\\Delta}(y)_i - y_i| = |\\Delta \\cdot \\operatorname{round}(y_i/\\Delta) - y_i| = \\Delta \\cdot |\\operatorname{round}(y_i/\\Delta) - y_i/\\Delta| \\le \\frac{\\Delta}{2}\n$$\n该误差向量的 $\\ell_2$ 范数的平方是各分量误差平方的和：\n$$\n\\|Q_{\\Delta}(y) - y\\|_{2}^{2} = \\sum_{i=1}^{n} (Q_{\\Delta}(y)_i - y_i)^2 \\le \\sum_{i=1}^{n} \\left(\\frac{\\Delta}{2}\\right)^2 = n \\frac{\\Delta^2}{4}\n$$\n取平方根得到第一项的上界：\n$$\n\\|Q_{\\Delta}(S_{\\lambda_{q}}(Q_{\\Delta}(x))) - S_{\\lambda_{q}}(Q_{\\Delta}(x))\\|_{2} \\le \\sqrt{n} \\frac{\\Delta}{2}\n$$\n\n**第 3 项：传播的输入量化误差**\n第三项 $\\|S_{\\lambda}(Q_{\\Delta}(x)) - S_{\\lambda}(x)\\|_{2}$ 表示输入量化通过理想算子 $S_{\\lambda}$ 传播后的影响。问题陈述指出软阈值算子 $S_{\\lambda}$ 是 1-利普希茨的。这是一个标准结果，因为 $S_{\\lambda}$ 是 $\\ell_1$ 范数的近端算子，而近端算子是紧非扩张的，因此是 1-利普希茨的。\n使用 $S_{\\lambda}$ 的 1-利普希茨性质：\n$$\n\\|S_{\\lambda}(Q_{\\Delta}(x)) - S_{\\lambda}(x)\\|_{2} \\le 1 \\cdot \\|Q_{\\Delta}(x) - x\\|_{2}\n$$\n输入量化器误差 $\\|Q_{\\Delta}(x) - x\\|_{2}$ 的界定方式与输出量化器误差相同：\n$$\n\\|Q_{\\Delta}(x) - x\\|_{2} \\le \\sqrt{n} \\frac{\\Delta}{2}\n$$\n因此，第三项的上界为：\n$$\n\\|S_{\\lambda}(Q_{\\Delta}(x)) - S_{\\lambda}(x)\\|_{2} \\le \\sqrt{n} \\frac{\\Delta}{2}\n$$\n\n**第 2 项：阈值量化误差**\n第二项 $\\|S_{\\lambda_{q}}(z) - S_{\\lambda}(z)\\|_{2}$（其中 $z=Q_{\\Delta}(x)$）表示由于使用量化阈值 $\\lambda_q$ 而非 $\\lambda$ 所引起的误差。让我们分析分量上的差异 $|S_{\\lambda_{q}}(z_i) - S_{\\lambda}(z_i)|$。\n$$\nS_{t}(a) = \\operatorname{sign}(a) \\max\\{|a|-t, 0\\}\n$$\n函数 $t \\mapsto S_t(a)$ 是 1-利普希茨的。要证明这一点，假设 $a \\ge 0$。我们需要界定 $|\\max\\{a-\\lambda_q, 0\\} - \\max\\{a-\\lambda, 0\\}|$。函数 $g(t)=\\max\\{c-t,0\\}$ 是 $t\\mapsto c-t$（1-利普希茨）和 $u\\mapsto\\max\\{u,0\\}$（1-利普希茨）的复合函数，因此 $g(t)$ 是 1-利普希茨的。于是，有 $|\\max\\{a-\\lambda_q, 0\\} - \\max\\{a-\\lambda, 0\\}| \\le |\\lambda_q - \\lambda|$。通过提出 $\\operatorname{sign}(a)$ 因子，此结论对任何 $a$（包括负值）都成立。\n所以，对每个分量 $i$：\n$$\n|S_{\\lambda_{q}}(z_i) - S_{\\lambda}(z_i)| \\le |\\lambda_q - \\lambda|\n$$\n量化阈值 $\\lambda$ 的误差为 $|\\lambda_q - \\lambda| = |Q_{\\Delta_{\\lambda}}(\\lambda) - \\lambda| \\le \\frac{\\Delta_{\\lambda}}{2}$。\n因此，有 $|S_{\\lambda_{q}}(z_i) - S_{\\lambda}(z_i)| \\le \\frac{\\Delta_{\\lambda}}{2}$。\n此误差的 $\\ell_2$ 范数的平方是：\n$$\n\\|S_{\\lambda_{q}}(z) - S_{\\lambda}(z)\\|_{2}^{2} = \\sum_{i=1}^{n} (S_{\\lambda_{q}}(z_i) - S_{\\lambda}(z_i))^2 \\le \\sum_{i=1}^{n} \\left(\\frac{\\Delta_{\\lambda}}{2}\\right)^2 = n \\frac{\\Delta_{\\lambda}^2}{4}\n$$\n取平方根得到第二项的上界：\n$$\n\\|S_{\\lambda_{q}}(Q_{\\Delta}(x)) - S_{\\lambda}(Q_{\\Delta}(x))\\|_{2} \\le \\sqrt{n} \\frac{\\Delta_{\\lambda}}{2}\n$$\n\n**总误差界**\n将三项的上界相加，我们得到总误差的一致上界：\n$$\n\\|\\widehat{S}_{\\lambda}(x)-S_{\\lambda}(x)\\|_{2} \\le \\sqrt{n} \\frac{\\Delta}{2} + \\sqrt{n} \\frac{\\Delta_{\\lambda}}{2} + \\sqrt{n} \\frac{\\Delta}{2} = \\sqrt{n} \\left(\\Delta + \\frac{\\Delta_{\\lambda}}{2}\\right)\n$$\n\n### 第 2 部分：支撑集识别容差\n\n我们需要找到最小的非负容差 $\\delta$，使得对于所有 $i \\in \\{1,\\dots,n\\}$，条件 $\\big||x_i| - \\lambda\\big| > \\delta$ 能够保证估计的支撑集 $I_{\\text{hat}} = \\{i: |Q_{\\Delta}(x_i)| > \\lambda_q\\}$ 等于真实的支撑集 $I = \\{i: |x_i| > \\lambda\\}$。\n这需要满足两个条件：\n1.  无假阴性：如果 $i \\in I$，则 $i \\in I_{\\text{hat}}$。\n2.  无假阳性：如果 $i \\notin I$，则 $i \\notin I_{\\text{hat}}$。\n\n量化误差的界如下：\n$|x_i - Q_{\\Delta}(x_i)| \\le \\frac{\\Delta}{2}$。由反三角不等式，可得 $||x_i| - |Q_{\\Delta}(x_i)|| \\le |x_i - Q_{\\Delta}(x_i)| \\le \\frac{\\Delta}{2}$，这意味着 $|x_i| - \\frac{\\Delta}{2} \\le |Q_{\\Delta}(x_i)| \\le |x_i| + \\frac{\\Delta}{2}$。\n$|\\lambda - \\lambda_q| \\le \\frac{\\Delta_{\\lambda}}{2} \\implies \\lambda - \\frac{\\Delta_{\\lambda}}{2} \\le \\lambda_q \\le \\lambda + \\frac{\\Delta_{\\lambda}}{2}$。\n\n**1. 无假阴性 ($I \\subseteq I_{\\text{hat}}$)**\n如果 $i \\in I$，则 $|x_i| > \\lambda$。容差条件 $\\big||x_i| - \\lambda\\big| > \\delta$ 意味着 $|x_i| > \\lambda + \\delta$。\n我们需要确保这能推导出 $|Q_{\\Delta}(x_i)| > \\lambda_q$。\n为了保证这一点，我们必须确保 $|Q_{\\Delta}(x_i)|$ 的最小可能值大于 $\\lambda_q$ 的最大可能值。\n$$\n\\min |Q_{\\Delta}(x_i)| > \\max \\lambda_q\n$$\n使用边界：\n$$\n|x_i| - \\frac{\\Delta}{2} > \\lambda + \\frac{\\Delta_{\\lambda}}{2} \\implies |x_i| > \\lambda + \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2}\n$$\n既然我们已知 $|x_i| > \\lambda + \\delta$，如果 $\\lambda + \\delta \\ge \\lambda + \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2}$，则该条件得到保证。为了使蕴涵关系对任何刚好超过阈值的 $|x_i|$ 都成立，不等式必须是非严格的。这得出的条件是 $\\delta \\ge \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2}$。\n\n**2. 无假阳性 ($I_{\\text{hat}} \\subseteq I$)**\n如果 $i \\notin I$，则 $|x_i| \\le \\lambda$。容差条件 $\\big||x_i| - \\lambda\\big| > \\delta$ 意味着 $|x_i|  \\lambda - \\delta$。\n我们需要确保这能推导出 $|Q_{\\Delta}(x_i)| \\le \\lambda_q$。\n为了保证这一点，我们必须确保 $|Q_{\\Delta}(x_i)|$ 的最大可能值小于或等于 $\\lambda_q$ 的最小可能值。\n$$\n\\max |Q_{\\Delta}(x_i)| \\le \\min \\lambda_q\n$$\n使用边界：\n$$\n|x_i| + \\frac{\\Delta}{2} \\le \\lambda - \\frac{\\Delta_{\\lambda}}{2} \\implies |x_i| \\le \\lambda - \\frac{\\Delta}{2} - \\frac{\\Delta_{\\lambda}}{2}\n$$\n既然我们已知 $|x_i|  \\lambda - \\delta$，如果 $\\lambda - \\delta \\le \\lambda - \\frac{\\Delta}{2} - \\frac{\\Delta_{\\lambda}}{2}$，则该条件得到保证。这得出 $-\\delta \\le -(\\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2})$，化简后为 $\\delta \\ge \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2}$。\n\n**最小容差 $\\delta$**\n两个条件都要求 $\\delta \\ge \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2}$。为了找到最小的非负 $\\delta$，我们取等式：\n$$\n\\delta = \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2}\n$$\n这个值确实是最小可能值。如果我们选择任何 $\\delta'  \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2}$，就有可能构造一个反例。例如，对于假阳性，我们可以选择 $\\lambda$ 和 $x_i$，使得量化误差在“错误”的方向上最大化：$\\lambda_q = \\lambda - \\frac{\\Delta_{\\lambda}}{2}$ 且 $Q_{\\Delta}(x_i) \\approx x_i + \\frac{\\Delta}{2}$。然后我们可以选择一个 $x_i$ 使得 $\\lambda - \\frac{\\Delta}{2} - \\frac{\\Delta_{\\lambda}}{2}  |x_i|  \\lambda - \\delta'$。对于这样的 $x_i$，我们有 $|x_i|  \\lambda - \\delta'$（满足 $i \\notin I$ 的容差条件），但是 $|Q_{\\Delta}(x_i)| \\approx |x_i| + \\frac{\\Delta}{2} > \\lambda - \\frac{\\Delta_{\\lambda}}{2} = \\lambda_q$，这是一个假阳性。一个对称的论证对假阴性也成立。因此，推导出的 $\\delta$ 值是最小可能值。\n\n所求的两个量是误差范数的一致上界和容差 $\\delta$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{n} \\left(\\Delta + \\frac{\\Delta_{\\lambda}}{2}\\right) \\\\ \\frac{\\Delta}{2} + \\frac{\\Delta_{\\lambda}}{2} \\end{pmatrix}}\n$$"
        }
    ]
}