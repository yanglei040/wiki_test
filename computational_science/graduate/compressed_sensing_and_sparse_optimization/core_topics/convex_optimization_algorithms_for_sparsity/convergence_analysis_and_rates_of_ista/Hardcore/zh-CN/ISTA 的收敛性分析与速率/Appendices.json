{
    "hands_on_practices": [
        {
            "introduction": "在深入探讨ISTA的长期收敛性之前，掌握单次迭代的计算机制至关重要。第一个练习提供了一个具体的计算实例，以巩固您的基础理解。通过手动计算一个迭代步骤，您将牢固掌握算法的几个核心构建模块：计算最小二乘损失的梯度、根据Lipschitz常数确定步长，以及应用软阈值算子 。",
            "id": "3438561",
            "problem": "考虑压缩感知和稀疏优化中的复合优化问题，旨在最小化函数 $F(x) = f(x) + \\lambda \\|x\\|_{1}$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$，且 $\\|\\cdot\\|_{1}$ 和 $\\|\\cdot\\|_{2}$ 分别表示 $\\ell_{1}$范数和欧几里得范数。迭代软阈值算法 (ISTA) 由近端梯度迭代定义：$x^{k+1} = S_{\\alpha \\lambda}\\!\\left(x^{k} - \\alpha \\nabla f(x^{k})\\right)$，其中 $S_{\\tau}$ 是阈值为 $\\tau$ 的软阈值算子，$\\alpha$ 是一个常数步长，其选择需满足基于 $\\nabla f$ 的 Lipschitz 连续性的理论收敛保证。\n\n从基本原理开始：\n- 最小二乘函数 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 的梯度由 $\\nabla f(x) = A^{\\top}(A x - b)$ 给出。\n- 梯度 $\\nabla f$ 是 Lipschitz 连续的，其 Lipschitz 常数为 $L = \\|A^{\\top} A\\|_{2}$，即 $A^{\\top} A$ 的谱范数（最大特征值）。\n- 软阈值算子 $S_{\\tau}$ 逐分量定义为 $S_{\\tau}(z)_{i} = \\operatorname{sign}(z_{i})\\max\\{|z_{i}| - \\tau, 0\\}$。\n\n设数据为\n$$\nA = \\begin{pmatrix}\n2  0 \\\\\n0  3 \\\\\n0  0\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n1 \\\\\n-6 \\\\\n0\n\\end{pmatrix}, \\quad\n\\lambda = 1, \\quad\nx^{0} = \\begin{pmatrix}\n\\frac{1}{3} \\\\\n-\\frac{1}{2}\n\\end{pmatrix}.\n$$\n选择常数步长 $\\alpha$ 为 $\\alpha = \\frac{1}{L}$，其中 $L$ 是由 $A$ 决定的 $\\nabla f$ 的 Lipschitz 常数。\n\n显式计算一次 ISTA 迭代，\n$$\nx^{1} = S_{\\alpha \\lambda}\\!\\left(x^{0} - \\alpha A^{\\top}(A x^{0} - b)\\right),\n$$\n并将得到的 $x^{1}$ 以单个行向量的形式给出。无需四舍五入；请提供精确的有理数值。",
            "solution": "该问题是有效的，因为它是稀疏优化领域中一个定义明确的数学练习，所有必要的数据和定义都已提供。它具有科学依据，内部一致且客观。\n\n目标是计算迭代软阈值算法 (ISTA) 的一次迭代，从给定的初始点 $x^{0}$ 开始，以求得 $x^{1}$。ISTA 的更新规则如下：\n$$\nx^{k+1} = S_{\\alpha \\lambda}\\!\\left(x^{k} - \\alpha \\nabla f(x^{k})\\right)\n$$\n对于我们的具体问题，我们需要使用 $k=0$ 来计算 $x^{1}$：\n$$\nx^{1} = S_{\\alpha \\lambda}\\!\\left(x^{0} - \\alpha \\nabla f(x^{0})\\right)\n$$\n函数 $f(x)$ 是最小二乘项 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$，其梯度为 $\\nabla f(x) = A^{\\top}(A x - b)$。\n\n首先，我们必须确定步长 $\\alpha$。问题指定 $\\alpha = \\frac{1}{L}$，其中 $L$ 是 $\\nabla f(x)$ 的 Lipschitz 常数。该 Lipschitz 常数由 $A^{\\top} A$ 的谱范数给出，记为 $L = \\|A^{\\top} A\\|_{2}$。\n\n给定的矩阵为 $A = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 0  0 \\end{pmatrix}$。其转置为 $A^{\\top} = \\begin{pmatrix} 2  0  0 \\\\ 0  3  0 \\end{pmatrix}$。\n我们计算乘积 $A^{\\top} A$：\n$$\nA^{\\top} A = \\begin{pmatrix} 2  0  0 \\\\ 0  3  0 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  9 \\end{pmatrix}\n$$\n对称（或在本例中，对角）矩阵的谱范数是其最大特征值的绝对值。对角矩阵 $\\begin{pmatrix} 4  0 \\\\ 0  9 \\end{pmatrix}$ 的特征值是其对角线元素，即 4 和 9。\n因此，Lipschitz 常数为 $L = \\max\\{4, 9\\} = 9$。\n步长为 $\\alpha = \\frac{1}{L} = \\frac{1}{9}$。\n\n接下来，我们计算 $f$ 在初始点 $x^{0} = \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix}$ 处的梯度。\n首先，计算 $A x^{0} - b$：\n$$\nA x^{0} = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 2(\\frac{1}{3}) \\\\ 3(-\\frac{1}{2}) \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{3}{2} \\\\ 0 \\end{pmatrix}\n$$\n已知 $b = \\begin{pmatrix} 1 \\\\ -6 \\\\ 0 \\end{pmatrix}$，我们有：\n$$\nA x^{0} - b = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{3}{2} \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ -6 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} - 1 \\\\ -\\frac{3}{2} + 6 \\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{9}{2} \\\\ 0 \\end{pmatrix}\n$$\n现在，我们计算梯度 $\\nabla f(x^{0}) = A^{\\top}(A x^{0} - b)$：\n$$\n\\nabla f(x^{0}) = \\begin{pmatrix} 2  0  0 \\\\ 0  3  0 \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{9}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2(-\\frac{1}{3}) \\\\ 3(\\frac{9}{2}) \\end{pmatrix} = \\begin{pmatrix} -\\frac{2}{3} \\\\ \\frac{27}{2} \\end{pmatrix}\n$$\n下一步是计算软阈值算子的参数，我们将其记为 $z$：\n$$\nz = x^{0} - \\alpha \\nabla f(x^{0}) = \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix} - \\frac{1}{9} \\begin{pmatrix} -\\frac{2}{3} \\\\ \\frac{27}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix} - \\begin{pmatrix} -\\frac{2}{27} \\\\ \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3} + \\frac{2}{27} \\\\ -\\frac{1}{2} - \\frac{3}{2} \\end{pmatrix}\n$$\n$$\nz = \\begin{pmatrix} \\frac{9}{27} + \\frac{2}{27} \\\\ -\\frac{4}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{11}{27} \\\\ -2 \\end{pmatrix}\n$$\n最后，我们应用软阈值算子 $S_{\\tau}(z)$，其阈值为 $\\tau = \\alpha \\lambda$。给定 $\\lambda = 1$ 和 $\\alpha = \\frac{1}{9}$，阈值为 $\\tau = \\frac{1}{9} \\cdot 1 = \\frac{1}{9}$。\n软阈值算子是逐分量应用的：$S_{\\tau}(z)_{i} = \\operatorname{sign}(z_{i})\\max\\{|z_{i}| - \\tau, 0\\}$。\n\n对于第一个分量，$z_1 = \\frac{11}{27}$：\n$$\nx^{1}_{1} = S_{1/9}\\left(\\frac{11}{27}\\right) = \\operatorname{sign}\\left(\\frac{11}{27}\\right) \\max\\left\\{\\left|\\frac{11}{27}\\right| - \\frac{1}{9}, 0\\right\\}\n$$\n因为 $\\frac{11}{27} > \\frac{1}{9}$ (即 $\\frac{11}{27} > \\frac{3}{27}$)，所以运算为：\n$$\nx^{1}_{1} = 1 \\cdot \\left(\\frac{11}{27} - \\frac{1}{9}\\right) = \\frac{11}{27} - \\frac{3}{27} = \\frac{8}{27}\n$$\n对于第二个分量，$z_2 = -2$：\n$$\nx^{1}_{2} = S_{1/9}(-2) = \\operatorname{sign}(-2) \\max\\left\\{|-2| - \\frac{1}{9}, 0\\right\\}\n$$\n因为 $|-2|=2 > \\frac{1}{9}$，所以运算为：\n$$\nx^{1}_{2} = -1 \\cdot \\left(2 - \\frac{1}{9}\\right) = -\\left(\\frac{18}{9} - \\frac{1}{9}\\right) = -\\frac{17}{9}\n$$\n因此，一次 ISTA 迭代的结果是向量 $x^{1} = \\begin{pmatrix} \\frac{8}{27} \\\\ -\\frac{17}{9} \\end{pmatrix}$。问题要求答案以单个行向量的形式给出。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{8}{27}  -\\frac{17}{9} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "ISTA的全局次线性收敛率往往不能完全描绘其在实践中的表现。在许多实际场景中，该算法会展现出一种两阶段行为：在有限步内识别出正确的稀疏模式（即“支撑集”），随后以更快的速度收敛。本练习将引导您通过一个精心构造的例子，亲眼见证这一现象，并理解严格互补性条件是如何实现有限时间支撑集识别，并最终切换到快速的局部线性收敛模式的 。",
            "id": "3438565",
            "problem": "考虑将迭代软阈值算法 (ISTA) 应用于压缩感知中的稀疏优化问题，该问题最小化目标函数\n$$\nF(x) \\triangleq f(x) + g(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1},\n$$\n其中 $A \\in \\mathbb{R}^{3 \\times 3}$，$y \\in \\mathbb{R}^{3}$，且 $\\lambda > 0$。光滑部分为 $f(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2}$，其梯度为 $\\nabla f(x) = A^{\\top}(A x - y)$，该梯度是 Lipschitz 连续的，常数为 $L = \\|A^{\\top}A\\|_{2}$。非光滑部分为 $g(x) = \\lambda \\|x\\|_{1}$，其邻近算子是软阈值算子。迭代软阈值算法 (ISTA) 的迭代过程为\n$$\nx^{k+1} = \\operatorname{prox}_{\\alpha_{k} g}\\big(x^{k} - \\alpha_{k} \\nabla f(x^{k})\\big),\n$$\n其中 $\\alpha_{k} > 0$ 通过标准的回溯程序选择，以确保基于 $\\nabla f$ 的局部 Lipschitz 连续性实现充分下降。在这种复合优化中，一个已知的现象是在严格互补性条件下，活动流形（支撑集和符号）的有限识别，此后迭代在已识别的流形上线性演化。\n\n构建以下具体实例。令\n$$\nA = \\begin{pmatrix}\n2  0  0\\\\\n0  2  0\\\\\n0  0  100\n\\end{pmatrix}, \\qquad y = \\begin{pmatrix} 2 \\\\ 2 \\\\ 0.005 \\end{pmatrix}, \\qquad \\lambda = 1.\n$$\n这一选择在科学上是现实的且内部一致的：与前两个变量对应的列被适度缩放且相互正交，而第三列非常大，从而产生一个大的全局 Lipschitz 常数。考虑带有回溯的 ISTA，在识别之后，它使用与已识别流形相关联的局部 Lipschitz 常数。\n\n任务：\n- 仅使用凸性、邻近算子和一阶最优性（Karush–Kuhn–Tucker 条件）的基本定义，证明唯一最小化子 $x^{\\star}$ 的支撑集为 $S = \\{1,2\\}$，其元素严格为正，且 $x_{3}^{\\star} = 0$。\n- 验证在非活动坐标 $3$ 上的严格互补性。\n- 从第一性原理出发，论证为什么在这些条件下 ISTA 能在有限次迭代中识别出 $S$ 和符号。\n- 一旦识别发生，描述限制在 $S$ 上的 ISTA 的局部线性迭代，并用 $A_{S}^{\\top}A_{S}$ 的谱以及回溯在流形上收敛到的可接受步长 $\\alpha$ 来表示其速率常数。\n- 对于此实例，计算识别后的局部线性收敛速率常数 $\\rho_{\\mathrm{local}}$ 的精确数值。以单个实数形式给出答案，无需四舍五入。",
            "solution": "该问题要求对一个应用于 LASSO 型目标函数的迭代软阈值算法 (ISTA) 的具体实例进行多部分分析。验证过程确认了该问题是适定的、有科学依据的，并提供了所有必要信息。我们按顺序处理每个任务来给出解答。\n\n需要最小化的目标函数是 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\|Ax - y\\|_{2}^{2}$ 且 $g(x) = \\lambda \\|x\\|_{1}$。给定的参数值为 $\\lambda = 1$ 和\n$$\nA = \\begin{pmatrix}\n2  0  0\\\\\n0  2  0\\\\\n0  0  100\n\\end{pmatrix}, \\qquad y = \\begin{pmatrix} 2 \\\\ 2 \\\\ 0.005 \\end{pmatrix}.\n$$\n光滑部分 $f(x)$ 的梯度是 $\\nabla f(x) = A^{\\top}(Ax - y)$。由于 $A$ 是一个对角矩阵，所以 $A^{\\top} = A$，因此 $\\nabla f(x) = A^2 x - Ay$。\n$$\nA^2 = \\begin{pmatrix}\n4  0  0\\\\\n0  4  0\\\\\n0  0  10000\n\\end{pmatrix}, \\qquad Ay = \\begin{pmatrix}\n4 \\\\\n4 \\\\\n0.5\n\\end{pmatrix}.\n$$\n梯度的分量为：\n$(\\nabla f(x))_1 = 4x_1 - 4$\n$(\\nabla f(x))_2 = 4x_2 - 4$\n$(\\nabla f(x))_3 = 10000x_3 - 0.5$\n\n### 任务 1：求唯一最小化子 $x^{\\star}$\n\n函数 $F(x)$ 是严格凸的，因为 $f(x)$ 是严格凸的（$A$ 可逆），且 $g(x)$ 是凸的。因此，存在唯一的最小化子 $x^{\\star}$。点 $x^{\\star}$ 成为最小化子的一阶最优性条件（或 Karush-Kuhn-Tucker 条件）表明 $0 \\in \\nabla f(x^{\\star}) + \\partial g(x^{\\star})$，其中 $\\partial g(x^{\\star})$ 是 $g(x)$ 在 $x^{\\star}$ 处的次微分。这等价于 $-\\nabla f(x^{\\star}) \\in \\partial (\\lambda \\|x\\|_1)|_{x=x^{\\star}}$。\n\n此条件可以按分量表示：\n1.  如果 $x_i^{\\star} \\ne 0$，则 $(\\nabla f(x^{\\star}))_i + \\lambda \\operatorname{sign}(x_i^{\\star}) = 0$。\n2.  如果 $x_i^{\\star} = 0$，则 $|(\\nabla f(x^{\\star}))_i| \\le \\lambda$。\n\n我们假设解的支撑集为 $S = \\{1,2\\}$，意味着 $x_1^{\\star} \\neq 0$，$x_2^{\\star} \\neq 0$，且 $x_3^{\\star} = 0$。我们进一步假设 $x_1^{\\star} > 0$ 且 $x_2^{\\star} > 0$。\n\n对于 $i=1$：我们应用条件 (1)，设 $\\operatorname{sign}(x_1^{\\star}) = 1$ 且 $\\lambda=1$。\n$(\\nabla f(x^{\\star}))_1 + 1 = 0 \\implies (4x_1^{\\star} - 4) + 1 = 0 \\implies 4x_1^{\\star} = 3 \\implies x_1^{\\star} = \\frac{3}{4}$。\n由于 $x_1^{\\star} = \\frac{3}{4} > 0$，我们的符号假设是一致的。\n\n对于 $i=2$：类似地，我们应用条件 (1)，设 $\\operatorname{sign}(x_2^{\\star}) = 1$。\n$(\\nabla f(x^{\\star}))_2 + 1 = 0 \\implies (4x_2^{\\star} - 4) + 1 = 0 \\implies 4x_2^{\\star} = 3 \\implies x_2^{\\star} = \\frac{3}{4}$。\n由于 $x_2^{\\star} = \\frac{3}{4} > 0$，这个符号假设也是一致的。\n\n对于 $i=3$：我们使用条件 (2) 检验我们的假设 $x_3^{\\star} = 0$。我们必须检查是否 $|(\\nabla f(x^{\\star}))_3| \\le \\lambda = 1$。\n我们将 $x_3^{\\star}=0$ 代入梯度分量的表达式中：\n$(\\nabla f(x^{\\star}))_3 = 10000x_3^{\\star} - 0.5 = 10000(0) - 0.5 = -0.5$。\n我们检查该条件：$|-0.5| = 0.5 \\le 1$。条件成立。\n\n候选解 $x^{\\star} = (\\frac{3}{4}, \\frac{3}{4}, 0)^{\\top}$ 满足所有条件。支撑集确实是 $S=\\{1,2\\}$，支撑集上的元素严格为正，且 $x_3^{\\star} = 0$。由于严格凸性，这是唯一的最小化子。\n\n### 任务 2：验证严格互补性\n\n对于一个非活动坐标 $j$（其中 $x_j^{\\star}=0$），严格互补性要求该坐标的次梯度条件以严格不等式成立。对于 $j=3$，我们必须验证 $|(\\nabla f(x^{\\star}))_3|  \\lambda$。\n从上一步中，我们计算出 $(\\nabla f(x^{\\star}))_3 = -0.5$ 并且给定 $\\lambda = 1$。\n条件是 $|-0.5|  1$，可简化为 $0.5  1$。这是成立的。\n因此，在非活动坐标 $j=3$ 上严格互补性成立。\n\n### 任务 3：活动流形的有限识别\n\nISTA 迭代由 $x^{k+1} = \\operatorname{prox}_{\\alpha_k g}(x^{k} - \\alpha_k \\nabla f(x^{k}))$ 给出。对于 $g(x) = \\lambda \\|x\\|_1$ 的邻近算子是分量形式的软阈值函数，$S_{\\alpha_k\\lambda}(z)_i = \\operatorname{sign}(z_i)\\max(|z_i|-\\alpha_k\\lambda, 0)$。\n一个坐标 $x_i^{k+1}$ 被设为零当且仅当 $|(x^k - \\alpha_k \\nabla f(x^k))_i| \\le \\alpha_k\\lambda$。\n\n由于 ISTA 是一个收敛算法，当 $k \\to \\infty$ 时，$x^k \\to x^{\\star}$。我们还假设在回溯线搜索中使用的步长 $\\alpha_k$ 收敛到一个正值 $\\alpha > 0$。令 $z^k = x^k - \\alpha_k \\nabla f(x^k)$。那么 $z^k \\to z^{\\star} = x^{\\star} - \\alpha \\nabla f(x^{\\star})$。\n\n我们来分析 $z^{\\star}$ 的分量：\n对于非活动坐标 $i=3$：\n$z_3^{\\star} = x_3^{\\star} - \\alpha (\\nabla f(x^{\\star}))_3 = 0 - \\alpha(-0.5) = 0.5\\alpha$。\n第 $3$ 个坐标被置零的条件是 $|z_3^k| \\le \\alpha_k \\lambda$。在极限情况下，这变成 $|z_3^{\\star}| \\le \\alpha\\lambda$，即 $|0.5\\alpha| \\le \\alpha(1)$，或 $0.5\\alpha \\le \\alpha$。对于 $\\alpha>0$，这个不等式是严格的。\n由于严格不等式 $0.5  1$（即严格互补性条件），根据连续性，对于任何足够大的 $k$，使得 $x^k$ 位于 $x^{\\star}$ 的一个足够小的邻域内且 $\\alpha_k$ 接近 $\\alpha$，我们将有 $|(x^k - \\alpha_k \\nabla f(x^k))_3|  \\alpha_k \\lambda$。一旦发生这种情况，$x_3^{k+1}$ 将精确地变为 $0$。在所有后续迭代中，它将保持为零，因为对于 $j > k$，第三个分量的迭代将是 $x_3^{j+1} = S_{\\alpha_j\\lambda}(-\\alpha_j (\\nabla f(x^j))_3)$，且其参数将保持在阈值区间 $[ -\\alpha_j\\lambda, \\alpha_j\\lambda ]$ 内。\n\n对于活动坐标 $i \\in S = \\{1,2\\}$：\n$z_i^{\\star} = x_i^{\\star} - \\alpha(\\nabla f(x^{\\star}))_i$。根据 KKT 条件，对于 $i=1,2$，有 $(\\nabla f(x^{\\star}))_i = -\\lambda \\operatorname{sign}(x_i^{\\star}) = -1$。\n$z_1^{\\star} = x_1^{\\star} - \\alpha(-1) = \\frac{3}{4} + \\alpha$。\n$z_2^{\\star} = x_2^{\\star} - \\alpha(-1) = \\frac{3}{4} + \\alpha$。\n由于 $\\alpha > 0$，我们有 $z_{1,2}^{\\star} > \\alpha = \\alpha\\lambda$。根据连续性，对于足够大的 $k$，有 $|z_{1,2}^k| > \\alpha_k\\lambda$。因此，$x_{1,2}^{k+1}$ 将是非零的。此外，由于 $z_{1,2}^k$ 将是正的，$x_{1,2}^{k+1}$ 的符号将是正的，与 $x_{1,2}^{\\star}$ 的符号相匹配。\n\n因此，由于解处的严格互补性，该算法将在有限次迭代中识别出正确的支撑集 $S=\\{1,2\\}$ 和符号。\n\n### 任务 4：局部线性迭代和收敛速率\n\n一旦算法对于 $k \\ge K$ 识别了活动流形（即，对于 $i \\notin S$，有 $x_i^k = 0$；对于 $i \\in S$，有 $\\operatorname{sign}(x_i^k) = \\operatorname{sign}(x_i^{\\star})$），迭代过程就简化了。令 $x_S$ 表示支撑集 $S=\\{1,2\\}$ 中的分量向量。对于 $k \\ge K$，我们有 $x_{S^c}^k = 0$ 且 $\\operatorname{sign}(x_S^k) = (1, 1)^{\\top}$。\n$x_S$ 的 ISTA 更新为：\n$$\nx_S^{k+1} = \\operatorname{prox}_{\\alpha g_S}(x_S^k - \\alpha \\nabla_S f(x^k))\n$$\n其中对于正的 $x_S$，$g_S(x_S) = \\lambda \\|x_S\\|_1 = \\lambda \\mathbf{1}^{\\top}x_S$，且 $\\alpha$ 是步长。限制在流形上的梯度为 $\\nabla_S f(x^k) = A_S^{\\top}(A_S x_S^k - y)$。邻近算子操作变成一个简单的平移：\n$$\nx_S^{k+1} = (x_S^k - \\alpha(A_S^{\\top}(A_S x_S^k - y))) - \\alpha\\lambda \\mathbf{1}.\n$$\n流形上的解 $x_S^{\\star}$ 是此迭代的一个不动点，满足：\n$$\nx_S^{\\star} = (x_S^{\\star} - \\alpha(A_S^{\\top}(A_S x_S^{\\star} - y))) - \\alpha\\lambda \\mathbf{1},\n$$\n这意味着 $A_S^{\\top}(A_S x_S^{\\star} - y) + \\lambda \\mathbf{1} = 0$，这与 KKT 条件一致。\n令误差为 $e^k = x_S^k - x_S^{\\star}$。从迭代方程中减去不动点方程，得到：\n$$\ne^{k+1} = e^k - \\alpha \\left( A_S^{\\top}A_S x_S^k - A_S^{\\top}A_S x_S^{\\star} \\right) = e^k - \\alpha A_S^{\\top}A_S e^k = (I - \\alpha A_S^{\\top}A_S) e^k.\n$$\n这是一个线性迭代。收敛速率由迭代矩阵 $M = I - \\alpha A_S^{\\top}A_S$ 的谱半径决定。局部线性收敛速率常数为 $\\rho_{\\mathrm{local}} = \\rho(M) = \\|I - \\alpha A_S^{\\top}A_S\\|_2$。\n$M$ 的特征值为 $1 - \\alpha\\mu_j$，其中 $\\mu_j$ 是 $A_S^{\\top}A_S$ 的特征值。因此，速率常数由以下公式给出：\n$$\n\\rho_{\\mathrm{local}} = \\max_j |1 - \\alpha \\mu_j(A_S^{\\top}A_S)| = \\max\\left( |1 - \\alpha \\mu_{\\min}(A_S^{\\top}A_S)|, |1 - \\alpha \\mu_{\\max}(A_S^{\\top}A_S)| \\right).\n$$\n\n### 任务 5：计算局部收敛速率的数值\n\n我们首先计算矩阵 $A_S^{\\top}A_S$。子矩阵 $A_S$ 由 $A$ 的前两列组成：\n$$\nA_S = \\begin{pmatrix} 2  0 \\\\ 0  2 \\\\ 0  0 \\end{pmatrix}.\n$$\n那么，\n$$\nA_S^{\\top}A_S = \\begin{pmatrix} 2  0  0 \\\\ 0  2  0 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  2 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  4 \\end{pmatrix} = 4I.\n$$\n$A_S^{\\top}A_S$ 的特征值为 $\\mu_1 = 4$ 和 $\\mu_2 = 4$。所以，$\\mu_{\\min}(A_S^{\\top}A_S) = \\mu_{\\max}(A_S^{\\top}A_S) = 4$。\n流形上梯度的局部 Lipschitz 常数为 $L_S = \\|A_S^{\\top}A_S\\|_2 = \\mu_{\\max}(A_S^{\\top}A_S) = 4$。\n问题陈述中提到使用了回溯法。ISTA 的标准回溯线搜索将接受任何步长 $\\alpha_k \\in (0, 1/L_S]$。该过程通常先尝试一个大步长然后减小它，因此预期它会收敛到满足下降条件的最大可能步长，即 $\\alpha = 1/L_S$。\n使用 $\\alpha = 1/L_S = 1/4$，我们计算速率常数：\n$$\n\\rho_{\\mathrm{local}} = \\max(|1 - \\alpha \\mu_1|, |1 - \\alpha \\mu_2|) = \\max\\left(\\left|1 - \\frac{1}{4} \\cdot 4\\right|, \\left|1 - \\frac{1}{4} \\cdot 4\\right|\\right) = \\max(|1-1|, |1-1|) = 0.\n$$\n速率常数为 $0$ 表明，一旦算法完全识别了活动流形并将其步长调整为局部常数 $L_S$，它将在单步内收敛。",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "在见证了ISTA收敛的“理想情况”后，理解其局限性也同等重要。本练习与前一个练习形成对照，旨在揭示当理想条件不被满足时会发生什么。您将构建一个违反严格互补性条件的特定案例，并通过推导迭代序列来证明，在这种情况下ISTA无法在有限时间内识别出解的零分量，从而突显了该条件对于实现快速局部收敛的必要性 。",
            "id": "3438522",
            "problem": "考虑一维最小绝对收缩和选择算子 (LASSO) 问题\n$$\\min_{x \\in \\mathbb{R}} \\; F(x) := \\frac{1}{2}\\,(x - b)^{2} + \\lambda\\,|x|,$$\n其中 $b \\in \\mathbb{R}$ 是一个给定的数据点，$\\lambda > 0$ 是正则化参数。步长为 $\\alpha \\in (0,1)$ 的迭代收缩阈值算法 (ISTA) 生成迭代序列\n$$x^{k+1} = \\operatorname{prox}_{\\alpha \\lambda |\\cdot|}\\big(x^{k} - \\alpha \\nabla f(x^{k})\\big), \\quad f(x) := \\frac{1}{2}\\,(x - b)^{2},$$\n其中，缩放后的绝对值的近端算子是软阈值映射\n$$S_{\\alpha'}(z) := \\operatorname{sign}(z)\\,\\max\\{|z| - \\alpha', 0\\}.$$\n要求在严格互补性失效的情况下，构造一个 ISTA 算法无法实现有限时间支撑集识别的反例。请按以下步骤进行。\n\n1. 将数据特殊化为 $b = \\lambda$ 的情况，并证明唯一极小化子是 $x^{\\star} = 0$。验证在 $x^{\\star}$ 处严格互补性失效，即 $|\\nabla f(x^{\\star})| = \\lambda$。\n2. 针对此一维实例，明确写出以 $\\alpha$、$\\lambda$、$b$ 和 $x^{k}$ 表示的 ISTA 更新规则，并在 $b = \\lambda$ 的特殊情况下进行简化。\n3. 假设初始点 $x^{0} > 0$。推导 ISTA 迭代序列 $x^{k}$ 作为 $k$、$\\alpha$ 和 $x^{0}$ 的函数的精确闭式表达式。仅使用上述定义和凸函数的标准最优性条件。\n\n你的最终答案必须是步骤 3 中推导出的 $x^{k}$ 的闭式解析表达式。无需四舍五入，不涉及单位。",
            "solution": "该问题要求针对一个特定的一维 LASSO 问题，推导迭代收缩阈值算法 (ISTA) 迭代序列的闭式表达式，该问题可作为严格互补性失效时有限时间支撑集识别失败的一个反例。我们将按照指定的三个步骤进行。\n\nLASSO 问题是求解 $x \\in \\mathbb{R}$ 的最小值问题 $F(x) := \\frac{1}{2}(x - b)^{2} + \\lambda|x|$，其中 $b \\in \\mathbb{R}$ 且 $\\lambda > 0$。函数 $F(x)$ 是一个严格凸函数 $f(x) = \\frac{1}{2}(x-b)^2$ 和一个凸函数 $g(x) = \\lambda|x|$ 的和。因此，$F(x)$ 是严格凸的，并拥有一个唯一的极小化子 $x^{\\star}$。\n\n**步骤 1：当 $b = \\lambda$ 时对极小化子和严格互补性的分析**\n\n唯一极小化子 $x^{\\star}$ 由一阶最优性条件 $0 \\in \\partial F(x^{\\star})$ 刻画，其中 $\\partial F(x)$ 是 $F(x)$ 的次微分。\n次微分由 $\\partial F(x) = \\nabla f(x) + \\partial g(x) = (x - b) + \\lambda \\partial|x|$ 给出。\n绝对值函数的次微分是：\n$$\n\\partial|x| =\n\\begin{cases}\n    \\{1\\}  &\\text{若 } x > 0 \\\\\n    [-1, 1]  &\\text{若 } x = 0 \\\\\n    \\{-1\\}  &\\text{若 } x < 0\n\\end{cases}\n$$\n最优性条件 $0 \\in (x^{\\star} - b) + \\lambda \\partial|x^{\\star}|$ 可以重写为 $b - x^{\\star} \\in \\lambda \\partial|x^{\\star}|$。我们分析 $x^{\\star}$ 的三种情况：\n1. 如果 $x^{\\star} > 0$：条件变为 $b - x^{\\star} = \\lambda$，这意味着 $x^{\\star} = b - \\lambda$。只有当 $x^{\\star} > 0$ 时，即 $b > \\lambda$ 时，这种情况才是自洽的。\n2. 如果 $x^{\\star} < 0$：条件变为 $b - x^{\\star} = -\\lambda$，这意味着 $x^{\\star} = b + \\lambda$。只有当 $x^{\\star} < 0$ 时，即 $b < -\\lambda$ 时，这种情况才是自洽的。\n3. 如果 $x^{\\star} = 0$：条件变为 $b - 0 \\in \\lambda[-1, 1]$，这等价于 $|b| \\le \\lambda$。\n\n问题指定了 $b = \\lambda$ 的情况。因为 $\\lambda > 0$，我们有 $|b| = |\\lambda| = \\lambda$，满足条件 $|b| \\le \\lambda$。因此，我们属于第三种情况，唯一极小化子是 $x^{\\star} = 0$。\n\n接下来，我们验证严格互补性的失效。对于一个解 $x^\\star$，若其分量 $x^\\star_i=0$，则严格互补性成立的条件是，光滑部分梯度的相应分量 $\\nabla_i f(x^\\star)$ 严格位于非光滑部分在 $x^\\star$ 处次微分的内部。在我们的一维情况中，当 $x^\\star=0$ 时，此条件为 $|\\nabla f(x^{\\star})| < \\lambda$。\n光滑部分的梯度是 $\\nabla f(x) = x - b$。\n在极小化子 $x^{\\star} = 0$ 处，梯度为 $\\nabla f(0) = 0 - b = -b$。\n在 $b = \\lambda$ 的特殊情况下，我们有 $\\nabla f(x^{\\star}) = -\\lambda$。\n其大小为 $|\\nabla f(x^{\\star})| = |-\\lambda| = \\lambda$。\n严格互补性条件会要求 $\\lambda < \\lambda$，这是不成立的。我们有 $|\\nabla f(x^{\\star})| = \\lambda$，这是严格互补性失效的边界情况。\n\n**步骤 2：$b = \\lambda$ 时的 ISTA 更新规则**\n\n一般的 ISTA 更新规则由\n$$x^{k+1} = \\operatorname{prox}_{\\alpha \\lambda |\\cdot|}\\left(x^{k} - \\alpha \\nabla f(x^{k})\\right)$$\n给出，其中 $\\alpha \\in (0,1)$ 是步长。由 $\\alpha$ 缩放的 $g(x) = \\lambda|x|$ 的近端算子是软阈值算子 $S_{\\alpha\\lambda}(z)$。\n算子的自变量是 $x^{k} - \\alpha \\nabla f(x^{k}) = x^{k} - \\alpha(x^{k}-b) = (1-\\alpha)x^{k} + \\alpha b$。\n所以，更新公式是 $x^{k+1} = S_{\\alpha\\lambda}((1-\\alpha)x^{k} + \\alpha b)$。\n特殊化到 $b=\\lambda$ 的情况，更新规则变为：\n$$x^{k+1} = S_{\\alpha\\lambda}((1-\\alpha)x^{k} + \\alpha\\lambda)$$\n\n**步骤 3：迭代序列 $x^{k}$ 的闭式表达式**\n\n我们被要求在假设初始点 $x^{0} > 0$ 的情况下推导 $x^{k}$ 的表达式。我们使用步骤 2 中的递推关系。\n软阈值算子定义为 $S_{\\alpha'}(z) = \\operatorname{sign}(z)\\max\\{|z| - \\alpha', 0\\}$。我们通过归纳法进行证明。基础情况是 $x^{0} > 0$。\n我们假设对于某个 $k \\ge 0$，有 $x^{k} > 0$。我们来分析下一个迭代值 $x^{k+1}$。\n软阈值函数的自变量是 $z^{k} = (1-\\alpha)x^{k} + \\alpha\\lambda$。\n给定 $\\alpha \\in (0,1)$，我们有 $1-\\alpha > 0$。同时，$\\lambda > 0$。根据我们的归纳假设，$x^{k} > 0$。\n因此，$z^{k}$ 表达式中的每一项都是正的，这意味着 $z^{k} > 0$。\n更具体地说，由于 $(1-\\alpha)x^k > 0$，我们有 $z^k = (1-\\alpha)x^k + \\alpha\\lambda > \\alpha\\lambda$。\n对于一个正的自变量 $z > 0$，软阈值算子简化为 $S_{\\alpha'}(z) = \\max\\{z - \\alpha', 0\\}$。\n在我们的情况中，$\\alpha' = \\alpha\\lambda$ 且自变量是 $z^k$。\n$$x^{k+1} = \\max\\{z^{k} - \\alpha\\lambda, 0\\}$$\n代入 $z^k$ 的表达式：\n$$x^{k+1} = \\max\\{( (1-\\alpha)x^{k} + \\alpha\\lambda ) - \\alpha\\lambda, 0\\} = \\max\\{(1-\\alpha)x^{k}, 0\\}$$\n由于 $1-\\alpha > 0$ 且我们假设了 $x^{k} > 0$，项 $(1-\\alpha)x^{k}$ 是严格为正的。\n因此，最大值就是该项本身：\n$$x^{k+1} = (1-\\alpha)x^{k}$$\n这证实了我们的归纳步骤：如果 $x^{k} > 0$，那么 $x^{k+1} > 0$。由于我们从 $x^{0} > 0$ 开始，因此对于所有 $k \\ge 0$ 都有 $x^{k} > 0$。\n递推关系 $x^{k+1} = (1-\\alpha)x^{k}$ 是一个简单的等比数列。我们可以将其展开以找到闭式解：\n$x^{1} = (1-\\alpha)x^{0}$\n$x^{2} = (1-\\alpha)x^{1} = (1-\\alpha)^2 x^{0}$\n依此类推。对于任何整数 $k \\ge 0$，迭代值由以下公式给出：\n$$x^{k} = (1-\\alpha)^{k} x^{0}$$\n这就是所求的闭式表达式。由于 $\\alpha \\in (0,1)$，我们有 $0 < 1-\\alpha < 1$，所以当 $k \\to \\infty$ 时，$x^k \\to 0 = x^\\star$。然而，对于任何有限的 $k$，$x^k$ 永远不会精确地等于 $0$，这表明解的支撑集无法在有限时间内被识别。",
            "answer": "$$\\boxed{(1-\\alpha)^{k} x^{0}}$$"
        }
    ]
}