{
    "hands_on_practices": [
        {
            "introduction": "在分析 OMP 的性能之前，我们必须牢固掌握如何量化字典的结构。这项练习将训练我们计算互相关性（mutual coherence, $\\mu$）和累积相关性（cumulative coherence, $\\mu_1(s)$）这两个基本指标，对象是一个在理论上很重要的特例——等角字典（equiangular dictionary）。通过完成这个计算，你将对这些值如何源于字典原子（atom）的几何结构建立起直观的理解。",
            "id": "3441533",
            "problem": "考虑一个字典矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其列向量为 $\\{a_{1}, \\dots, a_{n}\\}$，其中每一列都是单位范数，即对所有 $j \\in \\{1, \\dots, n\\}$ 都有 $\\|a_{j}\\|_{2} = 1$。假设该字典是等角的，即对于所有不同的索引 $i \\neq j$，其内积的绝对值满足 $|\\langle a_{i}, a_{j} \\rangle| = c$，其中 $c$ 为某个固定的常数且 $c \\in [0,1)$。在压缩感知的背景下，$A$ 的互相关性 $\\mu(A)$ 定义为不同列之间内积绝对值的最大值。累积相关性（也称为巴别函数）$\\mu_{1}(s)$ 定义为，对所有大小为 $s$ 的索引集合，以及所有不在此集合中的列索引，该列与该集合索引的 $s$ 个列的内积绝对值之和的最大值。\n\n从互相关性和累积相关性的基本定义出发，对上述等角字典进行完整推导，以 $c$ 和 $s$ 的形式显式计算 $\\mu(A)$ 和 $\\mu_{1}(s)$，并验证恒等式 $\\mu_{1}(s) = s c$。以解析表达式的形式给出最终答案。无需四舍五入，不涉及单位。您的最终答案必须列出 $\\mu(A)$ 和 $\\mu_{1}(s)$ 对。",
            "solution": "根据要求的协议，将首先通过仔细审查其前提和定义来验证问题陈述。\n\n**第一步：提取已知条件**\n问题提供了以下数据和定义：\n- 一个字典矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其列向量为 $\\{a_{1}, \\dots, a_{n}\\}$。\n- 列向量是单位范数：对所有 $j \\in \\{1, \\dots, n\\}$，都有 $\\|a_{j}\\|_{2} = 1$。\n- 该字典是等角的：对于所有不同的索引 $i \\neq j$，内积的绝对值为 $|\\langle a_{i}, a_{j} \\rangle| = c$，其中 $c$ 是一个满足 $c \\in [0,1)$ 的固定常数。\n- 互相关性的定义：$\\mu(A) = \\max_{i \\neq j} |\\langle a_{i}, a_{j} \\rangle|$。\n- 累积相关性（巴别函数）的定义：$\\mu_{1}(s) = \\max_{|S|=s} \\max_{j \\notin S} \\sum_{i \\in S} |\\langle a_{j}, a_{i} \\rangle|$。\n\n**第二步：使用提取的已知条件进行验证**\n根据所需标准对问题进行评估：\n- **科学依据：** 该问题牢固地植根于压缩感知和稀疏表示的数学理论。字典、互相关性、累积相关性和等角性等概念在该领域都是标准且明确定义的。没有违反科学或数学原则的地方。\n- **适定性：** 这是一个适定问题。它提供了唯一确定量 $\\mu(A)$ 和 $\\mu_{1}(s)$ 所需的所有定义和条件。任务是基于给定的定义和字典的特定结构进行直接计算。\n- **客观性：** 语言正式、精确且客观，使用了标准的数学术语。没有主观或含糊不清的陈述。\n\n经查，该问题不存在任何指出的缺陷（科学上不合理、非形式化、设置不完整、不切实际、不适定、伪深刻、无法验证）。等角字典存在的假设是该领域理论分析中的一种标准手段。\n\n**第三步：结论与行动**\n该问题被判定为**有效**。现在将提供一个完整的、有理有据的解答。\n\n**互相关性 $\\mu(A)$ 的推导**\n\n字典矩阵 $A$ 的互相关性定义为矩阵中任意两个不同列之间内积绝对值的最大值。其形式化定义为：\n$$\n\\mu(A) = \\max_{1 \\le i  j \\le n} |\\langle a_i, a_j \\rangle|\n$$\n问题陈述该字典是等角的。这是一个特定的结构属性，其定义条件是：对于任意一对不同的列索引 $i \\neq j$，它们内积的绝对值是一个常数 $c$。即：\n$$\n|\\langle a_i, a_j \\rangle| = c \\quad \\text{对所有 } i \\neq j\n$$\n将此条件直接代入互相关性的定义中，我们观察到取最大值的值集合 $\\{|\\langle a_i, a_j \\rangle| : i \\neq j\\}$ 只包含一个元素，即常数 $c$。因此，这个集合的最大值显然是 $c$。\n$$\n\\mu(A) = \\max_{i \\neq j} \\{c\\} = c\n$$\n因此，对于一个等角字典，其互相关性恰好是成对内积绝对值的那个常数值。\n\n**累积相关性 $\\mu_{1}(s)$ 的推导**\n\n累积相关性，或称巴别函数 $\\mu_{1}(s)$，衡量的是单个列与另外 $s$ 个列的集合之间的最大累积相关性。其形式化定义为：\n$$\n\\mu_{1}(s) = \\max_{S \\subset \\{1, \\dots, n\\}, |S|=s} \\left( \\max_{j \\notin S} \\sum_{i \\in S} |\\langle a_j, a_i \\rangle| \\right)\n$$\n为了对给定的等角字典计算这个值，我们首先分析最内层的和 $\\sum_{i \\in S} |\\langle a_j, a_i \\rangle|$，其中 $S$ 是一个基数为 $|S|=s$ 的任意索引集，而 $j$ 是一个不属于 $S$ 的任意索引。\n\n根据字典的等角性质，对于任何索引 $i \\in S$ 和任何索引 $j \\notin S$，索引 $i$ 和 $j$ 必然是不同的。问题陈述保证了对于任何不同的索引，都有 $|\\langle a_j, a_i \\rangle| = c$。\n因此，求和中的每一项都等于常数 $c$：\n$$\n|\\langle a_j, a_i \\rangle| = c \\quad \\text{对所有 } i \\in S \\text{ 和 } j \\notin S\n$$\n现在，这个和可以重写为：\n$$\n\\sum_{i \\in S} |\\langle a_j, a_i \\rangle| = \\sum_{i \\in S} c\n$$\n由于集合 $S$ 恰好包含 $s$ 个元素（即 $|S|=s$），该和由 $s$ 个相同的项组成，每一项都等于 $c$。因此，和的值为：\n$$\n\\sum_{i \\in S} c = s \\cdot c\n$$\n关键在于，这个结果 $sc$ 与索引集 $S$ 的具体选择（只要其基数为 $s$）以及索引 $j$ 的具体选择（只要 $j$ 不在 $S$ 中）无关。\n\n现在，我们必须应用 $\\mu_1(s)$ 定义中的最大化算子：\n$$\n\\mu_{1}(s) = \\max_{|S|=s} \\left( \\max_{j \\notin S} (sc) \\right)\n$$\n由于待最大化的表达式 $sc$ 对于任何有效的 $S$ 和 $j$ 的选择都是一个常数值，因此最大化操作是平凡的。一个常数值的最大值就是它本身。\n$$\n\\max_{j \\notin S} (sc) = sc\n$$\n并随后，\n$$\n\\max_{|S|=s} (sc) = sc\n$$\n这样就完成了推导，并验证了问题陈述中提出的恒等式。对于一个参数为 $c$ 的等角字典，其累积相关性函数是 $s$ 的一个线性函数：\n$$\n\\mu_{1}(s) = sc\n$$\n\n最终答案要求给出 $\\mu(A)$ 和 $\\mu_{1}(s)$ 的显式表达式。根据以上推导，它们分别是 $\\mu(A) = c$ 和 $\\mu_1(s) = sc$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nc  sc\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "OMP 的理论保证通常是在字典列向量为单位范数的假设下推导的，但为什么这个假设如此关键？这个实践问题将通过代码向你展示，OMP 的选择准则对列范数高度敏感，即使在简单情况下也可能导致恢复失败。通过探索不同的归一化策略，你将深入理解如何稳定算法，以避免原子尺度的误导性变化。",
            "id": "3441539",
            "problem": "设 $A \\in \\mathbb{R}^{m \\times n}$ 是一个字典，其列向量 $a_j \\in \\mathbb{R}^m$ 不一定被归一化。考虑将正交匹配追踪（OMP）算法（Orthogonal Matching Pursuit (OMP)）应用于测量值 $y = A x^\\star + e$，其中 $x^\\star \\in \\mathbb{R}^n$ 是 k-稀疏的，$e \\in \\mathbb{R}^m$ 是噪声，且 $k \\in \\mathbb{N}$ 是已知的。OMP 在第 $t$ 次迭代的选择步骤中，会选择使绝对内积 $|\\langle a_j, r^{(t)} \\rangle|$ 最大化的索引 $j$，其中 $r^{(t)}$ 是当前的残差。这个选择规则对列范数 $\\|a_j\\|_2$ 很敏感，因为 $|\\langle a_j, r^{(t)} \\rangle|$ 会随着 $\\|a_j\\|_2$ 缩放。定义以下相干性概念：\n- 标准的互相关性（在列归一化后计算）为\n$$\n\\mu(A) = \\max_{i \\neq j} \\left| \\frac{a_i^\\top a_j}{\\|a_i\\|_2 \\, \\|a_j\\|_2} \\right|.\n$$\n- 未归一化的相干性为\n$$\n\\tilde{\\mu}(A) = \\max_{i \\neq j} \\left| a_i^\\top a_j \\right|.\n$$\n为了减轻列范数不均匀的影响，考虑一个由 $\\alpha \\in [0,1]$ 参数化的幂归一化对角缩放族：构建缩放后的字典 $B_\\alpha$，其列向量为 $b_j = a_j / \\|a_j\\|_2^{\\alpha}$。注意，$\\alpha = 0$ 使 $A$ 保持不变，$\\alpha = 1$ 将所有列归一化为单位范数，而中间的 $\\alpha$ 值则部分地减弱了列范数的差异。\n\n您的任务是设计并实现一个程序，对于一个固定的问题实例测试套件，通过以下方式量化列归一化如何改变 OMP 的正确性和稳定性：\n1. 计算 $\\mu(A)$ 和 $\\tilde{\\mu}(A)$。\n2. 在 $B_\\alpha$ 上对 $\\alpha \\in \\{0, 1\\}$ 这两个选项运行 OMP，以获得两个正确性指标（精确支撑集恢复）。\n3. 在 $\\alpha \\in \\{0, 0.5, 1\\}$ 中搜索能恢复精确支撑集的最小指数 $\\alpha^\\star$。\n\n使用以下精确的定义和假设：\n- OMP 迭代 $k$ 步，其中 $k$ 是真实的稀疏度；在每一步中，它从未被选择的索引中选择一个使 $|\\langle b_j, r^{(t)} \\rangle|$ 最大的新列，并通过选择最小的索引来打破平局。每次选择后，它会在所选支撑集上重新计算最小二乘拟合，并更新残差。\n- 精确支撑集恢复意味着 OMP 在 $k$ 次迭代后选择的索引集合等于 $x^\\star$ 的支撑集。\n- 对于每个测试用例，在 $A$ 的列归一化版本上计算 $\\mu(A)$（即在将每列缩放至单位范数之后），并在原始未缩放的 $A$ 上计算 $\\tilde{\\mu}(A)$。\n- 噪声 $e$ 对每个测试用例是任意但固定的；本问题中没有物理单位。\n\n测试套件：\n- 测试用例 T1（具有严重范数不平衡的理想情况，会误导未归一化的 OMP）：\n  - $m = 3$, $n = 5$。\n  - 列向量：\n    - $a_1 = (1, 0, 0)^\\top$，\n    - $a_2 = (0, 1, 0)^\\top$，\n    - $a_3 = (0, 0, 1)^\\top$，\n    - $a_4 = (1, 1, 0)^\\top$，\n    - $a_5 = 10 \\cdot (0.25, 0.25, \\sqrt{0.875})^\\top$。\n  - 信号：$x^\\star = (1, 1, 0, 0, 0)^\\top$，稀疏度 $k = 2$。\n  - 噪声：$e = (0, 0, 0)^\\top$。\n\n- 测试用例 T2（原始缩放下的边界情况；小噪声会在不缩放的情况下错误地打破平局）：\n  - $m = 3$, $n = 3$。\n  - 列向量：\n    - $a_1 = (1, 0, 0)^\\top$，\n    - $a_2 = 5 \\cdot (0.2, 0, \\sqrt{0.96})^\\top$，\n    - $a_3 = (0, 1, 0)^\\top$。\n  - 信号：$x^\\star = (1, 0, 0)^\\top$，稀疏度 $k = 1$。\n  - 噪声：$e = (0, 0, 0.02)^\\top$。\n\n- 测试用例 T3（中等相干性和轻微范数变化；原始和归一化 OMP 都稳定）：\n  - $m = 4$, $n = 6$。\n  - 列向量：\n    - $a_1 = (1, 0, 0, 0)^\\top$，\n    - $a_2 = (0, 1, 0, 0)^\\top$，\n    - $a_3 = (0, 0, 1, 0)^\\top$，\n    - $a_4 = (0, 0, 0, 1)^\\top$，\n    - $a_5 = 0.5 \\cdot (1, 1, 0, 0)^\\top$，\n    - $a_6 = 0.5 \\cdot (0, 1, 1, 0)^\\top$。\n  - 信号：$x^\\star = (1.2, 0, 0.8, 0, 0, 0)^\\top$，稀疏度 $k = 2$。\n  - 噪声：$e = (0.01, -0.02, 0.015, 0)^\\top$。\n\n程序要求：\n- 对于每个测试用例，程序必须输出一个列表 $[\\mu(A), \\tilde{\\mu}(A), s_0, s_1, \\alpha^\\star]$，其中 $s_0$ 是一个布尔值，指示使用 $\\alpha = 0$ 的 OMP 是否精确恢复支撑集，$s_1$ 是一个布尔值，指示使用 $\\alpha = 1$ 的 OMP 是否精确恢复支撑集，而 $\\alpha^\\star$ 是在 $\\{0, 0.5, 1\\}$ 中使 OMP 实现精确支撑集恢复的最小值；如果无一成功，则为 $\\alpha^\\star$ 输出 $-1$。值 $\\mu(A)$ 和 $\\tilde{\\mu}(A)$ 必须是浮点数。\n- 您的程序应生成单行输出，其中包含 T1、T2 和 T3 的结果，格式为一个由方括号括起来的、以逗号分隔的各测试用例列表的列表，例如：$[[\\dots],[\\dots],[\\dots]]$。",
            "solution": "该问题要求分析正交匹配追踪（OMP）算法在给定传感矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的不同列归一化策略下的性能。性能评估基于对已知 k-稀疏信号 $x^\\star$ 从测量值 $y = A x^\\star + e$（其中 $e$ 是噪声）中的精确支撑集恢复。\n\n任务的核心是实现 OMP 算法，并在一个缩放字典族 $B_\\alpha$ 上进行测试，其中 $B_\\alpha$ 的列向量由 $b_j = a_j / \\|a_j\\|_2^{\\alpha}$ 给出，$\\alpha \\in \\{0, 0.5, 1\\}$。我们还将为原始字典 $A$ 计算两个相干性度量：标准的互相关性 $\\mu(A)$ 和未归一化的相干性 $\\tilde{\\mu}(A)$。\n\n解决方案按以下步骤进行：\n1. 对于每个测试用例，我们首先按定义计算相干性 $\\mu(A)$ 和 $\\tilde{\\mu}(A)$。\n2. 然后我们实现 OMP 算法。\n3. 对于每个指定的 $\\alpha \\in \\{0, 0.5, 1\\}$ 值，我们运行 OMP 进行 $k$ 次迭代。\n4. 对于每次运行，我们将 OMP 选择的支撑集与 $x^\\star$ 的真实支撑集进行比较，以确定恢复是否精确。\n5. 最后，我们将结果整理成指定的输出格式。\n\n**1. 相干性计算**\n- 标准的互相关性 $\\mu(A)$ 定义为 $\\mu(A) = \\max_{i \\neq j} \\left| \\frac{a_i^\\top a_j}{\\|a_i\\|_2 \\, \\|a_j\\|_2} \\right|$。这等同于计算 $A$ 的列归一化版本的格拉姆矩阵中最大的非对角线绝对值。设 $A'$ 是列向量为 $a'_j = a_j / \\|a_j\\|_2$ 的矩阵。则 $\\mu(A)$ 是 $G' = (A')^\\top A'$ 的非对角线元素的最大绝对值。\n- 未归一化的相干性 $\\tilde{\\mu}(A)$ 定义为 $\\tilde{\\mu}(A) = \\max_{i \\neq j} | a_i^\\top a_j |$。这是格拉姆矩阵 $G = A^\\top A$ 的最大非对角线绝对值。\n\n**2. 正交匹配追踪（OMP）实现**\nOMP 算法被实现用于恢复一个 k-稀疏信号 $x^\\star$ 的支撑集。\n- **输入**：字典 $A \\in \\mathbb{R}^{m \\times n}$，测量向量 $y \\in \\mathbb{R}^m$，稀疏度 $k$，以及归一化指数 $\\alpha$。\n- **初始化**：\n    - 残差初始化为测量向量：$r^{(0)} = y$。\n    - 已选索引集为空：$S_0 = \\emptyset$。\n    - 构建一个缩放后的字典 $B_\\alpha$，其列向量为 $b_j = a_j / \\|a_j\\|_2^{\\alpha}$。对于范数为 0 的列，我们可以认为其范数为 1 以避免除以零。\n- **迭代**：对于 $t = 1, \\dots, k$：\n    - **选择**：找到一个尚未在支撑集 $S_{t-1}$ 中的索引 $j_t$，该索引最大化与当前残差的相关性：\n    $$\n    j_t = \\arg\\max_{j \\notin S_{t-1}} |\\langle b_j, r^{(t-1)} \\rangle|\n    $$\n    若出现平局，则选择最小的索引 $j$。\n    - **更新支撑集**：新的支撑集为 $S_t = S_{t-1} \\cup \\{j_t\\}$。\n    - **更新残差**：通过在当前支撑集上使用原始字典 $A$ 解决一个最小二乘问题来找到新的信号估计：\n    $$\n    x_{S_t} = \\arg\\min_{z \\in \\mathbb{R}^{|S_t|}} \\|y - A_{S_t} z\\|_2^2 = (A_{S_t}^\\top A_{S_t})^{-1} A_{S_t}^\\top y\n    $$\n    其中 $A_{S_t}$ 是 $A$ 中包含由 $S_t$索引的列的子矩阵。使用伪逆以实现稳健的实现。新的残差是投影误差：\n    $$\n    r^{(t)} = y - A_{S_t} x_{S_t}\n    $$\n- **输出**：最终的支撑集 $S_k$。\n\n**3. 测试用例分析**\n\n**测试用例 T1:**\n- $A \\in \\mathbb{R}^{3 \\times 5}$, $k=2$, $x^\\star = (1, 1, 0, 0, 0)^\\top$, $e=(0,0,0)^\\top$。\n- 真实支撑集 $S^\\star=\\{0, 1\\}$。\n- $y = 1 \\cdot a_1 + 1 \\cdot a_2 = (1, 1, 0)^\\top$。\n- 列范数为 $\\|a_1\\|_2=1, \\|a_2\\|_2=1, \\|a_3\\|_2=1, \\|a_4\\|_2=\\sqrt{2}, \\|a_5\\|_2=10$。\n- **相干性**：\n    - $\\mu(A) = \\max_{i \\neq j} |(a_i/\\|a_i\\|_2)^\\top (a_j/\\|a_j\\|_2)| \\approx 0.9354$。\n    - $\\tilde{\\mu}(A) = \\max_{i \\neq j} |a_i^\\top a_j| \\approx 9.3541$。\n- **OMP 运行**：\n    - $\\alpha=0$：选择规则使用 $|\\langle a_j, y \\rangle|$。相关性为 $\\{1, 1, 0, 2, 5\\}$。选择 $a_5$（索引 4）。不正确。$s_0 = \\text{False}$。\n    - $\\alpha=1$：选择规则使用 $|\\langle a_j/\\|a_j\\|_2, y \\rangle|$。相关性为 $\\{1, 1, 0, 2/\\sqrt{2}, 5/10\\} = \\{1, 1, 0, \\sqrt{2}, 0.5\\}$。选择 $a_4$（索引 3）。不正确。$s_1 = \\text{False}$。\n    - $\\alpha=0.5$：选择规则使用 $|\\langle a_j/\\|a_j\\|_2^{0.5}, y \\rangle|$。相关性为 $\\{1, 1, 0, 2/2^{0.25}, 5/\\sqrt{10}\\} \\approx \\{1, 1, 0, 1.682, 1.581\\}$。选择 $a_4$（索引 3）。不正确。\n- **结果**：$\\alpha=0$, $\\alpha=0.5$, 和 $\\alpha=1$ 都未能正确恢复。因此 $\\alpha^\\star = -1.0$。\n- **输出**：$[0.935414..., 9.35414..., \\text{False}, \\text{False}, -1.0]$\n\n**测试用例 T2:**\n- $A \\in \\mathbb{R}^{3 \\times 3}$, $k=1$, $x^\\star = (1, 0, 0)^\\top$, $e=(0, 0, 0.02)^\\top$。\n- 真实支撑集 $S^\\star=\\{0\\}$。\n- $y = 1 \\cdot a_1 + e = (1, 0, 0.02)^\\top$。\n- 列范数为 $\\|a_1\\|_2=1, \\|a_2\\|_2=5, \\|a_3\\|_2=1$。\n- **相干性**：\n    - $\\mu(A) = |(a_1/\\|a_1\\|_2)^\\top (a_2/\\|a_2\\|_2)| = 0.2$。\n    - $\\tilde{\\mu}(A) = |a_1^\\top a_2| = 1$。\n- **OMP 运行**（$k=1$ 步）：\n    - $\\alpha=0$：我们基于 $|\\langle a_j, y \\rangle|$ 进行选择。\n        - $|\\langle a_1, y \\rangle| = 1$。\n        - $|\\langle a_2, y \\rangle| = |1 \\cdot 1 + (5\\sqrt{0.96}) \\cdot 0.02| \\approx 1.098$。\n        - $|\\langle a_3, y \\rangle| = 0$。\n        由于其大范数放大了噪声分量，选择了 $a_2$（索引 1）。不正确。$s_0 = \\text{False}$。\n    - $\\alpha=1$：我们基于 $|\\langle a_j/\\|a_j\\|_2, y \\rangle|$ 进行选择。\n        - $|\\langle a'_1, y \\rangle| = 1/1=1$。\n        - $|\\langle a'_2, y \\rangle| \\approx 1.098/5 \\approx 0.22$。\n        - $|\\langle a'_3, y \\rangle| = 0$。\n        选择了 $a_1$（索引 0）。正确。$s_1 = \\text{True}$。\n    - $\\alpha=0.5$：我们基于 $|\\langle a_j/\\|a_j\\|_2^{0.5}, y \\rangle|$ 进行选择。\n        - 对 $a_1$ 的相关性：$1/\\sqrt{1}=1$。\n        - 对 $a_2$ 的相关性：$1.098/\\sqrt{5} \\approx 0.49$。\n        选择了 $a_1$（索引 0）。正确。\n- **结果**：使用 $\\alpha=0$ 的 OMP 失败，而 $\\alpha=0.5$ 和 $\\alpha=1$ 成功。最小的成功指数是 $\\alpha^\\star=0.5$。\n- **输出**：$[0.2, 1.0, \\text{False}, \\text{True}, 0.5]$\n\n**测试用例 T3:**\n- $A \\in \\mathbb{R}^{4 \\times 6}$, $k=2$, $x^\\star=(1.2, 0, 0.8, 0, 0, 0)^\\top$, $e=(0.01, -0.02, 0.015, 0)^\\top$。\n- 真实支撑集 $S^\\star=\\{0, 2\\}$。\n- $y=1.2 a_1 + 0.8 a_3 + e = (1.21, -0.02, 0.815, 0)^\\top$。\n- 列范数为 $\\|a_1..a_4\\|_2=1$, $\\|a_5\\|_2=\\|a_6\\|_2=1/\\sqrt{2}$。\n- **相干性**：\n    - $\\mu(A) = |a_1^\\top (a_5/\\|a_5\\|_2)| = 0.5 / (1/\\sqrt{2}) = 1/\\sqrt{2} \\approx 0.7071$。\n    - $\\tilde{\\mu}(A) = |a_1^\\top a_5| = 0.5$。\n- **OMP 运行**：\n    - $\\alpha=0$：\n        - 迭代 1：$r^{(0)} = y$。相关性 $|\\langle a_j, y \\rangle|$ 为 $\\{1.21, 0.02, 0.815, 0, 0.595, 0.3975\\}$。选择索引 0。$S_1=\\{0\\}$。\n        - 迭代 2：$r^{(1)} = y - (a_1^\\top y) a_1 = (0, -0.02, 0.815, 0)^\\top$。对于 $j \\notin S_1$ 的相关性 $|\\langle a_j, r^{(1)} \\rangle|$ 为 $\\{0.02, 0.815, 0, 0.01, 0.3975\\}$。选择索引 2。\n        - 最终支撑集 $\\{0, 2\\}$。正确。$s_0 = \\text{True}$。\n    - $\\alpha=1$：\n        - 迭代 1：相关性 $|\\langle a_j/\\|a_j\\|_2, y \\rangle|$ 为 $\\{1.21, 0.02, 0.815, 0, 0.595\\sqrt{2}, 0.3975\\sqrt{2}\\} \\approx \\{1.21, 0.02, 0.815, 0, 0.841, 0.562\\}$。选择索引 0。\n        - 迭代 2：残差 $r^{(1)}$ 相同。相关性 $|\\langle a_j/\\|a_j\\|_2, r^{(1)} \\rangle|$ 为 $\\{0.02, 0.815, 0, 0.01\\sqrt{2}, 0.3975\\sqrt{2}\\} \\approx \\{0.02, 0.815, 0, 0.014, 0.562\\}$。选择索引 2。\n        - 最终支撑集 $\\{0, 2\\}$。正确。$s_1 = \\text{True}$。\n- **结果**：OMP 对于 $\\alpha=0$ 和 $\\alpha=1$ 都成功。最小的成功指数是 $\\alpha^\\star=0.0$。\n- **输出**：$[0.707106..., 0.5, \\text{True}, \\text{True}, 0.0]$",
            "answer": "[[0.9354143466934853,9.354143466934853,False,False,-1.0],[0.2,1.0,False,True,0.5],[0.7071067811865475,0.5,True,True,0.0]]"
        },
        {
            "introduction": "当高相关性不可避免时，标准 OMP 可能会因为错误地选择与真实支撑集（support）相关的原子而失败。这个高级练习要求你实现一个改进版的 OMP，主动惩罚这类候选原子。通过引入一个基于与已选原子累积相关性的重加权方案，你将探索一种强有力的技术，以提高 OMP 在具有挑战性的高相关性环境中的鲁棒性和正确性。",
            "id": "3441569",
            "problem": "考虑一个传感矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其原子（列）$\\{a_j\\}_{j=1}^n$ 经过列归一化。给定一个支撑集为 $S \\subset \\{1,\\dots,n\\}$ 且大小为 $|S| = k$ 的 $k$-稀疏信号 $x^\\star \\in \\mathbb{R}^n$，以及测量值 $y = A x^\\star + e$，其中 $e \\in \\mathbb{R}^m$ 是加性噪声。本任务的目标是分析并实现一种正交匹配追踪（Orthogonal Matching Pursuit, OMP）的变体算法。该算法使用重加权相关性来惩罚与已选原子相关的候选原子，并经验性地研究在存在互相关性的情况下，其正确性的改进。\n\n使用以下基础定义作为基础：\n- 互相关性 $\\mu(A) := \\max_{i \\neq j} |\\langle a_i, a_j \\rangle|$，其中 $\\langle \\cdot, \\cdot \\rangle$ 表示标准欧几里得内积。\n- 在标准正交匹配追踪（OMP）中，于第 $t$ 次迭代时，给定已选索引集 $T_t$、残差 $r_t = y - A_{T_t} x_{T_t}$ 和相关性向量 $c_t = A^\\top r_t$，下一个选定的索引 $j_t \\notin T_t$ 的选择标准是在所有 $j \\notin T_t$ 中最大化 $|\\langle a_j, r_t \\rangle|$。\n\n在重加权选择规则中，为每个候选索引 $j \\notin T_t$ 定义累积相关性分数\n$$\ns_j(t) := \\sum_{i \\in T_t} \\big|\\langle a_j, a_i \\rangle\\big|,\n$$\n以及一个正的重加权参数 $\\gamma  0$。提出一个加权函数\n$$\nw_j(t) := \\frac{1}{1 + \\gamma\\, s_j(t)}.\n$$\n修改 OMP 的选择步骤，使其选择\n$$\nj_t \\in \\arg\\max_{j \\notin T_t} \\Big( w_j(t)\\, \\big| \\langle a_j, r_t \\rangle \\big| \\Big).\n$$\n迭代继续进行，对更新后的集合 $T_{t+1} := T_t \\cup \\{j_t\\}$ 进行最小二乘拟合，更新残差 $r_{t+1} := y - A_{T_{t+1}} x_{T_{t+1}}$，并在 $k$ 次迭代后终止。\n\n您的任务：\n- 实现标准的 OMP 和上文定义的重加权 OMP 变体。\n- 对每个测试用例，构建矩阵 $A$、稀疏支撑集 $S$ 和支撑集上的系数以形成 $x^\\star$，生成 $y = A x^\\star + e$，其中噪声向量 $e$ 满足 $\\|e\\|_2 = \\eta \\|y_0\\|_2$（$y_0 := A x^\\star$），$\\eta \\ge 0$ 是指定的噪声水平。然后运行两种算法，均执行恰好 $k$ 次迭代，并返回支撑集 $T_{\\text{std}}$ 和 $T_{\\text{rw}}$。\n- 定义支撑集恢复误差为整数\n$$\n\\text{err}(T,S) := k - |T \\cap S|,\n$$\n这是在 $k$ 次选择中错误选择的数量。将改进量报告为整数\n$$\n\\Delta := \\text{err}(T_{\\text{std}},S) - \\text{err}(T_{\\text{rw}},S).\n$$\n正的 $\\Delta$ 值表示重加权 OMP 的支撑集恢复性能优于标准 OMP，错误数减少了 $\\Delta$；零值表示性能相当；负值表示性能更差。\n\n测试套件规格和构建细节：\n- $A$ 的所有列必须被缩放至单位 $\\ell_2$ 范数。为保证可复现性，请使用固定的伪随机种子。\n- 对于簇状相关字典，通过替换列 $a_j$ 来创建相关对 $(i,j)$：\n$$\na_j \\leftarrow \\frac{\\alpha\\, a_i + \\sqrt{1-\\alpha^2}\\, u}{\\|\\alpha\\, a_i + \\sqrt{1-\\alpha^2}\\, u\\|_2},\n$$\n其中 $u$ 是一个随机高斯向量，它与 $a_i$ 正交化以满足 $\\langle a_i, u \\rangle \\approx 0$，而 $\\alpha \\in (0,1)$ 控制了导致的成对相关性 $|\\langle a_i, a_j \\rangle| \\approx \\alpha$。\n- 将 $x^\\star$ 在支撑集 $S$ 上的非零项设置为正值，这些值在 $k$ 个支撑集索引上从最大到最小线性递减，以避免出现平凡的并列情况。\n\n使用以下四个测试用例：\n- 测试用例 1 (低相关性，无噪声):\n    - 维度: $m = 60$, $n = 120$, $k = 8$, 种子 $7$。\n    - 字典构建: 独立同分布的高斯条目，均值为零，方差为一，然后进行列归一化。\n    - 支撑集: $S = \\{5,17,23,42,55,63,88,107\\}$。\n    - $S$ 上的系数: 在八个索引上从 $1.0$ 线性递减到 $0.3$。\n    - 噪声水平: $\\eta = 0$。\n    - 重加权参数: $\\gamma = 0.5$。\n- 测试用例 2 (中等簇状相关性，小噪声):\n    - 维度: $m = 60$, $n = 120$, $k = 8$, 种子 $11$。\n    - 字典构建: 首先按前述方法生成高斯矩阵，然后在索引 $(10,11)$, $(30,31)$, $(70,71)$, $(95,96)$ 处以 $\\alpha = 0.98$ 引入相关对，并对这些列对进行重新归一化。\n    - 支撑集: $S = \\{10,30,70,95,20,50,90,110\\}$。\n    - $S$ 上的系数: 在八个索引上从 $1.0$ 线性递减到 $0.3$。\n    - 噪声水平: $\\eta = 0.02$，相对于 $\\|y_0\\|_2$。\n    - 重加权参数: $\\gamma = 1.0$。\n- 测试用例 3 (高簇状相关性，中等噪声):\n    - 维度: $m = 60$, $n = 120$, $k = 10$, 种子 $19$。\n    - 字典构建: 首先生成高斯矩阵，然后在索引 $(5,6)$, $(25,26)$, $(45,46)$, $(65,66), (85,86)$ 处以 $\\alpha = 0.99$ 引入相关对，并对这些列对进行重新归一化。\n    - 支撑集: $S = \\{5,25,45,65,85,12,34,56,78,100\\}$。\n    - $S$ 上的系数: 在十个索引上从 $1.0$ 线性递减到 $0.2$。\n    - 噪声水平: $\\eta = 0.05$，相对于 $\\|y_0\\|_2$。\n    - 重加权参数: $\\gamma = 1.5$。\n- 测试用例 4 (边界情况，不重加权):\n    - 使用与测试用例 2 完全相同的构建方法，但设置 $\\gamma = 0$ 以验证其与标准 OMP 的性能相当。\n\n您的程序应产生单行输出，其中包含四个测试用例的改进量 $\\Delta$，形式为方括号括起来的逗号分隔列表，例如 $[d_1,d_2,d_3,d_4]$，其中每个 $d_i$ 是按上述定义计算的整数。不应打印任何其他文本。此问题中没有物理单位或角度单位；所有报告的量均为无量纲量。",
            "solution": "用户提供了一个来自稀疏信号恢复和压缩感知领域的有效且良构的问题陈述。该问题具有科学依据，经过了形式化指定，并且可以通过计算进行验证。\n\n目标是实现并评估一种重加权的正交匹配追踪（Orthogonal Matching Pursuit, OMP）变体（RW-OMP），该变体旨在当传感矩阵（或字典）$A$ 包含高度相关的列时，提升其支撑集恢复性能。我们将在包含不同字典相关性和噪声水平的一系列测试用例上，将此重加权 OMP (RW-OMP) 与标准 OMP 进行比较。\n\n所要解决的根本挑战是，当字典原子并非互相不相关时，标准 OMP 的性能会显著下降。由 $\\mu(A) = \\max_{i \\neq j} |\\langle a_i, a_j \\rangle|$ 量化的高相关性，可能导致 OMP 错误地选择一个不在真实支撑集 $S$ 中、但与某个真实支撑集中的原子高度相关的原子。\n\n算法流程如下：\n\n设 $A \\in \\mathbb{R}^{m \\times n}$ 为传感矩阵，其列 $\\{a_j\\}$ 为单位范数向量；$y \\in \\mathbb{R}^m$ 为测量向量；$k$ 为已知的信号稀疏度。两种算法都旨在识别大小为 $k$ 的支撑集 $S$。它们都是迭代算法，运行 $k$ 步。\n\n在第 $t$ 次迭代（从 $t=1$ 到 $k$）：\n设 $T_{t-1}$ 为先前迭代中已选定的索引集合， $r_{t-1}$ 为对应的残差。初始时，$T_0 = \\emptyset$ 且 $r_0 = y$。\n\n**1. 标准正交匹配追踪 (OMP)**\n标准 OMP 算法贪婪地选择与当前残差最相关的原子。\n- **相关性计算**：计算所有原子与残差的内积：$c_j = \\langle a_j, r_{t-1} \\rangle$，其中 $j \\in \\{1, \\dots, n\\} \\setminus T_{t-1}$。\n- **索引选择**：找出使绝对相关性最大化的索引 $j_t$：\n$$\nj_t = \\arg\\max_{j \\notin T_{t-1}} |\\langle a_j, r_{t-1} \\rangle|\n$$\n- **支撑集更新**：扩充支撑集：$T_t = T_{t-1} \\cup \\{j_t\\}$。\n- **信号与残差更新**：通过求解一个限制在当前支撑集 $A_{T_t}$ 的原子上的最小二乘问题，来构建新的信号估计 $x_t$：\n$$\nx_t = \\arg\\min_{z: \\text{supp}(z) \\subseteq T_t} \\|y - A z\\|_2^2\n$$\n解由 $x_{T_t} = A_{T_t}^\\dagger y$ 给出，其中 $A_{T_t}^\\dagger = (A_{T_t}^\\top A_{T_t})^{-1} A_{T_t}^\\top$ 是 Moore-Penrose 伪逆。新的残差是信号中无法被已选原子解释的剩余部分：\n$$\nr_t = y - A_{T_t} x_{T_t}\n$$\n\n**2. 重加权正交匹配追踪 (RW-OMP)**\n重加权变体修改了选择步骤，以惩罚那些与已在支撑集 $T_{t-1}$ 中的原子高度相关的候选原子。\n- **相关性计算**：与标准 OMP 相同，计算 $c_j = \\langle a_j, r_{t-1} \\rangle$。\n- **重加权**：对于每个候选原子 $a_j$（其中 $j \\notin T_{t-1}$），计算其与已选原子的累积相关性：\n$$\ns_j(t-1) = \\sum_{i \\in T_{t-1}} |\\langle a_j, a_i \\rangle|\n$$\n然后使用给定的参数 $\\gamma > 0$ 计算加权因子：\n$$\nw_j(t-1) = \\frac{1}{1 + \\gamma s_j(t-1)}\n$$\n对于累积相关性低的原子，这个权重 $w_j(t-1)$ 接近 1；对于累积相关性高的原子，该权重则趋近于 0。\n- **索引选择**：通过最大化加权相关性来选择下一个索引 $j_t$：\n$$\nj_t = \\arg\\max_{j \\notin T_{t-1}} \\Big( w_j(t-1) \\cdot |\\langle a_j, r_{t-1} \\rangle| \\Big)\n$$\n- **支撑集与残差更新**：这些步骤与标准 OMP 相同。\n\n**仿真设置与评估**\n我们将按规定以编程方式构建四个测试用例。对每个用例，我们将生成矩阵 $A$、稀疏信号 $x^\\star$ 和测量向量 $y = A x^\\star + e$。噪声向量 $e$ 被缩放，使其范数 $\\|e\\|_2$ 是无噪声信号范数 $\\|y_0\\|_2 = \\|A x^\\star\\|_2$ 的一个特定比例 $\\eta$。\n字典由独立同分布的高斯条目生成，然后进行列归一化。对于具有结构化相关性的情况，特定的列会被替换为一个现有列和一个正交随机向量的线性组合，以达到目标相关性值 $\\alpha$。\n\n每种算法的性能通过支撑集恢复误差来衡量，该误差定义为算法选出的不在真实支撑集 $S$ 中的索引数量：\n$$\n\\text{err}(T,S) = k - |T \\cap S|\n$$\n最终报告的指标是改进量 $\\Delta$，即标准方法与重加权方法之间的误差之差：\n$$\n\\Delta = \\text{err}(T_{\\text{std}}, S) - \\text{err}(T_{\\text{rw}}, S)\n$$\n正的 $\\Delta$ 值表示 RW-OMP 比标准 OMP 正确识别了更多的真实支撑集索引。$\\Delta=0$ 的值意味着性能相同，这在测试用例 4 中是预期的，因为其 $\\gamma=0$ 使得两种算法等价。",
            "answer": "[0,2,2,0]"
        }
    ]
}