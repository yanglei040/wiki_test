{
    "hands_on_practices": [
        {
            "introduction": "正交匹配追踪（OMP）的核心在于其迭代过程。这个练习旨在通过一个基础但重要的计算，帮助你掌握 OMP 算法的第一个关键步骤。通过使用一个具体的信号和标准的沃尔什-哈达玛基，你将亲手实践如何找出最相关的原子并计算初始残差，这是理解整个算法如何逐步逼近真实信号的基础。",
            "id": "1108855",
            "problem": "考虑一个信号向量 $x \\in \\mathbb{R}^N$，其中 $N=2^n$，$n \\geq 1$ 为某个整数。$\\mathbb{R}^N$ 的沃尔什-哈达玛基是一组 $N$ 个正交向量，它们是归一化哈达玛矩阵 $\\Psi = \\frac{1}{\\sqrt{N}} H_n$ 的列向量。哈达玛矩阵 $H_n$ 是一个 $2^n \\times 2^n$ 的矩阵，递归定义如下：\n$$\nH_0 = (1), \\quad H_k = \\begin{pmatrix} H_{k-1}  H_{k-1} \\\\ H_{k-1}  -H_{k-1} \\end{pmatrix} \\text{ for } k \\ge 1.\n$$\n$\\Psi$ 的列向量，记作 $\\{\\psi_0, \\psi_1, \\dots, \\psi_{N-1}\\}$，构成 $\\mathbb{R}^N$ 的一个标准正交基。\n\n正交匹配追踪（Orthogonal Matching Pursuit, OMP）是一种贪心算法，用于使用原子字典为信号 $x$ 寻找稀疏近似，在本例中，该字典是沃尔什-哈达玛基。该算法迭代进行。\n\n**OMP 算法（第一次迭代）：**\n1.  **初始化：** 初始残差是信号本身，即 $r_0 = x$。\n2.  **匹配：** 找到与当前残差最相关的基向量 $\\psi_{j_1}$。索引 $j_1$ 的选择方式如下：\n    $$\n    j_1 = \\arg\\max_{j \\in \\{0, \\dots, N-1\\}} |\\langle r_0, \\psi_j \\rangle|\n    $$\n    其中 $\\langle \\cdot, \\cdot \\rangle$ 表示标准欧几里得内积。如果存在多个最大值，可以选择其中任何一个使之最大化的索引。\n3.  **投影与残差更新：** 将信号 $x$ 投影到所选基向量 $\\psi_{j_1}$ 的生成空间上，形成第一个近似 $\\hat{x}_1 = \\text{proj}_{\\text{span}(\\psi_{j_1})} x$。然后计算新的残差为 $r_1 = x - \\hat{x}_1$。\n\n**问题：**\n对于信号向量 $x = (1, 1, 1, 1, 0, 0, 0, 0)^T \\in \\mathbb{R}^8$，在使用 $N=8$ 的沃尔什-哈达玛基，并经过单次迭代的正交匹配追踪（OMP）算法后，求残差向量 $r_1$ 的欧几里得范数（$L_2$ 范数）的精确值。",
            "solution": "1. 相关公式  \n   OMP 第一次迭代的残差 $r_1$ 满足\n   $$\n   r_1 \\;=\\; x - \\proj_{\\psi_{j_1}}x,\n   $$\n   并且由于 $\\psi_{j_1}$ 是一个单位向量，\n   $$\n   \\|r_1\\|_2^2 \\;=\\;\\|x\\|_2^2 - |\\langle x,\\psi_{j_1}\\rangle|^2.\n   $$\n\n2. 计算 $\\|x\\|_2^2$  \n   $$\n   x = (1,1,1,1,0,0,0,0)^T \n   \\quad\\Longrightarrow\\quad\n   \\|x\\|_2^2 = 1^2+1^2+1^2+1^2 = 4.\n   $$\n\n3. 计算最大相关性  \n   沃尔什-哈达玛基向量为 $\\psi_j=\\tfrac1{\\sqrt8}h_j$，其中 $h_j\\in\\{\\pm1\\}^8$ 是 $H_3$ 的第 $j$ 列。由于 $x$ 的非零项仅在前四个坐标上，对于每个 $j$  \n   $$\n   \\langle x,\\psi_j\\rangle\n   = \\frac1{\\sqrt8}\\sum_{i=0}^3 h_{i,j}.\n   $$\n   可以验证，$h_j$ 的前四个元素之和的绝对值在 $j\\equiv0\\pmod4$ 时达到最大，得到\n   $$\n   \\max_j|\\langle x,\\psi_j\\rangle|\n   = \\frac1{\\sqrt8}(4) = \\frac{4}{2\\sqrt2} = \\sqrt2.\n   $$\n\n4. 残差范数  \n   $$\n   \\|r_1\\|_2\n   = \\sqrt{\\|x\\|_2^2 - \\bigl(\\max_j|\\langle x,\\psi_j\\rangle|\\bigr)^2}\n   = \\sqrt{4 - (\\sqrt2)^2}\n   = \\sqrt{2}.\n   $$",
            "answer": "$$\\boxed{\\sqrt{2}}$$"
        },
        {
            "introduction": "贪婪算法的简洁性背后也隐藏着其局限性，特别是在字典原子之间存在高度相关性（即高相干性）时。本练习通过构造一个精巧的例子，让你亲眼见证 OMP 算法如何被误导。你将计算在一个高相干性字典下，算法的第一步选择了一个“错误”的原子，从而深刻理解为何字典的相干性是决定 OMP 恢复性能的关键理论指标。",
            "id": "3387250",
            "problem": "考虑稀疏数据同化中使用的线性逆模型 $y = A x$，其中 $A \\in \\mathbb{R}^{2 \\times 3}$ 是一个具有单位范数-列的字典，$x \\in \\mathbb{R}^{3}$ 是一个稀疏系数向量。贪婪恢复算法正交匹配追踪 (Orthogonal Matching Pursuit, OMP) 的定义是在其第一次迭代中选择 $A$ 中与残差（初始化为 $r^{(0)} = y$）具有最大绝对相关性的列（原子）。当字典包含高度相关的原子时，OMP 可能会失败。\n\n构建以下具有单位范数原子的字典：\n- $a_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，\n- $a_{2} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix}$，其中 $\\theta = \\arccos(0.99)$，\n- $a_{3} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。\n\n设真实的稀疏信号由原子 $a_{2}$ 和 $a_{3}$ 支撑，其系数为\n- $x_{2}^{\\star} = 1$，\n- $x_{3}^{\\star} = -\\sin\\theta$，\n且 $x_{1}^{\\star} = 0$。因此，观测数据为 $y = A x^{\\star} = a_{2} x_{2}^{\\star} + a_{3} x_{3}^{\\star}$。\n\n计算三个绝对相关性\n$$c_{i} = \\left| \\langle a_{i}, y \\rangle \\right|, \\quad i \\in \\{1,2,3\\},$$\n它们决定了 OMP 的首次选择，从而证明了 $a_{1}$ 和 $a_{2}$ 之间的高度相关性所带来的误导效应。请提供这三个相关性的数值。无需四舍五入；请使用由 $\\cos\\theta = 0.99$ 和 $\\sin\\theta = \\sqrt{1 - 0.99^{2}}$ 所隐含的精确值。",
            "solution": "本题要求在特定的稀疏恢复设置下，计算绝对相关性 $c_{i} = \\left| \\langle a_{i}, y \\rangle \\right|$，其中 $i \\in \\{1,2,3\\}$。正交匹配追踪 (OMP) 算法在第一步中选择与测量向量 $y$ 具有最大绝对相关性的原子（字典 $A$ 的列）。真实的稀疏信号 $x^{\\star}$ 由原子 $a_{2}$ 和 $a_{3}$ 支撑，这意味着它们是“正确”的原子。\n\n第一步是计算测量向量 $y$。模型由 $y = A x^{\\star}$ 给出。由于真实信号是稀疏的，其非零系数为 $x_2^{\\star}$ 和 $x_3^{\\star}$，因此测量向量 $y$ 是相应原子 $a_{2}$ 和 $a_{3}$ 的线性组合。\n\n给定的原子是：\n$$a_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad a_{2} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix}, \\quad a_{3} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$$\n其中 $\\theta = \\arccos(0.99)$。给定 $\\cos\\theta = 0.99$。由于 $\\theta$ 是反余弦函数的主值，$\\theta \\in [0, \\pi]$，这确保了 $\\sin\\theta = \\sqrt{1 - \\cos^2\\theta} \\ge 0$。\n\n真实的系数是 $x_{1}^{\\star} = 0$, $x_{2}^{\\star} = 1$ 和 $x_{3}^{\\star} = -\\sin\\theta$。\n因此，测量向量 $y$ 是：\n$$y = a_{2} x_{2}^{\\star} + a_{3} x_{3}^{\\star} = a_{2}(1) + a_{3}(-\\sin\\theta)$$\n代入向量定义：\n$$y = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix} - \\sin\\theta \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta - \\sin\\theta \\end{pmatrix} = \\begin{pmatrix} \\cos\\theta \\\\ 0 \\end{pmatrix}$$\n\n现在，我们可以计算三个绝对相关性 $c_{1}$、$c_{2}$ 和 $c_{3}$。内积 $\\langle u, v \\rangle$ 定义为标准点积 $u^T v$。\n\n1.  计算 $c_{1} = |\\langle a_{1}, y \\rangle|$：\n    $$\\langle a_{1}, y \\rangle = a_{1}^T y = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta \\\\ 0 \\end{pmatrix} = (1)(\\cos\\theta) + (0)(0) = \\cos\\theta$$\n    给定 $\\cos\\theta = 0.99$，其为正数，因此绝对值为：\n    $$c_{1} = |\\cos\\theta| = 0.99$$\n\n2.  计算 $c_{2} = |\\langle a_{2}, y \\rangle|$：\n    $$\\langle a_{2}, y \\rangle = a_{2}^T y = \\begin{pmatrix} \\cos\\theta  \\sin\\theta \\end{pmatrix} \\begin{pmatrix} \\cos\\theta \\\\ 0 \\end{pmatrix} = (\\cos\\theta)(\\cos\\theta) + (\\sin\\theta)(0) = \\cos^2\\theta$$\n    由于 $\\cos^2\\theta$ 是非负的，其绝对值为：\n    $$c_{2} = |\\cos^2\\theta| = \\cos^2\\theta = (0.99)^2 = 0.9801$$\n\n3.  计算 $c_{3} = |\\langle a_{3}, y \\rangle|$：\n    $$\\langle a_{3}, y \\rangle = a_{3}^T y = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta \\\\ 0 \\end{pmatrix} = (0)(\\cos\\theta) + (1)(0) = 0$$\n    绝对值为：\n    $$c_{3} = |0| = 0$$\n\n三个相关性分别为 $c_1 = 0.99$、$c_2 = 0.9801$ 和 $c_3 = 0$。\nOMP 算法选择与最大相关性对应的原子 $a_k$，即 $k = \\arg\\max_i c_i$。在本例中，由于 $0.99  0.9801  0$，我们有 $c_1  c_2  c_3$。因此，OMP 在其第一次迭代中选择了原子 $a_1$。\n这证明了 OMP 在此特定情况下的失败。真实信号由原子 $a_2$ 和 $a_3$ 组成，但算法错误地选择了原子 $a_1$。这是原子 $a_1$ 和 $a_2$ 之间的高度相关性（其中 $\\langle a_1, a_2 \\rangle = \\cos\\theta = 0.99$）以及信号系数的特定构造的直接结果。\n\n所要求的三个相关性的数值为：\n$$c_{1} = 0.99$$\n$$c_{2} = 0.9801$$\n$$c_{3} = 0$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix} 0.99  0.9801  0 \\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "理论分析为 OMP 的成功恢复提供了充分条件，例如著名的相干性界限 $\\mu(A)  \\frac{1}{2k - 1}$。但在实际应用中，当这些条件被打破或存在噪声时，算法性能会如何变化？这个实践练习将引导你从纸笔计算走向编程实现，通过构建具有可控相干性的传感矩阵，并模拟不同信噪比下的测量过程，来系统地探索 OMP 在理论边界内外的支持集恢复性能。",
            "id": "3464820",
            "problem": "考虑压缩感知中的线性测量模型，定义为 $y = A x^\\star + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个列为单位范数的感知矩阵，$x^\\star \\in \\mathbb{R}^n$ 是一个 $k$-稀疏向量，$\\eta \\in \\mathbb{R}^m$ 是测量噪声。目标是通过正交匹配追踪（OMP）算法对 $x^\\star$ 进行精确支撑集恢复，即恢复集合 $\\operatorname{supp}(x^\\star) = \\{ j \\in \\{1,\\dots,n\\} : x^\\star_j \\neq 0 \\}$。\n\n正交匹配追踪（OMP）定义如下。给定 $A$、$y$ 和稀疏度 $k$，初始化残差 $r^{(0)} = y$ 和激活支撑集 $S^{(0)} = \\varnothing$。对于迭代 $t = 1, 2, \\dots, k$：选择索引 $j^{(t)} \\in \\{1,\\dots,n\\} \\setminus S^{(t-1)}$，该索引使得绝对内积 $|\\langle a_j, r^{(t-1)} \\rangle|$ 最大化，其中 $a_j$ 表示 $A$ 的第 $j$ 列；更新支撑集 $S^{(t)} = S^{(t-1)} \\cup \\{ j^{(t)} \\}$；计算最小二乘估计 $x_{S^{(t)}}^{(t)}$，该估计在支撑集为 $S^{(t)}$ 的向量 $x$ 上最小化 $\\| y - A_{S^{(t)}} x \\|_2$；更新残差 $r^{(t)} = y - A_{S^{(t)}} x_{S^{(t)}}^{(t)}$。经过 $k$ 次迭代后，估计的支撑集为 $S^{(k)}$。\n\n$A$ 的一个关键几何特性是其互相关性，定义为\n$$\n\\mu(A) = \\max_{i \\neq j} \\left| \\langle a_i, a_j \\rangle \\right|.\n$$\n在无噪声情况下，OMP 精确支撑集恢复的经典充分条件涉及相干性界限 $\\mu(A)  \\frac{1}{2k - 1}$。在此，我们将探讨当相干性 $\\mu(A)$ 略高于此经典阈值时的性能，并研究信噪比（SNR）的影响，其定义为\n$$\n\\mathrm{SNR} = \\frac{\\|A x^\\star\\|_2}{\\|\\eta\\|_2}.\n$$\n\n具有指定相干性的矩阵构造。令 $u \\in \\mathbb{R}^m$ 为单位向量，$\\{w_j\\}_{j=1}^n \\subset \\mathbb{R}^m$ 为一个标准正交集，使得每个 $w_j$ 都与 $u$ 正交。对于选定的 $c \\in (0,1)$，构造列向量\n$$\na_j = c\\, u + \\sqrt{1 - c^2}\\, w_j, \\quad j = 1,\\dots,n.\n$$\n每个 $a_j$ 的范数均为 1。对于 $i \\neq j$，内积为 $\\langle a_i, a_j \\rangle = c^2$，因此互相关性恰好为 $\\mu(A) = c^2$。这提供了一种可控的方法，通过选择 $c = \\sqrt{\\mu_{\\mathrm{target}}}$，将 $\\mu(A)$ 设置为所需的目标值 $\\mu_{\\mathrm{target}} \\in (0,1)$。\n\n稀疏信号和噪声模型。向量 $x^\\star$ 是 $k$-稀疏的，其非零项从一个连续分布中独立抽取，并随机分配符号以避免退化情况。噪声向量 $\\eta$ 从零均值高斯分布中抽取，并进行缩放以达到指定的信噪比（SNR）。\n\n程序要求。实现上述定义的 OMP 算法，从 $y$ 中估计支撑集，并返回一个布尔值，表示是否实现了精确支撑集恢复，即 $\\operatorname{supp}(x^\\star) = S^{(k)}$ 是否成立。使用上述描述的具有指定相干性的矩阵构造方法。对于每个测试用例，使用固定的随机种子生成 $A$、$x^\\star$ 和 $\\eta$，以确保可复现性。\n\n测试套件。使用以下参数集，每个由 $(m,n,k,\\mu_{\\mathrm{target}},\\mathrm{SNR},\\text{seed})$ 指定：\n- 情况 1：$(m=30, n=24, k=3, \\mu_{\\mathrm{target}}=0.18, \\mathrm{SNR}=100, \\text{seed}=1)$，其中 $\\mu_{\\mathrm{target}}$ 低于经典界限 $\\frac{1}{2k-1} = \\frac{1}{5} = 0.2$。\n- 情况 2：$(m=30, n=24, k=3, \\mu_{\\mathrm{target}}=0.22, \\mathrm{SNR}=100, \\text{seed}=2)$，其中 $\\mu_{\\mathrm{target}}$ 略高于经典界限。\n- 情况 3：$(m=30, n=24, k=3, \\mu_{\\mathrm{target}}=0.22, \\mathrm{SNR}=10, \\text{seed}=3)$，高于经典界限且有中等噪声。\n- 情况 4：$(m=30, n=24, k=5, \\mu_{\\mathrm{target}}=0.13, \\mathrm{SNR}=50, \\text{seed}=4)$，高于经典界限 $\\frac{1}{2k-1} = \\frac{1}{9} \\approx 0.111\\ldots$。\n- 情况 5：$(m=30, n=24, k=5, \\mu_{\\mathrm{target}}=0.10, \\mathrm{SNR}=50, \\text{seed}=5)$，低于经典界限。\n- 情况 6：$(m=30, n=24, k=1, \\mu_{\\mathrm{target}}=0.90, \\mathrm{SNR}=100, \\text{seed}=6)$，一个单脉冲信号，在高信噪比下其选择预计是鲁棒的。\n\n你的程序应产生一行输出，包含这六种情况的布尔结果，形式为方括号括起来的逗号分隔列表，例如 $[\\text{True},\\text{False},\\dots]$。不涉及物理单位；不使用角度；所有输出都是布尔值。",
            "solution": "该问题是有效的，因为它在科学上基于已建立的压缩感知理论，是适定的，有明确的目标和可复现的测试用例，并且没有歧义或矛盾。它提供了一个标准的数值实验，来研究正交匹配追踪算法的性能。\n\n这个问题的核心是实现一个数值模拟，以测试正交匹配追踪（OMP）算法在不同的矩阵相干性和信噪比（SNR）条件下的支撑集恢复性能。这个过程涉及几个不同的阶段：生成一个具有特定结构和互相关性的感知矩阵 $A \\in \\mathbb{R}^{m \\times n}$，创建一个 $k$-稀疏信号 $x^\\star \\in \\mathbb{R}^n$，添加噪声 $\\eta \\in \\mathbb{R}^m$ 以形成测量值 $y = A x^\\star + \\eta$，运行 OMP 算法来估计 $x^\\star$ 的支撑集，最后，验证恢复是否精确。\n\n**1. 具有指定相干性的感知矩阵构造**\n\n问题指定了一种构造矩阵 $A$ 的方法，该矩阵的列为单位范数，且具有精确控制的互相关性 $\\mu(A) = \\max_{i \\neq j} |\\langle a_i, a_j \\rangle|$。目标相干性表示为 $\\mu_{\\mathrm{target}}$。$A$ 的列 $a_j$（对于 $j=1, \\dots, n$）定义为：\n$$\na_j = c u + \\sqrt{1 - c^2} w_j\n$$\n此处，$u \\in \\mathbb{R}^m$ 是一个单位向量，$\\{w_j\\}_{j=1}^n$ 是 $\\mathbb{R}^m$ 中一个包含 $n$ 个标准正交向量的集合，这些向量也与 $u$ 正交，并且 $c = \\sqrt{\\mu_{\\mathrm{target}}}$。对于所有 $j$ 的正交条件 $\\langle u, w_j \\rangle = 0$ 以及集合 $\\{w_j\\}$ 的标准正交性（即 $\\langle w_i, w_j \\rangle = \\delta_{ij}$）确保了对于任何 $i \\neq j$，内积为 $\\langle a_i, a_j \\rangle = c^2$。因此，互相关性恰好为 $\\mu(A) = c^2 = \\mu_{\\mathrm{target}}$。\n\n为了使这种构造可行，在与 $u$ 正交的子空间中必须存在 $n$ 个标准正交向量。这个子空间的维度是 $m-1$。因此，我们必须有 $n \\le m-1$。所有测试用例都满足此条件，因为 $n=24$，$m=30$，意味着 $24 \\le 29$。实现首先生成一个随机单位向量 $u$。然后，计算 $u^T$ 的 $(m-1)$ 维零空间的一个标准正交基。这个基的前 $n$ 个向量被用作集合 $\\{w_j\\}_{j=1}^n$。\n\n**2. 稀疏信号和噪声模型**\n\n真实信号 $x^\\star \\in \\mathbb{R}^n$ 要求是 $k$-稀疏的，意味着它最多有 $k$ 个非零项。它的支撑集 $\\operatorname{supp}(x^\\star)$ 是这些非零项的索引集。支撑集是通过从 $\\{1, \\dots, n\\}$ 中均匀随机选择 $k$ 个索引来生成的。非零值本身从标准正态分布中抽取，这满足了问题对于具有随机符号的连续分布的要求。\n\n测量噪声 $\\eta \\in \\mathbb{R}^m$ 被建模为从零均值高斯分布中抽取的向量。它的幅度被缩放以达到特定的信噪比（SNR），定义为：\n$$\n\\mathrm{SNR} = \\frac{\\|A x^\\star\\|_2}{\\|\\eta\\|_2}\n$$\n更高的信噪比意味着更低的相对噪声水平。为了实现这一点，我们首先计算信号分量 $A x^\\star$ 及其欧几里得范数 $\\|A x^\\star\\|_2$。然后，我们生成一个随机高斯向量并将其归一化，再将其缩放以具有所需的范数 $\\|\\eta\\|_2 = \\|A x^\\star\\|_2 / \\mathrm{SNR}$。最后，测量向量形成为 $y = A x^\\star + \\eta$。\n\n**3. 正交匹配追踪（OMP）算法**\n\nOMP 是一种用于求解线性方程组稀疏解的迭代贪心算法。给定测量值 $y$、感知矩阵 $A$ 和稀疏度 $k$，其过程如下：\n\n- **初始化**：残差初始化为测量向量 $r^{(0)} = y$，支撑集为空 $S^{(0)} = \\varnothing$。\n\n- **迭代**：对于 $t = 1, 2, \\dots, k$：\n    1.  **选择步骤**：算法识别出尚未在支撑集中且与当前残差最相关的 $A$ 的列。这是贪心步骤，其中选择索引 $j^{(t)}$ 以最大化内积的幅值：\n        $$\n        j^{(t)} = \\operatorname{argmax}_{j \\notin S^{(t-1)}} |\\langle a_j, r^{(t-1)} \\rangle|\n        $$\n        这对应于选择能最好地“解释”信号剩余部分的原子。支撑集被更新：$S^{(t)} = S^{(t-1)} \\cup \\{ j^{(t)} \\}$。\n    2.  **投影步骤**：计算一个临时解 $x^{(t)}$，该解被约束为仅在当前激活集 $S^{(t)}$ 上受支撑。这通过求解一个最小二乘问题来实现，以在由 $S^{(t)}$ 索引的 $A$ 的列（表示为 $A_{S^{(t)}}$）所张成的子空间中找到 $y$ 的最佳近似：\n        $$\n        x_{S^{(t)}}^{(t)} = \\operatorname{argmin}_{x : \\operatorname{supp}(x) = S^{(t)}} \\| y - A_{S^{(t)}} x \\|_2\n        $$\n        这个问题的解可以通过正规方程找到，或者更鲁棒地，使用用于最小二乘问题的数值线性代数求解器。\n    3.  **残差更新**：通过从测量值中减去新找到的近似值来更新残差：\n        $$\n        r^{(t)} = y - A_{S^{(t)}} x_{S^{(t)}}^{(t)}\n        $$\n        此步骤的一个关键特性是，新的残差 $r^{(t)}$ 与 $A_{S^{(t)}}$ 张成的子空间正交，即对于所有 $j \\in S^{(t)}$ 都有 $\\langle a_j, r^{(t)} \\rangle = 0$。这个“正交”特性防止算法重新选择相同的原子，并有助于其强大的性能保证。\n\n经过 $k$ 次迭代后，算法终止，最终估计的支撑集为 $S^{(k)}$。\n\n**4. 精确支撑集恢复的验证**\n\n最后一步是确定算法对于每个测试用例是否成功。成功被定义为“精确支撑集恢复”，这意味着估计的支撑集 $S^{(k)}$ 必须与真实的支撑集 $\\operatorname{supp}(x^\\star)$ 完全相同。实现通过将真实和估计的索引列表都转换为集合并比较它们是否相等来执行此检查。每种情况的布尔结果（成功为 $True$，失败为 $False$）都会被记录下来。提供的测试用例旨在探索 OMP 的性能，特别是当互相关性 $\\mu(A)$ 超过经典理论界限 $\\frac{1}{2k - 1}$ 以及当信噪比降低时，其性能如何下降。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import null_space\n\ndef generate_matrix(m, n, mu_target, rng):\n    \"\"\"\n    Generates a matrix A with prescribed mutual coherence mu_target.\n    The columns are constructed as a_j = c*u + sqrt(1-c^2)*w_j.\n    \"\"\"\n    if n > m - 1:\n        raise ValueError(f\"Cannot construct matrix: n must be = m-1. Got n={n}, m={m}.\")\n    \n    c = np.sqrt(mu_target)\n    \n    # 1. Generate a random unit vector u in R^m\n    u = rng.standard_normal(m)\n    u /= np.linalg.norm(u)\n    \n    # 2. Find an orthonormal basis for the subspace orthogonal to u\n    # The null space of u.T is the orthogonal complement of the space spanned by u.\n    basis_ortho = null_space(u.reshape(1, -1)) # Shape is (m, m-1)\n    \n    # 3. Take the first n vectors from this basis as the {w_j} set\n    W = basis_ortho[:, :n] # Shape is (m, n)\n    \n    # 4. Construct the matrix A\n    A = c * u[:, np.newaxis] + np.sqrt(1 - c**2) * W\n    \n    # Verification (optional): check norms and coherence\n    # for j in range(n):\n    #     assert np.isclose(np.linalg.norm(A[:, j]), 1.0)\n    # for i in range(n):\n    #     for j in range(i + 1, n):\n    #         assert np.isclose(np.abs(A[:, i].T @ A[:, j]), mu_target)\n            \n    return A\n\ndef generate_sparse_signal(n, k, rng):\n    \"\"\"\n    Generates a k-sparse vector x_star of length n.\n    \"\"\"\n    x_star = np.zeros(n)\n    support = rng.choice(n, k, replace=False)\n    values = rng.standard_normal(k)\n    x_star[support] = values\n    return x_star, support\n\ndef generate_noise(signal_component, snr, m, rng):\n    \"\"\"\n    Generates Gaussian noise scaled to a given SNR.\n    \"\"\"\n    signal_norm = np.linalg.norm(signal_component)\n    if snr == np.inf or snr = 0:\n        return np.zeros(m)\n    \n    noise_norm = signal_norm / snr\n    \n    eta_raw = rng.standard_normal(m)\n    eta_raw_norm = np.linalg.norm(eta_raw)\n    \n    if eta_raw_norm == 0: # Extremely unlikely but possible\n        return np.zeros(m)\n        \n    eta = eta_raw * (noise_norm / eta_raw_norm)\n    return eta\n\ndef omp(A, y, k):\n    \"\"\"\n    Implements Orthogonal Matching Pursuit (OMP).\n    \"\"\"\n    m, n = A.shape\n    r = y.copy()\n    support = []\n    \n    for _ in range(k):\n        # Selection step\n        correlations = A.T @ r\n        # We must only consider atoms not already in the support\n        if support: # list can't be indexed by list in numpy\n             correlations[support] = 0\n        \n        j_t = np.argmax(np.abs(correlations))\n        \n        if j_t in support:\n            # This can happen if the residual is zero or orthogonal to all remaining atoms\n            # A well-posed problem should not lead to this, but we handle it.\n            break\n            \n        support.append(j_t)\n        \n        # Projection and residual update\n        A_S = A[:, sorted(support)]\n        \n        # Solve the least squares problem: min ||A_S x_S - y||_2\n        x_S, _, _, _ = np.linalg.lstsq(A_S, y, rcond=None)\n        \n        # Update residual\n        r = y - A_S @ x_S\n        \n    return sorted(support)\n\ndef run_single_test(m, n, k, mu_target, snr, seed):\n    \"\"\"\n    Runs a single test case for OMP support recovery.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # 1. Generate matrix A\n    A = generate_matrix(m, n, mu_target, rng)\n    \n    # 2. Generate sparse signal x_star\n    x_star, true_support = generate_sparse_signal(n, k, rng)\n    \n    # 3. Generate measurement y = Ax* + eta\n    signal_component = A @ x_star\n    eta = generate_noise(signal_component, snr, m, rng)\n    y = signal_component + eta\n    \n    # 4. Run OMP to estimate support\n    estimated_support = omp(A, y, k)\n    \n    # 5. Check for exact support recovery\n    return set(estimated_support) == set(true_support)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (m, n, k, mu_target, SNR, seed)\n        (30, 24, 3, 0.18, 100, 1), # Case 1: Below bound, high SNR\n        (30, 24, 3, 0.22, 100, 2), # Case 2: Above bound, high SNR\n        (30, 24, 3, 0.22, 10,  3), # Case 3: Above bound, moderate SNR\n        (30, 24, 5, 0.13, 50,  4), # Case 4: Above bound (1/9), high-ish SNR\n        (30, 24, 5, 0.10, 50,  5), # Case 5: Below bound, high-ish SNR\n        (30, 24, 1, 0.90, 100, 6), # Case 6: k=1, robust case\n    ]\n\n    results = []\n    for case in test_cases:\n        m, n, k, mu_target, snr, seed = case\n        result = run_single_test(m, n, k, mu_target, snr, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}