{
    "hands_on_practices": [
        {
            "introduction": "Eigenmodes obtained from solving Maxwell's equations are more than just mathematical field patterns; they represent fundamental states of the electromagnetic field with distinct physical properties. A crucial step in any modal analysis is to normalize these solutions to a consistent physical quantity, such as stored energy. This practice  provides a foundational exercise in connecting the abstract vector field of an eigenmode to its time-averaged stored energy, a process that is essential for quantitative modeling, perturbation theory, and understanding energy dynamics in resonant systems.",
            "id": "3304078",
            "problem": "Consider the source-free time-harmonic Maxwell eigenvalue problem in a homogeneous, isotropic, lossless medium with constant permittivity $\\epsilon>0$ and permeability $\\mu>0$, with suppressed time dependence $\\exp(j \\omega t)$. The domain $\\Omega$ is a three-dimensional periodic box of volume $V$, so that plane waves are admissible eigenmodes under periodic boundary conditions. Let $\\mathbf{k} \\in \\mathbb{R}^{3}$ and $\\hat{\\mathbf{k}}=\\mathbf{k}/\\|\\mathbf{k}\\|$, and let $\\mathbf{e}$ be a constant unit polarization vector satisfying $\\mathbf{k}\\cdot \\mathbf{e}=0$. Consider the eigenmode\n$$\n\\mathbf{E}(\\mathbf{r})=\\alpha\\,\\mathbf{e}\\,\\exp\\!\\big(j\\,\\mathbf{k}\\cdot \\mathbf{r}\\big),\\qquad \\mathbf{H}(\\mathbf{r})\\ \\text{determined by Maxwell's equations},\n$$\nwith $\\|\\mathbf{k}\\|=\\omega\\sqrt{\\mu\\epsilon}$ so that the dispersion relation is satisfied. Determine the real, nonnegative scalar $\\alpha$ such that the total time-averaged electromagnetic energy\n$$\n\\frac{1}{4}\\int_{\\Omega}\\big(\\epsilon\\,\\|\\mathbf{E}(\\mathbf{r})\\|^{2}+\\mu\\,\\|\\mathbf{H}(\\mathbf{r})\\|^{2}\\big)\\,dV=1.\n$$\nExpress your final answer for $\\alpha$ in closed form in terms of $\\epsilon$ and $V$ only. No numerical evaluation is required.\n\nThen, briefly explain, without performing any calculation, how normalization is modified in lossy dispersive media where $\\epsilon$ and/or $\\mu$ are complex and frequency dependent, and name at least one mathematically consistent normalization convention used in computational electromagnetics for such non-Hermitian eigenvalue problems. Your explanation should be concise and conceptual; the graded final answer is only the value of $\\alpha$.",
            "solution": "The problem as stated is scientifically sound, self-contained, and well-posed. It describes a standard normalization procedure for an electromagnetic eigenmode in a lossless, homogeneous medium within a periodic domain. We may proceed with the solution.\n\nThe problem asks for the determination of a real, nonnegative scalar normalization constant $\\alpha$ for a given plane-wave electric field eigenmode,\n$$\n\\mathbf{E}(\\mathbf{r})=\\alpha\\,\\mathbf{e}\\,\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})\n$$\nsuch that the total time-averaged electromagnetic energy in the volume $\\Omega$ is equal to $1$. The normalization condition is\n$$\n\\frac{1}{4}\\int_{\\Omega}\\big(\\epsilon\\,\\|\\mathbf{E}(\\mathbf{r})\\|^{2}+\\mu\\,\\|\\mathbf{H}(\\mathbf{r})\\|^{2}\\big)\\,dV=1\n$$\nThe medium is lossless, homogeneous, and isotropic, with permittivity $\\epsilon>0$ and permeability $\\mu>0$. The vector $\\mathbf{e}$ is a unit polarization vector, $\\|\\mathbf{e}\\|=1$, and it is transverse to the wave vector $\\mathbf{k}$, i.e., $\\mathbf{k}\\cdot \\mathbf{e}=0$.\n\nFirst, we must determine the magnetic field $\\mathbf{H}(\\mathbf{r})$ corresponding to the given electric field $\\mathbf{E}(\\mathbf{r})$ using Maxwell's equations. For time-harmonic fields with suppressed time dependence $\\exp(j \\omega t)$, Faraday's law of induction is\n$$\n\\nabla \\times \\mathbf{E} = -j\\omega\\mu\\mathbf{H}\n$$\nWe can solve for $\\mathbf{H}$ as\n$$\n\\mathbf{H} = \\frac{1}{-j\\omega\\mu} (\\nabla \\times \\mathbf{E}) = \\frac{j}{\\omega\\mu} (\\nabla \\times \\mathbf{E})\n$$\nTo compute the curl of $\\mathbf{E}$, we apply the vector identity $\\nabla \\times (f\\mathbf{A}) = f(\\nabla \\times \\mathbf{A}) + (\\nabla f) \\times \\mathbf{A}$. In our case, $f(\\mathbf{r}) = \\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})$ and the vector $\\mathbf{A} = \\alpha\\mathbf{e}$ is constant. Thus, $\\nabla \\times \\mathbf{A} = \\mathbf{0}$. The gradient of $f$ is $\\nabla f = \\nabla \\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r}) = j\\mathbf{k}\\,\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})$.\nTherefore, the curl of $\\mathbf{E}$ is\n$$\n\\nabla \\times \\mathbf{E} = (\\nabla \\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})) \\times (\\alpha\\mathbf{e}) = (j\\mathbf{k}\\,\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})) \\times (\\alpha\\mathbf{e}) = j\\alpha(\\mathbf{k} \\times \\mathbf{e})\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})\n$$\nSubstituting this into the expression for $\\mathbf{H}$:\n$$\n\\mathbf{H}(\\mathbf{r}) = \\frac{j}{\\omega\\mu} \\left[ j\\alpha(\\mathbf{k} \\times \\mathbf{e})\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r}) \\right] = -\\frac{\\alpha}{\\omega\\mu}(\\mathbf{k} \\times \\mathbf{e})\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})\n$$\nNext, we evaluate the squared norms of the fields, $\\|\\mathbf{E}\\|^2 = \\mathbf{E} \\cdot \\mathbf{E}^*$ and $\\|\\mathbf{H}\\|^2 = \\mathbf{H} \\cdot \\mathbf{H}^*$, where $*$ denotes the complex conjugate.\nFor the electric field:\n$$\n\\|\\mathbf{E}(\\mathbf{r})\\|^2 = \\left(\\alpha\\,\\mathbf{e}\\,\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})\\right) \\cdot \\left(\\alpha\\,\\mathbf{e}^*\\,\\exp(-j\\,\\mathbf{k}\\cdot \\mathbf{r})\\right)\n$$\nSince $\\mathbf{e}$ is a real vector, $\\mathbf{e}^*=\\mathbf{e}$.\n$$\n\\|\\mathbf{E}(\\mathbf{r})\\|^2 = \\alpha^2 (\\mathbf{e}\\cdot\\mathbf{e}) \\exp(0) = \\alpha^2 \\|\\mathbf{e}\\|^2 = \\alpha^2(1)^2 = \\alpha^2\n$$\nFor the magnetic field:\n$$\n\\|\\mathbf{H}(\\mathbf{r})\\|^2 = \\left(-\\frac{\\alpha}{\\omega\\mu}(\\mathbf{k} \\times \\mathbf{e})\\exp(j\\,\\mathbf{k}\\cdot \\mathbf{r})\\right) \\cdot \\left(-\\frac{\\alpha}{\\omega\\mu}(\\mathbf{k} \\times \\mathbf{e})^*\\exp(-j\\,\\mathbf{k}\\cdot \\mathbf{r})\\right)\n$$\nSince $\\mathbf{k}$ and $\\mathbf{e}$ are real vectors, $(\\mathbf{k} \\times \\mathbf{e})^* = \\mathbf{k} \\times \\mathbf{e}$.\n$$\n\\|\\mathbf{H}(\\mathbf{r})\\|^2 = \\frac{\\alpha^2}{(\\omega\\mu)^2} \\|\\mathbf{k} \\times \\mathbf{e}\\|^2\n$$\nGiven the transversality condition $\\mathbf{k}\\cdot\\mathbf{e}=0$, the angle between $\\mathbf{k}$ and $\\mathbf{e}$ is $\\pi/2$. The magnitude of their cross product is $\\|\\mathbf{k} \\times \\mathbf{e}\\| = \\|\\mathbf{k}\\| \\|\\mathbf{e}\\| \\sin(\\pi/2) = \\|\\mathbf{k}\\|$. Let $k = \\|\\mathbf{k}\\|$.\nThen, $\\|\\mathbf{H}\\|^2 = \\frac{\\alpha^2 k^2}{\\omega^2\\mu^2}$.\nThe problem provides the dispersion relation for the plane wave: $k = \\omega\\sqrt{\\mu\\epsilon}$, which implies $k^2 = \\omega^2\\mu\\epsilon$. Substituting this into the expression for $\\|\\mathbf{H}\\|^2$:\n$$\n\\|\\mathbf{H}(\\mathbf{r})\\|^2 = \\frac{\\alpha^2(\\omega^2\\mu\\epsilon)}{\\omega^2\\mu^2} = \\alpha^2 \\frac{\\epsilon}{\\mu}\n$$\nWe observe that both $\\|\\mathbf{E}\\|^2$ and $\\|\\mathbf{H}\\|^2$ are constant throughout the domain $\\Omega$.\n\nNow we can evaluate the normalization integral. The integrand is\n$$\n\\epsilon\\,\\|\\mathbf{E}(\\mathbf{r})\\|^{2}+\\mu\\,\\|\\mathbf{H}(\\mathbf{r})\\|^{2} = \\epsilon\\alpha^2 + \\mu\\left(\\alpha^2 \\frac{\\epsilon}{\\mu}\\right) = \\epsilon\\alpha^2 + \\epsilon\\alpha^2 = 2\\epsilon\\alpha^2\n$$\nThis demonstrates the equipartition of time-averaged energy for a plane wave in a lossless medium: the electric and magnetic energy densities are equal, $\\frac{1}{4}\\epsilon\\|\\mathbf{E}\\|^2 = \\frac{1}{4}\\epsilon\\alpha^2$ and $\\frac{1}{4}\\mu\\|\\mathbf{H}\\|^2 = \\frac{1}{4}\\mu(\\alpha^2\\epsilon/\\mu) = \\frac{1}{4}\\epsilon\\alpha^2$.\n\nThe total energy is\n$$\n\\frac{1}{4}\\int_{\\Omega} (2\\epsilon\\alpha^2) \\,dV = \\frac{\\epsilon\\alpha^2}{2} \\int_{\\Omega} dV\n$$\nThe integral of $dV$ over the domain $\\Omega$ is its volume, $V$. So the total energy is\n$$\nW = \\frac{\\epsilon\\alpha^2 V}{2}\n$$\nSetting this equal to $1$ as per the normalization condition:\n$$\n\\frac{\\epsilon\\alpha^2 V}{2} = 1\n$$\nWe can now solve for $\\alpha$. Since $\\alpha$ is given as a nonnegative scalar:\n$$\n\\alpha^2 = \\frac{2}{\\epsilon V} \\implies \\alpha = \\sqrt{\\frac{2}{\\epsilon V}}\n$$\nThis is the required normalization constant expressed in terms of $\\epsilon$ and $V$.\n\nRegarding the conceptual question on normalization in lossy, dispersive media:\nIn such media, the permittivity $\\epsilon(\\omega)$ and/or permeability $\\mu(\\omega)$ become complex and frequency-dependent. This has several consequences. The governing wave operator is no longer Hermitian, leading to complex eigenvalues (complex frequencies $\\omega$), which represent temporal decay. The standard expression for time-averaged stored energy is no longer valid. The correct expression for the time-averaged energy density in a linear, dispersive, and weakly lossy medium is given by the Brillouin formula:\n$$\nw(\\mathbf{r}) = \\frac{1}{4}\\left(\\frac{d(\\omega\\,\\text{Re}\\{\\epsilon(\\omega)\\})}{d\\omega}\\|\\mathbf{E}(\\mathbf{r})\\|^2 + \\frac{d(\\omega\\,\\text{Re}\\{\\mu(\\omega)\\})}{d\\omega}\\|\\mathbf{H}(\\mathbf{r})\\|^2\\right)\n$$\nThis expression accounts for the energy stored in the dynamic response of the medium's polarization and magnetization.\nFor the non-Hermitian eigenvalue problems that arise in lossy or open systems, the right eigenvectors (the modes themselves) and the left eigenvectors are no longer adjoints of each other. They form a biorthogonal set. A mathematically consistent and widely used normalization convention for these problems is **biorthogonal normalization**. In this convention, a right eigenvector $\\mathbf{u}_i$ and a left eigenvector $\\mathbf{v}_j$ corresponding to distinct eigenvalues are orthogonal under a suitably defined inner product, and the normalization is chosen such that $\\langle \\mathbf{v}_j, \\mathbf{u}_i \\rangle = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. This ensures a unique modal expansion for any arbitrary field.",
            "answer": "$$\n\\boxed{\\sqrt{\\frac{2}{\\epsilon V}}}\n$$"
        },
        {
            "introduction": "While analytical solutions are possible for simple geometries, most real-world eigenvalue problems in electromagnetics require numerical methods like the Finite Element Method (FEM). A common and challenging task is to find resonant modes not at the extremes of the spectrum, but within a specific frequency range of interest. This practice  delves into the 'shift-and-invert' spectral transformation, a powerful and widely-used strategy in computational science that cleverly converts the hard problem of finding these 'interior' eigenvalues into an easy one of finding the largest-magnitude eigenvalues of a transformed operator.",
            "id": "3304065",
            "problem": "A source-free, perfectly electrically conducting cavity is modeled in the frequency domain by the curl-curl eigenproblem derived from Maxwellâ€™s equations: find nontrivial electric fields $\\mathbf{E}$ and angular frequency $\\omega$ such that\n$$\n\\nabla \\times \\mu^{-1} \\nabla \\times \\mathbf{E} \\;=\\; \\omega^{2} \\,\\epsilon\\, \\mathbf{E}, \n$$\nwith the boundary condition $\\mathbf{n}\\times \\mathbf{E} = \\mathbf{0}$ on the conducting boundary. A conforming Finite Element Method (FEM) discretization on an appropriate divergence-free subspace leads to the generalized matrix eigenvalue problem\n$$\n\\mathbf{K}\\,\\mathbf{e} \\;=\\; \\lambda\\, \\mathbf{M}\\,\\mathbf{e}, \n$$\nwhere $\\mathbf{K}$ and $\\mathbf{M}$ are Hermitian matrices arising from the bilinear forms of the curl-curl and mass terms, respectively, $\\lambda = \\omega^{2}$, the mass matrix $\\mathbf{M}$ is Hermitian positive definite on the discrete subspace, and the stiffness matrix $\\mathbf{K}$ is Hermitian positive semidefinite. Suppose the goal is to compute eigenvalues $\\lambda$ that lie near a prescribed real shift $\\sigma \\in \\mathbb{R}$, with $\\sigma$ not equal to any exact eigenvalue.\n\nConsider applying a Krylov subspace method to a linear-operator mapping that is defined implicitly by, for a given vector $\\mathbf{v}$, computing $\\mathbf{w}$ as the unique solution of the linear system\n$$\n\\left(\\mathbf{K} - \\sigma \\mathbf{M}\\right)\\,\\mathbf{w} \\;=\\; \\mathbf{M}\\,\\mathbf{v},\n$$\nand then returning $\\mathbf{w}$ as the operator action on $\\mathbf{v}$. This construction is commonly used to accelerate convergence to eigenvalues near $\\sigma$.\n\nWhich of the following statements about this construction are correct? Select all that apply.\n\nA. If $(\\lambda, \\mathbf{e})$ is an eigenpair of $\\mathbf{K}\\,\\mathbf{e}=\\lambda \\mathbf{M}\\,\\mathbf{e}$ with $\\lambda \\neq \\sigma$, then $\\mathbf{e}$ is an eigenvector of the implicitly defined operator with eigenvalue $\\mu = (\\lambda - \\sigma)^{-1}$. Consequently, eigenvalues $\\lambda$ close to $\\sigma$ are mapped to eigenvalues $\\mu$ of large magnitude.\n\nB. The construction maps eigenvalues $\\lambda$ close to $\\sigma$ to eigenvalues $\\mu$ of small magnitude, so methods that target dominant (largest-magnitude) eigenvalues will tend to converge to eigenvalues far from $\\sigma$.\n\nC. To preserve the eigenvectors, the method requires explicitly forming $\\left(\\mathbf{K}-\\sigma \\mathbf{M}\\right)^{-1}$; merely solving linear systems with coefficient $\\left(\\mathbf{K}-\\sigma \\mathbf{M}\\right)$ does not produce the same eigenpairs.\n\nD. Assume $\\mathbf{K}$ and $\\mathbf{M}$ are Hermitian and $\\mathbf{M}$ is positive definite, and $\\sigma \\in \\mathbb{R}$ lies outside the spectrum. Then the implicitly defined operator is self-adjoint with respect to the $\\mathbf{M}$-inner product, has real eigenvalues $\\mu$, and admits an $\\mathbf{M}$-orthogonal eigenbasis coinciding with the generalized eigenvectors of the original problem.\n\nE. Each application of the implicitly defined operator within a Krylov subspace method incurs the solution of a linear system with coefficient matrix $\\left(\\mathbf{K}-\\sigma \\mathbf{M}\\right)$ and right-hand side $\\mathbf{M}$ times the current vector.",
            "solution": "The user has provided a problem statement regarding the properties of a shift-and-invert spectral transformation for a generalized eigenvalue problem arising from the Finite Element Method (FEM) discretization of Maxwell's equations in a resonant cavity.\n\n### Step 1: Extract Givens\n\n-   **Continuous Eigenproblem**: Find nontrivial electric fields $\\mathbf{E}$ and angular frequency $\\omega$ such that $\\nabla \\times \\mu^{-1} \\nabla \\times \\mathbf{E} \\;=\\; \\omega^{2} \\,\\epsilon\\, \\mathbf{E}$.\n-   **Boundary Condition**: $\\mathbf{n}\\times \\mathbf{E} = \\mathbf{0}$ on the perfectly conducting boundary.\n-   **Discretized Eigenproblem**: $\\mathbf{K}\\,\\mathbf{e} \\;=\\; \\lambda\\, \\mathbf{M}\\,\\mathbf{e}$.\n-   **Matrix Properties**:\n    -   $\\mathbf{K}$ is a Hermitian positive semidefinite stiffness matrix.\n    -   $\\mathbf{M}$ is a Hermitian positive definite mass matrix.\n    -   The eigenvalue is $\\lambda = \\omega^{2}$.\n-   **Computational Goal**: Compute eigenvalues $\\lambda$ near a prescribed real shift $\\sigma \\in \\mathbb{R}$.\n-   **Constraint on Shift**: $\\sigma$ is not equal to any exact eigenvalue $\\lambda$.\n-   **Operator Definition**: An operator is defined implicitly. For a given vector $\\mathbf{v}$, the operator's action on $\\mathbf{v}$ yields a vector $\\mathbf{w}$ which is the unique solution to the linear system $\\left(\\mathbf{K} - \\sigma \\mathbf{M}\\right)\\,\\mathbf{w} \\;=\\; \\mathbf{M}\\,\\mathbf{v}$.\n\n### Step 2: Validate Using Extracted Givens\n\n-   **Scientific Groundedness**: The problem is well-grounded in computational electromagnetics and numerical linear algebra. The curl-curl equation is the standard starting point for frequency-domain analysis of source-free electromagnetic cavities. Its FEM discretization leading to a generalized eigenvalue problem $\\mathbf{K}\\,\\mathbf{e} \\;=\\; \\lambda\\, \\mathbf{M}\\,\\mathbf{e}$ is a cornerstone of the field. The properties of $\\mathbf{K}$ and $\\mathbf{M}$ being Hermitian and positive (semi)definite are correct for standard Galerkin FEM formulations.\n-   **Well-Posedness**: The problem describes the shift-and-invert spectral transformation. The condition that the shift $\\sigma$ is not an eigenvalue ensures that the matrix $\\mathbf{K} - \\sigma \\mathbf{M}$ is non-singular (invertible), making the operator well-defined. The questions posed about this operator's properties are standard and have definite answers.\n-   **Objectivity**: The problem is stated using precise, standard mathematical and engineering terminology (e.g., Hermitian, positive definite, Krylov subspace method, eigenpair). It is free of subjective or ambiguous language.\n-   **Completeness and Consistency**: The problem provides all necessary information and definitions to analyze the proposed operator. There are no contradictions in the setup.\n-   **Feasibility and Realism**: The described method, known as the shift-and-invert strategy (often used with Arnoldi or Lanczos algorithms), is a widely used and highly effective practical technique for finding interior eigenvalues of large sparse matrix systems.\n\n### Step 3: Verdict and Action\n\nThe problem statement is valid. It is a standard, well-posed problem in numerical methods for engineering. I will proceed with the derivation and analysis of the options.\n\n### Derivation of Operator Properties\n\nThe problem defines an operator, let's call it $\\mathbf{T}$, whose action on a vector $\\mathbf{v}$ is to produce a vector $\\mathbf{w}$ by solving the system:\n$$ (\\mathbf{K} - \\sigma \\mathbf{M})\\,\\mathbf{w} = \\mathbf{M}\\,\\mathbf{v} $$\nSince $\\sigma$ is not an eigenvalue, the matrix $(\\mathbf{K} - \\sigma \\mathbf{M})$ is invertible. Thus, we can write the operator $\\mathbf{T}$ explicitly as:\n$$ \\mathbf{T} = (\\mathbf{K} - \\sigma \\mathbf{M})^{-1} \\mathbf{M} $$\n\nLet $(\\lambda, \\mathbf{e})$ be an eigenpair of the original problem, satisfying $\\mathbf{K}\\,\\mathbf{e} = \\lambda \\mathbf{M}\\,\\mathbf{e}$. We will analyze the action of $\\mathbf{T}$ on the eigenvector $\\mathbf{e}$.\n\nWe rearrange the original eigenvalue equation:\n$$ \\mathbf{K}\\,\\mathbf{e} - \\sigma \\mathbf{M}\\,\\mathbf{e} = \\lambda \\mathbf{M}\\,\\mathbf{e} - \\sigma \\mathbf{M}\\,\\mathbf{e} $$\n$$ (\\mathbf{K} - \\sigma \\mathbf{M})\\,\\mathbf{e} = (\\lambda - \\sigma) \\mathbf{M}\\,\\mathbf{e} $$\nSince $\\lambda$ is an eigenvalue and $\\sigma$ is not, $\\lambda \\neq \\sigma$, so the scalar $(\\lambda - \\sigma)$ is non-zero. We can left-multiply by $(\\mathbf{K} - \\sigma \\mathbf{M})^{-1}$:\n$$ \\mathbf{e} = (\\mathbf{K} - \\sigma \\mathbf{M})^{-1}(\\lambda - \\sigma) \\mathbf{M}\\,\\mathbf{e} $$\nFactoring out the scalar $(\\lambda - \\sigma)$:\n$$ \\mathbf{e} = (\\lambda - \\sigma) \\left[ (\\mathbf{K} - \\sigma \\mathbf{M})^{-1} \\mathbf{M} \\right] \\mathbf{e} $$\nRecognizing the operator $\\mathbf{T}$:\n$$ \\mathbf{e} = (\\lambda - \\sigma) \\mathbf{T}\\,\\mathbf{e} $$\nDividing by the non-zero scalar $(\\lambda - \\sigma)$, we get the eigenvalue equation for the operator $\\mathbf{T}$:\n$$ \\mathbf{T}\\,\\mathbf{e} = \\frac{1}{\\lambda - \\sigma} \\mathbf{e} $$\nThis shows that $\\mathbf{e}$ is an eigenvector of the operator $\\mathbf{T}$. The corresponding eigenvalue, let's call it $\\mu$, is:\n$$ \\mu = \\frac{1}{\\lambda - \\sigma} $$\n\n### Option-by-Option Analysis\n\n**A. If $(\\lambda, \\mathbf{e})$ is an eigenpair of $\\mathbf{K}\\,\\mathbf{e}=\\lambda \\mathbf{M}\\,\\mathbf{e}$ with $\\lambda \\neq \\sigma$, then $\\mathbf{e}$ is an eigenvector of the implicitly defined operator with eigenvalue $\\mu = (\\lambda - \\sigma)^{-1}$. Consequently, eigenvalues $\\lambda$ close to $\\sigma$ are mapped to eigenvalues $\\mu$ of large magnitude.**\n\nThis statement is a direct consequence of our derivation above. The eigenvalue of the operator $\\mathbf{T}$ is indeed $\\mu = (\\lambda - \\sigma)^{-1}$. If the original eigenvalue $\\lambda$ is close to the shift $\\sigma$, the denominator $(\\lambda - \\sigma)$ becomes a small number. The reciprocal of a small number is a large number. Therefore, eigenvalues $\\lambda$ near $\\sigma$ are mapped to eigenvalues $\\mu$ of large magnitude. This property is precisely why this method is used: Krylov methods like Arnoldi or Lanczos converge most rapidly to the eigenvalues of largest magnitude (dominant eigenvalues).\n**Verdict: Correct.**\n\n**B. The construction maps eigenvalues $\\lambda$ close to $\\sigma$ to eigenvalues $\\mu$ of small magnitude, so methods that target dominant (largest-magnitude) eigenvalues will tend to converge to eigenvalues far from $\\sigma$.**\n\nThis statement is the logical opposite of the conclusion in option A. As derived, eigenvalues $\\lambda$ close to $\\sigma$ are mapped to eigenvalues $\\mu$ of large magnitude, not small. Therefore, Krylov methods that find dominant eigenvalues will converge to the desired eigenvalues (those near $\\sigma$).\n**Verdict: Incorrect.**\n\n**C. To preserve the eigenvectors, the method requires explicitly forming $\\left(\\mathbf{K}-\\sigma \\mathbf{M}\\right)^{-1}$; merely solving linear systems with coefficient $\\left(\\mathbf{K}-\\sigma \\mathbf{M}\\right)$ does not produce the same eigenpairs.**\n\nThis statement reflects a misunderstanding of how Krylov subspace methods are implemented. The action of the operator $\\mathbf{T}$ on a vector $\\mathbf{v}$ is $\\mathbf{T}\\mathbf{v} = (\\mathbf{K} - \\sigma \\mathbf{M})^{-1} \\mathbf{M} \\mathbf{v}$. Computationally, this is performed by first computing the vector $\\mathbf{b} = \\mathbf{M}\\mathbf{v}$, and then solving the linear system $(\\mathbf{K} - \\sigma \\mathbf{M})\\mathbf{w} = \\mathbf{b}$ for $\\mathbf{w}$. The solution $\\mathbf{w}$ is equal to $\\mathbf{T}\\mathbf{v}$. This procedure *is* the application of the operator. Explicitly forming the inverse matrix is computationally far more expensive (e.g., $O(N^3)$ for dense matrices) and often numerically less stable than solving the corresponding linear system (e.g., $O(N^2)$ for a dense LU factorization, and much faster for sparse systems). Solving the system is the standard, efficient, and correct way to implement the action of the inverse operator. The eigenvectors are perfectly preserved by this procedure.\n**Verdict: Incorrect.**\n\n**D. Assume $\\mathbf{K}$ and $\\mathbf{M}$ are Hermitian and $\\mathbf{M}$ is positive definite, and $\\sigma \\in \\mathbb{R}$ lies outside the spectrum. Then the implicitly defined operator is self-adjoint with respect to the $\\mathbf{M}$-inner product, has real eigenvalues $\\mu$, and admits an $\\mathbf{M}$-orthogonal eigenbasis coinciding with the generalized eigenvectors of the original problem.**\n\nLet's verify the self-adjointness with respect to the $\\mathbf{M}$-inner product, which is defined as $\\langle \\mathbf{x}, \\mathbf{y} \\rangle_{\\mathbf{M}} = \\mathbf{y}^H \\mathbf{M} \\mathbf{x}$. The operator $\\mathbf{T}$ is self-adjoint if $\\langle \\mathbf{T}\\mathbf{x}, \\mathbf{y} \\rangle_{\\mathbf{M}} = \\langle \\mathbf{x}, \\mathbf{T}\\mathbf{y} \\rangle_{\\mathbf{M}}$.\n\nLeft-hand side: $\\langle \\mathbf{T}\\mathbf{x}, \\mathbf{y} \\rangle_{\\mathbf{M}} = \\mathbf{y}^H \\mathbf{M} (\\mathbf{T}\\mathbf{x}) = \\mathbf{y}^H \\mathbf{M} (\\mathbf{K} - \\sigma\\mathbf{M})^{-1} \\mathbf{M} \\mathbf{x}$.\n\nRight-hand side: $\\langle \\mathbf{x}, \\mathbf{T}\\mathbf{y} \\rangle_{\\mathbf{M}} = (\\mathbf{T}\\mathbf{y})^H \\mathbf{M} \\mathbf{x} = ((\\mathbf{K} - \\sigma\\mathbf{M})^{-1} \\mathbf{M} \\mathbf{y})^H \\mathbf{M} \\mathbf{x} = \\mathbf{y}^H \\mathbf{M}^H ((\\mathbf{K} - \\sigma\\mathbf{M})^{-1})^H \\mathbf{M} \\mathbf{x}$.\n\nGiven that $\\mathbf{K}$ and $\\mathbf{M}$ are Hermitian and $\\sigma$ is real, the matrix $(\\mathbf{K} - \\sigma\\mathbf{M})$ is also Hermitian: $(\\mathbf{K} - \\sigma\\mathbf{M})^H = \\mathbf{K}^H - \\sigma^* \\mathbf{M}^H = \\mathbf{K} - \\sigma \\mathbf{M}$. The inverse of a Hermitian matrix is Hermitian, so $((\\mathbf{K} - \\sigma\\mathbf{M})^{-1})^H = (\\mathbf{K} - \\sigma\\mathbf{M})^{-1}$. Also, $\\mathbf{M}^H = \\mathbf{M}$. Substituting these into the RHS expression gives:\nRHS = $\\mathbf{y}^H \\mathbf{M} (\\mathbf{K} - \\sigma\\mathbf{M})^{-1} \\mathbf{M} \\mathbf{x}$, which is identical to the LHS.\nThus, the operator $\\mathbf{T}$ is self-adjoint with respect to the $\\mathbf{M}$-inner product. A fundamental result in linear algebra states that an operator that is self-adjoint with respect to an inner product has real eigenvalues and possesses a complete set of eigenvectors that are orthogonal with respect to that same inner product. The eigenvalues $\\mu = (\\lambda - \\sigma)^{-1}$ are indeed real since $\\lambda$ and $\\sigma$ are real. The eigenvectors are the same as the generalized eigenvectors $\\mathbf{e}$ of the original problem, which are known to form an $\\mathbf{M}$-orthogonal set.\n**Verdict: Correct.**\n\n**E. Each application of the implicitly defined operator within a Krylov subspace method incurs the solution of a linear system with coefficient matrix $\\left(\\mathbf{K}-\\sigma \\mathbf{M}\\right)$ and right-hand side $\\mathbf{M}$ times the current vector.**\n\nThis statement is a precise procedural description of applying the operator $\\mathbf{T}$. A Krylov subspace method builds a basis for the subspace $\\text{span}(\\mathbf{v}, \\mathbf{T}\\mathbf{v}, \\mathbf{T}^2\\mathbf{v}, \\dots)$. To compute the next vector in the sequence, e.g., $\\mathbf{w} = \\mathbf{T}\\mathbf{v}$, one must solve the linear system $(\\mathbf{K} - \\sigma \\mathbf{M})\\mathbf{w} = \\mathbf{M}\\mathbf{v}$, as specified in the problem's definition of the operator. The coefficient matrix is $(\\mathbf{K} - \\sigma \\mathbf{M})$ and the right-hand side is $\\mathbf{M}$ times the input vector $\\mathbf{v}$. This is exactly how the shift-and-invert method is implemented.\n**Verdict: Correct.**",
            "answer": "$$\\boxed{ADE}$$"
        },
        {
            "introduction": "Beyond the familiar realm of lossless, energy-conserving systems which yield Hermitian eigenvalue problems, a vibrant research area explores non-Hermitian systems incorporating material gain and loss. Such systems can exhibit fascinating and counter-intuitive phenomena, particularly when they possess a special kind of symmetry known as parity-time (PT) symmetry. This advanced exercise  uses a canonical $2 \\times 2$ matrix model to investigate the physics of PT-symmetry breaking, the coalescence of eigenvalues and eigenvectors at an 'exceptional point', and the associated Jordan form structure that departs fundamentally from standard Hermitian theory.",
            "id": "3304079",
            "problem": "Consider a one-dimensional, uniform, translationally invariant electromagnetic waveguide along the $z$-axis, with a scalar transverse electric field profile $E(x,z) = \\psi(x)\\,e^{i \\beta z}$, where $\\beta$ is the complex propagation constant and $\\psi(x)$ is the transverse mode profile. Assume time-harmonic fields with angular frequency $\\omega$ and neglect magnetic contrast (relative permeability equal to $1$). Let the relative permittivity be of the balanced gain/loss form $\\epsilon_r(x) = \\epsilon_{r0} + i \\gamma f(x)$, with $f(x)$ a real-valued function satisfying $f(-x) = - f(x)$ to enforce parity-time (PT) symmetry, and $\\gamma \\ge 0$ a real control parameter. \n\nStarting from Maxwell's equations and the Helmholtz equation for $\\psi(x)$, a two-mode coupled-mode reduction approximates the non-Hermitian eigenvalue problem governing the lowest two supermodes by a $2 \\times 2$ matrix operator of the form\n$$\n\\mathbf{A}(\\gamma) = \n\\begin{bmatrix}\n\\beta_0 + i \\gamma & \\kappa \\\\\n\\kappa & \\beta_0 - i \\gamma\n\\end{bmatrix},\n$$\nwhere $\\beta_0$ and $\\kappa$ are real constants determined by the underlying symmetric conservative structure (for $\\gamma = 0$). This reduced operator is PT-symmetric, non-Hermitian for $\\gamma \\ne 0$, and its spectrum $\\{\\lambda_j(\\gamma)\\}$ approximates $\\{\\beta_j(\\gamma)\\}$ for the two supermodes.\n\nYour task is to implement a program that, for specified parameter sets $(\\beta_0, \\kappa)$ and a scan range of $\\gamma$, will:\n\n1. Formulate the eigenvalue problem $\\mathbf{A}(\\gamma)\\,\\mathbf{v} = \\lambda\\,\\mathbf{v}$ and compute both eigenvalues for each sampled $\\gamma$.\n2. Identify the $\\gamma$ value within the scan range at which the two eigenvalues coalesce most closely (in the sense of minimizing the absolute separation $|\\lambda_1(\\gamma) - \\lambda_2(\\gamma)|$). Denote this value by $\\gamma^\\star$ and the corresponding (nearly) coalesced eigenvalue by $\\lambda^\\star$.\n3. Determine whether the coalescence at $\\gamma^\\star$ is an exceptional point in the strict sense of a defective eigenvalue (algebraic multiplicity exceeding geometric multiplicity). Classify it by computing the nullity of $\\mathbf{A}(\\gamma^\\star) - \\lambda^\\star \\mathbf{I}$: if the nullity equals $1$ while the two eigenvalues are equal within a numerical tolerance, declare a defective point; if the nullity equals $2$ at equality, it is a non-defective degeneracy; if the eigenvalues are not equal within tolerance, then no exceptional point is found within the scan.\n4. For the defective case, compute a Jordan chain vector $\\mathbf{w}$ associated with $\\lambda^\\star$ by solving the generalized chain equation\n$$\n\\left(\\mathbf{A}(\\gamma^\\star) - \\lambda^\\star \\mathbf{I}\\right)\\,\\mathbf{w} = \\mathbf{v},\n$$\nwhere $\\mathbf{v}$ is a (right) eigenvector satisfying $\\left(\\mathbf{A}(\\gamma^\\star) - \\lambda^\\star \\mathbf{I}\\right)\\,\\mathbf{v} = \\mathbf{0}$. In the non-defective or non-coalesced cases, still attempt to compute an approximate generalized eigenvector $\\mathbf{w}$ via a least-squares solution of the same equation and report the residual norm. Quantify the chain equation residual by\n$$\nr = \\left\\|\\left(\\mathbf{A}(\\gamma^\\star) - \\lambda^\\star \\mathbf{I}\\right)\\,\\mathbf{w} - \\mathbf{v}\\right\\|_2.\n$$\n\nUse dimensionless normalized units throughout (no physical unit conversion is required; all quantities are treated as dimensionless). Employ a fixed absolute numerical tolerance of $10^{-8}$ when determining equality of eigenvalues and counting the numerical nullity via singular values.\n\nImplement the above for the following test suite, scanning $\\gamma$ over a uniformly spaced grid:\n\n- Test case $1$ (happy path, PT-symmetry breaking inside the scan): $\\beta_0 = 10.0$, $\\kappa = 0.3$, $\\gamma$ scanned from $0.0$ to $0.6$ with step $0.002$.\n- Test case $2$ (boundary condition, degeneracy without defect): $\\beta_0 = 10.0$, $\\kappa = 0.0$, $\\gamma$ scanned from $0.0$ to $0.4$ with step $0.002$.\n- Test case $3$ (edge case, no exceptional point within scan range): $\\beta_0 = 10.0$, $\\kappa = 0.25$, $\\gamma$ scanned from $0.0$ to $0.2$ with step $0.002$.\n\nFor each test case, produce a result consisting of a list with three entries:\n- The identified $\\gamma^\\star$ as a float.\n- The residual norm $r$ as a float.\n- A boolean indicating whether a defective exceptional point was detected at $\\gamma^\\star$.\n\nFinal output format: Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case result is itself a list of the form $[\\gamma^\\star, r, \\text{defective}]$. For example, the output should look like $[[\\ldots],[\\ldots],[\\ldots]]$. Angles do not appear; no physical units are required because all quantities are dimensionless.",
            "solution": "The problem requires an analysis of a $2 \\times 2$ non-Hermitian, parity-time (PT) symmetric matrix operator, which serves as a simplified model for a two-mode electromagnetic waveguide with balanced gain and loss. The objective is to identify and characterize exceptional points (EPs) within a specified parameter range.\n\nThe governing matrix operator is given by:\n$$\n\\mathbf{A}(\\gamma) = \n\\begin{bmatrix}\n\\beta_0 + i \\gamma & \\kappa \\\\\n\\kappa & \\beta_0 - i \\gamma\n\\end{bmatrix}\n$$\nwhere $\\beta_0$ and $\\kappa$ are real constants representing the underlying conservative system, and $\\gamma \\ge 0$ is a real parameter controlling the magnitude of the non-Hermitian, gain-loss term.\n\nFirst, we establish the analytical properties of this system by solving the eigenvalue problem $\\mathbf{A}(\\gamma)\\mathbf{v} = \\lambda\\mathbf{v}$. The eigenvalues $\\lambda$ are found from the characteristic equation $\\det(\\mathbf{A}(\\gamma) - \\lambda \\mathbf{I}) = 0$:\n$$\n\\det \\begin{bmatrix}\n(\\beta_0 - \\lambda) + i \\gamma & \\kappa \\\\\n\\kappa & (\\beta_0 - \\lambda) - i \\gamma\n\\end{bmatrix} = 0\n$$\n$$\n((\\beta_0 - \\lambda) + i \\gamma)((\\beta_0 - \\lambda) - i \\gamma) - \\kappa^2 = 0\n$$\n$$\n(\\beta_0 - \\lambda)^2 - (i\\gamma)^2 - \\kappa^2 = 0\n$$\n$$\n(\\beta_0 - \\lambda)^2 = \\kappa^2 - \\gamma^2\n$$\nThis yields the two eigenvalues:\n$$\n\\lambda_{1,2}(\\gamma) = \\beta_0 \\mp \\sqrt{\\kappa^2 - \\gamma^2}\n$$\n\nThe behavior of the eigenvalues depends on the relationship between $\\gamma$ and $|\\kappa|$. Assuming, without loss of generality, that $\\kappa \\ge 0$:\n1.  **PT-Symmetric Phase ($\\gamma < \\kappa$):** The term $\\kappa^2 - \\gamma^2$ is positive, so the eigenvalues $\\lambda_{1,2}$ are real and distinct. The system possesses a purely real spectrum, a hallmark of an unbroken PT-symmetry phase.\n2.  **Exceptional Point ($\\gamma = \\kappa$):** The square root term vanishes, causing the eigenvalues to coalesce to a single value: $\\lambda_1 = \\lambda_2 = \\beta_0$. This point of coalescence is a candidate for an exceptional point.\n3.  **PT-Broken Phase ($\\gamma > \\kappa$):** The term $\\kappa^2 - \\gamma^2$ is negative. The eigenvalues become a complex conjugate pair: $\\lambda_{1,2} = \\beta_0 \\mp i\\sqrt{\\gamma^2 - \\kappa^2}$. The emergence of a complex spectrum signifies a spontaneous breaking of PT symmetry.\n\nTo determine if the coalescence at $\\gamma^\\star = \\kappa$ is a defective exceptional point, we must check if the geometric multiplicity of the eigenvalue is less than its algebraic multiplicity. The algebraic multiplicity is $2$ by virtue of the coalescence. The geometric multiplicity is the dimension of the null space (nullity) of the matrix $\\mathbf{M} = \\mathbf{A}(\\gamma^\\star) - \\lambda^\\star\\mathbf{I}$. Here, $\\gamma^\\star = \\kappa$ and $\\lambda^\\star = \\beta_0$.\n$$\n\\mathbf{M} = \\mathbf{A}(\\kappa) - \\beta_0\\mathbf{I} = \n\\begin{bmatrix}\n\\beta_0 + i \\kappa & \\kappa \\\\\n\\kappa & \\beta_0 - i \\kappa\n\\end{bmatrix} - \n\\begin{bmatrix}\n\\beta_0 & 0 \\\\\n0 & \\beta_0\n\\end{bmatrix} = \n\\begin{bmatrix}\ni \\kappa & \\kappa \\\\\n\\kappa & -i \\kappa\n\\end{bmatrix}\n$$\nFor $\\kappa \\ne 0$, the two rows of this matrix are linearly dependent (the second row is $-i$ times the first). Therefore, the rank of $\\mathbf{M}$ is $1$. By the rank-nullity theorem, the nullity is $2 - \\text{rank}(\\mathbf{M}) = 2 - 1 = 1$. Since the geometric multiplicity ($1$) is less than the algebraic multiplicity ($2$), the matrix is defective, and the coalescence at $\\gamma = \\kappa$ is a true exceptional point. An important special case is when $\\kappa=0$, where the matrix $\\mathbf{M}$ is the zero matrix at $\\gamma=0$, having a nullity of $2$. This corresponds to a non-defective (diabolical) degeneracy.\n\nAt a defective EP, the eigenvectors also coalesce. The single eigenvector $\\mathbf{v}$ is part of a Jordan chain, which includes a generalized eigenvector $\\mathbf{w}$ satisfying the chain equation:\n$$\n\\mathbf{M}\\,\\mathbf{w} = (\\mathbf{A}(\\gamma^\\star) - \\lambda^\\star \\mathbf{I})\\,\\mathbf{w} = \\mathbf{v}\n$$\nwhere $\\mathbf{v}$ is the eigenvector satisfying $(\\mathbf{A}(\\gamma^\\star) - \\lambda^\\star \\mathbf{I})\\mathbf{v} = \\mathbf{0}$. For a defective matrix, this system is consistent and solvable for $\\mathbf{w}$.\n\nThe numerical implementation proceeds as follows:\n1.  For each test case, we define a grid of $\\gamma$ values.\n2.  At each $\\gamma$, we construct matrix $\\mathbf{A}(\\gamma)$ and compute its eigenvalues $\\lambda_1, \\lambda_2$.\n3.  We find the value $\\gamma^\\star$ that minimizes the absolute separation $|\\lambda_1 - \\lambda_2|$. The corresponding nearly-coalesced eigenvalue $\\lambda^\\star$ is taken as the average of the two eigenvalues at $\\gamma^\\star$.\n4.  To classify the point at $\\gamma^\\star$, we construct $\\mathbf{M} = \\mathbf{A}(\\gamma^\\star) - \\lambda^\\star\\mathbf{I}$. The numerical nullity of $\\mathbf{M}$ is determined by counting its singular values that are smaller than a given tolerance of $10^{-8}$. An EP is detected if the nullity is $1$ and the eigenvalue separation is also below the tolerance.\n5.  An eigenvector $\\mathbf{v}$ corresponding to $\\lambda^\\star$ is computed and normalized. The generalized eigenvector $\\mathbf{w}$ is found by solving the linear system $\\mathbf{M}\\mathbf{w} = \\mathbf{v}$ using a least-squares solver (`numpy.linalg.lstsq`), which is robust for both singular (defective/degenerate) and non-singular cases.\n6.  Finally, the residual norm $r = \\|\\mathbf{M}\\mathbf{w} - \\mathbf{v}\\|_2$ is computed. This norm quantifies how well the Jordan chain equation is satisfied. It will be near zero for a true EP or a non-coalesced point (where $\\mathbf{M}$ is invertible), but significantly non-zero for a non-defective degeneracy (where $\\mathbf{M}=\\mathbf{0}$ and $\\mathbf{v}\\ne\\mathbf{0}$).",
            "answer": "```python\nimport numpy as np\n\ndef analyze_pt_system(beta0, kappa, gamma_range, tol):\n    \"\"\"\n    Analyzes a 2x2 PT-symmetric system to find and classify exceptional points.\n\n    Args:\n        beta0 (float): Real part of the diagonal elements.\n        kappa (float): Real coupling coefficient.\n        gamma_range (tuple): A tuple (start, stop, step) defining the scan range for gamma.\n        tol (float): Numerical tolerance for equality and nullity checks.\n\n    Returns:\n        list: A list containing [gamma_star, residual_norm, is_defective].\n    \"\"\"\n    gamma_start, gamma_stop, gamma_step = gamma_range\n    num_points = int(round((gamma_stop - gamma_start) / gamma_step)) + 1\n    gammas = np.linspace(gamma_start, gamma_stop, num_points)\n\n    min_separation = float('inf')\n    gamma_star = -1.0\n    eigenvalues_at_min_sep = None\n\n    for gamma in gammas:\n        A = np.array([\n            [beta0 + 1j * gamma, kappa],\n            [kappa,             beta0 - 1j * gamma]\n        ], dtype=np.complex128)\n        \n        eigenvalues = np.linalg.eigvals(A)\n        separation = np.abs(eigenvalues[0] - eigenvalues[1])\n        \n        if separation < min_separation:\n            min_separation = separation\n            gamma_star = gamma\n            eigenvalues_at_min_sep = eigenvalues\n\n    # Perform analysis at the identified point gamma_star\n    A_star = np.array([\n        [beta0 + 1j * gamma_star, kappa],\n        [kappa,             beta0 - 1j * gamma_star]\n    ], dtype=np.complex128)\n    \n    # The coalesced eigenvalue is approximated by the mean of the two nearly-equal eigenvalues\n    lambda_star = np.mean(eigenvalues_at_min_sep)\n\n    # Construct the matrix M for defectiveness and Jordan chain analysis\n    M = A_star - lambda_star * np.identity(2, dtype=np.complex128)\n\n    # 1. Defectiveness check using SVD for numerical nullity\n    _ , s, _ = np.linalg.svd(M)\n    nullity = np.sum(s < tol)\n    \n    # An EP is defective if nullity is 1 and eigenvalues are coalesced\n    is_defective = (nullity == 1) and (min_separation < tol)\n\n    # 2. Jordan chain vector and residual norm calculation\n    # Find the eigenvector v. Using np.linalg.eig on A_star is robust.\n    _ , eigvecs_star = np.linalg.eig(A_star)\n    \n    # Choose the eigenvector whose eigenvalue is closest to lambda_star\n    v_index = np.argmin(np.abs(np.linalg.eigvals(A_star) - lambda_star))\n    v = eigvecs_star[:, v_index]\n    v = v / np.linalg.norm(v)  # Normalize for a consistent residual measure\n\n    # Solve M w = v for w using least squares, which handles all cases\n    w, _, _, _ = np.linalg.lstsq(M, v, rcond=None)\n    \n    # Calculate the residual norm as per the problem definition\n    residual_norm = np.linalg.norm(M @ w - v)\n    \n    return [gamma_star, residual_norm, is_defective]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (beta0, kappa, (gamma_start, gamma_stop, gamma_step))\n        (10.0, 0.3,  (0.0, 0.6, 0.002)),  # PT-breaking inside scan\n        (10.0, 0.0,  (0.0, 0.4, 0.002)),  # Non-defective degeneracy\n        (10.0, 0.25, (0.0, 0.2, 0.002)),  # No EP in scan range\n    ]\n    \n    tolerance = 1e-8\n    results = []\n    \n    for case in test_cases:\n        beta0, kappa, gamma_range = case\n        result = analyze_pt_system(beta0, kappa, gamma_range, tolerance)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The default str() representation of list and boolean matches the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}