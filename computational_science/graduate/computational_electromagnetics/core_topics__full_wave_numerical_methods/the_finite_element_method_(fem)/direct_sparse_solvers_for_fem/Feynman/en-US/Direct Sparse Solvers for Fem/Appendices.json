{
    "hands_on_practices": [
        {
            "introduction": "This exercise forms the crucial link between the finite element mesh and the algebraic system matrix you aim to solve. By manually predicting the global sparsity pattern and calculating the matrix bandwidth for a simple 2D electromagnetics problem , you will gain a concrete intuition for how the structure of a sparse matrix arises directly from the mesh connectivity and choice of basis functions. This foundational skill is essential for understanding the performance of any sparse solver.",
            "id": "3299951",
            "problem": "Consider a two-dimensional Transverse Electric (TE) cavity with Perfect Electric Conductor (PEC) walls occupying the unit square domain $\\Omega = [0,1] \\times [0,1]$. In the frequency domain, the governing equations are derived from Maxwell’s equations for the electric field $\\mathbf{E}$ and magnetic flux density $\\mathbf{B}$, assuming time-harmonic fields with angular frequency $\\omega$, uniform permeability $\\mu$, and uniform permittivity $\\varepsilon$. The cavity is discretized using first-order Nédélec edge elements (of the first kind) on a conforming triangulation obtained by subdividing $\\Omega$ into a structured grid of $m=2$ by $n=2$ squares and splitting each square by a straight line from its lower-left vertex to its upper-right vertex. The Finite Element Method (FEM) unknowns are associated with oriented edges of the triangulation, corresponding to the tangential component of $\\mathbf{E}$ along each edge. The PEC boundary condition enforces the vanishing of the tangential component of $\\mathbf{E}$ on all boundary edges.\n\nPerform the following tasks:\n\n- Starting from Maxwell’s equations and the PEC boundary condition, derive the weak formulation appropriate for the TE cavity problem in two dimensions, and identify the bilinear forms whose discrete counterparts define, per element, the curl-curl (stiffness) and mass matrices in terms of the Nédélec basis functions on a reference triangle and the element mapping to physical coordinates.\n\n- Using the derived weak formulation, state the structure of the local element matrices for first-order Nédélec edge elements on a triangle, in terms of the integrals of basis function curls and basis function products. Do not invoke any pre-derived FEM templates; instead, give the expressions directly from the weak formulation and the definition of the edge basis functions.\n\n- Predict the global sparsity pattern of the assembled system matrix before imposing the PEC boundary constraints, explaining which pairs of degrees of freedom (DOFs) are coupled and why, and discuss how the pattern changes after eliminating boundary DOFs by enforcing the constraints strongly (Dirichlet elimination).\n\n- Define the half-bandwidth $b$ of a symmetric sparse matrix under a given ordering as $b = \\max\\{ j - i \\,:\\, a_{ij} \\neq 0,\\, j \\geq i\\}$, and use this definition to compute the exact half-bandwidth of the global matrix both before and after applying boundary constraints, under the following explicit DOF ordering: sort all edge DOFs by the $y$-coordinate of the edge midpoint in ascending order; for equal midpoint $y$, sort by the midpoint $x$ in ascending order; for equal $(x,y)$, order horizontally oriented edges first, then vertically oriented edges, then diagonally oriented edges. After applying boundary constraints, discard boundary edges and renumber interior edges using the same ordering rule applied only to the remaining interior edges.\n\nThe triangulation has the following edges, described by their midpoints: horizontal edges at $y=0$ with midpoints $(0.25,0)$ and $(0.75,0)$; horizontal edges at $y=0.5$ with midpoints $(0.25,0.5)$ and $(0.75,0.5)$; horizontal edges at $y=1$ with midpoints $(0.25,1)$ and $(0.75,1)$; vertical edges at $x=0$ with midpoints $(0,0.25)$ and $(0,0.75)$; vertical edges at $x=0.5$ with midpoints $(0.5,0.25)$ and $(0.5,0.75)$; vertical edges at $x=1$ with midpoints $(1,0.25)$ and $(1,0.75)$; diagonal edges inside each square with midpoints $(0.25,0.25)$, $(0.75,0.25)$, $(0.25,0.75)$, and $(0.75,0.75)$. The diagonal orientation is from lower-left to upper-right in each square. The boundary edges are those lying on $x=0$, $x=1$, $y=0$, or $y=1$; all diagonal edges are interior. Assume material coefficients are uniform and the mesh is conforming.\n\nCompute, exactly, the half-bandwidth after applying boundary constraints and renumbering interior edges under the stated ordering. Express your final answer as an integer. No rounding is required.",
            "solution": "The problem poses a comprehensive question concerning the Finite Element Method (FEM) analysis of a two-dimensional electromagnetic cavity. It requires the derivation of the governing weak formulation, an analysis of the resulting matrix system's structure, and a precise calculation of the matrix half-bandwidth under a specific ordering of degrees of freedom. The problem will be addressed by sequentially completing each of the specified tasks.\n\n### Problem Validation\n\nThe problem statement has been evaluated and is determined to be **valid**. It is scientifically grounded in Maxwell's equations and computational electromagnetics, well-posed with a clear and achievable objective, and self-contained with all necessary data for the calculation. The mesh, element type, boundary conditions, and degree-of-freedom ordering are specified unambiguously, ensuring that a unique solution for the half-bandwidth exists. No logical contradictions, factual errors, or unscientific premises were found. We may therefore proceed with a full solution.\n\n### Part 1: Derivation of the Weak Formulation\n\nThe analysis begins with the time-harmonic Maxwell's equations in a source-free, uniform medium with permeability $\\mu$ and permittivity $\\varepsilon$:\n$$ \\nabla \\times \\mathbf{E} = -j\\omega \\mathbf{B} $$\n$$ \\nabla \\times \\mathbf{H} = j\\omega \\mathbf{D} $$\nUsing the constitutive relations $\\mathbf{B} = \\mu\\mathbf{H}$ and $\\mathbf{D} = \\varepsilon\\mathbf{E}$, we can eliminate the magnetic field $\\mathbf{H}$. From the first equation, we have $\\mathbf{H} = \\frac{1}{-j\\omega\\mu}\\nabla \\times \\mathbf{E}$. Substituting this into the second equation yields:\n$$ \\nabla \\times \\left( \\frac{1}{-j\\omega\\mu} \\nabla \\times \\mathbf{E} \\right) = j\\omega\\varepsilon\\mathbf{E} $$\nRearranging the terms, we obtain the vector wave equation for the electric field $\\mathbf{E}$:\n$$ \\nabla \\times (\\mu^{-1} \\nabla \\times \\mathbf{E}) - \\omega^2\\varepsilon\\mathbf{E} = \\mathbf{0} $$\nThis is the strong form of the governing equation. The problem specifies a two-dimensional domain $\\Omega$ with Perfect Electric Conductor (PEC) boundary conditions. The use of Nédélec edge elements to discretize $\\mathbf{E}$ implies that the electric field vector lies in the plane of the domain, i.e., $\\mathbf{E} = E_x(x,y)\\hat{\\mathbf{x}} + E_y(x,y)\\hat{\\mathbf{y}}$. The PEC boundary condition requires the tangential component of the electric field to vanish on the boundary $\\partial\\Omega$:\n$$ \\mathbf{E} \\times \\hat{\\mathbf{n}} = \\mathbf{0} \\quad \\text{on } \\partial\\Omega $$\nHere, $\\hat{\\mathbf{n}}$ is the outward unit normal vector to the boundary.\n\nTo derive the weak formulation, we employ the weighted residual method. We multiply the vector wave equation by a vector test function $\\mathbf{F}$ and integrate over the domain $\\Omega$:\n$$ \\int_{\\Omega} \\mathbf{F} \\cdot \\left( \\nabla \\times (\\mu^{-1} \\nabla \\times \\mathbf{E}) - \\omega^2\\varepsilon\\mathbf{E} \\right) dA = 0 $$\nThe appropriate functional space for $\\mathbf{E}$ and $\\mathbf{F}$ is $H(\\mathbf{curl}, \\Omega) = \\{ \\mathbf{u} \\in (L^2(\\Omega))^2 : \\nabla \\times \\mathbf{u} \\in L^2(\\Omega) \\}$. The test functions $\\mathbf{F}$ are chosen from the space $H_0(\\mathbf{curl}, \\Omega)$, which incorporates the homogeneous boundary condition $\\mathbf{F} \\times \\hat{\\mathbf{n}} = \\mathbf{0}$ on $\\partial\\Omega$.\n\nWe apply a vector calculus identity (integration by parts) to the first term:\n$$ \\int_{\\Omega} \\mathbf{F} \\cdot (\\nabla \\times \\mathbf{G}) \\, dA = \\int_{\\Omega} (\\nabla \\times \\mathbf{F}) \\cdot \\mathbf{G} \\, dA - \\oint_{\\partial\\Omega} (\\mathbf{F} \\times \\mathbf{G}) \\cdot \\hat{\\mathbf{n}} \\, dL $$\nLetting $\\mathbf{G} = \\mu^{-1}\\nabla \\times \\mathbf{E}$, the integral becomes:\n$$ \\int_{\\Omega} (\\nabla \\times \\mathbf{F}) \\cdot (\\mu^{-1} \\nabla \\times \\mathbf{E}) \\, dA - \\int_{\\Omega} \\omega^2\\varepsilon \\mathbf{F} \\cdot \\mathbf{E} \\, dA - \\oint_{\\partial\\Omega} (\\mathbf{F} \\times (\\mu^{-1}\\nabla \\times \\mathbf{E})) \\cdot \\hat{\\mathbf{n}} \\, dL = 0 $$\nSince the test function $\\mathbf{F}$ is in $H_0(\\mathbf{curl}, \\Omega)$, its tangential component along the boundary is zero, i.e., $\\mathbf{F} \\times \\hat{\\mathbf{n}} = \\mathbf{0}$ on $\\partial\\Omega$. The boundary integral term vanishes, as it involves the tangential component of $\\mathbf{F}$.\n\nThe resulting weak formulation is: Find $(\\omega, \\mathbf{E}) \\in \\mathbb{R} \\times H_0(\\mathbf{curl}, \\Omega)$ with $\\mathbf{E} \\ne \\mathbf{0}$ such that for all $\\mathbf{F} \\in H_0(\\mathbf{curl}, \\Omega)$:\n$$ \\int_{\\Omega} \\mu^{-1} (\\nabla \\times \\mathbf{F}) \\cdot (\\nabla \\times \\mathbf{E}) \\, dA - \\omega^2\\varepsilon \\int_{\\Omega} \\mathbf{F} \\cdot \\mathbf{E} \\, dA = 0 $$\nThis is a generalized eigenvalue problem. The two bilinear forms are:\n1.  The **curl-curl (stiffness) form**: $a(\\mathbf{E}, \\mathbf{F}) = \\int_{\\Omega} \\mu^{-1} (\\nabla \\times \\mathbf{E}) \\cdot (\\nabla \\times \\mathbf{F}) \\, dA$\n2.  The **mass form**: $m(\\mathbf{E}, \\mathbf{F}) = \\int_{\\Omega} \\varepsilon \\mathbf{E} \\cdot \\mathbf{F} \\, dA$\n\n### Part 2: Structure of Local Element Matrices\n\nIn the FEM framework, the electric field is approximated as a linear combination of basis functions, $\\mathbf{E}_h = \\sum_{j} E_j \\mathbf{N}_j$, where $\\mathbf{N}_j$ are the first-order Nédélec vector basis functions associated with the edges of the mesh. Substituting this expansion into the weak formulation and choosing $\\mathbf{F} = \\mathbf{N}_i$ for each basis function $i$ leads to the matrix eigenvalue problem $S \\mathbf{e} = \\omega^2 M \\mathbf{e}$. The matrices $S$ and $M$ are assembled from contributions from each element $K$ in the triangulation.\n\nFor a single triangular element $K$, the local stiffness matrix $S^K$ and local mass matrix $M^K$ have entries given by the integrals of the bilinear forms over that element, using the local basis functions $\\mathbf{N}_i^K$ and $\\mathbf{N}_j^K$ associated with the three edges of the triangle.\nThe entries of the $3 \\times 3$ local matrices are:\n-   **Local stiffness matrix entry ($S^K_{ij}$)**: This is derived from the curl-curl form. For the 2D case, the curl of an in-plane vector field is a scalar field oriented in the $z$-direction.\n    $$ S^K_{ij} = \\int_K \\mu^{-1} (\\nabla \\times \\mathbf{N}_i^K) (\\nabla \\times \\mathbf{N}_j^K) \\, dA $$\n-   **Local mass matrix entry ($M^K_{ij}$)**: This is derived from the mass form.\n    $$ M^K_{ij} = \\int_K \\varepsilon (\\mathbf{N}_i^K \\cdot \\mathbf{N}_j^K) \\, dA $$\nThese expressions define the local matrices directly in terms of the basis functions over a physical element $K$, as requested.\n\n### Part 3: Global Sparsity Pattern\n\nThe global stiffness and mass matrices, $S$ and $M$, are assembled by summing the contributions from all element matrices $S^K$ and $M^K$. The entry $A_{ij}$ of the global system matrix (either $S$ or $M$) is non-zero if and only if the degrees of freedom (DOFs) $i$ and $j$ are coupled. In this context, DOFs are associated with mesh edges.\n\n-   **Before imposing boundary constraints**: Two DOFs, corresponding to edges $e_i$ and $e_j$, are coupled if and only if there exists at least one triangular element $K$ that contains both $e_i$ and $e_j$ as its edges. The matrix size is $N_{dof} \\times N_{dof}$, where $N_{dof}$ is the total number of edges in the mesh. For the given mesh, there are $16$ edges, so the matrix is $16 \\times 16$. Its sparsity pattern is symmetric and reflects the mesh connectivity.\n\n-   **After imposing boundary constraints**: The PEC boundary condition $\\mathbf{E} \\times \\hat{\\mathbf{n}} = \\mathbf{0}$ is enforced strongly. This means the DOFs corresponding to all edges on the boundary $\\partial\\Omega$ are set to zero. This is equivalent to removing the rows and columns associated with these boundary edges from the global system matrices. The resulting linear system involves only the interior DOFs. The size of the reduced matrix is $N_{int} \\times N_{int}$, where $N_{int}$ is the number of interior edges. The sparsity pattern of this smaller matrix is determined by the connectivity of the interior edges. A non-zero entry $(i,j)$ exists if the interior edges $e_i$ and $e_j$ belong to the same triangle.\n\n### Part 4: Half-Bandwidth Calculation\n\nThe final task is to compute the half-bandwidth $b = \\max\\{ j - i \\,:\\, a_{ij} \\neq 0,\\, j \\geq i\\}$ of the reduced system matrix (after applying boundary conditions) under a specific DOF ordering.\n\n**Step 1: Identify and order interior DOFs**\nFirst, we list the $8$ interior edges and their midpoints:\n-   Horizontal (H): $(0.25, 0.5)$, $(0.75, 0.5)$\n-   Vertical (V): $(0.5, 0.25)$, $(0.5, 0.75)$\n-   Diagonal (D): $(0.25, 0.25)$, $(0.75, 0.25)$, $(0.25, 0.75)$, $(0.75, 0.75)$\n\nNext, we apply the specified ordering rule: sort by midpoint $y$ (ascending), then midpoint $x$ (ascending), then by type (H, V, D). This yields the renumbered interior DOFs:\n\n| New Index ($i'$) | Midpoint $(x,y)$ | Type | Edge Description                       |\n|:----------------:|:----------------:|:----:|:---------------------------------------|\n|        1         |  $(0.25, 0.25)$  |   D  | Diagonal in square $[0,0.5]\\times[0,0.5]$    |\n|        2         |  $(0.5, 0.25)$   |   V  | Vertical on line $x=0.5$, lower half   |\n|        3         |  $(0.75, 0.25)$  |   D  | Diagonal in square $[0.5,1]\\times[0,0.5]$     |\n|        4         |  $(0.25, 0.5)$   |   H  | Horizontal on line $y=0.5$, left half  |\n|        5         |  $(0.75, 0.5)$   |   H  | Horizontal on line $y=0.5$, right half |\n|        6         |  $(0.25, 0.75)$  |   D  | Diagonal in square $[0,0.5]\\times[0.5,1]$     |\n|        7         |  $(0.5, 0.75)$   |   V  | Vertical on line $x=0.5$, upper half   |\n|        8         |  $(0.75, 0.75)$  |   D  | Diagonal in square $[0.5,1]\\times[0.5,1]$     |\n\n**Step 2: Determine couplings between interior DOFs**\nWe identify which pairs of interior edges belong to the same triangle. The mesh consists of $8$ triangles. We analyze the edges of each triangle. An edge is denoted by its new index.\n\n-   **T1**: Vertices $(0,0), (0.5,0), (0.5,0.5)$. Its interior edges are the diagonal across the lower-left square (index 1) and the lower vertical edge on $x=0.5$ (index 2). Coupling: $\\{1, 2\\}$.\n-   **T2**: Vertices $(0,0), (0,0.5), (0.5,0.5)$. Its interior edges are the diagonal (index 1) and the left horizontal edge on $y=0.5$ (index 4). Coupling: $\\{1, 4\\}$.\n-   **T3**: Vertices $(0.5,0), (1,0), (1,0.5)$. Its only interior edge is the diagonal across the lower-right square (index 3). No interior edge pairs.\n-   **T4**: Vertices $(0.5,0), (0.5,0.5), (1,0.5)$. Its interior edges are the lower vertical edge on $x=0.5$ (index 2), the diagonal (index 3), and the right horizontal edge on $y=0.5$ (index 5). Coupling: $\\{2, 3, 5\\}$.\n-   **T5**: Vertices $(0,0.5), (0.5,0.5), (0.5,1)$. Its interior edges are the left horizontal edge on $y=0.5$ (index 4), the diagonal across the upper-left square (index 6), and the upper vertical edge on $x=0.5$ (index 7). Coupling: $\\{4, 6, 7\\}$.\n-   **T6**: Vertices $(0,0.5), (0,1), (0.5,1)$. Its only interior edge is the diagonal (index 6). No interior edge pairs.\n-   **T7**: Vertices $(0.5,0.5), (1,0.5), (1,1)$. Its interior edges are the right horizontal edge on $y=0.5$ (index 5) and the diagonal across the upper-right square (index 8). Coupling: $\\{5, 8\\}$.\n-   **T8**: Vertices $(0.5,0.5), (0.5,1), (1,1)$. Its interior edges are the upper vertical edge on $x=0.5$ (index 7) and the diagonal (index 8). Coupling: $\\{7, 8\\}$.\n\n**Step 3: Compute the half-bandwidth**\nThe half-bandwidth is $b = \\max \\{j' - i'\\}$ over all coupled pairs $(i', j')$ with $j'>i'$. We examine the maximum difference arising from each coupling group:\n-   From T1, coupling $\\{1, 2\\}$: $2 - 1 = 1$.\n-   From T2, coupling $\\{1, 4\\}$: $4 - 1 = 3$.\n-   From T4, coupling $\\{2, 3, 5\\}$: $\\max(3-2, 5-2, 5-3) = \\max(1, 3, 2) = 3$.\n-   From T5, coupling $\\{4, 6, 7\\}$: $\\max(6-4, 7-4, 7-6) = \\max(2, 3, 1) = 3$.\n-   From T7, coupling $\\{5, 8\\}$: $8 - 5 = 3$.\n-   From T8, coupling $\\{7, 8\\}$: $8 - 7 = 1$.\n\nThe set of all differences $j'-i'$ is $\\{1, 3\\}$. The maximum difference observed across all couplings is $3$.\n\nTherefore, the half-bandwidth of the global matrix after applying boundary constraints and renumbering is $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "While the initial sparsity of a matrix is important, the performance of a direct solver is dominated by the \"fill-in\"—new nonzeros created during factorization. This practice introduces the elimination tree, a fundamental graph-theoretic tool that allows us to predict the structure of the factored matrix and understand the computational workflow of a sparse Cholesky or $LDL^T$ factorization . Constructing this tree for a small mesh demystifies the symbolic analysis phase that precedes numerical computation in all modern sparse direct solvers.",
            "id": "3299957",
            "problem": "In frequency-domain computational electromagnetics, consider the scalar potential formulation for a homogeneous isotropic conductor described by the elliptic operator applied to the electric scalar potential $u$, using a first-order Lagrange Finite Element Method (FEM) discretization on a tetrahedral mesh. The global stiffness matrix $K$ has entries\n$$\nK_{ij} \\;=\\; \\sum_{e} \\int_{\\Omega_e} \\sigma \\,\\nabla \\phi_i \\cdot \\nabla \\phi_j \\, dV \\;+\\; \\alpha \\int_{\\Omega} \\phi_i \\phi_j \\, dV,\n$$\nwhere $\\sigma>0$ is the conductivity, $\\alpha>0$ is a regularization parameter ensuring symmetric positive definiteness, $\\phi_i$ are the nodal basis functions, and the sum is over tetrahedral elements $\\Omega_e$. Two nodes $i$ and $j$ couple if and only if their supports overlap on at least one common tetrahedron. Thus the adjacency graph of the sparse matrix $K$ is determined solely by the mesh connectivity.\n\nConsider the mesh with nodes at coordinates\n- node $1$: $(0,0,0)$,\n- node $2$: $(1,0,0)$,\n- node $3$: $(0,1,0)$,\n- node $4$: $(0,0,1)$,\n- node $5$: $(1,1,1)$,\nand two tetrahedra\n- $T_1 = (1,2,3,4)$,\n- $T_2 = (1,2,3,5)$,\nwhich share the face $(1,2,3)$.\n\nAssume all $5$ nodes are degrees of freedom (no essential boundary conditions enforced), and use the natural ordering of unknowns $1 \\prec 2 \\prec 3 \\prec 4 \\prec 5$. Construct the undirected adjacency graph of $K$ (nodes represent unknowns, edges represent nonzero off-diagonal couplings), then consider a symmetric factorization by Cholesky decomposition and derive the corresponding elimination tree induced by this natural ordering. The elimination tree is defined so that the parent of node $j$ is the index of the first nonzero below the diagonal in column $j$ of the Cholesky factor, equivalently the smallest index $i>j$ such that $i$ is adjacent to $j$ in the filled graph produced by Gaussian elimination with this ordering.\n\nCompute the height of the elimination tree, defined as the number of nodes on the longest root-to-leaf path. Express your final answer as an integer with no units.",
            "solution": "The user wants me to find the height of an elimination tree for a sparse matrix arising from a Finite Element Method (FEM) discretization.\n\n### Step 1: Problem Validation\n\nThe problem is subjected to a rigorous validation process.\n\n**1.1. Extract Givens**\n- **Formulation**: Scalar potential elliptic operator on potential $u$ for a homogeneous isotropic conductor.\n- **Discretization**: First-order Lagrange FEM on a tetrahedral mesh.\n- **Stiffness Matrix ($K$) entries**: $K_{ij} = \\sum_{e} \\int_{\\Omega_e} \\sigma \\,\\nabla \\phi_i \\cdot \\nabla \\phi_j \\, dV \\;+\\; \\alpha \\int_{\\Omega} \\phi_i \\phi_j \\, dV$, with conductivity $\\sigma>0$ and regularization $\\alpha>0$.\n- **Sparsity Rule**: Two nodes $i$ and $j$ couple (i.e., $K_{ij} \\neq 0$ for $i \\neq j$) if and only if they belong to a common tetrahedron. The adjacency graph of $K$ is determined by mesh connectivity.\n- **Mesh Nodes**:\n    - Node $1$: $(0,0,0)$\n    - Node $2$: $(1,0,0)$\n    - Node $3$: $(0,1,0)$\n    - Node $4$: $(0,0,1)$\n    - Node $5$: $(1,1,1)$\n- **Mesh Elements (Tetrahedra)**:\n    - $T_1 = (1,2,3,4)$\n    - $T_2 = (1,2,3,5)$\n- **Degrees of Freedom**: All $5$ nodes are degrees of freedom.\n- **Ordering**: Natural ordering $1 \\prec 2 \\prec 3 \\prec 4 \\prec 5$.\n- **Task**: Construct the adjacency graph of $K$, derive the elimination tree for Cholesky factorization with the given ordering, and compute the height of this tree.\n- **Elimination Tree Definition**: The parent of node $j$ is `parent(j)` $= \\min\\{i > j \\text{ | } (i,j) \\text{ is an edge in the filled graph}\\}$.\n- **Height Definition**: The height of the tree is the number of nodes on the longest root-to-leaf path.\n\n**1.2. Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is well-grounded in computational electromagnetics and numerical linear algebra. It describes a standard FEM formulation and the associated sparse matrix analysis using concepts like Cholesky factorization, filled graphs, and elimination trees. These are fundamental topics in the field.\n- **Well-Posedness**: The problem is well-posed. The description of the mesh, the rule for matrix sparsity, the node ordering, and the definitions of the elimination tree and its height are all precise and self-contained, leading to a unique solution.\n- **Objectivity**: The problem is stated in objective, formal language, free of any subjective or ambiguous terms.\n\n**1.3. Verdict and Action**\nThe problem is scientifically sound, well-posed, and objective. It contains no invalidating flaws. Therefore, it is deemed **valid**. I will proceed with formulating a solution.\n\n### Step 2: Solution\n\nThe solution requires a four-step process: (1) construct the adjacency graph of the matrix $K$, (2) determine the filled graph produced by elimination, (3) derive the structure of the elimination tree, and (4) compute its height.\n\n**2.1. Construct the Adjacency Graph $G(K)$**\n\nThe set of vertices in the graph is the set of nodes $V = \\{1, 2, 3, 4, 5\\}$. An edge $(i, j)$ exists in the graph if and only if nodes $i$ and $j$ belong to a common tetrahedron.\n\n- **Tetrahedron $T_1 = \\{1, 2, 3, 4\\}$**: The nodes within this element form a clique. This contributes the edges $(1,2)$, $(1,3)$, $(1,4)$, $(2,3)$, $(2,4)$, and $(3,4)$.\n- **Tetrahedron $T_2 = \\{1, 2, 3, 5\\}$**: The nodes within this element also form a clique. This contributes the edges $(1,2)$, $(1,3)$, $(1,5)$, $(2,3)$, $(2,5)$, and $(3,5)$.\n\nThe adjacency graph $G(K)$ is formed by the union of all edges from all elements.\nThe adjacency list for each node is as follows:\n- Adjacency of node $1$: Neighbors in $T_1$ are $\\{2,3,4\\}$. Neighbors in $T_2$ are $\\{2,3,5\\}$. The union is $\\text{Adj}(1) = \\{2,3,4,5\\}$.\n- Adjacency of node $2$: Neighbors in $T_1$ are $\\{1,3,4\\}$. Neighbors in $T_2$ are $\\{1,3,5\\}$. The union is $\\text{Adj}(2) = \\{1,3,4,5\\}$.\n- Adjacency of node $3$: Neighbors in $T_1$ are $\\{1,2,4\\}$. Neighbors in $T_2$ are $\\{1,2,5\\}$. The union is $\\text{Adj}(3) = \\{1,2,4,5\\}$.\n- Adjacency of node $4$: This node is only in $T_1$. Its neighbors are $\\text{Adj}(4) = \\{1,2,3\\}$.\n- Adjacency of node $5$: This node is only in $T_2$. Its neighbors are $\\text{Adj}(5) = \\{1,2,3\\}$.\n\nCritically, nodes $4$ and $5$ do not share a tetrahedron, so the edge $(4,5)$ does not exist in the original graph $G(K)$.\n\n**2.2. Determine the Filled Graph $G^+$**\n\nThe filled graph $G^+$ results from adding \"fill-in\" edges during the symbolic Gaussian elimination process. An edge $(i,j)$ is a fill-in if $K_{ij}=0$ but the corresponding entry in the Cholesky factor $L_{ij}$ is non-zero. The process is simulated by eliminating nodes in the specified order $k = 1, 2, 3, 4$. When a node $k$ is eliminated, its neighbors in the current graph become a clique.\n\n- **Eliminate node $k=1$**: The neighbors of node $1$ in $G(K)$ are $\\{2,3,4,5\\}$. For these nodes to form a clique, an edge must connect every pair. The pairs are $(2,3), (2,4), (2,5), (3,4), (3,5), (4,5)$. We check which of these edges are missing from $G(K)$.\n  - $(2,3)$: Exists (in $T_1, T_2$).\n  - $(2,4)$: Exists (in $T_1$).\n  - $(2,5)$: Exists (in $T_2$).\n  - $(3,4)$: Exists (in $T_1$).\n  - $(3,5)$: Exists (in $T_2$).\n  - $(4,5)$: **Does not exist**.\n  Therefore, the elimination of node $1$ creates one fill-in edge: $(4,5)$. The graph on the remaining nodes $\\{2,3,4,5\\}$ becomes a complete graph (a clique $K_4$).\n\n- **Eliminate node $k=2$**: In the modified graph, the neighbors of node $2$ with a higher index are $\\{3,4,5\\}$. These three nodes already form a clique because the subgraph on $\\{2,3,4,5\\}$ is now complete. Thus, eliminating node $2$ creates no new fill-in.\n\n- **Eliminate nodes $k=3$ and $k=4$**: Similarly, eliminating node $3$ (neighbors $\\{4,5\\}$) and node $4$ (neighbor $\\{5\\}$) will not create any further fill-in.\n\nThe filled graph $G^+$ is the original graph $G(K)$ plus the single fill-in edge $(4,5)$.\n$E(G^+) = E(G(K)) \\cup \\{(4,5)\\}$.\nThis means that in the filled graph, every pair of nodes is connected. $G^+$ is the complete graph $K_5$ on the vertex set $V=\\{1,2,3,4,5\\}$.\n\n**2.3. Derive the Elimination Tree $T$**\n\nThe elimination tree is defined by the parent-child relationships, where the parent of node $j$ is given by the formula:\n$$ \\text{parent}(j) = \\min \\{i \\mid i > j \\text{ and } (i,j) \\text{ is an edge in } G^+\\} $$\nWe apply this rule for $j = 1, 2, 3, 4$. Node $5$ is the highest-numbered node and will be the root of the tree.\n\n- **`parent(1)`**: The neighbors of node $1$ in $G^+$ are $\\{2,3,4,5\\}$. All these indices are greater than $1$. The minimum among them is $2$.\n  $\\text{parent}(1) = \\min\\{2,3,4,5\\} = 2$.\n\n- **`parent(2)`**: The neighbors of node $2$ in $G^+$ are $\\{1,3,4,5\\}$. The neighbors with indices greater than $2$ are $\\{3,4,5\\}$. The minimum among them is $3$.\n  $\\text{parent}(2) = \\min\\{3,4,5\\} = 3$.\n\n- **`parent(3)`**: The neighbors of node $3$ in $G^+$ are $\\{1,2,4,5\\}$. The neighbors with indices greater than $3$ are $\\{4,5\\}$. The minimum among them is $4$.\n  $\\text{parent(3)} = \\min\\{4,5\\} = 4$.\n\n- **`parent(4)`**: The neighbors of node $4$ in $G^+$ are $\\{1,2,3,5\\}$. The only neighbor with an index greater than $4$ is $\\{5\\}$. The minimum is $5$.\n  $\\text{parent(4)} = \\min\\{5\\} = 5$.\n\nThe resulting elimination tree structure is a simple path: $1 \\rightarrow 2 \\rightarrow 3 \\rightarrow 4 \\rightarrow 5$, where $5$ is the root.\n\n**2.4. Compute the Height of the Elimination Tree**\n\nThe problem defines the height as \"the number of nodes on the longest root-to-leaf path\".\nIn the derived tree, there is only one root-to-leaf path.\n- Root: Node $5$.\n- Leaf: Node $1$.\n- Path: $5 \\rightsquigarrow 4 \\rightsquigarrow 3 \\rightsquigarrow 2 \\rightsquigarrow 1$.\nThe nodes on this path are $\\{5, 4, 3, 2, 1\\}$.\nThe number of nodes on this path is $5$.\n\nTherefore, the height of the elimination tree is $5$.",
            "answer": "$$\\boxed{5}$$"
        },
        {
            "introduction": "Maximizing computational performance often requires trading precision for speed, a principle at the heart of mixed-precision algorithms. This exercise challenges you to implement a sophisticated solver that combines a fast, low-precision factorization with high-precision iterative refinement to recover full accuracy . Mastering this technique provides insight into how modern scientific computing leverages hardware features to solve large-scale problems efficiently.",
            "id": "3299965",
            "problem": "Consider the frequency-domain form of Maxwell’s equations for the electric field, where the weak formulation with first-order Nédélec edge elements in a perfectly electrically conducting cavity with conductive fill leads to the linear system $A x = b$ with complex, sparse, symmetric $A$. Under standard assumptions on material parameters, the discrete operator has the structure\n$$\nA = K - \\omega^2 M + i \\,\\omega\\, \\sigma\\, M,\n$$\nwhere $K$ is the curl-curl (stiffness-like) matrix, $M$ is the mass matrix, $\\omega$ is the angular frequency, and $\\sigma$ is the conductivity. In one spatial dimension with linear elements (a mathematically simplified analog that preserves the symmetry and banded sparsity), $K$ is the tridiagonal matrix with $2/h$ on the diagonal and $-1/h$ on the immediate off-diagonals, $M$ is $h I$, and $h=1/(n+1)$ is the uniform element size for $n$ interior nodes.\n\nYour task is to implement a mixed-precision direct sparse solver based on the symmetric indefinite $L D L^T$ factorization (unit lower-triangular $L$ and diagonal $D$) for complex $A$, using the following requirements:\n\n- Compute the $L D L^T$ factorization of $A$ in lower precision (single precision, unit roundoff $u_{\\ell}$).\n- Perform iterative refinement in higher precision (double precision, unit roundoff $u_{h}$): compute the residual $r = b - A x$ in double precision, solve for the correction $\\delta x$ using the single-precision factorization, and update $x \\leftarrow x + \\delta x$ in double precision. Iterate this process a fixed number of times.\n- Derive, from first principles of the floating-point model and the perturbation analysis of direct factorizations, the attainable relative residual bound for iterative refinement as a function of the unit roundoffs and the condition number of $A$:\n$$\n\\frac{\\|r\\|_2}{\\|b\\|_2} \\quad \\text{as a function of} \\quad u_{\\ell},\\; u_{h},\\; \\kappa_2(A).\n$$\nYour derivation must start from the floating-point arithmetic model and employ normwise perturbation bounds for factorizations and solves. Do not assume a priori error formulas; derive them logically.\n\nImplementation details for the solver:\n\n- Implement the $L D L^T$ factorization without pivoting in single precision for complex symmetric $A$ constructed as above. Use unit diagonal $L$ and diagonal $D$.\n- Implement forward and backward substitutions tailored to $L D L^T$: solve $L y = \\text{rhs}$, then $D z = y$, then $L^T x = z$.\n- Iterative refinement must:\n  1. Compute an initial solution $x_0$ in single precision.\n  2. In double precision, compute $r_k = b - A x_k$.\n  3. Solve $A \\delta x_k = r_k$ via the single-precision $L D L^T$ factorization.\n  4. Update $x_{k+1} = x_k + \\delta x_k$ in double precision.\n  5. Repeat for a fixed number of iterations (e.g., $10$).\n\nDefine the test suite using the simplified one-dimensional finite element matrices and the following parameter sets, which probe distinct regimes:\n\n- Happy path (moderate conditioning): $(n,\\omega,\\sigma) = (12,\\,5.0,\\,0.05)$.\n- Boundary regime near instability (large condition number): $(n,\\omega,\\sigma) = (12,\\,18.5,\\,0.0001)$.\n- Strong damping (well-conditioned): $(n,\\omega,\\sigma) = (20,\\,0.1,\\,2.0)$.\n\nFor each test case:\n\n- Construct $A$ as above with $h = 1/(n+1)$, $K$ tridiagonal with $2/h$ on the diagonal and $-1/h$ off-diagonals, and $M = h I$.\n- Use a right-hand side $b$ with entries $1 + 0 i$.\n- Perform the mixed-precision iterative refinement for $10$ iterations.\n- Compute the final relative residual $\\|r\\|_2 / \\|b\\|_2$ as a floating-point number.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3]$), where each $r_j$ is the final $\\|r\\|_2 / \\|b\\|_2$ for the corresponding test case. No physical units are required in the answer. All angles, if any appear, must be in radians. Express any fractional quantities in decimal form, not with a percentage sign.",
            "solution": "The problem is assessed to be **valid**. It is scientifically grounded in computational electromagnetics and numerical linear algebra, is well-posed with a clear and complete problem statement, and is expressed in objective, formal language. The tasks, involving both theoretical derivation and numerical implementation, are standard and verifiable within these fields.\n\n### 1. Theoretical Derivation of the Attainable Residual Bound\n\nThe goal is to derive the attainable relative residual bound for mixed-precision iterative refinement, $\\frac{\\|r\\|_2}{\\|b\\|_2}$, as a function of the lower-precision unit roundoff $u_{\\ell}$, the higher-precision unit roundoff $u_{h}$, and the condition number of the system matrix $\\kappa_2(A)$. The derivation proceeds from the standard model of floating-point arithmetic.\n\nLet the linear system be $A x = b$. Iterative refinement aims to improve an approximate solution $x_k$ by computing a correction $\\delta x_k$ and setting $x_{k+1} = x_k + \\delta x_k$. The correction is found by solving $A \\delta x_k = r_k$, where $r_k = b - A x_k$ is the residual. In our mixed-precision scheme:\n- The factorization $A \\approx \\hat{L}\\hat{D}\\hat{L}^T$ is computed and stored in lower precision (unit roundoff $u_{\\ell}$).\n- The residual $r_k$ and the solution update $x_{k+1}$ are computed in higher precision (unit roundoff $u_{h}$).\n\nLet us analyze one step of the iteration, starting from an approximate solution $x_k$.\n\n**Step 1: Residual Computation**\nThe residual $r_k = b - A x_k$ is computed in higher precision, $u_h$. The computed residual, $\\hat{r}_k$, is $\\hat{r}_k = \\text{fl}_h(b - A x_k)$. Standard error analysis for matrix-vector products and vector subtraction shows that:\n$$\n\\hat{r}_k = (b - A x_k) + f_k = r_k + f_k\n$$\nwhere $f_k$ is the floating-point error. A normwise bound on this error is given by:\n$$\n\\|f_k\\|_2 \\le c_1 u_h (\\|b\\|_2 + \\|A\\|_2 \\|x_k\\|_2)\n$$\nfor a small constant $c_1$ related to the matrix dimension $n$. As the\niteration converges, $x_k$ approaches the true solution $x = A^{-1}b$. Thus, for a stable process, $\\|x_k\\|_2 \\approx \\|x\\|_2 \\le \\|A^{-1}\\|_2 \\|b\\|_2$. Substituting this gives:\n$$\n\\|f_k\\|_2 \\le c_1 u_h (\\|b\\|_2 + \\|A\\|_2 \\|A^{-1}\\|_2 \\|b\\|_2) = c_1 u_h (1 + \\kappa_2(A)) \\|b\\|_2\n$$\n\n**Step 2: Correction Solve**\nThe correction $\\delta x_k$ is computed by solving $A \\delta x_k = r_k$. We use the low-precision factorization of $A$ to solve for a correction $d_k$ using the computed residual $\\hat{r}_k$. The process of factorization and substitution in precision $u_{\\ell}$ is equivalent to solving a perturbed system exactly. The computed correction, $\\hat{d}_k$, satisfies:\n$$\n(A + E) \\hat{d}_k = \\hat{r}_k\n$$\nwhere $E$ is the backward error representing the inaccuracies in both factorization and substitution. The norm of this error is bounded by:\n$$\n\\|E\\|_2 \\le c_2 u_{\\ell} \\|A\\|_2\n$$\nwhere $c_2$ is a constant that depends on $n$ and the stability of the factorization (which we assume is adequate).\n\n**Step 3: Solution Update**\nThe solution is updated in higher precision: $x_{k+1} = \\text{fl}_h(x_k + \\hat{d}_k)$. The error in this addition is small, so we can approximate $x_{k+1} \\approx x_k + \\hat{d}_k$.\n\n**Step 4: Convergence Analysis**\nThe new residual is $r_{k+1} = b - A x_{k+1} \\approx b - A(x_k + \\hat{d}_k) = r_k - A \\hat{d}_k$.\nFrom Step 2, $A \\hat{d}_k = \\hat{r}_k - E \\hat{d}_k$. Substituting this gives:\n$$\nr_{k+1} \\approx r_k - (\\hat{r}_k - E \\hat{d}_k) = (r_k - \\hat{r}_k) + E \\hat{d}_k = -f_k + E \\hat{d}_k\n$$\nTaking norms:\n$$\n\\|r_{k+1}\\|_2 \\le \\|f_k\\|_2 + \\|E\\|_2 \\|\\hat{d}_k\\|_2\n$$\nWe have $\\hat{d}_k = (A+E)^{-1} \\hat{r}_k \\approx A^{-1} r_k$. So, $\\|\\hat{d}_k\\|_2 \\approx \\|A^{-1} r_k\\|_2 \\le \\|A^{-1}\\|_2 \\|r_k\\|_2$.\nSubstituting the bounds for $\\|f_k\\|_2$ and $\\|E\\|_2$:\n$$\n\\|r_{k+1}\\|_2 \\le c_1 u_h (1 + \\kappa_2(A)) \\|b\\|_2 + (c_2 u_{\\ell} \\|A\\|_2) (\\|A^{-1}\\|_2 \\|r_k\\|_2)\n$$\n$$\n\\|r_{k+1}\\|_2 \\le c_1 u_h (1 + \\kappa_2(A)) \\|b\\|_2 + c_2 u_{\\ell} \\kappa_2(A) \\|r_k\\|_2\n$$\nThis is a linear recurrence for the residual norm. The iteration converges if the contraction factor is less than $1$, i.e., $c_2 u_{\\ell} \\kappa_2(A) < 1$.\n\n**Step 5: Attainable Residual**\nAssuming the convergence condition holds, the iteration will proceed until the residual update stagnates. The limiting residual, $r_\\infty$, is determined by the component of the error that does not shrink with $\\|r_k\\|_2$. This is the error from the high-precision residual computation. The iteration effectively stalls when the true residual $r_k$ is on the same order of magnitude as the error $f_k$ in computing it. Thus, the attainable residual $\\|r_\\infty\\|_2$ is fundamentally limited by $\\|f_k\\|_2$.\n$$\n\\|r_\\infty\\|_2 \\approx \\|f_k\\|_2 \\le c_1 u_h (1 + \\kappa_2(A)) \\|b\\|_2\n$$\nDividing by $\\|b\\|_2$ gives the attainable relative residual bound:\n$$\n\\frac{\\|r_\\infty\\|_2}{\\|b\\|_2} \\le c_1 u_h (1 + \\kappa_2(A))\n$$\nFor matrices with a large condition number, where $\\kappa_2(A) \\gg 1$, this bound is often simplified to:\n$$\n\\frac{\\|r_\\infty\\|_2}{\\|b\\|_2} \\approx C u_h \\kappa_2(A)\n$$\nwhere $C$ is a modest constant. This result shows that if the system is not too ill-conditioned for the low-precision factorization to work (i.e., $u_{\\ell} \\kappa_2(A) < 1$), mixed-precision iterative refinement can achieve a final residual that is close to the working precision's machine epsilon, scaled by the condition number.\n\n### 2. Implementation Strategy\n\nThe problem specifies a simplified 1D analog where the matrix $A = K - \\omega^2 M + i \\omega \\sigma M$ is tridiagonal and complex-symmetric. This structure is exploited for an efficient implementation.\n\n- **Matrix Structure**: The stiffness matrix $K$ is tridiagonal, and the mass matrix $M$ is diagonal ($M=hI$). Therefore, the system matrix $A$ is also tridiagonal. We store it using three vectors: one for the main diagonal, and one for the sub/super-diagonals (which are equal due to symmetry).\n\n- **Factorization**: We implement a specialized $L D L^T$ factorization for a symmetric tridiagonal matrix. For a tridiagonal matrix $A$, its $L D L^T$ factors are also sparse: $L$ is a unit lower bidiagonal matrix and $D$ is a diagonal matrix. The factorization can be computed in $O(n)$ operations without any fill-in. This is performed in single precision (`complex64`).\n\n- **Solves**: The forward ($L y = b$), diagonal ($D z = y$), and backward ($L^T x = z$) substitution steps are also implemented to leverage the bidiagonal/diagonal structure of the factors, each requiring $O(n)$ operations.\n\n- **Iterative Refinement**: The main loop proceeds as described in the problem, for a fixed $10$ iterations:\n    1. The residual $r_k = b - A x_k$ is computed in double precision (`complex128`), using an efficient tridiagonal matrix-vector product.\n    2. The residual is cast to single precision (`complex64`) and the tridiagonal $L D L^T$ solve is used to find the correction $\\delta x_k$.\n    3. The correction is cast back to double precision and added to the solution vector $x_k$.\n\nThis approach is computationally efficient and directly implements the algorithm specified in the problem statement, tailored to the sparse matrix structure.",
            "answer": "[2.977209745580667e-16,1.259253457582239e-15,2.1120092524792472e-16]"
        }
    ]
}