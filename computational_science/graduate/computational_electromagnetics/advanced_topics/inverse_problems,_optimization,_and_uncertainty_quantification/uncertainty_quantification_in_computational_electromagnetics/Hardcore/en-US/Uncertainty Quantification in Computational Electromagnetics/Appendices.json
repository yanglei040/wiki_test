{
    "hands_on_practices": [
        {
            "introduction": "The most direct and conceptually straightforward method for uncertainty quantification is the Monte Carlo simulation. This technique involves propagating uncertainty by repeatedly solving the deterministic model for many random samples of the input parameters, drawn from their specified probability distributions. This practice  applies the Monte Carlo method to a critical problem in antenna engineering: assessing the impact of random phase errors on the performance of a phased array, specifically its ability to maintain low sidelobe levels.",
            "id": "3358419",
            "problem": "Consider a uniform linear antenna array modeled in the far field under the Huygens–Fresnel principle and the linearity of Maxwell's equations, where the electric field produced by a superposition of radiators is the sum of individual field contributions. Let there be $N$ isotropic elements located along the $x$-axis with uniform spacing $d$. For a monochromatic source of wavelength $\\lambda$ and wavenumber $k = 2\\pi/\\lambda$, the ideal deterministic array factor pointing to a desired steering angle $\\theta_0$ is obtained by applying steering phases that compensate the geometric path differences, producing a far-field phase progression across the elements that depends on $\\sin\\theta$. \n\nNow introduce source phase uncertainty at each element. Model the phase perturbations as a random vector $\\boldsymbol{\\delta\\phi}(\\xi) = [\\delta\\phi_0(\\xi), \\delta\\phi_1(\\xi), \\dots, \\delta\\phi_{N-1}(\\xi)]^\\top$ that is jointly Gaussian with zero mean and a covariance matrix $\\boldsymbol{\\Sigma}$ whose entries are\n$$\n\\Sigma_{mn} = \\sigma^2 \\exp\\!\\left(-\\frac{|m-n|}{L_c}\\right), \\quad m,n \\in \\{0,1,\\dots,N-1\\},\n$$\nfor a specified standard deviation $\\sigma$ (in radians) and a dimensionless correlation length $L_c > 0$. For the special case $L_c = 0$, assume independence so that $\\boldsymbol{\\Sigma} = \\sigma^2 \\mathbf{I}$. The steering law uses phase shifts $w_n = -k d n \\sin\\theta_0$ so that the nominal beam points to $\\theta_0$, and the uncertain beampattern magnitude (array factor magnitude) at observation angle $\\theta$ and random outcome $\\xi$ is defined as\n$$\nB(\\theta,\\xi) = \\frac{1}{N}\\left|\\sum_{n=0}^{N-1} \\exp\\!\\Big(j\\big(k d n (\\sin\\theta - \\sin\\theta_0) + \\delta\\phi_n(\\xi)\\big)\\Big)\\right|.\n$$\nTreat $B(\\theta,\\xi)$ as a random field over angle induced by the random phases. For a given realization, define the mainlobe peak magnitude as $B_{\\max}(\\xi) = \\max_{\\theta \\in \\Theta} B(\\theta,\\xi)$ over an angle grid $\\Theta$, and define the sidelobe region as the set of angles with $|\\theta - \\theta_0| \\ge \\Delta\\theta_{\\text{main}}$, where $\\Delta\\theta_{\\text{main}}$ is a specified mainlobe exclusion half-width in degrees. Let the maximum sidelobe level be\n$$\n\\text{SLL}(\\xi) = \\max_{\\,\\theta \\in \\Theta:\\,|\\theta - \\theta_0| \\ge \\Delta\\theta_{\\text{main}}}\\, \\left(20\\log_{10}\\frac{B(\\theta,\\xi)}{B_{\\max}(\\xi)}\\right),\n$$\nin decibels relative to the mainlobe peak for the same realization. Given a threshold $T_{\\text{dB}}$ in decibels, the exceedance event is $\\{\\text{SLL}(\\xi) > T_{\\text{dB}}\\}$, and the exceedance probability is the probability of this event under the joint Gaussian model for $\\boldsymbol{\\delta\\phi}(\\xi)$.\n\nStarting from the stated fundamental electromagnetic superposition principle and the definition of the uncertain beampattern, design an algorithm to estimate the exceedance probability via Monte Carlo sampling from the multivariate normal distribution with the specified covariance. Implement the algorithm to:\n- Construct the array steering phase law and the deterministic geometric phase template,\n- Sample the correlated phase perturbations,\n- Compute $B(\\theta,\\xi)$ over a finite angle grid,\n- Identify $B_{\\max}(\\xi)$ and $\\text{SLL}(\\xi)$ for each realization using the stated sidelobe region,\n- Estimate the exceedance probability as the fraction of realizations with $\\text{SLL}(\\xi) > T_{\\text{dB}}$.\n\nUse the following physical and numerical specifications consistently in the algorithm:\n- Wavelength $\\lambda = 1$ meter (so $k = 2\\pi$ radians per meter),\n- Inter-element spacing $d = \\lambda/2$ meters,\n- Angle grid $\\Theta$ spanning from $-90$ degrees to $+90$ degrees inclusive, with step size $0.2$ degrees,\n- Angles must be handled and specified in degrees in the input, and internally converted to radians for trigonometric evaluations.\n\nYour program must implement the estimation for the following test suite of parameter sets and produce the exceedance probabilities. Each parameter tuple is $(N, \\sigma, L_c, \\theta_0, T_{\\text{dB}}, \\Delta\\theta_{\\text{main}}, M)$ where $M$ is the number of Monte Carlo samples:\n\n- Test $1$: $(16, 0.1, 2.0, 0.0, -18.0, 6.0, 2000)$,\n- Test $2$: $(16, 0.2, 0.0, 30.0, -15.0, 8.0, 2000)$,\n- Test $3$: $(32, 0.05, 8.0, -10.0, -22.0, 3.0, 1500)$,\n- Edge Test $4$: $(16, 0.0, 1.0, 0.0, -18.0, 6.0, 500)$.\n\nIn all tests, express angles in degrees as specified. The exceedance probability must be expressed as a decimal number in $[0,1]$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[p_1,p_2,p_3,p_4]$), where $p_i$ is the exceedance probability for test $i$ in the order above. Use a fixed random seed to make the Monte Carlo results reproducible across runs. No user input is allowed; all numerical values are fixed as given.",
            "solution": "The derivation begins from electromagnetic superposition in the far field. Under Maxwell's equations, in the time-harmonic regime, the total field at an observation point is the sum of contributions of each source element. In the Fraunhofer (far-field) approximation, the phase of the field from element $n$ located along a line with uniform spacing is determined by the path difference relative to a reference. For a uniform linear array of $N$ isotropic elements spaced by $d$ along the $x$-axis, observed at elevation angle $\\theta$, the phase added by geometry is $k d n \\sin\\theta$, where $k = 2\\pi/\\lambda$ is the wavenumber and $n \\in \\{0,\\dots,N-1\\}$ indexes the element positions relative to the reference.\n\nBeam steering to a desired angle $\\theta_0$ is achieved by applying deterministic phase shifts $w_n = -k d n \\sin\\theta_0$. This compensates the geometric phase at $\\theta_0$, aligning the contributions in phase to produce a mainlobe centered at $\\theta_0$. With this steering law, the net deterministic phase contribution for element $n$ at angle $\\theta$ becomes $k d n (\\sin\\theta - \\sin\\theta_0)$.\n\nIntroduce random phase perturbations at each element, modeled by $\\delta\\phi_n(\\xi)$, where $\\xi$ denotes a random outcome. The vector $\\boldsymbol{\\delta\\phi}(\\xi) = [\\delta\\phi_0(\\xi), \\dots, \\delta\\phi_{N-1}(\\xi)]^\\top$ is modeled as a zero-mean multivariate Gaussian with covariance entries\n$$\n\\Sigma_{mn} = \\sigma^2 \\exp\\!\\left(-\\frac{|m-n|}{L_c}\\right),\n$$\nwith $L_c > 0$ defining a correlation length in units of elements. For $L_c = 0$, the model reduces to independent phase perturbations with covariance $\\sigma^2 \\mathbf{I}$. This covariance is positive semidefinite for $L_c \\ge 0$ and produces physically plausible correlation: closely spaced elements have higher correlation than distant ones.\n\nThe array factor (complex sum of contributions) can then be written as\n$$\nA(\\theta,\\xi) = \\sum_{n=0}^{N-1} \\exp\\!\\Big(j\\big(k d n (\\sin\\theta - \\sin\\theta_0) + \\delta\\phi_n(\\xi)\\big)\\Big),\n$$\nand the beampattern magnitude is defined as the normalized modulus\n$$\nB(\\theta,\\xi) = \\frac{1}{N}\\left|A(\\theta,\\xi)\\right|.\n$$\nNormalization by $N$ makes $B(\\theta_0,\\xi) \\le 1$ for any realization, with equality only in the absence of random phase errors and perfect steering.\n\nThe beampattern $B(\\theta,\\xi)$ is a nonlinear transformation of a Gaussian vector (due to the complex exponential and magnitude), so analytical characterization of its full distribution is intractable in general. However, one can compute statistics of interest using Monte Carlo sampling: generate many samples of $\\boldsymbol{\\delta\\phi}(\\xi)$ from the prescribed multivariate normal distribution, compute $B(\\theta,\\xi)$ across a discrete angle grid for each sample, and then compute derived quantities such as the mainlobe peak magnitude and maximum sidelobe level.\n\nFor each realization, define the mainlobe peak as\n$$\nB_{\\max}(\\xi) = \\max_{\\theta \\in \\Theta} B(\\theta,\\xi),\n$$\nover a finite angle grid $\\Theta$ with specified bounds and resolution. The sidelobe region excludes angles within a half-width $\\Delta\\theta_{\\text{main}}$ around the steering angle $\\theta_0$. The maximum sidelobe level relative to the mainlobe, in decibels, is\n$$\n\\text{SLL}(\\xi) = \\max_{\\,\\theta \\in \\Theta:\\,|\\theta - \\theta_0| \\ge \\Delta\\theta_{\\text{main}}}\\, \\left(20\\log_{10}\\frac{B(\\theta,\\xi)}{B_{\\max}(\\xi)}\\right).\n$$\nThe exceedance probability for a threshold $T_{\\text{dB}}$ is\n$$\np = \\mathbb{P}\\left(\\text{SLL}(\\xi) > T_{\\text{dB}}\\right).\n$$\n\nAlgorithmic design, integrating the above principles:\n1. Fix physical settings: choose $\\lambda = 1$ meter, so $k = 2\\pi$ radians per meter, and $d = \\lambda/2$ meters. These define the geometric phase progression.\n2. Construct the angle grid $\\Theta$ of degrees from $-90$ to $+90$ in uniform steps of $0.2$ degrees. Internally convert degrees to radians for computing sines: if $\\theta$ is in degrees, then $\\sin\\theta = \\sin(\\theta \\pi/180)$.\n3. Precompute the deterministic geometric-steering phase template for all angles and elements:\n   - For element indices $n = 0, 1, \\dots, N-1$, define $\\phi_{n}^\\text{geom}(\\theta) = k d n (\\sin\\theta - \\sin\\theta_0)$.\n   - Precompute $E(\\theta,n) = \\exp(j \\phi_{n}^\\text{geom}(\\theta))$ as a matrix of shape $(|\\Theta|, N)$, where $|\\Theta|$ is the number of angle samples.\n4. Build the phase covariance matrix $\\boldsymbol{\\Sigma}$:\n   - If $L_c > 0$, set $\\Sigma_{mn} = \\sigma^2 \\exp(-|m-n|/L_c)$.\n   - If $L_c = 0$, set $\\boldsymbol{\\Sigma} = \\sigma^2 \\mathbf{I}$.\n5. Sample $M$ realizations of the random phase vector:\n   - If $\\sigma = 0$, set all samples to the zero vector to represent no uncertainty.\n   - Otherwise, sample $\\boldsymbol{\\delta\\phi}^{(i)} \\sim \\mathcal{N}(\\mathbf{0}, \\boldsymbol{\\Sigma})$ for $i = 1, \\dots, M$. Use a fixed random seed for reproducibility.\n6. For each realization, compute the beampattern across the angle grid:\n   - Compute element random phase factors $\\exp(j\\,\\boldsymbol{\\delta\\phi}^{(i)})$ for each sample $i$.\n   - Multiply the precomputed template $E(\\theta,n)$ by these random phase factors and sum over $n$, yielding $A^{(i)}(\\theta) = \\sum_{n} E(\\theta,n)\\exp(j\\,\\delta\\phi^{(i)}_n)$.\n   - Normalize to get $B^{(i)}(\\theta) = |A^{(i)}(\\theta)|/N$.\n7. For each realization, identify the mainlobe peak $B_{\\max}^{(i)} = \\max_{\\theta \\in \\Theta} B^{(i)}(\\theta)$ and then compute the maximum sidelobe level over angles with $|\\theta - \\theta_0| \\ge \\Delta\\theta_{\\text{main}}$:\n   - Compute $r^{(i)}(\\theta) = B^{(i)}(\\theta)/B_{\\max}^{(i)}$ and convert to decibels via $20\\log_{10} r^{(i)}(\\theta)$.\n   - Set $\\text{SLL}^{(i)} = \\max_{\\theta \\in \\Theta, |\\theta - \\theta_0| \\ge \\Delta\\theta_{\\text{main}}} 20\\log_{10} r^{(i)}(\\theta)$.\n8. Estimate the exceedance probability by counting the fraction of realizations with $\\text{SLL}^{(i)} > T_{\\text{dB}}$:\n   $$\n   \\hat{p} = \\frac{1}{M}\\sum_{i=1}^{M} \\mathbf{1}\\{\\text{SLL}^{(i)} > T_{\\text{dB}}\\}.\n   $$\n\nNumerical stability considerations:\n- The normalization by $B_{\\max}^{(i)}$ ensures $r^{(i)}(\\theta) \\in [0,1]$; guard against $B_{\\max}^{(i)}$ being extremely small due to destructive interference by using a small positive lower bound $\\varepsilon$ in the denominator to avoid taking a logarithm of zero.\n- Complex exponentials and sums are computed in double precision; vectorization is used to aggregate many samples efficiently via matrix multiplication $(|\\Theta| \\times N)$ by $(N \\times M)$ to yield $(|\\Theta| \\times M)$ beampatterns across all realizations in one operation.\n\nThe program implements this algorithm for the specified test suite:\n- Test $1$: $(N=16, \\sigma=0.1, L_c=2.0, \\theta_0=0.0^\\circ, T_{\\text{dB}}=-18.0\\,\\text{dB}, \\Delta\\theta_{\\text{main}}=6.0^\\circ, M=2000)$,\n- Test $2$: $(N=16, \\sigma=0.2, L_c=0.0, \\theta_0=30.0^\\circ, T_{\\text{dB}}=-15.0\\,\\text{dB}, \\Delta\\theta_{\\text{main}}=8.0^\\circ, M=2000)$,\n- Test $3$: $(N=32, \\sigma=0.05, L_c=8.0, \\theta_0=-10.0^\\circ, T_{\\text{dB}}=-22.0\\,\\text{dB}, \\Delta\\theta_{\\text{main}}=3.0^\\circ, M=1500)$,\n- Edge Test $4$: $(N=16, \\sigma=0.0, L_c=1.0, \\theta_0=0.0^\\circ, T_{\\text{dB}}=-18.0\\,\\text{dB}, \\Delta\\theta_{\\text{main}}=6.0^\\circ, M=500)$.\n\nFor each test, the output is the exceedance probability $\\hat{p}$ as a decimal in $[0,1]$, yielding the final output format $[p_1,p_2,p_3,p_4]$ as a single printed line. A fixed random seed guarantees reproducibility of the Monte Carlo estimate.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef covariance_matrix_sigma_lc(N: int, sigma: float, Lc: float) -> np.ndarray:\n    \"\"\"\n    Construct the covariance matrix Sigma for correlated Gaussian phases.\n    Sigma_{mn} = sigma^2 * exp(-|m-n|/Lc) for Lc > 0.\n    For Lc == 0, return sigma^2 * I (independent phases).\n    \"\"\"\n    if sigma == 0.0:\n        # Zero variance; covariance can be zero matrix\n        return np.zeros((N, N), dtype=float)\n    if Lc == 0.0:\n        return (sigma ** 2) * np.eye(N, dtype=float)\n    # Toeplitz structure with exponential decay in element index distance\n    idx = np.arange(N, dtype=float)\n    # Use broadcasting to form |m - n|\n    diff = np.abs(idx[:, None] - idx[None, :])\n    Sigma = (sigma ** 2) * np.exp(-diff / Lc)\n    return Sigma\n\ndef estimate_exceedance_probability(N: int, sigma: float, Lc: float,\n                                    theta0_deg: float, T_dB: float,\n                                    delta_theta_main_deg: float, M: int,\n                                    rng: np.random.Generator) -> float:\n    \"\"\"\n    Estimate the exceedance probability that the maximum sidelobe level exceeds T_dB\n    given the random phase model with parameters (N, sigma, Lc).\n    \"\"\"\n    # Physical constants\n    lam = 1.0  # wavelength in meters\n    k = 2.0 * np.pi / lam  # wavenumber in rad/m\n    d = lam / 2.0  # inter-element spacing in meters\n\n    # Angle grid in degrees\n    theta_deg = np.arange(-90.0, 90.0 + 0.2, 0.2)  # inclusive range with step 0.2\n    theta_rad = np.deg2rad(theta_deg)\n    theta0_rad = np.deg2rad(theta0_deg)\n\n    # Precompute deterministic geometric phase template E(theta, n)\n    n_idx = np.arange(N, dtype=float)  # element indices 0..N-1\n    # Compute sin(theta) - sin(theta0) vector\n    sin_theta_diff = np.sin(theta_rad) - np.sin(theta0_rad)  # shape (T,)\n    # Phase for each (theta, n): k*d*n*(sin(theta) - sin(theta0))\n    # Use outer product n_idx (N,) with sin_theta_diff (T,)\n    # We want matrix of shape (T, N): E[t, n] = exp(j * k*d*n_idx[n] * sin_theta_diff[t])\n    phase_template = (k * d) * (sin_theta_diff[:, None] * n_idx[None, :])\n    E = np.exp(1j * phase_template)  # complex matrix (T, N)\n\n    # Build sidelobe mask excluding mainlobe region around theta0\n    main_exclude = np.abs(theta_deg - theta0_deg) < delta_theta_main_deg\n    sidelobe_mask = ~main_exclude  # True where sidelobe region\n\n    # Construct covariance and sample random phases\n    Sigma = covariance_matrix_sigma_lc(N, sigma, Lc)\n    # Sample M phase vectors\n    if sigma == 0.0:\n        delta_phi = np.zeros((M, N), dtype=float)\n    else:\n        # Multivariate normal sampling with fixed seed\n        # Ensure numerical stability: if Sigma is near-singular, np.random will still work\n        delta_phi = rng.multivariate_normal(mean=np.zeros(N, dtype=float), cov=Sigma, size=M)\n\n    # Compute complex random phase factors for all samples: shape (M, N)\n    rand_phase_factors = np.exp(1j * delta_phi)\n    # Compute array factor across theta for all samples via matrix multiplication: (T, N) @ (N, M) -> (T, M)\n    A = E @ rand_phase_factors.T\n    # Normalize beampattern magnitude by N\n    B = np.abs(A) / N  # shape (T, M)\n\n    # Compute mainlobe peak per sample\n    # Max across theta for each column (sample)\n    B_max = B.max(axis=0)  # shape (M,)\n    # Avoid division by zero or log of zero\n    eps = 1e-12\n    B_max_safe = np.maximum(B_max, eps)\n\n    # Compute normalized magnitudes in dB across sidelobe angles\n    # Select sidelobe rows\n    B_sidelobe = B[sidelobe_mask, :]  # shape (T_sidelobe, M)\n    # Compute ratio to mainlobe peak\n    ratio = B_sidelobe / B_max_safe[None, :]  # shape (T_sidelobe, M)\n    # Clip ratio for numerical safety to avoid log of zeros slightly negative due to roundoff\n    ratio = np.clip(ratio, eps, 1.0)\n    # Convert to dB\n    ratio_dB = 20.0 * np.log10(ratio)  # shape (T_sidelobe, M)\n\n    # Maximum sidelobe level per sample\n    SLL = ratio_dB.max(axis=0)  # shape (M,)\n\n    # Exceedance probability: fraction where SLL > T_dB\n    exceed = SLL > T_dB\n    p_hat = float(np.mean(exceed))\n    return p_hat\n\ndef solve():\n    # Define a fixed random seed for reproducibility\n    rng = np.random.default_rng(123456)\n\n    # Define the test cases from the problem statement.\n    # (N, sigma, Lc, theta0_deg, T_dB, delta_theta_main_deg, M)\n    test_cases = [\n        (16, 0.1, 2.0, 0.0, -18.0, 6.0, 2000),\n        (16, 0.2, 0.0, 30.0, -15.0, 8.0, 2000),\n        (32, 0.05, 8.0, -10.0, -22.0, 3.0, 1500),\n        (16, 0.0, 1.0, 0.0, -18.0, 6.0, 500),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, sigma, Lc, theta0_deg, T_dB, delta_theta_main_deg, M = case\n        p = estimate_exceedance_probability(N, sigma, Lc, theta0_deg, T_dB,\n                                            delta_theta_main_deg, M, rng)\n        # Round to a reasonable number of decimals for stable output\n        results.append(f\"{p:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While powerful, Monte Carlo methods can be computationally prohibitive when each model evaluation is expensive. A more efficient alternative is to construct a 'surrogate model,' an analytical approximation of the complex computational model. This practice explores the Polynomial Chaos Expansion (PCE), a sophisticated surrogate modeling technique based on orthogonal polynomials. You will investigate a crucial challenge in applying PCE: its breakdown when modeling systems with sharp resonant behavior, and implement an adaptive multi-element strategy  to overcome this limitation, thereby gaining insight into the practical nuances of advanced UQ algorithms.",
            "id": "3358464",
            "problem": "Consider a single driven electromagnetic cavity operating in the time-harmonic regime described by Maxwell’s equations. Near an isolated resonance, the field at a fixed spatial observation point can be modeled to leading order by a single-pole modal expansion. Under small but nonzero damping, the local response is well approximated by a scalar transfer function of the form of a simple pole in the complex frequency plane. Let the excitation angular frequency be fixed at $\\,\\omega_{0}\\,$. Let the material parameter variability be described by a single standardized random variable $\\,\\xi\\sim\\mathcal{U}([-1,1])\\,$. The resonance frequency depends on $\\,\\xi\\,$ through a smooth affine map $\\,\\omega_{r}(\\xi)=\\omega_{c}\\,(1+\\alpha\\,\\xi)\\,$ with known constants $\\,\\omega_{c}>0\\,$ and $\\,\\alpha\\in\\mathbb{R}\\,$. The effective damping is modeled by a constant $\\,\\gamma>0\\,$. Define the scalar quantity of interest as the real part of the transfer function evaluated at the fixed excitation, that is\n$$\nE(\\xi)\\equiv \\operatorname{Re}\\left\\{\\frac{1}{\\omega_{0}-\\omega_{r}(\\xi)+\\mathrm{j}\\,\\gamma}\\right\\}=\\frac{\\omega_{0}-\\omega_{r}(\\xi)}{\\left(\\omega_{0}-\\omega_{r}(\\xi)\\right)^{2}+\\gamma^{2}}.\n$$\nTreat all quantities as dimensionless. Angles are not used in the final output.\n\nThis problem investigates uncertainty quantification for $\\,E(\\xi)\\,$ using Polynomial Chaos Expansion (PCE) and the loss of accuracy of a single global PCE when the resonance $\\,\\omega_{r}(\\xi)\\,$ crosses the excitation $\\,\\omega_{0}\\,$ inside the support of $\\,\\xi\\,$. You must implement two surrogates:\n\n- A global Polynomial Chaos Expansion of total degree $\\,p_{\\mathrm{G}}\\,$ on $\\,[-1,1]\\,$ using the Legendre polynomial basis adapted to the uniform distribution of $\\,\\xi\\,$. Coefficients are to be computed by orthogonal projection with respect to the uniform measure on $\\,[-1,1]\\,$ approximated by Gaussian quadrature of sufficiently high order on $\\,[-1,1]\\,$.\n\n- A multi-element Polynomial Chaos Expansion with adaptive domain partitioning in $\\,\\xi\\,$. Start from the full interval $\\,[-1,1]\\,$ and recursively split intervals. On each element $\\,[a,b]\\subset[-1,1]\\,$, define the local affine map $\\,s=\\frac{2\\xi-(a+b)}{b-a}\\in[-1,1]\\,$ and build a local Legendre PCE of total degree $\\,p_{\\mathrm{L}}\\,$ by orthogonal projection with respect to the restriction of the uniform measure to $\\,[a,b]\\,$ (equivalently, by quadrature on $\\,s\\in[-1,1]\\,$). Use an adaptivity indicator based on the relative tail energy of the last few modal coefficients on the element; if the normalized tail energy exceeds a prescribed tolerance, split the element. When splitting, if the detuning $\\,\\Delta(\\xi)\\equiv \\omega_{0}-\\omega_{r}(\\xi)\\,$ changes sign over the element, split at the zero of $\\,\\Delta(\\xi)\\,$ inside the element; otherwise split at the midpoint. Continue until the indicator is below tolerance or a maximum refinement depth is reached, or the element becomes smaller than a minimum length.\n\nFor both surrogates, quantify accuracy by the root-mean-square $\\,L^{2}\\,$ error over $\\,\\xi\\in[-1,1]\\,$ with respect to the uniform distribution, approximated by uniform sampling. Explicitly, if $\\,\\{\\xi_{j}\\}_{j=1}^{N}\\,$ are uniformly spaced points in $\\,[-1,1]\\,$, define\n$$\n\\varepsilon \\equiv \\sqrt{\\frac{1}{N}\\sum_{j=1}^{N}\\left(E(\\xi_{j})-\\widehat{E}(\\xi_{j})\\right)^{2}},\n$$\nwhere $\\,\\widehat{E}\\,$ denotes either the global PCE or the multi-element PCE approximation. Express $\\,\\varepsilon\\,$ as a floating-point number with scientific notation.\n\nYou must implement a single program that, for each of the parameter sets below, constructs both surrogates and outputs their errors. Use the following fixed numerical settings for the surrogates and the error evaluation:\n\n- Global PCE total degree $\\,p_{\\mathrm{G}}=8\\,$.\n- Local PCE total degree $\\,p_{\\mathrm{L}}=6\\,$.\n- Local adaptivity tail-indicator tolerance $\\,\\tau=10^{-4}\\,$, where the tail indicator is the ratio of the sum of squares of the last $\\,3\\,$ local coefficients to the sum of squares of all local coefficients (use a small positive floor in the denominator to avoid division by zero).\n- Maximum refinement depth $\\,d_{\\max}=12\\,$.\n- Minimum element length $\\,\\ell_{\\min}=10^{-3}\\,$.\n- Use Gaussian quadrature of order $\\,N_{q}=200\\,$ for all coefficient projections on any element.\n- Use $\\,N=10001\\,$ uniformly spaced sample points on $\\,[-1,1]\\,$ for error evaluation.\n\nTest suite (each case is an independent run with the same numerical settings):\n\n- Case $\\,1\\,$ (smooth, no crossing): $\\,\\omega_{0}=1.0\\,$, $\\,\\omega_{c}=0.2\\,$, $\\,\\alpha=0.1\\,$, $\\,\\gamma=0.5\\,$.\n- Case $\\,2\\,$ (interior crossing, small damping): $\\,\\omega_{0}=1.0\\,$, $\\,\\omega_{c}=1.0\\,$, $\\,\\alpha=0.8\\,$, $\\,\\gamma=0.01\\,$.\n- Case $\\,3\\,$ (crossing near boundary): choose $\\,\\omega_{c}=1.0\\,$, $\\,\\alpha=0.6\\,$, and set $\\,\\omega_{0}=1.57\\,$, with $\\,\\gamma=0.01\\,$.\n- Case $\\,4\\,$ (interior crossing, very small damping): $\\,\\omega_{0}=1.0\\,$, $\\,\\omega_{c}=1.0\\,$, $\\,\\alpha=0.9\\,$, $\\,\\gamma=10^{-4}\\,$.\n\nYour program must produce a single line of output containing a list with eight floating-point numbers in scientific notation, in the order\n$$\n[\\varepsilon_{\\mathrm{G}}^{(1)},\\varepsilon_{\\mathrm{ME}}^{(1)},\\varepsilon_{\\mathrm{G}}^{(2)},\\varepsilon_{\\mathrm{ME}}^{(2)},\\varepsilon_{\\mathrm{G}}^{(3)},\\varepsilon_{\\mathrm{ME}}^{(3)},\\varepsilon_{\\mathrm{G}}^{(4)},\\varepsilon_{\\mathrm{ME}}^{(4)}],\n$$\nwhere $\\,\\varepsilon_{\\mathrm{G}}^{(k)}\\,$ is the global PCE error for case $\\,k\\,$ and $\\,\\varepsilon_{\\mathrm{ME}}^{(k)}\\,$ is the multi-element PCE error for case $\\,k\\,$. The line must be printed exactly as a comma-separated list enclosed in square brackets, for example, $\\,\\bigl[\\texttt{1.234000e-03},\\texttt{5.670000e-05},\\dots\\bigr]\\,$.\n\nAll quantities in this problem are dimensionless. The program must be self-contained, require no input, and adhere to the specified numerical settings without modification.",
            "solution": "The problem requires the implementation and comparison of two surrogate modeling techniques, Global Polynomial Chaos Expansion (GPCE) and Multi-Element Polynomial Chaos Expansion (ME-PCE), for a model of an electromagnetic cavity resonance. The goal is to quantify the uncertainty in the system's response due to variability in a material parameter.\n\nThe quantity of interest (QoI) is the real part of a resonant transfer function, given by:\n$$\nE(\\xi) = \\operatorname{Re}\\left\\{\\frac{1}{\\omega_{0}-\\omega_{r}(\\xi)+\\mathrm{j}\\,\\gamma}\\right\\} = \\frac{\\omega_{0}-\\omega_{r}(\\xi)}{\\left(\\omega_{0}-\\omega_{r}(\\xi)\\right)^{2}+\\gamma^{2}}\n$$\nThe resonance frequency $\\omega_{r}(\\xi)$ depends affinely on a random variable $\\xi \\sim \\mathcal{U}([-1,1])$:\n$$\n\\omega_{r}(\\xi) = \\omega_{c}\\,(1+\\alpha\\,\\xi)\n$$\nwhere $\\omega_0$ is the fixed excitation frequency, $\\omega_c$ and $\\alpha$ are constants defining the resonance behavior, and $\\gamma > 0$ is the damping factor.\n\nWhen the detuning $\\Delta(\\xi) = \\omega_{0}-\\omega_{r}(\\xi)$ becomes zero for some $\\xi$ within its support $[-1,1]$, the function $E(\\xi)$ exhibits a sharp peak characteristic of a Lorentzian lineshape. The sharpness of this peak is inversely proportional to the damping $\\gamma$. Such sharp, localized features pose a significant challenge for global polynomial approximation methods, which are better suited for smooth functions. This problem is designed to demonstrate this limitation and the effectiveness of an adaptive, domain-decomposition approach.\n\nThe accuracy of each surrogate model, $\\widehat{E}(\\xi)$, is measured by the root-mean-square ($L^2$) error on a fine grid of $N=10001$ points $\\{\\xi_j\\}$ uniformly spaced in $[-1,1]$:\n$$\n\\varepsilon \\equiv \\sqrt{\\frac{1}{N}\\sum_{j=1}^{N}\\left(E(\\xi_{j})-\\widehat{E}(\\xi_{j})\\right)^{2}}\n$$\n\n**1. Global Polynomial Chaos Expansion (GPCE)**\n\nThe GPCE method approximates the QoI $E(\\xi)$ as a finite series of orthogonal polynomials. Since $\\xi$ is uniformly distributed, the appropriate orthogonal basis is the Legendre polynomials, $\\{P_k(\\xi)\\}$. The GPCE of total degree $p_{\\mathrm{G}}$ is:\n$$\n\\widehat{E}_{\\mathrm{G}}(\\xi) = \\sum_{k=0}^{p_{\\mathrm{G}}} c_k P_k(\\xi)\n$$\nThe coefficients $c_k$ are determined by orthogonal projection, which minimizes the mean-squared error. The formula for the coefficients is:\n$$\nc_k = \\frac{\\langle E(\\xi), P_k(\\xi) \\rangle}{\\langle P_k(\\xi), P_k(\\xi) \\rangle} = \\frac{\\int_{-1}^{1} E(\\xi) P_k(\\xi) d\\xi}{\\int_{-1}^{1} P_k^2(\\xi) d\\xi} = \\frac{2k+1}{2} \\int_{-1}^{1} E(\\xi) P_k(\\xi) d\\xi\n$$\nThe integral is computed numerically using Gauss-Legendre quadrature with $N_q=200$ points and weights, denoted $(\\zeta_i, w_i)$:\n$$\nc_k \\approx \\frac{2k+1}{2} \\sum_{i=1}^{N_q} E(\\zeta_i) P_k(\\zeta_i) w_i\n$$\nThe problem specifies a fixed degree $p_{\\mathrm{G}}=8$. For cases where $E(\\xi)$ has a sharp peak, this low-degree global polynomial will struggle to capture the feature, leading to large errors and spurious oscillations (Gibbs phenomenon).\n\n**2. Multi-Element Polynomial Chaos Expansion (ME-PCE)**\n\nThe ME-PCE approach mitigates the limitations of GPCE by partitioning the domain of $\\xi$ into smaller elements and constructing a separate, local PCE on each. This allows the model to adapt to local features of the function. The algorithm is recursive:\n\n1.  **Initialization**: Begin with a single element covering the entire domain, $[-1,1]$, and a specified maximum refinement depth $d_{\\max}=12$.\n\n2.  **Iteration**: For each active element $[a, b]$ at the current refinement depth:\n    a.  **Local PCE Construction**: A local PCE of degree $p_{\\mathrm{L}}=6$ is constructed. This requires mapping the element $[a, b]$ to a reference element $s \\in [-1,1]$ via the affine transformation $s = \\frac{2\\xi-(a+b)}{b-a}$. The local expansion is $\\widehat{E}_{\\text{local}}(s) = \\sum_{j=0}^{p_{\\mathrm{L}}} c_j^{\\text{local}} P_j(s)$. The coefficients $c_j^{\\text{local}}$ are computed via quadrature on the reference element, similar to the global case.\n    b.  **Adaptivity Indicator**: To decide if the element needs further refinement, we compute a tail energy indicator. This measures the relative energy contained in the highest-degree modes of the local expansion.\n    $$\n    \\eta = \\frac{\\sum_{j=p_{\\mathrm{L}}-2}^{p_{\\mathrm{L}}} (c_j^{\\text{local}})^2}{\\varepsilon_{\\text{floor}} + \\sum_{j=0}^{p_{\\mathrm{L}}} (c_j^{\\text{local}})^2}\n    $$\n    where the problem specifies using the last $3$ coefficients and $\\varepsilon_{\\text{floor}}$ is a small positive number to prevent division by zero.\n    c.  **Refinement Decision**: The element $[a, b]$ is marked for refinement if its length is greater than $\\ell_{\\min}=10^{-3}$ and its indicator $\\eta$ is greater than the tolerance $\\tau=10^{-4}$.\n    d.  **Splitting Strategy**: If refinement is needed, the split point is chosen intelligently. We find the value $\\xi_z$ where the detuning is zero: $\\Delta(\\xi_z) = \\omega_0 - \\omega_r(\\xi_z) = 0$. This gives $\\xi_z = (\\frac{\\omega_0}{\\omega_c} - 1)/\\alpha$. If this point $\\xi_z$ lies strictly within the element, $(a, b)$, the element is split into $[a, \\xi_z]$ and $[\\xi_z, b]$. This focuses refinement around the sharp peak. Otherwise, the element is split at its midpoint, $m=(a+b)/2$.\n\n3.  **Termination**: The recursion stops for a given branch when the adaptivity indicator is below the tolerance, the element size is below the minimum, or the maximum depth is reached.\n\nThe final ME-PCE surrogate is a piecewise-polynomial function, where each piece is the local PCE on one of the final elements in the domain partition. This adaptive refinement strategy is expected to place many small elements around the sharp peak of $E(\\xi)$ (when present) and use larger elements where the function is smooth, resulting in a highly accurate and efficient approximation.\n\nFor the given test cases:\n*   **Case 1**: $E(\\xi)$ is smooth. Both GPCE and ME-PCE should perform well, with ME-PCE likely not refining the domain much, if at all.\n*   **Cases 2, 3, 4**: A resonance crossing occurs within $[-1,1]$, and damping $\\gamma$ is small. $E(\\xi)$ has a sharp peak. GPCE is expected to yield large errors. ME-PCE will adaptively refine around the peak, leading to significantly lower errors. The error for GPCE will be larger as $\\gamma$ decreases (Case 4 vs. Case 2), making the peak sharper.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\nfrom numpy.polynomial.legendre import legval, legvander\n\ndef solve():\n    \"\"\"\n    Solves the uncertainty quantification problem for an electromagnetic cavity model\n    using Global and Multi-Element Polynomial Chaos Expansions.\n    \"\"\"\n    \n    # --- Fixed Numerical Settings ---\n    p_G = 8          # Global PCE total degree\n    p_L = 6          # Local PCE total degree\n    tau = 1e-4       # Local adaptivity tail-indicator tolerance\n    d_max = 12       # Maximum refinement depth\n    l_min = 1e-3     # Minimum element length\n    N_q = 200        # Gaussian quadrature order\n    N = 10001        # Number of points for error evaluation\n    TAIL_COEFFS = 3  # Number of tail coefficients for indicator\n    \n    # --- Test Cases ---\n    test_cases = [\n        # (w0, wc, alpha, gamma)\n        (1.0, 0.2, 0.1, 0.5),    # Case 1: Smooth, no crossing\n        (1.0, 1.0, 0.8, 0.01),   # Case 2: Interior crossing, small damping\n        (1.57, 1.0, 0.6, 0.01),  # Case 3: Crossing near boundary\n        (1.0, 1.0, 0.9, 1e-4),   # Case 4: Interior crossing, very small damping\n    ]\n\n    # --- Precompute shared resources ---\n    xi_eval = np.linspace(-1.0, 1.0, N)\n    quad_nodes_ref, quad_weights_ref = roots_legendre(N_q)\n    \n    results = []\n    for w0, wc, alpha, gamma in test_cases:\n        \n        # --- Define the true model function (Quantity of Interest) ---\n        def E_func(xi):\n            wr = wc * (1 + alpha * xi)\n            detuning = w0 - wr\n            return detuning / (detuning**2 + gamma**2)\n\n        true_vals = E_func(xi_eval)\n\n        # -----------------------------------------------------------\n        # 1. Global Polynomial Chaos Expansion (GPCE)\n        # -----------------------------------------------------------\n        def build_gpce():\n            xi_q = quad_nodes_ref\n            E_q = E_func(xi_q)\n            \n            coeffs = np.zeros(p_G + 1)\n            for k in range(p_G + 1):\n                Pk_at_nodes = legval(xi_q, [1.0 if i == k else 0.0 for i in range(k + 1)])\n                # Integral of E(xi) * P_k(xi) dxi\n                integral = np.sum(E_q * Pk_at_nodes * quad_weights_ref)\n                # Normalization factor of Legendre polynomials\n                norm_sq = 2.0 / (2 * k + 1)\n                coeffs[k] = integral / norm_sq\n            return coeffs\n\n        gpce_coeffs = build_gpce()\n        gpce_vals = legval(xi_eval, gpce_coeffs)\n        error_gpce = np.sqrt(np.mean((true_vals - gpce_vals)**2))\n        \n        # -----------------------------------------------------------\n        # 2. Multi-Element Polynomial Chaos Expansion (ME-PCE)\n        # -----------------------------------------------------------\n        def compute_local_coeffs(a, b):\n            # Map reference quadrature nodes to element [a, b]\n            xi_q = 0.5 * ((b - a) * quad_nodes_ref + (a + b))\n            E_q = E_func(xi_q)\n            \n            coeffs = np.zeros(p_L + 1)\n            for k in range(p_L + 1):\n                Pk_at_nodes = legval(quad_nodes_ref, [1.0 if i == k else 0.0 for i in range(k + 1)])\n                # Integral of E_local(s) * P_k(s) ds over [-1, 1]\n                integral = np.sum(E_q * Pk_at_nodes * quad_weights_ref)\n                # The mapping jacobian (b-a)/2 cancels with the integral normalization 2/(2k+1)\n                # Local coeff c_k = ( (2k+1)/2 ) * integral_s( f(map(s)) * P_k(s) ) * ((b-a)/2) / ( (b-a)/2 )\n                # No, c_k = (2k+1)/(b-a) * integral_xi(f(xi) * Pk_local(xi) dxi)\n                # c_k = (2k+1)/(b-a) * integral_s(f(map(s)) Pk(s) (b-a)/2 ds) = (2k+1)/2 * integral_s(...)\n                # So this is correct:\n                coeffs[k] = (2 * k + 1) / 2.0 * integral\n            return coeffs\n\n        def build_mepce():\n            elements_to_process = [(-1.0, 1.0)]\n            final_elements = []\n\n            for _ in range(d_max):\n                if not elements_to_process:\n                    break\n                \n                next_elements_to_process = []\n                for a, b in elements_to_process:\n                    coeffs = compute_local_coeffs(a, b)\n                    \n                    # Tail energy indicator\n                    coeff_sq = coeffs**2\n                    tail_energy = np.sum(coeff_sq[-TAIL_COEFFS:])\n                    total_energy = np.sum(coeff_sq)\n                    eta = tail_energy / (total_energy + 1e-30)\n\n                    if eta <= tau or (b - a) < l_min:\n                        final_elements.append((a, b, coeffs))\n                    else: # Refine\n                        if alpha != 0:\n                            xi_z = (w0 / wc - 1.0) / alpha\n                        else: # Should not happen based on problem setup\n                            xi_z = np.inf\n\n                        if a < xi_z < b:\n                            split_point = xi_z\n                        else:\n                            split_point = 0.5 * (a + b)\n                        \n                        next_elements_to_process.append((a, split_point))\n                        next_elements_to_process.append((split_point, b))\n\n                elements_to_process = next_elements_to_process\n\n            # Handle elements remaining at max depth\n            for a, b in elements_to_process:\n                coeffs = compute_local_coeffs(a, b)\n                final_elements.append((a, b, coeffs))\n\n            final_elements.sort(key=lambda x: x[0])\n            return final_elements\n        \n        mepce_structure = build_mepce()\n\n        def eval_mepce(xi_pts, structure):\n            y_eval = np.zeros_like(xi_pts)\n            \n            # Using np.digitize for efficient binning\n            bins = np.array([el[0] for el in structure] + [structure[-1][1]])\n            \n            # Find which element each xi_pts belongs to\n            indices = np.digitize(xi_pts, bins, right=False) - 1\n            # Handle the rightmost point specifically\n            indices[xi_pts == bins[-1]] = len(structure) - 1\n\n            for i, (a, b, coeffs) in enumerate(structure):\n                mask = (indices == i)\n                if np.any(mask):\n                    xi_local = xi_pts[mask]\n                    s_local = (2 * xi_local - (a + b)) / (b - a)\n                    # Evaluate the polynomial sum efficiently\n                    y_eval[mask] = legval(s_local, coeffs)\n            return y_eval\n\n        mepce_vals = eval_mepce(xi_eval, mepce_structure)\n        error_mepce = np.sqrt(np.mean((true_vals - mepce_vals)**2))\n        \n        results.extend([error_gpce, error_mepce])\n\n    # --- Final Output ---\n    print(f\"[{','.join([f'{r:.6e}' for r in results])}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond simply analyzing the effects of uncertainty, a primary goal of UQ is to enable the design of systems that are robust and reliable in the face of variability. This involves reframing the design process as an uncertainty-aware optimization problem. In this hands-on exercise , you will design a microwave absorber by optimizing its thickness not for a single nominal performance, but for performance under a range of uncertain material parameters. You will implement and contrast two distinct design philosophies: a conservative worst-case optimization and a risk-aware approach using the Conditional Value-at-Risk (CVaR).",
            "id": "3358413",
            "problem": "Consider a one-dimensional, plane-wave, normal-incidence electromagnetic absorber consisting of a homogeneous isotropic slab backed by a perfectly electrically conducting plate. The ambient medium is free space. The absorber is characterized by complex permittivity and permeability, each defined by their relative parts with respect to free-space values. Fabrication variability induces uncertainty in the slab material parameters. The design objective is to select a slab thickness to achieve robustness against these uncertainties.\n\nStart from Maxwell's equations in the frequency domain, the plane-wave solution in homogeneous media, and the standard boundary conditions at material interfaces. Using these principles, derive the power reflectance at the front interface of the slab when the backing is a perfect electric conductor. Let the angular frequency be $\\,\\omega\\,$, free-space permittivity be $\\,\\varepsilon_0\\,$, and free-space permeability be $\\,\\mu_0\\,$. Denote the ambient medium (free space) wave impedance as $\\,Z_1 = \\sqrt{\\mu_0/\\varepsilon_0}\\,$. Denote the slab's complex permittivity and permeability as $\\,\\varepsilon = \\varepsilon_0(\\varepsilon_r' - j\\,\\varepsilon_r'')\\,$ and $\\,\\mu = \\mu_0(\\mu_r' - j\\,\\mu_r'')\\,$, where $\\,\\varepsilon_r'\\,$ and $\\,\\mu_r'\\,$ are the real relative parts, and $\\,\\varepsilon_r''\\,$ and $\\,\\mu_r''\\,$ are the loss terms. Let the slab thickness be $\\,d\\,$ in meters.\n\nDefine the worst-case (robust) design objective as the minimization of the supremum of the reflectance over a known uncertainty set $\\,\\mathcal{U}\\,$ that is a polytope (here, a hyper-rectangle) in the parameter space $\\,\\xi = (\\varepsilon_r', \\varepsilon_r'', \\mu_r', \\mu_r'')\\,$:\n$$\n\\min_{d \\in [d_{\\min}, d_{\\max}]} \\ \\sup_{\\xi \\in \\mathcal{U}} \\ R(\\omega, \\xi, d),\n$$\nwhere $\\,R(\\omega,\\xi,d)\\,$ is the power reflectance, a dimensionless quantity. Additionally, define a probabilistic risk objective using Conditional Value-at-Risk (CVaR) at level $\\,\\alpha \\in (0,1)\\,$ for a specified probability distribution on $\\,\\xi\\,$ across $\\,\\mathcal{U}\\,$. For a given thickness $\\,d\\,$ and random parameter $\\,\\xi\\,$ with distribution supported on $\\,\\mathcal{U}\\,$, let $\\,\\mathrm{CVaR}_\\alpha(d)\\,$ be the expected reflectance conditional on being in the worst $\\,\\alpha\\,$ tail of $\\,R(\\omega,\\xi,d)\\,$. The probabilistic design objective is:\n$$\n\\min_{d \\in [d_{\\min}, d_{\\max}]} \\ \\mathrm{CVaR}_\\alpha(d).\n$$\n\nYour task is to implement a complete program that:\n- Computes the power reflectance $\\,R(\\omega,\\xi,d)\\,$ for plane-wave normal incidence onto the slab backed by a perfect electric conductor, based on first principles as outlined above, expressed in terms of the slab's input impedance and the ambient impedance.\n- Approximates $\\,\\sup_{\\xi \\in \\mathcal{U}} R(\\omega,\\xi,d)\\,$ by evaluating $\\,R\\,$ on a uniform grid over the hyper-rectangle $\\,\\mathcal{U}\\,$ and taking the maximum.\n- Approximates $\\,\\mathrm{CVaR}_\\alpha(d)\\,$ by sampling the same uniform grid, computing all reflectance values, sorting them, and averaging the largest $\\,\\lceil \\alpha M \\rceil\\,$ values, where $\\,M\\,$ is the total number of grid points.\n- Performs a grid search over thickness $\\,d \\in [d_{\\min}, d_{\\max}]\\,$ to find the thickness that minimizes the worst-case reflectance, and the thickness that minimizes the CVaR objective, with the same uniform grid for $\\,d\\,$.\n\nPhysical constants and units:\n- Use $\\,\\varepsilon_0 = 8.854187817 \\times 10^{-12}\\,\\mathrm{F/m}\\,$ and $\\,\\mu_0 = 4\\pi \\times 10^{-7}\\,\\mathrm{H/m}\\,$.\n- The ambient impedance is $\\,Z_1 = \\sqrt{\\mu_0/\\varepsilon_0}\\,$ in $\\,\\Omega\\,$.\n- Frequency must be specified in $\\,\\mathrm{Hz}\\,$ and converted to angular frequency via $\\,\\omega = 2\\pi f\\,$.\n- Thickness must be in $\\,\\mathrm{m}\\,$.\n- Reflectance is dimensionless.\n\nTest suite:\nFor each case below, use a uniform grid in each uncertain parameter dimension with the specified number of points (inclusive endpoints), forming the hyper-rectangular polytope $\\,\\mathcal{U}\\,$. Use a uniform grid of thickness values $\\,d\\,$ across the specified interval with the given number of points (inclusive endpoints). Use a uniform distribution over the grid points in $\\,\\mathcal{U}\\,$ for the CVaR computation.\n\n- Case $\\,1\\,$ (general variability, moderate loss):\n    - Frequency $\\,f = 10 \\times 10^9\\,\\mathrm{Hz}\\,$.\n    - Thickness interval $\\,d \\in [5 \\times 10^{-4},\\, 1 \\times 10^{-2}]\\,\\mathrm{m}\\,$ with $\\,81\\,$ points.\n    - Uncertainty set $\\,\\mathcal{U}\\,$:\n        - $\\,\\varepsilon_r' \\in [2.0,\\, 2.5]\\,$ with $\\,9\\,$ points.\n        - $\\,\\varepsilon_r'' \\in [0.05,\\, 0.15]\\,$ with $\\,9\\,$ points.\n        - $\\,\\mu_r' \\in [1.0,\\, 1.0]\\,$ with $\\,1\\,$ point.\n        - $\\,\\mu_r'' \\in [0.0,\\, 0.05]\\,$ with $\\,7\\,$ points.\n    - CVaR level $\\,\\alpha = 0.1\\,$.\n\n- Case $\\,2\\,$ (strong loss variability, mild magnetic variability):\n    - Frequency $\\,f = 2 \\times 10^9\\,\\mathrm{Hz}\\,$.\n    - Thickness interval $\\,d \\in [1 \\times 10^{-3},\\, 5 \\times 10^{-2}]\\,\\mathrm{m}\\,$ with $\\,81\\,$ points.\n    - Uncertainty set $\\,\\mathcal{U}\\,$:\n        - $\\,\\varepsilon_r' \\in [1.5,\\, 1.6]\\,$ with $\\,7\\,$ points.\n        - $\\,\\varepsilon_r'' \\in [0.5,\\, 0.8]\\,$ with $\\,7\\,$ points.\n        - $\\,\\mu_r' \\in [1.0,\\, 1.05]\\,$ with $\\,5\\,$ points.\n        - $\\,\\mu_r'' \\in [0.0,\\, 0.2]\\,$ with $\\,7\\,$ points.\n    - CVaR level $\\,\\alpha = 0.2\\,$.\n\n- Case $\\,3\\,$ (near free-space material, weak loss):\n    - Frequency $\\,f = 6 \\times 10^9\\,\\mathrm{Hz}\\,$.\n    - Thickness interval $\\,d \\in [1 \\times 10^{-4},\\, 5 \\times 10^{-3}]\\,\\mathrm{m}\\,$ with $\\,101\\,$ points.\n    - Uncertainty set $\\,\\mathcal{U}\\,$:\n        - $\\,\\varepsilon_r' \\in [0.95,\\, 1.05]\\,$ with $\\,11\\,$ points.\n        - $\\,\\varepsilon_r'' \\in [0.0,\\, 0.02]\\,$ with $\\,5\\,$ points.\n        - $\\,\\mu_r' \\in [0.95,\\, 1.05]\\,$ with $\\,11\\,$ points.\n        - $\\,\\mu_r'' \\in [0.0,\\, 0.02]\\,$ with $\\,5\\,$ points.\n    - CVaR level $\\,\\alpha = 0.1\\,$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, report four values in order:\n- The robust-design thickness $\\,d_{\\mathrm{robust}}\\,$ in $\\,\\mathrm{m}\\,$,\n- The worst-case reflectance at that thickness $\\,R_{\\mathrm{worst}}\\,$ (dimensionless),\n- The CVaR-design thickness $\\,d_{\\mathrm{CVaR}}\\,$ in $\\,\\mathrm{m}\\,$,\n- The CVaR value at that thickness $\\,\\mathrm{CVaR}\\,$ (dimensionless).\n\nThus, for three cases, the output must be a list of $\\,12\\,$ floats:\n$$\n[ d_{\\mathrm{robust},1}, R_{\\mathrm{worst},1}, d_{\\mathrm{CVaR},1}, \\mathrm{CVaR}_1,\\ d_{\\mathrm{robust},2}, R_{\\mathrm{worst},2}, d_{\\mathrm{CVaR},2}, \\mathrm{CVaR}_2,\\ d_{\\mathrm{robust},3}, R_{\\mathrm{worst},3}, d_{\\mathrm{CVaR},3}, \\mathrm{CVaR}_3 ].\n$$\nAll thickness values must be in $\\,\\mathrm{m}\\,$ and all reflectance values are dimensionless. No additional text should be printed.",
            "solution": "The problem requires the derivation of the power reflectance for a single-layer electromagnetic absorber backed by a perfect electric conductor (PEC), and subsequent numerical optimization of the layer thickness under parameter uncertainty. We begin by recourse to first principles, namely Maxwell's equations, to derive the necessary analytical expressions.\n\nLet the coordinate system be defined such that the ambient medium (free space) is in the region $z<0$, the absorber slab is in the region $0 \\le z \\le d$, and the PEC is at the plane $z=d$. A plane wave is assumed to be normally incident from free space, propagating in the $+z$ direction.\n\nIn a source-free, homogeneous, and isotropic medium, the time-harmonic Maxwell's curl equations at an angular frequency $\\omega$ are:\n$$\n\\nabla \\times \\mathbf{E} = -j\\omega\\mu \\mathbf{H}\n$$\n$$\n\\nabla \\times \\mathbf{H} = j\\omega\\varepsilon \\mathbf{E}\n$$\nwhere $\\mathbf{E}$ and $\\mathbf{H}$ are the complex phasors for the electric and magnetic fields, $\\varepsilon$ is the complex permittivity, and $\\mu$ is the complex permeability. For a plane wave with electric field polarized in the $\\hat{\\mathbf{x}}$ direction, the solutions to these equations are of the form:\n$$\n\\mathbf{E}(z) = E_x(z) \\hat{\\mathbf{x}} \\quad , \\quad \\mathbf{H}(z) = H_y(z) \\hat{\\mathbf{y}}\n$$\nThe ratio of the transverse electric and magnetic field amplitudes defines the intrinsic impedance of the medium, $Z = \\sqrt{\\mu/\\varepsilon}$. The propagation of the wave is described by the propagation constant $\\gamma = j\\omega\\sqrt{\\mu\\varepsilon}$. The general solution for the electric field in a medium is a superposition of forward-propagating ($e^{-\\gamma z}$) and backward-propagating ($e^{+\\gamma z}$) waves.\n\nThe problem can be analyzed using transmission line analogy.\nThe ambient medium (Region $1$, $z<0$) is free space, with permittivity $\\varepsilon_0$ and permeability $\\mu_0$. Its intrinsic impedance is $Z_1 = \\sqrt{\\mu_0 / \\varepsilon_0}$.\nThe absorber slab (Region $2$, $0 \\le z \\le d$) has complex permittivity $\\varepsilon = \\varepsilon_0(\\varepsilon_r' - j\\varepsilon_r'')$ and permeability $\\mu = \\mu_0(\\mu_r' - j\\mu_r'')$. Its intrinsic impedance is $Z_2 = \\sqrt{\\mu/\\varepsilon}$ and its propagation constant is $\\gamma_2 = j\\omega\\sqrt{\\mu\\varepsilon}$.\n\nAt the boundary $z=d$, the slab is terminated by a PEC. The boundary condition for a PEC is that the tangential component of the electric field must be zero. In a transmission line analogy, this is equivalent to a short-circuit load, where the load impedance is $Z_L = 0$.\n\nThe input impedance $Z_{in}$ seen at the front face of the slab ($z=0$) is given by the impedance transformation formula for a transmission line of length $d$, characteristic impedance $Z_2$, and load impedance $Z_L$:\n$$\nZ_{in} = Z_2 \\frac{Z_L + Z_2 \\tanh(\\gamma_2 d)}{Z_2 + Z_L \\tanh(\\gamma_2 d)}\n$$\nSubstituting $Z_L=0$ for the PEC backing yields:\n$$\nZ_{in} = Z_2 \\frac{0 + Z_2 \\tanh(\\gamma_2 d)}{Z_2 + 0} = Z_2 \\tanh(\\gamma_2 d)\n$$\nThis is the input impedance of the PEC-backed slab.\n\nAt the interface $z=0$, the incident wave encounters an effective impedance $Z_{in}$. The reflection coefficient $\\Gamma$ at this interface is determined by the impedance mismatch between the ambient medium ($Z_1$) and the slab ($Z_{in}$):\n$$\n\\Gamma = \\frac{Z_{in} - Z_1}{Z_{in} + Z_1}\n$$\nThe power reflectance $R$ is the squared magnitude of the reflection coefficient $\\Gamma$:\n$$\nR(\\omega, \\xi, d) = |\\Gamma|^2 = \\left| \\frac{Z_{in} - Z_1}{Z_{in} + Z_1} \\right|^2\n$$\nSubstituting the expression for $Z_{in}$, we obtain the final formula for power reflectance:\n$$\nR(\\omega, \\xi, d) = \\left| \\frac{Z_2 \\tanh(\\gamma_2 d) - Z_1}{Z_2 \\tanh(\\gamma_2 d) + Z_1} \\right|^2\n$$\nThe parameters $Z_2$ and $\\gamma_2$ depend on the uncertain material properties $\\xi = (\\varepsilon_r', \\varepsilon_r'', \\mu_r', \\mu_r'')$:\n$$\nZ_2(\\xi) = \\sqrt{\\frac{\\mu_0(\\mu_r' - j\\mu_r'')}{\\varepsilon_0(\\varepsilon_r' - j\\varepsilon_r'')}} = Z_1 \\sqrt{\\frac{\\mu_r' - j\\mu_r''}{\\varepsilon_r' - j\\varepsilon_r''}}\n$$\n$$\n\\gamma_2(\\omega, \\xi) = j\\omega\\sqrt{\\mu_0\\varepsilon_0 (\\mu_r' - j\\mu_r'')(\\varepsilon_r' - j\\varepsilon_r'')}\n$$\nThis formulation admits a direct computational implementation.\n\nThe design objectives involve handling the uncertainty in $\\xi \\in \\mathcal{U}$. We are tasked with solving two optimization problems via a grid search over the thickness $d \\in [d_{\\min}, d_{\\max}]$.\nFor each candidate thickness $d$, the uncertainty is propagated through the reflectance function $R(\\omega, \\xi, d)$. This is done by discretizing the hyper-rectangular uncertainty set $\\mathcal{U}$ into a uniform grid of $M$ points, $\\{\\xi_i\\}_{i=1}^M$. For each $d$, we compute a set of $M$ reflectance values, $\\{R_i(d) = R(\\omega, \\xi_i, d)\\}_{i=1}^M$.\n\nThe first objective is the robust or worst-case design, which aims to minimize the maximum possible reflectance over the uncertainty set:\n$$\n\\min_{d} \\sup_{\\xi \\in \\mathcal{U}} R(\\omega, \\xi, d)\n$$\nNumerically, for each $d$, this is approximated as $\\max_{i} R_i(d)$. We then find the thickness $d_{\\mathrm{robust}}$ that minimizes this maximum value.\n\nThe second objective uses a risk-based metric, the Conditional Value-at-Risk (CVaR). For a given confidence level $\\alpha$, $\\mathrm{CVaR}_\\alpha$ is the expected value of the worst $\\alpha \\times 100\\%$ of outcomes. The objective is:\n$$\n\\min_{d} \\mathrm{CVaR}_\\alpha(d)\n$$\nNumerically, for each $d$, the $M$ reflectance values $\\{R_i(d)\\}$ are sorted in ascending order. Let $k = \\lceil \\alpha M \\rceil$ be the number of samples in the tail. The $\\mathrm{CVaR}_\\alpha(d)$ is approximated by the average of the $k$ largest reflectance values:\n$$\n\\mathrm{CVaR}_\\alpha(d) \\approx \\frac{1}{k} \\sum_{j=M-k+1}^{M} R_{(j)}(d)\n$$\nwhere $R_{(j)}(d)$ are the sorted reflectance values. We then find the thickness $d_{\\mathrm{CVaR}}$ that minimizes this CVaR value.\n\nThe implementation will perform a grid search over a specified range of $d$ values. For each $d$, it will evaluate the reflectance over the full grid of uncertain parameters $\\xi$, and then compute the corresponding worst-case and CVaR objectives. The optimal thicknesses and their corresponding objective function values are then identified by finding the minima across the grid of $d$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the robust and CVaR-based design optimization problem for a microwave absorber.\n    \"\"\"\n    \n    # Physical Constants\n    EPS0 = 8.854187817e-12  # F/m\n    MU0 = 4 * np.pi * 1e-7   # H/m\n    Z1 = np.sqrt(MU0 / EPS0) # Impedance of free space in Ohm\n\n    test_cases = [\n        {\n            \"f\": 10e9,\n            \"d_range\": [5e-4, 1e-2], \"d_pts\": 81,\n            \"eps_r_p_range\": [2.0, 2.5], \"eps_r_p_pts\": 9,\n            \"eps_r_pp_range\": [0.05, 0.15], \"eps_r_pp_pts\": 9,\n            \"mu_r_p_range\": [1.0, 1.0], \"mu_r_p_pts\": 1,\n            \"mu_r_pp_range\": [0.0, 0.05], \"mu_r_pp_pts\": 7,\n            \"alpha\": 0.1\n        },\n        {\n            \"f\": 2e9,\n            \"d_range\": [1e-3, 5e-2], \"d_pts\": 81,\n            \"eps_r_p_range\": [1.5, 1.6], \"eps_r_p_pts\": 7,\n            \"eps_r_pp_range\": [0.5, 0.8], \"eps_r_pp_pts\": 7,\n            \"mu_r_p_range\": [1.0, 1.05], \"mu_r_p_pts\": 5,\n            \"mu_r_pp_range\": [0.0, 0.2], \"mu_r_pp_pts\": 7,\n            \"alpha\": 0.2\n        },\n        {\n            \"f\": 6e9,\n            \"d_range\": [1e-4, 5e-3], \"d_pts\": 101,\n            \"eps_r_p_range\": [0.95, 1.05], \"eps_r_p_pts\": 11,\n            \"eps_r_pp_range\": [0.0, 0.02], \"eps_r_pp_pts\": 5,\n            \"mu_r_p_range\": [0.95, 1.05], \"mu_r_p_pts\": 11,\n            \"mu_r_pp_range\": [0.0, 0.02], \"mu_r_pp_pts\": 5,\n            \"alpha\": 0.1\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Unpack case parameters\n        f = case[\"f\"]\n        d_min, d_max = case[\"d_range\"]\n        d_pts = case[\"d_pts\"]\n        \n        eps_r_p_min, eps_r_p_max = case[\"eps_r_p_range\"]\n        eps_r_p_pts = case[\"eps_r_p_pts\"]\n        eps_r_pp_min, eps_r_pp_max = case[\"eps_r_pp_range\"]\n        eps_r_pp_pts = case[\"eps_r_pp_pts\"]\n        mu_r_p_min, mu_r_p_max = case[\"mu_r_p_range\"]\n        mu_r_p_pts = case[\"mu_r_p_pts\"]\n        mu_r_pp_min, mu_r_pp_max = case[\"mu_r_pp_range\"]\n        mu_r_pp_pts = case[\"mu_r_pp_pts\"]\n        \n        alpha = case[\"alpha\"]\n        omega = 2 * np.pi * f\n\n        # Create parameter grids\n        d_values = np.linspace(d_min, d_max, d_pts)\n        \n        eps_r_p_grid = np.linspace(eps_r_p_min, eps_r_p_max, eps_r_p_pts)\n        eps_r_pp_grid = np.linspace(eps_r_pp_min, eps_r_pp_max, eps_r_pp_pts)\n        mu_r_p_grid = np.linspace(mu_r_p_min, mu_r_p_max, mu_r_p_pts)\n        mu_r_pp_grid = np.linspace(mu_r_pp_min, mu_r_pp_max, mu_r_pp_pts)\n\n        # Create mesh grid of uncertain parameters xi = (eps_r', eps_r'', mu_r', mu_r'')\n        xi_mesh = np.meshgrid(eps_r_p_grid, eps_r_pp_grid, mu_r_p_grid, mu_r_pp_grid, indexing='ij')\n        \n        # Flatten and stack to get a list of M parameter vectors\n        xi_params = np.stack([grid.ravel() for grid in xi_mesh], axis=-1)\n        eps_r_p_vec, eps_r_pp_vec, mu_r_p_vec, mu_r_pp_vec = xi_params.T\n\n        # Get total number of uncertainty points\n        M = xi_params.shape[0]\n\n        # Calculate complex relative material properties for all xi points\n        eps_r_complex = eps_r_p_vec - 1j * eps_r_pp_vec\n        mu_r_complex = mu_r_p_vec - 1j * mu_r_pp_vec\n\n        # Calculate slab intrinsic properties for all xi points\n        Z2 = Z1 * np.sqrt(mu_r_complex / eps_r_complex)\n        gamma2 = 1j * omega * np.sqrt(MU0 * EPS0 * mu_r_complex * eps_r_complex)\n\n        robust_objectives = []\n        cvar_objectives = []\n\n        # Grid search over thickness d\n        for d in d_values:\n            # Calculate input impedance for current d, vectorized over all xi\n            Z_in = Z2 * np.tanh(gamma2 * d)\n            \n            # Calculate reflection coefficient and power reflectance\n            Gamma = (Z_in - Z1) / (Z_in + Z1)\n            R_values = np.abs(Gamma)**2\n            \n            # 1. Robust (worst-case) objective\n            sup_R = np.max(R_values)\n            robust_objectives.append(sup_R)\n            \n            # 2. CVaR objective\n            k = int(np.ceil(alpha * M))\n            if k > 0:\n                # Sort reflectance values and average the k largest ones\n                R_sorted = np.sort(R_values)\n                cvar_val = np.mean(R_sorted[-k:])\n            else: # Handle k=0 case, although alpha in (0,1) prevents this\n                R_sorted = np.sort(R_values)\n                cvar_val = R_sorted[-1]\n            cvar_objectives.append(cvar_val)\n\n        # Find optimal thickness for robust design\n        min_robust_idx = np.argmin(robust_objectives)\n        d_robust = d_values[min_robust_idx]\n        R_worst = robust_objectives[min_robust_idx]\n\n        # Find optimal thickness for CVaR design\n        min_cvar_idx = np.argmin(cvar_objectives)\n        d_cvar = d_values[min_cvar_idx]\n        CVaR_val = cvar_objectives[min_cvar_idx]\n        \n        results.extend([d_robust, R_worst, d_cvar, CVaR_val])\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}