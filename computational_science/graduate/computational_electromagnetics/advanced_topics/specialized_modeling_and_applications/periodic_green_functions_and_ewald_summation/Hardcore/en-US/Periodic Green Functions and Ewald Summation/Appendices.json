{
    "hands_on_practices": [
        {
            "introduction": "The efficiency of the Ewald method critically depends on the choice of the splitting parameter, $\\eta$. This parameter orchestrates the trade-off between the computational work of the real-space sum and the reciprocal-space sum. In this practice , you will derive an analytical expression for the optimal $\\eta$ that minimizes the total computational cost for a given error tolerance, providing a concrete understanding of how these two components are balanced.",
            "id": "3340042",
            "problem": "Consider the scalar three-dimensional Helmholtz equation for time-harmonic fields with free-space wavenumber $k$, and the associated periodic Green function over a simple-cubic Bravais lattice of lattice constant $a$. The free-space Green function is $G_{0}(\\mathbf{r})=\\exp(\\mathrm{i} k r)/(4\\pi r)$, where $r=|\\mathbf{r}|$. In the Ewald method, one introduces a Gaussian screening with a splitting parameter $\\eta0$ to write the periodic Green function as a sum of a rapidly decaying real-space lattice sum and a rapidly decaying reciprocal-space lattice sum. The real-space sum is truncated at radius $R_{c}$, and the reciprocal-space sum is truncated at wavenumber radius $G_{c}$. Assume the wavelength and lattice scale satisfy $k a  2\\pi$ so that the reciprocal-space tail is exponentially suppressed by the Ewald Gaussian in the lowest reciprocal shell.\n\nFor large arguments, the complementary error function and Gaussian screening imply that the leading-order truncation errors are exponentially dominated as follows (neglecting algebraic prefactors): the real-space truncation error decays as $\\exp\\!\\left(-(\\eta R_{c})^{2}\\right)$, and the reciprocal-space truncation error decays as $\\exp\\!\\left(-\\left(G_{c}^{2}-k^{2}\\right)/(4\\eta^{2})\\right)$. You are given a target absolute tolerance $\\varepsilon\\in(0,1)$ on the total truncation error of the Ewald-summed periodic Green function.\n\nAssume an equal allocation of the error budget to the two sums, so that each truncation error is controlled at level approximately $\\varepsilon/2$ via its dominant exponential. This implies the relations\n$$\n(\\eta R_{c})^{2}=\\ln\\!\\left(\\frac{2}{\\varepsilon}\\right),\\qquad \\frac{G_{c}^{2}-k^{2}}{4\\eta^{2}}=\\ln\\!\\left(\\frac{2}{\\varepsilon}\\right).\n$$\nFor a simple-cubic lattice with lattice constant $a$, estimate the number of retained real-space and reciprocal-space terms by continuum counts:\n$$\nN_{r}\\approx \\frac{4\\pi R_{c}^{3}}{3 a^{3}},\\qquad N_{k}\\approx \\frac{V}{(2\\pi)^{3}}\\cdot \\frac{4\\pi G_{c}^{3}}{3},\\quad V=a^{3}.\n$$\nChoose the Ewald splitting parameter $\\eta$ so as to balance the computational work between the two sums by imposing $N_{r}\\approx N_{k}$ while meeting the target tolerance via the exponential controls above. Derive an analytic approximation for the optimal splitting parameter $\\eta$ as a closed-form function of $\\varepsilon$, $k$, and $a$. Express your final answer as a single analytical expression for $\\eta(\\varepsilon,k,a)$. No numerical evaluation is required, and no units should be included in the final expression.",
            "solution": "The problem requires the derivation of an optimal Ewald splitting parameter, $\\eta$, that balances the computational work between the real-space and reciprocal-space sums while achieving a specified error tolerance, $\\varepsilon$. The computational work is estimated by the number of terms in each sum, $N_r$ and $N_k$, respectively. The optimization criterion is to set $N_r \\approx N_k$.\n\nFirst, we formalize the given relationships. Let the quantity $L$ be defined as $L = \\ln(2/\\varepsilon)$. The two equations governing the error tolerance are given as:\n$$\n(\\eta R_{c})^{2} = L \\quad (1)\n$$\n$$\n\\frac{G_{c}^{2}-k^{2}}{4\\eta^{2}} = L \\quad (2)\n$$\nwhere $R_c$ and $G_c$ are the truncation radii in real and reciprocal space, respectively, $k$ is the free-space wavenumber, and $\\eta$ is the Ewald splitting parameter.\n\nThe number of terms in the real-space sum, $N_r$, and the reciprocal-space sum, $N_k$, are approximated by continuum counts for a simple-cubic lattice with lattice constant $a$:\n$$\nN_{r} \\approx \\frac{4\\pi R_{c}^{3}}{3 a^{3}} \\quad (3)\n$$\n$$\nN_{k} \\approx \\frac{V}{(2\\pi)^{3}}\\cdot \\frac{4\\pi G_{c}^{3}}{3} = \\frac{a^{3}}{8\\pi^3} \\cdot \\frac{4\\pi G_{c}^{3}}{3} = \\frac{a^{3} G_{c}^{3}}{6\\pi^{2}} \\quad (4)\n$$\nwhere $V=a^3$ is the volume of the real-space unit cell.\n\nThe optimization condition to balance the computational work is $N_r \\approx N_k$. Equating the expressions from $(3)$ and $(4)$:\n$$\n\\frac{4\\pi R_{c}^{3}}{3 a^{3}} = \\frac{a^{3} G_{c}^{3}}{6\\pi^{2}}\n$$\nWe can rearrange this equation to find a relationship between $R_c$ and $G_c$:\n$$\n\\frac{R_{c}^{3}}{G_{c}^{3}} = \\frac{a^{3}}{6\\pi^{2}} \\cdot \\frac{3a^3}{4\\pi} = \\frac{3a^6}{24\\pi^3} = \\frac{a^6}{8\\pi^3}\n$$\nTaking the cube root of both sides gives a simple linear relationship:\n$$\n\\frac{R_c}{G_c} = \\left(\\frac{a^6}{8\\pi^3}\\right)^{1/3} = \\frac{a^2}{2\\pi}\n$$\nThis implies $G_c = \\frac{2\\pi}{a^2} R_c$.\n\nNext, we express $R_c$ and $G_c$ in terms of $\\eta$ using the error control equations $(1)$ and $(2)$. From equation $(1)$:\n$$\nR_c = \\frac{\\sqrt{L}}{\\eta} \\quad (5)\n$$\nFrom equation $(2)$:\n$$\nG_c^2 = k^2 + 4\\eta^2 L \\implies G_c = \\sqrt{k^2 + 4\\eta^2 L} \\quad (6)\n$$\nNow, substitute expressions $(5)$ and $(6)$ into the relationship $G_c = \\frac{2\\pi}{a^2} R_c$:\n$$\n\\sqrt{k^2 + 4\\eta^2 L} = \\frac{2\\pi}{a^2} \\left(\\frac{\\sqrt{L}}{\\eta}\\right)\n$$\nTo solve for $\\eta$, we square both sides of the equation:\n$$\nk^2 + 4\\eta^2 L = \\left(\\frac{2\\pi}{a^2}\\right)^2 \\left(\\frac{\\sqrt{L}}{\\eta}\\right)^2 = \\frac{4\\pi^2}{a^4} \\frac{L}{\\eta^2}\n$$\nMultiplying the entire equation by $\\eta^2$ clears the denominator:\n$$\nk^2 \\eta^2 + 4L \\eta^4 = \\frac{4\\pi^2 L}{a^4}\n$$\nThis can be rearranged into a standard quadratic equation for the variable $\\eta^2$. Let $x = \\eta^2$:\n$$\n(4L)x^2 + (k^2)x - \\frac{4\\pi^2 L}{a^4} = 0\n$$\nWe solve this quadratic equation for $x$ using the quadratic formula $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$, where the coefficients are $a_{quad} = 4L$, $b_{quad} = k^2$, and $c_{quad} = -\\frac{4\\pi^2 L}{a^4}$:\n$$\nx = \\eta^2 = \\frac{-k^2 \\pm \\sqrt{(k^2)^2 - 4(4L)\\left(-\\frac{4\\pi^2 L}{a^4}\\right)}}{2(4L)}\n$$\n$$\n\\eta^2 = \\frac{-k^2 \\pm \\sqrt{k^4 + \\frac{64\\pi^2 L^2}{a^4}}}{8L}\n$$\nSince $\\eta$ is a real-valued physical parameter, $\\eta^2$ must be a positive real number. The term under the square root, $\\sqrt{k^4 + \\frac{64\\pi^2 L^2}{a^4}}$, is strictly greater than $\\sqrt{k^4} = k^2$. Therefore, to ensure $\\eta^2  0$, we must choose the positive sign in the numerator:\n$$\n\\eta^2 = \\frac{-k^2 + \\sqrt{k^4 + \\frac{64\\pi^2 L^2}{a^4}}}{8L}\n$$\nTaking the square root of both sides gives the expression for $\\eta$. We substitute back $L = \\ln(2/\\varepsilon)$:\n$$\n\\eta = \\sqrt{\\frac{-k^2 + \\sqrt{k^4 + \\frac{64\\pi^2 (\\ln(2/\\varepsilon))^2}{a^4}}}{8 \\ln(2/\\varepsilon)}}\n$$\nThis is the final analytical expression for the optimal splitting parameter $\\eta$ as a function of the tolerance $\\varepsilon$, the wavenumber $k$, and the lattice constant $a$.",
            "answer": "$$\n\\boxed{\\sqrt{\\frac{-k^2 + \\sqrt{k^4 + \\frac{64\\pi^2 \\left(\\ln\\left(\\frac{2}{\\varepsilon}\\right)\\right)^2}{a^4}}}{8 \\ln\\left(\\frac{2}{\\varepsilon}\\right)}}}\n$$"
        },
        {
            "introduction": "Moving from theory to a robust implementation, this exercise challenges you to construct the complete Ewald summation for the three-dimensional electrostatic periodic Green's function from fundamental principles. The focus extends beyond the derivation to address crucial aspects of numerical computation, including stability, near-field regularization at the source singularity, and the use of symmetry for diagnostics . Successfully completing this practice will equip you with a tested and reliable computational tool for lattice-sum problems.",
            "id": "3340050",
            "problem": "Consider the three-dimensional scalar electrostatic Green function under triply periodic boundary conditions for a simple cubic lattice of period $L$, representing a unit point source embedded in a uniform neutralizing background, so that the potential satisfies the Laplace equation with periodic images and has finite spatial average over a unit cell. Starting from the governing equation $\\nabla^2 \\Phi(\\mathbf{r}) = -4\\pi \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3}\\delta\\!\\left(\\mathbf{r} - \\mathbf{n}L\\right) + \\frac{4\\pi}{L^3}$, where the final term enforces charge neutrality by the uniform background, derive an Ewald-splitting representation that decomposes the potential into a rapidly convergent real-space sum, a rapidly convergent reciprocal-space sum, and a background constant, with a Gaussian screening parameter $\\alpha  0$. Your derivation must begin from the definition of the free-space Green function $G(\\mathbf{r}) = \\frac{1}{4\\pi \\|\\mathbf{r}\\|}$, the convolution identity, and the Poisson summation formula, and it must justify the removal of the zero reciprocal mode and the addition of the background constant. Do not assume any textbook formulas for the Ewald summation; instead, reason from these base principles.\n\nImplementation objective: Design and implement a numerically stable algorithm to evaluate the resulting Ewald representation for the periodic Green function $\\Phi(\\mathbf{r})$ in a simple cubic cell of side $L$, using finite truncations in both real and reciprocal spaces. The algorithm should:\n- Use a real-space cutoff specified by an integer $N_r$, summing over all integer lattice vectors $\\mathbf{n} = (n_x,n_y,n_z)$ with $n_i \\in \\{-N_r,\\ldots,N_r\\}$, and evaluating the screened direct terms at $\\mathbf{r} - \\mathbf{n}L$ while avoiding the singular self-term at $\\mathbf{r}=\\mathbf{0}$.\n- Use a reciprocal-space cutoff specified by an integer $N_g$, summing over all reciprocal lattice vectors $\\mathbf{G} = \\frac{2\\pi}{L}\\mathbf{m}$ with $\\mathbf{m} = (m_x,m_y,m_z)$ and $m_i \\in \\{-N_g,\\ldots,N_g\\}$, excluding $\\mathbf{G}=\\mathbf{0}$, and including the Gaussian attenuation factor determined by $\\alpha$.\n- Include the uniform background constant implied by the neutralizing background and the exclusion of the $\\mathbf{G}=\\mathbf{0}$ mode.\n- Return a real-valued potential $\\Phi(\\mathbf{r})$ that is independent of the choice of $\\alpha$ in the limit of large cutoffs.\n\nFocus on numerical stability and implementation pitfalls that arise in practical computation:\n- Explain how the choice of $\\alpha$ mediates the division of work between real and reciprocal sums, and why poor choices can cause slow convergence or loss of accuracy due to truncation or catastrophic cancellation.\n- Describe how to treat the near-field behavior for $\\|\\mathbf{r}\\|\\to 0$, including the subtraction of the singular free-space term and the interpretation of the finite regularized limit.\n- Justify the removal of the zero reciprocal mode and the necessity of a uniform background to ensure physical and mathematical consistency under periodic boundary conditions.\n- Identify symmetry properties of $\\Phi(\\mathbf{r})$ and how to leverage them to design diagnostics for implementation errors.\n\nAll quantities in this problem are dimensionless. Angles, where applicable, are in radians.\n\nTest suite and required outputs: Implement your algorithm to compute the following four diagnostics, each returning a single floating-point value.\n\nCase A (screening-parameter independence): With $L = 1.0$, $\\mathbf{r} = \\left(0.31,0.2,0.1\\right)$, $N_r = 4$, $N_g = 4$, compute the absolute difference $\\left|\\Phi_{\\alpha_1}(\\mathbf{r}) - \\Phi_{\\alpha_2}(\\mathbf{r})\\right|$ with $\\alpha_1 = 2.0$ and $\\alpha_2 = 4.0$.\n\nCase B (truncation sensitivity): With $L = 1.0$, $\\mathbf{r} = \\left(0.33,0.27,0.41\\right)$, $\\alpha = 3.0$, compute the absolute difference between a loosely truncated and a tightly truncated evaluation: $\\left|\\Phi^{(N_r=1,N_g=1)}(\\mathbf{r}) - \\Phi^{(N_r=4,N_g=4)}(\\mathbf{r})\\right|$.\n\nCase C (near-field regularization): With $L = 1.0$, $\\mathbf{r}_\\varepsilon = \\left(10^{-4},0.0,0.0\\right)$, $\\alpha = 3.5$, $N_r=5$, $N_g=5$, compute the regularized value $\\Phi(\\mathbf{r}_\\varepsilon) - \\frac{1}{\\|\\mathbf{r}_\\varepsilon\\|}$.\n\nCase D (symmetry diagnostic): With $L = 1.0$, $\\mathbf{r} = \\left(0.21,0.37,0.49\\right)$, $\\alpha = 3.0$, $N_r=4$, $N_g=4$, compute $\\left|\\Phi(\\mathbf{r}) - \\Phi(-\\mathbf{r})\\right|$.\n\nFinal program output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $\\left[\\text{Case A}, \\text{Case B}, \\text{Case C}, \\text{Case D}\\right]$. For example, a valid output line has the form $\\left[\\text{resultA},\\text{resultB},\\text{resultC},\\text{resultD}\\right]$.",
            "solution": "### Derivation of the Ewald Summation Formula\n\nThe objective is to compute the potential $\\Phi(\\mathbf{r})$ generated by a periodic lattice of unit point charges located at positions $\\mathbf{n}L$ for $\\mathbf{n} \\in \\mathbb{Z}^3$, embedded in a uniform neutralizing background. The governing equation is the Poisson equation:\n$$\n\\nabla^2 \\Phi(\\mathbf{r}) = -4\\pi \\rho(\\mathbf{r})\n$$\nwhere the total charge density $\\rho(\\mathbf{r})$ includes the point charges and the background:\n$$\n\\rho(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\delta(\\mathbf{r} - \\mathbf{n}L) - \\frac{1}{L^3}\n$$\nThe formal solution is a sum over the potential from all image charges, $\\Phi(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\frac{1}{\\|\\mathbf{r} - \\mathbf{n}L\\|}$, plus a term for the background. This sum is conditionally convergent and computationally prohibitive. The Ewald method splits this sum into two rapidly convergent series: one in real space and one in reciprocal space.\n\nThe core idea is to add and subtract a lattice of smooth Gaussian charge distributions centered on each point charge. We split the point charge density $\\delta(\\mathbf{r})$ into a short-range part (a point charge screened by a surrounding negative Gaussian) and a long-range part (the positive Gaussian itself):\n$$\n\\delta(\\mathbf{r}) = \\underbrace{\\left( \\delta(\\mathbf{r}) - \\rho_G(\\mathbf{r}, \\alpha) \\right)}_{\\text{short-range}} + \\underbrace{\\rho_G(\\mathbf{r}, \\alpha)}_{\\text{long-range}}\n$$\nwhere $\\rho_G(\\mathbf{r}, \\alpha) = \\frac{\\alpha^3}{\\pi^{3/2}} e^{-\\alpha^2 \\|\\mathbf{r}\\|^2}$ is a normalized Gaussian charge distribution with a tunable width parameter $\\alpha$. The total potential $\\Phi$ is likewise split into $\\Phi = \\Phi_{real} + \\Phi_{recip} + \\Phi_{const}$.\n\n**1. Real-Space Sum ($\\Phi_{real}$)**\n\nThe real-space contribution arises from the lattice of short-range charge densities. The potential of a single point charge screened by a Gaussian is found by solving the Poisson equation, which yields the well-known result:\n$$\n\\phi_{screened}(\\mathbf{r}) = \\frac{1}{\\|\\mathbf{r}\\|} - \\int_{\\mathbb{R}^3} \\frac{\\rho_G(\\mathbf{r'})}{\\|\\mathbf{r}-\\mathbf{r'}\\|} d^3\\mathbf{r'} = \\frac{1}{\\|\\mathbf{r}\\|} - \\frac{\\text{erf}(\\alpha \\|\\mathbf{r}\\|)}{\\|\\mathbf{r}\\|} = \\frac{\\text{erfc}(\\alpha \\|\\mathbf{r}\\|)}{\\|\\mathbf{r}\\|}\n$$\nwhere $\\text{erfc}$ is the complementary error function. Summing this potential over the entire lattice gives the real-space sum:\n$$\n\\Phi_{real}(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\frac{\\text{erfc}(\\alpha \\|\\mathbf{r} - \\mathbf{n}L\\|)}{\\|\\mathbf{r} - \\mathbf{n}L\\|}\n$$\nThis sum converges rapidly because $\\text{erfc}(x)$ decays exponentially for large $x$. The summation is truncated in practice to a finite number of lattice vectors, controlled by the cutoff $N_r$.\n\n**2. Reciprocal-Space Sum ($\\Phi_{recip}$)**\n\nThe reciprocal-space contribution arises from the smooth, periodic lattice of Gaussian charge distributions, $\\rho_{long}(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\rho_G(\\mathbf{r} - \\mathbf{n}L, \\alpha)$, plus the neutralizing background. The total charge density for this part, $\\rho_{recip}(\\mathbf{r}) = \\rho_{long}(\\mathbf{r}) - 1/L^3$, is periodic and has zero average charge. We can therefore expand it in a Fourier series over the reciprocal lattice vectors $\\mathbf{G} = \\frac{2\\pi}{L}\\mathbf{m}$ for $\\mathbf{m} \\in \\mathbb{Z}^3$:\n$$\n\\rho_{recip}(\\mathbf{r}) = \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\hat{\\rho}_{\\mathbf{G}} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\n$$\nThe Fourier coefficients $\\hat{\\rho}_{\\mathbf{G}}$ are found by integrating over the unit cell. Due to periodicity, this is equivalent to the Fourier transform of a single Gaussian, scaled by the cell volume $V=L^3$:\n$$\n\\hat{\\rho}_{\\mathbf{G}} = \\frac{1}{L^3} \\int_{\\mathbb{R}^3} \\rho_G(\\mathbf{r}, \\alpha) e^{-i\\mathbf{G}\\cdot\\mathbf{r}} d^3\\mathbf{r} = \\frac{1}{L^3} e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}\n$$\nThe $\\mathbf{G}=\\mathbf{0}$ component is zero because the total average charge density is zero. This is the justification for excluding the $\\mathbf{G}=\\mathbf{0}$ term from the sum and for the physical necessity of the neutralizing background; without it, the potential would diverge.\n\nSolving the Poisson equation $\\nabla^2 \\Phi_{recip} = -4\\pi \\rho_{recip}$ in Fourier space gives a simple algebraic relation: $-\\|\\mathbf{G}\\|^2 \\hat{\\Phi}_{\\mathbf{G}} = -4\\pi \\hat{\\rho}_{\\mathbf{G}}$. For $\\mathbf{G} \\ne \\mathbf{0}$, we have:\n$$\n\\hat{\\Phi}_{\\mathbf{G}} = \\frac{4\\pi \\hat{\\rho}_{\\mathbf{G}}}{\\|\\mathbf{G}\\|^2} = \\frac{4\\pi}{L^3 \\|\\mathbf{G}\\|^2} e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}\n$$\nTransforming back to real space gives the reciprocal-space potential sum. Since $\\Phi_{recip}$ must be real and the charge density is even, the sum simplifies using $\\cos(\\mathbf{G}\\cdot\\mathbf{r})$:\n$$\n\\Phi_{recip}(\\mathbf{r}) = \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\hat{\\Phi}_{\\mathbf{G}} e^{i\\mathbf{G}\\cdot\\mathbf{r}} = \\frac{4\\pi}{L^3} \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\frac{e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}}{\\|\\mathbf{G}\\|^2} \\cos(\\mathbf{G}\\cdot\\mathbf{r})\n$$\nThis sum converges rapidly because of the Gaussian exponential factor. The summation is truncated with a cutoff $N_g$.\n\n**3. Background Constant ($\\Phi_{const}$)**\n\nThe exclusion of the $\\mathbf{G}=\\mathbf{0}$ mode means that the average value of the potential, $\\langle \\Phi \\rangle$, is not determined by Poisson's equation. A convention must be chosen. A common and physically meaningful one is to set the average potential of the entire system to zero. The combined average of the real and reciprocal space sums is not zero. A constant must be added to enforce $\\langle \\Phi \\rangle=0$. The average of $\\Phi_{recip}$ is zero by construction. The average of $\\Phi_{real}$ is:\n$$\n\\langle \\Phi_{real} \\rangle = \\frac{1}{L^3} \\int_{cell} \\sum_{\\mathbf{n}} \\frac{\\text{erfc}(\\alpha\\|\\mathbf{r}-\\mathbf{n}L\\|)}{\\|\\mathbf{r}-\\mathbf{n}L\\|} d^3\\mathbf{r} = \\frac{1}{L^3} \\int_{\\mathbb{R}^3} \\frac{\\text{erfc}(\\alpha r)}{r} d^3\\mathbf{r} = \\frac \\pi{\\alpha^2 L^3}\n$$\nTo make the total average potential zero, we must subtract this value. Thus, the background constant is:\n$$\n\\Phi_{const} = -\\frac{\\pi}{\\alpha^2 L^3}\n$$\n\n**Final Ewald Formula:**\nThe complete potential is the sum of these three parts:\n$$\n\\Phi(\\mathbf{r}) = \\sum_{\\mathbf{n}} \\frac{\\text{erfc}(\\alpha \\|\\mathbf{r} - \\mathbf{n}L\\|)}{\\|\\mathbf{r} - \\mathbf{n}L\\|} + \\frac{4\\pi}{L^3} \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\frac{e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}}{\\|\\mathbf{G}\\|^2} \\cos(\\mathbf{G}\\cdot\\mathbf{r}) - \\frac{\\pi}{\\alpha^2 L^3}\n$$\n\n### Numerical Implementation Considerations\n\n- **Choice of $\\alpha$**: The Ewald parameter $\\alpha$ balances the workload between the real- and reciprocal-space sums. A large $\\alpha$ makes the real-space sum converge quickly but the reciprocal-space sum slowly. A small $\\alpha$ has the opposite effect. An optimal $\\alpha$ minimizes the total computation time by roughly equating the truncation errors from both sums. Poor choices of $\\alpha$ can lead to slow convergence and necessitate large cutoffs ($N_r, N_g$) for a given accuracy.\n- **Near-field Behavior**: As the evaluation point $\\mathbf{r}$ approaches a lattice site (e.g., the origin), the $\\mathbf{n}=\\mathbf{0}$ term in the real-space sum, $\\frac{\\text{erfc}(\\alpha \\|\\mathbf{r}\\|)}{\\|\\mathbf{r}\\|}$, becomes singular. For small $\\|\\mathbf{r}\\|$, this term has the expansion $\\frac{1}{\\|\\mathbf{r}\\|} - \\frac{2\\alpha}{\\sqrt{\\pi}} + O(\\|\\mathbf{r}\\|^2)$. The $\\frac{1}{\\|\\mathbf{r}\\|}$ part is the expected singularity of the Green function. The \"regularized\" value, $\\lim_{\\|\\mathbf{r}\\|\\to 0} \\left(\\Phi(\\mathbf{r}) - \\frac{1}{\\|\\mathbf{r}\\|}\\right)$, is a finite constant representing the potential at a charge's location due to all its periodic images and the background field. This value is computed in Case C.\n- **Symmetry**: The source charge distribution $\\rho(\\mathbf{r})$ is an even function, $\\rho(\\mathbf{r}) = \\rho(-\\mathbf{r})$. The resulting potential $\\Phi(\\mathbf{r})$ must also be an even function, $\\Phi(\\mathbf{r}) = \\Phi(-\\mathbf{r})$. This property serves as a powerful diagnostic tool. Any significant deviation in the computed values of $|\\Phi(\\mathbf{r}) - \\Phi(-\\mathbf{r})|$ from zero indicates a potential programming error, for example, in handling vector dot products or in implementing the trigonometric part of the reciprocal-space sum.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import erfc\n\ndef compute_phi(r_vec, L, alpha, Nr, Ng):\n    \"\"\"\n    Computes the periodic electrostatic Green function using Ewald summation for a simple cubic lattice.\n\n    This function calculates the potential Phi(r) satisfying the periodic Poisson equation\n    ∇²Φ = -4π Σ_n δ(r - nL) + 4π/L³, which represents a lattice of unit point charges\n    in a uniform neutralizing background.\n\n    Args:\n        r_vec (np.array): Position vector (x, y, z) to evaluate the potential.\n        L (float): Side length of the simple cubic cell.\n        alpha (float): Ewald splitting parameter.\n        Nr (int): Real-space cutoff (sum over n_i in [-Nr, Nr]).\n        Ng (int): Reciprocal-space cutoff (sum over m_i in [-Ng, Ng]).\n\n    Returns:\n        float: The value of the potential Phi(r).\n    \"\"\"\n    r_vec = np.asarray(r_vec, dtype=np.float64)\n    V = L**3\n\n    # Part 1: Real-space sum\n    # This sum is over the short-range part of the potential, which decays rapidly.\n    phi_real = 0.0\n    n_range = range(-Nr, Nr + 1)\n    for nx in n_range:\n        for ny in n_range:\n            for nz in n_range:\n                n_vec = np.array([nx, ny, nz], dtype=np.float64)\n                # The distance between the evaluation point r and the lattice point nL.\n                r_minus_nL = r_vec - n_vec * L\n                d = np.linalg.norm(r_minus_nL)\n                \n                # Avoid division by zero if r is exactly on a lattice point.\n                if d > 1e-14:\n                    phi_real += erfc(alpha * d) / d\n\n    # Part 2: Reciprocal-space sum\n    # This sum is over the long-range, smooth part of the potential.\n    phi_recip = 0.0\n    m_range = range(-Ng, Ng + 1)\n    for mx in m_range:\n        for my in m_range:\n            for mz in m_range:\n                if mx == 0 and my == 0 and mz == 0:\n                    continue  # Exclude the G=0 term, as required for charge neutrality.\n                \n                m_vec = np.array([mx, my, mz], dtype=np.float64)\n                G_vec = (2.0 * np.pi / L) * m_vec\n                G2 = np.dot(G_vec, G_vec)\n                \n                term = np.exp(-G2 / (4.0 * alpha**2)) / G2\n                term *= np.cos(np.dot(G_vec, r_vec))\n                \n                phi_recip += term\n\n    phi_recip *= (4.0 * np.pi / V)\n\n    # Part 3: Background constant term\n    # This constant is added to enforce the convention that the average potential is zero.\n    C_bkg = -np.pi / (alpha**2 * V)\n    \n    return phi_real + phi_recip + C_bkg\n\ndef solve():\n    \"\"\"\n    Calculates and prints the results for the four test cases specified in the problem.\n    \"\"\"\n    # Case A: Screening parameter independence check.\n    # For sufficiently large cutoffs, the result should be nearly independent of alpha.\n    L_A = 1.0\n    r_A = np.array([0.31, 0.2, 0.1])\n    Nr_A, Ng_A = 4, 4\n    alpha1_A, alpha2_A = 2.0, 4.0\n    phi1_A = compute_phi(r_A, L_A, alpha1_A, Nr_A, Ng_A)\n    phi2_A = compute_phi(r_A, L_A, alpha2_A, Nr_A, Ng_A)\n    result_A = np.abs(phi1_A - phi2_A)\n\n    # Case B: Truncation sensitivity check.\n    # Demonstrates that insufficient cutoffs lead to significant error.\n    L_B = 1.0\n    r_B = np.array([0.33, 0.27, 0.41])\n    alpha_B = 3.0\n    phi_loose_B = compute_phi(r_B, L_B, alpha_B, Nr=1, Ng=1)\n    phi_tight_B = compute_phi(r_B, L_B, alpha_B, Nr=4, Ng=4)\n    result_B = np.abs(phi_loose_B - phi_tight_B)\n\n    # Case C: Near-field regularization.\n    # Computes the finite, regularized potential at the location of a source charge.\n    L_C = 1.0\n    r_eps_C_val = 1e-4\n    r_eps_C = np.array([r_eps_C_val, 0.0, 0.0])\n    alpha_C = 3.5\n    Nr_C, Ng_C = 5, 5\n    phi_eps_C = compute_phi(r_eps_C, L_C, alpha_C, Nr_C, Ng_C)\n    result_C = phi_eps_C - 1.0 / r_eps_C_val\n\n    # Case D: Symmetry diagnostic.\n    # Checks if the computed potential satisfies the even symmetry Phi(r) = Phi(-r).\n    L_D = 1.0\n    r_D = np.array([0.21, 0.37, 0.49])\n    alpha_D = 3.0\n    Nr_D, Ng_D = 4, 4\n    phi_r_D = compute_phi(r_D, L_D, alpha_D, Nr_D, Ng_D)\n    phi_neg_r_D = compute_phi(-r_D, L_D, alpha_D, Nr_D, Ng_D)\n    result_D = np.abs(phi_r_D - phi_neg_r_D)\n    \n    results = [result_A, result_B, result_C, result_D]\n    \n    # Print the final output in the required format.\n    print(f\"[{','.join(f'{res:.10f}' for res in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "To gain a deeper insight into why the Ewald method is so effective at producing smooth, convergent results, this practice re-examines the reciprocal-space sum through the lens of spectral analysis. You will see how the Gaussian damping factor inherent in the Ewald split acts as a sophisticated spectral window, mitigating the Gibbs ringing that plagues sharply truncated Fourier series . By comparing this Ewald-Gaussian taper to other standard windowing functions, you will develop a more profound appreciation for the method's elegant design.",
            "id": "3340025",
            "problem": "Consider the zero-mean periodic Green function for the scalar Laplace equation on the square two-dimensional torus of side length $2\\pi$. Let $\\mathbf{x}=(x,y)\\in[0,2\\pi)^2$, and let $\\mathbf{m}=(m_x,m_y)\\in\\mathbb{Z}^2$. The function $G(\\mathbf{x})$ is defined to satisfy $-\\Delta G(\\mathbf{x}) = 4\\pi^2\\left(\\delta(\\mathbf{x}) - \\frac{1}{(2\\pi)^2}\\right)$ in the distributional sense and to have zero average over the torus. By Fourier series, a standard representation for $G(\\mathbf{x})$ is given by the absolutely convergent series\n$$\nG(\\mathbf{x}) \\;=\\; \\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} \\frac{e^{i\\mathbf{m}\\cdot \\mathbf{x}}}{\\lVert \\mathbf{m}\\rVert^2},\n$$\nwhere $\\mathbf{m}\\cdot \\mathbf{x} = m_x x + m_y y$ and $\\lVert \\mathbf{m}\\rVert^2 = m_x^2 + m_y^2$. This series, when naively truncated by restricting to a finite set of modes, exhibits Gibbs-like ringing near the singularity at $\\mathbf{x}=\\mathbf{0}$.\n\nStarting from the Poisson equation on the torus and the Fourier eigenpairs of the Laplace operator, and using only the following fundamental identity for positive $a$,\n$$\n\\frac{1}{a} \\;=\\; \\int_{0}^{\\infty} e^{-a t}\\,dt,\n$$\nderive and explain how an Ewald-type splitting of the reciprocal-space series arises by splitting the integral at $t=t_00$. Show that this produces a factor of the form $e^{-t_0 \\lVert \\mathbf{m}\\rVert^2}$ multiplying the truncated reciprocal sum, with $t_0$ related to a splitting parameter $\\eta$ by $t_0 = \\frac{1}{4\\eta^2}$. Contrast this with the “rectangular” truncation that applies no taper. Then, motivated by spectral windowing theory, explain and define at least two alternative tapering strategies applied to the truncated reciprocal sum, such as a Kaiser–Bessel window and a raised-cosine window, and justify their expected effect on Gibbs-like ringing.\n\nFor quantitative evaluation, restrict attention to the line $y=0$, so that $\\mathbf{m}\\cdot\\mathbf{x} = m_x x$, and let $x=r$ with $r\\in(0,\\pi]$ measured in radians. For a radial truncation parameter $K\\in\\mathbb{N}$ and a window/taper function $w(\\lVert\\mathbf{m}\\rVert)$ supported on $\\{\\lVert\\mathbf{m}\\rVert\\le K\\}$, define the truncated and tapered reciprocal approximation\n$$\nG_{K,w}(r) \\;=\\; \\sum_{\\substack{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}\\\\ \\lVert \\mathbf{m}\\rVert\\le K}} \\frac{w(\\lVert \\mathbf{m}\\rVert)}{\\lVert \\mathbf{m}\\rVert^2} \\cos(m_x r),\n$$\nwhich is well-defined for $r0$. To quantify overshoot, define a high-accuracy reference $G_{\\mathrm{ref}}(r)$ by taking a much larger radial cutoff $K_{\\mathrm{ref}}$ and a super-Gaussian window $w_{\\mathrm{ref}}(\\rho) = \\exp\\!\\left(-(\\rho/K_{\\mathrm{ref}})^4\\right)$ supported on $\\{\\rho\\le K_{\\mathrm{ref}}\\}$, and form\n$$\nG_{\\mathrm{ref}}(r) \\;=\\; \\sum_{\\substack{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}\\\\ \\lVert \\mathbf{m}\\rVert\\le K_{\\mathrm{ref}}}} \\frac{w_{\\mathrm{ref}}(\\lVert \\mathbf{m}\\rVert)}{\\lVert \\mathbf{m}\\rVert^2} \\cos(m_x r).\n$$\nOn the near-field interval $r\\in[r_{\\min},r_{\\max}]$ with $r_{\\min}0$ small and $r_{\\max}$ modest, define the overshoot of an approximation as\n$$\n\\mathcal{O}[G_{K,w}] \\;=\\; \\max_{r\\in\\mathcal{R}} \\max\\!\\left\\{\\,G_{K,w}(r) - G_{\\mathrm{ref}}(r),\\, 0\\,\\right\\},\n$$\nwhere $\\mathcal{R}$ is a discrete set of $N_r$ radii uniformly sampling $[r_{\\min},r_{\\max}]$.\n\nYour task is to:\n- Derive, from the stated base, the Ewald-Gaussian reciprocal taper $w_{\\mathrm{Ewald}}(\\rho) = \\exp\\!\\left(-\\rho^2/(4\\eta^2)\\right)$, with splitting parameter $\\eta0$, and explain its role in mitigating ringing in the truncated reciprocal sum.\n- Define and justify two additional taper functions: a Kaiser–Bessel radial window $w_{\\mathrm{Kaiser}}(\\rho) = \\frac{I_0\\!\\left(\\beta \\sqrt{1 - (\\rho/K)^2}\\right)}{I_0(\\beta)}$ for $\\rho\\le K$ and $0$ otherwise, where $I_0$ is the modified Bessel function of the first kind of order zero and $\\beta0$ is the shape parameter; and a raised-cosine window $w_{\\mathrm{RC}}(\\rho) = \\tfrac{1}{2}\\left(1+\\cos(\\pi \\rho/K)\\right)$ for $\\rho\\le K$ and $0$ otherwise.\n- Implement a program that constructs $G_{K,w}(r)$ and $G_{\\mathrm{ref}}(r)$ as defined above, evaluates the overshoot $\\mathcal{O}[G_{K,w}]$ over the discrete set $\\mathcal{R}$, and reports the overshoot values for the following test suite. All angles are in radians.\n\nTest suite (each test specifies $(K, w, \\text{parameters})$):\n1. $(K=\\;10,\\; w=\\;\\text{rectangular},\\; \\text{no parameters})$ with $w(\\rho)=1$ for $\\rho\\le K$ and $0$ otherwise.\n2. $(K=\\;10,\\; w=\\;\\text{Ewald-Gaussian},\\; \\eta=\\;2.5)$ with $w(\\rho)=\\exp\\!\\left(-\\rho^2/(4\\eta^2)\\right)$ for $\\rho\\le K$.\n3. $(K=\\;10,\\; w=\\;\\text{Kaiser–Bessel},\\; \\beta=\\;8.0)$.\n4. $(K=\\;20,\\; w=\\;\\text{rectangular},\\; \\text{no parameters})$.\n5. $(K=\\;20,\\; w=\\;\\text{Ewald-Gaussian},\\; \\eta=\\;3.5)$.\n6. $(K=\\;20,\\; w=\\;\\text{raised-cosine},\\; \\text{no parameters})$.\n\nUse the following fixed settings for the reference and the sampling:\n- $K_{\\mathrm{ref}}=\\;70$,\n- $w_{\\mathrm{ref}}(\\rho) = \\exp\\!\\left(-(\\rho/K_{\\mathrm{ref}})^4\\right)$ for $\\rho\\le K_{\\mathrm{ref}}$ and $0$ otherwise,\n- $r_{\\min}=\\;0.02$, $r_{\\max}=\\;0.40$, and $N_r=\\;128$, so that $\\mathcal{R}$ is the uniform grid on $[r_{\\min},r_{\\max}]$ with $N_r$ points.\n\nYour program should produce a single line of output containing the overshoot values for tests $1$ through $6$ as a comma-separated Python list of floats enclosed in square brackets. For example, an output of the form $[\\text{float}_1,\\text{float}_2,\\text{float}_3,\\text{float}_4,\\text{float}_5,\\text{float}_6]$ must be printed, with no additional text. Angles must be treated in radians throughout. No physical units other than radians are involved. The numerical answers must be reported as pure floating-point numbers without any percentage symbols.",
            "solution": "The core of the problem is to understand and mitigate the Gibbs phenomenon when approximating a singular function, the periodic Green's function for the Laplacian, by a truncated Fourier series. The slow decay of the Fourier coefficients, $\\mathcal{O}(1/\\lVert \\mathbf{m}\\rVert^2)$, leads to oscillations, known as ringing, near the singularity at $\\mathbf{x}=\\mathbf{0}$. The problem explores tapering or windowing the Fourier coefficients to accelerate convergence and suppress these oscillations.\n\n**Derivation of the Ewald-Gaussian Reciprocal Taper**\n\nThe problem starts with the Fourier series representation of the zero-mean periodic Green's function on a two-dimensional torus of side length $2\\pi$:\n$$\nG(\\mathbf{x}) \\;=\\; \\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} \\frac{e^{i\\mathbf{m}\\cdot \\mathbf{x}}}{\\lVert \\mathbf{m}\\rVert^2}\n$$\nThe key to the Ewald method is to split the slowly converging sum into two rapidly converging parts. Following the directive, we use the integral identity for $a0$:\n$$\n\\frac{1}{a} \\;=\\; \\int_{0}^{\\infty} e^{-a t}\\,dt\n$$\nApplying this to each term in the series with $a = \\lVert \\mathbf{m}\\rVert^2$, we obtain:\n$$\nG(\\mathbf{x}) \\;=\\; \\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} e^{i\\mathbf{m}\\cdot \\mathbf{x}} \\int_{0}^{\\infty} e^{-\\lVert \\mathbf{m}\\rVert^2 t}\\,dt\n$$\nAssuming uniform convergence allows swapping the summation and integration:\n$$\nG(\\mathbf{x}) \\;=\\; \\int_{0}^{\\infty} \\left( \\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} e^{i\\mathbf{m}\\cdot \\mathbf{x}} e^{-\\lVert \\mathbf{m}\\rVert^2 t} \\right) dt\n$$\nThe Ewald splitting consists of partitioning the domain of integration at an arbitrary splitting parameter $t_0  0$:\n$$\nG(\\mathbf{x}) \\;=\\; \\int_{t_0}^{\\infty} \\left(\\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} \\dots \\right) dt \\;+\\; \\int_{0}^{t_0} \\left( \\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} \\dots \\right) dt\n$$\nLet's analyze the first integral, from $t_0$ to $\\infty$. We can swap the summation and integration back:\n$$\nG_1(\\mathbf{x}) = \\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} e^{i\\mathbf{m}\\cdot \\mathbf{x}} \\int_{t_0}^{\\infty} e^{-\\lVert \\mathbf{m}\\rVert^2 t}\\,dt\n$$\nEvaluating the integral gives:\n$$\n\\int_{t_0}^{\\infty} e^{-\\lVert \\mathbf{m}\\rVert^2 t}\\,dt = \\left[ -\\frac{e^{-\\lVert \\mathbf{m}\\rVert^2 t}}{\\lVert \\mathbf{m}\\rVert^2} \\right]_{t_0}^{\\infty} = \\frac{e^{-\\lVert \\mathbf{m}\\rVert^2 t_0}}{\\lVert \\mathbf{m}\\rVert^2}\n$$\nThis yields a summation in reciprocal space with a Gaussian taper:\n$$\nG_1(\\mathbf{x}) = \\sum_{\\mathbf{m}\\in\\mathbb{Z}^2\\setminus\\{\\mathbf{0}\\}} \\frac{e^{i\\mathbf{m}\\cdot \\mathbf{x}}}{\\lVert \\mathbf{m}\\rVert^2} e^{-\\lVert \\mathbf{m}\\rVert^2 t_0}\n$$\nThe factor $e^{-\\lVert \\mathbf{m}\\rVert^2 t_0}$ causes the terms to decay exponentially for large $\\lVert \\mathbf{m}\\rVert$, ensuring rapid convergence. The second part of the integral, $G_2(\\mathbf{x})$, is typically transformed via the Poisson summation formula into a rapidly converging sum in real space. The full Ewald method computes both parts.\n\nHowever, the problem uses this derivation to motivate a tapering strategy for the original sum. The term $G_1(\\mathbf{x})$ can be seen as a smooth component of the full Green's function. By itself, it is not the full solution, but its structure suggests that multiplying the original Fourier coefficients by a Gaussian function $w(\\lVert\\mathbf{m}\\rVert) = e^{-\\lVert\\mathbf{m}\\rVert^2 t_0}$ is a physically motivated way to create a smooth, rapidly converging approximation. With the standard Ewald parameterization relating $t_0$ to a real-space width parameter $\\eta$ via $t_0 = \\frac{1}{4\\eta^2}$, we obtain the Ewald-Gaussian taper:\n$$\nw_{\\mathrm{Ewald}}(\\rho) = \\exp\\!\\left(-\\frac{\\rho^2}{4\\eta^2}\\right)\n$$\nwhere $\\rho = \\lVert \\mathbf{m} \\rVert$. This is in stark contrast to a rectangular (or \"boxcar\") truncation, where $w(\\rho)=1$ for $\\rho \\le K$ and $w(\\rho)=0$ for $\\rho  K$. The sharp discontinuity of the rectangular window in the frequency domain is precisely the cause of the Gibbs phenomenon (ringing) in the spatial domain. The smooth decay of the Gaussian taper avoids this sharp cutoff, thereby suppressing the ringing and providing a much smoother approximation, albeit with some broadening of the central peak.\n\n**Alternative Tapering Strategies from Spectral Windowing Theory**\n\nThe idea of smoothing the truncation of a Fourier series is central to the theory of spectral analysis and digital signal processing. Many window functions have been developed for this purpose.\n\n1.  **Kaiser–Bessel Window**:\n    The Kaiser–Bessel window is defined as:\n    $$\n    w_{\\mathrm{Kaiser}}(\\rho) = \\frac{I_0\\!\\left(\\beta \\sqrt{1 - (\\rho/K)^2}\\right)}{I_0(\\beta)} \\quad \\text{for } \\rho \\le K, \\text{ and } 0 \\text{ otherwise.}\n    $$\n    Here, $I_0$ is the modified Bessel function of the first kind of order zero, $K$ is the radial truncation parameter, and $\\beta$ is a shape parameter. This window is a near-optimal approximation to the discrete prolate spheroidal sequence of order $0$ (DPSS), which has the maximum possible energy concentration within a given spectral bandwidth. The parameter $\\beta$ controls the trade-off between the main-lobe width and the side-lobe attenuation in the window's Fourier transform. A larger $\\beta$ results in lower side-lobes (less ringing) at the cost of a wider main lobe (more blurring of the feature). Its justification lies in its ability to provide excellent side-lobe suppression for a given main-lobe width, making it highly effective at reducing Gibbs ringing artifacts.\n\n2.  **Raised-Cosine Window**:\n    The raised-cosine window is defined as:\n    $$\n    w_{\\mathrm{RC}}(\\rho) = \\frac{1}{2}\\left(1+\\cos\\left(\\frac{\\pi \\rho}{K}\\right)\\right) \\quad \\text{for } \\rho \\le K, \\text{ and } 0 \\text{ otherwise.}\n    $$\n    This window, a form of the Hann window generalized to a radial coordinate, provides a smooth taper from $1$ at the center ($\\rho=0$) to $0$ at the cutoff boundary ($\\rho=K$). It is computationally simple and very effective at reducing spectral leakage compared to a rectangular window. Its Fourier transform has significantly lower side-lobes, which translates to a dramatic reduction in Gibbs ringing. While not as tunable or optimal as the Kaiser–Bessel window, its performance is a substantial improvement over simple truncation and serves as a robust and common choice.\n\nBoth alternative windows, like the Ewald-Gaussian taper, function by smoothly driving the Fourier coefficients to zero at the truncation boundary, preventing the sharp cutoff that causes ringing. They are justified by the fundamental principle of Fourier analysis that smoothness in one domain corresponds to decay in the transformed domain.\n\n**Quantitative Evaluation**\n\nThe problem defines a quantitative measure of ringing, the overshoot $\\mathcal{O}[G_{K,w}]$, by comparing a tapered, truncated approximation $G_{K,w}(r)$ to a high-accuracy reference solution $G_{\\mathrm{ref}}(r)$. The following program implements this evaluation for the specified test suite. It first generates all necessary integer modes $(m_x, m_y)$, then computes the high-accuracy reference sum once, and finally iterates through the test cases, computing each approximation and its corresponding overshoot. The use of vectorized `NumPy` operations is essential for efficient computation of the lattice sums.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import i0\n\ndef solve():\n    \"\"\"\n    Derives and evaluates overshoot for different windowed approximations of a\n    periodic Green's function.\n    \"\"\"\n    # Fixed settings for reference calculation and sampling\n    K_ref = 70.0\n    r_min = 0.02\n    r_max = 0.40\n    N_r = 128\n    \n    # Test suite: (K, window_type, parameters_dict)\n    test_cases = [\n        (10.0, 'rectangular', {}),\n        (10.0, 'ewald_gaussian', {'eta': 2.5}),\n        (10.0, 'kaiser_bessel', {'beta': 8.0}),\n        (20.0, 'rectangular', {}),\n        (20.0, 'ewald_gaussian', {'eta': 3.5}),\n        (20.0, 'raised_cosine', {}),\n    ]\n\n    # Generate the grid of radii for evaluation\n    r_grid = np.linspace(r_min, r_max, N_r)\n\n    # Generate the master list of modes (mx, my, norm, norm^2) up to K_ref\n    # This is the most computationally intensive part if done naively.\n    # We iterate over a square and filter by radius.\n    K_max_int = int(np.floor(K_ref))\n    modes = []\n    for mx in range(-K_max_int, K_max_int + 1):\n        my_max_int = int(np.floor(np.sqrt(K_ref**2 - mx**2)))\n        for my in range(-my_max_int, my_max_int + 1):\n            if mx == 0 and my == 0:\n                continue\n            norm_sq = float(mx**2 + my**2)\n            # We only need to check norm_sq = K_ref**2, which is guaranteed by loop bounds.\n            modes.append((mx, my, np.sqrt(norm_sq), norm_sq))\n    \n    # Unpack modes into numpy arrays for vectorized operations\n    modes_arr = np.array(modes, dtype=np.float64)\n    all_mx = modes_arr[:, 0]\n    all_norm = modes_arr[:, 2]\n    all_norm2 = modes_arr[:, 3]\n\n    # --- Compute the high-accuracy reference function G_ref ---\n    \n    # Filter modes for the reference calculation\n    ref_indices = all_norm = K_ref\n    ref_mx = all_mx[ref_indices]\n    ref_norm = all_norm[ref_indices]\n    ref_norm2 = all_norm2[ref_indices]\n    \n    # Reference window function\n    w_ref = np.exp(-(ref_norm / K_ref)**4)\n    \n    # Calculate terms for the reference sum\n    terms_ref = w_ref / ref_norm2\n    \n    # Compute G_ref(r) for all r in r_grid using matrix multiplication\n    # cos_vals_ref is a (num_modes x N_r) matrix\n    cos_vals_ref = np.cos(np.outer(ref_mx, r_grid))\n    # G_ref is the dot product of terms with each column of cos_vals_ref\n    G_ref = terms_ref @ cos_vals_ref\n\n    # --- Process each test case ---\n    results = []\n    for K, window_type, params in test_cases:\n        \n        # Filter modes for the current approximation\n        approx_indices = all_norm = K\n        approx_mx = all_mx[approx_indices]\n        approx_norm = all_norm[approx_indices]\n        approx_norm2 = all_norm2[approx_indices]\n\n        # Define and apply the window function for the current case\n        if window_type == 'rectangular':\n            w_approx = np.ones_like(approx_norm)\n        elif window_type == 'ewald_gaussian':\n            eta = params['eta']\n            w_approx = np.exp(-approx_norm**2 / (4 * eta**2))\n        elif window_type == 'kaiser_bessel':\n            beta = params['beta']\n            # Avoid division by zero or sqrt of negative if rho > K (though filtered)\n            rho_over_K = approx_norm / K\n            arg = beta * np.sqrt(np.maximum(0, 1 - rho_over_K**2))\n            w_approx = i0(arg) / i0(beta)\n        elif window_type == 'raised_cosine':\n            w_approx = 0.5 * (1 + np.cos(np.pi * approx_norm / K))\n        else:\n            raise ValueError(f\"Unknown window type: {window_type}\")\n\n        # Calculate terms for the approximation sum\n        terms_approx = w_approx / approx_norm2\n        \n        # Compute G_approx(r) for all r in r_grid\n        cos_vals_approx = np.cos(np.outer(approx_mx, r_grid))\n        G_approx = terms_approx @ cos_vals_approx\n        \n        # Calculate the overshoot\n        difference = G_approx - G_ref\n        overshoot = np.max(np.maximum(difference, 0))\n        results.append(overshoot)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}