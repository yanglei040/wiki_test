{
    "hands_on_practices": [
        {
            "introduction": "To begin, we explore the fundamental local property of divergence-conforming basis functions, which is central to the construction of Buffa-Christiansen (BC) functions. This exercise  requires you to apply the surface divergence theorem to a simple two-element patch. By demonstrating analytically that the total divergence of an interior basis function is zero, you will gain a first-principles understanding of how continuity of normal components across element boundaries gives rise to globally well-behaved vector fields.",
            "id": "3290791",
            "problem": "Consider a flat surface patch in the plane $z=0$ composed of two triangles that form the unit square. Let the vertices be $v_{1}=(0,0,0)$, $v_{2}=(1,0,0)$, $v_{3}=(0,1,0)$, and $v_{4}=(1,1,0)$. Define the two oriented triangles $T^{+}=[v_{1},v_{2},v_{3}]$ and $T^{-}=[v_{2},v_{4},v_{3}]$, which share the interior edge $e=[v_{2},v_{3}]$. Let $\\Gamma=T^{+}\\cup T^{-}$ denote the patch, and let $\\partial\\Gamma$ be its outer boundary consisting of the four outer edges $[v_{1},v_{2}]$, $[v_{1},v_{3}]$, $[v_{2},v_{4}]$, and $[v_{4},v_{3}]$.\n\nOn each triangle $T\\in\\{T^{+},T^{-}\\}$, consider the lowest-order Raviart–Thomas space ($\\mathrm{RT}_0$), which consists of vector fields of the form $u(\\boldsymbol{x})=\\boldsymbol{a}+b\\,\\boldsymbol{x}$ with $\\boldsymbol{a}\\in\\mathbb{R}^{2}$ and $b\\in\\mathbb{R}$ when restricted to the plane $z=0$. The Buffa–Christiansen basis function $b_{e}\\in \\mathbf{H}(\\mathrm{div}_{\\Gamma},\\Gamma)$ associated with the interior edge $e$ is assembled by taking $b_{e}|_{T^{+}}\\in \\mathrm{RT}_0(T^{+})$ and $b_{e}|_{T^{-}}\\in \\mathrm{RT}_0(T^{-})$ such that:\n- $b_{e}\\cdot \\boldsymbol{\\nu}=0$ on each of the outer boundary edges of $\\partial\\Gamma$, where $\\boldsymbol{\\nu}$ denotes the unit outward co-normal to $\\partial T^{\\pm}$ within the plane,\n- the normal component across the shared edge $e$ is continuous, and\n- the normalization is chosen so that the edge flux on $T^{+}$ across $e$ equals $\\int_{e} b_{e}\\cdot \\boldsymbol{\\nu}_{e}^{+}\\,\\mathrm{d}\\ell=1$, where $\\boldsymbol{\\nu}_{e}^{+}$ is the unit outward co-normal of $T^{+}$ along $e$.\n\nStarting only from the above definitions and the surface divergence theorem, compute explicitly the value of the integral\n$$\nI \\;=\\; \\int_{\\Gamma} \\mathrm{div}_{\\Gamma}\\, b_{e}\\,\\mathrm{d}S.\n$$\nYour computation must be self-contained and use only the specified geometric data of the patch and the properties listed for $b_{e}$. Express your final answer as a single real number. No units are required.",
            "solution": "The problem is assessed to be valid. It is a well-posed, scientifically grounded question within the domain of numerical analysis for computational electromagnetics. All provided information is consistent and sufficient for deriving a unique solution.\n\nThe objective is to compute the integral $I = \\int_{\\Gamma} \\mathrm{div}_{\\Gamma}\\, b_{e}\\,\\mathrm{d}S$. The domain of integration, $\\Gamma$, is a surface patch composed of two triangles, $\\Gamma = T^{+} \\cup T^{-}$. The vector field $b_e$ is defined piecewise, with its restriction to each triangle, $b_e|_{T^+}$ and $b_e|_{T^-}$, being a smooth function (specifically, a polynomial vector field from the $\\mathrm{RT}_0$ space). Consequently, we can decompose the integral over $\\Gamma$ into a sum of integrals over the two triangles:\n$$\nI = \\int_{T^{+}} \\mathrm{div}_{\\Gamma}\\, (b_e|_{T^{+}})\\,\\mathrm{d}S + \\int_{T^{-}} \\mathrm{div}_{\\Gamma}\\, (b_e|_{T^{-}})\\,\\mathrm{d}S\n$$\nSince the patch $\\Gamma$ is flat and lies in the plane $z=0$, the surface divergence operator, $\\mathrm{div}_{\\Gamma}$, is identical to the standard two-dimensional divergence, which we will denote as $\\mathrm{div}$. Let us denote the restrictions of $b_e$ to the triangles as $b_e^{+} = b_e|_{T^{+}}$ and $b_e^{-} = b_e|_{T^{-}}$. The expression for $I$ becomes:\n$$\nI = \\int_{T^{+}} \\mathrm{div}\\, b_{e}^{+}\\,\\mathrm{d}S + \\int_{T^{-}} \\mathrm{div}\\, b_{e}^{-}\\,\\mathrm{d}S\n$$\nThe problem states that the computation should be based on the surface divergence theorem. We apply this theorem to each integral term separately.\n\nFor the integral over $T^{+}$:\nThe divergence theorem, applied to the triangle $T^{+}$, states that the integral of the divergence of a vector field over the area of the triangle is equal to the flux of the vector field through its boundary, $\\partial T^{+}$:\n$$\n\\int_{T^{+}} \\mathrm{div}\\, b_{e}^{+}\\,\\mathrm{d}S = \\oint_{\\partial T^{+}} b_{e}^{+} \\cdot \\boldsymbol{\\nu}^{+} \\,\\mathrm{d}\\ell\n$$\nwhere $\\boldsymbol{\\nu}^{+}$ is the outward-pointing unit co-normal vector on the boundary $\\partial T^{+}$. The boundary of $T^{+} = [v_1, v_2, v_3]$ consists of three edges: $[v_1, v_2]$, $[v_3, v_1]$, and the shared interior edge $e = [v_2, v_3]$. The edges $[v_1, v_2]$ and $[v_1, v_3]$ (on which $[v_3, v_1]$ lies) are part of the outer boundary $\\partial\\Gamma$.\n\nAccording to Property 2 of $b_e$, the normal component of the vector field is zero on the outer boundary of the patch $\\Gamma$: $b_{e}\\cdot \\boldsymbol{\\nu}=0$ on $\\partial\\Gamma$. This implies that the flux integrals over the portions of $\\partial T^{+}$ that lie on $\\partial\\Gamma$ are zero. Thus, the boundary integral reduces to the integral over only the interior edge $e$:\n$$\n\\oint_{\\partial T^{+}} b_{e}^{+} \\cdot \\boldsymbol{\\nu}^{+} \\,\\mathrm{d}\\ell = \\int_{e} b_{e}^{+} \\cdot \\boldsymbol{\\nu}_{e}^{+} \\,\\mathrm{d}\\ell\n$$\nwhere $\\boldsymbol{\\nu}_{e}^{+}$ is the outward unit co-normal of $T^{+}$ along the edge $e$, consistent with the problem's notation.\n\nProperty 4 provides the normalization condition for $b_e$, which is precisely the value of this integral:\n$$\n\\int_{e} b_{e}\\cdot \\boldsymbol{\\nu}_{e}^{+}\\,\\mathrm{d}\\ell = 1\n$$\nTherefore, the first term in our expression for $I$ is:\n$$\n\\int_{T^{+}} \\mathrm{div}\\, b_{e}^{+}\\,\\mathrm{d}S = 1\n$$\n\nFor the integral over $T^{-}$:\nSimilarly, we apply the divergence theorem to the triangle $T^{-}$:\n$$\n\\int_{T^{-}} \\mathrm{div}\\, b_{e}^{-}\\,\\mathrm{d}S = \\oint_{\\partial T^{-}} b_{e}^{-} \\cdot \\boldsymbol{\\nu}^{-} \\,\\mathrm{d}\\ell\n$$\nwhere $\\boldsymbol{\\nu}^{-}$ is the outward-pointing unit co-normal on the boundary $\\partial T^{-}$. The boundary of $T^{-} = [v_2, v_4, v_3]$ consists of the outer edges $[v_2, v_4]$ and $[v_4, v_3]$, and the interior edge $[v_3, v_2]$ (which corresponds to $-e$). Again, Property 2 ensures that the flux through the outer edges is zero. The boundary integral reduces to the integral over the shared edge $e$:\n$$\n\\oint_{\\partial T^{-}} b_{e}^{-} \\cdot \\boldsymbol{\\nu}^{-} \\,\\mathrm{d}\\ell = \\int_{e} b_{e}^{-} \\cdot \\boldsymbol{\\nu}_{e}^{-} \\,\\mathrm{d}\\ell\n$$\nwhere $\\boldsymbol{\\nu}_{e}^{-}$ is the outward unit co-normal of $T^{-}$ along the edge $e$.\n\nNow, we must use Property 3, which states that the normal component of $b_e$ across the shared edge $e$ is continuous. For a vector field in the space $\\mathbf{H}(\\mathrm{div}_{\\Gamma},\\Gamma)$, the continuity of the normal component across an interior interface $e$ between two elements $T^{+}$ and $T^{-}$ is expressed as:\n$$\n(b_e|_{T^{+}}) \\cdot \\boldsymbol{\\nu}_{e}^{+} + (b_e|_{T^{-}}) \\cdot \\boldsymbol{\\nu}_{e}^{-} = 0 \\quad \\text{for all points on } e\n$$\nThis condition ensures that the flux leaving $T^{+}$ across $e$ is equal to the flux entering $T^{-}$ across $e$. From this relation, we have:\n$$\nb_{e}^{-} \\cdot \\boldsymbol{\\nu}_{e}^{-} = -b_{e}^{+} \\cdot \\boldsymbol{\\nu}_{e}^{+} \\quad \\text{on } e\n$$\nSubstituting this into the integral for the second term, we find:\n$$\n\\int_{e} b_{e}^{-} \\cdot \\boldsymbol{\\nu}_{e}^{-} \\,\\mathrm{d}\\ell = \\int_{e} (-b_{e}^{+} \\cdot \\boldsymbol{\\nu}_{e}^{+}) \\,\\mathrm{d}\\ell = - \\int_{e} b_{e}^{+} \\cdot \\boldsymbol{\\nu}_{e}^{+} \\,\\mathrm{d}\\ell\n$$\nUsing Property 4 again, $\\int_{e} b_{e}^{+} \\cdot \\boldsymbol{\\nu}_{e}^{+} \\,\\mathrm{d}\\ell = 1$, we get:\n$$\n\\int_{T^{-}} \\mathrm{div}\\, b_{e}^{-}\\,\\mathrm{d}S = -1\n$$\n\nFinally, we sum the results for the two triangles to find the total integral $I$:\n$$\nI = \\left(\\int_{T^{+}} \\mathrm{div}\\, b_{e}^{+}\\,\\mathrm{d}S\\right) + \\left(\\int_{T^{-}} \\mathrm{div}\\, b_{e}^{-}\\,\\mathrm{d}S\\right) = 1 + (-1) = 0\n$$\nThe value of the integral is $0$. This result reflects a fundamental property of divergence-conforming basis functions like the Buffa-Christiansen functions: the total divergence over the support of an interior basis function is zero.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "Having established the local structure of divergence-conforming functions, we now turn to their most celebrated application: stabilizing integral equations at low frequencies. The standard Electric Field Integral Equation (EFIE) suffers from a low-frequency breakdown, where the discrete operator becomes severely ill-conditioned as the wavenumber $k$ approaches zero. This hands-on coding practice  uses a simplified block-operator model to let you numerically verify that the RWG-BC pairing cures this breakdown, yielding a condition number that remains bounded as $k \\to 0$, in stark contrast to the unstable Galerkin RWG-RWG scheme.",
            "id": "3290751",
            "problem": "Consider the Electric Field Integral Equation (EFIE) for a perfectly electrically conducting scatterer in the frequency domain. Let the time-harmonic wavenumber be $k$ (in $\\mathrm{m}^{-1}$). The EFIE maps a surface current density $\\mathbf{J}$ on a Lipschitz surface $\\Gamma$ to the tangential trace of the total electric field $\\mathbf{E}_t$ via boundary integral operators built from the vector and scalar potentials. It is well known that the Helmholtz decomposition splits $\\mathbf{J}$ into a surface-solenoidal part (divergence-free on $\\Gamma$) and a surface-irrotational part (nonzero surface divergence), and that, as $k \\to 0$, the vector-potential contribution that acts on the solenoidal part scales proportionally to $k$, whereas the scalar-potential contribution that acts on the irrotational part scales proportionally to $1/k$ when measured in compatible norms. When discretized with Rao–Wilton–Glisson (RWG) trial functions and Buffa–Christiansen (BC) test functions, the discrete operator can be represented, in a basis adapted to the Helmholtz splitting, by a block structure in which the off-diagonal couplings vanish as $k \\to 0$, while the diagonal blocks are balanced in norm. In contrast, a Galerkin pairing with RWG test functions induces a norm mismatch that yields persistent off-diagonal couplings that do not vanish as $k \\to 0$.\n\nStarting from the above fundamental facts and the Helmholtz decomposition, construct a self-contained block-operator model for the low-frequency behavior of the discrete EFIE that captures the $k$-scaling of the solenoidal and irrotational subspaces and the effect of the test space choice. Your model should be purely algebraic and defined as follows:\n\n- Let $n_s \\in \\mathbb{N}$ and $n_n \\in \\mathbb{N}$ denote the dimensions of the discrete solenoidal and irrotational subspaces, respectively. Let $A \\in \\mathbb{R}^{n_s \\times n_s}$ and $D \\in \\mathbb{R}^{n_n \\times n_n}$ be symmetric positive definite matrices that model, respectively, the discrete restrictions of the EFIE to the solenoidal and irrotational subspaces at $k$-independent reference scale. Let $B_0 \\in \\mathbb{R}^{n_s \\times n_n}$ and $B_1 \\in \\mathbb{R}^{n_s \\times n_n}$ be real coupling matrices.\n- Define two $k$-dependent discrete operators that model the two testings:\n  - RWG–RWG Galerkin model:\n    $$Z_{\\mathrm{RR}}(k) \\;=\\; \\begin{bmatrix} k A & B_0 \\\\ B_0^{\\mathsf{T}} & \\dfrac{1}{k} D \\end{bmatrix}.$$\n  - RWG–BC Petrov–Galerkin model:\n    $$Z_{\\mathrm{RB}}(k) \\;=\\; \\begin{bmatrix} A & k B_1 \\\\ k B_1^{\\mathsf{T}} & D \\end{bmatrix}.$$\n- For each operator, define the spectral condition number\n  $$\\kappa\\!\\left(Z(k)\\right) \\;=\\; \\dfrac{\\sigma_{\\max}\\!\\left(Z(k)\\right)}{\\sigma_{\\min}\\!\\left(Z(k)\\right)},$$\n  where $\\sigma_{\\max}$ and $\\sigma_{\\min}$ denote the largest and smallest singular values.\n\nYour task is to quantify the asymptotic scaling of $\\kappa\\!\\left(Z_{\\mathrm{RR}}(k)\\right)$ and $\\kappa\\!\\left(Z_{\\mathrm{RB}}(k)\\right)$ as $k \\to 0$ by computing the slope $\\alpha$ in the log–log relationship\n$$\\log \\kappa\\!\\left(Z(k)\\right) \\;\\approx\\; \\alpha \\, \\log k \\;+\\; \\beta,$$\nestimated by least-squares regression over a prescribed set of wavenumbers. The slope $\\alpha$ is dimensionless and must be reported as a real number.\n\nImplementation requirements:\n\n- Construct $A$ and $D$ as symmetric positive definite matrices by forming $M^{\\mathsf{T}} M$ from real Gaussian matrices and adding a positive diagonal shift. Ensure that $B_0$ has spectral norm strictly smaller than $\\sqrt{\\lambda_{\\min}(A)\\,\\lambda_{\\min}(D)}$ so that $Z_{\\mathrm{RR}}(k)$ remains positive definite for the $k$ in the test suite. Use independently seeded pseudo-random number generators to make all constructions deterministic.\n- For each test case, evaluate $\\kappa\\!\\left(Z_{\\mathrm{RR}}(k)\\right)$ and $\\kappa\\!\\left(Z_{\\mathrm{RB}}(k)\\right)$ for the wavenumber set $k \\in \\{10^{-1},5 \\cdot 10^{-2},2 \\cdot 10^{-2},10^{-2},5 \\cdot 10^{-3},2 \\cdot 10^{-3},10^{-3}\\}$ (in $\\mathrm{m}^{-1}$). Then compute the least-squares slope $\\alpha$ for each operator using $(x_i,y_i)=(\\log k_i,\\log \\kappa(Z(k_i)))$.\n- The final outputs for each test case are the two slopes $\\alpha_{\\mathrm{RB}}$ and $\\alpha_{\\mathrm{RR}}$ as real numbers. No physical units are required for these outputs.\n\nTest suite specification:\n\n- Test case $1$ (balanced dimensions, general case):\n  - Dimensions: $n_s = 3$, $n_n = 3$.\n  - Random seeds and shifts: build $A$ with seed $12345$ and shift $2$, build $D$ with seed $23456$ and shift $2$.\n  - Couplings:\n    - $B_0$ from seed $34567$, scale it to spectral norm $0.3 \\cdot \\sqrt{\\lambda_{\\min}(A)\\,\\lambda_{\\min}(D)}$.\n    - $B_1$ from seed $45678$, scale it to spectral norm $1$.\n- Test case $2$ (boundary scalar case, near-critical coupling):\n  - Dimensions: $n_s = 1$, $n_n = 1$.\n  - Scalars: $A = [2]$, $D = [3]$, $B_0 = [0.6 \\sqrt{2 \\cdot 3}]$.\n  - $B_1$ from seed $98765$, scale it to spectral norm $1$.\n- Test case $3$ (dimension imbalance):\n  - Dimensions: $n_s = 4$, $n_n = 2$.\n  - Random seeds and shifts: build $A$ with seed $111$ and shift $1$, build $D$ with seed $222$ and shift $1.5$.\n  - Couplings:\n    - $B_0$ from seed $333$, scale it to spectral norm $0.25 \\cdot \\sqrt{\\lambda_{\\min}(A)\\,\\lambda_{\\min}(D)}$.\n    - $B_1$ from seed $444$, scale it to spectral norm $1$.\n\nAngle units are not involved. All outputs are unitless real numbers.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$[\\alpha_{\\mathrm{RB}}^{(1)}, \\alpha_{\\mathrm{RR}}^{(1)}, \\alpha_{\\mathrm{RB}}^{(2)}, \\alpha_{\\mathrm{RR}}^{(2)}, \\alpha_{\\mathrm{RB}}^{(3)}, \\alpha_{\\mathrm{RR}}^{(3)}].$$",
            "solution": "The problem requires an analysis of the low-frequency behavior of two different numerical discretizations of the Electric Field Integral Equation (EFIE). The analysis is performed through simplified algebraic block-operator models that capture the essential frequency-dependent scaling properties of the underlying physics and numerical methods.\n\nThe EFIE governs the surface current density $\\mathbf{J}$ on a perfect electrical conductor. The Helmholtz decomposition provides a crucial theoretical tool, splitting the current $\\mathbf{J}$ into a surface-solenoidal (divergence-free) component and a surface-irrotational (curl-free) component. In the low-frequency limit, where the wavenumber $k \\to 0$, the integral operators of the EFIE exhibit distinct scaling behaviors when acting on these components. The vector potential operator, acting on the solenoidal subspace, scales proportionally to $k$. The scalar potential operator, acting on the irrotational subspace, scales proportionally to $1/k$. This disparity in scaling is the root of numerical instabilities at low frequencies, a phenomenon known as the \"low-frequency breakdown.\"\n\nThe choice of testing functions in the Method of Moments discretization significantly impacts the stability of the resulting linear system. The problem presents two models corresponding to two common choices:\n\n1.  **RWG–RWG (Galerkin) Model**: Both trial and test functions are the Rao–Wilton–Glisson (RWG) basis functions. The resulting discrete operator is modeled as:\n    $$Z_{\\mathrm{RR}}(k) = \\begin{bmatrix} k A & B_0 \\\\ B_0^{\\mathsf{T}} & \\dfrac{1}{k} D \\end{bmatrix}$$\n    Here, $A \\in \\mathbb{R}^{n_s \\times n_s}$ and $D \\in \\mathbb{R}^{n_n \\times n_n}$ are symmetric positive definite (SPD) matrices representing the discretized operators on the solenoidal and irrotational subspaces, respectively, at a reference scale. $B_0 \\in \\mathbb{R}^{n_s \\times n_n}$ represents a frequency-independent coupling between the subspaces. The scaling mismatch is explicit: the $(1,1)$ block vanishes as $k \\to 0$, while the $(2,2)$ block diverges.\n\n2.  **RWG–BC (Petrov–Galerkin) Model**: The trial functions are RWG, but the test functions are Buffa–Christiansen (BC) basis functions. The BC basis is specifically designed to correct the low-frequency breakdown by incorporating a frequency scaling within the definition of its irrotational basis functions. This pre-scaling effectively cancels the $1/k$ singularity of the scalar potential operator. The resulting discrete operator model is:\n    $$Z_{\\mathrm{RB}}(k) = \\begin{bmatrix} A & k B_1 \\\\ k B_1^{\\mathsf{T}} & D \\end{bmatrix}$$\n    In this model, the diagonal blocks $A$ and $D$ are well-scaled and independent of $k$. The off-diagonal coupling, represented by $k B_1$, vanishes as $k \\to 0$, leading to a block-diagonal system in the limit.\n\nThe objective is to quantify the stability of these two models by analyzing the asymptotic scaling of their spectral condition numbers, $\\kappa(Z(k)) = \\sigma_{\\max}(Z(k)) / \\sigma_{\\min}(Z(k))$, as $k \\to 0$. This is achieved by computing the slope $\\alpha$ of a linear fit to the data $(\\log k, \\log \\kappa(Z(k)))$.\n\n**Asymptotic Analysis of Condition Numbers**\n\nLet us analyze the behavior of $\\kappa(Z(k))$ for each model in the limit $k \\to 0$.\n\nFor the **RWG–BC model**, the matrix is $Z_{\\mathrm{RB}}(k) = \\begin{bmatrix} A & k B_1 \\\\ k B_1^{\\mathsf{T}} & D \\end{bmatrix}$. As $k \\to 0$, this matrix converges to a block-diagonal matrix:\n$$ \\lim_{k\\to 0} Z_{\\mathrm{RB}}(k) = Z_{\\mathrm{RB}}(0) = \\begin{bmatrix} A & 0 \\\\ 0 & D \\end{bmatrix} $$\nSince $A$ and $D$ are SPD, the singular values of $Z_{\\mathrm{RB}}(0)$ are the union of the eigenvalues of $A$ and $D$. The condition number is therefore:\n$$ \\kappa(Z_{\\mathrm{RB}}(0)) = \\frac{\\max(\\lambda_{\\max}(A), \\lambda_{\\max}(D))}{\\min(\\lambda_{\\min}(A), \\lambda_{\\min}(D))} $$\nThis is a finite, positive constant, independent of $k$. For small $k$, $\\kappa(Z_{\\mathrm{RB}}(k))$ will be close to this constant. Consequently, the plot of $\\log \\kappa(Z_{\\mathrm{RB}}(k))$ versus $\\log k$ is expected to be nearly horizontal. The slope $\\alpha_{\\mathrm{RB}}$ should be close to $0$. This indicates that the RWG–BC scheme is well-conditioned at low frequencies.\n\nFor the **RWG–RWG model**, the matrix is $Z_{\\mathrm{RR}}(k) = \\begin{bmatrix} k A & B_0 \\\\ B_0^{\\mathsf{T}} & \\frac{1}{k} D \\end{bmatrix}$. The problem specifies that $A$ and $D$ are SPD and that $\\|B_0\\|_2  \\sqrt{\\lambda_{\\min}(A)\\lambda_{\\min}(D)}$, which ensures $Z_{\\mathrm{RR}}(k)$ is positive definite for $k > 0$. The scaling of the eigenvalues (which are the singular values for an SPD matrix) can be estimated. The eigenvalues of the diagonal blocks scale as $O(k)$ and $O(1/k)$.\nThe largest singular value will be dominated by the diverging block:\n$$ \\sigma_{\\max}(Z_{\\mathrm{RR}}(k)) \\approx \\sigma_{\\max}\\left(\\frac{1}{k} D\\right) = \\frac{1}{k} \\lambda_{\\max}(D) \\propto k^{-1} $$\nThe smallest singular value can be estimated using the properties of Schur complements. For an SPD block matrix, the smallest eigenvalue is bounded by the smallest eigenvalues of its diagonal blocks. Heuristically, it is related to the smallest eigenvalue of the $kA$ block, which scales as:\n$$ \\sigma_{\\min}(Z_{\\mathrm{RR}}(k)) \\approx k \\lambda_{\\min}(A, B_0, D) \\propto k^{1} $$\nwhere the term $\\lambda_{\\min}(A, B_0, D)$ is a constant depending on the matrices.\nCombining these scalings, the condition number behaves as:\n$$ \\kappa(Z_{\\mathrm{RR}}(k)) = \\frac{\\sigma_{\\max}(Z_{\\mathrm{RR}}(k))}{\\sigma_{\\min}(Z_{\\mathrm{RR}}(k))} \\propto \\frac{k^{-1}}{k^1} = k^{-2} $$\nTaking the logarithm gives $\\log \\kappa(Z_{\\mathrm{RR}}(k)) \\approx C - 2 \\log k$ for some constant $C$. The slope $\\alpha_{\\mathrm{RR}}$ of the log-log plot is therefore expected to be $-2$. This confirms the severe ill-conditioning of the Galerkin scheme at low frequencies.\n\n**Numerical Procedure**\n\nThe implementation will follow these steps for each test case:\n1.  Construct the matrices $A$, $D$, $B_0$, and $B_1$ of specified dimensions using the provided random seeds and parameter values. For $A$ and $D$, a matrix $M$ is generated from a Gaussian distribution using a seeded pseudo-random number generator, and the final SPD matrix is formed as $M^{\\mathsf{T}}M + \\delta I$, where $\\delta$ is the given diagonal shift. The coupling matrices $B_0$ and $B_1$ are also generated from a seeded generator and then scaled to have a specific spectral norm.\n2.  Define the set of wavenumbers $k_i = \\{10^{-1}, 5 \\cdot 10^{-2}, \\dots, 10^{-3}\\}$.\n3.  For each $k_i$ in the set:\n    a. Assemble the matrices $Z_{\\mathrm{RB}}(k_i)$ and $Z_{\\mathrm{RR}}(k_i)$.\n    b. Compute their singular values using a standard numerical library routine. The largest and smallest singular values, $\\sigma_{\\max}$ and $\\sigma_{\\min}$, are extracted.\n    c. Calculate the condition number $\\kappa(Z(k_i)) = \\sigma_{\\max}/\\sigma_{\\min}$.\n4.  After computing the condition numbers for all $k_i$, create two sets of data points: $(\\log k_i, \\log \\kappa(Z_{\\mathrm{RB}}(k_i)))$ and $(\\log k_i, \\log \\kappa(Z_{\\mathrm{RR}}(k_i)))$.\n5.  Perform a linear least-squares regression on each data set to find the slope $\\alpha$. For a set of points $(x_i, y_i)$, the slope is calculated as:\n    $$ \\alpha = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{N} (x_i - \\bar{x})^2} $$\n    where $\\bar{x}$ and $\\bar{y}$ are the means of the $x_i$ and $y_i$ values, respectively.\n6.  The resulting slopes, $\\alpha_{\\mathrm{RB}}$ and $\\alpha_{\\mathrm{RR}}$, are reported for each test case.\n\nThis procedure will numerically verify the theoretical predictions that $\\alpha_{\\mathrm{RB}} \\approx 0$ and $\\alpha_{\\mathrm{RR}} \\approx -2$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_spd_matrix(dim, seed, shift):\n    \"\"\"\n    Constructs a symmetric positive definite matrix.\n    Generated as M.T @ M + shift * I, where M is from a Gaussian distribution.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    M = rng.standard_normal((dim, dim))\n    A = M.T @ M + shift * np.identity(dim)\n    return A\n\ndef get_spectral_norm(matrix):\n    \"\"\"Computes the spectral norm (largest singular value) of a matrix.\"\"\"\n    # For scalar matrices, svd returns a scalar, need to handle this\n    if matrix.size == 1:\n        return np.abs(matrix.item())\n    return np.linalg.svd(matrix, compute_uv=False)[0]\n\ndef scale_matrix_norm(matrix, target_norm):\n    \"\"\"Scales a matrix to have a specific spectral norm.\"\"\"\n    current_norm = get_spectral_norm(matrix)\n    if np.isclose(current_norm, 0):\n        return matrix # Cannot scale a zero matrix\n    return matrix * (target_norm / current_norm)\n\ndef compute_slope(k_values, kappa_values):\n    \"\"\"\n    Computes the slope of the log-log plot using least-squares regression.\n    \"\"\"\n    x = np.log(k_values)\n    y = np.log(kappa_values)\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    \n    numerator = np.sum((x - x_mean) * (y - y_mean))\n    denominator = np.sum((x - x_mean)**2)\n    \n    if np.isclose(denominator, 0):\n        return 0.0\n        \n    return numerator / denominator\n\ndef analyze_case(params):\n    \"\"\"\n    Analyzes a single test case for both Z_RR and Z_RB models.\n    \"\"\"\n    # Unpack parameters\n    ns, nn = params[\"dims\"]\n    A_params, D_params = params[\"spd_params\"]\n    B0_params, B1_params = params[\"coupling_params\"]\n\n    # --- Matrix Construction ---\n    if A_params[\"type\"] == \"scalar\":\n        A = np.array([[A_params[\"value\"]]])\n    else:\n        A = build_spd_matrix(ns, A_params[\"seed\"], A_params[\"shift\"])\n\n    if D_params[\"type\"] == \"scalar\":\n        D = np.array([[D_params[\"value\"]]])\n    else:\n        D = build_spd_matrix(nn, D_params[\"seed\"], D_params[\"shift\"])\n\n    # --- Coupling Matrix B0 ---\n    rng_b0 = np.random.default_rng(B0_params[\"seed\"])\n    if B0_params[\"type\"] == \"scalar\":\n        B0 = np.array([[B0_params[\"value\"]]])\n    else:\n        B0_raw = rng_b0.standard_normal((ns, nn))\n        lambda_min_A = np.min(np.linalg.eigvalsh(A))\n        lambda_min_D = np.min(np.linalg.eigvalsh(D))\n        target_norm_B0 = B0_params[\"scale_factor\"] * np.sqrt(lambda_min_A * lambda_min_D)\n        B0 = scale_matrix_norm(B0_raw, target_norm_B0)\n\n    # --- Coupling Matrix B1 ---\n    rng_b1 = np.random.default_rng(B1_params[\"seed\"])\n    B1_raw = rng_b1.standard_normal((ns, nn))\n    B1 = scale_matrix_norm(B1_raw, B1_params[\"norm\"])\n    \n    # --- Wavenumbers ---\n    k_values = np.array([1e-1, 5e-2, 2e-2, 1e-2, 5e-3, 2e-3, 1e-3])\n\n    kappa_rr_values = []\n    kappa_rb_values = []\n\n    for k in k_values:\n        # Assemble Z_RR(k)\n        Z_rr = np.block([\n            [k * A, B0],\n            [B0.T, (1/k) * D]\n        ])\n        \n        # Assemble Z_RB(k)\n        Z_rb = np.block([\n            [A, k * B1],\n            [k * B1.T, D]\n        ])\n        \n        # Compute condition numbers\n        s_rr = np.linalg.svd(Z_rr, compute_uv=False)\n        kappa_rr = s_rr[0] / s_rr[-1]\n        kappa_rr_values.append(kappa_rr)\n        \n        s_rb = np.linalg.svd(Z_rb, compute_uv=False)\n        kappa_rb = s_rb[0] / s_rb[-1]\n        kappa_rb_values.append(kappa_rb)\n\n    # Compute slopes\n    alpha_rr = compute_slope(k_values, np.array(kappa_rr_values))\n    alpha_rb = compute_slope(k_values, np.array(kappa_rb_values))\n    \n    return alpha_rb, alpha_rr\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run analysis, and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {\n            \"dims\": (3, 3),\n            \"spd_params\": (\n                {\"type\": \"generated\", \"seed\": 12345, \"shift\": 2},\n                {\"type\": \"generated\", \"seed\": 23456, \"shift\": 2}\n            ),\n            \"coupling_params\": (\n                {\"type\": \"generated\", \"seed\": 34567, \"scale_factor\": 0.3},\n                {\"seed\": 45678, \"norm\": 1.0}\n            )\n        },\n        # Test case 2\n        {\n            \"dims\": (1, 1),\n            \"spd_params\": (\n                {\"type\": \"scalar\", \"value\": 2.0},\n                {\"type\": \"scalar\", \"value\": 3.0}\n            ),\n            \"coupling_params\": (\n                {\"type\": \"scalar\", \"seed\": 0, \"value\": 0.6 * np.sqrt(2.0 * 3.0)}, # seed unused for scalar\n                {\"seed\": 98765, \"norm\": 1.0}\n            )\n        },\n        # Test case 3\n        {\n            \"dims\": (4, 2),\n            \"spd_params\": (\n                {\"type\": \"generated\", \"seed\": 111, \"shift\": 1.0},\n                {\"type\": \"generated\", \"seed\": 222, \"shift\": 1.5}\n            ),\n            \"coupling_params\": (\n                {\"type\": \"generated\", \"seed\": 333, \"scale_factor\": 0.25},\n                {\"seed\": 444, \"norm\": 1.0}\n            )\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha_rb, alpha_rr = analyze_case(case)\n        results.extend([alpha_rb, alpha_rr])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond ensuring numerical stability, the Buffa-Christiansen basis functions, when paired with RWG functions, form a discrete framework that remarkably mirrors the deep structures of algebraic topology. This connection ensures that the discretization respects the fundamental physical and geometric invariants of the problem. In this final practice , you will implement a topological test, using the discrete operators of the RWG-BC system to compute the Betti numbers of different surfaces, thereby validating that the null-spaces of these operators correctly encode the topology of the domain.",
            "id": "3290798",
            "problem": "Consider a closed, orientable, triangulated surface represented as a simplicial complex with a set of vertices, edges, and triangular faces. Let the counts of vertices, edges, and faces be $n_V$, $n_E$, and $n_F$, respectively. Define the boundary operators of the simplicial chain complex as the matrices $\\partial_1 \\in \\mathbb{R}^{n_V \\times n_E}$ and $\\partial_2 \\in \\mathbb{R}^{n_E \\times n_F}$, built from oriented incidences, satisfying $\\partial_1 \\partial_2 = 0$. In the discrete de Rham framework for computational electromagnetics, with Rao–Wilton–Glisson (RWG) edge basis functions and Buffa–Christiansen (BC) dual basis functions, the discrete gradient and curl operators correspond, up to transposes and appropriate mass pairings, to the coboundary operators $\\delta_0 = \\partial_1^\\top$ and $\\delta_1 = \\partial_2^\\top$. The harmonic subspace of $1$-forms is the intersection $\\ker(\\delta_0) \\cap \\ker(\\delta_1)$ and, for closed orientable surfaces, its dimension equals the first Betti number $b_1$.\n\nStarting from the foundational concepts of simplicial homology, the Hodge decomposition, and the discrete de Rham sequence, devise a topological test to recover the Betti numbers $b_0$, $b_1$, and $b_2$ from ranks and nullspaces of operators assembled with RWG–BC, and validate the recovery on surfaces with varying genus. Specifically:\n\n1. Construct the oriented incidence matrices $\\partial_1$ and $\\partial_2$ from the triangulations.\n2. Compute the Betti numbers using the rank formulas\n   $$\n   b_0 = n_V - \\operatorname{rank}(\\partial_1),\\quad\n   b_1 = n_E - \\operatorname{rank}(\\partial_1) - \\operatorname{rank}(\\partial_2),\\quad\n   b_2 = n_F - \\operatorname{rank}(\\partial_2).\n   $$\n3. Assemble the combinatorial $1$-Hodge Laplacian\n   $$\n   L_1 = \\partial_1^\\top \\partial_1 + \\partial_2 \\partial_2^\\top,\n   $$\n   which is equivalent to a RWG–BC weighted Laplacian up to symmetric positive definite inner-product choices, and extract the harmonic dimension as\n   $$\n   h_{\\mathrm{lap}} = \\dim \\ker(L_1).\n   $$\n4. Independently compute the harmonic dimension via the intersection of RWG divergence-null and BC curl-null subspaces:\n   $$\n   h_{\\mathrm{int}} = \\dim\\left(\\ker(\\partial_1) \\cap \\ker(\\partial_2^\\top)\\right) = n_E - \\operatorname{rank}\\left(\\begin{bmatrix}\\partial_1 \\\\ \\partial_2^\\top\\end{bmatrix}\\right).\n   $$\n5. Validate that $h_{\\mathrm{lap}} = b_1$ and $h_{\\mathrm{int}} = b_1$ for each test case.\n\nYour program must implement the above on the following triangulated surfaces:\n\n- Test case A (happy path): an octahedron triangulation of the sphere (genus $0$), with $n_V = 6$, $n_E = 12$, $n_F = 8$ constructed from oriented faces.\n- Test case B (different genus): a torus (genus $1$) obtained from an $N \\times N$ periodic grid with $N = 3$, triangulated by splitting each periodic cell into two oriented triangles.\n- Test case C (edge case): a disconnected surface formed by the disjoint union of Test case A and Test case B.\n\nFor each test case, your program must output a list containing the five items $[b_0, b_1, b_2, h_{\\mathrm{int}}, h_{\\mathrm{lap}}]$ followed by two boolean validations $[\\text{passed}_{\\mathrm{int}}, \\text{passed}_{\\mathrm{lap}}]$, where $\\text{passed}_{\\mathrm{int}}$ is true if $h_{\\mathrm{int}} = b_1$ and $\\text{passed}_{\\mathrm{lap}}$ is true if $h_{\\mathrm{lap}} = b_1$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[ [b_0,b_1,b_2,h_{\\mathrm{int}},h_{\\mathrm{lap}},\\text{passed}_{\\mathrm{int}},\\text{passed}_{\\mathrm{lap}}], [\\dots], [\\dots] ]$). No physical units or angles are involved in this problem. All computations must be performed over $\\mathbb{R}$ using singular value decomposition to determine ranks and nullities with a numerically stable tolerance.",
            "solution": "We begin with the simplicial chain complex of a triangulated closed orientable surface,\n$$\nC_2 \\xrightarrow{\\partial_2} C_1 \\xrightarrow{\\partial_1} C_0,\n$$\nwhere $C_k$ are the $k$-chains, and $\\partial_k$ are boundary operators satisfying $\\partial_1 \\partial_2 = 0$. The corresponding cochain complex has coboundary operators $\\delta_k = \\partial_{k+1}^\\top$. In the discrete de Rham sequence used in computational electromagnetics, Rao–Wilton–Glisson (RWG) edge basis functions represent discrete $1$-forms on the primal mesh, while Buffa–Christiansen (BC) dual edge basis functions represent discrete $1$-forms on the dual mesh. The discrete gradient and curl acting on primal $1$-forms are represented, up to inner products, by $\\delta_0 = \\partial_1^\\top$ and $\\delta_1 = \\partial_2^\\top$, respectively.\n\nThe Betti numbers $b_k$ are defined as the dimensions of the homology groups $H_k = \\ker(\\partial_k)/\\operatorname{im}(\\partial_{k+1})$. Over $\\mathbb{R}$, these are computable from ranks:\n$$\nb_0 = n_V - \\operatorname{rank}(\\partial_1),\\quad\nb_1 = n_E - \\operatorname{rank}(\\partial_1) - \\operatorname{rank}(\\partial_2),\\quad\nb_2 = n_F - \\operatorname{rank}(\\partial_2).\n$$\nThese identities follow from exactness of dimensions in the chain complex and the rank–nullity theorem:\n$\\dim \\ker(\\partial_k) = n_{C_k} - \\operatorname{rank}(\\partial_k)$ and $\\dim \\operatorname{im}(\\partial_{k+1}) = \\operatorname{rank}(\\partial_{k+1})$.\n\nTo connect with Buffa–Christiansen stabilization, consider the $1$-Hodge Laplacian on primal $1$-cochains,\n$$\nL_1 = \\delta_0 \\delta_0^\\top + \\delta_1^\\top \\delta_1 = \\partial_1^\\top \\partial_1 + \\partial_2 \\partial_2^\\top.\n$$\nIn continuous theory, the kernel of $L_1$ is the space of harmonic $1$-forms, whose dimension equals $b_1$. In discrete settings, weighting by symmetric positive definite (SPD) mass matrices (as arises with RWG–BC pairings) modifies $L_1$ to $L_1^{\\mathrm{SPD}} = \\partial_1^\\top W_0 \\partial_1 + \\partial_2 W_2 \\partial_2^\\top$ for SPD $W_0$ and $W_2$. The kernel condition $L_1^{\\mathrm{SPD}} x = 0$ implies $\\partial_1 x = 0$ and $\\partial_2^\\top x = 0$, hence the kernel is the intersection $\\ker(\\partial_1) \\cap \\ker(\\partial_2^\\top)$, and its dimension is a topological invariant equal to $b_1$. Therefore, any SPD choice (including the combinatorial choice $W_0 = I$ and $W_2 = I$) yields the same kernel dimension.\n\nAlgorithmic steps:\n\n1. Build oriented incidence matrices:\n   - For $\\partial_2 \\in \\mathbb{R}^{n_E \\times n_F}$, each face contributes three oriented edges with signs $\\pm 1$. Each column of $\\partial_2$ encodes the oriented boundary of that triangular face.\n   - For $\\partial_1 \\in \\mathbb{R}^{n_V \\times n_E}$, each oriented edge $(u \\to v)$ contributes $-1$ at row $u$, $+1$ at row $v$ in the corresponding column.\n\n2. Compute ranks using singular value decomposition (SVD). Given a matrix $A$ with singular values $\\sigma_i$, define a tolerance $\\tau = \\max(n_{\\text{rows}}, n_{\\text{cols}}) \\cdot \\sigma_{\\max} \\cdot \\epsilon$, with machine epsilon $\\epsilon$, and count singular values greater than $\\tau$ to obtain $\\operatorname{rank}(A)$.\n\n3. Recover Betti numbers:\n   $$\n   b_0 = n_V - \\operatorname{rank}(\\partial_1),\\quad\n   b_1 = n_E - \\operatorname{rank}(\\partial_1) - \\operatorname{rank}(\\partial_2),\\quad\n   b_2 = n_F - \\operatorname{rank}(\\partial_2).\n   $$\n\n4. Compute harmonic dimensions by two routes:\n   - Intersection route (RWG–BC nullspaces): stack the operators vertically, $S = \\begin{bmatrix}\\partial_1 \\\\ \\partial_2^\\top\\end{bmatrix}$, then\n     $$\n     h_{\\mathrm{int}} = n_E - \\operatorname{rank}(S).\n     $$\n     This follows since $\\ker(S) = \\ker(\\partial_1) \\cap \\ker(\\partial_2^\\top)$.\n   - Laplacian route: form $L_1 = \\partial_1^\\top \\partial_1 + \\partial_2 \\partial_2^\\top$ and compute\n     $$\n     h_{\\mathrm{lap}} = \\dim \\ker(L_1),\n     $$\n     via SVD as the count of singular values less than a tolerance.\n\n5. Validate that $h_{\\mathrm{int}} = b_1$ and $h_{\\mathrm{lap}} = b_1$ for each test case.\n\nConstruction of test triangulations:\n\n- Test case A (sphere, genus $0$): Use an octahedron triangulation with $n_V = 6$ vertices, $n_E = 12$ edges, $n_F = 8$ faces. Orient the top faces $(v_5, v_i, v_{i+1})$ for $i \\in \\{0,1,2,3\\}$ and the bottom faces $(v_4, v_{i+1}, v_i)$ for consistent global orientation.\n\n- Test case B (torus, genus $1$): Use a periodic $N \\times N$ grid with $N = 3$ and two oriented triangles per periodic cell:\n  $$\n  (i,j),\\ (i+1,j),\\ (i+1,j+1)\n  \\quad\\text{and}\\quad\n  (i,j),\\ (i+1,j+1),\\ (i,j+1),\n  $$\n  with indices modulo $N$ to enforce periodicity. This yields a closed orientable triangulated torus.\n\n- Test case C (disconnected union): Form the disjoint union of Test case A and Test case B by offsetting vertex indices of one complex and concatenating face lists. The boundary operators become block-diagonal, and Betti numbers add: $b_k^{\\text{union}} = b_k^{(A)} + b_k^{(B)}$.\n\nExpected topological invariants:\n- Sphere: $b_0 = 1$, $b_1 = 0$, $b_2 = 1$.\n- Torus: $b_0 = 1$, $b_1 = 2$, $b_2 = 1$.\n- Disjoint union (sphere $\\sqcup$ torus): $b_0 = 2$, $b_1 = 2$, $b_2 = 2$.\n\nThe program implements the above constructions, computes $\\partial_1$, $\\partial_2$, ranks, Betti numbers, $h_{\\mathrm{int}}$, and $h_{\\mathrm{lap}}$, and outputs for each test case the list $[b_0, b_1, b_2, h_{\\mathrm{int}}, h_{\\mathrm{lap}}, \\text{passed}_{\\mathrm{int}}, \\text{passed}_{\\mathrm{lap}}]$ in a single line, aggregated into one outer list. Since RWG–BC stabilization introduces symmetric positive definite inner products that do not alter the kernel conditions $\\partial_1 x = 0$ and $\\partial_2^\\top x = 0$, both harmonic dimension computations are consistent and purely topological.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef matrix_rank_svd(A, eps=None):\n    \"\"\"Numerically stable matrix rank using SVD with tolerance.\"\"\"\n    # Convert to float64\n    A = np.asarray(A, dtype=float)\n    # Handle empty matrices\n    if A.size == 0:\n        return 0\n    # Compute SVD\n    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n    # Machine epsilon\n    if eps is None:\n        eps = np.finfo(float).eps\n    # Tolerance as in numpy.linalg.matrix_rank\n    tol = s.max() * max(A.shape) * eps\n    return int(np.sum(s > tol))\n\ndef nullity_svd(A, eps=None):\n    \"\"\"Compute nullity of A over reals using SVD.\"\"\"\n    rank = matrix_rank_svd(A, eps=eps)\n    return A.shape[1] - rank\n\ndef build_incidence_from_faces(nV, faces):\n    \"\"\"\n    Build oriented incidence matrices ∂1 (V x E) and ∂2 (E x F)\n    from a list of oriented triangular faces with vertex indices.\n    Edge orientation is canonical: (min(u,v) -> max(u,v)).\n    For each face (a,b,c), edges are (a,b), (b,c), (c,a) with ±1 signs.\n    \"\"\"\n    # Collect edges as unordered pairs, map to index\n    edge_dict = {}  # key: (min, max) -> edge_index\n    edges = []      # list of (u, v) with u  v (canonical orientation)\n    # Temporary: per-face edge entries (edge_index, sign)\n    face_edges = []\n\n    def add_edge(u, v):\n        u0, v0 = (u, v)\n        if u0 == v0:\n            raise ValueError(\"Degenerate edge with identical vertices.\")\n        a, b = (u0, v0) if u0  v0 else (v0, u0)\n        sign = +1 if (u0  v0) else -1\n        key = (a, b)\n        if key not in edge_dict:\n            edge_dict[key] = len(edges)\n            edges.append(key)\n        return edge_dict[key], sign\n\n    for (a, b, c) in faces:\n        e1_idx, s1 = add_edge(a, b)\n        e2_idx, s2 = add_edge(b, c)\n        e3_idx, s3 = add_edge(c, a)\n        face_edges.append([(e1_idx, s1), (e2_idx, s2), (e3_idx, s3)])\n\n    nE = len(edges)\n    nF = len(faces)\n    # Build ∂2 (E x F)\n    d2 = np.zeros((nE, nF), dtype=float)\n    for f_idx, edges_in_face in enumerate(face_edges):\n        for e_idx, s in edges_in_face:\n            d2[e_idx, f_idx] += s\n    # Build ∂1 (V x E) based on canonical orientation (u -> v) with u  v\n    d1 = np.zeros((nV, nE), dtype=float)\n    for e_idx, (u, v) in enumerate(edges):\n        # canonical orientation from u -> v\n        d1[u, e_idx] = -1.0\n        d1[v, e_idx] = +1.0\n\n    return d1, d2, edges\n\ndef build_octahedron_sphere():\n    \"\"\"\n    Build an octahedron triangulation of the sphere:\n    vertices 0..5, where 4 is bottom apex, 5 is top apex,\n    and 0..3 are equatorial vertices in cyclic order.\n    Faces are oriented consistently.\n    \"\"\"\n    nV = 6\n    # Top faces: (5,i,i+1)\n    top_faces = [(5, 0, 1), (5, 1, 2), (5, 2, 3), (5, 3, 0)]\n    # Bottom faces: (4,i+1,i) to ensure consistent global orientation\n    bottom_faces = [(4, 1, 0), (4, 2, 1), (4, 3, 2), (4, 0, 3)]\n    faces = top_faces + bottom_faces\n    return nV, faces\n\ndef build_torus_grid(N):\n    \"\"\"\n    Build a torus triangulation from an N x N periodic grid.\n    Vertices are indexed by (i,j) with modulo N periodicity.\n    Two oriented triangles per grid cell:\n    (i,j),(i+1,j),(i+1,j+1) and (i,j),(i+1,j+1),(i,j+1).\n    \"\"\"\n    def vid(i, j):\n        return (i % N) * N + (j % N)\n\n    nV = N * N\n    faces = []\n    for i in range(N):\n        for j in range(N):\n            # Triangle 1\n            a = vid(i, j)\n            b = vid(i + 1, j)\n            c = vid(i + 1, j + 1)\n            faces.append((a, b, c))\n            # Triangle 2\n            a2 = vid(i, j)\n            b2 = vid(i + 1, j + 1)\n            c2 = vid(i, j + 1)\n            faces.append((a2, b2, c2))\n    return nV, faces\n\ndef disjoint_union(meshA, meshB):\n    \"\"\"\n    Disjoint union of two complexes. Each mesh is (nV, faces).\n    Returns (nV_total, faces_total) after offsetting indices of meshB.\n    \"\"\"\n    nV_A, faces_A = meshA\n    nV_B, faces_B = meshB\n    offset = nV_A\n    faces_B_off = [(a + offset, b + offset, c + offset) for (a, b, c) in faces_B]\n    nV_total = nV_A + nV_B\n    faces_total = faces_A + faces_B_off\n    return nV_total, faces_total\n\ndef hodge_laplacian_1(d1, d2):\n    \"\"\"\n    Build the combinatorial 1-Hodge Laplacian L1 = d1^T d1 + d2 d2^T.\n    \"\"\"\n    return d1.T @ d1 + d2 @ d2.T\n\ndef harmonic_dim_laplacian(L1, eps=None):\n    \"\"\"Compute dimension of kernel of L1 via SVD.\"\"\"\n    # SVD of symmetric matrix\n    U, s, Vt = np.linalg.svd(L1, full_matrices=False)\n    if eps is None:\n        eps = np.finfo(float).eps\n    tol = s.max() * max(L1.shape) * eps if s.size > 0 else 0.0\n    return int(np.sum(s = tol))\n\ndef compute_betti_and_harmonic(nV, faces):\n    \"\"\"\n    Compute Betti numbers and harmonic dimensions for a triangulated surface.\n    Returns b0, b1, b2, h_int, h_lap.\n    \"\"\"\n    d1, d2, edges = build_incidence_from_faces(nV, faces)\n    nE = len(edges)\n    nF = len(faces)\n\n    # Ranks\n    r1 = matrix_rank_svd(d1)\n    r2 = matrix_rank_svd(d2)\n\n    # Betti numbers\n    b0 = nV - r1\n    b1 = nE - r1 - r2\n    b2 = nF - r2\n\n    # Intersection harmonic dimension: nullity of [d1; d2^T]\n    S = np.vstack([d1, d2.T])\n    h_int = nE - matrix_rank_svd(S)\n\n    # Laplacian harmonic dimension\n    L1 = hodge_laplacian_1(d1, d2)\n    h_lap = harmonic_dim_laplacian(L1)\n\n    return b0, b1, b2, h_int, h_lap\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Test case A: Octahedron sphere (genus 0)\n    mesh_sphere = build_octahedron_sphere()\n    # Test case B: Torus (genus 1) with N=3\n    mesh_torus = build_torus_grid(N=3)\n    # Test case C: Disjoint union of sphere and torus\n    mesh_union = disjoint_union(mesh_sphere, mesh_torus)\n\n    test_cases = [\n        (\"sphere_octa\", mesh_sphere),\n        (\"torus_N3\", mesh_torus),\n        (\"union_sphere_torus\", mesh_union),\n    ]\n\n    results = []\n    for name, mesh in test_cases:\n        nV, faces = mesh\n        b0, b1, b2, h_int, h_lap = compute_betti_and_harmonic(nV, faces)\n        passed_int = (h_int == b1)\n        passed_lap = (h_lap == b1)\n        results.append([b0, b1, b2, h_int, h_lap, passed_int, passed_lap])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}