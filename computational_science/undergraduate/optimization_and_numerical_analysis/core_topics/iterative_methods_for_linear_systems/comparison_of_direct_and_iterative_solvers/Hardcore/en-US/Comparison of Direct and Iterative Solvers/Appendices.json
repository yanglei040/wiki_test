{
    "hands_on_practices": [
        {
            "introduction": "Before comparing solvers, we must first understand how to evaluate a solution's quality. Whether obtained from a direct or iterative method, an approximate solution's proximity to the true solution is measured by the residual vector. This exercise  provides practice in computing this fundamental diagnostic tool, which quantifies the error and serves as a core component in many advanced iterative algorithms.",
            "id": "2160095",
            "problem": "In numerical analysis, the quality of an approximate solution to a system of linear equations $Ax = b$ is often assessed by computing the residual vector, defined as $r = b - Ax_{approx}$. A small residual indicates that the approximate solution nearly satisfies the original equation. This concept is fundamental not only for error analysis but also as a building block for iterative solvers like the conjugate gradient method.\n\nConsider a linear system $Ax=b$ where the matrix $A$ and the vector $b$ are given by:\n$$\nA = \\begin{pmatrix} 7  -4 \\\\ -4  6 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix}\n$$\nA direct solver, subject to finite-precision arithmetic, has produced an approximate solution vector:\n$$\nx_{approx} = \\begin{pmatrix} 1.30 \\\\ 1.05 \\end{pmatrix}\n$$\nCalculate the two components of the residual vector, $r_1$ and $r_2$. Report your answer as a row matrix $[r_1 \\quad r_2]$, expressing each component rounded to three significant figures.",
            "solution": "We are given the linear system $Ax=b$ with $A=\\begin{pmatrix}7  -4 \\\\ -4  6\\end{pmatrix}$, $b=\\begin{pmatrix}5 \\\\ 1\\end{pmatrix}$, and an approximate solution $x_{\\text{approx}}=\\begin{pmatrix}1.30 \\\\ 1.05\\end{pmatrix}$. The residual vector is defined by $r=b-Ax_{\\text{approx}}$.\n\nFirst compute the matrix-vector product $Ax_{\\text{approx}}$:\n$$\nAx_{\\text{approx}}=\\begin{pmatrix}7  -4 \\\\ -4  6\\end{pmatrix}\\begin{pmatrix}1.30 \\\\ 1.05\\end{pmatrix}\n=\\begin{pmatrix}7\\cdot 1.30+(-4)\\cdot 1.05 \\\\ (-4)\\cdot 1.30+6\\cdot 1.05\\end{pmatrix}.\n$$\nEvaluate each component:\n$$\n7\\cdot 1.30=9.10,\\quad (-4)\\cdot 1.05=-4.20 \\;\\Rightarrow\\; 9.10+(-4.20)=4.90,\n$$\n$$\n(-4)\\cdot 1.30=-5.20,\\quad 6\\cdot 1.05=6.30 \\;\\Rightarrow\\; -5.20+6.30=1.10.\n$$\nThus,\n$$\nAx_{\\text{approx}}=\\begin{pmatrix}4.90 \\\\ 1.10\\end{pmatrix}.\n$$\nNow compute the residual $r=b-Ax_{\\text{approx}}$:\n$$\nr=\\begin{pmatrix}5 \\\\ 1\\end{pmatrix}-\\begin{pmatrix}4.90 \\\\ 1.10\\end{pmatrix}\n=\\begin{pmatrix}5-4.90 \\\\ 1-1.10\\end{pmatrix}\n=\\begin{pmatrix}0.10 \\\\ -0.10\\end{pmatrix}.\n$$\nRounding each component to three significant figures yields $r_{1}=0.100$ and $r_{2}=-0.100$. Reporting as a row matrix gives $\\begin{pmatrix}0.100  -0.100\\end{pmatrix}$.",
            "answer": "$$\\boxed{\\begin{pmatrix}0.100  -0.100\\end{pmatrix}}$$"
        },
        {
            "introduction": "Unlike direct methods, the success of iterative solvers is not guaranteed for every system. Convergence depends on the properties of the system's matrix, specifically the spectral radius of its corresponding iteration matrix. In this practice , you will calculate this crucial value for a Jacobi iteration, providing a concrete link between matrix theory and the practical prediction of an iterative method's success.",
            "id": "2160047",
            "problem": "In the field of numerical linear algebra, iterative methods provide an alternative to direct methods for solving linear systems of the form $A\\mathbf{x} = \\mathbf{b}$. One of the simplest iterative schemes is the Jacobi method. The convergence of the Jacobi method is determined by the spectral radius of its iteration matrix.\n\nFor a given $n \\times n$ matrix $A$, we can decompose it as $A = D - L - U$, where $D$ is a diagonal matrix containing the diagonal entries of $A$, $-L$ is the strictly lower triangular part of $A$, and $-U$ is the strictly upper triangular part of $A$. The Jacobi iteration matrix, denoted $T_J$, is then defined as $T_J = D^{-1}(L+U)$. An iterative process based on this matrix converges for any initial guess if and only if its spectral radius, $\\rho(T_J)$, is less than 1. The spectral radius is the maximum absolute value of the eigenvalues of $T_J$.\n\nConsider the specific matrix:\n$$\nA = \\begin{pmatrix} 4  1 \\\\ -2  5 \\end{pmatrix}\n$$\nThis matrix is strictly diagonally dominant, which guarantees the convergence of the Jacobi method. Your task is to explicitly verify this theoretical guarantee by direct calculation.\n\nCalculate the exact spectral radius, $\\rho(T_J)$, for the given matrix $A$. Express your answer as a single, simplified analytical expression.",
            "solution": "We are given $A=\\begin{pmatrix}4  1 \\\\ -2  5\\end{pmatrix}$ with the decomposition $A=D-L-U$, where $D$ is the diagonal of $A$, $-L$ is the strictly lower triangular part of $A$, and $-U$ is the strictly upper triangular part of $A$. Thus\n$$\nD=\\begin{pmatrix}4  0 \\\\ 0  5\\end{pmatrix},\\quad -L=\\begin{pmatrix}0  0 \\\\ -2  0\\end{pmatrix}\\;\\Rightarrow\\;L=\\begin{pmatrix}0  0 \\\\ 2  0\\end{pmatrix},\\quad -U=\\begin{pmatrix}0  1 \\\\ 0  0\\end{pmatrix}\\;\\Rightarrow\\;U=\\begin{pmatrix}0  -1 \\\\ 0  0\\end{pmatrix}.\n$$\nThe Jacobi iteration matrix is\n$$\nT_{J}=D^{-1}(L+U).\n$$\nCompute $L+U$ and $D^{-1}$:\n$$\nL+U=\\begin{pmatrix}0  -1 \\\\ 2  0\\end{pmatrix},\\qquad D^{-1}=\\begin{pmatrix}\\frac{1}{4}  0 \\\\ 0  \\frac{1}{5}\\end{pmatrix}.\n$$\nTherefore\n$$\nT_{J}=D^{-1}(L+U)=\\begin{pmatrix}\\frac{1}{4}  0 \\\\ 0  \\frac{1}{5}\\end{pmatrix}\\begin{pmatrix}0  -1 \\\\ 2  0\\end{pmatrix}=\\begin{pmatrix}0  -\\frac{1}{4} \\\\ \\frac{2}{5}  0\\end{pmatrix}.\n$$\nTo find the spectral radius, compute the eigenvalues of $T_{J}$. The characteristic polynomial is\n$$\n\\det(\\lambda I - T_{J})=\\det\\begin{pmatrix}\\lambda  \\frac{1}{4} \\\\ -\\frac{2}{5}  \\lambda\\end{pmatrix}=\\lambda^{2}+\\frac{1}{10}.\n$$\nThus the eigenvalues satisfy $\\lambda^{2}=-\\frac{1}{10}$, giving\n$$\n\\lambda=\\pm i\\,\\frac{1}{\\sqrt{10}}.\n$$\nThe spectral radius is the maximum absolute value of the eigenvalues, hence\n$$\n\\rho(T_{J})=\\frac{1}{\\sqrt{10}}.\n$$\nThis is less than $1$, confirming convergence, and provides the exact spectral radius.",
            "answer": "$$\\boxed{\\frac{1}{\\sqrt{10}}}$$"
        },
        {
            "introduction": "The theoretical conditions for convergence have direct practical consequences. This exercise  presents a system where the Jacobi method is doomed to fail because the matrix is not diagonally dominant, leading to diverging iterates. By solving the system using a direct method, you will underscore the key trade-off: direct solvers are more robust and guaranteed to find a solution, even when iterative methods are unstable.",
            "id": "2160102",
            "problem": "In numerical analysis, linear systems of the form $A\\mathbf{x} = \\mathbf{b}$ can be solved using either direct methods (like Gaussian elimination) or iterative methods (like the Jacobi method). While iterative methods can be very efficient for large, sparse systems, their convergence is not guaranteed for all matrices. A sufficient, but not necessary, condition for the Jacobi method to converge is that the matrix $A$ must be strictly diagonally dominant.\n\nConsider the following $2 \\times 2$ linear system, which is not strictly diagonally dominant:\n$$\n\\begin{pmatrix} 1  2 \\\\ 3  1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 5 \\\\ 7 \\end{pmatrix}\n$$\nAn attempt to solve this system using the Jacobi method with an initial guess $\\mathbf{x}^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ reveals that the iterates diverge rapidly. To obtain the correct solution, one must use a direct method.\n\nDetermine the exact solution vector $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ for this system. Express your answer as a row matrix $\\begin{pmatrix} x_1  x_2 \\end{pmatrix}$.",
            "solution": "We solve the linear system $A\\mathbf{x}=\\mathbf{b}$ with $A=\\begin{pmatrix}1  2 \\\\ 3  1\\end{pmatrix}$ and $\\mathbf{b}=\\begin{pmatrix}5 \\\\ 7\\end{pmatrix}$ by a direct method (Gaussian elimination).\n\nWrite the system as equations:\n$$\n\\begin{cases}\nx_{1}+2x_{2}=5, \\\\\n3x_{1}+x_{2}=7.\n\\end{cases}\n$$\nEliminate $x_{1}$ by multiplying the first equation by $3$ and subtracting the second equation:\n$$\n(3x_{1}+6x_{2})-(3x_{1}+x_{2})=15-7 \\;\\;\\Rightarrow\\;\\; 5x_{2}=8 \\;\\;\\Rightarrow\\;\\; x_{2}=\\frac{8}{5}.\n$$\nSubstitute $x_{2}=\\frac{8}{5}$ into the first equation:\n$$\nx_{1}+2\\left(\\frac{8}{5}\\right)=5 \\;\\;\\Rightarrow\\;\\; x_{1}+\\frac{16}{5}=5 \\;\\;\\Rightarrow\\;\\; x_{1}=5-\\frac{16}{5}=\\frac{9}{5}.\n$$\nTherefore, the exact solution vector is $\\begin{pmatrix}\\frac{9}{5}  \\frac{8}{5}\\end{pmatrix}$. For completeness, this agrees with the matrix inverse method: $\\det(A)=1\\cdot 1-2\\cdot 3=-5$, $\\operatorname{adj}(A)=\\begin{pmatrix}1  -2 \\\\ -3  1\\end{pmatrix}$, so\n$$\n\\mathbf{x}=A^{-1}\\mathbf{b}=\\frac{1}{-5}\\begin{pmatrix}1  -2 \\\\ -3  1\\end{pmatrix}\\begin{pmatrix}5 \\\\ 7\\end{pmatrix}=\\frac{1}{-5}\\begin{pmatrix}-9 \\\\ -8\\end{pmatrix}=\\begin{pmatrix}\\frac{9}{5} \\\\ \\frac{8}{5}\\end{pmatrix}.\n$$\nExpressed as a row matrix, this is $\\begin{pmatrix}\\frac{9}{5}  \\frac{8}{5}\\end{pmatrix}$.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{9}{5}  \\frac{8}{5}\\end{pmatrix}}$$"
        }
    ]
}