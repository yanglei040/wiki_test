{
    "hands_on_practices": [
        {
            "introduction": "要掌握任何准牛顿法，第一步都是理解其更新公式所依赖的基本构件。本练习将重点介绍 DFP 算法中的两个核心向量：位移向量 $s_k$ 和梯度变化向量 $y_k$。通过为一个具体二次函数计算这些向量，你将为执行完整的 DFP 更新  奠定坚实的基础，并熟悉这些关键量的实际计算过程。",
            "id": "2212535",
            "problem": "在诸如 Davidon-Fletcher-Powell (DFP) 算法的拟牛顿优化方法的背景下，海森矩阵的近似在每次迭代中都会被更新。此更新依赖于两个关键向量，记为 $s_k$ 和 $y_k$。向量 $s_k$ 表示在变量空间中所走的步长，向量 $y_k$ 表示梯度的相应变化。\n\n考虑函数 $f(x_1, x_2) = 2x_1^2 + x_2^2 + x_1 x_2$ 的无约束优化。\n假设我们处于第 $k$ 次迭代，当前点为 $x_k = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。通过某种线搜索过程找到的序列中的下一个点是 $x_{k+1} = \\begin{pmatrix} 0.5 \\\\ 1 \\end{pmatrix}$。\n\nDFP 更新所需的向量定义为 $s_k = x_{k+1} - x_k$ 和 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n\n下列哪个选项正确地表示了本次迭代的向量 $s_k$ 和 $y_k$？\n\nA. $s_k = \\begin{pmatrix} -0.5 \\\\ 1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} -1 \\\\ 1.5 \\end{pmatrix}$\n\nB. $s_k = \\begin{pmatrix} 0.5 \\\\ -1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} 1 \\\\ -1.5 \\end{pmatrix}$\n\nC. $s_k = \\begin{pmatrix} 1.5 \\\\ 1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} 7 \\\\ 3.5 \\end{pmatrix}$\n\nD. $s_k = \\begin{pmatrix} -1 \\\\ 1.5 \\end{pmatrix}$, $y_k = \\begin{pmatrix} -0.5 \\\\ 1 \\end{pmatrix}$\n\nE. $s_k = \\begin{pmatrix} -0.5 \\\\ 1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} 7 \\\\ 3.5 \\end{pmatrix}$",
            "solution": "给定函数 $f(x_1,x_2)=2x_1^2+x_2^2+x_1x_2$。梯度通过对各分量求导得到：\n$$\n\\nabla f(x_1,x_2)=\\begin{pmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2}\\end{pmatrix}\n=\\begin{pmatrix}4x_1+x_2 \\\\ 2x_2+x_1\\end{pmatrix}.\n$$\n根据定义，位移向量为 $s_k=x_{k+1}-x_k$。当 $x_k=\\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$ 和 $x_{k+1}=\\begin{pmatrix}\\frac{1}{2} \\\\ 1\\end{pmatrix}$ 时，我们得到\n$$\ns_k=\\begin{pmatrix}\\frac{1}{2}-1 \\\\ 1-0\\end{pmatrix}=\\begin{pmatrix}-\\frac{1}{2} \\\\ 1\\end{pmatrix}.\n$$\n接下来，梯度变化量为 $y_k=\\nabla f(x_{k+1})-\\nabla f(x_k)$。计算在每个点处的梯度：\n$$\n\\nabla f(x_k)=\\nabla f(1,0)=\\begin{pmatrix}4\\cdot 1+0 \\\\ 2\\cdot 0+1\\end{pmatrix}=\\begin{pmatrix}4 \\\\ 1\\end{pmatrix},\n$$\n$$\n\\nabla f(x_{k+1})=\\nabla f(\\frac{1}{2},1)=\\begin{pmatrix}4\\cdot \\frac{1}{2}+1 \\\\ 2\\cdot 1+\\frac{1}{2}\\end{pmatrix}=\\begin{pmatrix}3 \\\\ \\frac{5}{2}\\end{pmatrix}.\n$$\n因此，\n$$\ny_k=\\begin{pmatrix}3-4 \\\\ \\frac{5}{2}-1\\end{pmatrix}=\\begin{pmatrix}-1 \\\\ \\frac{3}{2}\\end{pmatrix}.\n$$\n与选项比较，这对应于 $s_k=\\begin{pmatrix}-\\frac{1}{2} \\\\ 1\\end{pmatrix}$ 和 $y_k=\\begin{pmatrix}-1 \\\\ \\frac{3}{2}\\end{pmatrix}$，即选项 A。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在计算了基本的 $s_k$ 和 $y_k$ 向量之后，下一步就是将它们代入 DFP 公式中，以更新我们对逆 Hessian 矩阵的近似。本练习将指导你完成这一核心步骤，从一个标准初始猜测（单位矩阵 $H_0=I$）开始，执行一次完整的 DFP 更新。通过这个实践，你将熟练掌握 DFP 更新中涉及的向量外积和矩阵运算，从而具体地理解算法是如何迭代地改进其对函数曲率的模型的。",
            "id": "2212500",
            "problem": "在数值优化领域，拟牛顿法是用于寻找函数局部最小值或最大值的迭代算法。这些方法的一个关键特征是逼近黑塞矩阵或其逆矩阵。最早也是最著名的拟牛顿算法之一是Davidon-Fletcher-Powell (DFP) 方法。\n\n用于逼近黑塞矩阵的逆（记为 $H$）的DFP更新公式如下：\n$$H_{k+1} = H_k + \\frac{s_k s_k^T}{s_k^T y_k} - \\frac{H_k y_k y_k^T H_k}{y_k^T H_k y_k}$$\n其中 $k$ 是迭代索引，$s_k = x_{k+1} - x_k$ 是在参数空间中采取的步长，而 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ 是目标函数 $f(x)$ 梯度的变化。\n\n考虑一个优化过程的第一步（$k=0$）。逆黑塞矩阵的初始近似设为单位矩阵，$H_0 = I$。在第一次线搜索之后，步长向量 $s_0$ 和梯度变化向量 $y_0$ 计算得出：\n$$s_0 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}, \\quad y_0 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$$\n\n你的任务是计算这第一步之后更新的逆黑塞近似矩阵 $H_1$。将你的答案表示为一个包含分数项的矩阵。",
            "solution": "我们使用DFP更新公式来近似逆黑塞矩阵：\n$$H_{k+1} = H_{k} + \\frac{s_{k}s_{k}^{T}}{s_{k}^{T}y_{k}} - \\frac{H_{k}y_{k}y_{k}^{T}H_{k}}{y_{k}^{T}H_{k}y_{k}}.$$\n在第一步，$k=0$，$H_{0}=I$，$s_{0}=\\begin{pmatrix}1 \\\\ -2\\end{pmatrix}$，以及 $y_{0}=\\begin{pmatrix}2 \\\\ -1\\end{pmatrix}$。由于 $H_{0}=I$，我们有 $H_{0}y_{0}=y_{0}$ 和 $y_{0}^{T}H_{0}y_{0}=y_{0}^{T}y_{0}$。因此，\n$$H_{1} = I + \\frac{s_{0}s_{0}^{T}}{s_{0}^{T}y_{0}} - \\frac{y_{0}y_{0}^{T}}{y_{0}^{T}y_{0}}.$$\n计算所需的内积：\n$$s_{0}^{T}y_{0} = 1\\cdot 2 + (-2)\\cdot(-1) = 4,$$\n$$y_{0}^{T}y_{0} = 2^{2} + (-1)^{2} = 5.$$\n计算所需的外积：\n$$s_{0}s_{0}^{T} = \\begin{pmatrix}1  -2 \\\\ -2  4\\end{pmatrix}, \\quad y_{0}y_{0}^{T} = \\begin{pmatrix}4  -2 \\\\ -2  1\\end{pmatrix}.$$\n因此，\n$$\\frac{s_{0}s_{0}^{T}}{s_{0}^{T}y_{0}} = \\frac{1}{4}\\begin{pmatrix}1  -2 \\\\ -2  4\\end{pmatrix} = \\begin{pmatrix}\\frac{1}{4}  -\\frac{1}{2} \\\\ -\\frac{1}{2}  1\\end{pmatrix}, \\quad \\frac{y_{0}y_{0}^{T}}{y_{0}^{T}y_{0}} = \\frac{1}{5}\\begin{pmatrix}4  -2 \\\\ -2  1\\end{pmatrix} = \\begin{pmatrix}\\frac{4}{5}  -\\frac{2}{5} \\\\ -\\frac{2}{5}  \\frac{1}{5}\\end{pmatrix}.$$\n合并各项：\n$$H_{1} = I + \\begin{pmatrix}\\frac{1}{4}  -\\frac{1}{2} \\\\ -\\frac{1}{2}  1\\end{pmatrix} - \\begin{pmatrix}\\frac{4}{5}  -\\frac{2}{5} \\\\ -\\frac{2}{5}  \\frac{1}{5}\\end{pmatrix}.$$\n计算每个元素：\n$$(1,1): 1 + \\frac{1}{4} - \\frac{4}{5} = \\frac{5}{4} - \\frac{4}{5} = \\frac{25 - 16}{20} = \\frac{9}{20},$$\n$$(1,2) \\text{ 和 } (2,1): 0 - \\frac{1}{2} - \\left(-\\frac{2}{5}\\right) = -\\frac{1}{2} + \\frac{2}{5} = -\\frac{1}{10},$$\n$$(2,2): 1 + 1 - \\frac{1}{5} = 2 - \\frac{1}{5} = \\frac{9}{5}.$$\n因此，\n$$H_{1} = \\begin{pmatrix}\\frac{9}{20}  -\\frac{1}{10} \\\\ -\\frac{1}{10}  \\frac{9}{5}\\end{pmatrix}.$$\n作为检验，割线条件 $H_{1}y_{0}=s_{0}$ 成立：\n$$\\begin{pmatrix}\\frac{9}{20}  -\\frac{1}{10} \\\\ -\\frac{1}{10}  \\frac{9}{5}\\end{pmatrix}\\begin{pmatrix}2 \\\\ -1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ -2\\end{pmatrix} = s_{0}.$$",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{9}{20}  -\\frac{1}{10} \\\\ -\\frac{1}{10}  \\frac{9}{5}\\end{pmatrix}}$$"
        },
        {
            "introduction": "为了更深刻地理解 DFP 公式的本质，我们有时需要剥离其多维度的复杂性，探究其在一维情况下的核心思想。本练习旨在通过将 DFP 更新公式简化到单变量函数的情境，揭示其与数值分析中一个更基本概念的联系。你会发现，在这种简化下，复杂的矩阵公式演变成了一个我们熟悉的形式，从而揭示了 DFP 方法作为割线法在多维空间中的一种推广 。",
            "id": "2212502",
            "problem": "在数值优化中，拟牛顿法是用于寻找函数局部最小值的一类重要算法。这些方法通过迭代构建函数海森矩阵的近似。Davidon-Fletcher-Powell (DFP) 方法提供了这样一种更新规则。虽然通常表示为对海森矩阵逆的更新，但 DFP 更新也可以直接针对第 $k$ 次迭代的海森近似矩阵 $B_k$ 来构建。该公式为：\n$$B_{k+1} = \\left(I - \\frac{y_k s_k^T}{y_k^T s_k}\\right) B_k \\left(I - \\frac{s_k y_k^T}{y_k^T s_k}\\right) + \\frac{y_k y_k^T}{y_k^T s_k}$$\n此处，$I$ 是单位矩阵。向量 $s_k = x_{k+1} - x_k$ 是在变量空间中采取的步长，而向量 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ 是被最小化的函数 $f$ 梯度的相应变化。\n\n考虑将 DFP 方法应用于单变量函数 $f(x)$，其中 $x$ 是一个标量。在这种一维情况下，所有向量都变为标量，矩阵运算（如乘法和转置）也变为简单的标量乘法。海森近似 $B_k$ 变为一个标量值，我们将其记为 $b_k$。\n\n你的任务是确定更新后的标量海森近似 $b_{k+1}$ 的简化表达式。你的结果应该是一个用标量 $s_k$ 和 $y_k$ 表示的单一闭式解析表达式。",
            "solution": "我们从所提供的用于海森近似的矩阵形式 DFP 更新公式开始：\n$$\nB_{k+1} = \\left(I - \\frac{y_k s_k^{T}}{y_k^{T} s_k}\\right) B_k \\left(I - \\frac{s_k y_k^{T}}{y_k^{T} s_k}\\right) + \\frac{y_k y_k^{T}}{y_k^{T} s_k}.\n$$\n在一维情况下，所有量都是标量。因此，$I$ 变为 $1$，$B_k$ 变为标量 $b_k$，且转置没有影响。步长 $s_k$ 和梯度变化 $y_k$ 是标量，且 $y_k^{T} s_k = y_k s_k$。因此，更新公式简化为\n$$\nb_{k+1} = \\left(1 - \\frac{y_k s_k}{y_k s_k}\\right) b_k \\left(1 - \\frac{s_k y_k}{y_k s_k}\\right) + \\frac{y_k y_k}{y_k s_k}.\n$$\n假设满足标准曲率条件 $y_k s_k \\neq 0$，我们简化标量分数：\n$$\n\\frac{y_k s_k}{y_k s_k} = 1, \\quad \\frac{s_k y_k}{y_k s_k} = 1,\n$$\n所以第一项消失：\n$$\n\\left(1 - 1\\right) b_k \\left(1 - 1\\right) = 0.\n$$\n对于剩下的项，\n$$\n\\frac{y_k y_k}{y_k s_k} = \\frac{y_k^{2}}{y_k s_k} = \\frac{y_k}{s_k}.\n$$\n因此，更新后的标量海森近似为\n$$\nb_{k+1} = \\frac{y_k}{s_k}.\n$$\n这也与一维割线条件 $b_{k+1} s_k = y_k$ 相符。",
            "answer": "$$\\boxed{\\frac{y_{k}}{s_{k}}}$$"
        }
    ]
}