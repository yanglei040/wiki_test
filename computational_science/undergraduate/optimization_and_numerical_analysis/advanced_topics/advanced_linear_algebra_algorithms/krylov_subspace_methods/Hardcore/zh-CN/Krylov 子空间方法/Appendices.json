{
    "hands_on_practices": [
        {
            "introduction": "Krylov 子空间方法的核心思想之一是在一个逐步扩大的子空间中寻找最优近似解。对于对称矩阵，Lanczos 算法是构建这个子空间标准正交基的基石。该算法能将一个大型对称矩阵 $A$ 转化为一个结构更简单的三对角矩阵 $T$，极大地简化了特征值计算和线性系统求解。这个练习  将带你亲手完成 Lanczos 过程的第一步，通过具体计算来理解这一转化过程的精髓。",
            "id": "2183327",
            "problem": "Lanczos 算法是一种迭代方法，它将一个对称矩阵 $A$ 变换为一个对称三对角矩阵 $T$。$T$ 的元素由对角项 $\\alpha_j$ 和非对角项 $\\beta_j$ 组成。该算法从一个初始向量 $b$ 开始，生成一系列称为 Lanczos 向量的标准正交向量 $q_j$。\n\n设对称矩阵 $A$ 和起始向量 $b$ 定义如下：\n$$A = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n\n执行 Lanczos 算法的第一次迭代，以求出相应的三对角矩阵 $T$ 的第一个对角元素 $\\alpha_1$ 和第一个非对角元素 $\\beta_1$。该过程从对 $b$ 进行标准化以获得第一个 Lanczos 向量 $q_1$ 开始。\n\n将您的答案以 $(\\alpha_1, \\beta_1)$ 的有序对形式报告。",
            "solution": "Lanczos 算法生成一系列标准正交向量 $q_j$ 和一个对称三对角矩阵 $T$。我们被要求求出该矩阵的首项，即 $\\alpha_1$ 和 $\\beta_1$。\n\n**第 1 步：初始化**\n\n第一步是对起始向量 $b$ 进行标准化，以获得第一个 Lanczos 向量 $q_1$。\n给定的起始向量为 $b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n我们计算其欧几里得范数 $\\|b\\|_2$：\n$$\\|b\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2}$$\n现在，我们通过将 $b$ 除以其范数来求得 $q_1$：\n$$q_1 = \\frac{b}{\\|b\\|_2} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n\n**第 2 步：第一次迭代 (j=1)**\n\nLanczos 迭代的核心是计算元素 $\\alpha_j$ 和 $\\beta_j$。对于第一次迭代（$j=1$），算法按以下步骤进行。\n\n首先，我们通过将矩阵 $A$ 应用于 $q_1$ 来计算向量 $v$：\n$$v = A q_1 = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right) = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2(1) + 1(1) \\\\ 1(1) + 3(1) \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$$\n\n接下来，我们计算第一个对角元素 $\\alpha_1$。这是通过取 $v$ 与 $q_1$ 的内积得到的：\n$$\\alpha_1 = q_1^T v$$\n代入 $q_1$ 和 $v$ 的表达式：\n$$\\alpha_1 = \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1  1 \\end{pmatrix} \\right) \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} \\right) = \\frac{1}{(\\sqrt{2})^2} (1 \\cdot 3 + 1 \\cdot 4) = \\frac{1}{2}(7) = \\frac{7}{2}$$\n\n求出 $\\alpha_1$ 后，我们计算未标准化的残差向量 $r_1$，该向量将用于求出 $\\beta_1$ 和 $q_2$。通过从 $v$ 中减去其在 $q_1$ 上的投影，使该向量与 $q_1$ 正交：\n$$r_1 = v - \\alpha_1 q_1$$\n代入已知值：\n$$r_1 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} - \\frac{7}{2} \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right)$$\n$$r_1 = \\frac{1}{\\sqrt{2}} \\left[ \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} - \\frac{7}{2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right] = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3 - \\frac{7}{2} \\\\ 4 - \\frac{7}{2} \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}$$\n\n最后，第一个非对角元素 $\\beta_1$ 是该残差向量 $r_1$ 的欧几里得范数：\n$$\\beta_1 = \\|r_1\\|_2$$\n$$\\beta_1 = \\left\\| \\frac{1}{\\sqrt{2}} \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\right\\|_2 = \\frac{1}{\\sqrt{2}} \\left\\| \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\right\\|_2 = \\frac{1}{\\sqrt{2}} \\sqrt{\\left(-\\frac{1}{2}\\right)^2 + \\left(\\frac{1}{2}\\right)^2}$$\n$$\\beta_1 = \\frac{1}{\\sqrt{2}} \\sqrt{\\frac{1}{4} + \\frac{1}{4}} = \\frac{1}{\\sqrt{2}} \\sqrt{\\frac{2}{4}} = \\frac{1}{\\sqrt{2}} \\sqrt{\\frac{1}{2}} = \\frac{1}{\\sqrt{2}} \\frac{1}{\\sqrt{2}} = \\frac{1}{2}$$\n\n第一次迭代现已完成。所求值为 $\\alpha_1 = \\frac{7}{2}$ 和 $\\beta_1 = \\frac{1}{2}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{7}{2}  \\frac{1}{2} \\end{pmatrix}}$$"
        },
        {
            "introduction": "当处理非对称线性系统时，Lanczos 算法被推广为 Arnoldi 过程。基于 Arnoldi 过程构建的 Krylov 子空间，发展出了多种求解方法，其中完全正交化方法 (FOM) 和广义最小残差方法 (GMRES) 是最著名的两种。尽管它们使用相同的子空间，但其寻找近似解的准则不同：FOM 采用伽辽金 (Galerkin) 条件，而 GMRES 则致力于最小化每一步的残差范数。这个练习  通过直接计算和比较两种方法的残差，清晰地揭示了 GMRES 在残差最小化方面的优化特性。",
            "id": "2183323",
            "problem": "考虑线性系统 $Ax=b$，其中\n$$ A = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\\\ 1  0  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}. $$\n我们希望使用两步（$m=2$）克里洛夫子空间方法，从初始猜测 $x_0 = \\vec{0}$ 开始，找到一个近似解。这两种方法是完全正交化方法（FOM）和广义最小残差方法（GMRES）。\n\n两种方法都首先使用 Arnoldi 过程为克里洛夫子空间 $\\mathcal{K}_2(A, r_0)$ 构建一个标准正交基 $\\{v_1, v_2\\}$，其中 $r_0 = b - Ax_0$。这个过程产生关系式 $AV_2 = V_3 \\tilde{H}_2$，其中 $V_k = [v_1, \\dots, v_k]$ 是以基向量为列的矩阵，$\\tilde{H}_2$ 是一个 $3 \\times 2$ 的上 Hessenberg 矩阵。令 $H_2$ 为通过移除 $\\tilde{H}_2$ 的最后一行得到的 $2 \\times 2$ 矩阵。\n\n两步后的近似解由 $x_2 = x_0 + V_2 y_2$ 给出，其中 $y_2$ 是 $\\mathbb{R}^2$ 中的一个向量。\n- 对于 FOM(2)，向量 $y_2^{\\text{FOM}}$ 通过求解系统 $H_2 y = \\|r_0\\|_2 e_1$ 得到，其中 $e_1 = [1, 0]^T$。\n- 对于 GMRES(2)，向量 $y_2^{\\text{GMRES}}$ 通过求解最小二乘问题 $\\min_{y \\in \\mathbb{R}^2} \\| \\tilde{H}_2 y - \\|r_0\\|_2 e_1 \\|_2$ 得到，其中 $e_1 = [1, 0, 0]^T$。\n\n最终的残差向量为 $r_2^{\\text{FOM}} = b - Ax_2^{\\text{FOM}}$ 和 $r_2^{\\text{GMRES}} = b - Ax_2^{\\text{GMRES}}$。\n\n计算两种方法的最终残差向量的 2-范数，即 $\\|r_2^{\\text{FOM}}\\|_2$ 和 $\\|r_2^{\\text{GMRES}}\\|_2$。将你的答案表示为一对精确的解析值 $(\\|r_2^{\\text{FOM}}\\|_2, \\|r_2^{\\text{GMRES}}\\|_2)$。",
            "solution": "我们有线性系统 $Ax=b$，其中\n$$\nA=\\begin{pmatrix}1  1  0\\\\0  1  1\\\\1  0  1\\end{pmatrix},\\quad b=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix},\n$$\n初始猜测为 $x_{0}=\\vec{0}$，且 $r_{0}=b-Ax_{0}=b$。因此 $\\beta=\\|r_{0}\\|_{2}=1$ 且 $v_{1}=r_{0}/\\beta=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}$。\n\n我们运行两步 Arnoldi 过程来为 $\\mathcal{K}_{2}(A,r_{0})$ 构建一个标准正交基 $\\{v_{1},v_{2}\\}$，并得到关系式 $AV_{2}=V_{3}\\tilde{H}_{2}$，其中 $V_{k}=[v_{1},\\dots,v_{k}]$。\n\n第一步：\n$$\nw=A v_{1}=A\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix},\\quad h_{1,1}=v_{1}^{T}w=1,\n$$\n$$\nw:=w-h_{1,1}v_{1}=\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix},\\quad h_{2,1}=\\|w\\|_{2}=1,\\quad v_{2}=w/h_{2,1}=\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}.\n$$\n\n第二步：\n$$\nw=A v_{2}=A\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix},\\quad h_{1,2}=v_{1}^{T}w=0,\\quad w:=w-h_{1,2}v_{1}=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix},\n$$\n$$\nh_{2,2}=v_{2}^{T}w=1,\\quad w:=w-h_{2,2}v_{2}=\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix},\\quad h_{3,2}=\\|w\\|_{2}=1,\\quad v_{3}=w/h_{3,2}=\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix}.\n$$\n\n因此，\n$$\n\\tilde{H}_{2}=\\begin{pmatrix}h_{1,1}  h_{1,2}\\\\ h_{2,1}  h_{2,2}\\\\ 0  h_{3,2}\\end{pmatrix}\n=\\begin{pmatrix}1  0\\\\ 1  1\\\\ 0  1\\end{pmatrix},\\qquad\nH_{2}=\\begin{pmatrix}1  0\\\\ 1  1\\end{pmatrix}.\n$$\n\n两步近似解具有形式 $x_{2}=x_{0}+V_{2}y$，其中 $y\\in\\mathbb{R}^{2}$。\n\n对于 FOM(2)，$y^{\\text{FOM}}$ 求解 $H_{2}y=\\beta e_{1}$，其中 $e_{1}=\\begin{pmatrix}1\\\\0\\end{pmatrix}$：\n$$\n\\begin{pmatrix}1  0\\\\1  1\\end{pmatrix}\\begin{pmatrix}y_{1}\\\\y_{2}\\end{pmatrix}=\\begin{pmatrix}1\\\\0\\end{pmatrix}\n\\;\\Rightarrow\\; y_{1}=1,\\; y_{2}=-1.\n$$\n因此 $x_{2}^{\\text{FOM}}=V_{2}y^{\\text{FOM}}=v_{1}\\cdot 1+v_{2}\\cdot(-1)=\\begin{pmatrix}1\\\\0\\\\-1\\end{pmatrix}$，残差为\n$$\nr_{2}^{\\text{FOM}}=b-Ax_{2}^{\\text{FOM}}=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}-A\\begin{pmatrix}1\\\\0\\\\-1\\end{pmatrix}\n=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}-\\begin{pmatrix}1\\\\-1\\\\0\\end{pmatrix}\n=\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix},\n$$\n所以 $\\|r_{2}^{\\text{FOM}}\\|_{2}=1$。\n\n对于 GMRES(2)，$y^{\\text{GMRES}}$ 最小化 $\\|\\tilde{H}_{2}y-\\beta e_{1}\\|_{2}$，其中 $e_{1}=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}$。令 $y=\\begin{pmatrix}y_{1}\\\\y_{2}\\end{pmatrix}$。则\n$$\n\\tilde{H}_{2}y-\\beta e_{1}=\\begin{pmatrix}y_{1}-1\\\\ y_{1}+y_{2}\\\\ y_{2}\\end{pmatrix},\n$$\n要最小化的范数的平方是\n$$\nf(y_{1},y_{2})=(y_{1}-1)^{2}+(y_{1}+y_{2})^{2}+y_{2}^{2}.\n$$\n将梯度设为零，\n$$\n\\frac{\\partial f}{\\partial y_{1}}=2(y_{1}-1)+2(y_{1}+y_{2})=0\\;\\Rightarrow\\;2y_{1}+y_{2}-1=0,\n$$\n$$\n\\frac{\\partial f}{\\partial y_{2}}=2(y_{1}+y_{2})+2y_{2}=0\\;\\Rightarrow\\;y_{1}+2y_{2}=0.\n$$\n求解得，$y_{2}=-\\frac{1}{3}$ 且 $y_{1}=\\frac{2}{3}$。最小化的残差范数是\n$$\n\\|\\tilde{H}_{2}y^{\\text{GMRES}}-\\beta e_{1}\\|_{2}\n=\\left\\|\\begin{pmatrix}\\frac{2}{3}-1\\\\ \\frac{2}{3}-\\frac{1}{3}\\\\ -\\frac{1}{3}\\end{pmatrix}\\right\\|_{2}\n=\\left\\|\\begin{pmatrix}-\\frac{1}{3}\\\\ \\frac{1}{3}\\\\ -\\frac{1}{3}\\end{pmatrix}\\right\\|_{2}\n=\\sqrt{\\frac{1}{9}+\\frac{1}{9}+\\frac{1}{9}}=\\sqrt{\\frac{1}{3}}.\n$$\n因为 $r_{2}^{\\text{GMRES}}=V_{3}(\\beta e_{1}-\\tilde{H}_{2}y^{\\text{GMRES}})$ 且 $V_{3}$ 是标准正交的，我们有 $\\|r_{2}^{\\text{GMRES}}\\|_{2}=\\|\\tilde{H}_{2}y^{\\text{GMRES}}-\\beta e_{1}\\|_{2}=\\sqrt{\\frac{1}{3}}$。\n\n因此，所求的残差范数对为 $(\\|r_{2}^{\\text{FOM}}\\|_{2},\\|r_{2}^{\\text{GMRES}}\\|_{2})=\\left(1,\\sqrt{\\frac{1}{3}}\\right)$。",
            "answer": "$$\\boxed{\\begin{pmatrix}1  \\sqrt{\\frac{1}{3}}\\end{pmatrix}}$$"
        },
        {
            "introduction": "在实际应用中，为了节省内存，我们通常使用重启的 GMRES 算法，即 GMRES(m)。然而，这种实用策略是有代价的——它牺牲了完全 GMRES 算法在精确算术下必定收敛的理论保证。对于某些性质特殊的矩阵（例如非正规矩阵），重启可能导致算法停滞不前。这个练习  构造了一个精巧的例子，让你观察到 GMRES(2) 在特定情况下完全无法收敛的现象，从而深刻理解重启策略的潜在风险以及矩阵性质对算法行为的重要影响。",
            "id": "2183305",
            "problem": "广义最小残差方法 (GMRES) 是一种迭代算法，用于求解形如 $Ax=b$ 的大型、稀疏、非对称线性方程组。一个常见的变体是重启 GMRES 算法，记为 GMRES(m)，它执行 $m$ 次 Arnoldi 过程迭代来构建一个 Krylov 子空间并找到一个近似解。这个解随后成为下一个 $m$ 次迭代“循环”的初始猜测。虽然完全 GMRES（其中 $m$ 是矩阵的维度）在精确算术下保证最多在 $m$ 步内收敛，但重启 GMRES 的行为可能更复杂，特别是对于非正规矩阵（其中 $A^T A \\neq A A^T$）。\n\n考虑由以下矩阵 $A$ 和向量 $b$ 定义的四维线性系统 $Ax=b$：\n$$\nA = \\begin{pmatrix} 0  0  0  1 \\\\ 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\end{pmatrix}, \\quad b = \\begin{pmatrix} \\sqrt{3} \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n从初始猜测 $x_0 = \\mathbf{0}$（其中 $\\mathbf{0}$ 是四维零向量）开始，应用 GMRES(2) 算法来近似求解。\n\n计算算法经过 5 个完整循环（即在第 $k=10$ 次迭代时）后残差向量 $r_k = b - Ax_k$ 的欧几里得范数（2-范数）。将你的最终答案四舍五入到四位有效数字。",
            "solution": "设 $e_{1},e_{2},e_{3},e_{4}$ 表示 $\\mathbb{R}^{4}$ 的标准基。矩阵 $A$ 是循环移位：\n$$\nA e_{1}=e_{2},\\quad A e_{2}=e_{3},\\quad A e_{3}=e_{4},\\quad A e_{4}=e_{1}.\n$$\n从 $x_{0}=\\mathbf{0}$ 开始。初始残差为\n$$\nr_{0}=b-Ax_{0}=b=\\sqrt{3}\\,e_{1},\\qquad \\|r_{0}\\|_{2}=\\sqrt{3},\\qquad v_{1}=\\frac{r_{0}}{\\|r_{0}\\|_{2}}=e_{1}.\n$$\n从 $v_{1}$ 开始，应用一个 GMRES(2) 循环（两步 Arnoldi 过程）。\n\n步骤 1: $w=A v_{1}=e_{2}$，$h_{11}=v_{1}^{T}w=0$，$w\\leftarrow w-h_{11}v_{1}=e_{2}$，$h_{21}=\\|w\\|_{2}=1$，$v_{2}=w/h_{21}=e_{2}$。\n\n步骤 2: $w=A v_{2}=e_{3}$，$h_{12}=v_{1}^{T}w=0$，$w\\leftarrow w-h_{12}v_{1}=e_{3}$，$h_{22}=v_{2}^{T}w=0$，$w\\leftarrow w-h_{22}v_{2}=e_{3}$，$h_{32}=\\|w\\|_{2}=1$。\n\n因此，Arnoldi 关系式中 $V_{2}=[v_{1},v_{2}]=[e_{1},e_{2}]$ 且 $\\widetilde{H}_{2}\\in\\mathbb{R}^{3\\times 2}$ 为\n$$\n\\widetilde{H}_{2}=\\begin{pmatrix}0  0\\\\ 1  0\\\\ 0  1\\end{pmatrix},\\qquad A V_{2}=[A e_{1},A e_{2}]=[e_{2},e_{3}].\n$$\nGMRES(2) 计算 $y\\in\\mathbb{R}^{2}$ 以最小化\n$$\n\\left\\|\\beta e_{1}-\\widetilde{H}_{2}y\\right\\|_{2},\\qquad \\beta=\\|r_{0}\\|_{2}=\\sqrt{3}.\n$$\n由于 $\\widetilde{H}_{2}y=[0,\\,y_{1},\\,y_{2}]^{T}$，目标函数为\n$$\n\\left\\|\\begin{pmatrix}\\sqrt{3}\\\\ 0\\\\ 0\\end{pmatrix}-\\begin{pmatrix}0\\\\ y_{1}\\\\ y_{2}\\end{pmatrix}\\right\\|_{2}^{2}=\\left(\\sqrt{3}\\right)^{2}+y_{1}^{2}+y_{2}^{2}.\n$$\n该式在 $y_{1}=0$，$y_{2}=0$ 时最小化，得到 $y=\\mathbf{0}$，因此 GMRES(2) 的更新为\n$$\nx_{1}=x_{0}+V_{2}y=x_{0},\\qquad r_{1}=b-Ax_{1}=r_{0},\\qquad \\|r_{1}\\|_{2}=\\sqrt{3}.\n$$\n因此，在第一个完整的 GMRES(2) 循环后，残差保持不变。以 $x_{1}$ 重启会产生相同的初始残差和相同的 Arnoldi 量，因此每个后续的 GMRES(2) 循环同样产生 $y=\\mathbf{0}$ 并且没有变化。因此，在任意数量的完整循环后，残差范数保持为 $\\sqrt{3}$。\n\n经过 $5$ 个完整循环（即 $k=10$ 次迭代）后，我们有\n$$\n\\|r_{10}\\|_{2}=\\sqrt{3}\\approx 1.7320508075688772\\ldots,\n$$\n将其四舍五入到四位有效数字为 $1.732$。",
            "answer": "$$\\boxed{1.732}$$"
        }
    ]
}