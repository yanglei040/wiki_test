{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a classic application of the method of Lagrange multipliers to a geometric problem. We will find the point on an ellipsoid that is furthest from the origin, which is equivalent to maximizing the distance function subject to the ellipsoidal constraint. This problem is an excellent way to practice setting up the Lagrangian and interpreting the first-order necessary conditions, which geometrically state that the gradient of the function we are optimizing must be parallel to the gradient of the constraint surface at the solution .",
            "id": "2173341",
            "problem": "In the study of plasticity for anisotropic materials, a yield surface is a criterion that defines the elastic limit of a material under a complex loading condition. For a specific orthotropic material, the state of principal stresses, denoted by the vector $(\\sigma_1, \\sigma_2, \\sigma_3)$, is constrained to lie on an ellipsoidal yield surface. The equation for this surface is given by:\n$$ \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} = 1 $$\nHere, $S_1, S_2,$ and $S_3$ represent the material's yield strengths along its three principal axes. These are positive constants, and for this particular material, they are ordered such that $S_1 > S_2 > S_3 > 0$.\n\nWe are interested in finding the stress state on this yield surface that has the largest overall magnitude. The magnitude of the stress vector is defined as $M = \\sqrt{\\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2}$.\n\nDetermine the maximum possible value of the magnitude $M$ for a stress state lying on this yield surface.",
            "solution": "The problem is to find the maximum value of the magnitude of the stress vector, $M = \\sqrt{\\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2}$, for a point $(\\sigma_1, \\sigma_2, \\sigma_3)$ that lies on the surface of an ellipsoid defined by the constraint equation $\\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} = 1$.\n\nThis is a constrained optimization problem. To simplify the calculations, instead of maximizing $M$, we can maximize its square, $M^2$, since $M$ is always non-negative. Let the function to be maximized be $f(\\sigma_1, \\sigma_2, \\sigma_3) = \\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2$. The constraint function is $g(\\sigma_1, \\sigma_2, \\sigma_3) = \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} - 1 = 0$.\n\nWe use the method of Lagrange multipliers. The Lagrangian function, $\\mathcal{L}$, is defined as:\n$$ \\mathcal{L}(\\sigma_1, \\sigma_2, \\sigma_3, \\lambda) = f(\\sigma_1, \\sigma_2, \\sigma_3) - \\lambda g(\\sigma_1, \\sigma_2, \\sigma_3) $$\n$$ \\mathcal{L}(\\sigma_1, \\sigma_2, \\sigma_3, \\lambda) = (\\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2) - \\lambda \\left( \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} - 1 \\right) $$\nTo find the extrema, we compute the partial derivatives of $\\mathcal{L}$ with respect to $\\sigma_1, \\sigma_2, \\sigma_3$, and $\\lambda$ and set them to zero.\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\sigma_1} = 2\\sigma_1 - \\frac{2\\lambda \\sigma_1}{S_1^2} = 2\\sigma_1 \\left( 1 - \\frac{\\lambda}{S_1^2} \\right) = 0 $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\sigma_2} = 2\\sigma_2 - \\frac{2\\lambda \\sigma_2}{S_2^2} = 2\\sigma_2 \\left( 1 - \\frac{\\lambda}{S_2^2} \\right) = 0 $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\sigma_3} = 2\\sigma_3 - \\frac{2\\lambda \\sigma_3}{S_3^2} = 2\\sigma_3 \\left( 1 - \\frac{\\lambda}{S_3^2} \\right) = 0 $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = -\\left( \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} - 1 \\right) = 0 $$\nThe last equation is simply the original constraint. From the first three equations, we analyze the conditions for a non-trivial solution (the origin $(\\sigma_1, \\sigma_2, \\sigma_3) = (0,0,0)$ is not on the ellipsoid, as it does not satisfy the constraint).\n\nCase 1: $\\sigma_1 \\neq 0$, $\\sigma_2 = 0$, $\\sigma_3 = 0$.\nThe first equation gives $1 - \\frac{\\lambda}{S_1^2} = 0$, which implies $\\lambda = S_1^2$. The second and third equations are satisfied since $\\sigma_2=0$ and $\\sigma_3=0$.\nSubstituting $\\sigma_2 = 0$ and $\\sigma_3 = 0$ into the constraint equation:\n$$ \\frac{\\sigma_1^2}{S_1^2} + 0 + 0 = 1 \\implies \\sigma_1^2 = S_1^2 \\implies \\sigma_1 = \\pm S_1 $$\nThe candidate points are $(\\pm S_1, 0, 0)$. The value of our objective function at these points is $f = (\\pm S_1)^2 + 0^2 + 0^2 = S_1^2$.\n\nCase 2: $\\sigma_2 \\neq 0$, $\\sigma_1 = 0$, $\\sigma_3 = 0$.\nThe second equation gives $1 - \\frac{\\lambda}{S_2^2} = 0$, which implies $\\lambda = S_2^2$.\nSubstituting $\\sigma_1 = 0$ and $\\sigma_3 = 0$ into the constraint equation:\n$$ 0 + \\frac{\\sigma_2^2}{S_2^2} + 0 = 1 \\implies \\sigma_2^2 = S_2^2 \\implies \\sigma_2 = \\pm S_2 $$\nThe candidate points are $(0, \\pm S_2, 0)$. The value of the objective function is $f = 0^2 + (\\pm S_2)^2 + 0^2 = S_2^2$.\n\nCase 3: $\\sigma_3 \\neq 0$, $\\sigma_1 = 0$, $\\sigma_2 = 0$.\nThe third equation gives $1 - \\frac{\\lambda}{S_3^2} = 0$, which implies $\\lambda = S_3^2$.\nSubstituting $\\sigma_1 = 0$ and $\\sigma_2 = 0$ into the constraint equation:\n$$ 0 + 0 + \\frac{\\sigma_3^2}{S_3^2} = 1 \\implies \\sigma_3^2 = S_3^2 \\implies \\sigma_3 = \\pm S_3 $$\nThe candidate points are $(0, 0, \\pm S_3)$. The value of the objective function is $f = 0^2 + 0^2 + (\\pm S_3)^2 = S_3^2$.\n\nOther cases where more than one component of $(\\sigma_1, \\sigma_2, \\sigma_3)$ is non-zero are not possible. For example, if $\\sigma_1 \\neq 0$ and $\\sigma_2 \\neq 0$, then from the first two partial derivative equations, we must have $\\lambda = S_1^2$ and $\\lambda = S_2^2$. This would mean $S_1^2 = S_2^2$, which contradicts the given condition that $S_1 > S_2 > S_3 > 0$.\n\nNow we compare the values of the objective function $f = M^2$ from the three cases: $S_1^2, S_2^2, S_3^2$.\nWe are given that $S_1 > S_2 > S_3 > 0$. Squaring these positive values preserves the inequality: $S_1^2 > S_2^2 > S_3^2$.\nThe maximum value of $f = M^2$ is therefore $S_1^2$.\nThe maximum value of the magnitude $M$ is the square root of this value.\n$$ M_{\\text{max}} = \\sqrt{S_1^2} = S_1 $$\n(We take the positive root since $M$ is a magnitude and $S_1$ is given as positive).",
            "answer": "$$\\boxed{S_1}$$"
        },
        {
            "introduction": "Building upon the single-constraint case, this problem introduces optimization with multiple equality constraints. We are tasked with finding the highest and lowest points on a curve formed by the intersection of two surfaces, a cone and a plane. The first-order necessary condition now requires the gradient of the objective function, $f(x,y,z) = z$, to be a linear combination of the gradients of the two constraint functions, which is a crucial generalization of the core principle .",
            "id": "2173347",
            "problem": "Consider a curve formed by the intersection of two surfaces in three-dimensional Euclidean space. The first surface is a double cone described by the equation $z^{2} = x^{2} + y^{2}$. The second surface is a plane defined by the equation $x + 2y + z = 4$.\n\nDetermine the maximum and minimum values of the $z$-coordinate for all points $(x,y,z)$ that lie on this intersection curve.\n\nProvide your answer as a pair of exact analytical values, ordered from the minimum value to the maximum value.",
            "solution": "We seek extrema of $f(x,y,z)=z$ on the curve defined by the constraints $g_{1}(x,y,z)=z^{2}-x^{2}-y^{2}=0$ and $g_{2}(x,y,z)=x+2y+z-4=0$. By the method of Lagrange multipliers, there exist $\\lambda$ and $\\mu$ such that\n$$\n\\nabla f=\\lambda\\,\\nabla g_{1}+\\mu\\,\\nabla g_{2}.\n$$\nCompute gradients: $\\nabla f=(0,0,1)$, $\\nabla g_{1}=(-2x,-2y,2z)$, and $\\nabla g_{2}=(1,2,1)$. Hence,\n$$\n(0,0,1)=\\lambda(-2x,-2y,2z)+\\mu(1,2,1).\n$$\nEquating components gives\n$$\n0=-2\\lambda x+\\mu,\\qquad 0=-2\\lambda y+2\\mu,\\qquad 1=2\\lambda z+\\mu.\n$$\nFrom the first two equations, $\\mu=2\\lambda x$ and $\\mu=\\lambda y$, so either $\\lambda=0$ or $y=2x$. If $\\lambda=0$, then $\\mu=0$ from the first equation, which contradicts the third equation $1=2\\lambda z+\\mu=0$. Therefore $\\lambda\\neq 0$ and $y=2x$.\n\nImpose the constraints with $y=2x$. The plane gives $x+2y+z=4$, i.e., $x+4x+z=4$, hence\n$$\nz=4-5x.\n$$\nThe cone gives $z^{2}=x^{2}+y^{2}=x^{2}+(2x)^{2}=5x^{2}$, i.e.,\n$$\nz^{2}=5x^{2}.\n$$\nSubstitute $z=4-5x$ into $z^{2}=5x^{2}$:\n$$\n(4-5x)^{2}=5x^{2}\\;\\;\\Longrightarrow\\;\\;16-40x+25x^{2}=5x^{2}\\;\\;\\Longrightarrow\\;\\;20x^{2}-40x+16=0.\n$$\nDivide by $4$ to obtain $5x^{2}-10x+4=0$, whose solutions are\n$$\nx=\\frac{10\\pm\\sqrt{100-80}}{10}=\\frac{10\\pm2\\sqrt{5}}{10}=1\\pm\\frac{\\sqrt{5}}{5}.\n$$\nThen\n$$\nz=4-5x=4-5\\left(1\\pm\\frac{\\sqrt{5}}{5}\\right)=-1\\mp\\sqrt{5}.\n$$\nThus the two critical $z$-values are $-1-\\sqrt{5}$ and $-1+\\sqrt{5}$. Since the intersection curve is bounded (an ellipse), these are respectively the minimum and maximum $z$-values on the curve.\n\nOrdered from minimum to maximum, the values are $-1-\\sqrt{5}$ and $-1+\\sqrt{5}$.",
            "answer": "$$\\boxed{\\begin{pmatrix}-1-\\sqrt{5} & -1+\\sqrt{5}\\end{pmatrix}}$$"
        },
        {
            "introduction": "This final practice problem demonstrates the versatility of constrained optimization by shifting from a purely geometric context to the realm of engineering model fitting. Here, we optimize a set of parameters for a trigonometric polynomial to best match a target model, while simultaneously satisfying a constraint from an experimental measurement. This exercise shows how the same first-order conditions can be applied in an abstract parameter space to solve practical problems in fields like signal processing and system identification .",
            "id": "2173359",
            "problem": "An engineer is modelling a periodic physical process using a trigonometric polynomial of the form $P(t) = c_1 \\cos(t) + c_2 \\sin(t) + c_3 \\cos(2t) + c_4 \\sin(2t)$. The coefficients are collected in a vector $\\mathbf{x} = (c_1, c_2, c_3, c_4)^T$. Based on prior theoretical work, an ideal set of coefficients is believed to be $\\mathbf{x}_{\\text{target}} = (2, 0, 1, 0)^T$. However, a new experimental measurement requires the model to satisfy the condition $P(\\pi/3) = 1$. The engineer decides to find the coefficient vector $\\mathbf{x}^*$ that is closest to the ideal vector $\\mathbf{x}_{\\text{target}}$ in a least-squares sense, while still satisfying the experimental constraint. This means minimizing the squared Euclidean norm $\\|\\mathbf{x} - \\mathbf{x}_{\\text{target}}\\|^2$. Determine the components of the optimal coefficient vector $\\mathbf{x}^* = (c_1^*, c_2^*, c_3^*, c_4^*)^T$. Present your answer as a row matrix containing the four coefficients in their exact fractional form.",
            "solution": "We minimize the squared Euclidean distance subject to a linear constraint. Let $\\mathbf{x}=(c_1,c_2,c_3,c_4)^T$, $\\mathbf{x}_{\\text{target}}=\\mathbf{x}_0=(2,0,1,0)^T$, and the constraint be $P(\\pi/3)=1$. This constraint can be written as $a^T\\mathbf{x}=b$ with\n$$\na=\\begin{pmatrix}\\cos(\\pi/3)\\\\ \\sin(\\pi/3)\\\\ \\cos(2\\pi/3)\\\\ \\sin(2\\pi/3)\\end{pmatrix}\n=\\begin{pmatrix}\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\\\ -\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\end{pmatrix},\\quad b=1.\n$$\nWe solve the constrained least-squares problem by orthogonal projection (equivalently, Lagrange multipliers). The standard result is\n$$\n\\mathbf{x}^{*}=\\mathbf{x}_{0}+\\frac{b-a^{T}\\mathbf{x}_{0}}{\\|a\\|^{2}}\\,a.\n$$\nCompute the needed quantities:\n$$\n\\|a\\|^{2}=\\left(\\frac{1}{2}\\right)^{2}+\\left(\\frac{\\sqrt{3}}{2}\\right)^{2}+\\left(-\\frac{1}{2}\\right)^{2}+\\left(\\frac{\\sqrt{3}}{2}\\right)^{2}=\\frac{1}{4}+\\frac{3}{4}+\\frac{1}{4}+\\frac{3}{4}=2,\n$$\n$$\na^{T}\\mathbf{x}_{0}=2\\cdot\\frac{1}{2}+0\\cdot\\frac{\\sqrt{3}}{2}+1\\cdot\\left(-\\frac{1}{2}\\right)+0\\cdot\\frac{\\sqrt{3}}{2}=\\frac{1}{2}.\n$$\nHence\n$$\n\\frac{b-a^{T}\\mathbf{x}_{0}}{\\|a\\|^{2}}=\\frac{1-\\frac{1}{2}}{2}=\\frac{1}{4},\n$$\nand therefore\n$$\n\\mathbf{x}^{*}=\\mathbf{x}_{0}+\\frac{1}{4}a=\\begin{pmatrix}2\\\\ 0\\\\ 1\\\\ 0\\end{pmatrix}+\\frac{1}{4}\\begin{pmatrix}\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\\\ -\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\end{pmatrix}=\\begin{pmatrix}\\frac{17}{8}\\\\ \\frac{\\sqrt{3}}{8}\\\\ \\frac{7}{8}\\\\ \\frac{\\sqrt{3}}{8}\\end{pmatrix}.\n$$\nA direct check shows $P(\\pi/3)=1$ with these coefficients, and they are the closest (in Euclidean norm) to $\\mathbf{x}_{\\text{target}}$ by construction.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{17}{8} & \\frac{\\sqrt{3}}{8} & \\frac{7}{8} & \\frac{\\sqrt{3}}{8}\\end{pmatrix}}$$"
        }
    ]
}