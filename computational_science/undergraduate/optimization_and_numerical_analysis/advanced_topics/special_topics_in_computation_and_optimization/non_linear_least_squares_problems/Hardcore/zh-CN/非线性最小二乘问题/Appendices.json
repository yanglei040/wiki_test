{
    "hands_on_practices": [
        {
            "introduction": "在深入研究复杂的优化算法之前，我们必须首先牢固掌握我们的目标是什么。非线性最小二乘法的核心是最小化模型预测与实际观测数据之间的误差平方和（Sum of Squared Errors, SSE）。这个练习  将带你计算给定模型和参数下的 SSE 值，这是评估模型拟合优度的第一步，也是所有后续优化工作的基础。",
            "id": "2214255",
            "problem": "在数据分析和数值优化领域，非线性最小二乘法是一种将模型拟合到一组观测数据点的基本技术。其目标是找到使观测数据与模型预测值之间平方差之和最小化的模型参数。\n\n考虑一个旨在描述饱和过程的模型，由以下函数给出：\n$$f(x, \\beta) = \\frac{\\beta_1}{1 + x^{\\beta_2}}$$\n其中 $\\beta = (\\beta_1, \\beta_2)$ 是模型参数的向量。\n\n假设一次实验产生两个数据点：$(x_1, y_1) = (1, 1)$ 和 $(x_2, y_2) = (2, 0.5)$。\n\n对于特定的参数选择，拟合的质量由误差平方和目标函数 $S(\\beta)$ 来量化，其定义为残差的平方和：\n$$S(\\beta) = \\sum_{i=1}^{2} (y_i - f(x_i, \\beta))^2$$\n\n作为像高斯-牛顿法这样的优化过程的第一步，必须在参数的初始猜测值处计算目标函数。计算特定参数向量 $\\beta = (2, 1)$ 时 $S(\\beta)$ 的值。\n\n将您的最终答案表示为最简精确分数。",
            "solution": "我们给定 $f(x,\\beta)=\\dfrac{\\beta_{1}}{1+x^{\\beta_{2}}}$ 和 $S(\\beta)=\\sum_{i=1}^{2}\\left(y_{i}-f(x_{i},\\beta)\\right)^{2}$，数据点为 $(x_{1},y_{1})=(1,1)$ 和 $(x_{2},y_{2})=(2,\\dfrac{1}{2})$。对于 $\\beta=(2,1)$，模型计算为\n$$\nf(x,(2,1))=\\frac{2}{1+x^{1}}=\\frac{2}{1+x}.\n$$\n在 $x_{1}=1$ 处，我们有\n$$\nf(1,(2,1))=\\frac{2}{1+1}=\\frac{2}{2}=1,\n$$\n所以残差为 $r_{1}=y_{1}-f(1,(2,1))=1-1=0$，得到 $r_{1}^{2}=0$。\n在 $x_{2}=2$ 处，我们有\n$$\nf(2,(2,1))=\\frac{2}{1+2}=\\frac{2}{3},\n$$\n所以残差为\n$$\nr_{2}=y_{2}-f(2,(2,1))=\\frac{1}{2}-\\frac{2}{3}=\\frac{3-4}{6}=-\\frac{1}{6},\n$$\n得到 $r_{2}^{2}=\\left(-\\frac{1}{6}\\right)^{2}=\\frac{1}{36}$。\n因此，\n$$\nS(\\beta)=r_{1}^{2}+r_{2}^{2}=0+\\frac{1}{36}=\\frac{1}{36}.\n$$",
            "answer": "$$\\boxed{\\frac{1}{36}}$$"
        },
        {
            "introduction": "掌握了目标函数的概念后，我们来实践一种强大的求解非线性最小二乘问题的算法：高斯-牛顿法。这个练习  将引导你对一个实际的光谱信号执行一次完整的高斯-牛顿迭代。通过亲手计算雅可比矩阵和求解正规方程，你将具体地理解该算法如何迭代地改进参数估计，以逼近最佳拟合。",
            "id": "2191243",
            "problem": "一位物理学家正在分析一个被认为源于单原子跃迁的光谱信号。光谱线的强度分布 $I$ 作为波长 $\\lambda$ 的函数，由一个高斯函数建模：\n$$ I(\\lambda) = A \\exp\\left(-\\frac{(\\lambda-\\mu)^2}{\\sigma^2}\\right) $$\n此处，$A$ 是峰值振幅，$\\mu$ 是平均波长（峰的中心），$\\sigma$ 是标准差，它表征了谱线的宽度。根据对实验装置的先验知识，谱线宽度参数已知为 $\\sigma^2 = 1.0 \\text{ nm}^2$。该物理学家旨在通过将模型与一组实验数据点进行拟合来确定 $A$ 和 $\\mu$ 的值。\n\n记录了以下三个不同波长下的强度测量值（单位任意）：\n- $(\\lambda_1, I_1) = (4.0 \\text{ nm}, 3.0)$\n- $(\\lambda_2, I_2) = (5.0 \\text{ nm}, 9.0)$\n- $(\\lambda_3, I_3) = (6.0 \\text{ nm}, 4.0)$\n\n为了找到参数 $\\boldsymbol{\\beta} = (A, \\mu)^T$ 的最优值，采用了非线性最小二乘法。从初始猜测值 $\\boldsymbol{\\beta}_0 = (A_0, \\mu_0)^T = (10.0, 5.0 \\text{ nm})^T$ 开始，执行单次高斯-牛顿算法迭代，以找到参数的更新估计值 $\\boldsymbol{\\beta}_1 = (A_1, \\mu_1)^T$。\n\n计算平均波长 $\\mu_1$ 的更新值。答案以 nm 为单位，并四舍五入到四位有效数字。",
            "solution": "我们将强度建模为 $f(\\lambda;A,\\mu)=A\\exp\\!\\left(-\\frac{(\\lambda-\\mu)^{2}}{\\sigma^{2}}\\right)$，其中已知 $\\sigma^{2}=1$。对于数据 $(\\lambda_{i},I_{i})$ 和当前参数 $\\boldsymbol{\\beta}_{0}=(A_{0},\\mu_{0})^{T}$，定义残差 $r_{i}=I_{i}-f(\\lambda_{i};A_{0},\\mu_{0})$ 和雅可比矩阵的元素\n$$\n\\frac{\\partial f}{\\partial A}(\\lambda_{i};A_{0},\\mu_{0})=\\exp\\!\\left(-(\\lambda_{i}-\\mu_{0})^{2}\\right),\\quad\n\\frac{\\partial f}{\\partial \\mu}(\\lambda_{i};A_{0},\\mu_{0})=A_{0}\\exp\\!\\left(-(\\lambda_{i}-\\mu_{0})^{2}\\right)\\cdot 2(\\lambda_{i}-\\mu_{0}).\n$$\n高斯-牛顿步长 $\\Delta\\boldsymbol{\\beta}$ 求解 $(J^{T}J)\\Delta\\boldsymbol{\\beta}=J^{T}\\boldsymbol{r}$，并且 $\\boldsymbol{\\beta}_{1}=\\boldsymbol{\\beta}_{0}+\\Delta\\boldsymbol{\\beta}$。\n\n给定 $(\\lambda_{1},I_{1})=(4,3)$，$(\\lambda_{2},I_{2})=(5,9)$，$(\\lambda_{3},I_{3})=(6,4)$ 和 $\\boldsymbol{\\beta}_{0}=(10,5)^{T}$，设 $a=\\exp(-1)$。那么\n- $\\exp\\!\\left(-(\\lambda_{1}-\\mu_{0})^{2}\\right)=\\exp(-1)=a$, $\\exp\\!\\left(-(\\lambda_{2}-\\mu_{0})^{2}\\right)=1$, $\\exp\\!\\left(-(\\lambda_{3}-\\mu_{0})^{2}\\right)=a$。\n- 模型值：$f_{1}=10a$, $f_{2}=10$, $f_{3}=10a$。\n- 残差：$r_{1}=3-10a$, $r_{2}=9-10=-1$, $r_{3}=4-10a$。\n\n在每个数据点处，雅可比矩阵的行 $(\\partial f/\\partial A,\\partial f/\\partial \\mu)$ 为\n- $i=1$: $(a,\\;10\\cdot a\\cdot 2(4-5))=(a,\\;-20a)$，\n- $i=2$: $(1,\\;10\\cdot 1\\cdot 2(5-5))=(1,\\;0)$，\n- $i=3$: $(a,\\;10\\cdot a\\cdot 2(6-5))=(a,\\;20a)$。\n\n因此\n$$\nJ^{T}J=\\begin{pmatrix}\na^{2}+1+a^{2}  & a(-20a)+1\\cdot 0+a(20a)\\\\\na(-20a)+1\\cdot 0+a(20a)  & (20a)^{2}+0^{2}+(20a)^{2}\n\\end{pmatrix}\n=\\begin{pmatrix}\n2a^{2}+1  & 0\\\\\n0  & 800a^{2}\n\\end{pmatrix},\n$$\n和\n$$\nJ^{T}\\boldsymbol{r}=\\begin{pmatrix}\na r_{1}+1\\cdot r_{2}+a r_{3}\\\\\n(-20a)r_{1}+0\\cdot r_{2}+(20a)r_{3}\n\\end{pmatrix}\n=\\begin{pmatrix}\na(r_{1}+r_{3})+r_{2}\\\\\n20a(r_{3}-r_{1})\n\\end{pmatrix}.\n$$\n使用 $r_{1}+r_{3}=(3-10a)+(4-10a)=7-20a$ 和 $r_{3}-r_{1}=(4-10a)-(3-10a)=1$，我们得到\n$$\nJ^{T}\\boldsymbol{r}=\\begin{pmatrix}\n7a-20a^{2}-1\\\\\n20a\n\\end{pmatrix}.\n$$\n由于 $J^{T}J$ 是对角矩阵，高斯-牛顿步长的分量为\n$$\n\\Delta A=\\frac{7a-20a^{2}-1}{2a^{2}+1},\\quad \\Delta\\mu=\\frac{20a}{800a^{2}}=\\frac{1}{40a}=\\frac{\\exp(1)}{40}.\n$$\n因此，\n$$\n\\mu_{1}=\\mu_{0}+\\Delta\\mu=5+\\frac{\\exp(1)}{40}.\n$$\n数值上，$\\exp(1)\\approx 2.718281828459045$，所以\n$$\n\\mu_{1}\\approx 5+0.067957045711476\\approx 5.067957045711476,\n$$\n四舍五入到四位有效数字为 $5.068$。",
            "answer": "$$\\boxed{5.068}$$"
        },
        {
            "introduction": "我们已经应用了高斯-牛顿法，但其成功的背后隐藏着一个关键的数学近似。为了真正掌握该方法，理解其原理和适用范围至关重要。这个练习  让你直面高斯-牛顿法的核心，通过比较其近似的Hessian矩阵 ($J^T J$) 与真实的Hessian矩阵，你将揭示该算法在小残差问题中表现优异的根本原因。",
            "id": "2214286",
            "problem": "考虑一个用于描述生长过程的单参数非线性模型，其函数为 $f(x; \\beta) = \\exp(\\beta x)$，其中 $\\beta$ 是模型参数。我们希望将此模型拟合到单个实验数据点 $(x_1, y_1) = (1, 3)$。\n\n对于给定的 $\\beta$，拟合的质量由最小二乘目标函数衡量。为与优化文献中的常见形式保持一致，该函数定义为残差平方的二分之一：\n$$ S(\\beta) = \\frac{1}{2}(f(x_1; \\beta) - y_1)^2 $$\n\n在优化中，目标函数的二阶导数（海森矩阵）提供了关于误差曲面曲率的信息。$S(\\beta)$ 的真实海森矩阵是标量 $H = \\frac{d^2S}{d\\beta^2}$。高斯-牛顿算法是求解非线性最小二乘问题的常用方法，它使用 $H_{GN} = J^T J$ 作为海森矩阵的近似，其中 $J$ 是残差函数 $r(\\beta) = f(x_1; \\beta) - y_1$ 的雅可比矩阵。由于只有一个参数和一个数据点，雅可比矩阵 $J$ 是一个 $1 \\times 1$ 矩阵。\n\n计算在特定参数值 $\\beta=1$ 时，真实海森矩阵与高斯-牛顿近似之间的确切差值 $\\Delta H = H - H_{GN}$。",
            "solution": "我们有一个单参数模型 $f(x;\\beta)=\\exp(\\beta x)$ 和一个数据点 $(x_{1},y_{1})=(1,3)$。残差定义为 $r(\\beta)=f(x_{1};\\beta)-y_{1}=\\exp(\\beta)-3$。根据问题定义，最小二乘目标函数为 $S(\\beta)=\\frac{1}{2}r(\\beta)^{2}$。\n\n为计算真实海森矩阵，我们对 $S(\\beta)$ 求二阶导数。使用链式法则：\n$$\n\\frac{dS}{d\\beta} = r(\\beta) \\cdot r'(\\beta)\n$$\n再次对 $\\beta$ 求导可得真实海森矩阵 $H$：\n$$\nH = \\frac{d^{2}S}{d\\beta^{2}} = (r'(\\beta))^{2} + r(\\beta) \\cdot r''(\\beta)\n$$\n对于 $r(\\beta)=\\exp(\\beta)-3$，我们有一阶导数 $r'(\\beta)=\\exp(\\beta)$ 和二阶导数 $r''(\\beta)=\\exp(\\beta)$。代入海森矩阵表达式：\n$$\nH = (\\exp(\\beta))^{2} + (\\exp(\\beta)-3)\\exp(\\beta) = \\exp(2\\beta) + \\exp(2\\beta) - 3\\exp(\\beta) = 2\\exp(2\\beta) - 3\\exp(\\beta)\n$$\n高斯-牛顿近似通过忽略包含残差 $r(\\beta)$ 的项来近似海森矩阵。在本问题中，雅可比矩阵 $J$ 是 $r'(\\beta)$，所以高斯-牛顿近似为：\n$$\nH_{GN} = J^T J = (r'(\\beta))^2 = (\\exp(\\beta))^2 = \\exp(2\\beta)\n$$\n真实海森矩阵与高斯-牛顿近似之间的差值为：\n$$\n\\Delta H = H - H_{GN} = (2\\exp(2\\beta) - 3\\exp(\\beta)) - \\exp(2\\beta) = \\exp(2\\beta) - 3\\exp(\\beta)\n$$\n在 $\\beta=1$ 处求值：\n$$\n\\Delta H = \\exp(2) - 3\\exp(1)\n$$",
            "answer": "$$\\boxed{\\exp(2)-3\\exp(1)}$$"
        }
    ]
}