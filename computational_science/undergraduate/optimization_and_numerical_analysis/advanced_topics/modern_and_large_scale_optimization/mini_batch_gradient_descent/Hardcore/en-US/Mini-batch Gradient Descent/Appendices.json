{
    "hands_on_practices": [
        {
            "introduction": "The journey into mini-batch gradient descent begins with its most fundamental component: the parameter update rule. This exercise strips away all other complexities to focus on this single, crucial step. By taking a pre-calculated gradient, you'll see exactly how a model parameter is nudged in the right direction to minimize error, providing a solid foundation for more complex scenarios. ",
            "id": "2187026",
            "problem": "A computational science student is training a simple predictive model. The model's behavior is controlled by a single dimensionless parameter, $\\theta$. The goal is to find the value of $\\theta$ that minimizes the model's prediction error, which is measured by a cost function $J(\\theta)$.\n\nThe student employs a numerical optimization technique known as gradient descent. The process starts with an initial guess for the parameter and iteratively refines it. Each update step is designed to move the parameter value in the direction opposite to the cost function's gradient. The magnitude of each step is determined by a parameter called the learning rate.\n\nThe student initializes the parameter at $\\theta_0 = 2$. For the first iteration, they use a subset of their data to compute the gradient of the cost function with respect to the parameter at this initial point. The computation yields a gradient value of $\\nabla J(\\theta_0) = 4$. The learning rate for the optimization process is set to $\\eta = 0.01$.\n\nCalculate the updated value of the parameter, $\\theta_1$, after this first iteration. Report your answer to three significant figures.",
            "solution": "We use the standard gradient descent update rule for a single parameter:\n$$\n\\theta_{k+1} = \\theta_{k} - \\eta \\frac{dJ}{d\\theta}\\bigg|_{\\theta=\\theta_{k}}.\n$$\nFor the first iteration with $k=0$, the given values are $\\theta_{0} = 2$, learning rate $\\eta = 0.01$, and gradient $\\nabla J(\\theta_{0}) = 4$. Substituting these into the update rule gives:\n$$\n\\theta_{1} = \\theta_{0} - \\eta \\nabla J(\\theta_{0}) = 2 - 0.01 \\times 4.\n$$\nCompute the product:\n$$\n0.01 \\times 4 = 0.04,\n$$\nso\n$$\n\\theta_{1} = 2 - 0.04 = 1.96.\n$$\nRounded to three significant figures, the value is $1.96$.",
            "answer": "$$\\boxed{1.96}$$"
        },
        {
            "introduction": "Having mastered the basic update rule, we now connect it to the data itself. In practice, the gradient is not just given; it is calculated from a mini-batch of data and a chosen cost function. This problem has you compute the gradient for a simple model before performing the update, illustrating the complete mini-batch workflow from a data sample to a refined parameter. ",
            "id": "2187016",
            "problem": "An engineer is developing a simple smart thermostat. The thermostat's goal is to learn a desired room temperature. The thermostat has a single internal parameter, $w$, which represents its current temperature setting in degrees Celsius. The model for the thermostat's setting is simple: the output setting is just the value of the parameter $w$, independent of any external sensor readings.\n\nTo train this parameter, the engineer uses a cost function $J(w; y) = (w - y)^2$, where $y$ is the target temperature in degrees Celsius provided by the user. The parameter $w$ is updated using mini-batch gradient descent.\n\nThe initial setting of the thermostat is $w_0 = 5.0$ degrees Celsius. The learning rate for the update algorithm is set to $\\eta = 0.1$. For the first training step, a mini-batch consisting of a single data point is used. This data point corresponds to a user's desired target temperature of $y = 10.0$ degrees Celsius.\n\nCalculate the value of the thermostat's parameter, $w_1$, after this single update step. Express your answer in degrees Celsius.",
            "solution": "The cost function is $J(w; y) = (w - y)^{2}$. Its gradient with respect to $w$ is obtained by differentiating:\n$$\n\\frac{\\partial J}{\\partial w} = 2(w - y).\n$$\nUsing mini-batch gradient descent with learning rate $\\eta$, the update rule is\n$$\nw_{1} = w_{0} - \\eta \\left.\\frac{\\partial J}{\\partial w}\\right|_{w=w_{0}}.\n$$\nSubstitute $w_{0} = 5.0$, $y = 10.0$, and $\\eta = 0.1$:\n$$\n\\left.\\frac{\\partial J}{\\partial w}\\right|_{w=w_{0}} = 2(5.0 - 10.0) = 2(-5.0) = -10.0,\n$$\n$$\nw_{1} = 5.0 - 0.1 \\times (-10.0) = 5.0 + 1.0 = 6.\n$$\nThus, after one update step, the thermostat parameter is $6$ in degrees Celsius.",
            "answer": "$$\\boxed{6}$$"
        },
        {
            "introduction": "Why is mini-batch gradient descent considered 'stochastic'? This question is best answered by exploring a scenario where the source of randomness is removed. This thought experiment challenges you to predict the algorithm's behavior on a dataset with no variation between data points. By doing so, you will gain a deeper intuition for the relationship between mini-batch and full-batch gradient descent and understand the fundamental reason for the noisy yet efficient convergence of mini-batch methods. ",
            "id": "2187032",
            "problem": "Consider a machine learning task where the objective is to find a set of model parameters, denoted by a vector $w$, that minimizes a total loss function $L(w)$. The total loss is defined as the average loss over a dataset of $N$ data points: $L(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\ell_i(w)$, where $\\ell_i(w)$ is the loss associated with the $i$-th data point.\n\nWe will use mini-batch Gradient Descent (GD) to perform this optimization. In each step of this algorithm, a small \"mini-batch\" of $b$ data points is randomly selected from the full dataset, where $1  b  N$. The gradient of the loss is computed only on this mini-batch, and the parameters are updated.\n\nNow, consider a very specific and unusual dataset where every single data point is identical. That is, the features and the corresponding label are exactly the same for all $N$ points in the dataset. Let's assume that the gradient of the loss for this single unique data point is not zero at the initial parameter values $w_0$.\n\nGiven this scenario, which of the following statements most accurately describes the behavior of the mini-batch GD algorithm compared to standard full-batch GD, assuming both start with the same initial parameters $w_0$ and use the same learning rate $\\eta$?\n\nA. Mini-batch GD will converge significantly faster to the minimum than full-batch GD because the per-step computation is lighter, while following a similar optimization path.\n\nB. The gradient calculated for any mini-batch will be zero, causing the learning process to stall immediately.\n\nC. Mini-batch GD will follow the exact same optimization trajectory (i.e., generate the same sequence of parameter vectors) as full-batch GD.\n\nD. The variance of the gradient estimates from different mini-batches will be maximized, leading to a highly erratic and unstable optimization path.\n\nE. Different mini-batches will yield different gradient estimates, causing the parameters to follow a stochastic path toward the minimum, which is the standard behavior of mini-batch GD.",
            "solution": "Define the per-example loss as $\\ell_{i}(w)$ for $i \\in \\{1,\\dots,N\\}$ and the empirical risk as\n$$\nL(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\ell_{i}(w).\n$$\nIn the given dataset, every data point is identical, so there exists a single function $\\ell(w)$ such that $\\ell_{i}(w) = \\ell(w)$ for all $i$. Therefore,\n$$\nL(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\ell(w) = \\ell(w).\n$$\nTaking gradients,\n$$\n\\nabla L(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\nabla \\ell_{i}(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\nabla \\ell(w) = \\nabla \\ell(w).\n$$\nFull-batch gradient descent (GD) with learning rate $\\eta$ and initialization $w_{0}$ performs updates\n$$\nw_{t+1}^{\\mathrm{FB}} = w_{t}^{\\mathrm{FB}} - \\eta \\nabla L\\!\\left(w_{t}^{\\mathrm{FB}}\\right) = w_{t}^{\\mathrm{FB}} - \\eta \\nabla \\ell\\!\\left(w_{t}^{\\mathrm{FB}}\\right).\n$$\nMini-batch gradient descent with batch size $b$ selects indices $\\{i_{1},\\dots,i_{b}\\}$ and uses the mini-batch gradient\n$$\ng_{t}^{\\mathrm{MB}}(w) = \\frac{1}{b} \\sum_{j=1}^{b} \\nabla \\ell_{i_{j}}(w).\n$$\nBecause all examples are identical, $\\nabla \\ell_{i_{j}}(w) = \\nabla \\ell(w)$ for all $j$, hence\n$$\ng_{t}^{\\mathrm{MB}}(w) = \\frac{1}{b} \\sum_{j=1}^{b} \\nabla \\ell(w) = \\nabla \\ell(w) = \\nabla L(w).\n$$\nThus the mini-batch update is\n$$\nw_{t+1}^{\\mathrm{MB}} = w_{t}^{\\mathrm{MB}} - \\eta\\, g_{t}^{\\mathrm{MB}}\\!\\left(w_{t}^{\\mathrm{MB}}\\right) = w_{t}^{\\mathrm{MB}} - \\eta \\nabla \\ell\\!\\left(w_{t}^{\\mathrm{MB}}\\right).\n$$\nComparing the full-batch and mini-batch updates shows they are identically defined at each iteration when initialized at the same $w_{0}$ and using the same $\\eta$. By induction on $t$, $w_{t}^{\\mathrm{MB}} = w_{t}^{\\mathrm{FB}}$ for all $t$. The assumption that $\\nabla \\ell(w_{0}) \\neq 0$ ensures that the first step is nontrivial, but does not alter the equality of the update rules.\n\nConsequently:\n- The mini-batch gradient has zero variance across batches, so there is no stochasticity (ruling out D and E).\n- The gradient is not zero at $w_{0}$, so updates do not stall (ruling out B).\n- Although per-step computation for a mini-batch is lighter than for a full batch, the optimization trajectory and number of steps are identical; therefore the most accurate statement about behavior is that both methods follow the exact same sequence of parameters (ruling out A as stated).\n\nTherefore, the correct choice is that mini-batch GD follows the exact same optimization trajectory as full-batch GD.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}