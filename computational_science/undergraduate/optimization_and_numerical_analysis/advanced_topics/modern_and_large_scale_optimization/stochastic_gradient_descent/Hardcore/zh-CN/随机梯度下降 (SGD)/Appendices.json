{
    "hands_on_practices": [
        {
            "introduction": "理论的最好补充就是实践。让我们从一个基础练习开始，亲手计算随机梯度下降（SGD）的单次更新步骤。这个练习将帮助你熟悉 SGD 的核心更新法则，并理解如何利用单个数据点的信息来调整模型参数 。",
            "id": "2206637",
            "problem": "一个迭代优化算法用于寻找使成本函数最小化的参数 $x$。总成本函数是几个分量函数的平均值：$F(x) = \\frac{1}{N}\\sum_{i=1}^{N} f_i(x)$。在这个具体案例中，分量函数是二次的，由 $f_i(x) = (x - c_i)^2$ 给出，其中常数 $c_i = i$，$i = 1, 2, \\dots, 10$，因此 $N=10$。\n\n优化过程从参数的初始猜测值 $x_0$ 开始。在每一步中，通过仅使用一个随机选择的分量函数 $f_j(x)$，从当前估计值 $x_k$ 计算出新的估计值 $x_{k+1}$。更新规则定义为：\n$$x_{k+1} = x_k - \\eta \\left( \\frac{d f_j(x)}{dx} \\bigg|_{x=x_k} \\right)$$\n其中 $\\eta$ 是一个称为学习率的常数。\n\n给定初始参数值 $x_0 = 10.0$ 和学习率 $\\eta = 0.1$，计算经过一次更新步骤后参数 $x_1$ 的值。对于这第一步，使用的分量函数是索引为 $j=5$ 的 $f_j(x)$。",
            "solution": "我们给定的分量函数形式为 $f_{i}(x) = (x - c_{i})^{2}$，其中 $c_{i} = i$。对于第一次更新，选择的索引是 $j=5$，所以 $f_{5}(x) = (x - 5)^{2}$。\n\n更新规则是\n$$\nx_{k+1} = x_{k} - \\eta \\left.\\frac{d f_{j}(x)}{dx}\\right|_{x=x_{k}}.\n$$\n使用幂法则和链式法则，所选分量函数的导数是\n$$\n\\frac{d f_{5}(x)}{dx} = \\frac{d}{dx}\\left[(x - 5)^{2}\\right] = 2(x - 5).\n$$\n在当前迭代点 $x_{0} = 10$ 处求值，得到\n$$\n\\left.\\frac{d f_{5}(x)}{dx}\\right|_{x=10} = 2(10 - 5) = 10.\n$$\n学习率为 $\\eta = 0.1$，更新变为\n$$\nx_{1} = x_{0} - \\eta \\cdot 10 = 10 - 0.1 \\times 10 = 10 - 1 = 9.\n$$\n因此，在使用 $f_5$ 进行一次更新步骤后，参数值为 $x_{1} = 9$。",
            "answer": "$$\\boxed{9}$$"
        },
        {
            "introduction": "随机梯度下降中的“随机”二字是其精髓所在。通过计算随机梯度的方差，这个练习揭示了为什么 SGD 的收敛路径是“嘈杂”的，但其期望方向却是正确的 。理解梯度的方差是掌握 SGD 行为及其与全批量梯度下降区别的关键。",
            "id": "2206620",
            "problem": "在许多机器学习问题中，目标是最小化一个损失函数 $F(x)$，该函数在结构上是一个数据集上的平均值。一种常见的形式是 $F(x) = \\frac{1}{N} \\sum_{i=1}^{N} f_i(x)$，其中 $f_i(x)$ 是与第 $i$ 个数据点相关的损失，$x$ 是一个模型参数。\n\n考虑一个简化的一维问题，我们想要找到最小化损失函数的参数 $x$。数据集仅包含两个数据点（$N=2$），由此得到以下分量损失函数：\n$$f_1(x) = (x-2)^2$$\n$$f_2(x) = (x+2)^2$$\n因此，总损失函数为 $F(x) = \\frac{1}{2} (f_1(x) + f_2(x))$。\n\n随机梯度下降（SGD）是一种迭代优化算法，它在每一步都近似 $F(x)$ 的真实梯度。在其最简单的形式中，一个随机梯度估计量（我们记为 $g(x)$）的计算方法是：首先从 $\\{1, 2\\}$ 中均匀随机地选择一个索引 $i$，然后计算相应分量函数的梯度，即 $g(x) = \\nabla f_i(x)$。在这个一维情况下，梯度算子 $\\nabla$ 就是关于 $x$ 的导数，即 $\\frac{d}{dx}$。\n\n计算随机梯度估计量 $g(x)$ 在特定点 $x = 1$ 处的方差。",
            "solution": "给定 $f_{1}(x)=(x-2)^{2}$ 和 $f_{2}(x)=(x+2)^{2}$，随机梯度估计量 $g(x)$ 的定义是从 $\\{1,2\\}$ 中均匀选择 $i$ 并设 $g(x)=\\frac{d}{dx}f_{i}(x)$。首先计算分量梯度：\n$$\n\\frac{d}{dx}f_{1}(x)=2(x-2), \\quad \\frac{d}{dx}f_{2}(x)=2(x+2).\n$$\n在 $x=1$ 处，$g(1)$ 的取值为\n$$\ng(1)=2(1-2)=-2 \\quad \\text{with probability } \\frac{1}{2}, \\quad g(1)=2(1+2)=6 \\quad \\text{with probability } \\frac{1}{2}.\n$$\n计算 $g(1)$ 的均值（期望）：\n$$\n\\mathbb{E}[g(1)]=\\frac{1}{2}(-2)+\\frac{1}{2}(6)=2.\n$$\n这等于 $F$ 在 $x=1$ 处的真实梯度，因为\n$$\nF'(x)=\\frac{1}{2}\\left(2(x-2)+2(x+2)\\right)=2x \\implies F'(1)=2.\n$$\n计算二阶矩：\n$$\n\\mathbb{E}[g(1)^{2}]=\\frac{1}{2}\\left((-2)^{2}+6^{2}\\right)=\\frac{1}{2}(4+36)=20.\n$$\n因此，方差为\n$$\n\\operatorname{Var}(g(1))=\\mathbb{E}[g(1)^{2}]-\\left(\\mathbb{E}[g(1)]\\right)^{2}=20-2^{2}=16.\n$$\n因此，随机梯度估计量在 $x=1$ 处的方差是 $16$。",
            "answer": "$$\\boxed{16}$$"
        },
        {
            "introduction": "在梯度下降中，我们期望每一步都朝着目标函数的更低点前进，但 SGD 的行为可能出乎意料。这个练习将通过一个具体的例子表明，一次针对单个样本的“正确”更新，有时反而会导致整体损失函数值的增加 。这个反直觉的结果突显了 SGD 路径的复杂性，并解释了为什么我们需要从宏观上评估其收敛性。",
            "id": "2206653",
            "problem": "在机器学习领域，优化算法通过最小化损失函数来训练模型参数。考虑一个具有单个标量参数 $w$ 的简单模型。目标是最小化总损失函数 $F(w)$，它被定义为一个包含两个数据点的小型数据集上各个损失函数的平均值。总损失函数由下式给出：\n\n$$F(w) = \\frac{1}{2}\\left[f_1(w) + f_2(w)\\right]$$\n\n与这两个数据点相关的各个损失函数为：\n\n$$f_1(w) = \\frac{1}{2}(w - 2)^2$$\n$$f_2(w) = \\frac{1}{2}(w - 10)^2$$\n\n训练过程从初始参数值 $w_0 = 3$ 开始。使用学习率为 $\\eta = 2$ 的随机梯度下降（SGD）算法执行单次更新步骤。对于本次特定更新，仅使用第一个数据点的损失函数 $f_1(w)$ 来计算梯度。\n\n计算由这次SGD单次更新导致的总体损失函数值的变化量 $F(w_1) - F(w_0)$。将您的最终答案四舍五入到三位有效数字。",
            "solution": "我们已知 $F(w)=\\frac{1}{2}\\left[f_{1}(w)+f_{2}(w)\\right]$，其中 $f_{1}(w)=\\frac{1}{2}(w-2)^{2}$ 且 $f_{2}(w)=\\frac{1}{2}(w-10)^{2}$。初始参数为 $w_{0}=3$。学习率为 $\\eta=2$ 的单次SGD步骤仅使用 $f_{1}$ 的梯度。\n\n一维的SGD更新规则是\n$$\nw_{1}=w_{0}-\\eta\\,\\frac{d f_{1}}{d w}\\bigg|_{w=w_{0}}.\n$$\n计算导数：\n$$\n\\frac{d f_{1}}{d w}=\\frac{d}{d w}\\left[\\frac{1}{2}(w-2)^{2}\\right]=(w-2).\n$$\n在 $w_{0}=3$ 处求值：\n$$\n\\frac{d f_{1}}{d w}\\bigg|_{w=3}=3-2=1.\n$$\n因此更新后的参数是\n$$\nw_{1}=3-2\\cdot 1=1.\n$$\n\n现在计算 $F(w_{0})$：\n$$\nf_{1}(3)=\\frac{1}{2}(3-2)^{2}=\\frac{1}{2},\\quad f_{2}(3)=\\frac{1}{2}(3-10)^{2}=\\frac{1}{2}\\cdot 49=\\frac{49}{2},\n$$\n$$\nF(3)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{49}{2}\\right)=\\frac{1}{2}\\cdot\\frac{50}{2}=\\frac{1}{2}\\cdot 25=\\frac{25}{2}.\n$$\n\n计算 $F(w_{1})$：\n$$\nf_{1}(1)=\\frac{1}{2}(1-2)^{2}=\\frac{1}{2},\\quad f_{2}(1)=\\frac{1}{2}(1-10)^{2}=\\frac{1}{2}\\cdot 81=\\frac{81}{2},\n$$\n$$\nF(1)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{81}{2}\\right)=\\frac{1}{2}\\cdot\\frac{82}{2}=\\frac{1}{2}\\cdot 41=\\frac{41}{2}.\n$$\n\n因此，总损失的变化量为\n$$\nF(w_{1})-F(w_{0})=\\frac{41}{2}-\\frac{25}{2}=\\frac{16}{2}=8.\n$$\n四舍五入到三位有效数字，结果为 $8.00$。",
            "answer": "$$\\boxed{8.00}$$"
        }
    ]
}