{
    "hands_on_practices": [
        {
            "introduction": "Simulated Annealing navigates a complex solution landscape by iteratively moving from a current solution to a nearby one. This exercise  makes the abstract concept of a solution \"neighborhood\" concrete, which defines the set of all possible moves from any given point. By exploring a specific neighborhood structure for the classic Traveling Salesperson Problem, you will develop a foundational understanding of how local search algorithms explore the space of possibilities.",
            "id": "2202549",
            "problem": "In the field of optimization, Simulated Annealing (SA) is a probabilistic technique used to find an approximate global optimum of a given function. Consider its application to a simplified version of the Traveling Salesperson Problem (TSP), where the goal is to find the shortest possible route that visits a set of cities and returns to the origin city.\n\nA \"state\" in this context is defined as a specific tour, represented by an ordered list (a permutation) of the cities to be visited. An algorithm is exploring the solution space for a problem with five distinct cities, labeled C1, C2, C3, C4, and C5.\n\nAt a certain step, the algorithm is at the current state $S = [\\text{C1, C2, C3, C4, C5}]$. To generate candidate moves, the algorithm defines a \"neighborhood\" of the current state. For this particular implementation, the neighborhood function is defined as follows: A new state is in the neighborhood of $S$ if and only if it can be obtained by swapping exactly one pair of adjacent cities in the list representing $S$.\n\nWhich of the following sets correctly and completely represents the neighborhood of the state $S$?\n\nA. $\\{[\\text{C2, C1, C3, C4, C5}], [\\text{C1, C3, C2, C4, C5}], [\\text{C1, C2, C4, C3, C5}], [\\text{C1, C2, C3, C5, C4}]\\}$\n\nB. $\\{[\\text{C5, C2, C3, C4, C1}], [\\text{C1, C4, C3, C2, C5}], [\\text{C1, C2, C5, C4, C3}]\\}$\n\nC. $\\{[\\text{C2, C1, C3, C4, C5}], [\\text{C1, C3, C2, C4, C5}], [\\text{C1, C2, C4, C3, C5}]\\}$\n\nD. $\\{[\\text{C2, C1, C3, C4, C5}], [\\text{C1, C3, C2, C4, C5}], [\\text{C1, C2, C4, C3, C5}], [\\text{C1, C2, C3, C5, C4}], [\\text{C1, C2, C3, C4, C5}]\\}$\n\nE. $\\{[\\text{C3, C2, C1, C4, C5}], [\\text{C1, C4, C3, C2, C5}], [\\text{C1, C2, C5, C4, C3}], [\\text{C5, C2, C3, C4, C1}]\\}$",
            "solution": "We are given the current state $S = [\\text{C1, C2, C3, C4, C5}]$ and a neighborhood defined by swapping exactly one pair of adjacent cities. In a list of length $n$, there are $n-1$ adjacent pairs; here $n=5$, so there are $5-1=4$ adjacent pairs: $(\\text{C1, C2})$, $(\\text{C2, C3})$, $(\\text{C3, C4})$, and $(\\text{C4, C5})$.\n\nSwapping each adjacent pair exactly once yields the following distinct neighbor states:\n- Swap $\\text{C1}$ and $\\text{C2}$: $[\\text{C2, C1, C3, C4, C5}]$.\n- Swap $\\text{C2}$ and $\\text{C3}$: $[\\text{C1, C3, C2, C4, C5}]$.\n- Swap $\\text{C3}$ and $\\text{C4}$: $[\\text{C1, C2, C4, C3, C5}]$.\n- Swap $\\text{C4}$ and $\\text{C5}$: $[\\text{C1, C2, C3, C5, C4}]$.\n\nTherefore, the neighborhood consists of exactly these four states. Comparing with the options:\n- A lists exactly these four states.\n- C omits $[\\text{C1, C2, C3, C5, C4}]$.\n- D incorrectly includes the original state, which requires zero swaps, violating the “exactly one” condition.\n- B and E include states not obtainable by a single adjacent swap.\n\nThus, the correct and complete set is given by option A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The true power of Simulated Annealing lies in its probabilistic acceptance of \"uphill\" moves—those that temporarily worsen the solution—to escape local optima. This decision is governed by the Metropolis criterion, where the temperature parameter $T$ acts as the crucial control knob. This practice  challenges you to quantify the effect of changing the temperature, building a strong intuition for how $T$ mediates the fundamental trade-off between broadly exploring the solution space and converging on a high-quality solution.",
            "id": "2202501",
            "problem": "An engineer is using a computational optimization algorithm to determine the optimal layout of components on a circuit board. The quality of any given layout is quantified by a cost function, $E$, where a lower cost represents a better design. The algorithm proceeds by iteratively proposing small changes to the layout. If a proposed change decreases the cost, it is always accepted. However, to avoid getting stuck in suboptimal solutions, the algorithm can sometimes accept a change that increases the cost.\n\nThe probability, $P$, of accepting a \"worse\" move that increases the cost by an amount $\\Delta E > 0$ is governed by the relation:\n$$\nP = \\exp\\left(-\\frac{\\Delta E}{T}\\right)\n$$\nwhere $T$ is a positive control parameter known as the \"computational temperature\".\n\nDuring an optimization process, the algorithm considers a specific layout modification that is known to increase the cost function by $\\Delta E = 12.5$ units. In one version of the algorithm, the computational temperature at this stage is set to $T_1 = 25.0$. In a second, more exploratory version, the temperature for the same stage is set higher, at $T_2 = 40.0$.\n\nBy what factor is the probability of accepting this specific detrimental move multiplied when the computational temperature is increased from $T_1$ to $T_2$? Provide your answer as a numerical value rounded to three significant figures.",
            "solution": "The acceptance probability for a detrimental move is given by $P = \\exp\\left(-\\frac{\\Delta E}{T}\\right)$. Let $P_{1}$ be the probability at temperature $T_{1}$ and $P_{2}$ at temperature $T_{2}$. The factor by which the probability is multiplied when increasing the temperature from $T_{1}$ to $T_{2}$ is\n$$\n\\frac{P_{2}}{P_{1}}=\\frac{\\exp\\left(-\\frac{\\Delta E}{T_{2}}\\right)}{\\exp\\left(-\\frac{\\Delta E}{T_{1}}\\right)}=\\exp\\left(-\\frac{\\Delta E}{T_{2}}+\\frac{\\Delta E}{T_{1}}\\right)=\\exp\\left(\\Delta E\\left(\\frac{1}{T_{1}}-\\frac{1}{T_{2}}\\right)\\right).\n$$\nSubstitute $\\Delta E=12.5$, $T_{1}=25.0$, and $T_{2}=40.0$:\n$$\n\\frac{P_{2}}{P_{1}}=\\exp\\left(12.5\\left(\\frac{1}{25.0}-\\frac{1}{40.0}\\right)\\right)=\\exp\\left(12.5\\left(0.04-0.025\\right)\\right)=\\exp\\left(12.5\\times 0.015\\right)=\\exp(0.1875).\n$$\nNumerically,\n$$\n\\exp(0.1875)\\approx 1.20623,\n$$\nwhich to three significant figures is $1.21$.",
            "answer": "$$\\boxed{1.21}$$"
        },
        {
            "introduction": "The performance of Simulated Annealing is critically dependent on the \"cooling schedule,\" which dictates how the temperature $T$ is lowered over time. A well-designed schedule allows the algorithm to explore freely at the start and then gradually zero in on a global optimum. This advanced, hands-on coding practice  models the entire SA process to analyze how different cooling schedules—such as exponential, linear, and logarithmic—affect the search. By implementing and comparing these strategies, you will gain insight into the theoretical underpinnings and practical consequences of choosing a cooling schedule.",
            "id": "2435160",
            "problem": "You are given a simplified, mathematically explicit model of Simulated Annealing (SA) for a one-dimensional domain with a single, extremely narrow global minimum (the \"needle\") embedded in a large suboptimal region (the \"haystack\"). The system is modeled as a time-inhomogeneous two-state Markov chain representing whether the current state is inside or outside the needle region. Let the two states be denoted by state $\\mathsf{B}$ (inside the needle, energy $0$) and state $\\mathsf{A}$ (outside the needle, energy $\\Delta$), where $\\Delta \\gt 0$ is a fixed energy gap.\n\nThe process evolves in discrete steps indexed by $k \\in \\{1,2,\\dots,N\\}$ with initial condition at step $k=0$ being outside the needle, i.e., in state $\\mathsf{A}$. At each step $k$, a candidate move is proposed. The following assumptions define the transition structure:\n- While in state $\\mathsf{A}$ at the beginning of a step, the proposal lands in state $\\mathsf{B}$ with an iteration-independent probability $p_{\\mathrm{in}} \\in (0,1)$, and otherwise remains in state $\\mathsf{A}$; the Metropolis acceptance rule of Simulated Annealing (SA) accepts any decrease in energy, so a proposed move from $\\mathsf{A}$ to $\\mathsf{B}$ is accepted with probability $1$.\n- While in state $\\mathsf{B}$ at the beginning of a step, any proposed move that would leave $\\mathsf{B}$ is considered an uphill move by energy $\\Delta$, and its acceptance probability is given by the Metropolis rule $\\min\\{1,\\exp(-\\Delta/T_k)\\}$, where $T_k \\gt 0$ is the temperature at step $k$. Because the needle is extremely narrow, take the proposal to leave $\\mathsf{B}$ as always available, so the net probability to exit $\\mathsf{B}$ at step $k$ equals $\\exp(-\\Delta/T_k)$.\n\nThe temperature $T_k$ is governed by an acceptance schedule (cooling schedule). Three standard classes of temperature schedules are to be considered, defined for $k \\in \\{1,2,\\dots,N\\}$:\n1. Exponential cooling: $T_k = T_0 \\,\\alpha^{\\,k-1}$ with $T_0 \\gt 0$ and $\\alpha \\in (0,1]$.\n2. Linear cooling: $T_k = \\dfrac{T_0}{1+\\beta\\,(k-1)}$ with $T_0 \\gt 0$ and $\\beta \\gt 0$.\n3. Logarithmic cooling: $T_k = \\dfrac{c}{\\ln(k_0 + k - 1)}$ with $c \\gt 0$ and $k_0 \\gt 1$, where $\\ln(\\cdot)$ denotes the natural logarithm.\n\nDefine the following quantities of interest:\n- The probability of being inside the needle at the end of step $N$, denoted $p_{\\mathrm{final}}(N)$.\n- The expected fraction of steps spent inside the needle over steps $1$ through $N$, defined as $f_{\\mathrm{occ}}(N) = \\dfrac{1}{N}\\sum_{k=1}^{N} \\Pr(\\text{in }\\mathsf{B}\\text{ at end of step }k)$.\n- The probability of ever having visited the needle by step $N$, denoted $p_{\\mathrm{ever}}(N)$.\n\nAll probabilities must be expressed as decimals in $[0,1]$.\n\nYour task is to write a complete, runnable program that, for each test case in the suite below, computes the triple $\\bigl(p_{\\mathrm{final}}(N), f_{\\mathrm{occ}}(N), p_{\\mathrm{ever}}(N)\\bigr)$ according to the model and definitions above, using the specified schedule and parameters. For each test case, assume the process starts in state $\\mathsf{A}$ at step $k=0$.\n\nTest suite (each case specifies the schedule type and its parameters, followed by $\\Delta$, $p_{\\mathrm{in}}$, and $N$):\n- Case $\\mathsf{A}$ (exponential cooling): $T_k = T_0 \\alpha^{k-1}$ with $T_0 = 5.0$, $\\alpha = 0.9995$, $\\Delta = 5.0$, $p_{\\mathrm{in}} = 10^{-4}$, $N = 20000$.\n- Case $\\mathsf{B}$ (linear cooling): $T_k = \\dfrac{T_0}{1+\\beta (k-1)}$ with $T_0 = 5.0$, $\\beta = 5\\times 10^{-5}$, $\\Delta = 5.0$, $p_{\\mathrm{in}} = 10^{-4}$, $N = 20000$.\n- Case $\\mathsf{C}$ (logarithmic cooling): $T_k = \\dfrac{2.0}{\\ln(10.0 + k - 1)}$ with $c = 2.0$, $k_0 = 10.0$, $\\Delta = 5.0$, $p_{\\mathrm{in}} = 10^{-4}$, $N = 20000$.\n- Case $\\mathsf{D}$ (constant temperature, as a special case of exponential cooling): $T_k = T_0$ with $T_0 = 5.0$, $\\alpha = 1.0$, $\\Delta = 1.0$, $p_{\\mathrm{in}} = 10^{-4}$, $N = 20000$.\n- Case $\\mathsf{E}$ (exponential cooling with rare entry): $T_k = T_0 \\alpha^{k-1}$ with $T_0 = 3.0$, $\\alpha = 0.9999$, $\\Delta = 5.0$, $p_{\\mathrm{in}} = 10^{-6}$, $N = 200000$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results for all cases in order $\\mathsf{A}$, $\\mathsf{B}$, $\\mathsf{C}$, $\\mathsf{D}$, $\\mathsf{E}$, as a comma-separated list enclosed in square brackets. For each case, append the three values in the order $\\bigl(p_{\\mathrm{final}}(N), f_{\\mathrm{occ}}(N), p_{\\mathrm{ever}}(N)\\bigr)$, each rounded to six decimal places. The final output thus contains $15$ numbers in total. For example, the output must be of the form $\\bigl[ x_{\\mathsf{A},1}, x_{\\mathsf{A},2}, x_{\\mathsf{A},3}, x_{\\mathsf{B},1}, \\dots, x_{\\mathsf{E},3} \\bigr]$ where each $x_{\\cdot,\\cdot}$ is a decimal rounded to six places and there are no spaces.",
            "solution": "The problem statement is scientifically grounded, objective, and well-posed. It provides a complete and consistent mathematical model of a simplified simulated annealing process. A rigorous solution can be derived and implemented.\n\nThe system is modeled as a two-state time-inhomogeneous Markov chain with states $\\mathsf{A}$ (outside the needle, energy $\\Delta  0$) and $\\mathsf{B}$ (inside the needle, energy $0$). The process evolves over discrete steps $k=1, 2, \\dots, N$, starting from state $\\mathsf{A}$ at step $k=0$.\n\nLet $p_k$ be the probability of being in state $\\mathsf{B}$ at the conclusion of step $k$. Consequently, the probability of being in state $\\mathsf{A}$ is $1-p_k$. The initial condition is $p_0=0$.\n\nThe probability $p_k$ for $k \\ge 1$ is determined by the state at step $k-1$ and the transition probabilities at step $k$. These transitions are:\n1.  From state $\\mathsf{A}$ to $\\mathsf{B}$: A proposal to state $\\mathsf{B}$ occurs with probability $p_{\\mathrm{in}}$. This move represents an energy decrease, so it is always accepted. The transition probability is thus $p_{\\mathrm{in}}$.\n2.  From state $\\mathsf{B}$ to $\\mathsf{A}$: Any move is an uphill energy step of $\\Delta$. The proposal is assumed to be always available. According to the Metropolis rule, the acceptance probability is $\\exp(-\\Delta/T_k)$, where $T_k$ is the temperature at step $k$. This is the transition probability from $\\mathsf{B}$ to $\\mathsf{A}$.\n\nUsing the law of total probability, a recurrence relation for $p_k$ can be established:\n$$p_k = \\Pr(\\text{in } \\mathsf{B} \\text{ at step } k-1) \\cdot \\Pr(\\text{stay in } \\mathsf{B}) + \\Pr(\\text{in } \\mathsf{A} \\text{ at step } k-1) \\cdot \\Pr(\\text{transition } \\mathsf{A} \\to \\mathsf{B})$$\nSubstituting the probabilities:\n$$p_k = p_{k-1} \\cdot \\left(1 - \\exp\\left(-\\frac{\\Delta}{T_k}\\right)\\right) + (1-p_{k-1}) \\cdot p_{\\mathrm{in}}$$\nThis linear recurrence relation allows for the iterative computation of $p_k$ for $k=1, \\dots, N$, with the initial condition $p_0=0$.\n\nThe three quantities of interest are computed as follows:\n\n1.  **$p_{\\mathrm{final}}(N)$**: This is the probability of being inside the needle at the final step $N$, which is by definition $p_N$. It is the last value obtained from the iterative computation of the sequence $\\{p_k\\}$.\n\n2.  **$f_{\\mathrm{occ}}(N)$**: This is the expected fraction of steps spent inside the needle. It is the arithmetic mean of the probabilities $p_k$ over all steps.\n$$f_{\\mathrm{occ}}(N) = \\frac{1}{N} \\sum_{k=1}^{N} p_k$$\nThis value is obtained by summing the $p_k$ values during the iteration and dividing by $N$ at the end.\n\n3.  **$p_{\\mathrm{ever}}(N)$**: This is the probability of having visited the needle (state $\\mathsf{B}$) at least once by step $N$. It is more direct to compute the complement: the probability of *never* having visited state $\\mathsf{B}$ up to step $N$. This occurs if and only if the system remains in state $\\mathsf{A}$ for all steps from $k=1$ to $N$.\nStarting from state $\\mathsf{A}$ at $k=0$, the probability of not transitioning to $\\mathsf{B}$ at step $k=1$ is $(1-p_{\\mathrm{in}})$. Given the system is in state $\\mathsf{A}$ at step $k-1$, the probability of remaining in state $\\mathsf{A}$ at step $k$ is also $(1-p_{\\mathrm{in}})$, as the transition $\\mathsf{A} \\to \\mathsf{B}$ does not depend on temperature. Thus, the probability of remaining in state $\\mathsf{A}$ for all $N$ steps is:\n$$\\Pr(\\text{never in } \\mathsf{B} \\text{ by step } N) = (1-p_{\\mathrm{in}})^N$$\nTherefore, the probability of ever visiting the needle is:\n$$p_{\\mathrm{ever}}(N) = 1 - (1-p_{\\mathrm{in}})^N$$\nThis quantity notably depends only on $p_{\\mathrm{in}}$ and $N$, not on the temperature schedule. For numerical stability, this is best computed as $1 - \\exp(N \\ln(1-p_{\\mathrm{in}}))$.\n\nThe temperature $T_k$ at each step $k$ is calculated according to the specified cooling schedule:\n- Exponential: $T_k = T_0 \\,\\alpha^{\\,k-1}$\n- Linear: $T_k = T_0 \\,/ \\left(1+\\beta\\,(k-1)\\right)$\n- Logarithmic: $T_k = c \\,/ \\ln(k_0 + k - 1)$\n\nThe computational algorithm proceeds by iterating from $k=1$ to $N$, at each step calculating $T_k$, then using it to update $p_k$ via the recurrence relation, and accumulating the sum of $p_k$. The value of $p_{\\mathrm{ever}}(N)$ is computed directly from its derived formula.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_quantities(schedule, params, delta, p_in, N):\n    \"\"\"\n    Computes the specified quantities for a single test case.\n\n    Args:\n        schedule (str): The type of cooling schedule ('exp', 'lin', 'log').\n        params (tuple): Parameters for the schedule.\n        delta (float): The energy gap Delta.\n        p_in (float): The probability of proposing a move into the needle.\n        N (int): The total number of steps.\n\n    Returns:\n        tuple: A tuple containing (p_final, f_occ, p_ever).\n    \"\"\"\n    # 1. Calculate p_ever(N)\n    # p_ever = 1 - (1 - p_in)^N.\n    # Using log1p for numerical stability with small p_in.\n    if p_in > 0:\n        p_ever = 1.0 - np.exp(N * np.log1p(-p_in))\n    else: # If p_in is zero, can never enter the needle\n        p_ever = 0.0\n\n    # 2. Iteratively compute p_k to find p_final(N) and f_occ(N)\n    p_current = 0.0  # p_0 = 0\n    p_sum = 0.0\n\n    # Unpack schedule parameters\n    if schedule == 'exp':\n        T0, alpha = params\n    elif schedule == 'lin':\n        T0, beta = params\n    elif schedule == 'log':\n        c, k0 = params\n\n    for k in range(1, N + 1):\n        # Calculate temperature T_k for the current step\n        if schedule == 'exp':\n            T_k = T0 * (alpha**(k - 1))\n        elif schedule == 'lin':\n            T_k = T0 / (1.0 + beta * (k - 1))\n        elif schedule == 'log':\n            # Constraints k_0 > 1 and k >= 1 ensure log argument is > 1.\n            T_k = c / np.log(k0 + k - 1)\n        \n        # Calculate exit probability from state B\n        # Guard against T_k being extremely small or zero\n        if T_k = 1e-300:\n            p_exit = 0.0\n        else:\n            p_exit = np.exp(-delta / T_k)\n\n        # Update p_k using the recurrence relation:\n        # p_k = p_{k-1} * (1 - p_exit) + (1-p_{k-1}) * p_in\n        p_current = p_current * (1.0 - p_exit) + (1.0 - p_current) * p_in\n        p_sum += p_current\n\n    p_final = p_current\n    f_occ = p_sum / N\n\n    return p_final, f_occ, p_ever\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        # Case A: Exponential cooling\n        {'name': 'A', 'schedule': 'exp', 'params': (5.0, 0.9995), 'delta': 5.0, 'p_in': 1e-4, 'N': 20000},\n        # Case B: Linear cooling\n        {'name': 'B', 'schedule': 'lin', 'params': (5.0, 5e-5), 'delta': 5.0, 'p_in': 1e-4, 'N': 20000},\n        # Case C: Logarithmic cooling\n        {'name': 'C', 'schedule': 'log', 'params': (2.0, 10.0), 'delta': 5.0, 'p_in': 1e-4, 'N': 20000},\n        # Case D: Constant temperature (special case of exponential)\n        {'name': 'D', 'schedule': 'exp', 'params': (5.0, 1.0), 'delta': 1.0, 'p_in': 1e-4, 'N': 20000},\n        # Case E: Exponential cooling with rare entry\n        {'name': 'E', 'schedule': 'exp', 'params': (3.0, 0.9999), 'delta': 5.0, 'p_in': 1e-6, 'N': 200000},\n    ]\n\n    all_results_str = []\n    for case in test_cases:\n        p_final, f_occ, p_ever = calculate_quantities(\n            case['schedule'], case['params'], case['delta'], case['p_in'], case['N'])\n        \n        # Round results to 6 decimal places and format as string\n        all_results_str.append(f\"{round(p_final, 6):.6f}\")\n        all_results_str.append(f\"{round(f_occ, 6):.6f}\")\n        all_results_str.append(f\"{round(p_ever, 6):.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        }
    ]
}