{
    "hands_on_practices": [
        {
            "introduction": "外部排序中的合并过程不仅仅是为了排序，它还为数据处理和优化提供了机会。本练习将探讨一种重要的优化技术：在合并过程中动态去重，并量化其带来的I/O节省。通过这个练习，你将为I/O成本分析打下坚实的基础。",
            "id": "3232889",
            "problem": "给定一个存储在磁盘上的大型记录文件，该文件恰好由 $D$ 个磁盘块组成，每个块都被定长记录完全利用。主内存中有 $M$ 个块缓冲区（每个缓冲区可以容纳一个磁盘块）。我们使用标准模型执行外部归并排序，在初始顺串生成阶段，大小为 $M$ 个块的连续数据块被读入内存，在内存中排序后，作为初始顺串写回磁盘；然后，算法重复执行 $k$-路归并过程，直到只剩下一个完全排序的顺串，其中 $k = M - 1$（一个用于输出，每个输入顺串各一个缓冲区）。假设所有磁盘输入/输出（I/O）都是顺序且块对齐的，并且与磁盘 I/O 相比，内存中的处理成本可以忽略不计。同时假设不使用置换选择法，因此每个初始顺串的大小恰好为 $M$ 个块。\n\n现要求您修改归并阶段，以便在过程中移除重复记录。具体来说，在每次 $k$-路归并期间，归并器仅当一条记录的键与最后写入输出的键不同时才输出该记录；对于来自不同输入流的键值相同的情况，通过输出一个代表记录，并在后续所有相等的键到达磁盘前将其丢弃来解决。假设相等的键在字节上是完全相同的，并且在排序顺序下比较结果为相等。此修改本身不会改变在任何一趟归并中读取输入块的数量（即总是读取该趟的全部输入数据），但它可以减少在首次消除重复项的那一趟中写入的块数，并因数据量减小而减少后续趟次的读写块数。\n\n在这些假设下，考虑以下具体实例：\n- 内存缓冲区数量为 $M = 101$，因此 $k = 100$。\n- 数据集占用 $D = 1010000$ 个磁盘块。\n- 初始顺串的长度为 $M$ 个块，因此初始顺串的数量为 $R_{0} = D / M$。\n- 由于 $R_{0}$ 是 $k$ 的整数次幂，基线排序（无去重）在初始顺串生成阶段之后，恰好通过两次 $k$-路归并完成。\n- 数据集由记录组成，每个键恰好有 $r = 5$ 个重复项，即每个唯一的键在数据集中恰好出现 $5$ 次。\n- 假设在第一次 $k$-路归并过程中，去重操作移除了所有冗余副本，因此每个键只有一个代表被写入。这将在所有后续的物化过程中将数据量减少为原来的 $1/r$。假设这种减少精确地转化为写入或读取的块数减少为原来的 $1/r$（没有填充或部分块效应）。\n\n与执行相同趟数序列但在每一趟都写入所有记录（即直到排序完成后才进行去重）的基线外部归并排序相比，计算在归并过程中执行这种实时去重所节省的磁盘块 I/O 的确切数量。\n\n请以单个整数形式提供节省的总块 I/O 数量作为您的最终答案。无需四舍五入。最终答案中不要包含任何单位。",
            "solution": "### 阶段 1：问题验证\n\n**步骤 1：提取已知条件**\n\n*   文件中的磁盘块数：$D = 1010000$\n*   主内存缓冲区数：$M = 101$\n*   外部归并排序模型：\n    *   初始顺串生成：读取 $M$ 个块，排序，写入 $M$ 个块。\n    *   归并阶段：$k$-路归并，其中 $k = M - 1$。\n*   假设：内存处理成本可忽略不计。\n*   假设：不使用置换选择法。\n*   初始顺串长度为 $M$ 个块。\n*   初始顺串数量：$R_0 = D/M$。\n*   $k$ 的值：$k = M - 1 = 101 - 1 = 100$。\n*   基线排序特性：$R_0$ 是 $k$ 的整数次幂。具体来说，它在两次 $k$-路归并后完成。\n*   去重修改：\n    *   在每次 $k$-路归并期间发生。\n    *   仅当记录的键与最后写入的键不同时才输出该记录。\n    *   通过输出一个代表并丢弃其他记录来处理键值相同的情况。\n*   数据集特性：每个不同的键恰好出现 $r=5$ 次。\n*   去重效果：\n    *   第一次 $k$-路归并会移除所有冗余副本。\n    *   在所有后续物化中，数据量减少为原来的 $1/r=1/5$。\n    *   这种减少精确地转化为块数减少为原来的 $1/5$（无部分块）。\n*   目标：计算节省的磁盘块 I/O 的确切数量。\n*   范围：计算所有过程（初始顺串生成、归并过程 1、归并过程 2）的读写操作。\n*   假设：最终排好序的输出被写入磁盘。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n1.  **科学上是否成立？** 是。该问题描述了标准的外部归并排序算法，这是计算机科学（数据结构与算法）中的一个基础课题。磁盘 I/O 的模型（基于块、顺序）是标准的。修改（实时去重）是一种常见的优化。所做的假设（CPU 成本可忽略、无部分块、精确的缩减因子）是为简化算法分析问题而设定的标准假设。\n\n2.  **是否定义明确？** 是。该问题提供了所有必要的参数（$D, M, r$）以及对基线算法和修改后算法的清晰定义。目标是具体的（计算 I/O 节省量）。归并过程的结构由参数决定。我们来检查一下“$R_0$ 是 $k$ 的整数次幂”这个条件。\n    *   $M = 101$\n    *   $D = 1010000$\n    *   $k = M - 1 = 100$\n    *   初始顺串数量 $R_0 = D/M = 1010000 / 101 = 10000$。\n    *   我们需要检查 $R_0$ 是否是 $k$ 的幂。\n    *   $k = 100$。\n    *   $R_0 = 10000 = 100^2$。\n    *   所以，$R_0 = k^2$。这证实了“$R_0$ 是 $k$ 的整数次幂”的说法。它也证实了需要两次归并过程。\n        *   第 1 趟：将 $R_0 = 10000$ 个顺串以 $k=100$ 为一组进行归并。这将产生 $R_1 = R_0 / k = 10000 / 100 = 100$ 个顺串。\n        *   第 2 趟：将 $R_1 = 100$ 个顺串以 $k=100$ 为一组进行归并。这将产生 $R_2 = R_1 / k = 100 / 100 = 1$ 个最终顺串。\n    *   该问题内部一致且定义明确。应该存在一个唯一的、有意义的解。\n\n3.  **是否客观？** 是。语言精确且量化。没有主观因素。\n\n4.  **其他缺陷？**\n    *   **不完整/矛盾？** 否，如上所述已确认。所有参数都已给出且一致。\n    *   **不切实际/不可行？** 这些数字虽然大，但对于外部排序问题来说是典型的。假设（例如，精确的缩减因子 5）是为了计算清晰而做的简化，但在理论背景下并非科学上不合理。\n    *   **不适定？** 否。\n    *   **伪深刻/琐碎？** 否。它要求仔细计算两种不同情景下的 I/O 成本，这是该领域的标准分析。\n    *   **超出科学可验证性？** 否。这是一个基于明确定义的算法模型的数学计算。\n\n**步骤 3：结论与行动**\n\n问题是**有效的**。我将继续进行解答。\n\n---\n\n### 阶段 2：解题规划\n\n我的目标是计算总的 I/O 节省量。\n$I/O_{saved} = I/O_{baseline} - I/O_{dedup}$\n\n我需要计算基线情况和去重情况下的总 I/O。总 I/O 是每个过程的 I/O 之和。\n\n让我们将第 $i$ 趟开始时数据集中的块数表示为 $D_i$。\n初始块数为 $D_0 = D = 1010000$。\n\n过程包括：\n1.  **第 0 趟：初始顺串生成**\n2.  **第 1 趟：第一次归并**\n3.  **第 2 趟：第二次（最后）归并**\n\n让我们分析两种场景下每一趟的 I/O。\n\n**场景 A：基线（无去重）**\n\n*   **第 0 趟：初始顺串生成**\n    *   读取整个文件：$D$ 个块。\n    *   写出初始排好序的顺串：$D$ 个块。\n    *   $I/O_{0, baseline} = D_{read} + D_{write} = D + D = 2D$。\n\n*   **第 1 趟：第一次归并**\n    *   输入为 $R_0 = D/M = k^2$ 个顺串。\n    *   这些顺串的总大小为 $D$ 个块。\n    *   从初始顺串中读取所有 $D$ 个块。\n    *   将它们归并成 $R_1 = R_0/k = k$ 个新顺串。\n    *   由于没有去重，输出的总大小仍然是 $D$ 个块。\n    *   为中间顺串写入所有 $D$ 个块。\n    *   $I/O_{1, baseline} = D_{read} + D_{write} = D + D = 2D$。\n\n*   **第 2 趟：第二次（最后）归并**\n    *   输入为第 1 趟产生的 $R_1 = k$ 个顺串。\n    *   这些顺串的总大小为 $D$ 个块。\n    *   读取所有 $D$ 个块。\n    *   将它们归并成一个最终的排好序的顺串。\n    *   写入大小为 $D$ 个块的最终排序文件。\n    *   $I/O_{2, baseline} = D_{read} + D_{write} = D + D = 2D$。\n\n*   **基线总 I/O**\n    *   $I/O_{baseline} = I/O_{0, baseline} + I/O_{1, baseline} + I/O_{2, baseline}$\n    *   $I/O_{baseline} = 2D + 2D + 2D = 6D$。\n\n**场景 B：带实时去重**\n\n*   **第 0 趟：初始顺串生成**\n    *   这一趟与基线相同。它只是读取数据并在内存中排序。这里没有发生归并，所以没有去重。\n    *   读取整个文件：$D$ 个块。\n    *   写出初始排好序的顺串：$D$ 个块。\n    *   $I/O_{0, dedup} = D_{read} + D_{write} = D + D = 2D$。\n\n*   **第 1 趟：第一次归并**\n    *   这是去重首次发生的地方。\n    *   输入是 $R_0 = k^2$ 个顺串，总大小为 $D$ 个块。\n    *   读取所有 $D$ 个块。\n    *   在归并过程中，重复项被移除。问题说明每个键出现 $r=5$ 次，去重将数据量减少为原来的 $1/r$。\n    *   输出的大小减少到 $D/r$。\n    *   为中间顺串写入 $D/r$ 个块。\n    *   $I/O_{1, dedup} = D_{read} + D_{write} = D + D/r$。\n\n*   **第 2 趟：第二次（最后）归并**\n    *   输入是第 1 趟产生的 $R_1 = k$ 个顺串。\n    *   这些顺串的总大小现在是 $D/r$ 个块。\n    *   读取所有 $D/r$ 个块。\n    *   问题陈述暗示所有重复项都在第一次归并中被移除。这意味着第二次归并的输入已经是唯一的。这里的归并过程只会合并已排序的顺串，而不会进一步减小大小。\n    *   写入大小为 $D/r$ 个块的最终排序并去重的文件。\n    *   $I/O_{2, dedup} = (D/r)_{read} + (D/r)_{write} = D/r + D/r = 2(D/r)$。\n\n*   **去重总 I/O**\n    *   $I/O_{dedup} = I/O_{0, dedup} + I/O_{1, dedup} + I/O_{2, dedup}$\n    *   $I/O_{dedup} = 2D + (D + D/r) + 2(D/r) = 3D + 3(D/r)$。\n\n**计算节省量**\n\n*   $I/O_{saved} = I/O_{baseline} - I/O_{dedup}$\n*   $I/O_{saved} = 6D - (3D + 3(D/r))$\n*   $I/O_{saved} = 6D - 3D - 3(D/r)$\n*   $I/O_{saved} = 3D - 3(D/r)$\n*   $I/O_{saved} = 3D(1 - 1/r)$\n\n让我再次检查一下逻辑。\n\n问题陈述中写道：“此修改不改变任何一趟中读取的输入块的数量，但是它可以减少在首次消除重复记录的那一趟中写入的块数，并且由于数据量的减小，它减少了后续趟次的读取和写入量。”\n\n我的分析与此描述相符。\n*   第 1 趟：\n    *   读取：$D$ 个块（与基线相同）。这与陈述一致。\n    *   写入：$D/r$ 个块（减少了）。这与陈述一致。\n*   第 2 趟：\n    *   读取：$D/r$ 个块（减少了）。这与陈述一致。\n    *   写入：$D/r$ 个块（减少了）。这与陈述一致。\n\n逻辑似乎是正确的。\n\n让我们推广外部排序的 I/O 成本公式。\n趟数为 $P = 1 + \\lceil \\log_k R_0 \\rceil$。\n这里 $R_0 = D/M = k^2$，所以 $\\log_k R_0 = \\log_k(k^2) = 2$。\n所以，归并趟数为 2。总趟数（包括顺串生成）为 $1+2=3$。这是正确的。\n\n标准外部排序的总 I/O 是 $2D \\times (\\text{趟数})$。\n趟数 = $1 (\\text{顺串生成}) + 2 (\\text{归并}) = 3$。\n总 I/O = $2D \\times 3 = 6D$。这与我对基线的计算相符。\n\n现在看去重的情况。\n第 0 趟 (顺串生成)：$2D$ I/O。（读 $D$，写 $D$）。数据大小为 $D$。\n第 1 趟 (归并 1)：读 $D$，写 $D_{out,1}$。数据大小变为 $D_{out,1}$。在这种情况下，$D_{out,1} = D/r$。I/O 为 $D + D/r$。\n第 2 趟 (归并 2)：读 $D_{out,1}$，写 $D_{out,2}$。输入已经去重，所以 $D_{out,2} = D_{out,1} = D/r$。I/O 为 $D/r + D/r = 2(D/r)$。\n总 I/O (去重) = $2D + (D + D/r) + 2(D/r) = 3D + 3D/r$。这是正确的。\n\n节省量计算：\n$I/O_{saved} = I/O_{baseline} - I/O_{dedup}$\n$I/O_{saved} = 6D - (3D + 3D/r) = 3D - 3D/r = 3D(1 - 1/r)$。\n\n这似乎是可靠的。\n\n现在，我将代入给定的值。\n*   $D = 1010000$\n*   $M = 101$\n*   $k = 100$\n*   $r = 5$\n\n$I/O_{saved} = 3 \\times 1010000 \\times (1 - 1/5)$\n$I/O_{saved} = 3 \\times 1010000 \\times (4/5)$\n$I/O_{saved} = 12/5 \\times 1010000$\n$I/O_{saved} = 2.4 \\times 1010000$\n\n让我们计算 $1010000 / 5$：\n$1010000 / 5 = (1000000 + 10000) / 5 = 200000 + 2000 = 202000$。\n所以，$I/O_{saved} = 12 \\times 202000$。\n$12 \\times 202000 = 12 \\times 202 \\times 1000$。\n$12 \\times 202 = 12 \\times (200 + 2) = 2400 + 24 = 2424$。\n$I/O_{saved} = 2424 \\times 1000 = 2424000$。\n\n让我们用 $2.4$ 这个因子重新计算。\n$2.4 \\times 1010000 = (2 + 0.4) \\times 1010000$\n$= 2 \\times 1010000 + 0.4 \\times 1010000$\n$= 2020000 + 4 \\times 101000$\n$= 2020000 + 404000$\n$= 2424000$。\n\n计算结果一致。\n\n让我们逐趟重新验证 I/O 成本。\n$D = 1010000$\n$r = 5$\n$D/r = 1010000 / 5 = 202000$。\n\n**基线 I/O：**\n*   第 0 趟：读 $1010000$，写 $1010000$。总计：$2020000$。\n*   第 1 趟：读 $1010000$，写 $1010000$。总计：$2020000$。\n*   第 2 趟：读 $1010000$，写 $1010000$。总计：$2020000$。\n*   $I/O_{baseline} = 3 \\times 2020000 = 6060000$。\n    （另外，$6D = 6 \\times 1010000 = 6060000$。正确。）\n\n**去重 I/O：**\n*   第 0 趟：读 $1010000$，写 $1010000$。总计：$2020000$。\n*   第 1 趟：读 $1010000$，写 $202000$（即 $D/r$）。总计：$1212000$。\n*   第 2 趟：读 $202000$，写 $202000$。总计：$404000$。\n*   $I/O_{dedup} = 2020000 + 1212000 + 404000 = 3636000$。\n\n让我们用公式 $3D + 3D/r$ 来检验：\n$3 \\times 1010000 + 3 \\times (1010000/5)$\n$= 3030000 + 3 \\times 202000$\n$= 3030000 + 606000$\n$= 3636000$。\n$I/O_{dedup}$ 的公式是正确的。\n\n**节省量：**\n$I/O_{saved} = I/O_{baseline} - I/O_{dedup}$\n$I/O_{saved} = 6060000 - 3636000 = 2424000$。\n\n这与我之前使用公式 $3D(1 - 1/r)$ 的计算结果相符。\n$3 \\times 1010000 \\times (1 - 1/5) = 3030000 \\times 4/5 = 12120000 / 5 = 2424000$。\n所有计算都是一致的。\n\n解答的结构应为：\n1.  象征性地定义参数：$D, M, k, r$。\n2.  陈述初始顺串数量 $R_0$ 和归并趟数。\n3.  逐趟计算基线场景的总 I/O 成本。\n    *   $I/O_{baseline} = I/O_{pass0} + I/O_{pass1} + I/O_{pass2}$。\n    *   证明这等于 $6D$。\n4.  逐趟计算去重场景的总 I/O 成本。\n    *   $I/O_{dedup} = I/O_{pass0} + I/O_{pass1} + I/O_{pass2}$。\n    *   解释第一次归并后数据大小如何变化。\n    *   证明这等于 $3D + 3D/r$。\n5.  将节省量计算为差值。\n    *   $I/O_{saved} = I/O_{baseline} - I/O_{dedup}$。\n    *   推导出符号表达式：$3D - 3D/r$。\n6.  将 $D$ 和 $r$ 的数值代入最终表达式以获得数值答案。\n7.  将最终整数放在 `\\boxed{...}` 中。\n\n所有数学实体都必须使用 LaTeX。\n例如：\n*   磁盘块数：$D$\n*   内存缓冲区数：$M$\n*   归并因子：$k = M-1$\n*   重复计数：$r$\n*   初始顺串：$R_0 = D/M$\n*   趟数：$1 + \\lceil \\log_k R_0 \\rceil$。\n*   I/O 成本：$I/O$\n*   数字 $1010000, 101, 100, 5, 0, 1, 2$ 都应该在 LaTeX 中。\n\n最终答案必须是单个整数。计算得出 $2424000$。\n\n符号化节省公式的最终检查：\n$I/O_{saved} = (I/O_{1, baseline} + I/O_{2, baseline}) - (I/O_{1, dedup} + I/O_{2, dedup})$\n注意第 0 趟是相同的，所以可以抵消。\n$I/O_{saved} = (2D + 2D) - ((D + D/r) + 2(D/r))$\n$I/O_{saved} = 4D - (D + 3D/r)$\n$I/O_{saved} = 3D - 3D/r = 3D(1 - 1/r)$\n这与之前的结果相同。逻辑是健全的。",
            "answer": "$$\\boxed{2424000}$$"
        },
        {
            "introduction": "外存算法的原理，如生成初始顺串和多路合并，是解决各种大数据问题的基本工具，而不仅限于排序。本练习将演示如何调整这些技术，以高效地计算远超内存容量的数据集的中位数。它挑战你将I/O成本分析应用于一个全新的场景。",
            "id": "3233023",
            "problem": "给定一个包含 $N=10^{9}$ 个整数键的未排序磁盘驻留文件。主内存一次最多可容纳 $M=10^{7}$ 个键，磁盘块大小为 $B=10^{5}$ 个键/块。输入/输出 (I/O) 模型如下：单次 I/O 操作在磁盘和主内存之间精确传输一个包含 $B$ 个连续键的完整块；主内存中的所有计算相对于 I/O 而言是免费的；寻道成本被忽略。在归并过程中，你可以为每个顺串分配一个输入缓冲块，并分配一个输出缓冲块。\n\n文件中键的多重集按值的频率描述如下：有 $10^{8}$ 个值为 $1$ 的副本，$4\\times 10^{8}$ 个值为 $5$ 的副本，以及 $5\\times 10^{8}$ 个值为 $9$ 的副本。文件在磁盘上以任意顺序存储。对于偶数 $N$，中位数定义为全局排序顺序中第 $\\frac{N}{2}$ 和第 $\\left(\\frac{N}{2}+1\\right)$ 个顺序统计量的平均值。\n\n你将使用受外部排序启发的技巧来计算中位数，过程如下。首先，进行顺串生成，重复地将最多 $M$ 个键读入内存，在内部进行排序，并将每个排好序的顺串写回磁盘。接下来，进行扇入为 $k$（其中 $k=\\lfloor M/B\\rfloor - 1$）的多路归并，通过为每个输入顺串分配1个块，为输出分配1个块，直到只剩下一个顺串。在最后的归并层级，不要将归并后的输出写回磁盘；而是在内存中流式处理归并后的序列，并对生成的元素进行计数，一旦识别出第 $\\frac{N}{2}$ 和第 $\\left(\\frac{N}{2}+1\\right)$ 个元素，就返回它们的平均值作为中位数并停止。对于最终归并层级的 I/O 核算，假设保守的最坏情况，即读取操作必须处理该层级的全部输入。以块传输的精确计数表示 I/O 成本。\n\n根据外存块传输模型的基本原理，确定：\n- 上述定义下的中位数的数值，以及\n- 该算法所产生的块传输的总确切数量，计算在顺串生成和归并期间所有读写操作，并对最终归并层级采用所述的最坏情况假设。\n\n将你的最终答案表示为一个二元行矩阵 $\\begin{pmatrix}\\text{中位数}  \\text{I/O 传输次数}\\end{pmatrix}$。无需四舍五入。以块传输为单位表示 I/O 成本。",
            "solution": "该问题要求两个量：数据集的中位数，以及使用特定的基于外部排序的算法找到它所需的总 I/O 成本。\n\n#### 第1部分：中位数的计算\n总键数为 $N = 10^9$，是一个偶数。中位数定义为全局排序序列中第 $\\frac{N}{2}$ 和第 $(\\frac{N}{2}+1)$ 个元素的平均值。\n\n首先，我们计算两个中间元素的索引：\n- $\\frac{N}{2} = \\frac{10^9}{2} = 5 \\times 10^8$。\n- $\\frac{N}{2} + 1 = 5 \\times 10^8 + 1$。\n\n接下来，我们通过检查排序后键值的累积频率来确定这些位置上元素的值。\n键值为 $1$、$5$ 和 $9$。\n- 值为 $1$ 的键的数量是 $N_1 = 10^8$。这些键在排序序列中占据位置 $1$ 到 $10^8$。\n- 值为 $5$ 的键的数量是 $N_5 = 4 \\times 10^8$。这些键占据接下来的 $4 \\times 10^8$ 个位置。累积计数为 $N_1 + N_5 = 10^8 + 4 \\times 10^8 = 5 \\times 10^8$。因此，值为 $5$ 的键占据从 $(10^8 + 1)$ 到 $5 \\times 10^8$ 的位置。\n- 值为 $9$ 的键的数量是 $N_9 = 5 \\times 10^8$。这些键占据了从 $(5 \\times 10^8 + 1)$ 到 $10^9$ 的剩余位置。\n\n我们现在可以确定所需的顺序统计量：\n- 第 $(\\frac{N}{2})$ 个元素位于位置 $5 \\times 10^8$。根据我们的累积计数，这是值为 $5$ 的键所占据的最后一个位置。因此，第 $(\\frac{N}{2})$ 个元素的值是 $5$。\n- 第 $(\\frac{N}{2}+1)$ 个元素位于位置 $5 \\times 10^8 + 1$。这是值为 $9$ 的键所占据的第一个位置。因此，第 $(\\frac{N}{2}+1)$ 个元素的值是 $9$。\n\n中位数是这两个值的平均值：\n$$ \\text{中位数} = \\frac{5 + 9}{2} = \\frac{14}{2} = 7 $$\n\n#### 第2部分：总I/O成本的计算\nI/O成本是块传输（读和写）的总数。该算法包括一个顺串生成阶段和随后的一系列归并遍。\n\n首先，我们计算文件在磁盘上占用的总块数：\n$$ N_{blocks} = \\frac{N}{B} = \\frac{10^9 \\text{ 键}}{10^5 \\text{ 键/块}} = 10^4 \\text{ 块} $$\n\n**阶段1：顺串生成**\n在此阶段，整个文件被读取，以大小为 $M$ 的内存块进行排序，并作为排序后的顺串写回磁盘。\n- 读取整个文件需要读取所有 $N_{blocks}$ 个块。成本：$N/B$ 次块传输。\n- 将排好序的顺串写回磁盘需要写入所有 $N_{blocks}$ 个块。成本：$N/B$ 次块传输。\n- 顺串生成的总I/O：$I/O_{gen} = \\frac{N}{B} + \\frac{N}{B} = 2 \\frac{N}{B}$。\n\n初始排序顺串的数量 $R_0$，取决于覆盖整个包含 $N$ 个键的文件需要多少个大小为 $M$ 的块：\n$$ R_0 = \\left\\lceil \\frac{N}{M} \\right\\rceil = \\left\\lceil \\frac{10^9}{10^7} \\right\\rceil = \\lceil 100 \\rceil = 100 $$\n\n**阶段2：归并**\n归并过程由多遍组成，每一遍都会减少顺串的数量。归并的扇入 $k$ 由 $k = \\lfloor M/B \\rfloor - 1$ 给出。\n$$ k = \\left\\lfloor \\frac{10^7}{10^5} \\right\\rfloor - 1 = \\lfloor 100 \\rfloor - 1 = 99 $$\n我们从 $R_0 = 100$ 个顺串开始，并确定每次归并遍后的顺串数量。\n- 第1遍之后：$R_1 = \\lceil R_0 / k \\rceil = \\lceil 100/99 \\rceil = 2$ 个顺串。\n- 第2遍之后：$R_2 = \\lceil R_1 / k \\rceil = \\lceil 2/99 \\rceil = 1$ 个顺串。\n\n这表明有两次归并遍。第二次归并遍是最后一次。\n\n**归并遍1的I/O成本：**\n这一遍将100个顺串归并成2个顺串。一个标准的归并遍会读取所有输入顺串并写入相应的输出顺串。读取和写入的总数据量是整个文件。\n- 读取：$N/B$ 次块传输。\n- 写入：$N/B$ 次块传输。\n- 归并遍1的总I/O：$I/O_{merge,1} = 2 \\frac{N}{B}$。\n\n**归并遍2（最终归并）的I/O成本：**\n这一遍归并剩余的2个顺串。根据问题描述，输出不被写入磁盘。然而，为了找到中位数元素，我们必须流式处理归并后的输出，这需要读取输入顺串。问题陈述要求假设最坏情况的读取场景，即该遍的所有输入顺串的块都必须被读取。\n- 读取：两个输入顺串共同包含所有 $N$ 个键，因此我们读取 $N/B$ 个块。\n- 写入：$0$ 次块传输。\n- 归并遍2的总I/O：$I/O_{merge,2} = \\frac{N}{B}$。\n\n**总I/O成本：**\n总I/O成本是所有阶段成本的总和。\n$$ I/O_{total} = I/O_{gen} + I/O_{merge,1} + I/O_{merge,2} $$\n$$ I/O_{total} = \\left(2 \\frac{N}{B}\\right) + \\left(2 \\frac{N}{B}\\right) + \\left(\\frac{N}{B}\\right) = 5 \\frac{N}{B} $$\n代入 $N/B = 10^4$ 的值：\n$$ I/O_{total} = 5 \\times 10^4 = 50000 $$\n\n块传输的总数是 $50,000$。\n\n两个要求的结果是中位数为 $7$，I/O 成本为 $50,000$ 次块传输。",
            "answer": "$$ \\boxed{\\begin{pmatrix} 7  50000 \\end{pmatrix}} $$"
        },
        {
            "introduction": "从抽象的基于块的I/O模型迈向真实的系统性能。这项高级练习将为一个k路合并算法创建一个精密的性能模型，该模型考虑了现代硬件特性，如SSD/HDD、异步I/O和双缓冲。通过实现这个模型，你将深入了解CPU成本、设备延迟和带宽如何相互作用，共同决定一个I/O密集型算法的实际吞吐量。",
            "id": "3232934",
            "problem": "您的任务是建模并实现一个由多流异步输入/输出（I/O）和双缓冲驱动的外部k路归并的持续吞吐量。目标是使用一个基于原则的性能模型，推导出在固态硬盘（SSD）和机械硬盘（HDD）两种设备类别下的稳态吞吐量。然后，您必须编写一个完整的、可运行的程序，为一组固定的测试用例计算预测的吞吐量。\n\n假设与背景：\n- 外部排序归并存储在辅助存储器上的顺串，其中数据量远超随机存取存储器（RAM）的容量。一个k路归并从 $K$ 个已排序的输入流中读取数据，并产生一个单一的已排序输出流。\n- 该算法为每个输入流使用两个缓冲区，为输出流也使用两个缓冲区（双缓冲）。当一个缓冲区由中央处理器（CPU）处理时，另一个缓冲区由异步I/O进行填充或刷写。\n- 归并过程使用一个大小为 $K$ 的最小堆来选择下一个输出元素，每个元素的CPU工作量随 $K$ 呈对数级增长。\n- 每一轮精确处理每个流的一个大小为 $C$ 字节的输入块，每轮总共输出 $K \\cdot C$ 字节。\n- 元素大小为 $s$ 字节，每次比较的成本为 $t_{\\mathrm{comp}}$ 秒。假设比较操作在归并的CPU时间中占主导地位。\n- 对于单个设备上大小为 $X$ 字节的单个阻塞请求，其I/O计时模型由基本设备性能关系定义，其中访问延迟为 $L$ 秒，流式带宽为 $B$ 字节/秒：请求时间等于延迟加上传输时间。每轮针对特定设备类别的假设如下：\n  - SSD模型：每个大小为 $C$ 的输入读取请求的成本为一个访问延迟加上传输时间；共有 $K$ 个这样的读取。大小为 $K \\cdot C$ 的输出写入请求的成本为一个访问延迟加上传输时间。\n  - HDD模型：每个大小为 $C$ 的输入读取请求会产生平均寻道和旋转延迟加上传输时间；共有 $K$ 个这样的读取。大小为 $K \\cdot C$ 的输出写入请求同样会产生一个延迟加上传输时间。由于机械运动，将 $K$ 个输入读取视为在设备端串行化。将输入设备和输出设备视为独立的，因此读取和写入可以重叠。\n- 带有异步I/O的双缓冲产生一个流水线，在稳态下，读取下一轮的输入、写入当前轮的输出以及对当前轮进行CPU归并这几个阶段是重叠的。每轮的时间等于该流水线中瓶颈阶段的时间，而持续吞吐量等于每轮的字节数除以每轮的时间。\n\n您的任务：\n- 使用上述假设，从第一性原理推导出稳态下的每轮时间。仅从上述定义和单个大小为 $X$ 的阻塞I/O需要花费延迟加传输时间这一基本设备性能关系出发。\n- 实现一个程序，计算以mebibyte每秒（MiB/s）为单位的持续吞吐量，其中一个mebibyte等于 $2^{20}$ 字节，结果四舍五入到三位小数。根据描述，使用双缓冲重叠来计算稳态吞吐量。\n- 对于基于堆的归并成本，使用以2为底的对数。您可以假设每个输出元素的比较次数与 $\\log_{2}(K)$ 成正比。\n\n输入和输出规范：\n- 没有运行时输入。您的程序必须嵌入并评估以下参数集的测试套件。对于每个测试用例，计算持续吞吐量，结果为一个以MiB/s为单位、四舍五入到三位小数的浮点数。您的程序应生成单行输出，包含一个方括号括起来的逗号分隔列表的结果（例如，“[x,y,z]”）。\n\n测试套件：\n每个测试用例是一个形式为 (device-type, $K$, $C$, $s$, $t_{\\mathrm{comp}}$, $B_{\\mathrm{in}}$, $B_{\\mathrm{out}}$, $L_{\\mathrm{in}}$, $L_{\\mathrm{out}}$) 的元组，其中：\n- device-type 是 \"SSD\" 或 \"HDD\"；它决定了延迟的解释方式，但使用相同的计算结构，\n- $K$ 是输入流的数量，\n- $C$ 是每个流的块大小（字节），\n- $s$ 是元素大小（字节），\n- $t_{\\mathrm{comp}}$ 是每次比较的时间（秒），\n- $B_{\\mathrm{in}}$ 和 $B_{\\mathrm{out}}$ 是输入和输出带宽（字节/秒），\n- $L_{\\mathrm{in}}$ 和 $L_{\\mathrm{out}}$ 是输入和输出访问延迟（秒）。\n\n使用以下七个案例：\n- 案例 A (SSD, 通用吞吐量): (\"SSD\", $8$, $4\\,000\\,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 B (HDD, 寻道主导): (\"HDD\", $8$, $4\\,000\\,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{8}$, $1.5 \\times 10^{8}$, $1.0 \\times 10^{-2}$, $1.0 \\times 10^{-2}$)。\n- 案例 C (SSD, 计算密集型): (\"SSD\", $8$, $4\\,000\\,000$, $8$, $5.0 \\times 10^{-8}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 D (SSD, 延迟主导的小块): (\"SSD\", $8$, $4\\,096$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 E (SSD, 大 $K$ 值): (\"SSD\", $64$, $4\\,000\\,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 F (HDD, $K = 1$ 边界情况): (\"HDD\", $1$, $4\\,000\\,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{8}$, $1.5 \\times 10^{8}$, $1.0 \\times 10^{-2}$, $1.0 \\times 10^{-2}$)。\n- 案例 G (SSD, 写带宽瓶颈): (\"SSD\", $8$, $4\\,000\\,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $3.0 \\times 10^{8}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n\n输出单位和格式：\n- 以mebibyte每秒（MiB/s）表示每个吞吐量，四舍五入到三位小数。\n- 您的程序必须严格按照 \"[v1,v2,v3,v4,v5,v6,v7]\" 的格式打印一行，其中每个 $v_{i}$ 是对应案例的四舍五入后的吞吐量，顺序与上文相同。",
            "solution": "该问题是有效的，因为它提出了一个基于外部存储器算法标准性能建模原则的、有科学依据、定义明确且客观的任务。它自成一体，没有矛盾。我现在将进行推导和求解。\n\n目标是推导使用双缓冲和异步I/O的 $K$ 路归并算法的稳态吞吐量。该系统的性能被建模为一个三级流水线。在稳态下，每轮的时间由最慢的阶段（瓶颈）决定，而吞吐量是每轮处理的数据量除以该轮时间。\n\n归并过程的单轮操作包括从 $K$ 个输入流中各读取一个大小为 $C$ 的数据块，并将它们归并以产生一个大小为 $K \\cdot C$ 的输出块。因此，每轮处理的总数据量为 $N_{\\text{bytes\\_round}} = K \\cdot C$。\n\n流水线由三个阶段组成，这些阶段并行处理不同轮次的数据：\n$1$. **CPU归并**：CPU归并来自第 $i$ 轮的输入块，以生成第 $i$ 轮的输出。\n$2$. **输入读取**：I/O系统为下一轮 $i+1$ 读取 $K$ 个输入块。\n$3$. **输出写入**：I/O系统写入来自上一轮 $i-1$ 的已归并输出块。在稳态下，我们将其视为当前轮 $i$ 的输出。\n\n在稳态下完成一轮的时间 $T_{\\text{round}}$ 是这三个阶段各自所用时间的最大值。\n$$T_{\\text{round}} = \\max(T_{\\text{CPU}}, T_{\\text{Read}}, T_{\\text{Write}})$$\n\n我们现在推导每个阶段所需时间的表达式。\n\n**1. CPU时间 ($T_{\\text{CPU}}$)**\nCPU时间主要由基于堆的归并所需的元素比较决定。一个大小为 $K$ 的最小堆被用来在所有输入流中找到下一个最小的元素。\n- 一轮中处理的元素数量为 $N_{\\text{elem}} = \\frac{N_{\\text{bytes\\_round}}}{s} = \\frac{K \\cdot C}{s}$，其中 $s$ 是每个元素的大小（以字节为单位）。\n- 问题指出，每个输出元素的比较次数与 $\\log_{2}(K)$ 成正比。我们假设一个标准的二叉堆实现，其中替换最小元素需要的比较次数在 $\\log_{2}(K)$ 的数量级。我们将比例常数设为 $1$，因此每个元素的比较次数为 $\\log_{2}(K)$。\n- 执行一次比较的时间给定为 $t_{\\text{comp}}$。\n- 因此，在一轮中归并所有元素的总CPU时间为：\n$$T_{\\text{CPU}} = N_{\\text{elem}} \\cdot (\\text{comparisons per element}) \\cdot t_{\\text{comp}} = \\left(\\frac{K \\cdot C}{s}\\right) \\cdot \\log_{2}(K) \\cdot t_{\\text{comp}}$$\n对于 $K=1$ 的特殊情况，不需要进行归并，且 $\\log_{2}(1) = 0$，这正确地得出 $T_{\\text{CPU}} = 0$。\n\n**2. 输入读取时间 ($T_{\\text{Read}}$)**\n这是为下一轮读取 $K$ 个输入块所需的时间。问题指定这涉及 $K$ 个独立的读取请求，每个请求的大小为 $C$。对于大小为 $X$ 的单个请求，其基本I/O性能关系为 $T_{\\text{I/O}}(X) = L + \\frac{X}{B}$，其中 $L$ 是延迟，$B$ 是带宽。\n- 对于SSD和HDD模型，问题都暗示从总时间计算的角度来看，$K$ 个输入读取是有效串行化的。对于HDD，由于机械磁头的移动，这是明确的。对于SSD，指令“每个大小为 $C$ 的输入读取请求的成本为一个访问延迟加上传输时间”导致了一个加法模型。\n- 单个大小为 $C$ 的输入读取时间为：$L_{\\text{in}} + \\frac{C}{B_{\\text{in}}}$。\n- 读取一轮所有 $K$ 个块的总时间为：\n$$T_{\\text{Read}} = K \\cdot \\left(L_{\\text{in}} + \\frac{C}{B_{\\text{in}}}\\right)$$\n\n**3. 输出写入时间 ($T_{\\text{Write}}$)**\n这是写入大小为 $K \\cdot C$ 的单个合并输出块所需的时间。\n- 写入的总大小为 $X = K \\cdot C$。\n- 写入操作作为单个I/O请求执行。\n- 使用基本I/O关系，总写入时间为：\n$$T_{\\text{Write}} = L_{\\text{out}} + \\frac{K \\cdot C}{B_{\\text{out}}}$$\n\n**4. 持续吞吐量 ($\\Theta$)**\n持续吞吐量是每轮处理的总数据量除以每轮的时间。\n- 吞吐量（字节/秒）：\n$$\\Theta_{\\text{B/s}} = \\frac{N_{\\text{bytes\\_round}}}{T_{\\text{round}}} = \\frac{K \\cdot C}{\\max\\left(\\frac{K \\cdot C \\cdot t_{\\text{comp}} \\cdot \\log_{2}(K)}{s}, K \\cdot \\left(L_{\\text{in}} + \\frac{C}{B_{\\text{in}}}\\right), L_{\\text{out}} + \\frac{K \\cdot C}{B_{\\text{out}}}\\right)}$$\n- 问题要求结果以mebibyte每秒（MiB/s）为单位，其中 $1 \\text{ MiB} = 2^{20}$ 字节。\n$$\\Theta_{\\text{MiB/s}} = \\frac{\\Theta_{\\text{B/s}}}{2^{20}}$$\n\n该模型适用于SSD和HDD两种设备类型，性能差异由参数 $L_{\\text{in}}$、$L_{\\text{out}}$、$B_{\\text{in}}$ 和 $B_{\\text{out}}$ 的具体值来体现。现在将实现推导出的公式，以计算给定测试套件的吞吐量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the sustained throughput for a k-way merge based on a\n    pipelined performance model.\n    \"\"\"\n\n    # Test suite of parameter sets. Each tuple is of the form:\n    # (device-type, K, C, s, t_comp, B_in, B_out, L_in, L_out)\n    test_cases = [\n        # Case A (SSD, general throughput)\n        (\"SSD\", 8, 4_000_000, 8, 1e-9, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case B (HDD, seek-dominated)\n        (\"HDD\", 8, 4_000_000, 8, 1e-9, 1.5e8, 1.5e8, 1.0e-2, 1.0e-2),\n        # Case C (SSD, compute-bound)\n        (\"SSD\", 8, 4_000_000, 8, 5.0e-8, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case D (SSD, latency-dominated small chunks)\n        (\"SSD\", 8, 4096, 8, 1e-9, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case E (SSD, large K)\n        (\"SSD\", 64, 4_000_000, 8, 1e-9, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case F (HDD, K = 1 boundary)\n        (\"HDD\", 1, 4_000_000, 8, 1e-9, 1.5e8, 1.5e8, 1.0e-2, 1.0e-2),\n        # Case G (SSD, write-bandwidth bottleneck)\n        (\"SSD\", 8, 4_000_000, 8, 1e-9, 1.5e9, 3.0e8, 5.0e-5, 5.0e-5),\n    ]\n\n    results = []\n    \n    # Conversion factor from bytes to mebibytes\n    BYTES_PER_MIB = 2**20\n\n    for case in test_cases:\n        _device_type, K, C, s, t_comp, B_in, B_out, L_in, L_out = case\n\n        # Total bytes processed per round\n        bytes_per_round = K * C\n\n        # 1. Calculate T_CPU: Time for CPU merge stage\n        if K  1:\n            log2_K = np.log2(K)\n            T_cpu = (K * C * t_comp * log2_K) / s\n        else:\n            # For K=1, no comparisons are needed.\n            T_cpu = 0.0\n\n        # 2. Calculate T_Read: Time for input read stage\n        # This models K serialized read requests of size C.\n        T_read = K * (L_in + C / B_in)\n\n        # 3. Calculate T_Write: Time for output write stage\n        # This models a single write request of size K*C.\n        T_write = L_out + (K * C) / B_out\n\n        # Determine the round time (bottleneck of the pipeline)\n        T_round = max(T_cpu, T_read, T_write)\n\n        # Calculate throughput in bytes per second\n        if T_round  0:\n            throughput_bps = bytes_per_round / T_round\n        else:\n            throughput_bps = float('inf')\n\n        # Convert throughput to MiB/s and round to 3 decimal places\n        throughput_mibs = throughput_bps / BYTES_PER_MIB\n        rounded_throughput = round(throughput_mibs, 3)\n        \n        results.append(rounded_throughput)\n\n    # Format the final output string as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}