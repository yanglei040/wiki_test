{
    "hands_on_practices": [
        {
            "introduction": "前缀和（或称“扫描”）操作是并行计算的基石之一，其应用远不止于简单的求和。这个练习将引导你从第一性原理出发，推导经典的基于树的并行前缀和算法，并将其应用于计算移动平均值等实际问题。通过这个实践，你将巩固对“上扫”/“下扫”(up-sweep/down-sweep)模式及其工作-深度分析的理解 。",
            "id": "3258324",
            "problem": "你需要基于并行随机存取机（PRAM）模型和工作-深度（WD）模型来推理并实现一个并行算法。PRAM 模型假设有一组同步处理器访问一个共享内存；请使用独占读取独占写入（EREW）变体，这意味着在任何单一步骤中，没有两个处理器能读取或写入同一个内存单元。在工作-深度模型中，总工作量是所有处理器执行的单位成本操作的总数（在所有同步步骤上求和），而深度是最长依赖链的长度，等同于在 EREW 约束下假设有无限处理器的同步并行步骤数。\n\n任务 A。仅使用这两个模型和以下基本原理，从第一性原理出发：\n- PRAM、EREW 和工作-深度的定义，\n- 加法具有结合律，以及对于 $n$ 个叶节点的平衡二叉树其高度为 $\\lceil \\log_{2} n \\rceil$ 这一事实，\n推导一个并行算法来计算长度为 $n$ 的输入序列 $A$ 的前缀和。其中，包含性前缀和序列 $S$ 定义为 $S[i] = \\sum_{k=0}^{i} A[k]$，对于 $i \\in \\{0,\\dots,n-1\\}$。你的推导必须在 EREW-PRAM 模型下证明 $O(\\log n)$ 的深度界和 $O(n)$ 的工作量界是合理的。不要假设任何“黑盒”扫描原语；请基于上述原理进行论证。\n\n任务 B。调整任务 A 中的方法，以计算长度为 $w$ 的移动平均值。给定一个长度为 $n$ 的序列 $A$ 和一个整数窗口 $w$（$1 \\le w \\le n$），移动平均值序列 $M$ 的长度为 $n-w+1$，其定义为\n$$\nM[i] \\;=\\; \\frac{1}{w} \\sum_{k=i}^{i+w-1} A[k], \\quad i \\in \\{0,\\dots,n-w\\}.\n$$\n在工作-深度模型下，推导你的移动平均值算法在 EREW-PRAM 上实现时的深度和工作量。你的推导应从前缀和的构建开始，并论证所需的额外步骤。\n\n测试套件和输出的实现要求。为了生成具体、可验证的输出：\n- 在为你的实现分析工作-深度成本时，请采用以下与教科书中的 EREW 构建相匹配的标准实例化：\n\n  1) 通过在一个完全二叉树上执行上扫（归约）和下扫来计算一个排除性前缀和 $P$。该树的叶节点数量为下一个2的幂 $m$，且 $m \\ge n$（使用零填充至长度 $m$）。将每个算术运算计为单位工作量。此排除性扫描的成本等于两次扫描中完成的算术运算总数，其深度是执行的并行层级数。\n\n  2) 使用恒等式\n  $$\n  M[i] \\;=\\; \\frac{P[i+w] - P[i]}{w}\n  $$\n  并行计算所有有效 $i$ 的移动平均值 $M$。将每次减法和每次除法计为一个单位工作量和一个同步步骤。总深度是扫描深度与这两个并行过程的深度之和。\n\n- 对于所有实数输出，四舍五入到 $6$ 位小数。\n- 对于所有输入，假设 $1 \\le w \\le n$ 且 $n \\ge 1$。\n\n你的程序必须实现以上要求，为以下 $(A,w)$ 对的测试套件生成输出：\n\n1) $A = [1,2,3,4,5,6,7,8]$, $w = 3$。\n\n2) $A = [42]$, $w = 1$。\n\n3) $A = [-2,0,5,-1,3]$, $w = 5$。\n\n4) $A = [0.5,-0.5,1.5,2.0]$, $w = 2$。\n\n5) $A = [3,1,4,1,5,9]$, $w = 4$。\n\n最终输出格式。你的程序应生成包含单个列表的单行输出。对于每个测试用例，输出一个双元素列表，其第一个元素是移动平均值列表（四舍五入到 $6$ 位小数），第二个元素是双元素列表 $[W,D]$，给出在上述实例化下的总工作量和深度。整个输出必须打印为一个无空格的类JSON列表，例如：\n$[[\\dots,[W_1,D_1]],[\\dots,[W_2,D_2]],\\dots]$。",
            "solution": "我们从并行随机存取机（PRAM）、独占读取独占写入（EREW）约束以及工作-深度（WD）模型的定义开始。在 PRAM 模型下，同步处理器步调一致地执行；EREW 约束禁止对同一内存单元进行并发读取或写入；工作-深度度量将总工作量定义为所有处理器执行的基本操作总数，将深度定义为在 EREW 约束下假设有无限处理器时的同步步骤数（最长依赖链）。\n\n推导并行前缀和。考虑一个长度为 $n$ 的序列 $A$。前缀和利用了加法的结合律。一个基本的构造方法是使用一个平衡二叉树，其叶节点对应于 $A$ 的元素。为避免任意 $n$ 带来的不均匀性，我们用零填充序列至长度 $m$，其中 $m$ 是满足 $m \\ge n$ 的最小的2的幂。该树有 $m$ 个叶节点，高度为 $\\log_{2} m$。\n\n构造过程分两个阶段：\n\n- 上扫（归约）：在层级 $\\ell \\in \\{1,\\dots,\\log_{2} m\\}$，成对的部分和相加，以构建父节点的和。第一层有 $m/2$ 次加法，第二层有 $m/4$ 次，以此类推，直到根节点只有1次。加法总次数为 $\\sum_{j=0}^{\\log_{2} m -1} m/2^{j+1} = m - 1$，深度为 $\\log_{2} m$，因为各层是顺序执行的。\n\n- 下扫（分发）：此阶段通过沿树向下分发左前缀值来传播排除性前缀和：每个内部节点将其当前值发送给其左子节点，并将其当前值与左子节点原始子树和的总和发送给其右子节点。每个层级都为右子节点的更新执行加法。加法总次数同样是 $m - 1$，深度为 $\\log_{2} m$。\n\n两个阶段相加，工作量为 $W_{\\text{scan}} = (m - 1) + (m - 1) = 2m - 2$，深度为 $D_{\\text{scan}} = \\log_{2} m + \\log_{2} m = 2 \\log_{2} m$。由于 $m \\le 2n$，我们得到 $W_{\\text{scan}} \\in \\Theta(n)$ 和 $D_{\\text{scan}} \\in \\Theta(\\log n)$，满足 $O(n)$ 的工作量界和 $O(\\log n)$ 的深度界。这是一个 EREW-PRAM 算法，因为在每个层级，不相交的节点对被读取和写入，没有冲突。\n\n调整以计算移动平均值。定义排除性前缀和 $P$ 为 $P[0] = 0$ 且 $P[i] = \\sum_{k=0}^{i-1} A[k]$，对于 $i \\in \\{1,\\dots,n\\}$（$P$ 自然地扩展到填充后的长度 $m$）。对于满足 $1 \\le w \\le n$ 的窗口长度 $w$，窗口 $A[i] + \\dots + A[i+w-1]$ 的和通过对消等于 $P[i+w] - P[i]$。因此，移动平均值为\n$$\nM[i] \\;=\\; \\frac{P[i+w] - P[i]}{w}, \\quad i \\in \\{0,\\dots,n-w\\}.\n$$\n这 $n-w+1$ 个值可以通过一个同步减法步骤并行计算所有有效 $i$ 的 $P[i+w] - P[i]$（深度为 $1$，工作量为 $n-w+1$），然后通过一个同步除法步骤除以 $w$（深度为 $1$，工作量为 $n-w+1$）。完整算法的成本为：\n$$\nW \\;=\\; W_{\\text{scan}} + (n-w+1) + (n-w+1) \\;=\\; 2m - 2 + 2(n-w+1),\n$$\n$$\nD \\;=\\; D_{\\text{scan}} + 1 + 1 \\;=\\; 2 \\log_{2} m + 2,\n$$\n其中 $m$ 是满足 $m \\ge n$ 的最小的2的幂。由于 $m \\le 2n$，我们得到 $W \\in \\Theta(n)$ 和 $D \\in \\Theta(\\log n)$，因此移动平均值算法在 EREW-PRAM 上也实现了 $O(n)$ 的工作量和 $O(\\log n)$ 的深度。\n\n测试套件的数值输出。使用上述方法并将所有实数四舍五入到 $6$ 位小数：\n- 测试 1：$A = [1,2,3,4,5,6,7,8]$, $w = 3$, $n = 8$, $m = 8$。移动平均值为 $[2.000000,3.000000,4.000000,5.000000,6.000000,7.000000]$。成本：$W = 2 \\cdot 8 - 2 + 2 \\cdot (8-3+1) = 14 + 12 = 26$, $D = 2 \\log_{2} 8 + 2 = 6 + 2 = 8$。\n\n- 测试 2：$A = [42]$, $w = 1$, $n = 1$, $m = 1$。移动平均值为 $[42.000000]$。成本：$W = 2 \\cdot 1 - 2 + 2 \\cdot (1-1+1) = 0 + 2 = 2$, $D = 2 \\log_{2} 1 + 2 = 0 + 2 = 2$。\n\n- 测试 3：$A = [-2,0,5,-1,3]$, $w = 5$, $n = 5$, $m = 8$。移动平均值为 $[1.000000]$。成本：$W = 2 \\cdot 8 - 2 + 2 \\cdot (5-5+1) = 14 + 2 = 16$, $D = 2 \\log_{2} 8 + 2 = 6 + 2 = 8$。\n\n- 测试 4：$A = [0.5,-0.5,1.5,2.0]$, $w = 2$, $n = 4$, $m = 4$。移动平均值为 $[0.000000,0.500000,1.750000]$。成本：$W = 2 \\cdot 4 - 2 + 2 \\cdot (4-2+1) = 6 + 6 = 12$, $D = 2 \\log_{2} 4 + 2 = 4 + 2 = 6$。\n\n- 测试 5：$A = [3,1,4,1,5,9]$, $w = 4$, $n = 6$, $m = 8$。移动平均值为 $[2.250000,2.750000,4.750000]$。成本：$W = 2 \\cdot 8 - 2 + 2 \\cdot (6-4+1) = 14 + 6 = 20$, $D = 2 \\log_{2} 8 + 2 = 6 + 2 = 8$。\n\n最终答案中的程序实现了使用前缀和计算移动平均值的方法，并使用上述实例化报告了相应的工作量和深度。它打印一个无空格的类JSON列表，其中每个测试用例贡献一对，包含移动平均值列表和 $[W,D]$ 列表，所有实数都四舍五入到 $6$ 位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef next_power_of_two(n: int) -> int:\n    \"\"\"Return the smallest power of two >= n for n >= 1.\"\"\"\n    if n == 1:\n        return 1\n    return 1  (n - 1).bit_length()\n\ndef compute_work_depth(n: int, w: int) -> tuple[int, int]:\n    \"\"\"\n    Compute total work and depth under the specified EREW-PRAM instantiation:\n    - Exclusive scan via up-sweep and down-sweep over m = next_power_of_two(n),\n      with W_scan = 2*m - 2, D_scan = 2*log2(m).\n    - Then one parallel subtraction pass and one parallel division pass over\n      (n - w + 1) elements (each pass depth 1 and work n - w + 1).\n    \"\"\"\n    m = next_power_of_two(n)\n    W_scan = 2 * m - 2  # total arithmetic ops across both sweeps\n    # log2(m) since m is power of two equals bit_length-1\n    D_scan = 2 * (m.bit_length() - 1)\n    window_count = n - w + 1\n    W_total = W_scan + window_count + window_count\n    D_total = D_scan + 1 + 1\n    return W_total, D_total\n\ndef moving_average_via_prefix(A: list[float], w: int) -> list[float]:\n    \"\"\"\n    Compute moving averages using exclusive prefix sums:\n    M[i] = (P[i+w] - P[i]) / w where P[0] = 0 and P[k] = sum_{t=0}^{k-1} A[t].\n    Returns floats rounded only at formatting time; values are double precision.\n    \"\"\"\n    # Exclusive prefix sums: P[0]=0, P[i+1]=P[i]+A[i]\n    P = [0.0]\n    s = 0.0\n    for x in A:\n        s += float(x)\n        P.append(s)\n    n = len(A)\n    res = []\n    for i in range(0, n - w + 1):\n        window_sum = P[i + w] - P[i]\n        res.append(window_sum / float(w))\n    return res\n\ndef format_no_spaces(value):\n    \"\"\"\n    Format nested lists of ints/floats without spaces.\n    Floats are rendered with exactly 6 decimal places.\n    \"\"\"\n    if isinstance(value, list):\n        return \"[\" + \",\".join(format_no_spaces(v) for v in value) + \"]\"\n    # Handle numpy scalar types\n    if isinstance(value, (np.floating,)):\n        return f\"{float(value):.6f}\"\n    if isinstance(value, (np.integer,)):\n        return str(int(value))\n    if isinstance(value, float):\n        return f\"{value:.6f}\"\n    if isinstance(value, int):\n        return str(value)\n    # Fallback: convert to float if possible\n    try:\n        fv = float(value)\n        return f\"{fv:.6f}\"\n    except Exception:\n        return str(value)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Each case is (A, w)\n        ([1, 2, 3, 4, 5, 6, 7, 8], 3),\n        ([42], 1),\n        ([-2, 0, 5, -1, 3], 5),\n        ([0.5, -0.5, 1.5, 2.0], 2),\n        ([3, 1, 4, 1, 5, 9], 4),\n    ]\n\n    results = []\n    for A, w in test_cases:\n        n = len(A)\n        # Compute moving averages via prefix sums\n        mavgs = moving_average_via_prefix(A, w)\n        # Compute work and depth according to the specified model\n        W, D = compute_work_depth(n, w)\n        # Round moving averages at formatting time; store as floats\n        results.append([mavgs, [W, D]])\n\n    # Final print statement in the exact required format: no spaces.\n    print(format_no_spaces(results))\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了基础的并行构件后，我们转向一个更通用的算法范式：动态规划。尽管动态规划天然带有顺序依赖性，但诸如“反斜线波前”(anti-diagonal wavefront)的模式能够实现显著的并行化。这个问题挑战你将此方法应用于经典的最长公共子序列（LCS）问题，并在CREW PRAM模型下分析其性能 。",
            "id": "3258264",
            "problem": "在并行随机存取机 (PRAM) 模型下，设计并分析一个并行算法，用于计算两个等长字符串的最长公共子序列 (LCS) 长度。您的算法必须针对 PRAM 的并发读取独占写入 (CREW) 变体（Concurrent Read Exclusive Write (CREW) PRAM）进行指定，并在工作-深度 (WD) 模型中进行分析，其中总工作量表示为 $W$，深度（也称为跨度或关键路径长度）表示为 $D$。工作-深度 (WD) 模型将 $W$ 解释为原始操作的总数，将 $D$ 解释为算法有向无环图中依赖关系最长链的长度。\n\n从以下基本依据出发：\n- 两个字符串之间的 LCS 长度可以通过一个定义在索引 $i \\in \\{0,\\dots,n\\}$ 和 $j \\in \\{0,\\dots,n\\}$ 上的动态规划表 $D[i,j]$ 计算，其边界条件为 $D[0,j] = 0$ 和 $D[i,0] = 0$。$D[i,j]$ 的依赖关系完全取决于 $D[i-1,j-1]$、$D[i-1,j]$ 和 $D[i,j-1]$ 这几项。\n- 在 CREW PRAM 模型中，多个处理器可以在同一步骤中读取同一内存位置，但每一步最多只有一个处理器可以写入任何内存位置。\n- 在工作-深度 (WD) 模型中，$W$ 是所有处理器执行的操作总数，$D$ 是沿最长依赖链的并行步骤数。如果有 $p$ 个处理器可用，一个理想化的调度器产生的运行时间上界约为 $W/p + D$。\n\n任务：\n1. 提出一个并行算法，在 CREW PRAM 上利用反对角线（波前）调度来利用其依赖结构，以评估 LCS 的动态规划表。精确描述每一步的计算以及同一反对角线内单元的独立性。\n2. 仅使用上述基本依据，推导对于等长为 $n$ 的输入的工作量 $W(n)$ 和深度 $D(n)$。\n3. 实现一个程序，对于下面给出的一个固定的等长字符串对测试套件，计算：\n   - 使用与 CREW PRAM 假设一致的反对角线调度计算出的 LCS 长度，\n   - 每个测试用例推导出的 $W(n)$ 和 $D(n)$，其中 $n$ 是字符串对的公共长度。\n4. 边界条件：如果 $n = 0$，定义深度为 $D(0) = 0$，工作量为 $W(0) = 0$。\n5. 用于覆盖正确性和分析方面的测试套件：\n   - 案例 A (小规模，不匹配): $(\"a\",\"b\")$，其中 $n = 1$。\n   - 案例 B (小规模，相同): $(\"abc\",\"abc\")$，其中 $n = 3$。\n   - 案例 C (中等规模，部分重叠): $(\"abcde\",\"acebd\")$，其中 $n = 5$。\n   - 案例 D (统一，不相交): $(\"aaaa\",\"bbbb\")$，其中 $n = 4$。\n   - 案例 E (经典，丰富): $(\"XMJYAUZQ\",\"MZJAWXUQ\")$，其中 $n = 8$。\n6. 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例报告为一个三元组 $[\\ell, W, D]$，其中 $\\ell$ 是 LCS 长度，$W$ 和 $D$ 是对应于给定 $n$ 的分析得出的整数。该行中不得有任何空格。对于上述五个案例，按顺序的输出格式为：\n   - $[[\\ell_1,W_1,D_1],[\\ell_2,W_2,D_2],[\\ell_3,W_3,D_3],[\\ell_4,W_4,D_4],[\\ell_5,W_5,D_5]]$。\n\n所有答案纯粹是数学或算法性质的，不带任何物理单位。不涉及角度。不涉及百分比。测试套件的最终输出必须是整数。",
            "solution": "计算两个字符串的最长公共子序列 (LCS) 是一个经典的动态规划问题。给定两个长度均为 $n$ 的字符串，$X = x_1x_2...x_n$ 和 $Y = y_1y_2...y_n$。任务是为 CREW PRAM 模型设计并分析一个并行算法来找到它们 LCS 的长度。\n\n令 $D[i,j]$ 表示前缀 $X[1..i]$ 和 $Y[1..j]$ 的 LCS 长度，其中索引 $i$ 和 $j$ 的范围是从 $0$ 到 $n$。动态规划公式由以下递推关系定义：\n$$\nD[i,j] =\n\\begin{cases}\n  0   \\text{if } i=0 \\text{ or } j=0 \\\\\n  D[i-1,j-1] + 1   \\text{if } i,j  0 \\text{ and } x_i = y_j \\\\\n  \\max(D[i-1,j], D[i,j-1])   \\text{if } i,j  0 \\text{ and } x_i \\neq y_j\n\\end{cases}\n$$\n$D[n,n]$ 的值给出了完整字符串 $X$ 和 $Y$ 的最终 LCS 长度。\n\n该递推关系的依赖结构表明，$D[i,j]$ 的计算需要来自单元 $(i-1,j-1)$、$(i-1,j)$ 和 $(i,j-1)$ 的值。这种结构表明，简单的按行或按列并行化是不可行的，因为行/列中的每个单元都依赖于同一行/列中的前一个单元。\n\n### 第 1 部分：使用反对角线波前调度的并行算法\n\n一个合适的并行化策略是反对角线或波前方法。我们可以根据 DP 表 $D$ 中单元格索引的和将其分组。一条反对角线，记为 $A_k$，是所有满足 $i+j=k$（其中 $1 \\le i, j \\le n$）的单元格 $(i,j)$ 的集合。\n\n关键的观察点是，给定反对角线 $A_k$ 上的所有单元格 $D[i,j]$ 可以在一个并行步骤中同时计算。这是因为它们的依赖项——$D[i-1,j-1]$、$D[i-1,j]$ 和 $D[i,j-1]$——属于之前的反对角线。具体来说，对于一个单元格 $(i,j) \\in A_k$：\n- 依赖项 $(i-1, j-1)$ 位于反对角线 $A_{k-2}$ 上，因为 $(i-1)+(j-1) = k-2$。\n- 依赖项 $(i-1, j)$ 和 $(i, j-1)$ 位于反对角线 $A_{k-1}$ 上，因为 $(i-1)+j = k-1$ 且 $i+(j-1) = k-1$。\n\n因此，如果直到 $A_{k-1}$ 的所有反对角线的值都已计算完毕，那么 $A_k$ 的所有值都可以并行计算，它们之间没有任何数据依赖关系。该算法像一个“波前”一样扫过 DP 表，从左上角到右下角。\n\n用于 CREW PRAM 的算法如下：\n1.  **初始化**：对于所有 $i \\in \\{0, \\dots, n\\}$ 设置 $D[i,0] = 0$，对于所有 $j \\in \\{0, \\dots, n\\}$ 设置 $D[0,j] = 0$。这可以通过 $2n+1$ 个处理器在一个并行步骤中完成，或者被视为一个耗时 $O(1)$ 的预计算步骤。\n2.  **迭代计算**：反对角线索引 $k=i+j$ 的范围从单元格 $(1,1)$ 的 $k=2$ 到单元格 $(n,n)$ 的 $k=2n$。算法按离散时间步 $s = 1, 2, \\dots, 2n-1$ 进行。\n    - 对于从 $1$ 到 $2n-1$ 的每一步 $s$：\n        - 设反对角线索引为 $k = s+1$。\n        - 对于反对角线 $A_k$ 上的每个单元格 $(i,j)$（即所有满足 $i+j=k$ 且 $1 \\le i,j \\le n$ 的 $(i,j)$），分配一个处理器。\n        - 分配给 $(i,j)$ 的处理器执行以下操作：\n            - **读取**：它从共享内存中读取 $D[i-1,j-1]$、$D[i-1,j]$ 和 $D[i,j-1]$ 的值。它还读取字符 $x_i$ 和 $y_j$。同一反对角线上不同单元格的多个处理器可能会读取相同的值（例如，处理 $(i,j)$ 的处理器和处理 $(i-1, j+1)$ 的处理器都读取 $D[i-1,j]$）。这在并发读取 (CR) 规则下是允许的。\n            - **计算**：它使用 LCS 递推关系计算 $D[i,j]$ 的值。\n            - **写入**：它将计算出的值写入 $D[i,j]$ 的内存位置。由于在当前步骤中每个处理器被分配给一个唯一的单元格 $(i,j)$，因此不会有两个处理器试图写入同一内存位置。这遵守了独占写入 (EW) 规则。\n\n3.  **结果**：在对应于 $k=2n$ 的最后一步之后，$D[n,n]$ 的值即为 LCS 长度。\n\n### 第 2 部分：工作量与深度分析\n\n我们针对长度为 $n$ 的字符串，在工作-深度 (WD) 模型中分析该算法。\n\n**深度 ($D(n)$)**：\n并行算法的深度是最长顺序依赖链的长度，这对应于并行步骤的数量。在我们的反对角线算法中，每一步计算一个完整的反对角线。步骤中每个单元格的计算是常数时间操作，因此每个并行步骤耗时 $O(1)$。总步骤数由必须计算的反对角线数量决定。\n反对角线由 $k=i+j$ 索引，其中 $1 \\le i,j \\le n$。索引 $k$ 的范围从 $1+1=2$ 到 $n+n=2n$。这样的反对角线数量为 $(2n) - 2 + 1 = 2n-1$。\n因此，有 $2n-1$ 个顺序步骤。\n- 对于 $n \\ge 1$，深度为 $D(n) = 2n-1$。\n- 根据问题陈述，对于 $n=0$，表格为空，无需计算，因此 $D(0)=0$。\n\n**工作量 ($W(n)$)**：\n工作量是所有处理器执行的基本操作的总数。核心计算涉及填充 DP 表的 $n \\times n$ 网格（从索引 $1$ 到 $n$）。对于 $n^2$ 个单元格中的每一个，我们执行常数数量的操作：字符比较、读取最多 $3$ 个值、一次可能的加法和一次取最大值操作。\n在工作-深度模型中，通常将工作量定义为主要计算任务的总数。在这里，任务是更新单个单元格 $D[i,j]$。由于对于 $1 \\le i,j \\le n$ 有 $n^2$ 个这样的单元格需要计算，因此总工作量与 $n^2$ 成正比。通过将比例常数设为 $1$（即将每个单元格更新计为一个工作单位），我们得到：\n- 对于 $n \\ge 0$，工作量为 $W(n) = n^2$。\n\n这与 $W(0)=0$ 的边界条件一致。\n\n总结分析如下：\n- 工作量：$W(n) = n^2$\n- 深度：对于 $n \\ge 1$，$D(n) = 2n-1$；对于 $n=0$，$D(0)=0$。\n\n### 第 3 和 4 部分：实现与测试用例\n\n实现将使用标准的串行动态规划算法计算 LCS 长度，因为其结果与并行算法的结果相同。然后，它将对每个测试用例使用推导出的公式计算 $W(n)$ 和 $D(n)$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes LCS length, Work (W), and Depth (D) for a test suite\n    of string pairs based on a CREW PRAM anti-diagonal algorithm.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\"a\", \"b\"),            # Case A\n        (\"abc\", \"abc\"),        # Case B\n        (\"abcde\", \"acebd\"),    # Case C\n        (\"aaaa\", \"bbbb\"),      # Case D\n        (\"XMJYAUZQ\", \"MZJAWXUQ\")  # Case E\n    ]\n\n    results = []\n    for s1, s2 in test_cases:\n        n = len(s1)\n        \n        # Part 4: Handle edge conditions (although not present in test suite)\n        if n == 0:\n            lcs_len = 0\n            W = 0\n            D = 0\n        else:\n            # Part 2: Derive Work and Depth\n            # Work W(n) is the total number of cells to compute.\n            W = n * n\n            # Depth D(n) is the number of anti-diagonals to process.\n            D = 2 * n - 1\n\n            # Part 3: Compute LCS length\n            # The LCS length is computed using a standard dynamic programming\n            # approach, which fills the table in an order consistent with\n            # the dependencies of the anti-diagonal schedule.\n            dp_table = np.zeros((n + 1, n + 1), dtype=int)\n            \n            for i in range(1, n + 1):\n                for j in range(1, n + 1):\n                    if s1[i - 1] == s2[j - 1]:\n                        dp_table[i, j] = dp_table[i - 1, j - 1] + 1\n                    else:\n                        dp_table[i, j] = max(dp_table[i - 1, j], dp_table[i, j - 1])\n            \n            lcs_len = int(dp_table[n, n])\n\n        results.append([lcs_len, W, D])\n\n    # Part 6: Format the output as specified, with no spaces.\n    # e.g., [[l1,W1,D1],[l2,W2,D2],...]\n    output_parts = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in results]\n    final_output = f\"[{','.join(output_parts)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "设计完并行算法后，理解其性能瓶颈至关重要。最后一个练习提出了一个反直觉但现实的场景：增加处理器数量反而可能导致总执行时间增加。通过分析工作量项 ($W/P$) 和深度项 ($D$) 之间的相互作用，你将对工作-深度模型以及并行计算扩展的实际挑战有更深刻的认识 。",
            "id": "3258375",
            "problem": "考虑一个算法，它通过 $R$ 个阶段处理一个数组，其中每个阶段执行 $S$ 个独立的单位时间任务，然后在下一阶段开始前有一个全局同步屏障。假设屏障在 $P$ 个处理器上以二叉树的形式实现，因此屏障在关键路径上贡献了长度为 $\\lceil \\log_2 P \\rceil$ 的每阶段依赖链。总工作量为 $W = R \\cdot S$，不包括屏障的计算深度为 $R$（每个阶段一个依赖步骤，表示在屏障和下一阶段之前需要完成该阶段的任务）。\n\n您将使用关于工作和依赖结构的基本原理，在“工作-深度”模型下分析总执行时间 $T_P$ 如何随着 $P$ 的增加而变化。使用以下具体参数来确定思路：$R = 100$ 个阶段，每个阶段 $S = 1000$ 个任务，因此 $W = 100{,}000$ 个单位操作。考虑 $P \\in \\{32, 64, 128, 256\\}$。\n\n在这种情况下，关于这些 $P$ 值下 $T_P$ 的行为，以下哪个陈述是正确的？\n\nA. 当 $P$ 从 $128$ 增加到 $256$ 时，执行时间 $T_P$ 增加；具体来说，$T_{256}  T_{128}$，这是因为屏障的依赖链像 $\\log_2 P$ 一样增长并占据主导地位。\n\nB. 对于集合 $\\{32, 64, 128, 256\\}$ 中的所有 $P$，$T_P$ 随着 $P$ 的增加而严格减少，因为在“工作-深度”模型下，更高的并行度总是会减少时间。\n\nC. 屏障成本不影响计算的深度，所以 $T_{32} = T_{256}$。\n\nD. 当 $P$ 从 $32$ 增加到 $64$ 时，每个处理器的工作量增加，因此即使存在屏障，$T_{64}  T_{32}$。",
            "solution": "### 分析框架\n我们将使用“工作-深度”模型来分析并行算法在 $P$ 个处理器上的执行时间 $T_P$。该模型给出了两个基本下界：\n1.  **工作量下界**: 执行时间至少是总工作量 $W$ 平均分配给 $P$ 个处理器的结果，即 $T_P \\ge W/P$。\n2.  **深度下界**: 执行时间不能少于最长顺序依赖链的长度，即深度 $D$，即 $T_P \\ge D$。\n\n一个理想化的执行时间模型可以表示为 $T_P \\approx W/P + D$，但在分析瓶颈时，更常用的是 $T_P \\approx \\max(W/P, D)$，因为它清楚地分开了受工作量限制（work-bound）和受深度限制（depth-bound/span-bound）的区域。我们将使用后者进行分析。\n\n### 定义工作量和深度\n根据问题描述：\n- 总工作量 $W = R \\cdot S = 100 \\cdot 1000 = 100,000$ 个操作。这是一个常数，与处理器数量 $P$ 无关。\n- 总深度 $D(P)$ 是所有 $R$ 个阶段的深度之和。每个阶段由一个深度为 1 的并行任务步骤和一个深度为 $\\lceil \\log_2 P \\rceil$ 的屏障组成。因此，一个阶段的深度是 $1 + \\lceil \\log_2 P \\rceil$。由于 $R$ 个阶段是顺序的，总深度为：\n  $$ D(P) = R \\cdot (1 + \\lceil \\log_2 P \\rceil) = 100 \\cdot (1 + \\lceil \\log_2 P \\rceil) $$\n  深度 $D(P)$ 随着处理器数量 $P$ 的增加而增加。\n\n### 计算不同 $P$ 值下的执行时间\n现在我们为每个给定的 $P$ 值计算 $W/P$ 和 $D(P)$，然后取其最大值得到 $T_P$。\n\n**对于 $P = 32$**:\n- 工作量项: $W/P = 100,000 / 32 = 3125$。\n- 深度项: $D(32) = 100 \\cdot (1 + \\lceil \\log_2 32 \\rceil) = 100 \\cdot (1 + 5) = 600$。\n- $T_{32} = \\max(3125, 600) = 3125$。执行是**受工作量限制的**。\n\n**对于 $P = 64$**:\n- 工作量项: $W/P = 100,000 / 64 = 1562.5$。\n- 深度项: $D(64) = 100 \\cdot (1 + \\lceil \\log_2 64 \\rceil) = 100 \\cdot (1 + 6) = 700$。\n- $T_{64} = \\max(1562.5, 700) = 1562.5$。执行是**受工作量限制的**。\n\n**对于 $P = 128$**:\n- 工作量项: $W/P = 100,000 / 128 = 781.25$。\n- 深度项: $D(128) = 100 \\cdot (1 + \\lceil \\log_2 128 \\rceil) = 100 \\cdot (1 + 7) = 800$。\n- $T_{128} = \\max(781.25, 800) = 800$。执行转为**受深度限制的**。\n\n**对于 $P = 256$**:\n- 工作量项: $W/P = 100,000 / 256 = 390.625$。\n- 深度项: $D(256) = 100 \\cdot (1 + \\lceil \\log_2 256 \\rceil) = 100 \\cdot (1 + 8) = 900$。\n- $T_{256} = \\max(390.625, 900) = 900$。执行是**受深度限制的**。\n\n### 总结与选项分析\n执行时间序列如下：\n- $T_{32} = 3125$\n- $T_{64} = 1562.5$\n- $T_{128} = 800$\n- $T_{256} = 900$\n\n我们可以观察到，当 $P$ 从 32 增加到 128 时，执行时间减少。然而，当 $P$ 从 128 增加到 256 时，执行时间从 800 增加到 900。\n\n现在我们来评估每个选项：\n\n**A. 当 $P$ 从 $128$ 增加到 $256$ 时，执行时间 $T_P$ 增加；具体来说，$T_{256}  T_{128}$，这是因为屏障的依赖链像 $\\log_2 P$ 一样增长并占据主导地位。**\n- 我们的计算表明 $T_{256} = 900$ 确实大于 $T_{128} = 800$。\n- 原因在于，在这些较高的 $P$ 值下，深度项 $D(P)$ 成为执行时间的决定因素。由于 $D(P)$ 随 $P$ 增加而增加，总执行时间也随之增加。这个理由是正确的。\n- **此陈述是正确的。**\n\n**B. 对于集合 $\\{32, 64, 128, 256\\}$ 中的所有 $P$，$T_P$ 随着 $P$ 的增加而严格减少，因为在“工作-深度”模型下，更高的并行度总是会减少时间。**\n- 这个陈述是错误的，因为 $T_{256}  T_{128}$。其理由也是一个常见的误解。\n\n**C. 屏障成本不影响计算的深度，所以 $T_{32} = T_{256}$。**\n- 这个陈述的前提与问题描述相矛盾，屏障成本明确地影响深度。其结论 ($T_{32} = 3125 \\ne T_{256} = 900$) 也是错误的。\n\n**D. 当 $P$ 从 $32$ 增加到 $64$ 时，每个处理器的工作量增加，因此即使存在屏障，$T_{64}  T_{32}$。**\n- 这个陈述的前提“每个处理器的工作量增加”是错误的；$W/P$ 会减少。其结论 ($T_{64} = 1562.5  T_{32} = 3125$) 也是错误的。\n\n因此，唯一正确的陈述是 A。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}