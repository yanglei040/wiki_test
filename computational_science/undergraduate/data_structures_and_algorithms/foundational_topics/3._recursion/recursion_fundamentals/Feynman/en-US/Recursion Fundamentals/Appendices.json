{
    "hands_on_practices": [
        {
            "introduction": "Before writing complex recursive algorithms, it is crucial to understand how to analyze their efficiency. Recurrence relations are the primary mathematical tool for describing the performance of recursive functions. This first exercise  provides practice in solving a non-trivial recurrence relation, $T(n) = T(\\sqrt{n}) + \\ln(n)$, which often arises in algorithms that reduce problem size exponentially. By using the method of repeated substitution, you will develop the skill to transform a recursive formula into an exact, closed-form solution, giving you a precise understanding of the algorithm's cost.",
            "id": "3264680",
            "problem": "Consider a recursive procedure on an input of size $n$ that performs exactly $\\ln n$ primitive operations before making a single recursive call on input size $\\sqrt{n}$, and terminates when the input size reaches $2$. Let $T(n)$ denote the exact number of primitive operations performed by this procedure on input size $n$, including all recursive calls. Assume the cost of the base case is $T(2)$, a fixed constant, and that $\\ln$ denotes the natural logarithm. To avoid rounding issues from the square-root recursion, assume the input size is restricted to the set $\\{2^{2^{k}} : k \\in \\mathbb{N}, k \\geq 0\\}$ so that every recursive call exactly lands on an integer until the base case $2$ is reached.\n\nStarting from the fundamental definition of recursion as repeated self-reduction and the exact counting of operations per invocation, derive a closed-form expression for $T(n)$ as a function of $n$ and $T(2)$ under the stated assumptions. Your answer must be an exact analytic expression, not an asymptotic form, and should be expressed using the natural logarithm.",
            "solution": "The problem statement has been analyzed and is determined to be valid. It is a well-posed problem in the analysis of algorithms, free of scientific or logical inconsistencies. The provided assumptions, particularly the domain restriction for the input size $n$, ensure that the recurrence relation can be solved exactly without ambiguity.\n\nThe problem describes a recursive procedure. Let $T(n)$ be the total number of primitive operations for an input of size $n$. The procedure performs $\\ln n$ operations and then makes a recursive call on an input of size $\\sqrt{n}$. The total cost $T(n)$ is therefore the sum of the cost at the current step and the cost of the recursive subproblem. This can be expressed as the following recurrence relation:\n$$T(n) = \\ln(n) + T(\\sqrt{n})$$\nThe recursion terminates when the input size reaches $2$, at which point the cost is a constant, denoted as $T(2)$. This provides the base case for the recurrence relation.\n\nTo find a closed-form expression for $T(n)$, we can use the method of repeated substitution, also known as unrolling or iteration.\n\nStarting with the recurrence for $T(n)$:\n$$T(n) = \\ln(n) + T(n^{1/2})$$\nWe substitute the expression for the recursive term, $T(n^{1/2})$:\n$$T(n^{1/2}) = \\ln(n^{1/2}) + T((n^{1/2})^{1/2}) = \\ln(n^{1/2}) + T(n^{1/4})$$\nSubstituting this back into the equation for $T(n)$:\n$$T(n) = \\ln(n) + \\ln(n^{1/2}) + T(n^{1/4})$$\nUsing the logarithm property $\\ln(x^y) = y \\ln(x)$, this becomes:\n$$T(n) = \\ln(n) + \\frac{1}{2}\\ln(n) + T(n^{1/4})$$\nWe can repeat this substitution process. The next step yields:\n$$T(n) = \\ln(n) + \\frac{1}{2}\\ln(n) + \\ln(n^{1/4}) + T(n^{1/8})$$\n$$T(n) = \\ln(n) + \\frac{1}{2}\\ln(n) + \\frac{1}{4}\\ln(n) + T(n^{1/8})$$\nA clear pattern emerges. After $m$ steps of unrolling, the expression for $T(n)$ is:\n$$T(n) = \\ln(n) \\left(1 + \\frac{1}{2} + \\frac{1}{4} + \\dots + \\frac{1}{2^{m-1}}\\right) + T(n^{1/2^m})$$\n$$T(n) = \\ln(n) \\sum_{i=0}^{m-1} \\left(\\frac{1}{2}\\right)^i + T(n^{1/2^m})$$\nThe recursion terminates when the input size reaches the base case, $2$. We need to find the number of steps, $m$, for this to occur.\n$$n^{1/2^m} = 2$$\nTo solve for $m$, we take the natural logarithm of both sides:\n$$\\ln(n^{1/2^m}) = \\ln(2)$$\n$$\\frac{1}{2^m} \\ln(n) = \\ln(2)$$\nRearranging for $\\frac{1}{2^m}$ gives:\n$$\\frac{1}{2^m} = \\frac{\\ln(2)}{\\ln(n)}$$\nThe term $T(n^{1/2^m})$ in the unrolled expression becomes $T(2)$.\n\nThe sum in the expression for $T(n)$ is a finite geometric series:\n$$S_m = \\sum_{i=0}^{m-1} \\left(\\frac{1}{2}\\right)^i = \\frac{1 - (1/2)^m}{1 - 1/2}$$\n$$S_m = \\frac{1 - (1/2)^m}{1/2} = 2\\left(1 - \\left(\\frac{1}{2}\\right)^m\\right)$$\nNow we substitute this sum back into the equation for $T(n)$:\n$$T(n) = \\ln(n) \\cdot 2\\left(1 - \\left(\\frac{1}{2}\\right)^m\\right) + T(2)$$\nWe can replace the term $(1/2)^m$ using our previously derived relation $\\frac{1}{2^m} = \\frac{\\ln(2)}{\\ln(n)}$:\n$$T(n) = 2\\ln(n) \\left(1 - \\frac{\\ln(2)}{\\ln(n)}\\right) + T(2)$$\nDistributing the $2\\ln(n)$ term through the parenthesis:\n$$T(n) = 2\\ln(n) \\cdot 1 - 2\\ln(n) \\cdot \\frac{\\ln(2)}{\\ln(n)} + T(2)$$\n$$T(n) = 2\\ln(n) - 2\\ln(2) + T(2)$$\nThis can be written more compactly using the logarithm property $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$T(n) = 2(\\ln(n) - \\ln(2)) + T(2) = 2\\ln\\left(\\frac{n}{2}\\right) + T(2)$$\nTo ensure correctness, we can verify this closed-form solution by substituting it back into the original recurrence relation $T(n) = \\ln(n) + T(\\sqrt{n})$:\nRight Hand Side $= \\ln(n) + T(\\sqrt{n})$\n$= \\ln(n) + \\left(2\\ln(\\sqrt{n}) - 2\\ln(2) + T(2)\\right)$\n$= \\ln(n) + \\left(2\\ln(n^{1/2}) - 2\\ln(2) + T(2)\\right)$\n$= \\ln(n) + \\left(2 \\cdot \\frac{1}{2}\\ln(n) - 2\\ln(2) + T(2)\\right)$\n$= \\ln(n) + \\ln(n) - 2\\ln(2) + T(2)$\n$= 2\\ln(n) - 2\\ln(2) + T(2)$\nThis result matches our derived expression for $T(n)$, confirming the solution is correct. The base case check $T(2) = 2\\ln(2) - 2\\ln(2) + T(2) = T(2)$ also holds. The assumption that $n$ is in the set $\\{2^{2^{k}} : k \\in \\mathbb{N}, k \\geq 0\\}$ guarantees that the argument to $T$ is always an integer power of $2$ when a square root is taken, until it reaches $2$.\nFor example, if $n=2^{2^k}$, then $\\sqrt{n}=2^{2^{k-1}}$, and so on, reaching $2^{2^0}=2$ after $k$ steps. This validates the structure of our derivation.\n\nThe final closed-form expression for $T(n)$ is a function of $n$ and the constant $T(2)$.",
            "answer": "$$\\boxed{2\\ln(n) - 2\\ln(2) + T(2)}$$"
        },
        {
            "introduction": "Moving from quantitative analysis to qualitative reasoning, this practice focuses on the process of recursion itself. The Tower of Hanoi is a classic pedagogical tool for introducing recursion, but a true understanding goes beyond memorizing the formula for the number of moves. This problem  introduces a constraint to the standard rules, challenging you to analyze how the recursive process unfolds step-by-step. Solving it requires you to reason about the state of the system at each level of recursion, testing your conceptual grasp of the algorithm's behavior.",
            "id": "3264714",
            "problem": "Consider the classical Tower of Hanoi with three pegs labeled $S$ (source), $A$ (auxiliary), and $T$ (target), and $n$ disks labeled $1, 2, \\dots, n$, where disk $1$ is the smallest and disk $n$ is the largest. Initially, all $n$ disks are stacked on peg $S$ in increasing order of size from top (small) to bottom (large). A legal move transfers one disk from the top of a peg to the top of another peg, and at all times no disk may be placed on top of a smaller disk. \n\nIn addition to these rules, impose the constraint that a specific disk $k$ can never occupy peg $A$ at any time during the process. You must move the entire stack from peg $S$ to peg $T$ while respecting all rules and the added constraint.\n\nAssume $k = n$ so that the forbidden disk is the largest one. Determine, in closed form, the minimal number of moves required to complete the task as a function of $n$. Provide your final answer as a single analytic expression and do not round or approximate.",
            "solution": "The problem statement is critically validated as follows:\n1.  **Givens Extracted**:\n    - A system of $3$ pegs: a source peg $S$, an auxiliary peg $A$, and a target peg $T$.\n    - A set of $n$ disks, labeled $1, 2, \\dots, n$ in increasing order of size.\n    - Initial state: All $n$ disks are on peg $S$.\n    - Final state: All $n$ disks are on peg $T$.\n    - Standard rules of Tower of Hanoi:\n        i. Only one disk can be moved at a time.\n        ii. A move consists of taking the upper disk from one stack and placing it on top of another stack.\n        iii. No disk may be placed on top of a smaller disk.\n    - Additional constraint: A specific disk $k$ is forbidden from ever occupying peg $A$.\n    - Specific instance for this problem: The forbidden disk is the largest one, i.e., $k=n$.\n    - Objective: Determine the minimal number of moves required to move all $n$ disks from $S$ to $T$.\n\n2.  **Validation Verdict**:\n    - The problem is **valid**. It is a well-posed variation of a classical problem in discrete mathematics and algorithms (the Tower of Hanoi). It is self-contained, logically consistent, and free of scientific or factual unsoundness. The constraint, while modifying the problem space, does not introduce a contradiction or make the problem unsolvable. The objective is clearly defined and seeks a definite mathematical quantity.\n\nThe solution proceeds as follows.\n\nLet $N(n, S, A, T)$ denote the minimal number of moves required to transfer a stack of $n$ disks from a source peg $S$ to a target peg $T$, using an auxiliary peg $A$, under the constraint that disk $n$ can never be placed on peg $A$.\n\nThe process of moving the entire tower of $n$ disks from peg $S$ to peg $T$ must, at some point, involve the movement of the largest disk, disk $n$. The only way to move disk $n$ from $S$ is if all smaller disks, i.e., disks $1, 2, \\dots, n-1$, are not on peg $S$. Furthermore, for disk $n$ to be moved to its final destination $T$, peg $T$ must be free of any smaller disks. Therefore, to make the move of disk $n$ from $S$ to $T$ possible, all $n-1$ smaller disks must be located on the only remaining peg, which is peg $A$.\n\nThe overall process can thus be decomposed into three distinct, sequential phases:\n\n**Phase 1: Move disks $1, 2, \\dots, n-1$ from peg $S$ to peg $A$.**\n- During this phase, the largest disk, disk $n$, remains at the bottom of peg $S$.\n- The constraint specifies that disk $n$ cannot occupy peg $A$. Since disk $n$ is not moved in this phase, the constraint is not violated.\n- The disks $1, 2, \\dots, n-1$ are not subject to this specific constraint and are free to use any of the three pegs $S$, $A$, and $T$ as required, as long as they obey the standard rules.\n- This phase is therefore equivalent to solving the standard Tower of Hanoi problem for $n-1$ disks, with $S$ as the source, $A$ as the destination, and $T$ as the auxiliary peg.\n- The minimal number of moves for the standard Tower of Hanoi problem with $m$ disks is $2^m - 1$. For this phase, with $m = n-1$, the number of moves is $2^{n-1} - 1$.\n\n**Phase 2: Move disk $n$ from peg $S$ to peg $T$.**\n- After Phase 1, the top of peg $S$ is disk $n$, and peg $T$ is empty. This move is legal under the standard rules.\n- The constraint is that disk $n$ must not be placed on peg $A$. The move is from $S$ to $T$, so this constraint is satisfied.\n- This phase consists of a single move. The number of moves is $1$.\n\n**Phase 3: Move disks $1, 2, \\dots, n-1$ from peg $A$ to peg $T$.**\n- Following Phase 2, disk $n$ is at the bottom of peg $T$, where it will remain for the rest of the process.\n- The task is to move the stack of $n-1$ disks from peg $A$ to peg $T$.\n- Since disk $n$ will not be moved, the constraint on it is trivially satisfied.\n- The disks $1, 2, \\dots, n-1$ are free to use any of the pegs.\n- This phase constitutes a standard Tower of Hanoi problem for $n-1$ disks, with $A$ as the source, $T$ as the destination, and $S$ as the auxiliary peg.\n- The minimal number of moves for this phase is, again, $2^{n-1} - 1$.\n\nThe total minimal number of moves, $N(n, S, A, T)$, is the sum of the moves from these three phases:\n$$N(n, S, A, T) = (\\text{Moves in Phase 1}) + (\\text{Moves in Phase 2}) + (\\text{Moves in Phase 3})$$\n$$N(n, S, A, T) = (2^{n-1} - 1) + 1 + (2^{n-1} - 1)$$\n$$N(n, S, A, T) = 2 \\cdot (2^{n-1}) - 2 + 1$$\n$$N(n, S, A, T) = 2^n - 1$$\n\nTo confirm this solution is minimal, we observe that the sequence of moves described corresponds exactly to the standard recursive algorithm for solving the unconstrained Tower of Hanoi problem. It is a fundamental result that this standard algorithm is optimal and requires $2^n-1$ moves. Since the set of legal move sequences for the constrained problem is a subset of the legal sequences for the unconstrained problem, the minimal number of moves for the constrained problem must be greater than or equal to the minimal number for the unconstrained problem. As we have found a valid sequence for the constrained problem with a length of $2^n-1$, this must be the minimal number of moves. The added constraint, for the specific case $k=n$, does not alter the optimal strategy or the minimal number of moves.",
            "answer": "$$\\boxed{2^n - 1}$$"
        },
        {
            "introduction": "This final practice is a comprehensive design challenge that combines recursive thinking with combinatorial enumeration and optimization. The task  is to count all valid sequences of nested brackets of multiple types, a generalization of a classic problem related to Catalan numbers. The key to solving this is to discover the recursive structure within the definition of a \"well-formed\" sequence and translate that structure into a recursive counting function. You will also need to employ memoization to manage overlapping subproblems, a technique that bridges recursion and dynamic programming.",
            "id": "3264821",
            "problem": "You are to design and implement a recursive generator for well-formed bracket sequences with multiple bracket types, from first principles in data structures and algorithms. The alphabet of tokens contains three bracket types: parentheses, square brackets, and a composite type that uses a paired two-character opening token and a paired two-character closing token. Concretely, the three types are: the pair $\\mathtt{(}$ and $\\mathtt{)}$, the pair $\\mathtt{[}$ and $\\mathtt{]}$, and the composite pair $\\mathtt{\\{(}$ and $\\mathtt{)\\}}$. The composite bracket pair $\\mathtt{\\{(}$ and $\\mathtt{)\\}}$ acts as a single matching pair: when opened, both a curly brace and a parenthesis are simultaneously opened, and when closed, the corresponding parenthesis and curly brace are simultaneously closed in that order. For example, a smallest valid instance of the composite pair is the four-character string $\\mathtt{\\{()\\}}$, which corresponds to $\\mathtt{\\{(}$ followed by an empty well-formed interior, followed by $\\mathtt{)\\}}$.\n\nA string over these tokens is well-formed if and only if it belongs to the generalization of the Dyck language defined inductively as follows:\n- Base: the empty string $\\epsilon$ is well-formed.\n- Enclosure: if $w$ is well-formed, then $\\mathtt{(} w \\mathtt{)}$ is well-formed, $\\mathtt{[} w \\mathtt{]}$ is well-formed, and $\\mathtt{\\{(} w \\mathtt{)\\}}$ is well-formed.\n- Concatenation: if $u$ and $v$ are well-formed, then $uv$ is well-formed.\n\nYou must implement a recursive algorithm that, given nonnegative integers $a$, $b$, and $c$, generates all well-formed strings that use exactly $a$ pairs of $\\mathtt{(}\\mathtt{)}$, exactly $b$ pairs of $\\mathtt{[}\\mathtt{]}$, and exactly $c$ pairs of $\\mathtt{\\{(}\\mathtt{)\\}}$. The algorithm must ensure correct nesting: closing tokens must match the most recently opened unmatched token of the same type. The design must start from foundational definitions and reason from first principles about recursion and state invariants, with precise justification of correctness.\n\nYour program must compute, for each test case, the integer count of distinct valid strings that satisfy the given $(a,b,c)$ and output the counts aggregated in a single line. There are no physical units, angles, or percentages in this problem.\n\nImplement the solution as a complete, runnable program. The final output format must be a single line containing the results as a comma-separated list enclosed in square brackets, for example, $\\mathtt{[r_1,r_2,\\dots,r_k]}$ where each $r_i$ is an integer count for the corresponding test case.\n\nTest suite:\n- Case 1: $(a,b,c) = (1,1,0)$, one $\\mathtt{(}\\mathtt{)}$ pair and one $\\mathtt{[}\\mathtt{]}$ pair.\n- Case 2: $(a,b,c) = (0,0,1)$, one composite $\\mathtt{\\{(}\\mathtt{)\\}}$ pair only.\n- Case 3: $(a,b,c) = (1,0,1)$, one $\\mathtt{(}\\mathtt{)}$ pair and one composite pair.\n- Case 4: $(a,b,c) = (0,2,0)$, two $\\mathtt{[}\\mathtt{]}$ pairs only.\n- Case 5: $(a,b,c) = (0,0,0)$, zero pairs of any type (the empty string).\n- Case 6: $(a,b,c) = (1,1,1)$, one of each type.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\mathtt{[result1,result2,result3,result4,result5,result6]}$).",
            "solution": "The problem asks us to count the number of distinct, well-formed bracket sequences given a specific number of pairs for three different bracket types. This is a combinatorial enumeration problem. The structure of well-formed bracket sequences, a generalization of the Dyck language, is inherently recursive, which suggests a recursive counting approach.\n\nLet $N(a, b, c)$ be the number of well-formed sequences with exactly $a$ pairs of $\\mathtt{(}\\mathtt{)}$, $b$ pairs of $\\mathtt{[}\\mathtt{]}$, and $c$ pairs of $\\mathtt{\\{(}\\mathtt{)\\}}$.\n\nThe recursive definition provides the key insight:\n1.  **Base Case**: The empty string is well-formed. This corresponds to using zero pairs of each bracket type. Thus, $N(0, 0, 0) = 1$.\n2.  **Recursive Step**: Any non-empty well-formed string $S$ can be uniquely decomposed into two parts: $S = S_p S_r$, where $S_p$ is the first *prime* well-formed prefix and $S_r$ is the remaining (possibly empty) well-formed suffix. A prime well-formed string is one that cannot be split into two non-empty well-formed strings; it must start with an opening bracket and end with its corresponding closing bracket, enclosing another well-formed string.\n\nWe can construct the recurrence for $N(a, b, c)$ by considering the type of the first prime prefix, $S_p$:\n- **Case 1: $S_p = \\mathtt{(}w\\mathtt{)}$**. The string $w$ inside is a well-formed sequence, and the remaining part $S_r$ is also a well-formed sequence. One pair of $\\mathtt{(}\\mathtt{)}$ is used for the enclosure. The remaining $a-1$ pairs of $\\mathtt{(}\\mathtt{)}$, $b$ pairs of $\\mathtt{[}\\mathtt{]}$, and $c$ pairs of $\\mathtt{\\{(}\\mathtt{)\\}}$ must be distributed between $w$ and $S_r$. Let $w$ have $(a_1, b_1, c_1)$ pairs and $S_r$ have $(a_2, b_2, c_2)$ pairs, where $a_1+a_2 = a-1$, $b_1+b_2=b$, and $c_1+c_2=c$. The total number of ways for this case is the sum over all such partitions: $\\sum_{a_1, a_2, b_1, \\dots} N(a_1, b_1, c_1) \\times N(a_2, b_2, c_2)$.\n- **Case 2: $S_p = \\mathtt{[}w\\mathtt{]}$**. Similarly, one pair of $\\mathtt{[}\\mathtt{]}$ is used, and the remaining pairs are partitioned between the inner sequence $w$ and the suffix $S_r$. The total number of ways is a similar sum where the total pairs to be partitioned are $(a, b-1, c)$.\n- **Case 3: $S_p = \\mathtt{\\{(}w\\mathtt{)\\}}$**. One pair of $\\mathtt{\\{(}\\mathtt{)\\}}$ is used. The remaining pairs $(a, b, c-1)$ are partitioned between $w$ and $S_r$.\n\nLet's define a convolution operation $C(A, B, C)$ as the total number of ways to form two sequential well-formed strings whose combined pairs total $(A, B, C)$:\n$$C(A, B, C) = \\sum_{a_1=0}^{A} \\sum_{b_1=0}^{B} \\sum_{c_1=0}^{C} N(a_1, b_1, c_1) \\times N(A-a_1, B-b_1, C-c_1)$$\n\nUsing this, the recurrence relation for $N(a, b, c)$ where not all arguments are zero becomes the sum of the three cases:\n$$N(a, b, c) = C(a-1, b, c) + C(a, b-1, c) + C(a, b, c-1)$$\nwhere we define $N(a,b,c) = 0$ if any argument is negative.\n\nThis recurrence relation involves many overlapping subproblems (e.g., calculating $N(1,1,0)$ requires $N(0,1,0)$ and $N(1,0,0)$, both of which require $N(0,0,0)$). This structure is a perfect candidate for dynamic programming or, equivalently, a recursive solution with memoization. A recursive function `count(a, b, c)` can be implemented to compute $N(a, b, c)$ by first checking a lookup table (or \"memo\") for a pre-computed result. If the result is not found, it computes it using the recurrence above (which involves recursive calls that also use the memo), stores the new result in the table, and then returns it. This ensures that each subproblem $N(a', b', c')$ is computed only once.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of counting well-formed bracket sequences\n    for multiple test cases.\n    \"\"\"\n\n    class BracketCounter:\n        \"\"\"\n        A class to compute the number of well-formed bracket sequences\n        using dynamic programming with memoization.\n        \"\"\"\n        def __init__(self):\n            # The memoization table stores results for N(a, b, c).\n            # The base case N(0,0,0) = 1 is pre-filled.\n            self.memo = {(0, 0, 0): 1}\n\n        def count_sequences(self, a, b, c):\n            \"\"\"\n            Computes N(a, b, c), the number of well-formed strings with:\n            - a pairs of ()\n            - b pairs of []\n            - c pairs of {()}\n            \n            This function uses a top-down recursive approach with memoization.\n            \"\"\"\n            \n            # The state is defined by the tuple of counts (a, b, c).\n            state = (a, b, c)\n\n            # Return 0 if any count is negative, as this is an invalid state.\n            if a < 0 or b < 0 or c < 0:\n                return 0\n\n            # If the result for this state is already computed, return it.\n            if state in self.memo:\n                return self.memo[state]\n\n            # The recurrence relation is derived from the decomposition of a\n            # non-empty sequence S into a prime prefix Sp and a suffix Sr (S = SpSr).\n            # The prime prefix must be of the form (w), [w], or {(w)}.\n            # We sum the contributions from these three cases.\n            \n            # Case 1: Sp = (w), Sr = v. The a-1, b, c pairs are partitioned\n            # between w and v. This is calculated by the convolution C(a-1, b, c).\n            term1 = self._convolution(a - 1, b, c)\n            \n            # Case 2: Sp = [w], Sr = v. The a, b-1, c pairs are partitioned.\n            # This is calculated by the convolution C(a, b-1, c).\n            term2 = self._convolution(a, b - 1, c)\n\n            # Case 3: Sp = {(w)}, Sr = v. The a, b, c-1 pairs are partitioned.\n            # This is calculated by the convolution C(a, b, c-1).\n            term3 = self._convolution(a, b, c - 1)\n            \n            # The total count is the sum of the three cases.\n            total = term1 + term2 + term3\n            \n            # Store the computed result in the memoization table before returning.\n            self.memo[state] = total\n            return total\n\n        def _convolution(self, A, B, C):\n            \"\"\"\n            Computes the convolution C(A, B, C), which represents summing\n            N(a1,b1,c1) * N(a2,b2,c2) over all partitions of (A,B,C).\n            \n            C(A,B,C) = sum_{a1+a2=A, b1+b2=B, c1+c2=C} N(a1,b1,c1) * N(a2,b2,c2)\n            \n            This is used to combine the counts for the inner sequence (w) and\n            the trailing sequence (v).\n            \"\"\"\n            \n            # If any target count is negative, the convolution is 0.\n            if A < 0 or B < 0 or C < 0:\n                return 0\n\n            conv_sum = 0\n            # Iterate over all possible partitions for 'a' pairs.\n            for a1 in range(A + 1):\n                a2 = A - a1\n                # Iterate over all possible partitions for 'b' pairs.\n                for b1 in range(B + 1):\n                    b2 = B - b1\n                    # Iterate over all possible partitions for 'c' pairs.\n                    for c1 in range(C + 1):\n                        c2 = C - c1\n                        \n                        # Recursively call count_sequences for the two subproblems.\n                        # The results will be retrieved from memoization if available.\n                        term_w = self.count_sequences(a1, b1, c1)\n                        term_v = self.count_sequences(a2, b2, c2)\n                        \n                        conv_sum += term_w * term_v\n            \n            return conv_sum\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 1, 0),\n        (0, 0, 1),\n        (1, 0, 1),\n        (0, 2, 0),\n        (0, 0, 0),\n        (1, 1, 1),\n    ]\n\n    results = []\n    for a, b, c in test_cases:\n        # For each test case, instantiate a new counter to ensure\n        # a fresh memoization table.\n        counter = BracketCounter()\n        result = counter.count_sequences(a, b, c)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}