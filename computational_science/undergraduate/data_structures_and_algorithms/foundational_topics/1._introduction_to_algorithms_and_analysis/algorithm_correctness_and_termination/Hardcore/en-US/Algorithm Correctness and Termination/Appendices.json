{
    "hands_on_practices": [
        {
            "introduction": "Loop invariants are often presented as a tool for verifying code that has already been written. However, their true power lies in their ability to guide the design of an algorithm from the ground up. This exercise demonstrates this constructive approach by asking you to reverse-engineer the body of a loop for an exponentiation algorithm, given only its invariant and termination condition. By treating the invariant as a contract to be maintained, you can systematically deduce the necessary steps to make progress while ensuring correctness at every stage .",
            "id": "3248351",
            "problem": "You are given an integer base $x$ and a nonnegative integer exponent $n$. Consider an algorithm that builds $x^n$ by maintaining three integer variables $p$, $k$, and $y$ with the following initialization and loop guard:\n- Initialization: $p \\leftarrow 1$, $k \\leftarrow 0$, $y \\leftarrow n$, and $n_{\\text{original}} \\leftarrow n$.\n- Loop guard: continue while $y  0$.\n- Loop invariant to be preserved at the start of every iteration: $p = x^k$ and $k + y = n_{\\text{original}}$.\n\nYour task is to reverse engineer a correct loop body, that is, determine the assignment statements that must be executed in the loop body to maintain the loop invariant and to ensure that upon termination the postcondition $p = x^{n_{\\text{original}}}$ holds.\n\nYour derivation must start from the following fundamental bases:\n- The definition of exponentiation on the natural numbers: $x^0 = 1$ and $x^{k+1} = x^k \\cdot x$ for all integers $x$ and all integers $k \\ge 0$.\n- The principle of mathematical induction on the natural numbers and the well-foundedness of the usual order on the natural numbers.\n- The standard definition of a loop invariant for partial correctness and a natural-number variant for total correctness in imperative programs.\n\nAssume the following domain and conventions:\n- $x$ is any integer and $n$ is any integer satisfying $n \\ge 0$.\n- For this problem, define $x^0 = 1$ for every integer $x$, including the case $x = 0$, so $0^0$ is taken to be $1$.\n\nTasks:\n1. Derive a minimal loop body (consisting only of assignments to $p$, $k$, and $y$) that preserves the invariant $p = x^k$ and $k + y = n_{\\text{original}}$ at the start of each iteration, decreases a natural-number variant to ensure termination, and yields the postcondition $p = x^{n_{\\text{original}}}$ when the loop terminates.\n2. Justify partial correctness and total correctness of your loop using the loop invariant method, starting only from the fundamental bases above.\n3. Implement a program that, for a suite of test cases, executes your loop and returns for each test case:\n   - The computed value $p$ on termination.\n   - A boolean indicating whether the invariant held at the start of every iteration and the postcondition $p = x^{n_{\\text{original}}}$ held at termination.\n\nTest suite:\n- $(x, n) = (2, 10)$\n- $(x, n) = (5, 0)$\n- $(x, n) = (0, 7)$\n- $(x, n) = (0, 0)$\n- $(x, n) = (-3, 4)$\n- $(x, n) = (-3, 5)$\n- $(x, n) = (2, 50)$\n- $(x, n) = (1, 100)$\n\nAnswer specification and output format:\n- For each test case, output a two-element list $[p, b]$ where $p$ is the computed integer $x^n$ using your derived loop and $b$ is a boolean that is $\\text{True}$ if and only if the invariant held at the start of every iteration and the final state satisfies $p = x^{n_{\\text{original}}}$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example: $[\\,[p_1, b_1],[p_2, b_2],\\dots]$.\n- No user input is required. The program must be self-contained and use only integer arithmetic and control flow; do not call any built-in exponentiation function to compute $p$ inside the loop body. For verification of the invariant in your implementation, you may compute $x^k$ using the defining recurrence $x^0 = 1$ and $x^{k+1} = x^k \\cdot x$.",
            "solution": "The problem of designing a loop body to compute $x^n$ based on a given loop invariant is a standard exercise in program verification and reverse engineering of algorithms. I will first validate the problem statement and then proceed with a formal derivation and proof of correctness.\n\n### Step 1: Problem Validation\n\nI begin by extracting the given information and conditions as stated in the problem.\n\n- **Inputs**: An integer base $x$ and a non-negative integer exponent $n$.\n- **Algorithm Variables**: Three integer variables $p$, $k$, and $y$.\n- **Initialization**: $p \\leftarrow 1$, $k \\leftarrow 0$, $y \\leftarrow n$, and a constant $n_{\\text{original}} \\leftarrow n$.\n- **Loop Guard**: The loop continues as long as $y  0$.\n- **Loop Invariant**: The proposition $I(p, k, y) \\equiv (p = x^k) \\land (k + y = n_{\\text{original}})$ must hold at the start of every loop iteration.\n- **Postcondition**: Upon termination, the final value of $p$ must be $x^{n_{\\text{original}}}$.\n- **Fundamental Bases**: The derivation must be grounded in:\n    1. The recursive definition of exponentiation: $x^0 = 1$ and $x^{k+1} = x^k \\cdot x$ for $k \\ge 0$.\n    2. The principle of mathematical induction.\n    3. The theory of loop invariants for proving partial and total correctness.\n- **Domain Conventions**: $x$ is any integer, $n$ is an integer with $n \\ge 0$, and for the purpose of this problem, $x^0=1$ for all integers $x$, including $0^0=1$.\n\nThe problem is scientifically and mathematically sound, well-posed, and objective. It is a standard problem in computer science concerning algorithm design and correctness, specifically focusing on loop invariants. The premises are consistent, and all necessary information for a derivation is provided. The problem is not trivial, as it requires a systematic application of the principles of program verification. Therefore, the problem is deemed valid.\n\n### Step 2: Derivation of the Loop Body\n\nLet the state of the variables at the start of an arbitrary loop iteration be $(p, k, y)$. By hypothesis (the loop invariant), we assume that at this point:\n1. $p = x^k$\n2. $k + y = n_{\\text{original}}$\n\nThe loop guard is $y  0$, so we can also assume $y$ is a positive integer.\nThe goal is to find a sequence of assignments to $p$, $k$, and $y$ that results in a new state $(p', k', y')$ which also satisfies the invariant, i.e., $p' = x^{k'}$ and $k' + y' = n_{\\text{original}}$. Additionally, we must ensure the loop terminates.\n\n**Ensuring Termination**:\nThe loop terminates if $y$ eventually becomes less than or equal to $0$. Since $y$ is an integer that is positive inside the loop, a simple way to guarantee progress towards termination is to decrement $y$ in each iteration. Let's propose the update:\n$$y' \\leftarrow y - 1$$\nThis defines a variant function $V(y) = y$, which is a non-negative integer that strictly decreases with each iteration, thus guaranteeing termination.\n\n**Preserving the Invariant**:\nNow, we must determine the updates for $k$ and $p$ that preserve the invariant, given the update to $y$.\n\nFirst, consider the second part of the invariant, $k + y = n_{\\text{original}}$. We need the new state $(k', y')$ to satisfy $k' + y' = n_{\\text{original}}$.\nSubstituting our proposed update $y' = y - 1$:\n$$k' + (y - 1) = n_{\\text{original}}$$\nFrom the invariant holding at the start of the iteration, we know $y = n_{\\text{original}} - k$. Substituting this into the previous equation:\n$$k' + (n_{\\text{original}} - k - 1) = n_{\\text{original}}$$\n$$k' - k - 1 = 0$$\n$$k' = k + 1$$\nThis gives us the required assignment for $k$:\n$$k' \\leftarrow k + 1$$\n\nNext, consider the first part of the invariant, $p = x^k$. We need the new state $(p', k')$ to satisfy $p' = x^{k'}$.\nSubstituting our derived update $k' = k + 1$:\n$$p' = x^{k+1}$$\nUsing the fundamental definition of exponentiation, $x^{k+1} = x^k \\cdot x$. So, we must have:\n$$p' = x^k \\cdot x$$\nFrom the invariant holding at the start of the iteration, we know $p = x^k$. Substituting this into the equation for $p'$:\n$$p' = p \\cdot x$$\nThis provides the required assignment for $p$:\n$$p' \\leftarrow p \\cdot x$$\n\nThus, the derived minimal loop body consists of the following three assignments:\n1. $p \\leftarrow p \\cdot x$\n2. $k \\leftarrow k + 1$\n3. $y \\leftarrow y - 1$\n\nThe order of these assignments does not matter as long as they all use the values of $p, k, y$ from the start of the iteration. The proposed sequential execution achieves this.\n\n### Step 3: Proof of Correctness\n\nWe use the loop invariant method to prove total correctness.\n\n- **Loop Invariant ($I$)**: $(p = x^k) \\land (k + y = n_{\\text{original}})$.\n- **Variant ($V$)**: $V(y) = y$.\n\n**1. Initialization (Base Case)**:\nWe must show that the invariant $I$ holds before the first iteration of the loop.\n- The initial state is $p \\leftarrow 1$, $k \\leftarrow 0$, $y \\leftarrow n$, and $n_{\\text{original}} \\leftarrow n$.\n- Check first conjunct: Is $p = x^k$? This means checking if $1 = x^0$. By the problem's definition of exponentiation, this is true for all integers $x$.\n- Check second conjunct: Is $k + y = n_{\\text{original}}$? This means checking if $0 + n = n$. This is true.\n- Both parts of the invariant hold. The initialization is correct.\n\n**2. Preservation (Inductive Step)**:\nAssume at the start of an iteration that the invariant $I$ holds and the loop guard $y  0$ is true. Let the state be $(p, k, y)$. We must show that after executing the loop body, the invariant still holds for the new state $(p', k', y')$.\n- **Hypothesis**: $p = x^k$, $k + y = n_{\\text{original}}$, and $y  0$.\n- **Loop Body**: $p' \\leftarrow p \\cdot x$, $k' \\leftarrow k + 1$, $y' \\leftarrow y - 1$.\n- **Proof for first conjunct ($p' = x^{k'}$)**:\n  - $p' = p \\cdot x$ (by assignment)\n  - $p' = (x^k) \\cdot x$ (by hypothesis $p = x^k$)\n  - $p' = x^{k+1}$ (by definition of exponentiation)\n  - Since $k' = k + 1$, we have $p' = x^{k'}$. The first conjunct holds.\n- **Proof for second conjunct ($k' + y' = n_{\\text{original}}$)**:\n  - $k' + y' = (k + 1) + (y - 1)$ (by assignment)\n  - $k' + y' = k + y$\n  - Since $k + y = n_{\\text{original}}$ by hypothesis, we have $k' + y' = n_{\\text{original}}$. The second conjunct holds.\n- The loop body preserves the invariant. This establishes partial correctness: if the loop terminates, its result is correct.\n\n**3. Termination and Postcondition**:\n- **Termination**: The variant is $V(y) = y$. At initialization, $y=n \\ge 0$. The loop condition is $y  0$. Inside the loop, $y$ is strictly positive. The update is $y' \\leftarrow y - 1$, so $y'  y$. A strictly decreasing sequence of non-negative integers must be finite. Therefore, the loop must terminate.\n- **Postcondition**: The loop terminates when the guard $y  0$ becomes false. Since $y$ is an integer decremented by $1$ at each step, termination occurs precisely when $y = 0$.\n  - At this point, the invariant still holds (it was true at the start of the final, non-executing check).\n  - From $k + y = n_{\\text{original}}$, with $y=0$, we get $k = n_{\\text{original}}$.\n  - From $p = x^k$, substituting $k = n_{\\text{original}}$, we get $p = x^{n_{\\text{original}}}$.\n- This is the desired postcondition.\n\nThe combination of initialization, preservation, and termination proves the total correctness of the algorithm with the derived loop body.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by running the derived algorithm on a suite of test cases\n    and verifying the loop invariant and postcondition for each case.\n    \"\"\"\n\n    def power_for_verification(base, exp):\n        \"\"\"\n        Computes base^exp using the fundamental recursive definition.\n        Handles the special case 0^0 = 1 as per the problem statement.\n        This function is used only for verifying the invariant and postcondition,\n        not in the main computation of p.\n        \"\"\"\n        if exp  0:\n            raise ValueError(\"Exponent must be non-negative.\")\n        if exp == 0:\n            return 1\n        \n        # Using integer arithmetic to avoid potential floating point issues\n        # and to handle large numbers.\n        result = 1\n        for _ in range(exp):\n            result *= base\n        return result\n\n    def execute_and_verify(x, n):\n        \"\"\"\n        Executes the derived exponentiation algorithm for a given base x and exponent n.\n        It checks if the loop invariant holds at the start of every iteration and\n        if the postcondition holds upon termination.\n\n        Returns:\n            A list [p, b], where p is the computed result and b is a boolean\n            indicating if all checks passed.\n        \"\"\"\n        # Initialization\n        p = 1\n        k = 0\n        y = n\n        n_original = n\n\n        all_checks_passed = True\n\n        # Check invariant after initialization and before the first iteration.\n        # This is a crucial step, especially for the n=0 case where the loop is skipped.\n        try:\n            p_check = (p == power_for_verification(x, k))\n            ky_check = (k + y == n_original)\n            if not (p_check and ky_check):\n                all_checks_passed = False\n        except Exception:\n            all_checks_passed = False\n\n        # Loop\n        while y > 0:\n            # Check invariant at the start of the current iteration\n            try:\n                p_check = (p == power_for_verification(x, k))\n                ky_check = (k + y == n_original)\n                if not (p_check and ky_check):\n                    all_checks_passed = False\n            except Exception:\n                all_checks_passed = False\n\n            # Loop body derived from the invariant\n            p = p * x\n            k = k + 1\n            y = y - 1\n        \n        # Check postcondition upon termination\n        try:\n            postcondition_check = (p == power_for_verification(x, n_original))\n            if not postcondition_check:\n                all_checks_passed = False\n        except Exception:\n            all_checks_passed = False\n\n        return [p, all_checks_passed]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, 10),\n        (5, 0),\n        (0, 7),\n        (0, 0),\n        (-3, 4),\n        (-3, 5),\n        (2, 50),\n        (1, 100),\n    ]\n\n    results = []\n    for case in test_cases:\n        x, n = case\n        result = execute_and_verify(x, n)\n        # Convert Python boolean to string 'True'/'False' for final output format\n        result[1] = 'True' if result[1] else 'False'\n        results.append(str(result).replace(\"'\", \"\"))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having seen how an invariant can shape code, we now turn to a complete, practical application: proving the correctness of an algorithm you design. This problem challenges you to develop and formally verify an in-place algorithm for removing duplicate elements from a sorted array, a common task in data processing. You will use the two-pointer technique to achieve efficiency and then formulate a precise loop invariant to build a rigorous proof of correctness and termination, honing the essential skill of guaranteeing your algorithm works as intended .",
            "id": "3205683",
            "problem": "You are given a sorted array $A$ of length $n$, where $n \\in \\mathbb{Z}_{\\ge 0}$ and sortedness means $\\forall i \\in \\{0, 1, \\dots, n-2\\}$, $A[i] \\le A[i+1]$. The objective is to remove duplicate values in-place so that the first occurrence of each distinct value is kept and the order of kept values is preserved. This is known as stable removal, meaning that if $x$ appears at positions $p_1  p_2  \\dots  p_m$, then after removal, the single retained $x$ must appear with the same relative order as the original sequence of distinct values. In-place requires using $O(1)$ additional space aside from a constant number of scalar variables.\n\nYour tasks are:\n\n1. Specification: Formally state the precondition, postcondition, and the allowable resources for the algorithm. Precisely define what constitutes a correct output in terms of the mutated array $A$ and an integer $k$, where $k$ is the number of distinct values retained and the prefix $A[0], A[1], \\dots, A[k-1]$ contains exactly the distinct values of $A$ in their original encounter order. Guarantee that $0 \\le k \\le n$.\n\n2. Pseudo-code: Provide unambiguous pseudo-code that computes $k$ and achieves the required in-place stable removal under the stated constraints. Use only constant extra space (e.g., a constant number of indices and temporary scalars). Do not allocate auxiliary arrays proportional to $n$.\n\n3. Loop invariant: State a precise loop invariant suitable for the primary loop you use. Your invariant must capture both the structural property of the already processed prefix and the progress condition relating the read and write indices. The invariant must be strong enough to derive the postcondition upon termination.\n\n4. Correctness: Prove partial correctness using the loop invariant method. Show initialization, maintenance, and termination, and deduce that upon loop completion, the postcondition holds with stable removal. Additionally, argue total correctness by showing termination. Provide a time complexity bound in terms of $n$ and a space complexity bound, both justified from first principles (primitive step counting and resource usage definitions).\n\n5. Implementation: Write a complete, runnable program that implements your pseudo-code and applies it to the following fixed test suite. The program must not read any input. For each test case, it must mutate the array in-place as per your algorithm, compute $k$, and output a single line containing the aggregated results across test cases.\n\nTest suite arrays:\n- Case $1$: $A = [1,1,2,2,2,3,3,4]$\n- Case $2$: $A = []$\n- Case $3$: $A = [5]$\n- Case $4$: $A = [7,7,7,7]$\n- Case $5$: $A = [1,2,3,4,5]$\n- Case $6$: $A = [-3,-3,-2,-1,-1,0,0,0,1]$\n\nRequired final output format:\n- The program must produce a single line that is a comma-separated list enclosed in square brackets with no spaces. Each element corresponds to one test case and is itself a list of the form $[k,\\text{unique\\_prefix}]$, where $k$ is the integer number of retained elements and $\\text{unique\\_prefix}$ is the list of the first $k$ elements of the mutated array. For example, an output for two cases could look like $[[2,[a,b]],[1,[c]]]$ where $a$, $b$, $c$ denote integers from the corresponding arrays.\n- For this problem, integers in the arrays should appear as ordinary integers (no units are required for these quantities).",
            "solution": "The problem of removing duplicate elements from a sorted array in-place is a classic algorithmic task that can be solved efficiently using a two-pointer technique. The solution must satisfy the constraints of in-place modification (using $O(1)$ auxiliary space) and stability. Given the input array is sorted, the stability requirement is naturally met by preserving the first encountered instance of each value.\n\n### 1. Specification\n\nA formal specification of the algorithm is as follows:\n\n**Precondition:**\nThe input is an array $A$ of length $n$, where $n \\in \\mathbb{Z}_{\\ge 0}$.\nThe array $A$ is sorted in non-decreasing order. Formally, for the original array $A_{in}$, it holds that $\\forall i \\in \\{0, 1, \\dots, n-2\\}, A_{in}[i] \\le A_{in}[i+1]$.\n\n**Postcondition:**\nThe algorithm must return an integer $k$ and modify the array $A$ such that:\n1.  $k$ is the number of distinct elements in the original array $A_{in}$. Thus, $0 \\le k \\le n$.\n2.  The prefix of the modified array, $A[0 \\dots k-1]$, contains exactly the distinct elements of $A_{in}$.\n3.  The elements in the prefix $A[0 \\dots k-1]$ are in strictly increasing order, preserving their original relative order (stable removal). For any two distinct values $x, y$ from $A_{in}$ where the first occurrence of $x$ is at index $i$ and the first occurrence of $y$ is at index $j$, if $i  j$, then the final position of $x$ in $A[0 \\dots k-1]$ is before the final position of $y$.\n4.  The contents of the array $A$ at indices $k, k+1, \\dots, n-1$ are unspecified and irrelevant.\n\n**Resource Constraints:**\nThe algorithm must operate in-place, using only a constant amount of additional memory, i.e., $O(1)$ auxiliary space. The input array itself does not count towards this limit.\n\n### 2. Pseudo-code\n\nThe algorithm uses a \"read\" pointer and a \"write\" pointer to traverse the array. The read pointer, $i$, scans every element of the array. The write pointer, $k$, tracks the end of the processed, unique prefix.\n\n```\nALGORITHM remove_duplicates(A)\nINPUT: A, a sorted array of length n.\n\n1.  n = length(A)\n2.  IF n == 0 THEN\n3.      RETURN 0\n4.  END IF\n5.\n6.  k = 1  // Initialize write pointer; A[0] is always the first unique element.\n7.  FOR i FROM 1 TO n-1 DO  // i is the read pointer.\n8.      // Compare current element with the last unique element found.\n9.      IF A[i]  A[k-1] THEN\n10.         // Found a new unique element.\n11.         A[k] = A[i]  // Place it at the next position in the unique prefix.\n12.         k = k + 1    // Increment the size of the unique prefix.\n13.     END IF\n14. END FOR\n15.\n16. RETURN k // k is the number of unique elements.\n```\n\n### 3. Loop Invariant\n\nThe core of the algorithm is the `FOR` loop (lines $7$-$14$). We can establish correctness by defining a loop invariant. Let $k_{i}$ denote the value of the write pointer $k$ at the beginning of the loop iteration for a given read pointer $i$.\n\n**Loop Invariant:** At the start of each iteration of the `FOR` loop, for the read pointer $i$ where $i \\in \\{1, 2, \\dots, n\\}$, the following properties hold:\n1.  The subarray $A[0 \\dots k-1]$ contains all the unique elements from the subarray $A[0 \\dots i-1]$.\n2.  The elements in $A[0 \\dots k-1]$ are sorted in strictly increasing order: $\\forall j \\in \\{0, \\dots, k-2\\}, A[j]  A[j+1]$.\n3.  The index of the write pointer $k$ satisfies $1 \\le k \\le i$.\n\n### 4. Correctness\n\nWe prove partial correctness using the loop invariant, and then total correctness by arguing termination.\n\n**Base Cases:** The algorithm handles $n=0$ and $n=1$ correctly.\n- If $n=0$, the function returns $0$, satisfying the postcondition with $k=0$.\n- If $n=1$, the loop from $i=1$ to $0$ does not execute. The function returns the initial value $k=1$, which is correct. The array $A[0 \\dots 0]$ contains the single unique element.\n\n**Proof by Loop Invariant (for $n \\ge 2$):**\n\n**Initialization:**\nBefore the first iteration of the loop, $i=1$ and $k=1$.\n1.  **Invariant 1:** The subarray to consider is $A[0 \\dots i-1] = A[0 \\dots 0]$. The unique prefix is $A[0 \\dots k-1] = A[0 \\dots 0]$. This subarray correctly contains the unique elements of itself. The invariant holds.\n2.  **Invariant 2:** The prefix $A[0 \\dots k-1]$ has length $1$, so the sorting property holds vacuously. The invariant holds.\n3.  **Invariant 3:** $k=1$ and $i=1$, so $1 \\le k \\le i$ becomes $1 \\le 1 \\le 1$. The invariant holds.\n\n**Maintenance:**\nAssume the invariant holds at the start of an iteration for some $i$, where $1 \\le i  n$. We must show it holds at the start of the next iteration, for $i+1$.\n- At the start of iteration $i$, $A[0 \\dots k-1]$ contains the unique elements of $A[0 \\dots i-1]$ in sorted order.\n- The loop body considers the element $A[i]$. Since the original array $A$ is sorted, we know $A[i] \\ge A[i-1]$. By the invariant, $A[k-1]$ is the largest element in $A[0 \\dots i-1]$, so $A[i-1] \\le A[k-1]$ is not necessarily true, but $A[k-1]$ is one of the elements from $A[0 \\dots i-1]$ and since everything is sorted, $A[k-1]$ is the maximum value in that unique prefix. We also know that $A[k-1] \\le A[i-1] \\le A[i]$ might not hold, but because $A[k-1]$ is the last unique element found in $A[0 \\dots i-1]$, and the overall array is sorted, we must have $A[k-1] \\le A[i]$. Thus, there are two cases:\n\n1.  **Case: $A[i]  A[k-1]$** (Line $9$). This means $A[i]$ is a new unique element not present in $A[0 \\dots k-1]$. The algorithm performs $A[k] = A[i]$ and increments $k$ to $k_{new} = k+1$.\n    - At the start of the next iteration (for $i+1$), the newly considered subarray is $A[0 \\dots i]$.\n    - The new unique prefix $A[0 \\dots k_{new}-1]$ now contains the previous unique elements plus $A[i]$. It correctly contains all unique elements from $A[0 \\dots i]$. (Invariant 1 holds).\n    - Since $A[k-1]  A[i]$ and $A[0 \\dots k-1]$ was strictly sorted, the new prefix $A[0 \\dots k_{new}-1]$ is also strictly sorted. (Invariant 2 holds).\n    - We have $k_{new}=k+1$. By the assumption $k \\le i$, we have $k+1 \\le i+1$, so $k_{new} \\le i+1$. Also $k_{new} \\ge 1+1 = 2 \\ge 1$. Thus $1 \\le k_{new} \\le i+1$. (Invariant 3 holds).\n\n2.  **Case: $A[i] = A[k-1]$** (Since $A$ is sorted, $A[i]  A[k-1]$ is impossible). This means $A[i]$ is a duplicate of the last unique element found. The algorithm does nothing. The value of $k$ remains unchanged.\n    - At the start of the next iteration (for $i+1$), the subarray is $A[0 \\dots i]$.\n    - The unique prefix $A[0 \\dots k-1]$ still contains the unique elements from $A[0 \\dots i]$, since $A[i]$ was a duplicate. (Invariant 1 holds).\n    - The prefix $A[0 \\dots k-1]$ is unchanged, so it remains strictly sorted. (Invariant 2 holds).\n    - $k$ is unchanged and $i$ increments to $i+1$. Since $k \\le i  i+1$, the relation $1 \\le k \\le i+1$ holds for the next iteration. (Invariant 3 holds).\n\nIn both cases, the loop invariant is maintained.\n\n**Termination:**\nThe loop terminates when $i=n$. At this point, the loop invariant holds for $i=n$.\n1.  **Invariant 1 implies:** $A[0 \\dots k-1]$ contains all unique elements from $A[0 \\dots n-1]$. This is exactly the postcondition for the array contents.\n2.  **Invariant 2 implies:** The prefix $A[0 \\dots k-1]$ is sorted, satisfying the postcondition.\n3.  The final value of $k$ is the count of these unique elements. This satisfies the postcondition for the return value.\nThe stability is implicitly guaranteed because the read pointer $i$ traverses the array from left to right, and we keep the first occurrence of each value.\n\n**Total Correctness:**\nThe algorithm's termination is guaranteed. The `FOR` loop iterates with a counter $i$ from $1$ to $n-1$. The variable $i$ is strictly increasing and bounded by $n$. The loop will execute exactly $n-1$ times (for $n \\ge 1$) and then terminate. As partial correctness has been shown, this proves total correctness.\n\n**Complexity Analysis:**\n-   **Time Complexity:** The algorithm consists of a single `FOR` loop that iterates $n-1$ times. Inside the loop, a constant number of operations (comparison, potential assignment, potential increment) are performed. Thus, the total time complexity is proportional to $n$, which is $O(n)$.\n-   **Space Complexity:** The algorithm uses a few scalar variables for indices and loop control ($n, k, i$). The amount of memory used by these variables is constant and does not depend on the input size $n$. The array modification is performed in-place. Therefore, the auxiliary space complexity is $O(1)$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef remove_duplicates(A: np.ndarray) - int:\n    \"\"\"\n    Removes duplicates from a sorted numpy array in-place.\n\n    Args:\n        A: A sorted numpy array of numbers.\n\n    Returns:\n        The number of unique elements `k`. The first `k` elements of `A`\n        will be the unique elements in sorted order.\n    \"\"\"\n    n = len(A)\n    if n == 0:\n        return 0\n\n    # k is the index of the next unique element to be written.\n    # It also serves as the count of unique elements found so far.\n    # A[0] is always the first unique element.\n    k = 1\n    \n    # Iterate through the array from the second element.\n    for i in range(1, n):\n        # If the current element is greater than the last recorded unique element,\n        # it's a new unique element.\n        if A[i]  A[k - 1]:\n            # Place the new unique element at the position k.\n            if i != k: # Optimization: avoid self-assignment\n              A[k] = A[i]\n            # Increment the count of unique elements.\n            k += 1\n            \n    return k\n\ndef solve():\n    \"\"\"\n    Defines the test suite, runs the algorithm on each case,\n    and prints the aggregated results in the specified format.\n    \"\"\"\n    test_cases_lists = [\n        [1, 1, 2, 2, 2, 3, 3, 4],\n        [],\n        [5],\n        [7, 7, 7, 7],\n        [1, 2, 3, 4, 5],\n        [-3, -3, -2, -1, -1, 0, 0, 0, 1]\n    ]\n\n    test_cases_np = [np.array(case, dtype=np.int64) for case in test_cases_lists]\n\n    results = []\n    for test_array in test_cases_np:\n        # The function modifies the array in-place and returns k.\n        k = remove_duplicates(test_array)\n        \n        # Get the prefix of unique elements from the modified array.\n        unique_prefix = test_array[:k].tolist()\n        \n        # Format the result string for this case as [k,[prefix]] without spaces.\n        result_str = f\"[{k},{str(unique_prefix).replace(' ', '')}]\"\n        results.append(result_str)\n\n    # Final print statement in the exact required format: [[...],[...],...]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "An algorithm's correctness often hinges on implicit assumptions about the operations it uses. This final practice explores what happens when a fundamental precondition is violated, moving our focus from an algorithm's internal logic to its external dependencies. We will investigate the behavior of quicksort when supplied with a non-transitive comparison operatorâ€”one that induces logical contradictions like \"$a$ is greater than $b$\", \"$b$ is greater than $c$\", but \"$c$ is greater than $a$\". Analyzing this hypothetical scenario reveals the deep truth that for some problems, correctness is not merely difficult to achieve but logically impossible, teaching a critical lesson about the foundational requirements of computation .",
            "id": "3262688",
            "problem": "Consider an implementation of quicksort that uses a user-supplied comparison operator, denoted by the binary function $G(x,y)$, where $G(x,y)$ returns $\\text{true}$ if and only if $x$ is considered \"greater than\" $y$ by the comparator. The standard correctness specification for quicksort under such a comparator is: for an output array $A[0\\,..\\,n-1]$, for all indices $i$ and $j$ with $0 \\le i  j \\le n-1$, it must hold that $\\neg G\\!\\left(A[i],A[j]\\right)$, meaning no element strictly precedes a later element under $G$. Assume pivot selection is deterministic (for example, always choosing the last element), and the partition scheme is either the Lomuto partition or the Hoare partition, both implemented in the usual way but using $G$ to drive comparisons.\n\nFundamental base:\n- A comparator intended for sorting should induce a strict weak order: a binary relation $R$ on a set $S$ that is irreflexive, asymmetric, and transitive on comparable elements; from this, a consistent \"less-than\" relation can be derived. Transitivity is the law that for all $x,y,z \\in S$, if $R(x,y)$ and $R(y,z)$ then $R(x,z)$.\n- Quicksort relies on partition invariants: the partition stage rearranges elements relative to a pivot so that one subarray contains those deemed \"not greater than\" the pivot and the other subarray contains those deemed \"greater than\" the pivot, then recursively sorts subarrays. Correctness follows by induction on subarray size if the comparator induces a transitive ordering and the partition invariants are sound.\n- Termination of quicksort follows if each partition strictly reduces the sizes of subproblems (for example, by fixing the pivot at some index or by returning subarrays with strictly smaller lengths).\n\nNow suppose $G$ is deterministic on pairs but non-transitive. Concretely, there exist distinct elements $a$, $b$, and $c$ such that $G(a,b)$, $G(b,c)$, and $G(c,a)$ all hold (a $3$-cycle). Let $A$ denote an input array containing $a$, $b$, and $c$ (potentially along with other elements).\n\nWhich statements are true under these assumptions?\n\nA. Even with $G$ non-transitive, a quicksort using the Lomuto partition scheme will terminate on any finite input because the pivot is placed at some index $p$ with $0 \\le p \\le n-1$, thereby strictly reducing subproblem sizes.\n\nB. If $G$ contains a cycle such as $G(a,b)$, $G(b,c)$, and $G(c,a)$, then there is no permutation of $\\{a,b,c\\}$ that satisfies the specification $\\forall ij:\\neg G\\!\\left(A[i],A[j]\\right)$, so quicksort cannot be correct with respect to $G$ on inputs containing $\\{a,b,c\\}$.\n\nC. If pivots are chosen uniformly at random, quicksort can, with probability $1$, still find an output that satisfies $\\forall ij:\\neg G\\!\\left(A[i],A[j]\\right)$ even when $G$ is non-transitive with $3$-cycles.\n\nD. Switching from the Lomuto partition to the Hoare partition restores correctness of quicksort with respect to $G$ even when $G$ is non-transitive with $3$-cycles.\n\nE. Non-transitivity of $G$ can cause quicksort to fail to terminate, because the partition step may not make progress and recursion can repeat indefinitely on subarrays of the same length.",
            "solution": "The user has provided a problem concerning the behavior of the quicksort algorithm when supplied with a non-transitive comparison operator. I will first validate the problem statement and then proceed to analyze each option.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- A quicksort implementation uses a binary function $G(x,y)$ which returns $\\text{true}$ if and only if $x$ is \"greater than\" $y$.\n- The correctness specification for the sorted output array $A[0 .. n-1]$ is: $\\forall i, j$ with $0 \\le i  j \\le n-1$, it must hold that $\\neg G(A[i], A[j])$.\n- Pivot selection is deterministic.\n- The partition scheme is either Lomuto or Hoare.\n- A valid comparator for sorting should induce a strict weak order (irreflexive, asymmetric, transitive). Transitivity is defined as: for all $x,y,z$, if $G(x,y)$ and $G(y,z)$, then $G(x,z)$.\n- Quicksort's correctness relies on partition invariants and transitivity.\n- Quicksort's termination relies on strictly reducing subproblem sizes.\n- **Hypothesis**: The comparator $G$ is deterministic but non-transitive. Specifically, there exist distinct elements $a,b,c$ such that $G(a,b)$, $G(b,c)$, and $G(c,a)$ are all true (a $3$-cycle).\n- The input array $A$ contains these three elements $\\{a, b, c\\}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly located within theoretical computer science, specifically the analysis of algorithms. It investigates the preconditions required for a sorting algorithm to be correct and to terminate, a standard topic in advanced algorithm courses. The concepts of transitivity, strict weak orders, and the mechanisms of quicksort (Lomuto and Hoare partitions) are all well-established.\n- **Well-Posed:** The problem defines a specific deviation from standard assumptions (non-transitivity) and asks for the logical consequences on a well-defined algorithm (quicksort). The question is structured to evaluate a set of formal statements, for which a definite truth value can be derived.\n- **Objective:** The problem is stated using precise, formal language common in mathematics and computer science. Terms like \"$G(x,y)$\", \"$\\neg G(A[i], A[j])$\", \"non-transitive\", and \"$3$-cycle\" are unambiguous.\n\n**Step 3: Verdict and Action**\nThe problem statement is scientifically sound, well-posed, objective, and contains no internal contradictions or missing information. It is a valid theoretical problem. I will proceed with the solution.\n\n### Derivation and Option Analysis\n\nThe core of the problem is the violation of transitivity by the comparator $G$. A standard comparator for sorting induces a total or partial order on the elements. The existence of a cycle, such as $G(a,b)$, $G(b,c)$, and $G(c,a)$, fundamentally breaks the acyclic nature of any such ordering. This has implications for both the correctness and potentially the termination of sorting algorithms that rely on this comparator.\n\n#### Analysis of Statement A\n**Statement A:** Even with $G$ non-transitive, a quicksort using the Lomuto partition scheme will terminate on any finite input because the pivot is placed at some index $p$ with $0 \\le p \\le n-1$, thereby strictly reducing subproblem sizes.\n\nThe Lomuto partition scheme works by selecting a pivot element (e.g., the last element $A[hi]$ of a subarray $A[lo..hi]$) and rearranging the subarray such that all elements \"not greater than\" the pivot are on its left, and all elements \"greater than\" the pivot are on its right. The crucial step is that after partitioning, the pivot element itself is swapped into a final position, let's say index $p$. The recursive calls to quicksort are then made on the subarrays $A[lo..p-1]$ and $A[p+1..hi]$.\n\nThe key observation for termination is that the pivot element at index $p$ is excluded from both recursive calls. Therefore, the total number of elements in the subproblems is $(p-1 - lo + 1) + (hi - (p+1) + 1) = (p-lo) + (hi-p) = hi-lo$. The original problem size was $hi-lo+1$. Since the recursion depth is bounded by the size of the array and each recursive step operates on strictly smaller subarrays, the algorithm must terminate. This structural argument about problem size reduction is independent of the properties of the comparator $G$ (such as transitivity). The partitioning will happen, and the recursion will bottom out at empty or single-element subarrays.\n\nTherefore, the reasoning provided in the statement is sound. The Lomuto partition scheme ensures termination regardless of whether $G$ is transitive.\n\n**Verdict on A: Correct**\n\n#### Analysis of Statement B\n**Statement B:** If $G$ contains a cycle such as $G(a,b)$, $G(b,c)$, and $G(c,a)$, then there is no permutation of $\\{a,b,c\\}$ that satisfies the specification $\\forall ij:\\neg G\\!\\left(A[i],A[j]\\right)$, so quicksort cannot be correct with respect to $G$ on inputs containing $\\{a,b,c\\}$.\n\nThe specification for a correctly sorted array $A$ is that for any two indices $i  j$, the condition $G(A[i], A[j])$ must be false. Let's test this condition for all $3! = 6$ permutations of the set $\\{a, b, c\\}$.\n\n1.  Permutation $[a, b, c]$: For $i=0, j=1$, we have $A[0]=a$ and $A[1]=b$. The condition requires $\\neg G(a,b)$. However, we are given $G(a,b)$ is true. This permutation is not correctly sorted.\n2.  Permutation $[a, c, b]$: For $i=0, j=2$, we have $A[0]=a$ and $A[2]=b$. The condition requires $\\neg G(a,b)$. We are given $G(a,b)$ is true. This permutation is not a valid output.\n3.  Permutation $[b, c, a]$: For $i=0, j=1$, we have $A[0]=b$ and $A[1]=c$. The condition requires $\\neg G(b,c)$. We are given $G(b,c)$ is true. This permutation is not correctly sorted.\n4.  Permutation $[b, a, c]$: For $i=0, j=2$, we have $A[0]=b$ and $A[2]=c$. The condition requires $\\neg G(b,c)$. We are given $G(b,c)$ is true. This permutation is not a valid output.\n5.  Permutation $[c, a, b]$: For $i=0, j=1$, we have $A[0]=c$ and $A[1]=a$. The condition requires $\\neg G(c,a)$. We are given $G(c,a)$ is true. This permutation is not correctly sorted.\n6.  Permutation $[c, b, a]$: For $i=0, j=2$, we have $A[0]=c$ and $A[2]=a$. The condition requires $\\neg G(c,a)$. We are given $G(c,a)$ is true. This permutation is not a valid output.\n\nAs demonstrated, none of the possible permutations of $\\{a, b, c\\}$ satisfy the sorting specification. Since the output of any sorting algorithm on this input must be one of these permutations, it is logically impossible for any comparison-based sorting algorithm, including quicksort, to produce a correct output. The statement is therefore correct.\n\n**Verdict on B: Correct**\n\n#### Analysis of Statement C\n**Statement C:** If pivots are chosen uniformly at random, quicksort can, with probability $1$, still find an output that satisfies $\\forall ij:\\neg G\\!\\left(A[i],A[j]\\right)$ even when $G$ is non-transitive with $3$-cycles.\n\nThis statement claims that a correct output can be found with probability $1$. However, as established in the analysis of Statement B, no correct output exists for an input containing $\\{a, b, c\\}$. An algorithm cannot find a solution that does not exist. The choice of pivot (random or otherwise) affects the path of execution and the specific permutation that is produced as output, but it cannot create a valid output where none is possible. The probability of finding a correct output is not $1$; it is $0$.\n\n**Verdict on C: Incorrect**\n\n#### Analysis of Statement D\n**Statement D:** Switching from the Lomuto partition to the Hoare partition restores correctness of quicksort with respect to $G$ even when $G$ is non-transitive with $3$-cycles.\n\nThe failure of quicksort is not due to the mechanics of a specific partition scheme but to the fundamental logical impossibility of linearizing a set of elements under a cyclic \"greater than\" relation, as established in the analysis of Statement B. Both Lomuto and Hoare partitions are merely different algorithms for dividing an array into two subarrays based on a pivot and the comparator $G$. Neither scheme can resolve the contradiction inherent in the comparator itself. Switching from one partition scheme to another will likely result in a different incorrect permutation of the input, but it cannot produce a correct one because none exists.\n\n**Verdict on D: Incorrect**\n\n#### Analysis of Statement E\n**Statement E:** Non-transitivity of $G$ can cause quicksort to fail to terminate, because the partition step may not make progress and recursion can repeat indefinitely on subarrays of the same length.\n\nThis statement contradicts Statement A. As shown in the analysis of Statement A, quicksort using the Lomuto partition scheme is guaranteed to terminate because its recursive structure strictly reduces the problem size. The statement \"quicksort can fail to terminate\" implies that this is a possibility for a standard implementation of the algorithm. Since the Lomuto scheme is a standard implementation and it does not fail to terminate, this statement is false.\n\nEven for the Hoare partition scheme, non-termination is typically associated with implementation flaws (e.g., improper handling of elements equal to the pivot) rather than properties of the comparator. A robust implementation of Hoare partition also ensures that the subproblems are strictly smaller than the parent problem, thus guaranteeing termination. The property of non-transitivity affects the correctness of the final permutation, but it does not introduce a new mechanism for non-termination in a well-implemented quicksort algorithm.\n\n**Verdict on E: Incorrect**",
            "answer": "$$\\boxed{AB}$$"
        }
    ]
}