{
    "hands_on_practices": [
        {
            "introduction": "线性探测是开放定址法中最简单的一种，但它有一个显著的弱点：主聚集（primary clustering）。这个实践旨在让你亲手验证并量化这个问题。通过人工构建一个连续的、无间断的元素簇，你将直接测量搜索时间如何随簇的长度线性增长，从而深刻理解线性探测在最坏情况下的性能瓶颈。",
            "id": "3257276",
            "problem": "考虑一个使用开放寻址法和线性探测实现的哈希表。该哈希表容量为 $m$，哈希函数为 $h(k)$，探测序列为 $p_j(k) = (h(k) + j) \\bmod m$，其中 $j = 0, 1, \\dots, m-1$。成本模型将搜索时间定义为检查的槽位数量（探测次数），这是一个以“探测次数”为单位的无量纲度量。\n\n从基本定义开始：\n- 开放寻址法将所有键都放入表本身；冲突通过使用探测序列找到下一个可用槽位来解决。\n- 线性探测使用等差级数探测序列，这会产生连续的已占用槽位（簇）。\n- 当在探测的槽位中找到键或遇到空槽位时，搜索终止。成功搜索的成本等于直到检查到匹配键为止的探测次数。不成功搜索的成本等于直到检查到第一个空槽位为止的探测次数。\n\n当连续的已占用槽位形成并增长时，就会出现一次聚集；探测到这样的簇会强制对整个簇进行顺序扫描。您将构建一个综合基准测试来分离这种现象。\n\n基准测试设计：\n- 使用基于模运算的哈希函数 $h(k) = k \\bmod m$。\n- 固定一个起始索引 $s$，并创建一个长度为 $C$ 的单一连续簇，占据槽位 $s, s+1, \\dots, s+C-1$ 且不回绕，槽位 $s+C$ 为空。通过插入键 $k_i = s + i \\cdot m$（其中 $i = 0, 1, \\dots, C-1$）来实现这一点。在线性探测和给定的哈希函数下，每个这样的键最初都哈希到 $s$，并被放置在下一个可用槽位，从而填满连续的块。\n- 对于每个簇长度 $C$，测量：\n  1. 簇内的平均成功搜索成本，通过搜索所有 $C$ 个已插入的键并对其探测次数取平均值获得。\n  2. 当初始探测位于簇的起始位置时的不成功搜索成本，通过搜索一个哈希到 $s$ 但不存在的键 $k^\\star = s + C \\cdot m$ 获得。\n  3. 当初始探测在簇偏移量上均匀分布时的平均不成功搜索成本，通过搜索 $C$ 个不同的键 $u_\\delta = (s + \\delta) + M \\cdot m$（其中 $\\delta = 0, 1, \\dots, C-1$，$M$ 是一个足够大的整数以确保这些键都不等于任何已插入的键）获得。每个这样的键都从索引 $s + \\delta$ 开始探测且不存在。\n\n科学要求：\n- 从给定的定义（不使用快捷公式）推导这三种成本对簇长度 $C$ 的预期依赖关系。您的推导必须解释为什么当探测单个连续簇时，搜索时间与 $C$ 呈线性关系。\n- 仔细处理边界情况。对于 $C = 0$，按照惯例将平均成功搜索成本定义为 $0$（没有成功搜索），从起始位置开始的不成功搜索成本为 $1$ 次探测（起始槽位为空），在均匀偏移下的平均不成功搜索成本为 $1$ 次探测。\n\n测试套件：\n- 使用固定的表大小 $m = 4096$ 和起始索引 $s = 123$。\n- 评估集合 $\\{0, 1, 8, 64, 512, 2048, 3968\\}$ 中的簇长度 $C$，这涵盖了空簇、微小簇、中等簇和接近最大且不回绕的簇，因为对于所有列出的 $C$ 值，都有 $s + C \\leq m - 1$。\n\n程序要求：\n- 完全按照定义实现线性探测。\n- 对于每个测试用例的簇长度 $C$，构建簇并计算上述指定的三个指标。\n- 以探测次数（无单位计数）表示所有三个指标。\n- 将所有测试用例的结果聚合成单行输出，形式为方括号括起来的逗号分隔列表。此列表的每个元素本身必须是方括号括起来的逗号分隔列表，格式为 $[C,\\ \\text{avg\\_succ},\\ \\text{unsucc\\_start},\\ \\text{avg\\_unsucc\\_uniform}]$，其中 $C$ 是一个整数，三个成本是以探测次数为单位的浮点数或整数。例如，顶层格式为 $[[\\dots],[\\dots],\\dots]$。",
            "solution": "基本依据是开放寻址法、线性探测以及探测次数成本模型的定义。设表容量为 $m$，哈希函数为 $h(k) = k \\bmod m$，探测序列为 $p_j(k) = (h(k) + j) \\bmod m$。搜索沿探测序列顺序检查槽位；成本等于检查的槽位总数。成功搜索在检查的槽位包含目标键时停止。不成功搜索在检查的槽位为空时停止。\n\n通过插入 $C$ 个都哈希到同一起始索引 $s$ 的键来构建一个巨大的簇：\n- 插入键 $k_i = s + i \\cdot m$，其中 $i \\in \\{0, 1, \\dots, C-1\\}$。\n- 每次插入都从 $h(k_i) = s$ 开始，并使用线性探测找到下一个空槽位，因此插入的键占据 $s, s+1, \\dots, s+C-1$ 且不回绕，前提是 $s + C \\leq m - 1$。槽位 $s+C$ 保持为空。\n\n我们现在推导搜索成本作为簇长度 $C$ 的函数。\n\n簇内的成功搜索：\n- 考虑放置在偏移量 $\\delta \\in \\{0, 1, \\dots, C-1\\}$ 处的键，它位于槽位 $s+\\delta$。\n- 其探测序列从 $s$ 开始，搜索会扫描 $s, s+1, \\dots, s+\\delta$ 直到找到该键。探测次数等于 $\\delta + 1$。\n- 对簇中所有键进行平均，平均成功搜索成本为\n$$\n\\frac{1}{C} \\sum_{\\delta=0}^{C-1} (\\delta + 1) = \\frac{1}{C} \\left( \\sum_{\\delta=0}^{C-1} \\delta + \\sum_{\\delta=0}^{C-1} 1 \\right) = \\frac{1}{C} \\left( \\frac{(C-1)C}{2} + C \\right) = \\frac{C+1}{2}.\n$$\n- 对于边界情况 $C=0$，没有成功搜索可供平均；按照惯例，我们将平均值定义为 $0$。\n\n从簇起始位置开始的不成功搜索：\n- 考虑一个缺失的键 $k^\\star$，其 $h(k^\\star) = s$（例如 $k^\\star = s + C \\cdot m$）。\n- 探测序列从 $s$ 开始，并扫描簇槽位 $s, s+1, \\dots, s+C-1$，发现每个槽位都已被占用。第一个空槽位在 $s+C$。\n- 探测次数等于检查的已占用槽位数加上对空槽位的检查，即 $C + 1$。\n- 对于边界情况 $C=0$，第一个探测的槽位 $s$ 是空的，所以成本为 $1$。\n\n在簇上具有均匀起始偏移的不成功搜索：\n- 考虑缺失的键 $u_\\delta$，其 $h(u_\\delta) = s + \\delta$（$\\delta \\in \\{0, 1, \\dots, C-1\\}$），并且 $u_\\delta$ 与任何已插入的键都不同。\n- 探测序列从 $s + \\delta$ 开始，扫描 $s + \\delta, s + \\delta + 1, \\dots, s+C - 1$，然后是位于 $s+C$ 的第一个空槽位。\n- 对于偏移量 $\\delta$，探测次数为 $(C - \\delta) + 1$。\n- 对所有偏移量进行平均，\n$$\n\\frac{1}{C} \\sum_{\\delta=0}^{C-1} \\big( (C - \\delta) + 1 \\big) = \\frac{1}{C} \\left( \\sum_{\\delta=0}^{C-1} (C - \\delta) + \\sum_{\\delta=0}^{C-1} 1 \\right) = \\frac{1}{C} \\left( \\frac{C(C+1)}{2} + C \\right) = \\frac{C+3}{2}.\n$$\n- 对于边界情况 $C=0$，没有偏移量可供平均；成本简化为起始情况，即 $1$。\n\n这些推导表明，在线性探测下，成本对聚集具有线性敏感性：\n- 平均成功搜索成本随 $\\frac{C+1}{2}$ 增长。\n- 从簇起始位置开始的不成功搜索成本随 $C+1$ 增长。\n- 在簇上具有均匀起始偏移的平均不成功搜索成本随 $\\frac{C+3}{2}$ 增长。\n每个表达式都是簇长度 $C$ 的仿射函数，因此创建一个巨大的簇会导致搜索时间随簇长度线性扩展。\n\n算法实现：\n- 根据给定的定义，使用线性探测实现插入和搜索。\n- 使用基于模运算的哈希函数，通过插入 $C$ 个初始索引为 $s$ 的冲突键来构建簇。\n- 通过检测搜索过程来计算检查的槽位数，从而直接测量探测次数。\n- 对于每个测试用例 $C \\in \\{0, 1, 8, 64, 512, 2048, 3968\\}$，其中 $m = 4096$ 且 $s = 123$，计算：\n  - 所有已插入键的平均成功搜索成本（对于 $C=0$ 定义为 $0$）。\n  - 使用一个哈希到 $s$ 的缺失键，从簇起始位置开始的不成功搜索成本。\n  - 每个偏移量使用一个缺失键，在均匀起始偏移下的平均不成功搜索成本。\n- 以指定的嵌套列表格式将聚合结果打印为单行。所有报告的值都以探测次数为单位。\n\n这种基于原理的设计直接反映了线性探测在连续占用下的行为，不依赖于超出既定定义的快捷公式，并产生与推导出的线性扩展相匹配的测量结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass LinearProbingTable:\n    def __init__(self, m: int):\n        self.m = m\n        # Use None to denote empty slot\n        self.table = [None] * m\n\n    def h(self, k: int) - int:\n        # Modulus-based hash function\n        return k % self.m\n\n    def insert(self, k: int) - bool:\n        \"\"\"Insert key k using linear probing. Returns True if inserted, False if table is full.\"\"\"\n        idx = self.h(k)\n        for _ in range(self.m):\n            if self.table[idx] is None:\n                self.table[idx] = k\n                return True\n            idx = (idx + 1) % self.m\n        return False  # Table full\n\n    def probe_count_search(self, k: int) - int:\n        \"\"\"Return number of probes used to search for k (successful or unsuccessful).\"\"\"\n        idx = self.h(k)\n        probes = 0\n        for _ in range(self.m):\n            probes += 1\n            slot = self.table[idx]\n            if slot is None:\n                return probes  # unsuccessful: empty slot terminates\n            if slot == k:\n                return probes  # successful: found the key\n            idx = (idx + 1) % self.m\n        # If full cycle without finding empty or the key (should not happen with our construction),\n        # return the maximum probes m.\n        return probes\n\ndef build_cluster_and_measure(m: int, s: int, C: int):\n    \"\"\"\n    Build a single contiguous cluster starting at index s of length C without wrap-around,\n    and measure:\n      - average successful search probes over all inserted keys,\n      - unsuccessful search probes starting from s (key hashing to s but missing),\n      - average unsuccessful search probes when initial probe is uniformly distributed over cluster offsets.\n    \"\"\"\n    # Preconditions: ensure the cluster fits without wrap-around\n    assert s + C = m - 1, \"Cluster must not wrap around.\"\n\n    table = LinearProbingTable(m)\n\n    # Insert C keys that all hash to s to form the cluster in slots s..s+C-1\n    inserted_keys = []\n    for i in range(C):\n        k = s + i * m  # all hash to s\n        ok = table.insert(k)\n        if not ok:\n            raise RuntimeError(\"Insertion failed: table unexpectedly full.\")\n        inserted_keys.append(k)\n\n    # Average successful search over inserted keys\n    if C == 0:\n        avg_succ = 0.0  # by convention\n    else:\n        succ_probes = [table.probe_count_search(k) for k in inserted_keys]\n        avg_succ = float(sum(succ_probes)) / float(len(succ_probes))\n\n    # Unsuccessful search from start (key hashing to s but not present)\n    missing_start_key = s + C * m  # hashes to s, not inserted\n    unsucc_start = float(table.probe_count_search(missing_start_key))\n\n    # Average unsuccessful search with uniform starting offsets over the cluster\n    if C == 0:\n        avg_unsucc_uniform = 1.0  # degenerate case: same as start case\n    else:\n        # For each offset delta in 0..C-1, choose a missing key hashing to s+delta\n        # Ensure keys do not equal any inserted key: pick a large M to avoid collisions with existing keys\n        M = C + 12345  # any large integer suffices\n        unsucc_uniform_probes = []\n        for delta in range(C):\n            u = (s + delta) + M * m\n            unsucc_uniform_probes.append(table.probe_count_search(u))\n        avg_unsucc_uniform = float(sum(unsucc_uniform_probes)) / float(len(unsucc_uniform_probes))\n\n    return [C, avg_succ, unsucc_start, avg_unsucc_uniform]\n\ndef format_list(obj):\n    \"\"\"Format nested lists without spaces, as required.\"\"\"\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(format_list(x) for x in obj) + \"]\"\n    elif isinstance(obj, (int, float)):\n        # Ensure consistent float formatting (no trailing .0 removal for ints)\n        return str(obj)\n    elif isinstance(obj, bool):\n        return \"True\" if obj else \"False\"\n    else:\n        raise TypeError(\"Unsupported type for formatting\")\n\ndef solve():\n    # Define the test cases from the problem statement.\n    m = 4096\n    s = 123\n    test_cases = [\n        # cluster lengths C covering empty, small, moderate, and near-maximum cluster sizes without wrap-around\n        0, 1, 8, 64, 512, 2048, 3968\n    ]\n\n    results = []\n    for C in test_cases:\n        results.append(build_cluster_and_measure(m, s, C))\n\n    # Final print statement in the exact required format: a single line with nested lists, comma-separated, no spaces.\n    print(format_list(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "理解了主聚集的理论影响后，下一个问题是它在实际中如何发生。这个编码练习将向你展示，非随机的插入顺序（例如，按排序顺序插入）是怎样导致灾难性的性能下降的。通过对比有序插入和随机顺序插入的平均探测量和最大簇长度，你将直观地看到数据模式对哈希表性能的巨大影响。",
            "id": "3257202",
            "problem": "您需要实现并分析一个使用线性探测的开放定址哈希表，以研究批量插入顺序如何影响性能。该研究必须比较同一组整数键的两种批量插入顺序：升序排序和伪随机顺序。比较必须使用明确定义的度量标准和一个固定的哈希函数来量化其影响，该哈希函数会创建一个从键值到初始地址的单调映射，当键分布不均匀时，可能导致非均匀的冲突。\n\n基本和核心定义：\n- 开放定址通过探测一系列候选索引，直到找到一个空槽，将每个键插入到一个容量为 $m$ 的单个数组中。\n- 线性探测将键 $k$ 的探测序列定义为连续的索引 $h(k), h(k)+1, h(k)+2, \\dots$ (对 $m$ 取模)，其中 $h(k)$ 是 $k$ 的哈希值。\n- 需要实现的哈希函数是除法方法 $h(k) = \\left\\lfloor \\dfrac{m \\cdot k}{U} \\right\\rfloor$，其中 $U$ 是一个定义键域尺度的正整数，$k$ 是范围在 $[0, U-1]$ 内的整数键。\n- 插入单个键的探测次数定义为检查的槽位数，包括最终成功放入的槽位。\n- 在一批次插入结束时，最大连续占用簇的长度定义为循环遍历表时遇到的最大连续占用槽位数（考虑环绕；遍历必须从某个空槽后立即开始，以避免重复计数）。\n\n两种插入顺序：\n- 排序顺序：键按升序数值顺序插入。\n- 随机顺序：键按以下顺序插入：通过线性同余生成器 (LCG) 为每个键生成一个伪随机分数，然后根据这些分数对键进行排序。线性同余生成器 (LCG) 定义为 $X_{i+1} = (a X_i + c) \\bmod M$，参数为 $a = 1664525$，$c = 1013904223$ 和 $M = 2^{32}$。每个测试用例给定一个固定的种子 $X_0$。为获得一个排列，为每个键生成一个分数 $X_i$，并根据这些分数对键进行排序。\n\n键集构造：\n- 对于每个测试用例，构造的键会在初始地址上产生双峰密度：一个低索引组和一个高索引组。\n- 设 $L$ 和 $t$ 为正整数。低索引组对于每个桶索引 $i \\in \\{0, 1, \\dots, L-1\\}$ 包含 $t$ 个键；高索引组对于每个桶索引 $j \\in \\{m-L, m-L+1, \\dots, m-1\\}$ 包含 $t$ 个键。\n- 对于桶索引 $b$，从区间 $I_b = \\left[\\left\\lfloor \\dfrac{U \\cdot b}{m} \\right\\rfloor, \\left\\lfloor \\dfrac{U \\cdot (b+1)}{m} \\right\\rfloor - 1\\right]$ 中选择 $t$ 个不同的键 $k$，使得 $h(k) = b$。使用 $I_b$ 中的前 $t$ 个整数（按升序）。键的总数为 $n = 2Lt$，负载因子为 $n/m$。所有测试用例均满足 $n  m$，以确保插入成功。\n\n每个测试用例要计算的度量标准：\n- 排序顺序的平均探测次数，记为 $\\overline{P}_{\\mathrm{sorted}}$。\n- 随机顺序的平均探测次数，记为 $\\overline{P}_{\\mathrm{random}}$。\n- 排序顺序的最终最大簇长度，记为 $C_{\\mathrm{sorted}}$。\n- 随机顺序的最终最大簇长度，记为 $C_{\\mathrm{random}}$。\n- 报告比率 $R_P = \\dfrac{\\overline{P}_{\\mathrm{sorted}}}{\\overline{P}_{\\mathrm{random}}}$ 和 $R_C = \\dfrac{C_{\\mathrm{sorted}}}{C_{\\mathrm{random}}}$。\n\n测试套件：\n对于每个参数元组 $(m, U, L, t, \\text{seed})$，构造键并测量上述两个比率。\n1. $(m, U, L, t, \\text{seed}) = (1024, 1024000, 240, 2, 123456789)$ 使得 $n = 2 \\cdot 240 \\cdot 2 = 960$。\n2. $(m, U, L, t, \\text{seed}) = (512, 512000, 120, 2, 987654321)$ 使得 $n = 480$。\n3. $(m, U, L, t, \\text{seed}) = (257, 257000, 64, 1, 20231102)$ 使得 $n = 128$。\n4. $(m, U, L, t, \\text{seed}) = (128, 128000, 24, 2, 31415926)$ 使得 $n = 96$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，该列表必须按顺序包含 $R_P$ 和 $R_C$，两者均为浮点数。对于上述整个测试套件，输出必须为：\n$[R_{P,1}, R_{C,1}, R_{P,2}, R_{C,2}, R_{P,3}, R_{C,3}, R_{P,4}, R_{C,4}]$。\n\n约束和期望：\n- 完全按照定义实现哈希表和度量标准。\n- 不允许外部输入；程序必须嵌入测试套件并打印单行输出。\n- 每个测试用例使用指定的LCG生成伪随机顺序。\n- 程序必须是完整且可运行的，并且必须严格遵守上述最终输出格式。",
            "solution": "该问题的核心在于演示线性探测中的主聚集现象如何被非随机的插入模式（如排序插入）显著加剧。\n\n**排序插入的性能退化**：当使用哈希函数 $h(k) = \\lfloor (m \\cdot k) / U \\rfloor$ 时，数值上相近的键 $k$ 和 $k+1$ 倾向于哈希到相同或相邻的槽位。当按排序顺序插入键时，一个小的冲突会滚雪球般地发展。例如，如果键 $k_1$ 和 $k_2$ 哈希到同一个槽位 $j$，那么 $k_2$ 会被放置到 $j+1$。当下一个键 $k_3$ 哈希到 $j$ 或 $j+1$ 时，它将被迫移动到 $j+2$。这种连锁反应导致了已占用槽位的长连续块（簇）的形成。随着簇的增长，后续插入和查找的平均探测次数会急剧增加，因为探测序列必须遍历整个簇。\n\n**随机插入的优势**：相比之下，随机顺序插入通过打乱键的邻近关系来打破这种模式。即使两个键在数值上很接近，它们也可能在插入序列中相隔很远。这使得冲突在哈希表中分布得更均匀，阻止了巨大簇的形成。因此，随机插入的平均探测次数和最大簇长度都将显著低于排序插入，其性能更接近于理论上的统一哈希假设。\n\n**算法实现**：\n1.  **键生成**：根据参数 $(m, U, L, t)$ 生成双峰分布的键集。\n2.  **顺序生成**：创建两个序列：一个按数值升序排序，另一个使用指定的LCG生成伪随机分数并据此排序。\n3.  **模拟**：对每种顺序，初始化一个空哈希表，并按顺序插入所有键。在每次插入时，记录探测次数。\n4.  **度量**：插入完成后，计算该顺序下的平均探测次数。然后，扫描整个哈希表（考虑环绕）以找到最长的连续占用槽块，即最大簇长度。\n5.  **比较**：最后，计算排序插入与随机插入的平均探测次数之比（$R_P$）和最大簇长度之比（$R_C$），以量化性能差异。\n\n这个实验将有力地证明，即使哈希函数本身是合理的，输入数据的模式也可能对线性探测的性能产生灾难性的影响。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the hash table analysis problem.\n    It iterates through predefined test cases, runs the insertion experiments,\n    and prints the final results in the required format.\n    \"\"\"\n    test_cases = [\n        (1024, 1024000, 240, 2, 123456789),\n        (512, 512000, 120, 2, 987654321),\n        (257, 257000, 64, 1, 20231102),\n        (128, 128000, 24, 2, 31415926),\n    ]\n\n    # LCG parameters\n    LCG_A = 1664525\n    LCG_C = 1013904223\n    LCG_M_MASK = 0xFFFFFFFF  # (2**32 - 1)\n\n    EMPTY_SLOT = -1 # Sentinel for an empty slot in the hash table\n\n    def generate_keys(m, U, L, t):\n        \"\"\"Generates the bimodal key set based on problem parameters.\"\"\"\n        keys = []\n        # Low-index group\n        for b in range(L):\n            start_key = (U * b) // m\n            keys.extend(range(start_key, start_key + t))\n        # High-index group\n        for b in range(m - L, m):\n            start_key = (U * b) // m\n            keys.extend(range(start_key, start_key + t))\n        return keys\n\n    def get_random_order(keys, n, seed):\n        \"\"\"Permutes keys based on scores from a Linear Congruential Generator.\"\"\"\n        lcg_state = seed\n        scores = []\n        for _ in range(n):\n            lcg_state = (LCG_A * lcg_state + LCG_C)  LCG_M_MASK\n            scores.append(lcg_state)\n        \n        # Pair keys with scores and sort by score\n        keyed_scores = list(zip(keys, scores))\n        keyed_scores.sort(key=lambda x: x[1])\n        \n        return [key for key, score in keyed_scores]\n\n    def run_experiment(m, U, n, key_order):\n        \"\"\"\n        Runs a single experiment for a given key insertion order.\n        Returns the average number of probes and the final max cluster length.\n        \"\"\"\n        table = np.full(m, EMPTY_SLOT, dtype=np.int64)\n        total_probes = 0\n\n        for key in key_order:\n            home_address = (m * key) // U\n            probes = 0\n            while True:\n                probes += 1\n                current_pos = (home_address + probes - 1) % m\n                if table[current_pos] == EMPTY_SLOT:\n                    table[current_pos] = key\n                    total_probes += probes\n                    break\n        \n        avg_probes = total_probes / n\n\n        # Calculate max cluster length\n        max_len = 0\n        current_len = 0\n        \n        # Per problem spec, start traversal after an empty slot to handle wrap-around\n        empty_indices = np.where(table == EMPTY_SLOT)[0]\n        if len(empty_indices) == 0:\n            # This case is not expected as n  m\n            max_len = m\n        else:\n            start_index = (empty_indices[0] + 1) % m\n            for i in range(m):\n                idx = (start_index + i) % m\n                if table[idx] != EMPTY_SLOT:\n                    current_len += 1\n                else:\n                    max_len = max(max_len, current_len)\n                    current_len = 0\n            # Final check for wrap-around cluster\n            max_len = max(max_len, current_len)\n            \n        return avg_probes, max_len\n\n    final_results = []\n    for m, U, L, t, seed in test_cases:\n        n = 2 * L * t\n        \n        keys = generate_keys(m, U, L, t)\n        \n        # Sorted order experiment\n        sorted_keys = sorted(keys)\n        p_sorted, c_sorted = run_experiment(m, U, n, sorted_keys)\n        \n        # Random order experiment\n        random_keys = get_random_order(keys, n, seed)\n        p_random, c_random = run_experiment(m, U, n, random_keys)\n        \n        # Calculate and store ratios\n        R_P = p_sorted / p_random\n        # Handle division by zero for cluster length, though not expected here\n        R_C = (c_sorted / c_random) if c_random != 0 else float('inf')\n        \n        final_results.append(R_P)\n        final_results.append(R_C)\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join(map(str, final_results)) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "除了插入和搜索性能，元素的删除也是哈希表设计中的一个关键挑战。在开放定址法中，一种常见的策略是使用“墓碑”（tombstone）来标记已删除的槽位。这个练习将挑战你的逆向思维能力：给定一个包含特定墓碑的最终状态，你需要设计出最高效的操作序列来达到这个状态。这有助于加深你对插入、删除和探測成本基本机制的理解。",
            "id": "3227311",
            "problem": "考虑一个使用开放寻址法和线性探测法的哈希表。该表的大小为 $m=7$，槽位索引为 $0,1,2,3,4,5,6$。键是整数，哈希函数为 $h(k)=k \\bmod 7$。一次成功的删除操作会将已删除的槽位标记为墓碑（记为 $\\dagger$），而不是将其置空；查找一个键时，从 $h(k)$ 开始，以模 $7$ 的方式线性探测后续索引，直到找到该键或一个空槽位，而墓碑标记不会终止查找。插入一个键 $k$ 时，从 $h(k)$ 开始线性探测，直到找到一个空槽位或第一个墓碑标记，并将键存储在该处。成本模型是开放寻址法的标准模型：在查找、插入或删除过程中的每次槽位检查计为一次探测。\n\n从一个空表开始，你可以选择任意整数键，并执行任意的插入和删除操作序列。你的目标是达到一个最终状态，在该状态下，表的槽位 $2$、$4$ 和 $6$ 处恰好是墓碑标记，所有其他槽位均为空，且表中没有任何活动的键。在上述规则下，要达到这样的最终状态，整个操作序列所需的槽位检查（探测）总数的最小值是多少？请以一个不带单位的精确整数形式给出答案。",
            "solution": "问题要求将一个大小为 $m=7$ 的空哈希表转换为一个在槽位 $2$、$4$ 和 $6$ 处有墓碑标记、所有其他槽位均为空的状态，所需的槽位检查（探测）总数的最小值。该哈希表使用开放寻址法和线性探测法，哈希函数为 $h(k) = k \\bmod 7$。\n\n首先，我们来分析创建一个墓碑标记的过程。在槽位 $i$ 创建一个墓碑标记，需要先将一个键插入该槽位，然后删除同一个键。这至少需要一次插入和一次删除操作。\n\n任何操作（插入、查找或删除）的成本定义为检查的槽位数量。由于每次操作都必须检查至少一个槽位，因此任何单个操作的成本至少为 $1$。因此，创建一个墓碑标记的最小成本至少是 $1$（用于插入）$+ 1$（用于删除）$= 2$ 次探测。\n\n我们的目标是在槽位 $2$、$4$ 和 $6$ 创建三个不同的墓碑标记。由于每个墓碑标记的创建至少需要两次探测，并且创建一个墓碑标记的操作不会免除创建另一个墓碑标记所需的操作，因此创建三个墓碑标记的总探测次数必须至少为 $3 \\times 2 = 6$。这为总成本建立了一个下界。\n\n现在，我们必须确定这个 $6$ 次探测的下界是否可以达到。为此，我们需要构造一个操作序列，该序列能达到目标状态，且总成本恰好为 $6$。总成本为 $6$ 要求三次必要的插入和三次必要的删除操作中的每一次成本都恰好为 $1$ 次探测。\n\n我们来分析一次插入和一次删除的成本。\n插入一个键 $k$ 的成本是从索引 $h(k)$ 开始探测直到找到一个可用槽位的探测次数。可用槽位定义为空槽位或第一个包含墓碑标记的槽位。如果索引 $h(k)$ 处的槽位本身就是可用的，则成本可最小化为 $1$。\n删除位于槽位 $i$ 的键 $k$ 的成本是从 $h(k)$ 开始探测直到到达槽位 $i$ 的探测次数。如果键 $k$ 的放置位置满足 $h(k)=i$，则成本可最小化为 $1$。\n\n为了在槽位 $i$ 处创建一个墓碑标记，并使插入和删除的成本都为 $1$，我们应该选择一个键 $k$ 使得 $h(k)=i$。让我们基于这个原则设计一个操作序列。我们需要在槽位 $i_1=2$、$i_2=4$ 和 $i_3=6$ 创建墓碑标记。\n\n我们可以选择三个不同的键 $k_1, k_2, k_3$，使其哈希值对应于期望的墓碑标记位置。让我们选择 $k_1=2$、$k_2=4$ 和 $k_3=6$。\n$h(k_1) = 2 \\bmod 7 = 2$\n$h(k_2) = 4 \\bmod 7 = 4$\n$h(k_3) = 6 \\bmod 7 = 6$\n\n考虑以下从空表开始的操作序列。\n\n1.  **插入键 $k_1=2$**：探测从 $h(2)=2$ 开始。槽位 $2$ 为空。将键 $2$ 放入槽位 $2$。\n    探测次数：$1$。\n    表状态：`[ , , 2, , , , ]`。\n    累计探测次数：$1$。\n\n2.  **插入键 $k_2=4$**：探测从 $h(4)=4$ 开始。槽位 $4$ 为空。将键 $4$ 放入槽位 $4$。\n    探测次数：$1$。\n    表状态：`[ , , 2, , 4, , ]`。\n    累计探测次数：$1+1=2$。\n\n3.  **插入键 $k_3=6$**：探测从 $h(6)=6$ 开始。槽位 $6$ 为空。将键 $6$ 放入槽位 $6$。\n    探测次数：$1$。\n    表状态：`[ , , 2, , 4, , 6]`。\n    累计探测次数：$2+1=3$。\n\n此时，所有需要的键都已在表中。现在我们删除它们以创建墓碑标记。\n\n4.  **删除键 $k_1=2$**：查找从 $h(2)=2$ 开始。在第一个探测的槽位，即索引 $2$ 处找到键 $2$。该槽位被标记为墓碑（$\\dagger$）。\n    探测次数：$1$。\n    表状态：`[ , , †, , 4, , 6]`。\n    累计探测次数：$3+1=4$。\n\n5.  **删除键 $k_2=4$**：查找从 $h(4)=4$ 开始。在槽位 $4$ 处找到键 $4$。该槽位被标记为墓碑。\n    探测次数：$1$。\n    表状态：`[ , , †, , †, , 6]`。\n    累计探测次数：$4+1=5$。\n\n6.  **删除键 $k_3=6$**：查找从 $h(6)=6$ 开始。在槽位 $6$ 处找到键 $6$。该槽位被标记为墓碑。\n    探测次数：$1$。\n    表状态：`[ , , †, , †, , †]`。\n    累计探测次数：$5+1=6$。\n\n表的最终状态是槽位 $2$、$4$ 和 $6$ 处有墓碑标记，所有其他槽位（$0, 1, 3, 5$）保持为空。这完全符合问题的要求。此序列的总探测次数为 $6$。\n\n既然我们已经建立了一个 $6$ 次探测的下界，并演示了一个达到此成本的操作序列，那么最小总探测次数必定是 $6$。任何其他选择的键或操作顺序都无法得到更低的成本。例如，使用一个哈希到与其最终位置 $i$ 不同的值（即 $h(k) \\neq i$）的键 $k$，将导致插入（由于冲突或槽位已被占用）和删除的探测次数都大于 $1$，从而增加总成本。特定的插入规则（在第一个墓碑标记处停止）不会改变这个最优策略，因为成本最低的路径是在空槽位中进行插入。",
            "answer": "$$\\boxed{6}$$"
        }
    ]
}