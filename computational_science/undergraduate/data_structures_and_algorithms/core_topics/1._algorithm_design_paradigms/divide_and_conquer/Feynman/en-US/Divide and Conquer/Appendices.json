{
    "hands_on_practices": [
        {
            "introduction": "The power of Divide and Conquer extends beyond simple sorting to solving complex combinatorial counting problems. This practice challenges you to count the number of \"inversions\" in an array, a measure of how unsorted it is. By augmenting the standard Merge Sort algorithm, you will see how the \"combine\" step can be cleverly designed to compute this count with no asymptotic overhead, turning a sorting algorithm into a powerful analytical tool .",
            "id": "3228600",
            "problem": "Consider an integer array $A$ of length $n$ whose elements are drawn from a known, but large, integer range $[\\alpha,\\beta]$. An inversion in $A$ is a pair of indices $(i,j)$ with $0 \\leq i < j < n$ such that $A[i] > A[j]$. Using the divide-and-conquer paradigm, design and implement a program that, for each array in the test suite specified below, counts the total number of inversions. The algorithm must rely only on comparison-based operations, must correctly handle duplicate values (equal values must not be counted as inversions), and must not allocate memory proportional to the range size $(\\beta - \\alpha + 1)$.\n\nFundamental base for reasoning: use core definitions and principles of divide-and-conquer in data structures and algorithms, including the notion of splitting into subproblems, recursively solving subproblems, and combining their solutions. The derivation should start from these principles and from the definition of an inversion as given above.\n\nTest suite:\n- $A_1 = [2,4,1,3,5]$, with $n = 5$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n- $A_2 = [1,2,3,4,5,6]$, with $n = 6$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n- $A_3 = [5,4,3,2,1]$, with $n = 5$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n- $A_4 = [10^{12},10^{12},-10^{12},0,10^{12}]$, with $n = 5$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n- $A_5 = []$, with $n = 0$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n- $A_6 = [42]$, with $n = 1$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n- $A_7 = [7,7,7]$, with $n = 3$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n- $A_8 = [3,3,2,2,1]$, with $n = 5$ and elements in $[\\alpha,\\beta] = [-10^{12},10^{12}]$.\n\nRequired final output format: your program should produce a single line of output containing the inversion counts for $A_1$ through $A_8$ as a comma-separated list enclosed in square brackets, in the order given above, for example $[x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8]$, where each $x_i$ is an integer.",
            "solution": "The user-provided problem is assessed as valid and will be solved.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Objective**: Count the total number of inversions in an integer array $A$ of length $n$.\n- **Definition of Inversion**: A pair of indices $(i, j)$ such that $0 \\leq i < j < n$ and $A[i] > A[j]$.\n- **Data Range**: Array elements are drawn from a known integer range $[\\alpha, \\beta]$, which is large.\n- **Paradigm Constraint**: The solution must use the divide-and-conquer paradigm.\n- **Operational Constraint**: The algorithm must rely only on comparison-based operations.\n- **Constraint on Duplicates**: Equal values, i.e., $A[i] = A[j]$, must not be counted as inversions.\n- **Memory Constraint**: The algorithm must not allocate memory proportional to the range size $(\\beta - \\alpha + 1)$.\n- **Test Suite**:\n    - $A_1 = [2,4,1,3,5]$, $n = 5$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n    - $A_2 = [1,2,3,4,5,6]$, $n = 6$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n    - $A_3 = [5,4,3,2,1]$, $n = 5$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n    - $A_4 = [10^{12},10^{12},-10^{12},0,10^{12}]$, $n = 5$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n    - $A_5 = []$, $n = 0$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n    - $A_6 = [42]$, $n = 1$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n    - $A_7 = [7,7,7]$, $n = 3$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n    - $A_8 = [3,3,2,2,1]$, $n = 5$, $[\\alpha,\\beta] = [-10^{12},10^{12}]$\n- **Output Format**: A single line string `[x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8]`.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is evaluated against the specified criteria:\n- **Scientifically Grounded & Objective**: The problem of counting inversions is a standard, well-defined problem in the field of algorithms and data structures. The definition is precise and mathematical. This satisfies the grounding and objectivity criteria.\n- **Well-Posed**: A unique, integer-valued solution exists for any given finite array. The constraints guide the choice of algorithm but do not make the problem unsolvable.\n- **Consistency**: The constraints are self-consistent and logical. Specifically, the large value range $[\\alpha, \\beta]$ combined with the constraint on memory allocation effectively rules out solutions based on counting sort or frequency arrays (which would require memory proportional to $\\beta - \\alpha$), thereby reinforcing the requirement for a comparison-based approach like the one derived from the divide-and-conquer paradigm.\n- **Relevance**: The problem is directly relevant to the topic of *divide and conquer*.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. It is a well-posed, scientifically-grounded problem with clear, consistent constraints that squarely falls within the domain of algorithm design using the divide-and-conquer paradigm. A complete solution will be provided.\n\n### Principle-Based Solution Derivation\n\nThe problem requires counting inversions in an array $A$ of length $n$ using the divide-and-conquer paradigm. An inversion is defined as a pair of indices $(i, j)$ where $i < j$ and $A[i] > A[j]$.\n\n**1. Divide-and-Conquer Strategy**\n\nThe divide-and-conquer approach involves three steps:\n- **Divide**: Split the problem into smaller, similar subproblems. We divide the array $A$ of size $n$ into two subarrays, a left half $L$ and a right half $R$, each of approximate size $n/2$.\n- **Conquer**: Solve the subproblems recursively. We recursively count the inversions within $L$ and $R$. Let these counts be $I_L$ and $I_R$, respectively.\n- **Combine**: Combine the solutions of the subproblems to get the solution for the original problem.\n\nThe total number of inversions in $A$ is the sum of three distinct types of inversions:\n1. Inversions entirely within the left subarray $L$ (counted by $I_L$).\n2. Inversions entirely within the right subarray $R$ (counted by $I_R$).\n3. Inversions with one element in $L$ and the other in $R$. These are \"split inversions\". Let this count be $I_S$.\n\nThe total inversion count is $I_{total} = I_L + I_R + I_S$. The recursive calls handle the first two components. The primary challenge is to efficiently compute $I_S$ in the combine step.\n\n**2. The Combine Step: Counting Split Inversions**\n\nA split inversion is a pair $(a, b)$ where $a \\in L$, $b \\in R$, and $a > b$. A naive approach of comparing every element of $L$ with every element of $R$ would take $\\mathcal{O}(n^2)$ time for the combine step, leading to a recurrence $T(n) = 2T(n/2) + \\mathcal{O}(n^2)$, which solves to $T(n) = \\mathcal{O}(n^2)$. This is no better than a brute-force check of all pairs in the original array.\n\nTo achieve a more efficient solution, we can leverage the structure of the Merge Sort algorithm. The key insight is that if the left subarray $L$ and the right subarray $R$ are already sorted, we can count the split inversions in linear time, i.e., $\\mathcal{O}(n)$, while simultaneously merging them into a single sorted array.\n\nLet's modify the recursive function to not only return the inversion count but also the sorted version of the subarray it processed. The combine step then becomes a \"merge-and-count\" procedure.\n\n**3. The Merge-and-Count Algorithm**\n\nSuppose we have the sorted left subarray $L'$ and the sorted right subarray $R'$. We use two pointers, $i$ for $L'$ and $j$ for $R'$, both initialized to $0$, and an auxiliary array `merged_array` to store the result. We iterate while both pointers are within their respective array bounds:\n\n- **Compare $L'[i]$ and $R'[j]$**:\n    - If $L'[i] \\le R'[j]$: This means $L'[i]$ is smaller than or equal to the current element $R'[j]$ and, by extension (since $R'$ is sorted), all subsequent elements in $R'$. Thus, $L'[i]$ does not form a split inversion with any remaining element of $R'$. We append $L'[i]$ to `merged_array` and increment $i$.\n    - If $L'[i] > R'[j]$: This is the crucial case. Since $L'[i] > R'[j]$, and $L'$ is also sorted, every element in $L'$ from index $i$ onwards (i.e., $L'[i], L'[i+1], \\dots$) must also be greater than $R'[j]$. The number of such elements is equal to the number of elements remaining in $L'$, which is $(|L'| - i)$. We have discovered $(|L'| - i)$ new split inversions. We add this number to our running count for $I_S$, append $R'[j]$ to `merged_array`, and increment $j$.\n\nAfter one of the subarrays is exhausted, we append the remaining elements of the other subarray to `merged_array`. This process correctly counts all split inversions and produces a single sorted array in $\\mathcal{O}(n)$ time.\n\n**4. Recurrence Relation and Complexity Analysis**\n\nThe algorithm can be described by the following recurrence relation for its time complexity, $T(n)$:\n$$T(n) = 2T(n/2) + \\mathcal{O}(n)$$\nwhere $2T(n/2)$ represents the two recursive calls on subarrays of size $n/2$, and $\\mathcal{O}(n)$ represents the linear time taken by the merge-and-count step.\n\nAccording to the Master Theorem (Case $2$, where $a=2, b=2,$ and $f(n) = \\Theta(n^{\\log_b a}) = \\Theta(n^{\\log_2 2}) = \\Theta(n)$), this recurrence solves to:\n$$T(n) = \\mathcal{O}(n \\log n)$$\n\nThe space complexity is determined by the auxiliary array required for the merge step, which is of size $n$. Thus, the space complexity is $\\mathcal{O}(n)$. This satisfies the constraint that memory allocation must not be proportional to the element value range $(\\beta - \\alpha + 1)$.\n\nThe base case for the recursion is an array of size $0$ or $1$, which by definition has $0$ inversions. The algorithm is comparison-based and correctly handles duplicates by using the strict inequality $A[i] > A[j]$ for inversions, which is implemented as $L'[i] > R'[j]$ in the logic.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the inversion counting problem for the given test suite.\n    \"\"\"\n\n    def count_inversions(arr):\n        \"\"\"\n        Main function to initiate the inversion counting process.\n        It uses a recursive helper function that implements the merge-sort-based algorithm.\n        \"\"\"\n        if not arr or len(arr) < 2:\n            return 0\n        \n        # The recursive function returns a tuple: (sorted_array, inversion_count)\n        _, total_inversions = _merge_sort_and_count(arr)\n        return total_inversions\n\n    def _merge_sort_and_count(arr):\n        \"\"\"\n        Recursively sorts the array and counts inversions using the divide-and-conquer strategy.\n        \n        Returns:\n            A tuple containing the sorted version of `arr` and the number of inversions.\n        \"\"\"\n        n = len(arr)\n        if n < 2:\n            # Base case: an array with 0 or 1 element has 0 inversions and is already sorted.\n            return arr, 0\n\n        # 1. Divide\n        mid = n // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        # 2. Conquer: Recursively sort and count inversions in both halves.\n        sorted_left, left_inversions = _merge_sort_and_count(left_half)\n        sorted_right, right_inversions = _merge_sort_and_count(right_half)\n\n        # 3. Combine: Merge the sorted halves and count split inversions.\n        merged_array = []\n        split_inversions = 0\n        i, j = 0, 0\n        len_left, len_right = len(sorted_left), len(sorted_right)\n\n        while i < len_left and j < len_right:\n            # The core logic for merging and counting split inversions.\n            if sorted_left[i] <= sorted_right[j]:\n                # No inversion here. Append the smaller element from the left.\n                merged_array.append(sorted_left[i])\n                i += 1\n            else:\n                # An inversion is found. The element from the right is smaller.\n                merged_array.append(sorted_right[j])\n                j += 1\n                # All remaining elements in sorted_left are also > sorted_right[j]\n                # The number of such elements is len_left - i.\n                split_inversions += (len_left - i)\n        \n        # Append any remaining elements from either half.\n        merged_array.extend(sorted_left[i:])\n        merged_array.extend(sorted_right[j:])\n\n        total_inversions = left_inversions + right_inversions + split_inversions\n        \n        return merged_array, total_inversions\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        [2, 4, 1, 3, 5],\n        [1, 2, 3, 4, 5, 6],\n        [5, 4, 3, 2, 1],\n        [10**12, 10**12, -10**12, 0, 10**12],\n        [],\n        [42],\n        [7, 7, 7],\n        [3, 3, 2, 2, 1],\n    ]\n\n    results = []\n    for case in test_cases:\n        result = count_inversions(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Divide and Conquer is the cornerstone of efficient searching, but its application is not limited to fully sorted data. This exercise asks you to find the peak element in a \"bitonic\" arrayâ€”an array that increases then decreases. The key is to adapt the logic of binary search; by inspecting the local slope at the midpoint, you can decisively eliminate half of the search space in each step, achieving a logarithmic time complexity .",
            "id": "3228689",
            "problem": "You are given a finite sequence (array) of pairwise distinct integers that is strictly increasing up to a unique maximum and then strictly decreasing. Such an array is called bitonic. Formally, an array $A$ of length $n$ with $n \\ge 3$ is bitonic if there exists an index $k$ with $0 < k < n-1$ such that $A[0] < A[1] < \\cdots < A[k-1] < A[k]$ and $A[k] > A[k+1] > \\cdots > A[n-1]$. The index $k$ is the peak index. All indices are $0$-based. You must design and implement a divide and conquer (D&C) algorithm that returns the peak index $i$ in time $\\mathcal{O}(\\log n)$ using only comparisons between array elements and index arithmetic.\n\nYour derivation should start from fundamental bases appropriate to algorithms on sequences: (i) the total order property of integers under the usual comparison operators, (ii) the definition of a bitonic sequence as strictly increasing followed by strictly decreasing, and (iii) the paradigm of divide and conquer as recursively solving a problem by partitioning it into subproblems of smaller size until a base case is reached. Do not rely on any specialized shortcut formulas; rather, reason from these bases to obtain a correct and efficient algorithm.\n\nYour program must compute the peak index for each of the following test arrays. The arrays are guaranteed to be bitonic and to contain pairwise distinct integers.\n\n- Test $1$: $[1,3,8,12,4,2]$\n- Test $2$: $[2,5,1]$\n- Test $3$: $[10,22,35,40,90,80,20,5,3,1]$\n- Test $4$: $[-9,-4,-2,-3,-8]$\n- Test $5$: $[0,9,7,5,2]$\n- Test $6$: $[1,2,3,4,5,7,6]$\n\nFor each test, the required answer is the peak index $i$ (an integer). Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[i_1,i_2,\\dots,i_6]$) in the same order as the tests above. There are no physical units or angles involved in this problem; all answers are pure integers. The time complexity requirement is $\\mathcal{O}(\\log n)$ per test case, and your algorithm must be based on divide and conquer.",
            "solution": "The user has provided a well-defined computational problem.\n\n### Step 1: Extract Givens\n- **Input**: A finite sequence, represented as an array $A$, of pairwise distinct integers.\n- **Array Property**: The array $A$ is bitonic.\n- **Definition of Bitonic**: For an array $A$ of length $n$, where $n \\ge 3$, there exists a unique peak index $k$ such that $0 < k < n-1$, with the properties:\n    - $A[0] < A[1] < \\cdots < A[k-1] < A[k]$ (strictly increasing segment)\n    - $A[k] > A[k+1] > \\cdots > A[n-1]$ (strictly decreasing segment)\n- **Objective**: Design and implement a divide and conquer (D&C) algorithm to find the peak index $k$.\n- **Performance Requirement**: The algorithm must have a time complexity of $\\mathcal{O}(\\log n)$.\n- **Allowed Operations**: The algorithm may only use comparisons between array elements and index arithmetic.\n- **Derivation Constraint**: The solution must be derived from fundamental principles: (i) the total order property of integers, (ii) the definition of a bitonic sequence, and (iii) the divide and conquer paradigm.\n- **Test Data**: Six guaranteed bitonic arrays are provided for testing.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is rooted in the mathematical field of algorithm design and analysis. The concepts of arrays, integer ordering, time complexity, and divide and conquer are rigorously defined within computer science. The problem is factually sound.\n- **Well-Posedness**: The problem states that the input array is always bitonic and has a *unique* maximum. This ensures that a single, well-defined peak index exists for every valid input, making the problem well-posed. The constraints on complexity and methodology guide the solution design but do not make it unsolvable.\n- **Objectivity**: The problem is stated using precise, unambiguous terminology such as \"strictly increasing,\" \"pairwise distinct,\" and \"unique maximum.\" There are no subjective or opinion-based elements.\n- **Flaw Check**:\n    1.  **Scientific/Factual Unsoundness**: None. The problem adheres to established principles of mathematics and computer science.\n    2.  **Non-Formalizable/Irrelevant**: None. The problem is a classic example within the specified topic of *divide and conquer*.\n    3.  **Incomplete/Contradictory Setup**: None. The problem provides all necessary definitions and constraints. The condition $0 < k < n-1$ for the peak index is consistent with the provided test cases.\n    4.  **Unrealistic/Infeasible**: Not applicable. The problem is abstract and does not involve physical quantities.\n    5.  **Ill-Posed/Poorly Structured**: None. A unique solution is guaranteed to exist.\n    6.  **Pseudo-Profound/Trivial**: None. Designing an $\\mathcal{O}(\\log n)$ algorithm for this non-standard search problem requires non-trivial application of the divide and conquer principle.\n    7.  **Outside Scientific Verifiability**: None. The correctness and efficiency of the resulting algorithm can be formally proven.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived and presented.\n\n### Algorithmic Derivation and Solution\n\nThe objective is to find the unique peak index $k$ in a bitonic array $A$ of length $n$ in $\\mathcal{O}(\\log n)$ time. This time complexity requirement strongly suggests a strategy that recursively or iteratively halves the search space, which is the central idea of the divide and conquer paradigm.\n\n**1. Foundational Principles**\n\n- **Total Order of Integers**: The elements of the array are integers, which are totally ordered. For any two distinct elements $A[i]$ and $A[j]$, we can definitively determine if $A[i] < A[j]$ or $A[i] > A[j]$. This allows for comparison-based decisions.\n- **Bitonic Property**: The structure of the array is fundamental to the algorithm. For any index $i$ in the range $0 \\le i < n-1$, we can determine if we are on the increasing or decreasing part of the sequence by comparing $A[i]$ and $A[i+1]$.\n    - If $A[i] < A[i+1]$, the segment at $i$ is increasing.\n    - If $A[i] > A[i+1]$, the segment at $i$ is decreasing.\n    The peak $k$ is the unique index satisfying $A[k-1] < A[k]$ and $A[k] > A[k+1]$.\n- **Divide and Conquer (D&C)**: The D&C strategy consists of three steps:\n    - **Divide**: Divide the problem into smaller subproblems. For an array, this typically involves selecting a pivot or middle element and partitioning the array's index range.\n    - **Conquer**: Solve the subproblems recursively. If the subproblems are small enough (base case), solve them directly.\n    - **Combine**: The combination step is often trivial in search-related D&C problems, as the solution to one of the subproblems is the solution to the overall problem.\n\n**2. Algorithm Design**\n\nLet our search space be the index range $[l, r]$, initially $[0, n-1]$. The D&C strategy involves probing an index within this range to decide which sub-range must contain the peak. A natural choice for the probe is the middle index, $m = l + \\lfloor (r - l) / 2 \\rfloor$.\n\nBy examining the value $A[m]$ relative to its neighbors, we can reduce the search space. The problem guarantees $n \\ge 3$ and $0 < k < n-1$, meaning the peak is never at the first or last position. This simplifies the logic, as we can always access a neighbor to determine the slope. The most efficient approach requires only one comparison per step. Let's compare $A[m]$ with its right neighbor, $A[m+1]$. Note that the index $m+1$ is always valid within the loop because the loop condition $l < r$ ensures $m < r$. If $r$ is at most $n-1$, then $m+1$ is also at most $n-1$.\n\nWe have two mutually exclusive cases, since all elements are distinct:\n\n- **Case 1: $A[m] < A[m+1]$**\n  This condition signifies that we are on the strictly increasing slope of the bitonic array. The peak element, which is the maximum, cannot be $A[m]$ or any element to its left, as $A[m+1]$ is greater. Therefore, the peak must lie in the index range to the right of $m$. We can confidently discard the left half of the search space, including $m$, and continue our search in the new range $[m+1, r]$. This is achieved by setting $l = m+1$.\n\n- **Case 2: $A[m] > A[m+1]$**\n  This condition signifies that we are either at the peak itself or on the strictly decreasing slope of the array. In either scenario, the peak must be at index $m$ or an index to its left. It cannot be to the right of $m$, because the sequence from $m$ is decreasing, and the bitonic property precludes a second peak. We can therefore discard the right half of the search space (all indices greater than $m$) and continue our search in the new range $[l, m]$. This is achieved by setting $r = m$.\n\n**3. The Algorithm**\n\nThis logic leads to an iterative algorithm resembling a binary search:\n1. Initialize the search space with $l = 0$ and $r = n-1$.\n2. Loop while $l < r$. This condition ensures the search space contains at least two elements.\n3. In each iteration, calculate the middle index: $m = l + \\lfloor (r - l) / 2 \\rfloor$.\n4. Compare $A[m]$ with $A[m+1]$:\n   - If $A[m] < A[m+1]$, update the lower bound: $l = m+1$.\n   - If $A[m] > A[m+1]$, update the upper bound: $r = m$.\n5. The loop terminates when $l=r$. At this point, the search space has been narrowed down to a single index. This single index, $l$ (or $r$), is the peak index $k$. The loop invariant is that the peak is always contained within the current $[l, r]$ range.\n\n**4. Complexity Analysis**\n\n- **Time Complexity**: In each step of the while loop, the size of the search range, $r-l$, is reduced by approximately half. This process is identical to that of a binary search. The number of iterations is therefore proportional to $\\log_2 n$. Since each iteration performs a constant number of operations (a calculation, a comparison, and an assignment), the total time complexity is $\\mathcal{O}(\\log n)$.\n- **Space Complexity**: The iterative algorithm uses a constant amount of extra space for the variables $l$, $r$, and $m$. Thus, the space complexity is $\\mathcal{O}(1)$.\n\nThis derivation directly from first principles fulfills all requirements of the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_peak_index(arr: np.ndarray) -> int:\n    \"\"\"\n    Finds the peak index in a bitonic array using a divide and conquer approach.\n\n    Args:\n        arr: A numpy array of pairwise distinct integers that is guaranteed to be bitonic.\n             A bitonic array is strictly increasing and then strictly decreasing.\n             The array length is guaranteed to be >= 3.\n             The peak is guaranteed not to be at the first or last position.\n\n    Returns:\n        The index of the peak element.\n    \"\"\"\n    n = arr.shape[0]\n    # Initialize the search space to the entire array.\n    # The problem guarantees the peak is not at index 0 or n-1, but the general\n    # binary search formulation handles this correctly.\n    low, high = 0, n - 1\n\n    # The loop continues as long as the search space has more than one element.\n    # The loop invariant is that the peak is always within the [low, high] range.\n    while low < high:\n        # Calculate the middle index, avoiding potential overflow for very large arrays.\n        mid = low + (high - low) // 2\n        \n        # Compare the middle element with its right neighbor to determine if we\n        # are on the increasing or decreasing slope of the bitonic array.\n        if arr[mid] < arr[mid + 1]:\n            # We are on the increasing part. The peak must be to the right of mid.\n            # Discard the left half of the search space, including mid.\n            low = mid + 1\n        else:\n            # We are on the decreasing part (or at the peak itself).\n            # The peak must be at mid or to its left.\n            # Discard the right half of the search space.\n            # Note: We keep `mid` in the search space as it could be the peak.\n            high = mid\n            \n    # When the loop terminates, low == high, and this single index is the peak.\n    return low\n\ndef solve():\n    \"\"\"\n    Processes the test cases provided in the problem statement and prints the results.\n    \"\"\"\n    test_cases = [\n        np.array([1, 3, 8, 12, 4, 2]),\n        np.array([2, 5, 1]),\n        np.array([10, 22, 35, 40, 90, 80, 20, 5, 3, 1]),\n        np.array([-9, -4, -2, -3, -8]),\n        np.array([0, 9, 7, 5, 2]),\n        np.array([1, 2, 3, 4, 5, 7, 6]),\n    ]\n\n    results = []\n    for case in test_cases:\n        peak_index = find_peak_index(case)\n        results.append(peak_index)\n\n    # The final print statement must produce only the specified single-line format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The most elegant Divide and Conquer solutions often involve a conceptual leap in how the \"division\" is performed. This problem asks you to find the $k$-th smallest element in the union of two sorted arrays, a task that seems to require a full merge. However, a far more efficient solution exists by dividing the *rank* $k$ itself, using pivot comparisons to discard portions of the arrays and logarithmically narrowing the search for the correct element .",
            "id": "3228718",
            "problem": "You are given two finite sequences of integers $A$ and $B$ that are individually sorted in non-decreasing order under the standard total order $\\leq$ on the integers. Consider the multiset union of these two sequences, denoted as $U = A \\uplus B$, where multiplicities are preserved (for example, if an element appears $p$ times in $A$ and $q$ times in $B$, it appears $p+q$ times in $U$). For a given positive integer $k$, the task is to determine the $k$-th smallest element of $U$, where the indexing is $1$-based.\n\nThe foundational base for this problem comprises the following core definitions:\n- A total order on a set $S$ is a binary relation $\\leq$ that is reflexive, antisymmetric, transitive, and total. For the integers, the usual $\\leq$ relation holds.\n- A sequence $(x_1, x_2, \\dots, x_n)$ is sorted in non-decreasing order if for all indices $i$ and $j$ with $1 \\leq i < j \\leq n$, we have $x_i \\leq x_j$.\n- The multiset union $A \\uplus B$ of sequences $A$ and $B$ contains every element from $A$ and $B$ with multiplicity equal to the sum of their occurrences in $A$ and $B$.\n\nDesign and implement a program that, without merging $A$ and $B$ into a single array and without scanning linearly across all elements, uses a divide-and-conquer strategy to find the $k$-th smallest element of $U$. The algorithm must be based on recursive or iterative partitioning and comparisons that discard portions of $A$ or $B$ in a manner justified by the ordering properties of sorted sequences. Your method should achieve worst-case time complexity $\\mathcal{O}(\\log k)$ and use $\\mathcal{O}(1)$ additional space.\n\nIf $k < 1$ or $k > |A| + |B|$, where $|A|$ and $|B|$ denote the lengths of $A$ and $B$, respectively, your program must return $-1$ for that test case.\n\nYour program must not read any input. Instead, it must compute results for the following test suite of parameter values and produce a single line of output aggregating all results in order:\n\n- Test case $1$: $A = [1,3,5,7]$, $B = [2,4,6,8,10]$, $k = 5$.\n- Test case $2$: $A = [1,1,1]$, $B = [1,1]$, $k = 4$.\n- Test case $3$: $A = []$, $B = [3,4,5]$, $k = 2$.\n- Test case $4$: $A = [-5,-2,0,3]$, $B = []$, $k = 3$.\n- Test case $5$: $A = [0,2]$, $B = [1,3,5]$, $k = 5$.\n- Test case $6$: $A = [2]$, $B = [-1,0,1]$, $k = 1$.\n- Test case $7$: $A = [1,2]$, $B = [3]$, $k = 10$.\n- Test case $8$: $A = [1000000000]$, $B = [-1000000000,0]$, $k = 2$.\n- Test case $9$: $A = [-2,-2,-1]$, $B = [-2,-1,0]$, $k = 4$.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases (for example, $[r_1,r_2,\\dots,r_9]$), where each $r_i$ is an integer result for test case $i$.",
            "solution": "The problem asks for the $k$-th smallest element in the multiset union of two sorted integer sequences, $A$ and $B$, using a divide-and-conquer strategy with a required time complexity of $\\mathcal{O}(\\log k)$ and additional space complexity of $\\mathcal{O}(1)$.\n\nThe problem is well-posed and a classic in algorithm design. The constraints require a solution more efficient than a linear merge, which would be $\\mathcal{O}(k)$. The logarithmic complexity points towards a binary search-like approach on the rank $k$.\n\nThe fundamental principle is to discard a portion of the elements from consideration at each step, guaranteeing that the true $k$-th element is not among them. To achieve $\\mathcal{O}(\\log k)$ complexity, we must discard a constant fraction of the remaining $k$ elements to search for in each step. A robust method is to try to discard approximately $k/2$ elements.\n\nWe can implement the algorithm iteratively to meet the $\\mathcal{O}(1)$ space constraint. We maintain pointers, `a_start` and `b_start`, to the beginning of the currently relevant subsequences in $A$ and $B$.\n\n**1. Divide-and-Conquer Strategy**\n\n- **Divide**: The \"problem\" is finding an element of rank $k$. We divide this rank into two parts, $i = \\lfloor k/2 \\rfloor$ and $j = k - i$. We will use these to select two pivot elements, one from each array: $p_A = A[\\text{a\\_start} + i - 1]$ and $p_B = B[\\text{b\\_start} + j - 1]$. The goal is to use a comparison of $p_A$ and $p_B$ to discard a prefix from either $A$ or $B$.\n\n- **Conquer/Combine**: Based on the comparison, we reduce the search space.\n  - If $p_A \\leq p_B$: All elements in the prefix $A[\\text{a\\_start} \\dots \\text{a\\_start} + i - 1]$ are less than or equal to $p_A$, which in turn is less than or equal to $p_B$. The rank of $p_A$ in the combined sorted sequence is at most $((\\text{a\\_start}+i) + (\\text{b\\_start}+j-1)) - (\\text{a\\_start}+\\text{b\\_start}) = i+j-1=k-1$. This means no element in this prefix of $A$ can be the $k$-th smallest. We can safely discard these $i$ elements. The problem is reduced to finding the $(k-i)$-th element in the remaining subsequences. We update `a_start` by $i$ and $k$ by $-i$.\n  - If $p_A > p_B$: By symmetric reasoning, all elements in the prefix $B[\\text{b\\_start} \\dots \\text{b\\_start} + j - 1]$ come before the $k$-th element. We discard these $j$ elements by updating `b_start` by $j$ and $k$ by $-j$.\n\n**2. Handling Base Cases and Edge Cases**\n\n- **Initial Validation**: First, check if $1 \\leq k \\leq |A| + |B|$. If not, the request is invalid.\n- **Array Exhaustion**: If at any point one array is fully discarded (`a_start \\ge |A|` or `b_start \\ge |B|`), the $k$-th element must be in the remaining part of the other array. The answer is $B[\\text{b\\_start} + k - 1]$ or $A[\\text{a\\_start} + k - 1]$, respectively.\n- **k=1**: If we are looking for the 1st element, the answer is simply the minimum of the first elements of the current subsequences, $\\min(A[\\text{a\\_start}], B[\\text{b\\_start}])$.\n- **Index Out of Bounds**: The choice of pivots $A[\\text{a\\_start} + i - 1]$ and $B[\\text{b\\_start} + j - 1]$ must handle cases where the current subsequence is shorter than the number of elements we wish to take. If `a_start + i > |A|`, we must discard from $B$, and vice-versa. A simple way to handle this is to set the pivot value of the exhausted array to infinity, guaranteeing that the other array's prefix is discarded.\n\n**3. The Algorithm**\n\nThe iterative algorithm proceeds as follows:\n1.  Check if $k$ is valid. Return -1 if not.\n2.  Initialize `a_start = 0`, `b_start = 0`.\n3.  Loop as long as $k > 0$ (or use a `while True` loop with return statements).\n4.  Inside the loop, handle the base cases: array exhaustion and $k=1$.\n5.  Set `i = k // 2` and `j = k - i`.\n6.  Determine pivot indices `idx_a = a_start + i - 1` and `idx_b = b_start + j - 1`.\n7.  Check if `idx_a` is out of bounds for $A$. If so, it means all remaining elements in $A$ are candidates, but there are fewer than $i$ of them. This implies that the pivot from $B$, $p_B$, must come before the $k$-th element. So, discard $B$'s prefix. Symmetrically for $B$.\n8.  If both pivots are in bounds, compare them and discard the appropriate prefix as described above.\n\nThis process guarantees that in each step, we discard at least $\\lfloor k/2 \\rfloor$ elements (unless an array is exhausted, which is a base case), leading to the desired $\\mathcal{O}(\\log k)$ time complexity.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_kth(A, B, k_orig):\n    \"\"\"\n    Finds the k-th smallest element in the union of two sorted numpy arrays.\n\n    The algorithm uses a divide-and-conquer strategy with O(log k) time\n    complexity and O(1) extra space. It is iterative to meet the space constraint.\n    \"\"\"\n    m, n = len(A), len(B)\n    \n    # 1. Initial validation of k (1-based index)\n    if k_orig  1 or k_orig > m + n:\n        return -1\n\n    # Pointers to the start of the current considered slice of arrays\n    a_start, b_start = 0, 0\n    k = k_orig\n\n    while True:\n        # Get the lengths of the remaining parts of the arrays\n        m_curr = m - a_start\n        n_curr = n - b_start\n\n        # 2. Handle base cases\n        # If one array is exhausted, the k-th element is in the other.\n        if m_curr == 0:\n            return B[b_start + k - 1]\n        if n_curr == 0:\n            return A[a_start + k - 1]\n        \n        # If we are looking for the 1st element, it's the minimum of the two starts.\n        if k == 1:\n            return min(A[a_start], B[b_start])\n\n        # 3. Divide k and find pivot elements to compare.\n        # We aim to discard about k/2 elements.\n        i = min(k // 2, m_curr)\n        j = min(k - i, n_curr)\n\n        # Pivot indices (0-based)\n        idx_a = a_start + i - 1\n        idx_b = b_start + j - 1\n\n        # 4. Compare pivots and discard one prefix.\n        if A[idx_a] = B[idx_b]:\n            # The first i elements of A's current view are smaller than the k-th element.\n            # Discard them.\n            a_start += i\n            k -= i\n        else: # B[idx_b]  A[idx_a]\n            # The first j elements of B's current view are smaller than the k-th element.\n            # Discard them.\n            b_start += j\n            k -= j\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([1, 3, 5, 7]), np.array([2, 4, 6, 8, 10]), 5),\n        (np.array([1, 1, 1]), np.array([1, 1]), 4),\n        (np.array([], dtype=int), np.array([3, 4, 5]), 2),\n        (np.array([-5, -2, 0, 3]), np.array([], dtype=int), 3),\n        (np.array([0, 2]), np.array([1, 3, 5]), 5),\n        (np.array([2]), np.array([-1, 0, 1]), 1),\n        (np.array([1, 2]), np.array([3]), 10),\n        (np.array([1000000000]), np.array([-1000000000, 0]), 2),\n        (np.array([-2, -2, -1]), np.array([-2, -1, 0]), 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        A, B, k = case\n        # A simpler implementation of the correct logic\n        def find_kth_simple(A, B, k):\n            m, n = len(A), len(B)\n            if k  1 or k > m + n:\n                return -1\n\n            a_start, b_start = 0, 0\n            while True:\n                if a_start == m: return B[b_start + k - 1]\n                if b_start == n: return A[a_start + k - 1]\n                if k == 1: return min(A[a_start], B[b_start])\n\n                i = min(k // 2, m - a_start)\n                j = min(k // 2, n - b_start)\n                \n                # To guarantee progress, must take at least one element if k > 1\n                if k > 1 and i == 0: i = 1\n                if k > 1 and j == 0: j = 1\n\n                if A[a_start + i - 1]  B[b_start + j - 1]:\n                    a_start += i\n                    k -= i\n                else:\n                    b_start += j\n                    k -= j\n\n        # Using a corrected implementation that is guaranteed to be O(log k)\n        def find_kth_correct(A, B, k_orig):\n            m, n = len(A), len(B)\n            if k_orig  1 or k_orig > m + n:\n                return -1\n\n            a_start, b_start = 0, 0\n            k = k_orig\n            \n            while True:\n                if a_start >= m: return B[b_start + k - 1]\n                if b_start >= n: return A[a_start + k - 1]\n                if k == 1: return min(A[a_start], B[b_start])\n                \n                i = k // 2\n                j = k - i\n                \n                idx_a = a_start + i - 1\n                idx_b = b_start + j - 1\n\n                val_a = A[idx_a] if idx_a  m else float('inf')\n                val_b = B[idx_b] if idx_b  n else float('inf')\n                \n                if val_a  val_b:\n                    a_start += i\n                    k -= i\n                else:\n                    b_start += j\n                    k -= j\n\n        result = find_kth_correct(A, B, k)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}