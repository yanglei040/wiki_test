{
    "hands_on_practices": [
        {
            "introduction": "Dijkstra's algorithm for finding the shortest paths in a graph is a quintessential application of priority queues. While many textbook implementations rely on a priority queue with a `decrease-key` operation, this exercise  explores a more common and practical approach known as the \"lazy\" method. By allowing duplicate, lower-priority entries for a vertex to remain in the queue, we can achieve the same result using only basic `insert` and `extract-min` operations, highlighting a powerful and elegant implementation pattern.",
            "id": "3227995",
            "problem": "You are given a directed graph with nonnegative edge weights. Let the graph be denoted by $G = (V, E)$ with a weight function $w : E \\to \\mathbb{R}_{\\ge 0}$. For a vertex $s \\in V$, the single-source shortest-path distance to a vertex $v \\in V$ is defined as the minimum, over all directed paths from $s$ to $v$, of the sum of the weights of the edges on the path. If there is no path from $s$ to $v$, the distance is considered undefined.\n\nYour task is to write a complete program that computes the single-source shortest-path distances from a given source $s$ using a design that relies only on the core definitions of path length and nonnegativity of weights. Your program must implement the following algorithmic constraint: use a min-priority queue (Priority Queue (PQ)) that permits duplicate entries and does not provide or simulate a decrease-key operation. That is, when a shorter tentative distance to a vertex is discovered, instead of modifying an existing PQ entry, push a new entry into the PQ and allow stale entries to be removed lazily when they are popped.\n\nFormally, the program must:\n- Accept a graph described by its vertex count $n$ and a set of directed edges $\\{(u, v, w)\\}$ where $u, v \\in \\{0, 1, \\dots, n-1\\}$ and $w \\in \\mathbb{Z}_{\\ge 0}$.\n- Compute the shortest-path distance from the source $s$ to every vertex $v \\in \\{0, 1, \\dots, n-1\\}$ using only PQ push and pop operations, allowing duplicate keys and without any operation that decreases a key inside the PQ.\n- Output, for each test case, a list of $n$ integers where the $i$-th entry is the shortest-path distance from $s$ to $i$, with unreachable vertices encoded as $-1$.\n\nThe foundational base you must rely on is restricted to the following facts:\n- A path from a vertex $x$ to a vertex $y$ is a sequence of edges whose concatenation is valid in $G$, and the length of a path is the sum of its edge weights.\n- All edge weights satisfy $w(e) \\ge 0$ for every $e \\in E$.\n- For any vertices $x, y, z \\in V$, if a path from $x$ to $y$ has length $\\ell(x, y)$ and a path from $y$ to $z$ has length $\\ell(y, z)$, then the concatenated path from $x$ to $z$ has length $\\ell(x, y) + \\ell(y, z)$.\n- If a vertex is extracted from the PQ with a value strictly larger than its current best-known distance, that PQ entry must be stale and must be ignored.\n\nTest suite. Your program must solve the following seven test cases. For each, the graph is specified by an integer $n$, a source $s$, and a set of directed edges written as triples $(u, v, w)$:\n\n- Test case $1$: $n = 5$, $s = 0$, edges $\\{(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)\\}$.\n- Test case $2$: $n = 3$, $s = 0$, edges $\\{(0, 1, 0), (1, 2, 0), (0, 2, 5)\\}$.\n- Test case $3$: $n = 4$, $s = 0$, edges $\\{(0, 1, 7)\\}$.\n- Test case $4$: $n = 1$, $s = 0$, edges $\\{\\}$.\n- Test case $5$: $n = 3$, $s = 0$, edges $\\{(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)\\}$.\n- Test case $6$: $n = 6$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)\\}$.\n- Test case $7$: $n = 4$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)\\}$.\n\nAll edge weights in the test suite are integers and satisfy nonnegativity.\n\nFinal output format. Your program should produce a single line of output containing all results aggregated as a single list, where each element is the distance list for one test case, in the order listed above. The aggregation must be printed as a single comma-separated list enclosed in square brackets and without spaces. For example, if there were two test cases with per-case results $[0, 1]$ and $[0, 2]$, the final output would be $[[0,1],[0,2]]$. In your program’s final output, use $-1$ to denote unreachable vertices. No physical units are involved in this problem; all quantities are pure numbers.",
            "solution": "The user has provided a problem statement that requires the computation of single-source shortest paths in a directed graph with non-negative edge weights. The core constraint is the implementation of an algorithm, equivalent to Dijkstra's, using a min-priority queue that does not support a `decrease-key` operation, thereby necessitating the handling of stale entries.\n\n### Step 1: Extract Givens\n\n-   **Graph**: A directed graph $G = (V, E)$, where $V = \\{0, 1, \\dots, n-1\\}$.\n-   **Edge Weights**: A function $w : E \\to \\mathbb{R}_{\\ge 0}$ assigns a non-negative weight to each edge. For the test cases, $w(e) \\in \\mathbb{Z}_{\\ge 0}$.\n-   **Source Vertex**: A specified vertex $s \\in V$.\n-   **Shortest-Path Distance**: The minimum sum of weights over all directed paths from $s$ to any vertex $v \\in V$. Unreachable vertices have an undefined distance.\n-   **Algorithmic Constraint 1**: The implementation must use a min-priority queue (PQ) that only supports `push` and `pop` operations.\n-   **Algorithmic Constraint 2**: A `decrease-key` operation is forbidden. If a shorter path to a vertex is found, a new entry `(distance, vertex)` must be pushed into the PQ, allowing for duplicate vertex entries.\n-   **Algorithmic Constraint 3**: Stale entries must be handled lazily. An entry `(d, u)` popped from the PQ is stale if $d$ is strictly greater than the currently known shortest distance to $u$. Such entries must be ignored.\n-   **Output Specification**: For each test case, the output must be a list of $n$ integers representing the shortest distances from $s$. Unreachable vertices must be encoded as $-1$. The final output is an aggregation of these lists.\n-   **Provided Foundational Facts**:\n    1.  The definitions of a path and its length (sum of edge weights).\n    2.  The non-negativity of edge weights: $w(e) \\ge 0$ for all $e \\in E$.\n    3.  The optimal substructure property related to path concatenation: the length of a concatenated path is the sum of the lengths of its subpaths.\n    4.  The specific rule for identifying and ignoring stale entries in the PQ.\n-   **Test Suite**:\n    -   Test case $1$: $n = 5$, $s = 0$, edges $\\{(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)\\}$.\n    -   Test case $2$: $n = 3$, $s = 0$, edges $\\{(0, 1, 0), (1, 2, 0), (0, 2, 5)\\}$.\n    -   Test case $3$: $n = 4$, $s = 0$, edges $\\{(0, 1, 7)\\}$.\n    -   Test case $4$: $n = 1$, $s = 0$, edges $\\{\\}$.\n    -   Test case $5$: $n = 3$, $s = 0$, edges $\\{(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)\\}$.\n    -   Test case $6$: $n = 6$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)\\}$.\n    -   Test case $7$: $n = 4$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)\\}$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to rigorous validation.\n\n-   **Scientifically Grounded**: The problem describes a standard variation of Dijkstra's algorithm. The algorithm's correctness for graphs with non-negative edge weights is a cornerstone of graph theory and computer science. The specified implementation detail—handling the absence of a `decrease-key` operation by inserting duplicates and lazily discarding stale entries—is a well-established and correct technique. This is scientifically and algorithmically sound.\n-   **Well-Posed**: The problem is well-posed. For a given graph with non-negative weights and a source vertex, the set of single-source shortest-path distances is uniquely defined. The constraints on the algorithm are precise, leading to a deterministic outcome.\n-   **Objective**: The problem is stated using formal mathematical notation and unambiguous terminology. It is free from subjective or opinion-based content.\n-   **Self-Contained and Consistent**: The problem provides all necessary data for each test case ($n$, $s$, and the edge set). The constraints are explicit and not contradictory. The foundational facts provided are correct and consistent with the principles underlying the algorithm.\n-   **Formalizable and Relevant**: The problem is directly an implementation task for a core algorithm, Dijkstra's algorithm, within the specified topic. It is perfectly suited for formalization into a program.\n-   **Complete and Unambiguous**: The vertex and edge specifications are complete. The output format is precisely defined. Terms like \"shortest-path distance\" and \"nonnegative\" are standard and unambiguous.\n-   **Non-Trivial**: The problem is not trivial. It requires a correct implementation of a non-trivial algorithm, including careful management of the priority queue state according to the specified constraints.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a well-defined, scientifically sound problem in the field of algorithms. I will now proceed to construct the solution.\n\nThe algorithm to be implemented is a variant of Dijkstra's algorithm. Let $d[v]$ be the tentative shortest distance from the source $s$ to a vertex $v$.\n\n1.  **Initialization**: An array $d$ of size $n$ is initialized to store the shortest-path estimates. We set $d[s] = 0$ and $d[v] = \\infty$ for all other vertices $v \\in V \\setminus \\{s\\}$. The value $\\infty$ signifies that no path from $s$ to $v$ has been discovered yet. A min-priority queue, PQ, is initialized. The PQ will store tuples of the form `(distance, vertex)`. We begin by inserting the source vertex into the PQ: `PQ.push((0, s))`.\n\n2.  **Iterative Processing**: The algorithm proceeds by repeatedly extracting the vertex with the minimum distance from the PQ. As long as the PQ is not empty, we perform the following steps:\n    a. Extract the entry $(dist_u, u)$ with the smallest $dist_u$ from the PQ.\n    b. **Stale Entry Check**: This is the critical step dictated by the problem constraints. We compare the extracted distance $dist_u$ with the current best-known distance to $u$, which is $d[u]$. If $dist_u > d[u]$, it implies that we have already found a shorter path to $u$ and have processed it in a previous iteration. The entry $(dist_u, u)$ is therefore \"stale\" and must be discarded. We then continue to the next iteration of the loop.\n    c. **Vertex Finalization and Relaxation**: If $dist_u \\le d[u]$ (which must be $dist_u = d[u]$ due to the properties of the algorithm and the stale check), it means we have found the shortest path to $u$. The non-negativity of edge weights ensures that any other path to $u$ not yet discovered must pass through some other vertex currently in the PQ, which by definition has a tentative distance greater than or equal to $d[u]$. Thus, no shorter path is possible. We then \"relax\" the edges originating from $u$. For each neighbor $v$ of $u$ connected by an edge $(u, v)$ with weight $w(u, v)$, we calculate a new potential distance to $v$ through $u$: $d[u] + w(u, v)$.\n    d. **Path Improvement**: If this new path is shorter than the current best-known path to $v$ (i.e., if $d[u] + w(u, v)  d[v]$), we have found an improvement. We update the distance array: $d[v] = d[u] + w(u, v)$. Crucially, instead of performing a `decrease-key` operation on $v$ in the PQ, we simply insert the new, improved entry $(d[v], v)$ into the PQ. This is the source of the duplicate entries.\n\n3.  **Termination**: The loop terminates when the PQ becomes empty. At this point, for every vertex $v$, the value $d[v]$ is the length of the shortest path from $s$ to $v$. If $d[v]$ remains $\\infty$, it means $v$ is unreachable from $s$.\n\n4.  **Final Output Formatting**: The final distance array $d$ is processed to replace any remaining $\\infty$ values with $-1$ to conform to the output specification. The results for all test cases are then aggregated into the required string format. For the implementation, the Python `heapq` module serves as an ideal min-priority queue, as it naturally accommodates duplicate entries and lacks a `decrease-key` method.\n\nThis procedure correctly computes the single-source shortest paths under the specified constraints, relying on the fundamental properties of non-negative edge weights and the greedy choice made by extracting the minimum-distance vertex from the priority queue.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Solves the single-source shortest path problem for a series of test cases\n    using a Dijkstra-like algorithm with a priority queue that allows duplicates\n    and has no decrease-key operation.\n    \"\"\"\n    \n    test_cases = [\n        {'n': 5, 's': 0, 'edges': [(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)]},\n        {'n': 3, 's': 0, 'edges': [(0, 1, 0), (1, 2, 0), (0, 2, 5)]},\n        {'n': 4, 's': 0, 'edges': [(0, 1, 7)]},\n        {'n': 1, 's': 0, 'edges': []},\n        {'n': 3, 's': 0, 'edges': [(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)]},\n        {'n': 6, 's': 0, 'edges': [(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)]},\n        {'n': 4, 's': 0, 'edges': [(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)]}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n = case['n']\n        s = case['s']\n        edges = case['edges']\n        \n        # Adjacency list representation of the graph\n        adj = [[] for _ in range(n)]\n        for u, v, w in edges:\n            adj[u].append((v, w))\n            \n        # Initialize distances: 0 for the source, infinity for all others.\n        # np.inf is used to represent infinite distance.\n        distances = np.full(n, np.inf)\n        distances[s] = 0\n        \n        # Min-priority queue storing tuples of (distance, vertex).\n        # We start with the source vertex.\n        pq = [(0, s)]\n        \n        while pq:\n            # Pop the vertex with the smallest tentative distance\n            dist_u, u = heapq.heappop(pq)\n            \n            # If the popped distance is greater than the known shortest distance,\n            # this is a stale entry. We ignore it and proceed.\n            if dist_u > distances[u]:\n                continue\n            \n            # Relax edges for the current vertex u\n            for v, weight in adj[u]:\n                # If we found a shorter path to v through u\n                if distances[u] + weight  distances[v]:\n                    # Update the distance to v\n                    distances[v] = distances[u] + weight\n                    # Push the new, better path information to the priority queue.\n                    # This may create duplicate entries for vertex v, as required.\n                    heapq.heappush(pq, (distances[v], v))\n                    \n        # Prepare the final result list for this test case.\n        # Replace np.inf with -1 for unreachable vertices.\n        # Convert all distances to integers.\n        result = [int(d) if d != np.inf else -1 for d in distances]\n        all_results.append(result)\n\n    # Format the final output string as specified in the problem.\n    # e.g., [[0,1,2],[0,-1]]\n    str_results = []\n    for res in all_results:\n        str_results.append(f\"[{','.join(map(str, res))}]\")\n    \n    final_output_string = f\"[{','.join(str_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "Having seen how a priority queue is used in an algorithm like Dijkstra's, we now turn our attention to building a more powerful version from the ground up. This practice  challenges you to design and implement an Indexed Priority Queue (IPQ) that directly supports `decrease-key` and `delete` operations in $O(\\log n)$ time. You will develop a robust handle-based system to reference elements, providing a deeper understanding of the internal mechanics required for the \"eager\" variant of many graph algorithms.",
            "id": "3261051",
            "problem": "Design and implement an Indexed Priority Queue (IPQ) with a binary heap that supports the operations `insert`, `decrease-key` by handle, `delete` by handle, and `extract-min`. Propose a robust handle scheme and rigorously justify that all operations execute in $O(\\log n)$ worst-case time, where $n$ is the current number of elements in the IPQ. The IPQ must maintain the heap-order invariant on keys and use an array-based complete binary tree representation to ensure the shape invariant. For deterministic behavior in the presence of equal keys, ties must be broken using immutable identifiers.\n\nFundamental basis to be used for the derivation and design:\n- A binary heap is a complete binary tree that satisfies the heap-order property on keys.\n- An array-backed complete binary tree of size $n$ has height $h = \\lfloor \\log_2 n \\rfloor$, and any path from a node to the root or to a leaf has length at most $h$.\n- Bubble-up (also called sift-up) adjusts a node upward by repeatedly comparing with its parent and swapping while the heap-order property is violated; bubble-down (also called sift-down) adjusts a node downward by repeatedly comparing with its minimal child and swapping while the heap-order property is violated.\n\nHandle scheme requirement:\n- The handle returned by `insert` must be a robust token that remains valid for the life of the specific element and becomes invalid immediately upon `delete` of that element.\n- The handle must prevent the \"ABA problem\" where a stale handle could accidentally refer to a newly inserted element that reuses an internal identifier.\n- Any operation presented with a stale or invalid handle must be rejected without mutating the IPQ.\n\nOperation semantics:\n- `insert(k)` inserts a key $k$ and returns a handle $h$ for the inserted element.\n- `decrease-key(h, k')` decreases the key associated with handle $h$ to a new key $k'$ under the precondition $k'  k$; if the handle is invalid or the precondition fails, the operation must be rejected.\n- `delete(h)` deletes the element associated with handle $h$; if the handle is invalid, the operation must be rejected.\n- `extract-min()` removes and returns the minimum key currently in the IPQ.\n\nValidation and complexity justification:\n- You must implement instrumentation that records the number of heap index movements performed by bubble-up or bubble-down during each operation. An index movement is defined as any swap that relocates an element from index $i$ to a different index $j$ in the heap array. Use this instrumentation to report per-test-case summary values as specified below. This instrumentation is required only for reporting; it must not change the asymptotic complexity of the implemented operations.\n\nRobust handle scheme to be implemented:\n- Each element has an immutable identifier $i \\in \\mathbb{N}$ assigned at insertion and never reused for another element.\n- Maintain a generation counter $g_i \\in \\mathbb{N}$ per identifier. The current valid handle for an element is the pair $(i, g_i)$ at the time of insertion. When the element is deleted, increment $g_i$ by $1$, which invalidates any previously issued handle for that identifier. Validity checks must ensure that a presented handle $(i, g)$ is accepted only if $g = g_i$ and the identifier $i$ is currently present in the heap (i.e., has a mapped position).\n- This $(i, g_i)$ scheme must be used in `decrease-key` and `delete` to ensure robustness against stale handles.\n\nTest suite and required outputs:\n- Test Case $1$ (general case): Insert the keys $A_1 = [\\,7,\\,3,\\,5,\\,2,\\,9,\\,1,\\,4\\,]$ in that order, collect the returned handles in the same order. Then perform `decrease-key` on the handle corresponding to the third insertion (original key $5$) to the new key $0$. Then perform `delete` on the handle corresponding to the first insertion (original key $7$). Finally, repeatedly call `extract-min` until the IPQ is empty, and record the list of extracted keys. The expected output for this test is the list of integers representing the extracted keys in ascending order after these operations.\n- Test Case $2$ (height-bound stress): Insert the keys $A_2 = [\\,10,\\,8,\\,6,\\,4,\\,2\\,]$ in that order. Perform `decrease-key` on the handle corresponding to the last insertion (original key $2$) to the new key $-100$. Then perform `delete` on the handle corresponding to the second insertion (original key $8$). During this test, record the maximum number of heap index movements made by any single bubble-up or bubble-down across all operations in this test case. The expected output for this test is a single integer equal to this maximum.\n- Test Case $3$ (stale handle and repeated decreases): Insert the single key $A_3 = [\\,50\\,]$ and capture the handle $h_0$. Perform `decrease-key(h_0, 20)`, then `decrease-key(h_0, 10)`, then `decrease-key(h_0, 5)`. Then perform `delete(h_0)`. Finally, attempt `decrease-key(h_0, 1)` and record whether the operation is rejected due to the handle being stale. The expected output for this test is a boolean indicating whether the stale handle was correctly rejected.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, specifically $[R_1, R_2, R_3]$, where $R_1$ is the list from Test Case $1$, $R_2$ is the integer from Test Case $2$, and $R_3$ is the boolean from Test Case $3$.\n- The program must be self-contained, require no input, and use Python version $3.12$ with only the Python standard library and the library Numerical Python (NumPy) version $1.23.5$.\n\nScientific realism and constraints:\n- All keys are integers and all operations must adhere to the described semantics.\n- Complexity claims must be justified from the properties of complete binary trees and the heap-order invariant, starting from the fundamental basis given above, without relying on unproven shortcuts or external references.",
            "solution": "The design and implementation of a robust Indexed Priority Queue (IPQ) must be grounded in the established principles of binary heaps and augmented with data structures to support efficient indexed operations. We will construct the IPQ by combining a binary heap with auxiliary mappings for position tracking and a generation-based scheme for robust handle management.\n\n### Data Structures\n\nThe IPQ is realized through four primary components:\n\n$1$. **The Heap Array, $\\mathcal{H}$**: A dynamic array representing a complete binary tree. For algebraic convenience, we use $1$-based indexing, where the element at index $j > 0$ has its parent at index $\\lfloor j/2 \\rfloor$ and its children at indices $2j$ and $2j+1$. Each entry in $\\mathcal{H}$ is a tuple $(k, i)$, where $k$ is the priority key (an integer) and $i$ is a unique, immutable identifier from $\\mathbb{N}$. The heap-order property is maintained on these tuples, where $(k_1, i_1)  (k_2, i_2)$ if $k_1  k_2$, or if $k_1 = k_2$ and $i_1  i_2$. This establishes a deterministic total ordering.\n\n$2$. **The Position Map, $\\mathcal{P}$**: A hash map that provides a bidirectional link between an element's identifier and its location in the heap. It maps an identifier $i$ to its current index $j$ in $\\mathcal{H}$, i.e., $\\mathcal{P}[i] = j$. This structure is critical for achieving $O(1)$ time access to an element for the `decrease-key` and `delete` operations.\n\n$3$. **The Generation Map, $\\mathcal{G}$**: A hash map that stores the current generation counter for each identifier that has ever been inserted into the IPQ. It maps an identifier $i$ to its generation $g_i \\in \\mathbb{N}$, i.e., $\\mathcal{G}[i] = g_i$.\n\n$4$. **The Identifier Counter, $N_{id}$**: A monotonically increasing integer counter used to dispense fresh, unique identifiers for new elements, ensuring no identifier is ever reused.\n\n### The Robust Handle Scheme\n\nA handle $h$ provides an external reference to an element within the IPQ. To ensure robustness against accidental misuse of stale handles (e.g., the \"ABA problem\"), a handle is defined as a pair $h = (i, g)$, where $i$ is the element's unique identifier and $g$ is the generation count of that identifier at the moment the handle was issued (i.e., upon insertion).\n\nAn operation invoked with a handle $h=(i, g)$ is considered valid if and only if two conditions are met simultaneously:\n- The identifier $i$ is present in the position map $\\mathcal{P}$, meaning the element is currently in the heap.\n- The generation $g$ provided in the handle matches the current generation $g_i$ stored in the generation map $\\mathcal{G}$.\n\nWhen an element with identifier $i$ is removed from the heap (via `delete` or `extract-min`), its entry is removed from $\\mathcal{P}$, and its generation counter $\\mathcal{G}[i]$ is incremented. This dual action immediately invalidates all previously issued handles for this element, as they will now fail one or both of the validity conditions. Any subsequent operation attempting to use a stale handle $(i, g)$ will be rejected.\n\n### Algorithmic Design and Complexity Analysis\n\nAll operations must maintain the heap invariants: the shape property (the heap is a complete binary tree) and the heap-order property. The shape property is maintained by adding/removing elements only at the end of the array. The heap-order property is restored using two fundamental procedures, `bubble-up` and `bubble-down`, each operating along a path in the heap. Since the heap is a complete binary tree of size $n$, its height is $h_{heap} = \\lfloor \\log_2 n \\rfloor$. The complexity of both restoration procedures is therefore bounded by the height of the tree, resulting in $O(\\log n)$ performance.\n\n**`insert(k)`**\n$1$. A new unique identifier $i$ is drawn from $N_{id}$, which is then incremented.\n$2$. The element's initial generation is recorded: $\\mathcal{G}[i] \\leftarrow 0$. A handle $h = (i, 0)$ is created.\n$3$. The new element $(k, i)$ is appended to the end of the heap array $\\mathcal{H}$, at index $j=n+1$.\n$4$. The position map is updated: $\\mathcal{P}[i] \\leftarrow j$.\n$5$. The `bubble-up(j)` procedure is called to move the element up the tree until the heap-order property is restored. This involves at most $\\lfloor \\log_2 n \\rfloor$ comparisons and swaps.\n$6$. The handle $h$ is returned.\n**Complexity**: Steps $1-4$ are $O(1)$. Step $5$, `bubble-up`, has a worst-case complexity of $O(\\log n)$. Thus, `insert` is $O(\\log n)$.\n\n**`extract-min()`**\n$1$. The minimum element $(k_{min}, i_{min})$ at the root of the heap, $\\mathcal{H}[1]$, is identified.\n$2$. The last element in the heap, $(k_{last}, i_{last})$ at index $n$, is moved to the root: $\\mathcal{H}[1] \\leftarrow (k_{last}, i_{last})$.\n$3$. The position map for the moved element is updated: $\\mathcal{P}[i_{last}] \\leftarrow 1$.\n$4$. The heap size is decremented, effectively removing the old last element's position.\n$5$. The identifier $i_{min}$ of the extracted element is removed from the position map $\\mathcal{P}$, and its generation is incremented in $\\mathcal{G}$: $\\mathcal{G}[i_{min}] \\leftarrow \\mathcal{G}[i_{min}] + 1$.\n$6$. The `bubble-down(1)` procedure is called to move the element now at the root down the tree to its correct position, restoring the heap-order property. This involves at most $O(\\log n)$ comparisons and swaps.\n$7$. The key $k_{min}$ is returned.\n**Complexity**: All steps are $O(1)$ except for `bubble-down`, which is $O(\\log n)$. Thus, `extract-min` is $O(\\log n)$.\n\n**`decrease-key(h, k')`**\n$1$. The handle $h=(i, g)$ is validated as described previously. If invalid, the operation is rejected.\n$2$. The element's current position $j$ is retrieved from $\\mathcal{P}[i]$ in $O(1)$ time.\n$3$. The precondition $k'  \\mathcal{H}[j].key$ is verified. If it fails, the operation is rejected.\n$4$. The key of the element at $\\mathcal{H}[j]$ is updated to $k'$.\n$5$. As the key has decreased, the heap-order property may be violated with the element's parent. The `bubble-up(j)` procedure is called to restore the invariant.\n**Complexity**: Handle validation, position lookup, and key update are $O(1)$. The dominant cost is `bubble-up`, which is $O(\\log n)$.\n\n**`delete(h)`**\n$1$. The handle $h=(i, g)$ is validated. If invalid, the operation is rejected.\n$2$. The element's current position $j$ is retrieved from $\\mathcal{P}[i]$ in $O(1)$ time.\n$3$. The element to be deleted at index $j$ is swapped with the last element in the heap at index $n$. The position map $\\mathcal{P}$ is updated for the swapped-in element.\n$4$. The heap size is decremented. The entry for identifier $i$ is removed from $\\mathcal{P}$, and its generation $\\mathcal{G}[i]$ is incremented.\n$5$. The element that was moved from index $n$ to index $j$ may violate the heap-order property. We compare it with its parent. If it is smaller than its parent, `bubble-up(j)` is performed. Otherwise, `bubble-down(j)` is performed. Only one of these procedures will perform any work.\n**Complexity**: All steps are $O(1)$ except for the final heap restoration. Both `bubble-up` and `bubble-down` are $O(\\log n)$, so the complexity of `delete` is $O(\\log n)$.\n\n**Instrumentation**\nTo satisfy the validation requirement, a counter is maintained for each high-level operation. This counter is incremented by $1$ for each swap of two elements in the heap array $\\mathcal{H}$. The maximum count observed across all operations in a given test case is recorded. This instrumentation adds a constant overhead to the swap operation and does not alter the asymptotic complexity.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass IndexedPriorityQueue:\n    \"\"\"\n    An Indexed Priority Queue (IPQ) implemented with a binary heap.\n\n    This IPQ supports insert, extract-min, decrease-key by handle, and\n    delete by handle, all in O(log n) time. It uses a robust handle\n    scheme based on unique identifiers and generation counters to prevent\n    issues with stale handles.\n\n    The heap is 1-indexed for simpler parent/child arithmetic.\n    - parent(i) = i // 2\n    - left_child(i) = 2 * i\n    - right_child(i) = 2 * i + 1\n    \"\"\"\n\n    def __init__(self):\n        # self.heap stores tuples of (key, identifier).\n        # Index 0 is a placeholder to enable 1-based indexing.\n        self.heap = [None]\n        # self.pos maps an identifier to its index in the heap array.\n        self.pos = {}\n        # self.gen maps an identifier to its generation counter.\n        self.gen = {}\n        # self.next_id is a counter for assigning new unique identifiers.\n        self.next_id = 0\n        # Instrumentation: tracks max movements for any single operation.\n        self.max_movements_per_op = 0\n        self._current_op_movements = 0\n\n    def is_empty(self):\n        return len(self.heap) == 1\n\n    def _swap(self, i, j):\n        \"\"\"Swaps elements at heap indices i and j, updating position map.\"\"\"\n        h = self.heap\n        p = self.pos\n        h[i], h[j] = h[j], h[i]\n        p[h[i][1]] = i\n        p[h[j][1]] = j\n        self._current_op_movements += 1\n\n    def _compare(self, i, j):\n        \"\"\"\n        Compares elements at heap indices i and j.\n        Uses (key, identifier) for deterministic tie-breaking.\n        Returns True if element at i is smaller than element at j.\n        \"\"\"\n        return self.heap[i]  self.heap[j]\n\n    def _bubble_up(self, i):\n        \"\"\"Restores heap property by moving element at index i up.\"\"\"\n        parent = i // 2\n        while i > 1 and self._compare(i, parent):\n            self._swap(i, parent)\n            i = parent\n            parent = i // 2\n\n    def _bubble_down(self, i):\n        \"\"\"Restores heap property by moving element at index i down.\"\"\"\n        size = len(self.heap)\n        while 2 * i  size:\n            left = 2 * i\n            right = 2 * i + 1\n            smallest = left\n            if right  size and self._compare(right, left):\n                smallest = right\n                \n            if self._compare(smallest, i):\n                self._swap(i, smallest)\n                i = smallest\n            else:\n                break\n\n    def _start_op(self):\n        \"\"\"Resets the movement counter for a new operation.\"\"\"\n        self._current_op_movements = 0\n\n    def _end_op(self):\n        \"\"\"Updates the max movement counter at the end of an operation.\"\"\"\n        self.max_movements_per_op = max(self.max_movements_per_op, self._current_op_movements)\n\n    def _validate_handle(self, handle):\n        \"\"\"Validates a handle (identifier, generation).\"\"\"\n        identifier, generation = handle\n        return identifier in self.pos and self.gen.get(identifier) == generation\n\n    def insert(self, key):\n        \"\"\"\n        Inserts a key, returns a robust handle. Complexity: O(log n).\n        \"\"\"\n        self._start_op()\n        identifier = self.next_id\n        self.next_id += 1\n        \n        # This is the first time we see this identifier\n        self.gen[identifier] = 0\n        handle = (identifier, self.gen[identifier])\n\n        self.heap.append((key, identifier))\n        new_pos = len(self.heap) - 1\n        self.pos[identifier] = new_pos\n        \n        self._bubble_up(new_pos)\n        self._end_op()\n        return handle\n\n    def extract_min(self):\n        \"\"\"\n        Removes and returns the minimum key. Complexity: O(log n).\n        \"\"\"\n        if self.is_empty():\n            raise IndexError(\"extract_min from an empty priority queue\")\n        \n        self._start_op()\n        min_key, min_id = self.heap[1]\n        last_item = self.heap.pop()\n        \n        if not self.is_empty():\n            self.heap[1] = last_item\n            self.pos[last_item[1]] = 1\n            self._bubble_down(1)\n        \n        del self.pos[min_id]\n        self.gen[min_id] += 1\n        \n        self._end_op()\n        return min_key\n\n    def decrease_key(self, handle, new_key):\n        \"\"\"\n        Decreases the key of an element specified by a handle.\n        Complexity: O(log n). Returns True on success, False on failure.\n        \"\"\"\n        if not self._validate_handle(handle):\n            return False\n\n        self._start_op()\n        identifier, _ = handle\n        current_pos = self.pos[identifier]\n        current_key, _ = self.heap[current_pos]\n\n        if new_key >= current_key:\n            # Precondition k'  k failed, do not count movements\n            self._current_op_movements = 0\n            self._end_op() \n            return False\n\n        self.heap[current_pos] = (new_key, identifier)\n        self._bubble_up(current_pos)\n        self._end_op()\n        return True\n\n    def delete(self, handle):\n        \"\"\"\n        Deletes an element specified by a handle. Complexity: O(log n).\n        Returns True on success, False on failure.\n        \"\"\"\n        if not self._validate_handle(handle):\n            return False\n\n        self._start_op()\n        identifier, _ = handle\n        pos_to_delete = self.pos[identifier]\n        \n        # Swap with the last element\n        last_pos = len(self.heap) - 1\n        self._swap(pos_to_delete, last_pos) # This counts as 1 movement\n        \n        # Pop the target element (which is now at the end)\n        deleted_key, deleted_id = self.heap.pop()\n        del self.pos[deleted_id]\n        self.gen[deleted_id] += 1\n\n        # If the heap is now empty or we deleted the last element, we are done.\n        if not self.is_empty() and pos_to_delete = len(self.heap) - 1:\n            # The swapped-in element might need to be moved up or down.\n            # A bubble_up will only occur if the element is smaller than its parent.\n            # Otherwise, a bubble_down might be needed.\n            item_key, _ = self.heap[pos_to_delete]\n            parent_pos = pos_to_delete // 2\n\n            # If it's not the root and smaller than its parent, bubble up.\n            if parent_pos > 0 and self._compare(pos_to_delete, parent_pos):\n                self._bubble_up(pos_to_delete)\n            else: # Otherwise, it might need to bubble down.\n                self._bubble_down(pos_to_delete)\n\n            self._end_op()\n            return True\n\n    results = []\n\n    # --- Test Case 1 ---\n    ipq1 = IndexedPriorityQueue()\n    handles1 = []\n    keys1 = [7, 3, 5, 2, 9, 1, 4]\n    for k in keys1:\n        handles1.append(ipq1.insert(k))\n\n    ipq1.decrease_key(handles1[2], 0)  # Decrease key of 5 to 0\n    ipq1.delete(handles1[0])          # Delete key 7\n    \n    extracted_keys = []\n    while not ipq1.is_empty():\n        extracted_keys.append(ipq1.extract_min())\n    results.append(extracted_keys)\n\n    # --- Test Case 2 ---\n    ipq2 = IndexedPriorityQueue()\n    handles2 = []\n    keys2 = [10, 8, 6, 4, 2]\n    for k in keys2:\n        handles2.append(ipq2.insert(k))\n    \n    ipq2.decrease_key(handles2[4], -100) # Decrease key of 2 to -100\n    ipq2.delete(handles2[1])           # Delete key 8\n\n    results.append(ipq2.max_movements_per_op)\n\n    # --- Test Case 3 ---\n    ipq3 = IndexedPriorityQueue()\n    h0 = ipq3.insert(50)\n    ipq3.decrease_key(h0, 20)\n    ipq3.decrease_key(h0, 10)\n    ipq3.decrease_key(h0, 5)\n    ipq3.delete(h0)\n    \n    # Attempt to use the stale handle, expecting rejection.\n    # decrease_key returns False on rejection.\n    is_rejected = not ipq3.decrease_key(h0, 1)\n    results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    # We need to manually format the list R1 to avoid spaces.\n    r1_str = f\"[{','.join(map(str, results[0]))}]\"\n    print(f\"[{r1_str},{results[1]},{str(results[2]).lower()}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A standard priority queue efficiently provides access to an extremum—either the minimum or the maximum element. This exercise  pushes the boundaries of the ADT by asking you to design a structure that supports fast extraction of *both* the minimum and maximum elements. To solve this, you will learn how to compose two separate heaps, a min-heap and a max-heap, and synchronize them, demonstrating a key principle in data structure design: combining simpler components to create more powerful tools.",
            "id": "3261069",
            "problem": "You must design and implement a double-ended priority queue as an Abstract Data Type (ADT) that supports both minimum and maximum operations with logarithmic runtime per update. The foundational base is the following set of definitions and well-tested facts: a priority queue supports insertion and removal of an element with highest or lowest priority; a binary heap is a complete binary tree with a heap-order invariant; the height of a complete binary tree with $n$ nodes is $\\lfloor \\log_2 n \\rfloor$. You must derive a data structure and its algorithms from these fundamentals so that both a minimum element and a maximum element can be extracted efficiently.\n\nRequirements:\n- Implement a double-ended priority queue that supports the following operations on a multiset of integers:\n  - `insert(x)`: insert integer $x$.\n  - `extract-min()`: remove and return the smallest element.\n  - `extract-max()`: remove and return the largest element.\n  - `peek-min()`: return the smallest element without removing it.\n  - `peek-max()`: return the largest element without removing it.\n  - `size()`: return the current number of elements.\n  - `is_empty()`: return a boolean indicating whether there are zero elements.\n- All update operations `insert`, `extract-min`, and `extract-max` must run in $O(\\log n)$ time, where $n$ is the number of elements currently stored. Query operations `peek-min`, `peek-max`, `size`, and `is_empty` must run in $O(1)$ time.\n- The underlying structure and algorithms must be justified from the base definitions and properties of heaps and complete binary trees. You may not assume or use any higher-level shortcut formulas; derive the design and complexity from first principles.\n\nFor testing, your program must construct the data structure and execute the following test suite. Each test case is an ordered sequence of operations. For each operation that returns a value, include that value in the test case’s result list in the same order. For operations that modify the data structure without returning a value (such as `insert`), do not include anything in the output for that operation.\n\nTest Suite:\n- Test Case $1$ (general case with mixed operations):\n  - Operations: `insert(5)`, `insert(3)`, `insert(8)`, `insert(1)`, `insert(7)`, `peek-min()`, `peek-max()`, `extract-min()`, `extract-max()`, `peek-min()`, `peek-max()`, `size()`, `is_empty()`.\n  - Expected result types: a list containing integers and booleans in the order returned by the queries.\n- Test Case $2$ (duplicates and negative values):\n  - Operations: `insert(-2)`, `insert(-2)`, `insert(0)`, `insert(5)`, `insert(5)`, `insert(-1)`, `extract-max()`, `extract-max()`, `extract-min()`, `extract-min()`, `peek-min()`, `peek-max()`, `size()`.\n  - Expected result types: a list containing integers.\n- Test Case $3$ (boundary conditions with small sizes):\n  - Operations: `insert(10)`, `peek-max()`, `extract-min()`, `is_empty()`, `insert(4)`, `insert(6)`, `extract-max()`, `extract-min()`, `is_empty()`.\n  - Expected result types: a list containing integers and booleans.\n- Test Case $4$ (stress with many inserts then alternating extractions):\n  - Operations: `insert(9)`, `insert(1)`, `insert(4)`, `insert(7)`, `insert(3)`, `insert(8)`, `insert(2)`, `insert(6)`, `insert(5)`, `extract-max()`, `extract-max()`, `extract-max()`, `extract-min()`, `extract-min()`, `extract-min()`, `peek-min()`, `peek-max()`, `size()`, `is_empty()`.\n  - Expected result types: a list containing integers and booleans.\n- Test Case $5$ (all equal elements and emptiness checks):\n  - Operations: `is_empty()`, `insert(0)`, `insert(0)`, `insert(0)`, `peek-min()`, `peek-max()`, `extract-min()`, `extract-max()`, `extract-max()`, `is_empty()`.\n  - Expected result types: a list containing booleans and integers.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case’s result list. For example, your program should print something of the form $[[r\\_1],[r\\_2],[r\\_3],[r\\_4],[r\\_5]]$ where each $[r\\_i]$ is the list of values returned by the operations in test case $i$, in order.\n- No units are involved, and all returned values are integers or booleans. The program must be self-contained and must not read any input.",
            "solution": "The user wants to solve the following problem:\nYou must design and implement a double-ended priority queue as an Abstract Data Type (ADT) that supports both minimum and maximum operations with logarithmic runtime per update. The foundational base is the following set of definitions and well-tested facts: a priority queue supports insertion and removal of an element with highest or lowest priority; a binary heap is a complete binary tree with a heap-order invariant; the height of a complete binary tree with $n$ nodes is $\\lfloor \\log_2 n \\rfloor$. You must derive a data structure and its algorithms from these fundamentals so that both a minimum element and a maximum element can be extracted efficiently.\n\nRequirements:\n- Implement a double-ended priority queue that supports the following operations on a multiset of integers:\n  - `insert(x)`: insert integer $x$.\n  - `extract-min()`: remove and return the smallest element.\n  - `extract-max()`: remove and return the largest element.\n  - `peek-min()`: return the smallest element without removing it.\n  - `peek-max()`: return the largest element without removing it.\n  - `size()`: return the current number of elements.\n  - `is_empty()`: return a boolean indicating whether there are zero elements.\n- All update operations `insert`, `extract-min`, and `extract-max` must run in $O(\\log n)$ time, where $n$ is the number of elements currently stored. Query operations `peek-min`, `peek-max`, `size`, and `is_empty` must run in $O(1)$ time.\n- The underlying structure and algorithms must be justified from the base definitions and properties of heaps and complete binary trees. You may not assume or use any higher-level shortcut formulas; derive the design and complexity from first principles.\n\nFor testing, your program must construct the data structure and execute the following test suite. Each test case is an ordered sequence of operations. For each operation that returns a value, include that value in the test case’s result list in the same order. For operations that modify the data structure without returning a value (such as `insert`), do not include anything in the output for that operation.\n\nTest Suite:\n- Test Case $1$ (general case with mixed operations):\n  - Operations: `insert(5)`, `insert(3)`, `insert(8)`, `insert(1)`, `insert(7)`, `peek-min()`, `peek-max()`, `extract-min()`, `extract-max()`, `peek-min()`, `peek-max()`, `size()`, `is_empty()`.\n  - Expected result types: a list containing integers and booleans in the order returned by the queries.\n- Test Case $2$ (duplicates and negative values):\n  - Operations: `insert(-2)`, `insert(-2)`, `insert(0)`, `insert(5)`, `insert(5)`, `insert(-1)`, `extract-max()`, `extract-max()`, `extract-min()`, `extract-min()`, `peek-min()`, `peek-max()`, `size()`.\n  - Expected result types: a list containing integers.\n- Test Case $3$ (boundary conditions with small sizes):\n  - Operations: `insert(10)`, `peek-max()`, `extract-min()`, `is_empty()`, `insert(4)`, `insert(6)`, `extract-max()`, `extract-min()`, `is_empty()`.\n  - Expected result types: a list containing integers and booleans.\n- Test Case $4$ (stress with many inserts then alternating extractions):\n  - Operations: `insert(9)`, `insert(1)`, `insert(4)`, `insert(7)`, `insert(3)`, `insert(8)`, `insert(2)`, `insert(6)`, `insert(5)`, `extract-max()`, `extract-max()`, `extract-max()`, `extract-min()`, `extract-min()`, `extract-min()`, `peek-min()`, `peek-max()`, `size()`, `is_empty()`.\n  - Expected result types: a list containing integers and booleans.\n- Test Case $5$ (all equal elements and emptiness checks):\n  - Operations: `is_empty()`, `insert(0)`, `insert(0)`, `insert(0)`, `peek-min()`, `peek-max()`, `extract-min()`, `extract-max()`, `extract-max()`, `is_empty()`.\n  - Expected result types: a list containing booleans and integers.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case’s result list. For example, your program should print something of the form $[[r\\_1],[r\\_2],[r\\_3],[r\\_4],[r\\_5]]$ where each $[r\\_i]$ is the list of values returned by the operations in test case $i$, in order.\n- No units are involved, and all returned values are integers or booleans. The program must be self-contained and must not read any input.\n***\n### Step 1: Extract Givens\n- **ADT**: Double-Ended Priority Queue (DE-PQ).\n- **Supported Operations**: `insert(x)`, `extract-min()`, `extract-max()`, `peek-min()`, `peek-max()`, `size()`, `is_empty()`.\n- **Performance Constraints**:\n    - Update operations (`insert`, `extract-min`, `extract-max`): $O(\\log n)$ time complexity.\n    - Query operations (`peek-min`, `peek-max`, `size`, `is_empty`): $O(1)$ time complexity.\n- **Foundational Principles**: The design must be derived from the properties of priority queues, binary heaps, and complete binary trees. A binary heap is a complete binary tree with a heap-order invariant. The height of a complete binary tree with $n$ nodes is $\\lfloor \\log_2 n \\rfloor$.\n- **Test Suite**: Five specific test cases with sequences of operations are provided for validation.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is to design a specific data structure, a double-ended priority queue, with strict performance guarantees, and to derive it from first principles of heaps and binary trees.\n\n- **Scientifically Grounded (Critical)**: The problem is rooted in the well-established field of data structures and algorithms, which is a core part of computer science. The concepts of priority queues, binary heaps, and complexity analysis are formal and mathematically sound. The problem is valid on this criterion.\n- **Well-Posed**: The problem is well-posed. It specifies the required operations, their inputs, their outputs, and their time complexities. A unique and meaningful solution in the form of a data structure and its associated algorithms is expected and possible.\n- **Objective (Critical)**: The problem is stated in precise, objective language. The requirements are formal and unambiguous.\n- **Completeness and Consistency**: The problem is self-contained. It provides all necessary definitions, constraints, and test cases. There are no contradictions. For example, the requirement to derive the solution from heap principles while achieving logarithmic updates and constant-time peeks is a standard, albeit non-trivial, design challenge that has known solutions.\n- **Other Flaws**: The problem is not metaphorical, trivial, or unverifiable. It is a standard, challenging problem in algorithm design.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed to design and implement the solution.\n\n### Principle-Based Design and Derivation\n\nThe objective is to create a Double-Ended Priority Queue (DE-PQ) that provides efficient access to both the minimum and maximum elements. A standard binary heap, the foundational priority queue implementation, is insufficient for this task. A min-heap provides $O(1)$ access to the minimum element but requires an $O(n)$ scan to find the maximum. A max-heap has the symmetric property.\n\nTo achieve the desired complexities, we can use a composite structure consisting of two binary heaps working in tandem: one min-heap, denoted $H_{min}$, and one max-heap, $H_{max}$. Every element inserted into the DE-PQ will be stored in both heaps. This ensures that the minimum element is always at the root of $H_{min}$ and the maximum element is at the root of $H_{max}$, allowing for $O(1)$ `peek-min` and `peek-max` operations.\n\nThe central challenge lies in synchronizing the two heaps during extraction operations. When an element is extracted from one heap (e.g., the minimum element from $H_{min}$), its corresponding entry must also be removed from the other heap ($H_{max}$) to maintain consistency. A standard heap does not support the efficient removal of an arbitrary element; locating such an element requires a linear scan, an $O(n)$ operation which violates the problem constraints.\n\nTo overcome this, we augment the heap structure with a mechanism for efficient cross-referencing and arbitrary removal. This is achieved by:\n1.  **Unique Identification**: The problem allows for a multiset, meaning duplicate values can exist. To uniquely identify each instance of a value, we store elements as tuples $(v, id)$, where $v$ is the integer value and $id$ is a unique identifier assigned upon insertion (e.g., a monotonically increasing integer).\n2.  **Position Maps**: We maintain two dictionaries (hash maps), $P_{min}$ and $P_{max}$, that map each unique $id$ to its current index in the array representation of $H_{min}$ and $H_{max}$, respectively. This allows for $O(1)$ average-time lookup of any element's position in either heap.\n\nWith this augmented structure, we can define an operation `remove_at_index(i)` for a heap that runs in $O(\\log n)$ time. This operation works as follows:\n- To remove the element at index $i$, it is swapped with the last element in the heap's array.\n- The array is shortened by one (the original last element is popped).\n- The position map is updated for the element that was moved into index $i$.\n- The heap property may now be violated at index $i$. The element at $i$ is sifted up or down the heap to restore the invariant. Since sifting traverses a path whose length is at most the height of the tree, which is $O(\\log n)$, the entire removal operation is $O(\\log n)$. All swaps performed during sifting must also update the position map, which is an $O(1)$ operation per swap.\n\nBased on this design, the ADT operations are implemented as follows:\n- **`size()`**, **`is_empty()`**: These return the current number of elements, e.g., `len(H_min)`, in $O(1)$ time.\n- **`peek-min()`**: Returns the value from the root element of $H_{min}$, which is at index $0$. This is an $O(1)$ operation.\n- **`peek-max()`**: Returns the value from the root element of $H_{max}$, also an $O(1)$ operation. Note that if $H_{max}$ is implemented as a min-heap storing negative values, we must return the negation of the value at the root.\n- **`insert(x)`**:\n    1. A new unique $id$ is generated.\n    2. The tuple $(x, id)$ is inserted into $H_{min}$ and sifted up. This takes $O(\\log n)$ time.\n    3. The tuple $(-x, id)$ is inserted into $H_{max}$ and sifted up. This also takes $O(\\log n)$ time.\n    4. The position maps $P_{min}$ and $P_{max}$ are updated accordingly. The total complexity is $O(\\log n)$.\n- **`extract-min()`**:\n    1. The root element $(v, id)$ of $H_{min}$ is identified. This is the minimum element.\n    2. The $id$ is used to find the index of this element in $H_{max}$ via the position map $P_{max}$. This lookup is $O(1)$.\n    3. The element is removed from $H_{max}$ using the $O(\\log n)$ `remove_at_index` procedure described above.\n    4. The root element is removed from $H_{min}$, also an $O(\\log n)$ operation.\n    5. The value $v$ is returned. The total time complexity is $O(\\log n) + O(\\log n) = O(\\log n)$.\n- **`extract-max()`**: This operation is symmetric to `extract-min()`. It extracts the root from $H_{max}$, uses its $id$ to find and remove the corresponding element from $H_{min}$, and returns the value. The complexity is also $O(\\log n)$.\n\nThis design fulfills all requirements of the problem. It is derived directly from the principles of binary heaps, augmented with a standard indexing technique to meet the specified time complexities. Each update operation consists of a constant number of fundamental heap manipulations (sifting), each of which is bounded by the tree height, $O(\\log n)$. Query operations are simple array/property lookups, taking $O(1)$ time.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass DoubleEndedPriorityQueue:\n    \"\"\"\n    A Double-Ended Priority Queue implemented using two binary heaps\n    and position maps for efficient synchronization.\n    - _min_heap: a min-heap storing tuples of (value, uid).\n    - _max_heap: a max-heap storing tuples of (-value, uid).\n    - _pos_min: a dictionary mapping uid -> index in _min_heap.\n    - _pos_max: a dictionary mapping uid -> index in _max_heap.\n    \"\"\"\n    def __init__(self):\n        self._min_heap = []\n        self._max_heap = []\n        self._pos_min = {}\n        self._pos_max = {}\n        self._uid_counter = 0\n\n    def is_empty(self) - bool:\n        return len(self._min_heap) == 0\n\n    def size(self) - int:\n        return len(self._min_heap)\n\n    def insert(self, x: int):\n        uid = self._uid_counter\n        self._uid_counter += 1\n\n        # Insert into min-heap\n        self._min_heap.append((x, uid))\n        self._pos_min[uid] = self.size() - 1\n        self._sift_up(self._min_heap, self._pos_min, self.size() - 1)\n\n        # Insert into max-heap (using negative values in a min-heap)\n        self._max_heap.append((-x, uid))\n        self._pos_max[uid] = self.size() - 1\n        self._sift_up(self._max_heap, self._pos_max, self.size() - 1)\n\n    def peek_min(self) - int:\n        if self.is_empty():\n            raise IndexError(\"peek_min from an empty queue\")\n        return self._min_heap[0][0]\n\n    def peek_max(self) - int:\n        if self.is_empty():\n            raise IndexError(\"peek_max from an empty queue\")\n        return -self._max_heap[0][0]\n\n    def extract_min(self) - int:\n        if self.is_empty():\n            raise IndexError(\"extract_min from an empty queue\")\n        \n        val, uid = self._min_heap[0]\n\n        # Remove corresponding element from max-heap\n        idx_in_max = self._pos_max[uid]\n        self._remove_at_index(self._max_heap, self._pos_max, idx_in_max)\n        \n        # Remove min element from min-heap\n        self._remove_at_index(self._min_heap, self._pos_min, 0)\n        \n        return val\n\n    def extract_max(self) - int:\n        if self.is_empty():\n            raise IndexError(\"extract_max from an empty queue\")\n            \n        neg_val, uid = self._max_heap[0]\n        val = -neg_val\n        \n        # Remove corresponding element from min-heap\n        idx_in_min = self._pos_min[uid]\n        self._remove_at_index(self._min_heap, self._pos_min, idx_in_min)\n\n        # Remove max element from max-heap\n        self._remove_at_index(self._max_heap, self._pos_max, 0)\n        \n        return val\n\n    # Helper methods for heap manipulation\n    def _swap(self, h, p, i, j):\n        uid_i = h[i][1]\n        uid_j = h[j][1]\n        h[i], h[j] = h[j], h[i]\n        p[uid_i] = j\n        p[uid_j] = i\n\n    def _sift_up(self, h, p, i):\n        parent_idx = (i - 1) // 2\n        while i > 0 and h[i][0]  h[parent_idx][0]:\n            self._swap(h, p, i, parent_idx)\n            i = parent_idx\n            parent_idx = (i - 1) // 2\n\n    def _sift_down(self, h, p, i):\n        max_index = len(h) - 1\n        while True:\n            left_child_idx = 2 * i + 1\n            right_child_idx = 2 * i + 2\n            smallest = i\n\n            if left_child_idx = max_index and h[left_child_idx][0]  h[smallest][0]:\n                smallest = left_child_idx\n            \n            if right_child_idx = max_index and h[right_child_idx][0]  h[smallest][0]:\n                smallest = right_child_idx\n            \n            if smallest != i:\n                self._swap(h, p, i, smallest)\n                i = smallest\n            else:\n                break\n\n    def _remove_at_index(self, h, p, i):\n        uid_to_remove = h[i][1]\n        last_idx = len(h) - 1\n        \n        if i == last_idx:\n            h.pop()\n        else:\n            self._swap(h, p, i, last_idx)\n            h.pop()\n            # After swap, element at i might need sifting.\n            # It came from the bottom, so it won't be smaller than its parent\n            # unless it's a very small value. Sifting up first is safer.\n            # Then sifting down. Only one will do work.\n            self._sift_up(h, p, i)\n            self._sift_down(h, p, i)\n\n        del p[uid_to_remove]\n\n\ndef solve():\n    test_cases_ops = [\n        # Test Case 1\n        [\"insert(5)\", \"insert(3)\", \"insert(8)\", \"insert(1)\", \"insert(7)\", \"peek-min()\", \"peek-max()\", \"extract-min()\", \"extract-max()\", \"peek-min()\", \"peek-max()\", \"size()\", \"is_empty()\"],\n        # Test Case 2\n        [\"insert(-2)\", \"insert(-2)\", \"insert(0)\", \"insert(5)\", \"insert(5)\", \"insert(-1)\", \"extract-max()\", \"extract-max()\", \"extract-min()\", \"extract-min()\", \"peek-min()\", \"peek-max()\", \"size()\"],\n        # Test Case 3\n        [\"insert(10)\", \"peek-max()\", \"extract-min()\", \"is_empty()\", \"insert(4)\", \"insert(6)\", \"extract-max()\", \"extract-min()\", \"is_empty()\"],\n        # Test Case 4\n        [\"insert(9)\", \"insert(1)\", \"insert(4)\", \"insert(7)\", \"insert(3)\", \"insert(8)\", \"insert(2)\", \"insert(6)\", \"insert(5)\", \"extract-max()\", \"extract-max()\", \"extract-max()\", \"extract-min()\", \"extract-min()\", \"extract-min()\", \"peek-min()\", \"peek-max()\", \"size()\", \"is_empty()\"],\n        # Test Case 5\n        [\"is_empty()\", \"insert(0)\", \"insert(0)\", \"insert(0)\", \"peek-min()\", \"peek-max()\", \"extract-min()\", \"extract-max()\", \"extract-max()\", \"is_empty()\"]\n    ]\n    \n    all_results = []\n\n    for ops in test_cases_ops:\n        depq = DoubleEndedPriorityQueue()\n        case_results = []\n        for op_str in ops:\n            op_name, op_args_str = op_str[:-1].split('(', 1)\n            \n            result = None\n            if op_name == 'insert':\n                arg = int(op_args_str)\n                depq.insert(arg)\n            elif op_name == 'extract-min':\n                result = depq.extract_min()\n            elif op_name == 'extract-max':\n                result = depq.extract_max()\n            elif op_name == 'peek-min':\n                result = depq.peek_min()\n            elif op_name == 'peek-max':\n                result = depq.peek_max()\n            elif op_name == 'size':\n                result = depq.size()\n            elif op_name == 'is_empty':\n                result = depq.is_empty()\n\n            if result is not None:\n                case_results.append(result)\n        all_results.append(case_results)\n\n    # Format the final output string exactly as required.\n    # e.g., [[1, 8, 1, 8, 3, 5, 3, False], [...]]\n    output_str = \"[\" + \",\".join([str(res).replace(\" \", \"\") for res in all_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}