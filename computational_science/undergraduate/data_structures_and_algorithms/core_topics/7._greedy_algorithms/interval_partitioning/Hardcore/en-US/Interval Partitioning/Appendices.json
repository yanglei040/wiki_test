{
    "hands_on_practices": [
        {
            "introduction": "This first practice will solidify the fundamental principle of interval partitioning. We will determine the minimum number of resources needed for a set of tasks by calculating the \"maximum depth\"—the largest number of tasks simultaneously active at any point in time. This hands-on calculation builds the core intuition that connects the resource requirement directly to the point of maximum contention. ",
            "id": "3241727",
            "problem": "A public library manages checkout requests for a single title by allocating copies to patrons over time. Each request is represented as a half-open interval $[s_i, e_i)$ on a discrete time axis, where $s_i$ is the start time and $e_i$ is the return time, and the interval includes time $s_i$ but excludes time $e_i$. A copy can serve at most one request at any time, and a request must be assigned to exactly one copy for its entire duration. The library seeks to know how many copies are required so that every request can be fulfilled without delay or interruption.\n\nConsider the following set of $12$ requests:\n- $I_1 = [1, 7)$\n- $I_2 = [3, 9)$\n- $I_3 = [6, 10)$\n- $I_4 = [8, 12)$\n- $I_5 = [11, 15)$\n- $I_6 = [14, 18)$\n- $I_7 = [16, 22)$\n- $I_8 = [20, 25)$\n- $I_9 = [4, 5)$\n- $I_{10} = [5, 6)$\n- $I_{11} = [9, 14)$\n- $I_{12} = [2, 3)$\n\nStarting only from the core definitions of interval overlap and resource assignment, and without invoking pre-stated results, determine the minimal integer $k^{*}$ such that the library can fulfill all $12$ requests using $k^{*}$ copies of the book. Your reasoning must justify why this $k^{*}$ suffices and why fewer copies cannot suffice. The final answer must be a single integer. No rounding is required.",
            "solution": "The problem asks for the minimum number of copies, denoted $k^*$, required to fulfill a given set of $12$ checkout requests. Each request is an interval of time, and two requests that overlap in time cannot be served by the same copy. This is a classic interval partitioning problem. The minimal number of partitions corresponds to the minimal number of copies required.\n\nLet the set of requests be $\\mathcal{I} = \\{I_1, I_2, \\dots, I_{12}\\}$, where each $I_i = [s_i, e_i)$ is a half-open interval on a time axis. Two intervals $I_i = [s_i, e_i)$ and $I_j = [s_j, e_j)$ are said to overlap if their intersection is non-empty, i.e., $I_i \\cap I_j \\neq \\emptyset$. This occurs if and only if $s_i < e_j$ and $s_j < e_i$. If two intervals overlap, they must be assigned to different copies.\n\nFirst, we establish a lower bound for $k^*$. At any given point in time $t$, let $D(t)$ be the number of requests that are active at that time. An interval $I_i=[s_i, e_i)$ is active at time $t$ if $s_i \\le t < e_i$. All requests that are simultaneously active at time $t$ must be assigned to distinct copies. Therefore, the number of copies required must be at least $D(t)$ for any time $t$. Consequently, the minimum number of copies $k^*$ must be at least the maximum value of $D(t)$ over all time. Let this maximum value be $\\omega$, the maximum depth of the set of intervals.\n$$k^* \\ge \\max_{t} D(t) = \\omega$$\nTo find $\\omega$, we can analyze the number of active intervals over time. The number of active intervals only changes at the start or end times of the intervals. We can construct a set of event points from all start and end times, sort them, and \"sweep\" across the time axis, tracking the count of active intervals.\n\nThe given intervals are:\n$I_1 = [1, 7)$, $I_2 = [3, 9)$, $I_3 = [6, 10)$, $I_4 = [8, 12)$, $I_5 = [11, 15)$, $I_6 = [14, 18)$, $I_7 = [16, 22)$, $I_8 = [20, 25)$, $I_9 = [4, 5)$, $I_{10} = [5, 6)$, $I_{11} = [9, 14)$, $I_{12} = [2, 3)$.\n\nLet's examine the number of active intervals at various points in time:\n- For $t \\in [1, 2)$: Only $I_1$ is active. $D(t)=1$.\n- For $t \\in [2, 3)$: $I_1, I_{12}$ are active. $D(t)=2$.\n- For $t \\in [3, 4)$: $I_1, I_2$ are active. $D(t)=2$.\n- For $t \\in [4, 5)$: $I_1, I_2, I_9$ are active. $D(t)=3$.\n- For $t \\in [5, 6)$: $I_1, I_2, I_{10}$ are active. $D(t)=3$.\n- For $t \\in [6, 7)$: $I_1, I_2, I_3$ are active. $D(t)=3$.\n- For $t \\in [7, 8)$: $I_2, I_3$ are active. $D(t)=2$.\n- For $t \\in [8, 9)$: $I_2, I_3, I_4$ are active. $D(t)=3$.\n- For $t \\in [9, 10)$: $I_3, I_4, I_{11}$ are active. $D(t)=3$.\n- For $t \\in [10, 11)$: $I_4, I_{11}$ are active. $D(t)=2$.\n- For $t \\in [11, 12)$: $I_4, I_{11}, I_5$ are active. $D(t)=3$.\n\nThe maximum number of simultaneously active intervals observed is $3$. For example, at time $t=6.5$, the intervals $I_1=[1, 7)$, $I_2=[3, 9)$, and $I_3=[6, 10)$ are all active. Since these three requests must be served by three distinct copies, we have established a lower bound for the number of required copies:\n$$k^* \\ge 3$$\nThis proves that fewer than $3$ copies cannot suffice.\n\nNext, we must show that $3$ copies are sufficient. To do this, we provide a constructive assignment of intervals to $3$ copies. A standard greedy algorithm can be used for this purpose. The algorithm proceeds as follows:\n1. Sort the intervals in increasing order of their start times.\n2. Iterate through the sorted intervals. For each interval, assign it to the first available copy (i.e., the copy with the smallest index that is not currently assigned to an overlapping interval).\n\nLet the copies be $C_1, C_2, C_3$. The sorted list of intervals by start time is:\n$I_1=[1, 7)$, $I_{12}=[2, 3)$, $I_2=[3, 9)$, $I_9=[4, 5)$, $I_{10}=[5, 6)$, $I_3=[6, 10)$, $I_4=[8, 12)$, $I_{11}=[9, 14)$, $I_5=[11, 15)$, $I_6=[14, 18)$, $I_7=[16, 22)$, $I_8=[20, 25)$.\n\nLet's assign them:\n- $I_1 = [1, 7)$: $C_1$ is free. Assign to $C_1$. ( $C_1$ busy until time $7$)\n- $I_{12} = [2, 3)$: $C_1$ is busy. $C_2$ is free. Assign to $C_2$. ( $C_2$ busy until time $3$)\n- $I_2 = [3, 9)$: $C_1$ is busy. $C_2$ is free at time $3$. Assign to $C_2$. ( $C_2$ busy until time $9$)\n- $I_9 = [4, 5)$: $C_1$ is busy. $C_2$ is busy. $C_3$ is free. Assign to $C_3$. ( $C_3$ busy until time $5$)\n- $I_{10} = [5, 6)$: $C_1$ is busy. $C_2$ is busy. $C_3$ is free at time $5$. Assign to $C_3$. ( $C_3$ busy until time $6$)\n- $I_3 = [6, 10)$: $C_1$ is busy. $C_2$ is busy. $C_3$ is free at time $6$. Assign to $C_3$. ( $C_3$ busy until time $10$)\n- $I_4 = [8, 12)$: $C_1$ is free at time $7$. Assign to $C_1$. ( $C_1$ busy until time $12$)\n- $I_{11} = [9, 14)$: $C_1$ is busy. $C_2$ is free at time $9$. Assign to $C_2$. ( $C_2$ busy until time $14$)\n- $I_5 = [11, 15)$: $C_1$ is busy. $C_2$ is busy. $C_3$ is free at time $10$. Assign to $C_3$. ( $C_3$ busy until time $15$)\n- $I_6 = [14, 18)$: $C_1$ is free at time $12$. Assign to $C_1$. ( $C_1$ busy until time $18$)\n- $I_7 = [16, 22)$: $C_1$ is busy. $C_2$ is free at time $14$. Assign to $C_2$. ( $C_2$ busy until time $22$)\n- $I_8 = [20, 25)$: $C_1$ is free at time $18$. Assign to $C_1$. ( $C_1$ busy until time $25$)\n\nAll $12$ intervals have been successfully assigned using at most $3$ copies. This demonstrates that $3$ copies are sufficient.\n$$k^* \\le 3$$\n\nTo justify the correctness of this procedure from core definitions, consider why the greedy algorithm is optimal. Let the algorithm use $M$ copies. This implies that there exists an interval, say $I_j = [s_j, e_j)$, that was assigned to the $M$-th copy, $C_M$. According to the algorithm's logic, this could only happen if copies $C_1, C_2, \\dots, C_{M-1}$ were all busy at the time of assignment. This means that for each copy $C_k$ (where $k \\in \\{1, \\dots, M-1\\}$), there was an interval $I_{p_k} = [s_{p_k}, e_{p_k})$ already assigned to it that overlaps with $I_j$. Since intervals are processed in order of their start times, we have $s_{p_k} \\le s_j$ for all $k$. For $I_{p_k}$ and $I_j$ to overlap, it must be true that $s_j < e_{p_k}$. This means that at the specific time $s_j$, all the $M-1$ intervals $I_{p_1}, \\dots, I_{p_{M-1}}$ are active. The interval $I_j$ itself is also active at time $s_j$. Therefore, at time $s_j$, there are at least $M$ simultaneously active intervals. This implies that the maximum depth $\\omega$ must be at least $M$. So, $M \\le \\omega$. Since we already know $M \\ge \\omega$, it follows that $M=\\omega$. The greedy algorithm thus uses exactly the minimum possible number of copies.\n\nCombining our findings, we have $k^* \\ge 3$ and $k^* \\le 3$. The only integer satisfying both conditions is $3$. Therefore, the minimal number of copies required is $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "Real-world scheduling often involves more than just task durations; pre-task setup and post-task teardown are common. This practice demonstrates how to model such complexities by transforming the problem into a standard interval partitioning case. You will learn to define an \"effective interval\" for each task that includes these overhead times, a powerful technique for reducing novel problems to familiar ones. ",
            "id": "3241746",
            "problem": "Consider a finite set of tasks, each represented by an interval with a start time $s_i$ and a finish time $f_i$ where $f_i > s_i$, for $i \\in \\{1,2,\\dots,n\\}$. A resource must perform a setup before each task and a teardown after each task. Specifically, whenever a resource is assigned to task $i$, it is unavailable during the interval $[s_i - S, f_i + T]$, where $S \\ge 0$ is the setup time and $T \\ge 0$ is the teardown time. Two tasks assigned to the same resource must have their resource-unavailable intervals non-overlapping in the sense that if a task $j$ is scheduled after task $i$ on the same resource, then $s_j - S \\ge f_i + T$ must hold. The goal is to assign all tasks to the minimum number of resources so that no resource’s unavailable intervals overlap.\n\nStarting from the fundamental definitions of intervals, partial orders, and the concept of resource unavailability caused by setup and teardown, derive a method to compute the minimum number of resources required to schedule all tasks under the above constraints. Your derivation must not rely on unproven shortcuts; it should proceed from first principles and well-tested facts about intervals and orderings. You must then implement this method as a complete, runnable program that computes the minimum number of resources for each test case below.\n\nUse the following test suite of parameter values, where each test case is specified by constants $S$, $T$, and a list of intervals $\\{(s_i,f_i)\\}$:\n\n- Test case $1$: $S=0$, $T=0$, intervals $\\{(1,3),(2,4),(3,5),(7,8)\\}$.\n- Test case $2$: $S=1$, $T=1$, intervals $\\{(1,2),(2,3),(3,4)\\}$.\n- Test case $3$: $S=1$, $T=2$, intervals $\\{(4,6),(9,10)\\}$.\n- Test case $4$: $S=0$, $T=2$, intervals $\\{(1,3),(3,4),(5,6),(6,7)\\}$.\n- Test case $5$: $S=2$, $T=0$, intervals $\\{(5,8),(10,12),(12,13),(13,15)\\}$.\n- Test case $6$: $S=2$, $T=2$, intervals $\\{(0,1),(5,6),(8,9)\\}$.\n\nFor each test case, the required answer is the minimum number of resources, an integer. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases given above, for example, $[r_1,r_2,r_3,r_4,r_5,r_6]$, where each $r_k$ is the integer result for test case $k$. No physical units or angle units are involved in this problem, and all outputs are integers.",
            "solution": "The problem requires finding the minimum number of resources to schedule a set of tasks, each with a specified start time, finish time, setup time, and teardown time. We will approach this by first formalizing the constraints and then demonstrating that the problem is equivalent to the classic interval partitioning problem. The solution to the latter will be derived from first principles.\n\nLet the set of tasks be indexed by $i \\in \\{1, 2, \\dots, n\\}$. Each task $i$ is defined by a time interval $(s_i, f_i)$ where $s_i$ is the start time and $f_i$ is the finish time, with $f_i > s_i$. A constant setup time $S \\ge 0$ is required before each task begins, and a constant teardown time $T \\ge 0$ is required after any task finishes. This means that a resource assigned to task $i$ is occupied and unavailable during the closed interval $[s_i - S, f_i + T]$.\n\nThe core constraint for scheduling two tasks, $i$ and $j$, on the same resource is that their periods of resource unavailability must not conflict. The problem states this as: if task $j$ is scheduled after task $i$, then $s_j - S \\ge f_i + T$ must hold. More generally, if any two distinct tasks $i$ and $j$ are to be assigned to the same resource, one must be completed before the other begins. This means either task $i$ is completed before task $j$ begins, or task $j$ is completed before task $i$ begins.\n- If task $i$ is first, the resource becomes available at time $f_i + T$. Task $j$ can then start, with its setup beginning at time $s_j - S$. The condition is $s_j - S \\ge f_i + T$.\n- If task $j$ is first, the condition is symmetrically $s_i - S \\ge f_j + T$.\n\nTherefore, two tasks $i$ and $j$ are **compatible** (can be placed on the same resource) if and only if $(s_j - S \\ge f_i + T) \\lor (s_i - S \\ge f_j + T)$.\n\nConversely, tasks $i$ and $j$ are **incompatible** (they conflict and require different resources) if they are not compatible. This occurs if the negation of the compatibility condition is true:\n$\\neg((s_j - S \\ge f_i + T) \\lor (s_i - S \\ge f_j + T))$\nUsing de Morgan's laws, this is equivalent to:\n$(\\neg(s_j - S \\ge f_i + T)) \\land (\\neg(s_i - S \\ge f_j + T))$\nWhich simplifies to:\n$(s_j - S  f_i + T) \\land (s_i - S  f_j + T)$\n\nTo simplify this expression, let us define an **effective interval** for each task $i$ as $I'_i = [s'_i, f'_i) = [s_i - S, f_i + T)$. The conflict condition between tasks $i$ and $j$ can now be rewritten using their effective interval endpoints $s'_i, f'_i, s'_j, f'_j$ as $s'_j  f'_i \\land s'_i  f'_j$. This is the precise mathematical definition of two half-open intervals, $I'_i$ and $I'_j$, having a non-empty intersection (i.e., they overlap).\n\nThe problem has now been transformed into the following: Given a set of half-open intervals $\\{I'_1, I'_2, \\dots, I'_n\\}$, partition them into the minimum number of subsets such that no two intervals in any given subset overlap. This is the **Interval Partitioning Problem**.\n\nThe solution to the interval partitioning problem is the **depth** of the set of intervals. The depth, denoted by $d$, is the maximum number of intervals that mutually overlap at any single point in time. Formally,\n$$d = \\max_{t \\in \\mathbb{R}} |\\{i \\mid t \\in I'_i\\}|$$\nWe must prove from first principles that the minimum number of required resources, $k_{min}$, is equal to $d$.\n\n**Lower Bound:** $k_{min} \\ge d$.\nBy the definition of depth, there exists a point in time $t_0$ at which $d$ distinct effective intervals $I'_{i_1}, I'_{i_2}, \\dots, I'_{i_d}$ all overlap. This means that for any pair of tasks $j, l \\in \\{i_1, \\dots, i_d\\}$, their effective intervals $I'_j$ and $I'_l$ have a non-empty intersection. Consequently, these $d$ tasks are all mutually incompatible. Therefore, each of these $d$ tasks must be assigned to a different resource. This directly implies that at least $d$ resources are necessary. Thus, $k_{min} \\ge d$.\n\n**Upper Bound (Constructive Proof):** $k_{min} \\le d$.\nWe can demonstrate that $d$ resources are always sufficient by providing a greedy algorithm that schedules all tasks using at most $d$ resources. The most direct method for computing $d$ and implicitly for assigning resources is the **sweep-line algorithm**.\n\n1.  For each effective interval $I'_i = [s'_i, f'_i)$, create two events: a start event $(s'_i, +1)$ and a finish event $(f'_i, -1)$.\n2.  Collect all $2n$ events into a single list.\n3.  Sort the list of events primarily by their time coordinate. For events that occur at the same time, a tie-breaking rule is crucial. If an interval ends at the exact time another begins (e.g., $[1,3)$ and $[3,5)$), they are not considered to overlap. A resource can be freed from the first task and immediately used for the second. To model this correctly, finish events ($-1$) must be processed before start events ($+1$) at the same time coordinate. Thus, the secondary sort key for an event $(t, \\text{type})$ should be `type`.\n4.  Initialize a counter for the number of currently overlapping intervals, `current_overlap = 0`, and a variable to track the maximum overlap found so far, `max_overlap = 0`.\n5.  Iterate through the sorted list of events. For each event $(t, \\text{type})$:\n    a. Update the current overlap: `current_overlap = current_overlap + type`.\n    b. Update the maximum overlap: `max_overlap = max(max_overlap, current_overlap)`.\n\nAfter processing all events, `max_overlap` will hold the value $d$. This sweep-line process simulates moving a point in time from $-\\infty$ to $+\\infty$ and counting how many intervals are \"active\" at each moment. The `current_overlap` increases by $1$ at the start of an interval and decreases by $1$ at the end. The maximum value it ever reaches is, by definition, the depth $d$.\n\nThis algorithm not only computes $d$ but also provides a constructive argument for sufficiency. Imagine a greedy assignment strategy that processes tasks in order of their effective start times. When considering a task, it assigns it to any resource that has become available (i.e., the previous task on it has an effective finish time less than or equal to the current task's effective start time). If no resource is available, it allocates a new one. The number of resources this greedy algorithm allocates never exceeds $d$. If it were to allocate a $(d+1)$-th resource for a task $T_i$, it would mean that at the start time $s'_i$, $d$ other tasks are active and occupy the first $d$ resources. This would imply that $d+1$ intervals (task $T_i$ and the $d$ other tasks) are simultaneously active, contradicting the fact that the depth is $d$.\n\nThus, $d$ resources are sufficient. Since we have shown $k_{min} \\ge d$ and $k_{min} \\le d$, it must be that $k_{min} = d$. The minimum number of resources is the depth of the set of effective intervals, which can be computed efficiently using the sweep-line algorithm described.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the solver for each,\n    and print the results in the specified format.\n    \"\"\"\n    # Each test case is a tuple: (S, T, list_of_intervals)\n    # Each interval is a tuple: (start_time, finish_time)\n    test_cases = [\n        (0, 0, [(1, 3), (2, 4), (3, 5), (7, 8)]),\n        (1, 1, [(1, 2), (2, 3), (3, 4)]),\n        (1, 2, [(4, 6), (9, 10)]),\n        (0, 2, [(1, 3), (3, 4), (5, 6), (6, 7)]),\n        (2, 0, [(5, 8), (10, 12), (12, 13), (13, 15)]),\n        (2, 2, [(0, 1), (5, 6), (8, 9)]),\n    ]\n\n    results = []\n    for S, T, intervals in test_cases:\n        result = compute_min_resources(S, T, intervals)\n        results.append(result)\n\n    # Format the output as a comma-separated list in square brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_min_resources(S, T, intervals):\n    \"\"\"\n    Computes the minimum number of resources required for a given set of tasks.\n    This is equivalent to finding the depth of the set of effective intervals.\n\n    The method used is the sweep-line algorithm.\n\n    Args:\n        S (int): The setup time, S = 0.\n        T (int): The teardown time, T = 0.\n        intervals (list of tuples): A list of (start_time, finish_time) for each task.\n\n    Returns:\n        int: The minimum number of resources required.\n    \"\"\"\n    if not intervals:\n        return 0\n\n    events = []\n    # Define constants for event types to aid sorting and readability\n    START_EVENT = 1\n    FINISH_EVENT = -1\n\n    for s_i, f_i in intervals:\n        # Calculate the effective interval [s_i - S, f_i + T).\n        # The conflict condition s'_j  f'_i and s'_i  f'_j corresponds to\n        # overlapping half-open intervals [s'_i, f'_i).\n        s_prime = s_i - S\n        f_prime = f_i + T\n        \n        # Add a start event\n        events.append((s_prime, START_EVENT))\n        # Add a finish event\n        events.append((f_prime, FINISH_EVENT))\n\n    # Sort events:\n    # 1. Primarily by time.\n    # 2. Secondarily by event type. A finish event (-1) must come before a\n    #    start event (1) at the same time to correctly handle intervals that\n    #    touch at endpoints, like [1,3) and [3,5). The natural sort order of\n    #    the types (-1  1) achieves this.\n    events.sort()\n\n    max_resources = 0\n    current_resources = 0\n    for time, event_type in events:\n        current_resources += event_type\n        if current_resources  max_resources:\n            max_resources = current_resources\n            \n    return max_resources\n\n# Execute the main function\nsolve()\n```"
        },
        {
            "introduction": "Tasks are often part of a larger workflow with dependencies, where one task cannot begin until its predecessors are complete. This final practice integrates graph theory with scheduling, requiring you to first resolve these precedence constraints using a topological sort of the task graph. Only after computing the true, dependency-adjusted schedule can you apply interval partitioning to find the minimum number of resources. ",
            "id": "3241721",
            "problem": "Consider a finite set of tasks, each represented by an interval with a planned start time and a planned end time. Let the tasks be indexed by integers, and let the planned interval for task $i$ be denoted by $[s_i, e_i)$, where $s_i$ is the planned start time and $e_i$ is the planned end time. The duration of task $i$ is $d_i = e_i - s_i$, and all durations satisfy $d_i  0$. The intervals are treated as half-open, meaning $[s_i, e_i)$ includes $s_i$ and excludes $e_i$, so that a task finishing at time $t$ does not overlap a task starting at time $t$.\n\nThere is a directed precedence relation among tasks forming a Directed Acyclic Graph (DAG), defined by a set of directed edges $p \\rightarrow i$, which means task $i$ cannot start until task $p$ has finished. Let $\\mathrm{pred}(i)$ be the set of predecessors of task $i$.\n\nA schedule is constructed by the following rule: each task $i$ must start as early as allowed by both its planned start time and its precedence constraints. Define the actual start time $a_i$ and the actual finish time $f_i$ by\n$$\na_i = \\max\\left(s_i,\\ \\max_{p \\in \\mathrm{pred}(i)} f_p\\right)\\quad\\text{with the convention that the inner maximum over an empty set equals } -\\infty\\text{, so that }a_i = s_i\\text{ if }\\mathrm{pred}(i)=\\varnothing,\n$$\nand\n$$\nf_i = a_i + d_i.\n$$\nThis rule yields a unique earliest-feasible schedule when the precedence graph is acyclic.\n\nOnce the actual intervals $[a_i, f_i)$ are determined, the interval partitioning problem asks for the minimum number of disjoint tracks (resources) needed to assign all tasks so that no two tasks assigned to the same track overlap in time. For a fixed set of intervals, this minimum equals the maximum number of intervals that overlap at any time.\n\nYour task is to write a complete and runnable program that, for each provided test case, performs the following steps:\n- Validates that the precedence relation forms a Directed Acyclic Graph (DAG). If it does not, output the integer $-1$ for that test case.\n- Otherwise, computes the earliest-feasible actual intervals $[a_i, f_i)$ using the rule above.\n- Computes the minimal number of tracks needed to partition these actual intervals so that no two intervals on the same track overlap.\n\nThe program must produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets. Each result must be an integer.\n\nFundamental base assumptions and definitions:\n- The precedence constraints define a partial order; in a Directed Acyclic Graph (DAG), a topological ordering exists.\n- For a fixed family of intervals, the minimum number of tracks required equals the maximum number of overlapping intervals at any time.\n\nTest suite and parameter specification:\nUse the following test cases, with indices, planned starts, planned ends, and predecessor lists as specified. All times are real numbers, but in the following tests they are integers.\n\n- Test case $1$ (general DAG with precedence-induced delays):\n  - Indices: $0, 1, 2, 3, 4$.\n  - Planned starts: $[0, 1, 2, 3, 0]$.\n  - Planned ends: $[3, 4, 5, 7, 2]$.\n  - Predecessors: $[\\varnothing, [0], [0], [1, 2], \\varnothing]$.\n  - Output: the minimal number of tracks as an integer.\n\n- Test case $2$ (no dependencies, overlapping intervals):\n  - Indices: $0, 1, 2$.\n  - Planned starts: $[0, 1, 2]$.\n  - Planned ends: $[2, 3, 4]$.\n  - Predecessors: $[\\varnothing, \\varnothing, \\varnothing]$.\n  - Output: the minimal number of tracks as an integer.\n\n- Test case $3$ (chain of dependencies, forcing sequential execution):\n  - Indices: $0, 1, 2$.\n  - Planned starts: $[0, 0, 0]$.\n  - Planned ends: $[3, 3, 3]$.\n  - Predecessors: $[\\varnothing, [0], [1]]$.\n  - Output: the minimal number of tracks as an integer.\n\n- Test case $4$ (branching dependencies creating a high overlap window):\n  - Indices: $0, 1, 2, 3, 4$.\n  - Planned starts: $[0, 0, 0, 0, 1]$.\n  - Planned ends: $[1, 2, 2, 2, 2]$.\n  - Predecessors: $[\\varnothing, [0], [0], [0], \\varnothing]$.\n  - Output: the minimal number of tracks as an integer.\n\n- Test case $5$ (invalid due to cycle; must be detected):\n  - Indices: $0, 1$.\n  - Planned starts: $[0, 0]$.\n  - Planned ends: $[1, 1]$.\n  - Predecessors: $[[1], [0]]$.\n  - Output: the integer $-1$.\n\nFinal output format requirement:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[r_1,r_2,r_3,r_4,r_5]\"), where each $r_i$ is the integer result for test case $i$ in the order listed above.",
            "solution": "The problem presented is a composite task requiring the integration of principles from graph theory, scheduling algorithms, and computational geometry. It can be systematically decomposed into three distinct, sequential stages: 1) validation of the precedence constraints as a Directed Acyclic Graph (DAG), 2) computation of an earliest-feasible schedule based on these constraints, and 3) determination of the minimum number of resources (tracks) required to execute the schedule without overlap.\n\nA valid solution must correctly implement each stage. We will now detail the formal methodology for each.\n\n**Stage 1: Precedence Graph Validation and Topological Sorting**\n\nThe set of tasks and their precedence constraints, $p \\rightarrow i$, form a directed graph $G = (V, E)$, where $V$ is the set of tasks and $E$ is the set of precedence edges. The rule for computing actual start times,\n$$\na_i = \\max\\left(s_i,\\ \\max_{p \\in \\mathrm{pred}(i)} f_p\\right),\n$$\nis well-defined only if the graph $G$ is acyclic. A cycle, for instance $i_1 \\rightarrow i_2 \\rightarrow \\dots \\rightarrow i_k \\rightarrow i_1$, would imply that the start time of task $i_1$ depends on its own completion, a logical impossibility leading to an undefined schedule. Therefore, the first step is to verify that $G$ is a DAG.\n\nThis validation is performed using a Depth-First Search (DFS) traversal. We maintain the state of each node using three sets:\n1.  A `white` set, containing all unvisited nodes.\n2.  A `gray` set, containing nodes currently being visited (i.e., nodes in the current recursion stack of the DFS).\n3.  A `black` set, containing nodes that have been fully explored (i.e., the DFS has visited the node and all of its descendants).\n\nThe algorithm proceeds by initiating a DFS from each node in the `white` set. When visiting a node $u$, it is moved from the `white` set to the `gray` set. For each neighbor $v$ of $u$, we check its state. If $v$ is in the `gray` set, a back edge has been detected, which implies the existence of a cycle. In this case, the graph is not a DAG, and the problem instance is invalid, for which a result of $-1$ is returned. If the DFS completes for all nodes without detecting a back edge, the graph is a DAG.\n\nA valuable byproduct of this DFS traversal is a topological sort of the graph's nodes. A topological sort is a linear ordering of the nodes such that for every directed edge from node $u$ to node $v$, $u$ comes before $v$ in the ordering. Such an ordering exists if and only if the graph is a DAG. By recording the nodes in the order they are moved from the `gray` to the `black` set, and then reversing this list, we obtain a valid topological ordering. This ordering is essential for the next stage.\n\n**Stage 2: Earliest-Feasible Schedule Computation**\n\nGiven that the precedence graph is a DAG, we can compute the actual start time $a_i$ and finish time $f_i$ for each task $i$. The computation relies on the topological sort obtained in Stage 1. By processing the tasks in topological order, we guarantee that when we compute the start time $a_i$ for task $i$, the actual finish times $f_p$ for all its predecessors $p \\in \\mathrm{pred}(i)$ have already been determined.\n\nThe process is as follows:\nInitialize an array for actual finish times, $f$, for all tasks (e.g., to $-\\infty$).\nIterate through each task $i$ according to the topological sort:\n1.  Determine the finish time of the latest-finishing predecessor: $f_{\\max\\_pred} = \\max_{p \\in \\mathrm{pred}(i)} f_p$. By convention, this maximum is $-\\infty$ if the set of predecessors $\\mathrm{pred}(i)$ is empty.\n2.  Calculate the actual start time $a_i$ by taking the maximum of the task's planned start time $s_i$ and the latest predecessor finish time: $a_i = \\max(s_i, f_{\\max\\_pred})$\n3.  Calculate the actual finish time $f_i$ by adding the task's duration $d_i = e_i - s_i$ to its actual start time: $f_i = a_i + d_i$\n\nAfter iterating through all tasks, we will have determined the set of actual execution intervals $\\{[a_i, f_i) \\mid i \\in V\\}$.\n\n**Stage 3: Minimal Track Allocation via Maximum Overlap Calculation**\n\nThe final stage is to solve the interval partitioning problem for the computed set of actual intervals $\\{[a_i, f_i)\\}$. The objective is to assign each task (interval) to a resource track such that no two tasks on the same track overlap in time, minimizing the total number of tracks used. A fundamental result in this area states that this minimum number of tracks is equal to the maximum depth of the set of intervals, which is the maximum number of intervals that overlap at any single point in time.\n\nWe can efficiently compute this maximum overlap using a sweep-line algorithm. The algorithm treats the start and end points of the intervals as \"events\" occurring along a time axis.\n1.  For each interval $[a_i, f_i)$, create two event points: a start event $(a_i, +1)$ and an end event $(f_i, -1)$. The value $+1$ signifies the beginning of an interval, increasing the overlap count, while $-1$ signifies the end, decreasing it.\n2.  Collect all event points into a single list.\n3.  Sort this list of events. The primary sorting key is the time of the event. The secondary sorting key is the event type. Because the intervals are half-open, $[a_i, f_i)$, a task finishing at time $t$ does not overlap with a task starting at $t$. To model this correctly, an end event $(-1)$ at time $t$ must be processed before a start event $(+1)$ at the same time $t$. Therefore, we sort events in ascending order of time, and for ties in time, in ascending order of event type (i.e., $-1$ before $+1$).\n4.  Initialize a counter for the current number of overlapping intervals, `current_overlap`, to $0$, and a variable for the maximum overlap found so far, `max_overlap`, to $0$.\n5.  Iterate through the sorted list of events. For each event $(t, \\text{type})$:\n    a. Update the overlap counter: `current_overlap = current_overlap + type`.\n    b. Update the maximum overlap: `max_overlap = max(max_overlap, current_overlap)`.\n\nAfter processing all events, `max_overlap` will hold the maximum number of intervals that overlap at any point, which is the minimum number of tracks required. This integer value is the result for the given test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print results.\n    \"\"\"\n    # Test cases defined in the problem statement.\n    # Each case is a tuple: (starts, ends, predecessors)\n    # The number of tasks is inferred from the length of the starts list.\n    test_cases = [\n        # Test case 1\n        (\n            np.array([0, 1, 2, 3, 0]),\n            np.array([3, 4, 5, 7, 2]),\n            {0: [], 1: [0], 2: [0], 3: [1, 2], 4: []}\n        ),\n        # Test case 2\n        (\n            np.array([0, 1, 2]),\n            np.array([2, 3, 4]),\n            {0: [], 1: [], 2: []}\n        ),\n        # Test case 3\n        (\n            np.array([0, 0, 0]),\n            np.array([3, 3, 3]),\n            {0: [], 1: [0], 2: [1]}\n        ),\n        # Test case 4\n        (\n            np.array([0, 0, 0, 0, 1]),\n            np.array([1, 2, 2, 2, 2]),\n            {0: [], 1: [0], 2: [0], 3: [0], 4: []}\n        ),\n        # Test case 5\n        (\n            np.array([0, 0]),\n            np.array([1, 1]),\n            {0: [1], 1: [0]}\n        ),\n    ]\n\n    results = []\n    for s, e, preds in test_cases:\n        result = compute_tracks(s, e, preds)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_tracks(s_planned, e_planned, predecessors):\n    \"\"\"\n    Computes the minimum number of tracks for a single test case.\n    \n    This function implements the three-stage process:\n    1. DAG validation and topological sorting.\n    2. Earliest-feasible schedule calculation.\n    3. Maximum overlap calculation using a sweep-line algorithm.\n    \n    Returns -1 if the precedence graph contains a cycle.\n    \"\"\"\n    num_tasks = len(s_planned)\n    \n    # --- Stage 1: DAG Validation and Topological Sort ---\n    \n    # Build a forward adjacency list from the predecessor list\n    adj = {i: [] for i in range(num_tasks)}\n    for i, preds in predecessors.items():\n        for p in preds:\n            adj[p].append(i)\n\n    # Sets for DFS-based cycle detection\n    # white_set (unvisited): nodes not in visiting_set or visited_set\n    # gray_set (visiting): nodes in the current recursion stack\n    # black_set (visited): nodes fully explored\n    visiting_set = set()\n    visited_set = set()\n    topo_order = []\n    \n    has_cycle = [False] # Use a list to make it mutable inside the nested function\n\n    def dfs(u):\n        if has_cycle[0]:\n            return\n\n        visiting_set.add(u)\n\n        for v in adj.get(u, []):\n            if v in visiting_set:\n                has_cycle[0] = True\n                return\n            if v not in visited_set:\n                dfs(v)\n        \n        visiting_set.remove(u)\n        visited_set.add(u)\n        topo_order.append(u)\n\n    for i in range(num_tasks):\n        if i not in visited_set:\n            dfs(i)\n\n    if has_cycle[0]:\n        return -1\n    \n    topo_order.reverse() # The reverse of post-order traversal is a topological sort\n\n    # --- Stage 2: Earliest-Feasible Schedule Calculation ---\n    \n    durations = e_planned - s_planned\n    f_actual = np.full(num_tasks, -np.inf, dtype=float)\n    a_actual = np.zeros(num_tasks, dtype=float)\n\n    for i in topo_order:\n        max_pred_finish_time = -np.inf\n        if predecessors[i]:\n            pred_finish_times = [f_actual[p] for p in predecessors[i]]\n            max_pred_finish_time = max(pred_finish_times)\n        \n        a_actual[i] = max(s_planned[i], max_pred_finish_time)\n        f_actual[i] = a_actual[i] + durations[i]\n\n    # --- Stage 3: Minimal Track Allocation (Max Overlap) ---\n    \n    events = []\n    for i in range(num_tasks):\n        events.append((a_actual[i], 1))  # Start of an interval\n        events.append((f_actual[i], -1)) # End of an interval\n\n    # Sort events: primary key is time, secondary key is type (-1 before 1).\n    # This correctly handles intervals [s, e) where an interval ending at t\n    # does not overlap with one starting at t.\n    events.sort(key=lambda x: (x[0], x[1]))\n\n    max_overlap = 0\n    current_overlap = 0\n    for time, type in events:\n        current_overlap += type\n        if current_overlap  max_overlap:\n            max_overlap = current_overlap\n            \n    return max_overlap\n\nsolve()\n\n```"
        }
    ]
}