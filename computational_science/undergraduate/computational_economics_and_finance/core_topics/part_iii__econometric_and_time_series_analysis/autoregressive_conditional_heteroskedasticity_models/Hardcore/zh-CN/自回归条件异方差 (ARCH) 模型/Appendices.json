{
    "hands_on_practices": [
        {
            "introduction": "在使用任何模型之前，我们必须理解其基本属性。对于 GARCH 模型，协方差平稳性至关重要，它确保了波动率存在一个稳定的长期均值。此练习将通过模拟位于此临界边界两侧的过程，将抽象的数学条件 $\\alpha_1 + \\beta_1 \\lt 1$ 与其可观察到的后果联系起来，从而帮助您深入理解平稳性的实际意义。",
            "id": "2373513",
            "problem": "考虑一个阶数为 $\\left(1,1\\right)$ 的广义自回归条件异方差（GARCH）模型，用于描述一个零均值收益率过程 $\\left\\{r_t\\right\\}$，该过程由以下随机差分方程定义\n$$r_t \\;=\\; \\sigma_t\\,\\varepsilon_t,$$\n$$\\sigma_t^2 \\;=\\; \\omega \\;+\\; \\alpha_1\\,r_{t-1}^2 \\;+\\; \\beta_1\\,\\sigma_{t-1}^2,$$\n其中 $\\left\\{\\varepsilon_t\\right\\}$ 是独立同分布（IID）的，且 $\\mathbb{E}\\!\\left[\\varepsilon_t\\right]=0$ 和 $\\mathbb{E}\\!\\left[\\varepsilon_t^2\\right]=1$，并且 $\\omega \\gt 0$、$\\alpha_1 \\ge 0$、$\\beta_1 \\ge 0$。在计算经济学和金融学中，一个关键问题是协方差平稳性，即是否存在一个有限的、不随时间变化的无条件二阶矩 $\\mathbb{E}\\!\\left[r_t^2\\right]$。\n\n你的任务如下。\n\n任务 A：仅从模型定义、迭代期望定律和独立性定律出发，推导无条件二阶矩 $\\mu_t \\equiv \\mathbb{E}\\!\\left[r_t^2\\right] = \\mathbb{E}\\!\\left[\\sigma_t^2\\right]$ 所满足的标量线性递归关系，并确定一个用 $\\alpha_1$ 和 $\\beta_1$ 表示的、使得当 $t \\to \\infty$ 时 $\\mu_t$ 收敛于一个有限极限的必要且充分条件。如果该极限存在，请用 $\\omega$、$\\alpha_1$ 和 $\\beta_1$ 将其符号化表示出来。\n\n任务 B：设计一个算法，在给定参数 $\\left(\\omega,\\alpha_1,\\beta_1\\right)$ 的情况下，通过对 GARCH$\\left(1,1\\right)$ 过程进行长时模拟，并通过验证以下两个属性来经验性地评估其协方差平稳性：\n- 收敛性：当理论无条件二阶矩存在时，$r_t^2$ 的长期样本均值应接近于任务 A 中得到的理论值。\n- 稳定性：在预烧期（burn-in）后的样本中，对大小相等、连续的时间块计算出的 $r_t^2$ 的块均值应相互稳定，且不表现出持续的漂移。您的算法应通过一个量化诊断指标来操作化稳定性，该指标需比较序列的早期和晚期片段，并包含一个跨块的离散度度量。\n\n任务 C：实现一个完整、可运行的程序，该程序：\n- 对以下测试套件中的每组参数，使用 IID 标准正态新息来模拟模型，总长度 $T = 120{,}000$，并在进行诊断前丢弃 $B = 20{,}000$ 个观测值作为预烧期。将 $\\sigma_0^2$ 初始化为一个与所有情况兼容的严格正有限值。使用固定的随机种子以确保可复现性。\n- 对预烧期后的样本使用 $K = 8$ 个大小相等的块来计算 $r_t^2$ 的块均值。\n- 根据以下量化标准，将每个测试用例分类为协方差平稳或非协方差平稳：\n  - 令 $\\widehat{m}$ 表示预烧期后样本中 $r_t^2$ 的样本均值，令 $m^\\star$ 表示任务 A 中得到的理论无条件二阶矩（当其存在时）。定义相对误差为 $\\left|\\widehat{m} - m^\\star\\right|/m^\\star$。\n  - 令 $m_{\\text{first}}$ 和 $m_{\\text{last}}$ 分别为预烧期后样本的第一个和最后一个四分之一部分中 $r_t^2$ 的样本均值，并定义增长率 $d \\equiv m_{\\text{last}}/m_{\\text{first}}$。\n  - 令 $m_1,\\dots,m_K$ 为块均值，并定义变异系数 $\\mathrm{CV} \\equiv \\mathrm{sd}\\!\\left(m_1,\\dots,m_K\\right)/\\overline{m}$，其中 $\\overline{m}$ 是 $K$ 个块均值的算术平均值。\n  - 当且仅当理论无条件二阶矩存在，并且以下所有条件同时成立时，将一组参数分类为协方差平稳：相对误差至多为 $\\tau = 0.10$，增长率满足 $d \\le \\rho = 1.20$，块稳定性满足 $\\mathrm{CV} \\le \\kappa = 0.20$。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目都是一个布尔值，按下面给出的顺序对应于相关测试用例的分类结果，且不含空格。\n\n测试套件：\n- 情况 A (和略小于 $1$)：$\\omega = 0.1$, $\\alpha_1 = 0.05$, $\\beta_1 = 0.90$。\n- 情况 B (和等于 $1$)：$\\omega = 0.1$, $\\alpha_1 = 0.05$, $\\beta_1 = 0.95$。\n- 情况 C (和略大于 $1$)：$\\omega = 0.1$, $\\alpha_1 = 0.05$, $\\beta_1 = 0.98$。\n\n答案规范：\n- 最终输出必须是单行，包含一个恰好按 $\\left[\\text{情况 A},\\text{情况 B},\\text{情况 C}\\right]$ 顺序排列的三个布尔值的列表，例如 $\\left[\\text{True},\\text{False},\\text{False}\\right]$。\n- 不涉及物理单位。所有数值阈值必须完全按照上述规定实现。",
            "solution": "该问题要求对 GARCH$\\left(1,1\\right)$ 模型进行两部分分析：首先，对协方差平稳性的条件进行理论推导；其次，设计并实现一个基于模拟的、针对此属性的经验性检验。\n\n我们从任务 A 中指定的理论推导开始。GARCH$\\left(1,1\\right)$ 模型由以下方程定义：\n$$r_t = \\sigma_t \\varepsilon_t$$\n$$\\sigma_t^2 = \\omega + \\alpha_1 r_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2$$\n其中 $\\left\\{\\varepsilon_t\\right\\}$ 是一个 IID 过程，满足 $\\mathbb{E}[\\varepsilon_t] = 0$ 和 $\\mathbb{E}[\\varepsilon_t^2] = 1$。参数满足 $\\omega  0$，$\\alpha_1 \\ge 0$，且 $\\beta_1 \\ge 0$。我们关心的是无条件二阶矩 $\\mu_t \\equiv \\mathbb{E}[r_t^2]$。\n\n令 $\\mathcal{F}_{t-1}$ 表示在时间 $t-1$ 可用的信息所构成的 $\\sigma$-代数，其包含 $\\varepsilon_t$ 的所有过去值。根据定义，$\\sigma_t^2$ 是过去收益率和方差的函数，因此是 $\\mathcal{F}_{t-1}$-可测的。新息 $\\varepsilon_t$ 与 $\\mathcal{F}_{t-1}$ 独立。\n\n首先，我们建立恒等式 $\\mu_t = \\mathbb{E}[\\sigma_t^2]$。使用迭代期望定律：\n$$\\mu_t = \\mathbb{E}[r_t^2] = \\mathbb{E}[\\sigma_t^2 \\varepsilon_t^2] = \\mathbb{E}\\left[\\mathbb{E}[\\sigma_t^2 \\varepsilon_t^2 | \\mathcal{F}_{t-1}]\\right]$$\n由于 $\\sigma_t^2$ 是 $\\mathcal{F}_{t-1}$-可测的，且 $\\varepsilon_t$ 独立于 $\\mathcal{F}_{t-1}$：\n$$\\mathbb{E}[\\sigma_t^2 \\varepsilon_t^2 | \\mathcal{F}_{t-1}] = \\sigma_t^2 \\mathbb{E}[\\varepsilon_t^2 | \\mathcal{F}_{t-1}] = \\sigma_t^2 \\mathbb{E}[\\varepsilon_t^2] = \\sigma_t^2 \\cdot 1 = \\sigma_t^2$$\n将其代回，我们得到：\n$$\\mu_t = \\mathbb{E}[\\sigma_t^2]$$\n这证实了问题陈述中提供的恒等式。\n\n接下来，我们推导 $\\mu_t$ 的递归关系。我们对条件方差方程取无条件期望：\n$$\\mathbb{E}[\\sigma_t^2] = \\mathbb{E}[\\omega + \\alpha_1 r_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2]$$\n根据期望算子的线性性质：\n$$\\mathbb{E}[\\sigma_t^2] = \\omega + \\alpha_1 \\mathbb{E}[r_{t-1}^2] + \\beta_1 \\mathbb{E}[\\sigma_{t-1}^2]$$\n使用我们的定义 $\\mu_t = \\mathbb{E}[\\sigma_t^2]$ 和 $\\mu_{t-1} = \\mathbb{E}[r_{t-1}^2] = \\mathbb{E}[\\sigma_{t-1}^2]$，我们得到无条件二阶矩的标量线性递归关系：\n$$\\mu_t = \\omega + (\\alpha_1 + \\beta_1) \\mu_{t-1}$$\n这是一个一阶线性非齐次递归关系。为了使 $\\mu_t$ 在 $t \\to \\infty$ 时收敛到一个有限的、不随时间变化的极限 $\\mu$，动态项的系数的绝对值必须小于 1。考虑到非负约束 $\\alpha_1 \\ge 0$ 和 $\\beta_1 \\ge 0$，存在一个有限的、不随时间变化的二阶矩的必要且充分条件是：\n$$\\alpha_1 + \\beta_1  1$$\n如果此条件成立，则称该过程为弱平稳或协方差平稳。极限无条件方差（我们记为 $m^\\star$）可以通过在递归关系中设定 $\\mu_t = \\mu_{t-1} = m^\\star$ 来找到，从而得到不动点方程：\n$$m^\\star = \\omega + (\\alpha_1 + \\beta_1) m^\\star$$\n求解 $m^\\star$ 即可得到理论无条件二阶矩的表达式：\n$$m^\\star = \\frac{\\omega}{1 - \\alpha_1 - \\beta_1}$$\n这一理论基础直接为任务 B 和 C 的算法设计提供了依据。\n\n经验性评估协方差平稳性的算法流程如下。\n1.  **理论预检验**：对于给定的参数集 $(\\omega, \\alpha_1, \\beta_1)$，首先检查条件 $\\alpha_1 + \\beta_1  1$。如果不满足该条件，则该过程立即被分类为非协方差平稳，因为理论无条件二阶矩不存在。\n2.  **模拟**：如果通过了预检验，则模拟一个长度为 $T = 120,000$ 的 GARCH$\\left(1,1\\right)$ 过程。新息 $\\varepsilon_t$ 从一个 IID 标准正态分布中抽取。为确保可复现性，使用一个固定的随机种子。模拟从一个初始方差 $\\sigma_0^2 > 0$ 开始。\n3.  **数据准备**：丢弃前 $B = 20,000$ 个数据点作为预烧期，以消除对初始条件的依赖。分析在随后的 $N = 100,000$ 个收益率平方的样本 $\\{r_t^2\\}_{t=B}^{T-1}$ 上进行。\n4.  **诊断评估**：计算三个量化指标以评估收敛性和稳定性。\n    a.  **收敛性标准**：计算预烧期后收益率平方的样本均值 $\\widehat{m}$。其相对于理论值 $m^\\star$ 的相对误差（由 $|\\widehat{m} - m^\\star|/m^\\star$ 给出）必须小于或等于容差 $\\tau = 0.10$。\n    b.  **稳定性标准（趋势）**：将预烧期后的样本分为四个相等的季度。计算最后一个季度的均值（$m_{\\text{last}}$）与第一个季度的均值（$m_{\\text{first}}$）之比，记为 $d = m_{\\text{last}}/m_{\\text{first}}$。平稳序列不应表现出显著的漂移，因此该比率必须小于或等于阈值 $\\rho = 1.20$。\n    c.  **稳定性标准（离散度）**：将预烧期后的样本划分为 $K=8$ 个大小相等的不重叠块。计算每个块的均值 $m_k$。过程的稳定性通过这些块均值的变异系数（CV）来评估，$\\mathrm{CV} = \\mathrm{sd}(m_1, \\dots, m_K) / \\overline{m}$，其中 $\\mathrm{sd}(\\cdot)$ 是样本标准差，$\\overline{m}$ 是块均值的均值。较低的 CV 表示方差在整个样本中是稳定的。该值必须小于或等于阈值 $\\kappa = 0.20$。\n5.  **最终分类**：当且仅当理论条件 $\\alpha_1 + \\beta_1  1$ 得到满足，并且所有三个经验标准（相对误差、增长率、块 CV）均满足其指定阈值时，一组参数才被分类为协方差平稳。否则，它被分类为非协方差平稳。对每个测试用例都执行此完整过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_garch_analysis(omega, alpha_1, beta_1, T, B, K, tau, rho, kappa, eps_series):\n    \"\"\"\n    Simulates a GARCH(1,1) process and assesses covariance stationarity.\n\n    Args:\n        omega (float): GARCH parameter.\n        alpha_1 (float): GARCH parameter.\n        beta_1 (float): GARCH parameter.\n        T (int): Total length of the simulation.\n        B (int): Length of the burn-in period.\n        K (int): Number of blocks for stability analysis.\n        tau (float): Relative error threshold.\n        rho (float): Growth ratio threshold.\n        kappa (float): Block stability (CV) threshold.\n        eps_series (np.ndarray): Pre-generated standard normal innovations.\n\n    Returns:\n        bool: True if classified as covariance-stationary, False otherwise.\n    \"\"\"\n    # Step 1: Theoretical Pre-check\n    if alpha_1 + beta_1 >= 1:\n        return False\n\n    # Theoretical unconditional second moment\n    m_star = omega / (1 - alpha_1 - beta_1)\n\n    # Step 2: Simulation\n    sigma_sq = np.zeros(T)\n    r_sq = np.zeros(T)\n    \n    # Initialization: choose a positive finite value compatible with all cases,\n    # as required by the problem.\n    sigma_sq[0] = 0.1\n\n    for t in range(T - 1):\n        r_sq[t] = sigma_sq[t] * eps_series[t]**2\n        sigma_sq[t+1] = omega + alpha_1 * r_sq[t] + beta_1 * sigma_sq[t]\n    \n    # Compute the last value of r_sq\n    r_sq[T-1] = sigma_sq[T-1] * eps_series[T-1]**2\n\n    # Step 3: Data Preparation\n    analysis_sample = r_sq[B:]\n    N = T - B\n    \n    # Step 4: Diagnostic Evaluation\n    \n    # a. Convergence Criterion\n    m_hat = np.mean(analysis_sample)\n    relative_error = np.abs(m_hat - m_star) / m_star\n    \n    # b. Stability Criterion (Trend)\n    n_quarter = N // 4\n    m_first = np.mean(analysis_sample[:n_quarter])\n    m_last = np.mean(analysis_sample[-n_quarter:])\n    \n    # To avoid division by zero if m_first happens to be pathologically small\n    if m_first = 0:\n        growth_ratio = float('inf')\n    else:\n        growth_ratio = m_last / m_first\n\n    # c. Stability Criterion (Dispersion)\n    block_size = N // K\n    block_means = np.array([\n        np.mean(analysis_sample[k*block_size : (k+1)*block_size]) for k in range(K)\n    ])\n    mean_of_block_means = np.mean(block_means) # This is equivalent to m_hat\n    \n    if mean_of_block_means = 0:\n        cv = float('inf')\n    else:\n        # Use ddof=1 for sample standard deviation\n        cv = np.std(block_means, ddof=1) / mean_of_block_means\n\n    # Step 5: Final Classification\n    is_conv_ok = relative_error = tau\n    is_growth_ok = growth_ratio = rho\n    is_stability_ok = cv = kappa\n\n    return is_conv_ok and is_growth_ok and is_stability_ok\n\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases.\n    \"\"\"\n    # Define parameters from the problem statement.\n    T = 120000\n    B = 20000\n    K = 8\n    tau = 0.10\n    rho = 1.20\n    kappa = 0.20\n\n    # Define the test cases.\n    test_cases = [\n        {'name': 'Case A', 'omega': 0.1, 'alpha_1': 0.05, 'beta_1': 0.90},\n        {'name': 'Case B', 'omega': 0.1, 'alpha_1': 0.05, 'beta_1': 0.95},\n        {'name': 'Case C', 'omega': 0.1, 'alpha_1': 0.05, 'beta_1': 0.98},\n    ]\n\n    # Set a fixed random seed for reproducibility of the entire program run.\n    # The same stream of random numbers will be used sequentially for all cases.\n    np.random.seed(42)\n    \n    # Pre-generate all random numbers needed.\n    eps_series = np.random.standard_normal(T)\n\n    results = []\n    for case in test_cases:\n        is_stationary = run_garch_analysis(\n            omega=case['omega'],\n            alpha_1=case['alpha_1'],\n            beta_1=case['beta_1'],\n            T=T, B=B, K=K,\n            tau=tau, rho=rho, kappa=kappa,\n            eps_series=eps_series\n        )\n        results.append(is_stationary)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理解模型属性之后，建模过程中的一个关键任务是为给定的数据集选择合适的模型。这个选择并非总是显而易见的，因为更复杂的模型虽然能更好地拟合数据，但会因其缺乏简约性而受到惩罚。本练习通过使用贝叶斯信息准则 (BIC) 来比较 GARCH 模型和更简单的 ARCH 模型，探讨了这种在拟合优度与简约性之间的权衡，并展示了模型选择在实践中可能遇到的挑战。",
            "id": "2373512",
            "problem": "您需要编写一个完整、可执行的程序，该程序构建模拟的金融收益序列，并使用高斯拟最大概似估计 (QMLE) 来评估两种波动率模型之间的模型选择。此任务的框架是自回归条件异方差，特别是在数据由低持续性的 GARCH(1,1) 过程生成时，比较一个一阶自回归条件异方差 (ARCH(1)) 模型与一个广义自回归条件异方差 GARCH(1,1) 模型。\n\n请从以下核心定义和广泛接受的事实开始：\n\n- 一个均值为零的收益序列 $\\{r_t\\}_{t=1}^T$ 具有条件异方差性，其模型为 $r_t = \\sigma_t z_t$，其中 $\\{z_t\\}$ 是独立同分布的标准常态变量，而 $\\sigma_t^2$ 是条件方差。\n- ARCH($p$) 模型将条件方差指定为 $\\sigma_t^2 = \\omega + \\sum_{i=1}^p \\alpha_i r_{t-i}^2$，其中 $\\omega  0$，$\\alpha_i \\ge 0$，且 $\\sum_{i=1}^p \\alpha_i  1$ 以满足协方差平稳性。\n- GARCH(1,1) 模型将条件方差指定为 $\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2$，其中 $\\omega  0$，$\\alpha \\ge 0$，$\\beta \\ge 0$，且 $\\alpha + \\beta  1$ 以满足协方差平稳性。\n- 在高斯 QMLE 下，在一个产生 $\\{\\sigma_t^2(\\theta)\\}$ 的参数化波动率递归关系（参数为 $\\theta$）中，其对数概似为\n$$\n\\ell_T(\\theta) = -\\frac{1}{2} \\sum_{t=1}^T \\left( \\log(2\\pi) + \\log\\left(\\sigma_t^2(\\theta)\\right) + \\frac{r_t^2}{\\sigma_t^2(\\theta)} \\right).\n$$\n- 对于一个有 $k$ 个自由参数和样本大小为 $n$ 的模型，其贝叶斯信息准则 (BIC) 为\n$$\n\\mathrm{BIC} = -2 \\ell_T(\\hat{\\theta}) + k \\log(n),\n$$\n其中 $\\hat{\\theta}$ 是最大化对数概似的参数。\n\n您的程序必须：\n\n1. 对于每个测试用例，从一个 GARCH(1,1) 过程中模拟一个收益序列 $\\{r_t\\}_{t=1}^T$，使用给定的参数和低持续性（即 $\\alpha + \\beta$ 严格小于 $1$ 且数值上较小）。使用标准正态创新项 $\\{z_t\\}$，并设定一个固定的 $B = 1000$ 个观测值的预烧期，在保留最后的 $T$ 个观测值之前丢弃，以减轻初始条件的影响。使用无条件方差作为初始方差，即 $\\sigma_0^2 = \\omega / (1 - \\alpha - \\beta)$。\n2. 通过高斯 QMLE 拟合以下两个模型：\n   - 一个指定阶数 $p$ 的 ARCH($p$) 模型。\n   - 一个 GARCH(1,1) 模型。\n   估计过程必须遵守上述的正性和定态性约束。您可以使用任何数值上稳定、可微分的重新参数化方法来在优化过程中施加这些约束。\n3. 对于每个拟合的模型，计算其最大化的对数似然和 BIC。ARCH($p$) 的 $k = 1 + p$，GARCH(1,1) 的 $k = 3$，且 $n = T$。\n4. 定义一个布尔值指标，表示模拟数据集是否“欺骗”了标准的 ARCH($p$) 模型。如果当数据由 GARCH(1,1) 生成时，ARCH($p$) 的 BIC 严格小于 GARCH(1,1) 的 BIC，则该指标为真。也就是说，如果 $\\mathrm{BIC}_{\\mathrm{ARCH}(p)}  \\mathrm{BIC}_{\\mathrm{GARCH}(1,1)}$，则输出真。\n\n实现要求和数值细节：\n\n- 在两种模型的似然评估期间，使用与当前参数猜测相关的无条件方差来初始化递归。对于 ARCH($p$) 似然递归，使用此无条件方差初始化样本前的平方收益 $r_{t-i}^2$（对于 $i  t$）。\n- 使用标准正态创新项进行模拟。\n- 确保在模拟和似然评估的所有时间步中，条件方差保持严格为正。\n- 使用任何确定性的数值优化例程来最大化每个模型的高斯对数似然，通过对无约束参数进行平滑变换来强制执行约束。\n\n测试套件：\n\n对于以下三个参数集中的每一个，运行上述完整的模拟-估计-选择流程，并返回一个布尔结果，指示 BIC 是否选择了 ARCH($p$) 模型而不是 GARCH(1,1) 模型：\n\n- 测试用例 1 (典型情况，低持续性): $T = 1200$, $\\omega = 0.05$, $\\alpha = 0.08$, $\\beta = 0.18$, $p = 1$, 模拟种子 $= 11$。\n- 测试用例 2 (较小样本): $T = 800$, $\\omega = 0.10$, $\\alpha = 0.05$, $\\beta = 0.25$, $p = 1$, 模拟种子 $= 22$。\n- 测试用例 3 (接近白噪声波动率): $T = 1000$, $\\omega = 0.02$, $\\alpha = 0.03$, $\\beta = 0.05$, $p = 1$, 模拟种子 $= 33$。\n\n最终输出格式：\n\n- 您的程序应生成一行输出，其中包含对应于三个测试用例的三个布尔结果，以逗号分隔并用方括号括起来（例如，\"[True,False,True]\"）。",
            "solution": "此问题要求在金融计量经济学中实现一个数值实验。目标是评估贝叶斯信息准则 (BIC) 在模型选择中的表现，具体是在数据实际上由一个低持续性的 GARCH(1,1) 过程生成时，于 GARCH(1,1) 模型和一个更简单的 ARCH(p) 模型之间进行选择。此练习对于理解模型设定错误以及模型精简性与拟合优度之间的权衡至关重要。\n\n对于每个指定的测试用例，将遵循一个严谨的三步流程来执行此过程：数据模拟、模型估计和模型选择。\n\n**1. 数据模拟**\n\n此分析的基础是一个模拟的金融收益序列 $\\{r_t\\}_{t=1}^T$。此序列由 GARCH(1,1) 过程生成，其定义方程为：\n$$\nr_t = \\sigma_t z_t\n$$\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2\n$$\n其中 $\\{z_t\\}_{t=1}^T$ 是从标准正态分布 $z_t \\sim \\mathcal{N}(0, 1)$ 中抽取的独立同分布 (i.i.d.) 随机变量序列。参数 $(\\omega, \\alpha, \\beta)$ 由每个测试用例提供，并满足协方差平稳性条件：$\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, and $\\alpha + \\beta  1$。\n\n为了减轻初始条件对生成序列的影响，我们首先模拟一个长度为 $T + B$ 的更长序列，其中 $T$ 是期望的样本大小，$B = 1000$ 是预烧期。递归使用过程的无条件方差 $\\sigma_0^2 = \\frac{\\omega}{1 - \\alpha - \\beta}$ 进行初始化。然后丢弃前 $B$ 个模拟观测值，留下最终的序列 $\\{r_t\\}_{t=1}^T$ 用于分析。\n\n**2. 通过拟最大概似估计 (QMLE) 进行参数估计**\n\n对于每个模拟序列，我们拟合两个相互竞争的模型：一个 ARCH(p) 模型和一个 GARCH(1,1) 模型。估计是通过最大化高斯拟对数概似函数来执行的。假设高斯创新项，对于大小为 $T$ 的样本，给定参数向量 $\\theta$ 的对数概似函数为：\n$$\n\\ell_T(\\theta) = -\\frac{1}{2} \\sum_{t=1}^T \\left( \\log(2\\pi) + \\log\\left(\\sigma_t^2(\\theta)\\right) + \\frac{r_t^2}{\\sigma_t^2(\\theta)} \\right)\n$$\n最大化 $\\ell_T(\\theta)$ 等同于最小化其负值。为了优化目的，常数项 $-\\frac{T}{2}\\log(2\\pi)$ 可以被忽略，因为它不影响最大值的位置。因此，要最小化的目标函数是：\n$$\n\\mathcal{L}(\\theta) = \\sum_{t=1}^T \\left( \\log\\left(\\sigma_t^2(\\theta)\\right) + \\frac{r_t^2}{\\sigma_t^2(\\theta)} \\right)\n$$\n估计的一个关键方面是强制执行方差正性和定态性所需的参数约束。这通过平滑、可微分的重新参数化来实现，它允许无约束的数值最优化器在有效的参数空间内搜索。\n\n对于 GARCH(1,1) 模型，参数为 $\\theta_{GARCH} = (\\omega, \\alpha, \\beta)$。约束条件是 $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, and $\\alpha + \\beta  1$。我们将一个无约束的向量 $\\psi = (\\psi_0, \\psi_1, \\psi_2) \\in \\mathbb{R}^3$ 映射到约束空间，如下所示：\n- $\\omega = \\exp(\\psi_0)$\n- $\\alpha = \\frac{\\psi_1^2}{1 + \\psi_1^2}$\n- $\\beta = \\left(1 - \\alpha\\right) \\frac{\\psi_2^2}{1 + \\psi_2^2}$\n此构建保证所有约束均得到满足。\n\n对于 ARCH(p) 模型，其中所有测试用例中的 $p=1$，参数为 $\\theta_{ARCH} = (\\omega, \\alpha_1)$。约束条件是 $\\omega > 0$, $0 \\le \\alpha_1  1$。我们从一个无约束的向量 $\\phi = (\\phi_0, \\phi_1) \\in \\mathbb{R}^2$ 进行映射：\n- $\\omega = \\exp(\\phi_0)$\n- $\\alpha_1 = \\frac{\\exp(\\phi_1)}{1 + \\exp(\\phi_1)}$\n此转换确保 $\\omega > 0$ 且 $\\alpha_1 \\in (0, 1)$。\n\n在优化例程中每次评估概似函数时，都必须计算条件方差序列 $\\{\\sigma_t^2(\\theta)\\}_{t=1}^T$。递归使用*当前*参数猜测 $\\theta$ 所隐含的无条件方差进行初始化。对于 GARCH(1,1)，样本前的 $r_0^2$ 和 $\\sigma_0^2$ 被设置为 $\\frac{\\omega}{1-\\alpha-\\beta}$。对于 ARCH(1)，样本前的 $r_0^2$ 被设置为 $\\frac{\\omega}{1-\\alpha_1}$。\n\n**3. 通过贝叶斯信息准则 (BIC) 进行模型选择**\n\n在获得每个模型的最大化对数概似值 $\\ell_T(\\hat{\\theta})$ 后，我们计算 BIC：\n$$\n\\mathrm{BIC} = -2 \\ell_T(\\hat{\\theta}) + k \\log(n)\n$$\n其中 $\\hat{\\theta}$ 是估计的参数向量，$k$ 是模型中的自由参数数量，$n=T$ 是样本大小。BIC 对模型的复杂性进行惩罚，其中 $k \\log(n)$ 项代表惩罚。较低的 BIC 值表示更受青睐的模型。\n- 对于 ARCH($p$) 模型，$k = p + 1$。由于 $p=1$，$k_{ARCH} = 2$。\n- 对于 GARCH(1,1) 模型，$k_{GARCH} = 3$。\n\n每个测试用例的最终输出是一个布尔值，指示 ARCH(p) 模型是否“欺骗”了选择准则。如果其 BIC 严格小于 GARCH(1,1) 模型的 BIC，即 $\\mathrm{BIC}_{\\mathrm{ARCH}(p)}  \\mathrm{BIC}_{\\mathrm{GARCH}(1,1)}$，则为真。此结果表明，尽管数据源自 GARCH 过程，但由于 BIC 对 GARCH 模型额外参数的惩罚，更精简的 ARCH 模型更受青睐。当真实的 GARCH 过程具有低持续性（小的 $\\alpha+\\beta$）时，这种情况更有可能发生，使其难以与更简单的 ARCH 过程区分开来，尤其是在样本量较小的情况下。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef simulate_garch11(T, B, omega, alpha, beta, seed):\n    \"\"\"\n    Simulates a GARCH(1,1) process.\n    \"\"\"\n    np.random.seed(seed)\n    total_len = T + B\n    \n    # Generate standard normal innovations\n    z = np.random.randn(total_len)\n    \n    r = np.zeros(total_len)\n    sigma2 = np.zeros(total_len)\n    \n    # Initial variance (unconditional variance)\n    uncond_var = omega / (1 - alpha - beta)\n    sigma2_t_minus_1 = uncond_var\n    # Use E[r_{t-1}^2] = sigma_{t-1}^2 for initialization of first r_t\n    r_t_minus_1_sq = uncond_var\n    \n    for t in range(total_len):\n        sigma2[t] = omega + alpha * r_t_minus_1_sq + beta * sigma2_t_minus_1\n        r[t] = np.sqrt(sigma2[t]) * z[t]\n        \n        sigma2_t_minus_1 = sigma2[t]\n        r_t_minus_1_sq = r[t]**2\n        \n    # Discard burn-in period\n    return r[B:]\n\ndef garch11_neg_loglike_factory(r):\n    \"\"\"\n    Factory for the negative log-likelihood of a GARCH(1,1) model.\n    \"\"\"\n    T = len(r)\n    r_sq = r**2\n\n    def neg_loglike(unconstrained_params):\n        # 1. Reparameterize to enforce constraints\n        psi_0, psi_1, psi_2 = unconstrained_params\n        omega = np.exp(psi_0)\n        # alpha is in [0, 1)\n        alpha = psi_1**2 / (1 + psi_1**2)\n        # beta is in [0, 1-alpha)\n        beta = (1 - alpha) * (psi_2**2 / (1 + psi_2**2))\n        \n        # 2. Check for stationarity to avoid division by zero\n        if (alpha + beta) >= 1.0:\n            return 1e9 # Return a large value if non-stationary\n\n        # 3. Calculate conditional variances\n        sigma2 = np.zeros(T)\n        uncond_var = omega / (1 - alpha - beta)\n        \n        # Initialize with unconditional variance\n        sigma2[0] = omega + alpha * uncond_var + beta * uncond_var\n        \n        for t in range(1, T):\n            sigma2[t] = omega + alpha * r_sq[t-1] + beta * sigma2[t-1]\n\n        # Prevent numerical issues with very small variances\n        sigma2 = np.maximum(sigma2, 1e-9)\n\n        # 4. Calculate log-likelihood\n        log_likelihood_sum = np.sum(np.log(sigma2) + r_sq / sigma2)\n        \n        return 0.5 * log_likelihood_sum\n\n    return neg_loglike\n\ndef arch1_neg_loglike_factory(r):\n    \"\"\"\n    Factory for the negative log-likelihood of an ARCH(1) model.\n    \"\"\"\n    T = len(r)\n    r_sq = r**2\n\n    def neg_loglike(unconstrained_params):\n        # 1. Reparameterize to enforce constraints\n        phi_0, phi_1 = unconstrained_params\n        omega = np.exp(phi_0)\n        # alpha1 is in (0, 1)\n        alpha1 = np.exp(phi_1) / (1 + np.exp(phi_1))\n\n        # 2. Check for stationarity\n        if alpha1 >= 1.0:\n            return 1e9\n        \n        # 3. Calculate conditional variances\n        sigma2 = np.zeros(T)\n        uncond_var = omega / (1 - alpha1)\n        \n        # Initialize with unconditional variance for pre-sample r_0^2\n        sigma2[0] = omega + alpha1 * uncond_var\n        \n        for t in range(1, T):\n            sigma2[t] = omega + alpha1 * r_sq[t-1]\n        \n        # Prevent numerical issues\n        sigma2 = np.maximum(sigma2, 1e-9)\n\n        # 4. Calculate log-likelihood\n        log_likelihood_sum = np.sum(np.log(sigma2) + r_sq / sigma2)\n        \n        return 0.5 * log_likelihood_sum\n\n    return neg_loglike\n    \ndef solve():\n    \"\"\"\n    Main function to run test cases and generate final output.\n    \"\"\"\n    test_cases = [\n        # T, omega, alpha, beta, p, seed\n        (1200, 0.05, 0.08, 0.18, 1, 11),\n        (800, 0.10, 0.05, 0.25, 1, 22),\n        (1000, 0.02, 0.03, 0.05, 1, 33),\n    ]\n\n    results = []\n    B = 1000 # Burn-in period\n\n    for case in test_cases:\n        T, omega_true, alpha_true, beta_true, p, seed = case\n        \n        # 1. Simulate data from GARCH(1,1)\n        r_sim = simulate_garch11(T, B, omega_true, alpha_true, beta_true, seed)\n        \n        # 2. Fit GARCH(1,1) model\n        garch_objective = garch11_neg_loglike_factory(r_sim)\n        # Initial guess for unconstrained params (psi_0, psi_1, psi_2)\n        # Corresponds roughly to omega=0.1, alpha=0.1, beta=0.8\n        x0_garch = [-2.3, 0.33, 2.8] \n        garch_res = minimize(garch_objective, x0_garch, method='BFGS')\n        \n        # maximized log-likelihood value (without constant)\n        min_neg_ll_garch = garch_res.fun\n        \n        # 3. Fit ARCH(p) model (here p=1)\n        arch_objective = arch1_neg_loglike_factory(r_sim)\n        # Initial guess for unconstrained params (phi_0, phi_1)\n        # Corresponds roughly to omega=0.1, alpha1=0.2\n        x0_arch = [-2.3, -1.38] \n        arch_res = minimize(arch_objective, x0_arch, method='BFGS')\n        \n        min_neg_ll_arch = arch_res.fun\n\n        # 4. Compute BIC for both models\n        k_garch = 3\n        # We need 2 * min_neg_ll since optimizer minimizes 0.5 * sum(...)\n        # The constant part of log-likelihood cancels out in comparison\n        bic_garch = 2 * min_neg_ll_garch + k_garch * np.log(T)\n        \n        k_arch = 1 + p\n        bic_arch = 2 * min_neg_ll_arch + k_arch * np.log(T)\n        \n        # 5. Compare BICs and record result\n        # True if ARCH(p) is wrongly selected\n        results.append(bic_arch  bic_garch)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "建模过程并非在参数估计后就宣告结束；我们必须对所选模型进行诊断，以确保它充分捕捉了数据的波动性动态。本练习将重点介绍一个关键的诊断工具——Ljung-Box 检验。通过将其应用于平方标准化残差，您可以检测模型中是否还存在未被解释的 ARCH 效应，从而验证模型的拟合优度。",
            "id": "2395745",
            "problem": "您的任务是构建一个完整的程序，用于估计一个广义自回归条件异方差 (GARCH) 模型，并对标准化残差的平方应用 Ljung-Box 诊断检验，以检测是否存在残留的自回归条件异方差 (ARCH) 效应。该程序必须基于核心定义，从基本原理出发实现以下组成部分：(i) 在高斯假设下通过最大似然法估计 GARCH 模型，(ii) 使用估计出的条件方差序列构建标准化残差，以及 (iii) 使用从标准化残差派生出的转换序列的样本自相关性计算 Ljung-Box 检验统计量。程序不得依赖任何预打包的 GARCH 或诊断程序，并且必须使用固定的伪随机种子以保证结果可复现。\n\n考虑一个单变量零均值收益率序列 $\\{r_t\\}_{t=1}^T$，其条件方差为 $\\{\\sigma_t^2\\}_{t=1}^T$。GARCH 模型将条件方差指定为一个由过去的平方新息和过去的条件方差驱动的递推关系。标准化残差的定义是将每个新息除以其条件方差的平方根。Ljung-Box 诊断是一种综合检验，用于评估一个序列在一组滞后阶数上的样本自相关是否共同为零。在适当的原假设和渐近条件下，Ljung-Box 统计量服从一个参考分布，从而可以计算出用于在给定显著性水平下制定决策规则的尾部概率。\n\n对于下述测试套件中的每个测试用例，您的程序必须执行以下操作：\n1. 使用指定的条件方差递推关系和正态新息来模拟一个收益率序列。使用固定的伪随机种子 $12345$ 并在收集最后 $T$ 个观测值之前进行正数的预烧期（burn-in），以减少初始化效应。\n2. 在高斯似然下，通过准最大似然估计 (QMLE) 对模拟序列拟合一个 GARCH($1,1$) 模型，同时对参数施加正性约束和严格的平稳性类型界限。\n3. 通过将每个新息除以拟合的当时条件方差的平方根来计算标准化残差。\n4. 对标准化残差的平方应用 Ljung-Box 检验，使用该测试用例指定的最大滞后阶数 $m$。使用基于样本协方差的样本自相关的标准定义以及大样本参考分布来获得尾部概率。如果此尾部概率严格小于显著性水平 $\\alpha = 0.05$，则判定为拒绝原假设。\n5. 为每个测试用例记录一个布尔值结果，指明诊断检验是否在指定滞后阶数上拒绝了“标准化残差的平方不存在残差自相关”的原假设。\n\n测试套件：\n- 用例 A (模型设定正确的基线，理想路径):\n  - 数据生成过程：GARCH($1,1$)，参数为 $(\\omega,\\alpha,\\beta) = (0.05,0.05,0.90)$。\n  - 样本大小：$T=3000$。\n  - Ljung-Box 最大滞后阶数：$m=20$。\n- 用例 B (模型设定错误，应检测到残留的 ARCH 效应):\n  - 数据生成过程：GARCH($2,1$)，参数为 $(\\omega,\\alpha_1,\\alpha_2,\\beta) = (0.02,0.04,0.08,0.86)$。\n  - 样本大小：$T=4000$。\n  - Ljung-Box 最大滞后阶数：$m=20$。\n- 用例 C (模型设定错误，但由于滞后截断选择不当和样本量有限，Ljung-Box 检验可能无法检测到残留的 ARCH 效应):\n  - 数据生成过程：一个在滞后阶数 $L=10$ 处具有单一长滞后效应的 ARCH 过程，定义为 $\\sigma_t^2 = \\omega + a_L \\cdot r_{t-L}^2$，参数为 $(\\omega,a_L)=(0.05,0.80)$。\n  - 样本大小：$T=800$。\n  - Ljung-Box 最大滞后阶数：$m=1$。\n\n实现细节：\n- 在估计中使用高斯似然，在模拟中使用高斯新息。明确约束 GARCH($1,1$) 参数 $(\\omega,\\alpha,\\beta)$ 满足 $\\omega0$, $\\alpha\\ge 0$, $\\beta\\ge 0$, 以及 $\\alpha+\\beta1$。\n- 使用从估计的 GARCH($1,1$) 模型得到的拟合条件方差路径来标准化残差。\n- 使用基于中心化数据的样本自相关标准定义来实现 Ljung-Box 统计量，并在 $m$ 阶滞后的大样本参考分布下推导尾部概率。\n- 在所有模拟中，保留最后 $T$ 个观测值之前，使用至少 $1000$ 个观测值的预烧期。\n\n最终输出格式：\n- 您的程序应生成单行输出，按顺序包含用例 A、B 和 C 的三个布尔决策，格式为用方括号括起来的逗号分隔列表，例如 $[{\\rm True},{\\rm False},{\\rm True}]$。\n\n您的答案必须是一个完整的、可运行的程序。不需要也不允许用户输入。此问题不涉及任何物理单位；所有数值输出均为指定列表格式的无量纲布尔值。",
            "solution": "所提出的问题是计算计量经济学中一个明确定义的练习，要求实现一个用于 GARCH 模型分析的完整流程。它以成熟的时间序列分析理论为科学基础，内容自成体系，并提出了一个客观、可形式化的任务。该问题没有可识别的缺陷；因此，有必要给出一个严谨的解决方案。\n\n该解决方案涉及几个连续的步骤：数据模拟、通过准最大似然估计 (QMLE) 进行模型估计、计算标准化残差，以及使用 Ljung-Box 检验进行诊断性检查。\n\n一个针对零均值收益率序列 $\\{r_t\\}$ 的通用 GARCH($p,q$) 过程由以下方程定义：\n$$ r_t = \\sigma_t z_t $$\n$$ \\sigma_t^2 = \\omega + \\sum_{i=1}^{q} \\alpha_i r_{t-i}^2 + \\sum_{j=1}^{p} \\beta_j \\sigma_{t-j}^2 $$\n在这里，$\\{z_t\\}$ 是一个均值为零、方差为一的独立同分布 (i.i.d.) 随机变量序列，我们假设其为标准正态分布，$z_t \\sim N(0,1)$。参数必须满足 $\\omega  0$、$\\alpha_i \\ge 0$ 和 $\\beta_j \\ge 0$，以确保方差非负。为使条件方差过程是弱平稳的，需要满足条件 $\\sum_{i=1}^{q} \\alpha_i + \\sum_{j=1}^{p} \\beta_j  1$。\n\n该问题要求估计一个 GARCH($1,1$) 模型，其条件方差递推关系简化为：\n$$ \\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2 $$\n待估计的参数向量是 $\\theta = (\\omega, \\alpha, \\beta)$。\n\n估计是使用 QMLE 进行的。假设新息是条件正态的，那么对于观测值 $t$，以信息集 $\\mathcal{F}_{t-1}$ 为条件的对数似然为：\n$$ l_t(\\theta) = -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\sigma_t^2(\\theta)) - \\frac{r_t^2}{2\\sigma_t^2(\\theta)} $$\n对于大小为 $T$ 的样本，总对数似然是总和 $\\mathcal{L}(\\theta) = \\sum_{t=1}^T l_t(\\theta)$。QMLE 估计量 $\\hat{\\theta}$ 是在满足参数约束的条件下，使 $\\mathcal{L}(\\theta)$ 最大化的 $\\theta$ 值。这等同于最小化负对数似然 $-\\mathcal{L}(\\theta)$。优化过程是数值进行的，通常使用像 L-BFGS-B 这样的拟牛顿法，该方法可以处理参数的箱形约束。严格的平稳性类型约束 $\\alpha + \\beta  1$ 是通过在目标函数中对违反该约束的情况返回无穷大惩罚来强制执行的。$\\sigma_t^2$ 的递推通过将 $\\sigma_1^2$ 设置为收益率序列的样本方差来初始化，这是一种常见且稳健的做法。\n\n一旦参数 $\\hat{\\theta} = (\\hat{\\omega}, \\hat{\\alpha}, \\hat{\\beta})$ 被估计出来，就使用这些估计值和 GARCH($1,1$) 递推关系来构建拟合的条件方差序列 $\\{\\hat{\\sigma}_t^2\\}_{t=1}^T$。然后，标准化残差计算如下：\n$$ \\hat{\\epsilon}_t = \\frac{r_t}{\\hat{\\sigma}_t} $$\n如果 GARCH($1,1$) 模型设定正确，序列 $\\{\\hat{\\epsilon}_t\\}$ 应近似为方差为 1 的独立同分布序列。因此，标准化残差的平方 $\\{\\hat{\\epsilon}_t^2\\}$ 应不表现出显著的自相关性。\n\n为了检验这一假设，我们对序列 $x_t = \\hat{\\epsilon}_t^2$ 采用 Ljung-Box 检验。首先，我们计算 $\\{x_t\\}$ 直至指定最大滞后阶数 $m$ 的样本自相关。滞后 $k > 0$ 的样本自相关定义为：\n$$ \\hat{\\rho}_k = \\frac{\\sum_{t=k+1}^T (x_t - \\bar{x})(x_{t-k} - \\bar{x})}{\\sum_{t=1}^T (x_t - \\bar{x})^2} $$\n其中 $\\bar{x}$ 是 $\\{x_t\\}$ 的样本均值。\n\n然后，Ljung-Box Q 统计量的计算公式为：\n$$ Q = T(T+2) \\sum_{k=1}^m \\frac{\\hat{\\rho}_k^2}{T-k} $$\n在原假设 ($H_0$) “序列中没有自相关”（即 $\\rho_1 = \\dots = \\rho_m = 0$）下，统计量 $Q$ 渐近服从自由度为 $m$ 的卡方分布，即 $Q \\sim \\chi^2(m)$。我们计算 p 值为 $P(\\chi^2(m)  Q_{\\text{obs}})$，其中 $Q_{\\text{obs}}$ 是该统计量的观测值。如果这个 p 值严格小于指定的显著性水平 $\\alpha = 0.05$，我们就拒绝原假设，这表明存在残留的 ARCH 效应。\n\n这整个过程将应用于三个测试用例：\n1.  **用例 A**：数据由 GARCH($1,1$) 过程生成，并拟合一个 GARCH($1,1$) 模型。这是一个模型设定正确的案例，我们预计诊断检验将不会拒绝原假设。\n2.  **用例 B**：数据由 GARCH($2,1$) 过程生成，但拟合的是一个 GARCH($1,1$) 模型。这种模型设定错误预计会留下未捕捉到的动态，导致标准化残差的平方出现自相关。我们预计 Ljung-Box 检验将拒绝原假设。\n3.  **用例 C**：数据由一个在滞后 $L=10$ 处具有特定滞后结构的 ARCH 过程生成。我们拟合一个 GARCH($1,1$) 模型，并应用最大滞后阶数仅为 $m=1$ 的 Ljung-Box 检验。由于该检验只检查滞后 1 阶，因此它不适合检测这种特定形式的模型设定错误。我们预计该检验将不会拒绝原假设，从而展示了诊断工具在配置不当时存在的局限性。\n\n实现部分将把这些组件综合成一个单一的程序，对所有三个用例执行分析，并报告每个用例的布尔决策（拒绝/不拒绝）。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import chi2\n\ndef simulate_series(omega, alpha_coeffs, beta_coeffs, T, burn_in, seed):\n    \"\"\"\n    Simulates a time series from a general GARCH(p,q) process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    q = len(alpha_coeffs)\n    p = len(beta_coeffs)\n    total_T = T + burn_in\n\n    r = np.zeros(total_T)\n    sigma2 = np.zeros(total_T)\n    z = rng.normal(size=total_T)\n\n    # Initialize with unconditional variance, assuming stationarity\n    uncond_var_denom = 1.0 - np.sum(alpha_coeffs) - np.sum(beta_coeffs)\n    # Ensure denominator is positive, preventing division by zero for non-stationary cases\n    uncond_var = omega / uncond_var_denom if uncond_var_denom > 0 else 1.0\n\n    # max_lag is the number of past values needed for the recursion\n    max_lag = max(p, q, 1) # Ensure max_lag is at least 1 for indexing\n    \n    sigma2[:max_lag] = uncond_var\n    r[:max_lag] = np.sqrt(sigma2[:max_lag]) * z[:max_lag]\n    \n    # Convert lists to numpy arrays for vectorized operations\n    alpha_arr = np.array(alpha_coeffs)\n    beta_arr = np.array(beta_coeffs)\n\n    for t in range(max_lag, total_T):\n        arch_term = np.sum(alpha_arr * np.flip(r[t-q:t]**2)) if q > 0 else 0\n        garch_term = np.sum(beta_arr * np.flip(sigma2[t-p:t])) if p > 0 else 0\n        sigma2[t] = omega + arch_term + garch_term\n        r[t] = np.sqrt(max(1e-9, sigma2[t])) * z[t] # Failsafe for numerical stability\n\n    return r[burn_in:]\n\n\ndef garch11_neg_log_likelihood(params, r_series):\n    \"\"\"\n    Computes the negative of the log-likelihood for a GARCH(1,1) model.\n    \"\"\"\n    omega, alpha, beta = params\n    \n    # Parameter constraints\n    if omega = 0 or alpha  0 or beta  0 or (alpha + beta) >= 1.0:\n        return np.inf\n\n    T = len(r_series)\n    sigma2 = np.zeros(T)\n    \n    # Initialize variance with sample variance\n    sigma2[0] = np.var(r_series)\n\n    for t in range(1, T):\n        sigma2[t] = omega + alpha * r_series[t-1]**2 + beta * sigma2[t-1]\n    \n    # Add a small constant to sigma2 to avoid log(0)\n    sigma2[sigma2 = 0] = 1e-9\n\n    log_likelihood = -0.5 * np.sum(np.log(2 * np.pi) + np.log(sigma2) + r_series**2 / sigma2)\n    \n    return -log_likelihood\n\n\ndef estimate_garch11(r_series):\n    \"\"\"\n    Estimates GARCH(1,1) parameters using QMLE.\n    \"\"\"\n    initial_params = np.array([np.var(r_series)*0.05, 0.05, 0.9])\n    bounds = [(1e-9, None), (0, 1), (0, 1)]\n    \n    # Add constraint dictionary for optimizer if needed, but the objective function handles it.\n    # Here, we only use bounds with L-BFGS-B, and check sum constraint inside objective.\n    result = minimize(garch11_neg_log_likelihood, initial_params, args=(r_series,),\n                      method='L-BFGS-B', bounds=bounds)\n    \n    return result.x\n\n\ndef ljung_box_test(series, m):\n    \"\"\"\n    Computes the Ljung-Box Q-statistic and its p-value.\n    \"\"\"\n    T = len(series)\n    x_mean = np.mean(series)\n    \n    # Sample variance (autocovariance at lag 0)\n    gamma0 = np.sum((series - x_mean)**2) / T\n    if gamma0 == 0:\n        return 1.0 # No variation, so no autocorrelation\n    \n    acf_sq_terms = []\n    for k in range(1, m + 1):\n        # Sample autocovariance at lag k\n        gamma_k = np.sum((series[k:] - x_mean) * (series[:-k] - x_mean)) / T\n        rho_k = gamma_k / gamma0\n        acf_sq_terms.append(rho_k**2 / (T - k))\n        \n    Q = T * (T + 2) * np.sum(acf_sq_terms)\n    \n    # p-value from chi-squared distribution\n    p_value = chi2.sf(Q, df=m)\n    return p_value\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    burn_in = 1000\n    seed = 12345\n    alpha_level = 0.05\n\n    test_cases = [\n        {\n            'name': 'Case A',\n            'dgp_params': {'omega': 0.05, 'alpha': [0.05], 'beta': [0.90]},\n            'T': 3000,\n            'm': 20\n        },\n        {\n            'name': 'Case B',\n            'dgp_params': {'omega': 0.02, 'alpha': [0.04, 0.08], 'beta': [0.86]},\n            'T': 4000,\n            'm': 20\n        },\n        {\n            'name': 'Case C',\n            'dgp_params': {'omega': 0.05, 'alpha': [0]*9 + [0.80], 'beta': []},\n            'T': 800,\n            'm': 1\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # 1. Simulate return series\n        dgp = case['dgp_params']\n        r_series = simulate_series(dgp['omega'], dgp['alpha'], dgp['beta'], case['T'], burn_in, seed)\n        \n        # 2. Fit GARCH(1,1) model\n        est_omega, est_alpha, est_beta = estimate_garch11(r_series)\n        \n        # 3. Compute standardized residuals\n        T = case['T']\n        sigma2_hat = np.zeros(T)\n        sigma2_hat[0] = np.var(r_series)\n        for t in range(1, T):\n            sigma2_hat[t] = est_omega + est_alpha * r_series[t-1]**2 + est_beta * sigma2_hat[t-1]\n        \n        std_residuals = r_series / np.sqrt(np.maximum(1e-9, sigma2_hat))\n        sq_std_residuals = std_residuals**2\n        \n        # 4. Apply Ljung-Box test\n        p_value = ljung_box_test(sq_std_residuals, case['m'])\n        \n        # 5. Record boolean decision\n        reject_null = p_value  alpha_level\n        results.append(reject_null)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}