{
    "hands_on_practices": [
        {
            "introduction": "Understanding a numerical algorithm begins with seeing it in action. This first exercise provides a direct, hands-on comparison between the secant method and the more familiar bisection method. By manually performing the first few iterations for both algorithms , you will gain a concrete understanding of how the secant method uses its approximation of the derivative to achieve faster convergence, a key advantage in many computational applications.",
            "id": "2199000",
            "problem": "Two common numerical methods for finding roots of a function are the bisection method and the secant method. Consider the polynomial function $p(x) = x^3 - 4x + 1$. We are interested in finding the largest real root of this polynomial, which is known to lie in the interval $[1, 2]$.\n\nYou are tasked to compare the results of the first few iterations of both methods.\n\nFirst, using the bisection method, start with the interval $[a_0, b_0] = [1, 2]$ and perform two iterations to find the approximation of the root. Let this approximation be denoted by $x_B$.\n\nSecond, using the secant method, start with the initial guesses $x_0 = 1$ and $x_1 = 2$ and perform two iterations to find the approximation of the root. Let this approximation be denoted by $x_S$.\n\nCalculate the absolute difference between these two approximations, $|x_B - x_S|$. Report your final answer rounded to four significant figures.",
            "solution": "We are given the polynomial $p(x)=x^{3}-4x+1$ and that its largest real root lies in $[1,2]$. First, we apply two iterations of the bisection method starting from $[a_{0},b_{0}]=[1,2]$, then two iterations of the secant method starting from $x_{0}=1$, $x_{1}=2$. Finally, we compute the absolute difference between the two approximations.\n\nBisection method:\n- Evaluate the endpoints: $p(1)=1-4+1=-2<0$ and $p(2)=8-8+1=1>0$, so a root lies in $[1,2]$.\n- Iteration 1: midpoint $m_{1}=\\frac{1+2}{2}=\\frac{3}{2}$. Then\n$$\np\\!\\left(\\frac{3}{2}\\right)=\\left(\\frac{3}{2}\\right)^{3}-4\\cdot\\frac{3}{2}+1=\\frac{27}{8}-6+1=\\frac{27}{8}-\\frac{40}{8}=-\\frac{13}{8}<0.\n$$\nSince $p(m_{1})<0$ and $p(2)>0$, the new interval is $[a_{1},b_{1}]=\\left[\\frac{3}{2},2\\right]$.\n- Iteration 2: midpoint $m_{2}=\\frac{\\frac{3}{2}+2}{2}=\\frac{7}{4}$. Then\n$$\np\\!\\left(\\frac{7}{4}\\right)=\\left(\\frac{7}{4}\\right)^{3}-4\\cdot\\frac{7}{4}+1=\\frac{343}{64}-7+1=\\frac{343}{64}-6=\\frac{343-384}{64}=-\\frac{41}{64}<0.\n$$\nAgain $p(m_{2})<0$ and $p(2)>0$, so after two iterations the bisection approximation is\n$$\nx_{B}=m_{2}=\\frac{7}{4}.\n$$\n\nSecant method:\nUse the update $x_{k+1}=x_{k}-p(x_{k})\\frac{x_{k}-x_{k-1}}{p(x_{k})-p(x_{k-1})}$.\n- With $x_{0}=1$, $x_{1}=2$, we have $p(1)=-2$, $p(2)=1$. The first update gives\n$$\nx_{2}=2-1\\cdot\\frac{2-1}{1-(-2)}=2-\\frac{1}{3}=\\frac{5}{3}.\n$$\nCompute\n$$\np\\!\\left(\\frac{5}{3}\\right)=\\left(\\frac{5}{3}\\right)^{3}-4\\cdot\\frac{5}{3}+1=\\frac{125}{27}-\\frac{20}{3}+1=\\frac{125-180+27}{27}=-\\frac{28}{27}.\n$$\n- The second update uses $x_{1}=2$, $x_{2}=\\frac{5}{3}$:\n$$\n\\begin{align*}\nx_3 &= x_2 - p(x_2)\\frac{x_2-x_1}{p(x_2)-p(x_1)} \\\\\n&= \\frac{5}{3} - \\left(-\\frac{28}{27}\\right) \\frac{\\frac{5}{3}-2}{-\\frac{28}{27}-1} \\\\\n&= \\frac{5}{3} - \\left(-\\frac{28}{27}\\right) \\left(\\frac{-1/3}{-55/27}\\right) \\\\\n&= \\frac{5}{3} - \\left(-\\frac{28}{165}\\right) \\\\\n&= \\frac{5}{3} + \\frac{28}{165} \\\\\n&= \\frac{275}{165} + \\frac{28}{165} = \\frac{303}{165} = \\frac{101}{55}.\n\\end{align*}\n$$\nThus after two iterations the secant approximation is\n$$\nx_{S}=\\frac{101}{55}.\n$$\n\nAbsolute difference and rounding:\nCompute\n$$\n|x_{B}-x_{S}|=\\left|\\frac{7}{4}-\\frac{101}{55}\\right|=\\left|\\frac{385-404}{220}\\right|=\\frac{19}{220}.\n$$\nAs a decimal, $\\frac{19}{220}=0.0863636\\ldots$, which rounded to four significant figures is $0.08636$.",
            "answer": "$$\\boxed{0.08636}$$"
        },
        {
            "introduction": "Having grasped the mechanics, we now apply the secant method to a classic problem in finance: determining a bond's yield to maturity (YTM). The YTM is the internal rate of return that equates the present value of a bond's future cash flows to its current market price, but its value cannot be solved for directly from the pricing formula. This exercise  challenges you to implement the secant method in code to solve this implicit equation, bridging the gap between numerical theory and its powerful application in fixed-income analysis.",
            "id": "2443656",
            "problem": "You are given a family of fixed-coupon bonds characterized by face value $F$, annual coupon rate $q$ (expressed as a decimal per annum), coupon payment frequency $m$ (payments per year), time to maturity $T$ (in years), and an observed market price $P$. Let the annual yield to maturity $y$ (expressed as a decimal per annum, compounded $m$ times per year) satisfy the pricing identity\n$$\nP \\;=\\; \\sum_{t=1}^{N} \\frac{qF/m}{\\left(1 + \\frac{y}{m}\\right)^t} \\;+\\; \\frac{F}{\\left(1 + \\frac{y}{m}\\right)^N},\n$$\nwhere $N = mT$ is the total number of coupon periods and the convention is that all cash flows occur at the end of each period.\n\nDefine the root-finding objective function\n$$\nf(y) \\;=\\; \\sum_{t=1}^{N} \\frac{qF/m}{\\left(1 + \\frac{y}{m}\\right)^t} \\;+\\; \\frac{F}{\\left(1 + \\frac{y}{m}\\right)^N} \\;-\\; P,\n$$\nand suppose it is evaluated only for values of $y$ such that $1 + \\frac{y}{m} > 0$. For each parameter set below, compute a value $\\hat{y}$ such that $f(\\hat{y}) = 0$ up to the following numerical tolerances: the absolute residual tolerance is $\\varepsilon_f = 10^{-12}$ and the absolute yield tolerance is $\\varepsilon_y = 10^{-12}$. Each instance also provides an initial search interval $[L,U]$ with $L < U$ for $y$.\n\nYour program must solve the equation $f(y) = 0$ for each parameter set in the test suite, starting its search in the corresponding interval $[L,U]$, and honoring the following global limits: a maximum of $N_{\\max} = 100$ function evaluations per instance, and the domain constraint $1 + \\frac{y}{m} > 0$ throughout the search. Report each $\\hat{y}$ in decimal per annum and round each value to $10$ decimal places.\n\nTest suite (each tuple is $(F, q, m, T, P, L, U)$):\n- Case $1$: $(1000.0, 0.05, 2, 5.0, 950.0, 0.0, 0.2)$\n- Case $2$: $(1000.0, 0.0, 2, 3.0, 850.0, 0.0, 0.2)$\n- Case $3$: $(1000.0, 0.08, 1, 10.0, 1100.0, 0.0, 0.15)$\n- Case $4$: $(1000.0, 0.03, 4, 2.0, 1000.0, -0.02, 0.2)$\n- Case $5$: $(1000.0, 0.01, 2, 5.0, 1060.0, -0.1, 0.1)$\n\nFinal output format: Your program should produce a single line of output containing the $5$ results as a comma-separated list enclosed in square brackets, in the same order as the cases above, rounded to $10$ decimal places, for example, $[\\hat{y}_1,\\hat{y}_2,\\hat{y}_3,\\hat{y}_4,\\hat{y}_5]$, where each $\\hat{y}_i$ is in decimal per annum.",
            "solution": "The core task is to find the root of the objective function $f(y)$, which represents the difference between the theoretical price of a bond for a given yield $y$ and its observed market price $P$. The theoretical price is the sum of the present values of all future cash flows (coupons and face value).\n\nThe objective function is given as:\n$$\nf(y) \\;=\\; \\left( \\sum_{t=1}^{N} \\frac{C}{\\left(1 + \\frac{y}{m}\\right)^t} \\;+\\; \\frac{F}{\\left(1 + \\frac{y}{m}\\right)^N} \\right) \\;-\\; P\n$$\nwhere $C = qF/m$ is the periodic coupon payment and $N=mT$ is the total number of coupon periods. The expression for the sum of discounted coupons is a geometric series, which can be expressed in a more computationally efficient closed form. Let $i = y/m$ be the periodic yield. The present value of the stream of coupons, which is an ordinary annuity, is given by:\n$$\nPV_{\\text{coupons}} = C \\cdot \\frac{1 - (1+i)^{-N}}{i}\n$$\nThis formula is valid for any $i \\neq 0$. For the special case where $y=0$ (and thus $i=0$), the price is calculated by simple summation, as the discount factor is $1$:\n$$\nP(y=0) = \\sum_{t=1}^{N} C + F = NC + F\n$$\nThe full objective function is therefore:\n$$\nf(y) = \\begin{cases} \\left( C \\frac{1 - (1+i)^{-N}}{i} + F(1+i)^{-N} \\right) - P & \\text{if } y \\neq 0 \\\\ (NC + F) - P & \\text{if } y = 0 \\end{cases}\n$$\nThe problem is to find $\\hat{y}$ such that $f(\\hat{y}) = 0$. The derivative of the bond price with respect to yield, $P'(y)$, is strictly negative for all valid yields ($1+y/m > 0$), which means $f(y)$ is a strictly monotonic decreasing function. This property guarantees that if a root exists, it is unique.\n\nA suitable numerical algorithm for this root-finding problem is the secant method. It is an iterative open method that approximates the root of a function using a sequence of secant lines. Given two initial approximations $y_{k-1}$ and $y_k$, the next approximation $y_{k+1}$ is calculated as the root of the line passing through $(y_{k-1}, f(y_{k-1}))$ and $(y_k, f(y_k))$:\n$$\ny_{k+1} = y_k - f(y_k) \\frac{y_k - y_{k-1}}{f(y_k) - f(y_k-1)}\n$$\nThe iteration begins with two initial guesses, for which the provided interval boundaries $[L, U]$ are used ($y_0 = L, y_1 = U$). The process continues until the solution converges, which is determined by two conditions:\n1.  The absolute value of the function at the current estimate is smaller than the residual tolerance: $|f(\\hat{y})| < \\varepsilon_f = 10^{-12}$.\n2.  The absolute difference between successive estimates is smaller than the yield tolerance: $|y_{k+1} - y_k| < \\varepsilon_y = 10^{-12}$.\n\nThe algorithm must also respect a maximum budget of $N_{\\max} = 100$ function evaluations. The initial points $y_0$ and $y_1$ require two evaluations, leaving $98$ for the iterative process. The secant method requires one new function evaluation per iteration, making this budget ample for convergence in well-behaved cases like this one. The implementation will handle the special case of $y \\approx 0$ to avoid numerical instability in the annuity formula.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to compute bond yields for a suite of test cases.\n    \"\"\"\n\n    def build_objective_function(F, q, m, T, P):\n        \"\"\"\n        Creates the objective function f(y) = Price(y) - P for a given bond.\n        \n        Args:\n            F (float): Face value.\n            q (float): Annual coupon rate (decimal).\n            m (int): Coupon frequency per year.\n            T (float): Time to maturity in years.\n            P (float): Market price.\n        \n        Returns:\n            A function that takes a yield y and returns the value of f(y).\n        \"\"\"\n        N = m * T\n        C = q * F / m\n\n        # Handle zero-coupon bond as a separate, simpler case.\n        if q == 0.0:\n            def objective_func_zero_coupon(y):\n                if 1 + y / m <= 0:\n                    return np.inf  # Invalid domain\n                i = y / m\n                if abs(i) < 1e-12: # y is close to 0\n                    price = F\n                else:\n                    price = F / ((1 + i)**N)\n                return price - P\n            return objective_func_zero_coupon\n\n        # Handle coupon-bearing bond.\n        def objective_func(y):\n            if 1 + y / m <= 0:\n                return np.inf # Invalid domain\n\n            i = y / m\n            \n            # Use Taylor expansion limit for i near 0 to avoid numerical instability\n            if abs(i) < 1e-9:\n                price = N * C + F\n            else:\n                pv_coupons = C / i * (1 - (1 + i)**(-N))\n                pv_face = F / ((1 + i)**N)\n                price = pv_coupons + pv_face\n            \n            return price - P\n        \n        return objective_func\n\n    def solve_ytm_secant(f, y0, y1, tol_f, tol_y, max_evals):\n        \"\"\"\n        Finds the root of a function using the secant method.\n        \n        Args:\n            f (function): The function for which to find a root.\n            y0, y1 (float): Initial guesses for the root.\n            tol_f (float): Absolute residual tolerance.\n            tol_y (float): Absolute step tolerance.\n            max_evals (int): Maximum number of function evaluations.\n            \n        Returns:\n            The estimated root, or None if not converged.\n        \"\"\"\n        fy0 = f(y0)\n        fy1 = f(y1)\n        num_evals = 2\n\n        if abs(fy0) < tol_f:\n            return y0\n        if abs(fy1) < tol_f:\n            return y1\n\n        for _ in range(max_evals - 2):\n            if abs(fy1 - fy0) < 1e-15: # Denominator is too small\n                break\n\n            # Secant step\n            y_next = y1 - fy1 * (y1 - y0) / (fy1 - fy0)\n\n            if abs(y_next - y1) < tol_y:\n                return y_next\n\n            y0, y1 = y1, y_next\n            fy0, fy1 = fy1, f(y1)\n            num_evals += 1\n\n            if abs(fy1) < tol_f:\n                return y1\n        \n        return y1 # Return the best guess upon reaching max iterations\n\n    # Test suite: (F, q, m, T, P, L, U)\n    test_cases = [\n        (1000.0, 0.05, 2, 5.0, 950.0, 0.0, 0.2),\n        (1000.0, 0.0, 2, 3.0, 850.0, 0.0, 0.2),\n        (1000.0, 0.08, 1, 10.0, 1100.0, 0.0, 0.15),\n        (1000.0, 0.03, 4, 2.0, 1000.0, -0.02, 0.2),\n        (1000.0, 0.01, 2, 5.0, 1060.0, -0.1, 0.1)\n    ]\n    \n    # Tolerances and limits\n    eps_f = 1e-12\n    eps_y = 1e-12\n    N_max = 100\n    \n    results = []\n    for case in test_cases:\n        F, q, m, T, P, L, U = case\n        \n        # Build the specific objective function for this case\n        f = build_objective_function(F, q, m, T, P)\n        \n        # Solve for the yield to maturity\n        y_hat = solve_ytm_secant(f, L, U, eps_f, eps_y, N_max)\n        \n        # Round to 10 decimal places as required\n        results.append(round(y_hat, 10))\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "The speed of the secant method is its greatest strength, but this can come at the cost of reliability, as it can sometimes fail to converge if not started carefully. Professional-grade solvers mitigate this risk by blending speed with safety. This advanced practice  guides you through the design of a robust, hybrid algorithm that combines the fast secant step with the guaranteed convergence of a bracketing method. Building this \"bounded\" secant method demonstrates how to engineer numerical tools that are both efficient and fail-safe, a crucial skill for any computational finance practitioner.",
            "id": "2443706",
            "problem": "You are given continuous real-valued functions that arise in computational economics and finance, each defined on a closed interval with opposite signs at the endpoints. For each function, compute a real root $x^\\star$ in the given interval using only function evaluations (no derivatives). The algorithm must satisfy all of the following properties for every iteration until termination: (i) all function evaluations must occur inside the current bracketing interval $\\left[a,b\\right]$, (ii) the interval must continue to bracket a root, meaning $f(a)\\cdot f(b)\\le 0$ at all times, and (iii) the sequence of trial points must be chosen by a rule that can exploit information from up to three previously evaluated points if doing so preserves the bracketing property. The routine must terminate when either the width of the current bracket satisfies $|b-a| \\le \\varepsilon_x$ or the function value at the current approximation satisfies $|f(x)| \\le \\varepsilon_f$, where $\\varepsilon_x=\\varepsilon_f=10^{-10}$. Use a maximum of $100$ iterations per test instance. If the termination conditions are met earlier, return immediately. The returned approximation must lie in the final bracketing interval.\n\nDefine the following test suite of root-finding instances. Each instance specifies a function $f(x)$, an interval $\\left[a,b\\right]$ with $f(a)\\cdot f(b)\\le 0$, and any needed parameters.\n\nTest case A (market-clearing price with constant elasticity demand and linear supply):\n- Variable: price $p$.\n- Demand: $D(p)=A\\,p^{-\\eta}$ with $A=120$ and $\\eta=1.5$.\n- Supply: $S(p)=c_0+c_1 p$ with $c_0=10$ and $c_1=2$.\n- Excess demand: $f(p)=D(p)-S(p)=A\\,p^{-\\eta}-(c_0+c_1 p)$.\n- Interval: $[a,b]=[1,20]$.\n\nTest case B (yield to maturity from price of a level-coupon bond):\n- Variable: yield $y$.\n- Coupon each period: $C=5$, face value: $F=100$, maturity in periods: $T=10$, observed price: $P=95$.\n- Present value function: $\\mathrm{PV}(y)=\\sum_{t=1}^{T}\\dfrac{C}{(1+y)^t}+\\dfrac{F}{(1+y)^T}$.\n- Root function: $f(y)=\\mathrm{PV}(y)-P$.\n- Interval: $[a,b]=[0,0.2]$.\n\nTest case C (implied volatility from Black–Scholes–Merton call price):\n- Variable: volatility $\\sigma$.\n- Underlying price: $S=100$, strike: $K=100$, continuously compounded risk-free rate: $r=0.02$, time to maturity in years: $\\tau=1$, observed call price: $C_{\\text{mkt}}=10$.\n- Black–Scholes–Merton call price: $C(\\sigma)=S\\,N(d_1)-K e^{-r\\tau} N(d_2)$ where $d_1=\\dfrac{\\ln(S/K)+(r+\\tfrac{1}{2}\\sigma^2)\\tau}{\\sigma\\sqrt{\\tau}}$, $d_2=d_1-\\sigma\\sqrt{\\tau}$, and $N(\\cdot)$ is the standard normal cumulative distribution function (CDF).\n- Root function: $f(\\sigma)=C(\\sigma)-C_{\\text{mkt}}$.\n- Interval: $[a,b]=[0.01,1.0]$.\n\nTest case D (boundary root in a zero-coupon yield equation):\n- Variable: yield $y$.\n- Face value: $F=100$, maturity in periods: $T=5$, reference yield: $y_0=0.04$, observed price: $P=F/(1+y_0)^T$.\n- Present value function: $\\mathrm{PV}(y)=\\dfrac{F}{(1+y)^T}$.\n- Root function: $f(y)=\\mathrm{PV}(y)-P$.\n- Interval: $[a,b]=[0.04,0.20]$.\n\nYour program must evaluate all four test cases in the order A, B, C, D using the same generic solver and produce a single line of output containing the four numerical approximations to the roots as a comma-separated list enclosed in square brackets, for example $[x_A,x_B,x_C,x_D]$. Each $x$ should be printed as a floating-point number. No angles are involved. There are no physical units in the answers. The output must appear on a single line exactly in the described format.",
            "solution": "The problem asks for the implementation of a specific class of root-finding algorithm to solve several well-defined problems from computational economics and finance.\n\nThe requirements for the algorithm are:\n1.  It must be a bracketing method, ensuring the root remains between two points, $a$ and $b$, such that $f(a) \\cdot f(b) \\le 0$.\n2.  All function evaluations must occur within the current bracketing interval.\n3.  It must use interpolation, based on up to three prior points, to accelerate convergence, but fall back to a safe method if the interpolated point is not satisfactory.\n4.  It must use function evaluations only, with no derivatives.\n5.  Termination must occur when either a tolerance on the interval width, $\\varepsilon_x = 10^{-10}$, or a tolerance on the function value, $\\varepsilon_f = 10^{-10}$, is met.\n\nThese constraints describe a robust, hybrid root-finding algorithm. The standard secant method does not guarantee that iterates remain inside a bracket. Therefore, a more sophisticated method is required. The specified properties are archetypal of the methods developed by Dekker and Brent, which combine a fast, open method (like the secant method or inverse quadratic interpolation) with a safe, closed method (bisection).\n\nThe algorithm implemented here is a variant of Dekker's method, a direct precursor to Brent's method. It satisfies all problem constraints.\n\n**Algorithm Design: Dekker-Brent Method**\n\nThe core of the method is to maintain a bracket $[a, b]$ and a convention that $b$ represents the best current approximation to the root $x^{\\star}$. Thus, at every step, we ensure $|f(b)| \\le |f(a)|$.\n\n1.  **Initialization**: Given an interval $[a, b]$ where $f(a)f(b) \\le 0$, we evaluate $f(a)$ and $f(b)$. If either endpoint is a root within tolerance $\\varepsilon_f$, we terminate. Otherwise, we establish the invariant that $|f(b)| \\le |f(a)|$ by swapping $a$ and $b$ if necessary. The point $c=a$ is stored as the *previous* best guess.\n\n2.  **Iteration**: The main loop consists of generating and evaluating a new trial point, $x_{\\text{next}}$, to shrink the bracket $[a, b]$.\n\n3.  **Trial Point Generation**:\n    *   **Interpolation Step (Secant Method)**: A trial point $s$ is computed using the secant method, which forms a line through the two most recent best guesses: the current best guess $(b, f(b))$ and the previous best guess $(c, f(c))$. The formula is:\n        $$ s = b - f(b) \\frac{b - c}{f(b) - f(c)} $$\n        This step uses two previous points ($b$ and $c$) to achieve super-linear convergence.\n    *   **Bisection Step**: A guaranteed, but slower, fallback is the bisection midpoint $m = (a+b)/2$.\n\n4.  **Hybrid Strategy**: A crucial decision is made at each step. To ensure convergence and satisfy the problem constraint that evaluations occur inside the bracket, the fast secant step $s$ is accepted only if it is \"reasonable\". A simple and effective condition, central to Dekker's method, is to accept $s$ only if it lies between the current best guess $b$ and the bisection midpoint $m$. If this condition fails, we distrust the interpolation and default to the safe bisection point $m$. This ensures $x_{\\text{next}}$ is always within the current bracket $[a, b]$.\n\n5.  **Bracket Update**: After evaluating $f(x_{\\text{next}})$, the bracket is updated. If $f(a)$ and $f(x_{\\text{next}})$ have opposite signs, the new bracket becomes $[a, x_{\\text{next}}]$; otherwise, it becomes $[x_{\\text{next}}, b]$. The new points are then relabeled to maintain the invariant that $b$ is the best guess, and the process repeats.\n\n6.  **Termination**: The loop terminates if the bracket width $|b-a|$ is less than or equal to $\\varepsilon_x$ OR the function value at the best guess $|f(b)|$ is less than or equal to $\\varepsilon_f$.\n\n**Test Case Implementation**\n\nThe four test cases are implemented as Python functions.\n- For test case B (yield to maturity), the present value is calculated by direct summation to maintain numerical stability and correctness for yield values near zero.\n- For test case C (implied volatility), the standard normal cumulative distribution function $N(x)$ is required. It is implemented using the error function, $\\mathrm{erf}(x)$, available in Python's standard `math` library, via the relation $N(x) = \\frac{1}{2}(1 + \\mathrm{erf}(x/\\sqrt{2}))$.\n- For test case D, the root is exactly at the boundary of the initial interval. The solver correctly identifies this on the first check and terminates immediately with the correct answer.\n\nThis robust, principle-based design ensures correct and efficient computation of the roots for all specified test cases.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the solver.\n    The output is a single line with comma-separated roots in a list format.\n    \"\"\"\n    # Define global constants for the solver.\n    EPS_X = 1e-10\n    EPS_F = 1e-10\n    MAX_ITER = 100\n\n    def dekker_brent_solver(f, a, b, eps_x, eps_f, max_iter):\n        \"\"\"\n        A robust root-finding algorithm based on Dekker's and Brent's methods.\n        It combines a fast interpolation step (secant method) with a safe\n        fallback (bisection method) to guarantee convergence while ensuring the\n        root remains bracketed.\n        \"\"\"\n        fa = f(a)\n        fb = f(b)\n\n        if fa * fb > 0:\n            raise ValueError(\"Root not bracketed in initial interval [a, b].\")\n\n        # Check if endpoints are already the root within tolerance.\n        if abs(fa) <= eps_f:\n            return a\n        if abs(fb) <= eps_f:\n            return b\n\n        # Convention: 'b' is always the current best guess for the root.\n        # 'a' is the contrapoint, ensuring f(a) and f(b) have opposite signs.\n        if abs(fa) < abs(fb):\n            a, b = b, a\n            fa, fb = fb, fa\n        \n        # 'c' is the previous best guess, used for the secant step.\n        c = a\n        fc = fa\n        \n        for _ in range(max_iter):\n            # Check for termination on either interval width or function value.\n            if abs(b - a) <= eps_x or abs(fb) <= eps_f:\n                return b\n\n            s = None\n            # Propose a new point 's' using the secant method (linear interpolation).\n            # This step uses the current best guess (b) and previous best guess (c).\n            if abs(fb - fc) > 1e-15:  # Avoid division by zero or large floating-point errors.\n                s = b - fb * (b - c) / (fb - fc)\n\n            # The bisection midpoint serves as a safe fallback.\n            m = (a + b) / 2\n            \n            # Hybrid strategy: Accept the secant step 's' only if it's reasonable.\n            # \"Reasonable\" means it falls strictly between 'b' and the bisection point 'm'.\n            # This ensures the new point is inside the bracket and promotes convergence.\n            is_secant_step_acceptable = False\n            if s is not None:\n                # The order of b and m is not known, so check both cases.\n                if (b < m and s > b and s < m) or (b > m and s < b and s > m):\n                    is_secant_step_acceptable = True\n\n            if is_secant_step_acceptable:\n                x_next = s\n            else:\n                # If interpolation is untrustworthy, fall back to bisection.\n                x_next = m\n            \n            f_next = f(x_next)\n\n            # Update state for the next iteration: the old 'b' becomes the new 'c'.\n            c, fc = b, fb\n\n            # Update the bracketing interval based on the sign of f_next.\n            if fa * f_next < 0:\n                b, fb = x_next, f_next\n            else:\n                a, fa = x_next, f_next\n\n            # Maintain the invariant that 'b' is the best guess so far (|f(b)| is minimal).\n            if abs(fa) < abs(fb):\n                a, b = b, a\n                fa, fb = fb, fa\n        \n        # If max iterations are reached, return the best approximation found.\n        return b\n\n    # --- Test Case Definitions ---\n\n    # Test Case A: Market-clearing price\n    def f_A(p):\n        A, eta, c0, c1 = 120.0, 1.5, 10.0, 2.0\n        if p <= 0: return float('inf')\n        return A * p**(-eta) - (c0 + c1 * p)\n    \n    # Test Case B: Yield to maturity\n    def f_B(y):\n        C, F, T, P = 5.0, 100.0, 10, 95.0\n        if y <= -1: return float('inf')\n        one_plus_y = 1.0 + y\n        # Direct summation is robust against numerical issues near y=0.\n        terms = [C / (one_plus_y**t) for t in range(1, T + 1)]\n        pv = np.sum(terms) + F / (one_plus_y**T)\n        return pv - P\n    \n    # Test Case C: Implied volatility\n    def f_C(sigma):\n        S, K, r, tau, C_mkt = 100.0, 100.0, 0.02, 1.0, 10.0\n        if sigma <= 0: return -C_mkt # C(0) = 0, so f(0) = -C_mkt\n\n        # Standard Normal CDF N(x) using math.erf from the standard library\n        def N(x):\n            return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))\n        \n        d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * tau) / (sigma * math.sqrt(tau))\n        d2 = d1 - sigma * math.sqrt(tau)\n        call_price = S * N(d1) - K * math.exp(-r * tau) * N(d2)\n        return call_price - C_mkt\n\n    # Test Case D: Boundary root\n    F_D, T_D, y0_D = 100.0, 5, 0.04\n    P_D = F_D / (1.0 + y0_D)**T_D\n    def f_D(y):\n        if y <= -1: return float('inf')\n        return F_D / (1.0 + y)**T_D - P_D\n\n    test_cases = [\n        {'func': f_A, 'a': 1.0, 'b': 20.0},\n        {'func': f_B, 'a': 0.0, 'b': 0.2},\n        {'func': f_C, 'a': 0.01, 'b': 1.0},\n        {'func': f_D, 'a': 0.04, 'b': 0.20},\n    ]\n\n    results = []\n    for case in test_cases:\n        root = dekker_brent_solver(case['func'], case['a'], case['b'], EPS_X, EPS_F, MAX_ITER)\n        results.append(root)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}