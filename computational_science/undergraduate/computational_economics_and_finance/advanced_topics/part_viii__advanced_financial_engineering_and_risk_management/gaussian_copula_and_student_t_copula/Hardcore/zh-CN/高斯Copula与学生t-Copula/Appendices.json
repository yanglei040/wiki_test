{
    "hands_on_practices": [
        {
            "introduction": "Copula的核心优势之一是能够对联合分布进行建模，以回答有关条件概率的问题，这在风险管理中至关重要。本练习将引导您从第一性原理出发，推导出一个条件风险价值（VaR），这是一项基本技能。通过这个过程，您将实践如何处理从边缘分布到Copula底层分布的转换，从而巩固对理论的理解 。",
            "id": "2396087",
            "problem": "一位风险管理者使用高斯Copula对一个具有连续边缘分布且包含相关性的非负单日损失向量 $(L_1,L_2,L_3)$ 进行建模。设边缘分布为指数分布，其各自的速率参数为 $\\lambda_1=\\frac{1}{2}$，$\\lambda_2=1$ 和 $\\lambda_3=2$。因此，对于 $i\\in\\{1,2,3\\}$，边缘累积分布函数为 $F_i(x)=1-\\exp(-\\lambda_i x)$，$x\\geq 0$。高斯Copula由 $U_i=F_i(L_i)$ 定义，并且 $(Z_1,Z_2,Z_3)$ 服从联合正态分布，其均值为 $0$，方差为 $1$，相关矩阵为\n$$\nR=\\begin{pmatrix}\n1  &\\frac{3}{5}  &\\frac{2}{5} \\\\\n\\frac{3}{5}  &1  &\\frac{1}{2} \\\\\n\\frac{2}{5}  &\\frac{1}{2}  &1\n\\end{pmatrix},\n$$\n其中 $U_i=\\Phi(Z_i)$，$\\Phi$ 是标准正态累积分布函数。假设在收盘时，两个交易指数的已实现损失分别为 $L_2=\\ln 2$ 和 $L_3=\\frac{\\ln 2}{2}$，交易部门需要给定这些实现值下 $L_1$ 的条件单日 $0.99$-分位数来设定部门级限额。这个条件分位数也是在给定观测到的 $L_2$ 和 $L_3$ 的情况下，交易部门对 $L_1$ 在 $0.99$ 水平上的条件风险价值（Value at Risk (VaR)）。\n\n根据所描述的模型，从第一性原理出发，推导在给定 $L_2=\\ln 2$ 和 $L_3=\\frac{\\ln 2}{2}$ 的条件下，$L_1$ 的条件 $0.99$-分位数的单一闭式解析表达式。你的最终表达式只能包含函数 $\\Phi$、$\\Phi^{-1}$ 和 $\\ln$。以美元表示最终答案。最终答案必须是单一的解析表达式；不要提供不等式或方程式。",
            "solution": "所述问题具有科学依据，是适定且客观的。不存在会妨碍形式解的矛盾或信息缺失。相关矩阵 $R$ 是对称正定的，这是有效的多元正态分布的必要条件。因此，我们可以进行推导。\n\n目标是求出单日损失 $L_1$ 的条件 $0.99$-分位数，我们将其表示为 $q$。这个值 $q$ 满足 $P(L_1 \\le q | L_2 = \\ln 2, L_3 = \\frac{\\ln 2}{2}) = 0.99$。\n\n求解过程分为以下几个步骤：\n1.  使用边缘累积分布函数（CDFs）将给定的损失值 $L_2$ 和 $L_3$ 转换为它们对应的均匀分布变量 $U_2$ 和 $U_3$。\n2.  使用标准正态累积分布函数的逆函数 $\\Phi^{-1}$，将这些均匀分布变量转换为它们对应的标准正态变量 $Z_2$ 和 $Z_3$。\n3.  确定在给定实现值 $Z_2=z_2$ 和 $Z_3=z_3$ 的条件下 $Z_1$ 的条件分布的参数。\n4.  建立 $L_1$ 的期望分位数与 $Z_1$ 条件分布的分位数之间的关系。\n5.  推导分位数 $q$ 的最终表达式。\n\n步骤 1：将损失 $L_i$ 转换为均匀分布变量 $U_i$。\n损失 $L_i$ 的边缘累积分布函数由 $F_i(x) = 1 - \\exp(-\\lambda_i x)$ 给出。均匀分布变量为 $U_i = F_i(L_i)$。我们已知 $L_2 = \\ln 2$，$\\lambda_2 = 1$，以及 $L_3 = \\frac{\\ln 2}{2}$，$\\lambda_3 = 2$。\n\n对于 $L_2$：\n$$ u_2 = F_2(L_2) = 1 - \\exp(-\\lambda_2 L_2) = 1 - \\exp(-1 \\cdot \\ln 2) = 1 - \\exp(\\ln(2^{-1})) = 1 - \\frac{1}{2} = \\frac{1}{2} $$\n对于 $L_3$：\n$$ u_3 = F_3(L_3) = 1 - \\exp(-\\lambda_3 L_3) = 1 - \\exp(-2 \\cdot \\frac{\\ln 2}{2}) = 1 - \\exp(-\\ln 2) = 1 - \\frac{1}{2} = \\frac{1}{2} $$\n\n步骤 2：将均匀分布变量 $U_i$ 转换为正态变量 $Z_i$。\n关系式为 $U_i = \\Phi(Z_i)$，这意味着 $Z_i = \\Phi^{-1}(U_i)$。\n$$ z_2 = \\Phi^{-1}(u_2) = \\Phi^{-1}\\left(\\frac{1}{2}\\right) = 0 $$\n$$ z_3 = \\Phi^{-1}(u_3) = \\Phi^{-1}\\left(\\frac{1}{2}\\right) = 0 $$\n值为 $0$ 是因为标准正态分布关于 $0$ 对称，其中位数（$0.5$ 分位数）位于此处。\n\n步骤 3：确定 $Z_1$ 的条件分布。\n向量 $\\mathbf{Z} = (Z_1, Z_2, Z_3)^T$ 服从多元正态分布 $N(\\boldsymbol{\\mu}, R)$，其中均值向量为 $\\boldsymbol{\\mu} = (0, 0, 0)^T$，相关矩阵为 $R$。我们将 $\\mathbf{Z}$ 分割为 $\\mathbf{Z}_a = Z_1$ 和 $\\mathbf{Z}_b = (Z_2, Z_3)^T$。相关矩阵也相应地进行分割：\n$$ R = \\begin{pmatrix} \\Sigma_{aa}  &\\Sigma_{ab} \\\\ \\Sigma_{ba}  &\\Sigma_{bb} \\end{pmatrix} $$\n其中\n$\\Sigma_{aa} = 1$\n$\\Sigma_{ab} = \\begin{pmatrix} \\frac{3}{5} & \\frac{2}{5} \\end{pmatrix}$\n$\\Sigma_{ba} = \\Sigma_{ab}^T = \\begin{pmatrix} \\frac{3}{5} \\\\ \\frac{2}{5} \\end{pmatrix}$\n$\\Sigma_{bb} = \\begin{pmatrix} 1 & \\frac{1}{2} \\\\ \\frac{1}{2} & 1 \\end{pmatrix}$\n\n$Z_1$ 在 $\\mathbf{Z}_b = \\mathbf{z}_b = (z_2, z_3)^T = (0, 0)^T$ 条件下的分布是一个正态分布 $N(\\mu_{\\text{cond}}, \\sigma^2_{\\text{cond}})$。\n条件均值为 $\\mu_{\\text{cond}} = \\mu_a + \\Sigma_{ab} \\Sigma_{bb}^{-1} (\\mathbf{z}_b - \\boldsymbol{\\mu}_b)$。\n由于 $\\mu_a = 0$，$\\boldsymbol{\\mu}_b = (0, 0)^T$，且 $\\mathbf{z}_b = (0, 0)^T$，项 $(\\mathbf{z}_b - \\boldsymbol{\\mu}_b)$ 是零向量。因此，条件均值为：\n$$ \\mu_{\\text{cond}} = 0 + \\Sigma_{ab} \\Sigma_{bb}^{-1} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = 0 $$\n条件方差为 $\\sigma^2_{\\text{cond}} = \\Sigma_{aa} - \\Sigma_{ab} \\Sigma_{bb}^{-1} \\Sigma_{ba}$。首先，我们计算 $\\Sigma_{bb}$ 的逆矩阵：\n$$ \\det(\\Sigma_{bb}) = 1 \\cdot 1 - \\left(\\frac{1}{2}\\right)^2 = 1 - \\frac{1}{4} = \\frac{3}{4} $$\n$$ \\Sigma_{bb}^{-1} = \\frac{1}{3/4} \\begin{pmatrix} 1 & -\\frac{1}{2} \\\\ -\\frac{1}{2} & 1 \\end{pmatrix} = \\frac{4}{3} \\begin{pmatrix} 1 & -\\frac{1}{2} \\\\ -\\frac{1}{2} & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{3} & -\\frac{2}{3} \\\\ -\\frac{2}{3} & \\frac{4}{3} \\end{pmatrix} $$\n现在我们计算乘积 $\\Sigma_{ab} \\Sigma_{bb}^{-1} \\Sigma_{ba}$：\n$$ \\Sigma_{ab} \\Sigma_{bb}^{-1} = \\begin{pmatrix} \\frac{3}{5} & \\frac{2}{5} \\end{pmatrix} \\begin{pmatrix} \\frac{4}{3} & -\\frac{2}{3} \\\\ -\\frac{2}{3} & \\frac{4}{3} \\end{pmatrix} = \\begin{pmatrix} \\frac{12}{15} - \\frac{4}{15} & -\\frac{6}{15} + \\frac{8}{15} \\end{pmatrix} = \\begin{pmatrix} \\frac{8}{15} & \\frac{2}{15} \\end{pmatrix} $$\n$$ (\\Sigma_{ab} \\Sigma_{bb}^{-1}) \\Sigma_{ba} = \\begin{pmatrix} \\frac{8}{15} & \\frac{2}{15} \\end{pmatrix} \\begin{pmatrix} \\frac{3}{5} \\\\ \\frac{2}{5} \\end{pmatrix} = \\frac{24}{75} + \\frac{4}{75} = \\frac{28}{75} $$\n因此，条件方差为：\n$$ \\sigma^2_{\\text{cond}} = 1 - \\frac{28}{75} = \\frac{47}{75} $$\n所以，$Z_1$ 在给定 $Z_2=0, Z_3=0$ 条件下的条件分布是 $N(0, \\frac{47}{75})$。\n\n步骤 4：关联 $L_1$ 和 $Z_1$ 的分位数。\n我们寻求 $q$ 使得 $P(L_1 \\le q | L_2=\\ln 2, L_3=\\frac{\\ln 2}{2}) = 0.99$。\n这个概率可以通过一连串的转换来表示：\n$L_1 \\le q \\iff F_1(L_1) \\le F_1(q) \\iff U_1 \\le F_1(q) \\iff \\Phi(Z_1) \\le F_1(q) \\iff Z_1 \\le \\Phi^{-1}(F_1(q))$。\n条件事件 $L_2=\\ln 2, L_3=\\frac{\\ln 2}{2}$ 等价于 $Z_2=0, Z_3=0$。\n所以，我们需要解：\n$$ P(Z_1 \\le \\Phi^{-1}(F_1(q)) | Z_2=0, Z_3=0) = 0.99 $$\n令 $Z'_1$ 表示在此条件下随机变量 $Z_1$。我们知道 $Z'_1 \\sim N(0, \\frac{47}{75})$。\n令 $Y = \\frac{Z'_1 - 0}{\\sqrt{47/75}} \\sim N(0,1)$。该概率变为：\n$$ P\\left(Y \\le \\frac{\\Phi^{-1}(F_1(q))}{\\sqrt{47/75}}\\right) = 0.99 $$\n根据标准正态累积分布函数 $\\Phi$ 的定义，这等价于：\n$$ \\Phi\\left(\\frac{\\Phi^{-1}(F_1(q))}{\\sqrt{47/75}}\\right) = 0.99 $$\n对两边应用逆函数 $\\Phi^{-1}$：\n$$ \\frac{\\Phi^{-1}(F_1(q))}{\\sqrt{47/75}} = \\Phi^{-1}(0.99) $$\n$$ \\Phi^{-1}(F_1(q)) = \\sqrt{\\frac{47}{75}} \\Phi^{-1}(0.99) $$\n\n步骤 5：推导 $q$ 的最终表达式。\n对上一个等式两边应用函数 $\\Phi$，得到：\n$$ F_1(q) = \\Phi\\left(\\sqrt{\\frac{47}{75}} \\Phi^{-1}(0.99)\\right) $$\n为了求出 $q$，我们需要边缘累积分布函数 $F_1(x)$ 的逆函数。\n$u = F_1(x) = 1 - \\exp(-\\lambda_1 x) \\implies \\exp(-\\lambda_1 x) = 1-u \\implies -\\lambda_1 x = \\ln(1-u) \\implies x = F_1^{-1}(u) = -\\frac{1}{\\lambda_1}\\ln(1-u)$。\n给定 $\\lambda_1 = \\frac{1}{2}$，我们有 $F_1^{-1}(u) = -2\\ln(1-u)$。\n应用这个逆函数来获得 $q$：\n$$ q = F_1^{-1}\\left( \\Phi\\left(\\sqrt{\\frac{47}{75}} \\Phi^{-1}(0.99)\\right) \\right) $$\n$$ q = -2 \\ln\\left(1 - \\Phi\\left(\\sqrt{\\frac{47}{75}} \\Phi^{-1}(0.99)\\right)\\right) $$\n这就是 $L_1$ 的条件 $0.99$-分位数的最终闭式解析表达式。根据题目说明中提到的“美元”，该表达式代表损失的基础货币单位的价值，在最终答案中我们将其视为一个纯数。",
            "answer": "$$\n\\boxed{-2 \\ln\\left(1 - \\Phi\\left(\\sqrt{\\frac{47}{75}} \\Phi^{-1}(0.99)\\right)\\right)}\n$$"
        },
        {
            "introduction": "在实践中，选择高斯 Copula 还是 t-Copula 的主要依据在于它们对尾部依赖性的处理方式不同。本模拟练习旨在将这一抽象差异具体化，通过编程模拟金融危机情景，您将直接观察并量化 t-Copula 如何产生更多的联合极端事件。理解这一关键特征对于构建切合实际的风险模型至关重要 。",
            "id": "2396079",
            "problem": "您的任务是构建一个针对两种资产的合成危机情景，方法是使用自由度极低（具体为 $\\nu=3$）的学生t-copula模拟联合左尾事件，并将其与高斯copula进行比较。您将编写一个完整、可运行的程序，该程序会针对几种参数设置，估计两种资产同时经历低于指定边际分位数的收益的经验概率，并将这些估计值汇总到单行输出中。\n\n将使用的基本概念包括：Copula（联结函数）是一个定义在 $[0,1]^d$ 上的多元累积分布函数（CDF），其边际分布为均匀分布，它将多个单变量边际分布耦合为一个联合分布。高斯copula是通过将标准正态CDF应用于一个多元正态向量而产生的；学生t-copula是通过将单变量学生t分布CDF应用于一个多元学生t分布向量而产生的。CDF指累积分布函数（Cumulative Distribution Function），本任务不需要概率密度函数（PDF）。Sklar定理表明，可以使用copula构建具有指定边际分布的联合分布。对于椭圆分布，一个标准且经过充分检验的构造方法如下：如果 $Z \\sim \\mathcal{N}(0,\\Sigma)$ 是一个相关矩阵为 $\\Sigma$ 的多元正态变量，并且 $S \\sim \\chi^2_{\\nu}$ 是一个独立于 $Z$ 的卡方随机变量，则 $T = Z/\\sqrt{S/\\nu}$ 服从自由度为 $\\nu$、相关矩阵为 $\\Sigma$ 的多元学生t分布。对于相关参数为 $\\rho \\in (-1,1)$ 的高斯copula，可以取 $Z \\in \\mathbb{R}^2$ 为相关矩阵是 $\\Sigma = \\begin{pmatrix}1 & \\rho \\\\ \\rho & 1\\end{pmatrix}$ 的二元正态变量，并通过标准正态CDF进行逐分量映射以获得均匀边际分布。对于具有相同相关参数 $\\rho$ 和自由度 $\\nu$ 的学生t-copula，可以取 $T \\in \\mathbb{R}^2$ 为相关矩阵是 $\\Sigma$、自由度为 $\\nu$ 的二元学生t变量，并通过自由度为 $\\nu$ 的单变量学生t CDF进行逐分量映射以获得均匀边际分布。\n\n将合成危机事件定义为两个资产的边际均匀变量同时低于给定水平 $\\alpha \\in (0,1)$ 的事件。对于高斯copula，这等同于观察到底层的两个高斯分量都低于 $q_{\\alpha}^{(N)} = \\Phi^{-1}(\\alpha)$；对于自由度为 $\\nu$ 的学生t-copula，这等同于观察到底层的两个学生t分量都低于 $q_{\\alpha}^{(t)} = F^{-1}_{t,\\nu}(\\alpha)$，其中 $\\Phi^{-1}$ 是标准正态CDF的反函数，$F^{-1}_{t,\\nu}$ 是自由度为 $\\nu$ 的单变量学生t CDF的反函数。\n\n您的程序必须为每个测试用例执行以下所有步骤：\n1. 固定整数样本量 $N = 1{,}000{,}000$ 和一个固定的随机种子（如下所述），以确保可复现性。\n2. 为指定的相关参数 $\\rho$ 构建 $2 \\times 2$ 相关矩阵 $\\Sigma = \\begin{pmatrix}1 & \\rho \\\\ \\rho & 1\\end{pmatrix}$。\n3. 从二元正态分布 $\\mathcal{N}(0,\\Sigma)$ 中模拟 $N$ 个独立样本 $Z \\in \\mathbb{R}^2$，并估计高斯copula下的经验联合左尾概率为\n$$\n\\widehat{p}_{G} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{1}\\{Z_{i,1} < q_{\\alpha}^{(N)} \\ \\text{and} \\ Z_{i,2} < q_{\\alpha}^{(N)}\\},\n$$\n其中 $q_{\\alpha}^{(N)} = \\Phi^{-1}(\\alpha)$ 且 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n4. 使用上述的椭圆尺度混合表示，从自由度为 $\\nu=3$、相关矩阵为 $\\Sigma$ 的二元学生t分布中模拟 $N$ 个独立样本 $T \\in \\mathbb{R}^2$。并估计学生t-copula下的经验联合左尾概率为\n$$\n\\widehat{p}_{t} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{1}\\{T_{i,1} < q_{\\alpha}^{(t)} \\ \\text{and} \\ T_{i,2} < q_{\\alpha}^{(t)}\\},\n$$\n其中 $q_{\\alpha}^{(t)} = F^{-1}_{t,\\nu}(\\alpha)$ 且 $\\nu=3$。\n5. 计算放大比率\n$$\nr = \\frac{\\widehat{p}_{t}}{\\widehat{p}_{G}}。\n$$\n\n使用以下固定的随机化协议以确保可复现性：对于下面给出的顺序中的测试用例索引 $k \\in \\{0,1,2,3\\}$，使用种子 $s_k = 24681357 + 10000 \\cdot k$ 初始化一个新的伪随机数生成器，并将其用于该测试用例中的所有随机抽样。\n\n测试套件（每个用例指定了相关参数 $\\rho$ 和尾部水平 $\\alpha$）：\n- 用例1（边界：零线性相关）：$\\rho = 0.0$, $\\alpha = 0.01$。\n- 用例2（正常路径：中等正相关）：$\\rho = 0.7$, $\\alpha = 0.01$。\n- 用例3（边缘：极强正相关）：$\\rho = 0.95$, $\\alpha = 0.01$。\n- 用例4（尾部水平变化）：$\\rho = 0.7$, $\\alpha = 0.05$。\n\n程序要求：\n- 通过一种数值稳定的方法（如Cholesky分解）施加指定的相关矩阵 $\\Sigma$，以实现二元正态模拟。\n- 使用尺度混合构造法实现二元学生t模拟，其中混合变量为自由度 $\\nu=3$ 的卡方变量，核心为相关矩阵是 $\\Sigma$ 的二元正态分布。\n- 如上所述，分别对底层的高斯或学生t样本使用阈值比较来评估联合左尾事件。不要通过单变量CDF转换每个样本坐标；只需计算分位数阈值 $q_{\\alpha}^{(N)}$ 和 $q_{\\alpha}^{(t)}$。\n- 每个测试用例中，每个copula使用 $N = 1{,}000{,}000$ 个样本。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于每个测试用例，按顺序附加三个浮点数 $\\widehat{p}_{G}$、$\\widehat{p}_{t}$ 和 $r$。因此，最后一行必须包含对应于四个测试用例的12个浮点数，并按所列顺序排列。例如，输出必须具有以下形式\n$[\\widehat{p}_{G,1},\\widehat{p}_{t,1},r_1,\\widehat{p}_{G,2},\\widehat{p}_{t,2},r_2,\\widehat{p}_{G,3},\\widehat{p}_{t,3},r_3,\\widehat{p}_{G,4},\\widehat{p}_{t,4},r_4]$。\n- 所有数字必须以十进制浮点数形式打印。不涉及任何物理单位或角度单位。不要打印任何附加文本。",
            "solution": "问题陈述经确认为科学上合理、定义明确且完整。它描述了量化金融领域一个标准且有意义的数值实验，用于比较高斯copula和学生t-copula的尾部相关性属性。该方法论是可靠的，并且所有必需的参数和程序都已明确规定。因此，我们可以着手解决。\n\n目标是量化由高斯copula与学生t-copula建模的联合左尾风险的差异。众所周知，学生t-copula（尤其是在自由度较少时）表现出更强的尾部相关性，这意味着极端负面事件比高斯模型预测的更有可能联合发生。我们将要测量的正是这一现象。放大比率 $r = \\widehat{p}_{t}/\\widehat{p}_{G}$ 将作为这种效应的直接度量。\n\n该任务的核心是蒙特卡洛模拟。对于四个指定的测试用例中的每一个，我们执行以下过程。\n\n一个测试用例由一个相关参数 $\\rho$ 和一个尾部概率水平 $\\alpha$ 定义。学生t分布的自由度固定为 $\\nu = 3$。每次估计的模拟样本数量为 $N = 1,000,000$。\n\n首先，我们建立模拟框架。为确保可复现性，我们为每个测试用例 $k \\in \\{0, 1, 2, 3\\}$ 使用特定种子 $s_k = 24681357 + 10000 \\cdot k$ 初始化一个新的伪随机数生成器。$2 \\times 2$ 相关矩阵构造如下：\n$$\n\\Sigma = \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}\n$$\n为了生成相关的随机变量，我们使用 $\\Sigma$ 的Cholesky分解。我们找到一个下三角矩阵 $L$，使得 $\\Sigma = LL^T$。如果 $X = (X_1, X_2)^T$ 是一个由两个独立的标准正态随机变量组成的向量，那么向量 $Z = LX$ 将服从二元正态分布 $\\mathcal{N}(0, \\Sigma)$。这是一种施加所需相关结构的标准且数值稳定的方法。\n\n有了这个设置，我们继续估计这两个概率。\n\n1.  **高斯Copula概率 ($\\widehat{p}_{G}$)**:\n    我们需要估计概率 $P(U_1 < \\alpha, U_2 < \\alpha)$，其中 $(U_1, U_2)$ 根据参数为 $\\rho$ 的高斯copula分布。这等同于估计底层的相关正态变量低于相应分位数的概率。具体来说，如果 $Z = (Z_1, Z_2)^T \\sim \\mathcal{N}(0, \\Sigma)$，我们正在估计 $P(Z_1 < q_{\\alpha}^{(N)}, Z_2 < q_{\\alpha}^{(N)})$。阈值 $q_{\\alpha}^{(N)}$ 是标准正态分布的 $\\alpha$-分位数，由 $q_{\\alpha}^{(N)} = \\Phi^{-1}(\\alpha)$ 给出，其中 $\\Phi^{-1}$ 是标准正态累积分布函数（CDF）的反函数。\n    我们从 $\\mathcal{N}(0, \\Sigma)$ 中生成 $N$ 个独立样本 $\\{Z_i\\}_{i=1}^N$。然后，经验概率计算为两个分量都低于阈值的样本所占的比例：\n    $$\n    \\widehat{p}_{G} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{1}\\{Z_{i,1} < q_{\\alpha}^{(N)} \\ \\text{and} \\ Z_{i,2} < q_{\\alpha}^{(N)}\\}\n    $$\n    其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n\n2.  **学生t-Copula概率 ($\\widehat{p}_{t}$)**:\n    过程是类似的，但使用的是多元学生t分布。我们估计概率 $P(T_1 < q_{\\alpha}^{(t)}, T_2 < q_{\\alpha}^{(t)})$，其中 $T = (T_1, T_2)^T$ 服从自由度为 $\\nu = 3$、相关矩阵为 $\\Sigma$ 的二元学生t分布。阈值 $q_{\\alpha}^{(t)}$ 是自由度为 $\\nu=3$ 的单变量学生t分布的 $\\alpha$-分位数，$q_{\\alpha}^{(t)} = F^{-1}_{t,3}(\\alpha)$。\n    为了从多元学生t分布中生成样本，我们使用指定的尺度混合表示。对于每个样本 $i=1, \\dots, N$，我们生成一个向量 $Z_i \\sim \\mathcal{N}(0, \\Sigma)$ 和一个独立的标量 $S_i \\sim \\chi^2_{\\nu}$（自由度为 $\\nu$ 的卡方分布）。然后，学生t分布的向量 $T_i$ 构造如下：\n    $$\n    T_i = \\frac{Z_i}{\\sqrt{S_i/\\nu}}\n    $$\n    生成 $N$ 个样本 $\\{T_i\\}_{i=1}^N$ 后，经验概率估计为：\n    $$\n    \\widehat{p}_{t} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{1}\\{T_{i,1} < q_{\\alpha}^{(t)} \\ \\text{and} \\ T_{i,2} < q_{\\alpha}^{(t)}\\}\n    $$\n\n最后，对于每个测试用例，我们计算放大比率 $r = \\widehat{p}_{t} / \\widehat{p}_{G}$。这个比率直接衡量了在学生t-copula模型下发生联合危机事件的可能性相对于高斯模型的增加程度。\n\n随附的Python程序实现了这整个过程。它使用 `numpy` 进行数值线性代数和随机数生成，使用 `scipy.stats` 计算所需的逆CDF值（`ppf`函数）。其逻辑被封装在一个循环中，该循环遍历四个测试用例，为每个用例计算 $\\widehat{p}_{G}$、$\\widehat{p}_{t}$ 和 $r$，并将结果汇总为指定的输出格式。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm, t\n\ndef solve():\n    \"\"\"\n    Simulates joint left-tail events for Gaussian and Student's t-copulas\n    to compare tail dependence and compute the amplification ratio.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple (rho, alpha).\n    test_cases = [\n        (0.0, 0.01),   # Case 1\n        (0.7, 0.01),   # Case 2\n        (0.95, 0.01),  # Case 3\n        (0.7, 0.05),   # Case 4\n    ]\n\n    # Global parameters as specified in the problem.\n    N = 1_000_000\n    nu = 3  # Degrees of freedom for the Student's t-copula.\n\n    # Store all final results (p_G, p_t, r for each case).\n    results = []\n\n    for k, case in enumerate(test_cases):\n        rho, alpha = case\n        \n        # 1. Initialize PRNG with the specified seed for reproducibility.\n        seed = 24681357 + 10000 * k\n        rng = np.random.default_rng(seed)\n\n        # 2. Construct the correlation matrix and its Cholesky decomposition.\n        # Sigma = [[1, rho], [rho, 1]]\n        sigma = np.array([[1.0, rho], [rho, 1.0]])\n        # L is the lower-triangular Cholesky factor, such that Sigma = L * L.T\n        try:\n            L = np.linalg.cholesky(sigma)\n        except np.linalg.LinAlgError:\n            # This should not happen for valid correlation matrices where |rho|  1.\n            # Handle as a failsafe.\n            results.extend([np.nan, np.nan, np.nan])\n            continue\n            \n        # --- Gaussian Copula Simulation ---\n        \n        # 3. Simulate N samples from the bivariate normal distribution N(0, Sigma).\n        # Generate N x 2 independent standard normal variates.\n        X_g = rng.standard_normal(size=(N, 2))\n        # Correlate them using the Cholesky factor: Z = X * L.T\n        Z = X_g @ L.T\n        \n        # Calculate the quantile threshold for the Gaussian case.\n        q_alpha_N = norm.ppf(alpha)\n        \n        # Estimate the empirical joint left-tail probability p_G.\n        # Count occurrences where both Z_1  q_alpha_N and Z_2  q_alpha_N.\n        joint_events_g = np.sum((Z[:, 0]  q_alpha_N)  (Z[:, 1]  q_alpha_N))\n        p_hat_G = joint_events_g / N\n\n        # --- Student's t-Copula Simulation ---\n        \n        # 4. Simulate N samples from the bivariate Student's t-distribution.\n        # Generate N x 2 independent standard normal variates (fresh draw).\n        X_t = rng.standard_normal(size=(N, 2))\n        # Correlate them: Z_t = X_t * L.T\n        Z_t = X_t @ L.T\n        \n        # Generate N samples from a chi-squared distribution with nu degrees of freedom.\n        s = rng.chisquare(df=nu, size=N)\n        \n        # Construct the Student's t samples using the scale-mixture representation.\n        # T = Z_t / sqrt(s / nu). Use [:, np.newaxis] for broadcasting.\n        T = Z_t / np.sqrt(s / nu)[:, np.newaxis]\n        \n        # Calculate the quantile threshold for the Student's t-case.\n        q_alpha_t = t.ppf(alpha, df=nu)\n        \n        # Estimate the empirical joint left-tail probability p_t.\n        # Count occurrences where both T_1  q_alpha_t and T_2  q_alpha_t.\n        joint_events_t = np.sum((T[:, 0]  q_alpha_t)  (T[:, 1]  q_alpha_t))\n        p_hat_t = joint_events_t / N\n\n        # 5. Compute the amplification ratio.\n        # Handle division by zero, though unlikely with these parameters.\n        if p_hat_G == 0:\n            ratio = np.inf if p_hat_t  0 else np.nan\n        else:\n            ratio = p_hat_t / p_hat_G\n            \n        results.extend([p_hat_G, p_hat_t, ratio])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "面对众多可用的 Copula 模型，从业者必须掌握一种有原则的方法，来为特定数据集选择最合适的模型。本练习将向您介绍赤池信息准则（Akaike Information Criterion, AIC），这是一种强大的模型选择工具。您将学习从处理原始数据、拟合多种 Copula 模型，到最终利用 AIC 做出有理有据选择的完整工作流程 。",
            "id": "2384712",
            "problem": "构建一个程序，给定三个配对资产回报率的合成数据集，通过最小化赤池信息准则（AIC）从三个Copula族中进行选择。您必须根据Sklar定理，使用基于秩的伪观测值来推导并实现Copula参数的最大似然估计量，然后为每个候选Copula计算AIC。三个候选Copula是：高斯Copula、学生t-Copula和Clayton Copula。为确保评估的明确性，您必须遵守以下规范。\n\n使用的基本原理和定义：\n- Sklar定理指出，任何联合累积分布函数都可以用其边缘分布函数和一个捕捉依赖结构的Copula来表示。因此，对于连续的边缘分布，联合密度可以分解为边缘密度与Copula密度的乘积。对于Copula的估计，您将使用基于秩的伪观测值。\n- 给定具有连续边缘分布的配对观测值 $\\{(X_i, Y_i)\\}_{i=1}^n$，通过 $U_i = \\frac{\\mathrm{rank}(X_i)}{n + 1}$ 和 $V_i = \\frac{\\mathrm{rank}(Y_i)}{n + 1}$ 定义伪观测值，其中 $\\mathrm{rank}(\\cdot)$ 是取值为 $\\{1,2,\\dots,n\\}$ 的递增秩。\n- 对于一个参数向量为 $\\theta$ 的Copula族，其Copula对数似然为 $\\ell(\\theta) = \\sum_{i=1}^n \\log c(U_i, V_i; \\theta)$，其中 $c(\\cdot,\\cdot;\\theta)$ 是Copula密度函数。赤池信息准则（AIC）为 $\\mathrm{AIC} = 2k - 2\\ell(\\hat{\\theta})$，其中 $k$ 是自由参数的数量，$\\hat{\\theta}$ 是使对数似然最大化的参数值。\n\n需要实现的任务：\n1. 伪观测值构建：\n   - 对每个给定的数据集，使用秩公式 $U_i = \\frac{\\mathrm{rank}(X_i)}{n + 1}$ 和 $V_i = \\frac{\\mathrm{rank}(Y_i)}{n + 1}$ 计算 $U_i$ 和 $V_i$，其中 $i = 1,\\dots,n$。\n2. Copula族和参数估计：\n   - 高斯Copula：一个参数 $\\rho \\in (-1,1)$。通过在 $\\rho \\in (-0.999, 0.999)$ 上最大化Copula对数似然，执行最大似然估计以获得 $\\hat{\\rho}$。\n   - 学生t-Copula：两个参数，相关性 $\\rho \\in (-1,1)$ 和自由度 $\\nu \\in (2, +\\infty)$。通过在 $\\rho \\in (-0.999, 0.999)$ 和一个合理的正数域（如 $\\nu \\in [3, 30]$）上最大化Copula对数似然，执行最大似然估计以获得 $(\\hat{\\rho}, \\hat{\\nu})$。\n   - Clayton Copula：一个参数 $\\theta \\in (0, +\\infty)$。通过在 $\\theta \\in (10^{-4}, 30]$ 上最大化Copula对数似然，执行最大似然估计以获得 $\\hat{\\theta}$。\n   - 您必须从这些Copula及其密度的标准定义出发，以数学上正确的方式实现Copula对数似然。除了上述基本定义外，不要假定任何捷径。\n3. 模型选择：\n   - 对于每个数据集，使用最大对数似然和适当的参数数量 $k$（高斯Copula $k=1$，学生t-Copula $k=2$，Clayton Copula $k=1$）为每个Copula族计算 $\\mathrm{AIC}$。选择具有最小AIC的Copula。\n4. 输出格式：\n   - 根据以下映射，将每个数据集选定的Copula编码为一个整数：高斯Copula $\\to 0$，学生t-Copula $\\to 1$，Clayton Copula $\\to 2$。\n   - 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。例如，如果三个数据集选定的Copula依次是高斯、学生t和Clayton，则输出必须是 `[0,1,2]`。\n\n测试套件（在程序内生成的数据集；不允许用户输入）：\n- 数据集A（高相关性，对称依赖）：\n  - 样本量 $n = 1000$。\n  - 随机种子 $s = 123$。\n  - 真实Copula：相关性 $\\rho = 0.9$ 的高斯Copula。\n  - 边缘分布（以获得逼真的“回报”但保留Copula）：使用自由度为 $\\nu_m = 5$ 的学生t分布进行变换，并由 $\\sigma_X = 0.01$ 和 $\\sigma_Y = 0.012$ 进行缩放，即定义 $X = \\sigma_X \\cdot t_{\\nu_m}^{-1}(U)$ 和 $Y = \\sigma_Y \\cdot t_{\\nu_m}^{-1}(V)$。\n- 数据集B（高相关性伴随重尾，对称尾部依赖）：\n  - 样本量 $n = 1500$。\n  - 随机种子 $s = 456$。\n  - 真实Copula：相关性 $\\rho = 0.85$ 和自由度 $\\nu = 4$ 的学生t-Copula。\n  - 边缘分布：使用高斯分位数进行变换，并由 $\\sigma_X = 0.008$ 和 $\\sigma_Y = 0.010$ 进行缩放，即定义 $X = \\sigma_X \\cdot \\Phi^{-1}(U)$ 和 $Y = \\sigma_Y \\cdot \\Phi^{-1}(V)$。\n- 数据集C（高的正向下尾相关性）：\n  - 样本量 $n = 1000$。\n  - 随机种子 $s = 789$。\n  - 真实Copula：参数 $\\theta = 5$ 的Clayton Copula。\n  - 边缘分布：使用偏态回报典型的单调映射进行变换，例如，通过 $X = \\exp(\\mu_X + \\sigma_X \\cdot \\Phi^{-1}(U)) - 1$ 和 $Y = \\exp(\\mu_Y + \\sigma_Y \\cdot \\Phi^{-1}(V)) - 1$ 得到类对数正态分布，其中 $\\mu_X = 0$, $\\mu_Y = 0$, $\\sigma_X = 0.2$, $\\sigma_Y = 0.25$。\n  \n注意：\n- 所有随机变量必须在程序内部使用指定的种子和参数生成，以便结果是可复现的。\n- 角度单位不适用。\n- 无需报告物理单位；最终答案是指定的整数。\n- 您的程序必须以要求的格式 `[r_1,r_2,r_3]` 准确输出一行，其中每个 $r_j$ 是一个在 $\\{0,1,2\\}$ 中的整数，按A、B、C的顺序指示数据集 $j$ 选定的Copula。",
            "solution": "所述问题经过严格验证，被认为是有效的。它在科学上是合理的、良定的，并以客观、无歧义的语言表述。它提出了一个计算计量经济学中标准的（尽管不简单）问题，涉及Copula模型选择。因此，我们将着手提供一个完整的解决方案。\n\n目标是为三个不同的合成数据集，从一个候选集合——高斯Copula、学生t-Copula和Clayton Copula——中选出最佳拟合的Copula。选择标准是最小化赤池信息准则（AIC）。该解决方案要求基于从生成数据中导出的秩伪观测值，实现每个Copula族参数的最大似然估计。\n\n总体方法如下：\n1.  对于三个测试案例（A、B、C）中的每一个，根据指定的真实Copula和边缘分布，生成一个大小为 $n$ 的二元数据集。\n2.  将每个原始数据集 $\\{(X_i, Y_i)\\}_{i=1}^n$ 转换为一组伪观测值 $\\{(U_i, V_i)\\}_{i=1}^n$。这是对边缘累积分布函数的非参数估计，基于秩：\n    $$\n    U_i = \\frac{\\mathrm{rank}(X_i)}{n + 1}, \\quad V_i = \\frac{\\mathrm{rank}(Y_i)}{n + 1}\n    $$\n    这种变换将作为Copula研究领域的依赖结构与边缘分布分离开来，这与Sklar定理一致。\n3.  对于每个Copula族和每个数据集，执行最大似然估计（MLE）以找到最优参数 $\\hat{\\theta}$。这通过数值最大化Copula对数似然函数 $\\ell(\\theta)$ 来实现，该函数定义为：\n    $$\n    \\ell(\\theta) = \\sum_{i=1}^n \\log c(U_i, V_i; \\theta)\n    $$\n    其中 $c(u, v; \\theta)$ 是Copula的概率密度函数。\n4.  为每个拟合的模型计算赤池信息准则（AIC）：\n    $$\n    \\mathrm{AIC} = 2k - 2\\ell(\\hat{\\theta})\n    $$\n    其中 $k$ 是参数向量 $\\theta$ 中估计的参数数量。\n5.  对于每个数据集，选择产生最小AIC值的Copula模型。最终输出将是代表每个数据集所选模型的整数代码。\n\n我们现在详细阐述每个候选Copula的对数似然的数学公式。\n\n**1. 高斯Copula**\n高斯Copula只有一个参数，即相关系数 $\\rho \\in (-1, 1)$，所以 $k=1$。其密度源自二元标准正态分布。设 $\\Phi^{-1}(\\cdot)$ 为标准正态分布的分位数函数。对于一对伪观测值 $(u,v)$，我们定义 $x = \\Phi^{-1}(u)$ 和 $y = \\Phi^{-1}(v)$。Copula密度为：\n$$\nc_G(u, v; \\rho) = \\frac{1}{\\sqrt{1-\\rho^2}} \\exp\\left( -\\frac{\\rho^2(x^2+y^2) - 2\\rho xy}{2(1-\\rho^2)} \\right)\n$$\n因此，对数密度为：\n$$\n\\log c_G(u, v; \\rho) = -\\frac{1}{2}\\log(1-\\rho^2) - \\frac{\\rho^2(x^2+y^2) - 2\\rho xy}{2(1-\\rho^2)}\n$$\n总对数似然 $\\ell_G(\\rho)$ 是对所有 $i=1, \\dots, n$ 的 $\\log c_G(u_i, v_i; \\rho)$ 的总和。我们通过最大化 $\\ell_G(\\rho)$ 来找到 $\\hat{\\rho}$。\n\n**2. 学生t-Copula**\n学生t-Copula有两个参数：相关系数 $\\rho \\in (-1, 1)$ 和自由度 $\\nu \\in (2, \\infty)$，所以 $k=2$。设 $t_\\nu^{-1}(\\cdot)$ 为具有 $\\nu$ 自由度的单变量学生t分布的分位数函数。对于一对 $(u,v)$，我们定义 $x = t_\\nu^{-1}(u)$ 和 $y = t_\\nu^{-1}(v)$。Copula密度由下式给出：\n$$\nc_t(u,v;\\rho,\\nu) = \\frac{1}{\\sqrt{1-\\rho^2}} \\frac{\\Gamma\\left(\\frac{\\nu+2}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right)}{\\left[\\Gamma\\left(\\frac{\\nu+1}{2}\\right)\\right]^2} \\frac{\\left(1+\\frac{x^2}{\\nu}\\right)^{\\frac{\\nu+1}{2}}\\left(1+\\frac{y^2}{\\nu}\\right)^{\\frac{\\nu+1}{2}}}{\\left(1+\\frac{x^2 - 2\\rho xy + y^2}{\\nu(1-\\rho^2)}\\right)^{\\frac{\\nu+2}{2}}}\n$$\n其中 $\\Gamma(\\cdot)$ 是伽马函数。使用对数伽马函数 $\\mathrm{gammaln}(\\cdot) = \\log\\Gamma(\\cdot)$，对数密度为：\n$$\n\\begin{aligned}\n\\log c_t(u,v;\\rho,\\nu) =  -\\frac{1}{2}\\log(1-\\rho^2) + \\mathrm{gammaln}\\left(\\frac{\\nu+2}{2}\\right) + \\mathrm{gammaln}\\left(\\frac{\\nu}{2}\\right) - 2\\cdot\\mathrm{gammaln}\\left(\\frac{\\nu+1}{2}\\right) \\\\\n - \\frac{\\nu+2}{2}\\log\\left(1 + \\frac{x^2 - 2\\rho xy + y^2}{\\nu(1-\\rho^2)}\\right) \\\\\n + \\frac{\\nu+1}{2}\\left(\\log\\left(1+\\frac{x^2}{\\nu}\\right) + \\log\\left(1+\\frac{y^2}{\\nu}\\right)\\right)\n\\end{aligned}\n$$\n对数似然 $\\ell_t(\\rho, \\nu)$ 是对所有数据点的总和。数值最大化中的一个关键点是，值 $x_i$ 和 $y_i$ 依赖于参数 $\\nu$，并且必须在对 $\\nu$ 的优化过程的每一步重新计算。\n\n**3. Clayton Copula**\nClayton Copula有一个参数 $\\theta \\in (0, \\infty)$，所以 $k=1$。它是一个阿基米德Copula，特别适用于模拟下尾相关性。其密度函数为：\n$$\nc_C(u, v; \\theta) = (\\theta+1)(uv)^{-(\\theta+1)}(u^{-\\theta} + v^{-\\theta} - 1)^{-(2\\theta+1)/\\theta}\n$$\n对数密度为：\n$$\n\\log c_C(u, v; \\theta) = \\log(\\theta+1) - (\\theta+1)(\\log u + \\log v) - \\frac{2\\theta+1}{\\theta}\\log(u^{-\\theta} + v^{-\\theta} - 1)\n$$\n总对数似然 $\\ell_C(\\theta)$ 是对所有数据点的 $\\log c_C(u_i,v_i;\\theta)$ 的总和，然后通过最大化该值来找到 $\\hat{\\theta}$。\n\n接下来的程序实现了这整个过程。它首先定义了生成三个数据集的函数。然后，对于每个数据集，它计算伪观测值，并为三个Copula中的每一个定义负对数似然函数。使用有界数值优化算法最小化这些函数以获得参数估计。最后，为每个模型计算AIC，确定最小值，并记录相应的模型索引。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import rankdata, norm, t\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\ndef generate_data_A():\n    \"\"\"Generates Dataset A.\"\"\"\n    n = 1000\n    seed = 123\n    rho = 0.9\n    nu_m = 5\n    sigma_X = 0.01\n    sigma_Y = 0.012\n    \n    rng = np.random.default_rng(seed)\n    cov = np.array([[1, rho], [rho, 1]])\n    Z = rng.multivariate_normal([0, 0], cov, size=n)\n    \n    U = norm.cdf(Z[:, 0])\n    V = norm.cdf(Z[:, 1])\n    \n    X = sigma_X * t.ppf(U, df=nu_m)\n    Y = sigma_Y * t.ppf(V, df=nu_m)\n    \n    return np.vstack((X, Y)).T\n\ndef generate_data_B():\n    \"\"\"Generates Dataset B.\"\"\"\n    n = 1500\n    seed = 456\n    rho = 0.85\n    nu = 4\n    sigma_X = 0.008\n    sigma_Y = 0.010\n\n    rng = np.random.default_rng(seed)\n    cov = np.array([[1, rho], [rho, 1]])\n    Z = rng.multivariate_normal([0, 0], cov, size=n)\n    chi2_vals = rng.chisquare(df=nu, size=n)\n    \n    T_samples = Z / np.sqrt(chi2_vals / nu)[:, np.newaxis]\n    \n    U = t.cdf(T_samples[:, 0], df=nu)\n    V = t.cdf(T_samples[:, 1], df=nu)\n    \n    X = sigma_X * norm.ppf(U)\n    Y = sigma_Y * norm.ppf(V)\n    \n    return np.vstack((X, Y)).T\n\ndef generate_data_C():\n    \"\"\"Generates Dataset C.\"\"\"\n    n = 1000\n    seed = 789\n    theta = 5.0\n    sigma_X = 0.2\n    sigma_Y = 0.25\n\n    rng = np.random.default_rng(seed)\n    E1 = rng.exponential(scale=1.0, size=n)\n    E2 = rng.exponential(scale=1.0, size=n)\n    G = rng.gamma(shape=1.0/theta, scale=1.0, size=n)\n\n    U = (1 + E1 / G)**(-1.0/theta)\n    V = (1 + E2 / G)**(-1.0/theta)\n\n    X = np.exp(sigma_X * norm.ppf(U)) - 1\n    Y = np.exp(sigma_Y * norm.ppf(V)) - 1\n    \n    return np.vstack((X, Y)).T\n\ndef get_pseudo_obs(data):\n    \"\"\"Computes pseudo-observations from a dataset.\"\"\"\n    n = data.shape[0]\n    u = rankdata(data[:, 0], method='ordinal') / (n + 1)\n    v = rankdata(data[:, 1], method='ordinal') / (n + 1)\n    return u, v\n\ndef neg_log_likelihood_gaussian(rho, u, v):\n    \"\"\"Negative log-likelihood for the Gaussian copula.\"\"\"\n    if np.abs(rho) = 1.0:\n        return np.inf\n    x = norm.ppf(u)\n    y = norm.ppf(v)\n    \n    log_c = -0.5 * np.log(1 - rho**2) - (rho**2 * (x**2 + y**2) - 2 * rho * x * y) / (2 * (1 - rho**2))\n    \n    return -np.sum(log_c)\n\ndef neg_log_likelihood_t(params, u, v):\n    \"\"\"Negative log-likelihood for the Student's t copula.\"\"\"\n    rho, nu = params\n    x = t.ppf(u, df=nu)\n    y = t.ppf(v, df=nu)\n    \n    term1 = -0.5 * np.log(1 - rho**2)\n    term2 = gammaln((nu + 2) / 2) + gammaln(nu / 2) - 2 * gammaln((nu + 1) / 2)\n    \n    num_log_term3 = x**2 - 2 * rho * x * y + y**2\n    den_log_term3 = nu * (1 - rho**2)\n    term3 = -((nu + 2) / 2) * np.log(1 + num_log_term3 / den_log_term3)\n    \n    term4 = ((nu + 1) / 2) * (np.log(1 + x**2 / nu) + np.log(1 + y**2 / nu))\n    \n    log_c = term1 + term2 + term3 + term4\n    return -np.sum(log_c)\n\ndef neg_log_likelihood_clayton(theta, u, v):\n    \"\"\"Negative log-likelihood for the Clayton copula.\"\"\"\n    if theta = 0:\n        return np.inf\n\n    log_c = np.log(theta + 1) \\\n            - (theta + 1) * (np.log(u) + np.log(v)) \\\n            - ((2 * theta + 1) / theta) * np.log(u**(-theta) + v**(-theta) - 1)\n    \n    # Handle potential NaNs from floating point issues\n    if np.any(np.isnan(log_c)):\n        return np.inf\n\n    return -np.sum(log_c)\n\ndef solve():\n    \"\"\"\n    Main function to perform model selection for the three datasets.\n    \"\"\"\n    datasets = {\n        'A': generate_data_A(),\n        'B': generate_data_B(),\n        'C': generate_data_C()\n    }\n    \n    results = []\n    \n    for key in ['A', 'B', 'C']:\n        data = datasets[key]\n        u, v = get_pseudo_obs(data)\n        \n        # 1. Gaussian Copula\n        res_g = minimize(neg_log_likelihood_gaussian, x0=0.5, args=(u, v),\n                         method='L-BFGS-B', bounds=[(-0.999, 0.999)])\n        max_ll_g = -res_g.fun\n        aic_g = 2 * 1 - 2 * max_ll_g\n\n        # 2. Student's t Copula\n        res_t = minimize(neg_log_likelihood_t, x0=[0.5, 10.0], args=(u, v),\n                         method='L-BFGS-B', bounds=[(-0.999, 0.999), (3.0, 30.0)])\n        max_ll_t = -res_t.fun\n        aic_t = 2 * 2 - 2 * max_ll_t\n        \n        # 3. Clayton Copula\n        res_c = minimize(neg_log_likelihood_clayton, x0=2.0, args=(u, v),\n                         method='L-BFGS-B', bounds=[(1e-4, 30.0)])\n        max_ll_c = -res_c.fun\n        aic_c = 2 * 1 - 2 * max_ll_c\n        \n        # Model Selection\n        aics = [aic_g, aic_t, aic_c]\n        best_model_idx = np.argmin(aics)\n        results.append(best_model_idx)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}