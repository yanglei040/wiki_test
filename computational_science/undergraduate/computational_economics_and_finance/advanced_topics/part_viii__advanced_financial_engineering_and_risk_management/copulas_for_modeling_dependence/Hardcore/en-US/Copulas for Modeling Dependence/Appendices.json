{
    "hands_on_practices": [
        {
            "introduction": "The power of copulas lies in their ability to separate a joint distribution into its marginals and its dependence structure. Before we can model this dependence structure, we must first transform our raw data to have uniform marginals. This exercise provides hands-on practice with the fundamental first step of any empirical copula analysis: converting a real-world dataset, such as stock prices, into \"pseudo-observations\" on the unit square .",
            "id": "1353883",
            "problem": "A financial analyst is studying the dependence between the daily closing prices of two technology stocks, \"Innovate Inc.\" (Stock X) and \"Quantum Corp.\" (Stock Y). The analyst collects the prices for six consecutive trading days, as shown below:\n\n- Day 1: (Stock X: $102, Stock Y: $55)\n- Day 2: (Stock X: $105, Stock Y: $53)\n- Day 3: (Stock X: $101, Stock Y: $58)\n- Day 4: (Stock X: $108, Stock Y: $60)\n- Day 5: (Stock X: $105, Stock Y: $59)\n- Day 6: (Stock X: $104, Stock Y: $55)\n\nTo prepare the data for a non-parametric dependence analysis, the analyst must convert this raw data into a set of \"normalized rank coordinates\". This transformation maps the original bivariate observations $(X_i, Y_i)$ to a new set of coordinates $(u_i, v_i)$ on the unit square $[0, 1] \\times [0, 1]$.\n\nThe transformation rule for a dataset of size $n$ is as follows: For each observation $X_i$ in the set $\\{X_1, \\dots, X_n\\}$, its transformed coordinate is $u_i = \\frac{R(X_i)}{n+1}$, where $R(X_i)$ is the rank of $X_i$ when the set is sorted in ascending order (from 1 for the smallest to $n$ for the largest). The same rule applies to the $Y$ observations. In the case of tied values, the rank assigned to each of the tied values is the average of the ranks they would occupy.\n\nUsing this procedure, determine the normalized rank coordinates $(u_1, v_1)$ corresponding to the data from Day 1. Express your answer as a pair of exact fractions.",
            "solution": "We have $n=6$ observations. The normalized rank transform is defined by\n$$\nu_{i}=\\frac{R(X_{i})}{n+1}, \\qquad v_{i}=\\frac{R(Y_{i})}{n+1},\n$$\nwhere $R(\\cdot)$ is the ascending rank with ties assigned the average of their occupied ranks.\n\nFor $X$: the multiset is $\\{102,105,101,108,105,104\\}$. Sorted ascending: $101,102,104,105,105,108$. The tied values $105$ occupy positions $4$ and $5$, so each receives rank $(4+5)/2=9/2$. Thus $R(X_{1})$ for Day 1 with $X_{1}=102$ is $2$. Therefore,\n$$\nu_{1}=\\frac{R(X_{1})}{6+1}=\\frac{2}{7}.\n$$\n\nFor $Y$: the multiset is $\\{55,53,58,60,59,55\\}$. Sorted ascending: $53,55,55,58,59,60$. The tied values $55$ occupy positions $2$ and $3$, so each receives rank $(2+3)/2=5/2$. Thus $R(Y_{1})$ for Day 1 with $Y_{1}=55$ is $5/2$. Therefore,\n$$\nv_{1}=\\frac{R(Y_{1})}{6+1}=\\frac{\\frac{5}{2}}{7}=\\frac{5}{14}.\n$$\n\nHence, the normalized rank coordinates for Day 1 are $\\left(\\frac{2}{7},\\frac{5}{14}\\right)$.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{2}{7}  \\frac{5}{14}\\end{pmatrix}}$$"
        },
        {
            "introduction": "Once data is transformed onto the unit square, the next task is to select an appropriate copula model that captures the observed dependence pattern. Different copulas are designed to model different types of dependence, particularly in the tails of the distribution. This problem challenges you to act as a modeler, interpreting a qualitative description of a dataset to choose between the Gumbel and Clayton copulas, two workhorses of financial and environmental modeling known for their distinct tail dependence properties .",
            "id": "1353897",
            "problem": "A hydrologist is analyzing the dependence between the daily river flow rates of two nearby rivers, River A and River B. They collect a large dataset of paired measurements. As a standard procedure in copula modeling, they transform the empirical marginal distributions of the flow rates for each river into standard uniform random variables, denoted as $U_A$ and $U_B$.\n\nUpon inspecting the scatter plot of the transformed pairs $(U_A, U_B)$, the hydrologist observes a distinct asymmetry in the dependence structure. Specifically, the data points show significant clustering in the upper-right corner of the unit square (i.e., when both $U_A$ and $U_B$ are close to 1), indicating that simultaneous major flood events are strongly linked. In contrast, there is very little clustering in the lower-left corner (i.e., when both $U_A$ and $U_B$ are close to 0), suggesting that periods of extreme low flow (droughts) in the two rivers are not as strongly connected.\n\nThe hydrologist decides to model this dependence using a one-parameter Archimedean copula and has narrowed the choice down to two common models: the Clayton copula and the Gumbel copula.\n\nBased on the described characteristics of the data, which of the following statements correctly identifies the more appropriate copula and the reason for its suitability?\n\nA. The Clayton copula, because it is specifically designed to model strong dependence in the upper tail of a joint distribution.\nB. The Clayton copula, because it is specifically designed to model strong dependence in the lower tail of a joint distribution.\nC. The Gumbel copula, because it is specifically designed to model strong dependence in the upper tail of a joint distribution.\nD. The Gumbel copula, because it is specifically designed to model strong dependence in the lower tail of a joint distribution.\nE. Either the Clayton or the Gumbel copula would be equally appropriate, as their tail dependence properties are identical for the same level of overall correlation.",
            "solution": "The hydrologist has transformed flow rates to standard uniforms $U_{A}$ and $U_{B}$ and observes strong clustering when both variables are close to $1$ (upper-right corner) and very weak clustering when both are close to $0$ (lower-left corner). In copula terms, this indicates strong upper tail dependence and weak (approximately zero) lower tail dependence.\n\nTail dependence is quantified by the coefficients\n$$\n\\lambda_{U}=\\lim_{u\\to 1^{-}} \\mathbb{P}\\left(U_{B}>u \\mid U_{A}>u\\right)=\\lim_{u\\to 1^{-}} \\frac{1-2u+C(u,u)}{1-u},\n$$\n$$\n\\lambda_{L}=\\lim_{u\\to 0^{+}} \\mathbb{P}\\left(U_{B}\\leq u \\mid U_{A}\\leq u\\right)=\\lim_{u\\to 0^{+}} \\frac{C(u,u)}{u},\n$$\nwhere $C$ is the copula.\n\nFor the candidate one-parameter Archimedean copulas:\n- Clayton copula (parameter $\\theta>0$) has lower tail dependence and no upper tail dependence:\n$$\n\\lambda_{L}=2^{-1/\\theta}>0,\\quad \\lambda_{U}=0.\n$$\n- Gumbel copula (parameter $\\theta\\geq 1$) has upper tail dependence and no lower tail dependence:\n$$\n\\lambda_{U}=2-2^{1/\\theta}>0\\ \\text{for}\\ \\theta>1,\\quad \\lambda_{L}=0.\n$$\n\nBecause the data show strong upper tail dependence and weak lower tail dependence, the appropriate choice is the Gumbel copula, whose defining feature matches the observed asymmetry. Therefore, the correct statement is that the Gumbel copula is suitable because it is designed to model strong dependence in the upper tail.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "A core task in computational finance is simulating scenarios for risk management and pricing complex derivatives. This requires the ability to generate random variates from a chosen joint distribution, a process masterfully handled by copulas. This advanced exercise takes you from theory to implementation, challenging you to build a simulation algorithm for a given Archimedean copula from first principles, test it against a theoretical benchmark, and verify your results empirically .",
            "id": "2384678",
            "problem": "Consider the bivariate copula defined by the Archimedean construction\n$$\nC_{\\theta,\\kappa}(u,v) \\;=\\; \\varphi_{\\theta,\\kappa}^{-1}\\!\\left(\\,\\varphi_{\\theta,\\kappa}(u) \\;+\\; \\varphi_{\\theta,\\kappa}(v)\\,\\right), \\quad (u,v)\\in(0,1]^2,\n$$\nwith the generator\n$$\n\\varphi_{\\theta,\\kappa}(x) \\;=\\; \\frac{x^{-\\theta}-1}{\\theta} \\;+\\; \\kappa\\,(1-x),\n$$\nfor parameters $\\theta>0$ and $\\kappa\\ge 0$. The function $\\varphi_{\\theta,\\kappa}$ is strictly decreasing, convex, satisfies $\\varphi_{\\theta,\\kappa}(1)=0$, and $\\lim_{x\\downarrow 0}\\varphi_{\\theta,\\kappa}(x)=+\\infty$. Therefore, for each $(\\theta,\\kappa)$ in the stated parameter range, this defines a valid strict Archimedean copula on $(0,1]^2$.\n\nYour task is to write a complete, runnable program that does the following, entirely in terms of the precise mathematical specifications below.\n\n1) Simulation target. For each parameter pair $(\\theta,\\kappa)$, simulate $n$ independent pairs $(U_i,V_i)$, $i=1,\\dots,n$, having uniform marginal distributions on $(0,1)$ and joint distribution given by the copula $C_{\\theta,\\kappa}$. There must be no transformation, reordering, or rejection that alters the target copula law; the output pairs must be draws from the stated copula.\n\n2) Conditional distribution characterization. For any bivariate copula $C(u,v)$ that is continuously differentiable, the conditional cumulative distribution function of $V$ given $U=u$ is\n$$\nF_{V\\mid U=u}(v) \\;=\\; \\frac{\\partial}{\\partial u} C(u,v), \\quad v\\in(0,1).\n$$\nUse this fact as the mathematical characterization for generating $V$ given a realized $U=u$. No numerical value in your output should rely on any assumption beyond this definition.\n\n3) Theoretical benchmark. For an Archimedean copula with strict generator $\\varphi$, Kendall's tau is\n$$\n\\tau(\\theta,\\kappa) \\;=\\; 1 \\;+\\; 4 \\int_{0}^{1} \\frac{\\varphi_{\\theta,\\kappa}(t)}{\\varphi_{\\theta,\\kappa}'(t)} \\, dt,\n$$\nwhere $\\varphi_{\\theta,\\kappa}'(t)$ denotes the derivative of $\\varphi_{\\theta,\\kappa}$ with respect to $t$.\n\n4) Empirical statistic. Given the simulated sample $\\{(U_i,V_i)\\}_{i=1}^n$, compute the empirical Kendall's tau, denoted $\\widehat{\\tau}_n(\\theta,\\kappa)$, using the standard definition for continuous data.\n\n5) Output quantity. For each test case, compute the absolute error\n$$\n\\Delta(\\theta,\\kappa,n,\\text{seed}) \\;=\\; \\left| \\widehat{\\tau}_n(\\theta,\\kappa) \\;-\\; \\tau(\\theta,\\kappa) \\right|.\n$$\n\n6) Test suite. Your program must compute the quantity $\\Delta(\\theta,\\kappa,n,\\text{seed})$ for each of the following parameter sets, using the specified sample sizes $n$ and pseudo-random number generator seeds. All random number generation must be reproducible and initialized by the stated seed at the start of each case.\n- Case 1 (happy path, standard boundary): $(\\theta,\\kappa,n,\\text{seed}) = (0.5,\\,0.0,\\,6000,\\,12345)$.\n- Case 2 (non-standard family): $(\\theta,\\kappa,n,\\text{seed}) = (0.5,\\,0.7,\\,6000,\\,12345)$.\n- Case 3 (near independence edge): $(\\theta,\\kappa,n,\\text{seed}) = (0.01,\\,0.0,\\,8000,\\,7)$.\n- Case 4 (stronger dependence, non-standard): $(\\theta,\\kappa,n,\\text{seed}) = (1.5,\\,1.0,\\,6000,\\,42)$.\n\n7) Final output format. Your program should produce a single line of output containing the four absolute errors for the test suite, rounded to six decimal places, as a comma-separated list enclosed in square brackets. Specifically, if the four errors are $d_1,d_2,d_3,d_4$, print\n$$\n[\\text{round}(d_1,6),\\text{round}(d_2,6),\\text{round}(d_3,6),\\text{round}(d_4,6)].\n$$\nNo additional text or lines should be printed.\n\nAll quantities are unitless. Angles do not appear. The final printed list must conform exactly to the specified format.",
            "solution": "The problem as stated is mathematically sound, self-contained, and well-posed. It presents a clear task in computational statistics, specifically in the domain of copula modeling. The definitions provided for the Archimedean copula, its generator, Kendall's tau, and the conditional distribution are all standard and correct. We shall proceed with a systematic, principle-based solution.\n\nThe solution is constructed in four main stages:\n1.  Implementation of the generator function $\\varphi_{\\theta,\\kappa}(x)$ and its inverse, with due attention to numerical stability.\n2.  Calculation of the theoretical Kendall's tau, $\\tau(\\theta,\\kappa)$, via numerical integration.\n3.  Design and implementation of the simulation algorithm for the copula $C_{\\theta,\\kappa}$ according to the specified conditional distribution method.\n4.  Computation of the empirical Kendall's tau, $\\widehat{\\tau}_n$, from the simulated data and the final absolute error $\\Delta$.\n\n**1. The Copula Generator and Associated Functions**\n\nThe generator for the copula family is given by\n$$ \\varphi_{\\theta,\\kappa}(x) \\;=\\; \\frac{x^{-\\theta}-1}{\\theta} \\;+\\; \\kappa\\,(1-x), \\quad x \\in (0, 1] $$\nwith parameters $\\theta > 0$ and $\\kappa \\ge 0$.\n\nFor numerical stability, particularly when $\\theta$ is close to zero, the term $\\frac{x^{-\\theta}-1}{\\theta}$ is better computed as $\\frac{\\exp(-\\theta \\ln x) - 1}{\\theta}$. This avoids the potential loss of precision in `(1 + epsilon - 1) / tiny_number` scenarios. In the limit as $\\theta \\to 0$, we have $\\varphi_{0,\\kappa}(x) = -\\ln x + \\kappa(1-x)$. While the problem specifies $\\theta > 0$, case 3 with $\\theta=0.01$ necessitates this stable formulation.\n\nThe first derivative of the generator, required for subsequent calculations, is\n$$ \\varphi'_{\\theta,\\kappa}(x) \\;=\\; -x^{-\\theta-1} - \\kappa. $$\nThe inverse of the generator, $\\varphi^{-1}_{\\theta,\\kappa}(y)$, does not have a closed-form expression. It must be computed numerically by solving the equation $\\varphi_{\\theta,\\kappa}(x) - y = 0$ for $x \\in (0, 1)$. Since $\\varphi_{\\theta,\\kappa}(x)$ is strictly decreasing and continuous on its domain, a unique root is guaranteed for any $y$ in its range $(0, \\infty)$. A robust root-finding algorithm, such as the Brent-Dekker method (`brentq`), is suitable for this task.\n\n**2. Theoretical Kendall's Tau $\\tau(\\theta,\\kappa)$**\n\nThe theoretical Kendall's tau is defined by the integral\n$$ \\tau(\\theta,\\kappa) \\;=\\; 1 \\;+\\; 4 \\int_{0}^{1} \\frac{\\varphi_{\\theta,\\kappa}(t)}{\\varphi'_{\\theta,\\kappa}(t)} \\, dt. $$\nThe integrand, $f(t) = \\varphi_{\\theta,\\kappa}(t)/\\varphi'_{\\theta,\\kappa}(t)$, is well-behaved on the interval $(0,1)$. As $t\\to 0^+$, $f(t) \\sim -t/\\theta \\to 0$. As $t\\to 1^-$, $\\varphi_{\\theta,\\kappa}(t) \\approx \\varphi'_{\\theta,\\kappa}(1)(t-1)$, so $f(t) \\sim (t-1) \\to 0$. Since the integrand is non-singular at the boundaries, the integral can be reliably computed using a standard numerical quadrature method, such as `scipy.integrate.quad`.\n\n**3. Simulation from Copula $C_{\\theta,\\kappa}$**\n\nThe problem mandates that simulation be based on the conditional cumulative distribution function $F_{V|U=u}(v) = \\frac{\\partial}{\\partial u} C(u,v)$. The generation procedure is thus:\n1.  Draw two independent uniform random variates, $u, w \\sim U(0,1)$.\n2.  Solve for $v$ in the equation $w = F_{V|U=u}(v)$.\n\nTo derive a computable expression, we first find $\\frac{\\partial C}{\\partial u}$. From the identity $\\varphi(C(u,v)) = \\varphi(u) + \\varphi(v)$, we differentiate with respect to $u$:\n$$ \\varphi'(C(u,v)) \\frac{\\partial C(u,v)}{\\partial u} = \\varphi'(u) \\implies \\frac{\\partial C(u,v)}{\\partial u} = \\frac{\\varphi'(u)}{\\varphi'(C(u,v))}. $$\nSubstituting $C(u,v) = \\varphi^{-1}(\\varphi(u)+\\varphi(v))$, the equation to solve for $v$ becomes\n$$ w = \\frac{\\varphi'(u)}{\\varphi'(\\varphi^{-1}(\\varphi(u)+\\varphi(v)))}. $$\nA direct numerical solution for $v$ would require a nested root-finding procedure (one for the outer equation, one for the inner $\\varphi^{-1}$), which is computationally intensive and potentially unstable. A more elegant and efficient approach is to simplify this equation analytically first. Let $X = \\varphi^{-1}(\\varphi(u)+\\varphi(v))$. The equation becomes $w = \\varphi'(u)/\\varphi'(X)$, which rearranges to $\\varphi'(X) = \\varphi'(u)/w$.\nCrucially, the function $\\varphi'(x)$ is invertible in closed form. Let $Z = \\varphi'(x) = -x^{-\\theta-1} - \\kappa$. Then $x = (-(Z+\\kappa))^{-1/(\\theta+1)}$. Let us denote this inverse by $(\\varphi')^{-1}$.\nApplying this inverse to our equation yields $X = (\\varphi')^{-1}(\\varphi'(u)/w)$.\nFrom the definition of $X$, we have $\\varphi(X) = \\varphi(u) + \\varphi(v)$. This gives an explicit expression for $\\varphi(v)$:\n$$ \\varphi(v) = \\varphi(X) - \\varphi(u). $$\nFinally, we obtain $v$ by applying the inverse generator:\n$$ v = \\varphi^{-1} \\left( \\varphi\\left((\\varphi')^{-1}\\left(\\frac{\\varphi'(u)}{w}\\right)\\right) - \\varphi(u) \\right). $$\nThis simplified procedure requires only a single numerical root-finding step (for the final $\\varphi^{-1}$) per generated variate, drastically improving efficiency and robustness. The argument of $(\\varphi')^{-1}$ is always a valid negative number, and the argument of the final $\\varphi^{-1}$ is always a valid positive number, ensuring the algorithm is well-defined.\n\n**4. Empirical Kendall's Tau $\\widehat{\\tau}_n$ and Error Calculation**\n\nGiven a simulated sample $\\{(U_i, V_i)\\}_{i=1}^n$, the empirical Kendall's tau is calculated. For continuous data with no ties, it is defined as\n$$ \\widehat{\\tau}_n = \\frac{N_c - N_d}{\\binom{n}{2}}, $$\nwhere $N_c$ is the number of concordant pairs and $N_d$ is the number of discordant pairs. This calculation is performed efficiently and accurately using a standard library function, such as `scipy.stats.kendalltau`.\n\nThe final required output for each test case is the absolute error between the empirical and theoretical values:\n$$ \\Delta = |\\widehat{\\tau}_n(\\theta,\\kappa) - \\tau(\\theta,\\kappa)|. $$\nThe program executes this full sequence for each parameter set specified in the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import optimize, integrate, stats\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating the absolute difference between theoretical\n    and empirical Kendall's tau for a specified copula family over several\n    test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (theta, kappa, n, seed)\n        (0.5, 0.0, 6000, 12345),\n        (0.5, 0.7, 6000, 12345),\n        (0.01, 0.0, 8000, 7),\n        (1.5, 1.0, 6000, 42),\n    ]\n\n    class CopulaModel:\n        \"\"\"\n        A class to encapsulate the logic for the specified Archimedean copula family.\n        \"\"\"\n        def __init__(self, theta, kappa):\n            if theta = 0 or kappa  0:\n                raise ValueError(\"Parameters must satisfy theta > 0 and kappa >= 0.\")\n            self.theta = theta\n            self.kappa = kappa\n        \n        def phi(self, x):\n            \"\"\"\n            Computes the generator function phi(x).\n            Uses a numerically stable form for theta close to 0.\n            \"\"\"\n            x = np.asarray(x)\n            # Use np.expm1 for stability when theta * log(x) is small.\n            # This handles the limit theta -> 0 correctly.\n            return np.expm1(-self.theta * np.log(x)) / self.theta + self.kappa * (1 - x)\n\n        def d_phi(self, x):\n            \"\"\"Computes the derivative of the generator, phi'(x).\"\"\"\n            return -x**(-self.theta - 1) - self.kappa\n\n        def inv_phi(self, y):\n            \"\"\"\n            Computes the inverse of the generator, phi_inv(y), by numerically\n            finding the root of phi(x) - y = 0.\n            \"\"\"\n            try:\n                # brentq is robust for monotonic functions.\n                # Search interval is (0, 1), tightened slightly for stability.\n                return optimize.brentq(lambda x: self.phi(x) - y, 1e-15, 1.0 - 1e-15)\n            except ValueError:\n                # Handle cases where y is so small/large the root is outside the\n                # initial bracket guesses for standard floats.\n                if np.isclose(y, 0): return 1.0\n                # A large y corresponds to a root near 0.\n                # A small y corresponds to a root near 1.\n                # This fallback logic can resolve edge cases for brentq.\n                f_low = self.phi(1e-15) - y\n                f_high = self.phi(1.0 - 1e-15) - y\n                if f_low > 0 and f_high > 0: return 1.0\n                if f_low  0 and f_high  0: return 1e-15\n                # If it still fails, there's a more serious numerical issue.\n                raise\n\n        def theoretical_tau(self):\n            \"\"\"Calculates the theoretical Kendall's tau via numerical integration.\"\"\"\n            integrand = lambda t: self.phi(t) / self.d_phi(t) if t > 0 else 0.0\n            # integrate.quad is a standard, reliable numerical integrator.\n            integral_val, _ = integrate.quad(integrand, 0, 1, epsabs=1e-12, epsrel=1e-12)\n            return 1 + 4 * integral_val\n\n        def inv_d_phi(self, z):\n            \"\"\"\n            Computes the inverse of the generator's derivative, (phi')^{-1}(z).\n            This has an analytical form.\n            \"\"\"\n            base = -z - self.kappa\n            # With correct inputs, base should always be positive.\n            # A small positive floor prevents NaN from floating point inaccuracies.\n            if base = 0:\n                base = 1e-300\n            return base**(-1.0 / (self.theta + 1.0))\n\n        def simulate_pairs(self, n, seed):\n            \"\"\"\n            Simulates n pairs (U, V) from the copula C(u,v) using the\n            specified conditional distribution method, simplified for efficiency.\n            \"\"\"\n            rng = np.random.default_rng(seed)\n            u_samples = rng.uniform(low=1e-9, high=1.0 - 1e-9, size=n)\n            w_samples = rng.uniform(low=1e-9, high=1.0 - 1e-9, size=n)\n            v_samples = np.zeros(n)\n\n            for i in range(n):\n                u, w = u_samples[i], w_samples[i]\n                \n                # Simplified algorithm based on F_{V|U=u}(v) = w\n                # 1. z = phi'(u) / w\n                z = self.d_phi(u) / w\n                \n                # 2. x_val = (phi')^{-1}(z)\n                x_val = self.inv_d_phi(z)\n                \n                # 3. y_target = phi(x_val) - phi(u)\n                y_target = self.phi(x_val) - self.phi(u)\n                \n                # 4. v = phi^{-1}(y_target)\n                v_samples[i] = self.inv_phi(y_target)\n                \n            return u_samples, v_samples\n\n    results = []\n    for theta, kappa, n, seed in test_cases:\n        model = CopulaModel(theta, kappa)\n        \n        # 1) Compute theoretical benchmark\n        tau_th = model.theoretical_tau()\n        \n        # 2) Simulate sample from the copula\n        u_sample, v_sample = model.simulate_pairs(n, seed)\n        \n        # 3) Compute empirical statistic\n        # scipy.stats.kendalltau is a standard, efficient implementation\n        tau_emp, _ = stats.kendalltau(u_sample, v_sample)\n        \n        # 4) Compute the absolute error\n        error = abs(tau_emp - tau_th)\n        results.append(error)\n\n    # Format the results as specified.\n    rounded_results = [f'{res:.6f}' for res in results]\n    print(f\"[{','.join(rounded_results)}]\")\n\nsolve()\n```"
        }
    ]
}