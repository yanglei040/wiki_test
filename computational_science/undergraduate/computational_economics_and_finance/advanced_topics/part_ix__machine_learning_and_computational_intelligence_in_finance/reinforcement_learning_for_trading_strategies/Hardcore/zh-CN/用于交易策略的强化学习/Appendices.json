{
    "hands_on_practices": [
        {
            "introduction": "在任何强化学习系统中，奖励函数的设计都至关重要，它直接定义了智能体的优化目标。本练习将通过一个单步决策问题，帮助你深入理解交易中的核心权衡：预期收益与交易成本（例如滑点）之间的平衡。通过求解这个优化问题，你将学会如何量化并找到最大化单步收益的最优交易规模。",
            "id": "2426687",
            "problem": "您面临一个单步交易决策问题，其中一个交易代理选择一个带符号的交易规模 $v$（正 $v$ 代表买入，负 $v$ 代表卖出），以最大化一个带惩罚的预期回报。单位即时预期价格变化为 $\\mu$，市场波动率参数为 $\\sigma$。瞬时滑点惩罚被建模为一种单位效应，它随着波动率和交易规模大小的平方根而增加，遵循经验性的平方根冲击模型：单位滑点为 $s_{\\text{per}}(v,\\sigma) = k\\,\\sigma\\,|v|^{1/2}$，其中 $k$ 是一个正常数。以货币单位计算的总滑点成本为 $C(v,\\sigma) = s_{\\text{per}}(v,\\sigma)\\,|v| = k\\,\\sigma\\,|v|^{3/2}$。因此，采取行动 $v$ 的带惩罚预期回报为\n$$\nR(v;\\mu,\\sigma,k) = \\mu\\,v \\;-\\; k\\,\\sigma\\,|v|^{3/2}.\n$$\n选择变量 $v$ 受到硬性交易限制 $|v| \\le V_{\\max}$ 的约束。\n\n任务：对于下面测试套件中的每一组参数，计算唯一的最优交易规模 $v^\\star$，它在满足 $|v|\\le V_{\\max}$ 的所有实数 $v$ 上最大化 $R(v;\\mu,\\sigma,k)$。当因退化而存在多个最大化点时，选择 $v^\\star = 0$ 作为打破僵局的约定。您的程序必须根据 $R(v;\\mu,\\sigma,k)$ 的定义来实现这一点，并为每个测试用例输出最优的 $v^\\star$。\n\n测试套件（每个项目是一个元组 $(\\mu,\\sigma,k,V_{\\max})$）：\n- 情况 $1$：$(0.01, 0.02, 0.5, 10)$\n- 情况 $2$：$(-0.015, 0.03, 0.7, 20)$\n- 情况 $3$：$(0.02, 0, 1, 5)$\n- 情况 $4$：$(0, 0.05, 0.5, 100)$\n- 情况 $5$：$(0.05, 0.02, 0.2, 1)$\n- 情况 $6$：$(0.01, 0.5, 2, 100)$\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序与上述情况相同。将每个结果四舍五入到 $6$ 位小数。例如，一个包含三个假设结果的有效输出将如下所示：$[0.123456,-0.500000,1.000000]$。",
            "solution": "问题陈述已提交以供验证。\n\n### 步骤1：提取已知条件\n- **目标函数**：带惩罚的预期回报为 $R(v;\\mu,\\sigma,k) = \\mu\\,v \\;-\\; k\\,\\sigma\\,|v|^{3/2}$。\n- **选择变量**：$v$，一个代表带符号交易规模的实数。\n- **参数**：\n    - $\\mu$：单位预期价格变化。\n    - $\\sigma$：市场波动率参数。\n    - $k$：一个正常数，$k0$。\n- **约束**：交易规模受限于 $|v| \\le V_{\\max}$。\n- **打破僵局规则**：如果因退化而存在多个最大化点，选择 $v^\\star = 0$。\n- **任务**：计算在约束条件下最大化 $R(v;\\mu,\\sigma,k)$ 的最优交易规模 $v^\\star$。\n- **测试套件**：\n    - 情况 $1$：$(\\mu,\\sigma,k,V_{\\max}) = (0.01, 0.02, 0.5, 10)$\n    - 情况 $2$：$(\\mu,\\sigma,k,V_{\\max}) = (-0.015, 0.03, 0.7, 20)$\n    - 情况 $3$：$(\\mu,\\sigma,k,V_{\\max}) = (0.02, 0, 1, 5)$\n    - 情况 $4$：$(\\mu,\\sigma,k,V_{\\max}) = (0, 0.05, 0.5, 100)$\n    - 情况 $5$：$(\\mu,\\sigma,k,V_{\\max}) = (0.05, 0.02, 0.2, 1)$\n    - 情况 $6$：$(\\mu,\\sigma,k,V_{\\max}) = (0.01, 0.5, 2, 100)$\n\n### 步骤2：使用提取的已知条件进行验证\n1.  **科学基础**：该问题描述了金融执行中的一个经典权衡：在最小化交易成本的同时最大化可预测价格变动带来的预期利润 ($\\mu v$)。成本函数 $C(v,\\sigma) = k\\,\\sigma\\,|v|^{3/2}$ 是“平方根市场冲击”定律的一种表示，这是金融市场中凭经验观察到的现象。该模型是计算金融中使用的标准简化表示。它具有科学基础。\n2.  **适定性**：任务是在一个紧集 $[-V_{\\max}, V_{\\max}]$ 上最大化一个连续函数 $R(v)$。根据极值定理，最大值必然存在。解的唯一性必须得到验证。该问题是适定的。\n3.  **客观性**：问题是用精确的数学术语陈述的，使用了明确的定义和客观的标准。\n4.  **完整性**：为每种情况提供了所有必要的参数($\\mu, \\sigma, k, V_{\\max}$)。目标函数和约束条件已完全指定。设置是完整的。\n5.  **缺陷**：该问题没有任何不合格的缺陷。这些参数在金融背景下是物理上合理的。有一种情况包括 $\\sigma=0$，这是一个有效且重要的极限情况，代表一个没有波动的市场，必须正确处理。\n\n### 步骤3：结论与行动\n问题是有效的。将提供一个严谨的解决方案。\n\n目标是找到在区间 $v \\in [-V_{\\max}, V_{\\max}]$上最大化函数 $R(v) = \\mu v - k \\sigma |v|^{3/2}$ 的 $v^\\star$。函数 $R(v)$ 是连续的，但其在 $v=0$ 处的导数未定义。因此，我们通过分别考虑 $v0$、$v0$ 和 $v=0$ 的情况来分析问题。$v=0$ 时的值为 $R(0)=0$。\n\n情况1：$v  0$。\n函数为 $R(v) = \\mu v - k \\sigma v^{3/2}$。我们在 $(0, V_{\\max}]$上寻求其最大值。\n关于 $v$ 的一阶和二阶导数是：\n$$\nR'(v) = \\mu - \\frac{3}{2} k \\sigma v^{1/2}\n$$\n$$\nR''(v) = -\\frac{3}{4} k \\sigma v^{-1/2}\n$$\n鉴于 $k0$ 且我们暂时假设 $\\sigma0$，对于所有 $v0$，$R''(v)  0$。这表明 $R(v)$ 对于 $v0$ 是严格凹函数，因此它在该域中至多有一个局部最大值。\n\n为了找到无约束最大化点，我们设 $R'(v) = 0$：\n$$\n\\mu - \\frac{3}{2} k \\sigma v^{1/2} = 0 \\implies v^{1/2} = \\frac{2\\mu}{3k\\sigma}\n$$\n只有当 $\\mu  0$ 时，才存在 $v^{1/2}$ 的实正解。在这种情况下，无约束最优交易为 $v_{\\text{unc}} = \\left(\\frac{2\\mu}{3k\\sigma}\\right)^2$。\n如果 $\\mu \\le 0$，则对于所有 $v0$，$R'(v) \\le 0$，意味着 $R(v)$ 在 $(0, \\infty)$ 上是非增的。因此，在 $[0, V_{\\max}]$ 上的最大值在 $v=0$ 处。\n如果 $\\mu  0$，$R(v)$ 的凹性意味着在 $[0, V_{\\max}]$ 上的最大值出现在 $v^\\star_+ = \\min(v_{\\text{unc}}, V_{\\max})$。所得回报 $R(v^\\star_+)$ 将为非负。\n\n情况2：$v  0$。\n令 $u = -v  0$。以 $u$ 表示的函数为 $R(u) = \\mu(-u) - k\\sigma u^{3/2} = -\\mu u - k\\sigma u^{3/2}$。我们在 $u \\in (0, V_{\\max}]$ 上最大化这个函数。\n关于 $u$ 的一阶导数是：\n$$\nR'(u) = -\\mu - \\frac{3}{2} k \\sigma u^{1/2}\n$$\n设 $R'(u) = 0$ 得到 $u^{1/2} = \\frac{-2\\mu}{3k\\sigma}$。只有当 $\\mu  0$ 时，才存在 $u^{1/2}$ 的实正解。无约束最优规模为 $u_{\\text{unc}} = \\left(\\frac{-2\\mu}{3k\\sigma}\\right)^2 = \\left(\\frac{2|\\mu|}{3k\\sigma}\\right)^2$。\n如果 $\\mu \\ge 0$，则对于所有 $u0$，$R'(u)  0$，意味着函数是递减的。对于负 $v$ (正 $u$) 值，最大值在 $v \\to 0^-$ 处，得到 $R(0)=0$。\n如果 $\\mu  0$，最优正规模 $u$ 是 $u^\\star = \\min(u_{\\text{unc}}, V_{\\max})$，这对应于一个负交易 $v^\\star_- = -u^\\star$。回报将是非负的。\n\n整体解的综合：\n- 如果 $\\mu  0$，任何交易 $v  0$ 都会产生 $R(v)  0$，而最优交易 $v^\\star_+  0$ 会产生 $R(v^\\star_+) \\ge 0$。因此，全局最优解是 $v^\\star = v^\\star_+$。\n- 如果 $\\mu  0$，任何交易 $v  0$ 都会产生 $R(v)  0$，而最优交易 $v^\\star_-  0$ 会产生 $R(v^\\star_-) \\ge 0$。因此，全局最优解是 $v^\\star = v^\\star_-$。\n- 如果 $\\mu = 0$ (且 $\\sigma  0$)，函数为 $R(v) = -k\\sigma|v|^{3/2}$，其在 $v^\\star = 0$ 处最大化。\n\n对于 $\\sigma  0$，综合这些结果：\n最优交易规模的大小为 $v_{\\text{mag}} = \\min\\left( \\left(\\frac{2|\\mu|}{3k\\sigma}\\right)^2, V_{\\max} \\right)$。交易的符号必须与 $\\mu$ 的符号匹配。如果 $\\mu=0$，大小为 $0$。\n所以，$v^\\star = \\text{sign}(\\mu) \\cdot \\min\\left( \\left(\\frac{2|\\mu|}{3k\\sigma}\\right)^2, V_{\\max} \\right)$。\n\n特殊情况：$\\sigma = 0$。\n目标函数简化为 $R(v) = \\mu v$。我们必须在 $v \\in [-V_{\\max}, V_{\\max}]$ 上最大化这个线性函数。\n- 如果 $\\mu  0$，$R(v)$ 在上界达到最大值，$v^\\star = V_{\\max}$。\n- 如果 $\\mu  0$，$R(v)$ 在下界达到最大值，$v^\\star = -V_{\\max}$。\n- 如果 $\\mu = 0$，$R(v)=0$ 对于所有 $v$ 成立。这是一个退化情况。所有 $v \\in [-V_{\\max}, V_{\\max}]$ 都是最大化点。根据规定的打破僵局规则，我们必须选择 $v^\\star = 0$。\n这可以紧凑地写成 $v^\\star = V_{\\max} \\cdot \\text{sign}(\\mu)$。\n\n最终算法：\n1. 对于一组给定的参数 $(\\mu, \\sigma, k, V_{\\max})$：\n2. 如果 $\\sigma = 0$，最优交易为 $v^\\star = V_{\\max} \\cdot \\text{sign}(\\mu)$。\n3. 如果 $\\sigma  0$：\n   - 如果 $\\mu = 0$，最优交易为 $v^\\star = 0$。\n   - 如果 $\\mu \\ne 0$，计算无约束最优规模大小 $v_{\\text{unc\\_mag}} = \\left(\\frac{2|\\mu|}{3k\\sigma}\\right)^2$。有约束的规模大小为 $v_{\\text{mag}} = \\min(v_{\\text{unc\\_mag}}, V_{\\max})$。最优交易为 $v^\\star = \\text{sign}(\\mu) \\cdot v_{\\text{mag}}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the optimal trade size v* for a series of one-step trading problems.\n    The problem is to maximize R(v) = mu*v - k*sigma*|v|^(3/2) subject to |v| = V_max.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (mu, sigma, k, V_max).\n    test_cases = [\n        (0.01, 0.02, 0.5, 10),\n        (-0.015, 0.03, 0.7, 20),\n        (0.02, 0, 1, 5),\n        (0, 0.05, 0.5, 100),\n        (0.05, 0.02, 0.2, 1),\n        (0.01, 0.5, 2, 100),\n    ]\n\n    results = []\n    for case in test_cases:\n        mu, sigma, k, V_max = case\n        \n        v_star = 0.0\n\n        if sigma == 0:\n            # Special case: no volatility implies no slippage penalty.\n            # Maximize R(v) = mu*v.\n            # Optimal trade is at the boundary, with sign matching mu.\n            # np.sign(0) is 0, correctly handling the mu=0 degenerate case.\n            v_star = V_max * np.sign(mu)\n        else:\n            # Standard case with volatility and slippage.\n            if mu == 0:\n                # If mu is 0, R(v) = -k*sigma*|v|^(3/2), which is maximized at v=0.\n                v_star = 0.0\n            else:\n                # Unconstrained optimal trade magnitude from setting R'(v)=0.\n                v_unc_mag = (2 * abs(mu) / (3 * k * sigma))**2\n                \n                # The optimal magnitude is constrained by V_max.\n                v_mag = min(v_unc_mag, V_max)\n                \n                # The sign of the trade should match the sign of the expected return.\n                v_star = np.sign(mu) * v_mag\n        \n        results.append(v_star)\n    \n    # Format the results to 6 decimal places and join into a single string.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了单步决策的优化后，我们将视野扩展到多步规划问题，这更贴近真实的交易场景。本练习要求你为智能体设计一个最优的日内平仓策略以规避隔夜风险，这本质上是一个有限时间范围内的最优控制问题。你将运用动态规划的方法，从收盘时刻倒推，为每个时间点的每种持仓状态找到最优行动，从而深刻理解强化学习中“策略”和“价值函数”的由来。",
            "id": "2426659",
            "problem": "你的任务是将隔夜风险形式化为期末库存惩罚，并为一个离散时间、单一资产的交易日计算最优期望回报。在该交易日中，一个代理学习在收盘前将其头寸清零。交易日包含有限数量的日内决策时间。在每个决策时间点，代理可以调整其库存，每个周期最多调整一个单位，且必须遵守严格的库存限制。\n\n环境定义如下。时间范围有限，日内决策时间由 $t \\in \\{0,1,\\dots,T-1\\}$ 索引，市场在 $t = T$ 收盘。代理在时间 $t$ 的库存为 $p_t \\in \\{-P_{\\max},-P_{\\max}+1,\\dots,P_{\\max}-1,P_{\\max}\\}$，且 $p_0 = 0$。在每个时间点 $t \\in \\{0,1,\\dots,T-1\\}$，代理选择一个行动 $a_t \\in \\{-1,0,1\\}$。库存转移遵循以下规则：\n$$\np_{t+1} = \\mathrm{clip}(p_t + a_t, -P_{\\max}, P_{\\max}),\n$$\n其中 $\\mathrm{clip}(x,\\ell,u) = \\min\\{u,\\max\\{\\ell,x\\}\\}$。\n\n在周期 $[t,t+1]$ 内的期望价格变动是给定的，记为 $\\mu_t$。在时间 $t$ 采取任何行动的每笔交易成本为 $c \\cdot |a_t|$。每个周期的持续风险惩罚为 $k \\cdot p_{t+1}^2$。在收盘时，会施加一个隔夜风险惩罚：$-\\beta \\cdot p_T^2$。\n\n在时间 $t$ 做出的决策，其每个周期的期望回报定义为在 $[t,t+1]$ 期间持有 $p_{t+1}$ 的期望交易利润减去交易成本和持续库存惩罚：\n$$\nr_t(p_t,a_t) = p_{t+1} \\cdot \\mu_t - c\\cdot|a_t| - k\\cdot p_{t+1}^2.\n$$\n期末贡献值为：\n$$\nr_T(p_T) = -\\beta \\cdot p_T^2.\n$$\n目标是计算从 $p_0=0$ 开始的最优期望总回报，\n$$\nR^\\star = \\max_{\\{a_t\\}_{t=0}^{T-1}} \\sum_{t=0}^{T-1} r_t(p_t,a_t) + r_T(p_T),\n$$\n受限于 $p_{t+1}$ 的转移动态和行动约束。\n\n必须使用确定性的决胜规则，以确保在任何决策时间 $t$ 当多个行动产生相同的最大期望值时，能有唯一的最佳行动。决胜规则如下：\n- 在使期望值最大化的行动中，优先选择导致 $|p_{t+1}|$ 最小的行动。\n- 如果仍然平局，则在这些行动中优先选择 $|a_t|$ 最小的行动。\n- 如果仍然平局，则按照 $-1  0  1$ 的常规顺序选择最小的 $a_t$。\n\n对于每个测试用例，从 $p_0=0$ 开始，计算：\n- 最优期望总回报 $R^\\star$。\n- 在指定决胜规则下，遵循最优行动所产生的最终期末库存 $p_T$。\n\n你的程序应为每个测试用例返回一对值 $\\left(R^\\star, p_T\\right)$，其中 $R^\\star$ 使用标准四舍五入保留到小数点后 $6$ 位，而 $p_T$ 是一个整数。将所有测试用例的结果按照下面给出的顺序汇总到一个列表中。\n\n测试套件：\n1. 用例 A（混合漂移的通用多周期）：$T=4$, $\\mu = [0.02, 0.01, 0.00, -0.01]$, $c=0.003$, $k=0.0005$, $\\beta=0.05$, $P_{\\max}=3$。\n2. 用例 B（零漂移基线）：$T=3$, $\\mu = [0.00, 0.00, 0.00]$, $c=0.001$, $k=0.00$, $\\beta=0.10$, $P_{\\max}=2$。\n3. 用例 C（立即收盘边界）：$T=1$, $\\mu = [0.05]$, $c=0.002$, $k=0.00$, $\\beta=0.03$, $P_{\\max}=1$。\n4. 用例 D（临近收盘时的平仓激励）：$T=2$, $\\mu = [0.03, 0.03]$, $c=0.002$, $k=0.00$, $\\beta=0.20$, $P_{\\max}=2$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 $[\\text{用例 A } R^\\star,\\text{用例 A } p_T,\\text{用例 B } R^\\star,\\text{用例 B } p_T,\\text{用例 C } R^\\star,\\text{用例 C } p_T,\\text{用例 D } R^\\star,\\text{用例 D } p_T]$。\n- $R^\\star$ 条目必须打印为保留 6 位小数的十进制数，$p_T$ 条目必须打印为整数。",
            "solution": "所提出的问题是一个离散时间、有限范围的最优控制问题，这是计算金融学中为最优执行策略建模的标准范式。该问题是适定的且科学上合理的，允许通过动态规划求解。目标是找到一个行动序列 $\\{a_t\\}_{t=0}^{T-1}$，以最大化从初始库存 $p_0=0$ 开始的总期望回报。\n\n求解过程首先定义一个价值函数 $V_t(p)$，它代表从时间 $t$ 到市场在时间 $T$ 收盘为止可能获得的最大回报总和，前提是时间 $t$ 的库存为 $p_t = p$。该问题通过反向归纳法解决，从期末时间 $T$ 开始，逆向推导至初始时间 $t=0$。\n\n在任何时间 $t \\in \\{0, 1, \\dots, T\\}$，系统的状态是代理的库存 $p_t$。状态空间是离散且有限的，由 $p_t \\in \\{-P_{\\max}, \\dots, P_{\\max}\\}$ 给出。在任何决策时间 $t \\in \\{0, 1, \\dots, T-1\\}$，行动空间也是离散且有限的：$a_t \\in \\{-1, 0, 1\\}$。\n\nBellman 最优性原理为价值函数提供了递归关系。在期末时间 $t=T$，价值函数仅由隔夜风险惩罚决定：\n$$\nV_T(p_T) = r_T(p_T) = -\\beta \\cdot p_T^2\n$$\n对于任何之前的时刻 $t \\in \\{T-1, T-2, \\dots, 0\\}$，价值函数 $V_t(p_t)$ 是在所有可能的行动 $a_t$ 上可实现的最大值。它等于即时回报 $r_t(p_t, a_t)$ 与后续状态的价值 $V_{t+1}(p_{t+1})$ 之和：\n$$\nV_t(p_t) = \\max_{a_t \\in \\{-1, 0, 1\\}} \\left\\{ r_t(p_t, a_t) + V_{t+1}(p_{t+1}) \\right\\}\n$$\n其中状态转移由 $p_{t+1} = \\mathrm{clip}(p_t + a_t, -P_{\\max}, P_{\\max})$ 给出，即时回报为 $r_t(p_t, a_t) = p_{t+1} \\cdot \\mu_t - c \\cdot |a_t| - k \\cdot p_{t+1}^2$。\n\n让我们定义品质函数，或 Q-值，$Q_t(p_t, a_t)$，作为在时间 $t$、状态 $p_t$ 下采取行动 $a_t$ 的价值：\n$$\nQ_t(p_t, a_t) = p_{t+1} \\cdot \\mu_t - c \\cdot |a_t| - k \\cdot p_{t+1}^2 + V_{t+1}(p_{t+1})\n$$\nBellman 方程可以写作 $V_t(p_t) = \\max_{a_t} Q_t(p_t, a_t)$。\n\n计算过程如下：\n1.  初始化一个表格以存储所有 $t \\in \\{0, \\dots, T\\}$ 和 $p \\in \\{-P_{\\max}, \\dots, P_{\\max}\\}$ 的值 $V_t(p)$。\n2.  在 $t=T$ 时，用所有可能的期末库存 $p_T$ 的期末值 $V_T(p_T) = -\\beta \\cdot p_T^2$ 填充该表格。\n3.  算法从时间 $t=T-1$ 逆向迭代至 $t=0$。在每个步骤 $t$ 中，对于每个可能的库存状态 $p_t$，使用已知的 $V_{t+1}$ 值计算所有三个行动 $a_t \\in \\{-1, 0, 1\\}$ 的 $Q_t(p_t, a_t)$ 值。\n4.  为确保有唯一的最优行动 $\\pi_t(p_t)$，必须严格执行指定的决胜规则。当多个行动产生相同的最大 Q-值时，通过字典序比较来精炼选择。所选行动 $a^\\star$ 必须是按顺序满足以下标准的行动：\n    a. 最大化 Q-值，$Q_t(p_t, a_t)$。\n    b. 最小化下一库存的绝对值，$|p_{t+1}|$。\n    c. 最小化行动的绝对值，$|a_t|$。\n    d. 最小化行动值本身，遵循自然排序 $-1  0  1$。\n5.  存储最优值 $V_t(p_t) = Q_t(p_t, \\pi_t(p_t))$。\n6.  从 $p_0=0$ 开始的整个交易日的最优总期望回报是 $R^\\star = V_0(0)$。\n7.  为了找到相应的期末库存 $p_T$，可以从初始状态 $(t,p) = (0,0)$ 开始，使用计算出的最优策略 $\\pi_t(p_t)$ 正向模拟轨迹。算法中采用了一种更直接的方法，即在反向传递过程中维护另一个表格，该表格将每个状态-时间对 $(t, p_t)$ 映射到如果从该点开始遵循最优策略所产生的期末库存 $p_T$。设其为 $P_T(t, p_t)$。那么 $P_T(T, p_T) = p_T$，而对于 $t  T$，则有 $P_T(t, p_t) = P_T(t+1, \\mathrm{clip}(p_t + \\pi_t(p_t), -P_{\\max}, P_{\\max}))$。期末库存的最终答案就是 $p_T = P_T(0, 0)$。\n\n这种动态规划方法保证了在模型假设下找到全局最优解。该实现为每个测试用例计算这些值，以确定指定的输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the given test cases for the optimal trading problem.\n    \"\"\"\n\n    def solve_case(T, mu, c, k, beta, Pmax):\n        \"\"\"\n        Solves a single instance of the optimal trading problem using dynamic programming.\n\n        Args:\n            T (int): Number of time steps.\n            mu (list): List of expected price changes.\n            c (float): Transaction cost per share.\n            k (float): Running inventory risk penalty coefficient.\n            beta (float): Terminal inventory risk penalty coefficient.\n            Pmax (int): Maximum absolute inventory.\n\n        Returns:\n            tuple: A tuple containing the optimal total reward (R_star) and the\n                   resulting terminal inventory (p_T).\n        \"\"\"\n        # State space for inventory p\n        num_p_states = 2 * Pmax + 1\n        p_states = np.arange(-Pmax, Pmax + 1)\n        \n        # DP tables\n        # V_table stores the value function V_t(p)\n        V_table = np.zeros((T + 1, num_p_states))\n        # pT_table stores the resulting terminal inventory p_T if starting from state p at time t\n        pT_table = np.zeros((T + 1, num_p_states), dtype=np.int32)\n\n        # Helper function to map inventory p to an array index\n        def p_to_idx(p):\n            return int(p + Pmax)\n\n        # --- Backward Pass ---\n\n        # Time t = T: Terminal condition\n        for p_idx, p_T in enumerate(p_states):\n            V_table[T, p_idx] = -beta * p_T**2\n            pT_table[T, p_idx] = p_T\n\n        # Recursion from t = T-1 down to 0\n        for t in range(T - 1, -1, -1):\n            for p_idx, p_t in enumerate(p_states):\n                \n                candidates = []\n                \n                # Evaluate all possible actions a_t in {-1, 0, 1}\n                for a_t in [-1, 0, 1]:\n                    # State transition\n                    p_t_plus_1 = int(np.clip(p_t + a_t, -Pmax, Pmax))\n                    p_t_plus_1_idx = p_to_idx(p_t_plus_1)\n                    \n                    # Immediate reward\n                    reward = p_t_plus_1 * mu[t] - c * abs(a_t) - k * p_t_plus_1**2\n                    \n                    # Q-value (sum of immediate reward and future value)\n                    q_value = reward + V_table[t + 1, p_t_plus_1_idx]\n                    \n                    # Store candidate with its tie-breaking criteria as a sortable tuple:\n                    # 1. Maximize Q-value (equivalent to minimizing -q_value)\n                    # 2. Minimize |p_{t+1}|\n                    # 3. Minimize |a_t|\n                    # 4. Minimize a_t\n                    sort_key = (-q_value, abs(p_t_plus_1), abs(a_t), a_t)\n                    candidates.append((sort_key, p_t_plus_1, q_value))\n                \n                # Sort to find the best action according to the tie-breaking rules\n                candidates.sort(key=lambda x: x[0])\n                \n                # The best choice is the first element after sorting\n                best_choice = candidates[0]\n                best_p_next = best_choice[1]\n                best_q = best_choice[2]\n                \n                # Store results in the DP tables\n                V_table[t, p_idx] = best_q\n                \n                # Propagate the terminal position for this state-time pair\n                best_p_next_idx = p_to_idx(best_p_next)\n                pT_table[t, p_idx] = pT_table[t + 1, best_p_next_idx]\n\n        # --- Extract Final Answer ---\n        \n        # The solution corresponds to the initial state p_0 = 0 at t = 0\n        p0_idx = p_to_idx(0)\n        \n        # Optimal total expected reward\n        R_star = V_table[0, p0_idx]\n        \n        # Resulting terminal inventory\n        p_T_final = pT_table[0, p0_idx]\n        \n        return R_star, p_T_final\n\n    test_cases = [\n        # Case A: general multi-period with mixed drifts\n        {'T': 4, 'mu': [0.02, 0.01, 0.00, -0.01], 'c': 0.003, 'k': 0.0005, 'beta': 0.05, 'Pmax': 3},\n        # Case B: zero drift baseline\n        {'T': 3, 'mu': [0.00, 0.00, 0.00], 'c': 0.001, 'k': 0.00, 'beta': 0.10, 'Pmax': 2},\n        # Case C: immediate close boundary\n        {'T': 1, 'mu': [0.05], 'c': 0.002, 'k': 0.00, 'beta': 0.03, 'Pmax': 1},\n        # Case D: flattening incentive near close\n        {'T': 2, 'mu': [0.03, 0.03], 'c': 0.002, 'k': 0.00, 'beta': 0.20, 'Pmax': 2},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        R_star, p_T = solve_case(\n            case['T'], case['mu'], case['c'], case['k'], case['beta'], case['Pmax']\n        )\n        all_results.append(format(R_star, '.6f'))\n        all_results.append(p_T)\n\n    # Print the final output in the exact required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个成功的强化学习应用，不仅需要聪明的“智能体”，也需要一个安全且真实的“环境”。本练习将你的注意力从策略优化转移到环境构建上，你将亲手实现一个“熔断机制”——这是金融领域中至关重要的风险控制工具。通过在交易模拟中加入最大回撤限制，你将学会如何为智能体创建一个安全的探索空间，防止其在学习过程中出现灾难性的虚拟亏损。",
            "id": "2426620",
            "problem": "您必须编写一个完整、可运行的程序，模拟一个具有数学上指定的“熔断机制”的离散时间交易环境，该机制在已实现的回撤超过固定阈值时停止交易。该环境随时间指数 $t \\in \\{0,1,\\dots,T\\}$ 演化，并给定一个严格为正的价格序列 $\\{p_t\\}_{t=0}^{T}$。代理人选择一个行动序列 $\\{a_t\\}_{t=0}^{T-1}$，其中每个 $a_t \\in \\{-1,0,1\\}$。初始财富为 $W_00$，交易成本率为 $\\kappa \\in [0,1)$，回撤阈值为 $\\bar{d} \\in [0,1)$。设风险资产的单步毛收益率定义为\n$$\nr_{t+1} \\equiv \\frac{p_{t+1}-p_t}{p_t}, \\quad t=0,1,\\dots,T-1.\n$$\n从时间 $t$ 到 $t+1$ 的财富更新由下式给出\n$$\nW_{t+1} \\equiv W_t \\left(1 + a_t\\, r_{t+1}\\right) - \\kappa\\, W_t \\, \\mathbf{1}\\{a_t \\neq a_{t-1}\\},\n$$\n约定 $a_{-1} \\equiv 0$。定义运行高水位标记 $H_t$ 和回撤 $D_t$ 为\n$$\nH_t \\equiv \\max_{0 \\le s \\le t} W_s, \\qquad D_t \\equiv 1 - \\frac{W_t}{H_t},\n$$\n对于 $t \\ge 0$，其中 $H_0 \\equiv W_0$ 且 $D_0 \\equiv 0$。熔断机制在以下首次出现的时刻停止过程\n$$\n\\tau \\equiv \\min\\{t \\in \\{1,\\dots,T\\} : D_t  \\bar{d}\\},\n$$\n如果这样的时刻存在；否则，设 $\\tau \\equiv T$。模拟必须在时刻 $\\tau$ 停止，并且不应用任何后续的更新。对于每个测试用例，您的程序必须计算：\n- 一个停止指标 $h$，如果熔断机制触发（即 $\\tau  T$），则 $h=1$，否则 $h=0$，\n- 最终财富 $W_{\\tau}$，\n- 最终回撤 $D_{\\tau}$，\n- 最终时间指数 $\\tau$。\n\n所有实值输出必须四舍五入到 $6$ 位小数。诸如回撤阈值和回撤之类的百分比必须表示为小数（例如，百分之五表示为 $0.05$），而不是使用百分号。\n\n使用以下参数值的测试套件。每个测试用例都是一个元组 $\\left(\\{p_t\\}_{t=0}^{T}, \\{a_t\\}_{t=0}^{T-1}, W_0, \\kappa, \\bar{d}\\right)$，其中价格序列和行动序列被明确提供：\n\n- 测试用例 1（中度波动下不停止）：\n  - 价格：$[100,\\,101,\\,99,\\,100,\\,103]$\n  - 行动：$[1,\\,1,\\,1,\\,1]$\n  - $W_0 = 1.0$, $\\kappa = 0$, $\\bar{d} = 0.2$。\n\n- 测试用例 2（边界情况，回撤恰好等于阈值，此时不得停止）：\n  - 价格：$[100,\\,90,\\,100]$\n  - 行动：$[1,\\,1]$\n  - $W_0 = 1.0$, $\\kappa = 0$, $\\bar{d} = 0.1$。\n\n- 测试用例 3（由于阈值小且初始亏损导致立即停止）：\n  - 价格：$[100,\\,98,\\,200]$\n  - 行动：$[1,\\,1]$\n  - $W_0 = 1.0$, $\\kappa = 0$, $\\bar{d} = 0.01$。\n\n- 测试用例 4（尽管收益为零，但因交易成本导致停止）：\n  - 价格：$[100,\\,100,\\,100,\\,100]$\n  - 行动：$[1,\\,-1,\\,1]$\n  - $W_0 = 1.0$, $\\kappa = 0.03$, $\\bar{d} = 0.05$。\n\n您的程序应生成单行输出。最终输出必须遵循以下格式，将所有四个测试用例的结果包含在一个列表中：\n$$\n\\big[ [h_1, W_{\\tau,1}, D_{\\tau,1}, \\tau_1], [h_2, W_{\\tau,2}, D_{\\tau,2}, \\tau_2], [h_3, W_{\\tau,3}, D_{\\tau,3}, \\tau_3], [h_4, W_{\\tau,4}, D_{\\tau,4}, \\tau_4] \\big],\n$$\n不带任何附加文本。所有浮点数必须按规定四舍五入到 $6$ 位小数。",
            "solution": "在尝试提供解决方案之前，对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n\n问题的数学模型由以下组件定义：\n- 时间指数：$t \\in \\{0, 1, \\dots, T\\}$。\n- 严格为正的价格序列：$\\{p_t\\}_{t=0}^{T}$。\n- 智能体的行动序列：$\\{a_t\\}_{t=0}^{T-1}$，其中 $a_t \\in \\{-1, 0, 1\\}$。\n- 初始财富：$W_0 > 0$。\n- 交易成本率：$\\kappa \\in [0, 1)$。\n- 回撤阈值：$\\bar{d} \\in [0, 1)$。\n\n系统动态由以下方程控制：\n- 单步毛收益率：$r_{t+1} \\equiv \\frac{p_{t+1}-p_t}{p_t}$，对于 $t=0, 1, \\dots, T-1$。\n- 财富更新：$W_{t+1} \\equiv W_t \\left(1 + a_t\\, r_{t+1}\\right) - \\kappa\\, W_t \\, \\mathbf{1}\\{a_t \\neq a_{t-1}\\}$，约定 $a_{-1} \\equiv 0$。\n- 运行高水位标记：$H_t \\equiv \\max_{0 \\le s \\le t} W_s$，其中 $H_0 \\equiv W_0$。\n- 回撤：$D_t \\equiv 1 - \\frac{W_t}{H_t}$，其中 $D_0 \\equiv 0$。\n- 停止时间（熔断机制）：$\\tau \\equiv \\min\\{t \\in \\{1,\\dots,T\\} : D_t > \\bar{d}\\}$，如果该集合为空则设 $\\tau \\equiv T$。\n\n每个测试用例要求的输出是：\n- $h$：停止指标（如果 $\\tau  T$ 则为 $1$，否则为 $0$）。\n- $W_{\\tau}$：在时间 $\\tau$ 的最终财富。\n- $D_{\\tau}$：在时间 $\\tau$ 的最终回撤。\n- $\\tau$：最终时间指数。\n\n测试套件包含四个具体案例，并提供了所有必要的参数。\n\n### 步骤2：使用提取的已知条件进行验证\n\n根据验证标准对问题进行评估。\n- **科学基础**：该问题描述了一个交易策略的离散时间模拟。该模型包含了量化金融中的标准元素，包括收益率、交易成本和基于回撤的风险管理规则。数学公式逻辑上一致，并基于金融建模中的既定原则。该问题具有科学依据。\n- **适定性**：该问题被表述为一个确定性的初值问题。给定初始状态（$W_0$, $a_{-1}=0$）以及价格和行动的输入序列，系统在任何未来时间 $t$ 的状态（$W_t, H_t, D_t$）都是唯一确定的。停止条件是明确的（使用严格不等式 $D_t > \\bar{d}$），确保了停止时间 $\\tau$ 的定义是明确的。因此，每个测试用例都存在唯一的解。\n- **客观性**：问题以精确、形式化的数学语言陈述。所有术语都得到了明确的定义，没有主观解释的余地。\n- **完整性与一致性**：为每个测试用例提供了所有参数，包括价格和行动序列、初始财富、成本率和回撤阈值。价格序列的长度决定了总时长 $T$，行动序列具有相应的正确长度 $T$。参数的约束（$p_t > 0$, $W_0>0$ 等）是一致的，并能防止诸如除以零之类的问题。\n\n### 步骤3：结论与行动\n\n该问题是**有效的**。它具有科学基础、适定、客观且自成体系。将提供一个解决方案。\n\n### 解决方案设计\n\n该问题要求对特定交易策略和风险约束下的智能体财富进行离散时间模拟。模拟按步进方式演化，在每个时间点更新系统的状态变量。\n\n设系统在时间 $t$ 的状态由财富 $W_t$、高水位标记 $H_t$ 和回撤 $D_t$ 来表征。模拟过程如下：\n\n1.  **初始化 (在 $t=0$ 时)**：\n    - 给定初始财富 $W_0$。\n    - 初始高水位标记为 $H_0 = W_0$。\n    - 初始回撤为 $D_0 = 1 - W_0/H_0 = 0$。\n    - 按照约定，前一步的行动设置为 $a_{-1} = 0$。\n    - 总模拟时域 $T$ 由给定价格序列的长度确定，具体为 $T = \\text{length}(\\{p_t\\}) - 1$。\n\n2.  **时间步进循环 (对于 $t = 0, 1, \\dots, T-1$)**：\n    在每一步 $t$，计算下一个时间点 $t+1$ 的状态。\n    - **a. 计算收益率**：根据价格数据计算风险资产的单步毛收益率：\n      $$r_{t+1} = \\frac{p_{t+1} - p_t}{p_t}$$\n    - **b. 计算交易成本**：如果行动与上一步不同，则产生交易成本。成本为：\n      $$C_t = \\kappa\\, W_t \\, \\mathbf{1}\\{a_t \\neq a_{t-1}\\}$$\n      其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，如果条件为真则为 $1$，否则为 $0$。\n    - **c. 更新财富**：根据投资回报和交易成本更新财富：\n      $$W_{t+1} = W_t(1 + a_t r_{t+1}) - C_t$$\n    - **d. 更新高水位标记**：更新运行中的财富最大值：\n      $$H_{t+1} = \\max(H_t, W_{t+1})$$\n    - **e. 计算回撤**：计算新的回撤。由于 $W_0>0$ 且 $p_t>0$，在 $\\tau$ 之前 $H_t$ 将保持为正。\n      $$D_{t+1} = 1 - \\frac{W_{t+1}}{H_{t+1}}$$\n    - **f. 检查熔断机制**：检查核心风险管理规则。如果新计算的回撤超过阈值，则停止模拟。\n      如果 $D_{t+1} > \\bar{d}$：\n        - 设置停止时间 $\\tau = t+1$。\n        - 设置停止指标 $h=1$。\n        - 过程终止。最终状态为 $\\{W_\\tau, D_\\tau, \\tau\\}$。\n    - **g. 更新前一行动**：对于下一次迭代，当前行动成为前一行动：设置 $a_{t-1} \\leftarrow a_t$。\n\n3.  **终止**：\n    - 如果循环因在时间 $\\tau$ 触发熔断机制而提前终止，最终结果为 $\\{h=1, W_\\tau, D_\\tau, \\tau\\}$。\n    - 如果循环完成而回撤从未超过阈值，模拟将运行完整过程。终止时间为 $\\tau=T$。最终结果为 $\\{h=0, W_T, D_T, \\tau=T\\}$。\n\n所有浮点输出值（$W_\\tau$, $D_\\tau$）必须四舍五入到 $6$ 位小数。此过程将对提供的每个测试用例实施。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the trading simulation problem for a given set of test cases.\n    \"\"\"\n\n    def simulate_trading(prices, actions, W0, kappa, d_bar):\n        \"\"\"\n        Simulates the trading environment with a circuit breaker.\n\n        Args:\n            prices (list or np.array): The sequence of asset prices {p_t}.\n            actions (list or np.array): The sequence of agent actions {a_t}.\n            W0 (float): Initial wealth.\n            kappa (float): Trading cost rate.\n            d_bar (float): Drawdown threshold.\n\n        Returns:\n            list: A list containing [h, W_tau, D_tau, tau].\n        \"\"\"\n        prices = np.array(prices, dtype=np.float64)\n        actions = np.array(actions, dtype=np.int8)\n        \n        T = len(prices) - 1\n        \n        # State variables\n        W = np.zeros(T + 1, dtype=np.float64)\n        H = np.zeros(T + 1, dtype=np.float64)\n        D = np.zeros(T + 1, dtype=np.float64)\n        \n        # Initialization at t=0\n        W[0] = float(W0)\n        H[0] = float(W0)\n        D[0] = 0.0\n        \n        # Convention for action at t=-1\n        a_prev = 0\n        \n        # Time-stepping simulation\n        for t in range(T):\n            # (a) Calculate return for step t -> t+1\n            r_tplus1 = (prices[t+1] - prices[t]) / prices[t]\n            \n            a_t = actions[t]\n            \n            # (b) Calculate trading cost\n            cost_indicator = 1 if a_t != a_prev else 0\n            cost = kappa * W[t] * cost_indicator\n            \n            # (c) Update wealth\n            W[t+1] = W[t] * (1 + a_t * r_tplus1) - cost\n            \n            # (d) Update high-water mark\n            H[t+1] = max(H[t], W[t+1])\n            \n            # (e) Calculate drawdown\n            if H[t+1] > 0:\n                D[t+1] = 1.0 - (W[t+1] / H[t+1])\n            else:\n                # This case implies ruin and should result in max drawdown.\n                # Given problem constraints (W0>0, p_t>0), H_t should not be = 0 unless W_t becomes =0.\n                D[t+1] = 1.0 \n\n            # (f) Check circuit breaker\n            if D[t+1] > d_bar:\n                tau = t + 1\n                h = 1\n                # Return results at halt time\n                return [h, W[tau], D[tau], tau]\n            \n            # (g) Update previous action for next iteration\n            a_prev = a_t\n            \n        # If loop completes without halting\n        tau = T\n        h = 0\n        return [h, W[T], D[T], T]\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # Test Case 1\n        {\n            \"prices\": [100.0, 101.0, 99.0, 100.0, 103.0],\n            \"actions\": [1, 1, 1, 1],\n            \"W0\": 1.0, \"kappa\": 0.0, \"d_bar\": 0.2\n        },\n        # Test Case 2\n        {\n            \"prices\": [100.0, 90.0, 100.0],\n            \"actions\": [1, 1],\n            \"W0\": 1.0, \"kappa\": 0.0, \"d_bar\": 0.1\n        },\n        # Test Case 3\n        {\n            \"prices\": [100.0, 98.0, 200.0],\n            \"actions\": [1, 1],\n            \"W0\": 1.0, \"kappa\": 0.0, \"d_bar\": 0.01\n        },\n        # Test Case 4\n        {\n            \"prices\": [100.0, 100.0, 100.0, 100.0],\n            \"actions\": [1, -1, 1],\n            \"W0\": 1.0, \"kappa\": 0.03, \"d_bar\": 0.05\n        }\n    ]\n\n    results_str_list = []\n    for case in test_cases:\n        result = simulate_trading(\n            case[\"prices\"], case[\"actions\"], case[\"W0\"], case[\"kappa\"], case[\"d_bar\"]\n        )\n        # Format the result list into the required string format\n        h, W_tau, D_tau, tau = result\n        result_str = f\"[{h}, {W_tau:.6f}, {D_tau:.6f}, {tau}]\"\n        results_str_list.append(result_str)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results_str_list)}]\")\n\nsolve()\n```"
        }
    ]
}