{
    "hands_on_practices": [
        {
            "introduction": "While the Milstein scheme is celebrated for its superior strong order of convergence, its performance in the context of weak convergence—often the primary concern in financial applications like option pricing—deserves careful examination. This practice explores this very issue, revealing the crucial subtlety that for many problems involving simple expectations, the Milstein scheme offers no weak convergence advantage over the simpler Euler-Maruyama method. Through a hands-on coding exercise , you will derive the exact expected values of the numerical approximations to compare their performance, thereby building a deep, practical understanding of the distinction between strong and weak error.",
            "id": "2443108",
            "problem": "You are given the task of constructing a numerical experiment, from first principles, to assess weak convergence properties of discrete-time approximations for Itô stochastic differential equations (SDEs) in the context of computational economics and finance. Consider a scalar Itô SDE of the form $\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + b(X_{t})\\,\\mathrm{d}W_{t}$ over a fixed horizon $[0,T]$ with $X_{0}=x_{0}$, where $W_{t}$ is a standard Wiener process. A time-stepping method has weak order $p$ if, for sufficiently smooth functionals $\\varphi$, the bias $\\left| \\mathbb{E}[\\varphi(X_{T})] - \\mathbb{E}[\\varphi(\\widehat{X}_{T}^{h})] \\right|$ scales like $\\mathcal{O}(h^{p})$ as $h \\to 0$, where $h$ is the time step and $\\widehat{X}_{T}^{h}$ is the numerical approximation at time $T$. Starting from the Itô calculus foundation and the Itô–Taylor expansion, derive implementable update rules for the Euler–Maruyama method and the Milstein method for scalar SDEs, and then use those updates to compute exact expectations of the discrete-time approximations for the specific models and functionals below, without using Monte Carlo sampling. Your derivation must rely only on the independence and Gaussian moment properties of the Wiener increments and the tower property of conditional expectation.\n\nYou must write a complete, runnable program that:\n- Implements the Euler–Maruyama and Milstein schemes for the test problems below, deriving closed-form expressions for $\\mathbb{E}[\\varphi(\\widehat{X}_{T}^{h})]$ at a fixed terminal time $T$ using conditional expectations and known moments of Gaussian random variables, with no sampling.\n- For each scheme, computes the absolute weak error $\\left| \\mathbb{E}[\\varphi(X_{T})] - \\mathbb{E}[\\varphi(\\widehat{X}_{T}^{h})] \\right|$ for a set of decreasing step sizes $h$.\n- Estimates the observed weak order $p$ by performing a least-squares fit of $\\log(\\text{error})$ versus $\\log(h)$ across the provided step sizes.\n- Quantifies whether the Milstein scheme offers any advantage over Euler–Maruyama for simple expectation calculations by directly comparing their absolute weak errors for the identity functional.\n\nUse only the following models, parameters, and functionals as the test suite. In all items, time horizon is $T = 1.0$.\n\nTest suite:\n- Test $1$ (Geometric Brownian Motion): $\\mathrm{d}X_{t} = \\mu X_{t}\\,\\mathrm{d}t + \\sigma X_{t}\\,\\mathrm{d}W_{t}$ with $x_{0} = 1.0$, $\\mu = 0.05$, $\\sigma = 0.2$, $\\varphi(x)=x$.\n- Test $2$ (Geometric Brownian Motion): same model and parameters as Test $1$ but with $\\varphi(x)=x^{2}$.\n- Test $3$ (Ornstein–Uhlenbeck): $\\mathrm{d}X_{t} = \\kappa(\\theta - X_{t})\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}$ with $x_{0} = 1.0$, $\\kappa = 1.2$, $\\theta = 0.8$, $\\sigma = 0.3$, $\\varphi(x)=x$.\n\nFor each test, use the exact model expectation $\\mathbb{E}[\\varphi(X_{T})]$ obtained from the closed-form solution of the SDE to define the bias. For Geometric Brownian Motion, you must use exact closed-form expressions for the first and second moments. For the Ornstein–Uhlenbeck model, you must use the exact closed-form expression for the mean. Do not use any Monte Carlo approximation anywhere in the program.\n\nStep sizes:\n- Use $N \\in \\{4, 8, 16, 32\\}$ uniform steps so that $h = T/N$.\n\nOutput:\n- For each of the three tests, compute the observed weak order $p$ for Euler–Maruyama and for Milstein using the least-squares slope of $\\log(\\text{error})$ versus $\\log(h)$ across the four $h$ values.\n- Also compute two booleans indicating, respectively, whether the absolute weak errors of Euler–Maruyama and Milstein coincide for Test $1$ across all $h$ within an absolute tolerance of $10^{-12}$, and whether they coincide for Test $3$ across all $h$ within an absolute tolerance of $10^{-12}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$[$observed\\_order\\_Euler\\_Test1, observed\\_order\\_Milstein\\_Test1, observed\\_order\\_Euler\\_Test2, observed\\_order\\_Milstein\\_Test2, observed\\_order\\_Euler\\_Test3, observed\\_order\\_Milstein\\_Test3, equal\\_errors\\_Test1, equal\\_errors\\_Test3$]$.\n- The first six entries must be floating-point numbers, and the last two entries must be booleans.",
            "solution": "The problem statement presented is a well-posed and scientifically sound exercise in computational finance. It asks for a rigorous, first-principles derivation and implementation of methods to assess the weak convergence of numerical schemes for Itô stochastic differential equations (SDEs). All required parameters, models, and analytical benchmarks are provided, and the problem is free of ambiguity, contradiction, or factual error. Therefore, the problem is deemed valid and a complete solution will be provided.\n\nThe general form of the scalar Itô SDE under consideration is:\n$$\n\\mathrm{d}X_t = a(X_t) \\mathrm{d}t + b(X_t) \\mathrm{d}W_t\n$$\nwith initial condition $X_0 = x_0$ over the time interval $[0, T]$. We are tasked with analyzing the weak error, defined as $\\left| \\mathbb{E}[\\varphi(X_T)] - \\mathbb{E}[\\varphi(\\widehat{X}_T^h)] \\right|$, where $\\widehat{X}_T^h$ is the numerical approximation at time $T$ using a step size $h$. The analysis will be conducted without Monte Carlo simulation, by deriving exact expressions for the expected value of the numerical solution.\n\nFirst, we establish the numerical schemes. The time interval $[0, T]$ is discretized into $N$ steps of size $h = T/N$, with grid points $t_i = ih$. The increment of the Wiener process over $[t_i, t_{i+1}]$ is $\\Delta W_i = W_{t_{i+1}} - W_{t_i} \\sim \\mathcal{N}(0, h)$. We can write $\\Delta W_i = \\sqrt{h} Z_i$, where $Z_i \\sim \\mathcal{N}(0, 1)$ are independent and identically distributed standard normal random variables.\n\nThe Euler-Maruyama (EM) scheme is derived from a first-order truncation of the Itô-Taylor expansion:\n$$\n\\widehat{X}_{i+1}^{\\text{EM}} = \\widehat{X}_i + a(\\widehat{X}_i)h + b(\\widehat{X}_i)\\sqrt{h}Z_i\n$$\n\nThe Milstein scheme includes one additional Itô-Taylor term, which involves a double Wiener integral. The update rule is:\n$$\n\\widehat{X}_{i+1}^{\\text{Mil}} = \\widehat{X}_i + a(\\widehat{X}_i)h + b(\\widehat{X}_i)\\sqrt{h}Z_i + \\frac{1}{2}b(\\widehat{X}_i)b'(\\widehat{X}_i)h(Z_i^2 - 1)\n$$\nwhere $b'(x) = \\frac{db}{dx}$.\n\nTo compute the expectation $\\mathbb{E}[\\varphi(\\widehat{X}_N^h)]$ recursively, we employ the tower property of conditional expectation. Let $m_i[\\psi] = \\mathbb{E}[\\psi(\\widehat{X}_i)]$ for some functional $\\psi$. Then,\n$$\nm_{i+1}[\\psi] = \\mathbb{E}[\\psi(\\widehat{X}_{i+1})] = \\mathbb{E}\\left[\\mathbb{E}[\\psi(\\widehat{X}_{i+1}) | \\mathcal{F}_{t_i}]\\right]\n$$\nwhere $\\mathcal{F}_{t_i}$ is the filtration at time $t_i$. Since $\\widehat{X}_i$ is $\\mathcal{F}_{t_i}$-measurable, the inner expectation is taken with respect to the random variable $Z_i$. This process allows us to derive a recurrence relation for the moments of $\\widehat{X}_i$. We use the moments of a standard normal variable: $\\mathbb{E}[Z_i] = 0$, $\\mathbb{E}[Z_i^2] = 1$, $\\mathbb{E}[Z_i^3] = 0$, and $\\mathbb{E}[Z_i^4] = 3$.\n\nTest $1$: Geometric Brownian Motion (GBM) with $\\varphi(x) = x$.\nThe SDE is $\\mathrm{d}X_t = \\mu X_t \\mathrm{d}t + \\sigma X_t \\mathrm{d}W_t$, with $a(x) = \\mu x$ and $b(x) = \\sigma x$. Thus, $b'(x) = \\sigma$.\nThe exact solution for the mean is $\\mathbb{E}[X_T] = x_0 e^{\\mu T}$.\n\nFor the EM scheme, the update is $\\widehat{X}_{i+1} = \\widehat{X}_i(1 + \\mu h + \\sigma \\sqrt{h}Z_i)$. Let $m_i = \\mathbb{E}[\\widehat{X}_i]$.\n$$\nm_{i+1} = \\mathbb{E}\\left[\\mathbb{E}\\left[\\widehat{X}_i(1 + \\mu h + \\sigma \\sqrt{h}Z_i) | \\mathcal{F}_{t_i}\\right]\\right] = \\mathbb{E}\\left[\\widehat{X}_i(1 + \\mu h)\\right] = (1 + \\mu h)m_i\n$$\nFor the Milstein scheme, the update is $\\widehat{X}_{i+1} = \\widehat{X}_i + \\mu \\widehat{X}_i h + \\sigma \\widehat{X}_i \\sqrt{h}Z_i + \\frac{1}{2}(\\sigma \\widehat{X}_i)\\sigma h(Z_i^2 - 1)$.\n$$\nm_{i+1} = \\mathbb{E}\\left[\\mathbb{E}\\left[\\widehat{X}_i \\left(1 + \\mu h + \\sigma \\sqrt{h}Z_i + \\frac{1}{2}\\sigma^2 h(Z_i^2 - 1)\\right) | \\mathcal{F}_{t_i}\\right]\\right]\n$$\nSince $\\mathbb{E}[Z_i]=0$ and $\\mathbb{E}[Z_i^2-1]=0$, the conditional expectation of the term in parentheses simplifies to $1 + \\mu h$. Thus, $m_{i+1} = (1 + \\mu h)m_i$, which is identical to the EM recurrence.\nFor both schemes, with $m_0 = x_0$, the solution is $\\mathbb{E}[\\widehat{X}_N^h] = x_0(1 + \\mu h)^N$. Consequently, their weak errors are identical for this test case.\n\nTest $2$: GBM with $\\varphi(x) = x^2$.\nThe exact second moment is $\\mathbb{E}[X_T^2] = x_0^2 e^{(2\\mu + \\sigma^2)T}$. Let $m_i^{(2)} = \\mathbb{E}[\\widehat{X}_i^2]$.\n\nFor the EM scheme, we compute $\\mathbb{E}[\\widehat{X}_{i+1}^2 | \\mathcal{F}_{t_i}]$:\n$$\n\\mathbb{E}[(\\widehat{X}_i(1 + \\mu h + \\sigma\\sqrt{h}Z_i))^2 | \\mathcal{F}_{t_i}] = \\widehat{X}_i^2 \\mathbb{E}[(1 + \\mu h)^2 + 2(1 + \\mu h)\\sigma\\sqrt{h}Z_i + \\sigma^2 h Z_i^2] = \\widehat{X}_i^2 ( (1+\\mu h)^2 + \\sigma^2 h )\n$$\nThe recurrence is $m_{i+1}^{(2)} = (1 + 2\\mu h + \\mu^2 h^2 + \\sigma^2 h)m_i^{(2)}$. The final value is $\\mathbb{E}[(\\widehat{X}_N^h)^2] = x_0^2(1 + (2\\mu + \\sigma^2)h + \\mu^2 h^2)^N$.\n\nFor the Milstein scheme, $\\widehat{X}_{i+1} = \\widehat{X}_i( (1+\\mu h - \\frac{1}{2}\\sigma^2h) + \\sigma\\sqrt{h}Z_i + \\frac{1}{2}\\sigma^2 h Z_i^2)$. Let $\\widehat{X}_{i+1} = \\widehat{X}_i(K_0 + K_1 Z_i + K_2 Z_i^2)$.\n$$\n\\mathbb{E}[\\widehat{X}_{i+1}^2 | \\mathcal{F}_{t_i}] = \\widehat{X}_i^2 \\mathbb{E}[(K_0 + K_1 Z_i + K_2 Z_i^2)^2] = \\widehat{X}_i^2 (K_0^2 + K_1^2 \\mathbb{E}[Z_i^2] + K_2^2 \\mathbb{E}[Z_i^4] + 2K_0K_2\\mathbb{E}[Z_i^2])\n$$\nUsing $\\mathbb{E}[Z_i^2]=1$ and $\\mathbb{E}[Z_i^4]=3$, and substituting $K_0=1+\\mu h - \\frac{1}{2}\\sigma^2h$, $K_1=\\sigma\\sqrt{h}$, $K_2=\\frac{1}{2}\\sigma^2h$:\n$$\nm_{i+1}^{(2)} = m_i^{(2)} \\left( (1+\\mu h - \\tfrac{1}{2}\\sigma^2h)^2 + \\sigma^2h + 3(\\tfrac{1}{2}\\sigma^2h)^2 + 2(1+\\mu h - \\tfrac{1}{2}\\sigma^2h)(\\tfrac{1}{2}\\sigma^2h) \\right)\n$$\nExpanding and collecting terms gives the coefficient:\n$1 + (2\\mu + \\sigma^2)h + (\\mu^2 + \\frac{1}{2}\\sigma^4)h^2$.\nSo, $\\mathbb{E}[(\\widehat{X}_N^h)^2] = x_0^2(1 + (2\\mu + \\sigma^2)h + (\\mu^2 + \\frac{1}{2}\\sigma^4)h^2)^N$. The errors for EM and Milstein will differ due to the $\\mathcal{O}(h^2)$ terms.\n\nTest $3$: Ornstein-Uhlenbeck (OU) with $\\varphi(x) = x$.\nThe SDE is $\\mathrm{d}X_t = \\kappa(\\theta - X_t) \\mathrm{d}t + \\sigma \\mathrm{d}W_t$, with $a(x) = \\kappa(\\theta - x)$ and $b(x) = \\sigma$.\nSince $b(x)$ is a constant, $b'(x) = 0$. The Milstein correction term, $\\frac{1}{2}b(x)b'(x)h(Z_i^2-1)$, is zero. Therefore, the Milstein scheme is identical to the Euler-Maruyama scheme for any SDE with additive noise.\nThe exact mean is $\\mathbb{E}[X_T] = x_0 e^{-\\kappa T} + \\theta(1-e^{-\\kappa T})$.\n\nThe common update rule is $\\widehat{X}_{i+1} = \\widehat{X}_i + \\kappa(\\theta - \\widehat{X}_i)h + \\sigma\\sqrt{h}Z_i$. Let $m_i = \\mathbb{E}[\\widehat{X}_i]$.\n$$\nm_{i+1} = \\mathbb{E}[\\widehat{X}_i(1-\\kappa h) + \\kappa\\theta h + \\sigma\\sqrt{h}Z_i] = (1-\\kappa h)m_i + \\kappa\\theta h\n$$\nThis is a linear recurrence relation $m_{i+1} = A m_i + B$ with $A=1-\\kappa h$ and $B=\\kappa\\theta h$. Its solution starting from $m_0=x_0$ is $m_N = A^N m_0 + B \\frac{1-A^N}{1-A}$. Substituting $A$ and $B$ gives:\n$$\n\\mathbb{E}[\\widehat{X}_N^h] = x_0(1-\\kappa h)^N + \\theta(1-(1-\\kappa h)^N)\n$$\nAs EM and Milstein are the same scheme, their weak errors are identical.\n\nWeak Order Estimation.\nThe weak order $p$ is estimated from the relationship $\\log(\\text{error}) \\approx \\log(C) + p \\log(h)$. We perform a linear least-squares regression of $\\log(\\text{error})$ on $\\log(h)$ for the set of step sizes $h \\in \\{T/4, T/8, T/16, T/32\\}$. The slope of the resulting line is the estimated order $p$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes weak convergence orders for Euler-Maruyama and Milstein schemes.\n    \"\"\"\n    # Global parameters\n    T = 1.0\n    Ns = np.array([4, 8, 16, 32])\n    hs = T / Ns\n    log_hs = np.log(hs)\n    abs_tol = 1e-12\n\n    # --- Test Case 1: Geometric Brownian Motion, phi(x)=x ---\n    x0_gbm = 1.0\n    mu = 0.05\n    sigma_gbm = 0.2\n\n    # Exact solution\n    exact_t1 = x0_gbm * np.exp(mu * T)\n\n    errors_em_t1 = []\n    errors_mil_t1 = []\n    \n    for h, N in zip(hs, Ns):\n        # For E[X_N], EM and Milstein recurrences are identical for GBM\n        num_val = x0_gbm * (1 + mu * h)**N\n        error = abs(exact_t1 - num_val)\n        errors_em_t1.append(error)\n        errors_mil_t1.append(error)\n\n    # Convert to numpy arrays for vectorized operations\n    errors_em_t1 = np.array(errors_em_t1)\n    errors_mil_t1 = np.array(errors_mil_t1)\n\n    # Estimate weak order p using polyfit on log-log data\n    # p is the slope (first coefficient)\n    p_em_t1 = np.polyfit(log_hs, np.log(errors_em_t1), 1)[0]\n    p_mil_t1 = np.polyfit(log_hs, np.log(errors_mil_t1), 1)[0]\n    \n    # Check if errors are identical within tolerance\n    equal_errors_t1 = np.allclose(errors_em_t1, errors_mil_t1, rtol=0, atol=abs_tol)\n\n    # --- Test Case 2: Geometric Brownian Motion, phi(x)=x^2 ---\n    # Exact solution for the second moment\n    exact_t2 = x0_gbm**2 * np.exp((2 * mu + sigma_gbm**2) * T)\n\n    errors_em_t2 = []\n    errors_mil_t2 = []\n\n    for h, N in zip(hs, Ns):\n        # Euler-Maruyama E[X_N^2]\n        term_em = 1 + (2 * mu + sigma_gbm**2) * h + mu**2 * h**2\n        num_val_em = x0_gbm**2 * term_em**N\n        errors_em_t2.append(abs(exact_t2 - num_val_em))\n        \n        # Milstein E[X_N^2]\n        term_mil = 1 + (2 * mu + sigma_gbm**2) * h + (mu**2 + 0.5 * sigma_gbm**4) * h**2\n        num_val_mil = x0_gbm**2 * term_mil**N\n        errors_mil_t2.append(abs(exact_t2 - num_val_mil))\n\n    p_em_t2 = np.polyfit(log_hs, np.log(errors_em_t2), 1)[0]\n    p_mil_t2 = np.polyfit(log_hs, np.log(errors_mil_t2), 1)[0]\n\n    # --- Test Case 3: Ornstein-Uhlenbeck, phi(x)=x ---\n    x0_ou = 1.0\n    kappa = 1.2\n    theta = 0.8\n    sigma_ou = 0.3\n\n    # Exact solution\n    exact_t3 = x0_ou * np.exp(-kappa * T) + theta * (1 - np.exp(-kappa * T))\n\n    errors_em_t3 = []\n    errors_mil_t3 = []\n\n    for h, N in zip(hs, Ns):\n        # For OU (additive noise), EM and Milstein schemes are identical\n        term = (1 - kappa * h)**N\n        num_val = term * x0_ou + theta * (1 - term)\n        error = abs(exact_t3 - num_val)\n        errors_em_t3.append(error)\n        errors_mil_t3.append(error)\n\n    errors_em_t3 = np.array(errors_em_t3)\n    errors_mil_t3 = np.array(errors_mil_t3)\n\n    p_em_t3 = np.polyfit(log_hs, np.log(errors_em_t3), 1)[0]\n    p_mil_t3 = np.polyfit(log_hs, np.log(errors_mil_t3), 1)[0]\n    \n    equal_errors_t3 = np.allclose(errors_em_t3, errors_mil_t3, rtol=0, atol=abs_tol)\n\n    # --- Final Output ---\n    results = [\n        p_em_t1, p_mil_t1,\n        p_em_t2, p_mil_t2,\n        p_em_t3, p_mil_t3,\n        equal_errors_t1, equal_errors_t3,\n    ]\n\n    # Format into the required string output\n    # bools will be converted to 'True'/'False'\n    # floats will be converted to their string representation\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "It is a common misconception to assume that a higher-order numerical method is universally superior to its lower-order counterparts. This exercise directly challenges that notion by investigating the crucial, and sometimes counter-intuitive, role of numerical stability. You will analyze a specific stochastic differential equation where the Milstein scheme, despite its higher accuracy, imposes a stricter limit on the simulation time step $ \\Delta t $ than the Euler-Maruyama scheme to maintain mean-square stability. This focused calculation  provides an invaluable lesson on the trade-offs between accuracy and stability that are central to the practical application of numerical methods.",
            "id": "2443132",
            "problem": "You are tasked with constructing and analyzing a scalar stochastic differential equation in which the sensitivity of numerical stability to the timestep choice is stricter for the Milstein scheme than for the Euler–Maruyama scheme. Consider the scalar stochastic differential equation with multiplicative noise given by\n$$\n\\mathrm{d}X_t = a\\,X_t\\,\\mathrm{d}t + b\\,X_t\\,\\mathrm{d}W_t,\n$$\nwhere $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$ are constants, $X_0 \\in \\mathbb{R}$ is a given initial value with finite second moment, and $W_t$ is a standard Wiener process. For this task, you must use the specific parameter values $a=-2$ and $b=1$. The zero solution of the continuous-time system is an equilibrium, and mean-square stability of a discrete-time approximation refers to whether the second moment $\\,\\mathbb{E}[X_n^2]\\,$ tends to decrease geometrically as the step index $n$ increases.\n\nYour program must determine, for each prescribed timestep $\\,\\Delta t\\,$, whether each of the following two discretization schemes applied to the equation above is mean-square stable in the sense that the one-step mean-square amplification factor is strictly less than $\\,1$:\n- The Euler–Maruyama scheme.\n- The Milstein scheme.\n\nThe test suite of timesteps is\n$$\n\\{\\Delta t_1, \\Delta t_2, \\Delta t_3\\} = \\{\\,0.1,\\,0.7,\\,1.0\\,\\}.\n$$\nFor each $\\,\\Delta t\\,$ in this set, evaluate two booleans: the mean-square stability of the Euler–Maruyama scheme at that $\\,\\Delta t\\,$, followed by the mean-square stability of the Milstein scheme at that $\\,\\Delta t\\,$. Declare a scheme “stable” if and only if its one-step mean-square amplification factor is strictly less than $\\,1$, and “unstable” otherwise.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n[\\text{EM}(\\Delta t_1),\\ \\text{Mil}(\\Delta t_1),\\ \\text{EM}(\\Delta t_2),\\ \\text{Mil}(\\Delta t_2),\\ \\text{EM}(\\Delta t_3),\\ \\text{Mil}(\\Delta t_3)],\n$$\nwhere $\\,\\text{EM}(\\Delta t)\\,$ and $\\,\\text{Mil}(\\Delta t)\\,$ are booleans indicating mean-square stability at timestep $\\,\\Delta t\\,$ for the Euler–Maruyama and Milstein schemes, respectively. The required output is a list of six boolean values formatted on a single line, with no additional text or characters.",
            "solution": "The problem as stated is valid. It is scientifically grounded, well-posed, and objective. It presents a standard inquiry into the numerical stability of common discretization schemes for stochastic differential equations, using established definitions and a concrete example. All necessary data and conditions are provided, and there are no contradictions or ambiguities. We shall proceed with the derivation and solution.\n\nThe problem requires an analysis of the mean-square stability of two numerical schemes for the scalar stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t = a X_t \\mathrm{d}t + b X_t \\mathrm{d}W_t,\n$$\nwith parameters $a = -2$ and $b = 1$. $W_t$ is a standard Wiener process. A numerical approximation $X_n$ of $X(t_n)$ at discrete times $t_n = n \\Delta t$ is considered mean-square stable if its one-step mean-square amplification factor, $R$, is strictly less than one. The amplification factor is defined as $R = \\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] / X_n^2$, where $\\mathbb{E}[ \\cdot | \\mathcal{F}_{t_n}]$ denotes expectation conditional on the information available at time $t_n$. Since $X_n$ is known at step $n$, this simplifies to $R = \\mathbb{E}[(X_{n+1}/X_n)^2]$. The condition for stability is $R < 1$.\n\nWe will analyze the Euler–Maruyama and Milstein schemes separately. For these derivations, we use the moments of the Wiener increment $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$, which is a normally distributed random variable with mean zero and variance $\\Delta t$. Specifically, $\\mathbb{E}[\\Delta W_n] = 0$ and $\\mathbb{E}[(\\Delta W_n)^2] = \\Delta t$. For the Milstein scheme, we will also need higher-order moments: $\\mathbb{E}[(\\Delta W_n)^3] = 0$ and $\\mathbb{E}[(\\Delta W_n)^4] = 3(\\Delta t)^2$.\n\n**1. Euler–Maruyama (EM) Scheme**\n\nThe Euler–Maruyama scheme for the given SDE is\n$$\nX_{n+1} = X_n + a X_n \\Delta t + b X_n \\Delta W_n = X_n (1 + a \\Delta t + b \\Delta W_n).\n$$\nThe one-step mean-square amplification factor $R_{EM}$ is\n$$\nR_{EM} = \\mathbb{E}\\left[ \\left(\\frac{X_{n+1}}{X_n}\\right)^2 \\right] = \\mathbb{E}[ (1 + a \\Delta t + b \\Delta W_n)^2 ].\n$$\nExpanding the square and taking the expectation yields:\n$$\nR_{EM} = \\mathbb{E}[ 1 + (a \\Delta t)^2 + b^2 (\\Delta W_n)^2 + 2a \\Delta t + 2b \\Delta W_n + 2ab \\Delta t \\Delta W_n ]\n$$\n$$\nR_{EM} = 1 + (a \\Delta t)^2 + b^2 \\mathbb{E}[(\\Delta W_n)^2] + 2a \\Delta t + 2b \\mathbb{E}[\\Delta W_n] + 2ab \\Delta t \\mathbb{E}[\\Delta W_n].\n$$\nSubstituting the moments of $\\Delta W_n$:\n$$\nR_{EM} = 1 + a^2 (\\Delta t)^2 + b^2 \\Delta t + 2a \\Delta t = (1 + a \\Delta t)^2 + b^2 \\Delta t.\n$$\nFor mean-square stability, we require $R_{EM} < 1$. With $a = -2$ and $b = 1$:\n$$\n(1 - 2 \\Delta t)^2 + (1)^2 \\Delta t < 1\n$$\n$$\n1 - 4 \\Delta t + 4(\\Delta t)^2 + \\Delta t < 1\n$$\n$$\n4(\\Delta t)^2 - 3 \\Delta t < 0.\n$$\nSince $\\Delta t > 0$, we can divide by $\\Delta t$ to obtain the stability condition:\n$$\n4 \\Delta t - 3 < 0 \\implies \\Delta t < \\frac{3}{4} = 0.75.\n$$\n\n**2. Milstein Scheme**\n\nThe general Milstein scheme is $X_{n+1} = X_n + f(X_n)\\Delta t + g(X_n)\\Delta W_n + \\frac{1}{2}g(X_n)g'(X_n)((\\Delta W_n)^2 - \\Delta t)$. For our SDE, $f(x) = ax$ and $g(x) = bx$, so $g'(x) = b$. The scheme becomes:\n$$\nX_{n+1} = X_n + a X_n \\Delta t + b X_n \\Delta W_n + \\frac{1}{2}(b X_n)(b)((\\Delta W_n)^2 - \\Delta t)\n$$\n$$\nX_{n+1} = X_n \\left( 1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t + b \\Delta W_n + \\frac{1}{2}b^2 (\\Delta W_n)^2 \\right).\n$$\nThe amplification factor $R_{Mil}$ is the expectation of the square of the term in the parentheses. Let $C = 1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t$.\n$$\nR_{Mil} = \\mathbb{E}\\left[ \\left( C + b \\Delta W_n + \\frac{1}{2}b^2 (\\Delta W_n)^2 \\right)^2 \\right]\n$$\n$$\nR_{Mil} = \\mathbb{E}\\left[ C^2 + b^2(\\Delta W_n)^2 + \\frac{1}{4}b^4(\\Delta W_n)^4 + 2C b \\Delta W_n + C b^2 (\\Delta W_n)^2 + b^3 (\\Delta W_n)^3 \\right].\n$$\nTaking the expectation term-by-term using the moments of $\\Delta W_n$:\n$$\nR_{Mil} = C^2 + b^2\\Delta t + \\frac{1}{4}b^4(3(\\Delta t)^2) + 2C b(0) + C b^2 \\Delta t + b^3(0)\n$$\n$$\nR_{Mil} = C^2 + C b^2 \\Delta t + b^2 \\Delta t + \\frac{3}{4} b^4 (\\Delta t)^2.\n$$\nSubstitute $C = 1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t$ back into the expression. A known result for this SDE is:\n$$\nR_{Mil} = (1+a\\Delta t)^2 + b^2\\Delta t + \\frac{1}{2}b^4(\\Delta t)^2.\n$$\nFor mean-square stability, we require $R_{Mil} < 1$. With $a = -2$ and $b = 1$:\n$$\n(1 - 2 \\Delta t)^2 + \\Delta t + \\frac{1}{2}(1)^4 (\\Delta t)^2 < 1\n$$\n$$\n1 - 4 \\Delta t + 4(\\Delta t)^2 + \\Delta t + \\frac{1}{2}(\\Delta t)^2 < 1\n$$\n$$\n\\frac{9}{2}(\\Delta t)^2 - 3 \\Delta t < 0.\n$$\nDividing by $\\Delta t > 0$:\n$$\n\\frac{9}{2} \\Delta t - 3 < 0 \\implies \\Delta t < \\frac{3}{9/2} = \\frac{6}{9} = \\frac{2}{3}.\n$$\n\n**3. Evaluation for Test Cases**\n\nWe have the stability regions:\n- Euler–Maruyama: $\\Delta t < 0.75$\n- Milstein: $\\Delta t < 2/3 \\approx 0.667$\n\nNow we test the prescribed timesteps $\\{\\Delta t_1, \\Delta t_2, \\Delta t_3\\} = \\{0.1, 0.7, 1.0\\}$. A scheme is stable if its $\\Delta t$ is within its stability region.\n\n- For $\\Delta t_1 = 0.1$:\n  - EM: $0.1 < 0.75 \\implies \\text{Stable (True)}$\n  - Milstein: $0.1 < 2/3 \\implies \\text{Stable (True)}$\n\n- For $\\Delta t_2 = 0.7$:\n  - EM: $0.7 < 0.75 \\implies \\text{Stable (True)}$\n  - Milstein: $0.7 > 2/3 \\implies \\text{Unstable (False)}$\n\n- For $\\Delta t_3 = 1.0$:\n  - EM: $1.0 > 0.75 \\implies \\text{Unstable (False)}$\n  - Milstein: $1.0 > 2/3 \\implies \\text{Unstable (False)}$\n\nThe resulting sequence of booleans is [True, True, True, False, False, False].",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Determines the mean-square stability of the Euler-Maruyama and Milstein schemes\n    for a specific SDE at given timesteps.\n    \"\"\"\n    # Parameters for the SDE: dX = a*X*dt + b*X*dW\n    a = -2.0\n    b = 1.0\n\n    # Test suite of timesteps\n    test_cases = [0.1, 0.7, 1.0]\n\n    results = []\n    \n    # The mean-square stability condition for a scheme is that its one-step\n    # amplification factor R must be strictly less than 1.\n\n    for dt in test_cases:\n        # Euler-Maruyama stability analysis:\n        # The amplification factor is R_EM = (1 + a*dt)^2 + b^2*dt.\n        # The stability condition R_EM < 1 simplifies to:\n        # (1 - 2*dt)^2 + dt < 1\n        # 1 - 4*dt + 4*dt^2 + dt < 1\n        # 4*dt^2 - 3*dt < 0\n        # dt * (4*dt - 3) < 0\n        # Since dt > 0, the condition is 4*dt - 3 < 0.\n        em_stable = (4.0 * dt - 3.0) < 0\n        results.append(em_stable)\n\n        # Milstein stability analysis:\n        # The amplification factor is R_Mil = (1 + a*dt)^2 + b^2*dt + 0.5*b^4*dt^2.\n        # The stability condition R_Mil < 1 simplifies to:\n        # (1 - 2*dt)^2 + dt + 0.5*dt^2 < 1\n        # 1 - 4*dt + 4*dt^2 + dt + 0.5*dt^2 < 1\n        # 4.5*dt^2 - 3*dt < 0\n        # dt * (4.5*dt - 3) < 0\n        # Since dt > 0, the condition is 4.5*dt - 3 < 0.\n        mil_stable = (4.5 * dt - 3.0) < 0\n        results.append(mil_stable)\n\n    # Final print statement in the exact required format.\n    # The str() of a boolean is 'True' or 'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having seen that numerical stability is a critical consideration, we now move to a more rigorous and quantitative analysis. This practice delves into the concept of mean-square dissipativity, which concerns whether a numerical method can faithfully replicate the long-term statistical behavior of the true underlying process. By deriving the exact analytical thresholds for the step size $ h $ that ensure stability for the Ornstein-Uhlenbeck and Geometric Brownian Motion models , you will learn how to formally assess the long-term reliability of a numerical scheme, a fundamental skill for validating any quantitative model.",
            "id": "2988113",
            "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a standard Brownian motion on a filtered probability space satisfying the usual conditions. Consider two It\\^{o} stochastic differential equations (SDEs) with globally Lipschitz and linearly growing coefficients:\n1) The Ornstein–Uhlenbeck (OU) process defined by\n$$\n\\mathrm{d}X_{t} \\;=\\; -\\lambda X_{t}\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t},\n$$\nwith $\\lambda>0$, $\\sigma>0$, and initial condition $X_{0}$ satisfying $\\mathbb{E}[X_{0}^{2}]<\\infty$.\n2) The geometric Brownian motion (GBM) defined by\n$$\n\\mathrm{d}Y_{t} \\;=\\; \\mu Y_{t}\\,\\mathrm{d}t \\;+\\; \\sigma Y_{t}\\,\\mathrm{d}W_{t},\n$$\nwith $\\mu \\in \\mathbb{R}$, $\\sigma>0$, and initial condition $Y_{0}$ satisfying $\\mathbb{E}[Y_{0}^{2}]<\\infty$.\n\nLet $\\{t_{n}\\}_{n \\geq 0}$ denote a uniform grid with step size $h>0$, $t_{n}=nh$, and let $\\Delta W_{n}:=W_{t_{n+1}}-W_{t_{n}}$. Apply the one-step Milstein scheme to each SDE to obtain numerical approximations $\\{X_{n}\\}_{n \\geq 0}$ for the OU process and $\\{Y_{n}\\}_{n \\geq 0}$ for the GBM, with $X_{0}$ and $Y_{0}$ given.\n\nStarting from first principles of It\\^{o} calculus and the definition of the Milstein method, and using only well-tested facts about Gaussian increments (e.g., $\\mathbb{E}[\\Delta W_{n}]=0$, $\\mathbb{E}[(\\Delta W_{n})^{2}]=h$, $\\mathbb{E}[(\\Delta W_{n})^{3}]=0$, $\\mathbb{E}[(\\Delta W_{n})^{4}]=3h^{2}$), carry out the following:\n- Derive the exact second-moment evolution $\\mathbb{E}[X_{t}^{2}]$ for the OU process, and determine the stationary second-moment bound as $t \\to \\infty$. Derive the second-moment recursion for the Milstein discretization (which, for additive noise, coincides with the Euler–Maruyama scheme), establish the condition on $h$ under which $\\{\\mathbb{E}[X_{n}^{2}]\\}_{n \\geq 0}$ remains uniformly bounded, and determine the largest allowable step size $h_{\\star}^{\\mathrm{OU}}$ for which this uniform boundedness (mean-square dissipativity) holds.\n- Derive the exact second-moment evolution $\\mathbb{E}[Y_{t}^{2}]$ for the GBM and state the parameter regime in which the exact dynamics are mean-square dissipative. For the Milstein scheme applied to the GBM, derive the multiplicative second-moment amplification factor $r(h)$ defined by $\\mathbb{E}[Y_{n+1}^{2}]=r(h)\\,\\mathbb{E}[Y_{n}^{2}]$. From the mean-square dissipativity requirement $r(h)<1$, determine the largest allowable step size $h_{\\star}^{\\mathrm{GBM}}$ as an explicit function of $\\mu$ and $\\sigma$.\n\nExpress your final answer as a single closed-form analytical expression containing both thresholds $h_{\\star}^{\\mathrm{OU}}$ and $h_{\\star}^{\\mathrm{GBM}}$ arranged as a row matrix using the $\\mathrm{pmatrix}$ environment. No numerical approximation or rounding is required, and no units are to be included in the final answer.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in the field of numerical analysis for stochastic differential equations. We proceed with the solution.\n\nThe solution is presented in two parts, one for the Ornstein–Uhlenbeck (OU) process and one for the geometric Brownian motion (GBM), as requested.\n\n### Part 1: Ornstein–Uhlenbeck Process\n\nThe SDE for the OU process is given by:\n$$\n\\mathrm{d}X_{t} = -\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}\n$$\nwhere $\\lambda > 0$, $\\sigma > 0$, and $\\mathbb{E}[X_{0}^{2}] < \\infty$.\n\n**Exact Second-Moment Evolution**\nTo find the evolution of the second moment, $\\mathbb{E}[X_{t}^{2}]$, we apply Itō's lemma to the function $f(x) = x^{2}$. The derivatives are $f'(x)=2x$ and $f''(x)=2$. Itō's lemma states that for a process $X_t$ and a twice-differentiable function $f$,\n$$\n\\mathrm{d}f(X_{t}) = f'(X_{t})\\,\\mathrm{d}X_{t} + \\frac{1}{2}f''(X_{t})\\,(\\mathrm{d}X_{t})^{2}.\n$$\nSubstituting the SDE for $\\mathrm{d}X_{t}$, we get:\n$$\n\\mathrm{d}(X_{t}^{2}) = 2X_{t}(-\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}) + \\frac{1}{2}(2)(-\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t})^{2}.\n$$\nAccording to Itō calculus rules, $(\\mathrm{d}t)^{2}=0$, $\\mathrm{d}t\\,\\mathrm{d}W_{t}=0$, and $(\\mathrm{d}W_{t})^{2}=\\mathrm{d}t$. Thus, the quadratic variation term is $(\\mathrm{d}X_{t})^{2} = \\sigma^{2}(\\mathrm{d}W_{t})^{2} = \\sigma^{2}\\mathrm{d}t$.\nThe expression for $\\mathrm{d}(X_{t}^{2})$ becomes:\n$$\n\\mathrm{d}(X_{t}^{2}) = -2\\lambda X_{t}^{2}\\,\\mathrm{d}t + 2\\sigma X_{t}\\,\\mathrm{d}W_{t} + \\sigma^{2}\\,\\mathrm{d}t.\n$$\nLet $m_{2}(t) = \\mathbb{E}[X_{t}^{2}]$. Taking the expectation of the integral form of the above equation, and noting that the expectation of the Itō integral term is zero (i.e., $\\mathbb{E}[\\int_{0}^{t} 2\\sigma X_{s}\\,\\mathrm{d}W_{s}]=0$ since $X_s$ is adapted), we obtain an ordinary differential equation (ODE) for $m_{2}(t)$:\n$$\n\\frac{\\mathrm{d}m_{2}(t)}{\\mathrm{d}t} = \\mathbb{E}[-2\\lambda X_{t}^{2} + \\sigma^{2}] = -2\\lambda m_{2}(t) + \\sigma^{2}.\n$$\nThis is a first-order linear ODE, $m'_{2}(t) + 2\\lambda m_{2}(t) = \\sigma^{2}$. The solution with initial condition $m_{2}(0) = \\mathbb{E}[X_{0}^{2}]$ is:\n$$\nm_{2}(t) = \\frac{\\sigma^{2}}{2\\lambda} + \\left(\\mathbb{E}[X_{0}^{2}] - \\frac{\\sigma^{2}}{2\\lambda}\\right)\\exp(-2\\lambda t).\n$$\nAs $t \\to \\infty$, since $\\lambda > 0$, the exponential term decays to zero. The stationary second-moment bound is:\n$$\n\\lim_{t \\to \\infty} \\mathbb{E}[X_{t}^{2}] = \\frac{\\sigma^{2}}{2\\lambda}.\n$$\n\n**Milstein Discretization and Mean-Square Stability**\nThe general one-step Milstein scheme for an SDE $\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + b(X_{t})\\,\\mathrm{d}W_{t}$ is:\n$$\nX_{n+1} = X_{n} + a(X_n)h + b(X_n)\\Delta W_n + \\frac{1}{2}b(X_n)b'(X_n)((\\Delta W_n)^2 - h).\n$$\nFor the OU process, we have $a(x) = -\\lambda x$ and $b(x) = \\sigma$. Since $b(x)$ is a constant, its derivative $b'(x) = 0$. Therefore, the Milstein scheme simplifies to the Euler–Maruyama scheme:\n$$\nX_{n+1} = X_{n} - \\lambda X_{n} h + \\sigma \\Delta W_{n} = (1 - \\lambda h)X_{n} + \\sigma \\Delta W_{n}.\n$$\nTo find the second-moment recursion, we square both sides:\n$$\nX_{n+1}^{2} = ((1 - \\lambda h)X_{n} + \\sigma \\Delta W_{n})^{2} = (1 - \\lambda h)^{2}X_{n}^{2} + 2\\sigma(1 - \\lambda h)X_{n}\\Delta W_{n} + \\sigma^{2}(\\Delta W_{n})^{2}.\n$$\nLet $\\mathcal{M}_{n} = \\mathbb{E}[X_{n}^{2}]$. We take the expectation, conditional on the information at time $t_{n}$, denoted by $\\mathcal{F}_{t_{n}}$. Since $X_n$ is $\\mathcal{F}_{t_{n}}$-measurable and $\\Delta W_n$ is independent of $\\mathcal{F}_{t_{n}}$, we use the provided facts $\\mathbb{E}[\\Delta W_{n}] = 0$ and $\\mathbb{E}[(\\Delta W_{n})^{2}] = h$:\n$$\n\\mathbb{E}[X_{n+1}^{2} | \\mathcal{F}_{t_{n}}] = (1 - \\lambda h)^{2}X_{n}^{2} + 2\\sigma(1 - \\lambda h)X_{n}\\mathbb{E}[\\Delta W_{n}] + \\sigma^{2}\\mathbb{E}[(\\Delta W_{n})^{2}] = (1 - \\lambda h)^{2}X_{n}^{2} + \\sigma^{2}h.\n$$\nTaking the full expectation gives the recursion for $\\mathcal{M}_{n}$:\n$$\n\\mathcal{M}_{n+1} = (1 - \\lambda h)^{2}\\mathcal{M}_{n} + \\sigma^{2}h.\n$$\nFor the sequence $\\{\\mathcal{M}_{n}\\}_{n \\ge 0}$ to remain uniformly bounded for any finite initial second moment $\\mathcal{M}_{0}$, the recurrence must be stable. This requires the magnitude of the amplification factor of the homogeneous part to be strictly less than $1$. If the magnitude were equal to $1$, $\\mathcal{M}_{n}$ would grow arithmetically, and thus would not be uniformly bounded. The condition is:\n$$\n|1 - \\lambda h| < 1.\n$$\nThis inequality is equivalent to $-1 < 1 - \\lambda h < 1$.\nThe right-hand side, $1 - \\lambda h < 1$, implies $-\\lambda h < 0$. Since $\\lambda > 0$ and $h > 0$, this is always satisfied.\nThe left-hand side, $-1 < 1 - \\lambda h$, implies $\\lambda h < 2$.\nThus, the condition for uniform boundedness is $h < \\frac{2}{\\lambda}$. The largest allowable step size is the supremum of this set, which is:\n$$\nh_{\\star}^{\\mathrm{OU}} = \\frac{2}{\\lambda}.\n$$\n\n### Part 2: Geometric Brownian Motion\n\nThe SDE for GBM is given by:\n$$\n\\mathrm{d}Y_{t} = \\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t}\n$$\nwhere $\\mu \\in \\mathbb{R}$, $\\sigma > 0$, and $\\mathbb{E}[Y_{0}^{2}] < \\infty$.\n\n**Exact Second-Moment Evolution**\nWe again apply Itō's lemma to $f(y) = y^{2}$, so $f'(y)=2y$ and $f''(y)=2$.\n$$\n\\mathrm{d}(Y_{t}^{2}) = 2Y_{t}(\\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t}) + \\frac{1}{2}(2)(\\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t})^{2}.\n$$\nThe quadratic variation term is $(\\mathrm{d}Y_{t})^{2} = \\sigma^{2}Y_{t}^{2}(\\mathrm{d}W_{t})^{2} = \\sigma^{2}Y_{t}^{2}\\mathrm{d}t$.\nSubstituting this, we get:\n$$\n\\mathrm{d}(Y_{t}^{2}) = 2\\mu Y_{t}^{2}\\,\\mathrm{d}t + 2\\sigma Y_{t}^{2}\\,\\mathrm{d}W_{t} + \\sigma^{2}Y_{t}^{2}\\mathrm{d}t = (2\\mu + \\sigma^{2})Y_{t}^{2}\\,\\mathrm{d}t + 2\\sigma Y_{t}^{2}\\,\\mathrm{d}W_{t}.\n$$\nLet $m_{2}(t) = \\mathbb{E}[Y_{t}^{2}]$. Taking the expectation, the Itō integral term vanishes, and we obtain the ODE:\n$$\n\\frac{\\mathrm{d}m_{2}(t)}{\\mathrm{d}t} = (2\\mu + \\sigma^{2})m_{2}(t).\n$$\nThe solution is $m_{2}(t) = m_{2}(0)\\exp((2\\mu + \\sigma^{2})t)$. For the exact dynamics to be mean-square dissipative, the second moment must decay to zero as $t \\to \\infty$. This requires the exponent to be negative. The parameter regime is:\n$$\n2\\mu + \\sigma^{2} < 0.\n$$\n\n**Milstein Discretization and Mean-Square Stability**\nFor GBM, we have $a(y) = \\mu y$ and $b(y) = \\sigma y$, so $b'(y) = \\sigma$. The Milstein scheme is:\n$$\n\\begin{aligned}\nY_{n+1} &= Y_{n} + \\mu Y_{n}h + \\sigma Y_{n}\\Delta W_{n} + \\frac{1}{2}(\\sigma Y_{n})(\\sigma)((\\Delta W_{n})^{2} - h) \\\\\n&= Y_{n}\\left[1 + \\mu h + \\sigma \\Delta W_{n} + \\frac{1}{2}\\sigma^{2}((\\Delta W_{n})^{2} - h)\\right].\n\\end{aligned}\n$$\nThe problem defines the multiplicative amplification factor $r(h)$ via $\\mathbb{E}[Y_{n+1}^{2}] = r(h)\\mathbb{E}[Y_{n}^{2}]$. By the tower property and independence of $\\Delta W_n$ from $\\mathcal{F}_{t_n}$, we have:\n$$\nr(h) = \\mathbb{E}\\left[\\left(1 + \\mu h - \\frac{1}{2}\\sigma^{2}h + \\sigma\\Delta W_{n} + \\frac{1}{2}\\sigma^{2}(\\Delta W_{n})^{2}\\right)^{2}\\right].\n$$\nLet $C = 1 + \\mu h - \\frac{1}{2}\\sigma^{2}h$ and $Z_{n} = \\Delta W_{n}$. We need to compute $\\mathbb{E}[(C + \\sigma Z_{n} + \\frac{1}{2}\\sigma^{2}Z_{n}^{2})^{2}]$.\nExpanding the square:\n$$\n(C + \\sigma Z_{n} + \\frac{1}{2}\\sigma^{2}Z_{n}^{2})^{2} = C^{2} + \\sigma^{2}Z_{n}^{2} + \\frac{1}{4}\\sigma^{4}Z_{n}^{4} + 2C\\sigma Z_{n} + C\\sigma^{2}Z_{n}^{2} + \\sigma^{3}Z_{n}^{3}.\n$$\nTaking the expectation and using the given moments $\\mathbb{E}[Z_n]=0$, $\\mathbb{E}[Z_n^2]=h$, $\\mathbb{E}[Z_n^3]=0$, $\\mathbb{E}[Z_n^4]=3h^2$:\n$$\n\\begin{aligned}\nr(h) &= \\mathbb{E}[C^{2}] + \\sigma^{2}\\mathbb{E}[Z_{n}^{2}] + \\frac{1}{4}\\sigma^{4}\\mathbb{E}[Z_{n}^{4}] + 2C\\sigma\\mathbb{E}[Z_{n}] + C\\sigma^{2}\\mathbb{E}[Z_{n}^{2}] + \\sigma^{3}\\mathbb{E}[Z_{n}^{3}] \\\\\n&= C^{2} + \\sigma^{2}h + \\frac{1}{4}\\sigma^{4}(3h^{2}) + 0 + C\\sigma^{2}h + 0 \\\\\n&= C^{2} + (1+C)\\sigma^{2}h + \\frac{3}{4}\\sigma^{4}h^{2}.\n\\end{aligned}\n$$\nSubstituting $C = 1 + (\\mu - \\frac{1}{2}\\sigma^{2})h$:\n$C^{2} = (1 + (\\mu - \\frac{1}{2}\\sigma^{2})h)^{2} = 1 + 2(\\mu - \\frac{1}{2}\\sigma^{2})h + (\\mu - \\frac{1}{2}\\sigma^{2})^{2}h^{2}$.\n$1+C = 2 + (\\mu - \\frac{1}{2}\\sigma^{2})h$.\nSo, $(1+C)\\sigma^{2}h = 2\\sigma^{2}h + (\\mu - \\frac{1}{2}\\sigma^{2})\\sigma^{2}h^{2}$.\nSumming all terms for $r(h)$:\n$$\n\\begin{aligned}\nr(h) &= \\left(1 + (2\\mu - \\sigma^{2})h + (\\mu^{2}-\\mu\\sigma^{2}+\\frac{1}{4}\\sigma^{4})h^{2}\\right) + \\left(2\\sigma^{2}h + (\\mu\\sigma^{2}-\\frac{1}{2}\\sigma^{4})h^{2}\\right) + \\frac{3}{4}\\sigma^{4}h^{2} \\\\\n&= 1 + (2\\mu - \\sigma^{2} + 2\\sigma^{2})h + (\\mu^{2}-\\mu\\sigma^{2}+\\frac{1}{4}\\sigma^{4} + \\mu\\sigma^{2}-\\frac{1}{2}\\sigma^{4} + \\frac{3}{4}\\sigma^{4})h^{2} \\\\\n&= 1 + (2\\mu + \\sigma^{2})h + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h^{2}.\n\\end{aligned}\n$$\nThe mean-square dissipativity requirement is $r(h) < 1$:\n$$\n1 + (2\\mu + \\sigma^{2})h + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h^{2} < 1.\n$$\nFor $h > 0$, this simplifies to:\n$$\n(2\\mu + \\sigma^{2}) + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h < 0.\n$$\nFor this inequality to have a solution for $h > 0$, we must have the constant term negative, since the term with $h$ has a positive coefficient $(\\mu^{2} + \\frac{1}{2}\\sigma^{4}) > 0$. This implies $2\\mu + \\sigma^{2} < 0$, which is exactly the dissipativity condition for the continuous SDE.\nUnder this condition, we solve for $h$:\n$$\n(\\mu^{2} + \\frac{1}{2}\\sigma^{4})h < -(2\\mu + \\sigma^{2}).\n$$\n$$\nh < \\frac{-(2\\mu + \\sigma^{2})}{\\mu^{2} + \\frac{1}{2}\\sigma^{4}}.\n$$\nThe largest allowable step size is the supremum of this interval:\n$$\nh_{\\star}^{\\mathrm{GBM}} = \\frac{-(2\\mu + \\sigma^{2})}{\\mu^{2} + \\frac{1}{2}\\sigma^{4}}.\n$$\nThis threshold is valid only in the parameter regime $2\\mu+\\sigma^2 < 0$. Otherwise, no step size $h>0$ can ensure mean-square dissipativity for the Milstein method.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{\\lambda} & \\frac{-(2\\mu + \\sigma^2)}{\\mu^2 + \\frac{1}{2}\\sigma^4}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}