{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex parallel code, it is crucial to understand the theoretical ceiling on performance gains. Amdahl's Law provides this vital perspective, revealing how the inherently sequential portion of any task imposes a strict limit on the maximum achievable speedup, regardless of how many processors are used. This exercise  applies this fundamental law to a realistic financial stress-testing scenario, allowing you to calculate the performance bottleneck imposed by a serial data-gathering stage.",
            "id": "2417876",
            "problem": "A central bank runs a large-scale macro-financial stress testing pipeline with $2$ stages: a data-gathering and cleaning stage that is strictly sequential, and a Monte Carlo simulation stage that can be perfectly parallelized across independent scenarios with negligible overhead. On a single-core baseline, the simulation stage accounts for $0.99$ of the total runtime. Let the speedup be defined as the ratio of the single-core runtime to the runtime on a machine with $N$ identical cores, when only the simulation stage is parallelized and the sequential stage remains strictly serial. In the limit as $N \\to \\infty$, what is the theoretical maximum speedup relative to the single-core baseline? Provide the answer as an exact number with no units.",
            "solution": "The problem as stated will be validated before any attempt at a solution is made.\n\nFirst, we extract the given information verbatim.\n1.  The process consists of $2$ stages: a strictly sequential data-gathering stage and a perfectly parallelizable Monte Carlo simulation stage.\n2.  The fraction of the total single-core runtime corresponding to the parallelizable simulation stage is $0.99$. Let this fraction be denoted by $P$. Therefore, $P = 0.99$.\n3.  The speedup, $S(N)$, is defined as the ratio of the single-core runtime to the runtime on a machine with $N$ identical cores.\n4.  The objective is to find the theoretical maximum speedup in the limit as the number of cores $N$ approaches infinity.\n\nSecond, we validate the problem. The problem is a straightforward application of Amdahl's Law, a fundamental concept in parallel computing. The scenario described is a classic and realistic model for computational pipelines in scientific and engineering domains, including computational finance. The problem is self-contained, scientifically grounded, and well-posed. All terms are clearly defined, and no information is missing or contradictory. Therefore, the problem is deemed valid and a solution will be formulated.\n\nThe solution proceeds from the principles of Amdahl's Law. Let $T_1$ be the total runtime on a single core. This total time can be decomposed into a sequential part and a parallelizable part.\n\nThe fraction of the task that is strictly sequential is $1 - P$. The time taken by this part is $T_{seq} = (1 - P) T_1$.\nThe fraction of the task that is parallelizable is $P$. The time taken by this part on a single core is $T_{par} = P T_1$.\n\nGiven from the problem statement, $P = 0.99$.\nThus, the sequential fraction is $1 - P = 1 - 0.99 = 0.01$.\n\nWhen the task is run on a system with $N$ cores, the sequential part of the task remains unchanged, taking time $T_{seq}$. The parallelizable part, however, is distributed across the $N$ cores. Assuming perfect parallelization with negligible overhead, the time for this part becomes $\\frac{T_{par}}{N}$.\n\nThe total runtime on $N$ cores, $T(N)$, is the sum of the execution times of the two parts:\n$$T(N) = T_{seq} + \\frac{T_{par}}{N} = (1 - P) T_1 + \\frac{P T_1}{N}$$\n\nThe speedup $S(N)$ is defined as the ratio of the single-core runtime to the $N$-core runtime:\n$$S(N) = \\frac{T_1}{T(N)} = \\frac{T_1}{(1 - P) T_1 + \\frac{P T_1}{N}}$$\n\nThe term $T_1$ is a common factor in the numerator and denominator and can be cancelled, which is expected as speedup is a relative measure:\n$$S(N) = \\frac{1}{(1 - P) + \\frac{P}{N}}$$\n\nThe problem asks for the theoretical maximum speedup, which is achieved in the limit as the number of cores $N$ approaches infinity. We must evaluate the limit of $S(N)$ as $N \\to \\infty$.\n$$S_{max} = \\lim_{N \\to \\infty} S(N) = \\lim_{N \\to \\infty} \\frac{1}{(1 - P) + \\frac{P}{N}}$$\n\nAs $N \\to \\infty$, the term $\\frac{P}{N}$ approaches $0$, because $P$ is a finite constant.\n$$\\lim_{N \\to \\infty} \\frac{P}{N} = 0$$\n\nTherefore, the limit of the speedup function is:\n$$S_{max} = \\frac{1}{(1 - P) + 0} = \\frac{1}{1 - P}$$\n\nThis result is the core statement of Amdahl's Law: the maximum speedup is limited by the sequential fraction of the code.\n\nSubstituting the given value $P = 0.99$ into the expression for maximum speedup:\n$$S_{max} = \\frac{1}{1 - 0.99} = \\frac{1}{0.01}$$\n\nEvaluating this expression gives the final answer.\n$$S_{max} = 100$$\nThis is the theoretical maximum speedup for the given pipeline, irrespective of how many more processors are added beyond a certain point. The performance is fundamentally bottlenecked by the $1\\%$ of the work that must be done sequentially.",
            "answer": "$$\n\\boxed{100}\n$$"
        },
        {
            "introduction": "Many economic models, such as Cournot competition, are built on the premise of simultaneous decision-making by rational agents. When we implement these models using parallel threads to represent the agents, we must employ synchronization primitives to enforce this simultaneity and ensure our simulation is a faithful representation of the theory. This practice  demonstrates the critical role of a barrier in correctly modeling a duopoly, contrasting a synchronized simulation with an unsynchronized one to reveal the significant modeling errors that can otherwise arise.",
            "id": "2417917",
            "problem": "You are asked to write a complete, runnable program that models a Cournot duopoly where two firms simultaneously choose quantities in discrete time steps using two separate threads. The program must demonstrate that to correctly model discrete time steps indexed by $t \\in \\{0,1,2,\\dots\\}$ as simultaneous decisions, a barrier synchronization is required so that both firms update from the same state at step $t$ and commit their updates simultaneously to step $t+1$. You will compare a synchronized simulation that uses a barrier with an intentionally unsynchronized sequential-updating simulation that does not impose a simultaneous-read constraint, highlighting the modeling error in the latter.\n\nFundamental base and core definitions to be used:\n- Let the inverse demand be $P(Q) = a - b Q$, where $a > 0$, $b > 0$, total quantity is $Q = q_1 + q_2$, and firm $i$ has constant marginal cost $c_i \\ge 0$. Profit for firm $i$ is $\\pi_i(q_i,q_j) = \\left(P(q_i+q_j) - c_i\\right) q_i$.\n- In Cournot competition, at any time step $t$, each firm $i$ chooses $q_i^{t+1}$ to maximize its profit given the rival's quantity at time $t$. There is a nonnegativity constraint $q_i^{t+1} \\ge 0$.\n- The step update intended by discrete-time simultaneous play is that both firms compute $q_i^{t+1}$ using only information from step $t$, and then commit $q^{t+1}$ atomically. This requires barrier synchronization between the threads to ensure that both firms read the same past state and that their writes are committed at the same discrete time boundary.\n- In contrast, without a barrier to enforce simultaneous read and commit, one thread can update earlier and the other thread may read a partially updated state, thus violating the intended model of simultaneous decisions at the boundary between $t$ and $t+1$.\n\nYour program must:\n1. From first principles, derive and implement the unique best response $BR_i(q_j)$ for firm $i$ given $q_j$ by maximizing $\\pi_i(q_i,q_j)$ subject to $q_i \\ge 0$. Use the derived $BR_i(q_j)$ in all updates.\n2. Implement two-thread simulations for $T$ discrete steps starting from given initial quantities $(q_1^0,q_2^0)$:\n   - Synchronous simulation with a barrier: Two threads represent firms. At each step $t$, both compute $q_i^{t+1} = BR_i(q_j^t)$ using only $(q_1^t,q_2^t)$ and commit the pair $(q_1^{t+1},q_2^{t+1})$ atomically at the barrier so that both read exactly the same state from step $t$.\n   - Unsynchronized sequential simulation without a barrier: Two threads represent firms but do not coordinate a simultaneous read. Within each step, enforce a deterministic sequential update order: firm $1$ updates first using $q_2^t$, and immediately writes $q_1^{t+1}$; then firm $2$ reads this updated $q_1^{t+1}$ and writes $q_2^{t+1}$. This construction intentionally violates simultaneous decisions to illustrate the modeling error in the absence of a barrier.\n3. Compute the static Nash equilibrium $(q_1^\\star,q_2^\\star)$ consistent with $q_i \\ge 0$ by solving for the Cournot equilibrium under nonnegativity constraints. If the unconstrained equilibrium yields $q_i^\\star \\ge 0$ for both $i$, use the interior solution. If one unconstrained $q_i^\\star$ is negative, enforce the corner case by setting that $q_i^\\star = 0$ and recomputing the other firm’s best response to this zero; if both are negative, set $(q_1^\\star,q_2^\\star) = (0,0)$.\n4. For each test case, run both simulations for the specified number of steps $T$, starting from the specified initial state. Then compute and report:\n   - The maximum absolute difference between the synchronous and unsynchronized final quantities at step $T$:\n     $$ d = \\max\\left\\{ \\left| q_1^{T,\\mathrm{sync}} - q_1^{T,\\mathrm{unsync}} \\right|, \\left| q_2^{T,\\mathrm{sync}} - q_2^{T,\\mathrm{unsync}} \\right| \\right\\}. $$\n   - The Euclidean norm of the synchronous final state’s error relative to the static equilibrium:\n     $$ e_{\\mathrm{sync}} = \\sqrt{\\left(q_1^{T,\\mathrm{sync}} - q_1^\\star\\right)^2 + \\left(q_2^{T,\\mathrm{sync}} - q_2^\\star\\right)^2}. $$\n   - The Euclidean norm of the unsynchronized final state’s error relative to the static equilibrium:\n     $$ e_{\\mathrm{unsync}} = \\sqrt{\\left(q_1^{T,\\mathrm{unsync}} - q_1^\\star\\right)^2 + \\left(q_2^{T,\\mathrm{unsync}} - q_2^\\star\\right)^2}. $$\n\nTest suite to cover different facets:\n- Case A (happy path; symmetric costs; single step difference is most pronounced): $a = 100$, $b = 1$, $c_1 = 10$, $c_2 = 10$, $T = 1$, initial $(q_1^0,q_2^0) = (0,0)$.\n- Case B (asymmetric costs; multiple steps; interior equilibrium): $a = 90$, $b = 1.5$, $c_1 = 10$, $c_2 = 30$, $T = 5$, initial $(q_1^0,q_2^0) = (0,0)$.\n- Case C (boundary case with nonnegativity constraint binding for one firm): $a = 40$, $b = 2$, $c_1 = 50$, $c_2 = 4$, $T = 3$, initial $(q_1^0,q_2^0) = (0,0)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists, each inner list corresponding to a test case and containing the three floating-point values $[d, e_{\\mathrm{sync}}, e_{\\mathrm{unsync}}]$ in that exact order. The output must be printed as a single line in the format\n  \"[[d_A,e_sync_A,e_unsync_A],[d_B,e_sync_B,e_unsync_B],[d_C,e_sync_C,e_unsync_C]]\"\n  where each floating-point number should be rendered in fixed-point with six digits after the decimal point. No extra text should be printed.\nNo physical units are involved. All angles, if any, are not applicable. All ratios must be expressed as decimals.",
            "solution": "The problem statement is subjected to validation and is found to be valid. It is scientifically grounded in established economic theory (Cournot competition) and computational science (parallel synchronization). The problem is well-posed, with all necessary parameters and definitions provided for a unique, verifiable solution. There are no contradictions, ambiguities, or factual inaccuracies. We may therefore proceed with a formal solution.\n\nThe core of the problem is to model a discrete-time Cournot duopoly. First, we must derive the best response function for each firm, which defines its optimal quantity choice given its rival's output.\n\nA firm $i$'s profit, $\\pi_i$, is given by its revenue minus its costs:\n$$ \\pi_i(q_i, q_j) = P(Q)q_i - c_i q_i $$\nwhere $Q = q_i + q_j$, the inverse demand is $P(Q) = a - b Q$, and $c_i$ is the constant marginal cost. Substituting the demand function, we have:\n$$ \\pi_i(q_i, q_j) = (a - b(q_i + q_j) - c_i)q_i = aq_i - bq_i^2 - bq_j q_i - c_i q_i $$\nTo find the quantity $q_i$ that maximizes this profit, we take the first-order partial derivative with respect to $q_i$ and set it to zero, which is the first-order condition for a maximum:\n$$ \\frac{\\partial \\pi_i}{\\partial q_i} = a - 2bq_i - bq_j - c_i = 0 $$\nSolving for $q_i$ yields the unconstrained reaction function:\n$$ 2bq_i = a - c_i - bq_j \\implies q_i = \\frac{a - c_i - bq_j}{2b} $$\nThe second-order condition for a maximum is satisfied, as $\\frac{\\partial^2 \\pi_i}{\\partial q_i^2} = -2b < 0$ since it is given that $b > 0$. However, firms cannot produce a negative quantity, so we must enforce the nonnegativity constraint $q_i \\ge 0$. The best response function $BR_i(q_j)$ is therefore:\n$$ BR_i(q_j) = \\max\\left\\{0, \\frac{a - c_i - bq_j}{2b}\\right\\} $$\n\nNext, we determine the static Cournot-Nash equilibrium $(q_1^\\star, q_2^\\star)$, which is the stable state where neither firm has an incentive to unilaterally change its output. This occurs when both firms are on their best response curves simultaneously, i.e., $q_1^\\star = BR_1(q_2^\\star)$ and $q_2^\\star = BR_2(q_1^\\star)$.\nAssuming an interior solution where $q_1^\\star > 0$ and $q_2^\\star > 0$, we solve the system of linear equations:\n$$ q_1^\\star = \\frac{a - c_1 - bq_2^\\star}{2b} $$\n$$ q_2^\\star = \\frac{a - c_2 - bq_1^\\star}{2b} $$\nSubstituting the expression for $q_2^\\star$ into the first equation and solving for $q_1^\\star$ yields:\n$$ q_1^\\star = \\frac{a - 2c_1 + c_2}{3b} $$\nBy symmetry, the equilibrium quantity for firm $2$ is:\n$$ q_2^\\star = \\frac{a - 2c_2 + c_1}{3b} $$\nIf these formulas yield a negative quantity for a firm, e.g., $q_i^\\star < 0$, its equilibrium output must be at the boundary, i.e., $q_i^\\star = 0$. The other firm, $j$, will then react to this zero output: $q_j^\\star = BR_j(0) = \\max\\{0, (a-c_j)/(2b)\\}$. If both unconstrained quantities are negative, the equilibrium is $(q_1^\\star, q_2^\\star) = (0,0)$.\n\nThe problem requires a comparison of two dynamic simulation models over $T$ time steps, from an initial state $(q_1^0, q_2^0)$. Both models are implemented using two threads, one for each firm.\n\n$1$. **Synchronous Simulation**: This correctly models the simultaneous-move nature of Cournot competition in discrete time. At each step $t$, both firms must decide their quantity for step $t+1$ based on the *same* information, which is the state of the market at step $t$, namely $(q_1^t, q_2^t)$.\n$$ q_1^{t+1} = BR_1(q_2^t) $$\n$$ q_2^{t+1} = BR_2(q_1^t) $$\nTo enforce this in a multi-threaded program, a synchronization barrier is necessary. The threads compute their next quantities based on the shared state at time $t$. They then wait at a barrier. After all threads have reached the barrier, the new quantities for step $t+1$ are committed to the shared state. This ensures that no thread can read a partially updated state from step $t+1$ while computing its own value for $t+1$. This is a computational analogue of the Jacobi method for solving linear systems.\n\n$2$. **Unsynchronized Sequential Simulation**: This simulation intentionally introduces a modeling error by omitting the synchronization barrier. It imposes a deterministic update order: firm $1$ updates first, and firm $2$ follows.\n$$ q_1^{t+1} = BR_1(q_2^t) $$\n$$ q_2^{t+1} = BR_2(q_1^{t+1}) $$\nHere, firm $2$'s decision for step $t+1$ is based on firm $1$'s quantity for step $t+1$, not $t$. This violates the principle of simultaneous moves. It models a sequential-move dynamic where firm $1$ is a leader and firm $2$ is a follower within each time step. This corresponds to the Gauss-Seidel method. The discrepancy between this simulation's trajectory and the synchronous one's highlights the critical importance of proper synchronization in modeling parallel or simultaneous events.\n\nThe program will implement these two simulations, calculate the specified metrics ($d$, $e_{\\mathrm{sync}}$, $e_{\\mathrm{unsync}}$) for the given test cases, and demonstrate the divergence caused by the modeling error in the unsynchronized case. The implementation of the synchronous model will use the `threading` module with a `Barrier` to correctly model the simultaneous-read-then-simultaneous-commit logic.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport threading\nfrom collections import namedtuple\n\n# Define data structure for problem parameters\nCaseParams = namedtuple('CaseParams', ['a', 'b', 'c1', 'c2', 'T', 'q0'])\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path, symmetric costs\n        CaseParams(a=100.0, b=1.0, c1=10.0, c2=10.0, T=1, q0=np.array([0.0, 0.0])),\n        # Case B: Asymmetric costs, multiple steps\n        CaseParams(a=90.0, b=1.5, c1=10.0, c2=30.0, T=5, q0=np.array([0.0, 0.0])),\n        # Case C: Boundary case, non-negativity constraint binding\n        CaseParams(a=40.0, b=2.0, c1=50.0, c2=4.0, T=3, q0=np.array([0.0, 0.0])),\n    ]\n\n    results = []\n    for params in test_cases:\n        results.append(solve_case(params))\n\n    # Format the final output string as specified\n    formatted_results = [\n        f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\" for res in results\n    ]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef best_response(q_other, a, b, c):\n    \"\"\"\n    Calculates the best response for a firm given the other's quantity.\n    BR_i(q_j) = max(0, (a - c_i - b*q_j) / (2*b))\n    \"\"\"\n    num = a - c - b * q_other\n    den = 2.0 * b\n    return max(0.0, num / den)\n\ndef calculate_nash_equilibrium(params):\n    \"\"\"\n    Calculates the static Cournot-Nash equilibrium quantities.\n    Handles both interior and corner solutions.\n    \"\"\"\n    a, b, c1, c2 = params.a, params.b, params.c1, params.c2\n    \n    # Calculate unconstrained interior solution\n    q1_star_unconstrained = (a - 2.0 * c1 + c2) / (3.0 * b)\n    q2_star_unconstrained = (a - 2.0 * c2 + c1) / (3.0 * b)\n\n    if q1_star_unconstrained >= 0 and q2_star_unconstrained >= 0:\n        return np.array([q1_star_unconstrained, q2_star_unconstrained])\n    \n    # Handle corner solutions\n    q1_star, q2_star = 0.0, 0.0\n    if q1_star_unconstrained  0 and q2_star_unconstrained  0:\n        # If both would be negative, both produce 0\n        q1_star, q2_star = 0.0, 0.0\n    elif q1_star_unconstrained  0:\n        # Firm 1 is non-competitive, check firm 2's monopoly power\n        q1_star = 0.0\n        q2_star = best_response(0.0, a, b, c2)\n    elif q2_star_unconstrained  0:\n        # Firm 2 is non-competitive, check firm 1's monopoly power\n        q2_star = 0.0\n        q1_star = best_response(0.0, a, b, c1)\n\n    return np.array([q1_star, q2_star])\n\ndef simulate_synchronized(params):\n    \"\"\"\n    Performs the synchronous simulation using two threads and a barrier.\n    This correctly models simultaneous moves.\n    \"\"\"\n    q_state = [params.q0.copy(), np.zeros(2)] # Double buffer for current and next state\n    read_idx, write_idx = 0, 1\n    \n    barrier = threading.Barrier(2)\n\n    def firm_worker(firm_id):\n        nonlocal read_idx, write_idx\n        my_c = params.c1 if firm_id == 0 else params.c2\n        other_firm_id = 1 - firm_id\n\n        for _ in range(params.T):\n            # Read from the same state (t)\n            q_other = q_state[read_idx][other_firm_id]\n            \n            # Compute own next quantity for state (t+1)\n            my_next_q = best_response(q_other, params.a, params.b, my_c)\n            q_state[write_idx][firm_id] = my_next_q\n            \n            # Wait at barrier for other firm to finish its calculation\n            barrier.wait()\n            \n            # One thread swaps buffers for the next iteration\n            if firm_id == 0:\n                read_idx, write_idx = write_idx, read_idx\n            \n            # Second barrier to ensure buffers are swapped before next read starts\n            barrier.wait()\n\n    thread1 = threading.Thread(target=firm_worker, args=(0,))\n    thread2 = threading.Thread(target=firm_worker, args=(1,))\n    \n    thread1.start()\n    thread2.start()\n    \n    thread1.join()\n    thread2.join()\n    \n    return q_state[read_idx]\n\ndef simulate_unsynchronized(params):\n    \"\"\"\n    Performs the unsynchronized sequential simulation.\n    This demonstrates the modeling error from lack of synchronization.\n    \"\"\"\n    q = params.q0.copy()\n    a, b, c1, c2, T = params.a, params.b, params.c1, params.c2, params.T\n    \n    for _ in range(T):\n        # Firm 1 updates first, based on q from step t\n        q1_next = best_response(q[1], a, b, c1)\n        q[0] = q1_next\n        \n        # Firm 2 updates second, based on the *new* q1 from step t+1\n        q2_next = best_response(q[0], a, b, c2)\n        q[1] = q2_next\n        \n    return q\n\ndef solve_case(params):\n    \"\"\"\n    Solves a single test case: calculates equilibrium, runs simulations,\n    and computes the required output metrics.\n    \"\"\"\n    q_star = calculate_nash_equilibrium(params)\n    \n    q_sync_final = simulate_synchronized(params)\n    q_unsync_final = simulate_unsynchronized(params)\n\n    # Calculate metrics\n    d = np.max(np.abs(q_sync_final - q_unsync_final))\n    e_sync = np.linalg.norm(q_sync_final - q_star)\n    e_unsync = np.linalg.norm(q_unsync_final - q_star)\n    \n    return d, e_sync, e_unsync\n\n# Run the solver\nsolve()\n\n```"
        },
        {
            "introduction": "Writing correct parallel code is only half the battle; achieving high performance requires understanding how software interacts with the underlying hardware. This exercise  explores \"false sharing,\" a subtle but potent performance pitfall where logically independent tasks interfere with each other simply because their data happens to reside on the same CPU cache line. By modeling and quantifying the slowdown in a simple household simulation, you will develop an intuition for memory layout considerations that are crucial for writing efficient parallel programs.",
            "id": "2417854",
            "problem": "You are given a simplified, first-principles model of \"false sharing\" in a parallel simulation of a one-dimensional grid of households. A total of $N$ households are indexed $h_0,h_1,\\dots,h_{N-1}$ and laid out contiguously in memory. The memory system uses cache lines that can each hold exactly $L$ households, so the cache-line identifier of household $h_i$ is $\\ell(i)=\\left\\lfloor i/L \\right\\rfloor$. There are $K$ identical workers (interpretable as cores of a central processing unit (CPU)), and time advances in discrete rounds $r\\in\\{0,1,\\dots,R-1\\}$, where $R=\\lceil N/K \\rceil$. In each round $r$, each worker $k\\in\\{0,1,\\dots,K-1\\}$ updates at most one household, specifically the household with index $i=k+rK$ if $iN$, and otherwise the worker is idle in that round.\n\nEach household update is a single write. The base time for a single write is $c0$. If, during the same round $r$, multiple workers update households that map to the same cache line, cache coherence causes additional delay as follows. For any round $r$ and any cache line $x$, define $m_x(r)$ as the number of updates in round $r$ that target households with $\\ell(i)=x$. The wall-clock duration of round $r$ is\n$$\nt_r \\;=\\; c \\;+\\; p\\cdot\\big(\\max_{x} m_x(r) - 1\\big),\n$$\nwith the convention that if there is no active worker in a round then the round does not occur. The total simulated wall-clock time of the execution under this interleaved schedule is\n$$\nT_{\\mathrm{interleaved}} \\;=\\; \\sum_{r=0}^{R-1} t_r.\n$$\n\nFor comparison, consider a conflict-free padded layout scenario in which households are laid out in memory with padding so that no two concurrently updated households ever share a cache line (effectively, one household per cache line). Under the same scheduling of indices, the duration of each round with at least one active worker is exactly $c$, hence\n$$\nT_{\\mathrm{padded}} \\;=\\; R\\cdot c.\n$$\n\nDefine the slowdown factor as\n$$\nS \\;=\\; \\frac{T_{\\mathrm{interleaved}}}{T_{\\mathrm{padded}}}.\n$$\n\nYour task is to implement a program that, for each of the specified test cases, computes the slowdown factor $S$ as defined above.\n\nTest suite:\n- Case $1$: $(N,K,L,c,p) = ($16$,$2$,$2$,$1.0$,$0.5$)$.\n- Case $2$: $(N,K,L,c,p) = ($16$,$2$,$1$,$1.0$,$10.0$)$.\n- Case $3$: $(N,K,L,c,p) = ($17$,$1$,$8$,$1.0$,$2.0$)$.\n- Case $4$: $(N,K,L,c,p) = ($100$,$4$,$4$,$2.0$,$0.0$)$.\n- Case $5$: $(N,K,L,c,p) = ($32$,$4$,$4$,$1.0$,$1.0$)$.\n\nAnswer specification:\n- For each case, output the slowdown factor $S$ as a decimal number.\n- Your program should produce a single line of output containing the results for all cases as a comma-separated list enclosed in square brackets, in the order of the cases above, with exactly three digits after the decimal point (for example, [$1.000$,$1.500$]).",
            "solution": "The problem statement is examined and found to be valid. It is scientifically grounded in the principles of parallel computing, specifically the concept of false sharing in cache-coherent systems. The problem is well-posed, with all variables, constants, and functional relationships defined unambiguously, permitting a unique and stable solution. The language is objective and the setup is internally consistent and complete.\n\nThe objective is to compute the slowdown factor $S$, defined as the ratio of the total execution time of an interleaved parallel schedule, $T_{\\text{interleaved}}$, to that of a conflict-free padded schedule, $T_{\\text{padded}}$.\n$$\nS = \\frac{T_{\\text{interleaved}}}{T_{\\text{padded}}}\n$$\nThe calculation proceeds by determining $T_{\\text{padded}}$ and $T_{\\text{interleaved}}$ separately for a given set of parameters $(N, K, L, c, p)$, where $N$ is the number of households, $K$ is the number of workers, $L$ is the cache line size in households, $c$ is the base write cost, and $p$ is the conflict penalty coefficient.\n\nFirst, we calculate the total time for the padded layout, $T_{\\text{padded}}$. The simulation proceeds in discrete rounds, $r$. The total number of rounds required to process all $N$ households with $K$ workers is $R = \\lceil N/K \\rceil$. In the padded layout, false sharing is eliminated, so each round with at least one active worker takes a constant time $c$. It can be shown that for all rounds $r \\in \\{0, 1, \\dots, R-1\\}$, at least worker $k=0$ is active since its target index $i=rK$ satisfies $rK  (\\lceil N/K \\rceil)K$, which implies $rK \\le (N/K)K = N$ and strict inequality holds for $r  N/K$. For the last round $r=R-1$, we have $(R-1)K  N$, so worker $0$ is always active. Thus, all $R$ rounds are active, and the total time is:\n$$\nT_{\\text{padded}} = R \\cdot c\n$$\n\nNext, we calculate the total time for the interleaved layout, $T_{\\text{interleaved}}$. This time is the sum of the durations of each individual round, $t_r$:\n$$\nT_{\\text{interleaved}} = \\sum_{r=0}^{R-1} t_r\n$$\nThe duration of a single round $r$ depends on the maximum number of workers concurrently accessing the same cache line. The duration is given by:\n$$\nt_r = c + p \\cdot \\left(\\max_{x} m_x(r) - 1\\right)\n$$\nwhere $m_x(r)$ is the number of updates in round $r$ to households residing on cache line $x$. To compute $t_r$, we must first find $\\max_{x} m_x(r)$.\n\nThe algorithm for each round $r$ from $0$ to $R-1$ is as follows:\n1.  Identify the set of household indices updated in this round. For each worker $k \\in \\{0, 1, \\dots, K-1\\}$, the target index is $i = k + rK$. An update occurs only if $i  N$.\n2.  For each such active index $i$, determine its cache line identifier, $\\ell(i) = \\lfloor i/L \\rfloor$.\n3.  Count the number of occurrences for each unique cache line identifier. This provides the values of $m_x(r)$ for all cache lines $x$ accessed in this round.\n4.  Determine the maximum count, $\\max_{x} m_x(r)$. Let this be $M_r$.\n5.  Calculate the round duration $t_r = c + p \\cdot (M_r - 1)$.\n6.  Sum these durations over all rounds to obtain $T_{\\text{interleaved}}$.\n\nFinally, the slowdown factor $S$ is computed using the ratio of the two total times. This procedure is repeated for each test case specified in the problem.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the specified test cases and print the results.\n    \"\"\"\n    # Test suite as defined in the problem statement.\n    test_cases = [\n        # (N, K, L, c, p)\n        (16, 2, 2, 1.0, 0.5),\n        (16, 2, 1, 1.0, 10.0),\n        (17, 1, 8, 1.0, 2.0),\n        (100, 4, 4, 2.0, 0.0),\n        (32, 4, 4, 1.0, 1.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack parameters for each case\n        N, K, L, c, p = case\n        # Calculate the slowdown factor\n        result = calculate_slowdown(N, K, L, c, p)\n        # Format the result to three decimal places as a string.\n        results.append(f\"{result:.3f}\")\n\n    # Print the final list of results in the specified format.\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_slowdown(N, K, L, c, p):\n    \"\"\"\n    Computes the slowdown factor S for a given set of parameters.\n\n    Args:\n        N (int): Total number of households.\n        K (int): Number of workers.\n        L (int): Number of households per cache line.\n        c (float): Base time for a single write.\n        p (float): Penalty coefficient for cache conflicts.\n\n    Returns:\n        float: The slowdown factor S.\n    \"\"\"\n    # The total number of rounds, R, is the ceiling of N/K.\n    R = int(np.ceil(N / K))\n\n    # The total time for the padded, conflict-free layout is R * c.\n    # As established in the analysis, every round from 0 to R-1 has at least one\n    # active worker, so all R rounds take time c.\n    T_padded = R * c\n\n    # Calculate the total time for the interleaved layout by summing round durations.\n    T_interleaved = 0.0\n    for r in range(R):\n        # Determine the household indices accessed by all workers in this round.\n        indices_this_round = []\n        for k in range(K):\n            idx = k + r * K\n            if idx  N:\n                indices_this_round.append(idx)\n        \n        # A round r  R always has at least one active worker, so this list is not empty.\n        \n        # Map each household index to its corresponding cache line ID.\n        cache_lines_this_round = [idx // L for idx in indices_this_round]\n        \n        # Count the number of updates for each unique cache line to find the maximum contention.\n        # This corresponds to finding max_x m_x(r).\n        # np.unique with return_counts is an efficient method for this.\n        _, counts = np.unique(cache_lines_this_round, return_counts=True)\n        max_updates_on_a_line = np.max(counts)\n            \n        # Calculate the duration of the current round, t_r.\n        # The penalty is proportional to the number of excess workers on the most contended cache line.\n        t_r = c + p * (max_updates_on_a_line - 1)\n        T_interleaved += t_r\n    \n    # The slowdown factor S is the ratio of the two total times.\n    # Division by zero is not a risk as c > 0 and N > 0, which implies R > 0 and T_padded > 0.\n    slowdown = T_interleaved / T_padded\n    \n    return slowdown\n\n# Execute the main function to run the simulation and print the output.\nsolve()\n```"
        }
    ]
}