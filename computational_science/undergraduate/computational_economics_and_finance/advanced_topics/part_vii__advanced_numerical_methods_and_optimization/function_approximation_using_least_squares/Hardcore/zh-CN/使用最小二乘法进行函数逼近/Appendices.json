{
    "hands_on_practices": [
        {
            "introduction": "许多经济关系（如税率与税收收入之间的关系）的精确函数形式是未知的。本练习将指导您使用多项式最小二乘法，从带有噪声的数据中近似著名的“拉弗曲线”。您不仅将学习如何拟合模型，还将通过交叉验证这一基本技术来选择最佳的多项式次数，以避免过拟合并获得更可靠的预测。",
            "id": "2395010",
            "problem": "考虑一个经济体，其中政府税收是平均税率的函数。设税率用 $t \\in [0,1]$ 表示（以小数而非百分比形式表示），并假设我们观察到由某种结构形式生成的、在不同税率下的带噪声的税收样本。您的任务是使用普通最小二乘法（OLS）拟合二次或三次多项式，来近似未知的拉弗曲线（Laffer curve，即税收作为税率的函数），然后使用拟合的近似函数计算单位区间上使税收最大化的税率。\n\n从以下基本概念开始：\n- 给定样本对 $\\{(t_i, y_i)\\}_{i=1}^n$，一个 $d$ 次多项式为 $p_d(t) = \\sum_{j=0}^{d} \\beta_j t^j$。普通最小二乘法（OLS）通过最小化残差平方和 $\\sum_{i=1}^{n} (y_i - p_d(t_i))^2$ 来估计系数。\n- 模型选择可以通过 $K$ 折交叉验证（$K$-fold cross-validation）来执行，该方法评估样本外预测误差，并选择平均验证误差最低的阶数 $d$。\n\n您的程序必须：\n1. 对每个测试用例，按如下方式模拟数据 $(t_i, y_i)$。抽取 $n$ 个独立的税率 $t_i \\sim \\text{Uniform}[0,1]$。生成噪声 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。将真实税收函数定义为 $R_{\\text{true}}(t) = A \\cdot t \\cdot (1 - t)^k$。然后设置 $y_i = R_{\\text{true}}(t_i) + \\varepsilon_i$。所有随机性必须按照测试套件中的规定进行确定性播种（seeded deterministically）。\n2. 对于每个候选阶数 $d \\in \\{2,3\\}$，使用模拟数据通过 OLS 拟合 $p_d(t)$。\n3. 使用 $K=5$ 折的 $K$ 折交叉验证（使用给定的种子进行随机打乱）来选择具有最低平均验证均方误差的阶数 $d$。如果出现平局，则优先选择较低的阶数。\n4. 在完整数据集上重新拟合所选阶数的模型，以获得最终系数 $\\hat{\\beta}_j$。\n5. 通过在闭区间 $[0,1]$ 上最大化拟合的多项式 $p_d(t)$ 来计算估计的税收最大化税率 $\\hat{t}^\\star$。即，通过求解 $p_d'(t)=0$ 找到位于 $[0,1]$ 内的所有实数临界点，在这些点以及端点 $t=0$ 和 $t=1$ 处计算 $p_d(t)$ 的值，并将 $\\hat{t}^\\star$ 设为最大值点。然后计算估计的最大税收 $\\hat{R}^\\star = p_d(\\hat{t}^\\star)$。\n6. 本问题不涉及角度。所有税率均以 $[0,1]$ 范围的小数表示，所有税收均以不带百分号的实数表示。\n\n使用以下测试套件。对于每种情况，对所有随机操作（包括数据生成和数据折的洗牌）使用提供的种子，抽取 $n$ 个点，使用噪声标准差 $\\sigma$，以及数据生成过程 $R_{\\text{true}}(t) = A \\cdot t \\cdot (1 - t)^k$ 的参数 $A$ 和 $k$：\n- 情况 1：种子 $42$，$n=40$，$\\sigma=0.005$，$A=1.0$，$k=1$。\n- 情况 2：种子 $123$，$n=50$，$\\sigma=0.01$，$A=1.0$，$k=2$。\n- 情况 3：种子 $7$，$n=25$，$\\sigma=0.05$，$A=1.0$，$k=2$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个 Python 风格的列表，该列表包含三个子列表，每个子列表对应一个测试用例，顺序与上文相同。每个子列表必须为 $[d,\\ \\hat{t}^\\star,\\ \\hat{R}^\\star]$ 的形式，其中 $d$ 是所选的阶数（一个在 $\\{2,3\\}$ 中的整数），而 $\\hat{t}^\\star$ 和 $\\hat{R}^\\star$ 四舍五入到恰好六位小数。例如：$[[2,0.500000,0.250000],[3,0.333333,0.197531],[2,0.480000,0.210000]]$。",
            "solution": "该问题将根据指定标准进行验证。\n\n**步骤 1：提取给定信息**\n- **域**：税率 $t \\in [0,1]$。\n- **数据**：样本对 $\\{(t_i, y_i)\\}_{i=1}^n$。\n- **模型**：$d$ 次多项式 $p_d(t) = \\sum_{j=0}^{d} \\beta_j t^j$。\n- **估计方法**：普通最小二乘法（OLS），通过最小化残差平方和 $\\sum_{i=1}^{n} (y_i - p_d(t_i))^2$。\n- **模型选择**：使用 $K=5$ 的 $K$ 折交叉验证。选择平均验证误差最低的阶数 $d$。候选阶数为 $d \\in \\{2,3\\}$。若出现平局，则选择较低的阶数。\n- **数据生成过程**：\n    - $t_i \\sim \\text{Uniform}[0,1]$。\n    - 噪声 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。\n    - 真实税收函数 $R_{\\text{true}}(t) = A \\cdot t \\cdot (1 - t)^k$。\n    - 观测到的税收样本 $y_i = R_{\\text{true}}(t_i) + \\varepsilon_i$。\n- **优化**：通过在区间 $[0,1]$ 上最大化拟合的多项式 $p_d(t)$ 来找到使税收最大化的税率 $\\hat{t}^\\star$。估计的最大税收为 $\\hat{R}^\\star = p_d(\\hat{t}^\\star)$。\n- **测试用例**：\n    - 情况 1：种子=$42$，$n=40$，$\\sigma=0.005$，$A=1.0$，$k=1$。\n    - 情况 2：种子=$123$，$n=50$，$\\sigma=0.01$，$A=1.0$，$k=2$。\n    - 情况 3：种子=$7$，$n=25$，$\\sigma=0.05$，$A=1.0$，$k=2$。\n\n**步骤 2：使用提取的给定信息进行验证**\n- **科学依据**：该问题具有科学依据。它提出了计量经济学和统计学中的一个标准任务：从带噪声的数据中进行函数近似。多项式回归、普通最小二乘法和用于模型选择的交叉验证都是基础且成熟的方法。拉弗曲线是经济学中一个有效的概念，所选的函数形式是一个在数学上易于处理的模型。\n- **适定性**：该问题是适定的。所有必要的参数、数据生成过程和算法步骤都已明确定义。目标清晰，并且在给定确定性种子的情况下，每个测试用例都会产生唯一的计算结果。\n- **客观性**：问题陈述是客观的，使用了精确的数学和统计语言，没有主观或含糊的术语。\n\n**步骤 3：结论与行动**\n该问题是有效的。它是在应用统计学中一个明确定义的计算练习。将提供一个解决方案。\n\n---\n\n该问题要求我们根据一组带噪声的观测数据，来近似一个代表税收与税率函数关系的未知函数。我们将使用多项式回归，并通过 $K$ 折交叉验证从候选集合 $\\{2, 3\\}$ 中选择最优的多项式阶数。随后，我们将在有效定义域 $[0,1]$ 上找到使估计的税收函数最大化的税率。\n\n**1. 数据生成**\n对于每个测试用例，我们都给定一个用于伪随机数生成器的种子、样本数量 $n$、噪声标准差 $\\sigma$ 以及真实税收函数的参数 $A$ 和 $k$。数据点 $(t_i, y_i)$（其中 $i=1, \\dots, n$）按以下方式生成：\n- 税率 $t_i$ 从区间 $[0, 1]$ 上的均匀分布中抽取，即 $t_i \\sim \\text{U}[0, 1]$。\n- 相应的真实税收使用 $R_{\\text{true}}(t_i) = A \\cdot t_i \\cdot (1 - t_i)^k$ 计算。\n- 噪声项 $\\varepsilon_i$ 从均值为 $0$、方差为 $\\sigma^2$ 的正态分布中抽取，即 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。\n- 观测到的税收为 $y_i = R_{\\text{true}}(t_i) + \\varepsilon_i$。\n\n**2. 通过普通最小二乘法（OLS）进行多项式回归**\n我们试图用一个 $d$ 次多项式 $p_d(t) = \\sum_{j=0}^{d} \\beta_j t^j$ 来近似真实函数。系数 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1, \\dots, \\beta_d]^T$ 通过最小化残差平方和（SSR）来估计：\n$$\n\\text{SSR}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - p_d(t_i))^2\n$$\n这是一个线性最小二乘问题。设 $\\mathbf{y} = [y_1, \\dots, y_n]^T$ 是观测税收的向量。设 $\\mathbf{X}$ 是 $n \\times (d+1)$ 的设计矩阵，对于多项式拟合，它是一个范德蒙德矩阵（Vandermonde matrix）：\n$$\n\\mathbf{X} =\n\\begin{pmatrix}\n1  t_1  t_1^2  \\dots  t_1^d \\\\\n1  t_2  t_2^2  \\dots  t_2^d \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n1  t_n  t_n^2  \\dots  t_n^d\n\\end{pmatrix}\n$$\n问题是最小化 $\\|\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}\\|_2^2$。解 $\\hat{\\boldsymbol{\\beta}}$ 由正规方程组（normal equations）给出：\n$$\n(\\mathbf{X}^T \\mathbf{X})\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^T \\mathbf{y}\n$$\n假设 $\\mathbf{X}^T \\mathbf{X}$ 是可逆的，则 OLS 估计为 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$。在计算上，这个问题可以通过 QR 分解等方法高效求解，这也是数值计算库通常采用的实现方式。\n\n**3. 通过 $K$ 折交叉验证进行模型选择**\n为了在二次（$d=2$）和三次（$d=3$）模型之间进行选择，我们使用 $K=5$ 的 $K$ 折交叉验证。该技术提供了模型样本外预测误差的估计，有助于防止过拟合。\n对于每个候选阶数 $d$，其过程如下：\n1. 将包含 $n$ 个样本的数据集随机打乱，并分割成 $K=5$ 个大小基本相等的互不相交的子集（折）。\n2. 对每一折 $k \\in \\{1, 2, 3, 4, 5\\}$：\n   a. 将第 $k$ 折指定为验证集。剩下的 $K-1$ 折组合成训练集。\n   b. 在训练集上使用 OLS 拟合一个 $d$ 次多项式，得到系数 $\\hat{\\boldsymbol{\\beta}}^{(k)}$。\n   c. 在验证集上计算均方误差（MSE）：$MSE_k = \\frac{1}{|N_k|} \\sum_{i \\in \\text{fold } k} (y_i - p_d(t_i; \\hat{\\boldsymbol{\\beta}}^{(k)}))^2$，其中 $|N_k|$ 是第 $k$ 折中的样本数量。\n3. 阶数 $d$ 的交叉验证得分是这些 MSE 的平均值：$CV(d) = \\frac{1}{K} \\sum_{k=1}^{K} MSE_k$。\n最优阶数 $d^\\star$ 被选为最小化该分数的阶数：$d^\\star = \\arg\\min_{d \\in \\{2,3\\}} CV(d)$。如果 $CV(2) \\le CV(3)$，我们选择更简单的模型，即 $d^\\star=2$。\n\n**4. 对所选模型进行优化**\n一旦选定了最优阶数 $d^\\star$，就使用整个数据集重新拟合多项式模型，以获得最终的系数向量 $\\hat{\\boldsymbol{\\beta}}$。我们将最终估计的税收函数表示为 $p_{d^\\star}(t)$。\n\n下一步是在闭区间 $[0, 1]$ 上找到使该函数最大化的税率 $\\hat{t}^\\star$。根据极值定理（Extreme Value Theorem），闭区间上的连续函数必能达到其最大值和最小值。最大值点必须是区间的端点（$t=0$ 或 $t=1$），或导数 $p'_{d^\\star}(t)$ 为零的内部临界点。\n\n该多项式的导数为 $p'_{d^\\star}(t) = \\sum_{j=1}^{d^\\star} j \\hat{\\beta}_j t^{j-1}$。\n- 如果 $d^\\star=2$，导数是 $p'_2(t) = \\hat{\\beta}_1 + 2\\hat{\\beta}_2 t$。令其为零可得一个临界点：$t_c = -\\frac{\\hat{\\beta}_1}{2\\hat{\\beta}_2}$。\n- 如果 $d^\\star=3$，导数是 $p'_3(t) = \\hat{\\beta}_1 + 2\\hat{\\beta}_2 t + 3\\hat{\\beta}_3 t^2$。这是一个二次方程。其根可以使用二次公式求得，最多可产生两个实数临界点。\n\n最大值点 $\\hat{t}^\\star$ 的候选值集合包括端点 $\\{0, 1\\}$ 以及落在区间 $[0, 1]$ 内的任何实数临界点。我们在每个候选点处计算 $p_{d^\\star}(t)$ 的值。产生最高税收的 $t$ 值即为估计的最优税率 $\\hat{t}^\\star$。\n$$\n\\hat{t}^\\star = \\arg\\max_{t \\in \\text{candidates}} p_{d^\\star}(t)\n$$\n估计的最大税收则为 $\\hat{R}^\\star = p_{d^\\star}(\\hat{t}^\\star)$。对每个测试用例都遵循此过程以生成最终结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Laffer curve approximation problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (seed, n, sigma, A, k)\n        (42, 40, 0.005, 1.0, 1),\n        (123, 50, 0.01, 1.0, 2),\n        (7, 25, 0.05, 1.0, 2),\n    ]\n\n    all_results = []\n    \n    for seed, n, sigma, A, k_param in test_cases:\n        # Set all sources of randomness for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Simulate data\n        t = rng.uniform(0, 1, n)\n        true_revenue = A * t * (1 - t)**k_param\n        noise = rng.normal(0, sigma, n)\n        y = true_revenue + noise\n\n        # 2.  3. Model selection using 5-fold cross-validation\n        K = 5\n        indices = np.arange(n)\n        rng.shuffle(indices)\n        folds = np.array_split(indices, K)\n        \n        candidate_degrees = [2, 3]\n        cv_errors = {}\n\n        for d in candidate_degrees:\n            fold_mses = []\n            for k_fold_idx in range(K):\n                val_indices = folds[k_fold_idx]\n                train_indices = np.concatenate([folds[i] for i in range(K) if i != k_fold_idx])\n\n                t_train, y_train = t[train_indices], y[train_indices]\n                t_val, y_val = t[val_indices], y[val_indices]\n\n                # Fit model on training data\n                X_train = np.vander(t_train, d + 1, increasing=True)\n                coeffs, _, _, _ = np.linalg.lstsq(X_train, y_train, rcond=None)\n\n                # Evaluate on validation data\n                X_val = np.vander(t_val, d + 1, increasing=True)\n                y_pred_val = X_val @ coeffs\n                mse = np.mean((y_val - y_pred_val)**2)\n                fold_mses.append(mse)\n            \n            cv_errors[d] = np.mean(fold_mses)\n\n        # Select the best degree, preferring the lower degree in case of a tie\n        if cv_errors[2] = cv_errors[3]:\n            d_star = 2\n        else:\n            d_star = 3\n\n        # 4. Refit the chosen model on the full dataset\n        X_full = np.vander(t, d_star + 1, increasing=True)\n        # beta has shape (d_star + 1,) where beta[j] is the coefficient for t^j\n        beta, _, _, _ = np.linalg.lstsq(X_full, y, rcond=None)\n\n        # 5. Compute the estimated revenue-maximizing tax rate\n        \n        # Derivative coefficients: p'(t) = sum_{j=1 to d} j * beta[j] * t^(j-1)\n        # np.roots expects coefficients in descending power order\n        # For p'(t) = c_0*t^(d-1) + ... + c_{d-1}, coeffs are [c_0, ..., c_{d-1}]\n        # c_m = (m+1)*beta[m+1] in our notation.\n        # So for np.roots, we need [(d_star)*beta[d_star], (d_star-1)*beta[d_star-1], ..., 1*beta[1]]\n        deriv_coeffs = [j * beta[j] for j in range(d_star, 0, -1)]\n        critical_points = np.roots(deriv_coeffs)\n        \n        # Candidate points for the maximum on [0, 1]\n        candidate_t = [0.0, 1.0]\n        for root in critical_points:\n            # Filter for real roots within the interval [0, 1]\n            if np.isreal(root) and 0.0 = root.real = 1.0:\n                candidate_t.append(root.real)\n        \n        candidate_t = np.unique(candidate_t)\n\n        # Evaluate the polynomial at candidate points to find the maximum\n        # np.polyval expects coefficients in descending power order [beta_d, ..., beta_0]\n        poly_coeffs_desc = beta[::-1]\n        candidate_R = np.polyval(poly_coeffs_desc, candidate_t)\n        \n        max_idx = np.argmax(candidate_R)\n        t_star = candidate_t[max_idx]\n        R_star = candidate_R[max_idx]\n\n        all_results.append(\n            f\"[{d_star},{t_star:.6f},{R_star:.6f}]\"\n        )\n        \n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当观测数据不理想时，例如数据点很少或自变量高度相关时，标准的最小二乘估计可能会变得不稳定。本练习介绍了一种强大的解决方案：正则化最小二乘法（岭回归）。通过在一个需求曲线估计问题中应用该方法，您将亲身体验正则化如何通过对模型系数施加惩罚，来产生在病态数据条件下更为稳健和可靠的估计。",
            "id": "2394930",
            "problem": "一位市场分析师希望估计一个线性的反需求关系，该关系将每日需求量与公布价格联系起来。对于每一天 $t \\in \\{1,2,\\dots,T\\}$，分析师观测到一个价格 $p_t \\in \\mathbb{R}$ 和一个数量 $q_t \\in \\mathbb{R}$。该关系被建模为 $q_t = a + b \\, p_t + \\varepsilon_t$，其中 $a \\in \\mathbb{R}$ 和 $b \\in \\mathbb{R}$ 是未知常数，而 $\\varepsilon_t \\in \\mathbb{R}$ 代表未观测到的误差。分析师每天仅使用截至当天观测到的数据来更新估计。在第 $t$ 天，将估计量 $(\\hat{a}_t,\\hat{b}_t)$ 定义为惩罚平方和\n$$\n\\sum_{i=1}^{t} \\left(q_i - a - b \\, p_i\\right)^2 \\;+\\; \\lambda \\, (a^2 + b^2),\n$$\n的最小化器，对于给定的惩罚权重 $\\lambda  0$，其中截距和斜率都受到惩罚。样本的最终估计量为 $(\\hat{a}_T,\\hat{b}_T)$。对于给定的预测价格 $p^\\star \\in \\mathbb{R}$，定义预测数量为 $\\hat{q}^\\star = \\hat{a}_T + \\hat{b}_T \\, p^\\star$。\n\n实现一个程序，对于下面的每个测试用例，按时间顺序处理每日观测数据，在每一天维持由最小化问题所隐含的当前估计量，并在最后一天之后返回最终估计量以及在指定预测价格下的预测数量。程序必须将所有量视为实数。不涉及角度。不涉及物理单位。所有输出必须是实数。\n\n测试套件包含三个用例。在每个用例中，程序会获得一个每日价格序列、一个等长的每日数量序列、一个正的惩罚值 $\\lambda$ 以及一个预测价格 $p^\\star$。\n\n测试用例 1（良态数据，中等变异）：\n- $t \\in \\{1,\\dots,6\\}$ 的价格 $p_t$：$\\{1.0, 2.0, 3.0, 4.0, 5.0, 2.5\\}$。\n- $t \\in \\{1,\\dots,6\\}$ 的数量 $q_t$：$\\{9.2, 5.9, 3.0, 0.1, -3.2, 4.55\\}$。\n- 惩罚 $\\lambda = 0.1$。\n- 预测价格 $p^\\star = 3.3$。\n\n测试用例 2（边界条件：无正则化时为欠定问题）：\n- $t \\in \\{1\\}$ 的价格 $p_t$：$\\{2.0\\}$。\n- $t \\in \\{1\\}$ 的数量 $q_t$：$\\{2.0\\}$。\n- 惩罚 $\\lambda = 10.0$。\n- 预测价格 $p^\\star = 2.0$。\n\n测试用例 3（近似共线性：价格密集聚集）：\n- $t \\in \\{1,\\dots,5\\}$ 的价格 $p_t$：$\\{1.0, 1.01, 0.99, 1.0, 1.005\\}$。\n- $t \\in \\{1,\\dots,5\\}$ 的数量 $q_t$：$\\{5.0, 4.98, 5.02, 5.0, 4.99\\}$。\n- 惩罚 $\\lambda = 0.5$。\n- 预测价格 $p^\\star = 1.0$。\n\n您的程序必须在单行中生成一个长度为 3 的列表，其第 $j$ 个元素对应于测试用例 $j \\in \\{1,2,3\\}$，并且本身是一个包含三个实数 $[\\hat{a}_T, \\hat{b}_T, \\hat{q}^\\star]$ 的列表，每个数字都四舍五入到小数点后六位。最终输出格式必须是单行，包含一个用方括号括起来的逗号分隔列表，不含任何额外文本，例如：\n$[[x_{11},x_{12},x_{13}],[x_{21},x_{22},x_{23}],[x_{31},x_{32},x_{33}]]$.",
            "solution": "问题陈述已经过验证，并被认定为有效。这是一个基于正则化线性回归既定原则的适定数学优化问题。所有必要的数据和条件都已提供，不存在科学或逻辑上的矛盾。\n\n该问题要求通过最小化惩罚平方和来估计线性模型 $q_t = a + b \\, p_t + \\varepsilon_t$ 的系数 $a \\in \\mathbb{R}$ 和 $b \\in \\mathbb{R}$。对于一个包含 $T$ 个观测值的数据集 $\\{(p_i, q_i)\\}_{i=1}^T$，需要最小化的目标函数是\n$$ S(a, b) = \\sum_{i=1}^{T} (q_i - a - b \\, p_i)^2 + \\lambda (a^2 + b^2) $$\n其中 $\\lambda  0$ 是一个给定的惩罚权重。估计量 $(\\hat{a}_T, \\hat{b}_T)$ 是使 $S(a, b)$ 最小化的 $(a, b)$ 的值。这是岭回归 (Ridge Regression) 的一个特例，其中截距项也受到了惩罚。\n\n为了找到最小值，我们必须计算 $S(a, b)$ 关于 $a$ 和 $b$ 的偏导数，并令它们为零。这一点对应于梯度为零，$\\nabla S(a, b) = \\mathbf{0}$。\n\n关于 $a$ 的偏导数是：\n$$ \\frac{\\partial S}{\\partial a} = \\sum_{i=1}^{T} 2(q_i - a - b \\, p_i)(-1) + 2\\lambda a = -2 \\sum_{i=1}^{T} (q_i - a - b \\, p_i) + 2\\lambda a $$\n令 $\\frac{\\partial S}{\\partial a} = 0$ 得到第一个正规方程：\n$$ \\sum_{i=1}^{T} (q_i - a - b \\, p_i) = \\lambda a $$\n$$ \\sum_{i=1}^{T} q_i - T a - b \\sum_{i=1}^{T} p_i = \\lambda a $$\n$$ (T + \\lambda)a + \\left(\\sum_{i=1}^{T} p_i\\right)b = \\sum_{i=1}^{T} q_i $$\n\n关于 $b$ 的偏导数是：\n$$ \\frac{\\partial S}{\\partial b} = \\sum_{i=1}^{T} 2(q_i - a - b \\, p_i)(-p_i) + 2\\lambda b = -2 \\sum_{i=1}^{T} (q_i p_i - a p_i - b p_i^2) + 2\\lambda b $$\n令 $\\frac{\\partial S}{\\partial b} = 0$ 得到第二个正规方程：\n$$ \\sum_{i=1}^{T} (q_i p_i - a p_i - b p_i^2) = \\lambda b $$\n$$ \\sum_{i=1}^{T} q_i p_i - a \\sum_{i=1}^{T} p_i - b \\sum_{i=1}^{T} p_i^2 = \\lambda b $$\n$$ \\left(\\sum_{i=1}^{T} p_i\\right)a + \\left(\\sum_{i=1}^{T} p_i^2 + \\lambda\\right)b = \\sum_{i=1}^{T} p_i q_i $$\n\n这两个方程构成了关于估计量 $(\\hat{a}_T, \\hat{b}_T)$ 的一个线性方程组。其矩阵形式为：\n$$\n\\begin{pmatrix}\nT + \\lambda  \\sum_{i=1}^{T} p_i \\\\\n\\sum_{i=1}^{T} p_i  \\sum_{i=1}^{T} p_i^2 + \\lambda\n\\end{pmatrix}\n\\begin{pmatrix}\n\\hat{a}_T \\\\\n\\hat{b}_T\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\sum_{i=1}^{T} q_i \\\\\n\\sum_{i=1}^{T} p_i q_i\n\\end{pmatrix}\n$$\n该系统可以写成 $(\\mathbf{X}^T\\mathbf{X} + \\lambda\\mathbf{I})\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}$，其中 $\\boldsymbol{\\beta} = [\\hat{a}_T, \\hat{b}_T]^T$，$\\mathbf{y}$ 是数量向量，$\\mathbf{I}$ 是 $2 \\times 2$ 的单位矩阵，而 $\\mathbf{X}$ 是一个 $T \\times 2$ 的设计矩阵，其中一列是1，另一列是价格。当 $\\lambda  0$ 时，目标函数 $S(a, b)$ 是严格凸的，这保证了唯一解的存在。\n\n针对每个测试用例，求解最终估计量 $(\\hat{a}_T, \\hat{b}_T)$ 的算法如下：\n1. 对于给定的包含 $T$ 个价格-数量对 $\\{p_i, q_i\\}_{i=1}^T$ 的数据集，计算必要的汇总统计量：$T$、$\\sum p_i$、$\\sum q_i$、$\\sum p_i^2$ 和 $\\sum p_i q_i$。\n2. 构建 $2 \\times 2$ 矩阵 $\\mathbf{M} = \\begin{pmatrix} T + \\lambda  \\sum p_i \\\\ \\sum p_i  \\sum p_i^2 + \\lambda \\end{pmatrix}$ 和 $2 \\times 1$ 向量 $\\mathbf{v} = \\begin{pmatrix} \\sum q_i \\\\ \\sum p_i q_i \\end{pmatrix}$。\n3. 求解线性系统 $\\mathbf{M}\\boldsymbol{\\beta} = \\mathbf{v}$ 以得到系数向量 $\\boldsymbol{\\beta} = [\\hat{a}_T, \\hat{b}_T]^T$。这可以使用数值线性代数库高效且稳健地完成。\n4. 一旦找到最终估计量 $\\hat{a}_T$ 和 $\\hat{b}_T$，使用模型 $\\hat{q}^\\star = \\hat{a}_T + \\hat{b}_T p^\\star$ 计算给定价格 $p^\\star$ 的预测数量。\n5. 每个测试用例的最终结果是一个列表 $[\\hat{a}_T, \\hat{b}_T, \\hat{q}^\\star]$，其中每个元素都四舍五入到小数点后六位。\n\n“按时间顺序处理每日观测数据”这一措辞并不意味着必须采用递归实现，因为第 $T$ 天的最终估计仅依赖于截至那天的全部观测数据集。对整个样本进行批量计算既更直接，也在数值上更优越。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the penalized least squares problem for all test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"prices\": [1.0, 2.0, 3.0, 4.0, 5.0, 2.5],\n            \"quantities\": [9.2, 5.9, 3.0, 0.1, -3.2, 4.55],\n            \"lambda\": 0.1,\n            \"p_star\": 3.3\n        },\n        {\n            \"prices\": [2.0],\n            \"quantities\": [2.0],\n            \"lambda\": 10.0,\n            \"p_star\": 2.0\n        },\n        {\n            \"prices\": [1.0, 1.01, 0.99, 1.0, 1.005],\n            \"quantities\": [5.0, 4.98, 5.02, 5.0, 4.99],\n            \"lambda\": 0.5,\n            \"p_star\": 1.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        p_vec = np.array(case[\"prices\"])\n        q_vec = np.array(case[\"quantities\"])\n        lam = case[\"lambda\"]\n        p_star = case[\"p_star\"]\n\n        # Calculate the required sums for the normal equations.\n        T = len(p_vec)\n        sum_p = np.sum(p_vec)\n        sum_q = np.sum(q_vec)\n        sum_p_sq = np.sum(p_vec**2)\n        sum_pq = np.sum(p_vec * q_vec)\n\n        # Construct the matrix M and vector v for the linear system M*beta = v.\n        # M = X'X + lambda*I\n        # v = X'y\n        M = np.array([\n            [T + lam, sum_p],\n            [sum_p, sum_p_sq + lam]\n        ])\n        v = np.array([sum_q, sum_pq])\n\n        # Solve for the coefficients [a_hat, b_hat].\n        try:\n            coeffs = np.linalg.solve(M, v)\n            a_hat, b_hat = coeffs[0], coeffs[1]\n        except np.linalg.LinAlgError:\n            # This should not occur as M is positive definite for lambda > 0.\n            a_hat, b_hat = float('nan'), float('nan')\n\n        # Calculate the forecast quantity.\n        q_star_hat = a_hat + b_hat * p_star\n\n        # Round results to six decimal places.\n        rounded_result = [\n            round(a_hat, 6),\n            round(b_hat, 6),\n            round(q_star_hat, 6)\n        ]\n        results.append(rounded_result)\n\n    # Format the final output string to match the required format precisely.\n    # The format is [[...],[...],[...]] with no spaces.\n    outer_list_str = []\n    for inner_list in results:\n        # Format each inner list as '[x,y,z]'\n        inner_str = f\"[{','.join(map(str, inner_list))}]\"\n        outer_list_str.append(inner_str)\n    \n    final_output_str = f\"[{','.join(outer_list_str)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "函数近似的价值远不止于预测函数值本身，它还为估算复杂函数的导数提供了一条捷径。本练习将这一思想应用于金融工程领域，您将首先使用多项式最小二乘法来近似期权定价的 Black–Scholes 公式 。然后，通过对您拟合的多项式求导，您将能够估算出期权的“希腊字母”（如 Delta 和 Gamma），这些是衡量风险的关键指标，从而将函数近似技术应用于实际的金融风险管理问题。",
            "id": "2394969",
            "problem": "您的任务是，将欧式看涨期权的价格函数近似为标的资产水平的单变量函数，然后通过微分使用该近似计算敏感性指标（“希腊字母”）。对于一个欧式看涨期权，其标的资产水平为 $S$，行权价为 $K$，连续复利无风险利率为 $r$（以小数表示），波动率为 $\\sigma$（以小数表示），到期时间为 $T$（以年为单位），根据布莱克-斯科尔斯模型，其价格为\n$$\nC(S) \\;=\\; S\\,\\Phi(d_1) \\;-\\; K\\,e^{-r T}\\,\\Phi(d_2),\n$$\n其中\n$$\nd_1 \\;=\\; \\frac{\\ln(S/K) + \\left(r + \\tfrac{1}{2}\\sigma^2\\right) T}{\\sigma\\sqrt{T}}, \n\\qquad\nd_2 \\;=\\; d_1 \\;-\\; \\sigma\\sqrt{T},\n$$\n$\\Phi(\\cdot)$ 是标准正态分布的累积分布函数，$\\ln(\\cdot)$ 表示自然对数。期权的 Delta 值和 Gamma 值分别是价格对 $S$ 的一阶和二阶偏导数：\n$$\n\\Delta(S) \\;=\\; \\frac{\\partial C}{\\partial S}(S), \n\\qquad\n\\Gamma(S) \\;=\\; \\frac{\\partial^2 C}{\\partial S^2}(S).\n$$\n在布莱克-斯科尔斯模型下，其解析公式为\n$$\n\\Delta_{\\mathrm{BS}}(S) \\;=\\; \\Phi(d_1), \n\\qquad\n\\Gamma_{\\mathrm{BS}}(S) \\;=\\; \\frac{\\phi(d_1)}{S\\,\\sigma\\,\\sqrt{T}},\n$$\n其中 $\\phi(\\cdot)$ 是标准正态分布的概率密度函数。\n\n您的任务是，对于每个指定的参数集，使用在给定 $S$ 区间上的样本点，构建定价函数 $C(S)$ 的一个 $m$ 次最小二乘多项式逼近。然后，通过对该多项式进行一次和二次对 $S$ 的微分，计算在指定评估点处的近似 Delta 值和 Gamma 值。最后，报告这些近似值相对于布莱克-斯科尔斯解析 Delta 值和 Gamma 值的绝对误差。\n\n对每个测试用例：\n- 在闭区间 $[S_{\\min}, S_{\\max}]$ 上构建一个包含 $n$ 个点的等距网格 $\\{S_i\\}_{i=1}^n$。\n- 使用上述布莱克-斯科尔斯公式，在每个网格点上计算精确价格 $y_i = C(S_i)$。\n- 令 $\\mathcal{P}_m$ 表示 $S$ 的次数至多为 $m$ 的多项式集合。计算最小二乘多项式逼近函数 $\\hat{C}_m \\in \\mathcal{P}_m$，该函数通过调整 $\\hat{C}_m$ 的系数来最小化 $\\sum_{i=1}^n \\left(y_i - \\hat{C}_m(S_i)\\right)^2$。\n- 对 $\\hat{C}_m$ 关于 $S$ 求导，以获得 $\\widehat{\\Delta}_m(S) = \\frac{\\mathrm{d}}{\\mathrm{d}S}\\hat{C}_m(S)$ 和 $\\widehat{\\Gamma}_m(S) = \\frac{\\mathrm{d}^2}{\\mathrm{d}S^2}\\hat{C}_m(S)$。\n- 在评估点 $S_0$ 处，计算绝对误差 $|\\widehat{\\Delta}_m(S_0) - \\Delta_{\\mathrm{BS}}(S_0)|$ 和 $|\\widehat{\\Gamma}_m(S_0) - \\Gamma_{\\mathrm{BS}}(S_0)|$。\n\n设计细节：\n- 所有的利率和波动率都必须按小数处理（例如，年化利率 $2\\%$ 输入并使用时为 $0.02$）。\n- 不涉及物理单位。本题中没有角度。不要使用百分号表示任何答案。\n- 程序的最终输出必须为单行，包含一个由方括号括起来的逗号分隔的结果列表。每个测试用例贡献一个包含两个浮点数的内部列表，顺序为 $[\\text{DeltaError}, \\text{GammaError}]$，每个浮点数四舍五入到六位小数。例如，一个包含两个测试用例的输出应如下所示：$[[0.000123,0.045678],[0.000010,0.000200]]$。\n\n测试套件（每个项目指定 $(K, r, \\sigma, T, S_{\\min}, S_{\\max}, n, m, S_0)$）：\n- 案例 A: $(100,\\, 0.02,\\, 0.2,\\, 0.5,\\, 50,\\, 150,\\, 101,\\, 5,\\, 100)$。\n- 案例 B: $(100,\\, 0.01,\\, 0.25,\\, 1.0,\\, 80,\\, 200,\\, 121,\\, 6,\\, 180)$。\n- 案例 C: $(100,\\, 0.03,\\, 0.05,\\, 1.0,\\, 80,\\, 120,\\, 81,\\, 5,\\, 100)$。\n- 案例 D: $(100,\\, 0.00,\\, 0.3,\\, 0.01,\\, 80,\\, 120,\\, 81,\\, 5,\\, 100)$。\n- 案例 E: $(120,\\, 0.02,\\, 0.2,\\, 1.0,\\, 60,\\, 120,\\, 121,\\, 5,\\, 60)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表，每个元素是对应测试用例 A 到 E 的内部列表 $[\\text{DeltaError}, \\text{GammaError}]$，每个浮点数四舍五入到六位小数。",
            "solution": "所述问题已经过严格验证。它要求使用多项式最小二乘拟合来数值逼近欧式看涨期权的价格函数及其一阶和二阶导数——Delta 和 Gamma。其理论基础是作为数理金融学基本概念的布莱克-斯科尔斯模型，以及作为数值分析标准工具的最小二乘法。所有参数、约束和目标都已足够清晰和精确地指定。所提供的测试用例均在模型和数值方法的有效域内。未发现任何科学或逻辑上的矛盾、歧义或信息缺失。因此，该问题被认为是有效的、适定的，并具有科学依据。我们可以着手构建解决方案。\n\n目标是将欧式看涨期权的布莱克-斯科尔斯价格函数 $C(S)$ 近似为标的资产价格 $S$ 的一个多项式。价格由下式给出：\n$$\nC(S) = S\\,\\Phi(d_1) - K\\,e^{-r T}\\,\\Phi(d_2)\n$$\n其中 $K$ 是行权价，$r$ 是无风险利率，$T$ 是到期时间，$\\sigma$ 是波动率，$\\Phi(\\cdot)$ 是标准正态分布的累积分布函数（CDF）。$d_1$ 和 $d_2$ 项定义为\n$$\nd_1 = \\frac{\\ln(S/K) + \\left(r + \\frac{1}{2}\\sigma^2\\right) T}{\\sigma\\sqrt{T}}, \\quad d_2 = d_1 - \\sigma\\sqrt{T}\n$$\n该问题要求我们生成一组包含 $n$ 个样本点的集合 $(S_i, y_i)$，其中网格 $\\{S_i\\}_{i=1}^n$ 在区间 $[S_{\\min}, S_{\\max}]$ 上等距分布，且 $y_i = C(S_i)$。然后，我们寻找一个次数至多为 $m$ 的多项式 $\\hat{C}_m(S)$，\n$$\n\\hat{C}_m(S) = \\sum_{j=0}^{m} p_j S^{m-j}\n$$\n该多项式能使残差平方和 $L = \\sum_{i=1}^n (y_i - \\hat{C}_m(S_i))^2$ 最小化。这是一个经典的线性最小二乘问题。系数向量 $\\mathbf{p} = [p_0, p_1, \\dots, p_m]^T$ 可以通过求解正规方程 $(\\mathbf{X}^T \\mathbf{X})\\mathbf{p} = \\mathbf{X}^T \\mathbf{y}$ 来找到，其中 $\\mathbf{y}$ 是价格 $y_i$ 的向量，$\\mathbf{X}$ 是设计矩阵，其元素为 $X_{ij} = S_i^{m-j}$。通常使用数值稳定的算法（例如基于 QR 分解的算法）来求解该系统。\n\n一旦确定了逼近多项式 $\\hat{C}_m(S)$ 的系数，我们就可以方便地计算其导数，以近似期权的敏感性指标（即“希腊字母”）。Delta 值 $\\Delta = \\frac{\\partial C}{\\partial S}$ 是对 $S$ 的一阶导数，Gamma 值 $\\Gamma = \\frac{\\partial^2 C}{\\partial S^2}$ 是二阶导数。这些值的多项式逼近如下：\n$$\n\\widehat{\\Delta}_m(S) = \\frac{\\mathrm{d}}{\\mathrm{d}S}\\hat{C}_m(S) = \\sum_{j=0}^{m-1} (m-j) p_j S^{m-j-1}\n$$\n$$\n\\widehat{\\Gamma}_m(S) = \\frac{\\mathrm{d}^2}{\\mathrm{d}S^2}\\hat{C}_m(S) = \\sum_{j=0}^{m-2} (m-j)(m-j-1) p_j S^{m-j-2}\n$$\n然后在指定的点 $S_0$ 处计算这些近似的希腊字母值。\n\n这些逼近的准确性通过与从布莱克-斯科尔斯模型导出的 Delta 和 Gamma 解析公式进行比较来评估：\n$$\n\\Delta_{\\mathrm{BS}}(S) = \\Phi(d_1)\n$$\n$$\n\\Gamma_{\\mathrm{BS}}(S) = \\frac{\\phi(d_1)}{S\\,\\sigma\\,\\sqrt{T}}\n$$\n其中 $\\phi(\\cdot)$ 是标准正态分布的概率密度函数（PDF）。在评估点 $S_0$ 处计算绝对误差：\n$$\n\\text{DeltaError} = |\\widehat{\\Delta}_m(S_0) - \\Delta_{\\mathrm{BS}}(S_0)|\n$$\n$$\n\\text{GammaError} = |\\widehat{\\Gamma}_m(S_0) - \\Gamma_{\\mathrm{BS}}(S_0)|\n$$\n每个测试用例的计算过程包括以下步骤：生成资产价格网格，计算这些点上的精确期权价格，拟合多项式，对其进行微分，在 $S_0$ 处评估近似和解析的希腊字母值，最后计算绝对误差。将使用标准的数值库来处理正态分布函数以及多项式拟合和微分，以确保准确性和数值稳定性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n# language: Python\n# version: 3.12\n# libraries:\n#     - name: numpy\n#       version: 1.23.5\n#     - name: scipy\n#       version: 1.11.4\n\ndef black_scholes_call(S, K, T, r, sigma):\n    \"\"\"\n    Calculates the Black-Scholes price for a European call option.\n    Note: S can be a numpy array.\n    \"\"\"\n    # Ensure S is a float array to avoid potential type issues\n    S = np.asarray(S, dtype=float)\n    \n    # Handle the case where S is very close to zero\n    S[S  1e-9] = 1e-9\n\n    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n    d2 = d1 - sigma * np.sqrt(T)\n    price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n    return price\n\ndef black_scholes_delta(S, K, T, r, sigma):\n    \"\"\"\n    Calculates the analytical Black-Scholes Delta for a European call option.\n    \"\"\"\n    S = float(S)\n    if S  1e-9:\n        S = 1e-9\n    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n    return norm.cdf(d1)\n\ndef black_scholes_gamma(S, K, T, r, sigma):\n    \"\"\"\n    Calculates the analytical Black-Scholes Gamma for a European call option.\n    \"\"\"\n    S = float(S)\n    if S  1e-9:\n        S = 1e-9\n    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n    pdf_d1 = norm.pdf(d1)\n    return pdf_d1 / (S * sigma * np.sqrt(T))\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and generate the final output.\n    \"\"\"\n    # Test cases: (K, r, sigma, T, S_min, S_max, n, m, S0)\n    test_cases = [\n        (100, 0.02, 0.2, 0.5, 50, 150, 101, 5, 100),\n        (100, 0.01, 0.25, 1.0, 80, 200, 121, 6, 180),\n        (100, 0.03, 0.05, 1.0, 80, 120, 81, 5, 100),\n        (100, 0.00, 0.3, 0.01, 80, 120, 81, 5, 100),\n        (120, 0.02, 0.2, 1.0, 60, 120, 121, 5, 60),\n    ]\n\n    results = []\n    for case in test_cases:\n        K, r, sigma, T, S_min, S_max, n, m, S0 = case\n\n        # 1. Construct the grid and evaluate exact prices\n        S_grid = np.linspace(S_min, S_max, n)\n        y_grid = black_scholes_call(S_grid, K, T, r, sigma)\n\n        # 2. Compute the least-squares polynomial approximant\n        # np.polyfit returns coefficients in descending order of power\n        coeffs = np.polyfit(S_grid, y_grid, m)\n        \n        # 3. Differentiate the polynomial to get Greeks approximations\n        # np.poly1d creates a polynomial object from coefficients\n        C_poly = np.poly1d(coeffs)\n        Delta_poly = C_poly.deriv(1)\n        Gamma_poly = C_poly.deriv(2)\n\n        # 4. Evaluate approximated Greeks at the evaluation point S0\n        delta_approx = Delta_poly(S0)\n        gamma_approx = Gamma_poly(S0)\n\n        # 5. Evaluate analytical Greeks at S0\n        delta_exact = black_scholes_delta(S0, K, T, r, sigma)\n        gamma_exact = black_scholes_gamma(S0, K, T, r, sigma)\n\n        # 6. Compute absolute errors\n        delta_error = abs(delta_approx - delta_exact)\n        gamma_error = abs(gamma_approx - gamma_exact)\n        \n        results.append([delta_error, gamma_error])\n\n    # Final print statement in the exact required format.\n    formatted_results = [f'[{d_err:.6f},{g_err:.6f}]' for d_err, g_err in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}