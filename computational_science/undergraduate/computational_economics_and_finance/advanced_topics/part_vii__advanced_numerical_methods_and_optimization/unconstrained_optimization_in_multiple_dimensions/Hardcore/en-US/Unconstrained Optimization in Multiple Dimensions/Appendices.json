{
    "hands_on_practices": [
        {
            "introduction": "At the heart of optimization lies the calculus of finding stationary points. This first practice provides a direct application of this core principle by modeling an individual's optimal job search strategy. By solving for the ideal application intensities, you will work through the essential mechanics of setting a function's gradient to zero and solving the resulting system of equations, a foundational skill for any optimization problem .",
            "id": "2445351",
            "problem": "A job seeker considers two application channels during a single week: a formal channel and an informal channel. Let $n_F$ denote the intensity of applications sent through the formal channel and $n_I$ denote the intensity of applications sent through the informal channel. Interpreting intensities as continuous proxies for application counts over a short horizon, and under independent and small-arrival-probability conditions, the weekly expected salary of the secured job can be approximated by a second-order expansion in $(n_F,n_I)$:\n$$\n\\mathbb{E}[S(n_F,n_I)] \\;=\\; \\beta_0 \\;+\\; \\beta_F \\, n_F \\;+\\; \\beta_I \\, n_I \\;-\\; \\frac{1}{2}\\Big( a_F \\, n_F^{2} \\;+\\; 2 a_{FI} \\, n_F n_I \\;+\\; a_I \\, n_I^{2} \\Big),\n$$\nwhere $\\beta_0$, $\\beta_F$, $\\beta_I$, $a_F$, $a_{FI}$, and $a_I$ are parameters. Assume $a_F > 0$, $a_I > 0$, and $a_F a_I - a_{FI}^{2} > 0$, and that $\\beta_F > 0$ and $\\beta_I > 0$. These conditions ensure the approximation is strictly concave in $(n_F,n_I)$ and delivers a unique interior maximizer.\n\nDetermine the unconstrained optimizer $(n_F^{\\star}, n_I^{\\star})$ that maximizes $\\mathbb{E}[S(n_F,n_I)]$ with respect to $n_F$ and $n_I$. Express your final answer as a single closed-form analytic expression. No rounding is required.",
            "solution": "The problem requires finding the unconstrained optimizer for the expected weekly salary function, which is a quadratic function of two variables: application intensity through a formal channel, $n_F$, and an informal channel, $n_I$.\n\nFirst, a validation of the problem statement is in order.\n\nStep 1: Extract Givens.\nThe objective function to be maximized is:\n$$\n\\mathbb{E}[S(n_F,n_I)] = \\beta_0 + \\beta_F n_F + \\beta_I n_I - \\frac{1}{2}\\Big( a_F n_F^{2} + 2 a_{FI} n_F n_I + a_I n_I^{2} \\Big)\n$$\nThe variables of optimization are $n_F$ and $n_I$.\nThe parameters are $\\beta_0$, $\\beta_F$, $\\beta_I$, $a_F$, $a_{FI}$, and $a_I$.\nThe following conditions are given:\n$a_F > 0$\n$a_I > 0$\n$a_F a_I - a_{FI}^{2} > 0$\n$\\beta_F > 0$\n$\\beta_I > 0$\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically and mathematically sound. It presents a standard unconstrained optimization problem for a quadratic function. The function represents a second-order Taylor approximation, a common and valid technique in many scientific fields, including computational economics. The problem is well-posed; the given conditions on the parameters $a_F$, $a_I$, and $a_{FI}$ are precisely the conditions required for the Hessian matrix of the quadratic part to be positive definite, which in turn makes the objective function strictly concave, guaranteeing a unique global maximum. The problem is stated objectively with precisely defined mathematical terms and constraints. It is self-contained and does not violate any fundamental principles.\n\nStep 3: Verdict and Action.\nThe problem is valid. A solution will be derived.\n\nLet the objective function be denoted by $J(n_F, n_I)$. To find the unconstrained maximum, we must apply the first-order necessary condition, which states that the gradient of the function must be the zero vector at the optimal point $(n_F^{\\star}, n_I^{\\star})$.\nThe gradient of $J(n_F, n_I)$ is the vector of its partial derivatives: $\\nabla J = \\begin{pmatrix} \\frac{\\partial J}{\\partial n_F} & \\frac{\\partial J}{\\partial n_I} \\end{pmatrix}^T$.\n\nWe calculate the partial derivatives:\n$$\n\\frac{\\partial J}{\\partial n_F} = \\frac{\\partial}{\\partial n_F} \\left( \\beta_0 + \\beta_F n_F + \\beta_I n_I - \\frac{1}{2} a_F n_F^{2} - a_{FI} n_F n_I - \\frac{1}{2} a_I n_I^{2} \\right) = \\beta_F - a_F n_F - a_{FI} n_I\n$$\n$$\n\\frac{\\partial J}{\\partial n_I} = \\frac{\\partial}{\\partial n_I} \\left( \\beta_0 + \\beta_F n_F + \\beta_I n_I - \\frac{1}{2} a_F n_F^{2} - a_{FI} n_F n_I - \\frac{1}{2} a_I n_I^{2} \\right) = \\beta_I - a_{FI} n_F - a_I n_I\n$$\n\nSetting these partial derivatives to zero yields a system of two linear equations for the two unknowns, $n_F$ and $n_I$:\n$$\na_F n_F + a_{FI} n_I = \\beta_F\n$$\n$$\na_{FI} n_F + a_I n_I = \\beta_I\n$$\n\nThis system can be expressed in matrix form as:\n$$\n\\begin{pmatrix} a_F & a_{FI} \\\\ a_{FI} & a_I \\end{pmatrix} \\begin{pmatrix} n_F \\\\ n_I \\end{pmatrix} = \\begin{pmatrix} \\beta_F \\\\ \\beta_I \\end{pmatrix}\n$$\n\nThe second-order sufficient condition for a maximum requires that the Hessian matrix of second partial derivatives, $H$, be negative definite at the critical point. Let us compute the Hessian:\n$$\nH = \\begin{pmatrix} \\frac{\\partial^2 J}{\\partial n_F^2} & \\frac{\\partial^2 J}{\\partial n_F \\partial n_I} \\\\ \\frac{\\partial^2 J}{\\partial n_I \\partial n_F} & \\frac{\\partial^2 J}{\\partial n_I^2} \\end{pmatrix} = \\begin{pmatrix} -a_F & -a_{FI} \\\\ -a_{FI} & -a_I \\end{pmatrix}\n$$\nA matrix is negative definite if its leading principal minors alternate in sign, starting with a negative sign.\nThe first principal minor is $H_1 = -a_F$. Since the problem states $a_F > 0$, we have $H_1  0$.\nThe second principal minor is the determinant of $H$:\n$$\n\\det(H) = (-a_F)(-a_I) - (-a_{FI})^2 = a_F a_I - a_{FI}^2\n$$\nThe problem states $a_F a_I - a_{FI}^2 > 0$.\nSince the leading principal minors alternate in sign as required ($-$, $+$), the Hessian matrix is negative definite. This confirms that the solution to the first-order conditions corresponds to a strict local maximum. Because the function is globally concave, this is the unique global maximum.\n\nTo solve the system of linear equations for $(n_F^{\\star}, n_I^{\\star})$, we can use matrix inversion. Let the coefficient matrix be $A = \\begin{pmatrix} a_F  a_{FI} \\\\ a_{FI}  a_I \\end{pmatrix}$. The determinant is $\\det(A) = a_F a_I - a_{FI}^2$, which is given to be positive. The inverse of $A$ is:\n$$\nA^{-1} = \\frac{1}{a_F a_I - a_{FI}^2} \\begin{pmatrix} a_I  -a_{FI} \\\\ -a_{FI}  a_F \\end{pmatrix}\n$$\nThe solution vector is then found by pre-multiplying the constant vector by $A^{-1}$:\n$$\n\\begin{pmatrix} n_F^{\\star} \\\\ n_I^{\\star} \\end{pmatrix} = A^{-1} \\begin{pmatrix} \\beta_F \\\\ \\beta_I \\end{pmatrix} = \\frac{1}{a_F a_I - a_{FI}^2} \\begin{pmatrix} a_I  -a_{FI} \\\\ -a_{FI}  a_F \\end{pmatrix} \\begin{pmatrix} \\beta_F \\\\ \\beta_I \\end{pmatrix}\n$$\nPerforming the matrix-vector multiplication gives the expressions for the optimal intensities:\n$$\n\\begin{pmatrix} n_F^{\\star} \\\\ n_I^{\\star} \\end{pmatrix} = \\frac{1}{a_F a_I - a_{FI}^2} \\begin{pmatrix} a_I \\beta_F - a_{FI} \\beta_I \\\\ a_F \\beta_I - a_{FI} \\beta_F \\end{pmatrix}\n$$\nThus, the components of the optimizer are:\n$$\nn_F^{\\star} = \\frac{a_I \\beta_F - a_{FI} \\beta_I}{a_F a_I - a_{FI}^2}\n$$\n$$\nn_I^{\\star} = \\frac{a_F \\beta_I - a_{FI} \\beta_F}{a_F a_I - a_{FI}^2}\n$$\nThese expressions represent the unique optimal application intensities that maximize the expected salary.",
            "answer": "$$ \\boxed{ \\left( \\frac{a_I \\beta_F - a_{FI} \\beta_I}{a_F a_I - a_{FI}^{2}}, \\frac{a_F \\beta_I - a_{FI} \\beta_F}{a_F a_I - a_{FI}^{2}} \\right) } $$"
        },
        {
            "introduction": "Beyond optimizing a single objective, we can use these tools to analyze strategic interactions. This exercise transports you into a classic Bertrand competition, where two firms set prices to maximize their own profits. You will apply unconstrained optimization to derive each firm's \"best response\" to the other's strategy, and then solve for the Nash Equilibrium where these strategies intersect, providing a powerful glimpse into game theory .",
            "id": "2445317",
            "problem": "Two firms indexed by $i \\in \\{1,2\\}$ produce differentiated products and simultaneously choose prices $p_1$ and $p_2$, with $p_1, p_2 \\in \\mathbb{R}$. The market demand system is linear and given by\n$$\nq_1 = 100 - 3 p_1 + p_2, \\quad q_2 = 100 - 3 p_2 + p_1,\n$$\nwhere $q_i$ is the quantity demanded from firm $i$ when the price vector $(p_1, p_2)$ is charged. Firm $1$ has constant marginal cost $c_1 = 10$ and firm $2$ has constant marginal cost $c_2 = 20$. Each firmâ€™s profit is\n$$\n\\pi_1(p_1,p_2) = (p_1 - c_1) q_1, \\quad \\pi_2(p_1,p_2) = (p_2 - c_2) q_2.\n$$\nA pure-strategy Nash equilibrium is a price vector $(p_1^\\star, p_2^\\star)$ such that $p_1^\\star$ maximizes $\\pi_1(p_1, p_2^\\star)$ over $p_1 \\in \\mathbb{R}$ and $p_2^\\star$ maximizes $\\pi_2(p_1^\\star, p_2)$ over $p_2 \\in \\mathbb{R}$.\n\nFind the unique pure-strategy Nash equilibrium price vector $(p_1^\\star, p_2^\\star)$. Provide exact values (do not round). The final answer must be the ordered pair of prices.",
            "solution": "The problem requires finding the unique pure-strategy Nash equilibrium in a Bertrand competition model with differentiated products and asymmetric costs. The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\nThe following information is provided:\n-   Firms: $i \\in \\{1,2\\}$\n-   Prices: $p_1, p_2 \\in \\mathbb{R}$\n-   Demand functions: $q_1 = 100 - 3 p_1 + p_2$ and $q_2 = 100 - 3 p_2 + p_1$.\n-   Marginal costs: $c_1 = 10$ and $c_2 = 20$.\n-   Profit functions: $\\pi_1(p_1,p_2) = (p_1 - c_1) q_1$ and $\\pi_2(p_1,p_2) = (p_2 - c_2) q_2$.\n-   Definition of Nash equilibrium: A price vector $(p_1^\\star, p_2^\\star)$ where $p_1^\\star$ maximizes $\\pi_1(p_1, p_2^\\star)$ and $p_2^\\star$ maximizes $\\pi_2(p_1^\\star, p_2)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a standard exercise in microeconomic game theory.\n-   **Scientifically Grounded**: The model is a classic Bertrand duopoly with differentiated products, a fundamental concept in industrial organization. It is scientifically and mathematically sound.\n-   **Well-Posed**: The problem is well-posed. The objective is clearly stated, and all necessary functions and parameters are provided for finding a unique solution, as suggested by the strict concavity of the profit functions.\n-   **Objective**: The problem is stated using precise mathematical language, free from subjective or ambiguous terms.\n-   **Completeness**: The problem is self-contained and provides all necessary information. There are no contradictions.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be formulated.\n\nThe profit function for each firm $i$ is given by $\\pi_i = (p_i - c_i) q_i$. Substituting the given demand functions and cost parameters yields the profit functions for Firm $1$ and Firm $2$.\n\nFor Firm $1$:\n$$\n\\pi_1(p_1, p_2) = (p_1 - 10)(100 - 3p_1 + p_2)\n$$\nFor Firm $2$:\n$$\n\\pi_2(p_1, p_2) = (p_2 - 20)(100 - 3p_2 + p_1)\n$$\nIn a Nash equilibrium, each firm chooses its price to maximize its own profit, taking the other firm's price as given. This unconstrained optimization problem is solved by finding the first-order condition for each firm.\n\nFirst, we find the best response function for Firm $1$. We differentiate $\\pi_1$ with respect to $p_1$ and set the derivative to zero.\n$$\n\\frac{\\partial \\pi_1}{\\partial p_1} = (1)(100 - 3p_1 + p_2) + (p_1 - 10)(-3) = 0\n$$\n$$\n100 - 3p_1 + p_2 - 3p_1 + 30 = 0\n$$\n$$\n130 - 6p_1 + p_2 = 0\n$$\nSolving for $p_1$ gives Firm $1$'s best response function, $p_1(p_2)$:\n$$\np_1 = \\frac{130 + p_2}{6}\n$$\nTo confirm this is a maximum, we check the second-order condition:\n$$\n\\frac{\\partial^2 \\pi_1}{\\partial p_1^2} = -6  0\n$$\nThe profit function is strictly concave with respect to $p_1$, so the first-order condition identifies a unique profit-maximizing price for any given $p_2$.\n\nNext, we find the best response function for Firm $2$. We differentiate $\\pi_2$ with respect to $p_2$ and set the derivative to zero.\n$$\n\\frac{\\partial \\pi_2}{\\partial p_2} = (1)(100 - 3p_2 + p_1) + (p_2 - 20)(-3) = 0\n$$\n$$\n100 - 3p_2 + p_1 - 3p_2 + 60 = 0\n$$\n$$\n160 - 6p_2 + p_1 = 0\n$$\nSolving for $p_2$ gives Firm $2$'s best response function, $p_2(p_1)$:\n$$\np_2 = \\frac{160 + p_1}{6}\n$$\nThe second-order condition confirms a maximum:\n$$\n\\frac{\\partial^2 \\pi_2}{\\partial p_2^2} = -6  0\n$$\nThe Nash equilibrium is the price vector $(p_1^\\star, p_2^\\star)$ that simultaneously satisfies both best response functions. We must solve the following system of linear equations:\n$$\n\\begin{cases}\np_1^\\star = \\frac{130 + p_2^\\star}{6} \\\\\np_2^\\star = \\frac{160 + p_1^\\star}{6}\n\\end{cases}\n$$\nSubstitute the second equation into the first:\n$$\np_1^\\star = \\frac{1}{6} \\left( 130 + \\frac{160 + p_1^\\star}{6} \\right)\n$$\nMultiply by $6$:\n$$\n6p_1^\\star = 130 + \\frac{160 + p_1^\\star}{6}\n$$\nMultiply by $6$ again to clear the fraction:\n$$\n36p_1^\\star = 6(130) + 160 + p_1^\\star\n$$\n$$\n36p_1^\\star = 780 + 160 + p_1^\\star\n$$\n$$\n35p_1^\\star = 940\n$$\n$$\np_1^\\star = \\frac{940}{35} = \\frac{188 \\times 5}{7 \\times 5} = \\frac{188}{7}\n$$\nNow, substitute the value of $p_1^\\star$ into the best response function for Firm $2$ to find $p_2^\\star$:\n$$\np_2^\\star = \\frac{160 + p_1^\\star}{6} = \\frac{1}{6} \\left( 160 + \\frac{188}{7} \\right)\n$$\n$$\np_2^\\star = \\frac{1}{6} \\left( \\frac{160 \\times 7}{7} + \\frac{188}{7} \\right) = \\frac{1}{6} \\left( \\frac{1120 + 188}{7} \\right)\n$$\n$$\np_2^\\star = \\frac{1}{6} \\left( \\frac{1308}{7} \\right) = \\frac{1308}{42}\n$$\nDividing the numerator and denominator by $6$:\n$$\np_2^\\star = \\frac{1308 \\div 6}{42 \\div 6} = \\frac{218}{7}\n$$\nThus, the unique pure-strategy Nash equilibrium price vector is $(p_1^\\star, p_2^\\star) = (\\frac{188}{7}, \\frac{218}{7})$.",
            "answer": "$$\n\\boxed{\n\\left( \\frac{188}{7}, \\frac{218}{7} \\right)\n}\n$$"
        },
        {
            "introduction": "While analytical solutions are elegant, many real-world optimization problems are too complex to be solved by hand. This practice shifts our focus to computational methods by asking you to implement the gradient descent algorithm, a cornerstone of modern machine learning and computational economics. By coding the algorithm with a backtracking line search, you will gain firsthand experience in how numerical optimizers iteratively find solutions and see how function properties can impact their performance .",
            "id": "2445371",
            "problem": "You are given smooth objective functions in multiple dimensions that arise in computational economics and finance. For each specified test case, construct an iterative unconstrained minimization method that generates a sequence $\\{\\mathbf{x}_k\\}_{k \\ge 0}$ according to $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{d}_k$ with descent direction $\\mathbf{d}_k = -\\nabla f(\\mathbf{x}_k)$. At each iteration $k$, the step length $\\alpha_k$ must be chosen from the geometric sequence $\\{\\alpha_0 \\rho^m: m \\in \\{0,1,2,\\dots\\}\\}$, with $\\alpha_0 \\in (0,\\infty)$ and $\\rho \\in (0,1)$ fixed and common to all test cases, to satisfy the Armijo sufficient decrease condition:\n$$\nf(\\mathbf{x}_k + \\alpha_k \\mathbf{d}_k) \\le f(\\mathbf{x}_k) + c\\,\\alpha_k \\nabla f(\\mathbf{x}_k)^\\top \\mathbf{d}_k,\n$$\nwith a fixed constant $c \\in (0,1)$ common to all test cases. Initialize from the given starting point, and terminate when $\\|\\nabla f(\\mathbf{x}_k)\\|_2 \\le \\varepsilon$ or when $k$ reaches a specified maximum number of iterations. All computations are over the real numbers. Angles are not used. No physical units are involved.\n\nUse the following fixed parameters for all test cases: $\\alpha_0 = 1$, $\\rho = \\tfrac{1}{2}$, $c = 10^{-4}$, $\\varepsilon = 10^{-8}$, and $\\text{max\\_iter} = 10000$.\n\nTest Suite (all matrices and vectors are written explicitly):\n\n- Test case $1$ (mean-variance quadratic in finance):\n  - Decision variable $\\mathbf{w} \\in \\mathbb{R}^2$.\n  - Objective\n    $$\n    f_1(\\mathbf{w}) = \\tfrac{1}{2}\\,\\mathbf{w}^\\top \\boldsymbol{\\Sigma}\\,\\mathbf{w} - \\boldsymbol{\\mu}^\\top \\mathbf{w},\n    \\quad\n    \\boldsymbol{\\Sigma} =\n    \\begin{bmatrix}\n    2  0.8 \\\\\n    0.8  1.5\n    \\end{bmatrix},\n    \\quad\n    \\boldsymbol{\\mu} =\n    \\begin{bmatrix}\n    0.5 \\\\\n    0.3\n    \\end{bmatrix}.\n    $$\n  - Initial condition $\\mathbf{w}_0 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n\n- Test case $2$ (ill-conditioned quadratic):\n  - Decision variable $\\mathbf{x} \\in \\mathbb{R}^2$.\n  - Objective\n    $\n    f_2(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^\\top \\mathbf{H}\\,\\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x},\n    \\quad\n    \\mathbf{H} =\n    \\begin{bmatrix}\n    1000  0 \\\\\n    0  1\n    \\end{bmatrix},\n    \\quad\n    \\mathbf{b} =\n    \\begin{bmatrix}\n    1 \\\\\n    1\n    \\end{bmatrix}.\n    $\n  - Initial condition $\\mathbf{x}_0 = \\begin{bmatrix} 10 \\\\ 10 \\end{bmatrix}$.\n\n- Test case $3$ (negative log-likelihood for binary choice with logistic link, not linearly separable):\n  - Parameter vector $\\boldsymbol{\\theta} \\in \\mathbb{R}^2$.\n  - Data matrix\n    $\n    \\mathbf{X} =\n    \\begin{bmatrix}\n    1  -2 \\\\\n    1  -1 \\\\\n    1  1 \\\\\n    1  2\n    \\end{bmatrix},\n    $\n    label vector\n    $\n    \\mathbf{y} =\n    \\begin{bmatrix}\n    -1 \\\\\n    1 \\\\\n    -1 \\\\\n    1\n    \\end{bmatrix}.\n    $\n  - Objective\n    $$\n    f_3(\\boldsymbol{\\theta}) = \\sum_{i=1}^{4} \\log\\!\\big(1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})\\big),\n    $$\n    where $\\mathbf{x}_i^\\top$ is the $i$-th row of $\\mathbf{X}$ and $y_i$ is the $i$-th entry of $\\mathbf{y}$.\n  - Initial condition $\\boldsymbol{\\theta}_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$.\n\nFor each test case, run the iterative minimization with the common parameters above and report the minimized objective value $f(\\mathbf{x}^\\star)$ at termination. Your program must not read any input. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, with each entry rounded to six decimal places, for example, $[0.123456,1.234567,2.345678]$.",
            "solution": "The problem statement has been rigorously evaluated and is determined to be valid. It presents a clear, mathematically sound, and well-posed set of tasks in the field of unconstrained optimization. The objective functions are standard examples from computational economics and finance, and all required parameters and initial conditions are provided without ambiguity or contradiction. The specified algorithm, gradient descent with a backtracking line search based on the Armijo condition, is a fundamental and appropriate method for solving such problems. We shall now proceed with the formal derivation and solution.\n\nThe core of the problem is to implement the method of steepest descent for minimizing a smooth function $f: \\mathbb{R}^n \\to \\mathbb{R}$. This is an iterative algorithm that generates a sequence of points $\\{\\mathbf{x}_k\\}_{k \\ge 0}$ using the update rule:\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{d}_k\n$$\nThe direction $\\mathbf{d}_k$ is chosen as the negative gradient of the objective function at the current iterate $\\mathbf{x}_k$, which is the direction of steepest descent:\n$$\n\\mathbf{d}_k = -\\nabla f(\\mathbf{x}_k)\n$$\nThe step length $\\alpha_k > 0$ is determined by a backtracking line search procedure to ensure sufficient decrease in the objective function value. Starting with an initial guess $\\alpha = \\alpha_0$, the step length is successively reduced by a factor $\\rho \\in (0,1)$ until the Armijo condition is satisfied:\n$$\nf(\\mathbf{x}_k + \\alpha \\mathbf{d}_k) \\le f(\\mathbf{x}_k) + c\\,\\alpha \\nabla f(\\mathbf{x}_k)^\\top \\mathbf{d}_k\n$$\nwhere $c \\in (0,1)$ is a small constant. The given parameters are fixed for all test cases as $\\alpha_0 = 1$, $\\rho = \\frac{1}{2}$, and $c = 10^{-4}$.\n\nThe algorithm terminates and reports the current point $\\mathbf{x}_k$ as the approximate minimizer $\\mathbf{x}^\\star$ when the Euclidean norm of the gradient is below a specified tolerance $\\varepsilon = 10^{-8}$, or when the number of iterations $k$ reaches the maximum limit $\\text{max\\_iter} = 10000$.\n\nWe now apply this general procedure to the three specified test cases.\n\n**Test Case 1: Mean-Variance Quadratic**\nThe objective function is a standard quadratic form from portfolio optimization:\n$$\nf_1(\\mathbf{w}) = \\tfrac{1}{2}\\,\\mathbf{w}^\\top \\boldsymbol{\\Sigma}\\,\\mathbf{w} - \\boldsymbol{\\mu}^\\top \\mathbf{w}\n$$\nwhere $\\mathbf{w} \\in \\mathbb{R}^2$, $\\boldsymbol{\\Sigma} = \\begin{bmatrix} 2  0.8 \\\\ 0.8  1.5 \\end{bmatrix}$, and $\\boldsymbol{\\mu} = \\begin{bmatrix} 0.5 \\\\ 0.3 \\end{bmatrix}$. The gradient of a general quadratic function $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x}$ for a symmetric matrix $\\mathbf{A}$ is $\\nabla f(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$. Therefore, the gradient for $f_1$ is:\n$$\n\\nabla f_1(\\mathbf{w}) = \\boldsymbol{\\Sigma}\\,\\mathbf{w} - \\boldsymbol{\\mu}\n$$\nThe Hessian of $f_1$ is $\\nabla^2 f_1(\\mathbf{w}) = \\boldsymbol{\\Sigma}$. The matrix $\\boldsymbol{\\Sigma}$ is symmetric and its eigenvalues are approximately $2.55$ and $0.95$, which are both positive. Thus, $\\boldsymbol{\\Sigma}$ is positive definite, which implies that $f_1$ is strictly convex and possesses a unique global minimum. The steepest descent algorithm is guaranteed to converge to this minimum. The algorithm is initialized from $\\mathbf{w}_0 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n\n**Test Case 2: Ill-Conditioned Quadratic**\nThe objective function is another quadratic:\n$$\nf_2(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^\\top \\mathbf{H}\\,\\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x}\n$$\nwith $\\mathbf{x} \\in \\mathbb{R}^2$, $\\mathbf{H} = \\begin{bmatrix} 1000  0 \\\\ 0  1 \\end{bmatrix}$, and $\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$. The gradient is:\n$$\n\\nabla f_2(\\mathbf{x}) = \\mathbf{H}\\,\\mathbf{x} - \\mathbf{b}\n$$\nThe Hessian matrix $\\mathbf{H}$ is positive definite, as its eigenvalues are $1000$ and $1$. Consequently, $f_2$ is strictly convex with a unique minimum. The condition number of $\\mathbf{H}$ is the ratio of its largest to smallest eigenvalue, which is $1000/1 = 1000$. This high condition number implies that the level sets of $f_2$ are highly elongated ellipses, which typically slows down the convergence of the steepest descent method. The algorithm starts from $\\mathbf{x}_0 = \\begin{bmatrix} 10 \\\\ 10 \\end{bmatrix}$.\n\n**Test Case 3: Negative Log-Likelihood for Binary Choice**\nThe objective function is the negative log-likelihood for a logistic regression model:\n$$\nf_3(\\boldsymbol{\\theta}) = \\sum_{i=1}^{4} \\log\\!\\big(1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})\\big)\n$$\nwhere $\\boldsymbol{\\theta} \\in \\mathbb{R}^2$. To find the gradient, we differentiate with respect to a component $\\theta_j$ of $\\boldsymbol{\\theta}$:\n$$\n\\frac{\\partial f_3}{\\partial \\theta_j} = \\sum_{i=1}^{4} \\frac{1}{1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})} \\cdot \\frac{\\partial}{\\partial \\theta_j} \\left(1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})\\right)\n$$\n$$\n= \\sum_{i=1}^{4} \\frac{\\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})}{1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})} \\cdot (-y_i x_{ij})\n$$\nLet $\\sigma(z) = 1/(1+e^{-z})$ be the logistic sigmoid function. The expression $\\frac{\\exp(-z)}{1+\\exp(-z)}$ can be rewritten as $\\frac{1}{e^z+1} = \\sigma(-z)$.\nThus, the gradient vector $\\nabla f_3(\\boldsymbol{\\theta})$ has components:\n$$\n[\\nabla f_3(\\boldsymbol{\\theta})]_j = \\sum_{i=1}^{4} \\sigma(-y_i \\mathbf{x}_i^\\top \\boldsymbol{\\theta}) (-y_i x_{ij})\n$$\nThis can be written compactly in vector form. Let $\\mathbf{p}$ be a vector with elements $p_i = \\sigma(y_i \\mathbf{x}_i^\\top \\boldsymbol{\\theta})$. Using the identity $\\sigma(-z) = 1 - \\sigma(z)$, the gradient is:\n$$\n\\nabla f_3(\\boldsymbol{\\theta}) = \\sum_{i=1}^{4} (1-p_i) (-y_i \\mathbf{x}_i) = \\sum_{i=1}^{4} y_i(p_i-1) \\mathbf{x}_i = \\mathbf{X}^\\top (\\mathbf{y} \\odot (\\mathbf{p} - \\mathbf{1}))\n$$\nwhere $\\odot$ denotes element-wise multiplication and $\\mathbf{1}$ is a vector of ones. The Hessian of this function can be shown to be positive semi-definite. Since the data matrix $\\mathbf{X}$ has linearly independent columns (full column rank), the Hessian is in fact positive definite, ensuring $f_3$ is strictly convex with a unique minimizer. The algorithm is initialized from the origin, $\\boldsymbol{\\theta}_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$. For numerical stability, the computation of $\\log(1+e^z)$ is performed using a log-sum-exp pattern.\n\nThe algorithm is implemented in software following these derivations to compute the final objective values for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit, logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the unconstrained optimization problems defined in the test suite\n    using the gradient descent method with backtracking line search.\n    \"\"\"\n    \n    # Define common parameters for the optimization algorithm\n    alpha0 = 1.0\n    rho = 0.5\n    c = 1e-4\n    epsilon = 1e-8\n    max_iter = 10000\n\n    def gradient_descent(f, grad_f, x0):\n        \"\"\"\n        Generic implementation of gradient descent with backtracking line search.\n\n        Args:\n            f (callable): The objective function.\n            grad_f (callable): The gradient of the objective function.\n            x0 (np.ndarray): The initial starting point.\n\n        Returns:\n            float: The minimized objective function value at termination.\n        \"\"\"\n        x = np.copy(x0).astype(np.float64)\n        \n        for k in range(max_iter):\n            grad = grad_f(x)\n            grad_norm = np.linalg.norm(grad)\n\n            # Termination condition: norm of the gradient is small enough\n            if grad_norm = epsilon:\n                break\n            \n            d = -grad  # Steepest descent direction\n            \n            # Backtracking line search to find step length alpha\n            alpha = alpha0\n            fx = f(x)\n            grad_dot_d = np.dot(grad, d)\n            \n            # Armijo condition check\n            while f(x + alpha * d) > fx + c * alpha * grad_dot_d:\n                alpha = rho * alpha\n            \n            # Update the iterate\n            x = x + alpha * d\n            \n        return f(x)\n\n    results = []\n\n    # Test Case 1: Mean-variance quadratic\n    Sigma = np.array([[2.0, 0.8], [0.8, 1.5]])\n    mu = np.array([0.5, 0.3])\n    w0 = np.array([1.0, 1.0])\n    \n    def f1(w):\n        return 0.5 * w.T @ Sigma @ w - mu.T @ w\n    \n    def grad_f1(w):\n        return Sigma @ w - mu\n        \n    result1 = gradient_descent(f1, grad_f1, w0)\n    results.append(result1)\n\n    # Test Case 2: Ill-conditioned quadratic\n    H = np.array([[1000.0, 0.0], [0.0, 1.0]])\n    b = np.array([1.0, 1.0])\n    x0_2 = np.array([10.0, 10.0])\n\n    def f2(x):\n        return 0.5 * x.T @ H @ x - b.T @ x\n    \n    def grad_f2(x):\n        return H @ x - b\n        \n    result2 = gradient_descent(f2, grad_f2, x0_2)\n    results.append(result2)\n\n    # Test Case 3: Negative log-likelihood for binary choice\n    X = np.array([[1.0, -2.0], [1.0, -1.0], [1.0, 1.0], [1.0, 2.0]])\n    y = np.array([-1.0, 1.0, -1.0, 1.0])\n    theta0 = np.array([0.0, 0.0])\n\n    def f3(theta):\n        # log(1+exp(z)) is computed robustly as log(exp(0)+exp(z))\n        z = -y * (X @ theta)\n        return np.sum(logsumexp(np.vstack((np.zeros_like(z), z)), axis=0))\n\n    def grad_f3(theta):\n        # Gradient of sum_i log(1+exp(-y_i*x_i'theta)) is sum_i y_i(p_i-1)x_i\n        # where p_i = sigmoid(y_i*x_i'theta)\n        h = y * (X @ theta)\n        p = expit(h)  # Numerically stable sigmoid function\n        # Vectorized gradient calculation\n        return X.T @ (y * (p - 1.0))\n        \n    result3 = gradient_descent(f3, grad_f3, theta0)\n    results.append(result3)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}