{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex implementations, it's crucial to understand the fundamental behavior of optimization algorithms at stationary points. This thought experiment explores a classic failure mode for line-search methods when started at a local maximum. By analyzing this simple case, you will gain insight into why algorithms must do more than just find a point where the gradient is zero. ",
            "id": "2461264",
            "problem": "In molecular geometry optimization within computational chemistry, a common goal is to find a local minimum of a potential energy surface. Consider the smooth potential surface given by the perfectly symmetric hill $$f(x,y) = -x^2 - y^2,$$ and suppose you attempt to minimize it starting from the exact top at $$x = 0, \\; y = 0.$$ You use a standard line-search quasi-Newton method designed for unconstrained minimization (for example, a Broyden–Fletcher–Goldfarb–Shanno method), with an initial inverse metric that is positive definite and a typical Wolfe-type line search. Assume exact arithmetic and no perturbations or regularization.\n\nFrom first principles, recall that a stationary point satisfies $$\\nabla f = 0,$$ that a descent direction $$p$$ for a differentiable function at a point with gradient $$g$$ must satisfy $$g^\\top p  0,$$ and that line-search methods generate trial steps by choosing a direction and then selecting a step length to reduce the objective.\n\nWhich outcome best describes what happens and why?\n\nA. The method immediately terminates at the starting point because the computed search direction is the zero vector and the line search cannot reduce the objective; it reports convergence to a stationary point even though the point is a maximizer.\n\nB. The method takes a step of arbitrary nonzero length along an arbitrary direction because the negative-definite curvature forces the line search to move to the boundary of a trust region, escaping the top.\n\nC. The method computes a Newton step that initially points uphill and is rejected by the Wolfe conditions; this triggers an update that makes the metric negative definite, after which the method rapidly finds a nearby minimum.\n\nD. The method enters a cycling behavior, alternating between orthogonal directions with small steps due to the symmetry of the surface, until numerical noise breaks the cycle.",
            "solution": "The problem statement must first be validated for scientific and logical integrity.\n\nStep 1: Extract Givens\n- Objective function: a smooth potential surface given by $$f(x,y) = -x^2 - y^2$$.\n- Starting point: $$(x_0, y_0) = (0, 0)$$.\n- Optimization algorithm: A standard line-search quasi-Newton method (e.g., BFGS).\n- Initial inverse metric (inverse Hessian approximation) $$H_0$$: Positive definite.\n- Line search conditions: Wolfe-type.\n- Assumptions: Exact arithmetic, no perturbations or regularization.\n- Provided definitions for recall:\n    - Stationary point condition: $$\\nabla f = 0$$.\n    - Descent direction $$p$$ for gradient $$g$$: $$g^\\top p  0$$.\n    - Line-search method operation: Choose a direction, then select a step length.\n\nStep 2: Validate Using Extracted Givens\nThe problem describes a classic test case for an unconstrained optimization algorithm. The function $$f(x,y)$$ is a simple, infinitely differentiable quadratic function. The starting point is its unique stationary point. The algorithm specified is a standard workhorse in numerical optimization and computational chemistry. The initial conditions (positive definite $$H_0$$) and assumptions (exact arithmetic) are standard for theoretical analysis of such algorithms.\n\n- **Scientific Grounding**: The problem is well-grounded in the theory of numerical optimization and its application to computational chemistry. The concepts used are fundamental and correctly stated.\n- **Well-Posedness**: The problem is well-posed. The function, starting point, and algorithm type are clearly defined, leading to a determinable outcome.\n- **Objectivity**: The problem is stated in precise, objective mathematical language.\n\nThe problem does not violate any of the invalidity criteria. It is a valid, formalizable problem in numerical analysis.\n\nStep 3: Verdict and Action\nThe problem is valid. I will now proceed with the solution derivation.\n\nThe task is to determine the outcome of applying a line-search quasi-Newton method to minimize the function $$f(x,y) = -x^2 - y^2$$, starting from the point $$(0,0)$$.\n\nLet the vector of variables be $$x_{vec} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$$. The objective function is $$f(x_{vec}) = -x_{vec}^\\top x_{vec}$$. The starting point is $$x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$.\n\nA line-search quasi-Newton iteration proceeds as follows:\n1.  At step $$k$$, compute the gradient $$g_k = \\nabla f(x_k)$$.\n2.  Check for convergence. A standard condition for termination is that the norm of the gradient is sufficiently small, i.e., $$||g_k||  \\epsilon$$, where $$\\epsilon$$ is a small positive tolerance.\n3.  Compute a search direction $$p_k$$ using the current approximation of the inverse Hessian, $$H_k$$. The direction is given by $$p_k = -H_k g_k$$.\n4.  Perform a line search to find a suitable step length $$\\alpha_k  0$$ such that the Wolfe conditions are satisfied for the new point $$x_{k+1} = x_k + \\alpha_k p_k$$.\n5.  Update the position to $$x_{k+1}$$ and update the inverse Hessian approximation to $$H_{k+1}$$.\n\nLet us analyze the first iteration ($$k=0$$).\nThe starting point is $$x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$.\nFirst, we compute the gradient of $$f(x,y) = -x^2 - y^2$$.\nThe gradient is $$g(x,y) = \\nabla f(x,y) = \\begin{pmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} -2x \\\\ -2y \\end{pmatrix}$$.\n\nAt the starting point $$x_0$$, the gradient is:\n$$g_0 = g(0,0) = \\begin{pmatrix} -2(0) \\\\ -2(0) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = 0$$.\n\nThe problem states that we are using exact arithmetic. The gradient at the starting point is exactly the zero vector.\nThe first step of the algorithm is to check for convergence. Since $$||g_0|| = 0$$, the convergence criterion $$||g_k||  \\epsilon$$ is satisfied for any $$\\epsilon  0$$. Therefore, the algorithm must terminate immediately at iteration $$k=0$$.\n\nIf, for a moment, we ignored the termination check and proceeded to calculate the search direction, we would have:\n$$p_0 = -H_0 g_0$$\nSince $$g_0 = 0$$, the search direction is $$p_0 = -H_0 \\cdot 0 = 0$$. The search direction is the zero vector, regardless of the initial inverse Hessian approximation $$H_0$$.\n\nWith a zero search direction, any subsequent step is of the form $$x_1 = x_0 + \\alpha_0 p_0 = x_0 + \\alpha_0 \\cdot 0 = x_0$$. No movement from the starting point is possible, and the objective function value cannot be changed, let alone reduced. A line search for $$\\alpha_0  0$$ would fail to find any step that produces a strict decrease in $$f$$.\n\nThe nature of the stationary point is determined by the Hessian matrix of second derivatives:\n$$H_f(x,y) = \\nabla^2 f(x,y) = \\begin{pmatrix} -2  0 \\\\ 0  -2 \\end{pmatrix}$$\nThe eigenvalues of this matrix are both $$-2$$. Since the eigenvalues are all negative, the Hessian is negative definite, and the stationary point at $$(0,0)$$ is a strict local maximum. The algorithm is intended for minimization, but it has found a stationary point. It is not the algorithm's primary responsibility to classify the point; it is designed to find points where the gradient is zero.\n\nBased on this analysis, the method will immediately stop and report that it has converged to a stationary point.\n\nNow, we evaluate the given options.\n\nA. The method immediately terminates at the starting point because the computed search direction is the zero vector and the line search cannot reduce the objective; it reports convergence to a stationary point even though the point is a maximizer.\n- This statement accurately describes the sequence of events. The gradient is zero, so the algorithm terminates based on the standard $$||g||=0$$ criterion. If it were to proceed, the search direction $$p_0$$ would be the zero vector. No move can be made to reduce the objective function. The algorithm reports convergence because it has found a point with zero gradient. This point is indeed a maximizer.\n- Verdict: **Correct**.\n\nB. The method takes a step of arbitrary nonzero length along an arbitrary direction because the negative-definite curvature forces the line search to move to the boundary of a trust region, escaping the top.\n- This option incorrectly describes the algorithm. The problem specifies a line-search method, not a trust-region method. Trust-region methods have mechanisms to handle non-positive definite Hessians, but they operate differently. In a line-search method, the search direction is computed first ($$p_0 = 0$$ in this case), and then a step length is sought. The direction is not arbitrary; it is deterministically zero. The concept of a trust region boundary is not applicable.\n- Verdict: **Incorrect**.\n\nC. The method computes a Newton step that initially points uphill and is rejected by the Wolfe conditions; this triggers an update that makes the metric negative definite, after which the method rapidly finds a nearby minimum.\n- The method computes a quasi-Newton step, not a Newton step. The step direction is $$p_0 = -H_0 g_0 = 0$$, which is the zero vector. A direction $$p$$ is \"uphill\" only if $$g^\\top p  0$$. Here, $$g_0^\\top p_0 = 0^\\top 0 = 0$$. The direction is not uphill. Since no step is taken ($$s_0 = x_1 - x_0 = 0$$), the Hessian approximation is not updated. The algorithm terminates, so it does not proceed to find any other point.\n- Verdict: **Incorrect**.\n\nD. The method enters a cycling behavior, alternating between orthogonal directions with small steps due to the symmetry of the surface, until numerical noise breaks the cycle.\n- The algorithm terminates at the first step because the gradient is zero. It does not take any steps, small or otherwise. Therefore, no cycling behavior can occur. The problem also explicitly assumes \"exact arithmetic,\" which precludes the influence of numerical noise.\n- Verdict: **Incorrect**.\n\nThe only correct description of the outcome is provided in option A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Quasi-Newton methods are the workhorses of geometry optimization, but not all are created equal. This exercise challenges you to implement and compare two historically important updates: the Davidon–Fletcher–Powell (DFP) and the Broyden–Fletcher–Goldfarb–Shanno (BFGS) formulas. By observing their performance on a challenging potential energy surface, you will discover firsthand why BFGS is the preferred method in modern computational chemistry software. ",
            "id": "2461204",
            "problem": "You must write a complete and runnable program that compares two quasi-Newton optimization methods on a two-dimensional, smooth potential energy surface intended to model a coupled bond-stretch and angle-bend in reduced units. Let the decision variables be $u$ (a reduced bond-length displacement) and $v$ (a reduced angular displacement in radians). Define the potential energy function\n$$\nV(u,v) \\;=\\; \\tfrac{1}{2}\\,k_r\\,(u - r_0)^2 \\;+\\; \\tfrac{1}{2}\\,k_{\\theta}\\,(v - \\theta_0)^2 \\;+\\; k_c\\,(u - r_0)^2\\,(v - \\theta_0) \\;+\\; \\gamma\\,\\big(u - r_0 - \\alpha\\,(v - \\theta_0)^2\\big)^2,\n$$\nwhere $k_r$, $k_{\\theta}$, $k_c$, $\\gamma$, $\\alpha$, $r_0$, and $\\theta_0$ are real parameters. All quantities are treated as dimensionless reduced units, with angular displacements $v$ measured in radians.\n\nYour program must minimize $V(u,v)$ in $\\mathbb{R}^2$ from given starting points using two different inverse-Hessian update formulas at each iteration $k$:\n- The Davidon–Fletcher–Powell (DFP) update for the inverse Hessian approximation $H_k \\in \\mathbb{R}^{2 \\times 2}$,\n$$\nH_{k+1} \\;=\\; H_k \\;+\\; \\frac{s_k s_k^{\\mathsf{T}}}{s_k^{\\mathsf{T}} y_k} \\;-\\; \\frac{H_k y_k y_k^{\\mathsf{T}} H_k}{y_k^{\\mathsf{T}} H_k y_k},\n$$\n- The Broyden–Fletcher–Goldfarb–Shanno (BFGS) update for the inverse Hessian approximation $H_k$,\n$$\nH_{k+1} \\;=\\; \\big(I - \\rho_k s_k y_k^{\\mathsf{T}}\\big)\\,H_k\\,\\big(I - \\rho_k y_k s_k^{\\mathsf{T}}\\big) \\;+\\; \\rho_k\\, s_k s_k^{\\mathsf{T}}, \\quad \\rho_k \\;=\\; \\frac{1}{y_k^{\\mathsf{T}} s_k},\n$$\nwhere $s_k = x_{k+1} - x_k$ and $y_k = \\nabla V(x_{k+1}) - \\nabla V(x_k)$ with $x_k = \\begin{bmatrix}u_k \\\\ v_k\\end{bmatrix}$, and $I$ is the $2 \\times 2$ identity matrix. At each iteration, the search direction must be $p_k = - H_k \\nabla V(x_k)$ and the step $x_{k+1} = x_k + \\alpha_k p_k$ for some scalar step length $\\alpha_k \\gt 0$. The algorithm must terminate successfully if $\\lVert \\nabla V(x_k)\\rVert_2 \\leq \\varepsilon$ for a specified tolerance $\\varepsilon$; otherwise it is deemed to have failed to converge within a specified maximum number of iterations.\n\nYou must apply both update formulas to each of the following three test cases. In all cases use the same termination tolerance $\\varepsilon = 10^{-5}$ and the Euclidean norm. The identity matrix must be used as the initial inverse Hessian approximation $H_0$.\n\nTest Suite:\n1. Case A (well-conditioned valley, general happy path): parameters $k_r = 1$, $k_{\\theta} = 1$, $k_c = 0.1$, $\\gamma = 100$, $\\alpha = 1$, $r_0 = 0$, $\\theta_0 = 0$; starting point $x_0 = \\begin{bmatrix}-1.5 \\\\ 1.0\\end{bmatrix}$; maximum iterations $N_{\\max} = 200$.\n2. Case B (highly curved, anisotropic valley intended to stress the update): parameters $k_r = 1$, $k_{\\theta} = 1$, $k_c = 0.2$, $\\gamma = 10^6$, $\\alpha = 10$, $r_0 = 0$, $\\theta_0 = 0$; starting point $x_0 = \\begin{bmatrix}3.0 \\\\ -2.0\\end{bmatrix}$; maximum iterations $N_{\\max} = 60$.\n3. Case C (boundary condition at the minimizer): parameters $k_r = 1$, $k_{\\theta} = 1$, $k_c = 0$, $\\gamma = 50$, $\\alpha = 0.5$, $r_0 = 0$, $\\theta_0 = 0$; starting point $x_0 = \\begin{bmatrix}0.0 \\\\ 0.0\\end{bmatrix}$; maximum iterations $N_{\\max} = 1$.\n\nYour program must, for each case, return two boolean values indicating whether the DFP-based optimization converged and whether the BFGS-based optimization converged, respectively, according to the stopping criterion $\\lVert \\nabla V(x_k)\\rVert_2 \\leq \\varepsilon$ within the iteration cap. Aggregate the six boolean results for Cases A, B, and C, in that order, into a single output line as a Python-style list literal with elements separated by commas and no spaces, namely\n- Output format: a single line containing [bA_DFP,bA_BFGS,bB_DFP,bB_BFGS,bC_DFP,bC_BFGS],\nwhere each b... is either True or False.\n\nAngles must be interpreted in radians. No other physical units are required in the output. You must ensure that the program’s output exactly matches the specified format in a single print statement.",
            "solution": "The problem as stated constitutes a valid and well-defined task in numerical optimization, specifically within the context of computational chemistry for potential energy surface minimization. Before proceeding to the solution, a critical validation is necessary.\n\nThe givens are:\n- A potential energy function $V(u,v) = \\tfrac{1}{2}\\,k_r\\,(u - r_0)^2 + \\tfrac{1}{2}\\,k_{\\theta}\\,(v - \\theta_0)^2 + k_c\\,(u - r_0)^2\\,(v - \\theta_0) + \\gamma\\,\\big(u - r_0 - \\alpha\\,(v - \\theta_0)^2\\big)^2$.\n- Two quasi-Newton update formulas for the inverse Hessian approximation $H_k$: Davidon–Fletcher–Powell (DFP) and Broyden–Fletcher–Goldfarb–Shanno (BFGS).\n- An iterative scheme: $x_{k+1} = x_k + \\alpha_k p_k$ with search direction $p_k = - H_k \\nabla V(x_k)$.\n- Initial inverse Hessian: $H_0 = I$.\n- Termination criterion: $\\lVert \\nabla V(x_k)\\rVert_2 \\leq \\varepsilon$ with $\\varepsilon = 10^{-5}$.\n- Three test cases (A, B, C) with specified parameters ($k_r, k_{\\theta}, k_c, \\gamma, \\alpha, r_0, \\theta_0$), starting points $x_0$, and maximum iterations $N_{\\max}$.\n\nThe problem is scientifically grounded, employing standard models and algorithms from computational science. However, the statement, \"the step $x_{k+1} = x_k + \\alpha_k p_k$ for some scalar step length $\\alpha_k  0$,\" is incomplete. The method for determining $\\alpha_k$ is not specified. For a quasi-Newton method to be robust and for the comparison between DFP and BFGS to be meaningful, $\\alpha_k$ must be chosen systematically via a line search procedure. A naive choice (e.g., a fixed $\\alpha_k=1$) would lead to poor performance or divergence, invalidating the comparison. Therefore, it is assumed that a standard line search algorithm must be used to find a step length $\\alpha_k$ that satisfies the Strong Wolfe conditions. This ensures both a sufficient decrease in the potential energy and that the curvature condition $y_k^{\\mathsf{T}} s_k  0$ holds, which is essential for the stability and positive-definiteness of the BFGS update. This assumption makes the problem well-posed and solvable. The provided test cases are objective and verifiable. Case C, where the starting point is the minimum, correctly tests the termination logic at iteration $k=0$. The problem is thus validated as solvable under this necessary and standard assumption.\n\nThe solution requires implementing a quasi-Newton optimization framework. The core of the algorithm is to iteratively build an approximation to the inverse of the Hessian matrix, $H_k \\approx (\\nabla^2 V(x_k))^{-1}$, to guide the search for a minimum of the potential energy function $V(x)$, where $x = [u, v]^{\\mathsf{T}}$.\n\nFirst, we must derive the analytical gradient of the potential energy function $V(u,v)$. Let $\\Delta u = u - r_0$ and $\\Delta v = v - \\theta_0$. The function is:\n$$V(u,v) = \\tfrac{1}{2} k_r (\\Delta u)^2 + \\tfrac{1}{2} k_\\theta (\\Delta v)^2 + k_c (\\Delta u)^2 (\\Delta v) + \\gamma (\\Delta u - \\alpha (\\Delta v)^2)^2$$\nThe gradient, $\\nabla V(u,v) = \\begin{bmatrix} \\partial V / \\partial u \\\\ \\partial V / \\partial v \\end{bmatrix}$, is:\n$$ \\frac{\\partial V}{\\partial u} = k_r (\\Delta u) + 2 k_c (\\Delta u)(\\Delta v) + 2\\gamma\\big(\\Delta u - \\alpha (\\Delta v)^2\\big) $$\n$$ \\frac{\\partial V}{\\partial v} = k_\\theta (\\Delta v) + k_c (\\Delta u)^2 - 4\\alpha\\gamma (\\Delta v)\\big(\\Delta u - \\alpha (\\Delta v)^2\\big) $$\n\nThe optimization algorithm for each method (DFP and BFGS) proceeds as follows:\n1.  Initialize iteration counter $k = 0$, the position vector $x_0$, and the inverse Hessian approximation $H_0 = I$, where $I$ is the $2 \\times 2$ identity matrix.\n2.  Calculate the initial gradient $\\nabla V(x_0)$. If its Euclidean norm $\\lVert \\nabla V(x_0) \\rVert_2 \\leq \\varepsilon = 10^{-5}$, the process terminates successfully. This is the case for Test Case C.\n3.  For $k = 0, 1, \\dots, N_{\\max}-1$:\n    a. Compute the search direction: $p_k = -H_k \\nabla V(x_k)$.\n    b. Perform a line search to find a suitable step length $\\alpha_k  0$. The search must find an $\\alpha_k$ that satisfies the Strong Wolfe conditions, which guarantees both sufficient decrease in $V$ and satisfaction of the curvature condition. If the line search fails to find such a step, the optimization fails.\n    c. Update the position: $x_{k+1} = x_k + \\alpha_k p_k$.\n    d. Define the change in position $s_k = x_{k+1} - x_k$ and the change in gradient $y_k = \\nabla V(x_{k+1}) - \\nabla V(x_k)$.\n    e. The curvature condition $y_k^{\\mathsf{T}} s_k  0$ is guaranteed by a successful line search. This quantity is used in the denominators of both update formulas.\n    f. Update the inverse Hessian approximation $H_k$ to $H_{k+1}$ using either the DFP or BFGS formula.\n        -   **DFP update:**\n            $$ H_{k+1} = H_k + \\frac{s_k s_k^{\\mathsf{T}}}{s_k^{\\mathsf{T}} y_k} - \\frac{H_k y_k y_k^{\\mathsf{T}} H_k}{y_k^{\\mathsf{T}} H_k y_k} $$\n            The DFP update is numerically sensitive and can lose positive definiteness. A safeguard is implemented: if the denominator $y_k^{\\mathsf{T}} H_k y_k$ is close to zero or negative, the update is skipped and we set $H_{k+1} = H_k$.\n        -   **BFGS update:**\n            $$ H_{k+1} = \\big(I - \\rho_k s_k y_k^{\\mathsf{T}}\\big)\\,H_k\\,\\big(I - \\rho_k y_k s_k^{\\mathsf{T}}\\big) + \\rho_k\\, s_k s_k^{\\mathsf{T}}, \\quad \\text{where } \\rho_k = \\frac{1}{y_k^{\\mathsf{T}} s_k} $$\n            The BFGS update is known to be more robust and maintains positive definiteness of $H_k$ if $H_0$ is positive definite and the curvature condition holds.\n    g. Check for termination: if $\\lVert \\nabla V(x_{k+1}) \\rVert_2 \\leq \\varepsilon$, the process terminates successfully. Note that we check the gradient at the *new* point before starting the next iteration. My implementation checks at the beginning of the loop for point $x_k$, which is equivalent.\n4.  If the loop completes without meeting the convergence criterion, the optimization has failed to converge within $N_{\\max}$ iterations.\n\nThe program will execute this algorithm for each of the three test cases using both DFP and BFGS updates and report a boolean value for each of the six runs, indicating success (True) or failure (False).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import line_search\n\ndef get_potential_and_gradient(params):\n    \"\"\"\n    Creates the potential energy function V and its gradient grad_V for a given set of parameters.\n    \"\"\"\n    kr, ktheta, kc, gamma, alpha, r0, theta0 = params\n\n    def V(x):\n        u, v = x\n        du = u - r0\n        dv = v - theta0\n        term1 = 0.5 * kr * du**2\n        term2 = 0.5 * ktheta * dv**2\n        term3 = kc * du**2 * dv\n        term4 = gamma * (du - alpha * dv**2)**2\n        return term1 + term2 + term3 + term4\n\n    def grad_V(x):\n        u, v = x\n        du = u - r0\n        dv = v - theta0\n        \n        common_term = du - alpha * dv**2\n        \n        # dV/du\n        grad_u = kr * du + 2.0 * kc * du * dv + 2.0 * gamma * common_term\n        \n        # dV/dv\n        grad_v = ktheta * dv + kc * du**2 - 4.0 * alpha * gamma * dv * common_term\n        \n        return np.array([grad_u, grad_v], dtype=float)\n        \n    return V, grad_V\n\ndef quasi_newton_optimizer(potential_params, x0, n_max, epsilon, update_formula):\n    \"\"\"\n    Performs minimization of a potential energy surface using a quasi-Newton method.\n\n    Args:\n        potential_params: Tuple of parameters for the potential function.\n        x0: Initial guess for the coordinates [u, v].\n        n_max: Maximum number of iterations.\n        epsilon: Convergence tolerance for the gradient norm.\n        update_formula: String specifying the update formula ('DFP' or 'BFGS').\n\n    Returns:\n        bool: True if converged, False otherwise.\n    \"\"\"\n    V, grad_V = get_potential_and_gradient(potential_params)\n    \n    x_k = np.array(x0, dtype=float)\n    H_k = np.identity(2, dtype=float)\n    \n    # Check for convergence at the starting point\n    grad_k = grad_V(x_k)\n    if np.linalg.norm(grad_k) = epsilon:\n        return True\n\n    for k in range(n_max):\n        # Compute search direction\n        p_k = -np.dot(H_k, grad_k)\n        \n        # Perform line search to find step length alpha_k\n        # scipy.optimize.line_search finds a step satisfying the Strong Wolfe conditions\n        alpha_k, _, _, _, _, _ = line_search(V, grad_V, x_k, p_k, gfk=grad_k, maxiter=100)\n        \n        # If line search fails, optimization has failed\n        if alpha_k is None:\n            return False\n            \n        # Update position\n        s_k = alpha_k * p_k\n        x_k_plus_1 = x_k + s_k\n        \n        # Calculate new gradient and check for convergence\n        grad_k_plus_1 = grad_V(x_k_plus_1)\n        if np.linalg.norm(grad_k_plus_1) = epsilon:\n            return True\n            \n        # Define y_k for the Hessian update\n        y_k = grad_k_plus_1 - grad_k\n        \n        # The curvature condition y_k.T @ s_k  0 is guaranteed by the Wolfe conditions\n        # from a successful line search. The denominator will be positive.\n        denom_sy = np.dot(y_k.T, s_k)\n\n        # Avoid updating if curvature condition is not sufficiently positive\n        if denom_sy = 1e-9:\n             x_k = x_k_plus_1\n             grad_k = grad_k_plus_1\n             continue\n\n        # Update inverse Hessian approximation H_k\n        if update_formula == 'DFP':\n            term1_numerator = np.outer(s_k, s_k)\n            term1 = term1_numerator / denom_sy\n            \n            Hy = np.dot(H_k, y_k)\n            yHy = np.dot(y_k.T, Hy)\n            \n            # Safeguard for DFP: skip update if H_k is not positive definite\n            # along the y_k direction.\n            if yHy = 1e-9:\n                H_k_plus_1 = H_k\n            else:\n                term2_numerator = np.outer(Hy, Hy)\n                term2 = term2_numerator / yHy\n                H_k_plus_1 = H_k + term1 - term2\n        \n        elif update_formula == 'BFGS':\n            rho_k = 1.0 / denom_sy\n            I = np.identity(2, dtype=float)\n            \n            # Use the more stable implementation for BFGS update\n            term_mat = I - rho_k * np.outer(s_k, y_k)\n            H_k_plus_1 = np.dot(term_mat, np.dot(H_k, term_mat.T)) + rho_k * np.outer(s_k, s_k)\n        else:\n            raise ValueError(\"Invalid update formula specified.\")\n            \n        # Prepare for next iteration\n        x_k = x_k_plus_1\n        grad_k = grad_k_plus_1\n        H_k = H_k_plus_1\n\n    # If loop finishes, convergence was not reached within n_max iterations\n    return False\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Define test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {'params': (1.0, 1.0, 0.1, 100.0, 1.0, 0.0, 0.0), 'x0': [-1.5, 1.0], 'N_max': 200},\n        # Case B\n        {'params': (1.0, 1.0, 0.2, 1e6, 10.0, 0.0, 0.0), 'x0': [3.0, -2.0], 'N_max': 60},\n        # Case C\n        {'params': (1.0, 1.0, 0.0, 50.0, 0.5, 0.0, 0.0), 'x0': [0.0, 0.0], 'N_max': 1}\n    ]\n    \n    epsilon = 1e-5\n    results = []\n\n    for case in test_cases:\n        # Run DFP optimizer\n        converged_dfp = quasi_newton_optimizer(case['params'], case['x0'], case['N_max'], epsilon, 'DFP')\n        results.append(converged_dfp)\n        \n        # Run BFGS optimizer\n        converged_bfgs = quasi_newton_optimizer(case['params'], case['x0'], case['N_max'], epsilon, 'BFGS')\n        results.append(converged_bfgs)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Trust-region methods offer a powerful alternative to line-search strategies, particularly in regions of difficult curvature. In this practice, you will code a one-dimensional trust-region algorithm from the ground up and apply it to a classic double-well potential. This exercise will demonstrate how the trust-region framework intelligently adjusts its step size to prevent overshooting and reliably converge to a minimum, even when starting near a maximum. ",
            "id": "2461247",
            "problem": "Consider the univariate objective function in dimensionless units given by $f(x)=x^4-x^2$ with first derivative $f'(x)=4x^3-2x$ and second derivative $f''(x)=12x^2-2$. The stationary points are the local maxima at $x=0$ and the local minima at $x_{\\pm}=\\pm 1/\\sqrt{2}$. For an iterate $x_k\\in\\mathbb{R}$, define the quadratic model $m_k(s)=f(x_k)+f'(x_k)s+\\tfrac{1}{2}f''(x_k)s^2$ and a trust-region radius $\\Delta_k0$. The trust-region subproblem is to find a step $s_k\\in\\mathbb{R}$ that minimizes $m_k(s)$ subject to the constraint $\\lvert s\\rvert\\le \\Delta_k$. Let the predicted reduction be $\\operatorname{pred}_k=-(m_k(s_k)-m_k(0))=-(f'(x_k)s_k+\\tfrac{1}{2}f''(x_k)s_k^2)$ and the actual reduction be $\\operatorname{ared}_k=f(x_k)-f(x_k+s_k)$. Define the acceptance ratio $\\rho_k=\\operatorname{ared}_k/\\operatorname{pred}_k$ when $\\operatorname{pred}_k0$; if $\\operatorname{pred}_k\\le 0$, set $\\rho_k=-\\infty$. A step is accepted if $\\rho_k\\ge \\eta_1$ and rejected otherwise. The trust-region radius is updated by the following rule with fixed parameters $\\eta_1\\in(0,1)$, $\\eta_2\\in(\\eta_1,1)$, $\\gamma_1\\in(0,1)$, and $\\gamma_21$:\n- If $\\rho_k\\eta_1$, set $\\Delta_{k+1}=\\gamma_1\\Delta_k$.\n- If $\\rho_k\\ge \\eta_2$ and $\\lvert s_k\\rvert\\ge 0.8\\,\\Delta_k$, set $\\Delta_{k+1}=\\min\\{\\gamma_2\\Delta_k,\\Delta_{\\max}\\}$.\n- Otherwise, set $\\Delta_{k+1}=\\Delta_k$.\nIf a step is rejected, keep $x_{k+1}=x_k$; if it is accepted, set $x_{k+1}=x_k+s_k$. The iteration terminates when either $\\lvert f'(x_k)\\rvert\\le \\varepsilon_g$, $\\lvert s_k\\rvert\\le \\varepsilon_s$ for an accepted step, $\\Delta_k\\le \\varepsilon_s$, or when a fixed iteration cap is reached.\n\nIn one spatial dimension, the unique global minimizer of the quadratic model subject to $\\lvert s\\rvert\\le \\Delta$ is characterized as follows. For given $g\\in\\mathbb{R}$ and $h\\in\\mathbb{R}$ with $g=f'(x)$ and $h=f''(x)$,\n- If $h0$ and the unconstrained minimizer $s_N=-g/h$ satisfies $\\lvert s_N\\rvert\\le \\Delta$, then $s^\\star=s_N$; otherwise $s^\\star=-\\operatorname{sign}(g)\\,\\Delta$.\n- If $h\\le 0$, then $s^\\star=\\Delta$ when $g0$, $s^\\star=-\\Delta$ when $g0$, and $s^\\star=\\Delta$ when $g=0$.\n\nFix the numerical parameters $\\eta_1=0.1$, $\\eta_2=0.9$, $\\gamma_1=0.25$, $\\gamma_2=2$, $\\Delta_{\\max}=10$, gradient tolerance $\\varepsilon_g=10^{-8}$, step tolerance $\\varepsilon_s=10^{-10}$, and a maximum of $100$ iterations. For each test case below, start from the given initial point $x_0$ with the given initial radius $\\Delta_0$, and apply the above iteration using the one-dimensional model minimizer $s_k$ at each step.\n\nDefine three scalar outputs for each test case:\n- $b_1$: the logical value that is true if and only if no accepted step ever increases the objective, that is, for all accepted steps $k$, $f(x_{k+1})\\le f(x_k)$.\n- $b_2$: the logical value that is true if and only if the full unconstrained Newton step at the first iterate, $s_N=-f'(x_0)/f''(x_0)$ (when $f''(x_0)\\ne 0$; define $b_2$ as false if $f''(x_0)=0$), produces a higher objective value, that is, $f(x_0+s_N)f(x_0)$.\n- $d$: the absolute distance from the final accepted iterate $x_{\\mathrm{final}}$ to the nearest local minimizer, $d=\\min\\{\\lvert x_{\\mathrm{final}}-1/\\sqrt{2}\\rvert,\\lvert x_{\\mathrm{final}}+1/\\sqrt{2}\\rvert\\}$.\n\nTest suite parameters to evaluate:\n1. $(x_0,\\Delta_0)=(0.1,0.05)$\n2. $(x_0,\\Delta_0)=(0.1,2.0)$\n3. $(x_0,\\Delta_0)=(0.0,0.5)$\n4. $(x_0,\\Delta_0)=(0.1,0.001)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output a list $[b_1,b_2,d]$ where $b_1$ and $b_2$ are the lowercase strings \"true\" or \"false\", and $d$ is a decimal-rounded float with exactly six digits after the decimal point. The final output must therefore be a single line of the form\n$[[b_{1,1},b_{1,2},d_1],[b_{2,1},b_{2,2},d_2],[b_{3,1},b_{3,2},d_3],[b_{4,1},b_{4,2},d_4]]$,\nwith no spaces anywhere in the line.",
            "solution": "The problem is valid. It presents a well-posed, self-contained, and scientifically sound exercise in numerical optimization, specifically the application of a trust-region algorithm to a one-dimensional potential energy function. All necessary parameters, algorithmic rules, functions, and termination criteria are provided with mathematical precision. We shall proceed with a complete solution.\n\nThe core of this problem is to implement and analyze a trust-region optimization algorithm. This class of methods is fundamental in computational sciences, particularly in computational chemistry for locating stable molecular geometries, which correspond to minima on a potential energy surface. The objective function $f(x) = x^4 - x^2$ is a canonical one-dimensional double-well potential, representing a system with two stable states (minima) at $x_{\\pm} = \\pm 1/\\sqrt{2}$ and an unstable transition state (maximum) at $x=0$.\n\nA trust-region algorithm iteratively finds a minimum by constructing a simpler model of the objective function, which is trusted only within a neighborhood of the current iterate $x_k$. This neighborhood is a \"trust region\" of radius $\\Delta_k$. The model is a quadratic function, $m_k(s)$, derived from a second-order Taylor expansion of $f(x)$ around $x_k$:\n$$m_k(s) = f(x_k) + f'(x_k)s + \\frac{1}{2}f''(x_k)s^2$$\nwhere $s$ is the step from $x_k$. This model is minimized with respect to $s$ subject to the constraint $\\lvert s \\rvert \\le \\Delta_k$. This constrained minimization is called the trust-region subproblem.\n\nThe solution to the one-dimensional subproblem, as provided, depends on the curvature of the model, given by the second derivative $h = f''(x_k)$.\n1.  If $h  0$, the model is convex (a parabola opening upwards). The unconstrained minimizer is the Newton step $s_N = -g/h$, where $g = f'(x_k)$. If this step lies within the trust region, i.e., $\\lvert s_N \\rvert \\le \\Delta_k$, it is the optimal step $s_k$. Otherwise, the model is minimized at the boundary of the trust region, $s_k = -\\operatorname{sign}(g)\\Delta_k$, moving as far as possible in the direction of steepest descent.\n2.  If $h \\le 0$, the model is locally concave or linear. Its minimum over the interval $[-\\Delta_k, \\Delta_k]$ must lie at one of the boundaries. The selection between $s = \\Delta_k$ and $s = -\\Delta_k$ is determined by the sign of the gradient $g$, which dictates the direction of descent.\n\nOnce the trial step $s_k$ is computed, its quality is assessed by comparing the *actual reduction* in the objective function, $\\operatorname{ared}_k = f(x_k) - f(x_k + s_k)$, to the *predicted reduction* from the model, $\\operatorname{pred}_k = m_k(0) - m_k(s_k)$. Their ratio, $\\rho_k = \\operatorname{ared}_k / \\operatorname{pred}_k$, measures the fidelity of the model.\n\n-   If $\\rho_k$ is close to $1$, the model is an excellent predictor. The step is accepted, and we may expand the trust region ($\\Delta_{k+1} = \\gamma_2 \\Delta_k$) to allow for more aggressive steps, provided the current step was already near the trust region boundary.\n-   If $\\rho_k$ is positive but not large, the model is adequate. The step is accepted, but the trust region size is maintained ($\\Delta_{k+1} = \\Delta_k$).\n-   If $\\rho_k$ is small or negative, the model is poor. The step is rejected ($x_{k+1} = x_k$), and the trust region is shrunk ($\\Delta_{k+1} = \\gamma_1 \\Delta_k$) to improve model accuracy in the subsequent iteration.\n\nThe step acceptance rule is $\\rho_k \\ge \\eta_1$. Since $\\eta_1 = 0.1  0$ and the solution to the subproblem ensures $\\operatorname{pred}_k \\ge 0$, any accepted step must have $\\operatorname{ared}_k \\ge \\eta_1 \\operatorname{pred}_k \\ge 0$. If $\\operatorname{pred}_k  0$, then $\\operatorname{ared}_k  0$, guaranteeing that $f(x_{k+1})  f(x_k)$. A step can only be accepted if the model predicts descent ($\\operatorname{pred}_k  0$). Therefore, the condition for $b_1$—that no accepted step ever increases the objective function—is guaranteed to be true by the very construction of this algorithm. Any deviation would indicate a flawed implementation.\n\nThe output $b_2$ probes the limitation of the pure Newton-Raphson method. The unconstrained Newton step, $s_N = -f'(x_0)/f''(x_0)$, finds the extremum of the quadratic model. Near a maximum, such as at $x_0=0.0$ or $x_0=0.1$, the Hessian $f''(x_0)$ is negative. The Newton step thus seeks the *maximum* of the local quadratic model, which is a poor strategy for minimizing the global function $f(x)$ and is likely to result in an ascent step, i.e., $f(x_0+s_N)  f(x_0)$. The trust-region framework corrects this deficiency by constraining the step size.\n\nThe final output, $d$, measures the accuracy of convergence to one of the true minimizers, $x_{\\pm} = \\pm 1/\\sqrt{2}$. Given the initial points are all non-negative, the algorithm is expected to converge to the positive minimizer, $x_+ = 1/\\sqrt{2}$.\n\nThe implementation will proceed by first defining the objective function and its derivatives. Then, for each test case, the value of $b_2$ is computed. The main iterative loop is then executed, which involves, at each step $k$: checking for termination, solving the trust-region subproblem for $s_k$, evaluating the step quality via $\\rho_k$, and updating the state variables $x_k$ and $\\Delta_k$ according to the specified rules. The value of $b_1$ is tracked throughout the iteration. Upon termination, the final distance $d$ is computed.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the trust-region optimization problem for the given test cases.\n    \"\"\"\n\n    # --- Problem Definition ---\n    def f(x):\n        return x**4 - x**2\n\n    def f_prime(x):\n        return 4 * x**3 - 2 * x\n\n    def f_double_prime(x):\n        return 12 * x**2 - 2\n\n    # --- Algorithm Parameters ---\n    eta1 = 0.1\n    eta2 = 0.9\n    gamma1 = 0.25\n    gamma2 = 2.0\n    delta_max = 10.0\n    eps_g = 1e-8\n    eps_s = 1e-10\n    max_iter = 100\n    \n    minimizers = [-1/np.sqrt(2), 1/np.sqrt(2)]\n\n    # --- Test Cases ---\n    test_cases = [\n        (0.1, 0.05),\n        (0.1, 2.0),\n        (0.0, 0.5),\n        (0.1, 0.001)\n    ]\n\n    results = []\n\n    for x0, delta0 in test_cases:\n        # --- Output variable initialization ---\n        b1_flag = True\n        \n        # --- Calculate b2 before starting iterations ---\n        g0 = f_prime(x0)\n        h0 = f_double_prime(x0)\n        \n        if h0 == 0:\n            b2 = False\n        else:\n            s_N = -g0 / h0\n            b2 = f(x0 + s_N)  f(x0)\n            \n        # --- Main Trust-Region Loop ---\n        x_k = x0\n        delta_k = delta0\n        final_x = x0 # Will hold the last accepted iterate value\n        \n        for _ in range(max_iter):\n            g_k = f_prime(x_k)\n            \n            # --- Termination check 1: Gradient ---\n            if abs(g_k) = eps_g:\n                final_x = x_k\n                break\n\n            # --- Solve the trust-region subproblem ---\n            h_k = f_double_prime(x_k)\n            s_k = 0.0\n            \n            if h_k  0:\n                s_N = -g_k / h_k\n                if abs(s_N) = delta_k:\n                    s_k = s_N\n                else:\n                    s_k = -np.sign(g_k) * delta_k\n            else: # h_k = 0\n                if g_k  0:\n                    s_k = delta_k\n                elif g_k  0:\n                    s_k = -delta_k\n                else: # g_k == 0\n                    s_k = delta_k\n\n            # --- Evaluate step quality ---\n            pred_k = -(g_k * s_k + 0.5 * h_k * s_k**2)\n            ared_k = f(x_k) - f(x_k + s_k)\n            \n            rho_k = 0.0\n            # Use small tolerance for pred_k to avoid division by zero instability\n            if pred_k  1e-12: # Check for meaningful predicted reduction\n                rho_k = ared_k / pred_k\n            else:\n                rho_k = -np.inf # Model predicts no improvement or a trivial step\n\n            delta_kp1 = delta_k\n            \n            # --- Step acceptance/rejection and state update ---\n            if rho_k = eta1: # Accept step\n                if f(x_k + s_k)  f(x_k):\n                    b1_flag = False\n                \n                x_k += s_k\n                final_x = x_k\n                \n                # --- Termination check 2: Step size for an accepted step ---\n                if abs(s_k) = eps_s:\n                    break\n                    \n                # --- Update trust radius (for accepted step) ---\n                if rho_k = eta2 and abs(s_k) = 0.8 * delta_k:\n                    delta_kp1 = min(gamma2 * delta_k, delta_max)\n                # else: delta_kp1 remains delta_k\n                \n            else: # Reject step\n                # x_k remains the same\n                delta_kp1 = gamma1 * delta_k\n            \n            delta_k = delta_kp1\n            \n            # --- Termination check 3: Trust radius size ---\n            if delta_k = eps_s:\n                break\n        \n        # --- Calculate final distance d ---\n        d = min(abs(final_x - m) for m in minimizers)\n        \n        # Format results for the current test case\n        b1_str = \"true\" if b1_flag else \"false\"\n        b2_str = \"true\" if b2 else \"false\"\n        d_str = \"{:.6f}\".format(d)\n        results.append(f'[{b1_str},{b2_str},{d_str}]')\n        \n    # --- Final Print ---\n    # The final output is a single line, formatted as a list of lists.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}