{
    "hands_on_practices": [
        {
            "introduction": "A Genetic Algorithm is driven by its core operators: selection, crossover, and mutation. Before diving into complex implementations, it is essential to build a solid intuition for what each operator contributes to the search process. This exercise () challenges you to analyze the behavior of a GA under extreme conditions—specifically, with no mutation—to clarify the indispensable role of this operator for maintaining genetic diversity and ensuring the algorithm can explore the entire search space.",
            "id": "3132693",
            "problem": "Consider a Genetic Algorithm (GA) operating on bitstrings of length $n$ to maximize the OneMax objective $f(\\mathbf{x})=\\sum_{i=1}^{n} x_i$, where $x_i \\in \\{0,1\\}$. The GA uses fitness-based selection (any scheme that probabilistically favors higher $f(\\mathbf{x})$), uniform crossover (each locus of the offspring is independently copied from one of two parents with probability $1/2$ for either parent), and per-bit mutation with probability $p_m$. The initial population consists of $N$ individuals whose bits are independent and identically distributed with $\\mathbb{P}(x_i=1)=1/2$ for all loci $i \\in \\{1,\\dots,n\\}$.\n\nAnalyze the two edge cases $p_m=0$ and $p_m=1/n$ from first principles. Specifically, reason about what operators can and cannot introduce new allele values at a locus, quantify the risk of initial allele fixation, and examine the expected mutational behavior at $p_m=1/n$. Then select all statements that are correct.\n\nA. With $p_m=0$, if both alleles $\\{0,1\\}$ are present at every locus in the initial population, then crossover and selection can, in principle, assemble the all-ones string; however, if any locus is initially fixed at $0$ across the entire population, the all-ones optimum is unreachable.\n\nB. With $p_m=1/n$, the expected number of bit flips per individual in one generation equals $1$, and the probability that an individual experiences no mutation in a generation is $(1-1/n)^n$, which tends to $e^{-1}$ as $n \\to \\infty$.\n\nC. With $p_m=0$, uniform crossover can still introduce a novel allele value at a locus even if that allele is entirely absent in the current population, so mutation is not strictly necessary for exploration.\n\nD. Under random initialization with $N$ individuals and $p_m=0$, the probability that there exists at least one locus fixed to $0$ across the population is $1 - \\left(1 - (1/2)^N\\right)^n$.\n\nE. Increasing the crossover rate always rescues stagnation under $p_m=0$ because recombination can create alleles not present in the population.",
            "solution": "The problem statement has been validated and found to be scientifically grounded, well-posed, and objective. It provides a standard theoretical setup for analyzing a Genetic Algorithm (GA) on the OneMax problem, which is a canonical task in the field of evolutionary computation. The setup is self-contained and free of contradictions or ambiguities. I will now proceed with the solution.\n\nThe core of this problem requires an analysis of the fundamental roles of the genetic operators—selection, crossover, and mutation—and their impact on the genetic diversity of the population, specifically in the context of allele presence and fixation.\n\n**First Principles Analysis**\n\n1.  **Operators and Allele Generation:**\n    *   **Selection:** This operator does not create new individuals or new genetic material. It biases the reproductive pool towards individuals with higher fitness. In the context of OneMax, it favors individuals with more $1$s.\n    *   **Crossover (Uniform):** This operator creates offspring by recombining the genetic material from two parent individuals. For each locus, it selects the allele (a $0$ or a $1$) from one of the two parents. Crucially, crossover *cannot* create an allele that is not present in at least one of the parents. If an allele is absent from the entire population at a given locus, no amount of crossover can introduce it.\n    *   **Mutation (Per-bit flip):** This operator randomly alters alleles. It can change a $0$ to a $1$ or a $1$ to a $0$. Mutation is the primary mechanism for introducing novel genetic material into the population and for reversing allele fixation.\n\n2.  **Analysis of Case $p_m = 0$ (No Mutation):**\n    When the mutation probability $p_m$ is $0$, the only source of alleles is the initial population. If, for a given locus $j$, every individual in the population has the allele $0$, this locus is said to be \"fixed\" at $0$. Since selection and crossover cannot create a $1$ at this locus, it will remain fixed at $0$ in all subsequent generations. Consequently, the all-ones string, which requires a $1$ at every locus, becomes unreachable if any locus is initially fixed at $0$.\n\n3.  **Analysis of Case $p_m = 1/n$ (Standard Mutation Rate):**\n    This is a common choice for the mutation rate in theoretical analyses of GAs.\n    *   **Expected Number of Mutations:** For a given individual (a bitstring of length $n$), each of the $n$ bits is subject to mutation with an independent probability $p_m = 1/n$. The total number of mutated bits, $K$, follows a binomial distribution $B(n, p_m)$. The expected value of this distribution is $\\mathbb{E}[K] = n \\cdot p_m = n \\cdot (1/n) = 1$. So, on average, one bit is expected to be flipped per individual per generation.\n    *   **Probability of No Mutation:** The probability that a single bit does *not* mutate is $1 - p_m = 1 - 1/n$. Since the mutations are independent for each of the $n$ bits, the probability that an individual experiences no mutation at all is the product of these probabilities for each bit, which is $(1 - 1/n)^n$. In the limit as the string length $n$ becomes large, this expression converges to a well-known mathematical constant: $\\lim_{n \\to \\infty} (1 - 1/n)^n = e^{-1}$.\n\n**Option-by-Option Evaluation**\n\n**A. With $p_m=0$, if both alleles $\\{0,1\\}$ are present at every locus in the initial population, then crossover and selection can, in principle, assemble the all-ones string; however, if any locus is initially fixed at $0$ across the entire population, the all-ones optimum is unreachable.**\n*   The first part of the statement is correct. If all necessary \"building blocks\" (i.e., the allele $1$ at every locus) are present somewhere in the population, crossover provides the mechanism to combine them into a single individual, and selection provides the pressure to guide the search towards that combination.\n*   The second part is also correct, as per our analysis above. If $p_m=0$ and a locus is fixed at $0$, there is no operator capable of introducing a $1$ at that position. The allele pool is closed, and the global optimum is unattainable.\n*   **Verdict:** **Correct**.\n\n**B. With $p_m=1/n$, the expected number of bit flips per individual in one generation equals $1$, and the probability that an individual experiences no mutation in a generation is $(1-1/n)^n$, which tends to $e^{-1}$ as $n \\to \\infty$.**\n*   As derived in the principles analysis, the number of bit flips is a random variable from a binomial distribution $B(n, p_m=1/n)$. Its expectation is $n \\cdot (1/n) = 1$. The first part is correct.\n*   The probability of a single bit not flipping is $1 - 1/n$. The probability of this happening for all $n$ independent bits is indeed $(1-1/n)^n$. The second part is correct.\n*   The limit $\\lim_{n \\to \\infty} (1 - 1/n)^n$ is a standard definition of $e^{-1}$. The third part is correct.\n*   The entire statement is a conjunction of three correct facts.\n*   **Verdict:** **Correct**.\n\n**C. With $p_m=0$, uniform crossover can still introduce a novel allele value at a locus even if that allele is entirely absent in the current population, so mutation is not strictly necessary for exploration.**\n*   This statement makes a fundamentally incorrect claim about the function of crossover. Crossover is a recombination operator; it shuffles existing alleles from the parents. It cannot create new alleles. If an allele (e.g., a $1$) is absent at a locus across the entire population, it is also absent from any pair of parents selected from that population, and thus cannot appear in their offspring via crossover. Mutation is the operator responsible for introducing such novelty.\n*   **Verdict:** **Incorrect**.\n\n**D. Under random initialization with $N$ individuals and $p_m=0$, the probability that there exists at least one locus fixed to $0$ across the population is $1 - \\left(1 - (1/2)^N\\right)^n$.**\n*   Let's calculate this probability from first principles.\n*   Consider a single locus, say locus $j$. The probability that a single individual has a $0$ at this locus is $1/2$.\n*   Since the initial population of $N$ individuals is generated with i.i.d. bits, the probability that all $N$ individuals have a $0$ at locus $j$ is $(1/2)^N$. This is the probability that locus $j$ is fixed to $0$.\n*   The complementary event is that locus $j$ is *not* fixed to $0$. The probability of this is $1 - (1/2)^N$.\n*   Now, we consider all $n$ loci. The initialization of each locus is an independent event. The probability that *no* locus is fixed to $0$ is the product of the probabilities that each individual locus is not fixed to $0$. This is $\\left(1 - (1/2)^N\\right)^n$.\n*   The event \"there exists at least one locus fixed to $0$\" is the complement of \"no locus is fixed to $0$\". Therefore, its probability is $1 - \\mathbb{P}(\\text{no locus is fixed to } 0) = 1 - \\left(1 - (1/2)^N\\right)^n$.\n*   This matches the expression given in the option.\n*   **Verdict:** **Correct**.\n\n**E. Increasing the crossover rate always rescues stagnation under $p_m=0$ because recombination can create alleles not present in the population.**\n*   This statement contains two errors. First, as established in the analysis of option C, recombination (crossover) cannot create alleles not present in the population. The justification provided is false.\n*   Second, the main claim that increasing the crossover rate rescues stagnation (when $p_m=0$) is also false. If stagnation is due to the loss of a necessary allele (e.g., all individuals have a $0$ at a locus where a $1$ is needed), crossover is powerless to help. It can only reshuffle the existing, suboptimal alleles.\n*   **Verdict:** **Incorrect**.",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "In many real-world optimization problems, from training machine learning models to engineering design, evaluating a solution's quality can be an imperfect, noisy process. A robust optimization algorithm must be able to find good solutions even when its feedback is unreliable. This hands-on coding challenge () guides you through implementing a GA that operates under noisy fitness evaluations, allowing you to compare how different selection schemes and noise-reduction strategies, like re-evaluation, contribute to the algorithm's resilience and performance.",
            "id": "3137379",
            "problem": "You are to implement and compare Genetic Algorithm (GA) selection strategies under noisy fitness evaluations. The fundamental base includes: (i) the definition of a GA population evolving by selection and variation; (ii) the OneMax objective $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$ for bit-strings $\\mathbf{x} \\in \\{0,1\\}^{L}$; (iii) an observed noisy fitness $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$; and (iv) the properties of expectations and variances of sums and averages of independent Gaussian variables. You must design a program that runs a GA with noisy evaluation and reports, for a set of specified test cases, the best true fitness found, defined as the maximum of $f(\\mathbf{x})$ observed at any time during the evolutionary run (best-so-far across generations), without noise.\n\nAlgorithmic setting to implement:\n- Representation: Individuals are bit-strings of length $L$ with $L = 24$.\n- Objective: True fitness $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$.\n- Noisy evaluation: For a given noise standard deviation $\\sigma \\ge 0$, each evaluation draws an independent $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ and returns $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$.\n- Re-evaluation and aggregation: To mitigate noise, you may perform $m \\in \\mathbb{N}$ independent evaluations of the same individual, obtaining $\\tilde{f}_1,\\dots,\\tilde{f}_m$, and aggregate them by either the sample mean or the sample median. Denote the aggregate by $g_m(\\mathbf{x})$. For $m=1$, $g_1(\\mathbf{x}) = \\tilde{f}(\\mathbf{x})$. Within each generation, each individual’s aggregate $g_m(\\mathbf{x})$ is computed once and reused for all selection decisions in that generation.\n- Population: Size $N = 80$. Initial population is independent and identically distributed, with each bit sampled from the Bernoulli distribution with probability $1/2$ for $1$.\n- Selection strategies to implement:\n  1. Fitness-proportionate (roulette) selection using aggregated scores $g_m(\\mathbf{x})$: Let $w_i = g_m(\\mathbf{x}^{(i)})$ for the $i$-th individual. Compute shifted nonnegative weights $u_i = \\max\\{w_i - \\min_j w_j + \\delta, \\delta\\}$ for $\\delta = 10^{-9}$ to avoid nonpositive weights. Select $N$ parents with replacement, where the probability of selecting individual $i$ is $u_i / \\sum_{k=1}^{N} u_k$.\n  2. Tournament selection of size $\\tau = 3$ using aggregated scores $g_m(\\mathbf{x})$: To select one parent, sample $\\tau$ distinct indices uniformly from $\\{1,\\dots,N\\}$ and choose the individual with the maximum $g_m(\\mathbf{x})$ among them. Repeat until $N$ parents are selected.\n- Variation: Mutation-only variation. Each selected parent produces exactly one offspring by independent bit-flip mutations with probability $p_m = 1/L$ per bit. No crossover is used.\n- Replacement: Generational replacement. The $N$ offspring form the next generation. No explicit elitism is used. However, for reporting the result, maintain the best-so-far true fitness $\\max f(\\mathbf{x})$ observed across the entire run.\n- Generations: Run for $T = 250$ generations per test case.\n\nMathematical and statistical conventions:\n- All random variates are independent unless stated otherwise. Across different generations, new noise samples are drawn. Within each generation, each individual’s aggregated score $g_m(\\mathbf{x})$ is computed using fresh noise and reused in all selection decisions for that generation.\n- For $m > 1$, the aggregation function is either the sample mean or the sample median of $m$ independent noisy evaluations; both aggregators operate on independent and identically distributed Gaussian samples.\n\nTest suite:\nEach test case is a tuple $(\\sigma, \\text{selection}, m, \\text{aggregator}, s)$ where $\\sigma$ is the noise standard deviation, $\\text{selection}$ is either the string \"roulette\" or \"tournament\", $m$ is the positive integer number of re-evaluations per individual per generation, $\\text{aggregator}$ is either the string \"mean\" or \"median\", and $s$ is the integer seed to initialize a pseudorandom number generator. Use the following parameter sets:\n- Case $1$: $(0, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 42)$.\n- Case $2$: $(2, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 7)$.\n- Case $3$: $(2, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 7)$.\n- Case $4$: $(2, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 7)$.\n- Case $5$: $(6, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 13)$.\n- Case $6$: $(6, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 13)$.\n- Case $7$: $(6, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 13)$.\n- Case $8$: $(6, \\text{\"tournament\"}, 5, \\text{\"median\"}, 13)$.\n\nFor every test case, run the GA described above and return the integer best-so-far true fitness, i.e., the maximum over all individuals ever seen during the run of the exact OneMax score $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$ without noise. All true-fitness computations are exact and have no noise.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases above. For example, the output should look like $[$$r_1$$,$$r_2$$,\\dots,$$r_8$$]$ where each $r_i$ is an integer best-so-far true fitness for case $i$.",
            "solution": "The user-provided problem has been analyzed and validated according to the specified criteria.\n\n### Step 1: Extract Givens\n- **Problem Domain**: Genetic Algorithm (GA) for the OneMax problem under noisy fitness evaluation.\n- **Objective Function (True Fitness)**: $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$ for a bit-string $\\mathbf{x} \\in \\{0,1\\}^{L}$.\n- **Noisy Fitness Evaluation**: $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$.\n- **GA Parameters**:\n    - Representation: Bit-strings of length $L = 24$.\n    - Population Size: $N = 80$.\n    - Generations: $T = 250$.\n    - Initial Population: Bits are i.i.d. Bernoulli with $p=1/2$.\n    - Variation: Per-bit mutation with probability $p_m = 1/L$. No crossover.\n    - Replacement: Generational replacement (offspring replace parents). No explicit elitism.\n- **Noise Handling**:\n    - Re-evaluation: $m$ independent evaluations per individual per generation.\n    - Aggregation Function ($g_m(\\mathbf{x})$): Sample mean or sample median of the $m$ evaluations. For $m=1$, $g_1(\\mathbf{x}) = \\tilde{f}(\\mathbf{x})$.\n- **Selection Strategies**:\n    1.  **Fitness-Proportionate (Roulette)**: Selects $N$ parents with replacement. Selection probability for individual $i$ is proportional to $u_i = \\max\\{w_i - \\min_j w_j + \\delta, \\delta\\}$, where $w_i = g_m(\\mathbf{x}^{(i)})$ and $\\delta = 10^{-9}$.\n    2.  **Tournament Selection**: Selects one parent by choosing the best individual from a randomly sampled tournament of size $\\tau = 3$. This is repeated $N$ times to form the parent pool.\n- **Reporting Metric**: The best true fitness $f(\\mathbf{x})$ observed across all individuals in all generations of a run (best-so-far).\n- **Test Cases**: A set of $8$ test cases is provided, each defined by a tuple $(\\sigma, \\text{selection}, m, \\text{aggregator}, s)$, where $s$ is the seed for the pseudorandom number generator.\n    - Case 1: $(0, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 42)$\n    - Case 2: $(2, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 7)$\n    - Case 3: $(2, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 7)$\n    - Case 4: $(2, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 7)$\n    - Case 5: $(6, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 13)$\n    - Case 6: $(6, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 13)$\n    - Case 7: $(6, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 13)$\n    - Case 8: $(6, \\text{\"tournament\"}, 5, \\text{\"median\"}, 13)$\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is a standard exercise in computational science, specifically in the domain of evolutionary algorithms. The OneMax problem is a canonical benchmark, and modeling noisy objective functions with additive Gaussian noise is a well-established practice. All specified components (selection, mutation, etc.) are fundamental concepts in GAs. The problem is scientifically sound.\n2.  **Well-Posed**: All parameters ($L, N, T, p_m, \\tau$, etc.) are precisely defined. The initial conditions, termination condition (number of generations), and evaluation procedures are unambiguous. The use of a specific seed for the random number generator for each test case ensures that the stochastic simulation is reproducible, leading to a unique, verifiable solution for each case.\n3.  **Objective**: The problem description uses clear, formal, and objective language, free from any subjective or opinion-based statements.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is self-contained, scientifically sound, well-posed, and objective. There are no contradictions, ambiguities, or missing information. The task is a non-trivial but feasible implementation of a standard scientific simulation. Therefore, I will proceed with providing a complete solution.\n\nThe solution implements a Genetic Algorithm as specified. The core logic is encapsulated within a `run_ga` function that executes one full evolutionary run for a given set of parameters.\n\nThe algorithm proceeds as follows:\n1.  **Initialization**: A random number generator is seeded. The initial population of $N$ bit-strings is created, with each bit being $0$ or $1$ with equal probability. The `best_so_far_fitness` is initialized by computing the true fitness of every individual in this initial population and taking the maximum.\n2.  **Generational Loop**: The algorithm iterates for $T$ generations. In each generation:\n    a. **Evaluation**: For each individual in the current population, an aggregated fitness score $g_m(\\mathbf{x})$ is computed. This involves calculating the true fitness $f(\\mathbf{x})$, adding $m$ independent Gaussian noise variates $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ to it, and then aggregating the $m$ noisy results using either the sample mean or median. These aggregated scores are stored for the selection step.\n    b. **Selection**: A pool of $N$ parents is selected from the current population based on the aggregated scores. The selection is performed using either the specified roulette wheel or tournament method.\n    c. **Variation**: Each of the $N$ selected parents produces one offspring. The offspring is generated by applying bit-flip mutation to a copy of the parent, where each bit has a probability $p_m = 1/L$ of being flipped.\n    d. **Replacement**: The set of $N$ offspring becomes the population for the next generation.\n    e. **Tracking**: The true fitness of all individuals in the new offspring population is calculated, and `best_so_far_fitness` is updated if a new maximum is found.\n3.  **Result**: After $T$ generations, the final `best_so_far_fitness` is returned as an integer.\n\nThe main script defines the test cases and iterates through them, calling `run_ga` for each one and collecting the results. Finally, it prints the results in the specified comma-separated format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and print the results of the GA test suite.\n    \"\"\"\n\n    def noisy_evaluation(true_f, sigma, m, aggregator, rng):\n        \"\"\"\n        Computes the aggregated noisy fitness score for an individual.\n        \n        Args:\n            true_f (float): The true fitness of the individual.\n            sigma (float): The standard deviation of the Gaussian noise.\n            m (int): The number of re-evaluations.\n            aggregator (str): The aggregation method ('mean' or 'median').\n            rng (np.random.Generator): The random number generator.\n            \n        Returns:\n            float: The aggregated noisy fitness score.\n        \"\"\"\n        if sigma == 0.0:\n            return true_f\n        \n        # Generate m independent noisy samples\n        noisy_samples = rng.normal(loc=true_f, scale=sigma, size=m)\n        \n        if m == 1:\n            return noisy_samples[0]\n        \n        if aggregator == \"mean\":\n            return np.mean(noisy_samples)\n        elif aggregator == \"median\":\n            return np.median(noisy_samples)\n        else:\n            # This path should not be reached with the given test cases.\n            raise ValueError(\"Invalid aggregator specified.\")\n\n    def roulette_selection(aggregated_scores, N, rng):\n        \"\"\"\n        Performs fitness-proportionate (roulette) selection.\n        \n        Args:\n            aggregated_scores (np.ndarray): Array of scores for the population.\n            N (int): Population size.\n            rng (np.random.Generator): The random number generator.\n        \n        Returns:\n            np.ndarray: An array of N selected parent indices.\n        \"\"\"\n        delta = 1e-9\n        # Shift scores to be non-negative to create weights.\n        # u_i = max{w_i - min_j w_j + delta, delta}\n        min_score = np.min(aggregated_scores)\n        weights = np.maximum(aggregated_scores - min_score + delta, delta)\n        \n        # Normalize weights to get selection probabilities.\n        sum_weights = np.sum(weights)\n        if sum_weights == 0:\n            # Uniform selection if all weights are zero (highly unlikely).\n            probabilities = np.full(N, 1.0 / N)\n        else:\n            probabilities = weights / sum_weights\n            \n        parent_indices = rng.choice(N, size=N, replace=True, p=probabilities)\n        return parent_indices\n\n    def tournament_selection(aggregated_scores, N, tau, rng):\n        \"\"\"\n        Performs tournament selection.\n        \n        Args:\n            aggregated_scores (np.ndarray): Array of scores for the population.\n            N (int): Population size.\n            tau (int): Tournament size.\n            rng (np.random.Generator): The random number generator.\n        \n        Returns:\n            np.ndarray: An array of N selected parent indices.\n        \"\"\"\n        parent_indices = np.zeros(N, dtype=int)\n        for i in range(N):\n            # Select tau distinct individuals for the tournament.\n            contender_indices = rng.choice(N, size=tau, replace=False)\n            contender_scores = aggregated_scores[contender_indices]\n            \n            # The winner is the one with the highest aggregated score.\n            winner_local_index = np.argmax(contender_scores)\n            winner_global_index = contender_indices[winner_local_index]\n            parent_indices[i] = winner_global_index\n            \n        return parent_indices\n\n    def mutation(parents, L, p_m, rng):\n        \"\"\"\n        Applies bit-flip mutation to a set of parents to create offspring.\n        \n        Args:\n            parents (np.ndarray): A (N, L) array of parent bit-strings.\n            L (int): The length of the bit-strings.\n            p_m (float): The per-bit mutation probability.\n            rng (np.random.Generator): The random number generator.\n            \n        Returns:\n            np.ndarray: A (N, L) array of offspring bit-strings.\n        \"\"\"\n        # Create a boolean mask for mutations. True indicates a flip.\n        mutation_mask = rng.random(size=parents.shape) < p_m\n        # Apply mutation using XOR operator.\n        offspring = parents ^ mutation_mask\n        return offspring.astype(np.int8)\n\n    def run_ga(L, N, T, sigma, selection_strat, m, aggregator, s):\n        \"\"\"\n        Runs a full Genetic Algorithm simulation for a single test case.\n        \n        Args:\n            L, N, T: GA structural parameters.\n            sigma, selection_strat, m, aggregator, s: Test case parameters.\n            \n        Returns:\n            int: The best-so-far true fitness found during the run.\n        \"\"\"\n        # --- Setup ---\n        rng = np.random.default_rng(s)\n        p_m = 1.0 / L\n        tau = 3  # Tournament size\n\n        # --- 1. Initialization ---\n        population = rng.integers(0, 2, size=(N, L), dtype=np.int8)\n        \n        # Calculate true fitness for the initial population (gen 0)\n        true_fitnesses = np.sum(population, axis=1)\n        best_so_far_fitness = np.max(true_fitnesses)\n\n        # --- 2. Generational Loop ---\n        for _ in range(T):\n            # --- a. Evaluation ---\n            # Calculate true fitnesses once per generation for noise calculation.\n            current_true_fitnesses = np.sum(population, axis=1)\n            \n            # Compute aggregated noisy scores for the current population.\n            aggregated_scores = np.array([\n                noisy_evaluation(f, sigma, m, aggregator, rng) for f in current_true_fitnesses\n            ])\n\n            # --- b. Selection ---\n            if selection_strat == \"roulette\":\n                parent_indices = roulette_selection(aggregated_scores, N, rng)\n            else:  # tournament\n                parent_indices = tournament_selection(aggregated_scores, N, tau, rng)\n            \n            parents = population[parent_indices]\n\n            # --- c. Variation ---\n            offspring = mutation(parents, L, p_m, rng)\n\n            # --- d. Replacement ---\n            population = offspring\n\n            # --- e. Update Best-So-Far ---\n            # The new population's individuals have been \"seen,\" so check their true fitness.\n            true_fitnesses_offspring = np.sum(population, axis=1)\n            current_max_true = np.max(true_fitnesses_offspring)\n            if current_max_true > best_so_far_fitness:\n                best_so_far_fitness = current_max_true\n        \n        return int(best_so_far_fitness)\n\n    # --- Main ---\n    # Global parameters for the GA.\n    L = 24\n    N = 80\n    T = 250\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (sigma, selection, m, aggregator, seed)\n        (0.0, \"roulette\", 1, \"mean\", 42),\n        (2.0, \"roulette\", 1, \"mean\", 7),\n        (2.0, \"tournament\", 1, \"mean\", 7),\n        (2.0, \"tournament\", 5, \"mean\", 7),\n        (6.0, \"roulette\", 1, \"mean\", 13),\n        (6.0, \"tournament\", 1, \"mean\", 13),\n        (6.0, \"tournament\", 5, \"mean\", 13),\n        (6.0, \"tournament\", 5, \"median\", 13),\n    ]\n\n    results = []\n    for case in test_cases:\n        sigma, selection, m, aggregator, s_seed = case\n        result = run_ga(L, N, T, sigma, selection, m, aggregator, s_seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While Genetic Algorithms were originally conceived for binary strings, many optimization tasks involve continuous variables, like tuning parameters in a manufacturing process or finding the optimal shape of a wing. To solve these problems, we must first decide how to *encode* a real-valued solution into a binary genotype. This practice () delves into this crucial topic by having you compare standard binary encoding with the more sophisticated Gray coding, analyzing how the choice of representation impacts the algorithm's search behavior and its ability to navigate the landscape of a continuous problem.",
            "id": "3132789",
            "problem": "You are to write a complete, runnable program that compares two genotype encodings used in Genetic Algorithms (Genetic Algorithm (GA)): standard binary encoding and Gray coding, when optimizing the sphere function. The objective function is the sphere function $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ defined on a bounded hyper-rectangle $[L, U]^n$ with $L &lt; 0 &lt; U$. Each decision variable $x_i$ is represented by $b$ bits and decoded into a real value by uniform linear quantization.\n\nFundamental base and definitions to use:\n- The sphere function $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ is separable by coordinates.\n- The genotype-to-phenotype mapping is a linear quantizer: for each coordinate, a $b$-bit code word represents an integer $k \\in \\{0,1,\\dots,2^b - 1\\}$ which maps to a real value $x = L + \\dfrac{U - L}{2^b - 1}\\,k$. This induces a uniform grid of $2^b$ points per coordinate including the endpoints $L$ and $U$.\n- For binary encoding, the code word is the standard base-$2$ representation of $k$. For Gray coding, the code word is the Gray encoding of $k$, and decoding applies Gray-to-binary conversion to recover the integer $k$ before the linear map to $x$.\n- A single-bit mutation is defined as flipping exactly one bit chosen uniformly at random among all $n b$ genotype bits.\n\nCompute and report the following for each test case:\n1) Discretization error. Define the discretization error as the minimum attainable value of $f(\\mathbf{x})$ over the discretized grid induced by the chosen $b$ (for either encoding; both induce the same set of phenotype grid points) minus the continuous optimum of $f(\\mathbf{x})$ over $[L, U]^n$. You must compute this quantity exactly, not by sampling.\n2) Search bias via one-step improvement probability. Define the one-step improvement probability $P_{\\mathrm{improve}}$ for an encoding as the probability (with respect to the uniform distribution over genotypes and uniform choice among $n b$ bit positions) that a single-bit flip strictly decreases $f(\\mathbf{x})$. You must compute this probability exactly by enumeration, not by simulation. Formally,\n$$\nP_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot n b} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{n b} \\mathbf{1}\\big(f(g^{(p)}) &lt; f(g)\\big),\n$$\nwhere $g^{(p)}$ is $g$ with bit $p$ flipped, and $\\mathbf{1}(\\cdot)$ is the indicator function. Use the separability of $f$ and the fact that the bit flip affects exactly one coordinate to reduce this to an equivalent exact enumeration over a single coordinate of $b$ bits.\n\nYour program must:\n- Implement both encodings (binary and Gray) exactly for any integer $b \\ge 1$.\n- Use exact logic instead of floating-point comparisons to test whether a bit flip improves a single coordinate’s contribution $x^2$, by observing that for symmetric bounds with $L = -U$ and uniform quantization with step size $\\Delta = \\dfrac{U - L}{2^b - 1}$, the per-coordinate value equals $x = \\Delta\\,(k - m)$ with $m = \\dfrac{2^b - 1}{2}$. Therefore, a flip improves the objective if and only if $\\lvert k' - m \\rvert &lt; \\lvert k - m \\rvert$, which is equivalent to $\\lvert 2k' - (2^b - 1) \\rvert &lt; \\lvert 2k - (2^b - 1) \\rvert$.\n- Compute the discretization error exactly from first principles, without numerically searching the grid. If $0 \\in [L, U]$, the continuous minimum is $0$ achieved at $\\mathbf{x} = \\mathbf{0}$; otherwise it is the closest boundary point to $0$ in each coordinate.\n- Output, for each test case, a list with four numbers: the discretization error under binary encoding, the discretization error under Gray coding, the one-step improvement probability under binary encoding, and the one-step improvement probability under Gray coding. All numbers must be printed as decimals rounded to $12$ places.\n\nTest suite:\nUse the following five test cases, each specified as a tuple $(n, b, L, U)$, where $n$ is the dimension, $b$ is the bit-length per coordinate, and $[L, U]$ is the bound interval:\n- $(\\,1,\\,3,\\,-1.0,\\,1.0\\,)$\n- $(\\,5,\\,4,\\,-1.0,\\,1.0\\,)$\n- $(\\,10,\\,8,\\,-1.0,\\,1.0\\,)$\n- $(\\,3,\\,1,\\,-1.0,\\,1.0\\,)$\n- $(\\,2,\\,12,\\,-1.0,\\,1.0\\,)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the five test cases as a comma-separated list of length five, where each element is itself a comma-separated list of four decimal numbers in the order described above, and every decimal is rounded to $12$ places. For example, a valid shape is\n$$\n[\\,[d_1^{\\text{bin}}, d_1^{\\text{gray}}, p_1^{\\text{bin}}, p_1^{\\text{gray}}],\\dots,[d_5^{\\text{bin}}, d_5^{\\text{gray}}, p_5^{\\text{bin}}, p_5^{\\text{gray}}]\\,].\n$$\nNo extra text should be printed.",
            "solution": "The user-provided problem has been analyzed and validated. It is scientifically grounded, well-posed, and all definitions and constraints are self-contained and consistent. The task is to compute two metrics, discretization error and one-step improvement probability, for binary and Gray encodings used in a genetic algorithm optimizing the sphere function.\n\n### 1. Discretization Error\n\nThe objective function is the sphere function $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ over the domain $\\mathbf{x} \\in [L, U]^n$. For all test cases, $L = -1.0$ and $U = 1.0$, so $L < 0 < U$. The continuous minimum of $f(\\mathbf{x})$ is $f(\\mathbf{0}) = 0$, achieved at $\\mathbf{x} = \\mathbf{0}$.\n\nThe problem describes a uniform linear quantization scheme where each coordinate $x_i$ is mapped from a $b$-bit codeword. The codeword corresponds to an integer $k \\in \\{0, 1, \\dots, 2^b-1\\}$, which in turn maps to a real value $x_k = L + \\frac{U-L}{2^b-1}k$. The set of possible real values for each coordinate, the grid points, is determined by the range of $k$.\n\nBoth binary and Gray encodings provide a bijective mapping from the set of $b$-bit strings to the set of integers $\\{0, 1, \\dots, 2^b-1\\}$. Consequently, the set of achievable phenotype values (the grid points) is identical for both encodings. The discretization error, defined as the difference between the minimum value on the grid and the continuous minimum, is therefore independent of the choice between binary and Gray encoding.\n\nTo find the minimum value of $f(\\mathbf{x})$ on the grid, we must find the grid point $x_k$ closest to $0$ for each coordinate. The value of $k$ that makes $x_k$ closest to $0$ is the integer nearest to the real value $k_{\\text{real}} = -L \\frac{2^b-1}{U-L}$.\nGiven $L=-1.0$ and $U=1.0$, this becomes $k_{\\text{real}} = -(-1.0) \\frac{2^b-1}{1.0 - (-1.0)} = \\frac{2^b-1}{2}$.\nSince $b \\ge 1$, $2^b-1$ is always odd, so $k_{\\text{real}}$ is never an integer. The two integers closest to $k_{\\text{real}}$ are $k_1 = \\lfloor \\frac{2^b-1}{2} \\rfloor = 2^{b-1}-1$ and $k_2 = \\lceil \\frac{2^b-1}{2} \\rceil = 2^{b-1}$.\nThe corresponding phenotype values are:\n$x_{k_1} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}-1) = \\frac{-(2^b-1) + 2^b-2}{2^b-1} = \\frac{-1}{2^b-1}$.\n$x_{k_2} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}) = \\frac{-(2^b-1) + 2^b}{2^b-1} = \\frac{1}{2^b-1}$.\nThe minimum possible absolute value for a coordinate is $|x^*| = \\frac{1}{2^b-1}$.\nThe minimum value of $f(\\mathbf{x})$ on the discrete grid is achieved when each $|x_i| = |x^*|$, so $\\min_{\\text{grid}} f(\\mathbf{x}) = \\sum_{i=1}^{n} (x^*)^2 = n \\left(\\frac{1}{2^b-1}\\right)^2$.\nThe discretization error $D$ is thus:\n$$ D = \\min_{\\text{grid}} f(\\mathbf{x}) - \\min_{\\text{continuous}} f(\\mathbf{x}) = \\frac{n}{(2^b-1)^2} - 0 = \\frac{n}{(2^b-1)^2} $$\nThis value is the same for both binary and Gray encoding, so $D_{\\text{binary}} = D_{\\text{Gray}}$.\n\n### 2. One-Step Improvement Probability ($P_{\\mathrm{improve}}$)\n\nThe one-step improvement probability is defined as:\n$$ P_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot nb} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{nb} \\mathbf{1}\\big(f(g^{(p)}) < f(g)\\big) $$\nDue to the separability of the sphere function $f(\\mathbf{x}) = \\sum_{i=1}^n x_i^2$, a single-bit flip in the genotype affects only one coordinate, say $x_i \\to x_i'$. The condition for improvement $f(g^{(p)}) < f(g)$ simplifies to $(x_i')^2 < x_i^2$, which is equivalent to $|x_i'| < |x_i|$.\nThe total number of improving moves can be summed over each coordinate independently. Let $S$ be the total number of single-bit flips that result in an improvement for a single $b$-bit coordinate, summed over all $2^b$ possible states of that coordinate.\n$$ S = \\sum_{c \\in \\{0,1\\}^b} \\sum_{j=1}^{b} \\mathbf{1}\\big( |x'(c^{(j)})| < |x(c)| \\big) $$\nwhere $c$ is a $b$-bit codeword, $c^{(j)}$ is $c$ with bit $j$ flipped, and $x(c)$ is the phenotype value corresponding to $c$.\nThe total number of improving moves across all $n$ coordinates and all $(2^b)^n$ genotypes is $n \\cdot (2^b)^{n-1} \\cdot S$.\nSubstituting this into the probability formula simplifies it significantly:\n$$ P_{\\mathrm{improve}} = \\frac{n \\cdot (2^b)^{n-1} \\cdot S}{(2^b)^n \\cdot nb} = \\frac{S}{2^b \\cdot b} $$\nThis means we only need to analyze a single $b$-bit coordinate to find the probability. The value of $S$ will differ between binary and Gray encodings because the mapping from a codeword $c$ to an integer $k$ (and thus to a phenotype value $x$) is different.\n\nTo avoid floating-point inaccuracies, we use the suggested integer-based comparison. For $L=-U$, the condition $|x'| < |x|$ is equivalent to $|k' - m| < |k - m|$ where $m = (2^b-1)/2$. This can be rewritten by multiplying by $2$ as $|2k' - (2^b-1)| < |2k - (2^b-1)|$.\n\nThe algorithm to compute $S$ for each encoding is as follows:\n1.  Initialize a counter for improving moves, `improvements`, to $0$. Let $M = 2^b - 1$.\n2.  Iterate through each possible $b$-bit codeword $c$, represented by an integer from $0$ to $2^b-1$.\n3.  For each $c$, determine its integer value $k$ for the given encoding (binary or Gray).\n    - For binary encoding, $k_{\\text{bin}}$ is the integer value of $c$.\n    - For Gray encoding, $k_{\\text{gray}}$ is obtained by a Gray-to-binary conversion of $c$.\n4.  Calculate the fitness-related term for the current state: $V_{\\text{bin}} = |2k_{\\text{bin}} - M|$ and $V_{\\text{gray}} = |2k_{\\text{gray}} - M|$.\n5.  Iterate through each bit position $j$ from $0$ to $b-1$.\n    a. Determine the new codeword $c'$ by flipping bit $j$ of $c$.\n    b. Decode $c'$ to get the new integer values $k'_{\\text{bin}}$ and $k'_{\\text{gray}}$.\n    c. Calculate the new fitness terms $V'_{\\text{bin}} = |2k'_{\\text{bin}} - M|$ and $V'_{\\text{gray}} = |2k'_{\\text{gray}} - M|$.\n    d. If $V'_{\\text{bin}} < V_{\\text{bin}}$, increment the counter for binary encoding.\n    e. If $V'_{\\text{gray}} < V_{\\text{gray}}$, increment the counter for Gray encoding.\n6.  After iterating through all codewords and bit flips, the total counts $S_{\\text{bin}}$ and $S_{\\text{gray}}$ are obtained.\n7.  The probabilities are then $P_{\\mathrm{improve}}^{\\text{bin}} = S_{\\text{bin}} / (2^b \\cdot b)$ and $P_{\\mathrm{improve}}^{\\text{gray}} = S_{\\text{gray}} / (2^b \\cdot b)$.\n\nThis procedure is implemented exactly in the provided code.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes discretization error and one-step improvement probability for\n    binary and Gray encodings on the sphere function.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, b, L, U)\n        (1, 3, -1.0, 1.0),\n        (5, 4, -1.0, 1.0),\n        (10, 8, -1.0, 1.0),\n        (3, 1, -1.0, 1.0),\n        (2, 12, -1.0, 1.0),\n    ]\n\n    def gray_to_bin_int(g: int) -> int:\n        \"\"\"\n        Converts a Gray-coded integer to its corresponding binary integer value.\n        \"\"\"\n        b = g\n        mask = g >> 1\n        while mask > 0:\n            b ^= mask\n            mask >>= 1\n        return b\n\n    # Store results as formatted strings to match output specification.\n    formatted_results = []\n\n    for n, b, L, U in test_cases:\n        # 1. Discretization Error Calculation\n        # For L = -U, the continuous minimum is 0. The discrete grid point closest to 0\n        # for a coordinate is at |U|/(2^b - 1). The minimum of sum(x_i^2) is n * (|U|/(2^b - 1))^2.\n        # Since all test cases have U=1.0, this simplifies.\n        if (2**b - 1) == 0: # a_val is denominator\n             disc_error = float('inf') if n > 0 else 0.0 # handle b=0 case, though not in tests\n        else:\n             disc_error = n * (U / (2**b - 1))**2\n        \n        # Discretization error is independent of the encoding strategy, as both\n        # cover the same set of phenotype points.\n        d_bin = disc_error\n        d_gray = disc_error\n\n        # 2. One-Step Improvement Probability Calculation\n        improvements_bin = 0\n        improvements_gray = 0\n        num_states = 2**b\n        # Precompute a map from Gray coded integers to binary integers for efficiency.\n        gray_map = {g: gray_to_bin_int(g) for g in range(num_states)}\n        \n        # This value is used for the integer-based fitness comparison\n        # |2k' - M| < |2k - M| to avoid floating point issues.\n        M = num_states - 1\n\n        # Iterate over all possible b-bit codewords (represented as integers 0..2^b-1)\n        for c_int in range(num_states):\n            # For binary encoding, the integer value k is the codeword itself.\n            k_bin = c_int\n            # For Gray encoding, the codeword c_int must be converted to find k.\n            k_gray = gray_map[c_int]\n\n            # Objective value proxy for the current state for each encoding\n            val_bin = abs(2 * k_bin - M)\n            val_gray = abs(2 * k_gray - M)\n\n            # Iterate over all possible single-bit flips\n            for j in range(b):\n                # Flipping the j-th bit is equivalent to XOR with 2^j\n                c_prime_int = c_int ^ (1 << j)\n\n                # --- Binary Encoding ---\n                k_prime_bin = c_prime_int\n                val_prime_bin = abs(2 * k_prime_bin - M)\n                if val_prime_bin < val_bin:\n                    improvements_bin += 1\n\n                # --- Gray Encoding ---\n                k_prime_gray = gray_map[c_prime_int]\n                val_prime_gray = abs(2 * k_prime_gray - M)\n                if val_prime_gray < val_gray:\n                    improvements_gray += 1\n\n        # The total number of possible one-bit mutations for a single coordinate\n        # is the number of states times the number of bits.\n        total_mutations = num_states * b\n        \n        p_bin = improvements_bin / total_mutations if total_mutations > 0 else 0.0\n        p_gray = improvements_gray / total_mutations if total_mutations > 0 else 0.0\n\n        sub_result = [d_bin, d_gray, p_bin, p_gray]\n        result_str = f\"[{','.join(f'{x:.12f}' for x in sub_result)}]\"\n        formatted_results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}