{
    "hands_on_practices": [
        {
            "introduction": "This first practice applies Tabu Search to the classic Traveling Salesperson Problem (TSP), a canonical challenge in combinatorial optimization. The exercise  focuses on a critical design choice: the trade-off between search quality and computational efficiency. By implementing and comparing a full neighborhood scan against a restricted candidate list, you will gain direct insight into balancing thorough exploration with per-iteration speed, a fundamental skill for tackling large-scale problems.",
            "id": "3190936",
            "problem": "Implement and empirically evaluate two candidate list strategies within Tabu Search for a symmetric Euclidean Traveling Salesperson Problem (TSP). The objective is to compare a full neighborhood scan against a restricted candidate list of size $k$ in terms of per-iteration computational cost and solution quality. The problem must be solved by writing a complete, runnable program.\n\nYou are given the following foundational definitions and assumptions:\n- The Traveling Salesperson Problem is defined on a complete graph with $n$ nodes (cities), where each undirected edge $(i,j)$ has a symmetric distance $d_{ij} = d_{ji} \\ge 0$. The objective function $f(\\pi)$ for a tour (permutation) $\\pi$ is the sum of the Euclidean distances along the cycle induced by $\\pi$, that is $f(\\pi) = \\sum_{t=0}^{n-1} d_{\\pi_t,\\pi_{t+1 \\pmod n}}$.\n- A neighborhood operator is defined by the $2$-opt move. For indices $i<j$, reversing the segment $\\pi[i:j]$ yields a new tour. The elementary cost change (delta) under a $2$-opt move can be computed from four edges in $O(1)$ time.\n- Tabu Search (TS) uses short-term memory to forbid recently made moves. Use an attribute-based tabu list that forbids removing recently added edges for a fixed tabu tenure $T_{\\text{tenure}}$. Use an aspiration criterion that allows any tabu move that yields a strict improvement over the globally best objective value seen so far.\n- The per-iteration computational cost is measured as the number of objective-change computations, that is, the number of $2$-opt delta evaluations performed during move selection in one iteration. Summed over iterations, this yields the total number of objective evaluations.\n\nYou must implement two strategies to select the move at each iteration:\n- Full neighborhood scan: examine the entire $2$-opt neighborhood defined by all pairs $(i,j)$ with $0 \\le i < j \\le n-1$ except $(i,j)=(0,n-1)$, compute the delta cost for each move, and select the best admissible (non-tabu or aspirational) move. If no admissible move exists, select the best move regardless of tabu status.\n- Restricted candidate list (RCL) of size $k$: uniformly sample, without replacement, exactly $k$ distinct valid $2$-opt moves from the same neighborhood as above, evaluate only those $k$ moves, and select the best admissible move among them. If none of the $k$ sampled moves are admissible, select the best move among them regardless of tabu. The sampling must be reproducible under a fixed random seed.\n\nInitialization and data generation:\n- Generate $n$ points independently and identically distributed in the unit square using a pseudo-random generator with a specified integer seed $s$, each coordinate drawn from $\\mathcal{U}[0,1]$.\n- Use the Euclidean metric to compute the distance matrix $D \\in \\mathbb{R}^{n \\times n}$ with entries $d_{ij} = \\sqrt{(x_i-x_j)^2 + (y_i-y_j)^2}$.\n- Build the initial tour deterministically using the greedy nearest-neighbor heuristic starting from node $0$ (break ties by the smallest index).\n\nAlgorithmic details to enforce:\n- Represent a $2$-opt move by indices $(i,j)$ with $0 \\le i < j \\le n-1$ and exclude only the trivial reversal $(0,n-1)$ to avoid a pure tour reversal equivalence.\n- The $O(1)$ delta for a $2$-opt move $(i,j)$ is given by removing edges $(\\pi_{i-1},\\pi_i)$ and $(\\pi_j,\\pi_{j+1 \\pmod n})$ and adding edges $(\\pi_{i-1},\\pi_j)$ and $(\\pi_i,\\pi_{j+1 \\pmod n})$. Count exactly one objective evaluation per such delta computation, and do not count any other operations.\n- After applying a $2$-opt move, insert the two newly added undirected edges into the tabu list for $T_{\\text{tenure}}$ iterations. A candidate is tabu if any of the to-be-added edges is currently tabu. Apply the aspiration criterion strictly when the resulting tour has an objective strictly less than the global best so far.\n\nMeasurement and outputs:\n- For each test case, run Tabu Search for exactly $T$ iterations under both strategies: full neighborhood scan and restricted candidate list. Record:\n  1. Average per-iteration objective evaluation count for full scan, defined as total deltas computed divided by $T$.\n  2. Average per-iteration objective evaluation count for restricted candidate list of size $k$.\n  3. Relative solution-quality gap defined as $(f_{\\text{RCL}}^\\star - f_{\\text{Full}}^\\star)/f_{\\text{Full}}^\\star$, where $f_{\\text{Full}}^\\star$ and $f_{\\text{RCL}}^\\star$ are the best objective values found by each strategy.\n  4. The two best objective values $f_{\\text{Full}}^\\star$ and $f_{\\text{RCL}}^\\star$.\n- Express all objective values and the relative gap as dimensionless real numbers (no physical units). The relative gap must be reported as a decimal number, not a percentage.\n\nTest suite:\nYour program must execute the following four test cases in the exact order shown. Each test case is the tuple $(n,T,k,s,T_{\\text{tenure}})$:\n- Case $1$: $(10, 120, 1, 42, 7)$\n- Case $2$: $(12, 150, 20, 7, 7)$\n- Case $3$: $(14, 180, 90, 123, 8)$\n- Case $4$: $(6, 80, 2, 5, 5)$\n\nFinal output format:\n- For each case, output a list of five numbers in the order: [average evaluations per iteration (full), average evaluations per iteration (RCL), relative quality gap, best full-scan objective, best RCL objective].\n- Round the two average evaluation counts to $2$ decimals, the relative quality gap to $6$ decimals, and both objective values to $6$ decimals.\n- Your program should produce a single line of output containing the results as a comma-separated list of these per-case lists, enclosed in square brackets; for example: [[c1_full,c1_rcl,qgap1,bf1,br1],[c2_full,c2_rcl,qgap2,bf2,br2],...].",
            "solution": "The user wants to implement and evaluate two candidate list strategies for a Tabu Search (TS) algorithm applied to the symmetric Euclidean Traveling Salesperson Problem (TSP). This requires a detailed implementation of the TSP environment, the TS metaheuristic with specific components, and the two competing strategies, followed by an empirical comparison based on provided test cases.\n\n### **1. Problem Formulation**\nThe problem is defined as the symmetric Traveling Salesperson Problem (TSP) on a complete graph $G=(V, E)$, where $V$ is a set of $n$ cities (nodes) located in the unit square $[0,1] \\times [0,1]$. The cost (distance) $d_{ij}$ for each edge $(i, j) \\in E$ is the Euclidean distance between cities $i$ and $j$. A solution is a tour, which is a permutation $\\pi$ of the cities. The objective is to find a tour that minimizes the total length, given by the function $f(\\pi) = \\sum_{t=0}^{n-1} d_{\\pi_t, \\pi_{(t+1) \\pmod n}}$.\n\n### **2. Neighborhood Structure and Move Evaluation**\nThe neighborhood of a solution is defined by the **2-opt operator**. A 2-opt move transforms a tour by selecting two non-adjacent edges, removing them, and reconnecting the four resulting endpoints in the only other way that produces a valid tour. This is equivalent to reversing a segment of the tour. A move is defined by a pair of indices $(i, j)$ with $0 \\le i < j \\le n-1$, corresponding to the reversal of the path segment $\\pi[i \\ldots j]$. The problem specifies excluding the trivial full-tour reversal $(i,j)=(0, n-1)$.\n\nThe change in tour length (delta) resulting from a 2-opt move can be calculated in $O(1)$ time. If the edges $(\\pi_{i-1}, \\pi_i)$ and $(\\pi_j, \\pi_{j+1})$ are removed and replaced by $(\\pi_{i-1}, \\pi_j)$ and $(\\pi_i, \\pi_{j+1})$ (where indices are modulo $n$), the delta is:\n$$ \\Delta = d(\\pi_{i-1}, \\pi_j) + d(\\pi_i, \\pi_{j+1}) - d(\\pi_{i-1}, \\pi_i) - d(\\pi_j, \\pi_{j+1}) $$\nEach such computation is counted as one objective evaluation, which serves as the primary measure of computational cost per iteration.\n\n### **3. Tabu Search Framework**\nThe Tabu Search (TS) algorithm is a metaheuristic that guides a local search method to escape local optima. The implementation follows these specific rules:\n\n-   **Tabu List**: An attribute-based short-term memory is used. When a 2-opt move is performed, the two newly **added** edges are declared tabu.\n-   **Tabu Tenure ($T_{\\text{tenure}}$)**: An edge placed on the tabu list is forbidden from being re-added for a fixed number of subsequent iterations, $T_{\\text{tenure}}$. A move is tabu if it would require adding an edge that is currently on the tabu list.\n-   **Aspiration Criterion**: The tabu status of a move can be overridden if performing the move results in a new tour with a total length strictly less than the best-so-far solution found during the entire search ($f(\\pi_{\\text{new}}) < f(\\pi^\\star)$).\n-   **Move Selection Rule**: In each iteration, the best \"admissible\" move (i.e., non-tabu or satisfying the aspiration criterion) from a set of candidates is chosen. If no admissible move is found within the candidate set, the best move from that set is selected, regardless of its tabu status.\n\n### **4. Candidate List Strategies**\nThe core of the problem is to compare two strategies for generating the candidate set of moves at each iteration:\n\n1.  **Full Neighborhood Scan**: The candidate set consists of all possible $N = \\frac{n(n-1)}{2}-1$ valid 2-opt moves. The algorithm evaluates the delta for every move in this set and selects the best admissible one. This is an exhaustive local search, maximizing the chance of finding a good move at the cost of high computational effort per iteration (exactly $N$ evaluations).\n\n2.  **Restricted Candidate List (RCL)**: The candidate set is a small subset of the full neighborhood. Exactly $k$ distinct 2-opt moves are uniformly sampled without replacement from the set of all possible moves. Only these $k$ moves are evaluated. This strategy significantly reduces the computational cost per iteration (to $k$ evaluations) but is non-exhaustive, risking to miss the best moves available in the full neighborhood.\n\n### **5. Initialization**\nTo ensure reproducibility, the search process is initialized deterministically:\n-   **City Coordinates**: For a given seed $s$, $n$ points are generated with coordinates drawn from a uniform distribution $\\mathcal{U}[0,1]$.\n-   **Initial Tour**: The initial solution is constructed using the greedy nearest-neighbor heuristic, starting from city $0$. Ties in distance are broken by selecting the city with the smaller index.\n\n### **6. Algorithmic Implementation and Metrics**\nThe implementation is encapsulated in a class for each test case. This class manages problem data generation, the two TS runs, and result calculation.\n\n-   **Data Structures**: A `numpy` array stores the tour permutation. A `dict` serves as the tabu list, mapping edge tuples `(u, v)` (with $u<v$) to the iteration number at which their tabu status expires.\n-   **Reproducibility**: The `numpy.random.default_rng` with the specified seed $s$ is used for both city coordinate generation and the RCL sampling process to guarantee consistent results.\n-   **Main Loop**: For each strategy, the TS algorithm runs for a fixed number of iterations $T$. In each iteration, it generates a candidate list, evaluates the moves, selects and applies one based on the rules, and updates the current solution, best-found solution, and tabu list.\n-   **Metrics**: After $T$ iterations, the following metrics are computed for each strategy:\n    1.  Average evaluations per iteration: Total delta computations divided by $T$. This will be $\\frac{n(n-1)}{2}-1$ for the full scan and $k$ for the RCL.\n    2.  Best objective value found: $f_{\\text{Full}}^\\star$ and $f_{\\text{RCL}}^\\star$.\n    3.  Relative quality gap: $(f_{\\text{RCL}}^\\star - f_{\\text{Full}}^\\star) / f_{\\text{Full}}^\\star$, measuring the quality loss of RCL relative to the full scan.\n\nThe final output is a list of lists, where each inner list contains these five formatted metrics for one test case.",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\nclass TSPSolver:\n    \"\"\"\n    Implements and compares Tabu Search with full-scan and RCL strategies for TSP.\n    \"\"\"\n    def __init__(self, n, T, k, s, T_tenure):\n        self.n = n\n        self.T = T\n        self.k = k\n        self.seed = s\n        self.T_tenure = T_tenure\n\n        # Generate problem data using the specified seed\n        self.rng = np.random.default_rng(self.seed)\n        self.points = self.rng.random((self.n, 2))\n        self.dist_matrix = distance_matrix(self.points, self.points)\n        \n        # Pre-compute all valid 2-opt moves\n        self.all_moves = self._generate_all_moves()\n        self.num_all_moves = len(self.all_moves)\n\n    def _generate_all_moves(self):\n        \"\"\"Generates all valid 2-opt moves (i, j) with 0 <= i < j < n, excluding (0, n-1).\"\"\"\n        moves = []\n        for i in range(self.n):\n            for j in range(i + 1, self.n):\n                if i == 0 and j == self.n - 1:\n                    continue\n                moves.append((i, j))\n        return moves\n\n    def _get_initial_tour(self):\n        \"\"\"Builds an initial tour using the nearest-neighbor heuristic from node 0.\"\"\"\n        tour = [0]\n        unvisited = set(range(1, self.n))\n        current_city = 0\n        while unvisited:\n            distances_to_unvisited = {\n                city: self.dist_matrix[current_city, city] for city in unvisited\n            }\n            min_dist_val = min(distances_to_unvisited.values())\n            candidates = [\n                city for city, dist in distances_to_unvisited.items() if dist == min_dist_val\n            ]\n            next_city = min(candidates)\n            \n            tour.append(next_city)\n            unvisited.remove(next_city)\n            current_city = next_city\n        return tour\n\n    def _calculate_tour_cost(self, tour):\n        \"\"\"Calculates the total length of a given tour.\"\"\"\n        cost = 0.0\n        for i in range(self.n):\n            cost += self.dist_matrix[tour[i], tour[(i + 1) % self.n]]\n        return cost\n\n    def _tabu_search(self, strategy):\n        \"\"\"\n        Executes the Tabu Search algorithm for a given strategy ('full' or 'rcl').\n        \"\"\"\n        # A separate RNG for sampling to ensure reproducibility based on the main seed.\n        sampling_rng = np.random.default_rng(self.seed)\n\n        # Initialization\n        initial_tour = self._get_initial_tour()\n        current_tour = np.array(initial_tour)\n        best_tour = current_tour.copy()\n        current_obj = self._calculate_tour_cost(current_tour)\n        best_obj = current_obj\n        \n        tabu_until = {}  # Maps tabu edges to the iteration they become available\n        total_evals = 0\n\n        for iter_num in range(1, self.T + 1):\n            if strategy == 'full':\n                moves_to_check_indices = range(self.num_all_moves)\n                evals_this_iter = self.num_all_moves\n            else: # rcl\n                k_effective = min(self.k, self.num_all_moves)\n                moves_to_check_indices = sampling_rng.choice(\n                    self.num_all_moves, size=k_effective, replace=False\n                )\n                evals_this_iter = k_effective\n            \n            total_evals += evals_this_iter\n            \n            best_delta_in_iter = np.inf\n            best_move_in_iter = None\n            best_admissible_delta = np.inf\n            best_admissible_move = None\n\n            for move_idx in moves_to_check_indices:\n                i, j = self.all_moves[move_idx]\n                \n                # Delta calculation (O(1))\n                p_im1_idx = i - 1\n                p_jp1_idx = (j + 1) % self.n\n                p_im1 = current_tour[p_im1_idx]\n                p_i = current_tour[i]\n                p_j = current_tour[j]\n                p_jp1 = current_tour[p_jp1_idx]\n\n                delta = (self.dist_matrix[p_im1, p_j] + self.dist_matrix[p_i, p_jp1] -\n                         self.dist_matrix[p_im1, p_i] - self.dist_matrix[p_j, p_jp1])\n\n                # Admissibility Check\n                new_obj = current_obj + delta\n                \n                # Aspiration\n                is_aspirated = new_obj < best_obj\n                \n                # Tabu check for the two edges to be added\n                edge1 = tuple(sorted((p_im1, p_j)))\n                edge2 = tuple(sorted((p_i, p_jp1)))\n                is_tabu = (tabu_until.get(edge1, 0) >= iter_num or\n                           tabu_until.get(edge2, 0) >= iter_num)\n                \n                is_admissible = (not is_tabu) or is_aspirated\n                \n                if is_admissible:\n                    if delta < best_admissible_delta:\n                        best_admissible_delta = delta\n                        best_admissible_move = (i, j)\n                \n                if delta < best_delta_in_iter:\n                    best_delta_in_iter = delta\n                    best_move_in_iter = (i, j)\n            \n            # Select move for this iteration\n            if best_admissible_move is not None:\n                move_to_apply = best_admissible_move\n                delta_to_apply = best_admissible_delta\n            else:\n                move_to_apply = best_move_in_iter\n                delta_to_apply = best_delta_in_iter\n\n            if move_to_apply is None:\n                continue\n\n            # Apply the chosen move\n            i, j = move_to_apply\n            \n            # Get cities for tabu update before reversal\n            p_im1_idx = i - 1\n            p_jp1_idx = (j + 1) % self.n\n            p_im1 = current_tour[p_im1_idx]\n            p_i = current_tour[i]\n            p_j = current_tour[j]\n            p_jp1 = current_tour[p_jp1_idx]\n\n            # Reverse the tour segment\n            current_tour[i : j + 1] = current_tour[i : j + 1][::-1]\n            current_obj += delta_to_apply\n\n            if current_obj < best_obj:\n                best_obj = current_obj\n                best_tour = current_tour.copy()\n\n            # Update tabu list with newly added edges\n            edge1 = tuple(sorted((p_im1, p_j)))\n            edge2 = tuple(sorted((p_i, p_jp1)))\n            tabu_expiry_iter = iter_num + self.T_tenure\n            tabu_until[edge1] = tabu_expiry_iter\n            tabu_until[edge2] = tabu_expiry_iter\n        \n        avg_evals = total_evals / self.T\n        return best_obj, avg_evals\n\n    def run_comparison(self):\n        \"\"\"Runs both strategies and computes the required metrics.\"\"\"\n        f_full_star, avg_evals_full = self._tabu_search(strategy='full')\n        f_rcl_star, avg_evals_rcl = self._tabu_search(strategy='rcl')\n        \n        if f_full_star == 0:\n            rel_gap = 0.0\n        else:\n            rel_gap = (f_rcl_star - f_full_star) / f_full_star\n            \n        return [avg_evals_full, avg_evals_rcl, rel_gap, f_full_star, f_rcl_star]\n\ndef solve():\n    test_cases = [\n        # (n, T, k, s, T_tenure)\n        (10, 120, 1, 42, 7),\n        (12, 150, 20, 7, 7),\n        (14, 180, 90, 123, 8),\n        (6, 80, 2, 5, 5),\n    ]\n\n    results_for_print = []\n    for case in test_cases:\n        solver = TSPSolver(*case)\n        result = solver.run_comparison()\n        \n        avg_full_str = f\"{result[0]:.2f}\"\n        avg_rcl_str = f\"{result[1]:.2f}\"\n        gap_str = f\"{result[2]:.6f}\"\n        best_full_str = f\"{result[3]:.6f}\"\n        best_rcl_str = f\"{result[4]:.6f}\"\n        \n        results_for_print.append(\n            f\"[{avg_full_str},{avg_rcl_str},{gap_str},{best_full_str},{best_rcl_str}]\"\n        )\n        \n    print(f\"[{','.join(results_for_print)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Moving beyond standard examples, this exercise  challenges you to apply Tabu Search to a network design task: finding a spanning tree with minimum average latency. The core lesson here is the use of penalty functions to handle complex constraints, such as graph connectivity. This powerful technique allows the search to navigate through infeasible regions of the solution space, providing a flexible way to guide the search towards high-quality, feasible solutions.",
            "id": "3190896",
            "problem": "You must implement a complete, runnable program that uses Tabu Search to optimize a spanning tree for minimum average latency on undirected weighted graphs. The program must follow the specification below.\n\nThe fundamental base for this task consists of the following definitions and well-tested facts:\n- A graph is an undirected weighted graph defined by a set of nodes and edges. Each edge connects two distinct nodes and has a nonnegative weight.\n- A spanning tree on a graph with $n$ nodes is any connected, acyclic subgraph containing exactly $n-1$ edges.\n- In a weighted graph, the length of a path is the sum of the weights of its edges. The shortest-path distance between two nodes is the minimum path length among all their paths. In a tree, there is exactly one path between any two nodes.\n- The average pairwise latency of a candidate edge set $E'$ on $n$ nodes is defined as\n$$\n\\bar{L}(E') \\equiv \\frac{1}{\\binom{n}{2}} \\sum_{0 \\le i < j \\le n-1} d_{E'}(i,j),\n$$\nwhere $d_{E'}(i,j)$ denotes the shortest-path distance induced by $E'$. If a pair $(i,j)$ is disconnected under $E'$, define a penalized distance $d^{\\text{pen}}_{E',P}(i,j)$ by setting $d^{\\text{pen}}_{E',P}(i,j) = P$ for a fixed penalty parameter $P > 0$. The penalized average objective is then\n$$\n\\bar{L}_{\\text{pen}}(E';P) \\equiv \\frac{1}{\\binom{n}{2}} \\sum_{0 \\le i < j \\le n-1} d^{\\text{pen}}_{E',P}(i,j).\n$$\n\nYour task is to implement a Tabu Search that:\n- Maintains candidate solutions as exactly $n-1$ selected edges (not necessarily connected), so that feasibility is handled via penalties rather than enforced constraints.\n- Uses a neighborhood defined by one-edge insertion and one-edge removal per move. A move is a pair $(e^{+}, e^{-})$ where $e^{+}$ is an edge not currently selected, and $e^{-}$ is an edge currently selected. Applying the move swaps these edges.\n- Uses attribute-based tabu restrictions: after applying $(e^{+}, e^{-})$, adding back $e^{-}$ is tabu and removing $e^{+}$ is tabu for a given tenure (number of iterations), unless the aspiration criterion is met.\n- Employs an aspiration criterion that allows a tabu move if it yields a strictly better best-so-far penalized objective $\\bar{L}_{\\text{pen}}$.\n- Admits uphill moves (i.e., the search always selects the best admissible neighbor even if it worsens the current penalized objective), consistent with the fundamental Tabu Search principle of exploring beyond local minima.\n\nYour algorithmic requirements:\n- Initialization: Build the initial candidate solution as any valid set of exactly $n-1$ edges. To ensure scientific realism and determinism, construct the initial solution as the minimum spanning tree computed by Kruskal’s algorithm.\n- Objective calculation: For any candidate set $E'$, compute $\\bar{L}_{\\text{pen}}(E';P)$ as defined above. Use Dijkstra’s algorithm from each node to compute shortest-path distances. For any pair that is disconnected, use the penalty $P$ for that pair in the average. All computations are purely numerical; no physical units are involved.\n- Neighborhood and selection: In each iteration, evaluate all swaps $(e^{+}, e^{-})$. A move is tabu if $e^{+}$ is marked tabu-for-add or $e^{-}$ is marked tabu-for-remove, unless the aspiration criterion allows it. Among admissible moves, pick the one with the smallest $\\bar{L}_{\\text{pen}}$. Break ties deterministically by the lexicographic order of $(e^{+}\\text{-index}, e^{-}\\text{-index})$. If all moves are tabu and none meet aspiration, select the tabu move with the best $\\bar{L}_{\\text{pen}}$.\n- Update: Apply the chosen move, update tabu tenures on attributes (forbid adding back the removed edge and removing the added edge for the specified tenure), decrement all positive tabu counters by $1$ each iteration, and continuously track the best-so-far candidate by penalized objective.\n- Output: For each test case, output the best-so-far penalized average objective $\\bar{L}_{\\text{pen}}$ achieved by the search, rounded to exactly six digits after the decimal point.\n\nTest suite to implement and run inside your program (each case specifies $n$, an edge list, and Tabu Search parameters: iteration budget, tabu tenure, and penalty $P$). Nodes are labeled by integers starting at $0$. Edges are triples $(u,v,w)$ with $u<v$ and weight $w>0$.\n\n- Case A (balanced star optimum, happy path):\n  - $n = 5$.\n  - Edges:\n    - $(0,1,1.0)$, $(0,2,1.0)$, $(0,3,1.0)$, $(0,4,1.0)$,\n    - $(1,2,2.0)$, $(2,3,2.0)$, $(3,4,2.0)$, $(1,3,3.0)$, $(2,4,3.0)$, $(1,4,4.0)$.\n  - Iterations: $200$. Tabu tenure: $7$. Penalty: $P=1000$.\n\n- Case B (two-hub balanced optimum, multiple near alternatives):\n  - $n = 6$.\n  - Edges:\n    - $(0,1,0.5)$, $(0,2,1.0)$, $(0,3,1.0)$, $(1,4,1.0)$, $(1,5,1.0)$,\n    - $(2,3,2.0)$, $(4,5,2.0)$, $(2,4,3.0)$, $(3,5,3.0)$, $(0,4,2.5)$, $(1,2,2.2)$, $(3,4,2.8)$, $(2,5,2.7)$.\n  - Iterations: $250$. Tabu tenure: $7$. Penalty: $P=100$.\n\n- Case C (edge-case with a very heavy edge, tests penalty robustness):\n  - $n = 4$.\n  - Edges:\n    - $(0,1,1.0)$, $(1,2,1.0)$, $(2,3,10.0)$, $(0,3,1.0)$, $(0,2,3.0)$, $(1,3,3.5)$.\n  - Iterations: $200$. Tabu tenure: $5$. Penalty: $P=1000$.\n\n- Case D (boundary condition: $n=2$, no neighborhood):\n  - $n = 2$.\n  - Edges:\n    - $(0,1,2.0)$.\n  - Iterations: $50$. Tabu tenure: $3$. Penalty: $P=1000$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the cases A, B, C, D in this order, as a comma-separated list enclosed in square brackets. Each value must be the best penalized average objective $\\bar{L}_{\\text{pen}}$ found by your search for that case, rounded to exactly six digits after the decimal point. For example, an output for four cases should look like\n- \"[x_A,x_B,x_C,x_D]\" where each $x_{\\cdot}$ has exactly six digits after the decimal point, e.g., \"[1.600000,1.633333,1.666667,2.000000]\".",
            "solution": "The problem statement has been validated and is determined to be **valid**. It presents a clear, self-contained, and scientifically grounded optimization task. The definitions related to graph theory, spanning trees, and average latency are standard. The specification of the Tabu Search metaheuristic, including the neighborhood structure, candidate representation, attribute-based tabu restrictions, aspiration criterion, and deterministic tie-breaking, is formal and unambiguous. All necessary parameters and data for the test cases are provided, and there are no internal contradictions or violations of scientific principles.\n\nThe task is to implement a Tabu Search algorithm to find a set of $n-1$ edges on a weighted undirected graph that minimizes the penalized average pairwise latency.\n\n### Algorithmic Framework\nThe core of the solution is a Tabu Search (TS) algorithm. TS is a metaheuristic that guides a local search procedure to explore the solution space beyond local optima. Our implementation will adhere strictly to the provided specifications.\n\nThe state of the search is defined by:\n1.  The current candidate solution $E_{\\text{current}}$, a set of exactly $n-1$ edges.\n2.  The best-so-far solution found, $E_{\\text{best}}$, and its corresponding penalized objective value, $\\bar{L}_{\\text{pen, best}}$.\n3.  The tabu lists, which record which moves are forbidden for a certain number of iterations (the tabu tenure).\n\nThe search proceeds iteratively as follows:\n1.  An initial solution is generated using Kruskal's algorithm to find a Minimum Spanning Tree (MST).\n2.  In each iteration, the algorithm explores the neighborhood of the current solution. A neighbor is generated by a *swap move* $(e^{+}, e^{-})$, which removes an edge $e^{-}$ from the current edge set and adds an edge $e^{+}$ that is not in the current set.\n3.  Each potential move is evaluated based on the penalized average latency $\\bar{L}_{\\text{pen}}$ of the resulting edge set.\n4.  Moves are classified as *tabu* or *admissible*. A move is tabu if it is restricted by the tabu list. However, a tabu move can be made admissible by an *aspiration criterion*, specifically if it leads to a solution better than any found so far.\n5.  The algorithm selects the best admissible move (the one yielding the lowest $\\bar{L}_{\\text{pen}}$). If all moves are tabu and none meet the aspiration criterion, the best-performing tabu move is selected. This allows the search to make \"uphill\" moves to escape local minima.\n6.  The chosen move is applied to update the current solution. The tabu lists are updated to forbid the reversal of the move for a specified tenure.\n7.  The best-so-far solution is updated if the new solution is superior.\n8.  The process repeats for a fixed number of iterations.\n\n### Core Components and Implementation Strategy\n\n**1. State and Graph Representation**\nThe input graph with $n$ nodes and $m$ total edges is represented by a list of its edges. Each edge $e = (u, v, w)$ is mapped to a unique integer index from $0$ to $m-1$ for efficient management. A candidate solution is represented as a `set` of these integer edge indices. The tabu status is maintained in two NumPy arrays, `tabu_add` and `tabu_remove`, where `tabu_add[i]` stores the remaining tenure for which adding edge $i$ is forbidden, and `tabu_remove[i]` stores the tenure for which removing edge $i$ is forbidden.\n\n**2. Initialization**\nThe initial solution is constructed by finding the Minimum Spanning Tree (MST) of the input graph using Kruskal's algorithm. This is a standard greedy algorithm that requires a Disjoint Set Union (DSU) data structure to efficiently detect cycles. Kruskal's algorithm deterministically provides a high-quality (often connected and low-cost) starting point, as specified.\n\n**3. Objective Function Calculation**\nThe objective function is the penalized average latency, $\\bar{L}_{\\text{pen}}(E'; P)$. For a given candidate edge set $E'$, we must compute the sum of shortest-path distances over all $\\binom{n}{2}$ pairs of nodes.\nTo do this efficiently:\n- A temporary adjacency matrix is constructed from the edges in $E'$.\n- The `scipy.sparse.csgraph.dijkstra` function is used to compute the all-pairs shortest-path (APSP) distance matrix. This function is highly optimized and correctly handles disconnected components by assigning a distance of infinity ($\\infty$).\n- The total penalized distance is calculated by summing the finite distances and adding the penalty $P$ for each pair with an infinite distance.\n- The sum is then divided by $\\binom{n}{2}$ to obtain the average.\n\n**4. Neighborhood Search and Move Selection**\nIn each iteration, the neighborhood is generated by considering all possible swap moves $(e^{+}, e^{-})$, where $e^{-} \\in E_{\\text{current}}$ and $e^{+} \\notin E_{\\text{current}}$. For each move, the objective function of the resulting neighbor solution is calculated.\n- **Tabu Check**: A move $(e^{+}, e^{-})$ is considered tabu if `tabu_add[index(e+)] > 0` or `tabu_remove[index(e-)] > 0`. This means attempting to re-add an edge that was recently removed, or removing an edge that was recently added, is forbidden.\n- **Aspiration Criterion**: A tabu move is pardoned if the neighbor's objective `new_obj` is strictly less than the global best objective, `best_objective`.\n- **Move Selection**:\n  - The best admissible move (non-tabu or meets aspiration) is tracked.\n  - The best tabu move (that does not meet aspiration) is also tracked separately.\n  - Ties in objective value are broken deterministically by the lexicographical order of edge index pairs `(index(e+), index(e-))`.\n  - If any admissible moves exist, the best one is chosen. Otherwise, the best tabu move is chosen.\n\n**5. Tabu List Management**\nAfter selecting and applying a move $(e^{+}, e^{-})$:\n- The tabu list is updated. The attribute associated with the removed edge $e^{-}$ is made tabu-to-add for a duration of `tenure` iterations. This is implemented by setting `tabu_add[index(e-)] = tenure`.\n- Similarly, the attribute for the added edge $e^{+}$ is made tabu-to-remove: `tabu_remove[index(e+)] = tenure`.\n- At the beginning of each iteration, all positive tenure counters in both tabu lists are decremented by $1$.\n\nThis structured approach ensures all problem constraints and algorithmic requirements are met, leading to a deterministic and correct implementation of the specified Tabu Search. The final output for each test case is the best penalized average objective found throughout the search, formatted to six decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import dijkstra\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and print results for all test cases.\n    \"\"\"\n\n    class DSU:\n        \"\"\"Disjoint Set Union data structure for Kruskal's algorithm.\"\"\"\n        def __init__(self, n):\n            self.parent = list(range(n))\n\n        def find(self, i):\n            if self.parent[i] == i:\n                return i\n            self.parent[i] = self.find(self.parent[i])\n            return self.parent[i]\n\n        def union(self, i, j):\n            root_i = self.find(i)\n            root_j = self.find(j)\n            if root_i != root_j:\n                self.parent[root_i] = root_j\n                return True\n            return False\n\n    def kruskal_mst(n, all_edges_with_indices):\n        \"\"\"\n        Computes the Minimum Spanning Tree using Kruskal's algorithm.\n        Args:\n            n (int): Number of nodes.\n            all_edges_with_indices (list): List of tuples (weight, u, v, index).\n        Returns:\n            set: A set of edge indices forming the MST.\n        \"\"\"\n        if n < 2:\n            return set()\n            \n        sorted_edges = sorted(all_edges_with_indices)\n        dsu = DSU(n)\n        mst_edge_indices = []\n        num_edges_added = 0\n        for weight, u, v, index in sorted_edges:\n            if dsu.union(u, v):\n                mst_edge_indices.append(index)\n                num_edges_added += 1\n                if num_edges_added == n - 1:\n                    break\n        return set(mst_edge_indices)\n\n    def calculate_objective(n, current_edge_indices, all_edges_list, penalty):\n        \"\"\"\n        Calculates the penalized average pairwise latency.\n        Args:\n            n (int): Number of nodes.\n            current_edge_indices (set): Set of indices for edges in the current solution.\n            all_edges_list (list): The list of all edges (u, v, w) in the graph.\n            penalty (float): Penalty for disconnected pairs.\n        Returns:\n            float: The calculated objective value.\n        \"\"\"\n        if n <= 1:\n            return 0.0\n\n        graph_matrix = np.full((n, n), np.inf, dtype=np.float64)\n        np.fill_diagonal(graph_matrix, 0)\n\n        for edge_idx in current_edge_indices:\n            u, v, w = all_edges_list[edge_idx]\n            # Use min in case of parallel edges in test data (though not present)\n            graph_matrix[u, v] = min(w, graph_matrix[u, v])\n            graph_matrix[v, u] = min(w, graph_matrix[v, u])\n        \n        dist_matrix = dijkstra(csgraph=graph_matrix, directed=False)\n        \n        num_pairs = n * (n - 1) // 2\n        \n        # Fast summation using NumPy\n        indices = np.triu_indices(n, k=1)\n        distances = dist_matrix[indices]\n        \n        disconnected_count = np.isinf(distances).sum()\n        total_dist = disconnected_count * penalty\n        \n        connected_distances = distances[np.isfinite(distances)]\n        total_dist += np.sum(connected_distances)\n                \n        return total_dist / num_pairs\n\n    def tabu_search(n, edges, iterations, tenure, penalty):\n        \"\"\"\n        Performs Tabu Search to optimize the spanning tree for minimum average latency.\n        Args:\n            n (int): Number of nodes.\n            edges (list): List of all available edges as (u, v, w) tuples.\n            iterations (int): Total number of iterations for the search.\n            tenure (int): Tabu tenure duration.\n            penalty (float): Penalty for disconnected pairs.\n        Returns:\n            float: The best penalized average objective found.\n        \"\"\"\n        if n <= 1:\n            return 0.0\n        \n        num_total_edges = len(edges)\n        \n        # Handle boundary case where a swap is not possible\n        if num_total_edges <= n - 1:\n            # kruskal_mst will simply select all available edges\n            kruskal_input = [(w, u, v, i) for i, (u, v, w) in enumerate(edges)]\n            initial_edge_indices = kruskal_mst(n, kruskal_input)\n            return calculate_objective(n, initial_edge_indices, edges, penalty)\n\n        kruskal_input = [(w, u, v, i) for i, (u, v, w) in enumerate(edges)]\n        initial_edge_indices = kruskal_mst(n, kruskal_input)\n\n        current_edges = initial_edge_indices\n        best_edges = initial_edge_indices.copy()\n        \n        initial_objective = calculate_objective(n, current_edges, edges, penalty)\n        best_objective = initial_objective\n\n        tabu_add = np.zeros(num_total_edges, dtype=int)\n        tabu_remove = np.zeros(num_total_edges, dtype=int)\n        \n        all_edge_indices = set(range(num_total_edges))\n\n        for _ in range(iterations):\n            tabu_add[tabu_add > 0] -= 1\n            tabu_remove[tabu_remove > 0] -= 1\n\n            best_admissible_move, best_admissible_obj, best_admissible_key = None, float('inf'), (float('inf'), float('inf'))\n            best_tabu_move, best_tabu_obj, best_tabu_key = None, float('inf'), (float('inf'), float('inf'))\n\n            edges_out_of_solution = all_edge_indices - current_edges\n            \n            for e_out_idx in current_edges:\n                for e_in_idx in edges_out_of_solution:\n                    neighbor_edges = current_edges - {e_out_idx} | {e_in_idx}\n                    neighbor_obj = calculate_objective(n, neighbor_edges, edges, penalty)\n                    move_key = (e_in_idx, e_out_idx)\n\n                    is_tabu = tabu_add[e_in_idx] > 0 or tabu_remove[e_out_idx] > 0\n                    aspiration_met = neighbor_obj < best_objective\n\n                    if not is_tabu or aspiration_met:\n                        if neighbor_obj < best_admissible_obj or \\\n                           (neighbor_obj == best_admissible_obj and move_key < best_admissible_key):\n                            best_admissible_obj = neighbor_obj\n                            best_admissible_move = (e_in_idx, e_out_idx)\n                            best_admissible_key = move_key\n                    else:\n                        if neighbor_obj < best_tabu_obj or \\\n                           (neighbor_obj == best_tabu_obj and move_key < best_tabu_key):\n                            best_tabu_obj = neighbor_obj\n                            best_tabu_move = (e_in_idx, e_out_idx)\n                            best_tabu_key = move_key\n\n            chosen_move = None\n            if best_admissible_move is not None:\n                chosen_move = best_admissible_move\n                chosen_obj = best_admissible_obj\n            elif best_tabu_move is not None:\n                chosen_move = best_tabu_move\n                chosen_obj = best_tabu_obj\n\n            if chosen_move is None:\n                break\n\n            e_in_idx, e_out_idx = chosen_move\n            \n            current_edges.remove(e_out_idx)\n            current_edges.add(e_in_idx)\n            current_objective = chosen_obj\n\n            tabu_add[e_out_idx] = tenure\n            tabu_remove[e_in_idx] = tenure\n\n            if current_objective < best_objective:\n                best_objective = current_objective\n                best_edges = current_edges.copy()\n\n        return best_objective\n\n    test_cases = [\n        # Case A\n        {'n': 5, 'edges': [\n            (0,1,1.0), (0,2,1.0), (0,3,1.0), (0,4,1.0),\n            (1,2,2.0), (2,3,2.0), (3,4,2.0), (1,3,3.0), (2,4,3.0), (1,4,4.0)],\n         'iterations': 200, 'tenure': 7, 'penalty': 1000},\n        # Case B\n        {'n': 6, 'edges': [\n            (0,1,0.5), (0,2,1.0), (0,3,1.0), (1,4,1.0), (1,5,1.0),\n            (2,3,2.0), (4,5,2.0), (2,4,3.0), (3,5,3.0), (0,4,2.5), \n            (1,2,2.2), (3,4,2.8), (2,5,2.7)],\n         'iterations': 250, 'tenure': 7, 'penalty': 100},\n        # Case C\n        {'n': 4, 'edges': [\n            (0,1,1.0), (1,2,1.0), (2,3,10.0), (0,3,1.0), (0,2,3.0), (1,3,3.5)],\n         'iterations': 200, 'tenure': 5, 'penalty': 1000},\n        # Case D\n        {'n': 2, 'edges': [(0,1,2.0)],\n         'iterations': 50, 'tenure': 3, 'penalty': 1000}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = tabu_search(case['n'], case['edges'], case['iterations'], case['tenure'], case['penalty'])\n        results.append(f\"{result:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "This final practice showcases the remarkable flexibility of Tabu Search by applying it to the register allocation problem, a core task in compiler design. This exercise  demonstrates how to abstract a complex, real-world scenario into a formal optimization model that a metaheuristic can solve. By modeling variables, registers, and interference constraints within the TS framework, you will learn how the principles of solution representation, neighborhood definition, and objective function design can be adapted to diverse and practical domains.",
            "id": "3190900",
            "problem": "Consider the combinatorial optimization problem of register allocation using Tabu Search (TS). Let there be $n$ program variables indexed by $i \\in \\{1,2,\\dots,n\\}$ and $k$ machine registers indexed by $r \\in \\{1,2,\\dots,k\\}$. An assignment is a function $x:\\{1,\\dots,n\\}\\to \\{0,1,\\dots,k\\}$, where $x_i = 0$ denotes that variable $i$ is spilled to memory and $x_i = r$ denotes that variable $i$ is assigned to register $r$. The interference constraints are given by an undirected graph $G=(V,E)$ with $V=\\{1,\\dots,n\\}$, where an edge $(i,j)\\in E$ indicates that variables $i$ and $j$ cannot share the same register simultaneously. A soft cost model is defined by spill costs $s_i \\ge 0$ for spilling variable $i$ and register assignment costs $c_{i,r} \\ge 0$ for assigning variable $i$ to register $r$, capturing attributes such as variable-register bindings and preferences. A variable $i$ may be restricted to a subset of allowed registers $A_i \\subseteq \\{1,\\dots,k\\}$; assignments to registers outside $A_i$ are disallowed.\n\nDefine the objective function to be minimized as\n$$\nC(x) = \\sum_{i=1}^{n} \\left( \\mathbf{1}\\{x_i=0\\} \\cdot s_i + \\mathbf{1}\\{x_i\\neq 0\\} \\cdot c_{i,x_i} \\right) + M \\cdot \\sum_{(i,j)\\in E} \\mathbf{1}\\{x_i = x_j \\land x_i \\neq 0\\},\n$$\nwhere $M$ is a positive penalty parameter chosen strictly larger than any achievable sum of spill and register costs so that violating interference constraints is strongly discouraged whenever a feasible assignment exists.\n\nImplement a deterministic Tabu Search (TS) to minimize $C(x)$ under the following fundamental design derived from standard heuristic search principles:\n1. Initialization: Start from the assignment $x_i=0$ for all $i$.\n2. Neighborhood: At each iteration, consider all moves that change exactly one component $x_i$: either set $x_i$ to any allowed register $r \\in A_i$ with $r \\neq x_i$, or set $x_i=0$ if $x_i \\neq 0$.\n3. Move attributes and tabu list: When performing a move that changes $x_i$ from a value $v_{\\text{old}}$ to a value $v_{\\text{new}}$, add the attribute $(i, v_{\\text{old}})$ to the tabu list with a fixed tenure $t$. A candidate move that sets $x_i$ to a value $v$ is tabu if $(i, v)$ is present in the tabu list with positive remaining tenure.\n4. Aspiration criterion: Allow a tabu move if it yields a strictly better objective than the best seen so far.\n5. Move selection and ties: Among admissible moves, select the one with minimum objective value. Break ties deterministically by choosing the smallest variable index $i$, and if still tied, the smallest target value for $x_i$ (with spill represented by $0$, which is smaller than any register index).\n6. Iteration and termination: Use a fixed iteration budget $I$, always moving to the selected neighbor even if it does not improve the current objective, and update the tabu tenures each iteration.\n\nYour program must implement this TS exactly as specified, with the penalty $M$ selected as\n$$\nM = \\left( \\sum_{i=1}^{n} s_i \\right) + \\left( \\sum_{i=1}^{n} \\max_{r \\in A_i} c_{i,r} \\right) + 1,\n$$\nwhich guarantees that one unit of conflict costs more than any non-conflicting combination of spill and register costs.\n\nUse the following test suite of instances, each given by $(n,k,E,s,c,\\{A_i\\}_{i=1}^{n})$. All indices for variables and registers in $E$ and $A_i$ are one-based. The algorithm must not generate assignments to disallowed registers.\n\nTest case $1$ (happy path with a feasible coloring):\n- $n=5$, $k=3$.\n- $E = \\{(1,2),(1,3),(2,4),(3,4),(4,5)\\}$.\n- $s = [8,7,6,9,5]$.\n- $c = \\begin{bmatrix}\n0 & 4 & 2\\\\\n3 & 0 & 5\\\\\n6 & 2 & 0\\\\\n0 & 2 & 4\\\\\n3 & 1 & 0\n\\end{bmatrix}$.\n- $A_1 = \\{1,2,3\\}$, $A_2 = \\{1,2,3\\}$, $A_3 = \\{1,2,3\\}$, $A_4 = \\{1,2,3\\}$, $A_5 = \\{1,2,3\\}$.\n\nTest case $2$ (boundary with $k=1$ and chain interference):\n- $n=4$, $k=1$.\n- $E = \\{(1,2),(2,3),(3,4)\\}$.\n- $s = [5,5,5,5]$.\n- $c = \\begin{bmatrix}\n0\\\\\n0\\\\\n0\\\\\n0\n\\end{bmatrix}$.\n- $A_1 = \\{1\\}$, $A_2 = \\{1\\}$, $A_3 = \\{1\\}$, $A_4 = \\{1\\}$.\n\nTest case $3$ (allowed-register restrictions and a cross-edge making conflicts unavoidable without spills):\n- $n=6$, $k=2$.\n- $E = \\{(1,2),(2,3),(1,3),(4,5),(5,6),(4,6),(3,4)\\}$.\n- $s = [9,4,9,4,8,3]$.\n- $c = \\begin{bmatrix}\n0 & 999\\\\\n1 & 0\\\\\n999 & 0\\\\\n999 & 0\\\\\n2 & 0\\\\\n0 & 999\n\\end{bmatrix}$.\n- $A_1 = \\{1\\}$, $A_2 = \\{1,2\\}$, $A_3 = \\{2\\}$, $A_4 = \\{2\\}$, $A_5 = \\{1,2\\}$, $A_6 = \\{1\\}$.\n\nTest case $4$ (no interference; assign to cheapest allowed registers):\n- $n=4$, $k=2$.\n- $E = \\emptyset$.\n- $s = [10,10,10,10]$.\n- $c = \\begin{bmatrix}\n1 & 5\\\\\n0 & 2\\\\\n3 & 0\\\\\n2 & 2\n\\end{bmatrix}$.\n- $A_1 = \\{1,2\\}$, $A_2 = \\{1,2\\}$, $A_3 = \\{1,2\\}$, $A_4 = \\{1,2\\}$.\n\nTest case $5$ (all variables allowed only one register; chain interference mandates spills):\n- $n=3$, $k=2$.\n- $E = \\{(1,2),(2,3)\\}$.\n- $s = [3,3,3]$.\n- $c = \\begin{bmatrix}\n1 & 999\\\\\n0 & 999\\\\\n2 & 999\n\\end{bmatrix}$.\n- $A_1 = \\{1\\}$, $A_2 = \\{1\\}$, $A_3 = \\{1\\}$.\n\nImplementation details:\n- Use a fixed tabu tenure $t=7$ and a fixed iteration budget $I=200$.\n- Use one-based register indices in the mathematical description but implement in zero-based arrays internally as needed.\n- Ensure determinism via the specified tie-breaking and by avoiding any randomness.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, namely $[r_1,r_2,r_3,r_4,r_5]$, where each $r_j$ is the minimal objective value found by the TS on the $j$-th test case. No physical units or angles are involved in this problem; all values are dimensionless integers derived from the defined costs and penalties. The output must be exactly in the specified format.",
            "solution": "The user has provided a well-defined combinatorial optimization problem, specifically register allocation, to be solved using a deterministically specified Tabu Search (TS) algorithm.\n\n### Step 1: Problem Validation\n\nThe first step is to validate the problem statement.\n\n#### Extracted Givens:\n- **Problem**: Minimize a cost function for register allocation.\n- **Entities**: $n$ variables, $k$ registers.\n- **Assignment**: $x_i \\in \\{0, 1, \\dots, k\\}$, where $x_i=0$ is a memory spill.\n- **Objective Function**: $C(x) = \\sum_{i=1}^{n} \\left( \\mathbf{1}\\{x_i=0\\} \\cdot s_i + \\mathbf{1}\\{x_i\\neq 0\\} \\cdot c_{i,x_i} \\right) + M \\cdot \\sum_{(i,j)\\in E} \\mathbf{1}\\{x_i = x_j \\land x_i \\neq 0\\}$.\n- **Penalty Parameter**: $M = \\left( \\sum_{i=1}^{n} s_i \\right) + \\left( \\sum_{i=1}^{n} \\max_{r \\in A_i} c_{i,r} \\right) + 1$.\n- **Hard Constraints**: Variable $i$ can only be assigned to registers in a given set $A_i$.\n- **Algorithm**: Deterministic Tabu Search with the following specifications:\n    1.  **Initialization**: All variables are spilled, i.e., $x_i=0$ for all $i$.\n    2.  **Neighborhood**: A move consists of changing the assignment $x_i$ for a single variable $i$ to a different, allowed value (either another register in $A_i$ or spilling to memory, represented by $0$).\n    3.  **Tabu Mechanism**: When moving $x_i$ from $v_{\\text{old}}$ to $v_{\\text{new}}$, the attribute $(i, v_{\\text{old}})$ is added to the tabu list with tenure $t$. A subsequent move setting $x_i$ to a value $v$ is tabu if $(i, v)$ is in the list. This prevents a variable's assignment from being immediately reverted.\n    4.  **Aspiration Criterion**: A tabu move is permitted if it results in a solution with a cost strictly lower than the best cost found so far in the search.\n    5.  **Move Selection & Tie-Breaking**: The best admissible move (non-tabu or meets aspiration) is chosen. Ties are broken by prioritizing the move involving the smallest variable index $i$, and then the smallest new assignment value $v_{\\text{new}}$ (with $0$ being the smallest).\n    6.  **Termination**: The search runs for a fixed number of iterations, $I$.\n- **Parameters**: Tabu tenure $t=7$, iteration budget $I=200$.\n- **Data**: Five distinct test cases are provided with all necessary parameters ($n, k, E, s, c, \\{A_i\\}$).\n\n#### Validation Verdict:\nThe problem is **valid**.\n- It is **scientifically grounded** in the established field of combinatorial optimization and compiler design.\n- It is **well-posed**, with all parameters, rules, and initial conditions specified, ensuring a deterministic and unique outcome.\n- It is **objective**, using precise mathematical language and avoiding any subjectivity.\n- The structure is complete and free of contradictions. The provided formula for the penalty $M$ is sound and serves its intended purpose of penalizing constraint violations more heavily than any possible valid assignment cost.\n\n### Step 2: Algorithmic Solution\nBased on the validated problem, a Python implementation of the specified Tabu Search algorithm is designed. The logic proceeds as follows for each test case.\n\n1.  **Data Preparation**: The parameters for the current test case ($n, k, E, s, c, A$) are loaded. The 1-based indices from the problem description are converted to 0-based indices for use in Python arrays and lists (e.g., variables $0$ to $n-1$, edges referencing these indices). An adjacency list representation of the interference graph $G=(V,E)$ is constructed for efficient lookup of conflicting variables.\n\n2.  **Penalty Calculation**: The penalty parameter $M$ is calculated precisely according to the given formula. This value ensures that any solution with even a single register conflict has a higher cost than any conflict-free solution.\n\n3.  **Initialization**: The search starts from the initial assignment $x$, where all variables are spilled ($x_i=0$ for all $i=0, \\dots, n-1$). The cost of this initial solution, $C(x_{\\text{initial}})$, is calculated. This solution and its cost are set as the initial best-found-so-far solution, $x_{\\text{best}}$, and cost, $C_{\\text{best}}$. A tabu list, implemented as a 2D array `tabu_list[n][k+1]`, is initialized to all zeros. `tabu_list[i][v]` will store the remaining tenure for which assigning value $v$ to variable $i$ is tabu.\n\n4.  **Iterative Search**: The main loop executes for a fixed number of iterations $I=200$. In each iteration:\n    a.  **Tabu Tenure Update**: All positive entries in the `tabu_list` are decremented by $1$. This simulates the passage of time and the eventual expiration of tabu statuses.\n    b.  **Neighborhood Exploration**: The algorithm systematically explores the neighborhood of the current solution $x$. For each variable $i \\in \\{0, \\dots, n-1\\}$, it considers all possible moves to a new value $v_{\\text{new}} \\in (A_i \\cup \\{0\\}) \\setminus \\{x_i\\}$. This exploration is ordered by variable index $i$ and then by the new value $v_{\\text{new}}$ to enforce the deterministic tie-breaking rule.\n    c.  **Move Evaluation**: For each potential move, the cost of the resulting neighbor solution is calculated. To optimize performance, this is done incrementally. The change in cost ($\\Delta C$) is computed by considering only the change in the base cost for variable $i$ and the change in conflict costs involving variable $i$ and its neighbors in the interference graph. The neighbor's cost is then $C(x') = C(x) + \\Delta C$.\n    d.  **Admissibility Check**: Each move is checked for admissibility. A move to set $x_i$ to $v_{\\text{new}}$ is admissible if either:\n        i.  It is not tabu (i.e., `tabu_list[i][v_new] == 0`).\n        ii. It is tabu but satisfies the aspiration criterion (i.e., the resulting cost $C(x')$ is strictly less than $C_{\\text{best}}$).\n    e.  **Best Move Selection**: The algorithm tracks the best admissible move found so far in the current iteration's neighborhood scan. The move leading to the lowest cost is selected, with ties broken deterministically by the predefined order of evaluation.\n    f.  **State Transition**: If an admissible move was found, the current solution $x$ is updated by applying the best move. The cost $C(x)$ is also updated. The `tabu_list` is modified by setting the tenure for the *reverse* move. Specifically, if $x_i$ was changed from $v_{\\text{old}}$ to $v_{\\text{new}}$, `tabu_list[i][v_old]` is set to the tabu tenure $t=7$.\n    g.  **Best Solution Update**: If the new current solution $x$ has a cost lower than $C_{\\text{best}}$, then $x_{\\text{best}}$ and $C_{\\text{best}}$ are updated.\n\n5.  **Result Collection**: After $I$ iterations, the final value of $C_{\\text{best}}$ for the current test case is stored. This process is repeated for all test cases.\n\n6.  **Final Output**: The collected minimal costs from all test cases are formatted into a single comma-separated string enclosed in square brackets, as required.\n\nThis detailed, deterministic procedure is implemented in the Python code provided in the final answer.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the specified deterministic Tabu Search algorithm for the register allocation problem.\n\n    The solution follows the problem's strict definition of the Tabu Search metaheuristic,\n    including initialization, neighborhood structure, tabu tenure, aspiration criterion,\n    deterministic tie-breaking, and termination condition.\n    \"\"\"\n    \n    test_suite = [\n        {\n            \"n\": 5, \"k\": 3, \"E\": [(1, 2), (1, 3), (2, 4), (3, 4), (4, 5)],\n            \"s\": [8, 7, 6, 9, 5],\n            \"c\": [[0, 4, 2], [3, 0, 5], [6, 2, 0], [0, 2, 4], [3, 1, 0]],\n            \"A\": [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]\n        },\n        {\n            \"n\": 4, \"k\": 1, \"E\": [(1, 2), (2, 3), (3, 4)],\n            \"s\": [5, 5, 5, 5],\n            \"c\": [[0], [0], [0], [0]],\n            \"A\": [[1], [1], [1], [1]]\n        },\n        {\n            \"n\": 6, \"k\": 2, \"E\": [(1, 2), (2, 3), (1, 3), (4, 5), (5, 6), (4, 6), (3, 4)],\n            \"s\": [9, 4, 9, 4, 8, 3],\n            \"c\": [[0, 999], [1, 0], [999, 0], [999, 0], [2, 0], [0, 999]],\n            \"A\": [[1], [1, 2], [2], [2], [1, 2], [1]]\n        },\n        {\n            \"n\": 4, \"k\": 2, \"E\": [],\n            \"s\": [10, 10, 10, 10],\n            \"c\": [[1, 5], [0, 2], [3, 0], [2, 2]],\n            \"A\": [[1, 2], [1, 2], [1, 2], [1, 2]]\n        },\n        {\n            \"n\": 3, \"k\": 2, \"E\": [(1, 2), (2, 3)],\n            \"s\": [3, 3, 3],\n            \"c\": [[1, 999], [0, 999], [2, 999]],\n            \"A\": [[1], [1], [1]]\n        }\n    ]\n\n    I = 200  # Iteration budget\n    t = 7    # Tabu tenure\n\n    final_results = []\n\n    for case_data in test_suite:\n        n = case_data[\"n\"]\n        k = case_data[\"k\"]\n        s = np.array(case_data[\"s\"])\n        c = np.array(case_data[\"c\"])\n        E_0based = [(u - 1, v - 1) for u, v in case_data[\"E\"]]\n        A = case_data[\"A\"]\n\n        adj = [[] for _ in range(n)]\n        for u, v in E_0based:\n            adj[u].append(v)\n            adj[v].append(u)\n\n        sum_s = np.sum(s)\n        sum_max_c = 0\n        for i in range(n):\n            if not A[i]:\n                max_c_i = 0\n            else:\n                max_c_i = max(c[i][r - 1] for r in A[i])\n            sum_max_c += max_c_i\n        M = sum_s + sum_max_c + 1\n\n        def calculate_full_cost(assignment):\n            cost = 0\n            for i in range(n):\n                if assignment[i] == 0:\n                    cost += s[i]\n                else:\n                    cost += c[i][assignment[i] - 1]\n            for u, v in E_0based:\n                if assignment[u] != 0 and assignment[u] == assignment[v]:\n                    cost += M\n            return cost\n\n        x = np.zeros(n, dtype=int)\n        current_cost = calculate_full_cost(x)\n        \n        best_x = np.copy(x)\n        best_cost = current_cost\n        \n        tabu_list = np.zeros((n, k + 1), dtype=int)\n\n        for _ in range(I):\n            tabu_list[tabu_list > 0] -= 1\n\n            best_move = None\n            best_move_cost = float('inf')\n\n            for i in range(n):\n                v_old = x[i]\n                \n                allowed_vals = set(A[i])\n                allowed_vals.add(0)\n                move_options = sorted([val for val in allowed_vals if val != v_old])\n\n                for v_new in move_options:\n                    old_base_cost_i = s[i] if v_old == 0 else c[i][v_old - 1]\n                    new_base_cost_i = s[i] if v_new == 0 else c[i][v_new - 1]\n                    delta_base = new_base_cost_i - old_base_cost_i\n                    \n                    delta_conflict = 0\n                    for j in adj[i]:\n                        if v_old != 0 and v_old == x[j]:\n                            delta_conflict -= M\n                        if v_new != 0 and v_new == x[j]:\n                            delta_conflict += M\n                    \n                    move_cost = current_cost + delta_base + delta_conflict\n                    \n                    is_tabu = tabu_list[i][v_new] > 0\n                    aspirated = move_cost < best_cost\n                    \n                    if (not is_tabu) or aspirated:\n                        if move_cost < best_move_cost:\n                            best_move_cost = move_cost\n                            best_move = (i, v_new)\n            \n            if best_move is None:\n                break\n                \n            i_move, v_new_move = best_move\n            v_old_move = x[i_move]\n            \n            x[i_move] = v_new_move\n            current_cost = best_move_cost\n            \n            tabu_list[i_move][v_old_move] = t\n            \n            if current_cost < best_cost:\n                best_cost = current_cost\n                best_x = np.copy(x)\n        \n        final_results.append(best_cost)\n    \n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}