{
    "hands_on_practices": [
        {
            "introduction": "本练习将介绍一种最基础的分解技术：拉格朗日松弛法。通过将耦合约束“松弛”并以惩罚项（即拉格朗日乘子）的形式纳入目标函数，我们通常可以将一个大型的整体问题分解为多个较小的、可独立求解的子问题。这个练习将指导你实现对偶次梯度法来求解一个可分离的二次规划问题，让你能够亲身体验在对偶解的质量与原始解的可行性之间的核心权衡 。",
            "id": "3116747",
            "problem": "给定一个凸的可分离优化问题族，其中每个问题都带有一个单一的线性耦合约束。对于一个整数 $m \\ge 2$，每个问题具有以下形式：\n$$\n\\min_{x \\in \\mathbb{R}^m} \\;\\; f(x) = \\sum_{i=1}^m f_i(x_i)\n\\quad \\text{subject to} \\quad \\sum_{i=1}^m A_i x_i = b, \\quad \\ell_i \\le x_i \\le u_i,\n$$\n其中每个分量函数都是二次的，\n$$\nf_i(x_i) = \\tfrac{1}{2} q_i x_i^2 + c_i x_i,\n$$\n且 $q_i  0$，边界满足 $\\ell_i  u_i$，因此可行集非空有界。耦合是一个单一的标量等式约束，其系数为 $A_i$，右侧值为 $b$。\n\n从（未增广的）拉格朗日函数及其对偶函数的定义出发，考虑使用对偶变量 $\\lambda \\in \\mathbb{R}$ 的标准拉格朗日松弛，\n$$\n\\mathcal{L}(x,\\lambda) = \\sum_{i=1}^m f_i(x_i) + \\lambda \\Big( \\sum_{i=1}^m A_i x_i - b \\Big),\n$$\n以及对偶函数 $g(\\lambda) = \\inf_{x \\in [\\ell,u]} \\mathcal{L}(x,\\lambda)$，其中 $[\\ell,u]$ 表示箱式区域 $\\prod_{i=1}^m [\\ell_i,u_i]$。对偶问题是在 $\\lambda \\in \\mathbb{R}$ 上最大化 $g(\\lambda)$。在对偶问题上使用步长等于 $1/\\rho$ 的常数步长次梯度上升法，其中 $\\rho  0$ 是用户选择的罚参数。具体来说，从初始值 $\\lambda_0 = 0$ 开始，对 $k = 0,1,\\ldots,T-1$ 进行迭代：\n- 计算 $x^{(k)} \\in \\arg\\min_{\\ell \\le x \\le u}\\, \\mathcal{L}(x,\\lambda_k)$（这在索引 $i$ 上是可分离的）。\n- 计算标量次梯度 $r_k = \\sum_{i=1}^m A_i x_i^{(k)} - b$。\n- 更新 $\\lambda_{k+1} = \\lambda_k + \\frac{1}{\\rho}\\, r_k$。\n\n经过 $T$ 次迭代后，构建平均原始候选解 $\\bar{x} = \\frac{1}{T} \\sum_{k=0}^{T-1} x^{(k)}$。令 $p^\\star$ 表示原始约束问题的最优原始值，令 $d_{\\text{best}}$ 表示在 $T$ 次迭代中观察到的最佳对偶值，即 $d_{\\text{best}} = \\max_{0 \\le k \\le T-1} g(\\lambda_k)$。请量化：\n- 对偶间隙 $p^\\star - d_{\\text{best}}$（一个非负浮点数）。\n- 恢复的平均解的原始可行性残差 $|\\sum_{i=1}^m A_i \\bar{x}_i - b|$（一个非负浮点数）。\n\n你的程序必须：\n1.  仅使用问题的核心定义和一阶最优性原理，高精度地计算 $p^\\star$。你不能假设任何预先推导出的封闭形式解。对于与等式约束相关的单个拉格朗日乘子，使用数值稳健的标量求根方法，并使用 Karush–Kuhn–Tucker 条件处理箱式约束。\n2.  实现上述描述的、步长为常数 $1/\\rho$ 的对偶次梯度上升法，在每次迭代中使用最小化 $x^{(k)}$ 来评估 $g(\\lambda_k)$，并跟踪 $d_{\\text{best}}$。\n3.  恢复 $\\bar{x}$ 并计算可行性残差。\n4.  为每个测试用例报告一对浮点数：首先是 $p^\\star - d_{\\text{best}}$，然后是 $|\\sum_{i=1}^m A_i \\bar{x}_i - b|$。每个浮点数应四舍五入到 $6$ 位小数。\n\n你必须使用的基本原理：\n- 等式约束的拉格朗日函数 $\\mathcal{L}(x,\\lambda)$ 的定义。\n- 对偶函数 $g(\\lambda) = \\inf_x \\mathcal{L}(x,\\lambda)$ 的定义，以及 $g$ 在 $\\lambda$ 处的次梯度是原始残差 $\\sum_i A_i x_i^\\star(\\lambda) - b$ 这一事实，其中 $x^\\star(\\lambda)$ 是在箱式约束下 $\\mathcal{L}(\\cdot,\\lambda)$ 的任意最小化子。\n- 用于计算 $p^\\star$ 的 Karush–Kuhn–Tucker 条件，适用于带单个线性等式约束和边界约束的凸二次规划，通过对拉格朗日乘子进行标量搜索来求解。\n\n测试套件：\n使用以下五个测试用例，每个用例指定为 $(m, q, c, A, \\ell, u, b, T, \\rho)$，其中向量按坐标顺序给出：\n- 案例 1（顺利路径，中等规模）：$m = 4$，$q = [\\,2,\\,1,\\,4,\\,3\\,]$，$c = [\\,0,\\,-1,\\,2,\\,-0.5\\,]$，$A = [\\,1,\\,-2,\\,1.5,\\,1\\,]$，$\\ell = [\\,-1,\\,0,\\,-0.5,\\,-2\\,]$，$u = [\\,2,\\,2,\\,1.5,\\,1\\,]$，$b = 0.7$，$T = 200$，$\\rho = 0.5$。\n- 案例 2（相同数据，较缓步长）：$m = 4$，$q = [\\,2,\\,1,\\,4,\\,3\\,]$，$c = [\\,0,\\,-1,\\,2,\\,-0.5\\,]$，$A = [\\,1,\\,-2,\\,1.5,\\,1\\,]$，$\\ell = [\\,-1,\\,0,\\,-0.5,\\,-2\\,]$，$u = [\\,2,\\,2,\\,1.5,\\,1\\,]$，$b = 0.7$，$T = 200$，$\\rho = 2$。\n- 案例 3（相同数据，小步长）：$m = 4$，$q = [\\,2,\\,1,\\,4,\\,3\\,]$，$c = [\\,0,\\,-1,\\,2,\\,-0.5\\,]$，$A = [\\,1,\\,-2,\\,1.5,\\,1\\,]$，$\\ell = [\\,-1,\\,0,\\,-0.5,\\,-2\\,]$，$u = [\\,2,\\,2,\\,1.5,\\,1\\,]$，$b = 0.7$，$T = 200$，$\\rho = 20$。\n- 案例 4（上边界为最优解）：$m = 3$，$q = [\\,1,\\,1,\\,1\\,]$，$c = [\\,0.1,\\,-0.2,\\,0.3\\,]$，$A = [\\,1,\\,1,\\,1\\,]$，$\\ell = [\\,0,\\,0,\\,0\\,]$，$u = [\\,1,\\,1,\\,1\\,]$，$b = 3$，$T = 200$，$\\rho = 2$。\n- 案例 5（病态曲率）：$m = 4$，$q = [\\,0.1,\\,10,\\,0.5,\\,8\\,]$，$c = [\\,0,\\,0,\\,0,\\,0\\,]$，$A = [\\,1,\\,1,\\,-1,\\,2\\,]$，$\\ell = [\\,-1,\\,-1,\\,-1,\\,-1\\,]$，$u = [\\,1,\\,1,\\,1,\\,1\\,]$，$b = 0.3$，$T = 200$，$\\rho = 2$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按顺序包含五个案例中每个案例的对偶间隙和可行性残差，两者均四舍五入到 $6$ 位小数。例如，输出必须如下所示：\n$$\n[\\;g_1,\\;r_1,\\;g_2,\\;r_2,\\;g_3,\\;r_3,\\;g_4,\\;r_4,\\;g_5,\\;r_5\\;],\n$$\n其中 $g_j$ 是案例 $j$ 的 $p^\\star - d_{\\text{best}}$，$r_j$ 是 $|\\sum_i A_i \\bar{x}_i - b|$。不得打印任何其他文本。",
            "solution": "该问题提出了一个凸的可分离二次优化问题，其带有一个单一的线性耦合约束和箱式约束。任务是计算精确的原始最优值，实现一个对偶次梯度上升算法，并报告最终的对偶间隙和原始可行性残差。\n\n该问题是有效的。它在科学上基于凸优化和对偶理论的原理。目标函数 $f(x) = \\sum_{i=1}^m f_i(x_i)$，其中每个 $f_i(x_i) = \\frac{1}{2} q_i x_i^2 + c_i x_i$ 且 $q_i  0$，是严格凸的。可行集由超平面 $\\sum_{i=1}^m A_i x_i = b$ 和一个紧致的箱式区域 $[\\ell, u] = \\prod_{i=1}^m [\\ell_i, u_i]$ 的交集定义，是凸且紧致的。问题陈述保证了该集合非空。因此，存在唯一的解 $x^\\star$，且该问题是适定的。所有参数和算法细节都已精确指定，使得问题自成体系且客观。\n\n我们的解决方案主要分两个阶段进行：首先，通过 Karush-Kuhn-Tucker (KKT) 条件计算精确的原始最优值 $p^\\star$；其次，实现指定的对偶次梯度方法以找到最佳对偶界 $d_{\\text{best}}$ 和平均原始解 $\\bar{x}$。\n\n### 第 1 部分：通过 KKT 条件求解精确的原始解\n\n为了找到精确的原始最优值 $p^\\star$，我们直接求解原始问题。该问题为：\n$$\n\\min_{x \\in \\mathbb{R}^m} \\;\\; \\sum_{i=1}^m \\left(\\tfrac{1}{2} q_i x_i^2 + c_i x_i\\right)\n\\quad \\text{s.t.} \\quad \\sum_{i=1}^m A_i x_i = b, \\quad \\ell_i \\le x_i \\le u_i \\text{ for } i=1,\\ldots,m.\n$$\n这是一个凸优化问题。KKT 条件为最优性提供了必要和充分条件。我们为等式约束引入一个拉格朗日乘子 $\\nu \\in \\mathbb{R}$，并为下界和上界约束 $x_i \\ge \\ell_i$ 和 $x_i \\le u_i$ 引入乘子 $\\mu_{l,i} \\ge 0$ 和 $\\mu_{u,i} \\ge 0$。完整的拉格朗日函数是：\n$$\n\\mathcal{L}_{\\text{full}}(x, \\nu, \\mu_l, \\mu_u) = \\sum_{i=1}^m \\left(\\tfrac{1}{2} q_i x_i^2 + c_i x_i\\right) + \\nu \\left(\\sum_{i=1}^m A_i x_i - b\\right) - \\sum_{i=1}^m \\mu_{l,i} (x_i - \\ell_i) + \\sum_{i=1}^m \\mu_{u,i} (u_i - x_i).\n$$\nKKT 定常性条件要求对每个 $i=1,\\ldots,m$，$\\nabla_{x_i} \\mathcal{L}_{\\text{full}} = 0$：\n$$\nq_i x_i + c_i + \\nu A_i - \\mu_{l,i} + \\mu_{u,i} = 0.\n$$\n互补松弛条件是 $\\mu_{l,i} (x_i - \\ell_i) = 0$ 和 $\\mu_{u,i} (u_i - x_i) = 0$。\n我们分析最优解 $x_i$ 的三种可能性：\n1.  如果 $\\ell_i  x_i  u_i$，则 $\\mu_{l,i} = \\mu_{u,i} = 0$，这意味着 $q_i x_i + c_i + \\nu A_i = 0$，所以 $x_i = \\frac{-c_i - \\nu A_i}{q_i}$。\n2.  如果 $x_i = \\ell_i$，则 $\\mu_{u,i} = 0$。定常性给出 $\\mu_{l,i} = q_i \\ell_i + c_i + \\nu A_i$。对偶可行性 $\\mu_{l,i} \\ge 0$ 要求 $q_i \\ell_i + c_i + \\nu A_i \\ge 0$，或 $\\frac{-c_i - \\nu A_i}{q_i} \\le \\ell_i$。\n3.  如果 $x_i = u_i$，则 $\\mu_{l,i} = 0$。定常性给出 $\\mu_{u,i} = -(q_i u_i + c_i + \\nu A_i)$。对偶可行性 $\\mu_{u,i} \\ge 0$ 要求 $q_i u_i + c_i + \\nu A_i \\le 0$，或 $\\frac{-c_i - \\nu A_i}{q_i} \\ge u_i$。\n\n综合这些情况，对于给定的最优乘子 $\\nu^\\star$，最优解的每个分量 $x_i^\\star$ 是通过将无约束最小化子投影到可行区间 $[\\ell_i, u_i]$ 上得到的：\n$$\nx_i^\\star(\\nu) = \\text{proj}_{[\\ell_i, u_i]} \\left( \\frac{-c_i - \\nu A_i}{q_i} \\right) = \\max\\left(\\ell_i, \\min\\left(u_i, \\frac{-c_i - \\nu A_i}{q_i}\\right)\\right).\n$$\n最优乘子 $\\nu^\\star$ 是确保满足原始等式约束的值：\n$$\n\\phi(\\nu) := \\sum_{i=1}^m A_i x_i^\\star(\\nu) - b = 0.\n$$\n函数 $\\phi(\\nu)$ 是连续且单调不增的，因为每个分量 $A_i x_i^\\star(\\nu)$ 都是 $\\nu$ 的不增函数。问题保证了可行解的存在，这意味着值 $b$ 位于 $x \\in [\\ell, u]$ 时 $\\sum_{i=1}^m A_i x_i$ 的可达范围内。这确保了方程 $\\phi(\\nu) = 0$ 至少有一个解 $\\nu^\\star$。我们可以使用数值标量求根方法（如 Brent 法）在一个足够大的区间上找到这个根。一旦找到 $\\nu^\\star$，最优原始解就是 $x^\\star = (x_1^\\star(\\nu^\\star), \\ldots, x_m^\\star(\\nu^\\star))$，最优值是 $p^\\star = f(x^\\star) = \\sum_{i=1}^m (\\frac{1}{2} q_i (x_i^\\star)^2 + c_i x_i^\\star)$。\n\n### 第 2 部分：对偶次梯度上升法\n\n对偶次梯度法作用于对偶问题，即最大化对偶函数 $g(\\lambda)$。未增广的拉格朗日函数是：\n$$\n\\mathcal{L}(x,\\lambda) = \\sum_{i=1}^m f_i(x_i) + \\lambda \\left( \\sum_{i=1}^m A_i x_i - b \\right).\n$$\n对偶函数是 $g(\\lambda) = \\inf_{\\ell \\le x \\le u} \\mathcal{L}(x,\\lambda)$。$g(\\lambda)$ 定义中的最小化过程在 $x$ 的各个分量上是可分离的：\n$$\ng(\\lambda) = \\sum_{i=1}^m \\left( \\min_{\\ell_i \\le x_i \\le u_i} \\left\\{ \\tfrac{1}{2} q_i x_i^2 + (c_i + \\lambda A_i) x_i \\right\\} \\right) - \\lambda b.\n$$\n对于给定的 $\\lambda$，最小化的 $x_i(\\lambda)$ 如 KKT 分析中所示，通过将二次项的无约束最小化子投影到 $[\\ell_i, u_i]$ 上得到：\n$$\nx_i(\\lambda) = \\text{proj}_{[\\ell_i, u_i]} \\left( \\frac{-(c_i + \\lambda A_i)}{q_i} \\right).\n$$\n凹函数 $g(\\lambda)$ 在点 $\\lambda_k$ 的一个次梯度由原始残差 $r_k = \\sum_{i=1}^m A_i x_i^{(k)} - b$ 给出，其中 $x^{(k)}$ 是任意一个最小化子 $x(\\lambda_k)$。次梯度上升算法沿着次梯度的方向更新对偶变量 $\\lambda$。从 $\\lambda_0 = 0$ 开始，对 $k = 0, 1, \\ldots, T-1$ 的迭代过程如下：\n1.  为当前对偶变量 $\\lambda_k$ 计算原始最小化子：\n    $x^{(k)} = (x_1(\\lambda_k), \\ldots, x_m(\\lambda_k))$。\n2.  计算对偶函数值 $g(\\lambda_k) = \\mathcal{L}(x^{(k)}, \\lambda_k)$ 并更新迄今为止的最佳对偶值：$d_{\\text{best}} = \\max(d_{\\text{best}}, g(\\lambda_k))$。\n3.  计算次梯度（原始残差）：$r_k = \\sum_{i=1}^m A_i x_i^{(k)} - b$。\n4.  使用指定的常数步长 $1/\\rho$ 更新对偶变量：\n    $\\lambda_{k+1} = \\lambda_k + \\frac{1}{\\rho} r_k$。\n\n经过 $T$ 次迭代后，我们得到平均原始候选解 $\\bar{x} = \\frac{1}{T} \\sum_{k=0}^{T-1} x^{(k)}$。\n\n### 第 3 部分：量化指标\n\n利用上述计算出的值，我们计算两个要求的指标：\n1.  **对偶间隙**：这衡量了真实原始最优值与算法找到的最佳对偶界之间的差异：$p^\\star - d_{\\text{best}}$。根据弱对偶性，这个值总是非负的。\n2.  **原始可行性残差**：这衡量了恢复的平均解在多大程度上满足耦合约束：$|\\sum_{i=1}^m A_i \\bar{x}_i - b|$。\n\n对每个提供的测试用例都将执行这些计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results in the required format.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path, medium scale)\n        (4, [2.0, 1.0, 4.0, 3.0], [0.0, -1.0, 2.0, -0.5], [1.0, -2.0, 1.5, 1.0], \n         [-1.0, 0.0, -0.5, -2.0], [2.0, 2.0, 1.5, 1.0], 0.7, 200, 0.5),\n        # Case 2 (same data, milder step)\n        (4, [2.0, 1.0, 4.0, 3.0], [0.0, -1.0, 2.0, -0.5], [1.0, -2.0, 1.5, 1.0],\n         [-1.0, 0.0, -0.5, -2.0], [2.0, 2.0, 1.5, 1.0], 0.7, 200, 2.0),\n        # Case 3 (same data, small step)\n        (4, [2.0, 1.0, 4.0, 3.0], [0.0, -1.0, 2.0, -0.5], [1.0, -2.0, 1.5, 1.0],\n         [-1.0, 0.0, -0.5, -2.0], [2.0, 2.0, 1.5, 1.0], 0.7, 200, 20.0),\n        # Case 4 (boundary optimum on upper bounds)\n        (3, [1.0, 1.0, 1.0], [0.1, -0.2, 0.3], [1.0, 1.0, 1.0], \n         [0.0, 0.0, 0.0], [1.0, 1.0, 1.0], 3.0, 200, 2.0),\n        # Case 5 (ill-conditioned curvature)\n        (4, [0.1, 10.0, 0.5, 8.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, -1.0, 2.0],\n         [-1.0, -1.0, -1.0, -1.0], [1.0, 1.0, 1.0, 1.0], 0.3, 200, 2.0),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        m, q, c, A, ll, u, b, T, rho = [np.array(v) if isinstance(v, list) else v for v in case]\n        \n        # --- Part 1: Compute p_star (exact primal optimum) via KKT and root-finding ---\n        \n        def get_x_star_from_nu(nu, q, c, A, ll, u):\n            \"\"\"Calculates x*(nu) = proj_[l,u] ( (-c - nu*A) / q )\"\"\"\n            unconstrained_x = (-c - nu * A) / q\n            return np.maximum(ll, np.minimum(u, unconstrained_x))\n\n        def phi(nu, q, c, A, ll, u, b):\n            \"\"\"The function sum(A_i * x_i*(nu)) - b, whose root is nu_star\"\"\"\n            x_star = get_x_star_from_nu(nu, q, c, A, ll, u)\n            return np.dot(A, x_star) - b\n\n        # Find nu_star by solving phi(nu)=0 using a robust bracketing strategy\n        nu_search_min, nu_search_max = -1e5, 1e5\n        phi_at_min = phi(nu_search_min, q, c, A, ll, u, b)\n        phi_at_max = phi(nu_search_max, q, c, A, ll, u, b)\n\n        # Since feasibility is guaranteed, phi_at_max = 0 = phi_at_min\n        if np.isclose(phi_at_min, 0.0):\n            nu_star = nu_search_min\n        elif np.isclose(phi_at_max, 0.0):\n            nu_star = nu_search_max\n        else:\n            # A root must exist in the interval\n            nu_star = brentq(phi, nu_search_min, nu_search_max, args=(q, c, A, ll, u, b))\n\n        x_star = get_x_star_from_nu(nu_star, q, c, A, ll, u)\n        p_star = np.sum(0.5 * q * x_star**2 + c * x_star)\n\n        # --- Part 2: Dual Subgradient Ascent ---\n        \n        lambda_k = 0.0\n        x_sum = np.zeros(m)\n        d_best = -np.inf\n\n        for _ in range(T):\n            # Compute x_k which minimizes L(x, lambda_k) over the box\n            unconstrained_x = (-c - lambda_k * A) / q\n            x_k = np.maximum(ll, np.minimum(u, unconstrained_x))\n            x_sum += x_k\n\n            # Compute subgradient r_k\n            r_k = np.dot(A, x_k) - b\n            \n            # Compute dual function value g(lambda_k) = inf_x L(x, lambda_k)\n            g_lambda_k = np.sum(0.5 * q * x_k**2 + c * x_k) + lambda_k * r_k\n            if g_lambda_k > d_best:\n                d_best = g_lambda_k\n            \n            # Update lambda\n            lambda_k += (1.0 / rho) * r_k\n        \n        # --- Part 3: Final Computations ---\n        x_bar = x_sum / T\n        \n        duality_gap = p_star - d_best\n        feasibility_residual = np.abs(np.dot(A, x_bar) - b)\n        \n        all_results.extend([duality_gap, feasibility_residual])\n        \n    # Format and print the final output as a single-line string\n    print(f\"[{','.join(f'{r:.6f}' for r in all_results)}]\")\n\n# Execute the self-contained solution process\nsolve()\n```"
        },
        {
            "introduction": "并非所有问题都最适合通过松弛约束来分解。Benders 分解法提供了另一种视角，它根据变量将问题划分为一个主问题和一个子问题。此方法特别适用于具有“困难变量”（例如整数变量）和给定这些变量后变得容易求解的子问题结构。本练习将引导你完成 Benders 分解的经典应用，你将学习如何从线性子问题的对偶问题中生成“最优性割”和“可行性割”，从而迭代地构建对主问题可行空间和成本的精确描述 。",
            "id": "3116814",
            "problem": "考虑以下适用于Benders分解的两阶段线性优化问题。主决策变量为 $x \\in [0,3]$。对于任意固定的 $x$，子问题是如下的线性规划（LP）问题\n$$\n\\begin{aligned}\n\\text{minimize}_{y_1,y_2} \\quad  y_1 + y_2 \\\\\n\\text{subject to} \\quad  y_1 + y_2 = d(x), \\\\\n y_1 \\leq 2, \\\\\n y_2 \\leq 2, \\\\\n y_1 \\geq 0,\\; y_2 \\geq 0,\n\\end{aligned}\n$$\n其中 $d(x) = 3 - 2x$。主问题目标是最小化 $5x + \\theta$，其中 $\\theta$ 是子问题成本的代理变量，将通过Benders割进行约束。当子问题可行时，它是退化多重最优的，因为任何满足 $y_1 + y_2 = d(x)$ 的可行对 $(y_1,y_2)$ 都会得到相同的目标值 $y_1 + y_2$。\n\n任务：\n1. 使用线性规划的基本原始-对偶配对和弱/强对偶性原理，从第一性原理出发推导子问题的对偶问题。\n2. （在子问题可行的情况下）找出一个能产生有限对偶最优解的极点，并推导出相关的关于 $\\theta$ 的Benders最优性割，该割是 $x$ 的函数。\n3. 找出对偶可行集的极射线，这些极射线在某些 $x$ 值下会导致与子问题不可行性相对应的对偶无界情况，并推导出相关的Benders可行性割，以 $x$ 的形式显式表示。\n4. 通过线性规划后处理进行割的冗余性检测：在你推导出的可行性割中，通过构建并求解一个在一维主问题定义域上最大化候选割违背量的一维线性规划，来识别当 $x \\in [0,3]$ 时是否存在冗余的割。\n5. 仅使用非冗余割和最优性割，写出最终的主问题并求解，以获得 $5x + \\theta$ 的最优目标值。\n\n你的最终答案必须是等于 $5x + \\theta$ 最优值的单个实数。无需四舍五入，不涉及单位。在答案中只写出最终的数字。",
            "solution": "用户要求我使用Benders分解法求解一个两阶段线性优化问题。我将通过完成五个指定任务来解答。\n\n### 问题验证\n问题陈述描述了一个标准的两阶段线性规划，包含一个第一阶段变量 $x$ 和一个涉及变量 $y_1, y_2$ 的第二阶段（子问题）。该结构适用于Benders分解。所有变量、函数和约束都已明确定义。该问题在数学上是适定的，在优化理论中有科学依据，且陈述客观。未发现任何缺陷。我将开始求解。\n\n### 任务1：推导子问题的对偶问题\n\n对于一个固定的 $x$，子问题由下式给出：\n$$\n\\begin{aligned}\n\\text{minimize}_{y_1,y_2} \\quad  y_1 + y_2 \\\\\n\\text{subject to} \\quad  y_1 + y_2 = d(x) \\\\\n y_1 \\leq 2 \\\\\n y_2 \\leq 2 \\\\\n y_1 \\geq 0,\\; y_2 \\geq 0\n\\end{aligned}\n$$\n其中 $d(x) = 3 - 2x$。为了推导对偶问题，我们首先将此LP表示为标准形式。我们为 $y_1, y_2$ 的上界引入非负松弛变量 $s_1, s_2$。子问题变为：\n$$\n\\begin{aligned}\n\\text{minimize} \\quad  y_1 + y_2 + 0s_1 + 0s_2 \\\\\n\\text{subject to} \\quad  y_1 + y_2 \\quad\\quad\\quad = 3 - 2x \\\\\n y_1 \\quad\\quad + s_1 \\quad = 2 \\\\\n \\quad\\quad y_2 \\quad\\quad + s_2 = 2 \\\\\n y_1, y_2, s_1, s_2 \\geq 0\n\\end{aligned}\n$$\n这是一个标准形式的LP：$\\min \\{c^T \\mathbf{y} \\mid A\\mathbf{y} = b, \\mathbf{y} \\geq 0\\}$，其中 $\\mathbf{y} = (y_1, y_2, s_1, s_2)^T$。对应的对偶问题是 $\\max \\{\\pi^T b \\mid A^T\\pi \\leq c\\}$，其中 $\\pi = (\\pi_0, \\pi_1, \\pi_2)^T$ 是与三个等式约束相关的对偶变量向量，这些对偶变量的符号不受限制。\n\n矩阵和向量如下：\n$$ c = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad A = \\begin{pmatrix} 1  1  0  0 \\\\ 1  0  1  0 \\\\ 0  1  0  1 \\end{pmatrix}, \\quad b(x) = \\begin{pmatrix} 3-2x \\\\ 2 \\\\ 2 \\end{pmatrix} $$\n对偶约束 $A^T\\pi \\leq c$ 为：\n$$\n\\begin{pmatrix}\n1  1  0 \\\\\n1  0  1 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix}\n\\begin{pmatrix} \\pi_0 \\\\ \\pi_1 \\\\ \\pi_2 \\end{pmatrix}\n\\leq\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n这给出了以下不等式：\n1. $\\pi_0 + \\pi_1 \\leq 1$\n2. $\\pi_0 + \\pi_2 \\leq 1$\n3. $\\pi_1 \\leq 0$\n4. $\\pi_2 \\leq 0$\n\n需要最大化的对偶目标函数是 $\\pi^T b(x)$:\n$$ (3-2x)\\pi_0 + 2\\pi_1 + 2\\pi_2 $$\n因此，子问题的对偶问题是：\n$$\n\\begin{aligned}\n\\text{maximize}_{\\pi_0, \\pi_1, \\pi_2} \\quad  (3-2x)\\pi_0 + 2\\pi_1 + 2\\pi_2 \\\\\n\\text{subject to} \\quad  \\pi_0 + \\pi_1 \\leq 1 \\\\\n \\pi_0 + \\pi_2 \\leq 1 \\\\\n \\pi_1 \\leq 0 \\\\\n \\pi_2 \\leq 0\n\\end{aligned}\n$$\n\n### 任务2：推导Benders最优性割\n\n最优性割是在子问题可行且具有有限最优值的 $x$ 值下，由对偶可行集的一个极点生成的。原始子问题是可行的，当且仅当存在 $y_1, y_2$ 使得 $y_1+y_2 = d(x)$ 且 $0 \\leq y_1, y_2 \\leq 2$。和 $y_1+y_2$ 可以在 $[0,4]$ 内取任何值。因此，子问题是可行的当且仅当 $0 \\leq d(x) \\leq 4$。\n$$ 0 \\leq 3-2x \\implies 2x \\leq 3 \\implies x \\leq 1.5 $$\n$$ 3-2x \\leq 4 \\implies -1 \\leq 2x \\implies x \\geq -0.5 $$\n考虑到主变量定义域 $x \\in [0,3]$，子问题在 $x \\in [0, 1.5]$ 时是可行的。\n\n对于此范围内的 $x$，对偶问题必须有有限的最优解。我们来找一个对偶可行域的极点。极点是由至少三个紧约束平面相交形成的顶点。我们来测试这些约束：\n$\\pi_0 + \\pi_1 = 1$, $\\pi_1 = 0$, $\\pi_2 = 0$。这得到 $\\pi_0=1$。该点为 $(\\pi_0, \\pi_1, \\pi_2) = (1,0,0)$。我们检查它是否可行：\n- $1 + 0 \\leq 1$ (满足)\n- $1 + 0 \\leq 1$ (满足)\n- $0 \\leq 0$ (满足)\n- $0 \\leq 0$ (满足)\n点 $(1,0,0)$ 是对偶可行集的一个极点。\n在此点，对偶目标函数为 $(3-2x)(1)+2(0)+2(0) = 3-2x$。\n当子问题可行时，其最优目标值由 $Q(x) = d(x) = 3-2x$ 给出。根据强对偶性，这也是对偶问题的最优值。最优性割为 $\\theta \\geq Q(x)$，其中 $Q(x)$ 由对偶目标在其一个极点处的值来近似。使用极点 $\\pi^*=(1,0,0)$，我们得到Benders最优性割：\n$$ \\theta \\geq (3-2x)\\pi_0^* + 2\\pi_1^* + 2\\pi_2^* $$\n$$ \\theta \\geq 3-2x $$\n\n### 任务3：推导Benders可行性割\n\n可行性割是在子问题不可行的 $x$ 值下生成的。这种情况在对偶问题无界时发生。无界方向是对偶问题衰退锥的极射线。\n衰退锥由以下齐次不等式组定义：\n$$\n\\begin{aligned}\nd_0 + d_1 \\leq 0 \\\\\nd_0 + d_2 \\leq 0 \\\\\nd_1 \\leq 0 \\\\\nd_2 \\leq 0\n\\end{aligned}\n$$\n如果该锥的一条极射线 $r=(\\pi_0, \\pi_1, \\pi_2)$ 为对偶目标提供了一个无界方向，即 $r^T c_D > 0$（其中 $c_D = (3-2x, 2, 2)^T$），则可以从中推导出一个Benders可行性割。该割的形式为 $r^T b(x) \\leq 0$。\n当 $x>1.5$ (因为 $d(x)  0$) 或 $x  -0.5$ (因为 $d(x)>4$) 时，子问题在 $x \\in [0,3]$ 上是不可行的。\n\n情况1：$x > 1.5$，这意味着 $3-2x  0$。\n我们来找一条导致目标无界的极射线。考虑射线 $r_1 = (-1, 0, 0)$。它在衰退锥中：$-1+0\\leq0$, $-1+0\\leq0$, $0\\leq0$, $0\\leq0$。\n沿这条射线的对偶目标变化量为 $(3-2x)(-1) + 2(0) + 2(0) = 2x-3$。对于 $x>1.5$，$2x-3 > 0$，因此对偶问题沿此射线无界。\n相应的可行性割是 $r_1^T b(x) \\leq 0$:\n$$ (-1,0,0) \\cdot (3-2x, 2, 2)^T \\leq 0 \\implies -(3-2x) \\leq 0 \\implies 2x-3 \\leq 0 \\implies x \\leq 1.5 $$\n这个割从主问题的可行集中移除了区域 $x > 1.5$。\n\n情况2：$x  -0.5$，这意味着 $3-2x > 4$。\n我们来找另一条极射线。考虑 $r_2 = (1, -1, -1)$。它在衰退锥中：$1-1=0\\leq0$, $1-1=0\\leq0$, $-1\\leq0$, $-1\\leq0$。\n沿这条射线的对偶目标变化量为 $(3-2x)(1) + 2(-1) + 2(-1) = 3-2x-4 = -2x-1$。对于 $x  -0.5$，$-2x > 1$，因此 $-2x-1 > 0$。对偶问题沿此射线无界。\n相应的可行性割是 $r_2^T b(x) \\leq 0$:\n$$ (1,-1,-1) \\cdot (3-2x, 2, 2)^T \\leq 0 \\implies (3-2x) - 2 - 2 \\leq 0 \\implies -2x-1 \\leq 0 \\implies x \\geq -0.5 $$\n这个割移除了区域 $x  -0.5$。\n\n这两个可行性割是 $x \\leq 1.5$ 和 $x \\geq -0.5$。\n\n### 任务4：进行割的冗余性检测\n\n$x$ 的主问题受其原始定义域 $[0,3]$ 和可行性割的约束。最终 $x$ 的可行域由下式给出：\n$$ \\{ x \\mid 0 \\leq x \\leq 3, \\quad x \\leq 1.5, \\quad x \\geq -0.5 \\} $$\n结合这些不等式，我们得到 $0 \\leq x \\leq 1.5$。\n我们在主问题定义域 $x \\in [0,3]$ 上检查可行性割 $x \\leq 1.5$ 和 $x \\geq -0.5$ 之间的冗余性。\n\n如果一个割被其他割和定义域约束所蕴含，那么它就是冗余的。\n约束 $x \\geq -0.5$ 是一个可能的冗余约束。我们检查在给定主问题定义域约束 $x \\in [0,3]$ 的情况下它是否冗余。\n根据问题说明，我们在由其他约束定义的域上最大化此候选割的违背量。$x \\geq -0.5$（或 $-x \\leq 0.5$）的违背量是 $-x - 0.5$。然而，标准方法是将割写成 $g(x) \\leq 0$ 的形式，所以对于 $x \\geq -0.5$，它是 $-x-0.5 \\leq 0$，违背量是 $-x-0.5$。但通常我们是比较 $x \\geq -0.5$ 和 $x \\geq 0$。\n定义域是 $[0,3]$。此定义域中的每个 $x$ 都已经满足 $x \\geq -0.5$。因此，割 $x \\geq -0.5$ 是冗余的。\n\n为了使用指定的LP方法将其形式化：\n我们来检查割 $x \\geq -0.5$ 是否是冗余的。问题是在由其他约束（即 $x \\in [0,3]$ 和 $x \\leq 1.5$）定义的域上最大化其违背量。\n$x \\geq -0.5$ 的违背量可以表示为 $-0.5 - x$。我们试图最大化这个值。\n$$ \\max_{x} \\quad -0.5 - x \\quad \\text{s.t.} \\quad 0 \\leq x \\leq 1.5 $$\n最大值在 $x$ 取最小值时出现，即 $x=0$。最大违背量是 $-0.5-0 = -0.5$。由于最大违背量不是正数，所以在由其他约束定义的可行域上，割 $x \\geq -0.5$ 永远不会被违背。因此它是冗余的。\n\n非冗余的可行性割是 $x \\leq 1.5$。\n\n### 任务5：求解主问题\n\n最终的主问题包含了非冗余的可行性割和最优性割：\n$$\n\\begin{aligned}\n\\text{minimize}_{x, \\theta} \\quad  5x + \\theta \\\\\n\\text{subject to} \\quad  0 \\leq x \\leq 1.5 \\\\\n \\theta \\geq 3-2x\n\\end{aligned}\n$$\n目标是最小化 $5x+\\theta$。为了达到这个目标，对于任意给定的 $x$，我们应该选择 $\\theta$ 可能的最小值，根据约束，即为 $\\theta = 3-2x$。将此代入目标函数，我们得到一个只含 $x$ 的问题：\n$$ \\text{minimize}_{x} \\quad 5x + (3-2x) \\quad \\text{s.t.} \\quad 0 \\leq x \\leq 1.5 $$\n目标简化为：\n$$ \\text{minimize}_{x} \\quad 3x+3 \\quad \\text{s.t.} \\quad 0 \\leq x \\leq 1.5 $$\n函数 $f(x)=3x+3$ 是一个具有正斜率（$3$）的线性函数。因此，它在区间 $[0, 1.5]$ 上的最小值在左端点 $x=0$ 处取得。\n$x$ 的最优值是 $x^*=0$。\n对应的目标函数最优值为 $3(0)+3=3$。\n\n整个问题的最优解是 $x^*=0$，子问题的成本为 $Q(0)=3-2(0)=3$。\n主问题目标函数的最优值为 $5x^* + Q(x^*) = 5(0) + 3 = 3$。",
            "answer": "$$\n\\boxed{3}\n$$"
        },
        {
            "introduction": "交替方向乘子法（ADMM）是在拉格朗日方法思想基础上发展而来的一种强大的分布式凸优化算法。它融合了对偶分解的可分解性与增广拉格朗日方法的优良收敛特性。在这个实践中，你将把 ADMM 应用于一个电力系统工程中的实际问题——最优潮流（OPF），并观察物理上分离的子系统如何通过协调最终达成全局最优解 。",
            "id": "3116714",
            "problem": "考虑一个小型电力网络上的直流最优潮流 (DC-OPF) 模型，该网络被划分为两个区域，并使用乘子交替方向法 (ADMM) 的分布式一致性公式进行求解。DC-OPF 使用线性化潮流关系 $$P = B \\theta,$$ 其中 $P$ 是节点净有功注入功率向量，$B$ 是由线路电抗构成的节点电纳拉普拉斯矩阵，$\\theta$ 是节点电压相角向量（单位为弧度）。连接节点 $i$ 和 $j$ 的线路上的潮流由 $$f_{ij} = \\frac{\\theta_i - \\theta_j}{x_{ij}}$$ 给出，其中 $x_{ij}$ 是线路电抗。节点 $i$ 的净注入功率满足 $$P_i = \\sum_{j \\in \\mathcal{N}(i)} \\frac{\\theta_i - \\theta_j}{x_{ij}},$$ 其中 $\\mathcal{N}(i)$ 是通过输电线路连接的相邻节点。\n\n区域 $1$ 包含节点 $\\{1,2,3\\}$，其内部线路 $(1,2)$ 的电抗为 $x_{12} = 0.1$，线路 $(2,3)$ 的电抗为 $x_{23} = 0.2$。区域 $2$ 包含节点 $\\{4,5\\}$，其内部线路 $(4,5)$ 的电抗为 $x_{45} = 0.15$。连接这两个区域的联络线是 $(3,4)$，其电抗为 $x_{34} = 0.25$。定义电纳为 $$b_{12} = \\frac{1}{x_{12}}, \\quad b_{23} = \\frac{1}{x_{23}}, \\quad b_{45} = \\frac{1}{x_{45}}, \\quad b_{34} = \\frac{1}{x_{34}}.$$ 负荷（单位为标幺值）为 $$d_1 = 0.0, \\quad d_2 = 0.2, \\quad d_3 = 1.0, \\quad d_4 = 0.8, \\quad d_5 = 0.3.$$ 发电机位于节点 $1$、$2$ 和 $5$，其二次成本函数为 $$C_1(g_1) = c_{2,1} g_1^2 + c_{1,1} g_1, \\quad C_2(g_2) = c_{2,2} g_2^2 + c_{1,2} g_2, \\quad C_5(g_5) = c_{2,5} g_5^2 + c_{1,5} g_5,$$ 其中 $$c_{2,1} = 0.02, \\quad c_{1,1} = 1.0, \\quad c_{2,2} = 0.04, \\quad c_{1,2} = 1.2, \\quad c_{2,5} = 0.03, \\quad c_{1,5} = 1.1.$$ 相角变量的单位是弧度，功率量的单位是标幺值。\n\n区域 $1$ 使用平衡节点相角约束 $\\theta_1 = 0$ 来设置参考。区域 $2$ 不固定平衡节点，联络线一致性将锚定跨区域的相角。局部 DC-OPF 约束是节点功率平衡方程。对于区域 $1$：\n- 在节点 $1$：$$b_{12}(\\theta_1 - \\theta_2) = g_1 - d_1.$$\n- 在节点 $2$：$$b_{12}(\\theta_2 - \\theta_1) + b_{23}(\\theta_2 - \\theta_3) = g_2 - d_2.$$\n- 在节点 $3$：$$b_{23}(\\theta_3 - \\theta_2) + b_{34}(\\theta_3 - \\phi_4) = 0 - d_3,$$ 其中 $\\phi_4$ 是区域 $1$ 中节点 $4$ 相角的局部副本，用于计算联络线潮流。\n\n对于区域 $2$：\n- 在节点 $4$：$$b_{45}(\\theta_4 - \\theta_5) + b_{34}(\\theta_4 - \\phi_3) = 0 - d_4,$$ 其中 $\\phi_3$ 是区域 $2$ 中节点 $3$ 相角的局部副本。\n- 在节点 $5$：$$b_{45}(\\theta_5 - \\theta_4) = g_5 - d_5.$$\n\n为了强制跨区域边界变量的一致性，分别为节点 $3$ 和 $4$ 引入一致性变量 $z_3$ 和 $z_4$。ADMM 罚参数表示为 $\\rho  0$。在步骤 $k$ 的缩放形式 ADMM 迭代包括：\n- 区域 $1$ 在其节点约束和平衡节点约束 $\\theta_1 = 0$ 的条件下，对其变量 $\\theta_1, \\theta_2, \\theta_3, g_1, g_2, \\phi_4$ 进行局部最小化，目标是局部成本函数与二次罚项 $$\\frac{\\rho}{2}\\left(\\theta_3 - z_3^{(k)} + u_{3,\\mathrm{A}}^{(k)}\\right)^2 + \\frac{\\rho}{2}\\left(\\phi_4 - z_4^{(k)} + u_{4,\\mathrm{A}}^{(k)}\\right)^2$$ 之和。\n- 区域 $2$ 在其节点约束的条件下，对其变量 $\\theta_4, \\theta_5, g_5, \\phi_3$ 进行局部最小化，目标是局部成本函数与二次罚项 $$\\frac{\\rho}{2}\\left(\\theta_4 - z_4^{(k)} + u_{4,\\mathrm{B}}^{(k)}\\right)^2 + \\frac{\\rho}{2}\\left(\\phi_3 - z_3^{(k)} + u_{3,\\mathrm{B}}^{(k)}\\right)^2$$ 之和。\n- 一致性更新 $$z_3^{(k+1)} = \\frac{\\theta_3^{(k+1)} + u_{3,\\mathrm{A}}^{(k)} + \\phi_3^{(k+1)} + u_{3,\\mathrm{B}}^{(k)}}{2}, \\quad z_4^{(k+1)} = \\frac{\\phi_4^{(k+1)} + u_{4,\\mathrm{A}}^{(k)} + \\theta_4^{(k+1)} + u_{4,\\mathrm{B}}^{(k)}}{2}.$$\n- 对偶变量更新 $$u_{3,\\mathrm{A}}^{(k+1)} = u_{3,\\mathrm{A}}^{(k)} + \\theta_3^{(k+1)} - z_3^{(k+1)}, \\quad u_{3,\\mathrm{B}}^{(k+1)} = u_{3,\\mathrm{B}}^{(k)} + \\phi_3^{(k+1)} - z_3^{(k+1)},$$ $$u_{4,\\mathrm{A}}^{(k+1)} = u_{4,\\mathrm{A}}^{(k)} + \\phi_4^{(k+1)} - z_4^{(k+1)}, \\quad u_{4,\\mathrm{B}}^{(k+1)} = u_{4,\\mathrm{B}}^{(k)} + \\theta_4^{(k+1)} - z_4^{(k+1)}.$$\n\n将迭代 $k$ 时的边界原始残差范数定义为 $$r^{(k)} = \\sqrt{\\left(\\theta_3^{(k)} - \\phi_3^{(k)}\\right)^2 + \\left(\\phi_4^{(k)} - \\theta_4^{(k)}\\right)^2}.$$ 我们将通过达到 $$r^{(k)} \\le \\varepsilon$$ 所需的迭代次数来衡量收敛速度，容差 $\\varepsilon = 10^{-6}$，最大迭代次数为 $500$ 次。相角单位必须是弧度，所有功率量单位必须是标幺值。\n\n任务：\n1. 实现上述带有 ADMM 的分布式 DC-OPF，其中每个局部区域的求解是一个带线性等式约束的二次规划问题，通过 Karush–Kuhn–Tucker (KKT) 条件求解。\n2. 通过对罚参数值 $\\rho \\in \\{0.01, 0.1, 1.0, 10.0, 100.0\\}$ 运行 ADMM，测试罚参数 $\\rho$ 的选择如何影响收敛速度和边界不匹配。\n3. 对于每个 $\\rho$，报告两个量：达到容差所需的整数迭代次数（如果未达到容差，则为最大迭代次数），以及最终的边界残差范数 $r$（浮点数）。\n\n你的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素是一个针对特定 $\\rho$ 的包含两个项目的列表 $[n, r]$，即 $$[[n_1, r_1],[n_2, r_2],[n_3, r_3],[n_4, r_4],[n_5, r_5]].$$\n\n相角单位：弧度。功率单位：标幺值。所有数值输出表示为不带单位、不带百分号的普通浮点数和整数。\n\n测试套件：\n- 罚参数值：$\\rho = 0.01$，$\\rho = 0.1$，$\\rho = 1.0$，$\\rho = 10.0$，$\\rho = 100.0$。\n- 最大迭代次数：$500$。\n- 容差：$\\varepsilon = 10^{-6}$。",
            "solution": "该问题要求实现一种分布式优化算法，具体是乘子交替方向法 (ADMM)，以解决一个小型电力网络的直流最优潮流 (DC-OPF) 问题。该网络被划分为两个区域，必须通过协调局部子问题来找到解决方案。\n\n首先，我们验证问题陈述。\n\n### 步骤 1：提取已知条件\n-   **模型**：使用线性化潮流关系 $P = B \\theta$ 的直流最优潮流 (DC-OPF)。\n-   **网络划分**：区域 $1$ 包含节点 $\\{1,2,3\\}$，区域 $2$ 包含节点 $\\{4,5\\}$。\n-   **线路电抗（标幺值）**：$x_{12} = 0.1$, $x_{23} = 0.2$, $x_{45} = 0.15$。联络线电抗为 $x_{34} = 0.25$。线路电纳定义为 $b_{ij} = 1/x_{ij}$。\n-   **负荷（标幺值）**：$d_1 = 0.0$, $d_2 = 0.2$, $d_3 = 1.0$, $d_4 = 0.8$, $d_5 = 0.3$。\n-   **发电成本**：位于节点 $1$、$2$ 和 $5$ 的发电机具有二次成本 $C_i(g_i) = c_{2,i} g_i^2 + c_{1,i} g_i$。系数已给出：$c_{2,1} = 0.02, c_{1,1} = 1.0$；$c_{2,2} = 0.04, c_{1,2} = 1.2$；$c_{2,5} = 0.03, c_{1,5} = 1.1$。\n-   **参考相角**：平衡节点约束 $\\theta_1 = 0$。\n-   **节点功率平衡方程**：问题明确给出了每个节点的直流潮流方程，这些方程作为优化子问题的线性等式约束。这些方程涉及局部变量 $(\\theta_i, g_i)$ 和边界变量的副本 $(\\phi_i)$。\n-   **ADMM 结构**：指定了 ADMM 一致性公式。\n    -   **一致性变量**：边界节点相角 $z_3$ 和 $z_4$。\n    -   **ADMM 罚参数**：$\\rho  0$。\n    -   **局部子问题**：每个区域求解一个局部优化问题，该问题最小化其自身的发电成本加上增广拉格朗日罚项。对于区域 $1$，目标是 $C_1(g_1) + C_2(g_2) + \\frac{\\rho}{2}(\\theta_3 - z_3^{(k)} + u_{3,\\mathrm{A}}^{(k)})^2 + \\frac{\\rho}{2}(\\phi_4 - z_4^{(k)} + u_{4,\\mathrm{A}}^{(k)})^2$。为区域 $2$ 定义了类似的目标。\n    -   **更新规则**：为更新一致性变量 $z_3, z_4$ 和缩放对偶变量 $u$ 提供了明确的公式。例如，$z_3^{(k+1)} = \\frac{1}{2}(\\theta_3^{(k+1)} + u_{3,\\mathrm{A}}^{(k)} + \\phi_3^{(k+1)} + u_{3,\\mathrm{B}}^{(k)})$。\n-   **任务参数**：\n    -   **子问题求解器**：Karush–Kuhn–Tucker (KKT) 条件。\n    -   **罚参数值**：$\\rho \\in \\{0.01, 0.1, 1.0, 10.0, 100.0\\}$。\n    -   **收敛容差**：边界原始残差范数 $r^{(k)} = \\sqrt{(\\theta_3^{(k)} - \\phi_3^{(k)})^2 + (\\phi_4^{(k)} - \\theta_4^{(k)})^2}$ 的容差为 $\\varepsilon = 10^{-6}$。\n    -   **最大迭代次数**：$500$。\n-   **输出格式**：一个由 $[n, r]$ 对组成的列表，其中 $n$ 是迭代次数，$r$ 是最终残差范数，针对每个 $\\rho$ 值。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在科学上和数学上是合理的。\n-   **科学依据**：DC-OPF 模型是电力系统工程中用于分析有功潮流和经济调度的标准且广为接受的简化模型。ADMM 是一种功能强大且理论基础扎实的分布式凸优化方法，常用于解决电力系统问题。\n-   **适定性**：整个问题是一个凸二次规划 (QP) 问题，因为目标函数是凸二次成本之和，且约束是线性的。这确保了存在唯一的全局最优解。局部子问题也是凸 QP 问题。对于任何 $\\rho  0$，ADMM 保证能收敛到此类问题的最优解。\n-   **完整性和一致性**：问题陈述是自包含的，提供了所有必要的数值数据、模型方程和算法步骤。所提供的信息中没有矛盾。定义的变量和方程与基于 ADMM 的 DC-OPF 问题分解的标准形式一致。\n\n### 步骤 3：结论与行动\n问题被认为是有效的。将逐步开发和实现一个解决方案。\n\n### 求解推导\n\n任务的核心是实现指定的 ADMM 算法。ADMM 算法为每个区域迭代求解局部子问题，然后更新用于协调解的一致性变量和对偶变量。\n\n**子问题公式化**\n\n区域 $1$ 和区域 $2$ 的子问题是带线性等式约束的二次规划问题。按照规定，我们通过构建它们的 Karush-Kuhn-Tucker (KKT) 条件来求解，这些条件构成一个线性方程组。\n\n**区域 1 子问题**\n\n区域 $1$ 的优化变量是 $x_{\\mathrm{A}} = [\\theta_2, \\theta_3, g_1, g_2, \\phi_4]^T$。平衡节点约束 $\\theta_1=0$ 是一个固定值。\n在迭代 $k+1$ 时要最小化的目标函数是：\n$$ L_{\\mathrm{A}}(x_{\\mathrm{A}}) = C_1(g_1) + C_2(g_2) + \\frac{\\rho}{2}(\\theta_3 - z_3^{(k)} + u_{3,\\mathrm{A}}^{(k)})^2 + \\frac{\\rho}{2}(\\phi_4 - z_4^{(k)} + u_{4,\\mathrm{A}}^{(k)})^2 $$\n受以下线性约束：\n\\begin{align*}\n-b_{12}\\theta_2 + g_1 = d_1 \\\\\n(b_{12}+b_{23})\\theta_2 - b_{23}\\theta_3 - g_2 = -d_2 \\\\\n-b_{23}\\theta_2 + (b_{23}+b_{34})\\theta_3 - b_{34}\\phi_4 = -d_3\n\\end{align*}\n为这些约束引入拉格朗日乘子 $\\lambda_{\\mathrm{A}} = [\\lambda_{1,1}, \\lambda_{1,2}, \\lambda_{1,3}]^T$，KKT 条件（平稳性和可行性）产生一个形式为 $K_1 y_1 = v_1$ 的线性系统，其中 $y_1 = [x_{\\mathrm{A}}; \\lambda_{\\mathrm{A}}]$。KKT 矩阵 $K_1$ 和向量 $v_1$ 是：\n$$\nK_1 = \\begin{pmatrix} Q_1  A_1^T \\\\ A_1  0 \\end{pmatrix}, \\quad\nv_1 = \\begin{pmatrix} -c_1 \\\\ b_1 \\end{pmatrix}\n$$\n其中 $Q_1$ 是目标函数的海森矩阵，$A_1$ 是约束矩阵，$c_1$ 包含来自目标函数的线性项，$b_1$ 是约束的右侧项。具体来说：\n- $Q_1 = \\mathrm{diag}(0, \\rho, 2c_{2,1}, 2c_{2,2}, \\rho)$\n- $c_1 = [0, -\\rho(z_3^{(k)} - u_{3,\\mathrm{A}}^{(k)}), c_{1,1}, c_{1,2}, -\\rho(z_4^{(k)} - u_{4,\\mathrm{A}}^{(k)})]^T$\n- $b_1 = [d_1, -d_2, -d_3]^T$\n- $A_1 = \\begin{pmatrix} -b_{12}  0  1  0  0 \\\\ b_{12}+b_{23}  -b_{23}  0  -1  0 \\\\ -b_{23}  b_{23}+b_{34}  0  0  -b_{34} \\end{pmatrix}$\n\n**区域 2 子问题**\n\n区域 $2$ 的优化变量是 $x_{\\mathrm{B}} = [\\theta_4, \\theta_5, g_5, \\phi_3]^T$。\n目标函数是：\n$$ L_{\\mathrm{B}}(x_{\\mathrm{B}}) = C_5(g_5) + \\frac{\\rho}{2}(\\theta_4 - z_4^{(k)} + u_{4,\\mathrm{B}}^{(k)})^2 + \\frac{\\rho}{2}(\\phi_3 - z_3^{(k)} + u_{3,\\mathrm{B}}^{(k)})^2 $$\n受以下线性约束：\n\\begin{align*}\n(b_{45}+b_{34})\\theta_4 - b_{45}\\theta_5 - b_{34}\\phi_3 = -d_4 \\\\\n-b_{45}\\theta_4 + b_{45}\\theta_5 - g_5 = -d_5\n\\end{align*}\n类似地，这形成一个 KKT 系统 $K_2 y_2 = v_2$，其中 $y_2 = [x_{\\mathrm{B}}; \\lambda_{\\mathrm{B}}]$ 且 $\\lambda_{\\mathrm{B}} = [\\lambda_{2,1}, \\lambda_{2,2}]^T$。其组成部分为：\n- $Q_2 = \\mathrm{diag}(\\rho, 0, 2c_{2,5}, \\rho)$\n- $c_2 = [-\\rho(z_4^{(k)} - u_{4,\\mathrm{B}}^{(k)}), 0, c_{1,5}, -\\rho(z_3^{(k)} - u_{3,\\mathrm{B}}^{(k)})]^T$\n- $b_2 = [-d_4, -d_5]^T$\n- $A_2 = \\begin{pmatrix} b_{45}+b_{34}  -b_{45}  0  -b_{34} \\\\ -b_{45}  b_{45}  -1  0 \\end{pmatrix}$\n\n对于给定的 $\\rho$，KKT 矩阵 $K_1$ 和 $K_2$ 依赖于 $\\rho$，但在整个 ADMM 迭代过程中是常数。\n\n**ADMM 算法**\n\n对于每个给定的 $\\rho$ 值，算法按以下步骤进行：\n1.  **初始化**：将所有变量设为零：局部变量 $(\\theta, g, \\phi)$、一致性变量 $(z_3, z_4)$ 和缩放对偶变量 $(u)$。\n2.  **迭代**：对于 $k = 0, 1, 2, \\dots$ 直到最大迭代次数：\n    a. **局部求解**：\n       i.  使用 $z^{(k)}$ 和 $u^{(k)}$ 构建向量 $v_1$。求解线性系统 $K_1 y_1^{(k+1)} = v_1$ 以获得更新后的区域 $1$ 变量，包括 $\\theta_3^{(k+1)}$ 和 $\\phi_4^{(k+1)}$。\n       ii. 使用 $z^{(k)}$ 和 $u^{(k)}$ 构建向量 $v_2$。求解线性系统 $K_2 y_2^{(k+1)} = v_2$ 以获得更新后的区域 $2$ 变量，包括 $\\theta_4^{(k+1)}$ 和 $\\phi_3^{(k+1)}$。\n    b. **收敛性检查**：计算边界原始残差范数 $r^{(k+1)} = \\sqrt{(\\theta_3^{(k+1)} - \\phi_3^{(k+1)})^2 + (\\phi_4^{(k+1)} - \\theta_4^{(k+1)})^2}$。如果 $r^{(k+1)} \\le \\varepsilon$，则终止并报告当前迭代次数和残差。\n    c. **一致性更新**：使用新的局部变量和旧的对偶变量更新一致性变量：\n       $$z_3^{(k+1)} = \\frac{1}{2}(\\theta_3^{(k+1)} + u_{3,\\mathrm{A}}^{(k)} + \\phi_3^{(k+1)} + u_{3,\\mathrm{B}}^{(k)})$$\n       $$z_4^{(k+1)} = \\frac{1}{2}(\\phi_4^{(k+1)} + u_{4,\\mathrm{A}}^{(k)} + \\theta_4^{(k+1)} + u_{4,\\mathrm{B}}^{(k)})$$\n    d. **对偶更新**：更新缩放对偶变量：\n       $$u_{3,\\mathrm{A}}^{(k+1)} = u_{3,\\mathrm{A}}^{(k)} + \\theta_3^{(k+1)} - z_3^{(k+1)}$$\n       $$u_{3,\\mathrm{B}}^{(k+1)} = u_{3,\\mathrm{B}}^{(k)} + \\phi_3^{(k+1)} - z_3^{(k+1)}$$\n       $$u_{4,\\mathrm{A}}^{(k+1)} = u_{4,\\mathrm{A}}^{(k)} + \\phi_4^{(k+1)} - z_4^{(k+1)}$$\n       $$u_{4,\\mathrm{B}}^{(k+1)} = u_{4,\\mathrm{B}}^{(k)} + \\theta_4^{(k+1)} - z_4^{(k+1)}$$\n3.  **终止**：如果循环在未达到容差的情况下完成，则报告最大迭代次数和最终计算的残差。\n\n对每个 $\\rho$ 值实施此过程，以研究其对收敛的影响。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the ADMM simulation for different rho values and print the results.\n    \"\"\"\n    test_rhos = [0.01, 0.1, 1.0, 10.0, 100.0]\n    max_iterations = 500\n    tolerance = 1e-6\n    all_results = []\n\n    # --- 1. Define problem data ---\n    x12, x23, x45, x34 = 0.1, 0.2, 0.15, 0.25\n    b12, b23, b45, b34 = 1.0/x12, 1.0/x23, 1.0/x45, 1.0/x34\n    \n    d1, d2, d3, d4, d5 = 0.0, 0.2, 1.0, 0.8, 0.3\n    \n    c21, c11 = 0.02, 1.0\n    c22, c12 = 0.04, 1.2\n    c25, c15 = 0.03, 1.1\n\n    def run_admm_for_rho(rho):\n        # --- 2. Build constant KKT matrices ---\n        # Area 1: vars [th2, th3, g1, g2, phi4, lam1, lam2, lam3]\n        K1 = np.zeros((8, 8))\n        K1[0, 0] = 0.0\n        K1[1, 1] = rho\n        K1[2, 2] = 2 * c21\n        K1[3, 3] = 2 * c22\n        K1[4, 4] = rho\n        \n        A1 = np.array([\n            [-b12, 0, 1, 0, 0],\n            [b12 + b23, -b23, 0, -1, 0],\n            [-b23, b23 + b34, 0, 0, -b34]\n        ])\n        \n        K1[0:5, 5:8] = A1.T\n        K1[5:8, 0:5] = A1\n\n        # Area 2: vars [th4, th5, g5, phi3, lam1, lam2]\n        K2 = np.zeros((6, 6))\n        K2[0, 0] = rho\n        K2[1, 1] = 0.0\n        K2[2, 2] = 2 * c25\n        K2[3, 3] = rho\n        \n        A2 = np.array([\n            [b45 + b34, -b45, 0, -b34],\n            [-b45, b45, -1, 0]\n        ])\n        \n        K2[0:4, 4:6] = A2.T\n        K2[4:6, 0:4] = A2\n        \n        # --- 3. Initialize ADMM variables ---\n        z3, z4 = 0.0, 0.0\n        u3A, u4A = 0.0, 0.0\n        u3B, u4B = 0.0, 0.0\n        \n        theta3, phi3 = 0.0, 0.0\n        theta4, phi4 = 0.0, 0.0\n        \n        final_residual = np.inf\n\n        for k in range(1, max_iterations + 1):\n            # --- 4a. Solve Area 1 subproblem ---\n            # RHS vector: [-c_vec; b_vec]\n            c1_vec = np.array([0, -rho * (z3 - u3A), c11, c12, -rho * (z4 - u4A)])\n            b1_vec = np.array([d1, -d2, -d3])\n            rhs1 = np.concatenate((-c1_vec, b1_vec))\n            \n            sol1 = np.linalg.solve(K1, rhs1)\n            theta3, phi4 = sol1[1], sol1[4]\n            \n            # --- 4b. Solve Area 2 subproblem ---\n            c2_vec = np.array([-rho * (z4 - u4B), 0, c15, -rho * (z3 - u3B)])\n            b2_vec = np.array([-d4, -d5])\n            rhs2 = np.concatenate((-c2_vec, b2_vec))\n            \n            sol2 = np.linalg.solve(K2, rhs2)\n            theta4, phi3 = sol2[0], sol2[3]\n\n            # --- 4c. Check convergence ---\n            final_residual = np.sqrt((theta3 - phi3)**2 + (phi4 - theta4)**2)\n            if final_residual = tolerance:\n                return k, final_residual\n            \n            # --- 4d. Consensus update ---\n            z3_new = (theta3 + u3A + phi3 + u3B) / 2.0\n            z4_new = (phi4 + u4A + theta4 + u4B) / 2.0\n\n            # --- 4e. Dual update ---\n            u3A += theta3 - z3_new\n            u4A += phi4 - z4_new\n            u3B += phi3 - z3_new\n            u4B += theta4 - z4_new\n            \n            # Update consensus vars for next iteration\n            z3, z4 = z3_new, z4_new\n\n        return max_iterations, final_residual\n\n    for rho_val in test_rhos:\n        n_iters, final_r = run_admm_for_rho(rho_val)\n        all_results.append([n_iters, final_r])\n\n    # Format output as specified\n    result_str_list = [f\"[{item[0]}, {item[1]}]\" for item in all_results]\n    print(f\"[{','.join(result_str_list)}]\")\n\nsolve()\n```"
        }
    ]
}