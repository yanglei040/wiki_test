{
    "hands_on_practices": [
        {
            "introduction": "次梯度法不仅在理论上强大，在机器人路径规划等实际应用中也至关重要。这个练习将带你模拟一个机器人智能体如何利用次梯度法，通过最小化其与目标的曼哈顿距离（$L_1$ 范数）来导航。通过计算最初的几次迭代，你将亲手实践次梯度向量的计算以及在递减步长规则下如何更新位置，这是掌握该算法基本操作的第一步。",
            "id": "2207185",
            "problem": "一个机器人代理正在接受训练，以导航到二维平面中的一个目标坐标。需要最小化的成本函数是到目标的曼哈顿距离（也称为 L1 距离），定义为 $C(\\mathbf{x}) = \\|\\mathbf{x} - \\mathbf{p}\\|_1$，其中 $\\mathbf{x}=(x,y)$ 是代理的当前位置，$\\mathbf{p}=(p_x, p_y)$ 是目标位置。对于一个向量 $\\mathbf{v}=(v_x, v_y)$，其 L1 范数为 $\\|\\mathbf{v}\\|_1 = |v_x| + |v_y|$。\n\n该代理使用次梯度法来更新其位置。第 $k$ 次迭代的更新规则由 $\\mathbf{x}_{k} = \\mathbf{x}_{k-1} - \\alpha_k \\mathbf{g}_{k-1}$ 给出，其中 $\\mathbf{g}_{k-1}$ 是成本函数 $C$ 在位置 $\\mathbf{x}_{k-1}$ 处求值的次微分中的任意向量。\n\n代理从初始位置 $\\mathbf{x}_0 = (9.5, -2.5)$ 开始，目标位置在 $\\mathbf{p} = (1.5, 4.5)$。第 $k$ 次迭代（对于 $k=1, 2, \\dots$）的步长由规则 $\\alpha_k = \\frac{2}{k}$ 给出。\n\n计算经过两次完整迭代后代理的位置 $\\mathbf{x}_2 = (x_2, y_2)$。",
            "solution": "我们最小化 $C(\\mathbf{x})=\\|\\mathbf{x}-\\mathbf{p}\\|_{1}=|x-p_{x}|+|y-p_{y}|$。对于 $f(t)=|t|$，其次微分在 $t0$ 时为 $\\partial f(t)=\\{1\\}$，在 $t0$ 时为 $\\{-1\\}$，在 $t=0$ 时为 $[-1,1]$。因此，$C$ 在 $\\mathbf{x}$ 处的一个次梯度是任意满足 $g_{x}\\in\\partial|x-p_{x}|$ 和 $g_{y}\\in\\partial|y-p_{y}|$ 的向量 $\\mathbf{g}=(g_{x},g_{y})$。\n\n更新规则为 $\\mathbf{x}_{k}=\\mathbf{x}_{k-1}-\\alpha_{k}\\mathbf{g}_{k-1}$，其中 $\\alpha_{k}=\\frac{2}{k}$。\n\n迭代 $k=1$：当 $\\mathbf{x}_{0}=(9.5,-2.5)$ 且 $\\mathbf{p}=(1.5,4.5)$ 时，我们有\n$$\nx_{0}-p_{x}=9.5-1.5=80,\\qquad y_{0}-p_{y}=-2.5-4.5=-70.\n$$\n因此我们可以选择\n$$\n\\mathbf{g}_{0}=(1,-1).\n$$\n因为 $\\alpha_{1}=\\frac{2}{1}=2$，所以更新为\n$$\n\\mathbf{x}_{1}=\\mathbf{x}_{0}-\\alpha_{1}\\mathbf{g}_{0}\n=(9.5,-2.5)-2(1,-1)=(9.5-2,\\,-2.5+2)=(7.5,-0.5).\n$$\n\n迭代 $k=2$：现在当 $\\mathbf{x}_{1}=(7.5,-0.5)$ 时，\n$$\nx_{1}-p_{x}=7.5-1.5=60,\\qquad y_{1}-p_{y}=-0.5-4.5=-50,\n$$\n所以我们可以再次取\n$$\n\\mathbf{g}_{1}=(1,-1).\n$$\n当 $\\alpha_{2}=\\frac{2}{2}=1$ 时，更新为\n$$\n\\mathbf{x}_{2}=\\mathbf{x}_{1}-\\alpha_{2}\\mathbf{g}_{1}\n=(7.5,-0.5)-1(1,-1)=(7.5-1,\\,-0.5+1)=(6.5,0.5).\n$$\n\n因此，经过两次迭代后，代理的位置是 $\\mathbf{x}_{2}=(6.5,0.5)$。",
            "answer": "$$\\boxed{\\begin{pmatrix}6.5  0.5\\end{pmatrix}}$$"
        },
        {
            "introduction": "步长选择是次梯度法的核心环节之一，它直接影响算法的收敛速度和稳定性。与前一个练习中使用的预设递减步长不同，本练习将介绍一种更智能的策略：Polyak 步长规则。该规则利用已知的最优函数值 $f^*$ 来动态调整每一步的大小，通常能实现更快的收敛。通过这个练习，你将学会如何应用 Polyak 步长，并体会不同步长策略的优劣。",
            "id": "2207151",
            "problem": "考虑最小化非光滑凸函数 $f(x) = |4x - 7|$ 的任务，其中 $x$ 是一个标量变量。已知该函数的最小值为 $f^* = 0$。我们将使用次梯度法来寻找最小化点的更好估计。\n\n次梯度法的更新规则如下：\n$$x_{k+1} = x_k - \\alpha_k g_k$$\n其中 $x_k$ 是当前点，$g_k$ 是函数 $f$ 在点 $x_k$ 处的一个次梯度，$\\alpha_k$ 是该次迭代的步长。\n\n从初始点 $x_0 = 1$ 开始，执行一次迭代。第一次迭代的步长 $\\alpha_0$ 由 Polyak 步长规则确定，定义为：\n$$\\alpha_0 = \\frac{f(x_0) - f^*}{\\|g_0\\|^2}$$\n\n计算下一次迭代的值 $x_1$。将您的答案表示为最简分数形式。",
            "solution": "我们有凸函数 $f(x)=|4x-7|$。对于 $h(t)=|t|$，一个次梯度为 $s\\in\\partial h(t)$，其中当 $t\\neq 0$ 时 $s=\\operatorname{sign}(t)$，当 $t=0$ 时 $s\\in[-1,1]$。根据仿射参数的次梯度链式法则，$f$ 在 $x$ 处的次梯度为 $g=4s$，其中 $s\\in\\partial|4x-7|$。\n\n在初始点 $x_{0}=1$ 处，我们有 $4x_{0}-7=4\\cdot 1-7=-30$，因此 $s_{0}=-1$，从而\n$$\ng_{0}=4(-1)=-4.\n$$\n计算函数值和最优值：$f(x_{0})=|4\\cdot 1-7|=3$ 且 $f^{*}=0$。由于 $x$ 是标量，$\\|g_{0}\\|^{2}=(-4)^{2}=16$。Polyak 步长为\n$$\n\\alpha_{0}=\\frac{f(x_{0})-f^{*}}{\\|g_{0}\\|^{2}}=\\frac{3}{16}.\n$$\n应用次梯度更新 $x_{1}=x_{0}-\\alpha_{0}g_{0}$：\n$$\nx_{1}=1-\\frac{3}{16}\\cdot(-4)=1+\\frac{12}{16}=1+\\frac{3}{4}=\\frac{7}{4}.\n$$\n因此，下一次迭代的值是 $\\frac{7}{4}$。",
            "answer": "$$\\boxed{\\frac{7}{4}}$$"
        },
        {
            "introduction": "理论分析为我们提供了不同步长策略收敛性的保证，但“眼见为实”能带来更深刻的理解。这个练习要求你从纸笔计算转向编程实践，通过编写代码来比较几种经典步长策略在解决同一个简单问题时的表现。你将实现并对比递减步长、调和级数步长和 Polyak 步长的收敛速度，从而直观地验证它们的理论性质，并培养将优化算法付诸实践的动手能力。",
            "id": "3188881",
            "problem": "要求您实现并比较次梯度法在凸函数 $f(x) = |x|$ 上，采用三种不同步长策略时的收敛行为。您的比较必须通过一个完整的、可运行的程序来执行。该程序应基于以下核心概念构建：\n\n1. 如果对于所有 $x,y\\in\\mathbb{R}$ 和所有 $\\theta\\in[0,1]$，不等式 $f(\\theta x+(1-\\theta)y)\\leq \\theta f(x)+(1-\\theta)f(y)$ 均成立，则函数 $f:\\mathbb{R}\\to\\mathbb{R}$ 是凸函数。函数 $f(x)=|x|$ 是凸函数，并且是利普希茨连续的，其利普希茨常数为 $L=1$。\n\n2. 在点 $x$ 处的次梯度 $g\\in\\partial f(x)$ 满足对于所有 $y\\in\\mathbb{R}$，有 $f(y)\\ge f(x)+g\\cdot(y-x)$。对于 $f(x)=|x|$，其次微分为：当 $x\\neq 0$ 时，$\\partial f(x)=\\{\\operatorname{sign}(x)\\}$；当 $x=0$ 时，$\\partial f(0) = [-1,1]$。请使用确定性选择 $g_k=\\operatorname{sign}(x_k)$，并约定 $\\operatorname{sign}(0)=0$。\n\n3. 次梯度法根据更新规则 $x_{k+1} = x_k - \\alpha_k g_k$ 进行迭代，其中 $\\alpha_k$ 是第 $k$ 次迭代的步长。\n\n您的程序必须实现三种不同的步长策略：\n- 递减步长策略 $\\alpha_k = \\dfrac{c}{\\sqrt{k}}$，其中 $k\\ge 1$。\n- 谐波步长策略 $\\alpha_k = \\dfrac{c}{k}$，其中 $k\\ge 1$。\n- Polyak 步长规则 $\\alpha_k = \\dfrac{f(x_k)-f^\\star}{\\lVert g_k\\rVert^2}$，假设已知最优值的下界 $f^\\star$。在标量情况下，$\\lVert g_k\\rVert^2 = g_k^2$，当 $x_k\\neq 0$ 时，其值等于 $1$。\n\n采用以下停止准则：在满足 $|x_k|\\le \\varepsilon$ 的最小迭代指数 $k$ 处宣告收敛。如果初始点 $x_0$ 已经满足 $|x_0|\\le \\varepsilon$，则迭代次数为 $0$。如果在指定的最大迭代次数 $N_{\\max}$ 内未达到收敛，则返回整数 $-1$。\n\n科学一致性要求：\n- 如果 $x_k=0$，则 $g_k=0$ 且 $f(x_k)=0$；将其视为收敛。对于 Polyak 规则，在计算步长之前检查是否收敛，以避免除以零。\n- 对于 Polyak 规则，使用提供的 $f^\\star$ 作为下界。如果 $f^\\star$ 严格低于 $f(x)=|x|$ 的真实最优值（即 $0$），步长规则可能不会收敛；当未满足停止准则时，您的程序必须通过返回 $-1$ 来稳健地报告不收敛的情况。\n\n为每种策略实现次梯度法，并使用下面的测试套件进行比较。对于每个测试用例，按固定顺序 $\\left[\\dfrac{c}{\\sqrt{k}}, \\dfrac{c}{k}, \\text{Polyak}\\right]$ 输出每种策略满足停止准则所需的迭代次数。\n\n测试套件（每个测试用例是一个元组 $(x_0,c,f^\\star,\\varepsilon,N_{\\max})$）：\n- 用例 1：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (10,5,0,10^{-2},10^4)$。\n- 用例 2：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (0,1,0,10^{-12},10^2)$。\n- 用例 3：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (-5,1,0,10^{-2},5\\cdot 10^4)$。\n- 用例 4：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (2,1,-1,10^{-3},10^4)$。\n\n您的程序必须生成单行输出，其中包含一个由方括号括起来的、逗号分隔的列表的列表。例如，预期的格式是 `[[r_11, r_12, r_13], [r_21, r_22, r_23], [r_31, r_32, r_33], [r_41, r_42, r_43]]`，其中每个 `r_ij` 是如上定义的整数。",
            "solution": "用户要求实现并比较三种用于最小化凸函数 $f(x) = |x|$ 的次梯度法步长策略。该任务涉及验证问题陈述，如果有效则提供合理的解决方案，并生成一个完整的、可运行的程序作为最终答案。\n\n### 问题验证\n\n**步骤 1：提取给定信息**\n\n- **要最小化的函数**：$f(x) = |x|$，一个凸且利普希茨连续的函数，利普希茨常数 $L=1$。\n- **定义域**：$f:\\mathbb{R}\\to\\mathbb{R}$。\n- **次梯度定义**：对于给定的 $x$，一个值 $g$ 满足对于所有 $y\\in\\mathbb{R}$，有 $f(y)\\ge f(x)+g\\cdot(y-x)$。\n- **$f(x)=|x|$ 的次微分**：当 $x\\neq 0$ 时，$\\partial f(x)=\\{\\operatorname{sign}(x)\\}$；当 $x=0$ 时，$\\partial f(0) = [-1,1]$。\n- **确定性次梯度选择**：$g_k=\\operatorname{sign}(x_k)$，并约定 $\\operatorname{sign}(0)=0$。\n- **次梯度法更新规则**：$x_{k+1} = x_k - \\alpha_k g_k$，其中 $\\alpha_k$ 是步长。\n- **步长策略**：\n    1.  **递减**：$\\alpha_k = \\dfrac{c}{\\sqrt{k}}$，其中 $k\\ge 1$。\n    2.  **谐波**：$\\alpha_k = \\dfrac{c}{k}$，其中 $k\\ge 1$。\n    3.  **Polyak**：$\\alpha_k = \\dfrac{f(x_k)-f^\\star}{\\lVert g_k\\rVert^2}$，其中 $f^\\star$ 是最优值的已知下界，在标量情况下，$\\lVert g_k\\rVert^2 = g_k^2$。\n- **停止准则**：在满足 $|x_k|\\le \\varepsilon$ 的最小迭代指数 $k$ 处终止。\n- **特殊条件**：\n    - 如果 $|x_0|\\le \\varepsilon$，迭代次数为 $0$。\n    - 如果在 $N_{\\max}$ 次迭代内未达到收敛，结果为 $-1$。\n    - 如果 $x_k=0$，则视为收敛。对于 Polyak 规则，这要求在计算步长之前检查是否收敛，以防止除以零。\n- **测试套件**：\n    - 用例 1：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (10,5,0,10^{-2},10^4)$。\n    - 用例 2：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (0,1,0,10^{-12},10^2)$。\n    - 用例 3：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (-5,1,0,10^{-2},5\\cdot 10^4)$。\n    - 用例 4：$(x_0,c,f^\\star,\\varepsilon,N_{\\max}) = (2,1,-1,10^{-3},10^4)$。\n- **输出格式**：一个逗号分隔的整数列表的列表，例如 `[[r_11, r_12, r_13], [r_21, r_22, r_23], ...]`。\n\n**步骤 2：使用提取的给定信息进行验证**\n\n根据验证标准对问题进行评估：\n\n-   **科学上合理**：该问题是次梯度法的一个典型应用，而次梯度法是凸优化中的一个基本算法。函数 $f(x)=|x|$ 是一个用于分析的标准非可微凸函数。凸性、次梯度和次梯度更新规则的定义都是标准且正确的。步长策略（递减、谐波和 Polyak）在优化文献中是公认的。关于 Polyak 规则的讨论，包括下界 $f^\\star$ 的作用以及在 $f^\\star  f_\\text{true}^\\star$ 时可能不收敛的情况，在科学上是准确的。\n-   **问题明确**：该问题是明确的。它指定了函数、算法、所有必要的参数、初始条件和精确的停止准则。对于每个测试用例，都会生成一个唯一的迭代序列，从而可以确定收敛前或达到最大限制前的迭代次数。\n-   **客观性**：问题以精确、客观的数学语言陈述，没有歧义或主观性陈述。\n-   **完整性和一致性**：问题提供了所有必要的信息（初始点、参数、停止准则），且不包含矛盾的约束。\n-   **现实性和可行性**：该问题是一个数值实验。参数和条件在数学上是一致的，在计算上是可行的。\n\n问题陈述没有表现出任何缺陷，如科学上不合理、信息缺失或含糊不清。\n\n**步骤 3：结论与行动**\n\n问题是 **有效** 的。将按要求开发并实现一个解决方案。\n\n### 解决方案设计\n\n解决方案的核心是一个函数，该函数为给定的步长策略实现次梯度法。此函数将针对四个测试用例中的每一个，在三种策略的每一种上执行。\n\n我们定义一个函数 `run_schedule(schedule_type, x_0, c, f_star, epsilon, n_max)` 来封装迭代过程。\n输入是策略类型（`'diminishing'`、`'harmonic'` 或 `'polyak'`）、初始点 $x_0$、步长常数 $c$、最优值下界 $f^\\star$、容差 $\\varepsilon$ 和最大迭代次数 $N_{\\max}$。\n\n算法流程如下：\n1.  用 $x_0$ 的值初始化当前点 $x$。\n2.  检查初始条件：如果 $|x| \\le \\varepsilon$，算法已经收敛。迭代次数为 $0$，函数返回 $0$。\n3.  开始一个从 $1$ 到 $N_{\\max}$ 的迭代计数循环 $k$。\n4.  在每次迭代 $k$ 开始时，$x$ 的当前值对应于 $x_{k-1}$。\n5.  确定次梯度 $g = \\operatorname{sign}(x)$。问题指定 $\\operatorname{sign}(0)=0$。这个选择确保了 $g \\in \\partial f(x)$。如果 $x \\neq 0$，则 $g$ 是 $1$ 或 $-1$。如果 $x=0$，则 $g=0$。如果 $x$ 变得足够小以满足容差，算法应该在上一步中终止，因此在迭代开始时，预期 $x \\neq 0$。\n6.  根据 `schedule_type` 计算步长 $\\alpha_k$：\n    -   对于 `diminishing`：$\\alpha_k = c / \\sqrt{k}$。\n    -   对于 `harmonic`：$\\alpha_k = c / k$。\n    -   对于 `polyak`：步长为 $\\alpha_k = (f(x_k)-f^\\star) / \\lVert g_k \\rVert^2$。对于我们的问题，$f(x) = |x|$ 且 $g = \\operatorname{sign}(x)$。对于任何非零 $x$，$\\lVert g \\rVert^2 = (\\pm 1)^2 = 1$。因此，步长简化为 $\\alpha_k = |x| - f^\\star$。由于此分支仅在 $x\\neq 0$ 时到达，因此避免了除以零。\n7.  使用次梯度下降规则更新迭代点：$x_{k} = x_{k-1} - \\alpha_k g_{k-1}$。在实现中，这表示为 $x \\leftarrow x - \\alpha_k g$。\n8.  检查是否收敛：如果新值满足 $|x| \\le \\varepsilon$，算法已经收敛。函数返回当前迭代次数 $k$。\n9.  如果循环完成而没有满足停止准则（即 $k$ 达到 $N_{\\max}$），则表示在给定的限制内未收敛。函数返回 $-1$。\n\n这个过程将对所有测试用例和策略的组合重复。具体来说，对于 Polyak 规则，用例 4 使用 $f^\\star=-1$，这严格小于真实最小值 $f_\\text{true}^\\star=0$。这将导致迭代点在 $1$ 和 $-1$ 之间振荡，永远不会收敛到 $0$ 附近的解集。实现必须正确处理这种情况，即达到 $N_{\\max}$ 并返回 $-1$。对于用例 1 和 3，其中 $f^\\star=0$，Polyak 方法预计将在单次迭代中收敛，因为对于 $x_0 \\neq 0$ 的更新规则变为 $x_1 = x_0 - (|x_0|-0)\\operatorname{sign}(x_0) = x_0 - x_0 = 0$。\n\n最终输出将通过收集每个测试用例的整数结果（迭代次数或 -1）到一个列表的列表中，并将其格式化为指定的字符串格式来构建。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares the subgradient method for f(x)=|x| with three\n    different step-size schedules.\n    \"\"\"\n\n    def run_schedule(schedule_type, x0, c, f_star, epsilon, n_max):\n        \"\"\"\n        Runs the subgradient method for a single schedule.\n\n        Args:\n            schedule_type (str): 'diminishing', 'harmonic', or 'polyak'.\n            x0 (float): Initial point.\n            c (float): Constant for step-size schedules.\n            f_star (float): Lower bound on the optimal value for Polyak's rule.\n            epsilon (float): Convergence tolerance.\n            n_max (int): Maximum number of iterations.\n\n        Returns:\n            int: The number of iterations to converge, or -1 if not converged.\n        \"\"\"\n        x = float(x0)\n\n        # Check for convergence at the initial point\n        if abs(x) = epsilon:\n            return 0\n\n        for k in range(1, n_max + 1):\n            # The value of x at the start of iteration k is x_{k-1}\n            f_x = abs(x)\n            \n            # This state is not expected to be reached due to the check after the update.\n            # If x becomes exactly 0, it would have been caught post-update.\n            # This is a safeguard, especially for Polyak's rule.\n            if f_x == 0.0:\n                 return k - 1\n            \n            g = np.sign(x)\n\n            # Calculate step size alpha_k\n            if schedule_type == 'diminishing':\n                alpha = c / np.sqrt(k)\n            elif schedule_type == 'harmonic':\n                alpha = c / k\n            elif schedule_type == 'polyak':\n                # For x != 0, g is +/- 1, so g_norm_sq is 1.\n                g_norm_sq = 1.0\n                alpha = (f_x - f_star) / g_norm_sq\n            else:\n                # This case should not be reached with the current problem setup\n                raise ValueError(\"Unknown schedule type\")\n\n            # Update x to get x_k\n            x = x - alpha * g\n\n            # Check for convergence\n            if abs(x) = epsilon:\n                return k\n\n        # If the loop finishes, convergence was not achieved\n        return -1\n\n    test_cases = [\n        # (x0, c, f_star, epsilon, n_max)\n        (10, 5, 0, 1e-2, 10000),\n        (0, 1, 0, 1e-12, 100),\n        (-5, 1, 0, 1e-2, 50000),\n        (2, 1, -1, 1e-3, 10000),\n    ]\n\n    all_results = []\n    schedules = ['diminishing', 'harmonic', 'polyak']\n\n    for params in test_cases:\n        x0, c, f_star, epsilon, n_max = params\n        case_results = []\n        for schedule in schedules:\n            result = run_schedule(schedule, x0, c, f_star, epsilon, n_max)\n            case_results.append(result)\n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified.\n    # e.g., [[-1,521,1],[0,0,0],...] -> \"[[-1,521,1],[0,0,0],...]\"\n    inner_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}