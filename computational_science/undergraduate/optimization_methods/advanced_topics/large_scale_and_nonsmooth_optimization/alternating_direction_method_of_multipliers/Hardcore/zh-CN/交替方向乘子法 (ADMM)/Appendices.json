{
    "hands_on_practices": [
        {
            "introduction": "掌握交替方向乘子法（ADMM）的第一步是理解如何求解其子问题。这个练习将带你处理最常见的一种情况：当目标函数的一部分是二次函数时，推导ADMM的更新步骤。你会发现，这个更新步骤可以简化为一个具有清晰、封闭解的线性系统，为后续更复杂的应用打下坚实的基础。",
            "id": "2153727",
            "problem": "交替方向乘子法 (ADMM) 是一种求解以下形式优化问题的算法：\n$$ \\min_{x, z} f(x) + g(z) $$\n$$ \\text{subject to } Ax + Bz = b $$\n其中变量为 $x \\in \\mathbb{R}^n$ 和 $z \\in \\mathbb{R}^m$，问题数据由矩阵 $A \\in \\mathbb{R}^{p \\times n}$、$B \\in \\mathbb{R}^{p \\times m}$、向量 $b \\in \\mathbb{R}^p$ 以及凸函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 和 $g: \\mathbb{R}^m \\to \\mathbb{R}$ 给出。\n\n该算法基于增广拉格朗日量：\n$$ L_\\rho(x, z, y) = f(x) + g(z) + y^T(Ax + Bz - b) + \\frac{\\rho}{2}\\|Ax + Bz - b\\|_2^2 $$\n其中 $y \\in \\mathbb{R}^p$ 是对偶变量（或拉格朗日乘子），$\\rho > 0$ 是一个惩罚参数。在每次迭代 $k$ 中，ADMM 依次执行以下更新：\n1.  $x^{k+1} := \\arg\\min_x L_\\rho(x, z^k, y^k)$\n2.  $z^{k+1} := \\arg\\min_z L_\\rho(x^{k+1}, z, y^k)$\n3.  $y^{k+1} := y^k + \\rho(Ax^{k+1} + Bz^{k+1} - b)$\n\n考虑该问题的一个具体实例，其中函数 $f(x)$ 定义为二次函数：\n$$ f(x) = \\frac{1}{2}\\|x - c\\|_2^2 $$\n对于一个给定的常数向量 $c \\in \\mathbb{R}^n$。\n\n推导 $x$ 更新步骤 $x^{k+1}$ 的闭式解析表达式。您的表达式应以问题数据 $A, B, b, c$、惩罚参数 $\\rho$ 以及前一次迭代的值 $z^k$ 和 $y^k$ 来表示。在您的推导中，令 $I$ 表示 $n \\times n$ 的单位矩阵，并假设矩阵 $(I + \\rho A^T A)$ 是可逆的。",
            "solution": "我们通过最小化关于 $x$ 的增广拉格朗日量来推导 $x$ 的更新，同时保持 $z^{k}$ 和 $y^{k}$ 固定。$x$ 子问题是\n$$\nx^{k+1} := \\arg\\min_{x}\\left\\{\\frac{1}{2}\\|x-c\\|_{2}^{2} + (y^{k})^{T}(Ax + B z^{k} - b) + \\frac{\\rho}{2}\\|Ax + B z^{k} - b\\|_{2}^{2}\\right\\}.\n$$\n定义 $d := B z^{k} - b$，则目标函数变为\n$$\n\\frac{1}{2}\\|x-c\\|_{2}^{2} + (y^{k})^{T}(A x + d) + \\frac{\\rho}{2}\\|A x + d\\|_{2}^{2}.\n$$\n与 $x$ 无关的项不影响最小化子，因此我们专注于与 $x$ 相关的部分。对 $x$ 求梯度并令其为零，得到\n$$\n\\nabla_{x}\\left(\\frac{1}{2}\\|x-c\\|_{2}^{2}\\right) + \\nabla_{x}\\left((y^{k})^{T}A x\\right) + \\nabla_{x}\\left(\\frac{\\rho}{2}\\|A x + d\\|_{2}^{2}\\right) = 0,\n$$\n化简为\n$$\n(x - c) + A^{T} y^{k} + \\rho A^{T}(A x + d) = 0.\n$$\n合并关于 $x$ 的项，得到\n$$\n\\left(I + \\rho A^{T}A\\right) x = c - A^{T} y^{k} - \\rho A^{T} d.\n$$\n代入 $d = B z^{k} - b$，我们有\n$$\n\\left(I + \\rho A^{T}A\\right) x = c - A^{T} y^{k} - \\rho A^{T}(B z^{k} - b).\n$$\n在 $\\left(I + \\rho A^{T}A\\right)$ 可逆的假设下，唯一的最小化子是\n$$\nx^{k+1} = \\left(I + \\rho A^{T}A\\right)^{-1}\\left(c - A^{T} y^{k} - \\rho A^{T}(B z^{k} - b)\\right).\n$$",
            "answer": "$$\\boxed{\\left(I+\\rho A^{T}A\\right)^{-1}\\left(c-A^{T}y^{k}-\\rho A^{T}\\left(Bz^{k}-b\\right)\\right)}$$"
        },
        {
            "introduction": "在掌握了基本更新规则后，我们来看一个ADMM在稀疏信号恢复中的经典应用：基追踪。这个练习将向你展示ADMM“分而治之”的强大威力，它如何将一个复杂问题拆解为投影和软阈值（一种重要的邻近算子）两个更简单的子问题。通过结合理论推导与具体数值计算，你将更深入地理解ADMM的工作原理及其参数$ \\rho $的实际影响。",
            "id": "3096765",
            "problem": "考虑基追踪问题，即通过求解凸规划 $\\min_{x} \\|x\\|_{1}$ subject to $A x = b$ 来寻找一个稀疏向量。引入一个副本变量 $z$ 和约束 $x=z$，将问题重写为在 $x=z$ 的约束下最小化 $\\|z\\|_{1} + \\mathcal{I}_{\\{x: A x = b\\}}(x)$，其中 $\\mathcal{I}_{\\{x: A x = b\\}}$ 是仿射集 $\\{x: A x = b\\}$ 的指示函数。使用交替方向乘子法 (ADMM)，从增广拉格朗日量的定义和交替最小化的基本原理出发，推导 $x$、$z$ 和缩放对偶变量 $u$ 的缩放形式更新规则。明确指出出现的近端算子。\n\n然后，将您的推导实例化到以下具体实例上。令 $A \\in \\mathbb{R}^{2 \\times 3}$ 和 $b \\in \\mathbb{R}^{2}$ 为\n$$\nA = \\begin{pmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 1\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}.\n$$\n假设罚参数 $\\rho$ 为 $\\rho = 2$，分裂变量的初始迭代值为 $z^{0} = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix}$，初始缩放对偶变量为 $u^{0} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$。计算一次完整的 ADMM 迭代，并精确报告更新后的 $x^{1}$。\n\n最后，假设传感矩阵 $A$ 满足有限等距性质 (RIP)，且其常数足够小以确保 $A x^{\\star} = b$ 的 $s$-稀疏解 $x^{\\star}$ 的唯一性（例如，阶数为 $2s$ 的 RIP 且常数小到足以保证基追踪的精确恢复），从凸问题的 ADMM 收敛理论出发，解释为什么精确的稀疏恢复不依赖于 $\\rho$ 的值（只要 $\\rho > 0$），并阐明 $\\rho$ 如何影响收敛速度和数值稳定性。\n\n您最终报告的答案必须是使用 `pmatrix` 环境写成行向量的 $x^{1}$ 的单一表达式。无需四舍五入。",
            "solution": "首先验证该问题是自洽的，在凸优化领域具有科学依据，并且在数学上是适定的。为理论推导和数值计算提供了所有必要的数据和条件。该问题有效。\n\n基追踪问题被表述为通过求解凸优化规划来寻找一个稀疏向量 $x$：\n$$\n\\min_{x} \\|x\\|_{1} \\quad \\text{subject to} \\quad A x = b\n$$\n为了应用交替方向乘子法（ADMM），我们引入一个分裂变量 $z$ 和一个辅助约束 $x=z$。问题被重写为等价形式：\n$$\n\\min_{x, z} f(x) + g(z) \\quad \\text{subject to} \\quad x - z = 0\n$$\n其中 $f(x) = \\mathcal{I}_{\\{x: A x = b\\}}(x)$ 且 $g(z) = \\|z\\|_{1}$。函数 $\\mathcal{I}_{\\{x: A x = b\\}}(x)$ 是仿射集 $\\{x \\in \\mathbb{R}^n: A x = b\\}$ 的指示函数，如果 $A x = b$ 则为 $0$，否则为 $+\\infty$。\n\n该问题的增广拉格朗日量为：\n$$\nL_{\\rho}(x, z, y) = f(x) + g(z) + y^T(x - z) + \\frac{\\rho}{2}\\|x - z\\|_{2}^{2}\n$$\n这里，$y$ 是拉格朗日乘子（或对偶变量），$\\rho > 0$ 是罚参数。ADMM 的缩放形式使用一个缩放对偶变量 $u = (1/\\rho)y$，这简化了更新步骤。用 $u$ 表示的增广拉格朗日量可以通过配方法写成：\n$$\nL_{\\rho}(x, z, u) = f(x) + g(z) + \\rho u^T(x - z) + \\frac{\\rho}{2}\\|x - z\\|_{2}^{2} = f(x) + g(z) + \\frac{\\rho}{2}\\|x - z + u\\|_{2}^{2} - \\frac{\\rho}{2}\\|u\\|_{2}^{2}\n$$\nADMM 算法包含三个步骤，在每一步 $k$ 进行迭代：\n$1$. $x$-最小化：$x^{k+1} = \\arg\\min_{x} L_{\\rho}(x, z^k, u^k)$\n$2$. $z$-最小化：$z^{k+1} = \\arg\\min_{z} L_{\\rho}(x^{k+1}, z, u^k)$\n$3$. 对偶更新：$u^{k+1} = u^k + x^{k+1} - z^{k+1}$\n\n现在我们推导 $x$ 和 $z$ 的具体更新规则。\n\n$x$-更新步骤是：\n$$\nx^{k+1} = \\arg\\min_{x} \\left( f(x) + g(z^k) + \\frac{\\rho}{2}\\|x - z^k + u^k\\|_{2}^{2} - \\frac{\\rho}{2}\\|u^k\\|_{2}^{2} \\right)\n$$\n由于 $g(z^k)$ 和 $\\|u^k\\|_2^2$ 相对于 $x$ 是常数，这等价于：\n$$\nx^{k+1} = \\arg\\min_{x} \\left( \\mathcal{I}_{\\{x: A x = b\\}}(x) + \\frac{\\rho}{2}\\|x - (z^k - u^k)\\|_{2}^{2} \\right)\n$$\n这个最小化问题等价于在仿射集 $\\{x : Ax=b\\}$ 中找到离点 $v^k = z^k - u^k$ 最近的点 $x$。这是将 $v^k$ 投影到该仿射集上的欧几里得投影。令 $\\Pi_{\\{x: Ax=b\\}}(\\cdot)$ 表示此投影算子。更新为：\n$$\nx^{k+1} = \\Pi_{\\{x: Ax=b\\}}(z^k - u^k)\n$$\n\n$z$-更新步骤是：\n$$\nz^{k+1} = \\arg\\min_{z} \\left( f(x^{k+1}) + g(z) + \\frac{\\rho}{2}\\|x^{k+1} - z + u^k\\|_{2}^{2} - \\frac{\\rho}{2}\\|u^k\\|_{2}^{2} \\right)\n$$\n由于 $f(x^{k+1})$ 和 $\\|u^k\\|_2^2$ 相对于 $z$ 是常数，这简化为：\n$$\nz^{k+1} = \\arg\\min_{z} \\left( \\|z\\|_{1} + \\frac{\\rho}{2}\\|z - (x^{k+1} + u^k)\\|_{2}^{2} \\right)\n$$\n这是 $\\ell_1$-范数的近端算子的定义。函数 $h$ 的近端算子定义为 $\\text{prox}_{\\lambda h}(v) = \\arg\\min_u (h(u) + \\frac{1}{2\\lambda}\\|u-v\\|_2^2)$。在我们的例子中，$h(z) = \\|z\\|_1$ 且 $\\frac{1}{2\\lambda} = \\frac{\\rho}{2}$，这意味着 $\\lambda = 1/\\rho$。$\\ell_1$-范数的近端算子是软阈值算子 $S_{\\kappa}(\\cdot)$，其中 $\\kappa = 1/\\rho$。该算子按分量作用：$(S_{\\kappa}(v))_i = \\text{sign}(v_i)\\max(|v_i| - \\kappa, 0)$。\n所以，$z$-更新是：\n$$\nz^{k+1} = S_{1/\\rho}(x^{k+1} + u^k)\n$$\n出现的近端算子是软阈值算子，它是 $\\ell_1$ 范数的近端算子。\n\n对偶变量更新保持不变：\n$$\nu^{k+1} = u^k + x^{k+1} - z^{k+1}\n$$\n\n接下来，我们用给定的数据实例化一次迭代：\n$A = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix}$，$b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$，$\\rho = 2$，$z^{0} = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix}$，$u^{0} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n我们需要计算 $x^1$。第一步是 $x$-更新：\n$$\nx^1 = \\Pi_{\\{x: Ax=b\\}}(z^0 - u^0)\n$$\n令 $v^0 = z^0 - u^0 = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix}$。对于一个行满秩矩阵 $A$，将点 $v$ 投影到仿射集 $\\{x : Ax=b\\}$ 的公式为 $x = v - A^T(AA^T)^{-1}(Av-b)$。\n我们首先计算矩阵 $AA^T$：\n$$\nAA^T = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1(1)+1(1)+0(0) & 1(0)+1(1)+0(1) \\\\ 0(1)+1(1)+1(0) & 0(0)+1(1)+1(1) \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}\n$$\n其逆矩阵是：\n$$\n(AA^T)^{-1} = \\frac{1}{(2)(2) - (1)(1)} \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix}\n$$\n接下来，我们计算 $Av^0 - b$：\n$$\nAv^0 = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix} = \\begin{pmatrix} 0.8+0.4 \\\\ 0.4+0.1 \\end{pmatrix} = \\begin{pmatrix} 1.2 \\\\ 0.5 \\end{pmatrix}\n$$\n$$\nAv^0 - b = \\begin{pmatrix} 1.2 \\\\ 0.5 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ -0.5 \\end{pmatrix}\n$$\n现在我们计算 $A^T(AA^T)^{-1}(Av^0-b)$：\n$$\n(AA^T)^{-1}(Av^0-b) = \\frac{1}{3} \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} \\begin{pmatrix} 0.2 \\\\ -0.5 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2(0.2) - (-0.5) \\\\ -0.2 + 2(-0.5) \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 0.4+0.5 \\\\ -0.2-1.0 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 0.9 \\\\ -1.2 \\end{pmatrix} = \\begin{pmatrix} 0.3 \\\\ -0.4 \\end{pmatrix}\n$$\n$$\nA^T \\left( (AA^T)^{-1}(Av^0-b) \\right) = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0.3 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 0.3 \\\\ 0.3-0.4 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 0.3 \\\\ -0.1 \\\\ -0.4 \\end{pmatrix}\n$$\n最后，我们计算 $x^1$：\n$$\nx^1 = v^0 - A^T(AA^T)^{-1}(Av^0-b) = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix} - \\begin{pmatrix} 0.3 \\\\ -0.1 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 0.8 - 0.3 \\\\ 0.4 - (-0.1) \\\\ 0.1 - (-0.4) \\end{pmatrix} = \\begin{pmatrix} 0.5 \\\\ 0.5 \\\\ 0.5 \\end{pmatrix}\n$$\n以分数形式表示，$x^1 = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix}$。\n\n最后，我们讨论罚参数 $\\rho$ 的作用。\n凸问题的 ADMM 收敛理论保证，如果优化问题存在解，ADMM 迭代将会收敛到一个解。具体到我们的问题，迭代 $(x^k, z^k)$ 将收敛到一对 $(x^*, z^*)$，使得 $x^*=z^*$ 是基追踪问题的最优解。问题陈述假设传感矩阵 $A$ 满足适当阶数和常数的有限等距性质 (RIP)。在此条件下，$Ax=b$ 的 $s$-稀疏解 $x^{\\star}$ 是唯一的，并且也是基追踪问题 $\\min \\|x\\|_1$ subject to $Ax=b$ 的唯一解。由于 ADMM 保证收敛到这个凸问题的解，并且在 RIP 假设下解是唯一的，因此无论参数 $\\rho$ 的选择如何（只要 $\\rho > 0$），该算法都将收敛到这个唯一的稀疏向量 $x^{\\star}$。极限点由问题的 Karush-Kuhn-Tucker (KKT) 最优性条件决定，而这些条件与 $\\rho$ 无关。\n\n然而，参数 $\\rho$ 在算法的收敛*速度*和数值行为中起着至关重要的作用。$\\rho$ 的选择决定了在最小化目标函数和满足一致性约束 $x=z$ 之间的平衡。\n- 如果 $\\rho$ 很大，增广拉格朗日量中对原始残差 $\\|x-z\\|_2^2$ 的惩罚就很高。这迫使迭代 $x^k$ 和 $z^k$ 彼此接近。然而，大的 $\\rho$ 意味着软阈值参数 $1/\\rho$ 很小。这导致在 $z$ 更新中收缩很少，从而减慢了使 $z$（并因此使 $x$）变得稀疏的进程，而这才是主要目标。\n- 如果 $\\rho$ 很小，对原始残差的惩罚就低，允许 $x^k$ 和 $z^k$ 相距较远。软阈值参数 $1/\\rho$ 很大，导致在 $z$ 更新中进行激进的阈值处理。这可以迅速将 $z$ 的许多分量驱动为零，在 $\\ell_1$ 目标上取得快速进展。然而，对 $x=z$ 约束的弱执行可能意味着迭代需要很长时间才能收敛到对原始问题可行的点（即 $x=z$ 且 $Ax=b$）。\n\n总之，这里存在一个权衡：$\\rho$ 平衡了最小化目标和满足约束。$\\rho$ 的最优选择（通常与问题相关）导致最快的收敛速度。尽管任意正的 $\\rho$ 保证最终收敛到正确的稀疏解（在 RIP 条件下），但一个糟糕的选择可能导致收敛极其缓慢，在实践中可能被误认为是数值不稳定性或不收敛。子问题本身（一个投影和一个软阈值处理）的数值稳定性通常很好，所以 $\\rho$ 的主要影响在于整个算法的收敛速率。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "这项高级实践展示了ADMM在解决现代机器学习问题时的强大功能和灵活性。在这里，子问题本身不再具有简单的封闭解，而是需要通过数值方法（如牛顿法和二分法）来求解，这体现了ADMM作为解决复杂优化问题通用框架的价值。通过解决一个关于算法公平性的前沿问题，你将体验到如何运用ADMM应对现实世界中的复杂挑战。",
            "id": "3096690",
            "problem": "您将实现交替方向乘子法 (ADMM) 来解决一个带有组间平均 logit 公平性约束的凸等式约束逻辑回归问题，然后报告可行性残差。请严格遵循凸优化、逻辑回归损失、线性等式约束和增广拉格朗日量的核心定义进行操作，不要使用任何未从这些原理推导出的快捷公式。\n\n考虑一个二元分类数据集，其设计矩阵为 $X \\in \\mathbb{R}^{n \\times d}$，标签为 $y \\in \\{-1, +1\\}^n$，以及一个敏感组指示符 $s \\in \\{0,1\\}^n$，该指示符将样本划分为两个不相交的组 $\\mathcal{G}_0 = \\{i : s_i = 0\\}$ 和 $\\mathcal{G}_1 = \\{i : s_i = 1\\}$。令 $n_0 = |\\mathcal{G}_0|$ 和 $n_1 = |\\mathcal{G}_1|$。定义向量 $a \\in \\mathbb{R}^n$，其元素为\n$$\na_i = \n\\begin{cases}\n\\frac{1}{n_0}, & \\text{if } i \\in \\mathcal{G}_0,\\\\\n-\\frac{1}{n_1}, & \\text{if } i \\in \\mathcal{G}_1.\n\\end{cases}\n$$\n我们考虑逻辑回归模型，其参数为 $w \\in \\mathbb{R}^d$，logits 为 $u \\in \\mathbb{R}^n$，并受约束 $u = X w$。logit 上的逻辑损失为\n$$\n\\ell(u; y) = \\sum_{i=1}^n \\log\\!\\big(1 + \\exp(-y_i u_i)\\big),\n$$\n我们对 $w$ 加入一个系数为 $\\lambda > 0$ 的 $\\ell_2$-正则化项。我们施加一个公平性约束，要求组间平均 logit 相等，表示为线性等式 $a^\\top u = 0$。\n\n您的任务是使用交替方向乘子法 (ADMM) 解决以下凸优化问题：\n$$\n\\begin{aligned}\n\\min_{w \\in \\mathbb{R}^d,\\, u \\in \\mathbb{R}^n}\\quad & \\ell(u; y) + \\frac{\\lambda}{2}\\,\\|w\\|_2^2\\\\\n\\text{s.t.}\\quad & u - X w = 0,\\\\\n& a^\\top u = 0.\n\\end{aligned}\n$$\n使用一种分裂方法，将 $u$ 和 $w$ 视为独立变量，通过可行集 $\\{u \\in \\mathbb{R}^n: a^\\top u = 0\\}$ 的指示函数将公平性约束 $a^\\top u = 0$ 附加到 $u$ 的更新步骤中，并用 ADMM 处理 $u - X w = 0$。请从增广拉格朗日量的定义推导更新步骤，不要假设任何预先给定的 ADMM 公式。\n\n在每次 ADMM 迭代中：\n- $w$-更新应通过最小化一个严格凸的二次目标函数获得，该目标函数由正则化项和对线性约束 $u - X w = 0$ 的二次惩罚项构成。\n- $u$-更新应最小化一个由逻辑损失、二次惩罚项和公平性约束 $a^\\top u = 0$ 构成的严格凸目标函数。解决这个 $u$-子问题的方法是：为单个线性等式构建标量对偶问题，并对其拉格朗日乘子使用一维二分法，其中每个坐标的最小化问题都通过对一个光滑的一维函数使用牛顿法来解决。\n\n停止规则：\n- 当原始可行性残差 $\\|u - X w\\|_2$ 和公平性可行性残差 $|a^\\top u|$ 均低于容差 $\\varepsilon = 10^{-5}$ 时，或达到最大迭代次数时，终止 ADMM。\n\n您的程序必须为每个测试用例计算以下两个浮点数：\n- 原始可行性残差 $r_{\\text{prim}} = \\|u - X w\\|_2$。\n- 公平性可行性残差 $r_{\\text{fair}} = |a^\\top u|$。\n\n测试套件：\n使用以下三个测试用例。对于每个用例，交替方向乘子法 (ADMM) 的惩罚参数为 $\\rho = 1.0$，容差为 $\\varepsilon = 10^{-5}$，最大迭代次数为 $200$。\n\n- 测试用例 1：\n  - $X \\in \\mathbb{R}^{10 \\times 3}$:\n    $\n    \\begin{bmatrix}\n    0.5 & -1.0 & 0.3\\\\\n    1.2 & 0.7 & -0.1\\\\\n    -0.3 & 0.8 & 1.0\\\\\n    0.0 & -0.5 & 1.2\\\\\n    0.9 & 0.1 & -0.7\\\\\n    -1.0 & 0.2 & 0.4\\\\\n    0.3 & 0.4 & -0.9\\\\\n    0.6 & -0.2 & 0.5\\\\\n    -0.7 & 1.1 & -0.3\\\\\n    0.2 & 0.0 & -0.6\n    \\end{bmatrix}\n    $\n  - $y \\in \\{-1,1\\}^{10}$: $[1, 1, -1, 1, 1, -1, -1, 1, -1, 1]$\n  - $s \\in \\{0,1\\}^{10}$: $[0,1,0,1,0,1,0,1,0,1]$\n  - $\\lambda = 0.1$\n- 测试用例 2：\n  - $X \\in \\mathbb{R}^{8 \\times 2}$:\n    $\n    \\begin{bmatrix}\n    0.1 & -0.2\\\\\n    0.3 & 0.5\\\\\n    -0.4 & 0.7\\\\\n    0.6 & -0.8\\\\\n    0.9 & 0.2\\\\\n    -0.5 & -0.1\\\\\n    0.2 & -0.3\\\\\n    -0.7 & 0.4\n    \\end{bmatrix}\n    $\n  - $y \\in \\{-1,1\\}^{8}$: $[1, 1, 1, 1, 1, 1, 1, 1]$\n  - $s \\in \\{0,1\\}^{8}$: $[0, 0, 1, 1, 0, 1, 0, 1]$\n  - $\\lambda = 0.01$\n- 测试用例 3：\n  - $X \\in \\mathbb{R}^{12 \\times 4}$:\n    $\n    \\begin{bmatrix}\n    0.5 & 0.2 & -0.1 & 0.7\\\\\n    -0.3 & 0.8 & 0.0 & -0.4\\\\\n    1.0 & -0.5 & 0.3 & 0.2\\\\\n    0.2 & 0.1 & -0.6 & 0.9\\\\\n    -0.8 & 0.4 & 0.5 & -0.2\\\\\n    0.6 & -0.7 & 0.1 & 0.3\\\\\n    0.0 & 0.9 & -0.2 & -0.1\\\\\n    -0.4 & -0.3 & 0.8 & 0.5\\\\\n    0.7 & -0.2 & -0.4 & 0.6\\\\\n    -0.9 & 0.5 & 0.2 & -0.3\\\\\n    0.3 & -0.1 & 0.4 & 0.0\\\\\n    -0.2 & 0.6 & -0.5 & 0.8\n    \\end{bmatrix}\n    $\n  - $y \\in \\{-1,1\\}^{12}$: $[1,-1,1,-1,1,-1,1,-1,1,-1,1,-1]$\n  - $s \\in \\{0,1\\}^{12}$: $[0,0,0,0,0,0,0,1,1,1,1,1]$\n  - $\\lambda = 0.5$\n\n输出要求：\n- 对于每个测试用例，计算终止时的两个浮点数 $(r_{\\text{prim}}, r_{\\text{fair}})$。\n- 您的程序应生成单行输出，其中包含一个由三个项目组成的逗号分隔列表，每个项目本身就是一个包含两个浮点数的列表。格式应严格如下：\n  - $[[r_{\\text{prim},1},r_{\\text{fair},1}],[r_{\\text{prim},2},r_{\\text{fair},2}],[r_{\\text{prim},3},r_{\\text{fair},3}]]$\n- 每个浮点数必须四舍五入到小数点后六位，并且打印时不带多余的空格。\n\n不涉及物理单位。不使用角度。不使用百分比。最终输出必须严格遵循上述单行格式。",
            "solution": "我们推导一个用于解决带有组间平均 logit 公平性约束的凸等式约束逻辑回归问题的交替方向乘子法 (ADMM) 算法。\n\n基本设置。令 $X \\in \\mathbb{R}^{n \\times d}$，标签 $y \\in \\{-1,+1\\}^n$，以及敏感组 $s \\in \\{0,1\\}^n$ 决定划分 $\\mathcal{G}_0, \\mathcal{G}_1$。定义 $a \\in \\mathbb{R}^n$ 为：如果 $i \\in \\mathcal{G}_0$，则 $a_i = \\frac{1}{n_0}$；如果 $i \\in \\mathcal{G}_1$，则 $a_i = -\\frac{1}{n_1}$，其中 $n_0 = |\\mathcal{G}_0|$，$n_1 = |\\mathcal{G}_1|$。考虑以下优化问题：\n$$\n\\min_{w \\in \\mathbb{R}^d,\\, u \\in \\mathbb{R}^n}\\; \\ell(u; y) + \\frac{\\lambda}{2}\\|w\\|_2^2\n\\quad\\text{s.t.}\\quad u - X w = 0,\\;\\; a^\\top u = 0,\n$$\n其中逻辑损失为\n$$\n\\ell(u; y) = \\sum_{i=1}^n \\log(1 + \\exp(-y_i u_i)).\n$$\n函数 $\\ell$ 关于 $u$ 是凸的，因为标量函数 $g(t) = \\log(1+e^{-t})$ 是凸的，且与线性函数 $t = y_i u_i$ 的复合保持了凸性（因为 $y_i \\in \\{-1,1\\}$）。正则化项 $\\frac{\\lambda}{2}\\|w\\|_2^2$ 也是凸的。约束是线性的，因此该问题是凸问题，适合采用增广拉格朗日方法。\n\nADMM 分裂。我们通过一个指示函数将公平性约束放入 $u$-块中，并用 ADMM 来强制执行 $u - X w = 0$。具体来说，定义指示函数\n$$\n\\iota_{\\mathcal{C}}(u) = \n\\begin{cases}\n0, & \\text{if } a^\\top u = 0,\\\\\n+\\infty, & \\text{otherwise},\n\\end{cases}\n$$\n并定义 $f(u) = \\ell(u; y) + \\iota_{\\mathcal{C}}(u)$ 和 $g(w) = \\frac{\\lambda}{2}\\|w\\|_2^2$。我们将问题重写为：\n$$\n\\min_{u,w} f(u) + g(w) \\quad \\text{s.t.} \\quad u - X w = 0.\n$$\n\n增广拉格朗日量。带有对偶变量 $\\nu \\in \\mathbb{R}^n$ 和惩罚参数 $\\rho > 0$ 的未缩放增广拉格朗日量为\n$$\n\\mathcal{L}_\\rho(u,w,\\nu) = f(u) + g(w) + \\nu^\\top(u - X w) + \\frac{\\rho}{2}\\|u - X w\\|_2^2.\n$$\n在缩放形式中，定义 $d = \\nu/\\rho$。省略与决策变量无关的常数项，缩放后的子问题变为：\n- $w$-更新：\n$$\nw^{k+1} = \\arg\\min_w\\; g(w) + \\frac{\\rho}{2}\\|u^k - X w + d^k\\|_2^2.\n$$\n- $u$-更新：\n$$\nu^{k+1} = \\arg\\min_u\\; \\ell(u; y) + \\iota_{\\mathcal{C}}(u) + \\frac{\\rho}{2}\\|u - X w^{k+1} + d^k\\|_2^2.\n$$\n- 对偶更新：\n$$\nd^{k+1} = d^k + u^{k+1} - X w^{k+1}.\n$$\n\n推导 $w$-更新。$w$-子问题是一个严格凸二次最小化问题：\n$$\n\\min_w \\frac{\\lambda}{2}\\|w\\|_2^2 + \\frac{\\rho}{2}\\|u^k + d^k - X w\\|_2^2.\n$$\n将梯度设为零可得\n$$\n\\lambda w - \\rho X^\\top(u^k + d^k - X w) = 0\n\\;\\;\\Rightarrow\\;\\;\n(\\lambda I + \\rho X^\\top X) w = \\rho X^\\top (u^k + d^k).\n$$\n由于 $\\lambda > 0$ 和 $\\rho > 0$，矩阵 $\\lambda I + \\rho X^\\top X$ 是对称正定的；因此，$w^{k+1}$ 通过求解这个线性系统唯一确定。\n\n推导带公平性约束的 $u$-更新。令 $v^{k+1} = X w^{k+1} - d^k$。$u$-子问题是\n$$\n\\min_{u \\in \\mathbb{R}^n} \\sum_{i=1}^n \\log\\!\\big(1 + \\exp(-y_i u_i)\\big) + \\frac{\\rho}{2}\\|u - v^{k+1}\\|_2^2\n\\quad \\text{s.t.} \\quad a^\\top u = 0.\n$$\n为约束 $a^\\top u = 0$ 引入一个标量拉格朗日乘子 $\\lambda_{\\text{eq}} \\in \\mathbb{R}$。对于这个严格凸问题，KKT 条件要求对每个坐标 $i$，\n$$\n\\frac{\\partial}{\\partial u_i} \\left( \\log(1 + \\exp(-y_i u_i)) + \\frac{\\rho}{2}(u_i - v^{k+1}_i)^2 \\right) + a_i \\lambda_{\\text{eq}} = 0,\n$$\n以及 $a^\\top u = 0$ 成立。导数为\n$$\n\\phi_i'(u_i) + \\rho(u_i - v_i^{k+1}) + a_i \\lambda_{\\text{eq}} = 0,\\quad\n\\phi_i'(u_i) = -\\frac{y_i}{1 + \\exp(y_i u_i)}.\n$$\n对于任意固定的 $\\lambda_{\\text{eq}}$，关于 $u_i$ 的方程是一维、连续可微且严格单调的，这是因为其二阶导数\n$$\n\\phi_i''(u_i) + \\rho = \\frac{\\exp(y_i u_i)}{(1 + \\exp(y_i u_i))^2} + \\rho \\ge \\rho > 0,\n$$\n所以每个坐标都有一个唯一的最小化子，可以通过对一个光滑的一维函数应用牛顿法来找到。约束 $a^\\top u = 0$ 使系统封闭；定义函数\n$$\ng(\\lambda_{\\text{eq}}) := a^\\top u(\\lambda_{\\text{eq}}) = \\sum_{i=1}^n a_i\\, u_i(\\lambda_{\\text{eq}}),\n$$\n其中 $u_i(\\lambda_{\\text{eq}})$ 是第 $i$ 个坐标最优性条件的解。我们有\n$$\n\\frac{d}{d\\lambda_{\\text{eq}}} g(\\lambda_{\\text{eq}})\n= \\sum_{i=1}^n a_i \\frac{d u_i}{d\\lambda_{\\text{eq}}}\n= -\\sum_{i=1}^n \\frac{a_i^2}{\\phi_i''(u_i) + \\rho} < 0,\n$$\n因此 $g$ 关于 $\\lambda_{\\text{eq}}$ 是严格递减、连续的，并满足 $\\lim_{\\lambda_{\\text{eq}}\\to -\\infty} g(\\lambda_{\\text{eq}}) = +\\infty$ 和 $\\lim_{\\lambda_{\\text{eq}}\\to +\\infty} g(\\lambda_{\\text{eq}}) = -\\infty$。因此，存在唯一的根 $g(\\lambda_{\\text{eq}}^\\star) = 0$，我们通过对 $\\lambda_{\\text{eq}}$ 进行二分法来找到这个根，其中函数值的计算需要求解 $n$ 个关于 $u_i(\\lambda_{\\text{eq}})$ 的独立一维牛顿问题。\n\n原始可行性残差和公平性可行性残差。交替方向乘子法 (ADMM) 的原始可行性残差为\n$$\nr_{\\text{prim}}^{(k)} = \\|u^{(k)} - X w^{(k)}\\|_2,\n$$\n反映组间平均 logit 相等的公平性可行性残差为\n$$\nr_{\\text{fair}}^{(k)} = |a^\\top u^{(k)}|.\n$$\n当两者都低于容差 $\\varepsilon$ 时，我们终止算法。\n\n算法总结：\n1. 初始化 $w^{(0)} = 0$，$u^{(0)} = 0$，$d^{(0)} = 0$，选择 $\\rho > 0$、容差 $\\varepsilon$ 和最大迭代次数。\n2. 对 $k=0,1,2,\\dots$ 重复：\n   - $w$-更新：求解 $(\\lambda I + \\rho X^\\top X) w^{(k+1)} = \\rho X^\\top (u^{(k)} + d^{(k)})$。\n   - 构造 $v^{(k+1)} = X w^{(k+1)} - d^{(k)}$。\n   - $u$-更新：如上文推导，通过对标量拉格朗日乘子使用二分法和对每个坐标使用牛顿法来求解 $u^{(k+1)} = \\arg\\min_{u}\\; \\sum_i \\log(1+\\exp(-y_i u_i)) + \\frac{\\rho}{2}\\|u - v^{(k+1)}\\|^2$ subject to $a^\\top u = 0$。\n   - 对偶更新：$d^{(k+1)} = d^{(k)} + u^{(k+1)} - X w^{(k+1)}$。\n   - 检查停止条件：如果 $\\|u^{(k+1)} - X w^{(k+1)}\\|_2 \\le \\varepsilon$ 且 $|a^\\top u^{(k+1)}| \\le \\varepsilon$，则停止；否则继续（或在达到迭代上限时停止）。\n3. 报告终止时的 $r_{\\text{prim}} = \\|u - X w\\|_2$ 和 $r_{\\text{fair}} = |a^\\top u|$。\n\n数值考量：\n- $w$-更新中的线性系统对于 $\\lambda > 0$ 是对称正定且良态的，可以通过直接求解器可靠地求解。\n- 由于严格凸性，每个坐标的一维牛顿步是稳健的；Hessian 矩阵的下界 $\\rho > 0$ 避免了平坦曲率。\n- 通过对标量乘子进行二分法实现的公平性投影，由于 $g(\\lambda_{\\text{eq}})$ 的严格单调性以及可以利用渐进行为来确定根的区间，保证收敛。\n\n该实现遵循给定的三个测试用例，并打印一行包含三对 $[r_{\\text{prim}}, r_{\\text{fair}}]$ 的结果，每对都四舍五入到六位小数，格式为无空格的逗号分隔列表，并用方括号括起来。",
            "answer": "[[0.000008,0.000000],[0.000007,0.000000],[0.000009,0.000000]]"
        }
    ]
}