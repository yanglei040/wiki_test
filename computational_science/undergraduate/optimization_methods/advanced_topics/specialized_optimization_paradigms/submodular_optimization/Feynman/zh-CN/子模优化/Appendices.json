{
    "hands_on_practices": [
        {
            "introduction": "贪心算法是次模优化的基石，它为许多问题提供了一种快速且有可证明性能保证的解决方案。然而，其短视的、逐步的决策并非总是全局最优的。本练习将探讨一种增强贪心解的常用策略：应用局部搜索启发式算法作为后处理步骤，并要求您分析解的质量与所产生的计算成本之间的权衡。",
            "id": "3189733",
            "problem": "给定一个集合函数族，其源于子模优化中的设施选址目标。设有限基础集表示为 $\\mathcal{V} = \\{0,1,\\dots,n-1\\}$，非负权重矩阵表示为 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times m}$。对于任意子集 $S \\subseteq \\mathcal{V}$，设施选址目标定义为\n$$\nf(S) \\;=\\; \\sum_{j=0}^{m-1} \\max_{i \\in S} W_{i,j},\n$$\n约定 $f(\\varnothing) = 0$。任务是选择一个固定基数 $k$ 的子集 $S$，使得 $f(S)$ 的值较大。\n\n基础知识：\n- 一个集合函数 $f: 2^{\\mathcal{V}} \\to \\mathbb{R}$ 称为单调的 (monotone)，如果对于所有的 $A \\subseteq B \\subseteq \\mathcal{V}$ 我们有 $f(A) \\le f(B)$；称为子模的 (submodular)，如果对于所有的 $A \\subseteq B \\subseteq \\mathcal{V}$ 和所有的 $x \\in \\mathcal{V} \\setminus B$ 我们有 $f(A \\cup \\{x\\}) - f(A) \\ge f(B \\cup \\{x\\}) - f(B)$。\n- 上面定义的设施选址目标 $f$ 是一个著名的单调子模函数。\n\n需要实现的算法：\n- 基数约束下的贪心选择 (Greedy selection under a cardinality constraint)：从空集 $S_0 = \\varnothing$ 开始，对于 $t = 1,2,\\dots,k$，添加一个元素 $x_t \\in \\mathcal{V} \\setminus S_{t-1}$，该元素能最大化边际增益 $f(S_{t-1} \\cup \\{x\\}) - f(S_{t-1})$。使用以下确定性的打破平局规则：在所有最大化者中，选择索引最小的一个。令 $S_{\\mathrm{greedy}}$ 表示最终得到的集合。\n- 应用一次的最佳单点交换（1-swap）局部改进 (Single best $1$-swap local improvement applied once)：给定 $S_{\\mathrm{greedy}}$，考虑所有满足 $a \\in S_{\\mathrm{greedy}}$ 和 $b \\in \\mathcal{V} \\setminus S_{\\mathrm{greedy}}$ 的配对 $(a,b)$。对每个配对，评估 $f(S_{\\mathrm{greedy}} \\setminus \\{a\\} \\cup \\{b\\})$。令 $(a^\\star,b^\\star)$ 为获得最大值的配对；通过选择字典序最小的配对 $(a,b)$ 来打破平局，即首先按最小的 $a$，如果相同，则按最小的 $b$ 来选择。如果这个最大值严格大于 $f(S_{\\mathrm{greedy}})$，则执行一次交换以获得 $S_{\\mathrm{swap}} = S_{\\mathrm{greedy}} \\setminus \\{a^\\star\\} \\cup \\{b^\\star\\}$。否则，设 $S_{\\mathrm{swap}} = S_{\\mathrm{greedy}}$。\n\n成本模型：\n- 将 $f$ 的评估视为一次单位成本的预言机 (oracle) 调用。每当对一个具体集合计算 $f(\\cdot)$ 时，计为一次预言机调用。\n- 在贪心算法中，不计算 $f(\\varnothing)$；对于每个被评估的候选集 $S \\cup \\{x\\}$，计为一次预言机调用。不要进行冗余的预言机调用；将选定候选集的目标值作为当前集合的值带入下一次迭代，无需额外的预言机调用。\n- 在最佳单点交换（1-swap）阶段，每个被评估的候选交换集恰好计为一次预言机调用。不要在该次最佳交换尝试之后进行迭代；最多执行一次改进交换。\n\n实证任务：\n- 对于每个测试实例，计算改进量 $\\Delta = f(S_{\\mathrm{swap}}) - f(S_{\\mathrm{greedy}})$ 和预言机成本的乘法因子\n$$\n\\varrho \\;=\\; \\frac{E_{\\mathrm{greedy}} + E_{\\mathrm{swap}}}{E_{\\mathrm{greedy}}},\n$$\n其中 $E_{\\mathrm{greedy}}$ 是贪心阶段的预言机调用次数，而 $E_{\\mathrm{swap}}$ 是最佳单点交换（1-swap）阶段的预言机调用次数。\n- 报告每个测试用例的 $\\Delta$ 和 $\\varrho$。\n\n测试套件：\n- 用例 $1$：$n = 4$, $m = 6$, $k = 3$，其中\n$$\nW^{(1)} \\;=\\; \\begin{bmatrix}\n5  5  5  5  5  5 \\\\\n10  10  0  0  0  0 \\\\\n0  0  9  9  0  0 \\\\\n0  0  0  0  9  9\n\\end{bmatrix}.\n$$\n- 用例 $2$：$n = 4$, $m = 4$, $k = 2$，其中所有行相同，\n$$\nW^{(2)} \\;=\\; \\begin{bmatrix}\n3  3  3  3 \\\\\n3  3  3  3 \\\\\n3  3  3  3 \\\\\n3  3  3  3\n\\end{bmatrix}.\n$$\n- 用例 $3$：$n = 4$, $m = 5$, $k = 2$，其中\n$$\nW^{(3)} \\;=\\; \\begin{bmatrix}\n5  5  5  5  5 \\\\\n10  10  0  0  0 \\\\\n0  0  9  9  0 \\\\\n0  0  0  0  9\n\\end{bmatrix}.\n$$\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按顺序包含用例 $1$、用例 $2$、用例 $3$ 的配对 $[\\Delta,\\varrho]$，并展开成一个单一列表。具体来说，输出\n$$\n[\\Delta^{(1)},\\varrho^{(1)},\\Delta^{(2)},\\varrho^{(2)},\\Delta^{(3)},\\varrho^{(3)}].\n$$\n- 所有报告的值必须是实数（浮点数）。不得打印任何其他文本。",
            "solution": "The user wants to analyze the performance of a greedy algorithm and a subsequent local search improvement step for the facility location problem, which is a classic example of maximizing a monotone submodular function under a cardinality constraint.\n\n### Step 1: Problem Validation\n\n**1. Extraction of Givens**\n\n- **Ground Set**: A finite set $\\mathcal{V} = \\{0, 1, \\dots, n-1\\}$.\n- **Weight Matrix**: A non-negative matrix $W \\in \\mathbb{R}_{\\ge 0}^{n \\times m}$.\n- **Objective Function**: For any subset $S \\subseteq \\mathcal{V}$, the facility location objective is $f(S) = \\sum_{j=0}^{m-1} \\max_{i \\in S} W_{i,j}$, with $f(\\varnothing) = 0$.\n- **Constraint**: The chosen subset $S$ must have a fixed cardinality, $|S|=k$.\n- **Foundations**: The function $f$ is stated to be monotone and submodular.\n- **Greedy Algorithm**:\n    - Start with $S_0 = \\varnothing$.\n    - For $t=1, \\dots, k$, select $x_t \\in \\mathcal{V} \\setminus S_{t-1}$ that maximizes the marginal gain $f(S_{t-1} \\cup \\{x\\}) - f(S_{t-1})$.\n    - Tie-breaking: Among maximizers, pick the one with the smallest index. The resulting set is $S_{\\mathrm{greedy}}$.\n- **Single Best 1-Swap Algorithm**:\n    - Given $S_{\\mathrm{greedy}}$, consider all pairs $(a,b)$ with $a \\in S_{\\mathrm{greedy}}$ and $b \\in \\mathcal{V} \\setminus S_{\\mathrm{greedy}}$.\n    - Find the pair $(a^\\star, b^\\star)$ that maximizes $f(S_{\\mathrm{greedy}} \\setminus \\{a\\} \\cup \\{b\\})$.\n    - Tie-breaking: Choose the lexicographically smallest pair $(a,b)$.\n    - If $f(S_{\\mathrm{greedy}} \\setminus \\{a^\\star\\} \\cup \\{b^\\star\\}) > f(S_{\\mathrm{greedy}})$, set $S_{\\mathrm{swap}} = S_{\\mathrm{greedy}} \\setminus \\{a^\\star\\} \\cup \\{b^\\star\\}$.\n    - Otherwise, $S_{\\mathrm{swap}} = S_{\\mathrm{greedy}}$.\n- **Cost Model**:\n    - Evaluation of $f(\\cdot)$ is one unit-cost oracle call.\n    - Greedy stage: $f(\\varnothing)$ is not counted. Each candidate set $S \\cup \\{x\\}$ evaluation counts as one call. The value $f(S_t)$ is carried over from the evaluation of the best candidate in step $t$. $E_{\\mathrm{greedy}}$ is the total number of calls.\n    - Swap stage: Each candidate swap set evaluation counts as one call. $E_{\\mathrm{swap}}$ is the total number of calls.\n- **Empirical Evidence Task**:\n    - Compute the improvement $\\Delta = f(S_{\\mathrm{swap}}) - f(S_{\\mathrm{greedy}})$.\n    - Compute the oracle-cost factor $\\varrho = (E_{\\mathrm{greedy}} + E_{\\mathrm{swap}}) / E_{\\mathrm{greedy}}$.\n- **Test Suite**:\n    - Case 1: $n=4, m=6, k=3$, $W^{(1)} = \\begin{bmatrix} 555555 \\\\ 10100000 \\\\ 009900 \\\\ 000099 \\end{bmatrix}$.\n    - Case 2: $n=4, m=4, k=2$, $W^{(2)} = \\begin{bmatrix} 3333 \\\\ 3333 \\\\ 3333 \\\\ 3333 \\end{bmatrix}$.\n    - Case 3: $n=4, m=5, k=2$, $W^{(3)} = \\begin{bmatrix} 55555 \\\\ 1010000 \\\\ 00990 \\\\ 00009 \\end{bmatrix}$.\n- **Output Format**: A single line `[Δ(1),ϱ(1),Δ(2),ϱ(2),Δ(3),ϱ(3)]`.\n\n**2. Validation using Extracted Givens**\n\nThe problem statement is a well-defined exercise in algorithm implementation and analysis within the standard framework of submodular optimization.\n- **Scientifically Grounded**: The problem is based on the facility location function, a canonical example of a monotone submodular function. The algorithms (greedy and local search) are standard, widely studied methods for this class of problems.\n- **Well-Posed**: The problem is specified with complete information. The objective function, algorithms, constraints, and tie-breaking rules are all defined precisely, ensuring a unique, deterministic outcome for each test case.\n- **Objective**: The problem is stated using formal mathematical language and is devoid of any subjective or ambiguous terminology.\n\n**3. Verdict and Action**\n\nThe problem is **valid**. It is self-contained, scientifically sound, and well-posed. I will proceed with the full solution.\n\n### Step 2: Solution Derivation\n\nThe solution requires implementing the facility location objective function, the greedy selection algorithm, and the single best $1$-swap local search procedure. We will apply these to each test case and compute the required metrics, $\\Delta$ and $\\varrho$.\n\n**Objective Function Oracle**\n\nThe function $f(S)$ for a given set $S \\subseteq \\mathcal{V}$ and weight matrix $W$ is $f(S) = \\sum_{j=0}^{m-1} \\max_{i \\in S} W_{i,j}$. An oracle for this function will be implemented to take a set of row indices $S$ and the matrix $W$ as input. If $S$ is empty, it returns $0$. Otherwise, it selects the rows of $W$ corresponding to indices in $S$, finds the maximum value in each column of this submatrix, and returns the sum of these maximums. Each call to this oracle will be counted.\n\n**Greedy Algorithm**\n\nThe greedy algorithm constructs a set $S_{\\mathrm{greedy}}$ of size $k$ iteratively.\n1.  Initialize $S_0 = \\varnothing$ and $f(S_0)=0$.\n2.  For each iteration $t$ from $1$ to $k$:\n    a. Let $S_{t-1}$ be the set from the previous iteration. The set of available elements is $\\mathcal{V} \\setminus S_{t-1}$.\n    b. For each element $x \\in \\mathcal{V} \\setminus S_{t-1}$, calculate the marginal gain $g(x) = f(S_{t-1} \\cup \\{x\\}) - f(S_{t-1})$. This requires $|\\mathcal{V} \\setminus S_{t-1}| = n - (t-1)$ oracle calls.\n    c. Find the maximum gain, $g_{\\max} = \\max_{x \\in \\mathcal{V} \\setminus S_{t-1}} g(x)$.\n    d. Identify the set of maximizers, $X_{\\max} = \\{x \\in \\mathcal{V} \\setminus S_{t-1} | g(x) = g_{\\max}\\}$.\n    e. Apply the tie-breaking rule: select the element $x_t = \\min(X_{\\max})$.\n    f. Update the set $S_t = S_{t-1} \\cup \\{x_t\\}$. The value $f(S_t)$ is known from the evaluation in step 2b and is carried forward.\n\nThe total number of oracle calls for the greedy stage is $E_{\\mathrm{greedy}} = \\sum_{t=1}^{k} (n - (t-1)) = \\sum_{i=0}^{k-1} (n - i) = nk - \\frac{k(k-1)}{2}$.\n\n**Single Best 1-Swap Local Search**\n\nAfter obtaining $S_{\\mathrm{greedy}}$ and $f(S_{\\mathrm{greedy}})$, we perform a single local search improvement step.\n1.  Identify the set of elements to swap in, $B = \\mathcal{V} \\setminus S_{\\mathrm{greedy}}$, and the set of elements to swap out, $A = S_{\\mathrm{greedy}}$.\n2.  For every pair $(a, b)$ where $a \\in A$ and $b \\in B$, form a candidate set $S'_{a,b} = (S_{\\mathrm{greedy}} \\setminus \\{a\\}) \\cup \\{b\\}$.\n3.  Evaluate $f(S'_{a,b})$ for each pair. This requires $|A| \\times |B| = k(n-k)$ oracle calls. This is the value of $E_{\\mathrm{swap}}$.\n4.  Find the maximum objective value achieved by any swap: $f_{\\max} = \\max_{a \\in A, b \\in B} f(S'_{a,b})$.\n5.  If $f_{\\max} \\le f(S_{\\mathrm{greedy}})$, no improvement is found. Set $S_{\\mathrm{swap}} = S_{\\mathrm{greedy}}$ and $f(S_{\\mathrm{swap}}) = f(S_{\\mathrm{greedy}})$.\n6.  If $f_{\\max} > f(S_{\\mathrm{greedy}})$, an improvement exists.\n    a. Identify the set of best pairs: $P_{\\max} = \\{(a,b) | a \\in A, b \\in B, f(S'_{a,b}) = f_{\\max}\\}$.\n    b. Apply the tie-breaking rule: choose the lexicographically smallest pair $(a^\\star, b^\\star)$ from $P_{\\max}$.\n    c. Perform the swap: $S_{\\mathrm{swap}} = (S_{\\mathrm{greedy}} \\setminus \\{a^\\star\\}) \\cup \\{b^\\star\\}$, and set $f(S_{\\mathrm{swap}}) = f_{\\max}$.\n\n**Calculations for Test Cases**\n\nLet's apply this procedure to each case.\n\n**Case 1:** $n=4, k=3$.\n- **Greedy Stage**:\n    - $S_0=\\varnothing, f(S_0)=0$.\n    - Iteration 1: Candidates $\\{0,1,2,3\\}$. $f(\\{0\\})=30, f(\\{1\\})=20, f(\\{2\\})=18, f(\\{3\\})=18$. Max gain from $x_1=0$. $S_1=\\{0\\}, f(S_1)=30$. Calls: $4$.\n    - Iteration 2: Candidates $\\{1,2,3\\}$. $f(\\{0,1\\})=40, f(\\{0,2\\})=38, f(\\{0,3\\})=38$. Max gain from $x_2=1$. $S_2=\\{0,1\\}, f(S_2)=40$. Calls: $3$.\n    - Iteration 3: Candidates $\\{2,3\\}$. $f(\\{0,1,2\\})=48, f(\\{0,1,3\\})=48$. Max gain is a tie. Smallest index is $2$. $x_3=2$. $S_3=\\{0,1,2\\}, f(S_3)=48$. Calls: $2$.\n    - Result: $S_{\\mathrm{greedy}} = \\{0,1,2\\}$, $f(S_{\\mathrm{greedy}}) = 48$. $E_{\\mathrm{greedy}} = 4+3+2=9$.\n- **Swap Stage**:\n    - Swaps $(a,b)$ for $a \\in \\{0,1,2\\}, b \\in \\{3\\}$.\n    - Evaluate $f(\\{1,2,3\\})$ for $(a,b)=(0,3)$: $\\sum \\max(W_{1j},W_{2j},W_{3j}) = 10+10+9+9+9+9=56$.\n    - Evaluate $f(\\{0,2,3\\})$ for $(a,b)=(1,3)$: $\\sum \\max(W_{0j},W_{2j},W_{3j}) = 5+5+9+9+9+9=46$.\n    - Evaluate $f(\\{0,1,3\\})$ for $(a,b)=(2,3)$: $\\sum \\max(W_{0j},W_{1j},W_{3j}) = 10+10+5+5+9+9=48$.\n    - Max value is $56$, for pair $(0,3)$. This is $> 48$.\n    - Result: $S_{\\mathrm{swap}} = \\{1,2,3\\}$, $f(S_{\\mathrm{swap}}) = 56$. $E_{\\mathrm{swap}}=3$.\n- **Metrics**:\n    - $\\Delta^{(1)} = 56 - 48 = 8$.\n    - $\\varrho^{(1)} = (9+3)/9 = 12/9 \\approx 1.3333$.\n\n**Case 2:** $n=4, k=2$. $W$ has all entries equal to $3$. For any $S \\neq \\varnothing, f(S) = \\sum_{j=0}^3 3 = 12$.\n- **Greedy Stage**:\n    - $S_0=\\varnothing, f(S_0)=0$.\n    - Iteration 1: Candidates $\\{0,1,2,3\\}$. $f(\\{0\\})=f(\\{1\\})=f(\\{2\\})=f(\\{3\\})=12$. All have max gain. Tie-break: $x_1=0$. $S_1=\\{0\\}, f(S_1)=12$. Calls: $4$.\n    - Iteration 2: Candidates $\\{1,2,3\\}$. $f(\\{0,1\\})=f(\\{0,2\\})=f(\\{0,3\\})=12$. Gains are all $0$. Tie-break: $x_2=1$. $S_2=\\{0,1\\}, f(S_2)=12$. Calls: $3$.\n    - Result: $S_{\\mathrm{greedy}} = \\{0,1\\}$, $f(S_{\\mathrm{greedy}}) = 12$. $E_{\\mathrm{greedy}} = 4+3=7$.\n- **Swap Stage**:\n    - Swaps $(a,b)$ for $a \\in \\{0,1\\}, b \\in \\{2,3\\}$. Any swap results in a set of size $2$, so its function value is $12$.\n    - Max value is $12$, which is not strictly greater than $f(S_{\\mathrm{greedy}})=12$. No swap is performed.\n    - Result: $S_{\\mathrm{swap}} = S_{\\mathrm{greedy}} = \\{0,1\\}$, $f(S_{\\mathrm{swap}}) = 12$. $E_{\\mathrm{swap}}=k(n-k)=2(4-2)=4$.\n- **Metrics**:\n    - $\\Delta^{(2)} = 12 - 12 = 0$.\n    - $\\varrho^{(2)} = (7+4)/7 = 11/7 \\approx 1.5714$.\n\n**Case 3:** $n=4, k=2$.\n- **Greedy Stage**:\n    - $S_0=\\varnothing, f(S_0)=0$.\n    - Iteration 1: Candidates $\\{0,1,2,3\\}$. $f(\\{0\\})=25, f(\\{1\\})=20, f(\\{2\\})=18, f(\\{3\\})=9$. Max gain from $x_1=0$. $S_1=\\{0\\}, f(S_1)=25$. Calls: $4$.\n    - Iteration 2: Candidates $\\{1,2,3\\}$. $f(\\{0,1\\})=35$ (gain 10), $f(\\{0,2\\})=33$ (gain 8), $f(\\{0,3\\})=29$ (gain 4). Max gain from $x_2=1$. $S_2=\\{0,1\\}, f(S_2)=35$. Calls: $3$.\n    - Result: $S_{\\mathrm{greedy}} = \\{0,1\\}$, $f(S_{\\mathrm{greedy}}) = 35$. $E_{\\mathrm{greedy}} = 4+3=7$.\n- **Swap Stage**:\n    - Swaps $(a,b)$ for $a \\in \\{0,1\\}, b \\in \\{2,3\\}$.\n    - Evaluate $f(\\{1,2\\})$ for $(a,b)=(0,2)$: $10+10+9+9+0 = 38$.\n    - Evaluate $f(\\{1,3\\})$ for $(a,b)=(0,3)$: $10+10+0+0+9=29$.\n    - Evaluate $f(\\{0,2\\})$ for $(a,b)=(1,2)$: $5+5+9+9+5 = 33$.\n    - Evaluate $f(\\{0,3\\})$ for $(a,b)=(1,3)$: $5+5+5+5+9=29$.\n    - Max value is $38$, for pair $(0,2)$. This is $> 35$.\n    - Result: $S_{\\mathrm{swap}} = \\{1,2\\}$, $f(S_{\\mathrm{swap}}) = 38$. $E_{\\mathrm{swap}}=k(n-k)=2(4-2)=4$.\n- **Metrics**:\n    - $\\Delta^{(3)} = 38 - 35 = 3$.\n    - $\\varrho^{(3)} = (7+4)/7 = 11/7 \\approx 1.5714$.\n\nFinal results to be reported:\n$[\\Delta^{(1)}, \\varrho^{(1)}, \\Delta^{(2)}, \\varrho^{(2)}, \\Delta^{(3)}, \\varrho^{(3)}] = [8.0, 1.3333..., 0.0, 1.5714..., 3.0, 1.5714...]$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It orchestrates the execution of algorithms on each test case and prints the final result.\n    \"\"\"\n\n    def f_oracle(S, W):\n        \"\"\"\n        Computes the facility location objective function value f(S).\n        This is the core oracle function.\n        \n        Args:\n            S (set): A subset of the ground set {0, ..., n-1}.\n            W (np.ndarray): The weight matrix.\n            \n        Returns:\n            float: The value of f(S).\n        \"\"\"\n        # The convention is f(emptyset) = 0\n        if not S:\n            return 0.0\n        \n        # Select rows corresponding to indices in S\n        s_list = list(S)\n        \n        # Compute max over selected rows (axis=0) for each column\n        # and sum the results.\n        return np.sum(np.max(W[s_list, :], axis=0))\n\n    def run_case(W, k):\n        \"\"\"\n        Runs the greedy and 1-swap algorithms for a single test case.\n        \n        Args:\n            W (np.ndarray): The n x m weight matrix.\n            k (int): The cardinality constraint.\n            \n        Returns:\n            tuple: A pair (delta, rho) containing the improvement and oracle cost factor.\n        \"\"\"\n        n, _ = W.shape\n        V = set(range(n))\n\n        # ---- Greedy Algorithm ----\n        S_current = set()\n        f_current = 0.0\n        E_greedy = 0\n\n        for _ in range(k):\n            candidates = V - S_current\n            \n            # Store gains and resulting f-values for all candidates\n            candidate_evals = {}\n            for x in candidates:\n                S_candidate = S_current | {x}\n                f_val = f_oracle(S_candidate, W)\n                E_greedy += 1\n                gain = f_val - f_current\n                candidate_evals[x] = {'gain': gain, 'f_val': f_val}\n\n            # Find the maximum gain\n            max_gain = -np.inf\n            if candidate_evals:\n                max_gain = max(v['gain'] for v in candidate_evals.values())\n\n            # Find all elements that achieve the maximum gain\n            maximizers = [x for x, v in candidate_evals.items() if v['gain'] == max_gain]\n            \n            # Tie-break by choosing the smallest index\n            best_x = min(maximizers)\n            \n            # Update the set and its function value\n            S_current.add(best_x)\n            f_current = candidate_evals[best_x]['f_val']\n        \n        S_greedy = S_current\n        f_greedy = f_current\n\n        # ---- Single Best 1-Swap Local Improvement ----\n        E_swap = 0\n        S_outside = V - S_greedy\n        \n        # Store results of all possible 1-swaps\n        swap_evals = {}\n        for a in S_greedy:\n            for b in S_outside:\n                S_candidate = (S_greedy - {a}) | {b}\n                f_val = f_oracle(S_candidate, W)\n                E_swap += 1\n                swap_evals[(a, b)] = f_val\n        \n        # Find the maximum function value among all swaps\n        max_f_swap = -np.inf\n        if swap_evals:\n            max_f_swap = max(swap_evals.values())\n\n        S_swap = S_greedy\n        f_swap = f_greedy\n\n        # Check for strict improvement\n        if max_f_swap > f_greedy:\n            # Find all pairs that achieve the maximum value\n            best_pairs = [pair for pair, val in swap_evals.items() if val == max_f_swap]\n            \n            # Tie-break by lexicographically smallest pair (a,b)\n            best_pairs.sort()\n            a_star, b_star = best_pairs[0]\n            \n            S_swap = (S_greedy - {a_star}) | {b_star}\n            f_swap = max_f_swap\n\n        # ---- Compute Metrics ----\n        delta = f_swap - f_greedy\n        \n        if E_greedy == 0:\n             # handle k=0 case, although not in test suite\n            rho = 1.0 if E_swap == 0 else np.inf\n        else:\n            rho = (E_greedy + E_swap) / E_greedy\n\n        return delta, rho\n\n    # --- Test Suite ---\n    test_cases = [\n        # Case 1\n        (\n            np.array([\n                [5, 5, 5, 5, 5, 5],\n                [10, 10, 0, 0, 0, 0],\n                [0, 0, 9, 9, 0, 0],\n                [0, 0, 0, 0, 9, 9]\n            ]),\n            3\n        ),\n        # Case 2\n        (\n            np.array([\n                [3, 3, 3, 3],\n                [3, 3, 3, 3],\n                [3, 3, 3, 3],\n                [3, 3, 3, 3]\n            ]),\n            2\n        ),\n        # Case 3\n        (\n            np.array([\n                [5, 5, 5, 5, 5],\n                [10, 10, 0, 0, 0],\n                [0, 0, 9, 9, 0],\n                [0, 0, 0, 0, 9]\n            ]),\n            2\n        )\n    ]\n    \n    # --- Run and Collect Results ---\n    results_flat = []\n    for W, k in test_cases:\n        delta, rho = run_case(W, k)\n        results_flat.extend([float(delta), float(rho)])\n\n    # --- Print Final Output ---\n    # Format: [d1,r1,d2,r2,d3,r3]\n    result_str = \",\".join(map(str, results_flat))\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "许多现实世界的优化问题不具备次模性，因而难以高效求解。一种强大的技术是使用一个次模代理目标来近似它们。本练习将指导您证明经典的设施选址函数（facility location function）的次模性，然后通过经验性评估，来验证最大化这个代理目标在多大程度上有助于为相关的非次模 $k$-中位（$k$-median）问题找到高质量的解。",
            "id": "3189779",
            "problem": "考虑一个有限基集 $V = \\{1,2,\\dots,n\\}$ 和一个距离函数 $d: V \\times V \\to \\mathbb{R}_{\\ge 0}$，该函数满足度量公理：对于所有 $i,j,k \\in V$，$d(i,j) = 0$ 当且仅当 $i=j$，$d(i,j) = d(j,i)$，以及 $d(i,k) \\le d(i,j) + d(j,k)$。对于任何大小为 $|S| = k$ 的选择 $S \\subseteq V$，$k$-中位成本由集合函数 $C(S) = \\sum_{j \\in V} \\min_{i \\in S} d(i,j)$ 定义。\n\n定义一个非负相似性矩阵 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$，其条目 $w_{ij}$ 是通过任意固定的非增变换从距离 $d(i,j)$ 获得的，该变换将较大的距离映射到较小或相等的相似性，例如，对于选定的半径 $r > 0$，有 $w_{ij} = \\max(0, r - d(i,j))$。设施选址函数定义为 $f(S) = \\sum_{j \\in V} \\max_{i \\in S} w_{ij}$。\n\n任务1 (理论)：仅从次模性的核心定义和上述定义出发，证明对于任何非负相似性矩阵 $W$，$f(S)$ 是 $2^V$ 上的一个单调次模函数。使用次模性的边际效益递减特性：一个集合函数 $f: 2^V \\to \\mathbb{R}$ 是次模的，如果对于所有 $A \\subseteq B \\subseteq V$ 和 $x \\in V \\setminus B$，都满足 $f(A \\cup \\{x\\}) - f(A) \\ge f(B \\cup \\{x\\}) - f(B)$。同时证明单调性：对于 $A \\subseteq B$，$f(A) \\le f(B)$。\n\n任务2 (算法与实证)：实现一个贪心算法，在基数约束 $|S| = k$ 下最大化设施选址函数。该算法应迭代添加具有最大边际增益 $f(S \\cup \\{x\\}) - f(S)$ 的元素 $x \\in V \\setminus S$，直到 $|S| = k$。使用从欧几里得平面中的点生成的合成度量，将贪心设施选址算法返回的集合 $S$ 的 $k$-中位成本 $C(S)$ 与通过对所有 $\\binom{n}{k}$ 个子集进行穷举搜索得到的最优 $k$-中位解进行比较。通过比率 $R = C(S_{\\mathrm{FL}})/C(S_{\\mathrm{OPT}})$ 来凭经验量化近似质量，其中 $S_{\\mathrm{FL}}$ 是贪心设施选址解，$S_{\\mathrm{OPT}}$ 是精确的 $k$-中位最小化解。不涉及物理单位，也不出现角度，因此不需要单位规范。\n\n测试套件和参数：\n- 在 $\\mathbb{R}^2$ 中使用欧几里得距离，即对于坐标为 $(x_i, y_i)$ 的点，定义 $d(i,j) = \\sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}$。\n- 对于相似性变换，在每种情况下使用指定的 $r$ 值，即 $w_{ij} = \\max(0, r - d(i,j))$。\n- 提供三个测试用例，覆盖正常路径、边界和边缘情况：\n  1. 用例A (正常路径)：$n = 12$，两个分离良好的簇，中心分别靠近 $(0,0)$ 和 $(5,5)$，$k = 2$，$r = 3.0$。\n  2. 用例B (边界情况)：$n = 12$，一个靠近 $(0,0)$ 的单个紧凑簇，$k = 1$，$r = 1.5$。\n  3. 用例C (边缘情况)：$n = 9$，三个中等分离的簇，中心分别靠近 $(0,0)$、$(4,0)$ 和 $(0,4)$，$k = 3$，$r = 2.0$。\n\n程序要求：\n- 程序必须构建指定的合成点集，计算成对距离矩阵 $d(i,j)$，通过 $w_{ij} = \\max(0, r - d(i,j))$ 构建相似性矩阵 $W$，运行贪心设施选址算法以获得 $S_{\\mathrm{FL}}$，计算 $C(S_{\\mathrm{FL}})$，通过穷举搜索计算精确的最优 $k$-中位解 $S_{\\mathrm{OPT}}$ 及其成本 $C(S_{\\mathrm{OPT}})$，然后为每个测试用例计算比率 $R = C(S_{\\mathrm{FL}})/C(S_{\\mathrm{OPT}})$。\n- 您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”），每个结果对应于相应测试用例的比率 $R$。每个结果必须是浮点数。\n- 实现必须是自包含和确定性的，不需要用户输入、外部文件或网络访问。唯一允许的库是 Python 标准库和指定的数值库。确保合成数据集使用固定坐标构建，以便结果在不同运行中是可复现的。",
            "solution": "问题陈述已经过严格验证，被认为是具有科学依据、适定、客观和完整的。它在次模优化这个已建立的领域内提出了一个标准的理论练习和一个受约束的实证任务。这些任务在计算上是可行的，并且参数的指定足以实现一个确定性和可复现的实现。\n\n### **任务1：理论分析**\n\n该任务旨在证明设施选址函数 $f(S)$ 是单调和次模的。该函数定义在基集 $V = \\{1, 2, \\dots, n\\}$ 的子集上，形式为 $f(S) = \\sum_{j \\in V} \\max_{i \\in S} w_{ij}$，其中 $W$ 是一个非负相似性矩阵，$w_{ij} \\ge 0$。\n\n我们可以将函数 $f(S)$ 表示为一些更简单函数的和。对于每个元素 $j \\in V$，我们定义一个函数 $g_j(S): 2^V \\to \\mathbb{R}$ 如下：\n$$\ng_j(S) = \\max_{i \\in S} w_{ij}\n$$\n根据这个定义，设施选址函数可以写成：\n$$\nf(S) = \\sum_{j \\in V} g_j(S)\n$$\n单调性和次模性在非负线性组合下是封闭的。因此，如果我们能证明每个函数 $g_j(S)$ 既是单调的又是次模的，那么 $f(S)$ 也将是单调和次模的，因为它是这些函数的和。按照惯例，非负数空集上的最大值取为 $0$，所以对所有 $j \\in V$ 都有 $g_j(\\emptyset) = 0$，这意味着 $f(\\emptyset) = 0$。\n\n**1. 单调性证明**\n\n如果对于任何子集 $A \\subseteq B \\subseteq V$，都有 $f(A) \\le f(B)$，则函数 $f$ 是单调的。我们将为每个 $g_j(S)$ 证明这一点。\n\n设 $A \\subseteq B \\subseteq V$。对于任何固定的 $j \\in V$，相似性集合 $\\{w_{ij} \\mid i \\in A\\}$ 是 $\\{w_{ij} \\mid i \\in B\\}$ 的一个子集。一个数集的最大值总是小于或等于其任何超集的最大值。因此，\n$$\n\\max_{i \\in A} w_{ij} \\le \\max_{i \\in B} w_{ij}\n$$\n这等价于 $g_j(A) \\le g_j(B)$。由于这个不等式对所有 $j \\in V$ 都成立，对所有 $j$ 求和会保持这个不等式关系：\n$$\n\\sum_{j \\in V} g_j(A) \\le \\sum_{j \\in V} g_j(B)\n$$\n这直接得出 $f(A) \\le f(B)$，从而证明了设施选址函数 $f(S)$ 是单调的。\n\n**2. 次模性证明**\n\n如果一个函数 $f$ 表现出边际效益递减的特性，那么它就是次模的。也就是说，对于任何子集 $A \\subseteq B \\subseteq V$ 和任何元素 $x \\in V \\setminus B$，将 $x$ 添加到较小集合 $A$ 的边际增益大于或等于将其添加到较大集合 $B$ 的边际增益：\n$$\nf(A \\cup \\{x\\}) - f(A) \\ge f(B \\cup \\{x\\}) - f(B)\n$$\n同样，我们首先为每个分量函数 $g_j(S)$ 证明这个性质。对于函数 $g_j$，将一个元素 $x \\notin S$ 添加到集合 $S$ 的边际增益是：\n$$\n\\Delta_{g_j}(x | S) = g_j(S \\cup \\{x\\}) - g_j(S) = \\max_{i \\in S \\cup \\{x\\}} w_{ij} - \\max_{i \\in S} w_{ij}\n$$\n使用性质 $\\max(a, b) - b = \\max(0, a-b)$，我们可以将边际增益重写为：\n$$\n\\Delta_{g_j}(x | S) = \\max(w_{xj}, \\max_{i \\in S} w_{ij}) - \\max_{i \\in S} w_{ij} = \\max(0, w_{xj} - \\max_{i \\in S} w_{ij})\n$$\n现在，设 $A \\subseteq B \\subseteq V$ 且 $x \\in V \\setminus B$。根据我们刚刚证明的 $g_j$ 的单调性，我们知道 $g_j(A) \\le g_j(B)$，这意味着：\n$$\n\\max_{i \\in A} w_{ij} \\le \\max_{i \\in B} w_{ij}\n$$\n让我们分析函数 $h(z) = \\max(0, c - z)$，其中 $c$ 为某个常数。这个函数对其参数 $z$ 是非增的。设 $c = w_{xj}$。那么集合 $A$ 和 $B$ 的边际增益可以写成：\n$$\n\\Delta_{g_j}(x | A) = \\max(0, w_{xj} - \\max_{i \\in A} w_{ij})\n$$\n$$\n\\Delta_{g_j}(x | B) = \\max(0, w_{xj} - \\max_{i \\in B} w_{ij})\n$$\n由于 $\\max_{i \\in A} w_{ij} \\le \\max_{i \\in B} w_{ij}$ 并且函数 $h(z)$ 是非增的，可以得出：\n$$\n\\max(0, w_{xj} - \\max_{i \\in A} w_{ij}) \\ge \\max(0, w_{xj} - \\max_{i \\in B} w_{ij})\n$$\n这就建立了 $\\Delta_{g_j}(x | A) \\ge \\Delta_{g_j}(x | B)$。因为这对每个 $j \\in V$ 都成立，将所有 $j$ 的边际增益求和得到：\n$$\n\\sum_{j \\in V} \\Delta_{g_j}(x | A) \\ge \\sum_{j \\in V} \\Delta_{g_j}(x | B)\n$$\n认识到 $\\Delta_f(x | S) = \\sum_{j \\in V} \\Delta_{g_j}(x | S)$，我们有 $\\Delta_f(x | A) \\ge \\Delta_f(x | B)$，这正是次模性条件。这就完成了证明：对于任何非负相似性矩阵 $W$，$f(S)$ 是一个单调次模函数。\n\n### **任务2：算法与实证分析**\n\n实证任务要求将贪心最大化设施选址函数得到的解与 $k$-中位问题的最优解进行比较。\n\n**算法设计**\n\n1.  **贪心设施选址 (FL) 算法**：为了找到在基数约束 $|S|=k$ 下最大化 $f(S)$ 的一个好解 $S_{\\mathrm{FL}}$，我们使用标准的贪心算法。已知该算法为最大化单调次模函数提供了一个 $(1 - 1/e)$-近似。\n    - 初始化解集 $S$ 为空。\n    - 重复 $k$ 次：\n        - 对于每个不在 $S$ 中的元素 $x$，计算边际增益 $\\Delta_f(x|S) = f(S \\cup \\{x\\}) - f(S)$。\n        - 选择提供最大边际增益的元素 $x^*$。\n        - 将 $x^*$ 添加到 $S$ 中。\n    - 最终的集合 $S$ 就是我们的解，$S_{\\mathrm{FL}}$。\n\n2.  **最优k-中位算法**：为了找到最小化 $k$-中位成本 $C(S) = \\sum_{j \\in V} \\min_{i \\in S} d(i,j)$ 的真正最优中心集 $S_{\\mathrm{OPT}}$，我们执行穷举搜索。\n    - 生成 $V$ 中所有大小为 $k$ 的可能子集。这样的子集数量为 $\\binom{n}{k}$。\n    - 对于每个子集，计算其 $k$-中位成本 $C(S)$。\n    - 成本最小的子集就是最优解 $S_{\\mathrm{OPT}}$，其成本为 $C(S_{\\mathrm{OPT}})$。\n\n**实现计划**\n\n实现遵循问题规范。使用硬编码的坐标构建合成数据集以确保可复现性。对于每个测试用例：\n1.  定义 $\\mathbb{R}^2$ 中的一个包含 $n$ 个点的集合。\n2.  计算成对欧几里得距离矩阵 $D$，其中 $d_{ij} = d(i,j)$。\n3.  使用变换 $w_{ij} = \\max(0, r - d_{ij})$ 计算相似性矩阵 $W$。\n4.  运行贪心设施选址算法以产生集合 $S_{\\mathrm{FL}}$。\n5.  使用距离矩阵 $D$ 计算该集合的 $k$-中位成本 $C(S_{\\mathrm{FL}})$。\n6.  执行穷举搜索以找到最优的 $k$-中位成本 $C(S_{\\mathrm{OPT}})$。\n7.  计算并存储比率 $R = C(S_{\\mathrm{FL}}) / C(S_{\\mathrm{OPT}})$。该比率量化了设施选址代理目标在为 $k$-中位问题寻找一个好解方面的表现。接近 $1.0$ 的比率表示高质量。\n\n最终程序为三个指定的测试用例实现了这一逻辑，并输出所得的比率。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # Define the test cases with fixed coordinates for reproducibility.\n    test_cases = [\n        {\n            \"name\": \"Case A (happy path)\",\n            \"n\": 12, \"k\": 2, \"r\": 3.0,\n            \"points\": np.array([\n                # Cluster 1 (near (0,0))\n                [0.1, 0.2], [-0.3, 0.1], [0.0, -0.4], [0.5, 0.3], [-0.2, -0.2], [0.4, -0.1],\n                # Cluster 2 (near (5,5))\n                [5.1, 5.2], [4.8, 5.3], [5.0, 4.7], [5.5, 5.1], [4.9, 4.8], [5.2, 5.5]\n            ])\n        },\n        {\n            \"name\": \"Case B (boundary case)\",\n            \"n\": 12, \"k\": 1, \"r\": 1.5,\n            \"points\": np.array([\n                # Single compact cluster near (0,0)\n                [0.1, 0.2], [-0.3, 0.1], [0.0, -0.4], [0.5, 0.3], [-0.2, -0.2], [0.4, -0.1],\n                [-0.5, 0.5], [0.6, -0.6], [0.2, 0.7], [-0.1, -0.5], [0.8, 0.0], [-0.6, 0.0]\n            ])\n        },\n        {\n            \"name\": \"Case C (edge case)\",\n            \"n\": 9, \"k\": 3, \"r\": 2.0,\n            \"points\": np.array([\n                # Cluster 1 (near (0,0))\n                [0.1, 0.1], [-0.2, 0.0], [0.0, -0.3],\n                # Cluster 2 (near (4,0))\n                [4.1, 0.2], [3.8, -0.1], [4.0, 0.0],\n                # Cluster 3 (near (0,4))\n                [0.1, 4.1], [-0.1, 3.9], [0.2, 4.3]\n            ])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        ratio = run_case(case)\n        results.append(ratio)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_k_median_cost(S, D):\n    \"\"\"Calculates the k-median cost C(S) for a given set S and distance matrix D.\"\"\"\n    if not S:\n        return np.inf\n    # For each point j, find the minimum distance to a center in S.\n    min_distances = np.min(D[S, :], axis=0)\n    return np.sum(min_distances)\n\ndef run_case(case_params):\n    \"\"\"\n    Runs a single test case: computes S_FL via greedy algorithm, S_OPT via\n    exhaustive search, and returns the ratio of their k-median costs.\n    \"\"\"\n    points = case_params[\"points\"]\n    n = case_params[\"n\"]\n    k = case_params[\"k\"]\n    r = case_params[\"r\"]\n\n    # Compute pairwise Euclidean distance matrix D\n    D = cdist(points, points, 'euclidean')\n\n    # Compute similarity matrix W\n    W = np.maximum(0, r - D)\n\n    # --- Greedy Algorithm for Facility Location ---\n    S_fl = []\n    candidates = list(range(n))\n    # Keep track of the maximum similarity from S_fl to each point j\n    current_max_sim = np.zeros(n)\n\n    for _ in range(k):\n        best_gain = -1.0\n        best_candidate = -1\n        \n        for x in candidates:\n            # Efficiently calculate marginal gain: sum(max(0, w_xj - max_sim_j))\n            gains_vector = np.maximum(0, W[x, :] - current_max_sim)\n            gain = np.sum(gains_vector)\n\n            if gain > best_gain:\n                best_gain = gain\n                best_candidate = x\n\n        if best_candidate != -1:\n            S_fl.append(best_candidate)\n            candidates.remove(best_candidate)\n            # Update the vector of maximum similarities\n            current_max_sim = np.maximum(current_max_sim, W[best_candidate, :])\n\n    # Calculate the k-median cost of the greedy facility location solution\n    C_fl = calculate_k_median_cost(S_fl, D)\n\n    # --- Exhaustive Search for Optimal k-Median ---\n    min_C_opt = np.inf\n    S_opt = None\n\n    for s_candidate_tuple in combinations(range(n), k):\n        s_candidate = list(s_candidate_tuple)\n        c_val = calculate_k_median_cost(s_candidate, D)\n        if c_val  min_C_opt:\n            min_C_opt = c_val\n            S_opt = s_candidate\n    \n    C_opt = min_C_opt\n    \n    # --- Compute the approximation ratio ---\n    if C_opt == 0:\n        # This case should not happen with the given test data,\n        # but as a safeguard, if the optimal cost is 0, the greedy\n        # solution should also be optimal.\n        return 1.0 if C_fl == 0 else np.inf\n        \n    ratio = C_fl / C_opt\n    return ratio\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "虽然许多应用涉及单调目标函数，但大量重要问题（例如涉及惩罚项或多样性的问题）本质上是非单调的。本练习挑战您在更一般化的划分拟阵（partition matroid）约束下，解决非单调次模最大化问题。通过在精心设计的实例上实现并比较贪心启发式算法与局部搜索算法，您将亲身体会它们在更广阔的优化领域中各自的优势与局限。",
            "id": "3189759",
            "problem": "给定一个有限组合优化实例族，它结合了非单调子模目标和拟阵约束。您的任务是实现并比较一个贪心算法和一个局部搜索算法，并构建特定实例来展示每种算法在何种情况下优于另一种。所有数学符号、变量、常数和数字都必须按照标准代数意义进行解释。\n\n基本概念：\n- 一个集合函数 $f: 2^{V} \\to \\mathbb{R}$ 如果对于所有 $A \\subseteq B \\subseteq V$ 和所有 $e \\in V \\setminus B$，都满足收益递减性质 $f(A \\cup \\{e\\}) - f(A) \\ge f(B \\cup \\{e\\}) - f(B)$，则称其为子模函数。\n- 拟阵是一个序对 $(V, \\mathcal{I})$，其中 $V$ 是一个有限基集，$\\mathcal{I} \\subseteq 2^{V}$ 是一个非空的独立集集合，满足遗传性和交换性质。划分拟阵通过将 $V$ 划分为不相交的部分，并为每个部分可选择的元素数量设置一个上限而产生。\n\n问题设置：\n- 基集：$V = \\{0,1,2,3\\}$。\n- 划分拟阵：元素通过一个映射 $g: V \\to \\{0,1\\}$ 分配到不同的部分，容量分别为 $b(0) = 1$ 和 $b(1) = 1$。因此，一个可行集 $S$ 必须对于每个部分 $p \\in \\{0,1\\}$ 满足 $\\lvert \\{i \\in S: g(i) = p\\} \\rvert \\le b(p)$。\n- 非单调子模目标：对于一个子集 $S \\subseteq V$，定义\n$$\nf(S) = \\sum_{i \\in S} w_i \\;-\\; \\sum_{\\{i,j\\} \\subseteq S} c_{ij},\n$$\n其中 $w_i \\in \\mathbb{R}$ 是物品权重，$c_{ij} \\in \\mathbb{R}_{\\ge 0}$ 是对称成对惩罚项，满足 $c_{ij} = c_{ji}$ 和 $c_{ii} = 0$。请注意，第二个求和是针对 $i \\ne j$ 的无序对 $\\{i,j\\}$。因为所有 $c_{ij} \\ge 0$，所以函数 $f$ 是子模的，并且通常是非单调的。\n\n需要实现的算法：\n- 贪心算法（最大正边际增益）：初始化 $S \\gets \\emptyset$。重复选择一个元素 $e \\in V \\setminus S$，该元素可被可行地添加（即 $S \\cup \\{e\\} \\in \\mathcal{I}$）并且能最大化边际增益 $\\Delta(e \\mid S) = f(S \\cup \\{e\\}) - f(S)$。通过选择最小索引来打破平局。如果最大边际增益严格为正，则将该元素添加到 $S$ 并继续；否则，停止并返回 $S$。\n- 局部搜索（使用添加/删除/交换的首次改善策略）：初始化 $S \\gets \\emptyset$。重复以下循环直到找不到改进：\n  1. 添加移动：按索引递增顺序扫描 $e \\in V \\setminus S$。如果 $S \\cup \\{e\\} \\in \\mathcal{I}$ 且 $\\Delta(e \\mid S) > 0$，则设置 $S \\gets S \\cup \\{e\\}$ 并重启循环。\n  2. 删除移动：按索引递增顺序扫描 $e \\in S$。如果 $f(S \\setminus \\{e\\}) - f(S) > 0$，则设置 $S \\gets S \\setminus \\{e\\}$ 并重启循环。\n  3. 交换移动：按索引的字典序扫描序对 $(o,i)$，其中 $o \\in S$ 且 $i \\in V \\setminus S$。如果 $(S \\setminus \\{o\\}) \\cup \\{i\\} \\in \\mathcal{I}$ 且 $f((S \\setminus \\{o\\}) \\cup \\{i\\}) - f(S) > 0$，则执行交换 $S \\gets (S \\setminus \\{o\\}) \\cup \\{i\\}$ 并重启循环。\n当循环终止时返回 $S$。\n\n测试套件：\n实现这两种算法，并在以下三个实例上进行评估。在所有情况下，都使用上述指定的索引顺序 $0,1,2,3$ 进行平局处理和扫描。\n\n- 测试用例 1（局部搜索优于贪心算法）：\n  - 分组分配：$g(0) = 0$, $g(1) = 0$, $g(2) = 1$, $g(3) = 1$，容量为 $b(0) = 1$, $b(1) = 1$。\n  - 权重：$(w_0, w_1, w_2, w_3) = (6, 10, 5, 7)$。\n  - 非零惩罚项：$c_{1,2} = 6$, $c_{1,3} = 8$, $c_{0,2} = 2$, $c_{0,3} = 1$。所有其他 $c_{ij} = 0$（当 $i \\ne j$ 时）。\n  - 预期的定性行为：由于任何添加操作的边际增益均为非正，贪心算法会以单个元素停止，而局部搜索可以通过交换达到一个严格更优的双元素解。\n\n- 测试用例 2（由于首次改善策略陷入困境，贪心算法优于局部搜索）：\n  - 分组分配：$g(0) = 0$, $g(1) = 0$, $g(2) = 1$, $g(3) = 1$，容量为 $b(0) = 1$, $b(1) = 1$。\n  - 权重：$(w_0, w_1, w_2, w_3) = (7, 9, 7, 9)$。\n  - 非零惩罚项：$c_{1,3} = 4$, $c_{0,2} = 4$, $c_{1,2} = 8$, $c_{0,3} = 8$。所有其他 $c_{ij} = 0$（当 $i \\ne j$ 时）。\n  - 预期的定性行为：贪心算法构建了一个高价值的兼容对，而采用首次改善策略的局部搜索锁定在一个低价值的兼容对上，并且无法执行非改进的中间交换，因此陷入困境。\n\n- 测试用例 3（具有非正单元素值的边界情况）：\n  - 分组分配：$g(0) = 0$, $g(1) = 0$, $g(2) = 1$, $g(3) = 1$，容量为 $b(0) = 1$, $b(1) = 1$。\n  - 权重：$(w_0, w_1, w_2, w_3) = (-1, -2, -3, -1)$。\n  - 所有惩罚项 $c_{ij} = 0$（当 $i \\ne j$ 时）。\n  - 预期的定性行为：两种算法都返回值为 $0$ 的空集。\n\n要求的计算和输出：\n- 对于每个测试用例 $t \\in \\{1,2,3\\}$，计算 $S_{\\mathrm{greedy}}^{(t)}$ 和 $S_{\\mathrm{LS}}^{(t)}$，然后计算值 $f(S_{\\mathrm{greedy}}^{(t)})$ 和 $f(S_{\\mathrm{LS}}^{(t)})$，最后计算整数差\n$$\nd^{(t)} = f(S_{\\mathrm{LS}}^{(t)}) - f(S_{\\mathrm{greedy}}^{(t)}).\n$$\n- 您的程序应生成单行输出，其中包含三个结果，形式为包含在方括号中的逗号分隔列表（例如，$\\;[d^{(1)},d^{(2)},d^{(3)}]\\;$）。输出必须是整数，不含额外的空格或文本。\n\n不涉及物理单位或角度。所有输出均为纯整数。确保所有算法步骤都完全按照规定遵守拟阵独立性约束，并在两种算法中都使用严格为正的改进移动来继续进行。",
            "solution": "该问题要求实现和比较一个贪心算法和一个局部搜索算法，用于解决一个在划分拟阵约束下的非单调子模最大化问题。我们必须在三个特定实例上评估这些算法，并计算它们所达到的目标值的差异。\n\n基集为 $V = \\{0, 1, 2, 3\\}$。对于给定的集合 $S \\subseteq V$，目标函数为 $f(S) = \\sum_{i \\in S} w_i - \\sum_{\\{i,j\\} \\subseteq S, i \\ne j} c_{ij}$，其中 $w_i$ 是权重，$c_{ij} \\ge 0$ 是对称惩罚项。函数 $f$ 是子模的。\n\n约束是一个划分拟阵 $(V, \\mathcal{I})$，由将 $V$ 划分为两个部分 $P_0$ 和 $P_1$ 定义，容量分别为 $b(0)=1$ 和 $b(1)=1$。一个集合 $S$ 是独立的，即 $S \\in \\mathcal{I}$，如果它从每个部分中最多包含一个元素。对于所有测试用例，划分为 $P_0 = \\{i \\in V \\mid g(i)=0\\} = \\{0, 1\\}$ 和 $P_1 = \\{i \\in V \\mid g(i)=1\\} = \\{2, 3\\}$。\n\n我们现在通过追踪两种算法的执行过程来分析每个测试用例。\n\n### 测试用例 1\n\n**实例参数：**\n- 权重：$(w_0, w_1, w_2, w_3) = (6, 10, 5, 7)$。\n- 非零惩罚项：$c_{1,2} = 6$, $c_{1,3} = 8$, $c_{0,2} = 2$, $c_{0,3} = 1$。\n\n**贪心算法追踪：**\n1. 初始化 $S = \\emptyset$，所以 $f(S) = 0$。\n2. **迭代 1：** 我们为每个 $e \\in V$ 计算边际增益 $\\Delta(e \\mid \\emptyset) = f(\\{e\\}) - f(\\emptyset) = w_e$：\n    - $\\Delta(0 \\mid \\emptyset) = w_0 = 6$。\n    - $\\Delta(1 \\mid \\emptyset) = w_1 = 10$。\n    - $\\Delta(2 \\mid \\emptyset) = w_2 = 5$。\n    - $\\Delta(3 \\mid \\emptyset) = w_3 = 7$。\n    最大增益为 $10$，对应元素 $e=1$。因为 $10 > 0$，我们更新 $S \\gets \\{1\\}$。当前值为 $f(\\{1\\}) = 10$。\n3. **迭代 2：** 当前解为 $S = \\{1\\}$。我们为可行的添加计算边际增益。因为 $g(1)=0$，我们只能从部分 $P_1 = \\{2, 3\\}$ 添加一个元素。\n    - $\\Delta(2 \\mid \\{1\\}) = f(\\{1,2\\}) - f(\\{1\\}) = (w_1+w_2-c_{1,2}) - w_1 = w_2 - c_{1,2} = 5 - 6 = -1$。\n    - $\\Delta(3 \\mid \\{1\\}) = f(\\{1,3\\}) - f(\\{1\\}) = (w_1+w_3-c_{1,3}) - w_1 = w_3 - c_{1,3} = 7 - 8 = -1$。\n    最大边际增益为 $-1$，不严格为正。算法终止。\n\n最终的贪心解为 $S_{\\mathrm{greedy}}^{(1)} = \\{1\\}$，其值为 $f(S_{\\mathrm{greedy}}^{(1)}) = 10$。\n\n**局部搜索算法追踪：**\n1. 初始化 $S = \\emptyset$。开始循环。\n2. **迭代 1：** $S = \\emptyset$，$f(S)=0$。\n    - **添加移动：** 扫描 $e \\in \\{0,1,2,3\\}$。对于 $e=0$，$f(\\{0\\}) = 6 > f(\\emptyset)$。这是一个有效的首次改善。\n    - 更新 $S \\gets \\{0\\}$。重启循环。\n3. **迭代 2：** $S = \\{0\\}$，$f(S)=6$。\n    - **添加移动：** 扫描 $e \\in \\{1,2,3\\}$。$e=1$ 不可行（$g(0)=g(1)=0$）。对于 $e=2$，$S \\cup \\{2\\} = \\{0,2\\}$ 是可行的。$f(\\{0,2\\}) = w_0+w_2-c_{0,2} = 6+5-2=9$。增益为 $9-6=3>0$。这是一个有效的首次改善。\n    - 更新 $S \\gets \\{0,2\\}$。重启循环。\n4. **迭代 3：** $S = \\{0,2\\}$，$f(S)=9$。\n    - **添加移动：** 无法添加任何元素。\n    - **删除移动：** 删除 $0$ 得到 $f(\\{2\\})=5  9$。删除 $2$ 得到 $f(\\{0\\})=6  9$。没有改进。\n    - **交换移动：** 按字典序扫描序对 $(o, i)$，其中 $o \\in \\{0,2\\}$ 且 $i \\in \\{1,3\\}$。\n        - $(0,1)$：交换到 $\\{1,2\\}$。$g$ 分配为：$g(0)=0, g(1)=0, g(2)=1, g(3)=1$。用 $1$ 交换 $0$ 得到 $\\{1,2\\}$，这是可行的。$f(\\{1,2\\}) = w_1+w_2-c_{1,2} = 10+5-6=9$。变化为 $9-9=0$。没有改进。\n        - $(0,3)$：交换到 $\\{2,3\\}$。可行。$f(\\{2,3\\}) = w_2+w_3-c_{2,3} = 5+7-0=12$。增益为 $12-9=3 > 0$。这是一个有效的首次改善。\n    - 更新 $S \\gets \\{2,3\\}$。重启循环。\n5. **迭代 4：** $S = \\{2,3\\}$，$f(S)=12$。\n    - **添加/删除移动：** 未找到改进。（删除 $2$ 得到 $f(\\{3\\})=712$；删除 $3$ 得到 $f(\\{2\\})=512$）。\n    - **交换移动：** 扫描序对 $(o,i)$，其中 $o \\in \\{2,3\\}, i \\in \\{0,1\\}$。\n        - $(2,0)$：交换到 $\\{0,3\\}$，可行。$f(\\{0,3\\}) = w_0+w_3-c_{0,3} = 6+7-1=12$。变化为 $0$。\n        - $(2,1)$：交换到 $\\{1,3\\}$，可行。$f(\\{1,3\\}) = w_1+w_3-c_{1,3} = 10+7-8=9$。变化为 $9-12  0$。\n        - $(3,0)$：交换到 $\\{0,2\\}$，可行。$f(\\{0,2\\}) = w_0+w_2-c_{0,2} = 6+5-2=9$。变化为 $9-12  0$。\n        - $(3,1)$：交换到 $\\{1,2\\}$，可行。$f(\\{1,2\\}) = w_1+w_2-c_{1,2} = 10+5-6=9$。变化为 $9-12  0$。\n    - 未找到改进移动。算法终止。\n\n最终的局部搜索解为 $S_{\\mathrm{LS}}^{(1)} = \\{2,3\\}$，其值为 $f(S_{\\mathrm{LS}}^{(1)}) = 12$。\n差异为 $d^{(1)} = f(S_{\\mathrm{LS}}^{(1)}) - f(S_{\\mathrm{greedy}}^{(1)}) = 12 - 10 = 2$。\n\n### 测试用例 2\n\n**实例参数：**\n- 权重：$(w_0, w_1, w_2, w_3) = (7, 9, 7, 9)$。\n- 非零惩罚项：$c_{1,3} = 4$, $c_{0,2} = 4$, $c_{1,2} = 8$, $c_{0,3} = 8$。\n\n**贪心算法追踪：**\n1. 初始化 $S = \\emptyset$，$f(S) = 0$。\n2. **迭代 1：** 计算边际增益 $\\Delta(e \\mid \\emptyset) = w_e$：\n    - $\\Delta(0 \\mid \\emptyset) = 7$。\n    - $\\Delta(1 \\mid \\emptyset) = 9$。\n    - $\\Delta(2 \\mid \\emptyset) = 7$。\n    - $\\Delta(3 \\mid \\emptyset) = 9$。\n    最大增益为 $9$，由元素 $1$ 和 $3$ 实现。平局规则选择最小索引，即 $e=1$。更新 $S \\gets \\{1\\}$，$f(\\{1\\}) = 9$。\n3. **迭代 2：** 当前解 $S = \\{1\\}$。可行的添加来自 $P_1 = \\{2,3\\}$。\n    - $\\Delta(2 \\mid \\{1\\}) = w_2 - c_{1,2} = 7 - 8 = -1$。\n    - $\\Delta(3 \\mid \\{1\\}) = w_3 - c_{1,3} = 9 - 4 = 5$。\n    最大增益为 $5$，对应元素 $e=3$。因为 $5>0$，更新 $S \\gets \\{1,3\\}$。值为 $f(\\{1,3\\}) = w_1+w_3-c_{1,3} = 9+9-4=14$。\n4. **迭代 3：** 当前解 $S=\\{1,3\\}$。无法再添加元素。算法终止。\n\n最终的贪心解为 $S_{\\mathrm{greedy}}^{(2)} = \\{1,3\\}$，其值为 $f(S_{\\mathrm{greedy}}^{(2)}) = 14$。\n\n**局部搜索算法追踪：**\n1. 初始化 $S = \\emptyset$。开始循环。\n2. **迭代 1：** $S = \\emptyset$，$f(S)=0$。\n    - **添加移动：** 扫描 $e \\in \\{0,1,2,3\\}$。对于 $e=0$，$f(\\{0\\})=7 > 0$。首次改善。\n    - 更新 $S \\gets \\{0\\}$。重启循环。\n3. **迭代 2：** $S = \\{0\\}$，$f(S)=7$。\n    - **添加移动：** 扫描 $e \\in \\{1,2,3\\}$。$e=1$ 不可行。对于 $e=2$，$S \\cup \\{2\\}=\\{0,2\\}$ 是可行的。$f(\\{0,2\\}) = w_0+w_2-c_{0,2} = 7+7-4=10$。增益为 $10-7=3>0$。首次改善。\n    - 更新 $S \\gets \\{0,2\\}$。重启循环。\n4. **迭代 3：** $S = \\{0,2\\}$，$f(S)=10$。\n    - **添加/删除移动：** 未找到改进。（删除 $0$ 得到 $f(\\{2\\})=710$；删除 $2$ 得到 $f(\\{0\\})=710$）。\n    - **交换移动：** 按字典序扫描序对。$S=\\{0,2\\}$，$V \\setminus S = \\{1,3\\}$。\n        - $(0,1)$：交换到 $\\{1,2\\}$。可行。$f(\\{1,2\\}) = w_1+w_2-c_{1,2} = 9+7-8=8$。变化为 $8-100$。\n        - $(0,3)$：交换到 $\\{2,3\\}$。不可行（$g(2)=1, g(3)=1$）。\n        - $(2,1)$：交换到 $\\{0,1\\}$。不可行（$g(0)=0, g(1)=0$）。\n        - $(2,3)$：交换到 $\\{0,3\\}$。可行。$f(\\{0,3\\}) = w_0+w_3-c_{0,3} = 7+9-8=8$。变化为 $8-100$。\n    - 未找到改进移动。算法终止。\n\n最终的局部搜索解为 $S_{\\mathrm{LS}}^{(2)} = \\{0,2\\}$，其值为 $f(S_{\\mathrm{LS}}^{(2)}) = 10$。\n差异为 $d^{(2)} = f(S_{\\mathrm{LS}}^{(2)}) - f(S_{\\mathrm{greedy}}^{(2)}) = 10 - 14 = -4$。\n\n### 测试用例 3\n\n**实例参数：**\n- 权重：$(w_0, w_1, w_2, w_3) = (-1, -2, -3, -1)$。\n- 非零惩罚项：所有 $c_{ij}=0$。\n\n**贪心算法追踪：**\n1. 初始化 $S = \\emptyset$，$f(S)=0$。\n2. **迭代 1：** 计算边际增益 $\\Delta(e \\mid \\emptyset) = w_e$：\n    - $\\Delta(0 \\mid \\emptyset) = -1$。\n    - $\\Delta(1 \\mid \\emptyset) = -2$。\n    - $\\Delta(2 \\mid \\emptyset) = -3$。\n    - $\\Delta(3 \\mid \\emptyset) = -1$。\n    最大增益为 $-1$，不严格为正。算法终止。\n\n最终的贪心解为 $S_{\\mathrm{greedy}}^{(3)} = \\emptyset$，其值为 $f(S_{\\mathrm{greedy}}^{(3)}) = 0$。\n\n**局部搜索算法追踪：**\n1. 初始化 $S = \\emptyset$。开始循环。\n2. **迭代 1：** $S = \\emptyset$，$f(S)=0$。\n    - **添加移动：** 所有单元素集合的值都为负，所以对于所有 $e$，$f(\\{e\\})  f(\\emptyset)$。没有改进的添加移动。\n    - **删除/交换移动：** 不适用，因为 $S$ 是空的。\n    - 未找到改进移动。算法终止。\n\n最终的局部搜索解为 $S_{\\mathrm{LS}}^{(3)} = \\emptyset$，其值为 $f(S_{\\mathrm{LS}}^{(3)}) = 0$。\n差异为 $d^{(3)} = f(S_{\\mathrm{LS}}^{(3)}) - f(S_{\\mathrm{greedy}}^{(3)}) = 0 - 0 = 0$。\n\n### 差异总结\n\n- $d^{(1)} = 2$\n- $d^{(2)} = -4$\n- $d^{(3)} = 0$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares greedy and local search algorithms for a submodular\n    maximization problem under a partition matroid constraint.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (local search > greedy)\n        {\n            \"g\": [0, 0, 1, 1],\n            \"b\": [1, 1],\n            \"w\": [6, 10, 5, 7],\n            \"c_raw\": {(1, 2): 6, (1, 3): 8, (0, 2): 2, (0, 3): 1},\n        },\n        # Test case 2 (greedy > local search)\n        {\n            \"g\": [0, 0, 1, 1],\n            \"b\": [1, 1],\n            \"w\": [7, 9, 7, 9],\n            \"c_raw\": {(1, 3): 4, (0, 2): 4, (1, 2): 8, (0, 3): 8},\n        },\n        # Test case 3 (boundary case)\n        {\n            \"g\": [0, 0, 1, 1],\n            \"b\": [1, 1],\n            \"w\": [-1, -2, -3, -1],\n            \"c_raw\": {},\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        V = set(range(4))\n        w = np.array(case[\"w\"])\n        g = case[\"g\"]\n        b = case[\"b\"]\n        C = np.zeros((4, 4))\n        for (i, j), val in case[\"c_raw\"].items():\n            C[i, j] = C[j, i] = val\n\n        def f(S, w_vec, C_mat):\n            \"\"\"Calculates the objective function f(S).\"\"\"\n            if not S:\n                return 0\n            s_list = list(S)\n            val = np.sum(w_vec[s_list])\n            penalty = 0\n            for i in range(len(s_list)):\n                for j in range(i + 1, len(s_list)):\n                    penalty += C_mat[s_list[i], s_list[j]]\n            return val - penalty\n\n        def is_independent(S, g_map, b_caps):\n            \"\"\"Checks if a set S is independent under the partition matroid.\"\"\"\n            part_counts = [0] * len(b_caps)\n            for e in S:\n                part_idx = g_map[e]\n                part_counts[part_idx] += 1\n            for part_idx, count in enumerate(part_counts):\n                if count > b_caps[part_idx]:\n                    return False\n            return True\n\n        def greedy_algorithm(V_set, w_vec, C_mat, g_map, b_caps):\n            S = set()\n            while True:\n                best_e = -1\n                max_gain = -np.inf\n                \n                # Iterate through candidates sorted by index for tie-breaking\n                candidates = sorted(list(V_set - S))\n                for e in candidates:\n                    S_prime = S | {e}\n                    if is_independent(S_prime, g_map, b_caps):\n                        gain = f(S_prime, w_vec, C_mat) - f(S, w_vec, C_mat)\n                        if gain > max_gain:\n                            max_gain = gain\n                            best_e = e\n                \n                if best_e != -1 and max_gain > 0:\n                    S.add(best_e)\n                else:\n                    break\n            return S\n\n        def local_search_algorithm(V_set, w_vec, C_mat, g_map, b_caps):\n            S = set()\n            while True:\n                current_f_S = f(S, w_vec, C_mat)\n                improved = False\n\n                # 1. Add moves\n                add_candidates = sorted(list(V_set - S))\n                for e in add_candidates:\n                    S_prime = S | {e}\n                    if is_independent(S_prime, g_map, b_caps):\n                        if f(S_prime, w_vec, C_mat) - current_f_S > 0:\n                            S = S_prime\n                            improved = True\n                            break\n                if improved:\n                    continue\n\n                # 2. Delete moves\n                delete_candidates = sorted(list(S))\n                for e in delete_candidates:\n                    S_prime = S - {e}\n                    if f(S_prime, w_vec, C_mat) - current_f_S > 0:\n                        S = S_prime\n                        improved = True\n                        break\n                if improved:\n                    continue\n\n                # 3. Swap moves\n                o_candidates = sorted(list(S))\n                i_candidates = sorted(list(V_set - S))\n                swap_pairs = []\n                for o in o_candidates:\n                    for i in i_candidates:\n                        swap_pairs.append((o, i))\n                \n                for o, i in swap_pairs:\n                    S_prime = (S - {o}) | {i}\n                    if is_independent(S_prime, g_map, b_caps):\n                        if f(S_prime, w_vec, C_mat) - current_f_S > 0:\n                            S = S_prime\n                            improved = True\n                            break\n                if improved:\n                    continue\n\n                # No improvement found in a full pass\n                break\n\n            return S\n\n        S_greedy = greedy_algorithm(V, w, C, g, b)\n        f_greedy = f(S_greedy, w, C)\n        \n        S_ls = local_search_algorithm(V, w, C, g, b)\n        f_ls = f(S_ls, w, C)\n\n        diff = f_ls - f_greedy\n        results.append(int(diff))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}