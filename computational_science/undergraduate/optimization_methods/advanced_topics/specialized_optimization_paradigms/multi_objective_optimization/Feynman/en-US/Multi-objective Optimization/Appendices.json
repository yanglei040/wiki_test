{
    "hands_on_practices": [
        {
            "introduction": "This problem provides a foundational exercise in multi-objective optimization. By working with simple quadratic functions, you will derive the Pareto front from first principles using the weighted-sum scalarization technique. This practice will solidify your understanding of how the trade-off between conflicting objectives can be mathematically characterized and will introduce you to the hypervolume indicator, a common metric for evaluating the quality of Pareto front approximations. ",
            "id": "3154179",
            "problem": "Consider the bi-objective minimization problem in one decision variable $x \\in \\mathbb{R}$ with objectives $f_{1}(x) = (x - 1)^{2} + 1$ and $f_{2}(x) = (x + 1)^{2} + 1$. The task is to characterize the trade-off between these two objectives using first principles from multi-objective optimization. \n\nStarting from the definition of Pareto optimality and the principle that, for convex problems, minimizing a positively weighted sum of objectives generates Pareto-optimal points, use the Weighted Sum (WS) scalarization $J_{\\alpha}(x) = \\alpha f_{1}(x) + (1 - \\alpha) f_{2}(x)$ for a weight $\\alpha \\in [0, 1]$ to derive analytically the parametric form of the Pareto front in objective space. Your derivation must begin from first-order optimality conditions for convex functions and the definition of Pareto dominance.\n\nNext, consider the Hypervolume (HV) indicator for a finite set in objective space under minimization, defined as the Lebesgue measure of the region weakly dominated by the set and bounded above by a reference point that is strictly worse (componentwise larger) than every point in the set. Let the reference point be $r = (6, 6)$, and for each $\\alpha \\in [0, 1]$, let $x^{\\star}(\\alpha)$ be a minimizer of $J_{\\alpha}(x)$. Treat the singleton set $\\{(f_{1}(x^{\\star}(\\alpha)), f_{2}(x^{\\star}(\\alpha)))\\}$ as the approximation of the Pareto front at weight $\\alpha$.\n\nUsing only the definitions and first-order conditions described above, derive a closed-form expression for the hypervolume $HV(\\alpha)$ of this singleton set with respect to the reference point $r = (6, 6)$, expressed as a function of $\\alpha$. Provide your final expression for $HV(\\alpha)$ in exact, simplified analytic form. Do not round your answer. The final answer must be a single expression.",
            "solution": "The user wants me to solve a multi-objective optimization problem.\n\n### Step 1: Extract Givens\n- **Decision Variable:** $x \\in \\mathbb{R}$.\n- **Objective Functions (Minimization):**\n  - $f_{1}(x) = (x - 1)^{2} + 1$\n  - $f_{2}(x) = (x + 1)^{2} + 1$\n- **Scalarization Method:** Weighted Sum (WS) $J_{\\alpha}(x) = \\alpha f_{1}(x) + (1 - \\alpha) f_{2}(x)$.\n- **Weight Parameter:** $\\alpha \\in [0, 1]$.\n- **Optimization Principle:** Minimizing the convex scalarization $J_{\\alpha}(x)$ generates Pareto-optimal points. The derivation must use first-order optimality conditions.\n- **Hypervolume (HV) Indicator Definition:** For a finite set in objective space and a reference point $r$, the HV is the Lebesgue measure of the region weakly dominated by the set and bounded above by $r$.\n- **Reference Point:** $r = (6, 6)$.\n- **Set for HV Calculation:** The singleton set $\\{(f_{1}(x^{\\star}(\\alpha)), f_{2}(x^{\\star}(\\alpha)))\\}$, where $x^{\\star}(\\alpha)$ is a minimizer of $J_{\\alpha}(x)$.\n- **Final Task:** Derive a closed-form expression for the hypervolume $HV(\\alpha)$ as a function of $\\alpha$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific or Factual Soundness:** The problem is grounded in the standard theory of multi-objective optimization. The concepts of Pareto optimality, the Weighted Sum method for convex problems, and the Hypervolume indicator are all well-established in the field. The provided functions are simple convex quadratics, which are appropriate for this type of analysis. The problem is scientifically and mathematically sound.\n2.  **Non-Formalizable or Irrelevant:** The problem is highly formal and directly related to the topic of multi-objective optimization.\n3.  **Incomplete or Contradictory Setup:** All necessary information is provided. The objectives, constraints, scalarization method, and reference point are explicitly defined. There are no contradictions.\n4.  **Unrealistic or Infeasible:** The problem is a theoretical exercise; physical realism is not a relevant criterion, but the mathematical setup is perfectly feasible.\n5.  **Ill-Posed or Poorly Structured:** The problem is well-posed. The objective functions are convex, ensuring that the weighted sum has a unique minimizer for any $\\alpha \\in (0,1)$, leading to a well-defined Pareto front and a unique value for $HV(\\alpha)$.\n6.  **Pseudo-Profound, Trivial, or Tautological:** The problem requires a multi-step derivation involving calculus and the application of optimization definitions. It is a substantive exercise, not a trivial or tautological one.\n7.  **Outside Scientific Verifiability:** The derivation and final expression are mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nThe bi-objective minimization problem involves two objective functions: $f_{1}(x) = (x - 1)^{2} + 1$ and $f_{2}(x) = (x + 1)^{2} + 1$. Both functions are convex on $\\mathbb{R}$. The task is to find a parametric representation of the Pareto front using the Weighted Sum (WS) method and then to derive an expression for the Hypervolume indicator as a function of the weight $\\alpha$.\n\nFirst, we define the WS scalarization, which combines the two objectives into a single objective function $J_{\\alpha}(x)$ using a weight $\\alpha \\in [0, 1]$:\n$$J_{\\alpha}(x) = \\alpha f_{1}(x) + (1 - \\alpha) f_{2}(x)$$\nSubstituting the expressions for $f_{1}(x)$ and $f_{2}(x)$:\n$$J_{\\alpha}(x) = \\alpha ((x - 1)^{2} + 1) + (1 - \\alpha) ((x + 1)^{2} + 1)$$\nSince $f_{1}(x)$ and $f_{2}(x)$ are convex functions and $\\alpha \\ge 0$, $1 - \\alpha \\ge 0$, their non-negative weighted sum $J_{\\alpha}(x)$ is also a convex function. For a convex function, the minimum can be found by setting its first derivative with respect to $x$ to zero. This is the first-order optimality condition.\n$$\\frac{dJ_{\\alpha}(x)}{dx} = \\frac{d}{dx} \\left[ \\alpha (x - 1)^{2} + \\alpha + (1 - \\alpha) (x + 1)^{2} + (1 - \\alpha) \\right] = 0$$\n$$\\frac{dJ_{\\alpha}(x)}{dx} = \\alpha [2(x - 1)] + (1 - \\alpha) [2(x + 1)] = 0$$\nDividing by $2$, we get:\n$$\\alpha (x - 1) + (1 - \\alpha) (x + 1) = 0$$\n$$\\alpha x - \\alpha + x + 1 - \\alpha x - \\alpha = 0$$\n$$x + 1 - 2\\alpha = 0$$\nSolving for $x$, we find the optimal decision variable $x^{\\star}$ as a function of $\\alpha$:\n$$x^{\\star}(\\alpha) = 2\\alpha - 1$$\nThis expression gives the Pareto-optimal solution in the decision space for each $\\alpha \\in [0, 1]$. The set of all such solutions, $\\{x | x = 2\\alpha - 1, \\alpha \\in [0, 1]\\}$, corresponds to the interval $[-1, 1]$.\n\nNext, we map these optimal solutions into the objective space to find the Pareto front. The Pareto front is the set of objective vectors $(f_{1}(x^{\\star}(\\alpha)), f_{2}(x^{\\star}(\\alpha)))$ for $\\alpha \\in [0, 1]$. Let's define the point on the Pareto front as $p(\\alpha) = (p_1(\\alpha), p_2(\\alpha))$.\n$$p_1(\\alpha) = f_{1}(x^{\\star}(\\alpha)) = f_{1}(2\\alpha - 1) = ((2\\alpha - 1) - 1)^{2} + 1 = (2\\alpha - 2)^{2} + 1 = 4(\\alpha - 1)^{2} + 1$$\n$$p_2(\\alpha) = f_{2}(x^{\\star}(\\alpha)) = f_{2}(2\\alpha - 1) = ((2\\alpha - 1) + 1)^{2} + 1 = (2\\alpha)^{2} + 1 = 4\\alpha^{2} + 1$$\nThe parametric form of the Pareto front is $(4(\\alpha - 1)^{2} + 1, 4\\alpha^{2} + 1)$ for $\\alpha \\in [0, 1]$.\n\nThe second part of the problem asks for the Hypervolume (HV) indicator of the singleton set $\\{p(\\alpha)\\}$ with respect to the reference point $r = (6, 6)$. The HV, in this two-dimensional case, corresponds to the area of the hyperrectangle formed by the point $p(\\alpha)$ and the reference point $r$.\nThe formula for the HV of a point $(p_1, p_2)$ with respect to a reference point $(r_1, r_2)$ is:\n$$HV = (r_1 - p_1)(r_2 - p_2)$$\nWe must first verify that the reference point $r = (6, 6)$ strictly dominates all points on the Pareto front.\nFor $\\alpha \\in [0, 1]$, the maximum value of $p_1(\\alpha) = 4(\\alpha - 1)^{2} + 1$ occurs at $\\alpha = 0$, giving $p_1(0) = 5$. The maximum value of $p_2(\\alpha) = 4\\alpha^{2} + 1$ occurs at $\\alpha = 1$, giving $p_2(1) = 5$. Thus, for any point $(p_1, p_2)$ on the front, $p_1 \\le 5$ and $p_2 \\le 5$. Since $r_1=6$ and $r_2=6$, the reference point is indeed a valid upper bound.\n\nNow, we compute $HV(\\alpha)$ as a function of $\\alpha$:\n$$HV(\\alpha) = (6 - p_1(\\alpha))(6 - p_2(\\alpha))$$\nWe need to express $p_1(\\alpha)$ and $p_2(\\alpha)$ as polynomials in $\\alpha$:\n$$p_1(\\alpha) = 4(\\alpha^{2} - 2\\alpha + 1) + 1 = 4\\alpha^{2} - 8\\alpha + 5$$\n$$p_2(\\alpha) = 4\\alpha^{2} + 1$$\nSubstitute these into the HV formula:\n$$HV(\\alpha) = (6 - (4\\alpha^{2} - 8\\alpha + 5))(6 - (4\\alpha^{2} + 1))$$\n$$HV(\\alpha) = (1 + 8\\alpha - 4\\alpha^{2})(5 - 4\\alpha^{2})$$\nNow, we expand the product to obtain a simplified polynomial expression for $HV(\\alpha)$:\n$$HV(\\alpha) = 1(5) + 1(-4\\alpha^{2}) + 8\\alpha(5) + 8\\alpha(-4\\alpha^{2}) - 4\\alpha^{2}(5) - 4\\alpha^{2}(-4\\alpha^{2})$$\n$$HV(\\alpha) = 5 - 4\\alpha^{2} + 40\\alpha - 32\\alpha^{3} - 20\\alpha^{2} + 16\\alpha^{4}$$\nFinally, we collect terms by descending powers of $\\alpha$:\n$$HV(\\alpha) = 16\\alpha^{4} - 32\\alpha^{3} + (-4 - 20)\\alpha^{2} + 40\\alpha + 5$$\n$$HV(\\alpha) = 16\\alpha^{4} - 32\\alpha^{3} - 24\\alpha^{2} + 40\\alpha + 5$$\nThis is the closed-form expression for the hypervolume of the singleton Pareto point approximation as a function of the weight $\\alpha$.",
            "answer": "$$\\boxed{16\\alpha^{4} - 32\\alpha^{3} - 24\\alpha^{2} + 40\\alpha + 5}$$"
        },
        {
            "introduction": "The weighted-sum method is a cornerstone of multi-objective optimization, but it cannot find every optimal solution. This practice uses an intuitive robot path-planning scenario to illustrate the important distinction between supported and unsupported efficient solutions. You will calculate the specific weight that makes two different paths equally optimal, providing insight into the geometry of the objective space and the limitations of linear scalarization in the presence of non-convex trade-offs. ",
            "id": "3154169",
            "problem": "A mobile robot must travel from a start cell to a goal cell in a discretized grid world while jointly minimizing two conflicting objectives: total path length and cumulative collision risk. Formally, consider a $6 \\times 6$ grid with start at $(1,1)$ and goal at $(6,6)$, and restrict motions to unit steps in the positive coordinate directions (right or up). Obstacles are placed so that feasible monotone paths exist, and the environment induces a nonuniform risk field with per-cell risk values $r(i,j) \\ge 0$. For any feasible path $P$, define the two objective functions\n$$\nL(P) = \\text{number of steps along } P, \\qquad R(P) = \\sum_{(i,j) \\in P} r(i,j).\n$$\nThe multi-objective problem is to minimize $(L(P), R(P))$ in the sense of Pareto dominance. Due to obstacle geometry, three archetypal routes emerge with measured objective vectors\n$$\nv_{A} = (L(P_{A}), R(P_{A})) = (10,\\,6), \\quad v_{B} = (L(P_{B}), R(P_{B})) = (12,\\,4), \\quad v_{C} = (L(P_{C}), R(P_{C})) = (11,\\,5.3).\n$$\nThese paths illustrate how obstacles can induce nonconvex trade-offs: $P_{A}$ is a short but riskier corridor, $P_{B}$ is a longer but safer detour, and $P_{C}$ is an intermediate route that balances the two.\n\nConsider the standard linear weighted-sum scalarization\n$$\nf_{w}(P) = w\\,L(P) + (1-w)\\,R(P), \\qquad w \\in [0,1],\n$$\nwhich is a commonly used method to obtain supported efficient solutions in multi-objective optimization.\n\nStarting from the core definitions of Pareto dominance and supported efficiency, determine the unique weight $w \\in [0,1]$ such that $f_{w}(P_{A}) = f_{w}(P_{B})$. Express your final answer as a single real number and round your answer to four significant figures.",
            "solution": "The problem statement is critically examined and deemed valid. It is scientifically grounded within the established principles of multi-objective optimization, specifically concerning path planning problems. The problem is well-posed, providing all necessary definitions, data, and constraints required to determine a unique solution. The language is objective and the setup is internally consistent and free from factual or logical flaws.\n\nThe core of the problem is to find the weighting factor $w$ that makes two distinct paths, $P_A$ and $P_B$, equally preferable under a linear weighted-sum scalarization scheme. The two objective functions to be minimized are the path length $L(P)$ and the cumulative risk $R(P)$. The scalarized objective function, $f_w(P)$, combines these two objectives into a single value:\n$$f_{w}(P) = w\\,L(P) + (1-w)\\,R(P)$$\nwhere the weight $w$ is constrained to the interval $w \\in [0,1]$. A larger $w$ prioritizes minimizing path length, while a smaller $w$ prioritizes minimizing risk.\n\nThe objective vectors for the two paths in question, $P_A$ and $P_B$, are provided:\n- Path $P_A$ has an objective vector $(L(P_A), R(P_A)) = (10, 6)$.\n- Path $P_B$ has an objective vector $(L(P_B), R(P_B)) = (12, 4)$.\n\nWe are tasked with finding the specific weight $w$ for which the scalarized cost of path $P_A$ is equal to the scalarized cost of path $P_B$. This condition is expressed by the equation:\n$$f_{w}(P_A) = f_{w}(P_B)$$\n\nSubstituting the definition of the scalarized function into this equality gives:\n$$w\\,L(P_A) + (1-w)\\,R(P_A) = w\\,L(P_B) + (1-w)\\,R(P_B)$$\n\nWe can now insert the specific numerical values for the objective components of each path into this equation:\n$$w(10) + (1-w)(6) = w(12) + (1-w)(4)$$\n\nTo solve for $w$, we first expand the terms on both sides of the equation:\n$$10w + 6 - 6w = 12w + 4 - 4w$$\n\nNext, we combine the terms involving $w$ and the constant terms on each side:\n$$4w + 6 = 8w + 4$$\n\nNow, we rearrange the equation to isolate $w$. We can move all terms with $w$ to one side and the constant terms to the other:\n$$6 - 4 = 8w - 4w$$\n$$2 = 4w$$\n\nFinally, we solve for $w$ by dividing by $4$:\n$$w = \\frac{2}{4} = \\frac{1}{2}$$\n\nThe resulting weight is $w = 0.5$. This value lies within the defined interval $[0,1]$, confirming it is a valid solution within the problem's context.\n\nIn the geometric interpretation of multi-objective optimization, finding a $w$ such that two non-dominated points have the same scalarized value means finding the slope of the line that connects these two points in the objective space. This line is a segment of the boundary of the convex hull of the set of all feasible objective vectors. The points on this segment are known as supported efficient solutions. The existence of path $P_C$ with objective vector $(11, 5.3)$ which, for $w=0.5$, yields a higher cost ($f_{0.5}(P_C) = 0.5 \\times 11 + 0.5 \\times 5.3 = 8.15$, whereas $f_{0.5}(P_A) = f_{0.5}(P_B) = 8$), illustrates that $P_C$ represents an unsupported efficient solution that cannot be found by this linear scalarization method, confirming the \"nonconvex trade-offs\" mentioned in the problem.\n\nThe problem requires the final answer to be rounded to four significant figures. The exact solution is $0.5$. Expressed with four significant figures, this becomes $0.5000$.",
            "answer": "$$\n\\boxed{0.5000}\n$$"
        },
        {
            "introduction": "In real-world applications, objectives often have vastly different scales, such as minimizing cost in thousands of dollars while maximizing a reliability score from $0$ to $1$. This hands-on coding exercise demonstrates how such scale disparities can unintentionally bias the solution selected by a weighted-sum approach. By comparing the outcomes with and without objective normalization, you will discover why this pre-processing step is crucial for making meaningful and balanced decisions in practice. ",
            "id": "3162727",
            "problem": "Consider a two-objective minimization problem with decision variable $x$ and objectives $f_1(x)$ and $f_2(x)$ that are evaluated over a finite candidate set $X$. Pareto dominance is defined componentwise: a decision $x_a$ dominates a decision $x_b$ if and only if $f_i(x_a) \\le f_i(x_b)$ for all $i \\in \\{1,2\\}$ and there exists at least one index $j \\in \\{1,2\\}$ such that $f_j(x_a) < f_j(x_b)$. The Pareto set is the subset of $X$ consisting of all decisions not dominated by any other decision in $X$. Normalization is performed using the componentwise utopia and nadir points computed over the candidate set $X$, namely $z_i^\\text{utopia} = \\min_{x \\in X} f_i(x)$ and $z_i^\\text{nadir} = \\max_{x \\in X} f_i(x)$, and the normalized objectives are defined by\n$$\nf_i'(x) = \\frac{f_i(x) - z_i^\\text{utopia}}{z_i^\\text{nadir} - z_i^\\text{utopia}}, \\quad i \\in \\{1,2\\}.\n$$\nYour task is to study how normalization affects the Pareto set and the selection produced by an equal-weight linear scalarization. For each test case below, you must:\n(1) Construct the candidate set $X$ as specified, and compute $f_1(x)$ and $f_2(x)$ for all $x \\in X$.\n(2) Compute $z_i^\\text{utopia}$ and $z_i^\\text{nadir}$ from the objective values on $X$ and form the normalized objectives $f_i'(x)$ for all $x \\in X$.\n(3) Determine the Pareto set in $X$ using the original objectives $(f_1,f_2)$ and the Pareto set using the normalized objectives $(f_1',f_2')$. Report whether these two Pareto sets are identical, using strict Pareto dominance as defined above.\n(4) Using equal weights $\\mathbf{w} = (1,1)$, compute the minimizers in $X$ of the unnormalized scalarization $g(x) = w_1 f_1(x) + w_2 f_2(x)$ and of the normalized scalarization $g'(x) = w_1 f_1'(x) + w_2 f_2'(x)$. If multiple minimizers exist, select the smallest $x$ among them.\nFor each test case, produce the result as the list $[\\text{pareto\\_equal}, \\text{pareto\\_count}, x^\\star_{\\text{unnorm}}, x^\\star_{\\text{norm}}]$, where $\\text{pareto\\_equal}$ is a boolean indicating whether the Pareto sets are identical, $\\text{pareto\\_count}$ is the integer count of points in the Pareto set (using the original objectives), and $x^\\star_{\\text{unnorm}}$ and $x^\\star_{\\text{norm}}$ are floats giving the selected minimizers of $g$ and $g'$ respectively. Your program should aggregate the results of all test cases into a single line of output containing the results as a comma-separated list enclosed in square brackets, with each test case result itself formatted as a comma-separated list enclosed in square brackets, for example $[[\\dots],[\\dots],[\\dots]]$.\nUse the following three scientifically plausible test cases that highlight different facets of normalization:\nTest Case A (scale disparity with strictly monotonic conflict):\n- Candidate set: $X = \\{0, 0.01, 0.02, \\dots, 1.00\\}$.\n- Objectives: $f_1(x) = 1000 x$, $f_2(x) = 1 - \\sqrt{x}$.\nTest Case B (scale disparity with non-monotonic second objective):\n- Candidate set: $X = \\{0, 0.01, 0.02, \\dots, 1.00\\}$.\n- Objectives: $f_1(x) = 1000 x^2$, $f_2(x) = (x - 0.6)^2$.\nTest Case C (coarse grid edge case):\n- Candidate set: $X = \\{0, 0.5, 1.0\\}$.\n- Objectives: $f_1(x) = 1000 x$, $f_2(x) = 1 - x$.\nAll quantities are dimensionless. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[[\\text{result}_1],[\\text{result}_2],[\\text{result}_3]]$). The results for each test case must follow the format described above and consist only of booleans, integers, and floats.",
            "solution": "The user wants me to analyze a two-objective minimization problem, focusing on the effects of normalization on the Pareto set and on the solution obtained via linear scalarization. The analysis must be performed for three specific test cases.\n\nThe problem is first validated for correctness and solvability.\n\n### Step 1: Extract Givens\n- **Decision Variable**: $x$\n- **Candidate Set**: A finite set $X$.\n- **Objectives**: Two functions to be minimized, $f_1(x)$ and $f_2(x)$.\n- **Pareto Dominance**: A decision $x_a$ dominates $x_b$ if and only if $f_i(x_a) \\le f_i(x_b)$ for all $i \\in \\{1,2\\}$ and there exists at least one index $j \\in \\{1,2\\}$ such that $f_j(x_a) < f_j(x_b)$.\n- **Pareto Set**: The subset of $X$ containing all decisions not dominated by any other decision in $X$.\n- **Normalization**:\n    - Utopia point: $z_i^\\text{utopia} = \\min_{x \\in X} f_i(x)$.\n    - Nadir point: $z_i^\\text{nadir} = \\max_{x \\in X} f_i(x)$.\n    - Normalized objective: $f_i'(x) = \\frac{f_i(x) - z_i^\\text{utopia}}{z_i^\\text{nadir} - z_i^\\text{utopia}}$ for $i \\in \\{1,2\\}$.\n- **Linear Scalarization**:\n    - Weights: $\\mathbf{w} = (w_1, w_2) = (1,1)$.\n    - Unnormalized scalarization: $g(x) = w_1 f_1(x) + w_2 f_2(x)$.\n    - Normalized scalarization: $g'(x) = w_1 f_1'(x) + w_2 f_2'(x)$.\n- **Tie-Breaking Rule**: If multiple minimizers exist for a scalarization, select the one with the smallest value of $x$.\n- **Test Cases**:\n    - **A**: $X = \\{0, 0.01, \\dots, 1.00\\}$, $f_1(x) = 1000 x$, $f_2(x) = 1 - \\sqrt{x}$.\n    - **B**: $X = \\{0, 0.01, \\dots, 1.00\\}$, $f_1(x) = 1000 x^2$, $f_2(x) = (x - 0.6)^2$.\n    - **C**: $X = \\{0, 0.5, 1.0\\}$, $f_1(x) = 1000 x$, $f_2(x) = 1 - x$.\n- **Required Output per Case**: A list $[\\text{pareto\\_equal}, \\text{pareto\\_count}, x^\\star_{\\text{unnorm}}, x^\\star_{\\text{norm}}]$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It deals with standard, well-defined concepts from multi-objective optimization: Pareto dominance, normalization, and linear scalarization. The problem is self-contained, providing all necessary definitions, functions, and data sets. The candidate sets $X$ are finite, and the objective functions are well-behaved over their respective domains, ensuring that the utopia and nadir points are well-defined. The normalization denominators, $z_i^\\text{nadir} - z_i^\\text{utopia}$, are non-zero for all specified test cases, as none of the objective functions are constant over the candidate set $X$. The tie-breaking rule ensures a unique solution for the scalarized minimizations. The problem is well-posed and does not violate any scientific principles or contain logical contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be developed.\n\n### Principle-Based Solution\nThe core task is to analyze how normalization affects Pareto optimality and the outcome of an equal-weight linear scalarization method. We will first establish a theoretical principle regarding the Pareto set and then outline the computational algorithm to determine the required quantities for each test case.\n\n**1. Invariance of the Pareto Set under Normalization**\n\nThe normalization specified is a component-wise affine transformation of the form $f_i'(x) = a_i f_i(x) + b_i$, where:\n$$ a_i = \\frac{1}{z_i^\\text{nadir} - z_i^\\text{utopia}} \\quad \\text{and} \\quad b_i = \\frac{-z_i^\\text{utopia}}{z_i^\\text{nadir} - z_i^\\text{utopia}} $$\nFor a non-constant objective function over the candidate set $X$, we have $z_i^\\text{nadir} > z_i^\\text{utopia}$, which implies $a_i > 0$. An affine transformation with a positive scaling factor ($a_i > 0$) is strictly increasing.\n\nLet's examine how this transformation affects the Pareto dominance relation. Suppose a decision $x_a$ dominates a decision $x_b$ in the original objective space. By definition:\n1. $f_i(x_a) \\le f_i(x_b)$ for $i \\in \\{1,2\\}$.\n2. $f_j(x_a) < f_j(x_b)$ for at least one $j \\in \\{1,2\\}$.\n\nSince $a_i > 0$, we can multiply the inequalities by $a_i$ without changing their direction:\n1. $a_i f_i(x_a) \\le a_i f_i(x_b)$ for $i \\in \\{1,2\\}$.\n2. $a_j f_j(x_a) < a_j f_j(x_b)$ for at least one $j \\in \\{1,2\\}$.\n\nAdding the constant $b_i$ to both sides also preserves the inequalities:\n1. $a_i f_i(x_a) + b_i \\le a_i f_i(x_b) + b_i \\implies f_i'(x_a) \\le f_i'(x_b)$ for $i \\in \\{1,2\\}$.\n2. $a_j f_j(x_a) + b_j < a_j f_j(x_b) + b_j \\implies f_j'(x_a) < f_j'(x_b)$ for at least one $j \\in \\{1,2\\}$.\n\nThis shows that $x_a$ dominates $x_b$ in the normalized objective space. The reverse implication holds by the same logic. Therefore, the dominance relations are identical for the original and normalized objectives. Consequently, the set of non-dominated solutions—the Pareto set—is invariant under this normalization. This means the boolean value for `pareto_equal` will be `True` for all test cases.\n\n**2. Algorithmic Procedure**\n\nFor each test case, the following procedure is executed:\n- **Step 2.1: Evaluation.** The candidate set $X$ is generated. For each $x \\in X$, the objective vectors $\\mathbf{f}(x) = (f_1(x), f_2(x))$ are computed and stored.\n- **Step 2.2: Pareto Set Identification.** The Pareto set is identified by pairwise comparison. For each candidate solution $x_i$, it is compared against every other candidate $x_j$. If any $x_j$ dominates $x_i$ (according to the definition), $x_i$ is marked as dominated. The set of all candidates not marked as dominated constitutes the Pareto set. The size of this set is `pareto_count`.\n- **Step 2.3: Normalization.** The utopia and nadir points, $z_i^\\text{utopia}$ and $z_i^\\text{nadir}$, are found by taking the minimum and maximum of the evaluated objective values for each objective $i \\in \\{1,2\\}$. The normalized objectives $f_i'(x)$ are then calculated for all $x \\in X$. As established, this does not alter the Pareto set.\n- **Step 2.4: Scalarization and Minimization.** The unnormalized and normalized scalarized objective functions are computed for all $x \\in X$:\n$$ g(x) = f_1(x) + f_2(x) $$\n$$ g'(x) = f_1'(x) + f_2'(x) $$\nThe minimum value of each function, $\\min_{x \\in X} g(x)$ and $\\min_{x \\in X} g'(x)$, is found. The set of all $x$ values that achieve this minimum is identified. According to the tie-breaking rule, the smallest $x$ from this set is selected as the minimizer, yielding $x^\\star_{\\text{unnorm}}$ and $x^\\star_{\\text{norm}}$.\n\n**3. Application to Test Cases**\n\n- **Test Case A**: $f_1(x) = 1000 x$ and $f_2(x) = 1 - \\sqrt{x}$. On $X = \\{0, 0.01, \\dots, 1.00\\}$, $f_1(x)$ is strictly increasing while $f_2(x)$ is strictly decreasing. This creates a direct conflict, meaning no solution dominates another. The entire set $X$ of $101$ points is the Pareto set. The large scale of $f_1$ dominates the unnormalized scalarization $g(x) = 1000x + 1 - \\sqrt{x}$, pushing its minimum towards $x=0$. After normalization, the objectives $f_1'(x) = x$ and $f_2'(x) = 1 - \\sqrt{x}$ are on a comparable scale. The minimum of $g'(x) = x + 1 - \\sqrt{x}$ is found at $x=0.25$.\n- **Test Case B**: $f_1(x) = 1000 x^2$ and $f_2(x) = (x - 0.6)^2$. For $x \\in [0, 0.6]$, $f_1(x)$ increases while $f_2(x)$ decreases, forming a Pareto front. For $x > 0.6$, both $f_1(x)$ and $f_2(x)$ increase, so any solution with $x > 0.6$ is dominated by the solution at $x=0.6$. The Pareto set is thus $\\{0, 0.01, \\dots, 0.60\\}$, containing $61$ points. The unnormalized scalarization $g(x)$ is again dominated by the high-magnitude $f_1$ term, placing the minimum at $x=0$. Normalization balances the scales, and the minimum of the normalized scalarization $g'(x)$ is found near the analytical minimum of $x \\approx 0.441$, which corresponds to $x=0.44$ on the discrete grid.\n- **Test Case C**: $f_1(x) = 1000 x$ and $f_2(x) = 1 - x$ on the coarse grid $X=\\{0, 0.5, 1.0\\}$. The points are $(0,1)$, $(500, 0.5)$, and $(1000,0)$. All three are mutually non-dominating, so the Pareto set has $3$ points. The unnormalized scalarization $g(x) = 999x + 1$ is minimized at $x=0$. The normalization perfectly balances the objectives, yielding $f_1'(x)=x$ and $f_2'(x)=1-x$. The normalized scalarization becomes $g'(x) = x + (1-x) = 1$, which is constant for all $x \\in X$. All three points are minimizers. The tie-breaking rule selects the smallest $x$, so $x^\\star_{\\text{norm}} = 0$.\n\nThis analysis provides the basis for the computational implementation that follows.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multi-objective optimization problem for three test cases.\n    \"\"\"\n\n    def find_pareto_indices(objectives: np.ndarray) -> set:\n        \"\"\"\n        Identifies the indices of Pareto optimal solutions in a set.\n\n        Args:\n            objectives: An (n_candidates, n_objectives) numpy array of objective values.\n\n        Returns:\n            A set of integer indices corresponding to the Pareto optimal solutions.\n        \"\"\"\n        num_candidates = objectives.shape[0]\n        is_dominated = np.zeros(num_candidates, dtype=bool)\n\n        for i in range(num_candidates):\n            # Check if candidate i is dominated by any other candidate j\n            for j in range(num_candidates):\n                if i == j:\n                    continue\n                \n                # Strict Pareto dominance check:\n                # j dominates i if f_k(j) <= f_k(i) for all objectives k\n                # and f_k(j) < f_k(i) for at least one objective k.\n                if np.all(objectives[j] <= objectives[i]) and np.any(objectives[j] < objectives[i]):\n                    is_dominated[i] = True\n                    break  # i is dominated, no need to check other j's\n\n        pareto_indices = np.where(~is_dominated)[0]\n        return set(pareto_indices)\n\n    def process_case(x_values: np.ndarray, f1_func: callable, f2_func: callable) -> list:\n        \"\"\"\n        Performs the full analysis for a single test case.\n\n        Args:\n            x_values: 1D numpy array of decision variable candidates.\n            f1_func: The first objective function.\n            f2_func: The second objective function.\n\n        Returns:\n            A list containing [pareto_equal, pareto_count, x_star_unnorm, x_star_norm].\n        \"\"\"\n        # (1) Compute objectives for all candidates\n        f1_values = f1_func(x_values)\n        f2_values = f2_func(x_values)\n        objectives = np.vstack([f1_values, f2_values]).T\n\n        # (2) Compute normalized objectives\n        z1_utopia, z1_nadir = np.min(f1_values), np.max(f1_values)\n        z2_utopia, z2_nadir = np.min(f2_values), np.max(f2_values)\n\n        # The problem statement ensures denominators are non-zero for these test cases.\n        denom1 = z1_nadir - z1_utopia if z1_nadir > z1_utopia else 1.0\n        denom2 = z2_nadir - z2_utopia if z2_nadir > z2_utopia else 1.0\n\n        f1_prime = (f1_values - z1_utopia) / denom1\n        f2_prime = (f2_values - z2_utopia) / denom2\n        normalized_objectives = np.vstack([f1_prime, f2_prime]).T\n\n        # (3) Determine Pareto sets and compare\n        original_pareto_indices = find_pareto_indices(objectives)\n        # As proven, normalization does not change the Pareto set.\n        # We can computationally verify this, but it must be true.\n        normalized_pareto_indices = find_pareto_indices(normalized_objectives)\n        \n        pareto_equal = (original_pareto_indices == normalized_pareto_indices)\n        pareto_count = len(original_pareto_indices)\n        \n        # (4) Compute minimizers of scalarizations (w = [1, 1])\n        # Unnormalized scalarization\n        g = f1_values + f2_values\n        min_g = np.min(g)\n        min_g_indices = np.where(np.isclose(g, min_g))[0]\n        # Tie-breaking: select smallest x\n        x_star_unnorm = x_values[min_g_indices[0]]\n\n        # Normalized scalarization\n        g_prime = f1_prime + f2_prime\n        min_g_prime = np.min(g_prime)\n        min_g_prime_indices = np.where(np.isclose(g_prime, min_g_prime))[0]\n        # Tie-breaking: select smallest x\n        x_star_norm = x_values[min_g_prime_indices[0]]\n\n        return [pareto_equal, pareto_count, float(x_star_unnorm), float(x_star_norm)]\n\n    # Define the test cases from the problem statement.\n    test_cases_defs = [\n        {\n            \"x_values\": np.linspace(0, 1.0, 101, dtype=float),\n            \"f1\": lambda x: 1000.0 * x,\n            \"f2\": lambda x: 1.0 - np.sqrt(x)\n        },\n        {\n            \"x_values\": np.linspace(0, 1.0, 101, dtype=float),\n            \"f1\": lambda x: 1000.0 * x**2,\n            \"f2\": lambda x: (x - 0.6)**2\n        },\n        {\n            \"x_values\": np.array([0.0, 0.5, 1.0], dtype=float),\n            \"f1\": lambda x: 1000.0 * x,\n            \"f2\": lambda x: 1.0 - x\n        }\n    ]\n\n    results = []\n    for case_def in test_cases_defs:\n        result = process_case(case_def[\"x_values\"], case_def[\"f1\"], case_def[\"f2\"])\n        results.append(result)\n    \n    # Format the results into a single string as specified\n    result_str = \"[\" + \",\".join([f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in results]) + \"]\"\n\n    # Final print statement in the exact required format.\n    print(result_str)\n\nsolve()\n```"
        }
    ]
}