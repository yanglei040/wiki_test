{
    "hands_on_practices": [
        {
            "introduction": "This first practice provides a foundational comparison between first-order (gradient descent) and second-order (Newton's) methods in a simple, one-dimensional setting. By applying these algorithms to a carefully chosen nonconvex function, you will directly observe the trade-offs between them: the slower, more reliable convergence of gradient descent versus the rapid local convergence but potential failure of Newton's method in regions of unfavorable curvature. This exercise is designed to build your core intuition about basins of attraction and how local landscape properties dictate algorithm behavior .",
            "id": "3145146",
            "problem": "Consider the task of minimizing a nonconvex scalar function using two methods: gradient descent with backtracking line search and Newton’s method with backtracking line search. The base concepts and definitions you must use are: the definition of local and global minima, the notion of gradient and Hessian for differentiable functions, and the first- and second-order Taylor approximations. A point $x^{\\star}$ is a local minimum if there exists a neighborhood around $x^{\\star}$ such that for all $x$ in that neighborhood, $f(x^{\\star}) \\leq f(x)$. A global minimum $x^{\\mathrm{glob}}$ satisfies $f(x^{\\mathrm{glob}}) \\leq f(x)$ for all $x$ in the domain. The gradient descent method is derived from the first-order Taylor approximation, and Newton’s method is derived from the second-order Taylor approximation.\n\nYou must implement both methods on the scalar function\n$$\nf(x) = (x^2 - 1)^2 + 0.3\\,x,\n$$\nwith gradient\n$$\n\\nabla f(x) = 4x^3 - 4x + 0.3,\n$$\nand Hessian\n$$\n\\nabla^2 f(x) = 12x^2 - 4.\n$$\nThe backtracking line search must enforce the Armijo sufficient decrease condition: for a trial step $x_{k+1} = x_k + \\alpha p_k$, accept $x_{k+1}$ if\n$$\nf(x_{k+1}) \\leq f(x_k) + c\\,\\alpha\\,\\nabla f(x_k)\\,p_k,\n$$\nwith $c \\in (0,1)$ fixed. Use $c = 10^{-4}$ and a shrinkage factor $\\rho = 0.5$ for the backtracking line search. For gradient descent, use the search direction $p_k = -\\nabla f(x_k)$. For Newton’s method, use the one-dimensional Newton direction $p_k = -\\nabla f(x_k)/\\nabla^2 f(x_k)$ whenever $\\nabla^2 f(x_k) \\neq 0$. If the Newton direction is not a descent direction, that is, if $\\nabla f(x_k)\\,p_k \\geq 0$, then declare the Newton method to have failed at $x_k$ due to the local curvature guiding the method toward the wrong basin, and do not proceed further from that initial condition.\n\nYour program must:\n- Implement both methods exactly as specified, with a maximum of $100$ iterations and a termination tolerance $\\varepsilon = 10^{-8}$ on the gradient norm, that is, stop when $|\\nabla f(x_k)| \\leq \\varepsilon$.\n- Determine the set of stationary points by solving $\\nabla f(x) = 0$ exactly via polynomial root finding of the cubic equation $4x^3 - 4x + 0.3 = 0$, classify minima using the sign of $\\nabla^2 f(x)$, and identify the global minimum among the minima by comparing their function values.\n- For each run, determine whether the method converged, the number of iterations used, the final point $x_{\\mathrm{final}}$, and whether the final value $f(x_{\\mathrm{final}})$ matches the global minimum value within a tolerance of $10^{-8}$.\n\nTest Suite:\nRun both methods from the following initial points:\n- $x_0 = -0.2$ (tests nonconvex curvature near the origin),\n- $x_0 = 0.8$ (tests attraction toward the shallow local basin on the right),\n- $x_0 = -0.8$ (tests attraction toward the deeper global basin on the left).\n\nOutput Specification:\nFor each initial point, produce a list with the following five entries:\n- a boolean indicating whether Newton’s method reached the global minimum,\n- a boolean indicating whether gradient descent reached the global minimum,\n- a boolean indicating whether Newton’s method required strictly fewer iterations than gradient descent (declare this boolean as false if Newton’s method failed to produce a step),\n- an integer with the number of iterations used by Newton’s method (use $0$ if Newton’s method failed immediately),\n- an integer with the number of iterations used by gradient descent.\n\nYour program should produce a single line of output containing the results for the three initial points as a comma-separated list enclosed in square brackets, with no spaces, where each element is the list described above, for example, $[\\,[\\cdots],\\,[\\cdots],\\,[\\cdots]\\,]$ formatted without spaces.",
            "solution": "The problem is valid. It is a well-posed, scientifically grounded exercise in numerical optimization, comparing the behavior of gradient descent and Newton's method on a one-dimensional nonconvex function. All parameters and conditions are clearly specified.\n\nThe core of the problem is to analyze the performance of a first-order method (gradient descent) versus a second-order method (Newton's method) when minimizing the function $f(x) = (x^2 - 1)^2 + 0.3x$. The nonconvex nature of this function, characterized by regions of both positive and negative curvature, is designed to highlight the fundamental differences between these two approaches.\n\nFirst, we must characterize the function $f(x)$ by identifying its stationary points and classifying them. The stationary points are the roots of the gradient $\\nabla f(x) = 4x^3 - 4x + 0.3 = 0$. Using a numerical root-finding algorithm for this cubic polynomial, we find three real roots:\n$x_1^* \\approx -1.03653191$\n$x_2^* \\approx 0.07530320$\n$x_3^* \\approx 0.96122871$\n\nTo classify these stationary points, we use the second-order sufficient condition, which involves evaluating the sign of the Hessian, $\\nabla^2 f(x) = 12x^2 - 4$, at each point.\n- For $x_1^* \\approx -1.0365$: $\\nabla^2 f(x_1^*) = 12(-1.0365)^2 - 4 \\approx 8.89 > 0$. This indicates that $x_1^*$ is a local minimum.\n- For $x_2^* \\approx 0.0753$: $\\nabla^2 f(x_2^*) = 12(0.0753)^2 - 4 \\approx -3.93  0$. This indicates that $x_2^*$ is a local maximum. This region of negative curvature is where Newton's method is expected to fail.\n- For $x_3^* \\approx 0.9612$: $\\nabla^2 f(x_3^*) = 12(0.9612)^2 - 4 \\approx 7.09 > 0$. This indicates that $x_3^*$ is another local minimum.\n\nTo find the global minimum, we compare the function values at the two local minima:\n- $f(x_1^*) \\approx f(-1.0365) = ((-1.0365)^2 - 1)^2 + 0.3(-1.0365) \\approx -0.30546$\n- $f(x_3^*) \\approx f(0.9612) = ((0.9612)^2 - 1)^2 + 0.3(0.9612) \\approx 0.29416$\nSince $f(x_1^*)  f(x_3^*)$, the point $x_1^*$ is the global minimum, and the global minimum value is $f_{\\mathrm{glob}} \\approx -0.30546193$. Any algorithm run will be considered to have found the global minimum if the function value at its final point is within a tolerance of $10^{-8}$ of this value.\n\nThe optimization algorithms are implemented as follows. Both methods utilize a backtracking line search to ensure sufficient decrease at each step, satisfying the Armijo condition $f(x_{k+1}) \\leq f(x_k) + c\\,\\alpha\\,\\nabla f(x_k)\\,p_k$ with $c = 10^{-4}$ and step-size reduction factor $\\rho = 0.5$. The initial step size is taken to be $\\alpha=1.0$.\n\n**Gradient Descent (GD):** This first-order method uses the negative gradient as its search direction, $p_k = -\\nabla f(x_k)$. This guarantees a descent direction as long as $\\nabla f(x_k) \\neq 0$, since $\\nabla f(x_k) p_k = -(\\nabla f(x_k))^2  0$. GD is robust and will always make progress towards a local minimum, but its convergence rate can be slow.\n\n**Newton's Method (NM):** This second-order method uses the search direction $p_k = -(\\nabla^2 f(x_k))^{-1} \\nabla f(x_k)$. It is derived from a quadratic model of the function. When the Hessian $\\nabla^2 f(x_k)$ is positive definite, the Newton direction is a descent direction, and the method exhibits rapid (quadratic) local convergence. However, if the Hessian is not positive definite (i.e., $\\nabla^2 f(x_k) \\leq 0$ in this 1D case), the direction may not be a descent direction, and the method can be attracted to saddle points or maxima. As per the problem specification, if $\\nabla^2 f(x_k) \\leq 0$ at any iteration $k$, the method is declared to have failed for that initial condition, and the process is terminated for that run. The number of iterations reported is $k$.\n\nThe program will execute both algorithms from each specified initial point ($x_0 \\in \\{-0.2, 0.8, -0.8\\}$), track their performance metrics (convergence status, iterations, final point), and report the results according to the specified output format. This involves comparing the outcomes against the pre-calculated global minimum and comparing the iteration counts between the two methods.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the optimization problem by implementing and comparing\n    gradient descent and Newton's method on a given nonconvex function.\n    \"\"\"\n\n    # --- Problem Definition ---\n    C = 1e-4\n    RHO = 0.5\n    TOL = 1e-8\n    MAX_ITER = 100\n\n    def f(x):\n        return (x**2 - 1)**2 + 0.3 * x\n\n    def grad_f(x):\n        return 4 * x**3 - 4 * x + 0.3\n\n    def hess_f(x):\n        return 12 * x**2 - 4\n\n    # --- Stationary Points and Global Minimum Analysis ---\n    # Solve grad_f(x) = 4x^3 - 4x + 0.3 = 0\n    roots = np.roots([4, 0, -4, 0.3])\n    \n    # Classify roots and find local minima\n    local_minima_x = []\n    for r in roots:\n        # We are only interested in real roots for this 1D problem.\n        if np.isreal(r):\n            if hess_f(np.real(r)) > 0:\n                local_minima_x.append(np.real(r))\n\n    # Find global minimum value by comparing function values at local minima\n    f_values_at_minima = [f(x) for x in local_minima_x]\n    global_min_val = min(f_values_at_minima)\n\n    # --- Core Algorithm Implementations ---\n    def backtracking_line_search(x, p, f, grad_f):\n        alpha = 1.0\n        fx = f(x)\n        grad_fx_p = grad_f(x) * p\n        while f(x + alpha * p) > fx + C * alpha * grad_fx_p:\n            alpha *= RHO\n            if alpha  1e-16: # Prevent infinite loop\n                break\n        return alpha\n\n    def gradient_descent(x0):\n        x = float(x0)\n        for k in range(MAX_ITER):\n            grad = grad_f(x)\n            if abs(grad) = TOL:\n                return x, k, 'converged'\n            \n            p = -grad\n            alpha = backtracking_line_search(x, p, f, grad_f)\n            x = x + alpha * p\n        \n        # Final check after max iterations\n        status = 'converged' if abs(grad_f(x)) = TOL else 'max_iter_reached'\n        return x, MAX_ITER, status\n\n    def newton_method(x0):\n        x = float(x0)\n        for k in range(MAX_ITER):\n            # Check for failure condition (non-positive definite Hessian)\n            hess = hess_f(x)\n            if hess = 0:\n                return x, k, 'failed'\n            \n            grad = grad_f(x)\n            if abs(grad) = TOL:\n                return x, k, 'converged'\n            \n            p = -grad / hess\n            alpha = backtracking_line_search(x, p, f, grad_f)\n            x = x + alpha * p\n            \n        # Final check after max iterations\n        status = 'converged' if abs(grad_f(x)) = TOL else 'max_iter_reached'\n        return x, MAX_ITER, status\n\n    # --- Test Suite Execution ---\n    test_cases = [-0.2, 0.8, -0.8]\n    results = []\n\n    for x0 in test_cases:\n        # Run Gradient Descent\n        x_final_gd, iters_gd, status_gd = gradient_descent(x0)\n        \n        # Run Newton's Method\n        x_final_nm, iters_nm, status_nm = newton_method(x0)\n\n        # --- Evaluate Results ---\n        # 1. Did Newton reach the global minimum?\n        nm_reaches_glob_min = False\n        if status_nm == 'converged' or status_nm == 'max_iter_reached':\n             if abs(f(x_final_nm) - global_min_val) = TOL:\n                 nm_reaches_glob_min = True\n\n        # 2. Did Gradient Descent reach the global minimum?\n        gd_reaches_glob_min = False\n        if status_gd == 'converged' or status_gd == 'max_iter_reached':\n            if abs(f(x_final_gd) - global_min_val) = TOL:\n                gd_reaches_glob_min = True\n        \n        # 3. Did Newton use strictly fewer iterations?\n        nm_fewer_iters = False\n        if status_nm != 'failed':\n            nm_fewer_iters = iters_nm  iters_gd\n        \n        # 4. Number of iterations for Newton\n        iters_nm_out = iters_nm\n        \n        # 5. Number of iterations for Gradient Descent\n        iters_gd_out = iters_gd\n        \n        case_result = [\n            str(nm_reaches_glob_min),\n            str(gd_reaches_glob_min),\n            str(nm_fewer_iters),\n            str(iters_nm_out),\n            str(iters_gd_out)\n        ]\n        results.append(f\"[{','.join(case_result)}]\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the one-dimensional case, this exercise explores a more complex and common challenge in optimization: navigating a narrow, curved valley. You will implement and analyze a function specifically designed to cause standard gradient descent to \"zig-zag\" inefficiently between the valley walls, a classic failure mode for first-order methods. By contrasting this with a curvature-aware Newton-like method, you will gain a practical understanding of why incorporating second-order information is crucial for efficient convergence in anisotropic or poorly-scaled problems .",
            "id": "3145074",
            "problem": "You are given the task of constructing and analyzing a concrete, smooth, two-dimensional function that exhibits zig-zag behavior for gradient descent with Armijo backtracking line search when navigating a narrow valley in a nonconvex landscape. The focus is on identifying local and global optima, demonstrating how a naive first-order method can cycle between valley walls (in the sense of repeatedly alternating the sign of the first coordinate), and proposing curvature-aware updates that mitigate this behavior. The derivation and implementation must be grounded in core definitions from optimization methods.\n\nFundamental base:\n- A point $x^\\star$ is a local minimizer of a differentiable function $f:\\mathbb{R}^n\\to\\mathbb{R}$ if there exists a radius $r>0$ such that $f(x^\\star)\\le f(x)$ for all $x$ with $\\lVert x-x^\\star\\rVert\\le r$. A point $x^\\star$ is a global minimizer if $f(x^\\star)\\le f(x)$ for all $x\\in\\mathbb{R}^n$.\n- For a differentiable function $f$, the first-order necessary condition for local optimality is $\\nabla f(x^\\star)=0$.\n- Gradient descent with Armijo backtracking chooses a direction $d_k=-\\nabla f(x_k)$ and a step size $t_k$ such that $f(x_k+t_k d_k)\\le f(x_k)+c\\,t_k\\,\\nabla f(x_k)^\\top d_k$, where $c\\in(0,1)$ is fixed. A standard backtracking contraction factor $\\tau\\in(0,1)$ reduces $t_k\\leftarrow \\tau t_k$ until the Armijo condition is satisfied.\n- The Hessian matrix $H(x)=\\nabla^2 f(x)$ captures local curvature. Curvature-aware updates precondition the gradient by an approximation of $H(x)^{-1}$, typically with a regularization to ensure positive definiteness.\n\nProblem setup:\n1. Consider the smooth function $f:\\mathbb{R}^2\\to\\mathbb{R}$ defined by\n$$\nf(x,y)=\\left(x^2-1\\right)^2+\\alpha\\,y^2+\\beta\\,\\sin(3y)\\,x+\\gamma\\,\\sin^2(3y),\n$$\nwhere $\\alpha>0$, $\\beta\\in\\mathbb{R}$, $\\gamma\\ge 0$ are fixed parameters. This function has a quartic cross-section in $x$ that forms a valley with nominal walls near $x=\\pm 1$, a shallow quadratic in $y$, and a sinusoidal coupling in $y$ that modulates the valley and can induce alternating lateral forces pushing $x$ towards opposite walls as $y$ evolves.\n\n2. Derive the gradient $\\nabla f(x,y)$ and the Hessian $H(x,y)$ from the above definition only using differentiation rules:\n- The gradient components are\n$$\n\\frac{\\partial f}{\\partial x}(x,y)=4x\\left(x^2-1\\right)+\\beta\\,\\sin(3y),\\quad\n\\frac{\\partial f}{\\partial y}(x,y)=2\\alpha\\,y+3\\beta\\,\\cos(3y)\\,x+6\\gamma\\,\\sin(3y)\\cos(3y).\n$$\n- The Hessian entries are\n$$\n\\frac{\\partial^2 f}{\\partial x^2}(x,y)=12x^2-4,\\quad\n\\frac{\\partial^2 f}{\\partial y^2}(x,y)=2\\alpha-9\\beta\\,\\sin(3y)\\,x+18\\gamma\\,\\cos(6y),\n$$\n$$\n\\frac{\\partial^2 f}{\\partial x\\partial y}(x,y)=\\frac{\\partial^2 f}{\\partial y\\partial x}(x,y)=3\\beta\\,\\cos(3y).\n$$\n\n3. Implement two descent methods using only the above definitions:\n- Method A (first-order): Gradient descent with Armijo backtracking using $d_k=-\\nabla f(x_k,y_k)$, Armijo parameter $c$ fixed to $10^{-4}$, backtracking factor $\\tau$ fixed to $0.5$, and initial step size $t_0=1$.\n- Method B (curvature-aware): A damped Newton-preconditioned step using $d_k=-\\left(H(x_k,y_k)+\\lambda_k I\\right)^{-1}\\nabla f(x_k,y_k)$, with $\\lambda_k$ chosen as $\\lambda_k=\\max\\left\\{0,-\\lambda_{\\min}(H(x_k,y_k))+\\varepsilon\\right\\}$ where $\\lambda_{\\min}(H)$ is the smallest eigenvalue of $H$, $I$ is the identity matrix, and $\\varepsilon$ is a small positive constant (take $\\varepsilon=10^{-3}$). Use the same Armijo parameters for backtracking on this direction.\n\n4. Detect zig-zag cycles: Define a \"wall flip\" as a change in sign of the $x$-coordinate between successive iterates, i.e., $\\operatorname{sign}(x_{k+1})\\neq \\operatorname{sign}(x_k)$ with both $x_{k+1}$ and $x_k$ nonzero. A \"cycle\" is declared if the number of wall flips is at least $K$, where $K=8$. Count wall flips for each method over a fixed iteration budget.\n\n5. Convergence and optima: Identify the global minimizers of $f$ for the parameter ranges used in the tests. Report whether the final iterate is near a global minimizer defined by two criteria simultaneously: distance to the nearest candidate global minimizer at $(1,0)$ or $(-1,0)$ less than a distance threshold $\\delta=10^{-2}$, and function value less than an absolute threshold $\\eta=10^{-6}$.\n\n6. Test suite and output specification:\nUse the following test cases, each specified by the tuple $(\\alpha,\\beta,\\gamma,x_0,y_0,\\text{max\\_iters})$ with all numbers written explicitly:\n- Case $1$: $(0.005,4.0,0.1,0.0,3.0,400)$, expected to show pronounced zig-zag for Method A and fewer flips for Method B.\n- Case $2$: $(0.005,4.0,0.1,0.0,0.2,200)$, starting near the valley floor, expected to show minimal zig-zag.\n- Case $3$: $(0.08,1.0,0.05,0.0,2.4,400)$, milder coupling, expected to show reduced zig-zag.\n- Case $4$: $(0.5,4.0,0.1,0.0,3.0,400)$, stiffer $y$ curvature, expected to damp oscillations.\n\nFor each case, run both Method A and Method B from the same initial point and record the following six values in order:\n- The integer number of wall flips for Method A.\n- The integer number of wall flips for Method B.\n- The final function value for Method A as a float.\n- The final function value for Method B as a float.\n- A boolean indicating whether Method A is in a neighborhood of a global minimum according to the criteria above.\n- A boolean indicating whether Method B is in a neighborhood of a global minimum according to the criteria above.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of the six values in the order specified above. For example, the output should look like\n$[[\\text{case1\\_vals}],[\\text{case2\\_vals}],[\\text{case3\\_vals}],[\\text{case4\\_vals}]]$.\nNo physical units are involved, and no angles or percentages are required. All computations must be performed in $\\mathbb{R}^2$ using real arithmetic.",
            "solution": "The problem requires the construction and analysis of a smooth, two-dimensional function designed to exhibit specific behaviors under first-order and curvature-aware optimization methods. The objective is to implement and compare two algorithms—gradient descent with Armijo backtracking and a damped Newton-preconditioned method—and to quantify their performance in navigating a narrow, non-convex valley. This analysis involves tracking a \"zig-zag\" metric, evaluating an objective function, and checking for convergence to a predefined target region. The problem is well-defined, mathematically sound, and provides all necessary parameters and specifications for a complete solution.\n\nThe function under consideration is $f:\\mathbb{R}^2\\to\\mathbb{R}$, defined as:\n$$\nf(x,y)=\\left(x^2-1\\right)^2+\\alpha\\,y^2+\\beta\\,\\sin(3y)\\,x+\\gamma\\,\\sin^2(3y)\n$$\nwith parameters $\\alpha > 0$, $\\beta \\in \\mathbb{R}$, and $\\gamma \\ge 0$. This function is engineered to possess a valley-like structure. The dominant term, $\\left(x^2-1\\right)^2$, creates a quartic potential with minima at $x=\\pm 1$, forming the walls of a valley aligned with the $y$-axis. The term $\\alpha y^2$ introduces a simple quadratic slope to the valley floor. The term $\\beta \\sin(3y)x$ provides a crucial coupling between the two coordinates, introducing an oscillatory force in the $x$ direction that depends on the position $y$. Finally, the term $\\gamma \\sin^2(3y)$ adds further undulations to the valley floor. For $\\beta \\ne 0$, the true global minimizers are not located at $(\\pm 1, 0)$, as the gradient does not vanish at these points. However, these points serve as reference locations for the bottom of the main valley structure, and the problem defines a specific convergence criterion based on them.\n\nThe analysis is based on two optimization algorithms:\n\n**Method A: Gradient Descent with Armijo Backtracking**\n\nThis is a first-order method where the search direction at each iteration $k$ is the negative gradient, $d_k = -\\nabla f(x_k, y_k)$. The gradient is given by:\n$$\n\\nabla f(x,y) = \\begin{pmatrix} 4x(x^2-1) + \\beta\\sin(3y) \\\\ 2\\alpha y + 3\\beta x\\cos(3y) + 3\\gamma\\sin(6y) \\end{pmatrix}\n$$\nThe step size $t_k$ is determined by an Armijo backtracking line search, starting with an initial guess $t_{k,0}=1$ and reducing it by a factor $\\tau=0.5$ until the condition $f(x_k+t_k d_k) \\le f(x_k) + c\\,t_k\\,\\nabla f(x_k)^\\top d_k$ is met, using the constant $c=10^{-4}$. In a narrow valley where the level sets are elongated and curved, the gradient vector is often almost orthogonal to the direction of the valley floor. Consequently, gradient descent tends to take large steps across the valley, bouncing between its walls, while making only slow progress along the valley. This manifests as the \"zig-zag\" behavior, which is quantified by counting \"wall flips,\" defined as successive iterates $x_k$ and $x_{k+1}$ having opposite signs.\n\n**Method B: Damped Newton-preconditioned Descent**\n\nThis is a curvature-aware method that uses information from the Hessian matrix, $H(x,y) = \\nabla^2 f(x,y)$, to find a more effective search direction. The Hessian is given by:\n$$\nH(x,y) = \\begin{pmatrix}\n12x^2-4  3\\beta\\cos(3y) \\\\\n3\\beta\\cos(3y)  2\\alpha - 9\\beta x\\sin(3y) + 18\\gamma\\cos(6y)\n\\end{pmatrix}\n$$\nThe search direction is computed as $d_k = - (H(x_k,y_k) + \\lambda_k I)^{-1} \\nabla f(x_k,y_k)$, where $I$ is the $2 \\times 2$ identity matrix. The term $\\lambda_k$ is a damping parameter used to ensure that the modified Hessian, $H(x_k,y_k) + \\lambda_k I$, is positive definite, which guarantees that $d_k$ is a descent direction. It is chosen as $\\lambda_k = \\max\\{0, -\\lambda_{\\min}(H(x_k,y_k)) + \\varepsilon\\}$, where $\\lambda_{\\min}(H)$ is the smallest eigenvalue of the Hessian and $\\varepsilon=10^{-3}$ is a small positive constant. By incorporating curvature information, this method effectively rescales the geometry of the problem, allowing the search direction to point more directly towards the minimizer along the valley floor, thereby mitigating the zig-zagging effect. The step size is determined using the same Armijo backtracking procedure as in Method A.\n\nThe implementation will simulate both methods for four distinct test cases, each defined by a set of parameters $(\\alpha, \\beta, \\gamma)$ and an initial point $(x_0, y_0)$. For each run, we will record the total number of wall flips. At the end of the specified number of iterations, we will evaluate the final function value and check for convergence. Convergence is defined by satisfying two conditions simultaneously: the Euclidean distance from the final iterate to the closer of the two points $(1,0)$ and $(-1,0)$ must be less than $\\delta=10^{-2}$, and the final function value must be less than $\\eta=10^{-6}$. The final output will be a structured list containing these six metrics for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the optimization problem for all test cases.\n    Implements and compares gradient descent and a damped Newton method\n    on a specified non-convex function.\n    \"\"\"\n\n    test_cases = [\n        # (alpha, beta, gamma, x0, y0, max_iters)\n        (0.005, 4.0, 0.1, 0.0, 3.0, 400),\n        (0.005, 4.0, 0.1, 0.0, 0.2, 200),\n        (0.08, 1.0, 0.05, 0.0, 2.4, 400),\n        (0.5, 4.0, 0.1, 0.0, 3.0, 400),\n    ]\n\n    # Armijo and convergence parameters\n    C_ARMIJO = 1e-4\n    TAU = 0.5\n    EPSILON = 1e-3\n    DIST_THRESHOLD = 1e-2\n    FUNC_THRESHOLD = 1e-6\n    MINIMIZER_CANDIDATES = [np.array([1.0, 0.0]), np.array([-1.0, 0.0])]\n\n    def f(p, alpha, beta, gamma):\n        x, y = p\n        return (x**2 - 1)**2 + alpha * y**2 + beta * np.sin(3*y) * x + gamma * np.sin(3*y)**2\n\n    def grad_f(p, alpha, beta, gamma):\n        x, y = p\n        df_dx = 4 * x * (x**2 - 1) + beta * np.sin(3*y)\n        df_dy = 2 * alpha * y + 3 * beta * np.cos(3*y) * x + 6 * gamma * np.sin(3*y) * np.cos(3*y)\n        return np.array([df_dx, df_dy])\n\n    def hess_f(p, alpha, beta, gamma):\n        x, y = p\n        d2f_dx2 = 12 * x**2 - 4\n        d2f_dy2 = 2 * alpha - 9 * beta * np.sin(3*y) * x + 18 * gamma * np.cos(6*y)\n        d2f_dxdy = 3 * beta * np.cos(3*y)\n        return np.array([[d2f_dx2, d2f_dxdy], [d2f_dxdy, d2f_dy2]])\n\n    def armijo_backtracking(p, d, grad_p, f_p, alpha, beta, gamma):\n        t = 1.0\n        while True:\n            p_new = p + t * d\n            f_new = f(p_new, alpha, beta, gamma)\n            if f_new = f_p + C_ARMIJO * t * np.dot(grad_p, d):\n                return t\n            t = t * TAU\n\n    def run_method_a(alpha, beta, gamma, x0, y0, max_iters):\n        p = np.array([x0, y0])\n        flips = 0\n        for k in range(max_iters):\n            grad_p = grad_f(p, alpha, beta, gamma)\n            d = -grad_p\n            f_p = f(p, alpha, beta, gamma)\n            \n            t = armijo_backtracking(p, d, grad_p, f_p, alpha, beta, gamma)\n            \n            p_prev = p\n            p = p + t * d\n\n            if np.sign(p_prev[0]) != np.sign(p[0]) and p_prev[0] != 0 and p[0] != 0:\n                flips += 1\n        \n        return p, flips\n\n    def run_method_b(alpha, beta, gamma, x0, y0, max_iters):\n        p = np.array([x0, y0])\n        flips = 0\n        for k in range(max_iters):\n            grad_p = grad_f(p, alpha, beta, gamma)\n            hess_p = hess_f(p, alpha, beta, gamma)\n\n            try:\n                min_eigval = np.linalg.eigvalsh(hess_p).min()\n            except np.linalg.LinAlgError:\n                min_eigval = -1.0 # If something fails, assume non-PD\n\n            lambda_k = max(0, -min_eigval + EPSILON)\n            \n            H_reg = hess_p + lambda_k * np.eye(2)\n            \n            try:\n                d = np.linalg.solve(H_reg, -grad_p)\n            except np.linalg.LinAlgError:\n                # Fallback to gradient descent if regularized Hessian is singular\n                d = -grad_p\n            \n            f_p = f(p, alpha, beta, gamma)\n            t = armijo_backtracking(p, d, grad_p, f_p, alpha, beta, gamma)\n            \n            p_prev = p\n            p = p + t * d\n\n            if np.sign(p_prev[0]) != np.sign(p[0]) and p_prev[0] != 0 and p[0] != 0:\n                flips += 1\n        \n        return p, flips\n\n    results = []\n    for case in test_cases:\n        alpha, beta, gamma, x0, y0, max_iters = case\n        \n        # Method A\n        p_final_a, flips_a = run_method_a(alpha, beta, gamma, x0, y0, max_iters)\n        f_val_a = f(p_final_a, alpha, beta, gamma)\n        dist_a = min(np.linalg.norm(p_final_a - m) for m in MINIMIZER_CANDIDATES)\n        converged_a = dist_a  DIST_THRESHOLD and f_val_a  FUNC_THRESHOLD\n        \n        # Method B\n        p_final_b, flips_b = run_method_b(alpha, beta, gamma, x0, y0, max_iters)\n        f_val_b = f(p_final_b, alpha, beta, gamma)\n        dist_b = min(np.linalg.norm(p_final_b - m) for m in MINIMIZER_CANDIDATES)\n        converged_b = dist_b  DIST_THRESHOLD and f_val_b  FUNC_THRESHOLD\n        \n        case_results = [\n            flips_a, flips_b, f_val_a, f_val_b, converged_a, converged_b\n        ]\n        results.append(case_results)\n\n    # Format output as specified\n    results_str = [\n        f\"[{r[0]},{r[1]},{r[2]},{r[3]},{str(r[4]).lower()},{str(r[5]).lower()}]\"\n        for r in results\n    ]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Our final practice introduces a sophisticated and powerful strategy for tackling nonconvex problems: the continuation method. Instead of confronting a difficult landscape directly, this approach begins with a simple, convex version of the problem and gradually introduces complexity, tracking the minimum's location throughout this transformation. This exercise  will not only allow you to implement this elegant technique but also provide a concrete understanding of bifurcation theory, revealing the exact moment a single global minimum splits into multiple local optima.",
            "id": "3145108",
            "problem": "You are given a one-dimensional parametric objective that implements a smoothing schedule which begins convex and gradually introduces nonconvex features as the schedule parameter increases. Let the family of functions be defined by\n$$\nf(x;s) \\;=\\; x^2 \\;+\\; \\lambda(s)\\,\\bigl(x^2 - a^2\\bigr)^2,\n\\quad \\text{with} \\quad \\lambda(s) \\;=\\; c\\,s,\\quad s \\in [0,1],\n$$\nwhere $a > 0$ and $c > 0$ are fixed parameters. The schedule parameter $s$ controls the strength of the nonconvex quartic term. The task is to precisely characterize when local minima emerge and to simulate how a basic descent algorithm adapts across the schedule.\n\nUse the following foundations as the starting point (do not assume any result beyond these):\n- The definition of convexity in one dimension: a twice-differentiable function $f$ is convex on $\\mathbb{R}$ if and only if $f''(x) \\ge 0$ for all $x \\in \\mathbb{R}$.\n- A point $x^\\star$ is a local minimizer if there exists $\\epsilon > 0$ such that $f(x^\\star) \\le f(x)$ for all $x$ with $\\lvert x - x^\\star \\rvert  \\epsilon$, and for twice-differentiable $f$, a strict local minimizer with $f'(x^\\star) = 0$ typically satisfies $f''(x^\\star) > 0$.\n- Gradient descent in one dimension with fixed step size $\\eta > 0$ iterates $x_{k+1} = x_k - \\eta\\,f'(x_k)$ and, under sufficiently small $\\eta$ and smoothness, converges to a stationary point.\n\nYour program must carry out the following steps for each test case:\n1) Derive and compute the exact schedule value $s_\\text{crit}$ at which convexity is lost and multiple critical points coalesce or split, expressed in terms of $a$ and $c$.\n2) For a prescribed list of schedule values $S = [\\,s_0, s_1, s_2, s_3, s_4\\,] = [\\,0.0, 0.2, 0.5, 0.8, 1.0\\,]$, determine the number of distinct local minima of $f(\\cdot; s_j)$ for each $s_j \\in S$.\n3) Simulate a continuation strategy (warm-start gradient descent) across the schedule:\n   - Use initial point $x_0 = 0.05$ at $s_0$.\n   - For $j = 0,1,2,3,4$, run gradient descent on $f(\\cdot; s_j)$ from the current starting point to obtain a converged point $x^\\star(s_j)$ using fixed step size $\\eta = 0.02$, maximum iterations $N_{\\max} = 50000$, and terminate when either the step change $\\lvert x_{k+1} - x_k \\rvert  10^{-10}$ or the gradient magnitude $\\lvert f'(x_k; s_j) \\rvert  10^{-8}$.\n   - To avoid getting trapped at an unstable stationary point when moving from $s_j$ to $s_{j+1}$, perturb the next starting point as $x_0 \\leftarrow x^\\star(s_j) + \\delta \\cdot \\operatorname{sgn}_+(x^\\star(s_j))$, where $\\delta = 10^{-6}$ and $\\operatorname{sgn}_+(x) = 1$ if $x \\ge 0$ and $\\operatorname{sgn}_+(x) = -1$ if $x  0$.\n   - At the final schedule $s_4 = 1.0$, report the integer sign of the converged point using the thresholded sign function $\\text{sign\\_int}(x) = 1$ if $x > 10^{-6}$, $\\text{sign\\_int}(x) = -1$ if $x  -10^{-6}$, and $\\text{sign\\_int}(x) = 0$ otherwise.\n4) Probe the landscape at the final schedule $s_4 = 1.0$ using a cold multi-start gradient descent with starting points $X_\\text{seeds} = [-1.0, -0.5, -0.1, 0.1, 0.5, 1.0]$ and the same descent hyperparameters as above, cluster the converged points by merging any two within absolute distance less than $10^{-3}$, and report the integer number of distinct minima discovered.\n\nTest suite. Run the above for the following three parameter sets:\n- Test case $1$: $a = 1.0$, $c = 0.3$.\n- Test case $2$: $a = 1.0$, $c = 1.5$.\n- Test case $3$: $a = 0.7$, $c = 5.0$.\n\nYour program must produce a single line of output containing all results in a single flat list, with the following order for each test case, then concatenated across the three cases:\n- $s_\\text{crit}$ rounded to $6$ decimal places,\n- the $5$ integers giving the number of local minima at $s_0, s_1, s_2, s_3, s_4$,\n- the single integer warm-start sign at $s_4$,\n- the single integer number of distinct minima found by cold multi-start at $s_4$.\n\nThus there are $8$ values per test case and $24$ values total. The program should print exactly one line containing these $24$ values as a comma-separated list enclosed in square brackets, with no spaces, for example: \"[r_1,r_2,...,r_{24}]\".",
            "solution": "The user-provided problem is a well-posed exercise in nonlinear optimization and bifurcation theory. It is scientifically sound, self-contained, and all terms are formally defined. The task is to analyze the behavior of a one-dimensional parametric objective function $f(x;s)$ by deriving a critical parameter value, analyzing the number of local minima, and simulating a gradient-based optimization strategy. The problem is valid.\n\nThe objective function is given by:\n$$\nf(x;s) = x^2 + \\lambda(s)\\,\\bigl(x^2 - a^2\\bigr)^2\n$$\nwhere $\\lambda(s) = c\\,s$, with parameters $a > 0$, $c > 0$, and the schedule parameter $s \\in [0,1]$.\n\n**Part 1: Derivation of the Critical Schedule Value $s_\\text{crit}$**\n\nA twice-differentiable function is convex on $\\mathbb{R}$ if and only if its second derivative is non-negative everywhere. We first compute the first and second derivatives of $f(x;s)$ with respect to $x$.\n\nThe function can be expanded as:\n$$\nf(x;s) = x^2 + cs(x^4 - 2a^2x^2 + a^4)\n$$\nThe first derivative, $f'(x;s)$, is:\n$$\nf'(x;s) = \\frac{\\partial f}{\\partial x} = 2x + cs(4x^3 - 4a^2x) = 2x \\bigl(1 + 2cs(x^2 - a^2)\\bigr)\n$$\nThe second derivative, $f''(x;s)$, is:\n$$\nf''(x;s) = \\frac{\\partial^2 f}{\\partial x^2} = 2 + cs(12x^2 - 4a^2) = 2 + 4cs(3x^2 - a^2)\n$$\nFor $f(x;s)$ to be convex for all $x \\in \\mathbb{R}$, we must have $f''(x;s) \\ge 0$ for all $x$. Since $c > 0$ and $s \\ge 0$, the term $12csx^2$ is non-negative. The expression $f''(x;s)$ is a parabolic function of $x$ opening upwards (or a constant if $cs=0$), so its global minimum occurs at $x=0$.\nWe evaluate $f''(x;s)$ at its minimum:\n$$\n\\min_x f''(x;s) = f''(0;s) = 2 + 4cs(3(0)^2 - a^2) = 2 - 4csa^2\n$$\nThe condition for convexity is that this minimum value must be non-negative:\n$$\n2 - 4csa^2 \\ge 0 \\implies 2 \\ge 4csa^2 \\implies s \\le \\frac{2}{4ca^2} = \\frac{1}{2ca^2}\n$$\nThe function loses convexity at the point where this inequality no longer holds. The critical schedule value, $s_\\text{crit}$, is the boundary of this inequality:\n$$\ns_\\text{crit} = \\frac{1}{2ca^2}\n$$\nFor $s > s_\\text{crit}$, $f''(0;s)  0$, indicating that $x=0$ has become a local maximum, and the function is no longer convex. This event corresponds to a pitchfork bifurcation where one minimum splits into two minima and a maximum.\n\n**Part 2: Determination of the Number of Local Minima**\n\nLocal minima are a subset of the critical points, which are the roots of $f'(x;s)=0$.\n$$\nf'(x;s) = 2x \\bigl(1 + 2cs(x^2 - a^2)\\bigr) = 0\n$$\nThis equation has solutions when $x=0$ or when $1 + 2cs(x^2-a^2) = 0$.\n\nCase 1: $s \\le s_\\text{crit}$\nIn this case, $s \\le \\frac{1}{2ca^2}$, which implies $2csa^2 \\le 1$.\nThe second term in the product gives $x^2 = a^2 - \\frac{1}{2cs}$. For a real solution for $x$ to exist, we need $a^2 - \\frac{1}{2cs} \\ge 0$, which implies $s \\ge \\frac{1}{2ca^2} = s_\\text{crit}$.\nThus, for $s  s_\\text{crit}$, the only real root is $x=0$.\nAt $s = s_\\text{crit}$, we have $x^2 = a^2 - a^2 = 0$, so again the only root is $x=0$.\nLet's check the stability at $x=0$: $f''(0;s) = 2 - 4csa^2 = 2(1 - 2csa^2)$.\nSince $s \\le s_\\text{crit}$, $2csa^2 \\le 1$, so $f''(0;s) \\ge 0$.\nTherefore, for $s \\le s_\\text{crit}$, $x=0$ is a local minimizer. There is exactly one local minimum.\n\nCase 2: $s > s_\\text{crit}$\nHere, $s > \\frac{1}{2ca^2}$, so $2csa^2 > 1$.\nThe critical points are:\n1.  $x_0 = 0$. At this point, $f''(0;s) = 2(1 - 2csa^2)  0$, so $x=0$ is a local maximum.\n2.  $x^2 = a^2 - \\frac{1}{2cs}$. Since $s > s_\\text{crit}$, $a^2 - \\frac{1}{2cs} > 0$, giving two distinct real roots $x_{1,2} = \\pm \\sqrt{a^2 - \\frac{1}{2cs}}$.\nLet's check the stability at these points. We substitute $x^2 = a^2 - \\frac{1}{2cs}$ into the second derivative expression:\n$$\nf''(x_{1,2};s) = 2 + 4cs(3x^2 - a^2) = 2 + 4cs\\left(3\\left(a^2 - \\frac{1}{2cs}\\right) - a^2\\right)\n$$\n$$\n= 2 + 4cs\\left(3a^2 - \\frac{3}{2cs} - a^2\\right) = 2 + 4cs\\left(2a^2 - \\frac{3}{2cs}\\right) = 2 + 8csa^2 - 6 = 8csa^2 - 4 = 4(2csa^2 - 1)\n$$\nSince $s > s_\\text{crit}$, we have $2csa^2 > 1$, which implies $f''(x_{1,2};s) > 0$.\nTherefore, for $s > s_\\text{crit}$, there are two distinct local minima.\n\nSummary for counting minima: For a given $s_j$, the number of local minima is $1$ if $s_j \\le s_\\text{crit}$ and $2$ if $s_j > s_\\text{crit}$.\n\n**Part 3  4: Numerical Simulation**\n\nThe remaining tasks involve numerical simulation.\nA gradient descent algorithm will be implemented with the update rule $x_{k+1} = x_k - \\eta f'(x_k; s)$. The specified hyperparameters are step size $\\eta=0.02$, maximum iterations $N_{\\max}=50000$, and termination based on step size change ($\\lvert x_{k+1} - x_k \\rvert  10^{-10}$) or gradient magnitude ($\\lvert f'(x_k; s) \\rvert  10^{-8}$).\n\nFor the continuation (warm-start) strategy:\n- Begin with $x_0 = 0.05$ at $s_0=0.0$.\n- For each subsequent schedule step $s_j$, the starting point is the converged point from the previous step $s_{j-1}$, perturbed by a small amount $\\delta=10^{-6}$ away from the origin. The function $\\operatorname{sgn}_+(x)$ provides the direction for this perturbation. This ensures that if the algorithm is at an unstable fixed point like $x=0$ post-bifurcation, it is pushed into a basin of attraction of a stable minimum.\n- The final result is the sign of the converged point at $s_4=1.0$, determined by the $\\text{sign\\_int}$ function.\n\nFor the multi-start (cold-start) strategy:\n- At the final schedule value $s_4 = 1.0$, gradient descent is run from a set of predefined starting points $X_\\text{seeds}$.\n- The converged points are collected and clustered. The number of clusters corresponds to the number of distinct local minima found by the search. Clustering is done by merging points within an absolute distance of $10^{-3}$.\n\nThese numerical procedures will be implemented for each of the three test cases $(a,c)$. The analytical formulas for $s_\\text{crit}$ and the number of minima will be used in conjunction with the numerical results to form the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef gradient_descent(a, c, s, x0):\n    \"\"\"\n    Performs gradient descent on the objective function f(x;s).\n    \"\"\"\n    eta = 0.02\n    max_iter = 50000\n    tol_step = 1e-10\n    tol_grad = 1e-8\n    \n    x = float(x0)\n    \n    for _ in range(max_iter):\n        # f'(x;s) = 2x + 4cs(x^3 - a^2*x)\n        grad = 2.0 * x + 4.0 * c * s * (x**3 - (a**2) * x)\n        \n        if abs(grad)  tol_grad:\n            break\n            \n        x_new = x - eta * grad\n        \n        if abs(x_new - x)  tol_step:\n            x = x_new\n            break\n        \n        x = x_new\n        \n    return x\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        (1.0, 0.3),  # Test case 1: a, c\n        (1.0, 1.5),  # Test case 2: a, c\n        (0.7, 5.0)   # Test case 3: a, c\n    ]\n\n    S = [0.0, 0.2, 0.5, 0.8, 1.0]\n    all_results = []\n\n    for a, c in test_cases:\n        # 1) Compute s_crit\n        s_crit = 1.0 / (2.0 * c * a**2)\n        all_results.append(round(s_crit, 6))\n\n        # 2) Determine the number of distinct local minima\n        num_minima = [1 if sj = s_crit else 2 for sj in S]\n        all_results.extend(num_minima)\n        \n        # 3) Simulate continuation strategy (warm-start gradient descent)\n        x_start_warm = 0.05\n        x_conv_warm = gradient_descent(a, c, S[0], x_start_warm)\n        \n        delta = 1e-6\n        for j in range(1, len(S)):\n            sj = S[j]\n            # sgn_+(x) = 1 if x >= 0, -1 if x  0\n            sgn_plus = 1.0 if x_conv_warm >= 0.0 else -1.0\n            x_start_warm = x_conv_warm + delta * sgn_plus\n            x_conv_warm = gradient_descent(a, c, sj, x_start_warm)\n        \n        # At the final schedule s_4 = 1.0, report the integer sign\n        sign_threshold = 1e-6\n        if x_conv_warm > sign_threshold:\n            warm_start_sign = 1\n        elif x_conv_warm  -sign_threshold:\n            warm_start_sign = -1\n        else:\n            warm_start_sign = 0\n        all_results.append(warm_start_sign)\n\n        # 4) Probe landscape with cold multi-start gradient descent\n        s_final = 1.0\n        X_seeds = [-1.0, -0.5, -0.1, 0.1, 0.5, 1.0]\n        converged_points = []\n        for seed in X_seeds:\n            res = gradient_descent(a, c, s_final, seed)\n            converged_points.append(res)\n        \n        # Cluster the converged points\n        clusters = []\n        cluster_tol = 1e-3\n        if len(converged_points) > 0:\n            clusters.append(converged_points[0])\n            for p in converged_points[1:]:\n                is_in_cluster = False\n                for cluster_rep in clusters:\n                    if abs(p - cluster_rep)  cluster_tol:\n                        is_in_cluster = True\n                        break\n                if not is_in_cluster:\n                    clusters.append(p)\n        num_clusters = len(clusters)\n        all_results.append(num_clusters)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}