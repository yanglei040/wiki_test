{
    "hands_on_practices": [
        {
            "introduction": "Our exploration begins with the most familiar way of measuring vector length: the Euclidean or $L_2$ norm. This exercise asks you to find its dual, a process that reveals a remarkable and elegant property of symmetry in Euclidean space. By applying the fundamental Cauchy-Schwarz inequality, you will discover why the $L_2$ norm holds a special place in optimization and linear algebra. ",
            "id": "977935",
            "problem": "Consider the vector space $\\mathbb{R}^2$ equipped with the standard inner product $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = x_1 y_1 + x_2 y_2$. The $L_2$ norm of a vector $\\mathbf{x} = (x_1, x_2)$ is defined as $\\|\\mathbf{x}\\|_2 = \\sqrt{x_1^2 + x_2^2}$. The dual norm of a vector $\\mathbf{z} \\in \\mathbb{R}^2$ with respect to the $L_2$ norm is given by:\n\n$$\n\\|\\mathbf{z}\\|_* = \\sup \\left\\{ \\langle \\mathbf{z}, \\mathbf{x} \\rangle \\mid \\|\\mathbf{x}\\|_2 \\leq 1 \\right\\}.\n$$\n\nCompute the dual norm of the vector $\\mathbf{z} = (1, 1)$.",
            "solution": "1. The dual norm is defined by\n$$\n\\|\\mathbf{z}\\|_* = \\sup_{\\|\\mathbf{x}\\|_2 \\le 1} \\langle \\mathbf{z}, \\mathbf{x} \\rangle.\n$$\n2. By the Cauchy–Schwarz inequality,\n$$\n\\langle \\mathbf{z}, \\mathbf{x} \\rangle \\le \\|\\mathbf{z}\\|_2 \\,\\|\\mathbf{x}\\|_2 \\le \\|\\mathbf{z}\\|_2.\n$$\nHence the supremum is achieved when $\\mathbf{x}$ is in the direction of $\\mathbf{z}$ and equals $\\|\\mathbf{z}\\|_2$.\n3. For $\\mathbf{z}=(1,1)$,\n$$\n\\|\\mathbf{z}\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2}.\n$$\nTherefore,\n$$\n\\|\\mathbf{z}\\|_* = \\sqrt{2}.\n$$",
            "answer": "$$\\boxed{\\sqrt{2}}$$"
        },
        {
            "introduction": "While standard $p$-norms are foundational, real-world applications often require custom norms tailored to specific problems, such as the weighted norm in this exercise. This practice moves beyond memorized duality pairs and challenges you to compute a dual norm from its first principles. By working through this problem, you will gain a deeper appreciation for the geometric interpretation of the dual norm calculation: finding the point on a non-standard unit ball that maximizes a linear function. ",
            "id": "977917",
            "problem": "Consider the vector space $\\mathbb{R}^2$ equipped with the weighted $L_\\infty$ norm defined by $\\| \\mathbf{x} \\| = \\max\\left( \\frac{|x_1|}{2}, |x_2| \\right)$ for any vector $\\mathbf{x} = (x_1, x_2)$. Compute the dual norm of the vector $\\mathbf{y} = (3, 4)$.\n\nRecall that the dual norm of a vector $\\mathbf{y}$ is defined as:\n\n$$\n\\|\\mathbf{y}\\|_* = \\sup \\left\\{ |\\langle \\mathbf{x}, \\mathbf{y} \\rangle| : \\|\\mathbf{x}\\| \\leq 1 \\right\\},\n$$\n\nwhere $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = x_1 y_1 + x_2 y_2$ denotes the standard inner product.",
            "solution": "The dual norm of $\\mathbf{y} = (3, 4)$ is computed by maximizing $|\\langle \\mathbf{x}, \\mathbf{y} \\rangle| = |3x_1 + 4x_2|$ over all $\\mathbf{x}$ satisfying $\\|\\mathbf{x}\\| \\leq 1$. The constraint $\\|\\mathbf{x}\\| \\leq 1$ expands to:\n\n$$\n\\max\\left( \\frac{|x_1|}{2}, |x_2| \\right) \\leq 1,\n$$\n\nwhich is equivalent to:\n\n$$\n|x_1| \\leq 2 \\quad \\text{and} \\quad |x_2| \\leq 1.\n$$\n\nThis defines a closed rectangle in $\\mathbb{R}^2$. Since $|3x_1 + 4x_2|$ is a continuous function and the feasible set is compact, the supremum is attained at an extreme point. The extreme points (vertices) of the rectangle are:\n\n$$\n(2, 1), \\quad (2, -1), \\quad (-2, 1), \\quad (-2, -1).\n$$\n\nEvaluating the objective function at these points:\n\n$$\n\\begin{align*}\n|3(2) + 4(1)| &= |6 + 4| = |10| = 10, \\\\\n|3(2) + 4(-1)| &= |6 - 4| = |2| = 2, \\\\\n|3(-2) + 4(1)| &= |-6 + 4| = |-2| = 2, \\\\\n|3(-2) + 4(-1)| &= |-6 - 4| = |-10| = 10.\n\\end{align*}\n$$\n\nThe maximum value is 10, so:\n\n$$\n\\|\\mathbf{y}\\|_* = 10.\n$$\n\nAlternatively, for the weighted $L_\\infty$ norm $\\|\\mathbf{x}\\| = \\max\\left( \\frac{|x_1|}{w_1}, \\frac{|x_2|}{w_2} \\right)$ with $w_1 = 2$ and $w_2 = 1$, the dual norm is the weighted $L_1$ norm:\n\n$$\n\\|\\mathbf{y}\\|_* = w_1 |y_1| + w_2 |y_2| = 2 \\cdot |3| + 1 \\cdot |4| = 6 + 4 = 10.\n$$\n\nBoth methods confirm the result.",
            "answer": "$$ \\boxed{10} $$"
        },
        {
            "introduction": "We conclude by connecting these concepts to a practical task central to machine learning and signal processing: projecting a point onto a convex set. This exercise asks you to find the closest point in an $L_{\\infty}$ ball to a given vector, a problem that appears in contexts like parameter clipping and robust optimization. The solution elegantly demonstrates how understanding the dual relationship between the $L_1$ and $L_{\\infty}$ norms provides the key to unlocking a simple, intuitive, and computationally efficient coordinate-wise solution. ",
            "id": "3197835",
            "problem": "Let $n \\in \\mathbb{N}$ and consider the Euclidean projection of a vector $\\boldsymbol{v} \\in \\mathbb{R}^{n}$ onto the closed convex set $\\mathcal{C}_{\\infty}(\\tau) \\coloneqq \\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau\\}$, where $\\tau > 0$ and $\\|\\cdot\\|_{\\infty}$ denotes the $\\ell_{\\infty}$ norm. Starting only from the definition of the Euclidean projection onto a nonempty closed convex set and the definition of the dual norm, do the following:\n\n1) Derive the structure of the Euclidean projection $\\Pi_{\\mathcal{C}_{\\infty}(\\tau)}(\\boldsymbol{v})$ by solving the defining optimization problem directly. In your derivation, determine whether the solution can be expressed as a coordinate-wise operation and justify your conclusion using first principles of convex optimization.\n\n2) Explain how $\\mathcal{C}_{\\infty}(\\tau)$ relates to the dual ball of the $\\ell_{1}$ norm, explicitly identifying the dual norm of $\\|\\cdot\\|_{1}$ and the associated dual ball.\n\n3) Apply your result to the concrete data\n$\\boldsymbol{v} = (\\,3.1,\\,-2.4,\\,1.8,\\,-0.9,\\,2.0,\\,-4.6\\,) \\in \\mathbb{R}^{6}$ and $\\tau = 2$ to compute the unique Euclidean projection $\\Pi_{\\mathcal{C}_{\\infty}(2)}(\\boldsymbol{v})$.\n\nProvide the final projected vector as your answer. You do not need to round; give exact values.",
            "solution": "### Part 1: Derivation of the Projection Operator\n\nThe Euclidean projection of a vector $\\boldsymbol{v} \\in \\mathbb{R}^{n}$ onto a nonempty closed convex set $\\mathcal{C}$ is defined as the unique vector $\\boldsymbol{x}^* \\in \\mathcal{C}$ that minimizes the Euclidean distance to $\\boldsymbol{v}$. This is equivalent to minimizing the squared Euclidean norm of the difference, which is a strictly convex optimization problem. Let $\\boldsymbol{x}^* = \\Pi_{\\mathcal{C}_{\\infty}(\\tau)}(\\boldsymbol{v})$. Then $\\boldsymbol{x}^*$ is the solution to:\n$$\n\\boldsymbol{x}^* = \\arg\\min_{\\boldsymbol{x} \\in \\mathcal{C}_{\\infty}(\\tau)} \\frac{1}{2} \\|\\boldsymbol{x} - \\boldsymbol{v}\\|_{2}^{2}\n$$\nThe objective function is $f(\\boldsymbol{x}) = \\frac{1}{2} \\|\\boldsymbol{x} - \\boldsymbol{v}\\|_{2}^{2} = \\frac{1}{2} \\sum_{i=1}^{n} (x_i - v_i)^2$. The constraint set is $\\mathcal{C}_{\\infty}(\\tau) = \\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau\\}$. By definition of the $\\ell_{\\infty}$-norm, $\\|\\boldsymbol{x}\\|_{\\infty} = \\max_{i=1, \\dots, n} |x_i|$. The constraint $\\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau$ is therefore equivalent to the set of $n$ independent constraints $|x_i| \\le \\tau$ for each $i \\in \\{1, \\dots, n\\}$. This can be written as $-\\tau \\le x_i \\le \\tau$.\n\nThe optimization problem is thus:\n$$\n\\begin{array}{ll}\n\\text{minimize} & \\frac{1}{2} \\sum_{i=1}^{n} (x_i - v_i)^2 \\\\\n\\text{subject to} & -\\tau \\le x_i \\le \\tau, \\quad \\text{for } i = 1, \\dots, n\n\\end{array}\n$$\nThe objective function is a sum of terms where each term depends only on a single variable $x_i$. The constraints are also decoupled, applying to each coordinate $x_i$ independently. This separability implies that the $n$-dimensional optimization problem can be decomposed into $n$ independent one-dimensional optimization problems:\n$$\n\\text{For each } i \\in \\{1, \\dots, n\\}, \\quad \\text{solve: } \\quad\n\\begin{array}{ll}\n\\text{minimize} & \\frac{1}{2} (x_i - v_i)^2 \\\\\n\\text{subject to} & x_i \\in [-\\tau, \\tau]\n\\end{array}\n$$\nThe unconstrained minimizer of $\\frac{1}{2} (x_i - v_i)^2$ is $x_i = v_i$.\n- If $v_i$ lies within the feasible interval $[-\\tau, \\tau]$ (i.e., $|v_i| \\le \\tau$), then a unique solution is $x_i^* = v_i$.\n- If $v_i > \\tau$, the quadratic function is minimized over the interval $[-\\tau, \\tau]$ at the endpoint closest to $v_i$, which is $x_i^* = \\tau$.\n- If $v_i < -\\tau$, the minimum is achieved at the other endpoint, $x_i^* = -\\tau$.\n\nThese three cases can be compactly expressed as projecting the scalar $v_i$ onto the interval $[-\\tau, \\tau]$. The solution for each component is:\n$$\nx_i^* = \\begin{cases}\n\\tau & \\text{if } v_i > \\tau \\\\\nv_i & \\text{if } -\\tau \\le v_i \\le \\tau \\\\\n-\\tau & \\text{if } v_i < -\\tau\n\\end{cases}\n$$\nThis operation is also known as clipping or saturation and can be written as $x_i^* = \\text{median}(-\\tau, v_i, \\tau)$ or $x_i^* = \\text{sign}(v_i) \\min(|v_i|, \\tau)$.\n\nThe structure of the projection $\\Pi_{\\mathcal{C}_{\\infty}(\\tau)}(\\boldsymbol{v})$ is a coordinate-wise operation. This is a direct consequence of the separability of both the objective function (squared Euclidean norm) and the constraint set (a hypercube aligned with the coordinate axes). From the first principles of convex optimization, because the problem decomposes into independent subproblems for each coordinate, the overall solution is simply the vector of the solutions to the subproblems.\n\n### Part 2: Relation to the Dual aorm of $\\|\\cdot\\|_1$\n\nThe dual norm $\\|\\cdot\\|_*$ of a norm $\\|\\cdot\\|$ on $\\mathbb{R}^n$ is defined by\n$$\n\\|\\boldsymbol{z}\\|_* \\coloneqq \\sup_{\\|\\boldsymbol{x}\\| \\le 1} \\boldsymbol{z}^{\\top}\\boldsymbol{x}\n$$\nWe seek the dual norm of the $\\ell_1$-norm, $\\|\\cdot\\|_1 = \\sum_{i=1}^n |x_i|$. Let $\\|\\cdot\\| = \\|\\cdot\\|_1$. Its dual is:\n$$\n\\|\\boldsymbol{z}\\|_* = \\sup_{\\|\\boldsymbol{x}\\|_1 \\le 1} \\sum_{i=1}^n z_i x_i\n$$\nTo maximize $\\sum_i z_i x_i$ subject to $\\sum_i |x_i| \\le 1$, we should align the vector $\\boldsymbol{x}$ with the component of $\\boldsymbol{z}$ that has the largest magnitude. Let $k = \\arg\\max_{i} |z_i|$, so that $|z_k| = \\|\\boldsymbol{z}\\|_{\\infty}$. We construct a vector $\\boldsymbol{x}$ with $x_k = \\text{sign}(z_k)$ and $x_i = 0$ for all $i \\neq k$. This vector satisfies the constraint $\\|\\boldsymbol{x}\\|_1 = |\\text{sign}(z_k)| = 1$. For this choice of $\\boldsymbol{x}$, the inner product is $\\boldsymbol{z}^{\\top}\\boldsymbol{x} = z_k x_k = z_k \\text{sign}(z_k) = |z_k| = \\|\\boldsymbol{z}\\|_{\\infty}$.\n\nBy the Hölder inequality for $\\ell_p$-norms, $|\\boldsymbol{z}^{\\top}\\boldsymbol{x}| \\le \\|\\boldsymbol{z}\\|_q \\|\\boldsymbol{x}\\|_p$ where $\\frac{1}{p} + \\frac{1}{q} = 1$. For $p=1$, we have $q=\\infty$. Thus, for any $\\boldsymbol{x}$ with $\\|\\boldsymbol{x}\\|_1 \\le 1$:\n$$\n\\boldsymbol{z}^{\\top}\\boldsymbol{x} \\le |\\boldsymbol{z}^{\\top}\\boldsymbol{x}| \\le \\|\\boldsymbol{z}\\|_{\\infty} \\|\\boldsymbol{x}\\|_1 \\le \\|\\boldsymbol{z}\\|_{\\infty}\n$$\nSince we found a feasible point $\\boldsymbol{x}$ that achieves this upper bound, the supremum is $\\|\\boldsymbol{z}\\|_{\\infty}$. Therefore, the dual norm of the $\\ell_1$-norm is the $\\ell_{\\infty}$-norm.\n\nThe unit dual ball associated with a norm $\\|\\cdot\\|$ is the set $\\{\\boldsymbol{z} \\in \\mathbb{R}^n : \\|\\boldsymbol{z}\\|_* \\le 1\\}$. For the $\\ell_1$-norm, the dual norm is $\\|\\cdot\\|_{\\infty}$, so its unit dual ball is $\\{\\boldsymbol{z} \\in \\mathbb{R}^n : \\|\\boldsymbol{z}\\|_{\\infty} \\le 1\\}$. This is precisely the set $\\mathcal{C}_{\\infty}(1)$.\nThe set given in the problem, $\\mathcal{C}_{\\infty}(\\tau) = \\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\|\\boldsymbol{x}\\|_{\\infty} \\le \\tau\\}$, is the $\\ell_{\\infty}$-ball of radius $\\tau$. It is a scaled version of the unit dual ball of the $\\ell_1$-norm, where the scaling factor is $\\tau$.\n\n### Part 3: Application to Concrete Data\n\nWe are given the vector $\\boldsymbol{v} = (\\,3.1,\\,-2.4,\\,1.8,\\,-0.9,\\,2.0,\\,-4.6\\,) \\in \\mathbb{R}^{6}$ and the parameter $\\tau = 2$. The projection $\\boldsymbol{x}^* = \\Pi_{\\mathcal{C}_{\\infty}(2)}(\\boldsymbol{v})$ is computed by applying the coordinate-wise clipping operation derived in Part 1 to each component of $\\boldsymbol{v}$ with respect to the interval $[ -2, 2 ]$.\n\n- $v_1 = 3.1$: Since $3.1 > 2$, $x_1^* = 2$.\n- $v_2 = -2.4$: Since $-2.4 < -2$, $x_2^* = -2$.\n- $v_3 = 1.8$: Since $-2 \\le 1.8 \\le 2$, $x_3^* = 1.8$.\n- $v_4 = -0.9$: Since $-2 \\le -0.9 \\le 2$, $x_4^* = -0.9$.\n- $v_5 = 2.0$: Since $-2 \\le 2.0 \\le 2$, $x_5^* = 2.0$.\n- $v_6 = -4.6$: Since $-4.6 < -2$, $x_6^* = -2$.\n\nCombining these results gives the projected vector.\nThe unique Euclidean projection is $\\boldsymbol{x}^* = (\\,2, -2, 1.8, -0.9, 2, -2\\,)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & -2 & 1.8 & -0.9 & 2 & -2\n\\end{pmatrix}\n}\n$$"
        }
    ]
}