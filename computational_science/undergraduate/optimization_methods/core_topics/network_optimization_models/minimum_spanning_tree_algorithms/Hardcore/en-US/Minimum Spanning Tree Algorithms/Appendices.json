{
    "hands_on_practices": [
        {
            "introduction": "Understanding the theoretical guarantees of Minimum Spanning Tree (MST) algorithms is one thing, but truly grasping their operational logic requires seeing them in action. This first practice problem focuses on the crucial, and often confused, differences between Kruskal's and Prim's algorithms. Using a cleverly constructed \"ladder graph,\" this exercise  will challenge you to trace the initial steps of each algorithm, forcing you to confront the distinction between Kruskal's global, edge-centric approach and Prim's local, tree-growing method. Mastering this difference is fundamental to correctly applying and analyzing these powerful tools.",
            "id": "3151259",
            "problem": "Consider a ladder graph with $n=5$ rungs constructed as follows. There are vertices $\\{t_1,t_2,t_3,t_4,t_5\\}$ on the top rail and $\\{b_1,b_2,b_3,b_4,b_5\\}$ on the bottom rail. For each $i \\in \\{1,2,3,4\\}$ there are rail edges $(t_i,t_{i+1})$ and $(b_i,b_{i+1})$, and for each $i \\in \\{1,2,3,4,5\\}$ there is a rung edge $(t_i,b_i)$. The edge weights are assigned as follows:\n- Every rail edge has weight $3$.\n- The rung edge $(t_i,b_i)$ has weight $1$ if $i$ is odd and weight $10$ if $i$ is even.\n\nAssume all edges are undirected and weights are strictly as given. You will run Kruskal’s algorithm and Prim’s algorithm on this graph. For Prim’s algorithm, the start vertex is $t_1$. Ties among equal-weight edges are broken arbitrarily when they occur, but no two different weight values tie.\n\nUsing only fundamental properties of minimum spanning trees, select all statements that must be true about the earliest edge selections made by these algorithms.\n\nA. Under Kruskal’s algorithm, the first accepted edges are exactly the three light rungs in columns $1$, $3$, and $5$ (that is, $(t_1,b_1)$, $(t_3,b_3)$, $(t_5,b_5)$), in some order, and these are all chosen before any rail edge.\n\nB. Under Prim’s algorithm started at $t_1$, the first edge chosen is the light rung $(t_1,b_1)$, and the second edge must be a rail of weight $3$ (not any rung).\n\nC. Under Prim’s algorithm started at $t_1$, the second edge can be the light rung $(t_3,b_3)$ because it has smaller weight than the rails.\n\nD. Even though both algorithms produce a minimum spanning tree, Prim’s and Kruskal’s early selections can differ: Kruskal’s globally sorted choices take all light rungs first, whereas Prim’s choices are constrained to the current cut and may interleave rails and rungs depending on the start.",
            "solution": "The user has provided a problem concerning the execution of Kruskal's and Prim's algorithms on a specific weighted graph.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Graph Type**: A ladder graph with $n=5$ rungs.\n*   **Vertex Set**: $V = \\{t_1, t_2, t_3, t_4, t_5\\} \\cup \\{b_1, b_2, b_3, b_4, b_5\\}$. The total number of vertices is $|V|=10$.\n*   **Edge Set and Weights**:\n    *   Top rail edges: $(t_i, t_{i+1})$ for $i \\in \\{1,2,3,4\\}$, with weight $3$.\n    *   Bottom rail edges: $(b_i, b_{i+1})$ for $i \\in \\{1,2,3,4\\}$, with weight $3$.\n    *   Rung edges: $(t_i, b_i)$ for $i \\in \\{1,2,3,4,5\\}$.\n        *   Weight of $(t_i, b_i)$ is $1$ if $i$ is odd ($i \\in \\{1,3,5\\}$).\n        *   Weight of $(t_i, b_i)$ is $10$ if $i$ is even ($i \\in \\{2,4\\}$).\n*   **Edge Properties**: All edges are undirected.\n*   **Algorithms**: Kruskal's algorithm and Prim's algorithm.\n*   **Prim's Algorithm Start Vertex**: $t_1$.\n*   **Tie-Breaking**: Ties among equal-weight edges are broken arbitrarily. The statement \"no two different weight values tie\" is a tautology; the set of distinct weight values is $\\{1, 3, 10\\}$.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientific or Factual Unsoundness**: The problem is based on standard graph theory and algorithms (Kruskal's, Prim's). It is mathematically sound.\n2.  **Non-Formalizable or Irrelevant**: The problem is a standard, formalizable exercise in the application of minimum spanning tree (MST) algorithms, directly relevant to optimization methods.\n3.  **Incomplete or Contradictory Setup**: The graph structure, vertex labels, edge definitions, and weights are all explicitly and consistently defined. The setup is complete.\n4.  **Unrealistic or Infeasible**: The problem is abstract and does not pertain to physical reality, so this criterion is not applicable in that sense. The graph is well-defined.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-posed. By asking what *must* be true, it correctly frames the question to be independent of the arbitrary tie-breaking. The existence of a solution is guaranteed by the properties of MST algorithms on connected, weighted, undirected graphs.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem requires a careful, step-by-step application and comparison of two distinct algorithms, which is a non-trivial reasoning task.\n7.  **Outside Scientific Verifiability**: The claims can be rigorously proven or disproven by executing the algorithms as described.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. I will proceed with the solution derivation.\n\n### Derivation and Option Evaluation\n\nFirst, let's categorize the edges by their weights:\n*   **Weight 1**: $(t_1, b_1)$, $(t_3, b_3)$, $(t_5, b_5)$. (3 edges, light rungs)\n*   **Weight 3**: $(t_1, t_2), (t_2, t_3), (t_3, t_4), (t_4, t_5)$ and $(b_1, b_2), (b_2, b_3), (b_3, b_4), (b_4, b_5)$. (8 edges, rails)\n*   **Weight 10**: $(t_2, b_2), (t_4, b_4)$. (2 edges, heavy rungs)\n\nAn MST on a graph with $V$ vertices will have $V-1$ edges. Here, $|V|=10$, so the MST will have $10-1 = 9$ edges.\n\n**Analysis of Kruskal's Algorithm**\n\nKruskal's algorithm works by sorting all edges by weight in non-decreasing order and adding an edge to the growing forest if it does not form a cycle with the previously added edges.\n\n1.  The algorithm first considers all edges of weight $1$. These are $(t_1, b_1)$, $(t_3, b_3)$, and $(t_5, b_5)$.\n    *   The edge $(t_1, b_1)$ connects vertices $t_1$ and $b_1$.\n    *   The edge $(t_3, b_3)$ connects vertices $t_3$ and $b_3$.\n    *   The edge $(t_5, b_5)$ connects vertices $t_5$ and $b_5$.\n    These three edges connect three disjoint pairs of vertices. Therefore, adding all three of them, in any order, will not create a cycle. Since they are the lowest-weight edges in the entire graph, Kruskal's algorithm *must* accept all three of them.\n\n2.  After accepting all weight-$1$ edges, the next edges to be considered are the eight rail edges of weight $3$.\n\n**Analysis of Prim's Algorithm**\n\nPrim's algorithm starts from a single vertex and grows the MST by iteratively adding the cheapest edge that connects a vertex in the MST to a vertex outside the MST. The start vertex is given as $t_1$.\n\n1.  **Step 1**: The initial tree is $T_0 = \\{t_1\\}$. The set of vertices in the tree is $S = \\{t_1\\}$. The algorithm considers all edges incident to $t_1$. These are:\n    *   $(t_1, b_1)$ with weight $1$.\n    *   $(t_1, t_2)$ with weight $3$.\n    The edge with the minimum weight is $(t_1, b_1)$. This edge must be chosen.\n    The new tree becomes $T_1 = \\{(t_1, b_1)\\}$, and the set of vertices is $S = \\{t_1, b_1\\}$.\n\n2.  **Step 2**: The algorithm now considers all edges that cross the cut between $S = \\{t_1, b_1\\}$ and $V \\setminus S$. These are edges with one endpoint in $\\{t_1, b_1\\}$ and the other outside this set.\n    *   From $t_1$: $(t_1, t_2)$ with weight $3$.\n    *   From $b_1$: $(b_1, b_2)$ with weight $3$.\n    The other edges, such as the rung $(t_3, b_3)$ with weight $1$, are not in the current cut because both of their endpoints ($t_3$ and $b_3$) are outside of $S$. The algorithm can only select from edges in the cut.\n    The minimum weight of an edge in the cut is $3$. The two edges with this weight are $(t_1, t_2)$ and $(b_1, b_2)$. The algorithm will choose one of these two. Since both are rail edges, the second edge chosen by Prim's algorithm *must* be a rail edge of weight $3$.\n\nNow, let's evaluate each option.\n\n**A. Under Kruskal’s algorithm, the first accepted edges are exactly the three light rungs in columns $1$, $3$, and $5$ (that is, $(t_1,b_1)$, $(t_3,b_3)$, $(t_5,b_5)$), in some order, and these are all chosen before any rail edge.**\n\nAs per our analysis of Kruskal's algorithm, the three edges with weight $1$ are the absolute lightest in the graph. They connect disjoint pairs of vertices and thus cannot form a cycle among themselves. Therefore, they will all be accepted before any edge of a higher weight (such as the rail edges of weight $3$) is even considered. This statement is a direct consequence of the mechanics of Kruskal's algorithm.\n**Verdict: Correct.**\n\n**B. Under Prim’s algorithm started at $t_1$, the first edge chosen is the light rung $(t_1,b_1)$, and the second edge must be a rail of weight $3$ (not any rung).**\n\nOur analysis of Prim's algorithm shows that from the start vertex $t_1$, the cheapest incident edge is $(t_1, b_1)$ with weight $1$. This is the mandatory first choice. After this, the vertices in the tree are $\\{t_1, b_1\\}$. The cheapest edges leaving this set are $(t_1, t_2)$ and $(b_1, b_2)$, both of which are rail edges with weight $3$. No other rung is incident to the set $\\{t_1, b_1\\}$. Therefore, the second edge chosen must be one of these two rail edges. The statement is accurate.\n**Verdict: Correct.**\n\n**C. Under Prim’s algorithm started at $t_1$, the second edge can be the light rung $(t_3,b_3)$ because it has smaller weight than the rails.**\n\nThis statement reflects a common misunderstanding of Prim's algorithm. While it is true that the edge $(t_3, b_3)$ has weight $1$, which is less than the weight of rail edges ($3$), it cannot be selected as the second edge. After the first step, the tree contains vertices $\\{t_1, b_1\\}$. Prim's algorithm can only select from edges connecting a vertex in $\\{t_1, b_1\\}$ to a vertex not in this set. The edge $(t_3, b_3)$ connects $t_3$ and $b_3$, neither of which is in the tree at this stage. Therefore, $(t_3, b_3)$ is not in the cut and is not a candidate for selection. The statement is factually incorrect.\n**Verdict: Incorrect.**\n\n**D. Even though both algorithms produce a minimum spanning tree, Prim’s and Kruskal’s early selections can differ: Kruskal’s globally sorted choices take all light rungs first, whereas Prim’s choices are constrained to the current cut and may interleave rails and rungs depending on the start.**\n\nThis statement serves as a summary of the properties of the two algorithms in the context of this specific problem.\n*   \"Kruskal’s globally sorted choices take all light rungs first\": As established in the analysis for option A, this is true. The first three edges selected by Kruskal's are the weight-$1$ rungs.\n*   \"Prim’s choices are constrained to the current cut\": This is the definition of Prim's algorithm.\n*   \"early selections can differ\": Kruskal's first three edges have weights $(1, 1, 1)$. Prim's first two edges have weights $(1, 3)$. The sequences are clearly different from the second step onward.\n*   \"Prim's may interleave rails and rungs\": Our analysis showed Prim's algorithm selecting a rung first, then a rail. This is an example of such interleaving.\nThe statement correctly contrasts the global perspective of Kruskal's algorithm (always taking the next-lightest edge in the whole graph) with the local or \"growing\" perspective of Prim's algorithm (taking the lightest edge attached to the current tree fragment). This difference is fundamental and well-illustrated by this problem.\n**Verdict: Correct.**",
            "answer": "$$\\boxed{\\text{ABD}}$$"
        },
        {
            "introduction": "After mastering how MST algorithms work, a crucial next step for any computer scientist or optimization expert is analyzing how *fast* they work. An algorithm's efficiency is not just an abstract property; it's deeply tied to implementation choices, particularly the data structures used to store the graph. This problem  guides you through a formal complexity analysis of Prim's algorithm, comparing an adjacency-matrix approach with a more sophisticated adjacency-list and binary-heap implementation. By deriving the leading-order operation counts for each, you will determine a precise sparsity threshold, $m^{*}(n)$, that dictates when one implementation becomes asymptotically faster than the other, providing a concrete lesson in the interplay between algorithms and data structures.",
            "id": "3151241",
            "problem": "Consider a connected, undirected, positively weighted graph with $n$ vertices and $m$ edges. The goal is to compute a Minimum Spanning Tree (MST) using Prim's algorithm. Two implementation strategies are available:\n\n(1) An adjacency-matrix implementation that maintains, for each vertex not yet in the tree, the current best-known connection weight to the tree and updates these values by scanning potential neighbors using the matrix.\n\n(2) An adjacency-list implementation that maintains the frontier edges keyed by their weights in a binary-heap priority queue, supporting the standard operations that are known from data structure theory to run in logarithmic time as a function of the number of stored elements.\n\nStarting from the core definitions of Prim's algorithm and the fundamental operation costs of scanning a matrix row and operating on a binary heap, derive the leading-order operation count for each implementation in terms of $n$ and $m$. Then, define a sparsity threshold $m^{*}(n)$ such that, for sufficiently large $n$, the adjacency-list implementation has strictly smaller leading-order growth than the adjacency-matrix implementation whenever $m  m^{*}(n)$.\n\nProvide your final answer as a single closed-form expression for $m^{*}(n)$ in terms of $n$, using the natural logarithm $\\ln(\\cdot)$. Do not approximate or round.",
            "solution": "The problem requires the derivation of a sparsity threshold $m^{*}(n)$ for a connected, undirected, positively weighted graph with $n$ vertices and $m$ edges. This threshold determines when Prim's algorithm implemented with an adjacency list and a binary heap is asymptotically more efficient than an implementation using an adjacency matrix. The derivation proceeds by analyzing the leading-order operation count for each implementation.\n\nFirst, we analyze the adjacency-matrix implementation of Prim's algorithm. Prim's algorithm iteratively constructs a Minimum Spanning Tree (MST) by adding vertices one by one. Let $S$ be the set of vertices already included in the MST. The algorithm performs $n-1$ main iterations to add the remaining vertices. In each iteration, it must find the vertex $u \\notin S$ connected to any vertex in $S$ by an edge of minimum weight. This is typically managed by maintaining an array of key values, say `key[v]`, for each vertex $v \\notin S$, storing the minimum weight of an edge connecting $v$ to $S$.\n\nIn an adjacency-matrix implementation, each of the $n-1$ iterations involves two primary steps:\n$1$. Selecting the next vertex to add to the tree. This requires finding the vertex $u \\notin S$ with the minimum `key` value. A linear scan through all $n$ vertices is needed to identify this minimum, which takes time proportional to $n$. Therefore, this step has a complexity of $O(n)$.\n$2$. Updating the `key` values. Once a vertex $u$ is added to $S$, the `key` values for all of its neighbors must be updated. With an adjacency matrix, identifying the neighbors of $u$ and their corresponding edge weights requires scanning the entire row for $u$ in the matrix. This is an $O(n)$ operation.\n\nSince each of the $n-1$ iterations requires $O(n)$ operations, the total time complexity is $(n-1) \\times O(n) = O(n^2)$. The operation count does not depend on the number of edges $m$, as the matrix scan is always performed. The leading-order operation count, $C_{1}(n, m)$, is thus proportional to $n^2$. We can express this as $C_{1}(n, m) \\approx k_1 n^2$ for some constant $k_1  0$, where the leading-order growth function is $n^2$.\n\nNext, we analyze the implementation using an adjacency list and a binary-heap priority queue. This version of Prim's algorithm also maintains the `key` values for vertices not in the tree $S$, but it stores these vertices in a priority queue keyed by their `key` values.\n$1$. Initialization: All $n$ vertices are inserted into the binary heap. The starting vertex is assigned a key of $0$, and all other vertices are assigned a key of $\\infty$. This can be accomplished in $O(n \\log n)$ time with $n$ individual insertions or $O(n)$ with a specialized `build-heap` procedure.\n$2$. The main loop runs $n$ times. In each iteration:\n   a. The vertex $u$ with the minimum key is extracted from the heap. This `extract-min` operation on a binary heap of size at most $n$ takes $O(\\log n)$ time.\n   b. For each neighbor $v$ of $u$ (retrieved via the adjacency list), if the edge $(u,v)$ provides a shorter connection to the tree for $v$, its key is updated. This `decrease-key` operation also takes $O(\\log n)$ time.\n\nOver the course of the algorithm, there are $n$ `extract-min` operations, contributing a total of $O(n \\log n)$ to the complexity. The number of `decrease-key` operations is at most the number of edges, $m$. Each edge $(u, v)$ is considered when its endpoints $u$ and $v$ are extracted from the heap. An edge can cause at most one `decrease-key` operation (for the second endpoint to be added to the tree). Thus, the total time for all `decrease-key` operations is $O(m \\log n)$.\n\nThe total complexity is the sum of these parts: $O(n \\log n + m \\log n) = O((n+m)\\log n)$. Since the graph is connected, $m \\geq n-1$, which implies that the $O(m \\log n)$ term is dominant. The leading-order operation count, $C_{2}(n, m)$, is proportional to $m \\log n$. Using the natural logarithm as specified, we can write $C_{2}(n, m) \\approx k_2 m \\ln n$ for some constant $k_2  0$, where the leading-order growth function is $m \\ln n$.\n\nTo find the sparsity threshold $m^{*}(n)$, we must determine the condition under which the adjacency-list implementation exhibits strictly smaller leading-order growth than the adjacency-matrix implementation. This entails comparing their respective growth functions:\n$$m \\ln n  n^2$$\nTo solve for $m$, we divide by $\\ln n$. For $n1$, $\\ln n  0$, so the inequality direction is preserved:\n$$m  \\frac{n^2}{\\ln n}$$\nThis inequality defines the condition on $m$ for the asymptotic superiority of the adjacency-list/heap implementation. The expression on the right-hand side represents the boundary of this condition. Therefore, the sparsity threshold $m^{*}(n)$ is defined as this boundary value. For any density where $m$ grows asymptotically slower than $m^{*}(n)$, the adjacency-list/heap implementation will have a better growth rate.\n$$m^{*}(n) = \\frac{n^2}{\\ln n}$$",
            "answer": "$$\\boxed{\\frac{n^2}{\\ln(n)}}$$"
        },
        {
            "introduction": "While finding an MST is a polynomially solvable problem, many real-world network design scenarios impose additional constraints that can make the problem significantly harder. This final exercise  introduces you to such a scenario: the Degree-Bounded MST problem, which is known to be NP-hard. You will explore a common problem-solving technique for such challenges by applying an intuitive greedy heuristic based on Kruskal's algorithm. By constructing a counterexample where this heuristic fails to find the optimal solution and quantifying its suboptimality, you will gain valuable insight into the nature of heuristics and the critical importance of understanding their limitations.",
            "id": "3151268",
            "problem": "Consider the Degree-Bounded Minimum Spanning Tree problem: given a connected, undirected, edge-weighted graph and an integer degree bound $k$, find a spanning tree whose maximum vertex degree is at most $k$ and whose total weight is minimized. A common heuristic is to run Kruskal’s algorithm but skip any edge that would increase any vertex’s degree above $k$. Kruskal’s algorithm scans edges in nondecreasing order of weight and inserts an edge if and only if doing so preserves acyclicity; in the heuristic variant, one additionally rejects an edge if it would cause any endpoint to have degree greater than $k$. A spanning tree is a connected, acyclic subgraph on all vertices, and its total weight is the sum of its edge weights.\n\nConstruct an explicit counterexample to show this heuristic can be suboptimal and quantify how far from optimal it can be on that instance as follows. Let $G=(V,E,w)$ be the undirected graph with vertex set $V=\\{A,B,C,D,E\\}$ and the following distinct positive edge weights $w$ (edges not listed are absent):\n- $w(AB)=1$, $w(BC)=2$, $w(CD)=3$, $w(BE)=4$, $w(CE)=5$,\n- $w(DE)=19$, $w(AE)=20$, $w(AC)=30$, $w(AD)=30$, $w(BD)=30$.\n\nTake the degree bound $k=2$.\n\nTasks:\n1) Apply the degree-bounded Kruskal heuristic described above to $G$ with $k=2$ and determine the total weight of the spanning tree it outputs.\n2) Determine the minimum possible total weight among all spanning trees of $G$ whose maximum degree is at most $2$.\n3) Compute the absolute difference between the heuristic’s total weight and the true minimum total weight.\n\nGive your final answer as a single exact real number (no units, no rounding).",
            "solution": "We begin from the core definitions. A spanning tree on a graph with $n$ vertices has exactly $n-1$ edges, is connected, and acyclic. Kruskal’s algorithm processes edges in nondecreasing order of weight and adds an edge if it does not create a cycle. The degree-bounded heuristic modifies this by additionally rejecting any edge that would make either endpoint’s degree exceed the bound $k$. For $k=2$, any feasible spanning tree must have maximum degree at most $2$. Every tree with maximum degree at most $2$ on $n$ vertices is a simple path on all $n$ vertices, because a tree with all degrees $\\le 2$ can have at most two vertices of degree $1$ and the rest of degree $2$, which is exactly the structure of a path.\n\nStep 1: Run the degree-bounded Kruskal heuristic on $G$ with $k=2$.\n\nList the edges in nondecreasing order of weight:\n- $AB$ with weight $1$,\n- $BC$ with weight $2$,\n- $CD$ with weight $3$,\n- $BE$ with weight $4$,\n- $CE$ with weight $5$,\n- $DE$ with weight $19$,\n- $AE$ with weight $20$,\n- $AC$ with weight $30$,\n- $AD$ with weight $30$,\n- $BD$ with weight $30$.\n\nProcess in this order while preserving acyclicity and the degree bound $k=2$:\n- Consider $AB$ ($1$): no cycle, degrees become $\\deg(A)=1$, $\\deg(B)=1$. Accept.\n- Consider $BC$ ($2$): no cycle, degrees become $\\deg(B)=2$, $\\deg(C)=1$. Accept.\n- Consider $CD$ ($3$): no cycle, degrees become $\\deg(C)=2$, $\\deg(D)=1$. Accept. The current forest is the path $A$–$B$–$C$–$D$.\n- Consider $BE$ ($4$): adding this would make $\\deg(B)=3$, violating $k=2$. Reject.\n- Consider $CE$ ($5$): adding this would make $\\deg(C)=3$, violating $k=2$. Reject.\n- Consider $DE$ ($19$): no cycle would be formed, and degrees become $\\deg(D)=2$, $\\deg(E)=1$. Accept. Now all $5$ vertices are connected with $4$ edges, so we have a spanning tree.\n\nThe heuristic’s spanning tree edges are $\\{AB,BC,CD,DE\\}$ with total weight $w_{\\text{heur}}=w(AB)+w(BC)+w(CD)+w(DE)=1+2+3+19=25$.\n\nStep 2: Find the optimal degree-bounded spanning tree for $k=2$.\n\nAs argued, any feasible tree must be a path on all $5$ vertices, i.e., $4$ edges where each internal vertex has degree $2$ and the two endpoints have degree $1$. We seek the minimum total weight among such paths using the available edges.\n\nConsider the set of edges with small weights: $AB$ ($1$), $BC$ ($2$), $CD$ ($3$), $BE$ ($4$), $CE$ ($5$). A tree on $5$ vertices has $4$ edges, so we attempt to use the cheapest four edges subject to degree $\\le 2$ and connectivity.\n\n- The four smallest edges $\\{AB,BC,CD,BE\\}$ violate the degree bound because $\\deg(B)$ would be $3$ (edges $AB$, $BC$, $BE$).\n- The set $\\{AB,BC,CD,CE\\}$ similarly violates the degree bound because $\\deg(C)$ would be $3$ (edges $BC$, $CD$, $CE$).\n\nTry $\\{AB,CD,BE,CE\\}$ with total weight $1+3+4+5=13$. The degrees are $\\deg(A)=1$ (from $AB$), $\\deg(B)=2$ (from $AB$, $BE$), $\\deg(E)=2$ (from $BE$, $CE$), $\\deg(C)=2$ (from $CE$, $CD$), $\\deg(D)=1$ (from $CD$). This forms a connected, acyclic graph on all vertices, namely the path $A$–$B$–$E$–$C$–$D$. Therefore it is feasible with maximum degree $2$ and total weight $13$.\n\nAny alternative feasible path using any edge heavier than $5$ would replace one of $1,3,4,5$ with at least $19$, increasing the total weight to at least $1+3+4+19=27$. The only other way to use only edges of weight at most $5$ is to include either $BC$ ($2$) together with both $BE$ and $CE$, which forces $\\deg(B)=3$ or $\\deg(C)=3$, violating the degree bound, as checked above. Thus, among all feasible degree-$2$ spanning trees, the minimum total weight is $w_{\\text{opt}}=13$.\n\nStep 3: Compute the absolute difference.\n\nThe requested gap is $|w_{\\text{heur}}-w_{\\text{opt}}|=|25-13|=12$.",
            "answer": "$$\\boxed{12}$$"
        }
    ]
}