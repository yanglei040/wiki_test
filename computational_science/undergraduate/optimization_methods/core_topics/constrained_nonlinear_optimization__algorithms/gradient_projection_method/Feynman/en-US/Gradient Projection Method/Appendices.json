{
    "hands_on_practices": [
        {
            "introduction": "The heart of the gradient projection method is the projection operator, $\\Pi_C$, which finds the closest point in a feasible set $C$ to a given point. This first exercise grounds your understanding by tasking you with computing a projection from first principles for a polyhedron defined by linear inequalities. By deriving and applying the Karush-Kuhn-Tucker (KKT) conditions, you will master the fundamental mechanics of how feasibility is enforced in constrained optimization .",
            "id": "3134385",
            "problem": "Consider the Euclidean projection operator onto a closed convex polyhedron $C \\subset \\mathbb{R}^{n}$ defined by $C = \\{ x \\in \\mathbb{R}^{n} : A x \\le b \\}$, where $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^{m}$. The projection of a point $z \\in \\mathbb{R}^{n}$ onto $C$ is the unique minimizer of the strictly convex quadratic optimization problem that minimizes the squared Euclidean distance to $z$ subject to the linear inequality constraints. This projection, and its first-order characterization, underpins the gradient projection method in constrained optimization. Starting from the fundamental definitions of Euclidean projection, convex sets, and the Lagrangian of a constrained optimization problem, derive the Karush-Kuhn-Tucker (KKT) conditions that characterize the projection $\\Pi_{C}(z)$. Then, use these conditions to compute the exact value of $\\Pi_{C}(z)$ for the concrete instance with $n = 2$, $m = 3$, \n$$\nA = \\begin{pmatrix}\n1  1\\\\\n-1  0\\\\\n0  -1\n\\end{pmatrix}, \n\\qquad\nb = \\begin{pmatrix}\n1\\\\\n0\\\\\n0\n\\end{pmatrix},\n\\qquad\nz = \\begin{pmatrix}\n2\\\\\n-\\frac{1}{2}\n\\end{pmatrix}.\n$$\nExpress the final answer as the projected point $\\Pi_{C}(z)$ in exact form as a $1 \\times 2$ row vector. No rounding is required, and no units are involved.",
            "solution": "The problem statement is critically validated and deemed valid. It is a well-posed problem in convex optimization, resting on established mathematical principles, and provides all necessary information for a unique solution.\n\nThe task is to find the Euclidean projection of a point $z \\in \\mathbb{R}^{n}$ onto a closed convex polyhedron $C = \\{ x \\in \\mathbb{R}^{n} : A x \\le b \\}$. By definition, the projection $\\Pi_{C}(z)$ is the unique point in $C$ that is closest to $z$. This can be formulated as a strictly convex quadratic optimization problem:\n$$\n\\begin{aligned}\n\\text{minimize}  \\quad f(x) = \\frac{1}{2} \\|x - z\\|_{2}^{2} \\\\\n\\text{subject to}  \\quad Ax \\le b\n\\end{aligned}\n$$\nThe factor of $\\frac{1}{2}$ is included for convenience as it simplifies the gradient without changing the minimizer, $x^* = \\Pi_{C}(z)$.\n\nThe constraints $Ax \\le b$ can be written component-wise as $g_i(x) = a_i^T x - b_i \\le 0$ for $i = 1, \\dots, m$, where $a_i^T$ is the $i$-th row of matrix $A$ and $b_i$ is the $i$-th component of vector $b$.\nSince the objective function $f(x)$ is convex and the constraints are linear (and thus convex), this is a convex optimization problem. Slater's condition holds if there exists a point $x_0$ such that $A x_0  b$ (strictly feasible). The existence of such a point is not guaranteed but is not necessary for strong duality for QPs. The Karush-Kuhn-Tucker (KKT) conditions are necessary and sufficient for optimality in this case.\n\nFirst, we derive the general KKT conditions. The Lagrangian function for this problem is:\n$$ L(x, \\lambda) = f(x) + \\sum_{i=1}^{m} \\lambda_i g_i(x) = \\frac{1}{2} (x-z)^T(x-z) + \\lambda^T(Ax - b) $$\nwhere $\\lambda \\in \\mathbb{R}^{m}$ is the vector of Lagrange multipliers.\n\nThe KKT conditions for a point $x^*$ to be the optimal solution are:\n1.  **Stationarity**: The gradient of the Lagrangian with respect to $x$ must be zero at the optimal point $x^*$:\n    $$ \\nabla_x L(x^*, \\lambda^*) = 0 $$\n    The gradient of the objective function is $\\nabla_x f(x) = x - z$. The gradient of the constraint term is $\\nabla_x(\\lambda^T(Ax-b)) = A^T \\lambda$.\n    Thus, the stationarity condition is:\n    $$ x^* - z + A^T \\lambda^* = 0 \\quad \\implies \\quad x^* = z - A^T \\lambda^* $$\n\n2.  **Primal Feasibility**: The optimal point $x^*$ must satisfy the problem constraints:\n    $$ A x^* \\le b $$\n\n3.  **Dual Feasibility**: The Lagrange multipliers must be non-negative:\n    $$ \\lambda^* \\ge 0 \\quad (\\text{i.e., } \\lambda_i^* \\ge 0 \\text{ for all } i = 1, \\dots, m) $$\n\n4.  **Complementary Slackness**: For each constraint, either the constraint is active (holds with equality) or the corresponding Lagrange multiplier is zero:\n    $$ \\lambda_i^*(a_i^T x^* - b_i) = 0 \\quad \\text{for all } i = 1, \\dots, m $$\n\nThese four conditions collectively characterize the projection $\\Pi_C(z) = x^*$.\n\nNext, we apply these conditions to the specific instance provided:\n$n=2$, $m=3$, and\n$$\nA = \\begin{pmatrix} 1  1\\\\ -1  0\\\\ 0  -1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}, \\quad z = \\begin{pmatrix} 2\\\\ -\\frac{1}{2} \\end{pmatrix}\n$$\nThe feasible set $C$ is defined by the following three inequalities:\n1. $x_1 + x_2 \\le 1$\n2. $-x_1 \\le 0 \\implies x_1 \\ge 0$\n3. $-x_2 \\le 0 \\implies x_2 \\ge 0$\n\nThis set is a triangle in the $x_1x_2$-plane with vertices at $(0,0)$, $(1,0)$, and $(0,1)$.\nThe point to be projected is $z = (2, -1/2)$. We check if $z$ is in $C$:\n$z_1 + z_2 = 2 - 1/2 = 3/2  1$. The first constraint is violated.\n$z_2 = -1/2  0$. The third constraint is violated.\nThus, $z \\notin C$, and the projection $x^* = \\Pi_C(z)$ must lie on the boundary of $C$.\n\nFrom the stationarity condition $x^* = z - A^T \\lambda^*$, we have:\n$$ \\begin{pmatrix} x_1^* \\\\ x_2^* \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -1/2 \\end{pmatrix} - \\begin{pmatrix} 1  -1  0 \\\\ 1  0  -1 \\end{pmatrix} \\begin{pmatrix} \\lambda_1^* \\\\ \\lambda_2^* \\\\ \\lambda_3^* \\end{pmatrix} $$\nThis gives the component-wise equations:\n$$ x_1^* = 2 - \\lambda_1^* + \\lambda_2^* $$\n$$ x_2^* = -1/2 - \\lambda_1^* + \\lambda_3^* $$\n\nWe now use the complementary slackness conditions to find the solution. We must determine which constraints are active (i.e., hold with equality) at the solution $x^*$. We can test the possible combinations of active constraints.\n\nLet's hypothesize which constraints are active based on the position of $z$. Since $z_1+z_2  1$ and $z_2  0$, it is plausible that constraints $1$ and $3$ are active.\n\n**Hypothesis: Constraints $1$ and $3$ are active.**\nThis implies $x_1^* + x_2^* = 1$ and $x_2^* = 0$. Solving this simple system gives the candidate point $x^* = (1, 0)$.\nAccording to complementary slackness, since these constraints are active, we may have $\\lambda_1^*  0$ and $\\lambda_3^*  0$. Since constraint $2$ is not assumed to be active, we must have $\\lambda_2^* = 0$.\n\nLet's check if there exist $\\lambda_1^* \\ge 0$ and $\\lambda_3^* \\ge 0$ that satisfy the stationarity conditions for $x^*=(1,0)$ and $\\lambda_2^*=0$.\nSubstitute $x_1^*=1$, $x_2^*=0$, and $\\lambda_2^*=0$ into the stationarity equations:\nFor $x_1^*$:\n$$ 1 = 2 - \\lambda_1^* + 0 \\implies \\lambda_1^* = 1 $$\nFor $x_2^*$:\n$$ 0 = -1/2 - \\lambda_1^* + \\lambda_3^* \\implies 0 = -1/2 - 1 + \\lambda_3^* \\implies \\lambda_3^* = \\frac{3}{2} $$\n\nNow we verify if this candidate solution, $x^* = (1, 0)$ and $\\lambda^* = (1, 0, 3/2)$, satisfies all KKT conditions.\n\n1.  **Stationarity**: Satisfied by construction.\n    $1 = 2 - 1 + 0 \\implies 1=1$.\n    $0 = -1/2 - 1 + 3/2 \\implies 0=0$.\n\n2.  **Primal Feasibility ($x^* \\in C$)**: We check $x^*=(1,0)$ against the constraints.\n    - $x_1^* + x_2^* = 1+0 = 1 \\le 1$. (Satisfied)\n    - $x_1^* = 1 \\ge 0$. (Satisfied)\n    - $x_2^* = 0 \\ge 0$. (Satisfied)\n    The point $x^*=(1,0)$ is in $C$.\n\n3.  **Dual Feasibility ($\\lambda^* \\ge 0$)**:\n    - $\\lambda_1^*=1 \\ge 0$. (Satisfied)\n    - $\\lambda_2^*=0 \\ge 0$. (Satisfied)\n    - $\\lambda_3^*=3/2 \\ge 0$. (Satisfied)\n    The vector $\\lambda^*$ is feasible.\n\n4.  **Complementary Slackness ($\\lambda_i^*(a_i^T x^* - b_i) = 0$)**:\n    - $\\lambda_1^*(x_1^*+x_2^*-1) = 1(1+0-1) = 0$. (Satisfied)\n    - $\\lambda_2^*(-x_1^*) = 0(-1) = 0$. (Satisfied because $\\lambda_2^*=0$)\n    - $\\lambda_3^*(-x_2^*) = (3/2)(-0) = 0$. (Satisfied)\n\nAll four KKT conditions are met. Since the optimization problem is strictly convex and the constraints are affine, satisfying the KKT conditions is both necessary and sufficient for a point to be the unique global minimum. Therefore, the projection of $z = (2, -1/2)$ onto the set $C$ is the point $x^* = (1, 0)$.\n\nThe final answer is the projected point $\\Pi_C(z) = (1,0)$, expressed as a $1 \\times 2$ row vector.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Once we know how to compute a projection, a crucial question remains: why does the algorithm work, especially for non-convex problems? This practice shifts focus from calculation to concept, asking you to analyze the behavior of a projected step at the boundary of a simple Euclidean ball . You will explore how the projection operator interacts with the gradient to ensure not only that the next iterate remains feasible, but also that it makes progress toward the minimum under appropriate conditions.",
            "id": "3134322",
            "problem": "You are given a continuously differentiable objective function $f:\\mathbb{R}^n \\to \\mathbb{R}$ with $L$-Lipschitz continuous gradient, i.e., there exists $L  0$ such that $\\|\\nabla f(x) - \\nabla f(y)\\|_2 \\le L \\|x - y\\|_2$ for all $x,y \\in \\mathbb{R}^n$. Consider the constrained problem of minimizing $f$ over the closed Euclidean ball $C = \\{x \\in \\mathbb{R}^n : \\|x\\|_2 \\le R\\}$ with $R  0$, and the gradient projection method with step $x^{+} = \\Pi_C\\big(x - \\alpha \\nabla f(x)\\big)$, where $\\Pi_C$ denotes the Euclidean projection onto $C$ and $\\alpha  0$ is a small step size. Suppose you are at a point $x \\in \\partial C$ with $\\|x\\|_2 = R$ and the objective has a negative curvature direction in a neighborhood of $x$ (that is, there exists $v \\ne 0$ with $v^\\top \\nabla^2 f(x) v  0$), while the gradient $\\nabla f(x)$ has an outward normal component at $x$ (i.e., $x^\\top \\nabla f(x)  0$). Which statement best explains how the projection resolves the instability associated with negative curvature near the boundary while preserving descent?\n\nA. The projection removes the outward normal component of the tentative step, yielding a feasible direction aligned with the tangent cone to $C$ at $x$, so the first-order change is nonpositive and, under a Lipschitz gradient, a decrease in $f$ is guaranteed for sufficiently small $\\alpha$.\n\nB. The projection flips any outward component of the step, turning ascent into descent for all $\\alpha  0$, even without any smoothness assumption on $\\nabla f$.\n\nC. The projection modifies the curvature of $f$ inside $C$ so that negative curvature disappears, effectively making the problem convex and thus always stable.\n\nD. The projection only enforces feasibility; it does not alter the descent behavior, so if the unconstrained step would be unstable due to negative curvature, the projected step is equally unstable.\n\nE. The projection always returns a boundary point, which suppresses instability by preventing escape but also eliminates any descent guarantee near the boundary.",
            "solution": "The problem statement is first validated according to the specified protocol.\n\n### Step 1: Extract Givens\n- Objective function: A continuously differentiable function $f:\\mathbb{R}^n \\to \\mathbb{R}$.\n- Gradient property: The gradient $\\nabla f(x)$ is $L$-Lipschitz continuous for some constant $L  0$, meaning $\\|\\nabla f(x) - \\nabla f(y)\\|_2 \\le L \\|x - y\\|_2$ for all $x,y \\in \\mathbb{R}^n$.\n- Constraint set: A closed Euclidean ball $C = \\{x \\in \\mathbb{R}^n : \\|x\\|_2 \\le R\\}$ with radius $R  0$.\n- Optimization problem: Minimize $f(x)$ subject to $x \\in C$.\n- Algorithm: The gradient projection method, with an update step defined as $x^{+} = \\Pi_C\\big(x - \\alpha \\nabla f(x)\\big)$. Here, $\\Pi_C$ is the Euclidean projection onto $C$ and $\\alpha  0$ is a step size.\n- Current point: $x \\in \\partial C$, which means $\\|x\\|_2 = R$.\n- Curvature condition: There exists a non-zero vector $v \\ne 0$ such that $v^\\top \\nabla^2 f(x) v  0$ (negative curvature direction at $x$).\n- Gradient orientation: The gradient at $x$ has an outward normal component, specified as $x^\\top \\nabla f(x)  0$. The outward unit normal to the ball $C$ at $x$ is $x/R$, so this condition means the gradient vector forms an acute angle with the outward normal.\n- Question: Explain how the projection operation resolves instability near the boundary while preserving descent, given the conditions on curvature and gradient orientation.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined within the mathematical field of constrained numerical optimization.\n- **Scientifically Grounded:** All concepts, including gradient projection, Lipschitz continuity, Euclidean balls, and curvature, are standard and rigorously defined in optimization theory. The setup describes a common scenario in non-convex constrained optimization.\n- **Well-Posed:** The problem asks for a conceptual explanation of a mechanism of a standard algorithm, based on a given set of conditions. It is a valid qualitative analysis problem.\n- **Objective:** The problem is stated using precise mathematical language and definitions ($x^\\top \\nabla f(x)  0$, $v^\\top \\nabla^2 f(x) v  0$). There is no subjectivity.\n- **Completeness and Consistency:** The given information is sufficient to analyze the first-order behavior of the gradient projection step. The conditions (Lipschitz gradient, point on boundary, outward-pointing gradient) are consistent and form the basis for analyzing the algorithm's local behavior. The negative curvature condition is relevant to the \"instability\" context, even though it's not directly used by the first-order projection mechanism.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. Proceeding to the solution.\n\n### Derivation and Option Analysis\n\nThe core of the problem is to understand the effect of the projection step $x^{+} = \\Pi_C(x - \\alpha \\nabla f(x))$ starting from a point $x$ on the boundary of the feasible set $C$.\n\nLet $y = x - \\alpha \\nabla f(x)$ be the tentative point after a standard gradient descent step. We are given $x \\in \\partial C$, so $\\|x\\|_2 = R$, and $x^\\top \\nabla f(x)  0$. Let's analyze the norm of $y$:\n$$ \\|y\\|_2^2 = \\|x - \\alpha \\nabla f(x)\\|_2^2 = \\|x\\|_2^2 - 2\\alpha x^\\top \\nabla f(x) + \\alpha^2 \\|\\nabla f(x)\\|_2^2 $$\nGiven $\\|x\\|_2^2 = R^2$ and $x^\\top \\nabla f(x)  0$, the term $-2\\alpha x^\\top \\nabla f(x)$ is strictly positive for $\\alpha  0$. Thus, for any $\\alpha  0$,\n$$ \\|y\\|_2^2 = R^2 + \\text{(a positive value)} + \\alpha^2 \\|\\nabla f(x)\\|_2^2  R^2 $$\nThis shows that the tentative point $y$ lies strictly outside the feasible ball $C$. The projection $\\Pi_C$ is therefore active and will map $y$ back to the boundary of $C$. The formula for projection onto a ball of radius $R$ is $\\Pi_C(y) = R \\frac{y}{\\|y\\|_2}$. So the new point is:\n$$ x^{+} = R \\frac{x - \\alpha \\nabla f(x)}{\\|x - \\alpha \\nabla f(x)\\|_2} $$\nThe \"instability\" mentioned in the problem refers to the unconstrained step leaving the feasible set. The projection operator explicitly resolves this by definition, as $x^{+}$ is guaranteed to be in $C$. The more subtle question is how it \"preserves descent\".\n\nTo analyze descent, we examine the function value $f(x^{+})$. The standard descent lemma, a consequence of the $L$-Lipschitz continuity of $\\nabla f$, states that for any two points $x_1, x_2$:\n$$ f(x_2) \\le f(x_1) + \\nabla f(x_1)^\\top (x_2 - x_1) + \\frac{L}{2} \\|x_2 - x_1\\|_2^2 $$\nApplying this with $x_1=x$ and $x_2=x^{+}$:\n$$ f(x^{+}) \\le f(x) + \\nabla f(x)^\\top (x^{+} - x) + \\frac{L}{2} \\|x^{+} - x\\|_2^2 $$\nTo guarantee descent ($f(x^{+})  f(x)$), the term $\\nabla f(x)^\\top (x^{+} - x)$ must be sufficiently negative to overcome the quadratic term. A key property of projection onto a convex set $C$ states that for any $y \\in \\mathbb{R}^n$ and $z \\in C$:\n$$ (y - \\Pi_C(y))^\\top (z - \\Pi_C(y)) \\le 0 $$\nLet $y = x - \\alpha \\nabla f(x)$, $\\Pi_C(y) = x^{+}$, and choose $z=x \\in C$. We get:\n$$ (x - \\alpha \\nabla f(x) - x^{+})^\\top (x - x^{+}) \\le 0 $$\n$$ \\|x - x^{+}\\|_2^2 - \\alpha \\nabla f(x)^\\top (x - x^{+}) \\le 0 $$\nRearranging gives a crucial inequality for the first-order term:\n$$ \\nabla f(x)^\\top (x^{+} - x) \\le -\\frac{1}{\\alpha}\\|x^{+} - x\\|_2^2 $$\nThis inequality shows that the directional derivative of $f$ in the direction of the step $(x^{+}-x)$ is non-positive. This step direction is a descent direction. Substituting this back into the descent lemma:\n$$ f(x^{+}) \\le f(x) - \\frac{1}{\\alpha}\\|x^{+} - x\\|_2^2 + \\frac{L}{2}\\|x^{+} - x\\|_2^2 $$\n$$ f(x^{+}) \\le f(x) - \\left(\\frac{1}{\\alpha} - \\frac{L}{2}\\right) \\|x^{+} - x\\|_2^2 $$\nFor a sufficiently small step size $\\alpha$ such that $\\frac{1}{\\alpha} - \\frac{L}{2}  0$ (i.e., $\\alpha  2/L$), the term multiplying $\\|x^{+} - x\\|_2^2$ is positive. As long as $x$ is not a stationary point (which would imply $x^{+} = x$), we have $\\|x^{+} - x\\|_2^2  0$ and thus a guaranteed decrease in the function value: $f(x^{+})  f(x)$.\n\nThe negative curvature condition, $v^\\top \\nabla^2 f(x) v  0$, highlights that the problem is non-convex. This condition is a primary source of instability for second-order methods (like Newton's method) but is not directly addressed by the first-order gradient projection method. The \"instability\" resolved here is the violation of feasibility constraints, and the method's stability arises from the properties of the first-order step combined with projection.\n\nFinally, the tangent cone to $C$ at $x \\in \\partial C$ is $T_C(x) = \\{d \\in \\mathbb{R}^n : x^\\top d \\le 0\\}$. The direction of the projected step is $d = x^{+} - x$. As shown in a detailed derivation (e.g., via Cauchy-Schwarz), it can be proven that $x^\\top(x^{+} - x) \\le 0$ under the given conditions, meaning the step direction lies in the tangent cone, and is thus a feasible direction.\n\nNow we evaluate the given options.\n\n**A. The projection removes the outward normal component of the tentative step, yielding a feasible direction aligned with the tangent cone to $C$ at $x$, so the first-order change is nonpositive and, under a Lipschitz gradient, a decrease in $f$ is guaranteed for sufficiently small $\\alpha$.**\nThis statement aligns perfectly with our derivation.\n- \"removes the outward normal component of the tentative step\": The projection ensures the final step does not move further outward.\n- \"yielding a feasible direction aligned with the tangent cone to $C$ at $x$\": We established that the step direction $d = x^+ - x$ satisfies $x^\\top d \\le 0$, which is the definition of the tangent cone.\n- \"first-order change is nonpositive\": We derived $\\nabla f(x)^\\top (x^{+} - x) \\le -\\frac{1}{\\alpha}\\|x^{+} - x\\|_2^2 \\le 0$.\n- \"under a Lipschitz gradient, a decrease in $f$ is guaranteed for sufficiently small $\\alpha$\": We derived $f(x^{+}) \\le f(x) - (\\frac{1}{\\alpha} - \\frac{L}{2}) \\|x^{+} - x\\|_2^2$, which ensures descent for $\\alpha  2/L$.\nThis option provides a correct and complete explanation. **Correct.**\n\n**B. The projection flips any outward component of the step, turning ascent into descent for all $\\alpha  0$, even without any smoothness assumption on $\\nabla f$.**\nThis statement contains several errors.\n- The projection does not \"flip\" components in a simple way.\n- The original unconstrained direction, $-\\nabla f(x)$, is already a descent direction. The issue is feasibility, not ascent vs. descent.\n- Descent is not guaranteed for all $\\alpha  0$; it requires a sufficiently small step size.\n- The smoothness assumption ($L$-Lipschitz gradient) is essential for the descent guarantee.\n**Incorrect.**\n\n**C. The projection modifies the curvature of $f$ inside $C$ so that negative curvature disappears, effectively making the problem convex and thus always stable.**\nThis is fundamentally flawed. The projection operator acts on points in the domain $\\mathbb{R}^n$; it does not alter the objective function $f$ or its properties like curvature ($\\nabla^2 f$). The problem remains non-convex. **Incorrect.**\n\n**D. The projection only enforces feasibility; it does not alter the descent behavior, so if the unconstrained step would be unstable due to negative curvature, the projected step is equally unstable.**\nThis is false. The projection *does* alter the step from $y-x$ to $x^{+}-x$, and this alteration is crucial for maintaining the descent property within the feasible set. The stability of the projected gradient method (in the sense of generating a feasible sequence with non-increasing function values) is a direct result of the projection, which resolves the \"instability\" of leaving the feasible set. **Incorrect.**\n\n**E. The projection always returns a boundary point, which suppresses instability by preventing escape but also eliminates any descent guarantee near the boundary.**\nThe first part is true under the specific conditions of the problem ($x$ on the boundary, gradient pointing out), but the second part is false. As shown in the derivation, the projection mechanism, combined with the Lipschitz gradient assumption, is precisely what *provides* the descent guarantee for small step sizes. **Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Theoretical knowledge is best solidified through implementation. This final practice challenges you to bridge the gap between mathematical principles and a computational experiment for the common case of box constraints, where the projection is a simple clipping operation . You will develop and verify a criterion based on the gradient, $\\nabla f(x)$, to predict which constraints will remain active during the optimization process, providing deep insight into the algorithm's dynamics and its relationship with optimality conditions.",
            "id": "3134326",
            "problem": "Consider the task of minimizing a continuously differentiable convex quadratic function $f:\\mathbb{R}^n \\to \\mathbb{R}$ over a box-constrained convex set. The objective function is $f(x) = \\tfrac{1}{2} x^\\top Q x + c^\\top x$, where $Q \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite and $c \\in \\mathbb{R}^n$. The feasible set is $[l,u] = \\{x \\in \\mathbb{R}^n : l \\le x \\le u\\}$ for given vectors $l,u \\in \\mathbb{R}^n$ satisfying $l_i \\le u_i$ for all indices $i$. Define the gradient $\\nabla f(x) = Q x + c$. The gradient projection method generates iterates by $x^{t+1} = P_{[l,u]}(x^t - \\alpha \\nabla f(x^t))$, where $P_{[l,u]}(\\cdot)$ is the Euclidean projection onto the box $[l,u]$ performed component-wise by clipping, and $\\alpha  0$ is a fixed stepsize.\n\nStarting from the core definitions of projection onto convex sets and the first-order optimality conditions for constrained convex optimization, devise and justify a principled criterion that uses the gradient to predict whether coordinates that are currently at their bounds will remain active (i.e., will stay exactly on the same bounds) at the very next iterate produced by the gradient projection method. Then implement an experiment that:\n- Detects when coordinates hit bounds (become active) during the iterations.\n- At each iteration $t$, for each coordinate $i$ that is active at either $l_i$ or $u_i$, uses your gradient-based criterion at $x^t$ to predict whether that coordinate will remain active at the next iterate $x^{t+1}$.\n- Performs the gradient projection update and verifies whether each prediction was correct.\n- Aggregates the prediction accuracy across all iterations and all active coordinates, defined as the number of correct predictions divided by the total number of predictions.\n\nUse the following test suite, which covers a general case, coupling effects, and an edge case involving zero gradient at an active coordinate. In all cases, treat a coordinate $i$ as active at the lower bound if $|x_i^t - l_i| \\le 10^{-12}$ and at the upper bound if $|x_i^t - u_i| \\le 10^{-12}$.\n\n- Test Case 1 (happy path, diagonal Hessian):\n  - Dimension $n = 3$.\n  - Matrix $Q = \\mathrm{diag}(2,3,4)$.\n  - Vector $c = \\begin{bmatrix} -2 \\\\ 1 \\\\ 0.5 \\end{bmatrix}$.\n  - Lower bounds $l = \\begin{bmatrix} 0 \\\\ -1 \\\\ -0.5 \\end{bmatrix}$.\n  - Upper bounds $u = \\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix}$.\n  - Initial point $x^0 = \\begin{bmatrix} 0 \\\\ 2 \\\\ -0.5 \\end{bmatrix}$.\n  - Stepsize $\\alpha = 0.3$.\n  - Number of iterations $T = 20$.\n\n- Test Case 2 (coupled Hessian with off-diagonal entries):\n  - Dimension $n = 4$.\n  - Matrix $Q = \\begin{bmatrix} 4  1  0  0 \\\\ 1  3  1  0 \\\\ 0  1  2  1 \\\\ 0  0  1  1.5 \\end{bmatrix}$.\n  - Vector $c = \\begin{bmatrix} 0.5 \\\\ -1 \\\\ 0 \\\\ 1 \\end{bmatrix}$.\n  - Lower bounds $l = \\begin{bmatrix} -1 \\\\ -1 \\\\ -1 \\\\ -1 \\end{bmatrix}$.\n  - Upper bounds $u = \\begin{bmatrix} 1 \\\\ 0.5 \\\\ 0.5 \\\\ 1 \\end{bmatrix}$.\n  - Initial point $x^0 = \\begin{bmatrix} 1 \\\\ 0.5 \\\\ -1 \\\\ -0.5 \\end{bmatrix}$.\n  - Stepsize $\\alpha = 0.25$.\n  - Number of iterations $T = 30$.\n\n- Test Case 3 (edge case with zero gradient at an active coordinate):\n  - Dimension $n = 3$.\n  - Matrix $Q = \\mathrm{diag}(1,1,1)$.\n  - Vector $c = \\begin{bmatrix} -1 \\\\ 0 \\\\ 1 \\end{bmatrix}$.\n  - Lower bounds $l = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$.\n  - Upper bounds $u = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$.\n  - Initial point $x^0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$.\n  - Stepsize $\\alpha = 0.5$.\n  - Number of iterations $T = 10$.\n\nYour program must:\n1. Implement the gradient projection iteration for the specified $f$, $[l,u]$, and $\\alpha$ for each test case.\n2. At each iteration and for each currently active coordinate, compute a prediction based on your gradient-based criterion about whether it will remain active at the next iterate, and then verify the prediction after performing the update.\n3. Compute the accuracy for each test case as a real number in $[0,1]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, such as $[r_1,r_2,r_3]$, where each $r_k$ is the prediction accuracy for Test Case $k$ represented as a decimal number. No other text should be printed.\n- Angles are not involved, and there are no physical units. All reported numbers must be unitless.",
            "solution": "The problem requires the derivation of a criterion to predict whether an active coordinate in a box-constrained optimization task will remain active in the next iterate of the gradient projection method. This criterion must be principled, grounded in the mechanics of the algorithm and optimization theory.\n\nThe optimization problem is to minimize a convex quadratic function $f(x) = \\frac{1}{2} x^\\top Q x + c^\\top x$ subject to the constraint $x \\in [l, u]$, where $[l, u]$ is a box defined by lower and upper bound vectors $l$ and $u$. The matrix $Q$ is symmetric positive definite, ensuring $f(x)$ is strictly convex. The gradient of the objective function is $\\nabla f(x) = Qx + c$.\n\nThe gradient projection method generates a sequence of iterates $\\{x^t\\}$ via the update rule:\n$$\nx^{t+1} = P_{[l,u]}(x^t - \\alpha \\nabla f(x^t))\n$$\nwhere $\\alpha  0$ is a fixed stepsize and $P_{[l,u]}(\\cdot)$ is the Euclidean projection onto the feasible set $[l,u]$. For a box constraint, this projection is separable and can be computed component-wise. For each coordinate $i \\in \\{1, \\dots, n\\}$, the update is:\n$$\nx_i^{t+1} = P_{[l_i, u_i]}(x_i^t - \\alpha g_i^t)\n$$\nwhere $g_i^t = (\\nabla f(x^t))_i$ is the $i$-th component of the gradient at $x^t$. The one-dimensional projection operator, also known as clipping, is defined as:\n$$\nP_{[l_i, u_i]}(y_i) = \\max(l_i, \\min(u_i, y_i))\n$$\n\nA coordinate $x_i^t$ is considered active if it lies on one of its bounds, i.e., $x_i^t = l_i$ or $x_i^t = u_i$. We need to devise a criterion using the gradient $g^t$ to predict whether $x_i^{t+1}$ will be equal to the same bound value.\n\n**Derivation of the Prediction Criterion**\n\nLet's analyze the conditions under which an active coordinate remains active.\n\n**Case 1: Coordinate $i$ is active at the lower bound.**\nSuppose at iteration $t$, coordinate $i$ is at its lower bound, so $x_i^t = l_i$. The update rule for this component becomes:\n$$\nx_i^{t+1} = \\max(l_i, \\min(u_i, l_i - \\alpha g_i^t))\n$$\nFor this coordinate to remain active at the lower bound, we must have $x_i^{t+1} = l_i$. This equality holds if and only if the argument to the outer $\\max$ function is less than or equal to $l_i$:\n$$\n\\min(u_i, l_i - \\alpha g_i^t) \\le l_i\n$$\nSince we are given that $l_i \\le u_i$, the minimum of $u_i$ and any other value can be at most $u_i$. The condition above is satisfied if the second argument of the $\\min$ function is less than or equal to $l_i$:\n$$\nl_i - \\alpha g_i^t \\le l_i\n$$\nSubtracting $l_i$ from both sides gives:\n$$\n-\\alpha g_i^t \\le 0\n$$\nSince the stepsize $\\alpha$ is strictly positive ($\\alpha  0$), we can divide by $-\\alpha$ and reverse the inequality sign:\n$$\ng_i^t \\ge 0\n$$\nTherefore, a coordinate $i$ active at its lower bound $l_i$ at iteration $t$ will remain active at $l_i$ at iteration $t+1$ if and only if the $i$-th component of the gradient, $g_i^t = (\\nabla f(x^t))_i$, is non-negative.\n\nThis criterion is intuitive. A non-negative gradient component $g_i^t \\ge 0$ at $x_i^t = l_i$ implies that the function $f$ is either stationary or increasing along coordinate $i$ into the feasible region. The gradient descent step $x_i^t - \\alpha g_i^t$ attempts to move to a value less than or equal to $l_i$. The projection operator then ensures the point remains at the boundary $l_i$.\n\n**Case 2: Coordinate $i$ is active at the upper bound.**\nNow, suppose at iteration $t$, coordinate $i$ is at its upper bound, so $x_i^t = u_i$. The update rule is:\n$$\nx_i^{t+1} = \\max(l_i, \\min(u_i, u_i - \\alpha g_i^t))\n$$\nFor this coordinate to remain active at the upper bound, we must have $x_i^{t+1} = u_i$. This occurs if the inner term $\\min(u_i, u_i - \\alpha g_i^t)$ evaluates to $u_i$. This is true if and only if:\n$$\nu_i \\le u_i - \\alpha g_i^t\n$$\nSubtracting $u_i$ from both sides gives:\n$$\n0 \\le -\\alpha g_i^t\n$$\nAgain, since $\\alpha  0$, this simplifies to:\n$$\ng_i^t \\le 0\n$$\nTherefore, a coordinate $i$ active at its upper bound $u_i$ at iteration $t$ will remain active at $u_i$ at iteration $t+1$ if and only if the $i$-th component of the gradient, $g_i^t$, is non-positive.\n\nThis criterion is also consistent with optimization principles. A non-positive gradient component $g_i^t \\le 0$ at $x_i^t = u_i$ indicates that the function is stationary or increasing as we move away from the boundary $u_i$ towards the exterior of the feasible set. A gradient descent step thus attempts to move to a value greater than or equal to $u_i$, which the projection clips back to $u_i$.\n\n**Final Criterion**\n\nThe gradient-based criterion to predict if an active coordinate remains active is as follows:\nLet $x^t$ be the current iterate and $g^t = \\nabla f(x^t)$ be the gradient. For any coordinate $i$:\n1.  If $x_i^t$ is active at the lower bound $l_i$, it is predicted to **remain active** if and only if $g_i^t \\ge 0$.\n2.  If $x_i^t$ is active at the upper bound $u_i$, it is predicted to **remain active** if and only if $g_i^t \\le 0$.\n\nThis set of conditions is directly related to the first-order necessary conditions for optimality (Karush-Kuhn-Tucker conditions) for this problem. A point $x^*$ is a local minimum only if for every coordinate $i$:\n- If $l_i  x_i^*  u_i$, then $(\\nabla f(x^*))_i = 0$.\n- If $x_i^* = l_i$, then $(\\nabla f(x^*))_i \\ge 0$.\n- If $x_i^* = u_i$, then $(\\nabla f(x^*))_i \\le 0$.\nOur criterion essentially checks if the iterate $x^t$ satisfies a portion of the optimality conditions for its active set. If it does, the gradient projection step for that coordinate is stationary.\n\nThe implementation will simulate the gradient projection method for a fixed number of iterations. At each iteration, for every coordinate identified as active (within a numerical tolerance of $10^{-12}$), it will apply the criterion above to make a prediction. It will then compute the next iterate and verify if the prediction was correct, aggregating these results to compute the overall accuracy.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_experiment(Q, c, l, u, x0, alpha, T):\n    \"\"\"\n    Runs the gradient projection experiment for a single test case.\n\n    Args:\n        Q (np.ndarray): The Hessian matrix of the quadratic term.\n        c (np.ndarray): The linear term vector.\n        l (np.ndarray): The lower bounds vector.\n        u (np.ndarray): The upper bounds vector.\n        x0 (np.ndarray): The initial point.\n        alpha (float): The stepsize.\n        T (int): The number of iterations.\n\n    Returns:\n        float: The prediction accuracy.\n    \"\"\"\n    n = len(x0)\n    x = np.array(x0, dtype=float)\n    l = np.array(l, dtype=float)\n    u = np.array(u, dtype=float)\n    Q = np.array(Q, dtype=float)\n    c = np.array(c, dtype=float)\n\n    total_predictions = 0\n    correct_predictions = 0\n    tolerance = 1e-12\n\n    for _ in range(T):\n        # 1. Calculate gradient at the current iterate x\n        grad = Q @ x + c\n\n        # 2. Identify active coordinates and make predictions\n        # A prediction is a dictionary storing info about an active coordinate\n        predictions_this_step = []\n        for i in range(n):\n            is_active_lower = np.abs(x[i] - l[i]) = tolerance\n            is_active_upper = np.abs(x[i] - u[i]) = tolerance\n            \n            predicted_will_remain = None\n            bound_type = None\n\n            if is_active_lower:\n                # Criterion for remaining at lower bound: grad_i = 0\n                predicted_will_remain = (grad[i] = 0)\n                bound_type = 'lower'\n            elif is_active_upper:\n                # Criterion for remaining at upper bound: grad_i = 0\n                predicted_will_remain = (grad[i] = 0)\n                bound_type = 'upper'\n\n            if predicted_will_remain is not None:\n                total_predictions += 1\n                predictions_this_step.append({\n                    'index': i,\n                    'predicted_will_remain': predicted_will_remain,\n                    'bound_type': bound_type\n                })\n\n        # 3. Perform the gradient projection update\n        x_unprojected = x - alpha * grad\n        x_next = np.clip(x_unprojected, l, u)\n\n        # 4. Verify predictions against the actual outcome\n        for pred_info in predictions_this_step:\n            i = pred_info['index']\n            predicted_will_remain = pred_info['predicted_will_remain']\n            bound_type = pred_info['bound_type']\n            \n            actual_remained = False\n            if bound_type == 'lower':\n                if np.abs(x_next[i] - l[i]) = tolerance:\n                    actual_remained = True\n            elif bound_type == 'upper':\n                if np.abs(x_next[i] - u[i]) = tolerance:\n                    actual_remained = True\n\n            if predicted_will_remain == actual_remained:\n                correct_predictions += 1\n                \n        # 5. Update x for the next iteration\n        x = x_next\n        \n    if total_predictions == 0:\n        # If no predictions were ever made, accuracy is vacuously 100%.\n        return 1.0\n    \n    return correct_predictions / total_predictions\n\ndef solve():\n    \"\"\"\n    Defines the test cases, runs the experiments, and prints the results.\n    \"\"\"\n    test_cases = [\n        # Test Case 1\n        {\n            \"Q\": np.diag([2.0, 3.0, 4.0]),\n            \"c\": np.array([-2.0, 1.0, 0.5]),\n            \"l\": np.array([0.0, -1.0, -0.5]),\n            \"u\": np.array([1.0, 2.0, 1.0]),\n            \"x0\": np.array([0.0, 2.0, -0.5]),\n            \"alpha\": 0.3,\n            \"T\": 20\n        },\n        # Test Case 2\n        {\n            \"Q\": np.array([\n                [4.0, 1.0, 0.0, 0.0],\n                [1.0, 3.0, 1.0, 0.0],\n                [0.0, 1.0, 2.0, 1.0],\n                [0.0, 0.0, 1.0, 1.5]\n            ]),\n            \"c\": np.array([0.5, -1.0, 0.0, 1.0]),\n            \"l\": np.array([-1.0, -1.0, -1.0, -1.0]),\n            \"u\": np.array([1.0, 0.5, 0.5, 1.0]),\n            \"x0\": np.array([1.0, 0.5, -1.0, -0.5]),\n            \"alpha\": 0.25,\n            \"T\": 30\n        },\n        # Test Case 3\n        {\n            \"Q\": np.diag([1.0, 1.0, 1.0]),\n            \"c\": np.array([-1.0, 0.0, 1.0]),\n            \"l\": np.array([0.0, 0.0, 0.0]),\n            \"u\": np.array([1.0, 1.0, 1.0]),\n            \"x0\": np.array([0.0, 0.0, 1.0]),\n            \"alpha\": 0.5,\n            \"T\": 10\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        accuracy = run_experiment(**params)\n        results.append(accuracy)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}