{
    "hands_on_practices": [
        {
            "introduction": "在应用惩罚函数法时，我们将一个约束优化问题转化为一系列无约束的子问题。为了求解这些子问题，我们通常会采用基于梯度的优化算法，例如牛顿法或拟牛顿法。因此，计算惩罚函数的梯度和Hessian矩阵是实现这些算法的基础。这个练习  将引导你运用多元微积分的知识，为通用的二次惩罚函数推导出这些关键的一阶和二阶导数。",
            "id": "3162062",
            "problem": "考虑一个二阶连续可微的目标函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$，一个二阶连续可微的等式约束向量 $h:\\mathbb{R}^{n}\\to\\mathbb{R}^{p}$，以及一个二阶连续可微的不等式约束向量 $g:\\mathbb{R}^{n}\\to\\mathbb{R}^{m}$。定义二次罚函数\n$$\nP_{\\mu}(x)\\;=\\;f(x)\\;+\\;\\frac{\\mu}{2}\\,\\|h(x)\\|^{2}\\;+\\;\\frac{\\mu}{2}\\,\\|\\max(0,\\,g(x))\\|^{2},\n$$\n其中最大值是按元素计算的，$\\mu0$，且 $\\|\\cdot\\|$ 表示欧几里得范数。令 $J_{h}(x)\\in\\mathbb{R}^{p\\times n}$ 和 $J_{g}(x)\\in\\mathbb{R}^{m\\times n}$ 分别表示由梯度 $\\nabla h_{j}(x)$ 和 $\\nabla g_{i}(x)$ 堆叠而成的雅可比矩阵，并令 $\\nabla^{2}h_{j}(x)$ 和 $\\nabla^{2}g_{i}(x)$ 表示单个约束分量的海森矩阵。假设我们处于一个点 $x$，使得对所有 $i$ 都有 $g_{i}(x)\\neq 0$；定义积极集 $A(x)=\\{\\,i\\in\\{1,\\dots,m\\}\\;|\\;g_{i}(x)0\\,\\}$，并令 $g_{A}(x)\\in\\mathbb{R}^{|A(x)|}$ 和 $J_{g_{A}}(x)\\in\\mathbb{R}^{|A(x)|\\times n}$ 表示限制在 $A(x)$ 中索引的子向量和子雅可比矩阵。\n\n从梯度、雅可比矩阵和可微函数复合的链式法则等核心定义出发，推导在此类正则点 $x$ 处梯度 $\\nabla P_{\\mu}(x)$ 和海森矩阵 $\\nabla^{2}P_{\\mu}(x)$ 的闭式表达式，用 $\\nabla f(x)$、$\\nabla^{2}f(x)$、$J_{h}(x)$、$J_{g_{A}}(x)$、$\\nabla^{2}h_{j}(x)$ 和 $\\nabla^{2}g_{i}(x)$ 表示。然后，讨论构建这些表达式所需的计算工作量如何随等式约束数量 $p$、不等式约束数量 $m$、积极集大小 $|A(x)|$ 以及决策维度 $n$ 的变化而变化，并明确指出当 $p$ 和 $|A(x)|$ 增长时，哪些项占主导地位。\n\n你的最终答案必须是梯度和海森矩阵表达式的组合，以符号形式写出。不需要数值近似，也不涉及单位。",
            "solution": "该问题要求求解二次罚函数 $P_{\\mu}(x)$ 的梯度和海森矩阵，并分析构建它们所需的计算工作量。该问题在非线性优化领域是适定的，并具有科学依据。假设对所有 $i \\in \\{1, \\dots, m\\}$ 都有 $g_i(x) \\neq 0$ 是至关重要的，因为它确保了罚函数 $P_{\\mu}(x)$ 在 $x$ 的一个邻域内是二阶连续可微的，从而保证了其梯度和海森矩阵的存在。\n\n二次罚函数定义为：\n$$\nP_{\\mu}(x)\\;=\\;f(x)\\;+\\;\\frac{\\mu}{2}\\,\\|h(x)\\|^{2}\\;+\\;\\frac{\\mu}{2}\\,\\|\\max(0,\\,g(x))\\|^{2}\n$$\n其中 $\\mu > 0$ 是罚参数。平方欧几里得范数可以写成和的形式：\n$$\n\\|h(x)\\|^{2} = \\sum_{j=1}^{p} (h_{j}(x))^{2}\n$$\n$$\n\\|\\max(0,\\,g(x))\\|^{2} = \\sum_{i=1}^{m} (\\max(0,\\,g_{i}(x)))^{2}\n$$\n根据微分的线性性质，梯度 $\\nabla P_{\\mu}(x)$ 和海森矩阵 $\\nabla^{2}P_{\\mu}(x)$ 分别是各个项的梯度之和与海森矩阵之和。\n\n**梯度 $\\nabla P_{\\mu}(x)$ 的推导**\n\n$P_{\\mu}(x)$ 的梯度为：\n$$\n\\nabla P_{\\mu}(x) = \\nabla f(x) + \\nabla \\left( \\frac{\\mu}{2} \\sum_{j=1}^{p} (h_{j}(x))^{2} \\right) + \\nabla \\left( \\frac{\\mu}{2} \\sum_{i=1}^{m} (\\max(0,\\,g_{i}(x)))^{2} \\right)\n$$\n\n1.  **等式约束惩罚项的梯度**：\n    使用链式法则，第 $j$ 个等式约束项的梯度为：\n    $$\n    \\nabla \\left( \\frac{\\mu}{2} (h_{j}(x))^{2} \\right) = \\frac{\\mu}{2} \\cdot 2 h_{j}(x) \\cdot \\nabla h_{j}(x) = \\mu h_{j}(x) \\nabla h_{j}(x)\n    $$\n    对所有 $p$ 个等式约束求和：\n    $$\n    \\nabla \\left( \\frac{\\mu}{2} \\|h(x)\\|^{2} \\right) = \\sum_{j=1}^{p} \\mu h_{j}(x) \\nabla h_{j}(x)\n    $$\n    这个和可以表示为矩阵形式。鉴于雅可比矩阵 $J_{h}(x)$ 的行是转置梯度 $(\\nabla h_{j}(x))^{T}$，这个和等价于矩阵-向量乘积 $\\mu J_{h}(x)^{T} h(x)$。\n\n2.  **不等式约束惩罚项的梯度**：\n    导数取决于 $g_{i}(x)$ 的符号。函数 $\\phi(z) = (\\max(0,z))^2$ 是连续可微的，当 $z>0$ 时 $\\phi'(z)=2z$，当 $z0$ 时 $\\phi'(z)=0$。由于我们假设对所有 $i$ 都有 $g_{i}(x) \\neq 0$，梯度是良定义的。\n    - 如果 $g_{i}(x) > 0$（即 $i \\in A(x)$），该项为 $\\frac{\\mu}{2} (g_{i}(x))^{2}$。其梯度为 $\\mu g_{i}(x) \\nabla g_{i}(x)$。\n    - 如果 $g_{i}(x)  0$（即 $i \\notin A(x)$），该项为 $0$，其梯度为零向量。\n    对所有 $m$ 个不等式约束求和，只有积极约束有贡献：\n    $$\n    \\nabla \\left( \\frac{\\mu}{2} \\|\\max(0, g(x))\\|^{2} \\right) = \\sum_{i \\in A(x)} \\mu g_{i}(x) \\nabla g_{i}(x)\n    $$\n    与等式约束情况类似，这个和可以紧凑地写为 $\\mu J_{g_{A}}(x)^{T} g_{A}(x)$，其中 $g_{A}(x)$ 是积极约束值的向量，$J_{g_{A}}(x)$ 是这些积极约束的雅可比矩阵。\n\n结合这些结果，完整的梯度为：\n$$\n\\nabla P_{\\mu}(x) = \\nabla f(x) + \\mu J_{h}(x)^{T} h(x) + \\mu J_{g_{A}}(x)^{T} g_{A}(x)\n$$\n\n**海森矩阵 $\\nabla^{2}P_{\\mu}(x)$ 的推导**\n\n海森矩阵是梯度向量的雅可比矩阵。我们对 $\\nabla P_{\\mu}(x)$ 的表达式进行微分：\n$$\n\\nabla^{2} P_{\\mu}(x) = \\nabla^{2} f(x) + \\nabla^{2} \\left( \\frac{\\mu}{2} \\|h(x)\\|^{2} \\right) + \\nabla^{2} \\left( \\frac{\\mu}{2} \\|\\max(0, g(x))\\|^{2} \\right)\n$$\n\n1.  **等式约束惩罚项的海森矩阵**：\n    我们对梯度项 $\\sum_{j=1}^{p} \\mu h_{j}(x) \\nabla h_{j}(x)$ 进行微分。对单个约束 $j$ 的项使用乘法法则进行微分：\n    $$\n    \\nabla (\\mu h_{j}(x) \\nabla h_{j}(x))^{T} = \\mu [ \\nabla h_{j}(x) (\\nabla h_{j}(x))^{T} + h_{j}(x) \\nabla^{2}h_{j}(x) ]\n    $$\n    对所有 $j=1, \\dots, p$ 求和：\n    $$\n    \\nabla^{2} \\left( \\frac{\\mu}{2} \\|h(x)\\|^{2} \\right) = \\mu \\sum_{j=1}^{p} \\left[ \\nabla h_{j}(x) (\\nabla h_{j}(x))^{T} + h_{j}(x) \\nabla^{2}h_{j}(x) \\right]\n    $$\n    和的第一部分，$\\sum_{j=1}^{p} \\nabla h_{j}(x) (\\nabla h_{j}(x))^{T}$，是矩阵乘积 $J_{h}(x)^{T} J_{h}(x)$ 的定义。因此，海森矩阵的贡献是：\n    $$\n    \\mu J_{h}(x)^{T} J_{h}(x) + \\mu \\sum_{j=1}^{p} h_{j}(x) \\nabla^{2}h_{j}(x)\n    $$\n\n2.  **不等式约束惩罚项的海森矩阵**：\n    其逻辑与等式约束情况相同，但求和仅限于积极集 $A(x)$。$g_i(x) \\neq 0$ 的假设确保了在 $x$ 的一个邻域内积极集是恒定的，使得二阶导数是良定义的。\n    $$\n    \\nabla^{2} \\left( \\frac{\\mu}{2} \\|\\max(0,g(x))\\|^{2} \\right) = \\mu \\sum_{i \\in A(x)} \\left[ \\nabla g_{i}(x) (\\nabla g_{i}(x))^{T} + g_{i}(x) \\nabla^{2}g_{i}(x) \\right]\n    $$\n    这可以写成：\n    $$\n    \\mu J_{g_{A}}(x)^{T} J_{g_{A}}(x) + \\mu \\sum_{i \\in A(x)} g_{i}(x) \\nabla^{2}g_{i}(x)\n    $$\n\n结合所有项，完整的海森矩阵为：\n$$\n\\nabla^{2}P_{\\mu}(x) = \\nabla^{2}f(x) + \\mu J_{h}(x)^{T} J_{h}(x) + \\mu \\sum_{j=1}^{p} h_{j}(x) \\nabla^{2}h_{j}(x) + \\mu J_{g_{A}}(x)^{T} J_{g_{A}}(x) + \\mu \\sum_{i \\in A(x)} g_{i}(x) \\nabla^{2}g_{i}(x)\n$$\n\n**计算工作量标度**\n\n在点 $x$ 处构建梯度和海森矩阵的计算工作量与变量数量 $n$、等式约束数量 $p$ 和不等式约束数量 $m$ 相关。令 $|A(x)|$ 为在 $x$ 处的积极不等式约束的数量。\n\n**梯度构建**：构建 $\\nabla P_{\\mu}(x)$ 需要：\n- 评估所有 $m$ 个不等式约束 $g_i(x)$ 以确定积极集 $A(x)$，其成本标度为 $O(m)$。\n- 评估目标梯度 $\\nabla f(x)$、约束向量 $h(x)$ 和 $g_{A}(x)$，以及雅可比矩阵 $J_{h}(x)$ 和 $J_{g_{A}}(x)$。评估雅可比矩阵的成本通常分别与 $O(pn)$ 和 $O(|A(x)|n)$ 成正比。\n- 执行矩阵-向量乘积 $J_{h}(x)^{T}h(x)$（成本 $O(pn)$）和 $J_{g_{A}}(x)^{T}g_{A}(x)$（成本 $O(|A(x)|n)$）。\n主要工作量的标度为 $O(m + (p+|A(x)|)n)$。成本在 $m$、$p$ 和 $|A(x)|$ 上是线性的。\n\n**海森矩阵构建**：构建 $n \\times n$ 矩阵 $\\nabla^{2}P_{\\mu}(x)$ 需要：\n- 梯度的所有计算，外加二阶导数的评估。\n- 形成矩阵乘积 $J_{h}(x)^{T}J_{h}(x)$（成本 $O(pn^{2})$）和 $J_{g_{A}}(x)^{T}J_{g_{A}}(x)$（成本 $O(|A(x)|n^{2})$）。\n- 计算 $p$ 个海森矩阵 $\\nabla^{2}h_{j}(x)$ 和 $|A(x)|$ 个海森矩阵 $\\nabla^{2}g_{i}(x)$，并形成它们的加权和。这分别需要大约 $O(pn^{2})$ 和 $O(|A(x)|n^{2})$ 的运算量。\n主要工作在于形成类外积项和单个海森矩阵的和。随着 $p$ 和 $|A(x)|$ 的增长，主导计算工作的项是矩阵乘积 $J_{h}(x)^{T}J_{h}(x)$ 和 $J_{g_{A}}(x)^{T}J_{g_{A}}(x)$，以及 $p + |A(x)|$ 个单个约束海森矩阵的计算和求和。构建海森矩阵的总体计算工作量标度为 $O((p + |A(x)|)n^{2})$。这个标度在等式约束和积极不等式约束的数量上是线性的，但在决策变量的数量上是二次的。",
            "answer": "$$\n\\boxed{\n\\begin{aligned}\n\\nabla P_{\\mu}(x) = \\nabla f(x) + \\mu J_{h}(x)^{T} h(x) + \\mu J_{g_{A}}(x)^{T} g_{A}(x) \\\\\n\\nabla^{2}P_{\\mu}(x) = \\nabla^{2}f(x) + \\mu \\left( J_{h}(x)^{T} J_{h}(x) + \\sum_{j=1}^{p} h_{j}(x) \\nabla^{2}h_{j}(x) \\right) + \\mu \\left( J_{g_{A}}(x)^{T} J_{g_{A}}(x) + \\sum_{i \\in A(x)} g_{i}(x) \\nabla^{2}g_{i}(x) \\right)\n\\end{aligned}\n}\n$$"
        },
        {
            "introduction": "在惩罚函数法中，惩罚项的选择并非无关紧要，它会显著影响算法的成败，尤其是在处理非凸问题时。这个练习  设计了一个巧妙的场景，在其中，平滑的二次惩罚法可能会被引导至一个较差的局部最优解。通过这个例子，你将亲身体会到为何非平滑但“精确”的惩罚（如 $\\ell_{1}$ 惩罚）在寻找真实约束最优解时可能更加稳健。",
            "id": "3162017",
            "problem": "考虑一个具有非凸目标的双变量等式约束最小化问题：\n最小化 $f(x,y)$，约束条件为 $g(x,y)=0$，其中\n$f(x,y)=(x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x$ 且 $g(x,y)=x$。\n该目标函数有一个以原点为中心的环形四次阱（有时称为“墨西哥帽”）和一个线性倾斜。您将比较两种用于强制执行此线性等式约束的罚函数形式。\n\n仅使用罚函数方法、一阶最优性条件和基础微积分的基本定义，完成以下任务。\n\n1) 通过消除约束并在可行集上最小化 $f$ 来精确求解该约束问题。确定全局约束最小化点的集合。\n\n2) 考虑二次罚函数 $P_{\\rho}(x,y)=f(x,y)+\\frac{\\rho}{2}\\,g(x,y)^{2}$，其中 $\\rho=\\frac{1}{10}$。证明 $P_{\\rho}$ 存在一个不可行的严格局部最小化点，并计算其目标值相对于 $P_{\\rho}$ 下最佳可行值的差。总结说明为什么对于有限的 $\\rho$，二次罚函数法会在这个非凸问题上被一个差的（不可行的）局部最小化点所吸引。\n\n3) 考虑精确 $\\ell_{1}$ 罚函数 $E_{\\mu}(x,y)=f(x,y)+\\mu\\,|g(x,y)|=f(x,y)+\\mu\\,|x|$。确定最小的值 $\\mu^{\\star}0$，使得 $E_{\\mu}$ 的每个全局最小化点都与原问题的全局约束最小化点重合。将最终答案表示为精确值（不要四舍五入）。",
            "solution": "该问题要求使用罚函数方法对一个等式约束优化问题进行三部分分析。我将首先验证问题陈述的有效性，然后按顺序解决每个部分。\n\n该问题是有效的。这是一个在优化领域中适定的数学问题。所有函数、常数和目标都得到了清晰的定义且科学上是合理的。该问题没有矛盾、歧义和无法形式化的陈述。\n\n第1部分：约束问题的精确解。\n问题是最小化目标函数 $f(x,y)=(x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x$，约束条件为等式约束 $g(x,y)=x=0$。\n\n为了解决这个问题，我们将约束 $x=0$ 直接代入目标函数。这将问题简化为单变量 $y$ 的无约束最小化问题。设约束后的目标函数为 $f_c(y)$。\n$$f_c(y) = f(0,y) = (0^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,(0) = (y^{2}-1)^{2}$$\n我们需要找到使 $f_c(y)$ 最小化的 $y$ 值。函数 $f_c(y)$ 是一个平方项，所以它的值总是非负的，即 $(y^{2}-1)^{2} \\ge 0$。可能的最小值为 $0$。当平方内的项为零时，达到这个最小值：\n$$y^{2}-1 = 0 \\implies y^{2} = 1 \\implies y = \\pm 1$$\n因此，约束目标函数的最小值为 $0$，在 $y=1$ 和 $y=-1$ 处取得。由于约束规定 $x=0$，在 $xy$ 平面上使函数最小化的点是 $(0, 1)$ 和 $(0, -1)$。\n\n全局约束最小化点的集合是 $\\{(0, 1), (0, -1)\\}$。最小目标值为 $f(0, \\pm 1)=0$。\n\n第2部分：二次罚函数法分析。\n我们考虑二次罚函数 $P_{\\rho}(x,y) = f(x,y)+\\frac{\\rho}{2}\\,g(x,y)^{2}$，罚参数为 $\\rho=\\frac{1}{10}$。\n$$P_{\\frac{1}{10}}(x,y) = (x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x + \\frac{1}{2}\\left(\\frac{1}{10}\\right)x^{2} = (x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x + \\frac{1}{20}\\,x^{2}$$\n为了找到局部最小化点，我们计算 $P_{\\frac{1}{10}}(x,y)$ 的梯度并令其为零。\n$$\\nabla P_{\\frac{1}{10}}(x,y) = \\begin{pmatrix} \\frac{\\partial P}{\\partial x} \\\\ \\frac{\\partial P}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\n偏导数为：\n$$\\frac{\\partial P}{\\partial x} = 2(x^{2}+y^{2}-1)(2x) + \\frac{1}{10} + \\frac{1}{10}x = 4x(x^{2}+y^{2}-1) + \\frac{1}{10}(1+x) = 0$$\n$$\\frac{\\partial P}{\\partial y} = 2(x^{2}+y^{2}-1)(2y) = 4y(x^{2}+y^{2}-1) = 0$$\n由第二个方程 $\\frac{\\partial P}{\\partial y}=0$ 可得两种情况：$y=0$ 或 $x^{2}+y^{2}-1=0$。\n\n情况A：$x^{2}+y^{2}-1=0$。\n将此代入 $\\frac{\\partial P}{\\partial x}=0$ 的方程中：\n$$4x(0) + \\frac{1}{10}(1+x) = 0 \\implies 1+x = 0 \\implies x=-1$$\n从 $x^{2}+y^{2}-1=0$ 可得 $(-1)^{2}+y^{2}-1=0 \\implies 1+y^{2}-1=0 \\implies y^{2}=0 \\implies y=0$。\n这给出了一个临界点 $(-1, 0)$。该点是不可行的，因为 $x=-1 \\neq 0$。\n\n情况B：$y=0$。\n将此代入 $\\frac{\\partial P}{\\partial x}=0$ 的方程中：\n$$4x(x^{2}+0^{2}-1) + \\frac{1}{10}(1+x) = 0$$\n$$4x(x^{2}-1) + \\frac{1}{10}(1+x) = 0$$\n$$4x^{3}-4x + \\frac{1}{10}x + \\frac{1}{10} = 0$$\n$$40x^{3} - 39x + 1 = 0$$\n从情况A我们知道 $x=-1$ 是一个根。我们可以对多项式进行因式分解：$(x+1)(40x^{2}-40x+1)=0$。\n根为 $x=-1$以及 $40x^{2}-40x+1=0$ 的根，由二次方程求根公式给出：\n$$x = \\frac{40 \\pm \\sqrt{1600 - 4(40)(1)}}{80} = \\frac{40 \\pm \\sqrt{1440}}{80} = \\frac{40 \\pm 12\\sqrt{10}}{80} = \\frac{10 \\pm 3\\sqrt{10}}{20}$$\n因此，当 $y=0$ 时，临界点为 $(-1, 0)$、$(\\frac{10+3\\sqrt{10}}{20}, 0)$ 和 $(\\frac{10-3\\sqrt{10}}{20}, 0)$。\n\n为了确定这些点是否为最小化点，我们使用二阶导数检验。$P_{\\frac{1}{10}}(x,y)$ 的Hessian矩阵是：\n$$H(x,y) = \\begin{pmatrix} 12x^{2}+4y^{2}-4+\\frac{1}{10}  8xy \\\\ 8xy  4x^{2}+12y^{2}-4 \\end{pmatrix}$$\n在任意点 $(x,0)$ 处，Hessian矩阵是对角的：\n$$H(x,0) = \\begin{pmatrix} 12x^{2}-4+\\frac{1}{10}  0 \\\\ 0  4x^{2}-4 \\end{pmatrix} = \\begin{pmatrix} 12x^{2}-\\frac{39}{10}  0 \\\\ 0  4x^{2}-4 \\end{pmatrix}$$\n要使一个点成为严格局部最小化点，其Hessian矩阵必须是正定的，这意味着两个对角线元素都必须为正。\n- 在点 $(-1, 0)$：$x^{2}=1$。$H_{11}=12(1)-\\frac{39}{10}=8.1 > 0$。$H_{22}=4(1)-4=0$。Hessian矩阵是半正定的。更高阶的检验可以确认这是一个严格局部最小化点。该点是不可行的。\n- 在点 $(\\frac{10+3\\sqrt{10}}{20}, 0)$：$x \\approx 0.974$，所以 $x^2  1$。因此 $H_{22} = 4x^2-4  0$。这是一个鞍点。\n- 在点 $(\\frac{10-3\\sqrt{10}}{20}, 0)$：$x \\approx 0.026$，所以 $x^2  1$ 且 $x^2  39/120$。因此 $H_{11}  0$ 且 $H_{22}  0$。这是一个局部最大化点。\n\n唯一的不可行局部最小化点是 $(-1, 0)$。\n罚函数在该最小化点的值为：\n$$P_{\\frac{1}{10}}(-1, 0) = ((-1)^{2}+0^{2}-1)^{2}+\\frac{1}{10}(-1) + \\frac{1}{20}(-1)^{2} = 0 - \\frac{1}{10} + \\frac{1}{20} = -\\frac{1}{20}$$\n$P_{\\rho}$ 的最佳可行值出现在可行集 $x=0$上。在该集合上，$P_{\\rho}(0,y)=f(0,y)$。从第1部分可知，$f(0,y)$ 的最小值为 $0$，在约束最小化点 $(0, \\pm 1)$ 处取得。\n所以，$P_{\\frac{1}{10}}$ 下的最佳可行值是 $0$。\n不可行最小化点处的目标值相对于最佳可行值的差值为：\n$$P_{\\frac{1}{10}}(-1, 0) - \\min_{y} P_{\\frac{1}{10}}(0,y) = -\\frac{1}{20} - 0 = -\\frac{1}{20}$$\n由于罚函数在不可行点 $(-1, 0)$ 处有一个局部最小值 $(-\\frac{1}{20})$，该值严格小于可行集上的最小值 ($0$)，因此对于这个有限的 $\\rho$ 值，在 $P_{\\rho}(x,y)$ 上执行无约束最小化的算法可能会收敛到这个“差的”不可行解。\n\n第3部分：精确$\\ell_{1}$罚函数法分析。\n我们考虑精确罚函数 $E_{\\mu}(x,y) = f(x,y)+\\mu|g(x,y)| = (x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x + \\mu|x|$。\n我们想找到最小的值 $\\mu^{\\star}>0$，使得 $E_{\\mu}(x,y)$ 的所有全局最小化点都是约束最小化点 $\\{(0, 1), (0, -1)\\}$。\n\n在约束最小化点 $(0, \\pm 1)$ 处，$E_{\\mu}$ 的值为 $E_{\\mu}(0, \\pm 1) = f(0, \\pm 1) + \\mu|0| = 0$。\n为了使这些点成为 $E_{\\mu}$ 的全局最小化点，我们需要对所有 $(x,y)$ 都有 $E_{\\mu}(x,y) \\ge 0$。\n$$E_{\\mu}(x,y) = (x^{2}+y^{2}-1)^{2} + \\left(\\frac{1}{10}x + \\mu|x|\\right) \\ge 0$$\n第一项 $(x^{2}+y^{2}-1)^{2}$ 总是非负的。我们需要分析第二项 $h(x) = \\frac{1}{10}x + \\mu|x|$。\n- 如果 $x>0$，$h(x) = \\frac{1}{10}x + \\mu x = (\\mu+\\frac{1}{10})x$。因为 $\\mu>0$，所以 $h(x)>0$。\n- 如果 $x0$，$h(x) = \\frac{1}{10}x - \\mu x = (\\frac{1}{10}-\\mu)x$。为了使 $h(x)$ 非负，由于 $x0$，我们需要系数 $(\\frac{1}{10}-\\mu)$ 小于或等于零。这意味着 $\\mu \\ge \\frac{1}{10}$。\n- 如果 $x=0$，$h(0)=0$。\n\n因此，对于 $\\mu \\ge \\frac{1}{10}$，项 $h(x)$ 对所有 $x$ 都是非负的。因此，$E_{\\mu}(x,y) \\ge 0$ 对所有 $(x,y)$ 都成立。\n由于我们知道 $E_{\\mu}(0,\\pm 1)=0$，因此对于任何 $\\mu \\ge \\frac{1}{10}$，$E_{\\mu}$ 的全局最小值为 $0$。\n\n全局最小化点是使 $E_{\\mu}(x,y)=0$ 的点 $(x,y)$。这要求两个非负项都为零：\n1) $(x^{2}+y^{2}-1)^{2}=0 \\implies x^{2}+y^{2}=1$。\n2) $\\frac{1}{10}x+\\mu|x|=0$。\n\n我们来研究当 $\\mu \\ge \\frac{1}{10}$ 时第二个方程的解：\n- 如果 $\\mu > \\frac{1}{10}$：对于 $x>0$，$(\\mu+\\frac{1}{10})x=0 \\implies x=0$，产生矛盾。对于 $x0$，$(\\frac{1}{10}-\\mu)x=0$。由于 $\\mu \\neq \\frac{1}{10}$，我们必须有 $x=0$，也产生矛盾。唯一的解是 $x=0$。如果 $x=0$，从条件1)可得 $0^{2}+y^{2}=1 \\implies y=\\pm 1$。全局最小化点是 $(0, 1)$ 和 $(0,-1)$。这个集合与约束最小化点集合匹配。\n\n- 如果 $\\mu = \\frac{1}{10}$：对于 $x>0$，$(\\frac{1}{10}+\\frac{1}{10})x=0 \\implies x=0$，产生矛盾。对于 $x0$，$(\\frac{1}{10}-\\frac{1}{10})x=0 \\cdot x = 0$。这对所有 $x0$ 都成立。因此对于 $\\mu=\\frac{1}{10}$，最小化点是满足条件1) $x^2+y^2=1$ 和条件 $x \\le 0$ 的点。这对应于单位圆的左半部分。这个最小化点集合是 $\\{(x,y) | x^{2}+y^{2}=1, x \\le 0\\}$，它严格大于约束最小化点集合 $\\{(0,1), (0,-1)\\}$。\n\n问题要求 $E_{\\mu}$ 的**每个**全局最小化点都是约束最小化点。这个条件当且仅当 $\\mu > \\frac{1}{10}$ 时成立。使该性质成立的 $\\mu$ 值集合是开区间 $(\\frac{1}{10}, \\infty)$。问题要求的是“最小的值 $\\mu^{\\star}>0$”。这指的是该集合的下确界，即行为发生变化的阈值。\n这个最小值是 $\\mu^{\\star} = \\frac{1}{10}$。这个值也等于原问题的拉格朗日乘子 $\\lambda^{\\star}$ 的绝对值，即 $|\\lambda^{\\star}| = |-\\frac{1}{10}| = \\frac{1}{10}$。",
            "answer": "$$\\boxed{\\frac{1}{10}}$$"
        },
        {
            "introduction": "理论的理解最好通过动手实现来巩固。这个练习  将引导你将二次惩罚法应用于一个具体的网络流问题，这是工程和物流领域中的一个常见应用。通过编写代码求解并观察当惩罚参数 $\\mu$ 增大时数值结果的变化，你将对该方法的收敛特性获得一个直观而具体的认识。",
            "id": "3162033",
            "problem": "给定一个有向网络，其节点为 $\\{0,1,2,3\\}$，有向边为 $\\{e_0,e_1,e_2,e_3,e_4\\}$，定义如下：$e_0$ 从节点 $0$ 指向节点 $1$，$e_1$ 从节点 $0$ 指向节点 $2$，$e_2$ 从节点 $1$ 指向节点 $2$，$e_3$ 从节点 $1$ 指向节点 $3$，$e_4$ 从节点 $2$ 指向节点 $3$。设流量向量为 $x \\in \\mathbb{R}^5$，其分量顺序为 $(x_{e_0},x_{e_1},x_{e_2},x_{e_3},x_{e_4})$。考虑节点 $\\{0,1,2\\}$ 处的流量守恒等式（节点 $3$ 被省略），并约定每个节点的净流出量等于其散度。在此约定下，代表节点 $\\{0,1,2\\}$ 处净流出量约束的矩阵 $A \\in \\mathbb{R}^{3 \\times 5}$ 为\n$$\nA=\\begin{bmatrix}\n1  1  0  0  0\\\\\n-1  0  1  1  0\\\\\n0  -1  -1  0  1\n\\end{bmatrix},\n$$\n散度向量为 $b \\in \\mathbb{R}^3$，且 $b=[1,0,0]^T$。对应的凸二次成本函数为\n$$\nf(x)=\\tfrac{1}{2} x^T Q x + c^T x,\n$$\n其中 $Q \\in \\mathbb{R}^{5 \\times 5}$ 是对角矩阵，对角线元素为 $\\{2,1,3,1,2\\}$，$c \\in \\mathbb{R}^5$ 等于 $[0.1,0.2,0.0,-0.1,0.1]^T$。考虑二次惩罚目标函数\n$$\nF_\\mu(x)=\\tfrac{1}{2} x^T Q x + c^T x + \\tfrac{\\mu}{2}\\lVert A x - b\\rVert_2^2,\n$$\n其中惩罚参数 $\\mu0$。\n\n从以下基本原则出发：(i) 无约束可微凸最小化问题的一阶最优性条件，即梯度等于零；(ii) 到仿射集的欧几里得投影是在线性等式约束下最小化欧几里得距离平方；以及 (iii) 为带线性等式约束的凸二次规划问题提供充分必要最优性条件的 Karush–Kuhn–Tucker (KKT) 条件，完成以下任务，过程中不得使用任何快捷公式。\n\n任务：\n- 推导 $F_\\mu(x)$ 的最小化点 $x(\\mu)$ 的平稳性条件，并将其表示为一个包含 $x(\\mu)$、$A$、$Q$、$b$、$c$ 和 $\\mu$ 的线性系统。\n- 推导到仿射集 $\\{y \\in \\mathbb{R}^5 \\mid A y = b\\}$ 上的欧几里得投影算子 $P(\\cdot)$，并通过 $A$ 和 $b$ 表示 $P(x)$。\n- 推导等式约束问题 $\\min_x f(x)$ subject to $A x = b$ 的 KKT 条件，并写出以原变量 $x^\\star$ 和拉格朗日乘子 $\\lambda^\\star$ 构成的相应线性系统。\n- 实现一个程序，该程序精确地按规定构建 $A$、$Q$、$c$ 和 $b$，然后对每个测试惩罚值 $\\mu$ 计算：\n  1. 通过求解您推导出的平稳性线性系统，得到惩罚最小化点 $x(\\mu)$。\n  2. 可行性违背量 $v(\\mu)=\\lVert A x(\\mu)-b\\rVert_2$。\n  3. 欧几里得投影 $y(\\mu)=P\\big(x(\\mu)\\big)$。\n  4. 到投影的距离 $d(\\mu)=\\lVert x(\\mu)-y(\\mu)\\rVert_2$。\n  5. 通过求解您推导出的 KKT 线性系统，得到等式约束最优点 $x^\\star$，以及目标差距 $g(\\mu)=f\\big(y(\\mu)\\big)-f\\big(x^\\star\\big)$。\n- 对惩罚参数 $\\mu$ 使用以下测试集：$\\{10^{-6},10^{-2},1,10,10^{4}\\}$。\n- 您的程序必须输出单行，其中包含一个结果列表，每个测试 $\\mu$ 对应一个结果。每个结果是一个包含三个浮点数 $[v(\\mu),d(\\mu),g(\\mu)]$ 的列表，每个浮点数四舍五入到6位小数。最终输出格式必须是单行，形式为用方括号括起来的逗号分隔列表，例如 $[\\,[v(\\mu_1),d(\\mu_1),g(\\mu_1)],\\,[v(\\mu_2),d(\\mu_2),g(\\mu_2)],\\,\\dots\\,]$。\n\n科学真实性和推导要求：\n- 所有推导都必须从上面列出的三个基本原则开始，逐步进行，不得引入任何未说明的快捷方式或直接引用目标公式。\n- 此处不涉及角度和物理单位。\n- 测试集的最终输出是浮点数列表，单行输出必须按规定将所有情况汇总到一个括号列表中。",
            "solution": "该问题是有效的。它提出了一个在凸优化领域内适定、自洽且有科学依据的问题，具体涉及用于线性约束二次规划的二次惩罚方法。所有必要的数据、定义和矩阵均已提供，任务涉及该领域的标准推导和计算。\n\n### 推导\n\n解答需要基于问题陈述中指定的基本原则进行三个核心推导。\n\n**1. 惩罚目标函数 $F_\\mu(x)$ 的平稳性条件**\n\n惩罚目标函数由下式给出\n$$F_\\mu(x)=\\tfrac{1}{2} x^T Q x + c^T x + \\tfrac{\\mu}{2}\\lVert A x - b\\rVert_2^2$$\n矩阵 $Q$ 是对角矩阵，其正对角元素为 $\\{2,1,3,1,2\\}$，因此是正定矩阵。因此，函数 $f(x)=\\tfrac{1}{2} x^T Q x + c^T x$ 是严格凸函数。对于任何 $\\mu > 0$，惩罚项 $\\tfrac{\\mu}{2}\\lVert A x - b\\rVert_2^2$ 也是凸的，因为它是一个仿射函数 $x \\mapsto Ax-b$ 和一个凸函数 $z \\mapsto \\tfrac{\\mu}{2}\\lVert z \\rVert_2^2$ 的复合。因此，对于 $\\mu>0$，$F_\\mu(x)$ 是一个严格凸且可微的函数。\n\n根据无约束凸最小化的一阶最优性条件，唯一的最小化点 $x(\\mu)$ 存在于 $F_\\mu(x)$ 相对于 $x$ 的梯度为零向量之处。\n梯度为：\n$$\\nabla F_\\mu(x) = \\nabla_x \\left( \\tfrac{1}{2} x^T Q x + c^T x \\right) + \\nabla_x \\left( \\tfrac{\\mu}{2}(A x - b)^T (A x - b) \\right)$$\n第一部分的梯度是 $\\nabla_x f(x) = Qx + c$。对于惩罚项，我们将其展开为 $\\tfrac{\\mu}{2}(x^T A^T A x - 2b^T A x + b^T b)$。这个二次型的梯度是 $\\tfrac{\\mu}{2}(2A^T A x - 2A^T b) = \\mu A^T(Ax-b)$。综合起来，$F_\\mu(x)$ 的梯度是：\n$$\\nabla F_\\mu(x) = Qx + c + \\mu A^T(Ax-b)$$\n在最优点 $x(\\mu)$ 处将梯度设为零：\n$$\\nabla F_\\mu(x(\\mu)) = Qx(\\mu) + c + \\mu A^T(Ax(\\mu)-b) = 0$$\n重新整理各项，形成关于 $x(\\mu)$ 的线性系统：\n$$Qx(\\mu) + \\mu A^T A x(\\mu) = \\mu A^T b - c$$\n$$(Q + \\mu A^T A) x(\\mu) = \\mu A^T b - c$$\n这就是表示为最小化点 $x(\\mu)$ 的线性系统的平稳性条件。由于 $Q$ 是正定的，且对于 $\\mu > 0$ 时 $\\mu A^T A$ 是半正定的，因此矩阵 $(Q + \\mu A^T A)$ 是正定的，这保证了 $x(\\mu)$ 有唯一解。\n\n**2. 欧几里得投影算子 $P(x)$**\n\n点 $x(\\mu)$ 到仿射集 $S = \\{y \\in \\mathbb{R}^5 \\mid Ay = b\\}$ 上的欧几里得投影 $y(\\mu) = P(x(\\mu))$ 是 $S$ 中使得到 $x(\\mu)$ 的欧几里得距离平方最小化的点。该问题是：\n$$\\min_{y \\in \\mathbb{R}^5} \\tfrac{1}{2} \\lVert y - x(\\mu) \\rVert_2^2 \\quad \\text{subject to} \\quad Ay = b$$\n这是一个等式约束的凸二次规划问题。Karush-Kuhn-Tucker (KKT) 条件为最优性提供了充分必要条件。设 $x$ 为待投影的点。拉格朗日函数为：\n$$L(y, \\lambda) = \\tfrac{1}{2} (y-x)^T(y-x) + \\lambda^T(Ay-b)$$\n其中 $\\lambda \\in \\mathbb{R}^3$ 是拉格朗日乘子向量。KKT 条件是：\n1.  **平稳性：** $L$ 关于 $y$ 的梯度必须为零。\n    $$\\nabla_y L(y, \\lambda) = (y-x) + A^T \\lambda = 0 \\implies y = x - A^T \\lambda$$\n2.  **原始可行性：** 必须满足约束条件。\n    $$Ay = b$$\n将平稳性条件中 $y$ 的表达式代入可行性条件：\n$$A(x - A^T \\lambda) = b$$\n$$Ax - A A^T \\lambda = b$$\n$$A A^T \\lambda = Ax - b$$\n矩阵 $A \\in \\mathbb{R}^{3 \\times 5}$ 具有满行秩（秩为 $3$），这意味着 $3 \\times 3$ 矩阵 $A A^T$ 是可逆的。我们可以解出 $\\lambda$：\n$$\\lambda = (A A^T)^{-1} (Ax - b)$$\n将这个 $\\lambda$ 代回 $y$ 的表达式，得到投影算子 $P(x)$：\n$$P(x) = y = x - A^T (A A^T)^{-1} (Ax - b)$$\n\n**3. 约束问题的 KKT 系统**\n\n原始的约束优化问题是：\n$$\\min_x f(x) = \\tfrac{1}{2} x^T Q x + c^T x \\quad \\text{subject to} \\quad Ax = b$$\n这是一个带线性等式约束的凸二次规划问题。KKT 条件是一个点 $x^\\star$ 成为唯一全局最小化点的充分必要条件。该问题的拉格朗日函数是：\n$$L(x, \\lambda) = f(x) + \\lambda^T(Ax-b) = \\tfrac{1}{2} x^T Q x + c^T x + \\lambda^T(Ax-b)$$\n最优原对偶对 $(x^\\star, \\lambda^\\star)$ 的 KKT 条件是：\n1.  **平稳性：** $L$ 关于 $x$ 的梯度为零。\n    $$\\nabla_x L(x^\\star, \\lambda^\\star) = Qx^\\star + c + A^T \\lambda^\\star = 0$$\n2.  **原始可行性：** 满足约束条件。\n    $$Ax^\\star = b$$\n这两个条件可以组合成一个单一的线性分块系统：\n$$\\begin{bmatrix} Q  A^T \\\\ A  0 \\end{bmatrix} \\begin{bmatrix} x^\\star \\\\ \\lambda^\\star \\end{bmatrix} = \\begin{bmatrix} -c \\\\ b \\end{bmatrix}$$\n其中 $0$ 是一个 $3 \\times 3$ 的零矩阵。求解该系统可得到约束最优点 $x^\\star$ 和相关的拉格朗日乘子 $\\lambda^\\star$。\n\n### 计算步骤\n\n数值实现按以下步骤进行：\n1.  按规定构建矩阵 $A$、$Q$ 和向量 $c$、$b$。\n2.  构造并求解一次约束问题的 KKT 系统，以找到最优解 $x^\\star$。此步骤与 $\\mu$ 无关。同时计算最优目标值 $f(x^\\star)$。\n3.  一个循环遍历测试集 $\\{10^{-6}, 10^{-2}, 1, 10, 10^{4}\\}$ 中的每个惩罚参数 $\\mu$。\n4.  在循环内部，对每个 $\\mu$：\n    a. 求解线性系统 $(Q + \\mu A^T A) x(\\mu) = \\mu A^T b - c$ 以找到惩罚最小化点 $x(\\mu)$。\n    b. 计算可行性违背量 $v(\\mu) = \\lVert A x(\\mu) - b \\rVert_2$。\n    c. 使用推导出的公式 $y(\\mu) = x(\\mu) - A^T (A A^T)^{-1} (A x(\\mu) - b)$ 计算投影 $y(\\mu)$。\n    d. 计算到投影的距离 $d(\\mu) = \\lVert x(\\mu) - y(\\mu) \\rVert_2$。\n    e. 计算投影点处的目标值 $f(y(\\mu))$，并确定目标差距 $g(\\mu) = f(y(\\mu)) - f(x^\\star)$。\n5.  计算出的值 $[v(\\mu), d(\\mu), g(\\mu)]$ 四舍五入到6位小数并存储。\n6.  最后，将所有 $\\mu$ 值的汇总结果格式化为指定的单行字符串表示的列表之列表。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the quadratic penalty method problem for a given set of parameters.\n    \"\"\"\n    # Define the problem data as specified.\n    A = np.array([\n        [1., 1., 0., 0., 0.],\n        [-1., 0., 1., 1., 0.],\n        [0., -1., -1., 0., 1.]\n    ])\n\n    b = np.array([1., 0., 0.])\n\n    Q = np.diag([2., 1., 3., 1., 2.])\n\n    c = np.array([0.1, 0.2, 0.0, -0.1, 0.1])\n    \n    # Test suite for the penalty parameter mu.\n    test_mus = [1e-6, 1e-2, 1, 10, 1e4]\n\n    # --- Pre-computation of the equality-constrained optimizer x_star ---\n    \n    # Form the KKT system: [[Q, A.T], [A, 0]] * [x_star, lambda_star]^T = [-c, b]^T\n    n_vars = Q.shape[0]  # Number of primal variables (5)\n    n_cons = A.shape[0]  # Number of constraints (3)\n    \n    KKT_matrix = np.zeros((n_vars + n_cons, n_vars + n_cons))\n    KKT_matrix[:n_vars, :n_vars] = Q\n    KKT_matrix[:n_vars, n_vars:] = A.T\n    KKT_matrix[n_vars:, :n_vars] = A\n    \n    KKT_rhs = np.concatenate([-c, b])\n    \n    # Solve the KKT system\n    kkt_sol = np.linalg.solve(KKT_matrix, KKT_rhs)\n    x_star = kkt_sol[:n_vars]\n\n    # Define the objective function f(x)\n    def f(x):\n        return 0.5 * x.T @ Q @ x + c.T @ x\n\n    f_star = f(x_star)\n    \n    # --- Projection Operator Pre-computation ---\n    AAT_inv = np.linalg.inv(A @ A.T)\n\n    results = []\n    \n    for mu in test_mus:\n        # 1. Compute the penalty minimizer x(mu)\n        # Solve (Q + mu * A.T @ A) * x_mu = mu * A.T @ b - c\n        M1 = Q + mu * (A.T @ A)\n        v1 = mu * (A.T @ b) - c\n        x_mu = np.linalg.solve(M1, v1)\n        \n        # 2. Compute the feasibility violation v(mu)\n        v_mu = np.linalg.norm(A @ x_mu - b)\n        \n        # 3. Compute the Euclidean projection y(mu)\n        # y_mu = x_mu - A.T @ (A @ A.T)^(-1) @ (A @ x_mu - b)\n        y_mu = x_mu - A.T @ AAT_inv @ (A @ x_mu - b)\n        \n        # 4. Compute the distance to projection d(mu)\n        d_mu = np.linalg.norm(x_mu - y_mu)\n        \n        # 5. Compute the objective gap g(mu)\n        f_y_mu = f(y_mu)\n        g_mu = f_y_mu - f_star\n        \n        # Store rounded results for the current mu\n        current_result = [round(v_mu, 6), round(d_mu, 6), round(g_mu, 6)]\n        results.append(current_result)\n\n    # Format the final output string as a list of lists.\n    # The str() of a list automatically includes brackets and spaces.\n    # The ','join will combine the string representations of the sublists.\n    # The outer f-string adds the final brackets.\n    # This precisely matches the behavior of the template and common interpretations.\n    # e.g., '[[1.0, 2.0],[3.0, 4.0]]'\n    final_output_str = f\"[{','.join(map(str, results))}]\"\n    final_output_str = final_output_str.replace(\" \", \"\")\n\n    print(final_output_str)\n\nsolve()\n\n```"
        }
    ]
}