{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在让你实践如何为一个基本问题推导拉格朗日对偶函数：在仿射子空间中寻找距离给定外部点最近的点。这个问题不仅是一个经典的几何问题，也是理解对偶性如何将一个约束问题转化为一个无约束（或更简单）对偶问题的基石。掌握此问题  将为应用拉格朗日对偶性打下坚实的基础。",
            "id": "2167450",
            "problem": "考虑将一个点投影到一个仿射子空间的问题。这等价于在子空间中找到一个点 $x$，该点与给定的外部点 $x_0$ 的欧几里得距离最近。该仿射子空间由所有满足线性系统 $Ax = b$ 的点 $x \\in \\mathbb{R}^n$ 的集合定义，其中 $A$ 是一个给定的 $m \\times n$ 矩阵，$b$ 是 $\\mathbb{R}^m$ 中的一个给定向量。外部点为 $x_0 \\in \\mathbb{R}^n$。\n\n为求此投影，我们求解以下优化问题：\n$$\n\\begin{array}{ll}\n\\text{最小化}  \\frac{1}{2}\\|x - x_0\\|_2^2 \\\\\n\\text{约束于}  Ax = b\n\\end{array}\n$$\n其中 $\\| \\cdot \\|_2$ 表示标准欧几里得范数。\n\n你的任务是求出拉格朗日对偶问题的目标函数。此对偶目标函数记为 $g(\\nu)$，它是与等式约束相关的拉格朗日乘子向量 $\\nu \\in \\mathbb{R}^m$ 的函数。请用 $\\nu$、$A$、$b$ 和 $x_0$ 将你的答案表示为符号表达式。",
            "solution": "我们为该等式约束问题构造拉格朗日函数。设约束 $Ax=b$ 的乘子为 $\\nu \\in \\mathbb{R}^{m}$，则拉格朗日函数为\n$$\nL(x,\\nu)=\\frac{1}{2}\\|x-x_{0}\\|_{2}^{2}+\\nu^{T}(Ax-b).\n$$\n为计算对偶函数 $g(\\nu)=\\inf_{x}L(x,\\nu)$，我们对 $L$ 关于 $x$ 求最小值。通过将关于 $x$ 的梯度置为零来获得驻点条件：\n$$\n\\nabla_{x}L(x,\\nu)=(x-x_{0})+A^{T}\\nu=0 \\quad \\Longrightarrow \\quad x^{\\star}(\\nu)=x_{0}-A^{T}\\nu.\n$$\n将 $x^{\\star}(\\nu)$ 代回 $L$ 中，可得\n$$\ng(\\nu)=L(x^{\\star}(\\nu),\\nu)=\\frac{1}{2}\\|x_{0}-A^{T}\\nu - x_{0}\\|_{2}^{2}+\\nu^{T}\\big(A(x_{0}-A^{T}\\nu)-b\\big).\n$$\n逐项化简，\n$$\n\\frac{1}{2}\\|x_{0}-A^{T}\\nu - x_{0}\\|_{2}^{2}=\\frac{1}{2}\\|A^{T}\\nu\\|_{2}^{2}=\\frac{1}{2}\\nu^{T}AA^{T}\\nu,\n$$\n且\n$$\n\\nu^{T}\\big(A(x_{0}-A^{T}\\nu)-b\\big)=\\nu^{T}Ax_{0}-\\nu^{T}AA^{T}\\nu-\\nu^{T}b.\n$$\n因此，\n$$\ng(\\nu)=\\frac{1}{2}\\nu^{T}AA^{T}\\nu+\\nu^{T}Ax_{0}-\\nu^{T}AA^{T}\\nu-\\nu^{T}b\n=-\\frac{1}{2}\\nu^{T}AA^{T}\\nu+\\nu^{T}(Ax_{0}-b).\n$$\n等价地，有 $g(\\nu)=-\\frac{1}{2}\\|A^{T}\\nu\\|_{2}^{2}+(Ax_{0}-b)^{T}\\nu$。",
            "answer": "$$\\boxed{-\\frac{1}{2}\\nu^{T}AA^{T}\\nu+\\nu^{T}(Ax_{0}-b)}$$"
        },
        {
            "introduction": "在掌握了仅有等式约束的问题后，本练习将我们带入一个更复杂、也更常见的场景，即同时包含等式和不等式约束。将一个点投影到概率单纯形上是机器学习和统计学中的一个常见任务。通过这个练习 ，你将学习如何处理不等式乘子，并且更重要的是，你将发现对偶公式如何揭示原始解所具有的优雅“阈值”结构。",
            "id": "3191755",
            "problem": "考虑将向量 $y \\in \\mathbb{R}^{n}$ 投影到概率单纯形 $\\Delta^{n} = \\{ x \\in \\mathbb{R}^{n} : x \\geq 0, \\ \\mathbf{1}^{\\top} x = 1 \\}$ 上的欧几里得投影问题，该问题可表示为如下凸优化问题\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2} \\| x - y \\|_{2}^{2} \\quad \\text{subject to} \\quad x \\geq 0, \\ \\mathbf{1}^{\\top} x = 1,\n$$\n其中 $\\mathbf{1} \\in \\mathbb{R}^{n}$ 表示全1向量。从拉格朗日函数和拉格朗日对偶函数的定义出发，通过对不等式乘子进行最大化来消去它们，从而推导出与等式乘子 $\\nu \\in \\mathbb{R}$ 相关的对偶函数 $g(\\nu)$。然后，描述最大化 $g(\\nu)$ 的最优标量 $\\nu$ 如何为原始最优点 $x^{\\star}$ 导出一个阈值形式。\n\n您必须从核心定义出发：拉格朗日函数、对偶函数（定义为拉格朗日函数对原始变量的下确界）以及 Karush–Kuhn–Tucker (KKT) 条件（驻点条件、原始可行性、对偶可行性和互补松弛性）。不要假设任何预先推导出的投影公式。\n\n您的最终答案必须是关于 $\\nu$ 和 $y$ 的对偶函数 $g(\\nu)$ 的单个闭式解析表达式。不需要进行数值计算。",
            "solution": "我们从以下凸优化问题开始\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2} \\| x - y \\|_{2}^{2} \\quad \\text{subject to} \\quad x \\geq 0, \\ \\mathbf{1}^{\\top} x = 1.\n$$\n为不等式约束 $x \\geq 0$ 引入拉格朗日乘子 $\\mu \\in \\mathbb{R}^{n}$，为等式约束 $\\mathbf{1}^{\\top} x = 1$ 引入拉格朗日乘子 $\\nu \\in \\mathbb{R}$。拉格朗日函数为\n$$\n\\mathcal{L}(x, \\mu, \\nu) = \\frac{1}{2} \\| x - y \\|_{2}^{2} - \\mu^{\\top} x + \\nu \\left( \\mathbf{1}^{\\top} x - 1 \\right),\n$$\n对偶可行性要求 $\\mu \\geq 0$。拉格朗日对偶函数 $g(\\mu, \\nu)$ 定义为拉格朗日函数关于原始变量 $x$ 的下确界：\n$$\ng(\\mu, \\nu) = \\inf_{x \\in \\mathbb{R}^{n}} \\ \\mathcal{L}(x, \\mu, \\nu).\n$$\n由于目标函数关于 $x$ 是严格凸的，其下确界在唯一的驻点处取得，该驻点处关于 $x$ 的梯度为零。计算驻点条件：\n$$\n\\nabla_{x} \\mathcal{L}(x, \\mu, \\nu) = x - y - \\mu + \\nu \\mathbf{1} = 0 \\quad \\Rightarrow \\quad x^{\\star}(\\mu, \\nu) = y + \\mu - \\nu \\mathbf{1}.\n$$\n将 $x^{\\star}(\\mu, \\nu)$ 代入拉格朗日函数：\n\\begin{align*}\n\\mathcal{L}\\big(x^{\\star}(\\mu, \\nu), \\mu, \\nu\\big)\n= \\frac{1}{2} \\| x^{\\star}(\\mu, \\nu) - y \\|_{2}^{2} - \\mu^{\\top} x^{\\star}(\\mu, \\nu) + \\nu \\left( \\mathbf{1}^{\\top} x^{\\star}(\\mu, \\nu) - 1 \\right) \\\\\n= \\frac{1}{2} \\| \\mu - \\nu \\mathbf{1} \\|_{2}^{2} - \\mu^{\\top} \\big( y + \\mu - \\nu \\mathbf{1} \\big) + \\nu \\big( \\mathbf{1}^{\\top} y + \\mathbf{1}^{\\top} \\mu - n \\nu - 1 \\big).\n\\end{align*}\n逐项展开并化简，\n\\begin{align*}\n\\frac{1}{2} \\| \\mu - \\nu \\mathbf{1} \\|_{2}^{2} = \\frac{1}{2} \\left( \\| \\mu \\|_{2}^{2} - 2 \\nu \\mathbf{1}^{\\top} \\mu + n \\nu^{2} \\right), \\\\\n- \\mu^{\\top} ( y + \\mu - \\nu \\mathbf{1} ) = - \\mu^{\\top} y - \\| \\mu \\|_{2}^{2} + \\nu \\mathbf{1}^{\\top} \\mu, \\\\\n\\nu ( \\mathbf{1}^{\\top} y + \\mathbf{1}^{\\top} \\mu - n \\nu - 1 ) = \\nu \\mathbf{1}^{\\top} y + \\nu \\mathbf{1}^{\\top} \\mu - n \\nu^{2} - \\nu.\n\\end{align*}\n因此，\n\\begin{align*}\ng(\\mu, \\nu)\n= \\left[ \\frac{1}{2} \\| \\mu \\|_{2}^{2} - \\nu \\mathbf{1}^{\\top} \\mu + \\frac{1}{2} n \\nu^{2} \\right]\n   + \\left[ - \\mu^{\\top} y - \\| \\mu \\|_{2}^{2} + \\nu \\mathbf{1}^{\\top} \\mu \\right]\n   + \\left[ \\nu \\mathbf{1}^{\\top} y + \\nu \\mathbf{1}^{\\top} \\mu - n \\nu^{2} - \\nu \\right] \\\\\n= - \\frac{1}{2} \\| \\mu \\|_{2}^{2} - \\mu^{\\top} y + \\nu \\mathbf{1}^{\\top} y + \\nu \\mathbf{1}^{\\top} \\mu - \\frac{1}{2} n \\nu^{2} - \\nu.\n\\end{align*}\n按分量收集各项会很方便；注意，对 $\\mu_{i}$ 的依赖是可分离的：\n$$\ng(\\mu, \\nu) = \\sum_{i=1}^{n} \\left( - \\frac{1}{2} \\mu_{i}^{2} - \\mu_{i} y_{i} + \\nu \\mu_{i} \\right) + \\nu \\left( \\sum_{i=1}^{n} y_{i} - 1 \\right) - \\frac{1}{2} n \\nu^{2}.\n$$\n对于固定的 $\\nu$，我们按分量计算 $g(\\mu, \\nu)$ 在 $\\mu \\geq 0$ 上的上确界。对每个索引 $i$，考虑关于 $\\mu_{i}$ 的凹二次函数：\n$$\n\\phi_{i}(\\mu_{i}; \\nu) = - \\frac{1}{2} \\mu_{i}^{2} - \\mu_{i} ( y_{i} - \\nu ), \\quad \\text{subject to} \\quad \\mu_{i} \\geq 0.\n$$\n无约束最大化点满足 $\\frac{\\partial \\phi_{i}}{\\partial \\mu_{i}} = - \\mu_{i} - ( y_{i} - \\nu ) = 0$，因此 $\\mu_{i}^{\\star} = - ( y_{i} - \\nu )$。施加 $\\mu_{i} \\geq 0$ 的约束得到\n$$\n\\mu_{i}^{\\star}(\\nu) = \\max\\{ 0, \\ \\nu - y_{i} \\}.\n$$\n将 $\\mu_{i}^{\\star}$ 代回 $\\phi_{i}$ 中得到\n$$\n\\sup_{\\mu_{i} \\geq 0} \\ \\phi_{i}(\\mu_{i}; \\nu)\n= \\begin{cases}\n\\frac{1}{2} ( \\nu - y_{i} )^{2},  & \\text{if } \\nu \\geq y_{i}, \\\\\n0,  & \\text{if } \\nu  y_{i},\n\\end{cases}\n= \\frac{1}{2} \\big( \\nu - y_{i} \\big)_{+}^{2},\n$$\n其中 $(a)_{+} = \\max\\{ a, 0 \\}$。因此，在对 $\\mu \\geq 0$ 最大化后，对偶函数简化为标量函数\n$$\ng(\\nu) = \\sum_{i=1}^{n} \\frac{1}{2} \\big( \\nu - y_{i} \\big)_{+}^{2} + \\nu \\left( \\sum_{i=1}^{n} y_{i} - 1 \\right) - \\frac{1}{2} n \\nu^{2}.\n$$\n这个 $g(\\nu)$ 是关于 $\\nu$ 的凹函数，因为它是若干凹函数（每个都是分段二次凹函数）的和减去一个正的二次项。\n\n我们现在使用 Karush–Kuhn–Tucker (KKT) 条件，来根据最大化 $g(\\nu)$ 的 $\\nu$ 提取出原始最优点 $x^{\\star}$。根据驻点条件，\n$$\nx^{\\star} = y + \\mu^{\\star} - \\nu^{\\star} \\mathbf{1},\n$$\n从 $\\mu^{\\star}$ 的表达式我们有按分量的结果\n$$\nx_{i}^{\\star} = y_{i} + \\max\\{ 0, \\ \\nu^{\\star} - y_{i} \\} - \\nu^{\\star} = \\max\\{ y_{i} - \\nu^{\\star}, \\ 0 \\}.\n$$\n因此 $x^{\\star} = \\big( y - \\nu^{\\star} \\mathbf{1} \\big)_{+}$，这是一个由 $\\nu^{\\star}$ 参数化的阈值规则。施加等式约束 $\\mathbf{1}^{\\top} x^{\\star} = 1$ 得到标量方程\n$$\n\\sum_{i=1}^{n} \\max\\{ y_{i} - \\nu^{\\star}, \\ 0 \\} = 1,\n$$\n在一般情况下，该方程唯一地确定了 $\\nu^{\\star}$（目标函数的严格凸性保证了唯一的 $x^{\\star}$；当多个索引在阈值处相等时，任何满足该方程的相应 $\\nu^{\\star}$ 都会产生相同的 $x^{\\star}$）。总而言之，对偶函数是上述的标量凹函数 $g(\\nu)$，而原始解是一个阈值化的向量，其阈值为 $\\nu^{\\star}$，使得各分量之和为一。\n\n要求的最终答案是 $g(\\nu)$ 的解析表达式。",
            "answer": "$$\\boxed{g(\\nu)=\\sum_{i=1}^{n}\\frac{1}{2}\\big(\\nu-y_{i}\\big)_{+}^{2}+\\nu\\left(\\sum_{i=1}^{n}y_{i}-1\\right)-\\frac{1}{2}n\\,\\nu^{2}}$$"
        },
        {
            "introduction": "拉格朗日对偶性不仅是用于分析的理论工具，它也是设计计算算法的强大组成部分。这个动手编程练习  要求你通过为一个二次规划问题实现一个原始解恢复启发式算法，从而将理论与实践联系起来。你将使用推导出的对偶函数来处理一系列对偶变量，并为原始问题构建一个高质量的可行解，这展示了对偶性在数值优化中的实际效用。",
            "id": "3191747",
            "problem": "考虑一个仅带分量非负约束的凸二次优化问题：最小化目标函数 $f(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^{\\top}\\mathbf{Q}\\,\\mathbf{x} + \\mathbf{c}^{\\top}\\mathbf{x}$，约束条件为 $\\mathbf{x} \\succeq \\mathbf{0}$，其中 $\\mathbf{Q}\\in\\mathbb{R}^{n\\times n}$ 是对称正定矩阵，$\\mathbf{c}\\in\\mathbb{R}^{n}$。不等式 $\\mathbf{x} \\succeq \\mathbf{0}$ 表示对于所有索引 $i$，$x_i \\ge 0$。对于不等式约束 $\\mathbf{A}\\mathbf{x} \\preceq \\mathbf{b}$，拉格朗日函数由基本构造 $L(\\mathbf{x},\\boldsymbol{\\lambda}) = f(\\mathbf{x}) + \\boldsymbol{\\lambda}^{\\top}(\\mathbf{A}\\mathbf{x}-\\mathbf{b})$ 定义，其中对偶变量 $\\boldsymbol{\\lambda} \\succeq \\mathbf{0}$。对于约束 $\\mathbf{x} \\succeq \\mathbf{0}$，取 $\\mathbf{A} = -\\mathbf{I}$ 和 $\\mathbf{b} = \\mathbf{0}$。拉格朗日对偶函数 $g(\\boldsymbol{\\lambda})$ 定义为 $g(\\boldsymbol{\\lambda}) = \\inf_{\\mathbf{x}} L(\\mathbf{x},\\boldsymbol{\\lambda})$，并且在 $\\boldsymbol{\\lambda} \\succeq \\mathbf{0}$ 上始终是关于 $\\boldsymbol{\\lambda}$ 的凹函数。\n\n任务：从这些定义出发，推导针对此类问题的最小化子 $\\mathbf{x}(\\boldsymbol{\\lambda}) = \\arg\\min_{\\mathbf{x}} L(\\mathbf{x},\\boldsymbol{\\lambda})$ 和对偶函数 $g(\\boldsymbol{\\lambda})$ 的表达式。然后，使用一个给定的对偶可行点序列（每个 $\\boldsymbol{\\lambda}^{k} \\succeq \\mathbf{0}$）$\\{\\boldsymbol{\\lambda}^{k}\\}_{k=1}^{K}$，实现以下原始恢复启发式算法：\n\n- 步骤 $\\mathbf{1}$：对于每个 $k \\in \\{1,\\dots,K\\}$，计算 $\\mathbf{x}(\\boldsymbol{\\lambda}^{k})$。\n- 步骤 $\\mathbf{2}$：平均原始迭代量以获得 $\\bar{\\mathbf{x}} = \\tfrac{1}{K}\\sum_{k=1}^{K} \\mathbf{x}(\\boldsymbol{\\lambda}^{k})$。\n- 步骤 $\\mathbf{3}$：将 $\\bar{\\mathbf{x}}$ 投影到可行集上，以获得恢复的原始点 $\\mathbf{x}_{\\mathrm{rec}} = \\operatorname{proj}_{\\{\\mathbf{x}\\succeq\\mathbf{0}\\}}(\\bar{\\mathbf{x}})$，其定义为 $\\mathbf{x}_{\\mathrm{rec}} = \\arg\\min_{\\mathbf{x}\\succeq\\mathbf{0}} \\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|_{2}$。对于非负约束，此投影是分量运算 $(\\mathbf{x}_{\\mathrm{rec}})_i = \\max\\{\\bar{x}_i, 0\\}$。\n- 步骤 $\\mathbf{4}$：平均对偶迭代量以获得 $\\bar{\\boldsymbol{\\lambda}} = \\tfrac{1}{K}\\sum_{k=1}^{K}\\boldsymbol{\\lambda}^{k}$。\n- 步骤 $\\mathbf{5}$：评估原始-对偶间隙值 $\\Delta = f(\\mathbf{x}_{\\mathrm{rec}}) - g(\\bar{\\boldsymbol{\\lambda}})$。\n\n使用上述步骤，为以下每个测试用例计算 $\\Delta$。每个测试用例提供 $\\mathbf{Q}$、$\\mathbf{c}$ 和序列 $\\{\\boldsymbol{\\lambda}^{k}\\}$。\n\n- 测试用例 $1$ (维度 $n=2$):\n  - $\\mathbf{Q} = \\begin{bmatrix} 2  0 \\\\ 0  1 \\end{bmatrix}$，\n  - $\\mathbf{c} = \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$，\n  - 对偶序列 $\\{\\boldsymbol{\\lambda}^{k}\\}_{k=1}^{3}$ 由 $\\boldsymbol{\\lambda}^{1} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\boldsymbol{\\lambda}^{2} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，$\\boldsymbol{\\lambda}^{3} = \\begin{bmatrix} 2 \\\\ 0.5 \\end{bmatrix}$ 给出。\n- 测试用例 $2$ (维度 $n=1$):\n  - $\\mathbf{Q} = \\begin{bmatrix} 4 \\end{bmatrix}$，\n  - $\\mathbf{c} = \\begin{bmatrix} 1 \\end{bmatrix}$，\n  - 对偶序列 $\\{\\boldsymbol{\\lambda}^{k}\\}_{k=1}^{3}$ 由 $\\boldsymbol{\\lambda}^{1} = \\begin{bmatrix} 0 \\end{bmatrix}$，$\\boldsymbol{\\lambda}^{2} = \\begin{bmatrix} 2 \\end{bmatrix}$，$\\boldsymbol{\\lambda}^{3} = \\begin{bmatrix} 4 \\end{bmatrix}$ 给出。\n- 测试用例 $3$ (维度 $n=3$):\n  - $\\mathbf{Q} = \\begin{bmatrix} 1  0  0 \\\\ 0  3  0 \\\\ 0  0  2 \\end{bmatrix}$，\n  - $\\mathbf{c} = \\begin{bmatrix} -1 \\\\ 0.5 \\\\ 2 \\end{bmatrix}$，\n  - 对偶序列 $\\{\\boldsymbol{\\lambda}^{k}\\}_{k=1}^{4}$ 由 $\\boldsymbol{\\lambda}^{1} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$，$\\boldsymbol{\\lambda}^{2} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 3 \\end{bmatrix}$，$\\boldsymbol{\\lambda}^{3} = \\begin{bmatrix} 0.5 \\\\ 1 \\\\ 0 \\end{bmatrix}$，$\\boldsymbol{\\lambda}^{4} = \\begin{bmatrix} 2 \\\\ 0.5 \\\\ 1 \\end{bmatrix}$ 给出。\n\n你的程序必须：\n- 实现你所获得的基于推导的 $\\mathbf{x}(\\boldsymbol{\\lambda})$ 和 $g(\\boldsymbol{\\lambda})$ 公式，然后为每个测试用例执行五步启发式算法。\n- 生成单行输出，其中包含一个Python风格的列表，按测试用例的顺序列出三个计算出的间隙值 $\\Delta$。例如，输出格式必须与 $[\\Delta_1,\\Delta_2,\\Delta_3]$ 完全一样，没有空格。\n- 所有数值结果必须打印为普通十进制数。此问题不涉及物理单位或角度。\n\n确保你的实现是自包含的，并且不需要外部输入。最终输出必须将所有提供的测试用例的结果聚合到指定格式的单行中。",
            "solution": "用户提出了一个在凸优化领域中定义明确的问题。任务是为一个特定类别的二次规划推导拉格朗日对偶函数，然后使用推导出的表达式来实现一个原始恢复启发式算法。问题的所有方面在科学上都是合理的、自包含的，并且在算法上是明确的。\n\n该优化问题通常被称为带非负约束的二次规划（QP），其表述如下：\n$$\n\\begin{aligned}\n \\underset{\\mathbf{x}}{\\text{minimize}}   f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} + \\mathbf{c}^{\\top}\\mathbf{x} \\\\\n \\text{subject to}   \\mathbf{x} \\succeq \\mathbf{0}\n\\end{aligned}\n$$\n其中 $\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$ 是一个对称正定矩阵，$\\mathbf{c} \\in \\mathbb{R}^{n}$，且 $\\mathbf{x} \\in \\mathbb{R}^{n}$。约束 $\\mathbf{x} \\succeq \\mathbf{0}$ 表示向量 $\\mathbf{x}$ 的每个分量 $x_i$ 都必须是非负的，即对于 $i=1, \\dots, n$，$x_i \\ge 0$。\n\n我们的第一个任务是推导拉格朗日函数的最小化子 $\\mathbf{x}(\\boldsymbol{\\lambda})$ 和相应的拉格朗日对偶函数 $g(\\boldsymbol{\\lambda})$ 的解析表达式。\n\n**步骤1：拉格朗日函数的构建**\n\n不等式约束的标准形式是 $\\mathbf{A}\\mathbf{x} \\preceq \\mathbf{b}$。给定的约束 $\\mathbf{x} \\succeq \\mathbf{0}$ 可以重写为 $-\\mathbf{x} \\preceq \\mathbf{0}$。通过确定 $\\mathbf{A} = -\\mathbf{I}$（其中 $\\mathbf{I}$ 是 $n \\times n$ 单位矩阵）和 $\\mathbf{b} = \\mathbf{0}$，我们可以为拉格朗日乘子向量 $\\boldsymbol{\\lambda} \\succeq \\mathbf{0}$ 构建拉格朗日函数 $L(\\mathbf{x}, \\boldsymbol{\\lambda})$：\n$$\nL(\\mathbf{x}, \\boldsymbol{\\lambda}) = f(\\mathbf{x}) + \\boldsymbol{\\lambda}^{\\top}(-\\mathbf{I} \\mathbf{x} - \\mathbf{0})\n$$\n代入 $f(\\mathbf{x})$ 的表达式：\n$$\nL(\\mathbf{x}, \\boldsymbol{\\lambda}) = \\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} + \\mathbf{c}^{\\top}\\mathbf{x} - \\boldsymbol{\\lambda}^{\\top}\\mathbf{x}\n$$\n该表达式可以合并为：\n$$\nL(\\mathbf{x}, \\boldsymbol{\\lambda}) = \\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} + (\\mathbf{c} - \\boldsymbol{\\lambda})^{\\top}\\mathbf{x}\n$$\n\n**步骤2：最小化子 $\\mathbf{x}(\\boldsymbol{\\lambda})$ 的推导**\n\n拉格朗日对偶函数 $g(\\boldsymbol{\\lambda})$ 定义为拉格朗日函数关于原始变量 $\\mathbf{x}$ 的下确界：\n$$\ng(\\boldsymbol{\\lambda}) = \\inf_{\\mathbf{x} \\in \\mathbb{R}^n} L(\\mathbf{x}, \\boldsymbol{\\lambda})\n$$\n拉格朗日函数 $L(\\mathbf{x}, \\boldsymbol{\\lambda})$ 是关于 $\\mathbf{x}$ 的二次函数。由于 $\\mathbf{Q}$ 是正定的，对于任何固定的 $\\boldsymbol{\\lambda}$，该函数关于 $\\mathbf{x}$ 是严格凸的。唯一的最小化子，我们记为 $\\mathbf{x}(\\boldsymbol{\\lambda})$，可以通过将拉格朗日函数关于 $\\mathbf{x}$ 的梯度设为零来找到。\n\n梯度 $\\nabla_{\\mathbf{x}} L(\\mathbf{x}, \\boldsymbol{\\lambda})$ 为：\n$$\n\\nabla_{\\mathbf{x}} L(\\mathbf{x}, \\boldsymbol{\\lambda}) = \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} + (\\mathbf{c} - \\boldsymbol{\\lambda})^{\\top}\\mathbf{x} \\right)\n$$\n使用标准矩阵微积分恒等式和 $\\mathbf{Q}$ 的对称性，我们得到：\n$$\n\\nabla_{\\mathbf{x}} L(\\mathbf{x}, \\boldsymbol{\\lambda}) = \\mathbf{Q}\\mathbf{x} + (\\mathbf{c} - \\boldsymbol{\\lambda})\n$$\n将梯度设为零向量 $\\mathbf{0}$：\n$$\n\\mathbf{Q}\\mathbf{x} + \\mathbf{c} - \\boldsymbol{\\lambda} = \\mathbf{0}\n$$\n由于 $\\mathbf{Q}$ 是正定的，它是可逆的。我们可以解出 $\\mathbf{x}$ 来找到最小化子 $\\mathbf{x}(\\boldsymbol{\\lambda})$：\n$$\n\\mathbf{Q}\\mathbf{x} = \\boldsymbol{\\lambda} - \\mathbf{c}\n$$\n$$\n\\mathbf{x}(\\boldsymbol{\\lambda}) = \\mathbf{Q}^{-1}(\\boldsymbol{\\lambda} - \\mathbf{c})\n$$\n\n**步骤3：对偶函数 $g(\\boldsymbol{\\lambda})$ 的推导**\n\n为了找到对偶函数 $g(\\boldsymbol{\\lambda})$，我们将最小化子 $\\mathbf{x}(\\boldsymbol{\\lambda})$ 的表达式代回拉格朗日函数：\n$$\ng(\\boldsymbol{\\lambda}) = L(\\mathbf{x}(\\boldsymbol{\\lambda}), \\boldsymbol{\\lambda}) = \\frac{1}{2}\\mathbf{x}(\\boldsymbol{\\lambda})^{\\top}\\mathbf{Q}\\mathbf{x}(\\boldsymbol{\\lambda}) + (\\mathbf{c} - \\boldsymbol{\\lambda})^{\\top}\\mathbf{x}(\\boldsymbol{\\lambda})\n$$\n代入 $\\mathbf{x}(\\boldsymbol{\\lambda}) = \\mathbf{Q}^{-1}(\\boldsymbol{\\lambda} - \\mathbf{c})$：\n$$\ng(\\boldsymbol{\\lambda}) = \\frac{1}{2} \\left( \\mathbf{Q}^{-1}(\\boldsymbol{\\lambda} - \\mathbf{c}) \\right)^{\\top} \\mathbf{Q} \\left( \\mathbf{Q}^{-1}(\\boldsymbol{\\lambda} - \\mathbf{c}) \\right) + (\\mathbf{c} - \\boldsymbol{\\lambda})^{\\top} \\left( \\mathbf{Q}^{-1}(\\boldsymbol{\\lambda} - \\mathbf{c}) \\right)\n$$\n让我们简化这两项。对于第一项，我们使用属性 $(AB)^{\\top} = B^{\\top}A^{\\top}$ 以及 $\\mathbf{Q}^{-1}$ 也是对称的（因为 $\\mathbf{Q}$ 是对称的）这一事实：\n$$\n\\frac{1}{2} (\\boldsymbol{\\lambda} - \\mathbf{c})^{\\top} (\\mathbf{Q}^{-1})^{\\top} \\mathbf{Q} \\mathbf{Q}^{-1} (\\boldsymbol{\\lambda} - \\mathbf{c}) = \\frac{1}{2} (\\boldsymbol{\\lambda} - \\mathbf{c})^{\\top} \\mathbf{Q}^{-1} (\\boldsymbol{\\lambda} - \\mathbf{c})\n$$\n对于第二项，我们可以写成 $(\\mathbf{c} - \\boldsymbol{\\lambda})^{\\top} = -(\\boldsymbol{\\lambda} - \\mathbf{c})^{\\top}$：\n$$\n-(\\boldsymbol{\\lambda} - \\mathbf{c})^{\\top} \\mathbf{Q}^{-1} (\\boldsymbol{\\lambda} - \\mathbf{c})\n$$\n合并两个简化后的项：\n$$\ng(\\boldsymbol{\\lambda}) = \\frac{1}{2} (\\boldsymbol{\\lambda} - \\mathbf{c})^{\\top} \\mathbf{Q}^{-1} (\\boldsymbol{\\lambda} - \\mathbf{c}) - (\\boldsymbol{\\lambda} - \\mathbf{c})^{\\top} \\mathbf{Q}^{-1} (\\boldsymbol{\\lambda} - \\mathbf{c})\n$$\n这简化为对偶函数的最终表达式：\n$$\ng(\\boldsymbol{\\lambda}) = -\\frac{1}{2}(\\boldsymbol{\\lambda} - \\mathbf{c})^{\\top}\\mathbf{Q}^{-1}(\\boldsymbol{\\lambda} - \\mathbf{c})\n$$\n\n**步骤4：原始恢复启发式算法的实现**\n\n有了推导出的 $\\mathbf{x}(\\boldsymbol{\\lambda})$ 和 $g(\\boldsymbol{\\lambda})$ 的公式，我们现在可以为每个测试用例实现问题陈述中描述的五步启发式算法。\n\n- **步骤 1**：对于给定序列 $\\{\\boldsymbol{\\lambda}^{k}\\}_{k=1}^{K}$ 中的每个对偶可行点 $\\boldsymbol{\\lambda}^{k}$，计算相应的拉格朗日函数原始最小化子：$\\mathbf{x}(\\boldsymbol{\\lambda}^{k}) = \\mathbf{Q}^{-1}(\\boldsymbol{\\lambda}^{k} - \\mathbf{c})$。\n\n- **步骤 2**：平均原始迭代量：$\\bar{\\mathbf{x}} = \\frac{1}{K}\\sum_{k=1}^{K} \\mathbf{x}(\\boldsymbol{\\lambda}^{k})$。\n\n- **步骤 3**：将平均后的原始迭代量投影到可行集 $\\{\\mathbf{x} \\mid \\mathbf{x} \\succeq \\mathbf{0}\\}$ 上。到非负象限的投影是一个分量运算：$(\\mathbf{x}_{\\mathrm{rec}})_i = \\max\\{\\bar{x}_i, 0\\}$。\n\n- **步骤 4**：平均对偶迭代量：$\\bar{\\boldsymbol{\\lambda}} = \\frac{1}{K}\\sum_{k=1}^{K} \\boldsymbol{\\lambda}^{k}$。\n\n- **步骤 5**：评估原始-对偶间隙 $\\Delta = f(\\mathbf{x}_{\\mathrm{rec}}) - g(\\bar{\\boldsymbol{\\lambda}})$。这两个分量计算如下：\n  $$\n  f(\\mathbf{x}_{\\mathrm{rec}}) = \\frac{1}{2}\\mathbf{x}_{\\mathrm{rec}}^{\\top}\\mathbf{Q}\\mathbf{x}_{\\mathrm{rec}} + \\mathbf{c}^{\\top}\\mathbf{x}_{\\mathrm{rec}}\n  $$\n  $$\n  g(\\bar{\\boldsymbol{\\lambda}}) = -\\frac{1}{2}(\\bar{\\boldsymbol{\\lambda}} - \\mathbf{c})^{\\top}\\mathbf{Q}^{-1}(\\bar{\\boldsymbol{\\lambda}} - \\mathbf{c})\n  $$\n这个过程将系统地应用于所提供的三个测试用例。对于每个用例，矩阵 $\\mathbf{Q}$ 都是对角的，这简化了其逆矩阵 $\\mathbf{Q}^{-1}$ 的计算，因为 $\\mathbf{Q}^{-1}$ 的对角线元素就是 $\\mathbf{Q}$ 对角线元素的倒数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the quadratic optimization problem for the given test cases\n    by implementing a primal recovery heuristic.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"Q\": np.array([[2, 0], [0, 1]]),\n            \"c\": np.array([1, -2]),\n            \"lambdas\": [\n                np.array([0, 0]),\n                np.array([1, 1]),\n                np.array([2, 0.5])\n            ]\n        },\n        {\n            \"Q\": np.array([[4]]),\n            \"c\": np.array([1]),\n            \"lambdas\": [\n                np.array([0]),\n                np.array([2]),\n                np.array([4])\n            ]\n        },\n        {\n            \"Q\": np.array([[1, 0, 0], [0, 3, 0], [0, 0, 2]]),\n            \"c\": np.array([-1, 0.5, 2]),\n            \"lambdas\": [\n                np.array([0, 0, 0]),\n                np.array([1, 0, 3]),\n                np.array([0.5, 1, 0]),\n                np.array([2, 0.5, 1])\n            ]\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        Q = case[\"Q\"]\n        c = case[\"c\"]\n        lambdas_k = case[\"lambdas\"]\n        K = len(lambdas_k)\n        \n        # Pre-compute the inverse of Q.\n        # For diagonal Q, inv(Q) is simple, but linalg.inv is general.\n        Q_inv = np.linalg.inv(Q)\n\n        # Step 1: For each k, compute x(lambda^k)\n        # x(lambda) = Q_inv @ (lambda - c)\n        x_k_list = [Q_inv @ (lk - c) for lk in lambdas_k]\n\n        # Step 2: Average the primal iterates\n        x_bar = np.mean(x_k_list, axis=0)\n\n        # Step 3: Project x_bar onto the feasible set {x = 0}\n        # For nonnegativity constraints, this is component-wise max(x_bar_i, 0)\n        x_rec = np.maximum(x_bar, 0)\n\n        # Step 4: Average the dual iterates\n        lambda_bar = np.mean(lambdas_k, axis=0)\n\n        # Step 5: Evaluate the primal-dual gap value Delta = f(x_rec) - g(lambda_bar)\n        \n        # Evaluate primal objective f(x_rec)\n        # f(x) = 0.5 * x.T @ Q @ x + c.T @ x\n        f_x_rec = 0.5 * x_rec.T @ Q @ x_rec + c.T @ x_rec\n        \n        # Evaluate dual function g(lambda_bar)\n        # g(lambda) = -0.5 * (lambda - c).T @ Q_inv @ (lambda - c)\n        g_lambda_bar = -0.5 * (lambda_bar - c).T @ Q_inv @ (lambda_bar - c)\n        \n        delta = f_x_rec - g_lambda_bar\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    # Convert numerical results to plain decimal numbers.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}