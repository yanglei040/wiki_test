{
    "hands_on_practices": [
        {
            "introduction": "第一个实践将处理数值误差最常见的来源之一：灾难性抵消。我们将探索一个在数学上表现良好，但在输入值几乎相等时数值不稳定的函数。然后，我们将使用一个简单的代数技巧——乘以共轭表达式——来创建一个稳健的算法。这个练习清晰地、动手地展示了如何识别并修正这一基本的数值陷阱。",
            "id": "2420071",
            "problem": "要求您为某个函数设计并实现一个数值稳定的求值策略，该函数在平面上一条细对角线附近会表现出灾难性抵消。考虑一个为实数输入 $x$ 和 $y$ 定义的标量函数，首先构造 $t = x - y$，然后是朴素表达式\n$$\nf_{\\text{naive}}(x,y) \\equiv \\frac{\\sqrt{1 + t} - 1}{t},\n$$\n该表达式仅在 $1 + t \\ge 0$ 的情况下有定义。沿着对角线 $y = x$，这个朴素表达式会变成 $0/0$ 并产生一个非数值 (Not a Number)，而当 $t$ 非常接近 $0$ 时，其分子会遭受灾难性抵消。\n\n您的任务是：\n- 基于有限精度算术遵循电气和电子工程师协会 (Institute of Electrical and Electronics Engineers, IEEE) 浮点算术标准 (IEEE 754) 的舍入模型，以及灾难性抵消是关于几乎相等的浮点数相减时发生抵消的定义，推导出一个对 $f(x,y)$ 进行数值稳定求值的方法，该方法：\n  1. 在 $1 + (x - y) \\ge 0$ 时，与数学上正确的值一致。\n  2. 在对角线 $y = x$ 上，即 $t = 0$ 时，返回正确的极限值。\n  3. 对于满足 $1 + (x - y) \\ge 0$ 的任何 $(x,y)$，避免产生非数值 (Not a Number)。\n- 为给定的测试套件用代码实现此稳定策略，并生成稳定化后的函数值作为程序的唯一输出。\n\n使用以下有序对 $(x,y)$ 的测试套件，该套件旨在精确测试对角线 $y=x$、从两侧逼近它、测试边界 $t = -1$ 附近的行为，并覆盖小幅值和大幅值的情况：\n- $(1, 1)$\n- $(1 + 10^{-16}, 1)$\n- $(1 - 10^{-16}, 1)$\n- $(0, 0)$\n- $(10^{-12}, 0)$\n- $(0, 10^{-12})$\n- $(2, 1)$\n- $(0, 1)$\n- $(10^{8}, 0)$\n- $(0, 0.999999999)$\n\n您的程序必须在定义域条件 $1 + (x - y) \\ge 0$ 下，按给定顺序为上述每个输入计算 $f(x,y)$ 的稳定化值。如果在您的推导中出现任何角度，都必须以弧度为单位，但此处不需要角度。不涉及物理单位。最终输出格式必须是单行，包含一个由方括号括起来的、包含 $10$ 个稳定化结果的逗号分隔列表。每个数字必须以 $15$ 位有效数字的浮点值形式打印，例如，\n[\\dots]\n且无任何附加文本。如果任何测试点在定义域 $1 + (x - y) \\ge 0$ 之外，您应在该处输出一个非数值 (Not a Number)，但所列出的所有测试都满足定义域条件，因此您的输出必须全部是有效的有限数。",
            "solution": "该问题要求为函数\n$$\nf_{\\text{naive}}(x,y) = \\frac{\\sqrt{1 + t} - 1}{t}\n$$\n推导并实现一个数值稳定的算法，其中 $t = x - y$，且定义域限制在 $1 + t \\ge 0$。\n\n分析始于识别数值不稳定性的来源。问题陈述朴素表达式在 $t$ 非常接近 $0$ 时会遭受灾难性抵消。这是因为当 $t \\approx 0$ 时，项 $\\sqrt{1 + t}$ 非常接近 $1$。根据浮点算术原理（IEEE 754 标准），两个几乎相等的数 $\\sqrt{1+t}$ 和 $1$ 相减会导致有效数字的损失。结果值带有很大的相对误差，这个误差在除以小数 $t$ 时被放大。\n\n为了构建一个稳定的替代方案，我们必须找到一个在数学上等价且能避免这种减法抵消的表达式。对于涉及平方根的表达式，一种标准而有效的方法是乘以其共轭式。分子 $\\sqrt{1 + t} - 1$ 的共轭式是 $\\sqrt{1 + t} + 1$。我们将分子和分母同乘以这个共轭式，对于 $t \\neq 0$ 这不会改变表达式的值：\n$$\nf(t) = \\frac{\\sqrt{1 + t} - 1}{t} \\times \\frac{\\sqrt{1 + t} + 1}{\\sqrt{1 + t} + 1}\n$$\n对分子应用平方差公式 $(a-b)(a+b) = a^2 - b^2$ 可得：\n$$\nf(t) = \\frac{(\\sqrt{1 + t})^2 - 1^2}{t(\\sqrt{1 + t} + 1)} = \\frac{(1 + t) - 1}{t(\\sqrt{1 + t} + 1)} = \\frac{t}{t(\\sqrt{1 + t} + 1)}\n$$\n对于任何 $t \\neq 0$，我们可以约去分子和分母中的因子 $t$，从而得到稳定化的表达式：\n$$\nf_{\\text{stable}}(t) = \\frac{1}{\\sqrt{1 + t} + 1}\n$$\n这个表达式 $f_{\\text{stable}}(t)$ 在数值上是鲁棒的。当 $t \\approx 0$ 时，分母涉及两个正数 $\\sqrt{1 + t}$ 和 $1$ 的相加，这是一个数值稳定的运算。这里没有几乎相等的量相减。因此，该形式适合在整个定义域内进行计算，尤其是对于接近 $0$ 的 $t$。\n\n问题还要求函数在对角线 $y = x$（对应于 $t=0$）上返回正确的极限值。在 $t=0$ 时，朴素表达式是 $0/0$ 的不定式。我们可以使用 L'Hôpital's rule 求极限：\n$$\n\\lim_{t \\to 0} f_{\\text{naive}}(t) = \\lim_{t \\to 0} \\frac{\\frac{d}{dt}(\\sqrt{1 + t} - 1)}{\\frac{d}{dt}(t)} = \\lim_{t \\to 0} \\frac{\\frac{1}{2\\sqrt{1 + t}}}{1} = \\frac{1}{2\\sqrt{1 + 0}} = \\frac{1}{2}\n$$\n直接在 $t=0$ 处计算我们的稳定表达式可得：\n$$\nf_{\\text{stable}}(0) = \\frac{1}{\\sqrt{1 + 0} + 1} = \\frac{1}{1 + 1} = \\frac{1}{2}\n$$\n这证实了稳定化公式在 $t=0$ 时能正确计算出极限值。因此，它能处理对角线 $y=x$ 的情况，既不会产生 `Not a Number`，也不需要针对 $t=0$ 设置特殊的条件语句。\n\n推导出的表达式 $f_{\\text{stable}}(t)$ 在整个定义域 $1 + t \\ge 0$ 上都是数值稳健的。对于远离 $0$ 的 $t$ 值，它在数学上仍然等价且在计算上是准确的。对于靠近边界 $t=-1$ 的值，例如当某个小的 $\\epsilon > 0$ 时有 $t = -1 + \\epsilon$，分母变为 $\\sqrt{\\epsilon} + 1$，这是良态的。特别地，在边界点 $t = -1$ 处，函数值为 $f_{\\text{stable}}(-1) = \\frac{1}{\\sqrt{1-1}+1} = \\frac{1}{0+1} = 1$，这是当 $t \\to -1^{+}$ 时的正确极限。\n\n因此，对于所有满足 $1 + (x - y) \\ge 0$ 的 $(x,y)$，单一的、全局稳定的求值策略是先计算 $t = x - y$，然后计算表达式：\n$$\nf(x,y) = \\frac{1}{\\sqrt{1 + t} + 1}\n$$\n这一个公式满足了问题陈述的所有条件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes numerically stable values for the function f(x,y).\n    The naive form is f_naive = (sqrt(1 + t) - 1) / t, where t = x - y.\n    This suffers from catastrophic cancellation when t is near 0.\n    The stable form, derived by multiplying by the conjugate, is:\n    f_stable = 1 / (sqrt(1 + t) + 1).\n    This form is used for all calculations as it is robust across the valid domain.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # The case (0, 10^{-12}) is interpreted as x=0.0, y=1e-12.\n    test_cases = [\n        (1.0, 1.0),\n        (1.0 + 1e-16, 1.0),\n        (1.0 - 1e-16, 1.0),\n        (0.0, 0.0),\n        (1e-12, 0.0),\n        (0.0, 1e-12),\n        (2.0, 1.0),\n        (0.0, 1.0),\n        (1e8, 0.0),\n        (0.0, 0.999999999),\n    ]\n\n    results = []\n    for x, y in test_cases:\n        # Calculate t = x - y\n        t = x - y\n        \n        # The domain condition 1 + t >= 0 is guaranteed by the problem statement.\n        # Use the numerically stable formula derived in the solution.\n        # This formula is valid and stable for all t in the domain, including t=0.\n        stable_value = 1.0 / (np.sqrt(1.0 + t) + 1.0)\n        results.append(stable_value)\n\n    # Final print statement in the exact required format.\n    # The format specifier '.15g' prints up to 15 significant digits.\n    print(f\"[{','.join(f'{r:.15g}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "数值方法常常涉及权衡。本实践将超越简单地修复不稳定性，转而探索如何在两种相互竞争的误差源之间找到最佳平衡：源于数学近似的截断误差，以及源于有限精度计算的舍入误差。通过确定有限差分公式的理想步长 $h$，你将学习如何最小化总误差，并体会数值优化这门精妙的艺术。",
            "id": "2420015",
            "problem": "考虑使用三点中心差分公式\n$$\nD(h) = \\frac{f(1.0+h) - f(1.0-h)}{2h}.\n$$\n来近似函数 $f(x) = \\sin(x)$ 在点 $x = 1.0$ 处的导数。\n假设所有算术运算都根据 Institute of Electrical and Electronics Engineers (IEEE) $754$ 标准在浮点数下进行，采用舍入到最近的规则，单位舍入误差为 $u = 2^{-53}$。进一步假设，基本函数 $\\sin(\\cdot)$ 的每次调用都遵循标准浮点模型，因此其计算值 $\\widetilde{\\sin}(y)$ 满足 $\\widetilde{\\sin}(y) = \\sin(y)\\,(1+\\delta)$，其中 $|\\delta| \\le u$，并且每次基本算术运算都满足相同的相对误差界。设 $h$ 足够小，以至于 $h$ 和 $u$ 的主阶项起主导作用，并以弧度为单位计算 $\\sin$ 和 $\\cos$。确定步长 $h$ 的值，该值使得在 $x=1.0$ 处计算 $D(h)$ 时，由截断误差和舍入误差的综合效应引起的绝对误差的主阶界最小。提供 $h$ 的单个数值。将您的答案四舍五入至 $4$ 位有效数字。该答案是无量纲的。",
            "solution": "问题陈述已经过验证，被认为是具有科学依据、适定且客观的。这是一个关于截断误差和舍入误差之间平衡的数值分析标准问题。我们将进行正式求解。\n\n使用中心差分公式的计算值 $\\widetilde{D}(h)$ 来近似导数 $f'(x)$ 的总绝对误差，其上界为截断误差和舍入误差之和：\n$$\n|\\widetilde{D}(h) - f'(x)| \\le |D(h) - f'(x)| + |\\widetilde{D}(h) - D(h)|\n$$\n第一项 $|D(h) - f'(x)|$ 表示截断误差 $E_{\\text{trunc}}(h)$，这是有限差分公式所固有的。第二项 $|\\widetilde{D}(h) - D(h)|$ 是舍入误差 $E_{\\text{round}}(h)$，它由浮点运算产生。\n\n首先，我们分析截断误差。函数 $f(x)$ 导数的三点中心差分公式由下式给出：\n$$\nD(h) = \\frac{f(x+h) - f(x-h)}{2h}\n$$\n我们使用 $f(x+h)$ 和 $f(x-h)$ 在点 $x$ 附近的泰勒级数展开：\n$$\nf(x+h) = f(x) + h f'(x) + \\frac{h^2}{2} f''(x) + \\frac{h^3}{6} f'''(x) + \\frac{h^4}{24} f^{(4)}(x) + \\frac{h^5}{120} f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x-h) = f(x) - h f'(x) + \\frac{h^2}{2} f''(x) - \\frac{h^3}{6} f'''(x) + \\frac{h^4}{24} f^{(4)}(x) - \\frac{h^5}{120} f^{(5)}(x) + O(h^6)\n$$\n第一个展开式减去第二个展开式可得：\n$$\nf(x+h) - f(x-h) = 2h f'(x) + \\frac{h^3}{3} f'''(x) + \\frac{h^5}{60} f^{(5)}(x) + O(h^7)\n$$\n将此结果代入 $D(h)$ 的公式：\n$$\nD(h) = \\frac{2h f'(x) + \\frac{h^3}{3} f'''(x) + O(h^5)}{2h} = f'(x) + \\frac{h^2}{6} f'''(x) + O(h^4)\n$$\n截断误差为 $E_{\\text{trunc}}(h) = |D(h) - f'(x)|$。该误差的主阶项为：\n$$\nE_{\\text{trunc}}(h) \\approx \\left| \\frac{h^2}{6} f'''(x) \\right|\n$$\n对于给定函数 $f(x) = \\sin(x)$，其三阶导数为 $f'''(x) = -\\cos(x)$。求值点为 $x=1.0$ 弧度。于是截断误差为：\n$$\nE_{\\text{trunc}}(h) \\approx \\frac{h^2}{6} |-\\cos(1.0)| = \\frac{h^2}{6} \\cos(1.0)\n$$\n因为 $1.0$ 弧度在第一象限，其中 $\\cos(1.0) > 0$。\n\n接下来，我们分析舍入误差。对于很小的 $h$，该公式涉及两个几乎相等的数 $f(x+h)$ 和 $f(x-h)$ 的相减，这会导致灾难性抵消。这是舍入误差的主要来源。函数的计算值为 $\\widetilde{f}(x+h) = f(x+h)(1+\\delta_1)$ 和 $\\widetilde{f}(x-h) = f(x-h)(1+\\delta_2)$，其中 $|\\delta_1|, |\\delta_2| \\le u$，而 $u = 2^{-53}$ 是单位舍入误差。分子计算的绝对误差的界为：\n$$\n|f(x+h)(1+\\delta_1) - f(x-h)(1+\\delta_2) - (f(x+h) - f(x-h))| \\approx |f(x+h)\\delta_1 - f(x-h)\\delta_2|\n$$\n该误差的界为 $\\le u|f(x+h)| + u|f(x-h)|$。对于较小的 $h$，我们可以近似认为 $f(x+h) \\approx f(x)$ 和 $f(x-h) \\approx f(x)$。因此，分子的误差界约为 $2u|f(x)|$。这个误差随后通过除以 $2h$ 进行传播。因此，主阶舍入误差为：\n$$\nE_{\\text{round}}(h) \\approx \\frac{2u|f(x)|}{2h} = \\frac{u|f(x)|}{h}\n$$\n对于 $f(x) = \\sin(x)$ 在 $x=1.0$ 的情况，这变为：\n$$\nE_{\\text{round}}(h) \\approx \\frac{u|\\sin(1.0)|}{h} = \\frac{u\\sin(1.0)}{h}\n$$\n因为 $\\sin(1.0) > 0$。\n\n总误差界 $E(h)$ 是主阶截断误差和舍入误差之和：\n$$\nE(h) \\approx E_{\\text{trunc}}(h) + E_{\\text{round}}(h) = \\frac{h^2}{6}\\cos(1.0) + \\frac{u\\sin(1.0)}{h}\n$$\n为了找到使该误差界最小化的步长 $h$，我们对 $E(h)$ 关于 $h$ 求导，并令结果为零：\n$$\n\\frac{dE}{dh} = \\frac{2h}{6}\\cos(1.0) - \\frac{u\\sin(1.0)}{h^2} = \\frac{h}{3}\\cos(1.0) - \\frac{u\\sin(1.0)}{h^2}\n$$\n令 $\\frac{dE}{dh} = 0$:\n$$\n\\frac{h_{\\text{opt}}}{3}\\cos(1.0) = \\frac{u\\sin(1.0)}{h_{\\text{opt}}^2}\n$$\n求解 $h_{\\text{opt}}$:\n$$\nh_{\\text{opt}}^3 = \\frac{3u\\sin(1.0)}{\\cos(1.0)} = 3u\\tan(1.0)\n$$\n$$\nh_{\\text{opt}} = (3u\\tan(1.0))^{1/3}\n$$\n现在，我们代入数值 $u = 2^{-53}$ 并以弧度计算 $\\tan(1.0)$。\n$$\nh_{\\text{opt}} = (3 \\times 2^{-53} \\times \\tan(1.0))^{1/3}\n$$\n使用计算器可得 $\\tan(1.0) \\approx 1.55740772$。\n$$\nh_{\\text{opt}} \\approx (3 \\times 2^{-53} \\times 1.55740772)^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx (4.67222317 \\times 2^{-53})^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx (4.67222317 \\times 1.11022302 \\times 10^{-16})^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx (5.18742014 \\times 10^{-16})^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx 8.03525 \\times 10^{-6}\n$$\n题目要求将答案四舍五入到 $4$ 位有效数字。\n$$\nh_{\\text{opt}} \\approx 8.035 \\times 10^{-6}\n$$\n这就是平衡了递减的截断误差和递增的舍入误差的最佳步长。",
            "answer": "$$\n\\boxed{8.035 \\times 10^{-6}}\n$$"
        },
        {
            "introduction": "计算过程的稳定性通常取决于算法本身的设计。在这个进阶实践中，我们将比较用于矢量正交化的经典格拉姆-施密特（CGS）方法和修正格拉姆-施密特（MGS）方法，以观察一个微小的操作顺序调整如何能极大地提高数值稳定性。这个练习突显了计算科学中的一个关键原则：在面对舍入误差时，数学上等价的算法可能表现出截然不同的行为。",
            "id": "2419987",
            "problem": "给定一个在实向量空间中构造的近似共线列向量集合族。对于给定的整数 $n \\ge k \\ge 1$ 和实数参数 $\\epsilon \\ge 0$，定义 $\\mathbb{R}^n$ 的标准基 $\\{e_1,\\dots,e_n\\}$，并构造一个 $n \\times k$ 矩阵 $A = [a_1,\\dots,a_k]$，其列向量为\n- $a_1 = e_1$，\n- 对于 $2 \\le j \\le k$，$a_j = e_1 + \\epsilon^{\\,j-1} e_j$。\n所有计算都应使用双精度浮点算术执行。\n\n任务：\n1. 使用上述定义的矩阵 $A$，对 $A$ 的列向量进行正交规范化，得到两个结果：\n   - 一个使用经典 Gram-Schmidt (CGS) 方法，得到矩阵 $Q^{(c)} \\in \\mathbb{R}^{n \\times k}$，\n   - 一个使用修正 Gram-Schmidt (MGS) 方法，得到矩阵 $Q^{(m)} \\in \\mathbb{R}^{n \\times k}$。\n   对于这两种方法，如果要用于归一化列向量的范数为零，则 $Q$ 中对应的列向量必须设为零向量。\n2. 对任意 $Q \\in \\mathbb{R}^{n \\times k}$，正交性误差定义如下。设 $q_j$ 表示 $Q$ 的第 $j$ 列，设 $\\delta = 10^{-14}$，并定义索引集 $J = \\{ j \\in \\{1,\\dots,k\\} : \\|q_j\\|_2 > \\delta \\}$。设 $r = |J|$，并令 $Q_J \\in \\mathbb{R}^{n \\times r}$ 是一个子矩阵，仅包含由 $J$ 索引的 $Q$ 的列（按 $j$ 的递增顺序）。定义\n   $$E(Q) = \\begin{cases}\n   \\left\\| Q_J^{\\mathsf{T}} Q_J - I_r \\right\\|_F, & r \\ge 1, \\\\\n   0, & r = 0,\n   \\end{cases}$$\n   其中 $\\|\\cdot\\|_F$ 表示 Frobenius 范数，$I_r$ 是 $r \\times r$ 单位矩阵。\n3. 对于下面测试套件中的每个测试用例，根据 $(n,k,\\epsilon)$ 构造 $A$，计算 $Q^{(c)}$ 和 $Q^{(m)}$，然后计算正交性误差对 $\\big(E(Q^{(c)}), E(Q^{(m)})\\big)$。\n\n测试套件：\n- 用例 1 (理想情况): $(n,k,\\epsilon) = (6, 3, 10^{-8})$。\n- 用例 2 (边界情况，除一个方向外完全共线): $(n,k,\\epsilon) = (6, 3, 0)$。\n- 用例 3 (更深层次的近似共线链): $(n,k,\\epsilon) = (10, 8, 10^{-12})$。\n- 用例 4 (边缘情况，扰动接近机器精度): $(n,k,\\epsilon) = (6, 5, 10^{-16})$。\n\n最终输出格式：\n- 您的程序必须生成单行输出，其中包含一个 Python 风格的浮点数列表的列表：\n  $$\\big[ [E(Q^{(c)}_1), E(Q^{(m)}_1)], [E(Q^{(c)}_2), E(Q^{(m)}_2)], [E(Q^{(c)}_3), E(Q^{(m)}_3)], [E(Q^{(c)}_4), E(Q^{(m)}_4)] \\big],$$\n  其中下标表示测试用例编号。数字应以标准十进制或科学记数法打印，不含任何附加文本。程序不得读取任何输入，且必须能直接运行。",
            "solution": "所提出的问题陈述已经过验证，并被认定是有效的。这是一个计算工程和数值线性代数中的适定问题，旨在展示经典 Gram-Schmidt (CGS) 和修正 Gram-Schmidt (MGS) 正交规范化算法在数值稳定性上的差异。该问题具有科学依据、内容自洽，且其所有组成部分都得到了严格定义。\n\n任务是比较将 CGS 和 MGS 应用于一组近似共线向量时正交性的损失情况。共线程度由参数 $\\epsilon$ 控制。当 $\\epsilon$ 很小时，这些向量在数值上变得难以区分，这暴露了数值不稳定算法的弱点。\n\n首先，我们为给定的整数 $n \\ge k \\ge 1$ 和实数参数 $\\epsilon \\ge 0$ 定义矩阵 $A \\in \\mathbb{R}^{n \\times k}$。其列向量 $a_j$ (其中 $j=1, \\dots, k$) 构造如下：\n- $a_1 = e_1$\n- 对于 $2 \\le j \\le k$，$a_j = e_1 + \\epsilon^{j-1} e_j$\n其中 $\\{e_1, \\dots, e_n\\}$ 是 $\\mathbb{R}^n$ 的标准基。当 $\\epsilon \\to 0$ 时，对于 $j \\ge 2$ 的向量 $a_j$ 会趋近于 $a_1$，从而构成一组近似线性相关的向量。这种构造对正交规范化算法提出了严峻的考验。所有计算均在标准双精度浮点算术中执行，其中机器精度约为 $\\epsilon_{mach} \\approx 2.22 \\times 10^{-16}$。\n\n两种正交规范化算法如下：\n\n**经典 Gram-Schmidt (CGS)**\nCGS 算法从输入向量 $\\{a_1, \\dots, a_k\\}$ 生成一组正交规范向量 $\\{q_1, \\dots, q_k\\}$。对于每个向量 $a_j$，它会减去该向量在先前已计算出的正交规范向量 $\\{q_1, \\dots, q_{j-1}\\}$ 方向上的分量。该过程定义如下：\n1. 初始化 $v_j = a_j$。\n2. 计算投影和：$v_j = a_j - \\sum_{i=1}^{j-1} (q_i^{\\mathsf{T}} a_j) q_i$。\n3. 归一化：$q_j = v_j / \\|v_j\\|_2$。\n\nCGS 的数值不稳定性源于步骤 2。项 $(q_i^{\\mathsf{T}} a_j)$ 是使用原始向量 $a_j$ 计算的。如果 $a_j$ 与由 $\\{q_1, \\dots, q_{j-1}\\}$ 张成的子空间近似平行，向量 $v_j$ 将是一个大向量减去另一个几乎相同的大向量的结果。这种被称为灾难性抵消的操作，会导致相对精度的巨大损失。计算得到的向量 $\\hat{v}_j$ 可能仍然含有与 $\\{q_1, \\dots, q_{j-1}\\}$ 平行的显著分量，这意味着最终的向量集 $\\{\\hat{q}_1, \\dots, \\hat{q}_k\\}$ 将不再正交。\n\n**修正 Gram-Schmidt (MGS)**\nMGS 算法是 CGS 计算的一种重新排列，在数值上更为稳定。MGS 并非将单个向量 $a_j$ 投影到所有先前的 $q_i$上，而是在得到每个新的正交规范向量 $q_j$ 后，立即从所有后续向量 $\\{a_{j+1}, \\dots, a_k\\}$ 中移除其分量。\n该过程是：\n1. 对于所有 $j=1, \\dots, k$，初始化 $v_j = a_j$。\n2. 对于 $j=1, \\dots, k$：\n   a. 归一化当前向量: $q_j = v_j / \\|v_j\\|_2$。\n   b. 将所有后续向量与新的 $q_j$ 正交化: 对于 $l = j+1, \\dots, k$, $v_l = v_l - (q_j^{\\mathsf{T}} v_l) q_j$。\n\n这个过程在数学上与 CGS 等价，但在有限精度下表现截然不同。通过在每一步正交化向量 $v_l$，MGS 有效地对正交性进行了迭代修正，防止了 CGS 中出现的误差累积。用于投影的向量 $v_l$ 已经被正交化至 $\\{q_1, \\dots, q_{j-1}\\}$，这使得计算更加稳健。\n\n对于这两种算法，问题规定，如果待归一化向量的范数 $\\|v_j\\|_2$ 为零，则生成的列 $q_j$ 应为零向量。在浮点环境中，我们通过检查范数是否低于一个小的容差（例如 $10^{-20}$）来实现这一点，以便稳健地处理因舍入误差而导致的、数学上为零但在数值上非零的值。\n\n**正交性误差度量**\n正交规范化的质量由正交性误差 $E(Q)$ 来衡量。给定一个矩阵 $Q \\in \\mathbb{R}^{n \\times k}$，我们首先滤除所有零列或接近零的列。我们定义一个索引集 $J = \\{ j \\in \\{1,\\dots,k\\} : \\|q_j\\|_2 > \\delta \\}$，容差为 $\\delta = 10^{-14}$。如果 $r = |J|$ 是不可忽略列的数量，我们由这些列构成一个子矩阵 $Q_J \\in \\mathbb{R}^{n \\times r}$。该误差是 $Q_J^{\\mathsf{T}} Q_J$ 与单位矩阵 $I_r$ 之差的 Frobenius 范数：\n$$\nE(Q) = \\begin{cases}\n   \\left\\| Q_J^{\\mathsf{T}} Q_J - I_r \\right\\|_F, & r \\ge 1, \\\\\n   0, & r = 0.\n\\end{cases}\n$$\n对于 $Q_J$ 中一组完全正交规范的列，此误差将为 $0$。\n\n**测试用例分析**\n- **用例 1: $(n, k, \\epsilon) = (6, 3, 10^{-8})$**。此处 $\\epsilon = 10^{-8}$。向量 $a_2$ 接近 $a_1$，而 $a_3$ 极其接近 $a_1$，因为其扰动为 $\\epsilon^2 = 10^{-16}$，已达到双精度浮点的极限。$\\epsilon=10^{-8}$ 的值约等于 $\\sqrt{\\epsilon_{mach}}$，这是一个已知的阈值，当达到此阈值时 CGS 会开始显著丧失正交性。我们预计 CGS 会产生明显的误差，而 MGS 则应保持准确。\n- **用例 2: $(n, k, \\epsilon) = (6, 3, 0)$**。当 $\\epsilon=0$ 时，列向量是精确共线的：$A = [e_1, e_1, e_1]$。两种算法都应能正确识别出线性相关性，生成 $Q = [e_1, 0, 0, \\dots]$。对于两种算法，最终的误差 $E(Q)$ 都应为 $0$，因为只有一个非零列。\n- **用例 3: $(n, k, \\epsilon) = (10, 8, 10^{-12})$**。扰动项 $\\epsilon^{j-1}$ 会迅速变得小于机器精度。对于 $j=3$，$\\epsilon^2 = 10^{-24}$，因此 $a_3$ 在计算上将与 $e_1$ 相同。矩阵 $A$ 在数值上将是 $[e_1, e_1 + 10^{-12}e_2, e_1, e_1, \\dots]$。由于误差传播，CGS 将遭受严重的正交性损失。MGS 会正确地将 $a_2$ 与 $a_1$ 正交化，然后会发现所有后续向量都在 $q_1$ 的张成空间中，从而得到零向量。MGS 的误差应该很小，而 CGS 的误差将会很大。\n- **用例 4: $(n, k, \\epsilon) = (6, 5, 10^{-16})$**。此处 $\\epsilon$ 本身就处于机器精度水平。向量 $a_2 = e_1 + 10^{-16} e_2$ 与 $a_1$ 几乎无法区分。所有后续的向量 $a_j$ (对于 $j \\ge 3$) 在数值上都将与 $e_1$ 相同。这是一个极端情况，预计 CGS 将完全失效，生成的列向量将远非正交。MGS 应该能够优雅地处理这种情况，产生两个正交规范向量和随后的零向量，从而得到一个非常低的误差。\n\n实现将遵循这些原则来为每个测试用例计算指定的误差对。",
            "answer": "```python\nimport numpy as np\n\ndef build_A(n, k, epsilon):\n    \"\"\"\n    Constructs the n x k matrix A with nearly collinear columns.\n    \n    Args:\n        n (int): Number of rows.\n        k (int): Number of columns.\n        epsilon (float): Parameter controlling collinearity.\n    \n    Returns:\n        np.ndarray: The n x k matrix A.\n    \"\"\"\n    A = np.zeros((n, k), dtype=np.float64)\n    # a_1 = e_1\n    A[0, 0] = 1.0\n    # a_j = e_1 + epsilon^(j-1) * e_j for j >= 2\n    for j in range(1, k):\n        A[0, j] = 1.0\n        if j < n:\n            A[j, j] = epsilon**j\n    return A\n\ndef classical_gram_schmidt(A):\n    \"\"\"\n    Orthonormalizes the columns of A using the Classical Gram-Schmidt method.\n    \n    Args:\n        A (np.ndarray): The matrix to orthonormalize.\n    \n    Returns:\n        np.ndarray: The matrix Q with orthonormal columns.\n    \"\"\"\n    n, k = A.shape\n    Q = np.zeros((n, k), dtype=np.float64)\n    # A small tolerance to check for zero norm\n    norm_tol = 1e-20 \n    \n    for j in range(k):\n        v = A[:, j].copy()\n        for i in range(j):\n            # CGS projects the original vector A[:, j] onto each q_i\n            proj_coeff = np.dot(Q[:, i].T, A[:, j])\n            v -= proj_coeff * Q[:, i]\n        \n        norm_v = np.linalg.norm(v)\n        if norm_v > norm_tol:\n            Q[:, j] = v / norm_v\n        # If norm_v is too small, Q[:, j] remains a zero vector.\n            \n    return Q\n\ndef modified_gram_schmidt(A):\n    \"\"\"\n    Orthonormalizes the columns of A using the Modified Gram-Schmidt method.\n    \n    Args:\n        A (np.ndarray): The matrix to orthonormalize.\n    \n    Returns:\n        np.ndarray: The matrix Q with orthonormal columns.\n    \"\"\"\n    V = A.copy()\n    n, k = V.shape\n    Q = np.zeros((n, k), dtype=np.float64)\n    # A small tolerance to check for zero norm\n    norm_tol = 1e-20\n\n    for j in range(k):\n        norm_v = np.linalg.norm(V[:, j])\n        if norm_v > norm_tol:\n            Q[:, j] = V[:, j] / norm_v\n            # MGS orthogonalizes all subsequent vectors against the new q_j\n            for l in range(j + 1, k):\n                proj_coeff = np.dot(Q[:, j].T, V[:, l])\n                V[:, l] -= proj_coeff * Q[:, j]\n        # If norm_v is too small, Q[:, j] remains zero and no orthogonalization\n        # is performed against it.\n            \n    return Q\n\ndef orthogonality_error(Q):\n    \"\"\"\n    Calculates the orthogonality error E(Q) as defined in the problem.\n    \n    Args:\n        Q (np.ndarray): The matrix with putatively orthonormal columns.\n        \n    Returns:\n        float: The orthogonality error.\n    \"\"\"\n    n, k = Q.shape\n    delta = 1e-14\n    \n    J = [j for j in range(k) if np.linalg.norm(Q[:, j]) > delta]\n    r = len(J)\n    \n    if r == 0:\n        return 0.0\n    \n    Q_J = Q[:, J]\n    \n    I_r = np.identity(r, dtype=np.float64)\n    error_matrix = Q_J.T @ Q_J - I_r\n    \n    return np.linalg.norm(error_matrix, 'fro')\n\ndef solve():\n    \"\"\"\n    Runs the full test suite and prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        (6, 3, 1e-8),      # Case 1\n        (6, 3, 0.0),       # Case 2\n        (10, 8, 1e-12),    # Case 3\n        (6, 5, 1e-16),     # Case 4\n    ]\n\n    all_results = []\n    for n, k, epsilon in test_cases:\n        A = build_A(n, k, epsilon)\n        \n        Q_cgs = classical_gram_schmidt(A)\n        Q_mgs = modified_gram_schmidt(A)\n        \n        error_cgs = orthogonality_error(Q_cgs)\n        error_mgs = orthogonality_error(Q_mgs)\n        \n        all_results.append([error_cgs, error_mgs])\n\n    # The final print statement must follow the exact specified format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}