{
    "hands_on_practices": [
        {
            "introduction": "To build a solid foundation, we begin with the classic, definition-based method for computing a matrix inverse. This exercise  tasks you with calculating the inverse using the adjugate matrix formula, a process that directly connects a matrix's invertibility to the value of its determinant. While computationally expensive for larger matrices, this hands-on calculation is essential for cementing the theoretical underpinnings of matrix inversion.",
            "id": "2400385",
            "problem": "Consider the real $3 \\times 3$ matrix\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2 & -1 & 3\\\\\n0 & 4 & -2\\\\\n1 & 5 & 1\n\\end{pmatrix}.\n$$\nA trusted computational tool reports the following candidate for the inverse of $A$:\n$$\nB \\;=\\;\n\\begin{pmatrix}\n\\frac{7}{9} & \\frac{8}{9} & -\\frac{5}{9}\\\\\n-\\frac{1}{9} & -\\frac{1}{18} & \\frac{2}{9}\\\\\n-\\frac{2}{9} & -\\frac{11}{18} & \\frac{4}{9}\n\\end{pmatrix}.\n$$\nUsing the adjugate-based definition of the inverse, where the adjugate matrix $\\operatorname{adj}(A)$ is the transpose of the cofactor matrix of $A$ and $A^{-1} = \\frac{1}{\\det(A)}\\,\\operatorname{adj}(A)$ for $\\det(A) \\neq 0$, compute $A^{-1}$ and verify it against $B$ via the identity $A A^{-1} = I_3$. Then report the scalar trace $\\operatorname{tr}(A^{-1})$. Provide the exact value (no rounding).",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- The matrix $A$ is given as:\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2 & -1 & 3\\\\\n0 & 4 & -2\\\\\n1 & 5 & 1\n\\end{pmatrix}\n$$\n- A candidate for the inverse of $A$ is given as:\n$$\nB \\;=\\;\n\\begin{pmatrix}\n\\frac{7}{9} & \\frac{8}{9} & -\\frac{5}{9}\\\\\n-\\frac{1}{9} & -\\frac{1}{18} & \\frac{2}{9}\\\\\n-\\frac{2}{9} & -\\frac{11}{18} & \\frac{4}{9}\n\\end{pmatrix}\n$$\n- The method for finding the inverse is specified: $A^{-1} = \\frac{1}{\\det(A)}\\,\\operatorname{adj}(A)$, where $\\operatorname{adj}(A)$ is the transpose of the cofactor matrix of $A$.\n- The task is to compute $A^{-1}$, verify it against $B$, verify the identity $A A^{-1} = I_3$, and report the trace $\\operatorname{tr}(A^{-1})$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It is a standard exercise in linear algebra, a core component of computational engineering. All definitions are standard, and the data provided are sufficient and consistent. The problem does not violate any scientific principles, is not ambiguous, and its solution is verifiable through computation.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\nThe task is to compute the inverse of the matrix $A$ using the adjugate method. The inverse of a non-singular square matrix $A$ is given by the formula:\n$$\nA^{-1} = \\frac{1}{\\det(A)}\\operatorname{adj}(A)\n$$\nwhere $\\operatorname{adj}(A)$ is the adjugate of $A$, which is the transpose of its cofactor matrix.\n\nFirst, we must compute the determinant of $A$, $\\det(A)$. We use cofactor expansion along the first column, as it contains a zero entry which simplifies calculation.\n$$\n\\det(A) = 2 \\begin{vmatrix} 4 & -2 \\\\ 5 & 1 \\end{vmatrix} - 0 \\begin{vmatrix} -1 & 3 \\\\ 5 & 1 \\end{vmatrix} + 1 \\begin{vmatrix} -1 & 3 \\\\ 4 & -2 \\end{vmatrix}\n$$\n$$\n\\det(A) = 2(4 \\cdot 1 - (-2) \\cdot 5) + 1((-1) \\cdot (-2) - 3 \\cdot 4)\n$$\n$$\n\\det(A) = 2(4 + 10) + (2 - 12) = 2(14) - 10 = 28 - 10 = 18\n$$\nSince $\\det(A)=18 \\neq 0$, the matrix $A$ is invertible.\n\nNext, we compute the cofactor matrix, $C$. Each element $C_{ij}$ is given by $(-1)^{i+j} M_{ij}$, where $M_{ij}$ is the minor of the element $a_{ij}$.\n$$\nC_{11} = (-1)^{1+1} \\begin{vmatrix} 4 & -2 \\\\ 5 & 1 \\end{vmatrix} = 1(4 - (-10)) = 14\n$$\n$$\nC_{12} = (-1)^{1+2} \\begin{vmatrix} 0 & -2 \\\\ 1 & 1 \\end{vmatrix} = -1(0 - (-2)) = -2\n$$\n$$\nC_{13} = (-1)^{1+3} \\begin{vmatrix} 0 & 4 \\\\ 1 & 5 \\end{vmatrix} = 1(0 - 4) = -4\n$$\n$$\nC_{21} = (-1)^{2+1} \\begin{vmatrix} -1 & 3 \\\\ 5 & 1 \\end{vmatrix} = -1(-1 - 15) = 16\n$$\n$$\nC_{22} = (-1)^{2+2} \\begin{vmatrix} 2 & 3 \\\\ 1 & 1 \\end{vmatrix} = 1(2 - 3) = -1\n$$\n$$\nC_{23} = (-1)^{2+3} \\begin{vmatrix} 2 & -1 \\\\ 1 & 5 \\end{vmatrix} = -1(10 - (-1)) = -11\n$$\n$$\nC_{31} = (-1)^{3+1} \\begin{vmatrix} -1 & 3 \\\\ 4 & -2 \\end{vmatrix} = 1(2 - 12) = -10\n$$\n$$\nC_{32} = (-1)^{3+2} \\begin{vmatrix} 2 & 3 \\\\ 0 & -2 \\end{vmatrix} = -1(-4 - 0) = 4\n$$\n$$\nC_{33} = (-1)^{3+3} \\begin{vmatrix} 2 & -1 \\\\ 0 & 4 \\end{vmatrix} = 1(8 - 0) = 8\n$$\nThe cofactor matrix is:\n$$\nC = \\begin{pmatrix}\n14 & -2 & -4\\\\\n16 & -1 & -11\\\\\n-10 & 4 & 8\n\\end{pmatrix}\n$$\nThe adjugate matrix is the transpose of the cofactor matrix, $\\operatorname{adj}(A) = C^T$.\n$$\n\\operatorname{adj}(A) = \\begin{pmatrix}\n14 & 16 & -10\\\\\n-2 & -1 & 4\\\\\n-4 & -11 & 8\n\\end{pmatrix}\n$$\nNow we construct the inverse matrix $A^{-1}$:\n$$\nA^{-1} = \\frac{1}{18} \\begin{pmatrix}\n14 & 16 & -10\\\\\n-2 & -1 & 4\\\\\n-4 & -11 & 8\n\\end{pmatrix} = \\begin{pmatrix}\n\\frac{14}{18} & \\frac{16}{18} & -\\frac{10}{18}\\\\\n-\\frac{2}{18} & -\\frac{1}{18} & \\frac{4}{18}\\\\\n-\\frac{4}{18} & -\\frac{11}{18} & \\frac{8}{18}\n\\end{pmatrix}\n$$\nSimplifying the fractions gives:\n$$\nA^{-1} = \\begin{pmatrix}\n\\frac{7}{9} & \\frac{8}{9} & -\\frac{5}{9}\\\\\n-\\frac{1}{9} & -\\frac{1}{18} & \\frac{2}{9}\\\\\n-\\frac{2}{9} & -\\frac{11}{18} & \\frac{4}{9}\n\\end{pmatrix}\n$$\nThis computed inverse matches the provided candidate matrix $B$ exactly.\n\nTo verify the identity $A A^{-1} = I_3$, we perform the multiplication. It is more convenient to compute $A \\cdot \\operatorname{adj}(A)$ first. From theory, we know $A \\cdot \\operatorname{adj}(A) = \\det(A) \\cdot I_3$.\n$$\nA \\cdot \\operatorname{adj}(A) = \\begin{pmatrix}\n2 & -1 & 3\\\\\n0 & 4 & -2\\\\\n1 & 5 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n14 & 16 & -10\\\\\n-2 & -1 & 4\\\\\n-4 & -11 & 8\n\\end{pmatrix}\n$$\nThe $(1,1)$ entry is $2(14) + (-1)(-2) + 3(-4) = 28 + 2 - 12 = 18$.\nThe $(2,2)$ entry is $0(16) + 4(-1) + (-2)(-11) = -4 + 22 = 18$.\nThe $(3,3)$ entry is $1(-10) + 5(4) + 1(8) = -10 + 20 + 8 = 18$.\nThe off-diagonal entries are all zero, as expected. For example, the $(1,2)$ entry is $2(16) + (-1)(-1) + 3(-11) = 32 + 1 - 33 = 0$.\nThus, the product is:\n$$\nA \\cdot \\operatorname{adj}(A) = \\begin{pmatrix}\n18 & 0 & 0\\\\\n0 & 18 & 0\\\\\n0 & 0 & 18\n\\end{pmatrix} = 18 \\cdot I_3\n$$\nTherefore, $A A^{-1} = A \\left( \\frac{1}{18}\\operatorname{adj}(A) \\right) = \\frac{1}{18} (A \\cdot \\operatorname{adj}(A)) = \\frac{1}{18}(18 \\cdot I_3) = I_3$. The calculation is correct.\n\nFinally, we compute the trace of $A^{-1}$, which is the sum of its diagonal elements.\n$$\n\\operatorname{tr}(A^{-1}) = \\frac{7}{9} + \\left(-\\frac{1}{18}\\right) + \\frac{4}{9}\n$$\nTo sum these fractions, we use a common denominator of $18$.\n$$\n\\operatorname{tr}(A^{-1}) = \\frac{14}{18} - \\frac{1}{18} + \\frac{8}{18} = \\frac{14 - 1 + 8}{18} = \\frac{21}{18}\n$$\nSimplifying the fraction by dividing the numerator and denominator by their greatest common divisor, $3$, gives:\n$$\n\\operatorname{tr}(A^{-1}) = \\frac{7}{6}\n$$",
            "answer": "$$\\boxed{\\frac{7}{6}}$$"
        },
        {
            "introduction": "Beyond general formulas, recognizing special structures in matrices can offer powerful shortcuts and deeper geometric insights. This practice  explores the properties of Householder reflection matrices, which are fundamental in areas like numerical linear algebra for QR factorization. By investigating this matrix, you will discover that it is its own inverse, a property that stems directly from its geometric meaning as a reflection.",
            "id": "2400407",
            "problem": "In computational engineering, Householder reflections are fundamental tools for constructing orthogonal-triangular (QR) factorizations. Let $n \\in \\mathbb{N}$ with $n \\geq 2$, and let $v \\in \\mathbb{R}^{n} \\setminus \\{0\\}$. Define the linear operator represented by the matrix\n$$\nH \\;=\\; I \\;-\\; 2\\,\\frac{v v^{\\top}}{v^{\\top} v}.\n$$\nSuch an $H$ is a reflection matrix, and it satisfies $\\det(H) = -1$.\n\nUsing only the definitions of matrix multiplication, transpose, determinant, and invertibility, establish whether $H$ is invertible and identify $H^{-1}$. Then determine $H^{2}$ explicitly and state the geometric interpretation of $H^{2}$ in $\\mathbb{R}^{n}$.\n\nAnswer specification: Provide, as your single reported value, the exact value of $\\det(H^{2})$. No rounding is required.",
            "solution": "The problem statement is validated and determined to be scientifically sound, well-posed, and objective. There are no contradictions or fallacies. We may proceed with the solution.\n\nThe problem defines a Householder matrix $H$ for a non-zero vector $v \\in \\mathbb{R}^{n}$ (where $n \\geq 2$) as:\n$$ H = I - 2 \\frac{v v^{\\top}}{v^{\\top} v} $$\nwhere $I$ is the $n \\times n$ identity matrix. The problem also provides the known property that $\\det(H) = -1$.\n\nFirst, we establish the invertibility of $H$. A square matrix is invertible if and only if its determinant is non-zero. The problem statement explicitly gives $\\det(H) = -1$. Since $\\det(H) \\neq 0$, the matrix $H$ is invertible.\n\nNext, we are asked to identify the inverse of $H$, denoted $H^{-1}$, and to determine $H^{2}$. We will compute $H^{2}$ directly by matrix multiplication:\n$$ H^{2} = H \\cdot H = \\left( I - 2 \\frac{v v^{\\top}}{v^{\\top} v} \\right) \\left( I - 2 \\frac{v v^{\\top}}{v^{\\top} v} \\right) $$\nUsing the distributive property of matrix multiplication:\n$$ H^{2} = I \\cdot I - I \\left( 2 \\frac{v v^{\\top}}{v^{\\top} v} \\right) - \\left( 2 \\frac{v v^{\\top}}{v^{\\top} v} \\right) I + \\left( 2 \\frac{v v^{\\top}}{v^{\\top} v} \\right) \\left( 2 \\frac{v v^{\\top}}{v^{\\top} v} \\right) $$\nSince multiplying by the identity matrix $I$ leaves a matrix unchanged, this simplifies to:\n$$ H^{2} = I - 2 \\frac{v v^{\\top}}{v^{\\top} v} - 2 \\frac{v v^{\\top}}{v^{\\top} v} + 4 \\frac{(v v^{\\top})(v v^{\\top})}{(v^{\\top} v)^{2}} $$\n$$ H^{2} = I - 4 \\frac{v v^{\\top}}{v^{\\top} v} + 4 \\frac{v (v^{\\top} v) v^{\\top}}{(v^{\\top} v)^{2}} $$\nThe term $v^{\\top} v$ is the dot product of $v$ with itself, which is a scalar. We can commute this scalar within the matrix product:\n$$ H^{2} = I - 4 \\frac{v v^{\\top}}{v^{\\top} v} + 4 \\frac{(v^{\\top} v) (v v^{\\top})}{(v^{\\top} v)^{2}} $$\nSince $v \\in \\mathbb{R}^{n} \\setminus \\{0\\}$, its norm is non-zero, which means the scalar $v^{\\top} v \\neq 0$. We can therefore cancel one factor of $v^{\\top} v$ from the numerator and denominator of the last term:\n$$ H^{2} = I - 4 \\frac{v v^{\\top}}{v^{\\top} v} + 4 \\frac{v v^{\\top}}{v^{\\top} v} $$\nThe last two terms cancel each other out, yielding the result:\n$$ H^{2} = I $$\nThus, $H^{2}$ is explicitly the identity matrix $I$.\n\nFrom the result $H \\cdot H = I$, we can identify the inverse of $H$. By definition, the inverse $H^{-1}$ is the matrix such that $H \\cdot H^{-1} = I$. Comparing this with our result $H \\cdot H = I$, we immediately see that:\n$$ H^{-1} = H $$\nSo, the Householder matrix is its own inverse. Such a matrix is called an involution.\n\nThe geometric interpretation of $H^{2}$ follows directly from the fact that $H^{2} = I$. The matrix $H$ represents a reflection across the hyperplane with normal vector $v$. Applying a reflection transformation twice consecutively returns any vector in $\\mathbb{R}^{n}$ to its original position. Therefore, the transformation corresponding to $H^{2}$ is the identity transformation, which leaves all vectors unchanged.\n\nFinally, we must determine the value of $\\det(H^{2})$. This can be done in two ways.\n\nMethod $1$: Using the result we derived, $H^{2} = I$.\n$$ \\det(H^{2}) = \\det(I) $$\nThe determinant of the identity matrix in any dimension is $1$.\n$$ \\det(H^{2}) = 1 $$\n\nMethod $2$: Using the multiplicative property of determinants, $\\det(AB) = \\det(A)\\det(B)$.\n$$ \\det(H^{2}) = \\det(H \\cdot H) = \\det(H) \\cdot \\det(H) = (\\det(H))^{2} $$\nThe problem statement gives that $\\det(H) = -1$. Substituting this value:\n$$ \\det(H^{2}) = (-1)^{2} = 1 $$\nBoth methods yield the same unambiguous result. The value of $\\det(H^{2})$ is $1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Moving from theoretical mechanics to practical implementation, we now address how matrix inversion is performed in computational settings. This problem  guides you through the Gauss-Jordan elimination algorithm, the workhorse for inverting matrices and testing for singularity in software. Mastering this procedure, including vital numerical considerations like partial pivoting and tolerance, is a core skill for any computational engineer.",
            "id": "2400410",
            "problem": "You are asked to implement a robust numerical procedure for determining whether a square matrix is invertible and, if so, computing its inverse, using only row operations. The method must be based on the Gauss–Jordan elimination procedure with partial pivoting.\n\nStart from foundational concepts in linear algebra: an $n \\times n$ matrix $A$ is invertible if and only if there exists a matrix $B$ such that $AB = BA = I_n$, where $I_n$ is the $n \\times n$ identity matrix. Elementary row operations correspond to left-multiplication by invertible elementary matrices. If a finite sequence of elementary row operations transforms $A$ into $I_n$, then the same transformations applied to $I_n$ yield $A^{-1}$. Conversely, if no such sequence exists because a pivot cannot be found at some step (that is, all entries in the pivot column below and including the current row are zero in exact arithmetic), then $A$ is singular.\n\nImplement the Gauss–Jordan algorithm as follows: given an $n \\times n$ real matrix $A$, construct the augmented matrix $[A \\mid I_n]$. For each column index $j \\in \\{0,1,\\dots,n-1\\}$, select as pivot the row $p \\in \\{j,\\dots,n-1\\}$ where the absolute value of the entry in column $j$ is maximal (partial pivoting). Swap rows $j$ and $p$. If the absolute value of the pivot is below a small tolerance $\\tau$, declare $A$ singular and stop. Otherwise, scale row $j$ to make the pivot equal to $1$, then eliminate all other entries in column $j$ by subtracting suitable multiples of row $j$ from the other rows. When the left block has been reduced to $I_n$, the right block equals $A^{-1}$.\n\nNumerical specification:\n- Use a pivot tolerance $\\tau = 10^{-12}$ to decide whether a pivot is effectively zero.\n- Use partial pivoting as described to improve numerical stability.\n- If the matrix is declared invertible, return the inverse as a flattened list in row-major order, with each entry rounded to six decimal places. If the matrix is singular, return an empty list for the inverse.\n\nTest suite:\nCompute the result for each of the following matrices:\n- Case $1$ (happy path, $3 \\times 3$): \n$$\nA_1 = \\begin{bmatrix}\n2 & 1 & 1 \\\\\n1 & 3 & 2 \\\\\n1 & 0 & 0\n\\end{bmatrix}.\n$$\n- Case $2$ (singular, $3 \\times 3$):\n$$\nA_2 = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n2 & 4 & 6 \\\\\n1 & 0 & 1\n\\end{bmatrix}.\n$$\n- Case $3$ (identity, $4 \\times 4$):\n$$\nA_3 = \\begin{bmatrix}\n1 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 1\n\\end{bmatrix}.\n$$\n- Case $4$ (requires row swap, $2 \\times 2$):\n$$\nA_4 = \\begin{bmatrix}\n0 & 1\\\\\n2 & 3\n\\end{bmatrix}.\n$$\n- Case $5$ (ill-conditioned but invertible, $2 \\times 2$):\n$$\nA_5 = \\begin{bmatrix}\n1 & 1\\\\\n1 & 1 + 10^{-10}\n\\end{bmatrix}.\n$$\n\nFinal output format:\n- For each case $k \\in \\{1,2,3,4,5\\}$, your program must produce a result of the form $[s_k, v_k]$ where $s_k$ is a boolean indicating whether $A_k$ is invertible under the tolerance $\\tau$, and $v_k$ is the row-major flattened inverse as a list of floats rounded to six decimal places when $s_k$ is true, or an empty list when $s_k$ is false.\n- Aggregate the five case results into a single list and print exactly one line containing this list, with items comma-separated and enclosed in square brackets, for example: \n\"[ [True,[...]], [False,[]], ... ]\".\nNo angles or physical units are involved in this task. All numerical answers are pure numbers. Ensure that floats are rounded to six decimal places in the output representation.",
            "solution": "The problem is determined to be valid. It is scientifically grounded in the principles of linear algebra, specifically the Gauss-Jordan elimination method for matrix inversion. The problem is well-posed, providing a complete algorithmic description, specific numerical parameters, and unambiguous test cases. The language used is objective and precise, avoiding any subjective or non-formalizable claims.\n\nThe task is to implement a procedure for computing the inverse of a square matrix $A$ of size $n \\times n$. The fundamental principle is that an elementary row operation on a matrix is equivalent to a left-multiplication by a corresponding elementary matrix. An elementary matrix is invertible. If a sequence of elementary matrices $E_1, E_2, \\dots, E_k$ transforms $A$ into the identity matrix $I_n$, then we have:\n$$ (E_k \\dots E_2 E_1) A = I_n $$\nBy definition of the inverse, this means:\n$$ A^{-1} = E_k \\dots E_2 E_1 $$\nIf we apply the same sequence of transformations to the identity matrix $I_n$, we obtain:\n$$ (E_k \\dots E_2 E_1) I_n = A^{-1} $$\nThis is the theoretical justification for the Gauss-Jordan elimination method on an augmented matrix. We start with the augmented matrix $[A \\mid I_n]$ and apply row operations to transform the left block $A$ into $I_n$. The same operations are simultaneously applied to the right block $I_n$, which is consequently transformed into $A^{-1}$. If at any point the left block cannot be transformed further towards $I_n$ because a non-zero pivot cannot be found, the matrix $A$ is singular and does not have an inverse.\n\nThe algorithm to be implemented is the Gauss-Jordan elimination with partial pivoting for numerical stability.\n\n**Algorithmic Steps:**\n\n1.  **Initialization**: Given an $n \\times n$ matrix $A$, construct the $n \\times 2n$ augmented matrix $M = [A \\mid I_n]$, where $I_n$ is the $n \\times n$ identity matrix.\n\n2.  **Forward Elimination and Back Substitution (Gauss-Jordan)**: Iterate through the columns of the left block, indexed by $j$ from $0$ to $n-1$. In each iteration $j$, perform the following steps:\n    a.  **Partial Pivoting**: To improve numerical stability and avoid division by small numbers, find the row index $p$ such that $j \\le p < n$ and $|M_{p,j}|$ is maximized. Swap row $j$ with row $p$. This operation affects the entire augmented matrix.\n    b.  **Singularity Check**: The element $M_{j,j}$ is now the pivot. If the absolute value of the pivot, $|M_{j,j}|$, is smaller than a pre-defined tolerance $\\tau$ (given as $10^{-12}$), the matrix is considered numerically singular. Terminate the algorithm and report that the matrix is not invertible.\n    c.  **Normalization**: Divide the entire row $j$ by the pivot value $M_{j,j}$. This makes the diagonal element $M_{j,j}$ equal to $1$.\n    $$ R_j \\leftarrow \\frac{1}{M_{j,j}} R_j $$\n    d.  **Elimination**: For every other row $i$ (where $i \\ne j$), eliminate the entry in column $j$. This is achieved by subtracting a multiple of the normalized pivot row $R_j$ from row $R_i$. The multiple is given by the value $M_{i,j}$.\n    $$ R_i \\leftarrow R_i - M_{i,j} R_j \\quad \\text{for } i = 0, \\dots, n-1, i \\ne j $$\n\n3.  **Result Extraction**: After iterating through all columns $j$ from $0$ to $n-1$, the left block of the augmented matrix will be the identity matrix $I_n$. The right block will be the inverse matrix $A^{-1}$.\n\n4.  **Output Formatting**:\n    - If the algorithm completed successfully, return a boolean `True` indicating invertibility. The computed inverse matrix $A^{-1}$ is then flattened into a one-dimensional list in row-major order, with each element rounded to six decimal places.\n    - If the matrix was determined to be singular, return a boolean `False` and an empty list.\n\nThis procedure will be applied to each of the five provided test matrices to generate the final output. The use of a small tolerance $\\tau$ is critical for handling floating-point arithmetic, as true zero may not be achieved due to precision errors. Partial pivoting is essential for robustness, especially for matrices that are ill-conditioned (like Case $5$) or have zeros on the diagonal (like Case $4$).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_inverse_with_gauss_jordan(A_list, tolerance):\n    \"\"\"\n    Computes the inverse of a square matrix using Gauss-Jordan elimination\n    with partial pivoting.\n\n    Args:\n        A_list (list of lists): The input square matrix.\n        tolerance (float): A small number to check for singularity.\n\n    Returns:\n        tuple: A tuple (is_invertible, inverse_list).\n               is_invertible (bool): True if the matrix is invertible, False otherwise.\n               inverse_list (list): The flattened, row-major inverse rounded to 6\n                                    decimal places, or an empty list if singular.\n    \"\"\"\n    # Create a copy to avoid modifying the original list, and use float type.\n    matrix = np.array(A_list, dtype=float)\n    \n    n, m = matrix.shape\n    if n != m:\n        # This case is not expected based on the problem description.\n        return False, []\n\n    # Construct the augmented matrix [A | I]\n    identity = np.identity(n)\n    aug_matrix = np.hstack([matrix, identity])\n\n    # Iterate through columns (pivots)\n    for j in range(n):\n        # Step 1: Partial Pivoting\n        # Find the row with the largest pivot in the current column below the diagonal\n        pivot_row_idx = j + np.argmax(np.abs(aug_matrix[j:, j]))\n\n        # Swap the current row with the pivot row\n        if pivot_row_idx != j:\n            aug_matrix[[j, pivot_row_idx]] = aug_matrix[[pivot_row_idx, j]]\n\n        # Step 2: Singularity Check\n        pivot_value = aug_matrix[j, j]\n        if abs(pivot_value) < tolerance:\n            return False, []  # Matrix is singular\n\n        # Step 3: Normalization\n        # Divide the pivot row by the pivot value to make the pivot 1\n        aug_matrix[j, :] /= pivot_value\n\n        # Step 4: Elimination\n        # Eliminate all other entries in the current pivot column\n        for i in range(n):\n            if i != j:\n                factor = aug_matrix[i, j]\n                aug_matrix[i, :] -= factor * aug_matrix[j, :]\n\n    # The right part of the augmented matrix is now the inverse\n    inverse_matrix = aug_matrix[:, n:]\n\n    # Flatten the inverse matrix and round to 6 decimal places\n    flat_inverse = inverse_matrix.flatten().tolist()\n    rounded_inverse = [round(val, 6) for val in flat_inverse]\n\n    return True, rounded_inverse\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (happy path, 3x3)\n        [[2, 1, 1],\n         [1, 3, 2],\n         [1, 0, 0]],\n        # Case 2 (singular, 3x3)\n        [[1, 2, 3],\n         [2, 4, 6],\n         [1, 0, 1]],\n        # Case 3 (identity, 4x4)\n        [[1, 0, 0, 0],\n         [0, 1, 0, 0],\n         [0, 0, 1, 0],\n         [0, 0, 0, 1]],\n        # Case 4 (requires row swap, 2x2)\n        [[0, 1],\n         [2, 3]],\n        # Case 5 (ill-conditioned but invertible, 2x2)\n        [[1, 1],\n         [1, 1 + 1e-10]],\n    ]\n    \n    # Numerical specification\n    pivot_tolerance = 1e-12\n\n    results = []\n    for case_matrix in test_cases:\n        is_invertible, inverse = compute_inverse_with_gauss_jordan(case_matrix, pivot_tolerance)\n        results.append([is_invertible, inverse])\n\n    # Final print statement in the exact required format.\n    # The str() representation of a list in Python naturally includes spaces\n    # after commas, which aligns with the provided example's styling.\n    # The f-string with join ensures a compact representation between the main list items.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}