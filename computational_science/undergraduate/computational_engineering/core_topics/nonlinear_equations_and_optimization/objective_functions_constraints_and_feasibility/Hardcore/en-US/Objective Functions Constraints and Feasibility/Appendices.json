{
    "hands_on_practices": [
        {
            "introduction": "A core challenge in computational engineering is efficiently allocating limited resources to a set of tasks, a problem that appears everywhere from manufacturing pipelines to cloud computing. This exercise explores the classic problem of scheduling tasks on parallel machines to minimize the total completion time, known as the makespan. You will learn to formally define the objective function (minimizing makespan), encode feasibility through precedence and resource constraints, and develop an exact algorithm to find the optimal schedule for small-scale instances .",
            "id": "2420381",
            "problem": "You are given a scheduling problem on identical parallel machines. There are $n$ non-preemptive tasks, indexed by $i \\in \\{1,\\dots,n\\}$, each with an integer processing time $p_i$ measured in seconds. There are $m$ identical machines that can run at most $m$ tasks concurrently, and a set of precedence constraints represented by directed edges $(i,j)$ meaning that task $i$ must complete before task $j$ can start. The precedence graph must be a directed acyclic graph (DAG) for feasibility. Define a schedule by start times $s_i \\ge 0$ for each task $i$, and define the makespan as $C_{\\max} = \\max_{i} (s_i + p_i)$. Your goal is to compute the optimal value of the objective function $\\min C_{\\max}$ subject to the following constraints, which encode feasibility:\n- Precedence constraints: for every edge $(i,j)$, $s_j \\ge s_i + p_i$.\n- Machine capacity constraints: at any time $\\tau$, the number of tasks with $\\tau \\in [s_i, s_i + p_i)$ is at most $m$.\n- Non-preemption: each task $i$ occupies a single machine continuously on $[s_i, s_i + p_i)$ with no interruption.\n- Start-time non-negativity: for all $i$, $s_i \\ge 0$.\n\nIf the precedence graph contains a directed cycle, the instance is infeasible and no schedule exists.\n\nYou must write a program that, for each specified test case, returns the optimal makespan $C_{\\max}$ in seconds as an integer, or returns the integer $-1$ if the instance is infeasible (contains a cycle). All processing times $p_i$ are integers in seconds. Angles are not involved. Express all outputs as integers in seconds.\n\nTest Suite:\nProvide the results for the following $6$ test cases. Each case is given as $(m, n, \\text{durations}, \\text{precedence edges})$, where durations are in seconds and edges are ordered pairs with $1$-based task indices.\n- Case $1$: $(m=\\;2,\\; n=\\;4,\\; \\text{durations}=\\;[\\,3,2,2,4\\,],\\; \\text{precedence edges}=\\;[\\, (1,3), (2,3), (3,4) \\,])$.\n- Case $2$: $(m=\\;3,\\; n=\\;5,\\; \\text{durations}=\\;[\\,2,2,2,2,2\\,],\\; \\text{precedence edges}=\\;[\\, ]\\; \\text{(no edges)})$.\n- Case $3$: $(m=\\;1,\\; n=\\;3,\\; \\text{durations}=\\;[\\,5,1,3\\,],\\; \\text{precedence edges}=\\;[\\, (1,2), (2,3) \\,])$.\n- Case $4$: $(m=\\;10,\\; n=\\;4,\\; \\text{durations}=\\;[\\,1,7,3,4\\,],\\; \\text{precedence edges}=\\;[\\, (2,4) \\,])$.\n- Case $5$: $(m=\\;2,\\; n=\\;2,\\; \\text{durations}=\\;[\\,1,1\\,],\\; \\text{precedence edges}=\\;[\\, (1,2), (2,1) \\,])$.\n- Case $6$: $(m=\\;2,\\; n=\\;3,\\; \\text{durations}=\\;[\\,0,3,2\\,],\\; \\text{precedence edges}=\\;[\\, (1,2), (1,3) \\,])$.\n\nYour program must compute the optimal $C_{\\max}$ for each case (or $-1$ if infeasible) and output a single line containing the results as a comma-separated list enclosed in square brackets, in the exact format:\n[res1,res2,res3,res4,res5,res6]\nEach entry must be an integer in seconds.\n\nThe computational task is to implement an algorithm that encodes the objective function $\\min C_{\\max}$, the constraints, and checks feasibility, then searches for the optimum. You may use any correct algorithmic approach, but it must be exact for the given test suite. The output must be computed without user input and must be reproducible.",
            "solution": "The problem statement is subjected to validation and is found to be valid. It is a well-posed, scientifically grounded problem from the field of computational engineering and operations research. The problem is a specific instance of parallel machine scheduling with precedence constraints, aiming to minimize the makespan ($C_{\\max}$). In the standard three-field notation, this problem is denoted as $P | prec | C_{\\max}$.\n\nThis problem is known to be NP-hard in the general case. However, the test instances specified have a very small number of tasks ($n \\le 5$), which makes an exact solution via an exhaustive search algorithm computationally feasible. The chosen approach leverages the theoretical foundation of list scheduling algorithms. While a single pass of a list scheduling algorithm with a fixed priority list is a heuristic, it is a fundamental result in scheduling theory that an optimal schedule for $P | prec | C_{\\max}$ can be found by a list scheduling algorithm for at least one priority ordering of the tasks. Consequently, by systematically exploring all valid priority orderings, we can guarantee finding the optimal makespan.\n\nThe algorithm is structured into the following distinct, logical stages:\n\n1.  **Feasibility Verification via Cycle Detection**: A schedule can only exist if the precedence constraints form a Directed Acyclic Graph (DAG). A cycle in the precedence relations, such as task $i$ must precede task $j$ and task $j$ must precede task $i$, creates a logical impossibility. We first model the precedence constraints as a directed graph and perform a Depth-First Search (DFS) to detect any cycles. If a back edge is found (an edge leading to a node currently in the recursion stack), a cycle is present. In such a case, the instance is infeasible, and the designated value of $-1$ is returned, terminating the process.\n\n2.  **Enumeration of All Task Permutations**: To explore the entire solution space of priority orderings, we generate all $n!$ permutations of the task indices $\\{0, 1, \\dots, n-1\\}$. Each permutation represents a potential priority list for the scheduling simulation. The `itertools.permutations` function is suitable for this task.\n\n3.  **Filtering for Valid Topologies**: A permutation of tasks is a valid priority list only if it constitutes a topological sort of the precedence graph. This means for every precedence constraint, represented by a directed edge $(i, j)$, task $i$ must appear before task $j$ in the permutation. Each of the $n!$ permutations is checked against this condition. Permutations that violate any precedence constraint are invalid and are discarded from further consideration.\n\n4.  **List Scheduling Simulation**: For each topologically valid priority list, a deterministic simulation is executed to construct a schedule and compute its makespan. The simulation proceeds as follows:\n    - We maintain the completion time $f_k$ for each task $k$ that has been scheduled.\n    - We maintain an array of size $m$ representing the time at which each of the $m$ identical machines becomes available. Initially, all machines are available at time $t=0$.\n    - Tasks are scheduled sequentially according to their position in the current priority list. For each task $i$:\n        a. The earliest time the task is ready due to precedence constraints is calculated as $T_{\\text{pred}} = \\max(\\{f_j | j \\in \\text{Pred}(i)\\} \\cup \\{0\\})$, where $\\text{Pred}(i)$ is the set of all direct predecessors of task $i$.\n        b. The earliest time a machine becomes available is $T_{\\text{mach}} = \\min(\\text{machine availability times})$.\n        c. The task $i$ can start at $s_i = \\max(T_{\\text{pred}}, T_{\\text{mach}})$. Its completion time is $f_i = s_i + p_i$.\n        d. The task is assigned to the machine corresponding to $T_{\\text{mach}}$, and that machine's availability time is updated to $f_i$.\n        e. A special case is made for tasks with zero processing time ($p_i=0$). These are treated as logical milestones that do not consume machine resources. Their completion time $f_i$ is set to their start time $s_i$, and they do not occupy a machine or alter any machine's availability time.\n    - After all tasks are scheduled, the makespan for the current priority list is given by $C_{\\max} = \\max_i \\{f_i\\}$.\n\n5.  **Identification of the Optimal Makespan**: The algorithm maintains a variable that tracks the minimum makespan found so far across all simulated valid permutations. After all valid permutations have been evaluated, this variable holds the optimal makespan for the problem instance. If no tasks exist ($n=0$), the makespan is trivially $0$.\n\nThis comprehensive search ensures that the globally optimal value for $C_{\\max}$ is found. The implementation of this algorithm will now be provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\nfrom collections import defaultdict\n\ndef compute_optimal_makespan(m, n, durations, edges):\n    \"\"\"\n    Computes the optimal makespan for a parallel machine scheduling problem.\n    This problem is P|prec|C_max, which is NP-hard. This implementation uses\n    an exact algorithm based on exhaustive search over all valid topological\n    sorts (priority lists), which is feasible for small n.\n    \"\"\"\n    if n == 0:\n        return 0\n\n    # Build adjacency lists for the precedence graph (0-based indexing)\n    adj = defaultdict(list)\n    predecessors = defaultdict(list)\n    for u, v in edges:\n        adj[u - 1].append(v - 1)\n        predecessors[v - 1].append(u - 1)\n\n    # Step 1: Feasibility check for cycles using Depth-First Search.\n    # path: nodes in current recursion stack. visited: all nodes ever visited.\n    path = set()\n    visited = set()\n\n    def has_cycle_util(u):\n        path.add(u)\n        visited.add(u)\n        for v in adj[u]:\n            if v in path:\n                return True\n            if v not in visited:\n                if has_cycle_util(v):\n                    return True\n        path.remove(u)\n        return False\n\n    for i in range(n):\n        if i not in visited:\n            if has_cycle_util(i):\n                return -1\n\n    # Step 2: Generate all n! permutations of tasks.\n    tasks = range(n)\n    all_permutations = itertools.permutations(tasks)\n    \n    min_makespan = float('inf')\n\n    for perm in all_permutations:\n        # Step 3: Filter for valid permutations (topological sorts).\n        is_valid_perm = True\n        pos = {task: i for i, task in enumerate(perm)}\n        for u in range(n):\n            for v in adj[u]:\n                if pos[u] > pos[v]:\n                    is_valid_perm = False\n                    break\n            if not is_valid_perm:\n                break\n        \n        if not is_valid_perm:\n            continue\n\n        # Step 4: Simulate list scheduling for the valid permutation.\n        machine_available_times = [0] * m\n        task_completion_times = {}\n\n        for task_idx in perm:\n            p_i = durations[task_idx]\n            \n            # Earliest start time based on predecessor completion.\n            pred_completion_time = 0\n            if task_idx in predecessors:\n                pred_completion_time = max(task_completion_times.get(p, 0) for p in predecessors[task_idx])\n            \n            if p_i > 0:\n                # Find the machine that becomes available earliest.\n                earliest_machine_idx = np.argmin(machine_available_times)\n                earliest_machine_time = machine_available_times[earliest_machine_idx]\n                \n                # Actual start time is the max of precedence and machine readiness.\n                start_time = max(pred_completion_time, earliest_machine_time)\n                finish_time = start_time + p_i\n                \n                task_completion_times[task_idx] = finish_time\n                machine_available_times[earliest_machine_idx] = finish_time\n            else: # Handle zero-duration tasks.\n                # These are milestones and do not consume machine resources.\n                start_time = pred_completion_time\n                finish_time = start_time\n                task_completion_times[task_idx] = finish_time\n\n        \n        # Calculate makespan for this permutation.\n        current_makespan = max(task_completion_times.values()) if task_completion_times else 0\n        \n        # Step 5: Update the minimum makespan found so far.\n        min_makespan = min(min_makespan, current_makespan)\n\n    # All valid permutations checked. Return the optimal makespan.\n    return int(min_makespan)\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the scheduling problem.\n    \"\"\"\n    # Test suite from the problem statement.\n    test_cases = [\n        # (m, n, durations, precedence edges)\n        (2, 4, [3, 2, 2, 4], [(1, 3), (2, 3), (3, 4)]),\n        (3, 5, [2, 2, 2, 2, 2], []),\n        (1, 3, [5, 1, 3], [(1, 2), (2, 3)]),\n        (10, 4, [1, 7, 3, 4], [(2, 4)]),\n        (2, 2, [1, 1], [(1, 2), (2, 1)]),\n        (2, 3, [0, 3, 2], [(1, 2), (1, 3)])\n    ]\n\n    results = []\n    for m, n, durations, edges in test_cases:\n        result = compute_optimal_makespan(m, n, durations, edges)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The rise of additive manufacturing, or 3D printing, has opened new frontiers in design, but it also introduces unique constraints, such as the need for structures to be self-supporting during the printing process. This practice dives into this modern challenge by asking you to design a minimal-mass bridge that is buildable layer-by-layer. By translating the physical rule of self-support into a mathematical constraint, you will use dynamic programming to navigate the design space and find an optimal, manufacturable structure, demonstrating how computational methods drive innovation in digital fabrication .",
            "id": "2420423",
            "problem": "You must write a complete program that, given a discretized two-dimensional bridge design space, computes the minimal-mass self-supporting structure that connects two base anchors under a layer-by-layer manufacturability constraint. The final structure must be feasible at every intermediate printing stage.\n\nMathematical model. Consider a rectangular lattice of cubic voxels with horizontal index $i \\in \\{0,1,\\dots,W-1\\}$ and vertical layer index $j \\in \\{0,1,\\dots,H\\}$, where $W$ is the domain width and $H$ is the maximum allowable number of printed layers above the base plate (layer $j=0$). A binary design variable $x_{i,j} \\in \\{0,1\\}$ indicates whether the voxel at coordinates $(i,j)$ is printed. The objective is to minimize the total mass, modeled as the sum of all printed voxels,\n$$\n\\min \\; M(x) = \\sum_{j=0}^{H}\\sum_{i=0}^{W-1} x_{i,j}.\n$$\nManufacturing feasibility is imposed by a discrete self-support constraint derived from the layer-by-layer nature of Fused Deposition Modeling (FDM). Specifically, for a given maximum horizontal support offset per layer $s \\in \\mathbb{Z}_{\\ge 1}$, every printed voxel above the base must have at least one supporting voxel in the immediately lower layer within horizontal distance at most $s$:\n$$\n\\forall\\, j \\in \\{1,\\dots,H\\}, \\; \\forall\\, i \\in \\{0,\\dots,W-1\\}:\\quad\nx_{i,j} = 1 \\;\\Rightarrow\\; \\sum_{k=\\max(0,i-s)}^{\\min(W-1,i+s)} x_{k,j-1} \\ge 1.\n$$\nBase voxels at layer $j=0$ are considered supported by the build plate and therefore exempt from the above constraint. The bridge must connect two base anchors located at $(0,0)$ and $(W-1,0)$. Connectivity is defined via upward self-supporting steps: a self-supporting path is a sequence of occupied voxels $\\{(i_t,j_t)\\}_{t=0}^{T}$ such that $j_{t+1}=j_t+1$ and $|i_{t+1}-i_t| \\le s$ for all $t$. The design is feasible if there exist two self-supporting paths, one starting at $(0,0)$ and one starting at $(W-1,0)$, that terminate at a common voxel, and all printed voxels satisfy the self-support rule. Among all such feasible designs, the mass $M(x)$ must be minimized. All parameters are integers with $W \\in \\mathbb{Z}_{\\ge 1}$, $H \\in \\mathbb{Z}_{\\ge 0}$, and $s \\in \\mathbb{Z}_{\\ge 1}$.\n\nYour task. Starting from the above fundamental definitions, derive an algorithm that, given $(W,H,s)$, returns the minimal possible value of $M(x)$ if the problem is feasible and returns $-1$ if no feasible design exists under the constraints. Your algorithm must be correct for all inputs satisfying the stated bounds. No physical units are involved.\n\nTest suite. Your program must compute results for the following parameter sets, each provided as a triple $(W,H,s)$:\n- Case A: $(W,H,s) = (9,5,1)$\n- Case B: $(W,H,s) = (13,3,2)$\n- Case C: $(W,H,s) = (11,4,1)$\n- Case D: $(W,H,s) = (1,0,1)$\n- Case E: $(W,H,s) = (20,4,3)$\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the cases above. Each entry must be an integer: the minimal mass if feasible, or $-1$ if infeasible. For example, an output could look like $[3,5,-1,7,9]$ (this is only an example, not the correct answer for the given cases).",
            "solution": "The problem statement presented is a well-posed optimization problem within the domain of computational engineering. It is scientifically grounded, objective, and contains sufficient information to derive a unique solution. The definitions are precise and free of contradiction. Therefore, the problem is valid, and a rigorous solution is derivable.\n\nThe task is to find a minimal-mass structure on a $W \\times (H+1)$ grid of voxels that connects two anchor points, $(0,0)$ and $(W-1,0)$, subject to a layer-by-layer self-support constraint.\n\nThe objective is to minimize the total mass, which is the count of active voxels $x_{i,j}=1$:\n$$\nM(x) = \\sum_{j=0}^{H}\\sum_{i=0}^{W-1} x_{i,j}\n$$\n\nA feasible structure must satisfy two conditions:\n$1$. The connectivity requirement: There must exist two self-supporting paths, one originating from the left anchor $(0,0)$ and one from the right anchor $(W-1,0)$, that meet at a common voxel. A self-supporting path is a sequence of voxels $\\{(i_t, j_t)\\}_{t=0}^{T}$ where each subsequent voxel $(i_{t+1}, j_{t+1})$ satisfies $j_{t+1} = j_t+1$ and $|i_{t+1}-i_t| \\le s$.\n$2$. The global self-support rule: Every active voxel $x_{i,j}=1$ for $j \\ge 1$ must be supported by at least one active voxel in the layer below, within a horizontal distance of $s$. This is expressed as:\n$$\nx_{i,j} = 1 \\implies \\exists k \\in [\\max(0, i-s), \\min(W-1, i+s)] \\text{ such that } x_{k,j-1} = 1\n$$\n\nThe principle of optimality dictates that a minimal-mass structure will contain no superfluous voxels. Any voxel not part of the connecting paths or not providing essential support would be removed to decrease mass. Consequently, the minimal structure is formed precisely by the union of the two self-supporting paths. The problem is thus equivalent to finding two such paths whose union of voxels is minimal.\n\nThis problem structure is amenable to dynamic programming. We define a state by the layer index and the horizontal positions of the endpoints of the two growing paths. Let $dp[j][i_L][i_R]$ be the minimum possible mass of a structure composed of two self-supporting paths originating from $(0,0)$ and $(W-1,0)$, respectively, and terminating at layer $j$ with horizontal positions $i_L$ and $i_R$.\n\nThe state space is defined for $j \\in \\{0, \\dots, H\\}$, $i_L \\in \\{0, \\dots, W-1\\}$, and $i_R \\in \\{0, \\dots, W-1\\}$.\n\nThe base case is at layer $j=0$. The two paths must start at the anchors.\nIf $W=1$, the anchors are identical. A single voxel at $(0,0)$ constitutes a valid, connected structure of mass $1$. $dp[0][0][0] = 1$.\nIf $W>1$, the paths start at $(0,0)$ and $(W-1,0)$. The initial structure consists of two voxels. Thus, $dp[0][0][W-1] = 2$.\nAll other states at $j=0$ are unreachable, so their cost is initialized to infinity:\n$$\ndp[0][i_L][i_R] = \\infty \\quad \\forall (i_L, i_R) \\neq \\begin{cases} (0,0) & \\text{if } W=1 \\\\ (0,W-1) & \\text{if } W>1 \\end{cases}\n$$\n\nFor the recurrence relation, consider the state $dp[j][i_L][i_R]$ for $j>0$. The paths arrive at $(i_L, j)$ and $(i_R, j)$ from some valid positions $(p_L, j-1)$ and $(p_R, j-1)$ in the layer below. The self-support constraint requires $|i_L-p_L| \\le s$ and $|i_R-p_R| \\le s$. The cost to transition from a state at layer $j-1$ to a state at layer $j$ is the number of new voxels added at layer $j$. This is $2$ if $i_L \\neq i_R$, and $1$ if $i_L = i_R$.\n\nTo achieve the minimum mass at $(j, i_L, i_R)$, we must have come from the lowest-cost valid predecessor state in layer $j-1$. The recurrence relation is therefore:\n$$\ndp[j][i_L][i_R] = \\left(2 - \\delta_{i_L, i_R}\\right) + \\min_{\\substack{p_L \\in [\\max(0, i_L-s), \\min(W-1, i_L+s)] \\\\ p_R \\in [\\max(0, i_R-s), \\min(W-1, i_R+s)]}} \\left\\{ dp[j-1][p_L][p_R] \\right\\}\n$$\nwhere $\\delta_{i_L, i_R}$ is the Kronecker delta, equal to $1$ if $i_L=i_R$ and $0$ otherwise.\n\nThe minimization term represents a 2D range minimum query over a rectangular region in the $dp[j-1]$ cost matrix. This can be computed efficiently. For each state $(j, i_L, i_R)$, we find the minimum value in the submatrix of $dp[j-1]$ defined by the support constraints.\n\nAfter populating the entire DP table from $j=1$ to $H$, the solution is found by identifying the minimum mass among all feasible final structures. A feasible structure is one where the paths meet, i.e., $i_L = i_R$. The meeting can occur at any voxel $(i, j)$ for $j \\in \\{0, \\dots, H\\}$ and $i \\in \\{0, \\dots, W-1\\}$. The cost of such a structure is given by $dp[j][i][i]$. The overall minimum mass is the minimum of these values over all possible meeting points.\n$$\nM_{min} = \\min_{\\substack{j \\in \\{0, \\dots, H\\} \\\\ i \\in \\{0, \\dots, W-1\\}}} \\left\\{ dp[j][i][i] \\right\\}\n$$\n\nIf this minimum value is infinity, it implies that no meeting of paths is possible within the given constraints ($W, H, s$), and the problem is infeasible. In this case, the specified output is $-1$.\n\nAlgorithm summary:\n$1$. Handle the trivial case $W=1$: the mass is $1$.\n$2$. Initialize a 3D DP table $dp[H+1][W][W]$ with $\\infty$.\n$3$. Set the base case: $dp[0][0][W-1] = 2$.\n$4$. Iterate $j$ from $1$ to $H$. For each $j$, compute the $dp[j]$ matrix based on $dp[j-1]$ using the recurrence. The minimization for each state $(i_L, i_R)$ is performed over a rectangular window of size up to $(2s+1) \\times (2s+1)$ in the $dp[j-1]$ matrix.\n$5$. After the DP table is complete, find the minimum value on the diagonals of all layer matrices: $\\min(dp[:, i, i])$ for all $i$.\n$6$. If the resulting minimum is $\\infty$, return $-1$. Otherwise, return the minimum mass as an integer. This algorithm correctly determines the minimal mass for any valid input.",
            "answer": "```python\nimport numpy as np\n\ndef solve_case(W, H, s):\n    \"\"\"\n    Computes the minimal mass of a self-supporting bridge structure.\n\n    This function uses dynamic programming to solve the problem. The state is\n    defined as dp[j][i_L][i_R], representing the minimum mass of a structure\n    with two paths ending at layer j, at horizontal positions i_L and i_R.\n    \"\"\"\n    if W = 0 or H  0 or s = 0:\n        # Invalid parameters based on problem constraints\n        return -1\n\n    if W == 1:\n        # If width is 1, anchors are at the same point. A single voxel is sufficient.\n        return 1\n\n    # dp[j][i_L][i_R]: min mass for paths ending at (i_L, j) and (i_R, j)\n    # Using np.inf for unreachable states.\n    dp = np.full((H + 1, W, W), np.inf, dtype=np.float64)\n\n    # Base case at j=0 (build plate)\n    # The two paths start at the anchors (0,0) and (W-1,0). Mass is 2.\n    dp[0, 0, W - 1] = 2.0\n\n    # Iterate through layers from 1 to H\n    for j in range(1, H + 1):\n        # We can optimize the search for the minimum in the previous layer's window.\n        # Instead of a complex sliding window, a direct slicing approach with NumPy\n        # is clear and fast enough for the given constraints.\n        prev_dp = dp[j - 1, :, :]\n        \n        # This part can be slow if written with Python loops.\n        # Let's vectorize or use efficient lookups.\n        # A 2D range minimum query structure would be optimal, but let's precompute.\n        \n        # Precompute horizontal sliding window minimums\n        h_min_vals = np.full((W, W), np.inf)\n        for r in range(W):\n            if np.all(np.isinf(prev_dp[r, :])):\n                continue\n            # Deque-based sliding window minimum for O(W) per row\n            q = []\n            for c in range(W):\n                # Window is [max(0, c-s), min(W-1, c+s)]\n                # Add current element\n                while q and prev_dp[r, q[-1]] >= prev_dp[r, c]:\n                    q.pop()\n                q.append(c)\n                # Remove elements outside the right boundary of the *first* window C belongs to\n                # The window is centered at an index k, [k-s, k+s]\n                # We are at c. We want to find min for window centered at c-s.\n                # Window for k is [k-s, k+s]\n                # We need min for all k in range(W)\n            # The above logic is complex to map to a single pass. Let's use a simpler method.\n            # Simple (but slower O(W*s)) implementation of sliding window min for each row\n            for c in range(W):\n                c_min = max(0, c - s)\n                c_max = min(W, c + s + 1)\n                h_min_vals[r, c] = np.min(prev_dp[r, c_min:c_max])\n\n        # Precompute vertical sliding window minimums on the result of horizontal mins\n        min_prev_dp = np.full((W, W), np.inf)\n        for c in range(W):\n            if np.all(np.isinf(h_min_vals[:, c])):\n                continue\n            for r in range(W):\n                r_min = max(0, r - s)\n                r_max = min(W, r + s + 1)\n                min_prev_dp[r, c] = np.min(h_min_vals[r_min:r_max, c])\n        \n        # Compute dp for current layer j\n        for i_L in range(W):\n            for i_R in range(W):\n                min_cost = min_prev_dp[i_L, i_R]\n                if np.isinf(min_cost):\n                    continue\n                \n                cost_increment = 2.0 if i_L != i_R else 1.0\n                dp[j, i_L, i_R] = min_cost + cost_increment\n\n    # The minimal mass is the minimum of all states where the paths meet (i_L == i_R)\n    min_mass = np.inf\n    for j in range(H + 1):\n        for i in range(W):\n            min_mass = min(min_mass, dp[j, i, i])\n    \n    if np.isinf(min_mass):\n        return -1\n    else:\n        return int(min_mass)\n\ndef solve():\n    \"\"\"\n    Runs the solver for the given test suite and prints the formatted output.\n    \"\"\"\n    test_cases = [\n        (9, 5, 1),   # Case A\n        (13, 3, 2),  # Case B\n        (11, 4, 1),  # Case C\n        (1, 0, 1),   # Case D\n        (20, 4, 3),  # Case E\n    ]\n\n    results = []\n    for W, H, s in test_cases:\n        result = solve_case(W, H, s)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Many engineering problems involve finding a \"center\" point within a complex region, whether for placing a sensor, a support column, or a distribution hub. This exercise tackles this by asking you to find the \"minimax center\"â€”the point that minimizes the maximum distance to any part of a given geometric region. This practice showcases a powerful problem-solving paradigm: using a fundamental insight from convex geometry to simplify a problem over an infinite, continuous space into a manageable one involving a finite number of points, which can then be solved with standard numerical optimization techniques .",
            "id": "2420377",
            "problem": "You are given a family of feasible regions in the plane described as unions of simple polygons. For each region, define its minimax center as the point in the Euclidean plane that minimizes the maximum Euclidean distance to any point in the region. Formally, for a nonempty compact feasible set $\\mathcal{S} \\subset \\mathbb{R}^2$, define the objective function\n$$\nf(\\mathbf{x}) = \\max_{\\mathbf{y} \\in \\mathcal{S}} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2,\n$$\nand define the minimax center as any minimizer $\\mathbf{x}^\\star \\in \\mathbb{R}^2$ of $f(\\mathbf{x})$. The corresponding optimal objective value is the minimax radius $r^\\star = f(\\mathbf{x}^\\star)$. Note that $\\mathbf{x}^\\star$ is not required to belong to $\\mathcal{S}$.\n\nYour task is to write a complete program that, for each specified test case, computes the minimax center $\\mathbf{x}^\\star$ and the minimax radius $r^\\star$, and reports them numerically.\n\nThe feasible region for each test case is the union of one or more simple polygons in $\\mathbb{R}^2$ given by lists of their vertices in counterclockwise order. Each polygon is the filled-in region bounded by the straight-line edges joining successive vertices (with the last vertex connected back to the first). All coordinates are expressed in dimensionless Cartesian units.\n\nYou must respect the following requirements:\n\n- Treat the problem in purely mathematical terms: given $\\mathcal{S}$ as a union of polygons, compute $\\mathbf{x}^\\star \\in \\mathbb{R}^2$ and $r^\\star \\in \\mathbb{R}_{\\ge 0}$ minimizing $f(\\mathbf{x})$ as defined above.\n- The answer requires no physical units and no angles.\n- Your program must not hard-code the answers. It must implement a general solver for the described task.\n\nTest suite to implement and solve:\n\n- Case $\\mathbf{1}$ (non-convex union of two disjoint squares):\n  - Polygon $\\mathbf{A}$ vertices: $\\left(-4,-1\\right)$, $\\left(-2,-1\\right)$, $\\left(-2,1\\right)$, $\\left(-4,1\\right)$.\n  - Polygon $\\mathbf{B}$ vertices: $\\left(2,-1\\right)$, $\\left(4,-1\\right)$, $\\left(4,1\\right)$, $\\left(2,1\\right)$.\n\n- Case $\\mathbf{2}$ (nearly colinear thin rectangle, a boundary condition):\n  - Single polygon with vertices: $\\left(0,0\\right)$, $\\left(10,0\\right)$, $\\left(10,0.001\\right)$, $\\left(0,0.001\\right)$.\n\n- Case $\\mathbf{3}$ (concave U-shaped polygon):\n  - Single polygon with vertices: $\\left(-3,-2\\right)$, $\\left(3,-2\\right)$, $\\left(3,2\\right)$, $\\left(1,2\\right)$, $\\left(1,0\\right)$, $\\left(-1,0\\right)$, $\\left(-1,2\\right)$, $\\left(-3,2\\right)$.\n\n- Case $\\mathbf{4}$ (acute triangle where three points determine the optimum):\n  - Single polygon with vertices: $\\left(0,0\\right)$, $\\left(2,0\\right)$, $\\left(1,\\sqrt{3}\\right)$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, output a list of three floating-point numbers $\\left[x^\\star, y^\\star, r^\\star\\right]$ rounded to exactly $6$ decimal places, in the same order as the cases above. The final output must therefore be of the form\n$$\n\\left[\\left[x^\\star_1,y^\\star_1,r^\\star_1\\right],\\left[x^\\star_2,y^\\star_2,r^\\star_2\\right],\\left[x^\\star_3,y^\\star_3,r^\\star_3\\right],\\left[x^\\star_4,y^\\star_4,r^\\star_4\\right]\\right].\n$$\nFor example, the output format should look like $\\left[\\left[0.000000,0.000000,1.234567\\right],\\ldots\\right]$ with no spaces.\n\nYour implementation must be a complete, runnable program that constructs the above test cases internally and prints the required single-line output.",
            "solution": "The problem as stated is valid. It is a well-posed optimization problem within the domain of computational geometry, formulated with objective and precise language. All necessary data is provided. I will proceed with a solution.\n\nThe problem asks for the computation of the minimax center $\\mathbf{x}^\\star \\in \\mathbb{R}^2$ and the corresponding minimax radius $r^\\star \\in \\mathbb{R}_{\\ge 0}$ for a given compact set $\\mathcal{S} \\subset \\mathbb{R}^2$. The set $\\mathcal{S}$ is described as a union of simple polygons. The minimax center is the point that minimizes the maximum Euclidean distance to any point in $\\mathcal{S}$. This is formally stated as finding $\\mathbf{x}^\\star = \\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^2} f(\\mathbf{x})$, where the objective function is $f(\\mathbf{x}) = \\max_{\\mathbf{y} \\in \\mathcal{S}} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2$. This is equivalent to finding the center and radius of the smallest enclosing circle of the set $\\mathcal{S}$.\n\nA fundamental principle of convex analysis dictates the path to a solution. For any fixed point $\\mathbf{x}$, the function $g(\\mathbf{y}) = \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2$ is a convex function of $\\mathbf{y}$. A convex function defined on a compact set attains its maximum at an extreme point of the set's convex hull. The given set $\\mathcal{S}$ is a union of polygons, which is a compact set. Let $\\text{conv}(\\mathcal{S})$ denote the convex hull of $\\mathcal{S}$. The extreme points of $\\text{conv}(\\mathcal{S})$ are a subset of the vertices of the input polygons.\n\nLet $V$ be the set of all vertices from all polygons that constitute $\\mathcal{S}$. The convex hull of $\\mathcal{S}$ is identical to the convex hull of its vertices, $\\text{conv}(\\mathcal{S}) = \\text{conv}(V)$. Let $V_{\\text{ext}} \\subseteq V$ be the set of vertices that form the boundary of $\\text{conv}(V)$. The objective function can therefore be simplified, as the maximum distance from $\\mathbf{x}$ to any point in $\\mathcal{S}$ will be the maximum distance to one of these extreme vertices:\n$$\nf(\\mathbf{x}) = \\max_{\\mathbf{y} \\in \\mathcal{S}} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2 = \\max_{\\mathbf{y} \\in \\text{conv}(\\mathcal{S})} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2 = \\max_{\\mathbf{v} \\in V_{\\text{ext}}} \\lVert \\mathbf{x} - \\mathbf{v} \\rVert_2\n$$\nThis reduces the problem from dealing with an infinite set of points in $\\mathcal{S}$ to a finite set of points $V_{\\text{ext}}$. The task is now to find the smallest enclosing circle for this finite point set $V_{\\text{ext}}$.\n\nThis problem can be formulated as a convex optimization problem. Let the unknown center of the circle be $\\mathbf{x} = (x, y)$ and its radius be $r$. We want to minimize $r$, which is equivalent to minimizing $r^2$. The constraint is that all points $\\mathbf{v}_i \\in V_{\\text{ext}}$ must lie within or on the boundary of this circle. This is expressed mathematically as:\n$$\n\\lVert \\mathbf{x} - \\mathbf{v}_i \\rVert_2 \\le r \\quad \\forall \\mathbf{v}_i \\in V_{\\text{ext}}\n$$\nTo create a more convenient formulation for standard solvers, we use the squared radius $R = r^2$ and the squared distance:\n$$\n\\lVert \\mathbf{x} - \\mathbf{v}_i \\rVert_2^2 \\le R \\quad \\forall \\mathbf{v}_i \\in V_{\\text{ext}}\n$$\nLetting $\\mathbf{v}_i = (v_{ix}, v_{iy})$, the optimization problem is:\n$$\n\\min_{x, y, R} R\n$$\nsubject to:\n$$\n(x - v_{ix})^2 + (y - v_{iy})^2 - R \\le 0 \\quad \\forall \\mathbf{v}_i \\in V_{\\text{ext}}\n$$\n$$\nR \\ge 0\n$$\nThis is a Quadratically Constrained Program (QCP) with a linear objective function and convex quadratic constraints. It can be solved numerically using standard optimization algorithms.\n\nThe algorithmic procedure is as follows:\n$1$. For each test case, aggregate the vertices of all given polygons into a single set of points $V$.\n$2$. Compute the convex hull of the point set $V$ to identify the extreme vertices $V_{\\text{ext}}$. This is accomplished using the `ConvexHull` function from the `scipy.spatial` library.\n$3$. Solve the aforementioned QCP. We employ the `minimize` function from `scipy.optimize` with the Sequential Least Squares Programming (`SLSQP`) method. The optimization variables are $(x, y, R)$.\n$4$. The objective function passed to the solver is simply $R$.\n$5$. The constraints are formulated as a list of functions, one for each vertex $\\mathbf{v}_i \\in V_{\\text{ext}}$, ensuring $(x - v_{ix})^2 + (y - v_{iy})^2 - R \\le 0$. A non-negativity bound on $R$ is also imposed.\n$6$. An initial guess for the optimization is constructed. The centroid of $V_{\\text{ext}}$ is used as the initial center $(x_0, y_0)$, and the initial squared radius $R_0$ is the maximum squared distance from this centroid to any vertex in $V_{\\text{ext}}$.\n$7$. The solver iteratively refines this guess to find the optimal solution $(x^\\star, y^\\star, R^\\star)$.\n$8$. The final minimax center is $\\mathbf{x}^\\star = (x^\\star, y^\\star)$ and the minimax radius is $r^\\star = \\sqrt{R^\\star}$. This procedure is repeated for each test case described in the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial import ConvexHull\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to solve the minimax center problem for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: non-convex union of two disjoint squares\n        [[(-4,-1), (-2,-1), (-2,1), (-4,1)],\n         [(2,-1), (4,-1), (4,1), (2,1)]],\n        # Case 2: nearly colinear thin rectangle\n        [[ (0,0), (10,0), (10,0.001), (0,0.001)]],\n        # Case 3: concave U-shaped polygon\n        [[(-3,-2), (3,-2), (3,2), (1,2), (1,0), (-1,0), (-1,2), (-3,2)]],\n        # Case 4: acute triangle\n        [[(0,0), (2,0), (1,math.sqrt(3))]]\n    ]\n\n    def compute_minimax_center(polygons):\n        \"\"\"\n        Computes the minimax center and radius for a set of polygons.\n\n        The problem is reduced to finding the smallest enclosing circle of the\n        set of vertices of the convex hull of the union of the polygons. This\n        is solved as a convex optimization problem.\n        \"\"\"\n        # 1. Aggregate all vertices from all polygons\n        all_vertices = np.vstack([np.array(p, dtype=float) for p in polygons])\n        \n        # Handle cases with few points where ConvexHull would fail\n        unique_vertices = np.unique(all_vertices, axis=0)\n        \n        if unique_vertices.shape[0]  2:\n            center = unique_vertices[0]\n            return center[0], center[1], 0.0\n\n        if unique_vertices.shape[0] == 2:\n            p1, p2 = unique_vertices[0], unique_vertices[1]\n            center = (p1 + p2) / 2.0\n            radius = np.linalg.norm(p1 - p2) / 2.0\n            return center[0], center[1], radius\n\n        # 2. Compute the convex hull of the vertices\n        try:\n            hull = ConvexHull(unique_vertices)\n            hull_vertices = unique_vertices[hull.vertices]\n        except: # QhullError often for colinear points\n             # For colinear points, the smallest enclosing circle's diameter\n             # is the distance between the two extreme points.\n            max_dist = 0\n            p1_max, p2_max = None, None\n            for i in range(len(unique_vertices)):\n                for j in range(i + 1, len(unique_vertices)):\n                    dist = np.linalg.norm(unique_vertices[i] - unique_vertices[j])\n                    if dist > max_dist:\n                        max_dist = dist\n                        p1_max = unique_vertices[i]\n                        p2_max = unique_vertices[j]\n            center = (p1_max + p2_max) / 2.0\n            radius = max_dist / 2.0\n            return center[0], center[1], radius\n\n        # 3. Set up the optimization problem\n        # Variables: p = [x, y, r_squared]\n\n        # Initial guess based on the centroid of the hull vertices\n        initial_center = np.mean(hull_vertices, axis=0)\n        initial_r_squared = np.max(np.sum((hull_vertices - initial_center)**2, axis=1))\n        p0 = np.array([initial_center[0], initial_center[1], initial_r_squared])\n\n        # Objective function: minimize r_squared (p[2])\n        objective = lambda p: p[2]\n\n        # Constraints: (x - v_x)^2 + (y - v_y)^2 = r_squared for each v in hull_vertices\n        # The form for SLSQP is fun(p) >= 0.\n        constraints = []\n        for v in hull_vertices:\n            constraints.append({\n                'type': 'ineq',\n                'fun': lambda p, v_pt=v: p[2] - ((p[0] - v_pt[0])**2 + (p[1] - v_pt[1])**2)\n            })\n\n        # Bounds for variables: r_squared must be non-negative\n        bounds = [(None, None), (None, None), (0, None)]\n\n        # 4. Run the optimizer\n        result = minimize(\n            objective,\n            p0,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=constraints,\n            tol=1e-12, # High tolerance for precision\n            options={'maxiter': 1000}\n        )\n        \n        if not result.success:\n            raise RuntimeError(f\"Optimization failed: {result.message}\")\n\n        # 5. Extract and return the results\n        x_star, y_star, r_squared_star = result.x\n        r_star = np.sqrt(r_squared_star)\n\n        return x_star, y_star, r_star\n\n    results = []\n    for case_polygons in test_cases:\n        x_star, y_star, r_star = compute_minimax_center(case_polygons)\n        results.append(f\"[{x_star:.6f},{y_star:.6f},{r_star:.6f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}