{
    "hands_on_practices": [
        {
            "introduction": "理论上的收敛阶数，如 $O(h)$ 和 $O(h^2)$，为我们选择数值格式提供了重要指导，但在实践中，情况往往更为复杂。本练习将通过一个具体的编程任务，让你亲手探索不同有限差分格式在处理高频振荡函数时的表现 。你将不仅验证中心差分的二阶精度优势，还将深入理解当网格无法解析波形时产生的振幅和相位误差，并揭示步长 $h$ 过小导致的舍入误差问题，从而对数值微分的实际应用建立深刻直观的认识。",
            "id": "2391174",
            "problem": "您将编写一个完整的程序，用于评估标准有限差分近似在一个高度振荡函数的一阶导数上的绝对逐点误差。测试函数为 $f(x) = \\sin(50x)$，其中角度以弧度为单位。其精确导数为 $f'(x) = 50\\cos(50x)$。您的目标是研究误差如何依赖于步长 $h$ 和所选择的差分格式，特别是当无量纲波数 $\\theta = 50h$ 变大时。\n\n从第一性原理出发，推导以下一阶导数有限差分格式在点 $x$ 处的主阶截断行为和精确离散响应：\n- 前向差分：$D^{+}_h f(x) = \\dfrac{f(x+h) - f(x)}{h}$。\n- 后向差分：$D^{-}_h f(x) = \\dfrac{f(x) - f(x-h)}{h}$。\n- 中心差分：$D^{0}_h f(x) = \\dfrac{f(x+h) - f(x-h)}{2h}$。\n\n从导数定义 $f'(x) = \\lim_{h\\to 0} \\dfrac{f(x+h)-f(x)}{h}$ 和 $f(x\\pm h)$ 在 $x$ 点的泰勒级数展开式开始。不要使用任何未经推导的现成有限差分误差公式。在为一般光滑函数 $f$ 建立主阶截断误差后，将您的分析具体应用到正弦函数 $f(x)=\\sin(\\omega x)$（其中 $\\omega=50$），并根据无量纲参数 $\\theta=\\omega h$ 说明离散近似如何同时改变振幅和相位。定性解释为什么当 $\\theta$ 接近 $\\pi$ 时精度会下降，以及为什么极小的 $h$ 会因浮点舍入而遭遇有效数字损失。\n\n然后，实现一个程序，该程序：\n1. 定义 $f(x)=\\sin(50x)$ 和 $f'(x)=50\\cos(50x)$，其中 $x$ 以弧度为单位。\n2. 实现三种格式 $D^{+}_h$、$D^{-}_h$ 和 $D^{0}_h$。\n3. 对于下述每个测试用例，在固定点 $x_0 = 0.7$（弧度）处使用双精度算术计算绝对逐点误差 $|D_h f(x_0) - f'(x_0)|$。\n4. 生成单行输出，其中包含一个误差列表，格式为方括号内以逗号分隔的值，其顺序与测试套件完全一致。\n\n测试套件（每个用例是一对格式和步长 $h$）：\n- $(\\text{中心}, h = 0.001)$\n- $(\\text{前向}, h = 0.001)$\n- $(\\text{后向}, h = 0.001)$\n- $(\\text{中心}, h = 0.02)$\n- $(\\text{前向}, h = 0.02)$\n- $(\\text{中心}, h = 0.04)$\n- $(\\text{前向}, h = 0.06)$\n- $(\\text{中心}, h = 0.062)$\n- $(\\text{中心}, h = \\pi/50)$\n- $(\\text{中心}, h = 10^{-8})$\n- $(\\text{前向}, h = 10^{-8})$\n\n所有角度均以弧度为单位。最终输出必须为以下格式：单行输出，包含误差列表，例如 $[e_1,e_2,\\dots,e_{11}]$，其中每个 $e_k$ 是您的程序按上述顺序计算出的浮点数。不得打印任何额外文本。",
            "solution": "有限差分法的基础是泰勒级数展开。对于一个在点 $x$ 邻域内足够光滑（即具有足够阶数的连续导数）的函数 $f(x)$，我们可以写出：\n$$f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2!}f''(x) + \\frac{h^3}{3!}f'''(x) + O(h^4)$$\n$$f(x-h) = f(x) - hf'(x) + \\frac{h^2}{2!}f''(x) - \\frac{h^3}{3!}f'''(x) + O(h^4)$$\n这些展开式是我们推导指定数值格式性质的基础。\n\n**1. 前向差分格式：$D^{+}_h f(x)$**\n我们重排 $f(x+h)$ 的泰勒展开式以分离出一阶导数项 $f'(x)$。\n$$f(x+h) - f(x) = hf'(x) + \\frac{h^2}{2}f''(x) + O(h^3)$$\n两边同除以 $h$ 得到 $f'(x)$ 的近似值：\n$$\\frac{f(x+h) - f(x)}{h} = f'(x) + \\frac{h}{2}f''(x) + O(h^2)$$\n左边的表达式就是前向差分算子 $D^{+}_h f(x)$。截断误差 $E_T$ 是近似值与真实导数之间的差：\n$$E_T^{(+)} = D^{+}_h f(x) - f'(x) = \\frac{h}{2}f''(x) + O(h^2)$$\n主阶误差与 $h$ 成正比，因此该格式为一阶精度。\n\n**2. 后向差分格式：$D^{-}_h f(x)$**\n类似地，我们使用 $f(x-h)$ 的展开式：\n$$f(x) - f(x-h) = hf'(x) - \\frac{h^2}{2}f''(x) + O(h^3)$$\n两边同除以 $h$ 得到后向差分近似：\n$$\\frac{f(x) - f(x-h)}{h} = f'(x) - \\frac{h}{2}f''(x) + O(h^2)$$\n截断误差为：\n$$E_T^{(-)} = D^{-}_h f(x) - f'(x) = -\\frac{h}{2}f''(x) + O(h^2)$$\n该格式也是一阶精度，其主阶误差项的量级与前向差分格式相同，但符号相反。\n\n**3. 中心差分格式：$D^{0}_h f(x)$**\n为了推导中心差分格式，我们用 $f(x+h)$ 的展开式减去 $f(x-h)$ 的展开式：\n$$f(x+h) - f(x-h) = \\left(f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x)\\right) - \\left(f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(x)\\right) + O(h^5)$$\n$$f(x+h) - f(x-h) = 2hf'(x) + \\frac{h^3}{3}f'''(x) + O(h^5)$$\n注意到涉及 $h$ 的偶次幂的项（以及像 $f''(x)$ 这样的偶数阶导数）被消去了。解出 $f'(x)$：\n$$\\frac{f(x+h) - f(x-h)}{2h} = f'(x) + \\frac{h^2}{6}f'''(x) + O(h^4)$$\n截断误差为：\n$$E_T^{(0)} = D^{0}_h f(x) - f'(x) = \\frac{h^2}{6}f'''(x) + O(h^4)$$\n主阶误差与 $h^2$ 成正比，使得该格式为二阶精度。对于小的 $h$，该格式比一阶的前向和后向格式要精确得多。\n\n**对 $f(x) = \\sin(\\omega x)$ 的分析**\n我们现在分析这些格式对于振荡函数 $f(x) = \\sin(\\omega x)$（其中 $\\omega=50$）的离散响应。精确导数为 $f'(x) = \\omega\\cos(\\omega x)$。我们使用无量纲波数 $\\theta = \\omega h$。\n\n**前向差分响应：**\n使用三角恒等式 $\\sin(A) - \\sin(B) = 2\\cos\\left(\\frac{A+B}{2}\\right)\\sin\\left(\\frac{A-B}{2}\\right)$：\n$$D^{+}_h \\sin(\\omega x) = \\frac{\\sin(\\omega(x+h)) - \\sin(\\omega x)}{h} = \\frac{2\\cos(\\omega x + \\frac{\\omega h}{2})\\sin(\\frac{\\omega h}{2})}{h}$$\n注意到 $h = \\theta/\\omega$：\n$$D^{+}_h \\sin(\\omega x) = \\omega \\frac{\\sin(\\theta/2)}{\\theta/2} \\cos(\\omega x + \\theta/2)$$\n与精确导数 $\\omega\\cos(\\omega x)$ 相比，前向差分格式引入了一个振幅修正因子 $\\frac{\\sin(\\theta/2)}{\\theta/2}$ 和一个相位误差 $+\\theta/2$。\n\n**后向差分响应：**\n遵循类似的过程：\n$$D^{-}_h \\sin(\\omega x) = \\frac{\\sin(\\omega x) - \\sin(\\omega(x-h))}{h} = \\frac{2\\cos(\\omega x - \\frac{\\omega h}{2})\\sin(\\frac{\\omega h}{2})}{h}$$\n$$D^{-}_h \\sin(\\omega x) = \\omega \\frac{\\sin(\\theta/2)}{\\theta/2} \\cos(\\omega x - \\theta/2)$$\n后向差分具有相同的振幅修正，但相位误差相反，为 $-\\theta/2$。\n\n**中心差分响应：**\n使用相同的恒等式：\n$$D^{0}_h \\sin(\\omega x) = \\frac{\\sin(\\omega(x+h)) - \\sin(\\omega(x-h))}{2h} = \\frac{2\\cos(\\omega x)\\sin(\\omega h)}{2h}$$\n$$D^{0}_h \\sin(\\omega x) = \\omega \\frac{\\sin(\\omega h)}{\\omega h} \\cos(\\omega x) = \\omega \\frac{\\sin(\\theta)}{\\theta} \\cos(\\omega x)$$\n中心差分格式将振幅修正了一个因子 $\\frac{\\sin(\\theta)}{\\theta}$，但关键的是，它不引入相位误差。这种相位的保持是其在波传播模拟中具有优越性的一个关键原因。\n\n**定性误差分析**\n\n**$\\theta$ 较大时的精度下降：**\n参数 $\\theta = \\omega h = 2\\pi h / \\lambda$，其中 $\\lambda = 2\\pi/\\omega$ 是函数的波长。因此，$\\theta$ 代表单个网格步长上的相移，或者是每个波长内网格点数的 $2\\pi$ 倍。Nyquist-Shannon采样定理指出，为了分辨一个正弦波，必须以其自身频率的两倍以上的频率对其进行采样，这意味着每个波长需要使用两个以上的点。$\\theta = \\pi$ 对应于每个波长恰好有两个点 ($h = \\lambda/2$)。\n对于中心差分，振幅因子为 $\\sin(\\theta)/\\theta$。当 $\\theta \\to \\pi$ 时，该因子趋向于 $\\sin(\\pi)/\\pi = 0$。该格式计算出的导数为零，完全无法捕捉到波形。这是因为在 $h = \\pi/\\omega$ 时，我们有 $f(x+h) = \\sin(\\omega x + \\pi) = -\\sin(\\omega x)$ 和 $f(x-h) = \\sin(\\omega x - \\pi) = -\\sin(\\omega x)$，所以 $f(x+h) = f(x-h)$，导致中心差分公式中的分子为零。这是一种灾难性的混叠误差。为了获得准确的结果，必须保持 $\\theta \\ll 1$。\n\n**$h$ 较小时的有效数字损失：**\n有限差分计算中的数值误差有两个来源：截断误差和舍入误差。\n- 截断误差：这是截断泰勒级数所带来的数学误差。它随着 $h$ 的减小而减小（例如，与 $O(h)$ 或 $O(h^2)$ 同阶）。\n- 舍入误差：这源于浮点运算的有限精度。考虑前向差分的分子 $f(x+h) - f(x)$。对于非常小的 $h$，$f(x+h)$ 非常接近 $f(x)$。在有限精度系统中对它们进行相减会导致有效数字的损失，这种效应被称为灾难性抵消。这个小差值的相对误差会变得很大。这个误差随后又被除以小数 $h$ 而放大。最终结果中的舍入误差大约与 $\\epsilon_m/h$ 成正比，其中 $\\epsilon_m$ 是机器ε（对于双精度，约为 $10^{-16}$）。\n总误差是这两种相互竞争效应的总和。随着 $h$ 的减小，截断误差下降，而舍入误差上升。这意味着存在一个最优步长 $h_{opt}$，可以使总误差最小化。使用一个远小于 $h_{opt}$ 的步长，例如 $h = 10^{-8}$，将导致舍入误差占主导地位，从而得到比使用适度较大的 $h$ 时精度更低的结果。对于 $O(h^2)$ 的中心差分格式，截断误差下降得更快，因此与一阶格式相比，舍入误差在更大的 $h$ 值时就开始占主导地位。\n\n接下来的程序将为特定的测试用例计算这些误差。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Evaluates the absolute pointwise error of finite difference schemes for the\n    first derivative of a highly oscillatory function.\n    \"\"\"\n\n    # Define the test function and its exact derivative\n    # All angles are in radians.\n    omega = 50.0\n    def f(x: float) - float:\n        \"\"\"Test function f(x) = sin(50x).\"\"\"\n        return np.sin(omega * x)\n\n    def df_dx_exact(x: float) - float:\n        \"\"\"Exact derivative f'(x) = 50*cos(50x).\"\"\"\n        return omega * np.cos(omega * x)\n\n    # Define the finite difference schemes\n    def forward_diff(func, x: float, h: float) - float:\n        \"\"\"Forward difference approximation.\"\"\"\n        return (func(x + h) - func(x)) / h\n\n    def backward_diff(func, x: float, h: float) - float:\n        \"\"\"Backward difference approximation.\"\"\"\n        return (func(x) - func(x - h)) / h\n\n    def central_diff(func, x: float, h: float) - float:\n        \"\"\"Central difference approximation.\"\"\"\n        return (func(x + h) - func(x - h)) / (2 * h)\n\n    # Point of evaluation\n    x0 = 0.7\n\n    # Test suite as defined in the problem statement\n    test_cases = [\n        ('central', 0.001),\n        ('forward', 0.001),\n        ('backward', 0.001),\n        ('central', 0.02),\n        ('forward', 0.02),\n        ('central', 0.04),\n        ('forward', 0.06),\n        ('central', 0.062),\n        ('central', np.pi / omega),\n        ('central', 1e-8),\n        ('forward', 1e-8),\n    ]\n\n    # Calculate the exact derivative at x0\n    exact_value = df_dx_exact(x0)\n\n    results = []\n    for scheme_name, h in test_cases:\n        if scheme_name == 'central':\n            approx_value = central_diff(f, x0, h)\n        elif scheme_name == 'forward':\n            approx_value = forward_diff(f, x0, h)\n        elif scheme_name == 'backward':\n            approx_value = backward_diff(f, x0, h)\n        else:\n            # This case should not be reached with the given test suite\n            raise ValueError(f\"Unknown scheme: {scheme_name}\")\n\n        # Calculate absolute pointwise error\n        error = np.abs(approx_value - exact_value)\n        results.append(error)\n\n    # Print the results in the specified format\n    # The format must be exactly a list of comma-separated values in brackets.\n    print(f\"[{','.join(f'{err:.17g}' for err in results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "所有有限差分公式都建立在一个核心假设之上：函数在所考察点附近是足够光滑的，可以用泰勒级数进行局部逼近。然而，当这一基本假设不成立时会发生什么？本练习将通过分析绝对值函数 $f(x) = |x - c|$ 这一典型非光滑函数，引导你探究有限差分在“尖点”处的行为 。通过从第一性原理出发进行推导和计算，你将发现不同格式会给出截然不同甚至具有误导性的结果，从而深刻理解在应用数值方法时批判性地审视其适用前提的重要性。",
            "id": "2391178",
            "problem": "要求您分析函数 $f(x) = \\lvert x - c \\rvert$ 在其不可微点 $x = c$ 处及其附近的一阶导数的有限差分近似。请从第一性原理出发：使用导数的定义和单侧极限的概念，并回顾有限差分近似是通过用一个小的正步长 $h$ 替代极限并使用邻近采样点得到的。不要假设任何特定的现成有限差分公式；相反，应直接根据导数定义和对称性论证来证明前向、后向和中心近似的结构。\n\n您的任务是：\n\n1. 基于第一性原理的理论分析：\n   - 使用导数定义 $f'(x) = \\lim_{h \\to 0} \\dfrac{f(x+h) - f(x)}{h}$（当极限存在时），通过考虑小的正数 $h$ 和单侧采样，推导 $f'(x)$ 的标准一阶前向和一阶后向近似。另外，通过考虑对称采样 $x \\pm h$ 以及当 $f$ 在目标点平滑时奇数阶误差项抵消的思想，来论证中心近似的合理性。\n   - 将这些思想应用于 $f(x) = \\lvert x - c \\rvert$ 在 $x = c$ 处。确定当 $h  0$ 时，前向、后向和中心近似的计算结果（作为 $h$ 的函数）。基于此，解释中心近似在尖点处“失效”的意义（即，它产生一个看似稳定但并非单側导数且不能反映不可微性的值）。\n   - 分析远离尖点处的行为。对于 $x \\neq c$，确定 $h$ 的条件，使得近似所用的采样点保持在 $c$ 的同一侧（这样 $f$ 在局部与一个线性函数重合），并推断这对每种近似产生的数值导数有何影响。同时分析当 $h$ 大到足以使采样模板跨越尖点（$x-h  c  x+h$）时会发生什么，并解释其对中心和后向近似的影响。\n\n2. 计算研究：\n   - 使用固定参数 $c = 0.3$。\n   - 定义函数 $f(x) = \\lvert x - c \\rvert$，并根据您的推导实现以下三种近似：一阶前向近似、一阶后向近似和对称中心近似，每种都使用正步长 $h$。\n   - 使用以下旨在探究不同行为的测试套件。\n     - 尖点测试，在 $x = c$ 处：使用一个非常小的步长 $h_{\\text{cusp}} = 10^{-12}$ 来计算在 $x = c$ 处的三种近似。\n     - 平滑区域稳定性测试：选择 $x_{\\text{smooth}} = c + 0.4$ 和步长集合 $\\{2^{-3}, 2^{-4}, 2^{-5}, 2^{-6}\\}$。对于此集合中的每个步长，计算在 $x_{\\text{smooth}}$ 处的中心和前向近似，并测量与那里正确的单侧导数的最大绝对偏差。\n     - 跨越尖点测试：选择 $x_{\\text{cross}} = c + 0.01$ 和 $h_{\\text{cross}} = 0.02$。计算在 $x_{\\text{cross}}$ 处的中心和前向近似，以说明当中心近似的模板跨越尖点时其性能如何下降，而具有前向模板的前向近似可能仍保持在一侧。\n   - 您的程序必须按此精确顺序将以下八个结果聚合为单行输出：\n     $[$\n     在 $x=c$ 处使用 $h = 10^{-12}$ 的中心近似值，\n     在 $x=c$ 处使用 $h = 10^{-12}$ 的前向近似值，\n     在 $x=c$ 处使用 $h = 10^{-12}$ 的后向近似值，\n     在 $x=c$ 处使用 $h = 10^{-12}$ 的前向和后向近似值之间的绝对差，\n     在 $x_{\\text{smooth}}$ 处，中心近似值与正确导数的最大绝对偏差（对 $h \\in \\{2^{-3}, 2^{-4}, 2^{-5}, 2^{-6}\\}$），\n     在 $x_{\\text{smooth}}$ 处，前向近似值与正确导数的最大绝对偏差（对 $h \\in \\{2^{-3}, 2^{-4}, 2^{-5}, 2^{-6}\\}$），\n     在 $x_{\\text{cross}}$ 处使用 $h = 0.02$ 的中心近似值，\n     在 $x_{\\text{cross}}$ 处使用 $h = 0.02$ 的前向近似值\n     $]$。\n   - 最终输出格式必须是单行，包含用逗号分隔并括在方括号中的结果，例如 $[r_1,r_2,\\dots,r_8]$。所有输出均为无单位的实数。\n\n您的推理和实现需要具备科学真实性和自洽性。上面选择的数值是为了确保双精度算术足够使用，并且行为在性质上是稳健的。",
            "solution": "分析始于函数 $f(x)$ 在点 $x$ 处的导数定义：\n$$ f'(x) = \\lim_{\\Delta x \\to 0} \\frac{f(x+\\Delta x) - f(x)}{\\Delta x} $$\n为使导数有定义，此极限必须存在。有限差分近似是通过用一个小的、有限的步长（此处表示为 $h  0$）替换此极限过程而得到的。\n\n首先，我们推导标准的有限差分公式。\n一阶前向差分近似通过设 $\\Delta x = h$ 得到，其中 $h$ 是一个小的正数：\n$$ D_{+h}f(x) = \\frac{f(x+h) - f(x)}{h} $$\n此公式在 $x$ 和 $x+h$ 处对函数进行采样。对于一个足够光滑的函数，$f(x+h)$ 在 $x$ 点的 Taylor 级数展开为 $f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + O(h^3)$。将此代入公式得到：\n$$ D_{+h}f(x) = \\frac{(f(x) + hf'(x) + O(h^2)) - f(x)}{h} = f'(x) + O(h) $$\n近似误差为 $h$ 阶，使其成为一阶方法。\n\n一阶后向差分近似通过设 $\\Delta x = -h$ 得到：\n$$ D_{-h}f(x) = \\frac{f(x-h) - f(x)}{-h} = \\frac{f(x) - f(x-h)}{h} $$\n此公式在 $x-h$ 和 $x$ 处对函数进行采样。Taylor 展开 $f(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) + O(h^3)$ 给出：\n$$ D_{-h}f(x) = \\frac{f(x) - (f(x) - hf'(x) + O(h^2))}{h} = f'(x) + O(h) $$\n这也是一个一阶方法。\n\n中心差分近似使用围绕 $x$ 的对称模板构建，在 $x-h$ 和 $x+h$ 处采样。有效步长为 $2h$：\n$$ D_{0h}f(x) = \\frac{f(x+h) - f(x-h)}{2h} $$\n它对光滑函数具有更高的精度，这可以通过从 $f(x+h)$ 的 Taylor 级数中减去 $f(x-h)$ 的 Taylor 级数来揭示：\n$$ f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + O(h^4) $$\n$$ f(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(x) + O(h^4) $$\n$$ f(x+h) - f(x-h) = 2hf'(x) + \\frac{h^3}{3}f'''(x) + O(h^5) $$\n除以 $2h$ 得到：\n$$ D_{0h}f(x) = f'(x) + \\frac{h^2}{6}f'''(x) + O(h^4) = f'(x) + O(h^2) $$\n主导误差项为 $h^2$ 阶，使其成为二阶方法。这种更高的精度依赖于 Taylor 级数中偶次幂项的抵消，而这又取决于函数在点 $x$ 处足够光滑（至少 $C^3$）。\n\n现在，我们将这些近似应用于函数 $f(x) = \\lvert x-c \\rvert$。该函数在 $x=c$ 处不光滑；其导数在该点不连续。因此，上述使用的 Taylor 级数展开在该点无效。\n\n在尖点 $x=c$ 处的行为：\n函数在尖点的值为 $f(c) = \\lvert c-c \\rvert = 0$。对于任何 $h  0$：\n前向近似为：\n$$ D_{+h}f(c) = \\frac{f(c+h) - f(c)}{h} = \\frac{\\lvert(c+h)-c\\rvert - 0}{h} = \\frac{\\lvert h \\rvert}{h} = \\frac{h}{h} = 1 $$\n此值对应于右导数 $f'_+(c) = 1$。\n后向近似为：\n$$ D_{-h}f(c) = \\frac{f(c) - f(c-h)}{h} = \\frac{0 - \\lvert(c-h)-c\\rvert}{h} = \\frac{-\\lvert -h \\rvert}{h} = \\frac{-h}{h} = -1 $$\n此值对应于左导数 $f'\\_(c) = -1$。\n中心近似为：\n$$ D_{0h}f(c) = \\frac{f(c+h) - f(c-h)}{2h} = \\frac{\\lvert h \\rvert - \\lvert -h \\rvert}{2h} = \\frac{h - h}{2h} = 0 $$\n中心差分“失效”的意义在于它产生一个稳定的值 $0$，但这并非函数在该点的导数（因为导数不存在）。这个结果源于模板围绕完美对称尖点的完美对称性，导致函数值 $f(c+h)$ 和 $f(c-h)$ 完全相同。结果 $0$ 隐藏了不可微性，并给人一种斜率为零的误导性印象。这个值恰好是单侧导数的平均值。\n\n远离尖点 $x \\neq c$ 处的行为：\n如果有限差分模板不跨越点 $x=c$，函数 $f(x)$ 在局部表现得像一个线性函数。\n假设 $x  c$。导数为 $f'(x) = 1$。如果模板的所有点都大于 $c$，则模板避开了尖点。对于中心和后向模板，这要求 $x-h  c$，即 $h  x-c$。对于前向模板 $[x, x+h]$，对于 $h  0$ 这总是成立的。如果 $h  x-c$，那么对于模板中的任何点 $u$，$u-c  0$，所以 $f(u) = u-c$。\n近似变为：\n$$ D_{+h}f(x) = \\frac{(x+h-c) - (x-c)}{h} = \\frac{h}{h} = 1 $$\n$$ D_{-h}f(x) = \\frac{(x-c) - (x-h-c)}{h} = \\frac{h}{h} = 1 $$\n$$ D_{0h}f(x) = \\frac{(x+h-c) - (x-h-c)}{2h} = \\frac{2h}{2h} = 1 $$\n所有三种方法都给出了精确的导数 $1$。\n假设 $x  c$。导数为 $f'(x) = -1$。如果 $x+h  c$（即 $h  c-x$），模板避开了尖点。如果这成立，对于模板中的所有点 $u$，$f(u) = c-u$。近似变为：\n$$ D_{+h}f(x) = \\frac{(c-(x+h)) - (c-x)}{h} = \\frac{-h}{h} = -1 $$\n$$ D_{-h}f(x) = \\frac{(c-x) - (c-(x-h))}{h} = \\frac{-h}{h} = -1 $$\n$$ D_{0h}f(x) = \\frac{(c-(x+h)) - (c-(x-h))}{2h} = \\frac{-2h}{2h} = -1 $$\n所有三种方法再次给出了精确的导数 $-1$。\n因此，只要模板不跨越奇点，有限差分方法对于这个分段线性函数是精确的。\n\n当模板跨越尖点时的行为：\n考虑 $x  c$ 但步长 $h$ 大到足以使 $x-h  c  x+h$ 的情况。这违反了条件 $h  x-c$。后向和中心近似的模板现在从尖点的两侧采样点。\n前向模板 $[x, x+h]$ 完全保留在区域 $uc$ 中，因此前向近似仍然是精确的：$D_{+h}f(x) = 1$。\n后向模板 $[x-h, x]$ 跨越了尖点。我们有 $f(x) = x-c$ 但 $f(x-h) = c - (x-h) = c-x+h$。近似为：\n$$ D_{-h}f(x) = \\frac{(x-c) - (c-x+h)}{h} = \\frac{2x - 2c - h}{h} $$\n中心模板 $[x-h, x+h]$ 也跨越了尖点。我们有 $f(x+h) = x+h-c$ 和 $f(x-h) = c-x+h$。近似为：\n$$ D_{0h}f(x) = \\frac{(x+h-c) - (c-x+h)}{2h} = \\frac{2x - 2c}{2h} = \\frac{x-c}{h} $$\n在这两种情况下，结果都不是正确的导数 $f'(x)=1$。数值方法因跨越奇点采样而受到污染，破坏了其推导所依据的局部光滑性假设。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs theoretical and computational analysis of finite difference\n    approximations for the derivative of f(x) = |x - c|.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    # Global constant c\n    c = 0.3\n\n    # Test Case 1: Cusp test\n    x_cusp = c\n    h_cusp = 1e-12\n\n    # Test Case 2: Smooth-region stability test\n    x_smooth = c + 0.4\n    h_smooth_set = np.array([2**-3, 2**-4, 2**-5, 2**-6])\n\n    # Test Case 3: Crossing-cusp test\n    x_cross = c + 0.01\n    h_cross = 0.02\n\n    # --- Function and Derivative Approximations ---\n    def f(x_val):\n        \"\"\"The function f(x) = |x - c|.\"\"\"\n        return np.abs(x_val - c)\n\n    def forward_diff(func, x, h):\n        \"\"\"First-order forward difference approximation.\"\"\"\n        return (func(x + h) - func(x)) / h\n\n    def backward_diff(func, x, h):\n        \"\"\"First-order backward difference approximation.\"\"\"\n        return (func(x) - func(x - h)) / h\n\n    def central_diff(func, x, h):\n        \"\"\"Second-order central difference approximation.\"\"\"\n        return (func(x + h) - func(x - h)) / (2 * h)\n\n    # --- Calculations ---\n    results = []\n\n    # 1. Central approximation at x=c\n    r1 = central_diff(f, x_cusp, h_cusp)\n    results.append(r1)\n\n    # 2. Forward approximation at x=c\n    r2 = forward_diff(f, x_cusp, h_cusp)\n    results.append(r2)\n\n    # 3. Backward approximation at x=c\n    r3 = backward_diff(f, x_cusp, h_cusp)\n    results.append(r3)\n\n    # 4. Absolute difference between forward and backward at x=c\n    r4 = np.abs(r2 - r3)\n    results.append(r4)\n\n    # 5. Maximum absolute deviation of central approximation at x_smooth\n    # The correct derivative at x_smooth = 0.7 is 1.0\n    correct_deriv_smooth = 1.0\n    central_devs = []\n    for h_val in h_smooth_set:\n        # Stencil is [x-h, x+h].\n        # x_smooth - c = 0.4. Largest h is 0.125.\n        # h  x_smooth - c, so stencil does not cross cusp. Approximation should be exact.\n        approx = central_diff(f, x_smooth, h_val)\n        central_devs.append(np.abs(approx - correct_deriv_smooth))\n    r5 = np.max(central_devs)\n    results.append(r5)\n\n    # 6. Maximum absolute deviation of forward approximation at x_smooth\n    forward_devs = []\n    for h_val in h_smooth_set:\n        # Stencil is [x, x+h]. Both points are to the right of c.\n        # Approximation should be exact.\n        approx = forward_diff(f, x_smooth, h_val)\n        forward_devs.append(np.abs(approx - correct_deriv_smooth))\n    r6 = np.max(forward_devs)\n    results.append(r6)\n\n    # 7. Central approximation at x_cross\n    # Here, x_cross - c = 0.01 and h_cross = 0.02.\n    # Since h_cross > x_cross - c, the stencil [x-h, x+h] crosses the cusp.\n    r7 = central_diff(f, x_cross, h_cross)\n    results.append(r7)\n\n    # 8. Forward approximation at x_cross\n    # The forward stencil [x, x+h] does not cross the cusp as x > c and h > 0.\n    r8 = forward_diff(f, x_cross, h_cross)\n    results.append(r8)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了基本有限差分格式的特性与局限后，一个自然的问题是：我们能否系统性地构造出精度更高的格式？理查森外推法（Richardson Extrapolation）为此提供了强有力的答案。其核心思想是，通过将同一个低阶格式在不同步长下的计算结果进行线性组合，可以逐级消除误差项，从而获得远超原始格式的高阶精度 。本练习将指导你运用这一思想，从基础的二阶中心差分出发，亲手构造一个六阶精度的导数近似格式，让你领略这一通用且强大的数值算法加速收敛技术的魅力。",
            "id": "2391187",
            "problem": "给定一个光滑标量函数 $f(x) = \\sin(x)$，任务是通过组合在三个步长下计算的二阶中心差分，为其一阶导数 $f^{\\prime}(x)$ 构建一个六阶精度的数值近似。令 $D(h)$ 表示在点 $x$ 处，步长为 $h$ 的 $f^{\\prime}(x)$ 的二阶中心差分近似，其定义为\n$$\nD(h) = \\frac{f(x+h) - f(x-h)}{2h}.\n$$\n仅使用上述定义和第一性原理（例如，关于 $x$ 的泰勒级数展开），确定构成 $D(h)$、$D\\left(\\frac{h}{2}\\right)$ 和 $D\\left(\\frac{h}{4}\\right)$ 的线性组合的常数，使其截断误差为 $h^{6}$ 阶，并实现一个程序，为指定的输入值计算此六阶近似。\n\n您的程序必须计算绝对数值误差，其定义为\n$$\nE(x,h) = \\left| \\widehat{f^{\\prime}}(x;h) - \\cos(x) \\right|,\n$$\n其中 $\\widehat{f^{\\prime}}(x;h)$ 是您由 $D(h)$、$D\\left(\\frac{h}{2}\\right)$ 和 $D\\left(\\frac{h}{4}\\right)$ 构建的六阶近似，而 $\\cos(x)$ 是 $\\sin(x)$ 的精确导数。所有角度均以弧度为单位。\n\n测试套件：\n- 情况 1：$x = 1.0$, $h = 0.2$ (弧度)。\n- 情况 2：$x = 0.0$, $h = 0.2$ (弧度)。\n- 情况 3：$x = \\frac{\\pi}{4}$, $h = 0.1$ (弧度)。\n- 情况 4：$x = \\frac{\\pi}{2}$, $h = 0.4$ (弧度)。\n- 情况 5：$x = 10.0$, $h = 0.05$ (弧度)。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个情况的绝对误差 $E(x,h)$，按顺序排列，并以逗号分隔的列表形式用方括号括起来。\n- 每个数字必须四舍五入到 $10$ 位小数。\n- 例如：$[e_1,e_2,e_3,e_4,e_5]$，其中每个 $e_i$ 是一个格式化为 $10$ 位小数的浮点数。",
            "solution": "该方法的基础是函数 $f(x)$ 在点 $x$ 附近的泰勒级数展开。假设函数足够光滑，我们有：\n$$ f(x+h) = f(x) + hf^{\\prime}(x) + \\frac{h^2}{2!}f^{\\prime\\prime}(x) + \\frac{h^3}{3!}f^{\\prime\\prime\\prime}(x) + \\frac{h^4}{4!}f^{(4)}(x) + \\frac{h^5}{5!}f^{(5)}(x) + \\frac{h^6}{6!}f^{(6)}(x) + \\frac{h^7}{7!}f^{(7)}(x) + \\mathcal{O}(h^8) $$\n$$ f(x-h) = f(x) - hf^{\\prime}(x) + \\frac{h^2}{2!}f^{\\prime\\prime}(x) - \\frac{h^3}{3!}f^{\\prime\\prime\\prime}(x) + \\frac{h^4}{4!}f^{(4)}(x) - \\frac{h^5}{5!}f^{(5)}(x) + \\frac{h^6}{6!}f^{(6)}(x) - \\frac{h^7}{7!}f^{(7)}(x) + \\mathcal{O}(h^8) $$\n从第一个展开式中减去第二个展开式，可以消除 $h$ 的偶次幂项：\n$$ f(x+h) - f(x-h) = 2hf^{\\prime}(x) + 2\\frac{h^3}{3!}f^{\\prime\\prime\\prime}(x) + 2\\frac{h^5}{5!}f^{(5)}(x) + 2\\frac{h^7}{7!}f^{(7)}(x) + \\mathcal{O}(h^9) $$\n两边同除以 $2h$，得到中心差分算子 $D(h)$ 的表达式：\n$$ D(h) = \\frac{f(x+h) - f(x-h)}{2h} = f^{\\prime}(x) + \\frac{h^2}{6}f^{\\prime\\prime\\prime}(x) + \\frac{h^4}{120}f^{(5)}(x) + \\frac{h^6}{5040}f^{(7)}(x) + \\mathcal{O}(h^8) $$\n这证实了 $D(h)$ 是 $f^{\\prime}(x)$ 的一个二阶精度近似，因为其主导误差项与 $h^2$ 成正比。我们可以将此误差结构更紧凑地写为：\n$$ D(h) = f^{\\prime}(x) + c_2 h^2 + c_4 h^4 + c_6 h^6 + \\mathcal{O}(h^8) $$\n其中 $c_{2k} = \\frac{f^{(2k+1)}(x)}{(2k+1)!}$。\n\n我们寻求一个六阶近似 $\\widehat{f^{\\prime}}(x;h)$，它是在三个不同步长下的近似值的线性组合：\n$$ \\widehat{f^{\\prime}}(x;h) = \\alpha D(h) + \\beta D\\left(\\frac{h}{2}\\right) + \\gamma D\\left(\\frac{h}{4}\\right) $$\n代入每一项的级数展开式：\n$$ \\widehat{f^{\\prime}} = \\alpha \\left( f^{\\prime}(x) + c_2 h^2 + c_4 h^4 + \\dots \\right) + \\beta \\left( f^{\\prime}(x) + c_2 \\left(\\frac{h}{2}\\right)^2 + c_4 \\left(\\frac{h}{2}\\right)^4 + \\dots \\right) + \\gamma \\left( f^{\\prime}(x) + c_2 \\left(\\frac{h}{4}\\right)^2 + c_4 \\left(\\frac{h}{4}\\right)^4 + \\dots \\right) $$\n为确保近似达到六阶精度，我们必须要求 $\\widehat{f^{\\prime}}$ 的组合表达式等于 $f^{\\prime}(x) + \\mathcal{O}(h^6)$。这可以通过按 $h$ 的幂次合并同类项，并将不需要的项的系数设为零来实现。\n\\begin{align*}\n\\widehat{f^{\\prime}} = (\\alpha + \\beta + \\gamma)f^{\\prime}(x) \\\\\n+ \\left(\\alpha + \\frac{\\beta}{4} + \\frac{\\gamma}{16}\\right)c_2 h^2 \\\\\n+ \\left(\\alpha + \\frac{\\beta}{16} + \\frac{\\gamma}{256}\\right)c_4 h^4 \\\\\n+ \\mathcal{O}(h^6)\n\\end{align*}\n这就得到了一个关于未知常数 $\\alpha$、$\\beta$ 和 $\\gamma$ 的三元线性方程组：\n1. $f^{\\prime}(x)$ 的系数必须为 $1$：$\\alpha + \\beta + \\gamma = 1$\n2. $h^2$ 的系数必须为 $0$：$\\alpha + \\frac{1}{4}\\beta + \\frac{1}{16}\\gamma = 0$\n3. $h^4$ 的系数必须为 $0$：$\\alpha + \\frac{1}{16}\\beta + \\frac{1}{256}\\gamma = 0$\n\n我们来解这个方程组。为清晰起见，将第二个方程乘以 $16$，第三个方程乘以 $256$：\n\\begin{align*}\n(1) \\quad \\alpha + \\beta + \\gamma = 1 \\\\\n(2) \\quad 16\\alpha + 4\\beta + \\gamma = 0 \\\\\n(3) \\quad 256\\alpha + 16\\beta + \\gamma = 0\n\\end{align*}\n方程 (3) 减去方程 (2)：\n$$ (256 - 16)\\alpha + (16 - 4)\\beta = 0 \\implies 240\\alpha + 12\\beta = 0 \\implies \\beta = -20\\alpha $$\n方程 (2) 减去方程 (1)：\n$$ 15\\alpha + 3\\beta = -1 $$\n将 $\\beta = -20\\alpha$ 代入此结果：\n$$ 15\\alpha + 3(-20\\alpha) = -1 \\implies 15\\alpha - 60\\alpha = -1 \\implies -45\\alpha = -1 \\implies \\alpha = \\frac{1}{45} $$\n现在我们求 $\\beta$ 和 $\\gamma$：\n$$ \\beta = -20\\alpha = -20 \\cdot \\frac{1}{45} = -\\frac{20}{45} = -\\frac{4}{9} $$\n$$ \\gamma = 1 - \\alpha - \\beta = 1 - \\frac{1}{45} - \\left(-\\frac{20}{45}\\right) = 1 + \\frac{19}{45} = \\frac{45+19}{45} = \\frac{64}{45} $$\n因此，六阶精度近似为：\n$$ \\widehat{f^{\\prime}}(x;h) = \\frac{1}{45}D(h) - \\frac{20}{45}D\\left(\\frac{h}{2}\\right) + \\frac{64}{45}D\\left(\\frac{h}{4}\\right) $$\n将实现此表达式以计算给定测试用例的数值导数。然后，绝对误差计算为 $E(x,h) = \\left| \\widehat{f^{\\prime}}(x;h) - \\cos(x) \\right|$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical differentiation problem by constructing and applying a\n    sixth-order accurate finite difference scheme.\n    \"\"\"\n\n    # Define the scalar function f(x) and its exact derivative\n    f = np.sin\n    f_prime_exact_func = np.cos\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 0.2),\n        (0.0, 0.2),\n        (np.pi / 4, 0.1),\n        (np.pi / 2, 0.4),\n        (10.0, 0.05)\n    ]\n\n    results = []\n\n    def central_difference(func, x_val, h_val):\n        \"\"\"\n        Computes the second-order central difference approximation D(h).\n        \"\"\"\n        return (func(x_val + h_val) - func(x_val - h_val)) / (2 * h_val)\n\n    # Coefficients for the sixth-order approximation\n    # f_hat' = a * D(h) + b * D(h/2) + g * D(h/4)\n    # The derivation shows:\n    # a = 1/45\n    # b = -20/45\n    # g = 64/45\n    alpha = 1.0 / 45.0\n    beta = -20.0 / 45.0\n    gamma = 64.0 / 45.0\n\n    for x, h in test_cases:\n        # Evaluate the second-order central differences at h, h/2, and h/4\n        d_h = central_difference(f, x, h)\n        d_h_2 = central_difference(f, x, h / 2.0)\n        d_h_4 = central_difference(f, x, h / 4.0)\n        \n        # Construct the sixth-order approximation using the derived coefficients\n        f_prime_approx = alpha * d_h + beta * d_h_2 + gamma * d_h_4\n        \n        # Calculate the exact derivative\n        f_prime_exact = f_prime_exact_func(x)\n        \n        # Calculate the absolute numerical error\n        error = np.abs(f_prime_approx - f_prime_exact)\n        \n        results.append(error)\n\n    # Final print statement in the exact required format.\n    # Each number is rounded to 10 decimal places.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}