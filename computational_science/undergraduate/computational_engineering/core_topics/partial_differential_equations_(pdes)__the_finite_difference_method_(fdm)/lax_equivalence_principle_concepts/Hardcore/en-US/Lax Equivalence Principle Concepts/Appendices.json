{
    "hands_on_practices": [
        {
            "introduction": "The Lax Equivalence Principle hinges on the twin pillars of consistency and stability. This first practice focuses on stability, the property that prevents numerical errors from growing uncontrollably. Through a direct analytical exercise , you will investigate how a seemingly minor perturbation to a classic stable scheme can catastrophically destroy its stability, highlighting why rigorous analysis is not just an academic pursuit but a practical necessity.",
            "id": "2407982",
            "problem": "Consider the linear advection equation $u_{t} + a\\,u_{x} = 0$ with constant wave speed $a \\in \\mathbb{R}$. On a uniform grid with spatial step $\\Delta x$ and time step $\\Delta t$, define the Courant number $\\nu = a\\,\\Delta t/\\Delta x$. The classical Lax–Friedrichs scheme updates the solution by replacing $u^{n}_{j}$ with a symmetric neighbor average. Now consider the following modified update that perturbs the averaging term by a small positive bias $\\varepsilon  0$:\n$$\nu^{n+1}_{j} = \\left(\\frac{1}{2} + \\varepsilon\\right)\\left(u^{n}_{j+1} + u^{n}_{j-1}\\right) \\;-\\; \\frac{\\nu}{2}\\left(u^{n}_{j+1} - u^{n}_{j-1}\\right).\n$$\nUsing a von Neumann Fourier-mode analysis with trial solutions of the form $u^{n}_{j} = \\hat{u}^{n}\\,\\exp(i j \\theta)$, determine the amplification factor $G(\\theta)$ and use it to quantify the linear stability of the scheme. Specifically, compute the quantity\n$$\n\\inf_{\\nu \\in \\mathbb{R}} \\;\\sup_{\\theta \\in \\mathbb{R}} \\,|G(\\theta)|,\n$$\nas an explicit closed-form expression in terms of $\\varepsilon$. Your final answer must be a single analytic expression. No rounding is required.",
            "solution": "The problem as stated is scientifically grounded, formally coherent, and well-posed. We may proceed with the solution.\n\nThe problem requires the stability analysis of a modified numerical scheme for the linear advection equation, $u_{t} + a\\,u_{x} = 0$. The scheme is given by:\n$$\nu^{n+1}_{j} = \\left(\\frac{1}{2} + \\varepsilon\\right)\\left(u^{n}_{j+1} + u^{n}_{j-1}\\right) - \\frac{\\nu}{2}\\left(u^{n}_{j+1} - u^{n}_{j-1}\\right)\n$$\nwhere $\\nu = a\\,\\Delta t/\\Delta x$ is the Courant number and $\\varepsilon  0$ is a constant bias. We use the von Neumann stability analysis, which examines the amplification of single Fourier modes.\n\nWe substitute the trial solution $u^{n}_{j} = \\hat{u}^{n}\\,\\exp(i j \\theta)$ into the scheme. The term $u^{n+1}_{j}$ is expressed as $u^{n+1}_{j} = G(\\theta) u^{n}_{j} = G(\\theta) \\hat{u}^{n}\\,\\exp(i j \\theta)$, where $G(\\theta)$ is the amplification factor. The spatial neighbors are given by:\n$$\nu^{n}_{j+1} = \\hat{u}^{n}\\,\\exp(i (j+1) \\theta) = u^{n}_{j}\\,\\exp(i\\theta)\n$$\n$$\nu^{n}_{j-1} = \\hat{u}^{n}\\,\\exp(i (j-1) \\theta) = u^{n}_{j}\\,\\exp(-i\\theta)\n$$\nSubstituting these forms into the numerical scheme, we obtain:\n$$\nG(\\theta) u^{n}_{j} = \\left(\\frac{1}{2} + \\varepsilon\\right)\\left(u^{n}_{j}\\,\\exp(i\\theta) + u^{n}_{j}\\,\\exp(-i\\theta)\\right) - \\frac{\\nu}{2}\\left(u^{n}_{j}\\,\\exp(i\\theta) - u^{n}_{j}\\,\\exp(-i\\theta)\\right)\n$$\nWe cancel the common non-zero term $u^{n}_{j}$ from both sides. Using the Euler identities $\\exp(i\\theta) + \\exp(-i\\theta) = 2\\cos(\\theta)$ and $\\exp(i\\theta) - \\exp(-i\\theta) = 2i\\sin(\\theta)$, we simplify the expression for $G(\\theta)$:\n$$\nG(\\theta) = \\left(\\frac{1}{2} + \\varepsilon\\right)(2\\cos(\\theta)) - \\frac{\\nu}{2}(2i\\sin(\\theta))\n$$\n$$\nG(\\theta) = (1 + 2\\varepsilon)\\cos(\\theta) - i\\nu\\sin(\\theta)\n$$\nThis is the amplification factor for the given scheme. It is a complex-valued function of the mode angle $\\theta$ and the Courant number $\\nu$.\n\nThe condition for linear stability is $|G(\\theta)| \\le 1$ for all $\\theta \\in [-\\pi, \\pi]$. The problem asks to compute $\\inf_{\\nu \\in \\mathbb{R}} \\sup_{\\theta \\in \\mathbb{R}} |G(\\theta)|$. We first find the supremum of $|G(\\theta)|$ with respect to $\\theta$ for a fixed $\\nu$. To simplify the analysis, we work with the squared magnitude, $|G(\\theta)|^2$:\n$$\n|G(\\theta)|^2 = \\left( (1 + 2\\varepsilon)\\cos(\\theta) \\right)^2 + \\left( -\\nu\\sin(\\theta) \\right)^2\n$$\n$$\n|G(\\theta)|^2 = (1 + 2\\varepsilon)^2\\cos^2(\\theta) + \\nu^2\\sin^2(\\theta)\n$$\nUsing the identity $\\sin^2(\\theta) = 1 - \\cos^2(\\theta)$, we express $|G(\\theta)|^2$ as a function of $\\cos^2(\\theta)$:\n$$\n|G(\\theta)|^2 = (1 + 2\\varepsilon)^2\\cos^2(\\theta) + \\nu^2(1 - \\cos^2(\\theta))\n$$\n$$\n|G(\\theta)|^2 = \\nu^2 + \\left[ (1 + 2\\varepsilon)^2 - \\nu^2 \\right]\\cos^2(\\theta)\n$$\nLet the variable $C = \\cos^2(\\theta)$. As $\\theta$ spans $\\mathbb{R}$, $C$ spans the interval $[0, 1]$. We wish to find the maximum of the function $f(C) = \\nu^2 + \\left[ (1 + 2\\varepsilon)^2 - \\nu^2 \\right]C$ for $C \\in [0, 1]$.\nThe function $f(C)$ is linear in $C$. Its maximum over the interval $[0, 1]$ will occur at one of the endpoints, $C=0$ or $C=1$, depending on the sign of the coefficient of $C$.\n\nCase 1: The coefficient $(1 + 2\\varepsilon)^2 - \\nu^2 \\ge 0$.\nThis is equivalent to $\\nu^2 \\le (1 + 2\\varepsilon)^2$, or $|\\nu| \\le 1 + 2\\varepsilon$. In this case, the maximum of $f(C)$ occurs at $C=1$ (corresponding to $\\theta = k\\pi$ for $k \\in \\mathbb{Z}$).\n$$\n\\sup_{\\theta} |G(\\theta)|^2 = \\nu^2 + \\left[ (1 + 2\\varepsilon)^2 - \\nu^2 \\right](1) = (1 + 2\\varepsilon)^2\n$$\n\nCase 2: The coefficient $(1 + 2\\varepsilon)^2 - \\nu^2  0$.\nThis is equivalent to $\\nu^2  (1 + 2\\varepsilon)^2$, or $|\\nu|  1 + 2\\varepsilon$. In this case, the maximum of $f(C)$ occurs at $C=0$ (corresponding to $\\theta = \\frac{\\pi}{2} + k\\pi$ for $k \\in \\mathbb{Z}$).\n$$\n\\sup_{\\theta} |G(\\theta)|^2 = \\nu^2 + \\left[ (1 + 2\\varepsilon)^2 - \\nu^2 \\right](0) = \\nu^2\n$$\n\nCombining these two cases, we can write the supremum of the squared magnitude as:\n$$\n\\sup_{\\theta \\in \\mathbb{R}} |G(\\theta)|^2 = \\max\\left( (1 + 2\\varepsilon)^2, \\nu^2 \\right)\n$$\nTaking the square root, we find the supremum of the magnitude:\n$$\n\\sup_{\\theta \\in \\mathbb{R}} |G(\\theta)| = \\sqrt{\\max\\left( (1 + 2\\varepsilon)^2, \\nu^2 \\right)} = \\max\\left( \\sqrt{(1 + 2\\varepsilon)^2}, \\sqrt{\\nu^2} \\right)\n$$\nSince $\\varepsilon  0$, $1 + 2\\varepsilon$ is positive. Therefore, $\\sqrt{(1 + 2\\varepsilon)^2} = 1 + 2\\varepsilon$.\n$$\n\\sup_{\\theta \\in \\mathbb{R}} |G(\\theta)| = \\max(1 + 2\\varepsilon, |\\nu|)\n$$\nFinally, we must compute the infimum of this quantity over all possible real values of $\\nu$. Let $M(\\nu) = \\max(1 + 2\\varepsilon, |\\nu|)$. We seek $\\inf_{\\nu \\in \\mathbb{R}} M(\\nu)$.\n\nThe function $M(\\nu)$ is defined as:\n$$\nM(\\nu) =\n\\begin{cases}\n1 + 2\\varepsilon  \\text{if } |\\nu| \\le 1 + 2\\varepsilon \\\\\n|\\nu|  \\text{if } |\\nu|  1 + 2\\varepsilon\n\\end{cases}\n$$\nFrom this definition, it is clear that for any $\\nu \\in \\mathbb{R}$, the value of $M(\\nu)$ is always greater than or equal to $1 + 2\\varepsilon$. The minimum value of $M(\\nu)$ is $1 + 2\\varepsilon$, and this minimum is achieved for any $\\nu$ in the closed interval $[-(1 + 2\\varepsilon), 1 + 2\\varepsilon]$.\nTherefore, the infimum is:\n$$\n\\inf_{\\nu \\in \\mathbb{R}} \\sup_{\\theta \\in \\mathbb{R}} |G(\\theta)| = 1 + 2\\varepsilon\n$$\nThe positive bias $\\varepsilon$ introduces an unconditional instability, as the minimal value of the maximum amplification factor is $1 + 2\\varepsilon$, which is strictly greater than $1$.",
            "answer": "$$\n\\boxed{1 + 2\\varepsilon}\n$$"
        },
        {
            "introduction": "Stability ensures that a numerical solution does not blow up, but it does not guarantee accuracy. This computational exercise  delves into this crucial distinction by examining a scheme that is perfectly non-dissipative ($|G|=1$) yet still produces significant errors. You will see firsthand how numerical dispersion—an error in the wave's phase rather than its amplitude—can cause a simulated wave packet to unphysically spread out, proving that stability is a necessary, but not sufficient, condition for a faithful simulation.",
            "id": "2407939",
            "problem": "Consider the one-dimensional linear advection initial value problem with periodic boundary conditions on a domain of length $L$,\n$$\nu_t(x,t) + a\\,u_x(x,t) = 0,\\quad x\\in[0,L),\\ t\\ge 0,\n$$\nwith wave speed $a0$ and a smooth initial condition. Discretize the partial differential equation on a uniform grid with $N$ points using spatial step $\\Delta x = L/N$ and temporal step $\\Delta t$, and evolve in time using the explicit two-step centered (leapfrog) scheme\n$$\n\\frac{u_j^{n+1} - u_j^{n-1}}{2\\,\\Delta t} + a\\,\\frac{u_{j+1}^n - u_{j-1}^n}{2\\,\\Delta x} = 0,\n$$\nor equivalently,\n$$\nu_j^{n+1} = u_j^{n-1} - \\nu\\left(u_{j+1}^{n} - u_{j-1}^{n}\\right),\n$$\nwhere $u_j^n$ approximates $u(x_j,t^n)$ with $x_j = j\\,\\Delta x$, $t^n = n\\,\\Delta t$, and $\\nu \\equiv a\\,\\Delta t/\\Delta x$ is the Courant number. For each Fourier mode with wavenumber $k$, this scheme has an amplification factor $G(k)$ that satisfies $\\lvert G(k)\\rvert = 1$.\n\nLet the initial condition be a Gaussian-modulated monochromatic wave packet centered at position $x_0$ with spatial width parameter $\\sigma$ and central wavenumber $k_0$,\n$$\nu(x,0) = \\exp\\!\\left(-\\frac{(x-x_0)^2}{2\\,\\sigma^2}\\right)\\cos\\!\\big(k_0\\,(x-x_0)\\big),\n$$\ninterpreted on the periodic domain $[0,L)$. Define the envelope $E(x,t)$ of $u(x,t)$ to be the modulus of its analytic signal,\n$$\nE(x,t) = \\left|u(x,t) + i\\,\\mathcal{H}[u(\\cdot,t)](x)\\right|,\n$$\nwhere $\\mathcal{H}$ denotes the Hilbert transform on the periodic domain. Define the root-mean-square envelope width $\\Sigma(t)$ by\n$$\n\\Sigma(t) = \\sqrt{\\frac{\\int_0^L (x-\\mu(t))^2\\,E(x,t)^2\\,\\mathrm{d}x}{\\int_0^L E(x,t)^2\\,\\mathrm{d}x}},\\quad \\mu(t) = \\frac{\\int_0^L x\\,E(x,t)^2\\,\\mathrm{d}x}{\\int_0^L E(x,t)^2\\,\\mathrm{d}x}.\n$$\n\nUsing the above scheme and definitions, compute, for each test case below, the ratio\n$$\nR = \\frac{\\Sigma(T)}{\\Sigma(0)},\n$$\nwhere $T$ is the final simulation time. The ratio $R$ is dimensionless and must be output as a floating-point number. All quantities in this problem are non-dimensional.\n\nYou must use periodic boundary conditions. Initialize $u(x,\\Delta t)$ consistently with the given initial condition and the partial differential equation so that the discrete evolution is well-defined for the two-step method. For each test case, use the exact same spatial grid and domain but vary the Courant number and the central wavenumber as specified.\n\nTest suite:\n- Common parameters for all tests: $L = 1$, $N = 1024$, $a = 1$, $\\sigma = 0.05$, $x_0 = 0.30$, $T = 0.25$.\n- The central wavenumber is set by an integer mode count $m_0$ with $k_0 = 2\\pi m_0/L$.\n- The four parameter sets are:\n  1. $(\\nu, m_0) = (0.8, 8)$,\n  2. $(\\nu, m_0) = (0.5, 8)$,\n  3. $(\\nu, m_0) = (0.8, 64)$,\n  4. $(\\nu, m_0) = (0.5, 64)$.\n\nFinal output format:\nYour program should produce a single line of output containing the four ratios $R$ corresponding to tests $1$ through $4$, as a comma-separated list enclosed in square brackets, for example, \"[r1,r2,r3,r4]\". Each $r_i$ must be a floating-point number. No other text should be printed.\n\nThe goal is to demonstrate, in accordance with the Lax equivalence principle, that even when the magnitude of the amplification factor satisfies $\\lvert G\\rvert = 1$ (neutral stability with no numerical dissipation), phase error (numerical dispersion) can still cause the simulated wave packet to spread over time, i.e., $R  1$ in general.",
            "solution": "The problem presented is valid. It is a well-posed problem in computational engineering, grounded in the established principles of numerical analysis for partial differential equations. All parameters and definitions are provided, and the task is to computationally demonstrate a known phenomenon—numerical dispersion—in a stable, non-dissipative finite difference scheme.\n\nThe problem investigates the one-dimensional linear advection equation:\n$$\n\\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x} = 0\n$$\nThis equation describes the transport of a quantity $u(x,t)$ with a constant velocity $a$. The exact solution for an initial condition $u(x,0) = f(x)$ is a simple translation: $u(x,t) = f(x-at)$. This means the initial waveform should propagate without changing its shape.\n\nWe are to use the explicit two-step centered-in-time, centered-in-space (leapfrog) finite difference scheme:\n$$\nu_j^{n+1} = u_j^{n-1} - \\nu \\left(u_{j+1}^{n} - u_{j-1}^{n}\\right)\n$$\nwhere $\\nu = a \\Delta t / \\Delta x$ is the Courant-Friedrichs-Lewy (CFL) number. To analyze this scheme, we perform a von Neumann stability analysis by substituting a single Fourier mode, $u_j^n = G^n e^{i k x_j} = G^n e^{i k j \\Delta x}$, where $G$ is the amplification factor. This substitution yields the characteristic equation for $G$:\n$$\nG^2 + \\left(2i\\nu \\sin(k\\Delta x)\\right)G - 1 = 0\n$$\nThe solutions for $G$ are $G = -i\\nu\\sin(k\\Delta x) \\pm \\sqrt{1 - \\nu^2 \\sin^2(k\\Delta x)}$. For the scheme to be stable, the term under the square root must be non-negative for all wavenumbers $k$. This leads to the stability condition $|\\nu \\sin(k\\Delta x)| \\le 1$, which simplifies to the CFL condition $|\\nu| \\le 1$. The test cases use $\\nu=0.8$ and $\\nu=0.5$, which satisfy this condition. When stable, the magnitude of the amplification factor is:\n$$\n|G|^2 = \\left(\\nu\\sin(k\\Delta x)\\right)^2 + \\left(1 - \\nu^2\\sin^2(k\\Delta x)\\right) = 1\n$$\nThus, $|G|=1$. This signifies that the scheme is non-dissipative; the amplitude of any Fourier mode is perfectly preserved over time, which mirrors the behavior of the original PDE.\n\nHowever, the phase of the numerical solution is not perfect. The amplification factor can be written as $G = e^{-i\\omega_{\\text{num}}\\Delta t}$, where $\\omega_{\\text{num}}$ is the numerical angular frequency. From the solution for $G$, we find:\n$$\n\\omega_{\\text{num}}(k) = \\frac{1}{\\Delta t}\\arcsin(\\nu\\sin(k\\Delta x))\n$$\nThe exact dispersion relation is $\\omega(k) = ak$. The discrepancy between $\\omega_{\\text{num}}$ and $\\omega$ leads to phase error. The propagation of a wave packet is dictated by the group velocity, $v_g = d\\omega/dk$. For the numerical scheme, this is:\n$$\nv_{g, \\text{num}}(k) = \\frac{d\\omega_{\\text{num}}}{dk} = a \\frac{\\cos(k\\Delta x)}{\\sqrt{1 - \\nu^2\\sin^2(k\\Delta x)}}\n$$\nThe exact group velocity is $v_{g, \\text{exact}} = a$. The numerical group velocity depends on the wavenumber $k$. A wave packet is a superposition of modes in a range around a central wavenumber $k_0$. Since different constituent modes travel at different speeds, the wave packet spreads out or disperses over time. This phenomenon is termed numerical dispersion. The degree of dispersion depends on how much $v_{g, \\text{num}}(k)$ varies with $k$, and how much it deviates from $a$. This effect is more pronounced for larger values of $k\\Delta x$ (poorly resolved waves) and for Courant numbers $\\nu$ further away from the special case of $\\nu=1$ (where $v_{g, \\text{num}}=a$ and the scheme is exact, apart from machine precision).\n\nThe computational procedure is as follows:\n$1$. **Grid and Parameters**: The spatial domain $[0, L)$ is discretized into $N$ points, giving a grid spacing $\\Delta x = L/N$. The time step $\\Delta t$ is determined from the specified Courant number $\\nu$ as $\\Delta t = \\nu \\Delta x / a$. The total number of time steps is $N_T = T/\\Delta t$.\n\n$2$. **Initialization**: The leapfrog scheme is a two-level scheme requiring data at time levels $n$ and $n-1$ to compute level $n+1$.\n- The solution at $t^0=0$, $u_j^0$, is given by the initial condition:\n  $$ u_j^0 = \\exp\\!\\left(-\\frac{(x_j-x_0)^2}{2\\,\\sigma^2}\\right)\\cos\\!\\big(k_0\\,(x_j-x_0)\\big) $$\n- The solution at $t^1=\\Delta t$, $u_j^1$, is initialized consistently with the PDE's exact solution, which is pure advection. Thus, we set $u_j^1 = u(x_j, \\Delta t) = u(x_j - a\\Delta t, 0)$.\n\n$3$. **Time Evolution**: The solution is advanced in time using the leapfrog update rule for $n=1, \\dots, N_T-1$. Periodic boundary conditions are enforced by treating the grid indices modulo $N$, i.e., $u_{N}^n = u_0^n$ and $u_{-1}^n = u_{N-1}^n$.\n\n$4$. **Envelope and Width Calculation**: The spreading of the wave packet is quantified by the root-mean-square (RMS) width $\\Sigma(t)$ of its envelope.\n- The envelope $E(x,t)$ is the modulus of the analytic signal, $E(x,t) = |u(x,t) + i\\mathcal{H}[u](x,t)|$, where $\\mathcal{H}$ is the Hilbert transform. Computationally, this is efficiently found using the Fast Fourier Transform (FFT).\n- The RMS width $\\Sigma(t)$ is the standard deviation of the spatial coordinate $x$, weighted by the squared envelope $E(x,t)^2$. The required integrals are replaced by discrete sums over the grid points:\n  $$ \\mu(t) \\approx \\frac{\\sum_j x_j E_j^2}{\\sum_j E_j^2}, \\quad \\Sigma(t)^2 \\approx \\frac{\\sum_j (x_j - \\mu(t))^2 E_j^2}{\\sum_j E_j^2} $$\n- This calculation is performed for the initial state $u(x,0)$ to find $\\Sigma(0)$ and for the final state $u(x,T)$ to find $\\Sigma(T)$.\n\n$5$. **Result**: The final result for each test case is the ratio $R = \\Sigma(T)/\\Sigma(0)$, which quantifies the net spreading of the wave packet envelope over the simulation time. A value $R1$ demonstrates the effect of numerical dispersion.",
            "answer": "```python\nimport numpy as np\nfrom scipy.signal import hilbert\n\ndef solve():\n    \"\"\"\n    Solves the 1D linear advection equation using the leapfrog scheme\n    and computes the spreading of a wave packet due to numerical dispersion.\n    \"\"\"\n\n    test_cases = [\n        # (nu, m0)\n        (0.8, 8),\n        (0.5, 8),\n        (0.8, 64),\n        (0.5, 64),\n    ]\n\n    results = []\n\n    # Common parameters for all test cases\n    L = 1.0\n    N = 1024\n    a = 1.0\n    sigma = 0.05\n    x0 = 0.30\n    T = 0.25\n\n    # Spatial grid\n    x_grid = np.linspace(0.0, L, N, endpoint=False)\n    dx = L / N\n\n    def calculate_sigma(u, x):\n        \"\"\"\n        Calculates the RMS envelope width Sigma for a given wave profile u.\n        \"\"\"\n        # The envelope E is the modulus of the analytic signal.\n        # The analytic signal is computed using the Hilbert transform.\n        analytic_signal = hilbert(u)\n        E = np.abs(analytic_signal)\n        E2 = E**2\n        sum_E2 = np.sum(E2)\n\n        if sum_E2  1e-16:\n            return 0.0\n\n        # Calculate the centroid (mean position) mu.\n        # The wave packet does not cross the periodic boundary in this problem,\n        # so a simple weighted average is sufficient for the centroid.\n        mu = np.sum(x * E2) / sum_E2\n\n        # Calculate the variance and then the RMS width (standard deviation).\n        variance = np.sum(((x - mu)**2) * E2) / sum_E2\n        return np.sqrt(variance)\n\n    for nu, m0 in test_cases:\n        # Set parameters for the specific test case\n        k0 = 2.0 * np.pi * m0 / L\n        dt = nu * dx / a\n        # The number of steps is an integer for all test cases.\n        n_steps = int(round(T / dt))\n\n        # Define the initial condition as a function\n        def u_initial_func(x_arg):\n            return np.exp(-((x_arg - x0)**2) / (2.0 * sigma**2)) * np.cos(k0 * (x_arg - x0))\n\n        # Initialize u at t=0\n        u_t0 = u_initial_func(x_grid)\n        \n        # Calculate the initial RMS width\n        sigma_0 = calculate_sigma(u_t0, x_grid)\n\n        # Initialize u at t=dt for the two-step scheme.\n        # This is based on the exact solution u(x,t) = f(x-at).\n        u_t1 = u_initial_func(x_grid - a * dt)\n\n        # Set up the states for the leapfrog iteration\n        u_nm1 = u_t0  # Represents u^{n-1}\n        u_n = u_t1    # Represents u^{n}\n        \n        # Perform time-stepping loop. Loop runs n_steps-1 times to evolve\n        # from t=dt to t=n_steps*dt = T.\n        for _ in range(n_steps - 1):\n            # Apply periodic boundary conditions using np.roll\n            u_n_jplus1 = np.roll(u_n, -1)\n            u_n_jminus1 = np.roll(u_n, 1)\n\n            # Leapfrog scheme update\n            u_np1 = u_nm1 - nu * (u_n_jplus1 - u_n_jminus1)\n\n            # Advance the states for the next iteration\n            u_nm1, u_n = u_n, u_np1\n        \n        # The final state is in u_n\n        u_T = u_n\n\n        # Calculate the final RMS width\n        sigma_T = calculate_sigma(u_T, x_grid)\n\n        # Calculate the ratio R and store it\n        ratio_R = sigma_T / sigma_0 if sigma_0 != 0 else 0.0\n        results.append(ratio_R)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The Lax Equivalence Principle provides a profound link between a scheme's local properties (consistency, stability) and its global behavior (convergence). This capstone exercise  challenges you to apply this principle in a practical scenario: verifying an unknown, \"black-box\" solver. By designing a numerical experiment with a manufactured solution, you will test for convergence and, by reasoning from the Lax principle, deduce whether the hidden scheme is truly consistent with the target partial differential equation.",
            "id": "2407986",
            "problem": "You are given oracle access to a single-step integrator for a one-dimensional Periodic Partial Differential Equation (PDE) initial value problem on the spatial interval $[0,1]$ with periodic boundary conditions. You cannot see or modify the internal numerical scheme used by the integrator; you may only invoke it as a black box with a chosen spatial grid and time step. Your task is to design, implement, and execute a numerical experiment to determine, from first principles, whether the underlying discrete scheme is consistent with the linear advection PDE\n$$\nu_t + a\\,u_x = 0,\n$$\nwhere $a$ is a given positive constant, on $x\\in[0,1]$ with periodic boundary conditions.\n\nThe fundamental definitions that you may assume without proof are:\n- Consistency: the local truncation error of a discrete scheme for a PDE tends to zero as the mesh spacings tend to zero.\n- Stability: the solution produced by the discrete scheme remains uniformly bounded in an appropriate norm when applied to a homogeneous linear problem with bounded data, for all sufficiently fine discretizations.\n- Lax Equivalence Principle (Lax): for a linear, well-posed initial value problem, a consistent scheme is convergent if and only if it is stable; conversely, convergence implies consistency.\n\nYour numerical experiment must be based only on these fundamental definitions and facts. In particular, do not assume any particular discrete stencil or order of accuracy of the unknown scheme. You must reason from the base definitions to decide how to test consistency.\n\nDesign requirements for your numerical experiment:\n- Use the method of manufactured solutions: choose a smooth, periodic, exact solution of the target PDE and use it to construct initial and boundary data. A convenient choice is\n$$\nu(x,t) = \\sin\\!\\big(2\\pi(x - a t)\\big),\n$$\nwhich exactly solves $u_t + a\\,u_x = 0$ on $[0,1]$ with periodic boundary conditions for any constant $a0$.\n- Spatial domain and grids: use uniform periodic grids with $N_x$ points over $[0,1)$, so that $\\Delta x = 1/N_x$. Consider the refinement sequence $N_x \\in \\{50, 100, 200, 400\\}$.\n- Time step selection: for each $N_x$, choose $\\Delta t = \\text{CFL}\\cdot \\Delta x/a$ with a fixed Courant–Friedrichs–Lewy (CFL) number $\\text{CFL} = 0.45$ to ensure a proportional refinement of temporal and spatial scales.\n- Final time: use $T = 1.0$. For the chosen manufactured solution and $a=1$, $u(\\cdot,T)$ equals $u(\\cdot,0)$ due to periodicity, which simplifies error assessment.\n- Error metric: for each grid, compute the discrete root-mean-square (RMS) error at time $T$,\n$$\nE(N_x) = \\Bigg(\\frac{1}{N_x}\\sum_{j=0}^{N_x-1}\\big(u_j^{\\text{num}}(T) - u(x_j,T)\\big)^2\\Bigg)^{1/2},\n$$\nwhere $x_j=j\\Delta x$ and $u_j^{\\text{num}}(T)$ is the black-box solution at time $T$.\n- Boundedness monitor: for each run, compute the amplification ratio\n$$\nG = \\frac{\\max_j |u_j^{\\text{num}}(T)|}{\\max_j |u_j^{\\text{num}}(0)|}.\n$$\nIf at any refinement level the run produces a non-finite number or $G  10^3$, declare the scheme unstable for the tested configuration and treat the consistency verdict as inconclusive for that case.\n\nDecision rule grounded in the Lax Equivalence Principle:\n- If instability is detected on any refinement level (non-finite values or $G10^3$), output the integer $-1$ for that case (unstable; cannot conclude consistency).\n- Otherwise, if the error sequence $E(N_x)$ is strictly decreasing with refinement and the finest-grid error satisfies $E(400)  0.05$, declare the scheme convergent, hence consistent by Lax; output the integer $1$ for that case.\n- Otherwise, if the sequence does not decrease or the finest-grid error does not fall below the stated tolerance, declare the scheme inconsistent with the target PDE; output the integer $0$ for that case.\n\nTest suite and parameters:\n- Apply your experiment to three opaque solver instances, each purporting to solve the target problem, identified as $\\text{BB1}$, $\\text{BB2}$, and $\\text{BB3}$. Treat them as black boxes whose internals you cannot inspect. Use the parameters $a=1.0$, $\\text{CFL}=0.45$, and $T=1.0$ for all three.\n- Your program must execute the experiment for the three identifiers in the order $[\\text{BB1},\\text{BB2},\\text{BB3}]$ and produce a verdict per identifier using the decision rule above.\n\nFinal output format:\n- Your program should produce a single line of output containing the three integer results in a comma-separated list enclosed in square brackets, in the order $[\\text{BB1},\\text{BB2},\\text{BB3}]$. For example, a valid output could be $[1,0,-1]$.",
            "solution": "We begin from the foundational definitions of consistency, stability, and the Lax Equivalence Principle (Lax). For a linear, well-posed initial value problem such as the constant-coefficient advection equation $u_t + a u_x = 0$ with periodic boundary conditions, the Lax Equivalence Principle states that consistency together with stability is equivalent to convergence, and conversely convergence implies consistency. Therefore, if we can empirically observe convergence while also ruling out instability along a refinement path, then we can conclude consistency of the underlying scheme with respect to the given PDE.\n\nTo operationalize this with only black-box access to a solver, we use the method of manufactured solutions. Choose an exact smooth solution of the target PDE; we pick $u(x,t) = \\sin(2\\pi(x - a t))$, which satisfies $u_t + a u_x = 0$ on $[0,1]$ with periodic boundary conditions for any constant $a0$. For $a=1$ and $T=1$, periodicity gives $u(x,1)=u(x,0)$, which facilitates error assessment because any discrepancy at time $T$ stems solely from discretization effects and not from changes in the exact solution’s amplitude or phase on the periodic domain.\n\nWe define a refinement path by uniform grids with $N_x \\in \\{50,100,200,400\\}$ so that $\\Delta x = 1/N_x$. To balance spatial and temporal refinement, we choose a fixed Courant–Friedrichs–Lewy number $\\text{CFL}=0.45$ and set $\\Delta t = \\text{CFL}\\cdot \\Delta x/a$. This ensures that both $\\Delta x \\to 0$ and $\\Delta t \\to 0$ proportionally, which is compatible with stability constraints of typical explicit advection schemes and keeps the test general.\n\nFor each refinement level, we supply the manufactured initial condition $u(x,0)=\\sin(2\\pi x)$ to the black-box solver and integrate to final time $T=1$. We then compute the discrete root-mean-square error\n$$\nE(N_x) = \\left(\\frac{1}{N_x}\\sum_{j=0}^{N_x-1}\\big(u_j^{\\text{num}}(T) - \\sin(2\\pi(x_j - a T))\\big)^2\\right)^{1/2}.\n$$\nTo guard against instability (which would invalidate a conclusion about consistency from convergence failure), we also monitor the amplification ratio\n$$\nG = \\frac{\\max_j |u_j^{\\text{num}}(T)|}{\\max_j |u_j^{\\text{num}}(0)|}.\n$$\nIf non-finite values appear or $G10^3$ on any refinement, we classify the run as unstable and report $-1$ because Lax indicates that, without stability, non-convergence does not imply inconsistency.\n\nIf all runs remain bounded, we assess convergence by the behavior of $E(N_x)$ across refinements. A consistent and stable scheme should yield $E(N_x)\\to 0$ as $N_x\\to\\infty$. We adopt two quantitative checks that are robust and do not assume a particular order:\n- The error must strictly decrease with each refinement, i.e., $E(400)  E(200)  E(100)  E(50)$.\n- The finest-grid error must be small relative to the signal magnitude; we require $E(400)  0.05$.\n\nIf both are satisfied, we declare convergence and, by Lax, consistency, and report $1$. Otherwise, the scheme is bounded but does not converge to the target PDE solution; we declare it inconsistent and report $0$.\n\nFor the provided test suite, there are three opaque solver instances: $\\text{BB1}$, $\\text{BB2}$, and $\\text{BB3}$, all tested with $a=1.0$, $\\text{CFL}=0.45$, $T=1.0$. Applying the procedure:\n- For $\\text{BB1}$, the error decreases under refinement and the finest-grid error is below the threshold, indicating convergence; hence, by Lax, the scheme is consistent with the advection PDE, and the verdict is $1$.\n- For $\\text{BB2}$, the runs remain bounded but the error does not decrease to near-zero as the mesh is refined (it asymptotes to a nonzero modeling error due to solving a different dynamics), so the verdict is $0$ (inconsistent).\n- For $\\text{BB3}$, the amplification ratio exceeds the stability threshold on at least one refinement, indicating instability; we cannot conclude consistency, so the verdict is $-1$.\n\nThe program implements the experiment, computes the errors and amplification ratios, applies the decision rule, and prints the results as a single line in the format $[r_1,r_2,r_3]$ for $[\\text{BB1},\\text{BB2},\\text{BB3}]$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef manufactured_solution(x, t, a):\n    # u(x,t) = sin(2*pi*(x - a t))\n    return np.sin(2.0 * np.pi * (x - a * t))\n\ndef bb1_upwind_advection(u0, a, dx, dt, T):\n    \"\"\"\n    Black-box BB1: Upwind scheme for linear advection (a0), periodic domain.\n    Stable for CFL = 1, first-order accurate, consistent with advection PDE.\n    \"\"\"\n    u = u0.copy()\n    steps = max(1, int(np.ceil(T / dt)))\n    dt_eff = T / steps\n    cfl = a * dt_eff / dx\n    max_amp = np.max(np.abs(u))\n    for _ in range(steps):\n        u = u - cfl * (u - np.roll(u, 1))\n        # Monitor growth\n        max_amp = max(max_amp, np.max(np.abs(u)))\n        if not np.isfinite(max_amp) or max_amp  1e8:  # early exit on blow-up\n            break\n    return u, max_amp\n\ndef bb2_implicit_heat(u0, nu, dx, dt, T):\n    \"\"\"\n    Black-box BB2: Backward Euler (implicit) for heat equation u_t = nu u_xx, periodic.\n    Unconditionally stable, but inconsistent with advection PDE if tested against it.\n    Uses spectral diagonalization of the discrete Laplacian.\n    \"\"\"\n    u = u0.copy()\n    N = u.size\n    steps = max(1, int(np.ceil(T / dt)))\n    dt_eff = T / steps\n    mu = nu * dt_eff / (dx * dx)\n\n    # Precompute spectral denominator for backward Euler: 1 + 4*mu*sin^2(pi k / N)\n    k = np.arange(0, N//2 + 1, dtype=float)  # rfft frequencies\n    s2 = np.sin(np.pi * k / N) ** 2\n    denom = 1.0 + 4.0 * mu * s2\n\n    max_amp = np.max(np.abs(u))\n    for _ in range(steps):\n        U = np.fft.rfft(u)\n        U_next = U / denom\n        u = np.fft.irfft(U_next, n=N)\n        max_amp = max(max_amp, np.max(np.abs(u)))\n        if not np.isfinite(max_amp) or max_amp  1e8:\n            break\n    return u, max_amp\n\ndef bb3_ftcs_advection(u0, a, dx, dt, T):\n    \"\"\"\n    Black-box BB3: FTCS (Forward-Time Centered-Space) for advection, periodic.\n    This is known to be unstable for linear advection; intended to trigger instability.\n    \"\"\"\n    u = u0.copy()\n    steps = max(1, int(np.ceil(T / dt)))\n    dt_eff = T / steps\n    cfl = a * dt_eff / dx\n    max_amp = np.max(np.abs(u))\n    for _ in range(steps):\n        u = u - 0.5 * cfl * (np.roll(u, -1) - np.roll(u, 1))\n        max_amp = max(max_amp, np.max(np.abs(u)))\n        if np.any(~np.isfinite(u)) or max_amp  1e8:\n            break\n    return u, max_amp\n\ndef run_black_box(identifier, Nx, a, cfl, T, nu_heat=0.01):\n    \"\"\"\n    Emulated black-box dispatcher. Interface is opaque to the experiment logic.\n    \"\"\"\n    dx = 1.0 / Nx\n    dt = cfl * dx / abs(a) if a != 0 else cfl * dx\n    x = np.linspace(0.0, 1.0, Nx, endpoint=False)\n    u0 = manufactured_solution(x, 0.0, a)\n\n    if identifier == \"BB1\":\n        un, max_amp = bb1_upwind_advection(u0, a, dx, dt, T)\n    elif identifier == \"BB2\":\n        un, max_amp = bb2_implicit_heat(u0, nu_heat, dx, dt, T)\n    elif identifier == \"BB3\":\n        un, max_amp = bb3_ftcs_advection(u0, a, dx, dt, T)\n    else:\n        raise ValueError(\"Unknown black-box identifier.\")\n\n    return x, u0, un, max_amp, dt\n\ndef classify_consistency(identifier, a=1.0, cfl=0.45, T=1.0):\n    \"\"\"\n    Execute the Lax-principle-based numerical experiment to determine\n    if the black-box scheme is consistent with the advection PDE.\n    Returns:\n    -1: unstable (cannot conclude),\n     1: consistent (convergent and bounded),\n     0: inconsistent (bounded but non-convergent).\n    \"\"\"\n    Nx_list = [50, 100, 200, 400]\n    errors = []\n    unstable = False\n    for Nx in Nx_list:\n        x, u0, un, max_amp, dt_used = run_black_box(identifier, Nx, a, cfl, T)\n        # Exact at final time\n        u_exact_T = manufactured_solution(x, T, a)\n        # Compute RMS error\n        err = np.sqrt(np.mean((un - u_exact_T) ** 2))\n        errors.append(err)\n        # Boundedness monitor\n        init_amp = np.max(np.abs(u0))\n        if init_amp == 0:\n            growth = np.inf if np.max(np.abs(un))  0 else 1.0\n        else:\n            growth = (np.max(np.abs(un)) / init_amp)\n        if not np.isfinite(growth) or growth  1e3 or not np.all(np.isfinite(un)):\n            unstable = True\n            break\n\n    if unstable:\n        return -1\n\n    # Check monotonic decrease and small finest error\n    monotone = all(errors[i+1]  errors[i] for i in range(len(errors)-1))\n    finest_small = errors[-1]  5e-2  # threshold per problem design\n    if monotone and finest_small:\n        return 1\n    else:\n        return 0\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Three opaque solvers: BB1, BB2, BB3; parameters a=1.0, CFL=0.45, T=1.0\n    test_cases = [\n        (\"BB1\", 1.0, 0.45, 1.0),\n        (\"BB2\", 1.0, 0.45, 1.0),\n        (\"BB3\", 1.0, 0.45, 1.0),\n    ]\n\n    results = []\n    for ident, a, cfl, T in test_cases:\n        verdict = classify_consistency(ident, a=a, cfl=cfl, T=T)\n        results.append(verdict)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}