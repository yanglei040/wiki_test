{
    "hands_on_practices": [
        {
            "introduction": "理解 QR 分解的一个核心应用是计算向量在子空间上的正交投影。如果我们拥有一个子空间的正交规范基（即 $Q$ 矩阵的列），那么投影的计算将变得异常简单和直观。这个练习将通过一个具体的计算，让你亲手实践如何利用 $Q$ 矩阵来直接求得一个向量在给定列空间上的投影，从而加深对 $Q$ 矩阵几何意义的理解 。",
            "id": "1385303",
            "problem": "设矩阵 $A$ 和向量 $\\mathbf{b}$ 定义如下：\n$$A = \\begin{pmatrix} 1  1 \\\\ 0  1 \\\\ 1  0 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}$$\n$A$ 的列向量张成 $\\mathbb{R}^3$ 的一个子空间，我们将其记为 $W = \\text{Col}(A)$。$A$ 的 QR 分解为 $A=QR$，其中 $Q$ 是一个列向量标准正交的矩阵，$R$ 是一个上三角矩阵。矩阵 $Q$ 的列向量构成 $W$ 的一个标准正交基，其形式如下：\n$$Q = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ 0  \\frac{2}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{2}}  -\\frac{1}{\\sqrt{6}} \\end{pmatrix}$$\n求向量 $\\mathbf{p}$，即 $\\mathbf{b}$ 在子空间 $W$ 上的正交投影。请用包含 $\\mathbf{p}$ 三个分量的行矩阵表示你的最终答案，并使用精确分数。",
            "solution": "给定一个矩阵 $Q$，其标准正交的列向量张成 $W=\\text{Col}(A)$。$\\mathbf{b}$ 在 $W$ 上的正交投影 $\\mathbf{p}$ 由以下公式给出\n$$\n\\mathbf{p} = Q Q^{T} \\mathbf{b} = \\sum_{i=1}^{2} (q_{i}^{T}\\mathbf{b})\\, q_{i},\n$$\n其中 $q_{1}$ 和 $q_{2}$ 是 $Q$ 的列向量。\n\n根据给定的 $Q$，\n$$\nq_{1} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}, \\quad\nq_{2} = \\begin{pmatrix} \\frac{1}{\\sqrt{6}} \\\\ \\frac{2}{\\sqrt{6}} \\\\ -\\frac{1}{\\sqrt{6}} \\end{pmatrix}, \\quad\n\\mathbf{b} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}.\n$$\n计算系数：\n$$\nq_{1}^{T}\\mathbf{b} = \\frac{1}{\\sqrt{2}}\\cdot 1 + 0\\cdot 2 + \\frac{1}{\\sqrt{2}}\\cdot 1 = \\frac{2}{\\sqrt{2}} = \\sqrt{2},\n$$\n$$\nq_{2}^{T}\\mathbf{b} = \\frac{1}{\\sqrt{6}}\\cdot 1 + \\frac{2}{\\sqrt{6}}\\cdot 2 - \\frac{1}{\\sqrt{6}}\\cdot 1 = \\frac{1+4-1}{\\sqrt{6}} = \\frac{4}{\\sqrt{6}}.\n$$\n因此，\n$$\n\\mathbf{p} = (q_{1}^{T}\\mathbf{b})\\,q_{1} + (q_{2}^{T}\\mathbf{b})\\,q_{2}\n= \\sqrt{2}\\,q_{1} + \\frac{4}{\\sqrt{6}}\\,q_{2}.\n$$\n计算每一项：\n$$\n\\sqrt{2}\\,q_{1} = \\sqrt{2}\\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n= \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix},\n\\quad\n\\frac{4}{\\sqrt{6}}\\,q_{2} = \\frac{4}{\\sqrt{6}}\\begin{pmatrix} \\frac{1}{\\sqrt{6}} \\\\ \\frac{2}{\\sqrt{6}} \\\\ -\\frac{1}{\\sqrt{6}} \\end{pmatrix}\n= \\begin{pmatrix} \\frac{4}{6} \\\\ \\frac{8}{6} \\\\ -\\frac{4}{6} \\end{pmatrix}\n= \\begin{pmatrix} \\frac{2}{3} \\\\ \\frac{4}{3} \\\\ -\\frac{2}{3} \\end{pmatrix}.\n$$\n将它们相加得到\n$$\n\\mathbf{p} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} \\frac{2}{3} \\\\ \\frac{4}{3} \\\\ -\\frac{2}{3} \\end{pmatrix}\n= \\begin{pmatrix} \\frac{5}{3} \\\\ \\frac{4}{3} \\\\ \\frac{1}{3} \\end{pmatrix}.\n$$\n按照要求，这用精确分数表示。根据题目要求写成行矩阵，我们将各分量写在一行中。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{5}{3}  \\frac{4}{3}  \\frac{1}{3} \\end{pmatrix}}$$"
        },
        {
            "introduction": "在计算工程领域，将理论算法转化为稳定高效的代码至关重要。本练习要求你从内积和正交投影等基本定义出发，实现“瘦”QR 分解，这是一种在处理高维数据时极具存储优势的分解形式。通过这个实践，你不仅将掌握 QR 分解的实现细节，包括处理数值秩亏问题，还将学习如何验证投影算子的性质并量化分析其计算效率 。",
            "id": "2430018",
            "problem": "要求您在一个纯数学线性代数的背景下，实现并验证一个用于“瘦”QR分解的计算过程。请从以下基本概念出发：内积的定义、欧几里得范数以及向量正交归一集的概念。具体来说，利用内积可以导出正交投影，以及正交归一向量可以简化投影运算这一事实。除了这些核心定义外，不要假设任何预先推导出的算法公式或恒等式。通过将向量重复投影到已构造的正交归一方向上并减去这些投影，来构建算法步骤。\n\n给定一个实矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其中 $m \\ge n$，其“瘦”QR分解是一种 $A \\approx Q R$ 的分解形式，其中 $Q \\in \\mathbb{R}^{m \\times r}$ 的列是正交归一的，张成与 $A$ 的列相同的子空间（直至数值秩 $r \\le n$），而 $R \\in \\mathbb{R}^{r \\times n}$ 是一个上梯形矩阵（当 $r=n$ 时为上三角矩阵）。“完整”QR分解使用一个方阵正交因子 $Q_{\\mathrm{full}} \\in \\mathbb{R}^{m \\times m}$ 和一个 $R_{\\mathrm{full}} \\in \\mathbb{R}^{m \\times n}$，其中 $R_{\\mathrm{full}}$ 的下面 $(m-n)$ 行为零。\n\n您的任务：\n\n1) 实现一个函数，在给定矩阵 $A$ 的情况下，仅使用内积和正交投影的定义来产生“瘦”QR分解。具体地，通过迭代地从当前列中减去其在先前构造的 $q_i$ 上的投影并进行归一化来构造列 $q_j$，并可选择进行第二轮正交化以提高数值稳定性。使用一个数值容差 $\\tau$ 来检测数值秩 $r$，使得投影后范数低于 $\\tau$ 的列被视为数值相关，并从 $Q$ 中排除。您的函数必须返回 $(Q, R, r)$，其中 $Q \\in \\mathbb{R}^{m \\times r}$ 具有正交归一的列，$R \\in \\mathbb{R}^{r \\times n}$ 是上梯形矩阵，而 $r$ 是检测到的秩。\n\n2) 使用构造的 $Q$，构建到 $A$ 的列空间（由 $Q$ 的列所捕获）上的正交投影算子 $P = Q Q^{\\mathsf{T}} \\in \\mathbb{R}^{m \\times m}$。数值验证投影算子的性质：对称性和幂等性。您的验证指标必须是定量的，并基于范数。\n\n3) 仅使用维度计算和投影性质（而非预先引用的算法成本公式），解释“瘦”QR分解在何时以及为何在存储和应用上比“完整”QR分解更高效。根据因子中存储的标量条目数量来量化存储需求。\n\n为了进行评估，您的程序必须实现上述要求，并为每个测试用例生成一个包含四个浮点数的列表：\n- 相对重构误差 $e_{\\mathrm{rec}} = \\lVert A - Q R \\rVert_{\\mathrm{F}} / \\lVert A \\rVert_{\\mathrm{F}}$。\n- 正交归一性误差 $e_{\\mathrm{orth}} = \\lVert Q^{\\mathsf{T}} Q - I_r \\rVert_{\\mathrm{F}}$，其中 $I_r$ 是 $r \\times r$ 的单位矩阵。\n- 投影算子幂等性误差 $e_{\\mathrm{proj}} = \\lVert P^2 - P \\rVert_{\\mathrm{F}}$，其中 $P = Q Q^{\\mathsf{T}}$。\n- 存储比率 $\\rho = \\dfrac{\\text{瘦分解因子的标量存储数}}{\\text{完整分解因子的标量存储数}}$，其中分子是 $Q \\in \\mathbb{R}^{m \\times r}$ 和 $R \\in \\mathbb{R}^{r \\times n}$ 中标量条目的总数，分母是 $Q_{\\mathrm{full}} \\in \\mathbb{R}^{m \\times m}$ 和 $R_{\\mathrm{full}} \\in \\mathbb{R}^{m \\times n}$ 中标量条目的总数。\n\n测试套件（三个矩阵），需确定性地生成：\n- 情况1（高瘦，良态）：$m = 8$, $n = 3$。令 $A \\in \\mathbb{R}^{8 \\times 3}$ 的元素为独立同分布的标准正态分布，由种子为 $7$ 的伪随机数生成器生成。\n- 情况2（高瘦，接近秩亏）：$m = 10$, $n = 5$。首先使用种子 $13$ 生成一个元素为独立同分布标准正态分布的矩阵 $B \\in \\mathbb{R}^{10 \\times 4}$，然后将第五列设置为 $A_{:,5} = B_{:,1} + \\epsilon \\eta$，其中 $\\eta \\in \\mathbb{R}^{10}$ 的元素由同一生成器生成，为独立同分布的标准正态分布，且 $\\epsilon = 10^{-16}$。$A$ 的前四列按顺序等于 $B$ 的列。\n- 情况3（方形范德蒙矩阵）：$m = n = 5$。令 $x_k = \\dfrac{k}{m-1}$，其中 $k = 0, 1, 2, 3, 4$。定义 $A \\in \\mathbb{R}^{5 \\times 5}$ 为 $A_{ij} = x_i^j$，其中 $i = 0, 1, 2, 3, 4$ 且 $j = 0, 1, 2, 3, 4$。\n\n使用数值容差 $\\tau = \\varepsilon \\cdot \\max(m,n) \\cdot \\lVert A \\rVert_{\\mathrm{F}}$，其中 $\\varepsilon$ 是双精度浮点运算的机器精度。所有范数均为 Frobenius 范数。不涉及角度；不涉及物理单位。\n\n您的程序应生成单行输出，其中包含三个测试用例的结果，格式为逗号分隔的列表的列表，每个内部列表按 $[e_{\\mathrm{rec}}, e_{\\mathrm{orth}}, e_{\\mathrm{proj}}, \\rho]$ 的顺序排列，并用方括号括起来（例如，`[[a,b,c,d],[a',b',c',d'],[a'',b'',c'',d'']]`），其中所有 $a,b,c,d$ 符号表示您的程序计算出的浮点数。",
            "solution": "该问题要求从线性代数的基本原理（即内积和正交投影）出发，实现并验证一个“瘦”QR分解算法。该算法必须对数值秩亏具有鲁棒性。随后，需要构造一个正交投影算子并验证其性质。最后，要求解释瘦分解相对于完整分解在计算和存储效率方面的优势。该问题陈述清晰，科学上合理，并包含了确定性求解所需的所有信息。\n\n### 第1部分：QR分解算法的推导\n\n目标是将一个列向量为 $\\{a_1, a_2, \\dots, a_n\\}$ 的矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 分解为 $A \\approx QR$，其中 $Q \\in \\mathbb{R}^{m \\times r}$ 具有正交归一的列 $\\{q_1, q_2, \\dots, q_r\\}$，$R \\in \\mathbb{R}^{r \\times n}$ 是一个上梯形矩阵。$Q$ 的列必须构成 $A$ 的列空间（记作 $\\mathrm{span}(A)$）的一组正交归一基。整数 $r \\le n$ 代表 $A$ 的数值秩。\n\n此过程的基础是 Gram-Schmidt 正交化过程，该过程从一组线性无关的向量构造出一个正交归一集。我们从两个向量 $u, v \\in \\mathbb{R}^{m}$ 的标准欧几里得内积的定义开始，即 $\\langle u, v \\rangle = u^{\\mathsf{T}}v$。该内积导出欧几里得范数 $\\lVert u \\rVert_2 = \\sqrt{\\langle u, u \\rangle}$。\n\n向量 $a_j$ 到单位向量 $q_i$ 方向上的正交投影由 $\\mathrm{proj}_{q_i} a_j = \\langle a_j, q_i \\rangle q_i$ 给出。要使向量 $a_j$ 与 $q_i$ 正交，我们减去这个投影：$a_j - \\mathrm{proj}_{q_i} a_j$。要使 $a_j$ 与整个正交归一集 $\\{q_1, \\dots, q_{k}\\}$ 正交，我们减去其在每个基向量上的投影：\n$$ v_j = a_j - \\sum_{i=1}^{k} \\mathrm{proj}_{q_i} a_j = a_j - \\sum_{i=1}^{k} \\langle a_j, q_i \\rangle q_i $$\n得到的向量 $v_j$ 与 $\\{q_1, \\dots, q_{k}\\}$ 中的每个向量都正交。\n\n算法逐列进行，对 $j=1, \\dots, n$：\n1.  对于当前列 $a_j$，我们计算一个向量 $v_j$，使其与所有先前构造的正交归一向量 $\\{q_1, \\dots, q_{r}\\}$ 正交，其中 $r$ 是当前已找到的基向量的数量。\n2.  如果 $v_j$ 不是零向量（即其范数高于数值容差），则它代表一个独立于先前向量的新方向。我们将其归一化以获得下一个正交归一向量，$q_{r+1} = v_j / \\lVert v_j \\rVert_2$。\n3.  投影的系数和归一化因子构成了 $R$ 矩阵的第 $j$ 列。\n\n这个过程构建了分解 $A=QR$。对于一个满秩矩阵（$r=n$），重新整理投影公式，我们对每一列 $a_j$ 有：\n$$ a_j = \\sum_{i=1}^{j-1} \\langle a_j, q_i \\rangle q_i + \\lVert v_j \\rVert_2 q_j = \\sum_{i=1}^{j} r_{ij} q_i $$",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a thin QR factorization algorithm from first principles.\n    \"\"\"\n\n    def thin_qr_from_scratch(A: np.ndarray):\n        \"\"\"\n        Computes the thin QR factorization of matrix A using an iterated\n        Gram-Schmidt process with rank detection.\n\n        Args:\n            A: A real matrix of size (m, n).\n\n        Returns:\n            A tuple (Q, R, r) where:\n            - Q is an (m, r) matrix with orthonormal columns.\n            - R is an (r, n) upper trapezoidal matrix.\n            - r is the detected numerical rank.\n        \"\"\"\n        m, n = A.shape\n        \n        # Define the numerical tolerance for rank detection\n        frob_norm_A = np.linalg.norm(A, 'fro')\n        if frob_norm_A == 0:\n            return np.zeros((m, 0)), np.zeros((0, n)), 0\n            \n        eps = np.finfo(A.dtype).eps\n        tolerance = eps * max(m, n) * frob_norm_A\n\n        # Pre-allocate matrices; they will be trimmed at the end\n        Q = np.zeros((m, n), dtype=A.dtype)\n        R = np.zeros((n, n), dtype=A.dtype)\n        rank = 0\n\n        for j in range(n):\n            v = A[:, j].copy()\n            \n            # Use two passes of orthogonalization for numerical stability\n            # This is an implementation of Iterated Gram-Schmidt\n            for _ in range(2):\n                for i in range(rank):\n                    q_i = Q[:, i]\n                    # Inner product:\n```"
        },
        {
            "introduction": "在许多现实世界的应用中，例如实时信号处理或在线学习，数据是逐步到达的，我们需要高效地更新我们的模型。本练习探讨了一个优雅且高效的算法，用于在原矩阵增加新行时更新其 QR 分解，而无需从头进行完全重新计算。掌握这种更新技术是理解矩阵分解在动态计算环境中强大功能的重要一步 。",
            "id": "2429968",
            "problem": "给定一个列满秩为 $n$ 的实矩阵 $A \\in \\mathbb{R}^{m \\times n}$，以及其瘦QR分解 $A = Q R$，其中 $Q \\in \\mathbb{R}^{m \\times n}$ 具有标准正交列，满足 $Q^{\\top} Q = I_n$，$R \\in \\mathbb{R}^{n \\times n}$ 是一个对角元严格为正的上三角矩阵。考虑追加单行 $a^{\\top} \\in \\mathbb{R}^{1 \\times n}$ 以获得增广矩阵 $A_{+} \\in \\mathbb{R}^{(m+1) \\times n}$，定义为\n$$\nA_{+} = \\begin{bmatrix} A \\\\ a^{\\top} \\end{bmatrix}.\n$$\n您的任务是，对每个指定的测试用例，计算唯一的、对角元严格为正的上三角矩阵 $R_{+} \\in \\mathbb{R}^{n \\times n}$，使得\n$$\nR_{+}^{\\top} R_{+} = A_{+}^{\\top} A_{+}.\n$$\n根据瘦QR分解的定义，在对角元严格为正的约定下，这个 $R_{+}$ 是与 $A_{+}$ 的瘦QR分解相关联的上三角因子。该计算必须仅基于初始因子 $R$ 和追加的行 $a^{\\top}$，通过基本恒等式和正交变换的性质进行。\n\n对每个测试用例，定义标量\n$$\n\\Delta = \\max_{1 \\le i,j \\le n} \\left| \\left(R_{+}\\right)_{ij} - \\left(\\widehat{R}_{+}\\right)_{ij} \\right|,\n$$\n其中 $\\widehat{R}_{+}$ 表示通过直接计算 $A_{+}$ 的瘦QR分解得到的上三角因子（对角元严格为正），而 $\\left(\\cdot\\right)_{ij}$ 表示第 $i$ 行第 $j$ 列的元素。您必须为每个测试用例输出 $\\Delta$。\n\n测试套件：\n- 用例 $1$：\n  - $A = \\begin{bmatrix}\n  2  -1  0 \\\\\n  1  2  1 \\\\\n  0  1  2 \\\\\n  1  0  1\n  \\end{bmatrix} \\in \\mathbb{R}^{4 \\times 3}$，\n  - $a^{\\top} = \\begin{bmatrix} 1  -2  3 \\end{bmatrix} \\in \\mathbb{R}^{1 \\times 3}$。\n- 用例 $2$：\n  - $A = \\begin{bmatrix}\n  1  0  0 \\\\\n  0  1  0 \\\\\n  0  0  1\n  \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 3}$，\n  - $a^{\\top} = \\begin{bmatrix} 0  0  0 \\end{bmatrix} \\in \\mathbb{R}^{1 \\times 3}$。\n- 用例 $3$：\n  - $A = \\begin{bmatrix}\n  1.0  2.0 \\\\\n  2.0  4.0001 \\\\\n  3.0  6.0002\n  \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 2}$，\n  - $a^{\\top} = \\begin{bmatrix} 4.0  8.0003 \\end{bmatrix} \\in \\mathbb{R}^{1 \\times 2}$。\n- 用例 $4$：\n  - $A = \\begin{bmatrix}\n  3  1  0 \\\\\n  1  3  1 \\\\\n  0  1  3\n  \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 3}$，\n  - $a^{\\top} = \\begin{bmatrix} 1  0  1 \\end{bmatrix} \\in \\mathbb{R}^{1 \\times 3}$。\n- 用例 $5$：\n  - $A = \\begin{bmatrix}\n  1 \\\\\n  2 \\\\\n  3 \\\\\n  4 \\\\\n  5\n  \\end{bmatrix} \\in \\mathbb{R}^{5 \\times 1}$，\n  - $a^{\\top} = \\begin{bmatrix} 6 \\end{bmatrix} \\in \\mathbb{R}^{1 \\times 1}$。\n\n答案规范与输出格式：\n- 对每个用例，计算如上定义的 $\\Delta$。\n- 您的程序应生成单行输出，其中按顺序包含用例1到5的 $\\Delta$ 值，形式为方括号括起来的逗号分隔列表，例如 $[x_1,x_2,x_3,x_4,x_5]$，其中每个 $x_k$ 是一个实数。\n- 每个 $x_k$ 必须以科学记数法打印，小数点后恰好有 $10$ 位数字。",
            "solution": "所陈述的问题已经过验证，被认为是具有科学依据、适定且客观的。它提出了计算工程中的一个标准任务：对一个追加了一行的矩阵更新其QR分解。所有提供的数据和条件都是一致且充分的，足以得出一个唯一且有意义的解。因此，我们着手进行解法的推导和实现。\n\n该问题要求从增广矩阵 $A_{+} \\in \\mathbb{R}^{(m+1) \\times n}$ 的瘦QR分解中计算上三角因子 $R_{+} \\in \\mathbb{R}^{n \\times n}$。矩阵 $A_{+}$ 是通过向一个具有已知瘦QR分解 $A = QR$ 的矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 追加一行 $a^{\\top} \\in \\mathbb{R}^{1 \\times n}$ 而形成的。因子 $R_{+} \\in \\mathbb{R}^{n \\times n}$ 由关系式 $R_{+}^{\\top} R_{+} = A_{+}^{\\top} A_{+}$ 以及其对角元必须严格为正的约束唯一确定。该计算必须利用已有的因子 $R$ 和新追加的行 $a^{\\top}$。\n\n首先，我们建立基本的代数关系。$A_{+}$ 的正规方程矩阵由下式给出：\n$$\nA_{+}^{\\top} A_{+} = \\begin{bmatrix} A^{\\top}  a \\end{bmatrix} \\begin{bmatrix} A \\\\ a^{\\top} \\end{bmatrix} = A^{\\top} A + a a^{\\top}\n$$\n根据初始的瘦QR分解 $A=QR$，其中 $Q^{\\top}Q=I_{n}$，我们有：\n$$\nA^{\\top} A = (QR)^{\\top}(QR) = R^{\\top}Q^{\\top}QR = R^{\\top}I_{n}R = R^{\\top}R\n$$\n将此代入 $A_{+}^{\\top} A_{+}$ 的表达式中，我们得到 $R_{+}$ 的目标关系式：\n$$\nR_{+}^{\\top} R_{+} = R^{\\top}R + aa^{\\top}\n$$\n项 $aa^{\\top}$ 表示对矩阵 $R^{\\top}R$ 的一个秩一更新。我们寻求更新后矩阵的 Cholesky 因子。通过观察到右侧可以表示为一个乘积，可以找到一条通往 $R_{+}$ 的更直接的路径：\n$$\nR^{\\top}R + aa^{\\top} = \\begin{bmatrix} R^{\\top}  a \\end{bmatrix} \\begin{bmatrix} R \\\\ a^{\\top} \\end{bmatrix}\n$$\n这揭示了 $R_{+}^{\\top} R_{+}$ 是辅助矩阵 $\\begin{bmatrix} R \\\\ a^{\\top} \\end{bmatrix}$ 的格拉姆矩阵。因此，$R_{+}$ 必定是该辅助矩阵的瘦QR分解的 R 因子。我们将此矩阵定义为 $M \\in \\mathbb{R}^{(n+1) \\times n}$：\n$$\nM = \\begin{bmatrix} R \\\\ a^{\\top} \\end{bmatrix}\n$$\n如果我们找到一个正交矩阵 $G \\in \\mathbb{R}^{(n+1) \\times (n+1)}$，使得 $GM$ 的最后一行完全为零，即\n$$\nGM = \\begin{bmatrix} R_{+} \\\\ 0_{1 \\times n} \\end{bmatrix}\n$$\n其中 $R_{+}$ 是上三角矩阵，那么根据 $G$ 的正交性（$G^{\\top}G=I$），我们有：\n$$\nM^{\\top}M = (GM)^{\\top}(GM) = \\begin{bmatrix} R_{+}^{\\top}  0^{\\top} \\end{bmatrix} \\begin{bmatrix} R_{+} \\\\ 0 \\end{bmatrix} = R_{+}^{\\top}R_{+}\n$$\n这证实了 $M$ 的 R 因子确实是所求的 $R_{+}$。\n\n由于 $R$ 已经是上三角矩阵，矩阵 $M$ 几乎是所需的形式。只有它的最后一行 $a^{\\top}$ 破坏了上三角结构。我们可以通过使用一系列 Givens 旋转系统地消去最后一行的非零元来恢复这种结构。\n\n过程如下。将工作矩阵记为 $\\tilde{M}$，并初始化为 $\\tilde{M} = M$。我们应用一系列 $n$ 次 Givens 旋转，$G_1, G_2, \\ldots, G_n$。对于 $j=1, 2, \\ldots, n$，旋转 $G_j$ 被设计用来通过旋转第 $j$ 行和第 $n+1$ 行，来消去当前矩阵在位置 $(n+1, j)$ 上的元素。\n\n具体来说，对每个 $j \\in \\{1, \\dots, n\\}$，设当前矩阵元素为 $\\tilde{m}_{jk}$ 和 $\\tilde{m}_{n+1,k}$。我们在 $(j, n+1)$ 平面上构造一个 Givens 旋转，以将元素 $\\tilde{m}_{n+1, j}$ 置零。令 $x = \\tilde{m}_{jj}$ 且 $y = \\tilde{m}_{n+1, j}$。Givens 旋转的参数 $c$ 和 $s$ 的计算需满足：\n$$\n\\begin{bmatrix} c  s \\\\ -s  c \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} \\sqrt{x^2+y^2} \\\\ 0 \\end{bmatrix}\n$$\n然后将此旋转应用于第 $j$ 行和第 $n+1$ 行的所有列 $k = j, \\ldots, n$。对 $j=1, \\ldots, n$ 依次应用此序列，可变换矩阵 $M$：\n$$\nG_n \\cdots G_2 G_1 \\begin{bmatrix} R \\\\ a^{\\top} \\end{bmatrix} = \\begin{bmatrix} R_{+} \\\\ 0_{1 \\times n} \\end{bmatrix}\n$$\n得到的 $n \\times n$ 上部块即为所求的矩阵 $R_{+}$。由于原始对角元 $R_{ii}$ 是严格为正的，并且每个新的对角元 $(R_{+})_{jj}$ 被计算为 $\\sqrt{(\\tilde{m}_{jj})^2 + (\\tilde{m}_{n+1, j})^2}$，因此 $R_{+}$ 的对角元也保证是严格为正的。\n\n此算法仅使用 $R$ 和 $a^{\\top}$ 来计算 $R_{+}$，满足了问题约束。为了验证，将得到的 $R_{+}$ 与 $\\widehat{R}_{+}$进行比较，后者是通过对 $A_{+}$ 进行直接的瘦QR分解得到的，并确保其对角元为正。这两个矩阵元素之间的最大绝对差 $\\Delta$ 量化了更新过程的数值一致性。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg.blas import drotg\n\ndef get_positive_diagonal_R(A):\n    \"\"\"\n    Computes the thin QR factorization of A and ensures the R factor has\n    strictly positive diagonal entries.\n    \"\"\"\n    # The problem statement guarantees A has full column rank.\n    if A.shape[1] == 0:\n        return np.empty((0, 0))\n        \n    _, R = np.linalg.qr(A, mode='reduced')\n    \n    n = R.shape[1]\n    for i in range(n):\n        if R[i, i]  0:\n            R[i, :] *= -1\n            \n    return R\n\ndef solve():\n    \"\"\"\n    Solves the problem for all specified test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([\n                [2.0, -1.0, 0.0],\n                [1.0, 2.0, 1.0],\n                [0.0, 1.0, 2.0],\n                [1.0, 0.0, 1.0]\n            ]),\n            np.array([1.0, -2.0, 3.0])\n        ),\n        (\n            np.array([\n                [1.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0],\n                [0.0, 0.0, 1.0]\n            ]),\n            np.array([0.0, 0.0, 0.0])\n        ),\n        (\n            np.array([\n                [1.0, 2.0],\n                [2.0, 4.0001],\n                [3.0, 6.0002]\n            ]),\n            np.array([4.0, 8.0003])\n        ),\n        (\n            np.array([\n                [3.0, 1.0, 0.0],\n                [1.0, 3.0, 1.0],\n                [0.0, 1.0, 3.0]\n            ]),\n            np.array([1.0, 0.0, 1.0])\n        ),\n        (\n            np.array([\n                [1.0],\n                [2.0],\n                [3.0],\n                [4.0],\n                [5.0]\n            ]),\n            np.array([6.0])\n        ),\n    ]\n\n    delta_results = []\n\n    for A, a_row in test_cases:\n        m, n = A.shape\n        \n        # Step 1: Obtain the initial R factor with positive diagonals.\n        R = get_positive_diagonal_R(A)\n        \n        # Step 2: Form the augmented matrix M = [R^T, a]^T\n        M_aug = np.vstack([R, a_row.reshape(1, n)])\n        \n        # Step 3: Use Givens rotations to zero out the last row of M_aug.\n        # The working matrix is a copy of M_aug.\n        R_plus_computed_aug = M_aug.copy()\n        \n        for j in range(n):\n            # Elements to be rotated are in column j of rows j and n.\n            x = R_plus_computed_aug[j, j]\n            y = R_plus_computed_aug[n, j]\n            \n            # drotg computes c, s for a Givens rotation.\n            # It's a low-level BLAS function. For floats it's drotg.\n            c, s = drotg(x, y)\n\n            # Define the 2x2 Givens rotation matrix\n            G = np.array([[c, s], [-s, c]])\n            \n            # Apply the rotation to the relevant part of rows j and n.\n            # This affects columns from j to n-1.\n            rows_to_update = R_plus_computed_aug[[j, n], j:]\n            R_plus_computed_aug[[j, n], j:] = G @ rows_to_update\n\n        # The updated R factor is the top n x n block\n        R_plus_computed = R_plus_computed_aug[:n, :]\n        \n        # Step 4: Compute the reference R_plus by direct QR factorization of A_plus.\n        A_plus = np.vstack([A, a_row.reshape(1, n)])\n        R_plus_ref = get_positive_diagonal_R(A_plus)\n        \n        # Step 5: Compute the delta value.\n        delta = np.max(np.abs(R_plus_computed - R_plus_ref))\n        delta_results.append(delta)\n\n    # Final print statement in the exact required format.\n    formatted_results = [\"{:.10e}\".format(res) for res in delta_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}