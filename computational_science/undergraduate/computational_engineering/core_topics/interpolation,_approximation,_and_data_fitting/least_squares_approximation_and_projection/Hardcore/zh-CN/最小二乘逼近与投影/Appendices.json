{
    "hands_on_practices": [
        {
            "introduction": "在工程实践中，我们获得的测量数据往往并非完美，其可靠性也各不相同。标准最小二乘法平等地对待每一个数据点，但这在某些情况下并非最佳策略。本练习将引导你运用加权最小二乘法（Weighted Least Squares, WLS），通过为不同可靠性的数据点分配不同权重，使更精确的测量值对模型拟合结果产生更大影响，从而获得更稳健的估计。",
            "id": "2408206",
            "problem": "在离散时间点，从单个传感器获得一组标量观测值，其误差方差已知，表明可靠性不同。设时间 $t_i$ 的观测值为 $y_i$，其误差方差为 $\\sigma_i^2$。考虑二次模型 $y_i \\approx \\beta_0 + \\beta_1 t_i + \\beta_2 t_i^2$，写成矩阵形式为 $y \\approx A \\beta$，其中 $A \\in \\mathbb{R}^{m \\times 3}$ 的行为 $[\\,1,\\ t_i,\\ t_i^2\\,]$，$y \\in \\mathbb{R}^m$ 堆叠了观测值，$\\beta \\in \\mathbb{R}^3$ 是系数向量。定义对角权重矩阵 $W \\in \\mathbb{R}^{m \\times m}$ 为 $W = \\mathrm{diag}(w_1,\\dots,w_m)$，其中 $w_i = 1/\\sigma_i^2$。\n\n对于下方的每个测试用例，计算能最小化加权平方误差的系数向量 $\\hat{\\beta} \\in \\mathbb{R}^3$\n$$\nJ(\\beta) = (y - A \\beta)^\\top W (y - A \\beta),\n$$\n以及加权残差范数\n$$\n\\rho = \\sqrt{(y - A \\hat{\\beta})^\\top W (y - A \\hat{\\beta})}.\n$$\n所有算术运算均无单位。不涉及角度。报告所有浮点输出，四舍五入至恰好$6$位小数。\n\n测试套件：\n- 用例 1（异方差，超定）：时间 $t = [0, 1, 2, 3]$，观测值 $y = [1.1, 1.9, 1.0, -0.2]$，方差 $\\sigma^2 = [0.04, 0.09, 0.04, 0.16]$。\n- 用例 2（恰定，可靠性变化）：时间 $t = [0, 1, 3]$，观测值 $y = [1.0, -0.5, -0.5]$，方差 $\\sigma^2 = [0.25, 4.0, 0.25]$。\n- 用例 3（可靠性差异巨大，对称采样）：时间 $t = [-2, -1, 0, 1, 2]$，观测值 $y = [4.7, 2.2, 0.6, 2.1, 4.6]$，方差 $\\sigma^2 = [1.0, 0.25, 0.0004, 0.25, 100.0]$。\n\n要求的最终输出格式：\n- 您的程序必须生成单行文本，其中包含一个列表，每个测试用例对应一个条目，并按顺序排列。每个条目必须是列表 $[\\hat{\\beta}_0,\\hat{\\beta}_1,\\hat{\\beta}_2,\\rho]$，其中每个值都四舍五入到$6$位小数。因此，总的行必须看起来像一个列表的列表，例如：$[[b_{0},b_{1},b_{2},r],[\\dots],[\\dots]]$。",
            "solution": "问题陈述已经过分析，被认为是有效的。它具有科学依据、良定、客观且完整。它代表了加权最小二乘法的标准应用，这是计算工程和统计学中的一个基本课题。我现在将提供解决方案。\n\n问题是找到系数向量 $\\hat{\\beta} \\in \\mathbb{R}^3$，使得模型 $y_i \\approx \\beta_0 + \\beta_1 t_i + \\beta_2 t_i^2$ 能够最佳拟合一组 $m$ 个观测值 $(t_i, y_i)$，其中每个观测值 $y_i$ 都有已知的误差方差 $\\sigma_i^2$。“最佳拟合”定义为最小化加权平方误差和的拟合，该准则由目标函数表示：\n$$\nJ(\\beta) = (y - A \\beta)^\\top W (y - A \\beta)\n$$\n这里，$y \\in \\mathbb{R}^m$ 是观测值的列向量，$\\beta = [\\beta_0, \\beta_1, \\beta_2]^\\top$ 是系数向量，$A \\in \\mathbb{R}^{m \\times 3}$ 是设计矩阵，其第 $i$ 行为 $[1, t_i, t_i^2]$，而 $W$ 是一个对角权重矩阵，$W = \\mathrm{diag}(w_1, w_2, \\dots, w_m)$，其中 $w_i = 1/\\sigma_i^2$。\n\n这个目标函数不是任意的。在测量误差是独立且服从零均值、方差为 $\\sigma_i^2$ 的正态分布的假设下，最小化该函数对应于 $\\beta$ 的最大似然估计 (MLE)。这是因为最大化似然函数等价于最小化由各自方差归一化的平方误差之和，而这正是 $J(\\beta)$ 所表示的。\n\n为了找到最小化二次型 $J(\\beta)$ 的向量 $\\hat{\\beta}$，我们必须通过将 $J(\\beta)$ 对 $\\beta$ 的梯度设为零来找到驻点。首先，我们展开目标函数：\n$$\nJ(\\beta) = y^\\top W y - y^\\top W A \\beta - (A \\beta)^\\top W y + (A \\beta)^\\top W A \\beta\n$$\n认识到 $y^\\top W A \\beta$ 是一个标量，因此等于其转置 $\\beta^\\top A^\\top W y$，我们合并线性项：\n$$\nJ(\\beta) = y^\\top W y - 2 \\beta^\\top A^\\top W y + \\beta^\\top (A^\\top W A) \\beta\n$$\n使用标准矩阵微积分恒等式求得关于 $\\beta$ 的梯度：\n$$\n\\nabla_{\\beta} J(\\beta) = \\frac{\\partial J(\\beta)}{\\partial \\beta} = -2 A^\\top W y + 2(A^\\top W A)\\beta\n$$\n将梯度设为零向量，得到最小值的条件：\n$$\n-2 A^\\top W y + 2(A^\\top W A)\\hat{\\beta} = 0\n$$\n这简化为称为**加权正规方程组**的线性方程组：\n$$\n(A^\\top W A) \\hat{\\beta} = A^\\top W y\n$$\n为了使唯一解 $\\hat{\\beta}$ 存在，矩阵 $A^\\top W A$ 必须是可逆的。如果 $A$ 的列是线性无关的，这个条件就成立，在所有给定的测试用例中都是如此，因为它们都涉及至少三个不同的时间点 $t_i$。由于所有指定的方差 $\\sigma_i^2$ 都是正的，权重矩阵 $W$ 是正定的，从而确保了 $A^\\top W A$ 的可逆性。解由以下公式形式给出：\n$$\n\\hat{\\beta} = (A^\\top W A)^{-1} (A^\\top W y)\n$$\n为了获得更好的数值稳定性，应避免直接计算逆矩阵。一个更好的方法是将问题转化为一个标准的、非加权的最小二乘问题。令 $\\sqrt{W}$ 为对角矩阵，其元素为 $\\sqrt{w_i} = 1/\\sigma_i$。我们定义缩放后的变量 $\\tilde{A} = \\sqrt{W} A$ 和 $\\tilde{y} = \\sqrt{W} y$。目标函数变为：\n$$\nJ(\\beta) = (\\tilde{y} - \\tilde{A} \\beta)^\\top (\\tilde{y} - \\tilde{A} \\beta) = ||\\tilde{y} - \\tilde{A} \\beta||_2^2\n$$\n这是一个标准的最小二乘问题，可以使用诸如 QR分解之类的方法稳健地求解 $\\hat{\\beta}$，就像在 `numpy.linalg.lstsq` 中实现的那样。\n\n一旦确定了最优系数向量 $\\hat{\\beta}$，第二个需要计算的量是加权残差范数 $\\rho$。这仅仅是最小化目标函数值 $J(\\hat{\\beta})$ 的平方根：\n$$\n\\rho = \\sqrt{J(\\hat{\\beta})} = \\sqrt{(y - A \\hat{\\beta})^\\top W (y - A \\hat{\\beta})} = \\sqrt{||\\tilde{y} - \\tilde{A} \\hat{\\beta}||_2^2}\n$$\n值 $||\\tilde{y} - \\tilde{A} \\hat{\\beta}||_2^2$ 是缩放后问题的残差平方和，通常由数值最小二乘求解器返回。\n\n在用例2中出现了一种特殊情况，即观测数量 $m=3$ 等于参数数量 $n=3$。如果时间点 $t_i$ 是不同的，矩阵 $A$ 是方阵且可逆。问题是恰定的。在这种情况下，解就是 $\\hat{\\beta} = A^{-1} y$，这会得到一个完美拟合，$A\\hat{\\beta} = y$。残差向量 $y - A\\hat{\\beta}$ 是零向量，因此，无论权重如何，加权残差范数 $\\rho$ 都为零。\n\n对每个测试用例要实现的算法如下：\n1.  构造观测向量 $y$ 和时间点向量 $t$。\n2.  构造设计矩阵 $A \\in \\mathbb{R}^{m \\times 3}$，其中第 $i$ 行为 $[1, t_i, t_i^2]$。\n3.  根据方差 $\\sigma^2$ 计算权重 $w_i = 1/\\sigma_i^2$。\n4.  通过将 $A$ 的每一行乘以对应的 $\\sqrt{w_i}$ 来形成缩放矩阵 $\\tilde{A}$。\n5.  通过将 $y$ 的每个元素乘以对应的 $\\sqrt{w_i}$ 来形成缩放向量 $\\tilde{y}$。\n6.  求解标准最小二乘问题 $\\tilde{A}\\beta \\approx \\tilde{y}$ 以找到 $\\hat{\\beta}$ 和残差平方和 $S_{res} = ||\\tilde{y} - \\tilde{A} \\hat{\\beta}||_2^2$。\n7.  计算加权残差范数 $\\rho = \\sqrt{S_{res}}$。\n8.  将结果向量 $[\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2, \\rho]$ 的值四舍五入到$6$位小数进行格式化。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of weighted least-squares problems to fit a quadratic model.\n    For each case, it computes the optimal coefficient vector and the weighted residual norm.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"t\": np.array([0, 1, 2, 3], dtype=float),\n            \"y\": np.array([1.1, 1.9, 1.0, -0.2], dtype=float),\n            \"sigma2\": np.array([0.04, 0.09, 0.04, 0.16], dtype=float)\n        },\n        {\n            \"t\": np.array([0, 1, 3], dtype=float),\n            \"y\": np.array([1.0, -0.5, -0.5], dtype=float),\n            \"sigma2\": np.array([0.25, 4.0, 0.25], dtype=float)\n        },\n        {\n            \"t\": np.array([-2, -1, 0, 1, 2], dtype=float),\n            \"y\": np.array([4.7, 2.2, 0.6, 2.1, 4.6], dtype=float),\n            \"sigma2\": np.array([1.0, 0.25, 0.0004, 0.25, 100.0], dtype=float)\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        t = case[\"t\"]\n        y = case[\"y\"]\n        sigma2 = case[\"sigma2\"]\n        m = len(t)\n        \n        # Construct the design matrix A\n        A = np.zeros((m, 3))\n        A[:, 0] = 1.0\n        A[:, 1] = t\n        A[:, 2] = t**2\n        \n        # Calculate weights and their square roots\n        w = 1.0 / sigma2\n        sqrt_w = np.sqrt(w)\n        \n        # Scale the problem to a standard least-squares form\n        # A_tilde = sqrt(W) * A\n        # y_tilde = sqrt(W) * y\n        # We can do this efficiently by row-wise multiplication\n        A_tilde = A * sqrt_w[:, np.newaxis]\n        y_tilde = y * sqrt_w\n        \n        # Solve the standard least-squares problem for beta_hat\n        # lstsq returns: coefficients, residuals, rank, singular values\n        # The 'residuals' is the sum of squared errors ||y_tilde - A_tilde*beta_hat||^2\n        beta_hat, residuals, _, _ = np.linalg.lstsq(A_tilde, y_tilde, rcond=None)\n        \n        # The weighted residual norm rho is the square root of the sum of squared residuals\n        # of the scaled problem. If the system is overdetermined, residuals will be non-empty.\n        if residuals.size > 0:\n            rho = np.sqrt(residuals[0])\n        else:\n            # For an exactly determined system, the residual is zero.\n            rho = 0.0\n            \n        case_result = [beta_hat[0], beta_hat[1], beta_hat[2], rho]\n        \n        # Format the result with values rounded to 6 decimal places.\n        formatted_case_result = [f\"{val:.6f}\" for val in case_result]\n        all_results.append(f\"[{','.join(formatted_case_result)}]\")\n    \n    # Print the final output in the required list-of-lists format\n    print(f\"[{','.join(all_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "掌握了模型拟合的基本方法后，一个自然的倾向是使用更复杂的模型（例如高次多项式）以期获得对已知数据更好的拟合。然而，这可能是一个陷阱，导致所谓的“过拟合”现象。本练习将通过一个经典的龙格现象（Runge's phenomenon）案例，让你亲手实践并观察到，使用高次多项式对等距采样点进行插值时，即使模型完美通过了所有数据点，但在数据点之间却可能产生剧烈振荡，从而丧失了预测能力。",
            "id": "2408214",
            "problem": "给定一个实值函数 $f:\\,[-1,1]\\to\\mathbb{R}$，其定义为 $f(x)=\\dfrac{1}{1+25x^{2}}$。对于一个给定的正整数 $m\\geq 2$，定义等距采样点 $x_i=-1+\\dfrac{2i}{m-1}$，其中 $i=0,1,\\dots,m-1$。令 $y_i=f(x_i)$ 对所有 $i$ 成立。对于一个给定的非负整数 $n$（$n\\leq m-1$），考虑最高次数为 $n$ 的多项式空间 $\\mathcal{P}_n=\\{p:\\,p(x)=\\sum_{j=0}^{n}c_j x^{j}\\}$。定义函数 $g,h:[-1,1]\\to\\mathbb{R}$ 上的离散内积为 $\\langle g,h\\rangle_m=\\sum_{i=0}^{m-1} g(x_i)\\,h(x_i)$。设 $p_n\\in\\mathcal{P}_n$ 是在所有 $p\\in\\mathcal{P}_n$ 中使离散平方和 $\\sum_{i=0}^{m-1}\\big(p(x_i)-y_i\\big)^2$ 最小化的任意多项式。此 $p_n$ 是 $f$ 在 $\\langle\\cdot,\\cdot\\rangle_m$ 意义下到 $\\mathcal{P}_n$ 上的正交投影。\n\n定义一个验证网格 $G$，由 $[-1,1]$ 上的 $N_v=1001$ 个等距点组成。$p_n$ 相对于 $f$ 的验证均方根（RMS）误差为\n$$\nE_{\\text{val}}=\\sqrt{\\frac{1}{N_v}\\sum_{x\\in G}\\big(p_n(x)-f(x)\\big)^2}\\,.\n$$\n您必须编写一个完整的、可运行的程序，为每个指定的测试用例计算如上定义的 $E_{\\text{val}}$。不涉及物理单位。如果出现任何角度，都必须以弧度为单位进行解释。使用标准四舍五入将每个 $E_{\\text{val}}$ 圆整到10位小数。\n\n待使用的参数对 $(m,n)$ 测试套件：\n- 用例 1：$(m,n)=(21,5)$。\n- 用例 2：$(m,n)=(21,20)$。\n- 用例 3：$(m,n)=(2,1)$。\n- 用例 4：$(m,n)=(41,20)$。\n- 用例 5：$(m,n)=(9,8)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按上述用例的顺序排列结果。例如，一个可接受的格式是 $[e_1,e_2,e_3,e_4,e_5]$，其中每个 $e_k$ 是用例 $k$ 的四舍五入后的验证RMS误差，以十进制数表示。",
            "solution": "该问题要求通过离散最小二乘法确定给定函数 $f(x)$ 的一个多项式逼近 $p_n(x)$，然后评估该逼近的准确性。\n\n待逼近的函数是龙格函数，定义为 $f(x) = \\dfrac{1}{1+25x^{2}}$，定义域为 $x \\in [-1, 1]$。对于每个测试用例，我们给定一个整数 $m \\geq 2$ 指定采样点数量，以及一个整数 $n \\geq 0$ 指定最大多项式次数，约束条件为 $n \\leq m-1$。\n\n$m$ 个采样点，记为 $x_i$（其中 $i=0, 1, \\dots, m-1$），被规定为在区间 $[-1, 1]$ 内等距分布，即 $x_i = -1 + \\dfrac{2i}{m-1}$。在这些点上对应的函数值为 $y_i = f(x_i)$。\n\n我们的任务是在所有最高次数为 $n$ 的多项式构成的空间 $\\mathcal{P}_n$ 中找到一个多项式 $p_n(x)$。该多项式在单项式基中定义为 $p_n(x) = \\sum_{j=0}^{n} c_j x^j$。这些系数由向量 $\\mathbf{c} = [c_0, c_1, \\dots, c_n]^T$ 表示，必须选择它们以最小化多项式与函数在采样点处的平方差之和：\n$$\nS(\\mathbf{c}) = \\sum_{i=0}^{m-1} \\left( p_n(x_i) - y_i \\right)^2 = \\sum_{i=0}^{m-1} \\left( \\left( \\sum_{j=0}^{n} c_j x_i^j \\right) - y_i \\right)^2\n$$\n这个最小化问题是一个经典的线性最小二乘问题。它可以通过矩阵代数来表述，方法是定义一个 $m \\times (n+1)$ 的范德蒙矩阵 $\\mathbf{A}$，其元素为 $A_{ij} = x_i^j$，其中 $i=0, \\dots, m-1$，$j=0, \\dots, n$。如果我们令 $\\mathbf{y}$ 为采样值的 $m \\times 1$ 列向量，$\\mathbf{y} = [y_0, y_1, \\dots, y_{m-1}]^T$，那么目标就是最小化残差向量的欧几里得范数的平方：\n$$\nS(\\mathbf{c}) = \\| \\mathbf{A}\\mathbf{c} - \\mathbf{y} \\|_2^2\n$$\n最小化此表达式的唯一系数向量 $\\mathbf{c}$ 是正规方程组的解：\n$$\n\\mathbf{A}^T \\mathbf{A} \\mathbf{c} = \\mathbf{A}^T \\mathbf{y}\n$$\n约束条件 $n \\leq m-1$ 意味着至少有 $n+1$ 个不同的采样点，这确保了矩阵 $\\mathbf{A}$ 的列是线性无关的。这反过来保证了格拉姆矩阵 $\\mathbf{A}^T\\mathbf{A}$ 是对称正定的，因此是可逆的，从而确保了 $\\mathbf{c}$ 的唯一解。虽然正规方程组提供了一个理论解，但由于 $\\mathbf{A}^T\\mathbf{A}$ 可能的病态性，直接计算可能会遭受数值不稳定性的影响。在计算上，采用基于矩阵分解的方法（如对 $\\mathbf{A}$ 进行QR分解或奇异值分解(SVD)）更为优越，这些方法已在高质量的数值库中实现。\n\n在 $n = m-1$ 的特定情况下，待定系数的数量 $n+1$ 与采样点的数量 $m$ 相同。矩阵 $\\mathbf{A}$ 变成一个可逆的方阵。此时，最小二乘解对应于线性系统 $\\mathbf{A}\\mathbf{c} = \\mathbf{y}$ 的精确解。这表明多项式 $p_n(x)$ 精确地插值了数据点，满足对所有 $i$ 都有 $p_n(x_i) = y_i$。\n\n在为给定的 $(m,n)$ 对计算出最优系数向量 $\\mathbf{c}$ 后，多项式 $p_n(x)$ 就被定义了。然后在一个精细的验证网格 $G$ 上评估其准确性，该网格由 $[-1, 1]$ 上的 $N_v = 1001$ 个等距点组成。验证均方根（RMS）误差定义并计算如下：\n$$\nE_{\\text{val}} = \\sqrt{\\frac{1}{N_v} \\sum_{x \\in G} \\left( p_n(x) - f(x) \\right)^2}\n$$\n因此，为每个测试用例 $(m, n)$ 执行的算法如下：\n1.  生成 $m$ 个采样点 $x_i$ 并计算相应的函数值 $y_i=f(x_i)$。\n2.  求解线性最小二乘问题 $\\min_{\\mathbf{c}} \\| \\mathbf{A}\\mathbf{c} - \\mathbf{y} \\|_2^2$ 以获得多项式系数 $\\mathbf{c}$，其中 $A_{ij} = x_i^j$。为此目的，使用一个数值稳定的库函数。\n3.  建立包含 $N_v=1001$ 个点的验证网格 $G$。\n4.  在 $G$ 中的所有点 $x$ 上，计算已确定的多项式 $p_n(x)$ 和原始函数 $f(x)$ 的值。\n5.  根据这些计算值计算RMS误差 $E_{\\text{val}}$。\n6.  将结果四舍五入到10位小数。\n\n将此系统性步骤应用于每个指定的测试用例，以产生最终结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the validation RMS error for polynomial least-squares approximations\n    of the Runge function for several test cases.\n    \"\"\"\n\n    def f(x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        The Runge function to be approximated.\n        f(x) = 1 / (1 + 25*x^2)\n        \"\"\"\n        return 1.0 / (1.0 + 25.0 * x**2)\n\n    # Test suite of parameter pairs (m, n)\n    # m: number of sample points\n    # n: degree of the polynomial\n    test_cases = [\n        (21, 5),\n        (21, 20),\n        (2, 1),\n        (41, 20),\n        (9, 8),\n    ]\n\n    results = []\n\n    # Define the validation grid G\n    N_v = 1001\n    x_val = np.linspace(-1.0, 1.0, N_v)\n    f_val = f(x_val)\n\n    for m, n in test_cases:\n        # Step 1: Generate m equispaced sample points and their function values.\n        x_samples = np.linspace(-1.0, 1.0, m)\n        y_samples = f(x_samples)\n\n        # Step 2: Find the polynomial p_n of degree n that best fits the\n        # (x_samples, y_samples) data in a least-squares sense.\n        # The numpy.polynomial.polynomial.polyfit function solves this by\n        # finding the coefficients c that minimize the squared error.\n        # The coefficients are returned for the basis 1, x, x^2, ..., x^n.\n        coeffs = np.polynomial.polynomial.polyfit(x_samples, y_samples, n)\n\n        # Step 3: Evaluate the obtained polynomial p_n on the validation grid.\n        p_n_val = np.polynomial.polynomial.polyval(x_val, coeffs)\n\n        # Step 4: Compute the validation root mean square (RMS) error.\n        squared_errors = (p_n_val - f_val)**2\n        mean_squared_error = np.mean(squared_errors)\n        rms_error = np.sqrt(mean_squared_error)\n\n        # Step 5: Round the result to 10 decimal places as specified.\n        rounded_error = round(rms_error, 10)\n        results.append(rounded_error)\n\n    # Format the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "前一个练习展示了高次多项式拟合可能出现的数值不稳定性。这种现象的根源是什么？答案在于问题的“病态性”（ill-conditioning）。本练习将深入探讨最小二乘问题的数值稳定性，揭示其解的稳定性如何严重依赖于设计矩阵的条件数。通过对比标准单项式基函数 $\\{1, x, x^2, \\dots\\}$ 构成的病态范德蒙德矩阵与正交多项式基函数构成的良态矩阵，你将理解为何选择合适的基函数对于保证计算的准确性和稳健性至关重要。",
            "id": "2408241",
            "problem": "考虑在一个区间上，通过 $N$ 个点采样，使用次数至多为 $p$ 的多项式对一个标量函数进行最小二乘逼近，其中 $N \\ge p+1$。设采样点位置为 $x_i \\in [-1,1]$，其中 $i=1,\\dots,N$。定义两个 $N \\times (p+1)$ 的设计矩阵：\n- 单项式 Vandermonde 矩阵 $A_{\\mathrm{m}}$，其元素为 $[A_{\\mathrm{m}}]_{i,k} = x_i^{k}$，其中 $k=0,\\dots,p$。\n- Legendre 矩阵 $A_{\\mathrm{L}}$，其元素为 $[A_{\\mathrm{L}}]_{i,k} = \\widetilde{P}_k(x_i)$，其中 $\\{\\widetilde{P}_k\\}_{k=0}^p$ 是前 $p+1$ 个 Legendre 多项式，它们在 $L^2([-1,1])$ 上关于单位权重是标准正交的，即 $\\int_{-1}^{1} \\widetilde{P}_k(x)\\,\\widetilde{P}_\\ell(x)\\,dx = \\delta_{k\\ell}$。\n\n对于一个给定的满列秩矩阵 $A$，考虑 $A$ 的 2-范数条件数，记为 $\\kappa_2(A)$，以及正规方程矩阵 $A^\\top A$ 的 2-范数条件数，记为 $\\kappa_2(A^\\top A)$。在下面的一些情形中，节点 $x_i$ 取为 $[-1,1]$ 上的 $N$ 点 Gauss–Legendre 求积节点，其对应的正权重为 $w_i$，$i=1,\\dots,N$。在加权最小二乘法中，可以等价地使用加权设计矩阵 $B = W^{1/2} A$，其中 $W = \\mathrm{diag}(w_1,\\dots,w_N)$。\n\n选择所有正确的陈述。\n\nA. 对于 $[-1,1]$ 上的 $N$ 个等距节点，$\\kappa_2(A_{\\mathrm{m}})$ 随 $p$ 快速增长，而 $\\kappa_2(A_{\\mathrm{L}})$ 则由一个与 $p$ 和 $N$ 都无关的常数界定。\n\nB. 如果 $N$ 个节点是 $[-1,1]$ 上的 Gauss–Legendre 节点，其求积权重为 $\\{w_i\\}_{i=1}^N$，那么对于 $N \\ge p+1$，加权 Legendre 设计矩阵 $B_{\\mathrm{L}} = W^{1/2} A_{\\mathrm{L}}$ 的列是标准正交的，因此 $\\kappa_2(B_{\\mathrm{L}}) = 1$。\n\nC. 对于任何满列秩的设计矩阵 $A$，关系式 $\\kappa_2(A^\\top A) = \\kappa_2(A)^2$ 成立。\n\nD. 设 $[a,b]$ 是一个区间，且 $|b-a|>2$。如果将 $x$ 替换为仿射缩放变量 $t = \\dfrac{2x-(a+b)}{b-a}$，使得 $t \\in [-1,1]$，并在 $[a,b]$ 中映射到 $[-1,1]$ 的 $N$ 个等距样本点上，用变量 $t$ 构建单项式设计矩阵，那么与在其他采样条件相当的情况下直接在 $[a,b]$ 上用 $x$ 构建单项式设计矩阵相比，这种缩放会减小 $\\kappa_2$。\n\nE. 在求解最小二乘问题之前使用正交-三角分解 (QR)，既能消除 $A_{\\mathrm{m}}$ 的病态性，又能保证计算解的数值敏感性与所选的多项式基无关，因此基的选择不再重要。\n\nF. 对于 $N$ 个等距节点和较大的 $p$， $A_{\\mathrm{m}}$ 的列变得近乎线性相关，而 $A_{\\mathrm{L}}$ 的列在无权重的离散内积下，对于所有 $p \\le N-1$ 都保持严格正交。",
            "solution": "该问题陈述已经过验证，并且在科学上是合理的、适定的和客观的。它提出了一组关于多项式最小二乘逼近的数值稳定性的标准命题。我们将依次分析每个陈述。\n\n问题的核心在于多项式最小二乘法的设计矩阵 $A$ 的性质。该矩阵的条件数 $\\kappa_2(A)$ 决定了最小二乘解对输入数据扰动的敏感性。大的条件数意味着一个病态问题，容易出现数值不稳定性。多项式基的选择深刻地影响着 $\\kappa_2(A)$。\n\n**陈述 A 的分析：**\n“对于 $[-1,1]$ 上的 $N$ 个等距节点，$\\kappa_2(A_{\\mathrm{m}})$ 随 $p$ 快速增长，而 $\\kappa_2(A_{\\mathrm{L}})$ 则由一个与 $p$ 和 $N$ 都无关的常数界定。”\n\n这个陈述的第一部分是正确的。当次数 $p$ 增加时，单项式基函数 $\\{x^k\\}_{k=0}^p$ 在区间 $[-1,1]$ 上变得近乎线性相关。这导致 Vandermonde 矩阵 $A_{\\mathrm{m}}$ 的列变得近乎共线，从而使得条件数 $\\kappa_2(A_{\\mathrm{m}})$ 随 $p$ 呈指数增长。\n\n然而，陈述的第二部分是错误的。虽然使用像 Legendre 多项式这样的正交多项式基，与 $A_{\\mathrm{m}}$ 相比，会得到一个条件好得多的矩阵 $A_{\\mathrm{L}}$，但对于等距节点，条件数 $\\kappa_2(A_{\\mathrm{L}})$ 并非由一个与 $p$ 无关的常数界定。$A_{\\mathrm{L}}$ 的列是函数 $\\{\\widetilde{P}_k(x)\\}$ 的采样，这些函数关于连续 $L^2$ 内积是正交的，即 $\\int_{-1}^{1} \\widetilde{P}_k(x)\\,\\widetilde{P}_\\ell(x)\\,dx = \\delta_{k\\ell}$。然而，对于等距节点， $A_{\\mathrm{L}}$ 的列关于离散内积 $\\sum_{i=1}^N v_i w_i$ 并不正交。因此，矩阵 $A_{\\mathrm{L}}^\\top A_{\\mathrm{L}}$ 不是对角矩阵，其条件数大于 1。理论和数值结果表明，对于等距节点，$\\kappa_2(A_{\\mathrm{L}})$ 随 $p$ 呈多项式增长（例如，为 $O(p^2)$）。这相比于指数增长是一个显著的改进，但它并非由一个与 $p$ 无关的常数界定。\n\n因此，该陈述是**错误的**。\n\n**陈述 B 的分析：**\n“如果 $N$ 个节点是 $[-1,1]$ 上的 Gauss–Legendre 节点，其求积权重为 $\\{w_i\\}_{i=1}^N$，那么对于 $N \\ge p+1$，加权 Legendre 设计矩阵 $B_{\\mathrm{L}} = W^{1/2} A_{\\mathrm{L}}$ 的列是标准正交的，因此 $\\kappa_2(B_{\\mathrm{L}}) = 1$。”\n\n为了验证这一点，我们必须检查 $B_{\\mathrm{L}}$ 的列的标准正交性。矩阵 $B_{\\mathrm{L}}$ 的元素为 $[B_{\\mathrm{L}}]_{i,k} = \\sqrt{w_i} \\widetilde{P}_k(x_i)$。第 $k$ 列和第 $\\ell$ 列之间的内积由下式给出：\n$$ (B_{\\mathrm{L}})_{:k}^\\top (B_{\\mathrm{L}})_{:\\ell} = \\sum_{i=1}^N (\\sqrt{w_i} \\widetilde{P}_k(x_i)) (\\sqrt{w_i} \\widetilde{P}_\\ell(x_i)) = \\sum_{i=1}^N w_i \\widetilde{P}_k(x_i) \\widetilde{P}_\\ell(x_i) $$\n这个和式正是应用于函数 $f(x) = \\widetilde{P}_k(x) \\widetilde{P}_\\ell(x)$ 的 $N$ 点 Gauss-Legendre 求积法则。函数 $f(x)$ 是一个次数为 $k+\\ell$ 的多项式。由于 $k, \\ell \\le p$，该多项式的最高次数为 $2p$。一个 $N$ 点的 Gauss-Legendre 求积法则对所有次数最高为 $2N-1$ 的多项式都是精确的。题目陈述 $N \\ge p+1$，这等价于 $p \\le N-1$。这意味着 $2p \\le 2(N-1) = 2N-2$。由于 $2N-2  2N-1$，该求积法则对于多项式 $\\widetilde{P}_k(x) \\widetilde{P}_\\ell(x)$ 是精确的。\n\n因此，该和等于积分：\n$$ \\sum_{i=1}^N w_i \\widetilde{P}_k(x_i) \\widetilde{P}_\\ell(x_i) = \\int_{-1}^1 \\widetilde{P}_k(x) \\widetilde{P}_\\ell(x) dx $$\n根据标准正交 Legendre 多项式的定义，这个积分等于克罗内克 δ，即 $\\delta_{k\\ell}$。\n这证明了 $B_{\\mathrm{L}}$ 的列是标准正交的。对于任何具有标准正交列的矩阵 $Q$，有 $Q^\\top Q=I$。这种矩阵的奇异值都等于 1。2-范数条件数是最大奇异值与最小奇异值的比率，所以 $\\kappa_2(B_{\\mathrm{L}}) = \\sigma_{\\max}/\\sigma_{\\min} = 1/1=1$。\n\n因此，该陈述是**正确的**。\n\n**陈述 C 的分析：**\n“对于任何满列秩的设计矩阵 $A$，关系式 $\\kappa_2(A^\\top A) = \\kappa_2(A)^2$ 成立。”\n\n设矩阵 $A$ 的奇异值分解 (SVD) 为 $A = U\\Sigma V^\\top$。由于 $A$ 是满列秩的，其奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_{p+1}$ 都是严格为正的。$A$ 的 2-范数条件数定义为 $\\kappa_2(A) = \\sigma_1/\\sigma_{p+1}$。\n\n现在考虑矩阵 $A^\\top A$：\n$$ A^\\top A = (U\\Sigma V^\\top)^\\top (U\\Sigma V^\\top) = V\\Sigma^\\top U^\\top U\\Sigma V^\\top $$\n由于 $U$ 是一个具有标准正交列的矩阵（如果 $Np+1$）或者是正交矩阵（如果 $N=p+1$），我们有 $U^\\top U = I$，即单位矩阵。因此：\n$$ A^\\top A = V (\\Sigma^\\top \\Sigma) V^\\top $$\n这是对称矩阵 $A^\\top A$ 的特征值分解。$A^\\top A$ 的特征值是对角矩阵 $\\Sigma^\\top \\Sigma$ 的对角元素，即 $\\sigma_1^2, \\sigma_2^2, \\dots, \\sigma_{p+1}^2$。\n像 $A^\\top A$ 这样的方阵的条件数是其最大特征值与最小特征值（的绝对值）之比。所以，\n$$ \\kappa_2(A^\\top A) = \\frac{\\lambda_{\\max}(A^\\top A)}{\\lambda_{\\min}(A^\\top A)} = \\frac{\\sigma_1^2}{\\sigma_{p+1}^2} $$\n将此与 $\\kappa_2(A)$ 的平方进行比较：\n$$ \\kappa_2(A)^2 = \\left(\\frac{\\sigma_1}{\\sigma_{p+1}}\\right)^2 = \\frac{\\sigma_1^2}{\\sigma_{p+1}^2} $$\n关系式 $\\kappa_2(A^\\top A) = \\kappa_2(A)^2$ 成立。这个恒等式是理解为什么构造并求解正规方程在数值上比直接对 $A$ 操作的方法更不稳定的基础。\n\n因此，该陈述是**正确的**。\n\n**陈述 D 的分析：**\n“设 $[a,b]$ 是一个区间，且 $|b-a|2$。如果将 $x$ 替换为仿射缩放变量 $t = \\dfrac{2x-(a+b)}{b-a}$，使得 $t \\in [-1,1]$，并在 $[a,b]$ 中映射到 $[-1,1]$ 的 $N$ 个等距样本点上，用变量 $t$ 构建单项式设计矩阵，那么与在其他采样条件相当的情况下直接在 $[a,b]$ 上用 $x$ 构建单项式设计矩阵相比，这种缩放会减小 $\\kappa_2$。”\n\n当区间 $[a,b]$ 远离原点或宽度很大时，单项式基 $\\{1, x, x^2, \\dots, x^p\\}$ 的病态性会加剧。在像 $[100, 101]$ 这样的区间上，函数 $x^k$ 几乎是彼此的常数倍，导致 Vandermonde 矩阵的列近乎线性相关。在像 $[0, 100]$ 这样的大区间上，$x^p$ 的值域非常巨大，导致矩阵尺度不佳。\n\n仿射变换 $t = \\frac{2x - (a+b)}{b-a}$ 将区间 $[a,b]$ 映射到 $[-1,1]$。使用基 $\\{1, t, t^2, \\dots, t^p\\}$ 构建设计矩阵，等价于在原始变量 $x$ 中使用一个经过平移和缩放的多项式基。这种重新中心化和缩放是改善多项式拟合问题条件数的标准且有效的技术。在 $[-1,1]$ 上，函数 $t^k$ 的“性态”远好于在一般区间 $[a,b]$ 上的 $x^k$。条件 $|b-a|2$ 是一个任意的细节；该原理对几乎任何区间 $[a,b]$ 都成立，特别是那些远离 0 或宽度不为 2 的区间。这个预处理步骤减轻了单项式基病态性的两个主要来源：变量量级过大和未以原点为中心。这总是会导致设计矩阵条件数的减小，通常是减少多个数量级。\n\n因此，该陈述是**正确的**。\n\n**陈述 E 的分析：**\n“在求解最小二乘问题之前使用正交-三角分解 (QR)，既能消除 $A_{\\mathrm{m}}$ 的病态性，又能保证计算解的数值敏感性与所选的多项式基无关，因此基的选择不再重要。”\n\n这个陈述包含两个不正确的断言。\n首先，将 $A$ 分解为 $QR$（其中 $Q$ 的列标准正交，$R$ 是上三角矩阵）并不能“消除”病态性。条件数被保留在 $R$ 因子中：$\\kappa_2(A) = \\kappa_2(QR) = \\kappa_2(Q)\\kappa_2(R) = \\kappa_2(R)$，因为 $\\kappa_2(Q)=1$。最小二乘问题被转化为求解三角系统 $Rc = Q^\\top y$。该系统的敏感性由 $\\kappa_2(R)$ 决定，它与 $\\kappa_2(A)$ 相同。QR 分解相对于正规方程的优势在于它避免了对条件数进行平方。$A$ 中固有的病态性仍然存在于 $R$ 中。\n\n其次，由于数值敏感性取决于 $\\kappa_2(A)$，而不同的基（例如，单项式基与 Legendre 基）会产生条件数截然不同的设计矩阵，因此基的选择仍然至关重要。使用像 Legendre 多项式这样条件良好的基，会得到一个小的 $\\kappa_2(A_{\\mathrm{L}})$，从而得到一个小的 $\\kappa_2(R_{\\mathrm{L}})$，确保了系数向量的稳定计算。而使用单项式基会导致一个大的 $\\kappa_2(A_{\\mathrm{m}})$ 和一个大的 $\\kappa_2(R_{\\mathrm{m}})$, 使得系数的计算不稳定。基的选择绝对重要。\n\n因此，该陈述是**错误的**。\n\n**陈述 F 的分析：**\n“对于 $N$ 个等距节点和较大的 $p$， $A_{\\mathrm{m}}$ 的列变得近乎线性相关，而 $A_{\\mathrm{L}}$ 的列在无权重的离散内积下，对于所有 $p \\le N-1$ 都保持严格正交。”\n\n陈述的第一部分是正确的，如在对陈述 A 的分析中所解释的。\n第二部分是关于 Legendre 多项式在等距网格上离散正交性的断言。$A_{\\mathrm{L}}$ 的第 $k$ 列和第 $\\ell$ 列之间的无权重离散内积是 $\\sum_{i=1}^N \\widetilde{P}_k(x_i) \\widetilde{P}_\\ell(x_i)$。该陈述声称当 $k \\ne \\ell$ 时此和为零。对于等距网格上的 Legendre 多项式，这个性质通常不成立。离散正交性是一个特殊的性质，仅在正交多项式与相应的特殊节点集特定配对时才会出现（例如，Chebyshev 节点上的 Chebyshev 多项式，或如陈述 B 所示，带有适当权重的 Gauss-Legendre 节点上的 Legendre 多项式）。对于像等距网格这样的任意网格，没有理由期望 Legendre 多项式的采样向量是正交的。\n\n因此，该陈述是**错误的**。",
            "answer": "$$\\boxed{BCD}$$"
        }
    ]
}