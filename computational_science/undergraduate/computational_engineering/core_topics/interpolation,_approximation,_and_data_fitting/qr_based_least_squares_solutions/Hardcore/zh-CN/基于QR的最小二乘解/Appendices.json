{
    "hands_on_practices": [
        {
            "introduction": "虽然QR分解因其数值稳定性而备受推崇，但其求解过程的最后一步——回代求解，也可能隐藏着问题。这个练习  揭示了一个重要的现象：即使上三角矩阵 $R$ 本身是良态的，回代过程中的元素增长也可能导致巨大的数值误差。通过一个精心设计的例子，本练习旨在培养对数值稳定性细微之处的深刻洞察力，这对于编写可靠的科学计算代码至关重要。",
            "id": "2430289",
            "problem": "在计算工程中，一个超定线性系统通过正交三角（QR）分解以最小二乘意义求解：对于一个满列秩矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\geq n$），我们计算 $A = Q R$，其中 $Q \\in \\mathbb{R}^{m \\times m}$ 是正交矩阵，$R \\in \\mathbb{R}^{m \\times n}$ 是上三角矩阵，其前导 $n \\times n$ 子块非奇异。最小二乘解 $x \\in \\mathbb{R}^{n}$ 是通过回代法求解上三角系统 $R_{1:n,1:n} x = Q^{T} b$ 得到的。\n\n考虑 $n = 4$，并假设 $4 \\times 4$ 的上三角因子为\n$$\nR \\;=\\; \\begin{pmatrix}\n1  1  1  1\\\\\n0  1  1  1\\\\\n0  0  1  1\\\\\n0  0  0  1\n\\end{pmatrix},\n$$\n且三角求解的右侧项为\n$$\ny \\;=\\; Q^{T} b \\;=\\; \\begin{pmatrix} \\epsilon \\\\ 0 \\\\ -M \\\\ -2M \\end{pmatrix},\n$$\n其中 $M = 10^{8}$ 且 $\\epsilon = 10^{-8}$。\n\n定义回代法的元素增长因子为\n$$\nG \\;=\\; \\max_{1 \\leq i \\leq n} \\frac{|y_{i}| + \\sum_{j=i+1}^{n} |r_{ij}|\\,|x_{j}|}{|r_{ii}|\\,|x_{i}|},\n$$\n其中 $x$ 是 $R x = y$ 的精确解。请根据以上数据计算 $G$。将您的答案四舍五入到四位有效数字。",
            "solution": "所提出的问题是数值线性代数中一个定义明确的练习。它在科学上是合理的、自洽的，并且需要将标准定义应用于一个具体例子。我们开始解题。\n\n问题要求计算给定上三角系统 $Rx = y$ 的元素增长因子 $G$。该系统由矩阵 $R$ 和向量 $y = Q^T b$ 定义。对于一个满秩 $A \\in \\mathbb{R}^{m \\times n}$，我们实际上是在考察子系统 $R_{1:n,1:n}x = (Q^{T}b)_{1:n}$。问题给出了 $n=4$，并提供了一个 $4 \\times 4$ 的上三角矩阵 $R$ 和一个 4 分量向量 $y$。\n\n方程组为 $Rx = y$，即：\n$$\n\\begin{pmatrix}\n1  1  1  1\\\\\n0  1  1  1\\\\\n0  0  1  1\\\\\n0  0  0  1\n\\end{pmatrix}\n\\begin{pmatrix}\nx_1 \\\\ x_2 \\\\ x_3 \\\\ x_4\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\epsilon \\\\ 0 \\\\ -M \\\\ -2M\n\\end{pmatrix}\n$$\n我们使用回代法求解向量 $x = (x_1, x_2, x_3, x_4)^T$，从最后一个方程开始向上求解。\n\n从第四行（$i=4$）：\n$$\n1 \\cdot x_4 = -2M \\implies x_4 = -2M\n$$\n\n从第三行（$i=3$）：\n$$\n1 \\cdot x_3 + 1 \\cdot x_4 = -M \\implies x_3 = -M - x_4 = -M - (-2M) = M\n$$\n\n从第二行（$i=2$）：\n$$\n1 \\cdot x_2 + 1 \\cdot x_3 + 1 \\cdot x_4 = 0 \\implies x_2 = -x_3 - x_4 = -M - (-2M) = M\n$$\n\n从第一行（$i=1$）：\n$$\n1 \\cdot x_1 + 1 \\cdot x_2 + 1 \\cdot x_3 + 1 \\cdot x_4 = \\epsilon \\implies x_1 = \\epsilon - x_2 - x_3 - x_4 = \\epsilon - M - M - (-2M) = \\epsilon\n$$\n\n因此，精确解向量为：\n$$\nx = \\begin{pmatrix}\n\\epsilon \\\\ M \\\\ M \\\\ -2M\n\\end{pmatrix}\n$$\n\n接下来，我们计算元素增长因子 $G$，其定义为：\n$$\nG = \\max_{1 \\leq i \\leq n} G_i, \\quad \\text{其中} \\quad G_i = \\frac{|y_{i}| + \\sum_{j=i+1}^{n} |r_{ij}|\\,|x_{j}|}{|r_{ii}|\\,|x_{i}|}\n$$\n对于本问题，$n=4$ 且所有对角元素 $r_{ii} = 1$。每个 $G_i$ 的公式简化为：\n$$\nG_i = \\frac{|y_{i}| + \\sum_{j=i+1}^{4} |r_{ij}|\\,|x_{j}|}{|x_{i}|}\n$$\n我们为每个 $i \\in \\{1, 2, 3, 4\\}$ 计算 $G_i$。\n\n对于 $i=4$：\n分子中的求和项为空，其值为 $0$。\n$$\nG_4 = \\frac{|y_4|}{|x_4|} = \\frac{|-2M|}{|-2M|} = 1\n$$\n\n对于 $i=3$：\n$$\nG_3 = \\frac{|y_3| + |r_{34}|\\,|x_4|}{|x_3|} = \\frac{|-M| + |1| \\cdot |-2M|}{|M|} = \\frac{M + 2M}{M} = \\frac{3M}{M} = 3\n$$\n\n对于 $i=2$：\n$$\nG_2 = \\frac{|y_2| + |r_{23}|\\,|x_3| + |r_{24}|\\,|x_4|}{|x_2|} = \\frac{|0| + |1| \\cdot |M| + |1| \\cdot |-2M|}{|M|} = \\frac{M + 2M}{M} = \\frac{3M}{M} = 3\n$$\n\n对于 $i=1$：\n$$\nG_1 = \\frac{|y_1| + |r_{12}|\\,|x_2| + |r_{13}|\\,|x_3| + |r_{14}|\\,|x_4|}{|x_1|} = \\frac{|\\epsilon| + |1| \\cdot |M| + |1| \\cdot |M| + |1| \\cdot |-2M|}{|\\epsilon|}\n$$\n给定 $M = 10^8  0$ 和 $\\epsilon = 10^{-8}  0$，我们有 $|\\epsilon| = \\epsilon$， $|M| = M$，以及 $|-2M|=2M$。\n$$\nG_1 = \\frac{\\epsilon + M + M + 2M}{\\epsilon} = \\frac{\\epsilon + 4M}{\\epsilon} = 1 + \\frac{4M}{\\epsilon}\n$$\n\n总的增长因子 $G$ 是这些值的最大值：\n$$\nG = \\max(G_1, G_2, G_3, G_4) = \\max\\left(1 + \\frac{4M}{\\epsilon}, 3, 3, 1\\right)\n$$\n我们代入给定的数值 $M = 10^8$ 和 $\\epsilon = 10^{-8}$：\n$$\nG_1 = 1 + \\frac{4 \\times 10^8}{10^{-8}} = 1 + 4 \\times 10^{16}\n$$\n显然，$1 + 4 \\times 10^{16}$ 远大于 $3$。因此，\n$$\nG = 1 + 4 \\times 10^{16} = 40,000,000,000,000,001\n$$\n问题要求答案四舍五入到四位有效数字。用科学记数法表示，该值为 $4.0000000000000001 \\times 10^{16}$。前四位有效数字是 $4$、$0$、$0$、$0$。第五位有效数字是 $0$，所以我们向下舍入（即，不改变第四位数字）。\n结果四舍五入到四位有效数字后是 $4.000 \\times 10^{16}$。",
            "answer": "$$\n\\boxed{4.000 \\times 10^{16}}\n$$"
        },
        {
            "introduction": "在解决了数值计算中的一个潜在陷阱后，我们转向一个强大的解决方案来处理更根本的难题：病态问题。Tikhonov 正则化是一种核心技术，通过向最小二乘目标函数中添加一个惩罚项来稳定解，特别适用于处理工程和科学中的逆问题。本练习  将指导你通过构造一个增广系统，并利用QR分解来稳健地实现这一正则化方法，这是计算科学工具箱中的一项基本技能。",
            "id": "2430326",
            "problem": "您需要实现一个程序，该程序使用基于正交-三角分解（也称为 QR 分解）的因式分解方法来计算 Tikhonov 正则化最小二乘解。该问题通过一个增广的超定系统来解决正则化最小二乘问题，从而处理病态或不适定的线性系统。\n\n起点与基本原理：对于给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$、数据向量 $b \\in \\mathbb{R}^{m}$ 以及正则化参数 $\\lambda \\ge 0$，正则化最小二乘问题旨在寻找一个向量 $x \\in \\mathbb{R}^{n}$，以最小化目标函数 $\\lVert A x - b \\rVert_2^2 + \\lambda^2 \\lVert x \\rVert_2^2$，其中 $\\lVert \\cdot \\rVert_2$ 表示欧几里得范数。通过考虑增广系统 $\\begin{pmatrix} A \\\\ \\lambda I \\end{pmatrix} x \\approx \\begin{pmatrix} b \\\\ 0 \\end{pmatrix}$，该问题可以被重新表述为一个标准的最小二乘问题，其中 $I \\in \\mathbb{R}^{n \\times n}$ 是单位矩阵，$0 \\in \\mathbb{R}^{n}$ 是零向量。\n\n您的任务是：\n1. 实现一个函数，该函数接收 $A$、$b$ 和 $\\lambda$ 作为输入，构造增广矩阵 $C = \\begin{pmatrix} A \\\\ \\lambda I \\end{pmatrix}$ 和增广右端项 $d = \\begin{pmatrix} b \\\\ 0 \\end{pmatrix}$，计算经济型 QR 分解 $C = Q R$（其中 $Q \\in \\mathbb{R}^{(m+n) \\times n}$ 具有标准正交列，$R \\in \\mathbb{R}^{n \\times n}$ 是上三角矩阵），然后通过回代法求解三角系统 $R x = Q^\\top d$ 以得到 $x$。不要构造或求解正规方程，也不要使用奇异值分解。\n2. 对于下面列出的每个测试用例，使用您基于 QR 的方法所获得的解 $x$，计算增广残差的欧几里得范数，其定义为 $\\lVert C x - d \\rVert_2 = \\left\\lVert \\begin{pmatrix} A \\\\ \\lambda I \\end{pmatrix} x - \\begin{pmatrix} b \\\\ 0 \\end{pmatrix} \\right\\rVert_2$。\n3. 生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的浮点数列表，每个浮点数四舍五入到六位小数，并按下面描述的测试用例顺序排列。\n\n算法约束：\n- 对增广系统应用正交-三角分解，然后对三角因子进行回代。利用正交性可以避免对条件数进行平方运算，而构造正规方程时会发生这种情况。\n\n测试套件：\n在以下四个确定性测试用例上实现并评估您的求解器。在下面的所有定义中，索引从 0 开始。\n\n- 测试用例 1（超定、不适定、非正则化）：\n  - 维度：$m = 30$， $n = 10$。\n  - 矩阵 $A \\in \\mathbb{R}^{30 \\times 10}$ 定义为 $A_{i,j} = \\dfrac{1}{i + j + 1}$，其中 $0 \\le i \\le 29$ 且 $0 \\le j \\le 9$。\n  - 真实向量 $x_{\\text{true}} \\in \\mathbb{R}^{10}$ 定义为 $(x_{\\text{true}})_j = 1$ （若 $j$ 为偶数）和 $(x_{\\text{true}})_j = -1$ （若 $j$ 为奇数），其中 $0 \\le j \\le 9$。\n  - 噪声向量 $\\varepsilon \\in \\mathbb{R}^{30}$ 定义为 $\\varepsilon_i = 10^{-4} \\cos(i)$，其中 $0 \\le i \\le 29$。\n  - 右端项 $b = A x_{\\text{true}} + \\varepsilon$。\n  - 正则化参数 $\\lambda = 0$。\n\n- 测试用例 2（与测试用例 1 系统相同，但进行正则化）：\n  - 使用与测试用例 1 中相同的 $A$、$x_{\\text{true}}$、$\\varepsilon$ 和 $b$。\n  - 正则化参数 $\\lambda = 10^{-2}$。\n\n- 测试用例 3（方阵、秩亏、精确数据、轻微正则化）：\n  - 维度：$m = 8$， $n = 6$。\n  - 按如下方式构造列向量 $c_k \\in \\mathbb{R}^{8}$：\n    - $c_0$ 是一个向量，其元素为 $c_{0,i} = 1 + \\dfrac{i}{7}$，其中 $0 \\le i \\le 7$。\n    - $c_1 = c_0$（重复列以确保秩亏）。\n    - $c_2$ 的元素为 $c_{2,i} = \\sin\\!\\left(\\dfrac{\\pi i}{7}\\right)$。\n    - $c_3$ 的元素为 $c_{3,i} = \\cos\\!\\left(\\dfrac{\\pi i}{3}\\right)$。\n    - $c_4 = c_2 + c_3$。\n    - $c_5$ 是一个常数向量，其所有元素均为 $1$。\n  - 构造 $A = [c_0\\, c_1\\, c_2\\, c_3\\, c_4\\, c_5] \\in \\mathbb{R}^{8 \\times 6}$。\n  - 定义 $x_{\\text{true}} \\in \\mathbb{R}^{6}$，其元素为 $(x_{\\text{true}})_j = [0.5, -0.5, 1.0, -1.0, 0.0, 2.0]_j$，其中 $0 \\le j \\le 5$。\n  - 右端项 $b = A x_{\\text{true}}$。\n  - 正则化参数 $\\lambda = 10^{-6}$。\n\n- 测试用例 4（欠定、含噪声、正则化）：\n  - 维度：$m = 5$， $n = 10$。\n  - 矩阵 $A \\in \\mathbb{R}^{5 \\times 10}$ 的元素为 $A_{i,j} = \\sin(i + j) + \\cos(2 i + 3 j)$，其中 $0 \\le i \\le 4$ 且 $0 \\le j \\le 9$，三角函数使用弧度作为参数。\n  - 真实向量 $x_{\\text{true}} \\in \\mathbb{R}^{10}$ 的元素为 $(x_{\\text{true}})_j = \\sin(j)$，其中 $0 \\le j \\le 9$。\n  - 噪声向量 $\\varepsilon \\in \\mathbb{R}^{5}$ 的元素为 $\\varepsilon_i = 10^{-5} \\sin(i)$，其中 $0 \\le i \\le 4$。\n  - 右端项 $b = A x_{\\text{true}} + \\varepsilon$。\n  - 正则化参数 $\\lambda = 10^{-1}$。\n\n输出规范：\n- 对于每个测试用例 $k \\in \\{1,2,3,4\\}$，使用您基于 QR 的解 $x$ 计算标量 $r_k = \\left\\lVert \\begin{pmatrix} A \\\\ \\lambda I \\end{pmatrix} x - \\begin{pmatrix} b \\\\ 0 \\end{pmatrix} \\right\\rVert_2$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的列表，其顺序为 $[r_1, r_2, r_3, r_4]$，每个 $r_k$ 四舍五入到六位小数，例如 $[0.123456,0.234567,0.345678,0.456789]$。\n\n角度单位：\n- 所有三角函数均使用弧度作为参数。\n\n此问题不涉及物理单位。\n\n您的实现必须是完全确定性的，并且不得依赖于用户输入或外部数据。程序必须是一个完整的、可运行的脚本，且只打印所需的输出行。",
            "solution": "所提出的问题是有效且适定的。它解决了计算科学中的一个基本任务：使用 Tikhonov 正则化来稳定求解不适定或欠定的线性系统。所指定的方法依赖于对增广系统进行正交-三角（$QR$）分解，这是一种标准且数值稳健的技术。\n\n目标是找到一个向量 $x \\in \\mathbb{R}^{n}$，以最小化 Tikhonov 正则化目标函数：\n$$ \\underset{x}{\\text{minimize}} \\quad \\lVert A x - b \\rVert_2^2 + \\lambda^2 \\lVert x \\rVert_2^2 $$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 是系统矩阵，$b \\in \\mathbb{R}^{m}$ 是数据向量，$\\lambda \\ge 0$ 是正则化参数。项 $\\lambda^2 \\lVert x \\rVert_2^2$ 对大范数的解进行惩罚，这对于在 $A$ 不适定或秩亏时稳定问题至关重要。\n\n该目标函数可以表示为单个向量的欧几里得范数的平方，从而将问题转化为标准的线性最小二乘形式。我们构造一个增广矩阵 $C \\in \\mathbb{R}^{(m+n) \\times n}$ 和一个增广向量 $d \\in \\mathbb{R}^{m+n}$：\n$$ C = \\begin{pmatrix} A \\\\ \\lambda I \\end{pmatrix}, \\quad d = \\begin{pmatrix} b \\\\ 0 \\end{pmatrix} $$\n在这里，$I$ 是 $n \\times n$ 的单位矩阵，$0$ 是 $\\mathbb{R}^{n}$ 中的零向量。原始的最小化问题等价于：\n$$ \\underset{x}{\\text{minimize}} \\quad \\left\\lVert \\begin{pmatrix} A \\\\ \\lambda I \\end{pmatrix} x - \\begin{pmatrix} b \\\\ 0 \\end{pmatrix} \\right\\rVert_2^2 = \\underset{x}{\\text{minimize}} \\quad \\lVert C x - d \\rVert_2^2 $$\n该最小二乘问题的解 $x$ 满足正规方程：\n$$ C^\\top C x = C^\\top d $$\n然而，问题描述正确地禁止了显式构造矩阵 $C^\\top C$。这是因为 $C^\\top C$ 的条件数是 $C$ 的条件数的平方，即 $\\kappa(C^\\top C) = \\kappa(C)^2$。因此，构造正规方程可能会引入不必要的数值不稳定性，尤其对于不适定系统。\n\n一种数值上更优越的方法是使用 $C$ 的正交-三角分解。我们计算增广矩阵 $C$ 的经济型 $QR$ 分解：\n$$ C = QR $$\n其中 $Q \\in \\mathbb{R}^{(m+n) \\times n}$ 是一个具有标准正交列的矩阵（即 $Q^\\top Q = I_n$），$R \\in \\mathbb{R}^{n \\times n}$ 是一个上三角矩阵。\n\n将 $C = QR$ 代入最小二乘问题，我们寻求最小化 $\\lVert QRx - d \\rVert_2$。由于 $Q$ 具有标准正交列，乘以 $Q^\\top$ 会保持 $Q$ 的列空间中残差分量的欧几里得范数。通过求解变换后的系统找到解 $x$。代入正规方程可得：\n$$ (QR)^\\top (QR) x = (QR)^\\top d $$\n$$ R^\\top Q^\\top Q R x = R^\\top Q^\\top d $$\n$$ R^\\top R x = R^\\top Q^\\top d $$\n为使问题有唯一解，矩阵 $R$ 必须是可逆的。如果 $\\lambda  0$，即使 $A$ 不是满列秩的，矩阵 $C$ 也保证是满列秩的。这是因为对应于 $\\lambda I$ 的行确保了 $C$ 的列的线性无关性。因此，上三角矩阵 $R$ 将是满秩的，从而也是可逆的。如果 $\\lambda = 0$ 且 $A$ 是满列秩的，$R$ 也是可逆的。在这些情况下，我们可以乘以 $(R^\\top)^{-1}$ 来获得上三角系统：\n$$ R x = Q^\\top d $$\n该系统可以通过回代法高效地求解出 $x$。\n\n计算出解向量 $x$ 后，最后一步是按要求计算增广残差的欧几里得范数。这可以直接计算：\n$$ r = \\lVert C x - d \\rVert_2 = \\left\\lVert \\begin{pmatrix} A \\\\ \\lambda I \\end{pmatrix} x - \\begin{pmatrix} b \\\\ 0 \\end{pmatrix} \\right\\rVert_2 $$\n此过程将应用于四个指定的测试用例中的每一个。每个用例的矩阵和向量的构造都严格按照问题描述中的定义执行。最终输出由计算出的残差范数组成。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_triangular\n\ndef solve_regularized_ls_qr(A, b, lam):\n    \"\"\"\n    Solves the Tikhonov-regularized least squares problem min ||Ax-b||^2 + lam^2||x||^2\n    using QR factorization of the augmented system.\n\n    Args:\n        A (np.ndarray): The matrix A of shape (m, n).\n        b (np.ndarray): The vector b of shape (m,).\n        lam (float): The regularization parameter lambda.\n\n    Returns:\n        float: The Euclidean norm of the augmented residual, ||Cx - d||_2.\n    \"\"\"\n    m, n = A.shape\n\n    # 1. Construct the augmented matrix C and augmented vector d.\n    if lam > 0:\n        C = np.vstack((A, lam * np.eye(n)))\n    else:\n        # Handle lambda = 0 case to avoid creating a zero matrix and then multiplying\n        C = np.vstack((A, np.zeros((n, n))))\n        \n    d = np.hstack((b, np.zeros(n)))\n\n    # 2. Compute the economy-size QR factorization of C.\n    Q, R = np.linalg.qr(C, mode='reduced')\n\n    # 3. Solve the upper triangular system Rx = Q^T d by back substitution.\n    qT_d = Q.T @ d\n    # SciPy's solver is efficient for this.\n    x = solve_triangular(R, qT_d, check_finite=False)\n\n    # 4. Compute the Euclidean norm of the augmented residual.\n    residual_norm = np.linalg.norm(C @ x - d)\n    \n    return residual_norm\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = []\n\n    # Test case 1: overdetermined, ill-conditioned, unregularized\n    m1, n1 = 30, 10\n    lam1 = 0.0\n    i1 = np.arange(m1)[:, np.newaxis]\n    j1 = np.arange(n1)\n    A1 = 1.0 / (i1 + j1 + 1)\n    x_true1 = np.array([(-1)**k for k in range(n1)])\n    epsilon1 = 1e-4 * np.cos(np.arange(m1))\n    b1 = A1 @ x_true1 + epsilon1\n    test_cases.append({'A': A1, 'b': b1, 'lam': lam1})\n\n    # Test case 2: same system as test case 1 but with regularization\n    lam2 = 1e-2\n    test_cases.append({'A': A1, 'b': b1, 'lam': lam2})\n\n    # Test case 3: square, rank-deficient, exact data, slight regularization\n    m3, n3 = 8, 6\n    lam3 = 1e-6\n    i3 = np.arange(m3)\n    c0 = 1 + i3 / 7.0\n    c1 = c0\n    c2 = np.sin(np.pi * i3 / 7.0)\n    c3 = np.cos(np.pi * i3 / 3.0)\n    c4 = c2 + c3\n    c5 = np.ones(m3)\n    A3 = np.column_stack([c0, c1, c2, c3, c4, c5])\n    x_true3 = np.array([0.5, -0.5, 1.0, -1.0, 0.0, 2.0])\n    b3 = A3 @ x_true3\n    test_cases.append({'A': A3, 'b': b3, 'lam': lam3})\n\n    # Test case 4: underdetermined, noisy, regularized\n    m4, n4 = 5, 10\n    lam4 = 1e-1\n    i4 = np.arange(m4)[:, np.newaxis]\n    j4 = np.arange(n4)\n    A4 = np.sin(i4 + j4) + np.cos(2 * i4 + 3 * j4)\n    x_true4 = np.sin(np.arange(n4))\n    epsilon4 = 1e-5 * np.sin(np.arange(m4))\n    b4 = A4 @ x_true4 + epsilon4\n    test_cases.append({'A': A4, 'b': b4, 'lam': lam4})\n\n    results = []\n    for case in test_cases:\n        residual = solve_regularized_ls_qr(case['A'], case['b'], case['lam'])\n        results.append(residual)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "最后，我们将把所学技能应用于一个实际的数据科学问题：时间序列分析中的自回归（AR）模型拟合。从原始时间序列数据构建模型矩阵本身就可能产生近乎奇异的（或称病态的）系统，这对数值方法的鲁棒性提出了挑战。此练习  采用了带列主元的QR分解，这是一种能够自动检测和处理数据中潜在共线性的先进技术，从而为模型参数提供稳定且有意义的估计。",
            "id": "2430292",
            "problem": "给定时间序列数据，要求您使用基于带列主元的正交三角 (QR) 分解的数值稳定的线性最小二乘公式来拟合一个自回归 (AR) 模型。该模型是 $p$ 阶自回归 (AR) 模型，定义为\n$$\nx_t \\;=\\; \\sum_{i=1}^{p} \\phi_i \\, x_{t-i} \\;+\\; \\varepsilon_t,\n$$\n其中 $x_t$ 是观测到的标量时间序列，$\\phi_i$ 是待估计的 AR 系数，$\\varepsilon_t$ 是一个未观测到的扰动项。\n\n基本出发点：\n- 最小二乘估计最小化残差平方和\n$$\n\\min_{\\phi \\in \\mathbb{R}^p} \\;\\left\\| H \\, \\phi - y \\right\\|_2^2,\n$$\n其中 $H$ 是滞后观测值的数据矩阵，$y$ 是当前观测值的向量。具体来说，对于一个序列 $\\{x_1,\\dots,x_N\\}$ 和阶数 $p$，定义 $m = N - p$，那么对于每个 $t \\in \\{p+1,\\dots,N\\}$，$H \\in \\mathbb{R}^{m \\times p}$ 的第 $t-p$ 行是 $[x_{t-1}, x_{t-2}, \\dots, x_{t-p}]$，而 $y \\in \\mathbb{R}^{m}$ 的相应条目是 $x_t$。\n- 带列主元的正交三角 (QR) 分解是解决最小二乘问题（包括秩亏情况）的一种经过充分检验且数值稳定的方法。如果 $H \\, P = Q \\, R$，其中 $Q$ 是标准正交的，$R$ 是上三角的，而 $P$ 是一个列置换，那么在秩亏情况下，具有最小欧几里得范数的最小二乘解可以通过截断至数值秩来获得。\n\n您的任务是编写一个完整的程序，该程序：\n1. 根据上述描述，从每个给定的时间序列 $\\{x_t\\}$ 和 AR 阶数 $p$ 构建 $H$ 和 $y$。\n2. 使用带列主元的 QR 分解计算最小二乘 AR 系数向量 $\\hat{\\phi}$。通过容差确定数值秩 $r$\n$$\n\\tau \\;=\\; \\max(m,p)\\, \\epsilon \\, |R_{11}|,\n$$\n其中 $\\epsilon$ 是双精度机器ε，$R_{11}$ 是 $R$ 的左上角元素。如果 $|R_{11}| = 0$，则取 $r = 0$。如果 $r  0$，令 $R_1 \\in \\mathbb{R}^{r \\times r}$ 为前导三角块，$Q_1 \\in \\mathbb{R}^{m \\times r}$ 为对应的标准正交列；则最小范数解为\n$$\n\\hat{z}_1 \\;=\\; R_1^{-1} \\, Q_1^\\top \\, y, \n\\quad\n\\hat{z}_2 \\;=\\; 0 \\in \\mathbb{R}^{p-r},\n\\quad\n\\hat{z} \\;=\\; \\begin{bmatrix}\\hat{z}_1 \\\\ \\hat{z}_2\\end{bmatrix},\n\\quad\n\\hat{\\phi} \\;=\\; P \\, \\hat{z}.\n$$\n如果 $r = 0$，则设 $\\hat{\\phi} = 0 \\in \\mathbb{R}^p$。\n3. 对于每个测试用例，输出估计的系数向量 $\\hat{\\phi}$，每个分量四舍五入到六位小数。\n\n测试套件：\n- 测试用例 1（一般良态情况，2 阶精确 AR）：\n  - 阶数：$p = 2$。\n  - 时间序列 $\\{x_t\\}_{t=1}^{7}$: $[100.0, 110.0, 80.0, 67.5, 53.75, 43.75, 35.3125]$。\n- 测试用例 2（$p = 1$ 的最小样本边界情况）：\n  - 阶数：$p = 1$。\n  - 时间序列 $\\{x_t\\}_{t=1}^{2}$: $[100.0, 102.0]$。\n- 测试用例 3（$p = 2$ 的近乎秩亏设计，几何增长）：\n  - 阶数：$p = 2$。\n  - 时间序列 $\\{x_t\\}_{t=1}^{8}$: $[100.0, 102.0, 104.04, 106.1208, 108.243216, 110.40808032, 112.6162419264, 114.868566764928]$。\n- 测试用例 4（过参数化模型 $p = 3$ 拟合精确一阶动态，秩亏）：\n  - 阶数：$p = 3$。\n  - 时间序列 $\\{x_t\\}_{t=1}^{8}$: $[100.0, 50.0, 25.0, 12.5, 6.25, 3.125, 1.5625, 0.78125]$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含四个测试用例的系数向量，形式为用方括号括起来的逗号分隔列表。每个系数向量本身必须是一个带括号的、逗号分隔的列表，其中每个浮点数条目四舍五入到六位小数。例如：\n$$\n[\\,[\\phi^{(1)}_1,\\dots,\\phi^{(1)}_{p_1}],\\,[\\phi^{(2)}_1,\\dots],\\,[\\phi^{(3)}_1,\\dots],\\,[\\phi^{(4)}_1,\\dots]\\,].\n$$\n- 具体来说，程序必须精确打印一行，其格式为\n$$\n[\\,[\\cdot,\\cdot],\\,[\\cdot],\\,[\\cdot,\\cdot],\\,[\\cdot,\\cdot,\\cdot]\\,],\n$$\n数字或括号之间没有空格，每个数字格式化为六位小数。",
            "solution": "该问题要求估计一个 $p$ 阶自回归 (AR) 模型的系数，该模型指定为\n$$\nx_t = \\sum_{i=1}^{p} \\phi_i x_{t-i} + \\varepsilon_t\n$$\n其中 $\\{x_t\\}$ 是一个时间序列，$\\phi = [\\phi_1, \\dots, \\phi_p]^\\top$ 是待确定的系数向量，$\\varepsilon_t$ 是一个随机扰动项。该估计被表述为一个线性最小二乘问题，必须使用带列主元的 QR 分解来求解，以确保数值稳定性。\n\n首先，我们将问题形式化。给定一个长度为 $N$ 的时间序列 $\\{x_1, \\dots, x_N\\}$ 和一个 AR 阶数 $p$，我们构建一个线性系统。令 $m = N - p$。如果 $m \\le 0$，则没有足够的数据来构建该问题；所有提供的测试用例都满足 $m  0$。我们定义一个响应向量 $y \\in \\mathbb{R}^m$ 和一个数据矩阵 $H \\in \\mathbb{R}^{m \\times p}$。向量 $y$ 由待预测的观测值组成，矩阵 $H$ 包含用作预测变量的滞后观测值。\n$$\ny = \\begin{bmatrix} x_{p+1} \\\\ x_{p+2} \\\\ \\vdots \\\\ x_N \\end{bmatrix}, \\quad\nH = \\begin{bmatrix}\nx_p  x_{p-1}  \\cdots  x_1 \\\\\nx_{p+1}  x_p  \\cdots  x_2 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\nx_{N-1}  x_{N-2}  \\cdots  x_{N-p}\n\\end{bmatrix}\n$$\nAR 模型可以表示为矩阵形式 $y \\approx H\\phi$。最小二乘估计 $\\hat{\\phi}$ 是最小化残差平方和的向量，也就是残差向量的欧几里得范数的平方：\n$$\n\\hat{\\phi} = \\arg\\min_{\\phi \\in \\mathbb{R}^p} \\| H\\phi - y \\|_2^2\n$$\n解决这个问题的一个常用方法是通过正规方程 $H^\\top H \\phi = H^\\top y$。然而，这在数值上是不明智的。$H^\\top H$ 的条件数是 $H$ 条件数的平方，即 $\\kappa(H^\\top H) = \\kappa(H)^2$。如果 $H$ 是病态的，$H^\\top H$ 将会更加病态，导致由于浮点运算而在计算解中产生巨大误差。\n\n一种数值上更优的方法是使用 $H$ 的正交分解。本问题指定了带列主元的 QR 分解。该方法计算分解 $HP = QR$，其中 $P$ 是一个 $p \\times p$ 的置换矩阵，$Q$ 是一个 $m \\times m$ 的正交矩阵（其列是标准正交的，$Q^\\top Q=I$），$R$ 是一个 $m \\times p$ 的上梯形矩阵。选择置换矩阵 $P$ 是为了确保 $R$ 的对角元素的绝对值非递增，这对于可靠地确定 $H$ 的数值秩至关重要。\n\n将 $H = QRP^{-1}$ 代入目标函数，并利用欧几里得范数在正交变换下不变的性质（即 $\\|Qz\\|_2 = \\|z\\|_2$），我们得到：\n$$\n\\| H\\phi - y \\|_2^2 = \\| QRP^{-1}\\phi - y \\|_2^2 = \\| Q(RP^{-1}\\phi - Q^\\top y) \\|_2^2 = \\| RP^{-1}\\phi - Q^\\top y \\|_2^2\n$$\n令 $z = P^{-1}\\phi$，这意味着 $\\phi = Pz$。向量 $z$ 代表与 $H$ 的置换列相对应的系数。问题就变成了最小化 $\\|Rz - Q^\\top y\\|_2^2$。\n\n矩阵 $H$ 可能是秩亏的或接近秩亏，特别是当底层时间序列表现出强烈的趋势或周期性时，会导致 $H$ 的列（即滞后观测向量）几乎线性相关。带列主元的 QR 分解对这种情况具有鲁棒性。我们通过检查 $R$ 的对角元素来确定 $H$ 的数值秩 $r$。使用一个容差 $\\tau = \\max(m,p) \\cdot \\epsilon \\cdot |R_{11}|$，其中 $\\epsilon$ 是机器ε。秩 $r$ 是满足 $|R_{ii}|  \\tau$ 的对角元素 $|R_{ii}|$ 的数量。如果 $|R_{11}|=0$，则矩阵为零，因此 $r=0$。\n\n根据秩 $r$，我们将 $R$、$z$ 和 $c = Q^\\top y$ 进行分块：\n$$\nR = \\begin{bmatrix} R_{11}  R_{12} \\\\ 0  R_{22} \\end{bmatrix}, \\quad z = \\begin{bmatrix} z_1 \\\\ z_2 \\end{bmatrix}, \\quad c = Q^\\top y = \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix}\n$$\n这里，$R_{11}$ 是一个 $r \\times r$ 的对角元素非零的上三角矩阵，$z_1 \\in \\mathbb{R}^r$，$c_1 \\in \\mathbb{R}^r$。需要最小化的范数变为：\n$$\n\\| Rz - c \\|_2^2 = \\| R_{11}z_1 + R_{12}z_2 - c_1 \\|_2^2 + \\| R_{22}z_2 - c_2 \\|_2^2\n$$\n $(m-r) \\times (p-r)$ 块 $R_{22}$ 的对角元素在数值上为零（小于或等于 $\\tau$）。对于最小范数解，我们设置 $z_2 = 0 \\in \\mathbb{R}^{p-r}$。这个选择消除了最不确定分量的贡献。问题简化为求解 $z_1$ 的满秩上三角系统：\n$$\nR_{11} z_1 = c_1\n$$\n这个系统可以通过回代法高效求解。置换后系数的最终解是 $\\hat{z} = [\\hat{z}_1^\\top, 0, \\dots, 0]^\\top \\in \\mathbb{R}^p$。\n\n最后，通过应用置换 $P$ 来恢复原始、未置换模型的系数向量 $\\hat{\\phi}$。如果来自 QR 例程的置换索引是 `piv`，使得 `H_perm = H[:, piv]`，那么系数之间的关系是 $\\hat{\\phi}_{\\text{piv}[k]} = \\hat{z}_k$。\n在数值秩 $r=0$ 的边缘情况下（例如，$H$ 是一个零矩阵），最小范数解就是 $\\hat{\\phi}=0$。\n\n总体算法如下：\n1. 从时间序列 $\\{x_t\\}$ 和阶数 $p$ 出发，构造矩阵 $H$ 和向量 $y$。\n2. 计算带列主元的 QR 分解：$H P = Q R$。大多数数值库会返回 $Q$、$R$ 和一个置换索引向量。\n3. 使用指定的容差 $\\tau$ 确定数值秩 $r$。\n4. 如果 $r=0$，设置 $\\hat{\\phi}=0$。\n5. 如果 $r0$，求解 $r \\times r$ 的三角系统 $R_{1:r, 1:r} \\, \\hat{z}_{1:r} = (Q^\\top y)_{1:r}$ 以得到 $\\hat{z}_{1:r}$。\n6. 通过用 $p-r$ 个零填充 $\\hat{z}_{1:r}$ 来构造 $\\hat{z} \\in \\mathbb{R}^p$。\n7. 对 $\\hat{z}$ 应用逆置换以获得最终的系数向量 $\\hat{\\phi}$。\n这个过程产生了一个鲁棒且数值稳定的 AR 系数估计，并在秩亏情况下提供了唯一的最小范数解。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import qr, solve_triangular\n\ndef solve():\n    \"\"\"\n    Main function to solve the autoregressive model fitting problem\n    for all test cases as specified.\n    \"\"\"\n\n    # Test cases as defined in the problem description.\n    test_cases = [\n        # (order p, time series x_t)\n        (2, [100.0, 110.0, 80.0, 67.5, 53.75, 43.75, 35.3125]),\n        (1, [100.0, 102.0]),\n        (2, [100.0, 102.0, 104.04, 106.1208, 108.243216, 110.40808032, 112.6162419264, 114.868566764928]),\n        (3, [100.0, 50.0, 25.0, 12.5, 6.25, 3.125, 1.5625, 0.78125]),\n    ]\n\n    results = []\n    for p, x_ts in test_cases:\n        phi_hat = estimate_ar_coeffs(np.array(x_ts, dtype=float), p)\n        results.append(phi_hat)\n\n    # Format the final output string as required.\n    # e.g., [[c1,c2],[c1],[c1,c2],[c1,c2,c3]]\n    # with 6 decimal places and no spaces.\n    output_parts = []\n    for res in results:\n        formatted_coeffs = \",\".join([f\"{c:.6f}\" for c in res])\n        output_parts.append(f\"[{formatted_coeffs}]\")\n    \n    final_output = f\"[{','.join(output_parts)}]\"\n    print(final_output)\n\ndef estimate_ar_coeffs(x, p):\n    \"\"\"\n    Estimates AR(p) coefficients for a time series x using QR factorization\n    with column pivoting.\n\n    Args:\n        x (np.ndarray): The time series data.\n        p (int): The order of the autoregressive model.\n\n    Returns:\n        np.ndarray: The estimated AR coefficients phi_hat.\n    \"\"\"\n    N = len(x)\n    m = N - p\n\n    if m = 0:\n        # Not enough data points to form the least squares problem.\n        # This case is not in the test suite but is a necessary check.\n        return np.zeros(p)\n\n    # 1. Construct the Hankel matrix H and response vector y.\n    # H is m x p, y is m x 1\n    H = np.zeros((m, p))\n    y = x[p:]\n    \n    for i in range(m):\n        # The i-th row of H corresponds to predicting x_{p+i+1}\n        # using [x_{p+i}, x_{p+i-1}, ..., x_{i+1}]\n        # In array indexing, this is y[i] from x[p+i-1:i-1:-1]\n        H[i, :] = x[i:i+p][::-1]\n\n    # 2. Compute QR factorization with column pivoting: H P = Q R\n    Q, R, piv = qr(H, pivoting=True)\n    \n    # 3. Determine numerical rank r.\n    m, p_eff = H.shape\n    eps = np.finfo(float).eps\n    \n    # Check for the case where H is the zero matrix.\n    if np.abs(R[0, 0]) == 0:\n        r = 0\n    else:\n        tau = np.max(H.shape) * eps * np.abs(R[0, 0])\n        diag_R = np.abs(np.diag(R))\n        r = np.sum(diag_R > tau)\n    \n    if r == 0:\n        # If rank is 0, the minimal norm solution is phi_hat = 0.\n        return np.zeros(p)\n\n    # 4. Solve the least squares problem using the factorization.\n    # We want to solve H * phi = y, which is (Q R P^T) * phi = y\n    # Let z = P^T * phi. Then Q R z = y, or R z = Q^T y.\n    # Scipy's output `piv` is such that H[:,piv] = Q @ R.\n    # We solve for z in (H[:,piv]) @ z = y.\n    # The coefficients are then `phi[piv] = z`.\n\n    # Calculate c = Q^T * y\n    c = Q.T @ y\n\n    # 5. Solve the upper triangular system for the first r components of z.\n    # R_sub @ z_sub = c_sub\n    R1 = R[:r, :r]\n    c1 = c[:r]\n    z_hat_r = solve_triangular(R1, c1, lower=False)\n\n    # 6. Construct full z_hat vector with zeros for components beyond rank r.\n    z_hat = np.zeros(p)\n    z_hat[:r] = z_hat_r\n    \n    # 7. Apply inverse permutation to get phi_hat.\n    # The `piv` array maps new column index `j` to old column index `piv[j]`.\n    # z_hat[j] is the coefficient for old column `piv[j]`.\n    # So, phi_hat[piv[j]] = z_hat[j]\n    phi_hat = np.zeros(p)\n    phi_hat[piv] = z_hat\n        \n    return phi_hat\n\nsolve()\n```"
        }
    ]
}