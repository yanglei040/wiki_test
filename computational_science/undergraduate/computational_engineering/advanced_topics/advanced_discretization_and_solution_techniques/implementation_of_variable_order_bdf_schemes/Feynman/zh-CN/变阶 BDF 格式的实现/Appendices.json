{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握可变阶BDF格式，最好的方法莫过于亲手从零开始构建一个求解器。本实践将指导你完成这一过程，你需要从多项式插值的基本原理出发，推导出不同阶数的BDF公式。 这项练习不仅能让你实现一个实用的阶数自适应选择策略，还能通过一个精巧的设计，让你深入探究数值计算中截断误差与舍入误差的来源及其影响，从而全面理解现代自适应求解器的核心机制。",
            "id": "2401859",
            "problem": "请为标量线性初值问题 $y'(t)=\\lambda\\,y(t)+s(t)$ 在步长为 $h$ 的均匀网格上，实现一个可变阶向后差分公式 (BDF) 时间积分器。该数值方法必须基于向后有限差分和多项式插值的定义，并且必须遵守以下约束。\n\n- 精度/稳定性基础：从初值问题的核心定义以及用一个在均匀网格上插值 $k$ 个先前点的多项式来逼近 $y(t)$ 的概念出发。使用导数的定义和多项式精确性，推导出一个 $k$ 阶的隐式线性多步法规则（即 $k$ 阶 BDF 方法）。在推导过程中，不得从任何预先给定的 BDF 公式开始。\n- 可变阶：在每一步 $t_{n+1}=t_n+h$，仅使用当前均匀历史数据 $\\{y_n,y_{n-1},\\dots\\}$ 来选择一个阶数 $k\\in\\{1,2,3,4,5\\}$，具体方法如下。对于每个可用的 $k$（受历史数据长度限制），通过求解为 $y_{n+1}$ 产生的单个隐式线性方程，计算出 $k$ 阶 BDF 预测值 $y_{n+1}^{(k)}$。对于 $k\\ge 2$，定义一个局部截断误差代理 $e_k=\\lvert y_{n+1}^{(k)}-y_{n+1}^{(k-1)}\\rvert$。在可用的 $k$ 中选择使 $e_k$ 最小化的阶数，但要约束所选阶数相对于上一步使用的阶数变化最多为 $\\pm 1$。当只有 $k=1$ 可用时，则使用 $k=1$。\n- 每步线性求解：由于 $f(t,y)=\\lambda\\,y+s(t)$ 对 $y$ 是线性的，因此 $k$ 阶隐式 BDF 步长必须简化为求解 $y_{n+1}$ 的单个线性方程，其分母为标量。不允许也不需要非线性迭代。\n- 有理系数：将每个 BDF 系数（对于每个阶数 $k\\in\\{1,2,3,4,5\\}$）存储为精确的有理数。您的程序必须执行两种不同的运行：\n  1. 一个“有理系数”运行，该运行使用这些在运行时转换为标准浮点数的精确有理数（系数不预先舍入到有限的小数位数）。\n  2. 一个“浮点系数”运行，该运行首先将每个有理系数舍入为单精度浮点数（将每个有理数转换为一个 $32$ 位浮点数），然后使用这些舍入后的系数进行计算（在算术运算中它们可能会被提升到标准精度，但它们的值必须是单精度舍入后的值）。\n- 最终时间 $T$ 处的误差分解目标：定义\n  - 步长为 $h$ 时的舍入误差代理为 $E_{\\mathrm{round}}(h)=\\lvert y^{\\mathrm{float\\text{-}coef}}(T;h)-y^{\\mathrm{rational\\text{-}coef}}(T;h)\\rvert$。\n  - 步长为 $h$ 时的截断误差代理为 $E_{\\mathrm{trunc}}(h)=\\lvert y^{\\mathrm{rational\\text{-}coef}}(T;h)-y^{\\mathrm{rational\\text{-}coef}}(T;h/2)\\rvert$。\n- 角度单位：当源项为余弦函数 $s(t)=\\cos(t)$ 时，角度必须以弧度为单位进行解释。\n\n实现求解器，并为下面测试套件中的每个测试用例计算 $E_{\\mathrm{round}}(h)$ 和 $E_{\\mathrm{trunc}}(h)$。假设 $t_0=0$ 且步长是均匀的。在所有情况下，最终时间 $T$ 都能被 $h$ 和 $h/2$ 整除。\n\n测试套件：\n- 用例 A（理想情况，中等刚性衰减）：$\\lambda=-1$，$s(t)\\equiv 0$，$y(0)=1$，$T=10$，$h=0.1$。\n- 用例 B（更强的刚性衰减）：$\\lambda=-50$，$s(t)\\equiv 0$，$y(0)=1$，$T=1$，$h=0.02$。\n- 用例 C（受迫衰减）：$\\lambda=-5$，$s(t)=\\cos(t)$，$t$ 以弧度为单位，$y(0)=0$，$T=10$，$h=0.1$。\n\n程序要求：\n- 使用上述过程实现一个最大阶数为 $5$ 的可变阶 BDF。\n- 将所有 BDF 系数存储为精确有理数，并从这些有理数生成两种系数集（运行时使用的有理数和单精度舍入的有理数）。\n- 对于每个用例，计算上面定义的对 $(E_{\\mathrm{round}}(h), E_{\\mathrm{trunc}}(h))$。\n\n最终输出格式：\n您的程序应该生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为\n$[E_{\\mathrm{round}}^{(A)},E_{\\mathrm{trunc}}^{(A)},E_{\\mathrm{round}}^{(B)},E_{\\mathrm{trunc}}^{(B)},E_{\\mathrm{round}}^{(C)},E_{\\mathrm{trunc}}^{(C)}]$，\n其中每个条目都是一个浮点数。例如，一个语法正确的输出看起来像 $[0.0,1.0,2.5,3.75,4.0,6.25]$。",
            "solution": "该问题要求为标量线性常微分方程(ODE) $y'(t) = \\lambda y(t) + s(t)$ 实现一个可变阶向后差分公式 (BDF) 求解器。这是一个计算科学中的适定问题。首先，我们必须按规定从基本原理推导 $k$ 阶 BDF 方法。\n\n**1. BDF-k 公式的推导**\n\n一个 $k$ 阶 BDF 方法通过对一个 $k$ 次多项式 $P(t)$ 求导来逼近导数 $y'(t_{n+1})$，该多项式插值了最近的 $k+1$ 个解点：$(t_{n+1}, y_{n+1}), (t_n, y_n), \\dots, (t_{n+1-k}, y_{n+1-k})$。对于均匀步长 $h$，我们有 $t_j = jh$。那么近似就是 $y'(t_{n+1}) \\approx P'(t_{n+1})$。\n\n一种推导这些系数的系统方法是使用向后差分。一个函数 $g$ 在点 $x$ 处的导数可以用它在该点的向后差分表示，公式如下：\n$$g'(x) = \\frac{1}{h} \\sum_{j=1}^{\\infty} \\frac{\\nabla^j g(x)}{j}$$\n其中 $\\nabla$ 是向后差分算子，$\\nabla g(x) = g(x) - g(x-h)$。将此级数在 $j=k$ 处截断，得到一个 $k$ 阶近似。将此方法应用于我们的数值解序列 $\\{y_i\\}$，我们将 $y'(t_{n+1})$ 近似为：\n$$y'(t_{n+1}) \\approx \\frac{1}{h} \\sum_{j=1}^{k} \\frac{1}{j} \\nabla^j y_{n+1}$$\n这里，$\\nabla^j y_{n+1}$ 是使用点 $y_{n+1}, y_n, \\dots$ 的 $j$ 阶向后差分。将此代入常微分方程 $y'(t_{n+1})=\\lambda y_{n+1}+s(t_{n+1})$，我们得到 BDF-k 公式：\n$$\\frac{1}{h} \\sum_{j=1}^{k} \\frac{1}{j} \\nabla^j y_{n+1} = \\lambda y_{n+1} + s(t_{n+1})$$\n让我们为 $k=1, \\dots, 5$ 展开这个公式。向后差分算子定义为 $\\nabla y_i = y_i - y_{i-1}$，且 $\\nabla^j y_i = \\nabla(\\nabla^{j-1} y_i)$。\n\n对于 $k=1$：\n$$ \\frac{1}{h} \\nabla y_{n+1} = \\frac{1}{h}(y_{n+1} - y_n) = \\lambda y_{n+1} + s_{n+1} $$\n$$ \\implies y_{n+1} - y_n = h(\\lambda y_{n+1} + s_{n+1}) $$\n\n对于 $k=2$：\n$$ \\frac{1}{h} \\left(\\nabla y_{n+1} + \\frac{1}{2}\\nabla^2 y_{n+1}\\right) = \\lambda y_{n+1} + s_{n+1} $$\n$$ \\nabla^2 y_{n+1} = (y_{n+1} - y_n) - (y_n - y_{n-1}) = y_{n+1} - 2y_n + y_{n-1} $$\n$$ \\implies (y_{n+1} - y_n) + \\frac{1}{2}(y_{n+1} - 2y_n + y_{n-1}) = h(\\lambda y_{n+1} + s_{n+1}) $$\n$$ \\implies \\frac{3}{2}y_{n+1} - 2y_n + \\frac{1}{2}y_{n-1} = h(\\lambda y_{n+1} + s_{n+1}) $$\n\n继续这个过程，我们可以将 BDF-k 方法表示为通用形式：\n$$\\sum_{i=0}^{k} c_{k,i} y_{n+1-i} = h(\\lambda y_{n+1} + s_{n+1})$$\n系数 $c_{k,i}$ 是有理数。它们的推导如下：\n- 对于 $k=1$： $\\{c_{1,0}, c_{1,1}\\} = \\{1, -1\\}$\n- 对于 $k=2$： $\\{c_{2,0}, c_{2,1}, c_{2,2}\\} = \\{\\frac{3}{2}, -2, \\frac{1}{2}\\}$\n- 对于 $k=3$： $\\{c_{3,0}, \\dots, c_{3,3}\\} = \\{\\frac{11}{6}, -3, \\frac{3}{2}, -\\frac{1}{3}\\}$\n- 对于 $k=4$： $\\{c_{4,0}, \\dots, c_{4,4}\\} = \\{\\frac{25}{12}, -4, 3, -\\frac{4}{3}, \\frac{1}{4}\\}$\n- 对于 $k=5$： $\\{c_{5,0}, \\dots, c_{5,5}\\} = \\{\\frac{137}{60}, -5, 5, -\\frac{10}{3}, \\frac{5}{4}, -\\frac{1}{5}\\}$\n\n**2. 求解 $y_{n+1}$**\n\nBDF 公式是隐式的。对于给定的线性常微分方程，我们可以用代数方法解出 $y_{n+1}$。\n$$c_{k,0} y_{n+1} + \\sum_{i=1}^{k} c_{k,i} y_{n+1-i} = h \\lambda y_{n+1} + h s_{n+1}$$\n$$(c_{k,0} - h\\lambda) y_{n+1} = h s_{n+1} - \\sum_{i=1}^{k} c_{k,i} y_{n+1-i}$$\n$$y_{n+1} = \\frac{h s_{n+1} - \\sum_{i=1}^{k} c_{k,i} y_{n-i+1}}{c_{k,0} - h\\lambda}$$\n求和项涉及到 $y$ 的前 $k$ 个值。设历史向量为 $Y_n = [y_n, y_{n-1}, \\dots]$。那么求和就是系数向量 $[c_{k,1}, \\dots, c_{k,k}]$ 和历史向量 $[y_n, \\dots, y_{n-k+1}]$ 的点积。\n\n**3. 可变阶选择算法**\n\n问题指定了一种在每个时间步改变阶数 $k$ 的特定算法。设 $k_{prev}$ 是上一步使用的阶数。在计算 $y_{n+1}$ 的当前步骤中：\n\n1.  **识别历史可用阶数：** 确定阶数集合 $K_{hist} = \\{ k \\in \\mathbb{Z} \\mid 1 \\le k \\le \\min(n+1, 5) \\}$，其中 $n+1$ 是历史中包括初始条件 $y_0$ 在内的点数。\n2.  **计算预测值：** 对于每个阶数 $k \\in K_{hist}$，使用上面推导的 BDF-k 公式计算一个预测值 $y_{n+1}^{(k)}$。\n3.  **计算误差代理：** 对于 $K_{hist}$ 中每个 $k \\ge 2$ 的阶数，计算误差代理 $e_k = \\lvert y_{n+1}^{(k)} - y_{n+1}^{(k-1)} \\rvert$。\n4.  **选择最优无约束阶数：** 如果只有 $k=1$ 可用，则必须选择 $k=1$。否则，在所有定义了 $e_k$ 的 $k$ 中，找到使其最小化的阶数 $k_{opt}$：\n    $$k_{opt} = \\underset{k \\in K_{hist}, k \\ge 2}{\\arg\\min} \\{e_k\\}$$\n5.  **应用约束：** 新阶数 $k_{new}$ 通过将 $k_{opt}$ 约束在与前一阶数 $k_{prev}$ 相差不超过一步的范围内确定。\n    $$k_{new} = \\max(k_{prev}-1, \\min(k_{opt}, k_{prev}+1))$$\n    我们必须确保 $k_{new} \\geq 1$。由于 $k_{prev} \\ge 1$，所以 $k_{prev}-1 \\ge 0$。因此，最终的保障是 $k_{new} = \\max(1, k_{new})$。\n6.  **更新解：** 当前步的解是与所选阶数相对应的解：$y_{n+1} = y_{n+1}^{(k_{new})}$。$k_{new}$ 的值成为下一步的 $k_{prev}$。\n\n初始步必须使用 $k=1$，所以我们初始化 $k_{prev}=1$。必须维护解值的历史记录以计算后续步骤。\n\n**4. 误差度量计算**\n程序必须为每个测试用例执行三次运行，以计算所需的误差度量：\n1.  使用步长 $h$ 的`rational-coef`（有理系数）运行：`y_rat_h`\n2.  使用步长 $h$ 的`float-coef`（浮点系数）运行：`y_float_h`\n3.  使用步长 $h/2$ 的`rational-coef`（有理系数）运行：`y_rat_h2`\n\n`float-coef` 运行要求在求解器中使用前，将精确的有理 BDF 系数舍入为单精度（$32$ 位）浮点数。\n\n然后按如下方式计算误差：\n- 舍入误差代理：$E_{\\mathrm{round}}(h) = \\lvert y_{float\\_h} - y_{rat\\_h} \\rvert$\n- 截断误差代理：$E_{\\mathrm{trunc}}(h) = \\lvert y_{rat\\_h} - y_{rat\\_h2} \\rvert$\n\n实现将精确遵循此逻辑。",
            "answer": "```python\nimport numpy as np\nfrom fractions import Fraction\nimport math\n\ndef get_bdf_coeffs(coeff_type='rational'):\n    \"\"\"\n    Generates BDF coefficients for orders 1-5.\n    \n    Args:\n        coeff_type (str): 'rational' for exact fractions, 'float' for\n                          single-precision rounded floats.\n\n    Returns:\n        A dictionary mapping order k to a list of its coefficients.\n    \"\"\"\n    # Coefficients c_{k,i} for sum_{i=0 to k} c_{k,i} y_{n+1-i} = h f_{n+1}\n    base_coeffs = {\n        1: [Fraction(1), Fraction(-1)],\n        2: [Fraction(3, 2), Fraction(-2), Fraction(1, 2)],\n        3: [Fraction(11, 6), Fraction(-3), Fraction(3, 2), Fraction(-1, 3)],\n        4: [Fraction(25, 12), Fraction(-4), Fraction(3), Fraction(-4, 3), Fraction(1, 4)],\n        5: [Fraction(137, 60), Fraction(-5), Fraction(5), Fraction(-10, 3), Fraction(5, 4), Fraction(-1, 5)],\n    }\n\n    if coeff_type == 'rational':\n        return {k: [float(c) for c in v] for k, v in base_coeffs.items()}\n    elif coeff_type == 'float':\n        # Round to single-precision float (float32) and then use as standard float (float64)\n        float_coeffs = {}\n        for k, v in base_coeffs.items():\n            float_coeffs[k] = [float(np.float32(c)) for c in v]\n        return float_coeffs\n    else:\n        raise ValueError(\"Invalid coefficient type\")\n\ndef solve_ode_variable_bdf(params, h, coeff_type):\n    \"\"\"\n    Solves y'(t) = lambda*y(t) + s(t) with a variable-order BDF method.\n    \"\"\"\n    lam, s_func, y0, T = params['lambda'], params['s_func'], params['y0'], params['T']\n    \n    # Ensure T is a multiple of h\n    num_steps = round(T / h)\n    \n    bdf_coeffs = get_bdf_coeffs(coeff_type)\n    \n    # History of y values, y_hist[0] = y_n, y_hist[1] = y_{n-1}, ...\n    y_hist = [y0]\n    k_prev = 1\n    max_order = 5\n\n    for n in range(num_steps):\n        t_next = (n + 1) * h\n        \n        # 1. Identify history-admissible orders\n        k_hist_max = min(len(y_hist), max_order)\n        \n        # 2. Compute predictions for all admissible orders\n        y_preds = {}\n        for k in range(1, k_hist_max + 1):\n            coeffs = bdf_coeffs[k]\n            c_k0 = coeffs[0]\n            \n            # History term: - sum_{i=1 to k} c_{k,i} * y_{n+1-i}\n            history_sum = -sum(coeffs[i] * y_hist[i-1] for i in range(1, k + 1))\n            \n            numerator = h * s_func(t_next) + history_sum\n            denominator = c_k0 - h * lam\n            \n            y_preds[k] = numerator / denominator\n\n        # 3. and 4. Select optimal order based on error proxies\n        k_opt = 1 \n        if k_hist_max > 1:\n            # Orders for which e_k can be computed\n            k_err_domain = range(2, k_hist_max + 1)\n            \n            errors = {k: abs(y_preds[k] - y_preds[k-1]) for k in k_err_domain}\n            \n            if errors:\n                # Find the order k that minimizes e_k\n                k_opt = min(errors, key=errors.get)\n\n        # 5. Apply +/- 1 constraint\n        k_new = k_opt\n        if k_new > k_prev + 1:\n            k_new = k_prev + 1\n        if k_new < k_prev - 1:\n            k_new = k_prev - 1\n        k_new = max(1, k_new)\n        \n        # 6. Update solution and history\n        y_next = y_preds[k_new]\n        y_hist.insert(0, y_next)\n        \n        # Trim history to max required length\n        if len(y_hist) > max_order:\n            y_hist.pop()\n            \n        k_prev = k_new\n        \n    return y_hist[0]\n\ndef solve():\n    test_cases = [\n        # Case A\n        {'params': {'lambda': -1.0, 's_func': lambda t: 0.0, 'y0': 1.0, 'T': 10.0}, 'h': 0.1},\n        # Case B\n        {'params': {'lambda': -50.0, 's_func': lambda t: 0.0, 'y0': 1.0, 'T': 1.0}, 'h': 0.02},\n        # Case C\n        {'params': {'lambda': -5.0, 's_func': lambda t: math.cos(t), 'y0': 0.0, 'T': 10.0}, 'h': 0.1},\n    ]\n\n    results = []\n    for case in test_cases:\n        params = case['params']\n        h = case['h']\n        \n        # Run with rational coeffs at h\n        y_rat_h = solve_ode_variable_bdf(params, h, 'rational')\n        \n        # Run with float coeffs at h\n        y_float_h = solve_ode_variable_bdf(params, h, 'float')\n        \n        # Run with rational coeffs at h/2\n        y_rat_h2 = solve_ode_variable_bdf(params, h / 2.0, 'rational')\n        \n        # Compute error proxies\n        e_round = abs(y_float_h - y_rat_h)\n        e_trunc = abs(y_rat_h - y_rat_h2)\n        \n        results.extend([e_round, e_trunc])\n    \n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "BDF等隐式方法的核心挑战在于每个时间步都需要求解一个代数方程组。对于非线性问题，这通常依赖于牛顿法等迭代策略。 本练习聚焦于这一关键环节，让你通过实践探索如何使用有限差分来近似计算牛顿法所需的雅可比矩阵。你将亲身体会到，有限差分步长 $h_J$ 的选择对求解器收敛速度和稳定性的重要影响，这是实现一个稳健的隐式积分器所必须掌握的实用技巧。",
            "id": "2401862",
            "problem": "考虑一个对所有实数时间定义的标量初值问题，其常微分方程为\n$$\ny'(t) = \\cos(t) + \\lambda\\,(y(t) - \\sin(t))^3,\\quad y(0)=0,\n$$\n其中 $\\lambda$ 是一个实数参数，$\\sin(\\cdot)$ 和 $\\cos(\\cdot)$ 分别表示正弦和余弦函数，角度以弧度为单位。对于所有 $t$，其精确解为 $y(t)=\\sin(t)$。\n\n假设使用一个阶数 $p\\in\\{1,2,3\\}$、固定时间步长 $\\Delta t>0$ 的变阶向后差分格式 (BDF) 方法，将解从时间 $t_n$ 向前推进一个步长至 $t_{n+1}=t_n+\\Delta t$。第 $(n+1)$ 步的 BDF 残差定义为\n$$\nR(y_{n+1}) = \\sum_{j=0}^{p} \\alpha_j\\, y_{n+1-j} - \\Delta t\\; f(t_{n+1}, y_{n+1}),\n$$\n其中 $f(t,y)=\\cos(t) + \\lambda\\,(y - \\sin(t))^3$，且对于均匀步长的 BDF 系数 $\\{\\alpha_j\\}_{j=0}^{p}$ 如下：\n- 对于 $p=1$：$\\alpha_0 = 1$, $\\alpha_1 = -1$,\n- 对于 $p=2$：$\\alpha_0 = \\tfrac{3}{2}$, $\\alpha_1 = -2$, $\\alpha_2 = \\tfrac{1}{2}$,\n- 对于 $p=3$：$\\alpha_0 = \\tfrac{11}{6}$, $\\alpha_1 = -3$, $\\alpha_2 = \\tfrac{3}{2}$, $\\alpha_3 = -\\tfrac{1}{3}$。\n\n假设先前的数值是精确的，由 $y_{n+1-j}=\\sin(t_{n+1}-j\\,\\Delta t)$ 给出（其中 $j=1,\\dots,p$），并且非线性求解的初始猜测值为 $y_{n+1}^{(0)}=y_n=\\sin(t_n)$，其中 $t_{n+1}=p\\,\\Delta t$ 且 $t_n=(p-1)\\,\\Delta t$。\n\n设残差关于 $y_{n+1}$ 的雅可比矩阵通过增量为 $h_J>0$ 的向前有限差分进行近似，\n$$\nJ(y) \\approx \\frac{R(y+h_J)-R(y)}{h_J}.\n$$\n在每个测试案例中，计算将牛顿法应用于 $R(y_{n+1})=0$ 所需的迭代次数 $k$。该牛顿法使用上述有限差分雅可比近似和初始猜测值，直到满足停止条件 $\\lvert R(y_{n+1}^{(k)})\\rvert \\le \\varepsilon$ 或超过最大迭代次数 $k_{\\max}$。使用 $\\varepsilon = 10^{-12}$ 和 $k_{\\max}=50$。同时，报告终止时的绝对解误差，\n$$\ne = \\lvert y_{n+1}^{(k)} - \\sin(t_{n+1})\\rvert,\n$$\n其中 $y_{n+1}^{(k)}$ 是最后一次迭代的结果（无论是在收敛时还是在达到 $k_{\\max}$ 后）。\n\n测试套件：\n对以下参数集 $(p,\\Delta t,\\lambda,h_J)$ 进行上述评估：\n- 案例 $1$：$(p=\\;1,\\;\\Delta t=\\;0.1,\\;\\lambda=\\;10,\\;h_J=\\;10^{-6})$,\n- 案例 $2$：$(p=\\;2,\\;\\Delta t=\\;0.05,\\;\\lambda=\\;100,\\;h_J=\\;10^{-6})$,\n- 案例 $3$：$(p=\\;3,\\;\\Delta t=\\;0.01,\\;\\lambda=\\;1000,\\;h_J=\\;10^{-6})$,\n- 案例 $4$：$(p=\\;2,\\;\\Delta t=\\;0.05,\\;\\lambda=\\;100,\\;h_J=\\;10^{-12})$,\n- 案例 $5$：$(p=\\;2,\\;\\Delta t=\\;0.05,\\;\\lambda=\\;100,\\;h_J=\\;10^{-2})$,\n- 案例 $6$：$(p=\\;1,\\;\\Delta t=\\;0.2,\\;\\lambda=\\;0,\\;h_J=\\;10^{-6})$。\n\n对于每个案例，生成一个结果列表 $[k,e]$，其中 $k$ 是所用的牛顿迭代次数（整数），$e$ 是上文定义的浮点绝对误差。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由六个案例结果组成的、以逗号分隔的列表。每个案例结果本身是一个包含两个元素的列表，无空格，并用方括号括起来。例如，格式必须如下所示：\n$$\n\\big[\\,[k_1,e_1],[k_2,e_2],[k_3,e_3],[k_4,e_4],[k_5,e_5],[k_6,e_6]\\,\\big].\n$$",
            "solution": "目标是为给定的非线性常微分方程模拟变阶 BDF 方法的单个步骤，并报告内部牛顿求解器的性能。对于每个测试案例 $(p, \\Delta t, \\lambda, h_J)$，其步骤如下。\n\n首先，我们为 BDF 积分步骤建立背景。BDF 方法是一种隐式线性多步法。对于形式为 $y'(t) = f(t, y(t))$ 的常微分方程，阶数为 $p$ 的 BDF 格式需要在每个时间步 $t_{n+1}$ 求解以下关于未知数 $y_{n+1}$ 的非线性代数方程：\n$$\n\\sum_{j=0}^{p} \\alpha_j y_{n+1-j} - \\Delta t f(t_{n+1}, y_{n+1}) = 0\n$$\n为了简化求解过程，我们定义残差函数 $R(y)$，其中 $y$ 是解 $y_{n+1}$ 的一个候选值：\n$$\nR(y) = \\alpha_0 y + \\sum_{j=1}^{p} \\alpha_j y_{n+1-j} - \\Delta t f(t_{n+1}, y)\n$$\n问题规定，对于 $j \\in \\{1, \\dots, p\\}$，历史值 $y_{n+1-j}$ 是已知且精确的，即 $y_{n+1-j} = \\sin(t_{n+1-j})$。时间由 $t_{n+1} = p \\Delta t$ 和 $t_{n+1-j} = t_{n+1} - j \\Delta t = (p-j)\\Delta t$ 定义。求和中的历史部分可以作为当前步骤的一个常数预先计算：\n$$\nH_n = \\sum_{j=1}^{p} \\alpha_j \\sin((p-j)\\Delta t)\n$$\n残差函数随后可以更紧凑地写作：\n$$\nR(y) = \\alpha_0 y + H_n - \\Delta t \\left( \\cos(t_{n+1}) + \\lambda(y - \\sin(t_{n+1}))^3 \\right)\n$$\n我们必须使用牛顿法求 $R(y)=0$ 的根。牛顿法的迭代格式如下：\n$$\ny_{n+1}^{(k+1)} = y_{n+1}^{(k)} - \\left[ J\\left(y_{n+1}^{(k)}\\right) \\right]^{-1} R\\left(y_{n+1}^{(k)}\\right)\n$$\n其中 $y_{n+1}^{(k)}$ 是第 $k$ 次迭代值。雅可比 $J(y)$ 是残差关于 $y$ 的导数，$J(y) = \\frac{dR}{dy}$。问题要求使用向前有限差分近似来计算该雅可比：\n$$\nJ(y) \\approx \\frac{R(y+h_J) - R(y)}{h_J}\n$$\n迭代过程从初始猜测值 $y_{n+1}^{(0)} = y_n = \\sin(t_n) = \\sin((p-1)\\Delta t)$ 开始。迭代持续进行，直到满足停止条件 $|R(y_{n+1}^{(k)})| \\le \\varepsilon = 10^{-12}$，或迭代次数 $k$ 超过最大值 $k_{\\max}=50$。\n\n单个测试案例的算法如下：\n$1$. 确定参数 $(p, \\Delta t, \\lambda, h_J)$ 和常数 $\\varepsilon=10^{-12}$, $k_{\\max}=50$。\n$2$. 选择与阶数 $p$ 对应的 BDF 系数 $\\{\\alpha_j\\}$。\n$3$. 设置当前步长的时间：$t_{n+1} = p \\Delta t$。\n$4$. 计算常数历史项 $H_n = \\sum_{j=1}^{p} \\alpha_j \\sin((p-j)\\Delta t)$。\n$5$. 定义残差函数 $R(y) = \\alpha_0 y + H_n - \\Delta t (\\cos(t_{n+1}) + \\lambda(y - \\sin(t_{n+1}))^3)$。\n$6$. 初始化牛顿迭代：$k=0$ 且 $y_{cur} = \\sin((p-1)\\Delta t)$。\n$7$. 开始迭代循环， $k$ 从 $0$ 到 $k_{\\max}-1$：\n    a. 计算当前迭代值的残差：$R_{cur} = R(y_{cur})$。\n    b. 检查收敛性：如果 $|R_{cur}| \\le \\varepsilon$，则跳出循环并进入第 $9$ 步。\n    c. 近似雅可比：$J_{cur} = (R(y_{cur} + h_J) - R_{cur}) / h_J$。\n    d. 执行牛顿更新：$y_{cur} \\leftarrow y_{cur} - R_{cur} / J_{cur}$。\n$8$. 如果循环完成但未收敛，最终迭代值为上一次迭代的 $y_{cur}$，迭代次数为 $k_{\\max}$。问题要求报告最终的迭代次数，即循环中的 $k+1$，也就是 $k_{\\max}$。然而，定义暗示我们应报告执行的*更新*次数或迭代次数。一个从 $k=0$ 到 $k_{max}-1$ 的循环执行 $k_{max}$ 次迭代。如果在 $k$ 处停止，则已执行 $k$ 次迭代。让我们将循环定义为从 $k=1$到 $k_{max}$。在 $k=0$ 时进行初始检查。如果未收敛，则循环开始。因此，如果在 3 次更新后收敛，则 $k=3$。如果初始猜测值正确，则 $k=0$。修正后的循环逻辑：\n   初始化 $k=0$, $y_k = y_{n+1}^{(0)}$。\n   当 $k < k_{\\max}$ 时：\n     计算 $R(y_k)$。\n     如果 $|R(y_k)| \\le \\varepsilon$，则跳出循环。\n     计算 $J(y_k)$。\n     $y_{k+1} = y_k - R(y_k)/J(y_k)$。\n     $k \\leftarrow k+1$。\n   这个逻辑能正确计算更新的次数。\n$9$. 终止时，最终迭代次数为 $k$，最终近似值为 $y_{n+1}^{(k)} = y_{cur}$。\n$10$. 计算绝对误差：$e = |y_{n+1}^{(k)} - \\sin(t_{n+1})|$。\n$11$. 该测试案例的结果是数对 $[k, e]$。\n\n对于六个指定的测试案例中的每一个，都必须执行这个完整的程序。实现将使用标准双精度浮点数进行运算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the given problem by running the specified test suite and printing\n    the results in the required format.\n    \"\"\"\n\n    test_cases = [\n        # (p, Δt, λ, h_J)\n        (1, 0.1, 10, 1e-6),\n        (2, 0.05, 100, 1e-6),\n        (3, 0.01, 1000, 1e-6),\n        (2, 0.05, 100, 1e-12),\n        (2, 0.05, 100, 1e-2),\n        (1, 0.2, 0, 1e-6),\n    ]\n\n    results = []\n    for case in test_cases:\n        k, e = run_newton_bdf_step(*case)\n        results.append(f\"[{k},{e}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef run_newton_bdf_step(p, dt, lam, h_j):\n    \"\"\"\n    Performs one BDF step using Newton's method for a given set of parameters.\n\n    Args:\n        p (int): Order of the BDF method.\n        dt (float): Time step size Δt.\n        lam (float): Parameter λ in the ODE.\n        h_j (float): Increment for finite-difference Jacobian.\n\n    Returns:\n        tuple: A tuple containing:\n            - k (int): Number of Newton iterations.\n            - error (float): Absolute error at termination.\n    \"\"\"\n    epsilon = 1e-12\n    k_max = 50\n\n    bdf_coeffs = {\n        1: {'alpha': [1.0, -1.0]},\n        2: {'alpha': [3.0/2.0, -2.0, 1.0/2.0]},\n        3: {'alpha': [11.0/6.0, -3.0, 3.0/2.0, -1.0/3.0]}\n    }\n\n    if p not in bdf_coeffs:\n        raise ValueError(f\"Invalid order p={p}. Must be 1, 2, or 3.\")\n\n    alpha = bdf_coeffs[p]['alpha']\n    alpha_0 = alpha[0]\n    \n    # Time points\n    t_next = p * dt\n    t_prev = (p - 1) * dt\n\n    # Pre-compute history term\n    history_sum = 0.0\n    for j in range(1, p + 1):\n        t_hist = (p - j) * dt\n        history_sum += alpha[j] * np.sin(t_hist)\n    \n    sin_t_next = np.sin(t_next)\n    cos_t_next = np.cos(t_next)\n\n    def f(y, t):\n        return cos_t_next + lam * (y - sin_t_next)**3\n\n    def residual(y):\n        return alpha_0 * y + history_sum - dt * f(y, t_next)\n    \n    # Newton's method\n    k = 0\n    y_k = np.sin(t_prev)  # Initial guess y_n+1^(0) = y_n\n\n    while k < k_max:\n        res_k = residual(y_k)\n\n        if np.abs(res_k) <= epsilon:\n            break\n\n        # Finite difference Jacobian\n        res_h = residual(y_k + h_j)\n        jac_k = (res_h - res_k) / h_j\n        \n        # Avoid division by zero if Jacobian is pathologically small\n        if np.abs(jac_k) < 1e-14:\n            # This indicates a problem, e.g., stagnation. We stop.\n            k = k_max\n            break\n\n        # Newton update\n        y_k = y_k - res_k / jac_k\n        k += 1\n    \n    # Final error calculation\n    error = np.abs(y_k - sin_t_next)\n\n    return k, error\n    \nsolve()\n```"
        },
        {
            "introduction": "在许多实际仿真中，积分过程可能因“事件”发生而中断，随后需要从该特定时间点重新启动。如果简单地从一阶方法开始，会严重影响计算效率。 本练习将探讨如何实现高阶重启，其关键在于利用事件发生前的数据构造一个插值多项式，从而生成一套与新步长对齐的“合成历史”，让你在解决实际问题的同时，加深对BDF方法多项式本质的理解。",
            "id": "2401895",
            "problem": "给定一个由常微分方程 (ODE) $y^{\\prime}(t) = \\lambda\\, y(t)$ 定义的标量初值问题，其精确解为 $y(t) = \\exp(\\lambda t)$。假设在时间 $t = t_e$ 检测到一个事件，且积分必须在 $t_e$ 处使用一个阶数为 $k$、事件后步长恒为 $h$ 的后向分化公式 (BDF) 重新启动。为了在重新启动时不损失 $k$ 阶精度，需要一套与新步长对齐的 $k$ 个历史值，即 $y(t_e), y(t_e - h), \\dots, y\\left(t_e - (k-1)h\\right)$，我们称之为合成历史值。\n\n对于下方的每个测试用例，请使用以下基于基本多项式插值和后向分化公式定义的定义和任务：\n\n- 设 $\\{\\tau_i\\}_{i=1}^{k}$ 为 $k$ 个不同的事件前采样时间，满足对于所有 $i$ 都有 $\\tau_i < t_e$。将 $k+1$ 个插值节点定义为 $\\{(\\tau_i, y(\\tau_i))\\}_{i=1}^{k} \\cup \\{(t_e, y(t_e))\\}$。设 $p_k(t)$ 是对这 $k+1$ 个点进行插值的唯一的、次数至多为 $k$ 的多项式。将与新步长对齐的合成历史值定义为 $y_e^{(j)} := p_k\\left(t_e - j h\\right)$，其中 $j \\in \\{0,1,\\dots,k-1\\}$ 且 $y_e^{(0)} = p_k(t_e)$。\n\n- $k$ 阶后向分化公式 (BDF) 在步长恒为 $h$ 的情况下，其系数 $\\{\\alpha_j\\}_{j=0}^{k}$ 由以下条件定义，这些条件使得在 $t_{n+1}$ 处的离散导数对于所有次数至多为 $k$ 的多项式都是精确的。这些系数由等距网格 $s_j = -j$（其中 $j \\in \\{0,1,\\dots,k\\}$）上的矩条件唯一确定：\n  1. $\\sum_{j=0}^{k} \\alpha_j s_j^m = 0$，对于所有满足 $m \\in \\{0,2,3,\\dots,k\\}$ 的整数 $m$，\n  2. $\\sum_{j=0}^{k} \\alpha_j s_j = 1$。\n  于是，在 $t_{n+1} = t_e + h$ 处的 BDF 更新由下式给出\n  $$\\sum_{j=0}^{k} \\alpha_j\\, y_{n+1-j} = h\\, y^{\\prime}(t_{n+1}),$$\n  其中 $y_{n+1} = y(t_e+h)$，而对于 $j \\in \\{1,\\dots,k\\}$，$y_{n+1-j}$ 是上文定义的合成历史值 $y_e^{(j-1)}$。对于 ODE $y^{\\prime} = \\lambda y$，这变成一个标量隐式方程\n  $$\\alpha_0\\, y(t_e+h) + \\sum_{j=1}^{k} \\alpha_j\\, y_e^{(j-1)} = h\\, \\lambda\\, y(t_e+h),$$\n  其唯一解为\n  $$y(t_e+h) = \\frac{-\\sum_{j=1}^{k} \\alpha_j\\, y_e^{(j-1)}}{\\alpha_0 - h\\, \\lambda}.$$\n\n对于每个测试用例，您的程序必须根据指定的插值节点构造 $p_k(t)$，评估合成历史值 $y_e^{(j)}$，通过求解上述线性矩条件来确定 $k$ 阶 BDF 系数 $\\{\\alpha_j\\}_{j=0}^{k}$，使用隐式公式计算单步重启值 $y(t_e+h)$，并报告与精确解 $y_{\\text{exact}}(t_e+h) = \\exp(\\lambda (t_e+h))$ 之间的绝对误差。每个测试用例的结果是浮点数表示的绝对误差 $|y(t_e+h) - y_{\\text{exact}}(t_e+h)|$。\n\n测试套件：\n- A例（常规顺利路径）：$\\lambda = -2.0$, $k = 3$, $h = 0.05$, $t_e = 0.9$，事件前采样时间 $\\tau = [0.2, 0.5, 0.7]$。\n- B例（边界阶数）：$\\lambda = 1.1$, $k = 1$, $h = 0.03$, $t_e = 0.2$，事件前采样时间 $\\tau = [0.0]$。\n- C例（更高阶数）：$\\lambda = -4.0$, $k = 5$, $h = 0.02$, $t_e = 0.9$，事件前采样时间 $\\tau = [0.0, 0.12, 0.25, 0.44, 0.68]$。\n- D例（小步长，聚集数据）：$\\lambda = 0.5$, $k = 2$, $h = 0.005$, $t_e = 0.92$，事件前采样时间 $\\tau = [0.88, 0.9]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的结果列表，其顺序与上面列出的测试用例相同。例如，输出格式必须为 $[r_A,r_B,r_C,r_D]$，其中每个 $r_{\\cdot}$ 是对应测试用例的绝对误差，表示为浮点数。",
            "solution": "该任务是计算一个后向分化公式 (BDF) 积分器在特定时间 $t_e$ 重新启动时的单步误差。此重启需要构建一套“合成历史值”——即在过去等距时间点上的一组解值——这些值先前并不存在，因为事件前的步长与新的、事件后的步长 $h$ 并不对齐。该问题使用多项式插值正确地形式化了此过程。\n\n解决方案是一个直接的多步计算过程。\n\n首先，我们必须构建合成历史值。对于一个 $k$ 阶 BDF 方法，我们需要 $k$ 个历史点。该方法必须对最高 $k$ 次的多项式是精确的。因此，生成历史值的函数最自然的选择是一个次数至多为 $k$ 的多项式，我们记为 $p_k(t)$。一个次数至多为 $k$ 的唯一多项式由 $k+1$ 个不同的点确定。问题提供了这些点：$k$ 个事件前数据点 $\\{(\\tau_i, y(\\tau_i))\\}_{i=1}^{k}$ 以及事件时间本身的值 $(t_e, y(t_e))$。函数 $y(t)$ 已给出，是测试方程 $y'(t) = \\lambda y(t)$ 的精确解，即 $y(t) = \\exp(\\lambda t)$。因此，我们有 $k+1$ 个插值节点 $\\{(\\tau, \\exp(\\lambda \\tau))\\}_{\\tau \\in \\{\\tau_1, \\dots, \\tau_k, t_e\\}}$。我们找到穿过这些节点的唯一多项式 $p_k(t)$。在计算上，这是通过求解一个关于多项式系数的线性系统来实现的。一旦确定了 $p_k(t)$，我们就可以通过在所需的等距网格点上评估该多项式来生成合成历史值 $y_e^{(j)}$：\n$$y_e^{(j)} = p_k(t_e - j h) \\quad \\text{for } j \\in \\{0, 1, \\dots, k-1\\}$$\n\n其次，我们必须确定 $k$ 阶 BDF 的系数 $\\{\\alpha_j\\}_{j=0}^{k}$。问题提供了其定义的矩条件。这些条件规定，离散微分算子对于所有次数最高为 $k$ 的单项式 $t^m$ 都必须是精确的，这导出了一个关于 $k+1$ 个未知系数的 $k+1$ 个线性方程组。该系统具体如下：\n$$\n\\sum_{j=0}^{k} \\alpha_j s_j^m =\n\\begin{cases}\n1 & \\text{if } m=1 \\\\\n0 & \\text{if } m \\in \\{0, 2, 3, \\dots, k\\}\n\\end{cases}\n$$\n其中 $s_j = -j$。这可以写成矩阵形式 $M \\mathbf{\\alpha} = \\mathbf{b}$，其中 $M$ 是一个范德蒙矩阵，其元素为 $M_{m,j} = (-j)^m$，行标 $m \\in \\{0, \\dots, k\\}$，列标 $j \\in \\{0, \\dots, k\\}$；未知向量是 $\\mathbf{\\alpha} = [\\alpha_0, \\dots, \\alpha_k]^T$；右侧向量是 $\\mathbf{b} = [0, 1, 0, \\dots, 0]^T$。求解这个非奇异系统可以得到给定阶数 $k$ 的唯一 BDF 系数组。\n\n第三，我们计算在第一个事件后时间步 $t_{e}+h$ 的数值解。将 BDF 公式应用于微分方程 $y' = \\lambda y$ 在时间 $t_e+h$ 处，得到：\n$$\\alpha_0 y(t_e+h) + \\sum_{j=1}^{k} \\alpha_j y_e^{(j-1)} = h \\lambda y(t_e+h)$$\n这里，值 $y_e^{(j-1)}$ 是第一步中计算的合成历史点。注意，对于 $j \\in \\{1, \\dots, k\\}$，索引 $j-1$ 的范围从 $0$ 到 $k-1$，与我们的合成值集合相匹配。这是一个关于未知数 $y(t_e+h)$ 的隐式方程，可以很容易地通过代数方法求解：\n$$y(t_e+h) = \\frac{-\\sum_{j=1}^{k} \\alpha_j y_e^{(j-1)}}{\\alpha_0 - h \\lambda}$$\n分子是合成历史值的加权和，分母是该方法在 $h\\lambda$ 处的稳定性函数。\n\n最后，我们通过计算绝对误差来量化此过程的准确性。我们将数值计算的值 $y(t_e+h)$ 与同一点的精确解析解 $y_{\\text{exact}}(t_e+h) = \\exp(\\lambda(t_e+h))$ 进行比较。因此，误差为：\n$$\\text{Error} = |y(t_e+h) - y_{\\text{exact}}(t_e+h)|$$\n\n对问题陈述中指定的每个测试用例，都执行这一完整的操作序列。实现将使用稳健的数值库函数进行多项式拟合和求解 BDF 系数的线性系统。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the BDF restart problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A (general happy path)\n        {'lambda_val': -2.0, 'k': 3, 'h': 0.05, 't_e': 0.9, 'tau': [0.2, 0.5, 0.7]},\n        # Case B (boundary order)\n        {'lambda_val': 1.1, 'k': 1, 'h': 0.03, 't_e': 0.2, 'tau': [0.0]},\n        # Case C (higher order)\n        {'lambda_val': -4.0, 'k': 5, 'h': 0.02, 't_e': 0.9, 'tau': [0.0, 0.12, 0.25, 0.44, 0.68]},\n        # Case D (short step, clustered data)\n        {'lambda_val': 0.5, 'k': 2, 'h': 0.005, 't_e': 0.92, 'tau': [0.88, 0.9]},\n    ]\n\n    results = []\n    for case in test_cases:\n        error = calculate_restart_error(**case)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_restart_error(lambda_val, k, h, t_e, tau):\n    \"\"\"\n    Calculates the absolute error for a single BDF restart test case.\n\n    Args:\n        lambda_val (float): The lambda parameter of the ODE y' = lambda*y.\n        k (int): The order of the BDF method.\n        h (float): The post-event step size.\n        t_e (float): The time of the event and restart.\n        tau (list[float]): A list of k pre-event sampling times.\n\n    Returns:\n        float: The absolute error |y_computed(t_e+h) - y_exact(t_e+h)|.\n    \"\"\"\n    # Step 1: Construct the interpolating polynomial p_k(t)\n    # The interpolation nodes are the k pre-event points plus the event point.\n    interp_times = np.array(tau + [t_e])\n    \n    # The corresponding y-values are from the exact solution y(t) = exp(lambda*t)\n    interp_values = np.exp(lambda_val * interp_times)\n    \n    # Find the coefficients of the unique polynomial of degree at most k.\n    # With k+1 points, polyfit of degree k gives the exact interpolating polynomial.\n    poly_coeffs = np.polyfit(interp_times, interp_values, k)\n\n    # Step 2: Evaluate p_k(t) to get the synthetic history\n    # The synthetic history points are at t_e, t_e - h, ..., t_e - (k-1)h\n    synth_eval_times = t_e - np.arange(k) * h\n    synthetic_history = np.polyval(poly_coeffs, synth_eval_times) # y_e^(0), ..., y_e^(k-1)\n\n    # Step 3: Determine the BDF coefficients {alpha_j}\n    # This requires solving a (k+1)x(k+1) linear system M*alpha = b\n    # M_mj = (-j)^m for m, j in {0, ..., k}\n    m_powers = np.arange(k + 1).reshape(-1, 1)\n    j_bases = -np.arange(k + 1)\n    M = np.power(j_bases, m_powers)\n    \n    # The RHS vector b is [0, 1, 0, ..., 0]^T\n    b = np.zeros(k + 1)\n    b[1] = 1.0\n    \n    alpha_coeffs = np.linalg.solve(M, b) # [alpha_0, alpha_1, ..., alpha_k]\n\n    # Step 4: Compute the one-step restart value y(t_e+h)\n    # y(t_e+h) = (-sum_{j=1 to k} alpha_j * y_e^(j-1)) / (alpha_0 - h*lambda)\n    # The sum is alpha_1*y_e^0 + alpha_2*y_e^1 + ... + alpha_k*y_e^(k-1)\n    numerator_sum = np.dot(alpha_coeffs[1:], synthetic_history)\n    numerator = -numerator_sum\n    \n    denominator = alpha_coeffs[0] - h * lambda_val\n    \n    y_computed = numerator / denominator\n\n    # Step 5: Calculate the absolute error\n    y_exact = np.exp(lambda_val * (t_e + h))\n    error = np.abs(y_computed - y_exact)\n    \n    return error\n\nsolve()\n```"
        }
    ]
}