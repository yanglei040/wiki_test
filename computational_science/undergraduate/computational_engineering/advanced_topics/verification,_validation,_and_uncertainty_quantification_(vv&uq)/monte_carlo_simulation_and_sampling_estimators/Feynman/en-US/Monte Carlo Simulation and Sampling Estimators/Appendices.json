{
    "hands_on_practices": [
        {
            "introduction": "Our first practice is a hands-on introduction to the core 'hit-or-miss' Monte Carlo method. We will apply this powerful technique to a question from number theory: estimating the probability that a randomly chosen integer is square-free . This exercise provides a concrete example of how simulation can be used to approximate a deterministic quantity, building a foundational understanding of the sample mean as an estimator.",
            "id": "2415243",
            "problem": "You are to write a complete program that computes estimates of a probability defined from first principles. A positive integer $k$ is called square-free if there is no integer $d \\ge 2$ such that $d^2$ divides $k$. Let $p$ denote the limiting probability that a uniformly selected positive integer is square-free, understood as the natural density $$p = \\lim_{n \\to \\infty} \\frac{1}{n}\\sum_{k=1}^{n} \\mathbf{1}\\{\\text{$k$ is square-free}\\}.$$ For finite $n$, define the finite-population probability $$p_n = \\frac{1}{n}\\sum_{k=1}^{n} \\mathbf{1}\\{\\text{$k$ is square-free}\\}.$$ For each test case, you must output a single real number that is an estimate of $p_n$ based on random sampling subject to the following condition: the computation for a test case with parameters $(n,m,s)$ must depend only on exactly $m$ independent random variates drawn from the discrete uniform distribution on $\\{1,2,\\dots,n\\}$ produced by a Pseudo-Random Number Generator (PRNG) initialized with seed $s$. No external input is provided.\n\nYour program must take no input and must process the following test suite of ordered triples $(n,m,s)$:\n- $(n,m,s) = (10^6, 200000, 17)$\n- $(n,m,s) = (1, 10000, 99)$\n- $(n,m,s) = (100, 5000, 2024)$\n- $(n,m,s) = (10^5, 150000, 123456)$\n- $(n,m,s) = (50, 10000, 314159)$\n\nRequirements for the final output:\n- For each test case, produce a single real number equal to your estimate of $p_n$, rounded to $6$ decimal places.\n- Aggregate the results for all test cases, in the same order as listed, into a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[x_1,x_2,x_3,x_4,x_5]$ where each $x_i$ is a real number with exactly $6$ digits after the decimal point.",
            "solution": "The posed problem must first be validated for scientific soundness, clarity, and completeness.\n\n**Step 1: Extract Givens**\n- **Definition**: A positive integer $k$ is square-free if there is no integer $d \\ge 2$ such that $d^2$ divides $k$.\n- **Limiting Probability**: $p = \\lim_{n \\to \\infty} \\frac{1}{n}\\sum_{k=1}^{n} \\mathbf{1}\\{\\text{$k$ is square-free}\\}$.\n- **Finite-Population Probability**: $p_n = \\frac{1}{n}\\sum_{k=1}^{n} \\mathbf{1}\\{\\text{$k$ is square-free}\\}$.\n- **Task**: For each parameter set $(n, m, s)$, estimate $p_n$.\n- **Methodology**: The estimate must be derived from exactly $m$ independent random variates drawn from the discrete uniform distribution on $\\{1, 2, \\dots, n\\}$.\n- **Reproducibility**: The Pseudo-Random Number Generator (PRNG) must be initialized with a given seed $s$.\n- **Test Cases**:\n    - $(n, m, s) = (10^6, 200000, 17)$\n    - $(n, m, s) = (1, 10000, 99)$\n    - $(n, m, s) = (100, 5000, 2024)$\n    - $(n, m, s) = (10^5, 150000, 123456)$\n    - $(n, m, s) = (50, 10000, 314159)$\n- **Output Format**: A single line containing a comma-separated list of estimates, each rounded to $6$ decimal places.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed against the required criteria:\n- **Scientifically Grounded**: The concept of square-free integers is a fundamental topic in number theory. The use of Monte Carlo simulation to estimate a probability is a standard and robust technique in computational science and engineering. The problem is firmly rooted in established mathematical and computational principles.\n- **Well-Posed**: The problem provides a clear and unambiguous definition of the quantity to be estimated, $p_n$. It specifies the population ($\\{1, \\dots, n\\}$), the sampling distribution (uniform), the sample size ($m$), and the PRNG seed ($s$). This is a complete specification for a Monte Carlo experiment, which guarantees a unique, deterministic result for each test case.\n- **Objective**: The problem is stated in precise, mathematical language, free from any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. It is a well-defined computational problem based on sound mathematical principles. A complete solution will now be developed.\n\n**Principle-Based Solution**\n\nThe objective is to estimate the probability, $p_n$, that a positive integer selected uniformly at random from the set $\\{1, 2, \\dots, n\\}$ is square-free. This probability is defined as the mean of an indicator random variable. Let $K$ be a random variable with a discrete uniform distribution on $\\{1, 2, \\dots, n\\}$. Then,\n$$p_n = \\mathbb{E}[\\mathbf{1}\\{K \\text{ is square-free}\\}]$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function.\n\nThe Monte Carlo method provides a powerful way to estimate such an expectation. By the Law of Large Numbers, the sample mean of independent and identically distributed random variables converges to the true expectation. We generate $m$ independent samples, $k_1, k_2, \\dots, k_m$, from the distribution of $K$. The Monte Carlo estimator for $p_n$, denoted $\\hat{p}_{n,m}$, is the sample mean of the indicator function evaluated at these samples:\n$$\\hat{p}_{n,m} = \\frac{1}{m} \\sum_{i=1}^{m} \\mathbf{1}\\{k_i \\text{ is square-free}\\}$$\nThis is equivalent to counting the number of samples that are square-free and dividing by the total number of samples, $m$.\n\nThe core computational task is to implement a function that correctly determines if an integer $k$ is square-free. A positive integer $k$ is square-free if it is not divisible by any perfect square greater than $1$. It is sufficient to check for divisibility by the squares of prime numbers. If $k$ were divisible by a composite square, $(ab)^2$, it would also be divisible by the squares of the prime factors of $ab$. Therefore, $k$ is square-free if and only if for every prime number $p$, $p^2$ does not divide $k$.\n\nFor a given integer $k$, we only need to perform this check for primes $p$ such that $p^2 \\le k$. To implement this test efficiently across many calls, it is advantageous to pre-compute a list of all primes up to $\\sqrt{\\max(n)}$, where $\\max(n)$ is the largest value of $n$ across all test cases. In this problem, $\\max(n) = 10^6$, so we require primes up to $\\sqrt{10^6} = 1000$. The Sieve of Eratosthenes is a classical and efficient algorithm for this purpose.\n\nThe overall algorithm for each test case $(n, m, s)$ is as follows:\n1.  **Pre-computation**: Generate a list of all prime numbers up to $1000$ using the Sieve of Eratosthenes. This is done once for all test cases.\n2.  **Initialization**: Initialize a Pseudo-Random Number Generator (PRNG) with the specified seed $s$.\n3.  **Sampling**: Draw $m$ random integers, $k_1, k_2, \\dots, k_m$, from the discrete uniform distribution on $\\{1, 2, \\dots, n\\}$.\n4.  **Counting**: Initialize a counter to zero. For each sample $k_i$, test if it is square-free using the pre-computed list of primes. If $k_i$ is square-free, increment the counter.\n5.  **Estimation**: Compute the estimate $\\hat{p}_{n,m}$ as the final count divided by the sample size $m$.\n6.  **Formatting**: Round the estimate to $6$ decimal places.\n\nThis procedure is deterministic for a given test case and will produce a single, verifiable estimate of $p_n$. The results for all test cases are then aggregated into the specified final output format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef sieve_of_eratosthenes(limit):\n    \"\"\"\n    Generates a list of prime numbers up to a given limit using the Sieve of Eratosthenes.\n    \"\"\"\n    if limit < 2:\n        return []\n    \n    prime_flags = [True] * (limit + 1)\n    prime_flags[0] = prime_flags[1] = False\n    \n    for i in range(2, int(np.sqrt(limit)) + 1):\n        if prime_flags[i]:\n            for multiple in range(i * i, limit + 1, i):\n                prime_flags[multiple] = False\n                \n    primes = [i for i, is_p in enumerate(prime_flags) if is_p]\n    return primes\n\ndef is_square_free(k, primes):\n    \"\"\"\n    Checks if an integer k is square-free using a pre-computed list of primes.\n    A number is square-free if it is not divisible by any square of a prime.\n    \"\"\"\n    if k == 1:\n        return True\n    \n    for p in primes:\n        p_squared = p * p\n        if p_squared > k:\n            # If p^2 > k, no larger prime's square can be a factor.\n            break\n        if k % p_squared == 0:\n            return False\n            \n    # If no prime square up to k divides k, it is square-free.\n    return True\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and compute Monte Carlo estimates.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (10**6, 200000, 17),\n        (1, 10000, 99),\n        (100, 5000, 2024),\n        (10**5, 150000, 123456),\n        (50, 10000, 314159)\n    ]\n\n    # Pre-compute primes required for the largest n in the test suite.\n    # The check is efficient if we have primes up to sqrt(max_n).\n    max_n = max(tc[0] for tc in test_cases if tc[0] > 1) if test_cases else 1\n    prime_limit = int(np.sqrt(max_n))\n    primes = sieve_of_eratosthenes(prime_limit)\n\n    results = []\n    for n, m, s in test_cases:\n        # Handle the trivial case where n=1. The only possible sample is 1,\n        # which is square-free. The probability is exactly 1.\n        if n == 1:\n            results.append(1.0)\n            continue\n            \n        # Initialize the random number generator with the specified seed.\n        rng = np.random.default_rng(seed=s)\n        \n        # Generate m independent random integers from {1, 2, ..., n}.\n        samples = rng.integers(low=1, high=n, size=m, endpoint=True)\n        \n        # Count how many of the samples are square-free.\n        square_free_count = 0\n        for k in samples:\n            if is_square_free(k, primes):\n                square_free_count += 1\n                \n        # The estimate for p_n is the fraction of square-free samples.\n        estimate = square_free_count / m\n        results.append(estimate)\n\n    # Format results to 6 decimal places and print in the required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building upon the basic concept of probability estimation, we now extend the Monte Carlo method to the geometric realm of high-dimensional integration . In this practice, you will estimate the ratio of the volume of a $d$-dimensional hypersphere to its enclosing hypercube. This classic problem not only demonstrates the power of Monte Carlo for approximating complex integrals but also provides a striking, hands-on encounter with the counter-intuitive 'curse of dimensionality'.",
            "id": "2415275",
            "problem": "You are to study how the ratio of a $d$-dimensional hypersphereâ€™s volume to that of a $d$-dimensional hypercube changes with dimension $d$. Let $C_d = [-1,1]^d \\subset \\mathbb{R}^d$ denote the hypercube of side length $2$ centered at the origin, and let $S_d = \\{x \\in \\mathbb{R}^d : \\lVert x \\rVert_2 \\le 1\\}$ denote the unit hypersphere in $d$-dimensional Euclidean space. Define the ratio $R(d)$ by\n$$\nR(d) = \\frac{\\mathrm{Vol}(S_d)}{\\mathrm{Vol}(C_d)}.\n$$\nFor a given positive integer $N$ and integer seed $s$, let $X_1,\\dots,X_N$ be independent and identically distributed random vectors uniformly distributed on $C_d$, determined by a pseudo-random number generator initialized with seed $s$. Define the estimator\n$$\n\\widehat{R}_N(d,s) \\equiv \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\lVert X_i \\rVert_2 \\le 1\\},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function and $\\lVert \\cdot \\rVert_2$ is the Euclidean norm. For each test case below, compute the single real number $\\widehat{R}_N(d,s)$.\n\nAll answers must be dimensionless real numbers. Round each result to exactly $6$ decimal places.\n\nTest suite (each item is $(d,N,s)$):\n- $(1, 20000, 7)$\n- $(2, 100000, 11)$\n- $(8, 300000, 2025)$\n- $(12, 500000, 123)$\n- $(20, 500000, 99991)$\n\nFinal output format: Your program should produce a single line of output containing the results, in the same order as the test suite, as a comma-separated list enclosed in square brackets. For example, a generic format is [$x_1,x_2,x_3,x_4,x_5$], where each $x_i$ is a real number rounded to exactly $6$ decimal places as specified above.",
            "solution": "The problem requires the computation of a Monte Carlo estimator for the ratio of the volume of a $d$-dimensional hypersphere to that of a $d$-dimensional hypercube. I shall first validate the problem statement and then provide a complete solution based on fundamental principles of computational science.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following definitions and parameters:\n- Hypercube: $C_d = [-1,1]^d \\subset \\mathbb{R}^d$. This is a hypercube of side length $2$ centered at the origin.\n- Hypersphere: $S_d = \\{x \\in \\mathbb{R}^d : \\lVert x \\rVert_2 \\le 1\\}$. This is a unit hypersphere centered at the origin, fully inscribed within the hypercube $C_d$.\n- Ratio of volumes: $R(d) = \\frac{\\mathrm{Vol}(S_d)}{\\mathrm{Vol}(C_d)}$.\n- Random vectors: $X_1,\\dots,X_N$ are independent and identically distributed (i.i.d.) random vectors uniformly distributed on $C_d$. Their generation is determined by a pseudo-random number generator initialized with an integer seed $s$.\n- Estimator: $\\widehat{R}_N(d,s) \\equiv \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\lVert X_i \\rVert_2 \\le 1\\}$, where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function and $\\lVert \\cdot \\rVert_2$ is the Euclidean norm.\n- Test Cases (as tuples of $(d, N, s)$):\n    - $(1, 20000, 7)$\n    - $(2, 100000, 11)$\n    - $(8, 300000, 2025)$\n    - $(12, 500000, 123)$\n    - $(20, 500000, 99991)$\n- Output Specification: Each numerical result must be rounded to exactly $6$ decimal places.\n\n**Step 2: Validate Using Extracted Givens**\n\nI will now assess the validity of the problem based on the established criteria.\n- **Scientifically Grounded**: The problem is a classic application of Monte Carlo integration, a fundamental and widely used technique in computational physics, engineering, and applied mathematics. The definitions for the hypersphere, hypercube, and the Monte Carlo estimator are standard and mathematically correct. The problem rests on the principles of probability theory and statistical estimation. It is entirely sound.\n- **Well-Posed**: The problem is well-posed. For each test case, all necessary parameters ($d$, $N$, $s$) are provided. The use of a seeded pseudo-random number generator ensures that the sequence of random vectors $X_i$ is deterministic, leading to a unique and computable value for the estimator $\\widehat{R}_N(d,s)$.\n- **Objective**: The problem is stated using precise, unambiguous mathematical language. It is free from any subjective or speculative content.\n\nBased on this analysis, the problem does not exhibit any of the flaws listed in the validation checklist. It is scientifically sound, well-posed, objective, and directly related to the specified topic of Monte Carlo methods.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. I will proceed with formulating and presenting the solution.\n\n### Solution\n\nThe objective is to compute the estimator $\\widehat{R}_N(d,s)$ for several test cases. This estimator approximates the ratio $R(d) = \\frac{\\mathrm{Vol}(S_d)}{\\mathrm{Vol}(C_d)}$. The methodology is based on the principles of Monte Carlo integration.\n\nLet $X$ be a random vector uniformly distributed in the hypercube $C_d$. The probability that this vector lies within the inscribed hypersphere $S_d$ is given by the ratio of their volumes:\n$$\nP(X \\in S_d) = \\frac{\\int_{C_d} \\mathbf{1}\\{x \\in S_d\\} dx}{\\int_{C_d} 1 dx} = \\frac{\\mathrm{Vol}(S_d)}{\\mathrm{Vol}(C_d)} = R(d)\n$$\nwhere $\\mathbf{1}\\{x \\in S_d\\}$ is the indicator function that is $1$ if $x \\in S_d$ and $0$ otherwise.\n\nThe problem defines an estimator for this probability. We generate $N$ independent random vectors $X_1, X_2, \\dots, X_N$, each uniformly distributed in $C_d$. For each vector $X_i$, we define a Bernoulli random variable $Z_i = \\mathbf{1}\\{X_i \\in S_d\\}$. The condition $X_i \\in S_d$ is equivalent to $\\lVert X_i \\rVert_2 \\le 1$. The expectation of each $Z_i$ is precisely the probability $R(d)$:\n$$\nE[Z_i] = 1 \\cdot P(Z_i=1) + 0 \\cdot P(Z_i=0) = P(X_i \\in S_d) = R(d)\n$$\nThe estimator $\\widehat{R}_N(d,s)$ is the sample mean of these $N$ Bernoulli trials:\n$$\n\\widehat{R}_N(d,s) = \\frac{1}{N} \\sum_{i=1}^N Z_i = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\lVert X_i \\rVert_2 \\le 1\\}\n$$\nBy the Law of Large Numbers, this sample mean converges to the true expectation as $N$ approaches infinity:\n$$\n\\lim_{N \\to \\infty} \\widehat{R}_N(d,s) = R(d)\n$$\nThis provides the theoretical justification for the method. The prescribed algorithm for computing $\\widehat{R}_N(d,s)$ for a given set of parameters $(d, N, s)$ is as follows:\n\n1.  **Initialization**: Initialize a pseudo-random number generator with the specified integer seed $s$. This ensures reproducibility of the results.\n\n2.  **Sample Generation**: Generate a set of $N$ random vectors, $\\{X_1, \\dots, X_N\\}$, where each $X_i = (x_{i1}, x_{i2}, \\dots, x_{id})$ is a point in $\\mathbb{R}^d$. To ensure the vectors are uniformly distributed in the hypercube $C_d = [-1, 1]^d$, each component $x_{ij}$ must be drawn from the uniform distribution $U[-1, 1]$. This is achieved computationally by generating an $N \\times d$ matrix of floating-point numbers where each entry is an independent sample from $U[-1, 1]$.\n\n3.  **Condition Checking**: For each vector $X_i$, determine if it lies inside the unit hypersphere $S_d$. This is done by checking if its Euclidean norm is less than or equal to $1$. For computational efficiency, it is preferable to check the squared norm:\n    $$\n    \\lVert X_i \\rVert_2 \\le 1 \\iff \\lVert X_i \\rVert_2^2 \\le 1^2 \\iff \\sum_{j=1}^d x_{ij}^2 \\le 1\n    $$\n    This avoids the computationally expensive square root operation.\n\n4.  **Estimation**: Count the number of vectors, let us call it $M$, that satisfy the condition from the previous step. This count is equivalent to the sum of the indicator functions: $M = \\sum_{i=1}^N \\mathbf{1}\\{\\lVert X_i \\rVert_2^2 \\le 1\\}$. The Monte Carlo estimate is then calculated as the ratio:\n    $$\n    \\widehat{R}_N(d,s) = \\frac{M}{N}\n    $$\n5.  **Finalization**: The procedure is repeated for each test case $(d, N, s)$, and the resulting estimate is rounded to $6$ decimal places as required. The phenomenon of the \"curse of dimensionality\" will become apparent, where for high dimensions $d$, the volume of the hypersphere becomes exceedingly small relative to the hypercube, and the estimate $\\widehat{R}_N(d,s)$ rapidly approaches zero. For $d=20$, it is statistically probable that $M=0$, yielding an estimate of $0$.\n\nThis completes the theoretical framework and algorithmic design. The implementation will proceed based on this logic.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Monte Carlo estimate of the ratio of a d-dimensional hypersphere's\n    volume to that of its enclosing hypercube for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is in the format (d, N, s), where:\n    # d: dimension of the space\n    # N: number of samples\n    # s: seed for the pseudo-random number generator\n    test_cases = [\n        (1, 20000, 7),\n        (2, 100000, 11),\n        (8, 300000, 2025),\n        (12, 500000, 123),\n        (20, 500000, 99991)\n    ]\n\n    results = []\n    for d, N, s in test_cases:\n        # Initialize the pseudo-random number generator with the specified seed for reproducibility.\n        rng = np.random.default_rng(s)\n\n        # Generate N random vectors in d-dimensional space.\n        # Each component of each vector is drawn from the uniform distribution on [-1, 1].\n        # This creates an N x d matrix of points uniformly sampled from the hypercube C_d.\n        # The size parameter is (number of rows, number of columns), i.e., (N, d).\n        samples = rng.uniform(-1, 1, size=(N, d))\n\n        # For each sample vector, calculate its squared Euclidean norm.\n        # This is more computationally efficient than calculating the norm itself,\n        # as it avoids the square root operation.\n        # The condition ||x||_2 <= 1 is equivalent to ||x||_2^2 <= 1.\n        # The sum is performed along axis=1 to sum the squared components for each vector (row).\n        squared_norms = np.sum(samples**2, axis=1)\n\n        # Count the number of samples whose squared norm is less than or equal to 1.\n        # These are the points that lie within the unit hypersphere S_d.\n        count_inside = np.sum(squared_norms <= 1)\n\n        # The estimator is the ratio of points inside the hypersphere to the total number of points.\n        # This ratio approximates the volume ratio R(d).\n        estimate = count_inside / N\n\n        # Per the problem specification, the final result must be rounded to 6 decimal places.\n        # We format the number as a string to ensure exactly 6 decimal places are shown.\n        results.append(f\"{estimate:.6f}\")\n\n    # Final print statement in the exact required format: a comma-separated list in brackets.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In our final practice, we venture into the domain of statistical physics to simulate a complex system and identify one of its critical properties . You will estimate the site percolation threshold for a square lattice, the point at which a global connected path first emerges from local random connections. This exercise exemplifies the use of Monte Carlo simulation to study emergent phenomena and highlights the synergy between probability theory and efficient data structures in modern computational engineering.",
            "id": "2415272",
            "problem": "You are to implement a Monte Carlo simulation program to estimate the site percolation threshold on a square lattice. Consider a square grid with $n \\times n$ sites, with free boundaries, where each site is either open or closed. A configuration percolates if there exists a path of adjacent open sites connecting the top edge to the bottom edge, where adjacency is defined by $4$-neighbor connectivity (up, down, left, right). In each simulation trial, start with all sites closed and open sites one at a time in a uniformly random order without replacement until percolation first occurs. Let $N = n^2$. For a given trial, let $K$ be the number of open sites at the instant when percolation first occurs; define the percolation threshold observation for that trial as the fraction $K/N$. Repeat this process independently for a specified number of trials and estimate the percolation threshold by the arithmetic mean of the observed fractions across trials.\n\nBase your reasoning and algorithmic design solely on the following foundational elements: the definition of site percolation on a lattice, the definition of independence and identically distributed random variables across trials, the definition of the arithmetic mean as a sampling estimator, and the strong law of large numbers and central limit theorem from probability theory.\n\nImplementation requirements:\n- Use an algorithmic data structure that allows efficient testing of whether the current set of open sites contains a path from the top edge to the bottom edge after each site opening, without scanning the entire grid each time. You must justify your choice in your solution.\n- Each trial must use an independent uniformly random permutation of the $N$ sites to determine the opening order.\n- For each test case, report only the Monte Carlo estimate (the arithmetic mean of the recorded thresholds across trials), as a decimal rounded to exactly $4$ digits after the decimal point.\n\nTest suite:\nYour program must run the following four parameter sets and produce the estimates in the specified order:\n- Case A (happy path, target of interest): $n = 50$, number of trials $= 200$, random seed $= 12345$.\n- Case B (edge case, smallest lattice): $n = 1$, number of trials $= 200$, random seed $= 2$.\n- Case C (moderate lattice, more trials): $n = 10$, number of trials $= 300$, random seed $= 777$.\n- Case D (same size as Case A with more trials): $n = 50$, number of trials $= 300$, random seed $= 98765$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order [Case A, Case B, Case C, Case D]. Each entry must be rounded to exactly $4$ digits after the decimal point. For example, a valid output line has the form \"[0.5920,1.0000,0.5850,0.5925]\". No additional text may be printed.\n\nThere are no physical units, angles, or percentages in this task. All numerical values must be expressed as pure numbers.",
            "solution": "The problem requires the estimation of the site percolation threshold, denoted $p_c$, on an $n \\times n$ square lattice with free boundaries. This is to be achieved through a Monte Carlo simulation. The methodology is based on fundamental principles of probability theory and computational algorithm design.\n\nFirst, let us formalize the problem. The system is a square lattice with $N = n^2$ sites. In a single simulation trial, we begin with all sites designated as 'closed'. We then open sites one by one, with the order of site selection determined by a uniformly random permutation of the $N$ sites, drawn without replacement. Let $K$ be the number of open sites at the moment a continuous path of open, adjacent sites first connects the top boundary of the lattice to the bottom boundary. Adjacency is defined by the von Neumann neighborhood, or $4$-connectivity. The outcome of a single trial, $i$, is the critical fraction $p_i = K_i / N$. By conducting $M$ independent and identically distributed (i.i.d.) trials, we generate a set of observations $\\{p_1, p_2, \\ldots, p_M\\}$.\n\nThe theoretical foundation for estimating the true percolation threshold rests upon the laws of large numbers. The percolation threshold $p_c$ is a property of the infinite lattice ($n \\to \\infty$). For a finite lattice of size $n$, we are estimating the expected value of the critical fraction, $E[K/N]$. Our Monte Carlo estimator, $\\hat{p}_c$, is the arithmetic mean of the trial outcomes:\n$$ \\hat{p}_c = \\frac{1}{M} \\sum_{i=1}^{M} p_i $$\nAccording to the Strong Law of Large Numbers, as the number of trials $M$ approaches infinity, this sample mean converges almost surely to the true expected value for the given lattice size:\n$$ \\lim_{M \\to \\infty} \\hat{p}_c = E\\left[\\frac{K}{N}\\right] $$\nThe Central Limit Theorem further informs us that for a sufficiently large $M$, the distribution of the estimator $\\hat{p}_c$ is approximately normal, which allows for the quantification of statistical uncertainty, though this is not required for the present task.\n\nThe critical component of the algorithmic design is the efficient detection of the percolation event. A naive approach of performing a graph traversal, such as a Breadth-First Search (BFS) or Depth-First Search (DFS), from all top-row sites after each site is opened is computationally prohibitive. A single BFS/DFS on a grid of $N$ sites takes $O(N)$ time. Since we may need to open up to $O(N)$ sites, the total time for one trial would be $O(N^2)$, which is infeasible for the specified lattice size of $n = 50$ ($N = 2500$).\n\nA superior algorithm, and the one we shall employ, utilizes a Disjoint-Set Union (DSU) or Union-Find data structure. This data structure excels at maintaining a collection of disjoint sets and efficiently tracking connectivity. Each site on the lattice is mapped to an element in the DSU. Initially, each of the $N$ sites exists in its own singleton set. When a site is opened, we iterate through its four neighbors. If a neighbor is already open, we perform a `union` operation on the sets containing the current site and its neighbor. With optimizations such as union-by-size and path compression, the amortized time complexity of the `union` and `find` operations is nearly constant, denoted as $O(\\alpha(N))$, where $\\alpha(N)$ is the extremely slow-growing inverse Ackermann function.\n\nTo specifically test for top-to-bottom percolation, we augment the DSU data structure. For each set in the DSU, represented by its root element, we maintain two boolean flags: `is_top_connected` and `is_bottom_connected`.\n- When a new site at row $r$ and column $c$ is opened, it initially forms its own set. If $r = 0$, its set's `is_top_connected` flag is set to `true`. If $r = n-1$, its `is_bottom_connected` flag is set to `true`. For the special case $n=1$, both flags are set to `true`.\n- When two sets are merged via the `union` operation, the new merged set inherits the connectivity properties. If either of the original sets was connected to the top, the new set is. The same logic applies to bottom connectivity.\nPercolation is detected at the exact moment a set simultaneously possesses both `is_top_connected = true` and `is_bottom_connected = true` properties. This can occur either upon the opening of a single site (for $n=1$) or immediately after a `union` operation.\n\nThe overall algorithm for the simulation is as follows:\n1. For each test case, specified by lattice size $n$, number of trials $M$, and random seed, initialize a list to store trial results.\n2. Initialize a pseudo-random number generator with the given seed to ensure reproducibility.\n3. Begin the main loop, which iterates $M$ times. Each iteration is one trial.\n4. Within a trial:\n    a. Initialize an $N = n^2$ element DSU data structure, augmented with the two boolean flags per set.\n    b. Keep track of which sites are open, for example, with a boolean array.\n    c. Generate a random permutation of the site indices from $0$ to $N-1$. This sequence dictates the order in which sites are opened.\n    d. Iterate through the permuted site indices. For each site `s` being opened:\n        i. Increment the count of open sites, $K$. Mark site `s` as open.\n        ii. Initialize the percolation flags for the new set containing only `s`. Check if this new one-site cluster percolates (only possible for $n=1$).\n        iii. Identify the four neighbors of `s`. For each neighbor `t` that is already open, perform `union(s, t)`.\n        iv. After each `union` operation, check if the newly formed cluster percolates by checking the flags of its root.\n        v. If percolation is detected, calculate the fraction $p_i = K/N$, store it, and terminate the current trial, proceeding to the next one.\n5. After all $M$ trials are complete, calculate the arithmetic mean of the stored fractions $\\{p_i\\}$.\n6. Format the result to the required precision and add it to the final list of answers.\n\nThis DSU-based approach provides a time complexity of approximately $O(N \\cdot \\alpha(N))$ per trial, making the simulation for all test cases computationally efficient and practical. The case $n=1$ is a trivial edge case where percolation occurs as soon as the single site is opened, so $K=1$, $N=1$, and the threshold is always $1.0$. The algorithm correctly handles this scenario.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass UnionFind:\n    \"\"\"\n    A Disjoint-Set Union (DSU) data structure with path compression\n    and union by size, augmented for percolation checking.\n    \"\"\"\n    \n    def __init__(self, n_grid):\n        \"\"\"\n        Initializes the DSU for an n_grid x n_grid lattice.\n        \n        Args:\n            n_grid (int): The side length of the square grid.\n        \"\"\"\n        self.n = n_grid\n        self.N = n_grid * n_grid\n        self.parent = np.arange(self.N)\n        self.sz = np.ones(self.N, dtype=int)\n        \n        # Flags to track if a set is connected to the top or bottom edge.\n        # These properties are stored at the root of each set.\n        self.is_top_connected = np.zeros(self.N, dtype=bool)\n        self.is_bottom_connected = np.zeros(self.N, dtype=bool)\n\n    def find(self, i):\n        \"\"\"\n        Finds the root of the set containing element i with path compression.\n        \"\"\"\n        if self.parent[i] == i:\n            return i\n        self.parent[i] = self.find(self.parent[i])\n        return self.parent[i]\n\n    def union(self, i, j):\n        \"\"\"\n        Merges the sets containing elements i and j, using union by size.\n        Updates connectivity flags and returns True if percolation occurs.\n        \"\"\"\n        root_i = self.find(i)\n        root_j = self.find(j)\n        \n        if root_i == root_j:\n            # Already in the same set, no change.\n            return False\n\n        # Union by size heuristic\n        if self.sz[root_i] < self.sz[root_j]:\n            root_i, root_j = root_j, root_i\n        \n        self.parent[root_j] = root_i\n        self.sz[root_i] += self.sz[root_j]\n        \n        # Merge connectivity flags\n        new_top_connected = self.is_top_connected[root_i] or self.is_top_connected[root_j]\n        new_bottom_connected = self.is_bottom_connected[root_i] or self.is_bottom_connected[root_j]\n        \n        self.is_top_connected[root_i] = new_top_connected\n        self.is_bottom_connected[root_i] = new_bottom_connected\n        \n        # Check for percolation\n        return new_top_connected and new_bottom_connected\n\ndef run_single_trial(n, rng):\n    \"\"\"\n    Runs a single percolation simulation trial on an n x n grid.\n    \n    Args:\n        n (int): The side length of the square grid.\n        rng (numpy.random.Generator): The random number generator.\n\n    Returns:\n        float: The percolation threshold (K/N) for this trial.\n    \"\"\"\n    N = n * n\n    if n == 0:\n        return 0.0\n\n    uf = UnionFind(n)\n    is_open = np.zeros(N, dtype=bool)\n    \n    site_order = rng.permutation(N)\n    \n    for num_opened, site_idx in enumerate(site_order, 1):\n        is_open[site_idx] = True\n        \n        row, col = divmod(site_idx, n)\n        \n        # Initialize flags for the newly opened site's set\n        root = uf.find(site_idx)\n        if row == 0:\n            uf.is_top_connected[root] = True\n        if row == n - 1:\n            uf.is_bottom_connected[root] = True\n            \n        # Check if the single-site cluster percolates (only for n=1)\n        if uf.is_top_connected[root] and uf.is_bottom_connected[root]:\n            return num_opened / N\n            \n        # Check and union with open neighbors\n        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n            neighbor_row, neighbor_col = row + dr, col + dc\n            \n            if 0 <= neighbor_row < n and 0 <= neighbor_col < n:\n                neighbor_idx = neighbor_row * n + neighbor_col\n                if is_open[neighbor_idx]:\n                    if uf.union(site_idx, neighbor_idx):\n                        return num_opened / N\n    \n    # This part should not be reached in a valid percolation setup\n    # where the grid can become fully connected.\n    return 1.0\n\ndef run_simulation(n, num_trials, seed):\n    \"\"\"\n    Runs the full Monte Carlo simulation for a given parameter set.\n    \n    Args:\n        n (int): The side length of the square grid.\n        num_trials (int): The number of independent trials to run.\n        seed (int): The seed for the random number generator.\n\n    Returns:\n        float: The estimated percolation threshold.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    thresholds = []\n    \n    for _ in range(num_trials):\n        threshold = run_single_trial(n, rng)\n        thresholds.append(threshold)\n        \n    return np.mean(thresholds)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, num_trials, random_seed)\n        (50, 200, 12345),   # Case A\n        (1, 200, 2),        # Case B\n        (10, 300, 777),     # Case C\n        (50, 300, 98765),   # Case D\n    ]\n\n    results = []\n    for n, num_trials, seed in test_cases:\n        mean_threshold = run_simulation(n, num_trials, seed)\n        results.append(f\"{mean_threshold:.4f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}