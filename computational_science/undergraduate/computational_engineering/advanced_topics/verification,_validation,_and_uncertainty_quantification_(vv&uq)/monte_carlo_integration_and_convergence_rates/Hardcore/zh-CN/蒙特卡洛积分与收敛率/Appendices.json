{
    "hands_on_practices": [
        {
            "introduction": "蒙特卡罗方法的基础是中心极限定理，它预言了估计误差会随着样本数量 $N$ 的增加而以特定的速率收敛。本练习旨在通过数值实验来亲手验证这一理论预测的 $N^{-1/2}$ 收敛率。通过运行模拟并分析结果，你将对估计误差如何随样本数量增加而减小有一个具体的认识，这是所有蒙特卡罗分析的基石 ()。",
            "id": "2414889",
            "problem": "一块二维金属板占据单位平方区域，总面积等于 $1$。时间以由 $k \\in \\mathbb{N}$ 索引的离散步长进行测量。在每个时间索引 $k$，板的边界温度在空间上是均匀的，等于一个随机温度 $X_k$（单位为开尔文），其中 $\\{X_k\\}_{k \\ge 1}$ 是独立同分布的随机变量，其分布根据每个测试用例指定。假设相对于边界变化之间的时间，热传导足够快，因此在每个时间索引 $k$，板的内部温度场在空间上是均匀的，并等于边界温度 $X_k$。因此，在时间索引 $k$ 时，板的空间平均温度等于 $X_k$，而长时间平均板温等于数学期望 $\\mu = \\mathbb{E}[X_1]$（单位为开尔文）。$\\mu$ 的估计是一个关于 $X_1$ 分布的蒙特卡洛积分问题。\n\n对于下文的每个测试用例，请考虑以下定义。对于一个正整数 $n$，定义估计量 $\\widehat{\\mu}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$，其中 $X_1, \\dots, X_n$ 是从测试用例指定的 $X_1$ 的定律中抽取的独立样本。对于一个样本大小列表 $\\{n_j\\}_{j=1}^{J}$ 和一个正整数 $R$，为每个 $n_j$ 定义经验平均绝对误差\n$$\nM_{n_j} \\;=\\; \\frac{1}{R} \\sum_{r=1}^{R} \\left| \\widehat{\\mu}^{(r)}_{n_j} - \\mu \\right|,\n$$\n其中 $\\widehat{\\mu}^{(r)}_{n_j}$ 表示 $\\widehat{\\mu}_{n_j}$ 的一个独立重复实验。定义经验收敛速率指数 $\\widehat{r}$ 为对点 $\\left(x_j, y_j\\right)$（其中 $x_j = \\ln(n_j)$ 和 $y_j = \\ln(M_{n_j})$）进行线性拟合 $y = a + \\widehat{r}\\,x$ 的最小二乘斜率，其中 $\\ln(\\cdot)$ 表示自然对数。量 $\\widehat{r}$ 是无量纲的。每个测试用例还指定了伪随机数生成器的种子 $s$，以确保可复现性。\n\n测试套件：\n- 测试用例 1：$X_1 \\sim \\mathrm{Uniform}([0,1])$。精确均值为 $\\mu = \\frac{1}{2}$（单位为开尔文）。使用样本大小 $n \\in \\{100, 300, 1000, 3000, 10000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 12345$。\n- 测试用例 2：$X_1 \\sim \\mathrm{Beta}(\\alpha,\\beta)$，其中 $\\alpha = \\frac{1}{2}$ 和 $\\beta = \\frac{1}{2}$，支撑集为 $[0,1]$。精确均值为 $\\mu = \\frac{\\alpha}{\\alpha+\\beta} = \\frac{1}{2}$（单位为开尔文）。使用样本大小 $n \\in \\{100, 300, 1000, 3000, 10000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 2023$。\n- 测试用例 3：$X_1$ 是一个两点混合分布：$X_1 = 0$ 的概率为 $p = \\frac{9}{10}$，$X_1 = 1$ 的概率为 $1-p = \\frac{1}{10}$。精确均值为 $\\mu = \\frac{1}{10}$（单位为开尔文）。使用样本大小 $n \\in \\{100, 300, 1000, 3000, 10000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 777$。\n- 测试用例 4：$X_1 \\sim \\mathrm{Uniform}([0.49, 0.51])$。精确均值为 $\\mu = 0.5$（单位为开尔文）。使用样本大小 $n \\in \\{30, 100, 300, 1000, 3000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 4242$。\n\n角度单位不适用。所有温度单位均为开尔文。最终报告的量是四个实数 $\\widehat{r}_1, \\widehat{r}_2, \\widehat{r}_3, \\widehat{r}_4$，每个测试用例一个，各自等于上面定义的经验收敛速率指数。将每个报告的数字表示为小数（无百分号），并四舍五入到 $3$ 位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，格式为方括号内以逗号分隔的列表，按测试用例 1 到 4 的顺序排列，例如 $[\\widehat{r}_1,\\widehat{r}_2,\\widehat{r}_3,\\widehat{r}_4]$。",
            "solution": "问题陈述经评估有效。它在科学上以蒙特卡洛方法的理论为基础，问题设定良好，提供了所有必要信息，并且其表述是客观的。不存在不一致、模糊不清或事实不健全之处。\n\n该问题涉及对均值的蒙特卡洛估计量的收敛速率进行数值估计。涉及金属板的物理框架是一个类比；核心任务是统计任务。对于每个测试用例，我们被要求使用样本均值估计量 $\\widehat{\\mu}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$ 来估计随机变量 $X_1$ 的均值 $\\mu = \\mathbb{E}[X_1]$，这是基于 $n$ 个独立同分布的样本 $X_1, \\dots, X_n$。\n\n该估计量的收敛速率是计算统计学中的一个核心结果。根据中心极限定理 (Central Limit Theorem, CLT)，对于具有有限均值 $\\mu$ 和有限非零方差 $\\sigma^2 = \\mathrm{Var}(X_1)$ 的一系列独立同分布随机变量 $\\{X_i\\}$，样本均值估计量的分布收敛于正态分布。具体来说，当 $n \\to \\infty$ 时，随机变量 $\\sqrt{n}(\\widehat{\\mu}_n - \\mu)$ 在分布上收敛于一个正态随机变量 $\\mathcal{N}(0, \\sigma^2)$。\n\n这意味着对于较大的 $n$，估计量的误差 $\\widehat{\\mu}_n - \\mu$ 近似服从 $\\mathcal{N}(0, \\sigma^2/n)$ 分布。问题定义了平均绝对误差，其理论值为 $M_n = \\mathbb{E}[|\\widehat{\\mu}_n - \\mu|]$。使用正态近似，我们可以将 $M_n$ 与样本大小 $n$ 联系起来：\n$$\nM_n = \\mathbb{E}[|\\widehat{\\mu}_n - \\mu|] \\approx \\mathbb{E}\\left[\\left|\\frac{\\sigma}{\\sqrt{n}} Z\\right|\\right] = \\frac{\\sigma}{\\sqrt{n}} \\mathbb{E}[|Z|]\n$$\n其中 $Z \\sim \\mathcal{N}(0,1)$ 是一个标准正态随机变量。量 $\\mathbb{E}[|Z|] = \\sqrt{2/\\pi}$ 是一个常数。因此，我们有以下渐近关系：\n$$\nM_n \\propto n^{-1/2}\n$$\n这种比例关系表明，标准蒙特卡洛估计量的平均绝对误差以 $n^{-1/2}$ 的速率收敛于零。\n\n问题要求我们找到这个收敛速率指数的经验估计值。这是通过对数变换后的数据点 $(x_j, y_j)$（其中 $x_j = \\ln(n_j)$ 和 $y_j = \\ln(M_{n_j})$）进行线性最小二乘拟合来完成的。对渐近关系取自然对数，得到：\n$$\n\\ln(M_n) \\approx \\ln(C) - \\frac{1}{2} \\ln(n)\n$$\n其中 $C$ 是一个比例常数。这是一个形如 $y = a + \\widehat{r} x$ 的线性方程，其理论斜率（收敛速率指数）为 $\\widehat{r} = -1/2 = -0.5$。\n\n对于所有具有有限方差的分布，其函数的蒙特卡洛积分的理论速率 $-0.5$ 是普适的。测试用例中指定的所有四种分布都具有有限方差：\n1. 对于 $X_1 \\sim \\mathrm{Uniform}([0,1])$，$\\sigma^2 = 1/12$。\n2. 对于 $X_1 \\sim \\mathrm{Beta}(1/2, 1/2)$，$\\sigma^2 = 1/8$。\n3. 对于两点混合分布（伯努利试验），$\\sigma^2 = p(1-p) = (1/10)(9/10) = 9/100$。\n4. 对于 $X_1 \\sim \\mathrm{Uniform}([0.49, 0.51])$，$\\sigma^2 = (0.51-0.49)^2/12 = (0.02)^2/12 \\approx 3.33 \\times 10^{-5}$。\n\n由于所有方差都是有限的，因此在所有四个测试用例中，理论收敛速率指数均为 $-0.5$。问题中描述的程序是一个用于验证该理论速率的数值实验。我们将为每个测试用例实现此程序。\n\n每个测试用例的算法如下：\n1. 设置伪随机数生成器种子 $s$ 以确保可复现性。\n2. 对于所提供列表中的每个样本大小 $n_j$：\n    a. 执行 $R$ 次独立的模拟重复实验。\n    b. 在每次重复实验 $r \\in \\{1, \\dots, R\\}$ 中，从指定的 $X_1$ 分布中生成 $n_j$ 个随机样本。\n    c. 计算样本均值 $\\widehat{\\mu}^{(r)}_{n_j}$。\n    d. 计算绝对误差 $|\\widehat{\\mu}^{(r)}_{n_j} - \\mu|$，其中 $\\mu$ 是给定的精确均值。\n    e. 在 $R$ 次重复实验后，计算经验平均绝对误差 $M_{n_j} = \\frac{1}{R} \\sum_{r=1}^{R} |\\widehat{\\mu}^{(r)}_{n_j} - \\mu|$。\n3. 创建一组数据点 $(x_j, y_j)$，其中 $x_j = \\ln(n_j)$ 和 $y_j = \\ln(M_{n_j})$。\n4. 对这些点进行简单线性回归，以找到最佳拟合线 $y = a + \\widehat{r}x$ 的斜率 $\\widehat{r}$。该斜率即为经验收敛速率指数。\n5. 然后将结果四舍五入到 $3$ 位小数。\n\n将对所有四个测试用例执行此程序，以获得值 $\\widehat{r}_1, \\widehat{r}_2, \\widehat{r}_3, \\widehat{r}_4$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Monte Carlo convergence rate problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Uniform(0,1)\",\n            \"dist_gen\": lambda rng, size: rng.uniform(0, 1, size),\n            \"mu\": 0.5,\n            \"n_values\": [100, 300, 1000, 3000, 10000],\n            \"R\": 400,\n            \"seed\": 12345\n        },\n        {\n            \"name\": \"Beta(0.5, 0.5)\",\n            \"dist_gen\": lambda rng, size: rng.beta(0.5, 0.5, size),\n            \"mu\": 0.5,\n            \"n_values\": [100, 300, 1000, 3000, 10000],\n            \"R\": 400,\n            \"seed\": 2023\n        },\n        {\n            \"name\": \"Two-point mixture\",\n            \"dist_gen\": lambda rng, size: rng.choice([0, 1], size=size, p=[0.9, 0.1]),\n            \"mu\": 0.1,\n            \"n_values\": [100, 300, 1000, 3000, 10000],\n            \"R\": 400,\n            \"seed\": 777\n        },\n        {\n            \"name\": \"Uniform(0.49, 0.51)\",\n            \"dist_gen\": lambda rng, size: rng.uniform(0.49, 0.51, size),\n            \"mu\": 0.5,\n            \"n_values\": [30, 100, 300, 1000, 3000],\n            \"R\": 400,\n            \"seed\": 4242\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        dist_gen = case[\"dist_gen\"]\n        mu = case[\"mu\"]\n        n_values = case[\"n_values\"]\n        R = case[\"R\"]\n        seed = case[\"seed\"]\n\n        rng = np.random.default_rng(seed)\n        \n        log_n_values = []\n        log_M_n_values = []\n\n        for n in n_values:\n            # Store absolute errors for R replicates\n            absolute_errors = np.zeros(R)\n            \n            for r in range(R):\n                # Generate n samples\n                samples = dist_gen(rng, n)\n                # Compute sample mean\n                mu_hat = np.mean(samples)\n                # Compute absolute error\n                absolute_errors[r] = np.abs(mu_hat - mu)\n            \n            # Compute empirical mean absolute error M_n\n            M_n = np.mean(absolute_errors)\n            \n            # Store log-transformed values for regression\n            log_n_values.append(np.log(n))\n            log_M_n_values.append(np.log(M_n))\n            \n        # Perform linear least-squares regression on (log(n), log(M_n))\n        # np.polyfit returns [slope, intercept] for degree 1\n        x = np.array(log_n_values)\n        y = np.array(log_M_n_values)\n        \n        # The slope r_hat is the first element of the result\n        r_hat = np.polyfit(x, y, 1)[0]\n        \n        results.append(r_hat)\n\n    # Format the final output as specified\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "重要性采样是一种通过降低方差来加速蒙特卡罗收敛的强大技术，其关键在于选择一个与被积函数形状相似的“提议分布”。本练习将引导你分析并比较两种不同的提议密度，让你从解析和计算两个层面，亲身体会一个好的选择如何直接转化为在相同计算预算下更小的估计误差 ()。",
            "id": "2414928",
            "problem": "考虑积分\n$$\nI(a) \\;=\\; \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\,\\sin^{2}(a\\,x)\\,dx,\n$$\n其中 $a \\ge 0$ 是一个实值频率参数，角度以弧度为单位。令 $f_{a}(x) = e^{-x^{2}}\\sin^{2}(a\\,x)$ 在 $(-\\infty,\\infty)$ 上。在 $(-\\infty,\\infty)$ 上定义两个绝对连续的提议密度：\n$$\nq_{1}(x) \\;=\\; \\frac{1}{\\sqrt{\\pi}}\\,e^{-x^{2}}, \n\\qquad\nq_{2}(x) \\;=\\; \\frac{1}{\\sqrt{2\\pi}}\\,e^{-x^{2}/2}.\n$$\n对于任何 $a \\ge 0$ 和任何样本大小 $N \\in \\mathbb{N}$，考虑基于从 $q(x) \\in \\{q_{1}(x),q_{2}(x)\\}$ 中抽取的独立样本的 $I(a)$ 的标准重要性抽样估计量。令单样本重要性权重为 $Y_{q}(a;X) = f_{a}(X)/q(X)$，其中 $X \\sim q$，并将估计量表示为 $N$ 个独立 $Y_{q}(a;X)$ 副本的样本均值。对于给定的 $q$ 和 $N$，标准误差定义为该估计量的标准差。\n\n您的任务是：\n- 精确推导 $I(a)$。\n- 以闭合形式推导当 $q(x)=q_{1}(x)$ 和 $q(x)=q_{2}(x)$ 时估计量的精确标准误差，作为 $a$ 和 $N$ 的函数。\n\n使用您的推导计算以下 $(a,N)$ 对测试套件所需的输出：\n- 测试用例 1：$a = 100$，$N = 10000$。\n- 测试用例 2：$a = 0.5$，$N = 5000$。\n- 测试用例 3：$a = 0$，$N = 1234$。\n\n要求的最终输出格式：\n- 您的程序必须生成一个单行，其中包含一个用方括号括起来的逗号分隔列表。\n- 对于每个测试用例，按给定顺序输出三个实数，顺序如下：$I(a)$ 的精确值，给定 $N$ 时 $q_{1}(x)$ 的精确标准误差，以及给定 $N$ 时 $q_{2}(x)$ 的精确标准误差。\n- 因此，最终输出必须是一个长度为 $9$ 的单一列表：\n$$\n\\big[ I(a_{1}),\\ \\mathrm{SE}_{q_{1}}(a_{1},N_{1}),\\ \\mathrm{SE}_{q_{2}}(a_{1},N_{1}),\\ I(a_{2}),\\ \\mathrm{SE}_{q_{1}}(a_{2},N_{2}),\\ \\mathrm{SE}_{q_{2}}(a_{2},N_{2}),\\ I(a_{3}),\\ \\mathrm{SE}_{q_{1}}(a_{3},N_{3}),\\ \\mathrm{SE}_{q_{2}}(a_{3},N_{3}) \\big].\n$$\n所有输出都必须是实数（以小数形式）。本问题不涉及物理单位。",
            "solution": "所述问题在数学和科学上是合理的。它提法得当、完整且没有歧义。因此，我们将着手解决它。\n\n任务是推导积分 $I(a)$ 的精确值以及该积分的两种不同重要性抽样估计量的精确标准误差。\n\n积分为\n$$I(a) = \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\sin^{2}(a\\,x)\\,dx$$\n其中 $a \\ge 0$。被积函数为 $f_{a}(x) = e^{-x^{2}}\\sin^{2}(a\\,x)$。\n\n**第一部分：$I(a)$ 的精确推导**\n\n为计算 $I(a)$，我们使用三角恒等式 $\\sin^2(\\theta) = \\frac{1 - \\cos(2\\theta)}{2}$。将其应用于被积函数得到：\n$$I(a) = \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\left(\\frac{1 - \\cos(2ax)}{2}\\right) dx$$\n我们可以将其分为两个积分：\n$$I(a) = \\frac{1}{2} \\int_{-\\infty}^{\\infty} e^{-x^{2}} dx - \\frac{1}{2} \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\cos(2ax)\\,dx$$\n第一个积分是标准高斯积分，其值是已知的：\n$$\\int_{-\\infty}^{\\infty} e^{-x^{2}} dx = \\sqrt{\\pi}$$\n第二个积分可以通过考虑高斯函数的傅里叶变换来求解。$g(x) = e^{-bx^2}$ 的傅里叶变换由 $\\hat{g}(k) = \\int_{-\\infty}^{\\infty} e^{-bx^2} e^{-ikx} dx = \\sqrt{\\frac{\\pi}{b}} e^{-k^2/(4b)}$ 给出。我们表达式中的积分是指数中带有正号的此类变换的实部，对于实偶函数，这会产生相同的结果。\n$$\\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(2ax) dx = \\mathrm{Re}\\left[ \\int_{-\\infty}^{\\infty} e^{-x^2} e^{i(2a)x} dx \\right]$$\n使用傅里叶变换公式，令 $b=1$ 和 $k=2a$，我们发现：\n$$\\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(2ax) dx = \\sqrt{\\pi} e^{-(2a)^2/4} = \\sqrt{\\pi} e^{-a^2}$$\n将这些结果代回 $I(a)$ 的表达式中，我们得到：\n$$I(a) = \\frac{1}{2} \\sqrt{\\pi} - \\frac{1}{2} \\sqrt{\\pi} e^{-a^2} = \\frac{\\sqrt{\\pi}}{2} (1 - e^{-a^2})$$\n\n**第二部分：标准误差的推导**\n\n使用 $N$ 个样本 $X_i \\sim q(x)$ 对 $I(a)$ 的重要性抽样估计量是 $\\hat{I}_N = \\frac{1}{N} \\sum_{i=1}^{N} Y_i$，其中 $Y_i = \\frac{f_a(X_i)}{q(X_i)}$ 是独立同分布的随机变量。该估计量的标准误差定义为其标准差：\n$$\\mathrm{SE}(\\hat{I}_N) = \\mathrm{Std}\\left( \\frac{1}{N} \\sum_{i=1}^{N} Y_i \\right) = \\frac{\\mathrm{Std}(Y_1)}{\\sqrt{N}} = \\frac{\\sqrt{\\mathrm{Var}(Y_1)}}{\\sqrt{N}}$$\n单个样本 $Y = Y_q(a;X)$ 的方差由 $\\mathrm{Var}(Y) = \\mathbb{E}_{X \\sim q}[Y^2] - (\\mathbb{E}_{X \\sim q}[Y])^2$ 给出。\n$Y$ 的均值是：\n$$\\mathbb{E}_{X \\sim q}[Y] = \\int_{-\\infty}^{\\infty} \\frac{f_a(x)}{q(x)} q(x) dx = \\int_{-\\infty}^{\\infty} f_a(x) dx = I(a)$$\n因此，我们只需要计算二阶矩 $\\mathbb{E}_{X \\sim q}[Y^2]$：\n$$\\mathbb{E}_{X \\sim q}[Y^2] = \\int_{-\\infty}^{\\infty} \\left(\\frac{f_a(x)}{q(x)}\\right)^2 q(x) dx = \\int_{-\\infty}^{\\infty} \\frac{f_a(x)^2}{q(x)} dx$$\n我们必须对每个提议密度 $q_1(x)$ 和 $q_2(x)$ 进行此计算。\n\n**情况 1：提议密度 $q_1(x) = \\frac{1}{\\sqrt{\\pi}} e^{-x^2}$**\n\n单样本权重为：\n$$Y_{q_1}(a;x) = \\frac{f_a(x)}{q_1(x)} = \\frac{e^{-x^2} \\sin^2(ax)}{\\frac{1}{\\sqrt{\\pi}} e^{-x^2}} = \\sqrt{\\pi} \\sin^2(ax)$$\n二阶矩为：\n$$\\mathbb{E}[Y_{q_1}^2] = \\int_{-\\infty}^{\\infty} \\frac{(e^{-x^2} \\sin^2(ax))^2}{\\frac{1}{\\sqrt{\\pi}} e^{-x^2}} dx = \\sqrt{\\pi} \\int_{-\\infty}^{\\infty} e^{-x^2} \\sin^4(ax) dx$$\n我们使用降幂恒等式 $\\sin^4(\\theta) = \\frac{3 - 4\\cos(2\\theta) + \\cos(4\\theta)}{8}$。\n$$\\mathbb{E}[Y_{q_1}^2] = \\frac{\\sqrt{\\pi}}{8} \\int_{-\\infty}^{\\infty} e^{-x^2} (3 - 4\\cos(2ax) + \\cos(4ax)) dx$$\n这可以分解为三种先前已确定的积分类型：\n$$\\mathbb{E}[Y_{q_1}^2] = \\frac{\\sqrt{\\pi}}{8} \\left( 3\\int_{-\\infty}^{\\infty} e^{-x^2} dx - 4\\int_{-\\infty}^{\\infty} e^{-x^2}\\cos(2ax)dx + \\int_{-\\infty}^{\\infty} e^{-x^2}\\cos(4ax)dx \\right)$$\n$$\\mathbb{E}[Y_{q_1}^2] = \\frac{\\sqrt{\\pi}}{8} \\left( 3\\sqrt{\\pi} - 4\\sqrt{\\pi}e^{-a^2} + \\sqrt{\\pi}e^{-(2a)^2} \\right) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2})$$\n方差为 $\\mathrm{Var}(Y_{q_1}) = \\mathbb{E}[Y_{q_1}^2] - (I(a))^2$：\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2}) - \\left(\\frac{\\sqrt{\\pi}}{2}(1-e^{-a^2})\\right)^2$$\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2}) - \\frac{\\pi}{4}(1 - 2e^{-a^2} + e^{-2a^2})$$\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2} - 2 + 4e^{-a^2} - 2e^{-2a^2}) = \\frac{\\pi}{8} (1 - 2e^{-2a^2} + e^{-4a^2})$$\n这可以简化为一个完全平方：\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (1 - e^{-2a^2})^2$$\n大小为 $N$ 的样本的标准误差是：\n$$\\mathrm{SE}_{q_1}(a, N) = \\frac{\\sqrt{\\mathrm{Var}(Y_{q_1})}}{\\sqrt{N}} = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{8}} (1-e^{-2a^2})$$\n由于 $a \\ge 0$，项 $1-e^{-2a^2}$ 是非负的。\n\n**情况 2：提议密度 $q_2(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$**\n\n二阶矩积分为：\n$$\\mathbb{E}[Y_{q_2}^2] = \\int_{-\\infty}^{\\infty} \\frac{(e^{-x^2} \\sin^2(ax))^2}{\\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}} dx = \\sqrt{2\\pi} \\int_{-\\infty}^{\\infty} e^{-2x^2} e^{x^2/2} \\sin^4(ax) dx$$\n$$\\mathbb{E}[Y_{q_2}^2] = \\sqrt{2\\pi} \\int_{-\\infty}^{\\infty} e^{-3x^2/2} \\sin^4(ax) dx$$\n再次使用 $\\sin^4(ax) = \\frac{1}{8} (3 - 4\\cos(2ax) + \\cos(4ax))$，我们有：\n$$\\mathbb{E}[Y_{q_2}^2] = \\frac{\\sqrt{2\\pi}}{8} \\int_{-\\infty}^{\\infty} e^{-3x^2/2} (3 - 4\\cos(2ax) + \\cos(4ax)) dx$$\n我们使用 $\\int_{-\\infty}^{\\infty} e^{-bx^2} \\cos(kx) dx = \\sqrt{\\frac{\\pi}{b}} e^{-k^2/(4b)}$ 并设 $b=3/2$ 来计算积分：\n\\begin{align*}\n\\mathbb{E}[Y_{q_2}^2] = \\frac{\\sqrt{2\\pi}}{8} \\left( 3\\sqrt{\\frac{\\pi}{3/2}} - 4\\sqrt{\\frac{\\pi}{3/2}}e^{-(2a)^2/(4 \\cdot 3/2)} + \\sqrt{\\frac{\\pi}{3/2}}e^{-(4a)^2/(4 \\cdot 3/2)} \\right) \\\\\n= \\frac{\\sqrt{2\\pi}}{8} \\sqrt{\\frac{2\\pi}{3}} \\left( 3 - 4e^{-4a^2/6} + e^{-16a^2/6} \\right) \\\\\n= \\frac{2\\pi}{8\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right) = \\frac{\\pi}{4\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right)\n\\end{align*}\n方差为 $\\mathrm{Var}(Y_{q_2}) = \\mathbb{E}[Y_{q_2}^2] - (I(a))^2$：\n$$\\mathrm{Var}(Y_{q_2}) = \\frac{\\pi}{4\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right) - \\left( \\frac{\\sqrt{\\pi}}{2}(1-e^{-a^2}) \\right)^2$$\n大小为 $N$ 的样本的标准误差是：\n$$\\mathrm{SE}_{q_2}(a, N) = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{4\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right) - \\frac{\\pi}{4}(1-e^{-a^2})^2}$$\n\n**用于计算的公式摘要**\n1.  **精确积分**： $I(a) = \\frac{\\sqrt{\\pi}}{2} (1 - e^{-a^2})$\n2.  **$q_1$ 的标准误差**： $\\mathrm{SE}_{q_1}(a, N) = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{8}} (1-e^{-2a^2})$\n3.  **$q_2$ 的标准误差**： $\\mathrm{SE}_{q_2}(a, N) = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{4\\sqrt{3}} (3 - 4e^{-2a^2/3} + e^{-8a^2/3}) - \\frac{\\pi}{4}(1-e^{-a^2})^2}$\n\n将实现这些公式以计算给定测试用例所需的值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the exact integral value and standard errors for two Monte Carlo\n    estimators for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 10000),  # Test case 1: (a=100, N=10000)\n        (0.5, 5000),   # Test case 2: (a=0.5, N=5000)\n        (0, 1234),     # Test case 3: (a=0, N=1234)\n    ]\n\n    results = []\n    \n    # Store constants to avoid recomputation\n    PI = np.pi\n    SQRT_PI = np.sqrt(PI)\n\n    for a, N in test_cases:\n        # Task 1: Calculate the exact value of the integral I(a)\n        # I(a) = (sqrt(pi)/2) * (1 - exp(-a^2))\n        a_sq = a**2\n        i_a = (SQRT_PI / 2.0) * (1.0 - np.exp(-a_sq))\n\n        # Task 2: Calculate the standard error for proposal q1(x)\n        # SE_q1(a, N) = (1/sqrt(N)) * sqrt(pi/8) * (1 - exp(-2*a^2))\n        se_q1 = (1.0 / np.sqrt(N)) * np.sqrt(PI / 8.0) * (1.0 - np.exp(-2.0 * a_sq))\n\n        # Task 3: Calculate the standard error for proposal q2(x)\n        # Var(Y_q2) = E[Y_q2^2] - (I(a))^2\n        # E[Y_q2^2] = (pi / (4*sqrt(3))) * (3 - 4*exp(-2*a^2/3) + exp(-8*a^2/3))\n        e_y2_sq_term1 = np.exp(-2.0 * a_sq / 3.0)\n        e_y2_sq_term2 = np.exp(-8.0 * a_sq / 3.0)\n        e_y2_sq = (PI / (4.0 * np.sqrt(3.0))) * (3.0 - 4.0 * e_y2_sq_term1 + e_y2_sq_term2)\n        \n        # (I(a))^2 term\n        i_a_sq = i_a**2\n        \n        var_y_q2 = e_y2_sq - i_a_sq\n        \n        # Ensure variance is non-negative to handle potential floating point inaccuracies\n        if var_y_q2  0:\n            var_y_q2 = 0.0\n            \n        se_q2 = np.sqrt(var_y_q2) / np.sqrt(N)\n        \n        results.extend([i_a, se_q1, se_q2])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "控制变量是另一种先进的方差缩减方法，其核心思想是利用一个我们已知其精确积分的简单函数来近似被积函数。通过这个近似函数来“修正”我们的蒙特卡罗估计，从而有效降低其方差。本练习将指导你完成一个完整的控制变量工作流程，从拟合多项式近似到评估性能提升，为你提供高级蒙特卡罗方法的实用技能 ()。",
            "id": "2414893",
            "problem": "您被赋予一项任务：使用蒙特卡洛（MC）积分来近似函数在单位超立方体 $[0,1]^d$ 上的积分，并通过使用基于被积函数的低阶多项式近似的控制变量来加速收敛。对于下面测试套件中的每个测试用例，您的程序必须构建一个全次数多项式控制变量，并评估其相对于普通蒙特卡洛方法的精度影响。\n\n定义与设置：\n- 令 $f: [0,1]^d \\to \\mathbb{R}$ 为一个可积函数，目标积分为 $I = \\int_{[0,1]^d} f(\\boldsymbol{x}) \\,\\mathrm{d}\\boldsymbol{x}$。\n- 一个在 $d$ 个变量中次数至多为 $k$ 的全次数多项式是形如 $p(\\boldsymbol{x}) = \\sum_{\\lvert \\boldsymbol{\\alpha} \\rvert \\le k} c_{\\boldsymbol{\\alpha}} \\,\\boldsymbol{x}^{\\boldsymbol{\\alpha}}$ 的任意多项式，其中 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_0^d$，$\\lvert \\boldsymbol{\\alpha} \\rvert = \\alpha_1 + \\cdots + \\alpha_d$，且 $\\boldsymbol{x}^{\\boldsymbol{\\alpha}} = \\prod_{j=1}^d x_j^{\\alpha_j}$。\n- 一个单项式在 $[0,1]^d$ 上的精确积分为 $\\int_{[0,1]^d} \\boldsymbol{x}^{\\boldsymbol{\\alpha}} \\,\\mathrm{d}\\boldsymbol{x} = \\prod_{j=1}^d \\frac{1}{\\alpha_j + 1}$，因此对于 $p(\\boldsymbol{x})$，其精确积分为 $\\mu_p = \\int_{[0,1]^d} p(\\boldsymbol{x}) \\,\\mathrm{d}\\boldsymbol{x} = \\sum_{\\lvert \\boldsymbol{\\alpha} \\rvert \\le k} c_{\\boldsymbol{\\alpha}} \\prod_{j=1}^d \\frac{1}{\\alpha_j + 1}$。\n- 三角函数内部使用的角度必须以弧度为单位进行解释。\n\n对于每个测试用例：\n- 使用来自 $[0,1]^d$ 上均匀分布的 $m_{\\text{fit}}$ 个独立抽样 $\\{\\boldsymbol{Z}_j\\}_{j=1}^{m_{\\text{fit}}}$，以最小二乘的方式确定最能拟合数据 $\\{(\\boldsymbol{Z}_j, f(\\boldsymbol{Z}_j))\\}$ 的、次数至多为 $k$ 的全次数多项式 $p$ 的系数 $\\{c_{\\boldsymbol{\\alpha}}\\}$。\n- 使用来自 $[0,1]^d$ 上均匀分布的一个独立的 $n$ 次抽样集合 $\\{\\boldsymbol{Y}_i\\}_{i=1}^n$ 来计算：\n  - 普通蒙特卡洛估计量 $\\hat{I}_{\\mathrm{MC}} = \\frac{1}{n} \\sum_{i=1}^n f(\\boldsymbol{Y}_i)$，\n  - 控制变量估计量 $\\hat{I}_{\\mathrm{CV}} = \\frac{1}{n} \\sum_{i=1}^n \\big(f(\\boldsymbol{Y}_i) - p(\\boldsymbol{Y}_i)\\big) + \\mu_p$。\n- 对于每种情况，使用给定的 $f$ 的精确积分 $I$ 计算每个估计量的绝对误差。然后计算比率 $r = \\frac{\\lvert \\hat{I}_{\\mathrm{CV}} - I \\rvert}{\\lvert \\hat{I}_{\\mathrm{MC}} - I \\rvert}$。\n\n被积函数及其精确积分：\n- 在一维空间中（$d = 1$）：$f_1(x) = e^{-x} \\cos(7x) + x^3$，其精确积分为\n  $$\n  I_1 = \\int_0^1 e^{-x} \\cos(7x)\\,\\mathrm{d}x + \\int_0^1 x^3\\,\\mathrm{d}x = \\Re\\!\\left(\\frac{e^{-1 + i\\,7} - 1}{-1 + i\\,7}\\right) + \\frac{1}{4}.\n  $$\n- 在二维空间中（$d = 2$）：$f_2(x,y) = \\sin(\\pi x)\\sin(\\pi y) + x\\,y$，其精确积分为\n  $$\n  I_2 = \\left(\\int_0^1 \\sin(\\pi x)\\,\\mathrm{d}x\\right)^2 + \\left(\\int_0^1 x\\,\\mathrm{d}x\\right)\\left(\\int_0^1 y\\,\\mathrm{d}y\\right) = \\frac{4}{\\pi^2} + \\frac{1}{4}.\n  $$\n\n测试套件：\n- 用例1：$f_1$，$d = 1$，多项式次数 $k = 3$，$m_{\\text{fit}} = 200$，$n = 20000$，种子 $= 123456$。\n- 用例2：$f_2$，$d = 2$，多项式次数 $k = 2$，$m_{\\text{fit}} = 500$，$n = 30000$，种子 $= 202311$。\n- 用例3：$f_1$，$d = 1$，多项式次数 $k = 0$，$m_{\\text{fit}} = 30$，$n = 5000$，种子 $= 7777$。\n- 用例4：$f_2$，$d = 2$，多项式次数 $k = 1$，$m_{\\text{fit}} = 100$，$n = 20000$，种子 $= 8888$。\n\n要求：\n- 对于每个测试用例，使用给定的种子初始化一个伪随机数生成器，并将其用于该测试用例中的所有抽样。\n- 每个测试用例的最终报告值是上面定义的比率 $r$，四舍五入到6位小数。\n- 您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为各用例的结果，并按所列用例的顺序排列，例如 $[r_1,r_2,r_3,r_4]$。",
            "solution": "该问题是有效的，因为它具有科学依据、是适定的、客观的，并为计算工程中的一个标准问题提供了一套完整且一致的要求。任务是评估蒙特卡洛积分的控制变量法的有效性，其中控制变量是被积函数的多项式近似。\n\n蒙特卡洛积分的基本原理是大数定律。对于在单位超立方体 $[0,1]^d$ 中均匀分布的随机变量 $\\boldsymbol{X}$， $f(\\boldsymbol{X})$ 的期望值就是我们希望计算的积分：$E[f(\\boldsymbol{X})] = \\int_{[0,1]^d} f(\\boldsymbol{x}) \\, \\mathrm{d}\\boldsymbol{x} = I$。通过从该分布中抽取 $n$ 个独立同分布的样本 $\\{\\boldsymbol{Y}_i\\}_{i=1}^n$，我们可以构建普通蒙特卡洛估计量，即样本均值：\n$$\n\\hat{I}_{\\mathrm{MC}} = \\frac{1}{n} \\sum_{i=1}^n f(\\boldsymbol{Y}_i)\n$$\n中心极限定理指出，该估计量的误差 $\\hat{I}_{\\mathrm{MC}} - I$ 近似服从均值为 $0$、方差为 $\\sigma_f^2/n$ 的正态分布，其中 $\\sigma_f^2 = \\text{Var}(f(\\boldsymbol{X}))$。因此，标准误差以 $n^{-1/2}$ 的速度减小，这可能是一个较慢的收敛速度。\n\n为了加速收敛，我们可以使用方差缩减技术。控制变量法就是这样一种技术。它涉及找到一个函数 $p(\\boldsymbol{x})$，该函数是 $f(\\boldsymbol{x})$ 的一个良好近似，并且其积分 $\\mu_p = \\int_{[0,1]^d} p(\\boldsymbol{x}) \\, \\mathrm{d}\\boldsymbol{x}$ 可以解析地求出。然后我们将积分 $I$ 重写为：\n$$\nI = \\int_{[0,1]^d} (f(\\boldsymbol{x}) - p(\\boldsymbol{x})) \\, \\mathrm{d}\\boldsymbol{x} + \\int_{[0,1]^d} p(\\boldsymbol{x}) \\, \\mathrm{d}\\boldsymbol{x} = \\int_{[0,1]^d} (f(\\boldsymbol{x}) - p(\\boldsymbol{x})) \\, \\mathrm{d}\\boldsymbol{x} + \\mu_p\n$$\n我们可以对新的、有望性状更好的被积函数 $g(\\boldsymbol{x}) = f(\\boldsymbol{x}) - p(\\boldsymbol{x})$ 应用蒙特卡洛积分。这得到了控制变量估计量：\n$$\n\\hat{I}_{\\mathrm{CV}} = \\frac{1}{n} \\sum_{i=1}^n (f(\\boldsymbol{Y}_i) - p(\\boldsymbol{Y}_i)) + \\mu_p\n$$\n和 $\\hat{I}_{\\mathrm{MC}}$ 一样，这是 $I$ 的一个无偏估计量。其方差为 $\\text{Var}(\\hat{I}_{\\mathrm{CV}}) = \\frac{1}{n}\\text{Var}(f(\\boldsymbol{X}) - p(\\boldsymbol{X}))$。如果 $p(\\boldsymbol{x})$ 与 $f(\\boldsymbol{x})$ 强相关，那么它们差的方差就会很小，从而在相同的样本量 $n$ 下得到更精确的估计量。\n\n该问题指定使用次数至多为 $k$ 的全次数多项式作为控制变量 $p(\\boldsymbol{x})$。这样的多项式是单项式基函数的线性组合：$p(\\boldsymbol{x}) = \\sum_{|\\boldsymbol{\\alpha}| \\le k} c_{\\boldsymbol{\\alpha}} \\boldsymbol{x}^{\\boldsymbol{\\alpha}}$。这一选择的动机是 Weierstrass 逼近定理，该定理保证了多项式可以在像 $[0,1]^d$ 这样的紧致域上逼近任何连续函数。系数 $\\{c_{\\boldsymbol{\\alpha}}\\}$ 通过最小二乘拟合确定。我们生成 $m_{\\text{fit}}$ 个样本 $\\{\\boldsymbol{Z}_j\\}_{j=1}^{m_{\\text{fit}}}$，并找到最小化误差平方和 $\\sum_{j=1}^{m_{\\text{fit}}} (f(\\boldsymbol{Z}_j) - p(\\boldsymbol{Z}_j))^2$ 的系数 $\\boldsymbol{c}$。这是一个标准的线性回归问题，可表述为最小化 $\\|\\boldsymbol{A}\\boldsymbol{c} - \\boldsymbol{b}\\|_2^2$，其中设计矩阵 $\\boldsymbol{A}$ 的元素为 $A_{j, \\boldsymbol{\\alpha}} = \\boldsymbol{Z}_j^{\\boldsymbol{\\alpha}}$，目标向量 $\\boldsymbol{b}$ 的元素为 $b_j = f(\\boldsymbol{Z}_j)$。该系统使用数值线性代数程序求解 $\\boldsymbol{c}$。\n\n一旦找到系数 $\\boldsymbol{c}$，就使用提供的公式计算多项式的精确积分 $\\mu_p$：\n$$\n\\mu_p = \\sum_{|\\boldsymbol{\\alpha}| \\le k} c_{\\boldsymbol{\\alpha}} \\left( \\int_{[0,1]^d} \\boldsymbol{x}^{\\boldsymbol{\\alpha}} \\, \\mathrm{d}\\boldsymbol{x} \\right) = \\sum_{|\\boldsymbol{\\alpha}| \\le k} c_{\\boldsymbol{\\alpha}} \\prod_{j=1}^d \\frac{1}{\\alpha_j + 1}\n$$\n\n每个测试用例的解题步骤如下：\n1.  使用指定的种子初始化一个伪随机数生成器。\n2.  定义被积函数 $f(\\boldsymbol{x})$、其维度 $d$、其精确积分 $I$、多项式次数 $k$ 以及样本量 $m_{\\text{fit}}$ 和 $n$。\n3.  生成所有满足 $|\\boldsymbol{\\alpha}| \\le k$ 的多重索引 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_0^d$ 的集合。这些索引定义了多项式基。\n4.  从 $U([0,1]^d)$ 生成 $m_{\\text{fit}}$ 个随机点 $\\{\\boldsymbol{Z}_j\\}_{j=1}^{m_{\\text{fit}}}$。\n5.  通过在每个点 $\\boldsymbol{Z}_j$ 处评估每个基单项式来构建设计矩阵 $\\boldsymbol{A}$。\n6.  通过评估 $f(\\boldsymbol{Z}_j)$ 来构建目标向量 $\\boldsymbol{b}$。\n7.  求解最小二乘问题 $\\boldsymbol{A}\\boldsymbol{c} \\approx \\boldsymbol{b}$ 以找到系数向量 $\\boldsymbol{c}$。\n8.  计算所得多项式 $p(\\boldsymbol{x})$ 的精确积分 $\\mu_p$。\n9.  从 $U([0,1]^d)$ 生成第二个独立的包含 $n$ 个随机点的集合 $\\{\\boldsymbol{Y}_i\\}_{i=1}^n$。\n10. 对这个新集合中的所有点评估 $f(\\boldsymbol{Y}_i)$ 和 $p(\\boldsymbol{Y}_i)$。$p(\\boldsymbol{Y}_i)$ 的值通过为点 $\\boldsymbol{Y}$ 构建一个设计矩阵并乘以系数向量 $\\boldsymbol{c}$ 来找到。\n11. 计算估计量 $\\hat{I}_{\\mathrm{MC}}$ 和 $\\hat{I}_{\\mathrm{CV}}$。\n12. 计算绝对误差 $|\\hat{I}_{\\mathrm{MC}} - I|$ 和 $|\\hat{I}_{\\mathrm{CV}} - I|$。\n13. 计算比率 $r = \\frac{|\\hat{I}_{\\mathrm{CV}} - I|}{|\\hat{I}_{\\mathrm{MC}} - I|}$ 并将其四舍五入到6位小数。该比率量化了使用控制变量带来的精度提升。小于1的比率表示有所改进。$k=0$ 的情况作为一个对照组，其中 $p(x)$ 是一个常数，预计比率 $r$ 为 1，这验证了估计量的逻辑。\n\n将此系统化过程应用于每个测试用例，利用数值库进行随机数生成和求解线性最小二乘问题。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\nfrom typing import List, Tuple, Callable\n\ndef solve():\n    \"\"\"\n    Solves the Monte Carlo integration problem with control variates for all test cases.\n    \"\"\"\n\n    # Define functions and their exact integrals\n    def f1(x: np.ndarray) -> np.ndarray:\n        # x is assumed to be a column vector or a 2D array of shape (N, 1)\n        return np.exp(-x[:, 0]) * np.cos(7 * x[:, 0]) + x[:, 0]**3\n\n    # I1 = Re[ (e^(-1+7i) - 1) / (-1+7i) ] + 1/4\n    # Re part = (1 - e^-1*cos(7) + 7*e^-1*sin(7)) / 50\n    I1_re_part = (1 - np.exp(-1) * np.cos(7) + 7 * np.exp(-1) * np.sin(7)) / 50\n    I1 = I1_re_part + 0.25\n\n    def f2(x: np.ndarray) -> np.ndarray:\n        # x is assumed to be an array of shape (N, 2)\n        return np.sin(np.pi * x[:, 0]) * np.sin(np.pi * x[:, 1]) + x[:, 0] * x[:, 1]\n    \n    # I2 = (integral sin(pi*x) dx)^2 + (integral x dx)^2 = (2/pi)^2 + (1/2)^2\n    I2 = 4 / (np.pi**2) + 0.25\n\n    def generate_total_degree_exponents(d: int, k: int) -> List[Tuple[int, ...]]:\n        \"\"\"\n        Generates all multi-indices alpha for d variables with total degree = k.\n        \"\"\"\n        if d == 1:\n            return [(i,) for i in range(k + 1)]\n        \n        exponents = []\n        # Using itertools.product for a more general d-dimensional case\n        for combo in itertools.product(range(k + 1), repeat=d):\n            if sum(combo) = k:\n                exponents.append(combo)\n        return exponents\n\n    def evaluate_monomials(points: np.ndarray, exponents: List[Tuple[int, ...]]) -> np.ndarray:\n        \"\"\"\n        Evaluates a basis of monomials at a set of points.\n        points: (n_points, d)\n        exponents: list of alpha tuples\n        Returns: design matrix (n_points, n_exponents)\n        \"\"\"\n        n_points, d = points.shape\n        n_exponents = len(exponents)\n        design_matrix = np.ones((n_points, n_exponents))\n        \n        for i, alpha in enumerate(exponents):\n            # np.prod(points**alpha, axis=1) is a concise way to compute x^alpha\n            design_matrix[:, i] = np.prod(np.power(points, alpha), axis=1)\n            \n        return design_matrix\n\n    test_cases = [\n        {'f': f1, 'I': I1, 'd': 1, 'k': 3, 'm_fit': 200, 'n': 20000, 'seed': 123456},\n        {'f': f2, 'I': I2, 'd': 2, 'k': 2, 'm_fit': 500, 'n': 30000, 'seed': 202311},\n        {'f': f1, 'I': I1, 'd': 1, 'k': 0, 'm_fit': 30, 'n': 5000, 'seed': 7777},\n        {'f': f2, 'I': I2, 'd': 2, 'k': 1, 'm_fit': 100, 'n': 20000, 'seed': 8888},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        f, I, d, k, m_fit, n, seed = \\\n            case['f'], case['I'], case['d'], case['k'], case['m_fit'], case['n'], case['seed']\n            \n        rng = np.random.default_rng(seed)\n\n        # Step 1: Generate basis and fit the polynomial control variate\n        exponents = generate_total_degree_exponents(d, k)\n        \n        # Generate samples for fitting\n        Z_points = rng.random((m_fit, d))\n        \n        # Build design matrix and target vector for least-squares\n        A_fit = evaluate_monomials(Z_points, exponents)\n        b_fit = f(Z_points)\n        \n        # Solve for polynomial coefficients\n        c_coeffs, _, _, _ = np.linalg.lstsq(A_fit, b_fit, rcond=None)\n\n        # Step 2: Calculate the exact integral of the polynomial\n        integral_of_monomials = np.array([1.0 / np.prod([exp + 1 for exp in alpha]) for alpha in exponents])\n        mu_p = np.dot(c_coeffs, integral_of_monomials)\n\n        # Step 3: Use an independent sample set for MC estimation\n        Y_points = rng.random((n, d))\n        \n        # Evaluate f and p at the new samples\n        f_Y = f(Y_points)\n        A_eval = evaluate_monomials(Y_points, exponents)\n        p_Y = A_eval @ c_coeffs\n\n        # Step 4: Compute estimators and errors\n        I_hat_mc = np.mean(f_Y)\n        I_hat_cv = np.mean(f_Y - p_Y) + mu_p\n        \n        error_mc = np.abs(I_hat_mc - I)\n        error_cv = np.abs(I_hat_cv - I)\n\n        if error_mc == 0:\n            # This edge case is highly unlikely but robust code should handle it.\n            # If plain MC is perfect, the ratio is either 0 (if CV is also perfect) or infinite.\n            # In the context of performance improvement, if the baseline is perfect, \n            # any non-zero error from the new method is a degradation. If CV is also perfect,\n            # it's no better or worse, ratio could be 1.\n            # Given the problem's nature, error_mc will not be zero.\n            ratio = float('inf') if error_cv  0 else 1.0\n        else:\n            ratio = error_cv / error_mc\n        \n        results.append(round(ratio, 6))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}