{
    "hands_on_practices": [
        {
            "introduction": "The 'skeleton' of any phase portrait is its set of fixed points, where the dynamics come to a halt. Understanding the flow near these points is the first step in building a global picture. This practice  guides you through the essential task of linear stability analysis, where you will use the Jacobian matrix and its eigenvalues to classify the fixed points of the famous Duffing oscillator, determining whether they are stable nodes, unstable spirals, saddles, or other fundamental types.",
            "id": "2426930",
            "problem": "Consider the two-dimensional autonomous dynamical system defined by the damped Duffing oscillator\n$$\n\\dot{x} = y, \\qquad \\dot{y} = -\\delta\\, y + \\alpha\\, x - \\beta\\, x^3,\n$$\nwhere $x$ and $y$ are dimensionless state variables, and $\\alpha$, $\\beta$, and $\\delta$ are real, dimensionless parameters. A point $(x^\\ast,y^\\ast)$ is a fixed point if and only if\n$$\ny^\\ast = 0 \\quad \\text{and} \\quad -\\delta\\, y^\\ast + \\alpha\\, x^\\ast - \\beta\\, (x^\\ast)^3 = 0.\n$$\nThe Jacobian matrix at a point $(x,y)$ is the matrix of first-order partial derivatives\n$$\nJ(x,y) = \\begin{pmatrix}\n\\frac{\\partial \\dot{x}}{\\partial x} & \\frac{\\partial \\dot{x}}{\\partial y} \\\\\n\\frac{\\partial \\dot{y}}{\\partial x} & \\frac{\\partial \\dot{y}}{\\partial y}\n\\end{pmatrix}\n= \\begin{pmatrix}\n0 & 1 \\\\\n\\alpha - 3 \\beta x^2 & -\\delta\n\\end{pmatrix}.\n$$\nFor each parameter set below, you must numerically find all fixed points $(x^\\ast,y^\\ast)$ lying in the square domain $[-2,2]\\times[-2,2]$, with the following acceptance and distinctness criteria. Use a numerical tolerance of $\\varepsilon = 10^{-9}$. A candidate $(x^\\ast,y^\\ast)$ is accepted as a fixed point if $\\|\\,( \\dot{x}(x^\\ast,y^\\ast), \\dot{y}(x^\\ast,y^\\ast) )\\,\\|_2 \\le \\varepsilon$. Two candidates $(x_1^\\ast,y_1^\\ast)$ and $(x_2^\\ast,y_2^\\ast)$ represent the same fixed point if $\\sqrt{(x_1^\\ast-x_2^\\ast)^2 + (y_1^\\ast-y_2^\\ast)^2} \\le \\varepsilon$.\n\nAt each distinct fixed point, compute the Jacobian $J(x^\\ast,y^\\ast)$ and its eigenvalues. Classify the fixed point by eigenvalue-based linear stability into one of the following integer codes:\n- Code $1$: saddle (the determinant of $J$ is negative, equivalently one real eigenvalue is positive and the other is negative).\n- Code $2$: stable degenerate node (two equal real eigenvalues, negative real value).\n- Code $3$: unstable degenerate node (two equal real eigenvalues, positive real value).\n- Code $4$: stable node (two distinct real eigenvalues, both negative).\n- Code $5$: unstable node (two distinct real eigenvalues, both positive).\n- Code $6$: stable spiral (complex conjugate eigenvalues with strictly negative real parts).\n- Code $7$: unstable spiral (complex conjugate eigenvalues with strictly positive real parts).\n- Code $8$: center (complex conjugate eigenvalues with real parts of magnitude $\\le \\varepsilon$).\n- Code $9$: non-hyperbolic with a zero eigenvalue (the determinant of $J$ has magnitude $\\le \\varepsilon$).\n\nWhen applying the above tests, treat comparisons to zero using the tolerance $\\varepsilon = 10^{-9}$; for example, treat a real part as zero if its absolute value is $\\le \\varepsilon$, and treat two real eigenvalues as equal if their difference in absolute value is $\\le \\varepsilon$.\n\nFor each parameter set, output the list of classification codes for all distinct fixed points in the domain, ordered by sorting the fixed points lexicographically by $x^\\ast$ and then by $y^\\ast$, both in ascending order.\n\nTest suite (each line gives $(\\alpha,\\beta,\\delta)$):\n- $(1,1,0)$\n- $(1,1,1)$\n- $(1,1,4)$\n- $(1,1,2.8284271247461903)$, which equals $2\\sqrt{2}$ to the shown precision.\n- $(1,1,-1)$\n- $(-1,1,1)$\n- $(-1,1,4)$\n- $(0,1,1)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself the comma-separated list of codes for the corresponding parameter set, enclosed in square brackets. For example, the format must be\n$[$ [codes for the first parameter set] $,$ [codes for the second parameter set] $,$ $\\dots$ $]$\nwith no additional text. Angles do not appear, and there are no physical units involved in this problem; all quantities are dimensionless. The numerical tolerance is $\\varepsilon = 10^{-9}$ and must be used exactly as stated.",
            "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It constitutes a standard exercise in the linear stability analysis of a well-known dynamical system, the damped Duffing oscillator. All parameters, conditions, and criteria for classification are explicitly and unambiguously defined. Therefore, the problem is deemed valid, and a complete solution will be constructed.\n\nThe solution strategy involves two principal stages for each given parameter set $(\\alpha, \\beta, \\delta)$: first, the analytical identification of the system's fixed points, and second, their classification using eigenvalue analysis of the Jacobian matrix.\n\n**1. Finding Fixed Points**\n\nA fixed point $(x^\\ast, y^\\ast)$ of the dynamical system must satisfy the equilibrium conditions $\\dot{x}=0$ and $\\dot{y}=0$. The first condition, $\\dot{x} = y$, directly implies that $y^\\ast=0$. Substituting $y^\\ast=0$ into the second condition, $\\dot{y} = -\\delta y + \\alpha x - \\beta x^3$, yields the equation for the $x$-coordinates of the fixed points:\n$$ \\alpha x^\\ast - \\beta (x^\\ast)^3 = 0 $$\nThis polynomial equation can be factored as $x^\\ast(\\alpha - \\beta(x^\\ast)^2) = 0$. The real solutions for $x^\\ast$ depend on the parameters $\\alpha$ and $\\beta$:\n- One solution is always $x^\\ast = 0$, corresponding to the fixed point $(0, 0)$.\n- If the ratio $\\alpha/\\beta > 0$, two additional real solutions exist: $x^\\ast = \\pm\\sqrt{\\alpha/\\beta}$. These correspond to the fixed points $(\\sqrt{\\alpha/\\beta}, 0)$ and $(-\\sqrt{\\alpha/\\beta}, 0)$.\n- If $\\alpha/\\beta \\le 0$ or if $\\beta = 0$ (and $\\alpha \\neq 0$), $x^\\ast=0$ is the only real solution.\n\nAll fixed points thus found must lie within the specified domain $[-2, 2] \\times [-2, 2]$. Since $y^\\ast=0$ is always satisfied, this requirement reduces to ensuring $|x^\\ast| \\le 2$. The valid fixed points for each parameter set are then sorted lexicographically. As $y^\\ast$ is constant, this is equivalent to sorting by the value of $x^\\ast$ in ascending order.\n\n**2. Classification of Fixed Points**\n\nFor each sorted fixed point $(x^\\ast, y^\\ast)$, a linear stability analysis is conducted. This procedure is as follows:\n\na. **Jacobian Matrix**: The Jacobian matrix $J$ of the system is evaluated at the fixed point $(x^\\ast, y^\\ast)$:\n$$\nJ(x^\\ast, y^\\ast) = \\begin{pmatrix}\n\\frac{\\partial \\dot{x}}{\\partial x} & \\frac{\\partial \\dot{x}}{\\partial y} \\\\\n\\frac{\\partial \\dot{y}}{\\partial x} & \\frac{\\partial \\dot{y}}{\\partial y}\n\\end{pmatrix}_{(x^\\ast, y^\\ast)}\n= \\begin{pmatrix}\n0 & 1 \\\\\n\\alpha - 3 \\beta (x^\\ast)^2 & -\\delta\n\\end{pmatrix}\n$$\n\nb. **Eigenvalue Computation**: The eigenvalues, $\\lambda_1$ and $\\lambda_2$, of the Jacobian matrix are computed numerically. The local dynamics near the fixed point are determined by these eigenvalues.\n\nc. **Classification Logic**: A classification code is assigned based on the properties of the eigenvalues, using the specified numerical tolerance $\\varepsilon = 10^{-9}$ for all comparisons involving zero. The logic follows the specified criteria:\n\n- **Code 9 (Non-hyperbolic/Zero Eigenvalue)**: Assigned if the determinant of the Jacobian, $\\det(J) = \\lambda_1\\lambda_2$, has a magnitude less than or equal to $\\varepsilon$. That is, $|\\lambda_1\\lambda_2| \\le \\varepsilon$.\n\n- **Code 1 (Saddle)**: Assigned if $\\det(J) < -\\varepsilon$. This signifies that the eigenvalues are real and have opposite signs.\n\n- For cases where $\\det(J) > \\varepsilon$, the classification depends on whether the eigenvalues are real or form a complex conjugate pair.\n  - **Complex Eigenvalues** (identified if $|\\text{Im}(\\lambda_1)| > \\varepsilon$): The classification is determined by the sign of the real part of the eigenvalues, $\\text{Re}(\\lambda_1)$.\n    - **Code 6 (Stable Spiral)**: if $\\text{Re}(\\lambda_1) < -\\varepsilon$.\n    - **Code 7 (Unstable Spiral)**: if $\\text{Re}(\\lambda_1) > \\varepsilon$.\n    - **Code 8 (Center)**: if $|\\text{Re}(\\lambda_1)| \\le \\varepsilon$.\n  - **Real Eigenvalues** (identified if $|\\text{Im}(\\lambda_1)| \\le \\varepsilon$): The classification depends on whether the eigenvalues are equal and on their sign.\n    - **Degenerate Nodes** (eigenvalues are considered equal if their absolute difference $|\\lambda_1 - \\lambda_2|$ is less than or equal to $\\varepsilon$):\n      - **Code 2 (Stable)**: if the common eigenvalue is less than $-\\varepsilon$.\n      - **Code 3 (Unstable)**: if the common eigenvalue is greater than $\\varepsilon$.\n    - **Distinct Nodes** (if $|\\lambda_1 - \\lambda_2| > \\varepsilon$): Since $\\det(J) > 0$, the eigenvalues have the same sign. This sign is determined by the trace of the Jacobian, $\\text{Tr}(J) = \\lambda_1 + \\lambda_2$.\n      - **Code 4 (Stable)**: if $\\text{Tr}(J) < -\\varepsilon$.\n      - **Code 5 (Unstable)**: if $\\text{Tr}(J) > \\varepsilon$.\n\nThis systematic procedure is implemented and applied to each parameter set from the test suite to generate the required output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of finding and classifying fixed points for the\n    damped Duffing oscillator for a given set of parameters.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (alpha, beta, delta).\n    test_cases = [\n        (1.0, 1.0, 0.0),\n        (1.0, 1.0, 1.0),\n        (1.0, 1.0, 4.0),\n        (1.0, 1.0, 2.8284271247461903),  # 2*sqrt(2)\n        (1.0, 1.0, -1.0),\n        (-1.0, 1.0, 1.0),\n        (-1.0, 1.0, 4.0),\n        (0.0, 1.0, 1.0),\n    ]\n\n    all_results = []\n    epsilon = 1e-9\n\n    for params in test_cases:\n        alpha, beta, delta = params\n\n        # 1. Find fixed points analytically\n        fixed_points = []\n        \n        # Fixed point at x=0 is always a candidate\n        x_star_0 = 0.0\n        if abs(x_star_0) <= 2.0:\n            fixed_points.append((x_star_0, 0.0))\n\n        # Other fixed points from alpha - beta*x^2 = 0\n        if beta != 0:\n            ratio = alpha / beta\n            if ratio > 0:\n                x_star_pos = np.sqrt(ratio)\n                if abs(x_star_pos) <= 2.0:\n                    fixed_points.append((x_star_pos, 0.0))\n                \n                x_star_neg = -np.sqrt(ratio)\n                if abs(x_star_neg) <= 2.0:\n                    fixed_points.append((x_star_neg, 0.0))\n        \n        # Remove duplicates and sort lexicographically.\n        # Sorting a list of tuples sorts by the first element, then second, etc.\n        unique_fps = sorted(list(set(fixed_points)))\n\n        # 2. Classify each fixed point\n        case_results = []\n        for fp in unique_fps:\n            x_star, y_star = fp  # y_star is always 0\n\n            # Construct the Jacobian matrix\n            jacobian = np.array([\n                [0.0, 1.0],\n                [alpha - 3.0 * beta * x_star**2, -delta]\n            ])\n            \n            # Compute eigenvalues\n            eigenvalues = np.linalg.eigvals(jacobian)\n            l1, l2 = eigenvalues[0], eigenvalues[1]\n            \n            # Classification based on eigenvalue properties\n            code = 0\n            # product l1*l2 is the determinant, which is guaranteed to be real\n            det_J = (l1 * l2).real\n            \n            if abs(det_J) <= epsilon:\n                code = 9\n            elif det_J < -epsilon:\n                code = 1\n            else:  # det_J > epsilon\n                is_complex = abs(l1.imag) > epsilon\n                if is_complex:\n                    real_part = l1.real\n                    if real_part < -epsilon:\n                        code = 6  # Stable spiral\n                    elif real_part > epsilon:\n                        code = 7  # Unstable spiral\n                    else:\n                        code = 8  # Center\n                else:  # Real eigenvalues\n                    l1_real, l2_real = l1.real, l2.real\n                    \n                    # Check for degeneracy\n                    if abs(l1_real - l2_real) <= epsilon:\n                        if l1_real < -epsilon:\n                            code = 2  # Stable degenerate node\n                        elif l1_real > epsilon:\n                            code = 3  # Unstable degenerate node\n                        else:\n                            # Eigenvalue is zero, so det_J is zero.\n                            # This should have been caught by the first `if`.\n                            code = 9\n                    else:\n                        # Distinct real eigenvalues\n                        # sum l1+l2 is the trace, which is real\n                        trace_J = (l1 + l2).real\n                        if trace_J < -epsilon:\n                            code = 4  # Stable node\n                        elif trace_J > epsilon:\n                            code = 5  # Unstable node\n                        # else: trace is zero, which implies D<=0, a contradiction for this case.\n            \n            case_results.append(code)\n        \n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    list_of_lists_str = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    print(f\"[{','.join(list_of_lists_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While fixed points anchor the phase portrait, the stable and unstable manifolds of saddle points form the crucial separatrices that divide the space into regions of qualitatively different behavior. Tracing these manifolds is key to revealing the global structure of the dynamics. In this exercise , you will numerically compute the stable and unstable manifolds for a conservative system, starting from infinitesimal displacements and integrating forward or backward in time $t$ to map out these essential curves.",
            "id": "2426894",
            "problem": "You are to write a complete, runnable program that constructs a phase space portrait of a two-dimensional dynamical system by numerically computing both the stable and unstable manifolds of a saddle point. The program must implement and integrate a two-dimensional autonomous ordinary differential equation and automatically extract quantitative diagnostics of the computed manifolds. No plotting or file input/output is required; your program must produce a single-line textual output that contains the requested numerical metrics for a specified test suite of initial offsets.\n\nConsider the conservative planar system defined by the first-order equations\n$$\n\\frac{dx}{dt} = y, \\quad \\frac{dy}{dt} = x - x^{3}.\n$$\nThis system has a saddle equilibrium at the origin. The Jacobian at the origin is\n$$\nJ(0,0) = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix},\n$$\nwith eigenvalues $+1$ and $-1$ and corresponding unit eigenvectors along the directions of $(1,1)$ and $(1,-1)$, respectively. The stable and unstable manifolds of the saddle are defined as the sets of points whose trajectories approach the saddle as $t \\to +\\infty$ and $t \\to -\\infty$, respectively. The system is Hamiltonian with conserved energy\n$$\nH(x,y) = \\frac{y^{2}}{2} - \\frac{x^{2}}{2} + \\frac{x^{4}}{4},\n$$\nso that trajectories lie on level sets of $H$. The separatrix curves that form the global stable and unstable manifolds of the saddle are the level set $H(x,y) = 0$.\n\nYour tasks are:\n- Using the fundamental definitions above, construct numerical approximations to the unstable and stable manifolds that leave the origin in the first quadrant, by integrating initial conditions that are tangent to the corresponding linear eigen-directions and lie on the separatrix energy level $H = 0$. Do not use any explicit pre-constructed manifold formulas; compute initial conditions by enforcing $H(x,y)=0$ and tangency to the appropriate eigen-direction near the origin.\n- For the unstable manifold branch in the first quadrant, integrate forward in time until the trajectory first returns to the horizontal axis, that is, until $y=0$ is crossed from positive to zero. Record the $x$-coordinate at this crossing.\n- For the stable manifold branch in the fourth quadrant that approaches the origin, integrate backward in time (equivalently, integrate the system with reversed time) until the trajectory first reaches $y=0$ from negative values. Record the $x$-coordinate at this crossing.\n- For both branches, quantify how well your numerical trajectory adheres to the separatrix by computing the maximum absolute deviation of $H(x(t),y(t))$ from the initial energy value along the numerically integrated segment. Also quantify the local alignment with the linear eigenvector by computing the angle between the system vector field at the initial condition and the relevant eigenvector. The angle must be reported in radians.\n\nDesign your program to carry out the following test suite of three initial offsets, each specified by a small positive scalar $\\varepsilon$ that sets the initial distance from the origin along the appropriate eigen-direction, while remaining on the separatrix $H=0$:\n- Case $1$: $\\varepsilon = 10^{-6}$.\n- Case $2$: $\\varepsilon = 10^{-3}$.\n- Case $3$: $\\varepsilon = 10^{-2}$.\n\nImplementation requirements and conventions:\n- For the unstable branch in the first quadrant, choose an initial condition $(x_{0},y_{0})$ with $x_{0} = \\varepsilon$, $y_{0} > 0$, on the level set $H=0$, and tangent to the unstable eigen-direction at the origin. Integrate forward in time until the first crossing of $y=0$ from positive to zero. To avoid the trivial crossing at the start, you must use direction-sensitive event detection for the condition $y=0$ and detect only crossings with decreasing $y$. Use a sufficiently large final integration time so that the crossing is detected for all given $\\varepsilon$. The expected crossing $x$-coordinate is near $\\sqrt{2}$; your program must compute the absolute difference between the measured crossing $x$ and $\\sqrt{2}$.\n- For the stable branch in the fourth quadrant, choose an initial condition $(x_{0},y_{0})$ with $x_{0} = \\varepsilon$, $y_{0} < 0$, on the level set $H=0$, and tangent to the stable eigen-direction at the origin. Integrate backward in time until the first crossing of $y=0$ from negative to zero, and compute the absolute difference between the measured crossing $x$ and $\\sqrt{2}$.\n- For the unstable branch only, compute the angle in radians between the system vector field evaluated at $(x_{0},y_{0})$ and the unit unstable eigenvector at the origin. Report this angle as a nonnegative value in radians.\n- For the unstable branch only, report the maximum absolute deviation of the Hamiltonian $H$ along the integrated trajectory segment from its initial value. Since the initial condition is on $H=0$, this is simply the maximum absolute value of $H$ along the segment.\n\nAll angles must be reported in radians. There are no physical units.\n\nNumerical specifications:\n- Use an accurate time integrator with adaptive steps and event detection.\n- Use an integration horizon large enough to reach the first $y=0$ crossing for all cases, for example a maximum time of $T_{\\max} = 50$ in the forward or backward direction.\n- Use tolerances sufficiently tight to resolve the manifolds and events.\n\nFinal output format:\n- For each $\\varepsilon$ in the test suite, your program must output a list of four floating-point numbers in the order: $[\\text{unstable\\_apex\\_error}, \\text{unstable\\_angle\\_error}, \\text{unstable\\_max\\_energy\\_deviation}, \\text{stable\\_apex\\_error}]$.\n- Aggregate the results for the three cases into a single line printed to standard output, containing a list of the three per-case lists, for example\n$[[r_{11},r_{12},r_{13},r_{14}],[r_{21},r_{22},r_{23},r_{24}],[r_{31},r_{32},r_{33},r_{34}]]$,\nwith each $r_{ij}$ a floating-point number. The values must be rounded to six significant figures when printed.\n\nYour program must not read any input and must not produce any other output besides the single required line.",
            "solution": "The problem presented is a standard exercise in computational nonlinear dynamics and has been validated as scientifically sound, well-posed, and objective. It requires the numerical construction of stable and unstable manifolds for a two-dimensional Hamiltonian system and the calculation of specific quantitative metrics. We proceed with the solution.\n\nThe system is defined by the autonomous ordinary differential equations:\n$$\n\\frac{dx}{dt} = \\dot{x} = y\n$$\n$$\n\\frac{dy}{dt} = \\dot{y} = x - x^3\n$$\nThis system is conservative, derived from the Hamiltonian function $H(x,y)$:\n$$\nH(x,y) = \\frac{y^2}{2} - \\frac{x^2}{2} + \\frac{x^4}{4}\n$$\nThe dynamics are constrained to the level sets of this Hamiltonian. The equilibrium points are found by setting $\\dot{x}=0$ and $\\dot{y}=0$, which yields $y=0$ and $x - x^3 = 0$. The solutions are $(0,0)$, $(1,0)$, and $(-1,0)$. We are concerned with the equilibrium at the origin, $(0,0)$.\n\nThe stability of the origin is determined by the Jacobian matrix of the vector field $F(x,y) = (y, x-x^3)$:\n$$\nJ(x,y) = \\begin{pmatrix} \\frac{\\partial \\dot{x}}{\\partial x} & \\frac{\\partial \\dot{x}}{\\partial y} \\\\ \\frac{\\partial \\dot{y}}{\\partial x} & \\frac{\\partial \\dot{y}}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 1 - 3x^2 & 0 \\end{pmatrix}\n$$\nAt the origin, this becomes:\n$$\nJ(0,0) = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}\n$$\nThe eigenvalues $\\lambda$ are found from $\\det(J - \\lambda I) = 0$, which gives $\\lambda^2 - 1 = 0$, so $\\lambda_{1,2} = \\pm 1$. The presence of one positive and one negative eigenvalue confirms that the origin is a saddle point. The eigenvector for the unstable eigenvalue $\\lambda_u = +1$ is $\\vec{v}_u \\propto (1,1)$, and for the stable eigenvalue $\\lambda_s = -1$ is $\\vec{v}_s \\propto (1,-1)$. These eigenvectors define the local directions of the unstable and stable manifolds, respectively.\n\nThe global manifolds, which are also the separatrices of the phase space, correspond to the specific energy level that passes through the saddle point. Evaluating the Hamiltonian at the origin gives $H(0,0)=0$. Therefore, the stable and unstable manifolds lie on the curve defined by $H(x,y)=0$.\n\nTo numerically compute a branch of a manifold, we must select an initial condition $(x_0, y_0)$ that is infinitesimally displaced from the saddle point along the corresponding eigenvector and lies on the separatrix energy level. The problem specifies a displacement characterized by a small parameter $\\varepsilon$.\n\nFor the unstable manifold branch in the first quadrant ($x>0, y>0$), we set $x_0 = \\varepsilon$. The condition $H(\\varepsilon, y_0) = 0$ gives:\n$$\n\\frac{y_0^2}{2} - \\frac{\\varepsilon^2}{2} + \\frac{\\varepsilon^4}{4} = 0 \\implies y_0^2 = \\varepsilon^2 - \\frac{\\varepsilon^4}{2}\n$$\nSince we are in the first quadrant, we take the positive root:\n$$\ny_0 = \\sqrt{\\varepsilon^2 - \\frac{\\varepsilon^4}{2}} = \\varepsilon \\sqrt{1 - \\frac{\\varepsilon^2}{2}}\n$$\nFor small $\\varepsilon$, Taylor expansion shows $y_0 \\approx \\varepsilon(1 - \\varepsilon^2/4) \\approx \\varepsilon$. Thus, the initial point $(x_0, y_0)$ is approximately $(\\varepsilon, \\varepsilon)$, which is tangent to the unstable eigenvector direction $(1,1)$. We integrate this initial condition forward in time ($t>0$) until the trajectory first crosses the x-axis, i.e., $y=0$. The crossing point $x_{cross}$ is found when the homoclinic loop closes. On the separatrix, this occurs when $H(x,0) = 0$, which implies $-\\frac{x^2}{2} + \\frac{x^4}{4} = 0$. The non-zero solutions are $x = \\pm\\sqrt{2}$. The first quadrant branch will cross at $x = \\sqrt{2}$. The first metric is the deviation from this exact value: $|x_{cross} - \\sqrt{2}|$.\n\nFor the stable manifold branch that approaches the origin from the fourth quadrant ($x>0, y<0$), we similarly set $x_0 = \\varepsilon$. The condition $H(\\varepsilon, y_0) = 0$ requires the negative root:\n$$\ny_0 = -\\sqrt{\\varepsilon^2 - \\frac{\\varepsilon^4}{2}} = -\\varepsilon \\sqrt{1 - \\frac{\\varepsilon^2}{2}}\n$$\nFor small $\\varepsilon$, $y_0 \\approx -\\varepsilon$, and the initial point $(x_0, y_0)$ is approximately $(\\varepsilon, -\\varepsilon)$, tangent to the stable eigenvector direction $(1,-1)$. To trace this manifold away from the origin, we must integrate backward in time ($t<0$). The crossing point $x_{cross}$ on the $y=0$ axis is, by symmetry, also expected at $x=\\sqrt{2}$. The final metric is $|x_{cross} - \\sqrt{2}|$.\n\nThe remaining metrics are computed for the unstable branch. The angle error quantifies how well the true vector field at the initial point $(x_0, y_0)$ aligns with the linear approximation (the eigenvector $\\vec{v}_u=(1,1)$). The vector field is $\\vec{F}(x_0, y_0) = (y_0, x_0 - x_0^3)$. The angle $\\theta$ between $\\vec{F}$ and $\\vec{v}_u$ is calculated using the dot product formula:\n$$\n\\theta = \\arccos\\left(\\frac{\\vec{F}(x_0, y_0) \\cdot \\vec{v}_u}{||\\vec{F}(x_0, y_0)|| \\cdot ||\\vec{v}_u||}\\right)\n$$\nThe energy deviation measures the accuracy of the numerical integrator. Since the initial condition is exactly on the $H=0$ level set, the maximum absolute value of the Hamiltonian, $\\max_t |H(x(t), y(t))|$, along the computed trajectory segment quantifies the accumulated numerical error.\n\nThe numerical implementation will use a high-precision, adaptive-step differential equation solver equipped with event detection capabilities to accurately locate the $y=0$ crossings. `scipy.integrate.solve_ivp` is suited for this purpose. The integration is performed for each value of $\\varepsilon$ in the test suite, and the four specified metrics are computed and formatted as required.",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef format_float(val):\n    \"\"\"Formats a float to 6 significant figures in scientific notation if needed.\"\"\"\n    return f\"{val:.6g}\"\n\ndef solve():\n    \"\"\"\n    Computes stable and unstable manifolds for a 2D dynamical system,\n    and extracts quantitative diagnostics for a suite of initial offsets.\n    \"\"\"\n    test_cases = [1e-6, 1e-3, 1e-2]\n    all_results = []\n    \n    # The ODE system dx/dt = y, dy/dt = x - x^3\n    def diffeq(t, state):\n        x, y = state\n        return [y, x - x**3]\n\n    # Hamiltonian H(x,y) = y^2/2 - x^2/2 + x^4/4\n    def hamiltonian(x, y):\n        return 0.5 * y**2 - 0.5 * x**2 + 0.25 * x**4\n\n    # Event for y=0 crossing with y decreasing\n    def event_y_zero_down(t, state):\n        return state[1]\n    event_y_zero_down.terminal = True\n    event_y_zero_down.direction = -1\n\n    # Event for y=0 crossing with y increasing\n    def event_y_zero_up(t, state):\n        return state[1]\n    event_y_zero_up.terminal = True\n    event_y_zero_up.direction = 1\n\n    # Theoretical x-crossing on the separatrix\n    x_apex_theoretical = np.sqrt(2.0)\n\n    # Unit unstable eigenvector direction\n    evec_u = np.array([1.0, 1.0])\n\n    # Numerical integration settings\n    t_max = 50.0\n    rtol = 1e-12\n    atol = 1e-12\n\n    for eps in test_cases:\n        case_results = []\n\n        # --- Unstable Manifold (Q1) ---\n        x0_u = eps\n        y0_u = eps * np.sqrt(1.0 - 0.5 * eps**2)\n        ic_u = [x0_u, y0_u]\n\n        # Integrate forward in time\n        sol_u = solve_ivp(\n            diffeq, [0, t_max], ic_u,\n            events=event_y_zero_down,\n            dense_output=True,\n            rtol=rtol, atol=atol\n        )\n\n        unstable_apex_error = np.nan\n        unstable_angle_error = np.nan\n        unstable_max_energy_deviation = np.nan\n\n        if sol_u.status == 1 and sol_u.t_events[0].size > 0:\n            # Metric 1: Apex error\n            x_cross_u = sol_u.y_events[0][0, 0]\n            unstable_apex_error = np.abs(x_cross_u - x_apex_theoretical)\n\n            # Metric 2: Angle error at initial condition\n            vf_at_ic = np.array([y0_u, x0_u - x0_u**3])\n            cos_theta = np.dot(vf_at_ic, evec_u) / (np.linalg.norm(vf_at_ic) * np.linalg.norm(evec_u))\n            # Clip to handle potential floating point inaccuracies for arccos\n            cos_theta = np.clip(cos_theta, -1.0, 1.0)\n            unstable_angle_error = np.arccos(cos_theta)\n\n            # Metric 3: Max energy deviation\n            h_values = hamiltonian(sol_u.y[0, :], sol_u.y[1, :])\n            unstable_max_energy_deviation = np.max(np.abs(h_values))\n\n        # --- Stable Manifold (Q4) ---\n        x0_s = eps\n        y0_s = -eps * np.sqrt(1.0 - 0.5 * eps**2)\n        ic_s = [x0_s, y0_s]\n\n        # Integrate backward in time\n        sol_s = solve_ivp(\n            diffeq, [0, -t_max], ic_s,\n            events=event_y_zero_up,\n            dense_output=True,\n            rtol=rtol, atol=atol\n        )\n\n        stable_apex_error = np.nan\n        if sol_s.status == 1 and sol_s.t_events[0].size > 0:\n            # Metric 4: Apex error\n            x_cross_s = sol_s.y_events[0][0, 0]\n            stable_apex_error = np.abs(x_cross_s - x_apex_theoretical)\n        \n        case_results = [\n            unstable_apex_error,\n            unstable_angle_error,\n            unstable_max_energy_deviation,\n            stable_apex_error\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string\n    formatted_results = []\n    for row in all_results:\n        formatted_row = f\"[{','.join([format_float(v) for v in row])}]\"\n        formatted_results.append(formatted_row)\n    \n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Not all trajectories are attracted to fixed points or diverge to infinity; in integrable systems, they can live on invariant surfaces like tori. This exercise  explores the fascinating concept of quasi-periodic motion by simulating two uncoupled harmonic oscillators with frequencies $\\omega_1$ and $\\omega_2$. By analyzing how a trajectory covers the surface of a torus, you will discover the profound difference between rational and irrational frequency ratios, which determines whether a path is a simple closed loop or a dense, space-filling web.",
            "id": "2426886",
            "problem": "Consider two uncoupled one-dimensional harmonic oscillators with generalized coordinates $q_1(t)$ and $q_2(t)$ and conjugate momenta $p_1(t)$ and $p_2(t)$. Each oscillator satisfies the Ordinary Differential Equation (ODE) $m_i \\ddot{q}_i(t) + k_i q_i(t) = 0$ for $i \\in \\{1,2\\}$, where $m_i$ is the mass and $k_i$ is the spring constant. Let $\\omega_i = \\sqrt{k_i/m_i}$ denote the angular frequency in radians per second. For amplitudes $A_i &gt; 0$ and phases $\\phi_i \\in \\mathbb{R}$, the solutions can be written as $q_i(t) = A_i \\cos(\\omega_i t + \\phi_i)$ and $p_i(t) = m_i \\dot{q}_i(t) = -m_i A_i \\omega_i \\sin(\\omega_i t + \\phi_i)$, with angles measured in radians and time $t$ in seconds.\n\nDefine the phase angles $\\theta_i(t) = \\omega_i t + \\phi_i$ taken modulo $2\\pi$, so that $(\\theta_1(t) \\bmod 2\\pi, \\theta_2(t) \\bmod 2\\pi)$ evolves on the two-torus $\\mathbb{T}^2 = (\\mathbb{R}/2\\pi\\mathbb{Z})^2$. Consider the standard embedding of $\\mathbb{T}^2$ into Three-Dimensional (3D) Euclidean space $\\mathbb{R}^3$ by the smooth map\n$$\n\\Phi(\\theta_1,\\theta_2) = \\big((R + r \\cos \\theta_1)\\cos \\theta_2,\\; (R + r \\cos \\theta_1)\\sin \\theta_2,\\; r \\sin \\theta_1\\big),\n$$\nwith $R &gt; r &gt; 0$ dimensionless. The image $\\Phi(\\mathbb{T}^2)$ is a geometric torus in $\\mathbb{R}^3$.\n\nYour task is to construct numerical phase-space portraits of the flow on $\\mathbb{T}^2$ induced by the pair $(\\theta_1(t), \\theta_2(t))$ and to quantify how the trajectory samples the torus for different frequency ratios. Use the following precise definition of empirical coverage. Fix a positive integer $M$ and partition $[0,2\\pi)\\times[0,2\\pi)$ into $M\\times M$ equal rectangles of side lengths $2\\pi/M$ along each angular coordinate. For a uniform time grid $t_k = k\\Delta t$ with $k=0,1,\\dots,N-1$ and $\\Delta t = T/N$, form the set of angle pairs $\\big(\\theta_1(t_k) \\bmod 2\\pi,\\; \\theta_2(t_k) \\bmod 2\\pi\\big)$. The empirical coverage fraction is defined as the ratio\n$$\n\\mathcal{C} = \\frac{\\text{number of nonempty rectangles hit by at least one sampled angle pair}}{M^2}.\n$$\nAngles must be treated in radians. The coverage fraction $\\mathcal{C}$ is dimensionless and must be reported as a real number.\n\nImplement a complete, runnable program that, for the test suite below, computes and outputs the empirical coverage fraction $\\mathcal{C}$ for each case using the specified parameters. Use zero phases $\\phi_1 = \\phi_2 = 0$ and the torus embedding parameters $R = 2$ and $r = 1$ (these geometric parameters define the 3D torus but do not directly affect the coverage computation in angle space). Use the exact values stated; do not introduce any additional randomness.\n\nTest suite (angles in radians, frequencies in radians per second, time in seconds):\n- Case 1 (irrational ratio, happy path): $\\omega_1 = 1$, $\\omega_2 = \\frac{1+\\sqrt{5}}{2}$, total time $T = 2\\pi \\cdot 200$, number of samples $N = 200000$, grid size $M = 64$.\n- Case 2 (rational ratio, contrasting behavior): $\\omega_1 = 1$, $\\omega_2 = \\frac{3}{2}$, total time $T = 2\\pi \\cdot 200$, number of samples $N = 200000$, grid size $M = 64$.\n- Case 3 (near-resonant edge case over finite time): $\\omega_1 = 1$, $\\omega_2 = 1 + 10^{-6}$, total time $T = 2\\pi \\cdot 100$, number of samples $N = 200000$, grid size $M = 64$.\n\nYour program must compute the coverage fraction $\\mathcal{C}$ for each case using the same definition and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each value rounded to four digits after the decimal point (for example, \"[1.0000,0.0820,0.0313]\"). Angles must be handled in radians throughout. No user input is allowed, and the program must be self-contained.",
            "solution": "The problem as stated is valid. It is scientifically grounded in the principles of classical mechanics and dynamical systems theory, specifically the study of motion on a torus. The problem is well-posed, providing all necessary parameters and an unambiguous definition for the quantity to be computed. It is objective and free of any factual or logical inconsistencies. We may proceed with the solution.\n\nThe task is to quantify the sampling of the phase space of a two-dimensional dynamical system, defined by the evolution of two phase angles $\\theta_1(t)$ and $\\theta_2(t)$. The system represents two uncoupled harmonic oscillators. The state of the system at time $t$ is given by the point $(\\theta_1(t), \\theta_2(t))$ on the two-torus $\\mathbb{T}^2 = (\\mathbb{R}/2\\pi\\mathbb{Z})^2$. The evolution equations for the angles are given by $\\theta_i(t) = \\omega_i t + \\phi_i$, where $\\omega_i$ are the angular frequencies and $\\phi_i$ are initial phases. For this problem, we are given $\\phi_1 = \\phi_2 = 0$, so the trajectory is simply $(\\omega_1 t, \\omega_2 t)$ modulo $2\\pi$.\n\nThe behavior of this trajectory is fundamentally determined by the ratio of the frequencies, $\\omega_2/\\omega_1$.\n- If the ratio $\\omega_2/\\omega_1$ is a rational number, i.e., $\\omega_2/\\omega_1 = p/q$ for integers $p, q$, the trajectory is periodic. It forms a closed curve on the torus. After a time $T_p$ that is a common multiple of the individual periods $2\\pi/\\omega_1$ and $2\\pi/\\omega_2$, the system returns to its initial state. The trajectory, being a one-dimensional curve, will cover a vanishingly small fraction of the two-dimensional torus area.\n- If the ratio $\\omega_2/\\omega_1$ is an irrational number, the trajectory is quasi-periodic and, by the Kronecker-Weyl theorem, it is dense on the torus. This means that over an infinite time, the trajectory will pass arbitrarily close to every point on the torus.\n\nWe are asked to compute the empirical coverage fraction, $\\mathcal{C}$, which is a numerical measure of how much of the torus is explored by the trajectory over a finite time interval $[0, T)$. The torus $[0, 2\\pi) \\times [0, 2\\pi)$ is partitioned into an $M \\times M$ grid of identical rectangular cells. The coverage $\\mathcal{C}$ is the number of cells visited by at least one point of the sampled trajectory, divided by the total number of cells, $M^2$.\n\nThe algorithm to compute $\\mathcal{C}$ for each test case is as follows:\n1.  Set the parameters for the case: angular frequencies $\\omega_1, \\omega_2$; total time $T$; number of samples $N$; and grid dimension $M$.\n2.  Generate a uniform time vector $\\vec{t}$ with $N$ points in the interval $[0, T)$, such that $t_k = k \\cdot (T/N)$ for $k = 0, 1, \\dots, N-1$.\n3.  Compute the trajectories of the two angles: $\\vec{\\theta}_1 = (\\omega_1 \\vec{t}) \\pmod{2\\pi}$ and $\\vec{\\theta}_2 = (\\omega_2 \\vec{t}) \\pmod{2\\pi}$. The result of the modulo operation must be in the interval $[0, 2\\pi)$.\n4.  For each point $(\\theta_{1,k}, \\theta_{2,k})$ in the sampled trajectory, determine the grid cell it occupies. The cell indices $(i_1, i_2)$ for a point $(\\theta_1, \\theta_2)$ are given by $i_1 = \\lfloor \\frac{M \\theta_1}{2\\pi} \\rfloor$ and $i_2 = \\lfloor \\frac{M \\theta_2}{2\\pi} \\rfloor$. These indices will range from $0$ to $M-1$.\n5.  Maintain a two-dimensional boolean grid, `visited_cells`, of size $M \\times M$, initialized to `False`. For all computed index pairs $(i_{1,k}, i_{2,k})$, set the corresponding element `visited_cells`$[i_{1,k}, i_{2,k}]$ to `True`. Using a set of unique index pairs would be equivalent.\n6.  The number of visited cells, $N_{visited}$, is the total count of `True` entries in the `visited_cells` grid.\n7.  The empirical coverage fraction is $\\mathcal{C} = \\frac{N_{visited}}{M^2}$.\n\nWe apply this algorithm to the three specified cases.\n\n**Case 1: Irrational Ratio**\n- Parameters: $\\omega_1 = 1$, $\\omega_2 = \\frac{1+\\sqrt{5}}{2} \\approx 1.618$ (the golden ratio), $T = 2\\pi \\cdot 200$, $N = 200000$, $M = 64$.\n- The frequency ratio is irrational. The trajectory is expected to be dense. With a large number of samples $N$ over a long time $T$, the coverage $\\mathcal{C}$ should be close to $1$.\n\n**Case 2: Rational Ratio**\n- Parameters: $\\omega_1 = 1$, $\\omega_2 = \\frac{3}{2} = 1.5$, $T = 2\\pi \\cdot 200$, $N = 200000$, $M = 64$.\n- The frequency ratio is rational. The trajectory is periodic with period $T_p = 4\\pi$. Since the total integration time $T = 2\\pi \\cdot 200 = 100 \\cdot (2\\pi) = 50 \\cdot (4\\pi)$ is an integer multiple of the period, the trajectory will simply trace the same closed curve $50$ times. This curve is a one-dimensional object, so it will only intersect a small fraction of the $M^2 = 4096$ grid cells. We expect $\\mathcal{C} \\ll 1$.\n\n**Case 3: Near-Resonant Case**\n- Parameters: $\\omega_1 = 1$, $\\omega_2 = 1 + 10^{-6}$, $T = 2\\pi \\cdot 100$, $N = 200000$, $M = 64$.\n- The frequency ratio is extremely close to $1$. The motion is quasi-periodic, but evolves very slowly away from the resonance $\\omega_1 = \\omega_2$. The phase difference evolves as $\\theta_2(t) - \\theta_1(t) = (\\omega_2 - \\omega_1)t = 10^{-6} t$. At the final time $t=T=2\\pi \\cdot 100$, the maximum phase difference is a mere $2\\pi \\cdot 10^{-4}$ radians. The trajectory remains confined to a very narrow band around the diagonal $\\theta_1 = \\theta_2$. The width of this band is much smaller than the width of a single grid cell, which is $2\\pi/M = 2\\pi/64$. The trajectory will thus primarily occupy an almost one-dimensional path along the main diagonal of the grid, possibly spilling into adjacent cells. The number of visited cells should be on the order of $M$ or $2M$. The coverage is expected to be small, approximately $1/M \\approx 0.0156$ or $2/M \\approx 0.0313$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the empirical coverage fraction for three test cases of\n    a dynamical system on a 2-torus.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: Irrational ratio\n        {\n            \"omega1\": 1.0,\n            \"omega2\": (1.0 + np.sqrt(5.0)) / 2.0,\n            \"T\": 2.0 * np.pi * 200.0,\n            \"N\": 200000,\n            \"M\": 64\n        },\n        # Case 2: Rational ratio\n        {\n            \"omega1\": 1.0,\n            \"omega2\": 3.0 / 2.0,\n            \"T\": 2.0 * np.pi * 200.0,\n            \"N\": 200000,\n            \"M\": 64\n        },\n        # Case 3: Near-resonant edge case\n        {\n            \"omega1\": 1.0,\n            \"omega2\": 1.0 + 1e-6,\n            \"T\": 2.0 * np.pi * 100.0,\n            \"N\": 200000,\n            \"M\": 64\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        omega1 = case[\"omega1\"]\n        omega2 = case[\"omega2\"]\n        T = case[\"T\"]\n        N = case[\"N\"]\n        M = case[\"M\"]\n\n        # 1. Generate a uniform time vector\n        # The interval is [0, T), with N points.\n        t = np.linspace(0.0, T, N, endpoint=False)\n\n        # 2. Compute the trajectories of the two angles modulo 2*pi\n        theta1 = (omega1 * t) % (2.0 * np.pi)\n        theta2 = (omega2 * t) % (2.0 * np.pi)\n\n        # 3. Map angles to grid cell indices\n        # The mapping floor(angle * M / (2*pi)) correctly maps the\n        # interval [0, 2*pi) to integer indices [0, M-1].\n        idx1 = np.floor(theta1 * M / (2.0 * np.pi)).astype(int)\n        idx2 = np.floor(theta2 * M / (2.0 * np.pi)).astype(int)\n\n        # 4. Use a boolean grid to mark visited cells efficiently\n        # This avoids storing all points or using a slow loop.\n        visited_grid = np.zeros((M, M), dtype=bool)\n        # Advanced indexing marks all unique (idx1, idx2) pairs as True\n        visited_grid[idx1, idx2] = True\n        \n        # 5. Count the number of visited cells\n        num_visited_cells = np.sum(visited_grid)\n\n        # 6. Compute the empirical coverage fraction\n        coverage_fraction = num_visited_cells / (M * M)\n        \n        results.append(coverage_fraction)\n\n    # Format the results as specified: rounded to four decimal places.\n    formatted_results = [f\"{res:.4f}\" for res in results]\n    \n    # Print the final output in the required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}