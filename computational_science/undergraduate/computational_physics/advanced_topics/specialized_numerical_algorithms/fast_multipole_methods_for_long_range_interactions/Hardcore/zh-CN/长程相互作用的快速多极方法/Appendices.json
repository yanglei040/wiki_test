{
    "hands_on_practices": [
        {
            "introduction": "对于大规模模拟而言，深刻理解算法的内存占用是设计高效科学软件的关键。本练习  将指导你从第一性原理出发，为快速多极子方法（FMM）构建一个内存模型，将八叉树和球谐函数展开等理论组件与实际的内存成本联系起来，从而使你能够预测和规划大型计算所需的资源。",
            "id": "2392064",
            "problem": "要求您为三维拉普拉斯核的快速多极方法 (FMM) 实现建模并计算其内存占用，作为粒子数和展开阶数的函数。您的任务是根据算法数据结构的基本原理推导出一个原则性的内存模型，然后实现一个程序，用给定的测试套件评估该模型。\n\n假设使用以下标准且明确定义的设置：\n\n- 用于三维拉普拉斯势的快速多极方法 (FMM) 使用最高阶为 $p$ 的实球谐函数展开。\n- 计算域是一个立方体，被划分为一个深度为 $h$ 的完整的、层级均匀的八叉树，使得深度为 $h$ 的每个叶节点最多包含 $n_{\\text{leaf}}$ 个粒子。一个深度为 $h$ 的完整八叉树恰好有 $8^h$ 个叶节点和 $(8^{h+1} - 1)/7$ 个总节点（包括内部节点和叶节点）。选择最小的深度 $h$ 以满足 $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$，其中 $N$ 是粒子数。\n- 在三维空间中，拉普拉斯核的 $p$ 阶实球谐多极展开中的系数数量等于最高次数为 $p$ 的球谐函数的数量，即 $\\sum_{\\ell=0}^{p} (2\\ell + 1) = (p+1)^2$。局部展开具有相同数量的系数。\n- 所有浮点值都以 IEEE $754$ 双精度存储（即每个浮点值 $8$ 字节），所有整数索引都以 $64$ 位有符号整数存储（即每个整数 $8$ 字节）。\n\n您必须采用以下精确的内存模型：\n\n- 每个粒子：\n  - 存储位置 $(x,y,z)$ 为三个双精度浮点数：$3 \\times 8$ 字节。\n  - 存储粒子的标量源强度 $q$ 为一个双精度浮点数：$1 \\times 8$ 字节。\n  - 存储包含该粒子的叶节点的索引为一个 $64$ 位整数：$1 \\times 8$ 字节。\n  - 存储用于 Morton 排序的置换索引为一个 $64$ 位整数：$1 \\times 8$ 字节。\n  - 因此，每个粒子的内存为 $4 \\times 8 + 2 \\times 8 = 48$ 字节，总粒子存储为 $M_{\\text{particles}}(N) = 48 N$ 字节。\n- 每个树节点（包括内部节点和叶节点），存储节点元数据：\n  - 节点中心 $(c_x,c_y,c_z)$ 为三个双精度浮点数：$3 \\times 8$ 字节。\n  - 节点半尺寸 $h_{\\text{size}}$ 为一个双精度浮点数：$1 \\times 8$ 字节。\n  - Morton 排序顺序中的粒子索引范围 $(i_{\\text{start}}, i_{\\text{end}})$ 为两个 $64$ 位整数：$2 \\times 8$ 字节。\n  - 因此，每个节点的元数据为 $48$ 字节，总元数据存储为 $M_{\\text{node-meta}}(\\text{total\\_nodes}) = 48 \\times \\text{total\\_nodes}$ 字节。\n- 每个树节点，存储一个多极展开和一个局部展开（均为双精度浮点数），每个展开都有 $(p+1)^2$ 个系数：\n  - 每个节点的展开存储为 $2 \\times (p+1)^2 \\times 8$ 字节。\n  - 因此，总展开存储为 $M_{\\text{exp}}(\\text{total\\_nodes}, p) = 16 \\times (p+1)^2 \\times \\text{total\\_nodes}$ 字节。\n- 每个叶节点，存储一个固定大小的近邻列表，其中包含多达 $26$ 个邻居叶节点索引（轴对齐的相邻邻居），作为 $64$ 位整数：\n  - 每个叶节点的邻居列表存储为 $26 \\times 8$ 字节。\n  - 因此，总邻居列表存储为 $M_{\\text{near}}(\\text{leaves}) = 26 \\times 8 \\times \\text{leaves} = 208 \\times \\text{leaves}$ 字节。\n\n定义和基于核心原理的必要推导：\n\n- 根据球谐函数的定义，最高次数为 $p$ 的模态数量为 $\\sum_{\\ell=0}^{p} (2\\ell + 1) = (p+1)^2$。\n- 对于一个深度为 $h$ 的完整八叉树，总节点数为 $\\sum_{k=0}^{h} 8^k = (8^{h+1} - 1)/7$，叶节点数为 $8^h$。\n- 选择最小深度 $h$ 以满足 $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$。\n\n设 $N$ 表示粒子数，$p$ 表示展开阶数，$n_{\\text{leaf}}$ 表示叶节点容量。定义：\n- $L_{\\text{req}} = \\lceil N / n_{\\text{leaf}} \\rceil$，\n- $h = \\min \\{ h' \\in \\mathbb{N}_0 : 8^{h'} \\ge L_{\\text{req}} \\}$,\n- $\\text{leaves} = 8^h$,\n- $\\text{total\\_nodes} = (8^{h+1} - 1)/7$。\n\n那么总内存（以字节为单位）为：\n$$\nM_{\\text{total}}(N,p,n_{\\text{leaf}}) = M_{\\text{particles}}(N) + M_{\\text{node-meta}}(\\text{total\\_nodes}) + M_{\\text{exp}}(\\text{total\\_nodes}, p) + M_{\\text{near}}(\\text{leaves}).\n$$\n\n您的程序必须：\n\n- 实现一个函数，给定 $(N,p,n_{\\text{leaf}})$，使用上述模型计算 $M_{\\text{total}}$（以字节为单位）。\n- 将结果转换为 mebibytes (MiB)，其中 $1$ MiB $= 2^{20}$ 字节，并将结果报告为一个四舍五入到恰好 $6$ 位小数的浮点数。\n\n测试套件：\n\n针对以下参数集 $(N, p, n_{\\text{leaf}})$ 评估模型：\n\n- $(100000, 6, 200)$: 一个典型的中等规模案例。\n- $(50, 0, 200)$: 非常小的 $N$，最小展开阶数。\n- $(10000, 12, 128)$: 中等 $N$，高展开阶数。\n- $(1000000, 4, 256)$: 大规模 $N$，中等展开阶数。\n- $(400, 1, 200)$: 占用边界恰好为两个叶节点，低展开阶数。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含测试套件的有序结果，形式为方括号内由逗号分隔的列表，每个数字以 MiB 为单位，并四舍五入到恰好 $6$ 位小数。例如，包含两个结果的输出应如下所示：`[12.345000,67.890000]`。确保逗号后没有空格。",
            "solution": "该问题陈述已根据科学基础、良构性和客观性的既定标准进行了严格验证。\n\n已知条件如下：\n- 一个用于三维拉普拉斯核的快速多极方法 (FMM) 的内存占用模型。\n- 使用阶数为 $p$ 的实球谐函数展开，每次展开有 $(p+1)^2$ 个系数。\n- 一个深度为 $h$ 的完整的、层级均匀的八叉树，其中 $h$ 是满足 $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$ 的最小整数。总节点数为 $(8^{h+1}-1)/7$，叶节点数为 $8^h$。\n- 数据类型大小：双精度浮点数 $8$ 字节，64 位整数 $8$ 字节。\n- 定义了一个包含四个组件的特定内存模型：\n  1. 粒子存储：$M_{\\text{particles}}(N) = 48N$ 字节。\n  2. 节点元数据存储：$M_{\\text{node-meta}}(\\text{total\\_nodes}) = 48 \\times \\text{total\\_nodes}$ 字节。\n  3. 展开系数存储：$M_{\\text{exp}}(\\text{total\\_nodes}, p) = 16(p+1)^2 \\times \\text{total\\_nodes}$ 字节。\n  4. 叶节点邻居列表存储：$M_{\\text{near}}(\\text{leaves}) = 208 \\times \\text{leaves}$ 字节。\n- 总内存是各部分之和：$M_{\\text{total}} = M_{\\text{particles}} + M_{\\text{node-meta}} + M_{\\text{exp}} + M_{\\text{near}}$。\n- 最终结果必须以 mebibytes (MiB) 为单位报告，其中 $1 \\text{ MiB} = 2^{20}$ 字节，并四舍五入到 $6$ 位小数。\n\n验证结论是该问题有效。它在科学上是合理的，因为它基于 FMM 算法的既定原理及其常用数据结构。所有术语都得到了明确的定义，并提供了所有必要的参数和公式。该问题是良构的，对于每组输入参数都能得出一个唯一的、可验证的解。\n\n我们现在进行形式推导和计算。总内存 $M_{\\text{total}}$ 是粒子数 $N$、展开阶数 $p$ 和叶节点容量 $n_{\\text{leaf}}$ 的函数。对于给定的三元组 $(N, p, n_{\\text{leaf}})$，计算按以下步骤执行。\n\n首先，我们确定八叉树的结构参数。\n容纳 $N$ 个粒子所需的最小叶节点数（每个叶节点容量为 $n_{\\text{leaf}}$）是：\n$$ L_{\\text{req}} = \\left\\lceil \\frac{N}{n_{\\text{leaf}}} \\right\\rceil $$\n问题指定了一个完整的、层级均匀的八叉树。该树的深度 $h$ 必须是最小的非负整数，使得叶节点数 $8^h$ 至少为 $L_{\\text{req}}$。这表示为：\n$$ h = \\min \\{ h' \\in \\mathbb{N}_0 : 8^{h'} \\ge L_{\\text{req}} \\} $$\n这可以通过找到满足 $h \\ge \\log_8(L_{\\text{req}})$ 的最小整数 $h$ 来计算，即对于 $L_{\\text{req}} \\ge 1$，有 $h = \\lceil\\log_8(L_{\\text{req}})\\rceil$。对于 $N=0$ 或没有粒子落入任何盒子（测试套件中不包含这种情况）的边界情况，$L_{\\text{req}}$ 可能为 $0$，此时 $h=0$ 是正确的选择。\n一旦确定了深度 $h$，完整树模型中的叶节点数为：\n$$ \\text{leaves} = 8^h $$\n深度为 $h$ 的完整八叉树中的总节点数是一个几何级数的和：\n$$ \\text{total\\_nodes} = \\sum_{k=0}^{h} 8^k = \\frac{8^{h+1} - 1}{8 - 1} = \\frac{8^{h+1} - 1}{7} $$\n\n其次，我们使用这些结构参数计算模型各组件的内存使用情况。\n$N$ 个粒子的存储直接给出：\n$$ M_{\\text{particles}} = 48N $$\n所有树节点（内部和叶节点）的元数据是：\n$$ M_{\\text{node-meta}} = 48 \\times \\text{total\\_nodes} $$\n在所有节点上，多极展开和局部展开的存储（每个展开有 $(p+1)^2$ 个系数，大小为 $8$ 字节）是：\n$$ M_{\\text{exp}} = 2 \\times (p+1)^2 \\times 8 \\times \\text{total\\_nodes} = 16(p+1)^2 \\times \\text{total\\_nodes} $$\n所有叶节点的固定大小邻居列表的存储是：\n$$ M_{\\text{near}} = 26 \\times 8 \\times \\text{leaves} = 208 \\times \\text{leaves} $$\n\n第三，我们将这些组件相加以求得总内存（以字节为单位）：\n$$ M_{\\text{total}}(N, p, n_{\\text{leaf}}) = M_{\\text{particles}} + M_{\\text{node-meta}} + M_{\\text{exp}} + M_{\\text{near}} $$\n代入每个组件的表达式，得到完整的模型：\n$$ M_{\\text{total}} = 48N + 48 \\left(\\frac{8^{h+1} - 1}{7}\\right) + 16(p+1)^2 \\left(\\frac{8^{h+1} - 1}{7}\\right) + 208(8^h) $$\n这可以通过提取 `total_nodes` 项来简化：\n$$ M_{\\text{total}} = 48N + \\left(48 + 16(p+1)^2\\right) \\left(\\frac{8^{h+1} - 1}{7}\\right) + 208(8^h) $$\n\n最后，将以字节为单位的结果转换为 mebibytes (MiB)，并四舍五入到指定的精度：\n$$ M_{\\text{MiB}} = \\frac{M_{\\text{total}}}{2^{20}} $$\n将此过程应用于每个指定的测试用例以生成最终输出。例如，对于情况 $(N, p, n_{\\text{leaf}}) = (100000, 6, 200)$，我们有：\n- $L_{\\text{req}} = \\lceil 100000 / 200 \\rceil = 500$。\n- $h = \\min \\{h' : 8^{h'} \\ge 500\\} = 3$，因为 $8^2 = 64$ 且 $8^3 = 512$。\n- $\\text{leaves} = 8^3 = 512$。\n- $\\text{total\\_nodes} = (8^4 - 1)/7 = 4095/7 = 585$。\n- $M_{\\text{particles}} = 48 \\times 100000 = 4,800,000$ 字节。\n- $M_{\\text{node-meta}} = 48 \\times 585 = 28,080$ 字节。\n- $M_{\\text{exp}} = 16 \\times (6+1)^2 \\times 585 = 16 \\times 49 \\times 585 = 458,640$ 字节。\n- $M_{\\text{near}} = 208 \\times 512 = 106,496$ 字节。\n- $M_{\\text{total}} = 4800000 + 28080 + 458640 + 106496 = 5,393,216$ 字节。\n- $M_{\\text{MiB}} = 5393216 / 2^{20} \\approx 5.1434326... \\rightarrow 5.143433$ MiB。\n实现将机械化地执行此确切过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\n# from scipy import ...\n\ndef calculate_memory_mib(N, p, n_leaf):\n    \"\"\"\n    Calculates the total memory footprint of an FMM implementation in Mebibytes (MiB).\n\n    Args:\n        N (int): The total number of particles.\n        p (int): The expansion order for spherical harmonics.\n        n_leaf (int): The maximum number of particles per leaf node.\n\n    Returns:\n        float: The total memory usage in MiB.\n    \"\"\"\n    # Step 1: Determine tree structure parameters\n    if N == 0:\n        L_req = 0\n    else:\n        L_req = math.ceil(N / n_leaf)\n\n    if L_req == 0:\n        h = 0\n    else:\n        h = math.ceil(math.log(L_req, 8)) if L_req > 1 else 0\n\n    # Number of leaves in a complete octree of depth h\n    leaves = 8**h\n    # Total nodes in a complete octree of depth h\n    total_nodes = (8**(h + 1) - 1) // 7 if h >= 0 else 0\n\n    # Step 2: Calculate memory for each component in bytes\n    # Per-particle storage\n    m_particles = 48 * N\n    \n    # Per-node metadata storage\n    m_node_meta = 48 * total_nodes\n    \n    # Per-node expansion storage\n    num_coeffs = (p + 1)**2\n    # 2 expansions (multipole, local) * num_coeffs * 8 bytes/coeff\n    m_exp = 16 * num_coeffs * total_nodes\n    \n    # Per-leaf near-neighbor list storage\n    # 26 neighbors * 8 bytes/index\n    m_near = 208 * leaves\n\n    # Step 3: Sum components and convert to MiB\n    m_total_bytes = m_particles + m_node_meta + m_exp + m_near\n    \n    # 1 MiB = 2^20 bytes\n    mebibytes = m_total_bytes / (2**20)\n    \n    return mebibytes\n\ndef solve():\n    \"\"\"\n    Solves the problem by evaluating the memory model for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (N, p, n_leaf)\n    test_cases = [\n        (100000, 6, 200),  # a typical moderate case\n        (50, 0, 200),      # very small N, minimal expansion order\n        (10000, 12, 128),  # moderate N, high expansion order\n        (1000000, 4, 256), # large N, moderate expansion order\n        (400, 1, 200),     # exactly two leaves in occupancy bound\n    ]\n\n    results = []\n    for case in test_cases:\n        N, p, n_leaf = case\n        result_mib = calculate_memory_mib(N, p, n_leaf)\n        # Format the result to exactly 6 decimal places\n        results.append(f\"{result_mib:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "FMM 的 $\\mathcal{O}(N)$ 复杂度是一个渐近性的承诺，其性能表现依赖于粒子的空间分布。本练习  旨在通过探索“病态”或非均匀的粒子排列如何挑战算法的效率，让你深入了解分层方法的性能特点。通过分析不同几何构型下远场和近场计算量的变化，你将对多极子接受准则（Multipole-Acceptance Criterion）的有效性建立起深刻的直觉。",
            "id": "2392072",
            "problem": "您的任务是构建对于层次化长程相互作用方案而言是病态的粒子构型，并对每种构型量化一个基于单元的分组测试如何将相互作用划分为良好分离与近场两类。考虑一个以原点为中心、半尺寸为 $H$ 的轴对齐立方计算域，其中包含 $N$ 个位于位置 $\\{\\mathbf{x}_i\\}_{i=1}^N \\subset \\mathbb{R}^3$ 的点粒子。将该域划分为一个八叉树：递归地将任何包含超过 $C$ 个粒子的立方体细分为8个相等的子立方体，直到某个立方体中的粒子数最多为 $C$ 或达到最大深度 $D$ 为止。根据此规则，任何未被进一步細分的非空立方體都是一个叶单元。令 $\\mathcal{L}$ 表示所有此类至少包含一个粒子的叶单元的集合。\n\n对于每个中心为 $\\mathbf{c}_T$、半尺寸为 $h_T$ 的目标叶单元 $T \\in \\mathcal{L}$，根据以下几何规则定义其相互作用列表 $\\mathcal{I}(T)$，该列表是一个源单元 $S$ 的集合。对于任何中心为 $\\mathbf{c}_S$、半尺寸为 $h_S$ 的源单元 $S$，定义欧几里得距离 $r_{ST} = \\|\\mathbf{c}_S - \\mathbf{c}_T\\|_2$以及不相交谓词：$S$ 和 $T$ 不相交当且仅当存在至少一个坐标轴 $a \\in \\{x,y,z\\}$ 使得 $|\\mathbf{c}_{S,a} - \\mathbf{c}_{T,a}|  h_S + h_T$。定义参数为 $\\theta \\in (0,1)$ 的多极子接受测试如下：一个源单元 $S$ 被 $T$ 接受，当且仅当 $S$ 和 $T$ 不相交且 $h_S / r_{ST} \\le \\theta$。按如下方式为每个目标叶对源单元进行分类。从源根单元和一个固定的目标叶 $T$ 开始，如果一个源单元 $S$ 满足接受测试，则将 $S$ 包含在 $\\mathcal{I}(T)$ 中。如果 $S$ 不满足接受测试且 $S$ 不是叶单元，则以相同方式对其子单元进行分类。如果 $S$ 不满足接受测试且 $S$ 是叶单元，或者如果 $S$ 和 $T$ 不相交且 $S$ 是叶单元，则该对 $(S,T)$ 是一个必须直接计算的近场叶单元对。此外，如果 $r_{ST} = 0$，则该对不能被接受且必须被细化，除非 $S$ 是一个叶单元，此时它是一个近场叶单元对。对于每个目标叶 $T$，此过程产生一个有限集 $\\mathcal{I}(T)$ 和一个包含 $T$ 的相应近场叶单元对的多重集。\n\n对于下面指定的每种构型，使用给定参数构建八叉树，并计算以下四个量：\n- 所有目标中最大的相互作用列表大小，$\\max_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$。\n- 所有目标中相互作用列表大小的算术平均值，$\\frac{1}{|\\mathcal{L}|} \\sum_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$，四舍五入到小数点后三位。\n- 所有目标遇到的近场叶单元对的总数，$\\sum_{T \\in \\mathcal{L}} \\#\\{\\text{涉及 }T\\text{ 的近场叶单元对}\\}$。\n- 目标叶单元的数量， $|\\mathcal{L}|$。\n\n角度必须以弧度为单位进行解释。\n\n构建以下五种病态构型，每种构型都在半尺寸 $H=1.25$ 的立方体内，八叉树容量 $C=32$，最大深度 $D=20$，多极子接受参数 $\\theta = 0.5$。所有距离都是无单位的。在所有情况下，除非另有说明，否则取粒子半径参数 $R = 1$。\n\n测试套件（每行是一个指定几何形状和参数的测试用例）：\n1. 空心球壳：$N = 4096$ 个点准均匀分布在半径为 $R$ 的球面上。使用确定性的 Fibonacci 构造：令 $\\varphi = \\frac{1+\\sqrt{5}}{2}$ 且 $\\alpha = 2\\pi\\left(1 - \\frac{1}{\\varphi}\\right)$。对于 $k \\in \\{0,1,\\dots,N-1\\}$，定义 $z_k = 1 - \\frac{2(k+0.5)}{N}$，$r_k = \\sqrt{1 - z_k^2}$，$\\theta_k = \\alpha k$，并设置 $\\mathbf{x}_k = \\left(R r_k \\cos \\theta_k, R r_k \\sin \\theta_k, R z_k\\right)$。\n2. 大圆环：$N = 4096$ 个点位于 $z=0$ 平面上半径为 $R$ 的圆上。对于 $k \\in \\{0,1,\\dots,N-1\\}$，设置 $\\mathbf{x}_k = \\left(R \\cos \\frac{2\\pi k}{N}, R \\sin \\frac{2\\pi k}{N}, 0\\right)$。\n3. 八角点簇：$N=4096$ 个点排列成8个相同的 $8\\times 8 \\times 8$ 点网格，每个网格封装在一个边长为 $0.02$ 的小立方体内，该小立方体的中心靠近边长为 $2R$ 的大立方体的每个角点，并向内偏移 $0.05$。设向内偏移为 $\\delta = 0.05$，微网格跨度为 $\\varepsilon = 0.02$。对于每个角点符号三元组 $\\mathbf{s} \\in \\{-1,1\\}^3$，定义点簇中心 $\\mathbf{c}_{\\mathbf{s}} = \\mathbf{s}\\,(R - \\delta)$。对于网格索引 $(p,q,r) \\in \\{0,1,\\dots,7\\}^3$，定义局部偏移 $\\mathbf{o}_{pqr} = \\varepsilon \\left(\\frac{p}{7} - \\frac{1}{2}, \\frac{q}{7} - \\frac{1}{2}, \\frac{r}{7} - \\frac{1}{2}\\right)$，并为每个 $(\\mathbf{s},p,q,r)$ 在 $\\mathbf{x} = \\mathbf{c}_{\\mathbf{s}} + \\mathbf{o}_{pqr}$ 处放置一个粒子。\n4. 单个粒子：$N=1$ 个粒子位于原点，$\\mathbf{x}_1 = (0,0,0)$。\n5. 共线直线：$N=4096$ 个粒子等间距分布在从 $-R$ 到 $R$（含端点）的 $x$ 轴上。对于 $k \\in \\{0,1,\\dots,N-1\\}$，设置 $\\mathbf{x}_k = \\left(-R + \\frac{2R}{N-1} k, 0, 0\\right)$。\n\n对于所有测试用例，使用上面指定的相同域半尺寸 $H$、八叉树容量 $C$、最大深度 $D$ 和多极子参数 $\\theta$。您的程序必须构建粒子、建立八叉树、按定义为每个目标叶执行分类，并计算所要求的四个量。您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个测试用例贡献一个包含四个数字的列表，顺序如上所述。例如，输出格式应为单行，如 $[\\,[a_1,b_1,c_1,d_1],\\,[a_2,b_2,c_2,d_2],\\,\\dots\\,]$，其中 $a_i, b_i, c_i, d_i$ 是测试用例 $i$ 的四个数字，且 $b_i$ 四舍五入到小数点后三位。",
            "solution": "所提出的问题是计算物理学中一个明确定义的练习，具体涉及快速多极子方法（FMM）核心组件的分析。该任务要求实现一个八叉树数据结构来划分包含粒子的三维空间，并随后对该树的每个叶节点，基于几何多极子接受准则，将所有其他单元分类为远场（相互作用列表的一部分）或近场。此分析必须针对五个特定的粒子构型进行，这些构型旨在测试算法在病态条件下的行为。该问题在科学上是合理的，数学上是精确的，并且在算法上是明确的。因此，它被认为是一个有效的问题。\n\n解决方案通过实现指定的算法并将其应用于每个测试用例来进行。解决方案的主要组成部分是：粒子生成、八叉树构建和相互作用分类。\n\n**1. 粒子生成**\n\n对于五个测试用例中的每一个，在由半尺寸 $H=1.25$、以原点为中心的立方体定义的域内生成 $N$ 个粒子。坐标 $\\{\\mathbf{x}_i\\}_{i=1}^N$ 由以下规则确定，半径参数 $R=1$：\n\n- **情况1：空心球壳 ($N=4096$)**\n  粒子使用 Fibonacci 晶格构造分布在半径为 $R=1$ 的球面上。对于 $k \\in \\{0, 1, \\dots, N-1\\}$，其中 $\\varphi = \\frac{1+\\sqrt{5}}{2}$ 且 $\\alpha = 2\\pi(1 - 1/\\varphi)$，坐标 $\\mathbf{x}_k = (x_k, y_k, z_k)$ 为：\n  $$ z_k = 1 - \\frac{2(k+0.5)}{N} $$\n  $$ r_k = \\sqrt{1 - z_k^2} $$\n  $$ \\theta_k = \\alpha k $$\n  $$ \\mathbf{x}_k = (R r_k \\cos \\theta_k, R r_k \\sin \\theta_k, R z_k) $$\n\n- **情况2：大圆环 ($N=4096$)**\n  粒子均匀分布在 $z=0$ 平面上半径为 $R=1$ 的圆上。对于 $k \\in \\{0, 1, \\dots, N-1\\}$：\n  $$ \\mathbf{x}_k = \\left(R \\cos \\frac{2\\pi k}{N}, R \\sin \\frac{2\\pi k}{N}, 0\\right) $$\n\n- **情况3：八角点簇 ($N=4096$)**\n  $N/8 = 512$ 个粒子被放置在一个小的立方网格中，靠近边长为 $2R$ 的立方体的8个角点中的每一个。参数为 $\\delta=0.05$ 和 $\\varepsilon=0.02$。对于每个角点符号三元组 $\\mathbf{s} \\in \\{-1,1\\}^3$ 和网格索引 $(p,q,r) \\in \\{0,1,\\dots,7\\}^3$：\n  $$ \\mathbf{c}_{\\mathbf{s}} = \\mathbf{s}\\,(R - \\delta) $$\n  $$ \\mathbf{o}_{pqr} = \\varepsilon \\left(\\frac{p}{7} - \\frac{1}{2}, \\frac{q}{7} - \\frac{1}{2}, \\frac{r}{7} - \\frac{1}{2}\\right) $$\n  一个粒子被放置在 $\\mathbf{x} = \\mathbf{c}_{\\mathbf{s}} + \\mathbf{o}_{pqr}$处。\n\n- **情况4：单个粒子 ($N=1$)**\n  一个粒子被放置在原点：\n  $$ \\mathbf{x}_1 = (0, 0, 0) $$\n\n- **情况5：共线直线 ($N=4096$)**\n  粒子等间距地放置在从 $-R$到 $R$ 的 $x$ 轴上。对于 $k \\in \\{0, 1, \\dots, N-1\\}$：\n  $$ \\mathbf{x}_k = \\left(-R + \\frac{2R}{N-1} k, 0, 0\\right) $$\n\n**2. 八叉树构建**\n\n构建八叉树以空间划分粒子。该过程从一个根单元开始，这是一个以 $(0,0,0)$ 为中心、半尺寸为 $H=1.25$ 的立方体。该单元包含所有 $N$ 个粒子。应用递归细分过程：任何包含超过 $C=32$ 个粒子的单元被细分为8个相等的立方体子单元，除非该单元已达到最大深度 $D=20$。父单元内的粒子随后分布到其子单元中。此过程持续进行，直到所有单元要么包含 $C$ 或更少的粒子，要么处于深度 $D$。未被细分的非空单元是一个叶单元。所有此类葉單元的集合表示为 $\\mathcal{L}$。\n\n**3. 相互作用分类**\n\n对于每个目标叶单元 $T \\in \\mathcal{L}$，对整个八叉树进行遍历（从根单元作为初始源单元 $S$ 开始），以构建其相互作用列表 $\\mathcal{I}(T)$ 并计数近场叶单元对。源单元 $S$ 相对于目标叶 $T$ 的分类规则如下：\n\n- 令 $\\mathbf{c}_S, h_S$ 和 $\\mathbf{c}_T, h_T$ 分别为 $S$ 和 $T$ 的中心和半尺寸。\n- 如果对于至少一个轴 $a \\in \\{x,y,z\\}$，有 $|\\mathbf{c}_{S,a} - \\mathbf{c}_{T,a}|  h_S + h_T$，则单元是不相交的。\n- 如果 $S$ 和 $T$ 不相交且条件 $h_S / r_{ST} \\le \\theta$ 成立，则满足多极子接受准则（MAC），其中 $r_{ST} = \\|\\mathbf{c}_S - \\mathbf{c}_T\\|_2$ 且 $\\theta=0.5$。如果 $r_{ST}=0$，则测试失败。\n\n对于给定的目标 $T$ 和源单元 $S$，递归分类过程如下：\n1. 如果满足MAC，则将 $S$ 添加到 $\\mathcal{I}(T)$ 中，并且对源树此分支的遍历终止。\n2. 如果不满足MAC：\n   a. 如果 $S$ 是一个非叶单元，则对它的每个子单元递归应用此过程。\n   b. 如果 $S$ 是一个叶单元，则该对 $(S,T)$ 被分类为近场叶单元对。\n\n对每个目标叶单元 $T \\in \\mathcal{L}$ 重复此过程。\n\n**4. 统计数据计算**\n\n在为所有目标叶分类相互作用后，为每个测试用例计算以下四个量：\n- 任何相互作用列表的最大大小：$\\max_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$。\n- 相互作用列表大小的算术平均值，四舍五入到小数点后三位：$\\frac{1}{|\\mathcal{L}|} \\sum_{T \\in \\mathcal{L}} |\\mathcal{I}(T)|$。\n- 近场叶单元对的总数：$\\sum_{T \\in \\mathcal{L}} \\#\\{S \\in \\mathcal{L} \\mid (S,T) \\text{ 是近场对}\\}$。\n- 非空叶单元的总数：$|\\mathcal{L}|$。\n\n该实现系统地执行这些步骤，为五个粒子构型中的每一个收集四个统计数据。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\n# from scipy import ... # Scipy is not required for this implementation.\n\nclass Cell:\n    \"\"\"Represents a cell in the octree.\"\"\"\n    def __init__(self, center, half_size, depth, parent=None):\n        self.center = center\n        self.half_size = half_size\n        self.depth = depth\n        self.parent = parent\n        self.children = []\n        self.particle_indices = []\n        self.is_leaf = False\n\ndef generate_particles(config, N, R):\n    \"\"\"Generates particle coordinates for a given configuration.\"\"\"\n    if config == \"sphere\":\n        particles = np.zeros((N, 3))\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        alpha = 2.0 * np.pi * (1.0 - 1.0 / phi)\n        for k in range(N):\n            z_k = 1.0 - (2.0 * (k + 0.5)) / N\n            r_k = np.sqrt(1.0 - z_k**2)\n            theta_k = alpha * k\n            particles[k] = [R * r_k * np.cos(theta_k), R * r_k * np.sin(theta_k), R * z_k]\n        return particles\n    elif config == \"ring\":\n        particles = np.zeros((N, 3))\n        for k in range(N):\n            angle = 2.0 * np.pi * k / N\n            particles[k] = [R * np.cos(angle), R * np.sin(angle), 0.0]\n        return particles\n    elif config == \"clusters\":\n        particles = np.zeros((N, 3))\n        delta = 0.05\n        epsilon = 0.02\n        pidx = 0\n        signs = [-1.0, 1.0]\n        for sx in signs:\n            for sy in signs:\n                for sz in signs:\n                    s_vec = np.array([sx, sy, sz])\n                    cluster_center = s_vec * (R - delta)\n                    for p in range(8):\n                        for q in range(8):\n                            for r in range(8):\n                                o_pqr = epsilon * (np.array([p / 7.0, q / 7.0, r / 7.0]) - 0.5)\n                                particles[pidx] = cluster_center + o_pqr\n                                pidx += 1\n        return particles\n    elif config == \"single\":\n        return np.array([[0.0, 0.0, 0.0]])\n    elif config == \"line\":\n        return np.linspace([-R, 0, 0], [R, 0, 0], N)\n    return np.array([])\n\ndef build_octree_recursive(cell, particles, C, D):\n    \"\"\"Recursively builds the octree.\"\"\"\n    if len(cell.particle_indices) = C or cell.depth = D:\n        cell.is_leaf = len(cell.particle_indices)  0\n        return\n\n    child_half_size = cell.half_size / 2.0\n    offsets = np.array([\n        [-1, -1, -1], [ 1, -1, -1], [-1,  1, -1], [ 1,  1, -1],\n        [-1, -1,  1], [ 1, -1,  1], [-1,  1,  1], [ 1,  1,  1]\n    ]) * child_half_size\n\n    child_centers = cell.center + offsets\n    \n    # Partition particles\n    particle_coords = particles[cell.particle_indices]\n    relative_coords = particle_coords - cell.center\n    \n    child_indices_map = collections.defaultdict(list)\n    for i, p_idx in enumerate(cell.particle_indices):\n        pos = relative_coords[i]\n        child_num = ( (1 if pos[0] = 0 else 0) +\n                      (2 if pos[1] = 0 else 0) +\n                      (4 if pos[2] = 0 else 0) )\n        child_indices_map[child_num].append(p_idx)\n\n    for i in range(8):\n        child_center = child_centers[i]\n        child = Cell(child_center, child_half_size, cell.depth + 1, parent=cell)\n        if i in child_indices_map:\n            child.particle_indices = child_indices_map[i]\n            build_octree_recursive(child, particles, C, D)\n        else:\n            # Empty cell, mark as leaf but it won't be collected\n            child.is_leaf = True\n        cell.children.append(child)\n\ndef get_leaf_cells(cell):\n    \"\"\"Collects all non-empty leaf cells from the tree.\"\"\"\n    if not cell:\n        return []\n    if cell.is_leaf:\n        return [cell] if len(cell.particle_indices)  0 else []\n    \n    leaves = []\n    for child in cell.children:\n        leaves.extend(get_leaf_cells(child))\n    return leaves\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        (\"sphere\", 4096, 1.0),\n        (\"ring\", 4096, 1.0),\n        (\"clusters\", 4096, 1.0),\n        (\"single\", 1, 1.0),\n        (\"line\", 4096, 1.0),\n    ]\n\n    H = 1.25\n    C = 32\n    D = 20\n    THETA = 0.5\n\n    all_results = []\n\n    for config, N, R in test_cases:\n        particles = generate_particles(config, N, R)\n        \n        root = Cell(center=np.array([0.0, 0.0, 0.0]), half_size=H, depth=0)\n        root.particle_indices = list(range(N))\n        \n        build_octree_recursive(root, particles, C, D)\n        \n        leaf_cells = get_leaf_cells(root)\n        num_leaves = len(leaf_cells)\n\n        if num_leaves == 0:\n            all_results.append([0, 0.0, 0, 0])\n            continue\n\n        interaction_list_sizes = []\n        total_near_field_pairs = 0\n\n        for target_leaf in leaf_cells:\n            current_target_results = {'ilist': [], 'near_field_pairs': 0}\n            find_interactions_wrapper(target_leaf, root, THETA, current_target_results)\n\n            interaction_list_sizes.append(len(current_target_results['ilist']))\n            total_near_field_pairs += current_target_results['near_field_pairs']\n\n        max_ilist_size = max(interaction_list_sizes) if interaction_list_sizes else 0\n        mean_ilist_size = np.mean(interaction_list_sizes) if interaction_list_sizes else 0.0\n\n        all_results.append([\n            max_ilist_size,\n            round(mean_ilist_size, 3),\n            total_near_field_pairs,\n            num_leaves\n        ])\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef find_interactions_wrapper(target_leaf, root, theta, results):\n    \"\"\"\n    Wrapper for recursive interaction finding for a single target leaf.\n    This starts the traversal from the root for a given target.\n    \"\"\"\n    to_visit = [root]\n    while to_visit:\n        source_cell = to_visit.pop(0)\n\n        if not source_cell or (source_cell.is_leaf and not source_cell.particle_indices):\n            continue\n\n        r_st_vec = source_cell.center - target_leaf.center\n        \n        is_disjoint = np.any(np.abs(r_st_vec)  (source_cell.half_size + target_leaf.half_size))\n        \n        mac_satisfied = False\n        if is_disjoint:\n            r_st = np.linalg.norm(r_st_vec)\n            if r_st  1e-12 and (source_cell.half_size / r_st) = theta:\n                mac_satisfied = True\n\n        if mac_satisfied:\n            results['ilist'].append(source_cell)\n        else:\n            if source_cell.is_leaf:\n                results['near_field_pairs'] += 1\n            else:\n                for child in source_cell.children:\n                    to_visit.append(child)\n\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "虽然 FMM 显著降低了计算的总体复杂度，但剩余的直接（近场）计算部分仍然可能成为性能瓶颈。本练习  深入探讨了现代高性能计算技术，展示了如何利用 SIMD（单指令多数据）并行原理来加速这些直接计算。掌握这种优化是创建真正高速 FMM 实现的关键一步，它将算法理论与硬件感知编程实践联系在一起。",
            "id": "2392085",
            "problem": "给定一个三维空间中的$N$个点粒子系统，它们通过一种软化的反平方律核（引力或静电）进行相互作用，粒子$i$和$j$之间的势对力由下式给出：\n$$\n\\mathbf{F}_{ij} \\;=\\; G\\,m_i m_j \\,\\frac{\\mathbf{r}_{j}-\\mathbf{r}_{i}}{\\left(\\lVert \\mathbf{r}_{j}-\\mathbf{r}_{i}\\rVert^2 + \\varepsilon^2\\right)^{3/2}},\n$$\n其中$G$是一个常数，$m_i$是粒子$i$的质量，$\\mathbf{r}_i \\in \\mathbb{R}^3$是其位置，$\\varepsilon0$是一个软化长度，用于避免零间距时的奇点。快速多极子方法（FMM）的近场阶段仅计算每个单元局部邻域内粒子间的精确对相互作用，而远场相互作用则通过多极展开进行近似。在此任务中，您将通过使用向量化数组算术进行批量操作，为一组单元实现基于单指令多数据（SIMD）原则的近场计算。\n\n从以下基本原理开始：牛顿万有引力定律指出，位于位置$\\mathbf{r}_i$、质量为$m_i$的粒子，会受到位于位置$\\mathbf{r}_j$、质量为$m_j$的另一个粒子的作用力，该力的大小与质量乘积$m_i m_j$成正比，与它们之间的间隔距离的平方成反比，方向沿连接两个粒子的直线。在数值模拟中，一种标准且经过充分检验的修正是引入一个软化参数$\\varepsilon$来对短距离处的核进行正则化。这产生了上述的软化对力，它是在$N$体计算中广泛使用且物理上现实的模型。\n\n将单位立方体域$[0,1)^3$划分为一个均匀的笛卡尔网格，该网格由边长为$h0$的立方单元组成。每个单元由一个三元组$(c_x,c_y,c_z)$索引，其中$c_x\\in\\{0,\\dots,n_x-1\\}$，$c_y\\in\\{0,\\dots,n_y-1\\}$，$c_z\\in\\{0,\\dots,n_z-1\\}$，且$n_x=\\lceil 1/h\\rceil$，$n_y=\\lceil 1/h\\rceil$，$n_z=\\lceil 1/h\\rceil$。一个单元的近场相互作用列表包括其自身及其在$3\\times 3\\times 3$模板中的相邻邻居，并在域边界处截断。为避免重复计数，强制执行以下决胜规则：对于一个给定的索引为$(c_x,c_y,c_z)$的单元，只处理满足$(\\delta_x0)$或$(\\delta_x=0 \\wedge \\delta_y0)$或$(\\delta_x=0 \\wedge \\delta_y=0 \\wedge \\delta_z\\ge 0)$的邻居偏移$(\\delta_x,\\delta_y,\\delta_z)$。对于同一单元的情况$(\\delta_x,\\delta_y,\\delta_z)=(0,0,0)$，将对相互作用限制在按索引排序的对$i  j$上，以避免自相互作用和重复计算。您的任务是实现一个参考循环实现和一个向量化的“SIMD”实现，并使用提供的测试套件验证它们的一致性和正确性。向量化实现应将单元中的源粒子分块处理，块宽度为$w$。",
            "solution": "提交分析的问题陈述被认为是有效的。它在科学上是合理的、提法明确的、客观的且内部一致的。它提出了计算物理学中的一个标准任务：实现$N$体系统的直接近场力计算，这是诸如快速多极子方法（FMM）等算法的基本组成部分。该问题提供了精确的数学定义、算法约束和一套全面的可验证测试用例。因此，我将继续提供一个完整的解决方案。\n\n问题的核心是计算$N$粒子系统中每个粒子$i$上的总力$\\mathbf{F}_i = \\sum_{j \\neq i} \\mathbf{F}_{ij}$，其中对力由软化的反平方律给出：\n$$\n\\mathbf{F}_{ij} \\;=\\; G\\,m_i m_j \\,\\frac{\\mathbf{r}_{j}-\\mathbf{r}_{i}}{\\left(\\lVert \\mathbf{r}_{j}-\\mathbf{r}_{i}\\rVert^2 + \\varepsilon^2\\right)^{3/2}}\n$$\n对所有粒子对进行直接求和的计算成本为$\\mathcal{O}(N^2)$，这对于大的$N$来说是高得令人望而却步的。FMM通过将相互作用分解为近场和远场贡献来减轻这一成本。本问题专门关注近场部分，其中相互作用是直接计算的。\n\n为了组织这个计算，将域划分为一个立方单元网格。一个粒子的近场由其自身单元和相邻单元内的粒子组成。对于一个给定的单元，其相互作用列表包括其自身及其在$3 \\times 3 \\times 3$模板中的26个邻居。为了确保每个粒子对只被考虑一次并遵守牛顿第三定律（$\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}$），需要一个系统性的规则来处理单元对。问题指定了一个关于单元偏移向量$(\\delta_x, \\delta_y, \\delta_z)$的字典序决胜规则，这保证了对于任何两个不同的相互作用单元，计算只执行一次。\n\n我们将按要求构建两种实现：一种是使用显式循环的参考实现，作为正确性的基准；另一种是向量化实现，模仿单指令多数据（SIMD）处理，以提高在现代计算机架构上的性能。\n\n首先，必须有效地将粒子分配到它们各自的单元中。给定粒子位置$\\mathbf{r}_i = (x_i, y_i, z_i)$和单元边长$h$，单元索引$(c_x, c_y, c_z)$可通过$c_k = \\lfloor r_{i,k} / h \\rfloor$找到。可以为每个单元计算一个标量键，例如，通过$k = c_x n_y n_z + c_y n_z + c_z$，这有助于按单元对粒子进行排序和分组。\n\n**参考实现**\n\n此实现使用嵌套循环直接遵循规定的逻辑。\n1. 创建一个数据结构，如字典，将每个单元索引$(c_x, c_y, c_z)$映射到居住在其中的粒子索引列表。\n2. 算法遍历网格中的每个单元$C_1$。\n3. 对于每个$C_1$，它遍历由决胜规则定义的14个有效邻居偏移$(\\delta_x, \\delta_y, \\delta_z)$。这可以找到目标单元$C_2$。\n4. 如果$C_1$和$C_2$是同一个单元（偏移为$(0,0,0)$），我们计算其内部粒子之间的相互作用。为避免自相互作用和重复计数，我们遍历满足$i  j$的粒子对$(i, j)$，计算$\\mathbf{F}_{ij}$，并将其加到粒子$i$的总力上，将$-\\mathbf{F}_{ij}$加到粒子$j$的总力上。\n5. 如果$C_1$和$C_2$是不同的单元，我们遍历$C_1$中的所有粒子$i$和$C_2$中的所有粒子$j$。对于每一对，我们计算$\\mathbf{F}_{ij}$并相应地更新两个粒子上的力。\n\n**向量化（类SIMD）实现**\n\n此方法利用向量化数组操作（由NumPy等库提供）在单次操作中处理多个数据元素。\n1. **数据重组**：为了实现高效的块处理，根据粒子数据的单元键对其进行排序（位置和质量数组）。这将在内存中物理地将来自同一单元的粒子分组在一起。我们还必须存储反向映射，以将最终的力数组恢复到其原始顺序。\n2. **单元对迭代**：遍历单元对的主循环结构与参考实现相似。但是，我们现在处理的是已排序数组的切片，这些切片对应于给定单元中的粒子，而不是索引列表。\n3. **跨单元相互作用**：这是向量化最有效的地方。对于目标单元$C_1$和源单元$C_2$之间的相互作用，我们以指定的宽度$w$分块处理来自$C_2$的粒子。对于每个包含$w$个源粒子的块，我们使用广播同时计算其与$C_1$中所有目标粒子的相互作用：\n    - 设$C_1$中$N_t$个目标的位置为$\\mathbf{R}_t$（形状为$(N_t, 3)$），$C_2$中一个包含$w$个源粒子的块的位置为$\\mathbf{R}_s$（形状为$(w, 3)$）。\n    - 位移向量计算为一个张量：$\\Delta\\mathbf{R} = \\mathbf{R}_s[None, :, :] - \\mathbf{R}_t[:, None, :]$，结果形状为$(N_t, w, 3)$。\n    - 距离的平方$\\lVert \\Delta\\mathbf{R} \\rVert^2$及后续的力计算都在这些张量上执行。\n    - 通过沿源维度（轴1）求和，可以找到每个目标粒子受源块作用的总力。\n    - 根据牛顿第三定律，块中每个源粒子上的力是沿目标维度（轴0）求和的负值。然后将这些力贡献累加到全局力数组中。\n4. **同一单元内的相互作用**：条件$i  j$本质上是串行的，不能通过简单的数组操作高效地向量化。按照问题陈述的允许，这部分使用标准的嵌套循环遍历单元切片内的粒子，与参考方法相同。\n\n这种向量化策略，特别是对于跨单元相互作用，显著减少了显式Python循环的数量，并允许底层的编译库利用硬件级并行性，从而带来显著的性能提升。最后，计算出的已排序粒子的力数组将被重新排序，以匹配原始粒子输入顺序。提供的测试套件用于验证两种实现的正确性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    \n    # --- Helper function for force calculation kernel ---\n    def compute_pairwise_force(pos_i, mass_i, pos_j, mass_j, G, eps):\n        \"\"\"\n        Computes pairwise forces between two sets of particles i and j.\n        This is a vectorized kernel.\n        Returns:\n            F_on_i: Force on particles i from particles j.\n            F_on_j: Force on particles j from particles i.\n        \"\"\"\n        # Broadcasting to compute all pairs of interactions\n        # dr shape: (num_i, num_j, 3)\n        dr = pos_j[np.newaxis, :, :] - pos_i[:, np.newaxis, :]\n        \n        # r_sq shape: (num_i, num_j)\n        r_sq = np.sum(dr**2, axis=2)\n        \n        # inv_r3 shape: (num_i, num_j)\n        inv_r3 = (r_sq + eps**2)**(-1.5)\n        \n        # mass_prod shape: (num_i, num_j)\n        mass_prod = mass_i[:, np.newaxis] * mass_j[np.newaxis, :]\n        \n        # F_matrix shape: (num_i, num_j, 3)\n        # force on i from j\n        F_matrix = G * mass_prod[:, :, np.newaxis] * dr * inv_r3[:, :, np.newaxis]\n        \n        # F_on_i shape: (num_i, 3)\n        F_on_i = np.sum(F_matrix, axis=1)\n        \n        # F_on_j shape: (num_j, 3)\n        F_on_j = -np.sum(F_matrix, axis=0)\n        \n        return F_on_i, F_on_j\n\n    # --- Reference implementation using loops ---\n    def reference_near_field(N, pos, mass, h, G, eps):\n        \"\"\"\n        Reference near-field computation using nested loops.\n        \"\"\"\n        forces = np.zeros((N, 3), dtype=np.float64)\n        \n        if N == 0:\n            return forces\n\n        nx = ny = nz = int(np.ceil(1.0 / h))\n        \n        # Build cell map\n        cell_map = {}\n        for i in range(N):\n            cell_idx = tuple(np.floor(pos[i] / h).astype(int))\n            if cell_idx not in cell_map:\n                cell_map[cell_idx] = []\n            cell_map[cell_idx].append(i)\n\n        # Generate valid neighbor offsets\n        offsets = []\n        for dx in range(-1, 2):\n            for dy in range(-1, 2):\n                for dz in range(-1, 2):\n                    if dx  0 or (dx == 0 and dy  0) or (dx == 0 and dy == 0 and dz = 0):\n                        offsets.append((dx, dy, dz))\n        \n        for cx in range(nx):\n            for cy in range(ny):\n                for cz in range(nz):\n                    c1_idx = (cx, cy, cz)\n                    if c1_idx not in cell_map:\n                        continue\n                    \n                    particles_c1 = cell_map[c1_idx]\n                    \n                    for dx, dy, dz in offsets:\n                        c2_idx = (cx + dx, cy + dy, cz + dz)\n                        \n                        if not (0 = c2_idx[0]  nx and 0 = c2_idx[1]  ny and 0 = c2_idx[2]  nz):\n                            continue\n                        \n                        if c2_idx not in cell_map:\n                            continue\n                        \n                        particles_c2 = cell_map[c2_idx]\n\n                        if c1_idx == c2_idx: # Same-cell interaction\n                            for i_idx, p_i in enumerate(particles_c1):\n                                for p_j in particles_c1[i_idx + 1:]:\n                                    dr = pos[p_j] - pos[p_i]\n                                    r_sq = np.sum(dr**2)\n                                    inv_r3 = (r_sq + eps**2)**(-1.5)\n                                    f_vec = G * mass[p_i] * mass[p_j] * dr * inv_r3\n                                    forces[p_i] += f_vec\n                                    forces[p_j] -= f_vec\n                        else: # Cross-cell interaction\n                            for p_i in particles_c1:\n                                for p_j in particles_c2:\n                                    dr = pos[p_j] - pos[p_i]\n                                    r_sq = np.sum(dr**2)\n                                    inv_r3 = (r_sq + eps**2)**(-1.5)\n                                    f_vec = G * mass[p_i] * mass[p_j] * dr * inv_r3\n                                    forces[p_i] += f_vec\n                                    forces[p_j] -= f_vec\n        return forces\n\n    # --- SIMD-like implementation using vectorization ---\n    def simd_like_near_field(N, pos, mass, h, G, eps, w):\n        \"\"\"\n        SIMD-like near-field computation using vectorized array operations.\n        \"\"\"\n        forces_sorted = np.zeros((N, 3), dtype=np.float64)\n        if N == 0:\n            return forces_sorted\n        \n        nx = ny = nz = int(np.ceil(1.0 / h))\n\n        # Reorganize data by cell\n        cell_indices_per_particle = np.floor(pos / h).astype(int)\n        cell_keys = cell_indices_per_particle[:, 0] * (ny * nz) + cell_indices_per_particle[:, 1] * nz + cell_indices_per_particle[:, 2]\n        \n        sorted_indices = np.argsort(cell_keys)\n        unsorted_indices = np.argsort(sorted_indices)\n\n        pos_sorted = pos[sorted_indices]\n        mass_sorted = mass[sorted_indices]\n        \n        unique_cell_keys, cell_starts = np.unique(cell_keys[sorted_indices], return_index=True)\n        cell_counts = np.diff(np.append(cell_starts, N))\n\n        cell_info = {key: {'start': start, 'count': count} \n                     for key, start, count in zip(unique_cell_keys, cell_starts, cell_counts)}\n\n        # Generate valid neighbor offsets\n        offsets = []\n        for dx in range(-1, 2):\n            for dy in range(-1, 2):\n                for dz in range(-1, 2):\n                    if dx  0 or (dx == 0 and dy  0) or (dx == 0 and dy == 0 and dz = 0):\n                        offsets.append((dx, dy, dz))\n        \n        for cx in range(nx):\n            for cy in range(ny):\n                for cz in range(nz):\n                    c1_key = cx * (ny * nz) + cy * nz + cz\n                    if c1_key not in cell_info:\n                        continue\n                    \n                    c1_meta = cell_info[c1_key]\n                    c1_start, c1_count = c1_meta['start'], c1_meta['count']\n                    c1_end = c1_start + c1_count\n                    \n                    pos_c1 = pos_sorted[c1_start:c1_end]\n                    mass_c1 = mass_sorted[c1_start:c1_end]\n\n                    for dx, dy, dz in offsets:\n                        ncx, ncy, ncz = cx + dx, cy + dy, cz + dz\n                        \n                        if not (0 = ncx  nx and 0 = ncy  ny and 0 = ncz  nz):\n                            continue\n                        \n                        c2_key = ncx * (ny * nz) + ncy * nz + ncz\n                        if c2_key not in cell_info:\n                            continue\n                        \n                        c2_meta = cell_info[c2_key]\n                        c2_start, c2_count = c2_meta['start'], c2_meta['count']\n                        c2_end = c2_start + c2_count\n\n                        pos_c2 = pos_sorted[c2_start:c2_end]\n                        mass_c2 = mass_sorted[c2_start:c2_end]\n\n                        if c1_key == c2_key: # Same-cell interaction (loop-based)\n                            for i in range(c1_count):\n                                for j in range(i + 1, c1_count):\n                                    p_i, p_j = c1_start + i, c1_start + j\n                                    dr = pos_sorted[p_j] - pos_sorted[p_i]\n                                    r_sq = np.sum(dr**2)\n                                    inv_r3 = (r_sq + eps**2)**(-1.5)\n                                    f_vec = G * mass_sorted[p_i] * mass_sorted[p_j] * dr * inv_r3\n                                    forces_sorted[p_i] += f_vec\n                                    forces_sorted[p_j] -= f_vec\n                        else: # Cross-cell interaction (vectorized)\n                            for k in range(0, c2_count, w):\n                                block_end = min(k + w, c2_count)\n                                pos_c2_block = pos_c2[k:block_end]\n                                mass_c2_block = mass_c2[k:block_end]\n\n                                f_on_c1, f_on_c2_block = compute_pairwise_force(\n                                    pos_c1, mass_c1, pos_c2_block, mass_c2_block, G, eps)\n                                \n                                forces_sorted[c1_start:c1_end] += f_on_c1\n                                forces_sorted[c2_start + k : c2_start + block_end] += f_on_c2_block\n\n        return forces_sorted[unsorted_indices]\n\n    # --- Test Suite ---\n    results = []\n    G_val = 1.0\n\n    # Test 1: Equivalence on random system\n    N1, h1, eps1, w1 = 64, 0.5, 1e-4, 4\n    rng1 = np.random.default_rng(1234)\n    pos1 = rng1.uniform(0, 1, size=(N1, 3))\n    mass1 = rng1.uniform(0.5, 1.5, size=N1)\n    f_ref = reference_near_field(N1, pos1, mass1, h1, G_val, eps1)\n    f_simd = simd_like_near_field(N1, pos1, mass1, h1, G_val, eps1, w1)\n    results.append(np.max(np.abs(f_ref - f_simd))  1e-11)\n\n    # Test 2: Self-force zero\n    N2, h2, eps2, w2 = 1, 1.0, 1e-3, 4\n    pos2 = np.array([[0.3, 0.4, 0.5]])\n    mass2 = np.array([1.0])\n    f_self = simd_like_near_field(N2, pos2, mass2, h2, G_val, eps2, w2)\n    results.append(np.all(np.abs(f_self)  1e-15))\n\n    # Test 3: Softening finite limit check\n    h3, eps3, w3 = 1.0, 1e-3, 8\n    d3 = 1e-9\n    pos3 = np.array([[0.4, 0.4, 0.4], [0.4 + d3, 0.4, 0.4]])\n    mass3 = np.array([2.0, 3.0])\n    f_soft = simd_like_near_field(2, pos3, mass3, h3, G_val, eps3, w3)\n    f_num = np.linalg.norm(f_soft[0])\n    f_analytic = G_val * mass3[0] * mass3[1] * d3 / (d3**2 + eps3**2)**1.5\n    results.append(abs(f_num - f_analytic) / f_analytic  1e-12)\n\n    # Test 4: Newton’s third law consistency\n    N4, h4, eps4, w4 = 30, 1.0, 1e-4, 4\n    rng4 = np.random.default_rng(2023)\n    pos4 = rng4.uniform(0, 0.4, size=(N4, 3))\n    mass4 = rng4.uniform(0.5, 1.5, size=N4)\n    f_newton = simd_like_near_field(N4, pos4, mass4, h4, G_val, eps4, w4)\n    total_force = np.sum(f_newton, axis=0)\n    results.append(np.linalg.norm(total_force)  1e-11)\n\n    # Test 5: Block width invariance\n    N5, h5, eps5 = 80, 0.25, 1e-4\n    rng5 = np.random.default_rng(777)\n    pos5 = rng5.uniform(0, 1, size=(N5, 3))\n    mass5 = rng5.uniform(0.5, 1.5, size=N5)\n    f_w2 = simd_like_near_field(N5, pos5, mass5, h5, G_val, eps5, w=2)\n    f_w4 = simd_like_near_field(N5, pos5, mass5, h5, G_val, eps5, w=4)\n    f_w8 = simd_like_near_field(N5, pos5, mass5, h5, G_val, eps5, w=8)\n    diff1 = np.max(np.abs(f_w2 - f_w4))\n    diff2 = np.max(np.abs(f_w2 - f_w8))\n    results.append(diff1  1e-11 and diff2  1e-11)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}