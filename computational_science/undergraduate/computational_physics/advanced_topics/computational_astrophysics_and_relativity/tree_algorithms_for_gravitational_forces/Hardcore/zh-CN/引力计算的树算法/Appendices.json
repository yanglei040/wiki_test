{
    "hands_on_practices": [
        {
            "introduction": "掌握树算法的第一步是为静态情况构建一个稳健的实现。本练习  将引导你不仅计算引力加速度（$\\mathbf{a}$），还要计算潮汐张量（$T$），后者描述了作用在物体上的差异力。通过为两者实现基于树的近似，你将深入理解多极展开如何应用于计算引力势的不同阶导数，这是在处理动态模拟之前的一项关键技能。",
            "id": "2447281",
            "problem": "给定一个三维系统，包含 $N$ 个点质量，其位置为 $\\{\\mathbf{r}_k\\}_{k=1}^N \\subset \\mathbb{R}^3$，对应的正质量为 $\\{m_k\\}_{k=1}^N$。在代码单位制下工作，引力常数 $G = 1$，并使用 Plummer 软化，软化长度 $\\varepsilon > 0$。在位置 $\\mathbf{x} \\in \\mathbb{R}^3$ 处的引力势为\n$$\n\\Phi(\\mathbf{x}) \\;=\\; -\\sum_{k=1}^N \\frac{m_k}{\\sqrt{\\|\\mathbf{x}-\\mathbf{r}_k\\|^2 + \\varepsilon^2}} \\, .\n$$\n定义单位测试质量所受的引力（加速度）为 $\\mathbf{a}(\\mathbf{x}) = -\\nabla \\Phi(\\mathbf{x})$，并定义潮汐张量为 $T(\\mathbf{x}) = \\nabla \\mathbf{a}(\\mathbf{x})$，即分量为 $T_{ij}(\\mathbf{x}) = \\partial a_i(\\mathbf{x})/\\partial x_j$ 的雅可比矩阵。\n\n考虑以下用于源分组的近似规则。对于任意子集 $S \\subset \\{1,\\dots,N\\}$，令 $M_S = \\sum_{k \\in S} m_k$ 为其总质量，令 $\\mathbf{c}_S = \\left(\\sum_{k \\in S} m_k \\mathbf{r}_k\\right) / M_S$ 为其质心，并令 $L_S > 0$ 为包含 $\\{\\mathbf{r}_k\\}_{k \\in S}$ 的轴对齐立方体包围盒的边长。对于目标点 $\\mathbf{x}$ 和张角参数 $\\theta \\in (0,1)$，当且仅当满足以下条件时，子集 $S$ 的贡献可以近似为位于 $\\mathbf{c}_S$ 处、质量为 $M_S$ 的单个点质量：\n$$\n\\frac{L_S}{\\|\\mathbf{x} - \\mathbf{c}_S\\|} \\;\\le\\; \\theta \\, .\n$$\n否则，$S$ 必须被划分为不相交的真子集，并递归地应用相同规则，直到每个贡献子集都满足接受不等式或仅包含单个源。\n\n你的任务是编写一个完整的、可运行的程序，对下面指定的每个测试用例执行以下操作：\n- 在每个列出的目标点 $\\mathbf{x}$ 处，计算精确（直接求和）的 $\\mathbf{a}(\\mathbf{x})$ 和 $T(\\mathbf{x})$，\n- 根据上述接受规则，在每个列出的目标点 $\\mathbf{x}$ 处，计算近似（分组求和）的 $\\mathbf{a}(\\mathbf{x})$ 和 $T(\\mathbf{x})$，\n- 对每个测试用例，报告两个实数：\n  1. 在给定目标点上加速度的最大相对误差，测量方式为 $\\max_{\\mathbf{x}} \\|\\mathbf{a}_{\\mathrm{approx}}(\\mathbf{x}) - \\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2 \\,/\\, \\|\\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2$，\n  2. 在给定目标点上潮汐张量的最大相对误差，测量方式为 $\\max_{\\mathbf{x}} \\|T_{\\mathrm{approx}}(\\mathbf{x}) - T_{\\mathrm{exact}}(\\mathbf{x})\\|_F \\,/\\, \\|T_{\\mathrm{exact}}(\\mathbf{x})\\|_F$，其中 $\\|\\cdot\\|_F$ 是弗罗贝尼乌斯范数。\n\n在这些代码单位制下，所有计算都是无量纲的；最终误差以纯实数（无单位）报告。不涉及角度。没有百分比；所有结果都是实数。\n\n请使用以下测试套件。对于每个测试用例，程序必须使用给定的张角参数 $\\theta$ 和软化长度 $\\varepsilon$，在列出的目标点上进行评估，并使用完全相同的源数据。\n\n测试用例 1（立方体角落的团簇；一般情况）：\n- 源：质量和位置\n  - $m = [\\,1.0,\\, 2.0,\\, 3.0,\\, 4.0,\\, 1.5,\\, 0.5,\\, 0.8,\\, 2.5\\,]$,\n  - $\\mathbf{r} = [\\,(-1.0,-1.0,-1.0),\\; (1.0,-1.0,-1.0),\\; (-1.0,1.0,-1.0),\\; (1.0,1.0,-1.0),\\; (-1.0,-1.0,1.0),\\; (1.0,-1.0,1.0),\\; (-1.0,1.0,1.0),\\; (1.0,1.0,1.0)\\,]$.\n- 目标点：\n  - $\\mathbf{x}_1 = (\\,0.3,\\, 0.2,\\, 0.1\\,)$,\n  - $\\mathbf{x}_2 = (\\,-0.4,\\, 0.5,\\, -0.2\\,)$,\n  - $\\mathbf{x}_3 = (\\,0.7,\\, -0.6,\\, 0.4\\,)$.\n- 参数：$\\theta = 0.5$, $\\varepsilon = 0.01$。\n\n测试用例 2（紧凑团簇；远场目标点）：\n- 源：质量和位置\n  - $m = [\\,5.0,\\, 3.0,\\, 4.0,\\, 2.0\\,]$,\n  - $\\mathbf{r} = [\\,(0.02,\\,-0.01,\\,0.03),\\; (-0.03,\\,0.01,\\,-0.02),\\; (0.01,\\,0.02,\\,-0.01),\\; (-0.02,\\,-0.02,\\,0.02)\\,]$.\n- 目标点：\n  - $\\mathbf{x}_1 = (\\,10.0,\\, -9.0,\\, 8.0\\,)$,\n  - $\\mathbf{x}_2 = (\\,15.0,\\, 15.0,\\, -20.0\\,)$.\n- 参数：$\\theta = 0.7$, $\\varepsilon = 0.001$。\n\n测试用例 3（近场及对相消敏感的几何构型）：\n- 源：质量和位置\n  - $m = [\\,1.0,\\, 1.0,\\, 0.3\\,]$,\n  - $\\mathbf{r} = [\\,(-0.2,\\, 0.0,\\, 0.0),\\; (0.2,\\, 0.0,\\, 0.0),\\; (0.05,\\, 0.04,\\, 0.0)\\,]$.\n- 目标点：\n  - $\\mathbf{x}_1 = (\\,0.05,\\, 0.0,\\, 0.0\\,)$,\n  - $\\mathbf{x}_2 = (\\,0.0,\\, 0.05,\\, 0.0\\,)$.\n- 参数：$\\theta = 0.3$, $\\varepsilon = 0.05$。\n\n最终输出格式：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须包含按以下顺序排列的 6 个浮点数\n$$\n[\\;E^{(1)}_{\\mathrm{acc}},\\; E^{(1)}_{\\mathrm{tid}},\\; E^{(2)}_{\\mathrm{acc}},\\; E^{(2)}_{\\mathrm{tid}},\\; E^{(3)}_{\\mathrm{acc}},\\; E^{(3)}_{\\mathrm{tid}}\\;] \\, ,\n$$\n其中 $E^{(t)}_{\\mathrm{acc}}$ 是测试用例 $t$ 中加速度的最大相对误差，$E^{(t)}_{\\mathrm{tid}}$ 是测试用例 $t$ 中潮汐张量的最大相对误差。输出中的每个数字必须四舍五入到小数点后恰好 6 位。例如，一个有效的输出应如下所示：\n$$\n[\\,0.001234,0.045678,0.000012,0.000345,0.056789,0.012345\\,] \\, .\n$$",
            "solution": "该问题具有科学依据，是客观且适定的，其前提是采用对递归划分方案的标准解释。我将基于以下假设进行求解：轴对齐立方体包围盒内源集的划分是通过标准的八叉树分解实现的，其中盒子被细分为八个相等的立方体卦限。这是三维树算法的规范方法，并且问题中提及立方体包围盒和递归划分也强烈暗示了这一点。\n\n该问题要求计算一个 $N$ 点质量系统的引力加速度和潮汐张量，既要通过直接求和进行精确计算，也要使用基于树的算法进行近似计算。\n\n首先，我们建立所需物理量的解析表达式。带 Plummer 软化的引力势由下式给出：\n$$\n\\Phi(\\mathbf{x}) = -\\sum_{k=1}^N \\frac{m_k}{\\sqrt{\\|\\mathbf{x}-\\mathbf{r}_k\\|^2 + \\varepsilon^2}}\n$$\n其中 $m_k$ 是第 $k$ 个粒子的质量，$\\mathbf{r}_k$ 是其位置，$\\mathbf{x}$ 是评估点，$\\varepsilon$ 是软化长度。为简洁起见，令 $\\Delta\\mathbf{r}_k = \\mathbf{x} - \\mathbf{r}_k$ 且 $d_k = \\sqrt{\\|\\Delta\\mathbf{r}_k\\|^2 + \\varepsilon^2}$。\n\n引力加速度 $\\mathbf{a}(\\mathbf{x})$ 是势的负梯度：\n$$\n\\mathbf{a}(\\mathbf{x}) = -\\nabla\\Phi(\\mathbf{x}) = -\\sum_{k=1}^N \\nabla\\left(-\\frac{m_k}{d_k}\\right) = \\sum_{k=1}^N m_k \\nabla(d_k^{-1})\n$$\n$d_k^{-1}$ 的梯度是 $\\nabla(d_k^{-1}) = -d_k^{-2} \\nabla d_k$。由于 $\\nabla d_k = d_k^{-1} \\Delta\\mathbf{r}_k$，这可以简化为 $\\nabla(d_k^{-1}) = -d_k^{-3} \\Delta\\mathbf{r}_k$。\n因此，加速度为：\n$$\n\\mathbf{a}(\\mathbf{x}) = -\\sum_{k=1}^N m_k \\frac{\\mathbf{x} - \\mathbf{r}_k}{\\left(\\|\\mathbf{x} - \\mathbf{r}_k\\|^2 + \\varepsilon^2\\right)^{3/2}}\n$$\n\n潮汐张量 $T(\\mathbf{x})$ 是加速度的雅可比矩阵，$T_{ij}(\\mathbf{x}) = \\partial a_i(\\mathbf{x}) / \\partial x_j$。这等价于势的负海森矩阵，$T_{ij}(\\mathbf{x}) = -\\partial^2\\Phi(\\mathbf{x}) / \\partial x_i \\partial x_j$。\n我们计算单个粒子 $k$ 的分量 $T_{ij}^{(k)}$：\n$$\nT_{ij}^{(k)}(\\mathbf{x}) = -\\frac{\\partial}{\\partial x_j} \\left( -m_k \\frac{(\\Delta r_k)_i}{d_k^3} \\right) = m_k \\frac{\\partial}{\\partial x_j} \\left( (\\Delta r_k)_i d_k^{-3} \\right)\n$$\n使用乘法法则：\n$$\nT_{ij}^{(k)} = m_k \\left( \\frac{\\partial (\\Delta r_k)_i}{\\partial x_j} d_k^{-3} + (\\Delta r_k)_i \\frac{\\partial d_k^{-3}}{\\partial x_j} \\right) = m_k \\left( \\delta_{ij} d_k^{-3} - 3 (\\Delta r_k)_i d_k^{-5} (\\Delta r_k)_j \\right)\n$$\n其中 $\\delta_{ij}$ 是克罗内克 δ。总潮汐张量为 $T(\\mathbf{x}) = \\sum_k T^{(k)}(\\mathbf{x})$。以矩阵形式表示，来自粒子 $k$ 的贡献是：\n$$\nT^{(k)}(\\mathbf{x}) = \\frac{m_k}{d_k^5} \\left( d_k^2 I - 3 (\\Delta\\mathbf{r}_k \\otimes \\Delta\\mathbf{r}_k) \\right)\n$$\n这个表达式不正确；符号与加速度的推导结果相反。让我们重新验证一下。$\\mathbf{a}=-\\nabla\\Phi$。$T=\\nabla\\mathbf{a} = -\\nabla\\nabla\\Phi$。\n$a_i = -\\partial_i\\Phi$。$T_{ij} = \\partial_j a_i = -\\partial_j\\partial_i\\Phi$。\n$-\\partial_j\\partial_i\\Phi = -\\partial_j (m_k d_k^{-3}(\\Delta r_k)_i) = -m_k [ \\delta_{ij}d_k^{-3} + (\\Delta r_k)_i (-3 d_k^{-5})(\\Delta r_k)_j ] = m_k[ 3 d_k^{-5} (\\Delta r_k)_i (\\Delta r_k)_j - d_k^{-3}\\delta_{ij}]$。\n用矩阵表示法：\n$$\nT^{(k)}(\\mathbf{x}) = \\frac{m_k}{d_k^5} \\left( 3 (\\Delta\\mathbf{r}_k \\otimes \\Delta\\mathbf{r}_k) - d_k^2 I \\right)\n$$\n其中 $I$ 是 $3 \\times 3$ 单位矩阵，$\\otimes$ 表示外积。这才是正确的形式。\n\n精确计算涉及对每个目标点 $\\mathbf{x}$，将所有 $N$ 个粒子的这些贡献相加。\n\n近似计算基于树代码方法。构建一个八叉树数据结构来空间地组织粒子。\n1.  **树的构建**：定义一个包含所有粒子的初始立方体包围盒。这构成了八叉树的根节点。然后递归地插入每个粒子。当一个粒子被插入到一个已包含粒子的节点时，该节点成为一个内部节点，其单元被细分为八个卦限（子节点），并且旧粒子和新粒子都被向下传递到相应的子节点。此过程一直持续到每个叶节点恰好包含一个粒子。在此过程中，每个内部节点存储其子树中包含的所有粒子的总质量 $M_S$ 和质心 $\\mathbf{c}_S$。\n\n2.  **力和潮汐的近似**：对于给定的目标点 $\\mathbf{x}$，从根节点开始遍历树。在每个节点 $S$ 处，评估单极子接受准则（MAC）：\n    $$\n    \\frac{L_S}{\\|\\mathbf{x} - \\mathbf{c}_S\\|} \\le \\theta\n    $$\n    这里，$L_S$ 是节点的立方单元的边长，$\\theta$ 是张角参数。\n    -   如果满足该准则，则使用该节点的总质量 $M_S$ 和质心 $\\mathbf{c}_S$，将整个粒子群 $S$ 的引力贡献近似为单个粒子的相互作用。遍历不会进入其子节点。\n    -   如果不满足该准则，则“打开”该节点，并递归地继续遍历其每个子节点。\n    -   如果到达一个叶节点（无法再打开），则使用它包含的单个粒子精确计算其贡献。\n\n这种自适应方法确保了对远处粒子群进行近似，而对近处粒子进行单独解析，从而平衡了准确性和计算成本。\n\n误差由给定测试用例中所有目标点上的最大相对误差来量化。对于加速度，度量标准是相对 L2 范数误差。对于潮汐张量，它是相对弗罗贝尼乌斯范数误差：\n$$\nE_{\\mathrm{acc}} = \\max_{\\mathbf{x}} \\frac{\\|\\mathbf{a}_{\\mathrm{approx}}(\\mathbf{x}) - \\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2}{\\|\\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2}\n$$\n$$\nE_{\\mathrm{tid}} = \\max_{\\mathbf{x}} \\frac{\\|T_{\\mathrm{approx}}(\\mathbf{x}) - T_{\\mathrm{exact}}(\\mathbf{x})\\|_F}{\\|T_{\\mathrm{exact}}(\\mathbf{x})\\|_F}\n$$\n\n提供的代码实现了这整个过程。它为八叉树定义了一个 `Node` 类，定义了用于树构建的函数，以及用于计算精确和近似相互作用的函数。它遍历每个测试用例，构建树，在每个目标点评估力和潮汐，计算误差，并以指定格式报告最终结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# No other library imports are permitted.\n\nclass Node:\n    \"\"\"A node in the octree.\"\"\"\n    def __init__(self, center, size):\n        self.center = center  # Geometric center of the node's cube\n        self.size = size      # Side length of the node's cube\n        \n        # Aggregate properties for monopole approximation\n        self.mass = 0.0\n        self.com = np.zeros(3)  # Center of mass\n        \n        # Children nodes (for internal nodes)\n        self.children = None\n        \n        # Particle index (for leaf nodes)\n        self.particle_index = -1\n\n    def is_leaf(self):\n        return self.children is None\n\ndef _get_octant(position, center):\n    \"\"\"Determine which of the 8 octants a position belongs to.\"\"\"\n    octant = 0\n    if position[0] >= center[0]: octant |= 1  # x-axis\n    if position[1] >= center[1]: octant |= 2  # y-axis\n    if position[2] >= center[2]: octant |= 4  # z-axis\n    return octant\n\ndef _insert_particle(node, particle_pos, particle_mass, particle_idx, positions, masses):\n    \"\"\"Recursively insert a particle into the octree.\"\"\"\n    # Update aggregate properties of the node\n    new_total_mass = node.mass + particle_mass\n    node.com = (node.com * node.mass + particle_pos * particle_mass) / new_total_mass\n    node.mass = new_total_mass\n\n    # If node is an internal node, pass particle down to the correct child\n    if not node.is_leaf():\n        octant = _get_octant(particle_pos, node.center)\n        _insert_particle(node.children[octant], particle_pos, particle_mass, particle_idx, positions, masses)\n        return\n\n    # If node is empty, it becomes a leaf with the new particle\n    if node.particle_index == -1:\n        node.particle_index = particle_idx\n        return\n\n    # If node is a leaf with an existing particle, it must become an internal node\n    # Create children\n    node.children = [Node(node.center + 0.5 * node.size * octant_vec, node.size * 0.5) for octant_vec in [\n        np.array([-1,-1,-1]), np.array([1,-1,-1]), np.array([-1,1,-1]), np.array([1,1,-1]),\n        np.array([-1,-1,1]), np.array([1,-1,1]), np.array([-1,1,1]), np.array([1,1,1])\n    ]]\n    \n    # Move the original particle to its new child node\n    old_particle_idx = node.particle_index\n    old_particle_pos = positions[old_particle_idx]\n    old_particle_mass = masses[old_particle_idx]\n    octant_old = _get_octant(old_particle_pos, node.center)\n    _insert_particle(node.children[octant_old], old_particle_pos, old_particle_mass, old_particle_idx, positions, masses)\n    \n    # Insert the new particle into its child node\n    octant_new = _get_octant(particle_pos, node.center)\n    _insert_particle(node.children[octant_new], particle_pos, particle_mass, particle_idx, positions, masses)\n\n    # The node is now an internal node, so clear its particle_index\n    node.particle_index = -1\n\ndef _calc_interaction(mass, pos, target_pos, epsilon):\n    \"\"\"Calculate acceleration and tidal tensor contribution from a single source.\"\"\"\n    delta_r = target_pos - pos\n    dist_sq = np.dot(delta_r, delta_r)\n    d_sq = dist_sq + epsilon**2\n    d = np.sqrt(d_sq)\n    \n    if d == 0:\n        return np.zeros(3), np.zeros((3,3))\n\n    d_inv3 = d**-3\n    accel = -mass * delta_r * d_inv3\n\n    d_inv5 = d_inv3 / d_sq\n    tidal = mass * d_inv5 * (3 * np.outer(delta_r, delta_r) - d_sq * np.eye(3))\n    \n    return accel, tidal\n\ndef compute_exact(positions, masses, target_pos, epsilon):\n    \"\"\"Compute exact acceleration and tidal tensor via direct summation.\"\"\"\n    total_accel = np.zeros(3)\n    total_tidal = np.zeros((3, 3))\n    for i in range(len(masses)):\n        accel, tidal = _calc_interaction(masses[i], positions[i], target_pos, epsilon)\n        total_accel += accel\n        total_tidal += tidal\n    return total_accel, total_tidal\n\ndef compute_approx(root, positions, masses, target_pos, epsilon, theta):\n    \"\"\"Compute approximate acceleration and tidal tensor using the octree.\"\"\"\n    total_accel = np.zeros(3)\n    total_tidal = np.zeros((3, 3))\n    \n    stack = [root]\n    \n    while stack:\n        node = stack.pop()\n        if node.mass == 0:\n            continue\n            \n        is_leaf = node.is_leaf()\n        if is_leaf:\n            # If leaf, always compute interaction directly with the particle\n            accel, tidal = _calc_interaction(node.mass, node.com, target_pos, epsilon)\n            total_accel += accel\n            total_tidal += tidal\n            continue\n        \n        # For internal nodes, apply the monopole acceptance criterion (MAC)\n        dist_to_com = np.linalg.norm(target_pos - node.com)\n        \n        if dist_to_com == 0: # Target is at center of mass, must open node\n            mac_ratio = np.inf\n        else:\n            mac_ratio = node.size / dist_to_com\n\n        if mac_ratio = theta:\n            # Node is far enough, approximate as a single point mass\n            accel, tidal = _calc_interaction(node.mass, node.com, target_pos, epsilon)\n            total_accel += accel\n            total_tidal += tidal\n        else:\n            # Node is too close, push children onto stack to resolve further\n            for child in node.children:\n                stack.append(child)\n                \n    return total_accel, total_tidal\n\ndef solve():\n    test_cases = [\n        # Test case 1\n        {\n            \"masses\": np.array([1.0, 2.0, 3.0, 4.0, 1.5, 0.5, 0.8, 2.5]),\n            \"positions\": np.array([\n                [-1.0, -1.0, -1.0], [1.0, -1.0, -1.0], [-1.0, 1.0, -1.0], [1.0, 1.0, -1.0],\n                [-1.0, -1.0, 1.0], [1.0, -1.0, 1.0], [-1.0, 1.0, 1.0], [1.0, 1.0, 1.0]\n            ]),\n            \"targets\": np.array([\n                [0.3, 0.2, 0.1], [-0.4, 0.5, -0.2], [0.7, -0.6, 0.4]\n            ]),\n            \"theta\": 0.5, \"epsilon\": 0.01\n        },\n        # Test case 2\n        {\n            \"masses\": np.array([5.0, 3.0, 4.0, 2.0]),\n            \"positions\": np.array([\n                [0.02, -0.01, 0.03], [-0.03, 0.01, -0.02],\n                [0.01, 0.02, -0.01], [-0.02, -0.02, 0.02]\n            ]),\n            \"targets\": np.array([\n                [10.0, -9.0, 8.0], [15.0, 15.0, -20.0]\n            ]),\n            \"theta\": 0.7, \"epsilon\": 0.001\n        },\n        # Test case 3\n        {\n            \"masses\": np.array([1.0, 1.0, 0.3]),\n            \"positions\": np.array([\n                [-0.2, 0.0, 0.0], [0.2, 0.0, 0.0], [0.05, 0.04, 0.0]\n            ]),\n            \"targets\": np.array([\n                [0.05, 0.0, 0.0], [0.0, 0.05, 0.0]\n            ]),\n            \"theta\": 0.3, \"epsilon\": 0.05\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        masses = case[\"masses\"]\n        positions = case[\"positions\"]\n        targets = case[\"targets\"]\n        theta = case[\"theta\"]\n        epsilon = case[\"epsilon\"]\n\n        # 1. Build the Octree\n        # Find root bounding box\n        min_coords = np.min(positions, axis=0)\n        max_coords = np.max(positions, axis=0)\n        box_center = (min_coords + max_coords) / 2.0\n        box_size = np.max(max_coords - min_coords)\n        \n        # Add a small buffer to handle particles on the boundary\n        box_size *= 1.0001 \n        \n        root = Node(box_center, box_size)\n        \n        for i in range(len(masses)):\n            _insert_particle(root, positions[i], masses[i], i, positions, masses)\n\n        # 2. Compute errors for each target\n        accel_errors = []\n        tidal_errors = []\n\n        for target_pos in targets:\n            # Exact calculation\n            a_exact, T_exact = compute_exact(positions, masses, target_pos, epsilon)\n            \n            # Approximate calculation\n            a_approx, T_approx = compute_approx(root, positions, masses, target_pos, epsilon, theta)\n\n            # Calculate norms\n            norm_a_exact = np.linalg.norm(a_exact)\n            norm_T_exact = np.linalg.norm(T_exact, 'fro')\n\n            # Avoid division by zero if exact field is zero (e.g., at a symmetry point)\n            if norm_a_exact > 0:\n                err_a = np.linalg.norm(a_approx - a_exact) / norm_a_exact\n                accel_errors.append(err_a)\n            else: # If exact is 0, error is 0 only if approx is also 0\n                accel_errors.append(np.linalg.norm(a_approx))\n                \n            if norm_T_exact > 0:\n                err_T = np.linalg.norm(T_approx - T_exact, 'fro') / norm_T_exact\n                tidal_errors.append(err_T)\n            else:\n                tidal_errors.append(np.linalg.norm(T_approx, 'fro'))\n\n        # 3. Find max error for this test case\n        max_err_a = max(accel_errors) if accel_errors else 0.0\n        max_err_T = max(tidal_errors) if tidal_errors else 0.0\n        \n        final_results.extend([max_err_a, max_err_T])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join([f'{r:.6f}' for r in final_results])}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了静态力计算之后，我们现在引入时间维度。本练习  要求你构建一个完整的二维 N 体模拟器来模拟原行星盘的演化。你将把对 Barnes-Hut 算法的理解与辛蛙跳积分器相结合，后者是一种以其出色的长期能量守恒特性而闻名的方法。最终的挑战是通过追踪总角动量来验证模拟的物理准确性，这是封闭引力系统中的一个关键守恒量。",
            "id": "2447325",
            "problem": "实现一个二维引力 $N$ 体模拟器，使用 Barnes–Hut (BH) 四叉树来近似计算一个旋转的原行星盘中的力，并跟踪总角动量随时间的变化，以分析其守恒性。完全在无量纲的“代码单位”中工作，引力常数 $G=1$，因此不需要物理单位。所有角度测量必须使用弧度。你的任务是从基本定律和核心定义出发，从头设计并实现完整的算法，不依赖任何预封装的 $N$ 体程序。\n\n模拟域由一颗中心恒星和周围的粒子盘组成：\n- 中心恒星质量为 $M_{\\star}$，初始位于原点。\n- 粒子盘总质量为 $M_{\\mathrm{disk}}$，分布在 $N_{\\mathrm{disk}}$ 个等质量粒子上。这些粒子在一个内径为 $r_{\\min}$、外径为 $r_{\\max}$ 的环状区域内采样，其径向概率密度在 $[r_{\\min}, r_{\\max}]$ 上与 $r$ 成正比，角度在 $[0,2\\pi)$ 上均匀分布。\n- 每个盘粒子的初始速度是切向的，并设置为仅由中心恒星产生的圆周速度，因此 $v(r) = \\sqrt{G M_{\\star} / r}$，方向垂直于半径矢量，与顺行旋转一致。恒星的初始速度为零。\n\n基本原理：\n- 牛顿第二定律：$m_i \\, d^2 \\mathbf{r}_i/dt^2 = \\mathbf{F}_i$。\n- 带有 Plummer 软化的点质量牛顿万有引力定律：对于粒子 $i \\neq j$，粒子 $j$ 对粒子 $i$ 产生的加速度为\n$$\n\\mathbf{a}_{i\\leftarrow j} = G \\, m_j \\, \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\epsilon^2\\right)^{3/2}} \\, .\n$$\n- 二维空间中绕原点的总角动量（$z$ 分量）为\n$$\nL_z = \\sum_{i=1}^{N} m_i \\, (x_i v_{y,i} - y_i v_{x,i}) \\, .\n$$\n\n算法要求：\n- 在二维空间中使用 Barnes–Hut 四叉树（首次使用时定义缩写）。每个树节点存储总质量和质心。使用几何接受准则，当一个边长为 $s$、质心距离目标粒子为 $d$ 的节点满足 $s/d \\le \\theta$ 时，将其视为单个源，其中 $\\theta$ 是张角参数。如果不接受，则递归到子节点。对于叶节点，直接对包含的粒子进行成对软化贡献求和，排除自我相互作用。\n- 使用辛蛙跳（踢-漂移-踢）时间积分器，固定时间步长为 $\\Delta t$：\n  $$\n  \\mathbf{v}^{n+\\frac{1}{2}} = \\mathbf{v}^n + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^n), \\quad\n  \\mathbf{r}^{n+1} = \\mathbf{r}^n + \\Delta t\\,\\mathbf{v}^{n+\\frac{1}{2}}, \\quad\n  \\mathbf{v}^{n+1} = \\mathbf{v}^{n+\\frac{1}{2}} + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^{n+1}) \\, .\n  $$\n- 跟踪初始角动量 $L_z(0)$ 和在积分区间 $T = n_{\\mathrm{steps}} \\, \\Delta t$ 结束时的最终角动量 $L_z(T)$。报告由以下公式定义的相对漂移（无量纲）：\n$$\n\\delta_L = \\frac{\\lvert L_z(T) - L_z(0) \\rvert}{\\lvert L_z(0) \\rvert} \\, .\n$$\n\n实现细节与约束：\n- 使用确定性的随机数生成器种子来生成初始条件，以确保结果可复现。\n- 构建根四叉树单元以包围所有粒子，并根据需要进行细分。允许一个小的最大深度，并在过度精化的叶节点内切换到直接求和，以防止病态的无限细分。\n- 确保在每个时间步计算力时重建树。\n- 程序不得读取输入。它必须在内部生成指定的测试用例并打印结果。\n\n测试套件：\n所有测试的通用参数：\n- $G = 1$, $M_{\\star} = 10$, $M_{\\mathrm{disk}} = 1$, $N_{\\mathrm{disk}} = 128$, $r_{\\min} = 0.5$, $r_{\\max} = 2.5$, 确定性种子 $= 42$，总粒子数 $N = N_{\\mathrm{disk}} + 1$。\n- 每个测试的初始条件必须完全相同地重新生成，以便只有算法参数不同。\n\n每个测试用例指定 $(\\theta, \\Delta t, n_{\\mathrm{steps}}, \\epsilon)$：\n- 测试 $1$（标准路径）：$(\\theta = 0.5, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n- 测试 $2$（更严格的张角；趋向于直接求和）：$(\\theta = 0.2, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n- 测试 $3$（更宽松的张角；更大的近似误差）：$(\\theta = 1.0, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n- 测试 $4$（更粗的时间步长；积分器压力测试）：$(\\theta = 0.5, \\ \\Delta t = 0.02, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n\n对于每个测试，计算上面定义的标量 $\\delta_L$。你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[0.00123,0.00045,0.00321,0.00456]$），按测试 1 到 4 的顺序排列。输出是无量纲的实数。所有计算中角度必须使用弧度。不得打印任何额外文本。",
            "solution": "我们从第一性原理出发设计解决方案。从牛顿第二定律 $m_i \\, d^2 \\mathbf{r}_i/dt^2 = \\mathbf{F}_i$ 开始。对于一个由 $N$ 个相互作用的点质量组成的系统，牛顿万有引力定律给出了粒子 $j$ 对粒子 $i$ 的成对力 $\\mathbf{F}_{ij}$。除以 $m_i$ 得到加速度\n$$\n\\mathbf{a}_{i\\leftarrow j} = G \\, m_j \\, \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\epsilon^2\\right)^{3/2}} \\, ,\n$$\n其中 $\\epsilon$ 是一个小的 Plummer 软化长度，用于在零间距处正则化奇点，并模拟有限大小的质量元。对所有 $j \\neq i$ 求和，得到净加速度 $\\mathbf{a}_i$。\n\n对于二维系统，绕原点的总角动量由其 $z$ 分量定义：\n$$\nL_z = \\sum_{i=1}^{N} m_i \\, (x_i v_{y,i} - y_i v_{x,i}) = \\sum_{i=1}^{N} m_i \\, (\\mathbf{r}_i \\times \\mathbf{v}_i)_z \\, .\n$$\n对其进行时间求导，得到\n$$\n\\frac{dL_z}{dt} = \\sum_{i=1}^{N} m_i \\, (\\mathbf{r}_i \\times \\mathbf{a}_i)_z \\, .\n$$\n对于精确的牛顿引力和成对中心力，根据牛顿第三定律（沿质心连线方向大小相等、方向相反的力），内力矩成对抵消，这意味着在没有外力矩的情况下 $\\frac{dL_z}{dt} = 0$，总角动量守恒。数值近似可能引入对作用力-反作用力对称性的违反和时间积分误差，导致微小的漂移 $\\delta_L$。\n\n直接对所有成对相互作用求和的计算成本为每个力评估 $\\mathcal{O}(N^2)$。Barnes–Hut (BH) 算法将粒子组织成二维的分层四叉树。每个节点代表一个方形区域，并存储内部粒子的总质量和质心。对于位于位置 $\\mathbf{r}$ 的目标粒子和一个边长为 $s$、质心距 $\\mathbf{r}$ 为 $d$ 的树节点，当满足以下条件时，单极近似将整个节点视为一个位于其质心的伪粒子：\n$$\n\\frac{s}{d} \\le \\theta \\, ,\n$$\n其中 $\\theta$ 是控制精度与效率权衡的张角参数。若不满足该准则，则“打开”该节点，并递归到其子节点。对于叶节点，我们计算其包含粒子的直接软化贡献，排除自我相互作用。对于分离良好的粒子群，单极截断误差的量级为 $\\mathcal{O}\\!\\left((s/d)^2\\right)$，因此减小 $\\theta$ 可以提高精度，并减少可能导致角动量漂移的系统性力不对称。\n\n时间积分使用辛蛙跳（踢-漂移-踢）方法，该方法时间可逆，对哈密顿系统具有优越的长期守恒特性。给定时间步长 $\\Delta t$，更新过程如下：\n$$\n\\mathbf{v}^{n+\\frac{1}{2}} = \\mathbf{v}^n + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^n), \\quad\n\\mathbf{r}^{n+1} = \\mathbf{r}^n + \\Delta t\\,\\mathbf{v}^{n+\\frac{1}{2}}, \\quad\n\\mathbf{v}^{n+1} = \\mathbf{v}^{n+\\frac{1}{2}} + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^{n+1}) \\, .\n$$\n此方案在开始时需要一次力评估，之后每步一次。我们使用选定的 $\\theta$ 和软化参数 $\\epsilon$，通过 BH 树来评估力。\n\n初始条件模拟了代码单位下的一个原行星盘。质量为 $M_{\\star}$ 的中心恒星位于原点，速度为零。总质量为 $M_{\\mathrm{disk}}$ 的盘由 $N_{\\mathrm{disk}}$ 个等质量粒子表示，这些粒子在环状区域 $[r_{\\min}, r_{\\max}]$ 中采样，其径向概率密度与 $r$ 成正比，以实现环内的面积均匀分布。可以通过将一个均匀变数 $u \\in [0,1]$ 转换为半径来抽取样本：\n$$\nr = \\sqrt{u \\, (r_{\\max}^2 - r_{\\min}^2) + r_{\\min}^2} \\, ,\n$$\n角度 $\\phi$ 在 $[0, 2\\pi)$ 上均匀分布。每个盘粒子开始时都在绕恒星的圆形轨道上，速度为 $v(r) = \\sqrt{G M_{\\star}/r}$，方向为切向 $\\hat{\\boldsymbol{\\phi}} = (-\\sin \\phi, \\cos \\phi)$，因此初始状态近似为一个冷的、近开普勒盘。恒星的初始速度为零；对于足够各向同性的样本，根据对称性，总线性动量接近于零。\n\n数值设计细节：\n- 树的构建：计算一个包含所有位置的边界正方形，其中心和半尺寸稍作填充。根据需要将节点递归地细分为四个子节点（四叉树）。为避免几乎重合的点导致的病态无限细分，强制一个最大深度（例如 $d_{\\max}$），并允许叶节点在达到此限制后存储多个物体；此类叶节点通过直接相互作用求和。\n- 质量和质心计算：在所有插入操作完成后，执行一次后序遍历，从其子节点或包含的物体计算每个节点的总质量和质心。\n- 力评估：对于一个目标粒子，遍历树，应用接受准则 $s/d \\le \\theta$。对于被接受的节点，加上软化的单极加速度。对于叶节点或被拒绝的节点，递归或直接求和，跳过自我相互作用。使用 $\\epsilon$ 通过 $(r^2 + \\epsilon^2)^{3/2}$ 计算软化距离。\n- 角动量跟踪：从初始位置和速度计算 $L_z(0)$。运行蛙跳积分器 $n_{\\mathrm{steps}}$ 步。在执行最后的半步踢之后，计算 $L_z(T)$ 和相对漂移\n$$\n\\delta_L = \\frac{\\lvert L_z(T) - L_z(0) \\rvert}{\\lvert L_z(0) \\rvert} \\, .\n$$\n\n测试套件原理说明：\n- 测试 $1$ ($\\theta = 0.5$, $\\Delta t = 0.01$, $n_{\\mathrm{steps}} = 40$, $\\epsilon = 0.02$) 是一个平衡的配置，预计会产生较小的 $\\delta_L$。\n- 测试 $2$ ($\\theta = 0.2$) 收紧了张角，使 BH 力更接近直接求和；$\\delta_L$ 不应超过测试 1，通常会减小。\n- 测试 $3$ ($\\theta = 1.0$) 放宽了准则，增加了近似误差；预计 $\\delta_L$ 会比测试 1-2 大。\n- 测试 $4$ (更粗的时间步长 $\\Delta t = 0.02$) 对时间积分器施加压力，即使 $\\theta$ 与测试 1 相同，也可能增加 $\\delta_L$。\n\n程序为每个测试重新生成相同的初始条件（相同的种子），并使用指定的参数运行模拟，计算四个 $\\delta_L$ 值。它会打印一行格式为 Python 风格列表 $[x_1,x_2,x_3,x_4]$ 的结果，其中每个 $x_k$ 是测试 $k$ 对应的 $\\delta_L$。所有输出都是无量纲的实数，且计算中角度均使用弧度。",
            "answer": "```python\n# Barnes–Hut angular momentum conservation analysis in a rotating disk\n# Execution environment: Python 3.12, numpy 1.23.5, scipy 1.11.4 (not used)\nimport numpy as np\n\n# ----------------------------\n# Utility: angular momentum\n# ----------------------------\ndef angular_momentum_z(m, r, v):\n    # Lz = sum m_i (x_i v_yi - y_i v_xi)\n    return float(np.sum(m * (r[:, 0] * v[:, 1] - r[:, 1] * v[:, 0])))\n\n# ----------------------------\n# Quadtree implementation\n# ----------------------------\nclass QuadNode:\n    __slots__ = (\n        \"cx\", \"cy\", \"h\", \"children\", \"bodies\", \"mass\", \"comx\", \"comy\", \"depth\"\n    )\n\n    def __init__(self, cx, cy, h, depth=0):\n        self.cx = float(cx)\n        self.cy = float(cy)\n        self.h = float(h)  # half-size\n        self.children = None  # list of 4 QuadNode or None\n        self.bodies = []      # list of indices if leaf\n        self.mass = 0.0\n        self.comx = 0.0\n        self.comy = 0.0\n        self.depth = depth\n\n    def subdivide(self):\n        hh = 0.5 * self.h\n        d = self.depth + 1\n        self.children = [\n            QuadNode(self.cx - hh, self.cy - hh, hh, d),  # SW\n            QuadNode(self.cx + hh, self.cy - hh, hh, d),  # SE\n            QuadNode(self.cx - hh, self.cy + hh, hh, d),  # NW\n            QuadNode(self.cx + hh, self.cy + hh, hh, d),  # NE\n        ]\n\n    def which_child(self, x, y):\n        east = x > self.cx\n        north = y > self.cy\n        if not east and not north:\n            return 0  # SW\n        if east and not north:\n            return 1  # SE\n        if not east and north:\n            return 2  # NW\n        return 3  # NE\n\n    def insert(self, idx, pos, max_bucket, max_depth):\n        # Insert body index idx at position pos[idx]\n        if self.children is None:\n            # Leaf: store body\n            self.bodies.append(idx)\n            # If exceeds bucket and can subdivide, split and reinsert\n            if len(self.bodies) > max_bucket and self.depth  max_depth:\n                self.subdivide()\n                old = self.bodies\n                self.bodies = []\n                for j in old:\n                    child = self.which_child(pos[j, 0], pos[j, 1])\n                    self.children[child].insert(j, pos, max_bucket, max_depth)\n        else:\n            # Internal: insert into appropriate child\n            child = self.which_child(pos[idx, 0], pos[idx, 1])\n            self.children[child].insert(idx, pos, max_bucket, max_depth)\n\n    def finalize_mass_com(self, m, pos):\n        if self.children is None:\n            if len(self.bodies) == 0:\n                self.mass = 0.0\n                self.comx = self.cx\n                self.comy = self.cy\n            elif len(self.bodies) == 1:\n                j = self.bodies[0]\n                self.mass = float(m[j])\n                self.comx = float(pos[j, 0])\n                self.comy = float(pos[j, 1])\n            else:\n                # Aggregate\n                mm = 0.0\n                cx = 0.0\n                cy = 0.0\n                for j in self.bodies:\n                    mj = float(m[j])\n                    mm += mj\n                    cx += mj * float(pos[j, 0])\n                    cy += mj * float(pos[j, 1])\n                self.mass = mm\n                if mm > 0.0:\n                    self.comx = cx / mm\n                    self.comy = cy / mm\n                else:\n                    self.comx = self.cx\n                    self.comy = self.cy\n        else:\n            mm = 0.0\n            cx = 0.0\n            cy = 0.0\n            for ch in self.children:\n                ch.finalize_mass_com(m, pos)\n                mm += ch.mass\n                cx += ch.mass * ch.comx\n                cy += ch.mass * ch.comy\n            self.mass = mm\n            if mm > 0.0:\n                self.comx = cx / mm\n                self.comy = cy / mm\n            else:\n                self.comx = self.cx\n                self.comy = self.cy\n\n    def acc_on(self, i, pos, m, G, theta, eps2):\n        ax = 0.0\n        ay = 0.0\n        if self.mass == 0.0:\n            return 0.0, 0.0\n\n        # Distance from particle i to node COM\n        dx = self.comx - pos[i, 0]\n        dy = self.comy - pos[i, 1]\n        d2 = dx * dx + dy * dy\n\n        if self.children is None:\n            # Leaf: direct sum over contained bodies excluding self\n            for j in self.bodies:\n                if j == i:\n                    continue\n                rx = pos[j, 0] - pos[i, 0]\n                ry = pos[j, 1] - pos[i, 1]\n                r2 = rx * rx + ry * ry + eps2\n                invr3 = 1.0 / (r2 * np.sqrt(r2))\n                s = G * float(m[j]) * invr3\n                ax += s * rx\n                ay += s * ry\n            return ax, ay\n\n        # Internal node: apply BH acceptance criterion\n        # side length s = 2h\n        if d2 > 0.0:\n            s_over_d = (2.0 * self.h) / np.sqrt(d2)\n        else:\n            s_over_d = np.inf\n\n        if s_over_d = theta:\n            # Accept node as single source\n            r2 = d2 + eps2\n            invr3 = 1.0 / (r2 * np.sqrt(r2))\n            s = G * self.mass * invr3\n            ax += s * dx\n            ay += s * dy\n        else:\n            # Recurse into children\n            for ch in self.children:\n                cx, cy = ch.acc_on(i, pos, m, G, theta, eps2)\n                ax += cx\n                ay += cy\n        return ax, ay\n\n# ----------------------------\n# Force computation via BH\n# ----------------------------\ndef compute_accelerations(pos, m, theta, eps, max_bucket=1, max_depth=20):\n    N = pos.shape[0]\n    # Build bounding square\n    xmin = float(np.min(pos[:, 0]))\n    xmax = float(np.max(pos[:, 0]))\n    ymin = float(np.min(pos[:, 1]))\n    ymax = float(np.max(pos[:, 1]))\n    cx = 0.5 * (xmin + xmax)\n    cy = 0.5 * (ymin + ymax)\n    half = max(xmax - xmin, ymax - ymin) * 0.5\n    if half == 0.0:\n        half = 1.0\n    half *= 1.05  # small padding\n\n    root = QuadNode(cx, cy, half, depth=0)\n    for i in range(N):\n        root.insert(i, pos, max_bucket, max_depth)\n    root.finalize_mass_com(m, pos)\n\n    G = 1.0\n    eps2 = float(eps) * float(eps)\n    acc = np.zeros_like(pos)\n    for i in range(N):\n        ax, ay = root.acc_on(i, pos, m, G, theta, eps2)\n        acc[i, 0] = ax\n        acc[i, 1] = ay\n    return acc\n\n# ----------------------------\n# Leapfrog integrator (KDK)\n# ----------------------------\ndef leapfrog_bh(pos0, vel0, m, dt, nsteps, theta, eps):\n    pos = pos0.copy()\n    vel = vel0.copy()\n\n    # Initial angular momentum (using velocities at integer time)\n    L0 = angular_momentum_z(m, pos, vel)\n\n    # Initial acceleration and half kick\n    acc = compute_accelerations(pos, m, theta, eps)\n    vel += 0.5 * dt * acc\n\n    # Time stepping\n    for step in range(nsteps):\n        pos += dt * vel\n        acc = compute_accelerations(pos, m, theta, eps)\n        if step != nsteps - 1:\n            vel += dt * acc\n\n    # Final half kick\n    vel += 0.5 * dt * acc\n\n    Lf = angular_momentum_z(m, pos, vel)\n    rel_drift = abs(Lf - L0) / max(1e-16, abs(L0))\n    return rel_drift\n\n# ----------------------------\n# Initial conditions: rotating disk + central star\n# ----------------------------\ndef generate_initial_conditions(seed, N_disk, M_star, M_disk, rmin, rmax):\n    rng = np.random.default_rng(seed)\n    # Star at origin\n    pos_star = np.array([[0.0, 0.0]])\n    vel_star = np.array([[0.0, 0.0]])\n    m_star = np.array([M_star], dtype=float)\n\n    # Disk sampling: radial PDF ∝ r on [rmin, rmax]\n    u = rng.random(N_disk)\n    radii = np.sqrt(u * (rmax * rmax - rmin * rmin) + rmin * rmin)\n    phi = rng.random(N_disk) * (2.0 * np.pi)\n    x = radii * np.cos(phi)\n    y = radii * np.sin(phi)\n    pos_disk = np.column_stack((x, y))\n\n    # Tangential velocity for circular orbit due to star alone\n    G = 1.0\n    v_mag = np.sqrt(G * M_star / np.maximum(radii, 1e-12))\n    vx = -v_mag * np.sin(phi)\n    vy =  v_mag * np.cos(phi)\n    vel_disk = np.column_stack((vx, vy))\n\n    # Masses\n    m_disk = np.full(N_disk, M_disk / N_disk, dtype=float)\n\n    # Combine star + disk\n    pos = np.vstack((pos_star, pos_disk))\n    vel = np.vstack((vel_star, vel_disk))\n    m = np.concatenate((m_star, m_disk))\n    return pos, vel, m\n\n# ----------------------------\n# Main solve function\n# ----------------------------\ndef solve():\n    # Common parameters\n    G = 1.0  # code units\n    M_star = 10.0\n    M_disk = 1.0\n    N_disk = 128\n    rmin = 0.5\n    rmax = 2.5\n    seed = 42\n\n    # Test suite: (theta, dt, nsteps, eps)\n    test_cases = [\n        (0.5, 0.01, 40, 0.02),  # Test 1: happy path\n        (0.2, 0.01, 40, 0.02),  # Test 2: stricter opening\n        (1.0, 0.01, 40, 0.02),  # Test 3: looser opening\n        (0.5, 0.02, 40, 0.02),  # Test 4: coarser time step\n    ]\n\n    # Generate identical initial conditions for each test\n    pos0, vel0, m = generate_initial_conditions(seed, N_disk, M_star, M_disk, rmin, rmax)\n\n    results = []\n    for theta, dt, nsteps, eps in test_cases:\n        # Copy initial conditions so each test starts identically\n        pos = pos0.copy()\n        vel = vel0.copy()\n        rel_drift = leapfrog_bh(pos, vel, m, dt, nsteps, theta, eps)\n        # format with reasonable precision\n        results.append(rel_drift)\n\n    # Print in the exact required format\n    # Use repr-like formatting for clarity without extra text\n    print(f\"[{','.join(f'{x:.8g}' for x in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "一个真正强大的算法通过其通用性来展现其优雅。这最后一个练习  将带你超越熟悉的笛卡尔网格，将 Barnes-Hut 方法应用于球体的曲面上。这需要你从根本上重新思考单元划分方案和开放准则，用它们的角度对应物取代欧几里得距离和长度。成功完成此任务将巩固你对核心层次化原理的掌握，这些原理使得树代码能够在不同几何结构中发挥作用。",
            "id": "2447291",
            "problem": "考虑一组有限的质点，它们被约束在三维欧几里得空间中的单位球面上。每个质点的位置由一个笛卡尔单位向量 $\\mathbf{r}_j \\in \\mathbb{R}^3$（满足 $\\|\\mathbf{r}_j\\|_2 = 1$）表示，并具有一个标量质量 $m_j  0$。由所有其他质量在目标位置 $\\mathbf{r}_i$ 处引起的引力加速度是牛顿平方反比定律的和\n$$\n\\mathbf{a}_{\\mathrm{direct}}(\\mathbf{r}_i) \\;=\\; \\sum_{j \\neq i} G\\,m_j\\,\\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\|\\mathbf{r}_j - \\mathbf{r}_i\\|_2^2 + \\varepsilon^2\\right)^{3/2}},\n$$\n其中 $G$ 是引力常数，$\\varepsilon$ 是一个小的软化长度。在整个问题中，采用无量纲单位，其中 $G = 1$，单位球半径，并使用固定的软化长度 $\\varepsilon = 10^{-3}$。\n\n你的任务是通过使用球体的分层划分来聚合贡献，从而计算 $\\mathbf{a}_{\\mathrm{direct}}(\\mathbf{r}_i)$ 的一个近似值。定义一个球面四叉树如下。在球面坐标 $(\\lambda,\\phi)$ 中进行计算，其中经度 $\\lambda \\in [-\\pi,\\pi]$，纬度 $\\phi \\in [-\\pi/2,\\pi/2]$，且 $\\mathbf{r}(\\lambda,\\phi) = (\\cos\\phi\\cos\\lambda,\\cos\\phi\\sin\\lambda,\\sin\\phi)$。根单元覆盖整个区域 $[\\lambda_{\\min},\\lambda_{\\max}] = [-\\pi,\\pi]$ 和 $[\\phi_{\\min},\\phi_{\\max}] = [-\\pi/2,\\pi/2]$。任何边界为 $[\\lambda_{\\min},\\lambda_{\\max}]\\times[\\phi_{\\min},\\phi_{\\max}]$ 的单元通过在中间经度 $\\lambda_{\\mathrm{mid}} = (\\lambda_{\\min}+\\lambda_{\\max})/2$ 和中间纬度 $\\phi_{\\mathrm{mid}} = (\\phi_{\\min}+\\phi_{\\max})/2$ 处分裂，被细分为四个子单元，产生四个子单元：$[\\lambda_{\\min},\\lambda_{\\mathrm{mid}}]\\times[\\phi_{\\min},\\phi_{\\mathrm{mid}}]$、$[\\lambda_{\\mathrm{mid}},\\lambda_{\\max}]\\times[\\phi_{\\min},\\phi_{\\mathrm{mid}}]$、$[\\lambda_{\\min},\\lambda_{\\mathrm{mid}}]\\times[\\phi_{\\mathrm{mid}},\\phi_{\\max}]$、$[\\lambda_{\\mathrm{mid}},\\lambda_{\\max}]\\times[\\phi_{\\mathrm{mid}},\\phi_{\\max}]$。递归地进行细分，直到每个叶单元最多包含 $C$ 个粒子，或者达到最大深度 $D$。使用 $C = 1$ 和 $D = 12$。\n\n对于每个单元，定义其总质量 $M = \\sum_{j \\in \\mathrm{cell}} m_j$，其质心向量 $\\mathbf{R}_{\\mathrm{cm}} = \\sum_{j \\in \\mathrm{cell}} m_j\\,\\mathbf{r}_j$，以及其质心位置 $\\mathbf{r}_{\\mathrm{cm}} = \\mathbf{R}_{\\mathrm{cm}}/M$。同时，将几何中心方向 $\\mathbf{c}$ 定义为中点角度处的单位向量 $\\mathbf{c} = \\mathbf{r}(\\lambda_{\\mathrm{mid}},\\phi_{\\mathrm{mid}})$。设单元的角半径 $\\alpha$ 为 $\\mathbf{c}$ 与单元四个角点方向中任意一个之间的最大球面角距离；具体来说，如果 $\\{\\mathbf{q}_k\\}_{k=1}^4$ 是角点处的单位向量，则\n$$\n\\alpha \\;=\\; \\max_{k \\in \\{1,2,3,4\\}} \\arccos\\!\\left(\\mathrm{clip}\\!\\left(\\mathbf{c}\\cdot \\mathbf{q}_k,-1,1\\right)\\right).\n$$\n对于一个目标方向 $\\mathbf{u} = \\mathbf{r}_i/\\|\\mathbf{r}_i\\|_2$ 和一个几何中心为 $\\mathbf{c}$ 的单元，定义分离角 $\\delta = \\arccos\\!\\left(\\mathrm{clip}\\!\\left(\\mathbf{u}\\cdot \\mathbf{c},-1,1\\right)\\right)$。一个单元的聚合是可接受的，当且仅当它不包含目标索引 $i$ 并且满足张角不等式\n$$\n\\frac{\\alpha}{\\delta} \\;\\le\\; \\theta,\n$$\n其中 $\\theta  0$ 是张角参数。如果可接受，则将单元中所有粒子的贡献近似为一个位于 $\\mathbf{r}_{\\mathrm{cm}}$、质量为 $M$ 的单极子。否则，如果该单元是叶单元，则对其粒子求精确的成对贡献之和；如果不是叶单元，则递归到其子单元中。在所有情况下，排除自相互作用 $j=i$。\n\n对于下面的每个测试用例，使用上述规则计算指定目标索引处的近似加速度向量 $\\mathbf{a}_{\\mathrm{tree}}(\\mathbf{r}_i)$，并使用完整的成对表达式计算直接求和 $\\mathbf{a}_{\\mathrm{direct}}(\\mathbf{r}_i)$。将相对误差报告为欧几里得范数比\n$$\n\\mathrm{err} \\;=\\; \\frac{\\left\\|\\mathbf{a}_{\\mathrm{tree}}(\\mathbf{r}_i)-\\mathbf{a}_{\\mathrm{direct}}(\\mathbf{r}_i)\\right\\|_2}{\\left\\|\\mathbf{a}_{\\mathrm{direct}}(\\mathbf{r}_i)\\right\\|_2}.\n$$\n使用弧度制角度。在近似计算和直接计算中均使用相同的软化值 $\\varepsilon = 10^{-3}$。除非另有说明，所有质量均为 $1$。球体半径为 $1$。\n\n测试套件。对于每个用例，粒子集以笛卡尔单位向量形式给出，指定了目标索引 $i_{\\mathrm{target}}$，并指定了张角参数 $\\theta$。\n\n- 用例 A（平衡配置，“理想路径”）：\n  - 粒子：$\\{(1,0,0),(-1,0,0),(0,1,0),(0,-1,0),(0,0,1),(0,0,-1)\\}$。\n  - 目标：$i_{\\mathrm{target}} = 0$（位于 $(1,0,0)$ 的粒子）。\n  - 张角：$\\theta = 0.6$。\n\n- 用例 B（赤道上的环，多个近乎相等的分离）：\n  - 粒子：对于 $k \\in \\{0,1,2,3,4,5,6,7\\}$，$(\\cos(0)\\cos(k\\pi/4),\\cos(0)\\sin(k\\pi/4),\\sin(0))$; 也就是说，在经度为 $k\\pi/4$、纬度为 $0$ 的位置有 $8$ 个点。\n  - 目标：$i_{\\mathrm{target}} = 0$（经度为 $0$）。\n  - 张角：$\\theta = 0.6$。\n\n- 用例 C（极点附近的集群加上远处的质量，测试小角半径和近奇异几何形状）：\n  - 粒子：五个靠近北极的点，其纬度为 $\\phi = \\pi/2 - \\delta$，其中 $\\delta \\in \\{10^{-2},2\\cdot10^{-2},3\\cdot10^{-2},4\\cdot10^{-2},5\\cdot10^{-2}\\}$，经度为 $\\lambda = 2k\\pi/5$，其中 $k \\in \\{0,1,2,3,4\\}$，外加三个在赤道上的点，经度分别为 $0$、$2\\pi/3$ 和 $4\\pi/3$（纬度为 $0$）。\n  - 目标：$i_{\\mathrm{target}} = 0$（$\\delta = 10^{-2}$ 且 $\\lambda = 0$ 的粒子）。\n  - 张角：$\\theta = 0.5$。\n\n- 用例 D（经度接缝边界情况，测试分区边界）：\n  - 粒子：三个在赤道上的点，经度分别为 $\\lambda = \\pi - 10^{-3}$、$\\lambda = -\\pi + 2\\cdot 10^{-3}$ 和 $\\lambda = 0$（纬度为 $0$）。\n  - 目标：$i_{\\mathrm{target}} = 2$（经度为 $0$ 的粒子）。\n  - 张角：$\\theta = 0.7$。\n\n最终输出格式。你的程序应该生成单行输出，其中包含按顺序排列的用例 A、B、C 和 D 的四个相对误差，形式为用方括号括起来的逗号分隔列表，例如 $[\\mathrm{err}_A,\\mathrm{err}_B,\\mathrm{err}_C,\\mathrm{err}_D]$。不应产生任何其他输出。角度必须以弧度解释，所有计算都必须使用上述无量纲选择和参数。输出值为浮点数。不需要也不允许用户输入。",
            "solution": "我们在三维欧几里得空间中对单位球面上的 $N$ 个质点进行建模。在目标 $\\mathbf{r}_i$ 处，当软化值为 $\\varepsilon$、引力常数 $G$ 等于 $1$ 时，直接引力加速度为\n$$\n\\mathbf{a}_{\\mathrm{direct}}(\\mathbf{r}_i) \\;=\\; \\sum_{j \\neq i} m_j\\,\\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\|\\mathbf{r}_j - \\mathbf{r}_i\\|_2^2 + \\varepsilon^2\\right)^{3/2}}.\n$$\n当源群组与目标的距离相对于群组的范围足够远时，分层近似法会用单个聚合体替换该群组。在平面上，Barnes–Hut (BH) 方法中的一个标准张角判据是比较一个单元的特征尺寸 $s$ 与其到目标的欧几里得距离 $d$，如果 $s/d \\le \\theta$，则接受该聚合。在球面上，其自然几何结构建议使用角度量。假设一个单元覆盖了球面上的一个区域，其几何中心方向为 $\\mathbf{c}$，角半径为 $\\alpha$，定义为从 $\\mathbf{c}$ 到该单元任何角点方向的最大大圆距离。对于一个目标单位方向 $\\mathbf{u}$，分离度由大圆角 $\\delta = \\arccos(\\mathrm{clip}(\\mathbf{u}\\cdot\\mathbf{c},-1,1))$ 来衡量。单位球面上角距为 $\\gamma$ 的两点之间的弦长为 $d_{\\mathrm{chord}} = 2\\sin(\\gamma/2)$，它在 $\\gamma \\in [0,\\pi]$ 上随 $\\gamma$ 严格递增。因此，在嵌入的单位球面上，比率 $s/d$ 可以被角尺度比 $\\alpha/\\delta$ 替代，因为对于小角度，$\\sin(\\alpha/2)\\approx \\alpha/2$ 且 $\\sin(\\delta/2)\\approx \\delta/2$，而对于一般角度，单调性保持了顺序关系。因此，我们当且仅当 $\\alpha/\\delta \\le \\theta$ 时接受一个单元的单极子近似。\n\n球面四叉树分区是通过将一个单元的经度和纬度范围递归地二等分成四个子单元来定义的。从覆盖 $[\\lambda_{\\min},\\lambda_{\\max}] = [-\\pi,\\pi]$ 和 $[\\phi_{\\min},\\phi_{\\max}] = [-\\pi/2,\\pi/2]$ 的根节点开始，我们在 $\\lambda_{\\mathrm{mid}} = (\\lambda_{\\min}+\\lambda_{\\max})/2$ 和 $\\phi_{\\mathrm{mid}} = (\\phi_{\\min}+\\phi_{\\max})/2$ 处进行分裂，形成四个子单元。我们持续这一过程，直到一个叶单元最多包含 $C$ 个粒子或达到最大深度 $D$。每个单元存储：\n- 其总质量 $M = \\sum_{j \\in \\mathrm{cell}} m_j$。\n- 其质心向量 $\\mathbf{R}_{\\mathrm{cm}} = \\sum_{j \\in \\mathrm{cell}} m_j\\,\\mathbf{r}_j$，以及质心位置 $\\mathbf{r}_{\\mathrm{cm}} = \\mathbf{R}_{\\mathrm{cm}}/M$。\n- 其几何中心方向 $\\mathbf{c} = \\mathbf{r}(\\lambda_{\\mathrm{mid}},\\phi_{\\mathrm{mid}})$。\n- 其角半径 $\\alpha = \\max_k \\arccos(\\mathrm{clip}(\\mathbf{c}\\cdot \\mathbf{q}_k,-1,1))$，其中 $\\mathbf{q}_k$ 是四个角点坐标处的单位向量。\n\n为了评估目标索引 $i$ 处的近似加速度，我们从根节点开始遍历树：\n- 如果一个单元包含目标索引 $i$，那么无论比率 $\\alpha/\\delta$ 如何，它都永远不可接受；我们必须遍历其子单元，或者如果它是叶单元，则对其粒子（不包括 $i$）执行直接求和。\n- 如果单元不包含 $i$ 且张角判据 $\\alpha/\\delta \\le \\theta$ 成立，我们将单元中所有粒子的贡献近似为一个位于 $\\mathbf{r}_{\\mathrm{cm}}$、质量为 $M$ 的单极子，并加上\n$$\n\\Delta \\mathbf{a} \\;=\\; M\\,\\frac{\\mathbf{r}_{\\mathrm{cm}} - \\mathbf{r}_i}{\\left(\\|\\mathbf{r}_{\\mathrm{cm}} - \\mathbf{r}_i\\|_2^2 + \\varepsilon^2\\right)^{3/2}}.\n$$\n- 如果不可接受且不是叶单元，我们递归到子单元中并对其贡献求和；如果是叶单元，我们加上其粒子的精确成对贡献，并忽略 $j=i$。\n\n这个规则确保了没有自相互作用，并且只有当单元的角尺寸 $\\alpha$ 相对于其与目标的分离度 $\\delta$ 较小时，才使用聚合近似。选择使用几何中心 $\\mathbf{c}$ 和基于角点的 $\\alpha$ 为单元的足迹提供了一个保守的角度边界。质心位置 $\\mathbf{r}_{\\mathrm{cm}}$ 提供了与嵌入空间中牛顿定律一致的一阶（单极子）多极近似。由于球体半径为 $1$ 且 $G=1$，不需要额外的缩放。\n\n数值稳定性由软化参数 $\\varepsilon = 10^{-3}$ 维持，该参数同样应用于近似计算和直接计算。这避免了两个位置非常接近时的奇异性。经纬度范围的二等分方式避免了在 $\\lambda=0$ 处初始分裂后任何单元内的回绕问题，并且角点方向是根据单元边界计算的。每个子单元中粒子的归属是通过将其经纬度值与子单元的边界进行比较来确定的，使用半开区间约定以避免重复，并将父单元的上限包含在最上层的子单元中以确保覆盖。\n\n对于每个测试用例，我们：\n- 按规定构建粒子集。对于用例 B，我们在经度为 $k\\pi/4$（其中 $k \\in \\{0,\\ldots,7\\}$）、纬度为 $0$ 的位置取 $8$ 个赤道点。对于用例 C，我们包括 $5$ 个近极点，其纬度为 $\\pi/2 - \\delta$（其中 $\\delta \\in \\{10^{-2},2\\cdot10^{-2},3\\cdot10^{-2},4\\cdot10^{-2},5\\cdot10^{-2}\\}$），经度为 $\\lambda = 2k\\pi/5$（其中 $k \\in \\{0,\\ldots,4\\}$），外加 $3$ 个赤道点，经度分别为 $0$、$2\\pi/3$ 和 $4\\pi/3$。对于用例 A 和 D，笛卡尔位置被明确列出。所有质量均为 $1$。\n- 用 $C=1$ 和 $D=12$ 构建球面四叉树。\n- 使用每个用例给定的遍历方式和张角参数 $\\theta$ 计算 $\\mathbf{a}_{\\mathrm{tree}}(\\mathbf{r}_i)$。\n- 使用相同的软化值通过直接求和计算 $\\mathbf{a}_{\\mathrm{direct}}(\\mathbf{r}_i)$。\n- 报告 $\\mathrm{err} = \\|\\mathbf{a}_{\\mathrm{tree}}-\\mathbf{a}_{\\mathrm{direct}}\\|_2/\\|\\mathbf{a}_{\\mathrm{direct}}\\|_2$。\n\n该方法基于第一性原理：精确的引力定律、球面流形在 $\\mathbb{R}^3$ 中的嵌入，以及源自大圆几何的保守角张角判据。接受性测试比较了两个无量纲角度，确保了对单位球半径的不变性。测试套件涵盖了对称情况（用例 A）、准均匀角间距（用例 B）、小角半径和集群行为（用例 C）以及经度边界处理（用例 D）。程序按照规定的顺序和格式生成包含四个浮点相对误差的单行输出。",
            "answer": "```python\nimport numpy as np\n\n# Constants in nondimensional units\nG = 1.0\nEPS = 1e-3  # softening\nCAPACITY = 1\nMAX_DEPTH = 12\n\ndef cart_from_latlon(lat, lon):\n    c = np.cos(lat)\n    return np.array([c*np.cos(lon), c*np.sin(lon), np.sin(lat)], dtype=float)\n\ndef latlon_from_cart(r):\n    x, y, z = r\n    lat = np.arcsin(np.clip(z, -1.0, 1.0))\n    lon = np.arctan2(y, x)\n    return lat, lon\n\ndef ang_between(u, v):\n    # u and v are unit vectors\n    dot = float(np.dot(u, v))\n    dot = max(-1.0, min(1.0, dot))\n    return np.arccos(dot)\n\nclass SphNode:\n    __slots__ = (\"lam_min\",\"lam_max\",\"phi_min\",\"phi_max\",\"indices\",\"mass\",\"com_vec\",\n                 \"center_dir\",\"alpha\",\"children\",\"is_leaf\",\"index_set\",\"depth\")\n    def __init__(self, lam_min, lam_max, phi_min, phi_max, indices, positions, masses, lats, lons, depth):\n        self.lam_min = lam_min\n        self.lam_max = lam_max\n        self.phi_min = phi_min\n        self.phi_max = phi_max\n        self.indices = indices\n        self.index_set = set(indices)\n        self.depth = depth\n        # mass and center of mass vector\n        if len(indices) > 0:\n            m = masses[indices]\n            r = positions[indices]\n            self.mass = float(np.sum(m))\n            self.com_vec = np.sum((m[:, None] * r), axis=0) if self.mass > 0 else np.zeros(3)\n        else:\n            self.mass = 0.0\n            self.com_vec = np.zeros(3)\n        # geometric center direction\n        lam_mid = 0.5*(lam_min + lam_max)\n        phi_mid = 0.5*(phi_min + phi_max)\n        self.center_dir = cart_from_latlon(phi_mid, lam_mid)\n        # angular radius via corners\n        corners = [\n            cart_from_latlon(phi_min, lam_min),\n            cart_from_latlon(phi_min, lam_max),\n            cart_from_latlon(phi_max, lam_min),\n            cart_from_latlon(phi_max, lam_max),\n        ]\n        self.alpha = max(ang_between(self.center_dir, q) for q in corners) if len(corners) > 0 else 0.0\n        self.children = []\n        self.is_leaf = True  # will change if subdivision happens\n\ndef build_tree(lam_min, lam_max, phi_min, phi_max, indices, positions, masses, lats, lons, depth=0):\n    node = SphNode(lam_min, lam_max, phi_min, phi_max, indices, positions, masses, lats, lons, depth)\n    if depth >= MAX_DEPTH or len(indices) = CAPACITY:\n        node.is_leaf = True\n        return node\n    # compute midpoints\n    lam_mid = 0.5*(lam_min + lam_max)\n    phi_mid = 0.5*(phi_min + phi_max)\n    # Partition indices into 4 children; use half-open intervals to avoid duplication,\n    # and include the parent's maxima in the upper intervals.\n    idxs = indices\n    lam = lons[idxs]\n    phi = lats[idxs]\n\n    # child bounds: (lam_lo, lam_hi, phi_lo, phi_hi, include_lam_max, include_phi_max)\n    child_bounds = [\n        (lam_min, lam_mid, phi_min, phi_mid, False, False),\n        (lam_mid, lam_max, phi_min, phi_mid, True,  False),\n        (lam_min, lam_mid, phi_mid, phi_max, False, True),\n        (lam_mid, lam_max, phi_mid, phi_max, True,  True),\n    ]\n\n    child_indices = []\n    for (l0, l1, p0, p1, inc_lmax, inc_pmax) in child_bounds:\n        # Determine membership\n        if inc_lmax:\n            lam_mask = (lam >= l0)  (lam = l1)\n        else:\n            lam_mask = (lam >= l0)  (lam  l1)\n        if inc_pmax:\n            phi_mask = (phi >= p0)  (phi = p1)\n        else:\n            phi_mask = (phi >= p0)  (phi  p1)\n        mask = lam_mask  phi_mask\n        child_indices.append(idxs[mask])\n\n    # If subdivision is ineffective (all points in one child), stop subdividing.\n    sizes = [len(ci) for ci in child_indices]\n    if max(sizes) == len(indices):\n        node.is_leaf = True\n        return node\n\n    # Create children\n    node.is_leaf = False\n    for k, ci in enumerate(child_indices):\n        if k == 0:\n            l0, l1, p0, p1, inc_lmax, inc_pmax = child_bounds[k]\n            child = build_tree(l0, l1, p0, p1, ci, positions, masses, lats, lons, depth+1)\n        elif k == 1:\n            l0, l1, p0, p1, inc_lmax, inc_pmax = child_bounds[k]\n            child = build_tree(l0, l1, p0, p1, ci, positions, masses, lats, lons, depth+1)\n        elif k == 2:\n            l0, l1, p0, p1, inc_lmax, inc_pmax = child_bounds[k]\n            child = build_tree(l0, l1, p0, p1, ci, positions, masses, lats, lons, depth+1)\n        else:\n            l0, l1, p0, p1, inc_lmax, inc_pmax = child_bounds[k]\n            child = build_tree(l0, l1, p0, p1, ci, positions, masses, lats, lons, depth+1)\n        node.children.append(child)\n    return node\n\ndef approx_accel_from_node(node, target_idx, r_target, u_target, positions, masses, theta):\n    if node.mass == 0.0 or len(node.indices) == 0:\n        return np.zeros(3, dtype=float)\n    # If node contains the target index, never approximate at this node\n    contains_target = (target_idx in node.index_set)\n    if not contains_target:\n        # Compute separation angle delta\n        delta = ang_between(u_target, node.center_dir)\n        # If admissible by angular opening criterion and not a leaf, or leaf (allowed)\n        if delta > 0.0 and (node.alpha / delta) = theta:\n            # monopole contribution from center-of-mass position\n            r_cm = node.com_vec / node.mass\n            dr = r_cm - r_target\n            dist2 = float(np.dot(dr, dr)) + EPS*EPS\n            inv32 = dist2 ** (-1.5)\n            return node.mass * dr * inv32\n        # If delta == 0, the target lies exactly at the geometric center; not admissible.\n    # If leaf: sum exact contributions (excluding self)\n    if node.is_leaf:\n        acc = np.zeros(3, dtype=float)\n        for j in node.indices:\n            if j == target_idx:\n                continue\n            dr = positions[j] - r_target\n            dist2 = float(np.dot(dr, dr)) + EPS*EPS\n            inv32 = dist2 ** (-1.5)\n            acc += masses[j] * dr * inv32\n        return acc\n    # Else recurse\n    acc = np.zeros(3, dtype=float)\n    for ch in node.children:\n        acc += approx_accel_from_node(ch, target_idx, r_target, u_target, positions, masses, theta)\n    return acc\n\ndef direct_accel(target_idx, positions, masses):\n    r_i = positions[target_idx]\n    acc = np.zeros(3, dtype=float)\n    for j in range(len(positions)):\n        if j == target_idx:\n            continue\n        dr = positions[j] - r_i\n        dist2 = float(np.dot(dr, dr)) + EPS*EPS\n        inv32 = dist2 ** (-1.5)\n        acc += masses[j] * dr * inv32\n    return acc\n\ndef build_lats_lons(positions):\n    lats = np.empty(len(positions), dtype=float)\n    lons = np.empty(len(positions), dtype=float)\n    for idx, r in enumerate(positions):\n        lat, lon = latlon_from_cart(r)\n        lats[idx] = lat\n        lons[idx] = lon\n    return lats, lons\n\ndef run_case(positions, masses, target_idx, theta):\n    positions = np.array(positions, dtype=float)\n    masses = np.array(masses, dtype=float)\n    # Normalize positions to unit length (defensive, though inputs are unit vectors)\n    norms = np.linalg.norm(positions, axis=1)\n    positions = positions / norms[:, None]\n    lats, lons = build_lats_lons(positions)\n    # Build spherical quadtree\n    root = build_tree(-np.pi, np.pi, -0.5*np.pi, 0.5*np.pi, np.arange(len(positions)), positions, masses, lats, lons, depth=0)\n    # Compute approximate and direct accelerations\n    r_t = positions[target_idx]\n    u_t = r_t / np.linalg.norm(r_t)\n    a_tree = approx_accel_from_node(root, target_idx, r_t, u_t, positions, masses, theta)\n    a_dir = direct_accel(target_idx, positions, masses)\n    num = np.linalg.norm(a_tree - a_dir)\n    den = np.linalg.norm(a_dir)\n    if den == 0.0:\n        # If direct acceleration happens to be numerically zero, define error as norm of approx\n        err = np.linalg.norm(a_tree)\n    else:\n        err = num / den\n    return float(err)\n\ndef case_A():\n    positions = [\n        np.array([1.0, 0.0, 0.0]),\n        np.array([-1.0, 0.0, 0.0]),\n        np.array([0.0, 1.0, 0.0]),\n        np.array([0.0, -1.0, 0.0]),\n        np.array([0.0, 0.0, 1.0]),\n        np.array([0.0, 0.0, -1.0]),\n    ]\n    masses = [1.0]*6\n    target_idx = 0\n    theta = 0.6\n    return run_case(positions, masses, target_idx, theta)\n\ndef case_B():\n    positions = []\n    masses = []\n    for k in range(8):\n        lon = k * (np.pi/4.0)\n        lat = 0.0\n        positions.append(cart_from_latlon(lat, lon))\n        masses.append(1.0)\n    target_idx = 0\n    theta = 0.6\n    return run_case(positions, masses, target_idx, theta)\n\ndef case_C():\n    positions = []\n    masses = []\n    # five near-polar points\n    deltas = [1e-2, 2e-2, 3e-2, 4e-2, 5e-2]\n    for k, delta in enumerate(deltas):\n        lat = 0.5*np.pi - delta\n        lon = 2.0 * k * np.pi / 5.0\n        positions.append(cart_from_latlon(lat, lon))\n        masses.append(1.0)\n    # three equatorial points at 0, 2pi/3, 4pi/3\n    for lon in [0.0, 2.0*np.pi/3.0, 4.0*np.pi/3.0]:\n        positions.append(cart_from_latlon(0.0, lon))\n        masses.append(1.0)\n    target_idx = 0  # the first near-polar point\n    theta = 0.5\n    return run_case(positions, masses, target_idx, theta)\n\ndef case_D():\n    positions = []\n    masses = []\n    # three equatorial points at longitudes pi-1e-3, -pi+2e-3, and 0\n    positions.append(cart_from_latlon(0.0, np.pi - 1e-3))\n    positions.append(cart_from_latlon(0.0, -np.pi + 2e-3))\n    positions.append(cart_from_latlon(0.0, 0.0))\n    masses = [1.0, 1.0, 1.0]\n    target_idx = 2  # the one at longitude 0\n    theta = 0.7\n    return run_case(positions, masses, target_idx, theta)\n\ndef solve():\n    results = []\n    results.append(case_A())\n    results.append(case_B())\n    results.append(case_C())\n    results.append(case_D())\n    # Print in required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}