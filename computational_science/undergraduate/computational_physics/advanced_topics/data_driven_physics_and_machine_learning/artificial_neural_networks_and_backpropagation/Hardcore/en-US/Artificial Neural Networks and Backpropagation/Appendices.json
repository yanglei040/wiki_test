{
    "hands_on_practices": [
        {
            "introduction": "In complex loss landscapes, standard gradient-based optimization can easily become trapped in suboptimal local minima. This exercise explores a powerful technique inspired by statistical mechanics—adding noise to the gradient updates to escape these traps. You will implement a simulation connecting backpropagation to overdamped Langevin dynamics, providing a physical intuition for the success of stochastic training methods and their relationship to simulated annealing. ",
            "id": "2373958",
            "problem": "You will implement and analyze a computational experiment that connects artificial neural network training by backpropagation to thermal-noise-assisted escape from local minima, drawing a parallel to simulated annealing. Consider a scalar artificial neural network with a single parameter $w \\in \\mathbb{R}$ whose output is $y(w) = w$ for a single fixed input. Define a nonconvex training objective (interpreted as an energy landscape) by\n$$\nU(w) = (w^2 - 1)^2 + \\alpha\\, w + \\beta \\cos(k\\, w),\n$$\nwhere $\\alpha$, $\\beta$, and $k$ are fixed, known constants. Assume that the scalar network is trained by minimizing $U(w)$ via backpropagation in the sense that the training dynamics are driven by the gradient $\\frac{dU}{dw}$ with respect to $w$. You will incorporate thermal noise into the gradient signal to model thermal fluctuations, in direct analogy with overdamped Langevin dynamics and simulated annealing.\n\nFoundational bases you must use:\n- The definition of gradient-based training for a scalar parameter: the backpropagated gradient for the scalar parameter is $\\frac{dU}{dw}$.\n- The overdamped Langevin dynamics for a coordinate $w$ in an energy landscape $U(w)$ at temperature $T$ has the continuous-time form $dw/dt = -\\mu \\frac{dU}{dw} + \\sqrt{2 D}\\,\\xi(t)$ with mobility $\\mu$ and diffusion constant $D$ related by the Einstein relation $D = \\mu k_{\\mathrm{B}} T$, where $k_{\\mathrm{B}}$ is the Boltzmann constant and $\\xi(t)$ is standard white noise. In discrete time with step size $\\Delta t$ and identifying the learning rate with $\\eta = \\mu \\Delta t$, this yields a time-discretized update with a thermally scaled Gaussian noise term.\n\nYour tasks:\n1. Starting from the above bases, derive the discrete-time update for $w_{t+1}$ from $w_t$ that models gradient-descent-like backpropagation with an additive thermal noise term at a (possibly time-dependent) temperature $T(t)$. Use a constant learning rate $\\eta > 0$. Clearly justify the exact variance of the Gaussian noise term in terms of $\\eta$ and $T(t)$.\n2. Using your derived update, implement a simulation that starts the parameter at $w_0 = 0.95$ and performs a fixed number of update steps $N_{\\mathrm{steps}}$. Define a successful escape event as ending in the deeper, global well near $w \\approx -1$, which you must operationalize as the condition $w_{N_{\\mathrm{steps}}} \\le -0.9$.\n3. For each experiment, run $N_{\\mathrm{trials}}$ independent trials with different random seeds and report the fraction of successful escapes as a floating-point number in $[0,1]$. Each trial must use the same initial condition $w_0 = 0.95$ and the same schedule $T(t)$, but independent realizations of the Gaussian thermal noise. Use the following fixed constants: $\\alpha = 0.3$, $\\beta = 0.1$, $k = 5.0$, $\\eta = 0.01$, $N_{\\mathrm{steps}} = 4000$, $N_{\\mathrm{trials}} = 64$.\n4. Consider the following temperature schedules $T(t)$ that emulate different training regimes. For each schedule, compute and report the escape fraction as described.\n   - Case A (no thermal noise): $T(t) = 0$ for all $t$.\n   - Case B (constant thermal bath): $T(t) = 0.02$ for all $t$.\n   - Case C (exponential simulated annealing, slow): $T(t) = T_0 \\exp(-t/\\tau)$ with $T_0 = 0.05$ and $\\tau = 1500$.\n   - Case D (exponential simulated annealing, hot and fast): $T(t) = T_0 \\exp(-t/\\tau)$ with $T_0 = 0.15$ and $\\tau = 300$.\n5. Your program must compute the escape fractions for Cases A–D in this order and output them on a single line as a comma-separated list enclosed in square brackets. Each value must be rounded to exactly three decimal places. For example, an output for four cases should look like: [0.000,0.312,0.516,0.203].\n\nAdditional instructions:\n- Angles in trigonometric functions are dimensionless radians.\n- There are no physical units required in the output; report pure numbers.\n- The random number generation must be reproducible: fix a master seed of your choice and then derive distinct seeds for each independent trial.\n- Implement the gradient $\\frac{dU}{dw}$ exactly from the given $U(w)$. Do not approximate derivatives numerically.\n- Your code must be self-contained and must not read any input.\n\nTest suite specification:\n- Use the exact constants and schedules listed above. These constitute the test cases to be run by your program.\n- Output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets and rounded to three decimals, in the order [CaseA,CaseB,CaseC,CaseD].\n- Each of the four numbers must be of type float and must lie in $[0,1]$.",
            "solution": "The problem requires deriving a discrete-time update rule for a parameter $w$ undergoing training analogous to overdamped Langevin dynamics, and then using this rule to simulate escape from a local minimum of an energy landscape $U(w)$.\n\n**Part 1: Derivation of the Discrete-Time Update Rule**\n\nWe begin with the continuous-time overdamped Langevin equation for the parameter $w$ in the potential $U(w)$ at temperature $T$:\n$$\n\\frac{dw}{dt} = -\\mu \\frac{dU}{dw} + \\sqrt{2 D}\\,\\xi(t)\n$$\nHere, $\\mu$ is the mobility, $D$ is the diffusion constant, and $\\xi(t)$ is standard Gaussian white noise with $\\langle \\xi(t) \\rangle = 0$ and $\\langle \\xi(t)\\xi(t') \\rangle = \\delta(t-t')$. The mobility and diffusion are related by the Einstein relation, which we take as $D = \\mu T$ by absorbing the Boltzmann constant $k_B$ into the definition of temperature $T$ (treating $T$ as having units of energy).\n\nTo obtain a discrete-time update rule, we employ the Euler-Maruyama method to integrate this stochastic differential equation over a small time step $\\Delta t$. The change in $w$ from time $t$ to $t+\\Delta t$ is approximately:\n$$\nw_{t+1} - w_t = \\Delta w \\approx \\int_{t}^{t+\\Delta t} \\left( -\\mu \\frac{dU}{dw}\\bigg|_{w_s} + \\sqrt{2 D}\\,\\xi(s) \\right) ds\n$$\nAssuming $\\Delta t$ is small, the gradient term can be treated as constant over the interval, evaluated at $w_t = w(t)$. The integral of the noise term is a Wiener process increment, $\\Delta W_t = \\int_{t}^{t+\\Delta t} \\xi(s) ds$. This increment is a Gaussian random variable with mean $0$ and variance $\\Delta t$. We can write $\\Delta W_t = \\sqrt{\\Delta t} Z_t$, where $Z_t$ is a random variable drawn from the standard normal distribution $\\mathcal{N}(0, 1)$.\n\nThe discretized update equation thus becomes:\n$$\nw_{t+1} = w_t - \\mu \\Delta t \\frac{dU}{dw}\\bigg|_{w_t} + \\sqrt{2 D} \\sqrt{\\Delta t} Z_t\n$$\nThe problem statement provides an analogy between the learning rate $\\eta$ and the physical parameters via $\\eta = \\mu \\Delta t$. Substituting this and the relation $D = \\mu T$ into the equation gives:\n$$\nw_{t+1} = w_t - \\eta \\frac{dU}{dw}\\bigg|_{w_t} + \\sqrt{2 (\\mu T)} \\sqrt{\\Delta t} Z_t\n$$\nTo express the noise term purely in terms of $\\eta$ and $T$, we rearrange $\\eta = \\mu \\Delta t$ to find $\\mu = \\eta / \\Delta t$. Substituting this into the square root:\n$$\n\\sqrt{2 (\\mu T) \\Delta t} = \\sqrt{2 \\left(\\frac{\\eta}{\\Delta t} T\\right) \\Delta t} = \\sqrt{2 \\eta T}\n$$\nTherefore, the final discrete-time update rule for $w_t$ is:\n$$\nw_{t+1} = w_t - \\eta \\frac{dU}{dw}\\bigg|_{w_t} + \\sqrt{2 \\eta T(t)} Z_t\n$$\nwhere $Z_t \\sim \\mathcal{N}(0, 1)$ and the temperature $T(t)$ can be time-dependent. The first term, $-\\eta \\frac{dU}{dw}$, corresponds to a standard gradient descent update in machine learning. The second term, $\\sqrt{2 \\eta T(t)} Z_t$, is the additive thermal noise. This term is a Gaussian random variable with mean $0$ and variance $(\\sqrt{2\\eta T(t)})^2 = 2\\eta T(t)$.\n\n**Part 2: Gradient Calculation**\n\nThe energy landscape (or training objective) is given by:\n$$\nU(w) = (w^2 - 1)^2 + \\alpha w + \\beta \\cos(k w)\n$$\nTo implement the update rule, we must compute the analytical gradient of $U(w)$ with respect to $w$:\n$$\n\\frac{dU}{dw} = \\frac{d}{dw} \\left( w^4 - 2w^2 + 1 + \\alpha w + \\beta \\cos(k w) \\right)\n$$\nApplying the rules of differentiation, we get:\n$$\n\\frac{dU}{dw} = 4w^3 - 4w + \\alpha - \\beta k \\sin(k w)\n$$\nThis expression is used directly in the simulation with the provided constants $\\alpha=0.3$, $\\beta=0.1$, and $k=5.0$.\n\n**Part 3: Simulation Procedure**\n\nThe simulation aims to calculate the fraction of times the parameter $w$, starting near a local minimum at $w \\approx 1$, escapes to the global minimum basin near $w \\approx -1$.\n\nFor each of the four specified temperature schedules $T(t)$, we perform the following procedure:\n1.  Initialize a counter for successful escapes to $0$.\n2.  Run $N_{\\mathrm{trials}} = 64$ independent trials. For each trial:\n    a. Initialize the parameter $w$ to its starting value, $w_0 = 0.95$.\n    b. Generate an independent sequence of random numbers for the thermal noise. This is ensured by seeding a random number generator for each trial with a unique seed derived from a master generator to ensure reproducibility across and independence between trials.\n    c. Perform $N_{\\mathrm{steps}} = 4000$ update steps. For each step $t$ from $0$ to $N_{\\mathrm{steps}}-1$:\n        i.  Calculate the temperature $T_t = T(t)$ according to the given schedule.\n        ii. Calculate the gradient $g_t = \\frac{dU}{dw}\\big|_{w_t}$ using the formula derived above.\n        iii. Calculate the standard deviation of the noise term, $\\sigma_t = \\sqrt{2 \\eta T_t}$. If $T_t = 0$, then $\\sigma_t=0$.\n        iv. Draw a random sample $Z_t$ from the standard normal distribution $\\mathcal{N}(0, 1)$.\n        v.  Update the parameter: $w_{t+1} = w_t - \\eta g_t + \\sigma_t Z_t$.\n    d. After $N_{\\mathrm{steps}}$, check the final state of the parameter, $w_{N_{\\mathrm{steps}}}$. If $w_{N_{\\mathrm{steps}}} \\le -0.9$, the trial is counted as a successful escape.\n3.  The final escape fraction for the temperature schedule is the total number of successful escapes divided by $N_{\\mathrm{trials}}$.\n\nThis procedure is repeated for all four cases:\n- Case A (No Noise): $T(t) = 0$.\n- Case B (Constant Temperature): $T(t) = 0.02$.\n- Case C (Slow Annealing): $T(t) = 0.05 \\exp(-t/1500)$.\n- Case D (Fast Annealing): $T(t) = 0.15 \\exp(-t/300)$.\n\nThe implementation will directly follow this logic, using the provided constants: $\\alpha = 0.3$, $\\beta = 0.1$, $k = 5.0$, and $\\eta = 0.01$. The final results are rounded to three decimal places and presented in the specified format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Global constants from the problem statement\nALPHA = 0.3\nBETA = 0.1\nK = 5.0\nETA = 0.01\nW0 = 0.95\nN_STEPS = 4000\nN_TRIALS = 64\nSUCCESS_THRESHOLD = -0.9\nMASTER_SEED = 42 # For reproducible results\n\ndef gradient_U(w):\n    \"\"\"\n    Computes the analytical gradient of the potential U(w).\n    dU/dw = 4*w^3 - 4*w + alpha - beta*k*sin(k*w)\n    \"\"\"\n    return 4 * w**3 - 4 * w + ALPHA - BETA * K * np.sin(K * w)\n\ndef calculate_escape_fraction(T_func, master_rng):\n    \"\"\"\n    Runs N_trials simulations for a given temperature schedule T_func.\n    Returns the fraction of successful escapes.\n    \"\"\"\n    success_count = 0\n    for i in range(N_TRIALS):\n        # Derive a distinct seed for each trial from the master RNG for independence\n        trial_seed = master_rng.integers(2**32)\n        trial_rng = np.random.default_rng(seed=trial_seed)\n\n        w = W0\n        for t in range(N_STEPS):\n            # Calculate gradient\n            grad = gradient_U(w)\n\n            # Calculate temperature and noise term\n            temp = T_func(t)\n            noise = 0.0\n            if temp > 0:\n                # Variance of noise is 2*eta*T, so std_dev is sqrt(2*eta*T)\n                std_dev = np.sqrt(2 * ETA * temp)\n                noise = trial_rng.normal(0.0, std_dev)\n\n            # Update w using the derived discrete-time Langevin equation\n            # w_{t+1} = w_t - eta * dU/dw + noise\n            w = w - ETA * grad + noise\n        \n        # Check for successful escape\n        if w <= SUCCESS_THRESHOLD:\n            success_count += 1\n\n    return success_count / N_TRIALS\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run simulations, and print results.\n    \"\"\"\n    # Master RNG for generating trial seeds, ensuring independence between cases A, B, C, D\n    master_rng = np.random.default_rng(seed=MASTER_SEED)\n\n    # Define the four temperature schedules (test cases)\n    # Case A: No thermal noise\n    T_A = lambda t: 0.0\n    # Case B: Constant thermal bath\n    T_B = lambda t: 0.02\n    # Case C: Exponential simulated annealing, slow\n    T0_C, TAU_C = 0.05, 1500.0\n    T_C = lambda t: T0_C * np.exp(-t / TAU_C)\n    # Case D: Exponential simulated annealing, hot and fast\n    T0_D, TAU_D = 0.15, 300.0\n    T_D = lambda t: T0_D * np.exp(-t / TAU_D)\n\n    schedules = [T_A, T_B, T_C, T_D]\n\n    results = []\n    for schedule in schedules:\n        fraction = calculate_escape_fraction(schedule, master_rng)\n        results.append(fraction)\n\n    # Format the final output string exactly as required\n    formatted_results = [f\"{res:.3f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Execute the solver\nsolve()\n\n```"
        },
        {
            "introduction": "The abstract mathematics of backpropagation must ultimately be executed on physical hardware with finite numerical precision. This practice investigates the practical consequences of this limitation by quantizing gradients to a fixed number of bits, a crucial technique in modern efficient deep learning. By identifying the precision threshold at which learning breaks down, you will gain insight into the robustness of optimization algorithms and discover a compelling analogy to phase transitions in physical systems. ",
            "id": "2373947",
            "problem": "Construct a quantitative experiment to study learning under finite-precision backpropagation by training a single linear neuron with quantized gradients. Consider a dataset with input matrix $X \\in \\mathbb{R}^{N \\times d}$ and output vector $y \\in \\mathbb{R}^{N}$, where $N=d$ and $X$ is the identity matrix $I_{d}$. Let the target parameter vector be $w^{\\star} \\in \\mathbb{R}^{d}$ with entries $w^{\\star} = [1,-2,3,-4,5]^{\\top}$, and let the initial parameter vector be $w_{0}=\\mathbf{0} \\in \\mathbb{R}^{d}$. Define the empirical mean-squared error loss\n$$\nL(w) = \\frac{1}{N}\\,\\lVert Xw - y \\rVert_{2}^{2}.\n$$\nPerform full-batch gradient descent with a fixed learning rate $\\eta$ using a quantized gradient $Q_{b}(\\nabla L(w))$ that has exactly $b$ signed bits of precision (including the sign bit) applied componentwise. Let $N=5$, $d=5$, $X = I_{5}$, $y = w^{\\star}$, $w_{0}=\\mathbf{0}$, and $\\eta=1$. Train for exactly $T$ iterations with $T=2000$.\n\nThe quantizer is defined as follows. Compute the initial full-precision gradient $g_{0} = \\nabla L(w_{0})$ and set the fixed dynamic range $s_{\\mathrm{fixed}} = \\max_{j} |(g_{0})_{j}|$. For $b \\ge 2$, define the uniform quantization step\n$$\n\\Delta_{b} = \\frac{s_{\\mathrm{fixed}}}{2^{\\,b-1}-1},\n$$\nand apply componentwise rounding-to-zero quantization\n$$\n\\left[Q_{b}(g)\\right]_{j} = \\operatorname{sign}(g_{j}) \\cdot \\Delta_{b}\\,\\left\\lfloor \\frac{|g_{j}|}{\\Delta_{b}} \\right\\rfloor,\n$$\nwith the convention that $\\operatorname{sign}(0)=0$. For the edge case $b=1$, use one-bit sign quantization\n$$\n\\left[Q_{1}(g)\\right]_{j} = s_{\\mathrm{fixed}} \\cdot \\operatorname{sign}(g_{j}),\n$$\nwith $\\operatorname{sign}(0)=0$. The training update is\n$$\nw_{t+1} = w_{t} - \\eta \\, Q_{b}\\big(\\nabla L(w_{t})\\big),\n$$\napplied for $t=0,1,\\dots,T-1$.\n\nDefine the learning breakdown criterion as failure to achieve a target loss threshold $\\tau$ by iteration $T$, that is, breakdown occurs if $L(w_{T}) > \\tau$. Use the fixed threshold $\\tau = 0.002$.\n\nTest suite and required output:\n- Use the bit-precision test cases $b \\in \\{32,16,8,7,5,3,2,1\\}$.\n- For each $b$ in this set, run the above training and record a boolean indicating breakdown: output $\\mathrm{True}$ if $L(w_{T}) > \\tau$ and $\\mathrm{False}$ otherwise.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[False,False,False,True,True,True,True,True]\") in the exact order of the test cases $[32,16,8,7,5,3,2,1]$.\n\nAll quantities are unitless real numbers. Angles are not used. The required final output format is a single line containing the list of booleans as specified, with no additional text.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It poses a clear, verifiable computational experiment in the study of numerical precision in optimization algorithms. All parameters and functions are explicitly defined, and the premises are consistent with mathematical and machine learning principles. The problem is valid.\n\nThe task is to simulate the training of a single linear neuron using full-batch gradient descent where the gradients are quantized. We will analyze the behavior for different bit precisions and determine when the training process breaks down, defined as failing to reach a specific loss threshold.\n\nFirst, we formulate the loss function and its gradient. The model is a linear neuron with output $Xw$ for an input matrix $X$ and weight vector $w$. The loss is the empirical mean-squared error:\n$$\nL(w) = \\frac{1}{N} \\lVert Xw - y \\rVert_2^2\n$$\nThe problem specifies $N=5$, $d=5$, $X = I_5$ (the $5 \\times 5$ identity matrix), and the target outputs $y$ are set equal to the target weights $w^{\\star}$. Thus, the loss function simplifies to:\n$$\nL(w) = \\frac{1}{5} \\lVert w - w^\\star \\rVert_2^2\n$$\nThe global minimum of this loss is $L=0$ at $w = w^\\star$. The gradient of the loss function with respect to $w$ is:\n$$\n\\nabla L(w) = \\frac{2}{N} X^{\\top}(Xw - y) = \\frac{2}{5} I_5^{\\top}(I_5 w - w^\\star) = \\frac{2}{5} (w - w^\\star)\n$$\n\nThe training process starts with the initial parameter vector $w_0 = \\mathbf{0}$. The initial gradient is therefore:\n$g_0 = \\nabla L(w_0) = \\frac{2}{5} (w_0 - w^\\star) = -\\frac{2}{5} w^\\star$\nGiven $w^{\\star} = [1, -2, 3, -4, 5]^{\\top}$, we compute $g_0$:\n$g_0 = [-0.4, 0.8, -1.2, 1.6, -2.0]^{\\top}$\nThe quantization scheme uses a fixed dynamic range $s_{\\mathrm{fixed}}$ determined by the maximum magnitude of the initial gradient components:\n$s_{\\mathrm{fixed}} = \\max_{j} |(g_0)_j| = \\max\\{0.4, 0.8, 1.2, 1.6, 2.0\\} = 2.0$\n\nThe training proceeds for $T=2000$ iterations using the update rule:\n$w_{t+1} = w_t - \\eta \\, Q_b(\\nabla L(w_t))$\nwhere the learning rate is $\\eta=1$, and $Q_b$ is the quantization operator for $b$ bits of precision.\n\nFor $b \\ge 2$, the uniform quantization step $\\Delta_b$ is defined as:\n$$\n\\Delta_b = \\frac{s_{\\mathrm{fixed}}}{2^{b-1}-1} = \\frac{2.0}{2^{b-1}-1}\n$$\nThe component-wise quantization function is:\n$[Q_b(g)]_j = \\operatorname{sign}(g_j) \\cdot \\Delta_b \\cdot \\left\\lfloor \\frac{|g_j|}{\\Delta_b} \\right\\rfloor$\nThis function maps any gradient component $g_j$ to the nearest multiple of $\\Delta_b$ that is closer to zero. A \"dead zone\" exists around zero: if $|g_j| < \\Delta_b$, then $[Q_b(g)]_j = 0$.\n\nFor the edge case $b=1$, the quantization is:\n$ [Q_1(g)]_j = s_{\\mathrm{fixed}} \\cdot \\operatorname{sign}(g_j) = 2.0 \\cdot \\operatorname{sign}(g_j) $\nThis maps any non-zero gradient component to either $+2.0$ or $-2.0$.\n\nThe simulation will be run for each bit precision $b \\in \\{32, 16, 8, 7, 5, 3, 2, 1\\}$. After $T=2000$ iterations, we calculate the final loss $L(w_T)$ and check for breakdown, which occurs if $L(w_T) > \\tau=0.002$.\n\nA key cause of breakdown is the quantization dead zone. If the magnitude of an initial gradient component $|(g_0)_j|$ is smaller than the quantization step $\\Delta_b$, that component will be quantized to zero from the start. The corresponding weight $w_j$ will never be updated from its initial value of $0$. The smallest magnitude of a component in $g_0$ is $|(g_0)_0| = 0.4$. Breakdown is guaranteed if $\\Delta_b > 0.4$:\n$$\n\\frac{2.0}{2^{b-1}-1} > 0.4 \\implies 5 > 2^{b-1}-1 \\implies 6 > 2^{b-1} \\implies b-1 < \\log_2(6) \\approx 2.585 \\implies b < 3.585\n$$\nThus, for $b=3, 2, 1$, we anticipate breakdown because at least one weight component will fail to learn.\n\nFor higher values of $b$, where $\\Delta_b$ is small enough for all components to begin learning, the quantization error still limits the final precision. The training effectively stalls when the gradient magnitude for each component, $|\\nabla L(w_t)_j|$, falls below $\\Delta_b$. This leaves a residual error in the weights, $w_T - w^\\star$, where each component is roughly bounded by $\\frac{N}{2}\\Delta_b$. The final loss is approximately proportional to $\\Delta_b^2$. If this minimum achievable loss is greater than the threshold $\\tau$, breakdown occurs. We expect this to happen for intermediate values of $b$ such as $7$ and $5$.\n\nFor large $b$ (e.g., $32, 16$), $\\Delta_b$ is very small, the quantization error is negligible, and the algorithm converges well, resulting in a final loss below $\\tau$. The provided program implements this simulation precisely to find the breakdown point.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates training a single linear neuron with quantized gradients\n    to study learning under finite precision.\n    \"\"\"\n    # Define problem parameters\n    N = 5.0\n    d = 5\n    w_star = np.array([1.0, -2.0, 3.0, -4.0, 5.0])\n    w0 = np.zeros(d)\n    eta = 1.0\n    T = 2000\n    tau = 0.002\n\n    # Define the bit-precision test cases\n    b_cases = [32, 16, 8, 7, 5, 3, 2, 1]\n    \n    results = []\n\n    # Calculate the fixed dynamic range s_fixed from the initial gradient.\n    # This is constant for all test cases.\n    g0 = (2.0 / N) * (w0 - w_star)\n    s_fixed = np.max(np.abs(g0))\n\n    # Iterate over each bit-precision case\n    for b in b_cases:\n        # Initialize weights for the current simulation\n        w = w0.copy()\n\n        # Define the quantizer for the current bit precision b\n        def quantize_gradient(g: np.ndarray, b_val: int) -> np.ndarray:\n            \"\"\"\n            Applies component-wise quantization to the gradient vector.\n            \"\"\"\n            # Case b=1: Sign quantization\n            if b_val == 1:\n                return s_fixed * np.sign(g)\n\n            # Case b >= 2: Uniform quantization\n            # The denominator 2**(b-1) - 1 is greater than 0 for b >= 2.\n            denominator = (2**(b_val - 1)) - 1\n            \n            # For very large b like 32, delta_b is very small but non-zero.\n            # If hypothetically b was so large that denominator overflows,\n            # delta_b would tend to 0, meaning no quantization.\n            if denominator == 0:  # Should not happen for b>=2\n                return g\n            \n            delta_b = s_fixed / denominator\n\n            # The quantizer function is Q_b(g)_j = sign(g_j) * delta_b * floor(|g_j|/delta_b)\n            # This is equivalent to rounding towards zero (truncation).\n            sign_g = np.sign(g)\n            abs_g = np.abs(g)\n            \n            # np.floor implements the rounding-to-zero logic when combined with sign.\n            quantized_magnitude = delta_b * np.floor(abs_g / delta_b)\n            \n            return sign_g * quantized_magnitude\n\n        # Main training loop\n        for _ in range(T):\n            # 1. Calculate the full-precision gradient\n            gradient = (2.0 / N) * (w - w_star)\n            \n            # 2. Quantize the gradient\n            quantized_grad = quantize_gradient(gradient, b)\n            \n            # 3. Update the weights\n            w = w - eta * quantized_grad\n            \n        # After training, calculate the final loss\n        # L(w) = (1/N) * ||w - w_star||^2\n        final_loss = (1.0 / N) * np.linalg.norm(w - w_star)**2\n        \n        # Determine if a breakdown occurred based on the threshold tau\n        breakdown = final_loss > tau\n        results.append(breakdown)\n\n    # Final print statement in the exact required format.\n    # The output format is a string representation of a Python list of booleans.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Standard backpropagation assumes the parameter space is a simple, flat Euclidean space, but many problems involve inherent constraints that define a curved, non-Euclidean manifold. This exercise challenges you to generalize gradient descent by constraining a neuron's weights to the surface of a sphere. By implementing optimization using Riemannian gradients and geodesic updates, you will learn to apply the geometric principles fundamental to modern physics to the advanced domain of machine learning. ",
            "id": "2373877",
            "problem": "Construct a complete and runnable program that trains a single-neuron Artificial Neural Network (ANN) with binary logistic output while constraining the weight vector to the unit sphere. The neuron maps an input vector $\\mathbf{x} \\in \\mathbb{R}^3$ to a probability $\\hat{y} = \\sigma(z)$ with $z = \\mathbf{w} \\cdot \\mathbf{x} + b$, where $\\sigma(z) = \\dfrac{1}{1 + e^{-z}}$, the weight $\\mathbf{w} \\in \\mathbb{R}^3$ is constrained to the unit sphere $S^2 = \\{\\mathbf{w} \\in \\mathbb{R}^3 \\mid \\|\\mathbf{w}\\|_2 = 1\\}$, and the bias $b \\in \\mathbb{R}$ is unconstrained. The loss for a dataset $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^m$ with $y_i \\in \\{0,1\\}$ is the average binary cross-entropy\n$$\n\\mathcal{L}(\\mathbf{w}, b) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y_i \\log \\sigma(z_i) - (1 - y_i) \\log (1 - \\sigma(z_i)) \\right],\n$$\nwhere $z_i = \\mathbf{w} \\cdot \\mathbf{x}_i + b$ and $m$ is the number of samples.\n\nThe unit sphere $S^2$ is endowed with the Riemannian metric induced by the standard Euclidean inner product on $\\mathbb{R}^3$. At a point $\\mathbf{w} \\in S^2$, the tangent space is\n$$\nT_{\\mathbf{w}} S^2 = \\left\\{ \\mathbf{v} \\in \\mathbb{R}^3 \\ \\big| \\ \\mathbf{w} \\cdot \\mathbf{v} = 0 \\right\\}.\n$$\nLet $\\nabla_{\\!E} \\mathcal{L}(\\mathbf{w}, b)$ denote the Euclidean gradient with respect to $\\mathbf{w}$. The Riemannian gradient on $S^2$ is the orthogonal projection of $\\nabla_{\\!E} \\mathcal{L}$ onto $T_{\\mathbf{w}} S^2$:\n$$\n\\operatorname{grad}_{\\!S^2} \\mathcal{L}(\\mathbf{w}, b) = \\nabla_{\\!E} \\mathcal{L}(\\mathbf{w}, b) - \\left( \\mathbf{w} \\cdot \\nabla_{\\!E} \\mathcal{L}(\\mathbf{w}, b) \\right) \\mathbf{w}.\n$$\nFor a step size $\\alpha > 0$, one discrete-time learning step must move $\\mathbf{w}$ along the geodesic emanating from $\\mathbf{w}$ in the direction of $-\\operatorname{grad}_{\\!S^2} \\mathcal{L}$ by geodesic distance $\\alpha \\|\\operatorname{grad}_{\\!S^2} \\mathcal{L}\\|_2$, that is, the next iterate is the Riemannian exponential map\n$$\n\\mathbf{w}_{\\text{next}} =\n\\begin{cases}\n\\cos(\\|\\mathbf{v}\\|_2)\\, \\mathbf{w} + \\sin(\\|\\mathbf{v}\\|_2) \\dfrac{\\mathbf{v}}{\\|\\mathbf{v}\\|_2}, & \\text{if } \\|\\mathbf{v}\\|_2 \\neq 0, \\\\\n\\mathbf{w}, & \\text{if } \\|\\mathbf{v}\\|_2 = 0,\n\\end{cases}\n\\quad \\text{with } \\mathbf{v} = -\\alpha \\, \\operatorname{grad}_{\\!S^2} \\mathcal{L}(\\mathbf{w}, b).\n$$\nThe bias is updated in the Euclidean sense as $b_{\\text{next}} = b - \\alpha \\, \\dfrac{\\partial \\mathcal{L}}{\\partial b}$.\n\nUse the dataset of $m = 4$ samples in $\\mathbb{R}^3$:\n- $\\mathbf{x}_1 = (1, 0, 0)$, $y_1 = 1$,\n- $\\mathbf{x}_2 = (0, 1, 0)$, $y_2 = 0$,\n- $\\mathbf{x}_3 = (0, 0, 1)$, $y_3 = 1$,\n- $\\mathbf{x}_4 = (-1, 0, 0)$, $y_4 = 0$.\n\nYour program must:\n- Implement the above model, loss, and geometry,\n- Compute $\\nabla_{\\!E} \\mathcal{L}$ and $\\dfrac{\\partial \\mathcal{L}}{\\partial b}$ from first principles,\n- Perform a fixed number of iterations of the specified discrete-time learning dynamics for each test case,\n- Report, for each test case, the final average loss value $\\mathcal{L}$ (a float), the final Euclidean norm $\\|\\mathbf{w}\\|_2$ (a float), and the final bias $b$ (a float).\n\nTest suite:\n- Case A (general case): step size $\\alpha = 0.1$, iterations $T = 50$, initial weight $\\mathbf{w}_0 = \\left(\\dfrac{1}{\\sqrt{3}}, \\dfrac{1}{\\sqrt{3}}, \\dfrac{1}{\\sqrt{3}}\\right)$, initial bias $b_0 = 0$.\n- Case B (boundary case): step size $\\alpha = 0$, iterations $T = 50$, initial weight $\\mathbf{w}_0 = (1, 0, 0)$, initial bias $b_0 = 0$.\n- Case C (edge case with large step size): step size $\\alpha = 1$, iterations $T = 10$, initial weight $\\mathbf{w}_0 = (0, 0, 1)$, initial bias $b_0 = 0.5$.\n\nAngle usage in trigonometric functions is in radians. There are no physical units in this problem. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of three floats in the order $[\\text{final\\_loss}, \\|\\mathbf{w}\\|_2, b]$. For example, the output format must be exactly of the form\n$[[\\ell_A, n_A, b_A],[\\ell_B, n_B, b_B],[\\ell_C, n_C, b_C]]$,\nwith no additional text.",
            "solution": "The problem statement has been validated and is deemed valid. It is a well-posed problem in the field of computational physics and machine learning, specifically concerning optimization on Riemannian manifolds. The problem is scientifically grounded, free of contradictions, and contains all necessary information to derive a unique solution.\n\nThe task is to implement a training algorithm for a single neuron with a logistic activation function. The key constraint is that the weight vector $\\mathbf{w} \\in \\mathbb{R}^3$ must lie on the surface of the unit sphere, $\\|\\mathbf{w}\\|_2 = 1$. This constraint transforms the optimization problem from a standard Euclidean setting into one on the Riemannian manifold $S^2$.\n\nFirst, we derive the necessary gradients for the optimization procedure. The model's prediction for an input $\\mathbf{x}_i$ is $\\hat{y}_i = \\sigma(z_i)$, where $z_i = \\mathbf{w} \\cdot \\mathbf{x}_i + b$ and $\\sigma(z) = (1 + e^{-z})^{-1}$ is the sigmoid function. The loss function is the average binary cross-entropy over a dataset of $m$ samples:\n$$\n\\mathcal{L}(\\mathbf{w}, b) = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}_i = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y_i \\log \\sigma(z_i) - (1 - y_i) \\log (1 - \\sigma(z_i)) \\right]\n$$\nTo find the gradients with respect to the parameters $\\mathbf{w}$ and $b$, we apply the chain rule. The derivative of the loss for a single sample $\\mathcal{L}_i$ with respect to the linear activation $z_i$ is a standard result:\n$$\n\\frac{\\partial \\mathcal{L}_i}{\\partial z_i} = \\frac{\\partial \\mathcal{L}_i}{\\partial \\hat{y}_i} \\frac{\\partial \\hat{y}_i}{\\partial z_i}\n$$\nThe components are:\n$$\n\\frac{\\partial \\mathcal{L}_i}{\\partial \\hat{y}_i} = -\\frac{y_i}{\\hat{y}_i} + \\frac{1-y_i}{1-\\hat{y}_i} = \\frac{\\hat{y}_i - y_i}{\\hat{y}_i(1-\\hat{y}_i)}\n$$\n$$\n\\frac{\\partial \\hat{y}_i}{\\partial z_i} = \\frac{d\\sigma(z_i)}{dz_i} = \\sigma(z_i)(1 - \\sigma(z_i)) = \\hat{y}_i(1-\\hat{y}_i)\n$$\nCombining these, we obtain the remarkably simple form:\n$$\n\\frac{\\partial \\mathcal{L}_i}{\\partial z_i} = \\hat{y}_i - y_i\n$$\nNow, we can find the Euclidean gradient of the total loss $\\mathcal{L}$ with respect to $\\mathbf{w}$, denoted $\\nabla_{\\!E} \\mathcal{L}$, and the partial derivative with respect to the bias $b$.\n$$\n\\nabla_{\\!E} \\mathcal{L}(\\mathbf{w}, b) = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} = \\frac{1}{m} \\sum_{i=1}^m \\frac{\\partial \\mathcal{L}_i}{\\partial z_i} \\frac{\\partial z_i}{\\partial \\mathbf{w}} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}_i - y_i) \\mathbf{x}_i\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m \\frac{\\partial \\mathcal{L}_i}{\\partial z_i} \\frac{\\partial z_i}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}_i - y_i) \\cdot 1 = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}_i - y_i)\n$$\nThe optimization algorithm proceeds iteratively. The bias $b$ is unconstrained and can be updated using standard Euclidean gradient descent:\n$$\nb_{k+1} = b_k - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b}\n$$\nThe weight vector $\\mathbf{w}$, however, must remain on the unit sphere $S^2$. A naive Euclidean update $\\mathbf{w}_{k+1} = \\mathbf{w}_k - \\alpha \\nabla_{\\!E} \\mathcal{L}$ would move the vector off the sphere. The correct procedure involves two steps:\n\n1.  **Gradient Projection**: The direction of steepest descent on the manifold is given by the Riemannian gradient, $\\operatorname{grad}_{\\!S^2} \\mathcal{L}$. This is found by projecting the ambient Euclidean gradient $\\nabla_{\\!E} \\mathcal{L}$ onto the tangent space $T_{\\mathbf{w}} S^2$ at the current point $\\mathbf{w}$. The projection formula is given as:\n    $$\n    \\operatorname{grad}_{\\!S^2} \\mathcal{L}(\\mathbf{w}, b) = \\nabla_{\\!E} \\mathcal{L} - (\\mathbf{w} \\cdot \\nabla_{\\!E} \\mathcal{L}) \\mathbf{w}\n    $$\n    This operation subtracts the component of the Euclidean gradient that is normal to the sphere, leaving only the tangential component.\n\n2.  **Retraction**: The update step is performed by moving along the geodesic (a great circle on the sphere) from $\\mathbf{w}$ in the direction of the negative Riemannian gradient. This operation is called the exponential map. We first define the update vector in the tangent space, $\\mathbf{v} = -\\alpha \\, \\operatorname{grad}_{\\!S^2} \\mathcal{L}$. The magnitude $\\|\\mathbf{v}\\|_2$ is the length of the arc along which we travel. The updated weight vector $\\mathbf{w}_{\\text{next}}$ is given by the specified formula for the Riemannian exponential map:\n    $$\n    \\mathbf{w}_{\\text{next}} =\n    \\begin{cases}\n    \\cos(\\|\\mathbf{v}\\|_2)\\, \\mathbf{w} + \\sin(\\|\\mathbf{v}\\|_2) \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|_2}, & \\text{if } \\|\\mathbf{v}\\|_2 > 0, \\\\\n    \\mathbf{w}, & \\text{if } \\|\\mathbf{v}\\|_2 = 0.\n    \\end{cases}\n    $$\n    This update robustly ensures that $\\|\\mathbf{w}_{\\text{next}}\\|_2 = 1$ if $\\|\\mathbf{w}\\|_2 = 1$, thus preserving the constraint.\n\nThe implementation will consist of a loop that runs for a fixed number of iterations $T$. In each iteration, it will compute the predictions $\\hat{y}_i$ for all data points, calculate the Euclidean gradients, project the weight gradient to obtain the Riemannian gradient, and then update both $b$ and $\\mathbf{w}$ using their respective update rules. The final loss, weight vector norm, and bias will be reported for each test case specified in the problem statement. All calculations are performed using vectorized operations in `numpy` for efficiency.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem by running the specified test cases.\n    \"\"\"\n    # Define the dataset\n    X = np.array([\n        [1.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0],\n        [0.0, 0.0, 1.0],\n        [-1.0, 0.0, 0.0]\n    ])\n    y = np.array([1.0, 0.0, 1.0, 0.0])\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"alpha\": 0.1, \n            \"T\": 50, \n            \"w0\": np.array([1.0, 1.0, 1.0]) / np.sqrt(3), \n            \"b0\": 0.0\n        },\n        {\n            \"alpha\": 0.0, \n            \"T\": 50, \n            \"w0\": np.array([1.0, 0.0, 0.0]), \n            \"b0\": 0.0\n        },\n        {\n            \"alpha\": 1.0, \n            \"T\": 10, \n            \"w0\": np.array([0.0, 0.0, 1.0]), \n            \"b0\": 0.5\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        final_loss, final_w_norm, final_b = train_riemannian_neuron(\n            X, y, case[\"w0\"], case[\"b0\"], case[\"alpha\"], case[\"T\"]\n        )\n        results.append([final_loss, final_w_norm, final_b])\n\n    # Final print statement in the exact required format.\n    # The string representation is manipulated to remove spaces for exact format matching.\n    final_output_str = str(results).replace(\" \", \"\")\n    print(final_output_str)\n\ndef _sigmoid(z):\n    \"\"\"Computes the sigmoid function.\"\"\"\n    return 1.0 / (1.0 + np.exp(-z))\n\ndef _compute_loss(y, y_hat):\n    \"\"\"Computes the average binary cross-entropy loss.\"\"\"\n    m = len(y)\n    # Adding a small epsilon for numerical stability in log, though not strictly\n    # necessary as sigmoid output is always in (0,1).\n    epsilon = 1e-9\n    loss = -np.sum(y * np.log(y_hat + epsilon) + (1 - y) * np.log(1 - y_hat + epsilon)) / m\n    return loss\n\ndef train_riemannian_neuron(X, y, w0, b0, alpha, T):\n    \"\"\"\n    Trains a single neuron with a spherical weight constraint using Riemannian optimization.\n    \n    Args:\n        X (np.ndarray): Input data, shape (m, n).\n        y (np.ndarray): Target labels, shape (m,).\n        w0 (np.ndarray): Initial weight vector on the unit sphere, shape (n,).\n        b0 (float): Initial bias.\n        alpha (float): Learning rate (step size).\n        T (int): Number of training iterations.\n\n    Returns:\n        tuple: A tuple containing the final loss (float), final weight norm (float), \n               and final bias (float).\n    \"\"\"\n    w = np.copy(w0)\n    b = b0\n    m = X.shape[0]\n\n    for _ in range(T):\n        # Forward pass\n        z = X @ w + b\n        y_hat = _sigmoid(z)\n\n        # Gradient calculation (from first principles)\n        error = y_hat - y\n        \n        # Euclidean gradient w.r.t. w\n        grad_w_euclidean = (X.T @ error) / m\n        \n        # Gradient w.r.t. b\n        grad_b = np.mean(error)\n        \n        # Riemannian gradient for w (projection onto tangent space)\n        grad_w_riemannian = grad_w_euclidean - np.dot(w, grad_w_euclidean) * w\n\n        # Update bias (standard gradient descent)\n        b = b - alpha * grad_b\n        \n        # Update weights (Riemannian exponential map)\n        v = -alpha * grad_w_riemannian\n        v_norm = np.linalg.norm(v)\n        \n        # Geodesic update\n        if v_norm > 1e-15: # To avoid division by zero\n            w = np.cos(v_norm) * w + np.sin(v_norm) * v / v_norm\n\n    # Final computation after all iterations\n    z_final = X @ w + b\n    y_hat_final = _sigmoid(z_final)\n    final_loss = _compute_loss(y, y_hat_final)\n    final_w_norm = np.linalg.norm(w)\n    \n    return final_loss, final_w_norm, b\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}