{
    "hands_on_practices": [
        {
            "introduction": "This first exercise demonstrates one of the most remarkable properties of Gaussian quadrature: its ability to exactly integrate polynomials of a degree far higher than the number of sample points would suggest. You will apply a simple two-point rule to a quadratic function and verify by direct calculation that the result is not an approximation, but the exact answer. This practice provides a concrete foundation for understanding why an $n$-point rule is exact for polynomials of degree up to $2n-1$, a key reason for its power and efficiency.",
            "id": "2665798",
            "problem": "In one-dimensional solid mechanics, consider a two-node isoparametric bar element used in the Finite Element Method (FEM). Let the parent coordinate be denoted by $\\xi \\in [-1,1]$. Suppose that a nondimensionalized internal energy density per unit Jacobian associated with a certain virtual deformation mode is given by the quadratic function $u(\\xi) = 3\\xi^{2} + 2\\xi + 1$. The elemental contribution of this mode to the nondimensional internal virtual work is the integral\n$$\nI = \\int_{-1}^{1} u(\\xi)\\, d\\xi.\n$$\nUsing the two-point Gauss–Legendre quadrature rule on $[-1,1]$ with nodes $\\xi = \\pm 1/\\sqrt{3}$ and weights $w = 1$, evaluate $I$ by quadrature. Then, verify the exactness of the quadrature by computing the analytic value of the integral directly from the definition of the Riemann integral. Report the value of $I$ as a pure number (dimensionless). No rounding is necessary because the result is exact.",
            "solution": "The problem statement is subjected to validation before any attempt at a solution.\n\nStep 1: Extract Givens.\n- The context is one-dimensional solid mechanics, specifically a two-node isoparametric Finite Element Method (FEM) bar element.\n- The parent coordinate is $\\xi \\in [-1,1]$.\n- The internal energy density function per unit Jacobian is $u(\\xi) = 3\\xi^{2} + 2\\xi + 1$.\n- The integral for the elemental contribution to the internal virtual work is $I = \\int_{-1}^{1} u(\\xi)\\, d\\xi$.\n- The numerical integration method is two-point Gauss–Legendre quadrature.\n- The quadrature nodes are $\\xi = \\pm \\frac{1}{\\sqrt{3}}$.\n- The quadrature weights are $w = 1$.\n- The tasks are to evaluate $I$ using this quadrature rule and to verify the result by computing the analytic integral.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically sound. It describes a standard, fundamental procedure in computational mechanics: the numerical evaluation of an integral over an element's parent domain using Gauss quadrature. The integrand $u(\\xi)$ is a well-behaved polynomial. All parameters, including the integration limits, function definition, quadrature nodes, and weights, are provided, and they are consistent with the standard formulation of a two-point Gauss-Legendre rule. The problem is well-posed, objective, and contains no scientific or logical flaws. The question is a direct application of numerical analysis principles within the specified field and is therefore valid.\n\nStep 3: Verdict and Action.\nThe problem is valid. A solution will be provided.\n\nThe problem requires the evaluation of the integral $I = \\int_{-1}^{1} u(\\xi)\\, d\\xi$ for the function $u(\\xi) = 3\\xi^{2} + 2\\xi + 1$. The evaluation must be performed using two methods for comparison: two-point Gauss-Legendre quadrature and direct analytical integration.\n\nFirst, we apply the two-point Gauss-Legendre quadrature rule. The general form for this quadrature on the interval $[-1,1]$ is given by:\n$$\n\\int_{-1}^{1} f(\\xi)\\, d\\xi \\approx \\sum_{i=1}^{n} w_i f(\\xi_i)\n$$\nFor a two-point rule ($n=2$), the nodes are $\\xi_1 = -\\frac{1}{\\sqrt{3}}$ and $\\xi_2 = \\frac{1}{\\sqrt{3}}$, and the corresponding weights are $w_1 = 1$ and $w_2 = 1$. The integrand is $f(\\xi) = u(\\xi) = 3\\xi^{2} + 2\\xi + 1$.\n\nWe evaluate the function $u(\\xi)$ at each of the quadrature nodes:\nAt $\\xi_1 = -\\frac{1}{\\sqrt{3}}$:\n$$\nu\\left(-\\frac{1}{\\sqrt{3}}\\right) = 3\\left(-\\frac{1}{\\sqrt{3}}\\right)^{2} + 2\\left(-\\frac{1}{\\sqrt{3}}\\right) + 1 = 3\\left(\\frac{1}{3}\\right) - \\frac{2}{\\sqrt{3}} + 1 = 1 - \\frac{2}{\\sqrt{3}} + 1 = 2 - \\frac{2}{\\sqrt{3}}\n$$\nAt $\\xi_2 = \\frac{1}{\\sqrt{3}}$:\n$$\nu\\left(\\frac{1}{\\sqrt{3}}\\right) = 3\\left(\\frac{1}{\\sqrt{3}}\\right)^{2} + 2\\left(\\frac{1}{\\sqrt{3}}\\right) + 1 = 3\\left(\\frac{1}{3}\\right) + \\frac{2}{\\sqrt{3}} + 1 = 1 + \\frac{2}{\\sqrt{3}} + 1 = 2 + \\frac{2}{\\sqrt{3}}\n$$\nNow, we compute the approximate value of the integral, which we denote $I_{GQ}$:\n$$\nI_{GQ} = w_1 u(\\xi_1) + w_2 u(\\xi_2) = (1) \\left(2 - \\frac{2}{\\sqrt{3}}\\right) + (1) \\left(2 + \\frac{2}{\\sqrt{3}}\\right)\n$$\n$$\nI_{GQ} = 2 - \\frac{2}{\\sqrt{3}} + 2 + \\frac{2}{\\sqrt{3}} = 4\n$$\nThe value of the integral using two-point Gauss quadrature is $4$.\n\nNext, we proceed with the verification by computing the exact value of the integral analytically using the Fundamental Theorem of Calculus.\n$$\nI = \\int_{-1}^{1} (3\\xi^{2} + 2\\xi + 1)\\, d\\xi\n$$\nThe antiderivative of the integrand is:\n$$\n\\int (3\\xi^{2} + 2\\xi + 1)\\, d\\xi = 3\\frac{\\xi^{3}}{3} + 2\\frac{\\xi^{2}}{2} + \\xi + C = \\xi^{3} + \\xi^{2} + \\xi + C\n$$\nEvaluating the definite integral between the limits $\\xi = -1$ and $\\xi = 1$:\n$$\nI = \\left[ \\xi^{3} + \\xi^{2} + \\xi \\right]_{-1}^{1} = \\left( (1)^{3} + (1)^{2} + (1) \\right) - \\left( ((-1)^{3} + (-1)^{2} + (-1)) \\right)\n$$\n$$\nI = (1 + 1 + 1) - (-1 + 1 - 1) = (3) - (-1) = 3 + 1 = 4\n$$\nThe exact analytical value of the integral is $4$.\n\nThe result from the two-point Gauss quadrature, $I_{GQ} = 4$, matches the exact analytical result, $I = 4$. This is expected. A Gauss-Legendre quadrature rule with $n$ points integrates polynomials of degree up to $2n-1$ exactly. In this problem, $n=2$, so the rule must be exact for any polynomial of degree up to $2(2)-1 = 3$. The integrand $u(\\xi) = 3\\xi^{2} + 2\\xi + 1$ is a polynomial of degree $2$. Since $2 \\le 3$, the quadrature yields the exact result. The verification confirms this theoretical principle. The required value of $I$ is therefore $4$.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "The impressive \"spectral\" convergence of Gaussian quadrature holds for smooth, infinitely differentiable functions. This computational exercise explores what happens when we apply the method to an integrand with a \"kink\"—a function that is continuous but not differentiable at a point. By analyzing the integration error as a function of the number of quadrature points $n$, you will learn the essential skill of empirically measuring convergence rates and gain insight into the performance limitations of the method in more realistic scenarios.",
            "id": "2397754",
            "problem": "Consider the integral of the function $f(x)=\\lvert x-c\\rvert$ over the interval $[-1,1]$ for a fixed parameter $c\\in(-1,1)$. Let $I(c)$ denote the exact value of the integral, and let $Q_n(c)$ denote the $n$-point Gaussian quadrature approximation with Legendre weight on $[-1,1]$. Define the absolute error $E_n(c)=\\lvert Q_n(c)-I(c)\\rvert$. Investigate how the empirical algebraic convergence rate of $E_n(c)$ with respect to $n$ depends on the location of $c$ relative to the quadrature nodes.\n\nYour program must:\n- Compute the exact integral $I(c)$ from first principles.\n- For each $n$ in the integer set $\\{2,3,4,\\dots,80\\}$, compute $Q_n(c)$ and the absolute error $E_n(c)$.\n- For each fixed $c$, estimate two empirical algebraic convergence rates, $p_{\\mathrm{even}}(c)$ and $p_{\\mathrm{odd}}(c)$, by fitting a straight line to $(\\log n,\\log E_n(c))$ separately over the even subsequence $\\{n\\in\\mathbb{N}: n\\in\\{2,4,6,\\dots,80\\}\\}$ and the odd subsequence $\\{n\\in\\mathbb{N}: n\\in\\{3,5,7,\\dots,79\\}\\}$, respectively. Use the least-squares slope $\\hat{s}$ of $\\log E_n(c)$ versus $\\log n$ and define the empirical rate as $p=-\\hat{s}$. To avoid floating-point saturation, exclude any $(n,E_n(c))$ pairs with $E_n(c)\\le 10^{-14}$ from the fit; if fewer than $3$ points remain, use all available points without exclusion.\n- Use the natural logarithm for all logarithms in the rate estimation.\n\nUse the following test suite of parameter values:\n- $c_1=0$,\n- $c_2=0.1$,\n- $c_3=0.5773502691896257$.\n\nFor each $c_j$ in the test suite, compute and report the pair $\\big(p_{\\mathrm{even}}(c_j),\\,p_{\\mathrm{odd}}(c_j)\\big)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order and format:\n$[p_{\\mathrm{even}}(c_1),p_{\\mathrm{odd}}(c_1),p_{\\mathrm{even}}(c_2),p_{\\mathrm{odd}}(c_2),p_{\\mathrm{even}}(c_3),p_{\\mathrm{odd}}(c_3)]$.\nAll reported values must be real-valued numbers (no units), and angles do not appear in this task. The final output must be a single line and must not contain any additional text.",
            "solution": "The problem statement is subjected to validation and is found to be valid. It is scientifically grounded in the field of numerical analysis, specifically concerning the convergence properties of Gaussian quadrature. The problem is well-posed, objective, and contains all necessary information for a unique solution to be computed.\n\nThe task is to investigate the empirical algebraic convergence rate of $n$-point Gauss-Legendre quadrature for the integral of the function $f(x) = \\lvert x-c \\rvert$ over the interval $[-1, 1]$. The function $f(x)$ is continuous, but its first derivative, $f'(x) = \\text{sgn}(x-c)$, has a jump discontinuity at $x=c$. This lack of smoothness is known to degrade the convergence rate of high-order quadrature rules from exponential (for analytic functions) to algebraic. We hypothesize an error scaling of the form $E_n(c) \\propto n^{-p}$, where $E_n(c)$ is the absolute error for an $n$-point rule and $p$ is the algebraic convergence rate.\n\nFirst, we determine the exact value of the integral, denoted by $I(c)$. For $c \\in (-1, 1)$, we split the integral at the point of non-differentiability, $x=c$:\n$$\nI(c) = \\int_{-1}^{1} \\lvert x-c \\rvert \\, dx = \\int_{-1}^{c} -(x-c) \\, dx + \\int_{c}^{1} (x-c) \\, dx\n$$\nEvaluating the elementary integrals gives:\n$$\nI(c) = \\left[ cx - \\frac{x^2}{2} \\right]_{-1}^{c} + \\left[ \\frac{x^2}{2} - cx \\right]_{c}^{1}\n$$\n$$\nI(c) = \\left( (c^2 - \\frac{c^2}{2}) - (-c - \\frac{1}{2}) \\right) + \\left( (\\frac{1}{2} - c) - (\\frac{c^2}{2} - c^2) \\right)\n$$\n$$\nI(c) = \\left( \\frac{c^2}{2} + c + \\frac{1}{2} \\right) + \\left( \\frac{1}{2} - c + \\frac{c^2}{2} \\right) = c^2 + 1\n$$\nThis analytical result, $I(c) = c^2+1$, is the benchmark against which the numerical approximation is compared.\n\nThe $n$-point Gauss-Legendre quadrature approximation, $Q_n(c)$, of the integral is given by the sum:\n$$\nQ_n(c) = \\sum_{i=1}^{n} w_i f(x_i) = \\sum_{i=1}^{n} w_i \\lvert x_i - c \\rvert\n$$\nwhere $\\{x_i\\}_{i=1}^n$ are the roots of the $n$-th degree Legendre polynomial $P_n(x)$ and $\\{w_i\\}_{i=1}^n$ are the corresponding quadrature weights. The absolute error is then $E_n(c) = \\lvert Q_n(c) - I(c) \\rvert$.\n\nTheoretical considerations for functions with singularities of this type (a jump in the first derivative) suggest an asymptotic convergence rate of $E_n(c) = O(n^{-2})$, so we expect to find $p \\approx 2$. However, the problem asks for an empirical rate, which we must compute from the numerical data. The analysis is to be performed separately for even and odd values of $n$. This distinction is important because the node distributions of Gauss-Legendre quadrature have different symmetry properties for even and odd $n$. Specifically, for odd $n$, $x=0$ is always a node, which is highly relevant for the case $c=0$.\n\nTo estimate the convergence rate $p$, we assume the model $E_n(c) = A n^{-p}$ for some constant $A$. Taking the natural logarithm of this relation yields a linear equation:\n$$\n\\ln(E_n(c)) = \\ln(A) - p \\ln(n)\n$$\nThis equation is of the form $y = b + sx$, where $y = \\ln(E_n(c))$, $x = \\ln(n)$, the intercept is $b = \\ln(A)$, and the slope is $s = -p$. The problem requires us to find the slope $s$ of the best-fit line for the data points $(\\ln(n), \\ln(E_n(c)))$ using the method of least squares. The empirical rate is then given by $p = -s$.\n\nThe computational procedure is as follows:\n1. For each value of $c$ in the test suite $\\{0, 0.1, 0.5773502691896257\\}$, we compute the exact integral $I(c) = c^2+1$.\n2. We iterate through $n \\in \\{2, 3, \\ldots, 80\\}$. In each iteration, we compute the $n$ Gauss-Legendre nodes and weights, calculate the quadrature approximation $Q_n(c)$, and find the error $E_n(c)$.\n3. The pairs $(n, E_n(c))$ are collected and separated into two subsequences based on the parity of $n$.\n4. For each subsequence (even and odd), we perform a linear regression on the log-transformed data $(\\ln(n), \\ln(E_n(c)))$. The specific rule for data filtering is applied: any point with $E_n(c) \\le 10^{-14}$ is excluded from the fit, unless this would leave fewer than $3$ points, in which case all points are used.\n5. The slope $s$ of the linear fit is obtained. The convergence rates are then $p_{\\mathrm{even}}(c) = -s_{\\mathrm{even}}$ and $p_{\\mathrm{odd}}(c) = -s_{\\mathrm{odd}}$.\n6. The resulting six values, $(p_{\\mathrm{even}}(c_1), p_{\\mathrm{odd}}(c_1), \\ldots)$, are reported in the specified format.\n\nThe following program implements this entire procedure.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_rate(n_values, E_values, min_points=3, threshold=1e-14):\n    \"\"\"\n    Estimates the algebraic convergence rate p from E ~ n^(-p).\n\n    This is done by a linear least-squares fit on log-log data.\n    The rate p is the negative of the slope of log(E) vs log(n).\n    \n    Args:\n        n_values (np.ndarray): Array of integer orders n.\n        E_values (np.ndarray): Array of corresponding errors E_n.\n        min_points (int): The minimum number of points required for a filtered fit.\n        threshold (float): The error threshold for filtering.\n    \n    Returns:\n        float: The estimated convergence rate p.\n    \"\"\"\n    # Ensure there are enough points to attempt a fit\n    if len(n_values) < 2:\n        return np.nan\n\n    # Filter out points where the error is at or below the floating-point precision limit.\n    # This prevents these points from corrupting the log-log fit.\n    mask = E_values > threshold\n    \n    if np.sum(mask) < min_points:\n        # If filtering leaves too few points, use all available points as per the rule.\n        x_fit = np.log(n_values)\n        y_fit = np.log(E_values)\n    else:\n        # Use the filtered data for the fit.\n        x_fit = np.log(n_values[mask])\n        y_fit = np.log(E_values[mask])\n\n    # Check again if there are enough points for polyfit after filtering.\n    if len(x_fit) < 2:\n        return np.nan\n\n    # Perform a linear fit (degree 1 polynomial) to the log-log data.\n    # The slope is the first element of the returned coefficients.\n    slope = np.polyfit(x_fit, y_fit, 1)[0]\n    \n    # The convergence rate p is the negative of the slope.\n    return -slope\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem as stated.\n    - Computes exact and approximate integrals.\n    - Calculates errors for n-point Gaussian quadrature.\n    - Estimates convergence rates for even and odd n subsequences.\n    \"\"\"\n    # Test suite of parameter values for c.\n    test_cases = [\n        0.0,\n        0.1,\n        0.5773502691896257,  # This is 1/sqrt(3)\n    ]\n\n    # The range of n for the quadrature rule.\n    n_range = np.arange(2, 81)\n    \n    all_results = []\n    \n    for c in test_cases:\n        # Compute the exact integral I(c) = c^2 + 1.\n        I_c = c**2 + 1.0\n        \n        # Lists to store n and the corresponding errors for even and odd subsequences.\n        n_even, E_even = [], []\n        n_odd, E_odd = [], []\n        \n        # Compute errors for each n in the specified range.\n        for n in n_range:\n            # Get the n-point Gauss-Legendre quadrature nodes and weights.\n            nodes, weights = np.polynomial.legendre.leggauss(n)\n            \n            # Compute the quadrature approximation Q_n(c) for f(x) = |x-c|.\n            Q_n = np.sum(weights * np.abs(nodes - c))\n            \n            # Compute the absolute error.\n            E_n = np.abs(Q_n - I_c)\n            \n            # Separate the results into even and odd subsequences.\n            if n % 2 == 0:\n                n_even.append(n)\n                E_even.append(E_n)\n            else:\n                n_odd.append(n)\n                E_odd.append(E_n)\n        \n        # Estimate the convergence rates for both subsequences.\n        p_even = estimate_rate(np.array(n_even), np.array(E_even))\n        p_odd = estimate_rate(np.array(n_odd), np.array(E_odd))\n        \n        all_results.extend([p_even, p_odd])\n\n    # Print the final results in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "This advanced practice elevates you from a user of quadrature rules to a creator. For integrals of the form $\\int w(x)f(x)dx$, a custom quadrature tailored to the weight function $w(x)$ can be vastly more efficient than a standard method. You will derive and implement your own Gaussian quadrature rule from first principles, revealing the deep connection between numerical integration, orthogonal polynomials, and the eigenvalue problem for an associated Jacobi matrix.",
            "id": "2397730",
            "problem": "You are to construct and test a Gaussian quadrature rule tailored to the nonclassical weight function $w(x) = e^{x}$ on the interval $[-1,1]$. Your task is to derive, implement, and compare an $n$-point Gaussian quadrature for the inner product induced by $w(x)$ with the standard Gauss-Legendre quadrature for the same number of nodes. The derivation must start from the definition of orthogonality with respect to a weighted inner product and the exact moments of the weight. Use only the following foundational bases:\n- The definition of a weighted inner product, $\\langle p,q \\rangle = \\int_{-1}^{1} p(x)\\,q(x)\\,w(x)\\,dx$.\n- The fact that there exists a unique sequence of orthonormal polynomials $\\{\\phi_{k}(x)\\}_{k \\ge 0}$ with respect to this inner product satisfying a three-term recurrence.\n- The existence of a symmetric tridiagonal representation of multiplication by $x$ with respect to this orthonormal basis.\n- The exact moments $m_{k} = \\int_{-1}^{1} x^{k} e^{x}\\,dx$ can be generated by integration by parts.\n\nConstruct the $n$-point Gaussian quadrature for $w(x) = e^{x}$ on $[-1,1]$ by:\n- Deriving the orthonormal polynomials from first principles using the inner product and exact moments. Avoid any pre-tabulated special-function identities.\n- Obtaining the associated symmetric tridiagonal matrix representing multiplication by $x$ in the orthonormal basis.\n- Using its spectral decomposition to obtain nodes and weights.\nYour implementation must compute the exact moments $m_{k}$ for the needed orders using only algebra and integration by parts. Angles in any trigonometric function must be in radians.\n\nComparison target: Standard Gauss-Legendre quadrature (weight $w(x)=1$ on $[-1,1]$) applied directly to the same integrals with the same $n$.\n\nRequired numerical tests (test suite), all integrals over $[-1,1]$:\n- Test A (general smooth integrand): $I_{1} = \\int_{-1}^{1} e^{-x}\\,\\sin(x)\\,dx$. Interpret the weighted method correctly: write $I_{1} = \\int_{-1}^{1} w(x)\\,f(x)\\,dx$ with $f(x) = e^{-2x}\\sin(x)$. Compare the absolute error of the weighted rule to Gauss-Legendre directly on $e^{-x}\\sin(x)$. Use $n=3$. Angles must be in radians. The exact value must be computed analytically, not numerically, and used as the reference.\n- Test B (exactness check): $I_{2} = \\int_{-1}^{1} e^{x}\\,\\big(x^{3} - 0.3\\,x + 0.1\\big)\\,dx$. Using the moments $m_{k}$, compute the exact value by linearity and compare to the weighted Gaussian quadrature with $n=3$. Report the absolute error.\n- Test C (mass conservation edge case): For $n=1$, compute the weighted Gaussian quadrature weights $\\{W_{i}\\}$ and report the absolute difference $\\big|\\sum_{i} W_{i} - \\int_{-1}^{1} e^{x}\\,dx\\big|$.\n\nAngle unit: all trigonometric evaluations are in radians.\n\nImplementation details to respect:\n- The construction of the weighted quadrature must proceed from the weighted inner product and exact moments. Do not use precomputed special polynomials for $w(x)=e^{x}$.\n- For the standard Gauss-Legendre rule, you may use a reliable numerical routine to obtain nodes and weights on $[-1,1]$.\n\nFinal output specification:\n- Your program must produce a single line containing a comma-separated Python-like list with three entries corresponding to Tests A, B, and C, in this exact order:\n  $[r_{A}, r_{B}, r_{C}]$ where\n  $r_{A}$ is a boolean equal to $\\text{True}$ if the weighted rule’s absolute error is strictly smaller than Gauss-Legendre’s absolute error for $I_{1}$, and $\\text{False}$ otherwise;\n  $r_{B}$ is a float equal to the absolute error for $I_{2}$ using the weighted rule;\n  $r_{C}$ is a float equal to the absolute weight-sum difference for $n=1$ in Test C.\n- The two floats $r_{B}$ and $r_{C}$ must be rounded to $12$ significant digits in the printed output.\n- No other text may be printed.\n\nConstraints on scientific realism:\n- Ensure all computations are numerically stable for $n \\le 5$.\n- Provide all trigonometric evaluations in radians.\n\nNote: There are no physical units in this problem. All values are dimensionless.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC]\").",
            "solution": "The problem posed is a well-defined exercise in computational science, specifically in the domain of numerical integration. It requires the construction of a Gaussian quadrature rule for a non-classical weight function $w(x) = e^x$ on the interval $[-1, 1]$. The derivation must be performed from first principles, relying on the theory of orthogonal polynomials and their connection to the eigenvalue problem of a specific symmetric tridiagonal matrix, known as the Jacobi matrix. The validity of the problem is affirmed, as it is scientifically grounded, well-posed, and objective.\n\nThe foundation of Gaussian quadrature lies in the approximation of a weighted integral by a finite sum:\n$$ \\int_{-1}^{1} w(x) f(x) \\,dx \\approx \\sum_{i=1}^{n} W_i f(x_i) $$\nFor a given weight function $w(x)$, an $n$-point rule is uniquely defined by the nodes $\\{x_i\\}$ and weights $\\{W_i\\}$. The rule is exact if $f(x)$ is any polynomial of degree up to $2n-1$. The nodes $\\{x_i\\}_{i=1}^n$ are the roots of the $n$-th degree polynomial $\\phi_n(x)$ from the sequence of polynomials $\\{\\phi_k(x)\\}_{k=0}^\\infty$ that are orthonormal with respect to the inner product $\\langle p, q \\rangle = \\int_{-1}^{1} p(x)q(x)w(x)dx$.\n\nThe procedure is as follows: first, one derives the moments of the weight function. Second, using these moments, the coefficients of the three-term recurrence relation for the orthonormal polynomials are determined. These coefficients form the Jacobi matrix. Third, the spectral decomposition of this matrix yields the quadrature nodes and weights. Finally, the constructed quadrature rule is tested as specified.\n\n**1. Moment Calculation**\n\nThe moments of the weight function $w(x)=e^x$ are defined as $m_k = \\int_{-1}^{1} x^k e^x \\,dx$. These can be calculated via a recurrence relation derived from integration by parts.\nLet $u=x^k$ and $dv=e^x dx$. Then $du = kx^{k-1} dx$ and $v=e^x$.\n$$ m_k = \\int_{-1}^{1} x^k e^x \\,dx = [x^k e^x]_{-1}^{1} - k \\int_{-1}^{1} x^{k-1} e^x \\,dx $$\nThis yields the recurrence relation:\n$$ m_k = (1^k e^1 - (-1)^k e^{-1}) - k m_{k-1} = (e - (-1)^k e^{-1}) - k m_{k-1} $$\nThe base case for $k=0$ is the total mass:\n$$ m_0 = \\int_{-1}^{1} e^x \\,dx = [e^x]_{-1}^{1} = e - e^{-1} $$\nThis recurrence allows for the systematic computation of all necessary moments $m_k$ for $k=0, 1, \\dots, 2n-1$.\n\n**2. Construction of the Jacobi Matrix**\n\nThe sequence of orthonormal polynomials $\\{\\phi_k(x)\\}$ satisfies a three-term recurrence relation:\n$$ x \\phi_k(x) = \\beta_{k-1} \\phi_{k-1}(x) + \\alpha_k \\phi_k(x) + \\beta_k \\phi_{k+1}(x) $$\nwith $\\phi_{-1}(x) = 0$ and $\\|\\phi_k\\|^2 = \\langle \\phi_k, \\phi_k \\rangle = 1$. The coefficients $\\alpha_k$ and $\\beta_k$ form the $n \\times n$ symmetric tridiagonal Jacobi matrix $J_n$:\n$$ J_n = \\begin{pmatrix}\n\\alpha_0 & \\beta_0 & 0 & \\dots & 0 \\\\\n\\beta_0 & \\alpha_1 & \\beta_1 & \\dots & 0 \\\\\n0 & \\beta_1 & \\alpha_2 & \\ddots & \\vdots \\\\\n\\vdots & & \\ddots & \\ddots & \\beta_{n-2} \\\\\n0 & \\dots & \\dots & \\beta_{n-2} & \\alpha_{n-1}\n\\end{pmatrix} $$\nThe coefficients are found using the inner product defined by the moments. An inner product of two polynomials $p(x) = \\sum_{i=0}^d c_i x^i$ and $q(x) = \\sum_{j=0}^d d_j x^j$ is computed as $\\langle p, q \\rangle = \\sum_{i,j} c_i d_j m_{i+j}$.\n\nThe construction proceeds iteratively (a procedure equivalent to the Lanczos algorithm):\n1. Normalize the first polynomial: $\\phi_0(x) = 1 / \\sqrt{\\langle 1, 1 \\rangle} = 1 / \\sqrt{m_0}$.\n2. For $k = 0, 1, \\dots, n-1$:\n   a. Compute the diagonal coefficient: $\\alpha_k = \\langle x\\phi_k, \\phi_k \\rangle$.\n   b. Construct the next un-normalized polynomial: $\\hat{\\phi}_{k+1}(x) = (x - \\alpha_k)\\phi_k(x) - \\beta_{k-1}\\phi_{k-1}(x)$, with $\\beta_{-1}=0$.\n   c. Compute the off-diagonal coefficient: $\\beta_k = \\|\\hat{\\phi}_{k+1}\\| = \\sqrt{\\langle \\hat{\\phi}_{k+1}, \\hat{\\phi}_{k+1} \\rangle}$.\n   d. Normalize to find the next polynomial: $\\phi_{k+1}(x) = \\hat{\\phi}_{k+1}(x) / \\beta_k$.\n\nThis procedure is implemented numerically by representing polynomials as vectors of their coefficients in the monomial basis $\\{1, x, x^2, \\dots\\}$.\n\n**3. Derivation of Nodes and Weights (Golub-Welsch Algorithm)**\n\nThe connection between the Jacobi matrix and the Gaussian quadrature rule is fundamental. The $n$ quadrature nodes $\\{x_i\\}_{i=1}^n$ are precisely the eigenvalues of the $n \\times n$ Jacobi matrix $J_n$. The quadrature weights $\\{W_i\\}_{i=1}^n$ are derived from the first components of the corresponding normalized eigenvectors. If $\\mathbf{v}_i$ is the normalized eigenvector for the eigenvalue $x_i$, then the weight is:\n$$ W_i = m_0 (v_{i,1})^2 $$\nwhere $v_{i,1}$ is the first component of $\\mathbf{v}_i$. The sum of the weights is always $\\sum_{i=1}^n W_i = m_0$, a property that stems from the fact that the eigenvectors form an orthonormal basis.\n\n**4. Execution of Numerical Tests**\n\nThe methodology described above is used to construct the custom quadrature rules for $n=1$ and $n=3$. These are then applied to the specified test cases.\n\n**Test A: Comparison with Gauss-Legendre for $I_1 = \\int_{-1}^{1} e^{-x}\\sin(x)\\,dx$ ($n=3$)**\n\nThe analytical value of the integral is required for error computation. Using integration by parts twice, one finds the antiderivative:\n$$ \\int e^{-x}\\sin(x)\\,dx = -\\frac{1}{2} e^{-x}(\\sin(x) + \\cos(x)) $$\nEvaluating this from $-1$ to $1$ (with angles in radians) gives the exact value:\n$$ I_1 = -\\frac{1}{2} \\left[ e^{-1}(\\sin(1) + \\cos(1)) - e^1(\\sin(-1) + \\cos(-1)) \\right] = -\\frac{1}{2} \\left[ e^{-1}(\\sin(1)+\\cos(1)) - e(-\\sin(1)+\\cos(1)) \\right] $$\nThe custom quadrature is applied to the integral rewritten as $I_1 = \\int_{-1}^1 e^x f(x) dx$, where $f(x) = e^{-2x}\\sin(x)$. The approximation is $\\sum_{i=1}^3 W_i f(x_i)$.\nThe standard Gauss-Legendre quadrature is applied to the original integrand $g(x) = e^{-x}\\sin(x)$. Its approximation is $\\sum_{i=1}^3 w_i^{GL} g(x_i^{GL})$. The absolute errors of both methods are computed and compared. The custom rule is expected to be superior as it exactly accounts for the dominant exponential factor $e^x$ of the full integrand $e^x \\cdot (e^{-2x}\\sin(x))$.\n\n**Test B: Exactness Check for $I_2 = \\int_{-1}^{1} e^{x}(x^3 - 0.3x + 0.1)dx$ ($n=3$)**\n\nThe exact value of $I_2$ is found by linearity of integration:\n$$ I_2 = \\int_{-1}^{1} x^3 e^x dx - 0.3 \\int_{-1}^{1} x e^x dx + 0.1 \\int_{-1}^{1} e^x dx = m_3 - 0.3 m_1 + 0.1 m_0 $$\nThe custom $n=3$ Gaussian quadrature rule is exact for polynomials of degree up to $2n-1 = 5$. The function to which the rule is applied is $f(x) = x^3 - 0.3x + 0.1$, a polynomial of degree $3$. Since $3 \\le 5$, the quadrature must yield the exact result. The absolute error is therefore expected to be zero, limited only by machine floating-point precision.\n\n**Test C: Mass Conservation for $n=1$**\n\nGaussian quadrature must exactly integrate polynomials up to degree $2n-1$. For any $n \\ge 1$, this includes the constant polynomial $f(x)=1$ (degree $0$). The integral is $\\int_{-1}^1 w(x) \\cdot 1 \\,dx = m_0$. The quadrature approximation is $\\sum_{i=1}^n W_i \\cdot 1 = \\sum_{i=1}^n W_i$. Thus, for any $n$, the sum of weights must equal the zeroth moment $m_0$.\nFor the $n=1$ case, this means the single weight $W_1$ must equal $m_0$. The required quantity is $|\\sum_i W_i - \\int_{-1}^1 e^x dx| = |W_1 - m_0|$, which must be zero up to machine precision. This serves as a fundamental sanity check of the weight calculation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Constructs and tests a Gaussian quadrature for w(x)=exp(x) on [-1,1].\n    \"\"\"\n    \n    def compute_moments(k_max):\n        \"\"\"\n        Computes moments m_k = int_{-1 to 1} x^k exp(x) dx for k=0 to k_max.\n        \"\"\"\n        e = np.exp(1.0)\n        e_inv = np.exp(-1.0)\n        \n        m = np.zeros(k_max + 1)\n        m[0] = e - e_inv\n        \n        for k in range(1, k_max + 1):\n            term1 = e - ((-1)**k) * e_inv\n            m[k] = term1 - k * m[k-1]\n            \n        return m\n\n    def inner_product(p1_coeffs, p2_coeffs, moments):\n        \"\"\"\n        Computes the inner product <p1, p2> using moments.\n        Polynomials are represented by their coefficient arrays.\n        \"\"\"\n        res = 0.0\n        for i, c1 in enumerate(p1_coeffs):\n            for j, c2 in enumerate(p2_coeffs):\n                res += c1 * c2 * moments[i + j]\n        return res\n\n    def get_custom_quadrature(n, moments):\n        \"\"\"\n        Generates nodes and weights for the custom Gaussian quadrature for w(x)=e^x.\n        \"\"\"\n        if n == 0:\n            return np.array([]), np.array([])\n            \n        m0 = moments[0]\n        \n        # Iteratively build the Jacobi matrix using the Stieltjes procedure\n        alphas = np.zeros(n)\n        betas = np.zeros(n - 1)\n        \n        # Store orthonormal polynomial coefficients\n        phi_coeffs = []\n        \n        # k=0\n        phi_0_coeffs = np.array([1.0 / np.sqrt(m0)])\n        phi_coeffs.append(phi_0_coeffs)\n        \n        x_phi_0 = np.array([0.0, 1.0]) * phi_0_coeffs[0] # Coeffs of x * phi_0\n        alphas[0] = inner_product(x_phi_0, phi_0_coeffs, moments)\n        \n        if n > 1:\n            # Build hat_phi_1 = (x - alpha_0) * phi_0\n            hat_phi_1_coeffs = np.convolve(np.array([-alphas[0], 1.0]), phi_0_coeffs)\n            beta_0_sq = inner_product(hat_phi_1_coeffs, hat_phi_1_coeffs, moments)\n            betas[0] = np.sqrt(beta_0_sq)\n            phi_1_coeffs = hat_phi_1_coeffs / betas[0]\n            phi_coeffs.append(phi_1_coeffs)\n\n        # k > 0\n        for k in range(1, n):\n            # x*phi_k\n            x_phi_k_coeffs = np.convolve(np.array([0.0, 1.0]), phi_coeffs[k])\n            alphas[k] = inner_product(x_phi_k_coeffs, phi_coeffs[k], moments)\n\n            if k < n - 1:\n                # hat_phi_{k+1} = (x - alpha_k)*phi_k - beta_{k-1}*phi_{k-1}\n                term1 = np.convolve(np.array([-alphas[k], 1.0]), phi_coeffs[k])\n                term2 = -betas[k-1] * phi_coeffs[k-1]\n                # Pad term2 to match degree of term1\n                padded_term2 = np.pad(term2, (0, len(term1) - len(term2)), 'constant')\n                hat_phi_k_plus_1_coeffs = term1 + padded_term2\n                \n                beta_k_sq = inner_product(hat_phi_k_plus_1_coeffs, hat_phi_k_plus_1_coeffs, moments)\n                betas[k] = np.sqrt(beta_k_sq)\n                \n                phi_k_plus_1_coeffs = hat_phi_k_plus_1_coeffs / betas[k]\n                phi_coeffs.append(phi_k_plus_1_coeffs)\n\n        # Solve eigenvalue problem for the Jacobi matrix\n        jacobi_matrix = np.diag(alphas) + np.diag(betas, k=1) + np.diag(betas, k=-1)\n        nodes, eigenvectors = eigh(jacobi_matrix)\n        \n        # Weights W_i = m_0 * (v_{i,1})^2\n        weights = m0 * (eigenvectors[0, :])**2\n\n        return nodes, weights\n\n    # ==========================\n    # --- Execute Test Cases ---\n    # ==========================\n\n    results = []\n\n    # --- Test A: Comparison for I_1 = int e^{-x}sin(x) dx with n=3 ---\n    n_A = 3\n    moments_A = compute_moments(2 * n_A - 1)\n    \n    # Exact value of I_1\n    e = np.exp(1.0)\n    sin1 = np.sin(1.0)\n    cos1 = np.cos(1.0)\n    I1_exact = -0.5 * ( (1/e) * (sin1 + cos1) - e * (-sin1 + cos1) )\n\n    # Custom weighted quadrature\n    nodes_custom, weights_custom = get_custom_quadrature(n_A, moments_A)\n    f = lambda x: np.exp(-2*x) * np.sin(x)\n    I1_custom = np.sum(weights_custom * f(nodes_custom))\n    error_custom = np.abs(I1_custom - I1_exact)\n\n    # Standard Gauss-Legendre quadrature\n    nodes_gl, weights_gl = np.polynomial.legendre.leggauss(n_A)\n    g = lambda x: np.exp(-x) * np.sin(x)\n    I1_gl = np.sum(weights_gl * g(nodes_gl))\n    error_gl = np.abs(I1_gl - I1_exact)\n\n    r_A = error_custom < error_gl\n    results.append(r_A)\n\n    # --- Test B: Exactness check for I_2 = int e^x(x^3 - 0.3x + 0.1) dx with n=3 ---\n    n_B = 3\n    moments_B = compute_moments(2 * n_B - 1) # Same as for A\n    m0, m1, m2, m3 = moments_B[0], moments_B[1], moments_B[2], moments_B[3]\n\n    # Exact value of I_2 from moments\n    I2_exact = m3 - 0.3 * m1 + 0.1 * m0\n\n    # Custom weighted quadrature\n    nodes_B, weights_B = get_custom_quadrature(n_B, moments_B) # Same as for A\n    f_poly = lambda x: x**3 - 0.3*x + 0.1\n    I2_custom = np.sum(weights_B * f_poly(nodes_B))\n    \n    r_B = np.abs(I2_custom - I2_exact)\n    results.append(r_B)\n    \n    # --- Test C: Mass conservation for n=1 ---\n    n_C = 1\n    moments_C = compute_moments(2 * n_C - 1)\n    m0_C = moments_C[0]\n\n    # Custom weighted quadrature\n    nodes_C, weights_C = get_custom_quadrature(n_C, moments_C)\n    \n    r_C = np.abs(np.sum(weights_C) - m0_C)\n    results.append(r_C)\n\n    # Format output as specified\n    r_A_str = str(results[0])\n    r_B_str = \"{:.12g}\".format(results[1])\n    r_C_str = \"{:.12g}\".format(results[2])\n    \n    print(f\"[{r_A_str},{r_B_str},{r_C_str}]\")\n\nsolve()\n\n```"
        }
    ]
}