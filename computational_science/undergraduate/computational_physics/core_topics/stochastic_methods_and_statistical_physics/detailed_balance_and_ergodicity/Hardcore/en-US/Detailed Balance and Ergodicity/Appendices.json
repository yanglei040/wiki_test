{
    "hands_on_practices": [
        {
            "introduction": "The principle of detailed balance provides a straightforward path to constructing Markov chains that sample a desired stationary distribution. It is a sufficient, but not necessary, condition. This exercise challenges you to build a system that satisfies the weaker global balance condition but deliberately violates detailed balance. By analyzing this simple three-state system, you will gain a deeper understanding of the physical meaning of this violation: the emergence of a non-equilibrium steady state with persistent probability currents .",
            "id": "2385718",
            "problem": "In computational physics, Markov Chain Monte Carlo relies on the interplay between detailed balance and ergodicity to ensure correct sampling. Consider a discrete-time Markov chain on a cycle of $3$ states $\\{A,B,C\\}$, where transitions occur only between nearest neighbors on the cycle and to the same state (self-loops). You are to construct a transition mechanism that is ergodic and satisfies global balance but not detailed balance.\n\nLet the transition probabilities be parametrized by two real numbers $r$ and $s$ with $0 < s < r$ and $r + s < 1$, so that from each state the transition probabilities are:\n- from $A$: to $B$ with probability $r$, to $C$ with probability $s$, to $A$ with probability $1 - r - s$;\n- from $B$: to $C$ with probability $r$, to $A$ with probability $s$, to $B$ with probability $1 - r - s$;\n- from $C$: to $A$ with probability $r$, to $B$ with probability $s$, to $C$ with probability $1 - r - s$.\n\nThis defines a $3 \\times 3$ transition matrix $P$ with entries $P_{ij}$, where $i,j \\in \\{A,B,C\\}$. Use only the following foundational ingredients: the definition of a discrete-time Markov chain, the definition of irreducibility and aperiodicity (together called ergodicity), the stationarity condition (global balance) $\\boldsymbol{\\pi}^{\\top} P = \\boldsymbol{\\pi}^{\\top}$ for a stationary distribution $\\boldsymbol{\\pi}$, and the detailed balance condition $\\pi_i P_{ij} = \\pi_j P_{ji}$ for all pairs $i,j$.\n\nTasks:\n1. Prove that for $0 < s < r$ and $r + s < 1$, the Markov chain is ergodic (irreducible and aperiodic).\n2. Determine a stationary distribution $\\boldsymbol{\\pi}$ and verify that it satisfies global balance.\n3. Show that detailed balance does not hold unless $r = s$, and hence for $0 < s < r$ detailed balance is violated.\n4. Define the steady-state net probability current from $A$ to $B$ as $J_{A \\to B} = \\pi_A P_{AB} - \\pi_B P_{BA}$ and compute it in closed form as a function of $r$ and $s$.\n\nYour final answer must be the analytic expression for $J_{A \\to B}$ in terms of $r$ and $s$. No units are required. Do not round; provide an exact expression.",
            "solution": "The problem statement will first be subjected to a rigorous validation procedure.\n\n**Step 1: Extract Givens**\n- **System**: A discrete-time Markov chain on a state space $\\mathcal{S} = \\{A, B, C\\}$.\n- **Topology**: The states are arranged in a cycle.\n- **Parameters**: Two real numbers $r$ and $s$ satisfying the constraints $0 < s < r$ and $r + s < 1$.\n- **Transition Probabilities**:\n  - From state $A$: $P_{AB} = r$, $P_{AC} = s$, $P_{AA} = 1 - r - s$.\n  - From state $B$: $P_{BC} = r$, $P_{BA} = s$, $P_{BB} = 1 - r - s$.\n  - From state $C$: $P_{CA} = r$, $P_{CB} = s$, $P_{CC} = 1 - r - s$.\n- **Definitions**:\n  - **Ergodicity**: The properties of irreducibility and aperiodicity combined.\n  - **Global Balance (Stationarity)**: $\\boldsymbol{\\pi}^{\\top} P = \\boldsymbol{\\pi}^{\\top}$ for a stationary distribution $\\boldsymbol{\\pi}$.\n  - **Detailed Balance**: $\\pi_i P_{ij} = \\pi_j P_{ji}$ for all pairs of states $i, j \\in \\mathcal{S}$.\n- **Tasks**:\n  1. Prove the chain is ergodic.\n  2. Find the stationary distribution $\\boldsymbol{\\pi}$ and verify it satisfies global balance.\n  3. Show detailed balance is not satisfied under the given constraints.\n  4. Compute the steady-state net probability current $J_{A \\to B} = \\pi_A P_{AB} - \\pi_B P_{BA}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is analyzed against the required criteria.\n- **Scientifically Grounded**: The problem is based on the standard mathematical theory of Markov chains, a fundamental topic in statistical mechanics and computational physics. All definitions and concepts are standard and correct.\n- **Well-Posed**: The problem is well-defined. The transition probabilities are properly constrained by $0 < s < r$ and $r + s < 1$, ensuring all probabilities are positive and sum to $1$ for each state. The tasks are specific mathematical derivations that lead to a unique solution.\n- **Objective**: The problem is stated using precise mathematical language, free from any subjectivity or ambiguity.\n\nThe problem successfully passes all validation checks. It is a standard, formalizable problem in theoretical physics.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A full solution will be provided.\n\n**Solution Derivation**\n\nThe transition matrix $P$ for the states ordered as $(A, B, C)$ is given by:\n$$\nP = \\begin{pmatrix}\n1 - r - s & r & s \\\\\ns & 1 - r - s & r \\\\\nr & s & 1 - r - s\n\\end{pmatrix}\n$$\n\n**Task 1: Ergodicity**\nA finite-state Markov chain is ergodic if it is both irreducible and aperiodic.\n\n- **Irreducibility**: A chain is irreducible if it is possible to move from any state to any other state in a finite number of steps. The transitions can be visualized as a directed graph on the vertices $\\{A, B, C\\}$. The given probabilities are $P_{AB}=r$, $P_{BA}=s$, $P_{BC}=r$, $P_{CB}=s$, $P_{CA}=r$, $P_{AC}=s$. Since $r > 0$ and $s > 0$, all these transition probabilities are non-zero. The graph is strongly connected. For instance, one can traverse the cycle $A \\to B \\to C \\to A$. Therefore, every state is reachable from every other state, and the chain is irreducible.\n\n- **Aperiodicity**: The period of a state $i$ is the greatest common divisor (GCD) of all integers $n > 0$ such that $P_{ii}^{(n)} > 0$. A chain is aperiodic if all its states have a period of $1$. The condition $r+s  1$ implies that the self-loop probabilities $P_{AA} = P_{BB} = P_{CC} = 1 - r - s$ are all strictly greater than $0$. The existence of a self-loop (a return to state $i$ in $1$ step) for any state $i$ in an irreducible chain ensures that the period of that state is $1$. Since $P_{AA} > 0$, the set of possible return times for state $A$ includes $n=1$. The GCD of any set of integers including $1$ is $1$. Thus, state $A$ is aperiodic. As the chain is irreducible, aperiodicity of one state implies aperiodicity of all states.\n\nSince the chain is both irreducible and aperiodic, it is ergodic. This guarantees the existence of a unique stationary distribution.\n\n**Task 2: Stationary Distribution and Global Balance**\nThe stationary distribution $\\boldsymbol{\\pi} = (\\pi_A, \\pi_B, \\pi_C)^{\\top}$ must satisfy the global balance equation $\\boldsymbol{\\pi}^{\\top} P = \\boldsymbol{\\pi}^{\\top}$, subject to the normalization $\\pi_A + \\pi_B + \\pi_C = 1$. This corresponds to the system of linear equations:\n$$\n\\pi_A = \\pi_A(1 - r - s) + \\pi_B s + \\pi_C r \\\\\n\\pi_B = \\pi_A r + \\pi_B(1 - r - s) + \\pi_C s \\\\\n\\pi_C = \\pi_A s + \\pi_B r + \\pi_C(1 - r - s)\n$$\nDue to the cyclic symmetry of the transition probabilities, we can hypothesize a symmetric solution $\\pi_A = \\pi_B = \\pi_C = c$. Substituting into the normalization condition gives $3c = 1$, so $c = 1/3$.\nLet us verify if $\\pi_A = \\pi_B = \\pi_C = 1/3$ satisfies the first balance equation:\n$$\n\\frac{1}{3} \\overset{?}{=} \\frac{1}{3}(1 - r - s) + \\frac{1}{3}s + \\frac{1}{3}r \\\\\n\\frac{1}{3} = \\frac{1}{3} - \\frac{r}{3} - \\frac{s}{3} + \\frac{s}{3} + \\frac{r}{3} \\\\\n\\frac{1}{3} = \\frac{1}{3}\n$$\nThe equation holds. Due to symmetry, the other two equations are also satisfied. Therefore, the unique stationary distribution is $\\boldsymbol{\\pi} = (1/3, 1/3, 1/3)^{\\top}$. The act of finding this distribution and verifying it against the equations constitutes the verification of global balance.\n\n**Task 3: Violation of Detailed Balance**\nThe detailed balance condition is $\\pi_i P_{ij} = \\pi_j P_{ji}$ for all pairs $i,j$. Let us check this for the pair of states $(A, B)$.\n$$\n\\pi_A P_{AB} = \\pi_B P_{BA}\n$$\nUsing the stationary distribution and transition probabilities:\n$$\n\\frac{1}{3} \\cdot r = \\frac{1}{3} \\cdot s\n$$\nThis equality simplifies to $r = s$. However, the problem specifies the condition $0  s  r$, which explicitly means $r \\neq s$. Thus, the detailed balance condition is violated for the pair $(A,B)$.\n$$\n\\pi_A P_{AB} > \\pi_B P_{BA}\n$$\nA similar analysis for the pairs $(B,C)$ and $(C,A)$ also shows a violation of detailed balance unless $r=s$. Specifically, $\\pi_B P_{BC} = (1/3)r \\neq (1/3)s = \\pi_C P_{CB}$, and $\\pi_C P_{CA} = (1/3)r \\neq (1/3)s = \\pi_A P_{AC}$. Therefore, detailed balance does not hold for this system.\n\n**Task 4: Steady-State Net Probability Current**\nThe steady-state net probability current from state $A$ to state $B$ is defined as $J_{A \\to B} = \\pi_A P_{AB} - \\pi_B P_{BA}$. We substitute the known values:\n- $\\pi_A = 1/3$\n- $\\pi_B = 1/3$\n- $P_{AB} = r$\n- $P_{BA} = s$\n\nThe calculation is as follows:\n$$\nJ_{A \\to B} = \\left(\\frac{1}{3}\\right) r - \\left(\\frac{1}{3}\\right) s = \\frac{1}{3}(r - s)\n$$\nSince $r > s$, this current is positive, indicating a net flow of probability in the direction $A \\to B$. This non-zero current is a direct consequence of the violation of detailed balance. The system is in a non-equilibrium steady state with a persistent probability circulation $A \\to B \\to C \\to A$.",
            "answer": "$$\n\\boxed{\\frac{1}{3}(r-s)}\n$$"
        },
        {
            "introduction": "The Metropolis-Hastings algorithm is a cornerstone of computational physics, providing a universal recipe for sampling from complex probability distributions. Its power lies in a carefully crafted acceptance probability that enforces detailed balance. This problem presents a common scenario where an incorrect acceptance rule is implemented. By deriving the actual stationary distribution that this flawed algorithm converges to, you will see firsthand why the specific form of the Metropolis-Hastings criterion is essential for unbiased sampling .",
            "id": "2385732",
            "problem": "Consider a Markov chain constructed to sample from a discrete target distribution on the two-state space $\\{0,1\\}$ with target probabilities $\\pi(0)=p$ and $\\pi(1)=1-p$, where $0p1$. The proposal kernel is given by\n$$\nq(1 \\mid 0)=a,\\quad q(0 \\mid 1)=b,\\quad q(0 \\mid 0)=1-a,\\quad q(1 \\mid 1)=1-b,\n$$\nwith $0a1$ and $0b1$. However, the acceptance probability used is incorrectly specified as\n$$\nA(x' \\mid x)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right),\n$$\ninstead of the correct Metropolis-Hastings acceptance that includes proposal asymmetry. The resulting transition kernel implements a proposal according to $q(\\cdot \\mid x)$ followed by acceptance with the above $A(\\cdot \\mid x)$, and otherwise remains at the current state.\n\nAssume the chain is ergodic. Determine, in closed form, the stationary probability $\\mu(0)$ of state $0$ for this incorrectly implemented algorithm as an analytic expression in terms of $p$, $a$, and $b$. Express your final answer as a single closed-form expression. No rounding is required, and no units are involved.",
            "solution": "The problem as stated is subjected to validation.\n\nStep 1: Extract Givens\n- State space: $\\{0, 1\\}$.\n- Target distribution: $\\pi(0) = p$ and $\\pi(1) = 1-p$, where $0  p  1$.\n- Proposal kernel $q(x'|x)$: $q(1|0) = a$, $q(0|1) = b$, $q(0|0) = 1-a$, $q(1|1) = 1-b$, with $0  a  1$ and $0  b  1$.\n- Acceptance probability: $A(x'|x) = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x)}\\right)$.\n- Transition process: A proposal is made via $q(\\cdot|x)$, which is then accepted with probability $A(\\cdot|x)$. Otherwise, the state remains unchanged.\n- Assumption: The resulting Markov chain is ergodic.\n- Objective: Find the stationary probability $\\mu(0)$ in terms of $p$, $a$, and $b$.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, rooted in the theory of Markov chain Monte Carlo methods, a fundamental topic in computational physics and statistics. It describes a well-defined mathematical object: a finite-state Markov chain. The components (state space, proposal kernel, acceptance probability) are explicitly defined. The assumption of ergodicity is key, as it guarantees the existence and uniqueness of a stationary distribution. The question is objective and well-posed, asking for a specific quantity, $\\mu(0)$, derivable from the given parameters. The setup, while describing an incorrectly programmed algorithm (using the Metropolis acceptance for a potentially asymmetric proposal), is a valid and instructive scenario for analysis. No scientific or logical flaws are present.\n\nStep 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe stationary distribution $\\mu$ of a Markov chain is defined by the property that it is invariant under the evolution of the chain. This is expressed by the global balance equation:\n$$\n\\sum_{x} \\mu(x) T(x' | x) = \\mu(x')\n$$\nwhere $T(x'|x)$ is the transition probability from state $x$ to state $x'$. For a discrete two-state system, $\\{0, 1\\}$, this system of equations reduces to a single independent condition: the probability flux out of state $0$ must equal the probability flux into state $0$ from state $1$. This is expressed as:\n$$\n\\mu(0) T(1 | 0) = \\mu(1) T(0 | 1)\n$$\nHere, $\\mu(1) = 1 - \\mu(0)$ due to the normalization of probabilities. The transition probabilities $T(x'|x)$ for $x' \\neq x$ are given by the product of the proposal probability $q(x'|x)$ and the acceptance probability $A(x'|x)$.\n\nFirst, we construct the off-diagonal transition probabilities.\nThe transition from state $x=0$ to $x'=1$ has the probability:\n$$\nT(1 | 0) = q(1 | 0) A(1 | 0)\n$$\nUsing the given definitions:\n$q(1 | 0) = a$\n$A(1 | 0) = \\min\\left(1, \\frac{\\pi(1)}{\\pi(0)}\\right) = \\min\\left(1, \\frac{1-p}{p}\\right)$\nTherefore,\n$$\nT(1 | 0) = a \\min\\left(1, \\frac{1-p}{p}\\right)\n$$\nSimilarly, the transition from state $x=1$ to $x'=0$ has the probability:\n$$\nT(0 | 1) = q(0 | 1) A(0 | 1)\n$$\nUsing the given definitions:\n$q(0 | 1) = b$\n$A(0 | 1) = \\min\\left(1, \\frac{\\pi(0)}{\\pi(1)}\\right) = \\min\\left(1, \\frac{p}{1-p}\\right)$\nTherefore,\n$$\nT(0 | 1) = b \\min\\left(1, \\frac{p}{1-p}\\right)\n$$\nNow, we substitute these expressions into the balance equation:\n$$\n\\mu(0) \\left[a \\min\\left(1, \\frac{1-p}{p}\\right)\\right] = \\mu(1) \\left[b \\min\\left(1, \\frac{p}{1-p}\\right)\\right]\n$$\nUsing $\\mu(1) = 1 - \\mu(0)$, we have:\n$$\n\\mu(0) a \\min\\left(1, \\frac{1-p}{p}\\right) = (1 - \\mu(0)) b \\min\\left(1, \\frac{p}{1-p}\\right)\n$$\nWe solve this equation for $\\mu(0)$:\n$$\n\\mu(0) \\left[ a \\min\\left(1, \\frac{1-p}{p}\\right) + b \\min\\left(1, \\frac{p}{1-p}\\right) \\right] = b \\min\\left(1, \\frac{p}{1-p}\\right)\n$$\n$$\n\\mu(0) = \\frac{b \\min\\left(1, \\frac{p}{1-p}\\right)}{a \\min\\left(1, \\frac{1-p}{p}\\right) + b \\min\\left(1, \\frac{p}{1-p}\\right)}\n$$\nTo simplify this expression without case analysis, let $z = \\frac{p}{1-p}$. Then $\\frac{1-p}{p} = \\frac{1}{z}$. The expression becomes:\n$$\n\\mu(0) = \\frac{b \\min(1, z)}{a \\min(1, 1/z) + b \\min(1, z)}\n$$\nWe can divide the numerator and the denominator by $\\min(1, z)$ (which is non-zero since $0  p  1$, so $z  0$):\n$$\n\\mu(0) = \\frac{b}{a \\frac{\\min(1, 1/z)}{\\min(1, z)} + b}\n$$\nConsider the ratio $\\frac{\\min(1, 1/z)}{\\min(1, z)}$ for any $z  0$.\n- If $0  z \\leq 1$, then $1/z \\geq 1$. The ratio is $\\frac{1}{z}$.\n- If $z  1$, then $0  1/z  1$. The ratio is $\\frac{1/z}{1} = \\frac{1}{z}$.\nIn both cases, the ratio is equal to $1/z$.\nSubstituting back $1/z = \\frac{1-p}{p}$, we find:\n$$\n\\frac{\\min(1, 1/z)}{\\min(1, z)} = \\frac{1-p}{p}\n$$\nNow, we substitute this result back into the expression for $\\mu(0)$:\n$$\n\\mu(0) = \\frac{b}{a \\left(\\frac{1-p}{p}\\right) + b}\n$$\nTo eliminate the compound fraction, we multiply the numerator and denominator by $p$:\n$$\n\\mu(0) = \\frac{bp}{a \\left(\\frac{1-p}{p}\\right)p + bp} = \\frac{bp}{a(1-p) + bp}\n$$\nThis is the final expression for the stationary probability of being in state $0$. This result demonstrates that the stationary distribution $\\mu$ of the incorrectly implemented chain does not, in general, equal the target distribution $\\pi$. For them to be equal, we would need $\\mu(0)=p$, which implies $\\frac{b}{a(1-p)+bp} = 1$, or $b = a(1-p)+bp$. This simplifies to $b(1-p) = a(1-p)$, which requires $a=b$. This is the condition for the proposal kernel to be symmetric, in which case the Metropolis acceptance probability is correct and yields the Metropolis algorithm. For an asymmetric proposal ($a \\neq b$), the stationary distribution $\\mu$ deviates from the target $\\pi$.",
            "answer": "$$\\boxed{\\frac{bp}{a(1-p) + bp}}$$"
        },
        {
            "introduction": "The power of Markov Chain Monte Carlo extends far beyond sampling physical systems; it is a versatile tool for combinatorial optimization. This practice demonstrates how to frame a discrete logic puzzle as a problem in statistical mechanics. You will define an \"energy\" function based on the number of violated constraints and use the Metropolis algorithm to search for the ground stateâ€”the puzzle's solution. This exercise will solidify your understanding of how to design an ergodic move set and apply MCMC to navigate a complex, high-dimensional search space .",
            "id": "2385680",
            "problem": "Design and implement a program that uses Markov Chain Monte Carlo (MCMC) to search the space of assignments for small, structured logic puzzles. The puzzles consist of $N$ positions (indexed $0,1,\\dots,N-1$) and $K$ categorical attributes (for example, color, pet, drink). Each category has exactly $N$ distinct values, and a valid assignment is a bijection assigning one value from each category to each position, so that within a category no two positions share the same value. Constraints relate positions of values across categories (for example, equality, adjacency, ordering). Define an energy function $E(s)$ on a state $s$ as the total number of violated constraints in $s$. The target stationary distribution for the chain at temperature $T$ is the Boltzmann distribution $\\pi_T(s) \\propto \\exp(-E(s)/T)$.\n\nYour program must:\n- Represent states as $K$ independent permutations over $N$ positions, one permutation per category.\n- Use a proposal mechanism that is symmetric: at each step choose a category uniformly at random from the $K$ categories, then choose two distinct positions uniformly at random and propose swapping the values of that category at those two positions.\n- Use an acceptance rule that ensures detailed balance with respect to $\\pi_T(s)$ for any fixed $T0$.\n- Argue and implement a move set that is ergodic on the state space (connected and aperiodic).\n- Run the MCMC for a fixed number of steps from several random restarts with a prescribed random seed sequence, and return the minimum energy observed over the entire run for each test case.\n\nDefinitions to use:\n- Let $p_{A,v}$ denote the position of value $v$ in category $A$ within the current state. Each constraint contributes $1$ to $E(s)$ if it is violated and $0$ otherwise. Allowed primitive constraint types are:\n    - Equality across categories: $p_{A,v} = p_{B,w}$.\n    - Inequality across categories: $p_{A,v} \\neq p_{B,w}$.\n    - Fixed position: $p_{A,v} = \\ell$ for a given integer $\\ell \\in \\{0,\\dots,N-1\\}$.\n    - Adjacency: $|p_{A,v} - p_{B,w}| = 1$.\n    - Immediate-left: $p_{A,v} + 1 = p_{B,w}$.\n    - Strict-right-of: $p_{A,v}  p_{B,w}$.\n\nImplementation requirements:\n- Use a constant temperature $T$ (no annealing).\n- The proposal distribution must be symmetric so that detailed balance can be satisfied using only the energy difference and temperature.\n- Start each restart from an independent random assignment drawn uniformly over permutations within each category, using the specified seed offset.\n\nTest suite. Implement exactly the following three puzzles, MCMC parameters, and seeds. For each puzzle, output the minimum energy $E_{\\min}$ observed over all steps and restarts.\n\nPuzzle A (happy path, $N=4$):\n- Categories ($K=3$), each with $N=4$ values:\n    - color: [Yellow, Blue, Red, Green]\n    - pet: [Cat, Dog, Fish, Bird]\n    - drink: [Coffee, Tea, Milk, Water]\n- Constraints (each is one clause contributing $0$ if satisfied and $1$ if violated):\n    - Immediate-left: $p_{\\text{color},\\text{Red}} + 1 = p_{\\text{color},\\text{Green}}$.\n    - Equality: $p_{\\text{drink},\\text{Tea}} = p_{\\text{color},\\text{Blue}}$.\n    - Adjacency: $|p_{\\text{pet},\\text{Dog}} - p_{\\text{color},\\text{Yellow}}| = 1$.\n    - Fixed position: $p_{\\text{drink},\\text{Milk}} = 2$.\n    - Fixed position: $p_{\\text{pet},\\text{Cat}} = 0$.\n    - Inequality: $p_{\\text{drink},\\text{Water}} \\neq p_{\\text{color},\\text{Yellow}}$.\n    - Strict-right-of: $p_{\\text{pet},\\text{Bird}}  p_{\\text{color},\\text{Red}}$.\n    - Inequality: $p_{\\text{pet},\\text{Fish}} \\neq p_{\\text{color},\\text{Green}}$.\n    - Equality: $p_{\\text{drink},\\text{Coffee}} = p_{\\text{color},\\text{Yellow}}$.\n\nPuzzle B (small, $N=3$):\n- Categories ($K=3$), each with $N=3$ values:\n    - color: [Red, Green, Blue]\n    - pet: [Dog, Cat, Fish]\n    - drink: [Tea, Milk, Coffee]\n- Constraints:\n    - Equality: $p_{\\text{color},\\text{Red}} = p_{\\text{drink},\\text{Tea}}$.\n    - Fixed position: $p_{\\text{pet},\\text{Cat}} = 1$.\n    - Strict-right-of: $p_{\\text{color},\\text{Blue}}  p_{\\text{color},\\text{Green}}$.\n    - Inequality: $p_{\\text{pet},\\text{Fish}} \\neq p_{\\text{color},\\text{Red}}$.\n    - Adjacency: $|p_{\\text{drink},\\text{Milk}} - p_{\\text{pet},\\text{Dog}}| = 1$.\n    - Equality: $p_{\\text{drink},\\text{Coffee}} = p_{\\text{color},\\text{Blue}}$.\n\nPuzzle C (unsatisfiable by construction, $N=3$):\n- Categories ($K=3$), each with $N=3$ values:\n    - color: [Red, Green, Blue]\n    - pet: [Dog, Cat, Fish]\n    - drink: [Tea, Milk, Coffee]\n- Constraints:\n    - Equality: $p_{\\text{drink},\\text{Tea}} = p_{\\text{color},\\text{Red}}$.\n    - Equality: $p_{\\text{drink},\\text{Coffee}} = p_{\\text{color},\\text{Red}}$.\n    - Fixed position: $p_{\\text{pet},\\text{Dog}} = 0$.\n    - Fixed position: $p_{\\text{color},\\text{Blue}} = 2$.\n    - Adjacency: $|p_{\\text{drink},\\text{Milk}} - p_{\\text{pet},\\text{Cat}}| = 1$.\n    - Strict-right-of: $p_{\\text{pet},\\text{Fish}}  p_{\\text{color},\\text{Green}}$.\n\nMCMC parameters and seeds for all puzzles:\n- Temperature: $T = 0.7$.\n- Steps per restart: $S = 30000$.\n- Number of restarts: $R = 8$.\n- Base random seed: Puzzle A uses seed $20231105$, Puzzle B uses seed $20231106$, Puzzle C uses seed $20231107$. Each restart $r \\in \\{0,\\dots,R-1\\}$ must use seed $(\\text{base seed} + r)$.\n\nRequired output:\n- Your program should produce a single line containing the results as a comma-separated list enclosed in square brackets. The $i$-th entry must be the minimum energy $E_{\\min}$ found for the $i$-th puzzle in the test suite. For this test suite, the required output format is exactly \"[x,y,z]\" where $x$, $y$, and $z$ are integers.\n\nScientific and algorithmic requirements:\n- Start from the definition of the Boltzmann stationary distribution $\\pi_T(s) \\propto \\exp(-E(s)/T)$.\n- Ensure the acceptance rule satisfies detailed balance with respect to $\\pi_T$ for any fixed $T$.\n- Use a symmetric proposal so that the proposal probabilities cancel in the detailed balance condition.\n- Explain why the move set is ergodic over the space of states (product of symmetric groups), and why the chain is aperiodic (nonzero self-transition probability due to possible rejections).\n\nThere are no physical units, angles, or percentages in this problem. The final output must be integers as specified above, in the exact format.",
            "solution": "The problem presented is a valid and well-posed application of the Markov Chain Monte Carlo (MCMC) method to a combinatorial optimization problem, specifically the satisfaction of constraints in logic puzzles. The problem is scientifically grounded in the principles of statistical mechanics, using an energy function and the Boltzmann distribution, which are standard components of algorithms like simulated annealing. All parameters, state representations, and objectives are specified with sufficient precision and are internally consistent. The problem is solvable as stated.\n\nThe solution to this problem requires designing an MCMC simulation that samples from a state space of puzzle assignments, with the goal of finding an assignment that minimizes an energy function $E(s)$. The energy is defined as the number of violated logical constraints. The target stationary distribution for the Markov chain is the Boltzmann distribution, $\\pi_T(s) \\propto \\exp(-E(s)/T)$, where $T$ is a constant temperature. This distribution favors states with lower energy.\n\n**1. State Representation and Energy Function**\n\nA state $s$ of the system corresponds to a complete assignment of values to positions for all categories. The puzzle involves $N$ positions, indexed $0, \\dots, N-1$, and $K$ categories. For each category, there are $N$ distinct values. A valid assignment requires that for each category, the $N$ values are assigned to the $N$ positions in a one-to-one correspondence, forming a permutation.\n\nThe state space $\\mathcal{S}$ is therefore the product of $K$ symmetric groups, $\\mathcal{S} = (S_N)^K$, where $S_N$ is the group of permutations of $N$ elements. The size of the state space is $(N!)^K$.\n\nFor computational purposes, the state $s$ is represented by a set of lookup tables. The primary representation is a $K \\times N$ matrix, `pos_to_val`, where `pos_to_val[k][p]` holds the value of category $k$ at position $p$. To efficiently evaluate constraints, we also maintain a reverse lookup table, `val_to_pos`, a $K \\times N$ matrix where `val_to_pos[k][v]` holds the position of value $v$ in category $k$. Let $p_{k,v}$ denote `val_to_pos[k][v]`.\n\nThe energy function $E(s)$ is the total count of violated constraints. Each constraint is a logical proposition. If the proposition is false for a given state $s$, it contributes $1$ to the energy; otherwise, it contributes $0$. For example, a constraint $p_{A,v} = p_{B,w}$ is violated if `val_to_pos[A][v]` $\\ne$ `val_to_pos[B][w]`.\n\n**2. Metropolis-Hastings Algorithm**\n\nTo find low-energy states, we use the Metropolis-Hastings algorithm, a specific type of MCMC. This algorithm generates a sequence of states, $s_0, s_1, s_2, \\dots$, such that the distribution of these states converges to the target distribution $\\pi_T(s)$.\n\nThe transition from a state $s$ to a new state $s'$ is a two-step process: proposing a move from $s$ to a candidate state $s'$, and then accepting or rejecting this move.\n\n**2.1. Proposal Mechanism**\n\nThe problem specifies a symmetric proposal mechanism. At each step, starting from a state $s$:\n1.  A category $k$ is chosen uniformly at random from the $K$ available categories. The probability is $1/K$.\n2.  Two distinct positions, $p_1$ and $p_2$, are chosen uniformly at random from the set of all distinct pairs of positions. There are $\\binom{N}{2}$ such pairs, so the probability of choosing a specific pair $\\{p_1, p_2\\}$ is $1/\\binom{N}{2}$.\n3.  A candidate state $s'$ is generated by swapping the values of category $k$ at positions $p_1$ and $p_2$.\n\nThe proposal probability $g(s \\to s')$ is the probability of proposing $s'$ starting from $s$. For this mechanism, the probability is $(1/K) \\times (1/\\binom{N}{2})$. To reverse the move, one must start from $s'$, choose the same category $k$, and choose the same two positions $p_1$ and $p_2$ to swap. The probability of this reverse proposal, $g(s' \\to s)$, is also $(1/K) \\times (1/\\binom{N}{2})$. Since $g(s \\to s') = g(s' \\to s)$, the proposal distribution is symmetric.\n\n**2.2. Acceptance Rule and Detailed Balance**\n\nThe convergence of the Markov chain to the stationary distribution $\\pi_T(s)$ is guaranteed if the chain satisfies the detailed balance condition:\n$$ \\pi_T(s) P(s \\to s') = \\pi_T(s') P(s' \\to s) $$\nwhere $P(s \\to s') = g(s \\to s') A(s \\to s')$ is the total transition probability, with $A(s \\to s')$ being the acceptance probability.\n\nSubstituting the expressions for $P$ and $\\pi_T(s) \\propto \\exp(-E(s)/T)$ into the detailed balance equation yields:\n$$ \\exp(-E(s)/T) g(s \\to s') A(s \\to s') = \\exp(-E(s')/T) g(s' \\to s) A(s' \\to s) $$\nBecause our proposal mechanism is symmetric ($g(s \\to s') = g(s' \\to s)$), the proposal probabilities cancel out:\n$$ \\frac{A(s \\to s')}{A(s' \\to s)} = \\frac{\\exp(-E(s')/T)}{\\exp(-E(s)/T)} = \\exp\\left(-\\frac{E(s') - E(s)}{T}\\right) $$\nLet $\\Delta E = E(s') - E(s)$. The ratio becomes $\\exp(-\\Delta E / T)$. The standard Metropolis acceptance rule satisfies this condition:\n$$ A(s \\to s') = \\min\\left(1, \\exp(-\\Delta E / T)\\right) $$\nThis rule is used in the implementation. If a proposed move leads to a state with lower or equal energy ($\\Delta E \\le 0$), it is always accepted. If it leads to a state with higher energy ($\\Delta E > 0$), it is accepted with a probability $\\exp(-\\Delta E / T)$, which is less than $1$. This allows the search to escape local minima.\n\n**3. Ergodicity of the Markov Chain**\n\nFor the MCMC simulation to explore the entire state space and converge to the unique stationary distribution, the Markov chain must be ergodic. Ergodicity requires two properties: connectedness and aperiodicity.\n\n- **Connectedness**: The chain is connected if it is possible to go from any state $s_a \\in \\mathcal{S}$ to any other state $s_b \\in \\mathcal{S}$ in a finite number of steps. Our move set consists of swapping two values within any single category's permutation. A swap of two elements is a transposition in the symmetric group $S_N$. It is a fundamental theorem of group theory that the set of all transpositions generates the entire symmetric group $S_N$. This means that any permutation can be reached from any other permutation through a series of swaps. Since our move set allows us to apply swaps to any of the $K$ category permutations independently, we can transform each of the $K$ permutations in $s_a$ to match those in $s_b$. Thus, the entire state space $\\mathcal{S} = (S_N)^K$ is connected.\n\n- **Aperiodicity**: A Markov chain is aperiodic if for any state $s$, the greatest common divisor of the lengths of all possible paths from $s$ back to itself is $1$. A sufficient condition for aperiodicity is that the probability of staying in any state $s$, $P(s \\to s)$, is non-zero. In our algorithm, a self-transition occurs if a proposed move to $s' \\neq s$ is rejected. As long as the current state $s$ is not a global energy maximum, it is possible to propose a move to a state $s'$ with $E(s') > E(s)$. For such a move, $\\Delta E > 0$, and the acceptance probability $\\exp(-\\Delta E / T)$ is less than $1$. The probability of rejecting this move is $1 - \\exp(-\\Delta E/T) > 0$. Since there is a non-zero probability of both proposing such a move and rejecting it, the total probability of remaining in state $s$ is greater than zero ($P(s \\to s) > 0$). This ensures the chain is aperiodic.\n\nSince the chain is ergodic and satisfies detailed balance, it is guaranteed to converge to the Boltzmann distribution $\\pi_T(s)$. The algorithm proceeds by running the MCMC simulation for a fixed number of steps from several independent random initial states and reports the minimum energy found across all runs and all steps. This improves the chances of finding the global minimum energy, which for a satisfiable puzzle is $E_{\\min}=0$.",
            "answer": "```python\nimport numpy as np\n\n# Puzzle A Definition\npuzzle_a_def = {\n    \"N\": 4, \"K\": 3,\n    \"categories\": {\"color\": 0, \"pet\": 1, \"drink\": 2},\n    \"values\": {\n        0: {\"Yellow\": 0, \"Blue\": 1, \"Red\": 2, \"Green\": 3},\n        1: {\"Cat\": 0, \"Dog\": 1, \"Fish\": 2, \"Bird\": 3},\n        2: {\"Coffee\": 0, \"Tea\": 1, \"Milk\": 2, \"Water\": 3},\n    },\n    \"constraints\": [\n        (\"IMMEDIATE_LEFT\", (\"color\", \"Red\"), (\"color\", \"Green\")),\n        (\"EQUALITY\", (\"drink\", \"Tea\"), (\"color\", \"Blue\")),\n        (\"ADJACENCY\", (\"pet\", \"Dog\"), (\"color\", \"Yellow\")),\n        (\"FIXED_POS\", (\"drink\", \"Milk\"), 2),\n        (\"FIXED_POS\", (\"pet\", \"Cat\"), 0),\n        (\"INEQUALITY\", (\"drink\", \"Water\"), (\"color\", \"Yellow\")),\n        (\"STRICT_RIGHT_OF\", (\"pet\", \"Bird\"), (\"color\", \"Red\")),\n        (\"INEQUALITY\", (\"pet\", \"Fish\"), (\"color\", \"Green\")),\n        (\"EQUALITY\", (\"drink\", \"Coffee\"), (\"color\", \"Yellow\")),\n    ]\n}\n\n# Puzzle B Definition\npuzzle_b_def = {\n    \"N\": 3, \"K\": 3,\n    \"categories\": {\"color\": 0, \"pet\": 1, \"drink\": 2},\n    \"values\": {\n        0: {\"Red\": 0, \"Green\": 1, \"Blue\": 2},\n        1: {\"Dog\": 0, \"Cat\": 1, \"Fish\": 2},\n        2: {\"Tea\": 0, \"Milk\": 1, \"Coffee\": 2},\n    },\n    \"constraints\": [\n        (\"EQUALITY\", (\"color\", \"Red\"), (\"drink\", \"Tea\")),\n        (\"FIXED_POS\", (\"pet\", \"Cat\"), 1),\n        (\"STRICT_RIGHT_OF\", (\"color\", \"Blue\"), (\"color\", \"Green\")),\n        (\"INEQUALITY\", (\"pet\", \"Fish\"), (\"color\", \"Red\")),\n        (\"ADJACENCY\", (\"drink\", \"Milk\"), (\"pet\", \"Dog\")),\n        (\"EQUALITY\", (\"drink\", \"Coffee\"), (\"color\", \"Blue\")),\n    ]\n}\n\n# Puzzle C Definition\npuzzle_c_def = {\n    \"N\": 3, \"K\": 3,\n    \"categories\": {\"color\": 0, \"pet\": 1, \"drink\": 2},\n    \"values\": {\n        0: {\"Red\": 0, \"Green\": 1, \"Blue\": 2},\n        1: {\"Dog\": 0, \"Cat\": 1, \"Fish\": 2},\n        2: {\"Tea\": 0, \"Milk\": 1, \"Coffee\": 2},\n    },\n    \"constraints\": [\n        (\"EQUALITY\", (\"drink\", \"Tea\"), (\"color\", \"Red\")),\n        (\"EQUALITY\", (\"drink\", \"Coffee\"), (\"color\", \"Red\")),\n        (\"FIXED_POS\", (\"pet\", \"Dog\"), 0),\n        (\"FIXED_POS\", (\"color\", \"Blue\"), 2),\n        (\"ADJACENCY\", (\"drink\", \"Milk\"), (\"pet\", \"Cat\")),\n        (\"STRICT_RIGHT_OF\", (\"pet\", \"Fish\"), (\"color\", \"Green\")),\n    ]\n}\n\nPUZZLES = [puzzle_a_def, puzzle_b_def, puzzle_c_def]\n\nclass MCMCSolver:\n    def __init__(self, puzzle_def, T, S, R, base_seed):\n        self.N = puzzle_def[\"N\"]\n        self.K = puzzle_def[\"K\"]\n        self.T = T\n        self.S = S\n        self.R = R\n        self.base_seed = base_seed\n\n        self.cat_map = puzzle_def[\"categories\"]\n        self.val_maps = puzzle_def[\"values\"]\n        \n        self.parsed_constraints = self._parse_constraints(puzzle_def[\"constraints\"])\n\n    def _parse_constraints(self, constraints_def):\n        parsed = []\n        for c in constraints_def:\n            ctype = c[0]\n            if ctype in (\"EQUALITY\", \"INEQUALITY\", \"ADJACENCY\", \"IMMEDIATE_LEFT\", \"STRICT_RIGHT_OF\"):\n                cat1_name, val1_name = c[1]\n                cat2_name, val2_name = c[2]\n                k1 = self.cat_map[cat1_name]\n                k2 = self.cat_map[cat2_name]\n                v1 = self.val_maps[k1][val1_name]\n                v2 = self.val_maps[k2][val2_name]\n                parsed.append((ctype, (k1, v1), (k2, v2)))\n            elif ctype == \"FIXED_POS\":\n                cat_name, val_name = c[1]\n                pos = c[2]\n                k = self.cat_map[cat_name]\n                v = self.val_maps[k][val_name]\n                parsed.append((ctype, (k, v), pos))\n        return parsed\n\n    def _evaluate_energy(self, val_to_pos_map):\n        violations = 0\n        for ctype, term1, term2 in self.parsed_constraints:\n            if ctype == \"EQUALITY\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] != val_to_pos_map[k2, v2]:\n                    violations += 1\n            elif ctype == \"INEQUALITY\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] == val_to_pos_map[k2, v2]:\n                    violations += 1\n            elif ctype == \"FIXED_POS\":\n                k, v = term1\n                pos = term2\n                if val_to_pos_map[k, v] != pos:\n                    violations += 1\n            elif ctype == \"ADJACENCY\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if abs(val_to_pos_map[k1, v1] - val_to_pos_map[k2, v2]) != 1:\n                    violations += 1\n            elif ctype == \"IMMEDIATE_LEFT\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] + 1 != val_to_pos_map[k2, v2]:\n                    violations += 1\n            elif ctype == \"STRICT_RIGHT_OF\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] = val_to_pos_map[k2, v2]:\n                    violations += 1\n        return violations\n\n    def run(self):\n        min_global_energy = float('inf')\n\n        for r in range(self.R):\n            seed = self.base_seed + r\n            rng = np.random.default_rng(seed)\n\n            # Initialize state\n            pos_to_val = np.empty((self.K, self.N), dtype=int)\n            val_to_pos = np.empty((self.K, self.N), dtype=int)\n            for k in range(self.K):\n                perm = rng.permutation(self.N)\n                pos_to_val[k, :] = perm\n                for p, v in enumerate(perm):\n                    val_to_pos[k, v] = p\n\n            current_energy = self._evaluate_energy(val_to_pos)\n            min_restart_energy = current_energy\n\n            for _ in range(self.S):\n                # Propose a move\n                k_swap = rng.integers(self.K)\n                p1, p2 = rng.choice(self.N, 2, replace=False)\n                \n                # Create a proposed state by swapping\n                prop_pos_to_val = np.copy(pos_to_val)\n                prop_val_to_pos = np.copy(val_to_pos)\n\n                v1, v2 = prop_pos_to_val[k_swap, p1], prop_pos_to_val[k_swap, p2]\n                prop_pos_to_val[k_swap, p1], prop_pos_to_val[k_swap, p2] = v2, v1\n                prop_val_to_pos[k_swap, v1], prop_val_to_pos[k_swap, v2] = p2, p1\n                \n                proposed_energy = self._evaluate_energy(prop_val_to_pos)\n                \n                delta_E = proposed_energy - current_energy\n                \n                # Metropolis acceptance criterion\n                if delta_E = 0 or rng.random()  np.exp(-delta_E / self.T):\n                    pos_to_val = prop_pos_to_val\n                    val_to_pos = prop_val_to_pos\n                    current_energy = proposed_energy\n                \n                if current_energy  min_restart_energy:\n                    min_restart_energy = current_energy\n\n            if min_restart_energy  min_global_energy:\n                min_global_energy = min_restart_energy\n        \n        return int(min_global_energy)\n\ndef solve():\n    T = 0.7\n    S = 30000\n    R = 8\n    SEEDS = [20231105, 20231106, 20231107]\n    \n    test_cases = [\n        (PUZZLES[0], T, S, R, SEEDS[0]),\n        (PUZZLES[1], T, S, R, SEEDS[1]),\n        (PUZZLES[2], T, S, R, SEEDS[2]),\n    ]\n\n    results = []\n    for case in test_cases:\n        solver = MCMCSolver(*case)\n        min_energy = solver.run()\n        results.append(min_energy)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}