{
    "hands_on_practices": [
        {
            "introduction": "The Jacobi method, while being one of the most fundamental relaxation schemes, provides a powerful lens through which to understand modern parallel computing. This exercise simulates the execution of a solver on a Graphics Processing Unit (GPU), where each point on the grid is updated simultaneously. You will implement the synchronous Jacobi update, a process naturally suited to the Single Instruction, Multiple Threads (SIMT) architecture of devices using frameworks like the OpenGL Shading Language (GLSL) or the Compute Unified Device Architecture (CUDA). This practice not only builds your core implementation skills but also challenges you to connect empirical results with theory by deriving and verifying the method's convergence rate from first principles .",
            "id": "2433927",
            "problem": "You are to design and implement a synchronous relaxation solver for a model elliptic boundary-value problem that emulates the execution model of a Graphics Processing Unit (GPU). The physical problem is the two-dimensional Poisson equation with homogeneous Dirichlet boundary conditions on the unit square. Your implementation must mimic the behavior of a GPU kernel in which each thread updates exactly one grid point in parallel and all updates occur synchronously. Because the execution environment for this task is a Central Processing Unit (CPU), you must emulate the GPU by applying a single, vectorized update over the entire interior grid without using pointwise Python loops over grid points. You must use the Jacobi method and explicitly avoid in-place updates of interior values within an iteration. Define the OpenGL Shading Language (GLSL) and the Compute Unified Device Architecture (CUDA) on first mention: OpenGL Shading Language (GLSL) and Compute Unified Device Architecture (CUDA).\n\nStart from fundamental principles: discretize the partial differential equation using a uniform Cartesian grid and the standard five-point stencil for the Laplacian, and from this discretization derive the synchronous point update rule of the Jacobi method. Let the domain be $\\Omega = [0,1]\\times[0,1]$, let the number of interior points per coordinate direction be $N$, and define the grid spacing as $h = \\frac{1}{N+1}$. Let $u(x,y)$ denote the exact solution and $f(x,y)$ the source term in\n$$\n\\nabla^2 u(x,y) = f(x,y)\\quad \\text{for}\\ (x,y)\\in \\Omega,\\qquad\nu(x,y)=0\\quad \\text{for}\\ (x,y)\\in \\partial\\Omega.\n$$\nLet $u_{i,j}$ denote the discrete unknown at grid point $(x_i,y_j)$ with $x_i = i h$ and $y_j = j h$ for $i,j\\in\\{0,1,\\dots,N+1\\}$, where the boundary values satisfy $u_{i,0}=u_{i,N+1}=u_{0,j}=u_{N+1,j}=0$. Derive, from first principles, the synchronous Jacobi update that uses only neighbor values from the previous iteration and the source term. Explain why synchronous updates are natural for Single Instruction, Multiple Threads (SIMT) execution on a GPU.\n\nImplement a program that:\n- Constructs the discrete right-hand side $f_{i,j}$ for a prescribed source $f(x,y)$.\n- Initializes the interior state with $u_{i,j}^{(0)}=0$ for all interior $(i,j)$.\n- Iterates the Jacobi method until the discrete $\\ell^2$-norm of the residual,\n$$\n\\|r^{(k)}\\|_{2,h} = \\left(h^2 \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\left(f_{i,j} - (A u^{(k)})_{i,j}\\right)^2\\right)^{1/2},\n$$\nfalls below a specified tolerance $\\varepsilon$ or until a maximum number of iterations $k_{\\max}$ is reached. Here $(A u)_{i,j}$ is the five-point discrete Laplacian applied to $u$ and all angles used in trigonometric functions must be in radians.\n- Estimates the asymptotic convergence factor $\\hat{q}$ from the last available ratios $\\|r^{(k)}\\|_{2,h} / \\|r^{(k-1)}\\|_{2,h}$, averaged over up to the last $10$ iterations that have both $\\|r^{(k)}\\|_{2,h}$ and $\\|r^{(k-1)}\\|_{2,h}$ defined. If fewer than $2$ iterations occur, define $\\hat{q}=0$.\n- Computes the theoretical asymptotic convergence factor $q$ of the Jacobi iteration on this problem by analyzing the eigenmodes of the iteration operator on a uniform grid. Do not assume any formula for $q$ without justification; the value of $q$ must be computed from first principles in your solution and implemented in your code using your derived expression.\n\nIn addition to the residual norm, when an exact solution $u(x,y)$ is known, compute the discrete $\\ell^2$-error\n$$\n\\|e^{(k)}\\|_{2,h} = \\left(h^2 \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\left(u_{i,j}^{(k)} - u(x_i,y_j)\\right)^2\\right)^{1/2}.\n$$\n\nTest suite. Your program must run the following three test cases and aggregate their results:\n- Case A (happy path): $N=15$, $f(x,y)=-2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$, exact solution $u(x,y)=\\sin(\\pi x)\\sin(\\pi y)$, tolerance $\\varepsilon=10^{-8}$, $k_{\\max}=10000$.\n- Case B (larger grid): $N=31$, same $f$ and exact solution as Case A, tolerance $\\varepsilon=10^{-6}$, $k_{\\max}=100000$.\n- Case C (boundary condition edge case): $N=15$, $f(x,y)=0$ and exact solution $u(x,y)=0$, tolerance $\\varepsilon=10^{-12}$, $k_{\\max}=1000$.\n\nFor each case, your program must output a list of five values in the order:\n$[k_{\\text{it}}, \\|r^{(k)}\\|_{2,h}, \\|e^{(k)}\\|_{2,h}, \\hat{q}, q]$, where $k_{\\text{it}}$ is the number of Jacobi iterations actually performed, $\\|r^{(k)}\\|_{2,h}$ is the final residual norm, $\\|e^{(k)}\\|_{2,h}$ is the final error norm (use $0$ when no analytical solution is available), $\\hat{q}$ is the empirical convergence factor estimate, and $q$ is the theoretical factor derived from your analysis.\n\nFinal output format. Your program should produce a single line of output containing the three case results as a comma-separated list of lists, with numeric entries rounded to six significant figures, and no extra characters or whitespace. For example, the final line must look like\n$[[k_1,r_1,e_1,\\hat{q}_1,q_1],[k_2,r_2,e_2,\\hat{q}_2,q_2],[k_3,r_3,e_3,\\hat{q}_3,q_3]]$\nwith each $k_i$ an integer and each $r_i$, $e_i$, $\\hat{q}_i$, $q_i$ a floating-point number. The angle unit used in all trigonometric evaluations must be radians.",
            "solution": "The problem presented is valid; it is a standard, well-posed exercise in computational physics concerning the numerical solution of elliptic partial differential equations. It is scientifically grounded, internally consistent, and contains all necessary information for a unique numerical solution. We shall proceed with the derivation and implementation.\n\nFirst, we must define the computational architectures mentioned, as requested. The OpenGL Shading Language (GLSL) is a high-level shading language with a syntax based on the C programming language. It is used to create programs, known as shaders, that execute on a Graphics Processing Unit (GPU) as part of the graphics pipeline. The Compute Unified Device Architecture (CUDA) is a proprietary parallel computing platform and application programming interface (API) model created by Nvidia. It allows software developers to use a CUDA-enabled GPU for general-purpose processing, an approach known as GPGPU (General-Purpose computing on Graphics Processing Units).\n\nThe core of the problem is to solve the two-dimensional Poisson equation on the unit square $\\Omega = [0,1]\\times[0,1]$ with homogeneous Dirichlet boundary conditions:\n$$\n\\nabla^2 u(x,y) = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = f(x,y) \\quad \\text{for } (x,y) \\in \\Omega\n$$\n$$\nu(x,y) = 0 \\quad \\text{for } (x,y) \\in \\partial\\Omega\n$$\nWe discretize the domain $\\Omega$ using a uniform Cartesian grid with $N$ interior points in each direction. The grid spacing is $h = \\frac{1}{N+1}$. The grid points are $(x_i, y_j)$, where $x_i = ih$ and $y_j = jh$ for integers $i, j \\in \\{0, 1, \\dots, N+1\\}$. The discrete solution at these points is denoted by $u_{i,j}$. The boundary conditions imply $u_{i,0} = u_{i,N+1} = u_{0,j} = u_{N+1,j} = 0$.\n\nTo discretize the Laplacian operator $\\nabla^2$, we use second-order accurate central finite differences derived from Taylor series expansions:\n$$\n\\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{(x_i,y_j)} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\mathcal{O}(h^2)\n$$\n$$\n\\frac{\\partial^2 u}{\\partial y^2}\\bigg|_{(x_i,y_j)} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + \\mathcal{O}(h^2)\n$$\nSubstituting these into the Poisson equation yields the five-point stencil discrete equation for each interior grid point $(i,j)$ where $i,j \\in \\{1, \\dots, N\\}$:\n$$\n\\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} = f_{i,j}\n$$\nThis is a large, sparse system of $N^2$ linear equations for the $N^2$ unknown interior values $u_{i,j}$. To solve this system iteratively, we derive the Jacobi method by isolating the term $u_{i,j}$ and introducing an iteration index $k$:\n$$\n4u_{i,j} = u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j}\n$$\nThe Jacobi update rule computes the new value $u_{i,j}^{(k+1)}$ using only values from the previous iteration, $u^{(k)}$:\n$$\nu_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(k)} + u_{i-1,j}^{(k)} + u_{i,j+1}^{(k)} + u_{i,j-1}^{(k)} - h^2 f_{i,j} \\right)\n$$\nThis update is performed for all interior points $i,j \\in \\{1, \\dots, N\\}$.\n\nThe structure of this update rule is highly amenable to parallel computation, particularly on SIMT (Single Instruction, Multiple Threads) architectures like GPUs. The key observation is that the calculation for each point $u_{i,j}^{(k+1)}$ is completely independent of all other new values $u_{l,m}^{(k+1)}$ for $(l,m) \\neq (i,j)$. All values on the right-hand side belong to the previous state, $u^{(k)}$. A GPU can assign a thread to each grid point $(i,j)$, and all threads can execute the same instruction—the Jacobi update formula—simultaneously on their assigned data. This requires two memory buffers: one to read the old state $u^{(k)}$ and another to write the new state $u^{(k+1)}$. This process, known as a synchronous update, avoids data races and perfectly matches the hardware paradigm. Emulating this on a CPU involves using two arrays and performing a vectorized update, as specified.\n\nNext, we derive the theoretical asymptotic convergence factor, $q$. The Jacobi iteration can be written in matrix form as $\\mathbf{u}^{(k+1)} = T_J \\mathbf{u}^{(k)} + \\mathbf{c}$, where $T_J$ is the Jacobi iteration matrix. The convergence rate is determined by the spectral radius of $T_J$, defined as $q = \\rho(T_J) = \\max_m |\\lambda_m|$, where $\\lambda_m$ are the eigenvalues of $T_J$. The eigenvectors of the discrete Laplacian operator on this domain are known to be the discrete sine functions:\n$$\nv_{i,j}^{(p,q)} = \\sin\\left(\\frac{p\\pi i}{N+1}\\right) \\sin\\left(\\frac{q\\pi j}{N+1}\\right) \\quad \\text{for } p,q \\in \\{1, \\dots, N\\}\n$$\nThese are also the eigenvectors of the Jacobi iteration matrix $T_J$. Applying the Jacobi operator to such an eigenvector gives:\n$$\n(T_J v^{(p,q)})_{i,j} = \\frac{1}{4} \\left( v_{i+1,j}^{(p,q)} + v_{i-1,j}^{(p,q)} + v_{i,j+1}^{(p,q)} + v_{i,j-1}^{(p,q)} \\right)\n$$\nUsing the trigonometric identity $\\sin(A+B) + \\sin(A-B) = 2\\sin(A)\\cos(B)$, we simplify the terms:\n$$\nv_{i+1,j}^{(p,q)} + v_{i-1,j}^{(p,q)} = 2\\cos\\left(\\frac{p\\pi}{N+1}\\right) v_{i,j}^{(p,q)}\n$$\n$$\nv_{i,j+1}^{(p,q)} + v_{i,j-1}^{(p,q)} = 2\\cos\\left(\\frac{q\\pi}{N+1}\\right) v_{i,j}^{(p,q)}\n$$\nSubstituting these back, we find the eigenvalue $\\lambda_{p,q}$ corresponding to the eigenvector $v^{(p,q)}$:\n$$\n(T_J v^{(p,q)})_{i,j} = \\frac{1}{2} \\left[ \\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right) \\right] v_{i,j}^{(p,q)}\n$$\nThe spectral radius is the maximum of the absolute value of these eigenvalues over all $p, q \\in \\{1, \\dots, N\\}$. The cosine function is positive and monotonically decreasing on the interval $[0, \\pi/2]$. Thus, the maximum eigenvalue occurs for the smallest arguments, i.e., $p=1$ and $q=1$.\n$$\nq = \\rho(T_J) = \\lambda_{1,1} = \\frac{1}{2} \\left[ \\cos\\left(\\frac{\\pi}{N+1}\\right) + \\cos\\left(\\frac{\\pi}{N+1}\\right) \\right] = \\cos\\left(\\frac{\\pi}{N+1}\\right)\n$$\nThis is the required theoretical asymptotic convergence factor. It approaches $1$ as $N$ increases, indicating a significant slowdown in convergence for finer grids.\n\nThe implementation will follow these derived principles. A main loop will iterate the Jacobi update, checking for convergence at the beginning of each step. The residual norm $\\|r^{(k)}\\|_{2,h}$ and error norm $\\|e^{(k)}\\|_{2,h}$ will be computed using vectorized `numpy` operations. The empirical convergence factor $\\hat{q}$ will be estimated from the ratios of successive residual norms, and all numerical outputs will be formatted as specified.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef format_num(n):\n    \"\"\"Formats a number to 6 significant figures, or as an integer.\"\"\"\n    if isinstance(n, int):\n        return str(n)\n    if n == 0.0:\n        return \"0.0\"\n    return f\"{n:.6g}\"\n\ndef run_case(N, f_func, u_exact_func, epsilon, k_max):\n    \"\"\"\n    Solves the 2D Poisson BVP for a single test case using the Jacobi method.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    \n    # Create grid coordinates (including boundaries)\n    i_coords = np.arange(0, N + 2)\n    x = i_coords * h\n    X, Y = np.meshgrid(x, x, indexing='ij')\n\n    # Initialize solution array u (with zero boundaries) and source term f\n    u = np.zeros((N + 2, N + 2))\n    f_grid = f_func(X, Y)\n    \n    u_exact_grid = None\n    if u_exact_func is not None:\n        u_exact_grid = u_exact_func(X, Y)\n\n    residual_history = []\n    k_it = 0\n\n    for k in range(k_max + 1):\n        # Calculate the residual of the current state u^{(k)}\n        # A*u = (1/h^2) * (u_{i+1,j} + ... - 4u_{i,j})\n        # r = f - A*u\n        laplacian_u_interior = (u[2:, 1:-1] + u[:-2, 1:-1] + u[1:-1, 2:] + u[1:-1, :-2] - 4 * u[1:-1, 1:-1]) / (h**2)\n        f_interior = f_grid[1:-1, 1:-1]\n        \n        residual_matrix = f_interior - laplacian_u_interior\n        residual_norm = np.sqrt(h**2 * np.sum(residual_matrix**2))\n        residual_history.append(residual_norm)\n        \n        k_it = k\n        # Check for convergence before performing the update\n        if residual_norm  epsilon:\n            break\n        \n        # Check if max iterations reached\n        if k == k_max:\n            break\n\n        # Perform one synchronous Jacobi iteration (emulating GPU)\n        # Use a new array for the updated values, reading only from the old 'u'\n        u_new = np.zeros_like(u)\n        u_new[1:-1, 1:-1] = 0.25 * (u[2:, 1:-1] + u[:-2, 1:-1] +u[1:-1, 2:] + u[1:-1, :-2] - h**2 * f_grid[1:-1, 1:-1])\n        u = u_new\n\n    # --- Post-processing after loop termination ---\n    final_residual_norm = residual_history[-1]\n    \n    # Calculate final discrete L2 error norm if exact solution is available\n    final_error_norm = 0.0\n    if u_exact_grid is not None:\n        error_matrix = u[1:-1, 1:-1] - u_exact_grid[1:-1, 1:-1]\n        final_error_norm = np.sqrt(h**2 * np.sum(error_matrix**2))\n\n    # Estimate empirical convergence factor q_hat\n    q_hat = 0.0\n    # Per problem statement: q_hat=0 if fewer than 2 iterations occur.\n    if k_it = 2:\n        ratios = []\n        # residual_history has k_it+1 elements (for k=0, 1, ..., k_it)\n        for i in range(1, len(residual_history)):\n            # Avoid division by zero\n            if residual_history[i-1]  1e-16:\n                ratios.append(residual_history[i] / residual_history[i-1])\n        \n        num_ratios_to_avg = min(len(ratios), 10)\n        if num_ratios_to_avg  0:\n            q_hat = np.mean(ratios[-num_ratios_to_avg:])\n            \n    # Calculate theoretical convergence factor q\n    q_theory = np.cos(np.pi / (N + 1))\n    \n    return [\n        format_num(k_it),\n        format_num(final_residual_norm),\n        format_num(final_error_norm),\n        format_num(q_hat),\n        format_num(q_theory)\n    ]\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the Jacobi solver.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path\n        {\n            \"N\": 15,\n            \"f_func\": lambda x, y: -2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"u_exact_func\": lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"epsilon\": 1e-8,\n            \"k_max\": 10000\n        },\n        # Case B: Larger grid\n        {\n            \"N\": 31,\n            \"f_func\": lambda x, y: -2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"u_exact_func\": lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"epsilon\": 1e-6,\n            \"k_max\": 100000\n        },\n        # Case C: Trivial solution, boundary edge case\n        {\n            \"N\": 15,\n            \"f_func\": lambda x, y: np.zeros_like(x),\n            \"u_exact_func\": lambda x, y: np.zeros_like(x),\n            \"epsilon\": 1e-12,\n            \"k_max\": 1000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(\n            case[\"N\"],\n            case[\"f_func\"],\n            case[\"u_exact_func\"],\n            case[\"epsilon\"],\n            case[\"k_max\"]\n        )\n        # Format each list of results into the required string format\n        results.append(f\"[{','.join(result)}]\")\n\n    # Print the final aggregated output string\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Moving beyond idealized Cartesian grids is a crucial step toward solving realistic physical problems, which often involve complex geometries like pipes, disks, or spheres. This practice challenges you to adapt your solver to an annular domain by working in polar coordinates. You will derive the finite-difference stencil for the Laplacian operator, $\\nabla^2$, from its fundamental definition in polar coordinates, a skill essential for any computational physicist who must build solvers for new situations. By implementing a Successive Over-Relaxation (SOR) scheme, you will also gain experience with a more advanced and efficient relaxation technique to solve for the potential in this non-trivial geometry .",
            "id": "2433975",
            "problem": "Implement a complete, runnable program that computes the electrostatic potential governed by the Laplace equation inside an annular domain using a relaxation method on a polar grid. The governing partial differential equation is the Laplace equation in polar coordinates, which is a classical elliptic equation, expressed by the well-tested formula $\\nabla^{2}\\phi = \\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right) + \\frac{1}{r^{2}}\\frac{\\partial^{2}\\phi}{\\partial \\theta^{2}}$. The domain is the annulus $\\{(r,\\theta)\\,|\\, r \\in [r_{\\mathrm{in}}, r_{\\mathrm{out}}], \\theta \\in [0, 2\\pi)\\}$ with periodicity in the angular direction. You must use a relaxation method, specifically Successive Over-Relaxation (SOR), to solve for the discrete potential on a uniform polar grid. Angles must be in radians. There are no physical units to report in this problem.\n\nStarting from the divergence form of the Laplacian and the definition of central finite differences on a uniform grid, derive a consistent second-order finite-difference discretization of the operator $\\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right)$ and of $\\frac{1}{r^{2}}\\frac{\\partial^{2}\\phi}{\\partial \\theta^{2}}$ at an interior grid point. Then, using this discrete equation, construct a pointwise linear update for interior nodes that enforces the discrete Laplace equation. Embed this pointwise update in a Successive Over-Relaxation (SOR) sweep with relaxation factor $\\omega$ and iterate until the discrete residual is below a specified tolerance. The residual at an interior node must be defined by substituting the current iterate into your derived discrete Laplace operator. Use periodic boundary conditions in the angular direction and Dirichlet boundary conditions at $r=r_{\\mathrm{in}}$ and $r=r_{\\mathrm{out}}$.\n\nYour program must:\n- Build a uniform polar grid with $N_{r}$ nodes in the radial direction and $N_{\\theta}$ nodes in the angular direction. Use $r_{i} = r_{\\mathrm{in}} + i\\,\\Delta r$ for $i \\in \\{0,1,\\dots,N_{r}-1\\}$ with $\\Delta r = \\frac{r_{\\mathrm{out}}-r_{\\mathrm{in}}}{N_{r}-1}$ and $\\theta_{j} = j\\,\\Delta \\theta$ for $j \\in \\{0,1,\\dots,N_{\\theta}-1\\}$ with $\\Delta \\theta = \\frac{2\\pi}{N_{\\theta}}$. Angles must be in radians.\n- Impose Dirichlet boundary values at $r=r_{\\mathrm{in}}$ and $r=r_{\\mathrm{out}}$ as specified per test case below, and enforce periodicity in $\\theta$ by indexing with wrap-around for $\\theta_{j\\pm 1}$.\n- Use Successive Over-Relaxation (SOR) with a fixed relaxation factor $\\omega$ to iteratively update interior grid values until the $\\ell_{\\infty}$-norm of the discrete residual across all interior points is less than a tolerance $\\varepsilon$. Use a maximum iteration cap to avoid non-termination if convergence fails.\n- After convergence, compute the maximum absolute error on the entire grid against an analytic solution provided for each test case.\n\nDerivation constraints:\n- Begin from the divergence form identity for the Laplacian and central finite-difference definitions. Do not assume any pre-derived discrete update for polar coordinates; derive it explicitly from first principles.\n- The discretization must be second-order accurate in both $r$ and $\\theta$ on a uniform grid.\n- The SOR update must be constructed from the derived discrete equation by isolating the unknown at an interior node and applying the over-relaxation with factor $\\omega$.\n\nConvergence criterion and parameters:\n- Use the residual-based stopping criterion $\\max_{i,j} | \\mathcal{L}_{h}[\\phi]_{i,j} |  \\varepsilon$, where $\\mathcal{L}_{h}$ denotes your discrete Laplacian applied to the current iterate, and the maximum is taken over all interior grid points only.\n- Use relaxation factor $\\omega = 1.85$.\n- Use tolerance $\\varepsilon = 10^{-8}$.\n- Use a maximum of $N_{\\mathrm{it,max}} = 50000$ iterations.\n\nTest suite:\n- Case $1$ (radial Dirichlet data with analytic logarithmic solution):\n  - $r_{\\mathrm{in}} = 1$, $r_{\\mathrm{out}} = 2$, $N_{r} = 32$, $N_{\\theta} = 64$.\n  - Boundary values: $\\phi(r_{\\mathrm{in}},\\theta) = 0$ and $\\phi(r_{\\mathrm{out}},\\theta) = 1$ for all $\\theta$.\n  - Analytic solution: $\\phi_{\\mathrm{exact}}(r,\\theta) = \\dfrac{\\ln r - \\ln r_{\\mathrm{in}}}{\\ln r_{\\mathrm{out}} - \\ln r_{\\mathrm{in}}}$, independent of $\\theta$.\n- Case $2$ (single Fourier mode at the outer boundary):\n  - $r_{\\mathrm{in}} = 1$, $r_{\\mathrm{out}} = 2$, $N_{r} = 32$, $N_{\\theta} = 64$.\n  - Boundary values: $\\phi(r_{\\mathrm{in}},\\theta) = 0$ and $\\phi(r_{\\mathrm{out}},\\theta) = \\cos(n\\theta)$ with $n=3$ and $\\theta$ in radians.\n  - Analytic solution: $\\phi_{\\mathrm{exact}}(r,\\theta) = \\left(a\\,r^{n} + b\\,r^{-n}\\right)\\cos(n\\theta)$, where $a$ and $b$ satisfy $a\\,r_{\\mathrm{in}}^{n} + b\\,r_{\\mathrm{in}}^{-n} = 0$ and $a\\,r_{\\mathrm{out}}^{n} + b\\,r_{\\mathrm{out}}^{-n} = 1$. For $n=3$, $a = \\dfrac{1}{r_{\\mathrm{out}}^{3} - r_{\\mathrm{in}}^{6}\\,r_{\\mathrm{out}}^{-3}}$ and $b = -a\\,r_{\\mathrm{in}}^{6}$.\n- Case $3$ (thin annulus with radial Dirichlet data):\n  - $r_{\\mathrm{in}} = 0.5$, $r_{\\mathrm{out}} = 0.6$, $N_{r} = 16$, $N_{\\theta} = 64$.\n  - Boundary values: $\\phi(r_{\\mathrm{in}},\\theta) = 0$ and $\\phi(r_{\\mathrm{out}},\\theta) = 1$ for all $\\theta$.\n  - Analytic solution: $\\phi_{\\mathrm{exact}}(r,\\theta) = \\dfrac{\\ln r - \\ln r_{\\mathrm{in}}}{\\ln r_{\\mathrm{out}} - \\ln r_{\\mathrm{in}}}$, independent of $\\theta$.\n\nQuantifiable answer:\n- For each case, compute the maximum absolute error $E_{\\max} = \\max_{i,j}|\\phi_{i,j} - \\phi_{\\mathrm{exact}}(r_{i},\\theta_{j})|$ over all grid points, including boundaries. Each case yields a single floating-point number.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each floating-point value rounded and formatted in scientific notation with $6$ significant digits (for example, `[1.234567e-04,2.345678e-05,3.456789e-06]`).",
            "solution": "The problem statement has been critically examined and is determined to be **valid**. It presents a well-posed, scientifically grounded problem in computational physics, providing all necessary definitions, constants, and boundary conditions for a unique solution to be computed and verified. The task is to solve the Laplace equation in an annular domain using a Successive Over-Relaxation (SOR) method, which is a standard and appropriate technique for this class of elliptic partial differential equations. The problem is free from ambiguity, logical contradictions, and factual errors. We may proceed with the solution.\n\nThe solution requires the derivation of a finite-difference scheme for the Laplace equation in polar coordinates, followed by the implementation of the SOR algorithm to solve the resulting system of linear equations.\n\n### 1. Finite-Difference Discretization of the Laplacian\nThe governing equation is the Laplace equation in polar coordinates $(r, \\theta)$:\n$$ \\nabla^2 \\phi = \\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right) + \\frac{1}{r^2}\\frac{\\partial^2\\phi}{\\partial\\theta^2} = 0 $$\nWe discretize this equation on a uniform polar grid defined by points $(r_i, \\theta_j)$, where $r_i = r_{\\mathrm{in}} + i\\Delta r$ for $i \\in \\{0, 1, ..., N_r-1\\}$ and $\\theta_j = j\\Delta\\theta$ for $j \\in \\{0, 1, ..., N_\\theta-1\\}$. The grid spacings are $\\Delta r = (r_{\\mathrm{out}}-r_{\\mathrm{in}})/(N_r-1)$ and $\\Delta\\theta = 2\\pi/N_\\theta$. The potential at a grid point is denoted by $\\phi_{i,j} \\equiv \\phi(r_i, \\theta_j)$.\n\nThe discretization must be second-order accurate. We will derive the discrete form for each term at an interior grid point $(r_i, \\theta_j)$.\n\n**Angular Term:** The term $\\frac{1}{r^2}\\frac{\\partial^2\\phi}{\\partial\\theta^2}$ is discretized at $r=r_i$ using a standard second-order central difference for the second derivative in $\\theta$:\n$$ \\left.\\frac{1}{r^2}\\frac{\\partial^2\\phi}{\\partial\\theta^2}\\right|_{(r_i, \\theta_j)} \\approx \\frac{1}{r_i^2} \\left( \\frac{\\phi_{i,j+1} - 2\\phi_{i,j} + \\phi_{i,j-1}}{(\\Delta\\theta)^2} \\right) $$\n\n**Radial Term:** The term $\\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right)$ is given in divergence form. To preserve second-order accuracy, we discretize it by evaluating the derivative at $r_i$ using centered differences on half-integer grid points $r_{i\\pm 1/2} = r_i \\pm \\Delta r/2$:\n$$ \\left. \\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right) \\right|_{(r_i, \\theta_j)} \\approx \\frac{1}{r_i} \\frac{ \\left. r\\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i+1/2}} - \\left. r\\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i-1/2}} }{\\Delta r} $$\nThe derivatives $\\frac{\\partial\\phi}{\\partial r}$ at the half-points are also approximated by central differences:\n$$ \\left. \\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i+1/2}} \\approx \\frac{\\phi_{i+1,j} - \\phi_{i,j}}{\\Delta r} \\quad \\text{and} \\quad \\left. \\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i-1/2}} \\approx \\frac{\\phi_{i,j} - \\phi_{i-1,j}}{\\Delta r} $$\nSubstituting these into the expression for the radial term yields:\n$$ \\frac{1}{r_i \\Delta r} \\left[ r_{i+1/2} \\left(\\frac{\\phi_{i+1,j} - \\phi_{i,j}}{\\Delta r}\\right) - r_{i-1/2} \\left(\\frac{\\phi_{i,j} - \\phi_{i-1,j}}{\\Delta r}\\right) \\right] $$\nUsing $r_{i\\pm 1/2} = r_i \\pm \\frac{\\Delta r}{2}$, the expression becomes:\n$$ \\frac{1}{r_i (\\Delta r)^2} \\left[ (r_i + \\frac{\\Delta r}{2})(\\phi_{i+1,j} - \\phi_{i,j}) - (r_i - \\frac{\\Delta r}{2})(\\phi_{i,j} - \\phi_{i-1,j}) \\right] $$\nRearranging terms with respect to the potential $\\phi$:\n$$ \\frac{1}{(\\Delta r)^2} \\left[ \\left(1 + \\frac{\\Delta r}{2r_i}\\right)\\phi_{i+1,j} - 2\\phi_{i,j} + \\left(1 - \\frac{\\Delta r}{2r_i}\\right)\\phi_{i-1,j} \\right] $$\nThis is the required second-order accurate finite-difference approximation for the radial part.\n\n**Complete Discrete Equation:**\nThe full discrete Laplace equation, $\\mathcal{L}_h[\\phi]_{i,j} = 0$, is the sum of the discrete radial and angular terms:\n$$ \\mathcal{L}_h[\\phi]_{i,j} = \\frac{1}{(\\Delta r)^2} \\left[ \\left(1 + \\frac{\\Delta r}{2r_i}\\right)\\phi_{i+1,j} + \\left(1 - \\frac{\\Delta r}{2r_i}\\right)\\phi_{i-1,j} - 2\\phi_{i,j} \\right] + \\frac{1}{r_i^2 (\\Delta\\theta)^2} [\\phi_{i,j+1} + \\phi_{i,j-1} - 2\\phi_{i,j}] = 0 $$\n\n### 2. Successive Over-Relaxation (SOR) Algorithm\nThe discrete equation defines a large system of linear equations for the unknown potential values $\\phi_{i,j}$ at interior grid points. We solve this system using SOR. To derive the SOR update rule, we first isolate $\\phi_{i,j}$ from the discrete equation:\n$$ \\left( \\frac{2}{(\\Delta r)^2} + \\frac{2}{r_i^2 (\\Delta\\theta)^2} \\right) \\phi_{i,j} = \\frac{\\left(1 + \\frac{\\Delta r}{2r_i}\\right)}{(\\Delta r)^2}\\phi_{i+1,j} + \\frac{\\left(1 - \\frac{\\Delta r}{2r_i}\\right)}{(\\Delta r)^2}\\phi_{i-1,j} + \\frac{1}{r_i^2 (\\Delta\\theta)^2}(\\phi_{i,j+1} + \\phi_{i,j-1}) $$\nA Gauss-Seidel iteration updates $\\phi_{i,j}$ to a new value, $\\phi_{i,j}^{\\text{GS}}$, that solves this equation using the most recently computed values for its neighbors. Iterating over points in lexicographical order (increasing $i$, then increasing $j$), the update uses $\\phi_{i-1,j}^{\\text{new}}$, $\\phi_{i,j-1}^{\\text{new}}$, $\\phi_{i+1,j}^{\\text{old}}$, and $\\phi_{i,j+1}^{\\text{old}}$. The value $\\phi_{i,j}^{\\text{GS}}$ is:\n$$ \\phi_{i,j}^{\\text{GS}} = \\frac{ \\frac{1}{(\\Delta r)^2} \\left[ \\left(1 + \\frac{\\Delta r}{2r_i}\\right)\\phi_{i+1,j} + \\left(1 - \\frac{\\Delta r}{2r_i}\\right)\\phi_{i-1,j} \\right] + \\frac{1}{r_i^2 (\\Delta\\theta)^2} (\\phi_{i,j+1} + \\phi_{i,j-1}) } { \\frac{2}{(\\Delta r)^2} + \\frac{2}{r_i^2 (\\Delta\\theta)^2} } $$\nThe SOR method modifies this by introducing a relaxation factor $\\omega$. The new value $\\phi_{i,j}^{(k+1)}$ at iteration $k+1$ is a weighted average of the old value $\\phi_{i,j}^{(k)}$ and the Gauss-Seidel update:\n$$ \\phi_{i,j}^{(k+1)} = (1-\\omega)\\phi_{i,j}^{(k)} + \\omega\\,\\phi_{i,j}^{\\text{GS}} $$\nFor this problem, $\\omega = 1.85$. The iteration proceeds by sweeping through all interior grid points $(i, j)$ for $i \\in \\{1,...,N_r-2\\}$ and $j \\in \\{0,...,N_\\theta-1\\}$, applying this update rule at each point.\n\n### 3. Implementation and Convergence\nThe algorithm is implemented as follows:\n1.  **Grid and Initialization**: An $N_r \\times N_\\theta$ array is created for $\\phi$. The boundary values are set according to the Dirichlet conditions at $r=r_{\\mathrm{in}}$ ($i=0$) and $r=r_{\\mathrm{out}}$ ($i=N_r-1$). Interior points are initialized to $0$.\n2.  **Iteration**: A loop runs for a maximum of $N_{\\mathrm{it,max}}=50000$ iterations.\n3.  **SOR Sweep**: Inside the loop, a full sweep over all interior points is performed, updating $\\phi_{i,j}$ using the SOR formula. Periodicity in $\\theta$ is handled by using modulo arithmetic for the $j$ index (e.g., $j-1$ becomes $N_\\theta-1$ if $j=0$).\n4.  **Convergence Check**: After each full SOR sweep, the discrete residual $\\mathcal{L}_h[\\phi]_{i,j}$ is calculated for all interior points using the newly updated field $\\phi$. The $\\ell_\\infty$-norm of the residual, $\\max_{i,j} |\\mathcal{L}_h[\\phi]_{i,j}|$, is computed. If this norm is less than the tolerance $\\varepsilon = 10^{-8}$, the iteration terminates.\n5.  **Error Calculation**: Upon convergence, the numerical solution $\\phi_{i,j}$ is compared against the provided analytic solution $\\phi_{\\mathrm{exact}}(r_i, \\theta_j)$. The maximum absolute error, $E_{\\max} = \\max_{i,j} |\\phi_{i,j} - \\phi_{\\mathrm{exact}}(r_i, \\theta_j)|$, is computed over the entire grid, including boundaries.\n\nThis procedure is applied to each test case specified in the problem statement. The resulting maximum errors are collected and formatted as the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_case(r_in, r_out, N_r, N_theta, bc_in_func, bc_out_func, analytic_func, omega, epsilon, n_it_max):\n    \"\"\"\n    Solves the Laplace equation on an annulus using the SOR method for a single test case.\n    \"\"\"\n    # 1. Grid and Parameter Setup\n    dr = (r_out - r_in) / (N_r - 1)\n    dth = 2 * np.pi / N_theta\n    \n    r = np.linspace(r_in, r_out, N_r)\n    theta = np.linspace(0, 2 * np.pi, N_theta, endpoint=False)\n    \n    # 2D potential grid\n    phi = np.zeros((N_r, N_theta))\n    \n    # 2. Boundary Conditions\n    phi[0, :] = bc_in_func(r_in, theta)\n    phi[-1, :] = bc_out_func(r_out, theta)\n    \n    # Pre-calculate some inverse values for efficiency in loops\n    dr2_inv = 1.0 / (dr**2)\n    dth2_inv = 1.0 / (dth**2)\n\n    # 3. SOR Iteration Loop\n    for k in range(n_it_max):\n        # --- SOR Sweep ---\n        for i in range(1, N_r - 1):\n            # Coefficients that depend on r_i\n            ri = r[i]\n            ri_inv = 1.0 / ri\n            \n            coeff_ip1 = dr2_inv * (1.0 + 0.5 * dr * ri_inv)\n            coeff_im1 = dr2_inv * (1.0 - 0.5 * dr * ri_inv)\n            coeff_j_term = dth2_inv * ri_inv**2\n            \n            # Denominator of the Gauss-Seidel update term\n            den = 2.0 * dr2_inv + 2.0 * coeff_j_term\n            den_inv = 1.0 / den\n\n            for j in range(N_theta):\n                # Periodic boundary conditions in theta\n                j_plus_1 = (j + 1) % N_theta\n                j_minus_1 = (j - 1 + N_theta) % N_theta\n                \n                # Neighbors' values (using most recent updates for i-1 and j-1)\n                term_neighbors = (coeff_ip1 * phi[i + 1, j] +\n                                  coeff_im1 * phi[i - 1, j] +\n                                  coeff_j_term * (phi[i, j_plus_1] + phi[i, j_minus_1]))\n                \n                # Gauss-Seidel update value\n                phi_gs = term_neighbors * den_inv\n                \n                # SOR update\n                phi[i, j] = (1.0 - omega) * phi[i, j] + omega * phi_gs\n\n        # --- Convergence Check using Residual ---\n        max_residual = 0.0\n        for i in range(1, N_r - 1):\n            ri = r[i]\n            # Vectorized calculation for all theta points at a given radius\n            phi_i = phi[i, :]\n            phi_ip1 = phi[i+1, :]\n            phi_im1 = phi[i-1, :]\n            phi_jp1 = np.roll(phi_i, -1)\n            phi_jm1 = np.roll(phi_i, 1)\n\n            radial_term = ((1.0 + 0.5 * dr / ri) * phi_ip1 + \n                           (1.0 - 0.5 * dr / ri) * phi_im1 - \n                           2.0 * phi_i) / (dr**2)\n            angular_term = (phi_jp1 + phi_jm1 - 2.0 * phi_i) / (ri**2 * dth**2)\n            \n            residual_at_i = radial_term + angular_term\n            max_residual = max(max_residual, np.max(np.abs(residual_at_i)))\n            \n        if max_residual  epsilon:\n            break\n\n    # 4. Error Calculation\n    R_grid, THETA_grid = np.meshgrid(r, theta, indexing='ij')\n    phi_exact = analytic_func(R_grid, THETA_grid)\n    \n    max_abs_error = np.max(np.abs(phi - phi_exact))\n    \n    return max_abs_error\n\ndef solve():\n    # Define common parameters for the SOR solver\n    omega = 1.85\n    epsilon = 1e-8\n    n_it_max = 50000\n\n    # Test Case 1\n    case1_params = {\n        \"r_in\": 1.0, \"r_out\": 2.0, \"N_r\": 32, \"N_theta\": 64,\n        \"bc_in_func\": lambda r, th: np.zeros_like(th),\n        \"bc_out_func\": lambda r, th: np.ones_like(th),\n        \"analytic_func\": lambda r, th: (np.log(r) - np.log(1.0)) / (np.log(2.0) - np.log(1.0)),\n        \"omega\": omega, \"epsilon\": epsilon, \"n_it_max\": n_it_max\n    }\n\n    # Test Case 2\n    r_in_c2, r_out_c2, n_c2 = 1.0, 2.0, 3\n    a_c2 = 1.0 / (r_out_c2**n_c2 - r_in_c2**(2*n_c2) * r_out_c2**(-n_c2))\n    b_c2 = -a_c2 * r_in_c2**(2*n_c2)\n    case2_params = {\n        \"r_in\": r_in_c2, \"r_out\": r_out_c2, \"N_r\": 32, \"N_theta\": 64,\n        \"bc_in_func\": lambda r, th: np.zeros_like(th),\n        \"bc_out_func\": lambda r, th: np.cos(n_c2 * th),\n        \"analytic_func\": lambda r, th: (a_c2 * r**n_c2 + b_c2 * r**(-n_c2)) * np.cos(n_c2 * th),\n        \"omega\": omega, \"epsilon\": epsilon, \"n_it_max\": n_it_max\n    }\n\n    # Test Case 3\n    r_in_c3, r_out_c3 = 0.5, 0.6\n    case3_params = {\n        \"r_in\": r_in_c3, \"r_out\": r_out_c3, \"N_r\": 16, \"N_theta\": 64,\n        \"bc_in_func\": lambda r, th: np.zeros_like(th),\n        \"bc_out_func\": lambda r, th: np.ones_like(th),\n        \"analytic_func\": lambda r, th: (np.log(r) - np.log(r_in_c3)) / (np.log(r_out_c3) - np.log(r_in_c3)),\n        \"omega\": omega, \"epsilon\": epsilon, \"n_it_max\": n_it_max\n    }\n    \n    test_cases = [case1_params, case2_params, case3_params]\n    results = []\n    \n    for params in test_cases:\n        error = solve_case(**params)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Many phenomena in elasticity and fluid dynamics are governed by higher-order partial differential equations, such as the biharmonic equation, $\\nabla^4 \\psi = 0$. This exercise introduces a powerful and widely-used strategy for tackling such problems: the method of splitting. You will decompose the single fourth-order PDE into a coupled system of two second-order Poisson-type equations, which can then be solved sequentially using the relaxation methods you have already developed. This advanced practice demonstrates the versatility of your toolkit and introduces professional development techniques, including the use of a manufactured solution for robust code verification and the optimized red-black ordering for the SOR algorithm .",
            "id": "2434002",
            "problem": "Consider the two-dimensional biharmonic equation on the unit square domain $\\Omega = [0,1]\\times[0,1]$ with spatial coordinates $(x,y)$:\n$$\\nabla^4 \\psi(x,y) = 0 \\quad \\text{in } \\Omega.$$\nIntroduce the auxiliary variable $\\phi(x,y)$ defined by the fundamental identity $\\phi = \\nabla^2 \\psi$. This splits the biharmonic equation into the coupled elliptic system\n$$\\nabla^2 \\phi(x,y) = 0 \\quad \\text{in } \\Omega, \\qquad \\nabla^2 \\psi(x,y) = \\phi(x,y) \\quad \\text{in } \\Omega.$$\nYou will solve this system by relaxation methods on a uniform Cartesian grid using second-order finite differences and Successive Over-Relaxation (SOR), a specific acceleration of the Gauss–Seidel fixed-point iteration.\n\nYour tasks are as follows.\n\n1) Modeling and boundary data via a manufactured solution. Start from the foundational definitions of the Laplacian $\\nabla^2$ and the biharmonic operator $\\nabla^4 = \\nabla^2(\\nabla^2)$, and the identity $\\phi = \\nabla^2 \\psi$. Consider the smooth functions\n$$\\psi^\\star(x,y) = \\frac{x^4 - y^4}{12}, \\qquad \\phi^\\star(x,y) = x^2 - y^2.$$\nVerify from first principles that $\\nabla^2 \\phi^\\star(x,y) = 0$ and $\\nabla^2 \\psi^\\star(x,y) = \\phi^\\star(x,y)$, and hence that $\\psi^\\star$ is biharmonic, that is $\\nabla^4 \\psi^\\star = 0$. Impose Dirichlet data\n$$\\psi(x,y)\\big|_{\\partial\\Omega} = \\psi^\\star(x,y), \\qquad \\phi(x,y)\\big|_{\\partial\\Omega} = \\phi^\\star(x,y),$$\nso that the exact interior solutions coincide with $\\psi^\\star$ and $\\phi^\\star$ at the continuum level.\n\n2) Discretization from Taylor expansions. Let the grid consist of $M$ interior points per coordinate direction and a uniform spacing $h = 1/(M+1)$. Denote by $u_{i,j}$ a grid function defined on the full grid indices $i,j \\in \\{0,1,\\dots,M+1\\}$, where values at $i=0,M+1$ or $j=0,M+1$ lie on the boundary and interior indices are $i,j \\in \\{1,\\dots,M\\}$. Using Taylor expansions about $(x_i,y_j)$ up to second order and the core definition of second derivatives, derive the standard five-point discrete Laplacian\n$$\\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} \\approx \\left(\\nabla^2 u\\right)(x_i,y_j),$$\nwith a truncation error of order $\\mathcal{O}(h^2)$. Apply this to the model equations to obtain the discrete Laplace equation for $\\phi$ and the discrete Poisson equation for $\\psi$ with Dirichlet boundary values taken from $\\phi^\\star$ and $\\psi^\\star$.\n\n3) Relaxation algorithm. Starting from the discrete equations and the fixed-point idea that the new iterate matches the average of neighbors adjusted by the source term, derive the in-place Gauss–Seidel update and then the Successive Over-Relaxation (SOR) update with relaxation parameter $\\omega \\in (0,2)$. Implement a red–black SOR scheme (checkerboard ordering) that alternates updates over interior points with parity $(i+j) \\bmod 2 = 0$ and $(i+j) \\bmod 2 = 1$ to exploit data locality and improve convergence. Use the discrete residual\n$$r_{i,j} = f_{i,j} - \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2}$$\nas the stopping criterion, and terminate a solve when the maximum norm of the residual over interior points is less than or equal to a specified tolerance $\\tau$.\n\n4) Algorithmic workflow. For each test case: \n- Initialize the grid, set the boundary values for $\\phi$ to $\\phi^\\star$ and for $\\psi$ to $\\psi^\\star$, set interior initial guesses to $0$, and set $f\\equiv 0$ for the $\\phi$-solve.\n- Solve the discrete Laplace equation for $\\phi$ with red–black SOR until the residual maximum norm is below the tolerance $\\tau$.\n- Set the discrete source for the $\\psi$-solve to the converged interior values of $\\phi$ and solve the discrete Poisson equation for $\\psi$ with red–black SOR until the residual maximum norm is below $\\tau$.\n- Compute the maximum absolute error of $\\psi$ at interior points against the manufactured solution $\\psi^\\star$:\n$$E_\\infty = \\max_{1 \\le i,j \\le M} \\left| \\psi_{i,j} - \\psi^\\star(x_i,y_j) \\right|.$$\n\n5) Test suite. Your program must run the following four test cases and report, in order, the interior maximum absolute error $E_\\infty$ for $\\psi$ for each case:\n- Case A (happy path): $M = 8$, $\\omega = 1.8$, $\\tau = 1\\times 10^{-10}$.\n- Case B (minimal interior): $M = 1$, $\\omega = 1.5$, $\\tau = 1\\times 10^{-12}$.\n- Case C (refined grid): $M = 16$, $\\omega = 1.9$, $\\tau = 1\\times 10^{-10}$.\n- Case D (larger grid, aggressive relaxation): $M = 32$, $\\omega = 1.95$, $\\tau = 1\\times 10^{-9}$.\n\nUse a fixed maximum number of iterations per solve of $K_{\\max} = 20000$ to guarantee termination even if the tolerance is not met, and use the same $\\tau$ for both the $\\phi$-solve and the $\\psi$-solve within each test case.\n\n6) Final output format. Your program should produce a single line of output containing the four results as a comma-separated list enclosed in square brackets, in the order A, B, C, D, for example\n`[E_A,E_B,E_C,E_D]`,\nwhere each $E_\\bullet$ is a decimal real number.\n\nNo physical units or angles are involved in this problem, so no unit conversion is required. The numerical quantities reported are dimensionless real numbers.",
            "solution": "The problem presented is a well-posed exercise in computational physics, requiring the numerical solution of the two-dimensional biharmonic equation using a standard decomposition and an iterative relaxation method. The problem statement is scientifically sound, mathematically consistent, and provides all necessary data for a unique solution. We shall proceed with the derivation and implementation as specified.\n\nThe problem first demands a verification of the provided manufactured solution. The governing equations are the coupled system:\n$$\n\\nabla^2 \\phi(x,y) = 0 \\quad (1)\n$$\n$$\n\\nabla^2 \\psi(x,y) = \\phi(x,y) \\quad (2)\n$$\nThe proposed exact solutions are $\\psi^\\star(x,y) = \\frac{x^4 - y^4}{12}$ and $\\phi^\\star(x,y) = x^2 - y^2$. We must verify these functions satisfy the system.\n\nFirst, we compute the Laplacian of $\\phi^\\star(x,y)$:\n$$\n\\frac{\\partial \\phi^\\star}{\\partial x} = 2x \\implies \\frac{\\partial^2 \\phi^\\star}{\\partial x^2} = 2\n$$\n$$\n\\frac{\\partial \\phi^\\star}{\\partial y} = -2y \\implies \\frac{\\partial^2 \\phi^\\star}{\\partial y^2} = -2\n$$\n$$\n\\nabla^2 \\phi^\\star = \\frac{\\partial^2 \\phi^\\star}{\\partial x^2} + \\frac{\\partial^2 \\phi^\\star}{\\partial y^2} = 2 + (-2) = 0\n$$\nThis confirms that $\\phi^\\star(x,y)$ satisfies equation (1). It is a harmonic function.\n\nNext, we compute the Laplacian of $\\psi^\\star(x,y)$:\n$$\n\\frac{\\partial \\psi^\\star}{\\partial x} = \\frac{4x^3}{12} = \\frac{x^3}{3} \\implies \\frac{\\partial^2 \\psi^\\star}{\\partial x^2} = x^2\n$$\n$$\n\\frac{\\partial \\psi^\\star}{\\partial y} = \\frac{-4y^3}{12} = -\\frac{y^3}{3} \\implies \\frac{\\partial^2 \\psi^\\star}{\\partial y^2} = -y^2\n$$\n$$\n\\nabla^2 \\psi^\\star = \\frac{\\partial^2 \\psi^\\star}{\\partial x^2} + \\frac{\\partial^2 \\psi^\\star}{\\partial y^2} = x^2 - y^2\n$$\nWe observe that $\\nabla^2 \\psi^\\star = \\phi^\\star(x,y)$, which confirms that $\\psi^\\star(x,y)$ satisfies equation (2) with $\\phi = \\phi^\\star$. Consequently, $\\psi^\\star$ is biharmonic, as $\\nabla^4 \\psi^\\star = \\nabla^2(\\nabla^2 \\psi^\\star) = \\nabla^2 \\phi^\\star = 0$. The manufactured solution is correct.\n\nThe next step is the discretization of the Laplacian operator. We use Taylor series expansions for a grid function $u(x,y)$ around a point $(x_i, y_j)$. For the $x$-direction:\n$$\nu(x_i+h, y_j) = u_{i+1,j} = u_{i,j} + h \\frac{\\partial u}{\\partial x} \\bigg|_{i,j} + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} + \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\n$$\nu(x_i-h, y_j) = u_{i-1,j} = u_{i,j} - h \\frac{\\partial u}{\\partial x} \\bigg|_{i,j} + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} - \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\nAdding these two expansions cancels the odd-order derivative terms:\n$$\nu_{i+1,j} + u_{i-1,j} = 2u_{i,j} + h^2 \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\nRearranging gives the second-order central difference approximation for the second partial derivative with respect to $x$:\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\mathcal{O}(h^2)\n$$\nAn analogous expression holds for the $y$-direction:\n$$\n\\frac{\\partial^2 u}{\\partial y^2} \\bigg|_{i,j} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + \\mathcal{O}(h^2)\n$$\nSumming these two expressions yields the five-point stencil for the discrete Laplacian operator $\\nabla_h^2$:\n$$\n(\\nabla_h^2 u)_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} \\approx (\\nabla^2 u)(x_i, y_j)\n$$\nThe truncation error of this approximation is of order $\\mathcal{O}(h^2)$. Applying this to the coupled system, for interior grid points $(i,j)$ where $i,j \\in \\{1,...,M\\}$, gives:\n$$\n\\frac{\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1} - 4\\phi_{i,j}}{h^2} = 0 \\quad (3)\n$$\n$$\n\\frac{\\psi_{i+1,j} + \\psi_{i-1,j} + \\psi_{i,j+1} + \\psi_{i,j-1} - 4\\psi_{i,j}}{h^2} = \\phi_{i,j} \\quad (4)\n$$\nThese are the discrete equations to be solved. For a generic discrete Poisson equation $(\\nabla_h^2 u)_{i,j} = f_{i,j}$, we can write a fixed-point iteration by isolating $u_{i,j}$:\n$$\n4u_{i,j} = u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j}\n$$\nThe Gauss-Seidel method updates $u_{i,j}$ in-place using the most recently computed values of its neighbors:\n$$\nu_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(\\text{old})} + u_{i-1,j}^{(\\text{new})} + u_{i,j+1}^{(\\text{old})} + u_{i,j-1}^{(\\text{new})} - h^2 f_{i,j} \\right)\n$$\nwhere the choice of \"new\" and \"old\" neighbor values depends on the sweep order. The Successive Over-Relaxation (SOR) method accelerates convergence by introducing a relaxation parameter $\\omega$. The SOR update for $u_{i,j}$ is a weighted average of its current value and the Gauss-Seidel update:\n$$\nu_{i,j}^{(k+1)} = (1-\\omega) u_{i,j}^{(k)} + \\omega \\left[ \\frac{1}{4} \\left( \\dots \\right) \\right]\n$$\nwhere the term in brackets is the Gauss-Seidel update value, which we denote $\\tilde{u}_{i,j}^{(k+1)}$. The full SOR update expression is:\n$$\nu_{i,j} \\leftarrow (1-\\omega) u_{i,j} + \\frac{\\omega}{4} \\left( u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j} \\right)\n$$\nThe red-black ordering scheme partitions the grid points into two sets: 'red' for points where $(i+j)$ is even, and 'black' for points where $(i+j)$ is odd. Crucially, all neighbors of a red point are black, and vice versa. This allows for updating all red points simultaneously using only the values from the black points from the previous iteration step. Then, all black points are updated simultaneously using the newly computed red point values. This two-sweep process constitutes one full SOR iteration and is amenable to vectorization.\n\nThe stopping criterion is based on the discrete residual, $r_{i,j} = f_{i,j} - (\\nabla_h^2 u)_{i,j}$. The iteration for a given field terminates when the maximum absolute value of its residual over all interior points falls below a tolerance $\\tau$: $\\|\\mathbf{r}\\|_\\infty = \\max_{1 \\le i,j \\le M} |r_{i,j}| \\le \\tau$.\n\nThe overall algorithm proceeds as follows:\n1.  Initialize grids for $\\phi$ and $\\psi$ of size $(M+2) \\times (M+2)$. Set boundary values on these grids using the exact functions $\\phi^\\star(x,y)$ and $\\psi^\\star(x,y)$. Initialize all interior points to $0$.\n2.  Solve the discrete Laplace equation for $\\phi$ (equation (3), where $f_{i,j}=0$). Use red-black SOR with the specified $\\omega$, iterating until the residual norm is below $\\tau$ or the maximum number of iterations $K_{\\max}$ is reached.\n3.  Solve the discrete Poisson equation for $\\psi$ (equation (4)). The source term is the converged interior solution for $\\phi$ obtained in the previous step. Use red-black SOR with the same $\\omega$ and $\\tau$ until convergence.\n4.  After the $\\psi$ field has converged, compute the maximum absolute error $E_\\infty = \\max_{1 \\le i,j \\le M} |\\psi_{i,j} - \\psi^\\star(x_i, y_j)|$.\n\nThis procedure is repeated for each test case specified in the problem statement. The final implementation will follow this logic precisely.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy  # Per environment specification, though not used in the logic.\n\ndef solve_system(M, omega, tau, k_max):\n    \"\"\"\n    Solves the coupled elliptic system for a given set of parameters.\n\n    Args:\n        M (int): Number of interior points per dimension.\n        omega (float): SOR relaxation parameter.\n        tau (float): Convergence tolerance for the residual.\n        k_max (int): Maximum number of iterations.\n\n    Returns:\n        float: The maximum absolute error E_infty for psi.\n    \"\"\"\n    # 1. Grid setup\n    h = 1.0 / (M + 1)\n    # Grid coordinates, including boundaries\n    grid_coords = np.linspace(0.0, 1.0, M + 2)\n    x, y = np.meshgrid(grid_coords, grid_coords)\n\n    # Manufactured solutions\n    def phi_star_func(x_val, y_val):\n        return x_val**2 - y_val**2\n    \n    def psi_star_func(x_val, y_val):\n        return (x_val**4 - y_val**4) / 12.0\n\n    # Initialize fields phi and psi\n    phi = np.zeros((M + 2, M + 2), dtype=np.float64)\n    psi = np.zeros((M + 2, M + 2), dtype=np.float64)\n\n    # Set boundary conditions\n    phi = phi_star_func(x, y)\n    psi = psi_star_func(x, y)\n    \n    # Set interior initial guess to 0\n    phi[1:-1, 1:-1] = 0.0\n    psi[1:-1, 1:-1] = 0.0\n    \n    h2 = h * h\n\n    # 2. Solve for phi (Laplace equation: nabla^2 phi = 0)\n    for k in range(k_max):\n        # Red-black SOR update for phi\n        # Red points (i+j is even)\n        phi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 0,\n                                   (1 - omega) * phi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       phi[2:, 1:-1] + phi[:-2, 1:-1] +\n                                       phi[1:-1, 2:] + phi[1:-1, :-2]),\n                                   phi[1:-1, 1:-1])\n        # Black points (i+j is odd)\n        phi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 1,\n                                   (1 - omega) * phi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       phi[2:, 1:-1] + phi[:-2, 1:-1] +\n                                       phi[1:-1, 2:] + phi[1:-1, :-2]),\n                                   phi[1:-1, 1:-1])\n\n        # Check for convergence\n        if k % 10 == 0:  # Check residual periodically\n            residual = (phi[2:, 1:-1] + phi[:-2, 1:-1] + phi[1:-1, 2:] + phi[1:-1, :-2] - 4 * phi[1:-1, 1:-1]) / h2\n            if np.max(np.abs(residual)) = tau:\n                break\n    \n    # 3. Solve for psi (Poisson equation: nabla^2 psi = phi)\n    f_psi = phi[1:-1, 1:-1].copy() # Source term is the interior phi\n    \n    for k in range(k_max):\n        # Red-black SOR update for psi\n        # Red points\n        psi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 0,\n                                   (1 - omega) * psi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       psi[2:, 1:-1] + psi[:-2, 1:-1] +\n                                       psi[1:-1, 2:] + psi[1:-1, :-2] - h2 * f_psi),\n                                   psi[1:-1, 1:-1])\n        # Black points\n        psi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 1,\n                                   (1 - omega) * psi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       psi[2:, 1:-1] + psi[:-2, 1:-1] +\n                                       psi[1:-1, 2:] + psi[1:-1, :-2] - h2 * f_psi),\n                                   psi[1:-1, 1:-1])\n\n        # Check for convergence\n        if k % 10 == 0:\n            residual = f_psi - (psi[2:, 1:-1] + psi[:-2, 1:-1] + psi[1:-1, 2:] + psi[1:-1, :-2] - 4 * psi[1:-1, 1:-1]) / h2\n            if np.max(np.abs(residual)) = tau:\n                break\n\n    # 4. Compute final error E_infty\n    x_interior = grid_coords[1:-1]\n    y_interior = grid_coords[1:-1]\n    xv_int, yv_int = np.meshgrid(x_interior, y_interior)\n    psi_exact_interior = psi_star_func(xv_int, yv_int)\n    \n    psi_numeric_interior = psi[1:-1, 1:-1]\n    \n    error = np.max(np.abs(psi_numeric_interior - psi_exact_interior))\n    \n    return error\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, 1.8, 1e-10),   # Case A\n        (1, 1.5, 1e-12),   # Case B\n        (16, 1.9, 1e-10),  # Case C\n        (32, 1.95, 1e-9), # Case D\n    ]\n    \n    k_max = 20000\n    results = []\n    \n    for case in test_cases:\n        M, omega, tau = case\n        result = solve_system(M, omega, tau, k_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}