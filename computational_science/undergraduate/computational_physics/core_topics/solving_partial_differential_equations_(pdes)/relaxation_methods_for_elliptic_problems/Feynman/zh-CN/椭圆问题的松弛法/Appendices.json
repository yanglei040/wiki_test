{
    "hands_on_practices": [
        {
            "introduction": "我们的第一个实践练习将探讨雅可比方法，这是最直观的松弛方法之一。通过为一个二维泊松方程实现一个模拟图形处理器（GPU）行为的求解器，您将亲身体验到该方法内在的并行性。此练习旨在阐明为什么像雅可比这样的同步更新方案非常适合现代并行计算架构，同时将理论收敛分析与实际的数值实验联系起来 。",
            "id": "2433927",
            "problem": "你的任务是设计并实现一个同步松弛求解器，用于求解一个典型的椭圆边界值问题，该求解器需模拟图形处理单元 (GPU) 的执行模型。所述物理问题是在单位正方形上的具有齐次 Dirichlet 边界条件的二维泊松方程。你的实现必须模拟 GPU 内核的行为，其中每个线程并行更新一个网格点，且所有更新均同步发生。由于此项任务的执行环境是中央处理器 (CPU)，你必须通过对整个内部网格应用单个向量化更新来模拟 GPU，而不是使用逐网格点的 Python 循环。你必须使用 Jacobi 方法，并明确避免在一次迭代中对内部值进行原地更新。在首次提及时，定义 OpenGL Shading Language (GLSL) 和 Compute Unified Device Architecture (CUDA)：OpenGL Shading Language (GLSL) 和 Compute Unified Device Architecture (CUDA)。\n\n从基本原理出发：使用均匀笛卡尔网格和拉普拉斯算子的标准五点差分格式对偏微分方程进行离散化，并由此离散化推导出 Jacobi 方法的同步点更新法则。设区域为 $\\Omega = [0,1]\\times[0,1]$，每个坐标方向的内部点数为 $N$，定义网格间距为 $h = \\frac{1}{N+1}$。设 $u(x,y)$ 表示精确解，$f(x,y)$ 表示源项，满足\n$$\n\\nabla^2 u(x,y) = f(x,y)\\quad \\text{for}\\ (x,y)\\in \\Omega,\n$$\n$$\nu(x,y)=0\\quad \\text{for}\\ (x,y)\\in \\partial\\Omega.\n$$\n设 $u_{i,j}$ 表示网格点 $(x_i,y_j)$ 处的离散未知数，其中 $x_i = i h$ 且 $y_j = j h$，对于 $i,j\\in\\{0,1,\\dots,N+1\\}$，边界值满足 $u_{i,0}=u_{i,N+1}=u_{0,j}=u_{N+1,j}=0$。请从基本原理推导出同步 Jacobi 更新法则，该法则仅使用上一次迭代的相邻值和源项。解释为什么同步更新对于 GPU 上的单指令多线程 (SIMT) 执行模型是自然的。\n\n实现一个程序，该程序：\n- 为给定的源 $f(x,y)$ 构建离散的右端项 $f_{i,j}$。\n- 将所有内部点 $(i,j)$ 的初始状态初始化为 $u_{i,j}^{(0)}=0$。\n- 迭代 Jacobi 方法，直到残差的离散 $\\ell^2$-范数，\n$$\n\\|r^{(k)}\\|_{2,h} = \\left(h^2 \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\left(f_{i,j} - (A u^{(k)})_{i,j}\\right)^2\\right)^{1/2},\n$$\n小于指定的容差 $\\varepsilon$ 或达到最大迭代次数 $k_{\\max}$。此处 $(A u)_{i,j}$ 是应用于 $u$ 的五点离散拉普拉斯算子，并且三角函数中使用的所有角度必须是弧度制。\n- 根据最后可用的比率 $\\|r^{(k)}\\|_{2,h} / \\|r^{(k-1)}\\|_{2,h}$ 估计渐进收敛因子 $\\hat{q}$，对最多最近 $10$ 次同时定义了 $\\|r^{(k)}\\|_{2,h}$ 和 $\\|r^{(k-1)}\\|_{2,h}$ 的迭代进行平均。如果迭代次数少于 2 次，则定义 $\\hat{q}=0$。\n- 通过分析均匀网格上迭代算子的特征模态，计算此问题上 Jacobi 迭代的理论渐进收敛因子 $q$。不要在没有证明的情况下假设任何关于 $q$ 的公式；$q$ 的值必须在你的解中从基本原理计算得出，并在你的代码中使用你推导出的表达式进行实现。\n\n除了残差范数，当精确解 $u(x,y)$ 已知时，计算离散 $\\ell^2$-误差\n$$\n\\|e^{(k)}\\|_{2,h} = \\left(h^2 \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\left(u_{i,j}^{(k)} - u(x_i,y_j)\\right)^2\\right)^{1/2}.\n$$\n\n测试套件。你的程序必须运行以下三个测试案例并汇总它们的结果：\n- 案例 A (正常路径)：$N=15$, $f(x,y)=-2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$，精确解 $u(x,y)=\\sin(\\pi x)\\sin(\\pi y)$，容差 $\\varepsilon=10^{-8}$，$k_{\\max}=10000$。\n- 案例 B (更大网格)：$N=31$，与案例 A 相同的 $f$ 和精确解，容差 $\\varepsilon=10^{-6}$，$k_{\\max}=100000$。\n- 案例 C (边界条件边缘情况)：$N=15$，$f(x,y)=0$ 且精确解 $u(x,y)=0$，容差 $\\varepsilon=10^{-12}$，$k_{\\max}=1000$。\n\n对于每个案例，你的程序必须按以下顺序输出一个包含五个值的列表：\n$[k_{\\text{it}}, \\|r^{(k)}\\|_{2,h}, \\|e^{(k)}\\|_{2,h}, \\hat{q}, q]$，其中 $k_{\\text{it}}$ 是实际执行的 Jacobi 迭代次数，$\\|r^{(k)}\\|_{2,h}$ 是最终残差范数，$\\|e^{(k)}\\|_{2,h}$ 是最终误差范数（当无解析解时使用 $0$），$\\hat{q}$ 是经验收敛因子估计值，而 $q$ 是从你的分析中推导出的理论因子。\n\n最终输出格式。你的程序应生成单行输出，其中包含三个案例的结果，格式为逗号分隔的列表的列表，数值条目四舍五入到六位有效数字，且无多余字符或空格。例如，最后一行必须如下所示：\n$[[k_1,r_1,e_1,\\hat{q}_1,q_1],[k_2,r_2,e_2,\\hat{q}_2,q_2],[k_3,r_3,e_3,\\hat{q}_3,q_3]]$\n其中每个 $k_i$ 为整数，每个 $r_i$, $e_i$, $\\hat{q}_i$, $q_i$ 为浮点数。所有三角函数求值中使用的角度单位必须是弧度。",
            "solution": "所提出的问题是有效的；这是一个关于椭圆偏微分方程数值解的计算物理学中的标准、适定的练习。它具有科学依据，内部一致，并包含获得唯一数值解所需的所有必要信息。我们将着手进行推导和实现。\n\n首先，我们必须按要求定义所提到的计算架构。OpenGL Shading Language (GLSL) 是一种高级着色语言，其语法基于C语言。它用于创建在图形处理单元 (GPU) 上作为图形管线一部分执行的程序，即着色器 (shader)。Compute Unified Device Architecture (CUDA) 是由 Nvidia 创建的一个专有的并行计算平台和应用程序编程接口 (API) 模型。它允许软件开发人员使用支持 CUDA 的 GPU 进行通用目的处理，这种方法被称为 GPGPU (基于图形处理器的通用计算)。\n\n问题的核心是在单位正方形 $\\Omega = [0,1]\\times[0,1]$ 上求解具有齐次 Dirichlet 边界条件的二维泊松方程：\n$$\n\\nabla^2 u(x,y) = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = f(x,y) \\quad \\text{for } (x,y) \\in \\Omega\n$$\n$$\nu(x,y) = 0 \\quad \\text{for } (x,y) \\in \\partial\\Omega\n$$\n我们使用一个在每个方向上有 $N$ 个内部点的均匀笛卡尔网格来离散化区域 $\\Omega$。网格间距为 $h = \\frac{1}{N+1}$。网格点为 $(x_i, y_j)$，其中对于整数 $i, j \\in \\{0, 1, \\dots, N+1\\}$，$x_i = ih$ 且 $y_j = jh$。在这些点上的离散解用 $u_{i,j}$ 表示。边界条件意味着 $u_{i,0} = u_{i,N+1} = u_{0,j} = u_{N+1,j} = 0$。\n\n为了离散化拉普拉斯算子 $\\nabla^2$，我们使用从泰勒级数展开推导出的二阶精确中心有限差分：\n$$\n\\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{(x_i,y_j)} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\mathcal{O}(h^2)\n$$\n$$\n\\frac{\\partial^2 u}{\\partial y^2}\\bigg|_{(x_i,y_j)} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + \\mathcal{O}(h^2)\n$$\n将这些代入泊松方程，得到每个内部网格点 $(i,j)$（其中 $i,j \\in \\{1, \\dots, N\\}$）的五点差分格式离散方程：\n$$\n\\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} = f_{i,j}\n$$\n这是一个包含 $N^2$ 个线性方程的大型稀疏方程组，用于求解 $N^2$ 个未知的内部值 $u_{i,j}$。为了迭代求解这个系统，我们通过分离出项 $u_{i,j}$ 并引入迭代指数 $k$ 来推导 Jacobi 方法：\n$$\n4u_{i,j} = u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j}\n$$\nJacobi 更新法则使用上一次迭代 $u^{(k)}$ 的值来计算新值 $u_{i,j}^{(k+1)}$：\n$$\nu_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(k)} + u_{i-1,j}^{(k)} + u_{i,j+1}^{(k)} + u_{i,j-1}^{(k)} - h^2 f_{i,j} \\right)\n$$\n此更新对所有内部点 $i,j \\in \\{1, \\dots, N\\}$ 执行。\n\n这种更新法则的结构非常适合并行计算，尤其是在像 GPU 这样的 SIMT (单指令多线程) 架构上。关键的观察是，每个点 $u_{i,j}^{(k+1)}$ 的计算完全独立于所有其他新值 $u_{l,m}^{(k+1)}$（其中 $(l,m) \\neq (i,j)$）。右侧的所有值都属于先前的状态 $u^{(k)}$。GPU 可以为每个网格点 $(i,j)$ 分配一个线程，所有线程可以同时在它们被分配的数据上执行相同的指令——即 Jacobi 更新公式。这需要两个内存缓冲区：一个用于读取旧状态 $u^{(k)}$，另一个用于写入新状态 $u^{(k+1)}$。这个过程被称为同步更新，它避免了数据竞争，并与硬件范式完美匹配。如前所述，在 CPU 上模拟此过程涉及使用两个数组并执行向量化更新。\n\n接下来，我们推导理论渐进收敛因子 $q$。Jacobi 迭代可以写成矩阵形式 $\\mathbf{u}^{(k+1)} = T_J \\mathbf{u}^{(k)} + \\mathbf{c}$，其中 $T_J$ 是 Jacobi 迭代矩阵。收敛率由 $T_J$ 的谱半径决定，定义为 $q = \\rho(T_J) = \\max_m |\\lambda_m|$，其中 $\\lambda_m$ 是 $T_J$ 的特征值。已知该区域上离散拉普拉斯算子的特征向量是离散正弦函数：\n$$\nv_{i,j}^{(p,q)} = \\sin\\left(\\frac{p\\pi i}{N+1}\\right) \\sin\\left(\\frac{q\\pi j}{N+1}\\right) \\quad \\text{for } p,q \\in \\{1, \\dots, N\\}\n$$\n这些也是 Jacobi 迭代矩阵 $T_J$ 的特征向量。将 Jacobi 算子应用于这样一个特征向量，得到：\n$$\n(T_J v^{(p,q)})_{i,j} = \\frac{1}{4} \\left( v_{i+1,j}^{(p,q)} + v_{i-1,j}^{(p,q)} + v_{i,j+1}^{(p,q)} + v_{i,j-1}^{(p,q)} \\right)\n$$\n使用三角恒等式 $\\sin(A+B) + \\sin(A-B) = 2\\sin(A)\\cos(B)$，我们简化这些项：\n$$\nv_{i+1,j}^{(p,q)} + v_{i-1,j}^{(p,q)} = 2\\cos\\left(\\frac{p\\pi}{N+1}\\right) v_{i,j}^{(p,q)}\n$$\n$$\nv_{i,j+1}^{(p,q)} + v_{i,j-1}^{(p,q)} = 2\\cos\\left(\\frac{q\\pi}{N+1}\\right) v_{i,j}^{(p,q)}\n$$\n将这些代回，我们找到与特征向量 $v^{(p,q)}$ 对应的特征值 $\\lambda_{p,q}$：\n$$\n(T_J v^{(p,q)})_{i,j} = \\frac{1}{2} \\left[ \\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right) \\right] v_{i,j}^{(p,q)}\n$$\n谱半径是所有 $p, q \\in \\{1, \\dots, N\\}$ 的这些特征值绝对值的最大值。余弦函数在区间 $[0, \\pi/2]$ 上是正的且单调递减。因此，最大特征值出现在自变量最小时，即 $p=1$ 和 $q=1$。\n$$\nq = \\rho(T_J) = \\lambda_{1,1} = \\frac{1}{2} \\left[ \\cos\\left(\\frac{\\pi}{N+1}\\right) + \\cos\\left(\\frac{\\pi}{N+1}\\right) \\right] = \\cos\\left(\\frac{\\pi}{N+1}\\right)\n$$\n这就是所要求的理论渐进收敛因子。随着 $N$ 的增加，它趋近于 $1$，这表明对于更精细的网格，收敛速度会显著减慢。\n\n实现将遵循这些推导出的原理。一个主循环将迭代 Jacobi 更新，在每一步开始时检查收敛性。残差范数 $\\|r^{(k)}\\|_{2,h}$ 和误差范数 $\\|e^{(k)}\\|_{2,h}$ 将使用向量化的 `numpy` 操作进行计算。经验收敛因子 $\\hat{q}$ 将从连续残差范数的比率中估计，所有数值输出将按指定格式进行格式化。",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef format_num(n):\n    \"\"\"Formats a number to 6 significant figures, or as an integer.\"\"\"\n    if isinstance(n, int):\n        return str(n)\n    if n == 0.0:\n        return \"0.0\"\n    return f\"{n:.6g}\"\n\ndef run_case(N, f_func, u_exact_func, epsilon, k_max):\n    \"\"\"\n    Solves the 2D Poisson BVP for a single test case using the Jacobi method.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    \n    # Create grid coordinates (including boundaries)\n    i_coords = np.arange(0, N + 2)\n    x = i_coords * h\n    X, Y = np.meshgrid(x, x, indexing='ij')\n\n    # Initialize solution array u (with zero boundaries) and source term f\n    u = np.zeros((N + 2, N + 2))\n    f_grid = f_func(X, Y)\n    \n    u_exact_grid = None\n    if u_exact_func is not None:\n        u_exact_grid = u_exact_func(X, Y)\n\n    residual_history = []\n    k_it = 0\n\n    for k in range(k_max + 1):\n        # Calculate the residual of the current state u^{(k)}\n        # A*u = (1/h^2) * (u_{i+1,j} + ... - 4u_{i,j})\n        # r = f - A*u\n        laplacian_u_interior = (u[2:, 1:-1] + u[:-2, 1:-1] + u[1:-1, 2:] + u[1:-1, :-2] - 4 * u[1:-1, 1:-1]) / (h**2)\n        f_interior = f_grid[1:-1, 1:-1]\n        \n        residual_matrix = f_interior - laplacian_u_interior\n        residual_norm = np.sqrt(h**2 * np.sum(residual_matrix**2))\n        residual_history.append(residual_norm)\n        \n        k_it = k\n        # Check for convergence before performing the update\n        if residual_norm < epsilon:\n            break\n        \n        # Check if max iterations reached\n        if k == k_max:\n            break\n\n        # Perform one synchronous Jacobi iteration (emulating GPU)\n        # Use a new array for the updated values, reading only from the old 'u'\n        u_new = np.zeros_like(u)\n        u_new[1:-1, 1:-1] = 0.25 * (u[2:, 1:-1] + u[:-2, 1:-1] +u[1:-1, 2:] + u[1:-1, :-2] - h**2 * f_grid[1:-1, 1:-1])\n        u = u_new\n\n    # --- Post-processing after loop termination ---\n    final_residual_norm = residual_history[-1]\n    \n    # Calculate final discrete L2 error norm if exact solution is available\n    final_error_norm = 0.0\n    if u_exact_grid is not None:\n        error_matrix = u[1:-1, 1:-1] - u_exact_grid[1:-1, 1:-1]\n        final_error_norm = np.sqrt(h**2 * np.sum(error_matrix**2))\n\n    # Estimate empirical convergence factor q_hat\n    q_hat = 0.0\n    # Per problem statement: q_hat=0 if fewer than 2 iterations occur.\n    if k_it >= 2:\n        ratios = []\n        # residual_history has k_it+1 elements (for k=0, 1, ..., k_it)\n        for i in range(1, len(residual_history)):\n            # Avoid division by zero\n            if residual_history[i-1] > 1e-16:\n                ratios.append(residual_history[i] / residual_history[i-1])\n        \n        num_ratios_to_avg = min(len(ratios), 10)\n        if num_ratios_to_avg > 0:\n            q_hat = np.mean(ratios[-num_ratios_to_avg:])\n            \n    # Calculate theoretical convergence factor q\n    q_theory = np.cos(np.pi / (N + 1))\n    \n    return [\n        format_num(k_it),\n        format_num(final_residual_norm),\n        format_num(final_error_norm),\n        format_num(q_hat),\n        format_num(q_theory)\n    ]\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the Jacobi solver.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path\n        {\n            \"N\": 15,\n            \"f_func\": lambda x, y: -2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"u_exact_func\": lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"epsilon\": 1e-8,\n            \"k_max\": 10000\n        },\n        # Case B: Larger grid\n        {\n            \"N\": 31,\n            \"f_func\": lambda x, y: -2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"u_exact_func\": lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"epsilon\": 1e-6,\n            \"k_max\": 100000\n        },\n        # Case C: Trivial solution, boundary edge case\n        {\n            \"N\": 15,\n            \"f_func\": lambda x, y: np.zeros_like(x),\n            \"u_exact_func\": lambda x, y: np.zeros_like(x),\n            \"epsilon\": 1e-12,\n            \"k_max\": 1000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(\n            case[\"N\"],\n            case[\"f_func\"],\n            case[\"u_exact_func\"],\n            case[\"epsilon\"],\n            case[\"k_max\"]\n        )\n        # Format each list of results into the required string format\n        results.append(f\"[{','.join(result)}]\")\n\n    # Print the final aggregated output string\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了雅可比方法的基础之上，下一个练习将引导您进行一次对比分析，探索它与高斯-赛德尔方法的关键区别。您将设计一个物理上有趣的各向异性扩散问题，在此场景中雅可比方法发散而高斯-赛德尔方法收敛，从而揭示迭代矩阵的谱半径如何决定算法的成败。这个实践旨在培养您对算法选择的批判性思维，并加深对数值稳定性的理解 。",
            "id": "2433986",
            "problem": "要求您构建并分析一个由具有物理意义的椭圆边值问题产生的线性系统，并确定一个雅可比（Jacobi）迭代法发散而高斯-赛德尔（Gauss-Seidel）方法收敛的配置。分析和算法必须基于第一性原理：椭圆性的定义、一致的有限差分法的构建以及标准的线性迭代分裂。\n\n考虑在一个有界平面域上的稳态各向异性扩散方程，以张量形式写为：\n$$\n-\\nabla \\cdot \\big( \\boldsymbol{K} \\nabla u \\big) = 0 \\quad \\text{in } \\Omega,\n$$\n服从齐次狄利克雷（Dirichlet）边界条件\n$$\nu = 0 \\quad \\text{on } \\partial \\Omega.\n$$\n假设一个各向异性的、对称的、正定的扩散张量\n$$\n\\boldsymbol{K} = \\boldsymbol{R}(\\theta)\\begin{bmatrix}\\kappa & 0 \\\\ 0 & 1\\end{bmatrix}\\boldsymbol{R}(\\theta)^{\\top},\n$$\n其中 $ \\kappa \\ge 1 $ 是各向异性比率，$ \\boldsymbol{R}(\\theta) $ 是一个旋转角度为 $ \\theta $ 的 $ 2\\times 2 $ 旋转矩阵（以度为单位，在构建 $ \\boldsymbol{R}(\\theta) $ 时需解释为弧度）。对于单位正方形 $ \\Omega = (0,1)\\times(0,1) $ 上的间距为 $ h $ 的均匀网格，使用 $ u_{xx} $、$ u_{yy} $ 和 $ u_{xy} $ 的标准二阶中心差分近似，来为算子推导一个 $ 9 $ 点格式\n$$\n- \\left( a\\,u_{xx} + 2b\\,u_{xy} + c\\,u_{yy} \\right) = 0,\n$$\n其中 $ a = K_{xx} $，$ b = K_{xy} $ 和 $ c = K_{yy} $。中心差分为\n$$\nu_{xx}\\approx \\frac{u_{i+1,j}-2u_{i,j}+u_{i-1,j}}{h^2},\\quad\nu_{yy}\\approx \\frac{u_{i,j+1}-2u_{i,j}+u_{i,j-1}}{h^2},\\quad\nu_{xy}\\approx \\frac{u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}}{4h^2}.\n$$\n由于齐次狄利克雷边界条件，为内部未知量组装相应的线性系统 $ \\boldsymbol{A}\\boldsymbol{u}=\\boldsymbol{b} $，其中 $ \\boldsymbol{b}=\\boldsymbol{0} $，仅使用上述基本定义，并将所有边界贡献一致地移到右侧。矩阵 $ \\boldsymbol{A} $ 是实数矩阵，并且对于物理上允许的 $ \\boldsymbol{K} $，它是对称的。\n\n从雅可比（Jacobi）和高斯-赛德尔（Gauss-Seidel）格式作为源于矩阵分裂的线性定常方法的定义出发，\n$$\n\\boldsymbol{A}=\\boldsymbol{D}+\\boldsymbol{L}+\\boldsymbol{U}, \\quad\n\\text{Jacobi: } \\boldsymbol{T}_{J}=\\boldsymbol{I}-\\boldsymbol{D}^{-1}\\boldsymbol{A}, \\quad\n\\text{Gauss\\text{-}Seidel: } \\boldsymbol{T}_{GS}=-(\\boldsymbol{D}+\\boldsymbol{L})^{-1}\\boldsymbol{U},\n$$\n回顾一个经过充分检验的事实，即线性定常迭代收敛的充要条件是迭代矩阵的谱半径 $ \\rho(\\cdot) $ 小于 $ 1 $：\n$$\n\\rho(\\boldsymbol{T}) < 1 \\Longleftrightarrow \\text{convergence}.\n$$\n使用此原则来判断收敛性。\n\n任务要求：\n- 针对单位正方形，使用齐次狄利克雷边界条件和上述定义所隐含的 $ 9 $ 点格式，构建矩阵 $ \\boldsymbol{A} $。使用一个每个坐标方向有 $ n $ 个内部点、网格间距为 $ h = 1/(n+1) $ 的均匀网格。\n- 对于下面的每个测试用例，计算谱半径 $ \\rho(\\boldsymbol{T}_J) $ 和 $ \\rho(\\boldsymbol{T}_{GS}) $，并判断雅可比方法是否发散而高斯-赛德尔方法是否收敛。对于每个用例，当且仅当雅可比方法发散且高斯-赛德尔方法收敛时，您的程序必须返回布尔值 $ \\texttt{True} $；否则返回 $ \\texttt{False} $。\n- 为确保物理和数值上的合理性，请使用 $ \\kappa \\ge 1 $ 并将角度 $ \\theta $ 视为度。输出无需物理单位。角度在内部必须解释为弧度，但所有角度输入均以度为单位指定。\n\n测试套件（包括一个名义上的各向同性情况、一个中度各向异性的对齐情况，以及一个预期会挑战雅可比方法的强旋转各向异性情况）：\n- 情况 1：$ n=8 $，$ \\kappa=1.0 $, $ \\theta=0^\\circ $。\n- 情况 2：$ n=8 $，$ \\kappa=10.0 $, $ \\theta=30^\\circ $。\n- 情况 3：$ n=8 $，$ \\kappa=1000.0 $, $ \\theta=45^\\circ $。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的 Python 布尔文字列表（例如，$ [\\texttt{False},\\texttt{False},\\texttt{True}] $），按顺序对应于上述三个测试用例的结果。",
            "solution": "此问题已经过验证。\n\n### 步骤 1：提取已知条件\n- **控制方程**：稳态各向异性扩散方程，$-\\nabla \\cdot \\big( \\boldsymbol{K} \\nabla u \\big) = 0$，在单位正方形域 $\\Omega = (0,1)\\times(0,1)$ 上。\n- **边界条件**：齐次狄利克雷（Dirichlet）边界条件，$u = 0$ on $\\partial \\Omega$。\n- **扩散张量**：$\\boldsymbol{K} = \\boldsymbol{R}(\\theta)\\begin{bmatrix}\\kappa & 0 \\\\ 0 & 1\\end{bmatrix}\\boldsymbol{R}(\\theta)^{\\top}$，其中 $\\kappa \\ge 1$ 是各向异性比率，$\\boldsymbol{R}(\\theta)$ 是一个 $2 \\times 2$ 旋转矩阵。角度 $\\theta$ 以度为单位给出。\n- **算子形式**：该方程等价于 $- \\left( a\\,u_{xx} + 2b\\,u_{xy} + c\\,u_{yy} \\right) = 0$，其中 $a = K_{xx}$，$b = K_{xy}$，$c = K_{yy}$。\n- **离散化**：一个均匀网格，每个方向有 $n$ 个内部点，间距为 $h = 1/(n+1)$。指定了标准的二阶中心差分：\n  - $u_{xx}\\approx \\frac{u_{i+1,j}-2u_{i,j}+u_{i-1,j}}{h^2}$\n  - $u_{yy}\\approx \\frac{u_{i,j+1}-2u_{i,j}+u_{i,j-1}}{h^2}$\n  - $u_{xy}\\approx \\frac{u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}}{4h^2}$\n- **线性系统**：组装 $\\boldsymbol{A}\\boldsymbol{u}=\\boldsymbol{b}$，其中 $\\boldsymbol{b}=\\boldsymbol{0}$。\n- **迭代方法**：\n  - 矩阵分裂：$\\boldsymbol{A}=\\boldsymbol{D}+\\boldsymbol{L}+\\boldsymbol{U}$。\n  - Jacobi 迭代矩阵：$\\boldsymbol{T}_{J}=\\boldsymbol{I}-\\boldsymbol{D}^{-1}\\boldsymbol{A}$。\n  - Gauss-Seidel 迭代矩阵：$\\boldsymbol{T}_{GS}=-(\\boldsymbol{D}+\\boldsymbol{L})^{-1}\\boldsymbol{U}$。\n- **收敛条件**：一种方法收敛当且仅当其迭代矩阵的谱半径小于1，即 $\\rho(\\boldsymbol{T}) < 1$。\n- **任务**：对于每个测试用例，确定雅可比方法是否发散 ($\\rho(\\boldsymbol{T}_J) \\ge 1$) 而高斯-赛德尔方法收敛 ($\\rho(\\boldsymbol{T}_{GS}) < 1$)。\n- **测试用例**：\n  1. $n=8$, $\\kappa=1.0$, $\\theta=0^\\circ$。\n  2. $n=8$, $\\kappa=10.0$, $\\theta=30^\\circ$。\n  3. $n=8$, $\\kappa=1000.0$, $\\theta=45^\\circ$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，是适定且客观的。它提出了一个计算物理学中的标准问题，涉及椭圆偏微分方程的数值解。扩散方程、有限差分法和迭代求解器（Jacobi、Gauss-Seidel）都是基本概念。基于谱半径的收敛准则是数值线性代数的一个基石定理。扩散张量 $\\boldsymbol{K}$ 被定义为对称正定的，这保证了偏微分方程的椭圆性。该问题是自洽的，并提供了构建解决方案所需的所有必要信息。不存在科学缺陷、矛盾或含糊之处。\n\n### 步骤 3：结论与行动\n此问题有效。将提供一个完整的解决方案。\n\n### 基于原理的解决方案\n任务是，对于特定的物理参数，判断由各向异性扩散方程的有限差分离散化产生的线性系统，其雅可比迭代法是否发散而高斯-赛德尔方法收敛。\n\n**1. 偏微分方程系数的推导**\n首先，我们确定扩散算子的分量 $a$、$b$ 和 $c$。扩散张量为 $\\boldsymbol{K} = \\boldsymbol{R}(\\theta)\\boldsymbol{D}_\\kappa\\boldsymbol{R}(\\theta)^{\\top}$，其中 $\\boldsymbol{D}_\\kappa = \\begin{bmatrix}\\kappa & 0 \\\\ 0 & 1\\end{bmatrix}$ 且 $\\boldsymbol{R}(\\theta) = \\begin{bmatrix}\\cos\\phi & -\\sin\\phi \\\\ \\sin\\phi & \\cos\\phi\\end{bmatrix}$，$\\phi = \\theta \\cdot \\pi/180$。\n执行矩阵乘法得到：\n$$\n\\boldsymbol{K} =\n\\begin{bmatrix}\n\\kappa \\cos^2\\phi + \\sin^2\\phi & (\\kappa-1)\\sin\\phi\\cos\\phi \\\\\n(\\kappa-1)\\sin\\phi\\cos\\phi & \\kappa \\sin^2\\phi + \\cos^2\\phi\n\\end{bmatrix}\n$$\n因此，系数为：\n- $a = K_{xx} = \\kappa \\cos^2\\phi + \\sin^2\\phi$\n- $b = K_{xy} = (\\kappa-1)\\sin\\phi\\cos\\phi = \\frac{\\kappa-1}{2}\\sin(2\\phi)$\n- $c = K_{yy} = \\kappa \\sin^2\\phi + \\cos^2\\phi$\n\n该偏微分方程是椭圆的，因为 $\\det(\\boldsymbol{K}) = \\kappa \\ge 1 > 0$，这保证了 $ac-b^2 > 0$。\n\n**2. 有限差分格式和系统矩阵 $\\boldsymbol{A}$**\n我们将给定的中心差分近似代入算子 $- \\left( a\\,u_{xx} + 2b\\,u_{xy} + c\\,u_{yy} \\right) = 0$。在网格点 $(i,j)$ 处，得到：\n$$\n-a \\frac{u_{i+1,j}-2u_{i,j}+u_{i-1,j}}{h^2} - 2b \\frac{u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}}{4h^2} - c \\frac{u_{i,j+1}-2u_{i,j}+u_{i,j-1}}{h^2} = 0\n$$\n乘以 $h^2$（一个不影响迭代矩阵谱半径的常数缩放因子）并收集每个网格点的项，得到对应于网格点 $(i,j)$ 的矩阵 $\\boldsymbol{A}$ 的第 $k$ 行方程：\n$$\n(2a+2c)u_{i,j} - a(u_{i-1,j}+u_{i+1,j}) - c(u_{i,j-1}+u_{i,j+1}) - \\frac{b}{2}(u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}) = 0\n$$\n这定义了一个 $9$ 点格式。对于 $i,j \\in \\{1,\\dots,n\\}$ 的未知数 $u_{i,j}$ 使用行主序排列成一个大小为 $N=n^2$ 的向量 $\\boldsymbol{u}$，其中网格点 $(i,j)$ 的从 0 开始的索引 $k$ 为 $k = jn+i$。矩阵 $\\boldsymbol{A}$ 基于此格式构建。对于齐次狄利克雷边界条件，任何落在边界上的格式点都对应于 $u=0$ 的值，因此对未知向量的矩阵项没有贡献。由于算子是自伴的且离散化方案是一致的，所得矩阵 $\\boldsymbol{A}$ 是对称的。\n\n**3. 收敛性分析**\nJacobi 和 Gauss-Seidel 方法的收敛性取决于它们各自迭代矩阵 $\\boldsymbol{T}_J$ 和 $\\boldsymbol{T}_{GS}$ 的谱半径。\n由于该偏微分方程是椭圆的，且离散化是标准的，因此得到的矩阵 $\\boldsymbol{A}$ 是对称正定(SPD)的。数值线性代数中的一个关键定理指出，对于对称正定(SPD)矩阵 $\\boldsymbol{A}$，Gauss-Seidel 方法保证收敛。因此，对于所有有效的测试用例，$\\rho(\\boldsymbol{T}_{GS}) < 1$。\n\n因此，问题简化为确定 Jacobi 方法何时发散，即何时 $\\rho(\\boldsymbol{T}_J) \\ge 1$。对于一个 SPD 矩阵 $\\boldsymbol{A}$，Jacobi 方法收敛当且仅当矩阵 $2\\boldsymbol{D}-\\boldsymbol{A}$ 也是正定的。大的混合导数项（$b \\neq 0$）的存在可能导致 $2\\boldsymbol{D}-\\boldsymbol{A}$ 不是正定的，从而引起 Jacobi 方法发散。对于给定的 $\\kappa$，当 $\\sin(2\\phi)$ 最大时，系数 $b$ 达到最大值，这发生在 $\\theta=45^\\circ$ 时。因此，强各向异性（$\\kappa \\gg 1$）与 $\\theta=45^\\circ$ 的旋转相结合是 Jacobi 方法失败而 Gauss-Seidel 方法收敛的经典场景。\n\n**4. 算法**\n对于每个测试用例 ($n, \\kappa, \\theta$)：\n1.  使用 $\\theta$ 的弧度值计算系数 $a,b,c$。\n2.  基于推导出的 $9$ 点格式，应用齐次狄利克雷边界条件，构建 $n^2 \\times n^2$ 的矩阵 $\\boldsymbol{A}$。\n3.  将 $\\boldsymbol{A}$ 分解为其对角部分（$\\boldsymbol{D}$）、严格下三角部分（$\\boldsymbol{L}$）和严格上三角部分（$\\boldsymbol{U}$）。\n4.  计算 Jacobi 迭代矩阵 $\\boldsymbol{T}_J = -\\boldsymbol{D}^{-1}(\\boldsymbol{L}+\\boldsymbol{U})$ 和 Gauss-Seidel 迭代矩阵 $\\boldsymbol{T}_{GS} = -(\\boldsymbol{D}+\\boldsymbol{L})^{-1}\\boldsymbol{U}$。\n5.  通过找到每个矩阵的最大绝对值特征值来计算谱半径 $\\rho(\\boldsymbol{T}_J)$ 和 $\\rho(\\boldsymbol{T}_{GS})$。\n6.  评估布尔条件 $\\rho(\\boldsymbol{T}_J) \\ge 1 \\text{ and } \\rho(\\boldsymbol{T}_{GS}) < 1$。\n\n此过程将为给定的测试套件实施。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef analyze_convergence(n: int, kappa: float, theta_deg: float) -> bool:\n    \"\"\"\n    Analyzes the convergence of Jacobi and Gauss-Seidel methods for the given parameters.\n\n    Args:\n        n: Number of interior grid points per dimension.\n        kappa: Anisotropy ratio.\n        theta_deg: Rotation angle in degrees.\n\n    Returns:\n        True if Jacobi diverges and Gauss-Seidel converges, False otherwise.\n    \"\"\"\n    # 1. Calculate PDE coefficients\n    theta_rad = np.deg2rad(theta_deg)\n    cos_t, sin_t = np.cos(theta_rad), np.sin(theta_rad)\n    \n    a = kappa * cos_t**2 + sin_t**2\n    b = (kappa - 1) * sin_t * cos_t\n    c_pde = kappa * sin_t**2 + cos_t**2\n\n    # 2. Build the system matrix A\n    N = n * n\n    A = np.zeros((N, N), dtype=float)\n\n    for j in range(n):  # 0-based row index of the grid point\n        for i in range(n):  # 0-based column index of the grid point\n            k = j * n + i  # 1D index using row-major ordering\n\n            # Stencil coefficients for the discrete operator.\n            # The common factor 1/h^2 is omitted as it scales the entire matrix\n            # and does not affect the spectral radii of the iteration matrices.\n            \n            # Diagonal term\n            A[k, k] = 2.0 * a + 2.0 * c_pde\n\n            # Neighboring terms from u_xx and u_yy\n            if i > 0:       A[k, k - 1] = -a      # (i-1, j)\n            if i < n - 1:   A[k, k + 1] = -a      # (i+1, j)\n            if j > 0:       A[k, k - n] = -c_pde  # (i, j-1)\n            if j < n - 1:   A[k, k + n] = -c_pde  # (i, j+1)\n\n            # Mixed derivative terms from u_xy\n            if i > 0 and j > 0:         A[k, k - n - 1] = -b / 2.0  # (i-1, j-1)\n            if i < n - 1 and j > 0:     A[k, k - n + 1] = b / 2.0   # (i+1, j-1)\n            if i > 0 and j < n - 1:     A[k, k + n - 1] = b / 2.0   # (i-1, j+1)\n            if i < n - 1 and j < n - 1: A[k, k + n + 1] = -b / 2.0  # (i+1, j+1)\n\n    # 3. Decompose A into D (diagonal), L (lower), U (upper)\n    D = np.diag(np.diag(A))\n    L = np.tril(A, k=-1)\n    U = np.triu(A, k=1)\n\n    # 4. Compute iteration matrices\n    # Jacobi: T_J = -D^{-1}(L+U)\n    D_inv = np.linalg.inv(D)\n    T_J = -D_inv @ (L + U)\n\n    # Gauss-Seidel: T_GS = -(D+L)^{-1}U\n    DL_inv = np.linalg.inv(D + L)\n    T_GS = -DL_inv @ U\n\n    # 5. Compute spectral radii\n    rho_J = np.max(np.abs(np.linalg.eigvals(T_J)))\n    rho_GS = np.max(np.abs(np.linalg.eigvals(T_GS)))\n    \n    # 6. Check the condition for Jacobi divergence and Gauss-Seidel convergence\n    jacobi_diverges = rho_J >= 1.0\n    gauss_seidel_converges = rho_GS < 1.0\n\n    return jacobi_diverges and gauss_seidel_converges\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, kappa, theta_deg)\n        (8, 1.0, 0.0),       # Case 1\n        (8, 10.0, 30.0),     # Case 2\n        (8, 1000.0, 45.0),   # Case 3\n    ]\n\n    results = []\n    for case in test_cases:\n        n, kappa, theta_deg = case\n        result = analyze_convergence(n, kappa, theta_deg)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "最后的实践练习将挑战您解决一个更复杂的四阶偏微分方程——双调和方程，该方程在弹性力学和流体动力学中至关重要。通过将其分解为两个耦合的泊松方程，您将学习如何应用已有的知识来攻克更高阶的问题。此外，本练习还将介绍一种强大的加速技术——逐次超松弛（SOR）方法及其高效的红黑着色实现方案，展示如何显著提高迭代求解器的收敛速度 。",
            "id": "2434002",
            "problem": "考虑在单位正方形域 $\\Omega = [0,1]\\times[0,1]$ 上的二维双调和方程，其空间坐标为 $(x,y)$:\n$$\n\\nabla^4 \\psi(x,y) = 0 \\quad \\text{在 } \\Omega \\text{ 内}\n$$。\n引入由基本恒等式 $\\phi = \\nabla^2 \\psi$ 定义的辅助变量 $\\phi(x,y)$。这将双调和方程分解为耦合的椭圆系统\n$$\n\\nabla^2 \\phi(x,y) = 0 \\quad \\text{在 } \\Omega \\text{ 内}, \\qquad \\nabla^2 \\psi(x,y) = \\phi(x,y) \\quad \\text{在 } \\Omega \\text{ 内}\n$$。\n您将使用松弛法，在均匀的笛卡尔网格上，通过二阶有限差分和逐次超松弛（Successive Over-Relaxation, SOR）方法求解该系统。SOR 是高斯-赛德尔（Gauss–Seidel）定点迭代的一种特定加速方法。\n\n您的任务如下。\n\n1) 通过人造解进行建模并处理边界数据。从拉普拉斯算子 $\\nabla^2$ 和双调和算子 $\\nabla^4 = \\nabla^2(\\nabla^2)$ 的基本定义以及恒等式 $\\phi = \\nabla^2 \\psi$ 出发。考虑光滑函数\n$$\n\\psi^\\star(x,y) = \\frac{x^4 - y^4}{12}, \\qquad \\phi^\\star(x,y) = x^2 - y^2\n$$。\n根据第一性原理验证 $\\nabla^2 \\phi^\\star(x,y) = 0$ 和 $\\nabla^2 \\psi^\\star(x,y) = \\phi^\\star(x,y)$，从而验证 $\\psi^\\star$ 是双调和的，即 $\\nabla^4 \\psi^\\star = 0$。施加狄利克雷（Dirichlet）数据\n$$\n\\psi(x,y)\\big|_{\\partial\\Omega} = \\psi^\\star(x,y), \\qquad \\phi(x,y)\\big|_{\\partial\\Omega} = \\phi^\\star(x,y),\n$$\n使得内部的精确解在连续介质层面上与 $\\psi^\\star$ 和 $\\phi^\\star$ 一致。\n\n2) 基于泰勒展开进行离散化。设网格在每个坐标方向上包含 $M$ 个内部点，均匀间距为 $h = 1/(M+1)$。用 $u_{i,j}$ 表示一个定义在完整网格索引 $i,j \\in \\{0,1,\\dots,M+1\\}$ 上的网格函数，其中在 $i=0,M+1$ 或 $j=0,M+1$ 处的值位于边界上，内部索引为 $i,j \\in \\{1,\\dots,M\\}$。使用关于 $(x_i,y_j)$ 的最高达二阶的泰勒展开和二阶导数的核心定义，推导出标准的五点离散拉普拉斯算子\n$$\n\\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} \\approx \\left(\\nabla^2 u\\right)(x_i,y_j),\n$$\n其截断误差为 $\\mathcal{O}(h^2)$ 阶。将此应用于模型方程，得到 $\\phi$ 的离散拉普拉斯方程和 $\\psi$ 的离散泊松方程，其狄利克雷边界值取自 $\\phi^\\star$ 和 $\\psi^\\star$。\n\n3) 松弛算法。从离散方程和“新迭代值与由源项调整后的邻点平均值相匹配”的定点思想出发，推导原地高斯-赛德尔（Gauss–Seidel）更新，然后推导带有松弛参数 $\\omega \\in (0,2)$ 的逐次超松弛（SOR）更新。实现一个红黑 SOR 方案（棋盘格排序），该方案在奇偶性为 $(i+j)\\bmod 2 = 0$ 和 $(i+j)\\bmod 2 = 1$ 的内部点之间交替更新，以利用数据局部性并改善收敛性。使用离散残差\n$$\nr_{i,j} = f_{i,j} - \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2}\n$$\n作为停止准则，当内部点上残差的最大范数小于或等于指定容差 $\\tau$ 时，终止求解。\n\n4) 算法工作流程。对于每个测试用例：\n- 初始化网格，将 $\\phi$ 的边界值设置为 $\\phi^\\star$，$\\psi$ 的边界值设置为 $\\psi^\\star$，将内部初始猜测值设置为 $0$，并为求解 $\\phi$ 设置 $f\\equiv 0$。\n- 使用红黑 SOR 求解 $\\phi$ 的离散拉普拉斯方程，直到残差最大范数低于容差 $\\tau$。\n- 将求解 $\\psi$ 的离散源项设置为已收敛的 $\\phi$ 的内部值，并使用红黑 SOR 求解 $\\psi$ 的离散泊松方程，直到残差最大范数低于 $\\tau$。\n- 计算内部点上 $\\psi$ 相对于人造解 $\\psi^\\star$ 的最大绝对误差：\n$$\nE_\\infty = \\max_{1 \\le i,j \\le M} \\left| \\psi_{i,j} - \\psi^\\star(x_i,y_j) \\right|\n$$。\n\n5) 测试套件。您的程序必须运行以下四个测试用例，并按顺序报告每个案例中 $\\psi$ 的内部最大绝对误差 $E_\\infty$：\n- 案例 A (理想情况): $M = 8$, $\\omega = 1.8$, $\\tau = 1\\times 10^{-10}$。\n- 案例 B (最小内部): $M = 1$, $\\omega = 1.5$, $\\tau = 1\\times 10^{-12}$。\n- 案例 C (加密网格): $M = 16$, $\\omega = 1.9$, $\\tau = 1\\times 10^{-10}$。\n- 案例 D (更大网格，激进松弛): $M = 32$, $\\omega = 1.95$, $\\tau = 1\\times 10^{-9}$。\n\n每次求解使用固定的最大迭代次数 $K_{\\max} = 20000$，以保证即使未达到容差也能终止，并在每个测试用例中对求解 $\\phi$ 和求解 $\\psi$ 使用相同的 $\\tau$。\n\n6) 最终输出格式。您的程序应产生单行输出，其中包含四个结果，格式为方括号内的逗号分隔列表，顺序为 A, B, C, D，例如\n$[\\;E_A,\\;E_B,\\;E_C,\\;E_D\\;]$,\n其中每个 $E_\\bullet$ 是一个十进制实数。\n\n该问题不涉及任何物理单位或角度，因此无需进行单位转换。所报告的数值均为无量纲实数。",
            "solution": "所提出的问题是计算物理学中一个适定的练习，要求使用标准分解和迭代松弛法对二维双调和方程进行数值求解。问题陈述在科学上是合理的，数学上是一致的，并为获得唯一解提供了所有必要的数据。我们将按照规定进行推导和实现。\n\n该问题首先要求验证所提供的人造解。控制方程是以下耦合系统：\n$$\n\\nabla^2 \\phi(x,y) = 0 \\quad (1)\n$$\n$$\n\\nabla^2 \\psi(x,y) = \\phi(x,y) \\quad (2)\n$$\n提出的精确解为 $\\psi^\\star(x,y) = \\frac{x^4 - y^4}{12}$ 和 $\\phi^\\star(x,y) = x^2 - y^2$。我们必须验证这些函数满足该方程组。\n\n首先，我们计算 $\\phi^\\star(x,y)$ 的拉普拉斯算子：\n$$\n\\frac{\\partial \\phi^\\star}{\\partial x} = 2x \\implies \\frac{\\partial^2 \\phi^\\star}{\\partial x^2} = 2\n$$\n$$\n\\frac{\\partial \\phi^\\star}{\\partial y} = -2y \\implies \\frac{\\partial^2 \\phi^\\star}{\\partial y^2} = -2\n$$\n$$\n\\nabla^2 \\phi^\\star = \\frac{\\partial^2 \\phi^\\star}{\\partial x^2} + \\frac{\\partial^2 \\phi^\\star}{\\partial y^2} = 2 + (-2) = 0\n$$\n这证实了 $\\phi^\\star(x,y)$ 满足方程(1)。它是一个调和函数。\n\n接下来，我们计算 $\\psi^\\star(x,y)$ 的拉普拉斯算子：\n$$\n\\frac{\\partial \\psi^\\star}{\\partial x} = \\frac{4x^3}{12} = \\frac{x^3}{3} \\implies \\frac{\\partial^2 \\psi^\\star}{\\partial x^2} = x^2\n$$\n$$\n\\frac{\\partial \\psi^\\star}{\\partial y} = \\frac{-4y^3}{12} = -\\frac{y^3}{3} \\implies \\frac{\\partial^2 \\psi^\\star}{\\partial y^2} = -y^2\n$$\n$$\n\\nabla^2 \\psi^\\star = \\frac{\\partial^2 \\psi^\\star}{\\partial x^2} + \\frac{\\partial^2 \\psi^\\star}{\\partial y^2} = x^2 - y^2\n$$\n我们观察到 $\\nabla^2 \\psi^\\star = \\phi^\\star(x,y)$，这证实了 $\\psi^\\star(x,y)$ 在 $\\phi = \\phi^\\star$ 时满足方程(2)。因此，$\\psi^\\star$ 是双调和的，因为 $\\nabla^4 \\psi^\\star = \\nabla^2(\\nabla^2 \\psi^\\star) = \\nabla^2 \\phi^\\star = 0$。人造解是正确的。\n\n下一步是拉普拉斯算子的离散化。我们对网格函数 $u(x,y)$ 在点 $(x_i, y_j)$ 周围使用泰勒级数展开。对于 $x$ 方向：\n$$\nu(x_i+h, y_j) = u_{i+1,j} = u_{i,j} + h \\frac{\\partial u}{\\partial x} \\bigg|_{i,j} + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} + \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\n$$\nu(x_i-h, y_j) = u_{i-1,j} = u_{i,j} - h \\frac{\\partial u}{\\partial x} \\bigg|_{i,j} + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} - \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\n将这两个展开式相加可以消去奇数阶导数项：\n$$\nu_{i+1,j} + u_{i-1,j} = 2u_{i,j} + h^2 \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\n整理后可得到关于 $x$ 的二阶偏导数的二阶中心差分近似：\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\mathcal{O}(h^2)\n$$\n对于 $y$ 方向，存在一个类似的表达式：\n$$\n\\frac{\\partial^2 u}{\\partial y^2} \\bigg|_{i,j} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + \\mathcal{O}(h^2)\n$$\n将这两个表达式相加，得到离散拉普拉斯算子 $\\nabla_h^2$ 的五点差分格式：\n$$\n(\\nabla_h^2 u)_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} \\approx (\\nabla^2 u)(x_i, y_j)\n$$\n此近似的截断误差为 $\\mathcal{O}(h^2)$ 阶。将其应用于耦合系统，对于内部网格点 $(i,j)$，其中 $i,j \\in \\{1,...,M\\}$，可得：\n$$\n\\frac{\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1} - 4\\phi_{i,j}}{h^2} = 0 \\quad (3)\n$$\n$$\n\\frac{\\psi_{i+1,j} + \\psi_{i-1,j} + \\psi_{i,j+1} + \\psi_{i,j-1} - 4\\psi_{i,j}}{h^2} = \\phi_{i,j} \\quad (4)\n$$\n这些是待求解的离散方程。对于一个通用的离散泊松方程 $(\\nabla_h^2 u)_{i,j} = f_{i,j}$，我们可以通过分离 $u_{i,j}$ 来编写一个定点迭代式：\n$$\n4u_{i,j} = u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j}\n$$\nGauss-Seidel 方法使用其邻点的最新计算值对 $u_{i,j}$ 进行原地更新：\n$$\nu_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(\\text{old})} + u_{i-1,j}^{(\\text{new})} + u_{i,j+1}^{(\\text{old})} + u_{i,j-1}^{(\\text{new})} - h^2 f_{i,j} \\right)\n$$\n其中“新”和“旧”邻点值的选择取决于扫描顺序。逐次超松弛（SOR）方法通过引入一个松弛参数 $\\omega$ 来加速收敛。$u_{i,j}$ 的 SOR 更新是其当前值和 Gauss-Seidel 更新值的加权平均：\n$$\nu_{i,j}^{(k+1)} = (1-\\omega) u_{i,j}^{(k)} + \\omega \\left[ \\frac{1}{4} \\left( \\dots \\right) \\right]\n$$\n其中方括号中的项是 Gauss-Seidel 更新值，我们将其表示为 $\\tilde{u}_{i,j}^{(k+1)}$。完整的 SOR 更新表达式为：\n$$\nu_{i,j} \\leftarrow (1-\\omega) u_{i,j} + \\frac{\\omega}{4} \\left( u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j} \\right)\n$$\n红黑排序方案将网格点分为两组：“红”点，其中 $(i+j)$ 为偶数；“黑”点，其中 $(i+j)$ 为奇数。关键在于，一个红点的所有邻点都是黑点，反之亦然。这允许使用上一次迭代步骤中的黑点值同时更新所有红点。然后，使用新计算出的红点值同时更新所有黑点。这个双扫描过程构成了一次完整的 SOR 迭代，并且易于矢量化。\n\n停止准则是基于离散残差 $r_{i,j} = f_{i,j} - (\\nabla_h^2 u)_{i,j}$。当给定场的残差在所有内部点上的最大绝对值低于容差 $\\tau$ 时，迭代终止：$\\|\\mathbf{r}\\|_\\infty = \\max_{1 \\le i,j \\le M} |r_{i,j}| \\le \\tau$。\n\n总体算法流程如下：\n1.  初始化大小为 $(M+2) \\times (M+2)$ 的 $\\phi$ 和 $\\psi$ 网格。使用精确函数 $\\phi^\\star(x,y)$ 和 $\\psi^\\star(x,y)$ 在这些网格上设置边界值。将所有内部点初始化为 $0$。\n2.  求解 $\\phi$ 的离散拉普拉斯方程（方程(3)，其中 $f_{i,j}=0$）。使用指定 $\\omega$ 的红黑 SOR 方法进行迭代，直到残差范数低于 $\\tau$ 或达到最大迭代次数 $K_{\\max}$。\n3.  求解 $\\psi$ 的离散泊松方程（方程(4)）。源项是上一步中得到的已收敛的 $\\phi$ 的内部解。使用相同的 $\\omega$ 和 $\\tau$ 通过红黑 SOR 方法求解，直至收敛。\n4.  在 $\\psi$ 场收敛后，计算最大绝对误差 $E_\\infty = \\max_{1 \\le i,j \\le M} |\\psi_{i,j} - \\psi^\\star(x_i, y_j)|$。\n\n对问题陈述中指定的每个测试用例重复此过程。最终的实现将精确地遵循此逻辑。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy  # Per environment specification, though not used in the logic.\n\ndef solve_system(M, omega, tau, k_max):\n    \"\"\"\n    Solves the coupled elliptic system for a given set of parameters.\n\n    Args:\n        M (int): Number of interior points per dimension.\n        omega (float): SOR relaxation parameter.\n        tau (float): Convergence tolerance for the residual.\n        k_max (int): Maximum number of iterations.\n\n    Returns:\n        float: The maximum absolute error E_infty for psi.\n    \"\"\"\n    # 1. Grid setup\n    h = 1.0 / (M + 1)\n    # Grid coordinates, including boundaries\n    grid_coords = np.linspace(0.0, 1.0, M + 2)\n    x, y = np.meshgrid(grid_coords, grid_coords)\n\n    # Manufactured solutions\n    def phi_star_func(x_val, y_val):\n        return x_val**2 - y_val**2\n    \n    def psi_star_func(x_val, y_val):\n        return (x_val**4 - y_val**4) / 12.0\n\n    # Initialize fields phi and psi\n    phi = np.zeros((M + 2, M + 2), dtype=np.float64)\n    psi = np.zeros((M + 2, M + 2), dtype=np.float64)\n\n    # Set boundary conditions\n    phi = phi_star_func(x, y)\n    psi = psi_star_func(x, y)\n    \n    # Set interior initial guess to 0\n    phi[1:-1, 1:-1] = 0.0\n    psi[1:-1, 1:-1] = 0.0\n    \n    h2 = h * h\n\n    # 2. Solve for phi (Laplace equation: nabla^2 phi = 0)\n    for k in range(k_max):\n        # Red-black SOR update for phi\n        # Red points (i+j is even)\n        phi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 0,\n                                   (1 - omega) * phi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       phi[2:, 1:-1] + phi[:-2, 1:-1] +\n                                       phi[1:-1, 2:] + phi[1:-1, :-2]),\n                                   phi[1:-1, 1:-1])\n        # Black points (i+j is odd)\n        phi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 1,\n                                   (1 - omega) * phi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       phi[2:, 1:-1] + phi[:-2, 1:-1] +\n                                       phi[1:-1, 2:] + phi[1:-1, :-2]),\n                                   phi[1:-1, 1:-1])\n\n        # Check for convergence\n        if k % 10 == 0:  # Check residual periodically\n            residual = (phi[2:, 1:-1] + phi[:-2, 1:-1] + phi[1:-1, 2:] + phi[1:-1, :-2] - 4 * phi[1:-1, 1:-1]) / h2\n            if np.max(np.abs(residual)) <= tau:\n                break\n    \n    # 3. Solve for psi (Poisson equation: nabla^2 psi = phi)\n    f_psi = phi[1:-1, 1:-1].copy() # Source term is the interior phi\n    \n    for k in range(k_max):\n        # Red-black SOR update for psi\n        # Red points\n        psi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 0,\n                                   (1 - omega) * psi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       psi[2:, 1:-1] + psi[:-2, 1:-1] +\n                                       psi[1:-1, 2:] + psi[1:-1, :-2] - h2 * f_psi),\n                                   psi[1:-1, 1:-1])\n        # Black points\n        psi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 1,\n                                   (1 - omega) * psi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       psi[2:, 1:-1] + psi[:-2, 1:-1] +\n                                       psi[1:-1, 2:] + psi[1:-1, :-2] - h2 * f_psi),\n                                   psi[1:-1, 1:-1])\n\n        # Check for convergence\n        if k % 10 == 0:\n            residual = f_psi - (psi[2:, 1:-1] + psi[:-2, 1:-1] + psi[1:-1, 2:] + psi[1:-1, :-2] - 4 * psi[1:-1, 1:-1]) / h2\n            if np.max(np.abs(residual)) <= tau:\n                break\n\n    # 4. Compute final error E_infty\n    x_interior = grid_coords[1:-1]\n    y_interior = grid_coords[1:-1]\n    xv_int, yv_int = np.meshgrid(x_interior, y_interior)\n    psi_exact_interior = psi_star_func(xv_int, yv_int)\n    \n    psi_numeric_interior = psi[1:-1, 1:-1]\n    \n    error = np.max(np.abs(psi_numeric_interior - psi_exact_interior))\n    \n    return error\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, 1.8, 1e-10),   # Case A\n        (1, 1.5, 1e-12),   # Case B\n        (16, 1.9, 1e-10),  # Case C\n        (32, 1.95, 1e-9), # Case D\n    ]\n    \n    k_max = 20000\n    results = []\n    \n    for case in test_cases:\n        M, omega, tau = case\n        result = solve_system(M, omega, tau, k_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}