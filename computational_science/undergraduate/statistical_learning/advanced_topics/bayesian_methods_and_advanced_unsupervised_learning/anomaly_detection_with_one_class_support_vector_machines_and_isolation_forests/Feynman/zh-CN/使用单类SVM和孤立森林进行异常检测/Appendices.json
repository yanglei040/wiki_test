{
    "hands_on_practices": [
        {
            "introduction": "异常检测算法通常为每个数据点生成一个异常分数，但仅有分数本身是不够的。我们需要一种系统性的方法来利用这些分数进行分类决策并评估模型的性能。本练习将引导你实践一种常见的评估方法：基于预设的异常流行率 $\\pi$ 来设定阈值，并计算精确率这一关键性能指标。通过这个练习，你将掌握从原始分数到模型性能评估的基础技能，这对于比较不同异常检测方法至关-重要。",
            "id": "3099063",
            "problem": "您将获得多个测试集上两种无监督异常检测方法的异常分数：单类支持向量机 (OCSVM) 和孤立森林 (IF)。对于每个测试集，您必须通过选择前 $k$ 个最异常的点来设置一个基于流行率的阈值，其中 $k = \\lfloor \\pi n \\rfloor$，$\\pi \\in [0,1]$ 是目标异常流行率，$n$ 是测试集中的样本数。分数越高表示异常程度越高。在阈值处出现平局时，通过优先选择较小的样本索引来确定性地打破平局。在此阈值化规则下，计算每种方法的精确率。精确率定义为 $TP/(TP+FP)$（如果 $TP+FP > 0$），当 $TP+FP = 0$ 时定义为 $0$。\n\n基本定义和规则：\n- 给定分数向量 $\\mathbf{s} \\in \\mathbb{R}^n$，使用字典序规则按分数降序对索引进行排序，该规则首先按 $-s_i$ 排序，然后通过升序索引 $i$ 打破平局。选择前 $k = \\lfloor \\pi n \\rfloor$ 个索引作为预测的异常。这通过顺序统计量实现了一个基于流行率的阈值。\n- 真阳性为 $TP = \\sum_{i=1}^n \\mathbb{I}[\\hat{y}_i = 1 \\wedge y_i = 1]$，假阳性为 $FP = \\sum_{i=1}^n \\mathbb{I}[\\hat{y}_i = 1 \\wedge y_i = 0]$，精确率在 $TP+FP > 0$ 时为 $TP/(TP+FP)$，否则为 $0$。\n- 当 $\\pi = 0$ 时，$k = 0$，精确率定义为 $0$。当 $\\pi = 1$ 时，$k = n$，精确率等于数据集中异常的比例。\n\n您的程序必须针对以下每个测试用例计算两种方法的精确率，并按下方指定的顺序，将结果以单个列表的形式输出到一行，列表为逗号分隔，并用方括号括起来。所有报告的值必须是四舍五入到四位小数的浮点数。\n\n测试套件：\n1. 测试用例 $1$（正常路径，无平局）：\n   - $n = 12$\n   - OCSVM 分数 $\\mathbf{s}^{(1)}_{\\mathrm{OCSVM}} = [0.10, 0.95, 0.40, 0.30, 0.60, 0.90, 0.20, 0.85, 0.50, 0.55, 0.15, 0.45]$\n   - IF 分数 $\\mathbf{s}^{(1)}_{\\mathrm{IF}} = [0.12, 0.88, 0.80, 0.65, 0.50, 0.90, 0.85, 0.40, 0.30, 0.45, 0.20, 0.60]$\n   - 真实标签 $\\mathbf{y}^{(1)} = [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]$\n   - 目标流行率 $\\pi^{(1)} = 0.25$\n2. 测试用例 $2$（在截断点出现平局，通过索引打破平局）：\n   - $n = 10$\n   - OCSVM 分数 $\\mathbf{s}^{(2)}_{\\mathrm{OCSVM}} = [0.10, 0.50, 0.95, 0.70, 0.40, 0.85, 0.20, 0.60, 0.70, 0.30]$\n   - IF 分数 $\\mathbf{s}^{(2)}_{\\mathrm{IF}} = [0.30, 0.60, 0.92, 0.70, 0.45, 0.80, 0.20, 0.58, 0.89, 0.40]$\n   - 真实标签 $\\mathbf{y}^{(2)} = [0, 0, 1, 0, 0, 0, 0, 0, 1, 0]$\n   - 目标流行率 $\\pi^{(2)} = 0.30$\n3. 测试用例 $3$（边界情况 $\\pi = 0$）：\n   - 重用测试用例 $1$ 中的 $\\mathbf{s}^{(1)}_{\\mathrm{OCSVM}}$、$\\mathbf{s}^{(1)}_{\\mathrm{IF}}$ 和 $\\mathbf{y}^{(1)}$\n   - 目标流行率 $\\pi^{(3)} = 0.00$\n4. 测试用例 $4$（边界情况 $\\pi = 1$）：\n   - 重用测试用例 $1$ 中的 $\\mathbf{s}^{(1)}_{\\mathrm{OCSVM}}$、$\\mathbf{s}^{(1)}_{\\mathrm{IF}}$ 和 $\\mathbf{y}^{(1)}$\n   - 目标流行率 $\\pi^{(4)} = 1.00$\n\n最终输出规范：\n- 对于每个测试用例 $j \\in \\{1,2,3,4\\}$，计算 OCSVM 的精确率（记为 $P^{(j)}_{\\mathrm{OCSVM}}$）和 IF 的精确率（记为 $P^{(j)}_{\\mathrm{IF}}$）。\n- 您的程序应生成单行输出，其中包含一个含 $8$ 个浮点数的列表，四舍五入到四位小数，顺序如下：\n  $[\\,P^{(1)}_{\\mathrm{OCSVM}}, P^{(1)}_{\\mathrm{IF}}, P^{(2)}_{\\mathrm{OCSVM}}, P^{(2)}_{\\mathrm{IF}}, P^{(3)}_{\\mathrm{OCSVM}}, P^{(3)}_{\\mathrm{IF}}, P^{(4)}_{\\mathrm{OCSVM}}, P^{(4)}_{\\mathrm{IF}}\\,]$.",
            "solution": "该问题是有效的。它提出了一个基于机器学习模型性能评估标准原则的、定义明确的计算任务。问题陈述是自包含的，提供了所有必要的数据、定义和环境约束。它在统计学习领域具有科学依据，逻辑上一致，并且没有歧义或事实错误。\n\n任务是计算两种异常检测模型——单类支持向量机 (OCSVM) 和孤立森林 (IF)——在四个测试场景下的精确率。评估基于一种基于流行率的阈值化策略。\n\n问题的核心在于正确实现指定的阈值化规则和精确率度量，包括所有边界情况。整个过程可以分解为以下几个步骤：\n\n**1. 确定异常数量 ($k$)**\n对于一个包含 $n$ 个样本和目标异常流行率 $\\pi \\in [0, 1]$ 的给定测试集，要标记为异常的数据点数量（记为 $k$）由向下取整函数确定：\n$$k = \\lfloor \\pi n \\rfloor$$\n这个值 $k$ 代表预测的异常集合的大小。\n\n**2. 通过基于分数的排序识别异常**\n哪些样本是异常的预测是基于它们的分数 $\\mathbf{s} \\in \\mathbb{R}^n$。分数越高表示是异常的可能性越大。为了选择前 $k$ 个异常，我们必须建立一个确定性的排序。问题指定了一个字典序排序规则：\n- 主排序键是异常分数 $s_i$，按降序排列（即，我们按 -$s_i$ 升序排列）。\n- 次排序键是样本索引 $i$，按升序排列。此规则用于打破分数中的任何平局情况。\n\n因此，对于索引为 $i$ 和 $j$ 的两个样本，如果 ($s_i > s_j$) 或 ($s_i = s_j$ 且 $i  j$)，则样本 $i$ 被认为比样本 $j$ 更异常。预测的异常集合 $\\hat{Y}_1$ 由根据此规则排名最高的 $k$ 个样本组成。\n\n**3. 计算精确率**\n精确率是一个度量标准，用于衡量在所有被预测为异常的样本中，被正确识别的异常所占的比例。它根据真阳性 ($TP$) 和假阳性 ($FP$) 来定义。\n- 真阳性 ($TP$) 是一个被正确识别为异常的样本（预测标签 $\\hat{y}_i = 1$ 且真实标签 $y_i = 1$）。\n- 假阳性 ($FP$) 是一个被错误识别为异常的样本（预测标签 $\\hat{y}_i = 1$ 且真实标签 $y_i = 0$）。\n\n预测的异常总数为 $TP + FP$，它等于 $k$。然后精确率 $P$ 计算如下：\n$$P = \\begin{cases} \\frac{TP}{TP + FP}  \\text{if } TP + FP  0 \\\\ 0  \\text{if } TP + FP = 0 \\end{cases}$$\n由于 $TP+FP = k$，对于 $k  0$，这可以简化为 $P = TP / k$。\n\n**4. 处理流行率 ($\\pi$) 的边界情况**\n问题为 $\\pi$ 的边界值定义了特定行为：\n- 如果 $\\pi = 0$，则 $k = \\lfloor 0 \\cdot n \\rfloor = 0$。没有样本被预测为异常。在这种情况下，$TP=0$ 且 $FP=0$，所以 $TP+FP=0$。精确率被明确定义为 $0$。\n- 如果 $\\pi = 1$，则 $k = \\lfloor 1 \\cdot n \\rfloor = n$。所有样本都被预测为异常。精确率被定义为数据集中真实异常的总体比例。这等同于 $P = (\\sum_{i=1}^n y_i) / n$。这与通用公式是一致的，因为 $k=n$ 且 $TP$ 变为真实异常的总数。\n\n**单个测试用例的逐步计算：**\n\n给定分数向量 $\\mathbf{s}$、真实标签向量 $\\mathbf{y}$ 和流行率 $\\pi$：\n1.  计算 $n = \\text{length}(\\mathbf{s})$。\n2.  计算 $k = \\lfloor \\pi n \\rfloor$。\n3.  如果 $k=0$，则精确率为 $0$。\n4.  如果 $k0$，创建一个索引列表 $I = [0, 1, \\dots, n-1]$。\n5.  基于键 $(-s_i, i)$ 对索引 $I$ 进行排序，得到排序后的列表 $I'$。\n6.  从 $I'$ 中选择前 $k$ 个索引，形成预测的异常索引集合 $I'_{\\text{anom}} = \\{I'_1, I'_2, \\dots, I'_k\\}$。\n7.  计算真阳性的数量：$TP = \\sum_{i \\in I'_{\\text{anom}}} y_i$。\n8.  计算精确率：$P = TP / k$。\n9.  对四个测试用例中的 OCSVM 和 IF 的分数都应用此过程。将得到的八个精确率值收集、四舍五入并格式化。\n\n**在测试用例上执行：**\n\n- **测试用例 1**：$n = 12$，$\\pi = 0.25$，$k = \\lfloor 0.25 \\times 12 \\rfloor = 3$。\n  - OCSVM：最高分在索引 $1$ ($0.95$)、$5$ ($0.90$) 和 $7$ ($0.85$)。预测的异常在索引 $\\{1, 5, 7\\}$。真实标签为 $y_1=1, y_5=0, y_7=1$。所以，$TP=2, FP=1$。精确率 $P = 2/3 \\approx 0.6667$。\n  - IF：最高分在索引 $5$ ($0.90$)、$1$ ($0.88$) 和 $6$ ($0.85$)。预测的异常：$\\{5, 1, 6\\}$。真实标签为 $y_5=0, y_1=1, y_6=0$。所以，$TP=1, FP=2$。精确率 $P = 1/3 \\approx 0.3333$。\n\n- **测试用例 2**：$n = 10$，$\\pi = 0.30$，$k = \\lfloor 0.30 \\times 10 \\rfloor = 3$。\n  - OCSVM：最高分在索引 $2$ ($0.95$)、$5$ ($0.85$)。第三个位置在索引 $3$ ($0.70$) 和索引 $8$ ($0.70$) 之间出现平局。打破平局的规则（较小索引获胜）选择了索引 $3$。预测的异常：$\\{2, 5, 3\\}$。真实标签为 $y_2=1, y_5=0, y_3=0$。所以，$TP=1, FP=2$。精确率 $P = 1/3 \\approx 0.3333$。\n  - IF：最高分在索引 $2$ ($0.92$)、$8$ ($0.89$) 和 $5$ ($0.80$)。预测的异常：$\\{2, 8, 5\\}$。真实标签为 $y_2=1, y_8=1, y_5=0$。所以，$TP=2, FP=1$。精确率 $P = 2/3 \\approx 0.6667$。\n\n- **测试用例 3**：$\\pi = 0.0$。\n  - 根据问题定义，OCSVM 和 IF 的精确率均为 $0.0000$。\n\n- **测试用例 4**：$\\pi = 1.0$。\n  - 根据问题定义，精确率是数据集中真实异常的比例。数据来自测试用例 1，其中 12 个样本中有 4 个异常。\n  - 对于 OCSVM 和 IF，精确率均为 $4/12 = 1/3 \\approx 0.3333$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes precision for OCSVM and IF methods on four test cases\n    and prints the results in the specified format.\n    \"\"\"\n\n    def compute_precision(scores, labels, pi):\n        \"\"\"\n        Calculates precision based on a prevalence-based threshold.\n\n        Args:\n            scores (np.ndarray): Anomaly scores for each sample.\n            labels (np.ndarray): Ground-truth labels (1 for anomaly, 0 for normal).\n            pi (float): Target anomaly prevalence.\n\n        Returns:\n            float: The calculated precision.\n        \"\"\"\n        n = len(scores)\n\n        # Handle the boundary case pi=0 as per problem definition.\n        if pi == 0.0:\n            return 0.0\n\n        num_anomalies = int(np.floor(pi * n))\n\n        # If k=0, no anomalies are predicted, so TP=0, FP=0, and precision is 0.\n        if num_anomalies == 0:\n            return 0.0\n        \n        # Handle the boundary case pi=1 as per problem definition.\n        if pi == 1.0:\n            return np.sum(labels) / n\n\n        # For 0  pi  1:\n        # Create a list of indices from 0 to n-1.\n        indices = np.arange(n)\n\n        # Sort indices based on the specified lexicographical rule:\n        # Primary key: score (descending).\n        # Secondary key: index (ascending).\n        sorted_indices = sorted(indices, key=lambda i: (-scores[i], i))\n\n        # Select the top k indices as predicted anomalies.\n        top_k_indices = sorted_indices[:num_anomalies]\n\n        # Calculate True Positives (TP).\n        tp = 0\n        for i in top_k_indices:\n            if labels[i] == 1:\n                tp += 1\n        \n        # The number of predicted positives is TP + FP = num_anomalies.\n        # Precision is TP / (TP + FP).\n        precision = tp / num_anomalies\n        \n        return precision\n\n    # Test suite data\n    # Test case 1 data\n    s_ocsvm1 = np.array([0.10, 0.95, 0.40, 0.30, 0.60, 0.90, 0.20, 0.85, 0.50, 0.55, 0.15, 0.45])\n    s_if1 = np.array([0.12, 0.88, 0.80, 0.65, 0.50, 0.90, 0.85, 0.40, 0.30, 0.45, 0.20, 0.60])\n    y1 = np.array([0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n    pi1 = 0.25\n\n    # Test case 2 data\n    s_ocsvm2 = np.array([0.10, 0.50, 0.95, 0.70, 0.40, 0.85, 0.20, 0.60, 0.70, 0.30])\n    s_if2 = np.array([0.30, 0.60, 0.92, 0.70, 0.45, 0.80, 0.20, 0.58, 0.89, 0.40])\n    y2 = np.array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n    pi2 = 0.30\n\n    # Test cases parameters\n    test_cases = [\n        # (s_ocsvm, s_if, y, pi)\n        (s_ocsvm1, s_if1, y1, pi1),  # Test case 1\n        (s_ocsvm2, s_if2, y2, pi2),  # Test case 2\n        (s_ocsvm1, s_if1, y1, 0.0),  # Test case 3\n        (s_ocsvm1, s_if1, y1, 1.0),  # Test case 4\n    ]\n\n    results = []\n    for s_ocsvm, s_if, y, pi in test_cases:\n        p_ocsvm = compute_precision(s_ocsvm, y, pi)\n        p_if = compute_precision(s_if, y, pi)\n        results.extend([p_ocsvm, p_if])\n\n    # Format results to four decimal places and print in the required format.\n    formatted_results = [f\"{res:.4f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "仅仅知道模型的性能好坏还不够，理解模型为何将某个特定数据点标记为异常也同样重要。本练习深入探讨了单类支持向量机 (One-Class SVM) 的内部工作原理。通过计算决策函数 $f(x)$ 在某个异常点 $x$ 处的梯度 $\\nabla_{x} f(x)$，我们将揭示一个几何直觉：这个梯度指明了将该点“正常化”的最有效路径。这项实践不仅能加深你对核方法的数学理解，也是模型可解释性领域中的一个核心思想。",
            "id": "3099119",
            "problem": "一个使用径向基函数 (RBF) 核的单类支持向量机 (SVM) 在二维空间中进行训练，用于异常检测。决策函数由核表示法定义为\n$$\nf(x) \\;=\\; \\sum_{i=1}^{n} \\alpha_{i} \\, k(x, x_{i}) \\;-\\; \\rho,\n$$\n其中径向基函数 (RBF) 核为\n$$\nk(x, z) \\;=\\; \\exp\\!\\big(-\\gamma \\, \\|x - z\\|^{2}\\big),\n$$\n当 $f(x)  0$ 时，候选点被标记为异常。考虑一个模型，其有 $n=3$ 个支持向量，权重由下式给出\n$$\n\\alpha_{1} = 0.5, \\quad \\alpha_{2} = 0.3, \\quad \\alpha_{3} = 0.2, \\quad \\gamma = 1.2, \\quad \\rho = 0.25,\n$$\n位于\n$$\nx_{1} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad x_{2} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad x_{3} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}.\n$$\n一个测试点\n$$\nx = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n被标记为异常。从核方法和多元微积分的基本原理出发，完成以下任务：\n- 计算决策函数在点 $x$ 处的梯度 $\\nabla_{x} f(x)$。\n- 使用 $f$ 在 $x$ 附近的一阶近似，推导并计算将 $x$ 移动到局部决策边界 $f(x + \\delta) = 0$ 上的最小欧几里得范数扰动向量 $\\delta^{\\star}$。\n\n将你的最终答案表示为行矩阵形式的扰动向量 $\\delta^{\\star}$。将向量的每个分量四舍五入到四位有效数字。不涉及物理单位。",
            "solution": "目标是找到最小扰动 $\\delta^{\\star}$，将一个被标记为异常的点 $x$ 移动到由 $f(x + \\delta) = 0$ 定义的决策边界上。我们将为此使用一阶近似。\n\n**第一步：计算决策函数的梯度 $\\nabla_{x} f(x)$**\n\n决策函数为 $f(x) = \\sum_{i=1}^{n} \\alpha_{i} k(x, x_{i}) - \\rho$。其关于 $x$ 的梯度为：\n$$\n\\nabla_{x} f(x) = \\nabla_{x} \\left( \\sum_{i=1}^{n} \\alpha_{i} k(x, x_{i}) - \\rho \\right) = \\sum_{i=1}^{n} \\alpha_{i} \\nabla_{x} k(x, x_{i})\n$$\n对于 RBF 核 $k(x, z) = \\exp(-\\gamma \\|x - z\\|^{2})$，其梯度使用链式法则求得：\n$$\n\\nabla_{x} k(x, z) = \\nabla_{x} \\exp(-\\gamma \\|x - z\\|^{2}) = \\exp(-\\gamma \\|x - z\\|^{2}) \\cdot \\nabla_{x} (-\\gamma \\|x - z\\|^{2})\n$$\n由于 $\\|x - z\\|^{2} = (x - z)^{T}(x - z)$，其梯度为 $\\nabla_{x} (x-z)^{T}(x-z) = 2(x-z)$。所以，\n$$\n\\nabla_{x} k(x, z) = k(x, z) \\cdot (-\\gamma) \\cdot 2(x - z) = -2\\gamma (x - z) k(x, z)\n$$\n将此代入 $f(x)$ 的梯度表达式中：\n$$\n\\nabla_{x} f(x) = -2\\gamma \\sum_{i=1}^{n} \\alpha_{i} (x - x_{i}) k(x, x_{i})\n$$\n现在，我们代入给定值：$x = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$，$\\gamma = 1.2$，以及支持向量 $x_1, x_2, x_3$ 和它们的权重 $\\alpha_1, \\alpha_2, \\alpha_3$。\n\n首先，计算欧几里得距离的平方和核函数值：\n- $x_{1}$: $\\|x - x_{1}\\|^{2} = \\|(1, 1) - (0, 0)\\|^{2} = 1^2 + 1^2 = 2$.\n   $k(x, x_{1}) = \\exp(-1.2 \\cdot 2) = \\exp(-2.4) \\approx 0.090718$.\n- $x_{2}$: $\\|x - x_{2}\\|^{2} = \\|(1, 1) - (1, 0)\\|^{2} = 0^2 + 1^2 = 1$.\n   $k(x, x_{2}) = \\exp(-1.2 \\cdot 1) = \\exp(-1.2) \\approx 0.301194$.\n- $x_{3}$: $\\|x - x_{3}\\|^{2} = \\|(1, 1) - (0, 1)\\|^{2} = 1^2 + 0^2 = 1$.\n   $k(x, x_{3}) = \\exp(-1.2 \\cdot 1) = \\exp(-1.2) \\approx 0.301194$.\n\n现在计算梯度向量：\n$$\n\\nabla_{x} f(x) = -2(1.2) \\left[ \\alpha_{1} (x - x_{1}) k(x, x_{1}) + \\alpha_{2} (x - x_{2}) k(x, x_{2}) + \\alpha_{3} (x - x_{3}) k(x, x_{3}) \\right]\n$$\n$$\n\\nabla_{x} f(x) = -2.4 \\left[ 0.5 \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} (0.090718) + 0.3 \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} (0.301194) + 0.2 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} (0.301194) \\right]\n$$\n让我们计算各个分量：\n$$\n\\begin{align*}\n(\\nabla_{x} f(x))_1 = -2.4 \\left[ 0.5(1)(0.090718) + 0.3(0)(0.301194) + 0.2(1)(0.301194) \\right] \\\\\n= -2.4 [0.045359 + 0 + 0.0602388] = -2.4 [0.1055978] \\approx -0.25343\n\\end{align*}\n$$\n$$\n\\begin{align*}\n(\\nabla_{x} f(x))_2 = -2.4 \\left[ 0.5(1)(0.090718) + 0.3(1)(0.301194) + 0.2(0)(0.301194) \\right] \\\\\n= -2.4 [0.045359 + 0.0903582 + 0] = -2.4 [0.1357172] \\approx -0.32572\n\\end{align*}\n$$\n所以，梯度为：\n$$\n\\nabla_{x} f(x) \\approx \\begin{pmatrix} -0.25343 \\\\ -0.32572 \\end{pmatrix}\n$$\n\n**第二步：计算最小扰动 $\\delta^{\\star}$**\n\n我们使用 $f$ 在 $x$ 周围的一阶泰勒近似：\n$$\nf(x + \\delta) \\approx f(x) + (\\nabla_{x} f(x))^{T} \\delta\n$$\n我们想要找到将点移动到决策边界的 $\\delta$，所以我们设置 $f(x + \\delta) = 0$：\n$$\n(\\nabla_{x} f(x))^{T} \\delta \\approx -f(x)\n$$\n我们需要找到满足此线性约束且具有最小欧几里得范数 $\\|\\delta\\|$ 的向量 $\\delta$。这个问题的解是一个与约束超平面的法向量（即 $\\nabla_{x} f(x)$）平行的向量 $\\delta^{\\star}$。\n设 $\\delta^{\\star} = c \\cdot \\nabla_{x} f(x)$，其中 $c$ 为某个标量。将其代入约束条件中：\n$$\n(\\nabla_{x} f(x))^{T} (c \\cdot \\nabla_{x} f(x)) = -f(x) \\implies c \\, \\|\\nabla_{x} f(x)\\|^{2} = -f(x)\n$$\n解出 $c$：\n$$\nc = -\\frac{f(x)}{\\|\\nabla_{x} f(x)\\|^{2}}\n$$\n因此，最优扰动为：\n$$\n\\delta^{\\star} = -\\frac{f(x)}{\\|\\nabla_{x} f(x)\\|^{2}} \\nabla_{x} f(x)\n$$\n首先，我们需要计算在测试点 $x = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ 处的 $f(x)$：\n$$\n\\begin{align*}\nf(x) = \\alpha_{1}k(x,x_{1}) + \\alpha_{2}k(x,x_{2}) + \\alpha_{3}k(x,x_{3}) - \\rho \\\\\n= 0.5(0.090718) + 0.3(0.301194) + 0.2(0.301194) - 0.25 \\\\\n= 0.045359 + 0.0903582 + 0.0602388 - 0.25 \\\\\n= 0.195956 - 0.25 = -0.054044\n\\end{align*}\n$$\n接下来，我们计算梯度的范数平方：\n$$\n\\begin{align*}\n\\|\\nabla_{x} f(x)\\|^{2} \\approx (-0.25343)^2 + (-0.32572)^2 \\\\\n\\approx 0.064226 + 0.106094 = 0.17032\n\\end{align*}\n$$\n现在我们可以计算扰动向量 $\\delta^{\\star}$：\n$$\n\\delta^{\\star} \\approx -\\frac{-0.054044}{0.17032} \\begin{pmatrix} -0.25343 \\\\ -0.32572 \\end{pmatrix} \\approx 0.31731 \\begin{pmatrix} -0.25343 \\\\ -0.32572 \\end{pmatrix}\n$$\n结果是一个向量：\n$$\n\\delta^{\\star} \\approx \\begin{pmatrix} -0.080415 \\\\ -0.10340 \\end{pmatrix}\n$$\n将每个分量四舍五入到四位有效数字，我们得到：\n$$\n\\delta^{\\star} \\approx \\begin{pmatrix} -0.08042 \\\\ -0.1034 \\end{pmatrix}\n$$\n表示为行矩阵：\n$$\n\\begin{pmatrix} -0.08042  -0.1034 \\end{pmatrix}\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix} -0.08042  -0.1034 \\end{pmatrix}}$$"
        },
        {
            "introduction": "直接对原始异常分数设定一个简单的阈值，未必是实现最佳检测性能的方法。这项高级实践将探讨一种基于统计决策理论的强大校准技术。通过使用高斯混合模型对正常和异常数据的分数分布进行建模，我们可以构建一个似然比检验 $\\Lambda(s)$。根据内曼-皮尔逊引理 (Neyman-Pearson lemma)，基于似然比的决策规则在固定的假阳性率下具有最高的检测能力，从而帮助我们做出更精确的判断。",
            "id": "3099077",
            "problem": "您将实现并评估一种用于异常检测决策分数的半参数校准方法，该方法使用高斯混合模型来估计类条件分数密度，并在固定的假阳性率下采用似然比阈值法。其应用背景是使用单类支持向量机 (OCSVM) 和孤立森林 (IF) 进行异常检测，这两种方法都为每个样本生成标量决策分数。OCSVM 的决策函数通常表示为 $f(x)$；我们采用异常分数 $s=-f(x)$，以便更大的 $s$ 值表示更高的异常可能性。对于 IF，我们将其异常分数 $s$ 视为实线上的标量，同样是值越大表示异常可能性越高。您将获得代表 OCSVM 和 IF 典型输出的、合成的、具有科学合理性的分数分布。您的程序必须使用高斯混合模型估计正常分数和注入的异常分数的类条件密度，然后应用似然比检验原理来设置阈值。最后，您需要将此校准后的决策规则与在相同假阳性率下对原始分数进行朴素阈值处理的方法进行比较。\n\n使用的基础理论：\n- 基于 Neyman–Pearson 范式的似然比检验：在固定的假阳性率 $\\alpha$ 下，最有效的检验方法是将似然比 $\\Lambda(s)=\\frac{p(s\\mid y=\\text{anomaly})}{p(s\\mid y=\\text{normal})}$ 超过某个阈值的得分 $s$ 分类为异常。该阈值的选择是为了满足指定的假阳性率 $\\alpha$，其中 $p(\\cdot\\mid y)$ 表示类条件密度。\n- 使用高斯混合模型的半参数化建模：每个类条件密度都表示为有限个单变量高斯分布的混合，其参数通过最大似然法从数据中估计得出。\n\n您的任务：\n- 对于每个测试用例，使用固定的随机种子生成两组一维分数：一组来自正常分数分布，另一组来自注入的异常分数分布。每个分布都由指定的成分权重、均值和标准差定义。分数越大表示异常可能性越高。\n- 使用期望最大化 (Expectation–Maximization) 过程，通过最大似然法将一个高斯混合模型拟合到正常分数上，并将另一个（可能不同的）高斯混合模型拟合到异常分数上。每次拟合都必须是单变量的，并使用指定数量的混合成分。\n- 计算类条件密度估计值 $\\hat{p}(s\\mid y=\\text{normal})$ 和 $\\hat{p}(s\\mid y=\\text{anomaly})$。构建似然比 $\\hat{\\Lambda}(s)=\\frac{\\hat{p}(s\\mid y=\\text{anomaly})}{\\hat{p}(s\\mid y=\\text{normal})}$。\n- 通过将校准阈值 $\\tau$ 设置为正常分数上 $\\hat{\\Lambda}(s)$ 的 $1-\\alpha$ 分位数，来选择该阈值以达到假阳性率 $\\alpha$。如果一个分数的 $\\hat{\\Lambda}(s)\\tau$，则将其分类为异常。计算由此产生的真阳性率（被分类为异常的异常分数所占的比例）。\n- 作为基准，通过将原始分数阈值 $t$ 设置为正常分数上原始分数的 $1-\\alpha$ 分位数，来选择该阈值以达到相同的假阳性率 $\\alpha$。如果一个分数 $st$，则将其分类为异常。计算由此产生的真阳性率。\n- 对于每个测试用例，输出定义为校准后的真阳性率与原始分数真阳性率之差的提升值。假阳性率 $\\alpha$ 的值以小数形式指定。不涉及物理单位。\n\n测试套件和参数：\n- 案例 $1$（理想情况，类似 IF 的分离）：\n  - 正常混合模型：权重 $[0.6,0.4]$，均值 $[0.22,0.38]$，标准差 $[0.05,0.04]$，样本量 $300$。\n  - 异常混合模型：权重 $[1.0]$，均值 $[0.72]$，标准差 $[0.06]$，样本量 $30$。\n  - 使用 $K_{\\text{normal}}=2$ 和 $K_{\\text{anomaly}}=1$ 进行拟合。假阳性率 $\\alpha=0.1$。种子 $1$。\n- 案例 $2$（双峰正态分布，中心异常，通过分数方向调整来处理类似 OCSVM 的分数反转）：\n  - 正常混合模型：权重 $[0.5,0.5]$，均值 $[0.15,0.85]$，标准差 $[0.04,0.06]$，样本量 $300$。\n  - 异常混合模型：权重 $[1.0]$，均值 $[0.50]$，标准差 $[0.07]$，样本量 $30$。\n  - 使用 $K_{\\text{normal}}=2$ 和 $K_{\\text{anomaly}}=1$ 进行拟合。假阳性率 $\\alpha=0.1$。种子 $2$。\n- 案例 $3$（类别不平衡和异方差异常）：\n  - 正常混合模型：权重 $[1.0]$，均值 $[0.30]$，标准差 $[0.05]$，样本量 $1000$。\n  - 异常混合模型：权重 $[1.0]$，均值 $[0.60]$，标准差 $[0.20]$，样本量 $10$。\n  - 使用 $K_{\\text{normal}}=1$ 和 $K_{\\text{anomaly}}=2$ 进行拟合。假阳性率 $\\alpha=0.05$。种子 $3$。\n- 案例 $4$（分布近似相同，边界情况）：\n  - 正常混合模型：权重 $[1.0]$，均值 $[0.50]$，标准差 $[0.10]$，样本量 $500$。\n  - 异常混合模型：权重 $[1.0]$，均值 $[0.55]$，标准差 $[0.10]$，样本量 $50$。\n  - 使用 $K_{\\text{normal}}=1$ 和 $K_{\\text{anomaly}}=1$ 进行拟合。假阳性率 $\\alpha=0.1$。种子 $4$。\n\n程序要求：\n- 从零开始实现通过期望最大化算法拟合单变量高斯混合模型，不使用外部机器学习库。\n- 使用指定的种子进行可复现的采样。\n- 对每个案例，计算浮点数形式的提升值。将所有提升值按顺序汇总到一个输出列表中。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 `[r_1,r_2,r_3,r_4]`），其中每个 $r_i$ 是案例 $i$ 的提升值，表示为小数值。",
            "solution": "问题陈述经评估有效。它在科学上基于统计学习理论，表述清晰且提供了所有必要参数，并且其阐述是客观的。任务是实现并评估一种基于 Neyman-Pearson 检验范式的用于异常检测分数的半参数校准方法。\n\n核心原理是将原始异常分数 $s$ 转换到一个更具判别性的空间，该空间由似然比 $\\Lambda(s) = \\frac{p(s|y=\\text{anomaly})}{p(s|y=\\text{normal})}$ 定义，其中 $y$ 表示类别标签。Neyman-Pearson 引理指出，对于给定的显著性水平（假阳性率），当 $\\Lambda(s)$ 超过某个阈值时拒绝原假设（$y=\\text{normal}$）的检验是最优检验。\n\n我们的方法是半参数化的，因为我们不为类条件密度 $p(s|y)$ 假设一个单一、简单的形式。相反，我们将每个密度建模为单变量高斯混合模型 (GMM)，这是一种用于表示复杂、多峰分布的灵活而强大的选择。在具有 $K$ 个成分的 GMM 下，一个分数 $s$ 的密度由下式给出：\n$$p(s) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(s \\mid \\mu_k, \\sigma_k^2)$$\n其中 $\\pi_k$ 是混合权重（$\\sum \\pi_k = 1$），$\\mu_k$ 和 $\\sigma_k^2$ 分别是第 $k$ 个高斯成分 $\\mathcal{N}$ 的均值和方差。\n\n这些 GMM 的参数（$\\pi_k, \\mu_k, \\sigma_k$）不是先验已知的，必须从提供的正常类别和异常类别的分数数据中进行估计。我们采用期望最大化 (EM) 算法，这是一种用于在具有潜在变量的统计模型中寻找参数的最大似然估计的迭代过程。在 GMM 的背景下，潜在变量是每个数据点所属的成分标识。\n\nEM 算法分两步进行：\n1.  **期望 (E) 步**：给定当前的参数估计，我们计算每个数据点 $s_i$ 属于每个成分 $k$ 的后验概率，或称为“责任”。这由贝叶斯定理给出：\n    $$\\gamma_{ik} = \\frac{\\pi_k \\mathcal{N}(s_i \\mid \\mu_k, \\sigma_k^2)}{\\sum_{j=1}^{K} \\pi_j \\mathcal{N}(s_i \\mid \\mu_j, \\sigma_j^2)}$$\n2.  **最大化 (M) 步**：我们使用计算出的责任来更新模型参数，以最大化期望对数似然。更新公式如下：\n    -   成分 $k$ 中的有效点数：$N_k = \\sum_{i=1}^{N} \\gamma_{ik}$\n    -   新权重：$\\pi_k^{\\text{new}} = \\frac{N_k}{N}$\n    -   新均值：$\\mu_k^{\\text{new}} = \\frac{1}{N_k} \\sum_{i=1}^{N} \\gamma_{ik} s_i$\n    -   新方差：$(\\sigma_k^2)^{\\text{new}} = \\frac{1}{N_k} \\sum_{i=1}^{N} \\gamma_{ik} (s_i - \\mu_k^{\\text{new}})^2$\n\n重复这些步骤，直到数据的对数似然 $LL = \\sum_{i=1}^{N} \\log(\\sum_{k=1}^{K} \\pi_k \\mathcal{N}(s_i \\mid \\mu_k, \\sigma_k^2))$ 收敛。对于 $K=1$ 的特殊情况，EM 算法是不必要的，因为最大似然估计就是样本均值和样本方差。\n\n每个测试用例的完整流程如下：\n1.  **数据生成**：使用指定的随机种子，从各自的 GMM 定义中生成 `normal_scores` 和 `anomaly_scores`。\n2.  **密度估计**：使用 EM 算法将一个具有 $K_{\\text{normal}}$ 个成分的 GMM 拟合到 `normal_scores` 上，并将另一个具有 $K_{\\text{anomaly}}$ 个成分的 GMM 拟合到 `anomaly_scores` 上。这将产生估计的密度 $\\hat{p}(s|y=\\text{normal})$ 和 $\\hat{p}(s|y=\\text{anomaly})$。\n3.  **基准评估（原始分数）**：\n    -   确定阈值 $t$ 为 `normal_scores` 的 $(1-\\alpha)$ 分位数。这确保了在训练正常数据上的假阳性率为 $\\alpha$。\n    -   计算真阳性率 $TPR_{raw}$，即大于 $t$ 的 `anomaly_scores` 的比例。\n4.  **校准评估（似然比）**：\n    -   对于 `normal_scores` 集合中的每个分数，计算估计的似然比 $\\hat{\\Lambda}(s) = \\frac{\\hat{p}(s|y=\\text{anomaly})}{\\hat{p}(s|y=\\text{normal})}$。在分母上加上一个很小的 epsilon 以防止除以零。\n    -   确定阈值 $\\tau$ 为这些计算出的似然比值的 $(1-\\alpha)$ 分位数。\n    -   对于 `anomaly_scores` 集合中的每个分数，计算其 $\\hat{\\Lambda}(s)$。\n    -   计算校准后的真阳性率 $TPR_{calibrated}$，即这些异常似然比大于 $\\tau$ 的比例。\n5.  **性能比较**：该案例的最终输出是提升值，定义为差值 $TPR_{calibrated} - TPR_{raw}$。这量化了在固定假阳性率下，通过校准程序实现的检测能力的增益。\n\n对所有指定的测试用例重复此过程，以评估该方法在不同分数分布场景下的有效性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef generate_gmm_samples(weights, means, stds, n_samples):\n    \"\"\"Generates samples from a Gaussian Mixture Model.\"\"\"\n    component_choices = np.random.choice(len(weights), size=n_samples, p=weights)\n    samples = np.random.normal(loc=np.array(means)[component_choices], scale=np.array(stds)[component_choices])\n    return samples\n\ndef gmm_pdf(x, weights, means, stds):\n    \"\"\"Calculates the PDF of a GMM at points x.\"\"\"\n    pdf_val = np.zeros_like(x, dtype=float)\n    for w, m, s in zip(weights, means, stds):\n        pdf_val += w * norm.pdf(x, loc=m, scale=s)\n    return pdf_val\n\ndef fit_gmm_em(data, K, n_iter=150, tol=1e-6):\n    \"\"\"Fits a univariate GMM using the Expectation-Maximization algorithm.\"\"\"\n    n_samples = len(data)\n    \n    if K == 1:\n        mean = np.mean(data)\n        std = np.std(data)\n        if std  1e-6: std = 1e-6 # handle cases with identical data points\n        return np.array([1.0]), np.array([mean]), np.array([std])\n\n    # Initialization\n    weights = np.ones(K) / K\n    # Deterministic initialization based on data range\n    means = np.linspace(np.min(data), np.max(data), K)\n    stds = np.full(K, np.std(data))\n    \n    prev_log_likelihood = -np.inf\n    \n    for _ in range(n_iter):\n        # E-step: Calculate responsibilities\n        weighted_pdfs = np.zeros((n_samples, K))\n        for k in range(K):\n            # Prevent std dev from becoming zero\n            s_k = stds[k] if stds[k] > 1e-6 else 1e-6\n            weighted_pdfs[:, k] = weights[k] * norm.pdf(data, means[k], s_k)\n        \n        total_likelihood_per_point = np.sum(weighted_pdfs, axis=1)\n        \n        # Add a small constant to prevent log(0) and division by zero\n        safe_total_likelihood = total_likelihood_per_point + 1e-9\n        responsibilities = weighted_pdfs / safe_total_likelihood[:, np.newaxis]\n        \n        # Check for convergence\n        log_likelihood = np.sum(np.log(safe_total_likelihood))\n        if abs(log_likelihood - prev_log_likelihood)  tol:\n            break\n        prev_log_likelihood = log_likelihood\n\n        # M-step: Update parameters\n        Nk = np.sum(responsibilities, axis=0)\n        safe_Nk = Nk + 1e-9 # Prevent division by zero\n        \n        weights = Nk / n_samples\n        means = np.sum(responsibilities * data[:, np.newaxis], axis=0) / safe_Nk\n        variances = np.sum(responsibilities * (data[:, np.newaxis] - means)**2, axis=0) / safe_Nk\n        stds = np.sqrt(variances)\n        \n        # Prevent component collapse\n        stds = np.maximum(stds, 1e-6)\n        \n    return weights, means, stds\n\ndef solve():\n    \"\"\"Main function to run the test suite and print results.\"\"\"\n    test_cases = [\n        # Case 1 (happy path, IF-like separation)\n        {'normal_w': [0.6, 0.4], 'normal_m': [0.22, 0.38], 'normal_s': [0.05, 0.04], 'n_normal': 300,\n         'anomaly_w': [1.0], 'anomaly_m': [0.72], 'anomaly_s': [0.06], 'n_anomaly': 30,\n         'k_normal': 2, 'k_anomaly': 1, 'alpha': 0.1, 'seed': 1},\n        # Case 2 (bimodal normal, central anomalies)\n        {'normal_w': [0.5, 0.5], 'normal_m': [0.15, 0.85], 'normal_s': [0.04, 0.06], 'n_normal': 300,\n         'anomaly_w': [1.0], 'anomaly_m': [0.50], 'anomaly_s': [0.07], 'n_anomaly': 30,\n         'k_normal': 2, 'k_anomaly': 1, 'alpha': 0.1, 'seed': 2},\n        # Case 3 (class imbalance and heteroscedastic anomalies)\n        {'normal_w': [1.0], 'normal_m': [0.30], 'normal_s': [0.05], 'n_normal': 1000,\n         'anomaly_w': [1.0], 'anomaly_m': [0.60], 'anomaly_s': [0.20], 'n_anomaly': 10,\n         'k_normal': 1, 'k_anomaly': 2, 'alpha': 0.05, 'seed': 3},\n        # Case 4 (near-identical distributions)\n        {'normal_w': [1.0], 'normal_m': [0.50], 'normal_s': [0.10], 'n_normal': 500,\n         'anomaly_w': [1.0], 'anomaly_m': [0.55], 'anomaly_s': [0.10], 'n_anomaly': 50,\n         'k_normal': 1, 'k_anomaly': 1, 'alpha': 0.1, 'seed': 4},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        np.random.seed(case['seed'])\n        \n        # 1. Generate data\n        normal_scores = generate_gmm_samples(case['normal_w'], case['normal_m'], case['normal_s'], case['n_normal'])\n        anomaly_scores = generate_gmm_samples(case['anomaly_w'], case['anomaly_m'], case['anomaly_s'], case['n_anomaly'])\n        \n        # 2. Fit GMMs\n        w_n, m_n, s_n = fit_gmm_em(normal_scores, case['k_normal'])\n        w_a, m_a, s_a = fit_gmm_em(anomaly_scores, case['k_anomaly'])\n        \n        # 3. Baseline TPR (Raw Score Thresholding)\n        raw_score_threshold = np.quantile(normal_scores, 1 - case['alpha'])\n        raw_tpr = np.mean(anomaly_scores > raw_score_threshold)\n        \n        # 4. Calibrated TPR (Likelihood-Ratio Thresholding)\n        # Denominator for likelihood ratio, with a small epsilon for stability\n        epsilon = 1e-9\n        \n        # Calculate LR on normal scores to find the threshold\n        p_normal_on_normal = gmm_pdf(normal_scores, w_n, m_n, s_n)\n        p_anomaly_on_normal = gmm_pdf(normal_scores, w_a, m_a, s_a)\n        lr_on_normal = p_anomaly_on_normal / (p_normal_on_normal + epsilon)\n        calibrated_threshold = np.quantile(lr_on_normal, 1 - case['alpha'])\n        \n        # Calculate LR on anomaly scores to get TPR\n        p_normal_on_anomaly = gmm_pdf(anomaly_scores, w_n, m_n, s_n)\n        p_anomaly_on_anomaly = gmm_pdf(anomaly_scores, w_a, m_a, s_a)\n        lr_on_anomaly = p_anomaly_on_anomaly / (p_normal_on_anomaly + epsilon)\n        calibrated_tpr = np.mean(lr_on_anomaly > calibrated_threshold)\n        \n        # 5. Compute improvement and store result\n        improvement = calibrated_tpr - raw_tpr\n        results.append(improvement)\n\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}