{
    "hands_on_practices": [
        {
            "introduction": "To begin, we will demystify the abstract nature of an RNN's hidden state. This exercise demonstrates that the hidden state vector, $h_t$, can be engineered to represent discrete information, such as the states of a simple computational model. By manually setting the network's weights, you will learn how to map the states of a Finite-State Machine (FSM) to specific geometric regions in the hidden state space, providing a concrete foundation for how RNNs encode and process information .",
            "id": "3168429",
            "problem": "Consider the regular language over the alphabet $\\{a, b\\}$ that consists of all strings whose last symbol is $a$. A deterministic finite-state machine (FSM) that recognizes this language has two states: $q_a$ (the last observed symbol is $a$) and $q_b$ (the last observed symbol is $b$). Its transition rule is: upon seeing input symbol $x_t \\in \\{a, b\\}$ at time $t$, the next state is $q_a$ if $x_t = a$ and $q_b$ if $x_t = b$, independent of the previous state.\n\nYou will construct a simple recurrent neural network (RNN) that emulates this FSM by mapping each FSM state to a distinct region of the hidden state space so that, for every time $t$, the hidden vector $h_t \\in \\mathbb{R}^2$ lies in the region corresponding to the current FSM state. Use the following fundamental definitions as the base of your derivation:\n- The Elman RNN recurrence is $h_t = \\tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$, where $\\tanh(\\cdot)$ is applied elementwise, $W_{hh} \\in \\mathbb{R}^{2 \\times 2}$, $W_{xh} \\in \\mathbb{R}^{2 \\times 2}$, and $b_h \\in \\mathbb{R}^2$.\n- One-hot input encoding: $x_t = (1, 0)^{\\top}$ for $x_t = a$ and $x_t = (0, 1)^{\\top}$ for $x_t = b$.\n\nImpose the architectural constraints $W_{hh} = 0$ and $b_h = 0$ to minimize recurrence complexity, and define the state-to-region mapping as follows:\n- Region for $q_a$: $\\mathcal{R}_a = \\{h \\in \\mathbb{R}^2 : h_1  0 \\text{ and } h_2  0\\}$.\n- Region for $q_b$: $\\mathcal{R}_b = \\{h \\in \\mathbb{R}^2 : h_1  0 \\text{ and } h_2  0\\}$.\n\nChoose a positive gain parameter $\\alpha  0$ and require that the pre-activation $z_t = W_{xh} x_t$ satisfies $z_t = \\alpha v_a$ when $x_t = a$ and $z_t = \\alpha v_b$ when $x_t = b$, where $v_a = (1, -1)^{\\top}$ and $v_b = (-1, 1)^{\\top}$. Under these constraints, the nonlinearity $\\tanh(\\cdot)$ drives $h_t$ into the appropriate region $\\mathcal{R}_a$ or $\\mathcal{R}_b$.\n\nDerive, from first principles and the above definitions, the explicit matrix $W_{xh} \\in \\mathbb{R}^{2 \\times 2}$ in terms of the parameter $\\alpha$ that achieves this behavior. Your final answer must be the single matrix $W_{xh}$, expressed exactly, with no rounding.",
            "solution": "The problem requires the derivation of the input-to-hidden weight matrix $W_{xh}$ for a simple recurrent neural network (RNN) that emulates a specific deterministic finite-state machine (FSM).\n\nFirst, we perform a validation of the problem statement.\n\n**Step 1: Extract Givens**\n- **RNN Recurrence Relation:** $h_t = \\tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$\n- **Dimensionality:** $h_t \\in \\mathbb{R}^2$, $W_{hh} \\in \\mathbb{R}^{2 \\times 2}$, $W_{xh} \\in \\mathbb{R}^{2 \\times 2}$, $b_h \\in \\mathbb{R}^2$.\n- **Input Encoding:** For input symbol '$a$', $x_t = (1, 0)^{\\top}$. For input symbol '$b$', $x_t = (0, 1)^{\\top}$.\n- **Architectural Constraints:** $W_{hh} = 0$ (the zero matrix in $\\mathbb{R}^{2 \\times 2}$) and $b_h = 0$ (the zero vector in $\\mathbb{R}^2$).\n- **State-to-Region Mapping:**\n  - State $q_a$ corresponds to region $\\mathcal{R}_a = \\{h \\in \\mathbb{R}^2 : h_1  0 \\text{ and } h_2  0\\}$.\n  - State $q_b$ corresponds to region $\\mathcal{R}_b = \\{h \\in \\mathbb{R}^2 : h_1  0 \\text{ and } h_2  0\\}$.\n- **Pre-activation Constraint:** The pre-activation is $z_t = W_{xh} x_t$.\n- **Gain Parameter:** A positive constant $\\alpha  0$.\n- **Pre-activation Targets:**\n  - If $x_t = a$, then $z_t = \\alpha v_a$, where $v_a = (1, -1)^{\\top}$.\n  - If $x_t = b$, then $z_t = \\alpha v_b$, where $v_b = (-1, 1)^{\\top}$.\n- **Objective:** Derive the matrix $W_{xh}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It provides a set of consistent and complete mathematical constraints to determine a unique matrix $W_{xh}$. The task is a standard exercise in understanding the mechanics of RNNs. The FSM described is simple and its behavior is memoryless regarding the state (it only depends on the current input), which is directly mirrored by the constraint $W_{hh} = 0$. All terms are formally defined. The problem is valid.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\nThe derivation begins with the general Elman RNN recurrence relation:\n$$h_t = \\tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$$\nThe problem imposes the constraints $W_{hh} = 0$ and $b_h = 0$. Substituting these into the recurrence relation simplifies it significantly:\n$$h_t = \\tanh(0 \\cdot h_{t-1} + W_{xh} x_t + 0)$$\n$$h_t = \\tanh(W_{xh} x_t)$$\nThe expression inside the elementwise $\\tanh$ function is the pre-activation, which is denoted as $z_t = W_{xh} x_t$. Thus, the hidden state is $h_t = \\tanh(z_t)$.\n\nThe goal is to find the matrix $W_{xh} \\in \\mathbb{R}^{2 \\times 2}$. Let us represent $W_{xh}$ by its column vectors, $c_1$ and $c_2$:\n$$W_{xh} = \\begin{pmatrix} c_1  c_2 \\end{pmatrix} = \\begin{pmatrix} w_{11}  w_{12} \\\\ w_{21}  w_{22} \\end{pmatrix}$$\nwhere $c_1 = \\begin{pmatrix} w_{11} \\\\ w_{21} \\end{pmatrix}$ and $c_2 = \\begin{pmatrix} w_{12} \\\\ w_{22} \\end{pmatrix}$.\n\nWe are given two conditions based on the input symbol, which we can use to determine these columns.\n\n**Case 1: Input symbol is '$a$'**\nThe input vector is the one-hot encoding $x_t = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. We compute the pre-activation $z_t$:\n$$z_t = W_{xh} x_t = \\begin{pmatrix} w_{11}  w_{12} \\\\ w_{21}  w_{22} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} w_{11} \\\\ w_{21} \\end{pmatrix} = c_1$$\nThe problem states that for this input, the pre-activation must be $z_t = \\alpha v_a$, where $v_a = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$.\nTherefore, we have our first column:\n$$c_1 = \\alpha v_a = \\alpha \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} \\alpha \\\\ -\\alpha \\end{pmatrix}$$\n\n**Case 2: Input symbol is '$b$'**\nThe input vector is the one-hot encoding $x_t = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. We compute the pre-activation $z_t$:\n$$z_t = W_{xh} x_t = \\begin{pmatrix} w_{11}  w_{12} \\\\ w_{21}  w_{22} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} w_{12} \\\\ w_{22} \\end{pmatrix} = c_2$$\nThe problem states that for this input, the pre-activation must be $z_t = \\alpha v_b$, where $v_b = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$.\nTherefore, we have our second column:\n$$c_2 = \\alpha v_b = \\alpha \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -\\alpha \\\\ \\alpha \\end{pmatrix}$$\n\nNow we assemble the matrix $W_{xh}$ from the columns $c_1$ and $c_2$:\n$$W_{xh} = \\begin{pmatrix} c_1  c_2 \\end{pmatrix} = \\begin{pmatrix} \\alpha  -\\alpha \\\\ -\\alpha  \\alpha \\end{pmatrix}$$\n\nTo confirm, let's check that this matrix correctly places the hidden state $h_t$ into the specified regions.\nIf the input is '$a$', $x_t = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, the pre-activation is $z_t = \\begin{pmatrix} \\alpha \\\\ -\\alpha \\end{pmatrix}$. The hidden state is:\n$$h_t = \\tanh(z_t) = \\begin{pmatrix} \\tanh(\\alpha) \\\\ \\tanh(-\\alpha) \\end{pmatrix} = \\begin{pmatrix} \\tanh(\\alpha) \\\\ -\\tanh(\\alpha) \\end{pmatrix}$$\nSince $\\alpha  0$, we know that $\\tanh(\\alpha)  0$. Thus, the first component of $h_t$ is positive ($h_1 = \\tanh(\\alpha)  0$) and the second component is negative ($h_2 = -\\tanh(\\alpha)  0$). This places $h_t$ in the region $\\mathcal{R}_a$, as required for FSM state $q_a$.\n\nIf the input is '$b$', $x_t = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, the pre-activation is $z_t = \\begin{pmatrix} -\\alpha \\\\ \\alpha \\end{pmatrix}$. The hidden state is:\n$$h_t = \\tanh(z_t) = \\begin{pmatrix} \\tanh(-\\alpha) \\\\ \\tanh(\\alpha) \\end{pmatrix} = \\begin{pmatrix} -\\tanh(\\alpha) \\\\ \\tanh(\\alpha) \\end{pmatrix}$$\nSince $\\alpha  0$, the first component of $h_t$ is negative ($h_1 = -\\tanh(\\alpha)  0$) and the second component is positive ($h_2 = \\tanh(\\alpha)  0$). This places $h_t$ in the region $\\mathcal{R}_b$, as required for FSM state $q_b$.\n\nThe derived matrix $W_{xh}$ satisfies all conditions specified in the problem. The RNN's state $h_t$ is determined solely by the current input $x_t$, which correctly emulates the memoryless transition rule of the given FSM.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\alpha  -\\alpha \\\\ -\\alpha  \\alpha \\end{pmatrix}}$$"
        },
        {
            "introduction": "Building on the idea of state representation, we now investigate what kinds of rules an RNN can learn automatically from data. This practice challenges you to train an RNN to distinguish between two classes of formal languages: a simple regular language and a more complex context-free language that requires counting . By testing the network's ability to generalize to sequences longer than any it has seen, you will gain empirical insight into the computational limits of simple RNNs and their capacity for extrapolation.",
            "id": "3168367",
            "problem": "You are asked to design and implement, from first principles, a binary classifier based on a Recurrent Neural Network (RNN) to study extrapolation beyond training sequence lengths on two formal languages over the alphabet $\\Sigma = \\{a,b\\}$. You will operationalize empirical risk minimization with gradient-based learning, and you will evaluate extrapolation to longer sequences for a regular language and a context-free language. Your program must implement a simple, fully specified RNN and report quantitative generalization metrics for a provided test suite.\n\nDefinitions and modeling assumptions:\n- The regular language is $L_{\\mathrm{reg}} = \\{ a^i b^j \\mid i \\ge 1, j \\ge 1 \\}$, which contains all strings consisting of a positive number of $a$ symbols followed by a positive number of $b$ symbols.\n- The context-free language is $L_{\\mathrm{cf}} = \\{ a^n b^n \\mid n \\ge 1 \\}$, which contains all strings with exactly $n$ $a$ symbols followed by exactly $n$ $b$ symbols.\n- A Recurrent Neural Network (RNN) with hidden state $\\mathbf{h}_t \\in \\mathbb{R}^H$ processes a sequence $(\\mathbf{x}_1,\\dots,\\mathbf{x}_T)$ of one-hot vectors $\\mathbf{x}_t \\in \\{0,1\\}^2$ where $\\mathbf{x}_t = [1,0]^\\top$ represents $a$ and $\\mathbf{x}_t = [0,1]^\\top$ represents $b$. The RNN state update is\n$$\n\\mathbf{h}_t = \\tanh\\!\\left(W_{xh}\\mathbf{x}_t + W_{hh}\\mathbf{h}_{t-1} + \\mathbf{b}_h\\right),\n$$\nwith $\\mathbf{h}_0 = \\mathbf{0}$, where $W_{xh} \\in \\mathbb{R}^{H \\times 2}$, $W_{hh} \\in \\mathbb{R}^{H \\times H}$, and $\\mathbf{b}_h \\in \\mathbb{R}^H$. The sequence-level output is computed only at the final time step $T$ as\n$$\n\\hat{y} = \\sigma\\!\\left(\\mathbf{w}_{hy}^\\top \\mathbf{h}_T + b_y\\right),\n$$\nwhere $\\mathbf{w}_{hy} \\in \\mathbb{R}^H$, $b_y \\in \\mathbb{R}$, and $\\sigma(z) = \\frac{1}{1+e^{-z}}$ is the logistic sigmoid function.\n- The training objective is to minimize the empirical binary cross-entropy\n$$\n\\mathcal{L} = -\\frac{1}{N}\\sum_{k=1}^N \\left[y^{(k)} \\log \\hat{y}^{(k)} + \\left(1 - y^{(k)}\\right) \\log \\left(1 - \\hat{y}^{(k)}\\right)\\right],\n$$\nover a finite training set of $N$ labeled sequences $\\{(\\mathbf{x}^{(k)}_{1:T_k}, y^{(k)})\\}_{k=1}^N$ with $y^{(k)} \\in \\{0,1\\}$. Optimization must be performed by gradient-based updates obtained via backpropagation through time, without using any automatic differentiation library.\n\nData generation protocol:\n- For the regular language $L_{\\mathrm{reg}}$, positive examples are strings $a^i b^j$ with $i \\in \\{1,\\dots,N_{\\mathrm{train}}\\}$ and $j \\in \\{1,\\dots,N_{\\mathrm{train}}\\}$. Negative examples are strings $a^i b^j a^k$ with $i,j,k \\in \\{1,\\dots,N_{\\mathrm{train}}\\}$, which violate the monotonic ordering constraint. Labels are $1$ for positives and $0$ for negatives.\n- For the context-free language $L_{\\mathrm{cf}}$, positive examples are strings $a^n b^n$ with $n \\in \\{1,\\dots,N_{\\mathrm{train}}\\}$. Negative examples for each $n$ are $a^n b^{n+1}$ and $a^{n+1} b^n$. Labels are $1$ for positives and $0$ for negatives.\n- For evaluation of extrapolation, the test sets contain only lengths strictly greater than the training maximum. For $L_{\\mathrm{reg}}$, test positives are $a^n b^n$ and test negatives are $a^n b^n a$ for $n \\in \\{N_{\\mathrm{train}}{+}1,\\dots,N_{\\mathrm{test}}\\}$. For $L_{\\mathrm{cf}}$, test positives are $a^n b^n$ and test negatives are $a^n b^{n+1}$ and $a^{n+1} b^n$ for $n \\in \\{N_{\\mathrm{train}}{+}1,\\dots,N_{\\mathrm{test}}\\}$.\n\nImplementation constraints:\n- Use only the Python Standard Library and the specified numerical libraries. No external datasets or user input is allowed.\n- Use a single-layer RNN as specified, with $\\tanh$ nonlinearity and a logistic sigmoid output. Employ fixed random seeds for reproducibility, and stochastic or mini-batch gradient descent with a well-defined learning rate schedule or an adaptive method that you must implement yourself.\n\nQuantities to compute:\n- For each test case, train the RNN on the respective training set, then compute the extrapolation test accuracy as the fraction of correct predictions on the test set restricted to lengths $n \\in \\{N_{\\mathrm{train}}{+}1,\\dots,N_{\\mathrm{test}}\\}$. Use a decision threshold of $0.5$ on $\\hat{y}$ to map to class labels.\n- Report the final extrapolation accuracies as floating-point numbers rounded to three decimal places.\n\nTest suite:\n- Test case $\\#1$ (happy path, regular language): language type $=$ $L_{\\mathrm{reg}}$, random seed $=$ $1$, hidden size $H = 16$, training maximum $N_{\\mathrm{train}} = 5$, testing maximum $N_{\\mathrm{test}} = 12$, number of epochs $= 300$, learning rate $= 0.03$.\n- Test case $\\#2$ (contrast, context-free language): language type $=$ $L_{\\mathrm{cf}}$, random seed $=$ $2$, hidden size $H = 16$, training maximum $N_{\\mathrm{train}} = 5$, testing maximum $N_{\\mathrm{test}} = 12$, number of epochs $= 300$, learning rate $= 0.03$.\n- Test case $\\#3$ (capacity boundary, regular language with small hidden size): language type $=$ $L_{\\mathrm{reg}}$, random seed $=$ $3$, hidden size $H = 2$, training maximum $N_{\\mathrm{train}} = 3$, testing maximum $N_{\\mathrm{test}} = 8$, number of epochs $= 300$, learning rate $= 0.03$.\n\nFinal output format:\n- Your program should produce a single line of output containing the three extrapolation accuracies, in the order of the test cases above, as a comma-separated list enclosed in square brackets, for example, `[0.975,0.533,0.912]`. The values must be rounded to exactly three decimal places.",
            "solution": "We begin from the foundational definitions of formal languages and the computational model of a Recurrent Neural Network (RNN). The regular language $L_{\\mathrm{reg}} = \\{ a^i b^j \\mid i \\ge 1, j \\ge 1 \\}$ is recognized by a deterministic finite automaton with a finite number of states that enforce a monotonic ordering constraint: consume one or more $a$ symbols, then one or more $b$ symbols, and reject any $a$ after a $b$. The context-free language $L_{\\mathrm{cf}} = \\{ a^n b^n \\mid n \\ge 1 \\}$ requires unbounded counting of the difference between the numbers of $a$ and $b$ symbols, which is not representable by a finite automaton. Although a Recurrent Neural Network is a differentiable dynamical system that can, in principle, emulate various behaviors, practical training and finite precision often limit its ability to extrapolate counting beyond the training regime.\n\nModel specification: The RNN maintains a hidden state $\\mathbf{h}_t \\in \\mathbb{R}^H$ and processes input vectors $\\mathbf{x}_t \\in \\{0,1\\}^2$ representing the current symbol. The state update is\n$$\n\\mathbf{h}_t = \\tanh\\!\\left(W_{xh}\\mathbf{x}_t + W_{hh}\\mathbf{h}_{t-1} + \\mathbf{b}_h\\right).\n$$\nThe sequence-level prediction $\\hat{y} \\in (0,1)$ is produced at the final step by\n$$\n\\hat{y} = \\sigma\\!\\left(\\mathbf{w}_{hy}^\\top \\mathbf{h}_T + b_y\\right),\n$$\nwith $\\sigma(z) = \\frac{1}{1+e^{-z}}$. The training objective is the empirical binary cross-entropy\n$$\n\\mathcal{L} = -\\frac{1}{N}\\sum_{k=1}^N \\left[y^{(k)} \\log \\hat{y}^{(k)} + \\left(1 - y^{(k)}\\right) \\log \\left(1 - \\hat{y}^{(k)}\\right)\\right].\n$$\n\nBackpropagation through time: For a single sequence with label $y \\in \\{0,1\\}$, define the pre-activation at time $t$ as\n$$\n\\mathbf{a}_t = W_{xh}\\mathbf{x}_t + W_{hh}\\mathbf{h}_{t-1} + \\mathbf{b}_h,\\quad \\mathbf{h}_t = \\tanh(\\mathbf{a}_t).\n$$\nLet $z = \\mathbf{w}_{hy}^\\top \\mathbf{h}_T + b_y$ and $\\hat{y} = \\sigma(z)$. The derivative of the loss with respect to the output pre-activation is\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial z} = \\hat{y} - y,\n$$\nwhich yields\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}_{hy}} = (\\hat{y} - y)\\,\\mathbf{h}_T,\\quad \\frac{\\partial \\mathcal{L}}{\\partial b_y} = \\hat{y} - y.\n$$\nThe gradient flowing into the final hidden state is\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_T} = (\\hat{y} - y)\\,\\mathbf{w}_{hy}.\n$$\nUsing $\\frac{d}{d\\mathbf{a}} \\tanh(\\mathbf{a}) = \\mathbf{1} - \\tanh^2(\\mathbf{a})$, define the local error signal at time $t$ as\n$$\n\\boldsymbol{\\delta}_t = \\left(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t}\\right) \\odot \\left(\\mathbf{1} - \\mathbf{h}_t \\odot \\mathbf{h}_t\\right),\n$$\nwhere $\\odot$ denotes elementwise multiplication. For $t = T$,\n$$\n\\boldsymbol{\\delta}_T = \\left((\\hat{y} - y)\\,\\mathbf{w}_{hy}\\right) \\odot \\left(\\mathbf{1} - \\mathbf{h}_T \\odot \\mathbf{h}_T\\right).\n$$\nGradients for the recurrent and input weights and biases accumulate as\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial W_{xh}} \\mathrel{+}= \\boldsymbol{\\delta}_t\\,\\mathbf{x}_t^\\top,\\quad\n\\frac{\\partial \\mathcal{L}}{\\partial W_{hh}} \\mathrel{+}= \\boldsymbol{\\delta}_t\\,\\mathbf{h}_{t-1}^\\top,\\quad\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_h} \\mathrel{+}= \\boldsymbol{\\delta}_t.\n$$\nThe error propagates backward in time via\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_{t-1}} = W_{hh}^\\top \\boldsymbol{\\delta}_t,\\quad\n\\boldsymbol{\\delta}_{t-1} = \\left(W_{hh}^\\top \\boldsymbol{\\delta}_t\\right) \\odot \\left(\\mathbf{1} - \\mathbf{h}_{t-1} \\odot \\mathbf{h}_{t-1}\\right).\n$$\nThis recursion proceeds for $t = T, T-1, \\dots, 1$. Gradient clipping can be applied to $\\ell_2$-norms to stabilize training.\n\nOptimization: Parameters $\\Theta = \\{W_{xh}, W_{hh}, \\mathbf{b}_h, \\mathbf{w}_{hy}, b_y\\}$ are updated by a first-order method. An adaptive moment method such as Adam maintains, for each parameter $\\theta \\in \\Theta$, first and second moment estimates\n$$\n\\mathbf{m}_t = \\beta_1 \\mathbf{m}_{t-1} + (1 - \\beta_1)\\,\\nabla_\\theta \\mathcal{L},\\quad\n\\mathbf{v}_t = \\beta_2 \\mathbf{v}_{t-1} + (1 - \\beta_2)\\,\\left(\\nabla_\\theta \\mathcal{L}\\right)^2,\n$$\nwith bias corrections\n$$\n\\hat{\\mathbf{m}}_t = \\frac{\\mathbf{m}_t}{1 - \\beta_1^t},\\quad\n\\hat{\\mathbf{v}}_t = \\frac{\\mathbf{v}_t}{1 - \\beta_2^t},\n$$\nand update\n$$\n\\theta \\leftarrow \\theta - \\alpha \\frac{\\hat{\\mathbf{m}}_t}{\\sqrt{\\hat{\\mathbf{v}}_t} + \\epsilon},\n$$\nwhere $\\alpha$ is the learning rate, $\\beta_1 \\in (0,1)$, $\\beta_2 \\in (0,1)$, and $\\epsilon  0$.\n\nData generation rationale: For $L_{\\mathrm{reg}}$, positive examples enforce the monotone block structure $a^i b^j$ with $i \\ge 1$ and $j \\ge 1$, while negatives $a^i b^j a^k$ with $k \\ge 1$ explicitly violate it, preventing trivial heuristics. For $L_{\\mathrm{cf}}$, positives $a^n b^n$ require equal counts; negatives $a^n b^{n+1}$ and $a^{n+1} b^n$ are near-misses that force learning of equality rather than mere ordering or total length. Training uses lengths up to $N_{\\mathrm{train}}$, while extrapolation is evaluated on $n \\in \\{N_{\\mathrm{train}}{+}1,\\dots,N_{\\mathrm{test}}\\}$.\n\nExpected outcomes and interpretation: Because the property defining $L_{\\mathrm{reg}}$ is finite-state, a trained RNN with $\\tanh$ units can learn an internal state machine that distinguishes whether $a$ has been seen after any $b$, and extrapolate to longer runs by virtue of its state dynamics, yielding high extrapolation accuracy. In contrast, $L_{\\mathrm{cf}}$ requires precise unbounded counting to check equality of counts, a behavior that is difficult to learn and extrapolate with a simple RNN trained only on small $n$. Therefore, we expect lower extrapolation accuracy on $L_{\\mathrm{cf}}$ for $n  N_{\\mathrm{train}}$. The capacity boundary case with $H = 2$ further probes whether minimal hidden dimensionality suffices for the regular pattern and how robust the learned state-machine-like dynamics are.\n\nAlgorithmic procedure:\n- Initialize parameters with small random values and zeros for moment estimates.\n- Generate training sets for $L_{\\mathrm{reg}}$ or $L_{\\mathrm{cf}}$ as specified, using fixed random seeds for reproducibility.\n- For a fixed number of epochs, iterate through the training set (randomly permuted), perform a forward pass to compute $\\hat{y}$, compute the loss and gradients via backpropagation through time, apply gradient clipping, and update parameters via Adam.\n- After training, generate test sequences with lengths $n \\in \\{N_{\\mathrm{train}}{+}1,\\dots,N_{\\mathrm{test}}\\}$ as specified for the chosen language. Compute predictions with a $0.5$ threshold and calculate the fraction of correct predictions (accuracy).\n- Round each test case accuracy to three decimal places and print the results in the required aggregate format.\n\nThis solution links the mathematical underpinnings of RNN sequence processing and gradient-based learning with empirically testable extrapolation behavior on formal languages, enabling direct comparison between regular and context-free generalization by measuring accuracies for $n  N_{\\mathrm{train}}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef sigmoid(x):\n    # Numerically stable sigmoid\n    # Clip to avoid overflow in exp\n    x = np.clip(x, -40.0, 40.0)\n    return 1.0 / (1.0 + np.exp(-x))\n\ndef one_hot_seq_a_b(count_a, count_b):\n    # 'a' - [1,0], 'b' - [0,1]\n    seq = []\n    for _ in range(count_a):\n        seq.append(np.array([1.0, 0.0], dtype=np.float64))\n    for _ in range(count_b):\n        seq.append(np.array([0.0, 1.0], dtype=np.float64))\n    return seq\n\ndef one_hot_seq_a_b_a(count_a, count_b, count_a2):\n    seq = []\n    for _ in range(count_a):\n        seq.append(np.array([1.0, 0.0], dtype=np.float64))\n    for _ in range(count_b):\n        seq.append(np.array([0.0, 1.0], dtype=np.float64))\n    for _ in range(count_a2):\n        seq.append(np.array([1.0, 0.0], dtype=np.float64))\n    return seq\n\ndef generate_dataset_regular(N_train):\n    # Positives: a^i b^j, i,j in 1..N_train\n    # Negatives: a^i b^j a^k, i,j,k in 1..N_train\n    data = []\n    # positives\n    for i in range(1, N_train + 1):\n        for j in range(1, N_train + 1):\n            seq = one_hot_seq_a_b(i, j)\n            data.append((seq, 1))\n    # negatives\n    for i in range(1, N_train + 1):\n        for j in range(1, N_train + 1):\n            for k in [1]:  # one violation per (i,j) to keep dataset small\n                seq = one_hot_seq_a_b_a(i, j, k)\n                data.append((seq, 0))\n    return data\n\ndef generate_dataset_cf(N_train):\n    # Positives: a^n b^n, n in 1..N_train\n    # Negatives: a^n b^{n+1}, a^{n+1} b^n\n    data = []\n    for n in range(1, N_train + 1):\n        data.append((one_hot_seq_a_b(n, n), 1))\n        data.append((one_hot_seq_a_b(n, n + 1), 0))\n        data.append((one_hot_seq_a_b(n + 1, n), 0))\n    return data\n\ndef generate_testset_regular(N_train, N_test):\n    # Test positives: a^n b^n, n in N_train+1..N_test\n    # Test negatives: a^n b^n a, n in N_train+1..N_test\n    data = []\n    for n in range(N_train + 1, N_test + 1):\n        data.append((one_hot_seq_a_b(n, n), 1))\n        data.append((one_hot_seq_a_b_a(n, n, 1), 0))\n    return data\n\ndef generate_testset_cf(N_train, N_test):\n    data = []\n    for n in range(N_train + 1, N_test + 1):\n        data.append((one_hot_seq_a_b(n, n), 1))\n        data.append((one_hot_seq_a_b(n, n + 1), 0))\n        data.append((one_hot_seq_a_b(n + 1, n), 0))\n    return data\n\nclass SimpleRNNBinary:\n    def __init__(self, input_dim, hidden_dim, seed=0):\n        rng = np.random.default_rng(seed)\n        self.H = hidden_dim\n        self.D = input_dim\n        # Parameter initialization (small random)\n        scale = 0.1\n        self.W_xh = rng.normal(0.0, scale, size=(self.H, self.D))\n        self.W_hh = rng.normal(0.0, scale, size=(self.H, self.H))\n        # Spectral stabilization for W_hh (optional small scaling)\n        # self.W_hh *= 0.9\n        self.b_h = np.zeros((self.H,), dtype=np.float64)\n        self.w_hy = rng.normal(0.0, scale, size=(self.H,))\n        self.b_y = 0.0\n\n        # Adam optimizer states\n        self.m = { 'W_xh': np.zeros_like(self.W_xh),\n                   'W_hh': np.zeros_like(self.W_hh),\n                   'b_h':  np.zeros_like(self.b_h),\n                   'w_hy': np.zeros_like(self.w_hy),\n                   'b_y':  0.0 }\n        self.v = { 'W_xh': np.zeros_like(self.W_xh),\n                   'W_hh': np.zeros_like(self.W_hh),\n                   'b_h':  np.zeros_like(self.b_h),\n                   'w_hy': np.zeros_like(self.w_hy),\n                   'b_y':  0.0 }\n        self.t = 0  # Adam time step\n\n    def forward(self, seq):\n        # seq: list of one-hot vectors (D,)\n        h_prev = np.zeros((self.H,), dtype=np.float64)\n        hs = []\n        for x_t in seq:\n            a_t = self.W_xh @ x_t + self.W_hh @ h_prev + self.b_h\n            h_t = np.tanh(a_t)\n            hs.append(h_t)\n            h_prev = h_t\n        h_T = hs[-1] if hs else np.zeros((self.H,), dtype=np.float64)\n        z = float(self.w_hy @ h_T + self.b_y)\n        y_hat = sigmoid(z)\n        cache = {'hs': hs, 'seq': seq, 'h0': np.zeros((self.H,), dtype=np.float64)}\n        return y_hat, cache\n\n    def bptt(self, y_hat, y_true, cache, grad_clip=5.0):\n        hs = cache['hs']\n        seq = cache['seq']\n        H = self.H\n\n        # Initialize grads\n        g_W_xh = np.zeros_like(self.W_xh)\n        g_W_hh = np.zeros_like(self.W_hh)\n        g_b_h  = np.zeros_like(self.b_h)\n        g_w_hy = np.zeros_like(self.w_hy)\n        g_b_y  = 0.0\n\n        # Output layer grads\n        dz = (y_hat - y_true)  # scalar\n        g_w_hy += dz * hs[-1]\n        g_b_y  += dz\n\n        # Backprop through time\n        dh_next = dz * self.w_hy  # gradient wrt h_T\n        for t in reversed(range(len(seq))):\n            h_t = hs[t]\n            # derivative of tanh\n            dtanh = (1.0 - h_t * h_t)\n            delta_t = dh_next * dtanh  # (H,)\n            x_t = seq[t]\n            h_prev = hs[t-1] if t  0 else np.zeros_like(h_t)\n\n            # Accumulate grads\n            g_W_xh += np.outer(delta_t, x_t)\n            g_W_hh += np.outer(delta_t, h_prev)\n            g_b_h  += delta_t\n\n            # Propagate to previous hidden\n            dh_prev = self.W_hh.T @ delta_t\n            dh_next = dh_prev\n\n        # Gradient clipping\n        def clip_inplace(arr, clip):\n            norm = np.linalg.norm(arr)\n            if norm  clip and norm  0.0:\n                arr *= (clip / norm)\n        clip_inplace(g_W_xh, grad_clip)\n        clip_inplace(g_W_hh, grad_clip)\n        clip_inplace(g_b_h,  grad_clip)\n        # Scalars/vectors clipping\n        if abs(g_b_y)  grad_clip:\n            g_b_y = np.sign(g_b_y) * grad_clip\n        # w_hy clip\n        w_norm = np.linalg.norm(g_w_hy)\n        if w_norm  grad_clip and w_norm  0.0:\n            g_w_hy *= (grad_clip / w_norm)\n\n        grads = {\n            'W_xh': g_W_xh,\n            'W_hh': g_W_hh,\n            'b_h':  g_b_h,\n            'w_hy': g_w_hy,\n            'b_y':  g_b_y\n        }\n        return grads\n\n    def adam_update(self, grads, lr, beta1=0.9, beta2=0.999, eps=1e-8):\n        self.t += 1\n        for name in grads:\n            g = grads[name]\n            self.m[name] = beta1 * self.m[name] + (1 - beta1) * g\n            self.v[name] = beta2 * self.v[name] + (1 - beta2) * (g * g)\n            m_hat = self.m[name] / (1 - beta1 ** self.t)\n            v_hat = self.v[name] / (1 - beta2 ** self.t)\n            update = lr * (m_hat / (np.sqrt(v_hat) + eps))\n            if name == 'W_xh':\n                self.W_xh -= update\n            elif name == 'W_hh':\n                self.W_hh -= update\n            elif name == 'b_h':\n                self.b_h  -= update\n            elif name == 'w_hy':\n                self.w_hy -= update\n            elif name == 'b_y':\n                self.b_y  -= float(update)\n\ndef train_model(model, dataset, epochs, lr, seed):\n    rng = np.random.default_rng(seed)\n    # Shuffle and train with Adam\n    for epoch in range(epochs):\n        # Shuffle dataset order\n        indices = np.arange(len(dataset))\n        rng.shuffle(indices)\n        for idx in indices:\n            seq, y = dataset[idx]\n            y_hat, cache = model.forward(seq)\n            grads = model.bptt(y_hat, y, cache)\n            model.adam_update(grads, lr=lr)\n\ndef evaluate_accuracy(model, dataset):\n    correct = 0\n    total = 0\n    for seq, y in dataset:\n        y_hat, _ = model.forward(seq)\n        pred = 1 if y_hat = 0.5 else 0\n        correct += int(pred == y)\n        total += 1\n    return correct / total if total  0 else 0.0\n\ndef run_test_case(language_type, seed, hidden_size, N_train, N_test, epochs, lr):\n    # language_type: 'regular' or 'context_free'\n    rng = np.random.default_rng(seed)\n    model = SimpleRNNBinary(input_dim=2, hidden_dim=hidden_size, seed=seed)\n\n    if language_type == 'regular':\n        train_data = generate_dataset_regular(N_train)\n        test_data  = generate_testset_regular(N_train, N_test)\n    elif language_type == 'context_free':\n        train_data = generate_dataset_cf(N_train)\n        test_data  = generate_testset_cf(N_train, N_test)\n    else:\n        raise ValueError(\"Unknown language type.\")\n\n    train_model(model, train_data, epochs=epochs, lr=lr, seed=seed)\n    acc = evaluate_accuracy(model, test_data)\n    return acc\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (language_type, seed, hidden_size, N_train, N_test, epochs, lr)\n    test_cases = [\n        ('regular',       1, 16, 5, 12, 300, 0.03),\n        ('context_free',  2, 16, 5, 12, 300, 0.03),\n        ('regular',       3,  2, 3,  8, 300, 0.03),\n    ]\n\n    results = []\n    for case in test_cases:\n        language_type, seed, hidden_size, N_train, N_test, epochs, lr = case\n        acc = run_test_case(language_type, seed, hidden_size, N_train, N_test, epochs, lr)\n        # Round to three decimals\n        results.append(f\"{acc:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "The previous exercise highlighted that some tasks require more memory than others. This practice provides a quantitative framework for understanding an RNN's memory limitations by training it to perform multi-digit binary addition, an algorithm whose difficulty is tied to the propagation of a \"carry\" bit . You will implement a model with an intentionally constrained memory and analyze its performance, connecting the theoretical concept of the spectral radius to the practical failure of the network on inputs requiring long-term dependencies.",
            "id": "3167589",
            "problem": "You are asked to design, analyze, and implement a complete program that constructs and trains a Recurrent Neural Network (RNN) to emulate a simple algorithmic task (binary addition) and to diagnose principled failure cases arising from limited memory. The task must be framed in purely mathematical terms and solved using first principles of statistical learning and recurrent neural networks. The final output of your program must aggregate results from a fixed test suite into a single line in a specified format.\n\nThe fundamental base of this problem is the definition of a standard Elman Recurrent Neural Network and the causal structure of binary addition. Consider a Recurrent Neural Network (RNN) with hyperbolic tangent activation where the hidden state update is defined by the recurrence\n$$\n\\mathbf{h}_t = \\tanh\\!\\Big(\\mathbf{W}_{hh} \\mathbf{h}_{t-1} + \\mathbf{W}_{xh} \\mathbf{x}_t + \\mathbf{b}_h\\Big),\n$$\nwith output logits\n$$\n\\mathbf{o}_t = \\mathbf{W}_{hy} \\mathbf{h}_t + \\mathbf{b}_y,\n$$\nand probabilistic outputs\n$$\n\\mathbf{y}_t = \\sigma(\\mathbf{o}_t),\n$$\nwhere $\\sigma(\\cdot)$ denotes the elementwise logistic sigmoid. The input at time $t$ is the pair of bits $\\mathbf{x}_t = (a_t, b_t)$ with $a_t \\in \\{0,1\\}$ and $b_t \\in \\{0,1\\}$, scanned from the least significant bit ($t = 0$) to the most significant bit ($t = T-1$). The network must output at each time step two bits: the sum bit $s_t$ and the carry-out bit $c_t$. The true targets $(s_t, c_t)$ are generated by the causal addition rule from first principles: initialize $c_{-1} = 0$ and for each time step $t$ compute\n$$\nu_t = a_t + b_t + c_{t-1}, \\quad s_t = u_t \\bmod 2, \\quad c_t = \\left\\lfloor \\frac{u_t}{2} \\right\\rfloor.\n$$\nAfter $T$ steps, the full sum is recovered as\n$$\nS = \\sum_{t=0}^{T-1} s_t 2^t + c_{T-1} \\cdot 2^T.\n$$\n\nYour program must do the following:\n\n- Implement and train the above RNN on randomly generated pairs of $T_{\\text{train}}$-bit integers to emulate the bitwise addition algorithm, with $T_{\\text{train}} = 8$. Use a binary cross-entropy loss summed over time and outputs. Use stochastic gradient descent with gradient clipping. Initialize $\\mathbf{h}_{-1} = \\mathbf{0}$. After every parameter update, enforce the spectral radius constraint\n$$\n\\rho\\big(\\mathbf{W}_{hh}\\big) \\le \\rho_{\\max},\n$$\nwith $\\rho_{\\max} = 0.7$, by rescaling $\\mathbf{W}_{hh}$ as needed. This constraint is mandatory and serves to induce a finite memory length.\n\n- From fundamental definitions, derive and implement a principled estimator for the effective memory length $L_{\\varepsilon}$ of the trained network, expressed as the smallest integer $L$ such that the influence of information $L$ steps in the past on the current hidden state is bounded by a tolerance $\\varepsilon$. Your derivation must begin with the RNN recurrence, express the hidden-to-hidden influence through Jacobian products, and use a norm or spectral-radius-based bound to obtain a computable estimator $L_{\\varepsilon}$ in terms of the learned parameters and average activation derivatives. In code, set $\\varepsilon = 0.05$.\n\n- Define the carry chain length for a specific input pair $(\\{a_t\\}, \\{b_t\\})$ as the maximum number of consecutive time steps during which the running carry bit equals $1$ when computed causally from least significant to most significant bit. That is, if $\\{c_t\\}$ is the carry sequence induced by the true addition rule above, the carry chain length is\n$$\n\\max_{i \\le j} \\Big\\{ (j-i+1) \\; \\text{such that} \\; c_i = c_{i+1} = \\cdots = c_j = 1 \\Big\\}.\n$$\n\n- Predict sufficiency versus failure for a given input pair by comparing the estimated memory length $L_{\\varepsilon}$ with the input’s carry chain length. If $L_{\\varepsilon}$ is greater than or equal to the carry chain length, predict “sufficient”; otherwise, predict “insufficient.” Then empirically evaluate the trained RNN on that input pair by computing the entire predicted sum from the per-time-step outputs and comparing it to the true integer sum.\n\n- Test Suite. Use a fixed sequence length of $T = 12$ bits for all test inputs and evaluate the trained network on the following five input pairs of nonnegative integers, each represented in $12$ bits (least significant bit first in the computational procedure):\n    - Case $1$ (happy path): $(A,B) = (25, 6)$.\n    - Case $2$ (boundary proximity): $(A,B) = (255, 1)$.\n    - Case $3$ (beyond boundary): $(A,B) = (1023, 1)$.\n    - Case $4$ (edge case with zero): $(A,B) = (0, 0)$.\n    - Case $5$ (extreme carry propagation): $(A,B) = (4095, 1)$.\n  These inputs are selected to exercise typical behavior, boundary conditions, and significant edge cases regarding carry propagation.\n\n- Final Output Format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case in order, output two booleans:\n    1. The first boolean indicates whether the estimated memory length $L_{\\varepsilon}$ is sufficient for the maximum carry chain length of that case.\n    2. The second boolean indicates whether the trained RNN produces the exact correct integer sum for that case.\n  The final line must therefore contain $10$ boolean values in total, in the form\n$$\n[\\text{p}_1,\\text{a}_1,\\text{p}_2,\\text{a}_2,\\text{p}_3,\\text{a}_3,\\text{p}_4,\\text{a}_4,\\text{p}_5,\\text{a}_5],\n$$\nwhere $\\text{p}_i$ is the predicted sufficiency and $\\text{a}_i$ is the actual correctness for case $i$.\n\nAll mathematical quantities and numbers in this specification must be interpreted in their standard mathematical sense and, where applicable, answers must be expressed as booleans and evaluated exactly as defined. No physical units or angle units are involved in this problem.",
            "solution": "The problem requires the design, implementation, and analysis of a Recurrent Neural Network (RNN) to perform binary addition. A critical aspect of the problem is to theoretically and empirically investigate the network's memory limitations, which are intentionally induced by a spectral radius constraint on the recurrent weight matrix. The solution proceeds in three main stages: first, defining the model and training procedure; second, deriving a principled estimator for the network's effective memory length; and third, implementing the full system to test the hypothesis that network failure on long-carry additions is predictable by comparing this memory length to the task's required carry propagation length.\n\n### 1. RNN Model and Binary Addition Task\n\nThe RNN architecture is a standard Elman network. The hidden state $\\mathbf{h}_t \\in \\mathbb{R}^{d_h}$ evolves according to the recurrence:\n$$\n\\mathbf{h}_t = \\tanh(\\mathbf{W}_{hh} \\mathbf{h}_{t-1} + \\mathbf{W}_{xh} \\mathbf{x}_t + \\mathbf{b}_h)\n$$\nwhere $\\mathbf{x}_t \\in \\{0,1\\}^2$ is the input vector representing two bits $(a_t, b_t)$, $\\mathbf{W}_{hh} \\in \\mathbb{R}^{d_h \\times d_h}$, $\\mathbf{W}_{xh} \\in \\mathbb{R}^{d_h \\times 2}$, and $\\mathbf{b}_h \\in \\mathbb{R}^{d_h}$ are parameters. The initial hidden state is $\\mathbf{h}_{-1} = \\mathbf{0}$.\n\nAt each time step $t$, the network produces output logits $\\mathbf{o}_t \\in \\mathbb{R}^2$ and probabilistic outputs $\\mathbf{y}_t \\in (0,1)^2$:\n$$\n\\mathbf{o}_t = \\mathbf{W}_{hy} \\mathbf{h}_t + \\mathbf{b}_y\n$$\n$$\n\\mathbf{y}_t = \\sigma(\\mathbf{o}_t)\n$$\nwhere $\\mathbf{W}_{hy} \\in \\mathbb{R}^{2 \\times d_h}$, $\\mathbf{b}_y \\in \\mathbb{R}^2$, and $\\sigma(\\cdot)$ is the element-wise logistic sigmoid function. The two components of $\\mathbf{y}_t$ are the network's probabilistic predictions for the sum bit $s_t$ and the carry-out bit $c_t$.\n\nThe ground truth for training is generated by the rules of binary addition. Given input bits $(a_t, b_t)$ and the carry-in $c_{t-1}$ (with $c_{-1}=0$), the true sum bit $s_t$ and carry-out bit $c_t$ are:\n$$\nu_t = a_t + b_t + c_{t-1}\n$$\n$$\ns_t = u_t \\pmod 2\n$$\n$$\nc_t = \\left\\lfloor \\frac{u_t}{2} \\right\\rfloor\n$$\n\n### 2. Training Procedure\n\nThe network is trained to minimize the total binary cross-entropy (BCE) loss between its predictions $\\mathbf{y}_t = (y_{t,s}, y_{t,c})$ and the true targets $(s_t, c_t)$ over a sequence of length $T$:\n$$\nL = -\\sum_{t=0}^{T-1} \\left[ s_t \\log(y_{t,s}) + (1-s_t) \\log(1-y_{t,s}) + c_t \\log(y_{t,c}) + (1-c_t) \\log(1-y_{t,c}) \\right]\n$$\nParameters are updated using Stochastic Gradient Descent (SGD) with gradients computed via Backpropagation Through Time (BPTT). To prevent exploding gradients, all gradients are clipped to a maximum norm. A key feature of the training is the enforcement of a spectral radius constraint on the recurrent weight matrix, $\\rho(\\mathbf{W}_{hh}) \\le \\rho_{\\max}$, where $\\rho(\\cdot)$ denotes the spectral radius (maximum absolute eigenvalue). This is achieved by rescaling $\\mathbf{W}_{hh}$ after each gradient update if the constraint is violated:\n$$\n\\text{if } \\rho(\\mathbf{W}_{hh})  \\rho_{\\max}, \\quad \\mathbf{W}_{hh} \\leftarrow \\mathbf{W}_{hh} \\frac{\\rho_{\\max}}{\\rho(\\mathbf{W}_{hh})}\n$$\nThis constraint limits the long-term memory capacity of the RNN, as it forces the linear part of the recurrent dynamics to be contractive. For this problem, we use $\\rho_{\\max} = 0.7$ and train on $T_{\\text{train}}=8$ bit numbers. Hyperparameters such as hidden dimension, learning rate, and training epochs must be chosen appropriately; we select $d_h=4$, a learning rate of $\\eta=0.05$, and $3000$ training epochs.\n\n### 3. Derivation of Effective Memory Length $L_{\\varepsilon}$\n\nThe effective memory length, $L_{\\varepsilon}$, is the number of time steps over which information can propagate before its influence decays below a threshold $\\varepsilon$. We can formalize this by analyzing the Jacobian of the hidden state at time $t$ with respect to the hidden state at a past time $t-L$, $\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-L}}$.\n\nUsing the chain rule on the recurrence relation:\n$$\n\\frac{\\partial \\mathbf{h}_k}{\\partial \\mathbf{h}_{k-1}} = \\frac{\\partial \\tanh(\\mathbf{z}_k)}{\\partial \\mathbf{z}_k} \\frac{\\partial \\mathbf{z}_k}{\\partial \\mathbf{h}_{k-1}} = \\text{diag}(1-\\tanh^2(\\mathbf{z}_k)) \\cdot \\mathbf{W}_{hh} = \\mathbf{D}_k \\mathbf{W}_{hh}\n$$\nwhere $\\mathbf{z}_k = \\mathbf{W}_{hh} \\mathbf{h}_{k-1} + \\dots$ is the pre-activation at time $k$, and $\\mathbf{D}_k$ is a diagonal matrix of activation derivatives. The full Jacobian is a product of these terms:\n$$\n\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-L}} = \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-1}} \\frac{\\partial \\mathbf{h}_{t-1}}{\\partial \\mathbf{h}_{t-2}} \\cdots \\frac{\\partial \\mathbf{h}_{t-L+1}}{\\partial \\mathbf{h}_{t-L}} = \\prod_{k=t-L+1}^{t} (\\mathbf{D}_k \\mathbf{W}_{hh})\n$$\nThe norm of this Jacobian bounds the magnitude of the influence. To obtain a tractable estimator, we make two approximations. First, we replace the time-varying matrix $\\mathbf{D}_k$ with a scalar-matrix approximation $\\bar{d} \\mathbf{I}$, where $\\bar{d}$ is the average value of the derivative $1-\\tanh^2(z)$ across all hidden units and time steps, estimated from a sample of training data. Second, we use the property that for large $L$, the norm of a matrix power $\\|(\\bar{d}\\mathbf{W}_{hh})^L\\|$ is dominated by its spectral radius, $\\rho(\\bar{d}\\mathbf{W}_{hh})^L$.\nThe influence decay factor over $L$ steps is thus approximated by $(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))^L$. We seek the smallest integer $L$ for which this value is less than or equal to $\\varepsilon$:\n$$\n(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))^L \\le \\varepsilon\n$$\nSolving for $L$ by taking the logarithm of both sides yields:\n$$\nL \\log(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh})) \\le \\log(\\varepsilon)\n$$\nSince $\\rho(\\mathbf{W}_{hh}) \\le \\rho_{\\max} = 0.7  1$ and $\\bar{d} \\le 1$, the term $\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh})$ is less than $1$, making its logarithm negative. Dividing by this negative number reverses the inequality:\n$$\nL \\ge \\frac{\\log(\\varepsilon)}{\\log(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))}\n$$\nThe an estimator for the effective memory length $L_\\varepsilon$ is the smallest integer satisfying this:\n$$\nL_{\\varepsilon} = \\left\\lceil \\frac{\\log(\\varepsilon)}{\\log(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))} \\right\\rceil\n$$\nFor the implementation, we use $\\varepsilon = 0.05$. A larger $L_\\varepsilon$ implies the network can maintain information for longer durations.\n\n### 4. Failure Prediction and Evaluation\n\nThe binary addition task's memory requirement is determined by its longest carry chain. The \"carry chain length\" for an input pair is the maximum number of consecutive time steps for which the true carry-out bit $c_t$ is $1$. For the network to correctly perform the addition, its effective memory length $L_{\\varepsilon}$ must be at least as long as the required carry chain length, $L_{\\text{carry}}$. This gives us a prediction rule:\n- Predict \"sufficient\" if $L_{\\varepsilon} \\ge L_{\\text{carry}}$.\n- Predict \"insufficient\" if $L_{\\varepsilon}  L_{\\text{carry}}$.\n\nThis prediction is then compared against the actual performance of the trained RNN on the test cases. The empirical correctness is determined by feeding the $T=12$ bit representations of the test integers into the network, binarizing its outputs $(y_{t,s}, y_{t,c})$ to get predicted bits $(s'_t, c'_t)$, calculating the predicted integer sum $S_{\\text{pred}}$, and comparing it to the true sum $S_{\\text{true}}$.\n$$\nS_{\\text{pred}} = \\sum_{t=0}^{T-1} s'_t 2^t + c'_{T-1} 2^T\n$$\nThe network's performance is deemed correct if and only if $S_{\\text{pred}} = S_{\\text{true}}$. The final output aggregates these comparisons for the given test suite.",
            "answer": "```python\nimport numpy as np\nimport scipy.linalg\nimport math\n\n# Use a fixed random seed for reproducibility of training.\nnp.random.seed(42)\n\ndef solve():\n    \"\"\"\n    Main function to construct, train, and evaluate the RNN for binary addition.\n    \"\"\"\n\n    # --- Configuration ---\n    # RNN architecture\n    INPUT_DIM = 2\n    HIDDEN_DIM = 4  # A small hidden size is sufficient for this task.\n    OUTPUT_DIM = 2\n\n    # Training parameters\n    LEARNING_RATE = 0.05\n    N_EPOCHS = 3000\n    GRAD_CLIP_THRESHOLD = 1.0\n    T_TRAIN = 8  # Train on 8-bit numbers.\n\n    # Memory analysis parameters\n    RHO_MAX = 0.7\n    EPSILON = 0.05\n\n    # Testing parameters\n    T_TEST = 12 # Test on 12-bit numbers.\n\n    # --- Helper Functions ---\n    def int_to_binary_array(n, num_bits):\n        binary_str = format(n, f'0{num_bits}b')\n        return np.array([int(bit) for bit in reversed(binary_str)], dtype=np.float64)\n\n    def get_true_targets(a_bits, b_bits):\n        seq_len = len(a_bits)\n        s_bits = np.zeros(seq_len, dtype=np.float64)\n        c_bits = np.zeros(seq_len, dtype=np.float64)\n        carry_in = 0\n        for t in range(seq_len):\n            u_t = a_bits[t] + b_bits[t] + carry_in\n            s_bits[t] = u_t % 2\n            c_bits[t] = u_t // 2\n            carry_in = c_bits[t]\n        return s_bits, c_bits\n\n    class RNN:\n        \"\"\"A simple Elman Recurrent Neural Network.\"\"\"\n        def __init__(self, input_dim, hidden_dim, output_dim):\n            # Xavier/Glorot initialization for weights\n            limit_xh = np.sqrt(6.0 / (input_dim + hidden_dim))\n            limit_hh = np.sqrt(6.0 / (hidden_dim + hidden_dim))\n            limit_hy = np.sqrt(6.0 / (hidden_dim + output_dim))\n            \n            self.W_xh = np.random.uniform(-limit_xh, limit_xh, (hidden_dim, input_dim))\n            self.W_hh = np.random.uniform(-limit_hh, limit_hh, (hidden_dim, hidden_dim))\n            self.W_hy = np.random.uniform(-limit_hy, limit_hy, (output_dim, hidden_dim))\n            \n            self.b_h = np.zeros((hidden_dim, 1))\n            self.b_y = np.zeros((output_dim, 1))\n\n        def _sigmoid(self, x):\n            return 1.0 / (1.0 + np.exp(-x))\n\n        def forward(self, x_seq):\n            seq_len = x_seq.shape[0]\n            h = np.zeros((self.W_hh.shape[0], 1))\n            \n            history = {\n                'h': { -1: h }, # Store h_t values, key is time index\n                'y': [],\n                'deriv_activations': []\n            }\n            \n            for t in range(seq_len):\n                x_t = x_seq[t].reshape(-1, 1)\n                h_pre_act = self.W_xh @ x_t + self.W_hh @ h + self.b_h\n                h = np.tanh(h_pre_act)\n                o_t = self.W_hy @ h + self.b_y\n                y_t = self._sigmoid(o_t)\n                \n                history['h'][t] = h\n                history['y'].append(y_t)\n                history['deriv_activations'].append(1 - h**2)\n                \n            return history\n\n        def rescale_W_hh(self, rho_max):\n            eigenvalues = scipy.linalg.eigvals(self.W_hh)\n            rho = np.max(np.abs(eigenvalues))\n            if rho  rho_max:\n                self.W_hh *= rho_max / rho\n\n    def train_rnn(model, num_epochs, seq_len, learning_rate, clip_threshold, rho_max):\n        \"\"\"Train the RNN model using SGD and BPTT.\"\"\"\n        for epoch in range(num_epochs):\n            # Generate a random training sample\n            a_int = np.random.randint(0, 2**seq_len)\n            b_int = np.random.randint(0, 2**seq_len)\n            a_bits = int_to_binary_array(a_int, seq_len)\n            b_bits = int_to_binary_array(b_int, seq_len)\n            x_seq = np.vstack((a_bits, b_bits)).T\n            s_true, c_true = get_true_targets(a_bits, b_bits)\n            y_true_seq = np.vstack((s_true, c_true)).T\n\n            # Forward pass\n            history = model.forward(x_seq)\n            \n            # --- Backward Pass (BPTT) ---\n            dW_xh, dW_hh, dW_hy = np.zeros_like(model.W_xh), np.zeros_like(model.W_hh), np.zeros_like(model.W_hy)\n            db_h, db_y = np.zeros_like(model.b_h), np.zeros_like(model.b_y)\n            \n            delta_h_future = np.zeros_like(model.b_h)\n            \n            for t in reversed(range(seq_len)):\n                y_pred_t = history['y'][t]\n                y_true_t = y_true_seq[t].reshape(-1, 1)\n                h_t = history['h'][t]\n                h_prev = history['h'][t - 1]\n                x_t = x_seq[t].reshape(-1, 1)\n                deriv_act_t = history['deriv_activations'][t]\n\n                delta_o_t = y_pred_t - y_true_t\n                dW_hy += delta_o_t @ h_t.T\n                db_y += delta_o_t\n                \n                delta_h_from_output = model.W_hy.T @ delta_o_t\n                delta_h_total = delta_h_from_output + delta_h_future\n                \n                delta_pre_act_h = delta_h_total * deriv_act_t\n                \n                dW_hh += delta_pre_act_h @ h_prev.T\n                dW_xh += delta_pre_act_h @ x_t.T\n                db_h += delta_pre_act_h\n                \n                delta_h_future = model.W_hh.T @ delta_pre_act_h\n            \n            # Gradient clipping\n            grads = [dW_xh, dW_hh, dW_hy, db_h, db_y]\n            total_norm = np.sqrt(sum(np.sum(g**2) for g in grads))\n            if total_norm  clip_threshold:\n                for g in grads:\n                    g *= clip_threshold / total_norm\n\n            # SGD update\n            model.W_xh -= learning_rate * dW_xh\n            model.W_hh -= learning_rate * dW_hh\n            model.W_hy -= learning_rate * dW_hy\n            model.b_h -= learning_rate * db_h\n            model.b_y -= learning_rate * db_y\n            \n            # Enforce spectral radius constraint\n            model.rescale_W_hh(rho_max)\n        \n        return model\n\n    def calculate_memory_length(model, rho_max, epsilon):\n        # Estimate average activation derivative\n        num_samples = 100\n        all_deriv_activations = []\n        for _ in range(num_samples):\n            a_int = np.random.randint(0, 2**T_TRAIN)\n            b_int = np.random.randint(0, 2**T_TRAIN)\n            a_bits = int_to_binary_array(a_int, T_TRAIN)\n            b_bits = int_to_binary_array(b_int, T_TRAIN)\n            x_seq = np.vstack((a_bits, b_bits)).T\n            history = model.forward(x_seq)\n            all_deriv_activations.extend([d.flatten() for d in history['deriv_activations']])\n        \n        d_avg_scalar = np.mean(np.concatenate(all_deriv_activations))\n        \n        rho_W_hh = np.max(np.abs(scipy.linalg.eigvals(model.W_hh)))\n        \n        # Calculate L_epsilon\n        log_numerator = np.log(epsilon)\n        decay_factor = d_avg_scalar * rho_W_hh\n        \n        if decay_factor = 1.0:\n            return float('inf')\n        if decay_factor = 0:\n            return 1\n            \n        log_denominator = np.log(decay_factor)\n        L_eps = math.ceil(log_numerator / log_denominator)\n        return L_eps\n\n    def calculate_carry_chain_length(A, B, num_bits):\n        a_bits = int_to_binary_array(A, num_bits)\n        b_bits = int_to_binary_array(B, num_bits)\n        _, c_bits = get_true_targets(a_bits, b_bits)\n        \n        max_len = 0\n        current_len = 0\n        for bit in c_bits:\n            if bit == 1:\n                current_len += 1\n            else:\n                max_len = max(max_len, current_len)\n                current_len = 0\n        max_len = max(max_len, current_len)\n        return max_len\n\n    # --- Main Execution ---\n    rnn = RNN(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n    \n    # Train the RNN\n    trained_rnn = train_rnn(rnn, N_EPOCHS, T_TRAIN, LEARNING_RATE, GRAD_CLIP_THRESHOLD, RHO_MAX)\n    \n    # Analyze the trained network's memory\n    L_epsilon = calculate_memory_length(trained_rnn, RHO_MAX, EPSILON)\n    \n    # Test Suite\n    test_cases = [\n        (25, 6),\n        (255, 1),\n        (1023, 1),\n        (0, 0),\n        (4095, 1),\n    ]\n\n    results = []\n    for A, B in test_cases:\n        # 1. Predict sufficiency based on memory length\n        L_carry = calculate_carry_chain_length(A, B, T_TEST)\n        p_sufficient = (L_epsilon = L_carry)\n        \n        # 2. Evaluate actual performance\n        a_bits = int_to_binary_array(A, T_TEST)\n        b_bits = int_to_binary_array(B, T_TEST)\n        x_seq = np.vstack((a_bits, b_bits)).T\n        \n        history = trained_rnn.forward(x_seq)\n        \n        s_pred_bits = np.round([y[0,0] for y in history['y']])\n        c_pred_bits = np.round([y[1,0] for y in history['y']])\n        \n        S_pred = 0\n        for t in range(T_TEST):\n            S_pred += s_pred_bits[t] * (2**t)\n        # Add final carry-out\n        S_pred += c_pred_bits[T_TEST - 1] * (2**T_TEST)\n        \n        S_true = A + B\n        a_correct = (S_pred == S_true)\n        \n        results.extend([p_sufficient, a_correct])\n        \n    # Format and print the final output\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}