{
    "hands_on_practices": [
        {
            "introduction": "我们的公平性实践之旅始于审计。在修复一个模型之前，我们必须首先学会诊断其偏见。这个练习将介绍“人口统计均等”（Demographic Parity），这是一个基本的公平性标准，要求模型的预测独立于敏感属性。你将处理来自两个不同群体的原始模型分数，并学习如何执行非参数检验来检查是否违反了这一原则 ()。通过构建经验生存函数并计算柯尔莫哥洛夫-斯米尔诺夫（Kolmogorov-Smirnov）统计量，你将获得一个量化公平性差异的实用工具。",
            "id": "3120841",
            "problem": "考虑一个二元敏感属性 $A \\in \\{0,1\\}$ 以及一个由分类器为每个个体输出的黑盒分数 $\\hat{p} \\in [0,1]$。在人口统计均等性（demographic parity）下，二元决策 $\\hat{Y}$ 与 $A$ 无关。假设决策是通过在水平 $t \\in [0,1]$ 处对 $\\hat{p}$ 进行阈值处理来生成的，即 $\\hat{Y}_{t} = \\mathbf{1}\\{\\hat{p} \\ge t\\}$。通过使用生存函数 $S_{a}(t) = P(\\hat{p} \\ge t \\mid A=a)$ 和组间的上确界型差异，检验 $\\hat{p}$ 的分布在两个组中是否相同，从而非参数地审计人口统计均等性。请从第一性原理出发，基于人口统计均等性的独立性定义和经验分布函数的性质，推导出此检验，且不假设分数分布的任何参数形式。\n\n给定两个独立的分数样本：\n- 组 $A=0$ 有 $n_{0}=6$ 个分数：$0.02$, $0.10$, $0.22$, $0.40$, $0.65$, $0.90$。\n- 组 $A=1$ 有 $n_{1}=8$ 个分数：$0.05$, $0.08$, $0.25$, $0.30$, $0.45$, $0.60$, $0.85$, $0.95$。\n\n为这些样本构建经验生存函数 $\\hat{S}_{0}(t)$ 和 $\\hat{S}_{1}(t)$，并计算由此产生的柯尔莫哥洛夫-斯米尔诺夫（Kolmogorov–Smirnov, KS）统计量，该统计量定义为两个经验生存函数在 $t \\in [0,1]$ 上的绝对差的上确界。报告此 KS 统计量的值。最终答案需为精确值（不要四舍五入）。",
            "solution": "人口统计均等性要求决策 $\\hat{Y}$ 与敏感属性 $A$ 无关。如果决策是通过在阈值 $t \\in [0,1]$ 处对分数进行阈值处理生成的，那么 $\\hat{Y}_{t} = \\mathbf{1}\\{\\hat{p} \\ge t\\}$，且在阈值 $t$ 处的人口统计均等性意味着\n$$\nP(\\hat{Y}_{t}=1 \\mid A=0) \\;=\\; P(\\hat{Y}_{t}=1 \\mid A=1).\n$$\n根据 $\\hat{Y}_{t}$ 的定义，该条件等价于\n$$\nP(\\hat{p} \\ge t \\mid A=0) \\;=\\; P(\\hat{p} \\ge t \\mid A=1),\n$$\n也就是生存函数 $S_{0}(t)$ 和 $S_{1}(t)$ 在阈值 $t$ 处相等。如果阈值不是先验指定的，那么审计所有可能阈值下的人口统计均等性就相当于检验\n$$\nS_{0}(t) \\;=\\; S_{1}(t) \\quad \\text{for all } t \\in [0,1].\n$$\n这等价于检验给定 $A=0$ 和 $A=1$ 时 $\\hat{p}$ 的条件分布是否相等，因为 $S_{a}(t) = 1 - F_{a}(t-)$，其中 $F_{a}$ 是给定 $A=a$ 时 $\\hat{p}$ 的累积分布函数。一个旨在寻找分布之间最大差异的非参数检验是柯尔莫哥洛夫-斯米尔诺夫（Kolmogorov–Smirnov, KS）检验，它比较经验分布函数之间绝对差的上确界。由于 $S_{a}(t)$ 和 $F_{a}(t)$ 仅相差一个补集，因此在 $t$ 上 $|\\hat{S}_{0}(t) - \\hat{S}_{1}(t)|$ 的上确界与基于累积分布函数计算的 KS 统计量产生相同的差异值。\n\n为了从数据中非参数地估计 $S_{a}(t)$，我们使用经验生存函数\n$$\n\\hat{S}_{a}(t) \\;=\\; \\frac{1}{n_{a}} \\sum_{i: A_{i}=a} \\mathbf{1}\\{\\hat{p}_{i} \\ge t\\}.\n$$\n那么基于生存函数的 KS 统计量为\n$$\nD \\;=\\; \\sup_{t \\in [0,1]} \\left| \\hat{S}_{0}(t) - \\hat{S}_{1}(t) \\right|.\n$$\n\n现在我们为给定样本计算在不同 $t$ 值下的 $\\hat{S}_{0}(t)$ 和 $\\hat{S}_{1}(t)$。因为经验生存函数是仅在观测到的分数处发生变化的右连续阶梯函数，所以我们只需在从观测值的并集中取出的阈值 $t$ 处进行评估。设 $n_{0} = 6$ 且 $n_{1} = 8$。排序后的分数为：\n- 对于 $A=0$：$0.02$, $0.10$, $0.22$, $0.40$, $0.65$, $0.90$。\n- 对于 $A=1$：$0.05$, $0.08$, $0.25$, $0.30$, $0.45$, $0.60$, $0.85$, $0.95$。\n\n我们在唯一的阈值 $t \\in \\{0.02, 0.05, 0.08, 0.10, 0.22, 0.25, 0.30, 0.40, 0.45, 0.60, 0.65, 0.85, 0.90, 0.95\\}$ 处评估 $\\hat{S}_{0}(t)$ 和 $\\hat{S}_{1}(t)$（并注意它们在阈值之间的行为）：\n\n- 在 $t=0.02$ 处：$\\hat{S}_{0}(0.02) = \\frac{6}{6} = 1$，$\\hat{S}_{1}(0.02) = \\frac{8}{8} = 1$，差值为 $0$。\n- 在 $t=0.05$ 处：$\\hat{S}_{0}(0.05) = \\frac{5}{6}$，$\\hat{S}_{1}(0.05) = \\frac{8}{8} = 1$，差值为 $\\left| \\frac{5}{6} - 1 \\right| = \\frac{1}{6}$。\n- 在 $t=0.08$ 处：$\\hat{S}_{0}(0.08) = \\frac{5}{6}$，$\\hat{S}_{1}(0.08) = \\frac{7}{8}$，差值为 $\\left| \\frac{5}{6} - \\frac{7}{8} \\right| = \\frac{1}{24}$。\n- 在 $t=0.10$ 处：$\\hat{S}_{0}(0.10) = \\frac{5}{6}$，$\\hat{S}_{1}(0.10) = \\frac{6}{8} = \\frac{3}{4}$，差值为 $\\left| \\frac{5}{6} - \\frac{3}{4} \\right| = \\frac{1}{12}$。\n- 在 $t=0.22$ 处：$\\hat{S}_{0}(0.22) = \\frac{4}{6} = \\frac{2}{3}$，$\\hat{S}_{1}(0.22) = \\frac{6}{8} = \\frac{3}{4}$，差值为 $\\left| \\frac{2}{3} - \\frac{3}{4} \\right| = \\frac{1}{12}$。\n- 在 $t=0.25$ 处：$\\hat{S}_{0}(0.25) = \\frac{3}{6} = \\frac{1}{2}$，$\\hat{S}_{1}(0.25) = \\frac{6}{8} = \\frac{3}{4}$，差值为 $\\left| \\frac{1}{2} - \\frac{3}{4} \\right| = \\frac{1}{4}$。\n- 在 $t=0.30$ 处：$\\hat{S}_{0}(0.30) = \\frac{3}{6} = \\frac{1}{2}$，$\\hat{S}_{1}(0.30) = \\frac{5}{8}$，差值为 $\\left| \\frac{1}{2} - \\frac{5}{8} \\right| = \\frac{1}{8}$。\n- 在 $t=0.40$ 处：$\\hat{S}_{0}(0.40) = \\frac{3}{6} = \\frac{1}{2}$，$\\hat{S}_{1}(0.40) = \\frac{4}{8} = \\frac{1}{2}$，差值为 $0$。\n- 在 $t=0.45$ 处：$\\hat{S}_{0}(0.45) = \\frac{2}{6} = \\frac{1}{3}$，$\\hat{S}_{1}(0.45) = \\frac{4}{8} = \\frac{1}{2}$，差值为 $\\left| \\frac{1}{3} - \\frac{1}{2} \\right| = \\frac{1}{6}$。\n- 在 $t=0.60$ 处：$\\hat{S}_{0}(0.60) = \\frac{2}{6} = \\frac{1}{3}$，$\\hat{S}_{1}(0.60) = \\frac{3}{8}$，差值为 $\\left| \\frac{1}{3} - \\frac{3}{8} \\right| = \\frac{1}{24}$。\n- 在 $t=0.65$ 处：$\\hat{S}_{0}(0.65) = \\frac{2}{6} = \\frac{1}{3}$，$\\hat{S}_{1}(0.65) = \\frac{2}{8} = \\frac{1}{4}$，差值为 $\\left| \\frac{1}{3} - \\frac{1}{4} \\right| = \\frac{1}{12}$。\n- 在 $t=0.85$ 处：$\\hat{S}_{0}(0.85) = \\frac{1}{6}$，$\\hat{S}_{1}(0.85) = \\frac{2}{8} = \\frac{1}{4}$，差值为 $\\left| \\frac{1}{6} - \\frac{1}{4} \\right| = \\frac{1}{12}$。\n- 在 $t=0.90$ 处：$\\hat{S}_{0}(0.90) = \\frac{1}{6}$，$\\hat{S}_{1}(0.90) = \\frac{1}{8}$，差值为 $\\left| \\frac{1}{6} - \\frac{1}{8} \\right| = \\frac{1}{24}$。\n- 在 $t=0.95$ 处：$\\hat{S}_{0}(0.95) = 0$，$\\hat{S}_{1}(0.95) = \\frac{1}{8}$，差值为 $\\left| 0 - \\frac{1}{8} \\right| = \\frac{1}{8}$。\n\n在这些阈值之间，经验生存函数在区间内是恒定的，因此绝对差值等于每个区间内端点处的值。观测到的最大绝对差值为 $\\frac{1}{4}$，它在区间 $[0.25, 0.30)$ 内（包括 $t=0.25$）出现。\n\n因此，基于经验生存函数的柯尔莫哥洛夫-斯米尔诺夫统计量为\n$$\nD \\;=\\; \\frac{1}{4}.\n$$",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        },
        {
            "introduction": "虽然人口统计均等是一个很好的起点，但许多应用需要更细致的公平性定义，例如“均等化赔率”（Equalized Odds），它要求不同群体间的真正例率（TPR）和假正例率（FPR）相等。然而，实现这一点通常不像选择一个单一阈值那么简单。在这个练习 () 中，你将发现一个确定性分类器无法满足均等化赔率的场景。然后，你将学习一种强大的后处理技术：创建一个“混合”或随机化分类器，通过组合不同阈值的输出来成功满足公平性约束。",
            "id": "3120831",
            "problem": "考虑一个二元分类场景，其中包含一个受保护属性 $A \\in \\{a,b\\}$、一个二元标签 $Y \\in \\{0,1\\}$ 以及一个离散风险评分 $S \\in \\{3,2,1,0\\}$。对于每个组 $A$，您将构建受试者工作特征 (ROC) 点，并评估均等机会 (Equalized Odds, EO) 的可行性。在阈值 $\\tau$ 下的受试者工作特征 (ROC) 点由点对 $(\\text{FPR}, \\text{TPR})$ 定义，其中假阳性率 (FPR) 是在 $Y=0$ 条件下 $\\hat{Y}_{\\tau} = 1$ 的概率，真阳性率 (TPR) 是在 $Y=1$ 条件下 $\\hat{Y}_{\\tau} = 1$ 的概率。当且仅当 $S \\ge \\tau$ 时，阈值为 $\\tau$ 的分类器预测 $\\hat{Y}_{\\tau} = 1$。均等机会 (EO) 要求分类器在 $A=a$ 和 $A=b$ 两组中产生相同的 $\\text{FPR}$ 和 $\\text{TPR}$。在本问题中，您还必须遵守操作约束 $\\text{TPR} \\ge 0.6$ 和 $\\text{FPR} \\le 0.5$。\n\n给定一个由各组计数定义的合成数据集。对于 $A=a$，有 10 个正例和 10 个负例，其评分分配如下：\n- 对于 $Y=1$ (正例)：5 个的评分为 $S=3$，3 个为 $S=2$，1 个为 $S=1$，1 个为 $S=0$。\n- 对于 $Y=0$ (负例)：2 个的评分为 $S=3$，2 个为 $S=2$，3 个为 $S=1$，3 个为 $S=0$。\n\n对于 $A=b$，有 10 个正例和 10 个负例，其评分分配如下：\n- 对于 $Y=1$ (正例)：6 个的评分为 $S=3$，3 个为 $S=2$，1 个为 $S=1$，0 个为 $S=0$。\n- 对于 $Y=0$ (负例)：2 个的评分为 $S=3$，3 个为 $S=2$，2 个为 $S=1$，3 个为 $S=0$。\n\n任务：\n1. 使用 $\\text{TPR}$ 和 $\\text{FPR}$ 的定义，分别为 $A=a$ 和 $A=b$ 计算在阈值 $\\tau=3$ 和 $\\tau=2$ 下的 ROC 点 $(\\text{FPR}, \\text{TPR})$。\n2. 证明在约束条件 $\\text{TPR} \\ge 0.6$ 和 $\\text{FPR} \\le 0.5$ 下，不使用随机化时，均等机会是不可行的。您需要说明，对于每个组，没有任何单一阈值选择能够在 $A=a$ 和 $A=b$ 之间产生相同的 $(\\text{FPR}, \\text{TPR})$。\n3. 现在考虑一个用于 $A=b$ 的混合分类器，它在阈值 $\\tau=3$ 和 $\\tau=2$ 之间进行随机化：以概率 $\\lambda$ 使用 $\\tau=2$，以概率 $1-\\lambda$ 使用 $\\tau=3$。假设 $A=a$ 使用确定性阈值 $\\tau=2$。使用基本原理，将用于 $A=b$ 的混合分类器的 $\\text{TPR}$ 和 $\\text{FPR}$ 表示为 $\\lambda$ 的函数，建立与为 $A=a$ 选定点相等的 EO 等式，并求解在满足约束条件的同时实现 EO 的 $\\lambda \\in [0,1]$。将混合概率 $\\lambda$ 报告为单个精确值，无需四舍五入。",
            "solution": "该问题要求对基于离散风险评分 $S$ 的二元分类器的公平性指标，特别是均等机会 (Equalized Odds, EO)，进行三部分分析。该分析涉及 $A=a$ 和 $A=b$ 两个组。最终任务是为一个随机化分类器找到一个混合概率 $\\lambda$，使其在满足给定性能约束的同时实现 EO。\n\n首先，我们确定必要的定义和数据。如果评分 $S \\ge \\tau$，分类器预测 $\\hat{Y}_{\\tau} = 1$，否则预测 $\\hat{Y}_{\\tau} = 0$。\n真阳性率 (TPR) 是 $P(\\hat{Y}_{\\tau}=1|Y=1)$。\n假阳性率 (FPR) 是 $P(\\hat{Y}_{\\tau}=1|Y=0)$。\n使用每个组、标签和评分的个体数量来估计这些概率。\n\n对于组 $A=a$，正例 ($Y=1$) 的总数为 $N_{+,a}=10$，负例 ($Y=0$) 的总数为 $N_{-,a}=10$。评分分布如下：\n- 对于 $Y=1$：5 个的评分为 $S=3$，3 个为 $S=2$，1 个为 $S=1$，1 个为 $S=0$。\n- 对于 $Y=0$：2 个的评分为 $S=3$，2 个为 $S=2$，3 个为 $S=1$，3 个为 $S=0$。\n\n对于组 $A=b$，正例 ($Y=1$) 的总数为 $N_{+,b}=10$，负例 ($Y=0$) 的总数为 $N_{-,b}=10$。评分分布如下：\n- 对于 $Y=1$：6 个的评分为 $S=3$，3 个为 $S=2$，1 个为 $S=1$，0 个为 $S=0$。\n- 对于 $Y=0$：2 个的评分为 $S=3$，3 个为 $S=2$，2 个为 $S=1$，3 个为 $S=0$。\n\n**任务 1：计算 $\\tau=3$ 和 $\\tau=2$ 的 ROC 点**\n\n对于每个组和阈值，我们计算真阳性 (TP) 和假阳性 (FP) 的数量。\n- 真阳性是指 $Y=1$ 且 $S \\ge \\tau$ 的个体。\n- 假阳性是指 $Y=0$ 且 $S \\ge \\tau$ 的个体。\n\n对于组 $A=a$：\n- 在阈值 $\\tau=3$ 时：\n  - $\\text{TP}_a(\\tau=3) = (\\text{计数 } Y=1, S=3) = 5$。\n  - $\\text{TPR}_a(\\tau=3) = \\frac{\\text{TP}_a(\\tau=3)}{N_{+,a}} = \\frac{5}{10} = 0.5$。\n  - $\\text{FP}_a(\\tau=3) = (\\text{计数 } Y=0, S=3) = 2$。\n  - $\\text{FPR}_a(\\tau=3) = \\frac{\\text{FP}_a(\\tau=3)}{N_{-,a}} = \\frac{2}{10} = 0.2$。\n  - ROC 点为 $(\\text{FPR}_a, \\text{TPR}_a) = (0.2, 0.5)$。\n- 在阈值 $\\tau=2$ 时：\n  - $\\text{TP}_a(\\tau=2) = (\\text{计数 } Y=1, S \\ge 2) = 5 + 3 = 8$。\n  - $\\text{TPR}_a(\\tau=2) = \\frac{8}{10} = 0.8$。\n  - $\\text{FP}_a(\\tau=2) = (\\text{计数 } Y=0, S \\ge 2) = 2 + 2 = 4$。\n  - $\\text{FPR}_a(\\tau=2) = \\frac{4}{10} = 0.4$。\n  - ROC 点为 $(\\text{FPR}_a, \\text{TPR}_a) = (0.4, 0.8)$。\n\n对于组 $A=b$：\n- 在阈值 $\\tau=3$ 时：\n  - $\\text{TP}_b(\\tau=3) = (\\text{计数 } Y=1, S=3) = 6$。\n  - $\\text{TPR}_b(\\tau=3) = \\frac{\\text{TP}_b(\\tau=3)}{N_{+,b}} = \\frac{6}{10} = 0.6$。\n  - $\\text{FP}_b(\\tau=3) = (\\text{计数 } Y=0, S=3) = 2$。\n  - $\\text{FPR}_b(\\tau=3) = \\frac{\\text{FP}_b(\\tau=3)}{N_{-,b}} = \\frac{2}{10} = 0.2$。\n  - ROC 点为 $(\\text{FPR}_b, \\text{TPR}_b) = (0.2, 0.6)$。\n- 在阈值 $\\tau=2$ 时：\n  - $\\text{TP}_b(\\tau=2) = (\\text{计数 } Y=1, S \\ge 2) = 6 + 3 = 9$。\n  - $\\text{TPR}_b(\\tau=2) = \\frac{9}{10} = 0.9$。\n  - $\\text{FP}_b(\\tau=2) = (\\text{计数 } Y=0, S \\ge 2) = 2 + 3 = 5$。\n  - $\\text{FPR}_b(\\tau=2) = \\frac{5}{10} = 0.5$。\n  - ROC 点为 $(\\text{FPR}_b, \\text{TPR}_b) = (0.5, 0.9)$。\n\n**任务 2：证明不使用随机化时均等机会的不可行性**\n\n均等机会 (EO) 要求分类器为 $A=a$ 和 $A=b$ 两组实现相同的 $(\\text{FPR}, \\text{TPR})$ 对。我们还必须满足约束条件 $\\text{TPR} \\ge 0.6$ 和 $\\text{FPR} \\le 0.5$。我们需要检查所有可能的非随机化分类器，这对应于为每个组设置单个阈值 $\\tau$。可能的阈值是 $S$ 的值以及略高于/低于它们的值，实际上是 $\\tau > 3$, $\\tau=3$, $\\tau=2$, $\\tau=1$, $\\tau=0$。\n\n首先，我们找出每个组满足约束条件的有效 ROC 点集。\n对于组 $A=a$：\n- $\\tau>3$: $(\\text{FPR}, \\text{TPR})=(0,0)$。不满足 $\\text{TPR} \\ge 0.6$。\n- $\\tau=3$: $(\\text{FPR}, \\text{TPR})=(0.2, 0.5)$。不满足 $\\text{TPR} \\ge 0.6$。\n- $\\tau=2$: $(\\text{FPR}, \\text{TPR})=(0.4, 0.8)$。同时满足 $\\text{TPR} \\ge 0.6$ 和 $\\text{FPR} \\le 0.5$。有效。\n- $\\tau=1$: $(\\text{FPR}, \\text{TPR})=(\\frac{7}{10}, \\frac{9}{10}) = (0.7, 0.9)$。不满足 $\\text{FPR} \\le 0.5$。\n- $\\tau=0$: $(\\text{FPR}, \\text{TPR})=(1.0, 1.0)$。不满足 $\\text{FPR} \\le 0.5$。\n对于组 $A=a$，唯一有效的操作点是 $(0.4, 0.8)$，通过 $\\tau_a=2$ 实现。\n\n对于组 $A=b$：\n- $\\tau>3$: $(\\text{FPR}, \\text{TPR})=(0,0)$。不满足 $\\text{TPR} \\ge 0.6$。\n- $\\tau=3$: $(\\text{FPR}, \\text{TPR})=(0.2, 0.6)$。同时满足两个约束。有效。\n- $\\tau=2$: $(\\text{FPR}, \\text{TPR})=(0.5, 0.9)$。同时满足两个约束。有效。\n- $\\tau=1$: $(\\text{FPR}, \\text{TPR})=(\\frac{7}{10}, \\frac{10}{10}) = (0.7, 1.0)$。不满足 $\\text{FPR} \\le 0.5$。\n- $\\tau=0$: $(\\text{FPR}, \\text{TPR})=(1.0, 1.0)$。不满足 $\\text{FPR} \\le 0.5$。\n对于组 $A=b$，有效的操作点是 $(0.2, 0.6)$（通过 $\\tau_b=3$ 实现）和 $(0.5, 0.9)$（通过 $\\tau_b=2$ 实现）。\n\n为了满足 EO，我们必须找到一个共同的有效点。组 $a$ 的唯一有效点是 $(0.4, 0.8)$。该点不在组 $b$ 的有效点集 $\\{(0.2, 0.6), (0.5, 0.9)\\}$ 中。因此，不可能为每个组选择满足约束条件和 EO 条件的确定性阈值。不使用随机化时，EO 是不可行的。\n\n**任务 3：为均等机会找到混合概率 $\\lambda$**\n\n根据指示，我们将组 $A=a$ 的分类器固定为使用确定性阈值 $\\tau=2$。这产生的 ROC 点为 $(\\text{FPR}_a, \\text{TPR}_a) = (0.4, 0.8)$。如前所述，该点满足操作约束。\n\n对于组 $A=b$，我们使用一个在两个阈值之间随机化的混合分类器：它以概率 $\\lambda$ 使用 $\\tau=2$，以概率 $1-\\lambda$ 使用 $\\tau=3$。对应于组 $b$ 的这些阈值的 ROC 点是：\n- 对于 $\\tau=2$: $(\\text{FPR}_{b, \\tau=2}, \\text{TPR}_{b, \\tau=2}) = (0.5, 0.9)$。\n- 对于 $\\tau=3$: $(\\text{FPR}_{b, \\tau=3}, \\text{TPR}_{b, \\tau=3}) = (0.2, 0.6)$。\n\n组 $b$ 的混合分类器的 TPR 和 FPR，表示为 $\\text{TPR}_b(\\lambda)$ 和 $\\text{FPR}_b(\\lambda)$，是构成阈值处比率的线性组合，按各自的概率加权。\n使用全概率定律：\n$$ \\text{FPR}_b(\\lambda) = \\lambda \\cdot \\text{FPR}_{b, \\tau=2} + (1-\\lambda) \\cdot \\text{FPR}_{b, \\tau=3} $$\n$$ \\text{TPR}_b(\\lambda) = \\lambda \\cdot \\text{TPR}_{b, \\tau=2} + (1-\\lambda) \\cdot \\text{TPR}_{b, \\tau=3} $$\n代入数值：\n$$ \\text{FPR}_b(\\lambda) = \\lambda(0.5) + (1-\\lambda)(0.2) = 0.5\\lambda + 0.2 - 0.2\\lambda = 0.3\\lambda + 0.2 $$\n$$ \\text{TPR}_b(\\lambda) = \\lambda(0.9) + (1-\\lambda)(0.6) = 0.9\\lambda + 0.6 - 0.6\\lambda = 0.3\\lambda + 0.6 $$\n\n为实现均等机会，我们必须强制各组的 TPR 和 FPR 相等：\n$$ \\text{FPR}_a = \\text{FPR}_b(\\lambda) \\implies 0.4 = 0.3\\lambda + 0.2 $$\n$$ \\text{TPR}_a = \\text{TPR}_b(\\lambda) \\implies 0.8 = 0.3\\lambda + 0.6 $$\n\n我们求解任一方程以得到 $\\lambda$。两个方程必须得出相同的解，才存在一致的解。\n从 FPR 方程得出：\n$$ 0.4 - 0.2 = 0.3\\lambda $$\n$$ 0.2 = 0.3\\lambda $$\n$$ \\lambda = \\frac{0.2}{0.3} = \\frac{2}{3} $$\n从 TPR 方程得出：\n$$ 0.8 - 0.6 = 0.3\\lambda $$\n$$ 0.2 = 0.3\\lambda $$\n$$ \\lambda = \\frac{0.2}{0.3} = \\frac{2}{3} $$\n两个方程一致地得出 $\\lambda = \\frac{2}{3}$。该值在概率的有效范围 $[0,1]$ 内。\n两个组最终的 ROC 点均为 $(0.4, 0.8)$，满足约束条件 $\\text{TPR} \\ge 0.6$ 和 $\\text{FPR} \\le 0.5$。因此，混合概率 $\\lambda$ 为 $\\frac{2}{3}$。",
            "answer": "$$\\boxed{\\frac{2}{3}}$$"
        },
        {
            "introduction": "除了审计模型或在训练后进行修复（后处理）之外，我们还可以将公平性直接整合到学习过程本身。这个高级练习 () 将向你介绍“处理中”（in-processing）技术。你将学习如何通过使用平滑代理（smooth surrogates）使像均等化赔率这样的不可微公平性指标与基于梯度的优化方法兼容。本练习将指导你推导公平性惩罚项的梯度，并实现一个从一开始就同时为准确性和公平性进行优化的模型。",
            "id": "3120918",
            "problem": "给定一个统计学习中的二元分类场景，其中有一个表示两个群体的受保护属性。预测模型是一个可微的逻辑回归器，其参数为 $\\theta \\in \\mathbb{R}^d$，分数为 $z_i = \\theta^\\top x_i$。预测概率为 $\\hat{p}_i(\\theta) = \\sigma(z_i)$，其中 $\\sigma(u) = 1/(1+e^{-u})$。基本概念包括真阳性率（TPR）、假阳性率（FPR）、使用交叉熵损失的逻辑回归，以及要求跨受保护群体TPR和FPR相等的均等化赔率（EO）的定义。由于TPR和FPR中使用的指示函数是不可微的，一种标准方法是使用平滑代理：用带有温度参数 $\\tau > 0$ 的软化逻辑函数替代阈值指示函数。从第一性原理出发，使用此平滑代理推导两个群体之间TPR差异关于 $\\theta$ 的梯度，然后实现一个能够通过梯度下降平衡标准交叉熵损失和可微EO惩罚项的公平性感知优化器。\n\n数据集是固定的，提供如下。共有 $n = 12$ 个样本，两个实数特征外加一个截距项，以及一个二元受保护属性 $a_i \\in \\{0,1\\}$。输入的排列方式使得最后一个特征是常数 $1$，用以表示截距。数据为：\n- 特征 $X \\in \\mathbb{R}^{12 \\times 3}$，各行如下：\n$$\n\\begin{aligned}\nx_1 = [\\,2.0,\\,2.0,\\,1.0\\,],\\quad y_1 = 1,\\quad a_1 = 0\\\\\nx_2 = [\\,1.5,\\,2.0,\\,1.0\\,],\\quad y_2 = 1,\\quad a_2 = 0\\\\\nx_3 = [\\,1.7,\\,1.8,\\,1.0\\,],\\quad y_3 = 1,\\quad a_3 = 0\\\\\nx_4 = [\\,2.2,\\,1.4,\\,1.0\\,],\\quad y_4 = 1,\\quad a_4 = 0\\\\\nx_5 = [\\,-1.0,\\,-1.0,\\,1.0\\,],\\quad y_5 = 0,\\quad a_5 = 0\\\\\nx_6 = [\\,-0.5,\\,-1.2,\\,1.0\\,],\\quad y_6 = 0,\\quad a_6 = 0\\\\\nx_7 = [\\,1.2,\\,-0.2,\\,1.0\\,],\\quad y_7 = 1,\\quad a_7 = 1\\\\\nx_8 = [\\,0.8,\\,-0.5,\\,1.0\\,],\\quad y_8 = 1,\\quad a_8 = 1\\\\\nx_9 = [\\,-0.8,\\,0.3,\\,1.0\\,],\\quad y_9 = 0,\\quad a_9 = 1\\\\\nx_{10} = [\\,-1.0,\\,0.2,\\,1.0\\,],\\quad y_{10} = 0,\\quad a_{10} = 1\\\\\nx_{11} = [\\,-1.2,\\,-0.2,\\,1.0\\,],\\quad y_{11} = 0,\\quad a_{11} = 1\\\\\nx_{12} = [\\,-0.5,\\,0.1,\\,1.0\\,],\\quad y_{12} = 0,\\quad a_{12} = 1\n\\end{aligned}\n$$\n\n使用以下平滑代理：\n- 群体 $g \\in \\{0,1\\}$ 的软化真阳性率：\n$$\n\\mathrm{TPR}^{\\mathrm{soft}}_g(\\theta;\\tau) = \\frac{1}{N_{g,1} + \\epsilon} \\sum_{i: a_i=g,\\,y_i=1} \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right),\n$$\n其中 $N_{g,1}$ 是群体 $g$ 中 $y_i=1$ 的样本数量，$\\epsilon$ 是为避免除以零而添加的一个小的正常数。\n- 群体 $g$ 的软化假阳性率：\n$$\n\\mathrm{FPR}^{\\mathrm{soft}}_g(\\theta;\\tau) = \\frac{1}{N_{g,0} + \\epsilon} \\sum_{i: a_i=g,\\,y_i=0} \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right).\n$$\n\n定义差异：\n$$\n\\Delta \\mathrm{TPR}(\\theta;\\tau) = \\mathrm{TPR}^{\\mathrm{soft}}_0(\\theta;\\tau) - \\mathrm{TPR}^{\\mathrm{soft}}_1(\\theta;\\tau),\n$$\n$$\n\\Delta \\mathrm{FPR}(\\theta;\\tau) = \\mathrm{FPR}^{\\mathrm{soft}}_0(\\theta;\\tau) - \\mathrm{FPR}^{\\mathrm{soft}}_1(\\theta;\\tau).\n$$\n\n均等化赔率惩罚项为：\n$$\nJ_{\\mathrm{EO}}(\\theta;\\tau) = \\frac{1}{2}\\left(\\left[\\Delta \\mathrm{TPR}(\\theta;\\tau)\\right]^2 + \\left[\\Delta \\mathrm{FPR}(\\theta;\\tau)\\right]^2\\right).\n$$\n\n所有样本的平均逻辑交叉熵损失为：\n$$\nL(\\theta) = \\frac{1}{n} \\sum_{i=1}^n \\left( -y_i \\log(\\hat{p}_i(\\theta)) - (1 - y_i)\\log(1 - \\hat{p}_i(\\theta)) \\right),\n$$\n其中 $\\hat{p}_i(\\theta) = \\sigma(\\theta^\\top x_i)$。\n\n您的任务：\n- 仅从上述核心定义出发，明确推导梯度 $\\nabla_\\theta\\,\\Delta \\mathrm{TPR}(\\theta;\\tau)$，用 $\\theta$、$\\tau$ 和数据表示。使用链式法则进行微分，并利用逻辑函数的导数。类似地，描述 $\\nabla_\\theta\\,\\Delta \\mathrm{FPR}(\\theta;\\tau)$。\n- 设计并实现一个基于梯度的优化器，对组合目标\n$$\nJ_{\\mathrm{total}}(\\theta;\\tau,\\lambda) = L(\\theta) + \\lambda\\,J_{\\mathrm{EO}}(\\theta;\\tau),\n$$\n执行梯度下降，其中 $\\lambda \\geq 0$ 用以平衡准确性和公平性。使用固定的学习率和固定的迭代次数。通过在分母中使用 $\\epsilon$（例如 $\\epsilon = 10^{-8}$）以及对 $\\log$ 和 $\\sigma$ 进行安全计算来确保数值稳定性。\n\n测试套件和最终输出规范：\n- 对所有测试使用初始参数向量 $\\theta^{(0)} = [\\,0.2,\\,-0.4,\\,-0.1\\,]^\\top$。\n- 对于以下四个测试用例中的每一个，从 $\\theta^{(0)}$ 开始运行梯度下降，并为每个用例报告六个浮点数：初始 $\\Delta \\mathrm{TPR}$、优化后的最终 $\\Delta \\mathrm{TPR}$、初始 $\\Delta \\mathrm{FPR}$、优化后的最终 $\\Delta \\mathrm{FPR}$、初始 $L(\\theta)$ 和优化后的最终 $L(\\theta)$。所有比率和损失均以小数表示（而非百分比）。\n- 测试用例由 $(\\tau, \\lambda, \\eta, T)$ 指定，其中 $\\eta$ 是学习率， $T$ 是迭代次数：\n    1. $(\\tau = 1.0,\\, \\lambda = 0.5,\\, \\eta = 0.1,\\, T = 300)$\n    2. $(\\tau = 1.0,\\, \\lambda = 5.0,\\, \\eta = 0.1,\\, T = 300)$\n    3. $(\\tau = 0.2,\\, \\lambda = 2.0,\\, \\eta = 0.05,\\, T = 400)$\n    4. $(\\tau = 1.0,\\, \\lambda = 0.0,\\, \\eta = 0.1,\\, T = 300)$\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，列表中的每个元素本身是对应一个测试用例的逗号分隔列表，顺序相同。例如，输出应如下所示：\n$$\n[ [r_{1,1}, r_{1,2}, r_{1,3}, r_{1,4}, r_{1,5}, r_{1,6}], [r_{2,1}, \\dots, r_{2,6}], [r_{3,1}, \\dots, r_{3,6}], [r_{4,1}, \\dots, r_{4,6}] ].\n$$\n不应打印任何其他文本。所有值都应为 Python 浮点数。",
            "solution": "该问题被评估为有效。它在统计学习和算法公平性领域是一个适定、有科学依据且客观的问题表述。它包含了推导唯一且有意义的解所需的所有必要数据、定义和约束。其中没有矛盾、歧义或事实不准确之处。\n\n解决方案分两部分进行：首先，对必要的梯度进行原则性推导；其次，对公平性感知优化器进行算法描述。\n\n### 第一部分：梯度推导\n\n目标是对总损失函数执行梯度下降：\n$$\nJ_{\\mathrm{total}}(\\theta;\\tau,\\lambda) = L(\\theta) + \\lambda\\,J_{\\mathrm{EO}}(\\theta;\\tau)\n$$\n由于微分算子的线性特性，此函数关于模型参数 $\\theta \\in \\mathbb{R}^d$ 的梯度由两个分量的梯度之和给出：\n$$\n\\nabla_\\theta J_{\\mathrm{total}}(\\theta;\\tau,\\lambda) = \\nabla_\\theta L(\\theta) + \\lambda\\,\\nabla_\\theta J_{\\mathrm{EO}}(\\theta;\\tau)\n$$\n我们将分别推导每个分量。\n\n#### 交叉熵损失 $L(\\theta)$ 的梯度\n\n$n$ 个样本的平均逻辑交叉熵损失定义为：\n$$\nL(\\theta) = \\frac{1}{n} \\sum_{i=1}^n \\left( -y_i \\log(\\hat{p}_i(\\theta)) - (1 - y_i)\\log(1 - \\hat{p}_i(\\theta)) \\right)\n$$\n其中 $y_i \\in \\{0, 1\\}$ 是真实标签，$\\hat{p}_i(\\theta) = \\sigma(z_i)$ 是预测概率，且 $z_i = \\theta^\\top x_i$。逻辑 sigmoid 函数为 $\\sigma(u) = 1/(1+e^{-u})$。\n\n为了求梯度 $\\nabla_\\theta L(\\theta)$，我们应用链式法则。单个样本 $i$ 的损失梯度为：\n$$\n\\nabla_\\theta L_i(\\theta) = \\frac{\\partial L_i}{\\partial \\hat{p}_i} \\frac{\\partial \\hat{p}_i}{\\partial z_i} \\nabla_\\theta z_i\n$$\n各分量为：\n1.  $\\frac{\\partial L_i}{\\partial \\hat{p}_i} = -\\frac{y_i}{\\hat{p}_i} + \\frac{1-y_i}{1-\\hat{p}_i} = \\frac{-y_i(1-\\hat{p}_i) + (1-y_i)\\hat{p}_i}{\\hat{p}_i(1-\\hat{p}_i)} = \\frac{\\hat{p}_i - y_i}{\\hat{p}_i(1-\\hat{p}_i)}$\n2.  sigmoid 函数的导数为 $\\sigma'(u) = \\sigma(u)(1-\\sigma(u))$。因此，$\\frac{\\partial \\hat{p}_i}{\\partial z_i} = \\sigma'(z_i) = \\hat{p}_i(1-\\hat{p}_i)$。\n3.  分数 $z_i = \\theta^\\top x_i$ 关于 $\\theta$ 的梯度为 $\\nabla_\\theta z_i = x_i$。\n\n结合这些项，我们得到：\n$$\n\\nabla_\\theta L_i(\\theta) = \\left( \\frac{\\hat{p}_i - y_i}{\\hat{p}_i(1-\\hat{p}_i)} \\right) \\cdot (\\hat{p}_i(1-\\hat{p}_i)) \\cdot x_i = (\\hat{p}_i - y_i) x_i\n$$\n对所有 $n$ 个样本求平均，总交叉熵损失的梯度为：\n$$\n\\nabla_\\theta L(\\theta) = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\theta^\\top x_i) - y_i) x_i\n$$\n\n#### 均等化赔率惩罚项 $J_{\\mathrm{EO}}(\\theta;\\tau)$ 的梯度\n\n均等化赔率惩罚项定义为：\n$$\nJ_{\\mathrm{EO}}(\\theta;\\tau) = \\frac{1}{2}\\left(\\left[\\Delta \\mathrm{TPR}(\\theta;\\tau)\\right]^2 + \\left[\\Delta \\mathrm{FPR}(\\theta;\\tau)\\right]^2\\right)\n$$\n其中 $\\Delta \\mathrm{TPR} = \\mathrm{TPR}^{\\mathrm{soft}}_0 - \\mathrm{TPR}^{\\mathrm{soft}}_1$ 且 $\\Delta \\mathrm{FPR} = \\mathrm{FPR}^{\\mathrm{soft}}_0 - \\mathrm{FPR}^{\\mathrm{soft}}_1$。\n\n使用链式法则，其梯度为：\n$$\n\\nabla_\\theta J_{\\mathrm{EO}}(\\theta;\\tau) = \\Delta \\mathrm{TPR}(\\theta;\\tau) \\cdot \\nabla_\\theta \\Delta \\mathrm{TPR}(\\theta;\\tau) + \\Delta \\mathrm{FPR}(\\theta;\\tau) \\cdot \\nabla_\\theta \\Delta \\mathrm{FPR}(\\theta;\\tau)\n$$\n我们需要推导梯度 $\\nabla_\\theta \\Delta \\mathrm{TPR}$ 和 $\\nabla_\\theta \\Delta \\mathrm{FPR}$，根据线性性质，它们分别为 $\\nabla_\\theta \\mathrm{TPR}^{\\mathrm{soft}}_0 - \\nabla_\\theta \\mathrm{TPR}^{\\mathrm{soft}}_1$ 和 $\\nabla_\\theta \\mathrm{FPR}^{\\mathrm{soft}}_0 - \\nabla_\\theta \\mathrm{FPR}^{\\mathrm{soft}}_1$。\n\n让我们来推导一个通用软化率的梯度。群体 $g \\in \\{0, 1\\}$ 的软化真阳性率为：\n$$\n\\mathrm{TPR}^{\\mathrm{soft}}_g(\\theta;\\tau) = \\frac{1}{N_{g,1} + \\epsilon} \\sum_{i \\in S_{g,1}} \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\n$$\n其中 $S_{g,1} = \\{i: a_i=g, y_i=1\\}$ 是群体 $g$ 中正样本的索引集合，且 $N_{g,1} = |S_{g,1}|$。\n\n梯度为：\n$$\n\\nabla_\\theta \\mathrm{TPR}^{\\mathrm{soft}}_g(\\theta;\\tau) = \\frac{1}{N_{g,1} + \\epsilon} \\sum_{i \\in S_{g,1}} \\nabla_\\theta \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\n$$\n对求和项内的项应用链式法则：\n$$\n\\nabla_\\theta \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right) = \\sigma'\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right) \\cdot \\nabla_\\theta \\left(\\frac{\\theta^\\top x_i}{\\tau}\\right) = \\sigma'\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right) \\frac{x_i}{\\tau}\n$$\n代入 $\\sigma'(u) = \\sigma(u)(1-\\sigma(u))$，我们有：\n$$\n\\nabla_\\theta \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right) = \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\\left(1 - \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\\right) \\frac{x_i}{\\tau}\n$$\n因此，群体 $g$ 的软化TPR梯度为：\n$$\n\\nabla_\\theta \\mathrm{TPR}^{\\mathrm{soft}}_g(\\theta;\\tau) = \\frac{1}{(N_{g,1} + \\epsilon)\\tau} \\sum_{i \\in S_{g,1}} \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\\left(1 - \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\\right) x_i\n$$\n$\\nabla_\\theta \\mathrm{FPR}^{\\mathrm{soft}}_g(\\theta;\\tau)$ 的推导过程完全类似，只是求和是针对负样本集 $S_{g,0} = \\{i: a_i=g, y_i=0\\}$，并由 $N_{g,0} = |S_{g,0}|$ 进行归一化：\n$$\n\\nabla_\\theta \\mathrm{FPR}^{\\mathrm{soft}}_g(\\theta;\\tau) = \\frac{1}{(N_{g,0} + \\epsilon)\\tau} \\sum_{i \\in S_{g,0}} \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\\left(1 - \\sigma\\!\\left(\\frac{\\theta^\\top x_i}{\\tau}\\right)\\right) x_i\n$$\n\n#### 完整梯度\n\n结合所有推导出的分量，总目标函数的完整梯度为：\n$$\n\\begin{aligned}\n\\nabla_\\theta J_{\\mathrm{total}} = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\theta^\\top x_i) - y_i) x_i + \\lambda \\left[ \\Delta\\mathrm{TPR} \\cdot (\\nabla_\\theta \\mathrm{TPR}^{\\mathrm{soft}}_0 - \\nabla_\\theta \\mathrm{TPR}^{\\mathrm{soft}}_1) \\right. \\\\\n\\quad \\left. + \\Delta\\mathrm{FPR} \\cdot (\\nabla_\\theta \\mathrm{FPR}^{\\mathrm{soft}}_0 - \\nabla_\\theta \\mathrm{FPR}^{\\mathrm{soft}}_1) \\right]\n\\end{aligned}\n$$\n其中所有项均已在上面明确定义。\n\n### 第二部分：算法实现\n\n优化器将执行梯度下降。从初始参数向量 $\\theta^{(0)}$ 开始，它根据以下规则迭代更新参数：\n$$\n\\theta^{(k+1)} = \\theta^{(k)} - \\eta \\nabla_\\theta J_{\\mathrm{total}}(\\theta^{(k)};\\tau,\\lambda)\n$$\n其中 $\\eta$ 是学习率，$k$ 是迭代索引。该过程重复固定的迭代次数 $T$。\n\n对于每个测试用例 $(\\tau, \\lambda, \\eta, T)$，算法按以下步骤进行：\n1.  初始化 $\\theta \\leftarrow \\theta^{(0)}$。\n2.  预先计算每个子群 $(g, y) \\in \\{0, 1\\} \\times \\{0, 1\\}$ 的索引掩码及相应的计数 $N_{g,y}$。\n3.  计算并存储初始指标：$L(\\theta)$、$\\Delta\\mathrm{TPR}(\\theta; \\tau)$ 和 $\\Delta\\mathrm{FPR}(\\theta; \\tau)$。\n4.  对于 $k = 0, \\dots, T-1$：\n    a. 计算所有 $i=1, \\dots, n$ 的分数 $z_i = \\theta^\\top x_i$。\n    b. 计算损失梯度 $\\nabla_\\theta L(\\theta)$。\n    c. 计算 $g \\in \\{0, 1\\}$ 的软化率 $\\mathrm{TPR}^{\\mathrm{soft}}_g$ 和 $\\mathrm{FPR}^{\\mathrm{soft}}_g$。由此求得 $\\Delta\\mathrm{TPR}$ 和 $\\Delta\\mathrm{FPR}$。\n    d. 计算软化率的梯度 $\\nabla_\\theta \\mathrm{TPR}^{\\mathrm{soft}}_g$ 和 $\\nabla_\\theta \\mathrm{FPR}^{\\mathrm{soft}}_g$。\n    e. 从 (4c) 和 (4d) 中计算的项组装惩罚项梯度 $\\nabla_\\theta J_{\\mathrm{EO}}$。\n    f. 计算总梯度 $\\nabla_\\theta J_{\\mathrm{total}} = \\nabla_\\theta L + \\lambda \\nabla_\\theta J_{\\mathrm{EO}}$。\n    g. 更新参数：$\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J_{\\mathrm{total}}$。\n5.  在 $T$ 次迭代后，使用更新后的 $\\theta$ 计算并存储最终指标。\n6.  存储六个所需的值：初始和最终的 $\\Delta\\mathrm{TPR}$、初始和最终的 $\\Delta\\mathrm{FPR}$、初始和最终的 $L(\\theta)$。\n\n为保证数值稳定性，交叉熵损失 $L(\\theta)$ 可以使用恒等式 $L_i(\\theta) = -y_i \\log(\\hat{p}_i) - (1-y_i) \\log(1-\\hat{p}_i) = \\log(1+e^{-z_i}) + z_i(1-y_i)$ 计算，这可以通过 log-sum-exp 函数实现以防止溢出。在分母中添加一个小的常数 $\\epsilon$ 以避免除以零。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit, logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the fairness-aware optimization problem using gradient descent.\n    Derives and implements the gradient for a combined objective of cross-entropy\n    loss and an Equalized Odds penalty.\n    \"\"\"\n    # Define the dataset\n    X = np.array([\n        [2.0, 2.0, 1.0], [1.5, 2.0, 1.0], [1.7, 1.8, 1.0], [2.2, 1.4, 1.0],\n        [-1.0, -1.0, 1.0], [-0.5, -1.2, 1.0], [1.2, -0.2, 1.0], [0.8, -0.5, 1.0],\n        [-0.8, 0.3, 1.0], [-1.0, 0.2, 1.0], [-1.2, -0.2, 1.0], [-0.5, 0.1, 1.0]\n    ])\n    y = np.array([1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0])\n    a = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n    n = X.shape[0]\n\n    # Initial parameters and constants\n    theta0 = np.array([0.2, -0.4, -0.1])\n    epsilon = 1e-8\n\n    # Test cases: (tau, lambda, eta, T)\n    test_cases = [\n        (1.0, 0.5, 0.1, 300),\n        (1.0, 5.0, 0.1, 300),\n        (0.2, 2.0, 0.05, 400),\n        (1.0, 0.0, 0.1, 300)\n    ]\n    \n    # Pre-compute masks and counts for subgroups\n    mask_a0 = (a == 0)\n    mask_a1 = (a == 1)\n    mask_y1 = (y == 1)\n    mask_y0 = (y == 0)\n\n    mask_g0_y1 = mask_a0  mask_y1\n    mask_g0_y0 = mask_a0  mask_y0\n    mask_g1_y1 = mask_a1  mask_y1\n    mask_g1_y0 = mask_a1  mask_y0\n\n    N_g0_y1 = np.sum(mask_g0_y1)\n    N_g0_y0 = np.sum(mask_g0_y0)\n    N_g1_y1 = np.sum(mask_g1_y1)\n    N_g1_y0 = np.sum(mask_g1_y0)\n\n    def sigmoid(z):\n        return expit(z)\n\n    def calculate_metrics(theta, tau):\n        \"\"\"Calculates loss and fairness metrics for a given theta.\"\"\"\n        z = X @ theta\n        \n        # Cross-entropy loss (numerically stable)\n        # Loss for one sample: log(1+exp(-z)) + z*(1-y)\n        loss = np.mean(logsumexp(np.vstack([np.zeros_like(z), -z]), axis=0) + z * (1 - y))\n\n        z_tau = z / tau\n        p_hat_tau = sigmoid(z_tau)\n\n        # Softened TPR/FPR\n        tpr_soft_0 = np.sum(p_hat_tau[mask_g0_y1]) / (N_g0_y1 + epsilon)\n        tpr_soft_1 = np.sum(p_hat_tau[mask_g1_y1]) / (N_g1_y1 + epsilon)\n        fpr_soft_0 = np.sum(p_hat_tau[mask_g0_y0]) / (N_g0_y0 + epsilon)\n        fpr_soft_1 = np.sum(p_hat_tau[mask_g1_y0]) / (N_g1_y0 + epsilon)\n        \n        delta_tpr = tpr_soft_0 - tpr_soft_1\n        delta_fpr = fpr_soft_0 - fpr_soft_1\n        \n        return loss, delta_tpr, delta_fpr\n\n    def calculate_total_gradient(theta, tau, lambda_):\n        \"\"\"Calculates the gradient of the total objective function.\"\"\"\n        z = X @ theta\n        p_hat = sigmoid(z)\n\n        # Gradient of cross-entropy loss\n        grad_L = X.T @ (p_hat - y) / n\n        \n        # If lambda is zero, no need to compute the EO penalty gradient\n        if lambda_ == 0.0:\n            return grad_L\n\n        # Compute EO penalty gradient\n        z_tau = z / tau\n        p_hat_tau = sigmoid(z_tau)\n        p_hat_tau_prime = p_hat_tau * (1 - p_hat_tau)\n\n        # Softened rates (re-computed for clarity, could be passed in)\n        tpr_soft_0 = np.sum(p_hat_tau[mask_g0_y1]) / (N_g0_y1 + epsilon)\n        tpr_soft_1 = np.sum(p_hat_tau[mask_g1_y1]) / (N_g1_y1 + epsilon)\n        fpr_soft_0 = np.sum(p_hat_tau[mask_g0_y0]) / (N_g0_y0 + epsilon)\n        fpr_soft_1 = np.sum(p_hat_tau[mask_g1_y0]) / (N_g1_y0 + epsilon)\n        delta_tpr = tpr_soft_0 - tpr_soft_1\n        delta_fpr = fpr_soft_0 - fpr_soft_1\n\n        # Gradients of softened rates\n        summand_tpr0 = (p_hat_tau_prime[mask_g0_y1, np.newaxis] * X[mask_g0_y1]).sum(axis=0)\n        grad_tpr0 = summand_tpr0 / ((N_g0_y1 + epsilon) * tau)\n\n        summand_tpr1 = (p_hat_tau_prime[mask_g1_y1, np.newaxis] * X[mask_g1_y1]).sum(axis=0)\n        grad_tpr1 = summand_tpr1 / ((N_g1_y1 + epsilon) * tau)\n\n        summand_fpr0 = (p_hat_tau_prime[mask_g0_y0, np.newaxis] * X[mask_g0_y0]).sum(axis=0)\n        grad_fpr0 = summand_fpr0 / ((N_g0_y0 + epsilon) * tau)\n\n        summand_fpr1 = (p_hat_tau_prime[mask_g1_y0, np.newaxis] * X[mask_g1_y0]).sum(axis=0)\n        grad_fpr1 = summand_fpr1 / ((N_g1_y0 + epsilon) * tau)\n        \n        grad_delta_tpr = grad_tpr0 - grad_tpr1\n        grad_delta_fpr = grad_fpr0 - grad_fpr1\n        \n        grad_J_EO = delta_tpr * grad_delta_tpr + delta_fpr * grad_delta_fpr\n        \n        return grad_L + lambda_ * grad_J_EO\n\n    results = []\n    for tau, lambda_, eta, T in test_cases:\n        theta = theta0.copy()\n\n        # Initial metrics\n        loss_initial, delta_tpr_initial, delta_fpr_initial = calculate_metrics(theta, tau)\n        \n        # Gradient descent\n        for _ in range(T):\n            grad = calculate_total_gradient(theta, tau, lambda_)\n            theta -= eta * grad\n            \n        # Final metrics\n        loss_final, delta_tpr_final, delta_fpr_final = calculate_metrics(theta, tau)\n        \n        results.append([\n            delta_tpr_initial, delta_tpr_final,\n            delta_fpr_initial, delta_fpr_final,\n            loss_initial, loss_final\n        ])\n\n    # Format the output string exactly as required\n    output_str = \"[\" + \", \".join([\"[\" + \", \".join(map(str, case_res)) + \"]\" for case_res in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}