{
    "hands_on_practices": [
        {
            "introduction": "Reweighting is a common pre-processing strategy used to correct for imbalances in data, ensuring that underrepresented groups contribute more significantly to the model's training loss. While effective for balancing influence, such interventions can have unintended side effects. This practice guides you through an analytical exploration of how group-based reweighting can introduce a systematic bias in a logistic regression model's intercept, affecting its overall calibration. By deriving a closed-form adjustment, you will learn how to diagnose and correct for the secondary effects of fairness interventions, developing a more nuanced understanding of the interplay between pre-processing and post-processing techniques .",
            "id": "3105417",
            "problem": "Consider a binary outcome $y \\in \\{0,1\\}$ observed in a population partitioned into two groups $g \\in \\{\\mathrm{A}, \\mathrm{B}\\}$. The population proportions are $q_{\\mathrm{A}} = 0.7$ and $q_{\\mathrm{B}} = 0.3$, and the groupwise event rates are $\\pi_{\\mathrm{A}} = 0.12$ and $\\pi_{\\mathrm{B}} = 0.27$. The overall population prevalence is $\\pi = q_{\\mathrm{A}} \\pi_{\\mathrm{A}} + q_{\\mathrm{B}} \\pi_{\\mathrm{B}}$. You train an intercept-only logistic regression model $p = \\sigma(b)$, where $\\sigma(b) = 1/(1+\\exp(-b))$, using weighted maximum likelihood with group weights $\\alpha_{\\mathrm{A}} = \\frac{1}{q_{\\mathrm{A}}}$ and $\\alpha_{\\mathrm{B}} = \\frac{1}{q_{\\mathrm{B}}}$ to balance group loss contributions.\n\nStarting from the definition of the Bernoulli negative log-likelihood and its weighted version, derive the optimal intercept $b_{\\mathrm{w}}$ under the weighted training in terms of the weighted prevalence $\\pi_{\\mathrm{w}}$, and then derive a closed-form intercept adjustment $\\delta$ such that the adjusted intercept $b_{\\mathrm{w}} + \\delta$ yields marginal calibration on the unweighted population, defined by $\\sigma(b_{\\mathrm{w}} + \\delta) = \\pi$. Compute the numerical value of $\\delta$ for the given $q_{\\mathrm{A}}, q_{\\mathrm{B}}, \\pi_{\\mathrm{A}}, \\pi_{\\mathrm{B}}$ and weights $\\alpha_{\\mathrm{A}}, \\alpha_{\\mathrm{B}}$. Round your final numerical answer to four significant figures.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. All necessary data and definitions are provided, and there are no internal contradictions or violations of mathematical or statistical principles. We will therefore proceed with a full solution.\n\nThe problem asks for the derivation of an intercept adjustment for a logistic regression model. Let the model predict a probability $p = \\sigma(b)$, where $\\sigma(b) = \\frac{1}{1 + \\exp(-b)}$ is the sigmoid function and $b$ is the model's intercept.\n\nThe model is trained using weighted maximum likelihood. The weighted negative log-likelihood (cross-entropy loss) for a dataset of observations $\\{y_i, g_i\\}$ is given by:\n$$ \\mathcal{L}_{\\mathrm{w}}(b) = - \\sum_{i} \\alpha_{g_i} [y_i \\ln(\\sigma(b)) + (1-y_i)\\ln(1-\\sigma(b))] $$\nwhere $\\alpha_{g_i}$ is the weight for an observation $i$ from group $g_i$. To find the optimal intercept $b_{\\mathrm{w}}$, we\ndifferentiate the positive weighted log-likelihood with respect to $b$ and set the result to zero. The derivative of the log-likelihood term for a single observation is:\n$$ \\frac{d}{db} [y_i \\ln(\\sigma(b)) + (1-y_i)\\ln(1-\\sigma(b))] = y_i\\frac{\\sigma'(b)}{\\sigma(b)} + (1-y_i)\\frac{-\\sigma'(b)}{1-\\sigma(b)} $$\nUsing the identity $\\sigma'(b) = \\sigma(b)(1-\\sigma(b))$, this simplifies to:\n$$ y_i(1-\\sigma(b)) - (1-y_i)\\sigma(b) = y_i - \\sigma(b) $$\nThe derivative of the total weighted log-likelihood is therefore:\n$$ \\frac{d}{db} \\sum_{i} \\alpha_{g_i} [y_i \\ln(\\sigma(b)) + (1-y_i)\\ln(1-\\sigma(b))] = \\sum_{i} \\alpha_{g_i} [y_i - \\sigma(b)] $$\nSetting this to zero to find the optimal intercept $b_{\\mathrm{w}}$:\n$$ \\sum_{i} \\alpha_{g_i} (y_i - \\sigma(b_{\\mathrm{w}})) = 0 \\implies \\sum_{i} \\alpha_{g_i} y_i = \\sigma(b_{\\mathrm{w}}) \\sum_{i} \\alpha_{g_i} $$\nThis yields the solution for the model's prediction:\n$$ \\sigma(b_{\\mathrm{w}}) = \\frac{\\sum_{i} \\alpha_{g_i} y_i}{\\sum_{i} \\alpha_{g_i}} $$\nThe expression on the right is the weighted average of the outcomes, which we denote as the weighted prevalence $\\pi_{\\mathrm{w}}$. In terms of expectations over the population distribution, this is:\n$$ \\pi_{\\mathrm{w}} = \\frac{E[\\alpha_g y]}{E[\\alpha_g]} = \\frac{\\sum_{g \\in \\{\\mathrm{A}, \\mathrm{B}\\}} P(g) \\alpha_g E[y|g]}{\\sum_{g \\in \\{\\mathrm{A}, \\mathrm{B}\\}} P(g) \\alpha_g} = \\frac{q_{\\mathrm{A}} \\alpha_{\\mathrm{A}} \\pi_{\\mathrm{A}} + q_{\\mathrm{B}} \\alpha_{\\mathrm{B}} \\pi_{\\mathrm{B}}}{q_{\\mathrm{A}} \\alpha_{\\mathrm{A}} + q_{\\mathrm{B}} \\alpha_{\\mathrm{B}}} $$\nGiven the weights $\\alpha_{\\mathrm{A}} = \\frac{1}{q_{\\mathrm{A}}}$ and $\\alpha_{\\mathrm{B}} = \\frac{1}{q_{\\mathrm{B}}}$, we substitute them into the expression for $\\pi_{\\mathrm{w}}$:\n$$ \\pi_{\\mathrm{w}} = \\frac{q_{\\mathrm{A}} (\\frac{1}{q_{\\mathrm{A}}}) \\pi_{\\mathrm{A}} + q_{\\mathrm{B}} (\\frac{1}{q_{\\mathrm{B}}}) \\pi_{\\mathrm{B}}}{q_{\\mathrm{A}} (\\frac{1}{q_{\\mathrm{A}}}) + q_{\\mathrm{B}} (\\frac{1}{q_{\\mathrm{B}}})} = \\frac{\\pi_{\\mathrm{A}} + \\pi_{\\mathrm{B}}}{1+1} = \\frac{\\pi_{\\mathrm{A}} + \\pi_{\\mathrm{B}}}{2} $$\nThe optimal intercept from weighted training, $b_{\\mathrm{w}}$, is the logit of this weighted prevalence:\n$$ b_{\\mathrm{w}} = \\sigma^{-1}(\\pi_{\\mathrm{w}}) = \\ln\\left(\\frac{\\pi_{\\mathrm{w}}}{1-\\pi_{\\mathrm{w}}}\\right) $$\nThe problem requires an adjustment $\\delta$ to achieve marginal calibration on the unweighted population. This condition is stated as $\\sigma(b_{\\mathrm{w}} + \\delta) = \\pi$, where $\\pi$ is the overall population prevalence. The overall prevalence is given by the law of total probability:\n$$ \\pi = q_{\\mathrm{A}} \\pi_{\\mathrm{A}} + q_{\\mathrm{B}} \\pi_{\\mathrm{B}} $$\nFrom the calibration condition, we can solve for $b_{\\mathrm{w}} + \\delta$:\n$$ b_{\\mathrm{w}} + \\delta = \\sigma^{-1}(\\pi) = \\ln\\left(\\frac{\\pi}{1-\\pi}\\right) $$\nThe adjustment $\\delta$ is the difference between the target logit and the learned logit:\n$$ \\delta = \\ln\\left(\\frac{\\pi}{1-\\pi}\\right) - b_{\\mathrm{w}} = \\ln\\left(\\frac{\\pi}{1-\\pi}\\right) - \\ln\\left(\\frac{\\pi_{\\mathrm{w}}}{1-\\pi_{\\mathrm{w}}}\\right) $$\nUsing the quotient rule for logarithms, we arrive at the closed-form expression for $\\delta$:\n$$ \\delta = \\ln\\left(\\frac{\\pi(1-\\pi_{\\mathrm{w}})}{\\pi_{\\mathrm{w}}(1-\\pi)}\\right) $$\nNow, we compute the numerical value of $\\delta$ using the given values: $q_{\\mathrm{A}} = 0.7$, $q_{\\mathrm{B}} = 0.3$, $\\pi_{\\mathrm{A}} = 0.12$, and $\\pi_{\\mathrm{B}} = 0.27$.\n\nFirst, we calculate the overall prevalence $\\pi$:\n$$ \\pi = (0.7)(0.12) + (0.3)(0.27) = 0.084 + 0.081 = 0.165 $$\nNext, we calculate the weighted prevalence $\\pi_{\\mathrm{w}}$:\n$$ \\pi_{\\mathrm{w}} = \\frac{0.12 + 0.27}{2} = \\frac{0.39}{2} = 0.195 $$\nFinally, we substitute these values into the expression for $\\delta$:\n$$ \\delta = \\ln\\left(\\frac{0.165(1-0.195)}{0.195(1-0.165)}\\right) = \\ln\\left(\\frac{0.165 \\times 0.805}{0.195 \\times 0.835}\\right) $$\n$$ \\delta = \\ln\\left(\\frac{0.132825}{0.162825}\\right) \\approx \\ln(0.81576481...) $$\n$$ \\delta \\approx -0.203581... $$\nRounding the result to four significant figures gives $\\delta = -0.2036$.",
            "answer": "$$\\boxed{-0.2036}$$"
        },
        {
            "introduction": "In-processing techniques embed fairness directly into the heart of the machine learning model: the optimization algorithm itself. This exercise introduces a hypothetical method called \"fair gradient clipping,\" which provides an intuitive way to prevent the training process from being dominated by any single demographic group . By implementing a custom gradient descent loop, you will gain hands-on experience modifying a core learning algorithm and analyzing the resulting trade-offs between fairness, overall model performance, and the stability of the optimization process. This practice illuminates how fairness can be an active constraint during learning, not just an afterthought.",
            "id": "3105436",
            "problem": "You are asked to formalize and implement a bias mitigation technique for binary logistic regression, called fair gradient clipping, that limits the dominance of group-specific gradient contributions during training. You will start from the foundational empirical risk minimization principle and the definition of the logistic loss, derive the gradient and a clipping rule that enforces a bounded ratio between group contributions, and then implement a full-batch gradient descent procedure with this clipping. Your program must compute quantitative metrics that expose a bias versus stability trade-off as a function of a single hyperparameter.\n\nConsider a binary classification dataset with a sensitive attribute indicating two groups $A \\in \\{0,1\\}$. Let the data be $\\{(x_i, y_i, a_i)\\}_{i=1}^N$ where each $x_i \\in \\mathbb{R}^d$ (including an explicit bias coordinate as an extra feature with constant value $1$), $y_i \\in \\{0,1\\}$, and $a_i \\in \\{0,1\\}$. Let the model be $f_\\theta(x) = \\sigma(\\theta^\\top x)$ with parameter vector $\\theta \\in \\mathbb{R}^d$ and logistic link $\\sigma(z) = 1/(1 + e^{-z})$. The empirical risk with $\\ell_2$ regularization is\n$$\n\\mathcal{L}(\\theta) \\;=\\; \\frac{1}{N}\\sum_{i=1}^N \\Big( -y_i \\log \\sigma(\\theta^\\top x_i) \\;-\\; (1-y_i)\\log\\!\\big(1 - \\sigma(\\theta^\\top x_i)\\big) \\Big) \\;+\\; \\frac{\\lambda}{2}\\|\\theta\\|_2^2.\n$$\nFrom the definition of the logistic loss and the chain rule, the per-example gradient is the vector\n$$\ng_i(\\theta) \\;=\\; \\big(\\sigma(\\theta^\\top x_i) - y_i\\big)\\, x_i.\n$$\nLet $G_a$ denote the index set of examples with $a_i = a$, and $n_a = |G_a|$, so that $n_0 + n_1 = N$. Define the average gradient within group $a$ as\n$$\ng_a(\\theta) \\;=\\; \\frac{1}{n_a}\\sum_{i \\in G_a} g_i(\\theta),\n$$\nand define the group-weighted contribution vectors\n$$\nc_a(\\theta) \\;=\\; \\frac{n_a}{N}\\, g_a(\\theta), \\quad a \\in \\{0,1\\}.\n$$\nThe unclipped data gradient is $c_0(\\theta) + c_1(\\theta)$, and the full gradient includes regularization as $c_0(\\theta) + c_1(\\theta) + \\lambda \\theta$.\n\nFair gradient clipping imposes a dominance cap by restricting the ratio of the Euclidean norms of the two group contribution vectors. Specifically, for a given ratio cap $\\rho \\in [1,\\infty)$, in each update step you must reduce the norm of the larger of $\\|c_0(\\theta)\\|_2$ and $\\|c_1(\\theta)\\|_2$ (without changing its direction) so that, after scaling, the larger norm does not exceed $\\rho$ times the smaller norm; the smaller contribution remains unchanged. If neither group dominates by more than the factor $\\rho$, no scaling is applied. The data gradient used for the update is the sum of the two (possibly scaled) contribution vectors. Then perform a full-batch gradient descent update.\n\nStarting from the above definitions, derive a scaling rule that meets the dominance cap while preserving direction and leaving the non-dominant group unchanged. Implement the following training and evaluation protocol.\n\n1) Fixed dataset and setup. Use $d=3$ with a bias coordinate included in $x_i$ as the third component equal to $1$. Let $N=16$ with the following samples:\n- Group $A=0$ ($n_0 = 12$): six positive examples with $x = (2,2,1)$, $y=1$, and six negative examples with $x = (-2,-2,1)$, $y=0$.\n- Group $A=1$ ($n_1 = 4$): two positive examples with $x = (-2,2,1)$, $y=1$, and two negative examples with $x = (2,-2,1)$, $y=0$.\n\n2) Training constants. Use full-batch gradient descent with learning rate $\\eta = 0.2$, number of iterations $T = 200$, and regularization coefficient $\\lambda = 0.01$. Initialize $\\theta_0 = 0 \\in \\mathbb{R}^3$. In every iteration, compute the group contributions from the current $\\theta_t$, apply the fair gradient clipping with the specified $\\rho$, add the regularization term, and update $\\theta$ via $\\theta_{t+1} = \\theta_t - \\eta \\,\\tilde{g}_t$, where $\\tilde{g}_t$ is the clipped data gradient plus the regularization gradient. Use a small numerical constant $\\varepsilon = 10^{-12}$ where needed to avoid division by zero.\n\n3) Metrics to report after training:\n- Overall logistic loss: the average of the unregularized logistic losses over all $N$ samples,\n$$\n\\bar{\\ell} \\;=\\; \\frac{1}{N}\\sum_{i=1}^N \\Big( -y_i \\log \\sigma(\\theta^\\top x_i) - (1-y_i)\\log(1-\\sigma(\\theta^\\top x_i)) \\Big).\n$$\n- Fairness gap: the absolute difference in average unregularized logistic loss between the two groups,\n$$\n\\Delta_{\\text{loss}} \\;=\\; \\big| \\; \\frac{1}{n_0}\\sum_{i \\in G_0} \\ell_i \\;-\\; \\frac{1}{n_1}\\sum_{i \\in G_1} \\ell_i \\; \\big|.\n$$\n- Stability distortion: the average over iterations of the relative distortion between the unclipped data gradient and the clipped data gradient, defined as\n$$\nD \\;=\\; \\frac{1}{T} \\sum_{t=1}^{T} \\frac{\\big\\| \\,(c_0(\\theta_t)+c_1(\\theta_t)) \\;-\\; (\\tilde{c}_0(\\theta_t)+\\tilde{c}_1(\\theta_t)) \\,\\big\\|_2}{\\big\\|\\, c_0(\\theta_t)+c_1(\\theta_t) \\,\\big\\|_2 + \\varepsilon}.\n$$\n\n4) Test suite. Run the above with the following four values of the dominance cap $\\rho$:\n- Case $1$: $\\rho = 1.0$.\n- Case $2$: $\\rho = 1.5$.\n- Case $3$: $\\rho = 3.0$.\n- Case $4$: $\\rho = 10^9$ (this approximates no clipping).\n\n5) Program output. Your program must produce a single line containing a list of four results, one per test case, where each result is the list $[\\bar{\\ell}, \\Delta_{\\text{loss}}, D]$ with each value rounded to $6$ decimal places. The required output format is a single line in the form\n$[[\\bar{\\ell}_1,\\Delta_{\\text{loss},1},D_1],[\\bar{\\ell}_2,\\Delta_{\\text{loss},2},D_2],[\\bar{\\ell}_3,\\Delta_{\\text{loss},3},D_3],[\\bar{\\ell}_4,\\Delta_{\\text{loss},4},D_4]]$.\n\n6) Implementation constraints. The code must be fully self-contained with no inputs and must implement the derivation-based clipping rule you obtained from the dominance cap definition. All computations must be performed in floating point with careful handling of $\\varepsilon$ in any division or logarithm to avoid undefined values. No physical units are involved. Angles are not involved. Any time you must express a fraction, it must be as a decimal number in the final output as specified above.",
            "solution": "The user-provided problem is valid. It presents a well-defined task in computational statistics and machine learning, grounded in established principles of logistic regression, gradient-based optimization, and algorithmic fairness. All data, constants, and procedural steps are specified with sufficient precision to permit a unique, verifiable solution. The problem is self-contained, scientifically sound, and objective.\n\n### 1. Principle-Based Design: Derivation and Algorithm\n\nThe core of the problem is to implement a fair gradient clipping mechanism within a standard gradient descent procedure for logistic regression. This requires formalizing the clipping rule and integrating it into the iterative optimization algorithm.\n\n#### 1.1. Model and Gradient Definitions\n\nThe model is a logistic regressor, $f_\\theta(x) = \\sigma(\\theta^\\top x)$, where $\\sigma(z) = (1 + e^{-z})^{-1}$ is the sigmoid function. The parameters $\\theta \\in \\mathbb{R}^d$ are optimized by minimizing an empirical risk, which is the sum of the binary cross-entropy loss over all $N$ data points, plus an $\\ell_2$ regularization term:\n$$\n\\mathcal{L}(\\theta) = \\frac{1}{N}\\sum_{i=1}^N \\ell_i(\\theta) + \\frac{\\lambda}{2}\\|\\theta\\|_2^2, \\quad \\text{where} \\quad \\ell_i(\\theta) = -y_i \\log \\sigma(\\theta^\\top x_i) - (1-y_i)\\log(1 - \\sigma(\\theta^\\top x_i)).\n$$\nThe gradient of this loss function is the sum of contributions from the data term and the regularization term. The gradient of the data term can be decomposed by group. The per-example gradient is given as $g_i(\\theta) = (\\sigma(\\theta^\\top x_i) - y_i) x_i$. The group-weighted contribution vectors are defined as $c_a(\\theta) = \\frac{n_a}{N} g_a(\\theta) = \\frac{1}{N} \\sum_{i \\in G_a} g_i(\\theta)$ for groups $a \\in \\{0,1\\}$, where $G_a$ is the set of indices for data points in group $a$. The total data gradient is $g_{\\text{data}}(\\theta) = c_0(\\theta) + c_1(\\theta)$, and the full gradient is $g(\\theta) = c_0(\\theta) + c_1(\\theta) + \\lambda\\theta$.\n\n#### 1.2. Derivation of the Fair Gradient Clipping Rule\n\nThe clipping rule aims to limit the dominance of one group's gradient contribution over the other. Let $n_{c0} = \\|c_0(\\theta)\\|_2$ and $n_{c1} = \\|c_1(\\theta)\\|_2$ be the Euclidean norms of the group contribution vectors. For a given dominance cap $\\rho \\ge 1$, we must enforce that the norms of the clipped vectors, $\\tilde{c}_0(\\theta)$ and $\\tilde{c}_1(\\theta)$, satisfy $\\|\\tilde{c}_{\\text{larger}}\\|_2 \\le \\rho \\cdot \\|\\tilde{c}_{\\text{smaller}}\\|_2$. The clipping operation scales down the vector with the larger norm while preserving its direction, and leaves the vector with the smaller norm unchanged.\n\nLet's formalize this rule:\n\n1.  **Case 1: Group 0's contribution is dominant.**\n    If $n_{c0} > \\rho \\cdot n_{c1}$, the contribution $c_0(\\theta)$ must be clipped. To preserve its direction, the clipped vector $\\tilde{c}_0(\\theta)$ must be a scaled version of the original, i.e., $\\tilde{c}_0(\\theta) = s \\cdot c_0(\\theta)$ for some scalar $s > 0$. The new norm is required to be $\\|\\tilde{c}_0(\\theta)\\|_2 = \\rho \\cdot n_{c1}$. This implies $s \\cdot n_{c0} = \\rho \\cdot n_{c1}$, which gives the scaling factor $s = \\frac{\\rho \\cdot n_{c1}}{n_{c0}}$. The other contribution is unchanged. Thus:\n    $$\n    \\tilde{c}_0(\\theta) = c_0(\\theta) \\cdot \\frac{\\rho \\cdot \\|c_1(\\theta)\\|_2}{\\|c_0(\\theta)\\|_2}, \\quad \\tilde{c}_1(\\theta) = c_1(\\theta).\n    $$\n\n2.  **Case 2: Group 1's contribution is dominant.**\n    Symmetrically, if $n_{c1} > \\rho \\cdot n_{c0}$, the contribution $c_1(\\theta)$ must be clipped. Following the same logic:\n    $$\n    \\tilde{c}_1(\\theta) = c_1(\\theta) \\cdot \\frac{\\rho \\cdot \\|c_0(\\theta)\\|_2}{\\|c_1(\\theta)\\|_2}, \\quad \\tilde{c}_0(\\theta) = c_0(\\theta).\n    $$\n\n3.  **Case 3: No dominance.**\n    If neither group's contribution dominates the other by more than the factor $\\rho$ (i.e., $n_{c0} \\le \\rho \\cdot n_{c1}$ and $n_{c1} \\le \\rho \\cdot n_{c0}$), no clipping is applied:\n    $$\n    \\tilde{c}_0(\\theta) = c_0(\\theta), \\quad \\tilde{c}_1(\\theta) = c_1(\\theta).\n    $$\nTo prevent division by zero in implementation, especially if a norm is zero, the denominators will be augmented with a small constant $\\varepsilon$. For instance, the scaling factor in Case 1 becomes $s = \\frac{\\rho \\cdot \\|c_1(\\theta)\\|_2}{\\|c_0(\\theta)\\|_2 + \\varepsilon}$.\n\n#### 1.3. Algorithmic Procedure\n\nThe full algorithm integrates this clipping rule into a full-batch gradient descent loop. For each test case defined by a value of $\\rho$:\n\n1.  **Initialization**: Set the parameter vector $\\theta_0 = 0 \\in \\mathbb{R}^3$. Initialize an empty list to store per-iteration distortion values.\n\n2.  **Training Loop**: For each iteration $t$ from $0$ to $T-1$ (total $T=200$ iterations):\n    a.  Compute the current group contribution vectors $c_0(\\theta_t)$ and $c_1(\\theta_t)$ using all data points for each group.\n    b.  Calculate their norms, $n_{c0} = \\|c_0(\\theta_t)\\|_2$ and $n_{c1} = \\|c_1(\\theta_t)\\|_2$.\n    c.  Apply the derived clipping rule with the given $\\rho$ to obtain the clipped vectors $\\tilde{c}_0(\\theta_t)$ and $\\tilde{c}_1(\\theta_t)$.\n    d.  Calculate the stability distortion for this iteration:\n        $$\n        d_t = \\frac{\\big\\| (c_0(\\theta_t)+c_1(\\theta_t)) - (\\tilde{c}_0(\\theta_t)+\\tilde{c}_1(\\theta_t)) \\big\\|_2}{\\big\\| c_0(\\theta_t)+c_1(\\theta_t) \\big\\|_2 + \\varepsilon}\n        $$\n        and store it.\n    e.  Construct the final gradient for the update: $\\tilde{g}_t = \\tilde{c}_0(\\theta_t) + \\tilde{c}_1(\\theta_t) + \\lambda\\theta_t$.\n    f.  Update the parameters: $\\theta_{t+1} = \\theta_t - \\eta \\tilde{g}_t$.\n\n3.  **Evaluation**: After $T$ iterations, use the final parameter vector $\\theta_T$ to compute the evaluation metrics:\n    a.  **Overall loss $\\bar{\\ell}$**: Calculate the unregularized logistic loss for each of the $N=16$ data points and average them.\n    b.  **Fairness gap $\\Delta_{\\text{loss}}$**: Calculate the average loss for group $0$ (over $n_0=12$ points) and group $1$ (over $n_1=4$ points), and find the absolute difference between these two averages.\n    c.  **Stability distortion $D$**: Calculate the average of the $T$ stored distortion values $d_t$.\n\nThis procedure is repeated for each specified value of $\\rho$, yielding a set of metrics $[\\bar{\\ell}, \\Delta_{\\text{loss}}, D]$ for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates the fair gradient clipping algorithm for logistic regression.\n    \"\"\"\n    # 1. Fixed dataset and setup\n    d = 3\n    N = 16\n    n0, n1 = 12, 4\n    \n    # Define the four unique types of data points as numpy arrays\n    x0_pos = np.array([2.0, 2.0, 1.0])\n    x0_neg = np.array([-2.0, -2.0, 1.0])\n    x1_pos = np.array([-2.0, 2.0, 1.0])\n    x1_neg = np.array([2.0, -2.0, 1.0])\n    \n    # Counts for each type of point\n    counts = {'g0_pos': 6, 'g0_neg': 6, 'g1_pos': 2, 'g1_neg': 2}\n    \n    # 2. Training constants\n    eta = 0.2\n    T = 200\n    lambda_reg = 0.01\n    epsilon = 1e-12\n    \n    # 4. Test suite\n    test_cases = [1.0, 1.5, 3.0, 10**9]\n    \n    final_results = []\n\n    def sigma(z):\n        # Clip z to prevent overflow in exp\n        z = np.clip(z, -500, 500)\n        return 1.0 / (1.0 + np.exp(-z))\n\n    for rho in test_cases:\n        theta = np.zeros(d)\n        distortions = []\n        \n        # Training loop\n        for _ in range(T):\n            # Calculate predictions for each point type\n            pred_0_pos = sigma(theta @ x0_pos)\n            pred_0_neg = sigma(theta @ x0_neg)\n            pred_1_pos = sigma(theta @ x1_pos)\n            pred_1_neg = sigma(theta @ x1_neg)\n            \n            # Calculate per-example gradients\n            g_0_pos = (pred_0_pos - 1.0) * x0_pos  # y=1\n            g_0_neg = (pred_0_neg - 0.0) * x0_neg  # y=0\n            g_1_pos = (pred_1_pos - 1.0) * x1_pos  # y=1\n            g_1_neg = (pred_1_neg - 0.0) * x1_neg  # y=0\n\n            # Calculate group contribution vectors c_a = (1/N) * sum_{i in G_a} g_i\n            c0 = (1 / N) * (counts['g0_pos'] * g_0_pos + counts['g0_neg'] * g_0_neg)\n            c1 = (1 / N) * (counts['g1_pos'] * g_1_pos + counts['g1_neg'] * g_1_neg)\n            \n            # Apply Fair Gradient Clipping\n            norm_c0 = np.linalg.norm(c0)\n            norm_c1 = np.linalg.norm(c1)\n            \n            c0_tilde, c1_tilde = c0, c1\n            if norm_c0 > rho * norm_c1:\n                scaling_factor = (rho * norm_c1) / (norm_c0 + epsilon)\n                c0_tilde = c0 * scaling_factor\n            elif norm_c1 > rho * norm_c0:\n                scaling_factor = (rho * norm_c0) / (norm_c1 + epsilon)\n                c1_tilde = c1 * scaling_factor\n            \n            # Calculate distortion for the current iteration\n            unclipped_data_grad = c0 + c1\n            clipped_data_grad = c0_tilde + c1_tilde\n            \n            distortion_numerator = np.linalg.norm(unclipped_data_grad - clipped_data_grad)\n            distortion_denominator = np.linalg.norm(unclipped_data_grad) + epsilon\n            distortions.append(distortion_numerator / distortion_denominator)\n\n            # Gradient update\n            reg_grad = lambda_reg * theta\n            total_grad = clipped_data_grad + reg_grad\n            theta = theta - eta * total_grad\n\n        # 3. Metrics calculation after training\n        final_theta = theta\n        \n        # Predictions with final theta\n        pred_0_pos = sigma(final_theta @ x0_pos)\n        pred_0_neg = sigma(final_theta @ x0_neg)\n        pred_1_pos = sigma(final_theta @ x1_pos)\n        pred_1_neg = sigma(final_theta @ x1_neg)\n        \n        # Individual losses (with epsilon for log stability)\n        loss_0_pos = -np.log(pred_0_pos + epsilon)\n        loss_0_neg = -np.log(1 - pred_0_neg + epsilon)\n        loss_1_pos = -np.log(pred_1_pos + epsilon)\n        loss_1_neg = -np.log(1 - pred_1_neg + epsilon)\n\n        # Overall loss (ell_bar)\n        total_loss = (counts['g0_pos'] * loss_0_pos + counts['g0_neg'] * loss_0_neg +\n                      counts['g1_pos'] * loss_1_pos + counts['g1_neg'] * loss_1_neg)\n        ell_bar = total_loss / N\n\n        # Fairness gap (Delta_loss)\n        avg_loss_g0 = (counts['g0_pos'] * loss_0_pos + counts['g0_neg'] * loss_0_neg) / n0\n        avg_loss_g1 = (counts['g1_pos'] * loss_1_pos + counts['g1_neg'] * loss_1_neg) / n1\n        delta_loss = abs(avg_loss_g0 - avg_loss_g1)\n\n        # Stability distortion (D)\n        D = np.mean(distortions)\n        \n        final_results.append([round(ell_bar, 6), round(delta_loss, 6), round(D, 6)])\n\n    # 5. Program output\n    print(f\"{final_results}\")\n\nsolve()\n```"
        },
        {
            "introduction": "Post-processing methods offer the flexibility to mitigate bias by adjusting a model's outputs after it has already been trained. This practice explores a sophisticated post-processing technique, per-group temperature scaling, designed to improve both model calibration and fairness simultaneously . You will first prove a crucial theoretical result: monotonic score transformations like temperature scaling do not alter a model's underlying ranking performance (its ROC curve). You will then apply this insight to tune the scaling parameters, surgically modifying the model's scores to achieve a specific fairness goal—in this case, equalizing true positive rates across groups.",
            "id": "3105464",
            "problem": "A binary classifier produces an uncalibrated logit output $z(x,g) \\in \\mathbb{R}$ for an instance $x$ belonging to a sensitive group $g \\in \\{A,B\\}$. To mitigate bias while improving calibration, you consider per-group temperature scaling: for each group $g$, define a calibrated score $s(x,g) = \\sigma(z(x,g)/T_{g})$, where $\\sigma(u) = \\frac{1}{1+\\exp(-u)}$ is the logistic sigmoid and $T_{g} > 0$ is a group-specific temperature parameter to be chosen. A global decision rule thresholds the calibrated score at a common level $\\tau \\in (0,1)$ across both groups.\n\nUse only fundamental definitions of Receiver Operating Characteristic (ROC) and class-conditional decision rates to reason about the following. Assume throughout that for each group $g$ and label $y \\in \\{0,1\\}$, the class-conditional distribution of the uncalibrated logit is Gaussian with common variance: $z \\mid (Y=y,G=g) \\sim \\mathcal{N}(\\mu_{g,y}, \\sigma^{2})$ with $\\sigma>0$ known.\n\nYour tasks are:\n- Starting from the definition of the ROC curve as the set of achievable pairs $(\\operatorname{FPR}, \\operatorname{TPR})$ obtained by varying the decision threshold, argue from first principles whether, for any fixed group $g$, replacing $z$ by $z/T_{g}$ and then mapping to $s=\\sigma(z/T_{g})$ changes the ROC curve for that group. Justify your conclusion using the monotonicity properties of the transformations involved.\n- For a fixed global score threshold $\\tau \\in (0,1)$, derive closed-form expressions for the true positive rate $\\operatorname{TPR}_{g}(\\tau,T_{g})$ and false positive rate $\\operatorname{FPR}_{g}(\\tau,T_{g})$ in terms of the standard normal cumulative distribution function $\\Phi$ and the parameters $(\\mu_{g,1},\\mu_{g,0},\\sigma,T_{g},\\tau)$. Your derivation must begin from the definitions $\\operatorname{TPR}_{g} = \\mathbb{P}(s(x,g) \\ge \\tau \\mid Y=1,G=g)$ and $\\operatorname{FPR}_{g} = \\mathbb{P}(s(x,g) \\ge \\tau \\mid Y=0,G=g)$.\n- Suppose the parameters are $\\mu_{A,1} = 1.2$, $\\mu_{B,1} = 0.8$, $\\mu_{A,0} = -0.2$, $\\mu_{B,0} = -0.3$, $\\sigma = 1$, $T_{B} = 1$, and $\\tau = 0.7$. Determine the unique value $T_{A} > 0$ that equalizes the true positive rates across the two groups at the fixed threshold $\\tau$, that is, solves $\\operatorname{TPR}_{A}(\\tau,T_{A}) = \\operatorname{TPR}_{B}(\\tau,T_{B})$. Round your final numerical answer for $T_{A}$ to four significant figures.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- A binary classifier produces an uncalibrated logit output $z(x,g) \\in \\mathbb{R}$ for an instance $x$ and sensitive group $g \\in \\{A,B\\}$.\n- A calibrated score is defined as $s(x,g) = \\sigma(z(x,g)/T_{g})$, where $\\sigma(u) = \\frac{1}{1+\\exp(-u)}$ is the logistic sigmoid function.\n- $T_{g} > 0$ is a group-specific temperature parameter.\n- A global decision rule thresholds the calibrated score at a common level $\\tau \\in (0,1)$.\n- The class-conditional distribution of the logit is given as $z \\mid (Y=y,G=g) \\sim \\mathcal{N}(\\mu_{g,y}, \\sigma^{2})$, with $\\sigma>0$ known.\n- Task 1: Determine if the ROC curve for a group $g$ changes when the score is transformed from $z$ to $s=\\sigma(z/T_{g})$.\n- Task 2: Derive closed-form expressions for $\\operatorname{TPR}_{g}(\\tau,T_{g})$ and $\\operatorname{FPR}_{g}(\\tau,T_{g})$ using the definitions $\\operatorname{TPR}_{g} = \\mathbb{P}(s(x,g) \\ge \\tau \\mid Y=1,G=g)$ and $\\operatorname{FPR}_{g} = \\mathbb{P}(s(x,g) \\ge \\tau \\mid Y=0,G=g)$.\n- Task 3: Given parameters $\\mu_{A,1} = 1.2$, $\\mu_{B,1} = 0.8$, $\\mu_{A,0} = -0.2$, $\\mu_{B,0} = -0.3$, $\\sigma = 1$, $T_{B} = 1$, and $\\tau = 0.7$, find the value of $T_{A} > 0$ that solves $\\operatorname{TPR}_{A}(\\tau,T_{A}) = \\operatorname{TPR}_{B}(\\tau,T_{B})$.\n- The final numerical answer for $T_{A}$ must be rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly located in the field of statistical learning and algorithmic fairness. Temperature scaling is a standard technique for model calibration. The use of Gaussian distributions for logits is a common and valid modeling assumption. All concepts, such as ROC curves, TPR, and FPR, are standard and well-defined.\n- **Well-Posed:** The problem provides all necessary information. The questions are mathematically precise, and the structure leads to a unique solution. The existence of a unique positive $T_A$ can be verified.\n- **Objective:** The problem is stated in formal mathematical language, free from any subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem is valid as it is scientifically grounded, well-posed, objective, and complete. I will proceed with formulating the solution.\n\n### Solution\n\n**Part 1: Invariance of the ROC Curve**\n\nThe Receiver Operating Characteristic (ROC) curve is defined as the set of all achievable pairs of (False Positive Rate, True Positive Rate), or $(\\operatorname{FPR}, \\operatorname{TPR})$, generated by varying the decision threshold across the entire range of a classifier's score.\n\nFor a fixed group $g$, the original score is the logit $z$. A decision is made by comparing $z$ to a threshold $\\theta_z \\in (-\\infty, \\infty)$. The new score is $s = \\sigma(z/T_g)$. A decision is made by comparing $s$ to a threshold $\\tau_s \\in (0,1)$. We must determine if the set of $(\\operatorname{FPR}, \\operatorname{TPR})$ pairs is the same for both scoring systems.\n\nThe transformation from $z$ to $s$ is a composition of two functions: $f_1(z) = z/T_g$ and $f_2(u) = \\sigma(u)$.\n1.  Since $T_g > 0$ is a positive constant, the function $f_1(z) = z/T_g$ is a simple scaling, which is a strictly monotonically increasing function of $z$.\n2.  The logistic sigmoid function, $\\sigma(u) = \\frac{1}{1+\\exp(-u)}$, has a derivative $\\frac{d\\sigma}{du} = \\sigma(u)(1-\\sigma(u))$. Since $\\sigma(u) \\in (0,1)$ for all $u \\in \\mathbb{R}$, the derivative is strictly positive. Thus, $\\sigma(u)$ is also a strictly monotonically increasing function of $u$.\n\nThe composition of two strictly monotonically increasing functions is itself strictly monotonically increasing. Therefore, the calibrated score $s(z) = \\sigma(z/T_g)$ is a strictly monotonic function of the logit $z$.\n\nThis strict monotonicity implies a one-to-one correspondence between any decision threshold on $s$ and an equivalent decision threshold on $z$. A decision rule of the form $s \\ge \\tau_s$ is equivalent to:\n$$ \\sigma(z/T_g) \\ge \\tau_s $$\nApplying the inverse sigmoid function, $\\sigma^{-1}(v) = \\ln(\\frac{v}{1-v})$, which is also strictly increasing, to both sides preserves the inequality:\n$$ z/T_g \\ge \\sigma^{-1}(\\tau_s) $$\nSince $T_g > 0$, we can multiply by $T_g$ without changing the inequality direction:\n$$ z \\ge T_g \\sigma^{-1}(\\tau_s) $$\nLet $\\theta_z = T_g \\sigma^{-1}(\\tau_s)$. As the threshold $\\tau_s$ sweeps its full range $(0,1)$, its inverse $\\sigma^{-1}(\\tau_s)$ sweeps the range $(-\\infty, \\infty)$. Since $T_g$ is a positive constant, the equivalent threshold $\\theta_z$ also sweeps the full range $(-\\infty, \\infty)$.\n\nThis demonstrates that for any possible classification rule based on a threshold for $s$, there is an equivalent rule based on a threshold for $z$ that yields the exact same set of positive and negative predictions. Consequently, for any given $(\\operatorname{FPR}, \\operatorname{TPR})$ pair achievable with the score $s$, the same pair is achievable with the score $z$, and vice-versa.\n\nTherefore, the set of all achievable $(\\operatorname{FPR}, \\operatorname{TPR})$ pairs—the ROC curve—is identical for both scoring functions. Applying per-group temperature scaling and the sigmoid function does not change the ROC curve for that group; it only re-parameterizes the decision threshold.\n\n**Part 2: Derivation of TPR and FPR Expressions**\n\nWe derive the expressions for a specific group $g$, a fixed global threshold $\\tau$, and a temperature $T_g$.\n\nThe true positive rate is defined as $\\operatorname{TPR}_{g}(\\tau,T_{g}) = \\mathbb{P}(s(x,g) \\ge \\tau \\mid Y=1,G=g)$.\nSubstituting the definition of $s(x,g)$:\n$$ \\operatorname{TPR}_{g} = \\mathbb{P}\\left(\\sigma(z/T_{g}) \\ge \\tau \\mid Y=1,G=g\\right) $$\nAs established in Part 1, this inequality is equivalent to:\n$$ \\operatorname{TPR}_{g} = \\mathbb{P}\\left(z \\ge T_{g} \\sigma^{-1}(\\tau) \\mid Y=1,G=g\\right) $$\nWe are given that under the condition $(Y=1,G=g)$, the logit $z$ follows a normal distribution: $z \\sim \\mathcal{N}(\\mu_{g,1}, \\sigma^2)$. To evaluate the probability, we standardize the random variable $z$. Let $Z_{std} = \\frac{z - \\mu_{g,1}}{\\sigma}$, where $Z_{std} \\sim \\mathcal{N}(0,1)$.\nThe inequality $z \\ge T_{g} \\sigma^{-1}(\\tau)$ can be rewritten as:\n$$ z - \\mu_{g,1} \\ge T_{g} \\sigma^{-1}(\\tau) - \\mu_{g,1} $$\n$$ \\frac{z - \\mu_{g,1}}{\\sigma} \\ge \\frac{T_{g} \\sigma^{-1}(\\tau) - \\mu_{g,1}}{\\sigma} $$\nSo, $\\operatorname{TPR}_{g} = \\mathbb{P}\\left(Z_{std} \\ge \\frac{T_{g} \\sigma^{-1}(\\tau) - \\mu_{g,1}}{\\sigma}\\right)$.\nUsing the standard normal cumulative distribution function $\\Phi(v) = \\mathbb{P}(Z_{std} \\le v)$, and the symmetry property $\\mathbb{P}(Z_{std} \\ge c) = 1 - \\mathbb{P}(Z_{std}  c) = 1 - \\Phi(c)$, we get:\n$$ \\operatorname{TPR}_{g}(\\tau,T_{g}) = 1 - \\Phi\\left(\\frac{T_{g} \\sigma^{-1}(\\tau) - \\mu_{g,1}}{\\sigma}\\right) $$\nAlternatively, using the symmetry property $\\mathbb{P}(Z_{std} \\ge c) = \\mathbb{P}(Z_{std} \\le -c) = \\Phi(-c)$, we get:\n$$ \\operatorname{TPR}_{g}(\\tau,T_{g}) = \\Phi\\left(-\\frac{T_{g} \\sigma^{-1}(\\tau) - \\mu_{g,1}}{\\sigma}\\right) = \\Phi\\left(\\frac{\\mu_{g,1} - T_{g} \\sigma^{-1}(\\tau)}{\\sigma}\\right) $$\nThe derivation for the false positive rate is analogous. $\\operatorname{FPR}_{g}(\\tau,T_{g}) = \\mathbb{P}(s(x,g) \\ge \\tau \\mid Y=0,G=g)$.\nThe condition is now $(Y=0,G=g)$, under which $z \\sim \\mathcal{N}(\\mu_{g,0}, \\sigma^2)$.\nThe decision rule remains $z \\ge T_{g} \\sigma^{-1}(\\tau)$.\nStandardizing with respect to $\\mu_{g,0}$:\n$$ \\operatorname{FPR}_{g} = \\mathbb{P}\\left(\\frac{z - \\mu_{g,0}}{\\sigma} \\ge \\frac{T_{g} \\sigma^{-1}(\\tau) - \\mu_{g,0}}{\\sigma} \\mid Y=0,G=g\\right) $$\n$$ \\operatorname{FPR}_{g}(\\tau,T_{g}) = \\Phi\\left(\\frac{\\mu_{g,0} - T_{g} \\sigma^{-1}(\\tau)}{\\sigma}\\right) $$\n\n**Part 3: Calculation of $T_A$**\n\nWe are tasked with finding the value of $T_A  0$ such that $\\operatorname{TPR}_{A}(\\tau,T_{A}) = \\operatorname{TPR}_{B}(\\tau,T_{B})$. Using the expression for $\\operatorname{TPR}_{g}$ derived in Part 2:\n$$ \\Phi\\left(\\frac{\\mu_{A,1} - T_{A} \\sigma^{-1}(\\tau)}{\\sigma}\\right) = \\Phi\\left(\\frac{\\mu_{B,1} - T_{B} \\sigma^{-1}(\\tau)}{\\sigma}\\right) $$\nSince the standard normal CDF $\\Phi$ is a strictly increasing function, $\\Phi(a) = \\Phi(b)$ implies $a = b$. We can therefore equate the arguments of $\\Phi$:\n$$ \\frac{\\mu_{A,1} - T_{A} \\sigma^{-1}(\\tau)}{\\sigma} = \\frac{\\mu_{B,1} - T_{B} \\sigma^{-1}(\\tau)}{\\sigma} $$\nMultiplying by $\\sigma$ (since $\\sigma  0$):\n$$ \\mu_{A,1} - T_{A} \\sigma^{-1}(\\tau) = \\mu_{B,1} - T_{B} \\sigma^{-1}(\\tau) $$\nWe rearrange this equation to solve for $T_A$:\n$$ T_{A} \\sigma^{-1}(\\tau) = \\mu_{A,1} - \\mu_{B,1} + T_{B} \\sigma^{-1}(\\tau) $$\nThe term $\\sigma^{-1}(\\tau)$ is the logit function: $\\sigma^{-1}(\\tau) = \\ln\\left(\\frac{\\tau}{1-\\tau}\\right)$. For $\\tau=0.7$, this is $\\ln\\left(\\frac{0.7}{0.3}\\right) = \\ln(7/3)$, which is non-zero. Thus, we can divide by it:\n$$ T_A = \\frac{\\mu_{A,1} - \\mu_{B,1}}{\\sigma^{-1}(\\tau)} + T_B $$\nNow, we substitute the provided numerical values:\n$\\mu_{A,1} = 1.2$\n$\\mu_{B,1} = 0.8$\n$T_{B} = 1$\n$\\tau = 0.7$\n\nFirst, compute $\\sigma^{-1}(\\tau)$:\n$$ \\sigma^{-1}(0.7) = \\ln\\left(\\frac{0.7}{1-0.7}\\right) = \\ln\\left(\\frac{0.7}{0.3}\\right) = \\ln\\left(\\frac{7}{3}\\right) $$\nNow, substitute this into the expression for $T_A$:\n$$ T_A = \\frac{1.2 - 0.8}{\\ln(7/3)} + 1 $$\n$$ T_A = \\frac{0.4}{\\ln(7/3)} + 1 $$\nWe calculate the numerical value:\n$$ \\ln(7/3) \\approx 0.84729786038 $$\n$$ T_A \\approx \\frac{0.4}{0.84729786038} + 1 \\approx 0.472081015 + 1 = 1.472081015 $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ T_A \\approx 1.472 $$\nThis value is positive, consistent with the constraint $T_A  0$.",
            "answer": "$$\\boxed{1.472}$$"
        }
    ]
}