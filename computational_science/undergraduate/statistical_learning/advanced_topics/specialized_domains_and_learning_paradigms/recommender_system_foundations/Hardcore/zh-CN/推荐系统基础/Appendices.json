{
    "hands_on_practices": [
        {
            "introduction": "矩阵分解是现代推荐系统的基石，它通过学习用户和物品的隐向量来预测用户偏好。然而，一个简单的模型常常会放大“流行度偏见”，倾向于推荐已经很受欢迎的物品，从而损害了推荐的多样性和新颖性。这个实践练习将指导你构建一个矩阵分解模型，并通过对损失函数中的样本进行重新加权，来直接应对和缓解流行度偏见，同时衡量其对准确率和多样性的影响 。",
            "id": "3167503",
            "problem": "构建一个程序，该程序实现一个简单的经验风险最小化框架，用于处理带和不带项目流行度重加权的隐式反馈推荐，然后衡量 top-$K$ 准确率和推荐多样性的变化。设置如下。\n\n从以下基本基础开始：使用逐点逻辑损失、二元标签和线性预测器的经验风险最小化。给定一组用户、项目和一个二元训练交互集，通过最小化加权逻辑损失和二次正则化来学习用户和项目的潜在向量。对于一个标签为 $y_{ui} \\in \\{0,1\\}$、分数为 $x_{ui} = \\mathbf{p}_u^\\top \\mathbf{q}_i$ 的用户-项目对，逻辑损失为 $\\ell(y,x) = \\log(1 + \\exp(-(2y-1)x))$。在本问题中，使用等价的分离形式：\n$$\n\\ell_+(x) = \\log(1 + \\exp(-x)), \\quad \\ell_-(x) = \\log(1 + \\exp(x)).\n$$\n设训练集为一组正样本对 $\\mathcal{P} \\subseteq \\mathcal{U} \\times \\mathcal{I}$，并将每个用户 $u$ 的负样本集定义为该用户训练正样本中不存在且不等于该用户留出测试项的所有项目。将训练数据中的项目流行度定义为 $\\text{pop}(i) = \\sum_{(u,i)\\in \\mathcal{P}} 1$。\n\n训练两个模型，它们共享相同的结构（用户和项目嵌入以及相同的优化器），但应用于每个项目 $i$ 的正样本权重 $w_i$ 不同：\n- 未加权基线：对于所有 $\\text{pop}(i) > 0$ 的项目，$w_i = 1$。\n- 重加权：对于 $\\text{pop}(i) > 0$ 的项目，$w_i \\propto \\frac{1}{\\sqrt{\\text{pop}(i)}}$，并进行归一化，使得 $\\{w_i: \\text{pop}(i) > 0\\}$ 的平均值为 $1$。\n\n使用以下带正则化的经验风险：\n$$\n\\mathcal{L}(\\{\\mathbf{p}_u\\}, \\{\\mathbf{q}_i\\}) = \\sum_{(u,i)\\in \\mathcal{P}} w_i \\,\\ell_+(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\;+\\; \\sum_{u \\in \\mathcal{U}} \\sum_{j \\in \\mathcal{N}(u)} c_0 \\,\\ell_-(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\;+\\; \\frac{\\lambda}{2} \\left(\\sum_{u \\in \\mathcal{U}} \\|\\mathbf{p}_u\\|_2^2 + \\sum_{i \\in \\mathcal{I}} \\|\\mathbf{q}_i\\|_2^2\\right),\n$$\n其中 $\\mathcal{N}(u)$ 是用户 $u$ 的负样本集，$c_0$ 是一个恒定的负样本权重，$\\lambda$ 是正则化强度。\n\n使用固定的学习率，通过全批量梯度下降法对损失进行固定次数的迭代优化。使用相同的伪随机种子初始化所有潜在向量，以确保两个模型的确定性。\n\n训练完每个模型后，通过按预测分数 $x_{ui}$ 对所有候选项目（不在该用户训练正样本中的项目）进行排序，为每个用户计算 top-$K$ 推荐。将 top-$K$ 准确率定义为在 $K$ 处的平均命中率：对于每个用户，如果其留出的项目在 top-$K$ 列表中，则命中指示符为 $1$，否则为 $0$；准确率是这些指示符在所有用户中的平均值。将推荐多样性定义为一减去所有推荐列表中项目频率的基尼系数：\n- 设 $f_i$ 为项目 $i$ 在所有用户的 top-$K$ 列表中出现的次数。\n- 基尼系数为\n$$\nG = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |f_i - f_j|}{2 n \\sum_{i=1}^{n} f_i},\n$$\n其中 $n$ 是项目数量。将多样性定义为 $D = 1 - G$。较大的 $D$ 表示推荐在项目间的分布更均匀。\n\n您的程序必须在一个固定的测试套件上计算重加权模型和未加权模型在两种度量指标上的差异。对于每个测试用例，输出一对 $[\\Delta \\text{Acc}, \\Delta D]$，其中 $\\Delta \\text{Acc} = \\text{Acc}_{\\text{reweighted}} - \\text{Acc}_{\\text{unweighted}}$ 且 $\\Delta D = D_{\\text{reweighted}} - D_{\\text{unweighted}}$。\n\n训练和评估协议及超参数：\n- 使用潜在维度 $d = 3$。\n- 使用学习率 $\\eta = 0.02$。\n- 使用全批量迭代次数 $T = 300$。\n- 使用负样本权重 $c_0 = 0.05$。\n- 使用正则化 $\\lambda = 0.01$。\n- 对所有测试用例使用 top-$K$ 且 $K = 2$。\n- 使用 sigmoid 函数 $\\sigma(x) = \\frac{1}{1 + e^{-x}}$。\n- 对于负样本，对于每个用户 $u$，将 $\\mathcal{N}(u)$ 定义为该用户训练正样本中不存在且不等于该用户留出项的所有项目。\n- 所有潜在向量从均值为 $0$、标准差为 $0.01$ 的正态分布中初始化，伪随机种子固定为 $0$。\n\n测试套件：\n提供恰好三个测试用例，每个用例由一组训练交互和每个用户一个留出的正样本指定。在每个用例中，程序应根据给定数据构建用户-项目基数。\n\n- 用例 $1$ (流行度偏斜; $|\\mathcal{U}| = 4$, $|\\mathcal{I}| = 6$):\n  - 训练正样本 $\\mathcal{P}$:\n    - 用户 $0$: 项目 $\\{0, 1\\}$\n    - 用户 $1$: 项目 $\\{0\\}$\n    - 用户 $2$: 项目 $\\{0\\}$\n    - 用户 $3$: 项目 $\\{0\\}$\n  - 留出项目:\n    - 用户 $0$: 项目 $2$\n    - 用户 $1$: 项目 $2$\n    - 用户 $2$: 项目 $3$\n    - 用户 $3$: 项目 $4$\n\n- 用例 $2$ (均衡流行度; $|\\mathcal{U}| = 4$, $|\\mathcal{I}| = 6$):\n  - 训练正样本 $\\mathcal{P}$:\n    - 用户 $0$: 项目 $\\{0\\}$\n    - 用户 $1$: 项目 $\\{1\\}$\n    - 用户 $2$: 项目 $\\{2\\}$\n    - 用户 $3$: 项目 $\\{3\\}$\n  - 留出项目:\n    - 用户 $0$: 项目 $1$\n    - 用户 $1$: 项目 $2$\n    - 用户 $2$: 项目 $3$\n    - 用户 $3$: 项目 $4$\n\n- 用例 $3$ (极端偏斜带一些尾部信号; $|\\mathcal{U}| = 5$, $|\\mathcal{I}| = 7$):\n  - 训练正样本 $\\mathcal{P}$:\n    - 用户 $0$: 项目 $\\{0, 1\\}$\n    - 用户 $1$: 项目 $\\{0\\}$\n    - 用户 $2$: 项目 $\\{0, 1\\}$\n    - 用户 $3$: 项目 $\\{0, 2\\}$\n    - 用户 $4$: 项目 $\\{0, 2\\}$\n  - 留出项目:\n    - 用户 $0$: 项目 $3$\n    - 用户 $1$: 项目 $2$\n    - 用户 $2$: 项目 $4$\n    - 用户 $3$: 项目 $5$\n    - 用户 $4$: 项目 $6$\n\n所需最终输出格式：\n- 您的程序应生成一行输出，其中包含结果，格式为以逗号分隔的对列表，每个测试用例一对，并用方括号括起来。每对必须是一个双元素列表 $[\\Delta \\text{Acc}, \\Delta D]$，两个值都四舍五入到 $4$ 位小数。例如：$[[0.1250,0.3500],[0.0000,0.0000],[0.0500,0.1200]]$。\n\n本问题中没有物理单位。所有角度（如有）必须以弧度解释，但此处没有出现角度。所有分数值应表示为小数。如果一个用户的候选项目少于 $K$ 个，则使用 $K' = \\min(K, \\text{候选项目数})$ 为该用户形成推荐列表。",
            "solution": "已根据既定标准对用户的问题陈述进行了仔细审查和验证。\n\n### 步骤 1：提取给定信息\n- **模型：** 带有用户-项目潜在向量的经验风险最小化。\n- **分数函数：** 用户 $u$ 和项目 $i$ 的预测分数是其潜在向量的点积：$x_{ui} = \\mathbf{p}_u^\\top \\mathbf{q}_i$。\n- **损失函数：** 带二次正则化的加权逐点逻辑损失。总损失 $\\mathcal{L}$ 由以下公式给出：\n$$\n\\mathcal{L}(\\{\\mathbf{p}_u\\}, \\{\\mathbf{q}_i\\}) = \\sum_{(u,i)\\in \\mathcal{P}} w_i \\,\\ell_+(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\;+\\; \\sum_{u \\in \\mathcal{U}} \\sum_{j \\in \\mathcal{N}(u)} c_0 \\,\\ell_-(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\;+\\; \\frac{\\lambda}{2} \\left(\\sum_{u \\in \\mathcal{U}} \\|\\mathbf{p}_u\\|_2^2 + \\sum_{i \\in \\mathcal{I}} \\|\\mathbf{q}_i\\|_2^2\\right)\n$$\n其中 $\\ell_+(x) = \\log(1 + \\exp(-x))$ 是正样本的损失，$\\ell_-(x) = \\log(1 + \\exp(x))$ 是负样本的损失。$\\mathcal{P}$ 是正训练样本对的集合。\n- **数据集：** 提供了三个测试用例，每个用例都有一组用户 $\\mathcal{U}$、项目 $\\mathcal{I}$、训练正样本 $\\mathcal{P}$，以及每个用户一个用于测试的留出正样本项。\n- **负样本：** 对每个用户 $u$，负样本项集合 $\\mathcal{N}(u)$ 包括所有不在用户 $u$ 训练集中且不是该用户留出测试项的项目。\n- **加权方案：**\n  1.  **未加权：** 对于所有在 $\\mathcal{P}$ 中至少有一次交互的项目 $i$（即 $\\text{pop}(i) > 0$），$w_i = 1$。\n  2.  **重加权：** 对于 $\\text{pop}(i) > 0$ 的项目，$w_i \\propto \\frac{1}{\\sqrt{\\text{pop}(i)}}$，其中 $\\text{pop}(i) = \\sum_{(u,i)\\in \\mathcal{P}} 1$。权重 $\\{w_i: \\text{pop}(i) > 0\\}$ 被归一化以使其平均值为 $1$。\n- **超参数：**\n  - 潜在维度：$d = 3$。\n  - 学习率：$\\eta = 0.02$。\n  - 训练迭代次数：$T = 300$。\n  - 负样本权重：$c_0 = 0.05$。\n  - 正则化强度：$\\lambda = 0.01$。\n  - 评估排名：$K = 2$。\n- **初始化：** 所有潜在向量均从正态分布 $\\mathcal{N}(0, 0.01^2)$ 中初始化，并使用固定的伪随机种子 $0$。\n- **评估指标：**\n  - **Top-$K$ 准确率：** 留出项出现在其 top-$K$ 推荐项目列表中的用户所占的比例。为用户 $u$ 进行排名的候选项目包括除用户 $u$ 训练集中的项目之外的所有项目。\n  - **推荐多样性：** $D = 1 - G$，其中 $G$ 是项目推荐频率的基尼系数。$G = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |f_i - f_j|}{2 n \\sum_{i=1}^{n} f_i}$，其中 $f_i$ 是项目 $i$ 在所有用户的 top-$K$ 列表中出现的次数，$n=|\\mathcal{I}|$。\n- **任务：** 对于每个测试用例，计算 $\\Delta \\text{Acc} = \\text{Acc}_{\\text{reweighted}} - \\text{Acc}_{\\text{unweighted}}$ 和 $\\Delta D = D_{\\text{reweighted}} - D_{\\text{unweighted}}$ 的差异。\n- **输出格式：** 一个对的列表 `[[d_acc1, d_div1], [d_acc2, d_div2], ...]`，其值四舍五入到 4 位小数。\n\n### 步骤 2：使用提取的给定信息进行验证\n- **科学基础：** 该问题牢固地植根于统计学习和推荐系统的原理。它采用了标准的经验风险最小化（ERM）框架、逻辑损失、L2 正则化和梯度下降。通过重加权以减轻流行度偏差的概念是一种成熟的技术。评估指标是该领域的标准指标。\n- **适定性：** 该问题是完全指定的。所有需要的数据、参数和步骤都得到了明确的定义。确定性的初始化确保了唯一的训练轨迹和单一、可验证的解决方案。\n- **客观性：** 问题陈述是客观的，没有主观论断。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。它自成体系、科学合理且适定。将构建一个解决方案。\n\n### 基于原则的设计\n解决方案通过实现指定的 ERM 框架来推进。对于每个测试用例，我们将训练两个模型——一个未加权模型和一个重加权模型——然后计算它们在指定指标上的性能差异。\n\n**模型与优化**\n目标函数 $\\mathcal{L}$ 对于潜在向量 $\\mathbf{p}_u$ 和 $\\mathbf{q}_i$ 是可微的。我们使用全批量梯度下降来最小化这个损失。梯度是使用链式法则推导出来的。设 $\\sigma(x) = (1 + e^{-x})^{-1}$ 为 sigmoid 函数。损失分量的导数为 $\\frac{d}{dx}\\ell_+(x) = \\sigma(x) - 1$ 和 $\\frac{d}{dx}\\ell_-(x) = \\sigma(x)$。\n\n总损失 $\\mathcal{L}$ 对用户向量 $\\mathbf{p}_u$ 和项目向量 $\\mathbf{q}_i$ 的梯度为：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{p}_u} = \\sum_{i \\in \\text{Pos}(u)} w_i (\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) - 1) \\mathbf{q}_i + c_0 \\sum_{j \\in \\mathcal{N}(u)} \\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\mathbf{q}_j + \\lambda \\mathbf{p}_u\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{q}_i} = \\sum_{u | (u,i) \\in \\mathcal{P}} w_i (\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) - 1) \\mathbf{p}_u + c_0 \\sum_{u | i \\in \\mathcal{N}(u)} \\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\mathbf{p}_u + \\lambda \\mathbf{q}_i\n$$\n其中 $\\text{Pos}(u)$ 是用户 $u$ 在训练集 $\\mathcal{P}$ 中交互过的项目集合。\n\n为了计算效率，这些梯度以向量化的方式计算。我们构建一个大小为 $|\\mathcal{U}| \\times |\\mathcal{I}|$ 的误差矩阵 $E$，其中每个条目 $E_{ui}$ 代表对 $(u,i)$ 的误差信号。总误差是正样本和负样本误差的总和：\n$$\nE = (W_{\\text{pos}} \\odot (\\Sigma - 1)) + c_0 (M_{\\text{neg}} \\odot \\Sigma)\n$$\n这里，$\\odot$ 表示逐元素乘积，$\\Sigma$ 是 sigmoid 转换后分数的矩阵 $\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i)$，$W_{\\text{pos}}$ 是一个矩阵，其中如果 $(u,i) \\in \\mathcal{P}$ 则 $(W_{\\text{pos}})_{ui} = w_i$，否则为 $0$，$M_{\\text{neg}}$ 是一个指示负样本对的二元矩阵。\n潜在因子矩阵 $P$ 和 $Q$ 的全批量梯度更新则为：\n$$\n\\nabla_P \\mathcal{L} = E Q + \\lambda P \\quad \\implies \\quad P \\leftarrow P - \\eta \\nabla_P \\mathcal{L}\n$$\n$$\n\\nabla_Q \\mathcal{L} = E^\\top P + \\lambda Q \\quad \\implies \\quad Q \\leftarrow Q - \\eta \\nabla_Q \\mathcal{L}\n$$\n这个过程重复 $T=300$ 次迭代。为确保公平比较，对于给定的测试用例，未加权模型和重加权模型都从完全相同的初始潜在向量开始，这些向量是使用指定的随机种子生成的。\n\n**权重计算**\n对于重加权模型，项目权重是根据它们在训练集中的流行度 $\\text{pop}(i)$ 计算的。设 $\\mathcal{I}_{\\text{pop}} = \\{i \\in \\mathcal{I} | \\text{pop}(i) > 0\\}$。项目 $i \\in \\mathcal{I}_{\\text{pop}}$ 的原始权重是 $w'_i = 1/\\sqrt{\\text{pop}(i)}$。然后对这些权重进行归一化，以确保它们的均值为 $1$：\n$$\nw_i = \\frac{w'_i}{\\frac{1}{|\\mathcal{I}_{\\text{pop}}|} \\sum_{j \\in \\mathcal{I}_{\\text{pop}}} w'_j}\n$$\n这个方案降低了流行项目的权重，提高了小众项目的权重，目标是在不过度损害准确性的情况下提高推荐多样性。对于未加权的基线模型，所有 $i \\in \\mathcal{I}_{\\text{pop}}$ 的 $w_i=1$。\n\n**评估**\n训练后，对每个模型进行评估。对于每个用户，我们计算所有候选项目（不在他们训练集中的项目）的分数。对候选项目进行排序，前 $K=2$ 个项目构成推荐列表。\n- **准确率：** 我们通过检查用户的留出测试项是否出现在他们的推荐列表中来计算命中率，并在所有用户中取平均值。\n- **多样性：** 我们首先计算每个项目在所有生成的推荐列表中的频率 $f_i$。然后根据这些频率计算基尼系数 $G$，多样性报告为 $D = 1-G$。较高的 $D$ 值表示推荐在项目目录中分布得更均匀。\n\n最终输出是重加权模型和未加权模型在这些指标上的差异。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    # Define hyperparameters from the problem statement.\n    D_LATENT = 3\n    LEARNING_RATE = 0.02\n    ITERATIONS = 300\n    C0_NEGATIVE_WEIGHT = 0.05\n    LAMBDA_REG = 0.01\n    K_TOP = 2\n    RANDOM_SEED = 0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Popularity skew\n        (4, 6, {0: [0, 1], 1: [0], 2: [0], 3: [0]}, {0: 2, 1: 2, 2: 3, 3: 4}),\n        # Case 2: Balanced popularity\n        (4, 6, {0: [0], 1: [1], 2: [2], 3: [3]}, {0: 1, 1: 2, 2: 3, 3: 4}),\n        # Case 3: Extreme skew with some tail signal\n        (5, 7, {0: [0, 1], 1: [0], 2: [0, 1], 3: [0, 2], 4: [0, 2]}, {0: 3, 1: 2, 2: 4, 3: 5, 4: 6}),\n    ]\n\n    # --- Helper Functions ---\n\n    def calculate_weights(num_items, train_pos, reweighted):\n        \"\"\"Calculates item weights for the loss function.\"\"\"\n        item_pops = np.zeros(num_items)\n        for _, items in train_pos.items():\n            for item in items:\n                item_pops[item] += 1\n                \n        active_items_mask = item_pops > 0\n        weights = np.zeros(num_items)\n\n        if not np.any(active_items_mask):\n            return weights\n\n        if not reweighted:\n            weights[active_items_mask] = 1.0\n        else:\n            raw_weights = np.zeros(num_items)\n            raw_weights[active_items_mask] = 1.0 / np.sqrt(item_pops[active_items_mask])\n            \n            avg_raw_weight = np.mean(raw_weights[active_items_mask])\n            if avg_raw_weight > 0:\n                weights[active_items_mask] = raw_weights[active_items_mask] / avg_raw_weight\n\n        return weights\n\n    def train_model(num_users, num_items, train_pos, held_out, p_init, q_init, weights):\n        \"\"\"Trains the model using full-batch gradient descent.\"\"\"\n        P = p_init.copy()\n        Q = q_init.copy()\n\n        pos_indicator = np.zeros((num_users, num_items))\n        for u, items in train_pos.items():\n            if items:\n                pos_indicator[u, items] = 1\n\n        pos_weights_matrix = np.zeros((num_users, num_items))\n        for u, items in train_pos.items():\n            if items:\n                pos_weights_matrix[u, items] = weights[items]\n\n        held_out_indicator = np.zeros((num_users, num_items))\n        if held_out:\n            held_out_users, held_out_items = zip(*held_out.items())\n            held_out_indicator[held_out_users, held_out_items] = 1\n\n        neg_indicator = 1.0 - pos_indicator - held_out_indicator\n\n        for _ in range(ITERATIONS):\n            scores = P @ Q.T\n            sigma_scores = sigmoid(scores)\n\n            error_pos = pos_weights_matrix * (sigma_scores - 1)\n            error_neg = C0_NEGATIVE_WEIGHT * (neg_indicator * sigma_scores)\n            total_error = error_pos + error_neg\n\n            grad_P = total_error @ Q + LAMBDA_REG * P\n            grad_Q = total_error.T @ P + LAMBDA_REG * Q\n\n            P -= LEARNING_RATE * grad_P\n            Q -= LEARNING_RATE * grad_Q\n\n        return P, Q\n\n    def evaluate_model(P, Q, num_users, num_items, train_pos, held_out):\n        \"\"\"Evaluates the model on top-K accuracy and recommendation diversity.\"\"\"\n        scores = P @ Q.T\n        hits = 0\n        all_recommendations = []\n        \n        for u in range(num_users):\n            training_items = set(train_pos.get(u, []))\n            candidate_items = [i for i in range(num_items) if i not in training_items]\n            \n            if not candidate_items:\n                continue\n                \n            candidate_scores = scores[u, candidate_items]\n            sorted_indices = np.argsort(-candidate_scores)\n            \n            k_prime = min(K_TOP, len(candidate_items))\n            top_k_items = [candidate_items[i] for i in sorted_indices[:k_prime]]\n            \n            all_recommendations.extend(top_k_items)\n            \n            if held_out.get(u) in top_k_items:\n                hits += 1\n\n        accuracy = hits / num_users if num_users > 0 else 0.0\n\n        if not all_recommendations:\n            diversity = 0.0\n        else:\n            item_counts = np.zeros(num_items)\n            counts = collections.Counter(all_recommendations)\n            for item, count in counts.items():\n                item_counts[item] = count\n            \n            abs_diff_sum = np.sum(np.abs(item_counts[:, None] - item_counts[None, :]))\n            total_recs = np.sum(item_counts)\n            \n            if total_recs == 0:\n                gini = 0.0\n            else:\n                denominator = 2 * num_items * total_recs\n                gini = abs_diff_sum / denominator if denominator > 0 else 0.0\n            \n            diversity = 1.0 - gini\n\n        return accuracy, diversity\n\n    def solve_case(num_users, num_items, train_pos, held_out):\n        \"\"\"Executes one full test case, returning performance differences.\"\"\"\n        rng = np.random.RandomState(RANDOM_SEED)\n        p_init = rng.normal(0, 0.01, (num_users, D_LATENT))\n        q_init = rng.normal(0, 0.01, (num_items, D_LATENT))\n        \n        unweighted_w = calculate_weights(num_items, train_pos, reweighted=False)\n        p_unweighted, q_unweighted = train_model(num_users, num_items, train_pos, held_out, p_init, q_init, unweighted_w)\n        acc_unweighted, div_unweighted = evaluate_model(p_unweighted, q_unweighted, num_users, num_items, train_pos, held_out)\n\n        reweighted_w = calculate_weights(num_items, train_pos, reweighted=True)\n        p_reweighted, q_reweighted = train_model(num_users, num_items, train_pos, held_out, p_init, q_init, reweighted_w)\n        acc_reweighted, div_reweighted = evaluate_model(p_reweighted, q_reweighted, num_users, num_items, train_pos, held_out)\n        \n        return acc_reweighted - acc_unweighted, div_reweighted - div_unweighted\n    \n    # --- Main Execution Logic ---\n    results = []\n    for case in test_cases:\n        delta_acc, delta_div = solve_case(*case)\n        results.append([delta_acc, delta_div])\n\n    case_strings = [f\"[{da:.4f},{dd:.4f}]\" for da, dd in results]\n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "除了矩阵分解，基于图的算法为推荐系统提供了另一种强大的建模范式。此练习将用户与物品的交互数据看作一个二分图，并利用个性化 PageRank (PPR) 算法来计算图中节点间的“接近度”，从而生成推荐。通过亲手实现 PPR，你将深入理解图算法如何捕捉用户偏好，并探索“传送概率” $\\alpha$ 等关键参数如何平衡个性化深度与全局热门趋势 。",
            "id": "3167564",
            "problem": "给定一个用户-物品二部图，请您在该图上实现个性化PageRank，然后分析推荐物品对传送参数和个性化向量的敏感性。您必须推导您的解决方案，然后实现一个完整的、可运行的程序，该程序为预定义的测试套件输出所要求的结果。\n\n使用的基本原理：\n- 具有列随机转移矩阵 $P$ 的有限状态马尔可夫链，其状态分布通过 $x_{t+1} = P x_t$ 演化。\n- 个性化PageRank（PPR）是仿射收缩 $F(x) = \\alpha p + (1-\\alpha) P x$ 的唯一不动点 $x^\\star$，其中传送概率为 $\\alpha \\in (0,1]$，个性化分布 $p$ 的条目非负且总和为 $1$，$P$ 是列随机矩阵。\n\n图定义：\n- 有 $3$ 个用户节点和 $4$ 个物品节点。将用户标记为 $U_1, U_2, U_3$，物品标记为 $I_1, I_2, I_3, I_4$。\n- 完整的节点顺序为 $[U_1, U_2, U_3, I_1, I_2, I_3, I_4]$，总共有 $7$ 个节点。\n- 无向边（每条代表两条方向相反的有向边）：\n  - $U_1$ 连接到 $I_1$ 和 $I_2$。\n  - $U_2$ 连接到 $I_2$ 和 $I_3$。\n  - $U_3$ 连接到 $I_1$、$I_3$ 和 $I_4$。\n- 按如下方式构建一个列随机转移矩阵 $P \\in \\mathbb{R}^{7 \\times 7}$。对于每个节点 $j$，令 $\\deg(j)$ 为其在无向图中的邻居数量。对于 $j$ 的每个邻居 $i$，设置 $P_{i j} = 1/\\deg(j)$；如果 $i$ 不是 $j$ 的邻居，则设置 $P_{i j} = 0$。这定义了二部图上的一个随机游走，即从一个节点 $j$ 均匀地移动到其一个邻居。\n\n本问题的个性化PageRank定义：\n- 给定传送（重启）参数 $\\alpha \\in (0,1]$ 和一个个性化向量 $p \\in \\mathbb{R}^7$（其条目非负且总和为1），PPR向量 $x^\\star \\in \\mathbb{R}^7$ 定义为满足以下条件的唯一不动点\n$$\nx^\\star = \\alpha p + (1-\\alpha) P x^\\star.\n$$\n- 通过对仿射映射应用幂法来数值计算 $x^\\star$，即迭代\n$$\nx^{(t+1)} = \\alpha p + (1-\\alpha) P x^{(t)}\n$$\n从任意初始分布 $x^{(0)}$ 开始，直到 $\\ell_1$-差值满足 $\\lVert x^{(t+1)} - x^{(t)} \\rVert_1 \\le \\varepsilon$，或达到最大迭代次数。使用容差 $\\varepsilon = 10^{-12}$ 和足够大的最大迭代次数。对于特殊情况 $\\alpha = 1$，精确定义 $x^\\star = p$。\n- 物品的推荐分数由 $x^\\star$ 中对应于指定节点顺序中物品索引 $I_1, I_2, I_3, I_4$ 的分量给出。\n\n平局处理和排名：\n- 对于任何物品分数列表，按分数降序对物品进行排名。如果出现平局，使用升序的物品索引来打破平局。如果两个分数的绝对差小于或等于 $10^{-12}$，则认为它们是平局。\n\n使用的个性化向量：\n- 令 $e_j \\in \\mathbb{R}^7$ 表示标准基向量，在位置 $j$ 处为 $1$，其他位置为 $0$，节点顺序如上。\n- 情况A（单用户个性化）：$p^{(A)} = e_1$（所有权重集中在 $U_1$ 上）。\n- 情况B（双用户个性化）：$p^{(B)} = \\frac{1}{2} e_2 + \\frac{1}{2} e_3$（在 $U_2$ 和 $U_3$ 之间均匀分配权重）。\n\n测试套件：\n- 所有角度均不适用。不涉及物理单位。所有概率和距离必须表示为小数。\n- 使用以下 $5$ 个测试用例。对于每个测试用例，计算指定的输出。\n  1. 在 $\\alpha = 0.15$ 和 $p = p^{(A)}$ 条件下，计算排名前2的物品。将排名前2的物品标识符列表作为来自 $\\{1,2,3,4\\}$ 的整数列表输出，对应于 $[I_1,I_2,I_3,I_4]$。\n  2. 在 $\\alpha = 0.85$ 和 $p = p^{(A)}$ 条件下，计算排名前2的物品。如上输出列表。\n  3. 在 $\\alpha = 1.00$ 和 $p = p^{(A)}$ 条件下，计算排名前2的物品。如上输出列表。\n  4. 在 $\\alpha = 0.15$ 和 $p = p^{(B)}$ 条件下，计算排名前2的物品。如上输出列表。\n  5. 对于固定的个性化 $p = p^{(A)}$，对传送参数的敏感性：计算在 $\\alpha = 0.15$ 和 $\\alpha = 0.85$ 条件下物品分数子向量之间的 $\\ell_1$-距离。将此距离输出为一个小数，精确到小数点后 $6$ 位。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序完全如下：测试用例1到4的四个排名前2物品列表，后跟测试用例5的单个小数值。\n- 该列表不得包含任何空白字符。例如，一个语法上有效的输出看起来像 $[[1,2],[1,3],[2,4],[3,1],0.123456]$。您的程序必须严格遵守此格式。",
            "solution": "用户的要求是在一个指定的用户-物品二部图上实现并分析个性化PageRank（PPR）算法。分析内容包括计算顶部物品推荐，并检验这些推荐对算法参数（特别是传送概率 $\\alpha$ 和个性化向量 $p$）的敏感性。\n\n### 1. 数学和算法框架\n\n解决方案的基础在于有限状态马尔可夫链和不动点迭代理论。\n\n#### 1.1. 图表示与转移矩阵\n问题定义了一个包含 $N=7$ 个节点的二部图，包括 $3$ 个用户 ($U_1, U_2, U_3$) 和 $4$ 个物品 ($I_1, I_2, I_3, I_4$)。指定的节点顺序为 $[U_1, U_2, U_3, I_1, I_2, I_3, I_4]$，对应于索引 $0$ 到 $6$。\n\n边是：\n- $U_1 \\leftrightarrow \\{I_1, I_2\\}$\n- $U_2 \\leftrightarrow \\{I_2, I_3\\}$\n- $U_3 \\leftrightarrow \\{I_1, I_3, I_4\\}$\n\n每个节点 $j$ 的度 $\\deg(j)$ 是其邻居的数量：\n- $\\deg(U_1) = 2$\n- $\\deg(U_2) = 2$\n- $\\deg(U_3) = 3$\n- $\\deg(I_1) = 2$（连接到 $U_1, U_3$）\n- $\\deg(I_2) = 2$（连接到 $U_1, U_2$）\n- $\\deg(I_3) = 2$（连接到 $U_2, U_3$）\n- $\\deg(I_4) = 1$（连接到 $U_3$）\n\n为该图上的随机游走构建一个列随机转移矩阵 $P \\in \\mathbb{R}^{7 \\times 7}$。条目 $P_{ij}$ 表示从节点 $j$ 转移到节点 $i$ 的概率。对于 $i$ 和 $j$ 之间的无向边，此概率为 $P_{ij} = 1/\\deg(j)$。所有其他条目均为 $0$。得到的矩阵是：\n$$\nP = \\begin{pmatrix}\n0  0  0  1/2  1/2  0  0 \\\\\n0  0  0  0  1/2  1/2  0 \\\\\n0  0  0  1/2  0  1/2  1 \\\\\n1/2  0  1/3  0  0  0  0 \\\\\n1/2  1/2  0  0  0  0  0 \\\\\n0  1/2  1/3  0  0  0  0 \\\\\n0  0  1/3  0  0  0  0\n\\end{pmatrix}\n$$\n每列之和为 $1$，符合列随机矩阵的要求。\n\n#### 1.2. 个性化PageRank（PPR）\nPPR向量 $x^\\star \\in \\mathbb{R}^7$ 是一个修正后随机游走的平稳分布。它是不动点方程的唯一解：\n$$\nx^\\star = \\alpha p + (1-\\alpha) P x^\\star\n$$\n其中 $\\alpha \\in (0,1]$ 是传送概率，$p$ 是个性化向量（节点上的概率分布）。项 $\\alpha p$ 代表“传送”或“重启”动作，游走会跳转到由 $p$ 定义的节点分布。项 $(1-\\alpha) P x^\\star$ 代表一个标准的随机游走步骤。\n\n对于 $\\alpha \\in (0,1)$，映射 $F(x) = \\alpha p + (1-\\alpha) P x$ 是一个压缩映射。根据Banach不动点定理，存在唯一的不动点 $x^\\star$，并且可以通过从任意初始分布 $x^{(0)}$ 开始迭代 $x^{(t+1)} = F(x^{(t)})$ 来找到它。迭代持续进行，直到连续向量之间的变化足够小，具体来说，直到差值的 $\\ell_1$-范数低于容差 $\\varepsilon = 10^{-12}$：\n$$\n\\lVert x^{(t+1)} - x^{(t)} \\rVert_1 = \\sum_{i=0}^{N-1} |x^{(t+1)}_i - x^{(t)}_i| \\le \\varepsilon\n$$\n对于边界情况 $\\alpha = 1$，方程简化为 $x^\\star = 1 \\cdot p + (0) \\cdot P x^\\star = p$。\n\n#### 1.3. 推荐与排名\n计算出的PPR向量 $x^\\star$ 中对应于物品节点（索引 $3, 4, 5, 6$）的分量作为推荐分数。物品按其分数降序排名。规定了特定的平局处理规则：如果两个物品分数的绝对差小于或等于容差 $\\varepsilon = 10^{-12}$，则认为这两个物品平局，并通过按物品标识符升序排列来解决平局（例如，$I_1$ 在 $I_2$ 之前）。\n\n### 2. 测试用例的执行\n\n所提供的测试套件要求为不同场景计算PPR。\n\n**个性化向量：**\n- 情况A：$p^{(A)} = e_1$，其中 $e_1$ 是 $U_1$ 的标准基向量。$p^{(A)} = [1, 0, 0, 0, 0, 0, 0]^T$。\n- 情况B：$p^{(B)} = \\frac{1}{2}e_2 + \\frac{1}{2}e_3$，用于 $U_2$ 和 $U_3$。$p^{(B)} = [0, 1/2, 1/2, 0, 0, 0, 0]^T$。\n\n**测试用例1：** $(\\alpha = 0.15, p = p^{(A)})$\n通过幂法计算PPR向量 $x^\\star$。从 $x^\\star$ 的分量 $x^\\star_3, x^\\star_4, x^\\star_5, x^\\star_6$ 中提取物品 $I_1, I_2, I_3, I_4$ 的得分。然后根据指定规则对这些物品进行排名，以找到前2名。\n\n**测试用例2：** $(\\alpha = 0.85, p = p^{(A)})$\n过程与情况1相同，但 $\\alpha = 0.85$。较高的 $\\alpha$ 会增加传送回个性化节点 $U_1$ 的频率，从而将PageRank分数集中在更靠近 $U_1$ 的节点上。\n\n**测试用例3：** $(\\alpha = 1.00, p = p^{(A)})$\n此处，$x^\\star = p^{(A)} = [1, 0, 0, 0, 0, 0, 0]^T$。所有物品的得分为 $0$。它们全部平局。平局处理规则（升序物品ID）决定了排名，得到 $[I_1, I_2, I_3, I_4]$。前2名是 $I_1$ 和 $I_2$。\n\n**测试用例4：** $(\\alpha = 0.15, p = p^{(B)})$\n过程与情况1相同，但使用个性化向量 $p^{(B)}$。推荐结果将受到 $U_2$ 和 $U_3$ 邻域的影响。\n\n**测试用例5：** 敏感性分析\n该案例量化了当 $\\alpha$ 从 $0.15$ 变为 $0.85$ 时，对于 $p=p^{(A)}$ 的推荐变化。计算在情况1和情况2中获得的物品分数子向量之间的 $\\ell_1$-距离。设 $x^\\star_{(1)}$ 和 $x^\\star_{(2)}$ 为这两个情况下的PPR向量。所需的距离是：\n$$\nd = \\lVert x^\\star_{(1)}[3:7] - x^\\star_{(2)}[3:7] \\rVert_1\n$$\n结果四舍五入到小数点后恰好 $6$ 位。\n\n实现将把此逻辑封装到一个程序中，该程序系统地执行每个测试用例，并按要求将结果格式化为单个无空格的逗号分隔行。",
            "answer": "```python\nimport numpy as np\nfrom functools import cmp_to_key\n\ndef solve():\n    \"\"\"\n    Solves the Personalized PageRank problem as specified.\n    - Constructs the transition matrix.\n    - Implements the PPR power method.\n    - Implements the item ranking logic with tie-breaking.\n    - Executes the 5 test cases and formats the output.\n    \"\"\"\n\n    # 1. Define graph structure and build the transition matrix P\n    # Node ordering: [U1, U2, U3, I1, I2, I3, I4] (indices 0-6)\n    P = np.array([\n        [0,   0,   0,   1/2, 1/2, 0,   0],    # U1 receives from I1, I2\n        [0,   0,   0,   0,   1/2, 1/2, 0],    # U2 receives from I2, I3\n        [0,   0,   0,   1/2, 0,   1/2, 1],    # U3 receives from I1, I3, I4\n        [1/2, 0,   1/3, 0,   0,   0,   0],    # I1 receives from U1, U3\n        [1/2, 1/2, 0,   0,   0,   0,   0],    # I2 receives from U1, U2\n        [0,   1/2, 1/3, 0,   0,   0,   0],    # I3 receives from U2, U3\n        [0,   0,   1/3, 0,   0,   0,   0]     # I4 receives from U3\n    ], dtype=float)\n\n    def compute_ppr(alpha, p, P_matrix, epsilon=1e-12, max_iter=2000):\n        \"\"\"\n        Computes the Personalized PageRank vector using the power method.\n        \"\"\"\n        if alpha == 1.0:\n            return p.astype(float)\n        \n        N = P_matrix.shape[0]\n        # Start with a uniform distribution\n        x_curr = np.full(N, 1.0 / N, dtype=float)\n        \n        alpha_p_term = alpha * p\n        one_minus_alpha = 1.0 - alpha\n        \n        for _ in range(max_iter):\n            x_next = alpha_p_term + one_minus_alpha * (P_matrix @ x_curr)\n            \n            # Check for convergence using L1 norm\n            if np.linalg.norm(x_next - x_curr, ord=1) = epsilon:\n                return x_next\n            \n            x_curr = x_next\n            \n        return x_curr # Return last state if max_iter is reached\n\n    def rank_items(x_star, tie_tol=1e-12):\n        \"\"\"\n        Ranks items based on their scores in the PPR vector, handling ties.\n        \"\"\"\n        # Item indices in x_star are 3, 4, 5, 6\n        # Item IDs are 1, 2, 3, 4\n        item_scores_list = []\n        for i in range(4):\n            item_id = i + 1\n            score = x_star[3 + i]\n            item_scores_list.append((item_id, score))\n\n        def compare_items(item1, item2):\n            \"\"\"Custom comparison function for sorting.\"\"\"\n            id1, score1 = item1\n            id2, score2 = item2\n            \n            # Check for tie based on tolerance\n            if abs(score1 - score2) = tie_tol:\n                # Tie: sort by item ID ascending\n                return id1 - id2\n            else:\n                # No tie: sort by score descending\n                return -1 if score1 > score2 else 1\n\n        sorted_items = sorted(item_scores_list, key=cmp_to_key(compare_items))\n        \n        return [item[0] for item in sorted_items]\n\n    # 2. Define personalization vectors\n    p_A = np.array([1.0, 0, 0, 0, 0, 0, 0])\n    p_B = np.array([0, 0.5, 0.5, 0, 0, 0, 0])\n\n    # 3. Execute test cases\n    results = []\n\n    # Case 1: alpha = 0.15, p = p_A\n    alpha1 = 0.15\n    x_star1 = compute_ppr(alpha1, p_A, P)\n    ranked1 = rank_items(x_star1)\n    results.append(ranked1[:2])\n\n    # Case 2: alpha = 0.85, p = p_A\n    alpha2 = 0.85\n    x_star2 = compute_ppr(alpha2, p_A, P)\n    ranked2 = rank_items(x_star2)\n    results.append(ranked2[:2])\n\n    # Case 3: alpha = 1.00, p = p_A\n    alpha3 = 1.00\n    x_star3 = compute_ppr(alpha3, p_A, P)\n    ranked3 = rank_items(x_star3)\n    results.append(ranked3[:2])\n\n    # Case 4: alpha = 0.15, p = p_B\n    x_star4 = compute_ppr(alpha1, p_B, P)\n    ranked4 = rank_items(x_star4)\n    results.append(ranked4[:2])\n\n    # Case 5: Sensitivity L1 distance\n    item_scores1 = x_star1[3:7]\n    item_scores2 = x_star2[3:7]\n    distance = np.linalg.norm(item_scores1 - item_scores2, ord=1)\n    # Format to exactly 6 decimal places, including trailing zeros\n    results.append(f\"{distance:.6f}\")\n\n    # 4. Format and print the final output string\n    formatted_parts = []\n    for res in results:\n        if isinstance(res, list):\n            formatted_parts.append(f\"[{','.join(map(str, res))}]\")\n        else:\n            formatted_parts.append(str(res))\n    \n    print(f\"[{','.join(formatted_parts)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个完整的推荐系统不仅包含预测模型，还必须在最终输出阶段满足各种现实世界的业务约束，例如公平性或内容多样性。这个问题模拟了一个常见的“重排序”场景，你需要在保证推荐列表总相关性最大的同时，遵守对不同内容提供商的物品数量限制。这个练习将教会你如何将一个实际的系统需求转化为一个约束优化问题，并找到其最优解，让你体会到在追求相关性的同时如何平衡其他重要目标 。",
            "id": "3167527",
            "problem": "一个内容平台执行第二阶段重排序，从一个带有估计相关性分数的候选集中形成一个大小为 $K$ 的列表。为满足提供商公平性约束，平台对每个提供商组别在列表中可出现的项目数量施加了组别上限。给定 $9$ 个候选项目，它们被划分为三个提供商组别，并附有其估计的相关性分数 $r_i$：\n- 组 $\\mathcal{A}$：项目 $1,2,3$，分数 $r_1=9$，$r_2=8.2$，$r_3=6.1$。\n- 组 $\\mathcal{B}$：项目 $4,5,6$，分数 $r_4=7.5$，$r_5=7.4$，$r_6=4$。\n- 组 $\\mathcal{C}$：项目 $7,8,9$，分数 $r_7=5.9$，$r_8=5.2$，$r_9=3.5$。\n\n平台通过求解以下二元优化问题来选择一个最多包含 $K=4$ 个项目的列表\n$$\n\\max_{\\{x_i\\}_{i=1}^{9}} \\sum_{i=1}^{9} r_i x_i\n\\quad\\text{subject to}\\quad\n\\sum_{i=1}^{9} x_i \\le K,\\quad\n\\sum_{i \\in \\mathcal{G}_j} x_i \\le c_j \\ \\ \\forall j \\in \\{\\mathcal{A},\\mathcal{B},\\mathcal{C}\\},\\quad\nx_i \\in \\{0,1\\},\n$$\n其中 $\\mathcal{G}_{\\mathcal{A}}=\\{1,2,3\\}$，$\\mathcal{G}_{\\mathcal{B}}=\\{4,5,6\\}$，$\\mathcal{G}_{\\mathcal{C}}=\\{7,8,9\\}$，且组别上限为 $c_{\\mathcal{A}}=2$，$c_{\\mathcal{B}}=1$，$c_{\\mathcal{C}}=2$。\n\n仅使用二元决策优化和 $0$–$1$ 背包框架的基本定义，推导出一个等价的组合公式，该公式将组别上限的影响体现为类似容量的约束，并计算上述优化问题可实现的最大总相关性值。仅报告最优目标值作为最终答案。无需四舍五入，不涉及单位。",
            "solution": "用户提供了一个二元优化问题，并要求求解其最优目标值。\n\n### 步骤1：提取已知条件\n问题提供了以下数据：\n- 一组 $9$ 个候选项目，索引为 $i=1, \\dots, 9$。\n- 列表大小限制 $K=4$。\n- 项目被划分为三个提供商组别：\n  - 组 $\\mathcal{A}$：项目 $\\mathcal{G}_{\\mathcal{A}}=\\{1,2,3\\}$，相关性分数 $r_1=9$，$r_2=8.2$，$r_3=6.1$。\n  - 组 $\\mathcal{B}$：项目 $\\mathcal{G}_{\\mathcal{B}}=\\{4,5,6\\}$，相关性分数 $r_4=7.5$，$r_5=7.4$，$r_6=4$。\n  - 组 $\\mathcal{C}$：项目 $\\mathcal{G}_{\\mathcal{C}}=\\{7,8,9\\}$，相关性分数 $r_7=5.9$，$r_8=5.2$，$r_9=3.5$。\n- 组别上限（每个组别允许的最大项目数）：\n  - $c_{\\mathcal{A}}=2$\n  - $c_{\\mathcal{B}}=1$\n  - $c_{\\mathcal{C}}=2$\n- 优化问题的公式为：\n$$\n\\max_{\\{x_i\\}_{i=1}^{9}} \\sum_{i=1}^{9} r_i x_i\n$$\n约束条件如下：\n1. $\\sum_{i=1}^{9} x_i \\le K$ (项目总数约束)\n2. $\\sum_{i \\in \\mathcal{G}_j} x_i \\le c_j \\ \\ \\forall j \\in \\{\\mathcal{A},\\mathcal{B},\\mathcal{C}\\}$ (组别上限约束)\n3. $x_i \\in \\{0,1\\}$ (二元决策变量)\n\n### 步骤2：使用提取的已知条件进行验证\n根据指定标准对问题进行验证。\n- **科学性**：该问题是运筹学和计算机科学中一个成熟的公式，称为整数线性规划，特别是 $0$-$1$ 背包问题的一个变体（广义分配问题或多维多重选择背包问题）。它是资源分配的标准模型，具有科学合理性。\n- **适定性**：该问题是适定的。可行解的集合是有限的（$2^9$ 种可能性的一个子集），确保存在最大值。数据和约束条件定义明确，可以得出一个唯一的最优目标值。\n- **客观性**：问题陈述完全客观，使用精确的数学定义和数值，没有任何主观或模糊的语言。\n- **完整性和一致性**：所有必要的数据（$r_i$, $K$, $c_j$ 和组别定义）均已提供。约束条件之间没有矛盾。例如，组别上限之和（$2+1+2=5$）大于总列表大小 $K=4$，这是一个非平凡的条件。\n- **未检测到其他缺陷。** 问题结构严谨，可以求解。\n\n### 步骤3：结论与行动\n问题有效。将提供完整的解答。\n\n### 解题推导\n问题是要选择一个项目子集，使得在满足总基数约束和各组基数约束的条件下，总相关性最大化。题目要求基于 $0$-$1$ 背包框架推导一个等价的组合公式。这可以通过将问题重新表述为多重选择背包问题（MCKP）来实现。\n\n核心思想是，对于每个组 $\\mathcal{G}_j$，如果我们决定选择恰好 $k$ 个项目（其中 $0 \\le k \\le c_j$），最优选择总是选择该组内相关性分数最高的 $k$ 个项目。任何其他 $k$ 个项目的选择都会产生较小的总相关性，因此是次优的。\n\n这使我们能够为每个组别预先计算项目的“捆绑包”。每个捆绑包对应于从该组别中选择 $k$ 个项目的选择。捆绑包的特征是其“成本”（项目数量，$k$）和其“价值”（前 $k$ 个项目相关性之和）。\n\n设 $V_{j,k}$ 为从组 $j$ 中选出大小为 $k$ 的最优捆绑包的价值， $W_{j,k}$ 为其成本。成本就是 $W_{j,k}=k$。\n\n**组 $\\mathcal{A}$**：项目 $\\{1,2,3\\}$，分数 $\\{9, 8.2, 6.1\\}$，上限 $c_{\\mathcal{A}}=2$。\n按相关性排序的项目是项目 $1$ ($r_1=9$)，项目 $2$ ($r_2=8.2$)，和项目 $3$ ($r_3=6.1$)。\n- 捆绑包 $\\mathcal{A}_0$（选择 $k=0$ 个项目）：价值 $V_{\\mathcal{A},0}=0$，成本 $W_{\\mathcal{A},0}=0$。\n- 捆绑包 $\\mathcal{A}_1$（选择 $k=1$ 个项目）：选择项目 $1$。价值 $V_{\\mathcal{A},1}=9$，成本 $W_{\\mathcal{A},1}=1$。\n- 捆绑包 $\\mathcal{A}_2$（选择 $k=2$ 个项目）：选择项目 $1,2$。价值 $V_{\\mathcal{A},2}=r_1+r_2=9+8.2=17.2$，成本 $W_{\\mathcal{A},2}=2$。\n\n**组 $\\mathcal{B}$**：项目 $\\{4,5,6\\}$，分数 $\\{7.5, 7.4, 4\\}$，上限 $c_{\\mathcal{B}}=1$。\n按相关性排序的项目是项目 $4$ ($r_4=7.5$)，项目 $5$ ($r_5=7.4$)，和项目 $6$ ($r_6=4$)。\n- 捆绑包 $\\mathcal{B}_0$（选择 $k=0$ 个项目）：价值 $V_{\\mathcal{B},0}=0$，成本 $W_{\\mathcal{B},0}=0$。\n- 捆绑包 $\\mathcal{B}_1$（选择 $k=1$ 个项目）：选择项目 $4$。价值 $V_{\\mathcal{B},1}=7.5$，成本 $W_{\\mathcal{B},1}=1$。\n\n**组 $\\mathcal{C}$**：项目 $\\{7,8,9\\}$，分数 $\\{5.9, 5.2, 3.5\\}$，上限 $c_{\\mathcal{C}}=2$。\n按相关性排序的项目是项目 $7$ ($r_7=5.9$)，项目 $8$ ($r_8=5.2$)，和项目 $9$ ($r_9=3.5$)。\n- 捆绑包 $\\mathcal{C}_0$（选择 $k=0$ 个项目）：价值 $V_{\\mathcal{C},0}=0$，成本 $W_{\\mathcal{C},0}=0$。\n- 捆绑包 $\\mathcal{C}_1$（选择 $k=1$ 个项目）：选择项目 $7$。价值 $V_{\\mathcal{C},1}=5.9$，成本 $W_{\\mathcal{C},1}=1$。\n- 捆绑包 $\\mathcal{C}_2$（选择 $k=2$ 个项目）：选择项目 $7,8$。价值 $V_{\\mathcal{C},2}=r_7+r_8=5.9+5.2=11.1$，成本 $W_{\\mathcal{C},2}=2$。\n\n原问题现在等价于从每个组中恰好选择一个捆绑包，使得成本之和（项目总数）不超过背包容量 $K=4$，并且价值之和最大化。设 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ 是一个三元组，分别代表从组 $\\mathcal{A}$、$\\mathcal{B}$ 和 $\\mathcal{C}$ 中选择的项目数量。我们必须满足 $k_{\\mathcal{A}} \\le c_{\\mathcal{A}}$，$k_{\\mathcal{B}} \\le c_{\\mathcal{B}}$，$k_{\\mathcal{C}} \\le c_{\\mathcal{C}}$，以及项目总数约束 $k_{\\mathcal{A}} + k_{\\mathcal{B}} + k_{\\mathcal{C}} \\le K=4$。\n\n我们需要求解：\n$$\n\\max_{k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}} \\left( V_{\\mathcal{A},k_{\\mathcal{A}}} + V_{\\mathcal{B},k_{\\mathcal{B}}} + V_{\\mathcal{C},k_{\\mathcal{C}}} \\right)\n$$\n约束条件为：\n$$\nk_{\\mathcal{A}} \\in \\{0, 1, 2\\}, \\quad k_{\\mathcal{B}} \\in \\{0, 1\\}, \\quad k_{\\mathcal{C}} \\in \\{0, 1, 2\\}\n$$\n$$\nk_{\\mathcal{A}} + k_{\\mathcal{B}} + k_{\\mathcal{C}} \\le 4\n$$\n\n由于所有相关性分数都是正数，最优解将尽可能多地利用项目，直到达到总数限制 $K=4$。因此，我们枚举所有和为 $4$ 或更小的组合 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$，并计算其总价值。我们重点关注和为 $4$ 的组合，因为它们最有可能成为最大值的候选者。\n\n和为 $4$ 的组合 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$：\n1.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 1, 1)$：该组合有效，因为 $k_{\\mathcal{A}}=2 \\le c_{\\mathcal{A}}$，$k_{\\mathcal{B}}=1 \\le c_{\\mathcal{B}}$，且 $k_{\\mathcal{C}}=1 \\le c_{\\mathcal{C}}$。\n    总价值 = $V_{\\mathcal{A},2} + V_{\\mathcal{B},1} + V_{\\mathcal{C},1} = 17.2 + 7.5 + 5.9 = 30.6$。\n    选择的项目是 $\\mathcal{A}$ 组的 $\\{1, 2\\}$，$\\mathcal{B}$ 组的 $\\{4\\}$，以及 $\\mathcal{C}$ 组的 $\\{7\\}$。\n\n2.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 0, 2)$：该组合有效。\n    总价值 = $V_{\\mathcal{A},2} + V_{\\mathcal{B},0} + V_{\\mathcal{C},2} = 17.2 + 0 + 11.1 = 28.3$。\n\n3.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (1, 1, 2)$：该组合有效。\n    总价值 = $V_{\\mathcal{A},1} + V_{\\mathcal{B},1} + V_{\\mathcal{C},2} = 9 + 7.5 + 11.1 = 27.6$。\n\n在遵守组别上限的情况下，没有其他和为 $4$ 的 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ 组合。例如，$(1,2,1)$ 是无效的，因为 $k_{\\mathcal{B}}=2  c_{\\mathcal{B}}=1$。\n\n和小于 $4$ 的组合将具有较低的总价值。例如，和为 $3$ 的最佳组合是 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 1, 0)$，其价值为 $V_{\\mathcal{A},2} + V_{\\mathcal{B},1} + V_{\\mathcal{C},0} = 17.2 + 7.5 + 0 = 24.7$。这小于 $30.6$。\n\n比较和为 $4$ 的组合计算出的价值：\n- 组合 $(2,1,1)$ 的价值为 $30.6$。\n- 组合 $(2,0,2)$ 的价值为 $28.3$。\n- 组合 $(1,1,2)$ 的价值为 $27.6$。\n\n可实现的最大总相关性是这些价值中的最高者。\n\n最大价值 = $\\max(30.6, 28.3, 27.6) = 30.6$。\n\n这对应于从 $\\mathcal{A}$ 组选择 $2$ 个项目（项目 $1$ 和 $2$），从 $\\mathcal{B}$ 组选择 $1$ 个项目（项目 $4$），以及从 $\\mathcal{C}$ 组选择 $1$ 个项目（项目 $7$）。项目总数为 $2+1+1=4$，满足列表大小约束 $\\sum x_i \\le 4$。组别约束也得到满足。",
            "answer": "$$\n\\boxed{30.6}\n$$"
        }
    ]
}