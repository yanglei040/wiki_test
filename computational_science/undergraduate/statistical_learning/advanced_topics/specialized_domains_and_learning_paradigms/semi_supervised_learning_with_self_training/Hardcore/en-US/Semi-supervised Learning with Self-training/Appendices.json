{
    "hands_on_practices": [
        {
            "introduction": "Self-training's effectiveness hinges on the quality of the pseudo-labels it generates. While adding more data is appealing, adding noisy data can degrade model performance. This exercise provides a foundational analysis of this trade-off by guiding you to derive the expected noise rate among the pseudo-labels selected by a classifier . By expressing this noise rate in terms of the classifier's inherent error rates and the data distribution, you will gain a quantitative understanding of the factors that govern the success of a self-training procedure.",
            "id": "3172749",
            "problem": "Consider binary classification with labels $y \\in \\{0,1\\}$ and class prior $\\pi = \\Pr(y=1) \\in (0,1)$. A fixed classifier produces predictions $\\hat{y} \\in \\{0,1\\}$ with confusion rates $\\alpha = \\Pr(\\hat{y}=1 \\mid y=0)$ and $\\beta = \\Pr(\\hat{y}=0 \\mid y=1)$, and is equipped with calibrated confidence scores so that for any input $x$, the maximum predicted class probability is used as a confidence $c(x) \\in [0,1]$. In a self-training procedure, unlabeled inputs are pseudo-labeled by this classifier and added to the training set only if their confidence exceeds a fixed threshold $\\tau \\in (0.5,1)$.\n\nDefine the selection rates $s_{0}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=0)$ and $s_{1}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=1)$, and assume that, within each true class, crossing the threshold $\\tau$ is independent of whether the classifier predicts correctly, so that the confusion rates $\\alpha$ and $\\beta$ apply uniformly to the selected subset. Let $n_{L}$ denote the size of the labeled dataset and $n_{U}$ the size of the unlabeled pool. Suppose all selected unlabeled inputs are added, yielding an expected number $m = n_{U}\\big((1-\\pi)s_{0}(\\tau) + \\pi s_{1}(\\tau)\\big)$ of pseudo-labeled examples.\n\nUsing the law of total probability and the definition of empirical $0$-$1$ loss, derive an expression for the expected noise rate among the added pseudo labels at threshold $\\tau$, defined as\n$$\n\\eta(\\tau) = \\Pr\\big(\\hat{y} \\neq y \\,\\big|\\, c(X) \\ge \\tau\\big),\n$$\nin terms of $\\alpha$, $\\beta$, $\\pi$, $s_{0}(\\tau)$, and $s_{1}(\\tau)$. Then, analyze how this expected noise rate affects the empirical $0$-$1$ risk when retraining by Empirical Risk Minimization (ERM) on the augmented dataset under the simplifying assumption that the retrained classifier perfectly fits the added pseudo labels, giving the expected empirical $0$-$1$ loss on the augmented dataset as a function of $n_{L}$, the labeled empirical loss $R_{L}$, $m$, and $\\eta(\\tau)$.\n\nProvide your final answer as the closed-form analytic expression for $\\eta(\\tau)$. No rounding is required.",
            "solution": "The problem asks for two derivations. First, an expression for the expected noise rate $\\eta(\\tau)$ among the added pseudo-labels. Second, an analysis of the expected empirical $0$-$1$ loss on the augmented dataset.\n\n**Part 1: Derivation of the Expected Noise Rate $\\eta(\\tau)$**\n\nThe expected noise rate among the added pseudo-labels is defined as the probability that a pseudo-label is incorrect, conditioned on the instance being selected for pseudo-labeling. The selection criterion is that the confidence $c(X)$ exceeds a threshold $\\tau$. Formally, this is:\n$$\n\\eta(\\tau) = \\Pr\\big(\\hat{y} \\neq y \\,\\big|\\, c(X) \\ge \\tau\\big)\n$$\nWe use the definition of conditional probability:\n$$\n\\eta(\\tau) = \\frac{\\Pr(\\hat{y} \\neq y, c(X) \\ge \\tau)}{\\Pr(c(X) \\ge \\tau)}\n$$\nLet's denote the selection event as $S = \\{c(X) \\ge \\tau\\}$. The expression becomes:\n$$\n\\eta(\\tau) = \\frac{\\Pr(\\hat{y} \\neq y, S)}{\\Pr(S)}\n$$\nWe will evaluate the numerator and the denominator separately using the law of total probability, conditioning on the true class label $y \\in \\{0, 1\\}$.\n\nFirst, we compute the denominator, $\\Pr(S) = \\Pr(c(X) \\ge \\tau)$:\n$$\n\\Pr(S) = \\Pr(S \\mid y=0)\\Pr(y=0) + \\Pr(S \\mid y=1)\\Pr(y=1)\n$$\nFrom the problem statement, we are given:\n- The class prior $\\pi = \\Pr(y=1)$, which implies $\\Pr(y=0) = 1-\\pi$.\n- The class-conditional selection rates $s_{0}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=0)$ and $s_{1}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=1)$.\n\nSubstituting these givens into the expression for $\\Pr(S)$:\n$$\n\\Pr(S) = s_{0}(\\tau)(1-\\pi) + s_{1}(\\tau)\\pi\n$$\n\nNext, we compute the numerator, $\\Pr(\\hat{y} \\neq y, S)$. Again, we use the law of total probability, conditioning on the true class $y$:\n$$\n\\Pr(\\hat{y} \\neq y, S) = \\Pr(\\hat{y} \\neq y, S \\mid y=0)\\Pr(y=0) + \\Pr(\\hat{y} \\neq y, S \\mid y=1)\\Pr(y=1)\n$$\nLet's analyze each term in the sum:\n1.  For the case $y=0$, an incorrect prediction means $\\hat{y}=1$. So, the first term is $\\Pr(\\hat{y} = 1, S \\mid y=0)\\Pr(y=0)$.\n2.  For the case $y=1$, an incorrect prediction means $\\hat{y}=0$. So, the second term is $\\Pr(\\hat{y} = 0, S \\mid y=1)\\Pr(y=1)$.\n\nThe problem states a crucial independence assumption: \"within each true class, crossing the threshold $\\tau$ is independent of whether the classifier predicts correctly\".\nThis can be formalized as:\n- Given $y=0$, the event of an incorrect prediction, $\\{\\hat{y}=1\\}$, is independent of the selection event $S$.\n  $$ \\Pr(\\hat{y}=1, S \\mid y=0) = \\Pr(\\hat{y}=1 \\mid y=0) \\Pr(S \\mid y=0) $$\n- Given $y=1$, the event of an incorrect prediction, $\\{\\hat{y}=0\\}$, is independent of the selection event $S$.\n  $$ \\Pr(\\hat{y}=0, S \\mid y=1) = \\Pr(\\hat{y}=0 \\mid y=1) \\Pr(S \\mid y=1) $$\n\nWe are given the confusion rates $\\alpha = \\Pr(\\hat{y}=1 \\mid y=0)$ and $\\beta = \\Pr(\\hat{y}=0 \\mid y=1)$. Using these and the selection rates, the conditional probabilities become:\n- $\\Pr(\\hat{y}=1, S \\mid y=0) = \\alpha \\cdot s_{0}(\\tau)$\n- $\\Pr(\\hat{y}=0, S \\mid y=1) = \\beta \\cdot s_{1}(\\tau)$\n\nNow, we can write the full expression for the numerator:\n$$\n\\Pr(\\hat{y} \\neq y, S) = \\big( \\alpha \\cdot s_{0}(\\tau) \\big) (1-\\pi) + \\big( \\beta \\cdot s_{1}(\\tau) \\big) \\pi\n$$\n\nFinally, we combine the numerator and denominator to obtain the expression for $\\eta(\\tau)$:\n$$\n\\eta(\\tau) = \\frac{\\alpha s_{0}(\\tau)(1-\\pi) + \\beta s_{1}(\\tau)\\pi}{s_{0}(\\tau)(1-\\pi) + s_{1}(\\tau)\\pi}\n$$\n\n**Part 2: Analysis of the Expected Empirical Risk**\n\nThe second part of the problem asks for the expected empirical $0$-$1$ loss on the augmented dataset. The augmented dataset $D_{aug}$ consists of the original labeled set $D_L$ of size $n_L$ and the set of pseudo-labeled examples $D_{pseudo}$ of size $m$. The total size is $n_L + m$.\n\nThe empirical $0$-$1$ loss on this augmented set for a retrained classifier $h_{new}$ must be evaluated with respect to the *true* labels to quantify the effect of noise. Let $y_i$ be the true label for an instance $x_i$. The true empirical loss is:\n$$\nR_{D_{aug}}^{true}(h_{new}) = \\frac{1}{n_L + m} \\left( \\sum_{(x_i, y_i) \\in D_L} \\mathbb{I}(h_{new}(x_i) \\neq y_i) + \\sum_{(x_j, y_j) \\in D_{pseudo}} \\mathbb{I}(h_{new}(x_j) \\neq y_j) \\right)\n$$\nThe problem specifies that the retrained classifier \"perfectly fits the added pseudo labels\". This means that for any pseudo-labeled example $(x_j, \\hat{y}_j) \\in D_{pseudo}$, we have $h_{new}(x_j) = \\hat{y}_j$. Substituting this into the second sum:\n$$\nR_{D_{aug}}^{true}(h_{new}) = \\frac{1}{n_L + m} \\left( \\sum_{(x_i, y_i) \\in D_L} \\mathbb{I}(h_{new}(x_i) \\neq y_i) + \\sum_{(x_j, y_j) \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j) \\right)\n$$\nThe first sum is the total loss on the original labeled set, which is given as $n_L R_L$, where $R_L$ is the labeled empirical loss for $h_{new}$. The expression becomes:\n$$\nR_{D_{aug}}^{true}(h_{new}) = \\frac{n_L R_L + \\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j)}{n_L + m}\n$$\nWe need to find the *expected* empirical loss. The expectation is taken over the random selection of the unlabeled data.\n$$\nE[R_{D_{aug}}^{true}(h_{new})] = \\frac{1}{n_L+m} E\\left[ n_L R_L + \\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j) \\right]\n$$\nAssuming $R_L$ is a fixed outcome of the process, and using the linearity of expectation:\n$$\nE[R_{D_{aug}}^{true}(h_{new})] = \\frac{n_L R_L + E\\left[\\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j)\\right]}{n_L+m}\n$$\nThe sum is over the $m$ selected pseudo-labeled examples. For each such example, indexed by $j$, the term $\\mathbb{I}(\\hat{y}_j \\neq y_j)$ is a Bernoulli random variable. Its expectation is the probability that its pseudo-label is incorrect. By definition, this is the probability of an incorrect prediction, given that the example was selected, which is precisely $\\eta(\\tau)$.\n$$\nE[\\mathbb{I}(\\hat{y}_j \\neq y_j)] = \\Pr(\\hat{y} \\neq y \\mid c(X) \\ge \\tau) = \\eta(\\tau)\n$$\nSince this holds for each of the $m$ i.i.d. selected examples, the expectation of the sum is:\n$$\nE\\left[\\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j)\\right] = \\sum_{j=1}^{m} E[\\mathbb{I}(\\hat{y}_j \\neq y_j)] = \\sum_{j=1}^{m} \\eta(\\tau) = m \\eta(\\tau)\n$$\nSubstituting this back, the expected empirical $0$-$1$ loss on the augmented dataset is:\n$$\nE[R_{D_{aug}}^{true}(h_{new})] = \\frac{n_L R_L + m \\eta(\\tau)}{n_L + m}\n$$\nThis expression shows that the resulting effective loss is a weighted average of the loss on the original labeled data, $R_L$, and the noise rate of the pseudo-labels, $\\eta(\\tau)$.\n\nThe problem, however, only asks for the expression for $\\eta(\\tau)$ in the final answer.\n$$\n\\eta(\\tau) = \\frac{\\alpha s_0(\\tau)(1-\\pi) + \\beta s_1(\\tau)\\pi}{(1-\\pi)s_0(\\tau) + \\pi s_1(\\tau)}\n$$\nThis can also be written in a more compact form, but the current form is clear and directly derived.\nFinal check on the expression for final answer:\n$\\eta(\\tau) = \\frac{\\Pr(\\mathrm{error}, \\mathrm{selected})}{\\Pr(\\mathrm{selected})} = \\frac{\\Pr(\\mathrm{error}|y=0)\\Pr(y=0)\\Pr(\\mathrm{selected}|y=0) + \\Pr(\\mathrm{error}|y=1)\\Pr(y=1)\\Pr(\\mathrm{selected}|y=1)}{\\Pr(\\mathrm{selected}|y=0)\\Pr(y=0) + \\Pr(\\mathrm{selected}|y=1)\\Pr(y=1)}$.\nNo, this is wrong. The independence is conditional on $y$. So $\\Pr(\\mathrm{error}, \\mathrm{selected} | y=0) = \\Pr(\\mathrm{error}|y=0)\\Pr(\\mathrm{selected}|y=0)$.\n$\\Pr(\\mathrm{error}, \\mathrm{selected}) = \\Pr(\\mathrm{error}, \\mathrm{selected} | y=0) \\Pr(y=0) + \\Pr(\\mathrm{error}, \\mathrm{selected} | y=1) \\Pr(y=1) = \\Pr(\\mathrm{error} | y=0) \\Pr(\\mathrm{selected} | y=0) \\Pr(y=0) + \\Pr(\\mathrm{error} | y=1) \\Pr(\\mathrm{selected} | y=1) \\Pr(y=1)$.\n$\\Pr(\\mathrm{error}|y=0) = \\Pr(\\hat{y}=1|y=0) = \\alpha$.\n$\\Pr(\\mathrm{error}|y=1) = \\Pr(\\hat{y}=0|y=1) = \\beta$.\nSo the numerator is $\\alpha s_0(\\tau) (1-\\pi) + \\beta s_1(\\tau) \\pi$.\nThe denominator is $s_0(\\tau)(1-\\pi) + s_1(\\tau)\\pi$.\nThe derivation is correct.\nThe final answer is the expression for $\\eta(\\tau)$.",
            "answer": "$$\n\\boxed{\\frac{\\alpha s_{0}(\\tau)(1-\\pi) + \\beta s_{1}(\\tau)\\pi}{s_{0}(\\tau)(1-\\pi) + s_{1}(\\tau)\\pi}}\n$$"
        },
        {
            "introduction": "A critical challenge in real-world self-training is the presence of out-of-distribution (OOD) data in the unlabeled poolâ€”examples that do not belong to any of the classes seen during initial training. A naive classifier may assign a high-confidence, incorrect pseudo-label to such inputs, leading to error amplification. This practice introduces a robust solution: using an anomaly detector to filter out OOD examples based on prediction uncertainty, often measured by entropy . You will apply principles of Bayes decision theory to determine the optimal decision threshold that minimizes the costs associated with misclassifying inputs as either in-distribution or anomalous.",
            "id": "3172796",
            "problem": "A classifier with parameters $\\theta$ produces a categorical distribution $p_{\\theta}(y \\mid x)$ over $K$ seen classes for each input $x$ via the softmax transformation applied to its logits. In semi-supervised learning with self-training, unlabeled inputs $\\{x_{i}\\}$ are assigned pseudo-labels when the model is sufficiently confident, and are otherwise held out. However, the unlabeled pool also contains inputs from an unseen class (out-of-distribution, OOD), which must be prevented from being pseudo-labeled to avoid error accumulation.\n\nConsider an anomaly detector that thresholds the Shannon entropy $H(p_{\\theta}(x)) = -\\sum_{j=1}^{K} p_{\\theta,j}(x) \\ln p_{\\theta,j}(x)$: declare an input $x$ as in-distribution (eligible for pseudo-labeling) if $H(p_{\\theta}(x)) \\leq \\tau$, and otherwise declare it anomalous (reject). This detector is equivalent in spirit to thresholding an energy score $E(x) = -\\ln\\left(\\sum_{j=1}^{K} \\exp(z_{j}(x))\\right)$ when the softmax logits $z_{j}(x)$ are well-calibrated, since higher uncertainty (flatter softmax) simultaneously increases entropy and energy.\n\nAssume the following scientifically plausible model for entropy under the two regimes:\n- For inputs from seen classes, $H \\mid \\text{seen} \\sim \\mathcal{N}(\\mu_{s}, \\sigma^{2})$ with $\\mu_{s} = 0.4$ and $\\sigma = 0.25$ (nats).\n- For inputs from the unseen class, $H \\mid \\text{unseen} \\sim \\mathcal{N}(\\mu_{u}, \\sigma^{2})$ with $\\mu_{u} = 1.3$ and the same $\\sigma = 0.25$ (nats).\n\nLet the prior probabilities in the unlabeled pool be $\\pi_{s} = 0.85$ for seen-class inputs and $\\pi_{u} = 0.15$ for unseen-class inputs. Suppose the cost of a false acceptance (declaring unseen as seen, which leads to mislabeling) is $C_{\\text{FA}} = 4$, while the cost of a false rejection (declaring seen as unseen, which forgoes a useful pseudo-label) is $C_{\\text{FR}} = 1$.\n\nStarting from the principles of Bayes decision theory and the definitions above, derive the Bayes-optimal threshold $\\tau^{\\star}$ that minimizes the expected cost of detection trade-offs under this entropy-thresholding rule. Then compute the numerical value of $\\tau^{\\star}$ using the given parameters. Round your final numeric answer to four significant figures and express it in nats.",
            "solution": "The problem asks for the Bayes-optimal decision threshold $\\tau^{\\star}$ for classifying an input as belonging to a 'seen' or 'unseen' class based on the Shannon entropy $H$ of a model's prediction. The optimal threshold is the one that minimizes the total expected cost (Bayes risk) associated with classification errors.\n\nThe decision rule is defined as:\n- Declare 'seen' if the observed entropy $h \\leq \\tau$.\n- Declare 'unseen' if the observed entropy $h  \\tau$.\n\nThe two types of errors and their associated costs are:\n1.  **False Acceptance (FA)**: Declaring an 'unseen' input as 'seen'. This occurs when the true class is 'unseen' but $h \\leq \\tau$. The cost is $C_{\\text{FA}} = 4$.\n2.  **False Rejection (FR)**: Declaring a 'seen' input as 'unseen'. This occurs when the true class is 'seen' but $h  \\tau$. The cost is $C_{\\text{FR}} = 1$.\n\nThe prior probabilities for the classes are given as $\\pi_{s} = P(\\text{seen}) = 0.85$ and $\\pi_{u} = P(\\text{unseen}) = 0.15$.\n\nThe conditional distributions of the entropy $H$ for each class are given as Normal distributions:\n- For 'seen' inputs: $p(h|\\text{seen}) = p_s(h) = \\mathcal{N}(h; \\mu_s, \\sigma^2)$, with $\\mu_s = 0.4$ and $\\sigma = 0.25$.\n- For 'unseen' inputs: $p(h|\\text{unseen}) = p_u(h) = \\mathcal{N}(h; \\mu_u, \\sigma^2)$, with $\\mu_u = 1.3$ and $\\sigma = 0.25$.\n\nAccording to Bayes decision theory, we must minimize the expected cost, or risk, $R(\\tau)$. The risk is the sum of the costs of each type of error, weighted by their respective probabilities of occurrence.\n\nThe probability of a false acceptance is the joint probability of the input being 'unseen' and being declared 'seen':\n$$ P(\\text{FA}) = P(h \\leq \\tau, \\text{unseen}) = P(h \\leq \\tau | \\text{unseen}) P(\\text{unseen}) = \\pi_u \\int_{-\\infty}^{\\tau} p_u(h) \\, dh $$\nThe probability of a false rejection is the joint probability of the input being 'seen' and being declared 'unseen':\n$$ P(\\text{FR}) = P(h  \\tau, \\text{seen}) = P(h  \\tau | \\text{seen}) P(\\text{seen}) = \\pi_s \\int_{\\tau}^{\\infty} p_s(h) \\, dh $$\n\nThe total expected cost $R(\\tau)$ is the sum of the products of the costs and their probabilities:\n$$ R(\\tau) = C_{\\text{FA}} P(\\text{FA}) + C_{\\text{FR}} P(\\text{FR}) $$\n$$ R(\\tau) = C_{\\text{FA}} \\pi_u \\int_{-\\infty}^{\\tau} p_u(h) \\, dh + C_{\\text{FR}} \\pi_s \\int_{\\tau}^{\\infty} p_s(h) \\, dh $$\n\nTo find the optimal threshold $\\tau^{\\star}$ that minimizes $R(\\tau)$, we differentiate $R(\\tau)$ with respect to $\\tau$ and set the derivative to zero. Using the Fundamental Theorem of Calculus (specifically, the Leibniz integral rule):\n$$ \\frac{d}{d\\tau} \\int_{-\\infty}^{\\tau} f(x) \\, dx = f(\\tau) $$\n$$ \\frac{d}{d\\tau} \\int_{\\tau}^{\\infty} f(x) \\, dx = -f(\\tau) $$\n\nApplying this to the risk function $R(\\tau)$:\n$$ \\frac{dR(\\tau)}{d\\tau} = C_{\\text{FA}} \\pi_u p_u(\\tau) + C_{\\text{FR}} \\pi_s (-p_s(\\tau)) $$\nSetting the derivative to zero to find the minimum:\n$$ C_{\\text{FA}} \\pi_u p_u(\\tau^{\\star}) - C_{\\text{FR}} \\pi_s p_s(\\tau^{\\star}) = 0 $$\n$$ C_{\\text{FA}} \\pi_u p_u(\\tau^{\\star}) = C_{\\text{FR}} \\pi_s p_s(\\tau^{\\star}) $$\nThis equation defines the Bayes-optimal threshold $\\tau^{\\star}$. It signifies that at the decision boundary, the weighted likelihoods of the two classes are equal, where the weights are the products of the costs and prior probabilities.\n\nNow, we substitute the probability density functions (PDFs) for the Normal distributions:\n$$ p_s(h) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(h - \\mu_s)^2}{2\\sigma^2}\\right) $$\n$$ p_u(h) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(h - \\mu_u)^2}{2\\sigma^2}\\right) $$\nPlugging these into the optimality condition for $\\tau = \\tau^{\\star}$:\n$$ C_{\\text{FA}} \\pi_u \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(\\tau - \\mu_u)^2}{2\\sigma^2}\\right) = C_{\\text{FR}} \\pi_s \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(\\tau - \\mu_s)^2}{2\\sigma^2}\\right) $$\nThe normalization constant $\\frac{1}{\\sqrt{2\\pi}\\sigma}$ cancels from both sides:\n$$ C_{\\text{FA}} \\pi_u \\exp\\left(-\\frac{(\\tau - \\mu_u)^2}{2\\sigma^2}\\right) = C_{\\text{FR}} \\pi_s \\exp\\left(-\\frac{(\\tau - \\mu_s)^2}{2\\sigma^2}\\right) $$\nTo solve for $\\tau$, we take the natural logarithm of both sides:\n$$ \\ln(C_{\\text{FA}} \\pi_u) - \\frac{(\\tau - \\mu_u)^2}{2\\sigma^2} = \\ln(C_{\\text{FR}} \\pi_s) - \\frac{(\\tau - \\mu_s)^2}{2\\sigma^2} $$\nRearranging the terms to isolate $\\tau$:\n$$ \\frac{(\\tau - \\mu_s)^2}{2\\sigma^2} - \\frac{(\\tau - \\mu_u)^2}{2\\sigma^2} = \\ln(C_{\\text{FR}} \\pi_s) - \\ln(C_{\\text{FA}} \\pi_u) $$\nMultiplying by $2\\sigma^2$ and expanding the squared terms:\n$$ (\\tau^2 - 2\\tau\\mu_s + \\mu_s^2) - (\\tau^2 - 2\\tau\\mu_u + \\mu_u^2) = 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nThe $\\tau^2$ terms cancel out:\n$$ 2\\tau\\mu_u - 2\\tau\\mu_s + \\mu_s^2 - \\mu_u^2 = 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\n$$ 2\\tau(\\mu_u - \\mu_s) = \\mu_u^2 - \\mu_s^2 + 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nFactoring $\\mu_u^2 - \\mu_s^2 = (\\mu_u - \\mu_s)(\\mu_u + \\mu_s)$:\n$$ 2\\tau(\\mu_u - \\mu_s) = (\\mu_u - \\mu_s)(\\mu_u + \\mu_s) + 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nSince $\\mu_u \\neq \\mu_s$, we can divide by $2(\\mu_u - \\mu_s)$:\n$$ \\tau = \\frac{\\mu_u + \\mu_s}{2} + \\frac{\\sigma^2}{\\mu_u - \\mu_s} \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nThis is the analytical expression for the Bayes-optimal threshold $\\tau^{\\star}$.\n\nNow, we substitute the given numerical values:\n$\\mu_{s} = 0.4$, $\\mu_{u} = 1.3$, $\\sigma = 0.25$, $\\pi_{s} = 0.85$, $\\pi_{u} = 0.15$, $C_{\\text{FR}} = 1$, $C_{\\text{FA}} = 4$.\n\nThe first term is the midpoint of the means:\n$$ \\frac{\\mu_u + \\mu_s}{2} = \\frac{1.3 + 0.4}{2} = \\frac{1.7}{2} = 0.85 $$\nThe argument of the logarithm is:\n$$ \\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u} = \\frac{1 \\times 0.85}{4 \\times 0.15} = \\frac{0.85}{0.60} = \\frac{17}{12} $$\nThe remaining terms are:\n$$ \\mu_u - \\mu_s = 1.3 - 0.4 = 0.9 $$\n$$ \\sigma^2 = (0.25)^2 = 0.0625 $$\nSubstituting these into the expression for $\\tau^{\\star}$:\n$$ \\tau^{\\star} = 0.85 + \\frac{0.0625}{0.9} \\ln\\left(\\frac{17}{12}\\right) $$\nNow we compute the numerical value:\n$$ \\ln\\left(\\frac{17}{12}\\right) \\approx \\ln(1.41666...) \\approx 0.3483203 $$\n$$ \\frac{0.0625}{0.9} = \\frac{625 \\times 10^{-4}}{9 \\times 10^{-1}} = \\frac{625}{9000} = \\frac{5}{72} \\approx 0.0694444 $$\nCombining these:\n$$ \\tau^{\\star} \\approx 0.85 + (0.0694444) \\times (0.3483203) $$\n$$ \\tau^{\\star} \\approx 0.85 + 0.0241889 $$\n$$ \\tau^{\\star} \\approx 0.8741889 $$\nRounding the result to four significant figures gives $0.8742$.\nThe unit is nats, as the entropy is calculated using the natural logarithm.",
            "answer": "$$\n\\boxed{0.8742}\n$$"
        },
        {
            "introduction": "In many practical applications, the initial labeled dataset is not perfectly clean and may contain noisy labels. This raises a crucial question: can self-training, which introduces its own source of noise via pseudo-labels, help overcome the initial label noise, or does it simply make matters worse? This exercise explores the fascinating phenomenon of \"self-healing,\" where self-training can act as a denoising mechanism . By analyzing the interaction between symmetric label noise and the pseudo-labeling process, you will determine the conditions under which a self-training step is guaranteed to reduce the effective noise rate of the training data.",
            "id": "3172790",
            "problem": "Consider a binary classification problem with features $X \\in \\mathcal{X}$ and clean labels $Y \\in \\{0,1\\}$. You observe a labeled sample where each clean label is independently flipped with a symmetric label noise rate $\\rho \\in (0, \\tfrac{1}{2})$: for each example, with probability $\\rho$ the observed label equals $1-Y$ and with probability $1-\\rho$ it equals $Y$. You also have an unlabeled sample drawn from the same marginal distribution of $X$.\n\nA probabilistic classifier is trained on the noisy labeled sample to optimality in the sense that it returns, for any $x$, the corrupted posterior $g(x) = \\mathbb{P}(\\tilde{Y}=1 \\mid X=x)$, where $\\tilde{Y}$ denotes the observed noisy label. Define the clean posterior $\\eta(x) = \\mathbb{P}(Y=1 \\mid X=x)$.\n\nA single round of Self-Training (ST) is performed as follows. On the unlabeled sample, assign a pseudo-label $\\hat{Y}(x) \\in \\{0,1\\}$ equal to the Bayes decision with respect to $g(x)$, that is, $\\hat{Y}(x) = \\mathbf{1}\\{g(x) \\geq \\tfrac{1}{2}\\}$. Accept only those pseudo-labels whose confidence margin exceeds a fixed threshold $\\gamma \\in [0, \\tfrac{1}{2})$, meaning the accepted set is $\\{x: |g(x) - \\tfrac{1}{2}| \\geq \\gamma\\}$. Combine the original noisy labeled set with the accepted pseudo-labeled examples, and view the combined set as having an effective label noise rate equal to the fraction of incorrect labels relative to the clean labels $Y$.\n\nStarting from the definitions of symmetric label noise and conditional probabilities, derive the exact affine relationship between $g(x)$ and $\\eta(x)$. Then, using only this relationship and the acceptance rule $|g(x) - \\tfrac{1}{2}| \\geq \\gamma$, compute a distribution-free worst-case upper bound on the pseudo-label error rate among the accepted examples. Using this bound, determine the minimal confidence margin $\\gamma_{\\star}(\\rho)$ such that, for any $\\gamma \\geq \\gamma_{\\star}(\\rho)$ with $\\gamma  \\tfrac{1}{2} - \\rho$, the effective label noise rate after one ST round is strictly lower than the original noise rate $\\rho$, regardless of the distribution of $X$.\n\nYour final answer should be a single closed-form expression for $\\gamma_{\\star}(\\rho)$ in terms of $\\rho$. Do not include any inequalities in the final answer.",
            "solution": "### Derivation\nThe solution proceeds in three stages as required by the problem statement.\n\n**1. Relationship between $g(x)$ and $\\eta(x)$**\n\nThe corrupted posterior $g(x)$ is defined as $g(x) = \\mathbb{P}(\\tilde{Y}=1 \\mid X=x)$. Using the law of total probability, we can expand this by conditioning on the clean label $Y$:\n$$g(x) = \\mathbb{P}(\\tilde{Y}=1 \\mid Y=1, X=x)\\mathbb{P}(Y=1 \\mid X=x) + \\mathbb{P}(\\tilde{Y}=1 \\mid Y=0, X=x)\\mathbb{P}(Y=0 \\mid X=x)$$\nThe symmetric noise model states that the label flip probability is independent of the feature $X$. Therefore, $\\mathbb{P}(\\tilde{Y}=1 \\mid Y=1, X=x) = \\mathbb{P}(\\tilde{Y}=1 \\mid Y=1) = 1-\\rho$ and $\\mathbb{P}(\\tilde{Y}=1 \\mid Y=0, X=x) = \\mathbb{P}(\\tilde{Y}=1 \\mid Y=0) = \\rho$. The clean posteriors are given by $\\eta(x) = \\mathbb{P}(Y=1 \\mid X=x)$ and $1-\\eta(x) = \\mathbb{P}(Y=0 \\mid X=x)$.\nSubstituting these into the equation for $g(x)$:\n$$g(x) = (1-\\rho)\\eta(x) + \\rho(1-\\eta(x))$$\n$$g(x) = (1-\\rho)\\eta(x) + \\rho - \\rho\\eta(x)$$\n$$g(x) = (1-2\\rho)\\eta(x) + \\rho$$\nThis is the affine relationship between the corrupted posterior $g(x)$ and the clean posterior $\\eta(x)$. Since $\\rho \\in (0, \\frac{1}{2})$, the term $1-2\\rho$ is non-zero, and we can invert this relationship to express $\\eta(x)$ in terms of $g(x)$:\n$$\\eta(x) = \\frac{g(x) - \\rho}{1-2\\rho}$$\n\n**2. Worst-Case Pseudo-Label Error Rate**\n\nA pseudo-label $\\hat{Y}(x)$ is assigned based on the Bayes decision rule for the corrupted posterior: $\\hat{Y}(x) = \\mathbf{1}\\{g(x) \\geq \\frac{1}{2}\\}$. An example is accepted for self-training if its confidence margin $|g(x) - \\frac{1}{2}|$ is at least $\\gamma$. This acceptance condition partitions the accepted set into two disjoint subsets:\n-   Set 1: $\\{x \\mid g(x) \\geq \\frac{1}{2} + \\gamma\\}$. For these examples, the pseudo-label is $\\hat{Y}(x) = 1$.\n-   Set 2: $\\{x \\mid g(x) \\leq \\frac{1}{2} - \\gamma\\}$. For these examples, the pseudo-label is $\\hat{Y}(x) = 0$.\n\nThe pseudo-label error rate for a given $x$ is the probability that the pseudo-label $\\hat{Y}(x)$ does not match the true clean label $Y$, i.e., $\\mathbb{P}(\\hat{Y}(x) \\neq Y \\mid X=x)$. Let us find an upper bound for this error rate for any accepted example.\n\nFor an example in Set 1 ($g(x) \\geq \\frac{1}{2} + \\gamma$ and $\\hat{Y}(x)=1$), an error occurs if the true label is $Y=0$. The probability of this is:\n$$\\mathbb{P}(Y=0 \\mid X=x) = 1 - \\eta(x) = 1 - \\frac{g(x) - \\rho}{1-2\\rho} = \\frac{(1-2\\rho) - (g(x) - \\rho)}{1-2\\rho} = \\frac{1 - \\rho - g(x)}{1-2\\rho}$$\nSince $1-2\\rho  0$, this error probability is a decreasing function of $g(x)$. To find a worst-case (maximum) bound, we must use the minimum possible value of $g(x)$ in this set, which is $g(x) = \\frac{1}{2} + \\gamma$.\n$$\\text{Error Rate (Set 1)} \\leq \\frac{1 - \\rho - (\\frac{1}{2} + \\gamma)}{1-2\\rho} = \\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}$$\n\nFor an example in Set 2 ($g(x) \\leq \\frac{1}{2} - \\gamma$ and $\\hat{Y}(x)=0$), an error occurs if the true label is $Y=1$. The probability of this is:\n$$\\mathbb{P}(Y=1 \\mid X=x) = \\eta(x) = \\frac{g(x) - \\rho}{1-2\\rho}$$\nSince $1-2\\rho  0$, this error probability is an increasing function of $g(x)$. To find a worst-case bound, we must use the maximum possible value of $g(x)$ in this set, which is $g(x) = \\frac{1}{2} - \\gamma$.\n$$\\text{Error Rate (Set 2)} \\leq \\frac{(\\frac{1}{2} - \\gamma) - \\rho}{1-2\\rho} = \\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}$$\nBoth cases yield the same worst-case error bound. This bound is independent of $x$ and the underlying data distribution, as long as the example satisfies the acceptance criterion. Let $\\rho_{\\text{ST}}$ denote the pseudo-label error rate on the accepted set. We have established a distribution-free upper bound:\n$$\\rho_{\\text{ST}} \\leq \\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}$$\n\n**3. Minimal Confidence Margin $\\gamma_{\\star}(\\rho)$**\n\nThe problem asks for the condition that ensures the effective label noise rate of the combined dataset is strictly lower than the original noise rate $\\rho$. Let the original noisy labeled set be $S_L$ with size $n_L$, and the set of accepted pseudo-labeled examples be $S_A$ with size $n_A$. The number of errors in $S_L$ is approximately $n_L \\rho$. The number of errors in $S_A$ is $n_A \\rho_{\\text{ST}}$.\nThe effective noise rate, $\\rho_{\\text{eff}}$, is the total number of errors divided by the total size of the combined dataset:\n$$\\rho_{\\text{eff}} = \\frac{n_L \\rho + n_A \\rho_{\\text{ST}}}{n_L + n_A}$$\nWe require $\\rho_{\\text{eff}}  \\rho$:\n$$\\frac{n_L \\rho + n_A \\rho_{\\text{ST}}}{n_L + n_A}  \\rho$$\n$$n_L \\rho + n_A \\rho_{\\text{ST}}  n_L \\rho + n_A \\rho$$\nAssuming $n_A > 0$ (i.e., self-training adds some examples), this inequality simplifies to:\n$$\\rho_{\\text{ST}}  \\rho$$\nTo guarantee this condition holds regardless of the data distribution, we must enforce that the worst-case upper bound on $\\rho_{\\text{ST}}$ is strictly less than $\\rho$:\n$$\\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}  \\rho$$\nSince $\\rho \\in (0, \\frac{1}{2})$, we have $1-2\\rho  0$. We can multiply both sides by $1-2\\rho$ without changing the direction of the inequality:\n$$\\frac{1}{2} - \\rho - \\gamma  \\rho(1-2\\rho)$$\n$$\\frac{1}{2} - \\rho - \\gamma  \\rho - 2\\rho^2$$\nNow, we solve for $\\gamma$:\n$$\\frac{1}{2} - 2\\rho + 2\\rho^2  \\gamma$$\nThis inequality specifies the condition that $\\gamma$ must satisfy to guarantee a reduction in noise rate. The problem asks for the minimal confidence margin $\\gamma_{\\star}(\\rho)$ such that for any $\\gamma \\geq \\gamma_{\\star}(\\rho)$, this condition holds. This minimal value is the lower bound of the derived interval for $\\gamma$.\nTherefore, the minimal confidence margin is:\n$$\\gamma_{\\star}(\\rho) = \\frac{1}{2} - 2\\rho + 2\\rho^2$$\nThis can also be written as $\\gamma_{\\star}(\\rho) = 2(\\rho - \\frac{1}{2})^2$. The problem constraint $\\gamma  \\frac{1}{2} - \\rho$ ensures that $\\gamma_{\\star}(\\rho)$ is a valid choice, as $2(\\rho - \\frac{1}{2})^2  \\frac{1}{2} - \\rho$ for $\\rho \\in (0, \\frac{1}{2})$.",
            "answer": "$$\\boxed{\\frac{1}{2} - 2\\rho + 2\\rho^2}$$"
        }
    ]
}