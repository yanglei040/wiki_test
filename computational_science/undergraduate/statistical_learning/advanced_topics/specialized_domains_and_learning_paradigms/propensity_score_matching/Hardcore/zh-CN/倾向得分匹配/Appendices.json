{
    "hands_on_practices": [
        {
            "introduction": "为了在实践中应用倾向性得分，我们首先必须理解其基本定义和计算方法。这个练习提供了一个具体的非随机分配场景——自然保护区的划定——并要求我们从一个给定的逻辑回归模型中手动计算一个特定样本的倾向性得分。通过这个练习，你将深入理解倾向性得分是如何从模型的线性预测部分通过逻辑函数转化而来的，这是掌握倾向性得分匹配方法的基石。",
            "id": "2488850",
            "problem": "一位环境科学家，为了将其经验性评估角色与倡导导向的环保主义区分开来，旨在估计指定保护区对森林砍伐的因果影响。由于保护区的选址并非随机，如果被指定为保护区的区域在生物物理或政治特征上与非指定区域存在系统性差异，就可能产生选择偏差。为解决此问题，该科学家采用了倾向得分框架，其中倾向得分是在给定观测协变量的情况下，接受处理（被指定为保护区）的条件概率。\n\n您之前已使用广义线性模型（GLM）和 logit 链接函数，基于来自同一地区的训练样本，估计了一个用于保护区指定的二元响应模型。预测变量包括坡度、到道路的距离，以及一个表示是否邻近政治边界的指标。估计的线性预测器使用以下系数（根据先前数据估计得出）：截距 $\\beta_{0}=-3.8$，坡度系数 $\\beta_{\\text{slope}}=0.07$ 每度（度是角度单位），到道路距离的系数 $\\beta_{\\text{dist}}=0.05$ 每公里，以及政治边界系数 $\\beta_{\\text{bound}}=0.60$（对于一个二元指标，如果地块位于省界10公里以内，则该指标为$1$，否则为$0$）。\n\n对于一个特定的森林地块，其坡度为$18$度，距最近道路的距离为$25$公里，且位于省界$10$公里以内（指标等于$1$），请计算该地块被指定为保护区的倾向得分。请从倾向得分是给定协变量下的处理条件概率的定义出发，并结合广义线性模型中 logit 链接函数的对数几率变换（logit）的定义，在代入数值之前推导出您需要的任何概率映射。\n\n将您最终的数值倾向得分四舍五入到四位有效数字，并以无单位小数表示（不要使用百分比）。此外，请简要用文字概述基于此得分进行匹配如何能在估计保護区对森林砍伐的影响时减少选择偏差，并阐明区分推断性评估与倡导的科学推理。\n\n仅陈述计算出的倾向得分作为您的最终数值答案。",
            "solution": "问题陈述经过验证。\n\n**步骤1：提取已知条件**\n- 模型：用于保护区指定二元响应的广义线性模型（GLM），使用 logit 链接函数。\n- 倾向得分定义为在给定观测协变量的情况下接受处理（被指定为保护区）的条件概率。\n- 线性预测器系数：\n  - 截距 $\\beta_{0} = -3.8$\n  - 坡度系数 $\\beta_{\\text{slope}} = 0.07$ 每度\n  - 到道路距离的系数 $\\beta_{\\text{dist}} = 0.05$ 每公里\n  - 政治边界系数 $\\beta_{\\text{bound}} = 0.60$\n- 森林地块特征（协变量）：\n  - 坡度：$18$ 度\n  - 到最近道路的距离：$25$ 公里\n  - 邻近政治边界指标：$1$\n\n**步骤2：使用提取的已知条件进行验证**\n- 该问题具有**科学依据**。在观察性研究中，使用带 logit 链接函数的广义线性模型和倾向得分框架是统计学和计量经济学中用于因果推断的标准、成熟方法。\n- 该问题是**适定**的。它提供了计算唯一解所需的所有必要参数和变量值。问题明确无歧义。\n- 该问题是**客观**的。它使用了精确的技术语言，并正确地构建了项目评估中选择偏差的方法论挑战，区分了经验科学角色与倡导角色。\n- 该问题不包含科学或事实上的不健全之处，并非不可形式化，没有不完整或矛盾的设定，并非不现实或不可行，不是非适定的，不是琐碎的，并且是科学可验证的。\n\n**步骤3：结论与行动**\n该问题是**有效的**。将推导解答。\n\n任务是计算特定森林地块的倾向得分，并解释倾向得分匹配的逻辑。倾向得分，我们记为 $p(X)$，是在给定观测协变量向量 $X$ 的条件下，接受处理（$T=1$）的条件概率。在此背景下，处理是指将一个地块指定为保护区。\n\n$$p(X) = P(T=1 | X)$$\n\n所用模型为带有 logit 链接函数的广義线性模型（GLM）。logit 函数将概率 $p \\in (0, 1)$ 映射到实数轴 $(-\\infty, \\infty)$，定义为几率的自然对数：\n\n$$\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\n在 GLM 框架中，响应的条件均值的链接函数等于一个线性预测器 $\\eta$。对于二元响应，条件均值是概率 $p$。因此，我们有：\n\n$$\\eta = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\n为了从线性预测器 $\\eta$ 计算概率 $p$，我们必须推导出 logit 函数的反函数，即逻辑 S 型函数。我们首先对两边取指数：\n\n$$\\exp(\\eta) = \\frac{p}{1-p}$$\n\n现在，我们求解 $p$：\n$$\\exp(\\eta) \\cdot (1-p) = p$$\n$$\\exp(\\eta) - p \\cdot \\exp(\\eta) = p$$\n$$\\exp(\\eta) = p + p \\cdot \\exp(\\eta)$$\n$$\\exp(\\eta) = p \\cdot (1 + \\exp(\\eta))$$\n\n这给出了倾向得分作为线性预测器函数的表达式：\n$$p = \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)}$$\n\n线性预测器 $\\eta$ 是给定协变量及其相应系数的线性组合：\n$$\\eta = \\beta_{0} + \\beta_{\\text{slope}} \\cdot X_{\\text{slope}} + \\beta_{\\text{dist}} \\cdot X_{\\text{dist}} + \\beta_{\\text{bound}} \\cdot X_{\\text{bound}}$$\n\n问题提供了以下数值：\n- 截距：$\\beta_{0} = -3.8$\n- 系数：$\\beta_{\\text{slope}} = 0.07$, $\\beta_{\\text{dist}} = 0.05$, $\\beta_{\\text{bound}} = 0.60$\n- 地块的协变量：$X_{\\text{slope}} = 18$, $X_{\\text{dist}} = 25$, $X_{\\text{bound}} = 1$\n\n我们代入这些值来计算线性预测器 $\\eta$：\n$$\\eta = -3.8 + (0.07 \\times 18) + (0.05 \\times 25) + (0.60 \\times 1)$$\n$$\\eta = -3.8 + 1.26 + 1.25 + 0.60$$\n$$\\eta = -3.8 + 3.11$$\n$$\\eta = -0.69$$\n\n现在，我们使用这个 $\\eta$ 值来计算倾向得分 $p$：\n$$p = \\frac{\\exp(-0.69)}{1 + \\exp(-0.69)}$$\n\n计算数值：\n$$p \\approx \\frac{0.501574}{1 + 0.501574} = \\frac{0.501574}{1.501574} \\approx 0.334033$$\n\n问题要求四舍五入到四位有效数字。因此，该地块的倾向得分为 $0.3340$。\n\n关于此方法的效用，选择偏差的产生是因为保护区的选址并非随机。被指定为保护区的地块可能与未被指定的地块存在系统性差异（例如，它们可能更偏远，坡度更陡，或农业潜力更低）。对森林砍伐等结果进行简单比较会将保护的效果与这些预先存在的差异混为一谈。倾向得分匹配是一种减轻这种偏差的统计技术。它在条件可忽略性假设下运作，该假设假定，在给定观测协变量 $X$ 的条件下，处理分配与潜在结果无关。通过将一个处理单元（受保护的地块）与一个或多个具有非常相似倾向得分的控制单元（未受保护的地块）进行匹配，我们创建了一个在观测协变量上达到平衡的比较组。也就是说，对于给定的倾向得分，一个处理单元和一个控制单元在事前被保护的概率是相同的。这个过程模仿了随机实验的特性，从而能够更可信地估计保护的因果效应。这种纯粹的推断目标——通过控制混淆因素来分离因果效应——是此背景下环境科学的标志。它与环保主义不同，后者是一种倡导立场，可能无论其经验证明的、孤立的影响如何，都会推动保护。科学家的角色是为处理效应提供一个客观的、基于证据的估计，而这种方法是实现这一目标的关键工具。",
            "answer": "$$\n\\boxed{0.3340}\n$$"
        },
        {
            "introduction": "一个有效的倾向性得分模型并非理所当然，其构建和诊断是整个因果推断过程中的关键环节。这个动手实践将引导你完成一个在实际应用中至关重要的工作流程：首先，通过变量重要性度量来筛选倾向性得分模型中的协变量；然后，执行匹配并使用“标准化均值差”（SMD）这一核心指标来评估匹配后处理组和控制组的协变量是否达到了平衡。掌握这个流程对于确保匹配结果的可靠性至关重要。",
            "id": "3162937",
            "problem": "您接获一项任务，需要通过算法确定倾向性得分模型的变量删减策略，并评估在对估计的倾向性得分进行一对一最近邻匹配后，删减如何影响协变量的平衡性。您必须基于因果推断和统计建模的基本定义，实现完整的流程，并在一个小型测试集上进行定量比较。\n\n需使用的基本原理和定义：\n- 倾向性得分定义为 $e(x) = \\mathbb{P}(T = 1 \\mid X = x)$，其中 $T \\in \\{0,1\\}$ 是一个二元处理，$X \\in \\mathbb{R}^p$ 是一个协变量向量。\n- 您将通过逻辑回归对倾向性得分进行建模，即 $\\text{logit}(e(x)) = \\beta_0 + x^\\top \\beta$，其中 $\\text{logit}(u) = \\log\\left(\\frac{u}{1-u}\\right)$ 且 $\\beta \\in \\mathbb{R}^p$。\n- 使用迭代重加权最小二乘法 (IRLS) 最大化二项对数似然来拟合逻辑回归，该方法是应用于逻辑回归对数似然的 Newton–Raphson 方法。在信息矩阵上使用少量岭稳定化，以确保数值可逆性。\n- 倾向性模型中需计算两个变量重要性度量：\n  1. 绝对标准化系数大小，定义为 $I^{(\\text{coef})}_j = \\lvert \\hat{\\beta}_j \\rvert$（对于协变量 $j$），在将协变量标准化为零均值和单位方差之后。这度量了 $X_j$ 每变化一个标准差时，对数几率的变化幅度。\n  2. 绝对 Wald $z$ 统计量，定义为 $I^{(\\text{wald})}_j = \\left| \\frac{\\hat{\\beta}_j}{\\widehat{\\text{se}}(\\hat{\\beta}_j)} \\right|$，其中 $\\widehat{\\text{se}}(\\hat{\\beta}_j)$ 从最大似然估计处的观测 Fisher 信息矩阵的逆矩阵中获得。这度量了在对数几率尺度上一个信号-噪声标准化的效应。\n- 通过秩平均聚合这两个度量：\n  - 对每个度量，分配秩 $r^{(\\text{coef})}_j, r^{(\\text{wald})}_j \\in \\{1,2,\\dots,p\\}$，使得数值越大，秩越高。通过协变量索引顺序确定性地处理平局。将组合秩定义为 $r^{(\\text{comb})}_j = \\frac{r^{(\\text{coef})}_j + r^{(\\text{wald})}_j}{2}$。\n- 删减规则：给定一个删减比例 $q \\in [0,1)$，按 $r^{(\\text{comb})}_j$ 降序保留排名前 $\\lceil (1-q) \\cdot p \\rceil$ 的协变量，并舍弃其余变量。\n- 匹配：在估计的倾向性得分上执行无放回的一对一最近邻匹配。定义绝对距离 $d(i,k) = \\lvert \\hat{e}_i - \\hat{e}_k \\rvert$。使用样本量较小的组（处理组或对照组）作为锚定集以保证完全匹配，按 $\\hat{e}$ 升序对锚定集排序，并为每个锚定单位选择一个使 $d(i,k)$ 最小化的未匹配的对立组单位，通过最小索引处理平局以确保确定性。\n- 平衡性评估：对于每个协变量 $j \\in \\{1,\\dots,p\\}$，计算匹配后的标准化均值差 (SMD) 为\n$$\n\\text{SMD}_j = \\frac{\\bar{x}^{(T=1)}_j - \\bar{x}^{(T=0)}_j}{\\sqrt{\\frac{s^{2,(T=1)}_j + s^{2,(T=0)}_j}{2}}},\n$$\n其中 $\\bar{x}^{(T=t)}_j$ 和 $s^{2,(T=t)}_j$ 分别是处理组 $t \\in \\{0,1\\}$ 在匹配子样本中的样本均值和无偏样本方差。如果分母为零，则定义 $\\text{SMD}_j = 0$。通过平均绝对标准化均值差（mSMD）来总结平衡性，即 $\\text{mSMD} = \\frac{1}{p} \\sum_{j=1}^p \\lvert \\text{SMD}_j \\rvert$。\n- 比较两个模型：完整模型（所有 $p$ 个协变量）与删减后模型（仅保留的协变量，重新估计）。对于每种情况，使用由各模型的倾向性得分构建的匹配计算 $\\text{mSMD}^{\\text{full}}$ 和 $\\text{mSMD}^{\\text{pruned}}$，并报告由删减引起的变化 $\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$。负的 $\\Delta$ 值表示删减后平衡性得到改善。\n\n每个测试案例的数据生成过程：\n- 生成 $p$ 维协变量 $X \\sim \\mathcal{N}(0, \\Sigma)$ 的 $n$ 个观测值，其中 $\\Sigma_{ij} = \\rho^{\\lvert i-j \\rvert}$，$\\rho \\in [0,1)$ 是给定的相关性参数。\n- 设真实对数几率为 $\\eta = \\alpha_0 + X \\beta^{\\star}$，其中 $\\beta^{\\star} \\in \\mathbb{R}^p$ 为指定向量，$\\alpha_0 \\in \\mathbb{R}$ 为截距，则 $T \\sim \\text{Bernoulli}(\\sigma(\\eta))$ 在观测间独立同分布，其中 $\\sigma(u) = \\frac{1}{1 + e^{-u}}$。\n- 在建模时，先将协变量标准化为零均值和单位方差，然后再拟合逻辑回归，以便重要性度量 $I^{(\\text{coef})}_j$ 具有无尺度解释。\n\n测试集：\n您必须按以下确切顺序在以下三个参数集上运行您的程序。每个参数集指定了 $(n, p, \\rho, \\text{seed}, \\beta^{\\star}, \\alpha_0, q)$，其中所有数字均为实数或整数。对于 $\\beta^{\\star}$，按顺序列出 $p$ 个条目。\n\n- 测试案例 A（一般情况）：\n  - $n = 400$, $p = 6$, $\\rho = 0.3$, $\\text{seed} = 2021$, $\\beta^{\\star} = [0.8, -0.7, 0.6, 0.0, 0.0, 0.0]$, $\\alpha_0 = 0.0$, $q = 0.5$。\n- 测试案例 B（弱信号边缘情况）：\n  - $n = 300$, $p = 5$, $\\rho = 0.2$, $\\text{seed} = 7$, $\\beta^{\\star} = [0.0, 0.0, 0.0, 0.0, 0.0]$, $\\alpha_0 = 0.0$, $q = 0.4$。\n- 测试案例 C（高共线性）：\n  - $n = 500$, $p = 5$, $\\rho = 0.9$, $\\text{seed} = 99$, $\\beta^{\\star} = [1.0, 0.0, 0.0, 0.0, 0.0]$, $\\alpha_0 = -0.2$, $q = 0.6$。\n\n程序要求：\n- 通过 IRLS 实现逻辑回归，并在观测信息矩阵上进行少量岭稳定化。在模型中使用标准化的协变量并包含一个截距项。\n- 计算重要性度量 $I^{(\\text{coef})}_j$ 和 $I^{(\\text{wald})}_j$，通过秩平均进行聚合，并对每个测试案例按指定的比例 $q$ 进行删减。\n- 对于平衡性，如上所述，分别使用完整模型和删减后模型各自产生的匹配，计算所有原始 $p$ 个协变量的 $\\text{mSMD}$。\n- 对每个测试案例，输出单个浮点数 $\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$。\n- 最终输出格式：您的程序应生成一行输出，其中包含三个测试案例的结果，形式为一个逗号分隔的列表，并用方括号括起来，每个浮点数精确到小数点后六位，例如 `[0.012345,-0.067890,0.000000]`。\n\n不需要用户输入。不涉及物理单位或角度。所有比例和概率必须以小数形式计算和呈现，不带百分号。",
            "solution": "用户提供了一个定义明确的、以倾向性得分分析为核心的统计模拟问题。任务是实现一个从数据生成到模型拟合、变量选择、匹配和平衡性评估的完整流程。目标是量化在倾向性得分模型中采用特定变量删减策略后，协变量平衡性的变化。\n\n### 1. 问题验证\n问题陈述经过了严格验证，被确定为**有效**。它基于统计学和因果推断的既定原则，具有科学依据；其程序步骤确定，问题定义明确；并使用客观、正式的语言表述。所有必要的参数和定义都已提供，确保可以计算出唯一且可验证的解。\n\n### 2. 方法论框架与算法设计\n\n解决方案通过构建一系列与分析的不同逻辑阶段相对应的函数来实现。\n\n#### 2.1. 数据生成\n对于每个测试案例，我们首先根据指定的参数 $(n, p, \\rho, \\text{seed}, \\beta^{\\star}, \\alpha_0)$ 模拟一个数据集。\n$p$ 维协变量 $X \\in \\mathbb{R}^{n \\times p}$ 从一个多元正态分布 $X \\sim \\mathcal{N}(0, \\Sigma)$ 中抽取。协方差矩阵 $\\Sigma$ 是一个自回归-1 (AR-1) 结构，其中 $\\Sigma_{ij} = \\rho^{\\lvert i-j \\rvert}$，对于 $i,j \\in \\{1, \\dots, p\\}$。该矩阵使用 Toeplitz 构造生成。\n然后为每个观测 $i=1, \\dots, n$ 生成二元处理分配 $T \\in \\{0,1\\}^n$。接受处理的真实对数几率被建模为协变量的线性函数，$\\eta_i = \\alpha_0 + X_i^\\top \\beta^{\\star}$。然后，处理 $T_i$ 从一个伯努利分布中抽取，其概率为 $\\mathbb{P}(T_i = 1 \\mid X_i) = \\sigma(\\eta_i)$，其中 $\\sigma(u) = (1 + e^{-u})^{-1}$ 是 logistic sigmoid 函数。每个测试案例使用特定的随机种子以确保可复现性。\n\n#### 2.2. 协变量标准化与倾向性得分估计\n在拟合任何模型之前，生成的协变量 $X$ 被标准化，使每列的均值为 $0$，标准差为 $1$。设此标准化数据为 $X_{\\text{std}}$。此步骤确保基于系数的重要性度量 $I^{(\\text{coef})}$ 在不同协变量之间具有可比的尺度。\n\n倾向性得分 $e(x) = \\mathbb{P}(T=1 \\mid X=x)$ 使用逻辑回归模型 $\\text{logit}(e(x)) = \\gamma_0 + x_{\\text{std}}^\\top \\gamma$ 进行估计。我们使用迭代重加权最小二乘法 (IRLS) 算法来拟合此模型，这是 Newton-Raphson 方法在寻找参数 $\\gamma$（在问题描述中记为 $\\hat{\\beta}$，但我们在此用 $\\gamma$ 以区别于真实的 $\\beta^{\\star}$）的最大似然估计时的应用。IRLS 更新步骤为：\n$$ \\gamma^{(k+1)} = \\gamma^{(k)} + (X_{\\text{aug}}^\\top W^{(k)} X_{\\text{aug}} + \\lambda I)^{-1} X_{\\text{aug}}^\\top (T - \\mu^{(k)}) $$\n其中 $X_{\\text{aug}}$ 是增广了截距列的标准化协变量矩阵，$\\mu^{(k)} = \\sigma(X_{\\text{aug}}\\gamma^{(k)})$ 是在第 $k$ 次迭代时的预测概率，$W^{(k)}$ 是一个对角权重矩阵，其元素为 $W_{ii}^{(k)} = \\mu_i^{(k)}(1-\\mu_i^{(k)})$。项 $\\lambda I$ 表示一个小的岭惩罚（$\\lambda=10^{-8}$），添加到 Fisher 信息矩阵 $(X_{\\text{aug}}^\\top W^{(k)} X_{\\text{aug}})$ 中，以确保数值稳定性，特别是在高共线性的情况下。算法迭代进行，直到系数变化的 L2 范数低于容差 $10^{-7}$ 或达到最大迭代次数 $25$ 次。\n该过程返回估计的系数 $\\hat{\\gamma}$ 及其估计的协方差矩阵 $\\widehat{\\text{Cov}}(\\hat{\\gamma}) = (X_{\\text{aug}}^\\top \\hat{W} X_{\\text{aug}} + \\lambda I)^{-1}$。\n\n#### 2.3. 变量重要性与删减\n为了识别要删减的协变量，我们基于完整模型拟合结果，为每个协变量 $j \\in \\{1, \\dots, p\\}$ 计算两个重要性度量：\n1. 绝对标准化系数大小：$I^{(\\text{coef})}_j = \\lvert \\hat{\\gamma}_j \\rvert$。\n2. 绝对 Wald z-统计量：$I^{(\\text{wald})}_j = \\left| \\frac{\\hat{\\gamma}_j}{\\widehat{\\text{se}}(\\hat{\\gamma}_j)} \\right|$，其中 $\\widehat{\\text{se}}(\\hat{\\gamma}_j)$ 是从 $\\widehat{\\text{Cov}}(\\hat{\\gamma})$ 对角元素的平方根得到的标准误。\n\n这两个度量通过秩平均进行聚合。对于每个度量，协变量从 $1$ 到 $p$ 进行排名，使得重要性值越大，秩越高。通过将较小的秩分配给索引较小的协变量来确定性地处理平局。组合秩为 $r^{(\\text{comb})}_j = (r^{(\\text{coef})}_j + r^{(\\text{wald})}_j) / 2$。\n给定一个删减比例 $q$，我们保留组合秩最高的 $k = \\lceil (1-q)p \\rceil$ 个协变量。这定义了“删减后”的协变量集。然后，仅使用这个标准化的协变量子集重新估计一个新的倾向性得分模型。\n\n#### 2.4. 一对一最近邻匹配\n对于完整模型和删减后模型，我们都在估计的倾向性得分 $\\hat{e}$ 上执行无放回的一对一最近邻匹配。样本量较小的组（处理组或对照组）被指定为“锚定”组。锚定单位按其倾向性得分升序排序。对于每个锚定单位，我们在对立的（“目标”）组中找到一个倾向性得分绝对差值 $d(i,k) = \\lvert \\hat{e}_i - \\hat{e}_k \\rvert$ 最小的单位。该目标单位必须是之前未被匹配的。距离上的平局通过选择原始行索引最小的目标单位来打破。此过程产生一个由配对组成的匹配样本，每对包含一个处理单位和一个对照单位。\n\n#### 2.5. 协变量平衡性评估\n匹配的有效性通过测量匹配样本中的协变量平衡性来评估。对于所有原始的 $p$ 个协变量（在其原始、未标准化的尺度上），我们计算标准化均值差 (SMD)：\n$$ \\text{SMD}_j = \\frac{\\bar{x}^{(T=1)}_j - \\bar{x}^{(T=0)}_j}{\\sqrt{\\frac{s^{2,(T=1)}_j + s^{2,(T=0)}_j}{2}}} $$\n此处，$\\bar{x}^{(T=t)}_j$ 和 $s^{2,(T=t)}_j$ 分别是匹配子样本内处理组 $t$ 的协变量 $j$ 的样本均值和无偏样本方差。如果分母为零，则定义 $\\text{SMD}_j$ 为 $0$。\n总体平衡性由平均绝对标准化均值差 (mSMD) 总结，计算公式为 $\\text{mSMD} = \\frac{1}{p} \\sum_{j=1}^p \\lvert \\text{SMD}_j \\rvert$。\n\n#### 2.6. 评估协议\n对于每个测试案例，整个流程执行两次：\n1. **完整模型**：使用从所有 $p$ 个协变量估计的倾向性得分派生的匹配计算 mSMD，记为 $\\text{mSMD}^{\\text{full}}$。\n2. **删减后模型**：使用从删减后的协变量子集估计的倾向性得分派生的匹配计算 mSMD，记为 $\\text{mSMD}^{\\text{pruned}}$。\n\n每个测试案例报告的最终指标是由于删减引起的平衡性变化：$\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$。$\\Delta$ 的负值表示变量删减策略改善了协变量平衡性。",
            "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef generate_data(n, p, rho, seed, beta_star, alpha_0):\n    \"\"\"Generates synthetic data for a single test case.\"\"\"\n    rng = np.random.default_rng(seed)\n    # Generate covariates X ~ N(0, Sigma)\n    first_row = rho ** np.arange(p)\n    cov_matrix = scipy.linalg.toeplitz(first_row)\n    X = rng.multivariate_normal(np.zeros(p), cov_matrix, size=n)\n\n    # Generate treatment T ~ Bernoulli(sigma(alpha_0 + X @ beta_star))\n    eta = alpha_0 + X @ beta_star\n    prob_T = 1 / (1 + np.exp(-eta))\n    T = rng.binomial(1, prob_T)\n    \n    return X, T\n\ndef fit_logistic_irls(X, y, l2_penalty=1e-8, max_iter=25, tol=1e-7):\n    \"\"\"Fits logistic regression using Iteratively Reweighted Least Squares.\"\"\"\n    X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n    n_samples, n_features = X_aug.shape\n    beta = np.zeros(n_features)\n\n    for _ in range(max_iter):\n        eta = X_aug @ beta\n        mu = 1 / (1 + np.exp(-eta))\n        \n        gradient = X_aug.T @ (y - mu)\n        W_diag = mu * (1 - mu)\n        info_matrix = X_aug.T * W_diag @ X_aug\n        \n        # Add ridge stabilization\n        info_reg = info_matrix + l2_penalty * np.eye(n_features)\n        \n        delta_beta = np.linalg.solve(info_reg, gradient)\n        beta += delta_beta\n        \n        if np.linalg.norm(delta_beta)  tol:\n            break\n            \n    # Final Information Matrix and Covariance\n    eta = X_aug @ beta\n    mu = 1 / (1 + np.exp(-eta))\n    W_diag = mu * (1 - mu)\n    final_info_matrix = X_aug.T * W_diag @ X_aug\n    final_info_reg = final_info_matrix + l2_penalty * np.eye(n_features)\n    cov_beta = np.linalg.inv(final_info_reg)\n    \n    return beta, cov_beta\n\ndef get_pruning_indices(beta, cov_beta, p, q):\n    \"\"\"Determines which covariates to keep based on rank-averaged importance.\"\"\"\n    beta_coeffs = beta[1:]\n    se_beta = np.sqrt(np.diag(cov_beta))[1:]\n    \n    imp_coef = np.abs(beta_coeffs)\n    imp_wald = np.abs(np.divide(beta_coeffs, se_beta, out=np.zeros_like(beta_coeffs), where=se_beta != 0))\n    \n    covariate_indices = np.arange(p)\n    \n    # Ranking with tie-breaking: higher value -> higher rank. Tie -> smaller index -> smaller rank.\n    # Sort by (value, index) to achieve this.\n    sorted_by_coef = sorted(covariate_indices, key=lambda j: (imp_coef[j], j))\n    rank_coef = np.empty(p, dtype=int); rank_coef[sorted_by_coef] = np.arange(1, p + 1)\n    \n    sorted_by_wald = sorted(covariate_indices, key=lambda j: (imp_wald[j], j))\n    rank_wald = np.empty(p, dtype=int); rank_wald[sorted_by_wald] = np.arange(1, p + 1)\n    \n    rank_comb = (rank_coef + rank_wald) / 2\n    \n    num_to_keep = int(np.ceil((1 - q) * p))\n    # Sort indices by descending combined rank\n    indices_to_keep_sorted_by_rank = np.argsort(-rank_comb)\n    \n    kept_indices = indices_to_keep_sorted_by_rank[:num_to_keep]\n    return np.sort(kept_indices)\n\ndef perform_matching(pscores, T):\n    \"\"\"Performs 1-to-1 nearest neighbor matching without replacement.\"\"\"\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n    \n    if len(treated_indices) = len(control_indices):\n        anchor_indices, target_indices = treated_indices, control_indices\n        is_anchor_treated = True\n    else:\n        anchor_indices, target_indices = control_indices, treated_indices\n        is_anchor_treated = False\n        \n    sorted_anchor_indices = anchor_indices[np.argsort(pscores[anchor_indices])]\n    \n    target_pool = list(target_indices)\n    matched_targets = []\n    \n    for anchor_idx in sorted_anchor_indices:\n        anchor_pscore = pscores[anchor_idx]\n        \n        dists = np.abs(anchor_pscore - pscores[target_pool])\n        min_dist = np.min(dists)\n        \n        # Tie-breaking by smallest original index\n        candidate_pool_indices = np.where(dists == min_dist)[0]\n        candidate_original_indices = [target_pool[i] for i in candidate_pool_indices]\n        best_match_idx = min(candidate_original_indices)\n        \n        matched_targets.append(best_match_idx)\n        target_pool.remove(best_match_idx)\n        \n    matched_targets = np.array(matched_targets)\n    \n    if is_anchor_treated:\n        return sorted_anchor_indices, matched_targets\n    else:\n        return matched_targets, sorted_anchor_indices\n\ndef calculate_msmd(X_orig, matched_treated_indices, matched_control_indices):\n    \"\"\"Calculates the mean absolute standardized mean difference.\"\"\"\n    if len(matched_treated_indices) == 0 or len(matched_control_indices) == 0:\n        return 0.0\n\n    X_matched_treated = X_orig[matched_treated_indices, :]\n    X_matched_control = X_orig[matched_control_indices, :]\n    \n    mean_treated = np.mean(X_matched_treated, axis=0)\n    mean_control = np.mean(X_matched_control, axis=0)\n    \n    # Unbiased sample variance with ddof=1\n    var_treated = np.var(X_matched_treated, axis=0, ddof=1)\n    var_control = np.var(X_matched_control, axis=0, ddof=1)\n    \n    pooled_sd = np.sqrt((var_treated + var_control) / 2)\n    \n    smds = np.divide(mean_treated - mean_control, pooled_sd, out=np.zeros_like(pooled_sd), where=pooled_sd != 0)\n    \n    return np.mean(np.abs(smds))\n\ndef run_single_case(n, p, rho, seed, beta_star, alpha_0, q):\n    \"\"\"Executes the full pipeline for one test case.\"\"\"\n    # 1. Data Generation\n    X_orig, T = generate_data(n, p, rho, seed, beta_star, alpha_0)\n    \n    # 2. Standardization\n    X_mean = np.mean(X_orig, axis=0)\n    X_std = np.std(X_orig, axis=0)\n    X_std[X_std == 0] = 1.0  # Avoid division by zero for constant covariates\n    X_norm = (X_orig - X_mean) / X_std\n\n    # --- FULL MODEL ANALYSIS ---\n    beta_full, cov_beta_full = fit_logistic_irls(X_norm, T)\n    X_aug_full = np.hstack([np.ones((n, 1)), X_norm])\n    pscores_full = 1 / (1 + np.exp(-(X_aug_full @ beta_full)))\n    matched_treated_full, matched_control_full = perform_matching(pscores_full, T)\n    msmd_full = calculate_msmd(X_orig, matched_treated_full, matched_control_full)\n\n    # --- PRUNED MODEL ANALYSIS ---\n    indices_to_keep = get_pruning_indices(beta_full, cov_beta_full, p, q)\n    if len(indices_to_keep) > 0:\n        X_norm_pruned = X_norm[:, indices_to_keep]\n        beta_pruned, _ = fit_logistic_irls(X_norm_pruned, T)\n        X_aug_pruned = np.hstack([np.ones((n, 1)), X_norm_pruned])\n        pscores_pruned = 1 / (1 + np.exp(-(X_aug_pruned @ beta_pruned)))\n    else: # If all covariates are pruned, pscore is constant (based on intercept only)\n        beta_pruned_intercept_only, _ = fit_logistic_irls(np.empty((n,0)), T)\n        pscores_pruned = np.full(n, 1 / (1 + np.exp(-beta_pruned_intercept_only[0])))\n\n    matched_treated_pruned, matched_control_pruned = perform_matching(pscores_pruned, T)\n    msmd_pruned = calculate_msmd(X_orig, matched_treated_pruned, matched_control_pruned)\n    \n    # --- Final Result ---\n    delta = msmd_pruned - msmd_full\n    return delta\n\ndef solve():\n    \"\"\"Main function to run test suite and print results.\"\"\"\n    test_cases = [\n        # Test case A\n        dict(n=400, p=6, rho=0.3, seed=2021, beta_star=np.array([0.8, -0.7, 0.6, 0.0, 0.0, 0.0]), alpha_0=0.0, q=0.5),\n        # Test case B\n        dict(n=300, p=5, rho=0.2, seed=7, beta_star=np.array([0.0, 0.0, 0.0, 0.0, 0.0]), alpha_0=0.0, q=0.4),\n        # Test case C\n        dict(n=500, p=5, rho=0.9, seed=99, beta_star=np.array([1.0, 0.0, 0.0, 0.0, 0.0]), alpha_0=-0.2, q=0.6)\n    ]\n    \n    results = []\n    for params in test_cases:\n        delta = run_single_case(**params)\n        results.append(f\"{delta:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在真实的观察性研究中，我们常常需要处理混合类型的协变量，并对其中一些关键变量（如性别、地区）实现完美均衡。这个练习将向你介绍一种更复杂但非常实用的匹配策略：混合匹配。你将学习如何编程实现一个算法，该算法在关键的分类协变量上强制执行精确匹配，同时在连续变量和倾向性得分上使用卡尺（caliper）进行近似匹配。这种方法极大地增强了匹配在现实世界应用中的灵活性和有效性。",
            "id": "3163024",
            "problem": "您的任务是实现一个匹配程序，该程序对关键的分类混杂因素强制执行精确匹配，同时允许在连续协变量上存在卡尺内的差异。目标是评估平均处理效应（ATE）的偏差。从潜在结果框架和倾向得分的定义开始。在您的算法设计中，必须从第一性原理出发对平均处理效应（ATE）和倾向得分匹配（PSM）进行推理。\n\n考虑以下纯粹用数学术语定义的数据生成过程。对于每个单元 $i$，令 $X_i$ 为一个连续协变量，$C_{1,i}\\in\\{0,1\\}$ 为一个二元分类混杂因素，$C_{2,i}\\in\\{0,1,2\\}$ 为一个三元分类混杂因素，$T_i\\in\\{0,1\\}$ 为处理指标，$Y_i(0),Y_i(1)$ 为潜在结果。令 $\\varepsilon_i$ 为一个独立的噪声项。\n\n定义混杂因素和协变量：\n- $C_{1,i} \\sim \\mathrm{Bernoulli}(0.5)$。\n- $C_{2,i} \\in \\{0,1,2\\}$ 且 $\\Pr(C_{2,i}=0)=0.4$, $\\Pr(C_{2,i}=1)=0.4$, $\\Pr(C_{2,i}=2)=0.2$。\n- $X_i \\sim \\mathcal{N}(\\mu_i, 1)$，其中 $\\mu_i = 0.5\\,C_{1,i} + 0.3\\,\\mathbb{1}\\{C_{2,i}=1\\} - 0.3\\,\\mathbb{1}\\{C_{2,i}=2\\}$。\n\n使用逻辑函数 $\\sigma(u) = 1/(1+\\exp(-u))$ 定义处理分配：\n$$\n\\Pr(T_i=1 \\mid X_i, C_{1,i}, C_{2,i}) \n= \\sigma\\!\\Big(\\alpha_0 + \\alpha_X X_i + \\alpha_{C_1} C_{1,i} + \\alpha_{C_2,1}\\,\\mathbb{1}\\{C_{2,i}=1\\} + \\alpha_{C_2,2}\\,\\mathbb{1}\\{C_{2,i}=2\\}\\Big),\n$$\n固定系数为 $\\alpha_0=0.2$, $\\alpha_X=0.8$, $\\alpha_{C_1}=0.6$, $\\alpha_{C_2,1}=0.4$, $\\alpha_{C_2,2}=-0.4$。\n\n定义潜在结果和观测结果：\n- $\\varepsilon_i \\sim \\mathcal{N}(0,1)$ 独立同分布。\n- $Y_i(0) = \\gamma_0 + \\gamma_X X_i + \\gamma_{C_1} C_{1,i} + \\gamma_{C_2,1}\\,\\mathbb{1}\\{C_{2,i}=1\\} + \\gamma_{C_2,2}\\,\\mathbb{1}\\{C_{2,i}=2\\} + \\varepsilon_i$，其中 $\\gamma_0=1.0$, $\\gamma_X=1.0$, $\\gamma_{C_1}=0.5$, $\\gamma_{C_2,1}=0.2$, $\\gamma_{C_2,2}=-0.2$。\n- $Y_i(1) = Y_i(0) + \\tau$，其中 $\\tau=2.0$。\n- $Y_i = T_i\\,Y_i(1) + (1-T_i)\\,Y_i(0)$。\n\n倾向得分是 $e(X_i,C_{1,i},C_{2,i})=\\Pr(T_i=1\\mid X_i,C_{1,i},C_{2,i})$。在您的程序中，您必须通过使用最大似然法的逻辑回归来估计倾向得分，使用包含截距项和协变量 $(X_i, C_{1,i}, \\mathbb{1}\\{C_{2,i}=1\\}, \\mathbb{1}\\{C_{2,i}=2\\})$ 的设计矩阵。\n\n实现以下匹配规则：\n- 对于每个处理单元 $i$（$T_i=1$），找到至多一个控制单元 $j$（$T_j=0$），使得 $C_{1,j}=C_{1,i}$ 和 $C_{2,j}=C_{2,i}$（在两个分类混杂因素上进行精确匹配）。\n- 对连续协变量和倾向得分施加卡尺限制：$|X_i - X_j| \\le \\delta_x$ 和 $|e_i - e_j| \\le \\delta_p$，其中 $e_k$ 表示单元 $k$ 的估计倾向得分。\n- 在单元 $i$ 的所有合格控制候选项中，选择使 $|e_i - e_j|$ 最小化的那一个。进行无放回匹配。\n\n计算估计的 ATE，即匹配的处理组与控制组观测结果差异的均值，记为 $\\widehat{\\mathrm{ATE}}$。计算偏差为 $\\widehat{\\mathrm{ATE}} - \\tau$。\n\n您的程序必须实现上述逻辑，并对以下每个测试用例评估偏差，这些用例共同构成了测试套件：\n- 用例 1：$(\\text{seed}=101, N=800, \\delta_p=0.05, \\delta_x=0.5)$。\n- 用例 2：$(\\text{seed}=202, N=800, \\delta_p=0.02, \\delta_x=0.1)$。\n- 用例 3：$(\\text{seed}=303, N=800, \\delta_p=0.20, \\delta_x=2.0)$。\n- 用例 4：$(\\text{seed}=404, N=120, \\delta_p=0.05, \\delta_x=0.5)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。每个条目必须是对应案例的偏差，表示为四舍五入到六位小数的浮点数（例如，$[0.012345,-0.004321,0.000000,0.123456]$）。",
            "solution": "该问题要求实现一个倾向得分匹配算法，以在一个模拟的观察性研究中估计平均处理效应（ATE）的偏差。解决方案将从因果推断的第一性原理推导得出，特别是潜在结果框架。\n\n### 因果推断的基本原理\n\n此问题的基础在于潜在结果框架，通常称为 Neyman-Rubin 因果模型。对于每个单元 $i$，我们定义两个潜在结果：$Y_i(1)$，即单元接受处理时的结果；以及 $Y_i(0)$，即单元未接受处理时的结果。对于单元 $i$，处理的因果效应是其潜在结果之差，$Y_i(1) - Y_i(0)$。\n\n我们关注的核心估计量是平均处理效应（ATE），定义为该单元级效应在整个群体上的期望值：\n$$\n\\mathrm{ATE} = \\mathbb{E}[Y_i(1) - Y_i(0)]\n$$\n在给定的特定数据生成过程中，我们有 $Y_i(1) = Y_i(0) + \\tau$，其中 $\\tau = 2.0$ 是一个常数。因此，ATE 就是 $\\tau$。\n\n因果推断的基本问题在于，对于任何给定的单元 $i$，我们只能观察到两个潜在结果中的一个。观察到的结果 $Y_i$ 由下式给出：\n$$\nY_i = T_i Y_i(1) + (1-T_i) Y_i(0)\n$$\n\n### 混杂与倾向得分的作用\n\n在非随机研究中，处理分配通常受处理前协变量的影响。如果这些协变量也影响潜在结果，它们就被称为混杂因素。对处理组和控制组之间平均结果的简单比较，即 $\\mathbb{E}[Y_i | T_i=1] - \\mathbb{E}[Y_i | T_i=0]$，并不能估计 ATE。相反，由于两组之间协变量的系统性差异，这个比较是有偏的。在这个问题中，协变量是 $\\mathbf{Z}_i = (X_i, C_{1,i}, C_{2,i})$，它们既影响处理分配 $\\Pr(T_i=1 \\mid \\mathbf{Z}_i)$，也影响潜在结果 $Y_i(0)$ 和 $Y_i(1)$。\n\n为了克服这种混杂偏差，我们依赖于**无混杂性**（或条件可忽略性）假设。该假设指出，在给定协变量 $\\mathbf{Z}_i$ 的条件下，处理分配独立于潜在结果：\n$$\n(Y_i(0), Y_i(1)) \\perp T_i \\mid \\mathbf{Z}_i\n$$\n在给定的数据生成过程中，此假设通过设计得以成立。在无混杂性假设下，我们可以通过对协变量进行调整来识别 ATE。\n\n一个用于此调整的强大工具是**倾向得分**，由 Rosenbaum 和 Rubin 定义为在给定协变量的情况下接受处理的条件概率：\n$$\ne(\\mathbf{Z}_i) = \\Pr(T_i=1 \\mid \\mathbf{Z}_i)\n$$\n倾向得分的关键特性是，如果在给定 $\\mathbf{Z}_i$ 的情况下无混杂性成立，那么在给定标量倾向得分 $e(\\mathbf{Z}_i)$ 的情况下，该假设也成立，前提是 $0  e(\\mathbf{Z}_i)  1$（正值性或重叠假设）。这种降维至关重要，因为它允许我们通过对单个变量（倾向得分）进行匹配或分层来控制混杂，而不是对整个可能高维的协变量集 $\\mathbf{Z}_i$ 进行控制。\n\n### 算法设计\n\n解决方案涉及一系列步骤：数据生成、倾向得分估计、匹配，最后是 ATE 估计和偏差计算。\n\n**1. 数据生成**\n根据指定的随机过程生成一个大小为 $N$ 的数据集。对于每个单元 $i=1, \\dots, N$：\n- 抽取分类混杂因素 $C_{1,i} \\sim \\mathrm{Bernoulli}(0.5)$ 和 $C_{2,i}$ 从其离散分布中抽取。\n- 抽取连续协变量 $X_i \\sim \\mathcal{N}(\\mu_i, 1)$，其中 $\\mu_i$ 依赖于 $C_{1,i}$ 和 $C_{2,i}$。\n- 使用给定的逻辑函数和系数 $(\\alpha_0, \\alpha_X, \\alpha_{C_1}, \\ldots)$ 计算真实的倾向得分。\n- 分配处理 $T_i \\sim \\mathrm{Bernoulli}(\\Pr(T_i=1 \\mid X_i, C_{1,i}, C_{2,i}))$。\n- 基于涉及协变量和噪声项 $\\varepsilon_i \\sim \\mathcal{N}(0,1)$ 的线性模型生成潜在结果 $Y_i(0)$。潜在结果 $Y_i(1)$ 是 $Y_i(0) + \\tau$。\n- 根据 $T_i$ 确定观察结果 $Y_i$。\n\n**2. 倾向得分估计**\n虽然在此模拟中真实的倾向得分函数是已知的，但标准做法是从观测数据中估计它。问题指定使用逻辑回归。\n- 为 $N$ 个观测值构建一个设计矩阵 $\\mathbf{M}$。每一行 $\\mathbf{M}_i$ 对应于单元 $i$，并包含一个截距项和模型中使用的协变量：$(1, X_i, C_{1,i}, \\mathbb{1}\\{C_{2,i}=1\\}, \\mathbb{1}\\{C_{2,i}=2\\})$。\n- 逻辑模型将处理概率预测为 $p_i(\\boldsymbol{\\beta}) = \\sigma(\\mathbf{M}_i \\cdot \\boldsymbol{\\beta})$，其中 $\\sigma(u)$ 是 sigmoid 函数，$\\boldsymbol{\\beta}$ 是待估计的系数向量。\n- 系数 $\\hat{\\boldsymbol{\\beta}}$ 通过数值优化最大化对数似然函数来找到。这等同于最小化负对数似然：\n$$\n\\mathcal{L}(\\boldsymbol{\\beta}) = -\\sum_{i=1}^N \\left[ T_i \\log(p_i(\\boldsymbol{\\beta})) + (1-T_i) \\log(1 - p_i(\\boldsymbol{\\beta})) \\right]\n$$\n- 高效优化所需的负对数似然的梯度是：\n$$\n-\\nabla_{\\boldsymbol{\\beta}} \\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^N (T_i - p_i(\\boldsymbol{\\beta})) \\mathbf{M}_i = \\mathbf{M}^T (\\mathbf{T} - \\mathbf{p}(\\boldsymbol{\\beta}))\n$$\n- 一旦获得 $\\hat{\\boldsymbol{\\beta}}$，每个单元的估计倾向得分就计算为 $\\hat{e}_i = \\sigma(\\mathbf{M}_i \\cdot \\hat{\\boldsymbol{\\beta}})$。\n\n**3. 匹配过程**\n任务的核心是实现指定的匹配算法。目标是为每个处理单元找到一个控制对应项。这是一种带有额外约束的贪心最近邻匹配，且无放回地执行。\n- 数据集被划分为处理组（$T_i=1$）和控制组（$T_i=0$）。\n- 对于每个处理单元 $i$：\n    a. 从所有可用的（未匹配的）控制单元 $j$ 中形成一个候选控制池。\n    b. 根据匹配规则对池进行筛选：\n        - **精确匹配：** $C_{1,j} = C_{1,i}$ 且 $C_{2,j} = C_{2,i}$。\n        - **协变量卡尺：** $|X_i - X_j| \\le \\delta_x$。\n        - **倾向得分卡尺：** $|\\hat{e}_i - \\hat{e}_j| \\le \\delta_p$。\n    c. 如果最终的合格控制池不为空，则选择使倾向得分距离 $|\\hat{e}_i - \\hat{e}_{j^*}|$ 最小的控制单元 $j^*$ 作为匹配项。\n    d. 记录配对 $(i, j^*)$，并将控制单元 $j^*$ 标记为不可用于未来的匹配。\n    e. 如果没有找到合格的控制单元，则丢弃处理单元 $i$。\n\n**4. ATE 估计和偏差计算**\n- 匹配过程完成后，得到一组 $N_{\\text{matched}}$ 配对。\n- 估计的 ATE 计算为这些配对内结果差异的简单平均值：\n$$\n\\widehat{\\mathrm{ATE}} = \\frac{1}{N_{\\text{matched}}} \\sum_{(i,j) \\in \\text{matched pairs}} (Y_i - Y_j)\n$$\n- 该估计量是处理组平均处理效应（ATT）的一个近似。在此问题的恒定处理效应假设下，ATT = ATE。\n- 最后，通过将估计量与真实的 ATE（$\\tau=2.0$）进行比较来计算其偏差：\n$$\n\\text{Bias} = \\widehat{\\mathrm{ATE}} - \\tau\n$$\n对于由不同随机种子、样本大小和卡尺宽度定义的四个测试用例中的每一个，都重复这整个过程。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        (101, 800, 0.05, 0.5),\n        (202, 800, 0.02, 0.1),\n        (303, 800, 0.20, 2.0),\n        (404, 120, 0.05, 0.5),\n    ]\n\n    tau = 2.0\n    results = []\n\n    for seed, n_samples, delta_p, delta_x in test_cases:\n        bias = calculate_bias(seed, n_samples, delta_p, delta_x, tau)\n        results.append(f\"{bias:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_bias(seed, n_samples, delta_p, delta_x, tau):\n    \"\"\"\n    Calculates the bias of the ATE estimator for a single simulation case.\n    \"\"\"\n    # 1. Generate data\n    data = generate_data(seed, n_samples, tau)\n    X, C1, C2, T, Y = data['X'], data['C1'], data['C2'], data['T'], data['Y']\n    \n    # 2. Estimate propensity scores\n    e_hat = estimate_propensity_scores(X, C1, C2, T)\n    \n    # 3. Perform matching\n    matched_diffs = perform_matching(X, C1, C2, T, Y, e_hat, delta_p, delta_x)\n    \n    # 4. Calculate ATE and bias\n    if not matched_diffs:\n        ate_hat = 0.0\n    else:\n        ate_hat = np.mean(matched_diffs)\n    \n    bias = ate_hat - tau\n    return bias\n\ndef generate_data(seed, n_samples, tau):\n    \"\"\"\n    Generates data according to the problem's data-generating process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Confounders\n    C1 = rng.binomial(1, 0.5, size=n_samples)\n    C2 = rng.choice([0, 1, 2], size=n_samples, p=[0.4, 0.4, 0.2])\n    \n    mu = 0.5 * C1 + 0.3 * (C2 == 1) - 0.3 * (C2 == 2)\n    X = rng.normal(loc=mu, scale=1, size=n_samples)\n    \n    # Treatment assignment\n    alpha_0, alpha_X, alpha_C1 = 0.2, 0.8, 0.6\n    alpha_C2_1, alpha_C2_2 = 0.4, -0.4\n    \n    linear_pred_T = alpha_0 + alpha_X * X + alpha_C1 * C1 + \\\n                    alpha_C2_1 * (C2 == 1) + alpha_C2_2 * (C2 == 2)\n    propensity_true = 1 / (1 + np.exp(-linear_pred_T))\n    T = rng.binomial(1, propensity_true, size=n_samples)\n    \n    # Potential outcomes\n    gamma_0, gamma_X, gamma_C1 = 1.0, 1.0, 0.5\n    gamma_C2_1, gamma_C2_2 = 0.2, -0.2\n    \n    epsilon = rng.normal(0, 1, size=n_samples)\n    Y0 = gamma_0 + gamma_X * X + gamma_C1 * C1 + \\\n         gamma_C2_1 * (C2 == 1) + gamma_C2_2 * (C2 == 2) + epsilon\n    Y1 = Y0 + tau\n    \n    # Observed outcome\n    Y = T * Y1 + (1 - T) * Y0\n    \n    return {'X': X, 'C1': C1, 'C2': C2, 'T': T, 'Y': Y}\n\ndef estimate_propensity_scores(X, C1, C2, T):\n    \"\"\"\n    Estimates propensity scores using logistic regression with MLE.\n    \"\"\"\n    # Design matrix M\n    M = np.c_[np.ones(len(X)), X, C1, (C2 == 1).astype(int), (C2 == 2).astype(int)]\n    \n    def sigmoid(u):\n        return 1 / (1 + np.exp(-u))\n\n    def neg_log_likelihood(beta, M, T):\n        p = sigmoid(M @ beta)\n        # Add small epsilon to prevent log(0)\n        p = np.clip(p, 1e-9, 1 - 1e-9)\n        return -np.sum(T * np.log(p) + (1 - T) * np.log(1 - p))\n\n    def gradient(beta, M, T):\n        p = sigmoid(M @ beta)\n        return M.T @ (p - T)\n\n    initial_beta = np.zeros(M.shape[1])\n    res = minimize(neg_log_likelihood, initial_beta, args=(M, T), jac=gradient, method='BFGS')\n    \n    beta_hat = res.x\n    e_hat = sigmoid(M @ beta_hat)\n    \n    return e_hat\n\ndef perform_matching(X, C1, C2, T, Y, e_hat, delta_p, delta_x):\n    \"\"\"\n    Performs matching based on exact confounder match and calipers.\n    \"\"\"\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n    \n    control_data = {\n        'C1': C1[control_indices],\n        'C2': C2[control_indices],\n        'X': X[control_indices],\n        'e_hat': e_hat[control_indices]\n    }\n    \n    is_control_available = np.ones(len(control_indices), dtype=bool)\n    matched_diffs = []\n\n    for i in treated_indices:\n        # Candidate controls must be available and match exactly on C1, C2\n        eligible_mask = (is_control_available)  \\\n                        (control_data['C1'] == C1[i])  \\\n                        (control_data['C2'] == C2[i])\n        \n        # Apply calipers\n        eligible_mask = (np.abs(control_data['X'] - X[i]) = delta_x)\n        eligible_mask = (np.abs(control_data['e_hat'] - e_hat[i]) = delta_p)\n        \n        candidate_control_local_indices = np.where(eligible_mask)[0]\n        \n        if len(candidate_control_local_indices) > 0:\n            # Find the best match among eligible candidates (nearest neighbor on propensity score)\n            prop_diffs = np.abs(control_data['e_hat'][candidate_control_local_indices] - e_hat[i])\n            best_match_local_idx = candidate_control_local_indices[np.argmin(prop_diffs)]\n            \n            # Get the global index of the matched control\n            best_match_global_idx = control_indices[best_match_local_idx]\n            \n            # Record the matched difference and update control availability\n            matched_diffs.append(Y[i] - Y[best_match_global_idx])\n            is_control_available[best_match_local_idx] = False\n            \n    return matched_diffs\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}