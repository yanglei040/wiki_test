{
    "hands_on_practices": [
        {
            "introduction": "Estimating a single value for a quantile is often just the first step in a statistical analysis. To use this estimate responsibly, particularly in fields like finance and risk management, we must also quantify its uncertainty. This exercise  provides hands-on practice with the delta method, a fundamental technique for propagating the variance of an initial estimator—in this case, an empirical quantile—to a downstream metric that depends on it. By working through this calculation, you will gain a deeper appreciation for the principles of statistical inference and the tools used to assess the reliability of data-driven conclusions.",
            "id": "3177964",
            "problem": "A dataset of $n$ normalized daily loss magnitudes is given by\n$0.80,\\, 0.55,\\, 1.20,\\, 0.30,\\, 0.95,\\, 0.67,\\, 1.50,\\, 0.40,\\, 0.72,\\, 0.88,\\, 1.10,\\, 0.33,\\, 0.60,\\, 0.77,\\, 0.25,\\, 1.30,\\, 0.52,\\, 0.66,\\, 0.90,\\, 0.45$.\nYou are tasked to estimate a high-quantile risk and quantify its uncertainty using fundamental definitions, then validate the magnitude of your uncertainty estimate against a nonparametric bootstrap summary.\n\nUsing the empirical cumulative distribution function (CDF; cumulative distribution function) inversion, estimate the $p$-quantile with $p = 0.90$ from the sample. Define the downstream risk metric as $R(q) = \\exp(\\beta q)$ with $\\beta = 0.50$, evaluated at your empirical quantile estimate. Starting from first principles, use the delta method to derive and compute the standard error of $\\widehat{R}$ by propagating the uncertainty in the empirical quantile through $R(\\cdot)$. To estimate the density $f(q)$ at the quantile for the variance of the sample quantile, use the symmetric spacing of nearest order statistics (that is, approximate $f(q)$ locally by the finite difference of the empirical CDF across $x_{(r-1)}$ and $x_{(r+1)}$, where $r$ is the index of the empirical $p$-quantile). As a magnitude check, a nonparametric bootstrap with $B = 1000$ resamples yields a sample standard deviation of the risk metric of $0.121$.\n\nCompute and report the delta-method standard error of $\\widehat{R}$, and round your answer to four significant figures. No physical units are involved; provide a unitless numerical value.",
            "solution": "The posed problem is subject to validation.\n\n### Step 1: Extract Givens\nThe dataset of $n$ normalized daily loss magnitudes is given as: $X = \\{0.80,\\, 0.55,\\, 1.20,\\, 0.30,\\, 0.95,\\, 0.67,\\, 1.50,\\, 0.40,\\, 0.72,\\, 0.88,\\, 1.10,\\, 0.33,\\, 0.60,\\, 0.77,\\, 0.25,\\, 1.30,\\, 0.52,\\, 0.66,\\, 0.90,\\, 0.45\\}$.\nThe sample size, by inspection, is $n=20$.\nThe quantile level to be estimated is $p = 0.90$.\nThe method for quantile estimation is empirical cumulative distribution function (CDF) inversion.\nThe risk metric is defined as the function $R(q) = \\exp(\\beta q)$.\nThe parameter for the risk metric is $\\beta = 0.50$.\nThe standard error of the estimated risk metric, $\\widehat{R}$, is to be computed using the delta method.\nThe method for estimating the probability density function $f(q)$ at the quantile is specified as the symmetric spacing of nearest order statistics: approximate $f(q)$ by the finite difference of the empirical CDF across $x_{(r-1)}$ and $x_{(r+1)}$, where $r$ is the index of the empirical $p$-quantile.\nA validation value from a nonparametric bootstrap with $B=1000$ resamples is given as a sample standard deviation of $0.121$.\nThe final answer is to be the delta-method standard error of $\\widehat{R}$, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, employing standard and well-established statistical methods like empirical quantiles, the delta method for variance approximation, and density estimation from order statistics. These are fundamental techniques in statistics and its applications, such as quantitative risk management. The problem is well-posed, providing all necessary data, parameters, and methodological definitions required to arrive at a unique solution. The language is objective and precise. The setup is complete and internally consistent, with no missing information or contradictions. The data values are realistic for the context described. The problem falls squarely within the specified topic of summary statistics and quantiles.\n\n### Step 3: Verdict and Action\nThe problem is valid. A reasoned solution will be provided.\n\n### Solution\nThe objective is to compute the standard error of an estimated risk metric, $\\widehat{R} = R(\\widehat{q}_p)$, using the delta method. The process involves several steps: finding the sample quantile, deriving the form of the delta method approximation for the standard error, estimating the components of this approximation, and finally computing the numerical value.\n\nFirst, we must determine the sample size and sort the given data to find the order statistics, $x_{(i)}$. The sample size is $n = 20$. The sorted dataset is:\n$x_{(1)} = 0.25$, $x_{(2)} = 0.30$, $x_{(3)} = 0.33$, $x_{(4)} = 0.40$, $x_{(5)} = 0.45$,\n$x_{(6)} = 0.52$, $x_{(7)} = 0.55$, $x_{(8)} = 0.60$, $x_{(9)} = 0.66$, $x_{(10)} = 0.67$,\n$x_{(11)} = 0.72$, $x_{(12)} = 0.77$, $x_{(13)} = 0.80$, $x_{(14)} = 0.88$, $x_{(15)} = 0.90$,\n$x_{(16)} = 0.95$, $x_{(17)} = 1.10$, $x_{(18)} = 1.20$, $x_{(19)} = 1.30$, $x_{(20)} = 1.50$.\n\nThe problem specifies estimating the $p=0.90$ quantile, $\\widehat{q}_{0.90}$, using empirical CDF inversion. A common definition for the sample $p$-quantile is the $r$-th order statistic, where $r = \\lceil n \\cdot p \\rceil$.\nFor $n=20$ and $p=0.90$, the index is:\n$$r = \\lceil 20 \\times 0.90 \\rceil = \\lceil 18 \\rceil = 18$$\nThus, the estimated $0.90$-quantile is the $18$-th order statistic:\n$$\\widehat{q}_{0.90} = x_{(18)} = 1.20$$\n\nThe risk metric is $R(q) = \\exp(\\beta q)$ with $\\beta=0.50$. The estimated risk is:\n$$\\widehat{R} = R(\\widehat{q}_{0.90}) = \\exp(0.50 \\times 1.20) = \\exp(0.60)$$\n\nThe delta method approximates the variance of a function $g(\\widehat{\\theta})$ of an estimator $\\widehat{\\theta}$. For a univariate estimator, the approximation is $\\text{Var}(g(\\widehat{\\theta})) \\approx [g'(\\theta)]^2 \\text{Var}(\\widehat{\\theta})$.\nIn our context, $\\widehat{\\theta}$ is the sample quantile $\\widehat{q}_p$ and $g(\\cdot)$ is the risk function $R(\\cdot)$. Thus, the variance of $\\widehat{R}$ is:\n$$\\text{Var}(\\widehat{R}) \\approx [R'(q_p)]^2 \\text{Var}(\\widehat{q}_p)$$\nwhere $q_p$ is the true population quantile. The standard error is the square root of the variance.\n\nFirst, we find the derivative of $R(q)$:\n$$R'(q) = \\frac{d}{dq} \\exp(\\beta q) = \\beta \\exp(\\beta q)$$\nWe evaluate this using our estimates:\n$$R'(\\widehat{q}_{0.90}) = 0.50 \\times \\exp(0.50 \\times 1.20) = 0.50 \\exp(0.60)$$\n\nNext, we need the variance of the sample quantile, $\\text{Var}(\\widehat{q}_p)$. The large-sample approximation for this variance is:\n$$\\text{Var}(\\widehat{q}_p) \\approx \\frac{p(1-p)}{n [f(q_p)]^2}$$\nwhere $f(q_p)$ is the value of the probability density function at the true quantile $q_p$. We need to estimate $f(q_p)$. The problem directs us to use the symmetric spacing of nearest order statistics around our estimated quantile $x_{(r)}$. This gives the density estimate:\n$$\\widehat{f}(x_{(r)}) = \\frac{(r+1)/n - (r-1)/n}{x_{(r+1)} - x_{(r-1)}} = \\frac{2/n}{x_{(r+1)} - x_{(r-1)}}$$\nFor our quantile $\\widehat{q}_{0.90} = x_{(18)}$, we have $r=18$. We need the adjacent order statistics, $x_{(17)}$ and $x_{(19)}$.\nFrom the sorted list, $x_{(17)} = 1.10$ and $x_{(19)} = 1.30$.\nSubstituting these values with $n=20$:\n$$\\widehat{f}(\\widehat{q}_{0.90}) = \\frac{2/20}{x_{(19)} - x_{(17)}} = \\frac{0.1}{1.30 - 1.10} = \\frac{0.1}{0.2} = 0.50$$\n\nNow we can estimate the variance of the sample quantile:\n$$\\widehat{\\text{Var}}(\\widehat{q}_{0.90}) = \\frac{p(1-p)}{n [\\widehat{f}(\\widehat{q}_{0.90})]^2} = \\frac{0.90 \\times (1-0.90)}{20 \\times (0.50)^2} = \\frac{0.09}{20 \\times 0.25} = \\frac{0.09}{5} = 0.018$$\n\nFinally, we combine these results to find the variance of the estimated risk metric $\\widehat{R}$:\n$$\\widehat{\\text{Var}}(\\widehat{R}) \\approx [R'(\\widehat{q}_{0.90})]^2 \\widehat{\\text{Var}}(\\widehat{q}_{0.90})$$\n$$\\widehat{\\text{Var}}(\\widehat{R}) \\approx [0.50 \\exp(0.60)]^2 \\times 0.018$$\nThe standard error, $\\text{SE}(\\widehat{R})$, is the square root of the variance:\n$$\\text{SE}(\\widehat{R}) = \\sqrt{\\widehat{\\text{Var}}(\\widehat{R})} \\approx \\sqrt{[0.50 \\exp(0.60)]^2 \\times 0.018}$$\n$$\\text{SE}(\\widehat{R}) \\approx |0.50 \\exp(0.60)| \\sqrt{0.018} = 0.50 \\exp(0.60) \\sqrt{0.018}$$\nNow we compute the numerical value:\n$$\\exp(0.60) \\approx 1.8221188$$\n$$\\sqrt{0.018} \\approx 0.1341640786$$\n$$\\text{SE}(\\widehat{R}) \\approx 0.50 \\times 1.8221188 \\times 0.1341640786 \\approx 0.122235$$\nRounding to four significant figures, we get $0.1222$. This value is consistent with the provided bootstrap estimate of $0.121$, confirming the reasonableness of our calculation.",
            "answer": "$$\\boxed{0.1222}$$"
        },
        {
            "introduction": "While the concept of a quantile is clear in theory, its computation from a finite data sample involves choices, especially regarding how to handle values that fall between observed data points. This practice  explores the real-world consequences of these choices by examining how different standard interpolation methods for empirical quantiles can alter outcomes in a sensitive application like algorithmic fairness. This coding exercise demonstrates that seemingly minor methodological decisions are not merely academic; they can have a significant and tangible impact on results, underscoring the importance of transparent and carefully justified methods.",
            "id": "3177907",
            "problem": "You are given two finite sets of real-valued scores representing two demographic groups, and a global decision rule that accepts an individual if and only if their score is greater than or equal to a threshold defined by a specified empirical quantile of the pooled scores across both groups. The primary goal is to compare empirical quantiles computed under different interpolation rules and quantify their downstream effect on a fairness metric that uses percentile thresholds.\n\nStarting point and definitions:\n- Let $X$ be a real-valued random variable with cumulative distribution function (CDF) $F(x) = \\mathbb{P}(X \\le x)$. For a quantile level $q \\in [0,1]$, the $q$-quantile is any value $x_q$ such that $F(x_q) \\ge q$ and $F(x_q^{-}) \\le q$, where $x_q^{-}$ denotes the limit from the left.\n- Given a finite sample of size $n$, the empirical cumulative distribution function (ECDF) is $F_n(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\{X_i \\le x\\}$, where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function and $X_i$ are the observed scores. The empirical $q$-quantile is defined using $F_n$ and an interpolation rule that specifies how to handle non-integer ranks between neighboring order statistics.\n- Interpolation rules to be compared are the following widely used conventions: \"lower\" (choose the greatest observed value not exceeding the target rank), \"higher\" (choose the smallest observed value not less than the target rank), \"nearest\" (choose the closest observed rank), \"midpoint\" (average of the neighboring observed values bracketing the target rank), and \"linear\" (linear interpolation between the two neighboring observed values according to the fractional part of the target rank). All rules operate on the sorted pooled scores and differ only in how they resolve fractional ranks between order statistics.\n\nFairness metric to evaluate:\n- The fairness metric is the Demographic Parity (DP) difference. For groups $\\mathcal{A}$ and $\\mathcal{B}$ with acceptance rates $r_{\\mathcal{A}}$ and $r_{\\mathcal{B}}$, define the DP difference as $d = |r_{\\mathcal{A}} - r_{\\mathcal{B}}|$. Acceptance rates must be expressed as decimal fractions (for example, $0.6$ for sixty percent).\n- Acceptance is determined by a global threshold $T_q$ computed as the empirical $q$-quantile of the pooled scores from both groups. An individual is accepted if and only if their score is greater than or equal to $T_q$.\n\nTask:\n- For each test case, compute $T_q$ under each interpolation rule among $\\{\\text{linear}, \\text{lower}, \\text{higher}, \\text{nearest}, \\text{midpoint}\\}$ on the pooled scores of the two groups.\n- For each rule, compute the acceptance rates $r_{\\mathcal{A}}$ and $r_{\\mathcal{B}}$, then the DP difference $d$.\n- Let $d_{\\text{linear}}$ be the DP difference when using the \"linear\" rule. Quantify the effect of interpolation on the fairness metric for that test case by computing\n$$\\Delta = \\max_{m \\in \\{\\text{lower}, \\text{higher}, \\text{nearest}, \\text{midpoint}\\}} \\left| d_{m} - d_{\\text{linear}} \\right|,$$\nwhere $d_{m}$ is the DP difference under method $m$.\n- The final output for the entire test suite is a single list of the $\\Delta$ values, one per test case, printed on a single line as a comma-separated list enclosed in square brackets, for example $[0.0,0.1,0.05]$.\n\nTest suite:\n- Case $1$ (general case):\n  - Group $\\mathcal{A}$ scores: [$0.10$, $0.20$, $0.35$, $0.40$, $0.50$]\n  - Group $\\mathcal{B}$ scores: [$0.05$, $0.25$, $0.30$, $0.45$, $0.55$]\n  - Quantile level $q$: $0.70$\n- Case $2$ (boundary with small sample and median threshold):\n  - Group $\\mathcal{A}$ scores: [$0.20$, $0.80$, $0.90$]\n  - Group $\\mathcal{B}$ scores: [$0.10$, $0.70$, $0.95$]\n  - Quantile level $q$: $0.50$\n- Case $3$ (ties and repeated values):\n  - Group $\\mathcal{A}$ scores: [$0.30$, $0.30$, $0.30$, $0.60$, $0.60$]\n  - Group $\\mathcal{B}$ scores: [$0.40$, $0.40$, $0.40$, $0.40$, $0.70$]\n  - Quantile level $q$: $0.60$\n- Case $4$ (extreme upper quantile):\n  - Group $\\mathcal{A}$ scores: [$0.20$, $0.40$, $0.60$, $0.80$]\n  - Group $\\mathcal{B}$ scores: [$0.10$, $0.30$, $0.50$, $0.70$]\n  - Quantile level $q$: $0.95$\n\nPrecise output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$), where each $r_i$ is the computed $\\Delta$ for the $i$-th test case.",
            "solution": "The problem requires an analysis of the effect of different empirical quantile interpolation methods on a fairness metric, specifically the Demographic Parity (DP) difference. For each provided test case, we must calculate a metric $\\Delta$, which represents the maximum deviation in the DP difference caused by using alternative interpolation methods ('lower', 'higher', 'nearest', 'midpoint') relative to a baseline 'linear' interpolation method.\n\nThe process for each test case is as follows:\n1.  Combine the scores from Group $\\mathcal{A}$ and Group $\\mathcal{B}$ into a single pooled dataset.\n2.  For each of the five specified interpolation methods ($m \\in \\{\\text{linear}, \\text{lower}, \\text{higher}, \\text{nearest}, \\text{midpoint}\\}$), calculate the decision threshold $T_q^{(m)}$. This threshold is the empirical $q$-quantile of the pooled scores, computed using method $m$.\n3.  For each threshold $T_q^{(m)}$, determine the acceptance rates for each group, $r_{\\mathcal{A}}^{(m)}$ and $r_{\\mathcal{B}}^{(m)}$. An individual is accepted if their score is greater than or equal to the threshold. The acceptance rate is the fraction of individuals in a group who are accepted.\n4.  Calculate the DP difference for each method, $d_m = |r_{\\mathcal{A}}^{(m)} - r_{\\mathcal{B}}^{(m)}|$.\n5.  Finally, compute the target metric $\\Delta = \\max_{m \\in \\{\\text{lower}, \\text{higher}, \\text{nearest}, \\text{midpoint}\\}} |d_m - d_{\\text{linear}}|$.\n\nThe core of the calculation is the computation of the empirical $q$-quantile. Let the pooled and sorted sample of size $n$ be denoted by the $0$-indexed sequence $S = (x_0, x_1, \\dots, x_{n-1})$. The quantile value is determined by an index $k = q(n-1)$. Let $i = \\lfloor k \\rfloor$ be the floor and $j = \\lceil k \\rceil$ be the ceiling of this index. The thresholds $T_q$ for the different interpolation methods are then calculated as:\n- Linear: $T_q = x_i + (k-i)(x_j - x_i)$\n- Lower: $T_q = x_i$\n- Higher: $T_q = x_j$\n- Midpoint: $T_q = (x_i + x_j) / 2$\n- Nearest: $T_q = x_{\\text{round}(k)}$, where halves are rounded to the nearest even integer.\n\nWe now apply this methodology to each test case.\n\n**Case 1:**\n- Group $\\mathcal{A}$ scores: [$0.10, 0.20, 0.35, 0.40, 0.50$] ($n_{\\mathcal{A}} = 5$)\n- Group $\\mathcal{B}$ scores: [$0.05, 0.25, 0.30, 0.45, 0.55$] ($n_{\\mathcal{B}} = 5$)\n- Quantile level $q = 0.70$\nThe pooled and sorted scores are $S = (0.05, 0.10, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55)$, with size $n=10$.\nThe index is $k = 0.70 \\times (10-1) = 6.3$. Thus, $i=6$ and $j=7$. The values are $x_6 = 0.40$ and $x_7 = 0.45$.\n- $T_q^{(\\text{linear})} = 0.40 + (6.3-6)(0.45-0.40) = 0.415$.\n  $r_{\\mathcal{A}} = 1/5 = 0.2$, $r_{\\mathcal{B}} = 2/5 = 0.4$. $d_{\\text{linear}} = |0.2 - 0.4| = 0.2$.\n- $T_q^{(\\text{lower})} = x_6 = 0.40$.\n  $r_{\\mathcal{A}} = 2/5 = 0.4$, $r_{\\mathcal{B}} = 2/5 = 0.4$. $d_{\\text{lower}} = |0.4 - 0.4| = 0.0$.\n- $T_q^{(\\text{higher})} = x_7 = 0.45$.\n  $r_{\\mathcal{A}} = 1/5 = 0.2$, $r_{\\mathcal{B}} = 2/5 = 0.4$. $d_{\\text{higher}} = |0.2 - 0.4| = 0.2$.\n- $T_q^{(\\text{nearest})} = x_{\\text{round}(6.3)} = x_6 = 0.40$.\n  $d_{\\text{nearest}} = d_{\\text{lower}} = 0.0$.\n- $T_q^{(\\text{midpoint})} = (0.40+0.45)/2 = 0.425$.\n  $r_{\\mathcal{A}} = 1/5 = 0.2$, $r_{\\mathcal{B}} = 2/5 = 0.4$. $d_{\\text{midpoint}} = |0.2 - 0.4| = 0.2$.\nThe differences from $d_{\\text{linear}}$ are $|0.0 - 0.2| = 0.2$, $|0.2 - 0.2| = 0.0$, $|0.0 - 0.2| = 0.2$, and $|0.2 - 0.2| = 0.0$.\n$\\Delta = \\max(0.2, 0.0, 0.2, 0.0) = 0.2$.\n\n**Case 2:**\n- Group $\\mathcal{A}$ scores: [$0.20, 0.80, 0.90$] ($n_{\\mathcal{A}} = 3$)\n- Group $\\mathcal{B}$ scores: [$0.10, 0.70, 0.95$] ($n_{\\mathcal{B}} = 3$)\n- Quantile level $q = 0.50$\nThe pooled and sorted scores are $S = (0.10, 0.20, 0.70, 0.80, 0.90, 0.95)$, with size $n=6$.\nThe index is $k = 0.50 \\times (6-1) = 2.5$. Thus, $i=2$ and $j=3$. The values are $x_2 = 0.70$ and $x_3 = 0.80$.\n- $T_q^{(\\text{linear})} = 0.70 + (2.5-2)(0.80-0.70) = 0.75$.\n  $r_{\\mathcal{A}} = 2/3$, $r_{\\mathcal{B}} = 1/3$. $d_{\\text{linear}} = |2/3 - 1/3| = 1/3$.\n- $T_q^{(\\text{lower})} = x_2 = 0.70$.\n  $r_{\\mathcal{A}} = 2/3$, $r_{\\mathcal{B}} = 2/3$. $d_{\\text{lower}} = |2/3 - 2/3| = 0.0$.\n- $T_q^{(\\text{higher})} = x_3 = 0.80$.\n  $r_{\\mathcal{A}} = 2/3$, $r_{\\mathcal{B}} = 1/3$. $d_{\\text{higher}} = |2/3 - 1/3| = 1/3$.\n- $T_q^{(\\text{nearest})} = x_{\\text{round}(2.5)} = x_2 = 0.70$.\n  $d_{\\text{nearest}} = d_{\\text{lower}} = 0.0$.\n- $T_q^{(\\text{midpoint})} = (0.70+0.80)/2 = 0.75$.\n  $d_{\\text{midpoint}} = d_{\\text{linear}} = 1/3$.\nThe differences from $d_{\\text{linear}}$ are $|0.0 - 1/3| = 1/3$, $|1/3 - 1/3| = 0.0$, $|0.0 - 1/3| = 1/3$, and $|1/3 - 1/3| = 0.0$.\n$\\Delta = \\max(1/3, 0.0, 1/3, 0.0) = 1/3 \\approx 0.333...$.\n\n**Case 3:**\n- Group $\\mathcal{A}$ scores: [$0.30, 0.30, 0.30, 0.60, 0.60$] ($n_{\\mathcal{A}} = 5$)\n- Group $\\mathcal{B}$ scores: [$0.40, 0.40, 0.40, 0.40, 0.70$] ($n_{\\mathcal{B}} = 5$)\n- Quantile level $q = 0.60$\nThe pooled and sorted scores are $S = (0.30, 0.30, 0.30, 0.40, 0.40, 0.40, 0.40, 0.60, 0.60, 0.70)$, with size $n=10$.\nThe index is $k = 0.60 \\times (10-1) = 5.4$. Thus, $i=5$ and $j=6$. The values are $x_5 = 0.40$ and $x_6 = 0.40$.\nSince $x_i = x_j$, all interpolation methods yield the same threshold $T_q = 0.40$.\nConsequently, $d_m$ is the same for all methods $m$.\nFor $T_q = 0.40$:\n$r_{\\mathcal{A}} = 2/5 = 0.4$.\n$r_{\\mathcal{B}} = 5/5 = 1.0$.\n$d = |0.4 - 1.0| = 0.6$.\nSince $d_m=0.6$ for all $m$, $d_m - d_{\\text{linear}} = 0$ for all other methods.\n$\\Delta = 0.0$.\n\n**Case 4:**\n- Group $\\mathcal{A}$ scores: [$0.20, 0.40, 0.60, 0.80$] ($n_{\\mathcal{A}} = 4$)\n- Group $\\mathcal{B}$ scores: [$0.10, 0.30, 0.50, 0.70$] ($n_{\\mathcal{B}} = 4$)\n- Quantile level $q = 0.95$\nThe pooled and sorted scores are $S = (0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80)$, with size $n=8$.\nThe index is $k = 0.95 \\times (8-1) = 6.65$. Thus, $i=6$ and $j=7$. The values are $x_6 = 0.70$ and $x_7 = 0.80$.\n- $T_q^{(\\text{linear})} = 0.70 + (6.65-6)(0.80-0.70) = 0.765$.\n  $r_{\\mathcal{A}} = 1/4 = 0.25$, $r_{\\mathcal{B}} = 0/4 = 0.0$. $d_{\\text{linear}} = |0.25 - 0.0| = 0.25$.\n- $T_q^{(\\text{lower})} = x_6 = 0.70$.\n  $r_{\\mathcal{A}} = 1/4 = 0.25$, $r_{\\mathcal{B}} = 1/4 = 0.25$. $d_{\\text{lower}} = |0.25 - 0.25| = 0.0$.\n- $T_q^{(\\text{higher})} = x_7 = 0.80$.\n  $r_{\\mathcal{A}} = 1/4 = 0.25$, $r_{\\mathcal{B}} = 0/4 = 0.0$. $d_{\\text{higher}} = |0.25 - 0.0| = 0.25$.\n- $T_q^{(\\text{nearest})} = x_{\\text{round}(6.65)} = x_7 = 0.80$.\n  $d_{\\text{nearest}} = d_{\\text{higher}} = 0.25$.\n- $T_q^{(\\text{midpoint})} = (0.70+0.80)/2 = 0.75$.\n  $r_{\\mathcal{A}} = 1/4 = 0.25$, $r_{\\mathcal{B}} = 0/4 = 0.0$. $d_{\\text{midpoint}} = |0.25 - 0.0| = 0.25$.\nThe differences from $d_{\\text{linear}}$ are $|0.0 - 0.25| = 0.25$, $|0.25 - 0.25| = 0.0$, $|0.25 - 0.25| = 0.0$, and $|0.25 - 0.25| = 0.0$.\n$\\Delta = \\max(0.25, 0.0, 0.0, 0.0) = 0.25$.\n\nThe final calculated $\\Delta$ values for the four test cases are $[0.2, 0.333..., 0.0, 0.25]$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_delta(scores_A, scores_B, q):\n    \"\"\"\n    Computes the maximum impact of quantile interpolation on the DP difference.\n\n    Args:\n        scores_A (list): A list of real-valued scores for group A.\n        scores_B (list): A list of real-valued scores for group B.\n        q (float): The quantile level, between 0 and 1.\n\n    Returns:\n        float: The computed Delta value for the test case.\n    \"\"\"\n    scores_A_np = np.array(scores_A)\n    scores_B_np = np.array(scores_B)\n    \n    n_A = len(scores_A)\n    n_B = len(scores_B)\n\n    # Pool the scores from both groups.\n    pooled_scores = np.concatenate((scores_A_np, scores_B_np))\n    \n    interpolation_methods = ['linear', 'lower', 'higher', 'nearest', 'midpoint']\n    dp_differences = {}\n    \n    for method in interpolation_methods:\n        # Step 1: Compute the decision threshold T_q using the specified interpolation method.\n        # numpy.quantile's 'method' parameter was named 'interpolation' in older versions.\n        T_q = np.quantile(pooled_scores, q, method=method)\n        \n        # Step 2: Compute acceptance rates for each group.\n        # Acceptance is defined as score >= T_q.\n        rate_A = np.sum(scores_A_np >= T_q) / n_A\n        rate_B = np.sum(scores_B_np >= T_q) / n_B\n        \n        # Step 3: Compute the Demographic Parity (DP) difference.\n        d_m = np.abs(rate_A - rate_B)\n        dp_differences[method] = d_m\n        \n    # Step 4: Quantify the effect of interpolation relative to the 'linear' method.\n    d_linear = dp_differences['linear']\n    other_methods = ['lower', 'higher', 'nearest', 'midpoint']\n    \n    max_abs_diff = 0.0\n    for method in other_methods:\n        diff = np.abs(dp_differences[method] - d_linear)\n        if diff > max_abs_diff:\n            max_abs_diff = diff\n            \n    return max_abs_diff\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general case)\n        (\n            [0.10, 0.20, 0.35, 0.40, 0.50],\n            [0.05, 0.25, 0.30, 0.45, 0.55],\n            0.70\n        ),\n        # Case 2 (boundary with small sample and median threshold)\n        (\n            [0.20, 0.80, 0.90],\n            [0.10, 0.70, 0.95],\n            0.50\n        ),\n        # Case 3 (ties and repeated values)\n        (\n            [0.30, 0.30, 0.30, 0.60, 0.60],\n            [0.40, 0.40, 0.40, 0.40, 0.70],\n            0.60\n        ),\n        # Case 4 (extreme upper quantile)\n        (\n            [0.20, 0.40, 0.60, 0.80],\n            [0.10, 0.30, 0.50, 0.70],\n            0.95\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        scores_A, scores_B, q = case\n        delta = calculate_delta(scores_A, scores_B, q)\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Quantiles and percentiles are more than just descriptive summaries; they serve as a powerful tool for data transformation in the machine learning pipeline. This exercise  reveals the utility of converting raw prediction scores into their percentile ranks to create more robust and interpretable model evaluations. You will investigate the rank-based nature of the Area Under the ROC Curve (AUC) and see how a group-wise percentile transformation can harmonize scores from different scales, leading to a more meaningful and sometimes improved measure of predictive performance.",
            "id": "3177941",
            "problem": "You are given binary classification datasets consisting of a vector of labels and a corresponding vector of real-valued prediction scores. Your tasks are to (i) derive and implement an empirical percentile transformation of prediction scores, (ii) compute the Area Under the Receiver Operating Characteristic Curve (AUC; defined below) for both raw scores and percentile-transformed scores, and (iii) assess the stability of AUC under this transformation. Additionally, in a multi-group setting where raw score scales differ by group, implement a groupwise percentile normalization to explore whether percentile-based ranking is more informative than raw scores.\n\nFundamental base and definitions to use:\n- Let $N$ be the number of observations, indexed by $i \\in \\{1,\\dots,N\\}$. Each observation has a binary label $Y_i \\in \\{0,1\\}$ and a real-valued prediction score $S_i \\in \\mathbb{R}$.\n- The empirical cumulative distribution function (ECDF) of the scores is defined as $$F_N(s) = \\frac{1}{N}\\sum_{j=1}^{N} \\mathbf{1}\\{S_j \\le s\\},$$ where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. A percentile is a quantile expressed as a fraction in $[0,1]$; in this task, express percentiles as decimals in $[0,1]$ (not with a percentage sign).\n- Use midranks to handle ties: if the sorted positions of tied scores span integer ranks $r_{\\text{low}},\\dots,r_{\\text{high}}$, assign each tied score the midrank $$r_{\\text{mid}} = \\frac{r_{\\text{low}} + r_{\\text{high}}}{2}.$$ Define the global empirical percentile of $S_i$ as $$P_i = \\frac{r_i - 0.5}{N},$$ where $r_i$ is the midrank of $S_i$ among all $N$ scores. In the multi-group case with groups $G_i \\in \\{0,1,\\dots\\}$, define the groupwise percentile as $$P^{(g)}_i = \\frac{r^{(g)}_i - 0.5}{N_g},$$ where $r^{(g)}_i$ is the midrank of $S_i$ within its group $g = G_i$, and $N_g$ is the number of observations in group $g$.\n- The Receiver Operating Characteristic (ROC) curve (defined here as the set of achievable true positive rate and false positive rate pairs by thresholding scores) has Area Under the Curve (AUC), which can be defined as the probability that a randomly chosen positive-labeled score exceeds a randomly chosen negative-labeled score, with ties broken by assigning half credit. Using ranks, let $m = \\sum_{i=1}^{N} \\mathbf{1}\\{Y_i = 1\\}$ and $n = \\sum_{i=1}^{N} \\mathbf{1}\\{Y_i = 0\\}$, and let $R^+ = \\sum_{i: Y_i=1} r_i$ be the sum of midranks of the positive-labeled observations; then the AUC is given by $$\\text{AUC} = \\frac{R^+ - \\frac{m(m+1)}{2}}{m \\cdot n}.$$\n\nYour program must, for each test case below:\n1. Compute the raw-score AUC using the midrank-based formula.\n2. Compute the global percentile scores $P_i$ and the corresponding AUC, and then the absolute difference $$\\Delta_{\\text{global}} = \\left|\\text{AUC}_{\\text{raw}} - \\text{AUC}_{\\text{global}}\\right|.$$\n3. Compute the groupwise percentile scores $P^{(g)}_i$ and the corresponding AUC, and the improvement $$\\Delta_{\\text{group}} = \\text{AUC}_{\\text{group}} - \\text{AUC}_{\\text{raw}}.$$\n4. Report all AUCs and differences as decimals.\n\nTest suite (each case provides labels $Y$, scores $S$, and integer group labels $G$):\n- Case $1$ (continuous, mostly unique scores; single group):\n  - $Y = [0,0,0,0,1,1,1,1,1,0,1,0]$\n  - $S = [0.10,0.15,0.20,0.25,0.30,0.22,0.27,0.35,0.40,0.12,0.33,0.18]$\n  - $G = [0,0,0,0,0,0,0,0,0,0,0,0]$\n- Case $2$ (many ties; single group):\n  - $Y = [0,0,1,1,0,1,0,1]$\n  - $S = [0.50,0.50,0.50,0.50,0.70,0.70,0.20,0.20]$\n  - $G = [0,0,0,0,0,0,0,0]$\n- Case $3$ (extreme outlier; single group):\n  - $Y = [0,0,0,0,1,1,1,1,1,0]$\n  - $S = [0.01,0.02,0.03,100.00,0.04,0.05,0.06,0.07,0.08,0.90]$\n  - $G = [0,0,0,0,0,0,0,0,0,0]$\n- Case $4$ (degenerate constant scores; single group):\n  - $Y = [0,0,0,1,1,1,0,1]$\n  - $S = [0.30,0.30,0.30,0.30,0.30,0.30,0.30,0.30]$\n  - $G = [0,0,0,0,0,0,0,0]$\n- Case $5$ (two groups with different raw score scales; percentile ranking expected to be more informative):\n  - $Y = [0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1]$\n  - $S = [20,22,18,24,35,37,33,39,1030,1050,1100,1080,1005,1010,995,1020]$\n  - $G = [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]$\n\nFinal output format:\n- Your program should produce a single line of output containing a list of lists. For each test case, output the list $[\\text{AUC}_{\\text{raw}}, \\text{AUC}_{\\text{global}}, \\Delta_{\\text{global}}, \\text{AUC}_{\\text{group}}, \\Delta_{\\text{group}}]$ in this order, all as decimals. Aggregate the five case results into a single list and print it exactly as one line, for example, $$[[a_1,b_1,c_1,d_1,e_1],[a_2,b_2,c_2,d_2,e_2],\\dots].$$",
            "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in established statistical principles, well-posed with clear definitions and data, and objective in its formulation. All necessary components, including definitions for empirical percentiles using midranks and the rank-based formula for the Area Under the ROC Curve (AUC), are provided. The test cases are well-defined and cover a range of scenarios relevant to the concepts being tested.\n\nThe solution proceeds by first implementing a function to calculate the AUC according to the provided formula. This function will be the core computational block. Subsequently, for each test case, we will compute the required statistical measures in three distinct steps: once for the raw prediction scores, once for the globally transformed percentile scores, and once for the groupwise transformed percentile scores.\n\n### 1. AUC Calculation\nThe AUC is given by the formula:\n$$\n\\text{AUC} = \\frac{R^+ - \\frac{m(m+1)}{2}}{m \\cdot n}\n$$\nwhere $m$ is the count of positive labels ($Y_i=1$), $n$ is the count of negative labels ($Y_i=0$), and $R^+$ is the sum of the midranks of the scores $S_i$ corresponding to the positive labels. Midranks are used to handle ties in score values. If a set of tied scores occupies ranks from $r_{\\text{low}}$ to $r_{\\text{high}}$, each score is assigned the average rank $r_{\\text{mid}} = (r_{\\text{low}} + r_{\\text{high}})/2$. The implementation will use `scipy.stats.rankdata` with `method='average'` to compute these midranks efficiently and correctly.\n\n### 2. Global Percentile Transformation\nThe global percentile $P_i$ for a score $S_i$ is defined as:\n$$\nP_i = \\frac{r_i - 0.5}{N}\n$$\nwhere $r_i$ is the global midrank of $S_i$ and $N$ is the total number of observations. This transformation is a strictly order-preserving (monotonic) function of the ranks. Since the AUC formula is based entirely on ranks, any such transformation will not change the ranks of the scores relative to each other. Consequently, the AUC calculated on the raw scores, $\\text{AUC}_{\\text{raw}}$, must be identical to the AUC calculated on the global percentile scores, $\\text{AUC}_{\\text{global}}$. Therefore, the absolute difference, $\\Delta_{\\text{global}} = \\left|\\text{AUC}_{\\text{raw}} - \\text{AUC}_{\\text{global}}\\right|$, is theoretically expected to be $0$.\n\n### 3. Groupwise Percentile Transformation\nFor an observation $i$ belonging to group $g = G_i$, the groupwise percentile is:\n$$\nP^{(g)}_i = \\frac{r^{(g)}_i - 0.5}{N_g}\n$$\nHere, $r^{(g)}_i$ is the midrank of $S_i$ calculated **only** among the scores within group $g$, and $N_g$ is the number of observations in that group. This transformation rescales scores within each group to a common $[0, 1]$ range. Unlike the global transformation, this does **not** preserve the overall rank ordering of scores across different groups. A high score from a low-scale group might receive a higher percentile rank than a low score from a high-scale group. This can alter the overall AUC. We will compute the new set of scores, $P^{(g)}_i$, and then calculate $\\text{AUC}_{\\text{group}}$ using these new scores. The improvement is measured by $\\Delta_{\\text{group}} = \\text{AUC}_{\\text{group}} - \\text{AUC}_{\\text{raw}}$.\n\n### 4. Algorithmic Implementation\nFor each test case, the algorithm is as follows:\n1.  Receive the vectors of labels $Y$, scores $S$, and group assignments $G$.\n2.  **Raw AUC**: Compute midranks for all scores $S$ to find the ranks of the positive samples, sum them to get $R^+$, and calculate $\\text{AUC}_{\\text{raw}}$ using the provided formula.\n3.  **Global Percentile AUC**:\n    a. Use the same global midranks $r_i$ from the previous step.\n    b. Compute the global percentile scores $P_i = (r_i - 0.5) / N$.\n    c. Calculate $\\text{AUC}_{\\text{global}}$ using labels $Y$ and scores $P$.\n    d. Compute $\\Delta_{\\text{global}} = |\\text{AUC}_{\\text{raw}} - \\text{AUC}_{\\text{global}}|$.\n4.  **Groupwise Percentile AUC**:\n    a. Initialize a new score vector $P_{\\text{group}}$.\n    b. For each unique group $g$ in $G$:\n        i. Isolate the scores $S_g$ and labels $Y_g$ for that group.\n        ii. Compute midranks $r^{(g)}_i$ for the scores $S_g$.\n        iii. Calculate the group-specific percentiles $P^{(g)}_i = (r^{(g)}_i - 0.5) / N_g$.\n        iv. Place these percentile scores back into the corresponding positions in $P_{\\text{group}}$.\n    c. Calculate $\\text{AUC}_{\\text{group}}$ using labels $Y$ and scores $P_{\\text{group}}$.\n    d. Compute $\\Delta_{\\text{group}} = \\text{AUC}_{\\text{group}} - \\text{AUC}_{\\text{raw}}$.\n5.  Collect the five resulting values: $[\\text{AUC}_{\\text{raw}}, \\text{AUC}_{\\text{global}}, \\Delta_{\\text{global}}, \\text{AUC}_{\\text{group}}, \\Delta_{\\text{group}}]$.\n\nThis procedure is systematically applied to all test cases, and the results are aggregated into a final list for output.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import rankdata\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases, calculating AUC for raw scores,\n    global-percentile-transformed scores, and groupwise-percentile-transformed\n    scores, along with specified difference metrics.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"Y\": np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0]),\n            \"S\": np.array([0.10, 0.15, 0.20, 0.25, 0.30, 0.22, 0.27, 0.35, 0.40, 0.12, 0.33, 0.18]),\n            \"G\": np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n        },\n        {\n            \"Y\": np.array([0, 0, 1, 1, 0, 1, 0, 1]),\n            \"S\": np.array([0.50, 0.50, 0.50, 0.50, 0.70, 0.70, 0.20, 0.20]),\n            \"G\": np.array([0, 0, 0, 0, 0, 0, 0, 0])\n        },\n        {\n            \"Y\": np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 0]),\n            \"S\": np.array([0.01, 0.02, 0.03, 100.00, 0.04, 0.05, 0.06, 0.07, 0.08, 0.90]),\n            \"G\": np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n        },\n        {\n            \"Y\": np.array([0, 0, 0, 1, 1, 1, 0, 1]),\n            \"S\": np.array([0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30]),\n            \"G\": np.array([0, 0, 0, 0, 0, 0, 0, 0])\n        },\n        {\n            \"Y\": np.array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]),\n            \"S\": np.array([20, 22, 18, 24, 35, 37, 33, 39, 1030, 1050, 1100, 1080, 1005, 1010, 995, 1020]),\n            \"G\": np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n        }\n    ]\n\n    def calculate_auc(labels, scores):\n        \"\"\"\n        Calculates AUC using the rank-based formula.\n        AUC = (R_pos - m*(m+1)/2) / (m*n)\n        \"\"\"\n        pos_mask = (labels == 1)\n        m = np.sum(pos_mask)\n        n = len(labels) - m\n\n        if m == 0 or n == 0:\n            return 0.5 # Or np.nan, but 0.5 is a common convention for non-discriminable case\n\n        ranks = rankdata(scores, method='average')\n        R_pos = np.sum(ranks[pos_mask])\n\n        auc = (R_pos - m * (m + 1) / 2) / (m * n)\n        return auc\n\n    def process_case(Y, S, G):\n        \"\"\"\n        Processes a single test case according to the problem description.\n        \"\"\"\n        N = len(Y)\n\n        # 1. Raw-score AUC\n        auc_raw = calculate_auc(Y, S)\n\n        # 2. Global percentile AUC\n        ranks_global = rankdata(S, method='average')\n        P_global = (ranks_global - 0.5) / N\n        auc_global = calculate_auc(Y, P_global)\n        delta_global = abs(auc_raw - auc_global)\n\n        # 3. Groupwise percentile AUC\n        P_group = np.zeros_like(S, dtype=float)\n        unique_groups = np.unique(G)\n        for g_id in unique_groups:\n            group_mask = (G == g_id)\n            S_g = S[group_mask]\n            N_g = len(S_g)\n            if N_g > 0:\n                ranks_g = rankdata(S_g, method='average')\n                P_g_vals = (ranks_g - 0.5) / N_g\n                P_group[group_mask] = P_g_vals\n        \n        auc_group = calculate_auc(Y, P_group)\n        delta_group = auc_group - auc_raw\n        \n        return [auc_raw, auc_global, delta_global, auc_group, delta_group]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case[\"Y\"], case[\"S\"], case[\"G\"])\n        results.append(result)\n        \n    # Python's default float representation is sufficient for \"decimals\"\n    # The requirement is to format the list of lists into a string.\n    # e.g. [[a1, b1, ...], [a2, b2, ...]]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}