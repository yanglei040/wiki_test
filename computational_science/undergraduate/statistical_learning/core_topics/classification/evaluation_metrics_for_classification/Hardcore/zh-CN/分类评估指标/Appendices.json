{
    "hands_on_practices": [
        {
            "introduction": "在现实世界的分类问题中，类别不平衡现象十分普遍，例如欺诈检测或罕见病诊断。在这种情况下，准确率（Accuracy）等简单指标可能会产生误导，一个将所有样本都预测为多数类的“平凡”分类器也能获得很高的准确率。本练习旨在通过一个假设性的类别高度不平衡场景，帮助你深入理解平衡准确率（Balanced Accuracy）和 $F_1$ 分数等更鲁棒的评估指标，并学会如何从基本定义出发推导和计算它们。",
            "id": "3118882",
            "problem": "给定一个存在严重类别不平衡的二元分类场景。真实标签表示为 $y \\in \\{0,1\\}$，其固定的基准率 $\\mathbb{P}(y=1)=p=0.01$。分类器将每个实例映射到一个类别标签 $\\hat{y} \\in \\{0,1\\}$。一个概率模型将每个实例映射到一个分数 $s \\in [0,1]$，该分数被解释为校准概率，意味着对于分数 $s$ 范围内的任何值 $v$，条件概率满足 $\\mathbb{P}(y=1 \\mid s=v) = v$。为了将分数转换为硬标签，使用形式为“当且仅当 $s \\ge \\theta$ 时，预测 $\\hat{y}=1$”的阈值规则，并采用特定的平局约定，将等号情况归入阳性类别。你的任务是仅使用核心定义和全概率定律，推导并计算几种情况下的评估指标。\n\n从基础开始：由真阳性 (TP)、假阳性 (FP)、真阴性 (TN) 和假阴性 (FN) 事件定义的混淆结果。请使用总体比例而非有限样本计数。使用全概率定律从校准概率层和阈值决策中获取每个混淆分量。然后，使用准确率、平衡准确率（真阳性率和真阴性率的平均值）和 F1 分数（一阶 F 分数）的标准定义，计算下面所要求的量。如果比率的分母为零，则约定该比率为零。特别地，如果没有对阳性类别做出预测，则定义精确率为零，因此 F1 值也为零。所有值必须以小数表示，而不是百分比。\n\n合成校准双箱模型。考虑一个分数模型，它只输出两个值：在一个质量（概率）为 $w \\in (0,1)$ 的实例子集 $S_h$ 上输出一个“高”分 $p_h$，并在质量为 $1-w$ 的补集 $S_\\ell$ 上输出一个“低”分 $p_\\ell$。该模型是校准的，因此 $S_h$ 上的条件阳性率为 $p_h$，$S_\\ell$ 上的条件阳性率为 $p_\\ell$。总体阳性基准率必须等于 $p$，因此 $p = w \\, p_h + (1-w)\\, p_\\ell$。当未明确给出 $p_\\ell$ 时，你必须使用此恒等式从指定参数中设置它。对于一个阈值 $\\theta$，决策区域为：对任何分数至少为 $\\theta$ 的层预测为阳性，否则预测为阴性。\n\n测试套件。对以下每种情况，根据上述定义计算准确率、平衡准确率和 F1。输出每个指标，四舍五入到小数点后六位。\n\n- 情况 A（总是预测为阴性的分类器）：一个平凡分类器，对所有实例都预测 $\\hat{y}=0$，无论输入如何。\n- 情况 B（校准，阈值设为高分）：双箱校准模型，其中 $w=0.02$，$p_h=0.50$，$p_\\ell$ 由基准率 $p=0.01$ 确定。使用阈值 $\\theta=0.50$。\n- 情况 C（校准，阈值过高）：双箱校准模型，其中 $w=0.05$，$p_h=0.20$，$p_\\ell$ 由 $p=0.01$ 确定。使用阈值 $\\theta=0.50$。\n- 情况 D（校准，离散策略中 F1 最优）：参数与情况 C 相同。在由阈值引起的三种不同硬标签方案中，选择使 F1 最大化的预测策略：预测全为阴性（等价于 $\\theta > p_h$），仅预测高分箱为阳性（等价于 $p_\\ell  \\theta \\le p_h$），或预测两个箱都为阳性（等价于 $\\theta \\le p_\\ell$）。如果 F1 分数出现平局，选择预测阳性数量最少的方案。\n\n最终输出格式。你的程序应该生成一行包含 12 个值的输出，顺序完全如下：\n$[\\text{Acc}_A,\\text{BalAcc}_A,\\text{F1}_A,\\text{Acc}_B,\\text{BalAcc}_B,\\text{F1}_B,\\text{Acc}_C,\\text{BalAcc}_C,\\text{F1}_C,\\text{Acc}_D,\\text{BalAcc}_D,\\text{F1}_D]$，\n四舍五入到小数点后六位，并以方括号括起来的逗号分隔列表形式打印（例如，$[0.000000,0.000000,\\dots]$）。不允许有其他输出。",
            "solution": "问题要求在几种场景下计算一个二元分类器的三个评估指标——准确率、平衡准确率和 F1 分数。该设定是总体层面的分析，而非有限样本，其特征是阳性实例的基准率为 $\\mathbb{P}(y=1) = p = 0.01$。\n\n首先，我们基于四种混淆矩阵结果的总体比例来建立指标的定义：真阳性 ($TP$)、假阳性 ($FP$)、真阴性 ($TN$) 和假阴性 ($FN$)。这些比例之和为 $1$：$TP+FP+TN+FN=1$。\n\n阳性和阴性总体的比例由以下公式给出：\n$$TP + FN = \\mathbb{P}(y=1) = p$$\n$$TN + FP = \\mathbb{P}(y=0) = 1-p$$\n\n指标定义如下：\n1.  **准确率 ($Acc$)**：正确预测的比例。\n    $$Acc = TP + TN$$\n2.  **真阳性率 ($TPR$)** 或 **召回率 ($Rec$)**：被正确识别的实际阳性样本的比例。\n    $$TPR = Rec = \\frac{TP}{TP+FN} = \\frac{TP}{p}$$\n3.  **真阴性率 ($TNR$)**：被正确识别的实际阴性样本的比例。\n    $$TNR = \\frac{TN}{TN+FP} = \\frac{TN}{1-p}$$\n4.  **平衡准确率 ($BalAcc$)**：$TPR$ 和 $TNR$ 的算术平均值。\n    $$BalAcc = \\frac{1}{2}(TPR + TNR)$$\n5.  **精确率 ($Prec$)**：阳性预测中正确的比例。\n    $$Prec = \\frac{TP}{TP+FP}$$\n    分母 $TP+FP = \\mathbb{P}(\\hat{y}=1)$ 是被预测为阳性的实例的总比例。如果 $\\mathbb{P}(\\hat{y}=1)=0$，那么根据约定 $Prec=0$。\n6.  **F1 分数 ($F1$)**：精确率和召回率的调和平均值。\n    $$F1 = 2 \\cdot \\frac{Prec \\cdot Rec}{Prec + Rec}$$\n    如果 $Prec+Rec=0$（这在 $TP=0$ 的情况下发生），那么 $F1=0$。\n\n问题引入了一个校准的双箱分数模型。该模型在数据的一部分（比例为 $w$）上输出一个“高”分 $s=p_h$，在剩余部分（比例为 $1-w$）上输出一个“低”分 $s=p_\\ell$。校准意味着 $\\mathbb{P}(y=1|s=p_h)=p_h$ 和 $\\mathbb{P}(y=1|s=p_\\ell)=p_\\ell$。整体基准率 $p$ 受全概率定律约束：$p = w \\cdot p_h + (1-w) \\cdot p_\\ell$。由此，我们可以确定 $p_\\ell$ 为 $p_\\ell = \\frac{p - w p_h}{1-w}$。\n\n混淆矩阵的各个分量可以通过考虑分类器的决策规则“当 $s \\ge \\theta$ 时，预测 $\\hat{y}=1$”以及分数和真实标签的联合概率来推导。\n$$TP = \\mathbb{P}(\\hat{y}=1, y=1) \\qquad FP = \\mathbb{P}(\\hat{y}=1, y=0)$$\n$$TN = \\mathbb{P}(\\hat{y}=0, y=0) \\qquad FN = \\mathbb{P}(\\hat{y}=0, y=1)$$\n\n让我们分析一个双箱模型可能的三种不同预测策略，假设 $p_h  p_\\ell$。\n\n**策略1：总是预测为阴性 ($\\hat{y}=0$)**。这在阈值 $\\theta  p_h$ 时发生。\n- $\\mathbb{P}(\\hat{y}=1)=0$，所以 $TP=0, FP=0$。\n- 所有实例都被预测为阴性，所以 $FN = \\mathbb{P}(y=1) = p$ 且 $TN = \\mathbb{P}(y=0) = 1-p$。\n- 指标：\n    - $Acc = TP+TN = 1-p$。\n    - $TPR = 0/p = 0$。$TNR = (1-p)/(1-p) = 1$。\n    - $BalAcc = \\frac{1}{2}(0+1) = 0.5$。\n    - $Prec=0$（根据约定），$Rec=0$。\n    - $F1 = 0$。\n\n**策略2：预测高分箱为阳性，低分箱为阴性**。这在 $p_\\ell  \\theta \\le p_h$ 时发生。\n- 仅对 $S_h$ 层（质量为 $w$）预测 $\\hat{y}=1$。\n- $TP = \\mathbb{P}(s=p_h, y=1) = \\mathbb{P}(y=1|s=p_h)\\mathbb{P}(s=p_h) = p_h w$。\n- $FP = \\mathbb{P}(s=p_h, y=0) = (1-p_h)w$。\n- $TN = \\mathbb{P}(s=p_\\ell, y=0) = (1-p_\\ell)(1-w)$。\n- $FN = \\mathbb{P}(s=p_\\ell, y=1) = p_\\ell(1-w)$。\n- 指标：\n    - $Acc = p_h w + (1-p_\\ell)(1-w)$。\n    - $TPR = \\frac{p_h w}{p}$。$TNR = \\frac{(1-p_\\ell)(1-w)}{1-p}$。\n    - $BalAcc = \\frac{1}{2} \\left( \\frac{p_h w}{p} + \\frac{(1-p_\\ell)(1-w)}{1-p} \\right)$。\n    - $Prec = \\frac{p_h w}{p_h w + (1-p_h)w} = \\frac{p_h w}{w} = p_h$。\n    - $Rec = TPR = \\frac{p_h w}{p}$。\n    - $F1 = 2 \\frac{p_h \\cdot (p_h w/p)}{p_h + p_h w/p} = \\frac{2 p_h^2 w}{p_h(p+w)} = \\frac{2 p_h w}{p+w}$。\n\n**策略3：总是预测为阳性 ($\\hat{y}=1$)**。这在 $\\theta \\le p_\\ell$ 时发生。\n- $\\mathbb{P}(\\hat{y}=0)=0$，所以 $TN=0, FN=0$。\n- 所有实例都被预测为阳性，所以 $TP = \\mathbb{P}(y=1) = p$ 且 $FP = \\mathbb{P}(y=0) = 1-p$。\n- 指标：\n    - $Acc = TP+TN = p$。\n    - $TPR = p/p = 1$。$TNR = 0/(1-p) = 0$。\n    - $BalAcc = \\frac{1}{2}(1+0) = 0.5$。\n    - $Prec = \\frac{p}{p+(1-p)} = p$。$Rec=1$。\n    - $F1 = 2 \\frac{p \\cdot 1}{p+1} = \\frac{2p}{p+1}$。\n\n有了这些通用公式，我们就可以计算每种情况的值。基准率为 $p=0.01$。\n\n**情况A：总是预测为阴性的分类器**\n这是策略1。\n- $Acc_A = 1-p = 1-0.01 = 0.99$。\n- $BalAcc_A = 0.5$。\n- $F1_A = 0$。\n值：$0.990000, 0.500000, 0.000000$。\n\n**情况B：校准，阈值设为高分**\n参数：$w=0.02$，$p_h=0.50$，阈值 $\\theta=0.50$。\n首先，我们求出 $p_\\ell$：$p_\\ell = \\frac{0.01 - 0.02 \\cdot 0.50}{1-0.02} = \\frac{0.01 - 0.01}{0.98} = 0$。\n分数为 $p_h=0.50$ 和 $p_\\ell=0$。由于 $0  \\theta=0.50 \\le 0.50$，这是策略2。\n- $Acc_B = p_h w + (1-p_\\ell)(1-w) = 0.50 \\cdot 0.02 + (1-0)(1-0.02) = 0.01 + 0.98 = 0.99$。\n- $TPR_B = \\frac{p_h w}{p} = \\frac{0.50 \\cdot 0.02}{0.01} = 1$。\n- $TNR_B = \\frac{(1-p_\\ell)(1-w)}{1-p} = \\frac{(1-0)(1-0.02)}{1-0.01} = \\frac{0.98}{0.99}$。\n- $BalAcc_B = \\frac{1}{2}(1 + \\frac{0.98}{0.99}) = \\frac{1.97}{1.98} \\approx 0.994949$。\n- $F1_B = \\frac{2 p_h w}{p+w} = \\frac{2 \\cdot 0.50 \\cdot 0.02}{0.01+0.02} = \\frac{0.02}{0.03} = \\frac{2}{3} \\approx 0.666667$。\n值：$0.990000, 0.994949, 0.666667$。\n\n**情况C：校准，阈值过高**\n参数：$w=0.05$，$p_h=0.20$，阈值 $\\theta=0.50$。\n首先，我们求出 $p_\\ell$：$p_\\ell = \\frac{0.01 - 0.05 \\cdot 0.20}{1-0.05} = \\frac{0.01 - 0.01}{0.95} = 0$。\n分数为 $p_h=0.20$ 和 $p_\\ell=0$。由于 $\\theta=0.50  p_h=0.20$，这是策略1。\n结果与情况A相同。\n- $Acc_C = 0.99$。\n- $BalAcc_C = 0.5$。\n- $F1_C = 0$。\n值：$0.990000, 0.500000, 0.000000$。\n\n**情况D：校准，F1最优策略**\n参数与情况C相同：$w=0.05, p_h=0.20, p_\\ell=0$。我们必须选择使 $F1$ 最大化的策略。\n- **策略1 ($F1_1$)**：$F1_1=0$。\n- **策略2 ($F1_2$)**：$F1_2 = \\frac{2 p_h w}{p+w} = \\frac{2 \\cdot 0.20 \\cdot 0.05}{0.01+0.05} = \\frac{0.02}{0.06} = \\frac{1}{3} \\approx 0.333333$。\n- **策略3 ($F1_3$)**：$F1_3 = \\frac{2p}{p+1} = \\frac{2 \\cdot 0.01}{1.01} = \\frac{0.02}{1.01} \\approx 0.019802$。\n比较 F1 分数，$F1_2$ 是最大的。因此，最优策略是策略2。我们现在计算其指标。\n- $Acc_D = p_h w + (1-p_\\ell)(1-w) = 0.20 \\cdot 0.05 + (1-0)(1-0.05) = 0.01 + 0.95 = 0.96$。\n- $TPR_D = \\frac{p_h w}{p} = \\frac{0.20 \\cdot 0.05}{0.01} = 1$。\n- $TNR_D = \\frac{(1-p_\\ell)(1-w)}{1-p} = \\frac{(1-0)(1-0.05)}{1-0.01} = \\frac{0.95}{0.99}$。\n- $BalAcc_D = \\frac{1}{2}(1 + \\frac{0.95}{0.99}) = \\frac{1.94}{1.98} \\approx 0.979798$。\n- $F1_D = 1/3 \\approx 0.333333$。\n值：$0.960000, 0.979798, 0.333333$。\n\n合并所有结果得到最终输出：\n- Acc_A, BalAcc_A, F1_A: $0.990000, 0.500000, 0.000000$\n- Acc_B, BalAcc_B, F1_B: $0.990000, 0.994949, 0.666667$\n- Acc_C, BalAcc_C, F1_C: $0.990000, 0.500000, 0.000000$\n- Acc_D, BalAcc_D, F1_D: $0.960000, 0.979798, 0.333333$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Accuracy, Balanced Accuracy, and F1-score for four\n    binary classification scenarios as defined in the problem.\n    \"\"\"\n\n    def calculate_metrics(p_rate, TP, FP, TN, FN):\n        \"\"\"\n        Calculates evaluation metrics from confusion matrix components.\n        \n        Args:\n            p_rate (float): The base rate P(y=1).\n            TP, FP, TN, FN (float): Population fractions for confusion matrix.\n\n        Returns:\n            tuple: A tuple containing (Accuracy, Balanced Accuracy, F1-score).\n        \"\"\"\n        # Denominators for rates\n        # real_pos = p_rate\n        # real_neg = 1 - p_rate\n        real_pos = TP + FN\n        real_neg = TN + FP\n        pred_pos = TP + FP\n        \n        # Accuracy\n        acc = TP + TN\n\n        # True Positive Rate (Recall) and True Negative Rate\n        tpr = TP / real_pos if real_pos > 0 else 0.0\n        tnr = TN / real_neg if real_neg > 0 else 0.0\n\n        # Balanced Accuracy\n        bal_acc = 0.5 * (tpr + tnr)\n\n        # Precision and Recall\n        prec = TP / pred_pos if pred_pos > 0 else 0.0\n        recall = tpr # Recall is the same as TPR\n\n        # F1 Score\n        f1 = 2 * (prec * recall) / (prec + recall) if (prec + recall) > 0 else 0.0\n\n        return acc, bal_acc, f1\n\n    results = []\n    p = 0.01\n\n    # Case A: Always-negative classifier (Policy 1)\n    TP_A, FP_A, TN_A, FN_A = 0.0, 0.0, 1 - p, p\n    acc_A, bal_acc_A, f1_A = calculate_metrics(p, TP_A, FP_A, TN_A, FN_A)\n    results.extend([acc_A, bal_acc_A, f1_A])\n\n    # Case B: Calibrated, threshold at high score\n    w_B, p_h_B = 0.02, 0.50\n    p_l_B = (p - w_B * p_h_B) / (1 - w_B)\n    # Threshold theta = 0.50, which is = p_h_B. This is Policy 2.\n    TP_B = p_h_B * w_B\n    FP_B = (1 - p_h_B) * w_B\n    TN_B = (1 - p_l_B) * (1 - w_B)\n    FN_B = p_l_B * (1 - w_B)\n    acc_B, bal_acc_B, f1_B = calculate_metrics(p, TP_B, FP_B, TN_B, FN_B)\n    results.extend([acc_B, bal_acc_B, f1_B])\n\n    # Case C: Calibrated, threshold too high\n    w_C, p_h_C = 0.05, 0.20\n    p_l_C = (p - w_C * p_h_C) / (1 - w_C)\n    # Threshold theta = 0.50, which is > p_h_C. This is Policy 1.\n    TP_C, FP_C, TN_C, FN_C = 0.0, 0.0, 1 - p, p\n    acc_C, bal_acc_C, f1_C = calculate_metrics(p, TP_C, FP_C, TN_C, FN_C)\n    results.extend([acc_C, bal_acc_C, f1_C])\n    \n    # Case D: Calibrated, F1-optimal among discrete policies\n    w_D, p_h_D = w_C, p_h_C\n    p_l_D = p_l_C\n\n    # Evaluate F1 for the three possible policies\n    \n    # Policy 1: Predict none positive\n    # F1 is 0, as calculated in Case A.\n    f1_1 = f1_A\n    metrics_1 = (acc_A, bal_acc_A, f1_1)\n    pred_pos_1 = 0.0\n\n    # Policy 2: Predict high-score bin as positive\n    TP_2 = p_h_D * w_D\n    FP_2 = (1 - p_h_D) * w_D\n    TN_2 = (1 - p_l_D) * (1 - w_D)\n    FN_2 = p_l_D * (1 - w_D)\n    metrics_2 = calculate_metrics(p, TP_2, FP_2, TN_2, FN_2)\n    f1_2 = metrics_2[2]\n    pred_pos_2 = w_D\n\n    # Policy 3: Predict all positive\n    TP_3, FP_3, TN_3, FN_3 = p, 1 - p, 0.0, 0.0\n    metrics_3 = calculate_metrics(p, TP_3, FP_3, TN_3, FN_3)\n    f1_3 = metrics_3[2]\n    pred_pos_3 = 1.0\n\n    # Find the optimal policy: maximize F1, with tie-breaking by fewest predicted positives\n    policies = [\n        (f1_1, pred_pos_1, metrics_1),\n        (f1_2, pred_pos_2, metrics_2),\n        (f1_3, pred_pos_3, metrics_3)\n    ]\n    \n    # Sort by F1 descending (-f1), then by predicted positives ascending (pred_pos)\n    # The best policy is the first element after sorting.\n    best_policy = sorted(policies, key=lambda x: (-x[0], x[1]))[0]\n    acc_D, bal_acc_D, f1_D = best_policy[2]\n    results.extend([acc_D, bal_acc_D, f1_D])\n\n    # Format the final output string with rounding to 6 decimal places\n    output_str = f\"[{','.join(f'{x:.6f}' for x in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "对于输出概率分数的分类器，我们不仅关心在某个特定阈值下的表现，更关心模型对样本进行排序的整体能力。受试者工作特征曲线下面积（ROC-AUC）是衡量排序质量的常用指标，但在处理上一练习中讨论的类别不平衡问题时，它可能会给出过于乐观的评估。本练习将引导你对比 ROC-AUC 和精确率-召回率曲线下面积（PR-AUC），通过一个极端不平衡的例子，揭示为什么 PR-AUC 在这种场景下能更真实地反映模型性能。",
            "id": "3118905",
            "problem": "您的任务是仅使用基本定义，在极端类别不平衡的情况下比较两种二元分类评估指标。考虑一个大小为 $N$ 的二元数据集，其标签为 $y_i \\in \\{0,1\\}$，预测分数为 $s_i \\in \\mathbb{R}$，其中 $i \\in \\{1,\\dots,N\\}$。对于任意阈值 $\\tau \\in \\mathbb{R}$，定义预测标签 $\\hat{y}_i(\\tau) = \\mathbf{1}\\{s_i \\ge \\tau\\}$。令 $\\mathrm{TP}(\\tau)$、$\\mathrm{FP}(\\tau)$、$\\mathrm{TN}(\\tau)$ 和 $\\mathrm{FN}(\\tau)$ 分别表示依赖于阈值的真阳性、假阳性、真阴性和假阴性的计数。根据这些计数，定义在阈值 $\\tau$ 下的以下标准比率：\n- 真阳性率 (TPR): $\\mathrm{TPR}(\\tau) = \\dfrac{\\mathrm{TP}(\\tau)}{\\mathrm{TP}(\\tau) + \\mathrm{FN}(\\tau)}$。\n- 假阳性率 (FPR): $\\mathrm{FPR}(\\tau) = \\dfrac{\\mathrm{FP}(\\tau)}{\\mathrm{FP}(\\tau) + \\mathrm{TN}(\\tau)}$。\n- 精确率 (Precision): $\\mathrm{Prec}(\\tau) = \\dfrac{\\mathrm{TP}(\\tau)}{\\mathrm{TP}(\\tau) + \\mathrm{FP}(\\tau)}$。\n- 召回率 (Recall): $\\mathrm{Rec}(\\tau) = \\dfrac{\\mathrm{TP}(\\tau)}{\\mathrm{TP}(\\tau) + \\mathrm{FN}(\\tau)}$。\n\n受试者工作特征 (ROC) 曲线是由将阈值 $\\tau$ 从 $+\\infty$ 扫描到 $-\\infty$ 所产生的一组点 $\\{(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))\\}$。精确率-召回率 (PR) 曲线是在相同扫描过程中产生的一组点 $\\{(\\mathrm{Rec}(\\tau), \\mathrm{Prec}(\\tau))\\}$。通过按分数降序对样本进行排序，从最高分到最低分扫描一次来构建这两条曲线，在分数相同的情况下，将所有分数相等的样本聚合为单一步骤，然后计算下一个点。\n\n将ROC曲线下面积 (ROC-AUC) 定义为在 $[0,1]$ 区间上 $\\mathrm{TPR}$ 对 $\\mathrm{FPR}$ 的积分，通过对如上所述获得的 $(\\mathrm{FPR}, \\mathrm{TPR})$ 点序列（包括锚点 $(0,0)$ 和 $(1,1)$）使用梯形法则计算。将精确率-召回率曲线下面积 (PR-AUC) 定义为平均精确率 (AP)，即使用右连续阶梯函数近似在 $[0,1]$ 区间上 $\\mathrm{Prec}$ 对 $\\mathrm{Rec}$ 的黎曼-斯蒂尔杰斯积分：\n$$\n\\mathrm{AP} \\;=\\; \\sum_{k=1}^{K} \\mathrm{Prec}_k \\,\\big(\\mathrm{Rec}_k - \\mathrm{Rec}_{k-1}\\big),\n$$\n其中 $(\\mathrm{Rec}_k,\\mathrm{Prec}_k)$ 是在降序扫描中每个不同分数步骤后的点，且 $\\mathrm{Rec}_0 = 0$。不允许超出这些定义之外的平滑或插值。\n\n您的程序必须在 $p(y=1)=0.001$ 的极端类别不平衡情况下评估这些指标。为了使其完全确定且可测试，通过以下参数化构建数据集。对于给定的配对 $(N,r)$：\n- 使用 $N = 1000$，因此 $p(y=1) = 1/N = 0.001$。\n- 对 $k \\in \\{1,\\dots,N\\}$ 定义分数 $s_k = 1 - \\dfrac{k-1}{N-1}$，以使 $s_1  s_2  \\dots  s_N$，确保分数列表严格降序且无并列。\n- 定义标签 $y_k$ 为 $y_r = 1$ 且对于所有 $k \\neq r$，$y_k = 0$，即在分数降序排列中，只有一个正样本位于排名 $r$ 处。\n\n仅使用上述定义，为每个测试用例计算以下三个量：\n- 由 $(\\mathrm{FPR},\\mathrm{TPR})$ 上的梯形积分定义的ROC-AUC。\n- 使用上述定义的平均精确率计算的PR-AUC。\n- 差值 $\\mathrm{ROC\\mbox{-}AUC} - \\mathrm{PR\\mbox{-}AUC}$。\n\n测试套件：\n- 案例 A（一般可区分情况）：$(N,r) = (1000,10)$。\n- 案例 B（完美排序边界）：$(N,r) = (1000,1)$。\n- 案例 C（最差排序边界）：$(N,r) = (1000,1000)$。\n\n最终输出格式：\n- 您的程序应产生单行输出，其中包含一个结果列表，每个测试用例一个结果，每个结果是包含三个实数 $[\\mathrm{ROC\\mbox{-}AUC}, \\mathrm{PR\\mbox{-}AUC}, \\mathrm{ROC\\mbox{-}AUC} - \\mathrm{PR\\mbox{-}AUC}]$ 的列表，每个数字四舍五入到六位小数。例如，输出应类似于 $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3]]$，不含其他文本。",
            "solution": "### 第一步：提取已知条件\n- **数据集**：大小为 $N$，标签 $y_i \\in \\{0,1\\}$，分数 $s_i \\in \\mathbb{R}$。\n- **预测**：$\\hat{y}_i(\\tau) = \\mathbf{1}\\{s_i \\ge \\tau\\}$。\n- **计数**：$\\mathrm{TP}(\\tau)$, $\\mathrm{FP}(\\tau)$, $\\mathrm{TN}(\\tau)$, $\\mathrm{FN}(\\tau)$。\n- **比率定义**：\n    - $\\mathrm{TPR}(\\tau) = \\frac{\\mathrm{TP}(\\tau)}{\\mathrm{TP}(\\tau) + \\mathrm{FN}(\\tau)}$\n    - $\\mathrm{FPR}(\\tau) = \\frac{\\mathrm{FP}(\\tau)}{\\mathrm{FP}(\\tau) + \\mathrm{TN}(\\tau)}$\n    - $\\mathrm{Prec}(\\tau) = \\frac{\\mathrm{TP}(\\tau)}{\\mathrm{TP}(\\tau) + \\mathrm{FP}(\\tau)}$\n    - $\\mathrm{Rec}(\\tau) = \\frac{\\mathrm{TP}(\\tau)}{\\mathrm{TP}(\\tau) + \\mathrm{FN}(\\tau)}$\n- **曲线构建**：按分数 $s_i$ 降序排序，将阈值 $\\tau$ 从 $+\\infty$ 扫描到 $-\\infty$，为ROC生成点 $\\{(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))\\}$，为PR生成点 $\\{(\\mathrm{Rec}(\\tau), \\mathrm{Prec}(\\tau))\\}$。对于并列分数，聚合样本（注意：指定的数据集中不存在并列）。\n- **ROC-AUC定义**：ROC曲线下面积，通过对 $(\\mathrm{FPR}, \\mathrm{TPR})$ 点序列使用梯形法则计算，包括锚点 $(0,0)$ 和 $(1,1)$。\n- **PR-AUC定义**：平均精确率 (AP)，计算为黎曼-斯蒂尔杰斯积分 $\\mathrm{AP} = \\sum_{k=1}^{K} \\mathrm{Prec}_k \\,(\\mathrm{Rec}_k - \\mathrm{Rec}_{k-1})$，其中 $k$ 索引不同分数步骤，且 $\\mathrm{Rec}_0 = 0$。\n- **数据集参数化**：对于给定的配对 $(N,r)$：\n    - $N = 1000$，因此 $p(y=1) = 1/N = 0.001$。\n    - 对 $k \\in \\{1,\\dots,N\\}$ 定义分数 $s_k = 1 - \\frac{k-1}{N-1}$，确保分数严格降序。\n    - 标签 $y_k$ 为 $y_r = 1$ 且对于所有 $k \\neq r$，$y_k=0$。这将单个正样本置于排名 $r$ 处。\n- **任务**：为三个测试用例计算 ROC-AUC、PR-AUC 及其差值。\n- **测试套件**：\n    - 案例 A: $(N,r) = (1000,10)$。\n    - 案例 B: $(N,r) = (1000,1)$。\n    - 案例 C: $(N,r) = (1000,1000)$。\n- **输出**：单行列表的列表，`[[a1,b1,c1],[a2,b2,c2],[a3,b3,c3]]`，数字四舍五入到六位小数。\n\n### 第二步：使用提取的已知条件进行验证\n根据既定标准对问题进行评估。\n- **科学依据**：该问题基于统计学习和模型评估中的基本概念。这些指标（ROC-AUC、PR-AUC）及其计算方法都是标准的，尽管采用了特定的公式（梯形法则、右手黎曼和），但这些都是完全有效的。\n- **问题定义明确**：该问题已完全指定。所有变量、常数和过程都已明确定义。合成数据集的构建是确定性的，确保了唯一解。\n- **客观性**：语言是形式化的、数学的，并且没有主观性。\n\n该问题不存在任何使其无效的缺陷。这是一个在特定、可解析处理的场景中应用分类指标第一性原理定义的明确练习。\n\n### 第三步：结论与行动\n该问题是**有效的**。将推导并给出解决方案。\n\n### 解决方案\n任务是为一个唯一构造的数据集计算受试者工作特征曲线下面积（ROC-AUC）和精确率-召回率曲线下面积（PR-AUC），并对它们进行比较。该数据集有 $N=1000$ 个样本，其中恰好有一个正例（$P=1$）和 $N-1=999$ 个负例（$N_{neg}=999$）。分数是严格递减的，并且单个正样本在此排序中位于排名 $r$。\n\n我们将基于所提供的定义推导ROC-AUC和PR-AUC的解析表达式。该过程涉及按分数降序逐个处理样本，从排名 $k=1$到 $k=N$。在每一步 $k$，我们更新真阳性（TP）和假阳性（FP）的计数。\n\n令 $\\mathrm{TP}_k$ 和 $\\mathrm{FP}_k$ 为处理第 $k$ 个样本后的计数。正样本总数为 $P=1$，负样本总数为 $N_{neg} = N-1$。\n在步骤 $k$ 时的比率是：\n- $\\mathrm{TPR}_k = \\mathrm{TP}_k / P = \\mathrm{TP}_k$\n- $\\mathrm{FPR}_k = \\mathrm{FP}_k / N_{neg} = \\mathrm{FP}_k / (N-1)$\n- $\\mathrm{Rec}_k = \\mathrm{TPR}_k = \\mathrm{TP}_k$\n- $\\mathrm{Prec}_k = \\mathrm{TP}_k / (\\mathrm{TP}_k + \\mathrm{FP}_k)$\n\n曲线的点序列是通过改变分类阈值生成的，这等同于按分数降序处理样本。令 $(\\mathrm{FPR}_k, \\mathrm{TPR}_k)$ 为处理第 $k$ 个排名样本后的ROC曲线上的点。在 $k=0$ 处的初始状态（阈值在 $+\\infty$）对应于 $\\mathrm{TP}_0=0, \\mathrm{FP}_0=0$，给出ROC点 $(0,0)$。\n\n**ROC-AUC的推导**\nROC-AUC是使用梯形法则对点序列 $(\\mathrm{FPR}_k, \\mathrm{TPR}_k)$（$k=0, \\dots, N$）计算的。面积为 $\\sum_{k=1}^{N} \\frac{1}{2} (\\mathrm{FPR}_k - \\mathrm{FPR}_{k-1}) (\\mathrm{TPR}_k + \\mathrm{TPR}_{k-1})$。\n\n1.  对于步骤 $k=1, \\dots, r-1$：\n    - 样本全为负例。在每一步 $k$，$\\mathrm{TP}_k=0$ 且 $\\mathrm{FP}_k=k$。\n    - $\\mathrm{TPR}_k=0$，$\\mathrm{FPR}_k = k/(N-1)$。\n    - 点从 $(\\mathrm{FPR}_{k-1}, \\mathrm{TPR}_{k-1}) = ((k-1)/(N-1), 0)$ 移动到 $(\\mathrm{FPR}_k, \\mathrm{TPR}_k) = (k/(N-1), 0)$。\n    - 求和中的项是 $\\frac{1}{2} (k/(N-1) - (k-1)/(N-1)) (0+0) = 0$。面积贡献为零。\n\n2.  在步骤 $k=r$：\n    - 第 $r$ 个样本是正例。$\\mathrm{TP}_r=1$ 且 $\\mathrm{FP}_r=r-1$（从排名 $1$到 $r-1$的负例）。\n    - $\\mathrm{TPR}_r=1$，$\\mathrm{FPR}_r = (r-1)/(N-1)$。\n    - 前一个点是 $(\\mathrm{FPR}_{r-1}, \\mathrm{TPR}_{r-1}) = ((r-1)/(N-1), 0)$。\n    - FPR的变化是 $\\mathrm{FPR}_r - \\mathrm{FPR}_{r-1} = (r-1)/(N-1) - (r-1)/(N-1) = 0$。面积贡献为零。这一步对应于ROC图上的一条垂直线。\n\n3.  对于步骤 $k=r+1, \\dots, N$：\n    - 样本是负例。在步骤 $k$，$\\mathrm{TP}_k=1$ 且 $\\mathrm{FP}_k = k-1$（因为已经看到了排名为 $r$ 的正例和其他 $k-r$ 个负例）。\n    - $\\mathrm{TPR}_k=1$，$\\mathrm{FPR}_k = (k-1)/(N-1)$。\n    - 前一个点是 $(\\mathrm{FPR}_{k-1}, \\mathrm{TPR}_{k-1})$。对于 $kr$，$\\mathrm{TPR}_{k-1}=1$ 且 $\\mathrm{FPR}_{k-1} = ((k-1)-1)/(N-1) = (k-2)/(N-1)$。\n    - 步骤 $k$ 的梯形面积是：\n    $$ \\frac{1}{2} \\left( \\frac{k-1}{N-1} - \\frac{k-2}{N-1} \\right) (1+1) = \\frac{1}{2} \\left( \\frac{1}{N-1} \\right) (2) = \\frac{1}{N-1} $$\n    - 从 $k=r+1$ 到 $k=N$ 的每一步都有 $1/(N-1)$ 的贡献。这样的步骤数是 $N-(r+1)+1 = N-r$。\n\n总ROC-AUC是这些贡献的总和：\n$$ \\mathrm{ROC\\mbox{-}AUC} = \\sum_{k=r+1}^{N} \\frac{1}{N-1} = (N-r) \\times \\frac{1}{N-1} = \\frac{N-r}{N-1} $$\n\n**PR-AUC（平均精确率）的推导**\nPR-AUC定义为 $\\mathrm{AP} = \\sum_{k=1}^{N} \\mathrm{Prec}_k (\\mathrm{Rec}_k - \\mathrm{Rec}_{k-1})$，且 $\\mathrm{Rec}_0 = 0$。项 $(\\mathrm{Rec}_k - \\mathrm{Rec}_{k-1})$ 表示在步骤 $k$ 召回率的增加。\n\n1.  对于步骤 $k=1, \\dots, r-1$：\n    - 样本是负例，所以 $\\mathrm{TP}_k=0$。这意味着 $\\mathrm{Rec}_k = \\mathrm{TP}_k / P = 0$。\n    - 对于这些步骤，$\\mathrm{Rec}_k - \\mathrm{Rec}_{k-1} = 0 - 0 = 0$。对总和的贡献为零。\n\n2.  在步骤 $k=r$：\n    - 遇到正样本。$\\mathrm{TP}_r=1$，所以 $\\mathrm{Rec}_r=1$。\n    - 前一个召回率是 $\\mathrm{Rec}_{r-1}=0$。变化是 $\\mathrm{Rec}_r - \\mathrm{Rec}_{r-1} = 1-0=1$。\n    - 这一步的精确率是 $\\mathrm{Prec}_r = \\frac{\\mathrm{TP}_r}{\\mathrm{TP}_r + \\mathrm{FP}_r} = \\frac{1}{1 + (r-1)} = \\frac{1}{r}$。\n    - 对总和的贡献是 $\\mathrm{Prec}_r (\\mathrm{Rec}_r - \\mathrm{Rec}_{r-1}) = \\frac{1}{r} \\times 1 = \\frac{1}{r}$。\n\n3.  对于步骤 $k=r+1, \\dots, N$：\n    - $\\mathrm{TP}_k$ 保持为 $1$，所以 $\\mathrm{Rec}_k=1$。\n    - 召回率的变化是 $\\mathrm{Rec}_k - \\mathrm{Rec}_{k-1} = 1 - 1 = 0$。贡献为零。\n\nAP的求和化简为在 $k=r$ 处的单个非零项。\n$$ \\mathrm{PR\\mbox{-}AUC} = \\mathrm{AP} = \\frac{1}{r} $$\n\n**测试用例的计算**\n我们将这些推导出的公式应用于 $N=1000$ 的三个案例。\n\n- **案例 A: $(N,r) = (1000,10)$**\n    - $\\mathrm{ROC\\mbox{-}AUC} = \\frac{1000-10}{1000-1} = \\frac{990}{999} \\approx 0.990991$\n    - $\\mathrm{PR\\mbox{-}AUC} = \\frac{1}{10} = 0.1$\n    - $\\text{差值} = \\frac{990}{999} - 0.1 \\approx 0.890991$\n\n- **案例 B: $(N,r) = (1000,1)$** (完美排序)\n    - $\\mathrm{ROC\\mbox{-}AUC} = \\frac{1000-1}{1000-1} = \\frac{999}{999} = 1.0$\n    - $\\mathrm{PR\\mbox{-}AUC} = \\frac{1}{1} = 1.0$\n    - $\\text{差值} = 1.0 - 1.0 = 0.0$\n\n- **案例 C: $(N,r) = (1000,1000)$** (最差排序)\n    - $\\mathrm{ROC\\mbox{-}AUC} = \\frac{1000-1000}{1000-1} = \\frac{0}{999} = 0.0$\n    - $\\mathrm{PR\\mbox{-}AUC} = \\frac{1}{1000} = 0.001$\n    - $\\text{差值} = 0.0 - 0.001 = -0.001$\n\n这些计算展示了ROC-AUC和PR-AUC的不同敏感性。在极端不平衡的情况下，即使精确率非常低，也可以实现很高的ROC-AUC，如案例A所示。相反，PR-AUC对少数正样本的排序更为敏感。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_metrics_programmatically(N, r):\n    \"\"\"\n    Calculates ROC-AUC and PR-AUC by simulating the step-by-step process.\n    This serves as a verification of the analytically derived formulas.\n    \"\"\"\n    tp, fp = 0, 0\n    P, N_neg = 1, N - 1\n\n    roc_auc = 0.0\n    pr_auc = 0.0\n\n    tpr_prev, fpr_prev = 0.0, 0.0\n    rec_prev = 0.0\n    \n    # Loop through examples in descending order of score\n    for k in range(1, N + 1):\n        # Update TP/FP counts based on the label at rank k\n        if k == r:\n            tp += 1\n        else:\n            fp += 1\n\n        # Calculate current rates\n        tpr_curr = tp / P if P > 0 else 0.0\n        fpr_curr = fp / N_neg if N_neg > 0 else 0.0\n        rec_curr = tpr_curr\n        # Precision is defined only for tp+fp > 0\n        prec_curr = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n\n        # Update ROC-AUC using the trapezoidal rule\n        # Area of trapezoid = width * average height\n        roc_auc += (fpr_curr - fpr_prev) * (tpr_curr + tpr_prev) / 2.0\n\n        # Update PR-AUC (Average Precision)\n        # Add Prec * delta_Rec for steps where recall increases\n        delta_rec = rec_curr - rec_prev\n        if delta_rec > 0:\n            pr_auc += prec_curr * delta_rec\n\n        # Update \"previous\" state for the next iteration\n        tpr_prev, fpr_prev = tpr_curr, fpr_curr\n        rec_prev = rec_curr\n\n    return [roc_auc, pr_auc, roc_auc - pr_auc]\n\ndef calculate_metrics_analytically(N, r):\n    \"\"\"\n    Calculates ROC-AUC and PR-AUC using the derived closed-form formulas.\n    \"\"\"\n    # Derived formula for ROC-AUC\n    # With one positive at rank r, the TPR is 1 for all N-r+1 examples from rank r to N.\n    # The FPR goes from (r-1)/(N-1) to (N-1)/(N-1) while TPR is 1.\n    # The area of this rectangle is height * width = 1 * (1 - (r-1)/(N-1)) = (N-r)/(N-1)\n    # The simple Wilcoxon-Mann-Whitney U statistic interpretation also gives AUC = (N-r)/N_neg = (N-r)/(N-1).\n    roc_auc = (N - r) / (N - 1) if N > 1 else 0.5\n    \n    # Derived formula for PR-AUC (Average Precision)\n    # Recall only jumps from 0 to 1 at rank r. The precision at that point is 1/r.\n    # So AP = Prec@r * (Rec@r - Rec@(r-1)) = (1/r) * (1 - 0) = 1/r.\n    pr_auc = 1 / r\n    \n    diff = roc_auc - pr_auc\n    \n    return [roc_auc, pr_auc, diff]\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        (1000, 10),    # Case A\n        (1000, 1),     # Case B\n        (1000, 1000),  # Case C\n    ]\n\n    results = []\n    for N, r in test_cases:\n        # The analytical solution is exact and derived from the problem's definitions.\n        # It is more efficient and robust than a programmatic simulation.\n        case_values = calculate_metrics_analytically(N, r)\n        \n        # Format each value to six decimal places and create the string representation\n        # of the list for this case, e.g., \"[0.990991,0.100000,0.890991]\"\n        formatted_case_values = [f\"{val:.6f}\" for val in case_values]\n        results.append(f\"[{','.join(formatted_case_values)}]\")\n\n    # Join the results for all cases into the final output string format:\n    # \"[[...],[...],[...]]\"\n    final_output = f\"[{','.join(results)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "评估模型的最终目的是为了做出更优的决策。然而，诸如 $F_1$ 分数等标准指标隐含了对不同错误类型成本的特定假设，这可能与实际业务需求不符。本练习将带领你完成从模型评估到决策制定的完整闭环，你将学会如何基于明确的、非对称的误分类成本（例如，将病人误诊为健康的成本远高于将健康人误诊为病人的成本）来推导最优决策阈值，并量化因追求 $F_1$ 分数最大化而非成本最小化所带来的“遗憾”（regret）。",
            "id": "3118850",
            "problem": "一个二元分类器为每个输入实例生成一个校准分数 $s \\in [0,1]$，该分数被解释为正类的条件概率 $s = \\mathbb{P}(Y=1 \\mid X)$。决策规则是：如果 $s \\geq t$（其中 $t$ 是某个阈值），则将实例分类为正类。考虑以下包含12个实例的数据集，每个实例为一对 $(s_i, y_i)$，其中 $y_i \\in \\{0,1\\}$ 是真实标签（1为正类，0为负类）：\n$(0.95, 1)$; $(0.85, 1)$; $(0.70, 0)$; $(0.65, 1)$; $(0.60, 0)$; $(0.55, 1)$; $(0.50, 0)$; $(0.40, 1)$; $(0.35, 0)$; $(0.20, 0)$; $(0.10, 0)$; $(0.05, 1)$。\n\n假设错分成本是不对称的，假阴性（false negative）成本为 $C_{\\mathrm{FN}} = 20$，假阳性（false positive）成本为 $C_{\\mathrm{FP}} = 1$。对于一个校准分数为 $s$ 的实例，其确定性决策的期望成本定义如下：如果分类为正类，期望成本为 $C_{\\mathrm{FP}} \\cdot (1 - s)$；如果分类为负类，期望成本为 $C_{\\mathrm{FN}} \\cdot s$。\n\n你需要：\n- 根据第一性原理，使用风险最小化来确定最小化期望错分成本的阈值 $t_{\\mathrm{cost}}$，并通过对所有实例的期望成本求和，计算在该阈值下数据集的总期望成本。\n- 仅使用混淆矩阵计数（真阳性、假阳性、真阴性、假阴性）、精确率、召回率和谐波平均数的基本定义，从数据集中的唯一分数集合中选择一个阈值 $t_{F1}$，以最大化该数据集上的 $F_1$ 分数。然后，通过对所有实例的期望成本求和，计算在 $t_{F1}$ 阈值下数据集的总期望成本。\n- 将优化 $F_1$ 分数而非期望成本的“悔憾”（regret）量化为在 $t_{F1}$ 下的总期望成本与在 $t_{\\mathrm{cost}}$ 下的总期望成本之差。\n\n将你计算出的最终悔憾数值四舍五入到四位有效数字。你的最终答案应该是一个无单位的实数。",
            "solution": "### 第1步：提取已知条件\n- 一个包含12个实例的数据集，每个实例为一对 $(s_i, y_i)$，其中 $s_i$ 是校准分数，$y_i$ 是真实标签：\n  $(0.95, 1)$、$(0.85, 1)$、$(0.70, 0)$、$(0.65, 1)$、$(0.60, 0)$、$(0.55, 1)$、$(0.50, 0)$、$(0.40, 1)$、$(0.35, 0)$、$(0.20, 0)$、$(0.10, 0)$、$(0.05, 1)$。\n- 真实标签 $y_i \\in \\{0,1\\}$，其中1为正类，0为负类。\n- 分数 $s$ 被解释为条件概率 $\\mathbb{P}(Y=1 \\mid X)$。\n- 决策规则是：如果 $s \\geq t$（对于某个阈值 $t$），则分类为正类。\n- 假阴性成本为 $C_{\\mathrm{FN}} = 20$。\n- 假阳性成本为 $C_{\\mathrm{FP}} = 1$。\n- 对于一个分数为 $s$ 的实例，如果分类为正类，其期望成本为 $C_{\\mathrm{FP}} \\cdot (1 - s)$。\n- 对于一个分数为 $s$ 的实例，如果分类为负类，其期望成本为 $C_{\\mathrm{FN}} \\cdot s$。\n- 任务是：\n  1. 确定成本最小化阈值 $t_{\\mathrm{cost}}$，并计算在该阈值下数据集的总期望成本。\n  2. 从唯一的 数据 分数集合中确定最大化 $F_1$ 分数的阈值 $t_{F1}$，并计算在该阈值下数据集的总期望成本。\n  3. 计算悔憾，定义为总期望成本之差。\n\n### 第2步：使用提取的已知条件进行验证\n- **科学性：** 该问题植根于统计决策理论和二元分类器评估，这些都是机器学习和统计学的核心概念。使用期望成本最小化和 $F_1$ 分数是标准做法。\n- **适定性：** 所有必要组成部分均已提供：一个完整的数据集、明确的成本值以及对任务和指标的清晰定义。该问题是自洽的，能够得出一个唯一、稳定且有意义的解。\n- **客观性：** 语言精确且无偏见。所用术语（例如，“校准分数”、“期望成本”、“$F_1$ 分数”）在该领域具有标准的、无歧义的定义。\n\n### 第3步：结论与行动\n问题有效。有必要提供完整解答。\n\n### 第1部分：风险最小化与最优成本阈值\n我们寻求最小化期望错分成本的阈值 $t_{\\mathrm{cost}}$。对于分数为 $s = \\mathbb{P}(Y=1 \\mid X)$ 的单个实例，其为负类的概率是 $\\mathbb{P}(Y=0 \\mid X) = 1 - s$。\n\n将该实例分类为正类（行动 $a=1$）的期望成本为：\n$$E[\\text{Cost} \\mid s, a=1] = C_{\\mathrm{FP}} \\cdot \\mathbb{P}(Y=0 \\mid X) = C_{\\mathrm{FP}}(1-s)$$\n将该实例分类为负类（行动 $a=0$）的期望成本为：\n$$E[\\text{Cost} \\mid s, a=0] = C_{\\mathrm{FN}} \\cdot \\mathbb{P}(Y=1 \\mid X) = C_{\\mathrm{FN}} s$$\n\n风险最小化原则要求我们选择期望成本较低的行动。我们应该在以下情况下将其分类为正类：\n$$E[\\text{Cost} \\mid s, a=1] \\leq E[\\text{Cost} \\mid s, a=0]$$\n$$C_{\\mathrm{FP}}(1-s) \\leq C_{\\mathrm{FN}} s$$\n代入给定的成本值，$C_{\\mathrm{FP}} = 1$ 和 $C_{\\mathrm{FN}} = 20$：\n$$1(1-s) \\leq 20 s$$\n$$1 - s \\leq 20 s$$\n$$1 \\leq 21 s$$\n$$s \\geq \\frac{1}{21}$$\n决策规则是，如果分数 $s$ 大于或等于阈值 $t_{\\mathrm{cost}} = \\frac{1}{21}$，则分类为正类。\n数值上，$t_{\\mathrm{cost}} \\approx 0.0476$。\n数据集中最小的分数是 $s=0.05$。因为 $0.05 = \\frac{1}{20}$ 且 $\\frac{1}{20}  \\frac{1}{21}$，所以数据集中每个实例的分数 $s_i$ 都大于 $t_{\\mathrm{cost}}$。\n因此，在这个最优阈值下，每个实例都被分类为正类。\n\n根据决策规则，数据集上的总期望成本 $C_{\\mathrm{total}}(t_{\\mathrm{cost}})$ 是每个实例期望成本的总和。由于所有实例都被分类为正类，每个实例的成本是 $C_{\\mathrm{FP}}(1-s_i) = 1(1-s_i)$。\n$$C_{\\mathrm{total}}(t_{\\mathrm{cost}}) = \\sum_{i=1}^{12} (1-s_i) = 12 - \\sum_{i=1}^{12} s_i$$\n我们来计算分数的总和：\n$$\\sum s_i = 0.95+0.85+0.70+0.65+0.60+0.55+0.50+0.40+0.35+0.20+0.10+0.05 = 5.90$$\n总期望成本为：\n$$C_{\\mathrm{total}}(t_{\\mathrm{cost}}) = 12 - 5.90 = 6.10$$\n\n### 第2部分：$F_1$ 分数最大化及其相关成本\n$F_1$ 分数是精确率（$P$）和召回率（$R$）的调和平均数：\n$$F_1 = 2 \\cdot \\frac{P \\cdot R}{P+R}$$\n其中 $P = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}$ 且 $R = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$。这里，$\\mathrm{TP}$、$\\mathrm{FP}$ 和 $\\mathrm{FN}$ 分别是真阳性、假阳性和假阴性的数量。数据集中正类实例的总数为 $P_{true} = 6$，负类实例的总数为 $N_{true} = 6$。\n\n我们将数据集中每个唯一的分数值作为潜在阈值 $t$ 来评估 $F_1$ 分数。决策规则是：如果 $s_i \\geq t$，则预测为正类。\n\n- $t = 0.95$：$\\mathrm{TP}=1, \\mathrm{FP}=0$。 $P=\\frac{1}{1}=1, R=\\frac{1}{6}$。 $F_1 = \\frac{2 \\cdot 1 \\cdot \\frac{1}{6}}{1+\\frac{1}{6}} = \\frac{1/3}{7/6} = \\frac{2}{7}$。\n- $t = 0.85$：$\\mathrm{TP}=2, \\mathrm{FP}=0$。 $P=\\frac{2}{2}=1, R=\\frac{2}{6}=\\frac{1}{3}$。 $F_1 = \\frac{2 \\cdot 1 \\cdot \\frac{1}{3}}{1+\\frac{1}{3}} = \\frac{2/3}{4/3} = \\frac{1}{2}$。\n- $t = 0.70$：$\\mathrm{TP}=2, \\mathrm{FP}=1$。 $P=\\frac{2}{3}, R=\\frac{2}{6}=\\frac{1}{3}$。 $F_1 = \\frac{2 \\cdot \\frac{2}{3} \\cdot \\frac{1}{3}}{\\frac{2}{3}+\\frac{1}{3}} = \\frac{4/9}{1} = \\frac{4}{9}$。\n- $t = 0.65$：$\\mathrm{TP}=3, \\mathrm{FP}=1$。 $P=\\frac{3}{4}, R=\\frac{3}{6}=\\frac{1}{2}$。 $F_1 = \\frac{2 \\cdot \\frac{3}{4} \\cdot \\frac{1}{2}}{\\frac{3}{4}+\\frac{1}{2}} = \\frac{3/4}{5/4} = \\frac{3}{5}$。\n- $t = 0.55$：$\\mathrm{TP}=4, \\mathrm{FP}=2$。 $P=\\frac{4}{6}=\\frac{2}{3}, R=\\frac{4}{6}=\\frac{2}{3}$。 $F_1 = \\frac{2 \\cdot \\frac{2}{3} \\cdot \\frac{2}{3}}{\\frac{2}{3}+\\frac{2}{3}} = \\frac{8/9}{4/3} = \\frac{2}{3}$。\n- $t = 0.50$：$\\mathrm{TP}=4, \\mathrm{FP}=3$。 $P=\\frac{4}{7}, R=\\frac{4}{6}=\\frac{2}{3}$。 $F_1 = \\frac{2 \\cdot \\frac{4}{7} \\cdot \\frac{2}{3}}{\\frac{4}{7}+\\frac{2}{3}} = \\frac{16/21}{26/21} = \\frac{8}{13}$。\n- $t = 0.40$：$\\mathrm{TP}=5, \\mathrm{FP}=3$。 $P=\\frac{5}{8}, R=\\frac{5}{6}$。 $F_1 = \\frac{2 \\cdot \\frac{5}{8} \\cdot \\frac{5}{6}}{\\frac{5}{8}+\\frac{5}{6}} = \\frac{50/48}{35/24} = \\frac{25/24}{35/24} = \\frac{25}{35} = \\frac{5}{7}$。\n- $t = 0.35$：$\\mathrm{TP}=5, \\mathrm{FP}=4$。 $P=\\frac{5}{9}, R=\\frac{5}{6}$。 $F_1 = \\frac{2 \\cdot \\frac{5}{9} \\cdot \\frac{5}{6}}{\\frac{5}{9}+\\frac{5}{6}} = \\frac{50/54}{25/18} = \\frac{25/27}{25/18} = \\frac{18}{27} = \\frac{2}{3}$。\n- $t = 0.20$：$\\mathrm{TP}=5, \\mathrm{FP}=5$。 $P=\\frac{5}{10}=\\frac{1}{2}, R=\\frac{5}{6}$。 $F_1 = \\frac{2 \\cdot \\frac{1}{2} \\cdot \\frac{5}{6}}{\\frac{1}{2}+\\frac{5}{6}} = \\frac{5/6}{8/6} = \\frac{5}{8}$。\n- $t = 0.10$：$\\mathrm{TP}=5, \\mathrm{FP}=6$。 $P=\\frac{5}{11}, R=\\frac{5}{6}$。 $F_1 = \\frac{2 \\cdot \\frac{5}{11} \\cdot \\frac{5}{6}}{\\frac{5}{11}+\\frac{5}{6}} = \\frac{50/66}{85/66} = \\frac{50}{85} = \\frac{10}{17}$。\n- $t = 0.05$：$\\mathrm{TP}=6, \\mathrm{FP}=6$。 $P=\\frac{6}{12}=\\frac{1}{2}, R=\\frac{6}{6}=1$。 $F_1 = \\frac{2 \\cdot \\frac{1}{2} \\cdot 1}{\\frac{1}{2}+1} = \\frac{1}{3/2} = \\frac{2}{3}$。\n\n比较 $F_1$ 分数：$\\frac{2}{7} \\approx 0.286$, $\\frac{1}{2}=0.5$, $\\frac{4}{9}\\approx 0.444$, $\\frac{3}{5}=0.6$, $\\frac{2}{3}\\approx 0.667$, $\\frac{8}{13}\\approx 0.615$, $\\frac{5}{7}\\approx 0.714$, $\\frac{5}{8}=0.625$, $\\frac{10}{17}\\approx 0.588$。\n最大的 $F_1$ 分数是 $\\frac{5}{7}$，出现在阈值 $t_{F1} = 0.40$ 处。\n\n现在，我们计算 $t_{F1} = 0.40$ 时的总期望成本。\n- 对于 $s_i \\geq 0.40$ 的实例，我们分类为正类，成本为 $1(1-s_i)$。这些分数是：$0.95, 0.85, 0.70, 0.65, 0.60, 0.55, 0.50, 0.40$。\n- 对于 $s_i  0.40$ 的实例，我们分类为负类，成本为 $20 s_i$。这些分数是：$0.35, 0.20, 0.10, 0.05$。\n\n总期望成本 $C_{\\mathrm{total}}(t_{F1})$ 为：\n$$C_{\\mathrm{total}}(t_{F1}) = \\sum_{s_i \\geq 0.40} (1-s_i) + \\sum_{s_i  0.40} 20 s_i$$\n第一组的总和：\n$$ (1-0.95) + (1-0.85) + (1-0.70) + (1-0.65) + (1-0.60) + (1-0.55) + (1-0.50) + (1-0.40) $$\n$$ = 0.05 + 0.15 + 0.30 + 0.35 + 0.40 + 0.45 + 0.50 + 0.60 = 2.80 $$\n第二组的总和：\n$$ 20(0.35) + 20(0.20) + 20(0.10) + 20(0.05) $$\n$$ = 7 + 4 + 2 + 1 = 14.0 $$\n总期望成本：\n$$ C_{\\mathrm{total}}(t_{F1}) = 2.80 + 14.0 = 16.80 $$\n\n### 第3部分：悔憾计算\n优化 $F_1$ 分数而非期望成本的悔憾，是在 $t_{F1}$ 下的总成本与使用 $t_{\\mathrm{cost}}$ 实现的最小可能总成本之间的差值。\n$$ \\text{Regret} = C_{\\mathrm{total}}(t_{F1}) - C_{\\mathrm{total}}(t_{\\mathrm{cost}}) $$\n$$ \\text{Regret} = 16.80 - 6.10 = 10.70 $$\n问题要求答案四舍五入到四位有效数字。计算出的值 $10.70$ 已经是这种形式。",
            "answer": "$$\n\\boxed{10.70}\n$$"
        }
    ]
}