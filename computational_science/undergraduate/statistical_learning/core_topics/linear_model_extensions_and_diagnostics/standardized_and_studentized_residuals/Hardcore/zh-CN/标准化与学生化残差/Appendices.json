{
    "hands_on_practices": [
        {
            "introduction": "抽象的公式可能令人望而生畏。本练习旨在通过分析最简单的线性模型——仅含截距的模型，将看似复杂的标准化残差公式与入门统计学中熟悉的 Z 分数联系起来。通过推导这两个概念之间的直接关系，你将在一个清晰的背景下揭示标准化的核心思想 。",
            "id": "3176927",
            "problem": "考虑一个仅含截距项的单变量线性回归：对于由 $i \\in \\{1,2,\\ldots,n\\}$ 索引的观测值，模型为 $y_{i} = \\beta_{0} + \\varepsilon_{i}$，其中 $\\varepsilon_{i}$ 独立同分布于 $\\mathcal{N}(0,\\sigma^{2})$。设设计矩阵为 $X = \\mathbf{1}$，即一个 $n \\times 1$ 的全一向量。设 $\\hat{y}_{i}$ 表示拟合值，$e_{i} = y_{i} - \\hat{y}_{i}$ 为残差，而 $H$ 为帽子矩阵，其元素为 $h_{ij}$。定义残差平方和 $\\mathrm{RSS} = \\sum_{i=1}^{n} e_{i}^{2}$ 和残差标准误 $s = \\sqrt{\\mathrm{RSS}/(n-p)}$，其中 $p=1$。标准化残差定义为 $r_{i} = \\dfrac{e_{i}}{s \\sqrt{1 - h_{ii}}}$。设 $\\bar{y} = \\dfrac{1}{n}\\sum_{i=1}^{n} y_{i}$ 和样本标准差 $s_{y} = \\sqrt{\\dfrac{1}{n-1}\\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}}$。定义 $z$-分数为 $z_{i} = \\dfrac{y_{i} - \\bar{y}}{s_{y}}$。\n\n从线性模型中帽子矩阵、残差和方差估计量的标准定义出发，并且不预先假设任何仅含截距项模型的特有结果，推导 $h_{ii}$，展示 $s$ 和 $s_{y}$ 之间的关系，并获得一个仅用 $z_{i}$ 和 $n$ 表示的标准化残差 $r_{i}$ 的闭式表达式。请将你的最终答案表示为仅包含 $z_{i}$ 和 $n$ 的 $r_{i}$ 的单一闭式解析表达式。无需进行数值四舍五入。",
            "solution": "目标是为一个仅含截距项的单变量线性回归模型，推导出一个用 $z$-分数 $z_{i}$ 和样本量 $n$ 表示的标准化残差 $r_{i}$ 的闭式表达式。按要求，推导过程从第一性原理出发。\n\n模型被指定为 $y_{i} = \\beta_{0} + \\varepsilon_{i}$，对于 $i \\in \\{1, 2, \\ldots, n\\}$，其中误差项 $\\varepsilon_{i}$ 独立同分布于 $\\mathcal{N}(0,\\sigma^{2})$。该模型的设计矩阵是 $X = \\mathbf{1}$，一个 $n \\times 1$ 的全一列向量。\n\n首先，我们确定参数 $\\beta_{0}$ 的普通最小二乘 (OLS) 估计量，记作 $\\hat{\\beta}_{0}$。OLS 估计向量的一般公式是 $\\hat{\\beta} = (X^{T}X)^{-1}X^{T}y$。我们计算我们特定模型的各个组成部分。\n$X^{T}X$ 项为：\n$$X^{T}X = \\mathbf{1}^{T}\\mathbf{1} = \\sum_{i=1}^{n} 1^{2} = n$$\n其逆为 $(X^{T}X)^{-1} = n^{-1} = \\frac{1}{n}$。\n$X^{T}y$ 项为：\n$$X^{T}y = \\mathbf{1}^{T}y = \\sum_{i=1}^{n} y_{i}$$\n根据定义，样本均值为 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_{i}$，这意味着 $\\sum_{i=1}^{n} y_{i} = n\\bar{y}$。\n将这些代入 OLS 公式，得到标量估计 $\\hat{\\beta}_{0}$：\n$$\\hat{\\beta}_{0} = \\left(\\frac{1}{n}\\right)(n\\bar{y}) = \\bar{y}$$\n\n接下来，我们计算拟合值 $\\hat{y}_{i}$。拟合值向量为 $\\hat{y} = X\\hat{\\beta}_{0}$。\n$$\\hat{y} = \\mathbf{1}\\bar{y}$$\n这意味着对于所有 $i \\in \\{1, \\ldots, n\\}$，每个单独的拟合值为 $\\hat{y}_{i} = \\bar{y}$。\n\n帽子矩阵 $H$ 定义为 $H = X(X^{T}X)^{-1}X^{T}$。使用我们之前计算出的项：\n$$H = \\mathbf{1}\\left(\\frac{1}{n}\\right)\\mathbf{1}^{T} = \\frac{1}{n}\\mathbf{1}\\mathbf{1}^{T}$$\n外积 $\\mathbf{1}\\mathbf{1}^{T}$ 产生一个 $n \\times n$ 的矩阵，其中每个元素都为 $1$。因此，帽子矩阵 $H$ 是一个 $n \\times n$ 矩阵，其中每个元素 $h_{ij}$ 都等于 $\\frac{1}{n}$。因此，计算标准化残差所需的帽子矩阵的对角元素对于所有 $i$ 都是 $h_{ii} = \\frac{1}{n}$。\n\n残差由 $e_{i} = y_{i} - \\hat{y}_{i}$ 定义。代入拟合值的表达式，我们得到：\n$$e_{i} = y_{i} - \\bar{y}$$\n\n残差平方和 (RSS) 是平方残差的总和：\n$$\\mathrm{RSS} = \\sum_{i=1}^{n} e_{i}^{2} = \\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}$$\n\n残差标准误 $s$ 定义为 $s = \\sqrt{\\mathrm{RSS}/(n-p)}$，其中 $p$ 是模型中估计参数的数量。对于仅含截距项的模型，我们估计一个参数 $\\beta_0$，所以 $p=1$。\n$$s = \\sqrt{\\frac{\\mathrm{RSS}}{n-1}} = \\sqrt{\\frac{\\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}}{n-1}}$$\n\n问题给出了 $y$ 的样本标准差的定义为 $s_{y} = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}}$。通过直接比较 $s$ 和 $s_{y}$ 的表达式，我们建立了关键关系 $s = s_{y}$。\n\n现在我们准备推导标准化残差 $r_{i}$ 的表达式。其定义为 $r_{i} = \\dfrac{e_{i}}{s \\sqrt{1 - h_{ii}}}$。\n我们代入上面推导出的表达式：$e_{i} = y_{i} - \\bar{y}$，$s = s_{y}$，和 $h_{ii} = \\frac{1}{n}$。\n$$r_{i} = \\frac{y_{i} - \\bar{y}}{s_{y} \\sqrt{1 - \\frac{1}{n}}}$$\n化简分母中的项：\n$$r_{i} = \\frac{y_{i} - \\bar{y}}{s_{y} \\sqrt{\\frac{n-1}{n}}}$$\n\n最后一步是用给定的 $z$-分数来表示这个结果，其定义为 $z_{i} = \\dfrac{y_{i} - \\bar{y}}{s_{y}}$。我们将 $z_i$ 代入 $r_i$ 的表达式中：\n$$r_{i} = \\frac{z_{i}}{\\sqrt{\\frac{n-1}{n}}}$$\n整理这个表达式，得到标准化残差 $r_i$ 和 $z$-分数 $z_i$ 之间的最终闭式关系：\n$$r_{i} = z_{i} \\sqrt{\\frac{n}{n-1}}$$\n按要求，该表达式仅依赖于 $z_{i}$ 和 $n$。",
            "answer": "$$\\boxed{z_{i} \\sqrt{\\frac{n}{n-1}}}$$"
        },
        {
            "introduction": "较大的原始残差并不总是代表最需要关注的异常点，因为高杠杆值点可能会扭曲整个模型的拟合。这个动手编程练习将引导你构建一个同时包含高杠杆值点和高残差值点的数据集，让你亲眼见证为何在识别真实异常点方面，学生化残差通常比标准化残差更有效 。这项练习将加深你对杠杆值、残差和异常点检测之间相互作用的直观理解。",
            "id": "3176898",
            "problem": "考虑经典线性回归模型 $y = X\\beta + \\varepsilon$，其中 $X \\in \\mathbb{R}^{n \\times p}$ 是一个固定的设计矩阵（包含一列1以模拟截距），$\\beta \\in \\mathbb{R}^p$ 是参数向量，$\\varepsilon \\in \\mathbb{R}^{n}$ 是一个随机误差向量，假定其满足 $\\mathbb{E}[\\varepsilon] = 0$ 和 $\\mathrm{Var}(\\varepsilon) = \\sigma^2 I_n$。使用普通最小二乘（OLS）估计量 $\\hat{\\beta}$ 及其相关的残差向量 $e = y - X\\hat{\\beta}$、对角线元素为 $h_{ii}$ 的帽子矩阵 $H = X(X^\\top X)^{-1}X^\\top$ 以及自由度 $n - p$，从第一性原理出发，构建并分析标准化残差和学生化残差。\n\n您必须编写一个完整的程序，该程序：\n- 构建多个数据集，每个数据集包含一组位于真实直线附近的基准点集，以及两个特殊点：\n  1. 一个具有大杠杆值（$h_{ii}$ 大）但残差大小 $|e_i|$ 小的点。\n  2. 一个具有小杠杆值（$h_{ii}$ 小）但残差大小 $|e_i|$ 大的点。\n- 为每个数据集拟合带有截距和一个预测变量的OLS模型，计算所有观测值的 $e_i$ 和 $h_{ii}$，然后从线性回归的模型假设和核心定义出发，为每个观测值计算标准化残差 $r_i$ 和学生化残差 $t_i$。不要使用任何预封装的回归函数；直接从OLS、帽子矩阵和基于残差的方差估计量的定义中推导并实现所有需要的量。\n\n对于基准线，使用确定性模型 $y = \\beta_0 + \\beta_1 x$，其中 $\\beta_0 = 2$ 且 $\\beta_1 = 1.5$。通过以下方式构建每个数据集：\n- 在闭区间 $[-x_{\\max}, x_{\\max}]$上创建 $n_{\\text{base}}$ 个关于0对称的等距设计点 $x$，噪声为零。\n- 在 $x_{\\text{HL}}$ 处附加高杠杆点，其响应值恰好在真实直线上，并加上一个指定的小偏移量 $\\epsilon_{\\text{HL}}$。\n- 在 $x = 0$ 处附加低杠杆点，但其响应值与真实直线偏离一个指定的大量 $\\delta_{\\text{LL}}$。\n\n观测值的索引从0开始，并将这两个特殊点按顺序附加到末尾：首先是高杠杆点，然后是低杠杆大残差点的索引是 $n_{\\text{base}} + 1$。\n\n仅使用模型假设和定义，计算：\n- 所有 $i$ 的OLS估计值 $\\hat{\\beta}$ 和残差 $e_i$。\n- 通过帽子矩阵 $H$ 计算所有 $i$ 的杠杆值 $h_{ii}$。\n- 所有 $i$ 的标准化残差 $r_i$ 和学生化残差 $t_i$。\n\n您的程序必须处理以下参数集测试套件，每个参数集以元组 $(n_{\\text{base}}, x_{\\max}, x_{\\text{HL}}, \\delta_{\\text{LL}}, \\epsilon_{\\text{HL}})$ 的形式给出：\n- 测试用例 1：$(12, 3, 15, 15, 0)$。\n- 测试用例 2：$(10, 2, 50, 10, 0)$。\n- 测试用例 3：$(12, 3, 8, 6, 0.5)$。\n\n对于每个数据集，生成四个量：\n1. 具有最大标准化残差绝对值 $|r_i|$ 的观测值的索引 $i_r$。\n2. 具有最大学生化残差绝对值 $|t_i|$ 的观测值的索引 $i_t$。\n3. 一个布尔值 $b_1$，指示对于低杠杆大残差点，其学生化残差的大小是否超过标准化残差的大小，即在索引 $n_{\\text{base}}+1$ 处是否有 $|t_i| > |r_i|$。\n4. 一个布尔值 $b_2$，指示对于高杠杆小残差点，其标准化残差的大小是否至少与学生化残差的大小相等，即在索引 $n_{\\text{base}}$ 处是否有 $|r_i| \\ge |t_i|$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个结果本身就是一个列表 $[i_r, i_t, b_1, b_2]$，对应一个测试用例，顺序与测试套件相同（例如，$[[i_{r,1}, i_{t,1}, b_{1,1}, b_{2,1}], [i_{r,2}, i_{t,2}, b_{1,2}, b_{2,2}], [i_{r,3}, i_{t,3}, b_{1,3}, b_{2,3}]]$）。此问题不涉及物理单位或角度单位。",
            "solution": "用户提供的问题是有效的。这是一个在统计学习领域内定义明确的计算任务，基于线性回归分析的既定原则。该问题自成体系，科学上是合理的，所有参数和目标都已明确说明。解决方案将按照要求，从第一性原理出发实现所需的计算。\n\n### 理论基础与方法\n\n该问题要求在简单线性回归模型 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 中对残差进行分析。这可以表示为矩阵形式 $y = X\\beta + \\varepsilon$，其中 $y$ 是响应值的 $n \\times 1$ 向量，$X$ 是 $n \\times p$ 的设计矩阵（对于简单线性回归，$p=2$），$\\beta$ 是参数的 $p \\times 1$ 向量，$\\varepsilon$ 是随机误差的 $n \\times 1$ 向量。假设误差是独立同分布的，均值为0，方差为 $\\sigma^2$，即 $\\mathbb{E}[\\varepsilon] = 0$ 且 $\\mathrm{Var}(\\varepsilon) = \\sigma^2 I_n$。\n\n**1. 普通最小二乘（OLS）估计**\n参数向量 $\\beta$ 的OLS估计量 $\\hat{\\beta}$ 是通过最小化残差平方和 $S(\\beta) = (y - X\\beta)^\\top(y - X\\beta)$ 得到的。这会产生正规方程 $(X^\\top X)\\hat{\\beta} = X^\\top y$。假设矩阵 $X^\\top X$ 是可逆的（如果 $X$ 具有满列秩，则此条件成立），那么唯一的OLS估计量是：\n$$ \\hat{\\beta} = (X^\\top X)^{-1} X^\\top y $$\n拟合值向量为 $\\hat{y} = X\\hat{\\beta}$，残差向量为 $e = y - \\hat{y}$。\n\n**2. 帽子矩阵与杠杆值**\n拟合值可以表示为观测值 $y$ 的线性变换：\n$$ \\hat{y} = X((X^\\top X)^{-1} X^\\top y) = H y $$\n矩阵 $H = X(X^\\top X)^{-1}X^\\top$ 被称为“帽子矩阵”，因为它将 $y$ 变换为 $\\hat{y}$。它是一个 $n \\times n$ 的对称幂等（$H^2 = H$）投影矩阵。帽子矩阵的对角元素 $h_{ii}$ 被称为杠杆值。每个 $h_{ii}$ 衡量第 $i$ 个响应值 $y_i$ 对其自身拟合值 $\\hat{y}_i$ 的影响程度，因为 $\\hat{y}_i = \\sum_{j=1}^n H_{ij} y_j = h_{ii}y_i + \\sum_{j \\ne i} h_{ij} y_j$。杠杆值的取值范围是 $0 \\le h_{ii} \\le 1$。高杠杆值表示第 $i$ 个观测值在预测变量（$x$ 值）的空间中是一个离群点。\n\n**3. 残差分析**\n残差由 $e = y - \\hat{y} = y - Hy = (I - H)y$ 给出。残差的方差-协方差矩阵是：\n$$ \\mathrm{Var}(e) = \\mathrm{Var}((I-H)y) = (I-H)\\mathrm{Var}(y)(I-H)^\\top = (I-H)(\\sigma^2 I)(I-H) = \\sigma^2(I-H) $$\n因此，单个残差 $e_i$ 的方差是 $\\mathrm{Var}(e_i) = \\sigma^2(1 - h_{ii})$。误差方差 $\\sigma^2$ 的一个无偏估计量是均方误差（MSE）：\n$$ \\hat{\\sigma}^2 = \\frac{e^\\top e}{n-p} = \\frac{\\sum_{i=1}^n e_i^2}{n-p} $$\n其中 $n-p$ 是残差自由度。\n\n**4. 标准化残差**\n标准化残差考虑了原始残差 $e_i$ 方差不相等的事实。对于观测值 $i$，其标准化残差（记为 $r_i$）是原始残差除以其标准差的估计值：\n$$ r_i = \\frac{e_i}{\\widehat{\\mathrm{sd}}(e_i)} = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1 - h_{ii}}} $$\n这个度量根据每个残差的杠杆值对其进行调整。一个高杠杆点（$h_{ii}$ 大）的残差将被放大。\n\n**5. 学生化残差**\n标准化残差的一个关键问题是，被评估的观测值 $i$ 本身也参与了 $\\hat{\\sigma}$ 的估计。如果观测值 $i$ 是一个显著的离群点，它会夸大 $\\hat{\\sigma}$，从而导致标准化残差变小，进而“掩盖”其自身的离群状态。学生化残差（或称外部学生化残差）$t_i$ 通过使用一个在移除第 $i$ 个观测值后进行回归拟合所计算出的方差估计值 $\\hat{\\sigma}_{(i)}^2$ 来解决这个问题：\n$$ t_i = \\frac{e_i}{\\hat{\\sigma}_{(i)}\\sqrt{1 - h_{ii}}} $$\n一个计算上高效的公式将 $t_i$ 与标准化残差 $r_i$ 联系起来：\n$$ t_i = r_i \\sqrt{\\frac{n - p - 1}{n - p - r_i^2}} $$\n这个公式表明，当且仅当 $r_i^2 > 1$ 时，才有 $|t_i| > |r_i|$，这意味着学生化残差会进一步放大已经很大的标准化残差的量级，使其成为一个更敏感的离群点检测诊断工具。\n\n### 实现策略\n\n程序将按如下方式处理每个测试用例：\n1.  **数据构建**：对于每组参数 $(n_{\\text{base}}, x_{\\max}, x_{\\text{HL}}, \\delta_{\\text{LL}}, \\epsilon_{\\text{HL}})$，生成 $x$ 和 $y$ 向量。这包括在直线 $y = 2 + 1.5x$ 上创建基准点，并附加指定的高杠杆点和低杠杆/大残差点。\n2.  **模型拟合**：通过在 $x$ 向量前添加一列1来构建设计矩阵 $X$。然后，使用矩阵运算计算OLS估计值 $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y$。\n3.  **残差与杠杆值计算**：计算残差 $e = y - X\\hat{\\beta}$ 和作为帽子矩阵 $H = X(X^\\top X)^{-1}X^\\top$ 对角线元素的杠杆值 $h_{ii}$。\n4.  **诊断量计算**：计算方差估计值 $\\hat{\\sigma}^2$，然后使用各自的公式计算标准化残差 $r$ 和学生化残差 $t$ 的向量。\n5.  **结果提取**：从计算出的向量中，确定最大绝对标准化残差和最大绝对学生化残差的索引，并评估关于特殊点的两个指定布尔条件。\n6.  **输出格式化**：将所有测试用例的结果整理成一个列表的列表，并将其格式化为字符串作为最终输出。\n\n该实现依赖 `numpy` 库进行数值线性代数运算，并严格遵守从第一性原理推导出的公式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_residuals(n_base: int, x_max: float, x_HL: float, delta_LL: float, epsilon_HL: float) -> list:\n    \"\"\"\n    Constructs a dataset, fits an OLS model from first principles, and computes\n    standardized and studentized residuals to identify influential points.\n\n    Args:\n        n_base: Number of base points for the regression line.\n        x_max: The maximum absolute value for the range of base x-points.\n        x_HL: The x-coordinate of the high-leverage point.\n        delta_LL: The y-offset for the low-leverage, large-residual point.\n        epsilon_HL: The y-offset for the high-leverage point.\n\n    Returns:\n        A list containing [i_r, i_t, b1, b2]:\n        i_r: Index of the max absolute standardized residual.\n        i_t: Index of the max absolute studentized residual.\n        b1: Boolean, |t_i| > |r_i| for the low-leverage point.\n        b2: Boolean, |r_i| >= |t_i| for the high-leverage point.\n    \"\"\"\n    # True model parameters\n    beta0_true = 2.0\n    beta1_true = 1.5\n\n    # 1. Construct the dataset\n    # Base points on the true line\n    x_base = np.linspace(-x_max, x_max, n_base)\n    y_base = beta0_true + beta1_true * x_base\n    \n    # High-leverage point\n    x_hl = float(x_HL)\n    y_hl = (beta0_true + beta1_true * x_hl) + epsilon_HL\n    \n    # Low-leverage, large-residual point\n    x_ll = 0.0\n    y_ll = (beta0_true + beta1_true * x_ll) + delta_LL\n    \n    # Combine into the full dataset\n    x = np.concatenate((x_base, [x_hl, x_ll]))\n    y = np.concatenate((y_base, [y_hl, y_ll]))\n    \n    n = len(x)\n    p = 2  # Number of parameters (intercept beta0, slope beta1)\n    \n    # Indices of the special points\n    idx_hl = n_base\n    idx_ll = n_base + 1\n    \n    # 2. Fit OLS model from first principles\n    # Construct the design matrix X\n    X = np.c_[np.ones(n), x]\n    \n    # OLS estimator: beta_hat = (X'X)^-1 X'y\n    XTX_inv = np.linalg.inv(X.T @ X)\n    beta_hat = XTX_inv @ X.T @ y\n    \n    # Predicted values and residuals\n    y_hat = X @ beta_hat\n    e = y - y_hat\n    \n    # 3. Compute leverage values (h_ii)\n    # Hat matrix: H = X(X'X)^-1 X'\n    H = X @ XTX_inv @ X.T\n    h = np.diag(H)\n    \n    # 4. Compute standardized and studentized residuals\n    \n    # Unbiased estimator for error variance sigma^2\n    rss = e.T @ e\n    sigma2_hat = rss / (n - p)\n    sigma_hat = np.sqrt(sigma2_hat)\n    \n    # Standardized residuals: r_i = e_i / (sigma_hat * sqrt(1 - h_ii))\n    # Handle potential division by zero if h_ii is close to 1\n    sqrt_1_minus_h = np.sqrt(1 - h)\n    r = np.zeros_like(e)\n    valid_indices_r = (1 - h) > 1e-12\n    r[valid_indices_r] = e[valid_indices_r] / (sigma_hat * sqrt_1_minus_h[valid_indices_r])\n    \n    # Studentized residuals: t_i = r_i * sqrt((n - p - 1) / (n - p - r_i^2))\n    df_full = n - p\n    df_del = n - p - 1\n    \n    denom_t_sq = df_full - r**2\n    t = np.zeros_like(r)\n    \n    # Handle r_i^2  n-p for valid square root\n    valid_indices_t = denom_t_sq > 1e-12\n    t[valid_indices_t] = r[valid_indices_t] * np.sqrt(df_del / denom_t_sq[valid_indices_t])\n    \n    # If r_i^2 -> n-p, t -> inf\n    infinite_indices = np.abs(denom_t_sq) = 1e-12\n    t[infinite_indices] = np.inf * np.sign(r[infinite_indices])\n    \n    # 5. Determine the required outputs\n    i_r = int(np.argmax(np.abs(r)))\n    i_t = int(np.argmax(np.abs(t)))\n\n    b1 = bool(np.abs(t[idx_ll]) > np.abs(r[idx_ll]))\n    b2 = bool(np.abs(r[idx_hl]) >= np.abs(t[idx_hl]))\n    \n    return [i_r, i_t, b1, b2]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n_base, x_max, x_HL, delta_LL, epsilon_HL)\n        (12, 3, 15, 15, 0),\n        (10, 2, 50, 10, 0),\n        (12, 3, 8, 6, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack tuple into named arguments for clarity\n        n_base, x_max, x_HL, delta_LL, epsilon_HL = case\n        result = calculate_residuals(n_base, x_max, x_HL, delta_LL, epsilon_HL)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The str() conversion of a list includes spaces, which is standard.\n    # The problem example is symbolic; this literal interpretation of the template is safest.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当一个模型完美地拟合了所有数据时，我们的诊断工具会发生什么？这个思想实验探讨了一个饱和模型的理论极限，这是一个典型的过拟合案例，其中模型参数的数量等于甚至超过数据点的数量。通过研究这个极端情况，你将理解为何标准的残差诊断方法会失效，以及这种失效对于模型的有效性和泛化能力发出了怎样的信号 。",
            "id": "3176882",
            "problem": "考虑普通最小二乘 (OLS) 线性回归，其设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，响应向量为 $y \\in \\mathbb{R}^n$。拟合值是 $y$ 在 $X$ 的列空间上的正交投影，由对称幂等投影矩阵 $H$ 实现，因此 $\\hat{y} = H y$，残差向量为 $e = y - \\hat{y} = (I_n - H) y$，其中 $I_n$ 是 $n \\times n$ 的单位矩阵。观测值 $i$ 的杠杆值是 $H$ 的第 $i$ 个对角元素 $h_{ii}$。观测值 $i$ 的标准化残差由 $r_i = e_i / \\big( s \\sqrt{1 - h_{ii}} \\big)$ 给出，其中 $s$ 是基于残差的噪声尺度的常规无偏估计量。外学生化残差由 $\\tilde{r}_i = e_i / \\big( s_{(i)} \\sqrt{1 - h_{ii}} \\big)$ 给出，其中 $s_{(i)}$ 是在移除观测值 $i$ 后重新拟合模型计算出的无偏噪声估计。\n\n假设模型对训练数据达到了完美拟合，即 $X$ 的列空间等于 $\\mathbb{R}^n$。从正交投影算子的性质和上述定义出发，判断下列哪些陈述是正确的。\n\nA. 在完美拟合条件下，当 $\\operatorname{col}(X) = \\mathbb{R}^n$ 时，帽子矩阵满足 $H = I_n$ 且残差向量为 $e = 0$。\n\nB. 在完美拟合条件下，杠杆值对所有 $i$ 都满足 $h_{ii} = 0$，这意味着所有标准化残差都为 $0$。\n\nC. 在完美拟合条件下，标准化残差 $r_i$ 和外学生化残差 $\\tilde{r}_i$ 未定义，因为 $\\sqrt{1 - h_{ii}} = 0$ 并且在饱和拟合中尺度因子 $s$ 和 $s_{(i)}$ 没有被良好定义。\n\nD. 完美拟合意味着零训练误差，但会损害异常值检测和泛化能力；基于残差的诊断方法失效，这标志着过拟合。\n\nE. 即使在完美拟合条件下，外学生化残差 $\\tilde{r}_i$ 仍然是良好定义的，并服从自由度为 $n - p - 1$ 的 $t$ 分布。",
            "solution": "在继续之前，对问题陈述进行验证。\n\n核心前提是，对于一个具有设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 的普通最小二乘 (OLS) 模型，该模型达到了“完美拟合”，这被严格定义为 $X$ 的列空间张成了整个环境空间，即 $\\operatorname{col}(X) = \\mathbb{R}^n$。问题中使用了帽子矩阵 $H$、残差向量 $e$、杠杆值 $h_{ii}$、标准化残差 $r_i$ 和外学生化残差 $\\tilde{r}_i$ 的标准定义。\n\n条件 $\\operatorname{col}(X) = \\mathbb{R}^n$ 意味着矩阵 $X$ 的秩等于空间的维度，即 $n$。所以，$\\operatorname{rank}(X) = n$。由于矩阵的秩不能超过其行数或列数，我们有 $\\operatorname{rank}(X) \\le \\min(n, p)$。为了使 $\\operatorname{rank}(X) = n$，必须有 $p \\ge n$。这种情况对应于一个“饱和”模型，其中预测变量的数量至少与观测值的数量一样多。这是回归分析中一个有效但极端的理论案例，常用于研究过拟合的性质。该问题具有科学依据，提法恰当且客观。因此，问题陈述是有效的。\n\n我们现在基于给定的前提进行推导。\n\n首先，我们分析帽子矩阵 $H$ 的性质。帽子矩阵 $H$ 被定义为到 $X$ 的列空间 $\\operatorname{col}(X)$ 上的正交投影矩阵。在条件 $\\operatorname{col}(X) = \\mathbb{R}^n$ 下，$H$ 是到 $\\mathbb{R}^n$ 上的投影矩阵。唯一能将 $\\mathbb{R}^n$ 中的每个向量映射到整个 $\\mathbb{R}^n$ 的投影矩阵是单位矩阵 $I_n$。\n$$ H = I_n $$\n\n接下来，我们确定拟合值 $\\hat{y}$ 和残差向量 $e$。\n拟合值由 $\\hat{y} = H y$ 给出。代入 $H = I_n$：\n$$ \\hat{y} = I_n y = y $$\n这证实了“完美拟合”的含义：模型的预测与观测数据完全匹配。\n残差向量为 $e = y - \\hat{y}$。代入 $\\hat{y} = y$：\n$$ e = y - y = 0 $$\n残差向量是零向量，意味着对于 $i = 1, \\dots, n$，每个单独的残差 $e_i = 0$。\n\n现在，我们评估杠杆值 $h_{ii}$。观测值 $i$ 的杠杆值是帽子矩阵 $H$ 的第 $i$ 个对角元素。由于 $H = I_n$，其对角元素全为 $1$。\n$$ h_{ii} = 1 \\quad \\text{for all } i \\in \\{1, \\dots, n\\} $$\n\n我们现在可以分析标准化残差和学生化残差。\n观测值 $i$ 的标准化残差定义为 $r_i = e_i / \\big( s \\sqrt{1 - h_{ii}} \\big)$。\n我们发现分子是 $e_i = 0$。对于分母，我们有 $\\sqrt{1 - h_{ii}} = \\sqrt{1 - 1} = 0$。因此，$r_i$ 的表达式呈现为不定形式 $0/0$。\n此外，我们来考察尺度估计量 $s$。误差方差的常规无偏估计量是 $s^2 = \\text{RSS} / (n-p)$，其中 $\\text{RSS} = \\sum_{i=1}^n e_i^2$ 是残差平方和。由于 $e=0$，我们有 $\\text{RSS} = 0$。误差的自由度是 $n-p$。如前所述，条件 $\\operatorname{col}(X) = \\mathbb{R}^n$ 要求 $p \\ge n$，这意味着自由度 $n-p \\le 0$。一个有效的方差估计需要正的自由度。所以，$s^2 = 0 / (\\text{非正值})$，这是未定义的。\n因此，标准化残差 $r_i$ 未定义有两个原因：分母中包含一个零因子（$\\sqrt{1-h_{ii}}$），并且尺度估计 $s$ 本身没有被良好定义。\n\n外学生化残差是 $\\tilde{r}_i = e_i / \\big( s_{(i)} \\sqrt{1 - h_{ii}} \\big)$。\n这个表达式的分子也是 $e_i = 0$，分母中也有一个因子 $\\sqrt{1-h_{ii}} = 0$，所以它也是不定形式 $0/0$。留一法尺度估计 $s_{(i)}$ 是通过在 $n-1$ 个观测值和 $p$ 个预测变量上拟合模型来计算的。这个新模型的自由度将是 $(n-1) - p$。由于 $p \\ge n$，这些自由度为负数或零。在缩减数据集上的模型也会产生完美拟合（假设 $X$ 的列处于一般位置），导致残差平方和为零。因此，$s_{(i)}^2$ 也是未定义的。\n\n有了这些结果，我们可以评估每个陈述。\n\n**A. 在完美拟合条件下，当 $\\operatorname{col}(X) = \\mathbb{R}^n$ 时，帽子矩阵满足 $H = I_n$ 且残差向量为 $e = 0$。**\n我们的推导表明，如果 $\\operatorname{col}(X)=\\mathbb{R}^n$，投影矩阵 $H$ 必须是 $I_n$。因此，残差向量 $e = (I_n-H)y = (I_n-I_n)y = 0$。这个陈述是该前提直接且正确的数学推论。\n**结论：正确。**\n\n**B. 在完美拟合条件下，杠杆值对所有 $i$ 都满足 $h_{ii} = 0$，这意味着所有标准化残差都为 $0$。**\n我们的推导表明，在完美拟合下，$H=I_n$，这意味着对所有 $i$ 杠杆值为 $h_{ii}=1$。声称 $h_{ii}=0$ 是错误的。因此，该陈述不正确。\n**结论：不正确。**\n\n**C. 在完美拟合条件下，标准化残差 $r_i$ 和外学生化残差 $\\tilde{r}_i$ 未定义，因为 $\\sqrt{1 - h_{ii}} = 0$ 并且在饱和拟合中尺度因子 $s$ 和 $s_{(i)}$ 没有被良好定义。**\n我们的推导表明，对所有 $i$，$h_{ii}=1$，这使得项 $\\sqrt{1-h_{ii}}$ 等于 $0$。仅此一点就使得 $r_i$ 和 $\\tilde{r}_i$ 的分母为零。此外，我们还表明误差的自由度是非正的（$n-p \\le 0$），使得尺度估计量 $s$ 和 $s_{(i)}$ 未定义。该陈述为这些基于残差的诊断方法在这种情况下为何未定义提供了完整且正确的解释。\n**结论：正确。**\n\n**D. 完美拟合意味着零训练误差，但会损害异常值检测和泛化能力；基于残差的诊断方法失效，这标志着过拟合。**\n该陈述提供了对数学结果的统计解释。\n- “完美拟合意味着零训练误差”：正确，因为我们证明了 $e=0$。\n- “损害异常值检测”：正确。基于残差的异常值检测方法完全无效，因为所有残差都精确为零。所有点也都具有最大杠杆值 $h_{ii}=1$，因此杠杆图在区分点方面也无信息。\n- “损害...泛化能力”：正确。一个 $p \\ge n$ 且完美拟合训练数据的模型是过拟合的典型例子。这样的模型捕捉了训练数据中的噪声，并预期在未见过的数据上表现不佳。这是统计学习中的一个基本概念。\n- “基于残差的诊断方法失效”：正确。如选项 C 的分析所示，像 $r_i$ 和 $\\tilde{r}_i$ 这样的量变得未定义。\n- “标志着过拟合”：正确。这种诊断方法的失效是饱和、过拟合模型的一个关键标志。\n整个陈述是对给定情况后果的合理且正确的描述。\n**结论：正确。**\n\n**E. 即使在完美拟合条件下，外学生化残差 $\\tilde{r}_i$ 仍然是良好定义的，并服从自由度为 $n - p - 1$ 的 $t$ 分布。**\n这个陈述是错误的。如选项 C 的分析所示，外学生化残差 $\\tilde{r}_i$ 是未定义的。t 分布的结果要求标准的回归假设，包括 $n  p$，而这里违反了这一条。此外，t 分布的自由度参数必须为正，但在这里 $n-p-1$ 会是负数，这是无效的。\n**结论：不正确。**",
            "answer": "$$\\boxed{ACD}$$"
        }
    ]
}