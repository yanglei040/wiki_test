{
    "hands_on_practices": [
        {
            "introduction": "在构建了包含定性预测变量的线性模型后，一个核心任务是解释这些变量的实际影响。本练习将指导你进行一种反事实分析：量化当一个观测点的类别发生改变时，其预测结果会发生怎样的变化。通过这种方式，你可以更深刻地理解哑变量系数（包括其与定量特征的交互项）在预测中的具体作用和实际意义 。",
            "id": "3164642",
            "problem": "给定一个线性回归模型，其定性预测变量使用参考单元（也称为带截距的独热编码）虚拟变量进行编码。令预测结果表示为 $\\hat{y}(\\mathbf{x}, \\mathbf{z})$，其中 $\\mathbf{x} \\in \\mathbb{R}^p$ 是定量特征的向量，$\\mathbf{z}$ 是分类水平的向量，每个分类变量对应一个水平。对于每个具有水平集 $\\mathcal{L}_c$ 的分类变量 $c$，指定的基线水平 $\\text{baseline}_c \\in \\mathcal{L}_c$ 不被显式编码；只有 $\\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}$ 中水平的指示变量会进入模型。可选地，模型中可能包含分类水平和定量特征之间的交互作用。\n\n形式上，该模型的形式为\n$$\n\\hat{y}(\\mathbf{x}, \\mathbf{z}) \\;=\\; \\beta_0 \\;+\\; \\sum_{j=1}^{p} \\beta_j x_j \\;+\\; \\sum_{c \\in \\mathcal{C}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\gamma_{c,l}\\,\\mathbf{1}\\{z_c = l\\}\n\\;+\\; \\sum_{(c,j)\\in \\mathcal{I}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\delta_{c,l,j}\\,\\mathbf{1}\\{z_c = l\\}\\,x_j,\n$$\n其中 $\\beta_0 \\in \\mathbb{R}$ 是截距，$\\beta_j \\in \\mathbb{R}$ 是定量特征的系数，$\\gamma_{c,l} \\in \\mathbb{R}$ 是分类变量 $c$ 在水平 $l$ 上的主效应虚拟系数，$\\delta_{c,l,j} \\in \\mathbb{R}$ 是分类变量 $c$ 的水平 $l$ 与定量特征 $x_j$ 之间的交互作用系数。集合 $\\mathcal{I}$ 列出了模型中存在的分类-定量交互作用对。\n\n对于给定的观测 $(\\mathbf{x}, \\mathbf{z})$，考虑一个反事实情况，其中单个分类变量 $c^\\star$ 的水平从 $a$ 变为 $b$，产生 $\\mathbf{z}_{c^\\star \\leftarrow b}$。将原始类别转换效应定义为\n$$\n\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})\n\\;=\\;\n\\hat{y}(\\mathbf{x}, \\mathbf{z}_{c^\\star \\leftarrow b})\n-\n\\hat{y}(\\mathbf{x}, \\mathbf{z}),\n$$\n给定一个正常数 $\\sigma > 0$，标准化效应大小定义为\n$$\nE^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) = \\frac{\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})}{\\sigma}.\n$$\n\n您的任务是编写一个程序，针对以下每个测试用例，根据测试用例中提供的模型设定计算 $E^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})$。所有测试用例都使用带截距的参考单元编码；每个分类变量的基线水平都已明确指定。如果一个分类水平等于其基线水平，其主效应贡献为 $0$；同样，对于交互作用，缺失或基线水平的贡献为 $0$。\n\n测试套件：\n\n- 测试用例 1：\n  - 定量特征：一个名为 $x$ 的特征，系数 $\\beta_x = 1.5$，截距 $\\beta_0 = 2.0$。\n  - 分类变量：一个名为 color 的变量，水平为 $\\{\\text{red}, \\text{blue}, \\text{green}\\}$，基线水平为 red。主效应系数：$\\gamma_{\\text{color},\\text{blue}} = 0.8$，$\\gamma_{\\text{color},\\text{green}} = -0.5$。无交互作用。\n  - 观测：$x = 3.0$，color = red。将 color 切换到 blue。使用 $\\sigma = 0.4$。\n\n- 测试用例 2：\n  - 定量特征：一个名为 $x$ 的特征，系数 $\\beta_x = -1.0$，截距 $\\beta_0 = 0.0$。\n  - 分类变量：一个名为 color 的变量，水平为 $\\{\\text{red}, \\text{blue}, \\text{green}\\}$，基线水平为 red。主效应系数：$\\gamma_{\\text{color},\\text{blue}} = 1.2$，$\\gamma_{\\text{color},\\text{green}} = -0.3$。无交互作用。\n  - 观测：$x = -5.0$，color = green。将 color 切换到 green。使用 $\\sigma = 1.0$。\n\n- 测试用例 3：\n  - 定量特征：一个名为 $p$ 的特征，系数 $\\beta_p = -2.0$，截距 $\\beta_0 = 0.0$。\n  - 分类变量：\n    - brand，水平为 $\\{\\text{A}, \\text{B}\\}$，基线为 A；$\\gamma_{\\text{brand},\\text{B}} = 1.2$。\n    - season，水平为 $\\{\\text{winter}, \\text{spring}, \\text{summer}, \\text{autumn}\\}$，基线为 winter；$\\gamma_{\\text{season},\\text{spring}} = 0.5$，$\\gamma_{\\text{season},\\text{summer}} = 1.0$，$\\gamma_{\\text{season},\\text{autumn}} = 0.2$。\n    - 无交互作用。\n  - 观测：$p = 0.75$，brand = B，season = autumn。将 season 切换到 summer。使用 $\\sigma = 0.5$。\n\n- 测试用例 4：\n  - 定量特征：一个名为 $n\\_users$ 的特征，系数 $\\beta_{n\\_users} = 0.2$，截距 $\\beta_0 = 0.0$。\n  - 分类变量：一个名为 tier 的变量，水平为 $\\{\\text{basic}, \\text{pro}, \\text{enterprise}\\}$，基线为 basic。主效应系数：$\\gamma_{\\text{tier},\\text{pro}} = 0.3$，$\\gamma_{\\text{tier},\\text{enterprise}} = 1.0$。\n  - 存在交互作用：tier 和 $n\\_users$ 之间，其中 $\\delta_{\\text{tier},\\text{pro},\\,n\\_users} = 0.1$，$\\delta_{\\text{tier},\\text{enterprise},\\,n\\_users} = 0.05$。\n  - 观测：$n\\_users = 10$，tier = pro。将 tier 切换到 enterprise。使用 $\\sigma = 0.2$。\n\n- 测试用例 5：\n  - 定量特征：两个特征 $x_1$ 和 $x_2$，系数分别为 $\\beta_{x_1} = 1.0$，$\\beta_{x_2} = -0.5$，截距 $\\beta_0 = 5.0$。\n  - 分类变量：\n    - brand，水平为 $\\{\\text{A}, \\text{B}\\}$，基线为 A；$\\gamma_{\\text{brand},\\text{B}} = -0.7$。\n    - region，水平为 $\\{\\text{north}, \\text{south}, \\text{east}\\}$，基线为 north；$\\gamma_{\\text{region},\\text{south}} = 0.4$，$\\gamma_{\\text{region},\\text{east}} = -0.2$。\n    - 无交互作用。\n  - 观测：$x_1 = 4.0$, $x_2 = -2.0$，brand = B，region = south。将 brand 切换到 A。使用 $\\sigma = 0.7$。\n\n您的程序必须为每个测试用例计算标准化效应大小 $E^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})$，并生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，$[r_1,r_2,r_3,r_4,r_5]$）。不涉及物理单位。不涉及角度。不涉及百分比。输出项必须是实数（浮点数），按测试用例1到5的顺序排列。",
            "solution": "问题要求在线性回归模型中，为单个分类预测变量的反事实变化计算一个标准化的效应大小 $E^{\\mathrm{std}}$。该模型包含定量特征、定性（分类）特征及其交互作用。\n\n首先，我们必须将原始类别转换效应 $\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})$ 的计算形式化。模型由以下公式给出：\n$$\n\\hat{y}(\\mathbf{x}, \\mathbf{z}) \\;=\\; \\beta_0 \\;+\\; \\sum_{j=1}^{p} \\beta_j x_j \\;+\\; \\sum_{c \\in \\mathcal{C}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\gamma_{c,l}\\,\\mathbf{1}\\{z_c = l\\}\n\\;+\\; \\sum_{(c,j)\\in \\mathcal{I}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\delta_{c,l,j}\\,\\mathbf{1}\\{z_c = l\\}\\,x_j\n$$\n该效应定义为预测结果的差异：\n$$\n\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) \\;=\\; \\hat{y}(\\mathbf{x}, \\mathbf{z}_{c^\\star \\leftarrow b}) - \\hat{y}(\\mathbf{x}, \\mathbf{z})\n$$\n其中 $\\mathbf{z}_{c^\\star \\leftarrow b}$ 是与 $\\mathbf{z}$ 相同的特征向量，只是分类变量 $c^\\star$ 的水平从 $a$ 变为 $b$。\n\n当我们计算这个差值时，$\\hat{y}$ 的模型表达式中所有不依赖于 $c^\\star$ 水平的项都将相互抵消。这包括截距 $\\beta_0$、所有定量预测变量的主效应 $\\sum_{j=1}^{p} \\beta_j x_j$，以及所有其他 $c \\neq c^\\star$ 的分类变量 $c \\in \\mathcal{C}$ 的主效应和交互效应。\n\n唯一不抵消的部分是与 $c^\\star$ 相关的部分。让我们为给定的定量特征向量 $\\mathbf{x}$，定义分类变量 $c$ 的水平 $l$ 对预测的总贡献。我们将此贡献表示为 $f(c, l, \\mathbf{x})$。根据模型定义，此贡献为：\n$$\nf(c, l, \\mathbf{x}) = \\left( \\sum_{l' \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\gamma_{c,l'}\\,\\mathbf{1}\\{l = l'\\} \\right) + \\left( \\sum_{(c,j)\\in \\mathcal{I}} \\sum_{l' \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\delta_{c,l',j}\\,\\mathbf{1}\\{l = l'\\}\\,x_j \\right)\n$$\n这个表达式可以简化。如果水平 $l$ 是基线水平 $\\text{baseline}_c$，那么所有指示函数 $\\mathbf{1}\\{l=l'\\}$ 都为零，因此 $f(c, \\text{baseline}_c, \\mathbf{x}) = 0$。如果 $l$ 不是基线水平，则表达式简化为：\n$$\nf(c, l, \\mathbf{x}) = \\gamma_{c,l} + \\sum_{j \\text{ s.t. } (c,j) \\in \\mathcal{I}} \\delta_{c,l,j}\\,x_j \\quad \\text{for } l \\neq \\text{baseline}_c\n$$\n我们可以通过采用基线水平的系数为零的约定来统一这些情况：对于所有的 $c, j$，$\\gamma_{c,\\text{baseline}_c} = 0$ 和 $\\delta_{c,\\text{baseline}_c,j} = 0$。\n\n原始效应 $\\Delta_{c^\\star:a \\to b}$ 是新水平 $b$ 的贡献与原始水平 $a$ 的贡献之差：\n$$\n\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) = f(c^\\star, b, \\mathbf{x}) - f(c^\\star, a, \\mathbf{x})\n$$\n$$\n\\Delta_{c^\\star:a \\to b} = \\left( \\gamma_{c^\\star,b} + \\sum_{j \\text{ s.t. } (c^\\star,j) \\in \\mathcal{I}} \\delta_{c^\\star,b,j}\\,x_j \\right) - \\left( \\gamma_{c^\\star,a} + \\sum_{j \\text{ s.t. } (c^\\star,j) \\in \\mathcal{I}} \\delta_{c^\\star,a,j}\\,x_j \\right)\n$$\n最后，通过除以 $\\sigma$ 得到标准化的效应大小：\n$$\nE^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) = \\frac{\\Delta_{c^\\star:a \\to b}}{\\sigma}\n$$\n我们现在将此框架应用于每个测试用例。\n\n测试用例 1：\n- 将 $c^\\star=\\text{color}$ 从 $a=\\text{red}$ 切换到 $b=\\text{blue}$。\n- 水平 $\\text{red}$ 是基线，所以 $\\gamma_{\\text{color,red}}=0$。$\\text{blue}$ 的系数是 $\\gamma_{\\text{color,blue}} = 0.8$。\n- 没有交互作用，所以所有 $\\delta$ 系数都为 $0$。\n- $\\Delta_{\\text{color}:\\text{red} \\to \\text{blue}} = (\\gamma_{\\text{color,blue}}) - (\\gamma_{\\text{color,red}}) = 0.8 - 0 = 0.8$。\n- 给定 $\\sigma = 0.4$，标准化效应为 $E^{\\mathrm{std}} = 0.8 / 0.4 = 2.0$。\n\n测试用例 2：\n- 将 $c^\\star=\\text{color}$ 从 $a=\\text{green}$ 切换到 $b=\\text{green}$。\n- 由于起始水平与结束水平相同，预测的变化必然为零。\n- $\\Delta_{\\text{color}:\\text{green} \\to \\text{green}} = \\hat{y}(\\dots, \\text{color}=\\text{green}) - \\hat{y}(\\dots, \\text{color}=\\text{green}) = 0$。\n- 使用 $\\sigma = 1.0$，标准化效应为 $E^{\\mathrm{std}} = 0 / 1.0 = 0.0$。\n\n测试用例 3：\n- 将 $c^\\star=\\text{season}$ 从 $a=\\text{autumn}$ 切换到 $b=\\text{summer}$。\n- 变量 `brand` 没有变化，所以它的贡献会抵消。没有交互作用。\n- `season` 的基线是 `winter`。`autumn` 和 `summer` 都不是基线。\n- 系数是 $\\gamma_{\\text{season,autumn}} = 0.2$ 和 $\\gamma_{\\text{season,summer}} = 1.0$。\n- $\\Delta_{\\text{season}:\\text{autumn} \\to \\text{summer}} = \\gamma_{\\text{season,summer}} - \\gamma_{\\text{season,autumn}} = 1.0 - 0.2 = 0.8$。\n- 使用 $\\sigma = 0.5$，标准化效应为 $E^{\\mathrm{std}} = 0.8 / 0.5 = 1.6$。\n\n测试用例 4：\n- 将 $c^\\star=\\text{tier}$ 从 $a=\\text{pro}$ 切换到 $b=\\text{enterprise}$。\n- 该案例包含 `tier` 和 $n\\_users$ 之间的交互作用。\n- 观测值为 $n\\_users = 10$。`tier` 的基线是 `basic`。\n- 变化涉及两个非基线水平，`pro` 和 `enterprise`。\n- $\\Delta_{\\text{tier}:\\text{pro} \\to \\text{enterprise}} = f(\\text{tier}, \\text{enterprise}, \\{n\\_users: 10\\}) - f(\\text{tier}, \\text{pro}, \\{n\\_users: 10\\})$。\n- $f(\\text{tier}, \\text{enterprise}, \\{n\\_users: 10\\}) = \\gamma_{\\text{tier,enterprise}} + \\delta_{\\text{tier,enterprise},n\\_users} \\times n\\_users = 1.0 + 0.05 \\times 10 = 1.5$。\n- $f(\\text{tier}, \\text{pro}, \\{n\\_users: 10\\}) = \\gamma_{\\text{tier,pro}} + \\delta_{\\text{tier,pro},n\\_users} \\times n\\_users = 0.3 + 0.1 \\times 10 = 1.3$。\n- $\\Delta = 1.5 - 1.3 = 0.2$。\n- 使用 $\\sigma = 0.2$，标准化效应为 $E^{\\mathrm{std}} = 0.2 / 0.2 = 1.0$。\n\n测试用例 5：\n- 将 $c^\\star=\\text{brand}$ 从 $a=\\text{B}$ 切换到 $b=\\text{A}$。\n- 水平 `A` 是 `brand` 的基线，所以其有效系数为 $0$。水平 `B` 的系数为 $\\gamma_{\\text{brand,B}} = -0.7$。\n- 没有交互作用。其他变量（`region`，$x_1$，$x_2$）的状态是无关紧要的，因为它们的贡献会相互抵消。\n- $\\Delta_{\\text{brand}:\\text{B} \\to \\text{A}} = \\gamma_{\\text{brand,A}} - \\gamma_{\\text{brand,B}} = 0 - (-0.7) = 0.7$。\n- 使用 $\\sigma = 0.7$，标准化效应为 $E^{\\mathrm{std}} = 0.7 / 0.7 = 1.0$。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the standardized effect size for a counterfactual category switch\n    in a linear regression model for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1\n        {\n            \"c_star\": \"color\",\n            \"from_level\": \"red\",\n            \"to_level\": \"blue\",\n            \"x_vals\": {\"x\": 3.0},\n            \"coeffs\": {\n                \"gamma\": {\"color\": {\"blue\": 0.8, \"green\": -0.5}}\n            },\n            \"baselines\": {\"color\": \"red\"},\n            \"sigma\": 0.4\n        },\n        # Test case 2\n        {\n            \"c_star\": \"color\",\n            \"from_level\": \"green\",\n            \"to_level\": \"green\",\n            \"x_vals\": {\"x\": -5.0},\n            \"coeffs\": {\n                \"gamma\": {\"color\": {\"blue\": 1.2, \"green\": -0.3}}\n            },\n            \"baselines\": {\"color\": \"red\"},\n            \"sigma\": 1.0\n        },\n        # Test case 3\n        {\n            \"c_star\": \"season\",\n            \"from_level\": \"autumn\",\n            \"to_level\": \"summer\",\n            \"x_vals\": {\"p\": 0.75},\n            \"coeffs\": {\n                \"gamma\": {\n                    \"brand\": {\"B\": 1.2},\n                    \"season\": {\"spring\": 0.5, \"summer\": 1.0, \"autumn\": 0.2}\n                }\n            },\n            \"baselines\": {\"brand\": \"A\", \"season\": \"winter\"},\n            \"sigma\": 0.5\n        },\n        # Test case 4\n        {\n            \"c_star\": \"tier\",\n            \"from_level\": \"pro\",\n            \"to_level\": \"enterprise\",\n            \"x_vals\": {\"n_users\": 10},\n            \"coeffs\": {\n                \"gamma\": {\"tier\": {\"pro\": 0.3, \"enterprise\": 1.0}},\n                \"delta\": {\n                    \"tier\": {\n                        \"pro\": {\"n_users\": 0.1},\n                        \"enterprise\": {\"n_users\": 0.05}\n                    }\n                }\n            },\n            \"baselines\": {\"tier\": \"basic\"},\n            \"sigma\": 0.2\n        },\n        # Test case 5\n        {\n            \"c_star\": \"brand\",\n            \"from_level\": \"B\",\n            \"to_level\": \"A\",\n            \"x_vals\": {\"x1\": 4.0, \"x2\": -2.0},\n            \"coeffs\": {\n                \"gamma\": {\n                    \"brand\": {\"B\": -0.7},\n                    \"region\": {\"south\": 0.4, \"east\": -0.2}\n                }\n            },\n            \"baselines\": {\"brand\": \"A\", \"region\": \"north\"},\n            \"sigma\": 0.7\n        }\n    ]\n\n    def get_level_contribution(c_var, level, x_vals, coeffs, baselines):\n        \"\"\"\n        Calculates the total contribution of a specific categorical level to the\n        prediction, including main and interaction effects.\n        \"\"\"\n        if level == baselines[c_var]:\n            return 0.0\n\n        # Main effect (gamma coefficient)\n        gamma = coeffs.get(\"gamma\", {}).get(c_var, {}).get(level, 0.0)\n\n        # Sum of interaction effects (delta coefficients)\n        delta_sum = 0.0\n        # Check if interactions are defined for the variable and level\n        delta_coeffs_for_level = coeffs.get(\"delta\", {}).get(c_var, {}).get(level)\n        if delta_coeffs_for_level:\n            for x_var, x_val in x_vals.items():\n                if x_var in delta_coeffs_for_level:\n                    delta_sum += delta_coeffs_for_level[x_var] * x_val\n        \n        return gamma + delta_sum\n\n    results = []\n    for case in test_cases:\n        c_star = case[\"c_star\"]\n        from_level = case[\"from_level\"]\n        to_level = case[\"to_level\"]\n        x_vals = case[\"x_vals\"]\n        coeffs = case[\"coeffs\"]\n        baselines = case[\"baselines\"]\n        sigma = case[\"sigma\"]\n\n        # Calculate contribution from the original level\n        contrib_from = get_level_contribution(\n            c_star, from_level, x_vals, coeffs, baselines\n        )\n        \n        # Calculate contribution from the new (counterfactual) level\n        contrib_to = get_level_contribution(\n            c_star, to_level, x_vals, coeffs, baselines\n        )\n\n        # Raw effect is the difference in contributions\n        raw_effect = contrib_to - contrib_from\n        \n        # Standardized effect\n        std_effect = raw_effect / sigma\n        results.append(std_effect)\n\n    # Format the output as specified\n    formatted_results = [f\"{r:.16g}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "经典线性模型的一个关键假设是误差的方差恒定（同方差性）。然而，在处理包含不同组别的定性数据时，我们常常会发现各组内部的响应变量波动程度并不相同，即存在异方差性。本练习将带你亲手实践如何诊断这一问题，并应用加权最小二乘法（WLS）进行修正，从而构建出更稳健、更精确的回归模型 。",
            "id": "3164625",
            "problem": "给你一个统计学习任务，该任务涉及一个线性模型，其中包含一个定量预测变量和一个通过虚拟变量编码的多水平定性预测变量。目标是诊断不同类别水平间的异方差性并对其进行建模，以及使用加权最小二乘法（WLS）引入特定于水平的权重。请在以下基础框架内进行操作：经典线性模型假设响应 $y$ 通过设计矩阵 $X$ 与预测变量呈线性关系，并带有可加性误差 $\\varepsilon$，使得 $\\mathbb{E}[\\varepsilon] = 0$，误差不相关，且各组间的方差可能不恒定。一个具有多个水平的定性预测变量通过相对于一个选定的参考水平的虚拟变量来表示。对于每个测试用例，假设定性预测变量具有水平 $A$、$B$ 和 $C$，并且参考水平为 $A$。\n\n你的程序必须：\n- 构建设计矩阵 $X$，其中包含截距项、定量预测变量 $x$ 以及非参考水平 $B$ 和 $C$ 的虚拟变量。\n- 仅使用给定的数据和设计矩阵计算普通最小二乘（OLS）估计值。\n- 计算残差 $r = y - X\\hat{\\beta}_{\\text{OLS}}$，并对于每个水平 $g \\in \\{A,B,C\\}$，将该水平内残差的平方均值作为该水平特定的方差估计值 $\\hat{\\sigma}^2_g$。\n- 通过计算比率 $R = \\max_g \\hat{\\sigma}^2_g \\,/\\, \\min_g \\hat{\\sigma}^2_g$ 并将其与阈值 $\\tau$ 比较来诊断异方差性。如果 $R > \\tau$，则判断存在异方差性。\n- 如果存在异方差性，则使用对角权重 $w_i = 1 / \\hat{\\sigma}^2_{g(i)}$ 执行加权最小二乘法（WLS），其中 $g(i)$ 表示观测值 $i$ 的水平。如果不存在，则对所有 $i$ 设置 $w_i = 1$。计算 WLS 估计值。\n- 从 OLS 和 WLS 的结果中提取以下系数：$x$ 的斜率，以及水平 $B$ 和 $C$（相对于 $A$）的虚拟变量系数。\n\n对于数值输出，将所有浮点数结果四舍五入到 $6$ 位小数。此问题中不涉及物理单位和角度。不使用百分比。\n\n测试套件：\n使用以下测试用例（每个测试用例是一个元组 $(x, y, \\text{groups})$）和共同的阈值 $\\tau = 1.5$。在所有情况下，groups 是一个与 $x$ 和 $y$ 长度相同的列表，仅包含字符串 \"A\"、\"B\" 或 \"C\"。设计矩阵必须使用 \"A\" 作为参考水平。\n\n- 测试用例 1（各水平间存在异方差性）：\n    - $x = [1, 2, 3, 4, 1.5, 2.5, 3.5, 4.5, 0.5, 1.5, 2.5, 3.5]$\n    - $y = [3.7, 4.9, 6.6, 7.8, 5.75, 2.95, 7.95, 5.55, 4.25, 3.95, 7.0, 6.65]$\n    - groups = [\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\"]\n\n- 测试用例 2（各水平间近似同方差）：\n    - $x = [1, 2, 3, 4, 1.5, 2.5, 3.5, 4.5, 0.5, 1.5, 2.5, 3.5]$\n    - $y = [3.8, 4.6, 6.7, 7.9, 3.45, 4.45, 6.35, 7.55, 3.5, 4.55, 6.4, 7.65]$\n    - groups = [\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\"]\n\n- 测试用例 3（组大小不平衡，强异方差性）：\n    - $x = [1, 2, 3, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 1, 3, 5]$\n    - $y = [1.6, 1.8, 2.8, 3.3, 3.7, 4.29, 4.71, 5.28, 5.72, 2.5, -1.0, 4.0]$\n    - groups = [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"]\n\n要求的最终输出格式：\n你的程序应生成一行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个测试用例贡献一个形式如下的列表：\n$[\\text{hetero}, \\text{OLS\\_slope\\_x}, \\text{WLS\\_slope\\_x}, \\text{OLS\\_gamma\\_B}, \\text{WLS\\_gamma\\_B}, \\text{OLS\\_gamma\\_C}, \\text{WLS\\_gamma\\_C}]$。\n此处 $\\text{hetero}$ 是一个布尔值（True 或 False），其余条目是四舍五入到 $6$ 位小数的浮点数。对于这三个测试用例，程序必须打印一行，格式如下：\n$[[\\ldots],[\\ldots],[\\ldots]]$。",
            "solution": "此问题要求实现一个标准的统计工作流程，用于处理同时包含定量和定性预测变量的线性回归模型中的异方差性。解决方案按一系列明确的步骤进行，从模型设定和估计到诊断和校正。\n\n### 1. 模型设定与设计矩阵\n线性模型设定如下：\n$$\ny_i = \\beta_0 + \\beta_1 x_i + \\gamma_B D_{i,B} + \\gamma_C D_{i,C} + \\varepsilon_i\n$$\n此处，$y_i$ 和 $x_i$ 分别是响应和定量预测变量的第 $i$ 个观测值。$\\beta_0$ 是截距项，代表参考组（$A$）中当 $x=0$ 时 $y$ 的期望值。$\\beta_1$ 是定量预测变量 $x$ 的斜率系数。项 $D_{i,B}$ 和 $D_{i,C}$ 是定性预测变量水平的虚拟变量。\n- $D_{i,B} = 1$ 如果观测值 $i$ 属于 B 组，否则为 $0$。\n- $D_{i,C} = 1$ 如果观测值 $i$ 属于 C 组，否则为 $0$。\n对于参考组 A 中的观测值，$D_{i,B}$ 和 $D_{i,C}$ 均为 $0$。\n系数 $\\gamma_B$ 和 $\\gamma_C$ 代表相对于 A 组，观测值属于 B 组或 C 组对截距的差异效应。\n\n该模型可以表示为矩阵形式 $y = X\\beta + \\varepsilon$，其中 $y$ 是响应向量，$X$ 是设计矩阵，$\\beta$ 是系数向量，$\\varepsilon$ 是误差向量。对于 $N$ 个观测值，大小为 $N \\times 4$ 的设计矩阵 $X$ 构建如下：\n$$\nX = \\begin{bmatrix}\n1  x_1  D_{1,B}  D_{1,C} \\\\\n1  x_2  D_{2,B}  D_{2,C} \\\\\n\\vdots  \\vdots  \\vdots  \\vdots \\\\\n1  x_N  D_{N,B}  D_{N,C}\n\\end{bmatrix}\n\\quad \\text{and} \\quad\n\\beta = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\gamma_B \\\\ \\gamma_C \\end{bmatrix}\n$$\n\n### 2. 普通最小二乘（OLS）估计\n$\\beta$ 的 OLS 估计量，记为 $\\hat{\\beta}_{\\text{OLS}}$，是通过最小化残差平方和 $\\sum r_i^2 = (y-X\\beta)^T(y-X\\beta)$ 求得的。这会得到闭式解：\n$$\n\\hat{\\beta}_{\\text{OLS}} = (X^T X)^{-1} X^T y\n$$\n\n### 3. 异方差性诊断\n得到 $\\hat{\\beta}_{\\text{OLS}}$ 后，我们计算残差向量 $r = y - X\\hat{\\beta}_{\\text{OLS}}$。异方差性意味着误差的方差 $\\text{Var}(\\varepsilon_i) = \\sigma_i^2$ 在所有观测值上不是恒定的。在本问题中，我们检验方差在组 $\\{A, B, C\\}$ 之间是否恒定。我们将每个组 $g$ 的方差估计为该组内观测值残差的平方均值：\n$$\n\\hat{\\sigma}^2_g = \\frac{1}{n_g} \\sum_{i \\in \\text{group } g} r_i^2\n$$\n其中 $n_g$ 是组 $g$ 中的观测值数量。\n\n一个简单的诊断工具是最大估计组方差与最小估计组方差的比率：\n$$\nR = \\frac{\\max(\\hat{\\sigma}^2_A, \\hat{\\sigma}^2_B, \\hat{\\sigma}^2_C)}{\\min(\\hat{\\sigma}^2_A, \\hat{\\sigma}^2_B, \\hat{\\sigma}^2_C)}\n$$\n如果该比率 $R$ 超过预定义的阈值 $\\tau$，我们断定存在显著的异方差性。对于本问题，$\\tau = 1.5$。\n\n### 4. 加权最小二乘（WLS）估计\n如果检测到异方差性，OLS 估计量不再是最佳线性无偏估计量（BLUE），尽管它仍然是无偏的。WLS 通过给予方差较大的观测值较小的权重来提供一个更有效的估计量。WLS 估计量为：\n$$\n\\hat{\\beta}_{\\text{WLS}} = (X^T W X)^{-1} X^T W y\n$$\n其中 $W$ 是一个对角权重矩阵。最优权重与误差方差成反比，$w_i = 1/\\sigma_i^2$。由于真实方差未知，我们使用它们的估计值。对于属于组 $g(i)$ 的观测值 $i$，权重设置为 $w_i = 1/\\hat{\\sigma}^2_{g(i)}$。因此，权重矩阵 $W$ 为：\n$$\nW = \\text{diag}(w_1, w_2, \\ldots, w_N)\n$$\n如果未检测到异方差性（$R \\le \\tau$），我们被指示使用单位权重，即对所有 $i$ 都有 $w_i = 1$。这使得 $W$ 成为单位矩阵 $I$，WLS 估计量变得与 OLS 估计量相同：$\\hat{\\beta}_{\\text{WLS}} = (X^T I X)^{-1} X^T I y = \\hat{\\beta}_{\\text{OLS}}$。\n\n### 5. 提取系数\n每个测试用例的最后一步是从估计向量 $\\hat{\\beta}_{\\text{OLS}}$ 和 $\\hat{\\beta}_{\\text{WLS}}$ 中提取相关系数。所需的系数是：\n- $x$ 的斜率：$\\hat{\\beta}_1$，即 $\\hat{\\beta}$ 向量的第二个元素。\n- 水平 $B$ 的虚拟变量系数：$\\hat{\\gamma}_B$，即第三个元素。\n- 水平 $C$ 的虚拟变量系数：$\\hat{\\gamma}_C$，即第四个元素。\n将这些值与异方差性的布尔标志一起编译成最终的输出格式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of statistical learning problems involving OLS, heteroscedasticity\n    diagnosis, and WLS for a linear model with a qualitative predictor.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            [1, 2, 3, 4, 1.5, 2.5, 3.5, 4.5, 0.5, 1.5, 2.5, 3.5],\n            [3.7, 4.9, 6.6, 7.8, 5.75, 2.95, 7.95, 5.55, 4.25, 3.95, 7.0, 6.65],\n            [\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\"],\n        ),\n        (\n            [1, 2, 3, 4, 1.5, 2.5, 3.5, 4.5, 0.5, 1.5, 2.5, 3.5],\n            [3.8, 4.6, 6.7, 7.9, 3.45, 4.45, 6.35, 7.55, 3.5, 4.55, 6.4, 7.65],\n            [\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\"],\n        ),\n        (\n            [1, 2, 3, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 1, 3, 5],\n            [1.6, 1.8, 2.8, 3.3, 3.7, 4.29, 4.71, 5.28, 5.72, 2.5, -1.0, 4.0],\n            [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n        )\n    ]\n    \n    tau = 1.5\n    all_results = []\n    \n    for case in test_cases:\n        x_data, y_data, groups_data = case\n        \n        # Convert to numpy arrays for vectorized operations\n        x = np.array(x_data)\n        y = np.array(y_data)\n        groups = np.array(groups_data)\n        n_obs = len(y)\n        \n        # 1. Construct the design matrix X\n        X = np.zeros((n_obs, 4))\n        X[:, 0] = 1  # Intercept\n        X[:, 1] = x  # Quantitative predictor\n        X[:, 2] = (groups == \"B\").astype(int)  # Dummy for level B\n        X[:, 3] = (groups == \"C\").astype(int)  # Dummy for level C\n        \n        # 2. Compute the Ordinary Least Squares (OLS) estimate\n        try:\n            XTX_inv = np.linalg.inv(X.T @ X)\n            beta_ols = XTX_inv @ (X.T @ y)\n        except np.linalg.LinAlgError:\n            # This case should not occur with the given test data\n            # but is good practice for numerical stability.\n            all_results.append(None)\n            continue\n            \n        # 3. Compute residuals and estimate level-specific variances\n        residuals = y - X @ beta_ols\n        \n        group_indices = {\n            'A': np.where(groups == 'A')[0],\n            'B': np.where(groups == 'B')[0],\n            'C': np.where(groups == 'C')[0]\n        }\n        \n        group_variances = {}\n        for level, indices in group_indices.items():\n            if len(indices) > 0:\n                group_variances[level] = np.mean(residuals[indices]**2)\n            else:\n                 group_variances[level] = np.nan # Handle cases where a group might be empty\n        \n        valid_variances = [v for v in group_variances.values() if not np.isnan(v)]\n        \n        # 4. Diagnose heteroscedasticity\n        hetero_present = False\n        if len(valid_variances) > 1:\n            R = max(valid_variances) / min(valid_variances) if min(valid_variances) > 0 else float('inf')\n            if R > tau:\n                hetero_present = True\n\n        # 5. Perform WLS if heteroscedasticity is present\n        if hetero_present:\n            weights = np.ones(n_obs)\n            for level, var in group_variances.items():\n                if not np.isnan(var) and var > 0:\n                    weights[group_indices[level]] = 1.0 / var\n\n            W = np.diag(weights)\n            \n            try:\n                XTWX_inv = np.linalg.inv(X.T @ W @ X)\n                beta_wls = XTWX_inv @ (X.T @ W @ y)\n            except np.linalg.LinAlgError:\n                all_results.append(None)\n                continue\n        else:\n            # If not heteroscedastic, WLS is equivalent to OLS (with unit weights)\n            beta_wls = beta_ols\n            \n        # 6. Extract coefficients and round to 6 decimal places\n        ols_slope_x = round(beta_ols[1], 6)\n        wls_slope_x = round(beta_wls[1], 6)\n        ols_gamma_B = round(beta_ols[2], 6)\n        wls_gamma_B = round(beta_wls[2], 6)\n        ols_gamma_C = round(beta_ols[3], 6)\n        wls_gamma_C = round(beta_wls[3], 6)\n        \n        case_result = [\n            hetero_present,\n            ols_slope_x, wls_slope_x,\n            ols_gamma_B, wls_gamma_B,\n            ols_gamma_C, wls_gamma_C\n        ]\n        all_results.append(case_result)\n        \n    # Final print statement in the exact required format.\n    # Convert each inner list to its string representation\n    results_str = [str(res).replace(\"'\", \"\") for res in all_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在标准回归分析之外，现代统计学习越来越关注模型的社会影响，例如算法的公平性。本练习将引导你进入一个前沿领域：通过在传统最小二乘法目标函数中加入一个正则化项，来主动惩罚模型对不同类别群体产生的预测差异。这不仅是一种强大的建模技术，也体现了将“公平性”这一抽象概念量化并融入模型构建过程的核心思想 。",
            "id": "3164666",
            "problem": "考虑一个普通最小二乘回归问题，其中包含一个连续预测变量和一个具有三分类的定性预测变量。设有 $n$ 个观测值，索引为 $i \\in \\{1,\\dots,n\\}$，响应变量为 $y_i \\in \\mathbb{R}$，连续预测变量为 $x_i \\in \\mathbb{R}$，类别标签为 $g_i \\in \\{A,B,C\\}$。使用基线编码，以 $C$ 作为基线类别，并定义虚拟变量 $D_{A,i} \\in \\{0,1\\}$ 和 $D_{B,i} \\in \\{0,1\\}$，使得当 $g_i = A$ 时 $D_{A,i} = 1$，当 $g_i = B$ 时 $D_{B,i} = 1$，以及当 $g_i = C$ 时 $D_{A,i} = D_{B,i} = 0$。考虑以下线性模型\n$$\ny_i = \\beta_0 + \\beta_x x_i + \\beta_A D_{A,i} + \\beta_B D_{B,i} + \\varepsilon_i,\n$$\n其中 $\\varepsilon_i$ 是均值为零的噪声项。普通最小二乘法最小化以下准则\n$$\nJ_{\\mathrm{OLS}}(\\beta) = \\sum_{i=1}^{n} \\left(y_i - \\beta_0 - \\beta_x x_i - \\beta_A D_{A,i} - \\beta_B D_{B,i}\\right)^2.\n$$\n为了促进不同类别预测之间的公平性，引入一个正则化项，该项惩罚在参考输入 $x = 0$ 时特定类别预测之间的差异。在 $x = 0$ 时，类别 $k \\in \\{A,B,C\\}$ 的预测值为 $\\mu_k = \\beta_0 + \\beta_x \\cdot 0 + \\beta_k$，其中在基线编码下，$\\beta_C$ 隐式为 $0$。定义考虑公平性的惩罚准则\n$$\nJ_{\\lambda}(\\beta) = J_{\\mathrm{OLS}}(\\beta) + \\lambda \\sum_{k  \\ell \\in \\{A,B,C\\}} \\left(\\mu_k - \\mu_{\\ell}\\right)^2,\n$$\n其中 $\\lambda \\ge 0$。因此，公平性惩罚项惩罚 $\\beta_A$、$\\beta_B$ 和 $0$ 之间的成对差异。您的任务是：\n- 从第一性原理出发，推导最小化 $J_{\\lambda}(\\beta)$ 所对应的正规方程，将惩罚项表示为虚拟系数的二次型，并将其与类别预测被均等化的约束优化问题联系起来。\n- 实现一个算法，该算法构建设计矩阵，组合带有公平性惩罚项的增广正规方程，并通过求解线性系统来计算 $\\hat{\\beta}$。\n- 同时，计算对应于在 $x=0$ 时类别间完全公平的约束最小二乘解。在基线编码中，这意味著 $\\beta_A = 0$ 和 $\\beta_B = 0$，即一个只包含 $\\beta_0$ 和 $\\beta_x$ 的模型。\n- 对每个测试用例，计算并返回：\n  1. 惩罚估计量的分量 $[\\hat{\\beta}_0,\\hat{\\beta}_x,\\hat{\\beta}_A,\\hat{\\beta}_B]$，\n  2. 公平性差距，定义为 $\\sum_{k  \\ell} (\\hat{\\mu}_k - \\hat{\\mu}_{\\ell})^2$，其中 $\\hat{\\mu}_A = \\hat{\\beta}_0 + \\hat{\\beta}_A$，$\\hat{\\mu}_B = \\hat{\\beta}_0 + \\hat{\\beta}_B$，以及 $\\hat{\\mu}_C = \\hat{\\beta}_0$，\n  3. 通过仅使用截距和 $x$ 的普通最小二乘法获得的约束估计量的分量 $[\\hat{\\beta}_0^{(c)},\\hat{\\beta}_x^{(c)}]$。\n不使用物理单位。所有输出必须是实数。\n\n使用以下测试套件，它涵盖了一般情况、$\\lambda = 0$ 的边界情况、大 $\\lambda$ 值的情况，以及一个类别样本很少的不均衡情况：\n\n- 测试用例 1（类别均衡，中等公平性）：\n  - $x = [0,1,2,3,4,5,6,7,8]$\n  - $g = [A,B,C,A,B,C,A,B,C]$\n  - $y = [2.0,1.0,2.0,3.5,2.5,3.5,5.0,4.0,5.0]$\n  - $\\lambda = 1.0$\n\n- 测试用例 2（无公平性惩罚）：\n  - $x = [0,1,2,3,4,5,6,7,8]$\n  - $g = [A,B,C,A,B,C,A,B,C]$\n  - $y = [2.0,1.0,2.0,3.5,2.5,3.5,5.0,4.0,5.0]$\n  - $\\lambda = 0.0$\n\n- 测试用例 3（强公平性惩罚）：\n  - $x = [0,1,2,3,4,5,6,7,8]$\n  - $g = [A,B,C,A,B,C,A,B,C]$\n  - $y = [2.0,1.0,2.0,3.5,2.5,3.5,5.0,4.0,5.0]$\n  - $\\lambda = 1000000.0$\n\n- 测试用例 4（类别不均衡，中等公平性）：\n  - $x = [0,2,4,1,3]$\n  - $g = [A,B,C,A,B]$\n  - $y = [2.0,1.5,3.0,2.5,2.0]$\n  - $\\lambda = 5.0$\n\n您的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表形式的结果，顺序如下：对于每个测试用例，一个列表\n$$\n[\\hat{\\beta}_0,\\hat{\\beta}_x,\\hat{\\beta}_A,\\hat{\\beta}_B,\\text{fairness\\_gap},\\hat{\\beta}_0^{(c)},\\hat{\\beta}_x^{(c)}]\n$$\n并且所有四个列表都包含在一个外部列表中。例如，输出格式为\n$$\n[[b_{0,1},b_{x,1},b_{A,1},b_{B,1},fg_1,b_{0,1}^{(c)},b_{x,1}^{(c)}],[b_{0,2},\\dots],\\dots,[b_{0,4},\\dots]].\n$$",
            "solution": "核心任务是找到最小化惩罚目标函数 $J_{\\lambda}(\\beta)$ 的系数向量 $\\beta = [\\beta_0, \\beta_x, \\beta_A, \\beta_B]^T$。我们将首先用矩阵代数表示该问题，从第一性原理推导正规方程，然后概述求解算法。\n\n线性模型由 $y_i = \\beta_0 + \\beta_x x_i + \\beta_A D_{A,i} + \\beta_B D_{B,i} + \\varepsilon_i$ 给出。这可以表示为矩阵形式 $y = X\\beta + \\varepsilon$，其中 $y$ 是观测值的 $n \\times 1$ 向量，$X$ 是 $n \\times 4$ 的设计矩阵，$\\beta$ 是系数的 $4 \\times 1$ 向量，$\\varepsilon$ 是噪声项的向量。设计矩阵 $X$ 的第 $i$ 行是 $[1, x_i, D_{A,i}, D_{B,i}]$，对应于系数 $\\beta_0, \\beta_x, \\beta_A, \\beta_B$。\n\n目标函数 $J_{\\lambda}(\\beta)$ 由两部分组成：OLS 准则 $J_{\\mathrm{OLS}}(\\beta)$ 和一个公平性惩罚项。\nOLS 准则是残差平方和：\n$$\nJ_{\\mathrm{OLS}}(\\beta) = \\sum_{i=1}^{n} (y_i - (X\\beta)_i)^2 = (y - X\\beta)^T (y - X\\beta).\n$$\n公平性惩罚项旨在均等化三个类别 $A$、$B$ 和 $C$ 的预测截距。在 $x=0$ 时，类别 $k$ 的预测值为 $\\mu_k$。在使用 $C$ 作为参考的基线编码下，我们有：\n$$\n\\mu_A = \\beta_0 + \\beta_A, \\quad \\mu_B = \\beta_0 + \\beta_B, \\quad \\mu_C = \\beta_0.\n$$\n惩罚项是这些截距之间差异的平方和：\n$$\n\\text{Penalty} = \\lambda \\sum_{k  \\ell \\in \\{A,B,C\\}} (\\mu_k - \\mu_{\\ell})^2 = \\lambda \\left[ (\\mu_A - \\mu_B)^2 + (\\mu_A - \\mu_C)^2 + (\\mu_B - \\mu_C)^2 \\right].\n$$\n将 $\\mu_k$ 的表达式用 $\\beta$ 系数代入：\n$$\n\\text{Penalty} = \\lambda \\left[ ((\\beta_0 + \\beta_A) - (\\beta_0 + \\beta_B))^2 + ((\\beta_0 + \\beta_A) - \\beta_0)^2 + ((\\beta_0 + \\beta_B) - \\beta_0)^2 \\right]\n$$\n$$\n= \\lambda \\left[ (\\beta_A - \\beta_B)^2 + \\beta_A^2 + \\beta_B^2 \\right] = \\lambda (\\beta_A^2 - 2\\beta_A\\beta_B + \\beta_B^2 + \\beta_A^2 + \\beta_B^2) = \\lambda (2\\beta_A^2 + 2\\beta_B^2 - 2\\beta_A\\beta_B).\n$$\n该惩罚项是仅涉及虚拟变量系数 $\\beta_A$ 和 $\\beta_B$ 的二次型。它可以写成矩阵形式 $\\lambda \\beta^T P \\beta$，其中 $P$ 是一个 $4 \\times 4$ 矩阵：\n$$\n\\lambda \\beta^T P \\beta = \\lambda [\\beta_0, \\beta_x, \\beta_A, \\beta_B]\n\\begin{pmatrix}\n0  0  0  0 \\\\\n0  0  0  0 \\\\\n0  0  2  -1 \\\\\n0  0  -1  2\n\\end{pmatrix}\n\\begin{pmatrix} \\beta_0 \\\\ \\beta_x \\\\ \\beta_A \\\\ \\beta_B \\end{pmatrix}.\n$$\n需要最小化的总目标函数是：\n$$\nJ_{\\lambda}(\\beta) = (y - X\\beta)^T (y - X\\beta) + \\lambda \\beta^T P \\beta.\n$$\n为了找到最小值，我们计算 $J_{\\lambda}(\\beta)$ 关于 $\\beta$ 的梯度并将其设为零。使用标准的矩阵微积分结果，梯度为：\n$$\n\\nabla_{\\beta} J_{\\lambda}(\\beta) = \\nabla_{\\beta} (y^T y - 2y^T X\\beta + \\beta^T X^T X \\beta + \\lambda \\beta^T P \\beta) = -2X^T y + 2X^T X \\beta + 2\\lambda P \\beta.\n$$\n这里我们利用了 $X^T X$ 和 $P$ 都是对称矩阵的事实。将梯度设为零以找到最优估计量 $\\hat{\\beta}$：\n$$\n-2X^T y + 2X^T X \\hat{\\beta} + 2\\lambda P \\hat{\\beta} = 0 \\implies (X^T X + \\lambda P) \\hat{\\beta} = X^T y.\n$$\n这是惩罚回归问题的正规方程组。估计量 $\\hat{\\beta}$ 可以通过求解这个线性系统得到。当 $\\lambda > 0$ 时（假设 $X$ 具有满列秩），矩阵 $A = X^T X + \\lambda P$ 是一个正定矩阵，因此是可逆的，保证了唯一解的存在。\n\n这个正则化框架可以看作是强制执行约束 $\\mu_A = \\mu_B = \\mu_C$ 的一种惩罚方法。这些等式等价于要求 $\\beta_A = 0$ 和 $\\beta_B = 0$。惩罚项 $\\lambda (2\\beta_A^2 + 2\\beta_B^2 - 2\\beta_A\\beta_B)$ 为零当且仅当 $\\beta_A=0$ 和 $\\beta_B=0$。对于超参数 $\\lambda$ 的较大值，最小化器 $\\hat{\\beta}$ 将得到非常接近于零的 $\\hat{\\beta}_A$ 和 $\\hat{\\beta}_B$，使得惩罚解逼近约束最小二乘问题的解。\n\n约束问题是在约束条件 $\\beta_A = 0$ 和 $\\beta_B = 0$ 下最小化 $J_{\\mathrm{OLS}}$。这等价于拟合一个更简单的线性模型 $y_i = \\beta_0^{(c)} + \\beta_x^{(c)} x_i + \\varepsilon_i$。相应的设计矩阵 $X_c$ 是一个 $n \\times 2$ 的矩阵，其第 $i$ 行为 $[1, x_i]$。系数向量为 $\\beta_c = [\\beta_0^{(c)}, \\beta_x^{(c)}]^T$。这个标准 OLS 问题的正规方程是：\n$$\n(X_c^T X_c) \\hat{\\beta}_c = X_c^T y.\n$$\n解 $\\hat{\\beta}_c$ 是约束估计量。\n\n对于每个测试用例，实现将按以下步骤进行：\n1.  基于输入向量 $x$ 和 $g$ 构建 $n \\times 4$ 的设计矩阵 $X$。\n2.  构建如上定义的 $4 \\times 4$ 惩罚矩阵 $P$。\n3.  求解线性系统 $(X^T X + \\lambda P) \\hat{\\beta} = X^T y$ 以获得惩罚系数 $\\hat{\\beta} = [\\hat{\\beta}_0, \\hat{\\beta}_x, \\hat{\\beta}_A, \\hat{\\beta}_B]^T$。\n4.  使用估计的系数计算公平性差距：$\\text{gap} = (\\hat{\\beta}_A - \\hat{\\beta}_B)^2 + \\hat{\\beta}_A^2 + \\hat{\\beta}_B^2$。\n5.  构建 $n \\times 2$ 的约束设计矩阵 $X_c$。\n6.  求解线性系统 $(X_c^T X_c) \\hat{\\beta}_c = X_c^T y$ 以找到约束系数 $\\hat{\\beta}_c = [\\hat{\\beta}_0^{(c)}, \\hat{\\beta}_x^{(c)}]^T$。\n7.  收集并格式化所需的输出。\n\n这种基于原理的方法通过直接实现推导出的正规方程来确保正确性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the regularized least squares problem for multiple test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (balanced categories, moderate fairness)\n        {\n            \"x\": np.array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n            \"y\": np.array([2.0, 1.0, 2.0, 3.5, 2.5, 3.5, 5.0, 4.0, 5.0], dtype=float),\n            \"lambda_val\": 1.0\n        },\n        # Test case 2 (no fairness penalty)\n        {\n            \"x\": np.array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n            \"y\": np.array([2.0, 1.0, 2.0, 3.5, 2.5, 3.5, 5.0, 4.0, 5.0], dtype=float),\n            \"lambda_val\": 0.0\n        },\n        # Test case 3 (strong fairness penalty)\n        {\n            \"x\": np.array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n            \"y\": np.array([2.0, 1.0, 2.0, 3.5, 2.5, 3.5, 5.0, 4.0, 5.0], dtype=float),\n            \"lambda_val\": 1000000.0\n        },\n        # Test case 4 (imbalanced categories, moderate fairness)\n        {\n            \"x\": np.array([0, 2, 4, 1, 3], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B'],\n            \"y\": np.array([2.0, 1.5, 3.0, 2.5, 2.0], dtype=float),\n            \"lambda_val\": 5.0\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        x, g, y, lambda_val = case[\"x\"], case[\"g\"], case[\"y\"], case[\"lambda_val\"]\n        n = len(y)\n\n        # 1. Construct the full design matrix X\n        X = np.zeros((n, 4))\n        X[:, 0] = 1  # Intercept\n        X[:, 1] = x  # Continuous predictor\n        for i in range(n):\n            if g[i] == 'A':\n                X[i, 2] = 1\n            elif g[i] == 'B':\n                X[i, 3] = 1\n\n        # 2. Construct the penalty matrix P\n        P = np.zeros((4, 4))\n        P[2, 2] = 2\n        P[3, 3] = 2\n        P[2, 3] = -1\n        P[3, 2] = -1\n\n        # 3. Solve for the penalized estimator beta_hat\n        XtX = X.T @ X\n        Xty = X.T @ y\n        A = XtX + lambda_val * P\n        beta_hat = np.linalg.solve(A, Xty)\n\n        # 4. Calculate the fairness gap\n        beta_A_hat, beta_B_hat = beta_hat[2], beta_hat[3]\n        # The fairness penalty is lambda * (2*bA**2 + 2*bB**2 - 2*bA*bB)\n        # The fairness GAP is (mu_A - mu_B)^2 + (mu_A - mu_C)^2 + (mu_B - mu_C)^2\n        # which simplifies to (bA - bB)^2 + bA^2 + bB^2\n        fairness_gap = (beta_A_hat - beta_B_hat)**2 + beta_A_hat**2 + beta_B_hat**2\n\n        # 5. Construct the constrained design matrix Xc\n        Xc = np.zeros((n, 2))\n        Xc[:, 0] = 1  # Intercept\n        Xc[:, 1] = x  # Continuous predictor\n\n        # 6. Solve for the constrained estimator beta_c_hat\n        XctXc = Xc.T @ Xc\n        Xcty = Xc.T @ y\n        beta_c_hat = np.linalg.solve(XctXc, Xcty)\n\n        # 7. Assemble the results for the current test case\n        result = [\n            beta_hat[0], \n            beta_hat[1], \n            beta_hat[2], \n            beta_hat[3], \n            fairness_gap, \n            beta_c_hat[0], \n            beta_c_hat[1]\n        ]\n        all_results.append(result)\n\n    # Format the final output string\n    # E.g., [[val1, val2, ...], [val1, val2, ...]]\n    output_str = \"[\" + \",\".join([\"[\" + \",\".join(map(str, res)) + \"]\" for res in all_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}