{
    "hands_on_practices": [
        {
            "introduction": "赤池信息准则（AIC）是平衡模型拟合优度与复杂度的经典工具。然而，在样本量较小时，AIC倾向于选择过于复杂的模型，为此，学者们提出了修正版的赤池信息准则（AICc）。本练习将引导你通过编程实现一个场景，直观地比较这两种准则，并量化修正项在何种情况下会实质性地改变模型选择的结果。",
            "id": "3149493",
            "problem": "考虑在线性回归高斯误差模型中，基于最大似然估计（MLE）和Kullback–Leibler散度的两个嵌套参数模型之间的模型选择问题。赤池信息准则（Akaike Information Criterion, AIC）和修正的赤池信息准则（Corrected Akaike Information Criterion, AICc）——在首次使用时需写出全称——均由最大似然估计推导而来，其目标是最小化预期信息损失。修正版本引入了一个显式的小样本调整项，该调整项依赖于样本大小和模型维度。您的任务是构建一个完整的程序，构造一个场景，在该场景中，修正后的准则在小样本情况下优于未修正的准则，并量化修正项何时会实质性地改变所选模型。\n\n从高斯线性模型（方差未知）的最大化对数似然函数依赖于残差平方和这一基本出发点，假设每个测试用例具有以下设置：\n- 两个候选模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$，其参数数量分别为 $k_1$ 和 $k_2$，包括所有估计的参数（截距、回归系数和误差方差），以及一个共同的样本大小 $n$。\n- 模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的残差平方和分别表示为 $RSS_1$ 和 $RSS_2$。\n- 较小的准则值选定模型。\n\n将“实质性改变”定义如下：如果AIC选择 $\\mathcal{M}_2$ 而AICc选择 $\\mathcal{M}_1$，或者反之，则修正项实质性地改变了所选模型。此外，通过计算最小整数 $n^\\star$ 来量化样本大小的阈值。该 $n^\\star$ 使得两个修正准则相等，前提是保持观测到的最大化对数似然和参数数量不变，仅在修正项中改变 $n$。如果不存在有限解，则返回一个大的哨兵整数。\n\n实现一个程序，为每个测试用例计算：\n- AIC选择的模型，表示为整数（$1$ 表示 $\\mathcal{M}_1$，$2$ 表示 $\\mathcal{M}_2$）。\n- AICc选择的模型，表示为整数（$1$ 表示 $\\mathcal{M}_1$，$2$ 表示 $\\mathcal{M}_2$）。\n- 一个整数标志，指示修正项是否实质性地改变了所选模型（如果AIC和AICc选择的模型不同，则为 $1$，否则为 $0$）。\n- 最小整数 $n^\\star$，在该样本大小时，若保持拟合的最大化对数似然和参数数量不变，两个修正准则相等。如果等式在非整数 $n$ 处成立，则取大于该值的最小整数。如果由于退化情况而无有限解，则返回一个大的哨兵整数（使用 $10^9$）。\n\n使用以下参数值测试套件，每个测试用例指定为一个元组 $(n, k_1, k_2, RSS_1, RSS_2)$：\n- 测试 $1$：$(12, 3, 4, 10.0, 8.0)$，一个小样本案例，其中更复杂的模型拟合度有适度改善。\n- 测试 $2$：$(100, 3, 4, 80.0, 78.0)$，一个大样本案例，其中修正项很小。\n- 测试 $3$：$(20, 3, 6, 10.0, 7.0)$，一个中小型样本，模型维度差异较大。\n- 测试 $4$：$(200, 3, 6, 160.0, 152.0)$，一个大样本案例，模型维度差异较大但修正影响极小。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果本身必须是按 $[aic\\_selected, aicc\\_selected, changed\\_flag, n^\\star]$ 顺序排列的四个整数的列表。例如，总输出格式为 $[[r_{11}, r_{12}, r_{13}, r_{14}], [r_{21}, r_{22}, r_{23}, r_{24}], [r_{31}, r_{32}, r_{33}, r_{34}], [r_{41}, r_{42}, r_{43}, r_{44}]]$。",
            "solution": "该问题要求使用赤池信息准则（AIC）及其小样本修正版——修正的赤池信息准则（AICc），来分析两个线性回归模型之间的模型选择。我们必须计算每个准则选择了哪个模型，判断选择是否不同，并计算一个临界样本大小 $n^\\star$，在该样本大小时，若保持其他估计量固定，两个AICc值将相等。\n\nAIC和AICc的理论基础都源于信息论。它们旨在估计拟合模型与未知真实数据生成过程之间的预期相对Kullback-Leibler散度。较低的准则值表明模型预期会损失更少的信息，从而在拟合优度和模型复杂度之间提供了更好的平衡。\n\n对于一个具有 $k$ 个估计参数的参数统计模型，AIC的一般形式为：\n$$\nAIC = -2 \\hat{\\mathcal{L}} + 2k\n$$\n其中 $\\hat{\\mathcal{L}}$ 是模型对数似然函数的最大化值。\n\n在线性回归模型和正态分布误差的特定情境下，参数是回归系数（包括截距）和误差方差 $\\sigma^2$。如果一个模型有 $p$ 个预测变量，则需要估计 $p+1$ 个回归系数。方差 $\\sigma^2$ 也需要估计。因此，估计参数的总数为 $k = p+2$。问题陈述提供了模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的总参数数量，分别为 $k_1$ 和 $k_2$。\n\n对于一个样本大小为 $n$、残差平方和为 ($RSS$) 的高斯线性模型，其最大化对数似然为：\n$$\n\\hat{\\mathcal{L}} = -\\frac{n}{2} \\left( \\log(2\\pi) + \\log\\left(\\frac{RSS}{n}\\right) + 1 \\right)\n$$\n将此代入AIC公式可得：\n$$\nAIC = n \\left( \\log(2\\pi) + \\log\\left(\\frac{RSS}{n}\\right) + 1 \\right) + 2k\n$$\n当基于大小为 $n$ 的同一数据集比较两个模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 时，项 $n(\\log(2\\pi) + 1)$ 是一个公共加性常数，可以忽略而不影响选择。此外，项 $-n\\log(n)$ 对两者也是共有的。因此，为了比较，可以使用一个简化的等价形式：\n$$\nAIC' = n\\log(RSS) + 2k\n$$\n我们将使用这个简化形式来确定AIC选择的模型。具有较小 $AIC'$ 值的模型是更优选的。\n\n修正的赤池信息准则（AICc）调整了惩罚项，以解释小样本量的情况，在小样本下，AIC倾向于选择过于复杂的模型。其公式为：\n$$\nAICc = AIC + \\frac{2k(k+1)}{n - k - 1}\n$$\n当 $n$ 相对于 $k$ 较小时，此修正项非常重要，但随着 $n \\to \\infty$，它收敛于 $0$。分母要求 $n - k - 1 > 0$，即 $n > k+1$，这是模型可识别和AICc有定义的必要条件。对于每个测试用例，我们计算 $AICc_1$ 和 $AICc_2$，并选择值较小的模型。\n\n对每个测试用例 $(n, k_1, k_2, RSS_1, RSS_2)$，分析过程如下：\n\n$1$. **基于AIC的模型选择**：我们计算 $AIC'_1 = n\\log(RSS_1) + 2k_1$ 和 $AIC'_2 = n\\log(RSS_2) + 2k_2$。如果 $AIC'_1  AIC'_2$，我们选择模型 $\\mathcal{M}_1$；否则，我们选择模型 $\\mathcal{M}_2$。这决定了 `aic_selected`。\n\n$2$. **基于AICc的模型选择**：我们计算完整的 $AIC_1$ 和 $AIC_2$ 值（或简化的 $AIC'_1$ 和 $AIC'_2$）及其各自的修正项。\n$$\nAICc_1 = AIC'_1 + \\frac{2k_1(k_1+1)}{n - k_1 - 1}\n$$\n$$\nAICc_2 = AIC'_2 + \\frac{2k_2(k_2+1)}{n - k_2 - 1}\n$$\n选择具有较小 $AICc$ 值的模型。这决定了 `aicc_selected`。\n\n$3$. **实质性改变标志**：如果 `aic_selected` != `aicc_selected`，则 `changed_flag` 设置为 $1$，否则为 $0$。\n\n$4$. **临界样本大小 $n^\\star$**：我们被要求找到最小的整数 $n^\\star$，使得两个修正后的准则相等，假设最大化对数似然（也就是 $AIC'$ 值）保持在其观测值上固定不变，而只允许 $n$ 在修正项中变化。设观测值为 $AIC'_{1,obs}$ 和 $AIC'_{2,obs}$。我们必须求解方程中的 $n$：\n$$\nAIC'_{1,obs} + \\frac{2k_1(k_1+1)}{n - k_1 - 1} = AIC'_{2,obs} + \\frac{2k_2(k_2+1)}{n - k_2 - 1}\n$$\n令 $\\Delta AIC'_{obs} = AIC'_{1,obs} - AIC'_{2,obs}$，$P_1 = 2k_1(k_1+1)$，以及 $P_2 = 2k_2(k_2+1)$。方程为：\n$$\n\\Delta AIC'_{obs} = \\frac{P_2}{n - k_2 - 1} - \\frac{P_1}{n - k_1 - 1}\n$$\n重新整理后得到一个关于 $n$ 的二次方程，形式为 $an^2 + bn + c = 0$，其中：\n- $a = \\Delta AIC'_{obs}$\n- $b = -\\Delta AIC'_{obs}(k_1+k_2+2) - (P_2-P_1)$\n- $c = \\Delta AIC'_{obs}(k_1+1)(k_2+1) + P_2(k_1+1) - P_1(k_2+1)$\n\n这个方程可以用二次公式求解 $n$。我们寻找满足条件 $n > \\max(k_1, k_2) + 1$ 的最小实数根 $n$。最终值 $n^\\star$ 是大于或等于此根的最小整数（即 $\\lceil n \\rceil$）。如果不存在这样的有限有效根（例如，由于判别式为非正数、根不满足条件，或在所有 $n$ 上准则都相等的退化情况），则返回一个哨兵值 $10^9$。如果 $k_1=k_2$ 且 $RSS_1=RSS_2$，则会出现退化情况，使得 $\\Delta AIC'_{obs}=0$ 和 $P_1=P_2$，这将方程简化为 $0=0$。\n\n现在将通过对每个提供的测试用例应用这个四步过程来继续实现。",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the model selection problem for the test cases provided.\n    \"\"\"\n    \n    test_cases = [\n        # (n, k1, k2, RSS1, RSS2)\n        (12, 3, 4, 10.0, 8.0),\n        (100, 3, 4, 80.0, 78.0),\n        (20, 3, 6, 10.0, 7.0),\n        (200, 3, 6, 160.0, 152.0),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n, k1, k2, rss1, rss2 = case\n\n        # Step 1: Compute AIC and select model\n        # The comparative AIC can be simplified to n*log(RSS) + 2k, as other terms cancel out.\n        aic1_obs = n * np.log(rss1) + 2 * k1\n        aic2_obs = n * np.log(rss2) + 2 * k2\n        aic_selected = 1 if aic1_obs  aic2_obs else 2\n\n        # Step 2: Compute AICc and select model\n        # Check for valid denominators for AICc correction term\n        if n - k1 - 1 = 0 or n - k2 - 1 = 0:\n            # This case should not happen with the given test data, but is a necessary check.\n            # Set AICc to infinity to indicate it's not applicable.\n            aicc1 = float('inf')\n            aicc2 = float('inf')\n        else:\n            correction1 = (2 * k1 * (k1 + 1)) / (n - k1 - 1)\n            correction2 = (2 * k2 * (k2 + 1)) / (n - k2 - 1)\n            aicc1 = aic1_obs + correction1\n            aicc2 = aic2_obs + correction2\n\n        aicc_selected = 1 if aicc1  aicc2 else 2\n\n        # Step 3: Determine if the selection materially changed\n        changed_flag = 1 if aic_selected != aicc_selected else 0\n\n        # Step 4: Compute n_star\n        n_star = calculate_n_star(aic1_obs - aic2_obs, k1, k2)\n        \n        results.append([aic_selected, aicc_selected, changed_flag, int(n_star)])\n\n    # Format the final output as a string representation of a list of lists.\n    # e.g., [[r11, r12, r13, r14], [r21, r22, r23, r24]]\n    # This avoids numpy formatting and creates the exact required output string.\n    output_str = \"[\" + \", \".join(map(str, results)) + \"]\"\n    output_str = output_str.replace(\" \", \"\") # Remove spaces for exact match\n    print(output_str)\n\ndef calculate_n_star(delta_aic, k1, k2):\n    \"\"\"\n    Calculates the smallest integer n* where AICc1(n) = AICc2(n),\n    holding observed log-likelihoods constant.\n    \"\"\"\n    sentinel_value = 10**9\n    \n    # Check for degeneracy: if models are identical in parameters and fit,\n    # their AIC and AICc values will always be identical.\n    if k1 == k2 and abs(delta_aic)  1e-9:\n        return sentinel_value\n\n    p1 = 2 * k1 * (k1 + 1)\n    p2 = 2 * k2 * (k2 + 1)\n    \n    a = delta_aic\n    b = -delta_aic * (k1 + k2 + 2) - (p2 - p1)\n    c = delta_aic * (k1 + 1) * (k2 + 1) + p2 * (k1 + 1) - p1 * (k2 + 1)\n\n    min_n_valid = max(k1, k2) + 1\n\n    valid_roots = []\n\n    if abs(a)  1e-9: # Linear equation bn + c = 0\n        if abs(b) > 1e-9:\n            n_sol = -c / b\n            if n_sol > min_n_valid:\n                valid_roots.append(n_sol)\n    else: # Quadratic equation\n        discriminant = b**2 - 4 * a * c\n        if discriminant >= 0:\n            sqrt_d = np.sqrt(discriminant)\n            n1 = (-b + sqrt_d) / (2 * a)\n            n2 = (-b - sqrt_d) / (2 * a)\n            \n            if n1 > min_n_valid:\n                valid_roots.append(n1)\n            if n2 > min_n_valid:\n                valid_roots.append(n2)\n\n    if not valid_roots:\n        return sentinel_value\n    else:\n        # Return the ceiling of the smallest valid root\n        return math.ceil(min(valid_roots))\n\nsolve()\n\n```"
        },
        {
            "introduction": "当我们进入贝叶斯统计的领域，模型评估的焦点转向了基于后验分布的预测性能。广泛适用信息准则（WAIC）和留一法交叉验证（LOO-CV）是衡量贝叶斯模型样本外预测精度的两种现代主流方法。本练习将带领你实现这两种复杂的评估技术，并探讨在贝叶斯线性回归中，先验分布的选择如何影响最终的模型决策。",
            "id": "3149441",
            "problem": "您的任务是实现并分析高斯线性回归中贝叶斯模型选择对先验强度的敏感性，并比较广泛适用性信息准则 (WAIC) 和留一交叉验证 (LOO-CV)。该问题的教学背景是本科中级水平的统计学习，重点是模型选择方法。分析必须基于贝叶斯推断和预测性能评估的基本原则。\n\n考虑观测噪声方差已知的高斯线性回归模型。设有 $n$ 个观测值，设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，响应向量为 $y \\in \\mathbb{R}^n$。似然函数定义为\n$$\ny \\mid X, \\beta \\sim \\mathcal{N}\\left(X \\beta,\\ \\sigma^2 I_n\\right),\n$$\n其中 $\\beta \\in \\mathbb{R}^p$ 是回归系数，$\\sigma^2  0$ 是已知的噪声方差。为 $\\beta$ 设置一个零均值各向同性高斯先验：\n$$\n\\beta \\sim \\mathcal{N}\\left(0,\\ \\tau^2 I_p\\right),\n$$\n其中 $\\tau^2  0$ 是控制收缩强度的先验方差（较小的 $\\tau^2$ 表示更强的先验正则化）。您必须研究改变 $\\tau^2$ 如何在以下两个准则下影响贝叶斯模型选择：广泛适用性信息准则 (WAIC) 和留一交叉验证 (LOO-CV)，其定义如下。\n\n- 广泛适用性信息准则 (WAIC)：通过在后验上聚合逐点预测密度来评估样本外预测拟合，并针对有效模型复杂度进行校正。您必须通过对后验进行蒙特卡洛积分来计算它。\n- 留一交叉验证 (LOO-CV)：评估预测性能的方法是，对于每个观测值 $i$，将其留出，用剩余的 $n-1$ 个观测值重新计算后验，然后在后验抽样上聚合该留出观测值的对数预测密度。\n\n您的推导和实现必须基于以下基本原理：\n- 高斯线性模型在共轭先验下的贝叶斯更新。\n- 期望对数预测密度的定义，即在后验上的积分。\n- 模型复杂度调整的含义，即在后验下对数似然的方差。\n\n数据构建必须是确定性的和纯数学的。对于给定的 $(n, p)$ 且 $p = 3$，按如下方式构建 $X$ 和 $y$。对于 $i = 1, 2, \\ldots, n$，定义 $X$ 的第 $i$ 行为\n$$\nx_{i1} = \\frac{i}{n}, \\quad x_{i2} = \\left(\\frac{i}{n}\\right)^2, \\quad x_{i3} = \\sin(i),\n$$\n其中正弦函数的参数以弧度为单位。通过以下线性关系定义 $y$\n$$\ny_i = 1.5\\,x_{i1} - 2.0\\,x_{i2} + 0.5\\,x_{i3}.\n$$\n本问题中所有三角函数的角度都必须以弧度解释。\n\n实现要求：\n- 使用蒙特卡洛近似，并使用固定数量的后验抽样 $S$ 来计算 WAIC 和 LOO-CV。对所有计算，设置 $S = 3000$ 个后验样本。\n- 使用单个固定的随机种子，以使结果完全可复现。\n- 对于 WAIC，计算似然函数在后验抽样上的逐点对数平均值，并减去对数似然的逐点后验方差。将这些值在所有观测值上求和以获得一个标量分数，并选择使该分数最大化的先验方差 $\\tau^2$。\n- 对于 LOO-CV，对于每个观测值 $i$，在留出 $(x_i, y_i)$ 后重新计算后验，计算 $y_i$ 的似然函数在留一后验抽样下的对数平均值，将这些值在所有观测值上求和以获得一个标量分数，并选择使该分数最大化的先验方差 $\\tau^2$。\n- 对于每个测试用例，返回在 WAIC 和 LOO-CV 下最优 $\\tau^2$ 的索引。索引必须是零基整数，对应于所提供的 $\\tau^2$ 网格中的位置。\n\n测试套件：\n评估以下四个测试用例。在所有情况下，均使用 $p = 3$ 和上述指定的数据构建方法。\n1. 情况 A: $n = 20$, $\\sigma^2 = 1.0$, $\\tau^2$ 网格 $[0.1, 0.5, 1.0, 2.0, 10.0]$。\n2. 情况 B: $n = 20$, $\\sigma^2 = 0.25$, $\\tau^2$ 网格 $[0.01, 0.1, 0.5, 2.0, 100.0]$。\n3. 情况 C: $n = 20$, $\\sigma^2 = 4.0$, $\\tau^2$ 网格 $[0.01, 0.05, 0.1, 0.5, 2.0]$。\n4. 情况 D (边界样本量): $n = 5$, $\\sigma^2 = 1.0$, $\\tau^2$ 网格 $[0.1, 1.0, 10.0]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，格式为逗号分隔的配对列表，并用方括号括起来。每个配对分别是 WAIC 和 LOO-CV 下最优 $\\tau^2$ 的零基索引，对应一个测试用例，并按上述顺序列出。例如，一个包含四个用例的输出应如下所示\n$$\n[[i_{A,\\mathrm{WAIC}}, i_{A,\\mathrm{LOO}}],[i_{B,\\mathrm{WAIC}}, i_{B,\\mathrm{LOO}}],[i_{C,\\mathrm{WAIC}}, i_{C,\\mathrm{LOO}}],[i_{D,\\mathrm{WAIC}}, i_{D,\\mathrm{LOO}}]],\n$$\n其中每个 $i$ 都是一个整数。最终输出必须严格按照这种格式打印为单行，不含空格。",
            "solution": "该问题要求在高斯线性回归设置中，分析贝叶斯模型选择准则对先验强度的敏感性。我们需要比较广泛适用性信息准则 (WAIC) 和留一交叉验证 (LOO-CV) 在从给定值网格中选择最优先验方差 $\\tau^2$ 时的表现。\n\n首先，我们建立贝叶斯分析的数学框架。该模型由以下部分指定：\n1.  给定设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和回归系数 $\\beta \\in \\mathbb{R}^p$ 时，响应向量 $y \\in \\mathbb{R}^n$ 的高斯似然函数：\n    $$ y \\mid X, \\beta \\sim \\mathcal{N}(X \\beta, \\sigma^2 I_n) $$\n    假设噪声方差 $\\sigma^2$ 已知。\n2.  回归系数 $\\beta$ 的零均值各向同性高斯先验：\n    $$ \\beta \\sim \\mathcal{N}(0, \\tau^2 I_p) $$\n    超参数 $\\tau^2$ 控制先验正则化的强度，较小的值会强制系数更强地向零收缩。\n\n由于高斯先验与高斯似然的共轭性，$\\beta$ 的后验分布 $p(\\beta \\mid y, X) \\sim \\mathcal{N}(\\mu_{post}, \\Sigma_{post})$ 也是高斯分布。我们通过组合似然函数和先验密度函数的指数部分来推导后验参数。后验对数密度正比于：\n$$ -\\frac{1}{2\\sigma^2} (y - X\\beta)^T(y - X\\beta) - \\frac{1}{2\\tau^2} \\beta^T\\beta $$\n对 $\\beta$ 进行配方可知，后验精度矩阵（协方差的逆）为 $\\Sigma_{post}^{-1} = \\frac{1}{\\sigma^2} X^T X + \\frac{1}{\\tau^2} I_p$，后验均值为 $\\mu_{post} = \\frac{1}{\\sigma^2} \\Sigma_{post} X^T y$。因此，后验分布完全由以下参数确定：\n$$ \\Sigma_{post} = \\left( \\frac{1}{\\sigma^2} X^T X + \\frac{1}{\\tau^2} I_p \\right)^{-1} $$\n$$ \\mu_{post} = \\frac{1}{\\sigma^2} \\Sigma_{post} X^T y $$\n\n为了评估模型选择准则，我们通过从后验分布 $\\mathcal{N}(\\mu_{post}, \\Sigma_{post})$ 中抽取 $S$ 个样本 $\\{\\beta^{(s)}\\}_{s=1}^S$ 来进行蒙特卡洛积分。\n\n**广泛适用信息准则 (WAIC)**\n\nWAIC 提供了样本外预测准确度的一个估计。问题定义了一个需要最大化的分数，即逐点对数预测密度的总和，并由一个模型复杂度的惩罚项进行校正。对于每个数据点 $i \\in \\{1, \\dots, n\\}$，我们计算：\n1.  对数逐点预测密度 $\\text{lppd}_i$，通过后验样本上似然的平均值的对数来近似：\n    $$ \\text{lppd}_i = \\log\\left(\\frac{1}{S} \\sum_{s=1}^S p(y_i \\mid \\beta^{(s)})\\right) $$\n    在数值计算上，使用 log-sum-exp 技巧来保持稳定性：$\\text{lppd}_i = \\text{logsumexp}_{s}(\\log p(y_i \\mid \\beta^{(s)})) - \\log S$。\n2.  复杂度惩罚项 $p_{WAIC,i}$，通过后验样本上对数似然的样本方差来近似：\n    $$ p_{WAIC,i} \\approx \\text{Var}_{s}(\\log p(y_i \\mid \\beta^{(s)})) $$\n\n需要最大化的总 WAIC 分数是 $W = \\sum_{i=1}^n (\\text{lppd}_i - p_{WAIC,i})$。单个观测值 $y_i$ 的对数似然为 $\\log p(y_i \\mid \\beta) = -\\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{(y_i - x_i^T\\beta)^2}{2\\sigma^2}$。\n\n**留一交叉验证 (LOO-CV)**\n\nLOO-CV 提供了一种更直接、但计算量更大的样本外预测性能估计方法。对于每个观测值 $i=1, \\dots, n$，我们执行以下步骤：\n1.  移除第 $i$ 个数据点 $(x_i, y_i)$，形成一个简化的数据集 $(X_{-i}, y_{-i})$。\n2.  基于这个简化的数据集重新计算后验分布。这会得到一个留一后验 $p(\\beta \\mid y_{-i}, X_{-i}) \\sim \\mathcal{N}(\\mu_{post,-i}, \\Sigma_{post,-i})$。其参数计算如下：\n    $$ \\Sigma_{post, -i} = \\left( \\frac{1}{\\sigma^2} X_{-i}^T X_{-i} + \\frac{1}{\\tau^2} I_p \\right)^{-1} $$\n    $$ \\mu_{post, -i} = \\frac{1}{\\sigma^2} \\Sigma_{post, -i} X_{-i}^T y_{-i} $$\n3.  从这个留一后验中抽取 $S$ 个样本 $\\{\\beta^{(-i,s)}\\}_{s=1}^S$。\n4.  计算留出点 $y_i$ 的对数预测密度，并在这些样本上取平均：\n    $$ \\text{lpd}_{-i} = \\log\\left(\\frac{1}{S} \\sum_{s=1}^S p(y_i \\mid \\beta^{(-i,s)})\\right) $$\n\n需要最大化的总 LOO-CV 分数是这些单个对数预测密度的总和：$L = \\sum_{i=1}^n \\text{lpd}_{-i}$。\n\n**计算流程**\n\n对于每个测试用例，总体算法流程如下：\n1.  初始化空列表，用于存储所提供网格中每个 $\\tau^2$ 值对应的 WAIC 和 LOO-CV 分数。\n2.  对于给定的 $n$，按照规定构建数据矩阵 $X$ 和响应向量 $y$。注意，$y$ 的数据生成过程是确定性的（无噪声），这是模拟研究中提供已知基准真值的常见设置。\n3.  遍历网格中的每个 $\\tau^2$ 值： a. 首先计算完整后验，抽取 $S=3000$ 个样本，然后聚合逐点的 $\\text{lppd}_i$ 和 $p_{WAIC,i}$ 值，从而计算 WAIC 分数。 b. 通过从 $i=1$ 到 $n$ 迭代来计算 LOO-CV 分数，每次都在 $n-1$ 个数据点上重新计算后验，抽取 $S=3000$ 个新样本，并评估单个留出点的对数预测密度。将这些对数密度求和。\n4.  在计算完所有 $\\tau^2$ 值的分数后，找出 WAIC 和 LOO-CV 各自最大分数所对应的零基索引。这两个索引构成了该测试用例的结果。\n5.  将所有测试用例的索引对聚合到一个最终列表中，并格式化以供输出。固定的随机种子确保了蒙特卡洛采样的可复现性。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Implements and analyzes Bayesian model selection sensitivity to prior strength,\n    comparing WAIC and LOO-CV for a Gaussian linear regression model.\n    \"\"\"\n    S = 3000  # Number of Monte Carlo samples\n    P = 3     # Number of features\n    SEED = 42 # Fixed random seed for reproducibility\n\n    def compute_scores(n, p, sigma_sq, tau_sq, X, y, rng):\n        \"\"\"\n        Computes WAIC and LOO-CV scores for a given model configuration.\n        \"\"\"\n        # Common terms for log-likelihood calculations\n        log_lik_const = -0.5 * np.log(2 * np.pi * sigma_sq)\n        inv_2_sigma_sq = 1.0 / (2.0 * sigma_sq)\n\n        # ---------------- WAIC Calculation ----------------\n        \n        # Full posterior distribution\n        precision_post = (1.0 / sigma_sq) * (X.T @ X) + (1.0 / tau_sq) * np.identity(p)\n        cov_post = np.linalg.inv(precision_post)\n        mean_post = (1.0 / sigma_sq) * (cov_post @ X.T @ y)\n\n        # Draw samples from the full posterior\n        beta_samples = rng.multivariate_normal(mean_post, cov_post, size=S)\n\n        # Calculate pointwise log-likelihoods for all samples\n        # Shape: (n, S)\n        pred_means = X @ beta_samples.T\n        sq_errors = (y[:, np.newaxis] - pred_means)**2\n        log_liks = log_lik_const - sq_errors * inv_2_sigma_sq\n\n        # Compute lppd and p_waic for each data point\n        lppd = logsumexp(log_liks, axis=1) - np.log(S)\n        p_waic = np.var(log_liks, axis=1, ddof=1) # Using ddof=1 for sample variance estimate\n        \n        waic_score = np.sum(lppd - p_waic)\n\n        # ---------------- LOO-CV Calculation ----------------\n        \n        total_loo_score = 0.0\n        for i in range(n):\n            # Create leave-one-out dataset\n            X_loo = np.delete(X, i, axis=0)\n            y_loo = np.delete(y, i)\n            x_i, y_i = X[i], y[i]\n\n            # Recompute posterior for the LOO dataset\n            precision_post_loo = (1.0 / sigma_sq) * (X_loo.T @ X_loo) + (1.0 / tau_sq) * np.identity(p)\n            cov_post_loo = np.linalg.inv(precision_post_loo)\n            mean_post_loo = (1.0 / sigma_sq) * (cov_post_loo @ X_loo.T @ y_loo)\n\n            # Draw samples from the LOO posterior\n            beta_samples_loo = rng.multivariate_normal(mean_post_loo, cov_post_loo, size=S)\n            \n            # Compute predictive density for the held-out point\n            pred_means_i = x_i @ beta_samples_loo.T\n            sq_errors_i = (y_i - pred_means_i)**2\n            log_liks_i = log_lik_const - sq_errors_i * inv_2_sigma_sq\n            \n            lpd_i = logsumexp(log_liks_i) - np.log(S)\n            total_loo_score += lpd_i\n        \n        return waic_score, total_loo_score\n\n    test_cases = [\n        (20, 1.0, np.array([0.1, 0.5, 1.0, 2.0, 10.0])),\n        (20, 0.25, np.array([0.01, 0.1, 0.5, 2.0, 100.0])),\n        (20, 4.0, np.array([0.01, 0.05, 0.1, 0.5, 2.0])),\n        (5, 1.0, np.array([0.1, 1.0, 10.0]))\n    ]\n\n    all_results = []\n    rng = np.random.default_rng(seed=SEED)\n\n    for n, sigma_sq, tau_sq_grid in test_cases:\n        # Generate data deterministically based on n\n        X = np.zeros((n, P))\n        y = np.zeros(n)\n        for j in range(n):\n            i_math = j + 1.0\n            x_i1 = i_math / n\n            x_i2 = (i_math / n)**2\n            x_i3 = np.sin(i_math)\n            X[j, :] = [x_i1, x_i2, x_i3]\n            y[j] = 1.5 * x_i1 - 2.0 * x_i2 + 0.5 * x_i3\n\n        waic_scores = []\n        loo_scores = []\n        for tau_sq in tau_sq_grid:\n            waic, loo = compute_scores(n, P, sigma_sq, tau_sq, X, y, rng)\n            waic_scores.append(waic)\n            loo_scores.append(loo)\n        \n        best_waic_idx = np.argmax(waic_scores)\n        best_loo_idx = np.argmax(loo_scores)\n        \n        all_results.append([best_waic_idx, best_loo_idx])\n\n    formatted_results = [f\"[{r[0]},{r[1]}]\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```"
        }
    ]
}