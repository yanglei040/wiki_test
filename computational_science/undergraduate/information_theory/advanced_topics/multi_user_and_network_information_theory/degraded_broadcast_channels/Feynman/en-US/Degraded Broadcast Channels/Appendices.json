{
    "hands_on_practices": [
        {
            "introduction": "The defining feature of a degraded broadcast channel is its inherent Markov chain structure, where one receiver's output is a statistically noisier version of the other's. This first exercise provides a direct, hands-on opportunity to test this fundamental property. By working with a given joint probability distribution, you will apply the definition of conditional independence to determine if a channel is degraded and in which direction. ",
            "id": "1617295",
            "problem": "A broadcast communication system consists of a single transmitter and two receivers. The transmitter sends a signal $X$ from an input alphabet $\\mathcal{X} = \\{s_0, s_1, s_2\\}$. The two receivers get observations $Y_1$ and $Y_2$ from output alphabets $\\mathcal{Y}_1 = \\{r_{1,0}, r_{1,1}\\}$ and $\\mathcal{Y}_2 = \\{r_{2,0}, r_{2,1}\\}$, respectively.\n\nThe joint conditional probability distribution of the channel, $p(y_1, y_2 | x)$, which describes the probability of receiving the pair $(y_1, y_2)$ given that the signal $x$ was sent, is given by the following table. The columns correspond to the output pairs $(y_1, y_2)$ in the order $(r_{1,0}, r_{2,0})$, $(r_{1,0}, r_{2,1})$, $(r_{1,1}, r_{2,0})$, and $(r_{1,1}, r_{2,1})$.\n\n| $p(y_1, y_2 | x)$ | $(r_{1,0}, r_{2,0})$ | $(r_{1,0}, r_{2,1})$ | $(r_{1,1}, r_{2,0})$ | $(r_{1,1}, r_{2,1})$ |\n|:-----------------:|:--------------------:|:--------------------:|:--------------------:|:--------------------:|\n|     $x = s_0$     |         0.72         |         0.18         |         0.02         |         0.08         |\n|     $x = s_1$     |         0.08         |         0.02         |         0.18         |         0.72         |\n|     $x = s_2$     |         0.40         |         0.10         |         0.10         |         0.40         |\n\nA broadcast channel is defined as degraded if one receiver's observation is a noisy version of the other's, meaning the random variables form a Markov chain $X \\to Y_1 \\to Y_2$ or $X \\to Y_2 \\to Y_1$. Based on the provided channel statistics, which of the following statements is true?\n\nA. The broadcast channel is degraded because the outputs form the Markov chain $X \\to Y_1 \\to Y_2$.\n\nB. The broadcast channel is degraded because the outputs form the Markov chain $X \\to Y_2 \\to Y_1$.\n\nC. The broadcast channel is not degraded.\n\nD. The broadcast channel is degraded because the outputs form both Markov chains $X \\to Y_1 \\to Y_2$ and $X \\to Y_2 \\to Y_1$.\n\nE. There is not enough information to determine if the channel is degraded.",
            "solution": "A broadcast channel is degraded in the direction $X \\to Y_{1} \\to Y_{2}$ if there exists a stochastic mapping $q(y_{2}\\mid y_{1})$ independent of $x$ such that $p(y_{1},y_{2}\\mid x)=p(y_{1}\\mid x)q(y_{2}\\mid y_{1})$. Equivalently, $p(y_{2}\\mid y_{1},x)=q(y_{2}\\mid y_{1})$ must be independent of $x$. We test this by computing $p(y_{2}\\mid y_{1},x)$ for each $x$ and $y_{1}$.\n\nFirst compute the marginals $p(y_{1}\\mid x)$ from the table:\n$$\n\\begin{aligned}\np(r_{1,0}\\mid s_{0})&=0.72+0.18=0.90, & p(r_{1,1}\\mid s_{0})&=0.02+0.08=0.10,\\\\\np(r_{1,0}\\mid s_{1})&=0.08+0.02=0.10, & p(r_{1,1}\\mid s_{1})&=0.18+0.72=0.90,\\\\\np(r_{1,0}\\mid s_{2})&=0.40+0.10=0.50, & p(r_{1,1}\\mid s_{2})&=0.10+0.40=0.50.\n\\end{aligned}\n$$\nThen compute $p(y_{2}\\mid y_{1},x)=\\frac{p(y_{1},y_{2}\\mid x)}{p(y_{1}\\mid x)}$.\n\nFor $y_{1}=r_{1,0}$:\n$$\n\\begin{aligned}\np(r_{2,0}\\mid r_{1,0},s_{0})&=\\frac{0.72}{0.90}=0.8, & p(r_{2,1}\\mid r_{1,0},s_{0})&=\\frac{0.18}{0.90}=0.2,\\\\\np(r_{2,0}\\mid r_{1,0},s_{1})&=\\frac{0.08}{0.10}=0.8, & p(r_{2,1}\\mid r_{1,0},s_{1})&=\\frac{0.02}{0.10}=0.2,\\\\\np(r_{2,0}\\mid r_{1,0},s_{2})&=\\frac{0.40}{0.50}=0.8, & p(r_{2,1}\\mid r_{1,0},s_{2})&=\\frac{0.10}{0.50}=0.2.\n\\end{aligned}\n$$\nFor $y_{1}=r_{1,1}$:\n$$\n\\begin{aligned}\np(r_{2,0}\\mid r_{1,1},s_{0})&=\\frac{0.02}{0.10}=0.2, & p(r_{2,1}\\mid r_{1,1},s_{0})&=\\frac{0.08}{0.10}=0.8,\\\\\np(r_{2,0}\\mid r_{1,1},s_{1})&=\\frac{0.18}{0.90}=0.2, & p(r_{2,1}\\mid r_{1,1},s_{1})&=\\frac{0.72}{0.90}=0.8,\\\\\np(r_{2,0}\\mid r_{1,1},s_{2})&=\\frac{0.10}{0.50}=0.2, & p(r_{2,1}\\mid r_{1,1},s_{2})&=\\frac{0.40}{0.50}=0.8.\n\\end{aligned}\n$$\nThese conditional probabilities are independent of $x$, so there exists a channel $q(y_{2}\\mid y_{1})$ given (in the order $r_{2,0}, r_{2,1}$) by\n$$\nq(y_{2}\\mid y_{1})=\n\\begin{pmatrix}\n0.8 & 0.2\\\\\n0.2 & 0.8\n\\end{pmatrix},\n$$\nestablishing the Markov chain $X \\to Y_{1} \\to Y_{2}$.\n\nTo test the reverse direction $X \\to Y_{2} \\to Y_{1}$, we check whether $p(y_{1}\\mid y_{2},x)$ is independent of $x$. Compute $p(y_{2}\\mid x)$ first:\n$$\n\\begin{aligned}\np(r_{2,0}\\mid s_{0})&=0.72+0.02=0.74, & p(r_{2,1}\\mid s_{0})&=0.18+0.08=0.26,\\\\\np(r_{2,0}\\mid s_{1})&=0.08+0.18=0.26, & p(r_{2,1}\\mid s_{1})&=0.02+0.72=0.74,\\\\\np(r_{2,0}\\mid s_{2})&=0.40+0.10=0.50, & p(r_{2,1}\\mid s_{2})&=0.10+0.40=0.50.\n\\end{aligned}\n$$\nThen, for $y_{2}=r_{2,0}$ and $y_{1}=r_{1,0}$,\n$$\np(r_{1,0}\\mid r_{2,0},s_{0})=\\frac{0.72}{0.74}=\\frac{36}{37},\\qquad\np(r_{1,0}\\mid r_{2,0},s_{1})=\\frac{0.08}{0.26}=\\frac{4}{13}.\n$$\nSince $\\frac{36}{37}\\neq \\frac{4}{13}$, $p(y_{1}\\mid y_{2},x)$ depends on $x$, so no $q'(y_{1}\\mid y_{2})$ independent of $x$ exists. Therefore, the reverse Markov chain $X \\to Y_{2} \\to Y_{1}$ does not hold.\n\nConsequently, the channel is degraded only in the direction $X \\to Y_{1} \\to Y_{2}$.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Degraded broadcast channels often arise naturally when communication systems are physically cascaded, with one receiver's signal being a further processed version of another's. This practice moves from analysis to synthesis, challenging you to construct the complete transition probability matrix for a system built from two distinct channels in series. By combining a Binary Symmetric Channel with a Z-channel, you will see how the Markov property $X \\to Y_1 \\to Y_2$ is built into the channel's mathematical description from the ground up. ",
            "id": "1617331",
            "problem": "Consider a communication system consisting of two channels connected in series, forming a degraded broadcast channel. The overall input to the system is a binary variable $X \\in \\{0, 1\\}$.\n\nThe first channel is a Binary Symmetric Channel (BSC) with crossover probability $p$. It takes $X$ as input and produces an intermediate output $Y_1 \\in \\{0, 1\\}$. This means the probability of a bit being flipped is $p$, i.e., $P(Y_1 \\neq x | X=x) = p$.\n\nThe second channel is a Z-channel. It takes the intermediate output $Y_1$ as its input and produces the final output $Y_2 \\in \\{0, 1\\}$. In the Z-channel, the input '0' is always transmitted correctly to the output as '0', while the input '1' is incorrectly transmitted as '0' with probability $q$.\n\nThis cascaded system can be viewed as a single broadcast channel with input $X$ and a pair of outputs $(Y_1, Y_2)$. Your task is to determine the full transition probability matrix for this broadcast channel, which represents the conditional probability distribution $p(y_1, y_2 | x)$.\n\nProvide your answer as a $2 \\times 4$ matrix. The two rows should correspond to the inputs $x=0$ and $x=1$, respectively. The four columns should correspond to the output pairs $(y_1, y_2)$ in the order $(0,0), (0,1), (1,0), (1,1)$, respectively.",
            "solution": "Let $X \\in \\{0,1\\}$ be the input, $Y_{1} \\in \\{0,1\\}$ the output of the first channel (a BSC with crossover probability $p$), and $Y_{2} \\in \\{0,1\\}$ the output of the second channel (a Z-channel with crossover parameter $q$). The cascade forms the Markov chain $X \\to Y_{1} \\to Y_{2}$, so by the chain rule and conditional independence,\n$$\np(y_{1},y_{2}\\mid x)=p(y_{1}\\mid x)\\,p(y_{2}\\mid y_{1}).\n$$\nFor the BSC, the transition probabilities are\n$$\np(y_{1}=x\\mid x)=1-p,\\qquad p(y_{1}\\neq x\\mid x)=p.\n$$\nThus,\n$$\np(Y_{1}=0\\mid X=0)=1-p,\\quad p(Y_{1}=1\\mid X=0)=p,\n$$\n$$\np(Y_{1}=0\\mid X=1)=p,\\quad p(Y_{1}=1\\mid X=1)=1-p.\n$$\nFor the Z-channel from $Y_{1}$ to $Y_{2}$, by definition,\n$$\np(Y_{2}=0\\mid Y_{1}=0)=1,\\quad p(Y_{2}=1\\mid Y_{1}=0)=0,\n$$\n$$\np(Y_{2}=0\\mid Y_{1}=1)=q,\\quad p(Y_{2}=1\\mid Y_{1}=1)=1-q.\n$$\nTherefore, for each $x\\in\\{0,1\\}$ and $(y_{1},y_{2})\\in\\{(0,0),(0,1),(1,0),(1,1)\\}$,\n$$\np(0,0\\mid x)=p(Y_{1}=0\\mid x)\\cdot 1,\\quad\np(0,1\\mid x)=p(Y_{1}=0\\mid x)\\cdot 0=0,\n$$\n$$\np(1,0\\mid x)=p(Y_{1}=1\\mid x)\\cdot q,\\quad\np(1,1\\mid x)=p(Y_{1}=1\\mid x)\\cdot (1-q).\n$$\nSubstituting the BSC terms for each input value yields the $2\\times 4$ transition matrix with rows for $x=0$ and $x=1$, and columns ordered as $(0,0),(0,1),(1,0),(1,1)$:\nfor $x=0$,\n$$\n\\big(1-p,\\ 0,\\ pq,\\ p(1-q)\\big),\n$$\nfor $x=1$,\n$$\n\\big(p,\\ 0,\\ (1-p)q,\\ (1-p)(1-q)\\big).\n$$\nEach row sums to $1$, as required:\n$$\n(1-p)+pq+p(1-q)=1,\\qquad p+(1-p)q+(1-p)(1-q)=1.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}\n1-p & 0 & pq & p(1-q)\\\\\np & 0 & (1-p)q & (1-p)(1-q)\n\\end{pmatrix}}$$"
        },
        {
            "introduction": "Understanding the structure of a channel is crucial because it directly impacts its performance limitations and capabilities. This final practice demonstrates the practical utility of identifying a degraded channel by tasking you with calculating its symmetric capacityâ€”the maximum rate at which a common message can be sent to both receivers. You will see how the data processing inequality, a direct consequence of the channel's degraded nature, simplifies the optimization problem and leads to a clear, actionable result. ",
            "id": "1617275",
            "problem": "A central command station is transmitting binary data to two receiving agents, Agent 1 and Agent 2. The transmitted signal is represented by a random variable $X \\in \\{0, 1\\}$.\n\nAgent 1 receives a signal $Y_1 \\in \\{0, 1\\}$, where the communication link between the station and Agent 1 is a Binary Symmetric Channel (BSC) with a crossover probability of $p_1$.\n\nAgent 2 does not receive the signal directly from the station. Instead, it receives a relayed version of Agent 1's signal. The link between Agent 1 and Agent 2 is also a BSC, with a crossover probability of $p_2$. The signal received by Agent 2 is denoted by $Y_2 \\in \\{0, 1\\}$.\n\nThis hierarchical communication structure forms a degraded broadcast channel, as the random variables form the Markov chain $X \\to Y_1 \\to Y_2$. The station's objective is to broadcast a common message to both agents at the same rate $R$.\n\nDetermine the symmetric capacity, $C_s$, of this channel, which represents the maximum possible value for this common rate $R$. Express your final answer as a closed-form analytic expression in terms of the parameters $p_1$ and $p_2$. The information rate must be measured in bits per channel use, which implies the use of base-2 logarithms.",
            "solution": "Let $X \\in \\{0,1\\}$ be the transmitted bit. The links $X \\to Y_{1}$ and $Y_{1} \\to Y_{2}$ are binary symmetric channels (BSC) with crossover probabilities $p_{1}$ and $p_{2}$, respectively. Introduce independent noises $Z_{1} \\sim \\mathrm{Bern}(p_{1})$ and $Z_{2} \\sim \\mathrm{Bern}(p_{2})$ so that\n$$\nY_{1} = X \\oplus Z_{1}, \\quad Y_{2} = Y_{1} \\oplus Z_{2}.\n$$\nThen\n$$\nY_{2} = X \\oplus (Z_{1} \\oplus Z_{2}),\n$$\nand the equivalent noise $Z \\triangleq Z_{1} \\oplus Z_{2}$ is Bernoulli with\n$$\np \\triangleq \\Pr(Z=1) = \\Pr(Z_{1}=1,Z_{2}=0)+\\Pr(Z_{1}=0,Z_{2}=1) = p_{1}(1-p_{2})+(1-p_{1})p_{2} = p_{1}+p_{2}-2p_{1}p_{2}.\n$$\nHence, the effective channel $X \\to Y_{2}$ is a BSC with crossover probability $p = p_{1}+p_{2}-2p_{1}p_{2}$.\n\nFor broadcasting a common message at rate $R$ to both receivers, any achievable $R$ must satisfy\n$$\nR \\leq I(X;Y_{1}) \\quad \\text{and} \\quad R \\leq I(X;Y_{2})\n$$\nfor the chosen input distribution $P_{X}$. Therefore, the maximum common rate is\n$$\nC_{s} = \\max_{P_{X}} \\min\\{I(X;Y_{1}),\\, I(X;Y_{2})\\}.\n$$\nBecause $X \\to Y_{1} \\to Y_{2}$ forms a Markov chain, the data processing inequality gives $I(X;Y_{2}) \\leq I(X;Y_{1})$ for any $P_{X}$, so\n$$\nC_{s} = \\max_{P_{X}} I(X;Y_{2}).\n$$\nThus, $C_{s}$ equals the capacity of the effective BSC from $X$ to $Y_{2}$ with crossover probability $p$. For a BSC, by channel symmetry and concavity of mutual information in $P_{X}$, the maximizing input is uniform, $P_{X}(0)=P_{X}(1)=\\frac{1}{2}$. With the uniform input, the output $Y_{2}$ is also uniform, so $H(Y_{2})=1$, and the conditional entropy is $H(Y_{2}\\mid X)=H(p)$, where\n$$\nH(p) = -p \\log_{2}(p) - (1-p)\\log_{2}(1-p).\n$$\nTherefore,\n$$\nC_{s} = I(X;Y_{2}) = H(Y_{2}) - H(Y_{2}\\mid X) = 1 - H(p).\n$$\nSubstituting $p = p_{1}+p_{2}-2p_{1}p_{2}$ gives\n$$\nC_{s} = 1 + \\left(p_{1}+p_{2}-2p_{1}p_{2}\\right)\\log_{2}\\!\\left(p_{1}+p_{2}-2p_{1}p_{2}\\right) + \\left(1 - p_{1}-p_{2}+2p_{1}p_{2}\\right)\\log_{2}\\!\\left(1 - p_{1}-p_{2}+2p_{1}p_{2}\\right).\n$$\nThis is in bits per channel use, as required.",
            "answer": "$$\\boxed{1+\\left(p_{1}+p_{2}-2p_{1}p_{2}\\right)\\log_{2}\\!\\left(p_{1}+p_{2}-2p_{1}p_{2}\\right)+\\left(1-p_{1}-p_{2}+2p_{1}p_{2}\\right)\\log_{2}\\!\\left(1-p_{1}-p_{2}+2p_{1}p_{2}\\right)}$$"
        }
    ]
}