{
    "hands_on_practices": [
        {
            "introduction": "The source-channel separation theorem suggests we can design source codes and channel codes independently. However, this principle relies on idealized assumptions, such as infinitely long codes. This first practice problem demonstrates what happens in a more practical scenario when a highly efficient but variable-length source code, like a Huffman code, is directly transmitted over a noisy channel. By tracing the effect of a single bit error, you will witness the phenomenon of catastrophic error propagation, a critical concept that motivates the need for joint source-channel coding strategies. ",
            "id": "1635279",
            "problem": "An engineer is developing a data compression scheme for a sensor that outputs one of four possible symbols: $\\{S_1, S_2, S_3, S_4\\}$. The observed probabilities of these symbols are $P(S_1) = 0.5$, $P(S_2) = 0.25$, $P(S_3) = 0.125$, and $P(S_4) = 0.125$. To minimize the average data rate, an optimal prefix-free binary code is generated. The resulting codebook is as follows:\n- $C(S_1) = 0$\n- $C(S_2) = 10$\n- $C(S_3) = 110$\n- $C(S_4) = 111$\n\nA specific sequence of symbols, $S_2, S_1, S_4, S_3, S_1$, is encoded into a single binary stream for transmission. During transmission over a noisy channel, modeled as a Binary Symmetric Channel (BSC), a single bit error occurs, flipping the 4th bit of the concatenated binary stream.\n\nA receiver on the other end attempts to decode the corrupted bitstream. The decoder operates by reading bits from the start of the stream until a sequence of bits matches a valid codeword in the codebook. Once a match is found, the corresponding symbol is recorded, and the process repeats on the remainder of the bitstream. This continues until all bits have been consumed.\n\nWhich of the following represents the sequence of symbols decoded by the receiver from the corrupted bitstream?\n\nA. $S_2, S_1, S_4, S_3, S_1$\n\nB. $S_2, S_1, S_1, S_4, S_2, S_1$\n\nC. $S_2, S_1, S_1, S_4, S_2$\n\nD. $S_2, S_1, S_1, S_1, S_1, S_2$\n\nE. The stream is undecodable.",
            "solution": "The codebook is prefix-free with mappings $C(S_{1})=0$, $C(S_{2})=10$, $C(S_{3})=110$, $C(S_{4})=111$. Encoding the original sequence $S_{2},S_{1},S_{4},S_{3},S_{1}$ yields the concatenation\n$$\nC(S_{2})\\,C(S_{1})\\,C(S_{4})\\,C(S_{3})\\,C(S_{1})=10\\,0\\,111\\,110\\,0,\n$$\nwhich is the bitstring $1001111100$. Indexing bits as $b_{1}b_{2}\\dots b_{10}=1001111100$ gives $b_{4}=1$. A single bit flip at the fourth bit over the BSC produces the corrupted stream $b_{1}b_{2}b_{3}b_{4}'b_{5}\\dots b_{10}=1000111100$ with $b_{4}'=1-b_{4}=0$.\n\nDecoding proceeds greedily from the start, matching the shortest prefix that is a valid codeword and consuming it:\n- The first two bits are $10$, which match $C(S_{2})$, so the first decoded symbol is $S_{2}$. The remaining bits are $00111100$.\n- The next bit is $0$, which matches $C(S_{1})$, so decode $S_{1}$. The remaining bits are $0111100$.\n- The next bit is $0$ again, which matches $C(S_{1})$, so decode another $S_{1}$. The remaining bits are $111100$.\n- The next three bits are $111$, which match $C(S_{4})$, so decode $S_{4}$. The remaining bits are $100$.\n- The next two bits are $10$, which match $C(S_{2})$, so decode $S_{2}$. The remaining bit is $0$.\n- The final bit is $0$, which matches $C(S_{1})$, so decode $S_{1}$.\n\nThus the receiver decodes the sequence $S_{2}, S_{1}, S_{1}, S_{4}, S_{2}, S_{1}$, which corresponds to option B.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Having seen the potential pitfalls of a naive separation-based approach, we now turn to a constructive solution. This exercise introduces optimal index assignment, a fundamental technique in joint source-channel coding where the mapping from source symbols to channel codewords is carefully chosen. You will work to minimize end-to-end distortion by considering both the source's non-uniform statistics and the channel's unique asymmetric error probabilities. This practice moves from identifying a problem to actively designing a system that is inherently more robust by aligning the source and channel characteristics. ",
            "id": "1635292",
            "problem": "An autonomous environmental sensor monitors water quality and reports one of three possible states: 'Normal' (N), 'Warning' (W), or 'Critical' (C). Based on historical data, the probabilities of these states are $P(N) = 0.70$, $P(W) = 0.20$, and $P(C) = 0.10$. To transmit its findings, the sensor first maps each state to a unique binary codeword from the set of available codewords $C = \\{00, 01, 10\\}$.\n\nThe encoded bits are then transmitted sequentially over a memoryless Binary Asymmetric Channel (BAC). The channel is characterized by the following bit-flip probabilities: the probability of a transmitted '0' being received as a '1' is $p_{1|0} = 0.05$, and the probability of a transmitted '1' being received as a '0' is $p_{0|1} = 0.20$.\n\nThe performance of this communication system is evaluated by the average end-to-end distortion. The distortion for a single transmission is defined as the Hamming distance between the transmitted codeword and the received 2-bit word (i.e., the number of bit positions in which they differ). Your task is to find the optimal assignment of codewords from the set $C$ to the source states {N, W, C} that minimizes this average distortion.\n\nCalculate the value of this minimum possible average distortion. Round your final answer to three significant figures.",
            "solution": "Let the source states be $S \\in \\{N, W, C\\}$ with probabilities $P(N)=0.70$, $P(W)=0.20$, and $P(C)=0.10$. Each state is mapped to a length-$2$ binary codeword from $C=\\{00,01,10\\}$. Transmission occurs over a memoryless Binary Asymmetric Channel with bit-flip probabilities $p_{1|0}=0.05$ and $p_{0|1}=0.20$. The single-transmission distortion is the Hamming distance between the transmitted and received $2$-bit words.\n\nFor a single bit $b \\in \\{0,1\\}$ sent through the BAC, the expected Hamming contribution is the flip probability:\n$$\n\\mathbb{E}[d_{b} \\mid b=0] = p_{1|0}, \\quad \\mathbb{E}[d_{b} \\mid b=1] = p_{0|1}.\n$$\nBy memorylessness and additivity of Hamming distance across bit positions, for a length-$2$ codeword $b_{1}b_{2}$,\n$$\n\\mathbb{E}[d \\mid b_{1}b_{2}] = \\sum_{i=1}^{2} \\mathbb{E}[d_{b_{i}} \\mid b_{i}] .\n$$\nTherefore, for the available codewords,\n$$\n\\mathbb{E}[d \\mid 00] = 2 p_{1|0}, \\quad \\mathbb{E}[d \\mid 01] = \\mathbb{E}[d \\mid 10] = p_{1|0} + p_{0|1}.\n$$\nDefine $d_{00} := 2 p_{1|0}$ and $d_{01} = d_{10} := p_{1|0} + p_{0|1}$. The average distortion for an assignment $c(\\cdot)$ of states to codewords is\n$$\nD = \\sum_{s \\in \\{N,W,C\\}} P(s) \\, \\mathbb{E}[d \\mid c(s)].\n$$\nSince $d_{00} < d_{01}$, to minimize $D$ one should assign the most probable state to $00$. Hence, the optimal mapping is $c(N)=00$ and $c(W), c(C) \\in \\{01,10\\}$ in any order. The minimum average distortion is\n$$\nD_{\\min} = P(N) \\cdot 2 p_{1|0} + \\left(P(W)+P(C)\\right) \\cdot (p_{1|0}+p_{0|1}).\n$$\nSubstituting the given values,\n$$\nD_{\\min} = 0.70 \\cdot 2 \\cdot 0.05 + 0.30 \\cdot (0.05 + 0.20) = 0.07 + 0.075 = 0.145.\n$$\nRounded to three significant figures, the minimum possible average distortion is $0.145$.",
            "answer": "$$\\boxed{0.145}$$"
        },
        {
            "introduction": "In a real-world system, performance is not just about avoiding catastrophic failure but also about maintaining efficiency when conditions change. This problem explores the performance of a complete communication chain (source coding followed by channel coding) when there is a mismatch between the source statistics it was designed for and the statistics of the data it actually transmits. By calculating the resulting degradation in performance, you will gain a deeper appreciation for how tightly coupled the components of a communication system are. This exercise underscores the core philosophy of joint source-channel coding: achieving optimal performance requires a holistic design that considers all parts of the system in concert. ",
            "id": "1635330",
            "problem": "A deep-space probe is equipped with an imaging system designed to transmit grayscale pictures of nebulae and star fields. The image data is simplified and modeled as a memoryless source that generates pixels from a set of four possible intensity levels: $S = \\{s_0, s_1, s_2, s_3\\}$. The system was specifically designed for the statistical properties of typical deep-space images, where darker pixels are more common. The probability distribution for these images, let's call it $P_{DS}$, is given by:\n$P_{DS}(s_0) = 0.5$\n$P_{DS}(s_1) = 0.25$\n$P_{DS}(s_2) = 0.125$\n$P_{DS}(s_3) = 0.125$\n\nThe communication system employs the following scheme:\n1.  **Source Coding:** A binary Huffman code is constructed based on the distribution $P_{DS}$. This code assigns a unique binary codeword to each intensity level.\n2.  **Channel Coding:** Each bit from the Huffman encoder is individually protected using a repetition code of length $n=3$.\n3.  **Transmission:** The encoded bits are transmitted over a Binary Symmetric Channel (BSC) with a bit-flip probability of $p = 0.01$.\n4.  **Decoding:** At the receiver, each 3-bit block is decoded using a majority-logic decoder. The resulting stream of bits is then fed to the Huffman decoder.\n\nDuring a calibration procedure, the probe is commanded to take a picture of a uniformly illuminated test pattern. The pixel intensity distribution for this calibration image, denoted $P_{U}$, is uniform:\n$P_{U}(s_i) = 0.25$ for $i \\in \\{0, 1, 2, 3\\}$.\n\nThe system, however, continues to use the same Huffman code designed for $P_{DS}$. Your task is to analyze the performance degradation caused by this mismatch. Specifically, calculate the ratio $\\mathcal{R} = E_U / E_{DS}$, where $E_U$ is the expected number of bit errors per source symbol at the output of the majority-logic decoder when transmitting the uniform image, and $E_{DS}$ is the corresponding value for the designed deep-space image.\n\nExpress your final answer for the ratio $\\mathcal{R}$ as a real number rounded to three significant figures.",
            "solution": "The majority-logic decoder for a repetition code of length $n=3$ over a Binary Symmetric Channel with crossover probability $p$ produces a bit error if and only if at least two of the three transmitted bits are flipped. The per-bit error probability after majority decoding is\n$$\np_{\\text{maj}}=\\sum_{k=2}^{3}\\binom{3}{k}p^{k}(1-p)^{3-k}\n=\\binom{3}{2}p^{2}(1-p)+\\binom{3}{3}p^{3}\n=3p^{2}(1-p)+p^{3}=3p^{2}-2p^{3}.\n$$\nEach source symbol $s_{i}$ is first Huffman-encoded into a binary codeword of length $L(s_{i})$ (bits), then each bit is repeated and decoded bitwise by majority logic. Because the channel is memoryless and decoding is performed independently for each bit, every decoded bit is wrong with probability $p_{\\text{maj}}$, independent of the bit value and of the source symbol. Therefore, the expected number of bit errors per source symbol equals the expected Huffman codeword length times $p_{\\text{maj}}$:\n$$\nE = \\mathbb{E}[L]\\; p_{\\text{maj}}.\n$$\nThe Huffman code is constructed for $P_{DS}$ with probabilities $0.5, 0.25, 0.125, 0.125$. Combining the two least likely symbols of probabilities $0.125$ and $0.125$ yields a node of probability $0.25$. Then combining this node with the $0.25$ symbol yields $0.5$, and finally with the $0.5$ symbol yields the root. The resulting optimal codeword lengths are\n$$\nL(s_{0})=1,\\quad L(s_{1})=2,\\quad L(s_{2})=3,\\quad L(s_{3})=3.\n$$\nHence the average codeword length under $P_{DS}$ is\n$$\n\\mathbb{E}_{DS}[L]=0.5\\cdot 1+0.25\\cdot 2+0.125\\cdot 3+0.125\\cdot 3=\\frac{7}{4}=1.75,\n$$\nand under the uniform distribution $P_{U}$,\n$$\n\\mathbb{E}_{U}[L]=\\frac{1}{4}(1+2+3+3)=\\frac{9}{4}=2.25.\n$$\nThus the expected number of bit errors per source symbol for distribution $X\\in\\{DS,U\\}$ is\n$$\nE_{X}=\\mathbb{E}_{X}[L]\\; p_{\\text{maj}}.\n$$\nThe desired ratio is\n$$\n\\mathcal{R}=\\frac{E_{U}}{E_{DS}}=\\frac{\\mathbb{E}_{U}[L]}{\\mathbb{E}_{DS}[L]}=\\frac{\\frac{9}{4}}{\\frac{7}{4}}=\\frac{9}{7}\\approx 1.285714\\ldots,\n$$\nwhich rounded to three significant figures is $1.29$.",
            "answer": "$$\\boxed{1.29}$$"
        }
    ]
}