{
    "hands_on_practices": [
        {
            "introduction": "To begin our practical exploration, we will examine how Kolmogorov complexity behaves under simple, computable transformations. This exercise  uses data duplication, transforming a string $x$ into $xx$, as a model for redundancy. By determining the complexity of the new string, you will practice a fundamental technique: constructing a short program that leverages an existing description, illustrating that simple post-processing does not significantly increase algorithmic complexity.",
            "id": "1429018",
            "problem": "In the field of algorithmic information theory, a subfield of theoretical computer science, we quantify the complexity of an object by the length of its shortest possible description. For a finite binary string $x$, its Kolmogorov complexity, denoted $K(x)$, is defined with respect to a fixed universal Turing Machine, $U$. It is the length (in bits) of the shortest program $p$ that, when provided as input to $U$, causes $U$ to output the string $x$ and then halt. Formally, $K(x) = \\min\\{|p| : U(p)=x\\}$. While the exact value of $K(x)$ depends on the chosen universal machine $U$, key relationships in complexity theory, such as upper and lower bounds, hold up to an additive constant.\n\nConsider a data processing task where a binary string $x$ is concatenated with itself to form a new string $xx$. This is a simple model for data redundancy. We are interested in the complexity of this new, longer string.\n\nWhich of the following inequalities represents the tightest general upper bound on the Kolmogorov complexity of the string $xx$ for any binary string $x$? In these expressions, $c$ represents a positive constant whose value depends only on the choice of the universal Turing Machine $U$ and not on the string $x$ or its properties.\n\nA. $K(xx) \\le K(x) + c$\n\nB. $K(xx) \\le 2K(x) + c$\n\nC. $K(xx) \\le K(x)^2 + c$\n\nD. $K(xx) \\le K(x) + c \\log_2(|x|)$\n\nE. $K(xx) \\le |x| + c$",
            "solution": "Let $U$ be a fixed universal Turing machine and $K(\\cdot)$ the associated (prefix-free) Kolmogorov complexity. For any total computable function $f$, there exists a constant $c_{f}$ (depending only on $f$ and $U$) such that\n$$\nK(f(x)) \\leq K(x) + c_{f}.\n$$\nDerivation of this standard upper bound: let $p$ be a shortest $U$-program for $x$, so $|p| = K(x)$ and $U(p)=x$. Fix a program $r_{f}$ of constant length $|r_{f}|=c_{f}$ that, given a description of some program $p$, simulates $U(p)$ to obtain $x$, then computes and outputs $f(x)$. Consider the concatenated code $r_{f}p$ (well-formed because we use prefix-free descriptions), which has length $|r_{f}p| = |r_{f}| + |p| = c_{f} + K(x)$ and causes $U$ to output $f(x)$. Therefore\n$$\nK(f(x)) \\leq |r_{f}p| = K(x) + c_{f}.\n$$\n\nApply this with $f(y)=yy$ (duplicate the string). Since $f$ is total computable, there exists a constant $c$ such that\n$$\nK(xx) \\leq K(x) + c.\n$$\n\nThis bound is essentially tight up to an additive constant: define $g(z)$ to be the function that returns the first half of $z$. Then $g$ is total computable and $g(xx)=x$, so by the same reasoning there exists $c'$ with\n$$\nK(x) \\leq K(xx) + c'.\n$$\nHence $K(xx) \\geq K(x) - c'$, which combined with the upper bound shows $K(xx) = K(x) \\pm O(1)$ in general. Among the given options, this makes option A the tightest general upper bound; options B, C, D, and E are looser since they exceed $K(x)+c$ by, respectively, an additional $K(x)$ term, a quadratic term, a growing $\\log_{2}(|x|)$ term, or a replacement of $K(x)$ by the generally larger $|x|$.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Having seen how to describe structured data compactly, we now ask a profound question: are most strings simple or complex? This practice  introduces a powerful non-constructive method known as a counting argument. By comparing the vast number of possible strings of a given length to the limited number of short descriptive programs, you will uncover the fundamental principle that the overwhelming majority of strings cannot be significantly compressed, meaning they are algorithmically random.",
            "id": "1635770",
            "problem": "In the theoretical study of data compression, we analyze the properties of binary strings. Consider the set of all possible binary strings of length $n=128$. The Kolmogorov complexity of a string $s$, denoted $K(s)$, is defined as the length in bits of the shortest computer program that can generate $s$ as output and then halt. This value represents the ultimate limit of lossless compression for that string.\n\nWe can define a string $s$ as \"compressible\" if its Kolmogorov complexity is smaller than its length. For this problem, we will define a string $s$ of length $n=128$ as \"highly compressible\" if its complexity $K(s)$ satisfies the inequality $K(s) \\leq 118$.\n\nBased on the founding principle that for any given integer length $k$, there can be at most $2^k$ distinct programs of that length, calculate the minimum possible fraction of binary strings of length 128 that are *not* highly compressible. Express your answer as a decimal rounded to five significant figures.",
            "solution": "The goal is to find the minimum fraction of binary strings of length $n=128$ that are not \"highly compressible\". A string $s$ is defined as highly compressible if its Kolmogorov complexity $K(s) \\leq 118$. Therefore, a string is not highly compressible if $K(s) > 118$.\n\nFirst, let's determine the total number of distinct binary strings of length $n=128$. Since each of the 128 positions in the string can be either a 0 or a 1, the total number of possible strings is $2^{128}$.\n\nNext, we need to find an upper bound on the number of strings that are highly compressible. A string $s$ is highly compressible if $K(s) \\leq 118$. This means there exists a program of length $k \\leq 118$ bits that generates $s$. We can count the total number of such programs.\n\nA program is itself a binary string. The number of possible programs of a specific length $k$ is $2^k$. To find the total number of programs with a length less than or equal to 118, we sum the number of programs for each possible length from $k=0$ to $k=118$.\nLet $N_{programs}$ be the total number of programs with length $k \\leq 118$.\n$$ N_{programs} = \\sum_{k=0}^{118} 2^k $$\nThis is a geometric series. The sum of a geometric series $\\sum_{i=0}^{m} r^i$ is given by the formula $\\frac{r^{m+1}-1}{r-1}$. For our case, $r=2$ and $m=118$.\n$$ N_{programs} = \\frac{2^{118+1}-1}{2-1} = 2^{119} - 1 $$\nSo, there are at most $2^{119} - 1$ distinct programs with a length of 118 bits or less.\n\nEach of these short programs can generate at most one unique output string. Therefore, the number of strings that can be generated by these programs is also at most $2^{119} - 1$. This gives us an upper bound on the number of highly compressible strings. Let $N_{comp}$ be the number of highly compressible strings.\n$$ N_{comp} \\leq 2^{119} - 1 $$\nThe maximum possible number of highly compressible strings is $2^{119} - 1$.\n\nThe problem asks for the minimum fraction of strings that are *not* highly compressible. Let $N_{not\\_comp}$ be the number of strings that are not highly compressible.\n$$ N_{not\\_comp} = (\\text{Total number of strings}) - N_{comp} $$\nTo find the minimum possible value of $N_{not\\_comp}$, we must subtract the maximum possible value of $N_{comp}$.\n$$ N_{not\\_comp, min} = 2^{128} - (2^{119} - 1) $$\nThe minimum fraction, $f_{min}$, is this minimum number divided by the total number of strings.\n$$ f_{min} = \\frac{N_{not\\_comp, min}}{2^{128}} = \\frac{2^{128} - (2^{119} - 1)}{2^{128}} $$\nWe can split the fraction:\n$$ f_{min} = \\frac{2^{128}}{2^{128}} - \\frac{2^{119}}{2^{128}} + \\frac{1}{2^{128}} $$\n$$ f_{min} = 1 - 2^{119-128} + 2^{-128} $$\n$$ f_{min} = 1 - 2^{-9} + 2^{-128} $$\nNow we evaluate this expression numerically.\n$$ 2^9 = 512 $$\n$$ 2^{-9} = \\frac{1}{512} = 0.001953125 $$\nThe term $2^{-128}$ is extremely small (approximately $2.9 \\times 10^{-39}$) and will not affect the first several significant figures of our result. So we have:\n$$ f_{min} \\approx 1 - 0.001953125 = 0.998046875 $$\nFinally, we need to round this result to five significant figures. The first five significant figures are 9, 9, 8, 0, and 4. The sixth digit is 6, which is 5 or greater, so we round up the fifth significant figure (4) to 5.\n$$ f_{min} \\approx 0.99805 $$\nThis result shows that an overwhelming majority of strings cannot be significantly compressed, as their shortest description is nearly as long as the strings themselves.",
            "answer": "$$\\boxed{0.99805}$$"
        },
        {
            "introduction": "Now, let's apply our understanding to estimate the complexity of a structured object from graph theory. While an adjacency matrix for a graph can be a very large binary string, its true algorithmic complexity is tied to its underlying structure, not its size. This exercise  challenges you to determine the Kolmogorov complexity of a simple path graph, forcing you to think like a programmer: what is the minimal set of instructions needed to generate this object from scratch?",
            "id": "1635719",
            "problem": "In algorithmic information theory, the Kolmogorov complexity of an object, such as a piece of text or an image, is a measure of its computational resources needed to specify it. Formally, the Kolmogorov complexity of a finite binary string $s$, denoted $K(s)$, is the length of the shortest computer program (written in a fixed universal programming language) that outputs a string $s$ and then halts. We are interested in estimating this complexity for a highly structured object from graph theory.\n\nConsider a simple path graph, $P_n$, defined on a set of $n$ vertices labeled $v_1, v_2, \\dots, v_n$. The edges of this graph are precisely the set $\\{(v_i, v_{i+1}) \\mid i = 1, 2, \\dots, n-1\\}$. The structure of this graph can be fully described by its $n \\times n$ adjacency matrix, $A$, where the entry $A_{ij}$ is 1 if an edge exists between vertices $v_i$ and $v_j$, and 0 otherwise.\n\nTo analyze the complexity of this matrix, we represent it as a single binary string, $s_A$, of length $n^2$. This string is formed by concatenating the rows of the matrix in order, from row 1 to row $n$.\n\nYour task is to provide a simple, closed-form analytic expression that serves as a tight upper bound for the Kolmogorov complexity $K(s_A)$ for large $n$. Your answer should capture the dominant asymptotic behavior of the complexity. Express your answer in terms of $n$ and a generic constant $C$ which represents the fixed length of a generative program. For the purpose of this problem, you may assume that the number of bits required to specify the integer $n$ is $\\log_2(n)$.",
            "solution": "We construct an explicit short program that outputs the binary string $s_{A}$ encoding the $n \\times n$ adjacency matrix of the path graph $P_{n}$, then bound its length.\n\n1) Constructive upper bound. Consider a fixed algorithm that, given $n$ in binary, outputs $s_{A}$ by iterating through all ordered pairs $(i,j)$ with $1 \\leq i,j \\leq n$ and writing a $1$ exactly when $j=i+1$ or $i=j+1$, and $0$ otherwise; rows are emitted in order from $i=1$ to $i=n$, and within each row, columns are emitted from $j=1$ to $j=n$. This algorithm is the same for all $n$, so its description length is a constant independent of $n$; denote this constant by $C$. To specialize this program to a particular $n$, one hardcodes the binary representation of $n$ directly into the source. Under the stated assumption that specifying the integer $n$ requires $\\log_{2}(n)$ bits, the total length of this program is\n$$\nC+\\log_{2}(n),\n$$\nwhich yields the Kolmogorov complexity upper bound\n$$\nK(s_{A}) \\leq C+\\log_{2}(n).\n$$\n\n2) Asymptotic tightness up to additive constants. Let $\\ell(s_{A})$ denote the length of the string $s_{A}$. For $P_{n}$, $\\ell(s_{A})=n^{2}$. There is a fixed decoder (of constant description length, independent of $n$) that, given $s_{A}$, computes $n$ by $n=\\sqrt{\\ell(s_{A})}$ and outputs that integer. Therefore,\n$$\nK(n) \\leq K(s_{A}) + O(1).\n$$\nBy the problemâ€™s assumption, specifying $n$ requires $\\log_{2}(n)$ bits, so $K(n) \\geq \\log_{2}(n) - O(1)$. Combining these gives\n$$\nK(s_{A}) \\geq \\log_{2}(n) - O(1).\n$$\nTogether with the constructive upper bound, this shows the dominant asymptotic behavior is $\\Theta(\\log_{2}(n))$, and the simple closed-form tight upper bound (absorbing all constant overhead into $C$) is\n$$\nK(s_{A}) \\leq C+\\log_{2}(n).\n$$",
            "answer": "$$\\boxed{C+\\log_{2}(n)}$$"
        }
    ]
}