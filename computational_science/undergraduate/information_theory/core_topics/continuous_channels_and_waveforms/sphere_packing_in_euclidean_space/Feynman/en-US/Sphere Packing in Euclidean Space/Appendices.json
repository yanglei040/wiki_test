{
    "hands_on_practices": [
        {
            "introduction": "The ability of a digital communication system to withstand noise is fundamentally determined by how far apart its signal points are. This practice introduces the concept of the packing radius, which is half the minimum distance between any two codewords and represents the maximum amount of noise that can be tolerated without a decoding error. By analyzing a specific and efficient two-dimensional lattice code, you will learn to calculate this crucial parameter, providing a direct measure of the code's robustness. ",
            "id": "1659539",
            "problem": "In digital signal processing, lattice codes are used to create robust communication systems. Consider a specific two-dimensional lattice code designed for a noisy channel. The set of all valid signals, called codewords, is a subset of the points with integer coordinates in the 2D plane, $\\mathbb{Z}^2$. A point $(x_1, x_2)$ with integer coordinates is a codeword if and only if the sum of its coordinates, $x_1 + x_2$, is an even number.\n\nTo understand the error-correcting capability of this code, one key parameter is the packing radius. Imagine placing identical, non-overlapping circles centered at each codeword. The packing radius is the maximum possible radius of these circles such that no two circles intersect. This radius is directly related to the code's ability to tolerate noise: a received signal falling within a circle is uniquely decoded to the codeword at its center.\n\nDetermine the packing radius for this lattice code. Express your answer as an exact analytic expression.",
            "solution": "The packing radius, $r_p$, of a lattice code is defined as half of the minimum Euclidean distance, $d_{min}$, between any two distinct codewords in the code. This is because for non-overlapping spheres (or circles in 2D) of radius $r_p$ centered at each codeword, the distance between the centers of any two spheres must be at least $2r_p$. Thus, we have $2r_p = d_{min}$, or $r_p = \\frac{1}{2} d_{min}$.\n\nThe set of codewords, $\\mathcal{C}$, is given by $\\mathcal{C} = \\{ (x_1, x_2) \\in \\mathbb{Z}^2 \\mid x_1 + x_2 \\text{ is even} \\}$.\nThe minimum distance $d_{min}$ is given by:\n$$d_{min} = \\min_{c_1, c_2 \\in \\mathcal{C}, c_1 \\neq c_2} \\|c_1 - c_2\\|$$\nwhere $\\| \\cdot \\|$ denotes the standard Euclidean distance.\n\nBecause the code forms a lattice structure, the minimum distance between any two distinct codewords is equal to the minimum norm of a non-zero codeword. This is because if $c_1, c_2 \\in \\mathcal{C}$, then their difference $c_1 - c_2$ is also a point in the lattice (or a translated version of it, but the set of difference vectors is the lattice itself). Therefore, we can simplify the problem to finding the non-zero codeword closest to the origin, $(0,0)$. The origin is itself a codeword since $0+0=0$, which is an even integer.\n\nSo we need to find:\n$$d_{min} = \\min_{c \\in \\mathcal{C}, c \\neq (0,0)} \\|c\\| = \\min_{(x_1, x_2) \\in \\mathbb{Z}^2 \\setminus \\{(0,0)\\}, x_1+x_2 \\text{ is even}} \\sqrt{x_1^2 + x_2^2}$$\n\nThe condition that $x_1 + x_2$ is even for integers $x_1, x_2$ implies that $x_1$ and $x_2$ must have the same parity (i.e., both are even or both are odd). We can search for the non-zero integer pair $(x_1, x_2)$ satisfying this condition that minimizes the distance $\\sqrt{x_1^2 + x_2^2}$, which is equivalent to minimizing the squared distance $x_1^2 + x_2^2$.\n\nLet's examine the possible cases for non-zero codewords:\n\nCase 1: $x_1$ and $x_2$ are both odd.\nThe smallest possible non-zero integer magnitudes for odd numbers are $|x_1|=1$ and $|x_2|=1$. This gives codewords like $(1,1)$, $(1,-1)$, $(-1,1)$, and $(-1,-1)$.\nFor any of these codewords, the squared distance to the origin is $1^2 + 1^2 = 2$.\nThe distance is $\\sqrt{2}$.\n\nCase 2: $x_1$ and $x_2$ are both even.\nOne of the coordinates must be non-zero. Let's assume $x_1 \\neq 0$. The smallest possible non-zero even magnitude is 2. So we could have a codeword where $|x_1|=2$ and $x_2=0$. For example, $(2,0)$ or $(-2,0)$. The sum $2+0=2$ is even, so this is a valid codeword.\nThe squared distance to the origin is $2^2 + 0^2 = 4$.\nThe distance is $\\sqrt{4} = 2$.\nBy symmetry, $(0,2)$ and $(0,-2)$ are also codewords with the same distance to the origin.\nIf both coordinates are non-zero and even, the smallest magnitudes would give a point like $(2,2)$, with a squared distance of $2^2+2^2 = 8$.\n\nComparing the squared distances from the two cases, we have 2 and 4. The minimum of these is 2. Any other choice of integers for $x_1$ and $x_2$ (e.g., $(1,3)$ or $(2,4)$) will result in a larger squared distance. For example, for $(1,3)$, $1^2+3^2=10 > 2$. For $(2,4)$, $2^2+4^2=20 > 2$.\n\nTherefore, the minimum squared distance is 2, and the minimum distance is $d_{min} = \\sqrt{2}$.\n\nThe packing radius $r_p$ is half of this minimum distance:\n$$r_p = \\frac{d_{min}}{2} = \\frac{\\sqrt{2}}{2}$$",
            "answer": "$$\\boxed{\\frac{\\sqrt{2}}{2}}$$"
        },
        {
            "introduction": "Sphere packing is not just a geometric puzzle; it has profound implications for engineering efficiency. This exercise demonstrates the practical value of choosing a well-packed signal constellation by comparing the average energy required for two different arrangements that have the same minimum distance. You will discover why a square-based constellation (QAM) is more power-efficient than a line-based one (PAM), offering a clear lesson in how geometry directly impacts system performance. ",
            "id": "1659517",
            "problem": "In digital communication systems, information is often encoded into signals represented as points in a multi-dimensional space. An arrangement of such points is called a signal constellation. The average energy of a constellation with $M$ points, where the $i$-th point is at coordinate vector $\\boldsymbol{s}_i$, is defined as $E_{avg} = \\frac{1}{M} \\sum_{i=1}^{M} \\|\\boldsymbol{s}_i\\|^2$. The minimum distance, $d_{min}$, is the smallest Euclidean distance between any two distinct points in the constellation. A larger $d_{min}$ for a given energy level generally implies better performance in the presence of noise.\n\nConsider two different 4-point signal constellations in a 2D plane, both centered at the origin.\n\n1.  **Constellation A**: A 4-point Pulse Amplitude Modulation (PAM) style constellation where all points lie on the x-axis, are symmetric with respect to the origin, and are equally spaced.\n2.  **Constellation B**: A 4-point Quadrature Amplitude Modulation (QAM) style constellation where the points form the vertices of a square centered at the origin with sides parallel to the coordinate axes.\n\nBoth constellations are scaled such that their minimum distance $d_{min}$ is the same. Determine the ratio of the average energy of Constellation A to the average energy of Constellation B, $\\frac{E_{avg, A}}{E_{avg, B}}$.",
            "solution": "Let the minimum distance for both constellations be $d_{min}$. We will determine the coordinates of the points for each constellation in terms of $d_{min}$, calculate their respective average energies, and then find the ratio.\n\n**Analysis of Constellation A (PAM-style)**\n\nConstellation A consists of four points lying on the x-axis, equally spaced and symmetric about the origin. Let the distance from the origin to the innermost points be $\\alpha$. Due to the equal spacing and symmetry, the points must be located at coordinates $( -3\\alpha, 0)$, $(-\\alpha, 0)$, $(\\alpha, 0)$, and $(3\\alpha, 0)$.\n\nThe distance between any two adjacent points is $(3\\alpha - \\alpha) = 2\\alpha$ or $(\\alpha - (-\\alpha)) = 2\\alpha$. The other distances are larger. Therefore, the minimum distance is $d_{min} = 2\\alpha$, which implies $\\alpha = \\frac{d_{min}}{2}$.\n\nThe coordinates of the four points in Constellation A are:\n$\\boldsymbol{s}_{A,1} = (-\\frac{3}{2}d_{min}, 0)$\n$\\boldsymbol{s}_{A,2} = (-\\frac{1}{2}d_{min}, 0)$\n$\\boldsymbol{s}_{A,3} = (\\frac{1}{2}d_{min}, 0)$\n$\\boldsymbol{s}_{A,4} = (\\frac{3}{2}d_{min}, 0)$\n\nThe squared norm (energy) of each point is its squared distance from the origin.\n$\\|\\boldsymbol{s}_{A,1}\\|^2 = (-\\frac{3}{2}d_{min})^2 + 0^2 = \\frac{9}{4}d_{min}^2$\n$\\|\\boldsymbol{s}_{A,2}\\|^2 = (-\\frac{1}{2}d_{min})^2 + 0^2 = \\frac{1}{4}d_{min}^2$\n$\\|\\boldsymbol{s}_{A,3}\\|^2 = (\\frac{1}{2}d_{min})^2 + 0^2 = \\frac{1}{4}d_{min}^2$\n$\\|\\boldsymbol{s}_{A,4}\\|^2 = (\\frac{3}{2}d_{min})^2 + 0^2 = \\frac{9}{4}d_{min}^2$\n\nThe average energy of Constellation A is:\n$E_{avg, A} = \\frac{1}{4} \\sum_{i=1}^{4} \\|\\boldsymbol{s}_{A,i}\\|^2 = \\frac{1}{4} \\left( \\frac{9}{4}d_{min}^2 + \\frac{1}{4}d_{min}^2 + \\frac{1}{4}d_{min}^2 + \\frac{9}{4}d_{min}^2 \\right)$\n$E_{avg, A} = \\frac{1}{4} \\left( 2 \\cdot \\frac{9}{4}d_{min}^2 + 2 \\cdot \\frac{1}{4}d_{min}^2 \\right) = \\frac{1}{4} \\left( \\frac{18}{4}d_{min}^2 + \\frac{2}{4}d_{min}^2 \\right)$\n$E_{avg, A} = \\frac{1}{4} \\left( \\frac{20}{4}d_{min}^2 \\right) = \\frac{5}{4}d_{min}^2$\n\n**Analysis of Constellation B (QAM-style)**\n\nConstellation B consists of four points forming a square centered at the origin, with sides parallel to the axes. Let the vertices of the square be at $(\\pm \\beta, \\pm \\beta)$.\nThe coordinates of the four points are:\n$\\boldsymbol{s}_{B,1} = (-\\beta, -\\beta)$\n$\\boldsymbol{s}_{B,2} = (-\\beta, \\beta)$\n$\\boldsymbol{s}_{B,3} = (\\beta, -\\beta)$\n$\\boldsymbol{s}_{B,4} = (\\beta, \\beta)$\n\nThe distance between adjacent vertices, e.g., between $(\\beta, \\beta)$ and $(-\\beta, \\beta)$, is $\\sqrt{(\\beta - (-\\beta))^2 + (\\beta - \\beta)^2} = \\sqrt{(2\\beta)^2} = 2\\beta$. This is the length of a side of the square. The diagonal distance, e.g., between $(\\beta, \\beta)$ and $(-\\beta, -\\beta)$, is $\\sqrt{(\\beta - (-\\beta))^2 + (\\beta - (-\\beta))^2} = \\sqrt{(2\\beta)^2 + (2\\beta)^2} = \\sqrt{8\\beta^2} = 2\\sqrt{2}\\beta$.\n\nThe minimum distance between any two points is the side length of the square. So, $d_{min} = 2\\beta$, which implies $\\beta = \\frac{d_{min}}{2}$.\n\nThe coordinates of the four points in Constellation B are:\n$\\boldsymbol{s}_{B,1} = (-\\frac{d_{min}}{2}, -\\frac{d_{min}}{2})$\n$\\boldsymbol{s}_{B,2} = (-\\frac{d_{min}}{2}, \\frac{d_{min}}{2})$\n$\\boldsymbol{s}_{B,3} = (\\frac{d_{min}}{2}, -\\frac{d_{min}}{2})$\n$\\boldsymbol{s}_{B,4} = (\\frac{d_{min}}{2}, \\frac{d_{min}}{2})$\n\nBy symmetry, all four points are at the same distance from the origin, so they have the same energy. Let's calculate the energy for one point, say $\\boldsymbol{s}_{B,4}$:\n$\\|\\boldsymbol{s}_{B,4}\\|^2 = (\\frac{d_{min}}{2})^2 + (\\frac{d_{min}}{2})^2 = \\frac{d_{min}^2}{4} + \\frac{d_{min}^2}{4} = \\frac{2d_{min}^2}{4} = \\frac{1}{2}d_{min}^2$\n\nSince all points have the same energy, the average energy is simply the energy of any one point:\n$E_{avg, B} = \\|\\boldsymbol{s}_{B,4}\\|^2 = \\frac{1}{2}d_{min}^2$\n\n**Calculating the Ratio**\n\nFinally, we compute the ratio of the average energies:\n$\\frac{E_{avg, A}}{E_{avg, B}} = \\frac{\\frac{5}{4}d_{min}^2}{\\frac{1}{2}d_{min}^2}$\n\nThe $d_{min}^2$ term cancels out:\n$\\frac{E_{avg, A}}{E_{avg, B}} = \\frac{5/4}{1/2} = \\frac{5}{4} \\times \\frac{2}{1} = \\frac{10}{4} = \\frac{5}{2}$",
            "answer": "$$\\boxed{\\frac{5}{2}}$$"
        },
        {
            "introduction": "After analyzing specific codes, we can ask a more general question: what are the fundamental limits on how many messages we can reliably transmit? This problem guides you through a powerful thought experiment involving a greedy algorithm for constructing a code. By considering the state of the system when the algorithm terminates, you will use a volume-based argument to derive a famous lower bound on the size of a code, connecting a simple construction to the deep theoretical limits of communication. ",
            "id": "1659562",
            "problem": "A communication system encodes messages as points (codewords) in an $n$-dimensional Euclidean space, $\\mathbb{R}^n$. When a codeword $\\boldsymbol{x}_i$ is transmitted, the received vector $\\boldsymbol{y}$ is corrupted by noise, such that the error vector $\\boldsymbol{e} = \\boldsymbol{y} - \\boldsymbol{x}_i$ has a magnitude satisfying $\\|\\boldsymbol{e}\\| < r$. To ensure perfect decoding, the set of all possible codewords, $\\{\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\ldots, \\boldsymbol{x}_M\\}$, must be chosen such that the open balls of radius $r$ centered at each codeword are mutually disjoint.\n\nConsider the task of constructing such a code by selecting codewords from a large hyper-region of total volume $V_{total}$. A greedy algorithm is proposed for this task:\n\n1.  Initialize the codebook $C$ as an empty set.\n2.  Select an arbitrary point $\\boldsymbol{p}_1$ from the hyper-region and add it to $C$.\n3.  Iteratively, select a new candidate point $\\boldsymbol{p}_{new}$ from the hyper-region.\n4.  If the distance from $\\boldsymbol{p}_{new}$ to every existing codeword $\\boldsymbol{x}_i \\in C$ is at least $2r$, add $\\boldsymbol{p}_{new}$ to the codebook $C$.\n5.  Repeat from step 3 until no more points can be added to the codebook.\n\nLet $M$ be the total number of codewords in the final codebook generated by this algorithm. By considering the state of the system when the algorithm terminates, derive the strongest possible lower bound on $M$. Assume that boundary effects of the hyper-region are negligible.\n\nThe volume of an $n$-dimensional ball of radius $R$ is given by the formula $V_n(R) = C_n R^n$, where $C_n$ is a constant that depends only on the dimension $n$.\n\nExpress your answer for the lower bound on $M$ as a function of $V_{total}$, $r$, $n$, and $C_n$.",
            "solution": "The problem asks for a lower bound on the number of codewords, $M$, that can be generated by a specific greedy algorithm. The key is to analyze the condition under which the algorithm terminates.\n\nFirst, let's understand the coding constraint. For any two distinct codewords $\\boldsymbol{x}_i$ and $\\boldsymbol{x}_j$ in the codebook $C$, the open balls of radius $r$ around them must be disjoint. The condition for two balls $B(\\boldsymbol{x}_i, r)$ and $B(\\boldsymbol{x}_j, r)$ to be disjoint is that the distance between their centers must be at least the sum of their radii. Therefore, for any $\\boldsymbol{x}_i, \\boldsymbol{x}_j \\in C$ with $i \\neq j$, we must have $\\|\\boldsymbol{x}_i - \\boldsymbol{x}_j\\| \\ge r + r = 2r$. This is precisely the condition used in step 4 of the greedy algorithm to accept a new codeword.\n\nThe algorithm terminates when it is no longer possible to add a new point to the codebook $C$. Let the final codebook contain $M$ codewords, $C = \\{\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\ldots, \\boldsymbol{x}_M\\}$. The termination condition means that for any point $\\boldsymbol{p}$ in the hyper-region of volume $V_{total}$ (that is not already one of the chosen codewords), the condition for adding it to the codebook is violated.\n\nThe condition to add a point $\\boldsymbol{p}$ is $\\|\\boldsymbol{p} - \\boldsymbol{x}_i\\| \\ge 2r$ for all $i \\in \\{1, \\ldots, M\\}$. The violation of this condition means that for any such point $\\boldsymbol{p}$, there must exist at least one codeword $\\boldsymbol{x}_k \\in C$ for which $\\|\\boldsymbol{p} - \\boldsymbol{x}_k\\| < 2r$.\n\nThis implies that at the end of the algorithm, every point in the hyper-region is within a distance of $2r$ from at least one of the $M$ codewords. In other words, the entire hyper-region of volume $V_{total}$ is \"covered by\" the union of $M$ open balls of radius $2r$ centered at the $M$ codewords.\n\nLet $\\mathcal{V}$ be the hyper-region of volume $V_{total}$. The covering condition can be stated as:\n$$\n\\mathcal{V} \\subseteq \\bigcup_{i=1}^{M} B(\\boldsymbol{x}_i, 2r)\n$$\nwhere $B(\\boldsymbol{c}, R)$ denotes the open $n$-ball of radius $R$ centered at $\\boldsymbol{c}$.\n\nBy the properties of volume (or more generally, measure), the volume of a union of sets is less than or equal to the sum of the volumes of the individual sets.\n$$\n\\text{Volume}(\\mathcal{V}) \\le \\text{Volume}\\left(\\bigcup_{i=1}^{M} B(\\boldsymbol{x}_i, 2r)\\right) \\le \\sum_{i=1}^{M} \\text{Volume}(B(\\boldsymbol{x}_i, 2r))\n$$\n\nWe are given that $\\text{Volume}(\\mathcal{V}) = V_{total}$.\nThe volume of a single $n$-ball of radius $2r$ is given by the formula $V_n(R) = C_n R^n$, with $R=2r$.\n$$\nV_n(2r) = C_n (2r)^n = C_n 2^n r^n\n$$\n\nSince all $M$ of these covering balls have the same radius, the sum of their volumes is:\n$$\n\\sum_{i=1}^{M} \\text{Volume}(B(\\boldsymbol{x}_i, 2r)) = M \\cdot V_n(2r) = M C_n 2^n r^n\n$$\n\nSubstituting these into our inequality, we get:\n$$\nV_{total} \\le M C_n 2^n r^n\n$$\n\nTo find the lower bound on $M$, we rearrange the inequality by dividing by the positive quantity $C_n 2^n r^n$:\n$$\nM \\ge \\frac{V_{total}}{C_n 2^n r^n}\n$$\n\nThus, the strongest lower bound on $M$ that can be derived from this covering argument is $\\frac{V_{total}}{C_n 2^n r^n}$.",
            "answer": "$$\\boxed{\\frac{V_{total}}{C_n 2^n r^n}}$$"
        }
    ]
}