{
    "hands_on_practices": [
        {
            "introduction": "我们首先分析一种经典的信道模型——二进制删除信道（Binary Erasure Channel）。与比特翻转不同，该信道有时会直接“删除”输入信号，输出一个表示不确定性的特殊符号。通过这个练习 ，你将学习如何量化在这种部分信息丢失而非信息被污染的情况下，信道仍能传递多少信息。",
            "id": "1622685",
            "problem": "一个专门的数字通信系统被设计用来传输二进制数据。该系统可以被建模为一个离散无记忆信道。信道的输入是一个比特，由随机变量 $X$ 表示，其字母表为 $\\mathcal{X} = \\{0, 1\\}$。信道的输出由随机变量 $Y$ 表示。由于不完美性，信道有时无法解析传输的比特，而是输出一个特殊的“擦除”符号 $\\lambda$。因此，输出字母表为 $\\mathcal{Y} = \\{0, 1, \\lambda\\}$。\n\n该信道的行为由以下性质刻画：\n1.  信道从不翻转比特。这意味着如果输出为 $0$，则输入必定为 $0$；如果输出为 $1$，则输入必定为 $1$。\n2.  发生擦除的概率为 $\\alpha$，其中 $0  \\alpha  1$。此概率与发送的是 $0$ 还是 $1$ 无关。\n\n传输数据的信源产生比特的概率如下：$P(X=0) = p$ 和 $P(X=1) = 1-p$，其中 $0  p  1$。\n\n推导该信道输入 $X$ 和输出 $Y$ 之间互信息 $I(X;Y)$ 的闭式解析表达式。你的最终表达式应以参数 $p$ 和 $\\alpha$ 表示。在你的计算和最终答案中，所有对数必须以 2 为底。",
            "solution": "互信息 $I(X;Y)$ 可以使用公式 $I(X;Y) = H(X) - H(X|Y)$ 计算，其中 $H(X)$ 是输入的熵，$H(X|Y)$ 是给定输出时输入的条件熵。所有对数均以 2 为底。\n\n首先，我们计算输入源的熵 $H(X)$。\n随机变量 $X$ 服从参数为 $p$ 的伯努利分布。其熵由二元熵函数给出：\n$$H(X) = -\\sum_{x \\in \\mathcal{X}} P(X=x) \\log_{2}(P(X=x))$$\n$$H(X) = -[P(X=0) \\log_{2}(P(X=0)) + P(X=1) \\log_{2}(P(X=1))]$$\n代入给定的概率 $P(X=0) = p$ 和 $P(X=1) = 1-p$：\n$$H(X) = -[p \\log_{2}(p) + (1-p) \\log_{2}(1-p)]$$\n\n接下来，我们计算条件熵 $H(X|Y)$。其公式为：\n$$H(X|Y) = \\sum_{y \\in \\mathcal{Y}} P(Y=y) H(X|Y=y)$$\n其中 $H(X|Y=y) = -\\sum_{x \\in \\mathcal{X}} P(X=x|Y=y) \\log_{2}(P(X=x|Y=y))$。\n\n为此，我们需要确定信道的转移概率 $P(Y=y|X=x)$、输出概率 $P(Y=y)$ 和后验概率 $P(X=x|Y=y)$。\n\n转移概率由问题描述给出：\n-   $P(Y=0|X=0) = 1-\\alpha$ (0 的成功传输)\n-   $P(Y=\\lambda|X=0) = \\alpha$ (0 的擦除)\n-   $P(Y=1|X=0) = 0$ (无比特翻转)\n-   $P(Y=1|X=1) = 1-\\alpha$ (1 的成功传输)\n-   $P(Y=\\lambda|X=1) = \\alpha$ (1 的擦除)\n-   $P(Y=0|X=1) = 0$ (无比特翻转)\n\n现在，我们使用全概率定律 $P(Y=y) = \\sum_{x} P(Y=y|X=x)P(X=x)$ 来求输出概率 $P(Y=y)$：\n-   $P(Y=0) = P(Y=0|X=0)P(X=0) + P(Y=0|X=1)P(X=1) = (1-\\alpha)p + 0 \\cdot (1-p) = p(1-\\alpha)$\n-   $P(Y=1) = P(Y=1|X=0)P(X=0) + P(Y=1|X=1)P(X=1) = 0 \\cdot p + (1-\\alpha)(1-p) = (1-p)(1-\\alpha)$\n-   $P(Y=\\lambda) = P(Y=\\lambda|X=0)P(X=0) + P(Y=\\lambda|X=1)P(X=1) = \\alpha p + \\alpha(1-p) = \\alpha(p+1-p) = \\alpha$\n\n接着，我们使用贝叶斯定理 $P(X=x|Y=y) = \\frac{P(Y=y|X=x)P(X=x)}{P(Y=y)}$ 来确定后验概率 $P(X=x|Y=y)$：\n-   如果 $Y=0$：\n    $P(X=0|Y=0) = \\frac{P(Y=0|X=0)P(X=0)}{P(Y=0)} = \\frac{(1-\\alpha)p}{p(1-\\alpha)} = 1$。\n    $P(X=1|Y=0) = 0$。\n    当接收到 Y=0 时，关于 X 的不确定性为零。因此，$H(X|Y=0) = 0$。\n-   如果 $Y=1$：\n    $P(X=1|Y=1) = \\frac{P(Y=1|X=1)P(X=1)}{P(Y=1)} = \\frac{(1-\\alpha)(1-p)}{(1-p)(1-\\alpha)} = 1$。\n    $P(X=0|Y=1) = 0$。\n    当接收到 Y=1 时，关于 X 的不确定性为零。因此，$H(X|Y=1) = 0$。\n-   如果 $Y=\\lambda$：\n    $P(X=0|Y=\\lambda) = \\frac{P(Y=\\lambda|X=0)P(X=0)}{P(Y=\\lambda)} = \\frac{\\alpha p}{\\alpha} = p$。\n    $P(X=1|Y=\\lambda) = \\frac{P(Y=\\lambda|X=1)P(X=1)}{P(Y=\\lambda)} = \\frac{\\alpha (1-p)}{\\alpha} = 1-p$。\n    给定 $Y=\\lambda$ 时 $X$ 的条件分布与 $X$ 的原始分布相同。因此，条件熵为 $H(X|Y=\\lambda) = -[p \\log_{2}(p) + (1-p) \\log_{2}(1-p)] = H(X)$。\n\n现在我们可以计算总条件熵 $H(X|Y)$：\n$$H(X|Y) = P(Y=0)H(X|Y=0) + P(Y=1)H(X|Y=1) + P(Y=\\lambda)H(X|Y=\\lambda)$$\n$$H(X|Y) = [p(1-\\alpha)] \\cdot 0 + [(1-p)(1-\\alpha)] \\cdot 0 + \\alpha \\cdot H(X)$$\n$$H(X|Y) = \\alpha H(X)$$\n\n最后，我们计算互信息：\n$$I(X;Y) = H(X) - H(X|Y) = H(X) - \\alpha H(X) = (1-\\alpha)H(X)$$\n代入 $H(X)$ 的表达式：\n$$I(X;Y) = (1-\\alpha)[-p \\log_{2}(p) - (1-p) \\log_{2}(1-p)]$$\n该表达式表示给定信源分布下，二进制擦除信道输入与输出之间的互信息。",
            "answer": "$$\\boxed{(1-\\alpha)(-p \\log_{2}(p) - (1-p) \\log_{2}(1-p))}$$"
        },
        {
            "introduction": "信息丢失并非总是源于随机噪声，信道本身的确定性结构也可能导致信息损失。这个“配对-集合信道”（Pair-Set Channel） 的练习就是一个绝佳的例子，它会确定性地丢弃输入符号的顺序信息。计算其信道容量将帮助你理解，信道结构本身是如何决定通信极限的。",
            "id": "1622705",
            "problem": "考虑一个称为“对集信道”的离散无记忆信道。输入字母表 $\\mathcal{X}$ 由从集合 $S = \\{1, 2, \\ldots, N\\}$ 中抽取的不同整数的所有可能有序对 $(i, j)$ 组成，其中 $N \\ge 2$ 是一个整数。输出字母表 $\\mathcal{Y}$ 由集合 $S$ 的所有可能的二元子集 $\\{i, j\\}$ 组成。\n\n该信道按如下方式确定性地工作：对于任何输入 $(i, j) \\in \\mathcal{X}$，信道产生输出 $\\{i, j\\} \\in \\mathcal{Y}$。这意味着信道保留了两个数字的身份，但丢弃了关于它们原始顺序的信息。\n\n确定该信道的容量作为 $N$ 的函数。将容量以比特为单位，表示为关于 $N$ 的闭式解析表达式。",
            "solution": "信道容量 $C$ 是在所有可能的输入分布 $p(x)$ 上，互信息 $I(X;Y)$ 的最大值。\n$$C = \\max_{p(x)} I(X;Y) = \\max_{p(x)} (H(Y) - H(Y|X))$$\n首先，我们分析条件熵 $H(Y|X)$。信道是确定性的：对于每个输入 $x=(i,j)$，只有一个可能的输出 $y=\\{i,j\\}$。因此，在给定输入 $X$ 的情况下，关于输出 $Y$ 没有任何不确定性。这意味着 $H(Y|X) = 0$。\n\n所以，信道容量简化为输出熵的最大值：\n$$C = \\max_{p(x)} H(Y)$$\n输出字母表 $\\mathcal{Y}$ 是从集合 $S$ 中选取的大小为 2 的所有子集的集合。其大小为：\n$$|\\mathcal{Y}| = \\binom{N}{2} = \\frac{N(N-1)}{2}$$\n输出熵 $H(Y)$ 的最大值在输出分布 $P(Y=y)$ 为均匀分布时达到，即 $P(y) = 1/|\\mathcal{Y}|$ 对所有 $y \\in \\mathcal{Y}$ 成立。此时的最大熵为：\n$$H_{max}(Y) = \\log_2(|\\mathcal{Y}|) = \\log_2\\left(\\binom{N}{2}\\right)$$\n现在，我们需要验证是否存在一个输入分布 $p(x)$ 可以产生均匀的输出分布。\n输入字母表 $\\mathcal{X}$ 是所有有序对 $(i,j)$ 且 $i \\neq j$。其大小为 $|\\mathcal{X}| = N(N-1)$。\n对于每一个输出 $y=\\{i,j\\}$，都有两个输入可以产生它：$x_1=(i,j)$ 和 $x_2=(j,i)$。\n\n让我们选择一个均匀的输入分布，即对所有 $x \\in \\mathcal{X}$，有 $P(X=x) = \\frac{1}{|\\mathcal{X}|} = \\frac{1}{N(N-1)}$。\n在这种情况下，任意一个输出 $y=\\{i,j\\}$ 的概率为：\n$$P(Y=y) = P(X=(i,j)) + P(X=(j,i)) = \\frac{1}{N(N-1)} + \\frac{1}{N(N-1)} = \\frac{2}{N(N-1)}$$\n这与我们之前计算的均匀输出概率 $1/|\\mathcal{Y}| = 1/\\binom{N}{2} = 2/(N(N-1))$ 相符。\n因此，均匀的输入分布确实产生了均匀的输出分布，从而达到了输出熵的最大值。\n\n所以，信道容量为：\n$$C = \\log_2\\left(\\binom{N}{2}\\right) \\text{ 比特}$$",
            "answer": "$$\\boxed{\\log_{2}\\binom{N}{2}}$$"
        },
        {
            "introduction": "现在，让我们将目光从二进制扩展到更大的符号集，并研究一种带有加性噪声的信道。这个问题  中的信道模型在信号处理中很常见，但加入了模运算的特点。通过计算其互信息，你将练习处理更复杂的信道，并体会对称性在简化信息论分析中的强大作用。",
            "id": "1622708",
            "problem": "考虑一个离散通信信道，该信道用于传输七个可能的信号电平之一，我们用符号集 $\\mathcal{X} = \\{0, 1, 2, 3, 4, 5, 6\\}$ 来表示这些信号。信道的输入是从该集合中抽取的随机变量 $X$。对于这个特定系统，每个输入符号都以相等的概率被选择。\n\n该信道受到一种特定类型的加性噪声的影响。噪声由随机变量 $Z$ 表示，它以概率 $p$ 取值为 1，以概率 $1-p$ 取值为 0，其中 $0  p  1$。信道输出（用随机变量 $Y$ 表示）是输入 $X$ 和噪声 $Z$ 的和，并进行模 7 计算。即，$Y = (X + Z) \\pmod 7$。输出符号也在集合 $\\mathcal{Y} = \\{0, 1, 2, 3, 4, 5, 6\\}$ 中。\n\n计算输入 $X$ 和输出 $Y$ 之间的互信息 $I(X;Y)$。将你的答案表示为以奈特 (nats) 为单位、含概率 $p$ 的解析表达式。",
            "solution": "互信息 $I(X;Y)$ 以奈特 (nats) 为单位计算，因此使用自然对数 $\\ln$。互信息的公式为 $I(X;Y) = H(Y) - H(Y|X)$。\n\n首先计算条件熵 $H(Y|X)$。\n$$H(Y|X) = H((X+Z) \\pmod 7 | X)$$\n由于在给定 $X$ 的条件下，$X$ 是一个已知的常数，所以 $(X+Z) \\pmod 7$ 的不确定性完全来自于噪声 $Z$。因为加法和模运算是可逆的，所以 $H((X+Z) \\pmod 7 | X) = H(Z|X)$。又因为噪声 $Z$ 与输入 $X$ 是独立的，所以 $H(Z|X) = H(Z)$。\n噪声 $Z$ 的熵为：\n$$H(Z) = -[P(Z=0)\\ln(P(Z=0)) + P(Z=1)\\ln(P(Z=1))]$$\n$$H(Z) = -[(1-p)\\ln(1-p) + p\\ln(p)]$$\n\n接下来计算输出熵 $H(Y)$。我们需要先求出输出分布 $P(Y=y)$。根据全概率公式：\n$$P(Y=y) = \\sum_{x \\in \\mathcal{X}} P(Y=y|X=x) P(X=x)$$\n问题中给定输入是均匀分布的，所以 $P(X=x) = 1/7$ 对所有 $x \\in \\mathcal{X}$ 成立。\n条件概率 $P(Y=y|X=x)$ 是 $P((x+Z)\\pmod 7 = y) = P(Z = (y-x)\\pmod 7)$。\n因此，\n$$P(Y=y) = \\sum_{x=0}^{6} \\frac{1}{7} P(Z = (y-x)\\pmod 7)$$\n令 $k = (y-x) \\pmod 7$。当 $x$ 遍历 $\\{0, \\dots, 6\\}$ 时，对于固定的 $y$，$k$ 也遍历了 $\\{0, \\dots, 6\\}$ 的所有值。所以，\n$$P(Y=y) = \\frac{1}{7} \\sum_{k=0}^{6} P(Z=k)$$\n由于 $Z$ 只在 $\\{0, 1\\}$ 上有非零概率，$\\sum_{k=0}^{6} P(Z=k) = P(Z=0) + P(Z=1) = (1-p) + p = 1$。\n所以，$P(Y=y) = 1/7$ 对所有 $y \\in \\mathcal{Y}$ 成立。输出分布也是均匀的。\n输出熵 $H(Y)$ 为：\n$$H(Y) = -\\sum_{y=0}^{6} P(Y=y) \\ln(P(Y=y)) = -\\sum_{y=0}^{6} \\frac{1}{7} \\ln\\left(\\frac{1}{7}\\right) = -7 \\cdot \\frac{1}{7} \\ln\\left(\\frac{1}{7}\\right) = -\\ln\\left(\\frac{1}{7}\\right) = \\ln 7$$\n\n最后，计算互信息：\n$$I(X;Y) = H(Y) - H(Y|X) = H(Y) - H(Z)$$\n$$I(X;Y) = \\ln 7 - (-[(1-p)\\ln(1-p) + p\\ln(p)]) = \\ln 7 + p\\ln p + (1-p)\\ln(1-p)$$\n这是以奈特为单位的互信息。",
            "answer": "$$\\boxed{\\ln 7 + p\\ln p + (1-p)\\ln(1-p)}$$"
        }
    ]
}