{
    "hands_on_practices": [
        {
            "introduction": "To understand the rate-distortion function, $R(D)$, a good starting point is to examine its boundary conditions. Let's begin with the scenario where the transmission rate is zero, $R=0$. In this case, the decoder receives no information about the source symbol and must produce a constant \"best guess\" output. The problem then becomes finding the single reproduction value $\\hat{x}$ that minimizes the average distortion $E[d(X, \\hat{x})]$. This minimum possible distortion at zero rate is often denoted as $D_{max}$. The following exercise  challenges you to find this optimal reproduction point for a continuous source, uniquely featuring an asymmetric distortion measure. This effectively demonstrates how the optimal zero-rate strategy is critically dependent on the specific costs assigned to different types of errors.",
            "id": "1650343",
            "problem": "In the design of a simple scalar quantizer, a source $X$ is modeled as a continuous random variable uniformly distributed on the interval $[-1, 1]$. For a zero-rate code, all possible outputs of the source are mapped to a single, constant reproduction value, $\\hat{x}$.\n\nThe quality of the quantization is measured by a distortion function, $d(x, \\hat{x})$. For this particular application, an asymmetric squared-error distortion measure is used, which penalizes underestimation of the source value more severely than overestimation. This distortion is defined as:\n$$\nd(x, \\hat{x}) =\n\\begin{cases}\n4 (x - \\hat{x})^2 & \\text{if } x < \\hat{x} \\\\\n(x - \\hat{x})^2 & \\text{if } x \\ge \\hat{x}\n\\end{cases}\n$$\nYour task is to find the optimal reproduction point, $\\hat{x}$, that minimizes the average distortion for this source and distortion measure.\n\nExpress your answer as a single closed-form analytic expression.",
            "solution": "Let the constant reproduction value be denoted by $\\hat{x} \\in \\mathbb{R}$. The source $X$ is uniformly distributed on $[-1,1]$, so its density is $f_{X}(x) = \\frac{1}{2}$ for $x \\in [-1,1]$ and zero otherwise. The average distortion as a function of $\\hat{x}$ is\n$$\nD(\\hat{x}) = \\mathbb{E}\\!\\left[d(X,\\hat{x})\\right] = \\int_{-1}^{1} d(x,\\hat{x}) \\cdot \\frac{1}{2} \\, dx.\n$$\nUsing the given asymmetric squared-error distortion,\n$$\nd(x,\\hat{x}) =\n\\begin{cases}\n4(x-\\hat{x})^{2}, & x<\\hat{x},\\\\\n(x-\\hat{x})^{2}, & x \\ge \\hat{x},\n\\end{cases}\n$$\nwe split the integral at $x=\\hat{x}$, but must account for where $\\hat{x}$ lies relative to $[-1,1]$. Consider three cases.\n\nCase 1: $\\hat{x} \\le -1$. Then $x \\ge \\hat{x}$ for all $x \\in [-1,1]$, so\n$$\nD(\\hat{x}) = \\frac{1}{2} \\int_{-1}^{1} (x-\\hat{x})^{2} \\, dx.\n$$\nCompute\n$$\n\\int_{-1}^{1} (x-\\hat{x})^{2} \\, dx = \\left[\\frac{x^{3}}{3} - \\hat{x} x^{2} + \\hat{x}^{2} x\\right]_{-1}^{1} = \\frac{2}{3} + 2 \\hat{x}^{2},\n$$\nhence\n$$\nD(\\hat{x}) = \\hat{x}^{2} + \\frac{1}{3}.\n$$\nThis is minimized (over $\\hat{x} \\le -1$) at the boundary $\\hat{x}=-1$, giving $D(-1)=\\frac{4}{3}$.\n\nCase 2: $-1 \\le \\hat{x} \\le 1$. Then\n$$\nD(\\hat{x}) = \\frac{1}{2} \\left[ \\int_{-1}^{\\hat{x}} 4(x-\\hat{x})^{2} \\, dx + \\int_{\\hat{x}}^{1} (x-\\hat{x})^{2} \\, dx \\right].\n$$\nEvaluate the two integrals. First,\n$$\n\\int_{-1}^{\\hat{x}} (x-\\hat{x})^{2} \\, dx = \\left[\\frac{x^{3}}{3} - \\hat{x} x^{2} + \\hat{x}^{2} x\\right]_{-1}^{\\hat{x}} = \\frac{\\hat{x}^{3}}{3} + \\frac{1}{3} + \\hat{x} + \\hat{x}^{2}.\n$$\nSecond,\n$$\n\\int_{\\hat{x}}^{1} (x-\\hat{x})^{2} \\, dx = \\left[\\frac{x^{3}}{3} - \\hat{x} x^{2} + \\hat{x}^{2} x\\right]_{\\hat{x}}^{1} = \\frac{1}{3} - \\hat{x} + \\hat{x}^{2} - \\frac{\\hat{x}^{3}}{3}.\n$$\nTherefore,\n$$\nD(\\hat{x}) = \\frac{1}{2} \\left[ 4\\!\\left(\\frac{\\hat{x}^{3}}{3} + \\frac{1}{3} + \\hat{x} + \\hat{x}^{2}\\right) + \\left(\\frac{1}{3} - \\hat{x} + \\hat{x}^{2} - \\frac{\\hat{x}^{3}}{3}\\right) \\right]\n= \\frac{1}{2} \\left( \\hat{x}^{3} + 5 \\hat{x}^{2} + 3 \\hat{x} + \\frac{5}{3} \\right).\n$$\nDifferentiate and set to zero:\n$$\nD'(\\hat{x}) = \\frac{3}{2} \\hat{x}^{2} + 5 \\hat{x} + \\frac{3}{2} = 0 \\quad \\Longleftrightarrow \\quad 3 \\hat{x}^{2} + 10 \\hat{x} + 3 = 0.\n$$\nSolve the quadratic:\n$$\n\\hat{x} = \\frac{-10 \\pm \\sqrt{100 - 36}}{6} = \\frac{-10 \\pm 8}{6} \\in \\left\\{ -\\frac{1}{3}, -3 \\right\\}.\n$$\nOnly $\\hat{x} = -\\frac{1}{3}$ lies in $[-1,1]$. The second derivative is $D''(\\hat{x}) = 3 \\hat{x} + 5$, which on $[-1,1]$ satisfies $D''(\\hat{x}) \\ge 2 > 0$, so $D$ is strictly convex there and $\\hat{x}=-\\frac{1}{3}$ is the unique minimizer in this case.\n\nCase 3: $\\hat{x} \\ge 1$. Then $x < \\hat{x}$ for all $x \\in [-1,1]$, so\n$$\nD(\\hat{x}) = \\frac{1}{2} \\int_{-1}^{1} 4(x-\\hat{x})^{2} \\, dx = 2\\left(\\frac{1}{2}\\int_{-1}^{1} (x-\\hat{x})^{2} \\, dx\\right) = 2 \\left( \\hat{x}^{2} + \\frac{1}{3} \\right) = 2\\hat{x}^{2} + \\frac{2}{3}.\n$$\nThe solution provided `4/3 + 4\\hat{x}^2`, which is incorrect. Let's re-evaluate:\n$$ D(\\hat{x}) = \\frac{1}{2} \\int_{-1}^{1} 4(x-\\hat{x})^{2} \\, dx = 2 \\int_{-1}^{1} (x-\\hat{x})^{2} \\, dx = 2 \\left(\\frac{2}{3} + 2 \\hat{x}^{2}\\right) = \\frac{4}{3} + 4 \\hat{x}^{2}. $$\nThe solution's calculation is correct. My mental calculation was wrong.\nThis is minimized (over $\\hat{x} \\ge 1$) at the boundary $\\hat{x}=1$, giving $D(1)=\\frac{4}{3} + 4$.\n\nComparing across cases, the minimal value is achieved at $\\hat{x} = -\\frac{1}{3}$ from Case 2. Thus the optimal reproduction point that minimizes the average distortion is $\\hat{x} = -\\frac{1}{3}$.",
            "answer": "$$\\boxed{-\\frac{1}{3}}$$"
        },
        {
            "introduction": "Having explored the zero-rate limit, we now turn to the other extreme of the rate-distortion curve: the rate required for perfect, error-free reconstruction, where the distortion $D=0$. This is the domain of lossless compression, where every detail of the original source data must be preserved. It is a fundamental bridge between the theories of lossy and lossless coding. This practice problem  asks you to determine the absolute minimum rate needed to losslessly encode a simple discrete source. By solving this, you will directly see how for any discrete source, the rate-distortion function at zero distortion, $R(0)$, is equal to the source's Shannon entropy, $H(X)$, providing a crucial anchor for the entire $R(D)$ curve.",
            "id": "1650334",
            "problem": "A simple robotic explorer is designed to navigate a grid-based environment. At each time step, the robot's control system generates a command corresponding to one of the four cardinal directions: North, South, East, or West. Extensive testing has shown that the robot is equally likely to be instructed to move in any of these four directions.\n\nTo save bandwidth, the sequence of commands is compressed before being transmitted to the robot. The compression scheme is designed to be lossless, meaning the original sequence of commands can be perfectly reconstructed from the compressed data.\n\nWhat is the theoretical minimum average number of bits required to represent each directional command in this compressed format? Express your answer in bits per command.",
            "solution": "We model each directional command as a symbol from a discrete memoryless source with four equally likely outcomes: North, South, East, West. By the definition of Shannon entropy for a discrete source with probabilities $\\{p_{i}\\}$,\n$$\nH(X)=-\\sum_{i=1}^{4} p_{i}\\log_{2}(p_{i}).\n$$\nGiven equiprobability, $p_{i}=\\frac{1}{4}$ for all $i$, so\n$$\nH(X)=-4\\left(\\frac{1}{4}\\right)\\log_{2}\\left(\\frac{1}{4}\\right)= -\\log_{2}\\left(\\frac{1}{4}\\right)=\\log_{2}(4)=2.\n$$\nBy the source coding theorem, the theoretical minimum average number of bits per symbol for any lossless compression equals the entropy $H(X)$, and no lossless code can have a smaller expected length. Since $4$ is a power of $2$, a fixed-length code with $2$ bits per symbol achieves this bound exactly. Therefore, the theoretical minimum average number of bits per command is $2$.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "We have established the key endpoints of the rate-distortion curve: the distortion at zero rate ($D_{max}$) and the rate at zero distortion ($R(0)$). The shape of the curve connecting these points is defined by one of its most critical properties: convexity. This mathematical property is not just an abstract concept; it arises from a powerful and practical coding strategy known as time-sharing. If we have two different coder-decoder pairs, each achieving a specific $(R, D)$ point, we can achieve any point on the line segment between them simply by switching between the two systems. This exercise  invites you to analyze such a hybrid system. By calculating its effective rate and distortion, you will provide the operational proof for why the set of all achievable rate-distortion pairs is convex, and consequently, why the rate-distortion function $R(D)$ must be a convex function.",
            "id": "1650279",
            "problem": "A digital communication system is designed to compress and transmit data from a memoryless source. The performance of any compression scheme for this source is characterized by a rate-distortion pair $(R, D)$, where $R$ is the average number of bits used to represent each source symbol, and $D$ is the resulting average distortion between the original and reconstructed data.\n\nTwo existing compression algorithms, Algorithm A and Algorithm B, are available for this source.\n- Algorithm A operates at a rate $R_A$ and achieves an average distortion $D_A$.\n- Algorithm B operates at a rate $R_B$ and achieves an average distortion $D_B$.\n\nA new hybrid system is created that processes a long sequence of source symbols. This system employs Algorithm A for a fraction $\\alpha$ of the symbols and Algorithm B for the remaining fraction $(1-\\alpha)$ of the symbols, where $0 \\le \\alpha \\le 1$. The system switches between algorithms on large, independent blocks of data, so any overhead from the switching can be considered negligible.\n\nDetermine the effective rate, $R_{eff}$, and the effective average distortion, $D_{eff}$, of this hybrid system. Your answer should be a row matrix containing the effective rate and the effective distortion, in that order, expressed in terms of $R_A, D_A, R_B, D_B,$ and $\\alpha$.",
            "solution": "Let a long block contain $N$ source symbols. By design, Algorithm A is used on a fraction $\\alpha$ of the symbols and Algorithm B on the remaining fraction $(1-\\alpha)$, with switching overhead negligible.\n\nRate derivation:\n- The total number of bits used by Algorithm A is $(\\alpha N) R_{A}$, and by Algorithm B is $\\bigl((1-\\alpha) N\\bigr) R_{B}$.\n- The total number of bits over $N$ symbols is therefore\n$$\n(\\alpha N) R_{A} + \\bigl((1-\\alpha) N\\bigr) R_{B}.\n$$\n- The effective rate, defined as average bits per source symbol, is this total divided by $N$:\n$$\nR_{eff} = \\frac{(\\alpha N) R_{A} + \\bigl((1-\\alpha) N\\bigr) R_{B}}{N} = \\alpha R_{A} + (1-\\alpha) R_{B}.\n$$\nEquivalently, viewing the per-symbol rate as a random variable determined by which algorithm is used and applying linearity of expectation (law of total expectation), one has $R_{eff} = \\alpha R_{A} + (1-\\alpha) R_{B}$.\n\nDistortion derivation:\n- Let $D_{A}$ and $D_{B}$ be the average per-symbol distortions achieved by Algorithms A and B, respectively, under the given source and distortion measure.\n- Over the $\\alpha N$ symbols encoded by A, the aggregate distortion is $(\\alpha N) D_{A}$; over the $(1-\\alpha) N$ symbols encoded by B, it is $\\bigl((1-\\alpha) N\\bigr) D_{B}$.\n- The total distortion over $N$ symbols is\n$$\n(\\alpha N) D_{A} + \\bigl((1-\\alpha) N\\bigr) D_{B},\n$$\nso the effective average distortion per symbol is\n$$\nD_{eff} = \\frac{(\\alpha N) D_{A} + \\bigl((1-\\alpha) N\\bigr) D_{B}}{N} = \\alpha D_{A} + (1-\\alpha) D_{B}.\n$$\nThis also follows from the law of total expectation by conditioning on which algorithm is used for a given symbol.\n\nThus, the hybrid system’s effective rate and distortion are the convex combinations of the individual algorithms’ rate and distortion, weighted by $\\alpha$ and $(1-\\alpha)$.\n\nThe required row matrix, listing the effective rate first and effective distortion second, is $\\begin{pmatrix} R_{eff} & D_{eff} \\end{pmatrix}$ with\n$$\nR_{eff} = \\alpha R_{A} + (1-\\alpha) R_{B}, \\quad D_{eff} = \\alpha D_{A} + (1-\\alpha) D_{B}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}\\alpha R_{A}+(1-\\alpha) R_{B} & \\alpha D_{A}+(1-\\alpha) D_{B}\\end{pmatrix}}$$"
        }
    ]
}