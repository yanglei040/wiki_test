{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a direct application of the definition of average Hamming distortion. By analyzing a deterministic system with a periodic source and predictable channel errors, we can focus on the core mechanics of calculating long-term average distortion without the complexities of probability. This practice builds a solid foundation for understanding how distortion is quantified over time .",
            "id": "1628536",
            "problem": "An infinite binary source sequence, denoted by $S = (X_1, X_2, X_3, \\dots)$, is generated by the deterministic process of endlessly repeating the 4-bit block '1100'. This sequence is then transmitted through a communication channel that introduces errors in a predictable manner. The channel deterministically flips the bit at any position $n$ if and only if $n$ can be expressed in the form $n = 4k+1$, where $k$ is any non-negative integer ($k=0, 1, 2, \\dots$). All other bits are transmitted without alteration. Let the resulting output sequence from the channel be denoted by $S' = (Y_1, Y_2, Y_3, \\dots)$.\n\nThe performance of this system is measured by the average Hamming distortion, $D$, between the source sequence $S$ and the channel output sequence $S'$. It is defined as the long-term average of the per-symbol Hamming distance:\n$$D = \\lim_{N\\to\\infty} \\frac{1}{N} \\sum_{i=1}^{N} d_H(X_i, Y_i)$$\nwhere the per-symbol Hamming distance $d_H(x, y)$ is 1 if the bits $x$ and $y$ are different, and 0 if they are identical.\n\nCalculate the value of the average Hamming distortion $D$.",
            "solution": "The source is a periodic binary sequence with period 4 given by\n$$(X_{4k+1}, X_{4k+2}, X_{4k+3}, X_{4k+4})=(1,1,0,0) \\quad \\text{for all } k \\in \\{0,1,2,\\dots\\}.$$\nThe channel outputs $Y_{n}$ by flipping exactly when $n=4k+1$ and leaving the bit unchanged otherwise. Hence\n$$\nY_{n}=\\begin{cases}\n1-X_{n},  n=4k+1 \\text{ for some } k \\in \\{0,1,2,\\dots\\},\\\\\nX_{n},  \\text{otherwise}.\n\\end{cases}\n$$\nThe per-symbol Hamming distance is defined by $d_{H}(x,y)=1$ if $x\\neq y$ and $d_{H}(x,y)=0$ if $x=y$. Since flipping a binary bit always changes its value, we have\n$$\nd_{H}(X_{n},Y_{n})=\\begin{cases}\n1,  n=4k+1 \\text{ for some } k \\in \\{0,1,2,\\dots\\},\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThus $d_{H}(X_{n},Y_{n})$ is the indicator of the event $\\{n \\equiv 1 \\mod 4\\}$. Therefore, the average Hamming distortion is\n$$\nD=\\lim_{N\\to\\infty}\\frac{1}{N}\\sum_{n=1}^{N} d_{H}(X_{n},Y_{n})\n=\\lim_{N\\to\\infty}\\frac{1}{N}\\sum_{n=1}^{N} \\mathbf{1}\\{n \\equiv 1 \\ (\\mathrm{mod}\\ 4)\\}.\n$$\nFor $N=4m+r$ with $m\\in \\mathbb{N}$ and $r\\in\\{0,1,2,3\\}$, the number of indices in $\\{1,\\dots,N\\}$ that satisfy $n\\equiv 1 \\ (\\mathrm{mod}\\ 4)$ is $m$ if $r=0$ and $m+1$ if $r\\in\\{1,2,3\\}$. Hence\n$$\nD=\\lim_{m\\to\\infty}\n\\begin{cases}\n\\frac{m}{4m},  r=0,\\\\\n\\frac{m+1}{4m+r},  r\\in\\{1,2,3\\},\n\\end{cases}\n=\\frac{1}{4}.\n$$\nEquivalently, by 4-periodicity, within each block of four symbols exactly one position is flipped and three are unchanged, so the average distortion per symbol over any period is $\\frac{1}{4}$, and the long-term average equals this value.",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        },
        {
            "introduction": "Moving from deterministic to probabilistic models, this problem explores a fundamental trade-off in system design. We use expected Hamming distortion to compare two distinct strategies: transmitting data over a noisy channel versus relying solely on prior statistical knowledge of the source. This exercise highlights how distortion serves as a critical performance metric for making practical engineering decisions .",
            "id": "1628544",
            "problem": "A discrete memoryless source produces binary symbols, $X$, from the set $\\{0, 1\\}$. The probability of producing a '1' is given by $P(X=1) = p_s = 0.2$. We are tasked with evaluating two different schemes for communicating this source symbol to a receiver.\n\n**Scheme A:** The source symbol is transmitted through a Binary Symmetric Channel (BSC). A BSC is a channel model where a transmitted bit is flipped (i.e., a 0 becomes a 1 or a 1 becomes a 0) with a certain probability, known as the crossover probability. For this channel, the crossover probability is $\\epsilon = 0.1$.\n\n**Scheme B:** No information is transmitted. Instead, to reconstruct the source symbol, the receiver always guesses the single, most probable symbol from the source's probability distribution.\n\nThe quality of the reconstruction is measured by the expected Hamming distortion. The Hamming distortion between a source symbol $x$ and a reconstructed symbol $\\hat{x}$ is defined as $d(x, \\hat{x}) = 0$ if $x = \\hat{x}$ and $d(x, \\hat{x}) = 1$ if $x \\neq \\hat{x}$.\n\nLet $D_A$ be the expected Hamming distortion for Scheme A, and $D_B$ be the expected Hamming distortion for Scheme B. Calculate the difference $D_B - D_A$. Express your final answer as a single real number, rounded to three significant figures.",
            "solution": "We denote the source by $X \\in \\{0,1\\}$ with $P(X=1)=p_{s}=0.2$ and $P(X=0)=1-p_{s}=0.8$. The Hamming distortion is $d(x,\\hat{x})=0$ if $x=\\hat{x}$ and $d(x,\\hat{x})=1$ if $x\\neq \\hat{x}$. For any reconstruction rule, the expected Hamming distortion equals the probability of reconstruction error:\n$$\nD=\\mathbb{E}[d(X,\\hat{X})]=P(X\\neq \\hat{X}).\n$$\n\nScheme A (BSC with crossover probability $\\epsilon=0.1$): Let $Y$ be the channel output and use the optimal symbol-by-symbol decoder (MAP), which for a BSC with $\\epsilon\\frac{1}{2}$ decides $\\hat{X}=Y$ provided the prior is not extreme. Check MAP conditions:\nFor $Y=1$, choose $X=1$ if $(1-\\epsilon)p_{s} \\ge \\epsilon(1-p_{s})$, which is equivalent to $p_{s} \\ge \\epsilon$.\nFor $Y=0$, choose $X=0$ if $(1-\\epsilon)(1-p_{s}) \\ge \\epsilon p_{s}$, which is equivalent to $p_{s} \\le 1-\\epsilon$.\nWith $p_{s}=0.2$ and $\\epsilon=0.1$, both $p_{s} \\ge \\epsilon$ and $p_{s} \\le 1-\\epsilon$ hold, so $\\hat{X}=Y$ is optimal. Therefore the error probability is\n$$\nD_{A}=P(\\hat{X}\\neq X)=\\epsilon=0.1.\n$$\n\nScheme B (always guess the most probable symbol): The receiver always outputs $\\hat{X}=0$ since $P(X=0)=0.8$ is larger than $P(X=1)=0.2$. Thus the error occurs exactly when $X=1$, giving\n$$\nD_{B}=P(X\\neq \\hat{X})=P(X=1)=p_{s}=0.2.\n$$\n\nThe required difference is\n$$\nD_{B}-D_{A}=p_{s}-\\epsilon=0.2-0.1=0.1.\n$$\n\nRounded to three significant figures, the result is $0.100$.",
            "answer": "$$\\boxed{0.100}$$"
        },
        {
            "introduction": "This final practice delves into the realm of error-control coding, demonstrating how we can actively design systems to minimize distortion. By employing a simple repetition code and a majority-vote decoder, we can combat channel noise and improve communication fidelity. This problem illustrates the crucial interplay between the chosen code, the nature of the channel errors, and the decoding strategy in determining the overall system performance .",
            "id": "1628520",
            "problem": "A simple digital communication system is designed to transmit a single source bit, $X$, which can be either 0 or 1 with equal probability, i.e., $P(X=0) = P(X=1) = 1/2$. To protect against errors, the system employs a (3,1) repetition code, where the bit 0 is encoded as the codeword `000` and the bit 1 is encoded as `111`.\n\nThe 3-bit codeword is transmitted over a noisy channel that alters the codeword based on its operational mode:\n- **Mode A:** With a probability of $\\alpha = 5/7$, the channel deterministically flips exactly one bit of the transmitted codeword. The position of the flipped bit (first, second, or third) is chosen uniformly at random.\n- **Mode B:** With a probability of $1-\\alpha = 2/7$, the channel deterministically flips exactly two bits of the transmitted codeword. The pair of bit positions to be flipped is chosen uniformly at random from all possible pairs.\n\nAt the receiving end, a decoder uses a majority-vote rule to estimate the original source bit, denoted as $\\hat{X}$. If the received 3-bit word contains more 0s than 1s, the decoder outputs $\\hat{X}=0$; if it contains more 1s than 0s, it outputs $\\hat{X}=1$.\n\nCalculate the average Hamming distortion, $D = E[d(X, \\hat{X})]$, between the source bit $X$ and the decoded bit $\\hat{X}$. The per-symbol Hamming distortion $d(x, \\hat{x})$ is defined as 0 if $x = \\hat{x}$ and 1 if $x \\neq \\hat{x}$. Express your answer as an exact fraction.",
            "solution": "Let $X \\in \\{0,1\\}$ with $P(X=0)=P(X=1)=\\frac{1}{2}$ and the encoder map $0 \\mapsto 000$, $1 \\mapsto 111$. Let the channel mode be $M \\in \\{\\text{A},\\text{B}\\}$ with $P(M=\\text{A})=\\alpha$ and $P(M=\\text{B})=1-\\alpha$, where in mode A exactly one bit is flipped (position chosen uniformly among the three), and in mode B exactly two bits are flipped (pair chosen uniformly among the three pairs). The decoder outputs the majority of the three received bits.\n\nThe per-symbol Hamming distortion is $d(x,\\hat{x})=\\mathbf{1}\\{\\hat{x}\\neq x\\}$, hence the average distortion equals the error probability:\n$$\nD=E[d(X,\\hat{X})]=P(\\hat{X}\\neq X).\n$$\nCondition on $X=x$ and channel mode $M$:\n$$\nP(\\hat{X}\\neq X \\mid X=x)=P(M=\\text{A})\\,P(\\hat{X}\\neq X \\mid X=x,M=\\text{A})+P(M=\\text{B})\\,P(\\hat{X}\\neq X \\mid X=x,M=\\text{B}).\n$$\nGiven the repetition code, if exactly one bit is flipped, the received word has two correct bits and one incorrect bit, so majority decoding recovers $x$ and\n$$\nP(\\hat{X}\\neq X \\mid X=x,M=\\text{A})=0.\n$$\nIf exactly two bits are flipped, the received word has one correct bit and two incorrect bits, so majority decoding outputs $\\hat{X}\\neq x$ and\n$$\nP(\\hat{X}\\neq X \\mid X=x,M=\\text{B})=1.\n$$\nTherefore, for either $x\\in\\{0,1\\}$,\n$$\nP(\\hat{X}\\neq X \\mid X=x)=0\\cdot \\alpha+1\\cdot (1-\\alpha)=1-\\alpha.\n$$\nAveraging over $X$,\n$$\nD=P(\\hat{X}\\neq X)=\\sum_{x\\in\\{0,1\\}} P(X=x)\\,P(\\hat{X}\\neq X \\mid X=x)=\\frac{1}{2}(1-\\alpha)+\\frac{1}{2}(1-\\alpha)=1-\\alpha.\n$$\nSubstituting $\\alpha=\\frac{5}{7}$ yields\n$$\nD=1-\\frac{5}{7}=\\frac{2}{7}.\n$$",
            "answer": "$$\\boxed{\\frac{2}{7}}$$"
        }
    ]
}