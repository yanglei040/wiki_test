{
    "hands_on_practices": [
        {
            "introduction": "大数定律不仅仅是一个抽象的数学定理，它在工程和质量控制等领域有着重要的实际应用。这个练习将引导你使用弱大数定律的核心工具——切比雪夫不等式，来解决一个实际的工程问题：确定需要多少次重复操作才能保证平均结果达到预期的精度。通过这个练习，你将体会到如何将概率论的理论与制造业中的具体决策联系起来。",
            "id": "1967293",
            "problem": "一台自动化精密切割机按周期运行。在每个周期中，机器的切割头会进行微小的位置调整。设第 $i$ 个周期中的调整量由随机变量 $X_i$ 表示。这些调整是独立同分布的。机器经过校准，使得每次调整以相等的概率发生 $a$ 的正位移或 $-a$ 的负位移。\n\n机器的长期稳定性取决于多个周期内平均调整量是否接近于零。一项质量控制标准要求，在 $n$ 个周期后，平均调整量 $\\frac{1}{n}\\sum_{i=1}^{n} X_i$ 的绝对值大于或等于某个容差 $\\epsilon$ 的概率不得超过给定值 $\\delta$。\n\n给定以下参数：\n- 调整步长：$a = 0.5$ 单位。\n- 平均调整量的容差：$\\epsilon = 0.02$ 单位。\n- 超过容差的最大允许概率：$\\delta = 0.01$。\n\n使用一个常见概率不等式建立一个充分条件，确定满足此质量控制标准所需的最小周期数 $n$。最终答案必须是一个整数。",
            "solution": "设 $\\{X_{i}\\}_{i=1}^{n}$ 是独立同分布的随机变量，且 $\\mathbb{P}(X_{i}=a)=\\mathbb{P}(X_{i}=-a)=\\frac{1}{2}$。则\n$$\n\\mathbb{E}[X_{i}]=\\frac{a+(-a)}{2}=0,\\quad \\mathbb{E}[X_{i}^{2}]=\\frac{a^{2}+a^{2}}{2}=a^{2},\n$$\n所以\n$$\n\\operatorname{Var}(X_{i})=\\mathbb{E}[X_{i}^{2}]-\\mathbb{E}[X_{i}]^{2}=a^{2}.\n$$\n令 $\\overline{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。根据独立性，\n$$\n\\operatorname{Var}(\\overline{X}_{n})=\\operatorname{Var}\\!\\left(\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\right)=\\frac{1}{n^{2}}\\sum_{i=1}^{n}\\operatorname{Var}(X_{i})=\\frac{a^{2}}{n}.\n$$\n根据切比雪夫不等式，对于任意 $\\epsilon0$，\n$$\n\\mathbb{P}\\!\\left(\\left|\\overline{X}_{n}-\\mathbb{E}[\\overline{X}_{n}]\\right|\\geq \\epsilon\\right)\\leq \\frac{\\operatorname{Var}(\\overline{X}_{n})}{\\epsilon^{2}}=\\frac{a^{2}}{n\\,\\epsilon^{2}}.\n$$\n因此，确保 $\\mathbb{P}(|\\overline{X}_{n}|\\geq \\epsilon)\\leq \\delta$ 的一个充分条件是\n$$\n\\frac{a^{2}}{n\\,\\epsilon^{2}}\\leq \\delta \\quad\\Longleftrightarrow\\quad n\\geq \\frac{a^{2}}{\\delta\\,\\epsilon^{2}}.\n$$\n代入 $a=0.5$, $\\epsilon=0.02$, 和 $\\delta=0.01$ 可得\n$$\nn\\geq \\frac{0.5^{2}}{0.01\\cdot 0.02^{2}}=\\frac{0.25}{0.01\\cdot 0.0004}=\\frac{0.25}{0.000004}=62500.\n$$\n因为 $n$ 必须是整数，所以最小周期数是 $62500$。",
            "answer": "$$\\boxed{62500}$$"
        },
        {
            "introduction": "弱大数定律的威力并不仅限于简单的算术平均，该定律同样适用于随机变量函数的平均值，这极大地扩展了它的应用范围。本题要求你分析样本二阶矩的收敛性，这需要你将大数定律应用于一个新的随机变量序列 $Y_i = X_i^2$。这个练习有助于你深入理解大数定律的适用范围及其在估计方差等高阶统计特性时的作用。",
            "id": "1967327",
            "problem": "考虑一个独立同分布 (i.i.d.) 的随机变量序列 $X_1, X_2, \\dots, X_n$。该序列中的每个随机变量 $X_i$ 都有已知的有限均值 $E[X_i] = \\mu$ 和已知的有限正方差 $\\text{Var}(X_i) = \\sigma^2$。\n\n我们将此序列的样本二阶原点矩定义为：\n$$M_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i^2$$\n这个量在许多领域都具有重要意义，例如，在物理学中它可能与粒子系统的平均能量有关。\n\n确定当样本容量 $n$ 趋于无穷大时，$M_n$ 依概率收敛到的值。请用 $\\mu$ 和 $\\sigma$ 表示您的答案，形式为一个解析闭式表达式。",
            "solution": "问题要求解样本二阶原点矩 $M_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i^2$ 依概率收敛到的值。这是一个弱大数定律 (WLLN) 的直接应用。\n\n弱大数定律指出，对于一个具有有限期望值 $E[Y_i] = \\mu_Y$ 的独立同分布 (i.i.d.) 随机变量序列 $Y_1, Y_2, \\dots$，其样本均值 $\\bar{Y}_n = \\frac{1}{n} \\sum_{i=1}^{n} Y_i$ 会依概率收敛于 $\\mu_Y$。我们可以将其写作当 $n \\to \\infty$ 时，$\\bar{Y}_n \\xrightarrow{p} \\mu_Y$。\n\n为了将弱大数定律应用于我们的问题，我们定义一个新的随机变量序列 $Y_i = X_i^2$。这样，$M_n$ 就可以被重写为这个新序列的样本均值：\n$$M_n = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}_n$$\n\n现在，我们必须检查序列 $Y_i$ 是否满足弱大数定律的条件。\n1.  **独立同分布条件：** 题目说明随机变量 $X_1, X_2, \\dots$ 是独立同分布的。由于每个 $Y_i$ 都是相应 $X_i$ 的函数（具体为 $Y_i = X_i^2$），并且对于所有的 $i$ 这个函数都相同，因此随机变量序列 $Y_1, Y_2, \\dots$ 也是独立同分布的。\n\n2.  **有限均值条件：** 弱大数定律要求 $Y_i$ 的期望值，记为 $E[Y_i]$，是有限的。让我们来计算这个期望。\n$$E[Y_i] = E[X_i^2]$$\n我们可以将 $E[X_i^2]$ 与给定的 $X_i$ 的均值和方差联系起来。方差的定义是：\n$$\\text{Var}(X_i) = E[X_i^2] - (E[X_i])^2$$\n根据题意，$\\text{Var}(X_i) = \\sigma^2$ 且 $E[X_i] = \\mu$。将这些值代入方差公式，得到：\n$$\\sigma^2 = E[X_i^2] - \\mu^2$$\n解出 $E[X_i^2]$，我们得到：\n$$E[X_i^2] = \\mu^2 + \\sigma^2$$\n由于 $\\mu$ 和 $\\sigma^2$ 已知是有限的，所以期望 $E[Y_i] = \\mu^2 + \\sigma^2$ 也是有限的。我们将 $Y_i$ 序列的这个公共均值记为 $\\mu_Y = \\mu^2 + \\sigma^2$。\n\n由于序列 $Y_i = X_i^2$ 满足弱大数定律的两个条件，我们可以得出结论：其样本均值 $M_n$ 依概率收敛于其真实均值 $\\mu_Y$。\n$$M_n \\xrightarrow{p} E[Y_i] = \\mu^2 + \\sigma^2$$\n\n因此，$M_n$ 依概率收敛到的值是 $\\mu^2 + \\sigma^2$。",
            "answer": "$$\\boxed{\\mu^{2} + \\sigma^{2}}$$"
        },
        {
            "introduction": "在应用任何数学定理时，理解其前提假设至关重要，弱大数定律的结论便严重依赖于随机变量之间的独立性假设。这个练习设计了一个思想实验，其中所有测量值都受一个共同的随机因素影响，从而破坏了独立性。你将发现，在这种情况下，样本均值不再收敛到一个常数，而是收敛到该随机因素本身，这个练习对于培养对大数定律的深刻理解至关重要，它揭示了可被平均掉的非系统性噪声与无法被平均掉的系统性影响之间的根本区别。",
            "id": "1668567",
            "problem": "一个大规模环境传感网络被部署用于监测某一物理量 $T$。$T$ 的值不是一个固定的常数，而是由于复杂的环境动态随时间波动。为了分析，$T$ 被建模为一个随机变量，其均值 $E[T] = \\mu$ 已明确定义但未知，方差 $\\text{Var}(T) = \\sigma_T^2$ 有限且非零。\n\n该网络由 $n$ 个相同的传感器组成。第 $i$ 个传感器的读数（记为 $X_i$）是真实量 $T$ 与一个独立的内部噪声项 $\\epsilon_i$ 的和。因此，$X_i = T + \\epsilon_i$。噪声项 $\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_n$ 被建模为独立同分布（i.i.d.）的随机变量，每个噪声项的期望值为 $E[\\epsilon_i] = 0$，方差为有限值 $\\text{Var}(\\epsilon_i) = \\sigma_\\epsilon^2$。此外，噪声项独立于物理量 $T$。\n\n为了估计平均量 $\\mu$，一位工程师计算了所有传感器读数的样本均值：\n$$ \\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i $$\n虽然通常假设当 $n$ 很大时，这样的平均值会收敛到真实均值 $\\mu$，但 $T$ 对所有传感器的共同影响引入了系统性相关。你的任务是确定当传感器数量 $n$ 趋于无穷大时，样本均值 $\\bar{X}_n$ 的极限。找出 $\\bar{X}_n$ 依概率收敛到的值 $L$，即对于任何任意小的正数 $\\delta$，当 $n \\to \\infty$ 时，概率 $P(|\\bar{X}_n - L| \\geq \\delta)$ 趋近于零。\n\n用所定义的变量将你的答案 $L$ 表示为解析表达式。",
            "solution": "我们从每个传感器的给定测量模型开始，\n$$\nX_{i} = T + \\epsilon_{i},\n$$\n其中 $T$ 是一个随机变量，其 $E[T] = \\mu$ 且 $\\text{Var}(T) = \\sigma_{T}^{2}$，而 $\\epsilon_{i}$ 是独立同分布的，其 $E[\\epsilon_{i}] = 0$ 且 $\\text{Var}(\\epsilon_{i}) = \\sigma_{\\epsilon}^{2}$，并且独立于 $T$。\n\n$n$ 个传感器的样本均值为\n$$\n\\bar{X}_{n} = \\frac{1}{n}\\sum_{i=1}^{n} X_{i}.\n$$\n将模型代入平均值可得\n$$\n\\bar{X}_{n} = \\frac{1}{n}\\sum_{i=1}^{n} \\left(T + \\epsilon_{i}\\right) = T + \\frac{1}{n}\\sum_{i=1}^{n} \\epsilon_{i}.\n$$\n定义噪声平均值\n$$\n\\bar{\\epsilon}_{n} \\equiv \\frac{1}{n}\\sum_{i=1}^{n} \\epsilon_{i}.\n$$\n则\n$$\n\\bar{X}_{n} = T + \\bar{\\epsilon}_{n}.\n$$\n\n根据大数强定律（或弱定律，对于依概率收敛已经足够），由于 $\\epsilon_{i}$ 是独立同分布且具有有限均值 $E[\\epsilon_{i}] = 0$，我们有\n$$\n\\bar{\\epsilon}_{n} \\xrightarrow{p} 0 \\quad \\text{as } n \\to \\infty.\n$$\n因此，对于任何 $\\delta  0$，\n$$\nP\\left(\\left|\\bar{X}_{n} - T\\right| \\geq \\delta\\right) \n= P\\left(\\left|T + \\bar{\\epsilon}_{n} - T\\right| \\geq \\delta\\right) \n= P\\left(\\left|\\bar{\\epsilon}_{n}\\right| \\geq \\delta\\right) \\to 0 \\quad \\text{as } n \\to \\infty.\n$$\n这直接证明了\n$$\n\\bar{X}_{n} \\xrightarrow{p} T.\n$$\n等价地，依概率收敛的极限 $L$ 是随机变量 $T$（而不是常数 $\\mu$），因为公共项 $T$ 不会在传感器之间被平均掉，而独立的噪声项则会被平均掉。为了完整起见，请注意对于所有 $n$，$E[\\bar{X}_{n}] = \\mu$，并且 $\\text{Var}(\\bar{X}_{n}) = \\sigma_{T}^{2} + \\sigma_{\\epsilon}^{2}/n \\to \\sigma_{T}^{2}$，这与依概率收敛到 $T$ 而不是一个常数是一致的。",
            "answer": "$$\\boxed{T}$$"
        }
    ]
}