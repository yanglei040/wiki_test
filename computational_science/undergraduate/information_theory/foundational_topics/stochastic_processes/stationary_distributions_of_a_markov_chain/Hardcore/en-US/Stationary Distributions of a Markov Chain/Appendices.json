{
    "hands_on_practices": [
        {
            "introduction": "Calculating the stationary distribution is a foundational skill for analyzing Markov chains. This first practice problem guides you through the essential mechanics of this process. By translating a real-world scenario into a transition matrix $P$ and solving the core equation $\\pi P = \\pi$, you will build a solid base for understanding the long-term behavior of these systems.",
            "id": "1660504",
            "problem": "An algorithmic trading model classifies a stock's daily behavior into one of two states: State 1 (Uptrend) or State 2 (Downtrend). The model's prediction for the next day's state depends only on the current day's state. If the stock is in an Uptrend today, the probability it transitions to a Downtrend tomorrow is $\\alpha$. If the stock is in a Downtrend today, the probability it transitions to an Uptrend tomorrow is $3\\alpha$. The parameter $\\alpha$ is determined by market conditions and is constrained such that $0 < \\alpha < 1/3$.\n\nAfter the system has been running for a very long time, it is expected to settle into a steady state. Determine the vector $\\pi = [\\pi_1, \\pi_2]$ representing the long-term proportion of days the stock spends in the Uptrend state ($\\pi_1$) and the Downtrend state ($\\pi_2$), respectively. Express your answer as a function of $\\alpha$.",
            "solution": "Let the two states be indexed by $1$ (Uptrend) and $2$ (Downtrend). The one-step transition matrix $P$ with rows as current state and columns as next state is\n$$\nP=\\begin{pmatrix}\n1-\\alpha & \\alpha \\\\\n3\\alpha & 1-3\\alpha\n\\end{pmatrix},\n$$\nsince from state $1$ the chain stays in $1$ with probability $1-\\alpha$ and goes to $2$ with probability $\\alpha$, while from state $2$ it goes to $1$ with probability $3\\alpha$ and stays in $2$ with probability $1-3\\alpha$. The constraint $0<\\alpha<\\frac{1}{3}$ ensures $P$ is stochastic with strictly positive diagonal entries, so the chain is irreducible and aperiodic and has a unique stationary distribution.\n\nLet $\\pi=[\\pi_{1},\\pi_{2}]$ denote the stationary distribution. By definition, it satisfies $\\pi=\\pi P$ and the normalization $\\pi_{1}+\\pi_{2}=1$. Writing the balance equations from $\\pi=\\pi P$ gives\n$$\n\\pi_{1}=\\pi_{1}(1-\\alpha)+\\pi_{2}(3\\alpha), \\quad \\pi_{2}=\\pi_{1}\\alpha+\\pi_{2}(1-3\\alpha).\n$$\nFrom the first equation,\n$$\n\\pi_{1}-\\pi_{1}(1-\\alpha)=3\\alpha\\,\\pi_{2}\\;\\;\\Longrightarrow\\;\\;\\alpha\\,\\pi_{1}=3\\alpha\\,\\pi_{2}\\;\\;\\Longrightarrow\\;\\;\\pi_{1}=3\\pi_{2},\n$$\nwhere we used $\\alpha>0$ to divide both sides by $\\alpha$. Using the normalization $\\pi_{1}+\\pi_{2}=1$,\n$$\n3\\pi_{2}+\\pi_{2}=1 \\;\\;\\Longrightarrow\\;\\; 4\\pi_{2}=1 \\;\\;\\Longrightarrow\\;\\; \\pi_{2}=\\frac{1}{4}, \\quad \\pi_{1}=\\frac{3}{4}.\n$$\nThus the long-run proportion of days in each state is independent of $\\alpha$ (within the given range) and equals $[\\frac{3}{4},\\frac{1}{4}]$.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{3}{4} & \\frac{1}{4} \\end{pmatrix}}$$"
        },
        {
            "introduction": "While the algebraic method is always applicable, recognizing special structures in a transition matrix can offer significant shortcuts. This exercise  introduces the concept of a doubly stochastic matrix, a case where the system's inherent symmetry leads to a remarkably simple and intuitive stationary distribution. Mastering this concept allows you to solve certain problems almost by inspection, highlighting the power of theoretical insights in practical applications.",
            "id": "1660511",
            "problem": "An autonomous maintenance bot operates within a closed network of 4 identical servers, labeled S1, S2, S3, and S4. The bot's movement between servers can be modeled as a discrete-time Markov chain. The state of the system is the current location of the bot. At each time step, if the bot is at a particular server, it has a probability $p$ of remaining at that server for the next time step. If it decides to move, it chooses any of the other 3 servers with equal probability. The probability of remaining at the current server is given as $p = 0.4$. After the system has been running for a very long time, it is guaranteed to reach a steady state. Determine the stationary probability distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3, \\pi_4)$, where $\\pi_i$ is the long-term probability of finding the bot at server Si. Express your answer as a row vector of probabilities.",
            "solution": "Let the state space of the Markov chain be $S = \\{1, 2, 3, 4\\}$, corresponding to the servers S1, S2, S3, and S4. We need to find the stationary distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3, \\pi_4)$.\n\nFirst, let's construct the one-step transition probability matrix $P$. The element $P_{ij}$ is the probability of transitioning from state $i$ to state $j$.\n\nThe problem states that the probability of remaining at the current server is $p = 0.4$. This corresponds to the diagonal elements of the matrix:\n$P_{ii} = p = 0.4$ for $i \\in \\{1, 2, 3, 4\\}$.\n\nIf the bot decides to move, which occurs with probability $1-p = 1 - 0.4 = 0.6$, it chooses any of the other 3 servers with equal probability. So, the probability of moving from server $i$ to a different server $j$ is:\n$P_{ij} = \\frac{1-p}{3} = \\frac{0.6}{3} = 0.2$ for $i \\neq j$.\n\nThus, the transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n0.4 & 0.2 & 0.2 & 0.2 \\\\\n0.2 & 0.4 & 0.2 & 0.2 \\\\\n0.2 & 0.2 & 0.4 & 0.2 \\\\\n0.2 & 0.2 & 0.2 & 0.4\n\\end{pmatrix}\n$$\nThe stationary distribution $\\pi$ is a probability vector that satisfies two conditions:\n1. $\\pi P = \\pi$\n2. $\\sum_{i=1}^{4} \\pi_i = 1$\n\nThe equation $\\pi P = \\pi$ gives a system of linear equations:\n1. $0.4\\pi_1 + 0.2\\pi_2 + 0.2\\pi_3 + 0.2\\pi_4 = \\pi_1$\n2. $0.2\\pi_1 + 0.4\\pi_2 + 0.2\\pi_3 + 0.2\\pi_4 = \\pi_2$\n3. $0.2\\pi_1 + 0.2\\pi_2 + 0.4\\pi_3 + 0.2\\pi_4 = \\pi_3$\n4. $0.2\\pi_1 + 0.2\\pi_2 + 0.2\\pi_3 + 0.4\\pi_4 = \\pi_4$\n\nLet's analyze the first equation:\n$0.4\\pi_1 + 0.2(\\pi_2 + \\pi_3 + \\pi_4) = \\pi_1$\n$0.2(\\pi_2 + \\pi_3 + \\pi_4) = \\pi_1 - 0.4\\pi_1$\n$0.2(\\pi_2 + \\pi_3 + \\pi_4) = 0.6\\pi_1$\n$\\pi_2 + \\pi_3 + \\pi_4 = 3\\pi_1$\n\nFrom the normalization condition, we know that $\\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 = 1$, which implies $\\pi_2 + \\pi_3 + \\pi_4 = 1 - \\pi_1$.\nSubstituting this into our derived equation:\n$1 - \\pi_1 = 3\\pi_1$\n$1 = 4\\pi_1$\n$\\pi_1 = \\frac{1}{4}$\n\nDue to the symmetry of the transition matrix and the problem setup (all servers are identical), we can infer that all stationary probabilities must be equal: $\\pi_1 = \\pi_2 = \\pi_3 = \\pi_4$.\nWe can verify this. If we had started with the second equation, we would have found $\\pi_1 + \\pi_3 + \\pi_4 = 3\\pi_2$, leading to $\\pi_2 = 1/4$, and so on for $\\pi_3$ and $\\pi_4$.\n\nUsing the relation $\\pi_1 = \\pi_2 = \\pi_3 = \\pi_4$ in the normalization condition:\n$\\pi_1 + \\pi_1 + \\pi_1 + \\pi_1 = 1$\n$4\\pi_1 = 1$\n$\\pi_1 = \\frac{1}{4}$\n\nSo, all components of the stationary distribution are equal to $1/4$.\nThe stationary distribution vector is $\\pi = (\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})$.\n\nAlternatively, one could notice that the transition matrix $P$ is doubly stochastic. A matrix is doubly stochastic if both its rows and its columns sum to 1.\n- Each row of $P$ sums to $0.4 + 3 \\times 0.2 = 0.4 + 0.6 = 1$. This is always true for a transition matrix.\n- Each column of $P$ also sums to $0.4 + 3 \\times 0.2 = 1$. For example, the first column sum is $P_{11} + P_{21} + P_{31} + P_{41} = 0.4 + 0.2 + 0.2 + 0.2 = 1$.\n\nFor a finite-state, irreducible, and aperiodic Markov chain, if the transition matrix is doubly stochastic, the unique stationary distribution is the uniform distribution over the states. The chain is irreducible because it's possible to go from any server to any other server (all off-diagonal elements are non-zero). It is aperiodic because there's a non-zero probability of staying in the same state ($P_{ii} > 0$).\nSince there are $N=4$ states, the uniform distribution is given by $\\pi_i = 1/N = 1/4$ for all $i$.\nThis gives the same result: $\\pi = (\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})$.\nAs a row vector of probabilities, the answer is $\\begin{pmatrix} \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} \\end{pmatrix}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} \\end{pmatrix}}$$"
        },
        {
            "introduction": "Our final practice problem flips the script, moving from analysis to design. Instead of predicting the long-term behavior of a given system, we now ask: how can we engineer a system to achieve a desired long-term equilibrium? This exercise  challenges you to work backward by constructing a general transition matrix $P$ that produces a specific target stationary distribution $\\pi$. This type of 'inverse problem' is at the heart of applying Markov chain theory to fields like user experience design, economics, and systems engineering.",
            "id": "1660512",
            "problem": "A team designing a social media platform models its user base as a discrete-time Markov chain with two states: State 1 (Active) and State 2 (Inactive). The transition from one state to another in a single time step is described by a 2x2 right stochastic transition matrix $P$, where the element $p_{ij}$ is the probability of transitioning from state $i$ to state $j$:\n$$\nP = \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{21} & p_{22} \\end{pmatrix}\n$$\nThe team's goal is to engineer platform features such that, in the long-term equilibrium, a fraction $\\alpha$ of the users are Active and $1-\\alpha$ are Inactive. Here, $\\alpha$ is a design parameter such that $0 < \\alpha < 1$. This desired equilibrium corresponds to a stationary distribution $\\pi = [\\alpha, 1-\\alpha]$ for the Markov chain.\n\nTo understand their design choices, the team needs a general expression for any valid transition matrix $P$ that yields this stationary distribution. Let $x$ be the probability that an Inactive user becomes Active in one time step (i.e., $x = p_{21}$). Construct the most general form of the transition matrix $P$ in terms of the parameters $\\alpha$ and $x$. Express your answer as a 2x2 matrix.",
            "solution": "The problem asks for the general form of a 2x2 transition matrix $P$ that has a given stationary distribution $\\pi = [\\alpha, 1-\\alpha]$.\n\nA stationary distribution $\\pi$ for a Markov chain with transition matrix $P$ must satisfy the equation:\n$$\n\\pi P = \\pi\n$$\n\nThe transition matrix $P$ is a right stochastic matrix, which means that the elements in each row must sum to 1. For a 2x2 matrix, this gives us two constraints:\n1.  $p_{11} + p_{12} = 1 \\implies p_{11} = 1 - p_{12}$\n2.  $p_{21} + p_{22} = 1 \\implies p_{22} = 1 - p_{21}$\n\nThe problem defines the parameter $x$ as the probability of an inactive user becoming active, which corresponds to the transition from State 2 to State 1. Thus, $x = p_{21}$.\nUsing this information, we can write the transition matrix $P$ in terms of two unknown probabilities, $p_{12}$ and $x$:\n$$\nP = \\begin{pmatrix} 1 - p_{12} & p_{12} \\\\ x & 1 - x \\end{pmatrix}\n$$\n\nNow, we can substitute $\\pi = [\\alpha, 1-\\alpha]$ and the matrix $P$ into the stationary distribution equation $\\pi P = \\pi$:\n$$\n[\\alpha, 1-\\alpha] \\begin{pmatrix} 1 - p_{12} & p_{12} \\\\ x & 1 - x \\end{pmatrix} = [\\alpha, 1-\\alpha]\n$$\n\nPerforming the matrix-vector multiplication on the left side gives a new row vector:\n$$\n[\\alpha(1 - p_{12}) + (1-\\alpha)x, \\quad \\alpha p_{12} + (1-\\alpha)(1-x)] = [\\alpha, 1-\\alpha]\n$$\n\nThis equality of vectors yields a system of two linear equations. We only need to solve one of them, as they are linearly dependent. Let's use the first component:\n$$\n\\alpha(1 - p_{12}) + (1-\\alpha)x = \\alpha\n$$\n\nNow, we solve for $p_{12}$ in terms of $\\alpha$ and $x$:\n$$\n\\alpha - \\alpha p_{12} + x - \\alpha x = \\alpha\n$$\n$$\n-\\alpha p_{12} + (1-\\alpha)x = 0\n$$\n$$\n\\alpha p_{12} = (1-\\alpha)x\n$$\nSince the problem states $0 < \\alpha < 1$, $\\alpha$ is non-zero, and we can divide by it:\n$$\np_{12} = \\frac{(1-\\alpha)x}{\\alpha}\n$$\n\nNow we have found the expression for $p_{12}$. We can substitute this back into our general form for the matrix $P$. The elements of $P$ are:\n*   $p_{11} = 1 - p_{12} = 1 - \\frac{(1-\\alpha)x}{\\alpha}$\n*   $p_{12} = \\frac{(1-\\alpha)x}{\\alpha}$\n*   $p_{21} = x$\n*   $p_{22} = 1 - x$\n\nConstructing the matrix with these elements gives the final general form for $P$:\n$$\nP = \\begin{pmatrix} 1 - \\frac{(1-\\alpha)x}{\\alpha} & \\frac{(1-\\alpha)x}{\\alpha} \\\\ x & 1-x \\end{pmatrix}\n$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 - \\frac{(1-\\alpha)x}{\\alpha} & \\frac{(1-\\alpha)x}{\\alpha} \\\\\nx & 1-x\n\\end{pmatrix}\n}\n$$"
        }
    ]
}