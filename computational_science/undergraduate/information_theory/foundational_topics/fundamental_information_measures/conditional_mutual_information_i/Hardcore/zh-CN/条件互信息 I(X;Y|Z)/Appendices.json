{
    "hands_on_practices": [
        {
            "introduction": "我们从一个基本属性开始。当两个变量都是第三个变量的确定性函数时，一旦我们知道了这个共同原因，这两个变量之间还共享多少信息？这个练习  探讨了这种情况，并帮助我们建立一个重要的基准理解：对共同原因进行条件化会消除其派生效应之间的所有相关性，使得条件互信息为零。",
            "id": "1612854",
            "problem": "在一个自动驾驶汽车的安全系统中，一个主激光雷达（Light Detection and Ranging, LIDAR）传感器测量与前方障碍物的距离。设此距离由离散随机变量 $X$ 表示。该测量值被输入到两个独立的板载处理单元。\n\n1.  威胁评估模块（Threat Assessment Module, TAM）处理距离 $X$ 以确定一个“威胁等级”，我们用另一个随机变量 $Y$ 来表示。$Y$ 的值由 $X$ 的值通过一个固定的确定性函数完全确定。\n2.  主动安全协议（Active Safety Protocol, ASP）单元也处理距离 $X$，以作出是否预充液压制动器的二元决策。我们用随机变量 $Z$ 来表示这个决策。$Z$ 的值也由 $X$ 的值通过另一个固定的确定性函数完全确定。\n\n在此设定下，其中 $Y$ 和 $Z$ 都是 $X$ 的确定性函数，计算在给定激光雷达测量值 $X$ 的情况下，威胁等级 $Y$ 和制动决策 $Z$ 之间的条件互信息 $I(Y; Z | X)$。\n\n请用一个以比特为单位的数值表示你的答案。",
            "solution": "设 $X$ 是表示激光雷达测量值的离散随机变量，并设 $Y=f(X)$ 和 $Z=g(X)$ 是 $X$ 的确定性函数。我们需要计算条件互信息 $I(Y; Z \\mid X)$。\n\n根据定义，条件互信息可以写作\n$$\nI(Y; Z \\mid X) = H(Y \\mid X) - H(Y \\mid Z, X).\n$$\n我们对每一项进行评估。\n\n因为 $Y$ 是 $X$ 的一个确定性函数，对于任何 $x$，我们有当 $y=f(x)$ 时 $p_{Y \\mid X}(y \\mid x) = 1$，否则为 $0$。因此，\n$$\nH(Y \\mid X=x) = -\\sum_{y} p_{Y \\mid X}(y \\mid x) \\log_{2} p_{Y \\mid X}(y \\mid x) = -1 \\cdot \\log_{2}(1) = 0.\n$$\n对 $X$ 求平均可得\n$$\nH(Y \\mid X) = \\sum_{x} p_{X}(x) H(Y \\mid X=x) = 0.\n$$\n\n接下来，考虑 $H(Y \\mid Z, X)$。因为 $Y=f(X)$ 只依赖于 $X$，所以在已知 $X$ 的情况下，进一步以 $Z$ 为条件并不会增加关于 $Y$ 的不确定性。对于任何 $(x,z)$，$Y$ 仍然是 $f(x)$ 的概率为 $1$，因此\n$$\nH(Y \\mid Z=z, X=x) = 0 \\quad \\text{and thus} \\quad H(Y \\mid Z, X) = 0.\n$$\n\n代入定义中，\n$$\nI(Y; Z \\mid X) = H(Y \\mid X) - H(Y \\mid Z, X) = 0 - 0 = 0.\n$$\n\n等价地，可以使用恒等式\n$$\nI(Y; Z \\mid X) = H(Y \\mid X) + H(Z \\mid X) - H(Y, Z \\mid X),\n$$\n并注意到由于 $(Y,Z)$ 是 $X$ 的确定性函数，每个条件熵都为零，从而得到相同的结果。\n\n因此，在给定 $X$ 的情况下，$Y$ 和 $Z$ 之间的条件互信息为零比特。",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "接下来，我们来探索一个反直觉的现象。两个完全独立的变量，在对一个与它们相关的变量进行条件化后，会变得相互依赖吗？这个练习  揭示了著名的“解释消除”(explaining away)效应，这是一个关键概念，表明条件化并不总是像人们直观预期的那样减少不确定性，有时反而会引入新的关联。",
            "id": "1612850",
            "problem": "考虑一个简单的数字通信系统，该系统包含两个独立的二进制信源，信源1和信源2。每个信源各自生成一个比特，分别由随机变量 $X_1$ 和 $X_2$ 表示。对于每个信源，其生成的比特为“0”的概率为0.5，为“1”的概率也为0.5。\n\n一个监测站接收这两个比特并计算它们的和，该和由随机变量 $Z = X_1 + X_2$ 定义。然后观测到这个和 $Z$ 的值。我们感兴趣的是，在已知它们的和 $Z$ 的情况下，量化信源1的比特提供了多少关于信源2比特的信息。这是在观测到它们的和之后，两个信源之间剩余的统计依赖性的度量。\n\n计算条件互信息 $I(X_1; X_2 | Z)$。所有涉及对数的计算都必须以2为底。将您的最终答案以比特为单位表示为十进制数值。",
            "solution": "设 $X_{1}$ 和 $X_{2}$ 是独立的 $\\text{Bernoulli}\\left(\\frac{1}{2}\\right)$ 随机变量。定义 $Z=X_{1}+X_{2}$，其取值范围为 $\\{0,1,2\\}$，概率分布为\n$$\nP(Z=0)=\\frac{1}{4},\\quad P(Z=1)=\\frac{1}{2},\\quad P(Z=2)=\\frac{1}{4}.\n$$\n条件互信息为\n$$\nI(X_{1};X_{2}\\mid Z)=\\sum_{z}P(z)\\,I(X_{1};X_{2}\\mid Z=z),\n$$\n其中所有熵和对数均以2为底（单位为比特）。\n\n对每个 $z$ 使用公式 $I(X_{1};X_{2}\\mid Z=z)=H(X_{1}\\mid Z=z)-H(X_{1}\\mid X_{2},Z=z)$ 计算 $I(X_{1};X_{2}\\mid Z=z)$。\n\n1) 对于 $z=0$：只有 $(X_{1},X_{2})=(0,0)$ 是可能的，因此 $H(X_{1}\\mid Z=0)=0$ 且 $H(X_{1}\\mid X_{2},Z=0)=0$。所以 $I(X_{1};X_{2}\\mid Z=0)=0$。\n\n2) 对于 $z=2$：只有 $(X_{1},X_{2})=(1,1)$ 是可能的，因此 $H(X_{1}\\mid Z=2)=0$ 且 $H(X_{1}\\mid X_{2},Z=2)=0$。所以 $I(X_{1};X_{2}\\mid Z=2)=0$。\n\n3) 对于 $z=1$：数对 $(0,1)$ 和 $(1,0)$ 以相等的概率 $\\frac{1}{2}$ 出现。因此，在 $Z=1$ 的条件下，$X_1$ 服从 $\\text{Bernoulli}\\left(\\frac{1}{2}\\right)$ 分布，得到\n$$\nH(X_{1}\\mid Z=1)=-\\left(\\tfrac{1}{2}\\log_{2}\\tfrac{1}{2}+\\tfrac{1}{2}\\log_{2}\\tfrac{1}{2}\\right)=1.\n$$\n在给定 $Z=1$ 和 $X_{2}$ 的情况下，$X_{1}$ 由 $X_{1}=1-X_{2}$ 唯一确定，所以 $H(X_{1}\\mid X_{2},Z=1)=0$。因此 $I(X_{1};X_{2}\\mid Z=1)=1$。\n\n对 $Z$ 取平均值：\n$$\nI(X_{1};X_{2}\\mid Z)=\\frac{1}{4}\\cdot 0+\\frac{1}{2}\\cdot 1+\\frac{1}{4}\\cdot 0=\\frac{1}{2}.\n$$\n因此，条件互信息为 $0.5$ 比特。",
            "answer": "$$\\boxed{0.5}$$"
        },
        {
            "introduction": "综合前面的例子，这个问题将展示条件化的影响如何根据具体的条件值发生巨大变化。通过这个练习 ，我们将看到对于同一组变量，以某个结果为条件会使它们变得独立，而以另一个结果为条件则会使它们完全相关。这为我们理解“条件”在信息论中的强大作用提供了一个更全面的视角。",
            "id": "1612830",
            "problem": "一个电子游戏从集合 $\\{1, 2, 3, 4, 5, 6\\}$ 中生成一个随机整数结果 $\\omega$。这个过程模拟了掷一个均匀的六面骰子一次，所以每个结果 $\\omega$ 的概率都是 $1/6$。根据这个结果，确定三个二元随机变量 $X$、$Y$ 和 $Z$ 如下：\n\n-   如果结果 $\\omega$ 是一个奇数，则 $X=1$；否则 $X=0$。\n-   如果结果 $\\omega$ 是一个素数，则 $Y=1$；否则 $Y=0$。在本问题中，结果集合中的素数是 $\\{2, 3, 5\\}$。\n-   如果结果 $\\omega$ 严格大于 4，则 $Z=1$；否则 $Z=0$。\n\n计算条件互信息 $I(X; Y | Z)$。请用一个封闭形式的解析表达式来表示你的答案，单位为比特。请注意，以比特为单位的信息量对应于在熵的计算中使用以 2 为底的对数。",
            "solution": "令 $\\Omega=\\{1,2,3,4,5,6\\}$，对于每个结果，其概率 $P(\\omega)=\\frac{1}{6}$。定义\n- 对于 $\\{1,3,5\\}$，$X=1$，对于 $\\{2,4,6\\}$，$X=0$。\n- 对于 $\\{2,3,5\\}$，$Y=1$，对于 $\\{1,4,6\\}$，$Y=0$。\n- 对于 $\\{5,6\\}$，$Z=1$，对于 $\\{1,2,3,4\\}$，$Z=0$。\n\n我们要求解 $I(X;Y|Z)$，它可以写成\n$$\nI(X;Y|Z)=\\sum_{z}P(z)\\,I(X;Y\\,|\\,Z=z)\n=\\sum_{z}P(z)\\sum_{x,y}P(x,y\\,|\\,z)\\,\\log_{2}\\!\\left(\\frac{P(x,y\\,|\\,z)}{P(x\\,|\\,z)P(y\\,|\\,z)}\\right).\n$$\n\n首先，$P(Z=1)=\\frac{2}{6}=\\frac{1}{3}$ 且 $P(Z=0)=\\frac{4}{6}=\\frac{2}{3}$。\n\n情况 $Z=1$：结果为 $\\{5,6\\}$，每个的条件概率为 $\\frac{1}{2}$。对于 $\\omega=5$，我们有 $(X,Y)=(1,1)$；对于 $\\omega=6$，我们有 $(X,Y)=(0,0)$。因此 $P(X=1\\,|\\,Z=1)=P(Y=1\\,|\\,Z=1)=\\frac{1}{2}$ 且 $P(X=Y\\,|\\,Z=1)=1$。因此，在给定 $Z=1$ 的条件下，$Y$ 是 $X$ 的确定性函数（反之亦然），所以\n$$\nI(X;Y\\,|\\,Z=1)=H(X\\,|\\,Z=1)-H(X\\,|\\,Y,Z=1)=H(X\\,|\\,Z=1).\n$$\n因为 $P(X=1\\,|\\,Z=1)=\\frac{1}{2}$，\n$$\nH(X\\,|\\,Z=1)=-\\sum_{x\\in\\{0,1\\}}P(x\\,|\\,Z=1)\\log_{2}P(x\\,|\\,Z=1)=1,\n$$\n所以 $I(X;Y\\,|\\,Z=1)=1$。\n\n情况 $Z=0$：结果为 $\\{1,2,3,4\\}$，每个的条件概率为 $\\frac{1}{4}$。实现的 $(X,Y)$ 对为：来自 $\\omega=1$ 的 $(1,0)$，来自 $\\omega=2$ 的 $(0,1)$，来自 $\\omega=3$ 的 $(1,1)$，以及来自 $\\omega=4$ 的 $(0,0)$，每个的概率均为 $\\frac{1}{4}$。因此\n$$\nP(X=1\\,|\\,Z=0)=\\frac{1}{2},\\quad P(Y=1\\,|\\,Z=0)=\\frac{1}{2},\\quad P(X=x,Y=y\\,|\\,Z=0)=\\frac{1}{4}=P(X=x\\,|\\,Z=0)P(Y=y\\,|\\,Z=0),\n$$\n所以在给定 $Z=0$ 的条件下，$X$ 和 $Y$ 是独立的，因此\n$$\nI(X;Y\\,|\\,Z=0)=0.\n$$\n\n所以，\n$$\nI(X;Y\\,|\\,Z)=P(Z=1)\\,I(X;Y\\,|\\,Z=1)+P(Z=0)\\,I(X;Y\\,|\\,Z=0)=\\frac{1}{3}\\cdot 1+\\frac{2}{3}\\cdot 0=\\frac{1}{3}.\n$$\n\n为了完整起见，这与恒等式 $I(X;Y|Z)=H(X|Z)-H(X|Y,Z)$ 一致。确实，$H(X|Z=1)=1$ 且 $H(X|Z=0)=1$，所以 $H(X|Z)=1$。并且 $H(X|Y,Z=1)=0$ 且 $H(X|Y,Z=0)=1$，所以 $H(X|Y,Z)=\\frac{1}{3}\\cdot 0+\\frac{2}{3}\\cdot 1=\\frac{2}{3}$。因此 $I(X;Y|Z)=1-\\frac{2}{3}=\\frac{1}{3}$ 比特。",
            "answer": "$$\\boxed{\\frac{1}{3}}$$"
        }
    ]
}