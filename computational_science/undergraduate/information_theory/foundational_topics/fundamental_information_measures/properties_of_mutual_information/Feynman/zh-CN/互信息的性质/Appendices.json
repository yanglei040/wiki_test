{
    "hands_on_practices": [
        {
            "introduction": "本练习将带你从最基本的定义出发，计算互信息。通过一个简单的信号处理场景——一个信号 $X$ 经过一个平方运算单元得到 $Y$——我们将亲手计算 $I(X;Y)$。这个实践旨在加深你对“互信息是关于一个变量的不确定性的减少量”这一核心思想的理解，并揭示即使在确定性变换中，信息也可能因为变换的不可逆性而发生损失 。",
            "id": "1649998",
            "problem": "一个简单的数字传感器产生一个原始输出信号，由离散随机变量 $X$ 表示。信号 $X$ 可以等概率地取三个值之一，即 $\\{-1, 0, 1\\}$。该信号随后被馈送到一个信号处理单元，该单元根据函数 $Y = X^2$ 计算出一个新变量 $Y$。该变换有效地使系统对原始信号的符号不敏感。\n\n您的任务是计算原始信号 $X$ 和处理后信号 $Y$ 之间的互信息 $I(X;Y)$。这个量度量了（在信息论意义上）处理后信号 $Y$ 所提供的关于原始信号 $X$ 的信息。\n\n请将您的最终答案以比特为单位，表示为一个封闭形式的解析表达式。您的计算和最终答案应使用以2为底的对数（例如，$\\log_{2}(...)$）。",
            "solution": "互信息 $I(X;Y)$ 可以使用公式 $I(X;Y) = H(X) - H(X|Y)$ 来计算，其中 $H(X)$ 是随机变量 $X$ 的熵，$H(X|Y)$ 是在给定 $Y$ 的条件下 $X$ 的条件熵。我们将分别计算每一项。所有对数均以2为底，以满足答案以比特为单位的要求。\n\n首先，我们来计算源信号 $X$ 的熵，记为 $H(X)$。随机变量 $X$ 在集合 $\\{-1, 0, 1\\}$ 上是均匀分布的。因此，其各种结果的概率为：\n$P(X=-1) = \\frac{1}{3}$\n$P(X=0) = \\frac{1}{3}$\n$P(X=1) = \\frac{1}{3}$\n\n熵 $H(X)$ 由公式 $H(X) = -\\sum_{x} P(x) \\log_{2}(P(x))$ 给出。\n$$H(X) = - \\left( P(X=-1)\\log_{2}(P(X=-1)) + P(X=0)\\log_{2}(P(X=0)) + P(X=1)\\log_{2}(P(X=1)) \\right)$$\n$$H(X) = - \\left( \\frac{1}{3}\\log_{2}\\left(\\frac{1}{3}\\right) + \\frac{1}{3}\\log_{2}\\left(\\frac{1}{3}\\right) + \\frac{1}{3}\\log_{2}\\left(\\frac{1}{3}\\right) \\right)$$\n$$H(X) = -3 \\times \\frac{1}{3} \\log_{2}\\left(\\frac{1}{3}\\right) = -\\log_{2}\\left(\\frac{1}{3}\\right) = \\log_{2}(3)$$\n\n接下来，我们计算条件熵 $H(X|Y)$。其定义为 $H(X|Y) = \\sum_{y} P(y)H(X|Y=y)$。为此，我们首先需要求出 $Y$ 的概率分布。$Y=X^2$ 的可能值为：\n如果 $X=-1$，则 $Y = (-1)^2 = 1$。\n如果 $X=0$，则 $Y = (0)^2 = 0$。\n如果 $X=1$，则 $Y = (1)^2 = 1$。\n\n所以，$Y$ 的可能值集合为 $\\{0, 1\\}$。现在我们求它们的概率：\n事件 $Y=0$ 仅在 $X=0$ 时发生。所以，$P(Y=0) = P(X=0) = \\frac{1}{3}$。\n事件 $Y=1$ 在 $X=-1$ 或 $X=1$ 时发生。所以，$P(Y=1) = P(X=-1) + P(X=1) = \\frac{1}{3} + \\frac{1}{3} = \\frac{2}{3}$。\n\n现在我们可以计算对于每个 $y$ 值的条件熵：\n情况1：$Y=0$。\n给定 $Y=0$，我们可以确定 $X$ 必定为 0。不存在不确定性。条件概率分布 $P(X|Y=0)$ 为 $P(X=0|Y=0)=1$ 且对于 $x \\neq 0$ 有 $P(X=x|Y=0)=0$。\n条件熵为 $H(X|Y=0) = - \\sum_x P(x|Y=0) \\log_{2}(P(x|Y=0)) = - (1 \\cdot \\log_{2}(1)) = 0$。\n\n情况2：$Y=1$。\n给定 $Y=1$，我们知道 $X$ 可能为 $-1$ 或 $1$。我们需要条件概率：\n$P(X=-1|Y=1) = \\frac{P(X=-1, Y=1)}{P(Y=1)} = \\frac{P(X=-1)}{P(Y=1)} = \\frac{1/3}{2/3} = \\frac{1}{2}$。\n$P(X=1|Y=1) = \\frac{P(X=1, Y=1)}{P(Y=1)} = \\frac{P(X=1)}{P(Y=1)} = \\frac{1/3}{2/3} = \\frac{1}{2}$。\n条件熵为：\n$$H(X|Y=1) = - \\left( P(X=-1|Y=1)\\log_{2}(P(X=-1|Y=1)) + P(X=1|Y=1)\\log_{2}(P(X=1|Y=1)) \\right)$$\n$$H(X|Y=1) = - \\left( \\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right) + \\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right) \\right) = - \\log_{2}\\left(\\frac{1}{2}\\right) = \\log_{2}(2) = 1$$\n\n现在我们可以计算总条件熵 $H(X|Y)$：\n$$H(X|Y) = P(Y=0)H(X|Y=0) + P(Y=1)H(X|Y=1)$$\n$$H(X|Y) = \\left(\\frac{1}{3}\\right) \\cdot (0) + \\left(\\frac{2}{3}\\right) \\cdot (1) = \\frac{2}{3}$$\n\n最后，我们计算互信息 $I(X;Y)$：\n$$I(X;Y) = H(X) - H(X|Y) = \\log_{2}(3) - \\frac{2}{3}$$\n这个表达式表示观察到 $Y$ 所提供的关于 $X$ 的信息量，单位为比特。",
            "answer": "$$\\boxed{\\log_{2}(3) - \\frac{2}{3}}$$"
        },
        {
            "introduction": "在处理多个相互关联的变量时，直接计算互信息可能很复杂。本练习通过一个简化的天气预报模型，让你应用熵的链式法则来解决问题。你将利用一个基于链式法则的基本恒等式，通过已知的信息量来推导未知的信息量，这展示了信息论工具在分析复杂系统中的强大作用 。",
            "id": "1650000",
            "problem": "一位信息论学家正在分析一个简化的天气预报模型。该模型涉及三个离散随机变量：\n- $Z$：代表大气压力类别，可以是“高”或“低”。\n- $Y$：代表温度类别，可以是“暖”或“冷”。\n- $X$：代表模型对次日天气的预报，可以是“晴”或“雨”。\n\n该理论家使用香农熵来量化这些变量之间的关系，香农熵用于衡量随机变量的平均不确定性。所有熵值均以比特为单位计算，这对应于其定义中使用了以2为底的对数。\n\n在分析了大量数据集后，该理论家确定了以下条件熵：\n1. 仅在给定压力 $Z$ 的条件下，预报 $X$ 的不确定性为 $H(X|Z) = 0.875$ 比特。\n2. 仅在给定压力 $Z$ 的条件下，温度 $Y$ 的不确定性为 $H(Y|Z) = 0.941$ 比特。\n3. 在同时给定预报 $X$ 和压力 $Z$ 的条件下，温度 $Y$ 的不确定性为 $H(Y|X,Z) = 0.726$ 比特。\n\n使用这些信息，计算在同时给定温度 $Y$ 和压力 $Z$ 的条件下，预报 $X$ 的不确定性，记作 $H(X|Y,Z)$。结果以比特为单位表示，并四舍五入到三位有效数字。",
            "solution": "我们使用熵的条件链式法则。对于任意随机变量 $X$、$Y$ 和 $Z$，链式法则给出\n$$\nH(X,Y|Z)=H(X|Z)+H(Y|X,Z)=H(Y|Z)+H(X|Y,Z).\n$$\n令两个展开式相等，解出 $H(X|Y,Z)$ 可得\n$$\nH(X|Y,Z)=H(X|Z)+H(Y|X,Z)-H(Y|Z).\n$$\n代入给定值，\n$$\nH(X|Y,Z)=0.875+0.726-0.941=0.660 \\text{ bits}.\n$$\n四舍五入到三位有效数字，结果为 $0.660$ 比特。",
            "answer": "$$\\boxed{0.660}$$"
        },
        {
            "introduction": "数据处理不等式是信息论的基石之一，它指出信息在处理过程中只会丢失或保持不变。本练习将这一重要原理置于一个实际的信号处理级联模型中，其中信号连续两次受到高斯噪声的干扰。通过求解在特定信息损失条件下噪声方差需要满足的条件，你将深入理解信息在多级系统中的传递规律，并掌握高斯信道下互信息的计算方法 。",
            "id": "1650010",
            "problem": "考虑一个简化的两级信号处理流水线模型。一个输入信号，由随机变量 $X$ 表示，通过第一级传输。在此过程中，它被一个由随机变量 $N_1$ 建模的加性噪声所损坏。第一级的输出为 $Y = X + N_1$。这个中间信号 $Y$ 接着被送入第二级，在第二级中它被另一个独立的加性噪声源 $N_2$ 进一步损坏，得到最终的输出信号 $Z = Y + N_2$。\n\n随机变量 $X$、$N_1$ 和 $N_2$ 都是相互独立的零均值高斯随机变量，其方差分别为 $\\sigma_X^2$、$\\sigma_{N_1}^2$ 和 $\\sigma_{N_2}^2$。为确保分析有意义，假设输入信号不是确定性的（$\\sigma_X^2 > 0$），且第一级是有噪声的（$\\sigma_{N_1}^2 > 0$）。\n\n第一级末端的信号质量由信噪比 (SNR) 来表征，定义为 $S_{in} = \\sigma_X^2 / \\sigma_{N_1}^2$。对于这个特定系统，测得 $S_{in} = 15$。\n\n根据数据处理不等式，关于原始信号 $X$ 的信息在信号通过级联传播时只会丢失，这意味着互信息 $I(X;Z)$ 小于或等于 $I(X;Y)$。您的任务是找到一个特定条件，在该条件下，最终输出端保留的信息恰好是中间阶段可用信息的 75%。\n\n计算使得关系式 $I(X; Z) = 0.75 \\cdot I(X; Y)$ 成立时，所需的噪声方差之比 $R = \\sigma_{N_2}^2 / \\sigma_{N_1}^2$。",
            "solution": "因为 $X$、$N_{1}$ 和 $N_{2}$ 是相互独立的零均值高斯随机变量，所以 $Y=X+N_{1}$ 和 $Z=X+N_{1}+N_{2}$ 也是高斯随机变量。对于输入为高斯分布的加性高斯信道，其互信息可以从微分熵得到：\n$$\nI(X;Y)=h(Y)-h(N_{1}).\n$$\n由于 $Y\\sim\\mathcal{N}\\!\\left(0,\\sigma_{X}^{2}+\\sigma_{N_{1}}^{2}\\right)$ 且 $N_{1}\\sim\\mathcal{N}\\!\\left(0,\\sigma_{N_{1}}^{2}\\right)$，使用 $h(\\mathcal{N}(0,\\sigma^{2}))=\\tfrac{1}{2}\\log_2\\!\\left(2\\pi e\\,\\sigma^{2}\\right)$ 可得\n$$\nI(X;Y)=\\frac{1}{2}\\log_2\\!\\left(\\frac{\\sigma_{X}^{2}+\\sigma_{N_{1}}^{2}}{\\sigma_{N_{1}}^{2}}\\right)=\\frac{1}{2}\\log_2\\!\\left(1+\\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2}}\\right).\n$$\n定义 $S_{in}=\\sigma_{X}^{2}/\\sigma_{N_{1}}^{2}$。则\n$$\nI(X;Y)=\\frac{1}{2}\\log_2(1+S_{in}).\n$$\n\n对于级联输出 $Z=X+N_{1}+N_{2}$，有效噪声是 $N_{1}+N_{2}$，其方差为 $\\sigma_{N_{1}}^{2}+\\sigma_{N_{2}}^{2}$，且与 $X$ 独立。因此\n$$\nI(X;Z)=\\frac{1}{2}\\log_2\\!\\left(1+\\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2}+\\sigma_{N_{2}}^{2}}\\right).\n$$\n引入 $R=\\sigma_{N_{2}}^{2}/\\sigma_{N_{1}}^{2}$，因此 $\\sigma_{N_{1}}^{2}+\\sigma_{N_{2}}^{2}=\\sigma_{N_{1}}^{2}(1+R)$ 且\n$$\nI(X;Z)=\\frac{1}{2}\\log_2\\!\\left(1+\\frac{S_{in}}{1+R}\\right).\n$$\n\n施加条件 $I(X;Z)=0.75\\,I(X;Y)$：\n$$\n\\frac{1}{2}\\log_2\\!\\left(1+\\frac{S_{in}}{1+R}\\right)=0.75\\cdot\\frac{1}{2}\\log_2(1+S_{in}).\n$$\n两边乘以 $2$ 并取指数：\n$$\n\\log_2\\!\\left(1+\\frac{S_{in}}{1+R}\\right)=0.75\\,\\log_2(1+S_{in})\n\\quad\\Longrightarrow\\quad\n1+\\frac{S_{in}}{1+R}=(1+S_{in})^{0.75}.\n$$\n解出 $R$：\n$$\n\\frac{S_{in}}{1+R}=(1+S_{in})^{0.75}-1\n\\;\\Longrightarrow\\;\n1+R=\\frac{S_{in}}{(1+S_{in})^{0.75}-1}\n\\;\\Longrightarrow\\;\nR=\\frac{S_{in}}{(1+S_{in})^{0.75}-1}-1.\n$$\n\n代入给定的 $S_{in}=15$，计算\n$$\nR=\\frac{15}{16^{0.75}-1}-1.\n$$\n注意到 $16^{0.75}=16^{3/4}=(2^{4})^{3/4}=2^{3}=8$，所以\n$$\nR=\\frac{15}{8-1}-1=\\frac{15}{7}-1=\\frac{8}{7}.\n$$",
            "answer": "$$\\boxed{\\frac{8}{7}}$$"
        }
    ]
}