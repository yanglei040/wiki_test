{
    "hands_on_practices": [
        {
            "introduction": "理论知识需要通过实践来巩固。一个真正均匀的随机数序列在用于蒙特卡洛积分时，应该能准确地估计出已知积分的值。本练习将指导您从零开始，通过估计一个理论值为零的积分（$\\int_0^1 \\sin(2\\pi k x)\\\\,dx = 0$），构建一个基于傅里叶分析的均匀性检验。您将运用中心极限定理来判断观测结果是否“出乎意料地”偏离零，从而将概率论、微积分和统计推断融会贯通。",
            "id": "3201350",
            "problem": "考虑一个独立同分布（i.i.d.）的随机变量序列 $U_1,U_2,\\dots,U_n$，其设计为单位区间 $[0,1]$ 上连续均匀分布的样本。对于任意固定的正整数 $k$，将积分 $$\\int_0^1 \\sin(2\\pi k x)\\,dx$$ 的蒙特卡洛估计量定义为经验平均值 $$\\widehat{\\mu}_k = \\frac{1}{n}\\sum_{i=1}^n \\sin(2\\pi k U_i),$$ 其中正弦函数以弧度计算。在完全均匀的条件下，该积分等于 $0$，因此一个设计良好的估计量应随着 $n$ 的增大而集中在 $0$ 附近。你的任务是设计并实现一个均匀性检验，该检验利用 $\\widehat{\\mu}_k$ 与 $0$ 的偏差来标记非均匀性。\n\n从概率论和统计学的基本定义出发，不使用任何预先给定的简化公式，推导出一个决策规则，该规则：\n- 在零假设（即 $U_i$ 是在 $[0,1]$ 上独立同分布的均匀变量）下，对 $\\widehat{\\mu}_k$ 的抽样分布进行建模。\n- 在 $[0,1]$ 上的均匀分布下，从第一性原理出发，计算整数 $k$ 对应的 $\\sin(2\\pi k U)$ 的方差。\n- 使用中心极限定理（CLT）来近似 $\\widehat{\\mu}_k$ 的分布，并获得一个阈值，用于判断是否存在统计上显著的与 $0$ 的偏差。\n- 在同时检验多个频率 $k$ 时，将族群错误率控制在预先指定的显著性水平 $\\alpha$。\n- 如果任何被检验的频率 $k$ 显示出根据你推导的阈值具有统计上显著的偏差，则标记为非均匀。\n\n实现一个完整的、可运行的程序，对以下测试套件执行此检验。在所有情况下，角度必须以弧度解释，显著性水平 $\\alpha$ 以小数形式表示（不带百分号）。每个案例都指定了样本大小 $n$、待检验的频率列表 $\\{k_j\\}$、显著性水平 $\\alpha$、用于可复现性的随机种子，以及生成序列 $\\{U_i\\}$ 的方法：\n\n- 情况1（正常路径，独立同分布均匀）：$n=5000$，$\\{k_j\\} = \\{1,2,3,4,5\\}$，$\\alpha=0.01$，种子 $42$，生成器：$[0,1]$ 上的独立同分布均匀分布。\n- 情况2（非均匀，带有正弦倾斜）：$n=4000$，$\\{k_j\\} = \\{1,2,3,4\\}$，$\\alpha=0.01$，种子 $123$，生成器：从 $[0,1]$ 上一个与 $1+\\varepsilon\\sin(2\\pi x)$ 成正比的密度函数进行接受-拒绝采样，其中 $\\varepsilon=0.3$。使用均匀包络，并以概率 $\\frac{1+\\varepsilon\\sin(2\\pi x)}{1+\\varepsilon}$ 接受一个提议值 $x$；重复此过程直到接受 $n$ 个样本。\n- 情况3（边界条件，小样本，独立同分布均匀）：$n=200$，$\\{k_j\\} = \\{1\\}$，$\\alpha=0.01$，种子 $987$，生成器：$[0,1]$ 上的独立同分布均匀分布。\n- 情况4（非均匀，带有单点质量的混合分布）：$n=3000$，$\\{k_j\\} = \\{1,2,3\\}$，$\\alpha=0.01$，种子 $7$，生成器：对于每个索引 $i$，从成功概率为 $p=0.2$ 的伯努利分布中抽取 $B_i$，如果 $B_i=1$，则设 $U_i = 0.9$；否则，从 $[0,1]$ 上的独立同分布均匀分布中抽取 $U_i$。\n\n你的程序必须为每个案例输出一个布尔值，指示序列是否通过均匀性检验（$\\text{True}$ 表示“未检测到显著偏差”，$\\text{False}$ 表示“被标记为非均匀”）。最终输出必须是一行，包含四个案例的四个布尔值，按顺序排列，格式为方括号内以逗号分隔的列表（例如，“[True,False,True,False]”）。",
            "solution": "该问题要求构建并实现一个统计检验，以评估区间 $[0,1]$ 上随机数序列 $U_1, U_2, \\dots, U_n$ 的均匀性。该检验基于正弦函数积分的蒙特卡洛估计量 $\\widehat{\\mu}_k = \\frac{1}{n}\\sum_{i=1}^n \\sin(2\\pi k U_i)$，其中频率 $\\{k_j\\}$ 为一组正整数。\n\n零假设 $H_0$ 是样本 $U_i$ 独立同分布（i.i.d.）于 $[0,1]$ 上的连续均匀分布，记为 $U_i \\sim \\text{i.i.d. Uniform}[0,1]$。如果对于任何被检验的频率 $k_j$，$\\widehat{\\mu}_{k_j}$ 与其在 $H_0$ 下的期望值的偏差在统计上是显著的，则检验必须将该序列标记为非均匀。推导过程必须从第一性原理出发。\n\n**步骤1：零假设下检验统计量的均值和方差**\n\n对于固定的正整数 $k$，令 $X_i^{(k)} = \\sin(2\\pi k U_i)$。估计量是样本均值 $\\widehat{\\mu}_k = \\frac{1}{n} \\sum_{i=1}^n X_i^{(k)}$。\n在 $H_0$ 下，$U_i$ 的概率密度函数为 $f_U(u) = 1$（当 $u \\in [0,1]$ 时），否则为 $0$。\n\n首先，我们计算 $X_i^{(k)}$ 的期望值：\n$$\n\\mu_X = E[X_i^{(k)}] = E[\\sin(2\\pi k U_i)] = \\int_{-\\infty}^{\\infty} \\sin(2\\pi k u) f_U(u) \\,du = \\int_0^1 \\sin(2\\pi k u) \\cdot 1 \\,du\n$$\n计算该积分：\n$$\n\\mu_X = \\left[ -\\frac{\\cos(2\\pi k u)}{2\\pi k} \\right]_0^1 = -\\frac{\\cos(2\\pi k)}{2\\pi k} - \\left(-\\frac{\\cos(0)}{2\\pi k}\\right)\n$$\n因为 $k$ 是正整数，所以 $\\cos(2\\pi k) = 1$ 且 $\\cos(0) = 1$。\n$$\n\\mu_X = -\\frac{1}{2\\pi k} + \\frac{1}{2\\pi k} = 0\n$$\n因此，估计量 $\\widehat{\\mu}_k$ 的期望值为 $E[\\widehat{\\mu}_k] = E\\left[\\frac{1}{n}\\sum_{i=1}^n X_i^{(k)}\\right] = \\frac{1}{n}\\sum_{i=1}^n E[X_i^{(k)}] = 0$。\n\n接下来，我们从第一性原理计算 $X_i^{(k)}$ 的方差：\n$$\n\\sigma_X^2 = \\text{Var}(X_i^{(k)}) = E\\left[(X_i^{(k)} - \\mu_X)^2\\right] = E\\left[(X_i^{(k)})^2\\right] - (\\mu_X)^2 = E[\\sin^2(2\\pi k U_i)] - 0^2\n$$\n我们通过积分计算期望：\n$$\nE[\\sin^2(2\\pi k U_i)] = \\int_0^1 \\sin^2(2\\pi k u) \\,du\n$$\n使用三角恒等式 $\\sin^2(\\theta) = \\frac{1 - \\cos(2\\theta)}{2}$：\n$$\n\\int_0^1 \\frac{1 - \\cos(2 \\cdot 2\\pi k u)}{2} \\,du = \\frac{1}{2} \\int_0^1 (1 - \\cos(4\\pi k u)) \\,du\n$$\n$$\n= \\frac{1}{2} \\left[ u - \\frac{\\sin(4\\pi k u)}{4\\pi k} \\right]_0^1 = \\frac{1}{2} \\left( \\left(1 - \\frac{\\sin(4\\pi k)}{4\\pi k}\\right) - \\left(0 - \\frac{\\sin(0)}{4\\pi k}\\right) \\right)\n$$\n因为 $k$ 是整数，所以 $\\sin(4\\pi k) = 0$ 且 $\\sin(0) = 0$。\n$$\n\\sigma_X^2 = E[\\sin^2(2\\pi k U_i)] = \\frac{1}{2}(1 - 0) = \\frac{1}{2}\n$$\n然后计算估计量 $\\widehat{\\mu}_k$ 的方差。因为 $U_i$ 是独立同分布的，所以 $X_i^{(k)}$ 也是独立同分布的。\n$$\n\\text{Var}(\\widehat{\\mu}_k) = \\text{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i^{(k)}\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i^{(k)}) = \\frac{1}{n^2} (n \\cdot \\sigma_X^2) = \\frac{\\sigma_X^2}{n} = \\frac{1}{2n}\n$$\n\n**步骤2：通过中心极限定理（CLT）得到检验统计量的分布**\n\n中心极限定理指出，对于足够大的样本量 $n$，独立同分布随机变量的样本均值 $\\widehat{\\mu}_k$ 的分布近似为正态分布。\n$$\n\\widehat{\\mu}_k \\approx \\mathcal{N}\\left(E[\\widehat{\\mu}_k], \\text{Var}(\\widehat{\\mu}_k)\\right) \\implies \\widehat{\\mu}_k \\approx \\mathcal{N}\\left(0, \\frac{1}{2n}\\right)\n$$\n为了构建假设检验，我们定义一个标准化的检验统计量 $Z_k$，在 $H_0$ 下，它服从标准正态分布 $\\mathcal{N}(0,1)$。\n$$\nZ_k = \\frac{\\widehat{\\mu}_k - E[\\widehat{\\mu}_k]}{\\sqrt{\\text{Var}(\\widehat{\\mu}_k)}} = \\frac{\\widehat{\\mu}_k - 0}{\\sqrt{1/(2n)}} = \\widehat{\\mu}_k \\sqrt{2n}\n$$\n因此，在 $H_0$ 下，$Z_k \\approx \\mathcal{N}(0,1)$。\n\n**步骤3：处理多重比较和制定决策规则**\n\n该问题要求检验一组 $m$ 个频率，记为 $\\{k_1, k_2, \\dots, k_m\\}$。这涉及到执行 $m$ 个同时的假设检验。如果我们以显著性水平 $\\alpha$ 对每个假设进行检验，那么犯至少一次第一类错误（假阳性）的概率，即族群错误率（FWER），将会显著高于 $\\alpha$。\n\n为了将 FWER 控制在指定的水平 $\\alpha$，我们使用 Bonferroni 校正。该方法将每次单独检验的显著性水平调整为 $\\alpha' = \\alpha/m$。根据联合界（union bound），这能确保 FWER 小于或等于 $\\alpha$。\n\n对于在显著性水平 $\\alpha'$ 下的单次检验，决策规则是如果观察到的检验统计量落在拒绝域中，则拒绝 $H_0$。对于标准正态变量 $Z$ 的双尾检验，拒绝域为 $|Z| > z_{\\text{crit}}$，其中 $z_{\\text{crit}}$ 是满足 $P(|Z| > z_{\\text{crit}}) = \\alpha'$ 的临界值。该临界值由 $z_{\\text{crit}} = \\Phi^{-1}(1 - \\alpha'/2)$ 给出，其中 $\\Phi^{-1}$ 是标准正态分布的分位数函数（逆累积分布函数）。\n\n结合这些要素，该系列检验的最终决策规则如下：\n1.  设频率集合为 $\\{k_1, k_2, \\dots, k_m\\}$。检验次数为 $m$。\n2.  总体显著性水平为 $\\alpha$。\n3.  每次检验经 Bonferroni 校正后的显著性水平为 $\\alpha' = \\alpha / m$。\n4.  所有检验的临界值为 $z_{\\text{crit}} = \\Phi^{-1}(1 - \\frac{\\alpha'}{2}) = \\Phi^{-1}(1 - \\frac{\\alpha}{2m})$。\n5.  对于集合中的每个频率 $k_j$：\n    a. 生成 $n$ 个样本的序列 $U_1, \\dots, U_n$。\n    b. 计算估计量 $\\widehat{\\mu}_{k_j} = \\frac{1}{n}\\sum_{i=1}^n \\sin(2\\pi k_j U_i)$。\n    c. 计算检验统计量 $Z_{k_j} = \\widehat{\\mu}_{k_j} \\sqrt{2n}$。\n6.  如果存在*任何* $j \\in \\{1, \\dots, m\\}$ 使得 $|Z_{k_j}| > z_{\\text{crit}}$，则拒绝总体零假设 $H_0$（即序列是均匀的）。如果满足此条件，我们将序列标记为非均匀（`False`）。\n7.  如果对于所有的 $j \\in \\{1, \\dots, m\\}$，都有 $|Z_{k_j}| \\le z_{\\text{crit}}$，我们则不拒绝 $H_0$，并断定序列通过均匀性检验（`True`）。\n\n这个综合性的程序构成了实现的基础。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Performs uniformity tests on four specified cases and prints the results.\n    \"\"\"\n    test_cases = [\n        {'n': 5000, 'k_list': [1, 2, 3, 4, 5], 'alpha': 0.01, 'seed': 42, 'generator': 'uniform'},\n        {'n': 4000, 'k_list': [1, 2, 3, 4], 'alpha': 0.01, 'seed': 123, 'generator': 'sine_tilt', 'params': {'epsilon': 0.3}},\n        {'n': 200, 'k_list': [1], 'alpha': 0.01, 'seed': 987, 'generator': 'uniform'},\n        {'n': 3000, 'k_list': [1, 2, 3], 'alpha': 0.01, 'seed': 7, 'generator': 'point_mass_mixture', 'params': {'p': 0.2, 'loc': 0.9}},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n = case['n']\n        k_list = case['k_list']\n        alpha = case['alpha']\n        seed = case['seed']\n        generator = case['generator']\n        params = case.get('params', {})\n\n        np.random.seed(seed)\n\n        # Step 1: Generate the sequence of random numbers U\n        samples = np.array([])\n        if generator == 'uniform':\n            samples = np.random.uniform(0, 1, n)\n        \n        elif generator == 'sine_tilt':\n            # Acceptance-rejection sampling from a density proportional to 1 + ε*sin(2*pi*x)\n            epsilon = params['epsilon']\n            # The normalizing constant for the envelope is M = 1 + ε\n            M = 1.0 + epsilon\n            generated_samples = []\n            while len(generated_samples)  n:\n                # Propose from a uniform distribution\n                x_proposal = np.random.uniform(0, 1)\n                # Generate a uniform random number for the acceptance check\n                u_check = np.random.uniform(0, 1)\n                # Calculate the acceptance probability\n                prob_accept = (1.0 + epsilon * np.sin(2 * np.pi * x_proposal)) / M\n                if u_check  prob_accept:\n                    generated_samples.append(x_proposal)\n            samples = np.array(generated_samples[:n])\n\n        elif generator == 'point_mass_mixture':\n            # Mixture model: with probability p, U_i = loc; otherwise, U_i is uniform\n            p = params['p']\n            loc = params['loc']\n            # Generate Bernoulli trials to decide between the two components\n            bernoulli_draws = np.random.binomial(1, p, n)\n            # Generate uniform samples for the continuous part\n            uniform_draws = np.random.uniform(0, 1, n)\n            # Combine them: if B=1, use loc; if B=0, use uniform_draw\n            samples = (1 - bernoulli_draws) * uniform_draws + bernoulli_draws * loc\n            \n        # Step 2: Set up the hypothesis test parameters\n        m = len(k_list)  # Number of simultaneous tests\n        alpha_prime = alpha / m  # Bonferroni corrected significance level\n        \n        # Calculate the two-tailed critical value from the standard normal distribution\n        z_crit = norm.ppf(1 - alpha_prime / 2)\n\n        # Step 3: Perform the test for each frequency k\n        is_uniform = True  # Assume uniform until a deviation is found\n        for k in k_list:\n            # Calculate the Monte Carlo estimator\n            mu_hat_k = np.mean(np.sin(2 * np.pi * k * samples))\n            \n            # Calculate the test statistic Z_k\n            z_k = mu_hat_k * np.sqrt(2 * n)\n            \n            # Check if the statistic exceeds the critical value\n            if np.abs(z_k) > z_crit:\n                is_uniform = False\n                break  # A single failure is enough to reject uniformity\n\n        results.append(is_uniform)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "接下来，我们将从分析固定的数据批次转向监控一个持续的数据流，这在实时质量控制中至关重要。本练习将探讨如何构建一个能够实时标记非均匀性的序列监视器。我们将以中心化随机数的累积和构建一个随机游走过程，并利用霍夫丁不等式（Hoeffding's inequality）为其推导出动态的“停止边界”，从而创建一个能够及早发现问题的预警系统。",
            "id": "3201429",
            "problem": "考虑一系列在单位区间上的独立均匀分布随机数，记为 $U_1, U_2, \\dots, U_N$，其中每个 $U_i$ 都作为 Uniform$(0,1)$ 独立同分布 (i.i.d.)。基本前提是 $U_i$ 的期望为 $\\mathbb{E}[U_i] = \\tfrac{1}{2}$ 且有界于区间 $[0,1]$ 内。定义中心化部分和 $S_k = \\sum_{i=1}^{k} \\left(U_i - \\tfrac{1}{2}\\right)$，在均匀性原假设下，这构成了一个零均值有界随机游走。\n\n你的任务是设计一个序贯均匀性监视器，当累积和 $S_k$ 首次离开由对称时变阈值 $\\pm h_k$ 界定的预定接受域时，该监视器会在该时刻 $k$ 触发一个标志。接受边界 $\\{h_k\\}_{k=1}^N$ 必须使用 Hoeffding 不等式和并集界论证，从针对有界独立变量的、经过充分检验的集中不等式原理中推导得出。这样，在 $U_i$ 是 i.i.d. Uniform$(0,1)$ 的原假设下，在任意时刻 $k \\in \\{1,2,\\dots,N\\}$ 穿越任一边界的概率至多为一个预设水平 $\\alpha \\in (0,1)$。\n\n监视器必须按如下方式运行：对于每个时刻 $k = 1, 2, \\dots, N$，将 $S_k$ 与边界 $\\pm h_k$ 进行比较，并在 $S_k \\ge h_k$ 或 $S_k \\le -h_k$ 时立即停止。监视器输出首次穿越时刻的带符号索引：如果上边界在时刻 $k^\\star$ 首次被穿越，则输出整数 $k^\\star$；如果下边界在时刻 $k^\\star$ 首次被穿越，则输出整数 $-k^\\star$；如果在所有 $k \\le N$ 的时刻都未发生穿越，则输出整数 $0$。\n\n为以下测试套件实现此监视器。每个测试用例都指定了序列长度 $N$、误报水平 $\\alpha$ 以及生成序列 $U_1, \\dots, U_N$ 的方法。随机序列必须使用指定的种子确定性地生成，以确保可复现性。\n\n测试套件：\n1. 用例 A (理想情况)：$N = 500$，$\\alpha = 0.01$，$U_i$ 作为 i.i.d. Uniform$(0,1)$ 生成，伪随机生成器种子为 $123$。\n2. 用例 B (正向偏差)：$N = 200$，$\\alpha = 0.01$，$U_i$ 生成方式为 $U_i = \\min\\{1, V_i + 0.2\\}$，其中 $V_i$ 是 i.i.d. Uniform$(0,1)$，种子为 $456$。\n3. 用例 C (负向偏差)：$N = 200$，$\\alpha = 0.01$，$U_i$ 生成方式为 $U_i = \\max\\{0, V_i - 0.2\\}$，其中 $V_i$ 是 i.i.d. Uniform$(0,1)$，种子为 $789$。\n4. 用例 D (边界条件，短序列)：$N = 1$，$\\alpha = 0.01$，$U_1 = 0.9$ (确定性值)。\n5. 用例 E (边缘情况，完全中心化)：$N = 300$，$\\alpha = 0.01$，对所有 $i$，$U_i = \\tfrac{1}{2}$ (确定性值)。\n\n你的程序必须为每个用例计算带符号的首次穿越索引，如上所定义，使用从集中不等式方法推导出的边界，且在原假设下，整个时间范围 $N$ 内的总体误报水平为 $\\alpha$。最终输出格式必须是一行，包含五个用例的结果，以逗号分隔，置于方括号内，无空格，并按上述用例顺序列出。例如，如果结果为整数 $r_1, r_2, r_3, r_4, r_5$，则必须精确输出为 `[r_1,r_2,r_3,r_4,r_5]`。",
            "solution": "问题陈述经过严格审阅，被确定是有效的。它在概率论和统计学方面有科学依据，提法恰当，目标明确，信息充分，并用客观、无歧义的语言表述。任务是实现一个针对随机数的序贯均匀性检验，该检验基于中心化部分和的随机游走，其停止边界通过 Hoeffding 不等式和并集界论证推导得出，以控制总体误报概率。\n\n问题的核心是为一个累积和序列 $S_k = \\sum_{i=1}^{k} \\left(U_i - \\frac{1}{2}\\right)$ 构建时变边界 $\\pm h_k$。在原假设下，$\\{U_i\\}_{i=1}^N$ 作为 $\\text{Uniform}(0,1)$ 独立同分布 (i.i.d.)。该边界必须确保随机游走在达到时刻 $N$ 之前的任何时间点穿越它们的概率不超过指定的水平 $\\alpha$。\n$$ P\\left(\\bigcup_{k=1}^{N} \\{|S_k| \\ge h_k\\}\\right) \\le \\alpha $$\n\n我们首先定义随机变量 $X_i = U_i - \\frac{1}{2}$。在原假设下，$X_i$ 是期望为 $\\mathbb{E}[X_i] = 0$ 的 i.i.d. 变量。由于 $U_i \\in [0,1]$，每个 $X_i$ 都有界于区间 $[-\\frac{1}{2}, \\frac{1}{2}]$ 内。每个 $X_i$ 的范围是 $(\\frac{1}{2}) - (-\\frac{1}{2}) = 1$。和为 $S_k = \\sum_{i=1}^k X_i$。\n\n我们应用 Hoeffding 不等式，它为有界独立随机变量之和的尾部概率提供了一个界。对于我们的和 $S_k$，该不等式为：\n$$ P(S_k \\ge t) \\le \\exp\\left( - \\frac{2t^2}{\\sum_{i=1}^k (b_i - a_i)^2} \\right) $$\n由于对所有 $i$ 都有 $b_i-a_i = 1$，分母变为 $\\sum_{i=1}^k 1^2 = k$。因此，\n$$ P(S_k \\ge t) \\le \\exp\\left( - \\frac{2t^2}{k} \\right) $$\n根据设定的对称性（$X_i$ vs $-X_i$），同样的界也适用于 $P(S_k \\le -t)$。对单个时间步 $k$ 使用并集界，我们得到一个双边界：\n$$ P(|S_k| \\ge t) = P(S_k \\ge t \\text{ or } S_k \\le -t) \\le 2 \\exp\\left( - \\frac{2t^2}{k} \\right) $$\n\n为控制在整个时间范围 $k=1, \\dots, N$ 内的总体误报率，我们对所有时间步使用并集界（也称为 Boole 不等式）。设 $A_k$ 为事件 $|S_k| \\ge h_k$。\n$$ P(\\text{any crossing}) = P\\left(\\bigcup_{k=1}^{N} A_k\\right) \\le \\sum_{k=1}^{N} P(A_k) = \\sum_{k=1}^{N} P(|S_k| \\ge h_k) $$\n我们可以用我们的 Hoeffding 界来替代和中的每一项：\n$$ \\sum_{k=1}^{N} P(|S_k| \\ge h_k) \\le \\sum_{k=1}^{N} 2 \\exp\\left( - \\frac{2h_k^2}{k} \\right) $$\n为确保总概率以 $\\alpha$ 为界，我们需要选择阈值 $\\{h_k\\}$，使得这个和小于或等于 $\\alpha$。一种直接且常用的方法是为每个单独检验的概率 $P(|S_k| \\ge h_k)$ 设置一个界，使其为 $\\alpha$ 的一个常数部分，例如 $\\alpha/N$。这是 Bonferroni 校正的一个应用。\n我们设定：\n$$ 2 \\exp\\left( - \\frac{2h_k^2}{k} \\right) = \\frac{\\alpha}{N} $$\n对 $h_k$ 求解此方程，我们得到边界的显式公式：\n$$ \\exp\\left( - \\frac{2h_k^2}{k} \\right) = \\frac{\\alpha}{2N} $$\n$$ - \\frac{2h_k^2}{k} = \\ln\\left(\\frac{\\alpha}{2N}\\right) $$\n$$ \\frac{2h_k^2}{k} = -\\ln\\left(\\frac{\\alpha}{2N}\\right) = \\ln\\left(\\frac{2N}{\\alpha}\\right) $$\n$$ h_k^2 = \\frac{k}{2} \\ln\\left(\\frac{2N}{\\alpha}\\right) $$\n$$ h_k = \\sqrt{\\frac{k}{2} \\ln\\left(\\frac{2N}{\\alpha}\\right)} $$\n采用此选择，概率界之和为 $\\sum_{k=1}^N \\frac{\\alpha}{N} = \\alpha$，满足了设计要求。\n\n监视程序随后按如下方式实现：\n1. 对于给定的测试用例（$N$、$\\alpha$ 和序列生成规则），预先计算边界的常数因子：$C = \\sqrt{\\frac{1}{2} \\ln(\\frac{2N}{\\alpha})}$。那么时刻 $k$ 的边界为 $h_k = C\\sqrt{k}$。\n2. 初始化累积和 $S_0 = 0$。\n3. 从 $k=1$ 迭代至 $N$：\n    a. 生成或获取第 $k$ 个值 $U_k$。\n    b. 更新中心化和：$S_k = S_{k-1} + (U_k - \\frac{1}{2})$。\n    c. 将 $S_k$ 与边界 $\\pm h_k$ 进行比较。\n    d. 如果 $S_k \\ge h_k$，停止并报告穿越时刻为 $k$。\n    e. 如果 $S_k \\le -h_k$，停止并报告穿越时刻为 $-k$。\n4. 如果循环完成而未发生任何边界穿越，则报告 $0$。\n\n一旦 $U_i$ 值序列被固定，该程序就是确定性的，它将被应用于每个指定的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_monitor(N, alpha, U_sequence):\n    \"\"\"\n    Runs the sequential uniformity monitor for a given sequence.\n\n    Args:\n        N (int): The maximum length of the sequence to monitor.\n        alpha (float): The desired overall false alarm probability.\n        U_sequence (np.ndarray): The sequence of numbers to test.\n\n    Returns:\n        int: The signed index of the first crossing time, or 0 if no crossing occurs.\n    \"\"\"\n    # Defensive check in case N=0 or alpha is invalid, although problem constraints\n    # make this unlikely. The log would be undefined for N=0.\n    if N == 0:\n        return 0\n    if not (0  alpha  1):\n        raise ValueError(\"alpha must be in (0,1)\")\n\n    # Pre-compute the constant part of the boundary calculation\n    # h_k = sqrt(k/2 * ln(2N/alpha)) = C * sqrt(k)\n    boundary_constant = np.sqrt(0.5 * np.log(2 * N / alpha))\n\n    # Initialize the centered cumulative sum\n    S_k = 0.0\n\n    # Iterate through the sequence, updating the sum and checking boundaries\n    for k_idx, u_val in enumerate(U_sequence):\n        k = k_idx + 1  # Time index is 1-based\n        S_k += u_val - 0.5\n        h_k = boundary_constant * np.sqrt(k)\n\n        if S_k >= h_k:\n            return k\n        if S_k = -h_k:\n            return -k\n\n    # If the loop completes without crossing, return 0\n    return 0\n\ndef solve():\n    \"\"\"\n    Solves the problem by running the monitor on all specified test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'id': 'A', 'N': 500, 'alpha': 0.01, 'gen_type': 'uniform', 'seed': 123},\n        {'id': 'B', 'N': 200, 'alpha': 0.01, 'gen_type': 'positive_bias', 'seed': 456},\n        {'id': 'C', 'N': 200, 'alpha': 0.01, 'gen_type': 'negative_bias', 'seed': 789},\n        {'id': 'D', 'N': 1, 'alpha': 0.01, 'gen_type': 'deterministic', 'U_seq': np.array([0.9])},\n        {'id': 'E', 'N': 300, 'alpha': 0.01, 'gen_type': 'deterministic', 'U_seq': np.full(300, 0.5)}\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case['N']\n        alpha = case['alpha']\n        \n        if case['gen_type'] == 'uniform':\n            rng = np.random.default_rng(seed=case['seed'])\n            U = rng.uniform(0, 1, size=N)\n        elif case['gen_type'] == 'positive_bias':\n            rng = np.random.default_rng(seed=case['seed'])\n            V = rng.uniform(0, 1, size=N)\n            U = np.minimum(1.0, V + 0.2)\n        elif case['gen_type'] == 'negative_bias':\n            rng = np.random.default_rng(seed=case['seed'])\n            V = rng.uniform(0, 1, size=N)\n            U = np.maximum(0.0, V - 0.2)\n        elif case['gen_type'] == 'deterministic':\n            U = case['U_seq']\n        \n        result = run_monitor(N, alpha, U)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "有时，孤立地测试随机数生成器是不够的，它在复杂算法中的实际行为可能会暴露更深层次的问题。本练习将深入探讨拒绝抽样（rejection sampling）这一经典算法，检验其中起关键作用的辅助均匀随机变量的质量。您将设计一个双管齐下的诊断测试，通过分析算法的内部运作来捕捉那些可能被通用测试忽略的微小偏差或依赖性，这凸显了在特定应用场景下进行验证的重要性。",
            "id": "3201455",
            "problem": "给定一个在单位区间上的拒绝采样设置，旨在研究用于接受的辅助随机变量（记为 $U$）是否真正在 $[0,1]$ 上独立且均匀分布。目标密度定义为 $f(x) = 30\\,x\\,(1-x)^4$，其中 $x \\in [0,1]$，这是一个参数为 $(2,5)$ 的 Beta 分布的概率密度函数。提议密度为 $g(x) = 1$，其中 $x \\in [0,1]$，即均匀密度。设 $M = \\max_{x \\in [0,1]} f(x)$ 为一个有限常数，使得对于所有 $x \\in [0,1]$，都有 $f(x) \\le M\\,g(x)$。在此设置中，拒绝采样的过程为：从 $g$ 中抽取 $x$ 和在 $[0,1]$ 上抽取 $U$，如果 $U \\le v(x)$，则接受 $x$，其中 $v(x) = \\frac{f(x)}{M\\,g(x)}$。\n\n基本原理。拒绝采样方法假设 $U$ 独立于 $x$ 并在 $[0,1]$ 上服从均匀分布。在这些假设下，对于任何固定的 $x$，接受指示符 $A$ 满足 $\\mathbb{P}(A=1 \\mid x) = v(x)$，并且在接受和给定值 $x$ 的条件下，$U$ 的条件密度在 $[0,v(x)]$ 上是均匀的。接受率 $\\mathbb{E}[A]$ 相对于 $\\mathbb{E}[v(X)]$ 的偏差，或在被接受的样本中 $U$ 的条件分布的偏差，都表明 $U$ 存在非均匀性或依赖性。\n\n你的任务是实现一个程序，针对辅助变量 $U$ 的指定场景，通过分析接受率和被接受样本中 $U$ 的条件密度，来测试均匀性和独立性假设。你必须使用以下科学定义作为基本依据：\n- 拒绝接受规则：如果 $U \\le v(x)$ 则接受，其中 $v(x) = \\frac{f(x)}{M\\,g(x)}$。\n- 独立性假设：$U$ 独立于 $x$。\n- 均匀性假设：$U$ 在 $[0,1]$ 上是均匀的。\n\n除了这些基本规则外，你不能依赖任何快捷公式，并且你的推导应从这些定义开始。\n\n实现以下测试套件，其中每个场景的提议数量为 $n = 100000$：\n- 场景 $1$（理想基线）：$U$ 独立于 $x$ 并在 $[0,1]$ 上均匀分布。\n- 场景 $2$（全局偏差）：$U$ 在 $[0,1]$ 上服从参数为 $\\alpha = 0.8$ 和 $\\beta = 1.2$ 的 Beta 分布 $\\mathrm{Beta}(\\alpha,\\beta)$，且独立于 $x$。\n- 场景 $3$（依赖于提议的偏差）：$U$ 由 $U' = \\min\\{\\max\\{U + \\epsilon\\,(2x - 1),\\,0\\},\\,1\\}$ 定义，其中 $U \\sim \\mathrm{Uniform}[0,1]$ 独立于 $x$，提议 $x \\sim g$，且 $\\epsilon = 0.08$。这在 $U'$ 保持在 $[0,1]$ 范围内的同时，引入了其对 $x$ 的依赖性。\n\n对于所有场景，从 $[0,1]$ 上的 $g(x)$ 中抽取提议 $x$，使用 $M = \\max_{x \\in [0,1]} f(x)$ 计算 $v(x) = \\frac{f(x)}{M}$，并定义接受指示符 $A = \\mathbf{1}\\{U \\le v(x)\\}$。\n\n你必须为每个场景实现一个两方面的测试：\n- 接受率一致性：计算差异 $\\Delta = \\overline{A} - \\overline{v}$，其中 $\\overline{A}$ 是 $A$ 的样本均值，$\\overline{v}$ 是 $v(x)$ 的样本均值。通过使用基本原理所隐含的方差，用一个标准化统计量来量化此差异。\n- 条件密度检查：在被接受的样本中，进行变换 $W = \\frac{U}{v(x)}$，并检验 $W$ 是否在 $[0,1]$ 上服从均匀分布。\n\n检测规则。对于每个场景，如果接受率的标准化差异较大，或者条件密度检查在一个严格的水平上拒绝了均匀性，则标记 $U$ 的非均匀性。你必须为这两个测试选择明确的数值阈值，以便为每个场景生成一个布尔决策。\n\n使用的参数值：\n- 在 $[0,1]$ 上使用 $f(x) = 30\\,x\\,(1-x)^4$ 和 $g(x) = 1$。\n- 使用 $M = 30 \\cdot \\frac{1}{5} \\cdot \\left(\\frac{4}{5}\\right)^4$。\n- 使用 $n = 100000$，$\\alpha = 0.8$，$\\beta = 1.2$ 和 $\\epsilon = 0.08$。\n- 不涉及物理单位。\n\n定义最终输出格式如下。你的程序应生成一行输出，其中包含场景 1、2 和 3 的布尔检测结果，形式为逗号分隔的列表，并用方括号括起来，例如 $[\\mathrm{True},\\mathrm{False},\\mathrm{True}]$。",
            "solution": "经评估，用户提供的问题是**有效**的。它在科学上基于拒绝采样理论和统计假设检验，提法恰当，包含了所有必要的数据和明确的目标，并以客观、正式的语言表述。该问题是自洽的，没有矛盾或不可行的要求。因此，我们可以着手提供完整的解决方案。\n\n核心任务是针对三个不同的场景，检验拒绝采样的基本假设——即辅助随机变量 $U$ 独立于提议 $x$ 并在 $[0,1]$ 上均匀分布。测试方法包含两个方面，既检验总体接受率，也检验被接受样本中 $U$ 的条件分布。\n\n**方法论与理论基础**\n\n拒绝采样算法由目标概率密度函数 (PDF) $f(x) = 30x(1-x)^4$（在 $[0,1]$ 上）、均匀提议 PDF $g(x)=1$（在 $[0,1]$ 上）以及一个常数 $M$ 定义，该常数满足对所有 $x$ 都有 $f(x) \\le M g(x)$。$f(x)$ 的最大值在 $x=1/5$ 处取得，从而得到 $M = f(1/5) = 30 \\cdot \\frac{1}{5} \\cdot (\\frac{4}{5})^4 = \\frac{1536}{625} \\approx 2.4576$。\n\n如果 $U \\le v(x)$，则提议 $x$ 被接受，其中 $v(x) = \\frac{f(x)}{M g(x)} = \\frac{f(x)}{M}$。原假设 $H_0$ 表明，$U$ 独立于 $x$ 且 $U \\sim \\mathrm{Uniform}[0,1]$。我们构建两个统计检验来检测对 $H_0$ 的违反情况。\n\n**检验 1：接受率一致性**\n\n该检验分析观测到的接受率与在 $H_0$ 下的期望接受率之间的差异。对于一组 $n$ 个提议 $\\{x_i\\}_{i=1}^n$，我们定义一个接受指示符 $A_i = \\mathbf{1}\\{U_i \\le v(x_i)\\}$。问题要求检验差异 $\\Delta = \\overline{A} - \\overline{v}$，其中 $\\overline{A} = \\frac{1}{n} \\sum_{i=1}^n A_i$，$\\overline{v} = \\frac{1}{n} \\sum_{i=1}^n v(x_i)$。\n\n在原假设 $H_0$ 下，给定 $x_i$ 时 $A_i$ 的条件期望是 $\\mathbb{E}[A_i | x_i] = \\mathbb{P}(U_i \\le v(x_i) | x_i)$。由于 $U_i \\sim \\mathrm{Uniform}[0,1]$ 且独立于 $x_i$，这个概率就是 $v(x_i)$。根据全期望定律，差值 $D_i = A_i - v(x_i)$ 的无条件期望为：\n$$\n\\mathbb{E}[D_i] = \\mathbb{E}[A_i - v(x_i)] = \\mathbb{E}[\\mathbb{E}[A_i | x_i] - v(x_i)] = \\mathbb{E}[v(x_i) - v(x_i)] = 0\n$$\n因此，在 $H_0$ 下，样本差异 $\\Delta = \\frac{1}{n} \\sum D_i$ 的期望值也为 0。\n\n为标准化此差异，我们计算其在 $H_0$ 下的方差。$D_i$ 的方差为：\n$$\n\\mathrm{Var}(D_i) = \\mathbb{E}[D_i^2] - (\\mathbb{E}[D_i])^2 = \\mathbb{E}[(A_i - v(x_i))^2]\n$$\n再次使用全期望定律，并注意到 $A_i$ 是一个指示符，因此 $A_i^2 = A_i$：\n$$\n\\mathbb{E}[(A_i - v(x_i))^2] = \\mathbb{E}[\\mathbb{E}[A_i^2 - 2A_iv(x_i) + v(x_i)^2 | x_i]] = \\mathbb{E}[v(x_i) - 2v(x_i)^2 + v(x_i)^2] = \\mathbb{E}[v(x_i)(1-v(x_i))]\n$$\n根据中心极限定理，对于大样本 $n$，和 $\\sum_{i=1}^n D_i$ 近似服从正态分布。我们构建 Z-统计量：\n$$\nZ = \\frac{\\sum_{i=1}^n D_i}{\\sqrt{\\mathrm{Var}(\\sum D_i)}} = \\frac{\\sum_{i=1}^n (A_i - v(x_i))}{\\sqrt{n \\cdot \\mathrm{Var}(D_i)}}\n$$\n我们用其在样本上的经验均值 $\\frac{1}{n}\\sum_{i=1}^n v(x_i)(1-v(x_i))$ 来估计 $\\mathrm{Var}(D_i)$。这导出了检验统计量：\n$$\nZ = \\frac{\\sum_{i=1}^n (A_i - v(x_i))}{\\sqrt{\\sum_{i=1}^n v(x_i)(1-v(x_i))}}\n$$\n在 $H_0$ 下，对于较大的 $n$，$Z \\sim \\mathcal{N}(0,1)$。如果 $|Z| > 3$，我们将标记一个偏差，这对应于一个约 $\\alpha \\approx 0.0027$ 的严格显著性水平。\n\n**检验 2：条件密度检查**\n\n该检验考察被接受样本子集中辅助变量的分布。在 $H_0$ 下，可以推导出给定样本 $x$ 被接受（即 $A=1$）时 $U$ 的条件 PDF。其条件累积分布函数 (CDF) 为：\n$$\nF_{U|A=1, X=x}(u) = \\mathbb{P}(U \\le u \\mid U \\le v(x), X=x) = \\frac{\\mathbb{P}(U \\le u, U \\le v(x) \\mid X=x)}{\\mathbb{P}(U \\le v(x) \\mid X=x)}\n$$\n对于 $u \\in [0, v(x)]$，上式简化为 $\\frac{\\mathbb{P}(U \\le u \\mid X=x)}{v(x)} = \\frac{u}{v(x)}$。这是在区间 $[0, v(x)]$ 上的均匀分布的 CDF。\n\n如果我们通过定义 $W = U/v(x)$ 来变换这个变量，其在给定 $A=1$ 和 $X=x$ 的条件下的分布在 $[0,1]$ 上变为均匀的：\n$$\n\\mathbb{P}(W \\le w \\mid A=1, X=x) = \\mathbb{P}\\left(\\frac{U}{v(x)} \\le w \\mid A=1, X=x\\right) = \\mathbb{P}(U \\le w \\cdot v(x) \\mid A=1, X=x) = \\frac{w \\cdot v(x)}{v(x)} = w\n$$\n对于 $w \\in [0,1]$。这个结果独立于 $x$，因此所有被接受样本的 $W$ 的边缘分布也必须是 $\\mathrm{Uniform}[0,1]$。\n\n为了检验这一点，我们收集所有被接受的样本，计算相应的 $W$ 值，并对标准均匀分布进行一次双边 Kolmogorov-Smirnov (K-S) 检验。如果检验得出的 p-值小于严格阈值 $p  0.001$，我们将标记一个偏差。\n\n**各场景的实现**\n\n对于 $n=100000$ 个提议中的每一个 $x_i \\sim \\mathrm{Uniform}[0,1]$，我们计算 $v_i = v(x_i)$ 并根据指定场景生成辅助变量 $U_i$：\n1.  **理想基线**：$U_i$ 从 $\\mathrm{Uniform}[0,1]$ 中抽取。我们预期两个检验都会通过，从而产生一个 `False` 标记。\n2.  **全局偏差**：$U_i$ 从 $\\mathrm{Beta}(0.8, 1.2)$ 分布中抽取。该分布的均值为 0.4，小于标准均匀分布的均值 0.5，且其 CDF 有显著差异。我们预期这种全局偏差会被至少一个检验检测到，从而产生一个 `True` 标记。\n3.  **依赖于提议的偏差**：$U_i = \\min\\{\\max\\{U'_i + \\epsilon(2x_i - 1), 0\\}, 1\\}$，其中 $U'_i \\sim \\mathrm{Uniform}[0,1]$ 且 $\\epsilon = 0.08$。这违反了独立性假设。即使对总体接受率的影响很小，$U$ 的条件分布也被改变了，因此我们预期 K-S 检验会检测到这种违规，从而产生一个 `True` 标记。\n\n如果 $|Z| > 3$（来自检验 1）或 K-S p-值小于 $0.001$（来自检验 2），则该场景被标记为 `True`。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Implements a test suite to validate uniformity and independence assumptions\n    in a rejection sampling setup for three different scenarios of the auxiliary\n    variable U.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    N = 100000\n    ALPHA = 0.8\n    BETA_PARAM = 1.2 # Renamed from 'beta' to avoid conflict with scipy.stats.beta\n    EPSILON = 0.08\n    \n    # --- Statistical Thresholds ---\n    Z_THRESHOLD = 3.0\n    P_VALUE_THRESHOLD = 0.001\n\n    # --- Setup for Reproducibility ---\n    np.random.seed(42)\n\n    # --- Core Rejection Sampling Definitions ---\n    # Target PDF f(x)\n    def f(x):\n        return 30.0 * x * (1.0 - x)**4.0\n\n    # The maximum of f(x) on [0,1] occurs at x=1/5\n    M = f(1.0 / 5.0)\n\n    # v(x) = f(x) / M\n    def v(x):\n        return f(x) / M\n\n    # Generate a common set of proposals x and corresponding v(x) values\n    proposals_x = np.random.uniform(0.0, 1.0, N)\n    v_values = v(proposals_x)\n    \n    def run_test_scenario(u_values, v_vals, z_thresh, p_thresh):\n        \"\"\"\n        Performs the two-pronged test for a given set of U values.\n\n        Args:\n            u_values (np.ndarray): The auxiliary random variable samples.\n            v_vals (np.ndarray): The values of v(x) for each proposal.\n            z_thresh (float): The critical value for the Z-statistic.\n            p_thresh (float): The significance level for the K-S test.\n\n        Returns:\n            bool: True if the scenario is flagged as deviating, False otherwise.\n        \"\"\"\n        # Test 1: Acceptance Rate Consistency\n        A = (u_values = v_vals).astype(int)\n        \n        # Numerically stable calculation of the Z-statistic\n        z_numerator = np.sum(A - v_vals)\n        z_denominator = np.sqrt(np.sum(v_vals * (1.0 - v_vals)))\n  \n        z_score = 0.0\n        if z_denominator > 1e-9: # Avoid division by zero\n            z_score = z_numerator / z_denominator\n\n        test1_failed = abs(z_score) > z_thresh\n\n        # Test 2: Conditional Density Check\n        accepted_indices = np.where(A == 1)[0]\n        \n        test2_failed = False\n        # A K-S test requires a reasonable number of samples to be meaningful.\n        if len(accepted_indices) > 30:\n            u_accepted = u_values[accepted_indices]\n            v_accepted = v_vals[accepted_indices]\n            \n            # The transformed variable W should be Uniform[0,1] under H0\n            W = u_accepted / v_accepted\n            \n            # Perform Kolmogorov-Smirnov test against a standard uniform distribution\n            _ks_stat, p_value = kstest(W, 'uniform')\n            test2_failed = p_value  p_thresh\n        \n        # A scenario is flagged if either test fails\n        return test1_failed or test2_failed\n\n    results = []\n\n    # --- Scenario 1: Ideal Baseline ---\n    # U is independent and uniformly distributed on [0,1]\n    u_scenario1 = np.random.uniform(0.0, 1.0, N)\n    results.append(run_test_scenario(u_scenario1, v_values, Z_THRESHOLD, P_VALUE_THRESHOLD))\n\n    # --- Scenario 2: Global Bias ---\n    # U has a Beta(alpha, beta) distribution\n    u_scenario2 = np.random.beta(ALPHA, BETA_PARAM, N)\n    results.append(run_test_scenario(u_scenario2, v_values, Z_THRESHOLD, P_VALUE_THRESHOLD))\n\n    # --- Scenario 3: Proposal-Dependent Bias ---\n    # U' is a function of U and the proposal x\n    u_base = np.random.uniform(0.0, 1.0, N)\n    u_scenario3 = u_base + EPSILON * (2.0 * proposals_x - 1.0)\n    # Ensure U' remains in the [0,1] interval\n    u_scenario3 = np.clip(u_scenario3, 0.0, 1.0)\n    results.append(run_test_scenario(u_scenario3, v_values, Z_THRESHOLD, P_VALUE_THRESHOLD))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}