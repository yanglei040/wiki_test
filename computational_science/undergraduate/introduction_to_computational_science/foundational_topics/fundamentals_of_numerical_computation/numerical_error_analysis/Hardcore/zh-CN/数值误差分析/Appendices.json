{
    "hands_on_practices": [
        {
            "introduction": "数值计算中的一个常见陷阱是两个几乎相等的数相减，这可能导致“灾难性抵消”并严重损失精度。本练习  探讨了双指数差函数中出现的这一问题，该函数在物理和工程模型中很常见。通过分析误差的来源，您将学习如何通过代数重构来推导一个数值稳定的表达式，并利用像 $\\mathrm{expm1}$ 这样的专用函数来获得精确的结果。",
            "id": "3165829",
            "problem": "考虑计算双指数差 $S(t;\\tau_1,\\tau_2) = \\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)$，其中 $t \\ge 0$，时间常数 $\\tau_1  0$ 且 $\\tau_2  0$ 为严格正值，并且可能非常接近，即 $\\tau_1 \\approx \\tau_2$。计算在电气和电子工程师协会（IEEE）754 binary64 算术（通常称为双精度）的标准浮点舍入模型中进行，其中每个基本运算都建模为 $\\mathrm{fl}(z) = z(1+\\delta)$，且 $|\\delta| \\le \\epsilon_{\\mathrm{mach}}$，$\\epsilon_{\\mathrm{mach}}$ 为机器 epsilon。使用绝对误差 $|x - \\hat{x}|$ 和相对误差 $|x - \\hat{x}|/|x|$ 的核心定义，以及减去几乎相等的量时出现的灾难性抵消的概念。\n\n从这些基础出发，分析朴素减法计算 $S(t;\\tau_1,\\tau_2)$ 的数值稳定性，该方法在浮点运算中通过分别计算两个指数项然后相减来求值。推导朴素减法的相对误差界，用 $\\epsilon_{\\mathrm{mach}}$、 $|\\exp(-t/\\tau_1)|$、 $|\\exp(-t/\\tau_2)|$ 和 $|S(t;\\tau_1,\\tau_2)|$ 表示，并解释为什么当 $\\tau_1 \\to \\tau_2$ 时该界会变大（灾难性抵消）。然后，通过基于指数函数性质的精确代数操作，并利用特殊函数 $\\mathrm{expm1}(x)$（该函数在 $|x|$ 很小时能以高相对精度计算 $\\exp(x) - 1$），推导出一个与 $S(t;\\tau_1,\\tau_2)$ 代数等价的表达式。当 $\\tau_1 \\approx \\tau_2$ 时，该表达式通过将差值表示为带有小参数的单个缩放后的 $\\mathrm{expm1}$ 调用，从而避免了几乎相等的数相减的问题。\n\n只需报告用 $t$、$\\tau_1$、$\\tau_2$ 和 $\\mathrm{expm1}(\\cdot)$ 表示的 $S(t;\\tau_1,\\tau_2)$ 的最终闭式稳定表达式。不需要进行数值计算。",
            "solution": "问题要求分析计算双指数差 $S(t;\\tau_1,\\tau_2) = \\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)$ 的数值稳定性，并推导一个数值稳定的替代表达式。分析将按要求分两部分进行：首先，对朴素计算方法进行误差分析；其次，通过代数重构推导一个稳定的公式。\n\n我们从误差分析开始。问题设定为 $t \\ge 0$、$\\tau_1  0$ 和 $\\tau_2  0$，重点关注 $\\tau_1 \\approx \\tau_2$ 的情况。设各项的真实值为 $x_1 = \\exp(-t/\\tau_1)$ 和 $x_2 = \\exp(-t/\\tau_2)$。精确差值为 $S = x_1 - x_2$。\n\n在浮点运算中，朴素的计算方法是先计算两个指数项，然后相减。设 $\\hat{x}_1$ 和 $\\hat{x}_2$ 分别是 $x_1$ 和 $x_2$ 的计算所得的浮点表示。我们使用标准的浮点算术模型，其中像 $\\exp$ 这样的函数求值和基本算术运算会引入一个小的相对误差。因此，我们可以将计算值建模为：\n$$ \\hat{x}_1 = \\mathrm{fl}(\\exp(-t/\\tau_1)) = x_1(1+\\delta_1), \\quad |\\delta_1| \\le \\epsilon_{\\mathrm{mach}} $$\n$$ \\hat{x}_2 = \\mathrm{fl}(\\exp(-t/\\tau_2)) = x_2(1+\\delta_2), \\quad |\\delta_2| \\le \\epsilon_{\\mathrm{mach}} $$\n这里，$\\epsilon_{\\mathrm{mach}}$ 是机器 epsilon，我们假设计算参数 $-t/\\tau_1$ 和 $-t/\\tau_2$ 时产生的误差已包含在计算指数函数的总误差中，这是此级别分析中的标准简化。最终的计算值 $\\hat{S}$ 是在浮点运算中对这两个计算值进行减法运算的结果：\n$$ \\hat{S} = \\mathrm{fl}(\\hat{x}_1 - \\hat{x}_2) = (\\hat{x}_1 - \\hat{x}_2)(1+\\delta_3), \\quad |\\delta_3| \\le \\epsilon_{\\mathrm{mach}} $$\n为了分析误差，我们求计算值 $\\hat{S}$ 与真实值 $S$ 之间的差。\n$$ \\hat{S} = (x_1(1+\\delta_1) - x_2(1+\\delta_2))(1+\\delta_3) $$\n$$ \\hat{S} = (x_1 - x_2 + x_1\\delta_1 - x_2\\delta_2)(1+\\delta_3) $$\n由于 $S = x_1 - x_2$，我们有：\n$$ \\hat{S} = (S + x_1\\delta_1 - x_2\\delta_2)(1+\\delta_3) $$\n展开此表达式得到：\n$$ \\hat{S} = S + S\\delta_3 + x_1\\delta_1 - x_2\\delta_2 + (x_1\\delta_1 - x_2\\delta_2)\\delta_3 $$\n绝对误差为 $\\hat{S} - S$：\n$$ \\hat{S} - S = S\\delta_3 + x_1\\delta_1 - x_2\\delta_2 + (x_1\\delta_1 - x_2\\delta_2)\\delta_3 $$\n忽略与 $\\epsilon_{\\mathrm{mach}}^2$ 成正比的高阶项 $(x_1\\delta_1 - x_2\\delta_2)\\delta_3$，绝对误差近似为：\n$$ \\hat{S} - S \\approx x_1\\delta_1 - x_2\\delta_2 + S\\delta_3 $$\n相对误差为 $\\frac{|\\hat{S} - S|}{|S|}$。对绝对误差的近似值使用三角不等式，我们可以建立一个界：\n$$ |\\hat{S} - S| \\lesssim |x_1\\delta_1| + |x_2\\delta_2| + |S\\delta_3| $$\n$$ |\\hat{S} - S| \\lesssim |x_1||\\delta_1| + |x_2||\\delta_2| + |S||\\delta_3| $$\n代入每个 $\\delta_i$ 的界 $|\\delta_i| \\le \\epsilon_{\\mathrm{mach}}$：\n$$ |\\hat{S} - S| \\lesssim (|x_1| + |x_2| + |S|) \\epsilon_{\\mathrm{mach}} $$\n因此，相对误差的界为：\n$$ \\frac{|\\hat{S} - S|}{|S|} \\lesssim \\frac{|x_1| + |x_2| + |S|}{|S|} \\epsilon_{\\mathrm{mach}} = \\left(1 + \\frac{|x_1| + |x_2|}{|S|}\\right) \\epsilon_{\\mathrm{mach}} $$\n代入 $x_1$、$x_2$ 和 $S$ 的原始表达式：\n$$ \\frac{|\\hat{S} - S|}{|S|} \\lesssim \\left(1 + \\frac{|\\exp(-t/\\tau_1)| + |\\exp(-t/\\tau_2)|}{|\\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)|}\\right) \\epsilon_{\\mathrm{mach}} $$\n这个界解释了数值不稳定性。当 $\\tau_1 \\to \\tau_2$ 时，指数函数的参数变得几乎相等，即 $-t/\\tau_1 \\approx -t/\\tau_2$。因此，它们的值也变得几乎相等：$\\exp(-t/\\tau_1) \\approx \\exp(-t/\\tau_2)$。误差界中分数的分母 $|S| = |\\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)|$ 趋近于 $0$。然而，对于 $t0$，分子 $|\\exp(-t/\\tau_1)| + |\\exp(-t/\\tau_2)|$ 趋近于 $2\\exp(-t/\\tau)$，其中 $\\tau$ 是 $\\tau_1$ 和 $\\tau_2$ 的共同极限。因此，比率 $\\frac{|\\exp(-t/\\tau_1)| + |\\exp(-t/\\tau_2)|}{|S|}$ 会无界增长。这个大因子乘以机器 epsilon，导致计算结果 $\\hat{S}$ 的相对误差可能很大。这种两个几乎相等的数相减导致相对精度损失的现象，被称为灾难性抵消。\n\n为了避免这种数值不稳定性，我们必须对表达式 $S(t;\\tau_1,\\tau_2)$ 进行代数重构。目标是避免直接减去几乎相等的量。问题建议使用函数 $\\mathrm{expm1}(x)$，其定义为 $\\mathrm{expm1}(x) = \\exp(x) - 1$，并且其实现即使在 $|x|$ 很小时也能返回具有高相对精度的结果。\n\n我们从原始表达式开始：\n$$ S(t;\\tau_1,\\tau_2) = \\exp(-t/\\tau_1) - \\exp(-t/\\tau_2) $$\n我们可以提取其中一个指数项作为公因子。让我们提取 $\\exp(-t/\\tau_2)$:\n$$ S = \\exp(-t/\\tau_2) \\left[ \\frac{\\exp(-t/\\tau_1)}{\\exp(-t/\\tau_2)} - 1 \\right] $$\n利用性质 $\\exp(a)/\\exp(b) = \\exp(a-b)$，我们简化方括号内的项：\n$$ S = \\exp(-t/\\tau_2) \\left[ \\exp\\left(-\\frac{t}{\\tau_1} - \\left(-\\frac{t}{\\tau_2}\\right)\\right) - 1 \\right] $$\n$$ S = \\exp(-t/\\tau_2) \\left[ \\exp\\left(-\\frac{t}{\\tau_1} + \\frac{t}{\\tau_2}\\right) - 1 \\right] $$\n我们可以从指数中提取 $t$ 并合并分数：\n$$ -\\frac{t}{\\tau_1} + \\frac{t}{\\tau_2} = t \\left(\\frac{1}{\\tau_2} - \\frac{1}{\\tau_1}\\right) = t \\left(\\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right) $$\n将此代回 $S$ 的表达式：\n$$ S = \\exp(-t/\\tau_2) \\left[ \\exp\\left(t \\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right) - 1 \\right] $$\n方括号内的项现在的形式是 $\\exp(x) - 1$，其中 $x = t \\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}$。因此我们可以用 $\\mathrm{expm1}$ 函数来表示它：\n$$ S = \\exp(-t/\\tau_2) \\cdot \\mathrm{expm1}\\left(t \\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right) $$\n这个表达式是数值稳定的。当 $\\tau_1 \\approx \\tau_2$ 时，$\\mathrm{expm1}$ 函数的参数 $x$ 会变得很小。$\\mathrm{expm1}$ 函数是专门为高相对精度处理小参数而设计的。减法 $\\tau_1 - \\tau_2$ 是对输入数据的操作，而输入数据通常是精确的浮点数；根据 Sterbenz 引理，这个减法本身通常是精确的。其余的运算是乘法和除法，它们在数值上是良态的。这个重构的表达式避免了朴素方法中的灾难性抵消，即使在 $\\tau_1$ 和 $\\tau_2$ 非常接近时也能提供准确的结果。",
            "answer": "$$\\boxed{\\exp\\left(-\\frac{t}{\\tau_2}\\right) \\mathrm{expm1}\\left(t\\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right)}$$"
        },
        {
            "introduction": "在认识到直接代数重构的威力之后，我们来探讨一种更复杂的情况，即需要采用混合策略。本练习  关注著名的 `sinc` 函数 $f(x) = \\sin(x)/x$。您将发现，虽然直接计算 $f(x)$ 本身是稳定的，但计算其微小变化量 $1 - f(x)$ 时，在 $x$ 接近零的情况下会遭遇灾难性抵消。这项实践将指导您设计并实现一个鲁棒的混合算法，该算法在输入值较小时切换到泰勒级数逼近，这是数值库中广泛使用的一种关键技术。",
            "id": "3212241",
            "problem": "考虑函数 $f(x) = \\begin{cases}\\dfrac{\\sin x}{x},  x \\neq 0,\\\\ 1,  x = 0.\\end{cases}$，其中角度以弧度为单位。我们的目标是研究在使用标准浮点运算计算 $f(x)$ 时，对于小的 $x$ 出现的有效位数损失问题，并设计一种数值稳定的替代方法来精确捕捉微小的减量 $d(x) = 1 - f(x)$。\n\n从以下基础出发：\n- 正弦函数在 $x = 0$ 附近的泰勒级数：$\\sin x = x - \\dfrac{x^{3}}{3!} + \\dfrac{x^{5}}{5!} - \\cdots$。\n- $f(x)$ 的导出级数及相关的减量 $d(x)$：\n$$f(x) = 1 - \\dfrac{x^{2}}{3!} + \\dfrac{x^{4}}{5!} - \\cdots,\\quad d(x) = 1 - f(x) = \\dfrac{x^{2}}{3!} - \\dfrac{x^{4}}{5!} + \\dfrac{x^{6}}{7!} - \\cdots.$$\n- 标准浮点模型：对于基本运算 $\\circ \\in \\{+,-,\\times,\\div\\}$，$\\operatorname{fl}(a \\circ b) = (a \\circ b)(1 + \\delta)$，其中 $|\\delta| \\le u$，$u$ 是工作精度的单位舍入误差。\n\n任务：\n1. 基于上述基础，论证为何直接计算 $\\operatorname{fl}(\\sin x)/\\operatorname{fl}(x)$ 对于小 $x$ 的 $f(x)$ 具有较小的相对误差，但在计算 $1 - \\operatorname{fl}(\\sin x)/\\operatorname{fl}(x)$ 时，由于相减抵消，可能会完全丢失关于减量 $d(x)$ 的信息。推导出一个阈值的尺度（用 $u$ 的渐近形式表示），在该阈值下，朴素的计算方法无法可靠地解析 $d(x)$。\n2. 设计一个稳定的基于级数的求值方法，该方法：\n   - 对于 $|x|$ 小于一个基于 $u$ 的阈值 $\\,\\tau\\,$ 的情况，通过其交错级数计算 $d(x)$，并仅在最后通过 $f(x) = 1 - d(x)$ 形成 $f(x)$，采用数值稳定的求和策略。\n   - 对于 $|x| \\ge \\tau$ 的情况，使用直接求值 $f(x) = \\sin(x)/x$。\n   - 通过返回 $f(0) = 1$ 来处理 $x = 0$ 处的可去奇点。\n3. 实现一个完整、可运行的程序，该程序：\n   - 主要计算使用标准的双精度浮点算术。\n   - 使用基于任意精度算术计算的截断级数得到的高精度参考值，以近似 $f(x)$ 和 $d(x)$ 的真实值到多个正确位数。\n   - 对每个测试输入 $x$，计算三个误差指标：\n     - 朴素 $f(x)$ 的相对误差：$\\left|\\dfrac{f_{\\text{naive}} - f_{\\text{ref}}}{f_{\\text{ref}}}\\right|$。\n     - 朴素减量 $d_{\\text{naive}} = 1 - f_{\\text{naive}}$ 相对于 $d_{\\text{ref}}$ 的相对误差：$\\left|\\dfrac{d_{\\text{naive}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$（如果 $d_{\\text{ref}} = 0$ 则定义为 $0$）。\n     - 稳定级数减量 $d_{\\text{stable}}$ 相对于 $d_{\\text{ref}}$ 的相对误差：$\\left|\\dfrac{d_{\\text{stable}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$（如果 $d_{\\text{ref}} = 0$ 则定义为 $0$）。\n   - 使用弧度，不使用任何物理单位。\n\n测试套件：\n- 对输入 $x \\in \\{0,\\;10^{-12},\\;10^{-10},\\;10^{-8},\\;-10^{-7},\\;10^{-7},\\;10^{-4},\\;10^{-1}\\}$ 评估程序。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表的列表，每个内部列表对应一个测试输入，并按上述顺序包含三个误差指标。例如： \"[[e11,e12,e13],[e21,e22,e23],...]\"，所有条目均为浮点数。角度单位是弧度，在计算或输出的任何地方都不得使用百分号。",
            "solution": "此问题根据既定标准进行验证。\n\n### 第 1 步：提取已知条件\n- **函数定义**: $f(x) = \\begin{cases}\\dfrac{\\sin x}{x},  x \\neq 0,\\\\ 1,  x = 0.\\end{cases}$，角度以弧度为单位。\n- **减量定义**: $d(x) = 1 - f(x)$。\n- **正弦函数的泰勒级数**: $\\sin x = x - \\dfrac{x^{3}}{3!} + \\dfrac{x^{5}}{5!} - \\cdots$。\n- **$f(x)$ 和 $d(x)$ 的级数**: $f(x) = 1 - \\dfrac{x^{2}}{3!} + \\dfrac{x^{4}}{5!} - \\cdots$，以及 $d(x) = \\dfrac{x^{2}}{3!} - \\dfrac{x^{4}}{5!} + \\dfrac{x^{6}}{7!} - \\cdots$。\n- **浮点模型**: $\\operatorname{fl}(a \\circ b) = (a \\circ b)(1 + \\delta)$，其中 $|\\delta| \\le u$，$u$ 是单位舍入误差。\n- **任务 1**: 分析为什么直接计算 $f(x)$ 的相对误差很小，而通过 $1 - f(x)$ 计算 $d(x)$ 会因灾难性抵消而对小的 $x$ 产生问题。推导阈值尺度与 $u$ 的关系。\n- **任务 2**: 设计一种稳定的混合算法，当 $|x|  \\tau$ 时使用级数展开，当 $|x| \\ge \\tau$ 时使用直接求值。\n- **任务 3**: 实现一个程序，根据给定的测试套件，计算三种指定的误差指标（朴素 $f(x)$、朴素 $d(x)$ 和稳定 $d(x)$ 的相对误差），并与高精度参考值进行比较。\n- **执行环境与精度**: 主要计算使用双精度，参考值使用任意精度。\n- **测试套件**: $x \\in \\{0,\\;10^{-12},\\;10^{-10},\\;10^{-8},\\;-10^{-7},\\;10^{-7},\\;10^{-4},\\;10^{-1}\\}$。\n- **输出格式**: 单行字符串，表示一个包含误差指标列表的列表：`[[e11,e12,e13],[e21,e22,e23],...]`。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题是数值分析中的一个标准练习，重点关注灾难性抵消，这是科学计算中的一个核心概念。\n- **科学基础（关键）**: 该问题从根本上基于泰勒级数展开和标准浮点算术模型，这些都是数值方法的基石。它在科学上是合理的。\n- **适定性**: 这个问题是适定的。它清楚地定义了函数、要计算的量、要分析的方法以及预期的输出。存在唯一且有意义的解。\n- **客观性（关键）**: 语言精确且数学化。没有主观或基于观点的陈述。\n该问题是自洽且一致的。“任意精度”参考值的要求可以通过使用 Python 标准库中的 `decimal` 模块来满足，这是允许的。所有其他标准均已满足。\n\n### 第 3 步：结论与行动\n该问题有效。将提供完整解决方案。\n\n---\n\n### 数值误差分析与算法设计\n\n本解决方案解决了问题陈述中概述的三个任务：分析数值不稳定性、设计稳定算法以及实现验证。\n\n#### 1. 朴素计算中的数值误差分析\n\n我们分析在使用标准浮点算术计算小 $x$ 的 $f(x)$ 和 $d(x)$ 时的误差。\n\n**计算 $f(x)$ 的误差：**\n对于 $x \\neq 0$，$f(x)$ 的“朴素”计算是 $f_{\\text{naive}}(x) = \\operatorname{fl}(\\sin(x) / x)$。我们来为浮点误差建模。正弦函数的求值和除法运算引入的相对误差都受单位舍入误差 $u$ 的限制。\n首先，计算正弦函数：$\\operatorname{fl}(\\sin x) = (\\sin x)(1 + \\delta_1)$，其中 $|\\delta_1| \\le u$。\n然后，执行除法：\n$$ \\operatorname{fl}\\left(\\frac{\\operatorname{fl}(\\sin x)}{x}\\right) = \\left(\\frac{(\\sin x)(1 + \\delta_1)}{x}\\right)(1 + \\delta_2) = \\frac{\\sin x}{x}(1 + \\delta_1)(1 + \\delta_2) $$\n其中 $|\\delta_2| \\le u$。假设 $x$ 是一个精确的浮点数。\n令 $\\hat{f}(x)$ 表示计算值。展开误差项，我们得到：\n$$ \\hat{f}(x) = f(x)(1 + \\delta_1 + \\delta_2 + \\delta_1\\delta_2) \\approx f(x)(1 + \\delta_{\\text{f}}) $$\n其中 $\\delta_{\\text{f}} = \\delta_1 + \\delta_2$。计算 $f(x)$ 的总相对误差为：\n$$ \\left|\\frac{\\hat{f}(x) - f(x)}{f(x)}\\right| \\approx |\\delta_{\\text{f}}| \\le |\\delta_1| + |\\delta_2| \\le 2u $$\n这个相对误差很小，量级与单位舍入误差 $u$ 相当。因此，直接计算 $f(x)$ 在其定义域内是数值稳定的。\n\n**计算 $d(x) = 1 - f(x)$ 的误差：**\n减量的朴素计算是 $\\hat{d}(x) = \\operatorname{fl}(1 - \\hat{f}(x))$。对于小 $x$，我们从泰勒级数知道 $f(x) = 1 - \\frac{x^2}{6} + O(x^4)$，这非常接近 $1$。减法 $1 - \\hat{f}(x)$ 是灾难性抵消的典型例子，即两个几乎相等的数相减，导致相对精度的潜在损失。\n\n让我们更形式化地分析这一点。计算出的减量为：\n$$ \\hat{d}(x) = \\operatorname{fl}(1 - \\hat{f}(x)) = (1 - \\hat{f}(x))(1 + \\delta_3) \\quad \\text{其中 } |\\delta_3| \\le u $$\n代入 $\\hat{f}(x)$ 的表达式：\n$$ \\hat{d}(x) = (1 - f(x)(1 + \\delta_{\\text{f}}))(1 + \\delta_3) = (1 - f(x) - f(x)\\delta_{\\text{f}})(1 + \\delta_3) $$\n因为 $d(x) = 1 - f(x)$，这变成：\n$$ \\hat{d}(x) = (d(x) - f(x)\\delta_{\\text{f}})(1 + \\delta_3) = d(x) - f(x)\\delta_{\\text{f}} + d(x)\\delta_3 - f(x)\\delta_{\\text{f}}\\delta_3 $$\n绝对误差是 $\\hat{d}(x) - d(x) \\approx -f(x)\\delta_{\\text{f}} + d(x)\\delta_3$。\n$d(x)$ 的相对误差是：\n$$ \\frac{\\hat{d}(x) - d(x)}{d(x)} \\approx \\frac{-f(x)\\delta_{\\text{f}} + d(x)\\delta_3}{d(x)} = -\\frac{f(x)}{d(x)}\\delta_{\\text{f}} + \\delta_3 $$\n对于小 $x$，我们有 $f(x) \\approx 1$ 和 $d(x) \\approx x^2/6$。误差由第一项主导：\n$$ \\left|\\frac{\\hat{d}(x) - d(x)}{d(x)}\\right| \\approx \\left|-\\frac{f(x)}{d(x)}\\delta_{\\text{f}}\\right| \\approx \\frac{1}{x^2/6}|\\delta_{\\text{f}}| = \\frac{6|\\delta_{\\text{f}}|}{x^2} $$\n使用界 $|\\delta_{\\text{f}}| \\le 2u$，相对误差的界为：\n$$ \\left|\\frac{\\hat{d}(x) - d(x)}{d(x)}\\right| \\lesssim \\frac{12u}{x^2} $$\n当这个相对误差达到 $1$ 或更大时，朴素计算变得不可靠。这发生在 $12u/x^2 \\approx 1$ 时，从而给出阈值：\n$$ |x| \\approx \\sqrt{12u} $$\n对于双精度算术，$u = 2^{-53} \\approx 1.11 \\times 10^{-16}$。阈值是 $|x| \\approx \\sqrt{12 \\times 1.11 \\times 10^{-16}} \\approx 3.65 \\times 10^{-8}$。当 $|x|$ 的值达到或低于此尺度时，对 $d(x)$ 的朴素计算会丢失大部分或全部有效数字。阈值的渐近阶为 $O(\\sqrt{u})$。\n\n#### 2. 稳定算法的设计\n\n为了克服灾难性抵消，我们设计了一种混合算法，在 $|x|$ 较小时避免有问题的减法。\n算法如下：\n- 根据误差分析选择一个阈值 $\\tau$。对于双精度，一个实际的选择是 $\\tau = 10^{-7}$，这比完全损失有效数字的理论起始点（$\\approx 3.65 \\times 10^{-8}$）稍大，提供了一个安全边际。\n- **对于 $|x|  \\tau$**: 我们不先计算 $f(x)$，而是直接使用其泰勒级数展开来计算减量 $d(x)$：\n  $$ d(x) = \\frac{x^{2}}{3!} - \\frac{x^{4}}{5!} + \\frac{x^{6}}{7!} - \\cdots = \\sum_{k=1}^{\\infty} (-1)^{k-1} \\frac{x^{2k}}{(2k+1)!} $$\n  这是一个交错级数，当 $|x|  1$ 时，其项的绝对值迅速减小。我们可以通过对少数几项求和来精确计算 $d(x)$。这种方法是稳定的，因为它通过对其他小的、精确表示的值求和来构造小值 $d(x)$，而不是作为两个大的、几乎相等的数的差。一旦找到 $d_{\\text{stable}}(x)$ 的精确值，$f(x)$ 就可以计算为 $f_{\\text{stable}}(x) = 1 - d_{\\text{stable}}(x)$。最后的这个减法不会受到灾难性抵消的影响，因为 $d_{\\text{stable}}(x)$ 是一个小的、精确计算出的数。\n- **对于 $|x| \\ge \\tau$**: 使用朴素计算 $f(x) = \\sin(x)/x$。在此范围内，$f(x)$ 与 $1$ 的距离足够远，以至于在双精度数的上下文中，减法 $1-f(x)$ 不会引起灾难性的精度损失。级数求值也会变得效率更低，并且可能因为需要更多项才能收敛而变得不那么准确。\n- **对于 $x=0$**: 该函数作为特殊情况处理，根据定义返回 $f(0) = 1$ 和 $d(0)=0$。\n\n#### 3. 实现与验证\n\n实现将包括三个主要部分：\n1.  使用 Python 的 `decimal` 模块对 $f_{\\text{ref}}$ 和 $d_{\\text{ref}}$ 进行高精度参考计算。$d(x)$ 的级数非常适合此目的，求和足够多的项以确保收敛到 50 位数字的精度。\n2.  朴素计算函数，$f_{\\text{naive}}(x) = \\sin(x)/x$ 和 $d_{\\text{naive}}(x) = 1 - f_{\\text{naive}}(x)$。\n3.  稳定计算函数，它实现上述混合算法来找到 $d_{\\text{stable}}(x)$。\n\n对于测试套件中的每个输入 $x$，我们将计算三个所要求的相对误差：\n- $\\epsilon_1 = \\left|\\dfrac{f_{\\text{naive}} - f_{\\text{ref}}}{f_{\\text{ref}}}\\right|$\n- $\\epsilon_2 = \\left|\\dfrac{d_{\\text{naive}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$\n- $\\epsilon_3 = \\left|\\dfrac{d_{\\text{stable}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$\n\n对于 $x=0$ 的情况，$d_{\\text{ref}}=0$，误差指标 $\\epsilon_2$ 和 $\\epsilon_3$ 被定义为 $0$。",
            "answer": "```python\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Solves the numerical analysis problem of computing f(x) = sin(x)/x and d(x) = 1-f(x).\n    It compares a naive method with a stable, series-based method against a high-precision reference.\n    \"\"\"\n\n    # Set precision for the high-precision reference calculation. 50 digits is sufficient.\n    getcontext().prec = 50\n\n    def reference_d(x_str: str) - Decimal:\n        \"\"\"Computes d(x) to high precision using its Taylor series.\"\"\"\n        if x_str == '0':\n            return Decimal(0)\n\n        x = Decimal(x_str)\n        x_sq = x * x\n        \n        # d(x) = sum_{k=1 to inf} (-1)^(k-1) * x^(2k) / (2k+1)!\n        # term_{k} = (-1)^(k-1) * x^(2k) / (2k+1)!\n        # The ratio term_{k+1} / term_{k} = -x^2 / ((2k+2)(2k+3))\n\n        k = 1\n        term = x_sq / Decimal(6)  # First term (k=1)\n        d_val = term\n        \n        # Sum until the next term is smaller than the context precision\n        while abs(term)  Decimal('1e-50'):\n            k += 1\n            term *= -x_sq / Decimal((2 * k) * (2 * k + 1))\n            d_val += term\n        \n        return d_val\n\n    def naive_f(x: float) - float:\n        \"\"\"Computes f(x) = sin(x)/x naively.\"\"\"\n        if x == 0.0:\n            return 1.0\n        return np.sin(x) / x\n\n    def stable_d(x: float, threshold: float) - float:\n        \"\"\"\n        Computes d(x) using a stable hybrid algorithm.\n        \"\"\"\n        if x == 0.0:\n            return 0.0\n        \n        if abs(x)  threshold:\n            # For small |x|, use the Taylor series for d(x) to avoid cancellation.\n            # d(x) = x^2/6 - x^4/120 + x^6/5040 - ...\n            x_sq = x * x\n            \n            # term_{k+1} = term_{k} * (-x^2) / ((2k+2)(2k+3))\n            k = 1\n            term = x_sq / 6.0  # First term (k=1)\n            d_val = term\n            \n            # Sum until convergence at double precision\n            for k_iter in range(2, 15): # 15 iterations is more than enough\n                term *= -x_sq / ((2 * k_iter) * (2 * k_iter + 1))\n                d_val_prev = d_val\n                d_val += term\n                if d_val == d_val_prev:\n                    break\n            return d_val\n        else:\n            # For larger |x|, direct computation is stable enough.\n            f_val = np.sin(x) / x\n            return 1.0 - f_val\n\n    # Define test cases from the problem statement\n    test_cases_str = ['0', '1e-12', '1e-10', '1e-8', '-1e-7', '1e-7', '1e-4', '1e-1']\n    test_cases_float = [float(x) for x in test_cases_str]\n    \n    # Threshold for switching to series expansion, based on O(sqrt(u)) analysis\n    # For double precision, u ~ 10^-16, sqrt(u) ~ 10^-8. 10^-7 is a safe choice.\n    threshold = 1e-7\n\n    all_results = []\n    for x_str, x_float in zip(test_cases_str, test_cases_float):\n        # 1. High-precision reference calculation\n        d_ref_dec = reference_d(x_str)\n        f_ref_dec = Decimal(1) - d_ref_dec\n        d_ref = float(d_ref_dec)\n        f_ref = float(f_ref_dec)\n\n        # 2. Naive computation\n        f_naive_val = naive_f(x_float)\n        d_naive_val = 1.0 - f_naive_val\n\n        # 3. Stable computation for the decrement\n        d_stable_val = stable_d(x_float, threshold)\n\n        # 4. Compute error metrics\n        if x_float == 0.0:\n            err_f_naive = 0.0\n            err_d_naive = 0.0\n            err_d_stable = 0.0\n        else:\n            # Relative error of naive f(x)\n            err_f_naive = abs((f_naive_val - f_ref) / f_ref) if f_ref != 0 else 0.0\n            \n            if d_ref == 0.0:\n                # This branch should not be taken for x != 0\n                err_d_naive = 0.0 if d_naive_val == 0.0 else float('inf')\n                err_d_stable = 0.0 if d_stable_val == 0.0 else float('inf')\n            else:\n                # Relative error of naive d(x)\n                err_d_naive = abs((d_naive_val - d_ref) / d_ref)\n                # Relative error of stable d(x)\n                err_d_stable = abs((d_stable_val - d_ref) / d_ref)\n        \n        all_results.append([err_f_naive, err_d_naive, err_d_stable])\n\n    # Format output as a string representing a list of lists, without spaces.\n    formatted_results = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了算法和数学上的改进，现代硬件也为提高数值精度提供了强大的工具。本练习  将带您探索“融合乘加”（Fused Multiply-Add, FMA）指令，这是现代处理器的一项重要特性。您将通过评估多项式和计算点积等基本运算，量化比较使用和不使用 FMA 时的数值误差，从而亲身体验硬件级别的优化如何通过减少舍入次数来显著减轻灾难性抵消的影响。",
            "id": "3165813",
            "problem": "考虑在支持积和熔加（Fused Multiply-Add, FMA）的现代处理器中进行浮点计算。我们使用标准舍入模型来处理浮点运算：每个基本算术运算返回精确实数结果乘以一个形式为 $1 + \\delta$ 的因子，其中 $\\delta$ 是一个其绝对值受机器精度 $ \\epsilon $ 限制的小数。在没有 FMA 的情况下，像 $a\\times b + c$ 这样的复合运算在乘法和加法处会经历两次独立的舍入。使用 FMA 时，$a\\times b + c$ 会作为单次操作执行，只进行一次舍入。当两个数量级相近、符号相反的数相加时，会发生灾难性抵消，导致有效数字严重损失。舍入误差源于算术运算中的有限精度舍入，而截断误差源于对连续或无限过程的近似；本问题不涉及截断误差，但会涉及舍入误差和抵消误差。\n\n你需要评估特定的多项式和点积，在使用和不使用 FMA 的情况下测量数值误差，并量化 FMA 如何减轻抵消误差。定义绝对误差为 $E_{\\text{abs}} = \\lvert \\hat{y} - y \\rvert$，相对误差为 $E_{\\text{rel}} = \\frac{\\lvert \\hat{y} - y \\rvert}{\\lvert y \\rvert}$，其中 $\\hat{y}$ 是计算值，$y$ 是高精度参考值。当 $y = 0$ 时，使用绝对误差；否则，使用相对误差。\n\n任务是：\n\n1. 对于给定的输入，使用 Horner 方案，分别通过标准乘加运算和 FMA 运算来评估多项式。多项式为 $p_1(x) = (x - 1)^8$ 和 $p_2(x) = (x - 1)^{12}$。此外，还包括一个基准评估，即在一个远离抵消误差的值上评估 $p_3(x) = (x - 1)^8$。\n\n2. 在有和没有 FMA 累加的情况下，计算指定向量对的点积。\n\n3. 对每个测试用例，计算改进因子 $I = \\frac{E_{\\text{noFMA}}}{E_{\\text{FMA}}}$，当 $y \\neq 0$ 时使用相对误差，当 $y = 0$ 时使用绝对误差。\n\n使用通过任意精度算术计算的高精度参考值 $y$，以近似精确的实数算术结果进行比较。然后计算每个测试用例的改进因子。\n\n测试套件：\n- 通过 Horner 方法进行多项式测试：\n  - $T_1$：$p_1(x)$ 在 $x = 1 + 10^{-8}$ 处。\n  - $T_2$：$p_2(x)$ 在 $x = 1 + 10^{-10}$ 处。\n  - $T_3$：$p_3(x)$ 在 $x = 2$ 处。\n- 点积测试：\n  - $T_4$：$v^{(A)} = [10^8, 10^8, 10^8, 10^8, 10^8, 10^8, 10^8, 10^8]$ 和 $w^{(A)} = [10^{-8}, -10^{-8}, 10^{-8}, -10^{-8}, 10^{-8}, -10^{-8}, 10^{-8}, -10^{-8}]$。\n  - $T_5$：$v^{(B)} = [10^{16}, 1, -10^{16}, 1, 10^{16}, -1]$ 和 $w^{(B)} = [10^{-16}, 1, 10^{-16}, 1, -10^{-16}, 1]$。\n  - $T_6$：长度为 $100$ 的向量 $v^{(C)}$，其元素为 $v_i = (-1)^i \\cdot 10^8$，以及长度为 $100$ 的向量 $w^{(C)}$，其元素为 $w_i = 10^{-8}$，其中 $i = 1, \\dots, 100$。\n\n实现要求：\n- 使用 Horner 方案以 $y \\leftarrow y \\cdot x + a_i$ 的形式评估多项式，其中 $a_i$ 是从最高次项到常数项排序的系数。FMA 变体应使用单个积和熔加操作 $y \\leftarrow \\mathrm{fma}(y, x, a_i)$ 实现此更新，即 $y \\leftarrow (y \\cdot x + a_i)$ 只进行一次舍入。\n- 将点积评估为 $\\sum_{i=1}^{n} v_i w_i$；FMA 变体应使用 $y \\leftarrow \\mathrm{fma}(v_i, w_i, y)$ 进行累加。\n\n参考值：\n- 使用任意精度算术对相同的数学表达式进行计算以获得 $y$，其中数字以十进制形式指定（例如 $10^{-8}$），以便参考值能紧密近似精确的实数算术结果。\n\n最终输出：\n- 您的程序应生成一行输出，其中包含从 $T_1$ 到 $T_6$ 的六个改进因子，按顺序 $[I_{T_1}, I_{T_2}, I_{T_3}, I_{T_4}, I_{T_5}, I_{T_6}]$ 以逗号分隔的列表形式包含在方括号内，每个因子格式化为 $12$ 位有效数字（例如，$[1.23456789012,2.0,3.14159265359, ...]$）。",
            "solution": "用户的要求是解决一个数值分析问题，该问题涉及比较标准浮点算术与使用积和熔加（Fused Multiply-Add, FMA）能力的算术。目标是量化 FMA 在减轻数值误差（特别是舍入误差和灾难性抵消）方面所带来的改进。\n\n### 问题验证\n\n首先，我将根据所需程序验证问题陈述。\n\n#### 步骤1：提取给定信息\n\n-   **浮点模型**：每个基本算术运算都受舍入影响，模型为乘以一个 $(1 + \\delta)$ 因子，其中 $|\\delta| \\le \\epsilon$（$\\epsilon$ 是机器精度）。\n-   **标准计算**：像 $a \\times b + c$ 这样的运算涉及两个舍入步骤：一个用于乘法，一个用于加法，即 $fl(fl(a \\times b) + c)$。\n-   **FMA 计算**：像 $a \\times b + c$ 这样的运算作为单个单元执行，只有一个舍入步骤，即 $fl(a \\times b + c)$。\n-   **误差度量**：绝对误差 $E_{\\text{abs}} = |\\hat{y} - y|$ 和相对误差 $E_{\\text{rel}} = \\frac{|\\hat{y} - y|}{|y|}$。除非真值 $y=0$，否则使用相对误差；当 $y=0$ 时，使用绝对误差。\n-   **改进因子**：$I = \\frac{E_{\\text{noFMA}}}{E_{\\text{FMA}}}$，其中 $E$ 是误差（根据情况为相对或绝对误差）。\n-   **参考值 ($y$)**：使用任意精度算术计算的高精度值，作为精确实数结果的代理。\n-   **任务**：\n    1.  使用 Horner 方案，在有和没有 FMA 的情况下，评估多项式 $p_1(x) = (x - 1)^8$ 和 $p_2(x) = (x - 1)^{12}$。同时测试一个基准案例 $p_3(x) = (x-1)^8$。\n    2.  计算指定向量对的点积，在有和没有 FMA 累加的情况下进行。\n-   **实现**：\n    -   Horner 方案更新：$y \\leftarrow y \\cdot x + a_i$（标准）和 $y \\leftarrow \\mathrm{fma}(y, x, a_i)$（FMA）。\n    -   点积累加：$y \\leftarrow y + v_i \\cdot w_i$（标准循环）和 $y \\leftarrow \\mathrm{fma}(v_i, w_i, y)$（FMA 循环）。\n-   **测试套件**：\n    -   $T_1$：$p_1(x) = (x - 1)^8$ 在 $x = 1 + 10^{-8}$ 处。\n    -   $T_2$：$p_2(x) = (x - 1)^{12}$ 在 $x = 1 + 10^{-10}$ 处。\n    -   $T_3$：$p_3(x) = (x - 1)^8$ 在 $x = 2$ 处。\n    -   $T_4$：$v^{(A)} = [10^8, \\dots, 10^8]$ (8 个元素), $w^{(A)} = [10^{-8}, -10^{-8}, \\dots]$。\n    -   $T_5$：$v^{(B)} = [10^{16}, 1, -10^{16}, 1, 10^{16}, -1]$, $w^{(B)} = [10^{-16}, 1, 10^{-16}, 1, -10^{-16}, 1]$。\n    -   $T_6$：`v_i = (-1)^i \\cdot 10^8`，`w_i = 10^{-8}`，其中 $i=1, \\dots, 100$。\n-   **输出格式**：包含六个改进因子的单行列表，`[I_T1, ..., I_T6]`，格式化为 $12$ 位有效数字。\n\n#### 步骤2：使用提取的给定信息进行验证\n\n-   **科学基础**：该问题在根本上是合理的。它涉及数值分析的核心概念：浮点算术、舍入误差、灾难性抵消、Horner 方法和 FMA 指令。误差模型和定义都是标准的。\n-   **适定性**：该问题是适定的。输入、所需的计算和期望的输出都已明确定义。这些任务导向一组唯一且有意义的数值结果。从 $(x-1)^n$ 推导多项式系数是二项式定理的标准应用，而不是缺失的信息。\n-   **客观性**：问题以精确、客观和技术性的语言陈述，没有歧义或主观声明。\n\n该问题未表现出任何无效性缺陷。这是一个在计算科学或数值分析入门课程中常见的、表述清晰的标准问题。\n\n#### 步骤3：结论与行动\n\n该问题是**有效**的。将提供一个解决方案。\n\n### 基于原理的解决方案设计\n\n这个问题的核心在于积和熔加运算与非积和熔加运算之间的区别。\n\n1.  **基本原理**：像 $z = a \\times b + c$ 这样的标准浮点运算是作为两个独立的操作执行的：一次乘法后跟一次加法。每个操作都会产生舍入误差。\n    -   $\\hat{p} = fl(a \\times b) = (a \\times b)(1+\\delta_1)$\n    -   $\\hat{z} = fl(\\hat{p} + c) = (\\hat{p} + c)(1+\\delta_2)$\n    现代处理器上可用的积和熔加（FMA）指令以单次舍入执行这整个操作：\n    -   $\\hat{z}_{\\text{FMA}} = fl(a \\times b + c) = (a \\times b + c)(1+\\delta_3)$\n    FMA 在加上 $c$ 之前，以更高的中间精度计算乘积 $a \\times b$，从而减少了总的舍入误差。这在两种情况下尤其有效：\n    a.  当乘积 $a \\times b$ 本身不能精确表示为标准浮点数时，FMA 防止了在加法前对其进行舍入而导致的信息损失。\n    b.  当 $fl(a \\times b)$ 和 $c$ 的数量级几乎相等且符号相反时，它们的和会遭受灾难性抵消。FMA 可以通过将 $c$ 加到未舍入的高精度乘积 $a \\times b$ 上来缓解这种情况。\n\n2.  **多项式求值（Horner 方法）**：对于多项式 $P(x) = \\sum_{i=0}^{n} c_i x^i$，Horner 方法是一种高效的求值算法，由递推关系定义：$y_n = c_n$， $y_k = y_{k+1} \\cdot x + c_k$ 对 $k = n-1, \\dots, 0$。\n    多项式 $(x-1)^n$ 在展开后具有符号交替的大二项式系数。例如，$(x-1)^8 = x^8 - 8x^7 + 28x^6 - 56x^5 + 70x^4 - 56x^3 + 28x^2 - 8x + 1$。当在 $x=1$ 附近求值时，Horner 方法中的中间项会变得很大，它们的加减法会导致显著的灾难性抵消。FMA 以更高的精度执行每一步 $y \\cdot x + c_k$，保留了有效数字，从而得到更准确的结果。测试用例 $T_3$ 在 $x=2$ 处，作为一个不会发生此类抵消的基准。\n\n3.  **点积求值**：点积 $\\sum_{i=1}^{n} v_i w_i$ 是乘积之和。一个简单的实现涉及一个累加求和的循环。\n    -   _无 FMA_：`sum = sum + (v_i * w_i)`。这在乘积 `v_i * w_i` 之后有一次舍入，在与 `sum` 相加后又有一次舍入。\n    -   _有 FMA_：`sum = fma(v_i, w_i, sum)`。这里，`v_i` 和 `w_i` 的完整高精度乘积被计算出来，然后与 `sum` 相加，最后进行一次舍入。\n    测试用例 $T_4, T_5, T_6$ 被设计成精确和为零，但单个项不为零。这是求和中灾难性抵消的典型场景，其中 FMA 避免乘积中间舍入的能力对于准确性至关重要。\n\n4.  **处理边界情况**：在计算改进因子 $I = E_{\\text{noFMA}} / E_{\\text{FMA}}$ 时，如果 $E_{\\text{FMA}} = 0$，可能会发生除以零的情况。\n    -   如果 $E_{\\text{noFMA}}$ 和 $E_{\\text{FMA}}$ 均为零（如在 $T_3$ 中），则两种方法的准确性相同，改进因子逻辑上为 $1$。\n    -   如果 $E_{\\text{FMA}}=0$ 但 $E_{\\text{noFMA}}  0$（如在 $T_5$ 中），则改进理论上是无限的。为了按要求提供数值输出，我们可以使用一个代理来表示 FMA 误差。一个合理的选择是最小的正规化浮点数 `numpy.finfo(float).tiny`，它代表了浮点分辨率的极限。这将为改进因子产生一个非常大的有限数。\n    -   如果 $E_{\\text{noFMA}}=0$ 但 $E_{\\text{FMA}}  0$（如在 $T_4, T_6$ 中），这表明标准方法偶然产生了精确答案，而 FMA 方法累积了微小误差。在这种情况下，改进因子正确地计算为 $0$。\n\n实现将使用 Python 的 `math` 模块进行标准运算，使用 `math.fma` 进行积和熔加运算。高精度参考值将使用 `decimal` 模块计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport math\nimport decimal\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes numerical errors with and without Fused Multiply-Add (FMA)\n    and calculates the improvement factor for a suite of test cases.\n    \"\"\"\n    # Set precision for high-accuracy reference calculations.\n    decimal.getcontext().prec = 100\n\n    # --- Helper Functions ---\n\n    def get_poly_coeffs(n):\n        \"\"\"Computes coefficients for the expanded form of (x-1)^n.\"\"\"\n        coeffs = []\n        # Horner's method requires coefficients from highest degree (c_n) down to c_0.\n        # The coefficient of x^k in (x-1)^n is C(n, k) * (-1)^(n-k).\n        # But we need to order them for c_n, c_{n-1}, ..., c_0 for Horner's method.\n        # The coeff of x^i is C(n, i) * (-1)^(n-i).\n        for i in range(n, -1, -1):\n            coeff = math.comb(n, i) * ((-1)**(n - i))\n            coeffs.append(float(coeff))\n        return coeffs\n\n    def horner_nofma(coeffs, x):\n        \"\"\"Evaluates a polynomial using Horner's scheme with standard operators.\"\"\"\n        y = 0.0\n        for c in coeffs:\n            y = y * x + c\n        return y\n\n    def horner_fma(coeffs, x):\n        \"\"\"Evaluates a polynomial using Horner's scheme with FMA.\"\"\"\n        y = 0.0\n        for c in coeffs:\n            y = math.fma(y, x, c)\n        return y\n\n    def dot_nofma(v, w):\n        \"\"\"Computes a dot product with standard operators.\"\"\"\n        s = 0.0\n        for i in range(len(v)):\n            s += v[i] * w[i]\n        return s\n\n    def dot_fma(v, w):\n        \"\"\"Computes a dot product using FMA for accumulation.\"\"\"\n        s = 0.0\n        for i in range(len(v)):\n            s = math.fma(v[i], w[i], s)\n        return s\n\n    def get_improvement(y_ref, y_nofma, y_fma):\n        \"\"\"\n        Calculates the improvement factor I = E_noFMA / E_FMA.\n        Handles edge cases like division by zero.\n        \"\"\"\n        y_ref_f = float(y_ref)\n\n        if y_ref_f == 0.0:\n            err_nofma = abs(y_nofma)\n            err_fma = abs(y_fma)\n        else:\n            err_nofma = abs(y_nofma - y_ref_f) / abs(y_ref_f)\n            err_fma = abs(y_fma - y_ref_f) / abs(y_ref_f)\n\n        if err_fma == err_nofma:\n            return 1.0\n        \n        if err_fma == 0.0:\n            # Improvement is theoretically infinite. To provide a finite number,\n            # we can divide by the smallest representable error, which is related to machine epsilon.\n            # Using the smallest positive normalized float number as a proxy for the error.\n            if y_ref_f == 0.0:\n                err_fma_proxy = np.finfo(float).tiny\n            else:\n                err_fma_proxy = np.finfo(float).ulp(y_ref_f) if y_ref_f != 0 else np.finfo(float).tiny\n                if err_fma_proxy == 0.0: err_fma_proxy = np.finfo(float).tiny\n\n            if err_fma_proxy == 0.0: return np.inf\n            return err_nofma / err_fma_proxy\n\n        return err_nofma / err_fma\n\n    # --- Test Case Definitions ---\n\n    test_cases = [\n        # T1: p1(x) = (x-1)^8 at x = 1 + 1e-8\n        {\n            'eval_func_nofma': lambda: horner_nofma(get_poly_coeffs(8), 1.0 + 1e-8),\n            'eval_func_fma': lambda: horner_fma(get_poly_coeffs(8), 1.0 + 1e-8),\n            'ref_val': (decimal.Decimal('1e-8'))**8\n        },\n        # T2: p2(x) = (x-1)^12 at x = 1 + 1e-10\n        {\n            'eval_func_nofma': lambda: horner_nofma(get_poly_coeffs(12), 1.0 + 1e-10),\n            'eval_func_fma': lambda: horner_fma(get_poly_coeffs(12), 1.0 + 1e-10),\n            'ref_val': (decimal.Decimal('1e-10'))**12\n        },\n        # T3: p3(x) = (x-1)^8 at x = 2\n        {\n            'eval_func_nofma': lambda: horner_nofma(get_poly_coeffs(8), 2.0),\n            'eval_func_fma': lambda: horner_fma(get_poly_coeffs(8), 2.0),\n            'ref_val': (decimal.Decimal('2') - decimal.Decimal('1'))**8\n        },\n        # T4: Dot product vA . wA\n        {\n            'eval_func_nofma': lambda: dot_nofma([1e8] * 8, [1e-8, -1e-8] * 4),\n            'eval_func_fma': lambda: dot_fma([1e8] * 8, [1e-8, -1e-8] * 4),\n            'ref_val': decimal.Decimal('0')\n        },\n        # T5: Dot product vB . wB\n        {\n            'eval_func_nofma': lambda: dot_nofma([1e16, 1.0, -1e16, 1.0, 1e16, -1.0], [1e-16, 1.0, 1e-16, 1.0, -1e-16, 1.0]),\n            'eval_func_fma': lambda: dot_fma([1e16, 1.0, -1e16, 1.0, 1e16, -1.0], [1e-16, 1.0, 1e-16, 1.0, -1e-16, 1.0]),\n            'ref_val': decimal.Decimal('0')\n        },\n        # T6: Dot product vC . wC\n        {\n            'v': [(-1.0)**(i+1) * 1e8 for i in range(100)], # In problem desc, i starts at 1. In Python, 0. i vs i+1 to match.\n            'w': [1e-8] * 100,\n            'eval_func_nofma': lambda: dot_nofma([(-1.0)**(i) * 1e8 for i in range(1, 101)], [1e-8] * 100),\n            'eval_func_fma': lambda: dot_fma([(-1.0)**(i) * 1e8 for i in range(1, 101)], [1e-8] * 100),\n            'ref_val': decimal.Decimal('0')\n        }\n    ]\n\n    # --- Main Execution Loop ---\n\n    results = []\n    for case in test_cases:\n        y_ref = case['ref_val']\n        y_nofma = case['eval_func_nofma']()\n        y_fma = case['eval_func_fma']()\n        \n        improvement = get_improvement(y_ref, y_nofma, y_fma)\n        results.append(improvement)\n\n    result_str = ','.join(format(res, '.12g') for res in results)\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        }
    ]
}