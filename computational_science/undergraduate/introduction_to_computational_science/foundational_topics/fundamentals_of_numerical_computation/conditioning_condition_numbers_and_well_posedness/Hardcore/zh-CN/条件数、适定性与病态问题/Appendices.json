{
    "hands_on_practices": [
        {
            "introduction": "理解误差如何传播是计算科学的基石。条件数是我们量化这种传播的主要工具。我们将从最简单的情况开始：评估一个标量函数 $f(x)=e^{x}$。通过从第一性原理推导其条件数，我们将看到它如何与函数的导数和函数值相关联。这个练习  将理论条件数与使用常见近似（泰勒级数）时的可观察误差具体联系起来，从而帮助你建立直觉，理解为何同一个函数对某些输入是良态的，而对另一些输入却是病态的。",
            "id": "3110304",
            "problem": "你需要分析使用截断泰勒级数计算指数函数的数值条件，并量化值域大小与相对误差放大之间的关系。考虑函数 $f(x) = e^{x}$ 以及通过 $x=0$ 处的 $n$ 阶泰勒多项式来近似 $f(x)$ 的算法，该多项式记为 $T_{n}(x) = \\sum_{k=0}^{n} \\frac{x^{k}}{k!}$。你的任务是将计算 $f(x)$ 问题的条件数与此截断级数在不同 $x$ 值下观测到的前向相对误差联系起来。\n\n仅使用以下基本原理：\n- 对于一个可微标量函数 $f$ 的相对条件数的定义：在点 $x$ 处的相对条件数是当输入扰动趋于零时，相对输出变化与相对输入变化之比的极限。\n- 关于 $x=0$ 的光滑函数的带拉格朗日余项的泰勒多项式。\n- 指数函数的标准性质。\n\n任务：\n1) 从相对条件数的定义出发，推导函数 $f(x)=e^{x}$ 在点 $x$ 处（其中 $f(x) \\neq 0$）的相对条件数 $\\kappa_{f}(x)$。不要使用任何预先记忆的快捷公式；从扰动趋于零的极限形式的相对条件数定义开始。\n2) 使用拉格朗日形式的泰勒余项，为 $x \\ge 0$ 时情况下的前向相对误差 $\\frac{|e^{x} - T_{n}(x)|}{|e^{x}|}$ 推导一个可计算的上界 $B(x,n)$。\n3) 实现一个程序，对于下面测试套件中的每个测试用例 $(x,n)$，计算：\n   - 推导出的相对条件数 $\\kappa_{f}(x)$。\n   - 使用浮点运算观测到的前向相对误差 $r(x,n) = \\frac{|T_{n}(x) - e^{x}|}{|e^{x}|}$。\n   - 一个布尔值 $\\mathrm{BoundOK}(x,n)$，当且仅当 $r(x,n) \\le B(x,n)$ 时为 $\\mathrm{True}$。\n4) 程序不得读取任何输入。它必须计算测试套件的值，并按以下确切格式打印单行输出：一个由方括号括起来的、以逗号分隔的各用例三元组列表，其中每个三元组的形式为 $[\\kappa_{f}(x),r(x,n),\\mathrm{BoundOK}(x,n)]$。列表中不得包含空格，浮点数必须四舍五入到小数点后恰好 $10$ 位，布尔值必须打印为 $\\mathrm{True}$ 或 $\\mathrm{False}$。\n\n测试套件（每对 $(x,n)$ 是一个测试用例）：\n- $(x,n) = (0,0)$\n- $(x,n) = (0.1,3)$\n- $(x,n) = (1,5)$\n- $(x,n) = (5,10)$\n- $(x,n) = (10,10)$\n- $(x,n) = (20,10)$\n\n注意：\n- 不涉及物理单位。\n- 不涉及角度。\n- 输出应为单行，包含六个测试用例的结果列表，格式必须完全符合规定，例如 $[[a,b,c],[d,e,f],\\dots]$，但用指定的数值和布尔值替换。\n- 测试套件的设计包括一个 $x=0$ 的边界情况、一些中等值以及一个较大的值 $x=20$，以探究值域大小与相对误差放大之间的联系。\n\n你的程序应生成单行输出，其中包含一个由方括号括起来的、以逗号分隔的六个三元组列表，不含空格，例如：$[[\\kappa_{1},r_{1},\\mathrm{BoundOK}_{1}],[\\kappa_{2},r_{2},\\mathrm{BoundOK}_{2}],\\dots,[\\kappa_{6},r_{6},\\mathrm{BoundOK}_{6}]]$.",
            "solution": "问题被评估为有效。\n\n1.  **已知条件提取**：\n    *   函数：$f(x) = e^{x}$。\n    *   近似算法：关于 $x=0$ 的 $n$ 阶截断泰勒级数，$T_{n}(x) = \\sum_{k=0}^{n} \\frac{x^{k}}{k!}$。\n    *   相对条件数 $\\kappa_{f}(x)$ 的定义：当输入扰动趋于零时，相对输出变化与相对输入变化之比的极限。\n    *   误差界限工具：带拉格朗日余项的泰勒多项式。\n    *   误差界限的约束条件：$x \\ge 0$。\n    *   任务：\n        1.  从定义出发，推导 $f(x)=e^{x}$ 的 $\\kappa_{f}(x)$。\n        2.  为 $x \\ge 0$ 时情况下的前向相对误差 $\\frac{|e^{x} - T_{n}(x)|}{|e^{x}|}$ 推导一个可计算的上界 $B(x,n)$。\n        3.  实现一个程序来计算 $\\kappa_{f}(x)$、观测到的前向相对误差 $r(x,n)$ 以及一个布尔值 $\\mathrm{BoundOK}(x,n)$，该布尔值指示是否 $r(x,n) \\le B(x,n)$。\n        4.  以指定格式打印特定测试套件的结果。\n    *   测试套件：$(x,n) \\in \\{(0,0), (0.1,3), (1,5), (5,10), (10,10), (20,10)\\}$。\n\n2.  **有效性分析**：\n    *   **科学依据**：该问题植根于数值分析的基本概念，包括泰勒级数近似、误差分析和函数条件数。这些是计算数学和科学中的标准课题。\n    *   **适定性**：问题陈述清晰，包含了所有必要的定义和约束。每个任务都能导出一个唯一的、明确定义的数学或计算结果。\n    *   **客观性**：问题陈述精确、量化，并且没有主观或含糊不清的语言。\n    *   相对条件数的定义涉及相对输入变化，通常为 $|\\delta x / x|$。该项在 $x=0$ 处是奇异的。然而，对于函数 $f(x)=e^x$，其条件数的标准公式 $\\kappa_f(x) = |x f'(x) / f(x)|$ 在 $x=0$ 处有一个可去奇点，计算结果为 $0$。这是条件数分析中一个标准且易于理解的方面。因此，该问题被认为是完全有效的。\n\n3.  **结论**：问题有效，将提供解答。\n\n***\n\n**1. 相对条件数 $\\kappa_{f}(x)$ 的推导**\n\n相对条件数 $\\kappa_{f}(x)$ 量化了函数相对输出变化对相对输入变化的敏感度。根据定义，对于输入 $x$ (其中 $x \\neq 0$) 的一个微小扰动 $\\delta x$，它由以下极限给出：\n$$ \\kappa_{f}(x) = \\lim_{\\delta x \\to 0} \\left| \\frac{\\text{f(x)的相对变化}}{\\text{x的相对变化}} \\right| = \\lim_{\\delta x \\to 0} \\left| \\frac{(f(x+\\delta x) - f(x))/f(x)}{(\\delta x)/x} \\right| $$\n我们可以重新排列极限内的表达式：\n$$ \\kappa_{f}(x) = \\lim_{\\delta x \\to 0} \\left| \\frac{x}{f(x)} \\cdot \\frac{f(x+\\delta x) - f(x)}{\\delta x} \\right| $$\n根据极限的性质，我们可以将不依赖于 $\\delta x$ 的项移到极限外部：\n$$ \\kappa_{f}(x) = \\left| \\frac{x}{f(x)} \\right| \\lim_{\\delta x \\to 0} \\left| \\frac{f(x+\\delta x) - f(x)}{\\delta x} \\right| $$\n极限项是 $f$ 在 $x$ 处导数的绝对值的定义，即 $|f'(x)|$。\n$$ \\kappa_{f}(x) = \\left| \\frac{x f'(x)}{f(x)} \\right| $$\n对于特定函数 $f(x) = e^{x}$，其导数为 $f'(x) = e^{x}$。将这些代入公式可得：\n$$ \\kappa_{f}(x) = \\left| \\frac{x \\cdot e^{x}}{e^{x}} \\right| = |x| $$\n该公式是为 $x \\neq 0$ 推导的。然而，它在 $x=0$ 处有良好定义，此时 $\\kappa_{f}(0) = |0| = 0$。这表明计算 $e^{0}$ 的问题是完全良态的。我们将对所有 $x$ 使用公式 $\\kappa_{f}(x) = |x|$。\n\n**2. 相对误差上界 $B(x,n)$ 的推导**\n\n我们的任务是为 $x \\ge 0$ 的情况下，使用泰勒多项式 $T_n(x)$ 近似 $f(x)=e^x$ 的前向相对误差找到一个上界。前向相对误差定义为：\n$$ r(x,n) = \\frac{|f(x) - T_{n}(x)|}{|f(x)|} = \\frac{|e^{x} - T_{n}(x)|}{|e^{x}|} $$\n绝对误差 $|e^{x} - T_{n}(x)|$ 由泰勒展开的余项给出。使用拉格朗日形式的余项 $R_n(x) = f(x) - T_n(x)$，我们有：\n$$ R_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!} x^{n+1} $$\n其中某个值 $c$ 介于 $0$ 和 $x$ 之间。对于 $f(x)=e^x$，它的所有阶导数也都是 $e^x$，所以 $f^{(n+1)}(c) = e^c$。因此，绝对误差为：\n$$ e^x - T_n(x) = \\frac{e^c}{(n+1)!} x^{n+1} $$\n将此代入相对误差公式：\n$$ r(x,n) = \\frac{\\left| \\frac{e^c}{(n+1)!} x^{n+1} \\right|}{|e^x|} $$\n问题规定 $x \\ge 0$。这意味着 $x^{n+1} \\ge 0$ 且 $e^x > 0$。值 $c$ 在区间 $[0, x]$ 内。\n$$ r(x,n) = \\frac{e^c x^{n+1}}{(n+1)! e^x} = e^{c-x} \\frac{x^{n+1}}{(n+1)!} $$\n为了找到 $r(x,n)$ 的上界，我们需要找到项 $e^{c-x}$ 的最大可能值。由于 $c \\in [0, x]$，指数 $c-x$ 在区间 $[-x, 0]$ 内。指数函数是单调递增的，所以它在此区间上的最大值出现在右端点，即 $c-x=0$（对应于 $c=x$）。\n$$ e^{c-x} \\le e^0 = 1 $$\n通过应用这个不等式，我们获得了相对误差的一个上界 $B(x,n)$：\n$$ r(x,n) \\le 1 \\cdot \\frac{x^{n+1}}{(n+1)!} $$\n因此，一个可计算的上界是：\n$$ B(x,n) = \\frac{x^{n+1}}{(n+1)!} $$\n\n**3. 算法实现**\n\n程序将遍历测试套件中的每对 $(x,n)$ 并执行以下计算：\n\n*   **相对条件数 $\\kappa_f(x)$**：使用推导出的公式 $\\kappa_f(x) = |x|$ 直接计算。\n*   **观测到的前向相对误差 $r(x,n)$**：这需要计算 $e^x$ 和 $T_n(x) = \\sum_{k=0}^{n} \\frac{x^k}{k!}$。$T_n(x)$ 的求和将通过迭代计算以保持数值稳定性，并避免单独计算大的幂和阶乘。过程如下：\n    1.  初始化 `total = 1.0`（对于 $k=0$ 项）和 `term = 1.0`。\n    2.  从 $k=1$ 循环到 $n$：将项更新为 `term = term * x / k` 并将其加到总和中：`total = total + term`。\n    3.  计算 `exp_x = numpy.exp(x)`。\n    4.  计算相对误差 $r(x,n) = \\frac{|total - exp\\_x|}{|exp\\_x|}$。\n*   **上界 $B(x,n)$**：这根据推导出的公式 $B(x,n) = \\frac{x^{n+1}}{(n+1)!}$ 计算。幂将使用 `numpy.power` 计算，阶乘将使用 `scipy.special.factorial` 计算，后者可以处理非整数参数并返回浮点结果，从而防止大 $n$ 值时发生溢出。\n*   **边界检查 $\\mathrm{BoundOK}(x,n)$**：这是一个由逻辑比较 $r(x,n) \\le B(x,n)$ 决定的布尔值。\n\n每个测试用例的结果——$\\kappa_f(x)$、$r(x,n)$ 和 $\\mathrm{BoundOK}(x,n)$——将被格式化为字符串 `[k,r,b]`，其中浮点数四舍五入到小数点后10位。然后，这些字符串将用逗号连接并用方括号括起来，以生成最终的输出行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import factorial\n\ndef solve():\n    \"\"\"\n    Analyzes the numerical conditioning of evaluating e^x using a truncated\n    Taylor series for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 0),\n        (0.1, 3),\n        (1.0, 5),\n        (5.0, 10),\n        (10.0, 10),\n        (20.0, 10),\n    ]\n\n    all_results_str = []\n    \n    for x, n in test_cases:\n        # 1. Compute the relative condition number kappa_f(x) = |x|\n        kappa_fx = np.abs(x)\n\n        # 2. Compute the observed forward relative error r(x,n)\n        # 2a. Compute T_n(x) = sum_{k=0 to n} x^k/k!\n        # An iterative method is used for better numerical stability.\n        # term_{k} = term_{k-1} * x / k\n        tn_x = 0.0\n        term = 1.0  # k=0 term: x^0/0! = 1\n        tn_x += term\n        if n > 0: # Handle n=0 case\n            for k in range(1, n + 1):\n                term = term * x / k\n                tn_x += term\n        \n        # 2b. Compute e^x\n        exp_x = np.exp(x)\n\n        # 2c. Compute the relative error r(x,n) = |T_n(x) - e^x| / |e^x|\n        # The denominator |e^x| is never zero for real x.\n        if exp_x == 0:\n            # This case is physically impossible for f(x)=e^x and real x,\n            # but included for robustness.\n            r_xn = np.inf if tn_x != 0 else 0.0\n        else:\n            r_xn = np.abs(tn_x - exp_x) / np.abs(exp_x)\n\n        # 3. Compute the upper bound B(x,n) on the relative error\n        # B(x,n) = x^(n+1) / (n+1)! for x >= 0\n        # Use exact=False to get a float result from factorial and avoid overflow.\n        b_xn = np.power(x, n + 1) / factorial(n + 1, exact=False)\n\n        # 4. Check if the observed error is within the derived bound\n        # A small tolerance could be used for floating point comparisons,\n        # but for this problem, direct comparison is sufficient.\n        bound_ok = r_xn = b_xn\n        \n        # Format the results for this case according to the problem specification\n        # Convert the boolean to the required string \"True\" or \"False\"\n        bool_str = \"True\" if bound_ok else \"False\"\n        case_result_str = (\n            f\"[{kappa_fx:.10f},\"\n            f\"{r_xn:.10f},\"\n            f\"{bool_str}]\"\n        )\n        all_results_str.append(case_result_str)\n\n    # Print the final result string in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现在，让我们从简单的函数求值转向一个更复杂的问题：求解非线性方程。方程的根对于方程自身的微小变化有多敏感？我们将分析求根问题的适定性 (well-posedness)，并利用一阶微扰分析推导出一个公式，该公式可以预测当函数受到轻微扰动时根会移动多少。这个练习  巧妙地展示了一个问题的内在敏感性（即条件）与算法行为之间的区别。通过比较预测的根位移与使用牛顿法和二分法等数值方法观察到的位移，你将更深入地理解是什么让一个求根问题变得“敏感”，以及这种敏感性是如何由函数在根处的导数所决定的。",
            "id": "3110311",
            "problem": "考虑非线性方程 $f(x) = x^3 - 3x + 1 = 0$。任务是分析计算出的根对于函数和（对于需要初始猜测的迭代方法而言）初始猜测中微小扰动的敏感性。该分析应基于数值分析的基本定义：算法的稳定性、问题的适定性以及通过解映射敏感性定义的条件数。\n\n定义扰动函数族 $f_\\varepsilon(x) = f(x) + \\varepsilon\\,g(x)$，其中 $\\varepsilon$ 是一个小的实数参数，$g(x)$ 是一个光滑函数。您将比较两种求根方法的行为：\n- 牛顿-拉夫逊方法（牛顿法），该方法需要一个可微函数和一个初始猜测。\n- 二分法，该方法需要一个两端函数值异号的区间，且不需要导数。\n\n分析必须探讨在单根处根映射 $f \\mapsto x^\\star$ 的适定性，并根据函数的加性扰动凭经验估计根的绝对条件数。您不能使用三次方程的任何闭式解来获得根；相反，您应实现这两种求根方法来计算数值近似解。三角函数中的角度量必须以弧度为单位进行解释。\n\n您的程序必须实现：\n- 使用 $f_\\varepsilon$ 导数的牛顿法求解 $f_\\varepsilon$。\n- 在指定的、函数值存在符号变化的区间上，使用二分法求解 $f_\\varepsilon$。\n\n使用以下测试套件，其中每个案例都指定了方法、扰动 $\\varepsilon$、扰动函数 $g(x)$，以及牛顿法的初始猜测或二分法的括号区间 $[a,b]$。所有三角函数求值都必须以弧度为单位。对于每个案例，根据以下定义计算指定的输出。\n\n输出定义：\n- 对于 $\\varepsilon$ 非零的案例，计算观测到的位移 $\\Delta x_{\\text{obs}} = \\lvert x_\\varepsilon - x_0 \\rvert$，其中 $x_\\varepsilon$ 是由指定方法计算的 $f_\\varepsilon$ 的根，$x_0$ 是通过相同选择规则（相同方法和括号区间，或由初始猜测决定的相同吸引盆）计算的对应基准根 $f$。\n- 对于 $\\varepsilon$ 非零的案例，计算预测的一阶位移大小 $\\Delta x_{\\text{pred}} = \\left| \\dfrac{\\varepsilon\\,g(x_0)}{f'(x_0)} \\right|$，其中 $f'(x) = 3x^2 - 3$ 是在基准根 $x_0$ 处求值的未扰动函数的导数。\n- 对于 $\\varepsilon$ 为零的案例，计算返回的根相对于相应基准的绝对差，并报告该方法所用的迭代次数。\n\n测试套件包含以下七个案例：\n\n1. 在 $[1, 2]$ 上使用二分法，$\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于区间 $[1,2]$ 中的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n2. 使用牛顿法，初始猜测为 $x_{\\text{init}} = 1.3$，$\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于从此初始猜测收敛到的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n3. 使用牛顿法，初始猜测为 $x_{\\text{init}} = 0.2$，$\\varepsilon = 0$ 且 $g$ 无关紧要。输出：根相对于案例2（$\\varepsilon = 0$ 时）的基准牛顿根的绝对差，以及所用的迭代次数。\n4. 在 $[1.1, 2.0]$ 上使用二分法，$\\varepsilon = 0$ 且 $g$ 无关紧要。输出：根相对于案例1（$\\varepsilon = 0$ 时）的基准二分法根的绝对差，以及所用的迭代次数。\n5. 在 $[0, 1]$ 上使用二分法，$\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于区间 $[0,1]$ 中的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n6. 在 $[-2, -1]$ 上使用二分法，$\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于区间 $[-2,-1]$ 中的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n7. 使用牛顿法，初始猜测为 $x_{\\text{init}} = 0.3$，$\\varepsilon = 10^{-12}$ 且 $g(x) = \\sin(x)$（弧度）。输出：对于从此初始猜测收敛到的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n\n算法要求：\n- 对于二分法，当区间宽度小于 $10^{-14}$ 或达到最大迭代次数 $200$ 次时终止。\n- 对于牛顿法，当绝对步长小于 $10^{-14}$ 或达到最大迭代次数 $200$ 次时终止。如果在某次迭代中导数的绝对值小于 $10^{-14}$，则继续迭代而不作特殊处理；该方法在此类条件下的行为是分析的一部分。\n\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，顺序如下：\n$[\\Delta x_{\\text{obs}}^{(1)}, \\Delta x_{\\text{pred}}^{(1)}, \\Delta x_{\\text{obs}}^{(2)}, \\Delta x_{\\text{pred}}^{(2)}, \\Delta x^{(3)}, N^{(3)}, \\Delta x^{(4)}, N^{(4)}, \\Delta x_{\\text{obs}}^{(5)}, \\Delta x_{\\text{pred}}^{(5)}, \\Delta x_{\\text{obs}}^{(6)}, \\Delta x_{\\text{pred}}^{(6)}, \\Delta x_{\\text{obs}}^{(7)}, \\Delta x_{\\text{pred}}^{(7)}]$，其中上标表示案例编号，$N^{(k)}$ 是案例 $k$ 在 $\\varepsilon = 0$ 时的迭代次数。\n\n所有输出必须是实数或整数。此问题不涉及物理单位，且 $g(x) = \\sin(x)$ 的所有角度量必须以弧度为单位进行解释。",
            "solution": "该问题要求分析非线性方程 $f(x) = x^3 - 3x + 1 = 0$ 的根对微小扰动的敏感性。此分析涉及适定性、条件数和数值算法稳定性的概念，具体来说是牛顿-拉夫逊法和二分法。\n\n### 1. 理论基础：适定性与条件数\n\n如果一个数学问题的解存在、唯一且连续地依赖于输入数据，则该问题被认为是**适定的**。对于求根问题 $f(x) = 0$，“输入数据”就是函数 $f$ 本身。我们关心的是当 $f$ 受到扰动时，根 $x^\\star$ 如何变化。寻找单根（其中 $f'(x^\\star) \\neq 0$）的问题是适定的。\n\n问题的**条件数**量化了这种敏感性。我们分析扰动函数族 $f_\\varepsilon(x) = f(x) + \\varepsilon g(x)$，其中 $\\varepsilon$ 是一个小参数。设 $x(\\varepsilon)$ 是 $f_\\varepsilon(x) = 0$ 的根。根据定义，$x(0) = x^\\star$ 是未扰动问题 $f(x)=0$ 的根。\n\n为了确定一阶敏感性，我们可以使用隐函数定理。由于 $x^\\star$ 是一个单根，$f'(x^\\star) \\neq 0$。这保证了在 $\\varepsilon = 0$ 附近，$x(\\varepsilon)$ 是 $\\varepsilon$ 的一个可微函数。我们将恒等式 $f(x(\\varepsilon)) + \\varepsilon g(x(\\varepsilon)) = 0$ 对 $\\varepsilon$ 求导：\n$$\n\\frac{d}{d\\varepsilon} \\left[ f(x(\\varepsilon)) + \\varepsilon g(x(\\varepsilon)) \\right] = 0\n$$\n应用链式法则，我们得到：\n$$\nf'(x(\\varepsilon)) \\frac{dx}{d\\varepsilon} + g(x(\\varepsilon)) + \\varepsilon g'(x(\\varepsilon)) \\frac{dx}{d\\varepsilon} = 0\n$$\n在 $\\varepsilon = 0$ 处求值，并注意到 $x(0) = x^\\star$，方程简化为：\n$$\nf'(x^\\star) \\frac{dx}{d\\varepsilon}\\bigg|_{\\varepsilon=0} + g(x^\\star) = 0\n$$\n求解导数（它代表了根对扰动的敏感性），得到：\n$$\n\\frac{dx}{d\\varepsilon}\\bigg|_{\\varepsilon=0} = - \\frac{g(x^\\star)}{f'(x^\\star)}\n$$\n对于一个小的非零 $\\varepsilon$，根的变化量 $\\Delta x = x(\\varepsilon) - x^\\star$ 可以通过一阶泰勒展开来近似：\n$$\n\\Delta x \\approx \\varepsilon \\frac{dx}{d\\varepsilon}\\bigg|_{\\varepsilon=0} = -\\varepsilon \\frac{g(x^\\star)}{f'(x^\\star)}\n$$\n因此，这个预测位移的大小为：\n$$\n\\Delta x_{\\text{pred}} = |\\Delta x| \\approx \\left| \\frac{\\varepsilon g(x^\\star)}{f'(x^\\star)} \\right|\n$$\n在我们的数值实现中，精确根 $x^\\star$ 是未知的。我们用它的数值近似值 $x_0$ 来代替，该值由未扰动的方程（$\\varepsilon=0$）计算得出。这就得到了问题中指定的公式：$\\Delta x_{\\text{pred}} = \\left| \\dfrac{\\varepsilon\\,g(x_0)}{f'(x_0)} \\right|$。项 $\\left| \\frac{g(x_0)}{f'(x_0)} \\right|$ 是根相对于扰动 $g(x)$ 的估计绝对条件数。一个大的值表明问题是病态的，即函数中的小扰动可能导致根的巨大变化。\n\n### 2. 数值算法\n\n我们将实现两种标准的求根算法。\n\n**二分法**：如果连续函数 $h(x)$ 在区间 $[a, b]$ 上满足 $h(a)$ 和 $h(b)$ 异号，则该方法保证收敛。它通过迭代地将区间减半来保持根被包含在内。在每一步中，计算中点 $c = (a+b)/2$。如果 $h(a)h(c)  0$，新区间变为 $[a, c]$，否则变为 $[c, b]$。当区间宽度 $b-a$ 小于容差 $10^{-14}$ 时，我们将终止迭代。\n\n**牛顿法**：这种迭代方法可以找到实值函数 $h(x)$ 根的逐次更优近似值。迭代公式定义为：\n$$\nx_{k+1} = x_k - \\frac{h(x_k)}{h'(x_k)}\n$$\n如果初始猜测 $x_0$ 足够接近一个单根，该方法将二次收敛。我们将把这个方法应用于扰动函数 $h(x) = f_\\varepsilon(x) = x^3 - 3x + 1 + \\varepsilon g(x)$，使用其导数 $h'(x) = f'_\\varepsilon(x) = 3x^2 - 3 + \\varepsilon g'(x)$。当绝对步长 $|x_{k+1} - x_k|$ 小于容差 $10^{-14}$ 时，我们将终止迭代。\n\n### 3. 测试案例的分步执行\n\n对于每个测试案例，我们通过实现这些算法并应用推导出的敏感性公式来计算所需的输出。\n\n未扰动函数为 $f(x) = x^3 - 3x + 1$，其导数为 $f'(x) = 3x^2 - 3$。该函数有三个不同的实根，分别位于区间 $[-2, -1]$、$[0, 1]$ 和 $[1, 2]$ 中。\n\n- **案例 1  4**：在 $[1, 2]$ 和 $[1.1, 2.0]$ 上使用二分法。\n  对于案例 1，我们首先在 $[1, 2]$ 上找到 $f(x)=0$ 的基准根 $x_0$。然后，我们在同一区间上找到 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 的扰动根 $x_\\varepsilon$。我们计算 $\\Delta x_{\\text{obs}} = |x_\\varepsilon - x_0|$ 和 $\\Delta x_{\\text{pred}} = |\\varepsilon x_0 / f'(x_0)|$。\n  对于案例 4，我们计算 $f(x)=0$ 在 $[1.1, 2.0]$ 上的根，并找出它与案例 1 基准根的绝对差，以及迭代次数。这测试了二分法对初始含根区间的稳健性。\n\n- **案例 2  3**：使用初始猜测的牛顿法。\n  对于案例 2，使用 $x_{\\text{init}} = 1.3$，我们找到 $f(x)=0$ 的基准根 $x_0$ 和 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 的扰动根 $x_\\varepsilon$。用于牛顿法的导数是 $f'_\\varepsilon(x) = 3x^2 - 3 + 10^{-6}$。然后我们计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n  对于案例 3，我们对 $f(x)=0$ 使用 $x_{\\text{init}} = 0.2$。这个初始猜测位于与案例 2 中找到的根不同的根的吸引盆中。我们报告迭代次数以及这个根与案例 2 基准根的绝对差。\n\n- **案例 5**：在 $[0, 1]$ 上使用二分法。\n  与案例 1 类似，但是针对位于区间 $[0, 1]$ 内的根。我们找到一个基准根 $x_0$ 和一个 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 的扰动根 $x_\\varepsilon$，然后计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n\n- **案例 6**：在 $[-2, -1]$ 上使用二分法。\n  与案例 1 和 5 类似，但是针对位于区间 $[-2, -1]$ 内的根。我们找到 $x_0$ 和 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 的一个扰动根 $x_\\varepsilon$，然后计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n\n- **案例 7**：使用不同扰动的牛顿法。\n  使用 $x_{\\text{init}} = 0.3$，我们找到基准根 $x_0$。然后我们找到 $f_\\varepsilon(x) = f(x) + 10^{-12}\\sin(x)$ 的扰动根 $x_\\varepsilon$，使用导数 $f'_\\varepsilon(x) = 3x^2 - 3 + 10^{-12}\\cos(x)$。最后，我们计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}} = |\\varepsilon \\sin(x_0) / f'(x_0)|$。\n\n对于小的 $\\varepsilon$，$\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$ 之间的一致性为我们的一阶敏感性分析提供了经验验证。条件数在 $|f'(x_0)|$ 很小时会很大，它决定了对于给定的扰动，根位移的大小。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the root-finding algorithms and computes the required outputs for the seven test cases.\n    \"\"\"\n    # Define global parameters for algorithms\n    TOL = 1e-14\n    MAX_ITER = 200\n\n    # Define the base function and its derivative\n    def f(x):\n        return x**3 - 3*x + 1\n\n    def f_prime(x):\n        return 3*x**2 - 3\n\n    # Define perturbation functions and their derivatives\n    def g_x(x): return x\n    def g_x_prime(x): return 1.0\n    def g_sin(x): return np.sin(x)\n    def g_sin_prime(x): return np.cos(x)\n\n    # --- Numerical Method Implementations ---\n\n    def bisection(func, a, b, tol=TOL, max_iter=MAX_ITER):\n        \"\"\"\n        Bisection method for root finding.\n        Returns the root and the number of iterations.\n        \"\"\"\n        fa = func(a)\n        if fa * func(b) = 0:\n            # This should not happen with the given problem setup.\n            raise ValueError(\"Function has the same sign at interval endpoints.\")\n        \n        iterations = 0\n        while (b - a)  tol and iterations  max_iter:\n            iterations += 1\n            c = a + (b - a) / 2.0\n            fc = func(c)\n            if fc == 0.0:\n                break\n            if fa * fc  0:\n                b = c\n            else:\n                a = c\n                fa = fc\n        return a + (b - a) / 2.0, iterations\n\n    def newton(func, func_prime, x0, tol=TOL, max_iter=MAX_ITER):\n        \"\"\"\n        Newton-Raphson method for root finding.\n        Returns the root and the number of iterations.\n        \"\"\"\n        xk = x0\n        iterations = 0\n        while iterations  max_iter:\n            iterations += 1\n            f_val = func(xk)\n            fp_val = func_prime(xk)\n            \n            # The problem specifies to proceed even if fp_val is very small.\n            if fp_val == 0.0:\n                # This would cause a division by zero.\n                # A robust solver might stop, but we follow instructions.\n                # In this specific problem, it doesn't happen at relevant points.\n                break \n\n            step = f_val / fp_val\n            xk_next = xk - step\n            \n            if abs(step)  tol:\n                return xk_next, iterations\n            \n            xk = xk_next\n        return xk, iterations\n\n    # --- Test Case Execution ---\n\n    results = []\n\n    # Case 1: Bisection on [1, 2], eps=1e-6, g(x)=x\n    eps1 = 1e-6\n    g1, _ = g_x, g_x_prime\n    f_eps1 = lambda x: f(x) + eps1 * g1(x)\n    \n    x0_c1, _ = bisection(f, 1.0, 2.0)\n    xe_c1, _ = bisection(f_eps1, 1.0, 2.0)\n    \n    dx_obs1 = abs(xe_c1 - x0_c1)\n    dx_pred1 = abs((eps1 * g1(x0_c1)) / f_prime(x0_c1))\n    results.extend([dx_obs1, dx_pred1])\n    \n    # Stash baseline root for Case 4\n    baseline_bisection_root_from_c1 = x0_c1\n\n    # Case 2: Newton, x_init=1.3, eps=1e-6, g(x)=x\n    eps2 = 1e-6\n    g2, g2_prime = g_x, g_x_prime\n    f_eps2 = lambda x: f(x) + eps2 * g2(x)\n    fp_eps2 = lambda x: f_prime(x) + eps2 * g2_prime(x)\n\n    x0_c2, _ = newton(f, f_prime, 1.3)\n    xe_c2, _ = newton(f_eps2, fp_eps2, 1.3)\n\n    dx_obs2 = abs(xe_c2 - x0_c2)\n    dx_pred2 = abs((eps2 * g2(x0_c2)) / f_prime(x0_c2))\n    results.extend([dx_obs2, dx_pred2])\n\n    # Stash baseline root for Case 3\n    baseline_newton_root_from_c2 = x0_c2\n\n    # Case 3: Newton, x_init=0.2, eps=0\n    x_c3, n_c3 = newton(f, f_prime, 0.2)\n    dx_c3 = abs(x_c3 - baseline_newton_root_from_c2)\n    results.extend([dx_c3, n_c3])\n\n    # Case 4: Bisection, [1.1, 2.0], eps=0\n    x_c4, n_c4 = bisection(f, 1.1, 2.0)\n    dx_c4 = abs(x_c4 - baseline_bisection_root_from_c1)\n    results.extend([dx_c4, n_c4])\n\n    # Case 5: Bisection on [0, 1], eps=1e-6, g(x)=x\n    eps5 = 1e-6\n    g5, _ = g_x, g_x_prime\n    f_eps5 = lambda x: f(x) + eps5 * g5(x)\n\n    x0_c5, _ = bisection(f, 0.0, 1.0)\n    xe_c5, _ = bisection(f_eps5, 0.0, 1.0)\n\n    dx_obs5 = abs(xe_c5 - x0_c5)\n    dx_pred5 = abs((eps5 * g5(x0_c5)) / f_prime(x0_c5))\n    results.extend([dx_obs5, dx_pred5])\n\n    # Case 6: Bisection on [-2, -1], eps=1e-6, g(x)=x\n    eps6 = 1e-6\n    g6, _ = g_x, g_x_prime\n    f_eps6 = lambda x: f(x) + eps6 * g6(x)\n\n    x0_c6, _ = bisection(f, -2.0, -1.0)\n    xe_c6, _ = bisection(f_eps6, -2.0, -1.0)\n\n    dx_obs6 = abs(xe_c6 - x0_c6)\n    dx_pred6 = abs((eps6 * g6(x0_c6)) / f_prime(x0_c6))\n    results.extend([dx_obs6, dx_pred6])\n\n    # Case 7: Newton, x_init=0.3, eps=1e-12, g(x)=sin(x)\n    eps7 = 1e-12\n    g7, g7_prime = g_sin, g_sin_prime\n    f_eps7 = lambda x: f(x) + eps7 * g7(x)\n    fp_eps7 = lambda x: f_prime(x) + eps7 * g7_prime(x)\n\n    x0_c7, _ = newton(f, f_prime, 0.3)\n    xe_c7, _ = newton(f_eps7, fp_eps7, 0.3)\n\n    dx_obs7 = abs(xe_c7 - x0_c7)\n    dx_pred7 = abs((eps7 * g7(x0_c7)) / f_prime(x0_c7))\n    results.extend([dx_obs7, dx_pred7])\n\n    # --- Final Output ---\n    # Convert all results to string, join with commas, and enclose in brackets.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "条件的概念可以有力地扩展到线性代数领域。特征值问题是许多科学应用的核心，也是敏感性分析至关重要的一个典型例子。我们将探讨对称矩阵与非对称（特别是非正规）矩阵在特征值问题条件数上的显著差异。通过这个实践 ，你将通过数值计算验证对称矩阵的特征值非常稳定，这是谱定理的一个推论。相比之下，你将使用非正规矩阵的左右特征向量来计算其特征值条件数，并亲眼目睹一个微小的扰动如何引起特征值的巨大变化——这一现象在从控制理论到量子力学等领域都有着深远的影响。",
            "id": "3110268",
            "problem": "考虑在微小加性变化下，有限维实矩阵的特征值和特征向量的扰动。使用以下基本基础：矩阵的特征值和特征向量的定义、矩阵的诱导算子 $2$-范数、实对称矩阵的谱定理，以及非对称可对角化矩阵的左、右特征向量的概念。你的程序必须使用两个互补的思想来量化敏感性：对称矩阵的特征向量旋转几何，以及基于非正规矩阵的左、右特征向量的特征值条件数。\n\n在推理和实现中使用的定义：\n- 对于实矩阵 $M$，其诱导算子 $2$-范数是 $\\|M\\|_{2}$，定义为 $M$ 的最大奇异值。\n- 对于实对称矩阵 $A$，令 $\\lambda_{i}(A)$ 表示其特征值，并令 $u_{i}(A)$ 表示相应的单位范数特征向量。\n- 对于可对角化的实（可能非对称）矩阵 $B$，令 $x_{i}(B)$ 表示与同一（单）特征值 $\\lambda_{i}(B)$ 相关联的右特征向量，令 $y_{i}(B)$ 表示左特征向量，满足 $B x_{i}(B) = \\lambda_{i}(B) x_{i}(B)$ 和 $y_{i}(B)^{\\mathsf{T}} B = \\lambda_{i}(B) y_{i}(B)^{\\mathsf{T}}$。特征值条件数定义为\n$$\n\\kappa_{i}(B) = \\frac{\\|x_{i}(B)\\|_{2}\\,\\|y_{i}(B)\\|_{2}}{\\left|y_{i}(B)^{\\mathsf{T}} x_{i}(B)\\right|},\n$$\n该值与 $x_{i}(B)$ 和 $y_{i}(B)$ 的缩放无关。\n- 对于目标单特征向量 $u_{i}(A)$ 和一个扰动矩阵 $A + \\Delta$，定义 $u_{i}(A)$ 与匹配的扰动单位特征向量 $u_{i}(A+\\Delta)$ 之间的主夹角 $\\theta_{i}$ 为 $\\cos(\\theta_{i}) = \\left|u_{i}(A)^{\\mathsf{T}} u_{i}(A+\\Delta)\\right|$ 和 $\\sin(\\theta_{i}) = \\sqrt{1 - \\cos^{2}(\\theta_{i})}$。$\\lambda_{i}(A)$ 的谱隙为 $\\mathrm{gap}_{i} = \\min_{j \\neq i} \\left|\\lambda_{i}(A) - \\lambda_{j}(A)\\right|$。\n\n你的任务是实现一个程序，为指定的测试套件计算以下敏感性比率：\n- 对称矩阵特征值敏感性比率：\n$$\nr_{\\text{sym-eig}} = \\frac{\\max_{i} \\left|\\lambda_{i}(A+\\Delta) - \\lambda_{i}(A)\\right|}{\\|\\Delta\\|_{2}}.\n$$\n在比较 $A$ 和 $A+\\Delta$ 时，应通过邻近性来匹配特征值。\n- 带有 Davis–Kahan 型上界的对称矩阵特征向量旋转比率：\n$$\nr_{\\text{DK}} = \\frac{\\sin(\\theta_{i})}{\\min\\left(1, \\|\\Delta\\|_{2} / \\mathrm{gap}_{i}\\right)},\n$$\n为达到最小谱隙的索引 $i$ 计算。\n- 由特征值条件数归一化的非正规矩阵特征值敏感性比率：\n$$\nr_{\\text{non-normal}} = \\max_{i} \\frac{\\left|\\lambda_{i}(B+\\Delta) - \\lambda_{i}(B)\\right|}{\\kappa_{i}(B)\\,\\|\\Delta\\|_{2}},\n$$\n其中 $\\kappa_{i}(B)$ 是使用通过特征值邻近性匹配的 $B$ 的左、右特征向量计算的。同时报告 $\\kappa_{\\max}(B) = \\max_{i} \\kappa_{i}(B)$。\n\n测试套件矩阵和扰动：\n1. 对称、谱间距良好（理想情况）：\n$$\nA_{1} = \\begin{bmatrix}\n2  0.1  0 \\\\\n0.1  3  0.2 \\\\\n0  0.2  5\n\\end{bmatrix},\\quad\n\\Delta_{1} = 10^{-8}\\begin{bmatrix}\n0.5  0.1  -0.05 \\\\\n0.1  -0.2  0.02 \\\\\n-0.05  0.02  0.3\n\\end{bmatrix}.\n$$\n计算 $(A_{1}, \\Delta_{1})$ 的 $r_{\\text{sym-eig}}$。\n2. 对称、谱隙小（特征向量敏感性的边界条件）：\n$$\nA_{2} = \\begin{bmatrix}\n1  10^{-3}  0 \\\\\n10^{-3}  1  0 \\\\\n0  0  4\n\\end{bmatrix},\\quad\n\\Delta_{2} = 10^{-6}\\begin{bmatrix}\n0.3  -0.1  0 \\\\\n-0.1  0.2  0 \\\\\n0  0  -0.4\n\\end{bmatrix}.\n$$\n在 $A_{2}$ 中识别具有最小谱隙的索引 $i$，通过特征值邻近性在 $A_{2} + \\Delta_{2}$ 中匹配其特征向量，并计算 $(A_{2}, \\Delta_{2})$ 的 $r_{\\text{DK}}$。\n3. 强非正规、近乎亏损行为（特征值敏感性的边缘情况）：\n$$\nB_{1} = \\begin{bmatrix}\n1  1000 \\\\\n0  1.0001\n\\end{bmatrix},\\quad\n\\Delta_{3} = 10^{-8}\\begin{bmatrix}\n0  1 \\\\\n0  0\n\\end{bmatrix}.\n$$\n计算 $(B_{1}, \\Delta_{3})$ 的 $r_{\\text{non-normal}}$，并计算 $\\kappa_{\\max}(B_{1})$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含四个结果\n$$\n\\left[r_{\\text{sym-eig}},\\; r_{\\text{DK}},\\; r_{\\text{non-normal}},\\; \\kappa_{\\max}(B_{1})\\right]\n$$\n作为一个用方括号括起来的逗号分隔列表，顺序如上所示，并使用标准十进制表示法表示实数（无百分号）。\n\n无需用户输入；所有数据均已在上方提供。程序必须能在现代环境中直接运行。",
            "solution": "该问题要求计算矩阵在微小加性扰动下特征值和特征向量的几种敏感性指标。分析分为三种情况，每种情况旨在探究矩阵扰动理论的一个特定方面。这些计算依赖于数值线性代数的基本原理，包括对称矩阵的谱定理以及左、右特征向量在表征非对称矩阵特征值问题条件数方面的作用。所有数学实体都按要求使用 LaTeX 渲染。\n\n首先，我们处理实对称矩阵特征值的敏感性。对于对称矩阵 $A$ 和对称扰动 $\\Delta$，Weyl 不等式为特征值的扰动提供了一个严格的界：\n$$\n\\max_{i} \\left|\\lambda_{i}(A+\\Delta) - \\lambda_{i}(A)\\right| \\le \\|\\Delta\\|_{2}.\n$$\n这意味着实对称矩阵的特征值问题总是良态的，其条件数为 $1$。量 $r_{\\text{sym-eig}}$ 直接衡量了这种关系。对于第一个测试用例，我们有：\n$$\nA_{1} = \\begin{bmatrix}\n2  0.1  0 \\\\\n0.1  3  0.2 \\\\\n0  0.2  5\n\\end{bmatrix},\\quad\n\\Delta_{1} = 10^{-8}\\begin{bmatrix}\n0.5  0.1  -0.05 \\\\\n0.1  -0.2  0.02 \\\\\n-0.05  0.02  0.3\n\\end{bmatrix}.\n$$\n为计算 $r_{\\text{sym-eig}}$，我们执行以下步骤：\n$1$. 计算 $A_1$ 和 $A_1 + \\Delta_1$ 的特征值。由于它们是对称矩阵，我们使用数值稳定的算法返回排序后的实特征值。让它们分别为 $\\{\\lambda_{i}(A_1)\\}$ 和 $\\{\\lambda_{i}(A_1+\\Delta_1)\\}$，按非递减顺序排列。\n$2$. 计算对应特征值之间的最大绝对差：$\\max_{i} |\\lambda_{i}(A_1+\\Delta_1) - \\lambda_{i}(A_1)|$。\n$3$. 计算扰动的诱导 $2$-范数 $\\|\\Delta_1\\|_2$，即其最大奇异值。对于对称矩阵，这等于 $\\Delta_1$ 的最大绝对特征值。\n$4$. 比率则为 $r_{\\text{sym-eig}} = (\\max_{i} |\\lambda_{i}(A_1+\\Delta_1) - \\lambda_{i}(A_1)|) / \\|\\Delta_1\\|_2$。根据 Weyl 不等式，我们预期 $r_{\\text{sym-eig}} \\le 1$。\n\n其次，我们考察对称矩阵特征向量的敏感性。与特征值不同，如果相应的特征值彼此接近，特征向量可能高度敏感。Davis-Kahan 定理给出了原始特征向量 $u_i(A)$ 与其扰动后对应向量之间的夹角 $\\theta_i$ 的界。该界的一个简化版本是 $\\sin(\\theta_i) \\lesssim \\|\\Delta\\|_2 / \\mathrm{gap}_i$，其中 $\\mathrm{gap}_i = \\min_{j \\neq i} |\\lambda_i(A) - \\lambda_j(A)|$。比率 $r_{\\text{DK}}$ 旨在测试这个界的紧度。我们有第二个测试用例：\n$$\nA_{2} = \\begin{bmatrix}\n1  10^{-3}  0 \\\\\n10^{-3}  1  0 \\\\\n0  0  4\n\\end{bmatrix},\\quad\n\\Delta_{2} = 10^{-6}\\begin{bmatrix}\n0.3  -0.1  0 \\\\\n-0.1  0.2  0 \\\\\n0  0  -0.4\n\\end{bmatrix}.\n$$\n$A_2$ 的特征值为 $\\lambda_1 = 1 - 10^{-3} = 0.999$，$\\lambda_2 = 1 + 10^{-3} = 1.001$ 和 $\\lambda_3 = 4$。谱隙为 $\\mathrm{gap}_1 = \\lambda_2 - \\lambda_1 = 0.002$，$\\mathrm{gap}_2 = \\lambda_2 - \\lambda_1 = 0.002$ 和 $\\mathrm{gap}_3 = \\lambda_3 - \\lambda_2 = 2.999$。最小谱隙是 $0.002$，与 $\\lambda_1$ 和 $\\lambda_2$ 相关。我们选择对应于 $\\lambda_1$ 的特征向量（索引 $i=1$，假设基于1的索引；或 $i=0$，对于基于0的索引）。\n计算 $r_{\\text{DK}}$ 的步骤如下：\n$1$. 计算 $A_2$ 的特征值和特征向量。识别具有最小谱隙的索引 $i$，以及相应的特征向量 $u_i(A_2)$ 和谱隙 $\\mathrm{gap}_i$。\n$2$. 计算扰动矩阵 $A_2 + \\Delta_2$ 的特征值和特征向量。\n$3$. 通过寻找其对应特征值最接近 $\\lambda_i(A_2)$ 的特征向量来识别扰动后的特征向量 $u_i(A_2 + \\Delta_2)$。\n$4$. 计算两个单位范数特征向量之间主夹角的正弦值：$\\sin(\\theta_i) = \\sqrt{1 - (u_i(A_2)^{\\mathsf{T}} u_i(A_2+\\Delta_2))^2}$。注意，问题对余弦的定义中的绝对值处理了特征向量的符号模糊性。\n$5$. 计算 $2$-范数 $\\|\\Delta_2\\|_2$。\n$6$. 计算比率 $r_{\\text{DK}} = \\sin(\\theta_i) / \\min(1, \\|\\Delta_2\\|_2 / \\mathrm{gap}_i)$。我们预期这个比率的数量级为 $1$。\n\n第三，我们研究非对称（且非正规）矩阵的特征值敏感性。对于可对角化矩阵 $B$，单特征值 $\\lambda_i$ 的敏感性由其条件数 $\\kappa_i(B) = (\\|x_i\\|_2\\|y_i\\|_2) / |y_i^{\\mathsf{T}}x_i|$ 决定，其中 $x_i$ 和 $y_i$ 是相应的右、左特征向量。一阶扰动界为 $|\\lambda_i(B+\\Delta) - \\lambda_i(B)| \\lesssim \\kappa_i(B)\\|\\Delta\\|_2$。第三个测试用例使用了一个已知为高度非正规的矩阵：\n$$\nB_{1} = \\begin{bmatrix}\n1  1000 \\\\\n0  1.0001\n\\end{bmatrix},\\quad\n\\Delta_{3} = 10^{-8}\\begin{bmatrix}\n0  1 \\\\\n0  0\n\\end{bmatrix}.\n$$\n$B_1$ 的特征值是其对角线元素，$\\lambda_1=1$ 和 $\\lambda_2=1.0001$。它们非常接近。\n计算需要两部分：求 $\\kappa_{\\max}(B_1)$ 和 $r_{\\text{non-normal}}$。\n求 $\\kappa_i(B_1)$：\n$1$. 对 $B_1$ 的每个特征值 $\\lambda_i$，从 $B_1 x_i = \\lambda_i x_i$ 计算右特征向量 $x_i$，从 $y_i^{\\mathsf{T}} B_1 = \\lambda_i y_i^{\\mathsf{T}}$（或 $B_1^{\\mathsf{T}} y_i = \\lambda_i y_i$）计算左特征向量 $y_i$。\n$2$. 标准数值库提供单位范数特征向量，因此 $\\|x_i\\|_2 = 1$ 和 $\\|y_i\\|_2 = 1$。公式简化为 $\\kappa_i(B_1) = 1/|y_i^{\\mathsf{T}}x_i|$。必须注意将正确的左、右特征向量配对。\n$3$. $\\kappa_{\\max}(B_1)$ 是计算出的 $\\kappa_i(B_1)$ 的最大值。\n求 $r_{\\text{non-normal}}$：\n$1$. 计算 $B_1$ 和扰动矩阵 $B_1 + \\Delta_3$ 的特征值。\n$2$. 上三角矩阵的特征值是其对角线元素。对于 $B_1 + \\Delta_3 = \\begin{bmatrix} 1  1000+10^{-8} \\\\ 0  1.0001 \\end{bmatrix}$，特征值仍然是 $1$ 和 $1.0001$。\n$3$. 在这个特定情况下，两个特征值的差 $|\\lambda_i(B_1+\\Delta_3) - \\lambda_i(B_1)|$ 都恰好是 $0$。\n$4$. 计算 $\\|\\Delta_3\\|_2$。\n$5$. 比率项为 $\\frac{|\\lambda_i(B+\\Delta) - \\lambda_i(B)|}{\\kappa_{i}(B)\\,\\|\\Delta\\|_{2}} = \\frac{0}{\\kappa_{i}(B)\\,\\|\\Delta\\|_{2}} = 0$。\n$6$. 因此，$r_{\\text{non-normal}} = \\max_i(0) = 0$。尽管条件数很大，但这个特定的扰动并没有改变特征值，这表明该界并不总是紧的，并且敏感性是具有方向性的。\n我们现在继续这些步骤的数值实现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes sensitivity ratios for eigenvalues and eigenvectors for three test cases.\n    \"\"\"\n    \n    # --- Case 1: Symmetric eigenvalue sensitivity ---\n    A1 = np.array([\n        [2.0, 0.1, 0.0],\n        [0.1, 3.0, 0.2],\n        [0.0, 0.2, 5.0]\n    ])\n    Delta1 = 1e-8 * np.array([\n        [0.5, 0.1, -0.05],\n        [0.1, -0.2, 0.02],\n        [-0.05, 0.02, 0.3]\n    ])\n\n    A1_pert = A1 + Delta1\n    \n    # numpy.linalg.eigh returns sorted eigenvalues for symmetric matrices\n    e_vals_A1, _ = np.linalg.eigh(A1)\n    e_vals_A1_pert, _ = np.linalg.eigh(A1_pert)\n    \n    max_eig_diff_A1 = np.max(np.abs(e_vals_A1_pert - e_vals_A1))\n    norm_Delta1 = np.linalg.norm(Delta1, ord=2)\n    \n    r_sym_eig = max_eig_diff_A1 / norm_Delta1 if norm_Delta1 > 0 else 0.0\n\n    # --- Case 2: Symmetric eigenvector rotation ---\n    A2 = np.array([\n        [1.0, 1e-3, 0.0],\n        [1e-3, 1.0, 0.0],\n        [0.0, 0.0, 4.0]\n    ])\n    Delta2 = 1e-6 * np.array([\n        [0.3, -0.1, 0.0],\n        [-0.1, 0.2, 0.0],\n        [0.0, 0.0, -0.4]\n    ])\n\n    A2_pert = A2 + Delta2\n    \n    e_vals_A2, e_vecs_A2 = np.linalg.eigh(A2)\n    e_vals_A2_pert, e_vecs_A2_pert = np.linalg.eigh(A2_pert)\n\n    # Identify index `i` with the minimum spectral gap.\n    # eigh sorts eigenvalues, so the smallest gap is between adjacent eigenvalues.\n    gaps = np.diff(e_vals_A2)\n    min_gap = np.min(gaps)\n    # The minimum gap is between the first two eigenvalues. We select i=0.\n    i_min_gap = np.argmin(gaps)\n    \n    gap_i = min_gap\n    u_i = e_vecs_A2[:, i_min_gap]\n    \n    # The perturbed eigenvector is also at index i_min_gap because the perturbation is small.\n    u_i_pert = e_vecs_A2_pert[:, i_min_gap]\n    \n    # Calculate sin(theta)\n    cos_theta = np.abs(u_i.T @ u_i_pert)\n    # Clamp to 1.0 to avoid domain errors with sqrt due to floating point inaccuracies\n    if cos_theta > 1.0:\n        cos_theta = 1.0\n    sin_theta = np.sqrt(1.0 - cos_theta**2)\n\n    norm_Delta2 = np.linalg.norm(Delta2, ord=2)\n    \n    r_DK_denominator = min(1.0, norm_Delta2 / gap_i)\n    r_DK = sin_theta / r_DK_denominator if r_DK_denominator > 0 else 0.0\n    \n    # --- Case 3: Non-normal eigenvalue sensitivity ---\n    B1 = np.array([\n        [1.0, 1000.0],\n        [0.0, 1.0001]\n    ])\n    Delta3 = 1e-8 * np.array([\n        [0.0, 1.0],\n        [0.0, 0.0]\n    ])\n\n    # Eigenvalues and right eigenvectors of B1\n    e_vals_B1, r_vecs_B1 = np.linalg.eig(B1)\n\n    # Eigenvalues and left eigenvectors of B1 (eigenvectors of B1.T)\n    e_vals_B1T, l_vecs_B1_raw = np.linalg.eig(B1.T)\n\n    # Sort eigenvalues and eigenvectors to ensure correct pairing\n    sort_idx_r = np.argsort(e_vals_B1.real)\n    e_vals_B1_s = e_vals_B1[sort_idx_r]\n    r_vecs_B1_s = r_vecs_B1[:, sort_idx_r]\n\n    sort_idx_l = np.argsort(e_vals_B1T.real)\n    l_vecs_B1_s = l_vecs_B1_raw[:, sort_idx_l]\n    \n    # Calculate eigenvalue condition numbers kappa_i\n    kappas = np.zeros_like(e_vals_B1_s, dtype=float)\n    for i in range(len(e_vals_B1_s)):\n        # Eigenvectors from np.linalg.eig are already normalized to unit 2-norm\n        # kappa_i = ||x||*||y|| / |y.T @ x| simplifies to 1 / |y.T @ x|\n        # Use .conj() for robustness, though not strictly needed for real matrices\n        denom = np.abs(np.dot(l_vecs_B1_s[:, i].conj(), r_vecs_B1_s[:, i]))\n        kappas[i] = 1.0 / denom if denom > 0 else np.inf\n    \n    kappa_max_B1 = np.max(kappas)\n    \n    # Calculate r_non_normal\n    B1_pert = B1 + Delta3\n    e_vals_B1_pert, _ = np.linalg.eig(B1_pert)\n    e_vals_B1_pert_s = np.sort(e_vals_B1_pert.real) # Sort for matching\n\n    max_eig_diff_B1 = np.abs(e_vals_B1_pert_s - e_vals_B1_s)\n    \n    norm_Delta3 = np.linalg.norm(Delta3, ord=2)\n    \n    # Denominator for the ratio\n    sens_denom = kappas * norm_Delta3\n    r_non_normal_terms = np.zeros_like(sens_denom)\n    # Avoid division by zero if sensitivity denominator is zero\n    non_zero_idx = sens_denom > 0\n    r_non_normal_terms[non_zero_idx] = max_eig_diff_B1[non_zero_idx] / sens_denom[non_zero_idx]\n    \n    r_non_normal = np.max(r_non_normal_terms)\n\n    # --- Final Output ---\n    results = [r_sym_eig, r_DK, r_non_normal, kappa_max_B1]\n    \n    # Print in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}