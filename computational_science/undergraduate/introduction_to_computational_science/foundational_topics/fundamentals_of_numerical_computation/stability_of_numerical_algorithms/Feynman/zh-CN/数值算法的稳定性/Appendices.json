{
    "hands_on_practices": [
        {
            "introduction": "我们的第一个练习将解决数值计算中最常见的误差来源之一：灾难性抵消（catastrophic cancellation）。我们将分析一个简单的函数，其中两个几乎相等的巨大数值相减会导致精度的严重损失 。这个实践旨在展示如何通过代数重构，将一个表达式变换为在数值计算上更稳定的等价形式，这是一种非常强大且实用的技巧。",
            "id": "2205457",
            "problem": "考虑函数 $f(x) = \\sqrt{x+1} - \\sqrt{x}$。对于非常大的正数 $x$ 值，使用标准浮点运算直接计算 $f(x)$ 可能会导致严重的精度损失，这是由于两个几乎相等的数相减造成的。你的任务是首先找到一个与 $f(x)$ 代数上等价的表达式，该表达式对于大的 $x$ 在数值上更稳定，因为它避免了这种减法运算。然后，使用这个改进的表达式计算当 $x = 4 \\times 10^{16}$ 时 $f(x)$ 的值。\n\n将你的答案表示为 $a \\times 10^b$ 形式的科学记数法实数，并四舍五入到三位有效数字。",
            "solution": "我们希望对于大的正数 $x$，避免在计算 $f(x) = \\sqrt{x+1} - \\sqrt{x}$ 时出现灾难性抵消。将分子和分母同乘以其共轭表达式，得到一个代数等价形式：\n$$\nf(x) = \\left(\\sqrt{x+1} - \\sqrt{x}\\right)\\frac{\\sqrt{x+1} + \\sqrt{x}}{\\sqrt{x+1} + \\sqrt{x}} = \\frac{(x+1) - x}{\\sqrt{x+1} + \\sqrt{x}} = \\frac{1}{\\sqrt{x+1} + \\sqrt{x}}.\n$$\n这个表达式避免了两个几乎相等的大数相减，因此在数值上更稳定。\n\n对于 $x = 4 \\times 10^{16}$，使用稳定形式进行计算：\n$$\nf(4 \\times 10^{16}) = \\frac{1}{\\sqrt{4 \\times 10^{16} + 1} + \\sqrt{4 \\times 10^{16}}}.\n$$\n注意 $\\sqrt{4 \\times 10^{16}} = 2 \\times 10^{8}$。此外，\n$$\n\\sqrt{4 \\times 10^{16} + 1} = 2 \\times 10^{8}\\sqrt{1 + \\frac{1}{4 \\times 10^{16}}}.\n$$\n令 $\\epsilon = \\frac{1}{4 \\times 10^{16}}$。使用二项式展开 $\\sqrt{1+\\epsilon} = 1 + \\frac{\\epsilon}{2} - \\frac{\\epsilon^{2}}{8} + \\cdots$，我们有\n$$\n\\sqrt{4 \\times 10^{16} + 1} = 2 \\times 10^{8}\\left(1 + \\frac{\\epsilon}{2} - \\frac{\\epsilon^{2}}{8} + \\cdots \\right) = 2 \\times 10^{8} + 10^{8}\\epsilon + O(\\epsilon^{2}).\n$$\n因此分母是\n$$\n\\sqrt{4 \\times 10^{16} + 1} + \\sqrt{4 \\times 10^{16}} = 4 \\times 10^{8} + 10^{8}\\epsilon + O(\\epsilon^{2}).\n$$\n所以，\n$$\nf(4 \\times 10^{16}) = \\frac{1}{4 \\times 10^{8} + 10^{8}\\epsilon + O(\\epsilon^{2})} = \\frac{1}{4 \\times 10^{8}}\\left(1 - \\frac{10^{8}\\epsilon}{4 \\times 10^{8}} + O(\\epsilon^{2})\\right).\n$$\n因为 $\\epsilon = 2.5 \\times 10^{-17}$，首项是\n$$\n\\frac{1}{4 \\times 10^{8}} = 2.5 \\times 10^{-9},\n$$\n而修正项的量级是 $10^{-26}$，这不影响四舍五入到三位有效数字的结果。因此，保留三位有效数字，\n$$\nf(4 \\times 10^{16}) \\approx 2.50 \\times 10^{-9}.\n$$",
            "answer": "$$\\boxed{2.50 \\times 10^{-9}}$$"
        },
        {
            "introduction": "接下来，我们把注意力从单步计算转移到模拟动态系统的迭代过程中。本问题将探讨求解一个简单常微分方程时，显式欧拉法的稳定性问题 。你将亲眼见证，一个不恰当的时间步长选择，会如何导致数值解与真实的物理行为产生巨大偏离甚至发散，从而深刻理解条件稳定性的概念。",
            "id": "2205446",
            "problem": "一位科学家正在为一个简单的一级反应中的化学反应物浓度 $C(t)$ 建模。该反应物浓度的变化率与浓度本身成正比，遵循以下微分方程：\n$$\n\\frac{dC}{dt} = -k C(t)\n$$\n给定速率常数为 $k = 50.0 \\text{ s}^{-1}$，时间 $t=0$ 时的初始浓度为 $C(0) = 100.0 \\text{ mol/L}$。\n\n为了预测未来的浓度，该科学家采用了一种使用固定时间步长 $h$ 的数值方案。该方法根据显式欧拉更新法则，使用前一个时间步长 $t_n = nh$ 的值来近似时间 $t_{n+1} = (n+1)h$ 时的浓度：\n$$\nC_{n+1} = C_n + h \\left( \\frac{dC}{dt} \\right)_{t=t_n}\n$$\n科学家决定使用 $h = 0.0410 \\text{ s}$ 的时间步长。计算该方法在三个时间步长后预测的浓度 $C_3$ 的数值。答案以 mol/L 为单位，并四舍五入到三位有效数字。",
            "solution": "我们已知一阶线性常微分方程 $\\frac{dC}{dt}=-kC(t)$ 和显式欧拉更新公式\n$$\nC_{n+1}=C_{n}+h\\left(\\frac{dC}{dt}\\right)_{t=t_{n}}=C_{n}+h(-kC_{n})=(1-kh)C_{n}.\n$$\n通过递归，可得\n$$\nC_{n}=C_{0}(1-kh)^{n}.\n$$\n当 $C_{0}=100.0$, $k=50.0\\,\\text{s}^{-1}$ 且 $h=0.0410\\,\\text{s}$ 时，无量纲积为\n$$\nkh=(50.0)(0.0410)=2.05,\\quad 1-kh=1-2.05=-1.05.\n$$\n因此，经过三个步骤后，\n$$\nC_{3}=100.0\\,(-1.05)^{3}.\n$$\n计算该幂：\n$$\n(-1.05)^{2}=1.1025,\\quad (-1.05)^{3}=1.1025\\times(-1.05)=-1.157625,\n$$\n所以\n$$\nC_{3}=100.0\\times(-1.157625)=-115.7625.\n$$\n四舍五入到三位有效数字得到 $-1.16\\times 10^{2}$，即 $-116$。注意，显式欧拉因子满足 $|1-kh|=1.05>1$，表明对于此步长，方法是不稳定的，这也解释了不符合物理实际的符号变化。",
            "answer": "$$\\boxed{-116}$$"
        },
        {
            "introduction": "在最后的实践中，我们深入到计算统计学领域，在这个领域，数值稳定性至关重要。本练习比较了一个用于计算方差的、看似直观的“教科书”公式和一个更为稳健的单遍算法（Welford 算法）。它将向你展示，在处理真实世界数据时，算法的选择如何直接影响结果的准确性，尤其是在处理均值很大而方差很小的数据集时，这一点尤为突出。",
            "id": "3197369",
            "problem": "要求您编写一个完整、可运行的程序，来研究计算实值数据样本均值和样本方差的两种方法的数值稳定性：一种是数值稳定的一次遍历方法，称为 Welford 算法；另一种是使用涉及平方和恒等式的经典两次遍历公式。此任务必须以纯数学和算法的方式完成，其逻辑适用于任何现代编程语言。目的是为了演示在有限精度算术中，当数据具有大偏移量和小离散度时，表达式 $$\\sum_{i=1}^{n} x_i^2 - \\frac{\\left(\\sum_{i=1}^{n} x_i\\right)^2}{n}$$ 中的相消如何导致精度的巨大损失。计算必须使用标准的二进制浮点数，采用电气与电子工程师协会 (Institute of Electrical and Electronics Engineers, IEEE) $754$ 双精度格式进行算法测试，并使用一个独立的高精度基准来评估误差。本问题不涉及物理单位。\n\n任务的基本基础：\n- 一个实数数据集 $x_1, x_2, \\dots, x_n$ 的样本均值定义为 $$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i.$$\n- 无偏样本方差定义为 $$s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} \\left(x_i - \\bar{x}\\right)^2.$$\n- 有限精度浮点算术（特别是电气与电子工程师协会 (IEEE) $754$ 双精度格式）在每次运算中都会引入舍入误差，而两个相近大数的减法可能会遭受灾难性相消，从而放大相对误差。\n\n您的程序必须：\n- 实现一个使用 Welford 算法（一次遍历，在每个数据点到达时更新均值和平方偏差累积和）计算样本均值和无偏样本方差的函数。\n- 实现第二个函数，该函数使用经典的两次遍历方法计算样本均值和无偏样本方差，该方法首先以浮点数计算总和与平方和，然后应用代数恒等式 $$\\sum_{i=1}^{n} x_i^2 - \\frac{\\left(\\sum_{i=1}^{n} x_i\\right)^2}{n}$$。\n- 使用任意精度十进制算术实现一个高精度基准，以根据上述定义从数据集的精确十进制表示计算样本均值和无偏样本方差。在十进制算术中至少使用 $50$ 位精度，以确保对于给定的数据集，该基准基本上没有舍入误差。\n\n测试套件设计：\n为以下四个数据集计算所需的量，每个数据集都旨在测试稳定性的不同方面。对于下面的每个数据集，$n$ 表示数据点的数量。\n1. 正常路径，中等规模：从 $1$ 到 $1000$ 的整数，即对于 $i \\in \\{1, 2, \\dots, 1000\\}$，$x_i = i$，其中 $n = 1000$。\n2. 大偏移量，中等离散度：对于 $i \\in \\{-500, -499, \\dots, 498, 499\\}$，$x_i = 10^{9} + i$，其中 $n = 1000$。\n3. 极大偏移量，微小交替抖动：对于 $i \\in \\{0, 1, \\dots, 1999\\}$，$x_i = 10^{12} + \\delta_i$，其中 $n = 2000$，当 $i$ 为偶数时 $\\delta_i = 10^{-3}$，当 $i$ 为奇数时 $\\delta_i = -10^{-3}$。\n4. 大偏移量，极小线性漂移：对于 $i \\in \\{0, 1, \\dots, 99999\\}$，$x_i = 10^{9} + 10^{-8} i$，其中 $n = 100000$。\n\n本问题不使用角度单位。不需要任何物理单位。任何输出中不得出现百分比；所有量均为标准实数算术中的数值。\n\n对于每个数据集，计算：\n- 使用两次遍历浮点法计算的样本均值和无偏样本方差。\n- 使用 Welford 的一次遍历浮点法计算的样本均值和无偏样本方差。\n- 使用至少 $50$ 位精度的十进制算术计算的高精度基准样本均值和无偏样本方差。\n\n然后为每个数据集生成以下指标：\n- $E_{\\text{mean, two}} = \\left| \\bar{x}_{\\text{two}} - \\bar{x}_{\\text{baseline}} \\right|$,\n- $E_{\\text{mean, wel}} = \\left| \\bar{x}_{\\text{wel}} - \\bar{x}_{\\text{baseline}} \\right|$,\n- $E_{\\text{var, two}} = \\left| s^2_{\\text{two}} - s^2_{\\text{baseline}} \\right|$,\n- $E_{\\text{var, wel}} = \\left| s^2_{\\text{wel}} - s^2_{\\text{baseline}} \\right|$,\n- 一个布尔标志 $C$，指示在两次遍历方差计算中“怀疑发生灾难性相消”，如果 $$E_{\\text{var, two}} \\ge 1000 \\times \\max\\left(E_{\\text{var, wel}}, 10^{-300}\\right),$$ 则定义为真，否则为假。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含跨四个数据集按顺序连接的所有指标，作为一个用方括号括起来的逗号分隔列表。对于每个数据集，按上面列出的确切顺序附加五个指标，从而得到一个长度为 $20$ 个数值和 $4$ 个布尔值的顶层列表。例如，输出必须如下所示：$$[\\text{m2\\_err\\_ds1}, \\text{mw\\_err\\_ds1}, \\text{v2\\_err\\_ds1}, \\text{vw\\_err\\_ds1}, \\text{C\\_ds1}, \\dots, \\text{m2\\_err\\_ds4}, \\text{mw\\_err\\_ds4}, \\text{v2\\_err\\_ds4}, \\text{vw\\_err\\_ds4}, \\text{C\\_ds4}]$$ 其中每个占位符都由其计算值替换。不要包含任何其他文本。",
            "solution": "该问题要求研究计算数据集样本均值和方差的两种不同算法的数值稳定性。分析的核心在于有限精度浮点算术的特性，特别是 IEEE $754$ 双精度标准。我们需要将一种经典的两次遍历算法与一种更稳健的、称为 Welford 算法的一次遍历方法进行比较，并使用高精度计算作为衡量准确性的基准。\n\n基本量是样本均值 $\\bar{x}$ 和无偏样本方差 $s^2$，对于数据集 $\\{x_1, x_2, \\dots, x_n\\}$：\n$$\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n$$\n$$\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n$$\n\n分析取决于三种计算方法：\n\n1.  **高精度基准**：为了量化有限精度算法的误差，需要一个“真实值”或基准。该基准使用任意精度十进制算术计算，精度至少为 $50$ 位。这确保了基准计算中的舍入误差与待测双精度算法的误差相比可以忽略不计。均值和方差直接根据上述定义计算，所有中间值和最终值均使用高精度数据类型。\n\n2.  **两次遍历算法（数值不稳定）**：这种常用方法包括对数据进行两次遍历。在第一次遍历中，累积两个和：$\\sum_{i=1}^{n} x_i$ 和 $\\sum_{i=1}^{n} x_i^2$。在第二次遍历中，这些和通过以下代数恒等式用于计算方差：\n    $$\n    \\sum_{i=1}^{n} (x_i - \\bar{x})^2 = \\sum_{i=1}^{n} x_i^2 - \\frac{\\left(\\sum_{i=1}^{n} x_i\\right)^2}{n}\n    $$\n    因此，样本方差计算如下：\n    $$\n    s^2_{\\text{two}} = \\frac{1}{n-1} \\left( \\sum_{i=1}^{n} x_i^2 - \\frac{\\left(\\sum_{i=1}^{n} x_i\\right)^2}{n} \\right)\n    $$\n    这个被称为“教科书公式”的公式的数值不稳定性源于两个相近大数的相减。当数据点具有较大的共同偏移量（即均值 $\\bar{x}$ 很大）和较小的离散度（即标准差 $s$ 很小）时，项 $\\sum x_i^2 \\approx n\\bar{x}^2$ 和项 $(\\sum x_i)^2/n = n\\bar{x}^2$ 的值将非常接近。在有限精度算术中，这两个量的相减会导致一种称为“灾难性相消”的现象，其中大部分有效数字会丢失，导致最终计算出的方差出现较大的相对误差。\n\n3.  **Welford 算法（数值稳定）**：这是一种一次遍历算法，通过增量更新均值和与平方差之和相关的量来避免灾难性相消问题。令 $M_k$ 为前 $k$ 个数据点的滚动均值，令 $S_k$ 为与均值的平方偏差的滚动总和，即 $S_k = \\sum_{i=1}^{k} (x_i - M_k)^2$。Welford 算法基于以下递推关系：\n    $$\n    M_k = M_{k-1} + \\frac{x_k - M_{k-1}}{k}\n    $$\n    $$\n    S_k = S_{k-1} + (x_k - M_{k-1})(x_k - M_k)\n    $$\n    初始条件为 $M_1 = x_1$ 和 $S_1 = 0$。处理完所有 $n$ 个数据点后，无偏样本方差为 $s^2_{\\text{wel}} = S_n / (n-1)$。该方法在数值上是稳定的，因为它使用与*滚动*均值的偏差来计算方差。项 $(x_k - M_{k-1})$ 和 $(x_k - M_k)$ 很小，防止了大数的累积和随后的灾难性相减。\n\n程序将实现这三种方法，将它们应用于旨在暴露两次遍历方法不稳定性的四个指定数据集，并计算每种浮点方法相对于高精度基准的均值和方差的绝对误差。计算布尔标志 $C$ 以检测可疑的灾难性相消，方法是将两次遍历方差计算的误差与 Welford 算法的误差进行比较。\n\n数据集设计如下：\n-   数据集 1：一个简单案例，规模适中，没有大偏移，预计两种方法都表现良好。\n-   数据集 2：数据具有大偏移量 ($10^9$)，两次遍历方法可能会开始出现一些性能下降。\n-   数据集 3：数据具有极大偏移量 ($10^{12}$) 和极小的离散度，旨在诱发两次遍历方法中严重的灾难性相消。\n-   数据集 4：数据具有大偏移量 ($10^9$) 和非常小的系统性漂移。此案例测试输入数据本身的有限精度表示如何影响算法，以及方差公式的不稳定性。\n\n通过比较误差 $E_{\\text{mean, two}}$、$E_{\\text{mean, wel}}$、$E_{\\text{var, two}}$ 和 $E_{\\text{var, wel}}$，将证明 Welford 算法相对于朴素的两次遍历公式的卓越数值稳定性，特别是在计算变异系数（$\\sigma / \\mu$）接近于零的数据的方差时。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Computes sample mean and variance using three different methods\n    (two-pass float, Welford's float, and high-precision baseline)\n    for four datasets, and reports the errors and a cancellation flag.\n    \"\"\"\n\n    def two_pass_algorithm(data: np.ndarray):\n        \"\"\"Computes mean and variance using the naive two-pass formula.\"\"\"\n        n = data.shape[0]\n        if n < 2:\n            return np.nan, np.nan\n        \n        sum_x = np.sum(data)\n        sum_x_sq = np.sum(data**2)\n        \n        mean = sum_x / n\n        # This subtraction is prone to catastrophic cancellation\n        variance = (sum_x_sq - (sum_x**2) / n) / (n - 1)\n        \n        return mean, variance\n\n    def welford_algorithm(data: np.ndarray):\n        \"\"\"Computes mean and variance using Welford's stable one-pass algorithm.\"\"\"\n        n = 0\n        mean = 0.0\n        M2 = 0.0 # This is the running sum of squared deviations from the mean\n\n        for x in data:\n            n += 1\n            delta = x - mean\n            mean += delta / n\n            delta2 = x - mean\n            M2 += delta * delta2\n        \n        if n < 2:\n            return mean, 0.0\n        \n        variance = M2 / (n - 1)\n        return mean, variance\n\n    def high_precision_baseline(data_str: list[str]):\n        \"\"\"\n        Computes mean and variance using high-precision decimal arithmetic\n        to establish a ground truth.\n        \"\"\"\n        getcontext().prec = 60 # Set precision to 60 digits\n        \n        data_decimal = [Decimal(s) for s in data_str]\n        n = len(data_decimal)\n        \n        if n < 2:\n            return Decimal(0), Decimal(0)\n            \n        mean = sum(data_decimal) / Decimal(n)\n        \n        # Compute sum of squared deviations directly from the definition\n        sum_sq_dev = sum((x - mean)**2 for x in data_decimal)\n        variance = sum_sq_dev / Decimal(n - 1)\n        \n        return mean, variance\n\n    test_cases_defs = [\n        {\n            \"name\": \"ds1\", \"n\": 1000, \n            \"gen_float\": lambda n: np.arange(1, n + 1, dtype=np.float64),\n            \"gen_str\": lambda n: [str(i) for i in range(1, n + 1)],\n        },\n        {\n            \"name\": \"ds2\", \"n\": 1000,\n            \"gen_float\": lambda n: 1e9 + np.arange(-n//2, n//2, dtype=np.float64),\n            \"gen_str\": lambda n: [str(10**9 + i) for i in range(-n//2, n//2)],\n        },\n        {\n            \"name\": \"ds3\", \"n\": 2000,\n            \"gen_float\": lambda n: 1e12 + np.array([1e-3 if i % 2 == 0 else -1e-3 for i in range(n)], dtype=np.float64),\n            \"gen_str\": lambda n: ['1000000000000.001' if i % 2 == 0 else '999999999999.999' for i in range(n)],\n        },\n        {\n            \"name\": \"ds4\", \"n\": 100000,\n            \"gen_float\": lambda n: 1e9 + 1e-8 * np.arange(n, dtype=np.float64),\n            \"gen_str\": lambda n: [str(Decimal('1e9') + Decimal('1e-8') * Decimal(i)) for i in range(n)],\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases_defs:\n        n = case[\"n\"]\n        \n        # Generate data for floating-point and high-precision calculations\n        float_data = case[\"gen_float\"](n)\n        str_data = case[\"gen_str\"](n)\n        \n        # Run all three algorithms\n        mean_two, var_two = two_pass_algorithm(float_data)\n        mean_wel, var_wel = welford_algorithm(float_data)\n        mean_base_dec, var_base_dec = high_precision_baseline(str_data)\n\n        # Convert baseline results to float for comparison\n        mean_base = float(mean_base_dec)\n        var_base = float(var_base_dec)\n        \n        # Calculate error metrics\n        E_mean_two = abs(mean_two - mean_base)\n        E_mean_wel = abs(mean_wel - mean_base)\n        E_var_two = abs(var_two - var_base)\n        E_var_wel = abs(var_wel - var_base)\n        \n        # Determine the catastrophic cancellation flag\n        # The max with 1e-300 prevents division by zero or issues with tiny numbers\n        cancellation_threshold = 1000 * max(E_var_wel, 1e-300)\n        C_flag = E_var_two >= cancellation_threshold\n\n        results.extend([E_mean_two, E_mean_wel, E_var_two, E_var_wel, C_flag])\n\n    # Final print statement in the exact required format.\n    # The default str() for a boolean is 'True' or 'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}