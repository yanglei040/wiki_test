{
    "hands_on_practices": [
        {
            "introduction": "数值微分的核心思想是用离散的函数采样点来近似导数的定义。本练习将指导你从泰勒级数展开这一基本原理出发，推导出前向、后向和中心差分这三种基本的数值微分公式。通过这个过程，你将深入理解截断误差的概念，以及它如何与计算模板（stencil）的选择相关联，这是分析和设计数值方法的基石。",
            "id": "3132346",
            "problem": "给定标量函数 $f(x) = \\dfrac{1}{1 + e^{-x}}$，该函数对所有实数 $x$ 都是光滑的，并在 $x = 0$ 处有一个拐点。您的任务是使用在步长为 $h  0$ 的均匀网格上构建的离散差商来估计斜率 $f'(0)$，并量化当网格较粗时这些估计的偏差。\n\n在您的推导和算法设计中，请以下列内容为基本依据：\n- 光滑函数导数的定义，$f'(x) = \\lim_{h \\to 0} \\dfrac{f(x+h) - f(x)}{h}$。\n- 光滑函数在某点周围的泰勒级数展开，例如 $f(x \\pm h)$ 在 $x$ 点的展开。\n- 指数函数的基本求导法则。\n\n不要假定任何差分公式为已知。相反，应从上述原理出发进行推导。\n\n任务：\n1. 从 $x_0$ 点的泰勒级数展开出发，推导在 $x_0$ 处三种常用的一维差商导数估计量（即前向、后向和中心差分格式）的主阶截断误差。用 $f''(x_0)$、$f'''(x_0)$ 和 $h$ 的整数次幂表示截断误差。\n2. 将您的结果应用于逻辑斯谛函数 $f(x) = \\dfrac{1}{1 + e^{-x}}$ 及其拐点 $x_0 = 0$。精确计算 $f'(0)$，并计算 $f''(0)$ 和 $f'''(0)$，以确定中心差分格式在 $x_0 = 0$ 处的主阶截断误差。\n3. 实现一个程序，对于测试集 $\\{2, 1, 0.5, 0.25\\}$ 中的每个步长 $h$，在 $x_0 = 0$ 处执行以下所有操作：\n   - 使用前向、后向和中心差分格式计算三个数值斜率估计值。\n   - 计算每个估计值的经验偏差，公式为 $\\text{bias} = \\text{estimate} - f'(0)$。\n   - 使用您推导出的并应用于 $x_0=0$ 的主阶截断项，计算中心差分格式的预测主阶偏差。\n4. 最终输出格式：您的程序应生成单行输出，包含一个由逗号分隔的列表组成的列表，无空格，并用方括号括起来。对于每个步长 $h$，输出列表 $[h,\\text{bias}_{\\text{fwd}},\\text{bias}_{\\text{bwd}},\\text{bias}_{\\text{cen}},\\text{bias}_{\\text{cen,pred}}]$，其中所有条目均为十进制数。因此，总输出是包含这四个列表的单个列表，顺序为 $h \\in \\{2,1,0.5,0.25\\}$。\n\n注意：\n- 本问题不涉及物理单位；所有量均为无量纲量。\n- 不涉及角度。\n- 最终输出必须为单一行，其格式为如上所述的列表之列表，且仅包含指定测试集的值。",
            "solution": "这个问题是有效的，因为它是自洽的，科学上基于微积分和数值分析的原理，并且陈述清晰明确。我们被要求从第一性原理出发推导数值微分公式，分析其截断误差，并将此分析应用于特定函数和特定点。\n\n### 第1部分：差分格式和截断误差的推导\n\n我们从光滑函数 $f(x)$ 在点 $x_0$ 周围的泰勒级数展开开始。对于步长 $h > 0$，$f(x_0+h)$ 和 $f(x_0-h)$ 的展开式为：\n$$f(x_0+h) = f(x_0) + hf'(x_0) + \\frac{h^2}{2!}f''(x_0) + \\frac{h^3}{3!}f'''(x_0) + O(h^4)$$\n$$f(x_0-h) = f(x_0) - hf'(x_0) + \\frac{h^2}{2!}f''(x_0) - \\frac{h^3}{3!}f'''(x_0) + O(h^4)$$\n\n估计量的偏差定义为 $\\text{bias} = \\text{estimator} - f'(x_0)$。我们寻求该偏差的主阶项，即主阶截断误差。\n\n**前向差分格式**\n前向差商定义为 $\\frac{f(x_0+h) - f(x_0)}{h}$。整理 $f(x_0+h)$ 的泰勒展开式：\n$$f(x_0+h) - f(x_0) = hf'(x_0) + \\frac{h^2}{2}f''(x_0) + O(h^3)$$\n两边除以 $h$：\n$$\\frac{f(x_0+h) - f(x_0)}{h} = f'(x_0) + \\frac{h}{2}f''(x_0) + O(h^2)$$\n因此，偏差为：\n$$\\text{bias}_{\\text{fwd}} = \\left(\\frac{f(x_0+h) - f(x_0)}{h}\\right) - f'(x_0) = \\frac{h}{2}f''(x_0) + O(h^2)$$\n主阶截断误差为 $\\frac{h}{2}f''(x_0)$。\n\n**后向差分格式**\n后向差商为 $\\frac{f(x_0) - f(x_0-h)}{h}$。整理 $f(x_0-h)$ 的泰勒展开式：\n$$f(x_0) - f(x_0-h) = hf'(x_0) - \\frac{h^2}{2}f''(x_0) + O(h^3)$$\n两边除以 $h$：\n$$\\frac{f(x_0) - f(x_0-h)}{h} = f'(x_0) - \\frac{h}{2}f''(x_0) + O(h^2)$$\n偏差为：\n$$\\text{bias}_{\\text{bwd}} = \\left(\\frac{f(x_0) - f(x_0-h)}{h}\\right) - f'(x_0) = -\\frac{h}{2}f''(x_0) + O(h^2)$$\n主阶截断误差为 $-\\frac{h}{2}f''(x_0)$。\n\n**中心差分格式**\n为了推导中心差分格式，我们将 $f(x_0-h)$ 的展开式从 $f(x_0+h)$ 的展开式中减去：\n$$f(x_0+h) - f(x_0-h) = (f(x_0) + hf'(x_0) + \\frac{h^2}{2}f''(x_0) + \\frac{h^3}{6}f'''(x_0)) - (f(x_0) - hf'(x_0) + \\frac{h^2}{2}f''(x_0) - \\frac{h^3}{6}f'''(x_0)) + O(h^5)$$\n$h$ 的偶次幂项相互抵消：\n$$f(x_0+h) - f(x_0-h) = 2hf'(x_0) + \\frac{2h^3}{6}f'''(x_0) + O(h^5) = 2hf'(x_0) + \\frac{h^3}{3}f'''(x_0) + O(h^5)$$\n整理得到估计量 $\\frac{f(x_0+h) - f(x_0-h)}{2h}$：\n$$\\frac{f(x_0+h) - f(x_0-h)}{2h} = f'(x_0) + \\frac{h^2}{6}f'''(x_0) + O(h^4)$$\n偏差为：\n$$\\text{bias}_{\\text{cen}} = \\left(\\frac{f(x_0+h) - f(x_0-h)}{2h}\\right) - f'(x_0) = \\frac{h^2}{6}f'''(x_0) + O(h^4)$$\n主阶截断误差为 $\\frac{h^2}{6}f'''(x_0)$。\n\n### 第2部分：应用于逻辑斯谛函数\n\n给定函数 $f(x) = \\frac{1}{1 + e^{-x}}$ 和目标点 $x_0 = 0$。我们必须计算前三阶导数并在 $x_0 = 0$ 处求值。\n\n一种计算上高效的求导方法是利用性质 $f'(x) = f(x)(1-f(x))$。\n$f'(x) = \\frac{d}{dx}(1+e^{-x})^{-1} = -(1+e^{-x})^{-2}(-e^{-x}) = \\frac{e^{-x}}{(1+e^{-x})^2}$。\n$f(x)(1-f(x)) = \\frac{1}{1+e^{-x}}\\left(1 - \\frac{1}{1+e^{-x}}\\right) = \\frac{1}{1+e^{-x}}\\frac{e^{-x}}{1+e^{-x}} = \\frac{e^{-x}}{(1+e^{-x})^2}$。该性质成立。\n\n现在我们计算更高阶的导数：\n$f''(x) = \\frac{d}{dx}[f'(x)] = \\frac{d}{dx}[f(x)(1-f(x))] = f'(x)(1-f(x)) + f(x)(-f'(x)) = f'(x)(1-2f(x))$。\n$f'''(x) = \\frac{d}{dx}[f''(x)] = \\frac{d}{dx}[f'(x)(1-2f(x))] = f''(x)(1-2f(x)) + f'(x)(-2f'(x)) = f''(x)(1-2f(x)) - 2(f'(x))^2$。\n\n接下来，我们在 $x_0 = 0$ 处计算这些导数的值：\n在 $x_0=0$ 处，$e^{-0}=1$，所以 $f(0) = \\frac{1}{1+1} = \\frac{1}{2}$。\n$f'(0) = f(0)(1-f(0)) = \\frac{1}{2}(1-\\frac{1}{2}) = \\frac{1}{4}$。这是斜率的精确值。\n$f''(0) = f'(0)(1-2f(0)) = \\frac{1}{4}(1-2(\\frac{1}{2})) = \\frac{1}{4}(0) = 0$。这证实了如题所述，$x_0=0$ 是一个拐点。\n$f'''(0) = f''(0)(1-2f(0)) - 2(f'(0))^2 = (0)(1-2(\\frac{1}{2})) - 2(\\frac{1}{4})^2 = 0 - 2(\\frac{1}{16}) = -\\frac{1}{8}$。\n\n问题陈述 $x_0=0$ 是一个拐点，这意味着依赖于 $f''(x_0)$ 的前向和后向差分格式的主阶 $O(h)$ 误差项会消失。在这个特定点，它们的精度变为 $O(h^2)$。中心差分格式的主阶截断误差由 $f'''(0)$ 决定。\n\n中心差分格式的预测主阶偏差由其误差展开式中的主项给出：\n$$\\text{bias}_{\\text{cen,pred}} = \\frac{h^2}{6}f'''(0) = \\frac{h^2}{6}\\left(-\\frac{1}{8}\\right) = -\\frac{h^2}{48}$$\n\n### 第3部分：算法实现\n\n程序将实现以下逻辑：\n1. 定义逻辑斯谛函数 $f(x)$。\n2. 设置精确导数 $f'(0) = 0.25$ 和 $f'''(0) = -0.125$。\n3. 对于集合 $\\{2, 1, 0.5, 0.25\\}$ 中的每个步长 $h$：\n   a. 在 $x_0=0$ 处计算三个数值估计值：\n      - 前向：$\\text{est}_{\\text{fwd}} = \\frac{f(h) - f(0)}{h}$\n      - 后向：$\\text{est}_{\\text{bwd}} = \\frac{f(0) - f(-h)}{h}$\n      - 中心：$\\text{est}_{\\text{cen}} = \\frac{f(h) - f(-h)}{2h}$\n   b. 计算每个估计值的经验偏差：$\\text{bias} = \\text{estimate} - 0.25$。\n   c. 使用推导的公式计算中心差分格式的预测主阶偏差：$\\text{bias}_{\\text{cen,pred}} = -\\frac{h^2}{48}$。\n   d. 存储当前 $h$ 的结果 $[h, \\text{bias}_{\\text{fwd}}, \\text{bias}_{\\text{bwd}}, \\text{bias}_{\\text{cen}}, \\text{bias}_{\\text{cen,pred}}]$。\n4. 将收集到的结果格式化为表示列表之列表的单个字符串并打印。\n\n值得注意的是，对于函数 $f(x)=(1+e^{-x})^{-1}$，我们有对称性质 $f(x)+f(-x)=1$。在求值点 $x_0=0$ 处，其中 $f(0)=0.5$，这导致前向、后向和中心差商在数值上是相同的。因此，它们的经验偏差也将相同。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical differentiation problem for the logistic function.\n\n    This function performs the following tasks:\n    1. Defines the logistic function and its exact derivative details at x=0.\n    2. Iterates through a set of step sizes h.\n    3. For each h, calculates the forward, backward, and central difference estimates\n       of the derivative at x=0.\n    4. Computes the empirical bias for each estimate.\n    5. Calculates the theoretically predicted leading-order bias for the central\n       difference scheme.\n    6. Formats and prints the results as a list of lists.\n    \"\"\"\n    \n    # Define the scalar function f(x)\n    def f(x: float) - float:\n        return 1.0 / (1.0 + np.exp(-x))\n\n    # Test suite of step sizes\n    h_values = [2.0, 1.0, 0.5, 0.25]\n    \n    # Point of evaluation\n    x0 = 0.0\n    \n    # Analytically derived constants\n    f_prime_exact_at_0 = 0.25  # f'(0) = 1/4\n    f_triple_prime_at_0 = -0.125  # f'''(0) = -1/8\n    \n    all_results = []\n\n    for h in h_values:\n        # Evaluate the function at the required points on the grid\n        f_plus_h = f(x0 + h)\n        f_minus_h = f(x0 - h)\n        f_at_x0 = f(x0)\n\n        # Compute the three numerical slope estimates\n        est_fwd = (f_plus_h - f_at_x0) / h\n        est_bwd = (f_at_x0 - f_minus_h) / h\n        est_cen = (f_plus_h - f_minus_h) / (2.0 * h)\n        \n        # Compute the empirical bias for each estimate\n        bias_fwd = est_fwd - f_prime_exact_at_0\n        bias_bwd = est_bwd - f_prime_exact_at_0\n        bias_cen = est_cen - f_prime_exact_at_0\n        \n        # Compute the predicted leading-order bias for the central scheme\n        # The formula is (h^2 / 6) * f'''(0)\n        bias_cen_pred = (h**2 / 6.0) * f_triple_prime_at_0\n        \n        # Append the list of results for this h\n        all_results.append([h, bias_fwd, bias_bwd, bias_cen, bias_cen_pred])\n        \n    # Format the final output string as a list of lists without spaces\n    # Example: [[2.0,-0.0596...,-0.0596...,-0.0596...,-0.0833...],...]\n    output_str = f\"[{','.join([f'[{v[0]},{v[1]},{v[2]},{v[3]},{v[4]}]' for v in all_results])}]\"\n    \n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在理解了不同差分格式的理论精度之后，评估它们在处理真实世界中不完美数据时的表现至关重要。本练习设计了一个思想实验，分析当单个数据点存在异常值（outlier）时，每种差分格式的敏感度。这个实践将揭示中心差分格式在鲁棒性方面的一个关键且不那么直观的优点，强调了在选择算法时，除了截断误差之外还需要考虑的实际因素。",
            "id": "3132362",
            "problem": "给定一个平滑实值函数 $f$，它在一个一维均匀网格 $x_j = x_0 + j h$ 上采样，网格间距为常数 $h > 0$。考虑在内部网格点 $x_i$ 处计算的三种一阶导数有限差分格式：前向差分、后向差分和中心差分。假设在测量数据中，恰好有一个样本在 $x_i$ 处被一个大小为 $a$ 的加性异常值污染，而所有其他样本保持精确；也就是说，$x_i$ 处的测量值等于真实值加上 $a$，而任何 $j \\neq i$ 的 $x_j$ 处的测量值等于真实值。使用克罗内克 δ（Kronecker delta）$\\delta_{ij}$ 将此污染建模为加性扰动，其中当 $i=j$ 时 $\\delta_{ij} = 1$，否则 $\\delta_{ij}=0$。\n\n仅使用以下基础：\n- 导数作为差商极限的定义，以及\n- 有限差分格式通过用均匀网格上采样数据的有限差分代替极限来近似导数的思想，\n\n对于内部网格点 $x_i$，推导在 $x_i$ 处大小为 $a$ 的单点污染相对于未污染情况如何改变在 $x_i$ 处的三种导数近似值的显式表达式。然后，给出这种变化的绝对大小（灵敏度），作为 $a$ 和 $h$ 的函数，假设 $h0$ 并且中心差分有定义（即，$i$ 不是边界索引）。\n\n实现一个程序，对下面测试套件中的每个测试用例 $(h, a)$，计算一个包含三个实数的列表，这三个实数是三种格式在 $x_i$ 处的绝对变化（灵敏度），顺序为：前向、后向、中心。你的程序除了从上述基础推导出的公式外，不得假定任何特定公式，并且必须完全按照规定格式为测试套件生成结果。\n\n测试套件（每个用例为 $(h, a)$）：\n- 用例 1：$h = 0.1$, $a = 0.01$\n- 用例 2：$h = 0.1$, $a = 0$\n- 用例 3：$h = 10^{-6}$, $a = 10^{-3}$\n- 用例 4：$h = 2.5$, $a = -0.5$\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个以逗号分隔的子列表列表形式的结果，每个子列表对应一个测试用例，并按 [前向, 后向, 中心] 的顺序包含三个浮点数。整个序列必须用方括号括起来。例如，输出格式必须类似于 $[[v_{11},v_{12},v_{13}],[v_{21},v_{22},v_{23}],\\dots]$，前后无任何附加文本。不涉及物理单位，默认情况下，所有角度（如果有）均以弧度为单位（尽管此任务中未直接使用角度）。",
            "solution": "问题要求推导三种一阶导数 $f'(x_i)$ 的有限差分近似，对于在求值点 $x_i$ 处的单点加性误差的灵敏度。推导必须基于第一性原理：导数的极限定义及其在均匀网格上通过有限差分的近似。\n\n设真实、平滑的函数为 $f(x)$。其值在均匀网格 $x_j = x_0 + j h$ 上采样，其中 $j$ 为整数，常数间距 $h > 0$。采样值记为 $f_j = f(x_j)$。测量数据 $\\tilde{f}_j$ 在网格点 $x_i$ 处被一个大小为 $a$ 的单点加性异常值污染。此污染被建模为 $\\tilde{f}_j = f_j + a \\delta_{ij}$，其中 $\\delta_{ij}$ 是克罗内克 δ。这意味着 $\\tilde{f}_i = f_i + a$，而对于任何其他网格点 $j \\neq i$，测量值是未受污染的，即 $\\tilde{f}_j = f_j$。\n\n我们的目标是找到导数近似值的变化，我们将其泛指为 $D$。这个变化 $\\Delta D$ 是使用污染数据计算的近似值与使用真实数据计算的近似值之差：$\\Delta D = D(\\{\\tilde{f}_k\\}) - D(\\{f_k\\})$。灵敏度 $S$ 定义为此变化的绝对大小，$S = |\\Delta D|$。\n\n所有一阶导数 $f'(x)$ 的有限差分格式都是极限定义 $f'(x) = \\lim_{\\Delta x \\to 0} \\frac{f(x+\\Delta x) - f(x)}{\\Delta x}$ 的近似。这些格式是通过用网格间距 $h$ 上的有限差分替换极限而产生的。我们现在将在内部网格点 $x_i$ 分析这三种格式中的每一种。\n\n1.  **前向差分格式**\n\n前向差分近似 $D_+f(x_i)$ 是通过考虑大小为 $h$ 的一个前向步长得到的。其公式为：\n$$D_+f(x_i) = \\frac{f(x_i+h) - f(x_i)}{h} = \\frac{f_{i+1} - f_i}{h}$$\n使用真实、未受污染的函数值，近似值为 $D_+f(x_i)_{\\text{true}} = \\frac{f_{i+1} - f_i}{h}$。\n使用测量、受污染的值，近似值为 $\\tilde{D}_+f(x_i) = \\frac{\\tilde{f}_{i+1} - \\tilde{f}_i}{h}$。\n根据我们的误差模型，我们代入 $\\tilde{f}_{i+1} = f_{i+1}$（因为 $i+1 \\neq i$）和 $\\tilde{f}_i = f_i + a$：\n$$\\tilde{D}_+f(x_i) = \\frac{f_{i+1} - (f_i + a)}{h} = \\frac{f_{i+1} - f_i}{h} - \\frac{a}{h} = D_+f(x_i)_{\\text{true}} - \\frac{a}{h}$$\n前向差分近似的变化是 $\\Delta D_+f(x_i) = \\tilde{D}_+f(x_i) - D_+f(x_i)_{\\text{true}} = -\\frac{a}{h}$。\n灵敏度是此变化的绝对大小：\n$$S_+ = \\left| -\\frac{a}{h} \\right| = \\frac{|a|}{h}$$\n\n2.  **后向差分格式**\n\n后向差分近似 $D_-f(x_i)$ 使用大小为 $h$ 的一个后向步长。其公式源自另一种极限形式 $f'(x) = \\lim_{h \\to 0} \\frac{f(x) - f(x-h)}{h}$：\n$$D_-f(x_i) = \\frac{f(x_i) - f(x_i-h)}{h} = \\frac{f_i - f_{i-1}}{h}$$\n真实近似值为 $D_-f(x_i)_{\\text{true}} = \\frac{f_i - f_{i-1}}{h}$。\n使用受污染数据的近似值为 $\\tilde{D}_-f(x_i) = \\frac{\\tilde{f}_i - \\tilde{f}_{i-1}}{h}$。\n代入 $\\tilde{f}_i = f_i + a$ 和 $\\tilde{f}_{i-1} = f_{i-1}$（因为 $i-1 \\neq i$）：\n$$\\tilde{D}_-f(x_i) = \\frac{(f_i + a) - f_{i-1}}{h} = \\frac{f_i - f_{i-1}}{h} + \\frac{a}{h} = D_-f(x_i)_{\\text{true}} + \\frac{a}{h}$$\n变化为 $\\Delta D_-f(x_i) = \\tilde{D}_-f(x_i) - D_-f(x_i)_{\\text{true}} = \\frac{a}{h}$。\n灵敏度为：\n$$S_- = \\left| \\frac{a}{h} \\right| = \\frac{|a|}{h}$$\n\n3.  **中心差分格式**\n中心差分近似 $D_0f(x_i)$ 使用围绕 $x_i$ 的宽度为 $2h$ 的对称区间，提供一个更平衡的近似。问题陈述 $x_i$ 是一个内部点，因此其邻居 $x_{i-1}$ 和 $x_{i+1}$ 存在。其公式为：\n$$D_0f(x_i) = \\frac{f(x_i+h) - f(x_i-h)}{2h} = \\frac{f_{i+1} - f_{i-1}}{2h}$$\n真实近似值为 $D_0f(x_i)_{\\text{true}} = \\frac{f_{i+1} - f_{i-1}}{2h}$。\n对于受污染的数据，近似值为 $\\tilde{D}_0f(x_i) = \\frac{\\tilde{f}_{i+1} - \\tilde{f}_{i-1}}{2h}$。\n关键在于，在 $x_i$ 处导数的公式使用了来自 $x_{i+1}$ 和 $x_{i-1}$ 的值。污染局限于 $x_i$。因此，该格式所使用的值是未受污染的：$\\tilde{f}_{i+1} = f_{i+1}$ 和 $\\tilde{f}_{i-1} = f_{i-1}$。扰动值 $\\tilde{f}_i$ 并未出现在在 $x_i$ 处计算的中心差分的计算模板（stencil）中。\n因此，近似值不变：\n$$\\tilde{D}_0f(x_i) = \\frac{f_{i+1} - f_{i-1}}{2h} = D_0f(x_i)_{\\text{true}}$$\n变化为 $\\Delta D_0f(x_i) = 0$。\n因此，灵敏度为零：\n$$S_0 = |0| = 0$$\n\n总结来说，对于在网格点 $x_i$ 处大小为 $a$ 的单点污染，在 $x_i$ 处计算的三种导数近似的灵敏度为：\n-   前向差分灵敏度：$S_+ = \\frac{|a|}{h}$\n-   后向差分灵敏度：$S_- = \\frac{|a|}{h}$\n-   中心差分灵敏度：$S_0 = 0$\n\n这些结果将在程序中实现，以计算给定测试用例的数值。前向和后向格式表现出的灵敏度会随着网格间距 $h$ 的减小而放大，这是数值微分中病态条件的一个标志。相比之下，由于其计算模板的结构，中心差分格式对于在求值点本身的异常值是完全鲁棒的。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the sensitivity of forward, backward, and central difference\n    schemes to a single-point outlier.\n    \"\"\"\n    \n    # Test suite of (h, a) pairs, where h is grid spacing and a is outlier magnitude.\n    test_cases = [\n        (0.1, 0.01),\n        (0.1, 0.0),\n        (1e-6, 1e-3),\n        (2.5, -0.5),\n    ]\n\n    all_results = []\n    for h, a in test_cases:\n        # Based on the derivation, the sensitivities (absolute changes) are:\n        # S_forward = |a| / h\n        # S_backward = |a| / h\n        # S_central = 0\n        \n        # The problem statement guarantees h  0, so no division-by-zero check is needed.\n        \n        # Sensitivity of the forward difference scheme\n        sensitivity_forward = np.abs(a) / h\n        \n        # Sensitivity of the backward difference scheme\n        sensitivity_backward = np.abs(a) / h\n        \n        # Sensitivity of the central difference scheme\n        sensitivity_central = 0.0\n        \n        case_results = [sensitivity_forward, sensitivity_backward, sensitivity_central]\n        all_results.append(case_results)\n\n    # The required output is a single line string representation of a list of lists,\n    # with no spaces after commas. We construct this string manually to ensure\n    # exact formatting.\n    # Ex: [[v11,v12,v13],[v21,v22,v23]]\n    sublist_strs = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    final_output_str = f\"[{','.join(sublist_strs)}]\"\n    \n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在许多应用中，我们希望在不扩大计算模板（这在处理边界点时会带来麻烦）的情况下获得更高的精度。本练习将介绍理查森外推法（Richardson extrapolation），这是一种强大而通用的精度改进技术。通过将两个低阶的近似结果进行线性组合，你将构建出一个更高阶的近似公式，体验一种巧妙消除主导误差项的方法。",
            "id": "3132379",
            "problem": "您的任务是推导并实现一个使用理查森外推法（Richardson extrapolation）来提高一阶导数前向差分近似精度的算法。请从以下基础出发：一个足够光滑的函数在某点周围的泰勒级数展开，以及导数作为极限的定义。具体来说，使用光滑函数 $f$ 在 $x$ 处的泰勒级数展开来表示 $f(x+h)$（用 $f(x)$, $f'(x)$, $f''(x)$ 及更高阶导数表示），并使用由 $D_h^{+} f(x) = \\dfrac{f(x+h) - f(x)}{h}$ 给出的导数前向差分近似。以此为基础，分析 $D_h^{+} f(x)$ 的截断误差，并构建两个步长分别为 $h$ 和 $h/2$ 的前向差分的线性组合，以消除主阶截断误差项，从而得到一个误差为 $O(h^2)$ 阶的近似。\n\n您的任务是：\n- 使用泰勒级数确定 $D_h^{+} f(x)$ 的主截断误差项。\n- 确定系数 $\\alpha$ 和 $\\beta$，使得 $\\alpha D_{h/2}^{+} f(x) + \\beta D_h^{+} f(x)$ 是对 $f'(x)$ 的一个相容近似，且截断误差为 $O(h^2)$。\n- 实现一个程序，该程序针对下面指定的测试套件，计算每个 $(x,h)$ 对的理查森外推导数近似值，将其与精确导数进行比较，并返回浮点数形式的绝对误差。\n\n使用测试函数 $f(x) = \\cos x$，其精确导数为 $f'(x) = -\\sin x$。所有角度必须以弧度为单位。\n\n测试套件参数集 $(x,h)$（弧度）：\n- 情况1（一般情况）：$x = \\dfrac{\\pi}{3}$， $h = 0.2$。\n- 情况2（精确导数为零的类边界行为）：$x = 0$， $h = 0.1$。\n- 情况3（使用极小步长以探测舍入误差的边界情况）：$x = 1.0$， $h = 10^{-8}$。\n- 情况4（使用粗步长以观察误差行为）：$x = \\dfrac{\\pi}{2}$， $h = 0.5$。\n\n您的程序必须：\n- 实现 $D_h^{+} f(x) = \\dfrac{f(x+h) - f(x)}{h}$ 并使用您推导出的系数计算理查森外推近似值。\n- 对于每个测试用例，计算绝对误差 $\\left|\\text{approx} - f'(x)\\right|$。\n- 生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个浮点数四舍五入到 $10$ 位小数。例如，格式必须类似于“[r1,r2,r3,r4]”，其中每个 $r_i$ 是一个十进制数。\n\n不允许用户输入或使用外部文件。程序必须是自包含的，并且可以按原样执行。",
            "solution": "该问题要求推导并实现一个理查森外推算法，以提高一阶导数前向差分近似的精度。此过程始于对问题陈述的正式验证。\n\n### 第1步：提取已知条件\n- **函数**：一个足够光滑的函数，记为 $f$。\n- **测试函数**：$f(x) = \\cos x$。\n- **精确导数**：$f'(x) = -\\sin x$。\n- **基本近似**：前向差分公式，$D_h^{+} f(x) = \\dfrac{f(x+h) - f(x)}{h}$。\n- **基础**：$f(x+h)$ 在 $x$ 点的泰勒级数展开。\n- **目标**：找到系数 $\\alpha$ 和 $\\beta$，使得线性组合 $\\alpha D_{h/2}^{+} f(x) + \\beta D_h^{+} f(x)$ 产生一个截断误差为 $O(h^2)$ 阶的新近似。\n- **任务**：实现推导出的公式，并为给定的测试套件计算绝对误差 $|\\text{approx} - f'(x)|$。\n- **约束**：所有角度均以弧度为单位。\n- **测试套件**：\n    - 情况1：$x = \\dfrac{\\pi}{3}$，$h = 0.2$。\n    - 情况2：$x = 0$，$h = 0.1$。\n    - 情况3：$x = 1.0$，$h = 10^{-8}$。\n    - 情况4：$x = \\dfrac{\\pi}{2}$，$h = 0.5$。\n- **输出格式**：一个单行字符串 `\"[r1,r2,r3,r4]\"`，其中每个 $r_i$ 是对应测试用例的绝对误差，四舍五入到10位小数。\n\n### 第2步：使用提取的已知条件进行验证\n根据验证标准对问题陈述进行评估。\n\n- **科学依据**：该问题基于数值分析的基本和标准概念：泰勒级数、有限差分近似和理查森外推法。这些是计算科学和数学中核心且完善的原理。选择 $f(x) = \\cos x$ 是合适的，因为它是一个无限可微（$C^\\infty$）的函数，满足“足够光滑”的标准。该问题在科学上是合理的。\n- **适定性**：问题定义清晰。它指定了初始公式、理论工具（泰勒级数）、目标（推导更高阶的公式）、测试函数、确切的测试参数以及精确的输出格式。对于系数的推导和后续的计算，存在唯一且稳定的解。\n- **客观性**：问题以精确、形式化的数学语言陈述。它没有歧义、主观性或基于观点的论断。\n\n该问题不存在任何无效性缺陷。它是数值方法中一个标准的、形式化的问题，是完整的、一致的且可验证的。\n\n### 第3步：结论与行动\n该问题是**有效的**。将提供一个完整的、有理有据的解决方案。\n\n### 理查森外推公式的推导\n\n我们的目标是提高一阶导数前向差分近似的精度。我们从光滑函数 $f$ 在点 $x+h$ 处围绕 $x$ 的泰勒级数展开开始。\n\n泰勒级数展开由下式给出：\n$$\nf(x+h) = f(x) + h f'(x) + \\frac{h^2}{2!} f''(x) + \\frac{h^3}{3!} f'''(x) + O(h^4)\n$$\n其中 $f'(x)$，$f''(x)$ 等表示 $f$ 在 $x$ 处求得的导数。\n\n我们重新整理这个展开式以求解 $f'(x)$：\n$$\nh f'(x) = f(x+h) - f(x) - \\frac{h^2}{2} f''(x) - \\frac{h^3}{6} f'''(x) - O(h^4)\n$$\n两边除以 $h$ 得到精确导数的表达式：\n$$\nf'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{h}{2} f''(x) - \\frac{h^2}{6} f'''(x) - O(h^3)\n$$\n项 $\\frac{f(x+h) - f(x)}{h}$ 是前向差分近似，我们记为 $D_h^{+} f(x)$。因此，我们可以用真值和一个误差级数来表示这个近似：\n$$\nD_h^{+} f(x) = f'(x) + \\frac{h}{2} f''(x) + \\frac{h^2}{6} f'''(x) + O(h^3)\n$$\n这个方程表明，前向差分近似 $D_h^{+} f(x)$ 的截断误差主项为 $\\frac{h}{2} f''(x)$，这使得该近似达到一阶精度，即 $O(h)$。\n\n让我们将步长为 $h$ 的近似记为 $A(h)$。我们寻求的真值为 $L = f'(x)$。我们的误差展开式形式为 $A(h) = L + c_1 h + c_2 h^2 + c_3 h^3 + \\dots$。\n根据我们的推导，$c_1 = \\frac{f''(x)}{2}$ 且 $c_2 = \\frac{f'''(x)}{6}$。\n\n所以，我们有：\n$$\nD_h^{+} f(x) = f'(x) + \\frac{h}{2} f''(x) + O(h^2)\n\\quad \\quad (1)\n$$\n现在，我们为另一个不同的步长，具体为 $h/2$，写出相同的表达式：\n$$\nD_{h/2}^{+} f(x) = f'(x) + \\frac{(h/2)}{2} f''(x) + O((h/2)^2)\n$$\n$$\nD_{h/2}^{+} f(x) = f'(x) + \\frac{h}{4} f''(x) + O(h^2)\n\\quad \\quad (2)\n$$\n我们的目标是找到方程 $(1)$ 和 $(2)$ 的一个线性组合，以消除主误差项，即与 $h f''(x)$ 成正比的项。\n我们将方程 $(2)$ 乘以 $2$：\n$$\n2 D_{h/2}^{+} f(x) = 2 f'(x) + \\frac{h}{2} f''(x) + O(h^2)\n\\quad \\quad (3)\n$$\n现在，我们从方程 $(3)$ 中减去方程 $(1)$：\n$$\n2 D_{h/2}^{+} f(x) - D_h^{+} f(x) = (2 f'(x) - f'(x)) + \\left(\\frac{h}{2} f''(x) - \\frac{h}{2} f''(x)\\right) + O(h^2)\n$$\n$$\n2 D_{h/2}^{+} f(x) - D_h^{+} f(x) = f'(x) + O(h^2)\n$$\n这为我们提供了一个新的、更精确的 $f'(x)$ 近似值，我们可以称之为 $D_{extrap} f(x)$：\n$$\nD_{extrap} f(x) = 2 D_{h/2}^{+} f(x) - D_h^{+} f(x)\n$$\n这个新近似的误差是 $O(h^2)$ 阶的，因为 $O(h)$ 项已经被消除了。\n\n问题要求系数 $\\alpha$ 和 $\\beta$，使得新的近似为 $\\alpha D_{h/2}^{+} f(x) + \\beta D_h^{+} f(x)$。通过与我们推导出的公式进行比较，我们确定这些系数为：\n$$\n\\alpha = 2\n$$\n$$\n\\beta = -1\n$$\n为使近似是相容的，系数之和必须为 $1$。这里，$\\alpha + \\beta = 2 + (-1) = 1$，这证实了其相容性。\n\n最终需要实现的公式是：\n$$\nD_{extrap} f(x) = 2 \\left( \\frac{f(x+h/2) - f(x)}{h/2} \\right) - \\left( \\frac{f(x+h) - f(x)}{h} \\right)\n$$\n该公式将用于计算每个测试用例的近似导数。然后，绝对误差为 $|\\text{approx} - \\text{exact}| = |D_{extrap} f(x) - f'(x)|$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and applies Richardson extrapolation to a forward difference formula\n    to calculate the first derivative of f(x) = cos(x) and computes the absolute error.\n    \"\"\"\n\n    # Define the test function and its exact derivative.\n    # All angles are in radians, which is the default for numpy's trig functions.\n    def f(x):\n        return np.cos(x)\n\n    def df_dx_exact(x):\n        return -np.sin(x)\n\n    # Define the forward difference approximation D_h^{+} f(x).\n    def forward_difference(func, x, h):\n        if h == 0:\n            raise ValueError(\"Step size h cannot be zero.\")\n        return (func(x + h) - func(x)) / h\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.pi / 3, 0.2),       # Case 1: General case\n        (0.0, 0.1),             # Case 2: Boundary-like behavior (derivative is zero)\n        (1.0, 1e-8),            # Case 3: Edge case with small step (probes round-off)\n        (np.pi / 2, 0.5),       # Case 4: Coarse step size\n    ]\n\n    results = []\n    for x, h in test_cases:\n        # Calculate the forward difference for step sizes h and h/2.\n        # This is A(h) in the derivation.\n        approx_h = forward_difference(f, x, h)\n        \n        # This is A(h/2) in the derivation.\n        approx_h_half = forward_difference(f, x, h / 2.0)\n\n        # Apply the Richardson extrapolation formula: 2 * A(h/2) - A(h).\n        # The coefficients are alpha=2 and beta=-1.\n        richardson_approx = 2.0 * approx_h_half - 1.0 * approx_h\n\n        # Get the exact value of the derivative.\n        exact_value = df_dx_exact(x)\n\n        # Compute the absolute error between the extrapolated value and the exact value.\n        absolute_error = np.abs(richardson_approx - exact_value)\n        \n        results.append(absolute_error)\n\n    # Format the final output string according to the specification.\n    # Each result is formatted to 10 decimal places.\n    output_str = f\"[{','.join([f'{r:.10f}' for r in results])}]\"\n    \n    print(output_str)\n\nsolve()\n```"
        }
    ]
}