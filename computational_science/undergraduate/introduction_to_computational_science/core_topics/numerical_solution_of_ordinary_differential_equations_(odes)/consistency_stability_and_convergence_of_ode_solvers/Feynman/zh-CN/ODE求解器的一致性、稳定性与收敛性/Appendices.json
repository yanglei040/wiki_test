{
    "hands_on_practices": [
        {
            "introduction": "理论告诉我们，一个数值方法的收敛性取决于其相容性与稳定性。但如果没有稳定性，仅有相容性会发生什么？本练习  将通过构建一个虽然相容（局部误差趋于零）但不稳定（不满足零稳定性条件）的方法，清晰地揭示为何该方法无法收敛，从而深刻理解稳定性在连接局部精度和全局收敛中的关键作用。",
            "id": "3156045",
            "problem": "考虑一个由 $y'(t) = f(t,y(t))$ 和 $y(0) = y_0$ 给出的常微分方程（ODE）初值问题，其中 $y(t)$ 是一个足够光滑的标量函数，$f$ 是一个足够光滑的函数。将局部截断误差（LTE）定义为将精确解代入所提出的单步数值递推式中产生的余项，将全局截断误差（GTE）定义为在指定最终时刻数值近似解与精确解之间的差异。在线性多步法的背景下，零稳定性是指递推关系的齐次部分不会随着步数的增加而无限放大扰动；对于单步法，稳定性指的是由线性化递推因子控制的误差传播的有界性。\n\n设计并实现一个数值实验，以区分相容性（当步长趋于零时，LTE 趋于零）和收敛性（当步长趋于零时，GTE 趋于零）这两个概念。使用在区间 $t \\in [0,1]$ 上的 ODE $y'(t) = -y(t)$，其精确解为 $y(t) = e^{-t}$ 且 $y_0 = 1$。构建并分析一种线性多步法，该方法是相容的（其 LTE 随着 $h \\to 0$ 趋于 $0$），但不是稳定的，因此不收敛，以此与一种稳定的单步法进行对比。\n\n任务：\n1. 对 $f(t,y) = -y$ 实现两步递推式 $y_{n+1} - 2 y_n + y_{n-1} = h f(t_n, y_n)$。使用精确解中的 $y_0 = y(0)$ 和 $y_1 = y(h)$ 来初始化该方法，以隔离传播效应而非启动近似效应。对于 $n = 1,2,\\dots,N-1$ 且 $Nh = 1$，将递推演化至 $t_N = 1$ 并计算最终时刻的绝对全局截断误差 $|y_N - e^{-1}|$。\n2. 对于相同的方法，通过将精确解代入递推式中来计算单步余项，从而计算出时间上的最大绝对局部截断误差，即 $\\max_{n=1,\\dots,N-1} \\left| y(t_{n+1}) - 2 y(t_n) + y(t_{n-1}) - h f(t_n, y(t_n)) \\right|$，其中 $t_n = n h$。\n3. 对 $f(t,y) = -y$ 且 $y_0 = 1$ 实现 forward Euler 单步法 $y_{n+1} = y_n + h f(t_n, y_n)$，并类似地计算其时间上的最大绝对局部截断误差 $\\max_{n=0,\\dots,N-1} \\left| y(t_{n+1}) - y(t_n) - h f(t_n, y(t_n)) \\right|$ 及其最终时刻的绝对全局截断误差 $|y_N - e^{-1}|$。\n4. 使用以下步长测试集，该测试集探索了一般情况和逐步细化的步长：$h \\in \\{0.5, 0.25, 0.125, 0.0625\\}$。对于每个 $h$，令步数 $N = 1/h$，从而使得 $t_N = 1$。\n5. 您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表。对于列表中的每个 $h$，按此顺序附加四个浮点数：不稳定两步法的时间上最大绝对局部截断误差、不稳定两步法的最终时刻绝对全局截断误差、forward Euler 方法的时间上最大绝对局部截断误差、forward Euler 方法的最终时刻绝对全局截断误差。因此，最终输出包含 $16$ 个浮点数，对应于四个步长中的每一个的四个值，所有值都在一个扁平列表中。此问题不涉及物理单位，也未使用角度。",
            "solution": "我们从初值问题 $y'(t) = f(t,y(t))$ 开始，其中 $f(t,y) = -y$，$y(0) = 1$，在 $t \\in [0,1]$ 上的精确解为 $y(t) = e^{-t}$。对于给定格式，在时刻 $t_n$ 的局部截断误差（LTE）定义为将精确值代入单步数值递推式时得到的代数余项。在时刻 $t_N$ 的全局截断误差（GTE）定义为差值 $|y_N - y(t_N)|$，其中 $y_N$ 是数值解，$y(t_N)$ 是精确解。\n\n为了对比相容性与收敛性，我们考虑两种格式。\n\n第一种格式（两步法，相容但不稳定）：\n该方法为 $y_{n+1} - 2 y_n + y_{n-1} = h f(t_n,y_n)$，对于 $f(t,y) = -y$，该方法变为 $y_{n+1} = (2 - h) y_n - y_{n-1}$。其齐次递推关系为 $y_{n+1} - 2 y_n + y_{n-1} = 0$，特征多项式为 $\\rho(\\zeta) = \\zeta^2 - 2 \\zeta + 1 = (\\zeta - 1)^2$。在 $\\zeta = 1$ 处的二重根违反了线性多步法的零稳定性条件，该条件要求 $\\rho(\\zeta)$ 的所有根都满足 $|\\zeta| \\le 1$，并且任何满足 $|\\zeta| = 1$ 的根都必须是单根。因此，该方法不是零稳定的，无论是否相容，它都不能收敛。\n\n为了检验相容性，我们推导局部截断误差。根据定义，$t_n$ 处的 LTE 为\n$$\n\\tau_n = y(t_{n+1}) - 2 y(t_n) + y(t_{n-1}) - h f(t_n, y(t_n))。\n$$\n对足够光滑的 $y$ 在 $t_n$ 附近进行泰勒展开，\n$$\ny(t_{n\\pm 1}) = y(t_n) \\pm h y'(t_n) + \\frac{h^2}{2} y''(t_n) \\pm \\frac{h^3}{6} y^{(3)}(t_n) + \\mathcal{O}(h^4)。\n$$\n相减可得\n$$\ny(t_{n+1}) - 2 y(t_n) + y(t_{n-1}) = h^2 y''(t_n) + \\mathcal{O}(h^4)，\n$$\n并且由于 $f(t,y) = -y$，我们有 $-h f(t_n, y(t_n)) = h y(t_n)$。因此，\n$$\n\\tau_n = h^2 y''(t_n) + h y(t_n) + \\mathcal{O}(h^4)。\n$$\n对于我们特定的 ODE，$y'(t) = -y(t)$ 意味着 $y''(t) = -y'(t) = y(t)$，所以\n$$\n\\tau_n = h^2 y(t_n) + h y(t_n) + \\mathcal{O}(h^4) = h y(t_n) + \\mathcal{O}(h^2)。\n$$\n因此，当 $h \\to 0$ 时，$\\tau_n \\to 0$，证明了相容性。\n\n然而，收敛性（当 $h \\to 0$ 时 GTE $\\to 0$）除了相容性外还需要稳定性。为了理解为何此处的全局截断误差不消失，我们考虑误差 $e_n = y_n - y(t_n)$。减去精确递推式（精确解满足该递推式，误差为 LTE），误差满足\n$$\ne_{n+1} - 2 e_n + e_{n-1} = -h e_n + \\tau_n,\n$$\n其中 $\\tau_n$ 是如上所述的 LTE 余项。该误差递推的齐次部分，\n$$\ne_{n+1} - 2 e_n + e_{n-1} = 0,\n$$\n其解的形式为 $e_n = C_1 + C_2 n$。在 $\\zeta = 1$ 处的重根意味着即使在策动力项 $-h e_n$ 很小时，扰动也会随 $n$ 呈多项式增长。包含大小为 $\\mathcal{O}(h)$ 的策动力 $\\tau_n$，通过离散常数变易法论证可知，$e_n$ 会随着步数线性累积。在 $N = 1/h$ 步（因为 $Nh = 1$）之后，累积的放大效应产生\n$$\ne_N \\sim \\mathcal{O}(N \\cdot h) = \\mathcal{O}(1),\n$$\n该结果不会随着 $h \\to 0$ 而趋于零。因此，尽管 LTE $\\to 0$（相容性），但该方法由于不是零稳定的而不收敛；其 GTE 不会消失。\n\n第二种格式（单步法，稳定且收敛）：\nforward Euler 方法是 $y_{n+1} = y_n + h f(t_n,y_n)$，在此处为 $y_{n+1} = (1 - h) y_n$。其 LTE 通过代入精确解得到，为\n$$\n\\tau_n = y(t_{n+1}) - y(t_n) - h f(t_n, y(t_n)) = y(t_{n+1}) - y(t_n) + h y(t_n)。\n$$\n使用泰勒展开，\n$$\ny(t_{n+1}) - y(t_n) = h y'(t_n) + \\frac{h^2}{2} y''(t_n) + \\mathcal{O}(h^3) = -h y(t_n) + \\frac{h^2}{2} y''(t_n) + \\mathcal{O}(h^3)，\n$$\n且有 $y''(t_n) = y(t_n)$，我们得到\n$$\n\\tau_n = \\frac{h^2}{2} y(t_n) + \\mathcal{O}(h^3)，\n$$\n所以 LTE 以二次方式趋于 $0$。误差递推关系为\n$$\ne_{n+1} = (1 - h) e_n + \\tau_n。\n$$\n对于 $h \\in (0,2)$，我们有 $|1 - h|  1$，这意味着误差是衰减的。对受迫响应求和表明\n$$\ne_N = \\sum_{k=0}^{N-1} (1 - h)^{N-1-k} \\tau_k,\n$$\n该和由一个几何级数界定，其大小与 $\\max_k |\\tau_k| = \\mathcal{O}(h^2)$ 成比例，从而当 $h \\to 0$ 时得到 $e_N = \\mathcal{O}(h)$。因此，forward Euler 方法既是相容的也是稳定的，因此是收敛的，其 GTE $\\to 0$。\n\n实验设计与计算：\n- 我们固定 $T = 1$ 和步长 $h \\in \\{0.5, 0.25, 0.125, 0.0625\\}$，使得 $N = 1/h$ 是一个整数。\n- 对于两步法，我们使用精确的初始值 $y_0 = y(0)$ 和 $y_1 = y(h)$ 以关注传播稳定性。我们通过将 $y(t_n)$ 代入递推式并在 $n = 1,\\dots,N-1$ 上取最大值来计算时间上的最大绝对 LTE。我们将递推式演化到 $t_N = 1$ 后，计算最终时刻的绝对 GTE $|y_N - e^{-1}|$。\n- 对于 forward Euler 方法，我们类似地通过代入法计算其时间上的最大绝对 LTE，并通过从 $y_0 = 1$ 开始演化数值递推来计算其最终时刻的绝对 GTE。\n\n预期的定性结果：\n- 对于两步法，时间上的最大绝对 LTE 随 $h$ 减小（相容性），但由于缺乏零稳定性，最终时刻的绝对 GTE 不会趋于零；当 $h \\to 0$ 时，它保持在 $\\mathcal{O}(1)$ 的量级。\n- 对于 forward Euler 方法，时间上的最大绝对 LTE 和最终时刻的绝对 GTE 都随 $h$ 减小；最终时刻的 GTE 线性趋于零，反映了收敛性。\n\n程序为每个 $h$ 输出一个扁平列表，按照测试集的顺序包含以下内容：\n1. 两步法的时间上最大绝对 LTE，\n2. 两步法的最终时刻绝对 GTE，\n3. forward Euler 方法的时间上最大绝对 LTE，\n4. forward Euler 方法的最终时刻绝对 GTE。\n\n这直接证明了，没有稳定性，LTE $\\to 0$ 并不能保证 GTE $\\to 0$，从而区分了相容性与收敛性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef y_exact(t: float) - float:\n    # Exact solution for y' = -y with y(0) = 1\n    return np.exp(-t)\n\ndef f_rhs(t: float, y: float) - float:\n    # Right-hand side f(t,y) = -y\n    return -y\n\ndef lte_two_step(h: float, T: float) - float:\n    # Compute maximum-in-time absolute LTE for two-step method:\n    # tau_n = y(t_{n+1}) - 2 y(t_n) + y(t_{n-1}) - h f(t_n, y(t_n))\n    N = int(round(T / h))\n    # times t_n = n h, n = 0..N\n    max_tau = 0.0\n    for n in range(1, N):  # n=1..N-1 has neighbors n-1 and n+1 within [0,N]\n        t_n = n * h\n        tau = y_exact(t_n + h) - 2.0 * y_exact(t_n) + y_exact(t_n - h) - h * f_rhs(t_n, y_exact(t_n))\n        max_tau = max(max_tau, abs(tau))\n    return max_tau\n\ndef gte_two_step(h: float, T: float) - float:\n    # Compute final-time absolute GTE for two-step method evolution with exact starts\n    N = int(round(T / h))\n    y = np.zeros(N + 1, dtype=float)\n    # exact starts\n    y[0] = y_exact(0.0)\n    if N = 1:\n        y[1] = y_exact(h)\n    # evolve: y_{n+1} = (2 - h) y_n - y_{n-1}\n    for n in range(1, N):\n        y[n + 1] = (2.0 - h) * y[n] - y[n - 1]\n    return abs(y[N] - y_exact(T))\n\ndef lte_forward_euler(h: float, T: float) - float:\n    # Compute maximum-in-time absolute LTE for forward Euler:\n    # tau_n = y(t_{n+1}) - y(t_n) - h f(t_n, y(t_n)), for n=0..N-1\n    N = int(round(T / h))\n    max_tau = 0.0\n    for n in range(0, N):\n        t_n = n * h\n        tau = y_exact(t_n + h) - y_exact(t_n) - h * f_rhs(t_n, y_exact(t_n))\n        max_tau = max(max_tau, abs(tau))\n    return max_tau\n\ndef gte_forward_euler(h: float, T: float) - float:\n    # Compute final-time absolute GTE for forward Euler evolution\n    N = int(round(T / h))\n    y = 1.0  # y0\n    for _ in range(N):\n        y = y + h * f_rhs(0.0, y)  # f depends only on y here; t not needed\n        # Using t argument consistently, but for f = -y, t is irrelevant.\n    return abs(y - y_exact(T))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    T = 1.0\n    test_steps = [0.5, 0.25, 0.125, 0.0625]\n\n    results = []\n    for h in test_steps:\n        # Two-step method (consistent but not zero-stable)\n        lte_ts = lte_two_step(h, T)\n        gte_ts = gte_two_step(h, T)\n        # Forward Euler (stable for h in (0,2), convergent)\n        lte_fe = lte_forward_euler(h, T)\n        gte_fe = gte_forward_euler(h, T)\n        results.extend([lte_ts, gte_ts, lte_fe, gte_fe])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在现实世界的科学计算中，“刚性”问题无处不在，它对数值求解器的选择提出了严峻挑战。本练习  将带你深入一个具有饱和效应的捕食者-被捕食者模型，通过对比显式与隐式方法，亲手揭示刚性问题是如何迫使我们放弃计算简单的显式方法，转而使用更稳健的隐式方法来实现理论上的收敛阶。",
            "id": "3112018",
            "problem": "创建一个完整的、可运行的程序，对具有饱和功能反应的捕食者-被捕食者系统进行步长减半收敛性研究，并用它来推断常微分方程（ODE）求解器的一致性、稳定性和收敛性。该研究必须基于以下第一性原理：初值问题（IVP）的定义，一致性、稳定性和收敛性的概念，以及从泰勒展开和积分形式构造固定步长单步方法。利用这些思想设计一个程序，用于检测因被捕食者饱和而引入的刚性问题，何时会迫使隐式方法达到其形式精度阶，而显式方法在较粗糙的步长上受到稳定性限制。\n\n您必须使用以下捕食者-被捕食者系统\n$$\n\\begin{aligned}\n\\frac{dx}{dt} = r\\,x\\left(1-\\frac{x}{K}\\right)\\;-\\;\\frac{c\\,x\\,y}{1+\\alpha x},\\\\\n\\frac{dy}{dt} = \\varepsilon\\left(\\eta\\,\\frac{c\\,x\\,y}{1+\\alpha x}\\;-\\;m\\,y\\right),\n\\end{aligned}\n$$\n其中 $x$ 是被捕食者密度，$y$ 是捕食者密度。饱和功能反应由分母中的因子 $(1+\\alpha x)$ 编码，当被捕食者动力学迅速饱和（$r$ 相对于其他速率较大和/或较小的 $\\varepsilon$ 使得捕食者-被捕食者的时间尺度差异悬殊）时，可能会出现刚性问题。\n\n您的推理和算法设计必须仅基于以下基本要素：\n- 常微分方程（ODE）的初值问题（IVP）概念：给定 $\\frac{d\\mathbf{u}}{dt}=\\mathbf{f}(t,\\mathbf{u})$ 和 $\\mathbf{u}(0)=\\mathbf{u}_0$，求解 $\\mathbf{u}(t)$。\n- 定义：如果一个方法的局部截断误差在步长 $h\\to 0$ 时趋于 $0$，则该方法是一致的。如果误差在扰动下不会失控增长，则该方法是稳定的；对于线性标量测试 $\\frac{du}{dt}=\\lambda u$（其中 $\\mathrm{Re}(\\lambda)\\le 0$），这由复平面上关于 $z=h\\lambda$ 的一个稳定性区域来表征。如果一个方法的全局误差在 $h\\to 0$ 时趋于 $0$，则该方法是收敛的。一致性加稳定性意味着收敛性。\n- 固定步长单步法可以通过匹配泰勒级数（对于显式 Runge–Kutta 型格式）或通过应用微积分基本定理在步长上对矢量场进行平均（对于隐式梯形格式）来构造。\n\n实现两种方法：\n- 一种显式二阶 Runge-Kutta 方法（显式中点法），这是一种形式阶为 $2$ 的一致显式方法。\n- 隐式梯形法则（形式阶也为 $2$），每一步都使用精确的雅可比矩阵通过牛顿法求解。\n\n在固定的区间 $[0,T]$ 上使用这些方法，其中 $T$ 的值在下面指定。对每种方法，使用均匀步长进行步长减半研究。对于每个步长 $h_k$，计算在 $t=T$ 时的数值解，并与高精度参考解进行比较以估计全局误差。使用最小可用步长中误差递减的后缀部分，通过对 $\\log(\\text{误差})$ 与 $\\log(h)$ 进行线性拟合来估计实验收敛阶（EOC）。在本研究中，如果使用最小步长处至少 $3$ 个严格递减的误差点，估计出的 EOC 至少为 $1.7$，则称该方法“达到了其形式阶”。\n\n对于给定的参数集，将“因被捕食者饱和而引入的刚性问题迫使隐式方法达到其形式阶”定义为：隐式梯形法达到了如上定义的其形式阶，同时显式中点法在较粗糙的步长上受到稳定性限制，其证据是在步长减半序列中至少有一个较粗糙的步长未能产生有限的、非 NaN 的终值（即，在指定的 5 个步长中，它产生的有限终点近似值少于 5 个）。在此条件下，为该参数集报告值 $1$；否则报告 $0$。\n\n数值细节和测试套件：\n- 使用最终时间 $T=2$（即，$T=2$）。\n- 使用初始条件 $(x(0),y(0))=(x_0,y_0)=(0.5,0.3)$。\n- 使用 $N_k\\in\\{20,40,80,160,320\\}$ 个均匀步长，对应于 $h_k=T/N_k$，其中 $k=0,1,2,3,4$。这给出了 5 个步长并进行减半。\n- 使用能处理刚性问题的积分器以严格的容差计算在 $t=T$ 时的高精度参考解；该参考解仅用于测量固定步长方法的终端全局误差。\n- 对于隐式梯形法中的牛顿求解，使用 $\\mathbf{f}$ 的精确雅可比矩阵，牛顿绝对容差为 $10^{-12}$，每步最大迭代次数为 $20$ 次。\n\n为以下三个参数集（测试套件）提供结果，每个参数集表示为 $(r,K,\\alpha,c,\\eta,m,\\varepsilon)$：\n- 案例 $\\mathsf{A}$（非刚性基线）：$(2,\\,1,\\,2,\\,3,\\,0.7,\\,0.4,\\,1)$。\n- 案例 $\\mathsf{B}$（通过被捕食者饱和和时间尺度分裂导致的中度刚性）：$(50,\\,1,\\,2,\\,4,\\,0.7,\\,0.4,\\,0.1)$。\n- 案例 $\\mathsf{C}$（高度刚性）：$(150,\\,1,\\,2,\\,4,\\,0.7,\\,0.4,\\,0.05)$。\n\n输出规格：\n- 对于 $(\\mathsf{A},\\mathsf{B},\\mathsf{C})$ 顺序的每个案例，输出一个如上定义的整数 $0$ 或 $1$。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，例如 $[1,0,1]$。\n\n所有计算都是无量纲的；不需要物理单位。不使用角度。最终输出必须是可计算的布尔值或整数，如指定的那样，并且必须采用单行格式。",
            "solution": "核心任务是通过对一个捕食者-被捕食者系统进行步长减半收敛性研究，来探究常微分方程（ODE）求解器的数值特性。该系统的动力学可以调整为刚性，这使得可以清晰地展示显式和隐式数值方法的不同行为。我们将实现两种二阶方法，一种显式，一种隐式，并利用它们的性能，在严格遵守一致性、稳定性和收敛性定义的前提下，对不同参数集下系统的刚性进行分类。\n\n该系统是一个二维自治常微分方程（ODE），由以下公式给出：\n$$\n\\begin{aligned}\n\\frac{dx}{dt} = r\\,x\\left(1-\\frac{x}{K}\\right)\\;-\\;\\frac{c\\,x\\,y}{1+\\alpha x} \\\\\n\\frac{dy}{dt} = \\varepsilon\\left(\\eta\\,\\frac{c\\,x\\,y}{1+\\alpha x}\\;-\\;m\\,y\\right)\n\\end{aligned}\n$$\n这可以写成标准向量形式的初值问题（IVP）$\\frac{d\\mathbf{u}}{dt} = \\mathbf{f}(t, \\mathbf{u})$，并带有初始条件 $\\mathbf{u}(t_0) = \\mathbf{u}_0$。这里，状态向量是 $\\mathbf{u}(t) = [x(t), y(t)]^T$，矢量场是 $\\mathbf{f}(\\mathbf{u}) = [f_x(x,y), f_y(x,y)]^T$。初始条件为 $\\mathbf{u}(0) = [x_0, y_0]^T = [0.5, 0.3]^T$。研究将在时间区间 $[0, T]$ 上进行，其中 $T=2$。\n\n核心概念是：\n- **一致性**：如果一个方法的局部截断误差（在单步中产生的误差）在步长 $h \\to 0$ 时趋近于零，则该方法是一致的。\n- **稳定性**：如果在一个步骤中引入的误差在后续步骤中不会无界增长，则该方法是稳定的。对于刚性问题，这通过模型方程 $\\frac{du}{dt} = \\lambda u$ 进行分析，其中 $\\lambda$ 为复数且 $\\mathrm{Re}(\\lambda) \\le 0$。一个方法的稳定性区域是复数值 $z=h\\lambda$ 的集合，在此集合内数值解保持有界。\n- **收敛性**：如果全局误差（在固定的最终时间 $T$ 处的累积误差）在 $h \\to 0$ 时趋近于零，则该方法是收敛的。Lax-Richtmyer 等价定理指出，对于一个一致的方法，稳定性等价于收敛性。收敛速率通常通过实验收敛阶（EOC）来衡量。\n\n我们将实现两种形式阶为 $2$ 的固定步长单步法。\n\n**1. 显式二阶 Runge-Kutta 方法（显式中点法）**\n\n该方法通过匹配解的泰勒级数展开中的项而导出。它使用两次函数求值将解从时间 $t_n$ 推进到 $t_{n+1} = t_n + h$：\n$$\n\\begin{aligned}\n\\mathbf{k}_1 = \\mathbf{f}(t_n, \\mathbf{u}_n) \\\\\n\\mathbf{k}_2 = \\mathbf{f}\\left(t_n + \\frac{h}{2}, \\mathbf{u}_n + \\frac{h}{2}\\mathbf{k}_1\\right) \\\\\n\\mathbf{u}_{n+1} = \\mathbf{u}_n + h \\mathbf{k}_2\n\\end{aligned}\n$$\n此方法是显式的，因为 $\\mathbf{u}_{n+1}$ 是直接从已知量计算得出的。它是一致的，局部截断误差为 $O(h^3)$ 阶，这导致全局误差为 $O(h^2)$ 阶。然而，其稳定性区域是复平面上的一个有限区域。如果问题是刚性的，其雅可比矩阵的特征值可能具有大的负实部，这会迫使乘积 $h\\lambda$ 位于稳定性区域之外，除非步长 $h$ 受到严格限制。这是一种稳定性限制。\n\n**2. 隐式梯形法则**\n\n该方法源自微积分基本定理 $\\mathbf{u}(t_{n+1}) - \\mathbf{u}(t_n) = \\int_{t_n}^{t_{n+1}} \\mathbf{f}(t, \\mathbf{u}(t)) dt$，通过使用梯形法则近似该积分而导出：\n$$\n\\mathbf{u}_{n+1} = \\mathbf{u}_n + \\frac{h}{2} \\left[ \\mathbf{f}(t_n, \\mathbf{u}_n) + \\mathbf{f}(t_{n+1}, \\mathbf{u}_{n+1}) \\right]\n$$\n此方法是隐式的，因为未知数 $\\mathbf{u}_{n+1}$ 出现在方程的两边。它也是一个二阶方法。关键在于，它是 A-稳定的，意味着其稳定性区域包含整个复平面的左半部分。这一特性使其即使在步长很大时，对于刚性问题也能保持稳定，从而使其精度而非稳定性成为限制因素。\n\n为了使用梯形法则，我们必须在每一步求解一个关于 $\\mathbf{u}_{n+1}$ 的非线性方程组。我们定义一个函数 $\\mathbf{G}(\\mathbf{w}) = \\mathbf{0}$，其中我们寻求根 $\\mathbf{w} = \\mathbf{u}_{n+1}$：\n$$\n\\mathbf{G}(\\mathbf{w}) = \\mathbf{w} - \\mathbf{u}_n - \\frac{h}{2} \\left[ \\mathbf{f}(t_n, \\mathbf{u}_n) + \\mathbf{f}(t_{n+1}, \\mathbf{w}) \\right] = \\mathbf{0}\n$$\n这使用牛顿法求解。从一个初始猜测 $\\mathbf{w}^{(0)}$（例如，$\\mathbf{w}^{(0)} = \\mathbf{u}_n$）开始，我们进行迭代：\n$$\n\\mathbf{w}^{(k+1)} = \\mathbf{w}^{(k)} - [J_G(\\mathbf{w}^{(k)})]^{-1} \\mathbf{G}(\\mathbf{w}^{(k)})\n$$\n$\\mathbf{G}$ 相对于 $\\mathbf{w}$ 的雅可比矩阵是 $J_G(\\mathbf{w}) = I - \\frac{h}{2} J_f(t_{n+1}, \\mathbf{w})$，其中 $I$ 是单位矩阵，$J_f$ 是 ODE 矢量场 $\\mathbf{f}$ 的雅可比矩阵。对于我们的系统，$J_f$ 的分量是：\n$$\nJ_f(x, y) = \\begin{pmatrix} \\frac{\\partial f_x}{\\partial x}  \\frac{\\partial f_x}{\\partial y} \\\\ \\frac{\\partial f_y}{\\partial x}  \\frac{\\partial f_y}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} r\\left(1-\\frac{2x}{K}\\right) - \\frac{cy}{(1+\\alpha x)^2}  -\\frac{cx}{1+\\alpha x} \\\\ \\frac{\\varepsilon\\eta cy}{(1+\\alpha x)^2}  \\varepsilon\\left(\\frac{\\eta cx}{1+\\alpha x} - m\\right) \\end{pmatrix}\n$$\n牛顿迭代涉及求解线性系统 $J_G(\\mathbf{w}^{(k)}) \\Delta\\mathbf{w}^{(k)} = -\\mathbf{G}(\\mathbf{w}^{(k)})$ 以获得更新量 $\\Delta\\mathbf{w}^{(k)}$，然后设置 $\\mathbf{w}^{(k+1)} = \\mathbf{w}^{(k)} + \\Delta\\mathbf{w}^{(k)}$。当残差 $\\mathbf{G}(\\mathbf{w}^{(k)})$ 的范数低于 $10^{-12}$ 的容差时，我们停止迭代。\n\n**研究的算法设计**\n\n对于每个参数集 $(\\mathsf{A}, \\mathsf{B}, \\mathsf{C})$，执行以下过程：\n1.  **参考解**：使用一个鲁棒的刚性求解器（`SciPy` 中的 `Radau`）和非常严格的容差（`atol=10^{-13}`，`rtol=10^{-13}`），计算在 $t=T=2$ 时的高精度参考解 $\\mathbf{u}_{\\text{ref}}$。\n2.  **步长减半循环**：对步数 $N_k \\in \\{20, 40, 80, 160, 320\\}$（对应于步长 $h_k = T/N_k$）运行一个循环。\n3.  **方法评估**：对于每个 $h_k$：\n    *   使用显式中点法对 IVP 从 $t=0$ 积分到 $t=T$。记录最终状态 $\\mathbf{u}_{\\text{EM}}(T)$。我们检查结果是否是有限的。存储全局误差的 $L_2$ 范数 $\\|\\mathbf{u}_{\\text{EM}}(T) - \\mathbf{u}_{\\text{ref}}\\|_2$。\n    *   类似地使用隐式梯形法。存储最终状态 $\\mathbf{u}_{\\text{IT}}(T)$ 及其全局误差范数 $\\|\\mathbf{u}_{\\text{IT}}(T) - \\mathbf{u}_{\\text{ref}}\\|_2$。\n4.  **分析与分类**：\n    *   **显式方法稳定性**：我们检查显式方法是否在 5 个步长中为 $\\mathbf{u}_{\\text{EM}}(T)$ 产生了任何非有限（例如 `inf` 或 `NaN`）的结果。如果是，则将标志 `explicit_is_unstable` 设置为真。\n    *   **隐式方法收敛性**：我们分析来自隐式方法的误差。我们找到误差列表（对应于最小的步长）中严格递减的最长后缀。如果该后缀包含至少 3 个点，我们对这些点的 $\\log(\\text{误差})$ 与 $\\log(h)$ 进行线性回归。该拟合的斜率即为估计的 EOC。如果 EOC 至少为 $1.7$，则将标志 `implicit_realizes_order` 设置为真。\n    *   **最终裁定**：对于给定的参数集，如果 `implicit_realizes_order` 为真且 `explicit_is_unstable` 为真，则结果为 $1$。否则，结果为 $0$。\n\n这个过程有效地对比了这两种方法。在非刚性情况下，两种方法都应该收敛，且 EOC 接近 $2$。在刚性情况下，由于稳定性约束，显式方法在较大步长下会失败，而 A-稳定的隐式方法将保持稳定并展示其理论收敛阶，从而满足结果为 $1$ 的条件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.linalg import solve as solve_linear_system\n\ndef solve():\n    \"\"\"\n    Performs a step-halving convergence study on a predator-prey system to \n    detect stiffness based on the performance of explicit and implicit solvers.\n    \"\"\"\n\n    # --- Problem Definition ---\n    # Initial Value Problem (IVP) settings\n    T_FINAL = 2.0\n    U0 = np.array([0.5, 0.3])\n\n    # Step-halving study parameters\n    N_STEPS_LIST = [20, 40, 80, 160, 320]\n    H_LIST = [T_FINAL / n for n in N_STEPS_LIST]\n\n    # Newton's method parameters for the implicit solver\n    NEWTON_TOL = 1e-12\n    NEWTON_MAX_ITER = 20\n\n    # Test cases: (r, K, alpha, c, eta, m, epsilon)\n    test_cases = [\n        # Case A: Non-stiff baseline\n        (2.0, 1.0, 2.0, 3.0, 0.7, 0.4, 1.0),\n        # Case B: Moderately stiff\n        (50.0, 1.0, 2.0, 4.0, 0.7, 0.4, 0.1),\n        # Case C: Highly stiff\n        (150.0, 1.0, 2.0, 4.0, 0.7, 0.4, 0.05),\n    ]\n\n    # --- ODE System Definition ---\n    def f_ode(t, u, params):\n        r, K, alpha, c, eta, m, epsilon = params\n        x, y = u\n        \n        # Avoid potential division by zero or negative populations, though unlikely with the chosen IC\n        if x  0: x = 0\n        if y  0: y = 0\n            \n        common_term = (c * x * y) / (1.0 + alpha * x)\n        \n        dxdt = r * x * (1.0 - x / K) - common_term\n        dydt = epsilon * (eta * common_term - m * y)\n        \n        return np.array([dxdt, dydt])\n\n    def jacobian_f(t, u, params):\n        r, K, alpha, c, eta, m, epsilon = params\n        x, y = u\n        \n        # Avoid negative populations in Jacobian calculation\n        if x  0: x = 0\n        if y  0: y = 0\n\n        denom = 1.0 + alpha * x\n        denom_sq = denom * denom\n\n        df1_dx = r * (1.0 - 2.0 * x / K) - (c * y) / denom_sq\n        df1_dy = - (c * x) / denom\n        df2_dx = epsilon * eta * (c * y) / denom_sq\n        df2_dy = epsilon * (eta * (c * x) / denom - m)\n        \n        return np.array([[df1_dx, df1_dy], [df2_dx, df2_dy]])\n\n    # --- Numerical Methods ---\n    def explicit_midpoint_solver(f, u0, t_final, n_steps, params):\n        h = t_final / n_steps\n        u = u0.copy()\n        t = 0.0\n        for _ in range(n_steps):\n            k1 = f(t, u, params)\n            k2 = f(t + h / 2.0, u + h / 2.0 * k1, params)\n            u += h * k2\n            t += h\n            if not np.all(np.isfinite(u)):\n                return u # Propagate non-finite value immediately\n        return u\n\n    def implicit_trapezoidal_solver(f, jac, u0, t_final, n_steps, params):\n        h = t_final / n_steps\n        u_n = u0.copy()\n        t_n = 0.0\n        I = np.identity(len(u0))\n\n        for _ in range(n_steps):\n            f_n = f(t_n, u_n, params)\n            t_np1 = t_n + h\n            \n            # Newton's method to solve for u_{n+1}\n            w = u_n.copy() # Initial guess for u_{n+1}\n            for _ in range(NEWTON_MAX_ITER):\n                f_np1 = f(t_np1, w, params)\n                G = w - u_n - (h / 2.0) * (f_n + f_np1)\n                \n                if np.linalg.norm(G)  NEWTON_TOL:\n                    break\n\n                J_G = I - (h / 2.0) * jac(t_np1, w, params)\n                delta_w = solve_linear_system(J_G, -G)\n                w += delta_w\n            \n            u_n = w\n            t_n = t_np1\n            \n            if not np.all(np.isfinite(u_n)):\n                return u_n\n\n        return u_n\n\n    results = []\n    for params in test_cases:\n        # 1. Compute high-accuracy reference solution\n        ref_sol = solve_ivp(\n            f_ode, [0, T_FINAL], U0, method='Radau', \n            args=(params,), atol=1e-13, rtol=1e-13\n        )\n        u_ref = ref_sol.y[:, -1]\n\n        em_errors = []\n        it_errors = []\n        em_unstable = False\n\n        # 2. Run step-halving study for both methods\n        for i, N in enumerate(N_STEPS_LIST):\n            h = H_LIST[i]\n\n            # Explicit Midpoint\n            u_em = explicit_midpoint_solver(f_ode, U0, T_FINAL, N, params)\n            if not np.all(np.isfinite(u_em)):\n                em_unstable = True\n                em_errors.append(np.inf)\n            else:\n                em_errors.append(np.linalg.norm(u_em - u_ref))\n\n            # Implicit Trapezoidal\n            u_it = implicit_trapezoidal_solver(f_ode, jacobian_f, U0, T_FINAL, N, params)\n            if not np.all(np.isfinite(u_it)):\n                 it_errors.append(np.inf)\n            else:\n                it_errors.append(np.linalg.norm(u_it - u_ref))\n        \n        # 3. Analyze results and classify\n        \n        # Check if implicit method realizes its formal order\n        it_realizes_order = False\n        \n        # Find the longest strictly decreasing suffix of errors\n        fit_indices = []\n        if len(it_errors) > 0:\n            fit_indices.append(len(it_errors) - 1)\n            for i in range(len(it_errors) - 2, -1, -1):\n                if it_errors[i+1]  it_errors[i] and it_errors[i+1] > 0:\n                    fit_indices.insert(0, i)\n                else:\n                    break\n        \n        if len(fit_indices) >= 3:\n            h_fit = np.log([H_LIST[i] for i in fit_indices])\n            err_fit = np.log([it_errors[i] for i in fit_indices])\n            \n            # Use polyfit to find the slope (Experimental Order of Convergence)\n            eoc = np.polyfit(h_fit, err_fit, 1)[0]\n            \n            if eoc >= 1.7:\n                it_realizes_order = True\n        \n        # Final classification\n        if it_realizes_order and em_unstable:\n            results.append(1)\n        else:\n            results.append(0)\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们通常假设一个常微分方程初值问题有唯一的解，并在此基础上讨论数值方法的收敛性。但如果解不唯一呢？本练习  探讨了一个经典的非唯一解问题 $y'=\\sqrt{|y|}$，你将观察到不同的数值方法，甚至微小的初始扰动，如何引导数值解“选择”并收敛到不同的真实解分支，从而深化对收敛性背后深刻数学原理的理解。",
            "id": "3111982",
            "problem": "考虑由常微分方程 (ODE) $y'(t) = \\sqrt{|y(t)|}$ 和初始条件 $y(0) = 0$ 给出的自治初值问题 (IVP)。在常微分方程的经典存在唯一性理论中，如果方程右端函数关于因变量在初始条件附近是局部利普希茨连续的，则解的唯一性得到保证。此处，函数 $f(y) = \\sqrt{|y|}$ 是连续的，但在 $y = 0$ 附近不满足局部利普希茨条件。因此，该初值问题存在多个解，并且在步长细化的极限情况下，常见的数值方法可能会选择不同的解轨迹。这引发了在解不唯一的情况下，关于相容性、稳定性和收敛性的问题。\n\n您的任务是编写一个完整的、可运行的程序，该程序针对指定的测试套件，在时间范围 $T = 1$ 上使用均匀时间步长对该 IVP 进行数值积分，并报告每种情况下的终点值 $y(T)$。您必须从第一性原理出发实现以下数值方法：\n\n- 前向（显式）欧拉法：对于均匀步长 $h$，更新公式为 $y_{n+1} = y_n + h\\,\\sqrt{|y_n|}$。\n- 后向（隐式）欧拉法：对于均匀步长 $h$，通过求解隐式方程 $y_{n+1} = y_n + h\\,\\sqrt{|y_{n+1}|}$ 来更新 $y_{n+1}$。在每一步中，强制 $y_{n+1} \\ge 0$。当 $y_n  0$ 时，选择唯一的非负解。当 $y_n = 0$ 时，存在两个非负解；在这种特殊情况下，您的程序必须支持选择 $y_{n+1} = 0$（零分支）或 $y_{n+1} = h^2$（非零分支），然后在此后的计算中继续使用唯一的非负解。\n- 经典四阶显式龙格－库塔法 (RK4)：对于均匀步长 $h$，使用标准的四阶段公式进行更新，其中右端函数为 $f(y) = \\sqrt{|y|}$，并确保在整个过程中保持 $y_n \\ge 0$。\n\n基本推理依据：\n- 常微分方程的初值问题定义：给定 $y'(t) = f(y(t))$ 和 $y(0) = y_0$，若 $f$ 连续，则在 $t = 0$ 的一个邻域内至少存在一个解。\n- 某点附近的局部利普希茨连续性保证了解的唯一性，并且是相容、稳定的数值方法的标准收敛定理的基础。\n- 数值相容性意味着当 $h \\to 0$ 时，局部截断误差趋于 $0$。\n- 数值稳定性意味着扰动（包括由离散化选择或舍入引入的扰动）在该方法下不会不受控制地增长。\n- 数值收敛性意味着当 $h \\to 0$ 时，数值解逼近该初值问题的某个真实解。\n\n实现细节：\n- 在代码中始终使用右端函数 $f(y) = \\sqrt{|y|}$。\n- 使用 $y_0 = \\varepsilon$，其中 $\\varepsilon$ 是一个指定的初始扰动；这允许研究在 $y=0$ 附近的灵敏度。\n- 使用均匀步长 $h$，使得 $N = T/h$ 是一个整数。程序必须积分 $N$ 步以达到 $t = T$。\n- 在求解后向欧拉法的隐式方程时，将其简化为关于 $s = \\sqrt{y_{n+1}}$ 的标量二次方程，并如上所述选择合适的非负根。当 $y_n = 0$ 时，程序必须在第一步支持两种初始分支，然后在之后继续使用唯一的非负根。\n\n测试套件：\n计算并报告以下六种情况的 $y(T)$。在所有情况中，均取 $T = 1$：\n1. 前向欧拉法，其中 $h = 0.1$, $\\varepsilon = 0$，无特殊分支选择。\n2. 前向欧拉法，其中 $h = 0.1$, $\\varepsilon = 10^{-12}$，无特殊分支选择。\n3. 后向欧拉法（第一步选择非零分支），其中 $h = 0.1$, $\\varepsilon = 0$。\n4. 后向欧拉法（第一步选择零分支），其中 $h = 0.1$, $\\varepsilon = 0$。\n5. 龙格－库塔4法 (RK4)，其中 $h = 0.02$, $\\varepsilon = 0$。\n6. 龙格－库塔4法 (RK4)，其中 $h = 0.02$, $\\varepsilon = 10^{-12}$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个条目必须是对应测试用例的终点值 $y(T)$，并严格按照上面列出的顺序排列，表示为浮点数。例如，输出必须类似于 $[r_1,r_2,r_3,r_4,r_5,r_6]$，其中每个 $r_i$ 是一个浮点数。",
            "solution": "该问题是有效的。它提出了一个明确定义的计算任务，以探索标准数值方法对于一个已知表现出非唯一解的初值问题 (IVP) 的行为。该 IVP 为 $y'(t) = \\sqrt{|y(t)|}$，其中 $y(0)=0$。函数 $f(y) = \\sqrt{|y|}$ 在 $y=0$ 处是连续的，但不是局部利普希茨连续的，这是非唯一性的理论原因。问题指定了数值方法（前向欧拉法、后向欧拉法、RK4），提供了所有必要的参数（时间范围 $T$、步长 $h$、初始扰动 $\\varepsilon$），并给出了清晰的实现说明，包括如何解决隐式后向欧拉法中的歧义。从计算的角度来看，该任务是科学合理的、客观的并且是适定的。\n\n从 $y(0)=0$ 出发的该 IVP 的解析解是已知的。一个解是平凡解，$y_A(t) = 0$ (对所有 $t \\ge 0$）。另一个是抛物线解，$y_B(t) = t^2/4$ (对所有 $t \\ge 0$）。对于任何常数 $c \\ge 0$，形如 $y(t) = 0$ (当 $0 \\le t  c$) 且 $y(t) = (t-c)^2/4$ (当 $t \\ge c$) 的任何解也是一个有效的解。该问题研究的是，在不同条件下，数值方法会收敛到这些解中的哪一个（如果收敛的话）。\n\n我们将实现指定的三种方法，以求得 $T=1$ 时 $y(T)$ 的数值近似解。\n\n**1. 前向（显式）欧拉法**\n更新规则由 $y_{n+1} = y_n + h f(y_n)$ 给出。对于本问题，$f(y) = \\sqrt{|y|}$，因此公式为：\n$$y_{n+1} = y_n + h \\sqrt{|y_n|}$$\n从 $y_0 = \\varepsilon \\ge 0$ 开始，所有后续值 $y_n$ 都将是非负的，因此 $|y_n| = y_n$。\n如果初始条件是 $y_0 = 0$，那么 $y_1 = 0 + h\\sqrt{0} = 0$。通过归纳法，对所有 $n$ 都有 $y_n = 0$。该方法将保持在平凡解分支上。\n如果初始条件被扰动为 $y_0 = \\varepsilon  0$，解将立即变为非零，并开始逼近抛物线解 $y_B(t) = t^2/4$。\n\n**2. 后向（隐式）欧拉法**\n更新规则由隐式方程 $y_{n+1} = y_n + h f(y_{n+1})$ 给出，对于本问题，该方程为：\n$$y_{n+1} = y_n + h \\sqrt{|y_{n+1}|}$$\n假设 $y_n \\ge 0$ 并寻求一个解 $y_{n+1} \\ge 0$，我们可以去掉绝对值。令 $s = \\sqrt{y_{n+1}}$，其中 $s \\ge 0$。方程变为 $s^2 = y_n + hs$，可以重新整理为关于 $s$ 的标准二次方程：\n$$s^2 - hs - y_n = 0$$\n$s$ 的解由二次公式给出：\n$$s = \\frac{h \\pm \\sqrt{(-h)^2 - 4(1)(-y_n)}}{2} = \\frac{h \\pm \\sqrt{h^2 + 4y_n}}{2}$$\n由于我们要求 $s = \\sqrt{y_{n+1}} \\ge 0$，我们必须选择正根：\n$$s = \\frac{h + \\sqrt{h^2 + 4y_n}}{2}$$\n因此，$y_{n+1}$ 的通用更新规则是：\n$$y_{n+1} = s^2 = \\left( \\frac{h + \\sqrt{h^2 + 4y_n}}{2} \\right)^2$$\n只要 $y_n  0$，这个公式就给出 $y_{n+1}$ 的唯一非负解。\n\n当 $y_n = 0$ 时会出现一个特殊情况。关于 $s$ 的二次方程变为 $s^2 - hs = 0$，即 $s(s-h) = 0$。这会产生两个非负解：$s=0$ 和 $s=h$。它们分别对应于 $y_{n+1}=0$（“零分支”）和 $y_{n+1}=h^2$（“非零分支”）。\n\n问题根据测试用例指定了如何处理这种歧义：\n- 对于 $\\varepsilon = 0$ 的测试用例，$y_0 = 0$。在第一步（$n=0$）中明确选择零分支或非零分支。\n- 对于所有后续步骤（$n  0$），如果 $y_n$ 变为 $0$，问题指示“在此后的计算中继续使用唯一的非负解”。这被解释为使用通用公式，当 $y_n=0$ 时，该公式得出 $y_{n+1} = (\\frac{h+h}{2})^2 = h^2$。这构成了第一步之后默认选择非零分支。\n\n**3. 经典四阶龙格－库塔 (RK4) 法**\n更新规则由标准的四阶段公式给出：\n$$y_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)$$\n其中各个阶段计算如下：\n$$k_1 = f(y_n) = \\sqrt{|y_n|}$$\n$$k_2 = f(y_n + \\frac{h}{2}k_1) = \\sqrt{|y_n + \\frac{h}{2}k_1|}$$\n$$k_3 = f(y_n + \\frac{h}{2}k_2) = \\sqrt{|y_n + \\frac{h}{2}k_2|}$$\n$$k_4 = f(y_n + h k_3) = \\sqrt{|y_n + h k_3|}$$\n与前向欧拉法类似，如果 $y_0 = 0$，那么所有阶段 $k_1, k_2, k_3, k_4$ 都将为 $0$。因此，$y_1=0$，并且通过归纳法，对所有 $n$ 都有 $y_n = 0$。该方法保持在平凡解上。\n如果 $y_0 = \\varepsilon  0$，该方法将立即产生一条非零轨迹，该轨迹逼近抛物线解 $y_B(t) = t^2/4$。由于其阶数更高，RK4 的近似解预期会比一阶方法的近似解更精确。\n\n现在将构建程序来对六个指定的测试用例执行这三种方法。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Numerically integrates the IVP y'(t) = sqrt(|y(t)|) with y(0) = eps\n    over T=1 for a suite of test cases and reports the terminal value y(T).\n    \"\"\"\n\n    test_cases = [\n        {'method': 'forward_euler', 'h': 0.1, 'epsilon': 0.0, 'branch': None},\n        {'method': 'forward_euler', 'h': 0.1, 'epsilon': 1e-12, 'branch': None},\n        {'method': 'backward_euler', 'h': 0.1, 'epsilon': 0.0, 'branch': 'nonzero'},\n        {'method': 'backward_euler', 'h': 0.1, 'epsilon': 0.0, 'branch': 'zero'},\n        {'method': 'rk4', 'h': 0.02, 'epsilon': 0.0, 'branch': None},\n        {'method': 'rk4', 'h': 0.02, 'epsilon': 1e-12, 'branch': None},\n    ]\n\n    T = 1.0\n    results = []\n\n    def ode_rhs(y):\n        return np.sqrt(np.abs(y))\n\n    for case in test_cases:\n        h = case['h']\n        eps = case['epsilon']\n        method = case['method']\n        branch = case['branch']\n\n        # Number of steps\n        N = int(round(T / h))\n        if not np.isclose(T, N * h):\n            raise ValueError(\"T must be an integer multiple of h.\")\n\n        y = eps\n\n        if method == 'forward_euler':\n            for _ in range(N):\n                y = y + h * ode_rhs(y)\n            results.append(y)\n\n        elif method == 'backward_euler':\n            # Handle the first step where y0=eps might be 0\n            if np.isclose(y, 0.0):\n                if branch == 'zero':\n                    y = 0.0\n                elif branch == 'nonzero':\n                    y = h**2\n                else: # This case occurs if eps  0\n                    s = (h + np.sqrt(h**2 + 4 * y)) / 2.0\n                    y = s**2\n            else:\n                s = (h + np.sqrt(h**2 + 4 * y)) / 2.0\n                y = s**2\n\n            # Handle remaining N-1 steps\n            for _ in range(1, N):\n                if np.isclose(y, 0.0):\n                    # As per problem interpretation, if y_n=0 for n0,\n                    # the general formula picks the nonzero branch.\n                    y = h**2\n                else:\n                    # General update for y  0\n                    s = (h + np.sqrt(h**2 + 4 * y)) / 2.0\n                    y = s**2\n            results.append(y)\n            \n        elif method == 'rk4':\n            for _ in range(N):\n                k1 = ode_rhs(y)\n                k2 = ode_rhs(y + 0.5 * h * k1)\n                k3 = ode_rhs(y + 0.5 * h * k2)\n                k4 = ode_rhs(y + h * k3)\n                y = y + (h / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n            results.append(y)\n\n    # Format the final output as a comma-separated list in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}