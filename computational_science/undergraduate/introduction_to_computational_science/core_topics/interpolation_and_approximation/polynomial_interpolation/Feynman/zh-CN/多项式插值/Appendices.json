{
    "hands_on_practices": [
        {
            "introduction": "线性插值是多项式插值最简单的形式，本质上是在两个已知数据点之间画一条直线。这个基础工具在许多领域都有广泛应用，例如填补数据序列中的空白或进行简单的估计。本练习将通过一个实际的环境监测场景，让你亲手实践如何利用线性插值来估计缺失的数据点。",
            "id": "2218418",
            "problem": "一个环境监测站正在追踪某个下午特定大气污染物的浓度。该监测站定期记录数据，但一次传感器故障导致了短暂的数据丢失。故障前最后一次可靠的测量是在中午过后的 $t_0 = 2.00$ 小时，测得污染物浓度为 $C_0 = 87.2$ ppb（十亿分之几）。传感器恢复后首次可靠的测量是在中午过后的 $t_1 = 5.00$ 小时，测得浓度为 $C_1 = 61.4$ ppb。\n\n为了近似缺失的数据，一位分析师决定使用两个已知数据点之间的线性插值来对浓度进行建模。使用此方法，估计在中午过后 $t = 3.50$ 小时时的污染物浓度。\n\n你的答案应以ppb（十亿分之几）为单位，并四舍五入到三位有效数字。",
            "solution": "我们使用线性插值对两个已知数据点之间的浓度进行建模。对于在时间 $t$ 测量的量 $C$，在 $(t_{0}, C_{0})$ 和 $(t_{1}, C_{1})$ 之间的线性插值公式为\n$$\nC(t)=C_{0}+\\frac{C_{1}-C_{0}}{t_{1}-t_{0}}\\left(t-t_{0}\\right).\n$$\n代入给定值 $t_{0}=2.00$，$C_{0}=87.2$，$t_{1}=5.00$，$C_{1}=61.4$ 和 $t=3.50$，我们计算斜率\n$$\n\\frac{C_{1}-C_{0}}{t_{1}-t_{0}}=\\frac{61.4-87.2}{5.00-2.00}=\\frac{-25.8}{3.00}=-8.6,\n$$\n和时间差\n$$\nt-t_{0}=3.50-2.00=1.50.\n$$\n因此，\n$$\nC(3.50)=87.2+(-8.6)\\times 1.50=87.2-12.9=74.3.\n$$\n四舍五入到三位有效数字，估计值为 $74.3$。",
            "answer": "$$\\boxed{74.3}$$"
        },
        {
            "introduction": "当我们拥有两个以上的数据点时，可以使用更高阶的多项式来构建更精细的模型。二次插值使用一个二次多项式（抛物线）来穿过三个点，能够捕捉数据中的曲率。此练习将指导你确定一个描述材料偏转的二次多项式，并展示如何利用问题的物理约束（例如顶点信息）来简化求解过程。",
            "id": "2181788",
            "problem": "一位材料科学家正在研究一种新开发的合金在热应力下的行为。测量了该合金薄梁沿其长度在位置 $x$ 处的挠度 $y(x)$。在特定范围内的实验观察表明，挠度分布可以由形如 $y(x) = ax^2 + bx + c$ 的二次多项式精确建模。记录了三个精确的测量值：\n\n- 在位置 $x_1 = -1$ 处，挠度为 $y_1 = 8$。\n- 在位置 $x_2 = 2$ 处，挠度为 $y_2 = -1$。\n- 在位置 $x_3 = 5$ 处，挠度为 $y_3 = 8$。\n\n此外，根据该特定装置的梁力学原理可知，这三个测量点之一对应于最大挠度点（或最小挠度点，取决于 $a$ 的符号）。该点是抛物线的顶点。\n\n确定描述该挠度分布的二次多项式 $y(x)$。请以标准形式 $y(x) = ax^2 + bx + c$ 表达您的答案。",
            "solution": "我们用二次函数 $y(x)=ax^{2}+bx+c$ 来为挠度建模。抛物线可以写成顶点式 $y(x)=a(x-h)^{2}+k$，其中 $(h,k)$ 是顶点，对称轴是 $x=h$。与 $h$ 等距的点的 $y$ 值相等。\n\n根据数据，$y(-1)=8$ 且 $y(5)=8$。$-1$ 和 $5$ 的中点是 $h=\\frac{-1+5}{2}=2$，因此对称轴是 $x=2$。已知其中一个测量点是顶点；由于 $y(2)=-1$，并且这个值相对于另外两个值是极值，因此顶点是 $(h,k)=(2,-1)$。\n\n因此，该二次函数的形式为\n$$\ny(x)=a(x-2)^{2}-1.\n$$\n使用点 $(-1,8)$ 来求 $a$：\n$$\n8=a(-1-2)^{2}-1=a\\cdot 9-1 \\implies 9a=9 \\implies a=1.\n$$\n因此，\n$$\ny(x)=(x-2)^{2}-1=x^{2}-4x+4-1=x^{2}-4x+3.\n$$\n用 $x=5$ 进行检验，得到 $25-20+3=8$，与数据一致。所以该二次函数是 $y(x)=x^{2}-4x+3$。",
            "answer": "$$\\boxed{x^{2}-4x+3}$$"
        },
        {
            "introduction": "虽然高阶多项式插值功能强大，但在均匀分布的节点上使用时可能会遇到不准确甚至振荡的问题（即龙格现象）。解决此问题的一个关键策略是优化插值节点的位置。这项高级计算练习要求你通过编程来探究非均匀节点（在此案例中，节点在区间的一端更密集）如何显著提高特定函数的插值精度，从而将理论误差公式与实际的数值实现联系起来。",
            "id": "3174893",
            "problem": "考虑定义在 $x \\in [0,1]$ 上的函数 $f(x) = \\log(1+x)$，其中 $\\log$ 表示自然对数。任务是研究 $f(x)$ 的多项式插值精度如何依赖于插值节点的位置，特别是当节点在 $x=0$ 附近聚集与当节点在 $[0,1]$ 上均匀分布时的对比。您的研究必须基于多项式插值的核心定义和源于微积分的标准误差特征，不得使用任何快捷公式或预先指定的计算表达式。\n\n您必须实现一个程序，对于给定的不同节点 $x_0, x_1, \\dots, x_N$ 和值 $f(x_i)$，构造一个次数最多为 $N$ 的唯一多项式 $p_N(x)$，该多项式在这些节点上对 $f$ 进行插值，即对所有 $i \\in \\{0,1,\\dots,N\\}$ 满足 $p_N(x_i) = f(x_i)$。为了进行数值评估，您必须使用一种源于插值基本定义的稳定方法，在指定区间的一组网格点上计算 $p_N(x)$，然后将 $p_N(x)$ 与 $f(x)$ 进行比较。\n\n为给定的整数 $N \\geq 1$ 定义两族节点：\n- $[0,1]$ 上的均匀节点：$x_i^{\\mathrm{uni}} = \\frac{i}{N}$，对于 $i \\in \\{0,1,\\dots,N\\}$。\n- $[0,1]$ 上的聚集节点：$x_i^{\\mathrm{clu}} = \\left(\\frac{i}{N}\\right)^p$，对于 $i \\in \\{0,1,\\dots,N\\}$，其中 $p$ 是一个大于 $1$ 的固定整数指数。在本问题中，使用 $p=3$。\n\n对于下方的每个测试用例，为指定的 $N$ 构建两个插值多项式 $p_N^{\\mathrm{uni}}(x)$ 和 $p_N^{\\mathrm{clu}}(x)$，在给定区间 $[a,b]$ 上包含 $M=1001$ 个点的均匀网格上对它们进行求值，并计算该区间内每个节点族的最大绝对误差，\n$$\nE^{\\mathrm{uni}} = \\max_{x \\in [a,b]} \\left| f(x) - p_N^{\\mathrm{uni}}(x) \\right|, \\quad\nE^{\\mathrm{clu}} = \\max_{x \\in [a,b]} \\left| f(x) - p_N^{\\mathrm{clu}}(x) \\right|,\n$$\n并以浮点数形式报告比率 $R = \\frac{E^{\\mathrm{uni}}}{E^{\\mathrm{clu}}}$。比率 $R$ 量化了在 $x=0$ 附近聚集节点所带来的精度提升：$R > 1$ 的值表示在给定区间上，聚集节点的最大误差严格更小。\n\n测试套件（每个元组列出 $(N, p, a, b)$）：\n- 用例 1：$(4, 3, 0, 0.3)$：中等次数，靠近 $x=0$ 的局部区间。\n- 用例 2：$(4, 3, 0, 1)$：中等次数，完整区间。\n- 用例 3：$(8, 3, 0, 0.3)$：较高次数，靠近 $x=0$ 的局部区间。\n- 用例 4：$(8, 3, 0, 1)$：较高次数，完整区间。\n- 用例 5：$(1, 3, 0, 0.3)$：最低次数（线性），靠近 $x=0$ 的局部区间。\n\n您的程序必须生成单行输出，其中包含上述用例的比率，格式为方括号内以逗号分隔的列表，并按给定用例的顺序排列。例如，输出格式必须为\n$[R_1,R_2,R_3,R_4,R_5]$,\n其中每个 $R_k$ 是按规定计算的浮点数。本问题不涉及任何物理单位或角度单位；所有量均为无量纲实数。",
            "solution": "所述问题是数值分析中一个明确定义的练习，具体涉及多项式插值这一主题。它在科学上是合理的、自洽的且客观的。所有提供的数据和条件都是一致且充分的，足以得出一个唯一的、可计算的解。该问题要求进行一项基于基本原理的研究，这是一种标准的教学方法。因此，该问题被认为是有效的。\n\n核心任务是使用两种不同的插值节点分布——均匀节点和在 $x=0$ 附近聚集的节点——来比较函数 $f(x) = \\log(1+x)$ 在区间 $[0,1]$ 上的插值精度。该比较通过指定子区间上的最大绝对误差之比来量化。\n\n对于任意一组 $N+1$ 个不同的节点 $\\{x_0, x_1, \\dots, x_N\\}$ 和对应的函数值 $\\{y_0, y_1, \\dots, y_N\\}$（其中 $y_i = f(x_i)$），存在一个次数最多为 $N$ 的唯一插值多项式 $p_N(x)$。该多项式对所有 $i \\in \\{0, 1, \\dots, N\\}$ 满足 $p_N(x_i) = y_i$。\n\n该多项式的一个基本表示是拉格朗日形式：\n$$\np_N(x) = \\sum_{j=0}^{N} y_j L_j(x)\n$$\n其中 $L_j(x)$ 是拉格朗日基多项式，定义为：\n$$\nL_j(x) = \\prod_{k=0, k \\neq j}^{N} \\frac{x - x_k}{x_j - x_k}\n$$\n虽然这个公式是基础性的，但对多个点 $x$ 直接求值计算成本很高（每次求值的时间复杂度为 $O(N^2)$），并且可能存在数值不稳定的问题。一种更稳健的求值方法由拉格朗日形式推导而来，称为重心插值公式。\n\n首先，我们定义节点多项式 $\\ell(x) = \\prod_{k=0}^{N} (x-x_k)$ 和重心权重 $w_j$：\n$$\nw_j = \\frac{1}{\\prod_{k=0, k \\neq j}^{N} (x_j - x_k)}\n$$\n拉格朗日基多项式可以用这些量重写为：\n$$\nL_j(x) = \\ell(x) \\frac{w_j}{x-x_j}\n$$\n将此代入拉格朗日公式，得到第一重心形式：\n$$\np_N(x) = \\ell(x) \\sum_{j=0}^{N} \\frac{w_j}{x - x_j} y_j\n$$\n为了进一步简化并提高稳定性，我们考虑对常数函数 $g(x)=1$ 进行插值。插值多项式必须是 $g(x)$ 本身，所以 $1 = \\sum_{j=0}^{N} L_j(x)$。代入 $L_j(x)$ 的重心表达式可得：\n$$\n1 = \\ell(x) \\sum_{j=0}^{N} \\frac{w_j}{x - x_j}\n$$\n将 $p_N(x)$ 的第一重心公式除以此恒等式（对所有不等于节点的 $x$ 均成立），我们得到第二（或“真”）重心形式：\n$$\np_N(x) = \\frac{\\sum_{j=0}^{N} \\frac{w_j}{x - x_j} y_j}{\\sum_{j=0}^{N} \\frac{w_j}{x - x_j}}\n$$\n这个公式是计算的理想选择。对于给定的节点集，权重 $w_j$ 只需计算一次（一个 $O(N^2)$ 的过程）。然后，在任意点 $x$ 处计算 $p_N(x)$ 仅需 $O(N)$ 次操作。如果求值点 $x$ 与某个节点 $x_k$ 重合，该公式在解析上是未定义的，但我们知道插值多项式的值为 $p_N(x_k)=y_k$。此方法源于核心原理，并且数值稳定。\n\n多项式插值的理论误差由以下公式给出：\n$$\nf(x) - p_N(x) = \\frac{f^{(N+1)}(\\xi_x)}{(N+1)!} \\prod_{i=0}^{N} (x-x_i)\n$$\n其中 $\\xi_x$ 位于包含所有节点和 $x$ 的最小区间内。对于函数 $f(x) = \\log(1+x)$，其导数为：\n$$\nf'(x) = (1+x)^{-1}, \\quad f''(x) = -(1+x)^{-2}, \\quad \\dots, \\quad f^{(k)}(x) = (-1)^{k-1} (k-1)! (1+x)^{-k}\n$$\n其 $(N+1)$ 阶导数为 $f^{(N+1)}(x) = (-1)^N N! (1+x)^{-(N+1)}$。该导数的绝对值 $|f^{(N+1)}(x)| = N!(1+x)^{-(N+1)}$ 在 $x=0$ 附近最大，并随 $x$ 增大而减小。为了最小化总误差，应使节点多项式项 $\\prod_{i=0}^{N} (x-x_i)$ 保持较小，尤其是在导数项较大的地方。与均匀节点 $x_i^{\\mathrm{uni}}=i/N$ 相比，聚集节点 $x_i^{\\mathrm{clu}} = (i/N)^p$（其中 $p=3$）在 $x=0$ 附近更密集。这种节点聚集的设计旨在减小 $x=0$ 附近的节点多项式的值，从而减少该区域的插值误差。\n\n每个测试用例 $(N, p, a, b)$ 的计算步骤如下：\n$1$. 定义函数 $f(x) = \\log(1+x)$。\n$2$. 在 $[0,1]$ 上生成两组各包含 $N+1$ 个插值节点的集合：\n    - 均匀节点：$x_i^{\\mathrm{uni}} = \\frac{i}{N}$，对于 $i \\in \\{0, \\dots, N\\}$。\n    - 聚集节点：$x_i^{\\mathrm{clu}} = \\left(\\frac{i}{N}\\right)^p$，对于 $i \\in \\{0, \\dots, N\\}$，其中 $p=3$。\n$3$. 对每组节点集，计算相应的函数值，例如 $y_i^{\\mathrm{uni}} = f(x_i^{\\mathrm{uni}})$。\n$4$. 对每组节点集，使用 $O(N^2)$ 的直接公式计算重心权重 $w_j$。\n$5$. 在区间 $[a,b]$ 上创建一个包含 $M=1001$ 个点的细密均匀求值网格 $z_k$。\n$6$. 对每组节点集，使用第二重心公式在求值网格的每个点 $z_k$ 上计算相应的插值多项式（$p_N^{\\mathrm{uni}}(x)$ 和 $p_N^{\\mathrm{clu}}(x)$）。\n$7$. 在每个点 $z_k$ 上计算真实函数 $f(x)$ 的值。\n$8$. 在网格上计算每种情况下的最大绝对误差：\n    $$\n    E^{\\mathrm{uni}} = \\max_{k} |f(z_k) - p_N^{\\mathrm{uni}}(z_k)|, \\quad E^{\\mathrm{clu}} = \\max_{k} |f(z_k) - p_N^{\\mathrm{clu}}(z_k)|\n    $$\n$9$. 计算并记录比率 $R = E^{\\mathrm{uni}} / E^{\\mathrm{clu}}$。\n对于 $N=1$ 的特殊情况，两种节点分布是相同的：$x_0^{\\mathrm{uni}} = x_0^{\\mathrm{clu}} = 0$ 和 $x_1^{\\mathrm{uni}} = x_1^{\\mathrm{clu}} = 1$。这意味着插值多项式是相同的，因此预期的比率 $R=1$。这可以作为一个有用的合理性检查。",
            "answer": "```python\nimport numpy as np\n\ndef get_barycentric_weights(nodes: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes barycentric weights for a given set of nodes.\n    w_j = 1 / product(x_j - x_k) for k != j.\n    \"\"\"\n    n_nodes = len(nodes)\n    weights = np.ones(n_nodes)\n    for j in range(n_nodes):\n        # The product can be calculated more stably in log space for large N,\n        # but for small N direct product is fine.\n        prod = 1.0\n        for k in range(n_nodes):\n            if k != j:\n                prod *= (nodes[j] - nodes[k])\n        weights[j] = 1.0 / prod\n    return weights\n\ndef evaluate_barycentric(nodes: np.ndarray, y_values: np.ndarray, weights: np.ndarray, eval_points: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Evaluates the interpolating polynomial at given points using the barycentric formula.\n    \"\"\"\n    poly_values = np.zeros_like(eval_points, dtype=np.float64)\n\n    for i, x in enumerate(eval_points):\n        # Check if evaluation point is one of the nodes to avoid division by zero\n        close_nodes_mask = np.isclose(x, nodes)\n        if np.any(close_nodes_mask):\n            node_idx = np.where(close_nodes_mask)[0][0]\n            poly_values[i] = y_values[node_idx]\n            continue\n        \n        # Barycentric formula (second form)\n        terms = weights / (x - nodes)\n        numerator = np.sum(terms * y_values)\n        denominator = np.sum(terms)\n        \n        # The denominator can be zero only if the polynomial degree is higher\n        # than N, which shouldn't happen for interpolation.\n        if denominator == 0:\n            # This case is unlikely but we handle it. Could happen with catastrophic cancellation.\n            # Find the closest node and return its value.\n            closest_node_idx = np.argmin(np.abs(x - nodes))\n            poly_values[i] = y_values[closest_node_idx]\n        else:\n            poly_values[i] = numerator / denominator\n            \n    return poly_values\n\ndef calculate_error_ratio(N: int, p: int, a: float, b: float, M: int = 1001) -> float:\n    \"\"\"\n    Calculates the ratio of max interpolation errors for uniform vs. clustered nodes.\n    \"\"\"\n    # The function to interpolate\n    func = np.log1p\n\n    # --- Uniform nodes ---\n    x_uni = np.linspace(0.0, 1.0, N + 1)\n    y_uni = func(x_uni)\n    w_uni = get_barycentric_weights(x_uni)\n\n    # --- Clustered nodes ---\n    # For N=1, (i/N)^p gives [0, 1], same as uniform.\n    if N > 0:\n        base_nodes = np.linspace(0.0, 1.0, N + 1)\n        x_clu = np.power(base_nodes, p)\n    else: # N=0, single node at 0\n        x_clu = np.array([0.0])\n    \n    y_clu = func(x_clu)\n    # If nodes are identical, ratio is 1.\n    if np.allclose(x_uni, x_clu):\n        return 1.0\n    w_clu = get_barycentric_weights(x_clu)\n\n    # --- Evaluation ---\n    eval_grid = np.linspace(a, b, M)\n    f_true = func(eval_grid)\n\n    # Evaluate uniform interpolant and its error\n    p_uni = evaluate_barycentric(x_uni, y_uni, w_uni, eval_grid)\n    error_uni = np.max(np.abs(f_true - p_uni))\n\n    # Evaluate clustered interpolant and its error\n    p_clu = evaluate_barycentric(x_clu, y_clu, w_clu, eval_grid)\n    error_clu = np.max(np.abs(f_true - p_clu))\n\n    # Avoid division by zero if clustered error is zero\n    if error_clu == 0.0:\n        # If uniform error is also zero, they are equally good (ratio 1).\n        # If uniform error is non-zero, clustered is infinitely better.\n        return 1.0 if error_uni == 0.0 else np.inf\n\n    return error_uni / error_clu\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # (N, p, a, b)\n        (4, 3, 0.0, 0.3),\n        (4, 3, 0.0, 1.0),\n        (8, 3, 0.0, 0.3),\n        (8, 3, 0.0, 1.0),\n        (1, 3, 0.0, 0.3),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, p, a, b = case\n        ratio = calculate_error_ratio(N, p, a, b)\n        results.append(ratio)\n\n    # Format the final output as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}