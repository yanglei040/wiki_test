{
    "hands_on_practices": [
        {
            "introduction": "我们将通过一个经典的蒙特卡洛问题——估计 $\\pi$ 值——来实践控制变量法。这个练习将引导你从第一性原理出发，为一个几何上相关且易于分析的控制变量，推导并计算出最优系数 $\\beta^{\\star}$。通过这个过程，你将亲身体会到，选择一个好的控制变量并精确计算其参数，能够如何显著地提升估计的效率和准确性。",
            "id": "3218869",
            "problem": "一种常见的估计常数 $\\pi$ 的蒙特卡洛方法是，从正方形 $[-1,1] \\times [-1,1]$ 中均匀采样 $N$ 个独立同分布 (i.i.d.) 的点，并利用落在以原点为中心的单位圆内的点的比例。令 $Y_i$ 为指示随机变量 $Y_i = \\mathbf{1}\\{(U_i,V_i) \\in \\{(x,y): x^2 + y^2 \\leq 1\\}\\}$，其中 $(U_i,V_i)$ 是第 $i$ 个样本，并定义估计量 $\\hat{\\pi} = 4 \\,\\bar{Y}_N$，其中 $\\bar{Y}_N = \\frac{1}{N} \\sum_{i=1}^{N} Y_i$。\n\n为使用控制变量法减小方差，我们引入指示随机变量 $X_i = \\mathbf{1}\\{(U_i,V_i) \\in P_{12}\\}$，其中 $P_{12}$ 是内接于同一单位圆的正十二边形。期望 $\\mathbb{E}[X_i]$ 是 $P_{12}$ 的面积除以正方形 $[-1,1] \\times [-1,1]$ 的面积。考虑调整后的估计量\n$$\n\\hat{\\pi}_{\\beta} = 4 \\left( \\bar{Y}_N - \\beta \\left( \\bar{X}_N - \\mathbb{E}[X_i] \\right) \\right),\n$$\n其中 $\\bar{X}_N = \\frac{1}{N} \\sum_{i=1}^{N} X_i$ 且 $\\beta \\in \\mathbb{R}$ 是一个待选系数。\n\n仅从期望、方差、协方差以及圆内接正多边形面积的基本定义出发，推导使 $\\hat{\\pi}_{\\beta}$ 方差最小化的最优控制变量系数 $\\beta^{\\star}$ 的表达式，然后计算其对于正十二边形 $P_{12}$ 的精确值。将最终答案表示为单个闭式解析表达式。无需进行数值四舍五入。",
            "solution": "目标是找到使估计量 $\\hat{\\pi}_{\\beta}$ 方差最小化的最优控制变量系数 $\\beta^{\\star}$。估计量由下式给出\n$$ \\hat{\\pi}_{\\beta} = 4 \\left( \\bar{Y}_N - \\beta \\left( \\bar{X}_N - \\mathbb{E}[X_i] \\right) \\right) $$\n其中 $\\bar{Y}_N = \\frac{1}{N} \\sum_{i=1}^{N} Y_i$ 且 $\\bar{X}_N = \\frac{1}{N} \\sum_{i=1}^{N} X_i$。对于 $i=1, \\dots, N$，随机变量 $(Y_i, X_i)$ 是独立同分布的。为简化起见，我们将一个通用配对表示为 $(Y, X)$。\n\n首先，我们推导最优系数 $\\beta^{\\star}$ 的一般表达式。我们从计算 $\\hat{\\pi}_{\\beta}$ 的方差开始。\n$$ \\text{Var}(\\hat{\\pi}_{\\beta}) = \\text{Var}\\left( 4 \\left( \\bar{Y}_N - \\beta \\bar{X}_N + \\beta \\mathbb{E}[X] \\right) \\right) $$\n项 $\\beta \\mathbb{E}[X]$ 是一个常数，不影响方差。因此，\n$$ \\text{Var}(\\hat{\\pi}_{\\beta}) = \\text{Var}(4(\\bar{Y}_N - \\beta \\bar{X}_N)) = 16 \\, \\text{Var}(\\bar{Y}_N - \\beta \\bar{X}_N) $$\n利用方差的性质，\n$$ \\text{Var}(\\bar{Y}_N - \\beta \\bar{X}_N) = \\text{Var}(\\bar{Y}_N) + \\beta^2 \\text{Var}(\\bar{X}_N) - 2\\beta \\text{Cov}(\\bar{Y}_N, \\bar{X}_N) $$\n由于样本是独立同分布的，样本均值的方差是单个观测值方差的 $\\frac{1}{N}$ 倍，样本均值的协方差也类似：\n$$ \\text{Var}(\\bar{Y}_N) = \\frac{1}{N} \\text{Var}(Y), \\quad \\text{Var}(\\bar{X}_N) = \\frac{1}{N} \\text{Var}(X), \\quad \\text{Cov}(\\bar{Y}_N, \\bar{X}_N) = \\frac{1}{N} \\text{Cov}(Y, X) $$\n将这些代入 $\\hat{\\pi}_{\\beta}$ 的方差表达式中：\n$$ \\text{Var}(\\hat{\\pi}_{\\beta}) = \\frac{16}{N} \\left( \\text{Var}(Y) + \\beta^2 \\text{Var}(X) - 2\\beta \\text{Cov}(Y, X) \\right) $$\n为了找到使该方差最小化的 $\\beta$ 值，我们对 $\\beta$ 求导并将结果设为零。\n$$ \\frac{d}{d\\beta} \\text{Var}(\\hat{\\pi}_{\\beta}) = \\frac{16}{N} \\left( 2\\beta \\text{Var}(X) - 2 \\text{Cov}(Y, X) \\right) $$\n将其设为零可得：\n$$ 2\\beta^{\\star} \\text{Var}(X) - 2 \\text{Cov}(Y, X) = 0 $$\n求解最优系数 $\\beta^{\\star}$，我们得到标准结果：\n$$ \\beta^{\\star} = \\frac{\\text{Cov}(Y, X)}{\\text{Var}(X)} $$\n现在，我们必须计算该特定问题的 $\\text{Cov}(Y, X)$ 和 $\\text{Var}(X)$。采样域是正方形 $S = [-1,1] \\times [-1,1]$，其面积为 $A_S = 2 \\times 2 = 4$。\n随机变量被定义为指示变量：\n$Y = \\mathbf{1}\\{C_1\\}$，其中 $C_1$ 是单位圆，即 $\\{(x,y) : x^2 + y^2 \\leq 1\\}$。\n$X = \\mathbf{1}\\{P_{12}\\}$，其中 $P_{12}$ 是内接于单位圆的正十二边形。\n\n对于对应于区域 $R$ 的指示变量 $Z = \\mathbf{1}\\{R\\}$，其期望是一个均匀采样的点落在 $R$ 内的概率，即 $\\mathbb{E}[Z] = \\frac{\\text{Area}(R)}{\\text{Area}(S)}$。\n\n单位圆的面积为 $A_C = \\pi (1)^2 = \\pi$。因此，\n$$ \\mathbb{E}[Y] = \\frac{A_C}{A_S} = \\frac{\\pi}{4} $$\n内接于半径为 $R$ 的圆的正 $n$ 边形的面积由公式 $A_n = \\frac{1}{2} n R^2 \\sin(\\frac{2\\pi}{n})$ 给出。对于正十二边形 $P_{12}$，我们有 $n=12$ 和 $R=1$：\n$$ A_{12} = \\frac{1}{2} (12) (1)^2 \\sin\\left(\\frac{2\\pi}{12}\\right) = 6 \\sin\\left(\\frac{\\pi}{6}\\right) = 6 \\cdot \\frac{1}{2} = 3 $$\n因此，$X$ 的期望为：\n$$ \\mathbb{E}[X] = \\frac{A_{12}}{A_S} = \\frac{3}{4} $$\n接下来，我们计算 $X$ 的方差。由于 $X$ 是一个指示变量（一个伯努利随机变量），其方差由 $\\text{Var}(X) = \\mathbb{E}[X](1-\\mathbb{E}[X])$ 给出。\n$$ \\text{Var}(X) = \\frac{3}{4} \\left(1 - \\frac{3}{4}\\right) = \\frac{3}{4} \\cdot \\frac{1}{4} = \\frac{3}{16} $$\n现在我们计算协方差，$\\text{Cov}(Y, X) = \\mathbb{E}[YX] - \\mathbb{E}[Y]\\mathbb{E}[X]$。\n指示变量的乘积是 $YX = \\mathbf{1}\\{C_1\\} \\cdot \\mathbf{1}\\{P_{12}\\} = \\mathbf{1}\\{C_1 \\cap P_{12}\\}$。\n由于正十二边形 $P_{12}$ 内接于单位圆 $C_1$，任何在 $P_{12}$ 内的点也在 $C_1$ 内。这意味着区域 $P_{12}$ 是区域 $C_1$ 的一个子集，即 $P_{12} \\subseteq C_1$。\n因此，它们的交集就是正十二边形本身：$C_1 \\cap P_{12} = P_{12}$。\n这意味着 $YX = \\mathbf{1}\\{P_{12}\\} = X$。\n所以，乘积的期望是：\n$$ \\mathbb{E}[YX] = \\mathbb{E}[X] = \\frac{3}{4} $$\n现在我们可以计算协方差：\n$$ \\text{Cov}(Y, X) = \\mathbb{E}[YX] - \\mathbb{E}[Y]\\mathbb{E}[X] = \\frac{3}{4} - \\left(\\frac{\\pi}{4}\\right)\\left(\\frac{3}{4}\\right) = \\frac{3}{4} - \\frac{3\\pi}{16} = \\frac{12 - 3\\pi}{16} = \\frac{3(4-\\pi)}{16} $$\n最后，我们将协方差和方差代入 $\\beta^{\\star}$ 的公式中：\n$$ \\beta^{\\star} = \\frac{\\text{Cov}(Y, X)}{\\text{Var}(X)} = \\frac{\\frac{3(4-\\pi)}{16}}{\\frac{3}{16}} $$\n分子和分母中的公因子 $\\frac{3}{16}$ 相消，剩下：\n$$ \\beta^{\\star} = 4 - \\pi $$\n这就是最优控制变量系数。",
            "answer": "$$\n\\boxed{4-\\pi}\n$$"
        },
        {
            "introduction": "这个思想实验旨在挑战一个普遍的直觉：控制变量法仅适用于线性相关的变量。我们将构建一个特殊情境，其中目标变量与一个辅助变量之间的线性相关性为零，但一个精心选择的*非线性*控制变量却能带来巨大的方差缩减。这个练习将深化你对变量间依赖关系的理解，并揭示了寻找有效控制变量时，洞察其背后函数关系的重要性。",
            "id": "3218904",
            "problem": "考虑一个蒙特卡洛估计问题，目标是均值 $\\mu = \\mathbb{E}[X]$，其中您可以获取两个随机变量 $X$ 和 $Y$ 的样本。您需要构造一个 $(X,Y)$ 的联合分布，使得皮尔逊相关系数 $\\rho(X,Y)$ 为零，但一个非线性控制变量 $Z = g(Y)$ 能够带来非常大的方差缩减。仅使用期望、方差、协方差的基本定义以及正态分布的性质。\n\n设 $Y \\sim \\mathcal{N}(0,1)$ 且 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，与 $Y$ 独立，其中 $\\sigma^{2} = 0.01$。定义\n$$\nX = (Y^{2} - 1) + \\varepsilon\n$$\n并考虑非线性控制变量\n$$\nZ = g(Y) = Y^{2} - 1,\n$$\n其均值 $\\mathbb{E}[Z]$ 可由 $Y$ 的分布得知。\n\n任务：\n- 使用协方差的核心定义以及标准正态分布的矩的性质，验证协方差 $\\operatorname{Cov}(X,Y)$ 等于 $0$，因此相关系数 $\\rho(X,Y)$ 等于 $0$。\n- 从方差和协方差的定义出发，不假设任何特定公式，推导使 $\\mu$ 的调整估计量 $X - \\beta(Z - \\mathbb{E}[Z])$ 的方差最小化的系数 $\\beta$ 的值。\n- 计算在最优 $\\beta$ 选择下，调整后估计量的单样本方差，以及方差缩减因子\n$$\nR = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big)}。\n$$\n\n以有序对 $(\\beta^{\\star}, R)$ 的精确形式提供您的最终答案。无需四舍五入。最终答案必须是按规定进行的计算。",
            "solution": "该问题要求完成与蒙特卡洛估计情景相关的三项任务。我们已知随机变量 $Y \\sim \\mathcal{N}(0,1)$ 和 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，其中 $\\sigma^{2} = 0.01$。随机变量 $Y$ 和 $\\varepsilon$ 是独立的。我们关注的变量是 $X = (Y^{2} - 1) + \\varepsilon$，控制变量是 $Z = g(Y) = Y^{2} - 1$。\n\n首先，我们确定标准正态变量 $Y$ 的必要矩。\n$Y$ 的概率密度函数关于 $0$ 对称。因此，$Y$ 的所有奇数阶矩均为零。\n$\\mathbb{E}[Y] = 0$\n$\\mathbb{E}[Y^3] = 0$\n偶数阶矩是众所周知的。由于均值为零，二阶矩即为方差：\n$\\mathbb{E}[Y^2] = \\operatorname{Var}(Y) = 1$\n标准正态分布的四阶矩为：\n$\\mathbb{E}[Y^4] = 3$\n\n有了这些，我们就可以确定 $X$ 和 $Z$ 的性质。\n$Z$ 的均值为：\n$\\mathbb{E}[Z] = \\mathbb{E}[Y^2 - 1] = \\mathbb{E}[Y^2] - 1 = 1 - 1 = 0$。\n$X$ 的均值，即待估计的量 $\\mu$，为：\n$\\mu = \\mathbb{E}[X] = \\mathbb{E}[(Y^2 - 1) + \\varepsilon] = \\mathbb{E}[Y^2 - 1] + \\mathbb{E}[\\varepsilon] = \\mathbb{E}[Z] + 0 = 0$。\n\n**任务1：验证 $\\operatorname{Cov}(X,Y) = 0$**\n\n协方差定义为 $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$。\n我们有 $\\mathbb{E}[Y] = 0$，所以第二项消失：\n$\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X] \\cdot 0 = \\mathbb{E}[XY]$。\n我们通过代入 $X$ 的定义来计算 $\\mathbb{E}[XY]$：\n$\\mathbb{E}[XY] = \\mathbb{E}[((Y^2 - 1) + \\varepsilon)Y] = \\mathbb{E}[Y^3 - Y + \\varepsilon Y]$。\n根据期望的线性性质：\n$\\mathbb{E}[XY] = \\mathbb{E}[Y^3] - \\mathbb{E}[Y] + \\mathbb{E}[\\varepsilon Y]$。\n如前所述，$\\mathbb{E}[Y^3] = 0$ 且 $\\mathbb{E}[Y] = 0$。对于最后一项，由于 $\\varepsilon$ 和 $Y$ 独立，$\\mathbb{E}[\\varepsilon Y] = \\mathbb{E}[\\varepsilon]\\mathbb{E}[Y]$。我们知道 $\\mathbb{E}[\\varepsilon]=0$ 和 $\\mathbb{E}[Y]=0$，所以 $\\mathbb{E}[\\varepsilon Y] = 0 \\cdot 0 = 0$。\n因此，$\\mathbb{E}[XY] = 0 - 0 + 0 = 0$。\n这证实了 $\\operatorname{Cov}(X,Y) = 0$。\n皮尔逊相关系数为 $\\rho(X,Y) = \\frac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}$。由于分子为 $0$ 且方差不为零（如下所示），$\\rho(X,Y) = 0$。\n\n**任务2：推导最优系数 $\\beta^{\\star}$**\n\n我们的任务是找到 $\\beta$ 的值，记为 $\\beta^{\\star}$，它能使调整后估计量 $X_{\\beta} = X - \\beta(Z - \\mathbb{E}[Z])$ 的方差最小化。设 $V(\\beta) = \\operatorname{Var}(X_{\\beta})$。\n由于 $\\mathbb{E}[Z] = 0$，该估计量为 $X_{\\beta} = X - \\beta Z$。\n需要最小化的方差是：\n$V(\\beta) = \\operatorname{Var}(X - \\beta Z)$。\n利用方差的性质，其中 $\\beta$ 是一个常数：\n$V(\\beta) = \\operatorname{Var}(X) + \\operatorname{Var}(-\\beta Z) + 2\\operatorname{Cov}(X, -\\beta Z)$。\n$V(\\beta) = \\operatorname{Var}(X) + \\beta^{2}\\operatorname{Var}(Z) - 2\\beta\\operatorname{Cov}(X, Z)$。\n这是关于 $\\beta$ 的二次函数。为求最小值，我们计算其关于 $\\beta$ 的导数并令其为零：\n$\\frac{d V}{d\\beta} = \\frac{d}{d\\beta} \\left( \\operatorname{Var}(X) + \\beta^{2}\\operatorname{Var}(Z) - 2\\beta\\operatorname{Cov}(X, Z) \\right) = 2\\beta\\operatorname{Var}(Z) - 2\\operatorname{Cov}(X, Z)$。\n令导数为零：\n$2\\beta\\operatorname{Var}(Z) - 2\\operatorname{Cov}(X, Z) = 0$。\n求解最优系数 $\\beta^{\\star}$：\n$\\beta^{\\star} = \\frac{\\operatorname{Cov}(X, Z)}{\\operatorname{Var}(Z)}$。\n二阶导数 $\\frac{d^2 V}{d\\beta^2} = 2\\operatorname{Var}(Z)$ 为正，因为方差是非负的（在本例中非零），这证实了这是一个最小值点。\n\n**任务3：计算 $\\beta^{\\star}$ 和方差缩减因子 $R$**\n\n为了计算 $\\beta^{\\star}$，我们需要计算 $\\operatorname{Var}(Z)$ 和 $\\operatorname{Cov}(X,Z)$。\n首先，我们求控制变量 $Z$ 的方差：\n$\\operatorname{Var}(Z) = \\mathbb{E}[Z^2] - (\\mathbb{E}[Z])^2$。由于 $\\mathbb{E}[Z]=0$，$\\operatorname{Var}(Z) = \\mathbb{E}[Z^2]$。\n$\\operatorname{Var}(Z) = \\mathbb{E}[(Y^2-1)^2] = \\mathbb{E}[Y^4 - 2Y^2 + 1]$。\n利用期望的线性性质和 $Y$ 的矩：\n$\\operatorname{Var}(Z) = \\mathbb{E}[Y^4] - 2\\mathbb{E}[Y^2] + 1 = 3 - 2(1) + 1 = 2$。\n\n接下来，我们计算 $X$ 和 $Z$ 之间的协方差：\n$\\operatorname{Cov}(X,Z) = \\mathbb{E}[XZ] - \\mathbb{E}[X]\\mathbb{E}[Z]$。\n由于 $\\mathbb{E}[X] = 0$ 和 $\\mathbb{E}[Z] = 0$，我们有 $\\operatorname{Cov}(X,Z) = \\mathbb{E}[XZ]$。\n代入 $X = Z + \\varepsilon$：\n$\\operatorname{Cov}(X,Z) = \\mathbb{E}[(Z+\\varepsilon)Z] = \\mathbb{E}[Z^2 + \\varepsilon Z] = \\mathbb{E}[Z^2] + \\mathbb{E}[\\varepsilon Z]$。\n我们知道 $\\mathbb{E}[Z^2] = \\operatorname{Var}(Z) = 2$。\n对于 $\\mathbb{E}[\\varepsilon Z]$ 项，我们利用 $\\varepsilon$ 和 $Y$ 的独立性。由于 $Z = Y^2-1$ 是 $Y$ 的函数，所以 $Z$ 和 $\\varepsilon$ 也相互独立。\n因此，$\\mathbb{E}[\\varepsilon Z] = \\mathbb{E}[\\varepsilon]\\mathbb{E}[Z] = 0 \\cdot 0 = 0$。\n所以，$\\operatorname{Cov}(X,Z) = 2 + 0 = 2$。\n\n现在我们可以计算最优系数 $\\beta^{\\star}$：\n$\\beta^{\\star} = \\frac{\\operatorname{Cov}(X, Z)}{\\operatorname{Var}(Z)} = \\frac{2}{2} = 1$。\n\n最后，我们计算方差缩减因子 $R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big)}$。\n首先，分子 $\\operatorname{Var}(X)$：\n$X = Z + \\varepsilon$。由于 $Z$ 和 $\\varepsilon$ 相互独立，它们和的方差等于它们方差的和：\n$\\operatorname{Var}(X) = \\operatorname{Var}(Z) + \\operatorname{Var}(\\varepsilon) = 2 + \\sigma^2 = 2 + 0.01 = 2.01$。\n\n接下来，分母是使用最优 $\\beta^{\\star}=1$ 和 $\\mathbb{E}[Z]=0$ 的调整后估计量的方差：\n$\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big) = \\operatorname{Var}(X - 1 \\cdot (Z - 0)) = \\operatorname{Var}(X-Z)$。\n代入 $X = Z + \\varepsilon$：\n$\\operatorname{Var}(X-Z) = \\operatorname{Var}((Z+\\varepsilon) - Z) = \\operatorname{Var}(\\varepsilon)$。\n我们已知 $\\operatorname{Var}(\\varepsilon) = \\sigma^2 = 0.01$。\n\n现在，我们可以计算方差缩减因子 $R$：\n$R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(X-Z)} = \\frac{2.01}{0.01} = 201$。\n\n最终答案为有序对 $(\\beta^{\\star}, R)$。\n$\\beta^{\\star} = 1$\n$R = 201$\n最终的对是 $(1, 201)$。",
            "answer": "$$\n\\boxed{(1, 201)}\n$$"
        },
        {
            "introduction": "本编码练习将探讨一个在实现控制变量法时至关重要但常被忽视的细节。通过对比使用共享和独立的随机数流所产生的结果，我们将通过实验验证，产生相关性是该方法的核心机制。这一机制的实现，依赖于确保目标函数与其控制变量在每一次抽样中都使用相同的随机数。这个实践将帮助你避免常见的实现陷阱，并巩固对方差缩减技术工作原理的根本理解。",
            "id": "3112831",
            "problem": "您将实现并分析一个带有控制变量的蒙特卡洛估计量，以量化共享伪随机数生成器 (PRNG) 流所引起的相关性如何影响方差缩减。此任务的基础包括期望、方差、协方差的定义以及蒙特卡洛估计量的构造。设 $X$ 是一个随机变量，其分布为 $X \\sim \\operatorname{Uniform}(0,1)$。估计目标是期望 $\\mathbb{E}[f(X)]$，其中 $f$ 是一个实值函数。控制变量是第二个函数 $H$，其期望 $\\mu_H = \\mathbb{E}[H(X)]$ 是已知的。控制变量估计量通过减去中心化控制变量的倍数来调整每个样本的贡献。您的程序必须证明，对齐函数 $f$ 和 $H$ 的 PRNG 流（即对两个函数使用相同的种子和相同的抽样值 $X$）会引入相关性并减少方差，而使用独立的流（不同的种子和独立的抽样值）则不会产生同样的好处。\n\n需要使用的定义和约束：\n- 使用 $N$ 个独立同分布样本 $X_1, \\dots, X_N$ 对 $\\mathbb{E}[f(X)]$ 的基本蒙特卡洛估计量是每个样本贡献 $f(X_i)$ 的平均值。\n- 使用控制变量 $H$，样本 $i$ 调整后的单样本贡献为 $Y_i = f(X^{(f)}_i) - c \\cdot \\left(H(X^{(H)}_i) - \\mu_H\\right)$，其中 $c$ 是一个实系数，$X^{(f)}_i$ 是用于评估 $f$ 的抽样值，$X^{(H)}_i$ 是用于评估 $H$ 的抽样值。当 PRNG 流共享时，对于所有 $i$，$X^{(f)}_i = X^{(H)}_i$。当 PRNG 流独立时，对于每个 $i$，$X^{(f)}_i$ 和 $X^{(H)}_i$ 是独立的。\n- $f(X^{(f)}_i)$ 和 $H(X^{(H)}_i)$ 在 $N$ 个样本间的相关性，通过从配对值 $\\{f(X^{(f)}_i), H(X^{(H)}_i)\\}_{i=1}^N$ 计算出的样本相关系数来量化。\n- 方差缩减效果通过比率 $R = \\operatorname{Var}(Y) / \\operatorname{Var}(f(X^{(f)}))$ 来量化，其中 $\\operatorname{Var}(Y)$ 和 $\\operatorname{Var}(f(X^{(f)}))$ 表示单样本贡献的样本方差。这个比率等于样本均值估计量的方差之比，因为两种方差都以 $1/N$ 的比例缩放，因此比较单样本方差就足够了。\n\n您的程序必须为每个测试用例计算：\n- $f(X^{(f)}_i)$ 和 $H(X^{(H)}_i)$ 之间的样本相关性。\n- 控制变量估计器通过使用系数 $c$ 所实现的方差缩减比率 $R$。当 $\\widehat{\\operatorname{Var}}(H)  0$ 时，定义 $c = \\widehat{\\operatorname{Cov}}(f,H) / \\widehat{\\operatorname{Var}}(H)$；当 $\\widehat{\\operatorname{Var}}(H) = 0$ 时，定义 $c = 0$ 以避免除以零。此处，$\\widehat{\\operatorname{Cov}}(f,H)$ 和 $\\widehat{\\operatorname{Var}}(H)$ 是从配对样本计算出的样本协方差和样本方差。\n\n使用以下测试套件。在所有情况下，$X \\sim \\operatorname{Uniform}(0,1)$，$N$ 是样本数量。种子用于控制 PRNG。已知期望为 $\\mathbb{E}[X] = 1/2$，对于 $H(x)=1-x$ 同样有 $\\mathbb{E}[H(X)] = 1/2$。对于常数 $H(x) = 1/2$，$H$ 的方差为零。提供的所有数字必须完全按照所写的使用：\n1. $N = 50000$, $f(x) = \\exp(x)$, $H(x) = x$, 使用种子 $123$ 的共享流（对 $f$ 和 $H$ 使用相同的抽样值 $X$，即 $X^{(f)}_i = X^{(H)}_i$）。\n2. $N = 50000$, $f(x) = \\exp(x)$, $H(x) = x$, 使用种子 $123$（用于 $f$）和 $999$（用于 $H$）的独立流（对 $f$ 和 $H$ 使用独立的抽样值，即 $X^{(f)}_i$ 独立于 $X^{(H)}_i$）。\n3. $N = 50000$, $f(x) = x$, $H(x) = 1/2$ (常数), 使用种子 $555$ 的共享流（由于 $H$ 是常数，流共享无关紧要；请确保您的程序在此处使用 $c = 0$ 因为 $\\widehat{\\operatorname{Var}}(H) = 0$）。\n4. $N = 50000$, $f(x) = x$, $H(x) = 1 - x$, 使用种子 $777$ 的共享流。\n5. $N = 50000$, $f(x) = x$, $H(x) = 1 - x$, 使用种子 $777$（用于 $f$）和 $888$（用于 $H$）的独立流。\n\n对于每个测试用例，计算数对 $[\\rho, R]$，其中 $\\rho$ 是样本相关性，$R$ 是方差缩减比率。您必须将所有结果输出为单个浮点数的扁平列表，按测试用例排序，且在每个用例内按数对 $[\\rho, R]$ 的顺序排列，每个浮点数四舍五入到六位小数。具体来说，如果有 $M$ 个测试用例，输出必须是包含 $2M$ 个浮点数的单行，格式为 $[a_1,a_2,\\dots,a_{2M}]$。不涉及任何单位。无需报告角度或百分比。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如 $[result1,result2,\\dots]$），遵循上述顺序和舍入规则，并且不得读取任何输入或写入任何额外文本。",
            "solution": "目标是估计随机变量 $X$ 的函数 $f(X)$ 的期望，记为 $\\theta = \\mathbb{E}[f(X)]$，其中 $X \\sim \\operatorname{Uniform}(0,1)$。$\\theta$ 的标准蒙特卡洛 (MC) 估计量是 $N$ 次独立同分布 (i.i.d.) 的 $f(X)$ 评估值的样本均值：\n$$\n\\hat{\\theta}_{MC} = \\frac{1}{N} \\sum_{i=1}^{N} f(X_i)\n$$\n该估计量的方差为 $\\operatorname{Var}(\\hat{\\theta}_{MC}) = \\frac{1}{N} \\operatorname{Var}(f(X))$。为了在给定样本数量 $N$ 的情况下提高估计的精度，可以采用方差缩减技术。\n\n本问题探究了控制变量法。该技术使用第二个函数 $H(X)$，称为控制变量，其期望 $\\mu_H = \\mathbb{E}[H(X)]$ 是已知的。通过用中心化的控制变量 $H(X_i) - \\mu_H$ 的倍数调整每个样本 $f(X_i)$ 来构造一个新的估计量。调整后的单样本贡献为：\n$$\nY_i(c) = f(X_i) - c \\cdot (H(X_i) - \\mu_H)\n$$\n其中 $c$ 是一个常数系数。$Y_i(c)$ 的期望是\n$$\n\\mathbb{E}[Y_i(c)] = \\mathbb{E}[f(X_i)] - c \\cdot (\\mathbb{E}[H(X_i)] - \\mu_H) = \\mathbb{E}[f(X_i)] - c \\cdot (\\mu_H - \\mu_H) = \\theta\n$$\n因此，样本均值 $\\hat{\\theta}_{CV} = \\frac{1}{N} \\sum_{i=1}^{N} Y_i(c)$ 也是 $\\theta$ 的一个无偏估计量。该方法的效用来自于选择 $c$ 以最小化估计量的方差，这等价于最小化单样本方差 $\\operatorname{Var}(Y_i(c))$。$Y_i(c)$ 的方差由下式给出：\n$$\n\\operatorname{Var}(Y_i(c)) = \\operatorname{Var}(f(X_i) - c \\cdot H(X_i)) = \\operatorname{Var}(f(X_i)) - 2c \\cdot \\operatorname{Cov}(f(X_i), H(X_i)) + c^2 \\cdot \\operatorname{Var}(H(X_i))\n$$\n为找到最小化此方差的最优系数 $c^*$，我们对 $c$ 求导并令其为零：\n$$\n\\frac{d}{dc} \\operatorname{Var}(Y_i(c)) = -2 \\operatorname{Cov}(f(X_i), H(X_i)) + 2c \\operatorname{Var}(H(X_i)) = 0\n$$\n假设 $\\operatorname{Var}(H(X_i))  0$，解出 $c$ 可得最优值：\n$$\nc^* = \\frac{\\operatorname{Cov}(f(X_i), H(X_i))}{\\operatorname{Var}(H(X_i))}\n$$\n本问题的核心在于协方差项的计算。我们必须区分用于评估 $f$ 和 $H$ 的随机数生成的两种情况：设 $X^{(f)}_i$ 为 $f$ 的随机抽样值，$X^{(H)}_i$ 为 $H$ 的随机抽样值。\n1.  **共享 PRNG 流**：对于所有 $i=1, \\dots, N$，$X^{(f)}_i = X^{(H)}_i$。两个函数使用相同的随机数。在这种情况下，如果 $f(x)$ 和 $H(x)$ 是其输入变量 $x$ 的相关函数，它们的评估值 $f(X_i)$ 和 $H(X_i)$ 也将是相关的。协方差 $\\operatorname{Cov}(f(X_i), H(X_i))$ 将为非零，从而导致非零的最优系数 $c^*$ 和方差缩减的潜力。\n2.  **独立 PRNG 流**：$X^{(f)}_i$ 和 $X^{(H)}_i$ 是独立抽取的。因此，随机变量 $f(X^{(f)}_i)$ 和 $H(X^{(H)}_i)$ 是独立的。对于独立变量，协方差为零：$\\operatorname{Cov}(f(X^{(f)}_i), H(X^{(H)}_i)) = 0$。这意味着最优系数 $c^*$ 为 $0$，控制变量不提供任何方差缩减。$Y_i$ 的方差变得与 $f(X^{(f)}_i)$ 的方差相等。\n\n在实践中，真实的协方差和方差是未知的，必须从生成的样本中进行估计。问题指定使用基于样本的估计值来计算 $c$：\n$$\n\\hat{c} = \\frac{\\widehat{\\operatorname{Cov}}(f,H)}{\\widehat{\\operatorname{Var}}(H)}\n$$\n其中 $\\widehat{\\operatorname{Cov}}(f,H)$ 和 $\\widehat{\\operatorname{Var}}(H)$ 是从配对 $\\{ f(X^{(f)}_i), H(X^{(H)}_i) \\}_{i=1}^N$ 计算出的样本协方差和样本方差。一个特殊情况是当 $\\widehat{\\operatorname{Var}}(H) = 0$ 时，此时 $\\hat{c}=0$。\n\n程序将为每个测试用例实现这些计算。对于每个用例，我们将计算两个量：\n1.  **样本相关系数 ($\\rho$)**：\n    $$\n    \\rho = \\frac{\\widehat{\\operatorname{Cov}}(f(X^{(f)}), H(X^{(H)}))}{\\sqrt{\\widehat{\\operatorname{Var}}(f(X^{(f)})) \\cdot \\widehat{\\operatorname{Var}}(H(X^{(H)}))}}\n    $$\n    这衡量了 $f$ 和 $H$ 样本值之间的线性相关性。如果 $\\widehat{\\operatorname{Var}}(H(X^{(H)})) = 0$，则协方差也为 $0$，我们定义 $\\rho=0$。\n2.  **方差缩减比率 ($R$)**：\n    $$\n    R = \\frac{\\widehat{\\operatorname{Var}}(Y)}{\\widehat{\\operatorname{Var}}(f(X^{(f)}))}\n    $$\n    这个比率量化了方差缩减的有效性。$R  1$ 的值表示方差缩减成功。样本 $Y_i$ 计算为 $Y_i = f(X^{(f)}_i) - \\hat{c} \\cdot (H(X^{(H)}_i) - \\mu_H)$。\n\n每个测试用例的实现将按以下步骤进行：\n-   为 $f$ 生成 $N$ 个样本，记为 $\\{X^{(f)}_i\\}$，使用其指定的 PRNG 种子。\n-   根据流共享规则为 $H$ 生成 $N$ 个样本，记为 $\\{X^{(H)}_i\\}$。如果共享，则设置 $\\{X^{(H)}_i\\} = \\{X^{(f)}_i\\}$。如果独立，则使用第二个种子。\n-   计算函数值向量 $\\{f(X^{(f)}_i)\\}$ 和 $\\{H(X^{(H)}_i)\\}$。\n-   计算 $\\{H(X^{(H)}_i)\\}$ 的样本方差。如果为 $0$，则设置 $\\hat{c}=0$ 和 $\\rho=0$。否则，计算样本协方差矩阵以找到 $\\widehat{\\operatorname{Cov}}(f,H)$ 和 $\\widehat{\\operatorname{Var}}(H)$，然后计算 $\\hat{c}$。同时使用标准公式计算 $\\rho$。\n-   计算调整后的样本 $\\{Y_i\\}$。\n-   计算 $\\{f(X^{(f)}_i)\\}$ 和 $\\{Y_i\\}$ 的样本方差。\n-   计算比率 $R$。\n-   存储数对 $[\\rho, R]$ 以供最终输出。\n\n所有样本统计量（方差和协方差）将使用除数 $N-1$（无偏估计量）来计算，这是标准做法。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes a Monte Carlo estimator with control variates.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 50000, \n            \"f\": lambda x: np.exp(x), \n            \"H\": lambda x: x,\n            \"mu_H\": 0.5,\n            \"f_seed\": 123, \n            \"h_seed\": 123,  # Shared stream\n            \"shared\": True\n        },\n        {\n            \"N\": 50000, \n            \"f\": lambda x: np.exp(x), \n            \"H\": lambda x: x,\n            \"mu_H\": 0.5,\n            \"f_seed\": 123, \n            \"h_seed\": 999,  # Independent streams\n            \"shared\": False\n        },\n        {\n            \"N\": 50000,\n            \"f\": lambda x: x,\n            \"H\": lambda x: np.full_like(x, 0.5), # Constant function\n            \"mu_H\": 0.5,\n            \"f_seed\": 555,\n            \"h_seed\": 555, # Stream sharing is irrelevant\n            \"shared\": True\n        },\n        {\n            \"N\": 50000,\n            \"f\": lambda x: x,\n            \"H\": lambda x: 1.0 - x,\n            \"mu_H\": 0.5,\n            \"f_seed\": 777,\n            \"h_seed\": 777, # Shared stream\n            \"shared\": True\n        },\n        {\n            \"N\": 50000,\n            \"f\": lambda x: x,\n            \"H\": lambda x: 1.0 - x,\n            \"mu_H\": 0.5,\n            \"f_seed\": 777,\n            \"h_seed\": 888, # Independent streams\n            \"shared\": False\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N = case[\"N\"]\n        f = case[\"f\"]\n        H = case[\"H\"]\n        mu_H = case[\"mu_H\"]\n        f_seed = case[\"f_seed\"]\n        h_seed = case[\"h_seed\"]\n        shared = case[\"shared\"]\n\n        # 1. Generate random samples\n        rng_f = np.random.default_rng(f_seed)\n        x_f = rng_f.uniform(0, 1, N)\n\n        if shared:\n            x_h = x_f\n        else:\n            rng_h = np.random.default_rng(h_seed)\n            x_h = rng_h.uniform(0, 1, N)\n\n        # 2. Evaluate functions on samples\n        f_vals = f(x_f)\n        h_vals = H(x_h)\n\n        # 3. Calculate sample statistics\n        # Using ddof=1 for unbiased sample variance/covariance\n        var_h = np.var(h_vals, ddof=1)\n        var_f = np.var(f_vals, ddof=1)\n\n        # 4. Calculate coefficient c and correlation rho\n        if var_h > 0:\n            cov_matrix = np.cov(f_vals, h_vals, ddof=1)\n            cov_fh = cov_matrix[0, 1]\n            c = cov_fh / var_h\n            \n            # Correlation coefficient\n            corr_matrix = np.corrcoef(f_vals, h_vals)\n            rho = corr_matrix[0, 1]\n        else:\n            # Case where H is constant, so Var(H) = 0\n            c = 0.0\n            # Covariance is 0, so correlation is taken to be 0\n            rho = 0.0\n\n        # 5. Compute adjusted samples Y\n        y_vals = f_vals - c * (h_vals - mu_H)\n        \n        # 6. Compute variance of adjusted samples\n        var_y = np.var(y_vals, ddof=1)\n\n        # 7. Compute variance reduction ratio R\n        # var_f should not be zero for the given test cases\n        R = var_y / var_f\n        \n        all_results.extend([rho, R])\n\n    # Final print statement in the exact required format.\n    # Round to 6 decimal places and format as string to preserve trailing zeros.\n    formatted_results = [f\"{r:.6f}\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}