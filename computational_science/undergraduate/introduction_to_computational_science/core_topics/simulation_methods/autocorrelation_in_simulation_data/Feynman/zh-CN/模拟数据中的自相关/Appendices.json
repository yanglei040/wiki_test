{
    "hands_on_practices": [
        {
            "introduction": "在分析任何模拟数据之前，首要任务是确保数据的保真度。如果采样频率不足，高频信号会“伪装”成低频信号，这种现象称为混叠 (aliasing)。这个练习将通过一个具体的例子，向你展示混叠如何扭曲自相关函数 (ACF)，从而导致对系统动态的错误解读 。",
            "id": "3098943",
            "problem": "你将实现一个完整的、可运行的程序，以展示对快速振荡信号进行欠采样如何导致混叠，而混叠又会产生一个具有误导性的自相关函数 (ACF)，表明其动态特性较慢。整个工作应在纯数学和算法的环境中进行。\n\n一个连续时间标量信号定义为 $x(t) = \\sin\\!\\big(2\\pi f_0 t + \\varphi\\big)$，其中 $f_0$ 是以赫兹（周/秒）为单位的频率，$\\varphi$ 是以弧度为单位的固定相位。该信号以采样间隔 $\\Delta t$ 进行均匀采样，形成离散序列 $x_n = x(n\\,\\Delta t)$，其中整数 $n \\in \\{0,1,\\dots,N-1\\}$。定义样本均值 $\\mu = \\frac{1}{N}\\sum_{n=0}^{N-1} x_n$。对于整数延迟 $k \\in \\{0,1,\\dots,N-1\\}$，归一化、有限长度、单边样本自相关函数 (ACF) 定义为\n$$\nr[k] \\;=\\; \\frac{\\sum_{n=0}^{N-1-k}\\big(x_n - \\mu\\big)\\big(x_{n+k} - \\mu\\big)}{\\sum_{n=0}^{N-1}\\big(x_n - \\mu\\big)^2}.\n$$\n注意，根据构造，$r[0] = 1$。对于纯正弦输入，ACF所揭示的主导时间尺度可以估算为第一个非零延迟正局部最大值处的时间。换言之，定义 $k^\\star$ 为满足 $r[k] > 0$、$r[k] \\ge r[k-1]$ 和 $r[k] \\ge r[k+1]$ 的最小整数 $k \\ge 1$。然后定义估算的主导时间尺度\n$$\n\\tau_{\\mathrm{est}} \\;=\\; k^\\star \\,\\Delta t \\quad \\text{(单位：秒)}.\n$$\n\n你的任务是编写一个程序，针对下面测试套件中的每一组参数，构造 $x_n$，计算 $k \\ge 0$ 时的 $r[k]$，按上述方法找到 $k^\\star$，并返回以秒为单位的 $\\tau_{\\mathrm{est}}$。其目的是观察当采样频率 $f_s = 1/\\Delta t$ 相对于 $f_0$ 过低时，会发生混叠，并且 ACF 可能指示一个较慢的表观动态，即 $\\tau_{\\mathrm{est}}$ 大于真实周期 $T_0 = 1/f_0$。\n\n你可以依赖的基本原理：均匀采样的定义 $x_n = x(n\\,\\Delta t)$，上面给出的归一化样本 ACF 的定义，以及一个经过广泛验证的事实：如果采样频率 $f_s = 1/\\Delta t$ 不超过最高信号频率的两倍，则采样后的离散时间正弦波会在区间 $[0, f_s/2]$ 内编码一个混叠频率，该频率会反映在 ACF 中。\n\n测试套件（每个案例指定 $(f_0, \\Delta t, N, \\varphi)$）：\n- 案例 1（良好采样，正常路径）：$f_0 = 3.0$ Hz，$\\Delta t = 0.01$ s， $N = 1024$，$\\varphi = 0.3$ rad。\n- 案例 2（欠采样，混叠导致较慢的表观动态）：$f_0 = 45.0$ Hz，$\\Delta t = 0.02$ s， $N = 1024$，$\\varphi = 0.2$ rad。\n- 案例 3（奈奎斯特边界行为，通过相位避免退化）：$f_0 = 25.0$ Hz，$\\Delta t = 0.02$ s， $N = 1024$，$\\varphi = \\pi/2$ rad。\n\n程序要求：\n- 对每个案例，严格按照 $x_n = \\sin\\!\\big(2\\pi f_0 n \\Delta t + \\varphi\\big)$ 为 $n \\in \\{0,\\dots,N-1\\}$ 生成 $x_n$。\n- 对 $k \\in \\{0,\\dots,N-1\\}$，严格按照上述定义计算 $r[k]$。\n- 将 $k^\\star$ 确定为满足 $r[k] > 0$、$r[k] \\ge r[k-1]$ 和 $r[k] \\ge r[k+1]$ 的最小 $k \\ge 1$；如果不存在这样的 $k$，则使用使 $r[k]$ 最大化的 $k \\ge 1$。\n- 对每个案例，返回 $\\tau_{\\mathrm{est}} = k^\\star \\Delta t$，以秒为单位，四舍五入到 6 位小数。\n- 最终输出格式：你的程序应生成单行输出，包含一个由逗号分隔的三个 $\\tau_{\\mathrm{est}}$ 值列表，列表用方括号括起来，且不含空格（例如，$[0.123456,0.234567,0.345678]$）。",
            "solution": "问题陈述已经过严格验证，并被认为是有效的。它具有科学依据，问题提出得当，客观且内部一致。唯一解所需的所有参数和定义均已提供。任务是实现一个算法，展示混叠对采样正弦信号自相关函数的影响。\n\n对于每个测试案例，解决方案分四个主要步骤进行：\n1.  生成离散时间信号 $x_n$。\n2.  计算归一化样本自相关函数 (ACF) $r[k]$。\n3.  确定特征延迟 $k^\\star$。\n4.  计算估算的主导时间尺度 $\\tau_{\\mathrm{est}}$。\n\n让我们考虑一个给定的测试案例，其参数为 $(f_0, \\Delta t, N, \\varphi)$。\n\n**步骤 1：信号生成**\n连续时间信号由 $x(t) = \\sin(2\\pi f_0 t + \\varphi)$ 给出。我们以均匀间隔 $\\Delta t$ 对该信号进行采样，生成长度为 $N$ 的离散时间序列 $x_n$。时间点为 $t_n = n \\Delta t$，其中 $n \\in \\{0, 1, \\dots, N-1\\}$。因此，离散信号为：\n$$\nx_n = x(t_n) = \\sin(2\\pi f_0 n \\Delta t + \\varphi)\n$$\n该序列为所有从 $0$ 到 $N-1$ 的 $n$ 生成。\n\n**步骤 2：自相关函数 (ACF) 计算**\n问题为归一化样本 ACF $r[k]$ 提供了一个特定公式。计算需要几个子步骤。\n\n首先，我们计算信号 $x_n$ 的样本均值 $\\mu$：\n$$\n\\mu = \\frac{1}{N} \\sum_{n=0}^{N-1} x_n\n$$\n接下来，我们通过减去均值来中心化信号：$x'_n = x_n - \\mu$。\n\nACF 的分母是中心化信号的平方和，它对应于延迟 $k=0$ 时的自协方差，并作为归一化因子。\n$$\nS = \\sum_{n=0}^{N-1} (x_n - \\mu)^2 = \\sum_{n=0}^{N-1} (x'_n)^2\n$$\n分子是在给定整数延迟 $k$ 处的未归一化自协方差，其中 $k \\in \\{0, 1, \\dots, N-1\\}$：\n$$\nC[k] = \\sum_{n=0}^{N-1-k} (x_n - \\mu)(x_{n+k} - \\mu) = \\sum_{n=0}^{N-1-k} x'_n x'_{n+k}\n$$\n最后，归一化样本 ACF $r[k]$ 是延迟 $k$ 处的自协方差与归一化因子 $S$ 的比值：\n$$\nr[k] = \\frac{C[k]}{S} = \\frac{\\sum_{n=0}^{N-1-k} (x_n - \\mu)(x_{n+k} - \\mu)}{\\sum_{n=0}^{N-1} (x_n - \\mu)^2}\n$$\n注意，对于 $k=0$，分子变为 $\\sum_{n=0}^{N-1} (x_n - \\mu)^2$，与分母 $S$ 相同，从而确保了所述的 $r[0] = 1$。对 $k \\in \\{0, 1, \\dots, N-1\\}$ 计算整个函数 $r[k]$。\n\n**步骤 3：确定特征延迟 ($k^\\star$)**\n特征延迟 $k^\\star$ 用于估算 ACF 所揭示的信号中的主导周期。它被定义为代表正局部最大值的最小整数延迟 $k \\ge 1$。条件如下：\n1.  $k \\ge 1$\n2.  $r[k] > 0$\n3.  $r[k] \\ge r[k-1]$\n4.  $r[k] \\ge r[k+1]$\n\n为了找到 $k^\\star$，我们从 $k=1$ 迭代到 $N-2$（以确保 $r[k+1]$ 是可访问的）。第一个满足所有三个条件的 $k$ 值被选为 $k^\\star$。\n\n如果此搜索完成而未找到这样的 $k$，则应用备用规则：选择使 $r[k]$ 值最大化的延迟 $k \\ge 1$ 作为 $k^\\star$。这可以通过在子数组 $r[1], r[2], \\dots, r[N-1]$ 中搜索最大值来找到。\n\n**步骤 4：计算估算的时间尺度 ($\\tau_{\\mathrm{est}}$)**\n一旦确定了 $k^\\star$，就通过将延迟从样本单位转换回时间单位（秒）来计算估算的主导时间尺度 $\\tau_{\\mathrm{est}}$：\n$$\n\\tau_{\\mathrm{est}} = k^\\star \\cdot \\Delta t\n$$\n对每个测试案例计算此值。\n\n**测试案例的概念分析：**\n- **案例 1（良好采样）：** $f_0 = 3.0$ Hz，$\\Delta t = 0.01$ s。采样频率为 $f_s = 1/\\Delta t = 100$ Hz。奈奎斯特频率为 $f_s/2 = 50$ Hz。由于 $f_0 \\ll f_s/2$，信号被良好采样。真实周期为 $T_0 = 1/f_0 \\approx 0.3333$ s。我们预期 $\\tau_{\\mathrm{est}} \\approx T_0$。\n- **案例 2（欠采样）：** $f_0 = 45.0$ Hz，$\\Delta t = 0.02$ s。采样频率为 $f_s = 1/\\Delta t = 50$ Hz。奈奎斯特频率为 $f_s/2 = 25$ Hz。由于 $f_0 > f_s/2$，将会发生混叠。混叠频率为 $f_a = |f_0 - f_s| = |45 - 50| = 5.0$ Hz。表观周期为 $T_a = 1/f_a = 0.2$ s。我们预期 ACF 会反映这种混叠动态，因此 $\\tau_{\\mathrm{est}} \\approx T_a$。\n- **案例 3（奈奎斯特边界）：** $f_0 = 25.0$ Hz，$\\Delta t = 0.02$ s。这里，$f_0$ 正好是奈奎斯特频率。采样信号将是 $x_n = \\sin(2\\pi \\cdot 25 \\cdot n \\cdot 0.02 + \\pi/2) = \\sin(n\\pi + \\pi/2) = \\cos(n\\pi)$，其结果是序列 $\\{1, -1, 1, -1, \\dots\\}$。该信号在延迟 $k=1$ 时完全反相关，在延迟 $k=2$ 时完全相关。因此，ACF 中的第一个正峰值应出现在 $k^\\star=2$ 处，导致 $\\tau_{\\mathrm{est}} = 2 \\cdot 0.02 = 0.04$ s，对应于 $1/0.04 = 25$ Hz 的表观频率。\n\n实现将精确遵循这些步骤。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of finding the estimated dominant time scale from the\n    autocorrelation function of a sampled sinusoidal signal for three test cases,\n    demonstrating the effect of aliasing.\n    \"\"\"\n    # Test suite (f0, dt, N, phi)\n    test_cases = [\n        (3.0, 0.01, 1024, 0.3),         # Case 1: Well-sampled\n        (45.0, 0.02, 1024, 0.2),        # Case 2: Undersampled (aliasing)\n        (25.0, 0.02, 1024, np.pi/2),   # Case 3: Nyquist boundary\n    ]\n\n    results = []\n    \n    for f0, dt, N, phi in test_cases:\n        # Step 1: Generate the discrete-time signal\n        n = np.arange(N)\n        t = n * dt\n        x = np.sin(2 * np.pi * f0 * t + phi)\n\n        # Step 2: Compute the Autocorrelation Function (ACF)\n        \n        # Center the signal by subtracting its mean\n        mu = np.mean(x)\n        x_centered = x - mu\n        \n        # The denominator is the sum of squared deviations, which is also\n        # the unnormalized autocorrelation at lag 0.\n        # Efficiently computed using np.dot or np.sum(x_centered**2)\n        denominator = np.dot(x_centered, x_centered)\n        \n        # Handle the edge case where the denominator is zero (e.g., a constant signal)\n        if denominator == 0:\n            # For a constant signal, ACF is ill-defined. We can set r to zeros.\n            # However, for a sine wave, this is not expected.\n            r = np.zeros(N)\n            r[0] = 1.0\n        else:\n            # The numerator is the autocovariance at each lag k.\n            # np.correlate computes C[k] = sum_n(a[n+k] * v[n]).\n            # Using mode 'full' provides all lags. The second half corresponds\n            # to non-negative lags.\n            unnormalized_acf = np.correlate(x_centered, x_centered, mode='full')\n            \n            # The unnormalized ACF at non-negative lags k=0,1,...,N-1\n            # is the second half of the full correlation result.\n            autocovariance = unnormalized_acf[N - 1:]\n            \n            # Normalize to get the ACF r[k]\n            r = autocovariance / denominator\n\n        # Step 3: Determine the characteristic lag k_star\n        k_star = -1  # Sentinel value indicating not found\n\n        # Search for the smallest k >= 1 that is a positive local maximum.\n        # Loop up to N-2 to allow checking r[k+1].\n        for k in range(1, N - 1):\n            is_positive = r[k] > 0\n            is_local_max = (r[k] >= r[k - 1]) and (r[k] >= r[k + 1])\n            \n            if is_positive and is_local_max:\n                k_star = k\n                break  # Found the smallest k, so we can stop.\n\n        # If no such k was found, apply the fallback rule.\n        if k_star == -1:\n            # Find the k >= 1 that globally maximizes r[k].\n            # We search in r[1:] because k must be >= 1.\n            # np.argmax returns the index relative to the sliced array r[1:].\n            # We add 1 to get the index relative to the original array r.\n            k_star = np.argmax(r[1:]) + 1\n\n        # Step 4: Calculate the estimated dominant time scale\n        tau_est = k_star * dt\n        results.append(tau_est)\n\n    # Final print statement in the exact required format.\n    # We use a format specifier to ensure 6 decimal places.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "模拟数据中常常包含确定性的周期性模式，例如日循环或年循环，这被称为季节性 (seasonality)。这种季节性会产生强烈的虚假自相关，掩盖数据中潜在的随机动态。本练习将指导你如何通过季节性差分 (seasonal differencing) 来移除这种确定性结构，从而更清晰地揭示数据背后的真实相关性 。",
            "id": "3098918",
            "problem": "你需要实现一个完整的、可运行的程序，以演示未移除的季节性如何在模拟数据中引入误导性的依赖关系，以及季节性差分如何减轻这种伪短滞后依赖。请严格遵循核心定义。考虑一个离散时间序列 $\\{X_t\\}_{t=0}^{N-1}$，它由一个季节性确定性分量和一个加性噪声之和构成。季节性分量是一个已知周期的正弦波，加性噪声是独立同分布的高斯噪声。使用正弦函数，角度以弧度为单位。\n\n基本原理与定义：\n- 离散时间序列是由整数时间 $t$ 索引的序列 $\\{X_t\\}$。\n- 当其不随时间变化且有良好定义时，滞后 $k$ 的总体自协方差为 $\\gamma(k) = \\mathrm{Cov}(X_t, X_{t+k})$。\n- 样本均值为 $\\bar{X} = \\frac{1}{N}\\sum_{t=0}^{N-1}X_t$。\n- 滞后 $k$ 的无偏样本自协方差估计量为\n$$\\hat{\\gamma}(k) = \\frac{1}{N-k} \\sum_{t=0}^{N-1-k} \\left(X_t - \\bar{X}\\right)\\left(X_{t+k} - \\bar{X}\\right), \\quad 0 \\le k \\le N-1.$$\n- 滞后 $k$ 的样本自相关函数（Autocorrelation Function (ACF)）为\n$$\\hat{\\rho}(k) = \\frac{\\hat{\\gamma}(k)}{\\hat{\\gamma}(0)}.$$\n\n季节性模型与差分：\n- 模拟的序列为\n$$X_t = A \\sin\\!\\left(\\frac{2\\pi t}{s}\\right) + \\varepsilon_t,$$\n其中 $A$ 是振幅，$s$ 是以时间步长为单位的季节性周期，且 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 在各时间点 $t$ 上独立。\n- 周期为 $d$ 的季节性差分产生\n$$Y_t = X_t - X_{t-d}, \\quad t = d, d+1, \\dots, N-1.$$\n\n检测标准：\n- 对于每次模拟，计算原始序列 $\\{X_t\\}$ 和差分序列 $\\{Y_t\\}$ 的 $\\hat{\\rho}(1)$。\n- 在白噪声假设下，使用ACF的大样本高斯近似来定义双边 $95\\%$ 置信界为\n$$b_N = \\frac{1.96}{\\sqrt{N}},$$\n其中 $N$ 是计算ACF的序列的样本大小。将 $\\left|\\hat{\\rho}(1)\\right| > b_N$ 视为滞后 $1$ 处存在“统计上显著”的依赖性；否则视为不显著。\n- 当且仅当 $\\left|\\hat{\\rho}_{X}(1)\\right| > b_{N_X}$ 且 $\\left|\\hat{\\rho}_{Y}(1)\\right| \\le b_{N_Y}$ 时，判定“由季节性引起的伪短滞后自相关已被移除”，其中 $N_X = N$ 是 $\\{X_t\\}$ 的长度，$N_Y = N - d$ 是 $\\{Y_t\\}$ 的长度。\n\n待实现的任务：\n1. 对每个测试用例，使用上述模型、指定参数和固定随机种子（以确保可复现性）生成 $\\{X_t\\}$，然后计算 $\\{X_t\\}$ 的 $\\hat{\\rho}(1)$。\n2. 应用指定的周期 $d$ 进行季节性差分以获得 $\\{Y_t\\}$，然后计算 $\\{Y_t\\}$ 的 $\\hat{\\rho}(1)$。\n3. 计算置信界 $b_{N_X}$ 和 $b_{N_Y}$。\n4. 对每个测试用例，根据检测标准输出一个布尔值，用以指示差分是否移除了伪短滞后自相关。\n\n角度单位：\n- 正弦函数中的所有角度均以弧度为单位。\n\n测试套件：\n- 每个元组为 $(N, s, A, \\sigma, d, \\text{seed})$。\n- 使用以下参数集：\n  - 案例 $1$ (常规“理想路径”)：$(720, 24, 2.0, 0.5, 24, 2023)$。\n  - 案例 $2$ (错误的差分周期)：$(720, 24, 2.0, 0.5, 12, 2023)$。\n  - 案例 $3$ (无季节性；防止错误检测的边界情况)：$(720, 24, 0.0, 1.0, 24, 42)$。\n  - 案例 $4$ (接近季节性尺度的小样本)：$(36, 24, 1.5, 0.1, 24, 7)$。\n  - 案例 $5$ (季节性相对于噪声较弱)：$(720, 24, 0.2, 1.0, 24, 123)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个案例的布尔结果，格式为方括号内由逗号分隔的列表，例如 $\\texttt{[True,False,True,True,False]}$。\n- 程序必须自包含，不要求用户输入，并使用指定的运行时环境。",
            "solution": "该问题要求实现一个计算实验，以演示季节性差分如何消除由时间序列中的确定性季节性分量引起的伪短滞后自相关。解决方案涉及生成时间序列数据、计算样本自相关、应用季节性差分，并根据指定的统计标准评估结果。\n\n程序化步骤如下：\n\n1.  **时间序列生成**：对于每个测试用例，根据以下模型合成一个长度为 $N$ 的离散时间序列 $\\{X_t\\}_{t=0}^{N-1}$：\n    $$X_t = S_t + \\varepsilon_t = A \\sin\\left(\\frac{2\\pi t}{s}\\right) + \\varepsilon_t$$\n    此处，$S_t = A \\sin(\\frac{2\\pi t}{s})$ 表示一个振幅为 $A$、周期为 $s$ 的确定性季节性分量。项 $\\varepsilon_t$ 表示加性噪声，其被建模为来自均值为 $0$、方差为 $\\sigma^2$ 的正态分布的独立同分布 (i.i.d.) 随机变量，记作 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。正弦函数的参数以弧度为单位。每个案例使用固定的随机种子以确保噪声分量 $\\varepsilon_t$ 的可复现性。\n\n2.  **样本自相关函数 (ACF) 计算**：分析的核心是样本自相关函数 (ACF) $\\hat{\\rho}(k)$，它估计了滞后 $k$ 的观测值之间的相关性。问题指定了以下定义，必须精确实现。首先，计算样本均值 $\\bar{X}$：\n    $$\\bar{X} = \\frac{1}{N}\\sum_{t=0}^{N-1}X_t$$\n    接下来，计算滞后 $k$ 的无偏样本自协方差估计量 $\\hat{\\gamma}(k)$。对于所需的滞后 $k=1$ 和滞后 $k=0$ 的方差，公式为：\n    $$\\hat{\\gamma}(1) = \\frac{1}{N-1} \\sum_{t=0}^{N-2} \\left(X_t - \\bar{X}\\right)\\left(X_{t+1} - \\bar{X}\\right)$$\n    $$\\hat{\\gamma}(0) = \\frac{1}{N} \\sum_{t=0}^{N-1} \\left(X_t - \\bar{X}\\right)^2$$\n    注意，$\\hat{\\gamma}(0)$ 是（有偏的）样本方差。滞后 $k=1$ 的样本自相关，记为 $\\hat{\\rho}_X(1)$，则是比率：\n    $$\\hat{\\rho}_X(1) = \\frac{\\hat{\\gamma}(1)}{\\hat{\\gamma}(0)}$$\n    此过程应用于原始序列 $\\{X_t\\}$。\n\n3.  **季节性差分**：为了消除季节性，应用指定差分周期 $d$ 的季节性差分。这会创建一个新的时间序列 $\\{Y_t\\}$：\n    $$Y_t = X_t - X_{t-d}, \\quad \\text{for } t = d, d+1, \\dots, N-1$$\n    得到的差分序列 $\\{Y_t\\}$ 的长度较短，为 $N_Y = N - d$。当差分周期 $d$ 与真实的季节性周期 $s$ 匹配时，确定性的正弦分量在解析上被消除：\n    $$S_t - S_{t-s} = A \\sin\\left(\\frac{2\\pi t}{s}\\right) - A \\sin\\left(\\frac{2\\pi (t-s)}{s}\\right) = A \\sin\\left(\\frac{2\\pi t}{s}\\right) - A \\sin\\left(\\frac{2\\pi t}{s} - 2\\pi\\right) = 0$$\n    差分序列于是变为 $Y_t = \\varepsilon_t - \\varepsilon_{t-s}$。这是一个移动平均过程，对于 $s > 1$，其真实的滞后-1自相关为零。$\\{Y_t\\}$ 的样本ACF，即 $\\hat{\\rho}_Y(1)$，使用与 $\\{X_t\\}$ 相同的公式计算，但应用于数据 $\\{Y_t\\}$ 及其对应的长度 $N_Y$。\n\n4.  **检测标准**：季节性差分的有效性通过一个统计标准来评估。对于一个由纯白噪声组成、长度为 $M$ 的时间序列，当 $k>0$ 时，样本ACF值 $\\hat{\\rho}(k)$ 近似服从均值为 $0$、方差为 $1/M$ 的正态分布。这产生了一个双边 $95\\%$ 置信界：\n    $$b_M = \\frac{1.96}{\\sqrt{M}}$$\n    观测到的ACF值 $|\\hat{\\rho}(1)| > b_M$ 被认为是“统计上显著的”。问题定义，当且仅当同时满足以下两个条件时，“由季节性引起的伪短滞后自相关被移除”：\n    1.  原始序列显示出显著的滞后-1自相关：$|\\hat{\\rho}_X(1)| > b_{N_X}$，其中 $N_X = N$。\n    2.  差分序列未显示出显著的滞后-1自相关：$|\\hat{\\rho}_Y(1)| \\le b_{N_Y}$，其中 $N_Y = N - d$。\n\n    对于每个测试用例，我们计算 $\\hat{\\rho}_X(1)$ 和 $\\hat{\\rho}_Y(1)$，它们各自的界限 $b_{N_X}$ 和 $b_{N_Y}$，并评估这个由两部分组成的逻辑条件以产生最终的布尔结果。测试用例的选择考察了多种情景，包括正确的差分 ($d=s$)、不正确的差分 ($d \\neq s$)、无季节性 ($A=0$)、小样本量，以及低信噪比。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_rho1(series: np.ndarray) -> float:\n    \"\"\"\n    Calculates the sample autocorrelation at lag 1 based on the problem's definitions.\n\n    Args:\n        series: A 1D numpy array representing the time series.\n\n    Returns:\n        The sample autocorrelation at lag 1.\n    \"\"\"\n    N = len(series)\n    if N <= 1:\n        # Not enough data to compute lag-1 ACF.\n        return 0.0\n\n    mean_val = np.mean(series)\n    demeaned_series = series - mean_val\n\n    # Per problem definition: gamma(0) is the biased sample variance.\n    gamma_0 = np.var(series)\n\n    # Per problem definition: gamma(1) = (1/(N-1)) * sum((X_t - X_bar)*(X_{t+1} - X_bar))\n    # The sum is over t from 0 to N-2.\n    sum_of_products = np.sum(demeaned_series[:-1] * demeaned_series[1:])\n    gamma_1 = sum_of_products / (N - 1)\n\n    if gamma_0 == 0.0:\n        # If the series has zero variance, correlation is undefined or 0.\n        return 0.0\n\n    # Sample autocorrelation at lag 1\n    rho_1 = gamma_1 / gamma_0\n    \n    return rho_1\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and validation for all test cases.\n    \"\"\"\n    # Test suite: Each tuple is (N, s, A, sigma, d, seed)\n    test_cases = [\n        # Case 1 (general “happy path”): (720, 24, 2.0, 0.5, 24, 2023)\n        (720, 24, 2.0, 0.5, 24, 2023),\n        # Case 2 (wrong differencing period): (720, 24, 2.0, 0.5, 12, 2023)\n        (720, 24, 2.0, 0.5, 12, 2023),\n        # Case 3 (no seasonality; boundary against false detection): (720, 24, 0.0, 1.0, 24, 42)\n        (720, 24, 0.0, 1.0, 24, 42),\n        # Case 4 (small sample near the seasonal scale): (36, 24, 1.5, 0.1, 24, 7)\n        (36, 24, 1.5, 0.1, 24, 7),\n        # Case 5 (seasonality weak relative to noise): (720, 24, 0.2, 1.0, 24, 123)\n        (720, 24, 0.2, 1.0, 24, 123),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, s, A, sigma, d, seed = case\n\n        # 1. Generate the time series {X_t}\n        np.random.seed(seed)\n        t = np.arange(N)\n        seasonal_component = A * np.sin(2 * np.pi * t / s)\n        noise_component = np.random.normal(loc=0.0, scale=sigma, size=N)\n        X = seasonal_component + noise_component\n        \n        # Compute ACF for {X_t}\n        rho_X_1 = calculate_rho1(X)\n        N_X = N\n        \n        # 2. Apply seasonal differencing to get {Y_t}\n        Y = X[d:] - X[:-d]\n        \n        # Compute ACF for {Y_t}\n        rho_Y_1 = calculate_rho1(Y)\n        N_Y = N - d\n\n        # 3. Compute the confidence bounds\n        b_N_X = 1.96 / np.sqrt(N_X)\n        b_N_Y = 1.96 / np.sqrt(N_Y)\n\n        # 4. Apply the detection criterion\n        is_X_autocorrelated = np.abs(rho_X_1) > b_N_X\n        is_Y_not_autocorrelated = np.abs(rho_Y_1) <= b_N_Y\n        \n        is_removed = is_X_autocorrelated and is_Y_not_autocorrelated\n        results.append(is_removed)\n\n    # Format the final output as a comma-separated list of booleans\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在我们对数据进行建模（例如，移除趋势）之后，一个关键问题是：模型是否充分捕捉了数据的相关性结构？仅仅目视检查自相关图可能不够，我们需要一个正式的统计检验。这个练习将介绍 Ljung-Box 检验，这是一个强大的工具，用于量化评估模型残差中是否存在显著的自相关性 。",
            "id": "3098986",
            "problem": "给定一个场景，其中一名开发人员模拟了单个服务器排队系统在离散时间步长上的吞吐量。在时间索引 $t$ 处的观测吞吐量表示为 $y_t$，其中 $t = 1, 2, \\dots, n$。模拟器将 $y_t$ 构建为一个计数，该计数由一个时变速率生成，该速率包含一个确定性趋势和一个可能表现出自相关的随机分量。您的任务是使用 Ljung–Box 检验来测试从 $y_t$ 中移除线性趋势后，残差是否仍然表现出自相关。\n\n从时间序列中自协方差和自相关的核心定义以及白噪声的性质出发，推导出用于聚合多个滞后期的样本自相关性的检验统计量，以评估残差的行为是否符合白噪声。原假设是残差在指定的最大滞后期内是白噪声。使用原假设下的分布结果计算 $p$ 值，并根据给定的显著性水平决定是否拒绝原假设。\n\n模拟器通过以下过程生成 $y_t$：\n1. 一个一阶潜自回归 (AR) 模型，定义为 $a_t = \\phi a_{t-1} + \\eta_t$，其中 $a_0 = 0$，且新息 $\\eta_t \\sim \\mathcal{N}(0, \\sigma^2)$ 在 $t$ 上独立同分布。\n2. 一个时变速率 $\\lambda_t = \\lambda_0 \\left(1 + s \\frac{t}{n}\\right) \\exp(a_t)$。\n3. 观测吞吐量 $y_t$ 是以速率 $\\lambda_t$ 生成的泊松计数。\n\n通过拟合普通最小二乘 (OLS) 线性模型 $y_t \\approx \\beta_0 + \\beta_1 t$（其中 $t = 1, 2, \\dots, n$）来执行去趋势操作，并形成残差 $r_t = y_t - (\\hat{\\beta}_0 + \\hat{\\beta}_1 t)$。\n\n计算残差在每个滞后 $k$（$k = 1, 2, \\dots, h$）处的样本自相关 $\\hat{\\rho}_k$，计算聚合这些 $\\hat{\\rho}_k$ 的检验统计量，从其零分布中获取 $p$ 值，并根据 $p$ 值是否小于指定的显著性水平 $\\alpha$ 来判断是否存在残差自相关。\n\n您的程序必须实现上述过程，并为以下测试套件生成结果。每个测试用例由元组 $(n, \\lambda_0, s, \\phi, \\sigma, h, \\alpha)$ 指定：\n- 测试用例 1：$(n = 200, \\lambda_0 = 10, s = 0.5, \\phi = 0, \\sigma = 0.2, h = 20, \\alpha = 0.05)$。\n- 测试用例 2：$(n = 200, \\lambda_0 = 10, s = 0.5, \\phi = 0.7, \\sigma = 0.2, h = 20, \\alpha = 0.05)$。\n- 测试用例 3：$(n = 120, \\lambda_0 = 6, s = 0, \\phi = 0.9, \\sigma = 0.25, h = 15, \\alpha = 0.01)$。\n- 测试用例 4：$(n = 40, \\lambda_0 = 8, s = 0.4, \\phi = 0, \\sigma = 0.5, h = 10, \\alpha = 0.05)$。\n\n对于每个测试用例，您的程序应输出一个布尔值，指示在水平 $\\alpha$ 下是否拒绝残差为白噪声的原假设。也就是说，如果检测到残差自相关，则输出 $\\text{True}$，否则输出 $\\text{False}$。您的程序应生成单行输出，其中包含四个测试用例的结果，格式为方括号内以逗号分隔的列表，例如 $[\\text{False},\\text{True},\\text{True},\\text{False}]$。此问题不涉及物理单位，并且所有角度（如果存在）都将以弧度为单位，但此处不需要。请按规定将所有数值结果表示为布尔值。",
            "solution": "问题陈述已经过验证，被认为是合理的。它在科学上基于时间序列分析和统计假设检验的原理，问题设定良好，具有明确的目标和一套完整的参数，并且不包含内部矛盾或含糊之处。\n\n任务是确定在移除线性趋势后，模拟的时间序列中是否存在残差自相关。这涉及一个三步过程：数据模拟、通过普通最小二乘法 (OLS) 去趋势，以及使用 Ljung-Box 检验进行假设检验。\n\n**1. 数据生成过程**\n\n观测数据 $y_t$ 表示在 $t = 1, 2, \\dots, n$ 上模拟的计数过程。$y_t$ 的值是从具有时变速率 $\\lambda_t$ 的泊松分布中抽取的随机变量：\n$$ y_t \\sim \\text{Poisson}(\\lambda_t) $$\n速率 $\\lambda_t$ 的构造包括一个确定性趋势和一个随机的、可能自相关的分量：\n$$ \\lambda_t = \\lambda_0 \\left(1 + s \\frac{t}{n}\\right) \\exp(a_t) $$\n这里，$\\lambda_0$ 是一个基准速率，项 $(1 + s \\frac{t}{n})$ 引入了一个由参数 $s$ 缩放的在时间区间上的线性趋势，而 $\\exp(a_t)$ 引入了随机波动。随机项 $a_t$ 由一阶自回归 AR(1) 过程生成：\n$$ a_t = \\phi a_{t-1} + \\eta_t $$\n初始条件为 $a_0 = 0$，新息 $\\eta_t$ 是从均值为 0、方差为 $\\sigma^2$ 的正态分布中独立同分布地抽取的，记为 $\\eta_t \\sim \\mathcal{N}(0, \\sigma^2)$。参数 $\\phi$ 是 AR(1) 过程的自相关系数。如果 $\\phi=0$，$a_t = \\eta_t$ 是一个白噪声过程。如果 $\\phi \\neq 0$，序列 $\\{a_t\\}$ 是序列相关的，这反过来又会在观测序列 $\\{y_t\\}$ 中引发自相关。\n\n**2. 去趋势与残差**\n\n问题要求从观测数据 $\\{y_t\\}$ 中移除线性趋势。这是通过使用普通最小二乘法 (OLS) 拟合一个简单的线性回归模型来完成的：\n$$ y_t = \\beta_0 + \\beta_1 t + \\epsilon_t $$\nOLS 方法找到最小化误差平方和的估计值 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$。拟合值为 $\\hat{y}_t = \\hat{\\beta}_0 + \\hat{\\beta}_1 t$。残差代表移除线性趋势后的数据，其计算公式为：\n$$ r_t = y_t - \\hat{y}_t = y_t - (\\hat{\\beta}_0 + \\hat{\\beta}_1 t) $$\n核心问题是这个残差序列 $\\{r_t\\}$ 的行为是否像白噪声。\n\n**3. 用于自相关的 Ljung-Box 检验**\n\nLjung-Box 检验用于检验原假设 ($H_0$)：一个观测序列是独立分布的（即，是白噪声）。备择假设 ($H_1$) 是观测值并非独立分布，并且表现出序列相关性。\n\n该检验首先计算残差序列 $\\{r_t\\}$ 在指定数量的滞后期（$k = 1, 2, \\dots, h$）的样本自相关。滞后 $k$ 处的样本自相关定义为：\n$$ \\hat{\\rho}_k = \\frac{\\sum_{t=k+1}^n (r_t - \\bar{r})(r_{t-k} - \\bar{r})}{\\sum_{t=1}^n (r_t - \\bar{r})^2} $$\n其中 $n$ 是残差的数量，$\\bar{r}$ 是残差的样本均值。带有截距项的 OLS 的一个性质是残差之和为零，因此 $\\bar{r} = 0$，这简化了计算。\n\nLjung-Box 检验统计量 $Q$ 聚合了前 $h$ 个滞后的样本自相关平方：\n$$ Q = n(n+2) \\sum_{k=1}^h \\frac{\\hat{\\rho}_k^2}{n-k} $$\n该统计量提供了直至滞后 $h$ 的总体自相关的单一衡量标准。分母中的项 $(n-k)$ 是对早期 Box-Pierce 统计量的有限样本修正。\n\n在残差 $\\{r_t\\}$ 是白噪声的原假设下，$Q$ 统计量近似服从卡方 ($\\chi^2$) 分布的随机变量。该分布的自由度 ($df$) 为 $h$。虽然在检验来自拟合的 ARMA 模型的残差时需要调整自由度（通过减去拟合的 ARMA 参数数量），但对于来自对确定性变量（如时间趋势）进行回归的残差，通常不应用此类调整。因此，我们使用 $df = h$。\n\n拒绝或未能拒绝原假设的决定基于 $p$ 值。$p$ 值是在假设 $H_0$ 为真的情况下，观测到至少与计算出的 $Q$ 统计量一样大的值的概率：\n$$ p\\text{-value} = P(\\chi^2_h > Q_{obs}) $$\n其中 $Q_{obs}$ 是从数据中计算出的统计量的值。如果 $p$ 值小于预定的显著性水平 $\\alpha$，我们拒绝原假设，并得出结论：残差表现出显著的序列相关性。如果 $p\\text{-value} \\ge \\alpha$，我们未能拒绝 $H_0$，这意味着没有足够的证据得出残差不是白噪声的结论。如果 $H_0$ 被拒绝，程序将输出 $\\text{True}$，否则输出 $\\text{False}$。\n\n为每个提供的测试用例实现了这个完整的程序。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Simulates time series data, detrends it, and performs the Ljung-Box test\n    for autocorrelation on the residuals.\n    \"\"\"\n    # Set a random seed for reproducibility of the stochastic simulation.\n    np.random.seed(0)\n    \n    # Test cases defined as (n, lambda_0, s, phi, sigma, h, alpha)\n    test_cases = [\n        (200, 10, 0.5, 0.0, 0.2, 20, 0.05),\n        (200, 10, 0.5, 0.7, 0.2, 20, 0.05),\n        (120, 6, 0.0, 0.9, 0.25, 15, 0.01),\n        (40, 8, 0.4, 0.0, 0.5, 10, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, lambda_0, s, phi, sigma, h, alpha = case\n\n        # Step 1: Simulate the time series data\n        # Generate innovations eta_t ~ N(0, sigma^2) for the AR(1) process\n        eta = np.random.normal(loc=0.0, scale=sigma, size=n)\n\n        # Generate the latent AR(1) process a_t = phi * a_{t-1} + eta_t with a_0=0\n        a = np.zeros(n)\n        if n > 0:\n            # For t=1 (index 0), a_1 = phi*a_0 + eta_1 = eta_1\n            a[0] = eta[0]\n            for t in range(1, n):\n                a[t] = phi * a[t-1] + eta[t]\n        \n        # Generate the time-varying rate lambda_t\n        t_vals = np.arange(1, n + 1)\n        lambda_t = lambda_0 * (1.0 + s * t_vals / n) * np.exp(a)\n\n        # Generate the observed throughput y_t ~ Poisson(lambda_t)\n        y_t = np.random.poisson(lam=lambda_t)\n\n        # Step 2: Detrend the series using Ordinary Least Squares (OLS)\n        # Create the design matrix X for the linear model y_t = beta_0 + beta_1*t\n        X = np.vstack([np.ones(n), t_vals]).T\n        \n        # Fit the OLS model using np.linalg.lstsq\n        try:\n            beta = np.linalg.lstsq(X, y_t, rcond=None)[0]\n        except np.linalg.LinAlgError:\n            # Handle cases where the fit fails, though unlikely here\n            results.append(False) \n            continue\n        \n        # Calculate the fitted values and the residuals\n        y_hat = X @ beta\n        residuals = y_t - y_hat\n\n        # Step 3: Perform the Ljung-Box test on the residuals\n        n_res = len(residuals)\n        \n        # Center the residuals (mean is computationally near zero for OLS with intercept)\n        r_centered = residuals - np.mean(residuals)\n        \n        # Calculate sample autocorrelations rho_k for lags k=1,...,h\n        # First, calculate autocovariances using np.correlate\n        autocov = np.correlate(r_centered, r_centered, mode='full')\n        \n        # The autocovariance at lag 0 (gamma_0) is the middle element\n        gamma_0 = autocov[n_res - 1]\n        \n        rho_hat_sq = np.zeros(h)\n        if gamma_0 > 1e-12:  # Avoid division by zero if variance is zero\n            # Autocovariances for lags 1 to h are at indices n to n+h-1\n            autocov_lags = autocov[n_res : n_res + h]\n            rho_hats = autocov_lags / gamma_0\n            rho_hat_sq = rho_hats**2\n\n        # Calculate the Ljung-Box Q statistic\n        k_vals = np.arange(1, h + 1)\n        \n        # The divisor term n-k; ensure no division by a non-positive number\n        divisors = n_res - k_vals\n        valid_indices = divisors > 0\n\n        reject_null = False\n        if np.any(valid_indices):\n            # Sum only over lags k where n-k > 0\n            Q = n_res * (n_res + 2) * np.sum(rho_hat_sq[valid_indices] / divisors[valid_indices])\n            \n            # Degrees of freedom for the chi-squared distribution is h\n            # for residuals from regression on deterministic variables.\n            df = h\n            \n            # Compute the p-value from the chi-squared distribution's survival function\n            p_value = chi2.sf(Q, df)\n            \n            # Step 4: Make a decision based on the significance level alpha\n            if p_value < alpha:\n                reject_null = True\n\n        results.append(reject_null)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}