{
    "hands_on_practices": [
        {
            "introduction": "本次实践是一个经典的入门练习。我们将通过求解方程 $x = \\cos(x)$ 来具体观察一个行为良好的不动点迭代过程，并验证压缩映射定理的条件。这个练习旨在通过一个直观的例子，让你深入理解不动点迭代为何以及如何收敛，从而为后续更复杂的分析奠定坚实的基础。",
            "id": "3231288",
            "problem": "考虑在闭区间 $[0,1]$ 上定义的不动点方程 $x=\\cos x$ 和不动点迭代 $x_{k+1}=\\cos x_k$。使用以下基本依据：对于函数 $g$，不动点 $x^\\star$ 满足 $x^\\star=g(x^\\star)$ 的定义、中值定理（MVT）以及压缩映射定理（CMT），也称为巴拿赫不动点定理。迭代使用弧度作为角度单位。您的程序必须实现该迭代，并为指定的测试套件验证其收敛性和单调性。\n\n任务：\n- 从基本定义出发，论证为什么函数 $g(x)=\\cos x$ 将 $[0,1]$ 映射到自身。使用导数 $g'(x)=-\\sin x$ 和界 $\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1)$（其中 $\\sin(1)1$）来论证 $g$ 在 $[0,1]$ 上是一个压缩映射，因此存在唯一的不动点 $x^\\star\\in[0,1]$，对于任意 $x_0\\in[0,1]$，序列 $\\{x_k\\}$ 都收敛于该不动点。\n- 分析迭代序列的单调性。由于 $g$ 在 $[0,1]$ 上是严格递减的，因此完整序列 $\\{x_k\\}$ 通常不是单调的。然而，证明偶数子序列 $\\{x_{2k}\\}$ 和奇数子序列 $\\{x_{2k+1}\\}$ 各自是单调的，并且收敛于相同的极限 $x^\\star$。\n- 实现一个程序，对所提供的测试套件中的每个初始值 $x_0$，执行不动点迭代 $x_{k+1}=\\cos x_k$，直到相邻迭代之差满足 $|x_{k+1}-x_k|10^{-12}$ 或达到最大迭代次数 $1000$ 次为止。存储每个测试用例的完整迭代序列。角度单位必须是弧度。\n- 对于每个测试用例，计算并报告：\n  1. 初始值 $x_0$。\n  2. 停止后不动点的最终近似值，记为 $x_{\\text{approx}}$。\n  3. 执行的迭代次数 $N$。\n  4. 一个布尔值，指示完整序列 $\\{x_k\\}_{k=0}^N$ 是否是单调的（非递减或非递增）。\n  5. 一个布尔值，指示偶数索引子序列 $\\{x_{2k}\\}$ 是否是单调的（非递减或非递增）。\n  6. 一个布尔值，指示奇数索引子序列 $\\{x_{2k+1}\\}$ 是否是单调的（非递减或非递增）。\n- 使用以下初始值测试套件（均为弧度）：$x_0\\in\\{0,\\,\\tfrac{1}{2},\\,1,\\,0.7390851332151607\\}$。最后一个值是唯一不动点 $x^\\star$ 的高精度近似值。\n- 最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是 $[x_0,x_{\\text{approx}},N,\\text{is\\_monotone\\_full},\\text{is\\_monotone\\_even},\\text{is\\_monotone\\_odd}]$ 的精确形式列表。例如，总输出将类似于 $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot]]$，其中四个内部列表对应四个测试用例。\n\n上述所有数值在您的程序中都必须作为标量处理。程序不得读取任何输入，并且必须打印所需的单行作为其唯一输出。",
            "solution": "我们首先回顾基本定义和事实。函数 $g$ 的不动点是一个满足 $x^\\star=g(x^\\star)$ 的值 $x^\\star$。数值不动点迭代通过 $x_{k+1}=g(x_k)$ 构建一个序列 $\\{x_k\\}$，并寻求一个极限 $x^\\star$，使得 $x_k\\to x^\\star$ 且 $x^\\star=g(x^\\star)$。压缩映射定理（CMT）指出，如果 $g$ 将一个完备度量空间映射到其自身，并且对于定义域中的所有 $x,y$，都满足利普希茨界 $|g(x)-g(y)|\\le L|x-y|$（其中常数 $L1$），那么 $g$ 存在唯一的不动点 $x^\\star$，并且对于定义域中的任意初始值 $x_0$，迭代 $x_{k+1}=g(x_k)$ 收敛于 $x^\\star$。\n\n我们分析函数 $g(x)=\\cos x$ 在闭区间 $[0,1]$ 上的性质。首先，我们证明 $g$ 将 $[0,1]$ 映射到其自身。对于 $x\\in[0,1]$，我们有 $\\cos x\\in[\\cos 1,\\,\\cos 0]=[\\cos 1,\\,1]$。由于 $\\cos 10$，因此 $g([0,1])\\subset[0,1]$。接下来，我们计算导数 $g'(x)=-\\sin x$。在 $[0,1]$上，函数 $\\sin x$ 是非负的，且上界为 $\\sin 1$，因此\n$$\n\\sup_{x\\in[0,1]}|g'(x)|=\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1).\n$$\n由于 $\\sin(1)1$，我们可以使用中值定理（MVT）推导出利普希茨界：对于任意 $x,y\\in[0,1]$，\n$$\n|g(x)-g(y)|=|\\cos x-\\cos y|=|g'(\\xi)|\\,|x-y|\\le \\sin(1)\\,|x-y|,\n$$\n其中 $\\xi$ 介于 $x$ 和 $y$ 之间。因此 $g$ 是在 $[0,1]$ 上的一个压缩映射，压缩常数为 $L=\\sin(1)1$。根据压缩映射定理，存在唯一的不动点 $x^\\star\\in[0,1]$，并且对于任意 $x_0\\in[0,1]$，由 $x_{k+1}=\\cos x_k$ 定义的序列收敛于 $x^\\star$。\n\n我们接下来分析单调性。注意 $g$ 在 $[0,1]$ 上是严格递减的，因为 $g'(x)=-\\sin x\\le 0$，且对于 $x\\in(0,1]$，我们有 $\\sin x>0$。设 $x^\\star$ 是唯一不动点。考虑误差 $e_k=x_k-x^\\star$。使用中值定理，存在 $\\xi_k$ 介于 $x_k$ 和 $x^\\star$ 之间，使得\n$$\ne_{k+1}=x_{k+1}-x^\\star=g(x_k)-g(x^\\star)=g'(\\xi_k)\\,(x_k-x^\\star)=-\\sin(\\xi_k)\\,e_k.\n$$\n在 $[0,1]$ 上，$\\sin(\\xi_k)\\in[0,\\sin(1)]$，并且只要 $\\sin(\\xi_k)>0$，$e_{k+1}$ 的符号就与 $e_k$ 的符号相反。因此，除非 $e_k=0$，误差的符号会交替变化，所以完整序列 $\\{x_k\\}$ 通常是振荡的，而不是单调的。然而，我们可以推断出子序列的单调行为。由于 $g(x) = \\cos x$ 在 $[0,1]$ 上是递减函数，其复合函数 $h(x)=g(g(x)) = \\cos(\\cos x)$ 是递增函数。偶数项子序列 $\\{x_{2k}\\}$ 满足 $x_{2(k+1)} = h(x_{2k})$。由于 $h$ 是递增的，如果 $x_0  x_2$，则子序列 $\\{x_{2k}\\}$ 单调递增；如果 $x_0 > x_2$，则单调递减。奇数项子序列 $\\{x_{2k+1}\\}$ 同样由递增的 $h$ 映射生成（$x_{2k+3}=h(x_{2k+1})$），因此它也是单调的。两个子序列都有界（在 $[0,1]$ 内），因此它们都收敛。由于整个序列 $\\{x_k\\}$ 收敛到唯一的不动点 $x^\\star$，这两个子序列必然收敛到同一个极限 $x^\\star$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fixed_point_cos(x0, tol=1e-12, max_iter=1000):\n    \"\"\"\n    Perform fixed-point iteration x_{k+1} = cos(x_k) starting from x0.\n    Angles are in radians.\n    Returns:\n        x_approx: final approximation\n        iterations: number of iterations performed\n        seq: list of iterates including the initial value\n    \"\"\"\n    seq = [float(x0)]\n    x_prev = float(x0)\n    iterations = 0\n    for k in range(max_iter):\n        x_next = float(np.cos(x_prev))\n        seq.append(x_next)\n        iterations += 1\n        if abs(x_next - x_prev)  tol:\n            break\n        x_prev = x_next\n    return seq[-1], iterations, seq\n\ndef is_monotone(sequence, tol=0.0):\n    \"\"\"\n    Check if a sequence is monotone nondecreasing or monotone nonincreasing.\n    Equality is allowed.\n    tol can be used to soften comparisons, but defaults to strict.\n    \"\"\"\n    if len(sequence) = 1:\n        return True\n    diffs = [sequence[i+1] - sequence[i] for i in range(len(sequence)-1)]\n    nondecreasing = all(d >= -tol for d in diffs)\n    nonincreasing = all(d = tol for d in diffs)\n    return nondecreasing or nonincreasing\n\ndef solve():\n    # Define the test cases from the problem statement (radians).\n    test_cases = [\n        0.0,\n        0.5,\n        1.0,\n        0.7390851332151607,  # high-precision approximation to the fixed point\n    ]\n\n    results = []\n    for x0 in test_cases:\n        x_approx, iters, seq = fixed_point_cos(x0, tol=1e-12, max_iter=1000)\n        # Full sequence monotonicity\n        mono_full = is_monotone(seq, tol=0.0)\n        # Even-indexed subsequence: indices 0,2,4,...\n        even_seq = seq[0::2]\n        mono_even = is_monotone(even_seq, tol=0.0)\n        # Odd-indexed subsequence: indices 1,3,5,...\n        odd_seq = seq[1::2]\n        mono_odd = is_monotone(odd_seq, tol=0.0)\n        # Assemble result for this test case\n        results.append([x0, x_approx, iters, mono_full, mono_even, mono_odd])\n\n    # Final print statement in the exact required format.\n    inner_parts = []\n    for res in results:\n        # Format booleans as lowercase true/false for Python consistency\n        # and assemble the list string without spaces.\n        formatted_res = [f'{v}' for v in res]\n        inner_parts.append(f\"[{','.join(formatted_res)}]\")\n    print(f\"[{','.join(inner_parts)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "并非所有看似合理的不动点迭代都能收敛。本次实践将分析一个典型的失败案例，$x_{k+1} = a/x_k$，它不会收敛到不动点，而是在两个值之间振荡。通过引入“阻尼”或“松弛”迭代法，你将学会如何将一个发散的过程转化为收敛的过程，甚至找到最优的收敛速度，这展示了诊断和修复数值方法的关键技能。",
            "id": "3130607",
            "problem": "给定一个正常数 $a$，考虑不动点方程 $x^{\\ast} = \\frac{a}{x^{\\ast}}$，其迭代函数为定义在域 $\\mathbb{R} \\setminus \\{0\\}$ 上的 $g(x) = \\frac{a}{x}$。在本科中级水平的不动点迭代框架内进行分析。仅从不动点、不动点迭代 $x_{k+1} = g(x_{k})$ 的核心定义，以及围绕不动点进行局部误差分析的一阶泰勒展开出发，完成以下任务：\n\n1. 对于 $a0$，确定 $g(x)$ 的所有实不动点 $x^{\\ast}$。\n2. 使用不动点迭代的定义和 $g(x)$ 在不动点 $x^{\\ast}$ 附近的一阶泰勒展开，推导无阻尼迭代 $x_{k+1} = g(x_{k})$ 的局部误差传播因子，并评估在 $x^{\\ast}$ 附近是否发生局部收敛。\n3. 通过代数方法将 $g$ 与自身复合来分析无阻尼迭代的全局行为，并解释为何对于非不动点的一般初始值 $x_{0} \\in \\mathbb{R} \\setminus \\{0\\}$，全局收敛会失败。\n4. 提出一个形式为 $x_{k+1} = (1 - \\alpha)\\,x_{k} + \\alpha\\,g(x_{k})$ 的阻尼迭代，其中阻尼参数为 $\\alpha \\in \\mathbb{R}$。使用相同的一阶泰勒框架，推导在不动点 $x^{\\ast}$ 处的局部误差传播因子（作为 $\\alpha$ 的函数），并确定能实现局部收敛的 $\\alpha$ 值的集合。\n5. 在能实现局部收敛的 $\\alpha$ 值中，找到使不动点处线性化误差放大因子模长最小的 $\\alpha$ 值，从而优化局部收敛速率。\n\n将你的最终答案表示为单个最优 $\\alpha$ 值。不需要单位。提供精确值，不要四舍五入。",
            "solution": "首先对问题进行验证，以确保其科学上合理、良定且客观。\n\n**问题验证**\n\n**第 1 步：提取已知条件**\n- 给定一个正常数 $a$，因此 $a0$。\n- 不动点方程为 $x^{\\ast} = \\frac{a}{x^{\\ast}}$。\n- 迭代函数为 $g(x) = \\frac{a}{x}$。\n- $g(x)$ 的定义域为 $\\mathbb{R} \\setminus \\{0\\}$。\n- 框架为不动点迭代，使用核心定义和一阶泰勒展开进行局部误差分析。\n- 标准不动点迭代为 $x_{k+1} = g(x_{k})$。\n- 提出了一个阻尼迭代 $x_{k+1} = (1 - \\alpha)\\,x_{k} + \\alpha\\,g(x_{k})$，其中阻尼参数为 $\\alpha \\in \\mathbb{R}$。\n\n**第 2 步：使用提取的已知条件进行验证**\n- **科学基础：** 该问题是数值分析中的一个标准练习，侧重于不动点迭代、收敛性分析和松弛法。所有概念在数学上都是良定的，并且是该主题的基础。\n- **良定性：** 问题陈述清晰，包含所有必要信息。任务是顺序的，并且在逻辑上层层递进。可以确定最优参数 $\\alpha$ 的唯一解。\n- **客观性：** 语言是形式化和数学化的，没有主观性或模糊性。\n\n**结论：** 问题被认为是有效且自洽的。可以进行求解过程。\n\n**问题求解**\n\n**1. 确定不动点**\n函数 $g(x)$ 的不动点 $x^{\\ast}$ 满足方程 $x^{\\ast} = g(x^{\\ast})$。\n代入给定的函数 $g(x) = \\frac{a}{x}$，我们得到：\n$$x^{\\ast} = \\frac{a}{x^{\\ast}}$$\n假设 $x^{\\ast} \\neq 0$，这与 $g(x)$ 的定义域一致，我们可以两边乘以 $x^{\\ast}$ 得到：\n$$(x^{\\ast})^2 = a$$\n因为给定 $a  0$，所以 $x^{\\ast}$ 有两个实数解：\n$$x^{\\ast} = \\sqrt{a} \\quad \\text{和} \\quad x^{\\ast} = -\\sqrt{a}$$\n这就是函数 $g(x)$ 的两个实不动点。\n\n**2. 无阻尼迭代的局部收敛性分析**\n无阻尼不动点迭代由 $x_{k+1} = g(x_k)$ 给出。设第 $k$ 次迭代的误差为 $\\epsilon_k = x_k - x^{\\ast}$，其中 $x^{\\ast}$ 是一个不动点。那么 $x_k = x^{\\ast} + \\epsilon_k$。\n下一次迭代的误差是 $\\epsilon_{k+1} = x_{k+1} - x^{\\ast}$。\n代入迭代规则：\n$$x^{\\ast} + \\epsilon_{k+1} = g(x^{\\ast} + \\epsilon_k)$$\n我们对 $g(x)$ 在不动点 $x^{\\ast}$ 附近进行一阶泰勒展开：\n$$g(x^{\\ast} + \\epsilon_k) \\approx g(x^{\\ast}) + g'(x^{\\ast}) \\epsilon_k$$\n因为 $x^{\\ast}$ 是一个不动点，所以 $g(x^{\\ast}) = x^{\\ast}$。展开式变为：\n$$g(x^{\\ast} + \\epsilon_k) \\approx x^{\\ast} + g'(x^{\\ast}) \\epsilon_k$$\n将此代回误差方程：\n$$x^{\\ast} + \\epsilon_{k+1} \\approx x^{\\ast} + g'(x^{\\ast}) \\epsilon_k$$\n这可以简化为局部误差传播公式：\n$$\\epsilon_{k+1} \\approx g'(x^{\\ast}) \\epsilon_k$$\n项 $g'(x^{\\ast})$ 是局部误差传播因子。为了使迭代局部收敛，该因子的模必须小于 $1$，即 $|g'(x^{\\ast})|  1$。\n\n让我们计算 $g(x) = \\frac{a}{x} = a x^{-1}$ 的导数 $g'(x)$：\n$$g'(x) = -a x^{-2} = -\\frac{a}{x^2}$$\n现在，我们在不动点处计算这个导数。对于 $x^{\\ast} = \\sqrt{a}$ 和 $x^{\\ast} = -\\sqrt{a}$，我们都有 $(x^{\\ast})^2 = a$。\n$$g'(x^{\\ast}) = -\\frac{a}{(x^{\\ast})^2} = -\\frac{a}{a} = -1$$\n误差传播因子的模为 $|g'(x^{\\ast})| = |-1| = 1$。由于不满足局部收敛条件 $|g'(x^{\\ast})|  1$，迭代不保证局部收敛到任何一个不动点。在这种临界情况下，线性分析表明误差的符号会振荡，而其大小不会减小，因此无法收敛。\n\n**3. 无阻尼迭代的全局行为**\n为了分析全局行为，我们考察从任意 $x_0 \\in \\mathbb{R} \\setminus \\{0\\}$ 开始的迭代序列 $x_0, x_1, x_2, \\ldots$。\n第一次迭代的结果是 $x_1 = g(x_0) = \\frac{a}{x_0}$。\n第二次迭代的结果是 $x_2 = g(x_1) = g\\left(\\frac{a}{x_0}\\right) = \\frac{a}{a/x_0} = x_0$。\n第三次迭代的结果是 $x_3 = g(x_2) = g(x_0) = x_1 = \\frac{a}{x_0}$。\n迭代序列为 $x_0, \\frac{a}{x_0}, x_0, \\frac{a}{x_0}, \\ldots$。\n这个序列只有在各项相等时才收敛，即 $x_0 = \\frac{a}{x_0}$，这意味着 $x_0^2 = a$。这个条件只有在初始值 $x_0$ 是不动点之一，$x_0 = \\pm\\sqrt{a}$ 时才满足。对于任何其他初始值 $x_0$，序列会在两个不同的值之间无限振荡，并且不会收敛。这证实了全局收敛的失败。\n\n**4. 阻尼迭代及其局部收敛性**\n阻尼迭代使用一个新的迭代函数，我们记为 $G(x)$：\n$$G(x) = (1 - \\alpha)x + \\alpha\\,g(x)$$\n这个新迭代的不动点满足 $x^{\\ast} = G(x^{\\ast})$。\n$$x^{\\ast} = (1 - \\alpha)x^{\\ast} + \\alpha\\,g(x^{\\ast})$$\n$$0 = -\\alpha x^{\\ast} + \\alpha\\,g(x^{\\ast})$$\n$$\\alpha(g(x^{\\ast}) - x^{\\ast}) = 0$$\n对于任何 $\\alpha \\neq 0$，这要求 $g(x^{\\ast}) = x^{\\ast}$，意味着 $G(x)$ 的不动点与 $g(x)$ 的不动点相同，即 $x^{\\ast} = \\pm\\sqrt{a}$。$\\alpha=0$ 的情况是平凡的，因为 $G(x)=x$，每个点都是不动点。\n\n阻尼迭代的局部误差传播因子是 $G'(x^{\\ast})$。我们首先计算导数 $G'(x)$：\n$$G'(x) = \\frac{d}{dx} \\left[ (1 - \\alpha)x + \\alpha\\,g(x) \\right] = 1 - \\alpha + \\alpha\\,g'(x)$$\n在不动点 $x^{\\ast}$ 处计算该导数，并代入 $g'(x^{\\ast}) = -1$：\n$$G'(x^{\\ast}) = 1 - \\alpha + \\alpha(-1) = 1 - 2\\alpha$$\n为了实现局部收敛，我们需要 $|G'(x^{\\ast})|  1$。\n$$|1 - 2\\alpha|  1$$\n这个不等式等价于 $-1  1 - 2\\alpha  1$。\n解左边的不等式：\n$$-1  1 - 2\\alpha \\implies -2  -2\\alpha \\implies 1 > \\alpha$$\n解右边的不等式：\n$$1 - 2\\alpha  1 \\implies -2\\alpha  0 \\implies \\alpha > 0$$\n结合这两个条件，能实现局部收敛的 $\\alpha$ 值的集合是开区间 $(0, 1)$，即 $0  \\alpha  1$。\n\n**5. 最优阻尼参数**\n当线性化误差放大因子的模 $|G'(x^{\\ast})|$ 最小时，局部收敛速率最快。我们需要在收敛区间 $(0, 1)$ 内找到使 $|1 - 2\\alpha|$ 最小的 $\\alpha$ 值。\n函数 $f(\\alpha) = |1 - 2\\alpha|$ 的最小值为 $0$。这个最小值在自变量为零时取得：\n$$1 - 2\\alpha = 0$$\n$$2\\alpha = 1$$\n$$\\alpha = \\frac{1}{2}$$\n这个 $\\alpha$ 值位于收敛区间 $(0, 1)$ 内。在此值下，误差放大因子为 $G'(x^{\\ast}) = 1 - 2(\\frac{1}{2}) = 0$，这对应于最快的可能局部收敛速率（至少是二次的）。因此，这个 $\\alpha$ 值是最优的。\n得到的迭代式为 $x_{k+1} = \\frac{1}{2}x_k + \\frac{1}{2}\\frac{a}{x_k} = \\frac{1}{2}\\left(x_k + \\frac{a}{x_k}\\right)$，这是著名的用于求 $a$ 的平方根的牛顿-拉夫逊迭代法。\n阻尼参数 $\\alpha$ 的最优值为 $\\frac{1}{2}$。",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "有时即使迭代收敛，其速度也可能非常缓慢，缺乏实用价值。本次实践将构造一个压缩常数接近 $1$ 的例子，它会导致缓慢的线性收敛。你将学习并实现埃特金($\\text{Aitken}$) $\\Delta^2$ 加速法，这是一种强大的序列加速技术，能够显著提升收敛效率，并让你亲手量化其带来的巨大改进。",
            "id": "3130626",
            "problem": "考虑在实数线上的一维不动点迭代，该迭代由一个映射 $g:\\mathbb{R}\\to\\mathbb{R}$ 定义，该映射是一个利普希茨常数 $L\\in[0,1)$ 的压缩映射。使用压缩映射的基本定义：对于所有 $x,y\\in\\mathbb{R}$，有 $|g(x)-g(y)|\\le L|x-y|$，以及不动点迭代的定义 $x_{k+1}=g(x_k)$。您的目标是构建并分析一个映射族，当收缩常数 $L$ 接近 $1$ 时，该族表现出缓慢的线性收敛，然后应用一种经典的加速技术来量化改进效果。\n\n使用仿射族\n$g(x)=L\\,x+(1-L)\\,c,$\n其中 $c\\in\\mathbb{R}$ 是一个已知常数。只要 $L\\in[0,1)$，这个族就是一个压缩映射，其不动点是满足 $x^\\star=g(x^\\star)$ 的值 $x^\\star$。\n\n仅从核心定义出发，执行以下任务。\n\n- 任务 A（普通不动点迭代）：对于给定的 $L\\in[0,1)$、不动点目标 $c\\in\\mathbb{R}$、初始猜测值 $x_0\\in\\mathbb{R}$ 和容差 $\\varepsilon0$，确定未加速的不动点迭代 $x_{k+1}=g(x_k)$ 产生一个迭代值 $x_k$ 使得 $|x_k-c|\\le\\varepsilon$ 所需的最小 $g$ 函数求值次数。每次迭代计为一次 $g$ 函数的求值。仅使用问题数据中直接定义的量。\n\n- 任务 B（加速）：对不动点迭代应用标准的序列加速，特别是埃特金 $\\Delta^2$ 过程（当应用于不动点迭代时也称为 Steffensen 加速）。使用经典的三点变换将连续应用 $g$ 产生的三元组 $(x_k,x_{k+1},x_{k+2})$ 转换为一个加速估计值 $\\hat{x}_k$。计算获得一个满足 $|\\hat{x}_k-c|\\le\\varepsilon$ 的加速估计值所需的 $g$ 函数求值次数，其中每个加速估计值需要在当前 $x_k$ 的基础上额外两次 $g$ 函数的求值来形成 $(x_{k+1},x_{k+2})$。如果某一步由于数值退化而无法应用该变换，则根据需要继续生成下一个三元组。\n\n- 任务 C（量化改进）：对于每种情况，计算加速比，即普通不动点迭代所需的求值次数与加速方法所需次数的比值。将此加速比表示为小数。\n\n设计您的程序以解决以下测试套件。在所有情况下，使用相同的容差 $\\varepsilon=10^{-8}$、初始猜测值 $x_0=c+1$ 和不动点目标 $c=3$。\n\n- 情况 1：$L=0.9$。\n- 情况 2：$L=0.99$。\n- 情况 3：$L=0.0$（边界情况）。\n- 情况 4：$L=0.9999$（接近边界，普通收敛非常缓慢）。\n\n您的程序必须输出单行，由方括号括起来的逗号分隔列表组成，其中每个元素对应一种情况，并且本身是一个形式为 $[N_{\\text{plain}},N_{\\text{acc}},S]$ 的列表：\n- $N_{\\text{plain}}$ 是普通不动点迭代达到 $|x_k-c|\\le\\varepsilon$ 所需的最小 $g$ 函数求值次数。\n- $N_{\\text{acc}}$ 是 Aitken 加速方案达到 $|\\hat{x}_k-c|\\le\\varepsilon$ 所需的 $g$ 函数求值次数。\n- $S$ 是加速比 $N_{\\text{plain}}/N_{\\text{acc}}$，以小数表示。\n\n作为确切输出格式的示例，程序应打印一行，如 $[[1,2,0.5],[\\dots],[\\dots],[\\dots]]$，不含空格。\n\n此问题不涉及物理单位或角度。所有要求的输出均为指定的整数或小数。",
            "solution": "问题陈述经评估为有效。它在科学上基于不动点迭代和序列加速的数学理论，问题设定良好，提供了所有必要的数据，并使用客观、明确的语言进行表述。该问题是计算科学入门的标准练习，满足有效问题的所有标准。\n\n我们继续进行解答，该解答分为对普通不动点迭代的分析（任务 A）、对加速迭代的分析（任务 B）以及加速比的计算（任务 C）。\n\n不动点迭代由映射 $g(x) = L x + (1-L)c$ 定义，其中 $L \\in [0,1)$，迭代过程为 $x_{k+1} = g(x_k)$。该迭代的不动点 $x^\\star$ 是方程 $x^\\star = g(x^\\star)$ 的解。\n$$x^\\star = L x^\\star + (1-L)c$$\n$$x^\\star (1-L) = (1-L)c$$\n由于 $L \\in [0,1)$，项 $(1-L)$ 不为零，因此我们可以用它来除。\n$$x^\\star = c$$\n这证实了常数 $c$ 是映射 $g(x)$ 的唯一不动点。\n\n### 任务 A：普通不动点迭代\n\n我们分析序列 $x_k$ 收敛到不动点 $x^\\star = c$ 的情况。设第 $k$ 次迭代的误差为 $e_k = x_k - c$。\n$$x_{k+1} - c = g(x_k) - c$$\n$$x_{k+1} - c = (L x_k + (1-L)c) - c$$\n$$x_{k+1} - c = L x_k - Lc$$\n$$x_{k+1} - c = L(x_k - c)$$\n这给出了误差递推关系 $e_{k+1} = L e_k$。通过归纳法，第 $k$ 次迭代的误差与初始误差 $e_0 = x_0 - c$ 相关：\n$$e_k = L^k e_0$$\n终止条件是 $|x_k - c| \\le \\varepsilon$，用误差表示即为 $|e_k| \\le \\varepsilon$。\n$$|L^k e_0| \\le \\varepsilon$$\n$$|L|^k |x_0 - c| \\le \\varepsilon$$\n给定 $L \\in [0,1)$，我们有 $|L| = L$。问题指定 $x_0 = c+1$，所以 $|x_0 - c| = |(c+1) - c| = 1$。条件简化为：\n$$L^k \\le \\varepsilon$$\n我们必须找到满足此不等式的最小整数 $k \\ge 1$。获得 $x_k$ 所需的 $g$ 函数求值次数恰好为 $k$。我们将其表示为 $N_{\\text{plain}}$。初始状态 $x_0$ 是给定的，因此对于 $k=0$ 不需要求值。由于 $|x_0-c|=1$ 且 $\\varepsilon=10^{-8}$，在 $k=0$ 时条件不满足。\n\n我们必须考虑 $L$ 的两种子情况。\n\n情况 $L=0$：\n映射为 $g(x) = (1-0)c = c$。第一次迭代的值是 $x_1 = g(x_0) = c$。\n误差为 $|x_1 - c| = |c-c|=0$。由于 $0 \\le \\varepsilon$，条件在一次迭代后满足。\n因此，对于 $L=0$，$N_{\\text{plain}} = 1$。\n\n情况 $L \\in (0,1)$：\n我们通过对不等式 $L^k \\le \\varepsilon$ 两边取自然对数来求解。\n$$k \\ln(L) \\le \\ln(\\varepsilon)$$\n由于 $L \\in (0,1)$，其对数 $\\ln(L)$ 是负数。除以一个负数会反转不等号：\n$$k \\ge \\frac{\\ln(\\varepsilon)}{\\ln(L)}$$\n最小的整数 $k$ 是此表达式的向上取整。\n$$N_{\\text{plain}} = \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln(L)} \\right\\rceil$$\n\n### 任务 B：加速迭代\n\nAitken's $\\Delta^2$ 过程从给定序列 $x_k$ 生成一个加速序列 $\\hat{x}_k$。加速估计值的公式为：\n$$\\hat{x}_k = x_k - \\frac{(x_{k+1} - x_k)^2}{x_{k+2} - 2x_{k+1} + x_k}$$\n为了计算第一个加速项 $\\hat{x}_0$，我们需要三元组 $(x_0, x_1, x_2)$。这需要两次 $g$ 函数的求值：$x_1 = g(x_0)$ 和 $x_2 = g(x_1)$。要计算 $\\hat{x}_k$ 需要生成直到 $x_{k+2}$ 的序列，这需要 $k+2$ 次 $g$ 函数的求值。我们寻求找到一个估计值 $\\hat{x}_k$ 使得 $|\\hat{x}_k-c| \\le \\varepsilon$ 的最小总求值次数 $N_{\\text{acc}}$。\n\n让我们分析 Aitken 方法在仿射序列 $x_k = c + L^k(x_0-c)$ 上的性能。\n差值为：\n$$x_{k+1} - x_k = (c + L^{k+1}(x_0-c)) - (c + L^k(x_0-c)) = (L^{k+1} - L^k)(x_0-c) = L^k(L-1)(x_0-c)$$\n分母是二阶差分：\n$$x_{k+2} - 2x_{k+1} + x_k = (x_{k+2}-x_{k+1}) - (x_{k+1}-x_k)$$\n$$= L^{k+1}(L-1)(x_0-c) - L^k(L-1)(x_0-c) = (L^{k+1}-L^k)(L-1)(x_0-c)$$\n$$= L^k(L-1)(L-1)(x_0-c) = L^k(L-1)^2(x_0-c)$$\n只要 $L \\neq 0$、$L \\neq 1$ 且 $x_0 \\neq c$，分母就不为零。问题约束 $L \\in [0,1)$ 和 $x_0 = c+1$ 确保了对于 $L \\in (0,1)$ 这是成立的。\n\nAitken 公式中的修正项变为：\n$$\\frac{(x_{k+1} - x_k)^2}{x_{k+2} - 2x_{k+1} + x_k} = \\frac{\\left[L^k(L-1)(x_0-c)\\right]^2}{L^k(L-1)^2(x_0-c)} = \\frac{L^{2k}(L-1)^2(x_0-c)^2}{L^k(L-1)^2(x_0-c)} = L^k(x_0-c)$$\n将此代回 $\\hat{x}_k$ 的公式中：\n$$\\hat{x}_k = x_k - L^k(x_0-c) = (c + L^k(x_0-c)) - L^k(x_0-c) = c$$\n这个非凡的结果表明，对于仿射迭代，只要分母不为零，Aitken 方法就能在单步内产生精确的不动点 $c$。\n\n对于所有 $L \\in (0,1)$，$\\hat{x}_0$ 的分母为 $(L-1)^2(x_0-c) \\neq 0$。因此，第一个加速估计值 $\\hat{x}_0$ 等于 $c$。误差 $|\\hat{x}_0 - c| = 0$，它小于或等于任何正数 $\\varepsilon$。为了计算 $\\hat{x}_0$，我们需要 $x_1$ 和 $x_2$，这需要 2 次 $g$ 函数的求值。因此，对于所有 $L \\in (0,1)$，$N_{\\text{acc}} = 2$。\n\n对于边界情况 $L=0$，序列是 $x_0=c+1, x_1=c, x_2=c, \\dots$。\n让我们计算 $\\hat{x}_0$：\n$$x_1 - x_0 = c - (c+1) = -1$$\n$$x_2 - 2x_1 + x_0 = c - 2c + (c+1) = 1$$\n分母不为零。\n$$\\hat{x}_0 = x_0 - \\frac{(x_1 - x_0)^2}{x_2 - 2x_1 + x_0} = (c+1) - \\frac{(-1)^2}{1} = c+1 - 1 = c$$\n同样，找到了精确的不动点。这需要计算 $x_1=g(x_0)$ 和 $x_2=g(x_1)$，总共需要 2 次求值。所以，对于 $L=0$，$N_{\\text{acc}} = 2$。\n\n总之，对于所有测试用例，$N_{\\text{acc}} = 2$。\n\n### 任务 C：量化改进\n\n加速比 $S$ 是普通方法所需的求值次数与加速方法所需次数的比值：\n$$S = \\frac{N_{\\text{plain}}}{N_{\\text{acc}}}$$\n使用我们推导出的结果，这变为：\n$$S = \\frac{N_{\\text{plain}}}{2}$$\n\n### 测试用例计算\n- 共享参数：$c=3$，$x_0 = c+1 = 4$，$\\varepsilon=10^{-8}$。\n- $\\ln(\\varepsilon) = \\ln(10^{-8}) = -8 \\ln(10) \\approx -18.42068$。\n\n情况 1：$L=0.9$\n$N_{\\text{plain}} = \\lceil \\frac{\\ln(10^{-8})}{\\ln(0.9)} \\rceil = \\lceil \\frac{-18.42068}{-0.10536} \\rceil = \\lceil 174.83 \\rceil = 175$。\n$N_{\\text{acc}} = 2$。\n$S = 175 / 2 = 87.5$。\n\n情况 2：$L=0.99$\n$N_{\\text{plain}} = \\lceil \\frac{\\ln(10^{-8})}{\\ln(0.99)} \\rceil = \\lceil \\frac{-18.42068}{-0.01005} \\rceil = \\lceil 1832.85 \\rceil = 1833$。\n$N_{\\text{acc}} = 2$。\n$S = 1833 / 2 = 916.5$。\n\n情况 3：$L=0.0$\n$N_{\\text{plain}} = 1$。\n$N_{\\text{acc}} = 2$。\n$S = 1 / 2 = 0.5$。\n\n情况 4：$L=0.9999$\n$N_{\\text{plain}} = \\lceil \\frac{\\ln(10^{-8})}{\\ln(0.9999)} \\rceil = \\lceil \\frac{-18.42068}{-0.000100005} \\rceil = \\lceil 184201.3 \\rceil = 184202$。\n$N_{\\text{acc}} = 2$。\n$S = 184202 / 2 = 92101.0$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the fixed-point iteration problem for a given test suite.\n\n    The problem analyzes an affine fixed-point iteration g(x) = L*x + (1-L)*c\n    with fixed point c. It compares the number of function evaluations\n    required for convergence by a plain iteration versus an Aitken-accelerated\n    iteration.\n    \"\"\"\n\n    # Define the shared parameters from the problem statement.\n    c = 3.0\n    x0 = c + 1.0\n    eps = 1e-8\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        0.9,      # Case 1\n        0.99,     # Case 2\n        0.0,      # Case 3\n        0.9999,   # Case 4\n    ]\n\n    def get_n_plain(L: float, x0: float, c: float, eps: float) -> int:\n        \"\"\"\n        Calculates the minimal number of evaluations for plain fixed-point iteration.\n\n        The error e_k = x_k - c follows e_k = L^k * e_0.\n        The condition is |e_k| = eps, which means L^k * |x0 - c| = eps.\n        Given |x0 - c| = 1, this simplifies to L^k = eps.\n        \"\"\"\n        # Check if already converged (not the case for the given problem data)\n        if abs(x0 - c) = eps:\n            return 0\n        \n        # Handle the boundary case L=0 separately.\n        # x_1 = g(x_0) = (1-0)*c = c. Convergence in 1 step.\n        if L == 0.0:\n            return 1\n        \n        # For L in (0, 1), solve L^k = eps for k.\n        # k * log(L) = log(eps) -> k >= log(eps) / log(L)\n        # We need the smallest integer k.\n        num_iterations = np.ceil(np.log(eps) / np.log(L))\n        return int(num_iterations)\n\n    def get_n_acc(L: float, x0: float, c: float, eps: float) -> int:\n        \"\"\"\n        Calculates the minimal number of evaluations for Aitken-accelerated iteration.\n        \n        For an affine iteration g(x) = L*x + (1-L)*c, Aitken's method is known\n        to converge to the exact fixed point with the first accelerated estimate,\n        x_hat_0. Calculation of x_hat_0 requires the triple (x0, x1, x2).\n        \n        x1 = g(x0)  (1st evaluation)\n        x2 = g(x1)  (2nd evaluation)\n        \n        This holds for all L in [0, 1) as long as the denominator of Aitken's\n        formula is non-zero, which is true for the given test cases.\n        \"\"\"\n        # Check trivial convergence\n        if abs(x0 - c) = eps:\n            return 0\n            \n        # As derived in the solution, Aitken's method requires 2 evaluations\n        # to compute x_hat_0, which gives the exact solution c.\n        return 2\n\n    results = []\n    for L_val in test_cases:\n        N_plain = get_n_plain(L_val, x0, c, eps)\n        N_acc = get_n_acc(L_val, x0, c, eps)\n        \n        # Speedup is the ratio of evaluations.\n        S = N_plain / N_acc\n        \n        results.append([N_plain, N_acc, S])\n\n    # Format the output string exactly as specified in the problem,\n    # constructing it part by part to avoid extra spaces from str(list).\n    inner_parts = []\n    for res in results:\n        # For case L=0.9999, S is an integer value, but problem asks for decimal.\n        # Standard float formatting handles this.\n        inner_parts.append(f'[{res[0]},{res[1]},{res[2]}]')\n    \n    final_output = f\"[{','.join(inner_parts)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}