{
    "hands_on_practices": [
        {
            "introduction": "The communication matrix is the canvas on which all deterministic protocols operate, providing a complete map of a function's outputs for every possible input pair. This exercise invites you to work directly with this fundamental structure for the simple NOR function. By manually partitioning the matrix into monochromatic rectangles and identifying a maximal fooling set, you will build a concrete intuition for the core concepts that establish lower bounds on communication cost .",
            "id": "1416638",
            "problem": "In the field of communication complexity, we study the amount of communication required for two separated parties, conventionally named Alice and Bob, to collaboratively compute a function. Alice is given an input $x$ and Bob is given an input $y$, and they wish to compute $f(x, y)$.\n\nLet's consider the specific case where Alice holds a single bit $x \\in \\{0, 1\\}$ and Bob holds a single bit $y \\in \\{0, 1\\}$. They want to compute the logical NOR function, defined as $f(x, y) = \\text{NOR}(x, y) = \\neg(x \\vee y)$. The function evaluates to 1 if both $x$ and $y$ are 0, and 0 otherwise.\n\nThe function $f$ can be represented by a communication matrix $M_f$, where rows are indexed by Alice's inputs and columns by Bob's inputs. The entry at row $x$ and column $y$ is $f(x, y)$.\n\nA key concept is that of a *monochromatic rectangle*. This is a set of entries in the matrix, $R = A \\times B$ where $A$ is a subset of Alice's possible inputs and $B$ is a subset of Bob's possible inputs, such that all entries $f(x, y)$ for $(x, y) \\in R$ have the same value (i.e., are all 0s or all 1s). Any deterministic communication protocol implicitly partitions the communication matrix into a set of disjoint monochromatic rectangles. The minimum number of such rectangles, let's call it $k$, is related to the deterministic communication complexity $D(f)$ by the formula $D(f) = \\lceil \\log_2 k \\rceil$.\n\nAnother important tool is a *fooling set*. For a function $f$, a fooling set is a collection of input pairs $S = \\{(x_1, y_1), (x_2, y_2), \\dots, (x_k, y_k)\\}$ satisfying two properties:\n1. All pairs in the set produce the same output value: for some constant $c$, $f(x_i, y_i) = c$ for all $i \\in \\{1, \\dots, k\\}$.\n2. For any two distinct pairs $(x_i, y_i)$ and $(x_j, y_j)$ in $S$ (i.e., $i \\neq j$), at least one of the \"crossed\" pairs gives a different output value: $f(x_i, y_j) \\neq c$ or $f(x_j, y_i) \\neq c$.\nThe size of the largest possible fooling set provides a lower bound on $D(f)$.\n\nGiven the NOR function on single-bit inputs as described, your task is to identify a valid minimal partition of its communication matrix into monochromatic rectangles and a valid maximal-sized fooling set.\n\nWhich of the following options correctly provides both a minimal monochromatic partition and a maximal fooling set for the NOR function?\n\nA. Partition: $ \\{(\\{0\\}\\times\\{0\\}), (\\{0,1\\}\\times\\{1\\}), (\\{1\\}\\times\\{0\\})\\} $; Fooling Set: $ \\{(0,0), (0,1), (1,0)\\} $\n\nB. Partition: $ \\{(\\{0\\}\\times\\{0\\}), (\\{0\\}\\times\\{1\\}), (\\{1\\}\\times\\{0,1\\})\\} $; Fooling Set: $ \\{(0,1), (1,0), (1,1)\\} $\n\nC. Partition: $ \\{(\\{0\\}\\times\\{0\\}), (\\{0,1\\}\\times\\{1\\}), (\\{1\\}\\times\\{0\\})\\} $; Fooling Set: $ \\{(0,1), (1,0)\\} $\n\nD. Partition: $ \\{(\\{0\\}\\times\\{0\\}), (\\{0\\}\\times\\{1\\}), (\\{1\\}\\times\\{0\\}), (\\{1\\}\\times\\{1\\})\\} $; Fooling Set: $ \\{(0,1), (1,0), (1,1)\\} $\n\nE. Partition: $ \\{(\\{0\\}\\times\\{0\\}), (\\{1\\}\\times\\{0,1\\}), (\\{0\\}\\times\\{1\\})\\} $; Fooling Set: $ \\{(0,1), (1,1)\\} $",
            "solution": "The NOR function on single-bit inputs is defined by $f(x,y)=\\neg(x\\vee y)$. Its communication matrix, with rows indexed by $x\\in\\{0,1\\}$ and columns by $y\\in\\{0,1\\}$, has entries\n$$\nf(0,0)=1,\\quad f(0,1)=0,\\quad f(1,0)=0,\\quad f(1,1)=0.\n$$\nThus the matrix is\n$$\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & 0\n\\end{pmatrix}\n$$\nwhere the unique $1$ is at $(0,0)$ and the other three entries are $0$.\n\nA monochromatic rectangle is a set $A\\times B$ with $A\\subseteq\\{0,1\\}$ and $B\\subseteq\\{0,1\\}$ such that $f$ is constant on $A\\times B$. Any monochromatic partition must isolate $(0,0)$ in its own $1$-rectangle, since no other entry equals $1$. Therefore one rectangle is $\\{0\\}\\times\\{0\\}$.\n\nIt remains to cover the three $0$-entries: $(0,1)$, $(1,0)$, and $(1,1)$. A single rectangle cannot contain exactly these three, because any rectangle $A\\times B$ that contains both $(0,1)$ and $(1,0)$ must have $A=\\{0,1\\}$ and $B=\\{0,1\\}$, which would also include $(0,0)$, not allowed since $f(0,0)=1$. Hence at least two $0$-rectangles are needed. Two rectangles suffice, for example\n$$\nR_{2}=\\{0,1\\}\\times\\{1\\}\\quad\\text{covering }(0,1),(1,1),\\qquad R_{3}=\\{1\\}\\times\\{0\\}\\quad\\text{covering }(1,0).\n$$\nTogether with $R_{1}=\\{0\\}\\times\\{0\\}$, these three disjoint rectangles cover all entries and are monochromatic. Therefore a minimal partition uses exactly three rectangles, and one valid minimal partition is\n$$\n\\{(\\{0\\}\\times\\{0\\}),\\;(\\{0,1\\}\\times\\{1\\}),\\;(\\{1\\}\\times\\{0\\})\\}.\n$$\n\nA fooling set $S=\\{(x_{i},y_{i})\\}$ must satisfy: there exists a constant $c$ with $f(x_{i},y_{i})=c$ for all $i$, and for any distinct $i\\neq j$, at least one of $f(x_{i},y_{j})\\neq c$ or $f(x_{j},y_{i})\\neq c$. Since there is only one input with value $1$, any fooling set with $c=1$ has size at most $1$. To maximize size, take $c=0$ and choose from the three $0$-entries. Consider $S=\\{(0,1),(1,0)\\}$. Then $f(0,1)=0$ and $f(1,0)=0$, and the crossed pairs are $(0,0)$ and $(1,1)$ with values $f(0,0)=1\\neq 0$ and $f(1,1)=0=0$, so the condition is satisfied. Attempting to add $(1,1)$ fails because pairing $(0,1)$ with $(1,1)$ yields crossed pairs $(0,1)$ and $(1,1)$, both with value $0$, violating the requirement that at least one crossed value differ from $c$. Similarly, any pair that includes $(1,1)$ with either $(0,1)$ or $(1,0)$ fails. Therefore the maximal fooling set has size $2$, and a valid maximal fooling set is\n$$\n\\{(0,1),(1,0)\\}.\n$$\n\nComparing with the options, the partition and fooling set that are both valid and minimal/maximal respectively are exactly those in option C:\n$$\n\\text{Partition } \\{(\\{0\\}\\times\\{0\\}), (\\{0,1\\}\\times\\{1\\}), (\\{1\\}\\times\\{0\\})\\};\\quad \\text{Fooling Set } \\{(0,1), (1,0)\\}.\n$$",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "Often, a seemingly new problem is just a familiar one in disguise, and a key skill in complexity theory is learning to recognize these connections through reduction. This practice demonstrates how a geometric question about parallel lines can be elegantly reduced to the fundamental Equality (EQ) problem. You will then apply the fooling-set method to establish a tight and definitive bound on the communication required to solve it .",
            "id": "1421133",
            "problem": "Alice holds a pair of integer coefficients $(a, b)$ and Bob holds a pair of integer coefficients $(c, d)$. Each of these four coefficients is an integer drawn from the set $\\{0, 1, 2, \\ldots, N-1\\}$, where $N$ is an integer greater than 1. These coefficients define two lines in a 2D Cartesian plane: line $L_A$ with the equation $y = ax+b$ and line $L_B$ with the equation $y = cx+d$.\n\nAlice and Bob wish to determine if their lines $L_A$ and $L_B$ are parallel. They can communicate by sending bits to each other according to a deterministic protocol. The deterministic communication complexity of this problem is defined as the minimum number of bits that must be exchanged in the worst case, over all possible inputs $(a, b, c, d)$, for any correct protocol.\n\nFind the deterministic communication complexity for this problem as an exact function of $N$.",
            "solution": "We formalize the function to be computed. Alice holds $(a,b)\\in\\{0,1,\\ldots,N-1\\}^{2}$ and Bob holds $(c,d)\\in\\{0,1,\\ldots,N-1\\}^{2}$. Define\n$$\nf\\big((a,b),(c,d)\\big)=\n\\begin{cases}\n1,& \\text{if }L_{A}\\parallel L_{B},\\\\\n0,& \\text{otherwise}.\n\\end{cases}\n$$\nSince $L_{A}:y=ax+b$ and $L_{B}:y=cx+d$, the lines are parallel if and only if their slopes are equal, i.e., $a=c$. Therefore,\n$$\nf\\big((a,b),(c,d)\\big)=\\mathbf{1}[a=c],\n$$\nso $f$ depends only on $a$ and $c$, and is exactly the equality predicate on an alphabet of size $N$.\n\nUpper bound. There is a simple deterministic one-way protocol: Alice sends the binary encoding of $a$ to Bob using $\\lceil \\log_{2} N\\rceil$ bits. Bob compares the received $a$ with his $c$ and outputs $1$ if and only if $a=c$. This protocol is correct on all inputs and communicates exactly $\\lceil \\log_{2} N\\rceil$ bits in the worst case. Hence,\n$$\nD(f)\\leq \\lceil \\log_{2} N\\rceil.\n$$\n\nLower bound. We apply the fooling-set method. Consider the set\n$$\nF=\\{\\,((k,0),(k,0)):\\ k\\in\\{0,1,\\ldots,N-1\\}\\,\\}.\n$$\nFor every $((k,0),(k,0))\\in F$, we have $a=c=k$, hence $f((k,0),(k,0))=1$. For any two distinct elements $((k,0),(k,0))$ and $((\\ell,0),(\\ell,0))$ with $k\\neq \\ell$, the mixed pairs $((k,0),(\\ell,0))$ and $((\\ell,0),(k,0))$ satisfy $a\\neq c$, hence $f=0$ on both mixes. Therefore $F$ is a $1$-fooling set of size $|F|=N$. The fooling-set lower bound implies\n$$\nD(f)\\geq \\log_{2} |F|=\\log_{2} N,\n$$\nand since the number of bits is integral,\n$$\nD(f)\\geq \\lceil \\log_{2} N\\rceil.\n$$\n\nCombining the upper and lower bounds yields the exact deterministic communication complexity\n$$\nD(f)=\\lceil \\log_{2} N\\rceil.\n$$",
            "answer": "$$\\boxed{\\lceil \\log_{2} N\\rceil}$$"
        },
        {
            "introduction": "While fooling sets provide an intuitive way to prove lower bounds, some problems are better analyzed with more powerful algebraic techniques. This exercise introduces the celebrated log-rank lower bound, which connects communication cost to the rank of the function's communication matrix. By analyzing a practical problem related to computer arithmetic—detecting overflow—you'll see how this method can yield strong, non-obvious lower bounds .",
            "id": "1421161",
            "problem": "Alice and Bob are two remote computers that want to collaborate on a computation. Alice holds an $n$-bit non-negative integer $x$, where $x = \\sum_{i=0}^{n-1} x_i 2^i$. Bob holds an $n$-bit non-negative integer $y = \\sum_{i=0}^{n-1} y_i 2^i$. Their goal is to compute a function $f(x,y)$ whose output is the most significant bit of their sum, $S=x+y$. Specifically, if the sum can be written as an $(n+1)$-bit number $S = (s_n s_{n-1} \\dots s_0)_2$, the function they want to compute is $f(x,y) = s_n$. This bit indicates whether an arithmetic overflow occurs when storing the sum in $n$ bits, i.e., whether $x+y \\ge 2^n$.\n\nThey communicate by sending bits of information to each other over a communication channel. The complexity of a protocol is measured by the number of bits exchanged in the worst-case scenario. The deterministic communication complexity of this problem, denoted $D(f)$, is the minimum number of bits that must be exchanged in the worst case for any correct deterministic protocol that works for any pair of $n$-bit inputs $(x, y)$.\n\nFor a large integer $n$, which of the following best describes the asymptotic behavior of $D(f)$?\n\nA. $\\Theta(1)$\n\nB. $\\Theta(\\log n)$\n\nC. $\\Theta(n)$\n\nD. $\\Theta(n^2)$",
            "solution": "We formalize the problem as a two-party deterministic communication problem with Alice holding $x \\in \\{0,1,\\dots,2^{n}-1\\}$ and Bob holding $y \\in \\{0,1,\\dots,2^{n}-1\\}$, and the function\n$$\nf(x,y) = \\begin{cases}\n1 & \\text{if } x + y \\ge 2^{n},\\\\\n0 & \\text{otherwise}.\n\\end{cases}\n$$\nLet $m = 2^{n}$. The communication matrix $M$ of $f$ has rows indexed by $x \\in \\{0,\\dots,m-1\\}$ and columns indexed by $y \\in \\{0,\\dots,m-1\\}$ with entries $M_{x,y} = 1$ iff $x + y \\ge m$.\n\nUpper bound: There is a trivial protocol where Alice sends her entire $n$-bit input $x$ to Bob using $n$ bits. Bob then computes whether $x + y \\ge m$ and outputs $f(x,y)$. Thus,\n$$\nD(f) \\le n.\n$$\n\nLower bound by reduction to Greater-Than and the log-rank method: Define a permutation of Bob’s inputs by $y' = m - 1 - y$. Permuting columns does not change the deterministic communication complexity. Under this relabeling, define a new matrix $N$ with\n$$\nN_{x,y'} = M_{x,\\,m-1-y'}.\n$$\nThen\n$$\nN_{x,y'} = 1 \\iff x + (m - 1 - y') \\ge m \\iff x \\ge y' + 1 \\iff x > y'.\n$$\nHence $N$ is exactly the communication matrix of the strict greater-than function on $\\{0,\\dots,m-1\\}$, where $N_{x,y'} = 1$ iff $x > y'$ and $0$ otherwise.\n\nWe compute the real rank of $N$. The first row (corresponding to $x=0$) is all zeros, so $\\operatorname{rank}(N) \\le m - 1$. Consider the $(m-1) \\times (m-1)$ submatrix $T$ formed by rows $x = 1,2,\\dots,m-1$ and columns $y' = 0,1,\\dots,m-2$. Its entries satisfy\n$$\nT_{i,j} = 1 \\iff i \\ge j+1 \\iff i-1 \\ge j,\n$$\nwhich makes $T$ a lower triangular matrix with ones on the diagonal. Therefore $\\det(T) \\neq 0$ and $\\operatorname{rank}(T) = m - 1$. Hence\n$$\n\\operatorname{rank}(N) = m - 1.\n$$\nBy the log-rank lower bound for deterministic communication complexity,\n$$\nD(f) = D(N) \\ge \\log_{2}\\big(\\operatorname{rank}(N)\\big) = \\log_{2}(m - 1) = \\log_{2}(2^{n} - 1).\n$$\nSince $\\log_{2}(2^{n} - 1) = \\Theta(n)$ and we also have $D(f) \\le n$, it follows that\n$$\nD(f) = \\Theta(n).\n$$\n\nTherefore, among the given options, the correct asymptotic behavior is $\\Theta(n)$.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}