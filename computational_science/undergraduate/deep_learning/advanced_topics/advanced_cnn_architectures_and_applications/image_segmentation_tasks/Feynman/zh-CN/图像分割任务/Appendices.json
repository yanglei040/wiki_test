{
    "hands_on_practices": [
        {
            "introduction": "在训练任何深度学习模型时，选择合适的损失函数是至关重要的第一步。在图像分割任务中，由于前景和背景之间常存在严重的类别不平衡，这一选择尤为关键。本练习  将引导您深入研究三种基础的损失函数——像素级交叉熵损失（pixel-wise cross-entropy）、焦点损失（focal loss）和 Dice 损失（Dice loss）。您将通过它们的数学推导和梯度行为分析，掌握构建稳健分割模型的必备知识。",
            "id": "3136332",
            "problem": "您的任务是推导、分析和实现三种用于像素级二元语义分割的损失函数，这些函数适用于前景类别稀少的高度不平衡数据。考虑一个分割场景，其中每个像素被建模为一个独立伯努利随机变量，其目标值为 $y \\in \\{0,1\\}$，预测概率为 $p \\in (0,1)$，该概率由逻辑函数 $p = \\sigma(z)$ 生成，其中 $z \\in \\mathbb{R}$ 且 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$。从独立伯努利变量的最大似然估计原理以及将负对数似然定义为损失函数出发。推导以下三种损失函数及其相对于 logit $z$ 的梯度：\n\n1. 基于伯努利负对数似然的像素级交叉熵损失 $L_{CE}$。\n2. 用于二元分类的 Focal loss $L_{focal}$，其聚焦参数为 $\\gamma \\ge 0$，类别平衡因子为 $\\alpha \\in (0,1)$。\n3. 基于软 Sørensen–Dice 系数的 Dice loss $L_{Dice}$，其平滑常数 $s$ 严格为正以确保数值稳定性。\n\n对于每种损失，您必须：\n- 使用伯努利似然和适当的定义，从第一性原理推导损失的解析表达式，不得直接使用已知的最终公式。\n- 假设 $p = \\sigma(z)$ 和 $\\frac{dp}{dz} = p(1-p)$，使用链式法则推导相对于 logit $z$ 的梯度。\n- 分析和解释在严重类别不平衡的情况下，当正类别的预测概率满足 $p \\ll 1$ 时，梯度幅值的行为，并对比 $y=1$（正像素）和 $y=0$（负像素）时的行为。\n\n实现要求：\n- 为像素数组实现这三种损失及其相对于 $z$ 的梯度的数值稳定版本。使用一个小的 $\\epsilon$ 对概率进行截断，以避免出现未定义的对数。\n- 对于每个测试用例，分别计算正像素（$y=1$）和负像素（$y=0$）的每像素平均损失和相对于 $z$ 的平均绝对梯度幅值。\n\n测试套件：\n- 构建合成的分割数据集，指定总像素数 $N$、正类别比例 $r$，以及对正像素的恒定预测概率 $p_{pos}$ 和对负像素的恒定预测概率 $p_{neg}$。使用以下四个测试用例：\n    1. 用例 $1$：$N = 100$，$r = 0.2$，$p_{pos} = 0.6$，$p_{neg} = 0.4$，focal 参数 $\\gamma = 2$，$\\alpha = 0.25$，dice 平滑 $s = 1.0$。\n    2. 用例 $2$（严重类别不平衡且 $p \\ll 1$）：$N = 1000$，$r = 0.01$，$p_{pos} = 0.01$，$p_{neg} = 0.01$，focal 参数 $\\gamma = 2$，$\\alpha = 0.25$，dice 平滑 $s = 1.0$。\n    3. 用例 $3$（近乎完美的预测）：$N = 500$，$r = 0.1$，$p_{pos} = 0.999$，$p_{neg} = 0.001$，focal 参数 $\\gamma = 2$，$\\alpha = 0.25$，dice 平滑 $s = 1.0$。\n    4. 用例 $4$（focal loss 中 $\\gamma = 0$ 以与交叉熵加权进行比较）：$N = 200$，$r = 0.3$，$p_{pos} = 0.7$，$p_{neg} = 0.3$，focal 参数 $\\gamma = 0$，$\\alpha = 0.25$，dice 平滑 $s = 1.0$。\n\n输出规格：\n- 对于每个测试用例，计算一个嵌套列表，其中包含三个子列表，每个子列表对应一种损失，顺序为 $[L_{CE}, L_{focal}, L_{Dice}]$。每个子列表必须采用 $[\\text{平均损失}, y=1\\text{ 的平均绝对梯度}, y=0\\text{ 的平均绝对梯度}]$ 的形式，所有数值均为浮点数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，且不含空格。顶层列表必须为每个测试用例包含一个元素，顺序与上文相同。例如，对于三个测试用例，格式必须是 $[[l_{11},g_{11}^+,g_{11}^-],[l_{12},g_{12}^+,g_{12}^-],[l_{13},g_{13}^+,g_{13}^-]]$, 并为四个用例作相应扩展。\n\n不涉及物理单位；所有结果均为无量纲浮点数。请将所有量表示为十进制数。",
            "solution": "该问题是有效的，因为它在科学上基于统计学习理论，定义明确，包含了所有必要的数据和定义，并以客观、正式的语言表述。我们继续进行推导、分析和实现。\n\n本分析的基础是将二元语义分割任务中的每个像素建模为一个独立的伯努利试验。一个像素的真实标签是 $y \\in \\{0, 1\\}$，模型对正类别（$y=1$）的预测概率是 $p \\in (0,1)$。这个概率是对一个 logit $z \\in \\mathbb{R}$ 应用逻辑 sigmoid 函数的输出，使得 $p = \\sigma(z) = (1 + e^{-z})^{-1}$。sigmoid 函数的一个关键特性是其相对于输入的导数形式简单：$\\frac{dp}{dz} = \\frac{d\\sigma(z)}{dz} = \\sigma(z)(1-\\sigma(z)) = p(1-p)$。\n\n单个像素观测的似然由伯努利概率质量函数给出：$P(y|p) = p^y(1-p)^{1-y}$。对于一个有 $N$ 个像素的图像，假设像素之间相互独立，总似然是各个似然的乘积：$\\mathcal{L} = \\prod_{i=1}^{N} p_i^{y_i}(1-p_i)^{1-y_i}$。\n\n在机器学习中，标准做法是最大化对数似然，或者等价地，最小化负对数似然 (NLL)。整个图像的 NLL 为：\n$$ \\text{NLL} = -\\log(\\mathcal{L}) = -\\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right] $$\n对 NLL 的每个像素的贡献构成了交叉熵损失的基础。\n\n### 1. 像素级交叉熵损失 ($L_{CE}$)\n\n#### 推导\n单个像素的交叉熵损失直接从单个伯努利试验的负对数似然推导而来。\n$$ L_{CE}(y, p) = -[y \\log(p) + (1-y) \\log(1-p)] $$\n这个损失函数会对模型在错误预测上的高置信度进行惩罚。例如，如果 $y=1$，损失为 $-\\log(p)$，当预测概率 $p$ 趋近于 $0$ 时，该损失趋近于无穷大。\n\n#### 梯度推导\n我们求解损失函数相对于 logit $z$ 的梯度 $\\frac{dL_{CE}}{dz}$。使用链式法则，$\\frac{dL_{CE}}{dz} = \\frac{dL_{CE}}{dp} \\frac{dp}{dz}$。\n首先，我们求相对于 $p$ 的导数：\n$$ \\frac{dL_{CE}}{dp} = -\\left[ \\frac{y}{p} - \\frac{1-y}{1-p} \\right] = -\\frac{y(1-p) - p(1-y)}{p(1-p)} = -\\frac{y - yp - p + py}{p(1-p)} = -\\frac{y-p}{p(1-p)} $$\n现在，乘以 $\\frac{dp}{dz} = p(1-p)$：\n$$ \\frac{dL_{CE}}{dz} = \\left( -\\frac{y-p}{p(1-p)} \\right) \\cdot p(1-p) = -(y-p) = p-y $$\n这个异常简单的结果表明，交叉熵损失相对于 logit 的梯度就是预测值与目标值之差。\n\n#### 梯度分析 ($p \\ll 1$)\n在严重类别不平衡的情况下，正类别是稀少的。我们分析当模型（通常情况下）对正类别预测出较低概率（$p \\ll 1$）时的梯度。\n- **对于正像素（$y=1$）：** 梯度为 $\\frac{dL_{CE}}{dz} = p-1$。当 $p \\to 0$ 时，梯度趋近于 $-1$。梯度幅值 $|\\frac{dL_{CE}}{dz}| \\approx 1$。这些稀少的正像素，即使被以低概率错误分类，也会产生一个强大的、恒定的误差信号来更新模型。\n- **对于负像素（$y=0$）：** 梯度为 $\\frac{dL_{CE}}{dz} = p-0 = p$。当 $p \\to 0$ 时，梯度趋近于 $0$。梯度幅值 $|\\frac{dL_{CE}}{dz}| \\approx 0$。这些常见的负像素，当被以低概率正确分类时，会产生一个非常小的误差信号。\n在不平衡设置中，$L_{CE}$ 的问题在于，来自大量“简单”负样本的许多小梯度的总和，可能会压倒来自少数“困难”正样本的少数大梯度的总和。\n\n### 2. Focal Loss ($L_{focal}$)\n\n#### 推导\nFocal loss 旨在通过修改交叉熵损失来解决类别不平衡问题，它引入了一个调制因子，该因子会减少来自被良好分类样本的损失贡献。聚焦参数 $\\gamma \\ge 0$ 控制着降权的速率。该损失还包含一个权重因子 $\\alpha \\in (0,1)$，用以平衡正/负类别的重要性。\n\n单个像素的损失定义为：\n$$ L_{focal}(y, p) = -y \\alpha (1-p)^\\gamma \\log(p) - (1-y)(1-\\alpha) p^\\gamma \\log(1-p) $$\n当 $\\gamma=0$ 时，该损失简化为加权交叉熵。随着 $\\gamma$ 的增加，调制因子（对于 $y=1$ 是 $(1-p)^\\gamma$，对于 $y=0$ 是 $p^\\gamma$）会更积极地对简单样本（例如，$y=0, p \\to 0$ 或 $y=1, p \\to 1$）进行降权。\n\n#### 梯度推导\n我们分 $y=1$ 和 $y=0$ 两种情况，对 $L_{focal}$ 关于 $z$ 求导。\n情况 $y=1$：$L = -\\alpha (1-p)^\\gamma \\log(p)$。\n$$ \\frac{dL}{dz} = \\frac{dL}{dp} \\frac{dp}{dz} = \\left(-\\alpha \\left[ -\\gamma(1-p)^{\\gamma-1} \\log(p) + \\frac{(1-p)^\\gamma}{p} \\right] \\right) \\cdot (p(1-p)) $$\n$$ = -\\alpha [-\\gamma p (1-p)^\\gamma \\log(p) + (1-p)^{\\gamma+1}] = \\alpha (1-p)^\\gamma [\\gamma p \\log(p) - (1-p)] $$\n$$ = \\alpha (1-p)^\\gamma (\\gamma p \\log(p) + p - 1) $$\n情况 $y=0$：$L = -(1-\\alpha) p^\\gamma \\log(1-p)$。\n$$ \\frac{dL}{dz} = \\frac{dL}{dp} \\frac{dp}{dz} = \\left(-(1-\\alpha) \\left[ \\gamma p^{\\gamma-1} \\log(1-p) + p^\\gamma \\frac{-1}{1-p} \\right] \\right) \\cdot (p(1-p)) $$\n$$ = -(1-\\alpha) [\\gamma p^\\gamma(1-p) \\log(1-p) - p^{\\gamma+1}] = (1-\\alpha) p^\\gamma [p - \\gamma(1-p)\\log(1-p)] $$\n将这些组合起来，得到完整的梯度表达式：\n$$ \\frac{dL_{focal}}{dz} = y \\cdot \\left[ \\alpha (1-p)^\\gamma (\\gamma p \\log(p) + p - 1) \\right] + (1-y) \\cdot \\left[ (1-\\alpha) p^\\gamma (p - \\gamma(1-p)\\log(1-p)) \\right] $$\n\n#### 梯度分析 ($p \\ll 1$)\n- **对于正像素（$y=1$）：** 梯度为 $\\frac{dL_{focal}}{dz} = \\alpha (1-p)^\\gamma (\\gamma p \\log(p) + p - 1)$。当 $p \\to 0$ 时，我们利用 $\\lim_{p\\to 0} p\\log(p) = 0$ 这一事实。梯度趋近于 $\\alpha(1-0)^\\gamma(0 + 0 - 1) = -\\alpha$。梯度幅值 $|\\frac{dL_{focal}}{dz}| \\approx \\alpha$。与交叉熵类似，这提供了一个恒定的学习信号，但被 $\\alpha$ 缩放了。\n- **对于负像素（$y=0$）：** 梯度为 $\\frac{dL_{focal}}{dz} = (1-\\alpha) p^\\gamma (p - \\gamma(1-p)\\log(1-p))$。当 $p \\to 0$ 时，我们使用泰勒展开 $\\log(1-p) \\approx -p$。括号中的项变为 $p - \\gamma(1-p)(-p) = p(1 + \\gamma(1-p)) \\approx p(1+\\gamma)$。梯度约等于 $(1-\\alpha) p^\\gamma \\cdot p(1+\\gamma) = (1-\\alpha)(1+\\gamma)p^{\\gamma+1}$。对于 $\\gamma > 0$，此梯度比交叉熵梯度（$p$）更快地减小到零。当 $\\gamma=2$ 时，梯度为 $O(p^3)$，有效地消除了大量简单负样本的贡献。\n\n### 3. Dice Loss ($L_{Dice}$)\n\n#### 推导\nDice loss 基于 Sørensen–Dice 系数，这是一种衡量两个集合重叠度的指标。它不是从伯努利 NLL 推导出来的，但作为一种常见且有效的分割替代方案被包含在此。针对所有 $N$ 个像素的预测概率 $p_i$ 和真实标签 $y_i$ 的软 Dice 系数为：\n$$ D(y, p) = \\frac{2 \\sum_{i=1}^N y_i p_i + s}{\\sum_{i=1}^N y_i + \\sum_{i=1}^N p_i + s} $$\n其中 $s>0$ 是一个平滑常数，用于防止除以零并提高稳定性。Dice loss 定义为 $L_{Dice} = 1 - D$。\n$$ L_{Dice} = 1 - \\frac{2 \\sum_{i=1}^N y_i p_i + s}{\\sum_{i=1}^N y_i + \\sum_{i=1}^N p_i + s} $$\n与 CE 和 Focal loss 不同，Dice loss 是一个全局指标；损失值是在整个图像上计算的，而不是逐像素计算。\n\n#### 梯度推导\n$L_{Dice}$ 相对于单个 logit $z_j$ 的梯度为 $\\frac{\\partial L_{Dice}}{\\partial z_j} = \\frac{\\partial L_{Dice}}{\\partial p_j} \\frac{dp_j}{dz_j}$。令 $U = 2 \\sum_i y_i p_i + s$ 且 $V = \\sum_i y_i + \\sum_i p_i + s$。\n$$ \\frac{\\partial L_{Dice}}{\\partial p_j} = -\\frac{\\partial}{\\partial p_j}\\left(\\frac{U}{V}\\right) = - \\frac{\\frac{\\partial U}{\\partial p_j}V - U\\frac{\\partial V}{\\partial p_j}}{V^2} $$\n这些和的偏导数为 $\\frac{\\partial U}{\\partial p_j} = 2y_j$ 和 $\\frac{\\partial V}{\\partial p_j} = 1$。\n$$ \\frac{\\partial L_{Dice}}{\\partial p_j} = - \\frac{2y_j V - U}{V^2} = - \\frac{2y_j (\\sum_i y_i + \\sum_i p_i + s) - (2 \\sum_i y_i p_i + s)}{(\\sum_i y_i + \\sum_i p_i + s)^2} $$\n乘以 $\\frac{dp_j}{dz_j} = p_j(1-p_j)$ 得到最终梯度：\n$$ \\frac{\\partial L_{Dice}}{\\partial z_j} = -p_j(1-p_j) \\frac{2y_j (\\sum_i y_i + \\sum_i p_i + s) - (2 \\sum_i y_i p_i + s)}{(\\sum_i y_i + \\sum_i p_i + s)^2} $$\n\n#### 梯度分析（对所有 i，$p_i \\ll 1$）\n假设所有预测 $p_i$ 都很小。\n- **对于正像素（$y_j=1$）：** 分子中的项 $2y_j V$ 非零。梯度取决于全局总和 $\\sum y_i$、$\\sum p_i$ 等。即使 $p_j \\to 0$，梯度也未必消失，因为巨大的分数项（它取决于像正像素总数 $\\sum y_i$ 这样的全局统计数据）提供了一个可观的信号。正像素的梯度信号得以保持。\n- **对于负像素（$y_j=0$）：** 分子中的项 $2y_j V$ 为零。梯度表达式变为 $\\frac{\\partial L_{Dice}}{\\partial z_j} = p_j(1-p_j) \\frac{U}{V^2}$。当 $p_j \\to 0$ 时，因子 $p_j(1-p_j)$ 会将梯度驱动至零。简单负样本的梯度被抑制。\n\nDice loss 自然地平衡了类别，因为其梯度结构内在地考虑了正像素的全局计数，使其在没有像 $\\alpha$ 这样的显式重加权参数的情况下也能对不平衡具有鲁棒性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Global constant for numerical stability in log operations\nEPSILON = 1e-7\n\ndef compute_ce(y_true, p_pred):\n    \"\"\"\n    Computes pixel-wise Cross-Entropy loss and its gradient statistics.\n\n    Args:\n        y_true (np.ndarray): Array of true binary labels {0, 1}.\n        p_pred (np.ndarray): Array of predicted probabilities (0, 1).\n\n    Returns:\n        list: [mean_loss, mean_abs_grad_pos, mean_abs_grad_neg]\n    \"\"\"\n    # Clamp probabilities to avoid log(0)\n    p_clamped = np.clip(p_pred, EPSILON, 1 - EPSILON)\n    \n    # 1. Compute mean loss per pixel\n    loss_ce = -(y_true * np.log(p_clamped) + (1 - y_true) * np.log(1 - p_clamped))\n    mean_loss = np.mean(loss_ce)\n    \n    # 2. Compute gradient with respect to the logit z\n    grad_z = p_pred - y_true\n    \n    # 3. Separate gradients for positive (y=1) and negative (y=0) pixels\n    pos_mask = y_true == 1\n    neg_mask = y_true == 0\n    \n    grad_abs_pos = np.abs(grad_z[pos_mask])\n    mean_grad_abs_pos = np.mean(grad_abs_pos) if grad_abs_pos.size > 0 else 0.0\n    \n    grad_abs_neg = np.abs(grad_z[neg_mask])\n    mean_grad_abs_neg = np.mean(grad_abs_neg) if grad_abs_neg.size > 0 else 0.0\n    \n    return [mean_loss, mean_grad_abs_pos, mean_grad_abs_neg]\n\ndef compute_focal(y_true, p_pred, gamma, alpha):\n    \"\"\"\n    Computes pixel-wise Focal loss and its gradient statistics.\n\n    Args:\n        y_true (np.ndarray): Array of true binary labels {0, 1}.\n        p_pred (np.ndarray): Array of predicted probabilities (0, 1).\n        gamma (float): The focusing parameter.\n        alpha (float): The class-balancing factor.\n\n    Returns:\n        list: [mean_loss, mean_abs_grad_pos, mean_abs_grad_neg]\n    \"\"\"\n    p_clamped = np.clip(p_pred, EPSILON, 1 - EPSILON)\n    \n    # 1. Compute mean loss per pixel\n    loss_pos = -alpha * ((1 - p_clamped)**gamma) * np.log(p_clamped)\n    loss_neg = -(1 - alpha) * (p_clamped**gamma) * np.log(1 - p_clamped)\n    loss_focal = y_true * loss_pos + (1 - y_true) * loss_neg\n    mean_loss = np.mean(loss_focal)\n    \n    # 2. Compute gradient with respect to the logit z\n    # Note: Use p_clamped for log terms in gradient to maintain numerical stability.\n    grad_pos = alpha * ((1 - p_pred)**gamma) * (gamma * p_pred * np.log(p_clamped) + p_pred - 1)\n    grad_neg = (1 - alpha) * (p_pred**gamma) * (p_pred - gamma * (1 - p_pred) * np.log(1 - p_clamped))\n    grad_z = y_true * grad_pos + (1 - y_true) * grad_neg\n    \n    # 3. Separate gradients\n    pos_mask = y_true == 1\n    neg_mask = y_true == 0\n    \n    grad_abs_pos = np.abs(grad_z[pos_mask])\n    mean_grad_abs_pos = np.mean(grad_abs_pos) if grad_abs_pos.size > 0 else 0.0\n    \n    grad_abs_neg = np.abs(grad_z[neg_mask])\n    mean_grad_abs_neg = np.mean(grad_abs_neg) if grad_abs_neg.size > 0 else 0.0\n    \n    return [mean_loss, mean_grad_abs_pos, mean_grad_abs_neg]\n    \ndef compute_dice(y_true, p_pred, s):\n    \"\"\"\n    Computes Dice loss and its gradient statistics.\n\n    Args:\n        y_true (np.ndarray): Array of true binary labels {0, 1}.\n        p_pred (np.ndarray): Array of predicted probabilities (0, 1).\n        s (float): The smoothing constant.\n\n    Returns:\n        list: [loss_value, mean_abs_grad_pos, mean_abs_grad_neg]\n    \"\"\"\n    # 1. Compute global loss value\n    intersection = np.sum(y_true * p_pred)\n    total_sum = np.sum(y_true) + np.sum(p_pred)\n    dice_coeff = (2. * intersection + s) / (total_sum + s)\n    loss_dice = 1. - dice_coeff  # This is the single loss value for the whole image.\n    \n    # 2. Compute gradient with respect to the logit z (per-pixel)\n    U = 2. * intersection + s\n    V = total_sum + s\n    \n    grad_p = - (2 * y_true * V - U) / (V**2)\n    grad_z = grad_p * p_pred * (1 - p_pred)\n    \n    # 3. Separate gradients\n    pos_mask = y_true == 1\n    neg_mask = y_true == 0\n    \n    grad_abs_pos = np.abs(grad_z[pos_mask])\n    mean_grad_abs_pos = np.mean(grad_abs_pos) if grad_abs_pos.size > 0 else 0.0\n    \n    grad_abs_neg = np.abs(grad_z[neg_mask])\n    mean_grad_abs_neg = np.mean(grad_abs_neg) if grad_abs_neg.size > 0 else 0.0\n    \n    return [loss_dice, mean_grad_abs_pos, mean_grad_abs_neg]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N': 100, 'r': 0.2, 'p_pos': 0.6, 'p_neg': 0.4, 'gamma': 2, 'alpha': 0.25, 's': 1.0},\n        {'N': 1000, 'r': 0.01, 'p_pos': 0.01, 'p_neg': 0.01, 'gamma': 2, 'alpha': 0.25, 's': 1.0},\n        {'N': 500, 'r': 0.1, 'p_pos': 0.999, 'p_neg': 0.001, 'gamma': 2, 'alpha': 0.25, 's': 1.0},\n        {'N': 200, 'r': 0.3, 'p_pos': 0.7, 'p_neg': 0.3, 'gamma': 0, 'alpha': 0.25, 's': 1.0},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        N = params['N']\n        r = params['r']\n        p_pos = params['p_pos']\n        p_neg = params['p_neg']\n        gamma = params['gamma']\n        alpha = params['alpha']\n        s = params['s']\n\n        n_pos = int(round(N * r))\n        n_neg = N - n_pos\n\n        y_true = np.array([1] * n_pos + [0] * n_neg, dtype=np.float64)\n        p_pred = np.array([p_pos] * n_pos + [p_neg] * n_neg, dtype=np.float64)\n\n        case_results = []\n        # L_CE\n        case_results.append(compute_ce(y_true, p_pred))\n        # L_focal\n        case_results.append(compute_focal(y_true, p_pred, gamma, alpha))\n        # L_Dice\n        case_results.append(compute_dice(y_true, p_pred, s))\n        \n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified in the problem statement\n    all_case_strings = []\n    for case_result in all_results:\n        loss_strings = []\n        for loss_result in case_result:\n            # Format each sublist of floats into \"[v1,v2,v3]\"\n            loss_strings.append(f\"[{','.join(f'{v:.10f}'.rstrip('0').rstrip('.') if v != 0 else '0.0' for v in loss_result)}]\")\n        # Join the sublists for a single test case\n        case_string = f\"[{','.join(loss_strings)}]\"\n        all_case_strings.append(case_string)\n    \n    # Join all test case results into the final string\n    final_output = f\"[{','.join(all_case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "一个模型的优劣取决于评估它的指标。对于现代的全景分割（panoptic segmentation）任务而言，全景质量（Panoptic Quality, $PQ$）是黄金标准。然而，要真正理解模型的性能，我们必须超越单一的数字。本练习  将引导您把 $PQ$ 指标分解为其两个核心组成部分——识别质量（Recognition Quality, $RQ$）和分割质量（Segmentation Quality, $SQ$），并利用合成的测试案例来观察它们如何独特地捕捉不同类型的实例级错误。",
            "id": "3136328",
            "problem": "你的任务是形式化并测试标准的全景分割度量如何分解为能够区分识别质量和分割质量的组件，然后设计受控的失败案例，在这些案例中，语义准确度保持不变，而实例级划分则不同。所有工作都完全在一个单一的语义类别中进行，并在合成的二值掩码上进行评估，这些掩码的并集等于真值语义区域，从而确保在所有设计的案例中语义准确度都相同。所有计算必须由你的程序实现，无需读取输入。\n\n使用的基本基础和定义：\n- 使用交并比（Intersection-over-Union, IoU）为每个类别定义真值实例和预测实例之间的匹配。对于每个真值实例掩码 $g$ 和预测实例掩码 $p$，将 IoU 定义为 $|g \\cap p| / |g \\cup p|$，其中 $|\\cdot|$ 表示以像素为单位测量的集合基数。\n- 通过最大化总 IoU 来构建实例间的一对一匹配，约束条件是只有 IoU 严格大于 $0.5$ 的配对才有资格。未匹配的真值实例计为假阴性（false negatives, FN），未匹配的预测实例计为假阳性（false positives, FP），而已匹配的配对计为真阳性（true positives, TP）。\n- 将分割质量（Segmentation Quality, SQ）定义为所有匹配对的平均 IoU，并约定如果真阳性数量 $|TP|$ 为 $0$，则 $SQ=0$。\n- 将识别质量（Recognition Quality, RQ）定义为 $2|TP|/(2|TP| + |FP| + |FN|)$，这是在上述阈值匹配协议下，实例识别的 F1 风格项。\n- 从基本原理出发定义全景质量（Panoptic Quality, PQ），将其视为每个匹配的质量分量与识别分量的乘积。首先从标准定义开始，即匹配对的 IoU 总和除以一个带惩罚的检测计数，即分母 $|TP| + 0.5|FP| + 0.5|FN|$。展示这如何得出一个乘法分解，而无需预先声明。\n\n你的程序必须：\n1. 使用上述 IoU 定义和 IoU 严格大于 $0.5$ 的阈值，实现每类的实例匹配。匹配必须是一对一的，并且必须最大化所有接受配对的 IoU 总和。\n2. 计算 $SQ$、$RQ$ 及其乘积 $PQ$，并计算语义准确度，即预测与真值之间语义类别标签匹配的像素比例。使用约定：背景标签为 $0$，单一前景语义类别由任何正整数实例标识符编码。对于语义准确度，合并所有实例，仅考虑前景与背景，而不考虑实例身份。此问题中没有物理单位。\n3. 使用以下测试套件，每个测试都在一个大小为 $10 \\times 10$ 像素的图像上进行。本说明中的所有数字和索引在区间表示法中都包含起始索引且不包含结束索引，行和列索引从 $0$ 开始。\n   - 案例 A（完美预测）：\n     - 真值：一个覆盖所有 $10 \\times 10$ 像素的实例。该实例使用标签值 $1$，实例外的背景使用 $0$（此处没有背景）。\n     - 预测：与真值相同。\n   - 案例 B（过度合并，语义相同）：\n     - 真值：两个大小分别为 $60$ 和 $40$ 像素的不相交实例，通过在所有列 $[0,10)$ 上，用实例标签 $1$ 填充行 $[0,6)$，用实例标签 $2$ 填充行 $[6,10)$ 来创建。\n     - 预测：一个合并后的实例，用标签 $1$ 覆盖所有 $10 \\times 10$ 像素。\n   - 案例 C（过度分割，语义相同）：\n     - 真值：一个用标签 $1$ 覆盖所有 $10 \\times 10$ 像素的实例。\n     - 预测：两个大小分别为 $60$ 和 $40$ 像素的不相交实例，通过在所有列 $[0,10)$ 上，用实例标签 $1$ 填充行 $[0,6)$，用实例标签 $2$ 填充行 $[6,10)$ 来创建。\n   - 案例 D（极端过度分割，语义相同）：\n     - 真值：一个用标签 $1$ 覆盖所有 $10 \\times 10$ 像素的实例。\n     - 预测：四个大小各为 $25$ 的不相交实例，以四个 $5 \\times 5$ 的象限形式放置：左上角行 $[0,5)$、列 $[0,5)$ 标签为 $1$；右上角行 $[0,5)$、列 $[5,10)$ 标签为 $2$；左下角行 $[5,10)$、列 $[0,5)$ 标签为 $3$；右下角行 $[5,10)$、列 $[5,10)$ 标签为 $4$。\n\n要求：\n- 匹配必须使用 IoU 严格大于 $0.5$ 的阈值。\n- 对于每个案例，计算 $PQ$、$SQ$、$RQ$ 和语义准确度。所有值必须是四舍五入到 $6$ 位小数的浮点数。\n- 最终输出格式：你的程序应生成单行输出，其中包含按案例 A、B、C、D 顺序排列的结果，格式为一个由四元素列表组成的逗号分隔列表，每个内部列表为 $[PQ,SQ,RQ,SA]$，其中 $SA$ 为语义准确度。例如：\"[[vA1,vA2,vA3,vA4],[vB1,vB2,vB3,vB4],[vC1,vC2,vC3,vC4],[vD1,vD2,vD3,vD4]]\"。\n- 输出必须与所述测试套件和上述定义一致，并且必须说明过度合并和过度分割如何在语义相同的情况下产生相同的语义准确度，同时区分出识别与分割组件的敏感性。",
            "solution": "用户提供的问题被评估为**有效**。它在科学上植根于计算机视觉评估指标的原理，特别是全景分割。该问题定义明确，提供了一套自洽的定义、约束和测试数据，允许一个唯一的、可验证的解决方案。所有术语都得到了客观且无歧义的定义。该任务要求进行形式化推导和具体实现，是科学计算领域一个实质性且结构良好的练习。\n\n### 理论基础与度量分解\n\n该问题围绕**全景质量（Panoptic Quality, $PQ$）**展开，这是一种用于评估全景分割任务的度量。全景分割统一了语义分割（为每个像素分配一个类别标签）和实例分割（检测并分割单个对象实例）。$PQ$ 度量可以优雅地分解为两个组成部分：**分割质量（Segmentation Quality, $SQ$）**和**识别质量（Recognition Quality, $RQ$）**。\n\n设一组**真值**实例掩码表示为 $\\{g_i\\}$，一组预测实例掩码表示为 $\\{p_j\\}$。基础度量定义如下：\n\n1.  **交并比 (IoU)**：对于一个**真值**实例 $g$ 和一个预测实例 $p$，IoU 由下式给出：\n    $$ \\text{IoU}(g, p) = \\frac{|g \\cap p|}{|g \\cup p|} $$\n    其中 $|\\cdot|$ 表示集合的基数（像素数量）。\n\n2.  **实例匹配**：在**真值**实例和预测实例之间建立**一对一匹配**。只有当一对 $(g, p)$ 的 $\\text{IoU}(g, p) > 0.5$ 时，才被视为一个潜在的匹配。在所有可能的潜在配对的一对一匹配中，选择使 IoU 总和最大化的那一个。这构成了一个**最大权二分图匹配**问题。\n    -   **真阳性 ($TP$)**：由此过程产生的匹配对 $(g, p)$ 的集合。\n    -   **假阴性 ($FN$)**：保持未匹配状态的**真值**实例的集合。\n    -   **假阳性 ($FP$)**：保持未匹配状态的预测实例的集合。\n\n根据这些计数，质量度量定义如下：\n\n-   **分割质量 ($SQ$)**：此项衡量所有正确匹配实例（**真阳性**）的平均 IoU。它反映了检测到的对象的像素被分割得有多好。\n    $$ SQ = \\frac{\\sum_{(g,p) \\in TP} \\text{IoU}(g,p)}{|TP|} $$\n    按照惯例，如果 $|TP|=0$，则 $SQ=0$。\n\n-   **识别质量 ($RQ$)**：这是一个在实例检测级别上计算的 F1 分数。它衡量模型检测对象的好坏，而不考虑分割的准确性。\n    $$ RQ = \\frac{|TP|}{|TP| + \\frac{1}{2}|FP| + \\frac{1}{2}|FN|} = \\frac{2|TP|}{2|TP|+|FP|+|FN|} $$\n\n-   **全景质量 ($PQ$)**：该问题提供了 $PQ$ 的基本定义，即匹配对的总 IoU，并由错误检测的数量进行惩罚。\n    $$ PQ = \\frac{\\sum_{(g,p) \\in TP} \\text{IoU}(g,p)}{|TP| + \\frac{1}{2}|FP| + \\frac{1}{2}|FN|} $$\n\n**$PQ$ 的分解**：我们可以证明 $PQ$ 是 $SQ$ 和 $RQ$ 的乘积。从 $PQ$ 的定义出发，我们可以将其重写为：\n$$ PQ = \\left( \\frac{\\sum_{(g,p) \\in TP} \\text{IoU}(g,p)}{|TP|} \\right) \\times \\left( \\frac{|TP|}{|TP| + \\frac{1}{2}|FP| + \\frac{1}{2}|FN|} \\right) $$\n当 $|TP| > 0$ 时，此操作有效。第一项正是 $SQ$ 的定义，第二项是 $RQ$ 的定义。因此：\n$$ PQ = SQ \\times RQ $$\n如果 $|TP|=0$，根据定义 $SQ=0$ 且 $PQ$ 的分子为 $0$，使得 $PQ=0$。$RQ$ 的分子也为 $0$，使得 $RQ=0$。恒等式 $PQ = SQ \\times RQ$ 仍然成立，因为 $0 = 0 \\times 0$。这种**乘法分解**表明，$PQ$ 联合测量了分割和识别质量。$PQ=1$ 的完美分数既需要完美的识别（$RQ=1$，意味着没有未匹配的实例），也需要完美的分割（$SQ=1$，意味着所有匹配实例的 IoU 均为 $1$）。\n\n-   **语义准确度 ($SA$)**：这是一个更简单的像素级度量，它忽略了实例信息。所有正的实例标签都被合并成一个单一的“前景”类别。$SA$ 是预测和**真值**中语义标签（前景 vs. 背景）相同的像素所占的比例。\n\n### 算法实现与案例分析\n\n实现的核心涉及一个函数，该函数接收**真值**和预测掩码，识别唯一实例，计算成对的 IoU 矩阵，解决分配问题以找到最优匹配，然后计算各项度量。\n\n-   **匹配**：通过解决**最大权二分图匹配**问题来找到匹配。我们构建一个成本矩阵，其中将**真值**实例 $i$ 与预测实例 $j$ 匹配的成本是 $-\\text{IoU}(g_i, p_j)$（如果 $\\text{IoU}(g_i, p_j) > 0.5$），否则为一个大的正数（以防止匹配）。使用 `scipy.optimize.linear_sum_assignment` 来找到最小成本分配，这对应于最大 IoU 总和。\n\n分析在 $10 \\times 10$ 图像上的四个测试案例上进行。\n\n**案例 A：完美预测**\n-   真值 ($GT$)：1个实例，大小 $100$。\n-   预测 ($Pred$)：1个实例，大小 $100$。\n-   IoU 矩阵：一个值为 $1.0$ 的 $1 \\times 1$ 矩阵。\n-   匹配：单个 $GT$ 实例与单个 $Pred$ 实例匹配，$\\text{IoU}=1.0$。\n-   计数：$|TP|=1$，$|FP|=0$，$|FN|=0$。\n-   度量：\n    -   $SQ = 1.0 / 1 = 1.0$\n    -   $RQ = (2 \\times 1) / (2 \\times 1 + 0 + 0) = 1.0$\n    -   $PQ = SQ \\times RQ = 1.0 \\times 1.0 = 1.0$\n    -   $SA = (100 \\text{ 个匹配像素}) / 100 = 1.0$\n-   结果：$[1.0, 1.0, 1.0, 1.0]$\n\n**案例 B：过度合并**\n-   $GT$：2个实例，$g_1$ (大小 $60$) 和 $g_2$ (大小 $40$)。\n-   $Pred$：1个实例，$p_1$ (大小 $100$)。\n-   IoU：$\\text{IoU}(g_1, p_1) = 60/100 = 0.6$。$\\text{IoU}(g_2, p_1) = 40/100 = 0.4$。\n-   匹配：由于 $\\text{IoU}(g_2, p_1) \\le 0.5$，它不是一个有效的匹配候选项。$p_1$ 只能与 $g_1$ 匹配。\n-   计数：$|TP|=1$（对于配对 $(g_1, p_1)$），$|FP|=0$（单个预测实例被匹配），$|FN|=1$（$g_2$ 未匹配）。\n-   度量：\n    -   $SQ = 0.6 / 1 = 0.6$\n    -   $RQ = (2 \\times 1) / (2 \\times 1 + 0 + 1) = 2/3 \\approx 0.666667$\n    -   $PQ = SQ \\times RQ = 0.6 \\times (2/3) = 0.4$\n    -   $SA$：$GT$ 和 $Pred$ 都覆盖了全部 $100$ 个像素，因此它们在语义上是相同的。$SA=1.0$。\n-   结果：$[0.4, 0.6, 0.666667, 1.0]$\n\n**案例 C：过度分割**\n-   $GT$：1个实例，$g_1$ (大小 $100$)。\n-   $Pred$：2个实例，$p_1$ (大小 $60$) 和 $p_2$ (大小 $40$)。\n-   IoU：$\\text{IoU}(g_1, p_1) = 60/100 = 0.6$。$\\text{IoU}(g_1, p_2) = 40/100 = 0.4$。\n-   匹配：$g_1$ 只能匹配一个预测。它与 $p_1$ 匹配，因为 $\\text{IoU}(g_1, p_1) > 0.5$。\n-   计数：$|TP|=1$（对于配对 $(g_1, p_1)$），$|FP|=1$（$p_2$ 未匹配），$|FN|=0$（单个 $GT$ 实例被匹配）。\n-   度量：\n    -   $SQ = 0.6 / 1 = 0.6$\n    -   $RQ = (2 \\times 1) / (2 \\times 1 + 1 + 0) = 2/3 \\approx 0.666667$\n    -   $PQ = SQ \\times RQ = 0.6 \\times (2/3) = 0.4$\n    -   $SA$：语义上与 $GT$ 相同，所以 $SA=1.0$。\n-   结果：$[0.4, 0.6, 0.666667, 1.0]$。值得注意的是，这与案例 B 的结果相同，表明 $PQ$ 对一个假合并（1个 $FN$）和一个假分割（1个 $FP$）的惩罚是对称的。\n\n**案例 D：极端过度分割**\n-   $GT$：1个实例，$g_1$ (大小 $100$)。\n-   $Pred$：4个实例，$p_1, p_2, p_3, p_4$ (每个大小为 $25$)。\n-   IoU：对于任何 $p_i$，$\\text{IoU}(g_1, p_i) = 25/100 = 0.25$。\n-   匹配：由于所有 IoU 值均为 $0.25$，不严格大于 $0.5$，因此无法进行匹配。\n-   计数：$|TP|=0$，$|FP|=4$（所有四个预测实例都未匹配），$|FN|=1$（$g_1$ 未匹配）。\n-   度量：\n    -   $SQ$：由于 $|TP|=0$，根据定义 $SQ=0.0$。\n    -   $RQ$：由于 $|TP|=0$，$RQ = 0 / (0+4+1) = 0.0$。\n    -   $PQ = SQ \\times RQ = 0.0 \\times 0.0 = 0.0$。\n    -   $SA$：语义上与 $GT$ 相同，所以 $SA=1.0$。\n-   结果：$[0.0, 0.0, 0.0, 1.0]$。这突显了识别上的灾难性失败（$RQ=0$），它将整体 $PQ$ 推向零，尽管单个（但未被识别的）部分的分割质量可能很高，且语义准确度是完美的。\n\n这些案例正确地展示了 $PQ$ 及其组件如何提供对实例级错误的细致评估，而这是语义准确度完全无法捕捉的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef get_test_cases():\n    \"\"\"Generates the four test cases as pairs of (gt_mask, pred_mask).\"\"\"\n    cases = []\n    \n    # Case A: Perfect prediction\n    gt_a = np.ones((10, 10), dtype=int)\n    pred_a = np.ones((10, 10), dtype=int)\n    cases.append(('A', gt_a, pred_a))\n\n    # Case B: Over-merge\n    gt_b = np.zeros((10, 10), dtype=int)\n    gt_b[0:6, :] = 1\n    gt_b[6:10, :] = 2\n    pred_b = np.ones((10, 10), dtype=int)\n    cases.append(('B', gt_b, pred_b))\n\n    # Case C: Over-split\n    gt_c = np.ones((10, 10), dtype=int)\n    pred_c = np.zeros((10, 10), dtype=int)\n    pred_c[0:6, :] = 1\n    pred_c[6:10, :] = 2\n    cases.append(('C', gt_c, pred_c))\n\n    # Case D: Extreme over-split\n    gt_d = np.ones((10, 10), dtype=int)\n    pred_d = np.zeros((10, 10), dtype=int)\n    pred_d[0:5, 0:5] = 1\n    pred_d[0:5, 5:10] = 2\n    pred_d[5:10, 0:5] = 3\n    pred_d[5:10, 5:10] = 4\n    cases.append(('D', gt_d, pred_d))\n    \n    return cases\n\ndef calculate_metrics(gt_mask, pred_mask, iou_threshold=0.5):\n    \"\"\"\n    Computes PQ, SQ, RQ, and SA for a given pair of masks.\n    \"\"\"\n    # 1. Semantic Accuracy (SA)\n    gt_semantic = gt_mask > 0\n    pred_semantic = pred_mask > 0\n    sa = np.mean(gt_semantic == pred_semantic)\n\n    # 2. Instance Extraction\n    gt_ids = np.unique(gt_mask[gt_mask > 0])\n    pred_ids = np.unique(pred_mask[pred_mask > 0])\n    \n    num_gt = len(gt_ids)\n    num_pred = len(pred_ids)\n    \n    if num_gt == 0 and num_pred == 0:\n        return 1.0, 1.0, 1.0, sa # PQ, SQ, RQ, SA\n\n    # 3. IoU Matrix Calculation\n    iou_matrix = np.zeros((num_gt, num_pred))\n    for i, gt_id in enumerate(gt_ids):\n        g_mask = (gt_mask == gt_id)\n        for j, pred_id in enumerate(pred_ids):\n            p_mask = (pred_mask == pred_id)\n            intersection = np.sum(np.logical_and(g_mask, p_mask))\n            union = np.sum(np.logical_or(g_mask, p_mask))\n            iou = intersection / union if union > 0 else 0\n            iou_matrix[i, j] = iou\n\n    # 4. Instance Matching (Maximum Weight Bipartite Matching)\n    # We want to maximize sum of IoUs, which is equivalent to minimizing sum of -IoUs.\n    # Set costs for invalid matches (IoU = threshold) to a high value.\n    cost_matrix = -iou_matrix\n    cost_matrix[iou_matrix = iou_threshold] = 1.0 # high cost for non-matchable pairs\n    \n    gt_ind, pred_ind = linear_sum_assignment(cost_matrix)\n    \n    # Filter matches to only include those above the threshold\n    matched_pairs = []\n    sum_iou = 0.0\n    for r, c in zip(gt_ind, pred_ind):\n        if iou_matrix[r, c] > iou_threshold:\n            matched_pairs.append((r, c))\n            sum_iou += iou_matrix[r, c]\n            \n    # 5. Calculate TP, FP, FN\n    tp = len(matched_pairs)\n    fp = num_pred - tp\n    fn = num_gt - tp\n    \n    # 6. Calculate SQ, RQ, PQ\n    # Segmentation Quality\n    sq = sum_iou / tp if tp > 0 else 0.0\n\n    # Recognition Quality\n    denominator_rq = 2 * tp + fp + fn\n    rq = (2 * tp) / denominator_rq if denominator_rq > 0 else 0.0\n    \n    # Panoptic Quality\n    # Using the product form, which is equivalent to the first-principles definition\n    pq = sq * rq\n    \n    # Round all values to 6 decimal places\n    pq = round(pq, 6)\n    sq = round(sq, 6)\n    rq = round(rq, 6)\n    sa = round(sa, 6)\n    \n    return [pq, sq, rq, sa]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = get_test_cases()\n    \n    all_results = []\n    for name, gt, pred in test_cases:\n        result = calculate_metrics(gt, pred)\n        all_results.append(result)\n\n    # Format the final output string\n    result_strings = []\n    for res in all_results:\n        result_strings.append(f\"[{','.join(map(str, res))}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "标准的损失函数通常独立地处理每个像素，忽略了图像中宝贵的结构信息。为了创造更真实、更连贯的分割结果，我们可以设计能够融合空间上下文的损失函数。这项高级练习  介绍了一种强大的方法：将像素网格建模为图，并利用图拉普拉斯算子（graph Laplacian）定义一个结构感知的平滑惩罚项，从而在深度学习与经典的基于图的视觉方法之间架起一座桥梁。",
            "id": "3136266",
            "problem": "将一个二维像素网格视为一个无向加权图，其中每个像素是一个节点，边连接着四邻域像素。设网格大小为 $N \\times N$，其中 $N \\in \\mathbb{N}$。用 $\\mathcal{V}$ 表示所有像素的集合，其中 $|\\mathcal{V}| = n$，并通过一个展平映射将像素索引到一个向量空间 $\\mathbb{R}^{n}$ 中。设 $I \\in \\mathbb{R}^{n}$ 表示给定的强度图像，设 $y \\in \\{0,1\\}^{n}$ 表示单个语义类别（语义分割）的二元真实分割。定义对称加权邻接矩阵 $W \\in \\mathbb{R}^{n \\times n}$ 如下：\n$$\nW_{ij} = \n\\begin{cases}\n\\exp\\big(-\\beta \\, |I_i - I_j|\\big)  \\text{如果像素 $i$ 和 $j$ 是四邻域}, \\\\\n0  \\text{否则},\n\\end{cases}\n$$\n其中 $\\beta \\in \\mathbb{R}_{\\ge 0}$ 控制对强度差异的敏感度。定义对角度矩阵 $D \\in \\mathbb{R}^{n \\times n}$ 为 $D_{ii} = \\sum_{j=1}^{n} W_{ij}$，组合图拉普拉斯算子 $\\mathcal{L} \\in \\mathbb{R}^{n \\times n}$ 为 $\\mathcal{L} = D - W$。\n\n对于一个表示逐像素类别概率的实值预测向量 $p \\in \\mathbb{R}^{n}$，考虑基于图差分的结构感知平滑惩罚项\n$$\nL_{\\text{smooth}}(p) = \\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} \\, \\|p_i - p_j\\|_2^2,\n$$\n和数据保真项\n$$\nL_{\\text{data}}(p) = \\|p - y\\|_2^2.\n$$\n定义组合损失\n$$\nL_{\\text{total}}(p) = L_{\\text{data}}(p) + \\lambda \\, L_{\\text{smooth}}(p),\n$$\n其中 $\\lambda \\in \\mathbb{R}_{\\ge 0}$ 控制平滑度与清晰度的权衡。从图拉普拉斯算子、度矩阵和欧几里得范数的基石定义出发，推导 $L_{\\text{total}}(p)$ 的无约束最小化子 $p^\\star \\in \\mathbb{R}^{n}$ 的一阶最优性条件，并通过求解得到的线性系统计算 $p^\\star$。使用图差分和拉普拉斯二次型之间已建立的恒等关系来证明平滑项的半正定性以及最小化子的存在性和唯一性。\n\n对于每个测试用例，计算在最小化子 $p^\\star$ 处的两个标量值：\n- 数据项的值 $D = L_{\\text{data}}(p^\\star)$。\n- 平滑项的值 $S = L_{\\text{smooth}}(p^\\star)$。\n\n返回每个测试用例的序列 $[D,S]$，展平成一个浮点数列表，四舍五入到六位小数。\n\n您的程序必须实现以下具有固定参数的测试套件，构建相应的图，求解 $p^\\star$，并输出指定的结果：\n\n- 测试用例 1（一般边缘感知平滑，理想路径）：\n    - 网格大小 $N = 8$。\n    - 强度图像 $I$：左半部分列的强度为 $0$，右半部分列的强度为 $1$。\n    - 真实分割 $y$：类别存在于左半部分（第 $1$ 到 $4$ 列为 $1$，第 $5$ 到 $8$ 列为 $0$）。\n    - 平滑权重 $\\lambda = 0.1$。\n    - 边缘敏感度 $\\beta = 5.0$。\n- 测试用例 2（边界条件，无平滑）：\n    - 网格大小 $N = 8$。\n    - 强度图像 $I$：与测试用例 1 相同。\n    - 真实分割 $y$：与测试用例 1 相同。\n    - 平滑权重 $\\lambda = 0$。\n    - 边缘敏感度 $\\beta = 5.0$。\n- 测试用例 3（强平滑，清晰度被抑制）：\n    - 网格大小 $N = 8$。\n    - 强度图像 $I$：与测试用例 1 相同。\n    - 真实分割 $y$：与测试用例 1 相同。\n    - 平滑权重 $\\lambda = 10.0$。\n    - 边缘敏感度 $\\beta = 5.0$。\n- 测试用例 4（强度均匀且实例较小的边缘情况）：\n    - 网格大小 $N = 8$。\n    - 强度图像 $I$：全为零。\n    - 真实分割 $y$：一个 $2 \\times 2$ 的 1 方块，中心位于第 $4$ 和 $5$ 行、第 $4$ 和 $5$ 列，其余为零。\n    - 平滑权重 $\\lambda = 0.5$。\n    - 边缘敏感度 $\\beta = 0.0$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序固定为\n$$\n[D_1,S_1,D_2,S_2,D_3,S_3,D_4,S_4],\n$$\n并四舍五入到六位小数。",
            "solution": "该问题要求推导最小化组合损失函数的最优预测向量 $p^\\star$，然后计算几个测试用例的特定量。总损失由 $L_{\\text{total}}(p) = L_{\\text{data}}(p) + \\lambda \\, L_{\\text{smooth}}(p)$ 给出。\n\n首先，我们验证问题陈述的有效性。所有给出的定义——网格作为图、加权邻接矩阵 $W$、度矩阵 $D$、图拉普拉斯算子 $\\mathcal{L}$ 以及损失分量 $L_{\\text{data}}$ 和 $L_{\\text{smooth}}$——在图信号处理和机器学习领域都是标准的且数学上明确定义的。该问题是图结构域上吉洪诺夫正则化的一个经典例子。目标函数是严格凸的，确保了唯一最小化子的存在，这使得问题是适定的。所有测试用例的参数都已明确指定且在科学上是合理的。因此，该问题被认为是有效的，我们继续进行求解。\n\n任务的核心是找到总损失函数的最小化子 $p^\\star$：\n$$\nL_{\\text{total}}(p) = \\|p - y\\|_2^2 + \\lambda \\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} \\, (p_i - p_j)^2\n$$\n其中 $p \\in \\mathbb{R}^n$ 是预测向量，$y \\in \\{0,1\\}^n$ 是真实分割，$\\lambda \\in \\mathbb{R}_{\\ge 0}$ 是一个正则化参数。\n\n为了便于最小化，我们首先将损失函数表示为矩阵向量形式。数据保真项已经是一个方便的形式：\n$$\nL_{\\text{data}}(p) = \\|p - y\\|_2^2 = (p-y)^T(p-y) = p^T p - 2p^T y + y^T y\n$$\n\n接下来，我们分析结构感知平滑项 $L_{\\text{smooth}}(p)$。该项是一个涉及图拉普拉斯算子 $\\mathcal{L} = D - W$ 的二次型。我们建立恒等式 $L_{\\text{smooth}}(p) = 2p^T \\mathcal{L} p$。\n推导过程如下：\n$$\nL_{\\text{smooth}}(p) = \\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} (p_i - p_j)^2 = \\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} (p_i^2 - 2p_i p_j + p_j^2)\n$$\n展开求和：\n$$\nL_{\\text{smooth}}(p) = \\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} p_i^2 - 2\\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} p_i p_j + \\sum_{i=1}^{n}\\sum_{j=1}^{n} W_{ij} p_j^2\n$$\n根据度矩阵的定义，$D_{ii} = \\sum_{j=1}^{n} W_{ij}$。第一项变为 $\\sum_{i=1}^{n} p_i^2 D_{ii} = p^T D p$。\n对于第三项，我们利用邻接矩阵的对称性 $W_{ij} = W_{ji}$，因此 $\\sum_{i=1}^{n} W_{ij} = \\sum_{i=1}^{n} W_{ji} = D_{jj}$。第三项是 $\\sum_{j=1}^{n} p_j^2 D_{jj} = p^T D p$。\n中间项是 $-2 \\sum_{i,j} p_i W_{ij} p_j = -2 p^T W p$。\n合并这些部分：\n$$\nL_{\\text{smooth}}(p) = p^T D p - 2 p^T W p + p^T D p = 2 p^T D p - 2 p^T W p = 2 p^T (D-W) p = 2 p^T \\mathcal{L} p\n$$\n因此，总损失函数可以写成：\n$$\nL_{\\text{total}}(p) = (p-y)^T(p-y) + 2\\lambda p^T \\mathcal{L} p = p^T p - 2p^T y + y^T y + 2\\lambda p^T \\mathcal{L} p \\\\\nL_{\\text{total}}(p) = p^T(I_n + 2\\lambda \\mathcal{L})p - 2p^T y + y^T y\n$$\n其中 $I_n$ 是 $n \\times n$ 的单位矩阵。\n\n为了找到最小化子 $p^\\star$，我们计算 $L_{\\text{total}}(p)$ 关于 $p$ 的梯度并将其设为零。使用标准的矩阵微积分恒等式 $\\nabla_p (p^T A p) = (A + A^T)p$ 和 $\\nabla_p(b^T p) = b$。\n矩阵 $A = I_n + 2\\lambda \\mathcal{L}$ 是对称的，因为 $I_n$ 是对称的，且对于无向图，图拉普拉斯算子 $\\mathcal{L}=D-W$ 是对称的。因此，$A^T=A$ 且 $\\nabla_p(p^T A p) = 2Ap$。\n梯度为：\n$$\n\\nabla_p L_{\\text{total}}(p) = 2(I_n + 2\\lambda \\mathcal{L})p - 2y\n$$\n将梯度设为零，得到一阶最优性条件：\n$$\n2(I_n + 2\\lambda \\mathcal{L})p^\\star - 2y = 0 \\\\\n(I_n + 2\\lambda \\mathcal{L})p^\\star = y\n$$\n这是一个 $Ax=b$ 形式的线性方程组，其中 $A = I_n + 2\\lambda \\mathcal{L}$，$x=p^\\star$，$b=y$。\n\n最小化子 $p^\\star$ 的存在性和唯一性由矩阵 $I_n + 2\\lambda \\mathcal{L}$ 的性质保证。问题要求证明平滑项的半正定性。项 $L_{\\text{smooth}}(p) = \\sum_{i,j} W_{ij}(p_i-p_j)^2$ 是非负项之和，因为 $W_{ij} \\ge 0$（由 $\\beta \\ge 0$ 得出）且 $(p_i-p_j)^2 \\ge 0$。因此，对于所有 $p$，$L_{\\text{smooth}}(p) \\ge 0$。正如我们已经证明的 $L_{\\text{smooth}}(p) = 2p^T\\mathcal{L}p$，可以得出图拉普拉斯算子 $\\mathcal{L}$ 是一个半正定矩阵。\n矩阵 $I_n$ 是正定的。对于 $\\lambda \\ge 0$，矩阵 $2\\lambda\\mathcal{L}$ 是半正定的。一个正定矩阵和一个半正定矩阵的和是正定的。因此，对于任何 $\\lambda \\ge 0$，系统矩阵 $(I_n + 2\\lambda \\mathcal{L})$ 都是正定的，这意味着它是可逆的。这保证了唯一的解 $p^\\star$ 存在，并且可以通过求解该线性系统找到。总损失函数 $L_{\\text{total}}(p)$ 是严格凸的。\n\n解 $p^\\star$ 为：\n$$\np^\\star = (I_n + 2\\lambda \\mathcal{L})^{-1}y\n$$\n在数值上，这是通过直接求解线性系统而不是计算逆矩阵来找到的。\n计算出 $p^\\star$ 后，所需的量为：\n- 数据项：$D = L_{\\text{data}}(p^\\star) = \\|p^\\star - y\\|_2^2 = \\sum_{i=1}^n (p^\\star_i - y_i)^2$。\n- 平滑项：$S = L_{\\text{smooth}}(p^\\star) = 2(p^\\star)^T \\mathcal{L} p^\\star$。\n\n每个测试用例的算法如下：\n1.  构建 $N \\times N$ 的强度图像 $I$ 和真实分割 $y$，然后将它们展平成 $n$ 维向量，其中 $n = N^2$。\n2.  构建稀疏加权邻接矩阵 $W \\in \\mathbb{R}^{n \\times n}$。\n3.  计算稀疏度矩阵 $D$ 和图拉普拉斯算子 $\\mathcal{L} = D-W$。\n4.  如果 $\\lambda = 0$，解就是 $p^\\star = y$。否则，求解线性系统 $(I_n + 2\\lambda \\mathcal{L})p^\\star = y$ 以获得 $p^\\star$。\n5.  计算并存储值 $D = L_{\\text{data}}(p^\\star)$ 和 $S = L_{\\text{smooth}}(p^\\star)$。\n对所有四个测试用例执行此过程。",
            "answer": "```python\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Main function to execute all test cases and print the final results.\n    \"\"\"\n\n    def solve_case(N, I_grid, y_grid, lam, beta):\n        \"\"\"\n        Solves the regularized linear system for a single test case.\n\n        Args:\n            N (int): Grid size.\n            I_grid (np.ndarray): N x N intensity image.\n            y_grid (np.ndarray): N x N ground truth segmentation.\n            lam (float): Smoothness weight lambda.\n            beta (float): Edge sensitivity beta.\n\n        Returns:\n            tuple: A tuple containing the data term (D) and smoothness term (S).\n        \"\"\"\n        n = N * N\n        I = I_grid.flatten()\n        y = y_grid.flatten()\n\n        # Use LIL format for efficient sparse matrix construction\n        W = sparse.lil_matrix((n, n))\n        \n        for i in range(n):\n            r, c = i // N, i % N\n            # Iterate over 4-connected neighbors\n            for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                nr, nc = r + dr, c + dc\n                if 0 = nr  N and 0 = nc  N:\n                    j = nr * N + nc\n                    weight = np.exp(-beta * np.abs(I[i] - I[j]))\n                    W[i, j] = weight\n\n        # Convert to CSR format for efficient algebraic operations\n        W_csr = W.tocsr()\n        \n        # Compute the degree matrix D\n        degree_vector = np.array(W_csr.sum(axis=1)).flatten()\n        D = sparse.diags(degree_vector, format='csr')\n        \n        # Compute the combinatorial graph Laplacian L\n        L = D - W_csr\n        \n        # If lambda is zero, no smoothing is applied, p_star is just the ground truth\n        if lam == 0:\n            p_star = y.copy()\n        else:\n            # Construct the system matrix A = I + 2*lambda*L\n            A = sparse.identity(n, format='csr') + 2 * lam * L\n            \n            # Solve the linear system Ap* = y for p*\n            p_star = spsolve(A, y)\n\n        # Calculate the final data and smoothness term values\n        data_term = np.sum((p_star - y)**2)\n        # L_smooth(p) = 2 * p.T @ L @ p, as derived in the solution\n        smoothness_term = 2 * p_star.T @ (L @ p_star)\n        \n        return data_term, smoothness_term\n\n    # --- Test Case Definitions ---\n    N = 8\n    \n    # Common Intensity and Ground Truth for Cases 1, 2, 3\n    I_common = np.zeros((N, N))\n    I_common[:, N//2:] = 1\n    y_common = np.zeros((N, N))\n    y_common[:, :N//2] = 1\n\n    # Ground Truth for Case 4\n    I4 = np.zeros((N, N))\n    y4 = np.zeros((N, N))\n    # A 2x2 square of ones centered at rows 4,5 and cols 4,5 (1-based),\n    # which is indices 3,4 (0-based).\n    y4[N//2-1:N//2+1, N//2-1:N//2+1] = 1\n\n    test_cases = [\n        # Case 1: General edge-aware smoothing\n        {'N': N, 'I_grid': I_common, 'y_grid': y_common, 'lam': 0.1, 'beta': 5.0},\n        # Case 2: Boundary condition, no smoothing\n        {'N': N, 'I_grid': I_common, 'y_grid': y_common, 'lam': 0.0, 'beta': 5.0},\n        # Case 3: Strong smoothing, sharpness suppressed\n        {'N': N, 'I_grid': I_common, 'y_grid': y_common, 'lam': 10.0, 'beta': 5.0},\n        # Case 4: Edge case with uniform intensities\n        {'N': N, 'I_grid': I4, 'y_grid': y4, 'lam': 0.5, 'beta': 0.0},\n    ]\n\n    results = []\n    for params in test_cases:\n        D_val, S_val = solve_case(**params)\n        results.extend([D_val, S_val])\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}