## 引言
基于能量的模型（Energy-based Models, EBMs）是机器学习中一类极为强大且灵活的[概率建模](@entry_id:168598)框架。其核心思想是，不直接定义一个复杂的、需要归一化的概率密度函数，而是通过一个可学习的标量**能量函数**来为每个数据点赋予一个“可能性”得分。这种方法的优雅之处在于其无与伦比的灵活性——任何能将输入映射到标量的函数（如[深度神经网络](@entry_id:636170)）都可以用作能量函数，从而捕获极其复杂的数据[分布](@entry_id:182848)。

然而，这种灵活性也带来了其核心的理论与实践挑战：即难以处理的**[配分函数](@entry_id:193625)**（partition function）。这个归一化常数需要在整个高维空间上进行积分，这在计算上是不可行的，从而给模型的训练、采样和评估带来了巨大障碍。本文旨在系统性地解决这一知识鸿沟，带领读者深入理解EBMs的工作原理，并掌握应对其挑战的现代方法。

为此，本文将分为三个部分展开。我们将在**“原理与机制”**一章中，从[概率论基础](@entry_id:158925)出发，阐明[最大似然](@entry_id:146147)训练的“推拉”动态，并深入剖析[MCMC采样](@entry_id:751801)在其中扮演的关键角色与挑战。随后，在**“应用与跨学科连接”**一章中，我们将探索EBMs的通用性，展示其在[生成建模](@entry_id:165487)、鲁棒性与安全、[结构化预测](@entry_id:634975)以及科学发现等多个领域的强大应用。最后，通过**“动手实践”**部分，您将有机会将理论付诸实践，巩固对EBM训练、评估和[组合性](@entry_id:637804)等核心概念的理解。

## 原理与机制

本章深入探讨了驱动基于能量的模型（Energy-based Models, EBMs）的核心原理与关键机制。我们将从其[概率论基础](@entry_id:158925)出发，阐明其训练[范式](@entry_id:161181)，剖析在实践中遇到的挑战，并介绍旨在克服这些挑战的先进技术。

### 基于能量的模型的概率论框架

从根本上说，一个基于能量的模型通过一个称为**能量函数**的标量函数 $E_\theta(x)$ 来为输入空间中的每一个点 $x$ 赋予一个非标准化的对数概率。该模型的[概率密度函数](@entry_id:140610) $p_\theta(x)$ 由吉布斯-玻尔兹曼分布（Gibbs-Boltzmann distribution）定义：

$$
p_\theta(x) = \frac{\exp(-E_\theta(x))}{Z(\theta)}
$$

在这里，$\theta$ 代表模型的可学习参数，通常是[神经网](@entry_id:276355)络的权重。能量函数 $E_\theta(x)$ 是模型的“心脏”，它将低能量赋予与数据[分布](@entry_id:182848)相似的构型，而将高能量赋予不相似的构型。

分母 $Z(\theta)$ 被称为**[配分函数](@entry_id:193625)**（partition function），它是一个归一化常数，通过对整个输入空间积分（或求和）来确保[概率密度](@entry_id:175496)（或质量）函数的总和为 1：

$$
Z(\theta) = \int_x \exp(-E_\theta(x)) \, dx
$$

对于[离散空间](@entry_id:155685)，积分被替换为求和。[配分函数](@entry_id:193625)的计算通常是 EBMs 中最主要的挑战，因为它需要遍历整个[状态空间](@entry_id:177074)，这对于[高维数据](@entry_id:138874)（如图像或文本）来说是计算上不可行的。因此，EBMs 的训练和推理方法通常致力于规避对 $Z(\theta)$ 的直接计算。

能量函数的具体形式可以多种多样。在连续空间中，一个简单的例子是二次能量函数，例如 $E_\theta(x) = \frac{a}{2} \|x\|^2$ ，它对应一个中心在原点的[高斯分布](@entry_id:154414)。而在离散空间中，一个经典例子是霍普菲尔德网络（Hopfield network），其能量函数定义为 $E(x) = -\frac{1}{2}x^\top Wx - b^\top x$，其中 $x$ 是一个二元向量。在这种情况下，网络的动力学（例如，[异步更新](@entry_id:266256)神经元状态）被设计为总是降低系统的能量，使得存储的模式对应于能量函数的局部最小值 。

此外，我们可以在定义中引入一个**温度**（temperature）参数 $T > 0$，得到一个更广义的形式：

$$
p_\theta^T(x) \propto \exp(-E_\theta(x)/T)
$$

温度 $T$ 控制着[分布](@entry_id:182848)的“尖锐”程度。当 $T \to 0$ 时，概率质量会集中在能量最低的几个点上，使得[分布](@entry_id:182848)变得尖锐；当 $T \to \infty$ 时，能量差异的影响减弱，[分布](@entry_id:182848)趋于均匀。通过调节温度，我们可以控制模型的探索性与利用性。例如，在一个由多个能量“阱”构成的[能量景观](@entry_id:147726)中，温度会影响每个“阱”所占据的总概率质量。具体而言，通过[拉普拉斯近似](@entry_id:636859)（Laplace approximation），可以证明每个能量阱 $i$ 的局部协[方差](@entry_id:200758)与温度 $T$ 成正比，而其总概率质量则依赖于能量最小值 $b_i$ 和局部曲率（由海森矩阵 $H_i$ 描述）与温度的复杂相互作用。这导致温度变化不仅可以“缩放”模式的宽度，还可能“扭曲”模式间的相对权重，这是一个在模型分析中需要考虑的重要现象 。

### 最大似然训练原理

训练 EBMs 最常见的目标是**最大似然估计**（Maximum Likelihood Estimation, MLE）。其目标是[调整参数](@entry_id:756220) $\theta$，使得模型在给定训练数据集 $\mathcal{D} = \{x^{(i)}\}_{i=1}^N$ 上的对数似然最大化。平均对数似然 $\ell(\theta)$ 为：

$$
\ell(\theta) = \frac{1}{N} \sum_{i=1}^N \ln p_\theta(x^{(i)}) = \frac{1}{N} \sum_{i=1}^N \left( -E_\theta(x^{(i)}) - \ln Z(\theta) \right)
$$

为了通过梯度上升来最大化此似然，我们需要计算其关于参数 $\theta$ 的梯度。梯度的计算揭示了 EBM 训练的核心动态：

$$
\nabla_\theta \ell(\theta) = -\frac{1}{N} \sum_{i=1}^N \nabla_\theta E_\theta(x^{(i)}) - \nabla_\theta \ln Z(\theta)
$$

利用[对数导数技巧](@entry_id:751429)（log-derivative trick），我们可以推导出[配分函数](@entry_id:193625)对数梯度的重要性质：
$$
\nabla_\theta \ln Z(\theta) = \frac{1}{Z(\theta)} \nabla_\theta Z(\theta) = \frac{1}{Z(\theta)} \int \nabla_\theta \exp(-E_\theta(x)) \, dx = \int \frac{\exp(-E_\theta(x))}{Z(\theta)} (-\nabla_\theta E_\theta(x)) \, dx = -\mathbb{E}_{x \sim p_\theta(x)}[\nabla_\theta E_\theta(x)]
$$
将此结果代回似然梯度表达式，我们得到：

$$
\nabla_\theta \ell(\theta) = \mathbb{E}_{x \sim p_\theta(x)}[\nabla_\theta E_\theta(x)] - \mathbb{E}_{x \sim p_{\text{data}}(x)}[\nabla_\theta E_\theta(x)]
$$

为了使梯度上升更直观，通常将其写为负梯度下降的形式，即最小化[负对数似然](@entry_id:637801)：
$$
-\nabla_\theta \ell(\theta) = \underbrace{\mathbb{E}_{x \sim p_{\text{data}}(x)}[\nabla_\theta E_\theta(x)]}_{\text{正相 (Positive Phase)}} - \underbrace{\mathbb{E}_{x \sim p_\theta(x)}[\nabla_\theta E_\theta(x)]}_{\text{负相 (Negative Phase)}}
$$

这个梯度表达式极其优美且富有解释性。它由两部分组成：
*   **正相**：在来自真实数据[分布](@entry_id:182848) $p_{\text{data}}$ 的样本（即训练数据）上计算的能量梯度期望。这一项的作用是[调整参数](@entry_id:756220) $\theta$ 以**降低**真实数据点的能量。这可以被看作是模型在“学习”数据。
*   **负相**：在来自模型自身[分布](@entry_id:182848) $p_\theta$ 的样本（称为“负样本”或“幻想粒子”）上计算的能量梯度期望。这一项的作用是[调整参数](@entry_id:756220) $\theta$ 以**升高**模型生成样本的能量。这可以被看作是模型在“反学习”或修正其不完美的表征，防止能量面在所有地方都坍缩为负无穷。

整个学习过程可以被视为一个“推拉”动态：在数据点所在的位置“向下拉”能量函数，在模型倾向于生成样本的位置“向上推”能量函数。

在一个理想化的场景中，如果能量函数的形式允许我们解析地计算负相的期望，那么训练过程将非常直接。例如，考虑一个二次能量函数 $E_\theta(x) = \frac{1}{2}\|x\|^2 - \theta^\top x$。通过[配方法](@entry_id:265480)可以证明，该能量函数对应的[概率分布](@entry_id:146404)是一个均值为 $\theta$、协[方差](@entry_id:200758)为[单位矩阵](@entry_id:156724)的高斯分布 $p_\theta(x) = \mathcal{N}(x | \theta, I)$。在这种情况下，模型期望 $\mathbb{E}_{x \sim p_\theta(x)}[x]$ 就是其均值 $\theta$。梯度更新因此变得异常简单，它驱使参数 $\theta$ 移动到数据样本的均值 $\bar{x}$ 处，这正是[高斯分布](@entry_id:154414)的[最大似然](@entry_id:146147)解 。然而，对于由深度神经网络定义的复杂能量函数，这种解析计算是不可能的，这引出了下一个核心挑战。

### 负相的挑战：MCMC 采样

由于无法解析计算负相中的期望 $\mathbb{E}_{x \sim p_\theta(x)}[\cdot]$，我们必须依赖于近似方法。**马尔可夫链蒙特卡洛（Markov Chain [Monte Carlo](@entry_id:144354), MCMC）** 是从复杂[分布](@entry_id:182848)中采样的标准工具，也自然成为 EBM 训练的核心组件。

MCMC 的基本思想是构建一个[马尔可夫链](@entry_id:150828)，其[平稳分布](@entry_id:194199)（stationary distribution）恰好是我们想要采样的[目标分布](@entry_id:634522) $p_\theta(x)$。如果一个转移核（transition kernel）$P(x'|x)$ 满足**细致平稳条件**（detailed balance condition）：
$$
p_\theta(x) P(x'|x) = p_\theta(x') P(x|x')
$$
那么 $p_\theta(x)$ 就是该马尔可夫链的[平稳分布](@entry_id:194199)。这意味着，只要我们从任意初始状态开始，并根据转移核反复迭代，最终生成的样本就会像是从 $p_\theta(x)$ 中抽取的一样 。

在 EBM 的背景下，基于梯度的 MCMC 方法尤为流行，其中最著名的是**[随机梯度朗之万动力学](@entry_id:755466)**（Stochastic Gradient Langevin Dynamics, SGLD）。该算法源于物理学中的朗之万方程，其离散化更新规则如下：
$$
x_{t+1} = x_t - \eta \nabla_x E_\theta(x_t) + \sqrt{2\eta T} \xi_t, \quad \xi_t \sim \mathcal{N}(0, I)
$$
其中 $\eta$ 是步长，$\xi_t$ 是标准高斯噪声。这个过程可以直观地理解为在[能量景观](@entry_id:147726)上下降的梯度流，同时注入了适量的噪声以防止陷入局部极小值并确保能够探索整个[分布](@entry_id:182848)。

在实践中，如何运行 MCMC 链引出了几种不同的训练策略：
*   **对比散度（Contrastive Divergence, CD）**：由于从随机初始点运行 MCMC 直至收敛非常耗时，CD 算法提出一个捷径：从每个真实数据点 $x_{\text{data}}$ 开始，只运行 $k$ 步 MCMC（$k$ 通常很小，如 1 或 10），得到负样本。这种“短时运行”的 MCMC 引入了偏差，但经验上证明是有效的。
*   **持续性对比散度（Persistent Contrastive Divergence, PCD）**：为了更好地逼近[平稳分布](@entry_id:194199)，PCD 维护一个持续存在的 MCMC 链（通常存储在一个“重放缓冲区”中）。在每次训练迭代中，从缓冲区中取出样本，继续运行 $k$ 步 MCMC，然后将新样本放回缓冲区。这样，链的状态在参数更新之间得以保持，使其有机会更好地探索[能量景观](@entry_id:147726) 。

现代观点将这种短时运行的 MCMC 训练过程重新概念化。$k$ 步[朗之万动力学](@entry_id:142305)可以被看作是一个依赖于参数 $\theta$ 的随机映射 $G_\theta$，它将初始点（例如来自重放缓冲区的点）和随机噪声转化为一个负样本。因此，训练过程实际上是在拟合一个由 MCMC 链定义的**隐式生成器**，即使我们无法写出其样本的显式密度 。

然而，MCMC 采样也带来了其自身的挑战和失效模式：
*   **链的停滞与混合缓慢**：如果能量景观中存在被高能量壁垒隔开的多个模式，MCMC 链可能需要极长的时间才能在模式间“混合”。链可能会被困在一个模式中，导致负样本缺乏多样性，从而对模型产生误导性的梯度。我们可以设计一些诊断工具来检测链的停滞，例如计算平稳状态下的自转移概率或样本序列的自相关性。高自相关性表明链在相邻步骤间变化缓慢，是混合不良的信号 。
*   **模式丢失**：当 MCMC 链混合不充[分时](@entry_id:274419)，它可能只会探索到 $p_\theta$ [分布](@entry_id:182848)中的一部分模式。如果负相梯度只在这些被探索到的模式上“向上推”能量，那么未被探索到的模式的能量可能会不受控制地降低，导致最终训练出的模型只捕捉到数据的一部分模式 。
*   **虚假能量谷**：由于负相只在 MCMC 链访问过的区域惩罚低能量，能量函数可能会在采样器从未访问过的“偏僻”区域形成虚假的、不合理的低能量谷。这会导致模型在长时运行的采样中产生质量差的样本，尽管短时运行的样本看起来不错 。

### 先进主题与现代技术

为了应对上述挑战并提升 EBM 的性能，研究者们开发了一系列先进技术和替代性训练框架。

#### 替代性训练目标

[最大似然估计](@entry_id:142509)等价于最小化前向 KL 散度 $\mathrm{KL}(p_{\text{data}}\|p_\theta)$。该目标具有**模式覆盖**（mode-covering）的行为：为了避免在 $p_{\text{data}}(x) > 0$ 的区域给出 $p_\theta(x) \approx 0$（这会导致 KL 散度趋于无穷），模型会被激励去覆盖数据[分布](@entry_id:182848)的所有模式，即使这意味着生成一些位于模式之间的低概率样本。

一种替代方案是最小化反向 KL 散度 $\mathrm{KL}(p_\theta\|p_{\text{data}})$。该目标具有**模式寻求**（mode-seeking）的行为：如果模型在 $p_{\text{data}}(x) \approx 0$ 的区域放置了概率质量（即 $p_\theta(x) > 0$），KL 散度会趋于无穷。因此，模型被激励只在数据真实存在的区域生成样本。如果[模型容量](@entry_id:634375)有限，它宁愿精确地捕捉一个模式，也不愿模糊地覆盖所有模式，这可能导致“模式坍塌”。虽然直接最小化反向 KL 散度很困难，但可以通过基于其变分表示（如 Donsker-Varadhan 表示）的对抗性训练框架来近似实现 。

另一个重要的替代方案是**[分数匹配](@entry_id:635640)**（Score Matching）。它旨在最小化模型[分数函数](@entry_id:164520) $\nabla_x \ln p_\theta(x)$ 与数据[分数函数](@entry_id:164520) $\nabla_x \ln p_{\text{data}}(x)$ 之间的差异。其目标函数（费雪散度, Fisher divergence）为：
$$
J(\theta) = \mathbb{E}_{x \sim p_{\text{data}}}\left\|\nabla_{x} \ln p_{\theta}(x) - \nabla_{x} \ln p_{\text{data}}(x)\right\|^{2}
$$
[分数匹配](@entry_id:635640)的一个巨大优势是，$\nabla_x \ln p_\theta(x) = -\nabla_x E_\theta(x)$，它不依赖于[配分函数](@entry_id:193625) $Z(\theta)$。虽然数据[分数函数](@entry_id:164520) $\nabla_x \ln p_{\text{data}}(x)$ 通常未知，但可以通过去噪[分数匹配](@entry_id:635640)等技术进行估计。理论上，如果模型族能够完美地表示数据[分布](@entry_id:182848)（即模型是“良定的”），那么最小化[分数匹配](@entry_id:635640)目标与最大化[似然](@entry_id:167119)是等价的，两者都会在 $p_\theta(x) = p_{\text{data}}(x)$ 时达到最优，此时目标函数值为 0 。

#### 改进采样过程

MCMC 的效率对 EBM 训练至关重要。
*   **利用动量**：除了 SGLD，还可以使用**[随机梯度哈密顿蒙特卡洛](@entry_id:755465)（Stochastic Gradient Hamiltonian [Monte Carlo](@entry_id:144354), [SGHMC](@entry_id:754717)）**。[SGHMC](@entry_id:754717) 引入了一个辅助的动量变量，使得采样过程除了梯度信息外还具有“惯性”。在[能量景观](@entry_id:147726)平坦的“山谷”中（对应于特征空间中的慢变化方向），SGLD 的步长可能很小，导致混合缓慢。而 [SGHMC](@entry_id:754717) 的动量可以帮助采样器更快地穿过这些平坦区域，从而提高[采样效率](@entry_id:754496) 。
*   **理解离散化效应**：SGLD 是连续[朗之万动力学](@entry_id:142305)的离散化近似。这种离散化会引入误差。可以证明，使用有限步长 $h$ 的 SGLD，其[平稳分布](@entry_id:194199)的[方差](@entry_id:200758)会高于目标分布。这相当于在一个比预设温度更高的“[有效温度](@entry_id:161960)” $T_{\text{eff}} = T / (1 - \alpha h/2)$ 下进行采样（对于二次能量 $E(x)=\frac{\alpha}{2}x^2$）。这意味着，较大的步长不仅加速了计算，还隐式地向模型中注入了熵，可能有助于避免模式坍塌，但也可能影响[模型校准](@entry_id:146456) 。

#### 正则化[能量景观](@entry_id:147726)

直接训练的 EBMs 的能量景观可能非常“崎岖”，这给 MCMC 采样带来了巨大困难。一个有效的策略是直接在训练目标中加入对能量景观平滑度的正则化项。一种常见的做法是惩罚能量函数梯度的范数，例如，在[损失函数](@entry_id:634569)中加入一项 $\frac{\lambda}{2} \mathbb{E}_{x \sim q(x)}[\|\nabla_x E_\theta(x)\|^2]$，其中 $q(x)$ 是某个固定的[分布](@entry_id:182848)（如高斯分布或数据[分布](@entry_id:182848)）。

这种正则化项鼓励能量函数在各处都比较平坦。从数学上看，它控制了能量梯度 $\nabla_x E_\theta(x)$ 的[利普希茨常数](@entry_id:146583)（Lipschitz constant），使其不会变得过大。然而，这也带来了一个微妙的权衡：一个更平滑的[能量景观](@entry_id:147726)（梯度更小）虽然更容易被采样器探索，但根据[朗之万动力学](@entry_id:142305)的原理，收敛到[平稳分布](@entry_id:194199)的[混合时间](@entry_id:262374)也可能因此变长。例如，对于二次能量 $E(x) = \frac{a}{2}\|x\|^2$，[混合时间](@entry_id:262374)常数与曲率 $a$ 成反比 $\tau(a) = 1/a$。[梯度惩罚](@entry_id:635835)会降低最优的曲率 $a^\star$，从而导致[混合时间](@entry_id:262374) $\tau(a^\star)$ 增加 。因此，在实践中需要仔细调整正则化强度 $\lambda$，以在[能量景观](@entry_id:147726)的平滑度和 MCMC [采样效率](@entry_id:754496)之间找到最佳平衡。