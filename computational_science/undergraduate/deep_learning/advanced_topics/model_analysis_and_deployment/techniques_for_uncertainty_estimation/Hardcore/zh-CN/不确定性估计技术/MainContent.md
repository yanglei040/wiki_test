## 引言
在[自动驾驶](@entry_id:270800)、医疗诊断等关键领域，深度学习模型的预测不仅要准确，更要可靠。一个无法量化自身“不知道”程度的模型，可能导致灾难性的后果。然而，标准的[深度学习模型](@entry_id:635298)往往会做出过度自信的预测，缺乏对自身不确定性的认知，这构成了其在现实世界安全部署中的核心挑战。本文旨在系统性地解决这一知识鸿沟，为您提供一套理解、量化和利用深度学习不确定性的完整框架。

接下来，我们将通过三个章节层层递进。在“原理与机制”一章中，我们将深入剖析不确定性的两种基本类型——[偶然不确定性与认知不确定性](@entry_id:746346)，并介绍量化与校准它们的关键技术。随后，在“应用与跨学科联系”一章中，我们将展示这些理论如何在[主动学习](@entry_id:157812)、高风险决策、[计算机视觉](@entry_id:138301)等多个领域发挥关键作用。最后，通过“动手实践”环节，您将有机会亲手实现这些核心算法，将理论知识转化为解决实际问题的能力。

## 原理与机制

在[深度学习](@entry_id:142022)中，模型不仅需要做出准确的预测，还需要知道其预测的[置信度](@entry_id:267904)。一个无法表达其不确定性的模型，在自动驾驶、医疗诊断等高风险领域是不可靠的。本章将深入探讨[不确定性估计](@entry_id:191096)的原理和核心机制，阐明不确定性的基本类型，并介绍量化、校准和利用这些不确定性的关键技术。

### 不确定性的核心概念：[偶然不确定性与认知不确定性](@entry_id:746346)

在预测任务中，不确定性并非单一概念，它主要分为两个[基本类](@entry_id:158335)型：**偶然不确定性 (Aleatoric Uncertainty)** 和 **认知不确定性 (Epistemic Uncertainty)**。理解这两种不确定性的区别至关重要，因为它们的来源不同，处理方式也各异。

**偶然不确定性**源于数据本身固有的随机性和噪声。即使我们拥有一个完美的模型，这种不确定性也无法消除。想象一下，在一个测量物理量的实验中，由于传感器本身的精度限制，每次测量都会有微小的[随机误差](@entry_id:144890)。这种由[数据采集](@entry_id:273490)过程引入的、不可避免的噪声，就是偶然不确定性。它反映了给定输入$x$下，目标$y$的真实[分布](@entry_id:182848)的[方差](@entry_id:200758)。

**认知不确定性**则源于模型自身的不完美。当训练数据有限或模型结构不足以完全捕捉数据的真实规律时，就会产生[认知不确定性](@entry_id:149866)。它反映了模型对数据中未见区域的“无知”。理论上，通过收集更多的训练数据或改进模型，认知不确定性是可以被降低的。

为了更具体地理解这两种不确定性，我们可以构建一个模拟场景 。假设我们正在构建一个模型，用于根据一维输入$x$预测目标$y$。真实关系为线性函数$y = ax + b$，但[数据采集](@entry_id:273490)过程中存在一个问题：传感器有时会被遮挡。我们引入一个二[进制](@entry_id:634389)特征$o$来表示遮挡状态 ($o=1$表示被遮挡，$o=0$表示未被遮挡)。当传感器未被遮挡时，测量噪声很小，例如服从$\mathcal{N}(0, \sigma_0^2)$；而被遮挡时，噪声显著增大，服从$\mathcal{N}(0, \sigma_1^2)$，其中$\sigma_1 \gg \sigma_0$。

在这个场景中，由传感器遮挡引起的噪声[方差](@entry_id:200758)变化（$\sigma_0^2$ vs $\sigma_1^2$）就是典型的**[偶然不确定性](@entry_id:154011)**。它是一个与输入特征$o$相关的、数据固有的属性。一个优秀的模型应该能够学会：当$o=1$时，预测的固有[方差](@entry_id:200758)会变大。

现在，假设我们的训练数据主要集中在$x \in [-3, 0]$的区域，并且在[训练集](@entry_id:636396)中从未出现过遮挡情况（即所有训练样本的$o$都为0）。然后，我们要求模型对$x \in [1.5, 3]$区域的数据进行预测，并且这些测试数据大部分是处于遮挡状态的（$o=1$）。对于模型来说，它不仅从未见过$x > 0$的区域，也从未学习过$o=1$会如何影响噪声。因此，模型在对这个新区域进行预测时会表现出极大的不确定性。这种由于训练数据覆盖不足而导致的不确定性，就是**认知不确定性**。模型在自己“知识”范围之外的区域表现出不自信，这正是[认知不确定性](@entry_id:149866)的体现。

总结来说：
- **[偶然不确定性](@entry_id:154011)**是“数据的属性”，描述了“已知中的未知”，即使拥有无限数据也无法消除。
- **[认知不确定性](@entry_id:149866)**是“模型的属性”，描述了“未知中的未知”，可以通过更多的数据或更好的模型来降低。

### 量化预测不确定性

为了在实践中使用不确定性，我们首先需要对其进行量化。

对于[分类任务](@entry_id:635433)，模型输出一个在$C$个类别上的[概率分布](@entry_id:146404)$p(y|x)$。一个直观且常用的[不确定性度量](@entry_id:152963)是**预测熵 (Predictive Entropy)**。对于一个给定的预测[概率分布](@entry_id:146404)$p$，其香农熵定义为：

$$
H(p) = -\sum_{k=1}^{C} p_k \ln p_k
$$

熵衡量了[概率分布](@entry_id:146404)的“混乱”或“平坦”程度。如果模型对某个类别非常有信心（例如，$p_k \approx 1$），则熵接近于0；如果模型在多个类别之间犹豫不决（例如，概率在多个类别上[均匀分布](@entry_id:194597)），则熵会很高 。

对于多模型集成的场景，我们还可以使用更简单的启发式方法。假设一个由$M$个模型组成的集成系统，每个模型$m$都输出一个[概率分布](@entry_id:146404)$p^{(m)}$。我们可以先将这些[概率分布](@entry_id:146404)取平均，得到集成的[预测分布](@entry_id:165741)$\bar{p} = \frac{1}{M} \sum_{m=1}^{M} p^{(m)}$。然后，一个简单的[不确定性度量](@entry_id:152963)是**变异率 (Variation Ratio)**，它定义为1减去集成预测中最可能类别的概率：

$$
\mathrm{VR} = 1 - \max_{k} \bar{p}_k
$$

这个值衡量了集成预测距离“确定”（即某个类别的概率为1）的程度。当所有模型都高度一致地指向同一个类别时，$\max_k \bar{p}_k$接近1，变异率接近0。当模型们意见不合，导致集成[概率分布](@entry_id:146404)在多个类别上时，变异率就会增大 。

对于回归任务，不确定性通常由**预测[方差](@entry_id:200758) (Predictive Variance)** 来量化。一个能够估计不确定性的回归模型，其输出不仅是一个预测均值$\mu(x)$，还有一个预测[方差](@entry_id:200758)$\sigma^2(x)$。这个[方差](@entry_id:200758)直接代表了模型对预测值的不确定性程度。

### 单个模型的校准与不确定性

标准的[深度学习模型](@entry_id:635298)，尤其是使用[交叉熵损失](@entry_id:141524)函数训练的分类器，往往会产生**过度自信 (overconfident)** 的预测。这意味着模型输出的置信度（即预测类别的概率）系统性地高于其真实准确率。例如，模型可能对一系列预测给出99%的置信度，但实际上这些预测的准确率只有85%。一个“良好校准”的模型，其置信度应该能真实反映其准确率。

#### 温度缩放

**温度缩放 (Temperature Scaling)** 是一种简单而有效的后处理技术，用于校准已经训练好的模型 。该技术通过在应用[Softmax函数](@entry_id:143376)之前，将模型的logits向量$z$除以一个可学习的标量参数$T > 0$（称为**温度**）来实现：

$$
p_k = \frac{\exp(z_k/T)}{\sum_{j=1}^{C} \exp(z_j/T)}
$$

- 当$T=1$时，我们得到标准的[Softmax](@entry_id:636766)。
- 当$T>1$时，[概率分布](@entry_id:146404)会变得更加“平缓”（[熵增](@entry_id:138799)加），从而降低模型的[置信度](@entry_id:267904)。
- 当$0  T  1$时，[概率分布](@entry_id:146404)会变得更加“尖锐”（熵减少），从而增加模型的[置信度](@entry_id:267904)。

关键在于，$T$是一个正数，所以除以$T$不会改变logits的相对顺序。因此，$\arg\max_k z_k = \arg\max_k (z_k/T)$，这意味着模型的预测类别（即准确率）保持不变。温度$T$通常通过在[验证集](@entry_id:636445)上最小化某个校准指标（如[负对数似然](@entry_id:637801)）来找到。通过一个简单的缩放，我们可以在不牺牲准确率的情况下，显著改善模型的校准水平。

#### 评估校准度

我们如何衡量一个模型是否良好校准？

**预期校准误差 (Expected Calibration Error, ECE)** 是一个广泛使用的指标。其思想是将预测的[置信度](@entry_id:267904)区间（例如$[0, 1]$）划分为$B$个等宽的箱子（bins）。然后，对于落入每个箱子里的所有预测，我们计算它们的平均[置信度](@entry_id:267904)和平均准确率。一个完美校准的模型，其每个箱子内的平均[置信度](@entry_id:267904)应该等于平均准确率。ECE正是这些差异的加权平均值：

$$
\mathrm{ECE} = \sum_{b=1}^{B} \frac{n_b}{N} \left|\overline{a}_b - \overline{c}_b\right|
$$

其中$\frac{n_b}{N}$是落入箱子$b$的样本比例，$\overline{a}_b$是箱子$b$的平均准确率，$\overline{c}_b$是箱子$b$的平均置信度。ECE越低，表示模型的校准度越好。

然而，ECE的计算本身也存在挑战 。它的值高度依赖于箱子的数量$B$。如果$B$太小，可能会掩盖局部的校准错误；如果$B$太大，每个箱子里的样本过少，导致对准确率的估计噪声很大。这引入了估计ECE时的**偏差-方差权衡**。一种改进策略是使用**等质量[分箱](@entry_id:264748) (equal-mass binning)**，即调整箱子的边界，使得每个箱子包含相同数量的样本，这有助于稳定对每个箱子准确率的估计，从而降低ECE估计器的[方差](@entry_id:200758)。

除了ECE，还有一些**严格适当评分规则 (Strictly Proper Scoring Rules)**，如**[负对数似然](@entry_id:637801) (Negative Log-Likelihood, NLL)** 和 **布里尔分数 (Brier Score)**，它们也能评估校准度。这些指标不仅奖励准确的预测，还奖励与真实结果相符的[置信度](@entry_id:267904)。对于真实类别为$y$、预测[概率向量](@entry_id:200434)为$p$的单个样本，NLL为$-\ln(p_y)$，布里尔分数为$\sum_{k=1}^{C} (p_k - \mathbb{1}[k=y])^2$。一个过度自信的错误预测（例如，对错误类别赋予高概率）会受到这些指标的严厉惩罚。

### 估计认知不确定性的方法

单个确定性模型难以有效估计[认知不确定性](@entry_id:149866)。为了捕捉这种源于模型的“无知”，我们需要引入某种形式的随机性或模型多样性。

#### [集成方法](@entry_id:635588)

**集成 (Ensemble)** 是估计认知不确定性的黄金标准。通过独立训练多个模型（例如，从不同的随机初始化开始），我们可以得到一个模型“委员会”。对于一个给定的输入，如果所有模型都做出相似的预测，说明该输入位于它们共同的“知识”范围内，认知不确定性较低。反之，如果模型们的预测出现显著分歧，则表明该输入可能处于数据稀疏或[分布](@entry_id:182848)外的区域，认知不确定性较高。

在聚合集成模型的预测时，我们有两种主要策略 ：
1.  **概率平均 (Probability Mean, PM)**：先对每个模型的logits应用[Softmax](@entry_id:636766)得到概率，然后再对[概率向量](@entry_id:200434)进行平均。这种方法等价于构建一个混合模型，其[预测分布](@entry_id:165741)是各成员[分布](@entry_id:182848)的[凸组合](@entry_id:635830)。
2.  **Logits平均 (Logit Averaging, LA)**：先对各模型的logits向量进行平均，然后再对平均后的logits应用一次[Softmax](@entry_id:636766)。

根据[詹森不等式](@entry_id:144269) (Jensen's inequality)，由于熵函数的[凹性](@entry_id:139843)，PM方法得到的集成[预测分布](@entry_id:165741)的熵通常会大于或等于LA方法得到的熵。换句话说，当模型之间存在分歧时，PM倾向于产生一个更平坦、不确定性更高的[预测分布](@entry_id:165741)，因为它直接平均了各个模型的“赌注”。而LA在平均logits时，一个具有极大logits值的“自信”模型可能会主导最终的预测，导致预测结果更尖锐、不确定性更低。例如，如果一个模型对类别A的logit是10，另一个是-10，而第三个模型对类别B的logit是9，PM会反映出A和B之间的竞争，而LA可能会因为平均后的logit仍然偏向A而给出一个对A相对自信的预测。选择哪种聚合方式取决于具体应用场景对保守性（PM）和校准度（LA通常更好）的需求。

#### [蒙特卡洛](@entry_id:144354) Dropout (MC Dropout)

[集成方法](@entry_id:635588)虽然强大，但训练和存储多个模型的成本很高。**MC Dropout**  提供了一种更高效的近似方法。Dropout最初是作为一种[正则化技术](@entry_id:261393)被提出的，它在训练期间随机地将一部分神经元的输出置为零。在标准的测试流程中，Dropout会被关闭。

MC Dropout的核心思想是：**在测试时也保持Dropout开启**。通过对同一个输入进行$T$次[前向传播](@entry_id:193086)，每次都使用不同的随机Dropout掩码，我们就能得到$T$个不同的预测结果。这些预测结果的差异（例如，预测概率的[方差](@entry_id:200758)）就可以被用作认知不确定性的估计。从贝叶斯角度看，MC Dropout可以被解释为对某个特定[贝叶斯神经网络](@entry_id:746725)[后验分布](@entry_id:145605)的一种近似采样。

Dropout率$p$在这里变成了一个重要的超参数。当$p=0$时，没有随机性，[认知不确定性](@entry_id:149866)为0。随着$p$的增加，随机性增强，预测结果的[方差](@entry_id:200758)（[认知不确定性](@entry_id:149866)）也随之增大。然而，过高的$p$会过度破坏模型的结构，可能导致准确率下降。因此，需要在准确率和有效的[不确定性估计](@entry_id:191096)之间进行权衡。

#### 随机权重平均高斯 (SWAG)

**SWAG (Stochastic Weight Averaging Gaussian)**  是另一种捕捉权重[后验分布](@entry_id:145605)的方法。它利用了[随机梯度下降](@entry_id:139134)（SGD）在训练[后期](@entry_id:165003)会在损失平坦区域的中心附近[振荡](@entry_id:267781)的特性。SWAG通过收集SGD在训练过程中的权重向量，并用它们来估计一个[高斯分布](@entry_id:154414)的后验。具体来说，它会计算这些权重向量的**平均值**作为[后验均值](@entry_id:173826)$\mu$，并用一个**低秩加对角**的结构来估计协方差矩阵$\Sigma$。

得到参数的[后验分布](@entry_id:145605)$\theta \sim \mathcal{N}(\mu, \Sigma)$后，我们可以推导出[预测分布](@entry_id:165741)的[方差](@entry_id:200758)。对于一个在$\mu$附近线性化的模型$f_\theta(x) \approx f_\mu(x) + (\nabla_\theta f_\theta(x)|_{\mu})^\top(\theta-\mu)$，其总预测[方差](@entry_id:200758)可以根据**[全方差公式](@entry_id:177482)**分解为：
$$
\operatorname{Var}[y|x] = \mathbb{E}_{\theta}[\operatorname{Var}[y|x, \theta]] + \operatorname{Var}_{\theta}[\mathbb{E}[y|x, \theta]]
$$
- 第一项是**偶然不确定性**，即固有的观测噪声[方差](@entry_id:200758)$\tau^2$。
- 第二项是**认知不确定性**，它源于参数$\theta$的不确定性，可以计算为$J_{\mu}(x)^{\top} \Sigma J_{\mu}(x)$，其中$J_{\mu}(x)$是模型输出关于参数在$\mu$处的雅可比矩阵。对于一个简单的[线性模型](@entry_id:178302)$f_\theta(x) = \theta^\top x$，[雅可比矩阵](@entry_id:264467)就是输入$x$，认知不确定性简化为$x^\top \Sigma x$。

SWAG提供了一种在单次训练运行结束时，以较小的额外计算成本获得高质量[不确定性估计](@entry_id:191096)的方法。

### 建模[偶然不确定性](@entry_id:154011)

上述方法主要关注[认知不确定性](@entry_id:149866)。要显式地建模偶然不确定性，我们需要让模型直接预测与输入相关的噪声水平。

**异[方差](@entry_id:200758)回归 (Heteroscedastic Regression)**  就是为此设计的。在一个标准的回归模型中，我们通常假设噪声[方差](@entry_id:200758)是恒定的（同[方差](@entry_id:200758)）。而在异[方差](@entry_id:200758)回归中，我们让[神经网](@entry_id:276355)络对每个输入$x$输出两个值：预测均值$\mu(x)$和预测[方差](@entry_id:200758)$\sigma^2(x)$。

为了训练这样的模型，我们最大化高斯[似然函数](@entry_id:141927)，这等价于最小化以下[负对数似然](@entry_id:637801)[损失函数](@entry_id:634569)（忽略常数项）：
$$
\mathcal{L}(\mu(x), \sigma^2(x)) = \frac{1}{2} \left( \ln(\sigma^2(x)) + \frac{(y - \mu(x))^2}{\sigma^2(x)} \right)
$$
这个[损失函数](@entry_id:634569)直观地鼓励模型：当预测误差$(y - \mu(x))^2$大时，预测一个大的[方差](@entry_id:200758)$\sigma^2(x)$来“解释”这个误差，从而避免过大的惩罚；当误差小时，则预测一个小的[方差](@entry_id:200758)以获得更低的损失。

由于[方差](@entry_id:200758)$\sigma^2(x)$必须为正，我们不能让网络直接输出它。常见的参数化技巧包括：
1.  **对数-[方差](@entry_id:200758)参数化**：网络输出一个实数$s(x)$，[方差](@entry_id:200758)为$\sigma^2(x) = \exp(s(x))$。
2.  **Softplus参数化**：网络输出一个实数$a(x)$，[方差](@entry_id:200758)为$\sigma^2(x) = \text{softplus}(a(x)) = \ln(1 + \exp(a(x)))$。

这两种方法都能保证[方差](@entry_id:200758)为正，但在[数值稳定性](@entry_id:146550)和梯度特性上略有不同。例如，对于较大的网络输出值，$s$或$a$，$\exp(s)$呈[指数增长](@entry_id:141869)，而$\text{softplus}(a)$近似[线性增长](@entry_id:157553)，这可能影响训练的动态过程。

### 不确定性的应用

#### 选择性分类

获得可靠的[不确定性估计](@entry_id:191096)后，一个直接的应用是**选择性分类 (Selective Classification)** 或**带拒绝选项的预测 (Prediction with a Rejection Option)** 。其核心思想是：当模型对其预测不确定时，它应该拒绝做出预测，并将该问题移交给人类专家。

我们可以设定一个不确定性阈值$\tau$（例如，基于预测熵）。如果一个样本的熵$H(p)  \tau$，模型就“弃权”；否则，它就做出预测。通过调整$\tau$，我们可以在**覆盖率 (Coverage)**（模型做出预测的样本比例）和**风险 (Risk)**（在做出预测的样本上的错误率）之间进行权衡。

**风险-覆盖率曲线 (Risk-Coverage Curve)** 是评估这种权衡的有力工具。它描绘了随着覆盖率从1（不拒绝任何样本）降低到0（拒绝所有样本），风险如何变化。一个好的[不确定性估计](@entry_id:191096)器应该能让模型优先拒绝最可能出错的样本，从而使得风险随着覆盖率的降低而迅速下降。**风险-覆盖率[曲线下面积](@entry_id:169174) (Area Under the Risk-Coverage Curve, AURC)** 为我们提供了一个单一的标量指标来量化这种性能：AURC越小，说明[不确定性估计](@entry_id:191096)越有效。

#### [物理信息](@entry_id:152556)引导的不确定性

在科学和工程领域，我们常常拥有关于系统行为的先验知识，例如控制方程（如常微分方程ODE或[偏微分方程](@entry_id:141332)PDE）。这些物理约束可以被用来改善[不确定性估计](@entry_id:191096) 。

在一个集成模型中，并非所有成员都是同等可信的。我们可以通过评估每个模型预测与物理定律的符合程度来为其赋权。例如，对于ODE $y'(x) + y(x) = 0$，我们可以为每个集成成员$m$计算一个**物理残差**能量$R_m$，表示其预测违反该ODE的程度。然后，我们可以根据$R_m$为每个模型分配权重$w_m \propto \exp(-\lambda R_m)$，其中$\lambda$控制了物理约束的强度。

这样，物理上更 plausible 的模型会获得更高的权重。最终的认知不确定性（加权[方差](@entry_id:200758)）和预测均值（加权平均）将更可靠，因为它们排除了或降低了那些不符合物理规律的“荒谬”模型的贡献。然后，这个物理信息引导的[认知不确定性](@entry_id:149866)可以与已知的[偶然不确定性](@entry_id:154011)（如测量噪声）相结合，得到总的预测不确定性。

通过本章的学习，我们不仅理解了不确定性的[基本类](@entry_id:158335)型和原理，还掌握了从[模型校准](@entry_id:146456)到高级贝叶斯近似等一系列估计和评估不确定性的实用技术。这些工具对于构建更安全、更可靠、更值得信赖的深度学习系统至关重要。