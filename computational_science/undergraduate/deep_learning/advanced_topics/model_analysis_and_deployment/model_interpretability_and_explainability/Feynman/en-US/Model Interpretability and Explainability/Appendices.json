{
    "hands_on_practices": [
        {
            "introduction": "Many interpretability methods seem intuitive, but do they all tell the same story? This exercise  challenges you to explore the relationship between two fundamental techniques: occlusion-based attribution and Gradient-times-Input. By deriving the conditions for their equivalence and computing their discrepancy in a non-linear model, you will gain a crucial insight into how model complexity, specifically interaction terms, causes different attribution methods to diverge.",
            "id": "3153229",
            "problem": "Consider a predictive model $f: \\mathbb{R}^{d} \\to \\mathbb{R}$ and a zero-baseline occlusion ablation procedure which, for an input $x \\in \\mathbb{R}^{d}$ and feature index $j \\in \\{1,\\dots,d\\}$, defines the occlusion attribution for feature $j$ as $A_{\\mathrm{occ},j}(x) \\triangleq f(x) - f\\big(x^{(j \\leftarrow 0)}\\big)$, where $x^{(j \\leftarrow 0)}$ is the vector obtained from $x$ by setting its $j$-th coordinate to $0$ and keeping all other coordinates unchanged. The Gradient times Input attribution is defined as $A_{\\mathrm{gxi},j}(x) \\triangleq x_{j} \\,\\frac{\\partial f}{\\partial x_{j}}(x)$.\n\n1) Using only the linearity of differentiation and the definition of affine linear functions, derive the necessary and sufficient conditions under which $A_{\\mathrm{occ},j}(x) = A_{\\mathrm{gxi},j}(x)$ for every input $x \\in \\mathbb{R}^{d}$ and every feature index $j \\in \\{1,\\dots,d\\}$.\n\n2) Now consider the specific nonlinear model in $d=3$ defined by\n$$\nf(x) \\;=\\; w^{\\top}x \\;+\\; b \\;+\\; \\gamma\\, x_{1} x_{2} \\;+\\; \\delta\\, x_{2}^{2},\n$$\nwith parameters $w = (1,-2,3)$, $b = 0$, $\\gamma = \\tfrac{1}{2}$, $\\delta = -1$, and the input $x = (2,-1,4)$. For feature $j=2$, compute the occlusion attribution $A_{\\mathrm{occ},2}(x)$ and the Gradient times Input attribution $A_{\\mathrm{gxi},2}(x)$, and then define the discrepancy\n$$\nD \\;\\triangleq\\; A_{\\mathrm{occ},2}(x) \\;-\\; A_{\\mathrm{gxi},2}(x).\n$$\nReport $D$ as your final answer. No rounding is required, and the answer is unitless.",
            "solution": "This problem consists of two parts. The first part requires deriving the necessary and sufficient conditions for the equality of occlusion attribution and Gradient-times-Input attribution. The second part involves a direct computation of these quantities and their difference for a specific nonlinear model.\n\n### Part 1: Derivation of Necessary and Sufficient Conditions\n\nWe are given two attribution methods for a function $f: \\mathbb{R}^{d} \\to \\mathbb{R}$:\n1.  The zero-baseline occlusion attribution: $A_{\\mathrm{occ},j}(x) \\triangleq f(x) - f\\big(x^{(j \\leftarrow 0)}\\big)$.\n2.  The Gradient-times-Input attribution: $A_{\\mathrm{gxi},j}(x) \\triangleq x_{j} \\,\\frac{\\partial f}{\\partial x_{j}}(x)$.\n\nThe problem asks for the necessary and sufficient conditions on $f$ such that $A_{\\mathrm{occ},j}(x) = A_{\\mathrm{gxi},j}(x)$ for every input $x \\in \\mathbb{R}^{d}$ and every feature index $j \\in \\{1,\\dots,d\\}$. The condition is thus:\n$$\nf(x) - f\\big(x^{(j \\leftarrow 0)}\\big) = x_{j} \\frac{\\partial f}{\\partial x_{j}}(x) \\quad \\forall x \\in \\mathbb{R}^d, \\forall j \\in \\{1, \\dots, d\\}\n$$\n\nLet us analyze this condition for a single, arbitrary feature $j$. To isolate the dependence on the variable $x_j$, we fix all other coordinates $x_k$ for $k \\neq j$. We define a single-variable function $g: \\mathbb{R} \\to \\mathbb{R}$ as follows:\n$$\ng(t) \\triangleq f(x_1, \\dots, x_{j-1}, t, x_{j+1}, \\dots, x_d)\n$$\nThe partial derivative of $f$ with respect to $x_j$ is the ordinary derivative of $g$ with respect to its argument: $\\frac{\\partial f}{\\partial x_{j}}(x) = g'(x_j)$. The vector $x^{(j \\leftarrow 0)}$ corresponds to setting the argument of $g$ to $0$, so $f(x^{(j \\leftarrow 0)}) = g(0)$. With this notation, the required condition for the specific feature $j$ and input $x$ becomes an equation for $g$ evaluated at $t=x_j$:\n$$\ng(x_j) - g(0) = x_j g'(x_j)\n$$\nSince this must hold for any $x \\in \\mathbb{R}^d$, it must hold for any value of $x_j$. Let's replace $x_j$ with a generic variable $t$. The function $g(t)$ must satisfy the identity:\n$$\ng(t) - g(0) = t g'(t) \\quad \\forall t \\in \\mathbb{R}\n$$\nWe can rearrange this into a first-order ordinary differential equation for $g(t)$. Let's define a new function $H(t) \\triangleq g(t) - t g'(t)$. The condition is equivalent to stating that $H(t) = g(0)$ for all $t$. Since $g(0)$ is a constant with respect to $t$, the function $H(t)$ must be constant. Consequently, its derivative with respect to $t$ must be zero for all $t$.\n$$\nH'(t) = \\frac{d}{dt} \\left( g(t) - t g'(t) \\right) = 0\n$$\nUsing the linearity of differentiation and the product rule, we find:\n$$\ng'(t) - \\left( \\frac{d}{dt}(t) \\cdot g'(t) + t \\cdot \\frac{d}{dt}(g'(t)) \\right) = 0\n$$\n$$\ng'(t) - (1 \\cdot g'(t) + t \\cdot g''(t)) = 0\n$$\n$$\n-t g''(t) = 0\n$$\nFor this equation to hold for all $t \\in \\mathbb{R}$, we must have $g''(t) = 0$ for all $t \\ne 0$. If we assume $f$ is a twice continuously differentiable function ($C^2$), then $g''(t)$ is continuous, which implies $g''(t)=0$ for all $t \\in \\mathbb{R}$.\n\nThe condition $g''(t) = 0$ means that the second derivative of $g$ is zero. Integrating twice with respect to $t$ yields:\n$g'(t) = c_1$\n$g(t) = c_1 t + c_2$\nwhere $c_1$ and $c_2$ are constants of integration. This is the definition of an affine linear function. The constants $c_1$ and $c_2$ can depend on the other coordinates $x_k$ ($k \\ne j$) that were held fixed.\nIn terms of $f$, the condition $g''(t)=0$ is $\\frac{\\partial^2 f}{\\partial x_j^2} = 0$. This must hold for all $j \\in \\{1, \\dots, d\\}$.\n\nThis implies that for each $j$, the partial derivative $\\frac{\\partial f}{\\partial x_j}$ is independent of $x_j$. Let's write this as:\n$$\n\\frac{\\partial f}{\\partial x_j}(x) = \\phi_j(x_1, \\dots, x_{j-1}, x_{j+1}, \\dots, x_d)\n$$\nThis must hold for every $j \\in \\{1, \\dots, d\\}$. Now, we use the equality of mixed partial derivatives (Clairaut's theorem), assuming $f \\in C^2$. For any two distinct indices $j, k$:\n$$\n\\frac{\\partial^2 f}{\\partial x_k \\partial x_j} = \\frac{\\partial^2 f}{\\partial x_j \\partial x_k}\n$$\n$$\n\\frac{\\partial}{\\partial x_k} \\left( \\frac{\\partial f}{\\partial x_j} \\right) = \\frac{\\partial \\phi_j}{\\partial x_k}\n$$\n$$\n\\frac{\\partial}{\\partial x_j} \\left( \\frac{\\partial f}{\\partial x_k} \\right) = \\frac{\\partial \\phi_k}{\\partial x_j}\n$$\nSince $\\phi_j$ is independent of $x_j$ and $\\phi_k$ is independent of $x_k$, $\\frac{\\partial \\phi_j}{\\partial x_k}$ is independent of $x_j$, and $\\frac{\\partial \\phi_k}{\\partial x_j}$ is independent of $x_k$.\n\nThe result $\\frac{\\partial^2 f}{\\partial x_j^2}=0$ for all $j$, along with the equality of mixed partials, forces all second-order partial derivatives to be zero. Consider $\\frac{\\partial^2 f}{\\partial x_j \\partial x_k}$ for $j \\neq k$. Since $\\frac{\\partial f}{\\partial x_j}$ is independent of $x_j$, we can write $f(x) = x_j \\phi_j(x_{-j}) + \\psi_j(x_{-j})$. Then $\\frac{\\partial f}{\\partial x_k} = x_j \\frac{\\partial \\phi_j}{\\partial x_k} + \\frac{\\partial \\psi_j}{\\partial x_k}$. We also know $\\frac{\\partial f}{\\partial x_k} = \\phi_k(x_{-k})$ which is independent of $x_j$. For this to hold, the coefficient of $x_j$ must be zero, i.e., $\\frac{\\partial \\phi_j}{\\partial x_k}=0$. This means $\\phi_j$ is independent of $x_k$ for all $k \\ne j$. Thus, $\\phi_j$ must be a constant, say $w_j$.\n\nSo, we have established that $\\frac{\\partial f}{\\partial x_j} = w_j$ for all $j$, where each $w_j$ is a constant. This means the gradient of $f$ is a constant vector $w = (w_1, \\dots, w_d)^\\top$.\nIf $\\nabla f(x) = w$, we can integrate to find the form of $f(x)$. Integrating $\\frac{\\partial f}{\\partial x_1} = w_1$ gives $f(x) = w_1 x_1 + h_1(x_2, \\dots, x_d)$. Differentiating this with respect to $x_2$ gives $\\frac{\\partial f}{\\partial x_2} = \\frac{\\partial h_1}{\\partial x_2}$. Since we know $\\frac{\\partial f}{\\partial x_2} = w_2$, we have $\\frac{\\partial h_1}{\\partial x_2} = w_2$. Integrating this gives $h_1(x_2, \\dots, x_d) = w_2 x_2 + h_2(x_3, \\dots, x_d)$. Continuing this process inductively, we arrive at:\n$$\nf(x) = w_1 x_1 + w_2 x_2 + \\dots + w_d x_d + b\n$$\nwhere $b$ is a constant of integration. This can be written as $f(x) = w^\\top x + b$. This is the general form of an affine linear function. This is the necessary condition.\n\nTo show sufficiency, let's assume $f(x) = w^\\top x + b = \\sum_{k=1}^d w_k x_k + b$.\nThe occlusion attribution is:\n$A_{\\mathrm{occ},j}(x) = f(x) - f(x^{(j \\leftarrow 0)}) = \\left( \\sum_{k=1}^d w_k x_k + b \\right) - \\left( \\sum_{k \\ne j} w_k x_k + w_j \\cdot 0 + b \\right) = w_j x_j$.\nThe Gradient-times-Input attribution is:\n$A_{\\mathrm{gxi},j}(x) = x_j \\frac{\\partial f}{\\partial x_j}(x)$.\nThe partial derivative is $\\frac{\\partial f}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\left( \\sum_{k=1}^d w_k x_k + b \\right) = w_j$.\nTherefore, $A_{\\mathrm{gxi},j}(x) = x_j \\cdot w_j$.\nSince both attributions equal $w_j x_j$, the equality holds.\n\nThus, the necessary and sufficient condition is that the function $f$ must be an affine linear function of its input $x$.\n\n### Part 2: Computation for a Specific Model\n\nWe are given the model $f(x) \\;=\\; w^{\\top}x \\;+\\; b \\;+\\; \\gamma\\, x_{1} x_{2} \\;+\\; \\delta\\, x_{2}^{2}$ with parameters $w = (1,-2,3)^\\top$, $b = 0$, $\\gamma = \\frac{1}{2}$, and $\\delta = -1$.\nThe specific function is:\n$$\nf(x_1, x_2, x_3) = (1 \\cdot x_1 - 2 \\cdot x_2 + 3 \\cdot x_3) + 0 + \\frac{1}{2} x_1 x_2 - 1 \\cdot x_2^2\n$$\n$$\nf(x_1, x_2, x_3) = x_1 - 2x_2 + 3x_3 + \\frac{1}{2} x_1 x_2 - x_2^2\n$$\nThis function is not affine linear due to the terms $\\frac{1}{2} x_1 x_2$ and $-x_2^2$. Therefore, based on Part 1, we do not expect the two attributions to be equal in general.\n\nThe input is $x = (2, -1, 4)$ and the feature is $j=2$. We need to compute $D = A_{\\mathrm{occ},2}(x) - A_{\\mathrm{gxi},2}(x)$.\n\nFirst, we compute the occlusion attribution $A_{\\mathrm{occ},2}(x) = f(x) - f(x^{(2 \\leftarrow 0)})$.\nThe original input is $x = (2, -1, 4)$.\nThe occluded input is $x^{(2 \\leftarrow 0)} = (2, 0, 4)$.\n\n$f(2, -1, 4) = (2) - 2(-1) + 3(4) + \\frac{1}{2}(2)(-1) - (-1)^2$\n$f(2, -1, 4) = 2 + 2 + 12 - 1 - 1 = 14$.\n\n$f(2, 0, 4) = (2) - 2(0) + 3(4) + \\frac{1}{2}(2)(0) - (0)^2$\n$f(2, 0, 4) = 2 - 0 + 12 + 0 - 0 = 14$.\n\n$A_{\\mathrm{occ},2}(x) = 14 - 14 = 0$.\n\nNext, we compute the Gradient-times-Input attribution $A_{\\mathrm{gxi},2}(x) = x_2 \\frac{\\partial f}{\\partial x_2}(x)$.\nFirst, we find the partial derivative of $f$ with respect to $x_2$:\n$$\n\\frac{\\partial f}{\\partial x_2} = \\frac{\\partial}{\\partial x_2} \\left( x_1 - 2x_2 + 3x_3 + \\frac{1}{2} x_1 x_2 - x_2^2 \\right) = -2 + \\frac{1}{2}x_1 - 2x_2\n$$\nNow, we evaluate this partial derivative at the input $x=(2,-1,4)$:\n$$\n\\frac{\\partial f}{\\partial x_2}(2, -1, 4) = -2 + \\frac{1}{2}(2) - 2(-1) = -2 + 1 + 2 = 1\n$$\nNow we can compute $A_{\\mathrm{gxi},2}(x)$:\n$$\nA_{\\mathrm{gxi},2}(x) = x_2 \\cdot \\frac{\\partial f}{\\partial x_2}(x) = (-1) \\cdot (1) = -1\n$$\nFinally, we compute the discrepancy $D$:\n$$\nD = A_{\\mathrm{occ},2}(x) - A_{\\mathrm{gxi},2}(x) = 0 - (-1) = 1\n$$",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Having established that simple attribution methods can be inconsistent, we now turn to more sophisticated approaches like SHAP and Integrated Gradients (IG). This practice  delves into their core differences by applying them to a model with known feature interactions and dominance, derived from a simple logical rule. By calculating the attributions from first principles, you will directly observe how SHAP's game-theoretic foundation and IG's path-based definition lead them to distribute credit differently, revealing their unique strengths and underlying assumptions.",
            "id": "3153200",
            "problem": "You are given a binary classification dataset where features are independent and identically distributed Bernoulli random variables and the label is generated by a logical rule. Specifically, let $(X_1, X_2, X_3)$ be independent with $X_i \\sim \\mathrm{Bernoulli}(1/2)$ for $i \\in \\{1,2,3\\}$, and let the label be $Y = \\mathbb{1}[(X_1 \\land X_2) \\lor X_3]$. Consider the differentiable surrogate model $f:\\mathbb{R}^3 \\to \\mathbb{R}$ defined by $f(x_1,x_2,x_3) = x_1 x_2 + x_3 - x_1 x_2 x_3$, which coincides with the logical rule on $\\{0,1\\}^3$.\n \nYour goal is to compare attributions from Shapley Additive Explanations (SHAP) and Integrated Gradients (IG) at the input $x^{\\star} = (1,1,1)$ using the following settings.\n \n- For SHAP, use the interventional value function $v(S) = \\mathbb{E}[f(X) \\mid X_S = x^{\\star}_S]$ under the independent background distribution of $(X_1,X_2,X_3)$, and define the Shapley value for feature $i$ by\n  $$\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!\\,(|N|-|S|-1)!}{|N|!}\\,\\big(v(S \\cup \\{i\\}) - v(S)\\big),$$\n  where $N = \\{1,2,3\\}$.\n- For IG, use the baseline $x' = (0,0,0)$ and the straight-line path from $x'$ to $x^{\\star}$, with the attribution for feature $i$ defined by\n  $$\\mathrm{IG}_i(x^{\\star}) = (x^{\\star}_i - x'_i) \\int_{0}^{1} \\frac{\\partial f(x' + \\alpha (x^{\\star} - x'))}{\\partial x_i} \\, d\\alpha.$$\n \nTasks:\n1. Starting from the definitions above, compute the Shapley values $\\phi_1$, $\\phi_2$, and $\\phi_3$ at $x^{\\star}$, and briefly explain how the terms reflect distribution of interaction credit between $X_1$ and $X_2$ and the dominance of $X_3$.\n2. Compute the Integrated Gradients attributions $\\mathrm{IG}_1(x^{\\star})$, $\\mathrm{IG}_2(x^{\\star})$, and $\\mathrm{IG}_3(x^{\\star})$ using the given baseline and path, and show that their sum equals $f(x^{\\star}) - f(x')$.\n3. Use your results to illustrate non-additivity across methods by showing that the sum of SHAP attributions equals $f(x^{\\star}) - \\mathbb{E}[f(X)]$ while the sum of IG attributions equals $f(x^{\\star}) - f(x')$. Then, compute the ratio\n   $$R \\equiv \\frac{\\mathrm{IG}_3(x^{\\star})}{\\phi_3}.$$\n \nProvide your final answer as a single reduced fraction. No rounding is required and no units are needed.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. All necessary definitions, variables, and conditions are provided to compute the required quantities. The problem is a standard exercise in applying the definitions of SHAP and Integrated Gradients, two established methods in machine learning interpretability.\n\nThe solution proceeds by following the three tasks outlined in the problem.\n\nLet the feature vector be $x = (x_1, x_2, x_3)$. The surrogate model is given by $f(x_1, x_2, x_3) = x_1 x_2 + x_3 - x_1 x_2 x_3$. The features $X_i$ are independent Bernoulli random variables with parameter $p=1/2$, so $\\mathbb{E}[X_i] = 1/2$ for $i \\in \\{1,2,3\\}$. The input for attribution is $x^{\\star} = (1,1,1)$.\n\n### Task 1: Computation of SHAP values\n\nThe Shapley value for feature $i$ is given by\n$$\n\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!\\,(|N|-|S|-1)!}{|N|!}\\,\\big(v(S \\cup \\{i\\}) - v(S)\\big)\n$$\nwhere $N = \\{1,2,3\\}$ and the value function is $v(S) = \\mathbb{E}[f(X) \\mid X_S = x^{\\star}_S]$. Given $x^{\\star}=(1,1,1)$, this means we fix the components in $S$ to $1$ and take the expectation over the remaining components, which follow the background distribution $X_i \\sim \\mathrm{Bernoulli}(1/2)$.\n\nFirst, we compute the value function $v(S)$ for all $S \\subseteq N$:\n- $S=\\emptyset$: $v(\\emptyset) = \\mathbb{E}[f(X_1,X_2,X_3)] = \\mathbb{E}[X_1 X_2 + X_3 - X_1 X_2 X_3]$. By independence of $X_i$:\n  $v(\\emptyset) = \\mathbb{E}[X_1]\\mathbb{E}[X_2] + \\mathbb{E}[X_3] - \\mathbb{E}[X_1]\\mathbb{E}[X_2]\\mathbb{E}[X_3] = (\\frac{1}{2})(\\frac{1}{2}) + \\frac{1}{2} - (\\frac{1}{2})(\\frac{1}{2})(\\frac{1}{2}) = \\frac{1}{4} + \\frac{1}{2} - \\frac{1}{8} = \\frac{5}{8}$.\n- $S=\\{1\\}$: $v(\\{1\\}) = \\mathbb{E}[f(1,X_2,X_3)] = \\mathbb{E}[X_2 + X_3 - X_2 X_3] = \\mathbb{E}[X_2] + \\mathbb{E}[X_3] - \\mathbb{E}[X_2]\\mathbb{E}[X_3] = \\frac{1}{2} + \\frac{1}{2} - (\\frac{1}{2})(\\frac{1}{2}) = 1 - \\frac{1}{4} = \\frac{3}{4}$.\n- $S=\\{2\\}$: By symmetry with feature $1$, $v(\\{2\\}) = \\mathbb{E}[f(X_1,1,X_3)] = \\frac{3}{4}$.\n- $S=\\{3\\}$: $v(\\{3\\}) = \\mathbb{E}[f(X_1,X_2,1)] = \\mathbb{E}[X_1 X_2 + 1 - X_1 X_2] = \\mathbb{E}[1] = 1$.\n- $S=\\{1,2\\}$: $v(\\{1,2\\}) = \\mathbb{E}[f(1,1,X_3)] = \\mathbb{E}[1 + X_3 - X_3] = \\mathbb{E}[1] = 1$.\n- $S=\\{1,3\\}$: $v(\\{1,3\\}) = \\mathbb{E}[f(1,X_2,1)] = \\mathbb{E}[X_2 + 1 - X_2] = \\mathbb{E}[1] = 1$.\n- $S=\\{2,3\\}$: $v(\\{2,3\\}) = \\mathbb{E}[f(X_1,1,1)] = \\mathbb{E}[X_1 + 1 - X_1] = \\mathbb{E}[1] = 1$.\n- $S=\\{1,2,3\\}$: $v(\\{1,2,3\\}) = f(1,1,1) = 1 \\cdot 1 + 1 - 1 \\cdot 1 \\cdot 1 = 1$.\n\nNow we compute the Shapley values. For $|N|=3$, the weights are $\\frac{0!2!}{3!} = \\frac{2}{6} = \\frac{1}{3}$ for $|S|=0$, $\\frac{1!1!}{3!} = \\frac{1}{6}$ for $|S|=1$, and $\\frac{2!0!}{3!} = \\frac{1}{3}$ for $|S|=2$.\n\nFor $\\phi_3$:\n$$\n\\phi_3 = \\frac{1}{3}\\big(v(\\{3\\}) - v(\\emptyset)\\big) + \\frac{1}{6}\\big(v(\\{1,3\\}) - v(\\{1\\})\\big) + \\frac{1}{6}\\big(v(\\{2,3\\}) - v(\\{2\\})\\big) + \\frac{1}{3}\\big(v(\\{1,2,3\\}) - v(\\{1,2\\})\\big)\n$$\n$$\n\\phi_3 = \\frac{1}{3}\\left(1 - \\frac{5}{8}\\right) + \\frac{1}{6}\\left(1 - \\frac{3}{4}\\right) + \\frac{1}{6}\\left(1 - \\frac{3}{4}\\right) + \\frac{1}{3}\\left(1 - 1\\right)\n$$\n$$\n\\phi_3 = \\frac{1}{3}\\left(\\frac{3}{8}\\right) + \\frac{1}{6}\\left(\\frac{1}{4}\\right) + \\frac{1}{6}\\left(\\frac{1}{4}\\right) + 0 = \\frac{3}{24} + \\frac{1}{24} + \\frac{1}{24} = \\frac{5}{24}\n$$\n\nFor $\\phi_1$:\n$$\n\\phi_1 = \\frac{1}{3}\\big(v(\\{1\\}) - v(\\emptyset)\\big) + \\frac{1}{6}\\big(v(\\{1,2\\}) - v(\\{2\\})\\big) + \\frac{1}{6}\\big(v(\\{1,3\\}) - v(\\{3\\})\\big) + \\frac{1}{3}\\big(v(\\{1,2,3\\}) - v(\\{2,3\\})\\big)\n$$\n$$\n\\phi_1 = \\frac{1}{3}\\left(\\frac{3}{4} - \\frac{5}{8}\\right) + \\frac{1}{6}\\left(1 - \\frac{3}{4}\\right) + \\frac{1}{6}\\left(1 - 1\\right) + \\frac{1}{3}\\left(1 - 1\\right)\n$$\n$$\n\\phi_1 = \\frac{1}{3}\\left(\\frac{1}{8}\\right) + \\frac{1}{6}\\left(\\frac{1}{4}\\right) + 0 + 0 = \\frac{1}{24} + \\frac{1}{24} = \\frac{2}{24} = \\frac{1}{12}\n$$\nBy symmetry of the model $f$ with respect to $x_1$ and $x_2$, we have $\\phi_2 = \\phi_1 = 1/12$.\n\nThe attributions are $\\phi_1 = 1/12$, $\\phi_2 = 1/12$, and $\\phi_3 = 5/24$. Feature $X_3$ receives the highest attribution ($\\phi_3 = 10/48$) compared to $X_1$ and $X_2$ ($\\phi_1=\\phi_2=4/48$). This reflects its dominant role; setting $X_3=1$ guarantees an output of $1$, regardless of $X_1$ and $X_2$. Features $X_1$ and $X_2$ receive smaller, equal attributions, reflecting their symmetric and interactive natureâ€”they must both be $1$ to affect the output, and only when $X_3=0$. SHAP fairly distributes the credit for the interaction between $X_1$ and $X_2$.\n\n### Task 2: Computation of Integrated Gradients (IG) attributions\n\nThe IG attribution for feature $i$ is defined as:\n$$\n\\mathrm{IG}_i(x^{\\star}) = (x^{\\star}_i - x'_i) \\int_{0}^{1} \\frac{\\partial f(x' + \\alpha (x^{\\star} - x'))}{\\partial x_i} \\, d\\alpha\n$$\nHere, $x^{\\star}=(1,1,1)$ and the baseline is $x'=(0,0,0)$. The path is $x(\\alpha) = x' + \\alpha(x^{\\star}-x') = (0,0,0) + \\alpha(1,1,1) = (\\alpha, \\alpha, \\alpha)$. Also, $x^{\\star}_i - x'_i = 1-0=1$ for all $i$.\nThe partial derivatives of $f(x_1,x_2,x_3) = x_1 x_2 + x_3 - x_1 x_2 x_3$ are:\n- $\\frac{\\partial f}{\\partial x_1} = x_2 - x_2 x_3 = x_2(1-x_3)$\n- $\\frac{\\partial f}{\\partial x_2} = x_1 - x_1 x_3 = x_1(1-x_3)$\n- $\\frac{\\partial f}{\\partial x_3} = 1 - x_1 x_2$\n\nWe evaluate these derivatives along the path $x(\\alpha)=(\\alpha,\\alpha,\\alpha)$:\n- $\\frac{\\partial f(x(\\alpha))}{\\partial x_1} = \\alpha(1-\\alpha) = \\alpha - \\alpha^2$\n- $\\frac{\\partial f(x(\\alpha))}{\\partial x_2} = \\alpha(1-\\alpha) = \\alpha - \\alpha^2$\n- $\\frac{\\partial f(x(\\alpha))}{\\partial x_3} = 1 - \\alpha \\cdot \\alpha = 1 - \\alpha^2$\n\nNow we compute the integrals:\n- $\\mathrm{IG}_1(x^{\\star}) = \\int_{0}^{1} (\\alpha - \\alpha^2) \\, d\\alpha = \\left[\\frac{\\alpha^2}{2} - \\frac{\\alpha^3}{3}\\right]_0^1 = \\frac{1}{2} - \\frac{1}{3} = \\frac{1}{6}$.\n- $\\mathrm{IG}_2(x^{\\star}) = \\int_{0}^{1} (\\alpha - \\alpha^2) \\, d\\alpha = \\frac{1}{6}$.\n- $\\mathrm{IG}_3(x^{\\star}) = \\int_{0}^{1} (1 - \\alpha^2) \\, d\\alpha = \\left[\\alpha - \\frac{\\alpha^3}{3}\\right]_0^1 = 1 - \\frac{1}{3} = \\frac{2}{3}$.\n\nThe sum of IG attributions is:\n$$\n\\sum_{i=1}^3 \\mathrm{IG}_i(x^{\\star}) = \\frac{1}{6} + \\frac{1}{6} + \\frac{2}{3} = \\frac{2}{6} + \\frac{4}{6} = \\frac{6}{6} = 1\n$$\nWe must verify this equals $f(x^{\\star}) - f(x')$.\n- $f(x^{\\star}) = f(1,1,1) = 1(1) + 1 - 1(1)(1) = 1$.\n- $f(x') = f(0,0,0) = 0(0) + 0 - 0(0)(0) = 0$.\nSo, $f(x^{\\star}) - f(x') = 1 - 0 = 1$. The sum is correct, confirming the completeness property for IG.\n\n### Task 3: Comparison and Ratio Calculation\n\nWe compare the sums of attributions for the two methods.\nFor SHAP, the sum of attributions is:\n$$\n\\sum_{i=1}^3 \\phi_i = \\phi_1 + \\phi_2 + \\phi_3 = \\frac{1}{12} + \\frac{1}{12} + \\frac{5}{24} = \\frac{2}{24} + \\frac{2}{24} + \\frac{5}{24} = \\frac{9}{24} = \\frac{3}{8}\n$$\nThis sum equals $f(x^{\\star}) - \\mathbb{E}[f(X)]$, as required by the efficiency property of Shapley values:\n$f(x^{\\star}) - \\mathbb{E}[f(X)] = 1 - v(\\emptyset) = 1 - \\frac{5}{8} = \\frac{3}{8}$.\n\nFor IG, the sum of attributions is $\\sum_{i=1}^3 \\mathrm{IG}_i(x^{\\star}) = 1$, which equals $f(x^{\\star}) - f(x') = 1-0=1$.\n\nThe sums are different ($\\frac{3}{8} \\ne 1$), illustrating that the total attribution score depends on the method and its choice of baseline (expected value for SHAP, a specific point $x'$ for IG). This is a known difference between the two methods, often described as non-additivity across methods.\n\nFinally, we compute the ratio $R$:\n$$\nR = \\frac{\\mathrm{IG}_3(x^{\\star})}{\\phi_3} = \\frac{2/3}{5/24} = \\frac{2}{3} \\cdot \\frac{24}{5} = \\frac{2 \\cdot 8}{5} = \\frac{16}{5}\n$$\nThe ratio is not $1$, which highlights that even for a single feature, the attribution scores from different methods can differ significantly, not just in their sum but in their individual values.",
            "answer": "$$\\boxed{\\frac{16}{5}}$$"
        },
        {
            "introduction": "To truly understand a model, we must move beyond attributing importance to inputs and begin to dissect its internal mechanisms. Activation patching is a powerful causal intervention technique that allows us to probe the specific function of a model's components, like an attention head in a transformer. In this exercise , you will implement this technique by swapping activations between an example and a counterexample to precisely measure an attention head's causal contribution to the final prediction, providing a hands-on introduction to mechanistic interpretability.",
            "id": "3153142",
            "problem": "You are given a simplified, fully specified, two-head self-attention classifier and a procedure for activation patching. The goal is to compute the causal contribution of a single attention head to the change in the predicted probability when its post-attention activations for one example are replaced with those from a counterexample. Your program must implement the model, compute the original and patched predictions, and output the signed differences in predicted probability for a provided test suite.\n\nModel definition from first principles:\n- Let $L$ denote the sequence length, $d_{\\text{model}}$ denote the model dimension, $H$ denote the number of attention heads, and $d_h$ denote the per-head dimension. For each input sequence, let the token embedding matrix be $X \\in \\mathbb{R}^{L \\times d_{\\text{model}}}$.\n- For head $h \\in \\{0, 1\\}$, define query, key, and value weight matrices $W_Q^{(h)} \\in \\mathbb{R}^{d_{\\text{model}} \\times d_h}$, $W_K^{(h)} \\in \\mathbb{R}^{d_{\\text{model}} \\times d_h}$, and $W_V^{(h)} \\in \\mathbb{R}^{d_{\\text{model}} \\times d_h}$.\n- Queries, keys, and values are computed as $Q^{(h)} = X W_Q^{(h)}$, $K^{(h)} = X W_K^{(h)}$, and $V^{(h)} = X W_V^{(h)}$.\n- The scaled dot-product attention for head $h$ is computed as\n$$\nS^{(h)} = \\frac{Q^{(h)} (K^{(h)})^\\top}{\\sqrt{d_h}}, \\quad A^{(h)}_{i,:} = \\operatorname{softmax}\\left(S^{(h)}_{i,:}\\right),\n$$\nwhere $\\operatorname{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_k e^{z_k}}$ is applied row-wise, giving attention weights $A^{(h)} \\in \\mathbb{R}^{L \\times L}$. The post-attention head output is\n$$\nO^{(h)} = A^{(h)} V^{(h)} \\in \\mathbb{R}^{L \\times d_h}.\n$$\n- Multi-Head Attention (MHA) output is the concatenation $O = \\operatorname{concat}(O^{(0)}, O^{(1)}) \\in \\mathbb{R}^{L \\times d_{\\text{model}}}$ followed by an output projection $W_O \\in \\mathbb{R}^{d_{\\text{model}} \\times d_{\\text{model}}}$, giving\n$$\n\\tilde{O} = O W_O^\\top \\in \\mathbb{R}^{L \\times d_{\\text{model}}}.\n$$\n- The classifier reads the first token (index $0$, akin to a classification token) as $\\tilde{o}_{\\text{cls}} = \\tilde{O}_{0,:} \\in \\mathbb{R}^{d_{\\text{model}}}$ and computes a logit $y = w^\\top \\tilde{o}_{\\text{cls}} + b$ for a binary prediction, with probability\n$$\np = \\sigma(y) = \\frac{1}{1 + e^{-y}}.\n$$\n\nActivation patching procedure:\n- For a chosen head index $h^\\star \\in \\{0, 1\\}$, replace the entire post-attention activation matrix $O^{(h^\\star)}$ of an example with the corresponding matrix computed from a counterexample, while leaving all other heads unchanged. Recompute the prediction probability for the patched example and define the causal contribution as the signed difference\n$$\n\\Delta = p_{\\text{patched}} - p_{\\text{original}}.\n$$\n\nConcrete, numerically specified model:\n- Dimensions: $L = 3$, $d_{\\text{model}} = 6$, $H = 2$, $d_h = 3$.\n- Head $0$ weights (selecting the first three embedding dimensions):\n$$\nW_Q^{(0)} = \\begin{bmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\n\\end{bmatrix},\\quad\nW_K^{(0)} = \\begin{bmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\n\\end{bmatrix},\\quad\nW_V^{(0)} = \\begin{bmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\n\\end{bmatrix}.\n$$\n- Head $1$ weights (selecting the last three embedding dimensions):\n$$\nW_Q^{(1)} = \\begin{bmatrix}\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\n\\end{bmatrix},\\quad\nW_K^{(1)} = \\begin{bmatrix}\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\n\\end{bmatrix},\\quad\nW_V^{(1)} = \\begin{bmatrix}\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n0 & 0 & 0\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\n\\end{bmatrix}.\n$$\n- Output projection:\n$$\nW_O = I_6,\n$$\nthe $6 \\times 6$ identity matrix.\n- Classifier parameters:\n$$\nw = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0.1 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix},\\quad b = 0.\n$$\n\nTest suite inputs:\n- Example $X^{(E1)} \\in \\mathbb{R}^{3 \\times 6}$:\n$$\nX^{(E1)} = \\begin{bmatrix}\n2 & 2 & 2 & 0.1 & -0.2 & 0.0\\\\\n3 & -1 & 0 & 0.2 & 0.1 & -0.1\\\\\n-1 & 1 & 0.5 & 0.0 & 0.0 & 0.2\n\\end{bmatrix}.\n$$\n- Counterexample $X^{(C1)} \\in \\mathbb{R}^{3 \\times 6}$:\n$$\nX^{(C1)} = \\begin{bmatrix}\n-2 & -2 & -2 & 0.0 & 0.0 & 0.1\\\\\n-3 & 0.5 & 1 & 0.1 & -0.2 & 0.3\\\\\n1 & 1 & 1 & 0.0 & -0.1 & 0.0\n\\end{bmatrix}.\n$$\n- Example $X^{(E3)} \\in \\mathbb{R}^{3 \\times 6}$:\n$$\nX^{(E3)} = \\begin{bmatrix}\n4 & 0 & 1 & 0.0 & 0.0 & 0.0\\\\\n0.5 & 3 & 1 & 0.1 & 0.0 & -0.1\\\\\n1 & -2 & 2 & 0.0 & 0.2 & 0.2\n\\end{bmatrix}.\n$$\n- Counterexample $X^{(C3)} \\in \\mathbb{R}^{3 \\times 6}$:\n$$\nX^{(C3)} = \\begin{bmatrix}\n-4 & 0 & -1 & 0.0 & 0.0 & 0.0\\\\\n0.5 & -3 & -1 & 0.0 & 0.1 & 0.0\\\\\n-1 & 2 & -2 & -0.1 & 0.0 & 0.1\n\\end{bmatrix}.\n$$\n\nTest suite and required outputs:\n- Case $1$: Patch head $h^\\star = 0$ for $X^{(E1)}$ with $X^{(C1)}$; output $\\Delta_1 \\in \\mathbb{R}$.\n- Case $2$: Patch head $h^\\star = 1$ for $X^{(E1)}$ with $X^{(C1)}$; output $\\Delta_2 \\in \\mathbb{R}$.\n- Case $3$: Patch head $h^\\star = 0$ for $X^{(E1)}$ with itself $X^{(E1)}$; output $\\Delta_3 \\in \\mathbb{R}$ (a boundary case that should be zero).\n- Case $4$: Patch head $h^\\star = 0$ for $X^{(E3)}$ with $X^{(C3)}$; output $\\Delta_4 \\in \\mathbb{R}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, specifically in the format $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4]$. No physical units or angles are involved; all outputs are real numbers.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and fully specified. It provides a clear, computationally verifiable task in the domain of deep learning model interpretability. We will proceed with a solution.\n\nThe objective is to compute the causal contribution $\\Delta$ of a specific attention head to a model's prediction. This is defined as the change in the predicted probability when the post-attention activations of that head for an example $X_E$ are replaced with those from a counterexample $X_C$. The formula is $\\Delta = p_{\\text{patched}} - p_{\\text{original}}$.\n\nThe solution requires implementing the forward pass of the specified two-head attention model and then applying the activation patching procedure for the four given test cases.\n\n**1. Model Forward Pass**\n\nThe forward pass computes the prediction probability $p$ for a given input token embedding matrix $X \\in \\mathbb{R}^{L \\times d_{\\text{model}}}$. The dimensions are given as $L=3$, $d_{\\text{model}}=6$, $H=2$, and the per-head dimension is $d_h = d_{\\text{model}} / H = 3$.\n\n**Step 1.1: Per-Head Computations**\n\nFor each head $h \\in \\{0, 1\\}$, we calculate the query ($Q^{(h)}$), key ($K^{(h)}$), and value ($V^{(h)}$) matrices. The problem specifies weight matrices $W_Q^{(h)}$, $W_K^{(h)}$, $W_V^{(h)}$ that act as selectors.\n\nFor head $h=0$, the weights select the first $d_h=3$ columns of the input embedding $X$. Thus:\n$$\nQ^{(0)} = K^{(0)} = V^{(0)} = X_{[ :, 0:3 ]} \\in \\mathbb{R}^{3 \\times 3}\n$$\n\nFor head $h=1$, the weights select the last $d_h=3$ columns of $X$:\n$$\nQ^{(1)} = K^{(1)} = V^{(1)} = X_{[ :, 3:6 ]} \\in \\mathbb{R}^{3 \\times 3}\n$$\n\nNext, we compute the scaled dot-product attention scores $S^{(h)}$, the attention weights $A^{(h)}$ via a row-wise softmax, and the post-attention head output $O^{(h)}$.\n$$\nS^{(h)} = \\frac{Q^{(h)} (K^{(h)})^\\top}{\\sqrt{d_h}}\n$$\n$$\nA^{(h)}_{i,:} = \\operatorname{softmax}\\left(S^{(h)}_{i,:}\\right) \\quad \\text{where } \\operatorname{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_k e^{z_k}}\n$$\n$$\nO^{(h)} = A^{(h)} V^{(h)} \\in \\mathbb{R}^{3 \\times 3}\n$$\n\n**Step 1.2: MHA Output and Classification**\n\nThe outputs of the two heads, $O^{(0)}$ and $O^{(1)}$, are concatenated to form the Multi-Head Attention (MHA) input $O$:\n$$\nO = \\operatorname{concat}(O^{(0)}, O^{(1)}) \\in \\mathbb{R}^{3 \\times 6}\n$$\n\nThis is followed by an output projection $\\tilde{O} = O W_O^\\top$. Since $W_O = I_6$ (the $6 \\times 6$ identity matrix), we have $W_O^\\top = I_6$ and therefore:\n$$\n\\tilde{O} = O I_6 = O\n$$\n\nThe classifier uses the representation of the first token (at index $0$), denoted $\\tilde{o}_{\\text{cls}}$, which is the first row of $\\tilde{O}$:\n$$\n\\tilde{o}_{\\text{cls}} = \\tilde{O}_{0,:} \\in \\mathbb{R}^{6}\n$$\n\nA logit $y$ is computed using the weight vector $w = [1, 1, 1, 0.1, 0.1, 0.1]^\\top$ and bias $b=0$:\n$$\ny = w^\\top \\tilde{o}_{\\text{cls}} + b = \\sum_{i=0}^{5} w_i (\\tilde{o}_{\\text{cls}})_i\n$$\n\nFinally, the prediction probability $p$ is obtained by applying the sigmoid function $\\sigma(\\cdot)$:\n$$\np = \\sigma(y) = \\frac{1}{1 + e^{-y}}\n$$\n\nThis completes the forward pass for a single input $X$.\n\n**2. Activation Patching Procedure**\n\nTo compute the causal contribution $\\Delta$ for a given example $X_E$, counterexample $X_C$, and target head $h^\\star$, we proceed as follows:\n\n**Step 2.1: Compute Original Probability**\nFirst, we compute the original prediction probability $p_{\\text{original}}$ by performing a full forward pass on the example input $X_E$. This requires computing both head outputs, $O^{(0)}_E$ and $O^{(1)}_E$, from $X_E$.\n$$\np_{\\text{original}} = \\text{compute_prob}(X_E)\n$$\n\n**Step 2.2: Compute Patched Probability**\nNext, we compute the \"patched\" probability $p_{\\text{patched}}$. This involves replacing the activation of the target head $h^\\star$ with the corresponding activation from the counterexample $X_C$, while keeping the other head's activation from the original example $X_E$.\n\nIf $h^\\star = 0$, the patched MHA input is formed using $O^{(0)}_C$ (computed from $X_C$) and $O^{(1)}_E$ (computed from $X_E$):\n$$\nO_{\\text{patched}} = \\operatorname{concat}(O^{(0)}_C, O^{(1)}_E)\n$$\n\nIf $h^\\star = 1$, the patched MHA input uses $O^{(0)}_E$ and $O^{(1)}_C$:\n$$\nO_{\\text{patched}} = \\operatorname{concat}(O^{(0)}_E, O^{(1)}_C)\n$$\n\nFrom $O_{\\text{patched}}$, we compute the patched logit $y_{\\text{patched}}$ and probability $p_{\\text{patched}}$ following the same classification steps as in the standard forward pass.\n\n**Step 2.3: Compute Causal Contribution**\nThe causal contribution $\\Delta$ is the signed difference between the patched and original probabilities:\n$$\n\\Delta = p_{\\text{patched}} - p_{\\text{original}}\n$$\n\nFor the test case where $X_C = X_E$ (Case $3$), the \"patched\" activation $O^{(h^\\star)}_C$ is identical to the original activation $O^{(h^\\star)}_E$. Consequently, $p_{\\text{patched}} = p_{\\text{original}}$, and we expect $\\Delta_3 = 0$, which serves as a sanity check for the implementation.\n\nThe following Python program implements this logic to compute $\\Delta_1, \\Delta_2, \\Delta_3, \\Delta_4$ for the specified test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import softmax\n\ndef solve():\n    \"\"\"\n    Computes the causal contribution of attention heads via activation patching.\n    \"\"\"\n    \n    # Define model parameters\n    d_h = 3\n    w = np.array([1.0, 1.0, 1.0, 0.1, 0.1, 0.1])\n    b = 0.0\n\n    # Define test suite inputs as numpy arrays\n    X_E1 = np.array([\n        [2.0, 2.0, 2.0, 0.1, -0.2, 0.0],\n        [3.0, -1.0, 0.0, 0.2, 0.1, -0.1],\n        [-1.0, 1.0, 0.5, 0.0, 0.0, 0.2]\n    ])\n    X_C1 = np.array([\n        [-2.0, -2.0, -2.0, 0.0, 0.0, 0.1],\n        [-3.0, 0.5, 1.0, 0.1, -0.2, 0.3],\n        [1.0, 1.0, 1.0, 0.0, -0.1, 0.0]\n    ])\n    X_E3 = np.array([\n        [4.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n        [0.5, 3.0, 1.0, 0.1, 0.0, -0.1],\n        [1.0, -2.0, 2.0, 0.0, 0.2, 0.2]\n    ])\n    X_C3 = np.array([\n        [-4.0, 0.0, -1.0, 0.0, 0.0, 0.0],\n        [0.5, -3.0, -1.0, 0.0, 0.1, 0.0],\n        [-1.0, 2.0, -2.0, -0.1, 0.0, 0.1]\n    ])\n\n    # Define the test cases\n    test_cases = [\n        {'X_E': X_E1, 'X_C': X_C1, 'h_star': 0},  # Case 1\n        {'X_E': X_E1, 'X_C': X_C1, 'h_star': 1},  # Case 2\n        {'X_E': X_E1, 'X_C': X_E1, 'h_star': 0},  # Case 3\n        {'X_E': X_E3, 'X_C': X_C3, 'h_star': 0}   # Case 4\n    ]\n    \n    def sigmoid(y):\n        \"\"\"Computes the sigmoid function.\"\"\"\n        return 1 / (1 + np.exp(-y))\n\n    def compute_head_output(X, h, d_h_val):\n        \"\"\"\n        Computes the post-attention output for a single head.\n        \n        Args:\n            X (np.ndarray): Input token embeddings, shape (L, d_model).\n            h (int): Head index (0 or 1).\n            d_h_val (int): Per-head dimension.\n            \n        Returns:\n            np.ndarray: Post-attention head output, shape (L, d_h).\n        \"\"\"\n        if h == 0:\n            sub_X = X[:, :d_h_val]\n        else: # h == 1\n            sub_X = X[:, d_h_val:]\n        \n        Q, K, V = sub_X, sub_X, sub_X\n        \n        S = (Q @ K.T) / np.sqrt(d_h_val)\n        A = softmax(S, axis=1)\n        O_h = A @ V\n        \n        return O_h\n\n    def compute_prob_from_heads(O_0, O_1):\n        \"\"\"\n        Computes the final probability from the head outputs.\n        \"\"\"\n        O = np.concatenate((O_0, O_1), axis=1)\n        o_cls = O[0, :]\n        y = np.dot(w, o_cls) + b\n        p = sigmoid(y)\n        return p\n\n    results = []\n    \n    # Process each test case\n    for case in test_cases:\n        X_E = case['X_E']\n        X_C = case['X_C']\n        h_star = case['h_star']\n\n        # 1. Compute original probability\n        O0_E = compute_head_output(X_E, 0, d_h)\n        O1_E = compute_head_output(X_E, 1, d_h)\n        p_original = compute_prob_from_heads(O0_E, O1_E)\n\n        # 2. Compute patched probability\n        if h_star == 0:\n            O0_patched = compute_head_output(X_C, 0, d_h)\n            p_patched = compute_prob_from_heads(O0_patched, O1_E)\n        else: # h_star == 1\n            O1_patched = compute_head_output(X_C, 1, d_h)\n            p_patched = compute_prob_from_heads(O0_E, O1_patched)\n        \n        # 3. Compute and store the difference\n        delta = p_patched - p_original\n        results.append(delta)\n\n    # Format the output as specified\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}