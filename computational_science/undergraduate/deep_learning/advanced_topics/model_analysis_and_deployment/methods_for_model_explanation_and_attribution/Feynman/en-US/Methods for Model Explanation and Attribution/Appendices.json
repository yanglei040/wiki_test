{
    "hands_on_practices": [
        {
            "introduction": "While raw gradients, $\\nabla_{\\mathbf{x}} f(\\mathbf{x})$, offer a simple starting point for attribution, they suffer from a critical flaw known as saturation, where the gradient can be zero even if a feature is highly influential. This exercise challenges you to move beyond this limitation by implementing Integrated Gradients (IG), a method that satisfies the completeness axiom by integrating gradients along a path from a baseline to the input. By deriving the IG formula for a ReLU network from first principles , you will gain a deep, practical understanding of why this method provides a more reliable attribution.",
            "id": "3150467",
            "problem": "You are given a single hidden-unit Rectified Linear Unit (ReLU) model defined by the scalar-valued function $f(\\mathbf{x})=\\max\\left(0,\\mathbf{w}^\\top \\mathbf{x}+b\\right)$, where $\\mathbf{w}\\in\\mathbb{R}^d$, $b\\in\\mathbb{R}$, and $\\mathbf{x}\\in\\mathbb{R}^d$. Consider two attribution methods for a target input $\\mathbf{x}$:\n- Raw gradients: $a_i=\\frac{\\partial f}{\\partial x_i}(\\mathbf{x})$.\n- Integrated gradients (from a baseline $\\mathbf{x}'$ along the straight-line path): for each coordinate $i$, the attribution is\n$$\\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')=(x_i-x'_i)\\int_{0}^{1}\\frac{\\partial f}{\\partial x_i}\\big(\\mathbf{x}'+\\alpha(\\mathbf{x}-\\mathbf{x}')\\big)\\,d\\alpha.$$\n\nYour task is to derive, implement, and compare the two attribution methods using only the fundamental definitions of gradients, the ReLU function, and path integrals, without relying on any pre-derived shortcut formulas. Work entirely in purely mathematical terms. No physical units are involved.\n\nRequirements:\n1) Starting from the definitions of gradient, the ReLU function, and the line integral along a straight path, derive a closed-form expression for $\\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')$ specialized to $f(\\mathbf{x})=\\max\\left(0,\\mathbf{w}^\\top \\mathbf{x}+b\\right)$, expressed only in terms of $\\mathbf{w}$, $b$, $\\mathbf{x}$, and $\\mathbf{x}'$. You must reason from first principles about when the derivative of the ReLU is active or inactive along the straight-line path.\n2) Define the raw gradient attribution at $\\mathbf{x}$ by $a(\\mathbf{x})=\\nabla_{\\mathbf{x}} f(\\mathbf{x})$, with the convention that when $\\mathbf{w}^\\top\\mathbf{x}+b=0$ the gradient is taken to be the zero vector for definiteness.\n3) Define two baselines $\\mathbf{x}'$:\n   - Zero baseline $\\mathbf{x}'=\\mathbf{0}$.\n   - A principled baseline $\\mathbf{x}'$ on the ReLU decision boundary: choose the orthogonal projection of $\\mathbf{x}$ onto the hyperplane $\\{\\mathbf{z}:\\mathbf{w}^\\top \\mathbf{z}+b=0\\}$, i.e.,\n   $$\\mathbf{x}'=\\mathbf{x}-\\frac{\\mathbf{w}^\\top \\mathbf{x}+b}{\\lVert \\mathbf{w}\\rVert_2^2}\\,\\mathbf{w},$$\n   whenever $\\lVert \\mathbf{w}\\rVert_2>0$. In the degenerate case $\\lVert \\mathbf{w}\\rVert_2=0$ (so $f(\\mathbf{x})=\\max(0,b)$), define the boundary baseline by $\\mathbf{x}'=\\mathbf{x}$ so that the straight-line path is trivial.\n4) Define a saturation diagnostic at $\\mathbf{x}$ relative to the zero baseline as the Boolean\n$$S(\\mathbf{x})=\\big(\\lVert \\nabla_{\\mathbf{x}} f(\\mathbf{x})\\rVert_2\\le \\varepsilon\\big)\\ \\wedge\\ \\big(\\lVert \\mathrm{IG}(\\mathbf{x},\\mathbf{0})\\rVert_2> \\varepsilon\\big),$$\nwhere $\\varepsilon=10^{-9}$ is a fixed tolerance used for numerical comparisons.\n5) Verify the completeness relation for integrated gradients for both baselines:\n   $$C_0(\\mathbf{x})=\\left|\\sum_{i=1}^d \\mathrm{IG}_i(\\mathbf{x},\\mathbf{0})-\\big(f(\\mathbf{x})-f(\\mathbf{0})\\big)\\right|\\le \\varepsilon,$$\n   $$C_b(\\mathbf{x})=\\left|\\sum_{i=1}^d \\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')-\\big(f(\\mathbf{x})-f(\\mathbf{x}')\\big)\\right|\\le \\varepsilon,$$\n   where $\\mathbf{x}'$ is the boundary baseline as defined in item $3$.\n6) Implement a program that, for each test case below, computes:\n   - The saturation diagnostic $S(\\mathbf{x})$ (Boolean).\n   - The completeness checks $C_0(\\mathbf{x})\\le\\varepsilon$ and $C_b(\\mathbf{x})\\le\\varepsilon$ (Booleans).\n   Use exact closed-form reasoning for the integrated gradients derived in item $1$ rather than numerical quadrature.\n\nTest suite (each case gives $(\\mathbf{w},b,\\mathbf{x})$):\n- Case $1$: $\\mathbf{w}=[1.0,-2.0]$, $b=0.5$, $\\mathbf{x}=[2.0,1.0]$.\n- Case $2$: $\\mathbf{w}=[1.0,1.0]$, $b=1.0$, $\\mathbf{x}=[-2.0,-2.0]$.\n- Case $3$: $\\mathbf{w}=[1.0,3.0]$, $b=-4.0$, $\\mathbf{x}=[1.0,1.0]$.\n- Case $4$: $\\mathbf{w}=[2.0,-2.0]$, $b=1.0$, $\\mathbf{x}=[1.0,1.0]$.\n- Case $5$: $\\mathbf{w}=[0.0,0.0]$, $b=1.5$, $\\mathbf{x}=[3.0,-7.0]$.\n\nAngle units are not relevant. There are no physical units.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- For each case $k\\in\\{1,2,3,4,5\\}$, output the triple $\\big(S(\\mathbf{x}^{(k)}),\\ C_0(\\mathbf{x}^{(k)})\\le\\varepsilon,\\ C_b(\\mathbf{x}^{(k)})\\le\\varepsilon\\big)$ as three Booleans.\n- Concatenate the triples for all cases into one flat list of length $15$ and print it in a single line, e.g., $[r_1,r_2,\\ldots,r_{15}]$ where each $r_j$ is either $\\mathrm{True}$ or $\\mathrm{False}$.",
            "solution": "We begin from fundamental definitions. The model is $f(\\mathbf{x})=\\max(0,z(\\mathbf{x}))$ with $z(\\mathbf{x})=\\mathbf{w}^\\top\\mathbf{x}+b$. The gradient of $f$ with respect to $\\mathbf{x}$ exists everywhere except where $z(\\mathbf{x})=0$; we adopt the convention that at $z(\\mathbf{x})=0$ the gradient is the zero vector. Thus,\n$$\n\\nabla_{\\mathbf{x}} f(\\mathbf{x})=\n\\begin{cases}\n\\mathbf{0}, & \\text{if } z(\\mathbf{x})\\le 0,\\\\\n\\mathbf{w}, & \\text{if } z(\\mathbf{x})>0.\n\\end{cases}\n$$\n\nIntegrated gradients (from a straight-line path) are defined by the path integral of the gradient projected onto the input difference. For a baseline $\\mathbf{x}'$ and target $\\mathbf{x}$, let $\\gamma(\\alpha)=\\mathbf{x}'+\\alpha(\\mathbf{x}-\\mathbf{x}')$ for $\\alpha\\in[0,1]$. The $i$-th coordinate integrated gradient is\n$$\n\\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')=(x_i-x'_i)\\int_{0}^{1}\\frac{\\partial f}{\\partial x_i}\\big(\\gamma(\\alpha)\\big)\\,d\\alpha.\n$$\nBy the structure of $f$, along the path the derivative toggles between $\\mathbf{0}$ and $\\mathbf{w}$ depending on the sign of $z(\\gamma(\\alpha))$. We compute $z(\\gamma(\\alpha))$:\n$$\nz(\\gamma(\\alpha))=\\mathbf{w}^\\top\\big(\\mathbf{x}'+\\alpha(\\mathbf{x}-\\mathbf{x}')\\big)+b=\\underbrace{\\big(\\mathbf{w}^\\top \\mathbf{x}'+b\\big)}_{z_0}+\\alpha\\underbrace{\\mathbf{w}^\\top(\\mathbf{x}-\\mathbf{x}')}_{c}=z_0+\\alpha c.\n$$\nThus $z(\\gamma(\\alpha))$ is an affine function of $\\alpha$. Define the crossing point (if any) by\n$$\n\\alpha^\\star=-\\frac{z_0}{c},\\quad\\text{when }c\\ne 0.\n$$\nWe analyze cases:\n\n- If $\\lVert \\mathbf{w}\\rVert_2=0$, then $f(\\mathbf{x})=\\max(0,b)$ is constant in $\\mathbf{x}$ and $\\nabla_{\\mathbf{x}}f(\\mathbf{x})=\\mathbf{0}$ for all $\\mathbf{x}$. Therefore $\\mathrm{IG}(\\mathbf{x},\\mathbf{x}')=\\mathbf{0}$ for any $\\mathbf{x},\\mathbf{x}'$, and completeness holds because $f(\\mathbf{x})-f(\\mathbf{x}')=0$ for any $\\mathbf{x},\\mathbf{x}'$ when $b>0$, and equals $0$ as well when $b\\le 0$.\n\n- Assume $\\lVert \\mathbf{w}\\rVert_2>0$. Then along the path, the gradient is $\\mathbf{w}$ on the subset of $\\alpha\\in[0,1]$ where $z(\\gamma(\\alpha))>0$, and $\\mathbf{0}$ where $z(\\gamma(\\alpha))\\le 0$. Since $z(\\gamma(\\alpha))=z_0+\\alpha c$ is affine, the set where it is positive is an interval whose length equals:\n  - If $c=0$, then $z(\\gamma(\\alpha))\\equiv z_0$. The positive-length measure $L$ of the active region is $L=1$ if $z_0>0$ and $L=0$ otherwise.\n  - If $c>0$, then $z(\\gamma(\\alpha))>0$ for $\\alpha>\\alpha^\\star$; the active length is $L=\\begin{cases}0,&\\alpha^\\star\\ge 1,\\\\1,&\\alpha^\\star\\le 0,\\\\1-\\alpha^\\star,&\\text{otherwise.}\\end{cases}$\n  - If $c<0$, then $z(\\gamma(\\alpha))>0$ for $\\alpha<\\alpha^\\star$; the active length is $L=\\begin{cases}0,&\\alpha^\\star\\le 0,\\\\1,&\\alpha^\\star\\ge 1,\\\\\\alpha^\\star,&\\text{otherwise.}\\end{cases}$\n\nSince on the active set the gradient equals $\\mathbf{w}$ and on the inactive set it is $\\mathbf{0}$, we have for each $i$:\n$$\n\\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')=(x_i-x'_i)\\cdot w_i \\cdot L.\n$$\nCollecting across coordinates, the vector form is\n$$\n\\mathrm{IG}(\\mathbf{x},\\mathbf{x}')=\\big(\\mathbf{x}-\\mathbf{x}'\\big)\\odot \\mathbf{w}\\cdot L,\n$$\nwhere $\\odot$ denotes elementwise product and $L$ is the active-length scalar determined above.\n\nWhy this is correct: The integral reduces to the measure of the set where the integrand is nonzero because the derivative is piecewise constant along the straight path. This leverages only the definition of the ReLU derivative and the path integral.\n\nCompleteness property: The sum of integrated gradients equals the line integral of the gradient along the path in the direction of $\\mathbf{x}-\\mathbf{x}'$:\n$$\n\\sum_{i=1}^d \\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')=\\int_0^1 \\nabla_{\\mathbf{x}} f\\big(\\gamma(\\alpha)\\big)^\\top (\\mathbf{x}-\\mathbf{x}')\\,d\\alpha.\n$$\nSince $\\nabla_{\\mathbf{x}} f(\\gamma(\\alpha))$ is $\\mathbf{w}$ on the active region and $\\mathbf{0}$ otherwise, this integral equals $L\\cdot \\mathbf{w}^\\top(\\mathbf{x}-\\mathbf{x}')=L\\cdot c$. But\n$$\nf(\\mathbf{x})-f(\\mathbf{x}')=\\max(0,z_0+c)-\\max(0,z_0).\n$$\nGiven the affine form and piecewise-constant derivative except possibly at a single $\\alpha^\\star$ of measure zero, the fundamental theorem of calculus along the path implies\n$$\n\\int_0^1 \\frac{d}{d\\alpha} f\\big(\\gamma(\\alpha)\\big)\\,d\\alpha=f(\\gamma(1))-f(\\gamma(0))=f(\\mathbf{x})-f(\\mathbf{x}'),\n$$\nand since $\\frac{d}{d\\alpha} f(\\gamma(\\alpha))=\\nabla_{\\mathbf{x}} f(\\gamma(\\alpha))^\\top (\\mathbf{x}-\\mathbf{x}')$, we obtain\n$$\n\\sum_{i=1}^d \\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')=f(\\mathbf{x})-f(\\mathbf{x}').\n$$\nOur explicit $L$-based expression satisfies this equality case-wise, including the degenerate cases $c=0$ and $\\lVert\\mathbf{w}\\rVert_2=0$.\n\nPrincipled baseline on the ReLU boundary: For $\\lVert\\mathbf{w}\\rVert_2>0$, define the boundary baseline as the orthogonal projection of $\\mathbf{x}$ onto the hyperplane $\\mathbf{w}^\\top \\mathbf{z}+b=0$:\n$$\n\\mathbf{x}'=\\mathbf{x}-\\frac{\\mathbf{w}^\\top \\mathbf{x}+b}{\\lVert \\mathbf{w}\\rVert_2^2}\\,\\mathbf{w}.\n$$\nThis choice satisfies $\\mathbf{w}^\\top \\mathbf{x}'+b=0$, hence $f(\\mathbf{x}')=0$. For this baseline, $c=\\mathbf{w}^\\top(\\mathbf{x}-\\mathbf{x}')=\\mathbf{w}^\\top \\mathbf{x}+b$, and $z_0=0$. Therefore $\\alpha^\\star=0$ when $c\\ne 0$. If $c>0$ (the active case at $\\mathbf{x}$), the active length is $L=1$ and\n$$\n\\mathrm{IG}(\\mathbf{x},\\mathbf{x}')=(\\mathbf{x}-\\mathbf{x}')\\odot \\mathbf{w}.\n$$\nSumming yields\n$$\n\\sum_i \\mathrm{IG}_i(\\mathbf{x},\\mathbf{x}')=\\mathbf{w}^\\top(\\mathbf{x}-\\mathbf{x}')=\\mathbf{w}^\\top\\mathbf{x}+b=f(\\mathbf{x})-f(\\mathbf{x}')=f(\\mathbf{x}),\n$$\nverifying completeness and that attributions exactly account for the output. If $c\\le 0$ (inactive at $\\mathbf{x}$ or on the boundary), $L=0$ and $\\mathrm{IG}(\\mathbf{x},\\mathbf{x}')=\\mathbf{0}$, again matching completeness since $f(\\mathbf{x})=f(\\mathbf{x}')=0$. In the degenerate case $\\lVert\\mathbf{w}\\rVert_2=0$, no such hyperplane exists unless $b=0$. We define $\\mathbf{x}'=\\mathbf{x}$, which yields the trivial path, $\\mathrm{IG}=\\mathbf{0}$, and $f(\\mathbf{x})-f(\\mathbf{x}')=0$.\n\nSaturation diagnosis: Raw gradients can be misleadingly small (or zero) when $z(\\mathbf{x})\\le 0$, even though relative to a baseline such as $\\mathbf{0}$ the integrated gradients can be nonzero and reveal that moving toward the baseline changes the model output. We formalize this via\n$$\nS(\\mathbf{x})=\\big(\\lVert \\nabla_{\\mathbf{x}} f(\\mathbf{x})\\rVert_2\\le \\varepsilon\\big)\\ \\wedge\\ \\big(\\lVert \\mathrm{IG}(\\mathbf{x},\\mathbf{0})\\rVert_2> \\varepsilon\\big),\n$$\nwith $\\varepsilon=10^{-9}$.\n\nAlgorithm summary for each test case:\n- Compute $f(\\mathbf{x})$, $f(\\mathbf{0})$, and the raw gradient at $\\mathbf{x}$ using the definition of the ReLU derivative.\n- Compute the zero-baseline integrated gradients using the closed-form derived above with $L$ determined by $z_0=\\mathbf{w}^\\top \\mathbf{0}+b=b$, $c=\\mathbf{w}^\\top(\\mathbf{x}-\\mathbf{0})=\\mathbf{w}^\\top\\mathbf{x}$, including the $c=0$ and $\\lVert\\mathbf{w}\\rVert_2=0$ cases.\n- Construct the boundary baseline $\\mathbf{x}'$ as the orthogonal projection if $\\lVert\\mathbf{w}\\rVert_2>0$, otherwise set $\\mathbf{x}'=\\mathbf{x}$. Compute the corresponding integrated gradients similarly.\n- Form $S(\\mathbf{x})$ and check completeness $C_0(\\mathbf{x})\\le \\varepsilon$ and $C_b(\\mathbf{x})\\le \\varepsilon$.\n\nApplying this procedure to the provided test suite ensures coverage of: an active case, an inactive case where zero-baseline path crosses into the active region (revealing saturation), a boundary case, a case with a path parallel to the boundary ($c=0$ but active), and a degenerate case with $\\mathbf{w}=\\mathbf{0}$. The final output is the flattened list of Booleans in the specified order.",
            "answer": "```python\nimport numpy as np\n\ndef relu(z):\n    return np.maximum(0.0, z)\n\ndef f_val(x, w, b):\n    return relu(np.dot(w, x) + b)\n\ndef grad_raw(x, w, b, eps=0.0):\n    # At z > 0: gradient is w; at z <= 0: zero vector (by convention at z=0)\n    z = np.dot(w, x) + b\n    if z > 0:\n        return w.copy()\n    else:\n        return np.zeros_like(w)\n\ndef ig_closed_form(x, x_base, w, b, tol=1e-12):\n    # Integrated gradients along straight-line path from x_base to x\n    # Handle degenerate w=0: IG is zero vector\n    if np.allclose(w, 0.0, atol=tol):\n        return np.zeros_like(w)\n    # Compute z0 and c\n    z0 = np.dot(w, x_base) + b\n    dx = x - x_base\n    c = np.dot(w, dx)\n    # Active length L determination\n    if abs(c) <= tol:\n        # z(alpha) = z0 constant\n        if z0 > 0:\n            L = 1.0\n        else:\n            L = 0.0\n    else:\n        a_star = -z0 / c\n        if c > 0:\n            if a_star >= 1.0:\n                L = 0.0\n            elif a_star <= 0.0:\n                L = 1.0\n            else:\n                L = 1.0 - a_star\n        else:  # c < 0\n            if a_star <= 0.0:\n                L = 0.0\n            elif a_star >= 1.0:\n                L = 1.0\n            else:\n                L = a_star\n    return dx * w * L\n\ndef boundary_baseline(x, w, b, tol=1e-12):\n    # If w is zero vector, return x (trivial path)\n    if np.allclose(w, 0.0, atol=tol):\n        return x.copy()\n    ww = np.dot(w, w)\n    # Projection of x onto the hyperplane w^T z + b = 0\n    factor = (np.dot(w, x) + b) / ww\n    return x - factor * w\n\ndef solve():\n    # Define epsilon for numerical checks\n    eps = 1e-9\n\n    # Test cases: (w, b, x)\n    test_cases = [\n        (np.array([1.0, -2.0]), 0.5, np.array([2.0, 1.0])),     # Case 1\n        (np.array([1.0, 1.0]), 1.0, np.array([-2.0, -2.0])),    # Case 2\n        (np.array([1.0, 3.0]), -4.0, np.array([1.0, 1.0])),     # Case 3\n        (np.array([2.0, -2.0]), 1.0, np.array([1.0, 1.0])),     # Case 4\n        (np.array([0.0, 0.0]), 1.5, np.array([3.0, -7.0])),     # Case 5 (degenerate w=0)\n    ]\n\n    results = []\n    for w, b, x in test_cases:\n        # Raw gradient and norms\n        g = grad_raw(x, w, b)\n        g_norm = np.linalg.norm(g, 2)\n\n        # Zero baseline IG\n        x0 = np.zeros_like(x)\n        ig0 = ig_closed_form(x, x0, w, b)\n        ig0_norm = np.linalg.norm(ig0, 2)\n\n        # Saturation diagnostic\n        saturation = (g_norm <= eps) and (ig0_norm > eps)\n\n        # Boundary baseline and IG\n        xb = boundary_baseline(x, w, b)\n        igb = ig_closed_form(x, xb, w, b)\n\n        # Completeness checks\n        comp0_err = abs(np.sum(ig0) - (f_val(x, w, b) - f_val(x0, w, b)))\n        compb_err = abs(np.sum(igb) - (f_val(x, w, b) - f_val(xb, w, b)))\n        comp0_ok = comp0_err <= eps\n        compb_ok = compb_err <= eps\n\n        # Append booleans in the specified order per case\n        results.extend([saturation, comp0_ok, compb_ok])\n\n    # Final print statement in the exact required format: single-line list\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "In practice, machine learning models are rarely applied to raw data; pre-processing steps like feature standardization are common and essential. This practice investigates how such transformations can distort gradient-based attributions, potentially leading to misleading conclusions about feature importance. By deriving standardized attributions that are invariant to scaling , you will learn to produce more robust and comparable explanations that correctly reflect the model's behavior in the standardized feature space.",
            "id": "3150465",
            "problem": "You are given a scalar-valued feedforward model that begins with a feature standardization layer, followed by a differentiable transformation. The feature standardization layer maps an input vector $x \\in \\mathbb{R}^d$ to $z \\in \\mathbb{R}^d$ via elementwise standardization $z = (x - \\mu) \\oslash \\sigma$, where $\\mu \\in \\mathbb{R}^d$ and $\\sigma \\in \\mathbb{R}^d$ has strictly positive components, and $\\oslash$ denotes elementwise division. The model output is $f(x) = g(z)$, where $g$ is a differentiable scalar function of $z$. Consider gradient-based attribution methods in the input space and analyze how the standardization layer affects them. Your goal is to derive from first principles how scaling by $\\sigma$ influences gradient-based attributions, and to propose standardized attributions that undo the influence of scaling such that they coincide with the corresponding attributions computed directly in the standardized space. Use only fundamental definitions (gradient, chain rule, and line integral for path-integrated attributions) as the base for your derivations.\n\nDefinitions for the attribution methods considered:\n- Vanilla gradient attribution: the vector $A_{\\text{grad}}(x) = \\nabla_x f(x)$.\n- Input-times-gradient attribution: the vector $A_{\\text{IGR}}(x) = x \\odot \\nabla_x f(x)$, where $\\odot$ denotes elementwise multiplication.\n- Integrated Gradients (IG): for a chosen baseline $x' \\in \\mathbb{R}^d$, the vector $A_{\\text{IG}}(x;x')$ is defined componentwise by $A_{\\text{IG},k}(x;x') = (x_k - x'_k) \\int_0^1 \\frac{\\partial f(x' + \\alpha (x - x'))}{\\partial x_k} \\, d\\alpha$.\n\nTasks:\n1. Using the chain rule applied to $f(x) = g\\!\\left((x-\\mu) \\oslash \\sigma\\right)$, derive from first principles how the feature standardization layer affects the vanilla gradient attribution, and propose a standardized gradient attribution $A_{\\text{grad}}^{\\text{std}}(x)$ that undoes the scaling effect so that it matches the gradient computed directly in the standardized space, i.e., $\\nabla_z g(z)$ evaluated at $z = (x - \\mu) \\oslash \\sigma$.\n2. Analyze the input-times-gradient attribution under feature standardization and propose a standardized version $A_{\\text{IGR}}^{\\text{std}}(x)$ that undoes scaling and equals the input-times-gradient computed directly in the standardized space, i.e., $z \\odot \\nabla_z g(z)$ evaluated at $z = (x - \\mu) \\oslash \\sigma$.\n3. Analyze the Integrated Gradients attribution under feature standardization and determine whether a standardized transformation is needed for invariance with respect to scaling. Use the fundamental definition of Integrated Gradients and the change-of-variables induced by $z = (x-\\mu) \\oslash \\sigma$.\n\nProgram specification:\n- Implement a program that, for each test case below, computes three quantities:\n  (i) the $\\ell_\\infty$ norm (maximum absolute component) of the difference between your proposed standardized gradient attribution and the gradient attribution computed directly in the standardized space,\n  (ii) the $\\ell_\\infty$ norm of the difference between your proposed standardized input-times-gradient attribution and the input-times-gradient computed directly in the standardized space,\n  (iii) the $\\ell_\\infty$ norm of the difference between Integrated Gradients computed in input space and in standardized space.\n- For Integrated Gradients, implement the line integral numerically using the midpoint rule with $N$ equally spaced steps along the straight-line path from $x'$ to $x$. Use $N = 2000$.\n- The model $g$ is specified per test case. You must implement two forms:\n  (a) Linear: $g(z) = w^\\top z + b$, where $w \\in \\mathbb{R}^d$ and $b \\in \\mathbb{R}$.\n  (b) Single hidden layer with hyperbolic tangent: $g(z) = u^\\top \\tanh(W z + c)$, where $W \\in \\mathbb{R}^{m \\times d}$, $c \\in \\mathbb{R}^m$, $u \\in \\mathbb{R}^m$, and $\\tanh(\\cdot)$ is applied elementwise. The derivative of $\\tanh$ is $\\frac{d}{da}\\tanh(a) = 1 - \\tanh^2(a)$.\n\nTest Suite:\n- Test Case $1$ (linear, happy path):\n  - Dimension $d = 3$.\n  - $\\mu = [0.0, 0.0, 0.0]$, $\\sigma = [2.0, 0.5, 10.0]$.\n  - $w = [1.0, -3.0, 0.5]$, $b = 0.7$.\n  - Input $x = [1.0, -2.0, 0.3]$, baseline $x' = [0.0, 0.0, 0.0]$.\n- Test Case $2$ (nonlinear, coverage of differentiability):\n  - Dimension $d = 3$, hidden $m = 2$.\n  - $\\mu = [0.5, -1.0, 2.0]$, $\\sigma = [1.5, 0.8, 3.0]$.\n  - $W = \\begin{bmatrix} 0.2 & -0.1 & 0.4 \\\\ 1.0 & 0.5 & -0.3 \\end{bmatrix}$, $c = [0.1, -0.2]$, $u = [1.2, -0.7]$.\n  - Input $x = [2.0, -3.0, 4.5]$, baseline $x' = [0.0, 0.0, 0.0]$.\n- Test Case $3$ (nonlinear, edge case with extreme scaling and nonzero mean):\n  - Dimension $d = 3$, hidden $m = 4$.\n  - $\\mu = [-2.0, 0.5, 1.0]$, $\\sigma = [10^{-3}, 10^{3}, 1.0]$.\n  - $W = \\begin{bmatrix} -0.5 & 2.0 & 0.1 \\\\ 0.3 & -1.1 & 0.9 \\\\ 1.5 & 0.0 & -0.6 \\\\ -0.7 & 0.2 & 0.8 \\end{bmatrix}$, $c = [0.0, 0.1, -0.1, 0.2]$, $u = [0.5, -1.2, 0.3, 0.8]$.\n  - Input $x = [0.1, -0.2, 3.0]$, baseline $x' = [0.2, -0.1, 1.5]$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain $9$ floating-point numbers corresponding to the three quantities (i), (ii), (iii) in order for Test Cases $1$, $2$, and $3$ respectively. For example, the output format is $[r_1,r_2,r_3,r_4,r_5,r_6,r_7,r_8,r_9]$, where each $r_k$ is a floating-point number.\n- No physical units are involved. Angles, if any arise, must be in radians, but $\\tanh$ requires no angle units. Express all numerical results as floating-point numbers.",
            "solution": "The problem requires an analysis of how a feature standardization layer, $z = (x - \\mu) \\oslash \\sigma$, affects three gradient-based attribution methods. We must derive the relationships from first principles and propose standardized attributions that are invariant to the scaling parameter $\\sigma$.\n\nThe model is given by $f(x) = g(z(x))$, where $z(x) = (x - \\mu) \\oslash \\sigma$. The function $g(z)$ is a differentiable scalar function, and $x, \\mu, \\sigma \\in \\mathbb{R}^d$. The symbol $\\oslash$ denotes elementwise division and $\\odot$ denotes elementwise multiplication.\n\n### Task 1: Vanilla Gradient Attribution Analysis\n\nThe vanilla gradient attribution in the input space is defined as $A_{\\text{grad}}(x) = \\nabla_x f(x)$. Our objective is to relate this to the gradient attribution in the standardized space, $\\nabla_z g(z)$, and propose a standardized attribution $A_{\\text{grad}}^{\\text{std}}(x)$ that equals $\\nabla_z g(z)$.\n\nWe start by applying the chain rule to find the gradient of $f(x)$ with respect to $x_k$. The mapping from $x$ to $z$ is $z_j = (x_j - \\mu_j) / \\sigma_j$.\n$$\n\\frac{\\partial f}{\\partial x_k} = \\sum_{j=1}^d \\frac{\\partial g}{\\partial z_j} \\frac{\\partial z_j}{\\partial x_k}\n$$\nThe Jacobian of the transformation from $x$ to $z$ is a diagonal matrix, as each $z_j$ depends only on $x_j$. Specifically, $\\frac{\\partial z_j}{\\partial x_k} = \\delta_{jk} / \\sigma_j$, where $\\delta_{jk}$ is the Kronecker delta. The sum simplifies to a single term:\n$$\n\\frac{\\partial f}{\\partial x_k} = \\frac{\\partial g}{\\partial z_k} \\frac{\\partial z_k}{\\partial x_k} = \\frac{\\partial g}{\\partial z_k} \\frac{1}{\\sigma_k}\n$$\nIn vector notation, this relationship is:\n$$\nA_{\\text{grad}}(x) = \\nabla_x f(x) = \\nabla_z g(z) \\oslash \\sigma\n$$\nThe equation shows that the input-space gradient is the standardized-space gradient scaled elementwise by the inverse of the standard deviations $\\sigma$. To undo this scaling effect and recover the standardized-space gradient, we must multiply by $\\sigma$.\n\nWe define the standardized gradient attribution, $A_{\\text{grad}}^{\\text{std}}(x)$, as:\n$$\nA_{\\text{grad}}^{\\text{std}}(x) = A_{\\text{grad}}(x) \\odot \\sigma\n$$\nSubstituting the expression for $A_{\\text{grad}}(x)$, we verify that this definition achieves the desired result:\n$$\nA_{\\text{grad}}^{\\text{std}}(x) = (\\nabla_z g(z) \\oslash \\sigma) \\odot \\sigma = \\nabla_z g(z)\n$$\nThus, the correct standardized attribution is the input-space gradient elementwise multiplied by the standard deviation vector $\\sigma$.\n\n### Task 2: Input-times-Gradient Attribution Analysis\n\nThe input-times-gradient attribution in the input space is $A_{\\text{IGR}}(x) = x \\odot \\nabla_x f(x)$. The corresponding attribution in the standardized space is $z \\odot \\nabla_z g(z)$. We seek to define a standardized attribution $A_{\\text{IGR}}^{\\text{std}}(x)$ that equals the latter.\n\nLet's start from the target expression, $z \\odot \\nabla_z g(z)$, and express it in terms of input-space quantities. We substitute $z = (x - \\mu) \\oslash \\sigma$ and use the relation from Task 1, $\\nabla_z g(z) = \\nabla_x f(x) \\odot \\sigma$:\n$$\nz \\odot \\nabla_z g(z) = \\left( \\frac{x - \\mu}{\\sigma} \\right) \\odot (\\nabla_x f(x) \\odot \\sigma)\n$$\nThe elementwise operations $\\oslash \\sigma$ and $\\odot \\sigma$ cancel each other out, yielding:\n$$\nz \\odot \\nabla_z g(z) = (x - \\mu) \\odot \\nabla_x f(x)\n$$\nThis expression gives us the natural definition for the standardized input-times-gradient attribution:\n$$\nA_{\\text{IGR}}^{\\text{std}}(x) = (x - \\mu) \\odot \\nabla_x f(x)\n$$\nThis method can be interpreted as a \"centered-input-times-gradient\" attribution. It is invariant to the scaling $\\sigma$ and correctly corresponds to the input-times-gradient attribution computed in the standardized feature space.\n\n### Task 3: Integrated Gradients Analysis\n\nThe Integrated Gradients (IG) attribution for the $k$-th feature is defined by the path integral:\n$$\nA_{\\text{IG},k}(x;x') = (x_k - x'_k) \\int_0^1 \\frac{\\partial f(x' + \\alpha (x - x'))}{\\partial x_k} \\, d\\alpha\n$$\nLet's analyze the effect of the standardization layer by performing a change of variables. The straight-line path in the input space from a baseline $x'$ to an input $x$ is $\\gamma(\\alpha) = x' + \\alpha(x - x')$. The corresponding path in the standardized space, $\\tilde{\\gamma}(\\alpha)$, is:\n$$\n\\tilde{\\gamma}(\\alpha) = z(\\gamma(\\alpha)) = \\frac{(x' + \\alpha(x-x')) - \\mu}{\\sigma} = \\frac{x' - \\mu}{\\sigma} + \\alpha\\frac{x - x'}{\\sigma} = z' + \\alpha(z-z')\n$$\nwhere $z = (x-\\mu)\\oslash\\sigma$ and $z'=(x'-\\mu)\\oslash\\sigma$. This shows that a straight-line path in input space maps to a straight-line path in standardized space.\n\nNext, we relate the gradient components using the result from Task 1:\n$$\n\\frac{\\partial f(\\gamma(\\alpha))}{\\partial x_k} = \\frac{1}{\\sigma_k} \\frac{\\partial g(z(\\gamma(\\alpha)))}{\\partial z_k} = \\frac{1}{\\sigma_k} \\frac{\\partial g(\\tilde{\\gamma}(\\alpha))}{\\partial z_k}\n$$\nSubstituting this into the IG definition:\n$$\nA_{\\text{IG},k}(x;x') = (x_k - x'_k) \\int_0^1 \\frac{1}{\\sigma_k} \\frac{\\partial g(z' + \\alpha(z-z'))}{\\partial z_k} \\, d\\alpha\n$$\nWe can move the constant $1/\\sigma_k$ outside the integral and group it with the $(x_k - x'_k)$ term:\n$$\nA_{\\text{IG},k}(x;x') = \\left(\\frac{x_k - x'_k}{\\sigma_k}\\right) \\int_0^1 \\frac{\\partial g(z' + \\alpha(z-z'))}{\\partial z_k} \\, d\\alpha\n$$\nThe term in the parenthesis is simply the difference between the standardized feature components: $\\frac{x_k - x'_k}{\\sigma_k} = \\frac{(x_k - \\mu_k) - (x'_k - \\mu_k)}{\\sigma_k} = z_k - z'_k$.\nThe expression becomes:\n$$\nA_{\\text{IG},k}(x;x') = (z_k - z'_k) \\int_0^1 \\frac{\\partial g(z' + \\alpha(z-z'))}{\\partial z_k} \\, d\\alpha\n$$\nThis is precisely the definition of the $k$-th component of Integrated Gradients computed in the standardized space, $A_{\\text{IG, std. space}, k}(z;z')$. Therefore, we have shown that:\n$$\nA_{\\text{IG}}(x;x') = A_{\\text{IG, std. space}}(z;z')\n$$\nIntegrated Gradients is inherently invariant to per-feature affine transformations (like scaling and shifting) as long as the baseline is transformed consistently. Consequently, no additional standardization is required for the IG attribution itself; it automatically provides attributions that are consistent with the standardized space. The l-infinity norm of the difference between the two computations should be zero, up to numerical integration error.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes differences between standardized and standard-space attributions\n    for three attribution methods across three test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"d\": 3,\n            \"mu\": np.array([0.0, 0.0, 0.0]),\n            \"sigma\": np.array([2.0, 0.5, 10.0]),\n            \"model_type\": \"linear\",\n            \"w\": np.array([1.0, -3.0, 0.5]),\n            \"b\": 0.7,\n            \"x\": np.array([1.0, -2.0, 0.3]),\n            \"x_prime\": np.array([0.0, 0.0, 0.0]),\n        },\n        {\n            \"d\": 3, \"m\": 2,\n            \"mu\": np.array([0.5, -1.0, 2.0]),\n            \"sigma\": np.array([1.5, 0.8, 3.0]),\n            \"model_type\": \"nonlinear\",\n            \"W\": np.array([[0.2, -0.1, 0.4], [1.0, 0.5, -0.3]]),\n            \"c\": np.array([0.1, -0.2]),\n            \"u\": np.array([1.2, -0.7]),\n            \"x\": np.array([2.0, -3.0, 4.5]),\n            \"x_prime\": np.array([0.0, 0.0, 0.0]),\n        },\n        {\n            \"d\": 3, \"m\": 4,\n            \"mu\": np.array([-2.0, 0.5, 1.0]),\n            \"sigma\": np.array([1e-3, 1e3, 1.0]),\n            \"model_type\": \"nonlinear\",\n            \"W\": np.array([[-0.5, 2.0, 0.1], [0.3, -1.1, 0.9], [1.5, 0.0, -0.6], [-0.7, 0.2, 0.8]]),\n            \"c\": np.array([0.0, 0.1, -0.1, 0.2]),\n            \"u\": np.array([0.5, -1.2, 0.3, 0.8]),\n            \"x\": np.array([0.1, -0.2, 3.0]),\n            \"x_prime\": np.array([0.2, -0.1, 1.5]),\n        }\n    ]\n\n    results = []\n    N = 2000\n\n    for case in test_cases:\n        x = case[\"x\"]\n        x_prime = case[\"x_prime\"]\n        mu = case[\"mu\"]\n        sigma = case[\"sigma\"]\n\n        if case[\"model_type\"] == \"linear\":\n            w = case[\"w\"]\n            \n            def grad_z_g(Z):\n                # Z is a matrix of inputs of shape (d, num_points)\n                num_points = Z.shape[1] if Z.ndim > 1 else 1\n                return np.tile(w[:, np.newaxis], (1, num_points))\n\n        elif case[\"model_type\"] == \"nonlinear\":\n            W = case[\"W\"]\n            c = case[\"c\"]\n            u = case[\"u\"]\n                \n            def grad_z_g(Z):\n                # Z is a matrix of inputs of shape (d, num_points)\n                A = W @ Z + c[:, np.newaxis]\n                H = np.tanh(A)\n                # V is of shape (m, num_points)\n                V = u[:, np.newaxis] * (1 - H**2)\n                # W.T is (d,m), so result is (d, num_points)\n                return W.T @ V\n        \n        # Standardized space vectors\n        z = (x - mu) / sigma\n        z_prime = (x_prime - mu) / sigma\n\n        # Reshape for batch-compatible gradient function\n        _z_reshaped = z.reshape(-1, 1)\n        \n        # (i) Vanilla Gradient Attribution\n        # grad_z is (d,), grad_x is (d,), A_grad_std is (d,)\n        grad_z = grad_z_g(_z_reshaped).flatten()\n        grad_x = grad_z / sigma\n        A_grad_std = grad_x * sigma\n        err1 = np.linalg.norm(A_grad_std - grad_z, ord=np.inf)\n        results.append(err1)\n        \n        # (ii) Input-times-Gradient Attribution\n        # All vectors are (d,)\n        A_IGR_in_z_space = z * grad_z\n        A_IGR_std = (x - mu) * grad_x\n        err2 = np.linalg.norm(A_IGR_std - A_IGR_in_z_space, ord=np.inf)\n        results.append(err2)\n\n        # (iii) Integrated Gradients Attribution\n        alphas = (np.arange(N) + 0.5) / N\n\n        # IG in input space (x)\n        x_path_points = x_prime[:, np.newaxis] + (x - x_prime)[:, np.newaxis] * alphas\n        z_path_from_x = (x_path_points - mu[:, np.newaxis]) / sigma[:, np.newaxis]\n        \n        grads_z_on_x_path = grad_z_g(z_path_from_x)\n        grads_x_on_x_path = grads_z_on_x_path / sigma[:, np.newaxis]\n        \n        avg_grad_x = np.mean(grads_x_on_x_path, axis=1)\n        A_IG_x = (x - x_prime) * avg_grad_x\n\n        # IG in standardized space (z)\n        z_path_points = z_prime[:, np.newaxis] + (z - z_prime)[:, np.newaxis] * alphas\n        \n        grads_z_on_z_path = grad_z_g(z_path_points)\n        \n        avg_grad_z = np.mean(grads_z_on_z_path, axis=1)\n        A_IG_z = (z - z_prime) * avg_grad_z\n\n        err3 = np.linalg.norm(A_IG_x - A_IG_z, ord=np.inf)\n        results.append(err3)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once we have methods for generating explanations, we must ask: how trustworthy are they? This advanced practice explores the fragility of attribution methods through the lens of adversarial attacks, where the goal is to create a tiny, imperceptible perturbation to an input that dramatically changes its attribution map while leaving the model's prediction nearly unchanged. By implementing an optimization-based attack , you will gain critical insight into the robustness of popular explanation techniques and the ongoing challenge of developing truly reliable interpretability tools.",
            "id": "3150456",
            "problem": "You must write a complete and runnable program that constructs adversarial explainer attacks to change an attribution map while approximately keeping the model output fixed, and then measures the attackability of different explanation methods. The context is a deterministic, fully specified scalar-output neural network. The program must implement the network, three attribution methods, a constrained optimization to perturb the input, and a quantitative metric of attackability. The final output must be a single line containing a list of floating-point values, one per test case, representing the measured attackability in the specified order.\n\nThe model is a two-layer fully connected network with hyperbolic tangent nonlinearity. Let the input dimension be $d = 5$ and the hidden dimension be $h = 3$. The model is\n$$\nf(\\mathbf{x}) = \\mathbf{w}_2^\\top \\tanh(\\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1) + b_2,\n$$\nwith parameters\n$$\n\\mathbf{W}_1 = \\begin{bmatrix}\n0.8 & -0.4 & 0.1 & 0.0 & 0.5 \\\\\n-0.3 & 0.7 & -0.6 & 0.2 & -0.1 \\\\\n0.2 & 0.1 & 0.9 & -0.5 & 0.3\n\\end{bmatrix},\\quad\n\\mathbf{b}_1 = \\begin{bmatrix} 0.1 \\\\ -0.2 \\\\ 0.05 \\end{bmatrix},\\quad\n\\mathbf{w}_2 = \\begin{bmatrix} 0.6 \\\\ -0.4 \\\\ 0.3 \\end{bmatrix},\\quad\nb_2 = 0.0.\n$$\nFor any input $\\mathbf{x} \\in \\mathbb{R}^5$, denote by $\\nabla f(\\mathbf{x})$ the gradient of $f$ at $\\mathbf{x}$. The three explanation methods to be tested are defined as follows:\n- Gradient: $A_{\\mathrm{grad}}(\\mathbf{x}) = \\nabla f(\\mathbf{x})$.\n- Gradient times input: $A_{\\mathrm{gxi}}(\\mathbf{x}) = \\mathbf{x} \\odot \\nabla f(\\mathbf{x})$, where $\\odot$ denotes the element-wise (Hadamard) product.\n- Integrated Gradients (baseline $\\mathbf{0}$): with a positive integer parameter $m$, define\n$$\nA_{\\mathrm{ig}}(\\mathbf{x}; m) \\approx \\mathbf{x} \\odot \\left(\\frac{1}{m} \\sum_{k=1}^{m} \\nabla f\\!\\left(\\alpha_k \\mathbf{x}\\right)\\right), \\quad \\alpha_k = \\frac{k}{m}.\n$$\n\nThe adversarial explainer attack is formulated as follows. For a fixed input $\\mathbf{x}$ and a fixed explanation method $A$, choose a perturbation $\\boldsymbol{\\delta}$ to minimize the similarity between $A(\\mathbf{x} + \\boldsymbol{\\delta})$ and $A(\\mathbf{x})$ while keeping $f(\\mathbf{x} + \\boldsymbol{\\delta})$ close to $f(\\mathbf{x})$ and obeying a bound on $\\|\\boldsymbol{\\delta}\\|_\\infty$. Let the cosine similarity be\n$$\ns(\\mathbf{u}, \\mathbf{v}) = \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle}{\\|\\mathbf{u}\\|_2 \\, \\|\\mathbf{v}\\|_2 + 10^{-12}}.\n$$\nDefine the attack loss\n$$\n\\mathcal{L}(\\boldsymbol{\\delta}; \\mathbf{x}, A) = s\\!\\left(A(\\mathbf{x} + \\boldsymbol{\\delta}), A(\\mathbf{x})\\right) + \\lambda \\left(f(\\mathbf{x} + \\boldsymbol{\\delta}) - f(\\mathbf{x})\\right)^2,\n$$\nwith penalty weight $\\lambda > 0$, subject to $\\|\\boldsymbol{\\delta}\\|_\\infty \\le \\varepsilon$. The attackability of method $A$ at $\\mathbf{x}$ under budget $\\varepsilon$ is measured as\n$$\n\\mathrm{Attackability} = 1 - s\\!\\left(A(\\mathbf{x} + \\boldsymbol{\\delta}^\\star), A(\\mathbf{x})\\right),\n$$\nwhere $\\boldsymbol{\\delta}^\\star$ approximately minimizes $\\mathcal{L}$ under the $\\ell_\\infty$ constraint.\n\nYour program must:\n- Implement $f(\\mathbf{x})$ and $\\nabla f(\\mathbf{x})$ exactly for the above network.\n- Implement $A_{\\mathrm{grad}}$, $A_{\\mathrm{gxi}}$, and $A_{\\mathrm{ig}}$ as defined above. For $A_{\\mathrm{ig}}$, use a Riemann sum with a given $m$.\n- Optimize $\\boldsymbol{\\delta}$ using projected gradient descent on $\\mathcal{L}$ with respect to $\\boldsymbol{\\delta}$, using central finite differences to approximate the gradient with respect to $\\boldsymbol{\\delta}$. Use a central finite difference step size $h = 10^{-4}$. Perform $T$ iterations with step size $\\eta = 0.2 \\varepsilon$. After each gradient step and projection onto the $\\ell_\\infty$ ball of radius $\\varepsilon$, apply a scalar output-preservation correction using a first-order local linearization:\n$$\n\\boldsymbol{\\delta} \\leftarrow \\boldsymbol{\\delta} - \\frac{f(\\mathbf{x} + \\boldsymbol{\\delta}) - f(\\mathbf{x})}{\\|\\nabla f(\\mathbf{x})\\|_2^2 + 10^{-12}} \\, \\nabla f(\\mathbf{x}),\n$$\nfollowed by reprojection onto the $\\ell_\\infty$ ball. Initialize $\\boldsymbol{\\delta} = \\mathbf{0}$. Use $T = 60$ and $\\lambda = 50.0$.\n- Report the attackability as defined above for each test case, in the specified order.\n\nTest suite. For each case, you are given the explanation method $A$, the input $\\mathbf{x}$, the perturbation budget $\\varepsilon$, and, when applicable, the integrated gradients step count $m$. The five test cases are:\n- Case $1$: $A = A_{\\mathrm{grad}}$, $\\mathbf{x} = \\begin{bmatrix} 0.5 \\\\ -0.3 \\\\ 0.1 \\\\ 0.2 \\\\ 0.0 \\end{bmatrix}$, $\\varepsilon = 0.05$.\n- Case $2$: $A = A_{\\mathrm{gxi}}$, $\\mathbf{x} = \\begin{bmatrix} -0.1 \\\\ 0.4 \\\\ 0.0 \\\\ -0.3 \\\\ 0.2 \\end{bmatrix}$, $\\varepsilon = 0.05$.\n- Case $3$: $A = A_{\\mathrm{ig}}$ with $m = 50$, $\\mathbf{x} = \\begin{bmatrix} 0.2 \\\\ -0.2 \\\\ 0.3 \\\\ -0.1 \\\\ 0.1 \\end{bmatrix}$, $\\varepsilon = 0.05$.\n- Case $4$: $A = A_{\\mathrm{grad}}$, $\\mathbf{x} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\\\ 0.0 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}$, $\\varepsilon = 0.0$.\n- Case $5$: $A = A_{\\mathrm{ig}}$ with $m = 20$, $\\mathbf{x} = \\begin{bmatrix} 0.7 \\\\ -0.5 \\\\ 0.2 \\\\ 0.0 \\\\ -0.1 \\end{bmatrix}$, $\\varepsilon = 0.2$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above:\n$$\n[\\mathrm{Attackability}_1,\\mathrm{Attackability}_2,\\mathrm{Attackability}_3,\\mathrm{Attackability}_4,\\mathrm{Attackability}_5].\n$$\nEach $\\mathrm{Attackability}_i$ must be a floating-point number. No other text should be printed.",
            "solution": "The user has provided a well-defined computational problem concerning the adversarial attacking of explanation methods for a neural network. I will first formally restate the problem's components and then detail the algorithmic procedure for its solution.\n\nThe problem is valid as it is scientifically grounded in the domain of trustworthy machine learning, mathematically well-posed, and all parameters and procedures are specified without ambiguity.\n\n### Mathematical and Algorithmic Specification\n\nThe core of the problem involves a fully specified, deterministic neural network, several attribution methods for explaining its predictions, and an optimization procedure to find an adversarial perturbation that minimally changes the model's output while maximally altering its explanation.\n\n**1. Neural Network Model**\n\nThe model is a two-layer fully connected network that maps an input vector $\\mathbf{x} \\in \\mathbb{R}^d$ to a scalar output $f(\\mathbf{x}) \\in \\mathbb{R}$, where the input dimension is $d=5$ and the hidden layer has $h=3$ neurons. The model is defined as:\n$$\nf(\\mathbf{x}) = \\mathbf{w}_2^\\top \\tanh(\\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1) + b_2\n$$\nThe parameters are given as:\n- Weight matrix for the first layer: $\\mathbf{W}_1 \\in \\mathbb{R}^{h \\times d}$\n- Bias vector for the first layer: $\\mathbf{b}_1 \\in \\mathbb{R}^h$\n- Weight vector for the output layer: $\\mathbf{w}_2 \\in \\mathbb{R}^h$\n- Bias for the output layer: $b_2 \\in \\mathbb{R}$\n\nThe activation function for the hidden layer is the hyperbolic tangent, $\\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$.\n\n**2. Model Gradient**\n\nTo implement the specified attribution methods and the attack procedure, the gradient of the model output with respect to the input, $\\nabla f(\\mathbf{x})$, is required. Using the chain rule of calculus, we can derive an analytical expression for this gradient. Let $\\mathbf{z}(\\mathbf{x}) = \\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1$ be the pre-activation of the hidden layer and $\\mathbf{h}(\\mathbf{x}) = \\tanh(\\mathbf{z}(\\mathbf{x}))$ be the post-activation. The derivative of the $\\tanh$ function is $\\frac{d}{dz}\\tanh(z) = 1 - \\tanh^2(z)$.\n\nThe gradient is then:\n$$\n\\nabla f(\\mathbf{x}) = \\frac{\\partial f}{\\partial \\mathbf{x}} = \\frac{\\partial f}{\\partial \\mathbf{h}} \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{z}} \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}}\n$$\nEach term is a Jacobian matrix:\n- $\\frac{\\partial f}{\\partial \\mathbf{h}} = \\mathbf{w}_2^\\top$\n- $\\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{z}} = \\mathrm{diag}(1 - \\tanh^2(\\mathbf{z}))$, where $\\mathrm{diag}(\\cdot)$ creates a diagonal matrix.\n- $\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}} = \\mathbf{W}_1$\n\nCombining these yields the gradient vector:\n$$\n\\nabla f(\\mathbf{x}) = \\mathbf{W}_1^\\top \\left( \\mathbf{w}_2 \\odot (1 - \\tanh^2(\\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1)) \\right)\n$$\nwhere $\\odot$ denotes the element-wise (Hadamard) product.\n\n**3. Attribution Methods**\n\nThree attribution (explanation) methods are to be evaluated, each producing an attribution map $A(\\mathbf{x}) \\in \\mathbb{R}^d$:\n- **Gradient**: The attribution is simply the gradient of the output with respect to the input.\n  $$\n  A_{\\mathrm{grad}}(\\mathbf{x}) = \\nabla f(\\mathbf{x})\n  $$\n- **Gradient-times-Input**: The attribution is the element-wise product of the input and the gradient.\n  $$\n  A_{\\mathrm{gxi}}(\\mathbf{x}) = \\mathbf{x} \\odot \\nabla f(\\mathbf{x})\n  $$\n- **Integrated Gradients (IG)**: This method computes the average gradient along the straight-line path from a baseline (here, the zero vector $\\mathbf{0}$) to the input $\\mathbf{x}$, and then multiplies by the input. The integral is approximated by a finite Riemann sum with $m$ steps.\n  $$\n  A_{\\mathrm{ig}}(\\mathbf{x}; m) \\approx \\mathbf{x} \\odot \\left(\\frac{1}{m} \\sum_{k=1}^{m} \\nabla f\\!\\left(\\alpha_k \\mathbf{x}\\right)\\right), \\quad \\text{where } \\alpha_k = \\frac{k}{m}\n  $$\n\n**4. Adversarial Attack Formulation**\n\nThe goal is to find a small perturbation $\\boldsymbol{\\delta}$ that, when added to an input $\\mathbf{x}$, changes the resulting attribution map $A(\\mathbf{x}+\\boldsymbol{\\delta})$ as much as possible, while keeping the model output $f(\\mathbf{x}+\\boldsymbol{\\delta})$ close to the original output $f(\\mathbf{x})$. This is formulated as a constrained optimization problem.\n\nThe change in attribution is measured by minimizing the cosine similarity between the original and perturbed attribution maps:\n$$\ns(\\mathbf{u}, \\mathbf{v}) = \\frac{\\mathbf{u}^\\top \\mathbf{v}}{\\|\\mathbf{u}\\|_2 \\, \\|\\mathbf{v}\\|_2 + \\epsilon_{\\text{cos}}}\n$$\nwhere $\\epsilon_{\\text{cos}} = 10^{-12}$ is a small constant for numerical stability.\n\nThe objective is to find $\\boldsymbol{\\delta}^\\star$ that minimizes the following loss function:\n$$\n\\mathcal{L}(\\boldsymbol{\\delta}; \\mathbf{x}, A) = s\\!\\left(A(\\mathbf{x} + \\boldsymbol{\\delta}), A(\\mathbf{x})\\right) + \\lambda \\left(f(\\mathbf{x} + \\boldsymbol{\\delta}) - f(\\mathbf{x})\\right)^2\n$$\nsubject to the constraint $\\|\\boldsymbol{\\delta}\\|_\\infty \\le \\varepsilon$, where $\\varepsilon$ is the perturbation budget. The hyperparameter $\\lambda=50.0$ balances the two objectives.\n\n**5. Optimization Algorithm**\n\nThe problem specifies an iterative algorithm to find an approximate minimizer $\\boldsymbol{\\delta}^\\star$. The algorithm is Projected Gradient Descent (PGD), augmented with a specialized correction step.\n\nStarting with $\\boldsymbol{\\delta}_0 = \\mathbf{0}$, the algorithm iterates for $T=60$ steps. In each step $t$:\n1.  **Gradient Calculation**: The gradient of the loss with respect to the perturbation, $\\nabla_{\\boldsymbol{\\delta}} \\mathcal{L}(\\boldsymbol{\\delta}_t)$, is approximated using central finite differences with a step size of $h=10^{-4}$.\n    $$\n    [\\nabla_{\\boldsymbol{\\delta}} \\mathcal{L}]_i = \\frac{\\mathcal{L}(\\boldsymbol{\\delta}_t + h\\mathbf{e}_i) - \\mathcal{L}(\\boldsymbol{\\delta}_t - h\\mathbf{e}_i)}{2h}\n    $$\n    where $\\mathbf{e}_i$ is the $i$-th standard basis vector.\n2.  **PGD Step**: A gradient descent step is taken, and the result is projected onto the $\\ell_\\infty$-ball of radius $\\varepsilon$. The step size is $\\eta = 0.2\\varepsilon$.\n    $$\n    \\boldsymbol{\\delta}' = \\mathrm{Proj}_{\\|\\cdot\\|_\\infty \\le \\varepsilon} \\left( \\boldsymbol{\\delta}_t - \\eta \\nabla_{\\boldsymbol{\\delta}} \\mathcal{L}(\\boldsymbol{\\delta}_t) \\right)\n    $$\n    The projection operator is a simple element-wise clipping: $\\mathrm{Proj}_{\\|\\cdot\\|_\\infty \\le \\varepsilon}(\\mathbf{v})_i = \\mathrm{clip}(v_i, -\\varepsilon, \\varepsilon)$.\n3.  **Output Preservation Correction**: To further enforce the constraint on the model output, a correction is applied. This step projects $\\boldsymbol{\\delta}'$ towards the hyperplane that is tangent to the level set of $f$ at the original point $\\mathbf{x}$.\n    $$\n    \\boldsymbol{\\delta}'' = \\boldsymbol{\\delta}' - \\frac{f(\\mathbf{x} + \\boldsymbol{\\delta}') - f(\\mathbf{x})}{\\|\\nabla f(\\mathbf{x})\\|_2^2 + \\epsilon_{\\text{num}}} \\, \\nabla f(\\mathbf{x})\n    $$\n    where $\\epsilon_{\\text{num}} = 10^{-12}$ for stability. Note the use of the pre-computed gradient $\\nabla f(\\mathbf{x})$.\n4.  **Re-projection**: The perturbation is projected back into the $\\ell_\\infty$-ball after the correction step.\n    $$\n    \\boldsymbol{\\delta}_{t+1} = \\mathrm{Proj}_{\\|\\cdot\\|_\\infty \\le \\varepsilon} ( \\boldsymbol{\\delta}'' )\n    $$\n\nThe final perturbation after $T$ iterations is denoted $\\boldsymbol{\\delta}^\\star$.\n\n**6. Attackability Metric**\n\nThe success of the attack is quantified by the \"Attackability\" metric, which measures the drop in cosine similarity:\n$$\n\\mathrm{Attackability} = 1 - s\\!\\left(A(\\mathbf{x} + \\boldsymbol{\\delta}^\\star), A(\\mathbf{x})\\right)\n$$\nA value close to $1$ indicates a highly successful attack (low final similarity), while a value close to $0$ indicates failure (high final similarity). For the trivial case where $\\varepsilon=0$, $\\boldsymbol{\\delta}^\\star=\\mathbf{0}$, and the attackability is $0$.\n\nThe program will implement this entire pipeline and compute the attackability for the five specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs adversarial explainer attacks and measures the attackability\n    of different attribution methods on a specified neural network.\n    \"\"\"\n\n    # --- Model and Attack Parameters ---\n    W1 = np.array([\n        [0.8, -0.4, 0.1, 0.0, 0.5],\n        [-0.3, 0.7, -0.6, 0.2, -0.1],\n        [0.2, 0.1, 0.9, -0.5, 0.3]\n    ])\n    b1 = np.array([0.1, -0.2, 0.05])\n    w2 = np.array([0.6, -0.4, 0.3])\n    b2 = 0.0\n\n    # Optimization hyperparameters\n    LAMBDA = 50.0\n    T = 60\n    H_FD = 1e-4  # Finite difference step\n    EPS_NUM = 1e-12 # Numerical stability constant\n\n    # --- Core Functions ---\n\n    def f(x_in):\n        \"\"\"Computes the model's scalar output f(x).\"\"\"\n        z = W1 @ x_in + b1\n        h = np.tanh(z)\n        return w2 @ h + b2\n\n    def grad_f(x_in):\n        \"\"\"Computes the gradient of the model output w.r.t. the input x.\"\"\"\n        z = W1 @ x_in + b1\n        tanh_z = np.tanh(z)\n        # Derivative of tanh is 1 - tanh^2\n        d_tanh_dz = 1.0 - tanh_z**2\n        # Chain rule: grad = W1.T @ (d_f_dh * d_h_dz)\n        # d_f_dh = w2, d_h_dz is diagonal\n        v = w2 * d_tanh_dz\n        return W1.T @ v\n\n    # --- Attribution Methods ---\n    \n    def A_grad(x_in):\n        \"\"\"Gradient attribution method.\"\"\"\n        return grad_f(x_in)\n\n    def A_gxi(x_in):\n        \"\"\"Gradient-times-Input attribution method.\"\"\"\n        return x_in * grad_f(x_in)\n\n    def A_ig(x_in, m):\n        \"\"\"Integrated Gradients attribution method.\"\"\"\n        avg_grad = np.zeros_like(x_in, dtype=float)\n        if np.all(x_in == 0): # Handle zero input case\n            return avg_grad\n\n        for k in range(1, m + 1):\n            alpha_k = k / m\n            x_interp = alpha_k * x_in\n            avg_grad += grad_f(x_interp)\n        \n        avg_grad /= m\n        return x_in * avg_grad\n\n    # --- Attack Infrastructure ---\n    \n    def cosine_similarity(u, v):\n        \"\"\"Computes cosine similarity between two vectors.\"\"\"\n        dot_product = np.dot(u, v)\n        norm_u = np.linalg.norm(u)\n        norm_v = np.linalg.norm(v)\n        return dot_product / (norm_u * norm_v + EPS_NUM)\n\n    def find_delta_star(x_orig, method_name, epsilon, m=None):\n        \"\"\"\n        Finds the optimal perturbation delta_star using PGD.\n        \"\"\"\n        if epsilon == 0.0:\n            return np.zeros_like(x_orig)\n            \n        # Set up attribution function for this attack\n        if method_name == 'ig':\n            A_func = lambda y: A_ig(y, m)\n        elif method_name == 'gxi':\n            A_func = A_gxi\n        else: # 'grad'\n            A_func = A_grad\n\n        # Pre-compute target values that are constant in the loop\n        f_target = f(x_orig)\n        A_target = A_func(x_orig)\n        grad_f_x = grad_f(x_orig)\n        \n        delta = np.zeros_like(x_orig, dtype=float)\n        eta = 0.2 * epsilon\n\n        def loss_L(d_prime):\n            \"\"\"Calculates the attack loss for a given perturbation.\"\"\"\n            x_prime = x_orig + d_prime\n            A_prime = A_func(x_prime)\n            sim = cosine_similarity(A_prime, A_target)\n            f_penalty = (f(x_prime) - f_target)**2\n            return sim + LAMBDA * f_penalty\n\n        for _ in range(T):\n            # 1. Gradient of Loss w.r.t. delta (central finite differences)\n            grad_L_delta = np.zeros_like(delta, dtype=float)\n            for i in range(len(delta)):\n                d_plus = delta.copy()\n                d_minus = delta.copy()\n                d_plus[i] += H_FD\n                d_minus[i] -= H_FD\n                \n                L_plus = loss_L(d_plus)\n                L_minus = loss_L(d_minus)\n                grad_L_delta[i] = (L_plus - L_minus) / (2 * H_FD)\n\n            # 2. PGD step and projection onto L_inf ball\n            delta = delta - eta * grad_L_delta\n            delta = np.clip(delta, -epsilon, epsilon)\n            \n            # 3. Output preservation correction\n            f_current = f(x_orig + delta)\n            correction_numerator = f_current - f_target\n            correction_denominator = np.linalg.norm(grad_f_x)**2 + EPS_NUM\n            correction = (correction_numerator / correction_denominator) * grad_f_x\n            delta = delta - correction\n            \n            # 4. Re-projection onto L_inf ball\n            delta = np.clip(delta, -epsilon, epsilon)\n            \n        return delta\n\n    # --- Test Cases and Execution ---\n    test_cases = [\n        {'method': 'grad', 'x': np.array([0.5, -0.3, 0.1, 0.2, 0.0]), 'eps': 0.05, 'm': None},\n        {'method': 'gxi', 'x': np.array([-0.1, 0.4, 0.0, -0.3, 0.2]), 'eps': 0.05, 'm': None},\n        {'method': 'ig', 'x': np.array([0.2, -0.2, 0.3, -0.1, 0.1]), 'eps': 0.05, 'm': 50},\n        {'method': 'grad', 'x': np.array([0.0, 0.0, 0.0, 0.0, 0.0]), 'eps': 0.0, 'm': None},\n        {'method': 'ig', 'x': np.array([0.7, -0.5, 0.2, 0.0, -0.1]), 'eps': 0.2, 'm': 20},\n    ]\n\n    results = []\n    for case in test_cases:\n        method, x, eps, m_val = case['method'], case['x'], case['eps'], case['m']\n        \n        delta_star = find_delta_star(x, method, eps, m_val)\n\n        # Set up the attribution function to calculate final attackability\n        if method == 'ig':\n            A_func = lambda y: A_ig(y, m_val)\n        elif method == 'gxi':\n            A_func = A_gxi\n        else: # 'grad'\n            A_func = A_grad\n        \n        A_orig = A_func(x)\n        A_adv = A_func(x + delta_star)\n        \n        final_similarity = cosine_similarity(A_adv, A_orig)\n        attackability = 1.0 - final_similarity\n        \n        results.append(attackability)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}