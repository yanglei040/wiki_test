{
    "hands_on_practices": [
        {
            "introduction": "在神经架构搜索中，一个看似直接的方法是选择在训练集上表现最佳的架构。然而，当训练数据有限时，这种方法往往会选择过于复杂的模型，从而导致严重的过拟合。本练习将通过一个可控的模拟实验 ，揭示为什么单纯依赖训练精度是一个陷阱，并强调了可靠的性能评估策略在NAS中的重要性。",
            "id": "3158070",
            "problem": "要求您实现一个小型、完全可复现的模拟，以研究在有限训练数据下的神经架构搜索（NAS）。该问题关注的是，当训练样本数量较少时，在训练集上优化经验目标的NAS是否会隐式地偏爱过参数化的模型。请使用以下精确且自洽的设置。\n\n将架构空间定义为一组多项式模型，其次数参数为 $\\alpha \\in \\mathcal{A}$，每个模型使用特征映射 $\\phi_{\\alpha}(x) = \\left[x^{0}, x^{1}, \\dots, x^{\\alpha}\\right]$。将次数 $\\alpha$ 视为模型容量和可训练参数数量的代理指标。考虑一个有监督二元分类问题，其输入为 $x \\in [-1,1]$，标签为 $y \\in \\{0,1\\}$。数据从一个固定的、未知的目标函数生成，并带有加性高斯噪声：\n- 输入分布：$x \\sim \\mathrm{Uniform}([-1,1])$。\n- 潜在目标函数：$g(x) = \\sin(3\\pi x) + 0.2 x$。\n- 标签噪声：$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2})$，其中 $\\sigma = 0.35$。\n- 标签：$y = \\mathbb{1}\\{g(x) + \\varepsilon \\ge 0\\}$。\n\n对于给定的 $\\alpha$ 的训练规则是：拟合一个岭回归正则化的最小二乘预测器 $f_{\\alpha}(x) = w_{\\alpha}^{\\top}\\phi_{\\alpha}(x)$，该预测器最小化在大小为 $n$ 的训练集上的经验平方误差，岭惩罚项为 $\\lambda > 0$：\n$$\n\\hat{w}_{\\alpha} = \\arg\\min_{w} \\frac{1}{n}\\sum_{i=1}^{n} \\left(y_{i} - w^{\\top}\\phi_{\\alpha}(x_{i})\\right)^{2} + \\lambda \\lVert w \\rVert_{2}^{2}.\n$$\n使用闭式解\n$$\n\\hat{w}_{\\alpha} = (X_{\\alpha}^{\\top}X_{\\alpha} + \\lambda I)^{-1} X_{\\alpha}^{\\top} y,\n$$\n其中 $X_{\\alpha} \\in \\mathbb{R}^{n \\times (\\alpha+1)}$ 是设计矩阵，其行向量为 $\\phi_{\\alpha}(x_{i})^{\\top}$，$y \\in \\{0,1\\}^{n}$ 是标签向量。在评估时，通过在 $0.5$ 处进行阈值化，将预测结果转换为类别标签，即 $\\hat{y} = \\mathbb{1}\\{f_{\\alpha}(x) \\ge 0.5\\}$，并将准确率定义为正确分类点的比例。对于每个 $\\alpha$，定义泛化差距\n$$\n\\Delta(\\alpha) = A_{\\text{train}}(\\alpha) - A_{\\text{val}}(\\alpha),\n$$\n其中 $A_{\\text{train}}(\\alpha)$ 是训练准确率，$A_{\\text{val}}(\\alpha)$ 是在一个大型、留出的验证集上的准确率。\n\n基本原理：您的推理必须基于经验风险最小化（ERM）、泛化差距（定义为经验性能与总体性能之差）以及一个经过充分验证的观察，即当 $n$ 较小时，更高容量的模型可以拟合噪声，从而抬高 $A_{\\text{train}}$ 但不影响 $A_{\\text{val}}$。您不得假设任何捷径公式；所有步骤都必须从这些原则推导出来。\n\n实现细节和实验协议：\n- 架构集：$\\mathcal{A} = \\{1, 3, 5, 9, 13, 19, 27, 39\\}$。\n- 岭参数：$\\lambda = 10^{-6}$。\n- 训练数据来自一个大小为 $N_{\\text{pool}} = 4096$ 的固定数据池。使用单一随机种子 $s_{\\text{pool}} = 12345$ 一次性构建此池，然后通过对该池进行前缀子采样来形成训练集。这确保了小 $n$ 的集合嵌套在较大的集合中。也就是说，对于训练规模 $n$，使用池中的前 $n$ 个点。\n- 验证集：大小为 $V = 10000$，使用固定种子 $s_{\\text{val}} = 2025$ 独立抽取。\n- 模拟NAS的搜索规则，针对每个训练规模 $n$ 采用两种选择标准：\n  1. 训练集选择（代理驱动的NAS）：选择 $\\alpha_{\\text{train-sel}} \\in \\arg\\max_{\\alpha \\in \\mathcal{A}} A_{\\text{train}}(\\alpha)$。平局决胜规则：在最大化者中选择最大的 $\\alpha$。\n  2. 验证集选择（类似神谕的NAS）：选择 $\\alpha_{\\text{val-sel}} \\in \\arg\\max_{\\alpha \\in \\mathcal{A}} A_{\\text{val}}(\\alpha)$。平局决胜规则：在最大化者中选择最小的 $\\alpha$。\n- 待测试的训练规模（测试套件）：$n \\in \\{16, 64, 256, 1024\\}$。这些值分别探测了小样本、中等样本和较大样本的情况。\n\n您的程序必须：\n- 精确实现上述数据生成、训练、评估和选择过程。\n- 对于测试套件中的每个 $n$，计算并记录四元组 $[\\alpha_{\\text{train-sel}}, \\alpha_{\\text{val-sel}}, I, \\Delta(\\alpha_{\\text{train-sel}})]$，其中如果 $\\alpha_{\\text{train-sel}} > \\alpha_{\\text{val-sel}}$，则 $I = 1$，否则 $I = 0$，并且 $\\Delta(\\alpha_{\\text{train-sel}})$ 四舍五入到四位小数。\n- 使用无角度单位的设置；没有需要报告的物理单位。所有数值结果都是纯数字。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个结果列表，每个结果对应于指定顺序 $[16, 64, 256, 1024]$ 中的一个 $n$。每个结果本身必须是如上所述的四个数字的列表。例如，一个语法上有效的输出看起来像 $[[a_{1}, b_{1}, c_{1}, d_{1}], [a_{2}, b_{2}, c_{2}, d_{2}], [a_{3}, b_{3}, c_{3}, d_{3}], [a_{4}, b_{4}, c_{4}, d_{4}]]$, 其中 $a_{i}$ 和 $b_{i}$ 是 $\\mathcal{A}$ 中的整数，$c_{i}$ 是 $0$ 或 $1$，$d_{i}$ 是一个四舍五入到四位小数的浮点数。\n\n您必须通过您的实现，凭经验确定并报告对于每个 $n$：训练集选择的模型是否比验证集选择的模型更偏爱高容量，以及在该选择下过拟合差距 $\\Delta(\\alpha)$ 有多大。结果必须遵循上述确切的选择和平局决胜规则，使用上述确切的种子和样本大小，并且是可复现的。",
            "solution": "该问题陈述是有效的。它概述了一个定义明确的计算实验，用以研究机器学习和神经架构搜索（NAS）中的一个基本问题：当训练数据有限时，经验目标倾向于偏爱过于复杂的模型。该实验设置在科学上是合理的、完全指定的，并且在计算上是可行的。\n\n该问题的核心在于经验风险最小化（ERM）原则。在有监督学习中，目标是找到一个函数 $f$，使其最小化真实风险或期望损失 $R(f) = \\mathbb{E}_{(x,y) \\sim P}[L(f(x), y)]$，其中 $P$ 是真实数据分布。由于 $P$ 是未知的，我们转而最小化在训练集 $S = \\{(x_i, y_i)\\}_{i=1}^n$ 上的经验风险，即 $R_{\\text{emp}}(f) = \\frac{1}{n} \\sum_{i=1}^n L(f(x_i), y_i)$。该问题研究的是通过最小化经验风险选择的模型与真正泛化能力最好的模型之间的差异。\n\n该模拟通过以下方式来实施这项研究：\n\n1.  **架构空间与模型容量**：不同次数的多项式模型集合 $\\alpha \\in \\mathcal{A} = \\{1, 3, 5, 9, 13, 19, 27, 39\\}$，作为架构搜索空间。次数 $\\alpha$ 直接作为模型容量的代理指标，因为它决定了由 $\\phi_{\\alpha}(x) = [x^{0}, x^{1}, \\dots, x^{\\alpha}]$ 张成的特征空间的维度。更高的 $\\alpha$ 允许模型拟合更复杂的函数。\n\n2.  **数据生成**：数据从一个固定的、已知的过程中生成。输入 $x$ 从 $\\mathrm{Uniform}([-1,1])$ 中抽取。标签 $y \\in \\{0, 1\\}$ 由一个潜在函数 $g(x) = \\sin(3\\pi x) + 0.2 x$ 加上高斯噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$（其中 $\\sigma = 0.35$）决定。规则是 $y = \\mathbb{1}\\{g(x) + \\varepsilon \\ge 0\\}$。这种设置提供了一个可以客观衡量模型性能的基准真相，而噪声项 $\\varepsilon$ 为模型提供了过拟合的机会。\n\n3.  **作为ERM的训练**：对于给定的架构 $\\alpha$ 和大小为 $n$ 的训练集，通过最小化正则化的经验平方误差来找到权重 $w_{\\alpha}$：\n    $$\n    \\hat{w}_{\\alpha} = \\arg\\min_{w} \\frac{1}{n}\\sum_{i=1}^{n} \\left(y_{i} - w^{\\top}\\phi_{\\alpha}(x_{i})\\right)^{2} + \\lambda \\lVert w \\rVert_{2}^{2}\n    $$\n    这是一个带有岭回归正则化的经典ERM问题。小的正则化项 $\\lambda = 10^{-6}$ 确保了问题是适定的，特别是当特征数量 $(\\alpha+1)$ 大于样本数量 $n$ 时。指定的闭式解 $\\hat{w}_{\\alpha} = (X_{\\alpha}^{\\top}X_{\\alpha} + \\lambda I)^{-1} X_{\\alpha}^{\\top} y$ 是该优化问题的直接结果，其中 $X_{\\alpha}$ 是行向量为 $\\phi_{\\alpha}(x_i)^\\top$ 的设计矩阵。\n\n4.  **模拟NAS与评估泛化能力**：该实验针对不同的训练集大小 $n \\in \\{16, 64, 256, 1024\\}$ 模拟了两种NAS策略：\n    -   **训练集选择 ($\\alpha_{\\text{train-sel}}$)**：这模拟了一个实际的NAS场景，其中最佳架构是根据其在可用训练数据上的性能（$A_{\\text{train}}$）来选择的。这种选择基于真实目标的一个经验代理。平局决胜规则（选择最大的 $\\alpha$）反映了对复杂性的一种潜在隐式偏好。\n    -   **验证集选择 ($\\alpha_{\\text{val-sel}}$)**：这扮演了一个“神谕”的角色，通过选择在大型独立验证集上表现最佳的架构（$A_{\\text{val}}$）。这种选择被假定为接近于真正最小化泛化误差的选择。平局决胜规则（选择最小的 $\\alpha$）反映了对简单性的偏好（奥卡姆剃刀）。\n\n    中心假设是，对于较小的 $n$，训练数据包含抽样噪声，高容量模型可以轻易地拟合这些噪声。这将人为地抬高大 $\\alpha$ 的 $A_{\\text{train}}$，导致选择一个过于复杂的模型，即 $\\alpha_{\\text{train-sel}} > \\alpha_{\\text{val-sel}}$。这种现象被称为过拟合。泛化差距 $\\Delta(\\alpha) = A_{\\text{train}}(\\alpha) - A_{\\text{val}}(\\alpha)$ 量化了这种过拟合。$\\Delta(\\alpha_{\\text{train-sel}})$ 的一个大的正值表明，通过基于训练的代理选择的模型学习到了特定于训练集但不能泛化的模式。随着 $n$ 的增加，训练集变得更能代表真实分布，经验风险成为真实风险更可靠的代理，我们预期 $\\alpha_{\\text{train-sel}}$ 和 $\\alpha_{\\text{val-sel}}$ 会趋于一致，泛化差距也会减小。\n\n实现过程将如下进行：\n-   首先，将使用各自固定的随机种子 $s_{\\text{pool}}=12345$ 和 $s_{\\text{val}}=2025$ 一次性生成训练数据池（大小为 $N_{\\text{pool}}=4096$）和验证集（大小为 $V=10000$）。\n-   程序将遍历每个指定的训练规模 $n$。对于每个 $n$，将从池中取出前 $n$ 个样本构成训练集。\n-   在此循环内，将遍历每个架构次数 $\\alpha \\in \\mathcal{A}$。对于每个 $\\alpha$，它将：\n    1.  构建类范德蒙设计矩阵 $X_\\alpha$。\n    2.  求解线性系统 $(X_{\\alpha}^{\\top}X_{\\alpha} + \\lambda I) w = X_{\\alpha}^{\\top} y$ 以找到最优权重 $\\hat{w}_{\\alpha}$。\n    3.  在训练集和验证集上计算模型的预测值 $f_{\\alpha}(x) = X_{\\alpha} \\hat{w}_{\\alpha}$。\n    4.  应用 $0.5$ 的阈值得到二元标签 $\\hat{y} = \\mathbb{1}\\{f_{\\alpha}(x) \\ge 0.5\\}$。\n    5.  计算并存储训练准确率 $A_{\\text{train}}(\\alpha)$ 和验证准确率 $A_{\\text{val}}(\\alpha)$。\n-   在评估完给定 $n$ 的所有架构后，代码将通过找到存储准确率的最大值并应用指定的平局决胜规则来确定 $\\alpha_{\\text{train-sel}}$ 和 $\\alpha_{\\text{val-sel}}$。\n-   最后，它将计算指标 $I = \\mathbb{1}\\{\\alpha_{\\text{train-sel}} > \\alpha_{\\text{val-sel}}\\}$ 和泛化差距 $\\Delta(\\alpha_{\\text{train-sel}})$，四舍五入到四位小数。\n-   得到的结果四元组将被添加到一个列表中，最终输出将是包含所有测试的 $n$ 值的四元组列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a simulation to study Neural Architecture Search (NAS)\n    under limited training data.\n    \"\"\"\n    # Define experimental parameters from the problem statement.\n    ARCH_SET = [1, 3, 5, 9, 13, 19, 27, 39]\n    LAMBDA = 1e-6\n    N_POOL = 4096\n    S_POOL = 12345\n    V_SIZE = 10000\n    S_VAL = 2025\n    N_TEST_SUITE = [16, 64, 256, 1024]\n    NOISE_STD = 0.35\n\n    def g(x):\n        \"\"\"The latent target function.\"\"\"\n        return np.sin(3 * np.pi * x) + 0.2 * x\n\n    def generate_data(num_samples, seed):\n        \"\"\"Generates input-label pairs based on the problem's specification.\"\"\"\n        rng = np.random.default_rng(seed)\n        x = rng.uniform(-1, 1, size=num_samples)\n        epsilon = rng.normal(0, NOISE_STD, size=num_samples)\n        y = (g(x) + epsilon >= 0).astype(int)\n        return x, y\n\n    def evaluate_model(w, X, y_true):\n        \"\"\"Calculates model accuracy given weights, design matrix, and true labels.\"\"\"\n        y_pred_scores = X @ w\n        y_pred_labels = (y_pred_scores >= 0.5).astype(int)\n        return np.mean(y_pred_labels == y_true)\n\n    # Generate the fixed datasets for the experiment.\n    x_pool, y_pool = generate_data(N_POOL, S_POOL)\n    x_val, y_val = generate_data(V_SIZE, S_VAL)\n\n    # Pre-calculate validation design matrices for efficiency.\n    val_design_matrices = {\n        alpha: np.vander(x_val, N=alpha + 1, increasing=True)\n        for alpha in ARCH_SET\n    }\n\n    all_results = []\n    \n    # Iterate over the different training set sizes.\n    for n in N_TEST_SUITE:\n        x_train = x_pool[:n]\n        y_train = y_pool[:n]\n\n        train_accuracies = {}\n        val_accuracies = {}\n\n        # Iterate over all architectures (polynomial degrees).\n        for alpha in ARCH_SET:\n            # Create design matrix for the current training set and architecture.\n            X_train_alpha = np.vander(x_train, N=alpha + 1, increasing=True)\n            \n            # Train the ridge-regularized least-squares model using the closed-form solution.\n            d = alpha + 1\n            A = X_train_alpha.T @ X_train_alpha + LAMBDA * np.identity(d)\n            b = X_train_alpha.T @ y_train\n            try:\n                # Use np.linalg.solve for numerical stability.\n                w_alpha = np.linalg.solve(A, b)\n            except np.linalg.LinAlgError:\n                # Fallback to pseudoinverse if solve fails (unlikely with ridge penalty).\n                pinv_A = np.linalg.pinv(A)\n                w_alpha = pinv_A @ b\n\n            # Evaluate the trained model on both training and validation sets.\n            train_acc = evaluate_model(w_alpha, X_train_alpha, y_train)\n            train_accuracies[alpha] = train_acc\n\n            X_val_alpha = val_design_matrices[alpha]\n            val_acc = evaluate_model(w_alpha, X_val_alpha, y_val)\n            val_accuracies[alpha] = val_acc\n            \n        # 1. Selection based on training accuracy (proxy-driven NAS)\n        # Find max accuracy, handling potential float precision issues.\n        max_train_acc = max(train_accuracies.values())\n        best_train_alphas = [\n            alpha for alpha, acc in train_accuracies.items() if np.isclose(acc, max_train_acc)\n        ]\n        # Apply tie-breaking rule: pick the largest alpha.\n        alpha_train_sel = max(best_train_alphas)\n\n        # 2. Selection based on validation accuracy (oracle-like NAS)\n        # Find max accuracy.\n        max_val_acc = max(val_accuracies.values())\n        best_val_alphas = [\n            alpha for alpha, acc in val_accuracies.items() if np.isclose(acc, max_val_acc)\n        ]\n        # Apply tie-breaking rule: pick the smallest alpha.\n        alpha_val_sel = min(best_val_alphas)\n        \n        # Calculate indicator I for whether training-selected model is more complex.\n        I = 1 if alpha_train_sel > alpha_val_sel else 0\n        \n        # Calculate the generalization gap for the training-selected model.\n        # Delta(alpha) = A_train(alpha) - A_val(alpha)\n        delta = train_accuracies[alpha_train_sel] - val_accuracies[alpha_train_sel]\n        \n        # Assemble the quadruple of results for the current n.\n        result_for_n = [alpha_train_sel, alpha_val_sel, I, round(delta, 4)]\n        all_results.append(result_for_n)\n\n    # Format the final output as a string representing a list of lists.\n    # The string representation of each inner list will include spaces, e.g., '[1, 2, 3]'.\n    # Joining these with ',' and wrapping with '[]' matches the required format style.\n    # Example: [[list1], [list2]] -> \"[[1, 2, 3],[4, 5, 6]]\"\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n    \n    # Remove spaces to match the stricter template-based format.\n    final_output = output_str.replace(\" \", \"\")\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "面对庞大的搜索空间，可微神经架构搜索（Differentiable NAS）提供了一种高效的解决方案。本练习  将引导你实现其核心机制：使用温度控制的Sigmoid函数将离散的架构选择（如剪枝）松弛为连续门控值。通过梯度下降和退火策略，你将亲身体验如何将一个离散搜索问题转化为连续优化问题来求解。",
            "id": "3158131",
            "problem": "考虑一个神经架构搜索（NAS）问题，其中使用二元剪枝掩码来选择架构组件的一个子集。为了能够进行基于梯度的优化，通过温控 sigmoid 参数化 $m_\\ell(\\mathbf{z}, \\tau) = \\sigma\\!\\left(\\frac{z_\\ell}{\\tau}\\right)$，将每个二元掩码变量从 $m_\\ell \\in \\{0,1\\}$ 松弛为一个连续门 $m_\\ell \\in [0,1]$，其中 $\\sigma(u) = \\frac{1}{1 + e^{-u}}$，$\\mathbf{z} \\in \\mathbb{R}^L$ 是 logits 向量，$\\tau > 0$ 是一个温度参数。考虑复合目标\n$$\nJ(\\mathbf{z};\\tau) \\;=\\; -\\sum_{\\ell=1}^L b_\\ell \\, m_\\ell(\\mathbf{z}, \\tau) \\;+\\; \\lambda \\sum_{\\ell=1}^L \\big| m_\\ell(\\mathbf{z}, \\tau) \\big|,\n$$\n其中 $b_\\ell \\ge 0$ 模拟了保留组件 $\\ell$ 的效用，$\\lambda \\ge 0$ 通过对松弛掩码的 $\\ell_1$ 惩罚来控制稀疏性。这个设定抽象了验证性能贡献和稀疏性压力之间的权衡，是可微剪枝和神经架构搜索中一个常用的公式。\n\n从 sigmoid 函数和 $\\ell_1$ 范数的次梯度的定义出发，使用链式法则在 $\\mathbf{z}$ 上实现梯度下降，以计算 $\\nabla_{\\mathbf{z}} J(\\mathbf{z};\\tau)$。使用一个退火方案，乘法地降低温度 $\\tau$，直到达到一个最低温度。在每个温度水平上，使用固定的学习率对 $\\mathbf{z}$ 运行固定次数的梯度下降迭代。将 $\\mathbf{z}$ 初始化为零向量。\n\n定义松弛掩码到最近离散值的距离为 $d(x) = \\min\\{\\,|x-0|,\\;|x-1|\\,\\}$，对于 $x \\in [0,1]$。对于每个测试用例，在完成退火方案和梯度下降后，计算所有坐标上到离散值的最大距离，即 $\\max_{\\ell} d\\!\\left(m_\\ell(\\mathbf{z},\\tau_{\\text{final}})\\right)$，其中 $\\tau_{\\text{final}}$ 是你的方案所使用的最后一个温度。每个测试用例的这个单一实数将是需要报告的输出。\n\n你的程序必须以自包含的方式实现以下数值过程，并为所有列出的测试用例生成结果：\n\n- 在每个温度为 $\\tau$ 的退火阶段，更新过程使用学习率为 $\\eta$ 的梯度下降法对 $\\mathbf{z}$ 进行 $T$ 步更新。\n- 温度方案为 $\\tau_0, \\tau_1, \\dots$，其中 $\\tau_{k+1} = \\gamma \\, \\tau_k$，直到 $\\tau_K \\le \\tau_{\\min}$，其中 $0 < \\gamma < 1$。\n- $\\ell_1$ 项的次梯度使用如下：对于 $m_\\ell > 0$，取 $\\frac{\\partial}{\\partial m_\\ell} |m_\\ell| = 1$；在 $m_\\ell = 0$ 时，选择次梯度 $0$。这种选择产生了关于 $m_\\ell$ 的分段常数导数，并且与标准凸分析一致。\n- 为确保 $\\sigma\\!\\left(\\frac{z_\\ell}{\\tau}\\right)$ 的数值稳定性，在计算 sigmoid 时，你可以将 logits $z_\\ell$ 限制在一个有限范围内。\n\n测试套件：\n为以下四个测试用例提供输出。在每个案例中，维度是 $L$，效用向量是 $\\mathbf{b}$，稀疏性系数是 $\\lambda$，初始 logits 是 $\\mathbf{z}_0 = \\mathbf{0}$，初始温度是 $\\tau_0$，最低温度是 $\\tau_{\\min}$，乘法衰减因子是 $\\gamma$，每个温度的步数是 $T$，学习率是 $\\eta$。\n\n- 案例 1（偏好离散选择的理想路径）：\n  - $L = 5$\n  - $\\mathbf{b} = [\\,1.0,\\;0.3,\\;0.8,\\;0.49,\\;2.0\\,]$\n  - $\\lambda = 0.5$\n  - $\\tau_0 = 1.0$\n  - $\\tau_{\\min} = 10^{-3}$\n  - $\\gamma = 0.5$\n  - $T = 200$\n  - $\\eta = 0.5$\n\n- 案例 2（对所有 $\\ell$ 都有 $b_\\ell = \\lambda$ 的边界条件）：\n  - $L = 3$\n  - $\\mathbf{b} = [\\,0.5,\\;0.5,\\;0.5\\,]$\n  - $\\lambda = 0.5$\n  - $\\tau_0 = 1.0$\n  - $\\tau_{\\min} = 10^{-3}$\n  - $\\gamma = 0.5$\n  - $T = 200$\n  - $\\eta = 0.5$\n\n- 案例 3（无稀疏性压力）：\n  - $L = 4$\n  - $\\mathbf{b} = [\\,0.2,\\;0.1,\\;0.9,\\;1.5\\,]$\n  - $\\lambda = 0$\n  - $\\tau_0 = 1.0$\n  - $\\tau_{\\min} = 10^{-3}$\n  - $\\gamma = 0.5$\n  - $T = 200$\n  - $\\eta = 0.5$\n\n- 案例 4（强稀疏性与混合效用）：\n  - $L = 3$\n  - $\\mathbf{b} = [\\,0.1,\\;3.0,\\;1.9\\,]$\n  - $\\lambda = 2.0$\n  - $\\tau_0 = 1.0$\n  - $\\tau_{\\min} = 10^{-3}$\n  - $\\gamma = 0.5$\n  - $T = 200$\n  - $\\eta = 0.5$\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表顺序与测试用例相同，每个条目是为该案例计算的到离散值的最大距离（例如，像 \"[x1,x2,x3,x4]\" 这样的一行，其中每个 $x_i$ 是一个浮点数）。",
            "solution": "该问题要求在神经架构搜索（NAS）的背景下，为一个松弛的架构剪枝问题实现一个基于梯度的优化过程。我们被要求在退火方案结束后，找出最终松弛掩码到离散值的最大距离。这个问题有科学依据，定义明确，并且为确定性数值模拟提供了所有必要的参数。\n\n任务的核心是对 logits $\\mathbf{z}$ 执行梯度下降，以最小化目标函数 $J(\\mathbf{z};\\tau)$。目标函数由下式给出：\n$$\nJ(\\mathbf{z};\\tau) \\;=\\; -\\sum_{\\ell=1}^L b_\\ell \\, m_\\ell(\\mathbf{z}, \\tau) \\;+\\; \\lambda \\sum_{\\ell=1}^L \\big| m_\\ell(\\mathbf{z}, \\tau) \\big|\n$$\n其中 $m_\\ell(\\mathbf{z}, \\tau) = \\sigma(z_\\ell / \\tau)$ 是组件 $\\ell$ 的 sigmoid-松弛二元掩码，且 $\\sigma(u) = (1 + e^{-u})^{-1}$。参数 $b_\\ell \\ge 0$ 代表效用，$\\lambda \\ge 0$ 控制稀疏性。\n\n为了执行梯度下降，我们必须计算目标函数关于 logits 的梯度，$\\nabla_{\\mathbf{z}} J(\\mathbf{z};\\tau)$。目标函数是关于组件 $\\ell$ 的总和，而掩码 $m_\\ell$ 仅依赖于 logit $z_\\ell$。因此，梯度可以逐元素计算。关于单个 logit $z_\\ell$ 的偏导数可使用链式法则求得：\n$$\n\\frac{\\partial J}{\\partial z_\\ell} = \\frac{\\partial J}{\\partial m_\\ell} \\frac{\\partial m_\\ell}{\\partial z_\\ell}\n$$\n\n首先，我们计算 $J$ 关于掩码 $m_\\ell$ 的偏导数：\n$$\n\\frac{\\partial J}{\\partial m_\\ell} = \\frac{\\partial}{\\partial m_\\ell} \\left( -b_\\ell m_\\ell + \\lambda |m_\\ell| \\right) = -b_\\ell + \\lambda \\frac{\\partial |m_\\ell|}{\\partial m_\\ell}\n$$\n问题指定了绝对值项的次梯度。由于 sigmoid 函数的值域是 $(0, 1)$，所以 $m_\\ell$ 总是严格为正。因此，导数 $\\frac{\\partial |m_\\ell|}{\\partial m_\\ell}$ 明确为 $1$。这给出：\n$$\n\\frac{\\partial J}{\\partial m_\\ell} = -b_\\ell + \\lambda\n$$\n\n接下来，我们计算掩码 $m_\\ell$ 关于 logit $z_\\ell$ 的偏导数：\n$$\nm_\\ell(z_\\ell, \\tau) = \\sigma\\left(\\frac{z_\\ell}{\\tau}\\right)\n$$\n使用链式法则和已知的 sigmoid 函数导数 $\\sigma'(u) = \\sigma(u)(1 - \\sigma(u))$，我们得到：\n$$\n\\frac{\\partial m_\\ell}{\\partial z_\\ell} = \\sigma'\\left(\\frac{z_\\ell}{\\tau}\\right) \\cdot \\frac{\\partial}{\\partial z_\\ell}\\left(\\frac{z_\\ell}{\\tau}\\right) = \\sigma\\left(\\frac{z_\\ell}{\\tau}\\right)\\left(1 - \\sigma\\left(\\frac{z_\\ell}{\\tau}\\right)\\right) \\cdot \\frac{1}{\\tau} = \\frac{m_\\ell(1 - m_\\ell)}{\\tau}\n$$\n\n结合这些结果，目标函数关于 logit $z_\\ell$ 的偏导数是：\n$$\n\\frac{\\partial J}{\\partial z_\\ell} = (-b_\\ell + \\lambda) \\frac{m_\\ell(1 - m_\\ell)}{\\tau}\n$$\n完整的梯度向量 $\\nabla_{\\mathbf{z}} J$ 由每个 $\\ell = 1, \\dots, L$ 的这些偏导数组成。\n\n指定的数值过程如下：\n1. 初始化 logits $\\mathbf{z} = \\mathbf{0}$ 和温度 $\\tau = \\tau_0$。\n2. 进入一个退火循环，只要当前温度 $\\tau > \\tau_{\\min}$ 就继续。设 $\\tau_{\\text{final}}$ 为循环体执行时所用的最后一个温度值。\n3. 在退火循环内部，对于当前温度 $\\tau$，对 $\\mathbf{z}$ 执行 $T$ 步梯度下降：\n$$\n\\mathbf{z} \\leftarrow \\mathbf{z} - \\eta \\nabla_{\\mathbf{z}} J(\\mathbf{z};\\tau)\n$$\n其中 $\\eta$ 是学习率。\n4. 在 $T$ 步的内循环之后，为下一阶段更新温度：$\\tau \\leftarrow \\gamma \\tau$。\n5. 退火方案完成后，使用最终的 logit 向量 $\\mathbf{z}_{\\text{final}}$ 和最后使用的温度 $\\tau_{\\text{final}}$，计算最终的掩码值：\n$$\nm_{\\ell, \\text{final}} = \\sigma\\left(\\frac{z_{\\ell, \\text{final}}}{\\tau_{\\text{final}}}\\right)\n$$\n在实现过程中，为了在 $\\tau$ 很小时保持数值稳定性，$z_\\ell/\\tau$ 这个 sigmoid 函数的参数在绝对值上可能会变得非常大。`scipy.special.expit` 函数提供了一个数值上鲁棒的 sigmoid 实现，可以防止溢出/下溢问题，并在本解答中使用。\n\n最后，我们计算每个组件到离散值的距离，定义为 $d(x) = \\min(|x-0|, |x-1|)$，对于 $x \\in [0,1]$。由于 $m_{\\ell, \\text{final}} \\in (0,1)$，这可以简化为 $d(m_{\\ell, \\text{final}}) = \\min(m_{\\ell, \\text{final}}, 1 - m_{\\ell, \\text{final}})$。每个测试用例要报告的值是这些距离在所有组件 $\\ell$ 上的最大值：\n$$\n\\max_{\\ell} d(m_{\\ell, \\text{final}})\n$$\n对提供的四个测试用例均实现了此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path favoring discrete selections)\n        {\n            \"L\": 5,\n            \"b\": np.array([1.0, 0.3, 0.8, 0.49, 2.0]),\n            \"lambda\": 0.5,\n            \"tau0\": 1.0,\n            \"tau_min\": 1e-3,\n            \"gamma\": 0.5,\n            \"T\": 200,\n            \"eta\": 0.5,\n        },\n        # Case 2 (boundary condition where b_ell = lambda for all ell)\n        {\n            \"L\": 3,\n            \"b\": np.array([0.5, 0.5, 0.5]),\n            \"lambda\": 0.5,\n            \"tau0\": 1.0,\n            \"tau_min\": 1e-3,\n            \"gamma\": 0.5,\n            \"T\": 200,\n            \"eta\": 0.5,\n        },\n        # Case 3 (no sparsity pressure)\n        {\n            \"L\": 4,\n            \"b\": np.array([0.2, 0.1, 0.9, 1.5]),\n            \"lambda\": 0.0,\n            \"tau0\": 1.0,\n            \"tau_min\": 1e-3,\n            \"gamma\": 0.5,\n            \"T\": 200,\n            \"eta\": 0.5,\n        },\n        # Case 4 (strong sparsity with mixed utilities)\n        {\n            \"L\": 3,\n            \"b\": np.array([0.1, 3.0, 1.9]),\n            \"lambda\": 2.0,\n            \"tau0\": 1.0,\n            \"tau_min\": 1e-3,\n            \"gamma\": 0.5,\n            \"T\": 200,\n            \"eta\": 0.5,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation(\n            L=case[\"L\"],\n            b=case[\"b\"],\n            lambda_val=case[\"lambda\"],\n            tau0=case[\"tau0\"],\n            tau_min=case[\"tau_min\"],\n            gamma=case[\"gamma\"],\n            T=case[\"T\"],\n            eta=case[\"eta\"],\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(L, b, lambda_val, tau0, tau_min, gamma, T, eta):\n    \"\"\"\n    Runs the annealing and gradient descent procedure for a single test case.\n\n    Args:\n        L (int): Dimension of the logit vector.\n        b (np.ndarray): Utility vector.\n        lambda_val (float): Sparsity coefficient.\n        tau0 (float): Initial temperature.\n        tau_min (float): Minimum temperature for the schedule.\n        gamma (float): Multiplicative decay factor for temperature.\n        T (int): Number of gradient descent steps per temperature.\n        eta (float): Learning rate for gradient descent.\n\n    Returns:\n        float: The maximum distance to discreteness.\n    \"\"\"\n    z = np.zeros(L)\n    tau = tau0\n    tau_final = tau\n\n    # Annealing loop\n    while tau > tau_min:\n        tau_final = tau\n        # Gradient descent loop for the current temperature\n        for _ in range(T):\n            # Calculate relaxed masks m using a numerically stable sigmoid\n            # m_ell = sigma(z_ell / tau)\n            m = expit(z / tau)\n\n            # Calculate gradient of J w.r.t z\n            # dJ/dm_ell = -b_ell + lambda\n            dJ_dm = -b + lambda_val\n\n            # dm/dz_ell = m_ell * (1 - m_ell) / tau\n            dm_dz = (m * (1 - m)) / tau\n\n            # Gradient via chain rule: dJ/dz = dJ/dm * dm/dz\n            grad_z = dJ_dm * dm_dz\n\n            # Update logits using gradient descent\n            z = z - eta * grad_z\n        \n        # Anneal the temperature\n        tau *= gamma\n    \n    # After all optimization, calculate the final mask with the final z and tau_final\n    final_m = expit(z / tau_final)\n\n    # Calculate the distance to the nearest discrete value (0 or 1) for each component\n    # d(x) = min(|x-0|, |x-1|) which is min(x, 1-x) for x in [0,1]\n    distances = np.minimum(final_m, 1 - final_m)\n\n    # Return the maximum distance across all components\n    return np.max(distances)\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "优秀的架构设计是NAS成功的关键，而理解其背后的原理至关重要。本练习  将探讨为什么残差连接（skip connections）如此有效，帮助我们从“如何搜索”深入到“什么是好的架构”。你将通过推导并实现一个数学模型，来量化残差连接密度与网络可训练性之间的关系，从而加深对梯度传播问题的理解。",
            "id": "3158074",
            "problem": "在神经架构搜索 (NAS) 的背景下，考虑残差网络的设计。我们希望通过对跳跃密度及其对跨深度的梯度流的影响进行建模，来优化残差连接的模式。其目标是，通过对梯度范数进行有数学原理的近似，来确定在每一层包含残差跳跃连接的概率（视为一个密度参数）如何与网络的可训练性相关联。\n\n从以下基本依据和经过充分检验的事实出发：\n1. 深度网络的微分链式法则，其中通过一系列层的反向传播会以乘法方式复合雅可比矩阵。\n2. 算子范数的次乘性，它将乘积的范数上界确定为范数的乘积。\n3. 将残差层变换建模为恒等跳跃连接加上一个学习到的变换。当存在跳跃连接时，反向传播的梯度会通过恒等矩阵与局部雅可比矩阵之和的转置进行变换；而当不存在跳跃连接时，则仅通过雅可比矩阵的转置进行变换。\n4. 在各向同性假设以及层与跳跃决策之间相互独立的假设下，局部雅可比矩阵对梯度范数的影响可以近似为每层的一个标量增益随机变量。\n\n按如下方式对网络建模：\n- 网络共有 $D$ 层。在每一层 $l \\in \\{1,\\dots,D\\}$，跳跃连接以概率 $s \\in [0,1]$ 独立存在。\n- 在第 $l$ 层，局部雅可比矩阵对梯度范数的谱效应由一个标量随机变量 $a_l > 0$ 近似。假设 $\\{a_l\\}$ 是独立同分布的，并服从由 $\\mu \\in \\mathbb{R}$ 和 $\\tau > 0$ 参数化的对数正态分布，即 $\\ln a_l \\sim \\mathcal{N}(\\mu,\\tau^2)$。\n- 当存在跳跃连接时，每层的梯度范数乘子由算子 $I + J_l$ 近似；在各向同性和独立性假设下，使用基于算子 2-范数的三角不等式的标量近似，将该乘子表示为 $1 + a_l$。当不存在跳跃连接时，该乘子表示为 $a_l$。\n- 设输出层 $D$ 的梯度范数归一化为 $\\|g_D\\| = 1$。\n\n任务：\n1. 基于上述依据，仅依赖独立性假设和对数正态分布的性质，推导期望输入梯度范数 $\\mathbb{E}[\\|g_0\\|]$ 作为 $D$、$s$、$\\mu$ 和 $\\tau$ 的函数的闭式表达式。\n2. 定义一个可训练性准则：如果期望输入梯度范数位于闭区间 $[g_{\\text{lower}}, g_{\\text{upper}}]$ 内，其中 $g_{\\text{lower}} = 0.1$ 且 $g_{\\text{upper}} = 10.0$，则认为模型是可训练的。这些是无量纲量，必须作为小数处理，而不是百分比。\n3. 实现一个完整的、可运行的程序，该程序根据推导出的期望梯度范数，为每个测试用例计算布尔值的可训练性判定结果。\n\n使用以下参数值测试套件：\n- 测试 1：$D = 50$, $s = 0.2$, $\\mu = \\ln(0.8)$, $\\tau = 0.2$。\n- 测试 2：$D = 100$, $s = 0.0$, $\\mu = \\ln(0.95)$, $\\tau = 0.1$。\n- 测试 3：$D = 100$, $s = 0.9$, $\\mu = \\ln(0.8)$, $\\tau = 0.1$。\n- 测试 4：$D = 100$, $s = 0.05$, $\\mu = \\ln(0.95)$, $\\tau = 0.1$。\n- 测试 5：$D = 0$, $s = 0.5$, $\\mu = \\ln(0.9)$, $\\tau = 0.5$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表（例如：$[result_1,result_2,\\dots]$），其中每个 $result_i$ 是一个布尔值，指示该配置在所述准则下是否可训练。",
            "solution": "目标是为深度为 $D$ 的深度残差网络推导期望输入梯度范数 $\\mathbb{E}[\\|g_0\\|]$ 的闭式表达式，并用它来确定网络的可训练性。推导将基于问题陈述中提供的跳跃连接和局部雅可比效应的概率模型。\n\n设 $\\|g_l\\|$ 表示第 $l$ 层输出处的梯度向量范数，其中 $l$ 的范围从 $0$（网络输入）到 $D$（网络输出）。我们已知边界条件为输出层的梯度范数被归一化，即 $\\|g_D\\| = 1$。反向传播过程决定了梯度如何从第 $l$ 层演化到前一层 $l-1$。问题将此单步反向传播对梯度范数的影响建模为一个乘法标量因子 $M_l$。\n$$ \\|g_{l-1}\\| = M_l \\|g_l\\| $$\n从第 $D$ 层到第 $0$ 层递归地应用此关系，我们将输入梯度范数 $\\|g_0\\|$ 表示为这些乘子作用于初始梯度范数 $\\|g_D\\|$ 的乘积：\n$$ \\|g_0\\| = \\left( \\prod_{l=1}^{D} M_l \\right) \\|g_D\\| $$\n鉴于 $\\|g_D\\| = 1$，上式可简化为：\n$$ \\|g_0\\| = \\prod_{l=1}^{D} M_l $$\n每层 $l$ 的乘子 $M_l$ 是一个随机变量。其值取决于两个因素：是否存在跳跃连接，以及该层局部雅可比矩阵的谱效应。设 $S_l$ 是一个伯努利随机变量，如果存在跳跃连接，则 $S_l=1$，否则 $S_l=0$。问题陈述 $P(S_l=1) = s$ 且 $P(S_l=0) = 1-s$。雅可比矩阵对梯度范数的影响由一个标量随机变量 $a_l > 0$ 近似。\n\n根据问题描述：\n- 如果存在跳跃连接（$S_l=1$），则梯度范数乘子近似为 $1+a_l$。这是基于对恒等矩阵与局部雅可比矩阵之和的算子范数应用三角不等式，即 $\\|I+J_l\\| \\le \\|I\\| + \\|J_l\\| = 1+\\|J_l\\|$，然后用其标量近似 $a_l$ 替换 $\\|J_l\\|$。\n- 如果不存在跳跃连接（$S_l=0$），则乘子就是 $a_l$。\n\n我们可以将 $M_l$ 表示为包含 $S_l$ 和 $a_l$ 的单个代数表达式：\n$$ M_l = S_l \\cdot (1 + a_l) + (1 - S_l) \\cdot a_l = S_l + S_l a_l + a_l - S_l a_l = S_l + a_l $$\n我们的任务是求输入梯度范数的期望值 $\\mathbb{E}[\\|g_0\\|]$。使用 $\\|g_0\\|$ 的表达式：\n$$ \\mathbb{E}[\\|g_0\\|] = \\mathbb{E}\\left[ \\prod_{l=1}^{D} M_l \\right] $$\n问题陈述，每层的跳跃连接是独立选择的，并且雅可比效应 $\\{a_l\\}$ 是独立同分布 (i.i.d.) 的。此外，跳跃决策 $\\{S_l\\}$ 与雅可比效应 $\\{a_l\\}$ 无关。因此，对于 $l=1, \\dots, D$，乘子 $\\{M_l = S_l + a_l\\}$ 构成一组独立同分布的随机变量。对于独立的随机变量，其乘积的期望等于期望的乘积：\n$$ \\mathbb{E}\\left[ \\prod_{l=1}^{D} M_l \\right] = \\prod_{l=1}^{D} \\mathbb{E}[M_l] $$\n由于乘子 $\\{M_l\\}$ 是同分布的，它们的期望值相等。设 $\\mathbb{E}[M]$ 表示这个共同的期望值。该表达式简化为：\n$$ \\mathbb{E}[\\|g_0\\|] = (\\mathbb{E}[M])^D $$\n我们现在计算 $\\mathbb{E}[M]$。根据期望的线性性：\n$$ \\mathbb{E}[M] = \\mathbb{E}[S_l + a_l] = \\mathbb{E}[S_l] + \\mathbb{E}[a_l] $$\n伯努利随机变量 $S_l$ 的期望是其成功概率 $s$：\n$$ \\mathbb{E}[S_l] = 1 \\cdot P(S_l=1) + 0 \\cdot P(S_l=0) = s $$\n随机变量 $a_l$ 给定为服从对数正态分布，具体为 $\\ln a_l \\sim \\mathcal{N}(\\mu, \\tau^2)$。对于一个随机变量 $X$，其中 $\\ln X \\sim \\mathcal{N}(\\mu_{ln}, \\sigma_{ln}^2)$，其期望为 $\\mathbb{E}[X] = \\exp(\\mu_{ln} + \\sigma_{ln}^2/2)$。将此公式应用于参数为 $\\mu$ 和 $\\tau^2$ 的 $a_l$：\n$$ \\mathbb{E}[a_l] = \\exp\\left(\\mu + \\frac{\\tau^2}{2}\\right) $$\n将 $S_l$ 和 $a_l$ 的期望代回到 $\\mathbb{E}[M]$ 的表达式中：\n$$ \\mathbb{E}[M] = s + \\exp\\left(\\mu + \\frac{\\tau^2}{2}\\right) $$\n最后，我们得到期望输入梯度范数的闭式表达式：\n$$ \\mathbb{E}[\\|g_0\\|] = \\left(s + \\exp\\left(\\mu + \\frac{\\tau^2}{2}\\right)\\right)^D $$\n对于 $D=0$ 的特殊情况，该公式正确地得出 $\\mathbb{E}[\\|g_0\\|] = (\\dots)^0 = 1$，这对应于输入和输出相同的情况，因此 $\\|g_0\\|=\\|g_D\\|=1$。\n\n可训练性准则定义为期望输入梯度范数落在一个指定范围内：\n$$ g_{\\text{lower}} \\le \\mathbb{E}[\\|g_0\\|] \\le g_{\\text{upper}} $$\n其中 $g_{\\text{lower}} = 0.1$ 且 $g_{\\text{upper}} = 10.0$。我们将实现一个函数，使用推导出的公式计算 $\\mathbb{E}[\\|g_0\\|]$，并检查对于给定的测试用例，此条件是否成立。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the trainability decision for a series of neural network configurations.\n\n    The decision is based on a derived formula for the expected input gradient norm\n    in a residual network model.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test 1: (D=50, s=0.2, mu=ln(0.8), tau=0.2)\n        (50, 0.2, np.log(0.8), 0.2),\n        # Test 2: (D=100, s=0.0, mu=ln(0.95), tau=0.1)\n        (100, 0.0, np.log(0.95), 0.1),\n        # Test 3: (D=100, s=0.9, mu=ln(0.8), tau=0.1)\n        (100, 0.9, np.log(0.8), 0.1),\n        # Test 4: (D=100, s=0.05, mu=ln(0.95), tau=0.1)\n        (100, 0.05, np.log(0.95), 0.1),\n        # Test 5: (D=0, s=0.5, mu=ln(0.9), tau=0.5)\n        (0, 0.5, np.log(0.9), 0.5),\n    ]\n\n    # Trainability bounds\n    g_lower = 0.1\n    g_upper = 10.0\n\n    results = []\n    for case in test_cases:\n        D, s, mu, tau = case\n\n        # The derived formula for the expected input gradient norm is:\n        # E[||g_0||] = (s + exp(mu + tau^2 / 2))^D\n\n        # Handle the D=0 edge case directly for clarity and to avoid 0^0 issues,\n        # although Python's pow(x, 0) correctly returns 1.0.\n        if D == 0:\n            expected_grad_norm = 1.0\n        else:\n            # Calculate the expected value of the Jacobian gain 'a_l'.\n            # E[a_l] = exp(mu + tau^2 / 2)\n            E_a = np.exp(mu + (tau**2) / 2.0)\n\n            # Calculate the expected value of the per-layer multiplier 'M_l'.\n            # E[M_l] = s + E[a_l]\n            E_M = s + E_a\n\n            # Calculate the final expected input gradient norm.\n            # E[||g_0||] = (E[M_l])^D\n            expected_grad_norm = E_M**D\n\n        # Apply the trainability criterion.\n        is_trainable = g_lower = expected_grad_norm = g_upper\n        results.append(is_trainable)\n\n    # Format the final list of boolean results into the required string format.\n    # Note: str(True) -> \"True\", str(False) -> \"False\".\n    # The problem specifies boolean results, and this is the standard string representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}