{
    "hands_on_practices": [
        {
            "introduction": "本练习为理解领域偏移如何影响模型性能提供了基础。我们将利用一个可控的、解析性的场景，来量化协变量偏移（covariate shift）对使用批归一化（Batch Normalization, BN）的模型的具体影响。通过比较模型在使用源域统计数据与目标域统计数据时的风险，你将精确地体会到数据分布不匹配为何会导致性能下降 。",
            "id": "3117605",
            "problem": "要求您编写一个完整且可运行的程序，量化在测试时使用不同的批量归一化 (Batch Normalization, BN) 统计量如何影响偏移后目标域上的群体风险，以及输入白化变换是否能减轻这种影响。批量归一化 (BN) 在推理时应用逐特征的仿射变换 $$y_i = \\gamma_i \\frac{x_i - \\mu_i}{\\sqrt{\\sigma_i^2 + \\varepsilon}} + \\beta_i,$$ 其中 $x_i$ 是输入特征，$\\mu_i$ 和 $\\sigma_i$ 是归一化均值和标准差，$\\gamma_i$ 和 $\\beta_i$ 是学习到的缩放和平移参数。目标域上的群体风险定义为 $$R_T(f) = \\mathbb{E}_{(x,y) \\sim T}\\left[\\ell(f(x),y)\\right],$$ 其中损失函数为 $0$-$1$ 损失 $\\ell(\\hat{y},y)=\\mathbf{1}\\{\\hat{y}\\neq y\\}$。\n\n基本设定和假设：\n- 输入 $x \\in \\mathbb{R}^d$ 来自具有独立坐标的多元正态分布，且只有第一个坐标决定标签。具体来说，$$x_1 \\sim \\mathcal{N}(\\mu,\\sigma^2), \\quad x_j \\sim \\mathcal{N}(0,1) \\text{ for } j \\in \\{2,\\dots,d\\},$$ 各坐标之间相互独立。\n- 真实标签为 $$y = \\mathrm{sign}(x_1)$$，它以概率 $p \\in [0,1)$ 独立翻转（标签噪声），因此干净标签为 $y_{\\mathrm{clean}}=\\mathrm{sign}(x_1)$，观测到的标签以 $1-p$ 的概率为 $y=y_{\\mathrm{clean}}$，以 $p$ 的概率为 $y=-y_{\\mathrm{clean}}$。\n- 训练好的预测器是一个单层模型，它首先对每个特征应用带有参数 $(\\mu_{\\mathrm{used}},\\sigma_{\\mathrm{used}},\\gamma,\\beta)$ 的BN，然后对第一个归一化坐标应用单位权重、零偏置的分类器，$$f(x) = \\mathrm{sign}\\!\\left(\\gamma \\frac{x_1 - \\mu_{\\mathrm{used}}}{\\sigma_{\\mathrm{used}}} + \\beta\\right)$$ 我们考虑 $\\gamma=1$ 和 $\\beta=0$ 的特殊情况，此时分类器简化为 $$f(x)=\\mathrm{sign}\\!\\left(\\frac{x_1 - \\mu_{\\mathrm{used}}}{\\sigma_{\\mathrm{used}}}\\right) = \\mathrm{sign}(x_1 - \\mu_{\\mathrm{used}}),$$ 其中符号不受任何正数缩放的影响。因此，在原始特征轴上，有效决策阈值为 $\\tau=\\mu_{\\mathrm{used}}$。\n\n- 源域 $S$ 的参数为 $(\\mu_S,\\sigma_S)$。目标域 $T$ 的参数为 $(\\mu_T,\\sigma_T)$。在目标域上进行测试时，我们比较三种推理流程：\n  1. 冻结的BN (Frozen BN)：使用 $(\\mu_{\\mathrm{used}},\\sigma_{\\mathrm{used}}) = (\\mu_S,\\sigma_S)$，得到的决策为 $f_{\\mathrm{frozen}}(x) = \\mathrm{sign}(x_1 - \\mu_S)$。\n  2. 在T上更新的BN (Updated BN on $T$)：使用 $(\\mu_{\\mathrm{used}},\\sigma_{\\mathrm{used}}) = (\\mu_T,\\sigma_T)$，得到的决策为 $f_{\\mathrm{updated}}(x) = \\mathrm{sign}(x_1 - \\mu_T)$。\n  3. 白化后冻结BN (Whitening then Frozen BN)：应用一个逐特征的仿射映射，将目标域第一坐标的矩与源域对齐，$$x_1' = \\mu_S + \\frac{\\sigma_S}{\\sigma_T}(x_1 - \\mu_T),$$ 然后将 $x'$ 输入到使用 $(\\mu_S,\\sigma_S)$ 和相同 $(\\gamma,\\beta)=(1,0)$ 的冻结BN模型中。这种组合产生的有效决策与更新的BN相同，因为 $$f_{\\mathrm{whiten}\\to\\mathrm{frozen}}(x) = \\mathrm{sign}\\!\\left(\\frac{x_1' - \\mu_S}{\\sigma_S}\\right) = \\mathrm{sign}\\!\\left(\\frac{x_1 - \\mu_T}{\\sigma_T}\\right) = \\mathrm{sign}(x_1 - \\mu_T)$$。\n\n根据以上定义和 $x_1$ 的高斯模型，带有标签噪声 $p$ 和在 $x_1$ 上有阈值 $\\tau$ 的群体风险可以表示为 $$R_T(\\tau) = p + (1-2p)\\,\\mathbb{P}_{x_1 \\sim \\mathcal{N}(\\mu_T,\\sigma_T^2)}\\!\\left[\\mathrm{sign}(x_1)\\neq \\mathrm{sign}(x_1 - \\tau)\\right]$$ 不一致事件 $\\{\\mathrm{sign}(x_1)\\neq \\mathrm{sign}(x_1 - \\tau)\\}$ 恰好在 $x_1$ 位于 $0$ 和 $\\tau$ 之间时发生。因此，令 $\\Phi$ 表示标准正态累积分布函数，$$\\mathbb{P}\\!\\left[\\mathrm{sign}(x_1)\\neq \\mathrm{sign}(x_1 - \\tau)\\right] = \\left|\\Phi\\!\\left(\\frac{\\max\\{0,\\tau\\}-\\mu_T}{\\sigma_T}\\right) - \\Phi\\!\\left(\\frac{\\min\\{0,\\tau\\}-\\mu_T}{\\sigma_T}\\right)\\right|.$$\n\n您的程序必须：\n- 通过代入冻结BN的 $\\tau=\\mu_S$ 和更新的BN及白化后冻结BN的 $\\tau=\\mu_T$，使用上述公式和高斯累积分布函数，为这三种流程实现 $R_T(f)$ 的精确计算。\n- 使用下面的测试套件，计算每种情况下的三种风险，并将每个风险值四舍五入到 $6$ 位小数。\n\n所有测试中保持固定的参数：\n- 源域统计量 $(\\mu_S,\\sigma_S) = (\\,0.5,\\,1.0\\,)$。\n- 标签噪声 $p = 0.1$。\n- 维度 $d = 5$（只有第一个坐标影响标签；其他坐标是无关变量，并且是独立的标准正态分布，不影响计算）。\n\n测试套件（每个项目指定目标域的 $(\\mu_T,\\sigma_T)$）：\n- 情况A：$(\\,0.5,\\,1.0\\,)$。\n- 情况B：$(\\,0.0,\\,1.0\\,)$。\n- 情况C：$(\\,0.5,\\,0.5\\,)$。\n- 情况D：$(\\,-1.0,\\,2.0\\,)$。\n\n对于每种情况，按顺序 $[R_T(\\text{冻结BN}), R_T(\\text{更新BN}), R_T(\\text{白化}\\to\\text{冻结})]$ 输出一个包含三个浮点数的列表。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表，每个子列表对应一个测试用例，并用方括号括起来。例如，格式必须类似于 $[[r_{A,1},r_{A,2},r_{A,3}],[r_{B,1},r_{B,2},r_{B,3}],\\dots]$，其中每个 $r_{\\cdot,\\cdot}$ 都是四舍五入到 $6$ 位小数的浮点数。",
            "solution": "该问题要求计算一个简单分类器在三种不同的批量归一化（BN）参数测试时策略下，在目标域上的群体风险。该问题定义明确，具有科学依据，并为获得唯一解提供了所有必要信息。\n\n在目标域 $T$ 上，预测器 $f$ 的群体风险由 $R_T(f) = \\mathbb{E}_{(x,y) \\sim T}\\left[\\ell(f(x),y)\\right]$ 给出，其中损失为 $0$-$1$ 损失 $\\ell(\\hat{y},y)=\\mathbf{1}\\{\\hat{y}\\neq y\\}$。数据生成过程指定输入坐标 $x_1$ 在目标域上服从正态分布 $\\mathcal{N}(\\mu_T, \\sigma_T^2)$，真实标签为 $y_{\\mathrm{clean}} = \\mathrm{sign}(x_1)$。观测到的标签 $y$ 受到对称标签噪声的影响，以概率 $p$ 翻转。在 $\\gamma=1$ 和 $\\beta=0$ 的特殊情况下，简化BN变换后的预测器为 $f(x) = \\mathrm{sign}(x_1 - \\tau)$，其中 $\\tau$ 是一个有效决策阈值。\n\n总风险可以根据标签噪声进行分解。误分类的概率为：\n$$R_T(f) = \\mathbb{P}(f(x) \\neq y) = (1-p) \\mathbb{P}(f(x) \\neq y_{\\mathrm{clean}}) + p \\mathbb{P}(f(x) = y_{\\mathrm{clean}})$$\n由于 $\\mathbb{P}(f(x) = y_{\\mathrm{clean}}) = 1 - \\mathbb{P}(f(x) \\neq y_{\\mathrm{clean}})$，我们可以将风险重写为：\n$$R_T(f) = (1-p) \\mathbb{P}(f(x) \\neq y_{\\mathrm{clean}}) + p (1 - \\mathbb{P}(f(x) \\neq y_{\\mathrm{clean}}))$$\n$$R_T(f) = p + (1-2p) \\mathbb{P}(f(x) \\neq y_{\\mathrm{clean}})$$\n不一致事件 $f(x) \\neq y_{\\mathrm{clean}}$ 对应于 $\\mathrm{sign}(x_1-\\tau) \\neq \\mathrm{sign}(x_1)$。这恰好在 $x_1$ 落在 $0$ 和 $\\tau$ 之间的区间时发生。对于 $x_1 \\sim \\mathcal{N}(\\mu_T, \\sigma_T^2)$，此事件的概率由高斯概率密度函数在该区间上的积分给出。这可以用标准正态分布的累积分布函数（CDF）（表示为 $\\Phi(\\cdot)$）来表示。\n$$\\mathbb{P}(\\mathrm{sign}(x_1) \\neq \\mathrm{sign}(x_1 - \\tau)) = \\mathbb{P}(\\min(0,\\tau)  x_1  \\max(0,\\tau))$$\n$$= \\Phi\\left(\\frac{\\max(0,\\tau) - \\mu_T}{\\sigma_T}\\right) - \\Phi\\left(\\frac{\\min(0,\\tau) - \\mu_T}{\\sigma_T}\\right)$$\n由于概率必须为非负，且 $\\max$ 和 $\\min$ 的顺序取决于 $\\tau$ 的符号，因此表达式如题目所提供，使用了绝对值：\n$$\\mathbb{P}(\\text{disagreement}) = \\left|\\Phi\\left(\\frac{\\max\\{0,\\tau\\}-\\mu_T}{\\sigma_T}\\right) - \\Phi\\left(\\frac{\\min\\{0,\\tau\\}-\\mu_T}{\\sigma_T}\\right)\\right|$$\n因此，在目标域上，对于决策阈值 $\\tau$ 的群体风险的完整表达式为：\n$$R_T(\\tau) = p + (1-2p)\\left|\\Phi\\left(\\frac{\\max\\{0,\\tau\\}-\\mu_T}{\\sigma_T}\\right) - \\Phi\\left(\\frac{\\min\\{0,\\tau\\}-\\mu_T}{\\sigma_T}\\right)\\right|$$\n我们给定了固定参数：源域统计量 $(\\mu_S, \\sigma_S) = (0.5, 1.0)$ 和标签噪声概率 $p=0.1$。因子 $(1-2p)$ 为 $1 - 2(0.1) = 0.8$。\n\n三种推理流程对应于阈值 $\\tau$ 的不同选择：\n1.  **冻结的BN**：使用源域的BN统计量，因此 $(\\mu_{\\mathrm{used}}, \\sigma_{\\mathrm{used}}) = (\\mu_S, \\sigma_S)$。分类器变为 $f(x) = \\mathrm{sign}(x_1 - \\mu_S)$。有效阈值为 $\\tau_{\\mathrm{frozen}} = \\mu_S = 0.5$。\n2.  **在T上更新的BN**：在目标域上重新计算BN统计量，因此 $(\\mu_{\\mathrm{used}}, \\sigma_{\\mathrm{used}}) = (\\mu_T, \\sigma_T)$。分类器为 $f(x) = \\mathrm{sign}(x_1 - \\mu_T)$。有效阈值为 $\\tau_{\\mathrm{updated}} = \\mu_T$。\n3.  **白化后冻结BN**：首先应用一个初始仿射变换 $x_1' = \\mu_S + \\frac{\\sigma_S}{\\sigma_T}(x_1 - \\mu_T)$，然后是冻结的BN模型。决策函数为 $f(x) = \\mathrm{sign}\\left(\\frac{x_1' - \\mu_S}{\\sigma_S}\\right)$。代入 $x_1'$ 的表达式可得：\n$$ \\mathrm{sign}\\left(\\frac{\\left(\\mu_S + \\frac{\\sigma_S}{\\sigma_T}(x_1 - \\mu_T)\\right) - \\mu_S}{\\sigma_S}\\right) = \\mathrm{sign}\\left(\\frac{\\frac{\\sigma_S}{\\sigma_T}(x_1 - \\mu_T)}{\\sigma_S}\\right) = \\mathrm{sign}\\left(\\frac{x_1 - \\mu_T}{\\sigma_T}\\right) $$\n由于 $\\sigma_T > 0$，这等价于 $\\mathrm{sign}(x_1 - \\mu_T)$。因此，有效阈值为 $\\tau_{\\mathrm{whiten}} = \\mu_T$，与更新的BN情况相同。因此，它们的群体风险将始终相等。\n\n我们现在计算每个测试用例的风险。\n\n**情况A：** 目标域参数 $(\\mu_T, \\sigma_T) = (0.5, 1.0)$。\n- 冻结的BN：$\\tau = 0.5$。风险参数为 $\\left|\\Phi\\left(\\frac{0.5 - 0.5}{1.0}\\right) - \\Phi\\left(\\frac{0 - 0.5}{1.0}\\right)\\right| = |\\Phi(0) - \\Phi(-0.5)| \\approx 0.191462$。\n$R_T = 0.1 + 0.8 \\times 0.191462 = 0.253170$。\n- 更新的BN：$\\tau = \\mu_T = 0.5$。计算与冻结的BN相同。 $R_T = 0.253170$。\n- 白化后冻结BN：风险与更新的BN相同。 $R_T = 0.253170$。\n\n**情况B：** 目标域参数 $(\\mu_T, \\sigma_T) = (0.0, 1.0)$。\n- 冻结的BN：$\\tau = 0.5$。风险参数为 $\\left|\\Phi\\left(\\frac{0.5 - 0.0}{1.0}\\right) - \\Phi\\left(\\frac{0 - 0.0}{1.0}\\right)\\right| = |\\Phi(0.5) - \\Phi(0)| \\approx 0.191462$。\n$R_T = 0.1 + 0.8 \\times 0.191462 = 0.253170$。\n- 更新的BN：$\\tau = \\mu_T = 0.0$。不一致区间为从 $0$ 到 $0$，其测度为零。不一致概率为 $0$。\n$R_T = 0.1 + 0.8 \\times 0 = 0.100000$。\n- 白化后冻结BN：风险与更新的BN相同。 $R_T = 0.100000$。\n\n**情况C：** 目标域参数 $(\\mu_T, \\sigma_T) = (0.5, 0.5)$。\n- 冻结的BN：$\\tau = 0.5$。风险参数为 $\\left|\\Phi\\left(\\frac{0.5-0.5}{0.5}\\right) - \\Phi\\left(\\frac{0-0.5}{0.5}\\right)\\right| = |\\Phi(0) - \\Phi(-1.0)| \\approx 0.341345$。\n$R_T = 0.1 + 0.8 \\times 0.341345 = 0.373076$。\n- 更新的BN：$\\tau = \\mu_T = 0.5$。计算与冻结的BN相同。 $R_T = 0.373076$。\n- 白化后冻结BN：风险与更新的BN相同。 $R_T = 0.373076$。\n\n**情况D：** 目标域参数 $(\\mu_T, \\sigma_T) = (-1.0, 2.0)$。\n- 冻结的BN：$\\tau = 0.5$。风险参数为 $\\left|\\Phi\\left(\\frac{0.5 - (-1.0)}{2.0}\\right) - \\Phi\\left(\\frac{0 - (-1.0)}{2.0}\\right)\\right| = |\\Phi(0.75) - \\Phi(0.5)| \\approx 0.081911$。\n$R_T = 0.1 + 0.8 \\times 0.081911 = 0.165529$。\n- 更新的BN：$\\tau = \\mu_T = -1.0$。风险参数为 $\\left|\\Phi\\left(\\frac{0 - (-1.0)}{2.0}\\right) - \\Phi\\left(\\frac{-1.0 - (-1.0)}{2.0}\\right)\\right| = |\\Phi(0.5) - \\Phi(0)| \\approx 0.191462$。\n$R_T = 0.1 + 0.8 \\times 0.191462 = 0.253170$。\n- 白化后冻结BN：风险与更新的BN相同。 $R_T = 0.253170$。\n\n这些计算在提供的程序中实现。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes population risks for three Batch Normalization inference strategies\n    across a suite of test cases.\n    \"\"\"\n\n    # --- Fixed Parameters ---\n    # Source domain statistics\n    mu_S = 0.5\n    # sigma_S is not directly used in the simplified risk calculation,\n    # as it's only a positive scaling factor for the sign function's argument.\n    # sigma_S = 1.0\n\n    # Label noise probability\n    p = 0.1\n\n    # --- Test Cases ---\n    # Each case is a tuple (mu_T, sigma_T) for the target domain.\n    test_cases = [\n        (0.5, 1.0),   # Case A\n        (0.0, 1.0),   # Case B\n        (0.5, 0.5),   # Case C\n        (-1.0, 2.0)   # Case D\n    ]\n\n    def calculate_risk(tau, mu_T, sigma_T, p):\n        \"\"\"\n        Calculates the population risk R_T(tau).\n\n        Args:\n            tau (float): The decision threshold on the original feature x_1.\n            mu_T (float): The mean of x_1 in the target domain.\n            sigma_T (float): The standard deviation of x_1 in the target domain.\n            p (float): The label noise probability.\n\n        Returns:\n            float: The calculated population risk.\n        \"\"\"\n        # The disagreement event {sign(x_1) != sign(x_1 - tau)} occurs when x_1 is\n        # between 0 and tau.\n        # We calculate the probability of this event using the standard normal CDF.\n        z_arg1 = (max(0, tau) - mu_T) / sigma_T\n        z_arg2 = (min(0, tau) - mu_T) / sigma_T\n        \n        # The absolute value handles cases where tau  0.\n        disagreement_prob = abs(norm.cdf(z_arg1) - norm.cdf(z_arg2))\n        \n        # The risk is calculated based on the derived formula.\n        risk = p + (1 - 2 * p) * disagreement_prob\n        return risk\n\n    all_results = []\n    for mu_T, sigma_T in test_cases:\n        case_results = []\n\n        # 1. Frozen BN: uses source mean as threshold.\n        tau_frozen = mu_S\n        risk_frozen = calculate_risk(tau_frozen, mu_T, sigma_T, p)\n        case_results.append(risk_frozen)\n\n        # 2. Updated BN on T: uses target mean as threshold.\n        tau_updated = mu_T\n        risk_updated = calculate_risk(tau_updated, mu_T, sigma_T, p)\n        case_results.append(risk_updated)\n\n        # 3. Whitening then Frozen BN: effective threshold is also the target mean.\n        # Therefore, its risk is identical to Updated BN.\n        risk_whiten = risk_updated\n        case_results.append(risk_whiten)\n        \n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists, with each risk\n    # value formatted to 6 decimal places.\n    output_parts = []\n    for res_list in all_results:\n        formatted_nums = [f\"{r:.6f}\" for r in res_list]\n        output_parts.append(f\"[{','.join(formatted_nums)}]\")\n    \n    final_output = f\"[{','.join(output_parts)}]\"\n\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "在理解了领域偏移的影响之后，本练习将重点转向通过领域泛化（domain generalization）来缓解这一问题。你将研究不同的损失函数，例如带有标签平滑（label smoothing）的交叉熵损失，如何在训练时无需接触目标域数据的情况下，使模型对分布偏移具有更强的内在鲁棒性。这个动手实践的对比将突显训练目标在促进更好泛化能力方面所扮演的角色 。",
            "id": "3117573",
            "problem": "您将实现并比较在受控的源到目标分布偏移下的三种用于二元分类的经验风险最小化程序。您的目标是具体操作并展示，在源分布上训练时选择不同的损失函数，会如何影响其在目标分布上的迁移性能。您必须编写一个完整的程序，该程序使用三种不同的损失函数在源数据上训练一个线性分类器，使用标准化指标在目标数据上进行评估，并为每个测试用例输出一个最终决策，指明更平滑的损失函数是否能改善迁移效果。\n\n基本原理和定义：\n- 经验风险最小化（ERM）：给定从源分布 $\\mathcal{S}$ 采样的数据、一个假设类别 $\\mathcal{H}$ 和一个损失函数 $\\ell$，ERM 通过最小化经验风险 $\\hat{R}_{\\mathcal{S}}(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n} \\ell(f_{\\theta}(x_i), y_i)$ 来拟合参数 $\\theta$。\n- 领域自适应设置：存在一个源分布 $\\mathcal{S}$ 和一个目标分布 $\\mathcal{T}$，它们作用于相同的输入输出空间。模型在 $\\mathcal{S}$ 上训练，并在 $\\mathcal{T}$ 上评估。\n- 模型：一个线性分类器 $f_{\\theta}(x) = \\sigma(w^{\\top} x + b)$，其参数为 $\\theta = (w,b)$，其中 $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$ 是逻辑S型函数（logistic sigmoid）。\n- 待比较的训练损失函数：\n  1. 交叉熵（CE）：对于 $y \\in \\{0,1\\}$ 和 $p \\in (0,1)$，$\\ell_{\\mathrm{CE}}(p,y) = -\\left(y \\log p + (1-y)\\log(1-p)\\right)$。\n  2. 标签平滑交叉熵（LS-CE）：对于给定的平滑参数 $\\varepsilon \\in [0,1/2)$，将硬目标 $y \\in \\{0,1\\}$ 替换为平滑目标 $t \\in (0,1)$，其中当 $y=1$ 时 $t = (1-\\varepsilon)$，当 $y=0$ 时 $t = \\varepsilon$。然后使用 $\\ell_{\\mathrm{CE}}(p,t)$。\n  3. 间隔逻辑损失（M-Logit）：对于标签 $\\tilde{y} \\in \\{-1,+1\\}$ 和分数 $z = w^{\\top}x + b$，损失为 $\\ell_{\\mathrm{M}}(z,\\tilde{y}) = \\log\\left(1 + \\exp\\left(m - \\tilde{y}\\,z\\right)\\right)$，其中 $m \\ge 0$ 是间隔参数。\n\n所有三个训练目标都包含系数为 $\\lambda  0$ 的 $\\ell_2$ 正则化，且仅应用于 $w$。优化过程通过批量梯度下降执行，使用固定的周期数和固定的学习率。\n\n评估指标：\n- 为了在统一标准下比较不同损失函数的迁移性能，应使用标准交叉熵在目标数据上进行评估，其中使用真实标签 $y \\in \\{0,1\\}$ 和模型预测的概率 $p = \\sigma(w^{\\top}x + b)$。目标风险估计为 $\\hat{R}_{\\mathcal{T}}(\\theta) = \\frac{1}{n_{\\mathcal{T}}}\\sum_{j=1}^{n_{\\mathcal{T}}} -\\left(y_j \\log p_j + (1-y_j)\\log(1-p_j)\\right)$。\n\n数据生成：\n- 输入位于 $\\mathbb{R}^d$ 空间，其中 $d=2$。源分布 $\\mathcal{S}$ 和目标分布 $\\mathcal{T}$ 均为二元类条件高斯混合分布，具有各向同性的协方差 $\\sigma^2 I$，但类先验和类均值可能不同。对于一个包含 $n$ 个样本的数据集，首先根据类先验抽取类别标签，然后对于 $c \\in \\{0,1\\}$，从 $\\mathcal{N}(\\mu_c, \\sigma^2 I)$ 中抽取 $x \\mid y=c$。\n- 对于每个测试用例，您将获得：\n  - 源类均值 $\\mu^{\\mathcal{S}}_0 \\in \\mathbb{R}^2$ 和 $\\mu^{\\mathcal{S}}_1 \\in \\mathbb{R}^2$，\n  - 目标类均值 $\\mu^{\\mathcal{T}}_0 \\in \\mathbb{R}^2$ 和 $\\mu^{\\mathcal{T}}_1 \\in \\mathbb{R}^2$，\n  - 类别 1 的源类和目标类先验概率 $\\pi^{\\mathcal{S}} \\in (0,1)$ 和 $\\pi^{\\mathcal{T}} \\in (0,1)$（类别 0 的先验概率为 $1-\\pi$），\n  - 标准差 $\\sigma  0$（在类别和域之间共享），\n  - 训练集大小 $n_{\\mathcal{S}}$ 和评估集大小 $n_{\\mathcal{T}}$，\n  - 优化超参数：学习率 $\\alpha  0$，周期数 $E \\in \\mathbb{N}$，正则化系数 $\\lambda  0$，\n  - 标签平滑参数 $\\varepsilon \\in [0,1/2)$ 和间隔参数 $m \\ge 0$。\n\n每个测试用例的决策规则：\n- 设 $\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}$、$\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}}$ 和 $\\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}$ 分别表示使用交叉熵、标签平滑交叉熵和间隔逻辑损失训练的模型的目标评估风险。定义一个容差 $\\tau = 10^{-3}$。\n- 为该测试用例输出布尔值 $\\mathrm{LS\\_is\\_better}$，如果 $\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}} \\le \\min\\{\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}, \\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}\\} - \\tau$ 成立，则为 $True$，否则为 $False$。\n\n测试套件：\n使用以下四个测试用例，每个用例都指定为一个有序的参数元组。每个测试用例行列出：\n$(\\mu^{\\mathcal{S}}_0, \\mu^{\\mathcal{S}}_1, \\mu^{\\mathcal{T}}_0, \\mu^{\\mathcal{T}}_1, \\pi^{\\mathcal{S}}, \\pi^{\\mathcal{T}}, \\sigma, n_{\\mathcal{S}}, n_{\\mathcal{T}}, \\alpha, E, \\lambda, \\varepsilon, m)$，其中所有向量都在 $\\mathbb{R}^2$ 中，所有标量都是相应定义域内的实数。\n\n- 案例 1（轻度协变量偏移，小样本）：\n  - $( (-1.0, 0.0), (1.0, 0.0), (-0.6, 0.0), (1.4, 0.0), 0.5, 0.5, 0.5, 200, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n- 案例 2（无偏移，大样本）：\n  - $( (-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.5, 0.5, 4000, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n- 案例 3（强协变量偏移，中等样本）：\n  - $( (-1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (2.0, 0.0), 0.5, 0.5, 0.6, 1000, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n- 案例 4（标签偏移，无协变量偏移）：\n  - $( (-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.8, 0.5, 1000, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n\n实现要求：\n- 对每次训练运行，使用单一的线性模型类 $f_{\\theta}(x) = \\sigma(w^{\\top} x + b)$，并共享初始化参数 $(w,b)=(0,0)$。\n- 每个测试用例训练三个独立的模型：CE、LS-CE 和 M-Logit，每个模型都使用指定的超参数和对 $w$ 的 $\\ell_2$ 正则化。\n- 在 $\\mathcal{T}$ 上进行评估时，始终使用真实标签和模型的预测概率 $p = \\sigma(w^{\\top} x + b)$ 来计算标准交叉熵。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的布尔值列表（例如，“[True,False,True,False]”），其中第 $k$ 个布尔值对应于上面的第 $k$ 个案例。",
            "solution": "目标是为一个特定的源到目标分布偏移下的二元分类任务，实现并比较三种经验风险最小化（ERM）程序。我们将使用三种不同的损失函数在源分布 $\\mathcal{S}$ 上训练一个线性分类器，并使用一个通用指标评估它们在目标分布 $\\mathcal{T}$ 上的泛化性能。\n\n### 1. 模型与数据生成\n模型是一个线性分类器，由权重 $w \\in \\mathbb{R}^d$ 和偏置 $b \\in \\mathbb{R}$ 参数化，本问题中 $d=2$。这些参数统称为 $\\theta = (w,b)$。对于输入 $x \\in \\mathbb{R}^d$，分类器预测其属于类别 1 的概率为：\n$$f_{\\theta}(x) = p = \\sigma(w^{\\top} x + b)$$\n其中 $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$ 是逻辑S型函数。\n\n源域和目标域的数据都由一个双组分高斯混合模型生成。对于给定的域（$\\mathcal{S}$ 或 $\\mathcal{T}$），其类别先验为 $\\pi_0$ 和 $\\pi_1$（其中 $\\pi_0 + \\pi_1 = 1$），一个数据点 $(x,y)$ 的生成过程如下：首先从参数为 $\\pi_1$ 的伯努利分布中采样一个类别标签 $y \\in \\{0,1\\}$。然后，特征向量 $x$ 从类条件高斯分布中采样：\n$$x \\mid y=c \\sim \\mathcal{N}(\\mu_c, \\sigma^2 I)$$\n对于 $c \\in \\{0,1\\}$，其中 $\\mu_c$ 是类别均值，$\\sigma^2 I$ 是各向同性协方差矩阵，$I$ 是 $d \\times d$ 的单位矩阵。\n\n### 2. 通过经验风险最小化进行训练\n模型参数 $\\theta$ 通过在源数据 $\\{(x_i, y_i)\\}_{i=1}^{n_{\\mathcal{S}}}$ 上最小化正则化的经验风险来学习。目标函数的通用形式为：\n$$L(\\theta) = \\frac{1}{n_{\\mathcal{S}}} \\sum_{i=1}^{n_{\\mathcal{S}}} \\ell(f_{\\theta}(x_i), y_i) + \\lambda \\|w\\|_2^2$$\n其中 $\\ell$ 是所选的损失函数，$\\lambda  0$ 是 $\\ell_2$ 正则化的系数，该正则化仅应用于权重 $w$。优化过程使用批量梯度下降法，在固定的周期数 $E$ 内以学习率 $\\alpha$ 进行。\n\n参数更新规则如下：\n$$w \\leftarrow w - \\alpha \\nabla_w L(\\theta)$$\n$$b \\leftarrow b - \\alpha \\nabla_b L(\\theta)$$\n梯度是在整个源数据集上计算的：\n$$\\nabla_w L(\\theta) = \\left( \\frac{1}{n_{\\mathcal{S}}} \\sum_{i=1}^{n_{\\mathcal{S}}} \\frac{\\partial \\ell_i}{\\partial z_i} x_i^{\\top} \\right) + 2\\lambda w$$\n$$\\nabla_b L(\\theta) = \\frac{1}{n_{\\mathcal{S}}} \\sum_{i=1}^{n_{\\mathcal{S}}} \\frac{\\partial \\ell_i}{\\partial z_i}$$\n其中 $z_i = w^{\\top}x_i + b$ 是样本 $i$ 的 logit，$\\ell_i$ 是该样本的损失。关键部分是每个样本损失相对于 logit 的梯度 $\\frac{\\partial \\ell_i}{\\partial z_i}$，它因三种不同的损失函数而异。\n\n### 3. 损失函数及其梯度\n\n#### 3.1. 交叉熵损失 (CE)\n对于标签 $y \\in \\{0,1\\}$ 的标准二元分类交叉熵损失为：\n$$\\ell_{\\mathrm{CE}}(p,y) = -\\left(y \\log p + (1-y)\\log(1-p)\\right)$$\n其中 $p = \\sigma(z)$。该损失相对于 logit $z$ 的梯度是：\n$$\\frac{\\partial \\ell_{\\mathrm{CE}}}{\\partial z} = p - y$$\n\n#### 3.2. 标签平滑交叉熵损失 (LS-CE)\n该损失是交叉熵的一种变体，其中硬标签 $y \\in \\{0,1\\}$ 被替换为“软”或平滑的目标概率 $t$。对于平滑参数 $\\varepsilon \\in [0, 1/2)$，目标 $t$ 定义为：\n$$t = y(1-\\varepsilon) + (1-y)\\varepsilon$$\n损失函数为 $\\ell_{\\mathrm{CE}}(p,t)$。其相对于 logit $z$ 的梯度与标准 CE 情况类似：\n$$\\frac{\\partial \\ell_{\\mathrm{LS}}}{\\partial z} = p - t$$\n\n#### 3.3. 间隔逻辑损失 (M-Logit)\n该损失使用标签 $\\tilde{y} \\in \\{-1,+1\\}$ 定义，通过映射 $\\tilde{y} = 2y-1$ 与 $y \\in \\{0,1\\}$ 对应。给定一个间隔参数 $m \\ge 0$，损失为：\n$$\\ell_{\\mathrm{M}}(z, \\tilde{y}) = \\log\\left(1 + \\exp\\left(m - \\tilde{y}z\\right)\\right)$$\n此损失鼓励分数 $\\tilde{y}z$ 大于间隔 $m$。其相对于 logit $z$ 的梯度为：\n$$\\frac{\\partial \\ell_{\\mathrm{M}}}{\\partial z} = \\frac{\\partial}{\\partial z} \\log\\left(1 + \\exp\\left(m - \\tilde{y}z\\right)\\right) = \\frac{\\exp(m-\\tilde{y}z)}{1+\\exp(m-\\tilde{y}z)} \\cdot (-\\tilde{y}) = -\\tilde{y} \\, \\sigma(m - \\tilde{y}z)$$\n\n### 4. 评估与决策\n在源数据 $\\mathcal{S}$ 上训练了三个独立的模型（每种损失函数一个）后，它们的性能在目标数据 $\\mathcal{T} = \\{(x_j, y_j)\\}_{j=1}^{n_{\\mathcal{T}}}$ 上进行评估。评估指标是标准的、未经平滑的交叉熵风险，以确保公平比较。对于参数为 $\\theta$ 的模型，其目标风险为：\n$$\\hat{R}_{\\mathcal{T}}(\\theta) = \\frac{1}{n_{\\mathcal{T}}} \\sum_{j=1}^{n_{\\mathcal{T}}} -\\left(y_j \\log p_j + (1-y_j)\\log(1-p_j)\\right)$$\n其中 $p_j = \\sigma(w^{\\top}x_j + b)$。为保证数值稳定性，这可以计算为 $\\frac{1}{n_{\\mathcal{T}}} \\sum_j \\left( \\log(1+e^{z_j}) - y_j z_j \\right)$。\n\n对于每个测试用例，我们计算目标风险 $\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}$、$\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}}$ 和 $\\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}$。最终决策基于一个容差 $\\tau = 10^{-3}$。当且仅当以下条件成立时，布尔值输出 $\\mathrm{LS\\_is\\_better}$ 为 `True`：\n$$\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}} \\le \\min\\{\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}, \\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}\\} - \\tau$$\n\n### 5. 实现摘要\n解决方案涉及一个遍历所有给定测试用例的主循环。对于每个用例：\n1.  为保证可复现性，设置一个确定性的随机种子。\n2.  根据指定参数生成源数据集和目标数据集。\n3.  对于三种损失函数（'CE', 'LS', 'M'）中的每一种，使用批量梯度下降法从初始化状态 $(w,b)=(0,0)$ 开始训练一个线性模型。\n4.  在目标数据集上评估这三个训练好的模型，以获得它们各自的目标风险。\n5.  应用决策规则，判断标签平滑方法是否比其他两种方法提供了足够好的结果。\n收集所有测试用例的结果，并按指定格式打印。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import expit # Numerically stable sigmoid function\n\ndef generate_data(means, prior_1, sigma, n_samples, seed):\n    \"\"\"\n    Generates data from a 2-component Gaussian mixture model.\n    \"\"\"\n    d = len(means[0])\n    cov = sigma**2 * np.eye(d)\n    \n    rng = np.random.default_rng(seed)\n    \n    # Generate labels from a Bernoulli distribution\n    labels = rng.random(n_samples)  prior_1\n    y = labels.astype(int)\n    \n    n_class1 = np.sum(y)\n    n_class0 = n_samples - n_class1\n    \n    X = np.zeros((n_samples, d))\n    if n_class0 > 0:\n        X[y == 0] = rng.multivariate_normal(means[0], cov, n_class0)\n    if n_class1 > 0:\n        X[y == 1] = rng.multivariate_normal(means[1], cov, n_class1)\n        \n    return X, y\n\ndef train_model(X, y, loss_type, hparams):\n    \"\"\"\n    Trains a linear classifier using batch gradient descent.\n    \"\"\"\n    n_samples, d = X.shape\n    alpha = hparams['alpha']\n    epochs = hparams['epochs']\n    reg_lambda = hparams['lambda']\n    ls_eps = hparams.get('eps', 0.1)\n    margin_m = hparams.get('m', 0.6)\n\n    w = np.zeros(d)\n    b = 0.0\n\n    for _ in range(epochs):\n        z = X @ w + b\n        \n        if loss_type == 'ce':\n            p = expit(z)\n            grad_z = p - y\n        elif loss_type == 'ls':\n            p = expit(z)\n            t = y * (1 - ls_eps) + (1 - y) * ls_eps\n            grad_z = p - t\n        elif loss_type == 'm':\n            y_tilde = 2 * y - 1\n            arg = margin_m - y_tilde * z\n            # Note: expit(x) is sigmoid(x)\n            grad_z = -y_tilde * expit(arg)\n        else:\n            raise ValueError(\"Unknown loss type\")\n            \n        grad_w = (X.T @ grad_z) / n_samples + 2 * reg_lambda * w\n        grad_b = np.mean(grad_z)\n        \n        w -= alpha * grad_w\n        b -= alpha * grad_b\n        \n    return w, b\n\ndef evaluate_risk(X, y, w, b):\n    \"\"\"\n    Evaluates the standard cross-entropy risk on a dataset.\n    Uses a numerically stable implementation: log(1+exp(z)) - y*z\n    \"\"\"\n    z = X @ w + b\n    # np.logaddexp(0, z) computes log(1 + exp(z)) stably\n    losses = np.logaddexp(0, z) - y * z\n    return np.mean(losses)\n\ndef solve():\n    \"\"\"\n    Main solver function to run the experiment for all test cases.\n    \"\"\"\n    # Each case: (mu_s0, mu_s1, mu_t0, mu_t1, pi_s, pi_t, sigma, n_s, n_t, alpha, E, lambda, eps, m)\n    test_cases = [\n        # Case 1 (mild covariate shift, small sample)\n        ((-1.0, 0.0), (1.0, 0.0), (-0.6, 0.0), (1.4, 0.0), 0.5, 0.5, 0.5, 200, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n        # Case 2 (no shift, large sample)\n        ((-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.5, 0.5, 4000, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n        # Case 3 (strong covariate shift, medium sample)\n        ((-1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (2.0, 0.0), 0.5, 0.5, 0.6, 1000, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n        # Case 4 (label shift, no covariate shift)\n        ((-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.8, 0.5, 1000, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n    ]\n\n    results = []\n    \n    for i, case in enumerate(test_cases):\n        mu_s0, mu_s1, mu_t0, mu_t1, pi_s, pi_t, sigma, n_s, n_t, alpha, E, reg_lambda, eps, m = case\n\n        # Convert means to numpy arrays\n        mu_s = (np.array(mu_s0), np.array(mu_s1))\n        mu_t = (np.array(mu_t0), np.array(mu_t1))\n\n        hparams = {\n            'alpha': alpha, 'epochs': E, 'lambda': reg_lambda,\n            'eps': eps, 'm': m\n        }\n        \n        # Use a deterministic seed for each case to ensure reproducibility.\n        # Use derived seeds for data generation to ensure source/target are different.\n        case_seed = 42 + i\n        \n        # Generate data\n        X_s, y_s = generate_data(mu_s, pi_s, sigma, n_s, seed=case_seed)\n        X_t, y_t = generate_data(mu_t, pi_t, sigma, n_t, seed=case_seed + 100) # Different seed for target\n        \n        # Train models\n        w_ce, b_ce = train_model(X_s, y_s, 'ce', hparams)\n        w_ls, b_ls = train_model(X_s, y_s, 'ls', hparams)\n        w_m, b_m = train_model(X_s, y_s, 'm', hparams)\n        \n        # Evaluate models\n        risk_ce = evaluate_risk(X_t, y_t, w_ce, b_ce)\n        risk_ls = evaluate_risk(X_t, y_t, w_ls, b_ls)\n        risk_m = evaluate_risk(X_t, y_t, w_m, b_m)\n        \n        # Apply decision rule\n        tau = 1e-3\n        is_better = risk_ls = min(risk_ce, risk_m) - tau\n        results.append(is_better)\n        \n    # Format output as specified\n    formatted_results = [str(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "这最后一个练习将探索更高级的无监督领域自适应（unsupervised domain adaptation）技术，即利用无标签的目标域数据来主动对齐分布。你将实现并比较两种强大的特征对齐方法：最优传输（Optimal Transport, OT）和最大均值差异（Maximum Mean Discrepancy, MMD）。通过这个练习，你将获得解决OT问题的实践经验，并理解显式的分布匹配如何能显著提升模型在新领域上的性能 。",
            "id": "3117509",
            "problem": "给定一个二元分类域适应任务，该任务通过使用最优传输（Optimal Transport, OT）和最大均值差异（Maximum Mean Discrepancy, MMD）在源域和目标域之间进行特征对齐。源域和目标域都由有限样本表示，源域样本带有标签，目标域样本的标签仅用于评估。特征提取器是恒等映射，因此特征与输入向量相同。目标是实现具有均匀边缘分布的熵正则化最优传输，从得到的传输方案构建一个重心对齐，在对齐后的源特征上微调一个分类器，并将其在目标域上的准确率与使用基于线性核的MMD对齐方法微调的分类器进行比较。最终输出应汇总多个测试案例中OT相对于MMD的准确率提升。\n\n需要使用的基本原理和定义：\n- 该任务设定在域适应的背景下。源域提供带标签的样本，而目标域提供用于对齐的无标签样本和用于评估的带标签样本。\n- 恒等特征提取器表示为 $f_{\\theta}(x) = x$。在此任务中，参数向量 $\\theta$ 不进行显式优化。\n- 最优传输对齐解决以下熵正则化传输问题：给定源特征 $\\{z_{i}^{S}\\}_{i=1}^{n_{S}}$、目标特征 $\\{z_{j}^{T}\\}_{j=1}^{n_{T}}$、均匀边缘分布 $a \\in \\mathbb{R}^{n_{S}}$ 和 $b \\in \\mathbb{R}^{n_{T}}$（其中 $a_{i} = \\frac{1}{n_{S}}$ 且 $b_{j} = \\frac{1}{n_{T}}$），以及由 $C_{ij} = \\lVert z_{i}^{S} - z_{j}^{T} \\rVert_{2}^{2}$ 定义的代价矩阵 $C \\in \\mathbb{R}^{n_{S} \\times n_{T}}$，找到一个传输方案 $\\pi \\in \\mathbb{R}^{n_{S} \\times n_{T}}$，使其在满足边缘约束的条件下最小化正则化目标函数：\n$$\n\\min_{\\pi} \\sum_{i=1}^{n_{S}} \\sum_{j=1}^{n_{T}} \\pi_{ij} \\lVert z_{i}^{S} - z_{j}^{T} \\rVert_{2}^{2} + \\varepsilon \\sum_{i=1}^{n_{S}} \\sum_{j=1}^{n_{T}} \\pi_{ij} \\log \\pi_{ij}\n$$\n约束条件为 $\\sum_{j=1}^{n_{T}} \\pi_{ij} = a_{i}$ 和 $\\sum_{i=1}^{n_{S}} \\pi_{ij} = b_{j}$。熵正则化参数为 $\\varepsilon  0$。\n- 使用Sinkhorn-Knopp迭代尺度法（此处不提供显式公式；您必须推导并实现该过程）来解决熵正则化问题，并获得满足边缘约束的传输方案 $\\pi$。\n- 使用传输方案构建源特征相对于目标特征的重心对齐。具体来说，通过将目标特征按传输方案和源边缘分布加权形成重心组合，生成对齐后的源特征 $\\{z_{i}^{S,\\mathrm{OT}}\\}_{i=1}^{n_{S}}$。\n- 使用源标签在对齐后的源特征上微调一个二元分类器。该分类器必须实现为通过梯度下降法在交叉熵损失上训练的逻辑回归。\n- 最大均值差异（MMD）是一种基于核均值嵌入的分布间差异度量。使用线性核 $k(x,y) = x^{\\top}y$。在此核下，推导并实现在源特征上的对齐变换，该变换最小化对齐后源特征与目标特征之间的经验MMD。然后，使用源标签在MMD对齐的源特征上微调同一个逻辑回归分类器。\n- 使用真实的目标标签在原始目标特征上评估这两个分类器。计算OT对齐分类器和MMD对齐分类器的准确率。对于每个测试案例，报告准确率提升，计算为标量 $A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$，其中 $A_{\\mathrm{OT}}$ 和 $A_{\\mathrm{MMD}}$ 分别是两种方法实现的目标域准确率。\n\n数据生成协议（所有角度均以弧度为单位）：\n- 为两个类别生成样本量相等的源数据（二元标签）。令 $d = 2$。类条件源均值为 $\\mu_{0}^{S} = [-2, 0]$ 和 $\\mu_{1}^{S} = [2, 0]$。对于源样本，抽取均值为零、协方差为 $\\sigma_{S}^{2} I_{2}$ 的独立高斯噪声，其中 $I_{2}$ 是 $2 \\times 2$ 的单位矩阵。源标签是已知的。\n- 通过对源类别均值应用旋转和平移来生成目标数据，从而产生目标类别均值。设旋转角为 $\\alpha$，平移向量为 $t = [t_{x}, t_{y}]$。目标类别均值为 $\\mu_{c}^{T} = R(\\alpha) \\mu_{c}^{S} + t$，对于 $c \\in \\{0,1\\}$，其中 $R(\\alpha)$ 是弧度为 $\\alpha$ 的 $2 \\times 2$ 旋转矩阵。围绕每个目标类别均值抽取均值为零、协方差为 $\\sigma_{T}^{2} I_{2}$ 的独立高斯噪声。目标标签仅用于评估。\n\n实现要求：\n- 使用 $f_{\\theta}(x) = x$。\n- 使用均匀边缘分布 $a_{i} = \\frac{1}{n_{S}}$ 和 $b_{j} = \\frac{1}{n_{T}}$。\n- 使用Sinkhorn-Knopp方法解决给定 $\\varepsilon$ 的熵正则化OT问题。\n- 使用传输方案和目标特征构建源特征的重心对齐。\n- 通过梯度下降法训练逻辑回归，使用测试套件中指定的固定轮次和学习率。使用交叉熵损失，并通过在$0.5$处对logistic函数进行阈值化来预测。\n- 对于基于线性核的MMD对齐，推导最小化对齐后源特征与目标特征之间经验MMD的对齐方法。实现此对齐，然后在对齐后的源特征上微调逻辑回归。\n- 在目标域上评估准确率，并为每个案例计算准确率提升 $A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$。\n\n测试套件：\n- 所有随机抽样必须使用指定的种子以保证可复现性。每个测试案例使用独立的种子：seed $= 10 + \\text{case\\_index}$，其中四个案例的案例索引分别为 $0,1,2,3$。\n- 提供四个测试案例，参数为 $(n_{S}, n_{T}, \\sigma_{S}, \\sigma_{T}, \\alpha, t_{x}, t_{y}, \\varepsilon, \\text{epochs}, \\text{learning\\_rate})$：\n    1. 案例 $0$ (理想情况)：$(n_{S}, n_{T}) = (60, 60)$，$\\sigma_{S} = 0.4$，$\\sigma_{T} = 0.4$，$\\alpha = 0.5$， $t_{x} = 1.0$， $t_{y} = 0.5$， $\\varepsilon = 0.2$，epochs $= 200$，学习率 $= 0.1$。\n    2. 案例 $1$ (无偏移边界条件)：$(n_{S}, n_{T}) = (60, 60)$，$\\sigma_{S} = 0.4$，$\\sigma_{T} = 0.4$，$\\alpha = 0.0$， $t_{x} = 0.0$， $t_{y} = 0.0$， $\\varepsilon = 0.2$，epochs $= 200$，学习率 $= 0.1$。\n    3. 案例 $2$ (困难偏移)：$(n_{S}, n_{T}) = (80, 80)$，$\\sigma_{S} = 0.4$，$\\sigma_{T} = 0.6$，$\\alpha = 1.0$， $t_{x} = 2.0$， $t_{y} = -1.0$， $\\varepsilon = 0.3$，epochs $= 250$，学习率 $= 0.08$。\n    4. 案例 $3$ (小样本量边缘情况)：$(n_{S}, n_{T}) = (12, 12)$，$\\sigma_{S} = 0.5$，$\\sigma_{T} = 0.5$，$\\alpha = 0.8$， $t_{x} = 1.5$， $t_{y} = 1.5$， $\\varepsilon = 0.25$，epochs $= 300$，学习率 $= 0.12$。\n\n答案类型和最终输出格式：\n- 对于每个测试案例，计算浮点数 $A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$，其中 $A_{\\mathrm{OT}}$ 和 $A_{\\mathrm{MMD}}$ 是表示为 $[0,1]$ 区间内小数的目标域准确率。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个浮点数按测试案例的顺序格式化为四位小数（例如，$[0.1234,0.0000,-0.0567,0.0321]$）。",
            "solution": "该问题要求对一个二元分类任务中的两种域适应技术进行对比分析，一种基于最优传输（OT），另一种基于最大均值差异（MMD）。目标是在特征空间中将一个带标签的源域分布与一个无标签的目标域分布对齐，在本例中，特征空间即输入空间本身，因为特征提取器是恒等映射，$f_{\\theta}(x) = x$。我们将实现这两种对齐方法，在对齐后的源数据上训练一个逻辑回归分类器，在目标域上评估其性能，并计算基于OT的方法相对于基于MMD的方法的准确率提升。\n\n首先，我们定义数据生成过程。源数据包含来自$d=2$维空间中两个平衡类别的 $n_S$ 个样本。类条件分布是高斯分布。均值分别为 $\\mu_{0}^{S} = [-2, 0]^{\\top}$ 和 $\\mu_{1}^{S} = [2, 0]^{\\top}$。样本生成方式为 $z_i^S \\sim \\mathcal{N}(\\mu_{y_i^S}^S, \\sigma_S^2 I_2)$，其中 $y_i^S \\in \\{0, 1\\}$ 是源标签，$I_2$ 是 $2 \\times 2$ 的单位矩阵。目标域数据包含 $n_T$ 个样本，通过对源类别均值应用旋转和平移生成。目标类别均值为 $\\mu_{c}^{T} = R(\\alpha) \\mu_{c}^{S} + t$（对于 $c \\in \\{0,1\\}$），其中 $R(\\alpha)$ 是角度为 $\\alpha$ 的旋转矩阵，$t = [t_x, t_y]^\\top$ 是平移向量。目标样本生成方式为 $z_j^T \\sim \\mathcal{N}(\\mu_{y_j^T}^T, \\sigma_T^2 I_2)$，其中 $y_j^T$ 是目标标签，仅用于评估。\n\n第一种对齐方法的核心是熵正则化最优传输。我们的目标是找到一个传输方案 $\\pi \\in \\mathbb{R}^{n_S \\times n_T}$，以最小化正则化的传输代价。源特征 $z_i^S$ 和目标特征 $z_j^T$ 之间的代价是平方欧氏距离，$C_{ij} = \\lVert z_i^S - z_j^T \\rVert_2^2$。优化问题是：\n$$\n\\min_{\\pi} \\sum_{i=1}^{n_{S}} \\sum_{j=1}^{n_{T}} \\pi_{ij} C_{ij} - \\varepsilon H(\\pi)\n$$\n其中 $H(\\pi) = -\\sum_{ij} \\pi_{ij} \\log \\pi_{ij}$ 是传输方案的熵，$\\varepsilon  0$ 是正则化强度。最小化过程受边缘约束 $\\pi \\mathbf{1}_{n_T} = a$ 和 $\\pi^\\top \\mathbf{1}_{n_S} = b$ 的限制，其中 $\\mathbf{1}_k$ 是大小为 $k$ 的全1向量。边缘分布是均匀的，即 $a_i = 1/n_S$ 和 $b_j = 1/n_T$。\n\n这个问题可以使用Sinkhorn-Knopp算法高效求解。解 $\\pi$ 可以表示为 $\\pi = \\text{diag}(u) K \\text{diag}(v)$，其中 $K_{ij} = e^{-C_{ij}/\\varepsilon}$，$u, v$ 是尺度向量。该算法迭代更新 $u$ 和 $v$ 以满足边缘约束：\n$$\nu \\leftarrow a \\oslash (K v) \\quad \\text{和} \\quad v \\leftarrow b \\oslash (K^\\top u)\n$$\n其中 $\\oslash$ 表示逐元素除法。从 $v$ 的一个初始猜测（例如，$v = \\mathbf{1}_{n_T}$）开始，重复这些更新直至收敛。\n\n一旦找到最优传输方案 $\\pi$，我们执行源特征的重心对齐。对齐后的源特征 $z_i^{S,\\mathrm{OT}}$ 是 $z_i^S$ 映射到的目标特征的期望，由条件传输概率加权。$z_i^S$ 映射到 $z_j^T$ 的条件概率是 $p(j|i) = \\pi_{ij} / a_i = n_S \\pi_{ij}$。因此，对齐后的特征是：\n$$\nz_i^{S,\\mathrm{OT}} = \\sum_{j=1}^{n_T} p(j|i) z_j^T = n_S \\sum_{j=1}^{n_T} \\pi_{ij} z_j^T\n$$\n用矩阵表示法，即为 $Z_{S,\\mathrm{OT}} = (n_S \\pi) Z_T$，其中 $Z_T$ 是目标特征矩阵。\n\n第二种对齐方法基于最小化使用线性核 $k(x,y) = x^\\top y$ 的最大均值差异（MMD）。一组变换后的源特征 $\\{\\mathcal{T}(z_i^S)\\}_{i=1}^{n_S}$ 与目标特征 $\\{z_j^T\\}_{j=1}^{n_T}$ 之间的平方经验MMD是：\n$$\n\\text{MMD}^2 = \\left\\lVert \\frac{1}{n_S} \\sum_{i=1}^{n_S} \\phi(\\mathcal{T}(z_i^S)) - \\frac{1}{n_T} \\sum_{j=1}^{n_T} \\phi(z_j^T) \\right\\rVert_{\\mathcal{H}}^2\n$$\n对于线性核，特征映射 $\\phi$ 是恒等映射，即 $\\phi(x) = x$。我们选择一个简单的对齐变换类别：全局平移，$\\mathcal{T}(z) = z + v$。目标是找到向量 $v$ 来最小化：\n$$\n\\min_v \\left\\lVert \\frac{1}{n_S} \\sum_{i=1}^{n_S} (z_i^S + v) - \\frac{1}{n_T} \\sum_{j=1}^{n_T} z_j^T \\right\\rVert_2^2 = \\min_v \\left\\lVert (\\bar{z}^S + v) - \\bar{z}^T \\right\\rVert_2^2\n$$\n其中 $\\bar{z}^S$ 和 $\\bar{z}^T$ 分别是源特征和目标特征的经验均值。当 $v = \\bar{z}^T - \\bar{z}^S$ 时，该表达式最小化。因此，基于MMD的对齐是一种均值匹配变换：\n$$\nz_i^{S,\\mathrm{MMD}} = z_i^S + (\\bar{z}^T - \\bar{z}^S)\n$$\n这将源分布的质心与目标分布的质心对齐。\n\n在使用OT（$Z_{S,\\mathrm{OT}}$）和MMD（$Z_{S,\\mathrm{MMD}}$）两种方法对齐源特征后，我们训练两个独立的二元逻辑回归分类器。模型预测类别1的概率为 $\\hat{y} = \\sigma(z^\\top w + b)$，其中 $\\sigma(s) = 1/(1+e^{-s})$ 是sigmoid函数，$w \\in \\mathbb{R}^2$ 是权重，$b \\in \\mathbb{R}$ 是偏置。分类器通过使用梯度下降法在固定的轮次和给定的学习率下最小化二元交叉熵损失函数进行训练。对于大小为 $N$、特征为 $X$、标签为 $Y$ 的数据集，损失 $L$ 的梯度为：\n$$\n\\nabla_w L = \\frac{1}{N} X^\\top (\\hat{Y} - Y), \\quad \\nabla_b L = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)\n$$\n权重和偏置按 $w \\leftarrow w - \\eta \\nabla_w L$ 和 $b \\leftarrow b - \\eta \\nabla_b L$ 进行更新，其中 $\\eta$ 是学习率。\n\n最后，我们评估这两个分类器的性能。在 $Z_{S,\\mathrm{OT}}$ 上训练的分类器和在 $Z_{S,\\mathrm{MMD}}$ 上训练的分类器都在原始、未对齐的目标特征 $Z_T$ 及其真实标签 $Y_T$ 上进行测试。如果输出概率大于 $0.5$，则预测为类别 $1$，否则为 $0$。准确率是正确分类的目标样本的比例。每个测试案例的最终结果是准确率之差：$A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef generate_data(n_s, n_t, sigma_s, sigma_t, alpha, t_x, t_y, seed):\n    \"\"\"Generates source and target domain data.\"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Source domain data\n    mu_s0 = np.array([-2.0, 0.0])\n    mu_s1 = np.array([2.0, 0.0])\n    \n    n_s_half = n_s // 2\n    z_s0 = rng.multivariate_normal(mu_s0, sigma_s**2 * np.eye(2), size=n_s_half)\n    z_s1 = rng.multivariate_normal(mu_s1, sigma_s**2 * np.eye(2), size=n_s - n_s_half)\n    \n    Z_s = np.vstack((z_s0, z_s1))\n    Y_s = np.hstack((np.zeros(n_s_half), np.ones(n_s - n_s_half)))\n\n    # Target domain data\n    R = np.array([[np.cos(alpha), -np.sin(alpha)], [np.sin(alpha), np.cos(alpha)]])\n    t = np.array([t_x, t_y])\n    \n    mu_t0 = R @ mu_s0 + t\n    mu_t1 = R @ mu_s1 + t\n    \n    n_t_half = n_t // 2\n    z_t0 = rng.multivariate_normal(mu_t0, sigma_t**2 * np.eye(2), size=n_t_half)\n    z_t1 = rng.multivariate_normal(mu_t1, sigma_t**2 * np.eye(2), size=n_t - n_t_half)\n    \n    Z_t = np.vstack((z_t0, z_t1))\n    Y_t = np.hstack((np.zeros(n_t_half), np.ones(n_t - n_t_half)))\n    \n    return Z_s, Y_s, Z_t, Y_t\n\ndef sinkhorn_knopp(C, epsilon, n_s, n_t, num_iter=100):\n    \"\"\"Solves entropically regularized OT using Sinkhorn-Knopp.\"\"\"\n    a = np.full(n_s, 1.0 / n_s)\n    b = np.full(n_t, 1.0 / n_t)\n    \n    K = np.exp(-C / epsilon)\n    v = np.ones(n_t)\n    \n    for _ in range(num_iter):\n        u = a / (K @ v)\n        v = b / (K.T @ u)\n        \n    pi = np.diag(u) @ K @ np.diag(v)\n    return pi\n\ndef ot_align(Z_s, Z_t, epsilon):\n    \"\"\"Aligns source features to target features using Optimal Transport.\"\"\"\n    n_s = Z_s.shape[0]\n    n_t = Z_t.shape[0]\n    \n    C = cdist(Z_s, Z_t, 'sqeuclidean')\n    pi = sinkhorn_knopp(C, epsilon, n_s, n_t)\n    \n    Z_s_ot = (n_s * pi) @ Z_t\n    return Z_s_ot\n\ndef mmd_align(Z_s, Z_t):\n    \"\"\"Aligns source features to target features by matching means (linear MMD).\"\"\"\n    mean_s = np.mean(Z_s, axis=0)\n    mean_t = np.mean(Z_t, axis=0)\n    \n    translation = mean_t - mean_s\n    Z_s_mmd = Z_s + translation\n    return Z_s_mmd\n\ndef train_logistic_regression(X, y, epochs, lr):\n    \"\"\"Trains a logistic regression classifier using gradient descent.\"\"\"\n    n_samples, n_features = X.shape\n    w = np.zeros(n_features)\n    b = 0.0\n    \n    y = y.reshape(-1, 1)\n\n    for _ in range(epochs):\n        linear_model = (X @ w + b).reshape(-1, 1)\n        y_pred = 1 / (1 + np.exp(-linear_model))\n        \n        dw = (1 / n_samples) * (X.T @ (y_pred - y))\n        db = (1 / n_samples) * np.sum(y_pred - y)\n        \n        w -= lr * dw.flatten()\n        b -= lr * db\n\n    return w, b\n\ndef predict_and_evaluate(X, y, w, b):\n    \"\"\"Makes predictions and computes accuracy.\"\"\"\n    linear_model = (X @ w + b).reshape(-1, 1)\n    y_pred_prob = 1 / (1 + np.exp(-linear_model))\n    y_pred_class = (y_pred_prob > 0.5).astype(int)\n    \n    accuracy = np.mean(y_pred_class.flatten() == y.flatten())\n    return accuracy\n\ndef solve():\n    test_cases = [\n        (60, 60, 0.4, 0.4, 0.5, 1.0, 0.5, 0.2, 200, 0.1),\n        (60, 60, 0.4, 0.4, 0.0, 0.0, 0.0, 0.2, 200, 0.1),\n        (80, 80, 0.4, 0.6, 1.0, 2.0, -1.0, 0.3, 250, 0.08),\n        (12, 12, 0.5, 0.5, 0.8, 1.5, 1.5, 0.25, 300, 0.12),\n    ]\n\n    results = []\n    for i, params in enumerate(test_cases):\n        n_s, n_t, sigma_s, sigma_t, alpha, t_x, t_y, epsilon, epochs, lr = params\n        seed = 10 + i\n        \n        Z_s, Y_s, Z_t, Y_t = generate_data(n_s, n_t, sigma_s, sigma_t, alpha, t_x, t_y, seed)\n        \n        # OT path\n        Z_s_ot = ot_align(Z_s, Z_t, epsilon)\n        w_ot, b_ot = train_logistic_regression(Z_s_ot, Y_s, epochs, lr)\n        acc_ot = predict_and_evaluate(Z_t, Y_t, w_ot, b_ot)\n        \n        # MMD path\n        Z_s_mmd = mmd_align(Z_s, Z_t)\n        w_mmd, b_mmd = train_logistic_regression(Z_s_mmd, Y_s, epochs, lr)\n        acc_mmd = predict_and_evaluate(Z_t, Y_t, w_mmd, b_mmd)\n        \n        accuracy_improvement = acc_ot - acc_mmd\n        results.append(accuracy_improvement)\n\n    print(f\"[{','.join(f'{r:.4f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}