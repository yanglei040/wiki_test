{
    "hands_on_practices": [
        {
            "introduction": "理论上，梯度下降法可以优化任何可微的损失函数。但在实践中，特别是在使用有限精度浮点数（如 32 位浮点数）的计算机上，模型的数值稳定性是一个核心问题。这个练习将通过一个精心设计的实验，让你亲手揭示当目标值（labels）尺度非常大时，梯度如何“爆炸”并导致训练失败，并探索如何通过目标标准化或梯度归一化来有效预防这种数值不稳定问题 。",
            "id": "3178853",
            "problem": "你需要设计并分析一个最小化的监督学习回归实验，该实验旨在展示，在使用平方欧几里得损失（也称为 $L_2$ 损失）时，当目标值极大时，梯度的量级会如何变得数值不稳定，以及两种标准补救措施——目标标准化和梯度归一化——如何防止这种不稳定性。请在以下数学定义的环境中进行操作。\n\n数据集构建与模型：\n- 考虑一个标量线性模型，其参数为 $w \\in \\mathbb{R}$，预测值为 $\\hat{y}_i = w x_i$。\n- 构建一个包含 $N$ 个点的确定性数据集，其中 $N = 200$。令 $x_i$ 在区间 $\\left[-5, 5\\right]$ 内均匀分布，其中 $i = 1, \\dots, N$。\n- 固定一个基准真相标量 $w_\\star = 2$。对于给定的尺度 $s  0$，通过 $y_i = s \\cdot w_\\star \\cdot x_i$ 为每个 $i$ 定义目标值。\n- 所有训练计算均使用单精度浮点数（$32$位，IEEE $754$），以便观察到有限精度效应。\n\n损失与梯度：\n- 使用均方误差（平方 $L_2$ 损失） $$J(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\left(\\hat{y}_i - y_i\\right)^2.$$ \n- 从 $w^{(0)} = 0$ 开始，使用恒定步长（学习率）$\\alpha$ 执行 $T$ 步梯度下降：\n  $$w^{(t+1)} = w^{(t)} - \\alpha \\cdot \\nabla J\\left(w^{(t)}\\right), \\quad t = 0, 1, \\dots, T-1.$$\n- 在实现之前，你必须从基本定义出发，推导出此模型的 $\\nabla J(w)$ 的解析表达式。不要假设任何“快捷”公式。\n\n不稳定性定义与诊断：\n- 如果在任何迭代中，以单精度计算的训练状态出现以下任一情况，则认为一次运行是不稳定的：损失、参数或梯度中出现非有限数（Not-a-Number 或无穷大）。这对应于检测到数值溢出或无效操作。\n- 为了在不引起诊断溢出的情况下评估单调改进，还需要计算一个尺度不变的代理损失\n  $$\\tilde{J}(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\left(\\frac{\\hat{y}_i - y_i}{M}\\right)^2,$$\n  其中 $M = \\max_i |y_i|$ 在训练前以双精度（$64$位）计算，然后被视为一个常数；评估 $\\tilde{J}(w)$ 时，涉及 $w$、$x_i$ 和 $y_i$ 的算术运算使用单精度，但除以从双精度常数 $M$ 转换过来的单精度值。这个代理损失不会改变训练过程，并能避免诊断本身的溢出。如果一次运行保持有限，并且 $\\tilde{J}(w)$ 在迭代过程中非递增（在容差 $\\varepsilon = 10^{-6}$ 内），且至少严格减少一次，则认为该运行是稳定改进的。\n\n需要实现的补救措施：\n- 目标标准化：计算标准化目标 $y^{\\mathrm{std}}_i = \\left(y_i - \\mu_y\\right)/\\sigma_y$，其中 $\\mu_y$ 是 $y_i$ 的均值，$\\sigma_y$ 是 $y_i$ 的标准差。为避免在计算这些统计数据时因 $s$ 值过大而导致溢出，请使用双精度（$64$位 IEEE $754$）计算 $\\mu_y$ 和 $\\sigma_y$，然后将 $y^{\\mathrm{std}}_i$ 转换为单精度进行训练。使用相同的 $\\alpha$ 和 $T$，通过单精度梯度下降法在 $(x_i, y^{\\mathrm{std}}_i)$ 上训练同一个标量线性模型。\n- 通过逐样本裁剪进行梯度归一化：对于原始（未标准化的）目标，计算每个样本对损失函数关于 $w$ 的梯度的贡献，在求和前将每个贡献裁剪到选定的量级，然后取平均以形成批量梯度。这里的所有操作，包括裁剪和求和，都必须以单精度进行。\n\n测试套件：\n使用以下参数值进行四次运行，以共同测试无保护情况下的不稳定性、两种补救措施以及一个良性基线。\n- 数据集大小与输入：$N = 200$，$x_i$ 在 $\\left[-5, 5\\right]$ 内均匀分布。\n- 基准真相与初始化：$w_\\star = 2$，$w^{(0)} = 0$。\n- 训练超参数：学习率 $\\alpha = 0.05$，迭代次数 $T = 60$，容差 $\\varepsilon = 10^{-6}$。\n- 大规模数据集（在单精度下有意设置为危险值）：$s_{\\mathrm{large}} = 10^{36}$。\n- 小规模数据集（良性）：$s_{\\mathrm{small}} = 1$。\n- 用于逐样本归一化的梯度裁剪阈值：$g_{\\mathrm{clip}} = 10^{34}$。\n\n对于每次运行，在以下四种场景下实现全批量梯度下降：\n- 场景 A（未标准化，大规模）：在 $y_i = s_{\\mathrm{large}} \\cdot w_\\star \\cdot x_i$ 上使用朴素的全批量梯度（无归一化）进行训练。\n- 场景 B（目标标准化，大规模）：使用双精度统计数据从相同的大规模 $y_i$ 计算标准化目标，转换为单精度，然后使用朴素梯度在标准化目标上进行训练。\n- 场景 C（逐样本梯度裁剪，大规模）：在相同的大规模 $y_i$ 上进行训练，在求平均之前，以单精度将逐样本的梯度贡献裁剪到量级 $g_{\\mathrm{clip}}$。\n- 场景 D（未标准化，小规模）：在 $y_i = s_{\\mathrm{small}} \\cdot w_\\star \\cdot x_i$ 上使用朴素的全批量梯度（无归一化）进行训练。\n\n答案规格：\n- 对于场景 A，输出一个布尔值，指示是否发生不稳定性（如果不稳定则为 true）。\n- 对于场景 B，输出一个布尔值，指示运行是否如上文所定义的那样稳定改进（如果稳定且改进则为 true）。\n- 对于场景 C，输出一个布尔值，指示运行是否如上文所定义的那样稳定改进（如果稳定且改进则为 true）。\n- 对于场景 D，输出一个布尔值，指示运行是否如上文所定义的那样稳定改进（如果稳定且改进则为 true）。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含按 $\\left[\\text{A}, \\text{B}, \\text{C}, \\text{D}\\right]$ 顺序排列的四个布尔结果，格式为方括号内以逗号分隔的列表，例如 $[{\\tt True},{\\tt False},{\\tt True},{\\tt True}]$。",
            "solution": "问题陈述是一个定义明确的数值实验，旨在研究有限精度算术在监督学习背景下对基于梯度的优化的影响。它具有科学依据、客观，并提供了解决问题所需的所有必要规格。因此，这是一个有效的问题。\n\n我们从第一性原理出发，给出一个完整的解决方案。\n\n### 基本定义与梯度推导\n\n该分析基于一个标量线性模型，其中对于输入 $x_i$ 的预测 $\\hat{y}_i$ 由单个参数 $w \\in \\mathbb{R}$ 生成：\n$$\n\\hat{y}_i = w x_i\n$$\n目标是最小化数据集 $N$ 个点 $(x_i, y_i)$ 上的均方误差 (MSE) 损失函数 $J(w)$：\n$$\nJ(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\left(\\hat{y}_i - y_i\\right)^2 = \\frac{1}{N}\\sum_{i=1}^{N} \\left(w x_i - y_i\\right)^2\n$$\n参数 $w$ 通过梯度下降进行更新。梯度 $\\nabla J(w)$ 是损失函数关于参数 $w$ 的导数。我们从 $J(w)$ 的定义推导出它：\n$$\n\\nabla J(w) = \\frac{dJ}{dw} = \\frac{d}{dw} \\left( \\frac{1}{N}\\sum_{i=1}^{N} (w x_i - y_i)^2 \\right)\n$$\n根据微分的线性性质，我们可以将导数移到求和符号内：\n$$\n\\nabla J(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{d}{dw} (w x_i - y_i)^2\n$$\n应用链式法则，其中外函数是 $u^2$，内函数是 $u(w) = w x_i - y_i$：\n$$\n\\frac{d}{dw} (w x_i - y_i)^2 = 2(w x_i - y_i) \\cdot \\frac{d}{dw}(w x_i - y_i) = 2(w x_i - y_i) \\cdot x_i\n$$\n将其代回，得到全批量梯度的表达式：\n$$\n\\nabla J(w) = \\frac{2}{N}\\sum_{i=1}^{N} (w x_i - y_i) x_i\n$$\n在迭代次数为 $t$ 时，使用学习率 $\\alpha$ 对 $w$ 进行梯度下降的更新规则是：\n$$\nw^{(t+1)} = w^{(t)} - \\alpha \\cdot \\nabla J\\left(w^{(t)}\\right)\n$$\n所有训练计算都使用单精度浮点数（$32$位 IEEE $754$），其范围和精度有限。可表示的最大有限值约为 $3.4 \\times 10^{38}$。导致更大值的操作将导致数值溢出，产生无穷大 (`inf`)。\n\n### 场景分析\n\n**场景 A（未标准化，大规模）：**\n在这里，目标是 $y_i = s_{\\mathrm{large}} \\cdot w_\\star \\cdot x_i$，其中 $s_{\\mathrm{large}} = 10^{36}$ 且 $w_\\star = 2$。$x_i$ 的最大绝对值为 $5$。\n目标值的最大量级是 $|y_i|_{\\max} = 10^{36} \\cdot 2 \\cdot 5 = 10^{37}$。这个值在单精度下是可表示的。\n然而，在计算损失和梯度期间会出现不稳定性。在第一次迭代（$t=0$）时，$w^{(0)} = 0$。单个样本的平方误差为：\n$$\n\\left(w^{(0)} x_i - y_i\\right)^2 = (-y_i)^2 = y_i^2\n$$\n对于具有最大目标量级的样本，这将变为 $(10^{37})^2 = 10^{74}$。这远远超过了单精度极限 $\\approx 3.4 \\times 10^{38}$，导致溢出为 `inf`。因此，损失 $J(w^{(0)})$ 将为 `inf`。\n类似地，对未求和梯度的逐样本贡献是 $2(w^{(0)}x_i - y_i)x_i = -2y_ix_i$。最大量级为 $|-2 \\cdot (10^{36} \\cdot 2 \\cdot 5) \\cdot 5| = 10^{38}$。虽然这个单项可能是可表示的，但将许多这样的大数相加也可能导致溢出。关键是，损失计算中的溢出足以将该次运行归类为不稳定。\n**预期结果：`True`（发生不稳定性）。**\n\n**场景 B（目标标准化，大规模）：**\n这种补救措施预先重新缩放了目标。标准化是使用双精度（$64$位）算术执行的，以避免在计算统计数据时发生溢出。标准化的目标是：\n$$\ny^{\\mathrm{std}}_i = \\frac{y_i - \\mu_y}{\\sigma_y}\n$$\n其中 $\\mu_y$ 和 $\\sigma_y$ 是原始大规模目标 $y_i$ 的均值和标准差。由于 $x_i$ 关于 $0$ 对称，均值 $\\mu_y = \\mathbb{E}[s w_\\star x_i]$ 为 $0$。标准差为 $\\sigma_y = |s w_\\star| \\sigma_x$。\n然后在新数据集 $(x_i, y^{\\mathrm{std}}_i)$ 上进行训练。参数 $w$ 的新目标是 $w^{\\mathrm{std}}_\\star = (s w_\\star)/\\sigma_y = \\text{sign}(s w_\\star)/\\sigma_x$。对于给定的 $x_i$，$\\sigma_x \\approx 2.89$，所以 $w^{\\mathrm{std}}_\\star \\approx 1/2.89 \\approx 0.346$。\n训练过程中的所有值——参数、目标、预测、损失、梯度——现在的量级都很小且易于管理。学习率 $\\alpha=0.05$ 对于这个良态凸问题是合适的，可以确保单调收敛。运行将是有限的。代理损失 $\\tilde{J}(w)$ 在原始尺度上衡量性能，它将是非递增的，并将从其初始值严格减小。\n**预期结果：`True`（运行是稳定改进的）。**\n\n**场景 C（逐样本梯度裁剪，大规模）：**\n这种补救措施直接处理梯度量级问题。逐样本的梯度贡献是 $g_i(w) = 2(wx_i - y_i)x_i$。\n在 $t=0$ 时，$w^{(0)}=0$，所以 $g_i(w^{(0)}) = -2y_ix_i = -2(s w_\\star x_i)x_i = -2 s w_\\star x_i^2$。这些贡献的量级可以大到 $|-2 \\cdot 10^{36} \\cdot 2 \\cdot 5^2| = 10^{38}$，这接近单精度极限，但本身可能不会溢出。\n然而，这些值被裁剪到范围 $[-g_{\\mathrm{clip}}, g_{\\mathrm{clip}}]$ 内，其中 $g_{\\mathrm{clip}} = 10^{34}$。由于 $|g_i(w^{(0)})|  g_{\\mathrm{clip}}$，每个非零贡献都会被裁剪。梯度变为 $\\nabla J(w) \\approx -g_{\\mathrm{clip}}$。\n第一次更新是 $w^{(1)} = w^{(0)} - \\alpha \\cdot \\nabla J(w^{(0)}) \\approx 0 - 0.05 \\cdot (-10^{34}) = 5 \\times 10^{32}$。\n参数 $w$ 的更新保持有限。尽管梯度信息已饱和，但方向是正确的（将 $w$ 朝着正目标 $s w_\\star$ 增加）。损失将在每一步减少，尽管不是最优的。运行将保持有限，代理损失将是非递增的。\n**预期结果：`True`（运行是稳定改进的）。**\n\n**场景 D（未标准化，小规模）：**\n这是一个良性基线。尺度为 $s_{\\mathrm{small}}=1$。目标是 $y_i = 2x_i$。所有的值都很小。最大目标量级为 $10$。没有数值溢出的风险。该问题在几何上与场景 B 相同，只是目标参数的缩放不同（$w_\\star=2$ 而不是 $w^{\\mathrm{std}}_\\star \\approx 0.346$）。在一个安全的学习率下，梯度下降将顺利进行，呈现单调收敛。\n**预期结果：`True`（运行是稳定改进的）。**",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Designs and runs a supervised learning regression experiment to demonstrate\n    numerical instability and remedies in gradient descent.\n    \"\"\"\n    # Global parameters from the problem\n    N = 200\n    W_STAR = 2.0\n    W0 = 0.0\n    ALPHA = 0.05\n    T = 60\n    EPSILON = 1e-6\n    S_LARGE = 1e36\n    S_SMALL = 1.0\n    G_CLIP = 1e34\n\n    # Data types\n    F32 = np.float32\n    F64 = np.float64\n\n    # Common dataset generation\n    x_64 = np.linspace(-5, 5, N, dtype=F64)\n    x_32 = x_64.astype(F32)\n\n    y_large_64 = S_LARGE * W_STAR * x_64\n    y_large_32 = y_large_64.astype(F32)\n\n    y_small_64 = S_SMALL * W_STAR * x_64\n    y_small_32 = y_small_64.astype(F32)\n\n    def run_scenario_A():\n        w = F32(W0)\n        x = x_32\n        y = y_large_32\n        \n        for _ in range(T):\n            if not np.isfinite(w): return True\n            y_hat = w * x\n            errors = y_hat - y\n            loss = np.mean(errors**2)\n            if not np.isfinite(loss): return True\n            grad = np.mean(F32(2.0) * errors * x)\n            if not np.isfinite(grad): return True\n            w = w - F32(ALPHA) * grad\n        \n        return not np.isfinite(w)\n\n    def run_scenario_B():\n        mu_y_64 = np.mean(y_large_64)\n        sigma_y_64 = np.std(y_large_64)\n        \n        y_std_64 = (y_large_64 - mu_y_64) / sigma_y_64 if sigma_y_64 != 0 else y_large_64 - mu_y_64\n        y_train = y_std_64.astype(F32)\n        x = x_32\n        \n        M_64 = np.max(np.abs(y_large_64))\n        M_32 = F32(M_64)\n        mu_y_32 = F32(mu_y_64)\n        sigma_y_32 = F32(sigma_y_64)\n\n        w = F32(W0)\n        proxy_losses = []\n        is_finite_run = True\n\n        for t in range(T + 1):\n            w_unstd = w * sigma_y_32\n            y_hat_unstd = w_unstd * x + mu_y_32\n            errors_orig_scale = y_hat_unstd - y_large_32\n            \n            proxy_loss = np.mean((errors_orig_scale / M_32)**2) if M_32 != 0 else np.mean(errors_orig_scale**2)\n            \n            if not np.isfinite(proxy_loss):\n                is_finite_run = False\n                break\n            proxy_losses.append(proxy_loss)\n            \n            if t == T: break\n\n            y_hat = w * x\n            errors = y_hat - y_train\n            loss = np.mean(errors**2)\n            grad = np.mean(F32(2.0) * errors * x)\n            \n            if not (np.isfinite(w) and np.isfinite(loss) and np.isfinite(grad)):\n                is_finite_run = False\n                break\n            w = w - F32(ALPHA) * grad\n        \n        if not is_finite_run: return False\n\n        is_non_increasing = all(proxy_losses[i+1] = proxy_losses[i] + EPSILON for i in range(T))\n        has_decreased = any(proxy_losses[i+1]  proxy_losses[i] for i in range(T))\n            \n        return is_non_increasing and has_decreased\n\n    def run_scenario_C():\n        w = F32(W0)\n        x = x_32\n        y = y_large_32\n        M_64 = np.max(np.abs(y_large_64))\n        M_32 = F32(M_64)\n        clip_val = F32(G_CLIP)\n        \n        proxy_losses = []\n        is_finite_run = True\n\n        for t in range(T + 1):\n            y_hat = w * x\n            errors = y_hat - y\n            proxy_loss = np.mean((errors / M_32)**2) if M_32 != 0 else np.mean(errors**2)\n            if not np.isfinite(proxy_loss):\n                is_finite_run = False\n                break\n            proxy_losses.append(proxy_loss)\n\n            if t == T: break\n\n            loss = np.mean(errors**2)\n            grad_contribs = F32(2.0) * errors * x\n            clipped_contribs = np.clip(grad_contribs, -clip_val, clip_val)\n            grad = np.mean(clipped_contribs)\n\n            if not (np.isfinite(w) and np.isfinite(loss) and np.isfinite(grad)):\n                is_finite_run = False\n                break\n            w = w - F32(ALPHA) * grad\n        \n        if not is_finite_run: return False\n\n        is_non_increasing = all(proxy_losses[i+1] = proxy_losses[i] + EPSILON for i in range(T))\n        has_decreased = any(proxy_losses[i+1]  proxy_losses[i] for i in range(T))\n            \n        return is_non_increasing and has_decreased\n\n    def run_scenario_D():\n        w = F32(W0)\n        x = x_32\n        y = y_small_32\n        M_64 = np.max(np.abs(y_small_64))\n        M_32 = F32(M_64)\n        \n        proxy_losses = []\n        is_finite_run = True\n\n        for t in range(T + 1):\n            y_hat = w * x\n            errors = y_hat - y\n            proxy_loss = np.mean((errors / M_32)**2) if M_32 != 0 else np.mean(errors**2)\n            if not np.isfinite(proxy_loss):\n                is_finite_run = False\n                break\n            proxy_losses.append(proxy_loss)\n\n            if t == T: break\n            \n            loss = np.mean(errors**2)\n            grad = np.mean(F32(2.0) * errors * x)\n\n            if not (np.isfinite(w) and np.isfinite(loss) and np.isfinite(grad)):\n                is_finite_run = False\n                break\n            w = w - F32(ALPHA) * grad\n\n        if not is_finite_run: return False\n\n        is_non_increasing = all(proxy_losses[i+1] = proxy_losses[i] + EPSILON for i in range(T))\n        has_decreased = any(proxy_losses[i+1]  proxy_losses[i] for i in range(T))\n        \n        return is_non_increasing and has_decreased\n\n    results = [\n        run_scenario_A(),\n        run_scenario_B(),\n        run_scenario_C(),\n        run_scenario_D(),\n    ]\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "数据中的异常值（outliers）是导致训练不稳定的另一个常见原因，它们会产生巨大的损失和梯度，从而扰乱优化过程。虽然上一个练习中的标准化可以处理整体尺度问题，但它对孤立的极端异常值不够鲁棒。本练习将引导你实现梯度裁剪（gradient clipping）——一种在训练期间直接控制梯度大小的强大技术，并量化评估不同裁剪阈值对模型稳定性和最终性能的影响 。",
            "id": "3178891",
            "problem": "您将实现并分析一个深度学习中的监督学习回归任务，该任务在一个包含极端目标值离群值的合成数据集上，使用带有梯度裁剪的全批量梯度下降法。该模型是一个标量线性预测器 $f_{\\theta}(x) = w x + b$，通过最小化由 $N$ 个独立同分布样本的均方误差给出的经验风险进行训练。请使用以下基本定义和假设，不要引入任何未经检验的捷径或预先推导的训练公式：\n\n- 经验风险最小化（均方误差）：给定数据 $\\{(x_i, y_i)\\}_{i=1}^N$，将经验风险定义为\n$$\nR(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(f_{\\theta}(x_i) - y_i\\right)^2.\n$$\n\n- 梯度下降动力学：参数向量通过以下方式进行迭代更新\n$$\n\\theta_{t+1} = \\theta_t - \\alpha \\, \\tilde{g}_t,\n$$\n其中 $\\alpha$ 是学习率，$\\tilde{g}_t$ 是第 $t$ 次迭代时裁剪后的梯度向量。\n\n- 梯度裁剪要求：在每次迭代中，通过重新缩放来裁剪梯度，使其欧几里得范数不超过指定的阈值 $c$。也就是说，如果原始梯度 $g_t$ 的欧几里得范数超过 $c$，则将其缩小，使得 $\\tilde{g}_t$ 的欧几里得范数等于 $c$；否则，保持不变。不要使用任何启发式替代方法；请精确地按照规定实现基于范数的裁剪。\n\n- 均方根误差 (RMSE)：报告最终训练均方根误差，其定义为\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}\\left(f_{\\theta}(x_i) - y_i\\right)^2}.\n$$\n\n数据生成与训练协议：\n- 生成 $N = 200$ 个样本，固定随机种子为 $42$ 以确保可复现性。\n- 从标准正态分布 $\\mathcal{N}(0,1)$ 中独立抽取输入 $x_i$。\n- 设真实线性关系为 $y_i^\\star = w^\\star x_i + b^\\star + \\epsilon_i$，其中 $w^\\star = 2$，$b^\\star = -0.5$，以及独立噪声 $\\epsilon_i \\sim \\mathcal{N}(0, 0.1^2)$。\n- 通过均匀随机选择比例为 $p_{\\text{out}} = 0.1$ 的索引，并将其目标值替换为 $y_i \\leftarrow s_i \\cdot O$，来引入极端目标离群值。其中 $s_i \\in \\{-1, +1\\}$ 是独立的随机符号，$O = 10^6$ 是离群值幅度。\n- 将参数初始化为 $w_0 = 0$ 和 $b_0 = 0$。\n- 使用固定学习率 $\\alpha = 1.0$。\n- 进行 $T = 200$ 次全批量梯度下降迭代训练。在每次迭代中：\n  - 计算 $R(\\theta_t)$ 关于 $(w, b)$ 的原始梯度 $g_t$。\n  - 计算其欧几里得范数，并在裁剪前记录下来。\n  - 在阈值 $c$ 处应用基于范数的裁剪以获得 $\\tilde{g}_t$。\n  - 使用裁剪后的梯度更新参数。\n\n优化稳定性准则：\n- 令 $R_0$ 表示在 $(w_0, b_0)$ 处的初始 RMSE，令 $R_T$ 表示在 $T$ 次迭代后于 $(w_T, b_T)$ 处的最终 RMSE。\n- 当且仅当 $R_T \\le R_0$ 且在整个训练过程中所有 RMSE 值和参数均保持有限（无非数值）时，定义该训练运行是稳定的。\n\n任务：\n- 对每个指定的裁剪阈值 $c$，运行训练协议并计算：\n  1. 最终的 RMSE $R_T$，作为浮点数。\n  2. 在所有迭代中观察到的裁剪前梯度欧几里得范数的最大值，作为浮点数。\n  3. 根据上述准则得出的稳定性布尔值。\n\n测试套件：\n- 评估以下五个裁剪阈值：\n  - $c = 0.0$ (完全裁剪为零)，\n  - $c = 0.1$ (非常激进的裁剪)，\n  - $c = 1.0$ (激进的裁剪)，\n  - $c = 10.0$ (适度裁剪)，\n  - $c = +\\infty$ (不裁剪)。\n这些情况涵盖了一个边界情况、几个小阈值、一个适中阈值以及不裁剪的极端情况。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。列表中的每个条目对应于上述顺序的一个测试用例，并且其本身是一个包含三个元素的列表，顺序为：最终 RMSE (浮点数)、最大裁剪前梯度范数 (浮点数)、稳定性 (布尔值)。例如，输出应如下所示\n$$\n[[r_1, g_1, b_1], [r_2, g_2, b_2], [r_3, g_3, b_3], [r_4, g_4, b_4], [r_5, g_5, b_5]],\n$$\n不带任何额外文本。不涉及物理单位；值为无量纲的实数和布尔值。不使用角度。在编程语言中将所有布尔值表示为字面上的 true 或 false 值。浮点数必须以其默认的十进制表示法打印，不超出语言默认设置的舍入指令。",
            "solution": "该问题要求在一个包含极端离群值的合成数据集上，实现并分析一个使用全批量梯度下降法训练的简单线性回归模型。任务的核心是研究梯度裁剪对训练过程稳定性和性能的影响。\n\n模型是一个标量线性函数 $f_{\\theta}(x) = w x + b$，其中参数向量为 $\\theta = (w, b)$。目标是找到最小化经验风险的参数，该经验风险定义为 $N$ 个样本 $\\{(x_i, y_i)\\}_{i=1}^N$ 数据集上的均方误差 (MSE)：\n$$\nR(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(f_{\\theta}(x_i) - y_i\\right)^2 = \\frac{1}{N} \\sum_{i=1}^{N} \\left(w x_i + b - y_i\\right)^2\n$$\n参数通过梯度下降法进行迭代更新。对于全批量梯度下降，风险的梯度 $g_t = \\nabla_{\\theta} R(\\theta_t)$ 在每次迭代 $t$ 中使用整个数据集计算。梯度向量 $g_t = (g_{t,w}, g_{t,b})$ 的分量是 $R(\\theta)$ 关于 $w$ 和 $b$ 的偏导数：\n$$\ng_{t,w} = \\frac{\\partial R}{\\partial w}\\bigg|_{\\theta_t} = \\frac{2}{N} \\sum_{i=1}^{N} (w_t x_i + b_t - y_i) x_i\n$$\n$$\ng_{t,b} = \\frac{\\partial R}{\\partial b}\\bigg|_{\\theta_t} = \\frac{2}{N} \\sum_{i=1}^{N} (w_t x_i + b_t - y_i)\n$$\n目标值 $y_i$ 中极端离群值的存在，可能导致这些数据点的残差 $(f_{\\theta}(x_i) - y_i)$ 变得异常大。这反过来又会导致梯度具有巨大的量级（一种称为梯度爆炸的现象），从而可能破坏训练过程的稳定性。一个大的梯度步长可能导致参数急剧“超调”最小值，可能导致浮点溢出和优化完全失败。\n\n梯度裁剪是对抗这种不稳定性的标准技术。它涉及约束梯度向量的量级。具体来说，我们将实现基于范数的裁剪。首先，计算原始梯度的欧几里得范数 $\\|g_t\\|_2 = \\sqrt{g_{t,w}^2 + g_{t,b}^2}$。然后，根据阈值 $c$ 确定裁剪后的梯度 $\\tilde{g}_t$：\n$$\n\\tilde{g}_t =\n\\begin{cases}\ng_t  \\text{if } \\|g_t\\|_2 \\le c \\\\\nc \\frac{g_t}{\\|g_t\\|_2}  \\text{if } \\|g_t\\|_2 > c\n\\end{cases}\n$$\n这可以更紧凑地写为 $\\tilde{g}_t = \\min\\left(1, \\frac{c}{\\|g_t\\|_2}\\right) g_t$，并理解为如果 $\\|g_t\\|_2 = 0$，则缩放因子为 $1$。如果发生裁剪，梯度的方向被保留，但其量级被缩小到最大为 $c$。然后参数更新规则使用这个裁剪后的梯度：\n$$\n\\theta_{t+1} = \\theta_t - \\alpha \\tilde{g}_t\n$$\n其中 $\\alpha$ 是学习率。\n\n实现将按以下步骤进行：\n1.  **数据生成**：创建一个包含 $N=200$ 个点的合成数据集。输入 $x_i$ 从标准正态分布中抽取。初始目标 $y_i^\\star$ 由真实线性关系 $y_i^\\star = 2x_i - 0.5 + \\epsilon_i$ 生成，其中 $\\epsilon_i$ 是小的高斯噪声。然后，将这些目标中的一部分（比例为 $p_{\\text{out}}=0.1$）替换为幅度为 $O=10^6$ 的极端值，以创建离群值。使用固定的随机种子可确保可复现性。\n2.  **训练**：对每个指定的裁剪阈值 $c$，执行一个包含 $T=200$ 次迭代的完整训练过程。\n    -   参数初始化为 $w_0=0, b_0=0$。\n    -   计算初始均方根误差 (RMSE)，$R_0 = \\sqrt{R(w_0, b_0)}$。\n    -   在每次迭代中，计算全批量梯度 $g_t$。记录其裁剪前的范数 $\\|g_t\\|_2$，并跟踪观察到的最大范数。\n    -   根据上述规则对梯度进行裁剪，并使用裁剪后的梯度和学习率 $\\alpha=1.0$ 更新参数 $(w, b)$。\n    -   在整个训练循环中，监控所有参数和中间值是否为非有限数（NaN 或 infinity），以检测不稳定性。\n3.  **评估**：在 $T$ 次迭代后，计算最终的 RMSE，$R_T$。当且仅当 $R_T \\le R_0$ 且在训练过程中没有遇到非有限值时，该训练运行被认为是稳定的。\n4.  **报告**：对每个 $c$ 值，编制一个列表，其中包含最终的 RMSE、观察到的最大裁剪前梯度范数以及稳定性布尔值。最终输出是这些列表的列表。\n\n该程序允许系统性地评估不同级别的裁剪——从完全抑制 ($c=0$) 到不裁剪 ($c=\\infty$)——如何影响梯度下降算法在存在极端数据损坏情况下的学习能力。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes a linear regression task using full-batch gradient descent\n    with gradient clipping on a dataset with extreme outliers.\n    \"\"\"\n    \n    # ------------------\n    # Problem Definition\n    # ------------------\n    # Data generation parameters\n    N = 200\n    w_star, b_star = 2.0, -0.5\n    noise_std = 0.1\n    p_out = 0.1\n    O = 1e6\n    seed = 42\n    \n    # Training hyperparameters\n    w0, b0 = 0.0, 0.0\n    alpha = 1.0\n    T = 200\n    \n    # Test suite for clipping thresholds\n    clip_thresholds = [0.0, 0.1, 1.0, 10.0, np.inf]\n\n    # ------------------\n    # Data Generation\n    # ------------------\n    rng = np.random.default_rng(seed)\n    x = rng.normal(loc=0.0, scale=1.0, size=N)\n    epsilon = rng.normal(loc=0.0, scale=noise_std, size=N)\n    y_star = w_star * x + b_star + epsilon\n    \n    y = np.copy(y_star)\n    n_outliers = int(N * p_out)\n    outlier_indices = rng.choice(N, size=n_outliers, replace=False)\n    signs = rng.choice([-1, 1], size=n_outliers)\n    y[outlier_indices] = signs * O\n\n    final_results = []\n    \n    # ------------------\n    # Main Loop over Test Cases\n    # ------------------\n    for c in clip_thresholds:\n        # Initialize parameters for the current run\n        w, b = w0, b0\n        max_grad_norm = 0.0\n        is_stable = True\n        \n        # Calculate initial RMSE (R0)\n        y_pred_initial = w * x + b\n        mse_initial = np.mean((y_pred_initial - y)**2)\n        \n        if not np.isfinite(mse_initial):\n            # This case is unlikely with given initial conditions but included for robustness\n            is_stable = False\n            RT = np.nan\n            current_max_grad_norm = np.nan\n            final_results.append([RT, current_max_grad_norm, is_stable])\n            continue\n            \n        R0 = np.sqrt(mse_initial)\n        \n        # Training loop\n        for _ in range(T):\n            # Check for instability from previous iteration\n            if not (np.isfinite(w) and np.isfinite(b)):\n                is_stable = False\n                break\n                \n            # Forward pass: predictions\n            y_pred = w * x + b\n            residuals = y_pred - y\n            \n            # Check for non-finite values in predictions/residuals\n            if not np.all(np.isfinite(residuals)):\n                is_stable = False\n                break\n            \n            # Compute raw gradients\n            grad_w = (2.0 / N) * np.dot(residuals, x)\n            grad_b = (2.0 / N) * np.sum(residuals)\n            \n            # Check for gradient explosion\n            if not (np.isfinite(grad_w) and np.isfinite(grad_b)):\n                is_stable = False\n                # The gradient norm would be inf/nan, so we update max_grad_norm accordingly\n                max_grad_norm = max(max_grad_norm, np.inf)\n                break\n            \n            # Compute and track pre-clipping gradient norm\n            grad_norm = np.sqrt(grad_w**2 + grad_b**2)\n            max_grad_norm = max(max_grad_norm, grad_norm)\n            \n            # Apply gradient clipping\n            if grad_norm > c:\n                # Note: grad_norm > np.inf is always False, handling the no-clipping case.\n                # If grad_norm is 0, this condition is also false for c>=0.\n                scale = c / grad_norm\n                clipped_grad_w = grad_w * scale\n                clipped_grad_b = grad_b * scale\n            else:\n                clipped_grad_w = grad_w\n                clipped_grad_b = grad_b\n            \n            # Update parameters\n            w = w - alpha * clipped_grad_w\n            b = b - alpha * clipped_grad_b\n\n        # ------------------\n        # Post-Training Evaluation\n        # ------------------\n        if is_stable:\n            y_pred_final = w * x + b\n            mse_final = np.mean((y_pred_final - y)**2)\n            RT = np.sqrt(mse_final)\n            # Final stability check\n            if not np.isfinite(RT) or RT > R0:\n                is_stable = False\n                if not np.isfinite(RT):\n                    RT = np.nan\n        else:\n            RT = np.nan\n        \n        # Store results for the current clipping threshold\n        final_results.append([RT, max_grad_norm, is_stable])\n\n    # ------------------\n    # Format Final Output\n    # ------------------\n    output_parts = []\n    for r, g, b in final_results:\n        # np.nan and np.inf have standard string representations 'nan' and 'inf'\n        r_str = str(r)\n        g_str = str(g)\n        b_str = str(b).lower() # Booleans to lowercase 'true'/'false'\n        output_parts.append(f\"[{r_str},{g_str},{b_str}]\")\n        \n    print(f\"[{','.join(output_parts)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了在训练过程中“被动”地修正梯度，我们还可以通过“主动”设计更优的损失函数来从根本上提升模型的鲁棒性。标准的均方误差（$L_2$ 损失）对异常值非常敏感，而其他损失函数，如绝对误差（$L_1$ 损失）或 Huber 损失，则能更好地容忍它们。这个练习将通过一个简化的理论模型，让你定量地比较不同损失函数（$L_1$、Huber 和广义 Charbonnier 损失）在面对对抗性标签噪声时的表现，从而深刻理解鲁棒回归的内在原理 。",
            "id": "3178857",
            "problem": "考虑一个经验风险最小化框架下的监督学习回归任务，其目标是选择一个常数预测值 $\\hat{y} \\in \\mathbb{R}$，以最小化在某个噪声标签模型上的期望损失。设真实标签为 $y = 0$，观测标签为 $y_{\\text{obs}} = y + \\eta$，其中对抗性标签噪声 $\\eta$ 由一个两点分布定义：$\\eta = 0$ 的概率为 $1 - p$，$\\eta = \\delta$ 的概率为 $p$。标量 $p \\in [0,1]$ 是一个以小数或分数形式给出的概率，$\\delta  0$ 是给定的对抗性偏移的幅度。\n\n定义单样本残差为 $r = y_{\\text{obs}} - \\hat{y}$，期望风险为\n$$\nR(\\hat{y};p,\\delta,\\ell) = \\mathbb{E}[\\ell(r)] = (1-p)\\,\\ell(-\\hat{y}) + p\\,\\ell(\\delta - \\hat{y}),\n$$\n其中 $\\ell$ 是所选的损失函数。考虑以下三种损失函数：\n1. 绝对误差损失（通常称为 $\\mathcal{L}_1$ 损失）：$\\ell_{\\mathcal{L}_1}(r) = |r|$。\n2. 带阈值 $\\kappa  0$ 的 Huber 损失：\n$$\n\\ell_{\\text{Huber}}(r;\\kappa) = \n\\begin{cases}\n\\dfrac{1}{2} r^2,  \\text{若 } |r| \\le \\kappa,\\\\\n\\kappa\\left(|r| - \\dfrac{1}{2}\\kappa\\right),  \\text{若 } |r|  \\kappa.\n\\end{cases}\n$$\n本问题使用 $\\kappa = 10$。\n3. 带参数 $\\epsilon  0$ 和 $\\beta \\in (0,1)$ 的广义 Charbonnier 损失：\n$$\n\\ell_{\\text{GC}}(r;\\epsilon,\\beta) = \\left(r^2 + \\epsilon^2\\right)^{\\beta}.\n$$\n本问题使用 $\\epsilon = 1$ 和 $\\beta = 0.45$。\n\n对每种损失函数，定义最优常数预测器\n$$\n\\hat{y}^*_{\\ell}(p,\\delta) \\in \\arg\\min_{\\hat{y} \\in \\mathbb{R}} R(\\hat{y};p,\\delta,\\ell),\n$$\n并将在 $(p,\\delta)$ 下给定损失函数的鲁棒性得分定义为绝对偏差\n$$\nb_{\\ell}(p,\\delta) = \\left|\\hat{y}^*_{\\ell}(p,\\delta) - y\\right| = \\left|\\hat{y}^*_{\\ell}(p,\\delta)\\right|.\n$$\n\n您的任务是实现一个程序，对于下方测试套件中的每个 $(p,\\delta)$，计算与 $\\ell_{\\mathcal{L}_1}$、$\\ell_{\\text{Huber}}$（$\\kappa=10$）以及 $\\ell_{\\text{GC}}$（$\\epsilon=1$ 和 $\\beta=0.45$）相对应的三个鲁棒性得分 $b_{\\mathcal{L}_1}(p,\\delta)$、$b_{\\text{Huber}}(p,\\delta)$ 和 $b_{\\text{GC}}(p,\\delta)$。对于 $\\mathcal{L}_1$ 损失，当 $p = 0.5$ 时，通过选择 $\\hat{y}^*_{\\mathcal{L}_1}(p,\\delta) = 0$ 来解决平局问题。\n\n测试套件：\n- 情况 $1$：$p = 0.1$，$\\delta = 20$。\n- 情况 $2$：$p = 0.4$，$\\delta = 50$。\n- 情况 $3$：$p = 0.6$，$\\delta = 50$。\n- 情况 $4$：$p = 0.9$，$\\delta = 100$。\n- 情况 $5$：$p = 0.0$，$\\delta = 10$。\n- 情况 $6$：$p = 1.0$，$\\delta = 10$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。该外层列表的每个元素对应一个测试用例（按上述顺序排列），其本身是该用例的三个浮点数列表 $[b_{\\mathcal{L}_1}, b_{\\text{Huber}}, b_{\\text{GC}}]$。例如，输出格式必须为\n$$\n[\\,[b_{\\mathcal{L}_1}^{(1)},b_{\\text{Huber}}^{(1)},b_{\\text{GC}}^{(1)}],\\,[b_{\\mathcal{L}_1}^{(2)},b_{\\text{Huber}}^{(2)},b_{\\text{GC}}^{(2)}],\\,\\dots,\\, [b_{\\mathcal{L}_1}^{(6)},b_{\\text{Huber}}^{(6)},b_{\\text{GC}}^{(6)}]\\,].\n$$\n不涉及物理单位。不涉及角度。概率 $p$ 以小数形式给出。输出值为浮点数。",
            "solution": "目标是找到最优常数预测器 $\\hat{y}^*$，以最小化期望风险 $R(\\hat{y})$。风险定义为：\n$$R(\\hat{y};p,\\delta,\\ell) = \\mathbb{E}[\\ell(y_{\\text{obs}} - \\hat{y})] = (1-p)\\,\\ell(-\\hat{y}) + p\\,\\ell(\\delta - \\hat{y})$$\n其中 $y_{\\text{obs}}$ 以 $1-p$ 的概率取值 $0$，以 $p$ 的概率取值 $\\delta$。真实标签为 $y=0$。最优预测器 $\\hat{y}^*$ 是 $\\mathbb{R}$ 中使 $R(\\hat{y})$ 最小化的值。对于所考虑的凸损失函数，可通过将风险关于 $\\hat{y}$ 的导数设为零来找到该最小值。\n\n使用链式法则可以得到风险的导数：\n$$\\frac{d R}{d \\hat{y}} = (1-p) \\frac{d}{d\\hat{y}}\\ell(-\\hat{y}) + p \\frac{d}{d\\hat{y}}\\ell(\\delta - \\hat{y})$$\n$$\\frac{d R}{d \\hat{y}} = (1-p) \\ell'(-\\hat{y}) \\cdot (-1) + p \\ell'(\\delta - \\hat{y}) \\cdot (-1)$$\n$$\\frac{d R}{d \\hat{y}} = - \\left[ (1-p) \\ell'(-\\hat{y}) + p \\ell'(\\delta - \\hat{y}) \\right]$$\n将此导数设为零，得到最优性条件：\n$$(1-p) \\ell'(-\\hat{y}^*) = -p \\ell'(\\delta - \\hat{y}^*)$$\n我们将对三种指定的损失函数分别求解该方程以得到 $\\hat{y}^*$。然后，鲁棒性得分计算为绝对偏差 $b_{\\ell}(p,\\delta) = |\\hat{y}^*_{\\ell}(p,\\delta)|$。\n\n**1. 绝对误差损失 ($\\ell_{\\mathcal{L}_1}(r) = |r|$)**\n\n绝对误差损失的导数是符号函数，$\\ell'_{\\mathcal{L}_1}(r) = \\text{sgn}(r)$。风险函数为 $R(\\hat{y}) = (1-p)|-\\hat{y}| + p|\\delta-\\hat{y}|$。该函数的最小化器是数据点 $0$ 和 $\\delta$ 的加权中位数。基于次梯度的分析证实了这一点。$R(\\hat{y})$ 的次梯度为：\n$$\\partial R(\\hat{y}) = (1-p)\\,\\text{sgn}(\\hat{y}) - p\\,\\text{sgn}(\\delta-\\hat{y})$$\n我们寻找 $\\hat{y}^*$ 使得 $0 \\in \\partial R(\\hat{y}^*)$。假设 $0  \\hat{y}^*  \\delta$，导数为 $1-2p$。\n- 如果 $p  0.5$，则 $1-2p  0$。风险在 $(0, \\delta)$ 上是递增的，因此最小值在 $\\hat{y}^*_{\\mathcal{L}_1} = 0$ 处取得。\n- 如果 $p  0.5$，则 $1-2p  0$。风险在 $(0, \\delta)$ 上是递减的，因此最小值在 $\\hat{y}^*_{\\mathcal{L}_1} = \\delta$ 处取得。\n- 如果 $p = 0.5$，风险在 $[0, \\delta]$ 上是平坦的，意味着此区间内的任何值都是最小化器。问题指定了决胜规则 $\\hat{y}^*_{\\mathcal{L}_1} = 0$。\n因此，最优预测器为：\n$$\\hat{y}^*_{\\mathcal{L}_1}(p,\\delta) = \\begin{cases} 0  \\text{若 } p \\le 0.5 \\\\ \\delta  \\text{若 } p  0.5 \\end{cases}$$\n鲁棒性得分为 $b_{\\mathcal{L}_1}(p,\\delta) = |\\hat{y}^*_{\\mathcal{L}_1}(p,\\delta)|$。\n\n**2. Huber 损失 ($\\ell_{\\text{Huber}}(r; \\kappa)$)**\n\n当 $\\kappa=10$ 时，Huber 损失的导数为 $\\ell'_{\\text{Huber}}(r;10) = \\text{clip}(r, -10, 10)$。最优性条件是：\n$$(1-p)\\,\\text{clip}(-\\hat{y}^*, -10, 10) = -p\\,\\text{clip}(\\delta - \\hat{y}^*, -10, 10)$$\n我们分段分析。我们假设 $0  \\hat{y}^*  \\delta$。\n- **情况1**：两个自变量都在二次区域内：$|\\hat{y}^*| \\le 10$ 和 $|\\delta-\\hat{y}^*| \\le 10$。\n条件变为 $(1-p)(-\\hat{y}^*) = -p(\\delta - \\hat{y}^*)$，可简化为 $\\hat{y}^* = p\\delta$。此解在 $p\\delta \\le 10$ 和 $\\delta(1-p) \\le 10$ 时有效。\n\n- **情况2**：左项是线性的，右项是二次的：$\\hat{y}^*  10$ 和 $\\delta-\\hat{y}^* \\le 10$。\n条件变为 $(1-p)(-10) = -p(\\delta - \\hat{y}^*)$，解得 $\\hat{y}^* = \\delta - \\frac{10(1-p)}{p}$。此情况适用于 $p  0.5$，并且当 $p\\delta  10$ 时，结果与假设一致。\n\n- **情况3**：左项是二次的，右项是线性的：$\\hat{y}^* \\le 10$ 和 $\\delta-\\hat{y}^*  10$。\n条件变为 $(1-p)(-\\hat{y}^*) = -p(10)$，解得 $\\hat{y}^* = \\frac{10p}{1-p}$。此情况适用于 $p  0.5$ 且 $\\delta(1-p)10$。\n\n综合这些情况，得到 $\\hat{y}^*_{\\text{Huber}}$ 的解：\n- 如果 $p \\le 0.5$：\n  $$\\hat{y}^*_{\\text{Huber}} = \\begin{cases} p\\delta  \\text{若 } \\delta(1-p) \\le 10 \\\\ \\frac{10p}{1-p}  \\text{若 } \\delta(1-p)  10 \\end{cases}$$\n- 如果 $p  0.5$：\n  $$\\hat{y}^*_{\\text{Huber}} = \\begin{cases} p\\delta  \\text{若 } p\\delta \\le 10 \\\\ \\delta - \\frac{10(1-p)}{p}  \\text{若 } p\\delta  10 \\end{cases}$$\n对于边缘情况 $p=0$ 和 $p=1$，此逻辑分别正确地得出 $\\hat{y}^*=0$ 和 $\\hat{y}^*=\\delta$。鲁棒性得分为 $b_{\\text{Huber}}(p,\\delta) = |\\hat{y}^*_{\\text{Huber}}(p,\\delta)|$。\n\n**3. 广义 Charbonnier 损失 ($\\ell_{\\text{GC}}(r; \\epsilon, \\beta)$)**\n\n当 $\\epsilon=1$ 和 $\\beta=0.45$ 时，损失为 $\\ell_{\\text{GC}}(r) = (r^2+1)^{0.45}$。其导数为 $\\ell'_{\\text{GC}}(r) = 2\\beta r (r^2+\\epsilon^2)^{\\beta-1} = 0.9 r (r^2+1)^{-0.55}$。\n最优性条件是 $(1-p)\\ell'_{\\text{GC}}(-\\hat{y}^*) = -p\\ell'_{\\text{GC}}(\\delta - \\hat{y}^*)$。代入导数可得：\n$$(1-p) [0.9(-\\hat{y}^*)((-\\hat{y}^*)^2+1)^{-0.55}] = -p [0.9(\\delta-\\hat{y}^*)((\\delta-\\hat{y}^*)^2+1)^{-0.55}]$$\n简化并重新整理各项，我们得到关于 $\\hat{y}^*$ 的方程：\n$$(1-p)\\hat{y}^*(\\hat{y}^{*2}+1)^{-0.55} - p(\\delta-\\hat{y}^*)((\\delta-\\hat{y}^*)^2+1)^{-0.55} = 0$$\n这是一个非线性方程，无法以闭式解的形式求解。我们必须用数值方法求根。设 $g(\\hat{y})$ 为方程的左侧。\n- 对于 $p=0$，方程变为 $\\hat{y}^*(\\hat{y}^{*2}+1)^{-0.55} = 0$，这意味着 $\\hat{y}^*_{\\text{GC}} = 0$。\n- 对于 $p=1$，方程变为 $-(\\delta-\\hat{y}^*)((\\delta-\\hat{y}^*)^2+1)^{-0.55} = 0$，这意味着 $\\hat{y}^*_{\\text{GC}} = \\delta$。\n- 对于 $p \\in (0,1)$，我们可以观察到 $g(0)  0$ 和 $g(\\delta)  0$。由于 $g(\\hat{y})$ 在 $0$ 和 $\\delta$ 之间是连续且单调的，因此存在一个唯一的根 $\\hat{y}^*_{\\text{GC}} \\in (0, \\delta)$。可以使用数值方法（如二分法或 Brent 方法）找到这个根。\n鲁棒性得分为 $b_{\\text{GC}}(p,\\delta) = |\\hat{y}^*_{\\text{GC}}(p,\\delta)|$。\n\n实现部分将为每个测试用例计算这三个得分。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Computes robustness scores for L1, Huber, and Generalized Charbonnier losses\n    for a set of test cases.\n    \"\"\"\n    \n    # Loss function parameters\n    HUBER_KAPPA = 10.0\n    GC_EPSILON = 1.0\n    GC_BETA = 0.45\n\n    test_cases = [\n        (0.1, 20.0),  # Case 1\n        (0.4, 50.0),  # Case 2\n        (0.6, 50.0),  # Case 3\n        (0.9, 100.0), # Case 4\n        (0.0, 10.0),  # Case 5\n        (1.0, 10.0),  # Case 6\n    ]\n\n    def get_l1_bias(p, delta):\n        \"\"\"Computes the bias for the L1 loss.\"\"\"\n        if p > 0.5:\n            y_star = delta\n        else: # p = 0.5, including tie-breaking at p = 0.5\n            y_star = 0.0\n        return abs(y_star)\n\n    def get_huber_bias(p, delta, kappa):\n        \"\"\"Computes the bias for the Huber loss.\"\"\"\n        if p = 0.5:\n            if delta * (1.0 - p) = kappa:\n                y_star = p * delta\n            else:\n                y_star = (p * kappa) / (1.0 - p)\n        else: # p > 0.5\n            if p * delta = kappa:\n                y_star = p * delta\n            else:\n                y_star = delta - (kappa * (1.0 - p)) / p\n        return abs(y_star)\n\n    def get_gc_bias(p, delta, epsilon, beta):\n        \"\"\"Computes the bias for the Generalized Charbonnier loss.\"\"\"\n        if p == 0.0:\n            return 0.0\n        if p == 1.0:\n            return float(delta)\n\n        # Define the function whose root we need to find.\n        # This is derived from setting the derivative of the expected risk to zero.\n        def root_function(y_hat):\n            term1 = (1.0 - p) * y_hat * ((y_hat**2 + epsilon**2)**(beta - 1.0))\n            term2 = p * (delta - y_hat) * (((delta - y_hat)**2 + epsilon**2)**(beta - 1.0))\n            return term1 - term2\n\n        # Use Brent's method to find the root in the interval [0, delta].\n        # The function has opposite signs at the interval endpoints for p in (0, 1).\n        y_star = brentq(root_function, 0.0, delta)\n        return abs(y_star)\n\n    results = []\n    for p, delta in test_cases:\n        b_l1 = get_l1_bias(p, delta)\n        b_huber = get_huber_bias(p, delta, HUBER_KAPPA)\n        b_gc = get_gc_bias(p, delta, GC_EPSILON, GC_BETA)\n        \n        results.append([b_l1, b_huber, b_gc])\n\n    # Format the final output string as per requirements.\n    outer_parts = [f\"[{','.join(map(str, inner_list))}]\" for inner_list in results]\n    final_output = f\"[{','.join(outer_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}