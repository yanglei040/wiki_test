{
    "hands_on_practices": [
        {
            "introduction": "掌握任何一个数学概念的第一步都是从基础计算开始。本练习将引导你完成计算一个矩阵奇异值的核心步骤，即通过构建矩阵 $A^T A$，求解其特征值，最后取平方根得到奇异值。这个过程 将帮助你巩固奇异值的代数定义，并为理解其更深层的几何与应用价值奠定基础。",
            "id": "1071366",
            "problem": "计算 $2 \\times 2$ 矩阵 \n\n$$\nA = \\begin{bmatrix} 1  1 \\\\ 1  0 \\end{bmatrix}\n$$\n\n的奇异值。\n\n将奇异值以最简根式形式表示，并按降序排列。",
            "solution": "1. $A$ 的奇异值 $\\sigma_i$ 是 $A^T A$ 特征值的平方根。\n\n2. 计算 \n$$A^T A = \\begin{bmatrix} 1  1 \\\\ 1  0 \\end{bmatrix}\\begin{bmatrix} 1  1 \\\\ 1  0 \\end{bmatrix} =\\begin{bmatrix} 2  1 \\\\ 1  1 \\end{bmatrix}。$$\n\n3. $A^T A$ 的特征多项式为\n$$\\det\\bigl(\\begin{bmatrix}2  1\\\\1  1\\end{bmatrix}-\\lambda I\\bigr)\n=(2-\\lambda)(1-\\lambda)-1\n=\\lambda^2-3\\lambda+1。$$\n\n4. 解方程 $\\lambda^2-3\\lambda+1=0$：\n$$\\lambda=\\frac{3\\pm\\sqrt{9-4}}{2}=\\frac{3\\pm\\sqrt5}{2}。$$\n\n5. 因此，奇异值为\n$$\\sigma_1=\\sqrt{\\frac{3+\\sqrt5}{2}},\\quad\n\\sigma_2=\\sqrt{\\frac{3-\\sqrt5}{2}},$$\n按降序排列。",
            "answer": "$$\\boxed{\\sqrt{\\frac{3+\\sqrt{5}}{2}},\\ \\sqrt{\\frac{3-\\sqrt{5}}{2}}}$$"
        },
        {
            "introduction": "超越纯粹的计算，奇异值分解（SVD）为我们提供了理解线性变换的强大几何直觉。如此练习所示 ，一个矩阵可以被看作是将一个单位圆变换为一个椭圆的操作，而奇异值正是这个椭圆半轴的长度。通过探究一个可逆矩阵 $A$ 与其逆矩阵 $A^{-1}$ 奇异值之间的关系，我们可以加深对 SVD 几何意义的理解。",
            "id": "1388918",
            "problem": "考虑一个由可逆 $2 \\times 2$ 矩阵 $A$ 表示的二维笛卡尔平面中的线性变换。根据奇异值分解（Singular Value Decomposition, SVD）的几何解释，该变换将单位圆（所有满足 $\\|\\mathbf{x}\\|_2 = 1$ 的向量 $\\mathbf{x}$ 的集合）映射为一个椭圆。这个椭圆的长半轴和短半轴的长度对应于矩阵 $A$ 的奇异值。设这些奇异值用 $\\sigma_1$ 和 $\\sigma_2$ 表示，并满足条件 $\\sigma_1 \\ge \\sigma_2  0$。\n\n现在，考虑将该椭圆映射回单位圆的逆线性变换。这个逆变换由矩阵 $A^{-1}$ 表示。请用 $\\sigma_1$ 和 $\\sigma_2$ 来确定矩阵 $A^{-1}$ 的奇异值。将你的答案表示为一对从大到小排列的表达式。",
            "solution": "设可逆 $2 \\times 2$ 矩阵 $A$ 的奇异值分解（SVD）为 $A = U\\Sigma V^T$。在这个分解中：\n- $U$ 和 $V$ 是 $2 \\times 2$ 的正交矩阵，这意味着 $U^T U = UU^T = I$ 和 $V^T V = VV^T = I$，其中 $I$ 是单位矩阵。由这个性质可知，$U^{-1} = U^T$ 且 $V^{-1} = V^T$。\n- $\\Sigma$ 是一个 $2 \\times 2$ 的对角矩阵，其对角线上的元素是 $A$ 的奇异值。由于给定的奇异值 $\\sigma_1$ 和 $\\sigma_2$ 是按非递增顺序排列的，我们有：\n$$\n\\Sigma = \\begin{pmatrix} \\sigma_1  0 \\\\ 0  \\sigma_2 \\end{pmatrix}\n$$\n题目说明 $A$ 是可逆的。这与条件 $\\sigma_1 \\ge \\sigma_2  0$ 一致，该条件确保了没有奇异值为零，因此 $\\det(A) \\ne 0$。\n\n我们需要求逆矩阵 $A^{-1}$ 的奇异值。首先，我们利用 $A$ 的 SVD 来求 $A^{-1}$ 的表达式：\n$$\nA^{-1} = (U\\Sigma V^T)^{-1}\n$$\n利用矩阵求逆的性质 $(XYZ)^{-1} = Z^{-1}Y^{-1}X^{-1}$，我们得到：\n$$\nA^{-1} = (V^T)^{-1} \\Sigma^{-1} U^{-1}\n$$\n现在，我们利用正交矩阵的性质，其中 $(V^T)^{-1} = (V^{-1})^{-1} = V$ 且 $U^{-1} = U^T$：\n$$\nA^{-1} = V \\Sigma^{-1} U^T\n$$\n这个表达式具有矩阵 $A^{-1}$ 的 SVD 形式。我们来验证一下。该表达式是三个矩阵 $V$、$\\Sigma^{-1}$ 和 $U^T$ 的乘积。\n- 第一个矩阵 $V$ 是一个正交矩阵。\n- 第三个矩阵 $U^T$ 也是一个正交矩阵（正交矩阵的转置仍然是正交矩阵）。\n- 中间的矩阵 $\\Sigma^{-1}$ 必须是一个具有非负对角元素的对角矩阵，才能成为 $A^{-1}$ 的奇异值矩阵。\n\n我们来计算 $\\Sigma^{-1}$。由于 $\\Sigma$ 是一个对角矩阵，其逆矩阵是其对角元素倒数构成的对角矩阵。\n$$\n\\Sigma^{-1} = \\begin{pmatrix} \\sigma_1  0 \\\\ 0  \\sigma_2 \\end{pmatrix}^{-1} = \\begin{pmatrix} \\frac{1}{\\sigma_1}  0 \\\\ 0  \\frac{1}{\\sigma_2} \\end{pmatrix}\n$$\n$\\Sigma^{-1}$ 的对角元素是 $\\frac{1}{\\sigma_1}$ 和 $\\frac{1}{\\sigma_2}$。因为 $\\sigma_1  0$ 且 $\\sigma_2  0$，所以这些元素都是正的。因此，表达式 $A^{-1} = V \\Sigma^{-1} U^T$ 确实是 $A^{-1}$ 的一个有效 SVD。\n\n一个矩阵的奇异值是其 SVD 中间矩阵的对角元素，按非递增顺序排列。$\\Sigma^{-1}$ 的对角元素是 $\\frac{1}{\\sigma_1}$ 和 $\\frac{1}{\\sigma_2}$。\n我们已知条件 $\\sigma_1 \\ge \\sigma_2  0$。对这个不等式序列取倒数会反转不等号的方向：\n$$\n\\frac{1}{\\sigma_1} \\le \\frac{1}{\\sigma_2}\n$$\n因此，$A^{-1}$ 的奇异值按从大到小（非递增）的顺序排列为 $\\frac{1}{\\sigma_2}$ 和 $\\frac{1}{\\sigma_1}$。题目要求将这对表达式按从大到小的顺序排列。\n\n$A^{-1}$ 的最大奇异值是 $\\frac{1}{\\sigma_2}$。\n$A^{-1}$ 的最小奇异值是 $\\frac{1}{\\sigma_1}$。",
            "answer": "$$\\boxed{\\frac{1}{\\sigma_2}, \\frac{1}{\\sigma_1}}$$"
        },
        {
            "introduction": "理论的最终目的是应用于实践。这个综合性练习将 SVD 应用于一个经典的机器学习问题：人脸识别。你将通过编写代码，利用 SVD 从一组人脸图像中提取出最重要的特征（即“特征脸”），并以此构建一个降维的分类系统。这个练习  完整地展示了 SVD 作为一种强大的降维工具，在数据科学和机器学习领域中的核心作用。",
            "id": "3275135",
            "problem": "考虑一个向量化的灰度人脸图像集合，这些图像排列为一个数据矩阵 $X \\in \\mathbb{R}^{m \\times n}$ 的各列，其中每张图像有 $m$ 个像素，训练集中有 $n$ 张图像。令 $\\mu \\in \\mathbb{R}^{m}$ 表示训练图像的经验均值，定义为 $\\mu = \\frac{1}{n} \\sum_{j=1}^{n} x_j$，其中 $x_j$ 是第 $j$ 个训练图像列向量。定义均值中心化后的训练矩阵 $X_c = X - \\mu \\mathbf{1}^T$，其中 $\\mathbf{1} \\in \\mathbb{R}^{n}$ 是全一向量。对 $X_c$ 进行奇异值分解 (SVD) $X_c = U \\Sigma V^T$，其中 $U \\in \\mathbb{R}^{m \\times r}$, $\\Sigma \\in \\mathbb{R}^{r \\times r}$ 且 $V \\in \\mathbb{R}^{n \\times r}$，$r = \\operatorname{rank}(X_c)$，$U$ 的列构成了中心化后数据的主子空间的一个标准正交基。$U$ 的前 $k$ 列定义了一个“特征脸”基 $U_k \\in \\mathbb{R}^{m \\times k}$。\n\n给定一个测试图像 $x \\in \\mathbb{R}^{m}$，其在特征脸基上的投影坐标定义为 $z = U_k^T (x - \\mu) \\in \\mathbb{R}^{k}$。为了进行分类，在投影空间中使用最近邻方法：对于每个测试图像，计算其到所有投影后的训练图像 $z_j = U_k^T (x_j - \\mu)$ 的距离，并将最近的投影训练图像的身份分配给该测试图像。如果多个距离完全相等，则通过选择训练图像出现顺序中最小的索引来打破平局。\n\n您的任务是实现一个完整的程序，该程序能够：\n- 构建合成的人脸图像数据集，其中每张图像有 $m$ 个像素，并包含指定数量的身份。对于每个身份 $i$，定义一个基础人脸向量 $b_i \\in \\mathbb{R}^{m}$，使得数据集在科学上合理且在低噪声下是线性可分的。通过向身份基础向量添加具有指定标准差 $\\sigma$ 的独立高斯噪声来生成训练和测试图像。\n- 计算均值 $\\mu$，执行均值中心化，并计算奇异值分解 $X_c = U \\Sigma V^T$。\n- 从前 $k$ 个左奇异向量构成特征脸基 $U_k$。\n- 将训练图像和测试图像都投影到特征脸子空间中，并在该子空间中执行最近邻分类。\n- 针对每个测试用例，报告所有身份中被正确识别的测试图像的整数数量。\n\n按如下方式为非退化数据集构建基础向量：选择 $m = 60$ 和 $C = 3$ 个身份。将 $m$ 个坐标划分为 $C$ 个长度相等的连续块，每块长度为 $m/C = 20$。对于身份 $i \\in \\{0,1,2\\}$，设置 $b_i$ 在其对应的块上为1，在其他位置为0。对于退化数据集，设置所有身份共享相同的基础向量 $b$，该向量等于第一个身份的基础向量 $b_0$。\n\n所有角度（如果出现）必须以弧度处理，但此问题中不需要角度。不出现物理单位。程序必须生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个测试用例的唯一输出必须是整数。\n\n使用以下参数值的测试套件，其中 $m = 60$，$C = 3$，每个身份的训练图像数量为 $n_{\\text{train}} = 5$，每个身份的测试图像数量为 $n_{\\text{test}} = 3$。高斯噪声标准差为 $\\sigma$，特征脸维度为 $k$。所有用例必须使用单个固定的伪随机种子，以确保确定性行为。\n\n- 用例 1（理想情况）：$k = 9$，$\\sigma = 0.1$，非退化基础向量。\n- 用例 2（低维子空间压力测试）：$k = 1$，$\\sigma = 0.25$，非退化基础向量。\n- 用例 3（边界条件）：$k = 0$，$\\sigma = 0.0$，非退化基础向量。\n- 用例 4（退化数据集）：$k = 5$，$\\sigma = 0.0$，如上定义的退化基础向量。\n\n对于每个用例，汇总所有身份的测试图像，并计算在特征脸子空间中正确进行最近邻分类的总数。您的程序应生成单行输出，包含按顺序对应于用例1到4的四个整数，格式完全如下：\n$[r_1,r_2,r_3,r_4]$,\n其中 $r_i$ 是用例 $i$ 中正确识别的测试图像数量。",
            "solution": "用户提供的问题陈述已经过仔细验证，被认为是具有科学依据、适定且客观的。它描述了数值线性代数和模式识别领域一个完整且自洽的任务，特别是奇异值分解（SVD）在人脸识别中的应用，这种方法通常被称为“特征脸”。所有参数、定义和步骤都已明确说明，足以得出一个唯一且可验证的解。\n\n解决方案通过为四个指定的测试用例逐步实现所述算法来展开。使用固定的伪随机种子来确保合成数据的确定性生成，从而使结果可复现。\n\n### 步骤 1：合成数据生成\n\n对于每个测试用例，我们首先生成一个训练集和一个测试集的合成图像。问题指定每张图像 $m=60$ 个像素，有 $C=3$ 个不同身份，每个身份 $n_{\\text{train}}=5$ 张训练图像，每个身份 $n_{\\text{test}}=3$ 张测试图像。这导致总共有 $n = C \\times n_{\\text{train}} = 3 \\times 5 = 15$ 张训练图像和 $C \\times n_{\\text{test}} = 3 \\times 3 = 9$ 张测试图像。\n\n各身份的基础向量 $b_i \\in \\mathbb{R}^{m}$ (其中 $i \\in \\{0, 1, 2\\}$) 构建如下：\n- **非退化情况**：将 $m=60$ 个像素坐标划分为 $C=3$ 个大小为 $m/C = 20$ 的连续不重叠的块。基础向量 $b_i$ 被定义为在第 $i$ 个块内的所有坐标上值为 $1$，在其他地方为 $0$。这三个向量 $b_0, b_1, b_2$ 是相互正交的。\n- **退化情况**：所有身份共享相同的基础向量，该向量被设置为非退化情况下的 $b_0$。即，$b_0 = b_1 = b_2$。\n\n通过为给定身份取相应的基向量 $b_i$，并加上从均值为 $0$、标准差为 $\\sigma$ 的高斯分布中采样的独立随机值向量，来生成训练和测试图像。伪随机数生成器的固定种子确保每次运行生成的噪声相同。\n\n训练图像被组织成数据矩阵 $X \\in \\mathbb{R}^{60 \\times 15}$ 的列，其对应的身份标签（例如 $0, 1, 2$）被存储起来。同样地，9 张测试图像及其标签被分开存储。\n\n### 步骤 2：均值中心化与 SVD\n\n特征脸方法的核心在于对训练数据执行主成分分析 (PCA)。这是通过计算均值中心化后的数据矩阵的 SVD 来实现的。\n\n首先，计算训练图像的经验均值 $\\mu \\in \\mathbb{R}^{60}$：\n$$\n\\mu = \\frac{1}{n} \\sum_{j=1}^{n} x_j\n$$\n其中 $x_j$ 是训练数据矩阵 $X$ 的列。\n\n接下来，通过减去均值来对每个训练图像进行中心化，形成中心化数据矩阵 $X_c \\in \\mathbb{R}^{60 \\times 15}$：\n$$\nX_c = X - \\mu \\mathbf{1}^T\n$$\n其中 $\\mathbf{1} \\in \\mathbb{R}^{15}$ 是一个全一列向量。\n\n然后计算 $X_c$ 的 SVD。由于 $m  n$，我们使用“经济”SVD 以提高效率：\n$$\nX_c = U \\Sigma V^T\n$$\n此处，$U \\in \\mathbb{R}^{60 \\times 15}$ 是左奇异向量（即特征脸）矩阵，$\\Sigma \\in \\mathbb{R}^{15 \\times 15}$ 是奇异值的对角矩阵，$V \\in \\mathbb{R}^{15 \\times 15}$ 是右奇异向量矩阵。$U$ 的列构成了由中心化后的训练图像张成的子空间的一个标准正交基。\n\n### 步骤 3：投影到特征脸子空间\n\n下一步是通过将数据投影到由最重要的特征脸张成的低维子空间来降低数据维度。问题指定使用前 $k$ 个特征脸，它们对应于矩阵 $U$ 的前 $k$ 列。这就构成了投影基 $U_k \\in \\mathbb{R}^{60 \\times k}$。\n\n每个中心化后的训练图像 $x_j - \\mu$ 被投影到这个子空间上，以获得其低维表示 $z_j \\in \\mathbb{R}^{k}$：\n$$\nz_j = U_k^T (x_j - \\mu)\n$$\n类似地，对于每个测试图像 $x_{\\text{test}}$，其中心化版本被投影以获得其坐标向量 $z_{\\text{test}} \\in \\mathbb{R}^{k}$：\n$$\nz_{\\text{test}} = U_k^T (x_{\\text{test}} - \\mu)\n$$\n\n### 步骤 4：最近邻分类\n\n分类在低维特征脸子空间中进行。对于每个投影后的测试图像 $z_{\\text{test}}$，我们找到离它最近的投影训练图像 $z_j$。距离使用欧几里得范数来衡量：\n$$\nd_j = \\| z_{\\text{test}} - z_j \\|_2\n$$\n最近邻的索引 $j^*$ 通过最小化此距离找到：\n$$\nj^* = \\arg\\min_{j \\in \\{1, \\dots, n\\}} d_j\n$$\n问题指定了一个平局打破规则：如果多个训练图像等距，则选择索引 $j$ 最小的那个。测试图像的预测身份是训练图像 $x_{j^*}$ 的身份。\n\n然后将这个预测身份与测试图像的真实身份进行比较。对每个测试用例，累加正确分类的测试图像总数。\n\n### 特殊情况分析\n\n- **用例 3 ($k=0$)：** 在此情况下，投影基 $U_0$ 是一个大小为 $60 \\times 0$ 的空矩阵。因此，任何投影 $z = U_0^T (\\dots)$ 都会得到一个 0 维向量。所有投影后的训练图像和测试图像都变成了 $\\mathbb{R}^0$ 中的零向量。任何投影测试图像和任何投影训练图像之间的距离都是 $\\|0 - 0\\|_2 = 0$。根据平局打破规则，每个测试图像都被分配了第一个训练图像（索引 $j=0$）的身份，即身份 $0$。由于有 3 个测试图像属于身份 $0$，因此正确分类的数量是 3。\n\n- **用例 4 ($k=5$, $\\sigma=0$, 退化)：** 在这种情况下，所有基础向量都相同，并且没有噪声（$\\sigma=0$）。因此，所有 15 个训练图像都相同，即对所有 $j$ 都有 $x_j = b$。均值图像是 $\\mu = b$。中心化数据矩阵 $X_c$ 变成零矩阵，因为 $x_j - \\mu = b - b = 0$。零矩阵的 SVD 产生零奇异值。所有投影后的训练向量 $z_j = U_5^T (0)$ 都是 $\\mathbb{R}^5$ 中的零向量。所有测试图像也等于 $b$，因此它们的投影 $z_{\\text{test}} = U_5^T(b-b)$ 也是零向量。与 $k=0$ 的情况一样，所有距离都为 0，平局打破规则将身份 0 分配给所有测试图像。正确分类的数量同样是 3。\n\n最终输出是一个列表，包含四个用例中每个用例的正确分类的整数计数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the eigenface recognition pipeline for a series of test cases\n    and computes the number of correctly classified images for each.\n    \"\"\"\n    \n    # Set a single fixed pseudo-random seed for deterministic data generation.\n    np.random.seed(0)\n\n    # Define problem parameters\n    m = 60  # Pixels per image\n    C = 3   # Number of identities\n    n_train_per_id = 5\n    n_test_per_id = 3\n    n_train_total = C * n_train_per_id\n    n_test_total = C * n_test_per_id\n\n    # Test suite parameters\n    test_cases = [\n        # (k, sigma, is_degenerate)\n        {'k': 9, 'sigma': 0.1, 'degenerate': False, 'label': 'Case 1'},\n        {'k': 1, 'sigma': 0.25, 'degenerate': False, 'label': 'Case 2'},\n        {'k': 0, 'sigma': 0.0, 'degenerate': False, 'label': 'Case 3'},\n        {'k': 5, 'sigma': 0.0, 'degenerate': True, 'label': 'Case 4'},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        k = case['k']\n        sigma = case['sigma']\n        is_degenerate = case['degenerate']\n\n        # Step 1: Generate synthetic data\n        \n        # Construct base vectors\n        base_vectors = np.zeros((m, C))\n        block_size = m // C\n        if not is_degenerate:\n            for i in range(C):\n                base_vectors[i * block_size : (i + 1) * block_size, i] = 1.0\n        else:\n            base_vectors[0 * block_size : 1 * block_size, 0] = 1.0\n            for i in range(1, C):\n                base_vectors[:, i] = base_vectors[:, 0]\n\n        # Generate training data\n        X_train = np.zeros((m, n_train_total))\n        y_train = np.zeros(n_train_total, dtype=int)\n        img_idx = 0\n        for i in range(C):\n            for _ in range(n_train_per_id):\n                noise = np.random.normal(0, sigma, m)\n                X_train[:, img_idx] = base_vectors[:, i] + noise\n                y_train[img_idx] = i\n                img_idx += 1\n\n        # Generate test data\n        X_test = np.zeros((m, n_test_total))\n        y_test = np.zeros(n_test_total, dtype=int)\n        img_idx = 0\n        for i in range(C):\n            for _ in range(n_test_per_id):\n                noise = np.random.normal(0, sigma, m)\n                X_test[:, img_idx] = base_vectors[:, i] + noise\n                y_test[img_idx] = i\n                img_idx += 1\n        \n        # Step 2: Mean Centering and SVD\n        mu = np.mean(X_train, axis=1, keepdims=True)\n        X_c = X_train - mu\n        \n        U, s, Vt = np.linalg.svd(X_c, full_matrices=False)\n        \n        # Step 3: Projection onto the Eigenface Subspace\n        U_k = U[:, :k]\n        \n        # Project training images\n        Z_train = U_k.T @ X_c\n        \n        # Step 4: Nearest-Neighbor Classification\n        num_correct = 0\n        for i in range(n_test_total):\n            x_test_vec = X_test[:, i]\n            \n            # Center and project the test image\n            x_test_c = x_test_vec.reshape(-1, 1) - mu\n            z_test = U_k.T @ x_test_c\n\n            # Compute distances to all projected training images\n            # The reshape of z_test ensures correct broadcasting\n            distances = np.linalg.norm(Z_train - z_test, axis=0)\n            \n            # Find the index of the nearest neighbor. np.argmin handles ties\n            # by returning the first occurrence, as required.\n            best_match_idx = np.argmin(distances)\n            \n            # Get the predicted label and compare with the true label\n            predicted_label = y_train[best_match_idx]\n            true_label = y_test[i]\n            \n            if predicted_label == true_label:\n                num_correct += 1\n        \n        results.append(num_correct)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}