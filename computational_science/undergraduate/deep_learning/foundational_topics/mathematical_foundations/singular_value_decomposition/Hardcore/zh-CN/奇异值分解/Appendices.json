{
    "hands_on_practices": [
        {
            "introduction": "掌握奇异值分解的第一步是学会如何计算奇异值。这个练习将带你通过一个具体的 $2 \\times 2$ 矩阵，实践从定义出发，通过计算 $A^T A$ 的特征值来求得奇异值的基本流程。这个基础计算是理解 SVD 背后代数机制的关键。",
            "id": "1071366",
            "problem": "计算 $2 \\times 2$ 矩阵 \n\n$$\nA = \\begin{bmatrix} 1  1 \\\\ 1  0 \\end{bmatrix}\n$$\n\n的奇异值。\n\n将奇异值以简化的根式形式表示，并按降序排列。",
            "solution": "1. 矩阵 $A$ 的奇异值 $\\sigma_i$ 是 $A^T A$ 的特征值的平方根。\n\n2. 计算 \n$$A^T A = \\begin{bmatrix} 1  1 \\\\ 1  0 \\end{bmatrix}^T \\begin{bmatrix} 1  1 \\\\ 1  0 \\end{bmatrix}\n=\\begin{bmatrix} 2  1 \\\\ 1  1 \\end{bmatrix}。$$\n\n3. $A^T A$ 的特征多项式是\n$$\\det\\bigl(\\begin{bmatrix} 2  1 \\\\ 1  1 \\end{bmatrix}-\\lambda I\\bigr)\n=(2-\\lambda)(1-\\lambda)-1\n=\\lambda^2-3\\lambda+1。$$\n\n4. 解方程 $\\lambda^2-3\\lambda+1=0$：\n$$\\lambda=\\frac{3\\pm\\sqrt{9-4}}{2}=\\frac{3\\pm\\sqrt5}{2}。$$\n\n5. 因此，奇异值为\n$$\\sigma_1=\\sqrt{\\frac{3+\\sqrt5}{2}},\\quad\n\\sigma_2=\\sqrt{\\frac{3-\\sqrt5}{2}},$$\n按降序排列。",
            "answer": "$$\\boxed{\\sqrt{\\frac{3+\\sqrt{5}}{2}},\\ \\sqrt{\\frac{3-\\sqrt{5}}{2}}}$$"
        },
        {
            "introduction": "奇异值分解不僅僅是一种矩阵分解技术，它还揭示了矩阵深层的几何与代数属性。本练习探讨了矩阵的奇异值与其逆矩阵奇异值之间的关系，帮助你理解 SVD 如何阐释线性变换的可逆性。通过这个思想实验，你将看到变换的“拉伸”程度与它的逆变换之间存在的优美倒数关系。",
            "id": "1388918",
            "problem": "考虑一个二维笛卡尔平面上的线性变换，该变换由一个可逆的 $2 \\times 2$ 矩阵 $A$ 表示。根据奇异值分解 (SVD) 的几何解释，该变换将单位圆（所有范数为 $\\|\\mathbf{x}\\|_2 = 1$ 的向量 $\\mathbf{x}$ 的集合）映射为一个椭圆。该椭圆的半长轴和半短轴的长度对应于矩阵 $A$ 的奇异值。设这些奇异值为 $\\sigma_1$ 和 $\\sigma_2$，满足条件 $\\sigma_1 \\ge \\sigma_2  0$。\n\n现在，考虑将该椭圆映射回单位圆的逆线性变换。该逆变换由矩阵 $A^{-1}$ 表示。请用 $\\sigma_1$ 和 $\\sigma_2$ 表示矩阵 $A^{-1}$ 的奇异值。请将你的答案表示为一对从大到小排列的表达式。",
            "solution": "设可逆 $2 \\times 2$ 矩阵 $A$ 的奇异值分解 (SVD) 为 $A = U\\Sigma V^T$。在此分解中：\n- $U$ 和 $V$ 是 $2 \\times 2$ 的正交矩阵，这意味着 $U^T U = UU^T = I$ 且 $V^T V = VV^T = I$，其中 $I$ 是单位矩阵。根据此性质，可得 $U^{-1} = U^T$ 和 $V^{-1} = V^T$。\n- $\\Sigma$ 是一个 $2 \\times 2$ 的对角矩阵，其对角线上的元素是 $A$ 的奇异值。由于给定的奇异值 $\\sigma_1$ 和 $\\sigma_2$ 是按非递增顺序排列的，我们有：\n$$\n\\Sigma = \\begin{pmatrix} \\sigma_1  0 \\\\ 0  \\sigma_2 \\end{pmatrix}\n$$\n题目指出 $A$ 是可逆的。这与条件 $\\sigma_1 \\ge \\sigma_2  0$ 一致，该条件确保了没有奇异值为零，因此 $\\det(A) \\ne 0$。\n\n我们需要求逆矩阵 $A^{-1}$ 的奇异值。首先，我们利用 $A$ 的 SVD 来求 $A^{-1}$ 的表达式：\n$$\nA^{-1} = (U\\Sigma V^T)^{-1}\n$$\n利用矩阵求逆的性质 $(XYZ)^{-1} = Z^{-1}Y^{-1}X^{-1}$，我们得到：\n$$\nA^{-1} = (V^T)^{-1} \\Sigma^{-1} U^{-1}\n$$\n现在，我们利用正交矩阵的性质，即 $(V^T)^{-1} = (V^{-1})^{-1} = V$ 和 $U^{-1} = U^T$：\n$$\nA^{-1} = V \\Sigma^{-1} U^T\n$$\n这个表达式是矩阵 $A^{-1}$ 的 SVD 形式。我们来验证一下。该表达式是三个矩阵 $V$、$\\Sigma^{-1}$ 和 $U^T$ 的乘积。\n- 第一个矩阵 $V$ 是一个正交矩阵。\n- 第三个矩阵 $U^T$ 也是一个正交矩阵（正交矩阵的转置仍然是正交矩阵）。\n- 中间的矩阵 $\\Sigma^{-1}$ 必须是一个对角元素为非负的对角矩阵，才能成为 $A^{-1}$ 的奇异值矩阵。\n\n我们来计算 $\\Sigma^{-1}$。由于 $\\Sigma$ 是一个对角矩阵，它的逆矩阵是对角线上各元素取倒数后形成的对角矩阵。\n$$\n\\Sigma^{-1} = \\begin{pmatrix} \\sigma_1  0 \\\\ 0  \\sigma_2 \\end{pmatrix}^{-1} = \\begin{pmatrix} \\frac{1}{\\sigma_1}  0 \\\\ 0  \\frac{1}{\\sigma_2} \\end{pmatrix}\n$$\n$\\Sigma^{-1}$ 的对角元素是 $\\frac{1}{\\sigma_1}$ 和 $\\frac{1}{\\sigma_2}$。由于 $\\sigma_1  0$ 且 $\\sigma_2  0$，这些元素都是正数。因此，表达式 $A^{-1} = V \\Sigma^{-1} U^T$ 确实是 $A^{-1}$ 的一个有效的 SVD。\n\n一个矩阵的奇异值是其 SVD 中间矩阵的对角元素，按非递增顺序排列。$\\Sigma^{-1}$ 的对角元素是 $\\frac{1}{\\sigma_1}$ 和 $\\frac{1}{\\sigma_2}$。\n我们已知条件 $\\sigma_1 \\ge \\sigma_2  0$。对这个不等式序列取倒数会反转不等号的方向：\n$$\n\\frac{1}{\\sigma_1} \\le \\frac{1}{\\sigma_2}\n$$\n因此，$A^{-1}$ 的奇异值，从大到小（非递增）排列，是 $\\frac{1}{\\sigma_2}$ 和 $\\frac{1}{\\sigma_1}$。题目要求将这对表达式从大到小排列。\n\n$A^{-1}$ 的最大奇异值是 $\\frac{1}{\\sigma_2}$。\n$A^{-1}$ 的最小奇异值是 $\\frac{1}{\\sigma_1}$。",
            "answer": "$$ \\boxed{\\frac{1}{\\sigma_2}, \\frac{1}{\\sigma_1}} $$"
        },
        {
            "introduction": "理论学习的最终目的是应用于实践。这个综合性练习将引导你使用 SVD 来解决一个经典的机器学习问题：人脸识别。你将亲手实现“特征脸”（Eigenfaces）算法，通过对图像数据进行降维来提取关键特征，这是一个展示 SVD 在数据压缩和模式识别中强大功能的绝佳范例。",
            "id": "3275135",
            "problem": "考虑一组矢量化的灰度人脸图像，这些图像作为数据矩阵 $X \\in \\mathbb{R}^{m \\times n}$ 的列排列，其中每张图像有 $m$ 个像素，训练集中有 $n$ 张图像。令 $\\mu \\in \\mathbb{R}^{m}$ 表示训练图像的经验均值，定义为 $\\mu = \\frac{1}{n} \\sum_{j=1}^{n} x_j$，其中 $x_j$ 是第 $j$ 个训练图像列向量。定义均值中心化的训练矩阵 $X_c = X - \\mu \\mathbf{1}^T$，其中 $\\mathbf{1} \\in \\mathbb{R}^{n}$ 是全一向量。对 $X_c$ 执行奇异值分解 (singular value decomposition, SVD) $X_c = U \\Sigma V^T$，其中 $U \\in \\mathbb{R}^{m \\times r}$，$\\Sigma \\in \\mathbb{R}^{r \\times r}$，$V \\in \\mathbb{R}^{n \\times r}$，$r = \\operatorname{rank}(X_c)$，并且 $U$ 的列构成了中心化数据主子空间的一组标准正交基。$U$ 的前 $k$ 列定义了一个“特征脸”基 $U_k \\in \\mathbb{R}^{m \\times k}$。\n\n给定一个测试图像 $x \\in \\mathbb{R}^{m}$，其在特征脸基上的投影坐标定义为 $z = U_k^T (x - \\mu) \\in \\mathbb{R}^{k}$。为了进行分类，在投影空间中使用最近邻方法：对每个测试图像，计算其到所有投影训练图像 $z_j = U_k^T (x_j - \\mu)$ 的距离，并将其归类为最近的投影训练图像的身份。如果多个距离完全相等，则通过选择训练图像出现顺序中最小的索引来打破平局。\n\n您的任务是实现一个完整的程序，该程序：\n- 构建包含 $m$ 个像素/图像和指定数量身份的合成人脸图像数据集。对每个身份 $i$，定义一个基准人脸向量 $b_i \\in \\mathbb{R}^{m}$，使得数据集在低噪声下是科学上合理且线性可分的。通过向身份基准向量添加标准差为 $\\sigma$ 的独立高斯噪声来生成训练和测试图像。\n- 计算均值 $\\mu$，执行均值中心化，并计算奇异值分解 $X_c = U \\Sigma V^T$。\n- 从前 $k$ 个左奇异向量构成特征脸基 $U_k$。\n- 将训练和测试图像都投影到特征脸子空间中，并在该子空间中执行最近邻分类。\n- 针对每个测试用例，报告所有身份中被正确识别的测试图像的整数数量。\n\n按如下方式为非退化数据集构建基准向量：选择 $m = 60$ 和 $C = 3$ 个身份。将 $m$ 个坐标划分为 $C$ 个长度相等 ($m/C = 20$) 的连续块。对于身份 $i \\in \\{0,1,2\\}$，将其对应的块中的 $b_i$ 元素设置为1，其他位置为0。对于退化数据集，设置所有身份共享与第一个身份的基准向量 $b_0$ 相同的基准向量 $b$。\n\n所有角度（如果出现）必须以弧度处理，但本问题中不需要角度。不涉及物理单位。程序必须生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。每个测试用例的唯一输出必须是整数。\n\n使用以下参数值的测试套件，其中 $m = 60$，$C = 3$，每个身份的训练图像数量为 $n_{\\text{train}} = 5$，每个身份的测试图像数量为 $n_{\\text{test}} = 3$。高斯噪声的标准差为 $\\sigma$，特征脸维度为 $k$。所有用例必须使用单个固定的伪随机种子，以确保确定性行为。\n\n- 用例 1 (正常路径): $k = 9$, $\\sigma = 0.1$, 非退化基准向量。\n- 用例 2 (低维子空间压力测试): $k = 1$, $\\sigma = 0.25$, 非退化基准向量。\n- 用例 3 (边界条件): $k = 0$, $\\sigma = 0.0$, 非退化基准向量。\n- 用例 4 (退化数据集): $k = 5$, $\\sigma = 0.0$, 如上定义的退化基准向量。\n\n对于每个用例，汇总所有身份的测试图像，并计算在特征脸子空间中正确进行最近邻分类的总数。您的程序应生成单行输出，其中包含按顺序对应于用例 1 到 4 的四个整数，格式完全如下：\n$[r_1,r_2,r_3,r_4]$,\n其中 $r_i$ 是用例 $i$ 中正确识别的测试图像数量。",
            "solution": "用户提供的问题陈述经过了仔细验证，被认为是科学上合理的、适定的和客观的。它描述了数值线性代数和模式识别领域一个完整且自洽的任务，具体来说是奇异值分解（SVD）在人脸识别中的应用，该方法通常被称为“特征脸”。所有参数、定义和程序都得到了足够清晰的说明，从而可以得出一个唯一的、可验证的解决方案。\n\n解决方案通过为四个指定的测试用例逐步实现所述算法来推进。使用一个固定的伪随机种子来确保合成数据的确定性生成，从而使结果可复现。\n\n### 步骤 1：合成数据生成\n\n对于每个测试用例，我们首先生成一个训练集和一个测试集的合成图像。问题指定每张图像 $m=60$ 个像素，$C=3$ 个不同身份，每个身份 $n_{\\text{train}}=5$ 张训练图像，以及每个身份 $n_{\\text{test}}=3$ 张测试图像。这导致总共有 $n = C \\times n_{\\text{train}} = 3 \\times 5 = 15$ 张训练图像和 $C \\times n_{\\text{test}} = 3 \\times 3 = 9$ 张测试图像。\n\n身份的基准向量 $b_i \\in \\mathbb{R}^{m}$ (其中 $i \\in \\{0, 1, 2\\}$) 的构造如下：\n- **非退化情况**：将 $m=60$ 个像素坐标划分为 $C=3$ 个大小为 $m/C = 20$ 的连续、不重叠的块。基准向量 $b_i$ 定义为在第 $i$ 个块内的所有坐标上值为 $1$，在其他位置为 $0$。这三个向量 $b_0, b_1, b_2$ 相互正交。\n- **退化情况**：所有身份共享相同的基准向量，该向量被设置为非退化情况下的 $b_0$。即 $b_0 = b_1 = b_2$。\n\n通过取给定身份的相应基准向量 $b_i$，并加上一个从均值为 $0$、标准差为 $\\sigma$ 的高斯分布中采样的独立随机值向量来生成训练和测试图像。为伪随机数生成器设置一个固定的种子可确保每次运行时生成的噪声相同。\n\n训练图像被组织为数据矩阵 $X \\in \\mathbb{R}^{60 \\times 15}$ 的列，并且它们对应的身份标签（例如 $0, 1, 2$）被存储起来。同样地，9 个测试图像及其标签也被分开存储。\n\n### 步骤 2：均值中心化和 SVD\n\n特征脸方法的核心在于对训练数据执行主成分分析 (PCA)。这通过计算均值中心化数据矩阵的 SVD 来实现。\n\n首先，计算训练图像的经验均值 $\\mu \\in \\mathbb{R}^{60}$：\n$$\n\\mu = \\frac{1}{n} \\sum_{j=1}^{n} x_j\n$$\n其中 $x_j$ 是训练数据矩阵 $X$ 的列。\n\n接下来，通过减去均值来对每个训练图像进行中心化，形成中心化数据矩阵 $X_c \\in \\mathbb{R}^{60 \\times 15}$：\n$$\nX_c = X - \\mu \\mathbf{1}^T\n$$\n其中 $\\mathbf{1} \\in \\mathbb{R}^{15}$ 是一个全一列向量。\n\n然后计算 $X_c$ 的 SVD。由于 $m  n$，为了效率，我们使用“经济”SVD (economy SVD)：\n$$\nX_c = U \\Sigma V^T\n$$\n此处，$U \\in \\mathbb{R}^{60 \\times 15}$ 是左奇异向量矩阵（特征脸），$\\Sigma \\in \\mathbb{R}^{15 \\times 15}$ 是奇异值的对角矩阵，$V \\in \\mathbb{R}^{15 \\times 15}$ 是右奇异向量矩阵。$U$ 的列构成了由中心化训练图像张成的子空间的一组标准正交基。\n\n### 步骤 3：投影到特征脸子空间\n\n下一步是通过将数据投影到由最重要的特征脸张成的低维子空间上来降低数据维度。问题指定使用前 $k$ 个特征脸，这对应于矩阵 $U$ 的前 $k$ 列。这构成了投影基 $U_k \\in \\mathbb{R}^{60 \\times k}$。\n\n每个中心化的训练图像 $x_j - \\mu$ 被投影到该子空间上，以获得其低维表示 $z_j \\in \\mathbb{R}^{k}$：\n$$\nz_j = U_k^T (x_j - \\mu)\n$$\n同样，对于每个测试图像 $x_{\\text{test}}$，其中心化版本被投影以获得其坐标向量 $z_{\\text{test}} \\in \\mathbb{R}^{k}$：\n$$\nz_{\\text{test}} = U_k^T (x_{\\text{test}} - \\mu)\n$$\n\n### 步骤 4：最近邻分类\n\n分类在低维特征脸子空间中进行。对于每个投影的测试图像 $z_{\\text{test}}$，我们找到离它最近的投影训练图像 $z_j$。距离使用欧几里得范数来测量：\n$$\nd_j = \\| z_{\\text{test}} - z_j \\|_2\n$$\n最近邻的索引 $j^*$ 通过最小化该距离找到：\n$$\nj^* = \\arg\\min_{j \\in \\{1, \\dots, n\\}} d_j\n$$\n问题指定了一个平局打破规则：如果多个训练图像距离相等，则选择索引 $j$ 最小的那个。测试图像的预测身份是训练图像 $x_{j^*}$ 的身份。\n\n然后将此预测身份与测试图像的真实身份进行比较。为每个测试用例累积正确分类的测试图像的总数。\n\n### 特殊情况分析\n\n- **用例 3 ($k=0$)**：在此情况下，投影基 $U_0$ 是一个大小为 $60 \\times 0$ 的空矩阵。因此，任何投影 $z = U_0^T (\\dots)$ 都会得到一个 0 维向量。所有投影的训练和测试图像都成为 $\\mathbb{R}^0$ 中的零向量。任何投影的测试图像与任何投影的训练图像之间的距离均为 $\\|0 - 0\\|_2 = 0$。根据平局打破规则，每个测试图像都被分配为第一个训练图像（索引 $j=0$）的身份，即身份 0。由于有 3 个测试图像属于身份 0，所以正确分类的数量为 3。\n\n- **用例 4 ($k=5$, $\\sigma=0$, 退化)**：在这种情况下，所有基准向量都相同，且没有噪声 ($\\sigma=0$)。因此，所有 15 个训练图像都相同，$x_j = b$ 对所有 $j$ 成立。均值图像为 $\\mu = b$。中心化数据矩阵 $X_c$ 成为零矩阵，因为 $x_j - \\mu = b - b = 0$。零矩阵的 SVD 产生零奇异值。所有投影的训练向量 $z_j = U_5^T (0)$ 都是 $\\mathbb{R}^5$ 中的零向量。所有测试图像也等于 $b$，因此它们的投影 $z_{\\text{test}} = U_5^T(b-b)$ 也是零向量。与 $k=0$ 的情况一样，所有距离都为 0，平局打破规则将身份 0 分配给所有测试图像。正确分类的数量同样是 3。\n\n最终输出是一个列表，包含四个用例中每个用例的正确分类的整数计数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the eigenface recognition pipeline for a series of test cases\n    and computes the number of correctly classified images for each.\n    \"\"\"\n    \n    # Set a single fixed pseudo-random seed for deterministic data generation.\n    np.random.seed(0)\n\n    # Define problem parameters\n    m = 60  # Pixels per image\n    C = 3   # Number of identities\n    n_train_per_id = 5\n    n_test_per_id = 3\n    n_train_total = C * n_train_per_id\n    n_test_total = C * n_test_per_id\n\n    # Test suite parameters\n    test_cases = [\n        # (k, sigma, is_degenerate)\n        {'k': 9, 'sigma': 0.1, 'degenerate': False, 'label': 'Case 1'},\n        {'k': 1, 'sigma': 0.25, 'degenerate': False, 'label': 'Case 2'},\n        {'k': 0, 'sigma': 0.0, 'degenerate': False, 'label': 'Case 3'},\n        {'k': 5, 'sigma': 0.0, 'degenerate': True, 'label': 'Case 4'},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        k = case['k']\n        sigma = case['sigma']\n        is_degenerate = case['degenerate']\n\n        # Step 1: Generate synthetic data\n        \n        # Construct base vectors\n        base_vectors = np.zeros((m, C))\n        block_size = m // C\n        if not is_degenerate:\n            for i in range(C):\n                base_vectors[i * block_size : (i + 1) * block_size, i] = 1.0\n        else:\n            base_vectors[0 * block_size : 1 * block_size, 0] = 1.0\n            for i in range(1, C):\n                base_vectors[:, i] = base_vectors[:, 0]\n\n        # Generate training data\n        X_train = np.zeros((m, n_train_total))\n        y_train = np.zeros(n_train_total, dtype=int)\n        img_idx = 0\n        for i in range(C):\n            for _ in range(n_train_per_id):\n                noise = np.random.normal(0, sigma, m)\n                X_train[:, img_idx] = base_vectors[:, i] + noise\n                y_train[img_idx] = i\n                img_idx += 1\n\n        # Generate test data\n        X_test = np.zeros((m, n_test_total))\n        y_test = np.zeros(n_test_total, dtype=int)\n        img_idx = 0\n        for i in range(C):\n            for _ in range(n_test_per_id):\n                noise = np.random.normal(0, sigma, m)\n                X_test[:, img_idx] = base_vectors[:, i] + noise\n                y_test[img_idx] = i\n                img_idx += 1\n        \n        # Step 2: Mean Centering and SVD\n        mu = np.mean(X_train, axis=1, keepdims=True)\n        X_c = X_train - mu\n        \n        U, s, Vt = np.linalg.svd(X_c, full_matrices=False)\n        \n        # Step 3: Projection onto the Eigenface Subspace\n        U_k = U[:, :k]\n        \n        # Project training images\n        Z_train = U_k.T @ X_c\n        \n        # Step 4: Nearest-Neighbor Classification\n        num_correct = 0\n        for i in range(n_test_total):\n            x_test_vec = X_test[:, i]\n            \n            # Center and project the test image\n            x_test_c = x_test_vec.reshape(-1, 1) - mu\n            z_test = U_k.T @ x_test_c\n\n            # Compute distances to all projected training images\n            # The reshape of z_test ensures correct broadcasting\n            distances = np.linalg.norm(Z_train - z_test, axis=0)\n            \n            # Find the index of the nearest neighbor. np.argmin handles ties\n            # by returning the first occurrence, as required.\n            best_match_idx = np.argmin(distances)\n            \n            # Get the predicted label and compare with the true label\n            predicted_label = y_train[best_match_idx]\n            true_label = y_test[i]\n            \n            if predicted_label == true_label:\n                num_correct += 1\n        \n        results.append(num_correct)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}