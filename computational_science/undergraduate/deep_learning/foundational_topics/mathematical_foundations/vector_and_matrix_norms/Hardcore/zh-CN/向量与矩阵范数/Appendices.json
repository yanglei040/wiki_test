{
    "hands_on_practices": [
        {
            "introduction": "掌握科学概念的第一步往往是将其应用于基础示例。这项练习要求你为一个简单的“全一矩阵”计算四种常见的矩阵范数。这个过程将帮助你巩固不同范数的定义，并直观地理解它们如何以不同的方式衡量一个矩阵的“大小”或“尺度”。",
            "id": "2449594",
            "problem": "设 $m,n \\in \\mathbb{N}$ 且 $m \\geq 1$，$n \\geq 1$。对于矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和 $p \\in \\{1,2,\\infty\\}$，由向量 $p$-范数诱导的算子范数定义为\n$$\n\\|A\\|_{p} = \\sup_{x \\neq 0} \\frac{\\|A x\\|_{p}}{\\|x\\|_{p}},\n$$\n其中，对于 $x \\in \\mathbb{R}^{k}$，向量范数分别为 $\\|x\\|_{1} = \\sum_{i=1}^{k} |x_{i}|$，$\\|x\\|_{2} = \\sqrt{\\sum_{i=1}^{k} |x_{i}|^{2}}$，以及 $\\|x\\|_{\\infty} = \\max_{1 \\leq i \\leq k} |x_{i}|$。$A$ 的弗罗贝尼乌斯范数 (Frobenius norm) 定义为\n$$\n\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^{2}}.\n$$\n考虑全一矩阵 $J \\in \\mathbb{R}^{m \\times n}$，其元素为 $J_{ij} = 1$ 对所有 $i,j$ 成立。求 $\\|J\\|_{1}$、$\\|J\\|_{2}$、$\\|J\\|_{\\infty}$ 和 $\\|J\\|_{F}$ 作为 $m$ 和 $n$ 的显式函数。请按 $\\big(\\|J\\|_{1}, \\|J\\|_{2}, \\|J\\|_{\\infty}, \\|J\\|_{F}\\big)$ 的顺序，将最终答案表示为单个行向量。答案必须是精确值，不可近似。",
            "solution": "对问题陈述进行验证。\n\n**步骤1：提取已知条件**\n- $m, n \\in \\mathbb{N}$ 且 $m \\geq 1$，$n \\geq 1$。\n- 矩阵 $A \\in \\mathbb{R}^{m \\times n}$。\n- 算子范数：$\\|A\\|_{p} = \\sup_{x \\neq 0} \\frac{\\|A x\\|_{p}}{\\|x\\|_{p}}$，其中 $p \\in \\{1, 2, \\infty\\}$。\n- 对于 $x \\in \\mathbb{R}^{k}$ 的向量范数：\n  - $\\|x\\|_{1} = \\sum_{i=1}^{k} |x_{i}|$\n  - $\\|x\\|_{2} = \\sqrt{\\sum_{i=1}^{k} |x_{i}|^{2}}$\n  - $\\|x\\|_{\\infty} = \\max_{1 \\leq i \\leq k} |x_{i}|$\n- 弗罗贝尼乌斯范数：$\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^{2}}$。\n- 所考虑的矩阵是全一矩阵 $J \\in \\mathbb{R}^{m \\times n}$，其元素为 $J_{ij} = 1$ 对所有 $i,j$ 成立。\n- 目标是求出 $\\|J\\|_{1}$、$\\|J\\|_{2}$、$\\|J\\|_{\\infty}$ 和 $\\|J\\|_{F}$ 作为 $m$ 和 $n$ 的显式函数。\n- 最终答案需要以行向量的形式给出：$\\big(\\|J\\|_{1}, \\|J\\|_{2}, \\|J\\|_{\\infty}, \\|J\\|_{F}\\big)$。\n\n**步骤2：使用提取的已知条件进行验证**\n根据所需标准对问题进行评估。\n- **科学依据：** 该问题使用了线性代数和数值分析领域中关于向量和矩阵范数的标准、普遍接受的定义。它在科学上和数学上是合理的。\n- **适定性：** 问题陈述清晰。矩阵 $J$ 以及待计算的范数都有明确的定义。对于所要求的四个量，都存在唯一且有意义的解。\n- **客观性：** 问题以精确的数学语言表述，没有任何主观性或歧义。\n\n经审查，该问题没有任何科学上不合理、不完整或矛盾等缺陷。\n\n**步骤3：结论与行动**\n该问题是**有效的**。将提供一个完整的、有理有据的解答。\n\n我们接下来计算全一矩阵 $J \\in \\mathbb{R}^{m \\times n}$ 的四个指定范数。\n\n**1. 计算 $1$-范数，$\\|J\\|_{1}$**\n矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的算子 $1$-范数定义为最大绝对列和：\n$$\n\\|A\\|_{1} = \\max_{1 \\leq j \\leq n} \\sum_{i=1}^{m} |a_{ij}|\n$$\n对于矩阵 $J$，所有元素均为 $J_{ij} = 1$。我们计算任意一列 $j$ 的绝对值之和：\n$$\n\\sum_{i=1}^{m} |J_{ij}| = \\sum_{i=1}^{m} |1| = \\sum_{i=1}^{m} 1 = m\n$$\n对于每一列 $j$（其中 $1 \\leq j \\leq n$），这个和都是常数。因此，这些相同和的最大值是 $m$。\n$$\n\\|J\\|_{1} = m\n$$\n\n**2. 计算 $\\infty$-范数，$\\|J\\|_{\\infty}$**\n矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的算子 $\\infty$-范数定义为最大绝对行和：\n$$\n\\|A\\|_{\\infty} = \\max_{1 \\leq i \\leq m} \\sum_{j=1}^{n} |a_{ij}|\n$$\n对于矩阵 $J$，我们计算任意一行 $i$ 的绝对值之和：\n$$\n\\sum_{j=1}^{n} |J_{ij}| = \\sum_{j=1}^{n} |1| = \\sum_{j=1}^{n} 1 = n\n$$\n对于每一行 $i$（其中 $1 \\leq i \\leq m$），这个和都是常数。这些相同和的最大值是 $n$。\n$$\n\\|J\\|_{\\infty} = n\n$$\n\n**3. 计算弗罗贝尼乌斯范数，$\\|J\\|_{F}$**\n矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的弗罗贝尼乌斯范数定义为：\n$$\n\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^{2}}\n$$\n对于矩阵 $J$，这变为：\n$$\n\\|J\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |1|^{2}} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} 1}\n$$\n这个双重求和表示矩阵中元素的总数，即 $mn$。\n$$\n\\|J\\|_{F} = \\sqrt{mn}\n$$\n\n**4. 计算 $2$-范数（谱范数），$\\|J\\|_{2}$**\n矩阵 $A$ 的算子 $2$-范数是其最大奇异值 $\\sigma_{\\max}(A)$。这等价于矩阵 $A^T A$ 的最大特征值的平方根。\n$$\n\\|A\\|_{2} = \\sqrt{\\lambda_{\\max}(A^T A)}\n$$\n对于我们的矩阵 $J$，我们首先构造矩阵 $J^T J$。矩阵 $J$ 是一个 $m \\times n$ 的全一矩阵，所以其转置 $J^T$ 是一个 $n \\times m$ 的全一矩阵。乘积 $J^T J$ 是一个 $n \\times n$ 的矩阵。该乘积的第 $(k,l)$ 个元素是：\n$$\n(J^T J)_{kl} = \\sum_{i=1}^{m} (J^T)_{ki} J_{il} = \\sum_{i=1}^{m} J_{ik} J_{il} = \\sum_{i=1}^{m} 1 \\cdot 1 = m\n$$\n因此，$J^T J$ 是一个 $n \\times n$ 的矩阵，其中每个元素都等于 $m$。我们可以将其写作 $J^T J = m U_n$，其中 $U_n$ 是 $n \\times n$ 的全一矩阵。$J^T J$ 的特征值是 $U_n$ 特征值的 $m$ 倍。\n\n矩阵 $U_n$ 的秩为 $1$，因为它的所有列都相同。一个秩为 $k$ 的矩阵至少有 $n-k$ 个零特征值。因此，$U_n$ 有一个特征值 $0$，其重数至少为 $n-1$。矩阵的特征值之和等于其迹。$U_n$ 的迹是 $\\text{Tr}(U_n) = \\sum_{i=1}^{n} 1 = n$。由于 $n-1$ 个特征值为 $0$，剩下的一个特征值必定是 $n$。所以，$U_n$ 的特征值是 $n$（重数为 $1$）和 $0$（重数为 $n-1$）。\n\n$J^T J = m U_n$ 的特征值因此是 $mn$（重数为 $1$）和 $0$（重数为 $n-1$）。最大特征值是 $\\lambda_{\\max}(J^T J) = mn$。\n$2$-范数是该值的平方根：\n$$\n\\|J\\|_{2} = \\sqrt{\\lambda_{\\max}(J^T J)} = \\sqrt{mn}\n$$\n\n综上所述，计算出的四个范数是：\n- $\\|J\\|_{1} = m$\n- $\\|J\\|_{2} = \\sqrt{mn}$\n- $\\|J\\|_{\\infty} = n$\n- $\\|J\\|_{F} = \\sqrt{mn}$\n\n最终答案按指定顺序以行向量形式呈现。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} m  & \\sqrt{mn}  & n  & \\sqrt{mn} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "虽然范数可以衡量矩阵的“大小”，但其他量（如谱半径）则决定了其在迭代过程中的长期动态行为。这项练习通过一个精心构造的矩阵，展示了谱半径本身并非一种范数，但它在判断迭代过程（如在优化算法中）的收敛性方面扮演着至关重要的角色。理解这一点对于分析深度学习模型的训练稳定性至关重要。",
            "id": "2449584",
            "problem": "在计算工程中使用的线性定点迭代中，迭代矩阵控制着稳定性。构造一个 $2 \\times 2$ 的实矩阵 $A$，使其满足两个性质：$\\rho(A) = 0$ 和 $\\|A\\|_{F} = 1$，其中 $\\rho(A)$ 表示谱半径，$\\|A\\|_{F}$ 表示弗罗贝尼乌斯范数。然后确定极限的精确值\n$$\nL = \\lim_{k \\to \\infty} \\|A^{k}\\|_{F}.\n$$\n请以一个实数形式给出你的答案。无需四舍五入。",
            "solution": "该问题陈述经过验证，被认为是科学上合理的、适定的和客观的。它提出了一个线性代数中可解的问题，与计算工程直接相关。我们将进行严谨的求解。\n\n该问题要求我们首先理解给定性质对于一个 $2 \\times 2$ 实矩阵 $A$ 的含义，然后计算一个涉及其幂的极限。这些性质是：\n$1$. 谱半径 $\\rho(A) = 0$。\n$2$. 弗罗贝尼乌斯范数 $\\|A\\|_{F} = 1$。\n\n矩阵 $A$ 的谱半径 $\\rho(A)$ 定义为其特征值绝对值的最大值。\n$$\n\\rho(A) = \\max_{i} |\\lambda_i|\n$$\n其中 $\\lambda_i$ 是 $A$ 的特征值。对于给定的 $2 \\times 2$ 矩阵 $A$，设其特征值为 $\\lambda_1$ 和 $\\lambda_2$。条件 $\\rho(A) = 0$ 意味着 $\\max(|\\lambda_1|, |\\lambda_2|) = 0$。这只在 $|\\lambda_1| = 0$ 且 $|\\lambda_2| = 0$ 时才可能成立，即两个特征值都必须为零：$\\lambda_1 = \\lambda_2 = 0$。\n\n所有特征值都为零的矩阵是幂零矩阵。$A$ 的特征多项式，记为 $p(\\lambda)$，由 $p(\\lambda) = \\det(A - \\lambda I)$ 给出。由于特征多项式的根是矩阵的特征值，对于 $A$，我们有：\n$$\np(\\lambda) = (\\lambda - \\lambda_1)(\\lambda - \\lambda_2) = (\\lambda - 0)(\\lambda - 0) = \\lambda^2\n$$\n根据凯莱-哈密顿定理，每个方阵都满足其自身的特征方程。因此，将矩阵 $A$ 代入其特征多项式会得到零矩阵：\n$$\np(A) = A^2 = O\n$$\n其中 $O$ 是 $2 \\times 2$ 的零矩阵。因此，任何满足 $\\rho(A)=0$ 的 $2 \\times 2$ 矩阵 $A$ 都必须满足 $A^2 = O$。第二个条件 $\\|A\\|_{F}=1$ 确保了 $A$ 本身不是零矩阵，因为 $\\|O\\|_F = 0$。因此，$A$ 是一个指数为 $2$ 的非零幂零矩阵。\n\n一个显式的构造证实了这种矩阵的存在。考虑矩阵\n$$\nA = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\n$$\n这是一个上三角矩阵，所以其特征值是其对角线元素，即 $\\lambda_1 = 0$ 和 $\\lambda_2 = 0$。因此，$\\rho(A) = 0$。弗罗贝尼乌斯范数计算如下\n$$\n\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{2} \\sum_{j=1}^{2} |a_{ij}|^2} = \\sqrt{0^2 + 1^2 + 0^2 + 0^2} = \\sqrt{1} = 1\n$$\n两个条件都满足。计算其平方得到：\n$$\nA^2 = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix} = O\n$$\n这证实了我们从凯莱-哈密顿定理得出的推论。\n\n问题要求计算极限 $L = \\lim_{k \\to \\infty} \\|A^{k}\\|_{F}$。我们必须分析对于整数 $k \\ge 1$ 的矩阵幂 $A^k$ 的序列。\n对于 $k=1$：$A^1 = A$。\n对于 $k=2$：$A^2 = O$。\n对于 $k=3$：$A^3 = A^2 \\cdot A = O \\cdot A = O$。\n通过归纳法，对于任何整数 $k \\ge 2$，矩阵的幂 $A^k$ 都是零矩阵：\n$$\nA^k = O \\quad \\forall k \\ge 2\n$$\n现在，我们考虑这些矩阵幂的弗罗贝尼乌斯范数序列 $\\{ \\|A^k\\|_F \\}_{k=1}^\\infty$。\n对于 $k=1$，我们有 $\\|A^1\\|_F = \\|A\\|_F = 1$。\n对于任何整数 $k \\ge 2$，我们有 $\\|A^k\\|_F = \\|O\\|_F$。零矩阵的弗罗贝尼乌斯范数是：\n$$\n\\|O\\|_{F} = \\sqrt{0^2 + 0^2 + 0^2 + 0^2} = 0\n$$\n因此，这个实数序列是 $\\{1, 0, 0, 0, \\dots\\}$。当 $k \\to \\infty$ 时，该序列的极限是序列项最终达到并保持的值。对于任何整数 $k > 1$，序列中的项为 $0$。根据极限的正式定义，对于任意选择的 $\\epsilon > 0$，我们可以选取整数 $N=1$。那么，对于所有 $k > N$，我们有 $\\|A^k\\|_F = 0$，因此 $|\\|A^k\\|_F - 0| = 0  \\epsilon$。\n\n该极限明确无误地是 $0$。\n$$\nL = \\lim_{k \\to \\infty} \\|A^{k}\\|_{F} = 0\n$$\n只要矩阵 $A$ 满足所述性质，结果与 $A$ 的具体选择无关。由 $\\rho(A)=0$ 施加于 $2 \\times 2$ 矩阵的结构决定了这一结果。",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "矩阵的 $2$-范数（或称谱范数）在理论和应用中都极为重要，但它的计算也最为复杂。这项实践将引导你超越简单的定义，从推导到实现，掌握用于高效估算此范数的经典算法——幂迭代法。这个练习旨在搭建抽象理论与实际计算之间的桥梁，让你了解在实践中我们是如何获得并使用这些关键的数学工具的。",
            "id": "2449590",
            "problem": "要求您设计并实现一个确定性程序，该程序使用基于幂迭代的算法来估计实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的诱导矩阵 $2$-范数 $\\lVert A \\rVert_2$。您只能从向量和矩阵范数的基本定义以及对称矩阵特征值的基本性质出发。您的目标是推导、论证并编码一个算法，该算法不依赖于显式构建除标准矩阵-向量乘法之外的任何矩阵乘积，并且适用于方阵和矩形矩阵。\n\n要完成的任务：\n1. 从诱导矩阵 $2$-范数的核心定义 $\\lVert A \\rVert_2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2}$ 以及对于任何实矩阵 $A$，矩阵 $A^\\top A$ 都是对称半正定的这一事实出发，推导出一个迭代方案。该方案通过重复应用形式为 $A \\mathbf{x}$ 和 $A^\\top \\mathbf{y}$ 的矩阵-向量乘法来估计 $\\lVert A \\rVert_2$，而无需显式地构建 $A^\\top A$。您的推导必须基于这些定义和性质，并应包含一个基于估计值变化的明确停止准则。\n2. 将推导出的算法实现为一个完整的、可运行的程序。该算法必须：\n   - 使用 $\\mathbb{R}^n$ 中的一个确定性非零向量进行初始化，并在 $\\ell_2$ 意义上对其进行归一化，在每次迭代中仅使用 $A \\mathbf{x}$ 和 $A^\\top \\mathbf{y}$ 操作。\n   - 当连续迭代之间估计范数的相对变化低于容差 $\\varepsilon = 10^{-10}$ 时，或达到最大迭代次数 $10^4$ 次时终止，以先到者为准。\n   - 稳健地处理边界情况 $A = 0$，得出估计值 $\\lVert A \\rVert_2 = 0$。\n   - 返回 $\\lVert A \\rVert_2$ 的一个非负估计值。\n3. 您的程序必须评估以下矩阵测试套件，并以指定的格式报告估计的范数：\n   - 情况 $1$ (方阵，对称正定)：\n     $$A_1 = \\begin{bmatrix} 3  1 \\\\ 1  3 \\end{bmatrix}.$$\n   - 情况 $2$ (方阵，高度非正规)：\n     $$A_2 = \\begin{bmatrix} 1  10  0 \\\\ 0  1  0 \\\\ 0  0  0.1 \\end{bmatrix}.$$\n   - 情况 $3$ (高矩形)：\n     $$A_3 = \\begin{bmatrix} 1  2 \\\\ 0  1 \\\\ 2  0 \\\\ 0  0 \\end{bmatrix}.$$\n   - 情况 $4$ (宽矩形)：\n     $$A_4 = \\begin{bmatrix} 1  0  2  0 \\\\ 0  1  0  1 \\end{bmatrix}.$$\n   - 情况 $5$ (零矩阵)：\n     $$A_5 = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}.$$\n   - 情况 $6$ (方阵，具有接近的多个主导奇异值)：\n     $$A_6 = \\begin{bmatrix} 1  0 \\\\ 0  0.999 \\end{bmatrix}.$$\n4. 最终输出格式：您的程序应生成单行输出，其中包含六个估计范数的结果，按 $A_1$ 到 $A_6$ 的顺序排列，以逗号分隔，并用方括号括起来。每个值必须四舍五入到8位小数。例如，一个有效的输出格式是\n   $$[\\text{v}_1,\\text{v}_2,\\text{v}_3,\\text{v}_4,\\text{v}_5,\\text{v}_6],$$\n   其中每个 $\\text{v}_i$ 是一个四舍五入到8位小数的小数。不应打印额外的文本或行。\n\n实现约束：\n- 程序必须是完全自包含的，无需用户输入，并且仅使用 Python 标准库和允许的库。\n- 此问题不使用角度。\n- 不涉及物理单位。",
            "solution": "该问题要求推导并实现一个迭代算法，用于估计实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的诱导矩阵 $2$-范数 $\\lVert A \\rVert_2$。推导过程必须基于第一性原理，并避免显式构建如 $A^\\top A$ 之类的矩阵乘积。\n\n首先对问题陈述进行验证。\n\n**步骤 1：提取已知条件**\n- **定义**：诱导矩阵 $2$-范数定义为 $\\lVert A \\rVert_2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2}$。\n- **性质**：对于任何实矩阵 $A$，矩阵 $A^\\top A$ 都是对称半正定的。\n- **算法目标**：推导一个仅使用形式为 $A \\mathbf{x}$ 和 $A^\\top \\mathbf{y}$ 的矩阵-向量乘法来估计 $\\lVert A \\rVert_2$ 的迭代方案。\n- **实现约束**：\n  - **初始化**：使用 $\\mathbb{R}^n$ 中一个确定性的、归一化的、非零的向量。\n  - **停止准则**：当范数估计值的相对变化小于容差 $\\varepsilon = 10^{-10}$ 时，或在达到最大迭代次数 $10^4$ 次后终止。\n  - **边界情况**：正确处理零矩阵 $A = 0$，得出估计值 $0$。\n  - **返回值**：函数必须返回 $\\lVert A \\rVert_2$ 的一个非负估计值。\n- **测试套件**：提供了六个矩阵（$A_1$ 到 $A_6$）用于评估。\n- **输出格式**：单行输出，包含一个用方括号括起来的、以逗号分隔的六个估计范数列表，每个值四舍五入到8位小数。\n\n**步骤 2：使用提取的已知条件进行验证**\n1.  **科学依据**：该问题基于诱导 $2$-范数的标准定义及其与 $A^\\top A$ 最大特征值的基本关系。所提出的方法，即幂迭代法，是数值线性代数中用于寻找主特征值的经典且科学可靠的算法。该问题牢固地建立在公认的数学原理之上。\n2.  **适定性**：该问题是适定的。它要求估计一个唯一定义的数学量（$\\lVert A \\rVert_2$）。算法的终止由最大迭代限制和收敛准则保证。\n3.  **客观性**：问题以精确、客观的数学语言陈述，没有歧义或主观论断。\n4.  **缺陷分析**：\n    - **科学或事实上的不健全**：无。所有前提都是正确的。\n    - **非形式化或不相关**：无。该问题是计算工程和数值分析中的一个标准任务，直接涉及向量和矩阵范数。\n    - **不完整或矛盾的设置**：无。所有必要的组成部分都已指定：目标、方法限制、终止准则和测试用例。\n    - **不切实际或不可行**：无。该算法是实用的，测试矩阵是标准示例。\n    - **病态或结构不良**：无。结构清晰，从理论推导到实现都有指导。\n    - **超出科学可验证性**：无。算法的正确性及其结果的准确性可以通过与已知的解析解或标准库函数（例如，奇异值分解）进行比较来验证。\n\n**步骤 3：结论与行动**\n该问题被判定为**有效**。将提供一个完整、合理的解决方案。\n\n**推导与算法设计**\n\n出发点是矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的诱导矩阵 $2$-范数的定义：\n$$\n\\lVert A \\rVert_2 = \\sup_{\\mathbf{x} \\in \\mathbb{R}^n, \\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2}\n$$\n由于范数总是非负的，我们可以考虑它的平方：\n$$\n\\lVert A \\rVert_2^2 = \\left( \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2}{\\lVert \\mathbf{x} \\rVert_2} \\right)^2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\lVert A \\mathbf{x} \\rVert_2^2}{\\lVert \\mathbf{x} \\rVert_2^2}\n$$\n使用欧几里得范数的定义 $\\lVert \\mathbf{v} \\rVert_2^2 = \\mathbf{v}^\\top \\mathbf{v}$，我们可以将表达式重写为：\n$$\n\\lVert A \\rVert_2^2 = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{(A \\mathbf{x})^\\top (A \\mathbf{x})}{\\mathbf{x}^\\top \\mathbf{x}} = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\mathbf{x}^\\top A^\\top A \\mathbf{x}}{\\mathbf{x}^\\top \\mathbf{x}}\n$$\n此表达式是矩阵 $B = A^\\top A$ 的瑞利商。线性代数中的一个基本定理指出，对称矩阵的瑞利商的上确界是其最大特征值 $\\lambda_{\\text{max}}$。矩阵 $B = A^\\top A$ 确实是对称的（因为 $(A^\\top A)^\\top = A^\\top (A^\\top)^\\top = A^\\top A$）并且是半正定的。因此，我们有以下关键关系：\n$$\n\\lVert A \\rVert_2^2 = \\lambda_{\\text{max}}(A^\\top A)\n$$\n这意味着诱导矩阵 $2$-范数是 $A^\\top A$ 最大特征值的平方根：\n$$\n\\lVert A \\rVert_2 = \\sqrt{\\lambda_{\\text{max}}(A^\\top A)}\n$$\n根据定义，值 $\\sqrt{\\lambda_{\\text{max}}(A^\\top A)}$ 也是 $A$ 的最大奇异值，记作 $\\sigma_1(A)$。\n\n问题现在简化为在不显式计算矩阵 $A^\\top A$ 的情况下找到 $\\lambda_{\\text{max}}(A^\\top A)$。这可以通过**幂迭代**法来实现。幂迭代法是一种迭代算法，用于找到模最大的特征值（主特征值）及其对应的特征向量。对于像 $A^\\top A$ 这样的对称半正定矩阵，所有特征值都是实数且非负的，因此模最大的特征值就是 $\\lambda_{\\text{max}}$。\n\n矩阵 $B$ 的标准幂迭代法如下：\n1.  从一个非零向量 $\\mathbf{v}_0$ 开始。\n2.  对 $k = 1, 2, \\dots$ 进行迭代：$\\mathbf{v}_k = \\frac{B \\mathbf{v}_{k-1}}{\\lVert B \\mathbf{v}_{k-1} \\rVert_2}$。\n只要初始向量 $\\mathbf{v}_0$ 在对应 $\\lambda_{\\text{max}}(B)$ 的特征向量方向上有非零分量，向量序列 $\\{\\mathbf{v}_k\\}$ 就会收敛到该特征向量。\n\n在我们的情况下，$B = A^\\top A$。迭代步骤为 $\\mathbf{v}_k \\propto (A^\\top A) \\mathbf{v}_{k-1}$。按照要求，我们通过执行两个连续的矩阵-向量乘积来避免构建 $A^\\top A$：\n1.  首先，计算 $\\mathbf{y}_{k-1} = A \\mathbf{v}_{k-1}$。\n2.  然后，计算 $\\mathbf{x}_k = A^\\top \\mathbf{y}_{k-1}$。\n所以，核心更新是 $\\mathbf{x}_k = A^\\top (A \\mathbf{v}_{k-1})$。下一个归一化向量是 $\\mathbf{v}_k = \\mathbf{x}_k / \\lVert \\mathbf{x}_k \\rVert_2$。\n\n我们还需要在每次迭代中估计 $\\lambda_{\\text{max}}(A^\\top A)$。这可以通过使用当前特征向量的估计值 $\\mathbf{v}_{k-1}$ 的瑞利商得到：\n$$\n\\lambda_k \\approx \\frac{\\mathbf{v}_{k-1}^\\top (A^\\top A) \\mathbf{v}_{k-1}}{\\mathbf{v}_{k-1}^\\top \\mathbf{v}_{k-1}}\n$$\n由于 $\\mathbf{v}_{k-1}$ 是一个单位向量（$\\lVert \\mathbf{v}_{k-1} \\rVert_2 = 1$），其分母为 $1$。分子变为：\n$$\n\\mathbf{v}_{k-1}^\\top A^\\top A \\mathbf{v}_{k-1} = (A \\mathbf{v}_{k-1})^\\top (A \\mathbf{v}_{k-1}) = \\mathbf{y}_{k-1}^\\top \\mathbf{y}_{k-1} = \\lVert \\mathbf{y}_{k-1} \\rVert_2^2\n$$\n因此，第 $k$ 次迭代时最大特征值的估计值为 $\\lambda_k = \\lVert A \\mathbf{v}_{k-1} \\rVert_2^2$。\n因此，矩阵 $2$-范数的估计值 $\\sigma_k = \\sqrt{\\lambda_k}$ 就简化为：\n$$\n\\sigma_k = \\lVert A \\mathbf{v}_{k-1} \\rVert_2 = \\lVert \\mathbf{y}_{k-1} \\rVert_2\n$$\n这提供了一种在每次迭代中简单高效地更新范数估计值的方法。\n\n**最终算法：**\n设 $A$ 是一个 $m \\times n$ 矩阵。设 $\\varepsilon = 10^{-10}$ 为容差，$K_{\\text{max}} = 10^4$ 为最大迭代次数。\n\n1.  **处理平凡情况**：如果 $n=0$，定义域为空，所以 $\\lVert A \\rVert_2 = 0$。\n2.  **初始化**：\n    - 选择一个确定性的非零起始向量 $\\mathbf{v}_0 \\in \\mathbb{R}^n$。一个标准的选择是全为1的向量。\n    - 对其进行归一化：$\\mathbf{v} \\leftarrow \\frac{\\mathbf{v}_0}{\\lVert \\mathbf{v}_0 \\rVert_2}$。\n    - 初始化范数估计值，例如，$\\sigma_{\\text{new}} \\leftarrow 0$。\n3.  **迭代**：对于 $k=1, \\dots, K_{\\text{max}}$：\n    a.  存储前一个估计值：$\\sigma_{\\text{old}} \\leftarrow \\sigma_{\\text{new}}$。\n    b.  应用第一个矩阵-向量乘积：$\\mathbf{y} \\leftarrow A \\mathbf{v}$。\n    c.  更新范数估计值：$\\sigma_{\\text{new}} \\leftarrow \\lVert \\mathbf{y} \\rVert_2$。\n    d.  **检查收敛性**：如果 $k1$ 且 $|\\sigma_{\\text{new}} - \\sigma_{\\text{old}}|  \\varepsilon \\cdot \\sigma_{\\text{new}}$，则跳出循环。\n    e.  **处理零矩阵情况**：如果 $\\sigma_{\\text{new}} = 0$，这意味着 $\\mathbf{y}=\\mathbf{0}$。这表示 $A\\mathbf{v}=\\mathbf{0}$。矩阵 $A$ 是奇异的，或者可能是零矩阵。算法正确地得出 $\\sigma_{\\text{new}} = 0$ 并应终止。我们可以跳出循环。\n    f.  应用第二个矩阵-向量乘积：$\\mathbf{x} \\leftarrow A^\\top \\mathbf{y}$。\n    g.  为下一次迭代归一化结果向量：$\\mathbf{v} \\leftarrow \\frac{\\mathbf{x}}{\\lVert \\mathbf{x} \\rVert_2}$。如果 $\\lVert \\mathbf{x} \\rVert_2 = 0$，则跳出循环。这种情况发生在 $\\mathbf{y}$ 位于 $A^\\top$ 的零空间中，对于 $\\mathbf{y}=A\\mathbf{v}$ 而言，这意味着 $A\\mathbf{v}=\\mathbf{0}$，从而正确地得到范数为 $0$。\n4.  **返回**：最终估计值 $\\sigma_{\\text{new}}$。\n\n该算法仅使用矩阵-向量乘积，遵守所有约束，并能正确估计 $\\lVert A \\rVert_2$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_induced_2_norm(A, tol=1e-10, max_iter=10000):\n    \"\"\"\n    Estimates the induced matrix 2-norm (largest singular value) of a real matrix A\n    using the power iteration method.\n\n    The algorithm iteratively computes v_k = A^T * A * v_{k-1} without explicitly\n    forming the matrix A^T*A. The norm is estimated as ||A*v_k||_2.\n\n    Args:\n        A (np.ndarray): The input matrix, m x n.\n        tol (float): The relative tolerance for convergence.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        float: The estimated induced 2-norm of A.\n    \"\"\"\n    # Get matrix dimensions\n    m, n = A.shape\n\n    # Handle the edge case of a matrix with zero columns.\n    if n == 0:\n        return 0.0\n\n    # Initialize with a deterministic non-zero vector in R^n.\n    # A vector of ones is a standard deterministic choice.\n    # The power method might fail if this initial vector is orthogonal\n    # to the dominant eigenvector of A^T*A. In practice, for general\n    # matrices and with finite-precision arithmetic, this is rare.\n    v = np.ones(n)\n    v /= np.linalg.norm(v)\n\n    norm_est = 0.0\n\n    for _ in range(max_iter):\n        norm_est_prev = norm_est\n\n        # First matrix-vector product: y = A*v\n        y = A @ v\n\n        # Update the norm estimate: ||A||_2 approx ||y||_2\n        norm_est = np.linalg.norm(y)\n\n        # Check for convergence using relative change.\n        # This check is safe because for a non-zero matrix, norm_est converges\n        # to a positive value.\n        if norm_est  0 and abs(norm_est - norm_est_prev)  tol * norm_est:\n            break\n        \n        # Handle the case where A is the zero matrix or v is in the null space of A.\n        if norm_est == 0:\n            return 0.0\n\n        # Second matrix-vector product: x = A^T*y\n        x = A.T @ y\n        \n        # Normalize the vector for the next iteration.\n        norm_x = np.linalg.norm(x)\n\n        # If norm_x is zero, the iteration has converged to the null space.\n        if norm_x == 0:\n            break\n            \n        v = x / norm_x\n\n    return norm_est\n\n\ndef solve():\n    \"\"\"\n    Defines the test cases, runs the norm estimation, and prints the results.\n    \"\"\"\n    \n    A1 = np.array([[3.0, 1.0], \n                   [1.0, 3.0]])\n\n    A2 = np.array([[1.0, 10.0, 0.0],\n                   [0.0, 1.0, 0.0],\n                   [0.0, 0.0, 0.1]])\n\n    A3 = np.array([[1.0, 2.0],\n                   [0.0, 1.0],\n                   [2.0, 0.0],\n                   [0.0, 0.0]])\n\n    A4 = np.array([[1.0, 0.0, 2.0, 0.0],\n                   [0.0, 1.0, 0.0, 1.0]])\n\n    A5 = np.array([[0.0, 0.0, 0.0],\n                   [0.0, 0.0, 0.0],\n                   [0.0, 0.0, 0.0]])\n\n    A6 = np.array([[1.0, 0.0],\n                   [0.0, 0.999]])\n                   \n    test_cases = [A1, A2, A3, A4, A5, A6]\n\n    results = []\n    for A in test_cases:\n        norm_estimate = estimate_induced_2_norm(A, tol=1e-10, max_iter=10000)\n        results.append(f\"{norm_estimate:.8f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}