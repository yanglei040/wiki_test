{
    "hands_on_practices": [
        {
            "introduction": "在深度学习编程中，一个常见且隐蔽的错误是张量操作的轴向错位。即使张量的形状（shape）在操作后看起来正确，但如果计算发生在错误的轴上，模型的语义就会完全错误，导致难以追踪的bug。这个练习将向你展示如何利用线性代数的基本性质，如等变性（equivariance）和不变性（invariance），来设计强大的单元测试，以确保张量操作的语义正确性。",
            "id": "3143508",
            "problem": "一位数据科学家在使用张量缩并实现序列模型中的一个线性层。令 $X \\in \\mathbb{R}^{B \\times T \\times D}$ 表示一个小批量（$B$）序列，包含 $T$ 个时间步，每个时间步有 $D$ 个特征通道。令 $W \\in \\mathbb{R}^{D \\times K}$ 是一个将特征映射到 $K$ 个输出的权重矩阵。预期的操作是通过将 $X$ 的最后一个轴与 $W$ 的第一个轴进行缩并来生成 $Y \\in \\mathbb{R}^{B \\times T \\times K}$，即，对于每个 $b$、$t$ 和 $k$，$Y_{b,t,k}$ 应等于 $X_{b,t,i} W_{i,k}$ 对特征索引 $i$ 的求和。假设一个 bug 缩并了错误的轴（例如，时间轴），当 $T=D$ 时，这可以在形状检查中静默通过，但会产生不正确的语义。\n\n您的任务是选择一个最小的单元测试集，这些测试基于不变性和等变性，能够可靠地检测出轴错位，无论具体的数值如何，甚至在 $T=D$ 导致形状具有欺骗性的兼容性的情况下也能检测出来。您的选择应基于张量缩并、单位矩阵、置换矩阵和正交基变换的基本性质。\n\n哪个选项描述了一个最小的单元测试集，可以在此场景下检测到轴错位？\n\nA. 两个测试：\n- 单位权重测试：选择 $D=K$ 并设置 $W = I_{D}$；断言 $f(X,W) = X$ 精确成立。\n- 时间置换等变性：令 $\\Pi \\in \\mathbb{R}^{T \\times T}$ 为一个置换矩阵；断言 $f(X \\Pi^{\\top}, W) = (f(X,W)) \\Pi^{\\top}$。\n\nB. 单个测试：\n- 特征轴基变换不变性：选择一个随机正交矩阵 $Q \\in \\mathbb{R}^{D \\times D}$，满足 $Q^{\\top} Q = I_{D}$，并设置 $W' = Q^{-1} W$；断言 $f(X Q, W') = f(X, W)$。\n\nC. 单个测试：\n- 对 $X$ 的线性：选择 $X_{1}, X_{2} \\in \\mathbb{R}^{B \\times T \\times D}$；断言 $f(X_{1}+X_{2}, W) = f(X_{1}, W) + f(X_{2}, W)$。\n\nD. 两个测试：\n- 批量置换等变性：令 $P \\in \\mathbb{R}^{B \\times B}$ 为一个置换矩阵；断言 $f(P X, W) = P f(X, W)$。\n- 正齐次性：对于任何 $\\alpha \\in \\mathbb{R}$，断言 $f(\\alpha X, W) = \\alpha f(X, W)$。\n\n此处，$f$ 表示为实现所述层而编写的张量缩并函数。请选择能够产生最小测试集的选项，该测试集能稳健地检测错位，且不包含冗余检查。",
            "solution": "用户请求对一个应用于深度学习的线性代数问题进行精确、教授式的验证和解答。\n\n### 问题验证\n\n我将首先按照要求的协议验证问题陈述。\n\n#### 步骤1：提取已知条件\n-   **输入张量 `X`**：$X \\in \\mathbb{R}^{B \\times T \\times D}$，表示一个包含 $B$ 个序列的小批量，每个序列有 $T$ 个时间步和 $D$ 个特征。\n-   **权重矩阵 `W`**：$W \\in \\mathbb{R}^{D \\times K}$，一个将 $D$ 个输入特征映射到 $K$ 个输出特征的权重矩阵。\n-   **输出张量 `Y`**：$Y \\in \\mathbb{R}^{B \\times T \\times K}$。\n-   **预期操作 `f_correct`**：输出张量的分量由公式 $Y_{b,t,k} = \\sum_{i=1}^{D} X_{b,t,i} W_{i,k}$ 给出。这对应于将 $X$ 的最后一个轴（维度 $D$）与 $W$ 的第一个轴（维度 $D$）进行张量缩并。此操作对每个批次元素 $b \\in \\{1, ..., B\\}$ 和每个时间步 $t \\in \\{1, ..., T\\}$ 独立应用。\n-   **Bug**：实现的函数，记为 $f(X, W)$，沿着一个不正确的轴进行缩并。给出的例子是缩并 $X$ 的时间轴（维度 $T$）与 $W$ 的特征轴（维度 $D$）。如果 $T=D$，这是可能的，并且该 bug 可以“在形状检查中静默通过”，意味着输出张量具有预期的形状 $\\mathbb{R}^{B \\times T \\times K}$。\n-   **目标**：基于不变性和等变性等基本性质，选择一个最小的单元测试集，能够可靠地检测此类轴错位。\n\n#### 步骤2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题设置在深度学习的背景下，使用了线性代数的基本概念，特别是张量缩并。等变性、不变性、置换矩阵和正交基变换的概念都是标准、严谨的数学概念。在数值计算库中出现索引 bug 的场景既真实又常见。该问题在科学上和数学上都是合理的。\n2.  **适定性**：问题是适定的。它清晰地定义了正确的行为和待检测的错误性质。它要求从给定的选项列表中选出“最小集”的测试，这是一个明确的目标。通过逻辑推导和对操作数学性质的分析，可以在选项中确定唯一的最优答案。\n3.  **客观性**：语言精确、正式，没有主观性。所有术语都是数学和计算机科学中的标准术语。\n4.  **完整性**：问题陈述是自洽的。它提供了张量、它们的维度、正确的操作以及要检测的 bug 类的所有必要定义。\n5.  **无其他缺陷**：这个问题并非微不足道，因为它需要理解与不同张量轴相关的特定属性（等变性/不变性）。它不是病态的、矛盾的，也不是基于有缺陷的前提。\n\n#### 步骤3：结论与行动\n问题陈述**有效**。我现在将进行完整的解答和分析。\n\n### 推导与选项分析\n\n令 $f_{correct}(X, W)$ 为预期操作，$f_{bug}(X, W)$ 为有问题的实现。\n\n正确的操作由以下公式给出：\n$$ (f_{correct}(X, W))_{b,t,k} = \\sum_{i=1}^{D} X_{b,t,i} W_{i,k} $$\n此操作是由 $W$ 定义的线性变换，应用于每个批次 $b$ 和时间步 $t$ 的 $D$ 维特征向量 $X_{b,t,:}$。\n\n如问题所述，有问题的操作缩并了 $X$ 的时间轴（轴1，维度 $T$）与 $W$ 的特征轴（轴0，维度 $D$）。这仅在 $T=D$ 时在计算上是可能的。为了确保输出形状为 $B \\times T \\times K$，实现必须适当地映射剩余的轴。当 $T=D$ 时，有问题的操作的一种可能形式是：\n$$ (f_{bug}(X, W))_{b,i,k} = \\sum_{t=1}^{T} X_{b,t,i} W_{t,k} $$\n注意索引 $t$ 和 $i$ 的角色互换。求和是针对时间步 $t$ 进行的，输出的第二个索引对应于特征通道 $i$。为了使形状匹配预期的 $B \\times T \\times K$，实现可能会隐式地置换输出轴，例如，定义输出 $Y$ 为 $Y_{b,t,k} = (f_{bug}(X, W))_{b,k,t}$。然而，根本的错误计算仍然是对时间轴的求和。我们将基于核心计算来分析这些属性。\n\n我们必须找到一个 $f_{correct}$ 通过但 $f_{bug}$ 失败的测试。该测试集还必须是最小的。\n\n#### 选项C的评估\n**C. 单个测试：对 $X$ 的线性。**\n该测试断言 $f(X_{1}+X_{2}, W) = f(X_{1}, W) + f(X_{2}, W)$。\n-   对于 $f_{correct}$：\n    $$ \\sum_{i} (X_{1,b,t,i} + X_{2,b,t,i}) W_{i,k} = \\sum_{i} X_{1,b,t,i} W_{i,k} + \\sum_{i} X_{2,b,t,i} W_{i,k} $$\n    此性质成立。\n-   对于 $f_{bug}$：\n    $$ \\sum_{t} (X_{1,b,t,i} + X_{2,b,t,i}) W_{t,k} = \\sum_{t} X_{1,b,t,i} W_{t,k} + \\sum_{t} X_{2,b,t,i} W_{t,k} $$\n    此性质也成立。\n正确和有问题的操作都是张量缩并，它们本质上都是线性操作（或更准确地说，是多线性操作）。此测试检查的是线性，两种实现都具备该性质。因此，它无法区分两者。\n**结论：不正确。**\n\n#### 选项D的评估\n**D. 两个测试：批量置换等变性和正齐次性。**\n-   **正齐次性**：$f(\\alpha X, W) = \\alpha f(X, W)$。这是线性的直接推论，我们在 C 中已经确定，两种实现都满足此性质。因此，此测试不具有区分性。\n-   **批量置换等变性**：$f(P X, W) = P f(X, W)$，其中 $P \\in \\mathbb{R}^{B \\times B}$ 是作用于批量轴的置换矩阵。无论是正确还是有问题的操作，都是独立应用于批量的每个元素的。沿批量轴置换输入元素，只会导致输出元素发生相应的置换。$f_{correct}$ 和 $f_{bug}$ 都关于批量轴上的置换是等变的。\n此选项中的两个测试检查的都是过于通用的属性，正确和有问题的实现都共享这些属性。\n**结论：不正确。**\n\n#### 选项A的评估\n**A. 两个测试：单位权重测试和时间置換等变性。**\n1.  **单位权重测试**：对于 $D=K$，设置 $W=I_D$。断言 $f(X, W) = X$。\n    -   对于 $f_{correct}$：$(f_{correct}(X, I_D))_{b,t,k} = \\sum_{i} X_{b,t,i} (I_D)_{i,k} = \\sum_{i} X_{b,t,i} \\delta_{ik} = X_{b,t,k}$。测试通过。\n    -   对于 $f_{bug}$（需要 $T=D=K$）：$(f_{bug}(X, I_D))_{b,i,k} = \\sum_{t} X_{b,t,i} (I_D)_{t,k} = \\sum_{t} X_{b,t,i} \\delta_{tk} = X_{b,k,i}$。测试断言输出为 $X$，即 $(f(X,I_D))_{b,t,k} = X_{b,t,k}$。有问题的实现产生的输出中，时间和特征轴被交换了：$X_{b,k,t}$。除非 $X$ 在其最后两个维度上是对称的（即 $X_{b,k,t} = X_{b,t,k}$），否则该测试将失败。这个测试是有效的。\n2.  **时间置換等变性**：令 $\\Pi \\in \\mathbb{R}^{T \\times T}$ 为一个置换矩阵。断言 $f(X \\Pi^{\\top}, W) = (f(X,W)) \\Pi^{\\top}$。这个符号表示 $\\Pi^{\\top}$ 置换了它所乘张量的时间轴。\n    -   对于 $f_{correct}$：操作独立应用于每个时间切片 $X_{b,t,:}$。在操作前置换时间切片等同于先应用操作然后置換结果的时间切片。此等变性成立。\n    -   对于 $f_{bug}$：操作涉及对时间轴求和（$\\sum_t$）。这个求和打破了时间步之间的独立性。如果输入的时间步被置换，所得的和将以一种不等同于简单置换原始操作输出的方式改变。有问题的实现对于时间轴置换不是等变的。这个测试也是有效的。\n\n两个测试都能够检测到这个 bug。但是，问题要求的是一个**最小集**。由于任何一个测试本身都足够，一个包含两个测试的集合不是最小的。因此，这个选项不是最优的。\n**结论：不正确。**\n\n#### 选项B的评估\n**B. 单个测试：特征轴基变换不变性。**\n该测试断言对于任何正交矩阵 $Q \\in \\mathbb{R}^{D \\times D}$，$f(X Q, Q^{\\top} W) = f(X, W)$。\n-   对于 $f_{correct}$：此性质描述了线性映射在基变换下的行为。我们对输入向量（$X$ 的 $D$ 轴上的特征向量）应用一个基变换 $Q$，并对线性映射的矩阵 $W$ 应用相应的逆变换 $Q^{-1}=Q^{\\top}$。整个变换的结果必须是不变的。让我们来验证：\n    $$ (f_{correct}(XQ, Q^{\\top}W))_{b,t,k} = \\sum_{i} (XQ)_{b,t,i} (Q^{\\top}W)_{i,k} $$\n    $$ = \\sum_{i} \\left(\\sum_{j} X_{b,t,j} Q_{j,i}\\right) \\left(\\sum_{l} (Q^{\\top})_{i,l} W_{l,k}\\right) $$\n    $$ = \\sum_{j,l} X_{b,t,j} W_{l,k} \\left(\\sum_{i} Q_{j,i} (Q^{\\top})_{i,l}\\right) $$\n    项 $\\sum_{i} Q_{j,i} (Q^{\\top})_{i,l}$ 是矩阵乘积 $Q Q^{\\top}$ 的第 $(j,l)$ 个元素。由于 $Q$ 是正交矩阵，$Q Q^{\\top} = I_D$，所以该和为 $\\delta_{jl}$。\n    $$ = \\sum_{j,l} X_{b,t,j} W_{l,k} \\delta_{jl} = \\sum_{j} X_{b,t,j} W_{j,k} = (f_{correct}(X,W))_{b,t,k} $$\n    测试通过。\n-   对于 $f_{bug}$（需要 $T=D$）：基变换 $Q$ 应用于 $X$ 的特征轴（索引 $i$）。然而，有问题的实现是对时间轴（索引 $t$）进行缩并。变换 $Q$ 及其逆变换 $Q^{\\top}$ 被应用于没有被一起缩并的轴上。\n    $$ (f_{bug}(XQ, Q^{\\top}W))_{b,i,k} = \\sum_{t} (XQ)_{b,t,i} (Q^{\\top}W)_{t,k} $$\n    $$ = \\sum_{t} \\left(\\sum_{j} X_{b,t,j} Q_{j,i}\\right) \\left(\\sum_{l} (Q^{\\top})_{t,l} W_{l,k}\\right) $$\n    该表达式不会化简为 $(f_{bug}(X, W))_{b,i,k} = \\sum_{t} X_{b,t,i} W_{t,k}$。矩阵 $Q$ 和 $Q^\\top$ 不会抵消。对于通用的输入选择，该测试将失败。\n\n这个单一测试足以检测轴错位。它正确地探查了预期操作的核心属性：即它是一个作用于 $D$ 维特征空间上的线性映射。因为它是一个单一且充分的测试，所以仅包含此测试的集合是最小的。\n**结论：正确。**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "在确保了计算的正确性之后，下一个关键步骤是提升效率。深度学习模型中的张量运算规模庞大，因此计算性能至关重要。这个练习将探讨一个核心问题：如何通过重排张量的轴来优化内存访问模式，从而最大化硬件（如CPU或GPU）的计算效率。我们将以批处理矩阵乘法（batched matrix multiplication）为例，揭示抽象的线性代数操作与底层硬件性能之间的深刻联系。",
            "id": "3143504",
            "problem": "一个深度学习模型执行批处理线性变换，其中对于每个批次索引 $b$，形状为 $n \\times k$ 的矩阵 $\\mathbf{A}^{(b)}$ 与形状为 $k \\times m$ 的矩阵 $\\mathbf{B}^{(b)}$ 相乘，生成形状为 $n \\times m$ 的矩阵 $\\mathbf{C}^{(b)}$。以张量形式表示，输入为 $\\mathbf{A} \\in \\mathbb{R}^{b \\times n \\times k}$ 和 $\\mathbf{B} \\in \\mathbb{R}^{b \\times k \\times m}$，输出为 $\\mathbf{C} \\in \\mathbb{R}^{b \\times n \\times m}$。矩阵以行主序（C-连续）布局存储，元素为 32 位浮点数（即每个元素 4 字节）。硬件以大小为 64 字节的缓存行读取内存。您必须通过函数 $\\mathrm{einsum}$ 将此批处理操作表示为 Einstein 求和约定收缩，并提出一种通过重排坐标轴来提高算术强度（每移动一字节内存所执行的浮点运算次数，即 FLOPs）的优化方案。该方案应通过改善空间局部性来实现，并用张量步长算术来证明其合理性。\n\n基于以下基本原理进行分析：\n- 使用矩阵乘法的核心定义 $C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B_{b,t,j}$，以及 Einstein 求和约定的定义，其中重复的索引表示对该索引进行求和。\n- 使用行主序步长的定义：对于形状为 ($d_0, d_1, d_2$) 的张量，沿轴 0 的元素步长为 $d_1 d_2$，沿轴 1 的元素步长为 $d_2$，沿轴 2 的元素步长为 1。字节步长等于元素步长乘以 4。\n- 假设内核通过在最内层循环中对归约维度 $k$ 进行累加来计算每个输出元素 $C_{b,i,j}$。对于空间局部性，沿着最内层循环的连续访问（元素步长为 1）能充分利用每个缓存行，而至少 16 个元素（因为每个缓存行 64 字节，每个元素 4 字节）的步长则会导致每次访问很可能落在一个不同的缓存行上，从而导致重用率极低。\n\n设具体尺寸为 $b=32$, $n=64$, $k=128$, $m=64$。选择一个选项，该选项同时满足：\n(i) 提供一个正确的 $\\mathrm{einsum}$ 收缩字符串，用于从 $\\mathbf{A}$ 和 $\\mathbf{B}$ 计算 $\\mathbf{C}$；\n(ii) 提出一种轴重排方案，通过使归约维度 $k$ 在两个输入中都在内存中连续，并使输出写入沿着最内层生成的维度连续，从而最大化算术强度。\n\n在所述模型下，哪个选项满足以上条件并能实现最佳的浮点运算与内存访问比（FLOP-to-memory ratio）？\n\nA. 在将 $\\mathbf{B}$ 转置为形状 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bnm'})$，保持 $\\mathbf{A}$ 的形状为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。\n\nB. 使用原始形状的 $\\mathbf{A}$ (即 $(b,n,k)$) 和 $\\mathbf{B}$ (即 $(b,k,m)$)，通过 $\\mathrm{einsum}(\\texttt{'bnk,bkm->bnm'})$ 计算，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。\n\nC. 在将 $\\mathbf{A}$ 转置为 $(b,k,n)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bkn,bkm->bmn'})$，保持 $\\mathbf{B}$ 的形状为 $(b,k,m)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。\n\nD. 在将 $\\mathbf{B}$ 转置为 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bmn'})$，保持 $\\mathbf{A}$ 的形状为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。",
            "solution": "用户希望确定批处理矩阵乘法 $\\mathbf{C} = \\mathbf{A} \\mathbf{B}$ 的最优策略，重点是通过内存访问模式进行性能优化。\n\n### 问题陈述验证\n\n**步骤1：提取已知条件**\n- 批处理矩阵乘法：对于每个批次索引 $b$，$\\mathbf{C}^{(b)} = \\mathbf{A}^{(b)} \\mathbf{B}^{(b)}$。\n- 输入张量：$\\mathbf{A} \\in \\mathbb{R}^{b \\times n \\times k}$ 和 $\\mathbf{B} \\in \\mathbb{R}^{b \\times k \\times m}$。\n- 输出张量：$\\mathbf{C} \\in \\mathbb{R}^{b \\times n \\times m}$。\n- 逐元素公式：$C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B_{b,t,j}$。\n- 数据表示：行主序（C-连续）布局，32位浮点元素（4字节/元素）。\n- 硬件约束：缓存行大小为 64 字节。\n- 内核执行模型：最内层循环是对归约维度 $k$ 进行。\n- 空间局部性模型：元素步长为 1 的访问是连续且高效的。步长为 16 个元素（即 $16 \\times 4 = 64$ 字节）或更大的访问是低效的。\n- 具体维度：$b=32$, $n=64$, $k=128$, $m=64$。\n- 任务：找到具有正确 Einstein 求和 (`einsum`) 字符串的选项，以及通过 (1) 使两个输入的归约维度 $k$ 在内存中连续，和 (2) 使输出写入连续，来最大化算术强度的轴重排方案。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题基于线性代数（矩阵乘法）、计算机科学（张量表示、数据布局）和计算机体系结构（缓存局部性、内存步长、算术强度）的基本原理。这些是高性能计算和深度学习中的标准和关键概念。\n- **定义良好：** 该问题提供了一个明确的目标（找到最佳选项）和一套用于评估的定量标准（步长算术、`einsum` 的正确性）。简化的缓存行为模型允许进行确定性分析，从而在选项中找到唯一的最佳答案。\n- **客观性：** 该问题使用精确的技术语言陈述，没有主观或模糊的术语。\n\n**步骤3：结论与行动**\n问题陈述是有效的。它在科学上是合理的，定义良好，客观，并包含进行严谨分析所需的所有必要信息。我现在将继续进行解题推导。\n\n### 推导与选项分析\n\n**1. 基本原理：步长与基线性能**\n\n问题使用行主序内存布局。对于形状为 $(d_0, d_1, ..., d_{N-1})$ 的张量，轴 $i$ 的元素步长由 $S_i = \\prod_{j=i+1}^{N-1} d_j$ 给出，其中 $S_{N-1} = 1$。字节步长为 $4 \\times S_i$。\n\n该操作是批处理矩阵乘法 $C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B_{b,t,j}$。索引 $t$ 对应于大小为 $k$ 的维度。该操作的标准 `einsum` 表示是 `'bnk,bkm->bnm'`。这对应于选项B，我们将把它作为基线进行分析。\n\n**基线分析（原始布局）：**\n- $\\mathbf{A}$ 的形状为 $(b, n, k) = (32, 64, 128)$。其元素步长为 $(n \\times k, k, 1) = (64 \\times 128, 128, 1) = (8192, 128, 1)$。\n- $\\mathbf{B}$ 的形状为 $(b, k, m) = (32, 128, 64)$。其元素步长为 $(k \\times m, m, 1) = (128 \\times 64, 64, 1) = (8192, 64, 1)$。\n\n内核的最内层循环遍历归约维度 $k$。\n- 访问 $A_{b,i,t}$：随着 $t$ 递增，我们沿 $\\mathbf{A}$ 的最后一个维度访问元素。步长为 1。这是连续的，并表现出极佳的空间局部性。\n- 访问 $B_{b,t,j}$：随着 $t$ 递增，我们沿 $\\mathbf{B}$ 的中间维度访问元素。步长是 $k$ 维度的步长，即 $m=64$ 个元素。由于 $64 > 16$ （每个缓存行的元素数量），每次内存访问很可能位于不同的缓存行中，导致缓存利用率非常低。这是性能瓶颈。\n\n**2. 优化策略**\n\n为了满足优化目标，归约维度 $k$ 必须是两个输入张量的最后一个维度（步长为 1）。\n- $\\mathbf{A}$ 的形状已经是 $(b,n,k)$，因此其 'k' 维度已经是最后一个维度。我们保持其不变。\n- $\\mathbf{B}$ 的形状为 $(b,k,m)$。要使 'k' 成为最后一个维度，我们必须转置最后两个轴，创建一个新张量 $\\mathbf{B'}$，其形状为 $(b,m,k)$。这个新张量在其新形状下将是 C-连续的。\n- $\\mathbf{B'}$ 的元素与 $\\mathbf{B}$ 的关系为 $B'_{b,j,t} = B_{b,t,j}$，其中 $j$ 是维度 $m$ 的索引，$t$ 是维度 $k$ 的索引。\n- 乘法公式变为：$C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B'_{b,j,t}$。\n\n这个新操作的 `einsum` 字符串涉及的输入，其索引对应于 $\\mathbf{A}$ 的 `bnk` 和 $\\mathbf{B'}$ 的 `bmk`。求和是针对 `k` 进行的，输出索引是 `b`、`n`、`m`。这得出的字符串是 `'bnk,bmk->bnm'`。\n\n**3. 逐项选项分析**\n\n**A. 在将 $\\mathbf{B}$ 转置为形状 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bnm'})$，保持 $\\mathbf{A}$ 的形状为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。**\n- **正确性：** 如上所述，将 $\\mathbf{B}$ 转置为形状为 $(b,m,k)$ 的 $\\mathbf{B'}$，并使用 `einsum` 字符串 `'bnk,bmk->bnm'` 可以正确计算 $C_{b,i,j} = \\sum_{t} A_{b,i,t}B'_{b,j,t} = \\sum_{t} A_{b,i,t}B_{b,t,j}$。输出形状 $(b,n,m)$ 也是正确的。\n- **性能：**\n    - 输入 $\\mathbf{A}$ (形状 $(b,n,k)$): 遍历 `k` 的步长为 1。最优。\n    - 输入 $\\mathbf{B'}$ (形状 $(b,m,k)$): 遍历 `k` 的步长为 1。最优。\n    - 输出 $\\mathbf{C}$ (形状 $(b,n,m)$): 一个 `for b, for n, for m, ...` 的循环嵌套将计算输出。在递增 $m$ 时写入 $C_{b,n,m}$ 意味着以步长 1 访问内存。最优。\n- **结论：****正确**。此选项满足所有规定要求并实现了预期的优化。\n\n**B. 使用原始形状的 $\\mathbf{A}$ (即 $(b,n,k)$) 和 $\\mathbf{B}$ (即 $(b,k,m)$)，通过 $\\mathrm{einsum}(\\texttt{'bnk,bkm->bnm'})$ 计算，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。**\n- **正确性：** 对于原始张量形状，`einsum` 字符串在数学上是正确的。\n- **性能：** 这是前面分析的基线情况。对 $\\mathbf{B}$ 的访问模式涉及 $m=64$ 的大步长，效率极低。它不满足优化目标。\n- **结论：****不正确**。它未能执行优化。\n\n**C. 在将 $\\mathbf{A}$ 转置为 $(b,k,n)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bkn,bkm->bmn'})$，保持 $\\mathbf{B}$ 的形状为 $(b,k,m)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。**\n- **正确性：** 此选项计算 $C'_{b,j,i} = \\sum_t A'_{b,t,i} B_{b,t,j}$。由于 $A'_{b,t,i} = A_{b,i,t}$，这变为 $C'_{b,j,i} = \\sum_t A_{b,i,t} B_{b,t,j} = C_{b,i,j}$。该操作计算了所需矩阵的转置 $\\mathbf{C}^T$。这是一个有效的计算路径。\n- **性能：**\n    - 输入 $\\mathbf{A'}$ (形状 $(b,k,n)$): 步长为 $(k \\times n, n, 1)$。遍历归约维度 `k`（中间维度）的步长为 $n=64$。低效。\n    - 输入 $\\mathbf{B}$ (形状 $(b,k,m)$): 步长为 $(k \\times m, m, 1)$。遍历 `k` 的步长为 $m=64$。低效。\n- **结论：****不正确**。建议的重排导致两个输入的内存访问模式都很差。\n\n**D. 在将 $\\mathbf{B}$ 转置为 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bmn'})$，保持 $\\mathbf{A}$ 的形状为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。**\n- **正确性：** 此选项使用与选项 A 相同的优化输入。`einsum` 计算 $C'_{b,j,i} = \\sum_t A_{b,i,t}B'_{b,j,t} = C_{b,i,j}$。输出形状 $(b,m,n)$ 表明它生成了所需矩阵的转置 $\\mathbf{C}^T$。\n- **性能：**\n    - 对 $\\mathbf{A}$ 和 $\\mathbf{B'}$ 的输入访问是最优的（步长为 1），与选项 A 相同。\n    - 对于 `for m, for n, ...` 循环结构，对 $\\mathbf{C'}$（形状为 $(b,m,n)$）的输出访问也是最优的（步长为 1）。\n- **与 A 的比较：** A 和 D 在计算内核内都具有最优的内存访问模式。然而，问题将最终输出定义为 $\\mathbf{C} \\in \\mathbb{R}^{b \\times n \\times m}$。选项 A 直接生成此结果张量。选项 D 生成 $\\mathbf{C}^T$，这将需要一个额外的转置操作来获得指定的输出格式，从而产生额外成本。因此，选项 A 是更直接、更高效的端到端解决方案。\n- **结论：****不正确**。虽然核心计算得到了优化，但它没有以其指定的原始形状生成最终输出，使其成为与选项 A 相比的次优策略。\n\n### 结论\n\n选项 A 为优化的内存布局提供了正确的 `einsum` 字符串，该布局直接以其指定的形状 $(b,n,m)$ 生成输出张量 $\\mathbf{C}$。它为输入读取（在归约维度上步长为 1）和输出写入（在最内层生成的维度上步长为 1）都实现了最优的空间局部性。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "线性代数为我们提供了理解和分析高维空间的强大语言，这在深度学习中至关重要。这个练习将带你应用向量、梯度和范数的概念来探索模型输入的几何特性，这是一个被称为对抗性攻击的关键领域。你将学习如何计算一个“最小”的输入扰动 $\\delta$，以最大程度地改变模型的输出，并理解不同范数（如 $L_2$ 和 $L_\\infty$）如何定义了不同的“最短路径”。",
            "id": "3143535",
            "problem": "给定一个标量值可微函数 $f:\\mathbb{R}^n\\to\\mathbb{R}$ 和一个点 $x\\in\\mathbb{R}^n$。设在点 $x$ 处的梯度为 $g=\\nabla_x f(x)\\in\\mathbb{R}^n$。在 $x$ 点附近的一阶泰勒近似为 $f(x+\\delta)\\approx f(x)+g^\\top \\delta$，其中 $\\delta\\in\\mathbb{R}^n$ 是一个小的扰动。考虑构造对抗性扰动 $\\delta$，使其线性化输出改变一个指定的量 $g^\\top \\delta=\\alpha$，其中 $\\alpha\\in\\mathbb{R}$ 是给定的。您将比较在欧几里得范数 ($L_2$) 和最大范数 ($L_\\infty$) 下的最小范数解，并通过奇异值分解 (SVD) 来解释最陡峭变化的方向。\n\n推导的基本依据：\n- 范数定义：对于 $p\\in[1,\\infty]$，$L_p$ 范数为 $\\lVert v\\rVert_p=\\left(\\sum_{i=1}^n |v_i|^p\\right)^{1/p}$ (当 $p<\\infty$ 时)，以及 $\\lVert v\\rVert_\\infty=\\max_i |v_i|$。\n- 对偶范数定义：对于给定的范数 $\\lVert\\cdot\\rVert$，其对偶范数 $\\lVert\\cdot\\rVert_\\ast$ 定义为 $\\lVert w\\rVert_\\ast=\\sup\\{w^\\top v:\\lVert v\\rVert\\le 1\\}$。\n- 奇异值分解 (SVD)：对于矩阵 $J\\in\\mathbb{R}^{m\\times n}$，其 SVD 分解为 $J=U\\Sigma V^\\top$，其中 $U\\in\\mathbb{R}^{m\\times m}$ 和 $V\\in\\mathbb{R}^{n\\times n}$ 是正交矩阵，$\\Sigma\\in\\mathbb{R}^{m\\times n}$ 是对角矩阵，其对角线上的非负奇异值按非递增顺序排列。当 $m=1$ 且 $J=g^\\top\\in\\mathbb{R}^{1\\times n}$ 时，主右奇异向量等于归一化的梯度方向。\n\n任务：\n- 对下文定义的每个测试用例，假设模型为标量输出的线性化模型 $f(x+\\delta)\\approx f(x)+g^\\top\\delta$，其中给定 $g\\in\\mathbb{R}^n$ 和指定的目标变化量 $\\alpha\\in\\mathbb{R}$。\n- 构造一个扰动 $\\delta_2$，使其在所有满足 $g^\\top\\delta=\\alpha$ 的 $\\delta$ 中具有最小的 $L_2$ 范数；并构造一个扰动 $\\delta_\\infty$，使其在所有满足 $g^\\top\\delta=\\alpha$ 的 $\\delta$ 中具有最小的 $L_\\infty$ 范数。\n- 报告最小范数 $n_2=\\lVert\\delta_2\\rVert_2$ 和 $n_\\infty=\\lVert\\delta_\\infty\\rVert_\\infty$，以及它们的比值 $r=n_2/n_\\infty$。\n- 数值验证 $g^\\top\\delta_2$ 和 $g^\\top\\delta_\\infty$ 是否在容差 $\\varepsilon=10^{-9}$ 内等于 $\\alpha$，并报告布尔标志以指示每个等式是否在容差范围内成立。\n- 特殊情况必须按如下方式处理：\n  - 如果 $\\alpha=0$，则零扰动对于两种范数都是可行且最小的；定义比值 $r$ 为非数字 (not-a-number)。\n  - 如果 $\\lVert g\\rVert_2=0$ 且 $\\alpha\\ne 0$，则没有有限的扰动可以改变线性化输出；定义两个最小范数均为无穷大，比值为非数字，且两个验证标志均为假 (false)。\n\n测试套件：\n- 情况1：$g=(3,4)$, $\\alpha=1$。\n- 情况2：$g=(1,-1,1,-1)$, $\\alpha=2$。\n- 情况3：$g=(0,0,0)$, $\\alpha=1$。\n- 情况4：$g=(-2,0.5)$, $\\alpha=0$。\n- 情况5：$g=(0,-3,4,0,12)$, $\\alpha=5$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，该输出是一个结果列表，每个测试用例一个结果，顺序与上文相同。每个结果本身必须是一个包含五个条目的列表：三个浮点数 $[n_2,n_\\infty,r]$，后跟两个布尔值，分别指示对 $g^\\top\\delta_2$ 和 $g^\\top\\delta_\\infty$ 的验证结果，每个都与 $\\alpha$ 在容差 $\\varepsilon=10^{-9}$ 内进行比较。\n- 所有浮点数输出必须精确到六位小数；对无穷大和非数字值使用规范字符串表示 \"inf\" 和 \"nan\"。布尔值应显示为 True 或 False。\n- 因此，最终输出应看起来像一个列表的列表，例如 $[\\,[\\cdots],\\,[\\cdots],\\,\\ldots\\,]$，打印为单行，不带任何额外文本。",
            "solution": "该问题是有效的，因为它在科学上基于线性代数和优化，信息完备且对特殊情况有妥善处理，属于适定问题，并且陈述客观。我们接下来推导最小范数扰动的解。\n\n问题的核心是，对于给定的梯度向量 $g \\in \\mathbb{R}^n$ 和标量目标变化量 $\\alpha \\in \\mathbb{R}$，找到一个向量 $\\delta \\in \\mathbb{R}^n$，满足线性约束 $g^\\top \\delta = \\alpha$，同时最小化 $\\delta$ 的指定范数。我们将针对 $L_2$ 和 $L_\\infty$ 范数解决这个问题。\n\n首先，我们处理问题陈述中定义的特殊情况。\n1.  如果 $\\alpha = 0$，约束条件为 $g^\\top \\delta = 0$。扰动 $\\delta = 0$ 满足此约束。由于对于任何 $L_p$ 范数（$p \\ge 1$），零向量的范数均为 0，且范数是非负的，因此 $\\delta=0$ 是唯一的最小范数解。所以，$n_2 = \\lVert 0 \\rVert_2 = 0$ 且 $n_\\infty = \\lVert 0 \\rVert_\\infty = 0$。比值 $r = n_2 / n_\\infty = 0/0$ 是不确定的，定义为非数字 (NaN)。\n2.  如果 $g = 0$ (即 $\\lVert g \\rVert_2 = 0$) 且 $\\alpha \\ne 0$，约束条件变为 $0^\\top \\delta = 0 = \\alpha$，这是一个矛盾。不存在这样的扰动 $\\delta$。在这种情况下，满足约束所需的最小范数是无穷大。因此，$n_2 = \\infty$，$n_\\infty = \\infty$，并且比值 $r$ 定义为 NaN。验证会失败，因为约束永远无法满足。\n\n现在，我们考虑 $g \\ne 0$ 且 $\\alpha \\ne 0$ 的一般情况。\n\n**最小 $L_2$ 范数扰动 ($\\delta_2$)**\n\n该优化问题是在约束 $g^\\top \\delta = \\alpha$ 下最小化 $\\lVert \\delta \\rVert_2$。最小化 $\\lVert \\delta \\rVert_2$ 等价于最小化 $\\frac{1}{2}\\lVert \\delta \\rVert_2^2 = \\frac{1}{2}\\delta^\\top \\delta$。我们使用拉格朗日乘子法。拉格朗日函数为：\n$$ \\mathcal{L}(\\delta, \\lambda) = \\frac{1}{2}\\delta^\\top\\delta - \\lambda(g^\\top\\delta - \\alpha) $$\n为求最小值，我们将 $\\mathcal{L}$ 关于 $\\delta$ 的梯度设为零：\n$$ \\nabla_\\delta \\mathcal{L} = \\delta - \\lambda g = 0 \\implies \\delta = \\lambda g $$\n这表明最优扰动 $\\delta_2$ 必须与梯度向量 $g$ 共线。这个方向是线性化函数 $f(x) + g^\\top\\delta$ 的最速上升方向。正如问题的推导依据中所述，对于雅可比矩阵 $J=g^\\top \\in \\mathbb{R}^{1\\times n}$，其唯一的奇异值为 $\\sigma_1 = \\lVert g \\rVert_2$，对应的右奇异向量为 $v_1 = g / \\lVert g \\rVert_2$。因此，最优扰动方向与系统雅可比矩阵的主右奇异向量对齐。\n\n为了找到标量乘子 $\\lambda$，我们将 $\\delta = \\lambda g$ 代入约束条件：\n$$ g^\\top (\\lambda g) = \\alpha \\implies \\lambda (g^\\top g) = \\alpha \\implies \\lambda \\lVert g \\rVert_2^2 = \\alpha $$\n求解 $\\lambda$ (因为 $g \\ne 0$，所以 $\\lVert g \\rVert_2^2 > 0$)：\n$$ \\lambda = \\frac{\\alpha}{\\lVert g \\rVert_2^2} $$\n因此，最小 $L_2$ 范数扰动为：\n$$ \\delta_2 = \\frac{\\alpha}{\\lVert g \\rVert_2^2} g $$\n这个最小范数的大小 $n_2$ 是：\n$$ n_2 = \\lVert \\delta_2 \\rVert_2 = \\left\\lVert \\frac{\\alpha}{\\lVert g \\rVert_2^2} g \\right\\rVert_2 = \\left| \\frac{\\alpha}{\\lVert g \\rVert_2^2} \\right| \\lVert g \\rVert_2 = \\frac{|\\alpha|}{\\lVert g \\rVert_2} $$\n\n**最小 $L_\\infty$ 范数扰动 ($\\delta_\\infty$)**\n\n该优化问题是在约束 $g^\\top \\delta = \\alpha$ 下最小化 $\\lVert \\delta \\rVert_\\infty$。我们可以使用赫尔德不等式来确立 $\\lVert \\delta \\rVert_\\infty$ 的一个下界。赫尔德不等式指出，对于对偶范数（其中 $1/p + 1/q = 1$），有 $|w^\\top v| \\le \\lVert w \\rVert_p \\lVert v \\rVert_q$。$L_\\infty$ 范数的对偶范数是 $L_1$ 范数。将此应用于我们的约束：\n$$ |\\alpha| = |g^\\top \\delta| \\le \\lVert g \\rVert_1 \\lVert \\delta \\rVert_\\infty $$\n由于 $g \\ne 0$，所以 $\\lVert g \\rVert_1 > 0$。我们可以重新排列以找到 $\\lVert \\delta \\rVert_\\infty$ 的一个下界：\n$$ \\lVert \\delta \\rVert_\\infty \\ge \\frac{|\\alpha|}{\\lVert g \\rVert_1} $$\n这个下界是可以达到的。对于 $(1, \\infty)$ 范数对，赫尔德不等式中的等号成立条件是扰动 $\\delta$ 被恰当地选择。具体来说，我们可以构造一个达到此下界的扰动 $\\delta_\\infty$。我们定义 $\\delta_\\infty$ 为：\n$$ \\delta_\\infty = c \\cdot \\mathrm{sgn}(g) $$\n其中 $\\mathrm{sgn}(g)$ 是一个向量，其分量是 $g$ 的各分量的符号（如果 $z>0$，$\\mathrm{sgn}(z)=1$；如果 $z<0$，$\\mathrm{sgn}(z)=-1$；如果 $z=0$，$\\mathrm{sgn}(z)=0$）。将此代入约束条件：\n$$ g^\\top (c \\cdot \\mathrm{sgn}(g)) = \\alpha \\implies c \\sum_{i=1}^n g_i \\mathrm{sgn}(g_i) = \\alpha $$\n由于 $g_i \\mathrm{sgn}(g_i) = |g_i|$，上式可简化为：\n$$ c \\sum_{i=1}^n |g_i| = \\alpha \\implies c \\lVert g \\rVert_1 = \\alpha \\implies c = \\frac{\\alpha}{\\lVert g \\rVert_1} $$\n所以，最小 $L_\\infty$ 范数扰动为：\n$$ \\delta_\\infty = \\frac{\\alpha}{\\lVert g \\rVert_1} \\mathrm{sgn}(g) $$\n这个最小范数的大小 $n_\\infty$ 是：\n$$ n_\\infty = \\lVert \\delta_\\infty \\rVert_\\infty = \\left\\lVert \\frac{\\alpha}{\\lVert g \\rVert_1} \\mathrm{sgn}(g) \\right\\rVert_\\infty = \\left| \\frac{\\alpha}{\\lVert g \\rVert_1} \\right| \\lVert \\mathrm{sgn}(g) \\rVert_\\infty $$\n对于任何 $g \\ne 0$，$\\mathrm{sgn}(g)$ 至少有一个分量是 $\\pm 1$，因此 $\\lVert \\mathrm{sgn}(g) \\rVert_\\infty = 1$。所以，最小范数为：\n$$ n_\\infty = \\frac{|\\alpha|}{\\lVert g \\rVert_1} $$\n\n**范数之比**\n\n最小范数的比值 $r$ 是：\n$$ r = \\frac{n_2}{n_\\infty} = \\frac{|\\alpha| / \\lVert g \\rVert_2}{|\\alpha| / \\lVert g \\rVert_1} = \\frac{\\lVert g \\rVert_1}{\\lVert g \\rVert_2} $$\n这个比值仅取决于梯度向量 $g$ 的性质。\n\n**实现摘要**\n对于每个测试用例 $(g, \\alpha)$：\n1. 如果 $\\alpha = 0$，设置 $n_2=0, n_\\infty=0, r=\\text{NaN}$。扰动为 $\\delta_2 = \\delta_\\infty = 0$。\n2. 如果 $\\alpha \\ne 0$，计算 $\\lVert g \\rVert_2$。如果 $\\lVert g \\rVert_2 = 0$，设置 $n_2=\\infty, n_\\infty=\\infty, r=\\text{NaN}$，并将验证标志设为 False。\n3. 如果 $\\alpha \\ne 0$ 且 $\\lVert g \\rVert_2 \\ne 0$，计算 $\\lVert g \\rVert_1$。计算 $n_2 = |\\alpha|/\\lVert g \\rVert_2$, $n_\\infty = |\\alpha|/\\lVert g \\rVert_1$, 以及 $r = \\lVert g \\rVert_1/\\lVert g \\rVert_2$。使用推导出的公式构造 $\\delta_2$ 和 $\\delta_\\infty$ 以进行验证检查。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes minimal L2 and L_inf norm perturbations for a set of test cases.\n    \"\"\"\n    test_cases = [\n        (np.array([3.0, 4.0]), 1.0),\n        (np.array([1.0, -1.0, 1.0, -1.0]), 2.0),\n        (np.array([0.0, 0.0, 0.0]), 1.0),\n        (np.array([-2.0, 0.5]), 0.0),\n        (np.array([0.0, -3.0, 4.0, 0.0, 12.0]), 5.0),\n    ]\n\n    results = []\n    epsilon = 1e-9\n\n    for g, alpha in test_cases:\n        norm_g_2 = np.linalg.norm(g, 2)\n        \n        # Handle special case: alpha = 0\n        if np.isclose(alpha, 0.0):\n            n2 = 0.0\n            n_inf = 0.0\n            r = np.nan\n            delta2 = np.zeros_like(g, dtype=float)\n            delta_inf = np.zeros_like(g, dtype=float)\n            verif2 = np.isclose(np.dot(g, delta2), alpha, atol=epsilon)\n            verif_inf = np.isclose(np.dot(g, delta_inf), alpha, atol=epsilon)\n\n        # Handle special case: g = 0 and alpha != 0\n        elif np.isclose(norm_g_2, 0.0):\n            n2 = np.inf\n            n_inf = np.inf\n            r = np.nan\n            verif2 = False\n            verif_inf = False\n        \n        # General case: g != 0 and alpha != 0\n        else:\n            norm_g_1 = np.linalg.norm(g, 1)\n            \n            n2 = abs(alpha) / norm_g_2\n            n_inf = abs(alpha) / norm_g_1\n            r = norm_g_1 / norm_g_2\n\n            # Perturbation for L2 minimization\n            delta2 = (alpha / (norm_g_2**2)) * g\n            # Perturbation for L_inf minimization\n            delta_inf = (alpha / norm_g_1) * np.sign(g)\n\n            # Verification\n            verif2 = np.isclose(np.dot(g, delta2), alpha, atol=epsilon)\n            verif_inf = np.isclose(np.dot(g, delta_inf), alpha, atol=epsilon)\n\n        results.append([n2, n_inf, r, bool(verif2), bool(verif_inf)])\n\n    def format_float(val):\n        \"\"\"Formats a float to 6 decimal places, handling inf and nan.\"\"\"\n        if np.isinf(val):\n            return \"inf\"\n        if np.isnan(val):\n            return \"nan\"\n        return f\"{val:.6f}\"\n\n    output_str_parts = []\n    for res in results:\n        n2_str = format_float(res[0])\n        n_inf_str = format_float(res[1])\n        r_str = format_float(res[2])\n        v2_str = str(res[3])\n        v_inf_str = str(res[4])\n        output_str_parts.append(f\"[{n2_str},{n_inf_str},{r_str},{v2_str},{v_inf_str}]\")\n    \n    final_output_str = f\"[{','.join(output_str_parts)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}