{
    "hands_on_practices": [
        {
            "introduction": "我们从一个训练循环神经网络（RNN）时的基本问题开始：应该在何处施加损失函数？这个练习将比较两种常见的监督模式——“多对多”（many-to-many）和“多对一”（many-to-one）——在一个简单的序列任务上的表现。通过实现一个学习累加和的简单 RNN，你将直接观察到，与仅在序列末尾提供指导信号相比，在每一步都提供信号如何影响学习速度和效果。这项实践 () 对于建立循环模型训练动态的直觉，以及理解损失函数设计中的权衡至关重要，它具体地展示了稀疏监督（如仅在最终步骤监督）可能带来的梯度消失等挑战。",
            "id": "3171353",
            "problem": "要求您设计并分析一个最小的循环神经网络（RNN）学习场景，以比较两种监督模式：带每步损失的多对多模式与带最终损失的多对一模式。该任务必须纯粹用数学方式进行描述，并实现为一个完整的、可运行的程序。程序必须按末尾指定的那样，产生单行输出。\n\n考虑一个标量RNN，其隐藏状态更新和输出定义如下\n$$\nh_t = \\alpha h_{t-1} + \\beta x_t,\\quad h_0 = 0,\\quad o_t = w h_t,\n$$\n其中 $x_t \\in \\mathbb{R}$ 是时间步 $t$ 的输入，$h_t \\in \\mathbb{R}$ 是隐藏状态，$o_t \\in \\mathbb{R}$ 是输出。令监督目标为累积和\n$$\ny_t = \\sum_{i=1}^t x_i,\n$$\n以及最终结果 $y = y_T = \\sum_{i=1}^T x_i$。学习的目标是恢复这个累积和映射。您必须比较以下两种学习机制：\n- 带每步损失的多对多：定义所有时间步上的均方误差，\n$$\n\\mathcal{L}_{\\text{per}} = \\frac{1}{NT}\\sum_{n=1}^N \\sum_{t=1}^T \\big(o_t^{(n)} - y_t^{(n)}\\big)^2,\n$$\n- 带最终损失的多对一：\n$$\n\\mathcal{L}_{\\text{final}} = \\frac{1}{N}\\sum_{n=1}^N \\big(o_T^{(n)} - y_T^{(n)}\\big)^2,\n$$\n其中 $N$ 是序列数量，$T$ 是序列长度，上标 $(n)$ 用于索引数据集中的序列。\n\n使用全批量梯度下降和随时间反向传播（BPTT）来优化参数 $\\alpha$、$\\beta$ 和 $w$。每次训练开始时，均使用相同的初始参数值 $\\alpha = 0.5$、$\\beta = 0.5$、 $w = 0.5$。\n\n数据集生成：对于给定的 $(N,T)$，从标准正态分布中独立抽取 $x_t^{(n)}$，并在两种机制的比较中保持数据集固定。将 $y_t^{(n)}$ 精确计算为累积和。\n\n收敛性度量：对于每种训练机制和参数集，记录相应的训练损失 $\\mathcal{L}$ 首次严格低于给定阈值 $\\varepsilon$ 的轮数 $e$。如果到最大轮数时仍未达到阈值，则返回最大轮数作为报告的轮数计数。\n\n测试套件：在以下参数集上运行程序。为确保可复现性，每个案例必须使用其自己的随机种子，并且在同一案例中，两种机制必须使用相同的数据集。\n\n- 案例 $1$ (快乐路径): $N=32$, $T=20$, 学习率 $\\eta = 0.05$, 最大轮数 $E_{\\max} = 1000$, 阈值 $\\varepsilon = 0.005$, 随机种子 $s=42$。\n- 案例 $2$ (边界条件): $N=32$, $T=1$, 学习率 $\\eta = 0.10$, 最大轮数 $E_{\\max} = 300$, 阈值 $\\varepsilon = 0.0001$, 随机种子 $s=43$。\n- 案例 $3$ (长序列边缘案例): $N=32$, $T=50$, 学习率 $\\eta = 0.03$, 最大轮数 $E_{\\max} = 1500$, 阈值 $\\varepsilon = 0.01$, 随机种子 $s=44$。\n\n最终输出格式：您的程序应生成单行输出，包含一个逗号分隔的各案例结果列表，其中每个案例结果是 $[e_{\\text{per}},e_{\\text{final}}]$ 形式的数对，方括号内没有空格。例如，最终打印的行必须如下所示\n$$\n[\\,[e_{\\text{per}}^{(1)},e_{\\text{final}}^{(1)}],[e_{\\text{per}}^{(2)},e_{\\text{final}}^{(2)}],[e_{\\text{per}}^{(3)},e_{\\text{final}}^{(3)}]\\,]\n$$\n其中的整数由您的程序计算得出。程序不得打印任何其他文本。",
            "solution": "问题陈述已经过验证，被认为是合理的。它具有科学依据，问题定义良好且客观。所有参数、方程和条件都已明确给出，构成了一个完整的问题定义。该任务是计算神经科学和机器学习中的一个标准练习，适合进行严格的数学分析和实现。\n\n该问题要求对一个简单循环神经网络（RNN）的两种监督模式进行比较分析。解决方案的核心在于为两种指定的损失函数推导并实现学习算法，即全批量梯度下降与随时间反向传播（BPTT）。\n\nRNN模型由以下方程定义，适用于每个序列 $n$ 在时间步 $t$：\n$$\nh_t^{(n)} = \\alpha h_{t-1}^{(n)} + \\beta x_t^{(n)}\n$$\n$$\no_t^{(n)} = w h_t^{(n)}\n$$\n隐藏状态初始化为零，$h_0^{(n)} = 0$。要学习的参数是 $\\alpha$、$\\beta$ 和 $w$。任务是使网络输出 $o_t^{(n)}$ 逼近输入序列的累积和 $y_t^{(n)} = \\sum_{i=1}^t x_i^{(n)}$。\n\n目标是通过最小化损失函数 $\\mathcal{L}(\\theta)$ 来找到最优参数 $\\theta = (\\alpha, \\beta, w)$。我们使用梯度下降法，其中参数根据以下规则进行迭代更新：\n$$\n\\theta \\leftarrow \\theta - \\eta \\nabla_{\\theta} \\mathcal{L}\n$$\n其中 $\\eta$ 是学习率。梯度 $\\nabla_{\\theta} \\mathcal{L}$ 使用BPTT计算。我们分析两种不同的损失函数。为使以下推导清晰，我们先考虑单个数据序列的梯度，然后说明如何对 $N$ 个序列的批次进行平均。\n\n**机制1：带每步损失的多对多（$\\mathcal{L}_{\\text{per}}$）**\n\n损失函数是所有时间步和所有序列上均方误差的平均值：\n$$\n\\mathcal{L}_{\\text{per}} = \\frac{1}{NT}\\sum_{n=1}^N \\sum_{t=1}^T \\big(o_t^{(n)} - y_t^{(n)}\\big)^2\n$$\n为计算梯度，我们使用链式法则。\n关于 $w$ 的梯度是直接的，因为 $w$ 只在每个时间步局部影响输出 $o_t$：\n$$\n\\frac{\\partial \\mathcal{L}_{\\text{per}}}{\\partial w} = \\frac{1}{NT}\\sum_{n=1}^N \\sum_{t=1}^T \\frac{\\partial}{\\partial w} (o_t^{(n)} - y_t^{(n)})^2 = \\frac{1}{NT}\\sum_{n=1}^N \\sum_{t=1}^T 2(o_t^{(n)} - y_t^{(n)}) h_t^{(n)}\n$$\n参数 $\\alpha$ 和 $\\beta$ 在所有时间点都影响隐藏状态 $h_t$，而 $h_t$ 又会影响所有后续的输出。BPTT提供了一种系统计算这些梯度的方法。我们定义一个误差信号 $\\delta_t = \\frac{\\partial \\mathcal{L}_{\\text{total}}}{\\partial h_t}$，其中 $\\mathcal{L}_{\\text{total}} = \\sum_{n,t} (o_t-y_t)^2$。该信号沿时间反向传播。对于单个序列，总损失为 $L^{(n)} = \\sum_{t=1}^T (o_t^{(n)}-y_t^{(n)})^2$。$L^{(n)}$ 关于 $h_t^{(n)}$ 的梯度是：\n$$\n\\frac{\\partial L^{(n)}}{\\partial h_t^{(n)}} = \\frac{\\partial L^{(n)}}{\\partial o_t^{(n)}}\\frac{\\partial o_t^{(n)}}{\\partial h_t^{(n)}} + \\frac{\\partial L^{(n)}}{\\partial h_{t+1}^{(n)}}\\frac{\\partial h_{t+1}^{(n)}}{\\partial h_t^{(n)}}\n$$\n令 $\\delta_t^{(n)} = \\frac{\\partial L^{(n)}}{\\partial h_t^{(n)}}$。这个误差信号的递推关系是：\n$$\n\\delta_t^{(n)} = 2(o_t^{(n)} - y_t^{(n)})w + \\delta_{t+1}^{(n)}\\alpha\n$$\n这是从 $t=T$ 反向计算到 $t=1$，基准情况为 $\\delta_{T+1}^{(n)} = 0$，因此 $\\delta_T^{(n)} = 2(o_T^{(n)} - y_T^{(n)})w$。第一项代表在当前时间步注入的误差，第二项代表从未来传播回来的误差。\n一旦所有的 $\\delta_t^{(n)}$ 都计算出来，$\\alpha$ 和 $\\beta$ 的梯度可以通过对每个时间步的局部贡献求和得到：\n$$\n\\frac{\\partial L^{(n)}}{\\partial \\alpha} = \\sum_{t=1}^T \\frac{\\partial L^{(n)}}{\\partial h_t^{(n)}}\\frac{\\partial h_t^{(n)}}{\\partial \\alpha} = \\sum_{t=1}^T \\delta_t^{(n)} h_{t-1}^{(n)}\n$$\n$$\n\\frac{\\partial L^{(n)}}{\\partial \\beta} = \\sum_{t=1}^T \\frac{\\partial L^{(n)}}{\\partial h_t^{(n)}}\\frac{\\partial h_t^{(n)}}{\\partial \\beta} = \\sum_{t=1}^T \\delta_t^{(n)} x_t^{(n)}\n$$\n整个批次的最终梯度是通过对所有 $N$ 个样本的这些总和进行平均，并除以 $NT$ 来归一化得到的：\n$\\nabla_{\\theta} \\mathcal{L}_{\\text{per}} = \\frac{1}{NT} \\sum_{n=1}^N \\nabla_{\\theta} L^{(n)}$。\n\n**机制2：带最终损失的多对一（$\\mathcal{L}_{\\text{final}}$）**\n\n损失函数是在最终时间步 $T$ 的均方误差：\n$$\n\\mathcal{L}_{\\text{final}} = \\frac{1}{N}\\sum_{n=1}^N \\big(o_T^{(n)} - y_T^{(n)}\\big)^2\n$$\n梯度计算遵循类似的BPTT过程，但误差信号仅源于 $t=T$。对于单个序列，$L^{(n)} = (o_T^{(n)}-y_T^{(n)})^2$。\n\n关于 $w$ 的梯度仅取决于最终状态和输出：\n$$\n\\frac{\\partial L^{(n)}}{\\partial w} = 2(o_T^{(n)} - y_T^{(n)}) h_T^{(n)}\n$$\n误差信号 $\\delta_t^{(n)} = \\frac{\\partial L^{(n)}}{\\partial h_t^{(n)}}$ 具有不同的结构。由于损失仅取决于 $h_T$，对于任何 $t  T$，误差必须从 $h_{t+1}$ 传播回来：\n$$\n\\delta_t^{(n)} = \\frac{\\partial L^{(n)}}{\\partial h_{t+1}^{(n)}}\\frac{\\partial h_{t+1}^{(n)}}{\\partial h_t^{(n)}} = \\delta_{t+1}^{(n)}\\alpha\n$$\n对于任何 $t  T$，没有局部误差注入。在 $t=T$ 时的基准情况是：\n$$\n\\delta_T^{(n)} = \\frac{\\partial L^{(n)}}{\\partial o_T^{(n)}}\\frac{\\partial o_T^{(n)}}{\\partial h_T^{(n)}} = 2(o_T^{(n)} - y_T^{(n)})w\n$$\n然后像之前一样计算 $\\alpha$ 和 $\\beta$ 的梯度：\n$$\n\\frac{\\partial L^{(n)}}{\\partial \\alpha} = \\sum_{t=1}^T \\delta_t^{(n)} h_{t-1}^{(n)}\n$$\n$$\n\\frac{\\partial L^{(n)}}{\\partial \\beta} = \\sum_{t=1}^T \\delta_t^{(n)} x_t^{(n)}\n$$\n关键区别在于，对于 $t  T$，信号 $\\delta_t^{(n)}$ 是 $\\delta_T^{(n)}$ 的一个衰减版本（即 $\\delta_t^{(n)} = \\delta_T^{(n)}\\alpha^{T-t}$）。如果 $|\\alpha|1$，这可能导致早期时间步的梯度消失，使得学习长期依赖变得困难。\n批次的最终梯度被平均：$\\nabla_{\\theta} \\mathcal{L}_{\\text{final}} = \\frac{1}{N} \\sum_{n=1}^N \\nabla_{\\theta} L^{(n)}$。\n\n实现过程首先是为给定的测试案例生成固定的数据集 $(X, Y)$。然后，对两种机制中的每一种，执行一个训练循环。在每个轮次中，模型执行一次前向传播来计算输出和当前损失。如果损失低于阈值 $\\varepsilon$，则记录轮数。否则，通过BPTT如上所述计算梯度，并更新参数 $(\\alpha, \\beta, w)$。如果在 $E_{\\max}$ 轮内损失没有降到阈值以下，则记录 $E_{\\max}$。对所有测试案例重复此过程。当 $T=1$ 的特殊情况可作为健全性检查，因为此时两种损失函数变得相同，因此它们的训练动态必须完全一致。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef train(X, Y, N, T, eta, E_max, eps, regime, initial_params):\n    \"\"\"\n    Trains the RNN for a given regime and returns the convergence epoch.\n    \"\"\"\n    alpha, beta, w = initial_params\n    \n    for epoch in range(1, E_max + 1):\n        # Forward pass\n        h = np.zeros((N, T))\n        o = np.zeros((N, T))\n        h_prev = np.zeros(N)\n        for t in range(T):\n            h_t = alpha * h_prev + beta * X[:, t]\n            h[:, t] = h_t\n            o[:, t] = w * h_t\n            h_prev = h_t\n\n        # Calculate loss based on the regime\n        if regime == 'per_step':\n            loss = np.mean((o - Y)**2)\n        elif regime == 'final_only':\n            loss = np.mean((o[:, -1] - Y[:, -1])**2)\n        else:\n            # This path should not be reached with valid inputs\n            raise ValueError(\"Invalid regime specified.\")\n\n        # Check for convergence\n        if loss  eps:\n            return epoch\n\n        # Backward pass (BPTT) and gradient calculation\n        h_padded = np.concatenate((np.zeros((N, 1)), h[:, :-1]), axis=1)\n\n        if regime == 'per_step':\n            do = 2 * (o - Y) / (N * T)\n            grad_w = np.sum(do * h)\n            \n            delta_h = np.zeros((N, T))\n            delta_h_next = np.zeros(N)\n            for t in range(T - 1, -1, -1):\n                current_delta_h = do[:, t] * w + delta_h_next * alpha\n                delta_h[:, t] = current_delta_h\n                delta_h_next = current_delta_h\n            \n            grad_alpha = np.sum(delta_h * h_padded)\n            grad_beta = np.sum(delta_h * X)\n            \n        elif regime == 'final_only':\n            errors_final = o[:, -1] - Y[:, -1]\n            do_T = 2 * errors_final / N\n            \n            grad_w = np.sum(do_T * h[:, -1])\n            \n            delta_h = np.zeros((N, T))\n            if T > 0:\n                delta_h[:, -1] = do_T * w\n                for t in range(T - 2, -1, -1):\n                    delta_h[:, t] = delta_h[:, t + 1] * alpha\n            \n            grad_alpha = np.sum(delta_h * h_padded)\n            grad_beta = np.sum(delta_h * X)\n\n        # Update parameters using full-batch gradient descent\n        alpha -= eta * grad_alpha\n        beta -= eta * grad_beta\n        w -= eta * grad_w\n        \n    # Return max epochs if convergence threshold is not met\n    return E_max\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # (N, T, learning_rate, max_epochs, threshold, random_seed)\n        (32, 20, 0.05, 1000, 0.005, 42),\n        (32, 1, 0.10, 300, 0.0001, 43),\n        (32, 50, 0.03, 1500, 0.01, 44),\n    ]\n\n    all_results = []\n    initial_params = (0.5, 0.5, 0.5)\n\n    for case in test_cases:\n        N, T, eta, E_max, eps, seed = case\n        \n        # Generate a fixed dataset for the case\n        np.random.seed(seed)\n        X = np.random.randn(N, T)\n        Y = np.cumsum(X, axis=1)\n\n        # Run training for the per-step loss regime\n        e_per = train(X, Y, N, T, eta, E_max, eps, 'per_step', initial_params)\n        \n        # Run training for the final-only loss regime\n        e_final = train(X, Y, N, T, eta, E_max, eps, 'final_only', initial_params)\n        \n        all_results.append(f\"[{e_per},{e_final}]\")\n\n    # Print the final output in the exact specified format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界中的序列数据，其标签或关键事件往往出现在不规则的时间点。本次练习将挑战你构建一个“多对稀疏多”（many-to-sparse-many）的 RNN 模型，以处理这类事件驱动的数据。你将为一个仅在特定、稀疏时间步上计算的损失函数实现时间反向传播算法（BPTT）。这个过程将强化一个核心概念：即使在没有损失的“静默”时期，梯度也必须在整个序列中反向流动，以便正确地更新网络参数，因为这些时期的状态会影响未来的预测。通过解决这个问题 ()，你将从简单的 RNN 模式进阶到一个更灵活、更实用的架构，并更深刻地掌握在循环网络中，信用是如何在时间维度上被分配的。",
            "id": "3171336",
            "problem": "要求您设计并实现一个事件驱动的多对稀疏多循环神经网络 (RNN)，该网络接收连续的输入流，并且仅在不规则间隔的事件时间产生输出。您的任务是使用时间反向传播 (BPTT) 从第一性原理推导出算法，实现它，并在一个小型测试套件上进行评估。\n\n基本基础和模型定义。从循环神经网络 (RNN) 的标准定义开始。设离散时间的输入为 $\\mathbf{x}_t \\in \\mathbb{R}^D$，隐藏状态为 $\\mathbf{h}_t \\in \\mathbb{R}^H$，输出为 $\\hat{\\mathbf{y}}_t \\in \\mathbb{R}^O$。前向循环由以下公式定义：\n$$\n\\mathbf{h}_t = \\tanh(\\mathbf{W}_{xh}\\mathbf{x}_t + \\mathbf{W}_{hh}\\mathbf{h}_{t-1} + \\mathbf{b}_h), \\quad \\hat{\\mathbf{y}}_t = \\mathbf{W}_{hy}\\mathbf{h}_t + \\mathbf{b}_y,\n$$\n初始状态为 $\\mathbf{h}_{-1} = \\mathbf{0}$。输出仅在一个指定的事件索引集 $\\mathcal{E} \\subset \\{0,1,\\ldots,T-1\\}$ 上进行评估。定义一个事件掩码 $m_t \\in \\{0,1\\}$，其中如果 $t \\in \\mathcal{E}$，则 $m_t = 1$，否则 $m_t = 0$。损失仅在事件时间上定义为平方误差之和：\n$$\n\\mathcal{L} = \\frac{1}{2} \\sum_{t=0}^{T-1} m_t \\left\\lVert \\hat{\\mathbf{y}}_t - \\mathbf{y}_t \\right\\rVert_2^2,\n$$\n其中 $\\mathbf{y}_t$ 是仅在 $m_t = 1$ 时定义的目标。您的实现必须通过时间反向传播计算梯度，并且至关重要的是，将梯度传播过 $m_t = 0$ 的“静默”区间，因为那些隐藏状态会影响未来的事件输出。\n\n架构和维度规范。对所有测试用例使用以下固定维度：$D = 2$，$H = 3$，$O = 1$。对每个测试用例，将参数统一初始化为：\n$$\n\\mathbf{W}_{xh} = \\begin{bmatrix} 0.2  -0.1 \\\\ 0.0  0.1 \\\\ -0.1  0.2 \\end{bmatrix}, \\quad\n\\mathbf{W}_{hh} = \\begin{bmatrix} 0.1  0.0  -0.1 \\\\ 0.05  0.1  0.0 \\\\ 0.0  -0.05  0.1 \\end{bmatrix}, \\quad\n\\mathbf{b}_h = \\begin{bmatrix} 0.0 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix},\n$$\n$$\n\\mathbf{W}_{hy} = \\begin{bmatrix} 0.3  -0.2  0.1 \\end{bmatrix}, \\quad \\mathbf{b}_y = \\begin{bmatrix} 0.0 \\end{bmatrix}.\n$$\n使用学习率 $\\alpha = 0.1$ 的单步梯度下降更新。\n\n测试套件。对于下面的每个测试用例，您必须计算梯度步之前和一步梯度步之后的总损失。始终使用零向量作为初始隐藏状态。在每种情况下，输入都是一个序列 $\\{\\mathbf{x}_t\\}_{t=0}^{T-1}$，事件索引集是 $\\mathcal{E}$，目标是为 $t \\in \\mathcal{E}$ 定义的。\n\n- 用例 $\\mathrm{A}$：$T=5$，输入\n$\\mathbf{x}_0 = \\begin{bmatrix} 0.5 \\\\ -0.2 \\end{bmatrix}$，\n$\\mathbf{x}_1 = \\begin{bmatrix} -0.3 \\\\ 0.1 \\end{bmatrix}$，\n$\\mathbf{x}_2 = \\begin{bmatrix} 0.0 \\\\ 0.2 \\end{bmatrix}$，\n$\\mathbf{x}_3 = \\begin{bmatrix} -0.1 \\\\ -0.1 \\end{bmatrix}$，\n$\\mathbf{x}_4 = \\begin{bmatrix} 0.2 \\\\ 0.0 \\end{bmatrix}$；\n事件集 $\\mathcal{E} = \\{1,4\\}$；目标 $y_1 = 0.1$，$y_4 = -0.05$。\n\n- 用例 $\\mathrm{B}$：$T=6$，输入\n$\\mathbf{x}_0 = \\begin{bmatrix} 0.1 \\\\ 0.0 \\end{bmatrix}$，\n$\\mathbf{x}_1 = \\begin{bmatrix} 0.0 \\\\ 0.1 \\end{bmatrix}$，\n$\\mathbf{x}_2 = \\begin{bmatrix} -0.2 \\\\ 0.2 \\end{bmatrix}$，\n$\\mathbf{x}_3 = \\begin{bmatrix} 0.3 \\\\ -0.3 \\end{bmatrix}$，\n$\\mathbf{x}_4 = \\begin{bmatrix} 0.0 \\\\ 0.2 \\end{bmatrix}$，\n$\\mathbf{x}_5 = \\begin{bmatrix} -0.1 \\\\ 0.0 \\end{bmatrix}$；\n事件集 $\\mathcal{E} = \\{5\\}$；目标 $y_5 = 0.2$。\n\n- 用例 $\\mathrm{C}$：$T=4$，输入\n$\\mathbf{x}_0 = \\begin{bmatrix} 0.2 \\\\ 0.2 \\end{bmatrix}$，\n$\\mathbf{x}_1 = \\begin{bmatrix} -0.2 \\\\ 0.1 \\end{bmatrix}$，\n$\\mathbf{x}_2 = \\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix}$，\n$\\mathbf{x}_3 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$；\n事件集 $\\mathcal{E} = \\emptyset$；无目标。\n\n- 用例 $\\mathrm{D}$：$T=7$，输入\n$\\mathbf{x}_0 = \\begin{bmatrix} 0.0 \\\\ 0.1 \\end{bmatrix}$，\n$\\mathbf{x}_1 = \\begin{bmatrix} 0.1 \\\\ 0.0 \\end{bmatrix}$，\n$\\mathbf{x}_2 = \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix}$，\n$\\mathbf{x}_3 = \\begin{bmatrix} -0.2 \\\\ 0.2 \\end{bmatrix}$，\n$\\mathbf{x}_4 = \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix}$，\n$\\mathbf{x}_5 = \\begin{bmatrix} -0.1 \\\\ 0.1 \\end{bmatrix}$，\n$\\mathbf{x}_6 = \\begin{bmatrix} 0.0 \\\\ -0.1 \\end{bmatrix}$；\n事件集 $\\mathcal{E} = \\{2,3\\}$；目标 $y_2 = -0.1$，$y_3 = 0.05$。\n\n处理和要求输出。对于每个用例，执行一次完整的前向传播以计算 $\\mathcal{L}_{\\text{before}}$，通过遵循事件掩码 $m_t$ 的时间反向传播计算精确梯度，使用学习率 $\\alpha$ 进行一次参数更新，并计算新的损失 $\\mathcal{L}_{\\text{after}}$。您的程序应生成单行输出，其中包含结果，形式为一个扁平的、逗号分隔的浮点数列表，四舍五入到 $6$ 位小数，并用方括号括起来，顺序如下：\n$$\n[\\mathcal{L}_{\\text{before}}^{(A)}, \\mathcal{L}_{\\text{after}}^{(A)}, \\mathcal{L}_{\\text{before}}^{(B)}, \\mathcal{L}_{\\text{after}}^{(B)}, \\mathcal{L}_{\\text{before}}^{(C)}, \\mathcal{L}_{\\text{after}}^{(C)}, \\mathcal{L}_{\\text{before}}^{(D)}, \\mathcal{L}_{\\text{after}}^{(D)}].\n$$\n不应打印任何其他文本。不涉及物理单位。不会出现角度。所有数值答案必须是浮点数。",
            "solution": "用户提供的问题要求设计并实现一个事件驱动的多对稀疏多循环神经网络 (RNN)。任务的核心是为这种特定架构推导并实现时间反向传播 (BPTT) 算法，其中损失仅在离散、不规则的事件时间计算。解决方案将首先详细说明状态和输出的前向传播，然后是对计算损失函数相对于所有模型参数的梯度的 BPTT 算法进行严谨的推导。最后，将陈述梯度下降更新规则，从而完成算法的规范。\n\n设模型参数由集合 $\\theta = \\{\\mathbf{W}_{xh}, \\mathbf{W}_{hh}, \\mathbf{b}_h, \\mathbf{W}_{hy}, \\mathbf{b}_y\\}$ 表示。给定的维度为输入 $D=2$，隐藏层 $H=3$，输出 $O=1$。\n\n**1. 前向传播**\n\n前向传播计算网络的状态和输出序列。给定输入序列 $\\{\\mathbf{x}_t\\}_{t=0}^{T-1}$ 和初始隐藏状态 $\\mathbf{h}_{-1} = \\mathbf{0}$，网络的演化由以下递推关系描述，对于 $t = 0, 1, \\ldots, T-1$：\n\n时间 $t$ 时隐藏层的预激活值是当前输入 $\\mathbf{x}_t$ 和前一个隐藏状态 $\\mathbf{h}_{t-1}$ 的线性组合：\n$$\n\\mathbf{a}_t = \\mathbf{W}_{xh}\\mathbf{x}_t + \\mathbf{W}_{hh}\\mathbf{h}_{t-1} + \\mathbf{b}_h\n$$\n通过按元素应用双曲正切激活函数得到隐藏状态 $\\mathbf{h}_t$：\n$$\n\\mathbf{h}_t = \\tanh(\\mathbf{a}_t)\n$$\n网络输出 $\\hat{\\mathbf{y}}_t$ 是当前隐藏状态的线性变换：\n$$\n\\hat{\\mathbf{y}}_t = \\mathbf{W}_{hy}\\mathbf{h}_t + \\mathbf{b}_y\n$$\n总损失 $\\mathcal{L}$ 是仅在由集合 $\\mathcal{E}$ 指定的事件时间计算的平方误差之和。使用事件掩码 $m_t$（其中如果 $t \\in \\mathcal{E}$ 则 $m_t=1$，否则 $m_t=0$），损失为：\n$$\n\\mathcal{L} = \\frac{1}{2} \\sum_{t=0}^{T-1} m_t \\left\\lVert \\hat{\\mathbf{y}}_t - \\mathbf{y}_t \\right\\rVert_2^2\n$$\n在此问题中，由于 $O=1$，输出 $\\hat{y}_t$ 和目标 $y_t$ 是标量，因此平方范数变成简单的平方：$\\mathcal{L} = \\frac{1}{2} \\sum_{t=0}^{T-1} m_t (\\hat{y}_t - y_t)^2$。\n\n**2. 时间反向传播 (BPTT)**\n\n为了使用梯度下降更新参数，我们必须计算总损失 $\\mathcal{L}$ 相对于 $\\theta$ 中每个参数的梯度。这通过应用链式法则，从时间 $t=T-1$ 到 $t=0$ 递归地向后传播来实现。\n\n**输出层参数的梯度 ($\\mathbf{W}_{hy}, \\mathbf{b}_y$)**\n\n损失 $\\mathcal{L}$ 仅通过输出 $\\hat{\\mathbf{y}}_t$ 依赖于 $\\mathbf{W}_{hy}$ 和 $\\mathbf{b}_y$。损失相对于时间 $t$ 输出的梯度是：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{y}}_t} = m_t (\\hat{\\mathbf{y}}_t - \\mathbf{y}_t)\n$$\n使用链式法则，我们通过对所有时间步的贡献求和来找到 $\\mathbf{W}_{hy}$ 和 $\\mathbf{b}_y$ 的梯度：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{hy}} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{y}}_t} \\frac{\\partial \\hat{\\mathbf{y}}_t}{\\partial \\mathbf{W}_{hy}} = \\sum_{t=0}^{T-1} m_t (\\hat{\\mathbf{y}}_t - \\mathbf{y}_t) \\mathbf{h}_t^T\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_y} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{y}}_t} \\frac{\\partial \\hat{\\mathbf{y}}_t}{\\partial \\mathbf{b}_y} = \\sum_{t=0}^{T-1} m_t (\\hat{\\mathbf{y}}_t - \\mathbf{y}_t)\n$$\n\n**隐藏层参数的梯度 ($\\mathbf{W}_{xh}, \\mathbf{W}_{hh}, \\mathbf{b}_h$)**\n\n隐藏层参数的梯度更为复杂，因为隐藏状态 $\\mathbf{h}_t$ 会影响当前时间 $t$ 及所有后续时间的损失。BPTT 提供了一种系统地计算这些梯度的方法。关键是计算损失相对于隐藏层预激活值的梯度，$\\delta_t \\equiv \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{a}_t}$。\n\n梯度 $\\delta_t$ 可以通过链式法则找到：$\\delta_t = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{a}_t}$。\n激活函数的导数是 $\\frac{d \\tanh(z)}{dz} = 1 - \\tanh^2(z)$。按元素计算，即 $\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{a}_t} = \\text{diag}(1-\\mathbf{h}_t^2)$，其中平方是按元素计算的。\n梯度 $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t}$ 有两个部分：$\\mathbf{h}_t$ 对当前输出 $\\hat{\\mathbf{y}}_t$ 的影响，以及它对下一个隐藏状态预激活值 $\\mathbf{a}_{t+1}$ 的影响。\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} = \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{y}}_t} \\frac{\\partial \\hat{\\mathbf{y}}_t}{\\partial \\mathbf{h}_t}}_{\\text{来自当前输出}} + \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{a}_{t+1}} \\frac{\\partial \\mathbf{a}_{t+1}}{\\partial \\mathbf{h}_t}}_{\\text{来自下一个状态}} = \\mathbf{W}_{hy}^T m_t(\\hat{\\mathbf{y}}_t - \\mathbf{y}_t) + \\mathbf{W}_{hh}^T \\delta_{t+1}\n$$\n结合这些，得到 $\\delta_t$ 的反向递推关系：\n$$\n\\delta_t = \\left( \\mathbf{W}_{hy}^T m_t(\\hat{\\mathbf{y}}_t - \\mathbf{y}_t) + \\mathbf{W}_{hh}^T \\delta_{t+1} \\right) \\circ (1 - \\mathbf{h}_t^2)\n$$\n其中 $\\circ$ 表示按元素（哈达玛）积。递推以 $\\delta_T = \\mathbf{0}$ 初始化，因为在 $t=T-1$ 之后没有状态。\n\n计算出所有 $t$ 的 $\\delta_t$ 后，我们可以通过对时间求和来找到隐藏层参数的梯度：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{xh}} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{a}_t} \\frac{\\partial \\mathbf{a}_t}{\\partial \\mathbf{W}_{xh}} = \\sum_{t=0}^{T-1} \\delta_t \\mathbf{x}_t^T\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{hh}} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{a}_t} \\frac{\\partial \\mathbf{a}_t}{\\partial \\mathbf{W}_{hh}} = \\sum_{t=0}^{T-1} \\delta_t \\mathbf{h}_{t-1}^T\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_h} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{a}_t} \\frac{\\partial \\mathbf{a}_t}{\\partial \\mathbf{b}_h} = \\sum_{t=0}^{T-1} \\delta_t\n$$\n关键在于，即使当 $m_t=0$（一个“静默”时间步）时，$\\mathbf{W}_{hh}^T \\delta_{t+1}$ 项也会从未来的事件中传播梯度，从而确保非事件时间的隐藏状态被训练以携带对未来预测有用的信息。\n\n**3. 参数更新**\n\n计算完所有梯度后，使用学习率 $\\alpha = 0.1$ 执行单步梯度下降。对于任何参数 $\\mathbf{P} \\in \\theta$：\n$$\n\\mathbf{P}_{\\text{new}} = \\mathbf{P}_{\\text{old}} - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{P}}\n$$\n\n**4. 算法总结**\n\n对于每个测试用例，执行以下过程：\n1.  **初始前向传播：** 使用初始参数执行一次前向传播，计算所有隐藏状态 $\\{\\mathbf{h}_t\\}$ 和输出 $\\{\\hat{\\mathbf{y}}_t\\}$，并计算初始总损失 $\\mathcal{L}_{\\text{before}}$。为反向传播存储中间值（$\\mathbf{x}_t, \\mathbf{h}_t, \\mathbf{h}_{t-1}$）。\n2.  **反向传播：** 执行上述推导的 BPTT 算法，从 $t=T-1$ 向下迭代到 $0$，以计算损失相对于所有参数的梯度。\n3.  **参数更新：** 使用梯度下降更新规则计算新的参数值。\n4.  **最终前向传播：** 使用更新后的参数执行一次新的前向传播，以计算新的总损失 $\\mathcal{L}_{\\text{after}}$。\n然后收集每个用例的结果 $[\\mathcal{L}_{\\text{before}}, \\mathcal{L}_{\\text{after}}]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the event-driven RNN problem by implementing BPTT,\n    running it on four test cases, and printing the formatted results.\n    \"\"\"\n\n    def run_case(params, T, xs, event_set, targets_dict, D, H, O, alpha):\n        \"\"\"\n        Runs a single test case: forward pass, backward pass, parameter update,\n        and a final forward pass to compute before/after losses.\n        \"\"\"\n        W_xh, W_hh, b_h, W_hy, b_y = params\n\n        # 1. First forward pass to compute L_before\n        h_s = {-1: np.zeros((H, 1))}\n        a_s = {}\n        y_hats = {}\n        loss_before = 0.0\n\n        for t in range(T):\n            x_t = xs[t].reshape(D, 1)\n            \n            # Recurrence relation\n            a_s[t] = W_xh @ x_t + W_hh @ h_s[t-1] + b_h\n            h_s[t] = np.tanh(a_s[t])\n            \n            # Output computation\n            y_hat_t = W_hy @ h_s[t] + b_y\n            y_hats[t] = y_hat_t\n            \n            # Loss calculation at event times\n            if t in event_set:\n                y_t = np.array([[targets_dict[t]]])\n                loss_before += 0.5 * np.sum((y_hat_t - y_t)**2)\n\n        # 2. Backward pass (BPTT)\n        # Initialize gradients to zero\n        dW_xh, dW_hh, db_h = np.zeros_like(W_xh), np.zeros_like(W_hh), np.zeros_like(b_h)\n        dW_hy, db_y = np.zeros_like(W_hy), np.zeros_like(b_y)\n        \n        # Initialize gradient from the future (dL/da_{t+1}) to zero\n        delta_a_next = np.zeros((H, 1))\n\n        # Iterate backwards through time from T-1 to 0\n        for t in reversed(range(T)):\n            # Gradient of loss w.r.t. output y_hat_t\n            dy_hat = np.zeros((O, 1))\n            if t in event_set:\n                y_t = np.array([[targets_dict[t]]])\n                dy_hat = y_hats[t] - y_t\n            \n            # Accumulate gradients for output layer parameters\n            dW_hy += dy_hat @ h_s[t].T\n            db_y += dy_hat\n            \n            # Backpropagate gradient to hidden state h_t\n            # This is dL/dh_t, combining gradient from output and from next state\n            delta_h = W_hy.T @ dy_hat + W_hh.T @ delta_a_next\n            \n            # Backpropagate through tanh non-linearity to get dL/da_t\n            delta_a = delta_h * (1 - h_s[t]**2)\n\n            # Accumulate gradients for hidden layer parameters\n            dW_hh += delta_a @ h_s[t-1].T\n            dW_xh += delta_a @ xs[t].reshape(D, 1).T\n            db_h += delta_a\n            \n            # Pass the gradient w.r.t. pre-activation to the previous time step\n            delta_a_next = delta_a\n\n        # 3. Update parameters using gradient descent\n        W_xh_new = W_xh - alpha * dW_xh\n        W_hh_new = W_hh - alpha * dW_hh\n        b_h_new = b_h - alpha * db_h\n        W_hy_new = W_hy - alpha * dW_hy\n        b_y_new = b_y - alpha * db_y\n\n        # 4. Second forward pass with new parameters to compute L_after\n        h_s_new = {-1: np.zeros((H, 1))}\n        loss_after = 0.0\n        \n        for t in range(T):\n            x_t = xs[t].reshape(D, 1)\n            a_t_new = W_xh_new @ x_t + W_hh_new @ h_s_new[t-1] + b_h_new\n            h_s_new[t] = np.tanh(a_t_new)\n            y_hat_t_new = W_hy_new @ h_s_new[t] + b_y_new\n            \n            if t in event_set:\n                y_t = np.array([[targets_dict[t]]])\n                loss_after += 0.5 * np.sum((y_hat_t_new - y_t)**2)\n                \n        return loss_before, loss_after\n\n    # Define fixed model parameters and dimensions\n    D, H, O = 2, 3, 1\n    alpha = 0.1\n    W_xh_init = np.array([[0.2, -0.1], [0.0, 0.1], [-0.1, 0.2]])\n    W_hh_init = np.array([[0.1, 0.0, -0.1], [0.05, 0.1, 0.0], [0.0, -0.05, 0.1]])\n    b_h_init = np.array([[0.0], [0.0], [0.0]])\n    W_hy_init = np.array([[0.3, -0.2, 0.1]])\n    b_y_init = np.array([[0.0]])\n    initial_params = (W_xh_init, W_hh_init, b_h_init, W_hy_init, b_y_init)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {\n            \"T\": 5,\n            \"xs\": [np.array([0.5, -0.2]), np.array([-0.3, 0.1]), np.array([0.0, 0.2]), np.array([-0.1, -0.1]), np.array([0.2, 0.0])],\n            \"event_set\": {1, 4},\n            \"targets_dict\": {1: 0.1, 4: -0.05}\n        },\n        # Case B\n        {\n            \"T\": 6,\n            \"xs\": [np.array([0.1, 0.0]), np.array([0.0, 0.1]), np.array([-0.2, 0.2]), np.array([0.3, -0.3]), np.array([0.0, 0.2]), np.array([-0.1, 0.0])],\n            \"event_set\": {5},\n            \"targets_dict\": {5: 0.2}\n        },\n        # Case C\n        {\n            \"T\": 4,\n            \"xs\": [np.array([0.2, 0.2]), np.array([-0.2, 0.1]), np.array([0.1, -0.1]), np.array([0.0, 0.0])],\n            \"event_set\": set(),\n            \"targets_dict\": {}\n        },\n        # Case D\n        {\n            \"T\": 7,\n            \"xs\": [np.array([0.0, 0.1]), np.array([0.1, 0.0]), np.array([0.2, -0.1]), np.array([-0.2, 0.2]), np.array([0.1, -0.2]), np.array([-0.1, 0.1]), np.array([0.0, -0.1])],\n            \"event_set\": {2, 3},\n            \"targets_dict\": {2: -0.1, 3: 0.05}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Each case must start with the same initial parameters\n        params_copy = tuple(p.copy() for p in initial_params)\n        \n        loss_before, loss_after = run_case(\n            params_copy,\n            case[\"T\"],\n            case[\"xs\"],\n            case[\"event_set\"],\n            case[\"targets_dict\"],\n            D, H, O, alpha\n        )\n        results.append(loss_before)\n        results.append(loss_after)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "让我们从预测有序序列转向一项更高级的任务：预测无序的项目集合。这种模式对于多标签分类、或是在图像中检测多个物体等应用至关重要。本次练习要求你像一名架构师一样思考，从零开始设计一个损失函数。你将通过考虑模型预测与目标集合之间所有可能的分配，推导出一个“排列不变”（permutation-invariant）的损失函数，这项技术是现代集合预测模型的核心。这个更偏理论的实践 () 不仅能提升你的概率建模技能，还展示了如何将 RNN 编码器与专门的输出头相结合，以解决超越简单序列的复杂结构化预测问题。",
            "id": "3171341",
            "problem": "您正在使用循环神经网络（RNN）设计一个序列到集合（sequence-to-set）的预测器。一个长度为$T$的输入序列$x_{1:T}$被RNN编码为隐藏状态$h_{1:T}$，然后通过一个在时间上应用的、具有Deep Sets形式的置换不变集合函数进行聚合，具体来说是求和聚合器$u=\\sum_{t=1}^{T} h_t$。然后，一个头部（head）通过$m$个独立的带softmax的仿射映射，从$u$生成$K$个类别上的$m$个独立分类分布。也就是说，对于槽位 $s \\in \\{1,\\dots,m\\}$ 和类别索引 $k \\in \\{1,\\dots,K\\}$，\n$$\np_{s}(y=k \\mid x_{1:T}) \\;=\\; \\frac{\\exp\\!\\left(z_{s,k}\\right)}{\\sum_{j=1}^{K}\\exp\\!\\left(z_{s,j}\\right)},\n$$\n其中 $z_{s} \\in \\mathbb{R}^{K}$ 是槽位 $s$ 的 logits。\n\n目标输出是一个由$m$个不同类别标签组成的无序集合$S=\\{y_{1},\\dots,y_{m}\\}$。集合$S$的元素没有规范的排序，但模型会输出$m$个槽位级（slot-wise）的分类分布。您需要将$m$个输出槽位与$S$中$m$个元素之间的未知对应关系视为一个潜在的置换。\n\n从概率定律和负对数似然的定义出发，完成以下任务：\n\n1. 引入一个在$m$个元素的对称群上取值的潜在置换变量$\\pi$，并通过对$\\pi$进行边缘化，推导出在给定$x_{1:T}$的情况下观测到无序集合$S$的似然表达式。然后，为这个无序目标写出负对数似然损失。\n\n2. 现在，具体到$m=2$和$K=3$的情况。类别集合被索引为$\\{c_{1},c_{2},c_{3}\\}$。对于一个特定的输入序列$x_{1:T}$，两个槽位的 logits 由下式给出\n$$\nz_{1} \\;=\\; \\begin{pmatrix} 0.7  -0.2  1.1 \\end{pmatrix}, \\quad\nz_{2} \\;=\\; \\begin{pmatrix} 1.0  0.0  -0.5 \\end{pmatrix},\n$$\n其中$z_{s}$的第$k$个条目对应于类别$c_{k}$。真实标签的无序集合是$S=\\{c_{1},c_{3}\\}$。使用您推导出的表达式，计算最终的负对数似然损失。使用自然对数$\\ln$，并将最终数值答案四舍五入到四位有效数字。答案是无量纲的；不要包含单位。",
            "solution": "用户提供的问题陈述已经过分析，并被认为是有效的。它在科学上基于概率论和深度学习的原理，问题提出得很好，有唯一的可解答案，并且表述客观。完整解答所需的所有数据和定义均已提供。\n\n### 第1部分：负对数似然损失的推导\n\n问题要求模型预测一个由$m$个不同类别标签组成的无序集合，$S = \\{y_1, \\dots, y_m\\}$，其中每个$y_i \\in \\{1, \\dots, K\\}$。模型从$m$个槽位中产生$m$个独立的分类分布。对于每个槽位$s \\in \\{1, \\dots, m\\}$，输出类别$k \\in \\{1, \\dots, K\\}$的概率由应用于 logits 向量$z_s \\in \\mathbb{R}^K$的softmax函数给出：\n$$\np_s(k) \\equiv p(y=k \\mid x_{1:T}, \\text{slot } s) = \\frac{\\exp(z_{s,k})}{\\sum_{j=1}^{K} \\exp(z_{s,j})}\n$$\n由于目标$S$是一个无序集合，模型的$m$个输出槽位与$S$中的$m$个目标标签之间没有预定义的对应关系。我们必须考虑所有可能的一一对应分配。一个分配可以用一个置换$\\pi \\in S_m$来表示，其中$S_m$是$m$个元素上的对称群。我们将目标集合$S$的元素任意索引为一个元组$(y'_1, \\dots, y'_m)$。一个置换$\\pi$定义了一个分配，其中槽位$s$与目标标签$y'_{\\pi(s)}$匹配，对于$s=1, \\dots, m$。\n\n由$\\pi$指定的单个此类分配的似然，是所有槽位产生其分配的目标标签的联合概率。由于槽位的独立性，这是各个槽位概率的乘积：\n$$\nP(\\text{assignment } \\pi \\mid x_{1:T}) = \\prod_{s=1}^{m} p_s(y'_{\\pi(s)})\n$$\n为了找到观测到无序集合$S$的总似然，我们必须对所有可能的分配的似然求和。这等同于对潜在置换变量$\\pi$进行边缘化。由于在$S_m$中有$m!$个置换，总似然$L(S \\mid x_{1:T})$为：\n$$\nL(S \\mid x_{1:T}) = P(S \\mid x_{1:T}) = \\sum_{\\pi \\in S_m} \\prod_{s=1}^{m} p_s(y'_{\\pi(s)})\n$$\n负对数似然（NLL）损失，记为$\\mathcal{L}$，是这个总似然的负自然对数：\n$$\n\\mathcal{L} = -\\ln(L(S \\mid x_{1:T})) = -\\ln\\left( \\sum_{\\pi \\in S_m} \\prod_{s=1}^{m} p_s(y'_{\\pi(s)}) \\right)\n$$\n这个表达式代表了无序目标集的损失。\n\n### 第2部分：具体案例的计算\n\n我们有以下给定值：\n- 槽位/目标标签数量：$m=2$\n- 类别数量：$K=3$，索引为$\\{c_1, c_2, c_3\\}$\n- 槽位 logits：\n  $$\n  z_1 = \\begin{pmatrix} 0.7  -0.2  1.1 \\end{pmatrix}\n  $$\n  $$\n  z_2 = \\begin{pmatrix} 1.0  0.0  -0.5 \\end{pmatrix}\n  $$\n- 真实标签的无序集合：$S=\\{c_1, c_3\\}$\n\n对于$m=2$，对称群$S_2$包含两个置换：单位元$\\pi_1=(1, 2)$和交换$\\pi_2=(2, 1)$。我们将目标标签表示为$y'_1=c_1$和$y'_2=c_3$。\n\n总似然是两种可能分配的似然之和：\n1. 槽位1预测$c_1$且槽位2预测$c_3$。似然为$p_1(c_1) p_2(c_3)$。\n2. 槽位1预测$c_3$且槽位2预测$c_1$。似然为$p_1(c_3) p_2(c_1)$。\n\n总似然为 $L(S \\mid x_{1:T}) = p_1(c_1)p_2(c_3) + p_1(c_3)p_2(c_1)$。\n因此，NLL损失为：\n$$\n\\mathcal{L} = -\\ln\\left( p_1(c_1)p_2(c_3) + p_1(c_3)p_2(c_1) \\right)\n$$\n为了进行数值计算，我们可以先计算概率$p_s(k)$。然而，为了数值稳定性，最好在对数域中进行计算。我们将$p_s(k)$的定义代入似然表达式中：\n$$\nL = \\frac{\\exp(z_{1,c_1})}{\\sum_{j=1}^3 \\exp(z_{1,j})} \\frac{\\exp(z_{2,c_3})}{\\sum_{j=1}^3 \\exp(z_{2,j})} + \\frac{\\exp(z_{1,c_3})}{\\sum_{j=1}^3 \\exp(z_{1,j})} \\frac{\\exp(z_{2,c_1})}{\\sum_{j=1}^3 \\exp(z_{2,j})}\n$$\n$$\nL = \\frac{\\exp(z_{1,c_1} + z_{2,c_3}) + \\exp(z_{1,c_3} + z_{2,c_1})}{\\left(\\sum_{j=1}^3 \\exp(z_{1,j})\\right) \\left(\\sum_{j=1}^3 \\exp(z_{2,j})\\right)}\n$$\nNLL损失为$\\mathcal{L} = -\\ln(L)$。利用对数的性质，我们可以写出：\n$$\n\\mathcal{L} = \\ln\\left(\\sum_{j=1}^3 \\exp(z_{1,j})\\right) + \\ln\\left(\\sum_{j=1}^3 \\exp(z_{2,j})\\right) - \\ln\\left(\\exp(z_{1,c_1} + z_{2,c_3}) + \\exp(z_{1,c_3} + z_{2,c_1})\\right)\n$$\n这种涉及log-sum-exp（对数-和-指数）运算的形式在数值上是稳定的。我们来计算每一项。对应于类别$(c_1, c_2, c_3)$的 logits 是：\n$z_1 = (0.7, -0.2, 1.1)$\n$z_2 = (1.0, 0.0, -0.5)$\n\n第一项是$z_1$的log-sum-exp：\n$$\n\\ln(\\exp(0.7) + \\exp(-0.2) + \\exp(1.1)) \\approx \\ln(2.01375 + 0.81873 + 3.00417) = \\ln(5.83665) \\approx 1.76413\n$$\n第二项是$z_2$的log-sum-exp：\n$$\n\\ln(\\exp(1.0) + \\exp(0.0) + \\exp(-0.5)) \\approx \\ln(2.71828 + 1 + 0.60653) = \\ln(4.32481) \\approx 1.46431\n$$\n对于第三项，我们首先计算每个置换的 logits 之和：\n- 分配1（槽位1 $\\to c_1$，槽位2 $\\to c_3$）：Logits之和 = $z_{1,c_1} + z_{2,c_3} = 0.7 + (-0.5) = 0.2$\n- 分配2（槽位1 $\\to c_3$，槽位2 $\\to c_1$）：Logits之和 = $z_{1,c_3} + z_{2,c_1} = 1.1 + 1.0 = 2.1$\n\n第三项是这两个值的log-sum-exp：\n$$\n\\ln(\\exp(0.2) + \\exp(2.1)) \\approx \\ln(1.22140 + 8.16617) = \\ln(9.38757) \\approx 2.23934\n$$\n最后，我们将各项组合起来得到损失$\\mathcal{L}$：\n$$\n\\mathcal{L} \\approx 1.76413 + 1.46431 - 2.23934 = 0.98910\n$$\n使用更高精度进行中间计算可得：\n$\\mathcal{L} = 1.7641293... + 1.4643101... - 2.2393351... = 0.9891042...$\n\n将最终答案四舍五入到四位有效数字，得到$0.9891$。",
            "answer": "$$\\boxed{0.9891}$$"
        }
    ]
}