{
    "hands_on_practices": [
        {
            "introduction": "循环神经网络（RNN）的核心是状态转移系统。为了揭示其工作原理的本质，本练习将引导你手动构建一个RNN，使其精确地模拟一个简单的确定性有限自动机（DFA），而非通过统计训练得到。这个过程将阐明网络权重与计算逻辑之间的直接联系，让你从根本上理解RNN是如何按顺序处理信息的。",
            "id": "3167650",
            "problem": "您的任务是构建一个确定性循环神经网络，该网络能为一个正则形式语言精确地实现一个确定性有限自动机，并分析其隐状态嵌入的几何结构。请纯粹用数学术语进行推导，并基于以下基本定义：确定性有限自动机、具有固定单元的循环神经网络，以及整流线性单元 (ReLU) 和通过最大值参数 (argmax) 实现的硬决策规则。不要使用任何统计估计或训练；您的构建必须是显式和精确的。\n\n考虑在字母表 $\\Sigma = \\{a,b\\}$ 上定义的正则语言\n$$\nL \\;=\\; \\{\\, w \\in \\{a,b\\}^\\ast \\;:\\; w \\text{ 是子字符串 } ab \\text{ 的零次或多次重复拼接} \\,\\},\n$$\n即 $L = (ab)^\\ast$。将一个确定性有限自动机定义为一个元组 $(\\mathcal{Q},\\Sigma,\\delta,q_0,\\mathcal{F})$，其组成部分如下：\n- 状态集 $\\mathcal{Q} = \\{q_0,q_1,q_d\\}$，其中 $q_0$ 是起始状态，$q_1$ 是在读取一个开始区块的 $a$ 之后的状态，$q_d$ 是一个捕获任何无效延续的死状态。\n- 输入字母表 $\\Sigma = \\{a,b\\}$。\n- 转移函数 $\\delta: \\mathcal{Q}\\times\\Sigma \\to \\mathcal{Q}$，其逻辑由下式给出：\n  - $\\delta(q_0,a)=q_1$, $\\delta(q_0,b)=q_d$,\n  - $\\delta(q_1,a)=q_d$, $\\delta(q_1,b)=q_0$,\n  - $\\delta(q_d,a)=q_d$, $\\delta(q_d,b)=q_d$.\n- 起始状态 $q_0$。\n- 接受状态集 $\\mathcal{F}=\\{q_0\\}$。\n\n构建一个循环神经网络，该网络一次处理一个符号，并精确模拟此自动机，采用以下设计决策：\n- 将时间 $t$ 的 RNN 隐状态表示为 $h_t \\in \\mathbb{R}^3$，约束其为当前自动机状态的 one-hot 向量，即 $h_t \\in \\{e_0,e_1,e_2\\}$，其中 $e_i$ 是 $\\mathbb{R}^3$ 的第 $i$ 个标准基向量，并有对应关系 $e_0 \\leftrightarrow q_0$, $e_1 \\leftrightarrow q_1$, $e_2 \\leftrightarrow q_d$。\n- 将时间 $t$ 的输入符号表示为 $x_t \\in \\mathbb{R}^2$，它是一个 one-hot 向量 $x_t \\in \\{u_a,u_b\\}$，其中 $u_a=(1,0)^\\top$ 和 $u_b=(0,1)^\\top$ 分别对应于 $a$ 和 $b$。\n- 定义一个双层单元，它接收拼接向量 $u_t = [h_{t-1}; x_t] \\in \\mathbb{R}^{5}$，计算中间激活值 $g_t = \\mathrm{ReLU}(W_1 u_t + b_1) \\in \\mathbb{R}^{6}$，计算 logits $z_t = W_2 g_t + b_2 \\in \\mathbb{R}^3$，并将下一个隐状态设置为 one-hot 向量 $h_t = \\text{one\\_hot}(\\arg\\max_k z_t[k])$。此处，$\\mathrm{ReLU}(s)=\\max\\{0,s\\}$ 按元素应用。\n\n您的任务是：\n1. 指定 $W_1 \\in \\mathbb{R}^{6\\times 5}$ 和 $b_1 \\in \\mathbb{R}^{6}$ 的一个构造性选择，使得 $g_t$ 中的 6 个单元中的每一个都是一个对检测器，当且仅当一个特定的对 $(h_{t-1},x_t)$ 出现时，它会严格为正激活，否则为 $0$。在 $W_1$ 中仅使用集合 $\\{-1,0,1\\}$ 中的常数，并对所有 6 个隐藏单元使用相同的常数偏置 $b_1$。\n2. 指定 $W_2 \\in \\mathbb{R}^{3\\times 6}$ 和 $b_2 \\in \\mathbb{R}^{3}$ 的一个构造性选择，使得对于每个有效的对 $(h_{t-1},x_t)$，对三个 logits $z_t$ 的 argmax 运算能精确地产生 $\\delta(q,x)$ 的索引，从而保证 $h_t = e_{\\delta(q,x)}$。\n3. 根据上述定义，从第一性原理证明，对于任意有限长度的输入序列，您的构造在处理任何前缀后产生的 $h_t$ 等于自动机状态的精确 one-hot 状态编码。您的证明不应使用概率论证；它必须遵循 ReLU 的代数形式和 argmax 规则。\n4. 分析您的构造下隐状态嵌入 $\\{h_t\\}$ 的几何结构。描述三个状态嵌入之间的两两欧几里得距离，并论证以相同自动机状态结束的不同前缀的嵌入是否重合。\n\n程序规范和测试套件：\n- 您的程序必须使用固定的数值数组 $W_1$, $b_1$, $W_2$, $b_2$ 来实现您的显式构造，必须处理一批在 $\\{a,b\\}$ 上的测试字符串，并且必须计算两个输出：\n  1. 以下 10 个测试字符串的接受结果，顺序为：空字符串 $\\varepsilon$, $ab$, $abab$, $a$, $aba$, $abb$, $b$, $ba$, $aaa$, $ababa$。将每个接受结果报告为一个布尔值，布尔值以该语言的标准布尔字面量形式打印，接受意味着最终状态在 $\\mathcal{F}$ 中。\n  2. 三个状态嵌入之间的三个欧几里得距离列表，顺序为 $d(q_0,q_1)$, $d(q_0,q_d)$, $d(q_1,q_d)$。通过计算所有长度不超过 4 的字符串的隐状态 $h_T$ 来经验性地估计这些距离，并通过对以相同状态结束的那些 $h_T$ 进行平均，为每个状态获得一个质心，然后计算这三个质心之间的欧几里得距离。将这些距离表示为十进制浮点数。\n- 最终输出格式：您的程序应生成单行输出，包含一个含两个元素的顶层列表，其中第一个元素是按上述顺序列出的 10 个布尔值的列表，第二个元素是按指定顺序列出的三个浮点数的列表。例如，您的输出必须类似于\n  $$\n  [ [\\text{True}, \\ldots, \\text{False}], [d_{01}, d_{0d}, d_{1d}] ].\n  $$\n您的程序不会接收外部输入，也不应读取或写入任何外部文件。所有结果必须在内存中计算并严格按照规定打印。此任务不涉及物理单位或角度，因此不需要额外的单位约定。在您的推导和构建中出现的所有数字必须与上述定义一致。",
            "solution": "该问题要求构建一个循环神经网络 (RNN)，该网络能够确定性地模拟一个给定的确定性有限自动机 (DFA)，此 DFA 用于处理正则语言 $L = (ab)^\\ast$。该构建必须是精确的，并从第一性原理推导得出。\n\n用于 $L=(ab)^\\ast$ 的 DFA 由 $(\\mathcal{Q}, \\Sigma, \\delta, q_0, \\mathcal{F})$ 给出，其中：\n- 状态集 $\\mathcal{Q} = \\{q_0, q_1, q_d\\}$。\n- 字母表 $\\Sigma = \\{a, b\\}$。\n- 转移函数 $\\delta$: $\\delta(q_0,a)=q_1$, $\\delta(q_0,b)=q_d$, $\\delta(q_1,a)=q_d$, $\\delta(q_1,b)=q_0$, $\\delta(q_d,a)=q_d$, $\\delta(q_d,b)=q_d$。\n- 起始状态为 $q_0$。\n- 接受状态集 $\\mathcal{F} = \\{q_0\\}$。\n\nRNN 必须对状态和输入使用 one-hot 编码。状态 $q_0, q_1, q_d$ 分别映射到 $\\mathbb{R}^3$ 中的标准基向量 $e_0=(1,0,0)^\\top$, $e_1=(0,1,0)^\\top$ 和 $e_2=(0,0,1)^\\top$。输入符号 $a,b$ 分别映射到 $\\mathbb{R}^2$ 中的 $u_a=(1,0)^\\top$ 和 $u_b=(0,1)^\\top$。初始隐状态为 $h_0 = e_0$，对应于起始状态 $q_0$。\n\nRNN 从状态 $h_{t-1}$ 和输入 $x_t$ 到下一个状态 $h_t$ 的更新规则是：\n$u_t = [h_{t-1}; x_t] \\in \\mathbb{R}^5$\n$g_t = \\mathrm{ReLU}(W_1 u_t + b_1) \\in \\mathbb{R}^6$\n$z_t = W_2 g_t + b_2 \\in \\mathbb{R}^3$\n$h_t = \\text{one\\_hot}(\\arg\\max_k z_t[k])$\n\n我们现在将指定权重矩阵 $W_1, W_2$ 和偏置向量 $b_1, b_2$ 以实现 DFA 的逻辑。\n\n**1. $W_1$ 和 $b_1$ 的构建**\n\n第一层的目的是创建六个“对检测器”神经元，每个神经元对应于 $\\mathcal{Q} \\times \\Sigma$ 中六个可能的（状态，输入）对之一。设中间层 $g_t$ 中的神经元按以下顺序对应于这些对：$(q_0, a)$, $(q_0, b)$, $(q_1, a)$, $(q_1, b)$, $(q_d, a)$, $(q_d, b)$。一个用于对 $(q_i, \\text{sym}_j)$（其中 $\\text{sym}_0=a, \\text{sym}_1=b$）的检测器，当且仅当前一个状态是 $h_{t-1}=e_i$ 且当前输入是 $x_t=u_{\\text{sym}_j}$ 时，必须激活（即输出一个大于 0 的值）。\n\n拼接后的输入向量是 $u_t = (h_{t-1}[0], h_{t-1}[1], h_{t-1}[2], x_t[0], x_t[1])^\\top$。对于一个特定的输入对 $(e_i, u_{\\text{sym}_j})$，向量 $u_t$ 在索引 $i$ 处有一个 1，在索引 $3+j$ 处有一个 1，并且在各自的 one-hot 块中的其他位置为零。例如，对 $(q_0, a)$ 对应于 $h_{t-1}=e_0$ 和 $x_t=u_a$，所以 $u_t=(1,0,0,1,0)^\\top$。\n\n我们设计一个检测器，使其对目标对 $(e_i, u_j)$ 的预激活值为 $u_t[i] + u_t[3+j] - 1.5$。但为了使用整数和统一偏置，我们设预激活为 $u_t[i] + u_t[3+j] - 1$。\n- 对于目标对，预激活是 $1+1-1=1 > 0$，所以 $\\mathrm{ReLU}(1)=1$。\n- 对于状态相同但输入不同的对，或输入相同但状态不同的对，预激活是 $1+0-1=0$，所以 $\\mathrm{ReLU}(0)=0$。\n- 对于状态和输入都不同的对，预激活是 $0+0-1=-1$，所以 $\\mathrm{ReLU}(-1)=0$。\n\n这个构造完美有效。矩阵 $W_1 \\in \\mathbb{R}^{6 \\times 5}$ 的构建方法是为 6 个对 $(q_i, \\text{sym}_j)$ 中的每一个创建一个行：\n$$\nW_1 =\n\\begin{pmatrix}\n1  0  0  1  0 \\\\  % (q0, a) 检测器\n1  0  0  0  1 \\\\  % (q0, b) 检测器\n0  1  0  1  0 \\\\  % (q1, a) 检测器\n0  1  0  0  1 \\\\  % (q1, b) 检测器\n0  0  1  1  0 \\\\  % (qd, a) 检测器\n0  0  1  0  1     % (qd, b) 检测器\n\\end{pmatrix}\n$$\n偏置向量 $b_1 \\in \\mathbb{R}^6$ 是：\n$$\nb_1 = (-1, -1, -1, -1, -1, -1)^\\top\n$$\n通过这种构造，对于任何有效的 one-hot 输入 $h_{t-1}$ 和 $x_t$，向量 $g_t$ 将是一个 one-hot 向量，其中唯一的 1 表示六种可能的转移中哪一种发生了。\n\n**2. $W_2$ 和 $b_2$ 的构建**\n\n第二层必须将 $g_t$ 中激活的对检测器映射到下一个状态。由于 $g_t$ 是一个指示转移的 one-hot 向量，我们可以设计 $W_2$ 使得 $z_t = W_2 g_t$（选择 $b_2 = 0$）直接成为下一个状态的 one-hot 编码。这意味着 $W_2$ 的每一列都应是相应转移所导致的下一个状态的 one-hot 向量。$W_2$ 的行对应于 $q_0, q_1, q_d$ 的输出 logits，列对应于 6 种输入转移。\n\n- 第 0 列，用于 $(q_0, a) \\to q_1$ (索引1): $(0,1,0)^\\top$\n- 第 1 列，用于 $(q_0, b) \\to q_d$ (索引2): $(0,0,1)^\\top$\n- 第 2 列，用于 $(q_1, a) \\to q_d$ (索引2): $(0,0,1)^\\top$\n- 第 3 列，用于 $(q_1, b) \\to q_0$ (索引0): $(1,0,0)^\\top$\n- 第 4 列，用于 $(q_d, a) \\to q_d$ (索引2): $(0,0,1)^\\top$\n- 第 5 列，用于 $(q_d, b) \\to q_d$ (索引2): $(0,0,1)^\\top$\n\n所以，矩阵 $W_2 \\in \\mathbb{R}^{3 \\times 6}$ 是：\n$$\nW_2 =\n\\begin{pmatrix}\n0  0  0  1  0  0 \\\\  % q0 的 logit\n1  0  0  0  0  0 \\\\  % q1 的 logit\n0  1  1  0  1  1     % qd 的 logit\n\\end{pmatrix}\n$$\n偏置向量 $b_2 \\in \\mathbb{R}^3$ 是：\n$$\nb_2 = (0, 0, 0)^\\top\n$$\n通过这种构造，如果 $g_t$ 是 one-hot 向量 $e_k$ (在 $\\mathbb{R}^6$ 中)，那么 $z_t = W_2 e_k = (W_2 \\text{ 的第 k 列})$，这就是正确下一个状态的 one-hot 向量。$\\arg\\max$ 将唯一地识别这个下一个状态。\n\n**3. 正确性证明**\n\n我们通过对输入字符串 $w$ 的长度进行归纳来证明 RNN 的隐状态 $h_t$ 是处理 $w$ 后 DFA 状态的 one-hot 编码。\n- **基本情况 ($t=0$)：** 对于空字符串 $\\varepsilon$，RNN 初始化为 $h_0 = e_0 = (1,0,0)^\\top$。这正确地表示了 DFA 的起始状态 $q_0$。\n- **归纳假设：** 假设在处理长度为 $t-1$ 的前缀 $w'$ 后，RNN 状态 $h_{t-1}$ 是 $e_i$，其中 $i$ 是 DFA 当前状态 $q' = \\delta^\\ast(q_0, w')$ 的索引。\n- **归纳步骤：** 设下一个输入符号为 $s_t$。DFA 转移到状态 $q_{new} = \\delta(q', s_t)$。设 $q_{new}$ 的索引为 $m$。我们需要证明 RNN 转移到状态 $h_t = e_m$。\n1. RNN 单元接收输入 $u_t = [h_{t-1}; x_t]$，其中 $h_{t-1} = e_i$，而 $x_t$ 是 $s_t$ 的 one-hot 编码。\n2. 如第 1 部分所示，中间激活值 $g_t = \\mathrm{ReLU}(W_1 u_t + b_1)$ 将是一个 one-hot 向量 $e_k \\in \\mathbb{R}^6$，其中 $k$ 是对应于对 $(q', s_t)$ 的索引。\n3. logits 计算为 $z_t = W_2 g_t + b_2$。由于 $g_t=e_k$ 且 $b_2=0$，所以 $z_t$ 是 $W_2$ 的第 $k$ 列。\n4. 如第 2 部分所示，$W_2$ 的第 $k$ 列被构造成 $e_m$，即新状态 $q_{new}$ 的 one-hot 编码。因此，$z_t = e_m$。\n5. 新的隐状态是 $h_t = \\text{one\\_hot}(\\arg\\max_l z_t[l])$。由于 $z_t = e_m$，最大值 1 在索引 $m$ 处。因此，$\\arg\\max_l z_t[l] = m$。\n6. 应用 one-hot 函数得到 $h_t = e_m$，这是新 DFA 状态 $q_{new}$ 的正确 one-hot 编码。\n\n根据数学归纳法原理，对于任何有限长度的输入字符串，该 RNN 都能正确模拟 DFA。\n\n**4. 隐状态嵌入的几何结构**\n\n隐状态嵌入被限制为 $\\mathbb{R}^3$ 中的三个标准基向量之一：$\\{e_0, e_1, e_2\\}$。\n- $h(q_0) = e_0 = (1,0,0)^\\top$\n- $h(q_1) = e_1 = (0,1,0)^\\top$\n- $h(q_d) = e_2 = (0,0,1)^\\top$\n\n这三个向量构成了 $\\mathbb{R}^3$ 中正交基的顶点。两两之间的欧几里得距离是：\n- $d(q_0, q_1) = ||e_0 - e_1||_2 = ||(1, -1, 0)^\\top||_2 = \\sqrt{1^2 + (-1)^2 + 0^2} = \\sqrt{2}$。\n- $d(q_0, q_d) = ||e_0 - e_2||_2 = ||(1, 0, -1)^\\top||_2 = \\sqrt{1^2 + 0^2 + (-1)^2} = \\sqrt{2}$。\n- $d(q_1, q_d) = ||e_1 - e_2||_2 = ||(0, 1, -1)^\\top||_2 = \\sqrt{0^2 + 1^2 + (-1)^2} = \\sqrt{2}$。\n\n关于以相同自动机状态结束的前缀：我们的证明表明，RNN 在处理任何前缀后的隐状态*仅*由该前缀的 DFA 最终状态决定。例如，前缀 $\\varepsilon$ 和 $ab$ 都使 DFA 到达状态 $q_0$。在处理这两个前缀结束时，RNN 的隐状态将完全是 $e_0$。类似地，前缀 $a$ 和 $aba$ 都导致状态 $q_1$，两者最终的 RNN 隐状态都将完全是 $e_1$。\n\n因此，导致相同自动机状态的不同前缀的嵌入不仅仅是聚集在一起；它们是完全相同的。这是精确、确定性构造的直接结果，与统计训练的 RNN 形成对比，在后者中，状态表示会形成分布或簇，而不是离散的点。因此，问题中要求的“经验估计”将产生这些精确的几何结果，因为相同向量的平均值就是该向量本身。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Constructs and analyzes an RNN that simulates a DFA for the language (ab)*.\n    \"\"\"\n    # Task 1  2: Define the weight matrices and bias vectors for the RNN.\n    # W1 and b1 create 6 pair-detectors for (state, symbol) pairs.\n    # The order of detectors is (q0,a), (q0,b), (q1,a), (q1,b), (qd,a), (qd,b).\n    W1 = np.array([\n        [1, 0, 0, 1, 0],  # (q0, a)\n        [1, 0, 0, 0, 1],  # (q0, b)\n        [0, 1, 0, 1, 0],  # (q1, a)\n        [0, 1, 0, 0, 1],  # (q1, b)\n        [0, 0, 1, 1, 0],  # (qd, a)\n        [0, 0, 1, 0, 1]   # (qd, b)\n    ], dtype=np.float64)\n    b1 = np.full((6,), -1.0, dtype=np.float64)\n\n    # W2 and b2 map the activated detector to the next state's one-hot encoding.\n    # DFA transitions: d(q0,a)=q1, d(q0,b)=qd, d(q1,a)=qd, d(q1,b)=q0, d(qd,.)=qd\n    # Next state indices: q1=1, qd=2, qd=2, q0=0, qd=2, qd=2\n    W2 = np.array([\n        [0, 0, 0, 1, 0, 0],  # Logit for q0\n        [1, 0, 0, 0, 0, 0],  # Logit for q1\n        [0, 1, 1, 0, 1, 1]   # Logit for qd\n    ], dtype=np.float64)\n    b2 = np.zeros(3, dtype=np.float64)\n\n    # Input symbol encodings\n    symbol_map = {\n        'a': np.array([1, 0], dtype=np.float64),\n        'b': np.array([0, 1], dtype=np.float64)\n    }\n\n    # States: q0 (index 0), q1 (index 1), qd (index 2)\n    # Accepting state is q0.\n    accepting_idx = 0\n\n    def relu(x):\n        return np.maximum(0, x)\n    \n    def one_hot(index, size):\n        vec = np.zeros(size)\n        vec[index] = 1.0\n        return vec\n\n    def run_rnn(input_string):\n        \"\"\"Processes a string and returns the final state index.\"\"\"\n        # Initial state is q0\n        h = np.array([1, 0, 0], dtype=np.float64)\n        \n        for char in input_string:\n            x = symbol_map[char]\n            u = np.concatenate((h, x))\n            \n            g = relu(W1 @ u + b1)\n            z = W2 @ g + b2\n            \n            next_state_idx = np.argmax(z)\n            h = one_hot(next_state_idx, 3)\n            \n        final_state_idx = np.argmax(h)\n        return final_state_idx\n\n    # Part 1: Acceptance results\n    test_strings = [\"\", \"ab\", \"abab\", \"a\", \"aba\", \"abb\", \"b\", \"ba\", \"aaa\", \"ababa\"]\n    acceptance_results = []\n    for s in test_strings:\n        final_state = run_rnn(s)\n        acceptance_results.append(final_state == accepting_idx)\n\n    # Part 2: Euclidean distances between state embeddings\n    # Generate all strings of length 0 to 4\n    alphabet = ('a', 'b')\n    all_strings = []\n    for length in range(5):\n        for p in itertools.product(alphabet, repeat=length):\n            all_strings.append(\"\".join(p))\n    \n    # Store final hidden state vectors for each ending state\n    state_vectors = {0: [], 1: [], 2: []}\n    for s in all_strings:\n        final_state_idx = run_rnn(s)\n        final_h = one_hot(final_state_idx, 3)\n        state_vectors[final_state_idx].append(final_h)\n\n    # Compute centroids for each state\n    centroids = []\n    for i in range(3):\n        if state_vectors[i]:\n            centroids.append(np.mean(np.array(state_vectors[i]), axis=0))\n        else:\n            # Handle case where a state is unreachable by short strings\n            # In our case, all are reachable.\n            centroids.append(np.zeros(3))\n            \n    c0, c1, c2 = centroids[0], centroids[1], centroids[2]\n\n    # Compute pairwise Euclidean distances\n    dist_01 = np.linalg.norm(c0 - c1)\n    dist_02 = np.linalg.norm(c0 - c2)\n    dist_12 = np.linalg.norm(c1 - c2)\n    \n    distance_results = [dist_01, dist_02, dist_12]\n\n    # Combine results and print in the specified format\n    final_output = [acceptance_results, distance_results]\n    print(f\"[{[bool(b) for b in acceptance_results]}, {distance_results}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在理解了RNN的确定性构造后，我们转向一个更真实的学习场景。本练习要求你训练一个RNN来执行二进制加法，这项任务需要网络具备记忆能力来处理进位。通过有意限制网络的记忆容量，你将探索理论极限（如谱半径）与实际任务失败（如长距离进位错误）之间的直接关系，这是理解“长程依赖问题”的关键一步。",
            "id": "3167589",
            "problem": "您被要求设计、分析并实现一个完整的程序，该程序构建并训练一个循环神经网络（RNN），以模拟一个简单的算法任务（二进制加法），并诊断因有限记忆而产生的原则性失败案例。该任务必须以纯粹的数学术语进行框架设计，并使用统计学习和循环神经网络的基本原理来解决。您的程序的最终输出必须将来自固定测试套件的结果聚合到指定格式的单行中。\n\n此问题的基本基础是标准 Elman 循环神经网络的定义以及二进制加法的因果结构。考虑一个使用双曲正切激活函数的循环神经网络（RNN），其隐藏状态更新由以下递归关系定义\n$$\n\\mathbf{h}_t = \\tanh\\!\\Big(\\mathbf{W}_{hh} \\mathbf{h}_{t-1} + \\mathbf{W}_{xh} \\mathbf{x}_t + \\mathbf{b}_h\\Big),\n$$\n其输出 logit 为\n$$\n\\mathbf{o}_t = \\mathbf{W}_{hy} \\mathbf{h}_t + \\mathbf{b}_y,\n$$\n概率输出为\n$$\n\\mathbf{y}_t = \\sigma(\\mathbf{o}_t),\n$$\n其中 $\\sigma(\\cdot)$ 表示逐元素的 logistic sigmoid 函数。在时间 $t$ 的输入是比特对 $\\mathbf{x}_t = (a_t, b_t)$，其中 $a_t \\in \\{0,1\\}$ 且 $b_t \\in \\{0,1\\}$，从最低有效位（$t = 0$）扫描到最高有效位（$t = T-1$）。网络必须在每个时间步输出两个比特：和比特 $s_t$ 和进位输出比特 $c_t$。真实目标 $(s_t, c_t)$ 是根据第一原理的因果加法规则生成的：初始化 $c_{-1} = 0$，并对每个时间步 $t$ 计算\n$$\nu_t = a_t + b_t + c_{t-1}, \\quad s_t = u_t \\bmod 2, \\quad c_t = \\left\\lfloor \\frac{u_t}{2} \\right\\rfloor.\n$$\n经过 $T$ 步后，完整的和恢复为\n$$\nS = \\sum_{t=0}^{T-1} s_t 2^t + c_{T-1} \\cdot 2^T.\n$$\n\n您的程序必须执行以下操作：\n\n- 在随机生成的 $T_{\\text{train}}$-比特整数对上实现并训练上述 RNN，以模拟逐比特加法算法，其中 $T_{\\text{train}} = 8$。使用在时间和输出上求和的二元交叉熵损失。使用带梯度裁剪的随机梯度下降。初始化 $\\mathbf{h}_{-1} = \\mathbf{0}$。每次参数更新后，通过根据需要重新缩放 $\\mathbf{W}_{hh}$ 来强制执行谱半径约束\n$$\n\\rho\\big(\\mathbf{W}_{hh}\\big) \\le \\rho_{\\max},\n$$\n其中 $\\rho_{\\max} = 0.7$。此约束是强制性的，旨在引入有限的记忆长度。\n\n- 从基本定义出发，推导并实现一个训练后网络的有效记忆长度 $L_{\\varepsilon}$ 的原则性估计器，表示为最小整数 $L$，使得过去 $L$ 步的信息对当前隐藏状态的影响被容差 $\\varepsilon$ 所限制。您的推导必须从 RNN 递归关系开始，通过雅可比积表示隐藏状态到隐藏状态的影响，并使用基于范数或谱半径的界来获得一个可以用学习到的参数和平均激活导数表示的可计算估计器 $L_{\\varepsilon}$。在代码中，设置 $\\varepsilon = 0.05$。\n\n- 将特定输入对 $(\\{a_t\\}, \\{b_t\\})$ 的进位链长度定义为：从最低有效位到最高有效位因果计算时，运行中的进位比特等于 $1$ 的最大连续时间步数。也就是说，如果 $\\{c_t\\}$ 是由上述真实加法规则产生的进位序列，则进位链长度为\n$$\n\\max_{i \\le j} \\Big\\{ (j-i+1) \\; \\text{such that} \\; c_i = c_{i+1} = \\cdots = c_j = 1 \\Big\\}.\n$$\n\n- 通过比较估计的记忆长度 $L_{\\varepsilon}$ 和输入的进位链长度，预测给定输入对的充分性与失败。如果 $L_{\\varepsilon}$ 大于或等于进位链长度，则预测“充分”；否则，预测“不充分”。然后，通过计算每个时间步输出的完整预测和，并将其与真实整数和进行比较，来经验性地评估训练后的 RNN 在该输入对上的表现。\n\n- 测试套件。对所有测试输入使用固定的 $T = 12$ 比特序列长度，并在以下五个非负整数输入对上评估训练后的网络，每个输入对都用 $12$ 比特表示（在计算过程中最低有效位在前）：\n    - 情况 $1$ (happy path): $(A,B) = (25, 6)$。\n    - 情况 $2$ (boundary proximity): $(A,B) = (255, 1)$。\n    - 情况 $3$ (beyond boundary): $(A,B) = (1023, 1)$。\n    - 情况 $4$ (edge case with zero): $(A,B) = (0, 0)$。\n    - 情况 $5$ (extreme carry propagation): $(A,B) = (4095, 1)$。\n  选择这些输入是为了检验关于进位传播的典型行为、边界条件和重要的边缘情况。\n\n- 最终输出格式。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。对于每个测试用例，按顺序输出两个布尔值：\n    1. 第一个布尔值表示估计的记忆长度 $L_{\\varepsilon}$ 是否足以应对该用例的最大进位链长度。\n    2. 第二个布尔值表示训练后的 RNN 是否为该用例生成了完全正确的整数和。\n  因此，最后一行必须总共包含 10 个布尔值，格式为\n$$\n[\\text{p}_1,\\text{a}_1,\\text{p}_2,\\text{a}_2,\\text{p}_3,\\text{a}_3,\\text{p}_4,\\text{a}_4,\\text{p}_5,\\text{a}_5],\n$$\n其中 $\\text{p}_i$ 是预测的充分性，$\\text{a}_i$ 是情况 $i$ 的实际正确性。\n\n本说明书中的所有数学量和数字都必须以其标准数学意义进行解释，并且在适用情况下，答案必须表示为布尔值并完全按照定义进行评估。此问题不涉及任何物理单位或角度单位。",
            "solution": "该问题要求设计、实现和分析一个用于执行二进制加法的循环神经网络（RNN）。问题的关键方面是理论上和经验上研究网络的记忆局限性，这些局限性是通过对循环权重矩阵施加谱半径约束而有意引入的。解决方案分为三个主要阶段：首先，定义模型和训练过程；其次，为网络的有效记忆长度推导一个原则性的估计器；第三，实现完整的系统，以检验一个假设，即网络在长进位加法上的失败可以通过比较此记忆长度与任务所需的进位传播长度来预测。\n\n### 1. RNN 模型和二进制加法任务\n\nRNN 架构是一个标准的 Elman 网络。隐藏状态 $\\mathbf{h}_t \\in \\mathbb{R}^{d_h}$ 根据以下递归关系演化：\n$$\n\\mathbf{h}_t = \\tanh(\\mathbf{W}_{hh} \\mathbf{h}_{t-1} + \\mathbf{W}_{xh} \\mathbf{x}_t + \\mathbf{b}_h)\n$$\n其中 $\\mathbf{x}_t \\in \\{0,1\\}^2$ 是代表两个比特 $(a_t, b_t)$ 的输入向量，$\\mathbf{W}_{hh} \\in \\mathbb{R}^{d_h \\times d_h}$，$\\mathbf{W}_{xh} \\in \\mathbb{R}^{d_h \\times 2}$ 和 $\\mathbf{b}_h \\in \\mathbb{R}^{d_h}$ 是参数。初始隐藏状态为 $\\mathbf{h}_{-1} = \\mathbf{0}$。\n\n在每个时间步 $t$，网络产生输出 logit $\\mathbf{o}_t \\in \\mathbb{R}^2$ 和概率输出 $\\mathbf{y}_t \\in (0,1)^2$：\n$$\n\\mathbf{o}_t = \\mathbf{W}_{hy} \\mathbf{h}_t + \\mathbf{b}_y\n$$\n$$\n\\mathbf{y}_t = \\sigma(\\mathbf{o}_t)\n$$\n其中 $\\mathbf{W}_{hy} \\in \\mathbb{R}^{2 \\times d_h}$，$\\mathbf{b}_y \\in \\mathbb{R}^2$，$\\sigma(\\cdot)$ 是逐元素的 logistic sigmoid 函数。$\\mathbf{y}_t$ 的两个分量是网络对和比特 $s_t$ 和进位输出比特 $c_t$ 的概率预测。\n\n用于训练的真实标签（ground truth）是根据二进制加法规则生成的。给定输入比特 $(a_t, b_t)$ 和进位输入 $c_{t-1}$（其中 $c_{-1}=0$），真实和比特 $s_t$ 和进位输出比特 $c_t$ 为：\n$$\nu_t = a_t + b_t + c_{t-1}\n$$\n$$\ns_t = u_t \\pmod 2\n$$\n$$\nc_t = \\left\\lfloor \\frac{u_t}{2} \\right\\rfloor\n$$\n\n### 2. 训练过程\n\n训练网络以最小化其预测 $\\mathbf{y}_t = (y_{t,s}, y_{t,c})$ 与真实目标 $(s_t, c_t)$ 在长度为 $T$ 的序列上的总二元交叉熵（BCE）损失：\n$$\nL = -\\sum_{t=0}^{T-1} \\left[ s_t \\log(y_{t,s}) + (1-s_t) \\log(1-y_{t,s}) + c_t \\log(y_{t,c}) + (1-c_t) \\log(1-y_{t,c}) \\right]\n$$\n参数使用随机梯度下降（SGD）进行更新，梯度通过随时间反向传播（BPTT）计算。为防止梯度爆炸，所有梯度都被裁剪到最大范数。训练的一个关键特征是对循环权重矩阵强制执行谱半径约束 $\\rho(\\mathbf{W}_{hh}) \\le \\rho_{\\max}$，其中 $\\rho(\\cdot)$ 表示谱半径（最大绝对特征值）。这是通过在每次梯度更新后，如果违反约束，则重新缩放 $\\mathbf{W}_{hh}$ 来实现的：\n$$\n\\text{if } \\rho(\\mathbf{W}_{hh})  \\rho_{\\max}, \\quad \\mathbf{W}_{hh} \\leftarrow \\mathbf{W}_{hh} \\frac{\\rho_{\\max}}{\\rho(\\mathbf{W}_{hh})}\n$$\n此约束限制了 RNN 的长期记忆能力，因为它迫使循环动态的线性部分是收缩的。对于此问题，我们使用 $\\rho_{\\max} = 0.7$ 并在 $T_{\\text{train}}=8$ 比特的数字上进行训练。必须适当选择超参数，如隐藏维度、学习率和训练周期；我们选择 $d_h=4$，学习率为 $\\eta=0.05$，以及 $3000$ 个训练周期。\n\n### 3. 有效记忆长度 $L_{\\varepsilon}$ 的推导\n\n有效记忆长度 $L_{\\varepsilon}$ 是信息可以传播的时间步数，直到其影响衰减到阈值 $\\varepsilon$ 以下。我们可以通过分析时间 $t$ 的隐藏状态相对于过去时间 $t-L$ 的隐藏状态的雅可比矩阵 $\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-L}}$ 来形式化此概念。\n\n在递归关系上使用链式法则：\n$$\n\\frac{\\partial \\mathbf{h}_k}{\\partial \\mathbf{h}_{k-1}} = \\frac{\\partial \\tanh(\\mathbf{z}_k)}{\\partial \\mathbf{z}_k} \\frac{\\partial \\mathbf{z}_k}{\\partial \\mathbf{h}_{k-1}} = \\text{diag}(1-\\tanh^2(\\mathbf{z}_k)) \\cdot \\mathbf{W}_{hh} = \\mathbf{D}_k \\mathbf{W}_{hh}\n$$\n其中 $\\mathbf{z}_k = \\mathbf{W}_{hh} \\mathbf{h}_{k-1} + \\dots$ 是时间 $k$ 的激活前值，$\\mathbf{D}_k$ 是激活导数的对角矩阵。完整的雅可比矩阵是这些项的乘积：\n$$\n\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-L}} = \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-1}} \\frac{\\partial \\mathbf{h}_{t-1}}{\\partial \\mathbf{h}_{t-2}} \\cdots \\frac{\\partial \\mathbf{h}_{t-L+1}}{\\partial \\mathbf{h}_{t-L}} = \\prod_{k=t-L+1}^{t} (\\mathbf{D}_k \\mathbf{W}_{hh})\n$$\n该雅可比矩阵的范数界定了影响的大小。为了获得一个易于处理的估计器，我们做两个近似。首先，我们将时变矩阵 $\\mathbf{D}_k$ 替换为标量-矩阵近似 $\\bar{d} \\mathbf{I}$，其中 $\\bar{d}$ 是导数 $1-\\tanh^2(z)$ 在所有隐藏单元和时间步上的平均值，该平均值从训练数据样本中估计得出。其次，我们利用这样一个性质：对于大的 $L$，矩阵幂的范数 $\\|(\\bar{d}\\mathbf{W}_{hh})^L\\|$ 由其谱半径 $\\rho(\\bar{d}\\mathbf{W}_{hh})^L$ 主导。\n因此，超过 $L$ 步的影响衰减因子近似为 $(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))^L$。我们寻找最小的整数 $L$，使得该值小于或等于 $\\varepsilon$：\n$$\n(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))^L \\le \\varepsilon\n$$\n通过对两边取对数来求解 $L$ 可得：\n$$\nL \\log(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh})) \\le \\log(\\varepsilon)\n$$\n由于 $\\rho(\\mathbf{W}_{hh}) \\le \\rho_{\\max}  1$ 且 $\\bar{d} \\le 1$，项 $\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh})$ 小于 1，使其对数为负。除以这个负数会反转不等式：\n$$\nL \\ge \\frac{\\log(\\varepsilon)}{\\log(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))}\n$$\n有效记忆长度 $L_\\varepsilon$ 的估计器是满足此条件的最小整数：\n$$\nL_{\\varepsilon} = \\left\\lceil \\frac{\\log(\\varepsilon)}{\\log(\\bar{d} \\cdot \\rho(\\mathbf{W}_{hh}))} \\right\\rceil\n$$\n在实现中，我们使用 $\\varepsilon = 0.05$。一个更大的 $L_\\varepsilon$ 意味着网络可以维持信息更长的时间。\n\n### 4. 失败预测和评估\n\n二进制加法任务的记忆需求由其最长进位链决定。一个输入对的“进位链长度”是真实进位输出比特 $c_t$ 为 1 的最大连续时间步数。为了使网络正确执行加法，其有效记忆长度 $L_{\\varepsilon}$ 必须至少与所需的进位链长度 $L_{\\text{carry}}$ 一样长。这给了我们一个预测规则：\n- 如果 $L_{\\varepsilon} \\ge L_{\\text{carry}}$，预测“充分”。\n- 如果 $L_{\\varepsilon}  L_{\\text{carry}}$，预测“不充分”。\n\n然后将此预测与训练后的 RNN 在测试用例上的实际性能进行比较。经验正确性是通过将测试整数的 $T=12$ 比特表示输入到网络中，将其输出 $(y_{t,s}, y_{t,c})$ 二值化以获得预测比特 $(s'_t, c'_t)$，计算预测的整数和 $S_{\\text{pred}}$，并将其与真实和 $S_{\\text{true}}$ 进行比较来确定的。\n$$\nS_{\\text{pred}} = \\sum_{t=0}^{T-1} s'_t 2^t + c'_{T-1} 2^T\n$$\n当且仅当 $S_{\\text{pred}} = S_{\\text{true}}$ 时，网络的性能被视为正确。最终输出汇总了给定测试套件的这些比较结果。",
            "answer": "```python\nimport numpy as np\nimport scipy.linalg\nimport math\n\n# Use a fixed random seed for reproducibility of training.\nnp.random.seed(42)\n\ndef solve():\n    \"\"\"\n    Main function to construct, train, and evaluate the RNN for binary addition.\n    \"\"\"\n\n    # --- Configuration ---\n    # RNN architecture\n    INPUT_DIM = 2\n    HIDDEN_DIM = 4  # A small hidden size is sufficient for this task.\n    OUTPUT_DIM = 2\n\n    # Training parameters\n    LEARNING_RATE = 0.05\n    N_EPOCHS = 3000\n    GRAD_CLIP_THRESHOLD = 1.0\n    T_TRAIN = 8  # Train on 8-bit numbers.\n\n    # Memory analysis parameters\n    RHO_MAX = 0.7\n    EPSILON = 0.05\n\n    # Testing parameters\n    T_TEST = 12 # Test on 12-bit numbers.\n\n    # --- Helper Functions ---\n    def int_to_binary_array(n, num_bits):\n        binary_str = format(n, f'0{num_bits}b')\n        return np.array([int(bit) for bit in reversed(binary_str)], dtype=np.float64)\n\n    def get_true_targets(a_bits, b_bits):\n        seq_len = len(a_bits)\n        s_bits = np.zeros(seq_len, dtype=np.float64)\n        c_bits = np.zeros(seq_len, dtype=np.float64)\n        carry_in = 0\n        for t in range(seq_len):\n            u_t = a_bits[t] + b_bits[t] + carry_in\n            s_bits[t] = u_t % 2\n            c_bits[t] = u_t // 2\n            carry_in = c_bits[t]\n        return s_bits, c_bits\n\n    class RNN:\n        \"\"\"A simple Elman Recurrent Neural Network.\"\"\"\n        def __init__(self, input_dim, hidden_dim, output_dim):\n            # Xavier/Glorot initialization for weights\n            limit_xh = np.sqrt(6.0 / (input_dim + hidden_dim))\n            limit_hh = np.sqrt(6.0 / (hidden_dim + hidden_dim))\n            limit_hy = np.sqrt(6.0 / (hidden_dim + output_dim))\n            \n            self.W_xh = np.random.uniform(-limit_xh, limit_xh, (hidden_dim, input_dim))\n            self.W_hh = np.random.uniform(-limit_hh, limit_hh, (hidden_dim, hidden_dim))\n            self.W_hy = np.random.uniform(-limit_hy, limit_hy, (output_dim, hidden_dim))\n            \n            self.b_h = np.zeros((hidden_dim, 1))\n            self.b_y = np.zeros((output_dim, 1))\n\n        def _sigmoid(self, x):\n            return 1.0 / (1.0 + np.exp(-x))\n\n        def forward(self, x_seq):\n            seq_len = x_seq.shape[0]\n            h = np.zeros((self.W_hh.shape[0], 1))\n            \n            history = {\n                'h': { -1: h }, # Store h_t values, key is time index\n                'y': [],\n                'deriv_activations': []\n            }\n            \n            for t in range(seq_len):\n                x_t = x_seq[t].reshape(-1, 1)\n                h_pre_act = self.W_xh @ x_t + self.W_hh @ h + self.b_h\n                h = np.tanh(h_pre_act)\n                o_t = self.W_hy @ h + self.b_y\n                y_t = self._sigmoid(o_t)\n                \n                history['h'][t] = h\n                history['y'].append(y_t)\n                history['deriv_activations'].append(1 - h**2)\n                \n            return history\n\n        def rescale_W_hh(self, rho_max):\n            eigenvalues = scipy.linalg.eigvals(self.W_hh)\n            rho = np.max(np.abs(eigenvalues))\n            if rho > rho_max:\n                self.W_hh *= rho_max / rho\n\n    def train_rnn(model, num_epochs, seq_len, learning_rate, clip_threshold, rho_max):\n        \"\"\"Train the RNN model using SGD and BPTT.\"\"\"\n        for epoch in range(num_epochs):\n            # Generate a random training sample\n            a_int = np.random.randint(0, 2**seq_len)\n            b_int = np.random.randint(0, 2**seq_len)\n            a_bits = int_to_binary_array(a_int, seq_len)\n            b_bits = int_to_binary_array(b_int, seq_len)\n            x_seq = np.vstack((a_bits, b_bits)).T\n            s_true, c_true = get_true_targets(a_bits, b_bits)\n            y_true_seq = np.vstack((s_true, c_true)).T\n\n            # Forward pass\n            history = model.forward(x_seq)\n            \n            # --- Backward Pass (BPTT) ---\n            dW_xh, dW_hh, dW_hy = np.zeros_like(model.W_xh), np.zeros_like(model.W_hh), np.zeros_like(model.W_hy)\n            db_h, db_y = np.zeros_like(model.b_h), np.zeros_like(model.b_y)\n            \n            delta_h_future = np.zeros_like(model.b_h)\n            \n            for t in reversed(range(seq_len)):\n                y_pred_t = history['y'][t]\n                y_true_t = y_true_seq[t].reshape(-1, 1)\n                h_t = history['h'][t]\n                h_prev = history['h'][t - 1]\n                x_t = x_seq[t].reshape(-1, 1)\n                deriv_act_t = history['deriv_activations'][t]\n\n                delta_o_t = y_pred_t - y_true_t\n                dW_hy += delta_o_t @ h_t.T\n                db_y += delta_o_t\n                \n                delta_h_from_output = model.W_hy.T @ delta_o_t\n                delta_h_total = delta_h_from_output + delta_h_future\n                \n                delta_pre_act_h = delta_h_total * deriv_act_t\n                \n                dW_hh += delta_pre_act_h @ h_prev.T\n                dW_xh += delta_pre_act_h @ x_t.T\n                db_h += delta_pre_act_h\n                \n                delta_h_future = model.W_hh.T @ delta_pre_act_h\n            \n            # Gradient clipping\n            grads = [dW_xh, dW_hh, dW_hy, db_h, db_y]\n            total_norm = np.sqrt(sum(np.sum(g**2) for g in grads))\n            if total_norm > clip_threshold:\n                for g in grads:\n                    g *= clip_threshold / total_norm\n\n            # SGD update\n            model.W_xh -= learning_rate * dW_xh\n            model.W_hh -= learning_rate * dW_hh\n            model.W_hy -= learning_rate * dW_hy\n            model.b_h -= learning_rate * db_h\n            model.b_y -= learning_rate * db_y\n            \n            # Enforce spectral radius constraint\n            model.rescale_W_hh(rho_max)\n        \n        return model\n\n    def calculate_memory_length(model, rho_max, epsilon):\n        # Estimate average activation derivative\n        num_samples = 100\n        all_deriv_activations = []\n        for _ in range(num_samples):\n            a_int = np.random.randint(0, 2**T_TRAIN)\n            b_int = np.random.randint(0, 2**T_TRAIN)\n            a_bits = int_to_binary_array(a_int, T_TRAIN)\n            b_bits = int_to_binary_array(b_int, T_TRAIN)\n            x_seq = np.vstack((a_bits, b_bits)).T\n            history = model.forward(x_seq)\n            all_deriv_activations.extend([d.flatten() for d in history['deriv_activations']])\n        \n        d_avg_scalar = np.mean(np.concatenate(all_deriv_activations))\n        \n        rho_W_hh = np.max(np.abs(scipy.linalg.eigvals(model.W_hh)))\n        \n        # Calculate L_epsilon\n        log_numerator = np.log(epsilon)\n        decay_factor = d_avg_scalar * rho_W_hh\n        \n        if decay_factor >= 1.0:\n            return float('inf')\n        if decay_factor == 0:\n            return 1\n            \n        log_denominator = np.log(decay_factor)\n        L_eps = math.ceil(log_numerator / log_denominator)\n        return L_eps\n\n    def calculate_carry_chain_length(A, B, num_bits):\n        a_bits = int_to_binary_array(A, num_bits)\n        b_bits = int_to_binary_array(B, num_bits)\n        _, c_bits = get_true_targets(a_bits, b_bits)\n        \n        max_len = 0\n        current_len = 0\n        for bit in c_bits:\n            if bit == 1:\n                current_len += 1\n            else:\n                max_len = max(max_len, current_len)\n                current_len = 0\n        max_len = max(max_len, current_len)\n        return max_len\n\n    # --- Main Execution ---\n    rnn = RNN(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n    \n    # Train the RNN\n    trained_rnn = train_rnn(rnn, N_EPOCHS, T_TRAIN, LEARNING_RATE, GRAD_CLIP_THRESHOLD, RHO_MAX)\n    \n    # Analyze the trained network's memory\n    L_epsilon = calculate_memory_length(trained_rnn, RHO_MAX, EPSILON)\n    \n    # Test Suite\n    test_cases = [\n        (25, 6),\n        (255, 1),\n        (1023, 1),\n        (0, 0),\n        (4095, 1),\n    ]\n\n    results = []\n    for A, B in test_cases:\n        # 1. Predict sufficiency based on memory length\n        L_carry = calculate_carry_chain_length(A, B, T_TEST)\n        p_sufficient = (L_epsilon >= L_carry)\n        \n        # 2. Evaluate actual performance\n        a_bits = int_to_binary_array(A, T_TEST)\n        b_bits = int_to_binary_array(B, T_TEST)\n        x_seq = np.vstack((a_bits, b_bits)).T\n        \n        history = trained_rnn.forward(x_seq)\n        \n        s_pred_bits = np.round([y[0,0] for y in history['y']])\n        c_pred_bits = np.round([y[1,0] for y in history['y']])\n        \n        S_pred = 0\n        for t in range(T_TEST):\n            S_pred += s_pred_bits[t] * (2**t)\n        # Add final carry-out\n        S_pred += c_pred_bits[T_TEST - 1] * (2**T_TEST)\n        \n        S_true = A + B\n        a_correct = (S_pred == S_true)\n        \n        results.extend([p_sufficient, a_correct])\n        \n    # Format and print the final output\n    print(f\"[{','.join(str(b).lower() for b in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "基于前一个练习对记忆极限的探索，本练习提供了一个量化框架，用于比较不同RNN架构的性能。通过将记忆衰减建模为一个随机过程，你将分析简单RNN、门控循环单元（GRU）和长短期记忆网络（LSTM）在长时间内保持信息的能力有何不同。这让你能够具体地理解为什么门控机制对于捕捉长程依赖至关重要。",
            "id": "3168420",
            "problem": "给定三种典型的循环序列模型：循环神经网络 (RNN)、门控循环单元 (GRU) 和长短期记忆 (LSTM)。考虑以下简化的、标量的、线性化的记忆通道，它表示在延迟复制/重复任务中，这些架构下单个潜藏记忆分量的演化过程。设记忆变量表示为 $m_t \\in \\mathbb{R}$，并假设它根据带独立加性噪声的一阶自回归递归进行演化，\n$$\nm_t = r \\, m_{t-1} + \\epsilon_t,\n$$\n其中 $r \\in (0,1]$ 是一个固定的保留系数，$\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立同分布的高斯扰动。初始记忆振幅 $m_0$ 是给定的。保留系数 $r$ 必须根据特定模型的门控统计数据实例化，具体如下：\n- 对于长短期记忆 (LSTM)，使用期望的遗忘门值 $r = \\mathbb{E}[f_t]$。\n- 对于门控循环单元 (GRU)，使用期望的更新门值 $r = \\mathbb{E}[z_t]$。\n- 对于循环神经网络 (RNN)，在标量线性化 $h_t = \\alpha h_{t-1} + \\epsilon_t$ 中，使用 $r = \\alpha$。\n\n在复制/重复任务中，模型读取一个长度为 $L$ 的初始二进制模式以供记忆，然后等待 $G$ 个时间步的无信息输入间隔，最后需要输出该模式重复 $R$ 次的结果。成功的定义是：在最后一次重复的最后一个符号的解码时刻，记忆变量的绝对值超过一个固定的阈值 $ \\tau  0$。根据此定义，相对于模式读入结束点的解码时间偏移量 $D$ 为\n$$\nD = G + L \\cdot R - 1,\n$$\n因此最后一个符号的解码使用 $m_D$。\n\n仅从上述递归和高斯分布的标准性质出发，推导任务成功的概率作为参数 $(r, D, m_0, \\sigma, \\tau)$ 的解析表达式，然后实现一个程序，为以下每个测试用例计算此成功概率。在所有情况下，都使用上述针对 $r$ 的特定于架构的映射，将 $r$ 视为不随时间变化且等于所提供的平均门值，并假设每个时间步都有独立的高斯噪声 $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。如果 $r=1$，请使用该递归方差的科学一致性极限。不涉及物理单位，也不涉及角度。\n\n测试套件 (每一项为 $(\\text{架构}, \\text{门平均值}, G, L, R, m_0, \\sigma, \\tau)$):\n- $(\\text{LSTM}, 0.95, 20, 5, 2, 1.0, 0.05, 0.5)$\n- $(\\text{GRU}, 0.90, 20, 5, 2, 1.0, 0.05, 0.5)$\n- $(\\text{RNN}, 0.85, 20, 5, 2, 1.0, 0.05, 0.5)$\n- $(\\text{LSTM}, 0.999, 200, 3, 3, 1.0, 0.02, 0.5)$\n- $(\\text{GRU}, 0.50, 10, 4, 1, 1.0, 0.10, 0.5)$\n- $(\\text{LSTM}, 1.00, 50, 2, 5, 1.0, 0.05, 0.5)$\n- $(\\text{GRU}, 0.95, 30, 5, 1, 1.0, 0.50, 0.5)$\n\n您的程序应生成一行输出，其中包含这七个测试用例的成功概率，顺序相同，形式为一个用方括号括起来的逗号分隔列表（例如，$[\\text{result}_1,\\text{result}_2,\\ldots,\\text{result}_7]$）。每个结果必须是标准十进制表示法（Python浮点数）的实数。",
            "solution": "该问题要求推导和计算延迟复制任务的成功概率，该任务由一个标量的、线性化的循环记忆通道建模。任务的成功由记忆变量 $m_t \\in \\mathbb{R}$ 在某个特定未来时间步的值定义。\n\n记忆变量的演化由以下一阶自回归过程描述：\n$$\nm_t = r \\, m_{t-1} + \\epsilon_t\n$$\n其中 $m_0$ 是初始记忆状态，$r \\in (0,1]$ 是保留系数，$\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$ 是独立同分布的高斯噪声项。如果在最终解码时间步 $D$，满足条件 $|m_D|  \\tau$（对于给定的阈值 $\\tau  0$），则任务成功。解码时间偏移量由 $D = G + L \\cdot R - 1$ 给出。\n\n我们的目标是找到成功概率 $P(|m_D|  \\tau)$ 的解析表达式。这需要确定随机变量 $m_D$ 的概率分布。我们首先展开递归，用初始状态 $m_0$ 和噪声扰动序列 $\\epsilon_1, \\epsilon_2, \\ldots, \\epsilon_D$ 来表示 $m_D$。\n\n从 $m_1 = r m_0 + \\epsilon_1$ 开始，我们可以写出：\n$m_2 = r m_1 + \\epsilon_2 = r(r m_0 + \\epsilon_1) + \\epsilon_2 = r^2 m_0 + r \\epsilon_1 + \\epsilon_2$。\n通过归纳法，在任何时间步 $t0$，$m_t$ 的表达式为：\n$$\nm_t = r^t m_0 + \\sum_{i=1}^{t} r^{t-i} \\epsilon_i\n$$\n对于最终时间步 $D$，我们有：\n$$\nm_D = r^D m_0 + \\sum_{i=1}^{D} r^{D-i} \\epsilon_i\n$$\n项 $r^D m_0$ 是一个常数。求和项是 $D$ 个独立高斯随机变量 $\\epsilon_i$ 的线性组合。高斯分布的一个基本性质是，高斯随机变量的任何线性组合也是一个高斯随机变量。因此，$m_D$ 服从高斯分布，$m_D \\sim \\mathcal{N}(\\mu_D, \\sigma_D^2)$。我们现在必须求出其均值 $\\mu_D$ 和方差 $\\sigma_D^2$。\n\n均值 $\\mu_D$ 是 $m_D$ 的期望：\n$$\n\\mu_D = \\mathbb{E}[m_D] = \\mathbb{E}\\left[r^D m_0 + \\sum_{i=1}^{D} r^{D-i} \\epsilon_i\\right]\n$$\n根据期望的线性性质，并且由于对所有 $i$ 都有 $\\mathbb{E}[\\epsilon_i] = 0$：\n$$\n\\mu_D = r^D m_0 + \\sum_{i=1}^{D} r^{D-i} \\mathbb{E}[\\epsilon_i] = r^D m_0 + 0\n$$\n$$\n\\mu_D = r^D m_0\n$$\n方差 $\\sigma_D^2$ 是 $m_D$ 的方差。常数项 $r^D m_0$ 不影响方差。由于噪声项 $\\epsilon_i$ 是独立的，它们的和的方差等于它们方差的和：\n$$\n\\sigma_D^2 = \\text{Var}(m_D) = \\text{Var}\\left(\\sum_{i=1}^{D} r^{D-i} \\epsilon_i\\right) = \\sum_{i=1}^{D} \\text{Var}(r^{D-i} \\epsilon_i)\n$$\n使用性质 $\\text{Var}(aX) = a^2\\text{Var}(X)$ 以及 $\\text{Var}(\\epsilon_i) = \\sigma^2$：\n$$\n\\sigma_D^2 = \\sum_{i=1}^{D} (r^{D-i})^2 \\sigma^2 = \\sigma^2 \\sum_{i=1}^{D} (r^2)^{D-i}\n$$\n这是一个等比级数。通过替换索引 $j = D-i$，求和从 $j=0$ 到 $j=D-1$：\n$$\n\\sigma_D^2 = \\sigma^2 \\sum_{j=0}^{D-1} (r^2)^j\n$$\n我们根据 $r$ 的值来计算这个和：\n情况1：$r  1$。有限等比级数的和为 $\\frac{1 - (r^2)^D}{1 - r^2}$。\n$$\n\\sigma_D^2 = \\sigma^2 \\frac{1 - r^{2D}}{1 - r^2}\n$$\n情况2：$r = 1$。等比级数的公比为 $1$。和就是项数，即 $D$。\n$$\n\\sigma_D^2 = \\sigma^2 D\n$$\n这个 $r=1$ 时的结果也可以通过洛必达法则 (L'Hôpital's rule) 求 $r1$ 的表达式在 $r \\to 1$ 时的极限得到，从而按要求确保了一致性。\n\n当 $m_D$ 的分布完全确定为 $m_D \\sim \\mathcal{N}(r^D m_0, \\sigma_D^2)$ 后，我们可以计算成功概率 $P(|m_D|  \\tau)$。这等价于 $P(m_D  \\tau \\text{ 或 } m_D  -\\tau)$。由于这些是互斥事件：\n$$\nP(\\text{success}) = P(m_D  \\tau) + P(m_D  -\\tau)\n$$\n为了计算这些概率，我们对变量 $m_D$ 进行标准化。设 $Z \\sim \\mathcal{N}(0, 1)$ 为一个标准正态变量，并设 $\\Phi(z) = P(Z \\le z)$ 为其累积分布函数 (CDF)。标准差为 $\\sigma_D = \\sqrt{\\sigma_D^2}$。\n$$\nP(m_D  -\\tau) = P\\left(\\frac{m_D - \\mu_D}{\\sigma_D}  \\frac{-\\tau - \\mu_D}{\\sigma_D}\\right) = \\Phi\\left(\\frac{-\\tau - \\mu_D}{\\sigma_D}\\right)\n$$\n$$\nP(m_D  \\tau) = 1 - P(m_D \\le \\tau) = 1 - P\\left(\\frac{m_D - \\mu_D}{\\sigma_D} \\le \\frac{\\tau - \\mu_D}{\\sigma_D}\\right) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_D}{\\sigma_D}\\right)\n$$\n利用对称性质 $\\Phi(-z) = 1 - \\Phi(z)$，我们可以重写第二项：\n$$\n1 - \\Phi\\left(\\frac{\\tau - \\mu_D}{\\sigma_D}\\right) = \\Phi\\left(-\\left(\\frac{\\tau - \\mu_D}{\\sigma_D}\\right)\\right) = \\Phi\\left(\\frac{\\mu_D - \\tau}{\\sigma_D}\\right)\n$$\n合并各项，成功概率的最终表达式为：\n$$\nP(\\text{success}) = \\Phi\\left(\\frac{\\mu_D - \\tau}{\\sigma_D}\\right) + \\Phi\\left(\\frac{-\\mu_D - \\tau}{\\sigma_D}\\right)\n$$\n我们将实现这个表达式来计算给定测试用例的结果。$\\mu_D$ 和 $\\sigma_D^2$ 的值由每个测试用例的参数确定，而累积分布函数 $\\Phi(z)$ 进行数值计算，为此可以使用误差函数 $\\text{erf}(x)$ 和恒等式 $\\Phi(z) = \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right)$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Calculates the success probability for a memory task in simplified recurrent models.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (architecture, gate_average, G, L, R, m0, sigma, tau)\n    test_cases = [\n        ('LSTM', 0.95, 20, 5, 2, 1.0, 0.05, 0.5),\n        ('GRU', 0.90, 20, 5, 2, 1.0, 0.05, 0.5),\n        ('RNN', 0.85, 20, 5, 2, 1.0, 0.05, 0.5),\n        ('LSTM', 0.999, 200, 3, 3, 1.0, 0.02, 0.5),\n        ('GRU', 0.50, 10, 4, 1, 1.0, 0.10, 0.5),\n        ('LSTM', 1.00, 50, 2, 5, 1.0, 0.05, 0.5),\n        ('GRU', 0.95, 30, 5, 1, 1.0, 0.50, 0.5)\n    ]\n\n    results = []\n\n    def standard_normal_cdf(z):\n        \"\"\"\n        Computes the standard normal CDF using the error function.\n        Phi(z) = 0.5 * (1 + erf(z / sqrt(2)))\n        \"\"\"\n        return 0.5 * (1.0 + erf(z / np.sqrt(2.0)))\n\n    for case in test_cases:\n        # Unpack parameters for the current test case\n        architecture, r, G, L, R, m0, sigma, tau = case\n\n        # Calculate the decoding time offset D\n        D = G + L * R - 1\n\n        # Calculate the mean of the memory state at time D\n        mu_D = (r**D) * m0\n\n        # Calculate the variance of the memory state at time D\n        # Handle the special case where r = 1\n        if r == 1.0:\n            # For r=1, the variance is sigma^2 * D\n            sigma_D_sq = (sigma**2) * D\n        else:\n            # For r  1, use the geometric series sum formula\n            sigma_D_sq = (sigma**2) * (1.0 - r**(2.0 * D)) / (1.0 - r**2)\n\n        # Handle the deterministic case where sigma is zero\n        if sigma_D_sq  1e-12:  # Use a small tolerance for floating point\n            prob = 1.0 if np.abs(mu_D) > tau else 0.0\n        else:\n            # Calculate the standard deviation\n            sigma_D = np.sqrt(sigma_D_sq)\n\n            # Standardize the thresholds\n            z1 = (mu_D - tau) / sigma_D\n            z2 = (-mu_D - tau) / sigma_D\n            \n            # Calculate the success probability using the CDF\n            # P(success) = P(m_D > tau) + P(m_D  -tau)\n            # which is Phi((mu_D - tau) / sigma_D) + Phi((-mu_D - tau) / sigma_D)\n            prob = standard_normal_cdf(z1) + standard_normal_cdf(z2)\n        \n        results.append(prob)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}