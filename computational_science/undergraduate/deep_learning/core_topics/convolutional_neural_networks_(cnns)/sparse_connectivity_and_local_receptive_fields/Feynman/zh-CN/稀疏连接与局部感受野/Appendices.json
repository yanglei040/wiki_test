{
    "hands_on_practices": [
        {
            "introduction": "深入理解卷积神经网络（CNN）的第一步是掌握感受域的概念。本练习将引导你从基本定义出发，推导出一个通用公式，用于计算多层CNN中神经元的感受域大小，帮助你量化网络参数（如核大小、步长和扩张率）如何共同决定网络捕捉信息范围的能力。",
            "id": "3175390",
            "problem": "一个一维卷积神经网络由 $L$ 个相同层的堆叠构成，每一层都是一个离散、线性、移位不变的卷积，其卷积核大小为 $k$，步长为 $s$，扩张率为 $d$，无填充、无池化。考虑带扩张和步长的离散卷积的标准定义：第 $\\ell$ 层输出位置 $n$ 的激活前值是作用于以扩张率 $d$ 间隔的输入上的 $k$ 个权重的有限和，并且在前一层的输入索引中，连续的输出以步长 $s$ 间隔。顶层单个输出位置的局部感受野是指能够影响它的原始输入层中不同输入位置的数量。稀疏连接意味着这个数量是有限的，并且不随输入长度的增加而增加。\n\n仅从这些基本定义出发，不使用任何预先记下的公式，推导出一个在深度为 $L$ 时的感受野大小 $R_L$ 关于 $k$、$s$、$d$ 和 $L$ 的通用封闭形式表达式，假设所有层共享相同的 $(k,s,d)$ 且任何地方都不使用填充。然后，通过计算一个具有 $k=3$、$s=2$、$d=2$ 和 $L=4$ 的人工构建网络的感受野大小来验证你的表达式。\n\n以单个整数形式提供最终答案，该整数等于指定的人工网络的感受野大小。不需要单位，也不需要四舍五入。",
            "solution": "该问题要求推导一维卷积神经网络感受野大小的通用封闭形式表达式，然后针对一个具体案例进行计算。推导过程必须从基本定义出发。\n\n设网络的层从 $\\ell=1$ 到 $\\ell=L$ 进行索引。输入数据被指定为第 $\\ell=0$ 层。我们将第 $\\ell$ 层单个神经元的感受野大小（记为 $R_\\ell$）定义为第 $0$ 层中能够影响其激活前值的不同输入位置的数量。这 $L$ 个层中的每一层都是相同的，其特征是卷积核大小为 $k$，步长为 $s$，扩张率为 $d$。\n\n为了推导 $R_L$ 的通用表达式，我们首先建立一个递推关系。考虑第 $\\ell$ 层中的一个神经元。它的值由第 $\\ell-1$ 层的 $k$ 个输入计算得出。由于扩张率 $d$，这些输入在第 $\\ell-1$ 层的特征图上并不处于相邻位置。如果第一个输入在位置 $j$，则后续的输入位于位置 $j+d, j+2d, \\dots, j+(k-1)d$。第 $\\ell$ 层神经元的总感受野是来自第 $\\ell-1$ 层的这 $k$ 个输入神经元感受野的并集。\n\n要确定这个并集的大小，我们必须理解第 $\\ell-1$ 层的感受野在原始输入空间（第 $0$ 层）中是如何相互定位的。设 $J_{\\ell-1}$ 表示到第 $\\ell-1$ 层的累积步长。$J_{\\ell-1}$ 是第 $\\ell-1$ 层中两个相邻神经元的感受野起始点在第 $0$ 层输入空间中的距离。累积步长可以递归定义。由于所有层具有相同的步长 $s$，第 $\\ell$ 层的累积步长为：\n$$J_\\ell = s \\cdot J_{\\ell-1}$$\n以 $J_0 = 1$ 为基例（因为第 $0$ 层的相邻输入神经元相距一个位置），这个递推关系的解是一个等比数列：\n$$J_\\ell = s^\\ell$$\n\n现在，我们来分析第 $\\ell$ 层神经元的 $k$ 个输入的跨度。这些输入在第 $\\ell-1$ 层的特征图上位于相对位置 $0, d, 2d, \\dots, (k-1)d$。第一个输入（相对位置 $0$）和最后一个输入（相对位置 $(k-1)d$）在第 $\\ell-1$ 层的坐标系中相隔 $(k-1)d$ 的距离。在原始输入空间中的相应位移是这个间隔与到第 $\\ell-1$ 层的累积步长的乘积：\n$$\\text{输入空间中的位移} = ((j+(k-1)d) - j) \\times J_{\\ell-1} = (k-1)d \\cdot J_{\\ell-1}$$\n第 $\\ell$ 层的总感受野大小 $R_\\ell$ 是其在第 $\\ell-1$ 层的一个组成神经元的感受野大小（即 $R_{\\ell-1}$）加上其他输入神经元感受野移动所覆盖的额外跨度。这个额外的跨度等于上面计算出的位移。这给出了感受野大小的以下递推关系：\n$$R_\\ell = R_{\\ell-1} + (k-1)d \\cdot J_{\\ell-1}$$\n代入累积步长的表达式 $J_{\\ell-1} = s^{\\ell-1}$，我们得到：\n$$R_\\ell = R_{\\ell-1} + (k-1)d \\cdot s^{\\ell-1}$$\n这个递推关系的基本情况是输入层（第 $0$ 层）中一个神经元的感受野，也就是神经元本身。因此，$R_0 = 1$。我们可以通过裂项求和来求解 $R_L$ 的递推关系：\n$$R_L = R_0 + \\sum_{\\ell=1}^{L} (R_\\ell - R_{\\ell-1})$$\n代入递推关系和基本情况 $R_0=1$：\n$$R_L = 1 + \\sum_{\\ell=1}^{L} (k-1)d \\cdot s^{\\ell-1}$$\n我们可以将求和索引更改为 $i = \\ell-1$，其范围从 $0$ 到 $L-1$：\n$$R_L = 1 + \\sum_{i=0}^{L-1} (k-1)d \\cdot s^i$$\n项 $(k-1)d$ 相对于求和索引是常数，因此可以提取出来：\n$$R_L = 1 + (k-1)d \\sum_{i=0}^{L-1} s^i$$\n该和是一个有限等比数列，它有一个众所周知的封闭形式，取决于 $s$ 的值。\n\n情况1：$s \\neq 1$。\n等比数列的和为 $\\sum_{i=0}^{L-1} s^i = \\frac{s^L - 1}{s-1}$。\n因此，感受野大小为：\n$$R_L = 1 + (k-1)d \\left(\\frac{s^L - 1}{s-1}\\right)$$\n\n情况2：$s = 1$。\n和变为 $\\sum_{i=0}^{L-1} 1^i = L$。\n因此，感受野大小为：\n$$R_L = 1 + (k-1)d \\cdot L$$\n至此，通用封闭形式表达式的推导完成。\n\n问题的第二部分是计算具有以下参数的人工网络的感受野大小：\n- 层数：$L=4$\n- 卷积核大小：$k=3$\n- 步长：$s=2$\n- 扩张率：$d=2$\n\n由于 $s=2 \\neq 1$，我们使用情况1的公式：\n$$R_L = 1 + (k-1)d \\left(\\frac{s^L - 1}{s-1}\\right)$$\n代入给定的数值：\n$$R_4 = 1 + (3-1) \\cdot 2 \\cdot \\left(\\frac{2^4 - 1}{2-1}\\right)$$\n$$R_4 = 1 + 2 \\cdot 2 \\cdot \\left(\\frac{16 - 1}{1}\\right)$$\n$$R_4 = 1 + 4 \\cdot (15)$$\n$$R_4 = 1 + 60$$\n$$R_4 = 61$$\n指定的人工网络的感受野大小为 $61$。",
            "answer": "$$\\boxed{61}$$"
        },
        {
            "introduction": "理论计算之后，让我们将感受域的概念应用于一个实际问题：在噪声中检测边缘。这个练习模拟了一个典型的信号处理场景，要求你确定保证可靠检测所需的最小感受域大小，从而直观地展示了感受域大小在平衡信号增强与噪声抑制之间的关键作用。",
            "id": "3175463",
            "problem": "考虑一个二值图像中的水平扫描线的一维抽象，该扫描线包含一个单一的垂直边缘。干净信号由边缘左侧的恒定强度 $I_{\\ell}$ 和边缘右侧的恒定强度 $I_{r}$ 组成，形成一个对比度为 $\\Delta = |I_{\\ell} - I_{r}|$ 的理想阶跃。观测信号在每个像素处被独立的加性高斯噪声所破坏，该噪声均值为零，方差为 $\\sigma^{2}$。\n\n一个大小为 $R$（$R$ 为偶数）的局部感受野定义了一个稀疏连接模式，该模式仅使用以给定扫描位置为中心的 $R$ 个连续样本。考虑在此感受野上运行的以下线性检测器：感受野左半部分的权重均为 $+\\frac{1}{R/2}$，右半部分的权重均为 $-\\frac{1}{R/2}$。在给定位置，检测器的输出是感受野中 $R$ 个观测样本的加权和。假设扫描步长为 $1$，因此存在一个位置，使得感受野正好在真实边缘上居中。在检测器输出的绝对值上定义一个固定的决策阈值 $\\tau \\ge 0$，并定义一个所需可靠性 $q \\in (0,1)$，理解为十进制小数。\n\n鲁棒检测定义为：当感受野在真实边缘上居中时，检测器输出的幅值超过 $\\tau$ 的概率至少为 $q$。假设边缘离信号边界足够远，使得对齐的感受野完全包含在长度为 $N$ 的信号内；特别地，感受野大小受限于 $2 \\le R \\le N$。\n\n从线性滤波、局部感受野和独立高斯噪声在线性变换下的性质等基本定义出发，推导一种方法，用于在给定 $(N, I_{\\ell}, I_{r}, \\sigma, \\tau, q)$ 的情况下，确定保证上述意义上鲁棒检测的最小偶数 $R$。如果在约束 $R \\le N$ 下不存在这样的 $R$，则返回整数 $-1$ 以报告不可能。\n\n您的程序必须实现此推导，为以下测试套件中的每个参数集计算最小的 $R$。每个参数集被指定为一个有序元组 $(N, I_{\\ell}, I_{r}, \\sigma, \\tau, q)$：\n\n- 测试用例 1：$(N = 128, I_{\\ell} = 0.0, I_{r} = 1.0, \\sigma = 0.2, \\tau = 0.5, q = 0.95)$。\n- 测试用例 2：$(N = 128, I_{\\ell} = 0.0, I_{r} = 0.6, \\sigma = 0.3, \\tau = 0.25, q = 0.90)$。\n- 测试用例 3：$(N = 256, I_{\\ell} = 0.0, I_{r} = 0.4, \\sigma = 0.1, \\tau = 0.5, q = 0.90)$。\n- 测试用例 4：$(N = 64, I_{\\ell} = 0.0, I_{r} = 1.0, \\sigma = 0.0, \\tau = 0.7, q = 0.99)$。\n- 测试用例 5：$(N = 4, I_{\\ell} = 0.0, I_{r} = 0.6, \\sigma = 0.3, \\tau = 0.25, q = 0.90)$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的整数列表形式的结果，顺序与测试用例相同（例如，$[R_{1},R_{2},R_{3},R_{4},R_{5}]$）。不允许有其他输出。此问题中不出现角度，输出中也不需要物理单位。所有概率都必须作为十进制小数处理和表示，而不是百分比。",
            "solution": "在尝试求解之前，对问题陈述的有效性进行严格评估。\n\n### 步骤1：提取已知条件\n- **信号模型**：考虑来自二值图像的一维扫描线。\n- **干净信号**：一个理想的阶跃函数，边缘左侧强度恒为 $I_{\\ell}$，右侧强度恒为 $I_{r}$。\n- **对比度**：$\\Delta = |I_{\\ell} - I_{r}|$。\n- **噪声模型**：每个像素上存在均值为 $0$、方差为 $\\sigma^2$ 的独立加性高斯噪声。\n- **检测器**：一个大小为 $R$ 的局部感受野，其中 $R$ 是一个偶数。该检测器是一个带权重的线性滤波器。\n- **检测器权重**：感受野左半部分 $R/2$ 个样本的权重为 $+\\frac{1}{R/2}$，右半部分 $R/2$ 个样本的权重为 $-\\frac{1}{R/2}$。\n- **检测器输出**：输出是感受野中 $R$ 个观测样本的加权和。\n- **扫描与对齐**：使用步长为 $1$。考虑一个特定位置，在该位置感受野完美地在真实边缘上居中。\n- **决策规则**：对检测器输出的绝对值应用一个固定的决策阈值 $\\tau \\ge 0$。\n- **可靠性要求**：必须达到一个概率 $q \\in (0,1)$，使得检测器输出的幅值超过 $\\tau$。\n- **鲁棒检测**：当感受野在边缘上居中时，条件 $P(\\text{检测器输出幅值} > \\tau) \\ge q$ 必须成立。\n- **约束条件**：$2 \\le R \\le N$，其中 $N$ 是信号长度。假设感受野完全包含在信号内。\n- **目标**：对于给定的参数集 $(N, I_{\\ell}, I_{r}, \\sigma, \\tau, q)$，找到满足鲁棒检测标准的最小偶数 $R$。\n- **不可能性**：如果在约束 $R \\le N$ 内不存在这样的 $R$，结果应为 $-1$。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据**：该问题在信号处理、统计学和机器学习的基本原理方面有充分的依据。它模拟了一个在加性高斯白噪声（AWGN）下的经典边缘检测场景，使用了线性滤波器（一个简化的类哈尔特征检测器）和统计决策理论。这些概念都是标准的、科学上合理的。\n- **适定性**：该问题是适定的。它要求在明确定义的不等式和边界约束（$R$ 是一个偶数，$2 \\le R \\le N$）下，最小化一个整型变量 $R$。可以确定唯一最小解的存在性（或可证明其不存在）。\n- **客观性**：问题以精确、客观和数学化的语言陈述。主观术语被赋予了正式定义（例如，“鲁棒检测”）。\n\n该问题没有表现出任何诸如科学上不合理、模糊、矛盾或依赖非标准、非科学主张等缺陷。所有参数均已提供，目标也已明确指定。\n\n### 步骤3：结论与行动\n该问题是**有效的**。将推导一个有原则的解决方案。\n\n### 解题推导\n\n设大小为 $R$ 的感受野在边缘上居中。观测样本为 $s_i = \\mu_i + \\eta_i$，其中 $i=1, \\dots, R$，$\\mu_i$ 是干净信号的强度，$\\eta_i$ 是来自高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 的独立同分布（i.i.d.）随机变量。\n\n当感受野居中时，干净信号的值为：左半部分 ($i=1, \\dots, R/2$) $\\mu_i = I_{\\ell}$，右半部分 ($i=R/2+1, \\dots, R$) $\\mu_i = I_{r}$。\n\n检测器是一个具有权重 $w_i$ 的线性滤波器：\n$$\nw_i = \\begin{cases}\n+ \\frac{1}{R/2}  \\text{for } i = 1, \\dots, R/2 \\\\\n- \\frac{1}{R/2}  \\text{for } i = R/2+1, \\dots, R\n\\end{cases}\n$$\n检测器输出 $D$ 是一个由加权和给出的随机变量：\n$$\nD = \\sum_{i=1}^{R} w_i s_i = \\frac{1}{R/2} \\sum_{i=1}^{R/2} s_i - \\frac{1}{R/2} \\sum_{i=R/2+1}^{R} s_i\n$$\n\n我们确定 $D$ 的统计特性。由于 $D$ 是独立高斯随机变量的线性组合，$D$ 本身也服从高斯分布。我们需要求出其均值 $\\mu_D$ 和方差 $\\sigma_D^2$。\n\n检测器输出的均值（期望值）是：\n$$\n\\mu_D = E[D] = E\\left[\\sum_{i=1}^{R} w_i (\\mu_i + \\eta_i)\\right] = \\sum_{i=1}^{R} w_i \\mu_i + \\sum_{i=1}^{R} w_i E[\\eta_i]\n$$\n由于 $E[\\eta_i] = 0$，第二项消失。\n$$\n\\mu_D = \\sum_{i=1}^{R/2} \\left(+\\frac{1}{R/2}\\right) I_{\\ell} + \\sum_{i=R/2+1}^{R} \\left(-\\frac{1}{R/2}\\right) I_{r}\n$$\n$$\n\\mu_D = \\frac{R/2}{R/2} I_{\\ell} - \\frac{R/2}{R/2} I_{r} = I_{\\ell} - I_{r}\n$$\n\n检测器输出的方差是：\n$$\n\\sigma_D^2 = \\text{Var}(D) = \\text{Var}\\left(\\sum_{i=1}^{R} w_i (\\mu_i + \\eta_i)\\right) = \\text{Var}\\left(\\sum_{i=1}^{R} w_i \\eta_i\\right)\n$$\n由于噪声样本 $\\eta_i$ 是独立的，和的方差等于方差的和：\n$$\n\\sigma_D^2 = \\sum_{i=1}^{R} w_i^2 \\text{Var}(\\eta_i) = \\sum_{i=1}^{R} w_i^2 \\sigma^2\n$$\n$$\n\\sigma_D^2 = \\sigma^2 \\left( \\sum_{i=1}^{R/2} \\left(\\frac{1}{R/2}\\right)^2 + \\sum_{i=R/2+1}^{R} \\left(-\\frac{1}{R/2}\\right)^2 \\right)\n$$\n$$\n\\sigma_D^2 = \\sigma^2 \\left( (R/2) \\frac{1}{(R/2)^2} + (R/2) \\frac{1}{(R/2)^2} \\right) = \\sigma^2 \\left( \\frac{1}{R/2} + \\frac{1}{R/2} \\right) = \\frac{2\\sigma^2}{R/2} = \\frac{4\\sigma^2}{R}\n$$\n输出的标准差是 $\\sigma_D = \\sqrt{4\\sigma^2/R} = \\frac{2\\sigma}{\\sqrt{R}}$。\n\n因此，检测器输出是一个高斯随机变量 $D \\sim \\mathcal{N}\\left(I_{\\ell} - I_{r}, \\frac{4\\sigma^2}{R}\\right)$。\n\n鲁棒检测条件是 $P(|D| > \\tau) \\ge q$。这可以写成 $P(D > \\tau) + P(D  -\\tau) \\ge q$。\n令 $Z = \\frac{D-\\mu_D}{\\sigma_D}$ 为一个标准正态变量，$Z \\sim \\mathcal{N}(0,1)$。\n该条件变为：\n$$\nP\\left(Z  \\frac{\\tau - \\mu_D}{\\sigma_D}\\right) + P\\left(Z  \\frac{-\\tau - \\mu_D}{\\sigma_D}\\right) \\ge q\n$$\n令 $\\Phi(x)$ 为标准正态分布的累积分布函数（CDF）。该不等式为：\n$$\n\\left(1 - \\Phi\\left(\\frac{\\tau - \\mu_D}{\\sigma_D}\\right)\\right) + \\Phi\\left(\\frac{-\\tau - \\mu_D}{\\sigma_D}\\right) \\ge q\n$$\n令 $\\Delta = |I_{\\ell} - I_{r}|$。那么 $\\mu_D = \\pm \\Delta$。概率表达式关于 $\\mu_D$ 的符号是对称的。如果我们假设 $\\mu_D=\\Delta$，利用性质 $\\Phi(-x) = 1-\\Phi(x)$，表达式可简化为 $\\Phi\\left(-\\frac{\\tau-\\Delta}{\\sigma_D}\\right) + \\Phi\\left(\\frac{-\\tau-\\Delta}{\\sigma_D}\\right)$，对于 $\\mu_D=-\\Delta$ 也同样成立。我们可以将其写作 $\\Phi\\left(\\frac{\\Delta-\\tau}{\\sigma_D}\\right) + \\Phi\\left(\\frac{-\\Delta-\\tau}{\\sigma_D}\\right)$。\n代入 $\\sigma_D = \\frac{2\\sigma}{\\sqrt{R}}$：\n$$\nP(R) = \\Phi\\left(\\frac{(\\Delta - \\tau)\\sqrt{R}}{2\\sigma}\\right) + \\Phi\\left(\\frac{(-\\Delta - \\tau)\\sqrt{R}}{2\\sigma}\\right) \\ge q\n$$\n我们需要找到满足此不等式的最小偶数 $R \\in [2, N]$。\n\n我们分析概率函数 $P(R)$ 相对于 $R$ 的行为。\n1.  **情况 $\\sigma = 0$**：检测器输出是确定性的：$D = \\mu_D$。那么 $|D| = \\Delta$。如果 $\\Delta  \\tau$，概率 $P(|D|  \\tau)$ 为 $1$；如果 $\\Delta \\le \\tau$，概率为 $0$。如果 $\\Delta  \\tau$，任何 $R$ 都满足条件，因此最小偶数 $R$ 是 $2$。如果 $\\Delta \\le \\tau$，没有 $R$ 满足条件，所以答案是 $-1$。\n2.  **情况 $\\sigma  0$ 且 $\\Delta  \\tau$**：随着 $R$ 增加，$\\sigma_D$ 减小。$D$ 的分布变得更加集中在其均值 $\\mu_D$ 周围。由于 $|\\mu_D|=\\Delta  \\tau$，均值位于区间 $[-\\tau, \\tau]$ 之外。因此，将概率质量集中在 $\\mu_D$ 周围会增加落在 $[-\\tau, \\tau]$ 之外的概率。所以，$P(R)$ 是 $R$ 的单调递增函数。我们可以从 $R=2$ 开始，以 $2$ 为步长递增，直到满足条件或 $R  N$，从而找到最小的 $R$。\n3.  **情况 $\\sigma  0$ 且 $\\Delta \\le \\tau$**：随着 $R$ 增加，$\\sigma_D$ 减小。由于 $|\\mu_D|=\\Delta \\le \\tau$，均值位于区间 $[-\\tau, \\tau]$ 内部或边界上。将概率质量集中在 $\\mu_D$ 周围会增加落在 $[-\\tau, \\tau]$ 内部的概率，从而减小 $P(|D|  \\tau)$。因此，$P(R)$ 是 $R$ 的非增函数。如果对于最小可能的 $R$（即 $R=2$）不满足条件 $P(R) \\ge q$，那么对于任何更大的 $R$ 也不会满足。因此，我们只需要检查 $R=2$。如果通过，答案是 $2$；否则是 $-1$。\n\n算法如下：\n对于每个参数集 $(N, I_{\\ell}, I_{r}, \\sigma, \\tau, q)$：\n1.  计算 $\\Delta = |I_{\\ell} - I_{r}|$。\n2.  如果 $\\sigma = 0$：若 $\\Delta  \\tau$ 则返回 $2$，否则返回 $-1$。\n3.  如果 $\\sigma  0$ 且 $\\Delta  \\tau$：从 $2$ 到 $N$ 遍历偶数 $R$。对于每个 $R$，计算 $P(R)$。第一个使 $P(R) \\ge q$ 成立的 $R$ 就是答案。如果循环完成仍未找到这样的 $R$，则返回 $-1$。\n4.  如果 $\\sigma  0$ 且 $\\Delta \\le \\tau$：计算 $P(2)$。如果 $P(2) \\ge q$，则返回 $2$。否则，返回 $-1$。\n\n标准正态累积分布函数 $\\Phi(x)$ 可以使用误差函数 $\\text{erf}(x)$ 计算，公式为 $\\Phi(x) = \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Solves for the minimal receptive field size R for robust edge detection.\n    \"\"\"\n\n    # Test cases as specified in the problem statement.\n    # Each case is an ordered tuple (N, I_l, I_r, sigma, tau, q).\n    test_cases = [\n        (128, 0.0, 1.0, 0.2, 0.5, 0.95),  # Test case 1\n        (128, 0.0, 0.6, 0.3, 0.25, 0.90), # Test case 2\n        (256, 0.0, 0.4, 0.1, 0.5, 0.90), # Test case 3\n        (64, 0.0, 1.0, 0.0, 0.7, 0.99), # Test case 4\n        (4, 0.0, 0.6, 0.3, 0.25, 0.90),   # Test case 5\n    ]\n\n    results = []\n\n    def norm_cdf(x):\n        \"\"\"\n        Computes the standard normal cumulative distribution function (CDF).\n        \"\"\"\n        return 0.5 * (1.0 + erf(x / np.sqrt(2.0)))\n\n    def calculate_prob(R, delta, sigma, tau):\n        \"\"\"\n        Calculates the probability P(|D|  tau) for a given R.\n        \"\"\"\n        if sigma == 0:\n            return 1.0 if delta  tau else 0.0\n        \n        # Using the simplified expression P = Phi(-arg1) + Phi(arg2)\n        # where arg1 = (tau-delta)*sqrt(R)/(2*sigma) and arg2 = (-tau-delta)*sqrt(R)/(2*sigma)\n        # this is equivalent to P = Phi((delta-tau)*sqrt(R)/(2*sigma)) + Phi((-delta-tau)*sqrt(R)/(2*sigma))\n        \n        sqrt_R = np.sqrt(R)\n        denominator = 2.0 * sigma\n\n        arg1 = (delta - tau) * sqrt_R / denominator\n        arg2 = (-delta - tau) * sqrt_R / denominator\n        \n        return norm_cdf(arg1) + norm_cdf(arg2)\n\n    for case in test_cases:\n        N, I_l, I_r, sigma, tau, q = case\n        \n        delta = abs(I_l - I_r)\n        \n        found_R = -1\n\n        # Handle the special case of zero noise\n        if sigma == 0.0:\n            if delta  tau:\n                found_R = 2\n            else:\n                found_R = -1\n        # Case where probability increases with R\n        elif delta  tau:\n            # Iterate through even integers for R from 2 to N\n            for R in range(2, N + 1, 2):\n                prob = calculate_prob(R, delta, sigma, tau)\n                if prob = q:\n                    found_R = R\n                    break\n        # Case where probability decreases with R\n        else: # delta = tau\n            # Only need to check the smallest R\n            R = 2\n            prob = calculate_prob(R, delta, sigma, tau)\n            if prob = q:\n                found_R = R\n            else:\n                found_R = -1\n\n        results.append(found_R)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在实际应用中，局部感受域的一个必然结果是边界效应。当卷积核在输入数据的边缘操作时，需要一种策略来“填充”缺失的邻近信息。本练习通过量化不同填充策略（零填充、反射填充、循环填充）在信号边界处引入的伪影，让你深刻理解选择合适填充方法的重要性。",
            "id": "3175412",
            "problem": "考虑一个长度为 $n$ 的一维离散输入信号，表示为 $x[0], x[1], \\ldots, x[n-1]$。卷积神经网络（CNN）中的单层卷积单元通过将每个输出单元 $y[i]$ 仅连接到以 $i$ 为中心的输入的局部邻域来建立稀疏连接（Sparse Connectivity）和局部感受野（Local Receptive Fields）。设卷积核的长度为奇数 $m$，权重为 $w[0], w[1], \\ldots, w[m-1]$，并定义感受野半径 $r = \\lfloor m/2 \\rfloor$。在位置 $i$ 处的局部计算（使用深度学习中常见的互相关约定）为\n$$\ny[i] = \\sum_{k=0}^{m-1} w[k] \\, \\tilde{x}[i + k - r],\n$$\n其中 $\\tilde{x}[\\cdot]$ 表示对 $x[\\cdot]$ 超出边界的扩展，以支持那些使得核窗口索引超出 $[0, n-1]$ 范围的位置 $i$。\n\n我们研究由不同填充策略引起的边界效应，这些策略对任何整数索引 $j$ 定义如下：\n\n- 零填充（Zero padding）：\n$$\n\\tilde{x}[j] = \n\\begin{cases}\nx[j],  \\text{若 } 0 \\le j \\le n-1, \\\\\n0,  \\text{其他情况}。\n\\end{cases}\n$$\n\n- 反射填充（Reflection padding）（关于边界对称反射，复制边界值）：\n$$\n\\tilde{x}[j] = \n\\begin{cases}\nx[j],  \\text{若 } 0 \\le j \\le n-1, \\\\\nx[-j-1],  \\text{若 } j  0, \\\\\nx[2n - 1 - j],  \\text{若 } j \\ge n.\n\\end{cases}\n$$\n\n- 循环填充（Circular padding）（周期性扩展）：\n$$\n\\tilde{x}[j] = x[j \\bmod n].\n$$\n\n对于每个测试用例，我们将为生成观测到的有限片段的潜在无限信号指定一个基准（ground-truth）扩展规则。“真实输出” $y_{\\text{true}}[i]$ 的定义是：对所有 $i \\in \\{0, 1, \\ldots, n-1\\}$，使用基准扩展规则应用上述局部感受野计算得到。\n\n定义边界索引集\n$$\nB = \\{ i \\in \\{0, 1, \\ldots, n-1\\} \\mid i  r \\text{ 或 } i \\ge n - r \\}.\n$$\n也就是说，$B$ 包含其感受野与边界重叠的输出位置。对于一个填充策略 $P \\in \\{\\text{zero}, \\text{reflection}, \\text{circular}\\}$，将伪影分数（artifact score）定义为边界上的均方误差，\n$$\nA(P) = \\frac{1}{|B|} \\sum_{i \\in B} \\left( y_{P}[i] - y_{\\text{true}}[i] \\right)^2,\n$$\n其中 $y_{P}[i]$ 是使用填充策略 $P$ 计算的输出。该分数是无量纲的。\n\n对所有测试用例使用以下固定核：\n$$\nm = 5, \\quad r = 2, \\quad w = \\frac{1}{16}[1, 4, 6, 4, 1].\n$$\n\n三角函数中使用的角度必须是弧度。\n\n测试套件（每个测试用例由 $(n, x, \\text{ground truth})$ 完全指定）：\n- 用例 1（紧凑脉冲，基准为零扩展）：\n  - $n = 16$，\n  - 若 $i \\in \\{6, 7, 8, 9\\}$，则 $x[i] = 1$，否则 $x[i] = 0$，\n  - 基准扩展规则：零填充。\n- 用例 2（线性斜坡，基准为对称反射）：\n  - $n = 15$，\n  - 对于 $i \\in \\{0, 1, \\ldots, 14\\}$，$x[i] = i$，\n  - 基准扩展规则：反射填充。\n- 用例 3（离散余弦，基准为循环/周期性；余弦参数以弧度为单位）：\n  - $n = 32$，\n  - 对于 $i \\in \\{0, 1, \\ldots, 31\\}$，$x[i] = \\cos\\!\\left(\\frac{2\\pi i}{n}\\right)$，\n  - 基准扩展规则：循环填充。\n- 用例 4（小型边界情况，基准为零扩展）：\n  - $n = 3$，\n  - $x = [0, 2, 0]$，\n  - 基准扩展规则：零填充。\n\n您的程序必须为每个测试用例和每种填充策略 $P \\in \\{\\text{zero}, \\text{reflection}, \\text{circular}\\}$ 计算如上定义的伪影分数 $A(P)$。最终输出必须是单行，包含一个列表的列表，其中每个内部列表按给定顺序对应一个测试用例，并按 $[A(\\text{zero}), A(\\text{reflection}), A(\\text{circular})]$ 的顺序包含三个浮点数。\n\n最终输出格式：\n- 形式为\n$$\n[[a_{1,\\text{zero}}, a_{1,\\text{reflection}}, a_{1,\\text{circular}}], [a_{2,\\text{zero}}, a_{2,\\text{reflection}}, a_{2,\\text{circular}}], [a_{3,\\text{zero}}, a_{3,\\text{reflection}}, a_{3,\\text{circular}}], [a_{4,\\text{zero}}, a_{4,\\text{reflection}}, a_{4,\\text{circular}}]]\n$$\n的单行字符串，其中每个 $a_{\\cdot,\\cdot}$ 均为原始十进制表示。",
            "solution": "该问题要求针对四个测试用例，为三种不同的填充策略 $P \\in \\{\\text{zero}, \\text{reflection}, \\text{circular}\\}$ 计算伪影分数 $A(P)$。每个测试用例提供一个长度为 $n$ 的一维信号 $x$，并指定一个基准扩展规则，该规则定义了 $x$ 被假定为其片段来源的潜在无限信号。伪影分数用于量化给定填充策略在信号边界处引入的误差。\n\n方法步骤如下：\n\n1.  **遍历测试用例**：整体算法顺序处理四个测试用例中的每一个。对于每个用例，提取输入信号 $x$、其长度 $n$ 以及基准填充规则。卷积核 $w = \\frac{1}{16}[1, 4, 6, 4, 1]$ 及其对应的感受野半径 $r = 2$ 对所有用例保持不变。\n\n2.  **实现填充函数**：计算的核心依赖于根据给定的填充规则将有限信号 $x$ 扩展为一个有效的无限信号 $\\tilde{x}$。必须根据提供的数学定义实现三个函数，以检索任何整数索引 $j$ 处的值 $\\tilde{x}[j]$：\n    -   **零填充**：如果 $0 \\le j \\le n-1$ 则返回 $x[j]$，否则返回 $0$。\n    -   **反射填充**：对于 $0 \\le j \\le n-1$ 返回 $x[j]$，对于 $j  0$ 返回 $x[-j-1]$，对于 $j \\ge n$ 返回 $x[2n-1-j]$。\n    -   **循环填充**：返回 $x[j \\bmod n]$。\n\n3.  **实现卷积**：设计一个函数来执行指定的一维互相关：\n    $$y[i] = \\sum_{k=0}^{m-1} w[k] \\, \\tilde{x}[i + k - r]$$\n    此函数将信号 $x$ 和一个填充规则作为输入，并计算长度为 $n$ 的输出信号 $y$。\n\n4.  **计算基准输出和填充后输出**：对于每个测试用例：\n    -   通过使用指定的基准填充规则应用卷积函数，计算出基准输出 $y_{\\text{true}}$。\n    -   通过使用各自的填充规则应用卷积函数，计算出待评估的三种填充策略的输出 $y_{\\text{zero}}$、$y_{\\text{reflection}}$ 和 $y_{\\text{circular}}$。\n\n5.  **计算伪影分数**：为每个填充策略 $P$ 计算伪影分数 $A(P)$。\n    -   首先，确定受边界影响的输出索引集 $B = \\{ i \\in \\{0, 1, \\ldots, n-1\\} \\mid i  r \\text{ or } i \\ge n - r \\}$。确定其基数 $|B|$。当 $n > 2r$ 时， $|B|=2r$；否则， $|B|=n$。\n    -   该分数是填充后输出 $y_P$ 与基准输出 $y_{\\text{true}}$ 之间的均方误差，仅在集合 $B$ 中的索引上计算：\n    $$A(P) = \\frac{1}{|B|} \\sum_{i \\in B} \\left( y_{P}[i] - y_{\\text{true}}[i] \\right)^2$$\n    如果所选的填充策略 $P$ 与基准规则匹配，则误差预期为 $0$，因此 $A(P) = 0$。\n\n6.  **汇总和格式化结果**：收集每个测试用例计算出的分数 $[A(\\text{zero}), A(\\text{reflection}), A(\\text{circular})]$。最终输出是所有四个用例结果的汇总，并按要求格式化为单个列表的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating artifact scores for various padding strategies.\n    \"\"\"\n    \n    # Define fixed kernel parameters\n    m = 5\n    r = 2\n    w = np.array([1, 4, 6, 4, 1]) / 16.0\n    \n    # Define test cases from the problem statement\n    test_cases = [\n        # Case 1: Compact pulse, ground truth zero\n        {\n            \"n\": 16,\n            \"x\": np.array([1.0 if 6 = i = 9 else 0.0 for i in range(16)]),\n            \"ground_truth\": \"zero\"\n        },\n        # Case 2: Linear ramp, ground truth reflection\n        {\n            \"n\": 15,\n            \"x\": np.arange(15, dtype=float),\n            \"ground_truth\": \"reflection\"\n        },\n        # Case 3: Discrete cosine, ground truth circular\n        {\n            \"n\": 32,\n            \"x\": np.cos(2 * np.pi * np.arange(32) / 32),\n            \"ground_truth\": \"circular\"\n        },\n        # Case 4: Small edge case, ground truth zero\n        {\n            \"n\": 3,\n            \"x\": np.array([0.0, 2.0, 0.0]),\n            \"ground_truth\": \"zero\"\n        }\n    ]\n\n    all_results = []\n    padding_strategies = ['zero', 'reflection', 'circular']\n\n    # --- Helper functions for padding and convolution ---\n    \n    def get_padded_value(x_sig, j, n_sig, mode):\n        \"\"\"\n        Retrieves the value of a signal at index j, applying the specified padding rule.\n        \"\"\"\n        if 0 = j  n_sig:\n            return x_sig[j]\n        \n        if mode == 'zero':\n            return 0.0\n        \n        if mode == 'reflection':\n            if j  0:\n                # Per problem: x[-j-1] for j  0\n                idx = -j - 1\n            else:  # j >= n_sig\n                # Per problem: x[2n - 1 - j] for j >= n\n                idx = 2 * n_sig - 1 - j\n            \n            # Check if the reflected index is within bounds of the original signal\n            if 0 = idx  n_sig:\n                return x_sig[idx]\n            return 0.0  # Fallback for indices reflected out of bounds\n\n        if mode == 'circular':\n            # Per problem: x[j mod n]\n            return x_sig[j % n_sig]\n        \n        raise ValueError(\"Unknown padding mode\")\n\n    def convolve_1d(x_sig, n_sig, padding_mode):\n        \"\"\"\n        Computes the 1D cross-correlation using the fixed kernel w and specified padding.\n        \"\"\"\n        y = np.zeros(n_sig)\n        for i in range(n_sig):\n            val = 0.0\n            for k in range(m):\n                x_idx = i + k - r\n                val += w[k] * get_padded_value(x_sig, x_idx, n_sig, padding_mode)\n            y[i] = val\n        return y\n\n    # --- Main logic loop ---\n    \n    for case in test_cases:\n        n = case[\"n\"]\n        x = case[\"x\"]\n        gt_mode = case[\"ground_truth\"]\n        \n        # Compute the ground-truth output signal\n        y_true = convolve_1d(x, n, gt_mode)\n        \n        # Determine the boundary index set B\n        boundary_indices = [i for i in range(n) if i  r or i >= n - r]\n        num_boundary_points = len(boundary_indices)\n        \n        case_scores = []\n        for p_mode in padding_strategies:\n            # Compute the output signal for the current padding strategy\n            y_p = convolve_1d(x, n, p_mode)\n            \n            # Calculate the sum of squared errors over the boundary set B\n            sse = 0.0\n            for i in boundary_indices:\n                error = y_p[i] - y_true[i]\n                sse += error * error\n            \n            # Calculate the artifact score (mean squared error)\n            artifact_score = sse / num_boundary_points if num_boundary_points > 0 else 0.0\n            case_scores.append(artifact_score)\n            \n        all_results.append(case_scores)\n        \n    # --- Format final output ---\n    \n    final_output_segments = []\n    for scores in all_results:\n        segment = f\"[{','.join(map(str, scores))}]\"\n        final_output_segments.append(segment)\n        \n    print(f\"[{','.join(final_output_segments)}]\")\n\nsolve()\n```"
        }
    ]
}