{
    "hands_on_practices": [
        {
            "introduction": "While 'same' padding is a crucial tool for maintaining spatial dimensions in CNNs, it introduces subtle biases in how the network processes an image. Pixels located near the center of an input feature map are included in the receptive fields of more output neurons than pixels at the corners. This practice challenges you to quantify this effect, providing a concrete understanding of the inherent central bias in standard convolutional layers. ",
            "id": "3126198",
            "problem": "Consider a single two-dimensional convolutional layer in a Convolutional Neural Network (CNN) with stride $1$, an odd kernel of size $k$, and zero padding chosen so that the output spatial dimensions match the input spatial dimensions. Let the input have height $H$ and width $W$, with $H \\ge k$ and $W \\ge k$. Define the padding amount as $p = (k - 1)/2$. Use standard definitions: a receptive field at an output position is the set of input locations (including padding) that are linearly combined by the kernel to produce that output, and a position is said to be padding-affected if its receptive field includes at least one padded value.\n\nTask:\n- Let $F_{\\text{pad}}$ be the fraction of the $H \\times W$ output positions whose receptive fields include at least one padded element. Derive $F_{\\text{pad}}$ as a function of $H$, $W$, and $k$.\n- For central-bias quantification, let $n(i,j)$ denote the number of output positions whose receptive fields include a fixed input pixel at coordinates $(i,j)$ (with $i \\in \\{1,\\dots,H\\}$ and $j \\in \\{1,\\dots,W\\}$). Let $R$ be the ratio $n(\\text{center})/n(\\text{corner})$, where $\\text{center}$ denotes any pixel with $i \\in \\{p+1,\\dots,H-p\\}$ and $j \\in \\{p+1,\\dots,W-p\\}$, and $\\text{corner}$ denotes the pixel $(1,1)$. Derive $R$ in terms of $k$ (or $p$).\n\nWhich option gives the correct pair $(F_{\\text{pad}}, R)$?\n\nA. $F_{\\text{pad}} = 1 - \\dfrac{(H - 2p)(W - 2p)}{HW}$, and $R = \\dfrac{k^2}{(p+1)^2}$.\n\nB. $F_{\\text{pad}} = \\dfrac{(H - 2p)(W - 2p)}{HW}$, and $R = \\dfrac{(p+1)^2}{k^2}$.\n\nC. $F_{\\text{pad}} = 1 - \\dfrac{(H - k + 1)(W - k + 1)}{HW}$, and $R = \\dfrac{k}{p+1}$.\n\nD. $F_{\\text{pad}} = 1 - \\dfrac{(H - 2p + 1)(W - 2p + 1)}{HW}$, and $R = \\dfrac{(k - 1)^2}{(p+1)^2}$.",
            "solution": "The problem statement will first be rigorously validated before a solution is attempted.\n\n### Step 1: Extract Givens\n- A single two-dimensional convolutional layer is considered.\n- Stride: $s=1$.\n- Kernel size: $k$, where $k$ is an odd integer.\n- Padding: Zero padding is used.\n- Output dimensions: The output spatial dimensions ($H_{\\text{out}}, W_{\\text{out}}$) match the input spatial dimensions ($H, W$).\n- Input dimensions: Height $H$ and width $W$.\n- Constraints: $H \\ge k$ and $W \\ge k$.\n- Padding amount: $p = (k - 1)/2$.\n- Definition of a receptive field: For a given output position, it is the set of input locations (including padding) that are linearly combined by the kernel to produce that output.\n- Definition of a padding-affected position: An output position whose receptive field includes at least one padded value.\n- Task 1: Derive $F_{\\text{pad}}$, the fraction of the $H \\times W$ output positions that are padding-affected, as a function of $H$, $W$, and $k$.\n- Task 2: Define $n(i,j)$ as the number of output positions whose receptive fields include a fixed input pixel at coordinates $(i,j)$, where $i \\in \\{1,\\dots,H\\}$ and $j \\in \\{1,\\dots,W\\}$.\n- Task 3: Derive the ratio $R = n(\\text{center})/n(\\text{corner})$.\n- Definition of a \"center\" pixel: Any pixel $(i,j)$ with $i \\in \\{p+1,\\dots,H-p\\}$ and $j \\in \\{p+1,\\dots,W-p\\}$.\n- Definition of a \"corner\" pixel: The pixel at coordinates $(1,1)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement describes a standard \"same\" or \"half\" padding scenario in convolutional networks. The relationship between output size $O$, input size $I$, kernel size $k$, padding $p$, and stride $s$ for a single dimension is given by $O = \\lfloor \\frac{I - k + 2p}{s} \\rfloor + 1$.\nGiven $s=1$ and $O=I$, the formula becomes $I = I - k + 2p + 1$, which simplifies to $k - 2p - 1 = 0$.\nThe problem defines the padding amount as $p = (k-1)/2$. Substituting this into the consistency condition gives $k - 2\\left(\\frac{k-1}{2}\\right) - 1 = k - (k-1) - 1 = k - k + 1 - 1 = 0$. The definitions are internally consistent.\nThe problem is scientifically grounded in the principles of deep learning, specifically CNNs. The terminology is standard and the task is a well-posed mathematical exercise in coordinate counting based on the properties of convolution. The constraints $H \\ge k$ and $W \\ge k$ are provided, ensuring the \"center\" region is well-defined and non-empty, as $H \\ge 2p+1$ and $W \\ge 2p+1$. The problem is objective and contains no ambiguities.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. I will proceed with deriving the solution.\n\n### Derivation of $F_{\\text{pad}}$\nThe total number of output positions is given by the product of the output dimensions, which is $N_{\\text{total}} = H \\times W$.\n\nAn output position is padding-affected if its receptive field samples from the padded region. Conversely, an output position is *not* padding-affected if its entire receptive field lies within the original $H \\times W$ input image. Let us count the number of these \"safe\" positions, $N_{\\text{safe}}$.\n\nLet the output grid coordinates be $(u,v)$ where $u \\in \\{1, \\dots, H\\}$ and $v \\in \\{1, \\dots, W\\}$. The receptive field for the output at $(u,v)$ is a $k \\times k$ patch of the input. With \"same\" padding, this patch is centered at the corresponding input location $(u,v)$. The kernel has a radius of $(k-1)/2 = p$. Thus, the receptive field for output $(u,v)$ covers input pixels in the range $[u-p, u+p]$ for the row index and $[v-p, v+p]$ for the column index.\n\nFor the receptive field to be entirely within the original input image (i.e., not using any padding), the coordinates of all its constituent pixels must be valid. The input pixel indices $(i,j)$ must satisfy $1 \\le i \\le H$ and $1 \\le j \\le W$.\nApplying this to the receptive field boundaries for an output $(u,v)$:\n1.  $u-p \\ge 1 \\implies u \\ge p+1$\n2.  $u+p \\le H \\implies u \\le H-p$\n3.  $v-p \\ge 1 \\implies v \\ge p+1$\n4.  $v+p \\le W \\implies v \\le W-p$\n\nTherefore, the output positions $(u,v)$ that are not padding-affected are those satisfying $u \\in [p+1, H-p]$ and $v \\in [p+1, W-p]$.\nThe number of such integer values for $u$ is $(H-p) - (p+1) + 1 = H - 2p$.\nThe number of such integer values for $v$ is $(W-p) - (p+1) + 1 = W - 2p$.\n\nThe total number of non-padding-affected (safe) output positions is $N_{\\text{safe}} = (H-2p)(W-2p)$.\nThe number of padding-affected positions is $N_{\\text{pad}} = N_{\\text{total}} - N_{\\text{safe}} = HW - (H-2p)(W-2p)$.\nThe fraction of padding-affected positions is:\n$$ F_{\\text{pad}} = \\frac{N_{\\text{pad}}}{N_{\\text{total}}} = \\frac{HW - (H-2p)(W-2p)}{HW} = 1 - \\frac{(H-2p)(W-2p)}{HW} $$\n\n### Derivation of $R$\nThe quantity $n(i,j)$ represents the number of output positions whose receptive fields include the input pixel at $(i,j)$. An output at $(u,v)$ includes input $(i,j)$ in its receptive field if the input pixel $(i,j)$ falls within the $k \\times k$ region centered at $(u,v)$. This means:\n$u-p \\le i \\le u+p$ and $v-p \\le j \\le v+p$.\n\nTo find the number of valid outputs $(u,v)$, we can rearrange these inequalities for $u$ and $v$:\n$i-p \\le u \\le i+p$ and $j-p \\le v \\le j+p$.\n\nThese ranges for $u$ and $v$ must be restricted to the valid output coordinates, i.e., $u \\in [1, H]$ and $v \\in [1, W]$.\nSo, the valid range for $u$ is $[\\max(1, i-p), \\min(H, i+p)]$.\nAnd the valid range for $v$ is $[\\max(1, j-p), \\min(W, j+p)]$.\nThe number of integer positions is then:\n$n(i,j) = (\\min(H, i+p) - \\max(1, i-p) + 1) \\times (\\min(W, j+p) - \\max(1, j-p) + 1)$.\n\n**Calculation of $n(\\text{center})$:**\nA \"center\" pixel is defined as any pixel $(i,j)$ where $i \\in [p+1, H-p]$ and $j \\in [p+1, W-p]$.\nFor such an $i$, we have $i \\ge p+1 \\implies i-p \\ge 1$, so $\\max(1, i-p) = i-p$.\nAlso, $i \\le H-p \\implies i+p \\le H$, so $\\min(H, i+p) = i+p$.\nThe number of valid $u$ values is $(i+p) - (i-p) + 1 = 2p+1 = k$.\nSimilarly, for such a $j$, the number of valid $v$ values is $(j+p) - (j-p) + 1 = 2p+1 = k$.\nTherefore, $n(\\text{center}) = k \\times k = k^2$.\n\n**Calculation of $n(\\text{corner})$:**\nA \"corner\" pixel is $(1,1)$. We calculate $n(1,1)$.\nFor $i=1$: $\\max(1, 1-p) = 1$ (since $p \\ge 0$). And $\\min(H, 1+p) = 1+p$ (since $H \\ge k = 2p+1 > p+1$).\nThe number of valid $u$ values is $(1+p) - 1 + 1 = p+1$.\nFor $j=1$: $\\max(1, 1-p) = 1$. And $\\min(W, 1+p) = 1+p$ (since $W \\ge k > p+1$).\nThe number of valid $v$ values is $(1+p) - 1 + 1 = p+1$.\nTherefore, $n(\\text{corner}) = n(1,1) = (p+1)(p+1) = (p+1)^2$.\n\n**Calculation of $R$:**\nThe ratio $R$ is:\n$$ R = \\frac{n(\\text{center})}{n(\\text{corner})} = \\frac{k^2}{(p+1)^2} $$\n\nThe derived pair is $\\left( F_{\\text{pad}}, R \\right) = \\left( 1 - \\dfrac{(H - 2p)(W - 2p)}{HW}, \\dfrac{k^2}{(p+1)^2} \\right)$.\n\n### Option-by-Option Analysis\n\n**A. $F_{\\text{pad}} = 1 - \\dfrac{(H - 2p)(W - 2p)}{HW}$, and $R = \\dfrac{k^2}{(p+1)^2}$.**\nThe expression for $F_{\\text{pad}}$ matches our derivation. The expression for $R$ also matches our derivation.\nVerdict: **Correct**.\n\n**B. $F_{\\text{pad}} = \\dfrac{(H - 2p)(W - 2p)}{HW}$, and $R = \\dfrac{(p+1)^2}{k^2}$.**\nThe expression for $F_{\\text{pad}}$ represents the fraction of non-padding-affected positions, not padding-affected ones. This is incorrect. The expression for $R$ is the reciprocal of the correct value. This is also incorrect.\nVerdict: **Incorrect**.\n\n**C. $F_{\\text{pad}} = 1 - \\dfrac{(H - k + 1)(W - k + 1)}{HW}$, and $R = \\dfrac{k}{p+1}$.**\nThe expression for $F_{\\text{pad}}$ is equivalent to the derived one, since $p=(k-1)/2 \\implies 2p = k-1$, making $H-2p = H-(k-1) = H-k+1$. So, this part is correct. However, the expression for $R$ is $\\frac{k}{p+1}$, which is the square root of our derived value $\\frac{k^2}{(p+1)^2}$. This is incorrect.\nVerdict: **Incorrect**.\n\n**D. $F_{\\text{pad}} = 1 - \\dfrac{(H - 2p + 1)(W - 2p + 1)}{HW}$, and $R = \\dfrac{(k - 1)^2}{(p+1)^2}$.**\nThe expression for $F_{\\text{pad}}$ is incorrect. The number of safe rows is $H-2p$, not $H-2p+1$. The expression for $R$ is incorrect. The numerator should be $k^2$, not $(k-1)^2$.\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "A deep understanding of convolutional networks requires not only knowing what they do but also how much it costs to do it. The immense number of multiply-accumulate operations in a single convolutional layer can be a major computational bottleneck. This exercise guides you through a fundamental performance analysis, comparing the cost of direct spatial convolution with a more advanced method based on the Fast Fourier Transform (FFT), revealing the trade-offs that depend on kernel size. ",
            "id": "3126261",
            "problem": "Consider a two-dimensional convolutional layer in a Convolutional Neural Network (CNN) that maps an input tensor of spatial size $H \\times W$ with $c_{\\text{in}}$ input channels to an output tensor of the same spatial size $H \\times W$ with $c_{\\text{out}}$ output channels, using stride $1$ and zero-padding so that the output has the same spatial dimensions as the input. Each output channel is formed by convolving all $c_{\\text{in}}$ input channels with its corresponding set of $c_{\\text{in}}$ kernels of spatial size $k \\times k$ and summing the results across channels.\n\nUsing the foundational definition of discrete convolution and the convolution theorem for the Discrete Fourier Transform (DFT), perform the following:\n\nFirst, derive from first principles the total number of real multiply-accumulate operations (MACs) required to compute the layer by direct spatial-domain convolution as a function of $H$, $W$, $c_{\\text{in}}$, $c_{\\text{out}}$, and $k$.\n\nSecond, derive the total number of real MACs required by an approach that uses the Fast Fourier Transform (FFT) to perform convolution in the frequency domain with the following scientifically grounded cost model based on the Cooley–Tukey algorithm and separable two-dimensional transforms:\n- A single two-dimensional complex FFT of size $H \\times W$ requires approximately $\\frac{5}{2} H W \\left(\\log_{2} H + \\log_{2} W\\right)$ real MACs.\n- A single two-dimensional complex inverse FFT (IFFT) of size $H \\times W$ requires the same number of real MACs, $\\frac{5}{2} H W \\left(\\log_{2} H + \\log_{2} W\\right)$.\n- A single pointwise complex multiplication costs $3$ real MACs (counting $4$ real multiplications and $2$ real additions as $6$ real floating-point operations, i.e., $3$ MACs).\n- A single complex addition costs $1$ real MAC (counting $2$ real additions as $2$ real floating-point operations, i.e., $1$ MAC).\n\nAssume the FFT-based method pads each $k \\times k$ kernel to $H \\times W$ before transforming and proceeds by computing $c_{\\text{in}}$ FFTs of the input channels, $c_{\\text{in}} c_{\\text{out}}$ FFTs of the padded kernels, performing pointwise complex multiply-accumulate across the $c_{\\text{in}}$ input channels for each of the $c_{\\text{out}}$ outputs at every frequency bin, and then computing $c_{\\text{out}}$ inverse FFTs to return to the spatial domain.\n\nFinally, for typical intermediate CNN feature map dimensions $H = 128$ and $W = 128$, and channel counts $c_{\\text{in}} = 64$ and $c_{\\text{out}} = 128$, solve for the smallest kernel size $k$ such that the FFT-based method has equal total real MACs to the direct spatial method. Express your final numerical answer for $k$ rounded to four significant figures. No physical units are required for $k$.",
            "solution": "The problem statement has been critically evaluated and is determined to be valid. It is scientifically grounded in the principles of digital signal processing and computational complexity analysis as applied to convolutional neural networks. The problem is well-posed, providing all necessary definitions, constants, and a clear objective. The language is precise and unambiguous.\n\nWe will now proceed with the derivation. The problem asks for two derivations of the total number of real multiply-accumulate (MAC) operations for a convolutional layer, followed by a calculation to find the break-even kernel size.\n\n**Part 1: MACs for Direct Spatial-Domain Convolution**\n\nThe direct convolution operation computes each element of the output tensor by performing a dot product between a kernel and the corresponding receptive field in the input tensor.\n\nLet the input tensor have dimensions $H \\times W \\times c_{\\text{in}}$ and the output tensor have dimensions $H \\times W \\times c_{\\text{out}}$. The kernel size is $k \\times k$.\n\nTo compute a single value at a specific spatial location $(i,j)$ in one output channel, we must convolve a $k \\times k$ region of each of the $c_{\\text{in}}$ input channels with a corresponding $k \\times k$ kernel. This operation is then summed across all $c_{\\text{in}}$ channels.\n\nFor one output value, the number of multiplications is the size of the kernel's spatial dimensions multiplied by the number of input channels, which is $k \\times k \\times c_{\\text{in}} = k^2 c_{\\text{in}}$. Since these products are summed (accumulated), this corresponds to $k^2 c_{\\text{in}}$ MAC operations.\n\nThis calculation must be repeated for every spatial location in the output feature map. Since the output spatial dimensions are $H \\times W$, the number of MACs to produce one output channel is $(H \\times W) \\times (k^2 c_{\\text{in}})$.\n\nFinally, there are $c_{\\text{out}}$ output channels, each computed independently with its own set of kernels. Therefore, the total number of real MACs for the direct spatial convolution, denoted $N_{\\text{direct}}$, is:\n$$N_{\\text{direct}} = c_{\\text{out}} \\times (H \\cdot W \\cdot k^2 \\cdot c_{\\text{in}})$$\n$$N_{\\text{direct}} = H W c_{\\text{in}} c_{\\text{out}} k^2$$\n\n**Part 2: MACs for FFT-Based Frequency-Domain Convolution**\n\nThe FFT-based approach leverages the convolution theorem, which states that convolution in the spatial domain is equivalent to element-wise multiplication in the frequency domain. We will calculate the total MACs by summing the costs of the steps defined in the problem.\n\nIt is noted that performing convolution via multiplication in the frequency domain of size $H \\times W$ corresponds to a circular convolution. The calculation of linear convolution with 'same' padding, as implied by the direct method, would necessitate padding both the input and filters to a larger size (e.g., $(H+k-1) \\times (W+k-1)$). However, the problem explicitly prescribes the use of $H \\times W$ transforms for this analysis. Therefore, the following derivation strictly adheres to the specified algorithm and its associated costs.\n\nLet the cost of a single $H \\times W$ 2D complex FFT or IFFT be $C_{\\text{FFT}} = \\frac{5}{2} H W (\\log_{2} H + \\log_{2} W)$.\n\n1.  **FFT of Input Channels**: There are $c_{\\text{in}}$ input channels, each of size $H \\times W$. We perform one 2D FFT per channel.\n    Cost: $C_1 = c_{\\text{in}} \\cdot C_{\\text{FFT}} = c_{\\text{in}} \\frac{5}{2} H W (\\log_{2} H + \\log_{2} W)$.\n\n2.  **FFT of Padded Kernels**: There are $c_{\\text{in}} \\times c_{\\text{out}}$ kernels in total, each of size $k \\times k$. Each is padded to $H \\times W$ and transformed.\n    Cost: $C_2 = c_{\\text{in}} c_{\\text{out}} \\cdot C_{\\text{FFT}} = c_{\\text{in}} c_{\\text{out}} \\frac{5}{2} H W (\\log_{2} H + \\log_{2} W)$.\n\n3.  **Pointwise Multiply-Accumulate**: For each of the $c_{\\text{out}}$ output channels, we must combine the $c_{\\text{in}}$ transformed input channels with the corresponding $c_{\\text{in}}$ transformed kernels. For each of the $H \\times W$ frequency bins, this operation is $\\hat{O}_m = \\sum_{l=1}^{c_{\\text{in}}} \\hat{I}_l \\odot \\hat{K}_{l,m}$, where $\\odot$ is element-wise multiplication.\n    For a single frequency bin and a single output channel, this requires $c_{\\text{in}}$ complex multiplications and $c_{\\text{in}}-1$ complex additions.\n    Using the specified cost model:\n    -   Cost of complex multiplications: $c_{\\text{in}} \\times (3 \\text{ real MACs}) = 3c_{\\text{in}}$ real MACs.\n    -   Cost of complex additions: $(c_{\\text{in}}-1) \\times (1 \\text{ real MAC}) = c_{\\text{in}}-1$ real MACs.\n    Total cost per frequency bin, per output channel: $3c_{\\text{in}} + (c_{\\text{in}}-1) = 4c_{\\text{in}}-1$ real MACs.\n    This must be done for all $H \\times W$ frequency bins and for all $c_{\\text{out}}$ output channels.\n    Cost: $C_3 = H \\cdot W \\cdot c_{\\text{out}} \\cdot (4c_{\\text{in}}-1)$.\n\n4.  **Inverse FFT of Outputs**: We have $c_{\\text{out}}$ frequency-domain output maps, which must be transformed back to the spatial domain.\n    Cost: $C_4 = c_{\\text{out}} \\cdot C_{\\text{FFT}} = c_{\\text{out}} \\frac{5}{2} H W (\\log_{2} H + \\log_{2} W)$.\n\nThe total number of real MACs for the FFT-based method, $N_{\\text{FFT}}$, is the sum of these costs:\n$N_{\\text{FFT}} = C_1 + C_2 + C_3 + C_4$.\nLet $L = \\log_2 H + \\log_2 W$.\n$$N_{\\text{FFT}} = c_{\\text{in}} \\frac{5}{2} H W L + c_{\\text{in}} c_{\\text{out}} \\frac{5}{2} H W L + H W c_{\\text{out}} (4c_{\\text{in}}-1) + c_{\\text{out}} \\frac{5}{2} H W L$$\nFactoring out $H W$:\n$$N_{\\text{FFT}} = H W \\left[ \\frac{5}{2} L (c_{\\text{in}} + c_{\\text{in}}c_{\\text{out}} + c_{\\text{out}}) + c_{\\text{out}}(4c_{\\text{in}}-1) \\right]$$\n\n**Part 3: Solving for the Break-Even Kernel Size $k$**\n\nWe are asked to find the kernel size $k$ for which the two methods require an equal number of MACs, i.e., $N_{\\text{direct}} = N_{\\text{FFT}}$.\n$$H W c_{\\text{in}} c_{\\text{out}} k^2 = H W \\left[ \\frac{5}{2} L (c_{\\text{in}} + c_{\\text{in}}c_{\\text{out}} + c_{\\text{out}}) + c_{\\text{out}}(4c_{\\text{in}}-1) \\right]$$\nWe can cancel the $H W$ term from both sides:\n$$c_{\\text{in}} c_{\\text{out}} k^2 = \\frac{5}{2} L (c_{\\text{in}} + c_{\\text{in}}c_{\\text{out}} + c_{\\text{out}}) + 4c_{\\text{in}}c_{\\text{out}} - c_{\\text{out}}$$\nSolving for $k^2$:\n$$k^2 = \\frac{1}{c_{\\text{in}} c_{\\text{out}}} \\left[ \\frac{5}{2} L (c_{\\text{in}} + c_{\\text{in}}c_{\\text{out}} + c_{\\text{out}}) + 4c_{\\text{in}}c_{\\text{out}} - c_{\\text{out}} \\right]$$\n$$k^2 = \\frac{5L}{2} \\left( \\frac{c_{\\text{in}}}{c_{\\text{in}} c_{\\text{out}}} + \\frac{c_{\\text{in}}c_{\\text{out}}}{c_{\\text{in}} c_{\\text{out}}} + \\frac{c_{\\text{out}}}{c_{\\text{in}} c_{\\text{out}}} \\right) + \\frac{4c_{\\text{in}}c_{\\text{out}}}{c_{\\text{in}} c_{\\text{out}}} - \\frac{c_{\\text{out}}}{c_{\\text{in}} c_{\\text{out}}}$$\n$$k^2 = \\frac{5L}{2} \\left( \\frac{1}{c_{\\text{out}}} + 1 + \\frac{1}{c_{\\text{in}}} \\right) + 4 - \\frac{1}{c_{\\text{in}}}$$\n\nNow, we substitute the given numerical values: $H = 128$, $W = 128$, $c_{\\text{in}} = 64$, $c_{\\text{out}} = 128$.\nFirst, calculate $L$:\n$$L = \\log_2(128) + \\log_2(128) = 7 + 7 = 14$$\nSubstitute all values into the expression for $k^2$:\n$$k^2 = \\frac{5(14)}{2} \\left( 1 + \\frac{1}{64} + \\frac{1}{128} \\right) + 4 - \\frac{1}{64}$$\n$$k^2 = 35 \\left( \\frac{128}{128} + \\frac{2}{128} + \\frac{1}{128} \\right) + 4 - \\frac{2}{128}$$\n$$k^2 = 35 \\left( \\frac{131}{128} \\right) + 4 - \\frac{2}{128}$$\n$$k^2 = \\frac{4585}{128} + \\frac{512}{128} - \\frac{2}{128}$$\n$$k^2 = \\frac{4585 + 512 - 2}{128} = \\frac{5095}{128}$$\nNow, we calculate the numerical value of $k^2$:\n$$k^2 = 39.8046875$$\nFinally, we solve for $k$:\n$$k = \\sqrt{39.8046875} \\approx 6.3090956...$$\nRounding to four significant figures, we get $k \\approx 6.309$.",
            "answer": "$$\\boxed{6.309}$$"
        },
        {
            "introduction": "Ideally, a convolutional network should recognize an object regardless of where it appears in an image—a property known as translation equivariance. However, standard architectural components like zero-padding, striding, and max-pooling can disrupt this ideal behavior, making the network's output sensitive to small shifts in the input. This hands-on coding exercise provides a framework to empirically measure this equivariance error, diagnose its sources, and explore modern anti-aliasing techniques that help restore this crucial property. ",
            "id": "3126243",
            "problem": "You are asked to design and implement an experiment that measures and analyzes translation equivariance error in two-dimensional Convolutional Neural Networks (CNNs). Let the input be a single-channel image represented by a matrix $x \\in \\mathbb{R}^{H \\times W}$. Define the discrete circular translation operator $T_{\\delta}$ acting on a matrix $z \\in \\mathbb{R}^{H \\times W}$ by $T_{\\delta} z[i,j] = z[(i + \\delta_x) \\bmod H, (j + \\delta_y) \\bmod W]$ for a shift vector $\\delta = (\\delta_x,\\delta_y)$, where all indices are taken modulo $H$ and $W$. For a network $f$, the equivariance error for a shift $\\delta$ is defined as\n$$\nE(f, x, \\delta) = \\left\\| f\\!\\left(T_{\\delta} x\\right) - T_{\\delta'} \\, f(x) \\right\\|_2 \\, ,\n$$\nwhere $\\|\\cdot\\|_2$ is the Frobenius norm on matrices and $\\delta' = \\left(\\left\\lfloor \\frac{\\delta_x}{s_{\\text{eff}}} \\right\\rfloor, \\left\\lfloor \\frac{\\delta_y}{s_{\\text{eff}}} \\right\\rfloor\\right)$ is the output-space shift induced by the total downsampling factor $s_{\\text{eff}}$ of $f$. To make results directly comparable across architectures and shifts, use the relative error\n$$\nE_{\\text{rel}}(f, x, \\delta) = \\frac{\\left\\| f\\!\\left(T_{\\delta} x\\right) - T_{\\delta'} \\, f(x) \\right\\|_2}{\\left\\| f(x) \\right\\|_2 + \\varepsilon} \\, ,\n$$\nwith $\\varepsilon = 10^{-12}$ to avoid division by zero.\n\nConstruct the following deterministic components from well-tested formulas and core definitions:\n\n$1.$ Image $x$ of size $H = W = 32$ defined for $i \\in \\{0,\\dots,31\\}$ and $j \\in \\{0,\\dots,31\\}$ by\n$$\nx[i,j] = \\sin\\!\\left(\\frac{2\\pi i}{H}\\right) + \\frac{1}{2}\\cos\\!\\left(\\frac{2\\pi j}{W}\\right) + \\frac{1}{4} \\exp\\!\\left( - \\frac{(i - c)^2 + (j - c)^2}{2 \\sigma^2} \\right),\n$$\nwhere $c = 16$ and $\\sigma = 3$.\n\n$2.$ Convolution kernels:\n- Let $g = \\frac{1}{16}[1, 4, 6, 4, 1]$ and define the separable two-dimensional Gaussian kernel $k_1[u,v] = g[u] \\, g[v]$ for $u,v \\in \\{0,\\dots,4\\}$.\n- Let\n$$\nk_2 = \\begin{bmatrix}\n0 & -1 & 0 \\\\\n-1 & 4 & -1 \\\\\n0 & -1 & 0\n\\end{bmatrix}.\n$$\n\n$3.$ Nonlinearity: use the Rectified Linear Unit (ReLU), $\\phi(a) = \\max(a, 0)$, applied pointwise.\n\nDefine the following networks $f$ (all convolutions are two-dimensional, single-input-channel to single-output-channel):\n\n- Baseline $f_{\\text{base}}$: apply convolution with kernel $k_1$ at stride $1$ with circular padding to preserve spatial size, then apply $\\phi$, then convolve with kernel $k_2$ at stride $1$ with circular padding, and apply $\\phi$ again. The effective downsampling factor is $s_{\\text{eff}} = 1$.\n\n- Padding-variant $f_{\\text{pad}}$: identical to $f_{\\text{base}}$ but using zero padding instead of circular padding in both convolutions. The effective downsampling factor is $s_{\\text{eff}} = 1$.\n\n- Strided-variant $f_{\\text{stride}}$: identical to $f_{\\text{base}}$ except the first convolution uses stride $2$ (with circular padding). The effective downsampling factor is $s_{\\text{eff}} = 2$.\n\n- Pooling-variant $f_{\\text{pool}}$: identical to $f_{\\text{base}}$ but insert a $2 \\times 2$ max pooling with stride $2$ after the first $\\phi$. The effective downsampling factor is $s_{\\text{eff}} = 2$.\n\n- Stride remedy $f_{\\text{stride-rem}}$: replace the strided convolution of $f_{\\text{stride}}$ by an anti-aliased downsampling: first apply the convolution with $k_1$ at stride $1$ and circular padding, then convolve with the separable blur kernel $k_b$ defined by $k_b[u,v] = g[u] \\, g[v]$ and finally subsample by taking every $2$nd pixel in each spatial dimension. Then continue with $\\phi$, then convolve with $k_2$ at stride $1$ (circular padding), then apply $\\phi$. The effective downsampling factor is $s_{\\text{eff}} = 2$.\n\n- Pooling remedy $f_{\\text{pool-rem}}$: identical to $f_{\\text{base}}$ but after the first $\\phi$, first convolve with $k_b$ (circular padding), then perform $2 \\times 2$ average pooling with stride $2$ (which is equivalent to uniform low-pass filtering over non-overlapping windows), then continue with convolution by $k_2$ at stride $1$ (circular padding), then apply $\\phi$. The effective downsampling factor is $s_{\\text{eff}} = 2$.\n\nUse the test suite of shifts\n$$\n\\mathcal{D} = \\left\\{ (0,0), (1,0), (2,0), (3,5), (15,16) \\right\\}.\n$$\n\nYour tasks are:\n$1.$ Implement the networks above using only the specified kernels and pointwise nonlinearity.\n$2.$ For each $\\delta \\in \\mathcal{D}$, compute $E_{\\text{rel}}(f, x, \\delta)$ for $f \\in \\{ f_{\\text{base}}, f_{\\text{pad}}, f_{\\text{stride}}, f_{\\text{pool}}, f_{\\text{stride-rem}}, f_{\\text{pool-rem}} \\}$.\n$3.$ From these, estimate additive contributions of padding, stride, and pooling to equivariance error by the finite differences\n$$\n\\Delta_{\\text{pad}} = \\operatorname{mean}_{\\delta \\in \\mathcal{D}} \\left( E_{\\text{rel}}(f_{\\text{pad}}, x, \\delta) - E_{\\text{rel}}(f_{\\text{base}}, x, \\delta) \\right),\n$$\n$$\n\\Delta_{\\text{stride}} = \\operatorname{mean}_{\\delta \\in \\mathcal{D}} \\left( E_{\\text{rel}}(f_{\\text{stride}}, x, \\delta) - E_{\\text{rel}}(f_{\\text{base}}, x, \\delta) \\right),\n$$\n$$\n\\Delta_{\\text{pool}} = \\operatorname{mean}_{\\delta \\in \\mathcal{D}} \\left( E_{\\text{rel}}(f_{\\text{pool}}, x, \\delta) - E_{\\text{rel}}(f_{\\text{base}}, x, \\delta) \\right).\n$$\nAlso report the mean baseline error\n$$\n\\overline{E}_{\\text{base}} = \\operatorname{mean}_{\\delta \\in \\mathcal{D}} E_{\\text{rel}}(f_{\\text{base}}, x, \\delta).\n$$\n\n$4.$ Quantify the effect of the proposed remedies by computing the average improvements\n$$\nI_{\\text{stride}} = \\operatorname{mean}_{\\delta \\in \\mathcal{D}} \\left( E_{\\text{rel}}(f_{\\text{stride}}, x, \\delta) - E_{\\text{rel}}(f_{\\text{stride-rem}}, x, \\delta) \\right),\n$$\n$$\nI_{\\text{pool}} = \\operatorname{mean}_{\\delta \\in \\mathcal{D}} \\left( E_{\\text{rel}}(f_{\\text{pool}}, x, \\delta) - E_{\\text{rel}}(f_{\\text{pool-rem}}, x, \\delta) \\right).\n$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order:\n$$\n\\left[ \\overline{E}_{\\text{base}}, \\Delta_{\\text{pad}}, \\Delta_{\\text{stride}}, \\Delta_{\\text{pool}}, I_{\\text{stride}}, I_{\\text{pool}} \\right].\n$$\n\nAll computations are purely numerical with no physical units. Angles inside trigonometric functions are in radians. The answer for each metric must be a float. Ensure scientific realism by exactly following the definitions above and using the specified kernels and operators. The provided test suite $\\mathcal{D}$ includes a happy-path case $\\delta = (0,0)$, small shifts, and large shifts to exercise boundaries and downsampling effects. No user input is required; all parameters are fixed as specified.",
            "solution": "The user has requested a numerical experiment to analyze translation equivariance error in various two-dimensional Convolutional Neural Network (CNN) architectures. The problem is well-defined, scientifically sound, and computationally tractable. It provides a precise mathematical framework for constructing the input data, network components, and evaluation metrics. The following solution implements the specified experiment, calculates the required error metrics, and provides a complete, runnable program.\n\n### 1. Theoretical Framework and Core Components\n\nThe experiment is centered on the concept of translation equivariance. A function $f$ is equivariant to a translation operator $T_{\\delta}$ if applying the function to a translated input is the same as translating the function's output, i.e., $f(T_{\\delta}x) = T_{\\delta'}f(x)$. The operator $T_{\\delta'}$ is the corresponding translation in the output space, which may be downsampled. The problem defines a relative error metric, $E_{\\text{rel}}(f, x, \\delta)$, to quantify deviations from perfect equivariance.\n\nFirst, we construct the fundamental components of the experiment.\n\n**Input Image:** The input image $x$ is a $32 \\times 32$ matrix defined by the function:\n$$\nx[i,j] = \\sin\\!\\left(\\frac{2\\pi i}{H}\\right) + \\frac{1}{2}\\cos\\!\\left(\\frac{2\\pi j}{W}\\right) + \\frac{1}{4} \\exp\\!\\left( - \\frac{(i - c)^2 + (j - c)^2}{2 \\sigma^2} \\right)\n$$\nwith parameters $H=W=32$, $c=16$, and $\\sigma=3$. This superposition of sinusoids and a Gaussian blob provides a signal with both low and high-frequency components, suitable for testing convolutions.\n\n**Translation Operator:** The discrete circular translation $T_{\\delta}$ shifts the input image by a vector $\\delta = (\\delta_x, \\delta_y)$ with wrap-around boundaries. This is implemented using `numpy.roll`, which performs a circular shift on an array's elements along specified axes.\n\n**Convolution Kernels:** Two kernels are defined:\n- A $5 \\times 5$ separable Gaussian blur kernel, $k_1$, derived from the vector $g = \\frac{1}{16}[1, 4, 6, 4, 1]$. This is a low-pass filter.\n- A $3 \\times 3$ Laplacian kernel, $k_2$, which acts as a high-pass filter or edge detector.\n\n**Nonlinearity:** The Rectified Linear Unit (ReLU), $\\phi(a) = \\max(a, 0)$, is applied element-wise after convolution and pooling stages. This introduces nonlinearity, a critical component of deep networks.\n\n### 2. Network Operations\n\nThe specified networks are built from a sequence of fundamental operations.\n\n**Convolution:** Two-dimensional convolution is the core operation. The problem specifies two padding strategies:\n- **Circular Padding:** This ensures perfect equivariance for stride-1 convolutions, as the boundary conditions are consistent with the circular translation operator $T_{\\delta}$. It is implemented using `scipy.signal.convolve2d` with the arguments `mode='same'` and `boundary='wrap'`.\n- **Zero Padding:** This common alternative breaks perfect equivariance because translating the input image changes which parts of the signal interact with the zero-padded boundaries. It is implemented using `scipy.signal.convolve2d` with `mode='same'` and the default `boundary='fill'`.\n\n**Downsampling Operations:** Striding and pooling operations reduce the spatial dimensions of the feature maps, which is a primary source of equivariance error in standard CNNs.\n- **Strided Convolution:** A convolution with a stride greater than $1$. This is implemented by performing a standard stride-$1$ convolution and then subsampling the output grid (e.g., taking every second element for a stride of $2$).\n- **Max Pooling:** A downsampling operation that takes the maximum value over local patches of the input. For a $2 \\times 2$ kernel and stride $2$, this is implemented by reshaping a $(H, W)$ feature map into $(H/2, 2, W/2, 2)$ and taking the maximum over the newly created axes.\n- **Average Pooling:** Similar to max pooling, but takes the mean value over local patches.\n\n### 3. Network Architectures and Analysis\n\nWe implement six network architectures ($f_{\\text{base}}, f_{\\text{pad}}, f_{\\text{stride}}, f_{\\text{pool}}, f_{\\text{stride-rem}}, f_{\\text{pool-rem}}$) as distinct functions. Each function composes the operations described above in the specified sequence.\n\n- $f_{\\text{base}}$ serves as the idealized, \"most equivariant\" model, using stride-1 convolutions and circular padding. Its error will ideally be near zero (limited by floating-point precision).\n- $f_{\\text{pad}}$ isolates the error contribution from using zero padding instead of circular padding.\n- $f_{\\text{stride}}$ and $f_{\\text{pool}}$ demonstrate the significant equivariance error introduced by naive striding and max pooling, which discard information in a shift-variant manner.\n- $f_{\\text{stride-rem}}$ and $f_{\\text{pool-rem}}$ implement anti-aliasing techniques. By applying a low-pass filter (the blur kernel $k_b$) before downsampling (subsampling or average pooling), they aim to mitigate the error caused by aliasing, thereby improving equivariance.\n\n### 4. Computation and Final Metrics\n\nThe main computational loop iterates through each network and each specified shift $\\delta \\in \\mathcal{D}$. For each pair $(f, \\delta)$, it computes the relative equivariance error $E_{\\text{rel}}(f, x, \\delta)$ by executing the following steps:\n1.  Compute the output for the original image: $y = f(x)$.\n2.  Translate the input image: $x_{\\text{shifted}} = T_{\\delta} x$.\n3.  Compute the output for the translated image: $y_{\\text{shifted_in}} = f(x_{\\text{shifted}})$.\n4.  Translate the original output according to the network's effective stride: $y_{\\text{shifted_out}} = T_{\\delta'} y$, where $\\delta' = (\\lfloor \\delta_x / s_{\\text{eff}} \\rfloor, \\lfloor \\delta_y / s_{\\text{eff}} \\rfloor)$.\n5.  Calculate the Frobenius norms of the difference $\\| y_{\\text{shifted_in}} - y_{\\text{shifted_out}} \\|_2$ and the original output $\\|y\\|_2$.\n6.  Compute the final relative error $E_{\\text{rel}}$.\n\nAfter collecting all error values, we compute the final summary metrics as defined in the problem: $\\overline{E}_{\\text{base}}$ (mean baseline error), $\\Delta_{\\text{pad}}, \\Delta_{\\text{stride}}, \\Delta_{\\text{pool}}$ (error contributions from padding, striding, and pooling), and $I_{\\text{stride}}, I_{\\text{pool}}$ (improvements from anti-aliasing remedies). These are calculated by taking the mean of the relevant error values or their differences over the set of shifts $\\mathcal{D}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import signal\n\ndef solve():\n    \"\"\"\n    Implements and analyzes translation equivariance error in various 2D CNNs.\n    \"\"\"\n    # Define constants and test parameters from the problem statement.\n    H, W = 32, 32\n    c, sigma = 16, 3\n    epsilon = 1e-12\n    shifts = [(0, 0), (1, 0), (2, 0), (3, 5), (15, 16)]\n\n    # 1. Construct the input image x\n    i, j = np.mgrid[0:H, 0:W]\n    x = (np.sin(2 * np.pi * i / H) +\n         0.5 * np.cos(2 * np.pi * j / W) +\n         0.25 * np.exp(-((i - c)**2 + (j - c)**2) / (2 * sigma**2)))\n\n    # 2. Define convolution kernels\n    g = np.array([1, 4, 6, 4, 1]) / 16.0\n    k1 = np.outer(g, g)\n    k2 = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])\n    kb = k1  # The blur kernel is the same as k1\n\n    # Helper functions for network operations\n    def translate(mat, delta):\n        return np.roll(mat, shift=delta, axis=(0, 1))\n\n    def relu(mat):\n        return np.maximum(0, mat)\n\n    def do_conv(img, kernel, stride, padding):\n        if padding == 'circular':\n            convolved = signal.convolve2d(img, kernel, boundary='wrap', mode='same')\n        elif padding == 'zero':\n            convolved = signal.convolve2d(img, kernel, boundary='fill', fillvalue=0, mode='same')\n        else:\n            raise ValueError(f\"Unsupported padding type: {padding}\")\n        return convolved[::stride, ::stride]\n\n    def max_pool_2x2(mat):\n        h_in, w_in = mat.shape\n        h_out, w_out = h_in // 2, w_in // 2\n        return mat.reshape(h_out, 2, w_out, 2).max(axis=(1, 3))\n\n    def avg_pool_2x2(mat):\n        h_in, w_in = mat.shape\n        h_out, w_out = h_in // 2, w_in // 2\n        return mat.reshape(h_out, 2, w_out, 2).mean(axis=(1, 3))\n\n    # 3. Define the six network architectures\n    def f_base(img):\n        h = do_conv(img, k1, stride=1, padding='circular')\n        h = relu(h)\n        h = do_conv(h, k2, stride=1, padding='circular')\n        h = relu(h)\n        return h\n\n    def f_pad(img):\n        h = do_conv(img, k1, stride=1, padding='zero')\n        h = relu(h)\n        h = do_conv(h, k2, stride=1, padding='zero')\n        h = relu(h)\n        return h\n\n    def f_stride(img):\n        h = do_conv(img, k1, stride=2, padding='circular')\n        h = relu(h)\n        h = do_conv(h, k2, stride=1, padding='circular')\n        h = relu(h)\n        return h\n\n    def f_pool(img):\n        h = do_conv(img, k1, stride=1, padding='circular')\n        h = relu(h)\n        h = max_pool_2x2(h)\n        h = do_conv(h, k2, stride=1, padding='circular')\n        h = relu(h)\n        return h\n\n    def f_stride_rem(img):\n        h = do_conv(img, k1, stride=1, padding='circular')\n        h = do_conv(h, kb, stride=1, padding='circular')\n        h = h[::2, ::2]  # Subsample after blurring\n        h = relu(h)\n        h = do_conv(h, k2, stride=1, padding='circular')\n        h = relu(h)\n        return h\n\n    def f_pool_rem(img):\n        h = do_conv(img, k1, stride=1, padding='circular')\n        h = relu(h)\n        h = do_conv(h, kb, stride=1, padding='circular')\n        h = avg_pool_2x2(h)\n        h = do_conv(h, k2, stride=1, padding='circular')\n        h = relu(h)\n        return h\n\n    networks = {\n        'base':       (f_base, 1),\n        'pad':        (f_pad, 1),\n        'stride':     (f_stride, 2),\n        'pool':       (f_pool, 2),\n        'stride-rem': (f_stride_rem, 2),\n        'pool-rem':   (f_pool_rem, 2)\n    }\n\n    errors = {name: [] for name in networks}\n\n    # 4. Calculate equivariance error for each network and shift\n    for name, (f, s_eff) in networks.items():\n        y = f(x)\n        norm_y = np.linalg.norm(y)\n\n        for delta in shifts:\n            delta_x, delta_y = delta\n            x_shifted = translate(x, delta)\n            y_shifted_in = f(x_shifted)\n            \n            delta_prime = (delta_x // s_eff, delta_y // s_eff)\n            y_shifted_out = translate(y, delta_prime)\n            \n            norm_diff = np.linalg.norm(y_shifted_in - y_shifted_out)\n            e_rel = norm_diff / (norm_y + epsilon)\n            errors[name].append(e_rel)\n\n    # 5. Compute final metrics\n    mean_errors = {name: np.mean(err_list) for name, err_list in errors.items()}\n\n    E_base_mean = mean_errors['base']\n    Delta_pad = mean_errors['pad'] - mean_errors['base']\n    Delta_stride = mean_errors['stride'] - mean_errors['base']\n    Delta_pool = mean_errors['pool'] - mean_errors['base']\n    I_stride = mean_errors['stride'] - mean_errors['stride-rem']\n    I_pool = mean_errors['pool'] - mean_errors['pool-rem']\n\n    results = [E_base_mean, Delta_pad, Delta_stride, Delta_pool, I_stride, I_pool]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}