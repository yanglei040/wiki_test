{
    "hands_on_practices": [
        {
            "introduction": "学习曲线最常见的用途之一是识别模型何时停止泛化并开始过拟合。这项练习通过一组关于带噪标签的假设数据，构建了一个典型的过拟合场景。通过分析验证损失曲线的“U”形特征，您将掌握解读学习曲线并应用早停策略以获得最佳泛化性能的基本技能。",
            "id": "3115462",
            "problem": "你使用经验风险最小化（ERM）和交叉熵损失，在一个固定的图像分类数据集上训练同一个过参数化深度网络。训练集的标签以概率 $p \\in \\{0, 0.1, 0.4\\}$ 受到对称标签噪声的破坏，每个训练标签以概率 $p$ 被独立地翻转到一个均匀选择的错误类别。验证集保持干净（无噪声）。对于每个 $p$，你使用固定的优化器和学习率调度，记录了在 $e \\in \\{1,2,\\dots,10\\}$ 个轮次中的训练损失 $L_{\\text{train}}(e)$ 和验证损失 $L_{\\text{val}}(e)$。\n\n观察到的损失如下（每个序列按轮次 $1$ 到 $10$ 的顺序列出）：\n\n- 对于 $p=0$：\n  - $L_{\\text{train}}$: $\\{1.00,\\,0.80,\\,0.63,\\,0.50,\\,0.41,\\,0.35,\\,0.31,\\,0.28,\\,0.26,\\,0.25\\}$\n  - $L_{\\text{val}}$: $\\{1.02,\\,0.82,\\,0.66,\\,0.55,\\,0.47,\\,0.40,\\,0.36,\\,0.33,\\,0.31,\\,0.30\\}$\n\n- 对于 $p=0.1$：\n  - $L_{\\text{train}}$: $\\{1.00,\\,0.83,\\,0.70,\\,0.61,\\,0.54,\\,0.49,\\,0.45,\\,0.42,\\,0.40,\\,0.39\\}$\n  - $L_{\\text{val}}$: $\\{1.04,\\,0.86,\\,0.72,\\,0.63,\\,0.58,\\,0.56,\\,0.57,\\,0.60,\\,0.64,\\,0.69\\}$\n\n- 对于 $p=0.4$：\n  - $L_{\\text{train}}$: $\\{1.00,\\,0.88,\\,0.80,\\,0.75,\\,0.71,\\,0.68,\\,0.66,\\,0.65,\\,0.64,\\,0.63\\}$\n  - $L_{\\text{val}}$: $\\{1.10,\\,0.96,\\,0.90,\\,0.89,\\,0.91,\\,0.95,\\,1.00,\\,1.07,\\,1.16,\\,1.26\\}$\n\n假设训练动态是现代深度网络的典型情况：早期轮次主要拟合数据中的共享结构，而后期轮次可能记忆特异性样本，包括错误标记的点。使用这些学习曲线，诊断噪声记忆何时开始，并根据曲线中的转折或拐点行为提出一个早停规则。\n\n下列哪个陈述是正确的？\n\nA. 对于 $p=0$，在 $10$ 个轮次内没有记忆的证据，因为 $L_{\\text{val}}(e)$ 单调递减；在给定的轮次中，一个合理的早停选择是 $e=10$。\n\nB. 对于 $p=0.1$，记忆大约在 $L_{\\text{val}}(e)$ 达到最小值然后开始增加，而 $L_{\\text{train}}(e)$ 持续减少的轮次开始；一个合理的早停选择是 $e=6$。\n\nC. 对于 $p=0.4$，记忆比 $p=0.1$ 时开始得更早；一个合理的早停选择是 $e=4$。\n\nD. 一个普遍可靠的规则是在训练准确率超过验证准确率的最早轮次停止。\n\nE. 随着 $p$ 的增加，记忆的开始时间在训练中会提前，因此在观察到的曲线下，开始轮次满足 $e_{\\text{onset}}(p=0.4)  e_{\\text{onset}}(p=0.1)  e_{\\text{onset}}(p=0)$。",
            "solution": "核心任务是通过分析学习曲线来诊断模型的行为，学习曲线绘制了训练损失（$L_{\\text{train}}$）和验证损失（$L_{\\text{val}}$）随训练轮次（$e$）变化的函数。\n\n1.  **泛化与记忆**：一个有效的模型能很好地从训练数据泛化到未见过的数据。验证损失 $L_{\\text{val}}$ 在一个干净的、留出的数据集上测量，是模型泛化误差的代理指标。训练损失 $L_{\\text{train}}$ 衡量模型对训练数据的拟合程度。\n2.  **过拟合/记忆的特征**：一个过参数化的模型有足够的能力去记忆训练数据，包括任何噪声或错误标记的样本。给定的假设指出，模型首先学习通用模式（对训练集和验证集都有益），然后开始记忆特异性数据点，例如那些带有损坏标签的数据点。这种现象在学习曲线上表现如下：\n    - $L_{\\text{train}}$ 持续下降，因为模型越来越完美地拟合训练数据，包括噪声。\n    - $L_{\\text{val}}$ 首先下降（因为模型学习可泛化的特征），然后开始*增加*，因为模型的参数被调整以拟合训练集中的噪声，这损害了它对干净验证集的泛化能力。\n3.  **早停**：早停的目标是在模型达到最佳泛化性能的点停止训练。这对应于 $L_{\\text{val}}$ 达到其最小值的轮次。$L_{\\text{val}}$ 最小化的轮次是最佳停止点，随后 $L_{\\text{val}}$ 的增加标志着有害的过拟合或噪声记忆的开始。\n\n我们现在应用这个框架来分析每个噪声率 $p$ 的数据。\n\n- **对 $p=0$ （无噪声）的分析**：\n  - $L_{\\text{train}}(e)$ 从 $1.00$ 单调递减到 $0.25$。\n  - $L_{\\text{val}}(e)$ 从 $1.02$ 单调递减到 $0.30$。\n  - 由于在观察到的 $10$ 个轮次中 $L_{\\text{val}}(e)$ 一直在下降，所以没有过拟合的证据。模型仍在提高其泛化性能。在此训练期间内，最好的模型出现在 $e=10$。\n\n- **对 $p=0.1$ （$10\\%$ 噪声）的分析**：\n  - $L_{\\text{train}}(e)$ 从 $1.00$ 单调递减到 $0.39$。\n  - $L_{\\text{val}}(e)$ 序列为 $\\{1.04, 0.86, 0.72, 0.63, 0.58, \\mathbf{0.56}, 0.57, 0.60, 0.64, 0.69\\}$。\n  - $L_{\\text{val}}(e)$ 一直下降到第 $e=6$ 轮，此时达到最小值 $0.56$，然后开始增加。这种特有的U形是过拟合的经典标志。模型在 $e=6$ 之后开始记忆噪声标签，这降低了其在干净验证集上的性能。最优的早停点是 $e=6$。\n\n- **对 $p=0.4$ （$40\\%$ 噪声）的分析**：\n  - $L_{\\text{train}}(e)$ 从 $1.00$ 单调递减到 $0.63$。\n  - $L_{\\text{val}}(e)$ 序列为 $\\{1.10, 0.96, 0.90, \\mathbf{0.89}, 0.91, 0.95, 1.00, 1.07, 1.16, 1.26\\}$。\n  - $L_{\\text{val}}(e)$ 一直下降到第 $e=4$ 轮，此时达到最小值 $0.89$，然后急剧增加。与 $p=0.1$ 的情况相比，记忆开始得更早且更严重。最优的早停点是 $e=4$。\n\n### 逐项分析\n\n**A. 对于 $p=0$，在 $10$ 个轮次内没有记忆的证据，因为 $L_{\\text{val}}(e)$ 单调递减；在给定的轮次中，一个合理的早停选择是 $e=10$。**\n- **分析**：$p=0$ 的数据显示 $L_{\\text{val}}(e)$ 在这 $10$ 个轮次中是一个严格递减的序列。这证实了在此时间范围内没有发生过拟合/记忆。具有最佳泛化性能的模型是 $L_{\\text{val}}$ 最低的模型，这出现在最后一个观察到的轮次 $e=10$。该陈述是对数据的正确解释。\n- **结论**：**正确**。\n\n**B. 对于 $p=0.1$，记忆大约在 $L_{\\text{val}}(e)$ 达到最小值然后开始增加，而 $L_{\\text{train}}(e)$ 持续减少的轮次开始；一个合理的早停选择是 $e=6$。**\n- **分析**：对于 $p=0.1$，数据显示 $L_{\\text{train}}(e)$ 是单调递减的。验证损失 $L_{\\text{val}}(e)$ 在 $e=6$ 时达到最小值 $L_{\\text{val}}(6) = 0.56$。此轮次之后，$L_{\\text{val}}(e)$ 增加，表明开始记忆噪声标签。因此，在 $e=6$ 时停止是标准且正确的早停策略。\n- **结论**：**正确**。\n\n**C. 对于 $p=0.4$，记忆比 $p=0.1$ 时开始得更早；一个合理的早停选择是 $e=4$。**\n- **分析**：对于 $p=0.4$，记忆的开始（$L_{\\text{val}}$ 的最小值）是在第 $e=4$ 轮。对于 $p=0.1$，是在第 $e=6$ 轮。由于 $4  6$，对于更高的噪声率，记忆确实开始得更早。第 $e=4$ 轮对应于 $p=0.4$ 时的最小 $L_{\\text{val}}$，使其成为正确的早停点。\n- **结论**：**正确**。\n\n**D. 一个普遍可靠的规则是在训练准确率超过验证准确率的最早轮次停止。**\n- **分析**：该陈述提出了一个基于准确率的规则。就所提供的损失而言，类似的规则是在最早的 $L_{\\text{train}}(e)  L_{\\text{val}}(e)$ 的轮次停止。让我们用我们的数据来检验这个规则：\n    - 对于 $p=0.1$，对所有轮次 $e \\ge 1$ 都有 $L_{\\text{train}}(e)  L_{\\text{val}}(e)$。这个规则会建议在 $e=1$ 停止，这将产生一个次优模型（$L_{\\text{val}}(1)=1.04$），而最优模型在 $e=6$（$L_{\\text{val}}(6)=0.56$）。\n    - 对于 $p=0.4$，同样成立：对所有 $e \\ge 1$ 都有 $L_{\\text{train}}(e)  L_{\\text{val}}(e)$。该规则再次错误地建议在 $e=1$ 停止。\n训练性能优于验证性能的条件在整个训练过程中都很典型，但其本身并不能指示最佳停止点。可靠的指标是验证损失曲线的*转折点*，而不是它与训练损失曲线交叉的点。因此，所提出的规则是不可靠的。\n- **结论**：**不正确**。\n\n**E. 随着 $p$ 的增加，记忆的开始时间在训练中会提前，因此在观察到的曲线下，开始轮次满足 $e_{\\text{onset}}(p=0.4)  e_{\\text{onset}}(p=0.1)  e_{\\text{onset}}(p=0)$。**\n- **分析**：我们将开始轮次 $e_{\\text{onset}}$ 定义为 $L_{\\text{val}}(e)$ 最小化的轮次。\n    - 对于 $p=0.4$，$e_{\\text{onset}}(p=0.4) = 4$。\n    - 对于 $p=0.1$，$e_{\\text{onset}}(p=0.1) = 6$。\n    - 对于 $p=0$，$L_{\\text{val}}(e)$ 在所有 $10$ 个轮次中都是单调递减的，因此记忆尚未开始。因此我们可以说 $e_{\\text{onset}}(p=0) > 10$。\n检查不等式：$e_{\\text{onset}}(p=0.4) = 4  e_{\\text{onset}}(p=0.1) = 6$。第一部分是成立的。并且由于 $e_{\\text{onset}}(p=0) > 10$，那么 $e_{\\text{onset}}(p=0.1) = 6  e_{\\text{onset}}(p=0)$ 也是成立的。整个不等式链基于所提供的数据成立。这与理论上的理解是一致的，即更高比例的噪声会更快地耗尽“容易”学习的模式，迫使模型在更早的轮次开始记忆噪声标签。\n- **结论**：**正确**。",
            "answer": "$$\\boxed{ABCE}$$"
        },
        {
            "introduction": "在诊断出简单的过拟合之后，我们可以探讨一个更微妙的问题：训练与验证数据分布之间的根本性不匹配。这项练习展示了一个因数据增强策略不当而引发的典型问题，其中增强变换破坏了标签不变性。通过分析看似良好但具有误导性的训练损失和不断恶化的验证损失，您将学会如何诊断那些并非源于模型容量，而是源于数据处理流程本身的问题。",
            "id": "3115497",
            "problem": "一个用于图像分类的深度神经网络，在一个标签依赖于主色调类别的数据集上（例如，五个类别分别对应红色、绿色、蓝色、黄色和紫色），使用经验风险最小化进行训练。一位实践者引入了一个仅在训练期间对输入应用随机变换的训练时数据增强流水线。该流水线包括高达 $\\pm 180^\\circ$ 的随机色调偏移、随机水平翻转和轻微的高斯噪声。实践者进行了一个受控的学习曲线实验，并记录了在两种条件下，平均交叉熵训练损失 $L_{\\text{train}}(t)$ 和验证损失 $L_{\\text{val}}(t)$ 随周期 $t$ 的变化：\n\n- 基线（无增强）：到第 $t = 50$ 个周期，$L_{\\text{train}}(t)$ 从 $1.20$ 下降到 $0.60$，$L_{\\text{val}}(t)$ 从 $1.30$ 下降到 $0.80$。\n- 仅在训练期间应用增强：到第 $t = 50$ 个周期，$L_{\\text{train}}(t)$ 从 $1.30$ 下降到 $0.40$，而 $L_{\\text{val}}(t)$ 从 $1.40$ 上升到 $1.10$。\n\n此外，当色调偏移的强度由一个标量参数 $\\alpha \\in [0,1]$ 控制时（其中 $\\alpha = 0$ 表示无色调偏移，$\\alpha = 1$ 表示完整的 $\\pm 180^\\circ$ 范围），实践者观察到，随着 $\\alpha$ 的增加，最终训练损失 $L_{\\text{train}}(50)$ 单调递减，而最终验证损失 $L_{\\text{val}}(50)$ 单调递增。\n\n哪种解释和下一步措施最恰当地诊断和解决了观察到的学习曲线模式？\n\nA. 训练时数据增强包含了不满足标签不变性的变换 $T$，因此增强后的训练分布在标签语义上与验证分布不同。移除或限制此类非不变性变换（例如，消除大的色调偏移），然后重新运行学习曲线。\n\nB. 模型欠拟合；增加模型容量（例如，更多的层或更宽的层）以减少训练和验证损失。\n\nC. 学习率过大；减小学习率以使训练更稳定，这将降低验证损失，同时保持较低的训练损失。\n\nD. 问题仅仅是由于仅在训练时应用增强而导致的协变量偏移；在验证和测试时启用相同的增强，以使分布匹配，并使验证损失与训练损失对齐。",
            "solution": "此问题的分析通过在训练设置的背景下解释提供的学习曲线数据来进行。\n\n1.  **基线分析（无增强）**：基线条件显示出健康的学习趋势。$L_{\\text{train}}$ 和 $L_{\\text{val}}$ 都在下降，表明模型正在学习有意义的模式。最终状态 $L_{\\text{val}}(50) = 0.80  L_{\\text{train}}(50) = 0.60$ 显示出一个小的泛化差距（$0.20$），这是预期的，表明模型对训练数据的拟合略好于验证数据，但仍在很好地泛化。\n\n2.  **增强分析**：增强条件呈现出截然不同的情况。\n    - 最终训练损失 $L_{\\text{train}}(50) = 0.40$，低于基线的训练损失。这表明模型有足够的能力从增强数据中学习。\n    - 验证损失 $L_{\\text{val}}$ 不仅最终高于基线（$1.10$ 对比 $0.80$），而且随时间*增加*。这是一个关键症状。模型正在从增强的训练数据中学习那些对其在原始、未增强的验证数据上的性能有损害的特征。泛化差距巨大且不断增长（$1.10 - 0.40 = 0.70$）。\n\n3.  **识别因果因素**：问题的核心前提是分类任务基于**主色调**。应用的增强包括**高达 $\\pm 180^\\circ$ 的随机色调偏移**。$180^\\circ$ 的色调偏移会将一种颜色转换为其补色（例如，红色变为青色，绿色变为品红色）。数据增强只有在变换是**标签不变**时才有效。也就是说，对于一个变换 $T$ 和一个输入-标签对 $(x, y)$，变换后输入 $T(x)$ 的标签应保持为 $y$。在这个问题中，如果一个主色调为红色的图像 $x$ 的标签为 $y = \\text{\"红色\"}$，应用大的色调偏移会创建一个主色调显著不同的新图像 $T(x)$。然而，增强流水线保留了原始标签，在数据对 $(T(x), \\text{\"红色\"})$ 上训练模型。这违反了标签不变性原则。模型正在一个颜色和标签之间关系被系统性破坏的分布上进行训练。为了最小化训练损失，模型必须学会一个无意义的映射。当这个模型在验证集上评估时，由于颜色是主要的预测特征，其性能很差，并且随着它进一步内化训练集中的错误模式而退化。\n\n4.  **通过参数分析进行确认**：关于色调偏移强度参数 $\\alpha$ 的附加观察提供了决定性的证据。随着 $\\alpha$ 的增加，色调偏移变得更加极端，加剧了对标签不变性的违反。这直接对应于最终训练损失的*减少*和最终验证损失的*增加*。这直接将色调偏移变换与观察到的病态学习行为联系起来。\n\n### 逐项分析选项\n\n**A. 训练时数据增强包含了不满足标签不变性的变换 $T$，因此增强后的训练分布在标签语义上与验证分布不同。移除或限制此类非不变性变换（例如，消除大的色调偏移），然后重新运行学习曲线。**\n- **理由**：此解释正确地指出了根本原因：对于基于颜色的分类任务，大的色调偏移不是一种保持标签的变换。这在增强后的训练数据和原始验证数据之间的条件概率分布 $P(Y|X)$ 上造成了根本性的不匹配。提出的解决方案——移除或限制有问题的变换——是纠正此问题的逻辑上正确的下一步。\n- **结论**：**正确**。\n\n**B. 模型欠拟合；增加模型容量（例如，更多的层或更宽的层）以减少训练和验证损失。**\n- **理由**：这个诊断是不正确的。欠拟合的一个关键标志是高训练损失，表明模型甚至无法拟合训练数据。在这里，增强情况下的最终训练损失非常低（$0.40$）。这表明模型有足够的能力来拟合训练数据。问题在于由于数据不匹配导致的泛化能力差，而不是模型容量不足。\n- **结论**：**不正确**。\n\n**C. 学习率过大；减小学习率以使训练更稳定，这将降低验证损失，同时保持较低的训练损失。**\n- **理由**：过大的学习率通常会导致训练损失不稳定或发散。问题描述的训练损失平稳下降到一个非常低的值，这并非学习率过大的典型特征。证据指向数据问题，而非优化问题。\n- **结论**：**不正确**。\n\n**D. 问题仅仅是由于仅在训练时应用增强而导致的协变量偏移；在验证和测试时启用相同的增强，以使分布匹配，并使验证损失与训练损失对齐。**\n- **理由**：这是对验证集目的的误解。虽然在验证时应用相同的增强会使输入分布 $P(X)$ 匹配，但这将是在评估模型在一个无意义的任务上的性能。验证集的目的是估计模型在它将在生产中遇到的*真实、未经修改的数据分布*上的性能。这个所谓的“修复”只是通过将验证任务重新定义为与训练任务同样有缺陷的任务来掩盖了根本问题。\n- **结论**：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "除了分析学习曲线的整体趋势，训练初期的动态也至关重要，它能揭示优化过程的稳定性。本练习将通过一个确定性的仿真模型，帮助您诊断学习率预热（warmup）阶段的常见问题。通过检查最初几个周期是否存在损失剧增或进展缓慢的迹象，您将学会如何调试优化过程本身，这对于训练大型、敏感的模型是一项关键技能。",
            "id": "3115472",
            "problem": "您将实现并使用一个简单的、确定性的训练动态模拟器，利用学习曲线来诊断学习率预热 (warmup) 的情况。该设置为在一维严格凸二次函数上进行梯度下降，学习率策略为线性增加的预热阶段，然后是恒定学习率。您的程序必须模拟随周期 (epoch) 变化的训练损失，对学习曲线的早期部分应用有原则的诊断方法，并将每种情况分类为预热不足、预热过度或可接受的预热。\n\n基本原理：\n- 考虑损失函数 $L(x) = \\frac{1}{2} a x^{2}$，其曲率 $a > 0$。梯度为 $\\nabla L(x) = a x$。使用学习率 $\\eta_{t}$ 的梯度下降按 $x_{t+1} = x_{t} - \\eta_{t} \\nabla L(x_{t})$ 更新参数。\n- 一个预热长度为 $w$、最大学习率为 $\\eta_{\\max}$ 的线性预热学习率方案由下式给出\n  - $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$，对于整数周期 $t \\in \\{1, 2, \\dots, T\\}$。\n- 观测到的训练损失被确定性地建模为 $y_{t} = L(x_{t}) + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$，其中 $\\sigma \\ge 0$ 且周期参数 $P \\ge 1$。对于 $t = 0$，定义 $y_{0} = L(x_{0})$。\n\n需从基本原理实现的诊断方法：\n- 早期稳定性：定义一个长度为 $K = \\min(5, T)$ 的早期窗口。通过检查是否存在某个 $t \\in \\{1, \\dots, K\\}$ 使得 $y_{t} > (1 + \\tau) \\, y_{t-1}$ 来检测初始发散，阈值 $\\tau = 0.1$。\n- 进展延迟：将在周期 $K$ 前实现的总损失减少部分的比例量化为\n  $$f_{\\text{early}} = \\frac{y_{0} - y_{K}}{\\max(y_{0} - y_{T}, \\varepsilon)},$$\n  其中 $\\varepsilon = 10^{-12}$。如果 $f_{\\text{early}}  \\rho$ (其中 $\\rho = 0.2$)，则判断为进展延迟。\n- 分类规则，按此顺序应用：\n  - 如果在早期窗口中检测到初始发散，则分类为预热不足 (under-warmup) 并输出 $-1$。\n  - 否则，如果检测到进展延迟，则分类为预热过度 (over-warmup) 并输出 $1$。\n  - 否则，分类为可接受的预热 (acceptable warmup) 并输出 $0$。\n\n模拟细节：\n- 用 $x_{0}$ 初始化并计算 $y_{0} = L(x_{0})$。\n- 对于每个周期 $t = 1, 2, \\dots, T$：\n  - 计算 $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$。\n  - 更新 $x_{t} = x_{t-1} - \\eta_{t} a x_{t-1}$。\n  - 计算 $y_{t} = \\frac{1}{2} a x_{t}^{2} + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$。\n\n测试套件：\n为以下参数集提供输出。每个案例是一个元组 $(a, \\eta_{\\max}, w, T, x_{0}, \\sigma, P)$：\n- 案例 A (预期通过极短的预热探测初始发散): $(10.0, 0.25, 1, 40, 1.0, 0.0, 7)$。\n- 案例 B (预期在安全的最大学习率和短预热下为可接受的预热): $(10.0, 0.15, 3, 40, 1.0, 0.0, 7)$。\n- 案例 C (预期在非常长的预热下出现进展延迟): $(10.0, 0.18, 300, 500, 1.0, 0.0, 7)$。\n- 案例 D (预热后处于经典步长稳定性极限边缘的边界稳定性): $(10.0, 0.20, 5, 40, 1.0, 0.0, 7)$。\n- 案例 E (预期在预热结束时因最大学习率过高而出现初始发散): $(12.0, 0.25, 5, 50, 1.0, 0.0, 7)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为按上述测试套件顺序排列的结果。每个条目必须是 $\\{-1, 0, 1\\}$ 中的一个整数，代表该案例的类别，因此输出必须类似于 $[r_{A}, r_{B}, r_{C}, r_{D}, r_{E}]$。\n\n注意：\n- 此问题中没有物理单位。\n- 根据参数 $\\frac{2 \\pi t}{P}$ 的构造，正弦项中的角度单位是弧度。\n- 百分比必须表示为小数，所有阈值 $\\tau$、$\\rho$ 和 $\\varepsilon$ 均以数值形式提供。",
            "solution": "此任务要求模拟一维参数 $x$ 在梯度下降下的训练动态，并对学习率预热方案的行为进行分类。该过程涉及几个相互关联的组成部分：优化数学模型、学习率方案、训练损失的模拟以及一套诊断规则。\n\n首先，我们建立核心优化模型。损失函数是一个简单的凸二次函数，$L(x) = \\frac{1}{2} a x^2$，其中 $a > 0$ 是曲率。该损失函数关于参数 $x$ 的梯度是 $\\nabla L(x) = a x$。梯度下降更新规则在每个周期 $t$ 根据方程 $x_{t} = x_{t-1} - \\eta_{t} \\nabla L(x_{t-1})$ 修改参数 $x$，其中 $\\eta_t$ 是周期 $t$ 的学习率。代入梯度后，具体的更新规则是：\n$$x_{t} = x_{t-1} - \\eta_{t} a x_{t-1} = x_{t-1}(1 - \\eta_{t} a)$$\n此更新在周期 $t = 1, 2, \\dots, T$ 执行。\n\n学习率 $\\eta_t$ 遵循线性预热方案。对于总预热时长为 $w$ 个周期和目标最大学习率为 $\\eta_{\\max}$ 的情况，周期 $t$ 的学习率由下式给出：\n$$\\eta_{t} = \\eta_{\\max} \\cdot \\min\\left(\\frac{t}{w}, 1\\right)$$\n这意味着当 $t \\le w$ 时，$\\eta_t$ 从 $\\eta_1 = \\eta_{\\max}/w$ 线性增加到 $\\eta_w = \\eta_{\\max}$。对于所有随后的周期 $t > w$，学习率保持恒定在 $\\eta_t = \\eta_{\\max}$。\n\n模拟必须追踪随周期变化的训练损失。问题定义了一个观测损失 $y_t$，它由真实损失 $L(x_t)$ 加上一个确定性正弦噪声项组成。初始损失为 $y_0 = L(x_0)$。对于随后的周期 $t \\in \\{1, 2, \\dots, T\\}$，观测损失为：\n$$y_t = L(x_t) + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right) = \\frac{1}{2} a x_t^2 + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right)$$\n模拟过程如下：\n1. 初始化参数 $x_0$ 并计算初始损失 $y_0 = \\frac{1}{2} a x_0^2$。将所有损失值 $y_t$ 存储在一个数组中。\n2. 对于从 $1$ 到 $T$ 的每个周期 $t$：\n   a. 使用预热方案计算学习率 $\\eta_t$。\n   b. 使用梯度下降规则更新参数得到 $x_t$。\n   c. 计算观测损失 $y_t$ 并将其存储。\n\n模拟完成后，我们对生成的学习曲线 $\\{y_t\\}_{t=0}^T$ 应用一系列诊断测试。\n\n第一个诊断是针对 **早期稳定性**。该测试检查初始发散，这是学习率过于激进（即预热不足）的常见症状。我们定义一个 $K = \\min(5, T)$ 个周期的早期窗口。如果在此窗口内的任何时刻，损失的增幅超过了相对阈值 $\\tau = 0.1$，则检测到初始发散。也就是说，如果存在任何 $t \\in \\{1, \\dots, K\\}$ 使得 $y_t > (1 + \\tau) y_{t-1}$，则将预热分类为 `预热不足` ($-1$)。\n\n如果未发现初始发散，则进行第二个诊断，即针对 **进展延迟**。该测试检查学习率是否过于保守（即预热过度），这会导致模型在开始时学习过慢。我们将早期窗口 $K$ 个周期内发生的总损失减少量所占的比例量化为：\n$$f_{\\text{early}} = \\frac{y_0 - y_K}{\\max(y_0 - y_T, \\varepsilon)}$$\n这里，$\\varepsilon = 10^{-12}$ 是一个很小的常数，用于防止在周期 $0$ 到 $T$ 损失不减少时出现除以零的情况。如果这个比例低于阈值 $\\rho = 0.2$，我们判定为进展延迟。然后将预热分类为 `预热过度` ($1$)。\n\n最终的分类遵循严格的顺序。\n1. 如果检测到初始发散，结果为 $-1$。\n2. 否则，如果检测到进展延迟，结果为 $1$。\n3. 否则，预热被认为是 `可接受的`，结果为 $0$。\n\n此过程将应用于提供的每个测试案例，以得出最终分类。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates training dynamics to diagnose learning rate warmup for several test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (a, eta_max, w, T, x0, sigma, P)\n        (10.0, 0.25, 1, 40, 1.0, 0.0, 7),\n        # Case B:\n        (10.0, 0.15, 3, 40, 1.0, 0.0, 7),\n        # Case C:\n        (10.0, 0.18, 300, 500, 1.0, 0.0, 7),\n        # Case D:\n        (10.0, 0.20, 5, 40, 1.0, 0.0, 7),\n        # Case E:\n        (12.0, 0.25, 5, 50, 1.0, 0.0, 7),\n    ]\n\n    results = []\n\n    # Diagnostic thresholds and constants\n    tau = 0.1\n    rho = 0.2\n    epsilon = 1e-12\n\n    for case in test_cases:\n        a, eta_max, w, T, x0, sigma, P = case\n\n        # --- Simulation ---\n        # Initialize arrays for parameter and loss history\n        x_history = np.zeros(T + 1)\n        y_history = np.zeros(T + 1)\n\n        # Initial conditions\n        x_history[0] = x0\n        y_history[0] = 0.5 * a * x_history[0]**2\n\n        # Run the simulation loop for T epochs\n        for t in range(1, T + 1):\n            # Calculate learning rate with linear warmup\n            eta_t = eta_max * min(t / w, 1.0)\n            \n            # Update parameter using gradient descent\n            x_prev = x_history[t-1]\n            x_curr = x_prev * (1 - eta_t * a)\n            x_history[t] = x_curr\n            \n            # Calculate observed loss\n            true_loss = 0.5 * a * x_curr**2\n            noise = sigma * np.sin(2 * np.pi * t / P) if sigma  0 else 0.0\n            y_history[t] = true_loss + noise\n\n        # --- Diagnostics ---\n        K = min(5, T)\n        y0 = y_history[0]\n        yK = y_history[K]\n        yT = y_history[T]\n\n        # 1. Check for early-epoch stability (under-warmup)\n        initial_divergence = False\n        for t in range(1, K + 1):\n            if y_history[t]  (1 + tau) * y_history[t-1]:\n                initial_divergence = True\n                break\n\n        # 2. Check for delayed progress (over-warmup)\n        # This is only checked if no divergence was found.\n        delayed_progress = False\n        if not initial_divergence:\n            denominator = max(y0 - yT, epsilon)\n            f_early = (y0 - yK) / denominator\n            if f_early  rho:\n                delayed_progress = True\n        \n        # 3. Apply classification rule\n        if initial_divergence:\n            results.append(-1)  # Under-warmup\n        elif delayed_progress:\n            results.append(1)   # Over-warmup\n        else:\n            results.append(0)   # Acceptable warmup\n\n    # Print results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}