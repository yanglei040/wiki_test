{
    "hands_on_practices": [
        {
            "introduction": "理论知识需要通过实践来巩固。这个动手实践将探讨一个常见的数据预处理步骤——标签缩放——如何与不同的损失函数相互作用。通过从头开始实现梯度下降，你将亲自观察均方误差（$MSE$）和平均绝对误差（$MAE$）对误差幅度的不同敏感性，并理解这如何影响模型的训练动态。这项练习旨在建立对损失函数行为的基本直觉，并强调了在选择训练目标时考虑其内在属性的重要性。",
            "id": "3168883",
            "problem": "给定一个具有单一输入特征的一维回归模型，其仿射预测器定义为 $y_{\\text{hat},i} = w x_i + b$，其中样本索引 $i \\in \\{1,\\dots,n\\}$。训练使用由乘法常数 $\\alpha \\in \\mathbb{R}$ 缩放后的标签进行，即 $y_i' = \\alpha y_i$。训练损失为均方误差 (MSE)，定义为残差平方的平均值；评估则使用平均绝对误差 (MAE)，定义为相对于原始（未缩放）标签的绝对残差的平均值。具体来说，请使用以下核心定义作为基本依据：\n\n- 均方误差 (MSE): $L_{\\text{MSE}}(w,b) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(y_{\\text{hat},i} - y_i'\\right)^2$。\n- 平均绝对误差 (MAE): $L_{\\text{MAE}}(w,b) = \\frac{1}{n} \\sum_{i=1}^{n} \\left|y_{\\text{hat},i} - y_i\\right|$。\n- 微分链式法则、求和的线性性质以及学习率为 $\\eta$ 的标准梯度下降更新 $[w,b] \\leftarrow [w,b] - \\eta \\nabla L$。\n\n为了计算涉及 $L_{\\text{MAE}}$ 的导数，请采用符号函数的次梯度定义：如果 $z > 0$，则 $\\operatorname{sign}(z) = 1$；如果 $z < 0$，则 $\\operatorname{sign}(z) = -1$；如果 $z=0$，则 $\\operatorname{sign}(0) = 0$。\n\n你的任务如下，且仅能依赖上述基本定义和链式法则：\n\n1. 从第一性原理出发，推导关于参数 $w$ 和 $b$ 的参数空间梯度 $\\nabla L_{\\text{MSE}}(w,b)$ 和一个有效的次梯度 $\\partial L_{\\text{MAE}}(w,b)$。使用这些结果，为下方测试套件中的每个 $\\alpha$ 计算在初始化点 $(w_0,b_0)$ 处每个梯度向量的模（使用欧几里得范数）。其中，MAE 次梯度应相对于缩放后的标签 $y_i'$ 进行计算，以分离标签缩放对两种损失函数梯度模长的影响。具体而言，对每个 $\\alpha$ 计算\n$$\n\\left\\|\\nabla L_{\\text{MSE}}(w_0,b_0; \\alpha y)\\right\\|_2\n\\quad\\text{和}\\quad\n\\left\\|\\partial L_{\\text{MAE}}(w_0,b_0; \\alpha y)\\right\\|_2.\n$$\n\n2. 对于测试套件中的每个 $\\alpha$，使用标签 $y_i' = \\alpha y_i$ 和学习率 $\\eta$，从 $(w_0,b_0)$ 开始，使用 $L_{\\text{MSE}}(w,b)$ 执行梯度下降训练。每次更新后，在原始（未缩放的）标签 $y_i$ 上评估 MAE。当评估的 MAE 小于或等于阈值 $\\tau$ 时，或当迭代次数达到 $\\text{max\\_iters}$ 时停止。记录执行的迭代次数和最终评估的 MAE。在任何需要处理绝对值的地方，均使用上述次梯度约定。\n\n使用以下科学上合理的数据集和参数：\n\n- 样本数量: $n = 6$。\n- 特征: $x = [-2,-1,0,1,2,3]$。\n- 标签: $y = [ -3.4,-1.7,0.5,2.7,4.4,6.8 ]$，其遵循 $y_i = 2 x_i + 0.5 + \\varepsilon_i$，其中确定性噪声为 $\\varepsilon = [0.1,-0.2,0.0,0.2,-0.1,0.3]$。\n- 初始化: $(w_0,b_0) = (0.0,0.0)$。\n- 学习率: $\\eta = 0.01$。\n- 评估阈值: $\\tau = 0.25$。\n- 最大迭代次数: $\\text{max\\_iters} = 3000$。\n\n测试套件（覆盖一般情况、边界条件和边缘情况）: $\\alpha \\in [1.0, 0.0, -2.0, 10.0]$。\n\n你的程序必须：\n\n- 对于测试套件中的每个 $\\alpha$，计算：\n    1. 在 $y' = \\alpha y$ 上的 MSE 在初始化时的梯度模长。\n    2. 在 $y' = \\alpha y$ 上的 MAE 在初始化时的梯度模长（使用次梯度符号约定）。\n    3. 当使用 $L_{\\text{MSE}}(w,b)$ 在 $y' = \\alpha y$ 上训练时，达到 $L_{\\text{MAE}}(w,b) \\le \\tau$ 所需的梯度下降迭代次数，如果未达到该阈值则为 $\\text{max\\_iters}$。\n    4. 停止后最终评估的 $L_{\\text{MAE}}(w,b)$。\n\n- 生成单行输出，其中包含用方括号括起来的结果，结果是一个逗号分隔的列表。每个内部列表也采用同样格式且不含空格。每个内部列表必须按 $[\\alpha,\\text{grad\\_mse\\_norm\\_init},\\text{grad\\_mae\\_norm\\_init},\\text{iterations},\\text{final\\_mae}]$ 的顺序排列。例如：$[[\\alpha_1,g_1,h_1,i_1,m_1],[\\alpha_2,g_2,h_2,i_2,m_2],\\dots]$。所有数值条目必须以原始小数或整数形式打印（无单位，无百分号）。",
            "solution": "该问题要求对一个简单的线性回归模型进行两部分分析。首先，我们必须从第一性原理出发，推导均方误差 (MSE) 损失函数的梯度和平均绝对误差 (MAE) 损失函数的次梯度。其次，我们必须模拟一个在 MSE 损失上使用梯度下降的训练过程，并在不同的标签缩放条件下使用 MAE 评估其性能。\n\n### 第 1 部分：梯度与次梯度推导\n\n给定一个仿射预测器 $y_{\\text{hat},i} = w x_i + b$。训练在缩放后的标签 $y_i' = \\alpha y_i$ 上进行。\n\n**均方误差 (MSE) 损失的梯度**\n\nMSE 损失函数定义为：\n$$\nL_{\\text{MSE}}(w,b) = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{hat},i} - y_i')^2 = \\frac{1}{n} \\sum_{i=1}^{n} (w x_i + b - y_i')^2\n$$\n为了求得梯度 $\\nabla L_{\\text{MSE}}(w,b)$，我们计算关于参数 $w$ 和 $b$ 的偏导数。\n\n关于 $w$ 的偏导数可以通过使用导数的线性性质和链式法则求得：\n$$\n\\frac{\\partial L_{\\text{MSE}}}{\\partial w} = \\frac{\\partial}{\\partial w} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} (w x_i + b - y_i')^2 \\right] = \\frac{1}{n} \\sum_{i=1}^{n} 2(w x_i + b - y_i') \\cdot \\frac{\\partial}{\\partial w}(w x_i + b)\n$$\n$$\n\\frac{\\partial L_{\\text{MSE}}}{\\partial w} = \\frac{2}{n} \\sum_{i=1}^{n} (y_{\\text{hat},i} - y_i') x_i\n$$\n\n类似地，关于 $b$ 的偏导数为：\n$$\n\\frac{\\partial L_{\\text{MSE}}}{\\partial b} = \\frac{\\partial}{\\partial b} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} (w x_i + b - y_i')^2 \\right] = \\frac{1}{n} \\sum_{i=1}^{n} 2(w x_i + b - y_i') \\cdot \\frac{\\partial}{\\partial b}(w x_i + b)\n$$\n$$\n\\frac{\\partial L_{\\text{MSE}}}{\\partial b} = \\frac{2}{n} \\sum_{i=1}^{n} (y_{\\text{hat},i} - y_i')\n$$\n因此，梯度向量为：\n$$\n\\nabla L_{\\text{MSE}}(w,b) = \\begin{bmatrix} \\frac{2}{n} \\sum_{i=1}^{n} (y_{\\text{hat},i} - y_i') x_i \\\\ \\frac{2}{n} \\sum_{i=1}^{n} (y_{\\text{hat},i} - y_i') \\end{bmatrix}\n$$\n\n**平均绝对误差 (MAE) 损失的次梯度**\n\n问题要求我们计算 MAE 次梯度关于缩放后标签 $y_i'$ 的模长。MAE 损失为：\n$$\nL_{\\text{MAE}}(w,b) = \\frac{1}{n} \\sum_{i=1}^{n} |y_{\\text{hat},i} - y_i'| = \\frac{1}{n} \\sum_{i=1}^{n} |w x_i + b - y_i'|\n$$\n绝对值函数 $|z|$ 的导数在 $z=0$ 处未定义。我们使用次梯度，即所有有效斜率的集合。对于 $|z|$，其次梯度 $\\partial|z|$ 在 $z \\neq 0$ 时为 $\\operatorname{sign}(z)$，在 $z=0$ 时为区间 $[-1, 1]$。问题指定使用约定 $\\operatorname{sign}(0) = 0$，这会在 $z=0$ 时从次梯度集合中选择一个特定元素。\n\n使用次梯度的链式法则，$L_{\\text{MAE}}$ 关于其参数的一个有效次梯度为：\n$$\n\\partial L_{\\text{MAE}}(w,b) = \\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{sign}(w x_i + b - y_i') \\cdot \\nabla(w x_i + b)\n$$\n关于 $w$ 的偏次导数为：\n$$\n\\frac{\\partial L_{\\text{MAE}}}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{sign}(y_{\\text{hat},i} - y_i') \\cdot x_i\n$$\n关于 $b$ 的偏次导数为：\n$$\n\\frac{\\partial L_{\\text{MAE}}}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{sign}(y_{\\text{hat},i} - y_i')\n$$\n因此，一个次梯度向量为：\n$$\n\\partial L_{\\text{MAE}}(w,b) = \\begin{bmatrix} \\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{sign}(y_{\\text{hat},i} - y_i') x_i \\\\ \\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{sign}(y_{\\text{hat},i} - y_i') \\end{bmatrix}\n$$\n\n**初始梯度模长**\n\n在初始化时，$(w_0, b_0) = (0.0, 0.0)$。预测值为 $y_{\\text{hat},i} = 0 \\cdot x_i + 0 = 0$。用于计算梯度的残差为 $y_{\\text{hat},i} - y_i' = -\\alpha y_i$。\n\n对于 MSE，初始化时的梯度分量为：\n$$\n\\frac{\\partial L_{\\text{MSE}}}{\\partial w}\\bigg|_{(w_0,b_0)} = \\frac{2}{n} \\sum_{i=1}^{n} (-\\alpha y_i) x_i = -\\frac{2\\alpha}{n} \\sum_{i=1}^{n} y_i x_i\n$$\n$$\n\\frac{\\partial L_{\\text{MSE}}}{\\partial b}\\bigg|_{(w_0,b_0)} = \\frac{2}{n} \\sum_{i=1}^{n} (-\\alpha y_i) = -\\frac{2\\alpha}{n} \\sum_{i=1}^{n} y_i\n$$\n梯度的欧几里得范数为：\n$$\n\\|\\nabla L_{\\text{MSE}}(w_0,b_0)\\|_2 = \\sqrt{\\left(-\\frac{2\\alpha}{n} \\sum y_i x_i\\right)^2 + \\left(-\\frac{2\\alpha}{n} \\sum y_i\\right)^2} = \\frac{2|\\alpha|}{n} \\sqrt{\\left(\\sum y_i x_i\\right)^2 + \\left(\\sum y_i\\right)^2}\n$$\n这表明初始化时 MSE 梯度的模长与缩放因子 $|\\alpha|$ 的绝对值成正比。\n\n对于 MAE，初始化时的次梯度分量为：\n$$\n\\frac{\\partial L_{\\text{MAE}}}{\\partial w}\\bigg|_{(w_0,b_0)} = \\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{sign}(-\\alpha y_i) x_i = -\\frac{\\operatorname{sign}(\\alpha)}{n} \\sum_{i=1}^{n} \\operatorname{sign}(y_i) x_i\n$$\n$$\n\\frac{\\partial L_{\\text{MAE}}}{\\partial b}\\bigg|_{(w_0,b_0)} = \\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{sign}(-\\alpha y_i) = -\\frac{\\operatorname{sign}(\\alpha)}{n} \\sum_{i=1}^{n} \\operatorname{sign}(y_i)\n$$\n（假设没有 $y_i=0$ 且 $\\alpha \\neq 0$）。其范数为：\n$$\n\\|\\partial L_{\\text{MAE}}(w_0,b_0)\\|_2 = \\frac{|\\operatorname{sign}(\\alpha)|}{n} \\sqrt{\\left(\\sum \\operatorname{sign}(y_i) x_i\\right)^2 + \\left(\\sum \\operatorname{sign}(y_i)\\right)^2}\n$$\n对于 $\\alpha \\neq 0$，$|\\operatorname{sign}(\\alpha)|=1$，因此无论 $\\alpha$ 的值如何，其模长都是恒定的。对于 $\\alpha=0$，梯度为零向量，其模长为 $0$。MAE 梯度模长对误差尺度不敏感（只要符号保持不变），这是与 MSE 的一个关键区别。\n\n### 第 2 部分：梯度下降模拟逻辑\n\n该模拟将对测试套件中的每个 $\\alpha$ 值执行梯度下降。核心算法如下：\n1. 初始化参数 $(w,b) = (0.0, 0.0)$。\n2. 对于每次迭代，直到最大迭代次数 $\\text{max\\_iters}$：\n   a. 计算预测值 $y_{\\text{hat}} = w x + b$。\n   b. 使用缩放后的标签 $y' = \\alpha y$ 计算 MSE 损失的梯度 $\\nabla L_{\\text{MSE}}$。\n   c. 使用梯度下降规则更新参数：$[w,b] \\leftarrow [w,b] - \\eta \\nabla L_{\\text{MSE}}$。\n   d. 使用原始（未缩放的）标签 $y$ 评估 MAE，$L_{\\text{MAE}} = \\frac{1}{n} \\sum |y_{\\text{hat},i} - y_i|$。\n   e. 如果 $L_{\\text{MAE}} \\le \\tau$，则终止当前 $\\alpha$ 的处理过程。\n3. 记录迭代次数和最终的 MAE。\n\n我们预期会出现以下行为：\n- 对于 $\\alpha=1.0$，训练目标与评估指标一致（除了 MSE 和 MAE 最小值之间的差异），因此我们预期会收敛到一个较低的 MAE。\n- 对于 $\\alpha=0.0$，缩放后的标签全为零。初始梯度为零，因此不会发生学习。该过程将运行 $\\text{max\\_iters}$ 次迭代。\n- 对于 $\\alpha=-2.0$ 和 $\\alpha=10.0$，模型被训练来拟合一个相对于真实数据被错误缩放的目标。学习到的参数 $(w,b)$ 对缩放后的问题将是最优的，但在用原始标签评估时会产生很大的误差。因此，MAE 预计不会降至阈值 $\\tau$ 以下，模拟将运行 $\\text{max\\_iters}$ 次迭代。\n\n以下程序实现了这一逻辑，以计算每个 $\\alpha$ 所需的指标。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the regression problem by deriving gradients, running simulations,\n    and reporting the results as specified.\n    \"\"\"\n    # Dataset and parameters\n    x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0, 3.0])\n    y = np.array([-3.4, -1.7, 0.5, 2.7, 4.4, 6.8])\n    n = len(x)\n    w0, b0 = 0.0, 0.0\n    eta = 0.01\n    tau = 0.25\n    max_iters = 3000\n    \n    test_suite_alpha = [1.0, 0.0, -2.0, 10.0]\n    \n    results = []\n\n    for alpha in test_suite_alpha:\n        # --- Task 1: Compute initial gradient magnitudes ---\n        \n        y_prime = alpha * y\n        \n        # Initial predictions\n        y_hat_init = w0 * x + b0\n        \n        # Residuals for gradient calculation\n        residuals_init = y_hat_init - y_prime\n        \n        # MSE gradient at initialization\n        grad_mse_w_init = (2 / n) * np.sum(residuals_init * x)\n        grad_mse_b_init = (2 / n) * np.sum(residuals_init)\n        grad_mse_norm_init = np.sqrt(grad_mse_w_init**2 + grad_mse_b_init**2)\n        \n        # MAE subgradient at initialization (with sign(0)=0 convention)\n        signs = np.sign(residuals_init)\n        grad_mae_w_init = (1 / n) * np.sum(signs * x)\n        grad_mae_b_init = (1 / n) * np.sum(signs)\n        grad_mae_norm_init = np.sqrt(grad_mae_w_init**2 + grad_mae_b_init**2)\n\n        # --- Task 2: Gradient Descent Training ---\n        \n        w, b = w0, b0\n        iterations_performed = 0\n        \n        for i in range(1, max_iters + 1):\n            iterations_performed = i\n            \n            # Predictions\n            y_hat = w * x + b\n            \n            # MSE Gradients using scaled labels y_prime\n            residuals_mse = y_hat - y_prime\n            grad_w = (2 / n) * np.sum(residuals_mse * x)\n            grad_b = (2 / n) * np.sum(residuals_mse)\n            \n            # Update parameters\n            w -= eta * grad_w\n            b -= eta * grad_b\n            \n            # Evaluate MAE on original labels y\n            current_mae = np.mean(np.abs((w * x + b) - y))\n            \n            # Check stopping condition\n            if current_mae <= tau:\n                break\n        \n        # Final evaluated MAE on original labels\n        final_mae = np.mean(np.abs((w * x + b) - y))\n        \n        results.append([\n            alpha,\n            grad_mse_norm_init,\n            grad_mae_norm_init,\n            iterations_performed,\n            final_mae\n        ])\n    \n    # Format output as specified\n    output_str = \"[\" + \",\".join(\n        f\"[{','.join(map(str, row))}]\" for row in results\n    ) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在许多现实世界的场景中，我们用来训练模型的目标（例如，$MSE$）可能与我们最终用来评估其性能的指标（例如，$MAE$）不完全一致，尤其是在数据包含离群值时。这个练习将引导你设计一个受控实验，以量化这种“优化-评估不匹配”问题。你将实现一个对离群值更鲁棒的$MAE$可微代理损失函数（log-cosh损失），并与传统的$MSE$进行比较，从而学习如何设计一个与最终评估目标更紧密对齐的训练目标。",
            "id": "3168805",
            "problem": "给定一个经验风险最小化框架下的监督回归问题。设数据集为 $D = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$，其中 $\\mathbf{x}_i \\in \\mathbb{R}^d$。对于一个参数为 $(\\mathbf{w}, b)$ 的线性模型，其预测值为 $\\hat{y}_i = \\mathbf{w}^\\top \\mathbf{x}_i + b$，定义残差为 $r_i = y_i - \\hat{y}_i$。任务是设计并实现一个受控实验，该实验量化了当使用均方误差 (MSE) 进行训练但使用平均绝对误差 (MAE) 进行评估时，优化指标与评估指标之间的不匹配程度。同时，将此情况与使用基于双曲余弦对数的 MAE 可微代理进行训练的情况进行比较。\n\n使用的基本原理和定义：\n- 经验风险最小化 (ERM) 旨在最小化作用于残差 $r_i$ 的非负损失的经验平均值。\n- 均方误差 (MSE) 是由训练集上 $r_i^2$ 的平均值给出的经验风险。\n- 平均绝对误差 (MAE) 是由数据集上 $|r_i|$ 的平均值给出的经验风险。\n- 提出的 MAE 可微代理是双曲余弦的对数，即函数 $r \\mapsto \\log(\\cosh(r / \\tau))$，其中 $\\tau$ 是一个正的尺度参数，用于控制从二次行为到线性行为的过渡。\n\n实验设计和所需步骤：\n1. 从第一性原理生成数据：\n   - 固定一个在 $d=3$ 维空间中的真实线性数据生成过程，其确定性参数向量为 $\\mathbf{w}^\\star = [2.0, -3.0, 0.5]^\\top$，截距为 $b^\\star = 0.7$。对每个样本，独立抽取 $\\mathbf{x}_i$，其坐标是独立的标准正态分布。计算纯净目标值 $y_i^{\\text{clean}} = (\\mathbf{w}^\\star)^\\top \\mathbf{x}_i + b^\\star$。\n   - 向每个纯净目标值添加独立噪声 $\\epsilon_i$ 以生成 $y_i = y_i^{\\text{clean}} + \\epsilon_i$。该噪声从一个模拟离群点的混合模型中抽取：以 $1 - p_{\\text{out}}$ 的概率，从 $\\mathcal{N}(0, \\sigma^2)$ 中抽取 $\\epsilon_i$；以 $p_{\\text{out}}$ 的概率，从 $\\mathcal{N}(0, (\\sigma \\cdot s_{\\text{out}})^2)$ 中抽取 $\\epsilon_i$。这里 $p_{\\text{out}} \\in [0, 1)$ 是离群点率，$\\sigma > 0$ 是基础噪声尺度，$s_{\\text{out}} \\ge 1$ 是离群点尺度因子。\n   - 将独立生成的数据划分为大小为 $n_{\\text{train}}$ 的训练集和大小为 $n_{\\text{test}}$ 的测试集，两者均由相同的过程和相同的参数生成。\n2. 要实现并使用梯度下降法最小化的训练目标：\n   - 训练一个线性模型 $(\\mathbf{w}, b)$，通过梯度下降法最小化训练集上的经验 MSE。从零初始化开始，使用固定的学习率和固定的全批量轮次数。仅使用 ERM 原理和微积分来推导参数更新所需的梯度。\n   - 训练另一个线性模型 $(\\tilde{\\mathbf{w}}, \\tilde{b})$，通过梯度下降法最小化训练集上 $\\log(\\cosh(r / \\tau))$ 的经验平均值。使用相同的初始化和相同的优化超参数，以及给定的正数 $\\tau$。同样，仅使用 ERM 原理和微积分来推导参数更新所需的梯度。\n3. 评估指标和不匹配量化：\n   - 对每个训练好的模型，计算其在测试集上的 MAE，即测试集上 $|r_i|$ 的经验平均值。对于使用均方误差训练的模型和使用 $\\log(\\cosh(\\cdot))$ 代理训练的模型，分别将这些值表示为 $\\text{MAE}_{\\text{MSE}}$ 和 $\\text{MAE}_{\\log\\cosh}$。\n   - 通过两种方式量化优化-评估不匹配：绝对差距 $\\Delta = \\text{MAE}_{\\text{MSE}} - \\text{MAE}_{\\log\\cosh}$ 和比率 $\\rho = \\text{MAE}_{\\text{MSE}} / \\text{MAE}_{\\log\\cosh}$。如果 $\\text{MAE}_{\\log\\cosh} = 0$，则定义 $\\rho = 1.0$ 以避免除以零。\n4. 实现约束：\n   - 使用下面指定的种子初始化伪随机数生成器，将整个实验实现为一个确定性程序。使用全批量梯度下降，而非随机方法。仅使用 ERM 所蕴含的基础线性代数和微积分；不要依赖外部优化库。\n   - 对每个测试用例，输出一个包含4个浮点数的列表 $[\\text{MAE}_{\\text{MSE}}, \\text{MAE}_{\\log\\cosh}, \\Delta, \\rho]$，每个浮点数四舍五入到6位小数。\n\n测试套件：\n在以下参数集上运行您的程序，每个参数集都如上所述独立生成训练和测试数据：\n- 情况 A (理想情况，无离群点)：随机种子 $0$，训练集大小 $n_{\\text{train}} = 512$，测试集大小 $n_{\\text{test}} = 2048$，基础噪声 $\\sigma = 0.5$，离群点率 $p_{\\text{out}} = 0.0$，离群点尺度 $s_{\\text{out}} = 10.0$，学习率 $\\eta = 0.05$，轮次 $300$，代理尺度 $\\tau = 1.0$。\n- 情况 B (中度离群点)：随机种子 $1$，训练集大小 $n_{\\text{train}} = 512$，测试集大小 $n_{\\text{test}} = 2048$，基础噪声 $\\sigma = 0.5$，离群点率 $p_{\\text{out}} = 0.2$，离群点尺度 $s_{\\text{out}} = 8.0$，学习率 $\\eta = 0.05$，轮次 $300$，代理尺度 $\\tau = 1.0$。\n- 情况 C (更多离群点，不同尺度)：随机种子 $2$，训练集大小 $n_{\\text{train}} = 256$，测试集大小 $n_{\\text{test}} = 4096$，基础噪声 $\\sigma = 0.2$，离群点率 $p_{\\text{out}} = 0.3$，离群点尺度 $s_{\\text{out}} = 12.0$，学习率 $\\eta = 0.05$，轮次 $400$，代理尺度 $\\tau = 0.5$。\n- 情况 D (小样本边缘情况)：随机种子 $3$，训练集大小 $n_{\\text{train}} = 16$，测试集大小 $n_{\\text{test}} = 4096$，基础噪声 $\\sigma = 0.5$，离群点率 $p_{\\text{out}} = 0.25$，离群点尺度 $s_{\\text{out}} = 10.0$，学习率 $\\eta = 0.03$，轮次 $600$，代理尺度 $\\tau = 1.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个按用例划分的结果列表，每个用例贡献一个包含四个四舍五入浮点数的列表，顺序为 $[\\text{MAE}_{\\text{MSE}}, \\text{MAE}_{\\log\\cosh}, \\Delta, \\rho]$。顶层列表必须按 A、B、C、D 的顺序连接各用例的结果，并使用逗号且不带空格。例如，一个有效的形状和格式为\n$[[a_1,a_2,a_3,a_4],[b_1,b_2,b_3,b_4],[c_1,c_2,c_3,c_4],[d_1,d_2,d_3,d_4]]$\n其中每个 $a_j, b_j, c_j, d_j$ 都是四舍五入到6位小数的浮点数。",
            "solution": "用户提供的问题是有效的，因为它具有科学依据、是良定的且客观的。它在监督机器学习领域内概述了一个详细且可形式化的数值实验，并指定了所有必要的参数和条件。该问题是一项实质性任务，要求基于经验风险最小化的第一性原理，实现数据生成、基于梯度的优化和评估。\n\n该问题要求进行一个受控实验，以探究优化指标（均方误差，MSE）和评估指标（平均绝对误差，MAE）之间的不匹配，尤其是在存在离群点的情况下。这与使用 MAE 的可微代理——双曲余弦的对数（$\\log(\\cosh)$）作为优化指标的情况形成对比。被检验的核心原则是，当优化目标与评估指标更紧密地对齐时，可以获得更好的性能，尤其是当数据的噪声特性违反了标准目标的隐式假设时。\n\n### 1. 实验设计与数据生成\n\n该实验基于一个从已知线性过程生成的合成数据集，这允许进行受控分析。真实模型由参数 $\\mathbf{w}^\\star \\in \\mathbb{R}^d$ 和 $b^\\star \\in \\mathbb{R}$ 定义，维度为 $d=3$。数据点 $(\\mathbf{x}_i, y_i)$ 的生成方式如下：\n- 特征 $\\mathbf{x}_i \\in \\mathbb{R}^3$ 从标准正态分布中抽取，即每个分量 $x_{ij} \\sim \\mathcal{N}(0, 1)$。\n- 真实目标值计算为 $y_i^{\\text{clean}} = (\\mathbf{w}^\\star)^\\top \\mathbf{x}_i + b^\\star$。\n- 观测目标值 $y_i$ 是通过向纯净目标值添加噪声 $\\epsilon_i$ 创建的：$y_i = y_i^{\\text{clean}} + \\epsilon_i$。\n- 噪声 $\\epsilon_i$ 从一个用于模拟离群点的混合模型中抽取。以 $1 - p_{\\text{out}}$ 的概率，噪声来自基线正态分布 $\\mathcal{N}(0, \\sigma^2)$。以 $p_{\\text{out}}$ 的概率，噪声来自一个高方差正态分布 $\\mathcal{N}(0, (\\sigma \\cdot s_{\\text{out}})^2)$，代表离群点。参数 $p_{\\text{out}}$、$\\sigma$ 和 $s_{\\text{out}}$ 分别控制这些离群点的比率、基础尺度和幅度。\n\n此过程用于生成一个大小为 $n_{\\text{train}}$ 的独立训练集和一个大小为 $n_{\\text{test}}$ 的测试集。\n\n### 2. 通过经验风险最小化进行优化\n\n一个带有参数 $(\\mathbf{w}, b)$ 的线性模型提供预测值 $\\hat{y}_i = \\mathbf{w}^\\top \\mathbf{x}_i + b$。目标是通过最小化训练集上选定损失函数的经验平均值来找到最优参数。这通过全批量梯度下降来完成，其中参数根据总损失的梯度进行迭代更新。\n\n#### 场景1：使用均方误差 (MSE) 进行训练\nMSE 损失由残差的平方定义，$L_{\\text{MSE}}(r_i) = r_i^2 = (y_i - \\hat{y}_i)^2$。总经验风险为：\n$$J_{\\text{MSE}}(\\mathbf{w}, b) = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} (y_i - (\\mathbf{w}^\\top \\mathbf{x}_i + b))^2$$\n为了使用梯度下降最小化该风险，我们需要它关于参数 $\\mathbf{w}$ 和 $b$ 的偏导数。令 $r_i = y_i - \\hat{y}_i$ 为残差。\n梯度为：\n$$ \\nabla_{\\mathbf{w}} J_{\\text{MSE}} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} 2(y_i - \\hat{y}_i)(-\\mathbf{x}_i) = -\\frac{2}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} r_i \\mathbf{x}_i $$\n$$ \\nabla_{b} J_{\\text{MSE}} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} 2(y_i - \\hat{y}_i)(-1) = -\\frac{2}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} r_i $$\nMSE 损失函数中的平方项使其对大残差高度敏感，这意味着离群点会不成比例地影响最终的模型参数。\n\n#### 场景2：使用 Log-Cosh 代理进行训练\nlog-cosh 损失是 MAE 损失的一个平滑近似，定义为 $L_{\\log\\cosh}(r_i) = \\log(\\cosh(r_i / \\tau))$，其中 $\\tau > 0$ 是一个尺度参数。经验风险为：\n$$J_{\\log\\cosh}(\\tilde{\\mathbf{w}}, \\tilde{b}) = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\log\\left(\\cosh\\left(\\frac{y_i - (\\tilde{\\mathbf{w}}^\\top \\mathbf{x}_i + \\tilde{b})}{\\tau}\\right)\\right)$$\n对于小残差 ($|r_i| \\ll \\tau$)，该函数表现为二次函数（类似 MSE），对于大残差 ($|r_i| \\gg \\tau$)，则表现为线性函数（类似 MAE），这使其对离群点更具鲁棒性。梯度使用链式法则和恒等式 $\\frac{d}{dz}\\log(\\cosh(z)) = \\tanh(z)$ 推导得出：\n$$ \\nabla_{\\tilde{\\mathbf{w}}} J_{\\log\\cosh} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) \\frac{1}{\\tau} (-\\mathbf{x}_i) = -\\frac{1}{n_{\\text{train}}\\tau} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) \\mathbf{x}_i $$\n$$ \\nabla_{\\tilde{b}} J_{\\log\\cosh} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) \\frac{1}{\\tau} (-1) = -\\frac{1}{n_{\\text{train}}\\tau} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) $$\n使用双曲正切函数 $\\tanh(\\cdot)$ 可以“压缩”大残差的影响，从而提供所需的鲁棒性。\n\n对于这两种场景，参数都初始化为零，并使用学习率为 $\\eta$ 的梯度下降法则 $\\boldsymbol{\\theta}_{t+1} \\leftarrow \\boldsymbol{\\theta}_t - \\eta \\nabla_{\\boldsymbol{\\theta}} J$ 更新固定的轮次数，其中 $\\boldsymbol{\\theta}$ 代表参数对 $(\\mathbf{w}, b)$ 或 $(\\tilde{\\mathbf{w}}, \\tilde{b})$。\n\n### 3. 评估与不匹配量化\n\n训练后，两个模型都在独立生成的测试集上进行评估。性能指标是平均绝对误差 (MAE)，这是我们最终关注的指标。\n$$ \\text{MAE} = \\frac{1}{n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} |y_i - \\hat{y}_i| $$\n我们计算使用 MSE 训练的模型的 $\\text{MAE}_{\\text{MSE}}$ 和使用 log-cosh 代理训练的模型的 $\\text{MAE}_{\\log\\cosh}$。然后通过两个指标来量化优化目标和评估目标之间的不匹配：\n1.  绝对差距：$\\Delta = \\text{MAE}_{\\text{MSE}} - \\text{MAE}_{\\log\\cosh}$\n2.  比率：$\\rho = \\text{MAE}_{\\text{MSE}} / \\text{MAE}_{\\log\\cosh}$\n\n正的 $\\Delta$ 和大于 1 的比率 $\\rho$ 表明，使用鲁棒的 log-cosh 代理进行训练所得到的模型，在 MAE 评估指标上表现更好，从而减轻了优化-评估不匹配。预计这种效应在存在离群点的情况下（即 $p_{\\text{out}} > 0$ 时）会更加显著。\n\n该实验将以编程方式实现，遵守每个测试用例的指定参数，并通过使用带种子的伪随机数生成器来确保确定性和可复现的结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the series of experiments and print the final results.\n    \"\"\"\n    # Define the true parameters for data generation\n    w_star = np.array([2.0, -3.0, 0.5])\n    b_star = 0.7\n    d = 3\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: happy path, no outliers\n        {'seed': 0, 'n_train': 512, 'n_test': 2048, 'sigma': 0.5, 'p_out': 0.0, 's_out': 10.0, 'eta': 0.05, 'epochs': 300, 'tau': 1.0},\n        # Case B: moderate outliers\n        {'seed': 1, 'n_train': 512, 'n_test': 2048, 'sigma': 0.5, 'p_out': 0.2, 's_out': 8.0, 'eta': 0.05, 'epochs': 300, 'tau': 1.0},\n        # Case C: heavier outliers, different scale\n        {'seed': 2, 'n_train': 256, 'n_test': 4096, 'sigma': 0.2, 'p_out': 0.3, 's_out': 12.0, 'eta': 0.05, 'epochs': 400, 'tau': 0.5},\n        # Case D: small-sample edge case\n        {'seed': 3, 'n_train': 16, 'n_test': 4096, 'sigma': 0.5, 'p_out': 0.25, 's_out': 10.0, 'eta': 0.03, 'epochs': 600, 'tau': 1.0},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = run_experiment(w_star, b_star, d, **params)\n        all_results.append(result)\n\n    # Format the final output string exactly as required.\n    # e.g., [[val1,val2,val3,val4],[val1,val2,val3,val4],...]\n    results_str = ','.join([f\"[{','.join(map(str, [round(v, 6) for v in res]))}]\" for res in all_results])\n    print(f\"[{results_str}]\")\n\ndef generate_data(n_samples, d, w_star, b_star, sigma, p_out, s_out, rng):\n    \"\"\"\n    Generates synthetic data from a linear model with mixed Gaussian noise.\n    \"\"\"\n    X = rng.standard_normal(size=(n_samples, d))\n    y_clean = X @ w_star + b_star\n\n    # Generate noise from the mixture model\n    is_outlier = rng.uniform(size=n_samples) < p_out\n    noise_std = np.where(is_outlier, sigma * s_out, sigma)\n    noise = rng.normal(loc=0.0, scale=noise_std)\n    \n    y = y_clean + noise\n    return X, y\n\ndef train(X_train, y_train, loss_type, eta, epochs, tau=None):\n    \"\"\"\n    Trains a linear model using full-batch gradient descent.\n    \"\"\"\n    n_train, d = X_train.shape\n    w = np.zeros(d)\n    b = 0.0\n\n    for _ in range(epochs):\n        predictions = X_train @ w + b\n        residuals = y_train - predictions\n\n        if loss_type == 'mse':\n            grad_w = (-2 / n_train) * (X_train.T @ residuals)\n            grad_b = (-2 / n_train) * np.sum(residuals)\n        elif loss_type == 'logcosh':\n            if tau is None:\n                raise ValueError(\"tau must be provided for logcosh loss\")\n            tanh_term = np.tanh(residuals / tau)\n            grad_w = (-1 / (n_train * tau)) * (X_train.T @ tanh_term)\n            grad_b = (-1 / (n_train * tau)) * np.sum(tanh_term)\n        else:\n            raise ValueError(f\"Unknown loss type: {loss_type}\")\n\n        w -= eta * grad_w\n        b -= eta * grad_b\n    \n    return w, b\n\ndef evaluate_mae(X_test, y_test, w, b):\n    \"\"\"\n    Evaluates the Mean Absolute Error of a model on the test set.\n    \"\"\"\n    y_pred = X_test @ w + b\n    mae = np.mean(np.abs(y_test - y_pred))\n    return mae\n\ndef run_experiment(w_star, b_star, d, seed, n_train, n_test, sigma, p_out, s_out, eta, epochs, tau):\n    \"\"\"\n    Runs a single experimental case: data generation, training, and evaluation.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Generate training and test data\n    X_train, y_train = generate_data(n_train, d, w_star, b_star, sigma, p_out, s_out, rng)\n    X_test, y_test = generate_data(n_test, d, w_star, b_star, sigma, p_out, s_out, rng)\n\n    # Train model 1: Minimize MSE\n    w_mse, b_mse = train(X_train, y_train, loss_type='mse', eta=eta, epochs=epochs)\n    \n    # Train model 2: Minimize LogCosh loss\n    w_logcosh, b_logcosh = train(X_train, y_train, loss_type='logcosh', eta=eta, epochs=epochs, tau=tau)\n\n    # Evaluate both models on the test set using MAE\n    mae_mse = evaluate_mae(X_test, y_test, w_mse, b_mse)\n    mae_logcosh = evaluate_mae(X_test, y_test, w_logcosh, b_logcosh)\n\n    # Quantify the mismatch\n    delta = mae_mse - mae_logcosh\n    \n    if mae_logcosh == 0:\n        rho = 1.0\n    else:\n        rho = mae_mse / mae_logcosh\n        \n    return [mae_mse, mae_logcosh, delta, rho]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "回归任务不仅限于预测单个点估计值；预测一系列可能结果的范围（即概率性预测）通常更有价值。本练习将你带入分位数回归的世界，这是一种生成此类预测区间的强大技术。你将从“非对称成本”这一基本原则出发，推导出并实现用于评估分位数预测的“弹球损失”（pinball loss），并学习如何评估预测区间的质量，例如它们的覆盖率和宽度。",
            "id": "3168892",
            "problem": "给定多个观测值的预测条件分位数，其水平为 $\\tau \\in \\{0.1, 0.5, 0.9\\}$。您的任务是构建一个完整、可运行的程序，使用非对称线性损失原则和基于区间的覆盖率诊断来评估分位数回归的预测结果。\n\n使用的基本原理：\n- $\\tau$-分位数的特征是某个期望值的最小化器，该期望值对应于一个可加、正齐次、非对称线性损失。该损失函数对正残差和负残差施加由 $\\tau$ 决定的不同斜率的惩罚。具体而言，低估和高估会产生不同的线性成本，其比率取决于 $\\tau$。\n- 经验风险是在一个数据集上对每个观测值的损失进行可加聚合。\n\n基于此原理，您必须推导出给定残差 $u = y - \\hat{q}_\\tau(x)$ 的单个样本损失的精确表达式，并加以实现。不要假设或使用任何预封装的公式；请从所述的非对称性原则推导，并直接实现推导出的表达式。\n\n需要从第一性原理实现的定义：\n- 对于每个分位数水平 $\\tau$，单个样本的损失是 $u$ 的一个非对称线性函数，其斜率取决于 $u$ 的符号和参数 $\\tau$。\n- 给定 $\\tau$ 的平均损失是所有样本的单个样本损失的算术平均值。\n- 为研究非对称成本，将给定 $\\tau$ 的总损失分解为正残差和负残差的贡献，并计算正残差贡献的份额。如果总损失为零，则将此份额定义为 $0.0$。\n- 中心预测区间由 $\\tau = 0.1$ 的下分位数和 $\\tau = 0.9$ 的上分位数定义。如果某个样本的预测分位数未排序，则通过取两者中的最小值作为下端点、最大值作为上端点来构造区间。经验覆盖率是目标值 $y$ 落在构造区间内（包含端点）的比例。平均区间宽度是两个端点之间绝对差值的平均值。交叉计数是原始预测的下分位数严格大于原始预测的上分位数的样本数量。\n- 聚合分位数得分定义为跨 $\\tau \\in \\{0.1, 0.5, 0.9\\}$ 的单个样本损失之和在所有样本上的平均值。\n\n程序要求：\n1. 从非对称性原则推导出作为残差 $u$ 和参数 $\\tau$ 的函数的显式单样本非对称线性损失，并实现它。\n2. 对于每个测试用例和每个 $\\tau \\in \\{0.1, 0.5, 0.9\\}$，计算：\n   - 平均损失。\n   - 正残差贡献的损失份额（如果总损失为 $0$，则按惯例取 $0.0$）。\n3. 对于每个测试用例，使用预测的 $\\tau = 0.1$ 和 $\\tau = 0.9$ 分位数，计算：\n   - 中心预测区间的经验覆盖率。\n   - 平均区间宽度。\n   - 交叉计数（在重新排序前，有多少样本的下分位数严格大于上分位数）。\n4. 对于每个测试用例，计算聚合分位数得分，定义为跨 $\\tau \\in \\{0.1, 0.5, 0.9\\}$ 的单个样本损失之和在所有样本上的平均值。\n5. 将所有浮点数输出四舍五入到 $6$ 位小数。\n\n测试套件（精确实现以下三个案例；每个案例提供目标值和预测分位数的数组）：\n\n- 测试用例1（正常路径，有序分位数）：\n  - 目标值 $y$：$[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]$。\n  - 预测的 $\\hat{q}_{0.1}$：$[0.5, 1.5, 2.7, 3.0, 4.2, 5.5]$。\n  - 预测的 $\\hat{q}_{0.5}$：$[0.9, 1.8, 3.1, 3.9, 4.9, 6.2]$。\n  - 预测的 $\\hat{q}_{0.9}$：$[1.6, 2.5, 3.6, 4.8, 5.7, 6.8]$。\n\n- 测试用例2（边界情况，完美预测，零宽度）：\n  - 目标值 $y$：$[2.5, -1.0, 0.0, 3.3]$。\n  - 预测的 $\\hat{q}_{0.1}$：$[2.5, -1.0, 0.0, 3.3]$。\n  - 预测的 $\\hat{q}_{0.5}$：$[2.5, -1.0, 0.0, 3.3]$。\n  - 预测的 $\\hat{q}_{0.9}$：$[2.5, -1.0, 0.0, 3.3]$。\n\n- 测试用例3（边缘情况，分位数交叉）：\n  - 目标值 $y$：$[10.0, 0.0, -2.0, 5.0, 1.0]$。\n  - 预测的 $\\hat{q}_{0.1}$：$[12.0, 1.0, -1.0, 7.0, 3.0]$。\n  - 预测的 $\\hat{q}_{0.5}$：$[11.0, 0.5, -2.5, 6.0, 1.5]$。\n  - 预测的 $\\hat{q}_{0.9}$：$[9.0, -1.0, -3.0, 4.0, 0.0]$。\n\n最终输出格式：\n- 对于每个测试用例，按以下顺序输出包含十个值的列表：\n  $[\\text{mean\\_loss\\_0.1}, \\text{mean\\_loss\\_0.5}, \\text{mean\\_loss\\_0.9}, \\text{aggregate\\_quantile\\_score}, \\text{coverage\\_rate}, \\text{mean\\_interval\\_width}, \\text{crossing\\_count}, \\text{pos\\_loss\\_share\\_0.1}, \\text{pos\\_loss\\_share\\_0.5}, \\text{pos\\_loss\\_share\\_0.9}]$，其中除了交叉计数是整数外，所有条目都是四舍五入到 $6$ 位小数的浮点数。\n- 您的程序应生成单行输出，其中包含所有三个测试用例的结果，格式为用方括号括起来的逗号分隔列表，其中每个元素是单个测试用例的列表。例如：$[[\\dots],[\\dots],[\\dots]]$。\n- 此问题不涉及物理单位或角度。",
            "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上是合理的、自洽的、良构的，基于分位数回归评估的既定原则提供了一个清晰、客观的任务。唯一解所需的所有数据和定义均已提供。\n\n问题的核心是从第一性原理推导并实现分位数损失函数。\n\n**1. 单样本分位数损失函数的推导**\n\n问题指明 $\\tau$-分位数损失是残差 $u = y - \\hat{q}_\\tau$ 的一个非对称线性函数，其中 $y$ 是真实目标值，$\\hat{q}_\\tau$ 是水平为 $\\tau$ 的预测分位数。设该损失函数为 $\\rho_\\tau(u)$。\n\n非对称性意味着对低估（$u > 0$，即 $y > \\hat{q}_\\tau$）的惩罚与对高估（$u < 0$，即 $y < \\hat{q}_\\tau$）的惩罚不同。损失是线性的，因此我们可以将其写为：\n$$\n\\rho_\\tau(u) =\n\\begin{cases}\na_{pos} \\cdot u, & \\text{if } u > 0 \\\\\n0, & \\text{if } u = 0 \\\\\na_{neg} \\cdot (-u), & \\text{if } u < 0\n\\end{cases}\n$$\n其中 $a_{pos}$ 和 $a_{neg}$ 是非负斜率。\n\n分位数预测的一个基本属性是它应该平衡高估和低估的成本。$\\tau$-分位数是一个期望以概率 $\\tau$ 大于观测值的数值。为使期望损失 $E[\\rho_\\tau(y - \\hat{q}_\\tau)]$ 相对于预测 $\\hat{q}_\\tau$ 最小化，其一阶条件要求损失函数对 $\\hat{q}_\\tau$ 的导数的期望值为零。该导数为：\n$$\n\\frac{\\partial \\rho_\\tau(y - \\hat{q}_\\tau)}{\\partial \\hat{q}_\\tau} =\n\\begin{cases}\n-a_{pos}, & \\text{if } y > \\hat{q}_\\tau \\\\\na_{neg}, & \\text{if } y < \\hat{q}_\\tau\n\\end{cases}\n$$\n将期望值设为零可得：\n$$ E\\left[\\frac{\\partial \\rho_\\tau(y - \\hat{q}_\\tau)}{\\partial \\hat{q}_\\tau}\\right] = (-a_{pos}) \\cdot P(y > \\hat{q}_\\tau) + (a_{neg}) \\cdot P(y < \\hat{q}_\\tau) = 0 $$\n$$ a_{neg} \\cdot P(y < \\hat{q}_\\tau) = a_{pos} \\cdot P(y > \\hat{q}_\\tau) $$\n对于一个理想的预测，其中 $\\hat{q}_\\tau$ 是 $y$ 的条件分布的真实 $\\tau$-分位数，我们有 $P(y < \\hat{q}_\\tau) = \\tau$ 和 $P(y > \\hat{q}_\\tau) = 1 - \\tau$。将这些代入平衡条件可得：\n$$ a_{neg} \\cdot \\tau = a_{pos} \\cdot (1 - \\tau) $$\n这个方程决定了斜率的比率。满足此关系的一个标准且方便的选择是设 $a_{pos} = \\tau$ 和 $a_{neg} = 1 - \\tau$。这就导出了广泛使用的分位数损失（或弹球损失）函数。\n\n将这些斜率代回到分段定义中，并将 $u=0$ 的情况（损失为 $0$）并入 $u>0$ 的情况，我们得到单个样本损失的解析表达式：\n$$\n\\rho_\\tau(u) =\n\\begin{cases}\n\\tau \\cdot u, & \\text{if } u \\ge 0 \\\\\n(1-\\tau) \\cdot (-u), & \\text{if } u < 0\n\\end{cases}\n$$\n其中 $u = y - \\hat{q}_\\tau$。这个公式是按要求直接从非对称性原则推导出来的，并构成了所有基于损失的计算的基础。\n\n**2. 评估指标的定义**\n\n给定一个包含 $N$ 个观测值的数据集，索引为 $i=1, \\dots, N$，其目标值为 $y_i$，分位数预测为 $\\hat{q}_{i, \\tau}$，评估指标定义如下。\n\n- **平均损失**：对于给定的分位数水平 $\\tau$，单个样本损失的算术平均值：\n$$ \\text{MeanLoss}_\\tau = \\frac{1}{N} \\sum_{i=1}^N \\rho_\\tau(y_i - \\hat{q}_{i, \\tau}) $$\n\n- **正残差贡献的损失份额**：总损失中来自 $y_i > \\hat{q}_{i, \\tau}$ 的样本的比例。设 $u_{i, \\tau} = y_i - \\hat{q}_{i, \\tau}$。\n$$ \\text{PositiveLossShare}_\\tau = \\frac{\\sum_{i=1}^N \\rho_\\tau(u_{i, \\tau}) \\cdot \\mathbb{I}(u_{i, \\tau} > 0)}{\\sum_{i=1}^N \\rho_\\tau(u_{i, \\tau})} $$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。如果总损失（分母）为 $0$，则该份额定义为 $0.0$。\n\n- **基于区间的指标**：使用 $\\tau=0.1$ 和 $\\tau=0.9$ 的分位数预测：\n  - **交叉计数**：预测的下分位数大于预测的上分位数的样本数。\n  $$ \\text{CrossingCount} = \\sum_{i=1}^N \\mathbb{I}(\\hat{q}_{i, 0.1} > \\hat{q}_{i, 0.9}) $$\n  - **预测区间**：对于每个样本 $i$，区间为 $[l_i, u_i]$，其中 $l_i = \\min(\\hat{q}_{i, 0.1}, \\hat{q}_{i, 0.9})$ 且 $u_i = \\max(\\hat{q}_{i, 0.1}, \\hat{q}_{i, 0.9})$。\n  - **经验覆盖率**：观测值 $y_i$ 落在构造区间 $[l_i, u_i]$ 内的比例。\n  $$ \\text{CoverageRate} = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}(l_i \\le y_i \\le u_i) $$\n  - **平均区间宽度**：构造区间的平均宽度。\n  $$ \\text{MeanWidth} = \\frac{1}{N} \\sum_{i=1}^N (u_i - l_i) = \\frac{1}{N} \\sum_{i=1}^N |\\hat{q}_{i, 0.9} - \\hat{q}_{i, 0.1}| $$\n\n- **聚合分位数得分**：在所有指定分位数水平上，单个样本损失之和在所有样本上的平均值。\n$$ \\text{AggregateScore} = \\frac{1}{N} \\sum_{i=1}^N \\left( \\rho_{0.1}(u_{i, 0.1}) + \\rho_{0.5}(u_{i, 0.5}) + \\rho_{0.9}(u_{i, 0.9}) \\right) $$\n这等价于平均损失之和：$\\text{MeanLoss}_{0.1} + \\text{MeanLoss}_{0.5} + \\text{MeanLoss}_{0.9}$。\n\n实现将通过将这些推导出的公式应用于提供的测试数据来进行。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_metrics(y_true, q_pred_01, q_pred_05, q_pred_09):\n    \"\"\"\n    Computes quantile regression evaluation metrics from first principles.\n\n    Args:\n        y_true (np.ndarray): Array of true target values.\n        q_pred_01 (np.ndarray): Array of predicted 0.1-quantiles.\n        q_pred_05 (np.ndarray): Array of predicted 0.5-quantiles.\n        q_pred_09 (np.ndarray): Array of predicted 0.9-quantiles.\n\n    Returns:\n        list: A list of 10 computed metrics, rounded as required.\n    \"\"\"\n    y = np.array(y_true, dtype=float)\n    q01 = np.array(q_pred_01, dtype=float)\n    q05 = np.array(q_pred_05, dtype=float)\n    q09 = np.array(q_pred_09, dtype=float)\n\n    taus = [0.1, 0.5, 0.9]\n    quantiles = [q01, q05, q09]\n    \n    mean_losses = []\n    pos_loss_shares = []\n\n    for tau, q_pred in zip(taus, quantiles):\n        # Calculate per-sample quantile loss from the derived formula\n        u = y - q_pred\n        # rho(u) = tau * u if u >= 0 else (1 - tau) * (-u)\n        losses = np.where(u >= 0, tau * u, (1 - tau) * -u)\n        \n        # Calculate mean loss\n        mean_loss = np.mean(losses)\n        mean_losses.append(mean_loss)\n        \n        # Calculate share of loss from positive residuals\n        total_loss = np.sum(losses)\n        if total_loss == 0.0:\n            pos_share = 0.0\n        else:\n            # Positive residuals are strictly u > 0.\n            # Loss for u > 0 is tau * u.\n            pos_losses_sum = np.sum(np.where(u > 0, tau * u, 0.0))\n            pos_share = pos_losses_sum / total_loss\n        pos_loss_shares.append(pos_share)\n\n    # Interval-based metrics for tau=0.1 and tau=0.9\n    \n    # Crossing count\n    crossing_count = np.sum(q01 > q09)\n\n    # Construct intervals, handling crossings\n    interval_lower = np.minimum(q01, q09)\n    interval_upper = np.maximum(q01, q09)\n    \n    # Empirical coverage rate\n    covered = (y >= interval_lower)  (y = interval_upper)\n    coverage_rate = np.mean(covered)\n    \n    # Mean interval width\n    # Width is max - min, which is equivalent to |q09 - q01|\n    widths = interval_upper - interval_lower\n    mean_interval_width = np.mean(widths)\n    \n    # Aggregate quantile score\n    aggregate_score = sum(mean_losses)\n    \n    # Assemble results in the specified order and format\n    results = [\n        round(mean_losses[0], 6),\n        round(mean_losses[1], 6),\n        round(mean_losses[2], 6),\n        round(aggregate_score, 6),\n        round(coverage_rate, 6),\n        round(mean_interval_width, 6),\n        int(crossing_count),\n        round(pos_loss_shares[0], 6),\n        round(pos_loss_shares[1], 6),\n        round(pos_loss_shares[2], 6),\n    ]\n    \n    return results\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the metric calculations, and prints the final output.\n    \"\"\"\n    test_cases = [\n        {\n            \"y\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n            \"q_0.1\": [0.5, 1.5, 2.7, 3.0, 4.2, 5.5],\n            \"q_0.5\": [0.9, 1.8, 3.1, 3.9, 4.9, 6.2],\n            \"q_0.9\": [1.6, 2.5, 3.6, 4.8, 5.7, 6.8],\n        },\n        {\n            \"y\": [2.5, -1.0, 0.0, 3.3],\n            \"q_0.1\": [2.5, -1.0, 0.0, 3.3],\n            \"q_0.5\": [2.5, -1.0, 0.0, 3.3],\n            \"q_0.9\": [2.5, -1.0, 0.0, 3.3],\n        },\n        {\n            \"y\": [10.0, 0.0, -2.0, 5.0, 1.0],\n            \"q_0.1\": [12.0, 1.0, -1.0, 7.0, 3.0],\n            \"q_0.5\": [11.0, 0.5, -2.5, 6.0, 1.5],\n            \"q_0.9\": [9.0, -1.0, -3.0, 4.0, 0.0],\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        y_true = case[\"y\"]\n        q_pred_01 = case[\"q_0.1\"]\n        q_pred_05 = case[\"q_0.5\"]\n        q_pred_09 = case[\"q_0.9\"]\n        \n        result = calculate_metrics(y_true, q_pred_01, q_pred_05, q_pred_09)\n        all_results.append(result)\n\n    # Format the final output string exactly as required.\n    # The default str() for floats might not show trailing zeros,\n    # so we use a format specifier.\n    result_str = \"[\"\n    for i, res_list in enumerate(all_results):\n        res_list_str = \"[\"\n        for j, item in enumerate(res_list):\n            if isinstance(item, float):\n                res_list_str += f\"{item:.6f}\"\n            else:\n                res_list_str += str(item)\n            if j  len(res_list) - 1:\n                res_list_str += \",\"\n        res_list_str += \"]\"\n        result_str += res_list_str\n        if i  len(all_results) - 1:\n            result_str += \",\"\n    result_str += \"]\"\n    \n    print(result_str)\n\nsolve()\n```"
        }
    ]
}