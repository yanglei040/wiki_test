{
    "hands_on_practices": [
        {
            "introduction": "虽然总体准确率（Accuracy）是一个直观的性能指标，但它在类别不平衡的数据集上可能产生严重的误导。一个模型可能仅仅通过预测数量占优的类别就获得很高的准确率，而对稀有类别的识别能力却很差。本练习  旨在通过构建具有相同准确率但$F_1$分数迥异的混淆矩阵，来揭示准确率的局限性，并强调综合考量精确率（Precision）和召回率（Recall）的重要性。",
            "id": "3094202",
            "problem": "一个二元分类器在一个数据集上进行评估，其结果由一个混淆矩阵总结，矩阵的条目为 $(TP, FP, TN, FN)$，其中 $TP$ 表示真正例（true positives）的数量，$FP$ 表示假正例（false positives）的数量，$TN$ 表示真反例（true negatives）的数量，$FN$ 表示假反例（false negatives）的数量。准确率 (Accuracy, $\\text{Acc}$) 定义为 $ \\text{Acc} = \\dfrac{TP + TN}{TP + FP + TN + FN} $。精确率 (Precision, $P$) 和召回率 (Recall, $R$) 分别定义为 $ P = \\dfrac{TP}{TP + FP} $ 和 $ R = \\dfrac{TP}{TP + FN} $。$F_1$分数（$F_1$-score）是总结 $P$ 和 $R$ 的标准单一数值指标。\n\n选择唯一一个选项，该选项为两个系统（例如系统 X 和系统 Y）提供了两个混淆矩阵 $(TP, FP, TN, FN)$，它们具有相同的 $\\text{Acc}$ 但 $F_1$ 值截然不同（将“截然不同”解释为 $F_1$ 值的差异至少为 $0.30$），并且该选项还提供了关于为什么 $F_1$ 值不同的正确结构性解释，该解释用 $P$ 和 $R$ 来陈述，并基于 $FP$ 和 $FN$ 的差异。只有一个选项同时满足数值和解释上的要求。\n\nA. 系统 X：$(TP, FP, TN, FN) = (20, 5, 895, 80)$；系统 Y：$(TP, FP, TN, FN) = (80, 65, 835, 20)$。解释：两个系统的 $TP + TN$ 相同，因此 $\\text{Acc}$ 相匹配。$F_1$ 不同是因为在 $FP$ 和 $FN$ 之间进行了权衡：系统 X 的 $FP$ 很小（高 $P$），但 $FN$ 很大（低 $R$）；系统 Y 的 $FP$ 较大（较低的 $P$），但 $FN$ 较小（较高的 $R$），这导致 $P$ 和 $R$ 的调和平衡点显著不同。\n\nB. 系统 X：$(TP, FP, TN, FN) = (50, 50, 850, 50)$；系统 Y：$(TP, FP, TN, FN) = (45, 45, 855, 55)$。解释：因为两者的 $\\text{Acc}$ 相同，所以它们的 $F_1$ 分数必然相等；$F_1$ 完全由 $\\text{Acc}$ 决定。\n\nC. 系统 X：$(TP, FP, TN, FN) = (10, 10, 980, 0)$；系统 Y：$(TP, FP, TN, FN) = (10, 0, 970, 20)$。解释：它们的 $\\text{Acc}$ 值相等，而 $F_1$ 不同是因为真反例 $TN$ 的数量直接驱动 $F_1$。\n\nD. 系统 X：$(TP, FP, TN, FN) = (90, 10, 890, 10)$；系统 Y：$(TP, FP, TN, FN) = (80, 0, 900, 20)$。解释：这里的任何 $F_1$ 差异主要是由 $TN$ 的变化引起的，因为 $TN$ 出现在 $P$ 和 $R$ 的分母中，并直接改变两者。",
            "solution": "用户要求对问题陈述进行严格验证，然后对所提供的选项进行全面推导和评估。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n\n问题为在数据集上评估的二元分类器提供了以下定义和条件：\n- 混淆矩阵条目：$(TP, FP, TN, FN)$，代表真正例、假正例、真反例和假反例。\n- 准确率定义：$ \\text{Acc} = \\dfrac{TP + TN}{TP + FP + TN + FN} $。\n- 精确率定义：$ P = \\dfrac{TP}{TP + FP} $。\n- 召回率定义：$ R = \\dfrac{TP}{TP + FN} $。\n- $F_1$分数 $( F_1 )$ 被定义为“总结 $P$ 和 $R$ 的标准单一数值指标”。\n- 任务是选择唯一一个选项，该选项为系统 X 和系统 Y 提供了两个混淆矩阵，满足两个数值标准和一个解释性标准：\n    1.  准确率相同：$\\text{Acc}_X = \\text{Acc}_Y$。\n    2.  $F_1$分数“截然不同”，解释为差异至少为 $0.30$：$|F_{1,X} - F_{1,Y}| \\geq 0.30$。\n    3.  该选项用 $P$、$R$、$FP$ 和 $FN$ 对 $F_1$ 的差异提供了正确的结构性解释。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n- **科学依据：** 该问题基于统计学习和模型评估中使用的基本和标准度量。准确率、精确率和召回率的定义是正确的。将 $F_1$分数称为“标准单一数值指标”正确地指向了精确率和召回率的调和平均数，这是一个公认的概念。\n- **良构性：** 该问题是一个多项选择题，要求应用给定的公式并评估逻辑解释。“截然不同”一词被赋予了精确的量化含义（$|F_{1,X} - F_{1,Y}| \\geq 0.30$），消除了模糊性。问题的结构保证了只有一个正确答案同时满足数值和解释性标准。\n- **客观性：** 问题陈述使用精确、客观的语言和数学定义。没有主观性。\n- **完整性和一致性：** 解决问题所需的所有必要定义和数据（在选项中）都已提供。在此背景下，对标准 $F_1$分数的引用是明确的。问题内部是一致的。\n\n**步骤 3：结论和行动**\n\n问题陈述是有效的。它具有科学合理性、良构性和客观性。我将继续进行解答。\n\n### 解答推导\n\n$F_1$分数是精确率（$P$）和召回率（$R$）的调和平均数。其标准公式为：\n$$ F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} $$\n代入 $P$ 和 $R$ 的定义，得到一个直接用混淆矩阵分量表示的公式：\n$$ F_1 = 2 \\cdot \\frac{\\frac{TP}{TP + FP} \\cdot \\frac{TP}{TP + FN}}{\\frac{TP}{TP + FP} + \\frac{TP}{TP + FN}} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN} $$\n后一种形式在计算上很方便。样本总数为 $N = TP + FP + TN + FN$。准确率可以写成 $\\text{Acc} = \\frac{TP + TN}{N}$。\n\n现在我们将通过计算所需的度量并评估所提供解释的有效性来评估每个选项。\n\n**选项 A 的分析**\n\n系统 X：$(TP, FP, TN, FN) = (20, 5, 895, 80)$\n- 样本总数：$N_X = 20 + 5 + 895 + 80 = 1000$。\n- 准确率：$\\text{Acc}_X = \\frac{20 + 895}{1000} = \\frac{915}{1000} = 0.915$。\n- 精确率：$P_X = \\frac{20}{20 + 5} = \\frac{20}{25} = 0.8$。\n- 召回率：$R_X = \\frac{20}{20 + 80} = \\frac{20}{100} = 0.2$。\n- $F_1$分数：$F_{1,X} = \\frac{2 \\cdot TP_X}{2 \\cdot TP_X + FP_X + FN_X} = \\frac{2 \\cdot 20}{2 \\cdot 20 + 5 + 80} = \\frac{40}{40 + 85} = \\frac{40}{125} = 0.32$。\n\n系统 Y：$(TP, FP, TN, FN) = (80, 65, 835, 20)$\n- 样本总数：$N_Y = 80 + 65 + 835 + 20 = 1000$。\n- 准确率：$\\text{Acc}_Y = \\frac{80 + 835}{1000} = \\frac{915}{1000} = 0.915$。\n- 精确率：$P_Y = \\frac{80}{80 + 65} = \\frac{80}{145} = \\frac{16}{29} \\approx 0.5517$。\n- 召回率：$R_Y = \\frac{80}{80 + 20} = \\frac{80}{100} = 0.8$。\n- $F_1$分数：$F_{1,Y} = \\frac{2 \\cdot TP_Y}{2 \\cdot TP_Y + FP_Y + FN_Y} = \\frac{2 \\cdot 80}{2 \\cdot 80 + 65 + 20} = \\frac{160}{160 + 85} = \\frac{160}{245} = \\frac{32}{49} \\approx 0.6531$。\n\n**选项 A 的评估：**\n1.  **准确率相等：** $\\text{Acc}_X = 0.915$ 且 $\\text{Acc}_Y = 0.915$。此条件满足。\n2.  **$F_1$差异：** $|F_{1,X} - F_{1,Y}| = |0.32 - 0.6531| = 0.3331$。由于 $0.3331 \\geq 0.30$，此条件满足。\n3.  **解释：** 解释陈述了 $\\text{Acc}$ 相匹配是因为两者的 $TP + TN$ 相同（$915$），而总数 $N$ 也相同（$1000$）。这是正确的。它进一步解释说，$F_1$ 不同是由于 $FP$ 和 $FN$ 之间的权衡。系统 X 的 $FP$ 低（$5$）而 $FN$ 高（$80$），导致高 $P$（$0.8$）和低 $R$（$0.2$）。系统 Y 的 $FP$ 高（$65$）而 $FN$ 低（$20$），导致较低的 $P$（$\\approx 0.55$）和高 $R$（$0.8$）。$P$ 和 $R$ 之间的这种权衡导致了 $F_1$分数的差异，作为调和平均数，它对此类不平衡很敏感。该解释在结构上和事实上都是正确的。\n\n选项 A 的结论：**正确**。\n\n**选项 B 的分析**\n\n系统 X：$(TP, FP, TN, FN) = (50, 50, 850, 50)$\n系统 Y：$(TP, FP, TN, FN) = (45, 45, 855, 55)$\n- $\\text{Acc}_X = \\frac{50 + 850}{1000} = 0.9$。\n- $\\text{Acc}_Y = \\frac{45 + 855}{1000} = 0.9$。\n准确率相等。\n- $F_{1,X} = \\frac{2 \\cdot 50}{2 \\cdot 50 + 50 + 50} = \\frac{100}{200} = 0.5$。\n- $F_{1,Y} = \\frac{2 \\cdot 45}{2 \\cdot 45 + 45 + 55} = \\frac{90}{90 + 100} = \\frac{90}{190} = \\frac{9}{19} \\approx 0.4737$。\n- $|F_{1,X} - F_{1,Y}| = |0.5 - 0.4737| \\approx 0.0263$。这不满足 $\\geq 0.30$。\n- **解释：** 解释声称“因为两者的 $\\text{Acc}$ 相同，所以它们的 $F_1$ 分数必然相等；$F_1$ 完全由 $\\text{Acc}$ 决定。”这个说法根本上是错误的。准确率和 $F_1$分数是不同的度量，它们之间没有决定性联系。我们对选项 A 的分析已经提供了一个反例。\n\n选项 B 的结论：**错误**。\n\n**选项 C 的分析**\n\n系统 X：$(TP, FP, TN, FN) = (10, 10, 980, 0)$\n系统 Y：$(TP, FP, TN, FN) = (10, 0, 970, 20)$\n- $\\text{Acc}_X = \\frac{10 + 980}{1000} = 0.99$。\n- $\\text{Acc}_Y = \\frac{10 + 970}{1000} = 0.98$。\n- 准确率不相等（$\\text{Acc}_X \\neq \\text{Acc}_Y$）。问题的第一个条件未满足。\n- **解释：** 该解释包含两个错误的陈述。首先，它错误地声称准确率相等。其次，它声称“$TN$ 直接驱动 $F_1$”。$F_1$ 的公式是 $F_1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$，其中不包含 $TN$ 项。因此，$TN$ 对 $F_1$分数没有直接影响。\n\n选项 C 的结论：**错误**。\n\n**选项 D 的分析**\n\n系统 X：$(TP, FP, TN, FN) = (90, 10, 890, 10)$\n系统 Y：$(TP, FP, TN, FN) = (80, 0, 900, 20)$\n- $\\text{Acc}_X = \\frac{90 + 890}{1000} = 0.98$。\n- $\\text{Acc}_Y = \\frac{80 + 900}{1000} = 0.98$。\n准确率相等。\n- $F_{1,X} = \\frac{2 \\cdot 90}{2 \\cdot 90 + 10 + 10} = \\frac{180}{200} = 0.9$。\n- $F_{1,Y} = \\frac{2 \\cdot 80}{2 \\cdot 80 + 0 + 20} = \\frac{160}{180} = \\frac{8}{9} \\approx 0.8889$。\n- $|F_{1,X} - F_{1,Y}| = |0.9 - 0.8889| \\approx 0.0111$。这不满足 $\\geq 0.30$。\n- **解释：** 解释声称 $F_1$ 的差异“主要是由 $TN$ 的变化引起的，因为 $TN$ 出现在 $P$ 和 $R$ 的分母中”。这在事实上是错误的。$P$ 和 $R$ 的公式是 $P = \\frac{TP}{TP + FP}$ 和 $R = \\frac{TP}{TP + FN}$。$TN$ 项既没有出现在这两个公式中，也没有出现在 $F_1$ 的公式中。\n\n选项 D 的结论：**错误**。\n\n基于详细分析，只有选项 A 满足所有陈述的数值和解释要求。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "当我们将评估从二分类扩展到多分类任务时，特别是在处理类别高度不平衡的数据时，如何平均各个类别的性能指标变得至关重要。微平均（micro-averaging）赋予每个样本同等的权重，而宏平均（macro-averaging）则赋予每个类别同等的权重。这个练习  将通过一个具体的案例，向您展示为何一个分类器可以在微平均$F_1$分数和总体准确率上表现出色，但在宏平均$F_1$分数上却表现糟糕，从而凸显宏平均在评估模型对少数类别性能时的独特价值。",
            "id": "3181107",
            "problem": "一个单标签、多类别分类器在一个包含三个类别 $C_1$、$C_2$ 和 $C_3$ 的数据集上进行评估。总实例数为 $N = 1000$，真实类别计数为 $|C_1| = 950$、 $|C_2| = 40$ 和 $|C_3| = 10$，这使得数据集高度不平衡。一个 $3 \\times 3$ 的混淆矩阵记录了对于每个真实类别（行），有多少实例被预测为每个类别（列）。假设行按 $(C_1, C_2, C_3)$ 的顺序对应真实类别，列按 $(C_1, C_2, C_3)$ 的顺序对应预测类别。\n\n使用每个类别的精确率、每个类别的召回率及其调和平均数（$F_1$分数）的标准定义，将宏平均$F_1$分数定义为各类别 $F_1$分数的未加权平均值。通过首先聚合所有类别的真阳性、假阳性和假阴性，然后根据这些聚合量计算$F_1$分数来定义微平均$F_1$分数。\n\n选择下面所有同时满足以下所有条件的混淆矩阵：\n- 总体准确率至少为 $0.90$。\n- 微平均$F_1$分数至少为 $0.90$。\n- 宏平均$F_1$分数小于 $0.50$。\n\n选项 A:\n$$\n\\begin{bmatrix}\n950 & 0 & 0\\\\\n40 & 0 & 0\\\\\n10 & 0 & 0\n\\end{bmatrix}\n$$\n\n选项 B:\n$$\n\\begin{bmatrix}\n930 & 15 & 5\\\\\n10 & 25 & 5\\\\\n3 & 2 & 5\n\\end{bmatrix}\n$$\n\n选项 C:\n$$\n\\begin{bmatrix}\n940 & 5 & 5\\\\\n30 & 10 & 0\\\\\n8 & 2 & 0\n\\end{bmatrix}\n$$\n\n选项 D:\n$$\n\\begin{bmatrix}\n700 & 200 & 50\\\\\n25 & 5 & 10\\\\\n5 & 3 & 2\n\\end{bmatrix}\n$$\n\n选择所有适用的选项：A, B, C, D。",
            "solution": "问题要求我们确定给出的混淆矩阵中，哪些同时满足三个条件：总体准确率至少为 $0.90$，微平均 $F_1$分数至少为 $0.90$，以及宏平均 $F_1$分数小于 $0.50$。该数据集有 $N=1000$ 个实例，分布在三个类别 $C_1$、$C_2$ 和 $C_3$ 中，真实计数分别为 $|C_1|=950$、 $|C_2|=40$ 和 $|C_3|=10$。\n\n首先，让我们根据混淆矩阵 $M$ 来定义性能指标，其中 $M_{ij}$ 是真实类别为 $C_i$ 的实例被预测为类别 $C_j$ 的数量。\n\n**类别 $C_i$ 的性能指标**：\n- 真阳性 ($TP_i$): $TP_i = M_{ii}$\n- 假阳性 ($FP_i$): $FP_i = \\left(\\sum_{k=1}^3 M_{ki}\\right) - M_{ii}$ (第 $i$ 列的总和减去对角线元素)\n- 假阴性 ($FN_i$): $FN_i = \\left(\\sum_{j=1}^3 M_{ij}\\right) - M_{ii}$ (第 $i$ 行的总和减去对角线元素)\n- 精确率 ($P_i$): $P_i = \\frac{TP_i}{TP_i + FP_i}$。按照惯例，如果 $TP_i + FP_i = 0$，则 $P_i=0$。\n- 召回率 ($R_i$): $R_i = \\frac{TP_i}{TP_i + FN_i} = \\frac{TP_i}{|C_i|}$\n- $F_1$分数 ($F_{1,i}$): $F_{1,i} = 2 \\cdot \\frac{P_i \\cdot R_i}{P_i + R_i}$。如果 $P_i + R_i = 0$，则 $F_{1,i}=0$。\n\n**总体和平均指标**：\n- **总体准确率 ($Acc$)**：这是被正确分类的实例的比例。\n$$Acc = \\frac{\\sum_{i=1}^3 TP_i}{N} = \\frac{\\sum_{i=1}^3 M_{ii}}{N}$$\n- **微平均 $F_1$分数 ($F_{1,micro}$)**：这是根据聚合计数计算的。\n  - 聚合真阳性：$TP_{micro} = \\sum_{i=1}^3 TP_i$\n  - 聚合假阳性：$FP_{micro} = \\sum_{i=1}^3 FP_i$\n  - 聚合假阴性：$FN_{micro} = \\sum_{i=1}^3 FN_i$\n  在多类别、单标签分类中，$FP_{micro} = FN_{micro}$，因为每次错误分类对一个类别来说是假阳性，对另一个类别来说是假阴性。\n  - 微精确率：$P_{micro} = \\frac{TP_{micro}}{TP_{micro} + FP_{micro}} = \\frac{\\sum_i M_{ii}}{\\sum_i \\sum_k M_{ki}} = \\frac{\\sum_i M_{ii}}{N} = Acc$\n  - 微召回率：$R_{micro} = \\frac{TP_{micro}}{TP_{micro} + FN_{micro}} = \\frac{\\sum_i M_{ii}}{\\sum_i \\sum_j M_{ij}} = \\frac{\\sum_i M_{ii}}{N} = Acc$\n  - 由于 $P_{micro} = R_{micro}$，微平均 $F_1$分数与两者相等：$F_{1,micro} = P_{micro} = R_{micro} = Acc$。\n- **宏平均 $F_1$分数 ($F_{1,macro}$)**：这是各类别 $F_1$分数的未加权平均值。\n$$F_{1,macro} = \\frac{1}{3} \\sum_{i=1}^3 F_{1,i}$$\n\n**需要检查的条件**：\n1. $Acc \\ge 0.90$\n2. $F_{1,micro} \\ge 0.90$ (这与条件 1 相同)\n3. $F_{1,macro}  0.50$\n\n我们现在来评估每个选项。\n\n### 选项 A\n混淆矩阵是：\n$$ M_A = \\begin{bmatrix} 950  0  0\\\\ 40  0  0\\\\ 10  0  0 \\end{bmatrix} $$\n1.  **准确率和微平均$F_1$**：对角线元素之和为 $950+0+0 = 950$。\n    $Acc = F_{1,micro} = \\frac{950}{1000} = 0.95$。\n    由于 $0.95 \\ge 0.90$，前两个条件得到满足。\n\n2.  **宏平均$F_1$**：\n    -   **类别 $C_1$**：$TP_1=950$， $FN_1=0$。第 1 列的和为 $950+40+10=1000$，因此 $FP_1=1000-950=50$。\n        $P_1 = \\frac{950}{950+50} = \\frac{950}{1000} = 0.95$。\n        $R_1 = \\frac{950}{950+0} = 1$。\n        $F_{1,1} = 2 \\cdot \\frac{0.95 \\cdot 1}{0.95+1} = \\frac{1.9}{1.95} = \\frac{38}{39}$。\n    -   **类别 $C_2$**：$TP_2=0$， $FN_2=40$。第 2 列的和为 $0$，因此 $FP_2=0$。\n        $P_2 = \\frac{0}{0+0} = 0$ (按照惯例)。\n        $R_2 = \\frac{0}{0+40} = 0$。\n        $F_{1,2} = 0$。\n    -   **类别 $C_3$**：$TP_3=0$， $FN_3=10$。第 3 列的和为 $0$，因此 $FP_3=0$。\n        $P_3 = \\frac{0}{0+0} = 0$ (按照惯例)。\n        $R_3 = \\frac{0}{0+10} = 0$。\n        $F_{1,3} = 0$。\n    -   **宏平均$F_1$计算**：\n        $F_{1,macro} = \\frac{1}{3} \\left( \\frac{38}{39} + 0 + 0 \\right) = \\frac{38}{117} \\approx 0.3248$。\n        由于 $0.3248  0.50$，第三个条件得到满足。\n\n**选项 A 的结论**：正确。\n\n### 选项 B\n混淆矩阵是：\n$$ M_B = \\begin{bmatrix} 930  15  5\\\\ 10  25  5\\\\ 3  2  5 \\end{bmatrix} $$\n1.  **准确率和微平均$F_1$**：对角线元素之和为 $930+25+5 = 960$。\n    $Acc = F_{1,micro} = \\frac{960}{1000} = 0.96$。\n    由于 $0.96 \\ge 0.90$，前两个条件得到满足。\n\n2.  **宏平均$F_1$**：\n    -   **类别 $C_1$**：$TP_1=930$， $FN_1=15+5=20$， $FP_1=10+3=13$。\n        $P_1 = \\frac{930}{930+13} = \\frac{930}{943}$。$R_1 = \\frac{930}{930+20} = \\frac{930}{950}$。\n        $F_{1,1} = 2 \\cdot \\frac{P_1 R_1}{P_1+R_1} = \\frac{2 \\cdot \\frac{930}{943} \\cdot \\frac{930}{950}}{\\frac{930}{943} + \\frac{930}{950}} = \\frac{2}{\\frac{943}{930} + \\frac{950}{930}} = \\frac{1860}{1893} \\approx 0.9826$。\n    -   **类别 $C_2$**：$TP_2=25$， $FN_2=10+5=15$， $FP_2=15+2=17$。\n        $P_2 = \\frac{25}{25+17} = \\frac{25}{42}$。$R_2 = \\frac{25}{25+15} = \\frac{25}{40}$。\n        $F_{1,2} = \\frac{2}{\\frac{42}{25} + \\frac{40}{25}} = \\frac{50}{82} = \\frac{25}{41} \\approx 0.6098$。\n    -   **类别 $C_3$**：$TP_3=5$， $FN_3=3+2=5$， $FP_3=5+5=10$。\n        $P_3 = \\frac{5}{5+10} = \\frac{5}{15} = \\frac{1}{3}$。$R_3 = \\frac{5}{5+5} = \\frac{5}{10} = \\frac{1}{2}$。\n        $F_{1,3} = 2 \\cdot \\frac{\\frac{1}{3} \\cdot \\frac{1}{2}}{\\frac{1}{3}+\\frac{1}{2}} = 2 \\cdot \\frac{\\frac{1}{6}}{\\frac{5}{6}} = \\frac{2}{5} = 0.4$。\n    -   **宏平均$F_1$计算**：\n        $F_{1,macro} = \\frac{1}{3} \\left( \\frac{1860}{1893} + \\frac{25}{41} + 0.4 \\right) \\approx \\frac{1}{3} (0.9826 + 0.6098 + 0.4) \\approx \\frac{1.9924}{3} \\approx 0.6641$。\n        由于 $0.6641 \\ge 0.50$，第三个条件未得到满足。\n\n**选项 B 的结论**：不正确。\n\n### 选项 C\n混淆矩阵是：\n$$ M_C = \\begin{bmatrix} 940  5  5\\\\ 30  10  0\\\\ 8  2  0 \\end{bmatrix} $$\n1.  **准确率和微平均$F_1$**：对角线元素之和为 $940+10+0=950$。\n    $Acc = F_{1,micro} = \\frac{950}{1000} = 0.95$。\n    由于 $0.95 \\ge 0.90$，前两个条件得到满足。\n\n2.  **宏平均$F_1$**：\n    -   **类别 $C_1$**：$TP_1=940$， $FN_1=5+5=10$， $FP_1=30+8=38$。\n        $P_1 = \\frac{940}{940+38} = \\frac{940}{978}$。$R_1 = \\frac{940}{940+10} = \\frac{940}{950}$。\n        $F_{1,1} = \\frac{2}{\\frac{978}{940} + \\frac{950}{940}} = \\frac{1880}{1928} = \\frac{235}{241} \\approx 0.9751$。\n    -   **类别 $C_2$**：$TP_2=10$， $FN_2=30+0=30$， $FP_2=5+2=7$。\n        $P_2 = \\frac{10}{10+7} = \\frac{10}{17}$。$R_2 = \\frac{10}{10+30} = \\frac{10}{40} = \\frac{1}{4}$。\n        $F_{1,2} = \\frac{2}{\\frac{17}{10} + \\frac{40}{10}} = \\frac{20}{57} \\approx 0.3509$。\n    -   **类别 $C_3$**：$TP_3=0$， $FN_3=8+2=10$， $FP_3=5+0=5$。\n        $P_3 = \\frac{0}{0+5} = 0$。$R_3 = \\frac{0}{0+10} = 0$。\n        $F_{1,3} = 0$。\n    -   **宏平均$F_1$计算**：\n        $F_{1,macro} = \\frac{1}{3} \\left( \\frac{235}{241} + \\frac{20}{57} + 0 \\right) \\approx \\frac{1}{3} (0.9751 + 0.3509) \\approx \\frac{1.3260}{3} \\approx 0.4420$。\n        由于 $0.4420  0.50$，第三个条件得到满足。\n\n**选项 C 的结论**：正确。\n\n### 选项 D\n混淆矩阵是：\n$$ M_D = \\begin{bmatrix} 700  200  50\\\\ 25  5  10\\\\ 5  3  2 \\end{bmatrix} $$\n1.  **准确率和微平均$F_1$**：对角线元素之和为 $700+5+2=707$。\n    $Acc = F_{1,micro} = \\frac{707}{1000} = 0.707$。\n    由于 $0.707 \\not\\ge 0.90$，前两个条件未得到满足。我们无需继续进行。\n\n**选项 D 的结论**：不正确。\n\n综上所述，只有选项 A 和 C 满足所有三个指定标准。",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "在深度学习中，我们不仅用指标来评估模型，更希望能够直接将这些指标作为优化目标来训练模型。然而，像$F_1$分数这样的标准评估指标是基于非连续的计数操作，导致其不可微分，因此不能直接用作基于梯度的优化算法的损失函数。这个高级编程练习  将指导您完成一个关键的理论到实践的转换：通过引入平滑的代理函数，构建一个可微分的宏平均$F_1$分数版本，使其能够作为损失函数直接用于神经网络的端到端训练中。",
            "id": "3182549",
            "problem": "给定一个有限的数据集，其中包含输入、相关的真实类别标签以及模型为每个类别提供的实值分数。考虑一个有 $N$ 个样本的 $K$ 类单标签分类问题。对于每个输入 $i \\in \\{1,\\dots,N\\}$ 和类别 $c \\in \\{0,\\dots,K-1\\}$，模型会产生一个分数 $f_\\theta(x_i)_c \\in [0,1]$。硬分类器通过将 $f_\\theta(x_i)_c$ 与阈值 $\\tau \\in [0,1]$ 进行比较，并使用指示函数 $I\\{f_\\theta(x_i)_c \\ge \\tau\\}$ 来预测类别 $c$ 的成员资格。对于每个类别 $c$，在“一对多”（one-vs-rest）评估下，定义源自标准混淆矩阵的计数：真正例 $\\mathrm{TP}_c$、假正例 $\\mathrm{FP}_c$ 和假反例 $\\mathrm{FN}_c$。这些计数都是通过对所有样本的真实标签的相应指示函数加权贡献求和来计算的。宏$F_1$分数（macro-$F_1$ score）是各类别 $F_1$分数的算术平均值，而各类别 $F_1$分数以常规方式由 $\\mathrm{TP}_c$、$\\mathrm{FP}_c$ 和 $\\mathrm{FN}_c$ 定义。\n\n您的任务是用一个光滑、可微的函数替换不可微的指示函数 $I\\{\\cdot\\}$，使得最终的宏$F_1$目标函数对于模型输出和阈值 $\\tau$ 都是可微的。使用 logistic (sigmoid) 函数作为指示函数的光滑、单调近似，其陡峭度参数 $\\alpha  0$ 可调，具体为 $s(z) = \\frac{1}{1 + e^{-\\alpha z}}$，其中 $z$ 是边距 $f_\\theta(x_i)_c - \\tau$。使用这个光滑代理函数代替指示函数，构建 $\\mathrm{TP}_c$、$\\mathrm{FP}_c$ 和 $\\mathrm{FN}_c$ 的可微模拟量，然后定义一个宏$F_1$分数的可微代理，并将相应的损失定义为 1 减去该代理宏$F_1$。在任何需要的分母中加入一个小的正常数 $\\varepsilon$ 以确保数值稳定性。\n\n实现一个程序，该程序：\n- 不接受任何输入，并使用下面预定义的测试套件。\n- 对每个测试用例，计算如上所述的可微代理损失。\n- 产生单行输出，其中包含所有测试用例的损失，格式为方括号内的逗号分隔列表，每个值四舍五入到 $6$ 位小数，例如 `\"[0.123456,0.000001]\"`。\n\n您必须基于以下基本定义：\n- 对于给定的类别 $c$，一对多硬计数通过对样本 $i$ 求和来定义：\n  - $\\mathrm{TP}_c$ 统计真实标签为 $c$ 且被预测为类别 $c$ 的样本。\n  - $\\mathrm{FP}_c$ 统计真实标签不为 $c$ 但被预测为类别 $c$ 的样本。\n  - $\\mathrm{FN}_c$ 统计真实标签为 $c$ 但未被预测为类别 $c$ 的样本。\n- 类别 $c$ 的 $F_1$分数是根据 $\\mathrm{TP}_c$、$\\mathrm{FP}_c$ 和 $\\mathrm{FN}_c$ 定义的。\n- 宏$F_1$分数是所有类别上 $F_1$分数的算术平均值。\n\n您的可微设计必须通过将硬指示函数替换为应用于边距 $z = f_\\theta(x_i)_c - \\tau$ 的 logistic 函数 $s(z)$，然后聚合每个类别的软贡献来得出。\n\n测试套件（每个用例指定标签向量、分数矩阵和超参数 $(\\alpha,\\tau,\\varepsilon)$）。对于下面的每个矩阵，第 $i$ 行对应于样本 $i$，第 $c$ 列对应于类别 $c$：\n- 用例 $1$（二分类，分数校准合理）：$K=2$, $N=6$,\n  标签 $y^{(1)} = [\\,1,\\,0,\\,1,\\,0,\\,1,\\,0\\,]$,\n  分数\n  $$S^{(1)} = \\begin{bmatrix}\n  0.8  0.2\\\\\n  0.3  0.7\\\\\n  0.6  0.4\\\\\n  0.4  0.6\\\\\n  0.55  0.45\\\\\n  0.2  0.8\n  \\end{bmatrix},\\quad (\\alpha,\\tau,\\varepsilon) = (20.0,\\,0.5,\\,10^{-8}).$$\n- 用例 $2$（多分类，近乎完美的预测）：$K=3$, $N=5$,\n  标签 $y^{(2)} = [\\,0,\\,1,\\,2,\\,1,\\,0\\,]$,\n  分数\n  $$S^{(2)} = \\begin{bmatrix}\n  0.99  0.005  0.005\\\\\n  0.01  0.98  0.01\\\\\n  0.02  0.01  0.97\\\\\n  0.005  0.99  0.005\\\\\n  0.97  0.02  0.01\n  \\end{bmatrix},\\quad (\\alpha,\\tau,\\varepsilon) = (30.0,\\,0.5,\\,10^{-8}).$$\n- 用例 $3$（二分类，高阈值抑制正例）：$K=2$, $N=4$,\n  标签 $y^{(3)} = [\\,1,\\,0,\\,1,\\,0\\,]$,\n  分数\n  $$S^{(3)} = \\begin{bmatrix}\n  0.2  0.8\\\\\n  0.3  0.7\\\\\n  0.4  0.6\\\\\n  0.1  0.9\n  \\end{bmatrix},\\quad (\\alpha,\\tau,\\varepsilon) = (20.0,\\,0.9,\\,10^{-8}).$$\n- 用例 $4$（多分类，一个类别在标签中缺失但在预测中存在）：$K=3$, $N=6$,\n  标签 $y^{(4)} = [\\,0,\\,1,\\,1,\\,0,\\,1,\\,0\\,]$,\n  分数\n  $$S^{(4)} = \\begin{bmatrix}\n  0.6  0.2  0.2\\\\\n  0.2  0.5  0.3\\\\\n  0.1  0.6  0.3\\\\\n  0.55  0.15  0.3\\\\\n  0.3  0.5  0.2\\\\\n  0.4  0.2  0.4\n  \\end{bmatrix},\\quad (\\alpha,\\tau,\\varepsilon) = (25.0,\\,0.5,\\,10^{-8}).$$\n- 用例 $5$（多分类，因陡峭度小而导致代理非常平滑）：$K=3$, $N=5$,\n  标签 $y^{(5)} = [\\,0,\\,1,\\,2,\\,1,\\,0\\,]$,\n  分数\n  $$S^{(5)} = \\begin{bmatrix}\n  0.6  0.3  0.1\\\\\n  0.2  0.5  0.3\\\\\n  0.3  0.2  0.5\\\\\n  0.4  0.45  0.15\\\\\n  0.55  0.25  0.2\n  \\end{bmatrix},\\quad (\\alpha,\\tau,\\varepsilon) = (1.0,\\,0.5,\\,10^{-8}).$$\n\n您的程序应生成单行输出，其中包含五个损失值，格式为方括号内的逗号分隔列表，每个值四舍五入到 $6$ 位小数，没有空格，并按照上述用例的顺序排列，例如 `\"[a_1,a_2,a_3,a_4,a_5]\"`，其中每个 $a_j$ 是四舍五入到 $6$ 位小数的十进制表示。",
            "solution": "该问题要求为宏$F_1$损失函数构建并实现一个可微代理，该函数常用于多类别分类任务。标准的宏$F_1$分数由于依赖于指示函数 $I\\{\\cdot\\}$ 而不可微，这使其不适合直接用作基于梯度的优化算法（如随机梯度下降）中的损失函数。任务是用一个光滑的近似函数，特别是 logistic (sigmoid) 函数，来替换这个不连续函数，并推导出相应的可微损失。\n\n框架是一个具有 $N$ 个样本的 $K$ 类分类问题。模型输出一个分数矩阵 $S$，其中 $S_{ic} = f_\\theta(x_i)_c \\in [0,1]$ 是第 $i$ 个样本属于第 $c$ 类的分数。通过将此分数与一个阈值 $\\tau \\in [0,1]$ 进行比较来做出对类别 $c$ 的预测。\n\n首先，我们定义指示函数的光滑代理。对样本 $i$ 和类别 $c$ 的硬预测基于应用于边距的指示函数 $I\\{S_{ic} - \\tau \\ge 0\\}$。我们用 logistic (sigmoid) 函数 $s(z)$ 替换它，这是一个对亥维赛德阶跃函数 (Heaviside step function) 的光滑、可微、单调的近似。sigmoid 的参数 $z$ 是边距 $z_{ic} = S_{ic} - \\tau$。sigmoid 的陡峭度由一个参数 $\\alpha  0$ 控制，它决定了近似阶跃函数的紧密程度。因此，软性的、可微的预测 $\\tilde{y}_{ic}$ 由下式给出：\n$$ \\tilde{y}_{ic} = s(\\alpha(S_{ic} - \\tau)) = \\frac{1}{1 + e^{-\\alpha(S_{ic} - \\tau)}} $$\n这个值 $\\tilde{y}_{ic}$可以解释为样本 $i$ 被预测为类别 $c$ 的软概率。\n\n接下来，我们以“一对多”的方式为每个类别 $c$ 构建混淆矩阵计数的可微模拟量。设 $Y$ 是真实标签的独热编码矩阵 (one-hot encoded)，其中如果样本 $i$ 的真实标签是 $c$，则 $y_{ic}=1$，否则 $y_{ic}=0$。标准的“硬”计数是包含指示函数的乘积之和。通过用我们的软预测 $\\tilde{y}_{ic}$ 替换基于指示函数的硬预测，我们得到可微的或“软”的计数：\n\n-   **软真正例 ($\\widetilde{\\mathrm{TP}}_c$)**：对于真实属于类别 $c$ 的样本，其软预测的总和。\n    $$ \\widetilde{\\mathrm{TP}}_c = \\sum_{i=1}^N y_{ic} \\cdot \\tilde{y}_{ic} $$\n-   **软假正例 ($\\widetilde{\\mathrm{FP}}_c$)**：对于不属于类别 $c$ 的样本，其软预测的总和。\n    $$ \\widetilde{\\mathrm{FP}}_c = \\sum_{i=1}^N (1 - y_{ic}) \\cdot \\tilde{y}_{ic} $$\n-   **软假反例 ($\\widetilde{\\mathrm{FN}}_c$)**：对于真实属于类别 $c$ 的样本，其“错失”的概率总和。\n    $$ \\widetilde{\\mathrm{FN}}_c = \\sum_{i=1}^N y_{ic} \\cdot (1 - \\tilde{y}_{ic}) $$\n\n有了这些可微计数，我们可以为类别$F_1$分数定义一个代理。类别 $c$ 的标准 $F_1$分数是 $F_{1,c} = \\frac{2 \\cdot \\mathrm{TP}_c}{2 \\cdot \\mathrm{TP}_c + \\mathrm{FP}_c + \\mathrm{FN}_c}$。为了创建一个数值稳定且可微的版本，我们替换为软计数，并在分子和分母中添加一个小的正常数 $\\varepsilon$ 以防止除以零，特别是当一个类别可能没有真正例时。\n$$ \\widetilde{F}_{1,c} = \\frac{2 \\cdot \\widetilde{\\mathrm{TP}}_c + \\varepsilon}{2 \\cdot \\widetilde{\\mathrm{TP}}_c + \\widetilde{\\mathrm{FP}}_c + \\widetilde{\\mathrm{FN}}_c + \\varepsilon} $$\n项 $2 \\cdot \\widetilde{\\mathrm{TP}}_c + \\widetilde{\\mathrm{FP}}_c + \\widetilde{\\mathrm{FN}}_c$ 可简化为 $\\sum_{i=1}^N \\tilde{y}_{ic} + \\sum_{i=1}^N y_{ic}$，这是类别 $c$ 的总软预测和总真实实例之和。\n\n宏$F_1$分数是各类别 $F_1$分数的算术平均值。可微代理遵循此定义：\n$$ \\widetilde{\\text{macro-}F_1} = \\frac{1}{K} \\sum_{c=0}^{K-1} \\widetilde{F}_{1,c} $$\n\n最后，要最小化的目标，即损失 $\\mathcal{L}$，定义为 1 减去代理宏$F_1$分数。这将分数最大化问题转化为适合基于梯度的学习的最小化问题。\n$$ \\mathcal{L} = 1 - \\widetilde{\\text{macro-}F_1} $$\n这整个计算流程对于模型分数 $S_{ic}$（并因此对于模型参数 $\\theta$）和阈值 $\\tau$ 都是可微的，使其可以用作训练目标。\n\n该实现为给定的测试用例计算这些量。对于每个用例，它接收标签、分数和超参数 $(\\alpha, \\tau, \\varepsilon)$。它首先构建独热真实标签矩阵 $Y$，然后是软预测矩阵 $\\tilde{Y}$。它使用向量化数组操作计算软计数向量 $\\widetilde{\\mathrm{TP}}$、$\\widetilde{\\mathrm{FP}}$ 和 $\\widetilde{\\mathrm{FN}}$。根据这些，计算类别代理 $F_1$分数，然后是宏平均和最终损失。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating the differentiable surrogate F1 loss\n    for a predefined suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"labels\": [1, 0, 1, 0, 1, 0],\n            \"scores\": np.array([\n                [0.8, 0.2],\n                [0.3, 0.7],\n                [0.6, 0.4],\n                [0.4, 0.6],\n                [0.55, 0.45],\n                [0.2, 0.8]\n            ]),\n            \"params\": (20.0, 0.5, 1e-8)\n        },\n        {\n            \"labels\": [0, 1, 2, 1, 0],\n            \"scores\": np.array([\n                [0.99, 0.005, 0.005],\n                [0.01, 0.98, 0.01],\n                [0.02, 0.01, 0.97],\n                [0.005, 0.99, 0.005],\n                [0.97, 0.02, 0.01]\n            ]),\n            \"params\": (30.0, 0.5, 1e-8)\n        },\n        {\n            \"labels\": [1, 0, 1, 0],\n            \"scores\": np.array([\n                [0.2, 0.8],\n                [0.3, 0.7],\n                [0.4, 0.6],\n                [0.1, 0.9]\n            ]),\n            \"params\": (20.0, 0.9, 1e-8)\n        },\n        {\n            \"labels\": [0, 1, 1, 0, 1, 0],\n            \"scores\": np.array([\n                [0.6, 0.2, 0.2],\n                [0.2, 0.5, 0.3],\n                [0.1, 0.6, 0.3],\n                [0.55, 0.15, 0.3],\n                [0.3, 0.5, 0.2],\n                [0.4, 0.2, 0.4]\n            ]),\n            \"params\": (25.0, 0.5, 1e-8)\n        },\n        {\n            \"labels\": [0, 1, 2, 1, 0],\n            \"scores\": np.array([\n                [0.6, 0.3, 0.1],\n                [0.2, 0.5, 0.3],\n                [0.3, 0.2, 0.5],\n                [0.4, 0.45, 0.15],\n                [0.55, 0.25, 0.2]\n            ]),\n            \"params\": (1.0, 0.5, 1e-8)\n        }\n    ]\n\n    def calculate_loss(labels, scores, alpha, tau, epsilon):\n        \"\"\"\n        Computes the differentiable F1-surrogate loss for a single case.\n        \n        Args:\n            labels (list): A list of ground-truth integer class labels.\n            scores (np.ndarray): An N x K matrix of model scores.\n            alpha (float): The steepness parameter for the sigmoid function.\n            tau (float): The classification threshold.\n            epsilon (float): A small constant for numerical stability.\n\n        Returns:\n            float: The computed loss value.\n        \"\"\"\n        labels = np.array(labels)\n        N, K = scores.shape\n        \n        # Create one-hot encoded ground truth matrix Y\n        Y_one_hot = np.zeros((N, K))\n        Y_one_hot[np.arange(N), labels] = 1.0\n        \n        # Calculate soft predictions matrix Y_tilde using the sigmoid surrogate\n        margins = scores - tau\n        Y_tilde = 1.0 / (1.0 + np.exp(-alpha * margins))\n        \n        # Calculate surrogate counts (TP, FP, FN) for each class\n        # Results are vectors of length K.\n        tp_surrogate = np.sum(Y_one_hot * Y_tilde, axis=0)\n        fp_surrogate = np.sum((1.0 - Y_one_hot) * Y_tilde, axis=0)\n        fn_surrogate = np.sum(Y_one_hot * (1.0 - Y_tilde), axis=0)\n        \n        # Calculate class-wise surrogate F1 scores\n        numerator = 2.0 * tp_surrogate + epsilon\n        denominator = 2.0 * tp_surrogate + fp_surrogate + fn_surrogate + epsilon\n        \n        f1_classwise = numerator / denominator\n        \n        # Calculate macro-F1 surrogate\n        macro_f1 = np.mean(f1_classwise)\n        \n        # Calculate final loss\n        loss = 1.0 - macro_f1\n        \n        return loss\n\n    results = []\n    for case in test_cases:\n        result = calculate_loss(case[\"labels\"], case[\"scores\"], *case[\"params\"])\n        # Format the result to 6 decimal places as a string\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}