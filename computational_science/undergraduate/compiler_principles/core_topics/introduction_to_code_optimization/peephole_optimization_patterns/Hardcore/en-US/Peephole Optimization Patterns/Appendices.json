{
    "hands_on_practices": [
        {
            "introduction": "A key skill in compiler design is leveraging a deep understanding of binary arithmetic to uncover non-obvious optimizations. This exercise  presents a clever bitwise identity, challenging you to first prove its correctness and then to quantify the resulting performance gain based on a simple processor model. It serves as a perfect example of how formal mathematical reasoning about bit patterns can directly translate into faster, more efficient machine code.",
            "id": "3662231",
            "problem": "Consider a compiler Peephole Optimization (PO) that targets fixed-width Two’s Complement (TC) integers. Let $a$ and $b$ be $w$-bit integers for a fixed $w \\geq 1$. The optimizer proposes replacing the expression $a - (a  b)$ with $a  (\\sim b)$, where `` denotes bitwise AND and `~` denotes bitwise NOT, and `-` denotes integer subtraction modulo $2^{w}$ under TC semantics. Using only the core definitions of bitwise operations and TC subtraction, derive the equivalence of $a - (a  b)$ and $a  (\\sim b)$ and justify that the transformation is valid both under a bitwise interpretation (per-bit Boolean algebra) and under an arithmetic interpretation (values in $\\{0,1,\\dots,2^{w}-1\\}$ for unsigned view or $\\{-2^{w-1},\\dots,2^{w-1}-1\\}$ for signed view), noting that TC signed and unsigned interpretations share the same bit patterns. Then, evaluate the performance impact of this peephole pattern on a target Central Processing Unit (CPU) that has the following instruction latencies under a simple serialized execution model with no overlap: bitwise AND costs $1$ cycle, bitwise NOT costs $1$ cycle, and subtraction costs $2$ cycles. The original sequence for $a - (a  b)$ uses one bitwise AND followed by one subtraction; the optimized sequence for $a  (\\sim b)$ uses one bitwise NOT followed by one bitwise AND. If this optimization is applied to a hot path where the pattern occurs $N = 7.5 \\times 10^{7}$ times, compute the total number of cycles saved by performing the transformation. Round your answer to four significant figures.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- Let $a$ and $b$ be $w$-bit integers in Two’s Complement (TC) format, where $w \\geq 1$.\n- The proposed optimization is to replace the expression $a - (a  b)$ with $a  (\\sim b)$.\n- The operator `` denotes bitwise AND.\n- The operator `~` denotes bitwise NOT.\n- The operator `-` denotes integer subtraction modulo $2^{w}$ under TC semantics.\n- The task requires deriving the equivalence of the two expressions and justifying the transformation under both a bitwise and an arithmetic interpretation.\n- CPU instruction latencies for a simple serialized execution model are given:\n  - Bitwise AND: $1$ cycle.\n  - Bitwise NOT: $1$ cycle.\n  - Subtraction: $2$ cycles.\n- The original instruction sequence for $a - (a  b)$ is one bitwise AND followed by one subtraction.\n- The optimized instruction sequence for $a  (\\sim b)$ is one bitwise NOT followed by one bitwise AND.\n- The pattern occurs $N = 7.5 \\times 10^{7}$ times in a hot path.\n- The final task is to compute the total number of cycles saved and round the answer to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded (Critical)**: The problem is based on fundamental principles of computer arithmetic, specifically two's complement representation, bitwise logic, and instruction cycle counting. These are standard, well-established concepts in computer science and engineering.\n- **Well-Posed**: The problem is well-posed. It asks for a proof of a known identity and a subsequent calculation based on provided parameters. A unique and meaningful solution exists.\n- **Objective (Critical)**: The problem is stated in precise, objective language, free from ambiguity or subjective claims.\n- **Completeness and Consistency**: The problem is self-contained. All necessary variables ($a$, $b$, $w$, $N$), operation definitions (bitwise AND, NOT, TC subtraction), and constants (instruction latencies) are provided. There are no internal contradictions.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and all necessary information is provided. Therefore, the problem is **valid**. We may proceed with the solution.\n\n### Part 1: Derivation of Equivalence\nWe must prove that for any $w$-bit TC integers $a$ and $b$, the expression $a - (a  b)$ is equivalent to $a  (\\sim b)$. This equivalence will be demonstrated from both a bitwise and an arithmetic perspective.\n\n#### Bitwise Proof\nLet $a_i$ and $b_i$ be the $i$-th bit of the integers $a$ and $b$, respectively, for $i \\in \\{0, 1, \\dots, w-1\\}$.\n\nFirst, consider the target expression: $a  (\\sim b)$. The $i$-th bit of the result, let's call it $r_i$, is given by the Boolean expression $r_i = a_i \\wedge (\\neg b_i)$, where $\\wedge$ denotes logical AND and $\\neg$ denotes logical NOT. We can evaluate this based on the value of $b_i$:\n- If $b_i = 0$, then $\\neg b_i = 1$, so $r_i = a_i \\wedge 1 = a_i$.\n- If $b_i = 1$, then $\\neg b_i = 0$, so $r_i = a_i \\wedge 0 = 0$.\n\nNext, consider the original expression: $a - (a  b)$. Let $c = a  b$. The $i$-th bit of $c$, $c_i$, is $a_i \\wedge b_i$. A crucial observation is that for any bit $i$, $c_i$ can only be $1$ if $a_i$ is also $1$. This means that $a_i \\geq c_i$ for all $i$.\nWhen we compute the binary subtraction $a - c$, because the bit $a_i$ is always greater than or equal to the bit $c_i$, no borrow is ever generated from bit position $i$ to position $i+1$. The subtraction can thus be performed bit by bit independently.\nThe $i$-th bit of the result, let's call it $s_i$, is therefore simply $s_i = a_i - c_i = a_i - (a_i \\wedge b_i)$. We evaluate this based on the value of $b_i$:\n- If $b_i = 0$, then $c_i = a_i \\wedge 0 = 0$. The result is $s_i = a_i - 0 = a_i$.\n- If $b_i = 1$, then $c_i = a_i \\wedge 1 = a_i$. The result is $s_i = a_i - a_i = 0$.\n\nComparing the outcomes, we see that $r_i = s_i$ in all cases. Since the resulting bit is identical for every position $i \\in \\{0, 1, \\dots, w-1\\}$, the bit patterns of $a - (a  b)$ and $a  (\\sim b)$ are identical. As TC signed and unsigned interpretations share the same bit patterns and operations, this proof holds for both.\n\n#### Arithmetic Proof\nThe arithmetic proof relies on the properties of addition and bitwise operations. For any two numbers $X$ and $Y$, the bitwise identity $(X  Y) | (X  (\\sim Y)) = X$ holds, where $|$ is bitwise OR. The two terms on the left, $(X  Y)$ and $(X  (\\sim Y))$, are bitwise disjoint, meaning there is no bit position $i$ where both terms have a $1$.\nWhen two numbers are bitwise disjoint, their arithmetic sum is equal to their bitwise OR. Therefore, for numbers represented in a fixed-width format (like TC or unsigned), we have the arithmetic equality:\n$$\na = (a  b) + (a  (\\sim b))\n$$\nThis equality holds modulo $2^w$. By rearranging the terms, we directly obtain the identity we seek to prove:\n$$\na - (a  b) = a  (\\sim b)\n$$\nThe subtraction is performed modulo $2^w$, which is consistent with the problem's definition of TC subtraction. This completes the arithmetic proof and confirms the validity of the transformation.\n\n### Part 2: Performance Impact Calculation\nWe are asked to compute the total number of cycles saved by applying this optimization $N = 7.5 \\times 10^{7}$ times.\n\nLet the latencies be:\n- $L_{\\text{AND}} = 1$ cycle\n- $L_{\\text{NOT}} = 1$ cycle\n- $L_{\\text{SUB}} = 2$ cycles\n\nThe cost of the original expression, $a - (a  b)$, is the sum of the latencies for one bitwise AND operation and one subtraction operation, executed serially.\n$$\nC_{\\text{original}} = L_{\\text{AND}} + L_{\\text{SUB}} = 1 + 2 = 3 \\text{ cycles}\n$$\n\nThe cost of the optimized expression, $a  (\\sim b)$, is the sum of the latencies for one bitwise NOT operation and one bitwise AND operation, executed serially.\n$$\nC_{\\text{optimized}} = L_{\\text{NOT}} + L_{\\text{AND}} = 1 + 1 = 2 \\text{ cycles}\n$$\n\nThe number of cycles saved per application of the optimization is the difference between the original and optimized costs.\n$$\n\\Delta C = C_{\\text{original}} - C_{\\text{optimized}} = 3 - 2 = 1 \\text{ cycle}\n$$\n\nThe total number of cycles saved over $N$ occurrences is the product of the savings per occurrence and the number of occurrences.\n$$\nS_{\\text{total}} = N \\times \\Delta C\n$$\nSubstituting the given value $N = 7.5 \\times 10^{7}$:\n$$\nS_{\\text{total}} = (7.5 \\times 10^{7}) \\times 1 = 7.5 \\times 10^{7}\n$$\n\nThe problem requires the answer to be rounded to four significant figures. The calculated value is exact. To express $7.5 \\times 10^7$ with four significant figures, we write it as $7.500 \\times 10^7$.",
            "answer": "$$\\boxed{7.500 \\times 10^7}$$"
        },
        {
            "introduction": "Not all seemingly obvious algebraic simplifications are safe to apply. While replacing an expensive division with a cheap bit-shift is a classic optimization, it is fraught with subtle semantic traps. This practice  explores one of the most common pitfalls in this area, involving the specific rules for signed integer arithmetic. You will discover why the transformation can fail and learn to design a \"guarded\" pattern that applies the optimization only when it can be proven safe, a crucial technique for building robust compilers.",
            "id": "3662235",
            "problem": "A peephole optimizer considers replacing an integer division by two, $x / 2$, with an arithmetic right shift by one, $x \\gg 1$, over signed two’s complement integers of fixed word width $w \\ge 2$. The target machine defines arithmetic right shift as sign-propagating: shifting a signed integer $x$ right by one bit yields a value obtained by discarding the least significant bit and replicating the sign bit in the most significant bit. The source language defines signed integer division by two with truncation toward zero: for any signed integer $x$, the expression $x / 2$ computes the unique integer $\\mathrm{trunc}(x/2)$ whose magnitude is the floor of $|x/2|$ and whose sign matches that of $x$. Assume the domain of $x$ is all $w$-bit signed integers in two’s complement, i.e., $x \\in \\{-2^{w-1}, -2^{w-1}+1, \\dots, 2^{w-1}-1\\}$, and that the machine implements arithmetic right shift correctly for all values in this domain.\n\nStarting from these definitions, do the following:\n\n1. Derive a precise condition on $x$ under which the semantics of $x / 2$ and $x \\gg 1$ agree, and a complementary condition under which they disagree. Demonstrate the disagreement with at least one explicit counterexample value of $x$.\n\n2. Propose a guarded peephole rewrite pattern that applies the replacement $x / 2 \\mapsto x \\gg 1$ only when a local proof in the instruction stream establishes that $x \\ge 0$ at the use site. Describe the guard in terms of a dominating comparison that is syntactically available to a peephole optimizer (no global dataflow is needed), and explain why this guard preserves semantics.\n\n3. Suppose $x$ is uniformly distributed over all $w$-bit signed integers. Compute the exact fraction, as a reduced rational number, of all values of $x$ for which an unguarded replacement $x / 2 \\mapsto x \\gg 1$ would change the result of the program. Express your final fraction without a percentage sign.\n\nYour final answer must be a single real number or a single closed-form analytic expression. No rounding is required.",
            "solution": "The problem requires an analysis of the semantic equivalence between integer division by two and arithmetic right shift by one for signed two's complement integers. We must first validate the problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Operation 1: Integer division by two, denoted as $x / 2$. Its semantics are defined as truncation toward zero, i.e., $\\mathrm{trunc}(x/2)$. For any signed integer x, this yields the unique integer whose magnitude is $\\lfloor |x/2| \\rfloor$ and whose sign is the same as the sign of x.\n-   Operation 2: Arithmetic right shift by one, denoted as $x \\gg 1$. Its semantics are defined as discarding the least significant bit and replicating the sign bit into the most significant bit position.\n-   Integer Representation: Signed two's complement integers with a fixed word width $w \\ge 2$.\n-   Domain of x: The set of all $w$-bit signed integers, which is $\\{ -2^{w-1}, -2^{w-1}+1, \\dots, 2^{w-1}-1 \\}$.\n-   Assumption: The target machine correctly implements the arithmetic right shift for all values in the specified domain.\n-   Task 1: Derive conditions for agreement and disagreement between $x / 2$ and $x \\gg 1$, with a counterexample for disagreement.\n-   Task 2: Propose a guarded peephole optimization using a locally available dominating comparison to ensure $x \\ge 0$.\n-   Task 3: For a uniform distribution of x over its domain, compute the exact fraction of values where an unguarded replacement $x / 2 \\mapsto x \\gg 1$ would be incorrect.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, being a standard topic in compiler construction and computer architecture. The definitions provided for two's complement arithmetic, integer division semantics (truncation toward zero), and arithmetic right shift are standard and unambiguous. The problem is self-contained, providing all necessary information. The constraints ($w \\ge 2$) are reasonable. The problem is objective and well-posed, leading to a unique and verifiable solution. There are no contradictions, factual errors, or unverifiable claims.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A full solution will be provided.\n\n### Solution Derivation\n\nFirst, we must precisely formalize the mathematical behavior of the two operations. The standard definition of an arithmetic right shift by one bit on a two's complement integer x is that it computes the floor of the division of x by 2. That is, $x \\gg 1 \\equiv \\lfloor x/2 \\rfloor$. The programming language's division, $x / 2$, is defined as truncation toward zero, which can be expressed piece-wise:\n$$\n\\mathrm{trunc}(v) =\n\\begin{cases}\n    \\lfloor v \\rfloor  \\text{if } v \\ge 0 \\\\\n    \\lceil v \\rceil  \\text{if } v  0\n\\end{cases}\n$$\nTherefore, $x / 2 \\equiv \\mathrm{trunc}(x/2)$.\n\n**1. Conditions for Agreement and Disagreement**\n\nWe seek the condition on x under which $x \\gg 1$ and $x / 2$ are equivalent. This means finding when $\\lfloor x/2 \\rfloor = \\mathrm{trunc}(x/2)$.\n\nCase 1: $x \\ge 0$\nFor any non-negative x, $x/2 \\ge 0$. The definition of $\\mathrm{trunc}$ for non-negative values is $\\mathrm{trunc}(v) = \\lfloor v \\rfloor$.\nThus, for $x \\ge 0$, we have $\\mathrm{trunc}(x/2) = \\lfloor x/2 \\rfloor$.\nIn this case, the semantics of $x / 2$ and $x \\gg 1$ always agree.\n\nCase 2: $x  0$\nFor any negative x, $x/2  0$. The definition of $\\mathrm{trunc}$ for negative values is $\\mathrm{trunc}(v) = \\lceil v \\rceil$.\nThe equivalence condition becomes $\\lfloor x/2 \\rfloor = \\lceil x/2 \\rceil$.\nThe floor and ceiling of a number are equal if and only if the number is an integer. Therefore, the operations agree if and only if $x/2$ is an integer. This is true if and only if x is an even number.\nThe operations disagree if $\\lfloor x/2 \\rfloor \\neq \\lceil x/2 \\rceil$, which occurs if and only if $x/2$ is not an integer. This is true if and only if x is an odd number.\n\nSummary of conditions:\n-   **Agreement**: The semantics of $x/2$ and $x \\gg 1$ agree if $x \\ge 0$, or if x is a negative even number.\n-   **Disagreement**: The semantics disagree if x is a negative odd number.\n\nAs a demonstration of disagreement, let's provide a counterexample. Let x = -3.\n-   Language-defined division: $x / 2 = \\mathrm{trunc}(-3/2) = \\mathrm{trunc}(-1.5) = -1$.\n-   Arithmetic right shift: $x \\gg 1 = \\lfloor -3/2 \\rfloor = \\lfloor -1.5 \\rfloor = -2$.\nClearly, $-1 \\neq -2$, demonstrating the semantic difference.\n\n**2. Guarded Peephole Rewrite Pattern**\n\nBased on the analysis above, the replacement $x / 2 \\mapsto x \\gg 1$ is semantically preserving if it can be proven that $x \\ge 0$. A peephole optimizer can enforce this condition using a guard. A common scenario in compiled code is an `if` statement that tests the sign of a variable. This generates a comparison instruction followed by a conditional branch.\n\nConsider a sequence of machine instructions corresponding to `if (x >= 0) { y = x / 2; }`. This might be compiled to:\n`CMP x, #0`  (Compare register `x` with the immediate value 0)\n`JL is_negative` (Jump if Less to a different code block)\n`...`\n`DIV x, #2` (Integer division, result in `x`)\n`...`\n`is_negative:`\n`...`\n\nA peephole optimizer examining the `DIV` instruction can look backwards in the instruction stream. If it finds a preceding `CMP x, #0` and determines that the current basic block is only reachable if the \"greater than or equal to\" condition was met (i.e., the `JL` branch was not taken), it has a local proof that $x \\ge 0$ at the point of the division.\n\nThe **guarded peephole rewrite pattern** is as follows:\n-   **Pattern**: Identify a division by 2 (`DIV reg, #2`).\n-   **Guard**: Scan backwards within the peephole window for a `CMP reg, #0` instruction that has not been invalidated by an intervening instruction that modifies `reg`. Verify that the control flow leading to the `DIV` instruction guarantees that the condition $reg \\ge 0$ was met at the time of the comparison.\n-   **Replacement**: If the guard is satisfied, replace the `DIV reg, #2` instruction with a faster `SAR reg, #1` (Shift Arithmetic Right by 1) instruction.\n\nThis guard preserves semantics because, as proven in the first part, for all $x \\ge 0$, $\\mathrm{trunc}(x/2) = \\lfloor x/2 \\rfloor$. The guard ensures the condition for equivalence is met, making the optimization safe.\n\n**3. Fraction of Disagreeing Values**\n\nWe need to compute the fraction of $w$-bit signed integers for which the unguarded replacement would be incorrect. This corresponds to the set of values where $x/2 \\neq x \\gg 1$, which we identified as the set of negative odd integers.\n\nThe total number of distinct values for a $w$-bit integer is $2^w$.\nThe domain of signed two's complement integers is $\\{ -2^{w-1}, \\dots, -1, 0, 1, \\dots, 2^{w-1}-1 \\}$.\n-   The number of non-negative integers (0 to $2^{w-1}-1$) is $2^{w-1}$.\n-   The number of negative integers ($-2^{w-1}$ to $-1$) is $-1 - (-2^{w-1}) + 1 = 2^{w-1}$.\n\nWe need to count how many of these $2^{w-1}$ negative integers are odd. An integer is odd if and only if its least significant bit (LSB) is 1. An integer is even if and only if its LSB is 0. In any range of $N$ consecutive integers, if $N$ is even, there are exactly $N/2$ odd integers and $N/2$ even integers.\nThe range of negative integers, from $-2^{w-1}$ to $-1$, contains $2^{w-1}$ consecutive integers. Since the problem specifies $w \\ge 2$, the number of negative integers $2^{w-1}$ is an even number (as $2^{2-1}=2$, $2^{3-1}=4$, etc.).\nTherefore, the number of odd negative integers is exactly half of the total number of negative integers.\n\nNumber of odd negative integers = $\\frac{1}{2} \\times (\\text{Number of negative integers}) = \\frac{1}{2} \\times 2^{w-1} = 2^{w-2}$.\n\nThe fraction of values for which the replacement is incorrect is the ratio of the count of disagreeing values to the total count of values.\n$$\n\\text{Fraction} = \\frac{\\text{Number of odd negative integers}}{\\text{Total number of integers}} = \\frac{2^{w-2}}{2^w} = 2^{w-2-w} = 2^{-2} = \\frac{1}{4}\n$$\nThis fraction, $\\frac{1}{4}$, is independent of the word width $w$ (as long as $w \\ge 2$).\nThus, for a uniformly distributed $w$-bit signed integer, there is a 25% probability that an unguarded replacement of division by two with an arithmetic right shift will yield an incorrect result.",
            "answer": "$$\n\\boxed{\\frac{1}{4}}\n$$"
        },
        {
            "introduction": "Making code faster is rarely a simple choice, as optimizations often involve complex trade-offs. This problem  moves beyond simple pattern replacement and into the realistic world of cost-benefit analysis. By evaluating a strength-reduction pattern for multiplication, you will use a formal cost model to weigh the benefits of reduced execution time against the costs of increased code size and register pressure, learning how modern compilers make nuanced decisions about whether an optimization is truly \"profitable\".",
            "id": "3662150",
            "problem": "A compiler back-end for a $w$-bit machine ($w = 32$) uses an Intermediate Representation (IR) with two’s-complement modular integer arithmetic modulo $2^{w}$. The target has no dedicated hardware multiply, but the code generator can either emit a runtime helper call for multiplication, or synthesize multiplication by a constant using shifts and adds. The peephole optimizer is considering replacing a computation of the form $y \\leftarrow x \\times 9$ with a sequence using a left shift by $3$ and an addition. The optimizer must ensure semantic equivalence in the IR and decide profitability using a linear decision model.\n\nFundamental base assumptions:\n- Semantics: In modular arithmetic modulo $2^{w}$, left shift by $k$ bits implements multiplication by $2^{k}$ modulo $2^{w}$, and integer addition is taken modulo $2^{w}$.\n- Decision model: The optimizer minimizes an objective $J$ that combines three costs as a weighted sum,\n$$\nJ \\;=\\; \\alpha \\cdot L \\;+\\; \\beta \\cdot B \\;+\\; \\gamma \\cdot \\Delta R,\n$$\nwhere $L$ is the instruction latency in cycles along the local path, $B$ is the code size in bytes, and $\\Delta R$ is the increase in the maximum number of simultaneously live registers (a proxy for register pressure). The weights are fixed for a given compilation setting.\n\nConsider the following concrete target characterizations and peephole context:\n- Baseline multiply-by-constant implementation when no hardware multiply is available: a helper call with end-to-end latency $L_{\\text{call}} = 18$ cycles, code size $B_{\\text{call}} = 4$ bytes, and no increase in live registers for the caller beyond the existing live set (i.e., $\\Delta R_{\\text{call}} = 0$ for this local decision).\n- Synthesized sequence for multiply-by-$9$: emit a left shift of $x$ by $3$ bits followed by an addition with $x$. Each instruction has latency $1$ cycle and encoding size $4$ bytes, so $L_{\\text{synth}} = 2$ cycles and $B_{\\text{synth}} = 8$ bytes. Because $x$ remains live after computing $y$ (it is used later in the block), one additional temporary is required to hold the shifted value across the addition, so the local maximum number of simultaneously live registers increases by exactly $1$ over the two-instruction window (i.e., $\\Delta R_{\\text{synth}} = 1$).\n- Weight setting S1 (default): $\\alpha = 1$, $\\beta = 0.1$, $\\gamma = 3$.\n- Weight setting S2 (high pressure): same as S1 except $\\gamma = 20$.\n- Alternative target scenario T3 (for comparison only): suppose instead the target does have a slow hardware multiply instruction with latency $L_{\\text{mul}} = 4$ cycles and code size $B_{\\text{mul}} = 4$ bytes (still with $\\Delta R_{\\text{mul}} = 0$), even though the original description said no hardware multiply; this is to stress-test the decision rule’s sensitivity.\n\nWhich of the following statements are correct?\n\nA. Under setting S1 on the no-multiply target, applying the peephole rewrite to replace $x \\times 9$ with the shift-and-add sequence is profitable according to the objective $J$.\n\nB. Under setting S2 on the no-multiply target, applying the peephole rewrite is still profitable according to the objective $J$.\n\nC. Under scenario T3 with setting S1, the peephole rewrite is not profitable according to the objective $J$.\n\nD. Even under two’s-complement modular semantics modulo $2^{32}$, replacing $x \\times 9$ by $(x \\ll 3) + x$ is semantically unsafe in the presence of overflow.\n\nE. In the stated context where $x$ remains live after the computation of $y$, the shift-and-add implementation increases the local maximum number of simultaneously live registers by exactly $1$ compared to the helper call implementation.",
            "solution": "The problem statement is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n\n-   **Machine and Arithmetic:** A $w$-bit machine with $w = 32$. The Intermediate Representation (IR) uses two’s-complement modular integer arithmetic modulo $2^w$.\n-   **Optimization Task:** Replacing the computation $y \\leftarrow x \\times 9$ with a sequence of a left shift and an addition.\n-   **Semantic Assumption:** Left shift by $k$ bits is multiplication by $2^k$ modulo $2^w$. Integer addition is also modulo $2^w$.\n-   **Decision Model:** The optimizer seeks to minimize the objective function $J = \\alpha \\cdot L + \\beta \\cdot B + \\gamma \\cdot \\Delta R$.\n    -   $L$: instruction latency in cycles.\n    -   $B$: code size in bytes.\n    -   $\\Delta R$: increase in the maximum number of simultaneously live registers.\n-   **Baseline Implementation (no hardware multiply):** A helper call with characteristics:\n    -   $L_{\\text{call}} = 18$ cycles.\n    -   $B_{\\text{call}} = 4$ bytes.\n    -   $\\Delta R_{\\text{call}} = 0$.\n-   **Synthesized Implementation (shift-and-add):** A sequence of a left shift by $3$ and an addition, with characteristics:\n    -   $L_{\\text{synth}} = 2$ cycles (each of two instructions has latency $1$).\n    -   $B_{\\text{synth}} = 8$ bytes (each of two instructions has size $4$).\n    -   $\\Delta R_{\\text{synth}} = 1$ (due to a temporary register needed to hold the intermediate result of the shift, while $x$ remains live).\n-   **Weight Settings:**\n    -   **S1:** $\\alpha = 1$, $\\beta = 0.1$, $\\gamma = 3$.\n    -   **S2:** $\\alpha = 1$, $\\beta = 0.1$, $\\gamma = 20$.\n-   **Alternative Target Scenario T3:** A hypothetical target with a hardware multiply instruction:\n    -   $L_{\\text{mul}} = 4$ cycles.\n    -   $B_{\\text{mul}} = 4$ bytes.\n    -   $\\Delta R_{\\text{mul}} = 0$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is evaluated against the validation criteria.\n\n-   **Scientific Groundedness:** The problem is firmly rooted in the principles of compiler construction, specifically code generation and peephole optimization. The model of modular arithmetic, the cost function for optimization heuristics, and the strength-reduction transformation ($x \\times 9 \\rightarrow (x \\ll 3) + x$) are all standard and well-established concepts in the field.\n-   **Well-Posedness:** The problem provides a clear objective (evaluate the given statements) and all necessary quantitative data (costs, weights) to perform the required calculations. The scenarios are distinct and the questions unambiguous.\n-   **Objectivity:** The language is technical and precise, free from subjective or non-scientific claims.\n-   **Consistency and Completeness:** The provided data is self-consistent. The alternative scenario T3 is explicitly labeled as a separate case for comparison and does not contradict the main problem setup. All parameters required for the decision model are defined for each case. The semantic rules are explicitly stated.\n\nThe problem formulation is scientifically sound, well-posed, objective, and self-contained. Therefore, it is valid.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. A solution will be derived.\n\nA peephole rewrite is considered \"profitable\" if the objective function value for the new code sequence is less than that of the original sequence. The optimizer's goal is to minimize $J$.\n\nThe objective function for the baseline helper call is:\n$$J_{\\text{call}} = \\alpha \\cdot L_{\\text{call}} + \\beta \\cdot B_{\\text{call}} + \\gamma \\cdot \\Delta R_{\\text{call}}$$\n$$J_{\\text{call}} = \\alpha \\cdot 18 + \\beta \\cdot 4 + \\gamma \\cdot 0$$\n\nThe objective function for the synthesized shift-and-add sequence is:\n$$J_{\\text{synth}} = \\alpha \\cdot L_{\\text{synth}} + \\beta \\cdot B_{\\text{synth}} + \\gamma \\cdot \\Delta R_{\\text{synth}}$$\n$$J_{\\text{synth}} = \\alpha \\cdot 2 + \\beta \\cdot 8 + \\gamma \\cdot 1$$\n\nWe now evaluate each statement.\n\n**A. Under setting S1 on the no-multiply target, applying the peephole rewrite...is profitable...**\n\nUnder setting S1, the weights are $\\alpha = 1$, $\\beta = 0.1$, and $\\gamma = 3$. We compare $J_{\\text{call}}$ and $J_{\\text{synth}}$.\n\n-   Cost of helper call:\n    $$J_{\\text{call}} = (1 \\cdot 18) + (0.1 \\cdot 4) + (3 \\cdot 0) = 18 + 0.4 + 0 = 18.4$$\n-   Cost of synthesized sequence:\n    $$J_{\\text{synth}} = (1 \\cdot 2) + (0.1 \\cdot 8) + (3 \\cdot 1) = 2 + 0.8 + 3 = 5.8$$\n\nSince $5.8  18.4$, we have $J_{\\text{synth}}  J_{\\text{call}}$. The rewrite is profitable.\n\nVerdict: **Correct**.\n\n**B. Under setting S2 on the no-multiply target, applying the peephole rewrite is still profitable...**\n\nUnder setting S2, the weights are $\\alpha = 1$, $\\beta = 0.1$, and $\\gamma = 20$. The substantial increase in $\\gamma$ penalizes register pressure.\n\n-   Cost of helper call (note that $\\Delta R_{\\text{call}}=0$, so the cost is independent of $\\gamma$):\n    $$J_{\\text{call}} = (1 \\cdot 18) + (0.1 \\cdot 4) + (20 \\cdot 0) = 18 + 0.4 + 0 = 18.4$$\n-   Cost of synthesized sequence:\n    $$J_{\\text{synth}} = (1 \\cdot 2) + (0.1 \\cdot 8) + (20 \\cdot 1) = 2 + 0.8 + 20 = 22.8$$\n\nSince $22.8  18.4$, we have $J_{\\text{synth}}  J_{\\text{call}}$. The rewrite is not profitable. The statement claims it is profitable.\n\nVerdict: **Incorrect**.\n\n**C. Under scenario T3 with setting S1, the peephole rewrite is not profitable...**\n\nIn scenario T3, the baseline is a hardware multiply instruction. Its characteristics are $L_{\\text{mul}} = 4$, $B_{\\text{mul}} = 4$, and $\\Delta R_{\\text{mul}} = 0$. We use setting S1 weights ($\\alpha = 1, \\beta = 0.1, \\gamma = 3$).\n\n-   Cost of hardware multiply:\n    $$J_{\\text{mul}} = (1 \\cdot 4) + (0.1 \\cdot 4) + (3 \\cdot 0) = 4 + 0.4 + 0 = 4.4$$\n-   Cost of synthesized sequence (from A, as weights are S1):\n    $$J_{\\text{synth}} = 5.8$$\n\nSince $5.8  4.4$, we have $J_{\\text{synth}}  J_{\\text{mul}}$. The rewrite is not profitable. The statement claims it is not profitable.\n\nVerdict: **Correct**.\n\n**D. Even under two’s-complement modular semantics modulo $2^{32}$, replacing $x \\times 9$ by $(x \\ll 3) + x$ is semantically unsafe in the presence of overflow.**\n\nThe problem defines the IR semantics as modular arithmetic modulo $2^w$, where $w = 32$.\n-   The left shift operation `x  3` is defined as multiplication by $2^3$, i.e., $x \\cdot 8 \\pmod{2^w}$.\n-   The addition operation is also modular, i.e., $a + b \\pmod{2^w}$.\n\nTherefore, the expression $(x \\ll 3) + x$ evaluates to $(x \\cdot 8 \\pmod{2^w}) + x \\pmod{2^w}$.\nBy the properties of modular arithmetic, this is equivalent to $(x \\cdot 8 + x) \\pmod{2^w}$.\nUsing the distributive law, this simplifies to $x \\cdot (8 + 1) \\pmod{2^w}$, which is $x \\cdot 9 \\pmod{2^w}$.\n\nThis is precisely the semantics of the original operation, $x \\times 9$, within the specified IR. The concept of \"overflow\" meaning an error or undefined behavior is not applicable here; the wrap-around behavior is the defined, correct semantic. The transformation is thus semantically equivalent and perfectly safe under all conditions within this arithmetic model.\n\nVerdict: **Incorrect**.\n\n**E. In the stated context where $x$ remains live after the computation of $y$, the shift-and-add implementation increases the local maximum number of simultaneously live registers by exactly $1$ compared to the helper call implementation.**\n\nLet's analyze the register requirements. The quantity $\\Delta R$ is the increase in the maximum number of live registers.\n-   **Helper call:** The problem explicitly states $\\Delta R_{\\text{call}} = 0$. This is the baseline.\n-   **Shift-and-add sequence:**\n    1.  `t1 - x  3`\n    2.  `y - t1 + x`\n    Before this sequence, $x$ is live. Let the set of other live registers be $S_{\\text{live}}$. The number of live registers is $1 + |S_{\\text{live}}|$.\n    After instruction $1$, `t1` must be stored in a temporary register, and it is live. $x$ is also still live because it is needed for instruction $2$ and is specified to be live after the entire computation. So, between instructions $1$ and $2$, the live registers are at least $\\{x, t1\\} \\cup S_{\\text{live}}$. The maximum number of live registers in this window is $2 + |S_{\\text{live}}|$. The increase over the state before the sequence is $(2 + |S_{\\text{live}}|) - (1 + |S_{\\text{live}}|) = 1$. The problem correctly identifies this, stating $\\Delta R_{\\text{synth}} = 1$.\n\nThe increase for the shift-and-add sequence is $\\Delta R_{\\text{synth}} = 1$. The increase for the helper call is $\\Delta R_{\\text{call}} = 0$. The difference between them is $\\Delta R_{\\text{synth}} - \\Delta R_{\\text{call}} = 1 - 0 = 1$. The statement is a direct and correct interpretation of the problem's premises.\n\nVerdict: **Correct**.",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}