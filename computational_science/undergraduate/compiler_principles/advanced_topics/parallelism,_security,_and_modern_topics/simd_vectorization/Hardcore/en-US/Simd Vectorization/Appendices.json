{
    "hands_on_practices": [
        {
            "introduction": "Efficient SIMD vectorization hinges on ensuring that memory accesses are aligned with the hardware's requirements. Misaligned vector loads and stores can incur significant performance penalties, forcing the hardware to perform extra work. This exercise provides a hands-on look at a classic compiler optimization, loop peeling, used to transform a misaligned loop into a mostly-aligned one, allowing you to quantify the performance gains from this fundamental technique. ",
            "id": "3670086",
            "problem": "A compiler vectorizes the loop updating a contiguous array of single-precision values as follows: for index $i$ from $0$ to $N-1$, it performs $x[i] \\leftarrow x[i] + c$, where $x$ is an array of elements of size $E$ bytes and $c$ is a scalar constant. The machine supports Single Instruction Multiple Data (SIMD) vectors of width $W$ elements, with natural alignment $A$ bytes. The base address $p$ of $x$ is such that $p \\bmod A = 8$ bytes. Assume $E = 4$ bytes (single precision), $W = 8$, and $A = 32$ bytes, so that $W \\cdot E = A$. The total number of elements is $N = 1022$.\n\nUse the following cost model, which is throughput-limited and additive across iterations with no overlap:\n- A scalar iteration processing one element costs $c_s = 3$ cycles.\n- An aligned SIMD vector iteration processing $W$ elements costs $c_a = 2$ cycles.\n- A misaligned SIMD vector iteration (due to base address misalignment sustained across the loop) incurs an additional penalty of $d = 5$ cycles per vector iteration, so that its cost is $c_a + d$.\n\nStarting from the definitions of memory alignment and congruences, determine the minimal nonnegative number of scalar peel iterations $k$ required so that after peeling $k$ scalar iterations, the SIMD body operates on an address aligned to $A$. Then, propose the loop structure consisting of a scalar prologue of $k$ iterations, an aligned SIMD body, and a scalar epilogue for the remainder. Quantify the total number of cycles saved by performing this loop peeling compared to a naive SIMD vectorization that does not peel and thus executes all its vector iterations misaligned. Express the final result as a single integer number of cycles saved. Do not include any units in your final boxed answer.",
            "solution": "The user wants me to solve a compiler optimization problem regarding SIMD vectorization and memory alignment. I will first validate the problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- The loop operation is $x[i] \\leftarrow x[i] + c$ for index $i$ from $0$ to $N-1$.\n- Total number of elements: $N = 1022$.\n- Size of each element: $E = 4$ bytes.\n- SIMD vector width: $W = 8$ elements.\n- Natural alignment requirement: $A = 32$ bytes.\n- The base address $p$ of the array $x$ has the property $p \\bmod A = 8$ bytes.\n- It is stated that $W \\cdot E = A$, which is $8 \\cdot 4 = 32$, consistent with the given values.\n- Cost of a single scalar iteration: $c_s = 3$ cycles.\n- Cost of an aligned SIMD vector iteration: $c_a = 2$ cycles.\n- Cost penalty for a misaligned SIMD vector iteration: $d = 5$ cycles.\n- The cost of a misaligned SIMD vector iteration is $c_a + d$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes a classic scenario in computer architecture and compiler optimization, specifically loop vectorization with memory alignment considerations. The cost model, while simplified, reflects the real-world performance trade-offs between scalar and vector processing, and the penalties for misaligned memory access. The principles are sound.\n- **Well-Posed:** All necessary constants ($N$, $E$, $W$, $A$, $c_s$, $c_a$, $d$) and initial conditions ($p \\bmod A = 8$) are provided. The questions asked—to find the number of peel iterations, describe the resulting loop structure, and quantify the performance gain—are specific and lead to a unique, meaningful solution.\n- **Objective:** The problem is stated in precise, quantitative terms. The cost model is explicitly defined, leaving no room for subjective interpretation.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed with the solution.\n\n### Solution\n\nThe solution involves three main parts:\n1.  Determining the number of scalar peel iterations, $k$, required to align the starting address of the main vector loop.\n2.  Calculating the total execution time for a naive, misaligned vectorization strategy.\n3.  Calculating the total execution time for an optimized strategy using loop peeling, and then finding the difference to quantify the cycles saved.\n\n**1. Determine the Number of Peel Iterations ($k$)**\n\nThe address of the $i$-th element of the array $x$ is given by $p + i \\cdot E$, where $p$ is the base address. For the SIMD vector loop to operate on aligned data, its starting address must be a multiple of the alignment size, $A$. If we peel $k$ scalar iterations, the vector loop will start processing at index $k$. The address of this element is $p + k \\cdot E$. The alignment condition is therefore:\n$$(p + k \\cdot E) \\bmod A = 0$$\nWe are given the following values: $p \\bmod A = 8$, $E = 4$, and $A = 32$. Substituting these values into the congruence relation:\n$$((p \\bmod A) + (k \\cdot E) \\bmod A) \\bmod A = 0$$\n$$ (8 + 4k) \\bmod 32 = 0 $$\nThis equation implies that $8 + 4k$ must be a multiple of $32$. We can write this as an equation in integers:\n$$8 + 4k = 32j$$\nwhere $j$ is a positive integer. We seek the smallest non-negative integer $k$ that satisfies this condition.\n$$4k = 32j - 8$$\n$$k = 8j - 2$$\nTo find the minimum non-negative $k$, we test integer values for $j$ starting from $1$:\n- For $j=1$: $k = 8(1) - 2 = 6$.\nThis is the smallest non-negative integer value for $k$.\nThus, $k=6$ scalar iterations must be peeled from the beginning of the loop.\n\nThe proposed loop structure is as follows:\n- **Scalar prologue:** A loop that iterates from $i=0$ to $k-1=5$, executing the operation $x[i] \\leftarrow x[i] + c$.\n- **Aligned SIMD body:** A vectorized loop that starts at index $i=k=6$. It processes $W=8$ elements per iteration. The number of elements to be processed in this loop and the subsequent epilogue is $N - k = 1022 - 6 = 1016$. The number of vector iterations is $\\lfloor \\frac{1016}{8} \\rfloor = 127$. This loop covers indices from $6$ to $6 + (127 \\cdot 8) - 1 = 1021$.\n- **Scalar epilogue:** A loop for the remaining elements. The number of remaining elements is $(N - k) \\bmod W = 1016 \\bmod 8 = 0$. Therefore, no scalar epilogue is needed.\n\n**2. Calculate the Cost of Naive (Misaligned) Vectorization**\n\nIn a naive vectorization strategy, the compiler generates a SIMD loop starting at index $0$ without peeling. Since the base address $p$ is misaligned ($p \\bmod 32 = 8$), all vector memory accesses will be misaligned, because the starting address of any subsequent vector chunk (at index $j \\cdot W$) is $p + (j \\cdot W) \\cdot E = p + j \\cdot A$, and $(p + j \\cdot A) \\bmod A = p \\bmod A = 8 \\neq 0$.\n\nThe cost of a misaligned vector iteration is $c_m = c_a + d = 2 + 5 = 7$ cycles.\nThe number of full vector iterations is $N_{\\text{vec, naive}} = \\lfloor \\frac{N}{W} \\rfloor = \\lfloor \\frac{1022}{8} \\rfloor = 127$.\nThe cost of the vector part is $T_{\\text{vec, naive}} = N_{\\text{vec, naive}} \\cdot c_m = 127 \\cdot 7 = 889$ cycles.\n\nThe number of remaining elements that must be processed by a scalar epilogue is $N_{\\text{epilogue, naive}} = N \\bmod W = 1022 \\bmod 8 = 6$.\nThe cost of the scalar epilogue is $T_{\\text{epilogue, naive}} = N_{\\text{epilogue, naive}} \\cdot c_s = 6 \\cdot 3 = 18$ cycles.\n\nThe total cost for the naive strategy is $T_{\\text{naive}} = T_{\\text{vec, naive}} + T_{\\text{epilogue, naive}} = 889 + 18 = 907$ cycles.\n\n**3. Calculate the Cost of Optimized (Peeled) Vectorization and the Savings**\n\nIn the optimized strategy, we first execute a scalar prologue of $k=6$ iterations.\nThe cost of the prologue is $T_{\\text{prologue}} = k \\cdot c_s = 6 \\cdot 3 = 18$ cycles.\n\nAfter the prologue, $N' = N - k = 1022 - 6 = 1016$ elements remain. The SIMD loop starts at index $6$, where the address is aligned. All vector iterations in this loop are aligned.\nThe number of aligned vector iterations is $N_{\\text{vec, opt}} = \\lfloor \\frac{N'}{W} \\rfloor = \\lfloor \\frac{1016}{8} \\rfloor = 127$.\nThe cost of the vector part is $T_{\\text{vec, opt}} = N_{\\text{vec, opt}} \\cdot c_a = 127 \\cdot 2 = 254$ cycles.\n\nThe number of elements for a final scalar epilogue is $N_{\\text{epilogue, opt}} = N' \\bmod W = 1016 \\bmod 8 = 0$.\nThe cost of the epilogue is $T_{\\text{epilogue, opt}} = 0$ cycles.\n\nThe total cost for the optimized strategy is $T_{\\text{opt}} = T_{\\text{prologue}} + T_{\\text{vec, opt}} + T_{\\text{epilogue, opt}} = 18 + 254 + 0 = 272$ cycles.\n\nFinally, the total number of cycles saved is the difference between the naive and optimized costs:\n$$\\text{Savings} = T_{\\text{naive}} - T_{\\text{opt}} = 907 - 272 = 635$$\n\nThe loop peeling strategy saves $635$ cycles compared to the naive misaligned vectorization.",
            "answer": "$$\\boxed{635}$$"
        },
        {
            "introduction": "Beyond simple arithmetic, the true power of SIMD lies in its ability to accelerate complex algorithms that are not obviously parallel. This requires reformulating the algorithm in a data-parallel fashion, often using clever primitives that map well to vector instructions. In this practice, you will vectorize a sliding-window median filter by implementing it as a sorting network built from vectorized compare-exchange operations, demonstrating a powerful pattern for parallelizing order-based statistics. ",
            "id": "3670096",
            "problem": "You are to implement a data-parallel sliding-window median filter using Single Instruction Multiple Data (SIMD) vectorization, expressed purely as sorting networks constructed from compare-exchange primitives on equal-length vectors. The objective is to compute the median values for windows of size $3$ and $9$ across integer arrays, processing multiple windows in parallel lanes. All algorithmic steps must be grounded on accepted principles of compiler design for vectorization and the theory of sorting networks.\n\nFundamental base to be used:\n- The Single Instruction Multiple Data (SIMD) execution model applies a single operation to multiple data elements simultaneously. In our abstract formulation, this is represented by vectors of fixed lane width $L$ and elementwise operations on those lanes.\n- A compare-exchange primitive on two equal-length vectors is defined as the pair of elementwise functions that produce their elementwise minima and maxima. Specifically, for two input vectors $x$ and $y$, define $x_{\\min} = \\min(x,y)$ and $x_{\\max} = \\max(x,y)$, where $\\min$ and $\\max$ are applied lane-wise. The compare-exchange replaces $x \\leftarrow x_{\\min}$ and $y \\leftarrow x_{\\max}$. This models a sorting comparator as used in sorting networks, but performed across $L$ lanes simultaneously.\n- Sorting networks are fixed sequences of compare-exchange operations that sort a fixed number of inputs regardless of input values. They can be used to obtain order statistics such as the median element. A straightforward, well-tested choice is the odd-even transposition sorting network, which sorts $n$ elements with $n$ passes: on even passes it compares indices $(0,1),(2,3),\\dots$, and on odd passes it compares $(1,2),(3,4),\\dots$. For $n=9$, after $9$ passes the inputs are sorted; the median is the element at index $4$ (zero-based). For $n=3$, a minimal network exists that sorts with $3$ compare-exchange steps; the median is the element at index $1$ after sorting.\n\nImplementation requirements:\n- Represent vectors of lane width $L$ (a fixed positive integer) and implement lane-wise $\\min$ and $\\max$ operations. Use these to implement a vector compare-exchange that maps two input vectors to their elementwise order, with the first receiving the minima and the second receiving the maxima.\n- Implement a median-of-$3$ sorting network by composing compare-exchange on $3$ vector registers. Then apply this network lane-wise to $L$ windows simultaneously.\n- Implement a median-of-$9$ sorting network using odd-even transposition on $9$ vector registers. Then apply this network lane-wise to $L$ windows simultaneously.\n- Implement a sliding median filter with stride $1$ and valid-window semantics: for an array of length $N$ and window size $K$, produce exactly $N-K+1$ outputs if $N \\ge K$, otherwise produce zero outputs. All inputs are integers. No physical units apply in this problem.\n- Vectorization strategy: for a batch starting at window index $i$ and lane width $L$, construct $K$ vector registers such that lane $\\ell$ contains the element of window $(i+\\ell)$ at its $t$-th position, for $t \\in \\{0,1,\\dots,K-1\\}$. Perform the sorting network compare-exchange steps over these $K$ vector registers. Extract the median vector register and write out the first $m$ lanes, where $m = \\min(L, \\text{remaining windows})$. Repeat until all windows are processed. Use scalar fallback implicitly by reducing $m$ when fewer than $L$ windows remain; there is no separate scalar path required.\n\nTest suite:\n- Case 1: median-of-3 on array [1, 5, 2, 4, 3, 8, 7, 6].\n- Case 2: median-of-3 on array [9, 9, 9].\n- Case 3: median-of-9 on array [10, 1, 9, 2, 8, 3, 7, 4, 6, 5, 0, 11, 12].\n- Case 4: median-of-9 on array [5, 1, 5, 1, 5, 1, 5, 1, 5].\n- Case 5: median-of-9 on array [1, 2, 3, 4, 5, 6, 7, 8] (length less than $9$), which should produce an empty list.\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets, in the order of the test cases. For example, the format must be exactly of the form $[\\, [\\dots], [\\dots], [\\dots], [\\dots], [\\dots] \\,]$ with no spaces. Concretely, your output must be a single line with five sublists corresponding to Cases $1$ through $5$, in that order.\n\nDeliverables:\n- Provide a single, complete, runnable program implementing the above, with fixed lane width $L$ chosen by you and clearly documented in code comments. The program must not read any input and must print exactly one line in the required format.",
            "solution": "The problem requires the implementation of a data-parallel sliding-window median filter. The solution must be based on the specified principles of Single Instruction, Multiple Data (SIMD) vectorization and sorting networks. The core of the problem is to process multiple sliding windows of an integer array concurrently by mapping the algorithmic steps onto vector operations.\n\nThe fundamental principle is data parallelism, where a single operation is applied to multiple data elements, or \"lanes,\" simultaneously. We will model a SIMD vector as a fixed-size array of integers. Let the lane width be $L$. We choose a fixed lane width of $L=4$ for this implementation, representing a typical width for SIMD architectures (e.g., a $128$-bit register holding four $32$-bit integers). A vector $v$ is thus a tuple $(v_0, v_1, \\dots, v_{L-1})$.\n\nThe elementary building block of our sorting networks is the compare-exchange primitive. For two input vectors, $v_a$ and $v_b$, of length $L$, the compare-exchange operation modifies them such that after the operation, $v_a$ contains the element-wise minima and $v_b$ contains the element-wise maxima. That is, for each lane $i \\in \\{0, 1, \\dots, L-1\\}$, the new values $v'_{a,i}$ and $v'_{b,i}$ are computed as:\n$$ v'_{a,i} = \\min(v_{a,i}, v_{b,i}) $$\n$$ v'_{b,i} = \\max(v_{a,i}, v_{b,i}) $$\nThis operation is performed in parallel for all $L$ lanes and forms one vectorized compare-exchange step.\n\nWith this primitive, we construct sorting networks to find the median of a set of numbers. A sorting network is an oblivious sorting algorithm, meaning the sequence of comparisons is fixed and does not depend on the input data. This property makes them perfectly suited for hardware implementation or, in our case, SIMD vectorization.\n\nFor a window of size $K=3$, we use a minimal sorting network that sorts three elements with three compare-exchange operations. Given three vector registers, $r_0, r_1, r_2$, which hold the elements of $L$ windows at positions $0$, $1$, and $2$ respectively, the sorting proceeds as:\n1. Compare-exchange($r_0, r_1$)\n2. Compare-exchange($r_1, r_2$)\n3. Compare-exchange($r_0, r_1$)\nAfter these three steps, the vector register $r_1$ will contain, for each lane, the median of the three corresponding input values.\n\nFor a window of size $K=9$, a more complex network is required. The problem specifies the use of an odd-even transposition sorting network. This network sorts $n$ elements in $n$ passes. For our case, $n=9$. We use $9$ vector registers, $r_0, r_1, \\dots, r_8$. The algorithm iterates for $p$ from $0$ to $n-1 = 8$:\n- **Even Pass ($p$ is even):** Perform compare-exchange on pairs of registers $(r_i, r_{i+1})$ for all even indices $i \\in \\{0, 2, 4, 6\\}$.\n- **Odd Pass ($p$ is odd):** Perform compare-exchange on pairs of registers $(r_i, r_{i+1})$ for all odd indices $i \\in \\{1, 3, 5, 7\\}$.\nAfter $9$ such passes, the $9$ registers are sorted lane-wise. The median of $9$ elements is the 5th element (index $4$), so the vector register $r_4$ will contain the median for each of the $L$ windows.\n\nThe sliding-window filter is implemented by processing the input array in batches. For an input array `data` of length $N$ and a window size $K$, there are $N-K+1$ medians to compute. We iterate through these windows, processing up to $L$ windows at a time.\nIn each batch, starting at window index $i$, we first load data into the $K$ vector registers. This is a \"gather\" operation. For each register $t \\in \\{0, \\dots, K-1\\}$ and each active lane $\\ell \\in \\{0, \\dots, L-1\\}$, we load the value:\n$$ r_{t, \\ell} = \\text{data}[i + \\ell + t] $$\nThis organizes the data into a Structure-of-Arrays (SoA) layout, where each register holds the same-indexed element from $L$ different windows.\nAfter loading, a sorting network (`median-of-3` or `median-of-9`) is applied to the $K$ registers. Finally, the median values are extracted from the median register (e.g., $r_1$ for $K=3$, $r_4$ for $K=9$) and written to the output array. This is a \"scatter\" operation.\nTo handle cases where the number of remaining windows is less than $L$, the number of active lanes, $m$, is calculated as $m = \\min(L, \\text{remaining\\_windows})$. This ensures that the algorithm does not access data outside the array bounds and correctly processes the final few windows. This approach gracefully degrades to scalar-like processing when $m=1$ without requiring a separate code path.",
            "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include stdio.h\n#include stdlib.h\n#include string.h\n#include math.h\n// #include complex.h\n// #include threads.h\n// #include stdatomic.h\n\n// The lane width L for our SIMD model.\n// A width of 4 is chosen, analogous to a 128-bit SIMD register with 32-bit integers.\n#define LANE_WIDTH 4\n\n// A struct representing a SIMD vector of LANE_WIDTH integers.\ntypedef struct {\n    int lanes[LANE_WIDTH];\n} Vector;\n\n// The compare-exchange primitive. Operates element-wise on two vectors.\n// For each lane, the smaller value goes to v1 and the larger value to v2.\nvoid compare_exchange(Vector* v1, Vector* v2) {\n    for (int i = 0; i  LANE_WIDTH; ++i) {\n        int a = v1-lanes[i];\n        int b = v2-lanes[i];\n        if (a  b) {\n            v1-lanes[i] = b;\n            v2-lanes[i] = a;\n        }\n    }\n}\n\n// Sorting network for 3 vector registers.\n// After 3 compare-exchange steps, registers[1] holds the lane-wise medians.\nvoid median_of_3_network(Vector registers[3]) {\n    compare_exchange(registers[0], registers[1]); // C-E(r0, r1)\n    compare_exchange(registers[1], registers[2]); // C-E(r1, r2)\n    compare_exchange(registers[0], registers[1]); // C-E(r0, r1)\n}\n\n// Odd-even transposition sorting network for 9 vector registers.\n// After 9 passes, registers[4] holds the lane-wise medians.\nvoid median_of_9_network(Vector registers[9]) {\n    int n = 9;\n    for (int p = 0; p  n; ++p) {\n        if (p % 2 == 0) { // Even pass\n            compare_exchange(registers[0], registers[1]);\n            compare_exchange(registers[2], registers[3]);\n            compare_exchange(registers[4], registers[5]);\n            compare_exchange(registers[6], registers[7]);\n        } else { // Odd pass\n            compare_exchange(registers[1], registers[2]);\n            compare_exchange(registers[3], registers[4]);\n            compare_exchange(registers[5], registers[6]);\n            compare_exchange(registers[7], registers[8]);\n        }\n    }\n}\n\n// The main SIMD sliding median filter function.\nvoid sliding_median_filter(const int* data, int n_data, int k_window, int* result, int* result_count) {\n    *result_count = (n_data = k_window) ? (n_data - k_window + 1) : 0;\n    if (*result_count == 0) {\n        return;\n    }\n\n    Vector registers[k_window];\n\n    // Process windows in batches of LANE_WIDTH\n    for (int i = 0; i  *result_count; i += LANE_WIDTH) {\n        // Determine number of active lanes for this batch to handle edges\n        int active_lanes = (*result_count - i  LANE_WIDTH) ? (*result_count - i) : LANE_WIDTH;\n\n        // Load data into vector registers (gather operation)\n        for (int t = 0; t  k_window; ++t) {\n            for (int l = 0; l  active_lanes; ++l) {\n                registers[t].lanes[l] = data[i + l + t];\n            }\n        }\n\n        // Apply a sorting network based on window size\n        int median_register_idx = k_window / 2;\n        if (k_window == 3) {\n            median_of_3_network(registers);\n        } else if (k_window == 9) {\n            median_of_9_network(registers);\n        }\n        \n        // Extract the median vector and store results (scatter operation)\n        for (int l = 0; l  active_lanes; ++l) {\n            result[i + l] = registers[median_register_idx].lanes[l];\n        }\n    }\n}\n\n// A helper function to print an integer array in the required list format.\nvoid print_result_list(const int* arr, int count) {\n    printf(\"[\");\n    for (int i = 0; i  count; ++i) {\n        printf(\"%d\", arr[i]);\n        if (i  count - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n}\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    const int* data;\n    int data_size;\n    int window_size;\n} TestCase;\n\nint main(void) {\n    // Define the test data from the problem statement.\n    int case1_data[] = {1, 5, 2, 4, 3, 8, 7, 6};\n    int case2_data[] = {9, 9, 9};\n    int case3_data[] = {10, 1, 9, 2, 8, 3, 7, 4, 6, 5, 0, 11, 12};\n    int case4_data[] = {5, 1, 5, 1, 5, 1, 5, 1, 5};\n    int case5_data[] = {1, 2, 3, 4, 5, 6, 7, 8};\n\n    TestCase test_cases[] = {\n        {case1_data, sizeof(case1_data) / sizeof(case1_data[0]), 3},\n        {case2_data, sizeof(case2_data) / sizeof(case2_data[0]), 3},\n        {case3_data, sizeof(case3_data) / sizeof(case3_data[0]), 9},\n        {case4_data, sizeof(case4_data) / sizeof(case4_data[0]), 9},\n        {case5_data, sizeof(case5_data) / sizeof(case5_data[0]), 9},\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int max_outputs = 20; // Sufficiently large buffer for results\n    int results[max_outputs];\n\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        int result_count = 0;\n        sliding_median_filter(test_cases[i].data, test_cases[i].data_size, test_cases[i].window_size, results, result_count);\n        print_result_list(results, result_count);\n        if (i  num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```"
        },
        {
            "introduction": "Compilers must adhere to the \"as-if\" rule, meaning any optimization must not change the observable behavior of the program as defined by its sequential semantics. The speculative nature of SIMD can sometimes violate this rule, especially in loops with potential exceptions like division by zero, leading to incorrect results or altered program termination. This practice challenges you to model how naive vectorization can break sequential correctness and to explore safeguards that compilers use to preserve program semantics while still leveraging SIMD performance. ",
            "id": "3670137",
            "problem": "You are to design and implement a complete and runnable program to detect when a compiler transformation known as Single Instruction Multiple Data (SIMD) vectorization can change observable behavior for a loop that may raise exceptions due to division by zero. The core scenario is a loop computing $c[i] = a[i] / b[i]$ for indices $i$ from $0$ to $n-1$, where $b[i]$ may equal $0$, thereby potentially changing how exceptions occur and how elements of $c[i]$ are written when the loop is vectorized.\n\nFundamental base: In a sequential execution model, the program executes operations in program order (left-to-right over the loop indices). Observable behavior includes which iterations perform writes to memory and whether exceptional conditions occur, such as division by zero. Compilers are constrained to transformations that preserve observable behavior according to the as-if rule and to sequential semantics of the source language. However, speculative and out-of-order evaluation in SIMD vectorization may cause operations that would not execute under sequential short-circuit semantics to be performed, thereby writing additional elements and altering the index at which exceptions appear to occur. These facts are widely accepted and serve as the foundational starting point of this task.\n\nDesign a detector and safeguards using the following requirements:\n\n1. Define a sequential scalar semantics for the loop: iterate $i$ from $0$ to $n-1$, compute $a[i]/b[i]$, and assign to $c[i]$ until the first index $s$ such that $b[s] = 0$, at which point the loop stops without writing $c[s]$ or any $c[j]$ for $j \\ge s$. For the purposes of this detector, treat any value $b[i]$ satisfying $b[i] = 0$ (including $-0$) as a zero.\n\n2. Define a naive SIMD-vectorized semantics model with a fixed vector width $w$: process indices in chunks of width $w$, performing all divisions $a[i+j]/b[i+j]$ for chunk lanes $j$ where $i+j  n$, and write all results to $c[i+j]$ even if some $b[i+j] = 0$. This simulates speculative evaluation across lanes, and it does not short-circuit at the first zero.\n\n3. Define two safeguards to preserve observable behavior identical to the scalar semantics:\n   - Guard $G_1$ (pre-scan and fallback): Pre-scan the entire $b[i]$ array to check whether any $b[i] = 0$. If any zero is found, skip vectorization entirely and execute the scalar loop; otherwise, use naive SIMD-vectorized semantics. This is a conservative choice ensuring identical behavior when zeros exist, and full vectorization only when safe.\n   - Guard $G_2$ (masked prefix): Compute the index $s$ of the first zero by pre-scan. Perform vectorized computation only for indices $i  s$; do not write $c[i]$ for any $i \\ge s$. This simulates a vectorized masked execution that respects short-circuit behavior and avoids speculative writes at and beyond the first exceptional index.\n\n4. Implement a detector that compares the results produced by the naive SIMD-vectorized semantics to the results produced by the scalar semantics and reports whether behavior changed. To make comparison unambiguous, initialize all $c[i]$ to not-a-number and treat any $c[i]$ that remains not-a-number as \"not written.\" A behavioral change is detected if any index $k$ has differing write status or differing value between the vectorized semantics and the scalar semantics. Use double-precision floating point arithmetic for all computations. If any division generates $\\infty$ or not-a-number under vectorized semantics, treat it as a valid write for detection purposes.\n\n5. For each safeguard ($G_1$ and $G_2$), implement its corresponding semantics and report whether the safeguard preserves identical behavior to the scalar semantics.\n\n6. Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a three-integer list $[x_1, x_2, x_3]$ for a test case, with $x_1$ indicating whether naive SIMD-vectorized semantics changed behavior relative to scalar semantics, $x_2$ indicating whether Guard $G_1$ preserved behavior, and $x_3$ indicating whether Guard $G_2$ preserved behavior. Use $0$ for \"no change\" or \"preserved\" and $1$ for \"changed\" or \"not preserved.\"\n\nThere are no physical units involved. Angles are not applicable. Percentages are not applicable.\n\nTest suite and coverage:\n\nUse a fixed vector width $w = 4$ for all test cases. The loop length $n$ and arrays $a$ and $b$ for each test are specified below. All values are double-precision literals.\n\n- Test case 1 (happy path, no zeros):\n  - $n = 6$\n  - $a = [1, 2, 3, 4, 5, 6]$\n  - $b = [1, 1, 1, 1, 1, 1]$\n\n- Test case 2 (multiple zeros, early zero):\n  - $n = 6$\n  - $a = [10, 20, 30, 40, 50, 60]$\n  - $b = [2, 0, 5, 10, 0, 3]$\n\n- Test case 3 (zero at the first index):\n  - $n = 4$\n  - $a = [7, 8, 9, 10]$\n  - $b = [0, 2, 3, 4]$\n\n- Test case 4 (zero at the last index):\n  - $n = 4$\n  - $a = [8, 16, 24, 32]$\n  - $b = [2, 2, 2, 0]$\n\n- Test case 5 (signed zero):\n  - $n = 4$\n  - $a = [1.0, -2.0, 3.5, -4.5]$\n  - $b = [1.0, -0.0, 2.0, 2.0]$\n\n- Test case 6 (zero crossing vector chunk boundary):\n  - $n = 9$\n  - $a = [1, 2, 3, 4, 5, 6, 7, 8, 9]$\n  - $b = [1, 1, 1, 1, 1, 0, 1, 1, 1]$\n\nFinal output format specification:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a bracketed list of three integers $[x_1,x_2,x_3]$. For example, a valid output with two test cases would look like $[[0,0,0],[1,0,0]]$. Your program must produce exactly one line in this format and must not read any input.",
            "solution": "The problem requires the design and implementation of a program to analyze how SIMD (Single Instruction, Multiple Data) vectorization by a compiler can alter the observable behavior of a loop, specifically in the presence of division-by-zero exceptions. The analysis is performed by comparing the output of a well-defined sequential (scalar) loop against the output of a naive vectorized loop and two safeguarded vectorized loops.\n\nThe core principle at issue is the compiler's adherence to the `as-if` rule, which allows any transformation that does not change the observable behavior of the program as defined by the language's abstract machine. In sequential languages like C, program execution and its side effects (memory writes, exceptions) are defined by program order. A loop like `for (i=0; in; ++i) c[i] = a[i] / b[i];` is specified to execute for `i=0`, then `i=1`, and so on. If `b[k]` is zero, an exception is raised at iteration `k`, and no subsequent iterations are executed.\n\nSIMD vectorization breaks this strict sequential execution. A SIMD instruction operates on a vector of data elements simultaneously. For the given loop, a compiler might generate code that computes four divisions (`a[i]/b[i]`, `a[i+1]/b[i+1]`, ..., `a[i+3]/b[i+3]`) in a single instruction. This is a form of speculative execution: all four divisions are performed even if a scalar execution would have terminated at, say, `b[i+1] == 0`. According to the IEEE 754 floating-point standard, division by zero does not terminate the program but produces `+Infinity` or `-Infinity`. Consequently, the vectorized loop may write values to `c` for indices where the scalar loop would have written nothing, thus changing observable behavior.\n\nThis program models and detects such behavioral changes. The logic is designed around four distinct execution semantics and a comparison mechanism.\n\n1.  **Semantic Models**:\n    *   **Scalar Semantics**: This serves as the ground truth, perfectly emulating the C language's sequential execution model. A loop iterates from index $i=0$ to $n-1$. At each index, it checks if the divisor $b[i]$ is zero (which includes both $+0.0$ and $-0.0$). If it is, the loop terminates immediately, and no write to $c[i]$ or any subsequent elements occurs. Otherwise, it computes $c[i] = a[i] / b[i]$ and proceeds.\n    *   **Naive SIMD Semantics**: This model simulates a simple, aggressive vectorization strategy with a fixed vector width $w=4$. The loop is processed in chunks of size $w$. Within each chunk, all $w$ division operations are performed in parallel, irrespective of whether any divisors in that chunk are zero. The results, including any `Infinity` values from division by zero, are written to the corresponding elements of the output array $c$. This models how speculative execution across SIMD lanes can bypass the short-circuiting behavior of the scalar loop.\n    *   **Guard $G_1$ (Pre-scan and Fallback)**: This models a conservative safeguard. Before attempting vectorization, the entire divisor array $b$ is scanned for zeros. If any zero is found, vectorization is deemed unsafe, and the program falls back to the safe Scalar Semantics. If no zeros are found, the behavior of the vectorized loop is guaranteed to be identical to the scalar loop, so it proceeds with the Naive SIMD Semantics for maximum performance. This approach ensures correctness at the cost of a pre-scan and potentially forgoing vectorization.\n    *   **Guard $G_2$ (Masked Prefix)**: This models a more sophisticated safeguard that mimics modern masked vector instructions. It first finds the index $s$ of the first zero in the divisor array $b$. It then performs vectorized computation only on the \"safe prefix\" of the arrays, i.e., for all indices $i  s$. No writes are performed for any index $i \\ge s$. This preserves the exact termination behavior of the scalar loop while still benefiting from vectorization on the initial part of the computation.\n\n2.  **Behavioral Change Detection**:\n    To rigorously compare the outcomes of these semantics, the output array $c$ for each simulation is first initialized with Not-a-Number ($NaN$) values. A $NaN$ value at an index $i$ after a simulation signifies that $c[i]$ was never written. A behavioral change between two models is detected if, for any index $k$, either:\n    *   The \"write status\" differs: one model wrote a value to $c[k]$ while the other left it as $NaN$.\n    *   Both models wrote to $c[k]$, but the values are different.\n    This comparison is implemented by a function that iterates through the result arrays and returns `1` (change detected) or `0` (no change).\n\nThe overall program structure involves iterating through a suite of predefined test cases. For each case, it simulates all four semantics, producing four corresponding result arrays for $c$. It then compares the results from the Naive SIMD, Guard $G_1$, and Guard $G_2$ models against the ground-truth Scalar model to generate a triplet of flags $[x_1, x_2, x_3]$, indicating whether each model preserved the original scalar behavior. By design, the safeguards $G_1$ and $G_2$ should always preserve behavior, so their corresponding flags $x_2$ and $x_3$ serve as a validation of the simulation's correctness. The flag $x_1$ reveals the conditions under which naive vectorization is unsafe.",
            "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include stdio.h\n#include stdlib.h\n#include string.h\n#include math.h\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int n;\n    const double* a;\n    const double* b;\n    const char* description;\n} TestCase;\n\n// Forward declarations\nvoid init_c_array(double* c, int n);\nvoid run_scalar(double* c, const double* a, const double* b, int n);\nvoid run_naive_simd(double* c, const double* a, const double* b, int n, int w);\nvoid run_guard_g1(double* c, const double* a, const double* b, int n, int w);\nvoid run_guard_g2(double* c, const double* a, const double* b, int n, int w);\nint compare_results(const double* c1, const double* c2, int n);\nint find_first_zero_index(const double* b, int n);\n\n\nvoid init_c_array(double* c, int n) {\n    for (int i = 0; i  n; ++i) {\n        c[i] = NAN;\n    }\n}\n\nvoid run_scalar(double* c, const double* a, const double* b, int n) {\n    for (int i = 0; i  n; ++i) {\n        if (b[i] == 0.0) {\n            break; // Stop at first division by zero\n        }\n        c[i] = a[i] / b[i];\n    }\n}\n\nvoid run_naive_simd(double* c, const double* a, const double* b, int n, int w) {\n    for (int i = 0; i  n; i += w) {\n        for (int j = 0; j  w; ++j) {\n            int idx = i + j;\n            if (idx  n) {\n                // All operations in the vector are performed\n                c[idx] = a[idx] / b[idx];\n            }\n        }\n    }\n}\n\nint find_first_zero_index(const double* b, int n) {\n    for (int i = 0; i  n; ++i) {\n        if (b[i] == 0.0) {\n            return i;\n        }\n    }\n    return n; // Return n if no zero is found\n}\n\nvoid run_guard_g1(double* c, const double* a, const double* b, int n, int w) {\n    int has_zero = 0;\n    for (int i = 0; i  n; ++i) {\n        if (b[i] == 0.0) {\n            has_zero = 1;\n            break;\n        }\n    }\n\n    if (has_zero) {\n        run_scalar(c, a, b, n);\n    } else {\n        run_naive_simd(c, a, b, n, w);\n    }\n}\n\nvoid run_guard_g2(double* c, const double* a, const double* b, int n, int w) {\n    int first_zero_idx = find_first_zero_index(b, n);\n    // Perform vectorized computation only up to the first zero.\n    // We achieve this by running the naive SIMD model on a problem of size `first_zero_idx`.\n    run_naive_simd(c, a, b, first_zero_idx, w);\n}\n\nint compare_results(const double* c1, const double* c2, int n) {\n    for (int i = 0; i  n; ++i) {\n        int c1_is_nan = isnan(c1[i]);\n        int c2_is_nan = isnan(c2[i]);\n\n        // If one is NaN and the other is not, they differ (different write status)\n        if (c1_is_nan != c2_is_nan) {\n            return 1;\n        }\n        \n        // If both are not NaN, compare their values\n        if (!c1_is_nan  c1[i] != c2[i]) {\n            return 1;\n        }\n    }\n    return 0; // Results are identical\n}\n\nint main(void) {\n    // Define the test case data.\n    const double a1[] = {1, 2, 3, 4, 5, 6};\n    const double b1[] = {1, 1, 1, 1, 1, 1};\n\n    const double a2[] = {10, 20, 30, 40, 50, 60};\n    const double b2[] = {2, 0, 5, 10, 0, 3};\n\n    const double a3[] = {7, 8, 9, 10};\n    const double b3[] = {0, 2, 3, 4};\n\n    const double a4[] = {8, 16, 24, 32};\n    const double b4[] = {2, 2, 2, 0};\n\n    const double a5[] = {1.0, -2.0, 3.5, -4.5};\n    const double b5[] = {1.0, -0.0, 2.0, 2.0};\n\n    const double a6[] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n    const double b6[] = {1, 1, 1, 1, 1, 0, 1, 1, 1};\n\n    TestCase test_cases[] = {\n        {6, a1, b1, \"Happy path, no zeros\"},\n        {6, a2, b2, \"Multiple zeros, early zero\"},\n        {4, a3, b3, \"Zero at the first index\"},\n        {4, a4, b4, \"Zero at the last index\"},\n        {4, a5, b5, \"Signed zero\"},\n        {9, a6, b6, \"Zero crossing vector chunk boundary\"}\n    };\n    \n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases][3];\n    const int w = 4;\n\n    for (int i = 0; i  num_cases; ++i) {\n        TestCase tc = test_cases[i];\n        int n = tc.n;\n\n        // Allocate result arrays for the current test case\n        double* c_scalar = malloc(n * sizeof(double));\n        double* c_naive = malloc(n * sizeof(double));\n        double* c_g1 = malloc(n * sizeof(double));\n        double* c_g2 = malloc(n * sizeof(double));\n        if (!c_scalar || !c_naive || !c_g1 || !c_g2) {\n            fprintf(stderr, \"Memory allocation failed\\n\");\n            return EXIT_FAILURE;\n        }\n\n        // Initialize all to NaN\n        init_c_array(c_scalar, n);\n        init_c_array(c_naive, n);\n        init_c_array(c_g1, n);\n        init_c_array(c_g2, n);\n        \n        // Run simulations\n        run_scalar(c_scalar, tc.a, tc.b, n);\n        run_naive_simd(c_naive, tc.a, tc.b, n, w);\n        run_guard_g1(c_g1, tc.a, tc.b, n, w);\n        run_guard_g2(c_g2, tc.a, tc.b, n, w);\n\n        // Compare results and store\n        results[i][0] = compare_results(c_scalar, c_naive, n); // Naive vs Scalar\n        results[i][1] = compare_results(c_scalar, c_g1, n);    // G1 vs Scalar\n        results[i][2] = compare_results(c_scalar, c_g2, n);    // G2 vs Scalar\n\n        free(c_scalar);\n        free(c_naive);\n        free(c_g1);\n        free(c_g2);\n    }\n    \n    // Print the results in the EXACT REQUIRED format.\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        printf(\"[%d,%d,%d]\", results[i][0], results[i][1], results[i][2]);\n        if (i  num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```"
        }
    ]
}