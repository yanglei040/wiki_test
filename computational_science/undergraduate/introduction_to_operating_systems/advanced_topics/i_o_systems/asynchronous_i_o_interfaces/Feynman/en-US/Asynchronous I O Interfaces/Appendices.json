{
    "hands_on_practices": [
        {
            "introduction": "The primary goal of asynchronous I/O is to maximize resource utilization, especially keeping CPUs busy by overlapping I/O wait times with useful work. This exercise provides a foundational model for quantifying this balance. By deriving the ideal number of concurrent I/O operations needed to fully occupy a set of CPU cores, you will gain a first-principles understanding of how to structure high-performance applications and effectively hide I/O latency .",
            "id": "3621649",
            "problem": "Consider an application that processes a stream of independent requests using an Asynchronous Input/Output (AIO) interface. Each request follows a two-stage pipeline: an I/O stage and a compute stage. The I/O stage consists of submitting a read operation to the AIO subsystem and waiting for it to complete; the compute stage consists of performing deterministic computation on the data. Assume the following:\n- The AIO subsystem schedules up to $k$ outstanding I/O operations concurrently, each with deterministic latency $l$, and with no throughput degradation or queuing delay up to this level of concurrency.\n- The compute stage runs on a machine with $m$ identical central processing unit (CPU) cores, each capable of processing one request at a time. The compute time per request is deterministic and equal to $c$.\n- Scheduling overheads, data transfer bandwidth limits, memory limits, and contention effects besides the latency $l$ are negligible. The system reaches a steady state in which the arrival rate to the compute stage equals the completion rate of I/O operations.\n\nUsing only first principles from operating systems and queueing theory—specifically, the basic definition of throughput and Little’s law—derive the exact closed-form expression for the minimal integer concurrency level $k^{\\*}$ that ensures the CPU compute stage never waits for I/O completions in steady state. In other words, find the smallest $k^{\\*}$ such that the I/O latency is fully hidden and the long-run throughput is limited by the compute stage rather than by the I/O stage. Express your answer as a symbolic expression in terms of $m$, $c$, and $l$. The final answer must be a single analytic expression; do not provide an inequality or an equation.",
            "solution": "The user wants me to solve the problem. I will execute the user's request.\nThe problem is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n### Step 1: Extract Givens\n- An application processes a stream of independent requests.\n- It uses an Asynchronous Input/Output (AIO) interface.\n- Each request has a two-stage pipeline: I/O stage, then compute stage.\n- The AIO subsystem supports up to $k$ concurrent I/O operations.\n- The latency of each I/O operation is deterministic and equals $l$.\n- No I/O throughput degradation or queuing delay up to $k$ concurrency.\n- The compute stage has $m$ identical CPU cores.\n- The compute time per request is deterministic and equals $c$.\n- Scheduling overheads and other contention effects are negligible.\n- The system is in a steady state where the arrival rate to the compute stage equals the completion rate of I/O operations.\n- The objective is to find the minimal integer concurrency level $k^{\\*}$ that ensures the compute stage is the bottleneck (i.e., it never waits for I/O).\n- The derivation must use first principles, specifically the definition of throughput and Little's Law.\n- The answer must be a symbolic expression in terms of $m$, $c$, and $l$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a classic performance modeling question in operating systems, based on a producer-consumer or pipeline model.\n\n- **Scientifically Grounded:** The problem uses standard, idealized models of I/O and compute resources. The use of deterministic times and the negligence of certain overheads are common simplifying assumptions in first-principles analysis. The application of queueing theory concepts like throughput and Little's Law is appropriate and standard for this type of problem. The setup is scientifically and mathematically sound.\n- **Well-Posed:** The problem provides all necessary parameters ($m$, $c$, $l$) and a clear, unambiguous objective: to find the minimum integer $k$ that satisfies a specific performance condition. This structure leads to a unique, meaningful solution.\n- **Objective:** The problem is stated in precise, technical language, free from subjectivity or ambiguity.\n\nThe problem does not exhibit any of the invalidity flaws. It is not scientifically unsound, non-formalizable, incomplete, unrealistic (within the context of idealized modeling), or ill-posed.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be derived.\n\nThe objective is to find the minimum integer concurrency level, denoted as $k^{\\*}$, such that the throughput of the system is limited by the compute stage, not the I/O stage. This means a continuous supply of completed I/O requests must be available to the compute cores, ensuring they are never idle waiting for data.\n\nLet $\\lambda$ represent the steady-state throughput of the system, defined as the number of requests processed per unit time.\n\nFirst, we determine the maximum possible throughput of the compute stage, $\\lambda_{\\text{compute}}$. The compute stage has $m$ identical cores, and each core takes time $c$ to process a single request. The processing rate of a single core is $\\frac{1}{c}$ requests per unit time. Since the cores operate in parallel on independent requests, their capacities add up. Therefore, the maximum throughput of the compute stage is:\n$$\n\\lambda_{\\text{compute}} = m \\times \\frac{1}{c} = \\frac{m}{c}\n$$\n\nNext, we determine the maximum possible throughput of the I/O stage, $\\lambda_{\\text{I/O}}$. The problem directs us to use Little's Law, which relates the average number of items in a stable system ($N$), the average arrival/departure rate (throughput, $\\lambda$), and the average time an item spends in the system ($T$):\n$$\nN = \\lambda T\n$$\nIn the context of our AIO subsystem:\n- $N$ is the number of concurrent, outstanding I/O operations. To maximize I/O throughput, we must sustain as many concurrent operations as the system allows, which is $k$. Thus, we analyze the system at its capacity, where $N = k$.\n- $T$ is the time a request spends in the I/O stage, which is the deterministic latency $l$.\n- $\\lambda$ is the throughput of the I/O stage, $\\lambda_{\\text{I/O}}$.\n\nApplying Little's Law to the I/O subsystem:\n$$\nk = \\lambda_{\\text{I/O}} \\cdot l\n$$\nSolving for the I/O throughput gives:\n$$\n\\lambda_{\\text{I/O}} = \\frac{k}{l}\n$$\n\nThe condition that the compute stage is the bottleneck and never waits for I/O means that the I/O stage must be able to supply requests at a rate at least as great as the rate at which the compute stage can process them. This translates to the following inequality:\n$$\n\\lambda_{\\text{I/O}} \\ge \\lambda_{\\text{compute}}\n$$\n\nSubstituting the expressions for $\\lambda_{\\text{I/O}}$ and $\\lambda_{\\text{compute}}$ into the inequality:\n$$\n\\frac{k}{l} \\ge \\frac{m}{c}\n$$\n\nWe are looking for the minimal integer concurrency level $k^{\\*}$ that satisfies this condition. To find $k$, we rearrange the inequality:\n$$\nk \\ge \\frac{m \\cdot l}{c}\n$$\n\nSince $k$ must be an integer, the smallest integer value that satisfies this inequality is the ceiling of the right-hand side. The ceiling function, $\\lceil x \\rceil$, gives the smallest integer greater than or equal to $x$. Therefore, the minimal integer concurrency level $k^{\\*}$ is:\n$$\nk^{*} = \\left\\lceil \\frac{m \\cdot l}{c} \\right\\rceil\n$$\nThis expression represents the number of requests that must be \"in flight\" in the I/O system to cover the total compute work ($m/c$) that can be done during the time it takes for one I/O operation to complete ($l$). The ceiling function correctly handles the requirement that $k^{\\*}$ must be an integer.",
            "answer": "$$\n\\boxed{\\left\\lceil \\frac{m \\cdot l}{c} \\right\\rceil}\n$$"
        },
        {
            "introduction": "While powerful, mixing different I/O paradigms on the same underlying file can lead to subtle and catastrophic bugs related to state management. This practice explores a critical pitfall: combining buffered user-space I/O from libraries like C's `stdio` with modern asynchronous interfaces that operate directly on kernel file descriptions. By analyzing scenarios that cause state desynchronization, you will learn to identify and avoid data corruption bugs that arise from mismatched assumptions about the file's position and buffered data .",
            "id": "3621602",
            "problem": "A program manipulates a regular file using both the C Standard Input/Output library stream and asynchronous interfaces. The file is opened once with a single open file description, yielding a file descriptor $fd$, and then wrapped into a C Standard Input/Output stream $FILE$ via $fdopen$. Assume the following widely accepted and well-tested base facts and definitions hold:\n- The operating system kernel maintains, for each open file description, a current file offset $o$ that is advanced by sequential reads and writes.\n- A call to the system call $read$ on a descriptor that uses the shared file position reads from the current offset $o$ and advances $o$ by the number of bytes actually read.\n- A call to the system call $pread$ reads from an explicit offset without changing $o$.\n- The function $dup$ produces a new file descriptor that refers to the same open file description and therefore shares the current offset $o$.\n- The C Standard Input/Output stream $FILE$ maintains a user-space buffer (assume capacity $B = 8192$ bytes) to amortize system calls. The function $fread$ can fill this buffer with a single or multiple underlying $read$ calls and then serve application reads from this buffer without consulting the kernel again until the buffer is exhausted. The $FILE$ object’s internal notion of the next byte to deliver is independent from the kernel’s page cache and depends on the previously fetched data and the program’s subsequent reads from the stream.\n- In Linux $io\\_uring$, an operation submitted with offset $-1$ uses and advances the shared file position $o$ (file-position semantics). In contrast, $POSIX$ Asynchronous Input/Output operations such as $aio\\_read$ use an explicit offset (from $aiocb \\rightarrow aio\\_offset$) and do not change $o$.\n- Asynchronous operations may complete at any time relative to $fread$ calls unless the program enforces ordering.\n\nConsider a file of size $S = 16384$ bytes containing deterministic bytes $b[0..S-1]$. The program performs sequential reads using $fread$ on the $FILE$ stream but also submits asynchronous operations on the same underlying file. Suppose $fread$ initially fills its buffer by performing one underlying $read$ of $4096$ bytes at offset $o = 0$, then returns $2048$ bytes to the caller, leaving $2048$ bytes unread in the user-space buffer. Immediately after returning those $2048$ bytes, the program submits an asynchronous operation. After the asynchronous operation completes, the program calls $fread$ again expecting the next $2048$ bytes to be the sequence $b[2048..4095]$.\n\nWhich of the following scenarios can cause the state of $fread$ and the kernel’s notion of file position and buffered data to become desynchronized, such that the subsequent $fread$ either skips bytes, duplicates bytes, or otherwise returns a sequence not equal to the next contiguous bytes $b[2048..4095]$? Select all that apply.\n\nA. The program submits an $io\\_uring$ read with operation $IORING\\_OP\\_READ$ on $fd$ using offset $-1$ to read $4096$ bytes into an unrelated memory buffer. The asynchronous read completes before the next call to $fread$.\n\nB. The program submits a $POSIX$ Asynchronous Input/Output $aio\\_read$ on $fd$ with $aiocb \\rightarrow aio\\_offset = 4096$ to read $4096$ bytes into an unrelated memory buffer. The asynchronous read completes before the next call to $fread$.\n\nC. The program submits an $io\\_uring$ write with operation $IORING\\_OP\\_WRITE$ on $fd$ using offset $-1$ to write $4096$ bytes at the current file position $o$. The data being written overlaps the region that $fread$ would read next. The asynchronous write completes before the next call to $fread$.\n\nD. The program first duplicates the descriptor with $fd2 = dup(fd)$, then submits an $io\\_uring$ read $IORING\\_OP\\_READ$ on $fd2$ using offset $-1$ to read $4096$ bytes. The asynchronous read completes before the next call to $fread$.\n\nE. The program opens the same pathname a second time, obtaining a new, independent file descriptor $fd3$ (not via $dup$), and submits a $pread$ equivalent asynchronous read of $4096$ bytes at offset $4096$ on $fd3$. The asynchronous read completes before the next call to $fread$.\n\nGive your reasoning from the base definitions above and the concurrent nature of asynchronous completion, focusing on how and why $fread$’s user-space buffer state and the kernel’s open file description offset $o$ can diverge, and whether the kernel’s page cache contents seen by $fread$ can differ from the program’s intended sequential view of $b[0..S-1]$ in each scenario. Do not rely on library-specific undocumented behaviors; reason from the standardized semantics stated.",
            "solution": "### Problem Validation\n\n#### Step 1: Extract Givens\n\nThe problem provides the following facts, definitions, and initial conditions:\n\n1.  **File System Entities**: A regular file is manipulated via a single open file description, associated with a file descriptor $fd$ and a C Standard Input/Output stream `FILE*` stream created by $fdopen$.\n2.  **File Size**: $S = 16384$ bytes.\n3.  **File Content**: Deterministic bytes $b[0..S-1]$.\n4.  **Kernel File Offset**: The kernel maintains a current file offset $o$ for the open file description.\n5.  **System Call Semantics**:\n    *   $read$: Reads from offset $o$ and advances $o$ by the number of bytes read.\n    *   $pread$: Reads from an explicit offset and does not change $o$.\n    *   $dup$: Creates a new descriptor sharing the same open file description and thus the same offset $o$.\n6.  **C Standard I/O ($FILE*$) Semantics**:\n    *   Maintains a user-space buffer of capacity $B = 8192$ bytes.\n    *   $fread$ serves reads from this buffer.\n    *   When the buffer is exhausted, $fread$ refills it using underlying $read$ system calls, which advance the shared kernel offset $o$.\n7.  **Asynchronous I/O Semantics**:\n    *   $io\\_uring$ (Linux): An operation with offset $-1$ uses and advances the shared file position $o$.\n    *   $POSIX$ $AIO$ ($aio\\_read$): Uses an explicit offset from $aiocb \\rightarrow aio\\_offset$ and does not change $o$.\n8.  **Initial Scenario State**:\n    *   An initial $fread$ call results in an underlying $read$ of $4096$ bytes at offset $o=0$.\n    *   This initial $fread$ returns $2048$ bytes to the application.\n    *   The C library's user-space buffer now contains $2048$ bytes of unread data, corresponding to file content $b[2048..4095]$.\n    *   An asynchronous operation is submitted and completes.\n    *   A subsequent $fread$ call expects to read the next $2048$ bytes, which are $b[2048..4095]$.\n\n#### Step 2: Validate Using Extracted Givens\n\nThe problem statement is scientifically grounded in the established principles of operating systems, specifically the behavior of file I/O in Unix-like environments. The definitions provided for system calls ($read$, $pread$, $dup$), library functions ($fread$), and modern asynchronous I/O mechanisms ($io\\_uring$, $POSIX$ AIO) are accurate and consistent with their real-world, standardized behavior. The scenario is specific, self-contained, and formalizable.\n\nThere is a minor ambiguity in the problem's phrasing. It asks which scenario can cause \"the subsequent $fread$ [to return] a sequence not equal to the next contiguous bytes $b[2048..4095]$\". Given the initial state, the bytes $b[2048..4095]$ are already present in the C library's user-space buffer. Therefore, the very next call to $fread$ for $2048$ bytes will be satisfied from this buffer, without any kernel interaction, and will correctly return $b[2048..4095]$ in all scenarios. The desynchronization of the kernel file offset $o$ will only manifest as an error in a *later* $fread$ call, specifically the one that exhausts the user-space buffer and triggers the next underlying kernel $read$ to refill it.\n\nHowever, the core of the question is to identify scenarios that \"can cause the state of $fread$ and the kernel’s notion of file position and buffered data to become desynchronized\". This desynchronization is the root cause of the eventual data corruption. Interpreting \"the subsequent fread\" as any `fread` call that occurs after the state has been corrupted, rather than literally the very next one, makes the problem non-trivial and correctly tests the stated concepts. This is a reasonable interpretation of the problem's intent.\n\n#### Step 3: Verdict and Action\n\nThe problem is **valid** under the reasonable interpretation that the question is asking to identify which scenarios cause a desynchronization of the file offset that will lead to a future `fread` call returning incorrect data. The solution will proceed based on this interpretation.\n\n### Derivation and Option Analysis\n\nThe core of the problem lies in the management of the single kernel file offset $o$ associated with the open file description shared by the file descriptor $fd$ and the `FILE*` stream. Desynchronization occurs if an external operation modifies $o$ without the C standard library's knowledge.\n\n**Initial State Analysis:**\n1.  The program calls $fread$ for the first time. The `FILE*` stream's buffer is empty.\n2.  The `FILE*` stream's implementation issues a system call, `read(fd, internal_buffer, 4096)`, starting at the initial file offset $o = 0$.\n3.  This `read` is successful. The kernel reads $4096$ bytes ($b[0..4095]$) and advances the file offset to $o = 4096$.\n4.  The `FILE*` stream's buffer is now filled with $b[0..4095]$.\n5.  $fread$ copies the first $2048$ bytes ($b[0..2047]$) to the application's buffer and returns.\n6.  At this point, just before the asynchronous operation is submitted, the state is:\n    *   Kernel file offset: $o = 4096$.\n    *   `FILE*` stream's buffer: Contains $b[0..4095]$.\n    *   `FILE*` stream's internal position: Points to the next byte to be served from its buffer, which corresponds to the file content at offset $2048$. There are $2048$ bytes ($b[2048..4095]$) remaining in the buffer.\n    *   `FILE*` stream's expectation: It has consumed data up to offset $4095$. It expects the next kernel `read` to occur at offset $4096$.\n\nThe problem is to determine which of the following asynchronous operations, completing before the next buffer-refilling `read`, will alter the kernel offset $o$, thus violating the `FILE*` stream's expectation.\n\n**Option A: The program submits an $io\\_uring$ read with operation $IORING\\_OP\\_READ$ on $fd$ using offset $-1$ to read $4096$ bytes into an unrelated memory buffer. The asynchronous read completes before the next call to $fread$.**\n\nAccording to the provided definitions, an $io\\_uring$ operation with `offset = -1` uses and advances the shared file position $o$. The operation is submitted on $fd$, which uses the shared open file description. Before this operation, $o = 4096$. The asynchronous read will therefore commence at offset $4096$ and read $4096$ bytes. Upon completion, it will advance the file offset by $4096$. The new kernel offset will be $o = 4096 + 4096 = 8192$. The `FILE*` stream is unaware of this change. When its buffer is eventually exhausted (after serving the buffered $b[2048..4095]$), it will issue a `read` system call, expecting to get data starting from offset $4096$. Instead, the `read` will start at the current offset $o=8192$, causing it to read $b[8192..]$ and effectively skip the bytes $b[4096..8191]$. This is a desynchronization that leads to data skipping.\n\n*Verdict*: **Correct**.\n\n**Option B: The program submits a $POSIX$ Asynchronous Input/Output $aio\\_read$ on $fd$ with $aiocb \\rightarrow aio\\_offset = 4096$ to read $4096$ bytes into an unrelated memory buffer. The asynchronous read completes before the next call to $fread$.**\n\nThe problem states that $POSIX$ $AIO$ operations like $aio\\_read$ use an explicit offset (here, $4096$) and **do not change** the shared file offset $o$. This type of I/O is analogous to `pread`. The operation will read the bytes $b[4096..8191]$, but the kernel file offset $o$ will remain unchanged at $4096$. When the `FILE*` stream later issues its buffer-refilling `read`, it will correctly start at $o=4096$. No desynchronization of the file offset occurs.\n\n*Verdict*: **Incorrect**.\n\n**Option C: The program submits an $io\\_uring$ write with operation $IORING\\_OP\\_WRITE$ on $fd$ using offset $-1$ to write $4096$ bytes at the current file position $o$. The data being written overlaps the region that $fread$ would read next. The asynchronous write completes before the next call to $fread$.**\n\nSimilar to a read, an $io\\_uring$ write with `offset = -1` uses and advances the shared file position $o$. Before this operation, $o = 4096$. The `io_uring` write will begin at offset $4096$ and advance the offset to $o = 4096 + 4096 = 8192$. This causes the same file offset desynchronization as in option A, leading to data skipping in a future `fread`. Additionally, this operation modifies the file content in the range $[4096, 8191]$, which means the data eventually read by a future `fread` would not be from the original sequence $b$, another form of desynchronization. The primary cause of failure in the sense of skipping bytes is the modification of $o$.\n\n*Verdict*: **Correct**.\n\n**Option D: The program first duplicates the descriptor with $fd2 = dup(fd)$, then submits an $io\\_uring$ read $IORING\\_OP\\_READ$ on $fd2$ using offset $-1$ to read $4096$ bytes. The asynchronous read completes before the next call to $fread$.**\n\nThe definition of $dup$ states that the new file descriptor ($fd2$) refers to the **same open file description** as the original ($fd$). This means they share all file status flags and, critically, the current file offset $o$. Therefore, performing an operation on $fd2$ that modifies $o$ is indistinguishable from performing it on $fd$. This scenario is functionally identical to option A. The `io_uring` read on $fd2$ will start at $o = 4096$ and advance it to $o = 8192$. This causes desynchronization and will lead to a future `fread` skipping data.\n\n*Verdict*: **Correct**.\n\n**Option E: The program opens the same pathname a second time, obtaining a new, independent file descriptor $fd3$ (not via $dup$), and submits a $pread$ equivalent asynchronous read of $4096$ bytes at offset $4096$ on $fd3$. The asynchronous read completes before the next call to $fread$.**\n\nOpening a file path again with `open()` creates a **new and independent** open file description. This new description has its own file offset, which is completely separate from the offset $o$ associated with $fd$. Let's call the offset for $fd3$ as $o_3$. Operations on $fd3$ will use and modify $o_3$, but will have no effect on $o$. Furthermore, the operation specified is a \"$pread$ equivalent\", which uses an explicit offset ($4096$) and would not modify its own file offset ($o_3$) anyway. The kernel file offset $o$ associated with $fd$ remains $4096$, and no desynchronization occurs.\n\n*Verdict*: **Incorrect**.",
            "answer": "$$\\boxed{ACD}$$"
        },
        {
            "introduction": "A key challenge in systems that handle many concurrent operations is ensuring fairness, preventing any single task from being indefinitely ignored or \"starved\" of resources. This practice moves from abstract theory to concrete implementation, tasking you with building a deterministic model of a weighted, fair I/O scheduler. By coding this stress-testing tool, you will gain hands-on experience in modeling complex system behavior and develop a robust method for detecting and measuring I/O starvation in asynchronous systems .",
            "id": "3621582",
            "problem": "You are asked to design and implement a deterministic asynchronous Input/Output (I/O) stressor that detects starvation by comparing observed per-file-descriptor completion rates to a fairness target, all within a simplified, universal model of asynchronous I/O at the operating system level.\n\nThe fundamental base is the core definitions of asynchronous I/O and fairness: asynchronous I/O interfaces decouple submission and completion, and a fair scheduler should not starve any file descriptor. In a discrete-time abstraction, assume there are $M$ file descriptors (indexed $0$ to $M-1$), the system runs for $T$ discrete time steps, and the system can complete up to $K$ I/O operations per time step. Let $c_i$ denote the total number of completions attributed to file descriptor $i$ over $T$ time steps. The measured per-file-descriptor completion rate is $r_i = \\dfrac{c_i}{T}$, and the fairness target under equal sharing is $r^{*} = \\dfrac{K}{M}$. Given a tolerance factor $\\alpha \\in [0,1]$, define file descriptor $i$ to be starved if $r_i < \\alpha \\, r^{*}$.\n\nTo make the stressor deterministic and universally applicable, define the following completion assignment model that captures scheduler bias via nonnegative integer weights $w_i$:\n\n- Let the total number of completion selections be $S = K \\, T$. If $S = 0$, then $r^{*} = 0$ and starvation detection should return an empty set of indices because no completions occurred.\n- Otherwise, construct a sequence of $S$ completion selections using a smooth weighted round-robin procedure consistent with long-run proportional fairness: initialize accumulators $a_i = 0$ for all $i \\in \\{0,\\dots,M-1\\}$ and let $W = \\sum_{i=0}^{M-1} w_i$. For each selection step $s \\in \\{1,\\dots,S\\}$:\n  1. Update $a_i \\leftarrow a_i + w_i$ for all $i$.\n  2. If $W = 0$, no selection is possible; terminate the completion selection sequence early.\n  3. Choose $j = \\arg\\max_{i} a_i$, breaking ties by the smallest index.\n  4. Attribute this completion to file descriptor $j$, i.e., increment $c_j \\leftarrow c_j + 1$.\n  5. Update $a_j \\leftarrow a_j - W$.\nThis deterministic selection yields allocations close to the ideal proportional rule $c_i \\approx S \\cdot \\dfrac{w_i}{W}$ when $W > 0$, and exactly equal allocations when all weights are equal.\n\nYour program must:\n- Implement the above deterministic stressor and compute $r_i = \\dfrac{c_i}{T}$ and $r^{*} = \\dfrac{K}{M}$.\n- Detect starvation according to the rule $r_i < \\alpha \\, r^{*}$, with the special case that if $r^{*} = 0$ then the set of starved indices must be empty.\n- Produce a single-line output aggregating results for all provided test cases, in the exact format described below.\n\nInput is implicit: the program must hard-code the following test suite of parameters. Each test case is defined by $(M, T, K, \\alpha, \\{w_i\\})$:\n1. Happy path (equal weights, sufficient capacity): $M=4$, $T=120$, $K=2$, $\\alpha=0.9$, weights $\\{w_i\\} = \\{1,1,1,1\\}$.\n2. Single descriptor with zero weight (clear starvation): $M=4$, $T=100$, $K=2$, $\\alpha=0.5$, weights $\\{w_i\\} = \\{0,1,1,1\\}$.\n3. Boundary near threshold with discrete effects: $M=4$, $T=7$, $K=1$, $\\alpha=0.6$, weights $\\{w_i\\} = \\{1,1,1,1\\}$.\n4. Zero throughput boundary: $M=3$, $T=50$, $K=0$, $\\alpha=0.9$, weights $\\{w_i\\} = \\{1,1,1\\}$.\n5. Heavily skewed weights (multiple starvation): $M=3$, $T=60$, $K=3$, $\\alpha=0.9$, weights $\\{w_i\\} = \\{5,1,1\\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and is itself a list of zero or more integers indicating the indices of starved file descriptors in ascending order. For example, the output format must look like \"[[i_{1,1},i_{1,2}],[],[i_{3,1}],...]\" with no spaces and exactly one newline at the end.",
            "solution": "We start from the core definitions of asynchronous Input/Output (I/O) and fairness. In asynchronous I/O, a submission returns immediately and completions are delivered later by the operating system. For $M$ file descriptors over $T$ discrete time steps, with capacity $K$ completions per step, the total number of completion selections is $S = K T$. Let $c_i$ be the total completions attributed to descriptor $i$. The measured completion rate is $r_i = \\dfrac{c_i}{T}$, and under equal sharing the fairness target is $r^{*} = \\dfrac{K}{M}$.\n\nStarvation is defined operationally: descriptor $i$ is starved if $r_i < \\alpha \\, r^{*}$ for a chosen tolerance factor $\\alpha \\in [0,1]$. If $r^{*} = 0$ (which occurs when $K = 0$), there is no throughput to distribute; detecting starvation is not meaningful, and we return the empty set.\n\nTo generate a deterministic stressor that is faithful to proportional fairness principles without requiring actual operating system calls, we simulate a scheduler using a smooth weighted round-robin rule. The rule maintains accumulators $a_i$ and a total weight $W = \\sum_{i=0}^{M-1} w_i$:\n\n- Initialize $a_i = 0$ for all $i$.\n- For each of the $S$ completions:\n  - Update $a_i \\leftarrow a_i + w_i$.\n  - If $W = 0$, terminate the selection because no progress can be made (all weights are zero).\n  - Select $j = \\arg\\max_i a_i$ with ties broken by the smallest index.\n  - Attribute the completion to $j$: $c_j \\leftarrow c_j + 1$.\n  - Update $a_j \\leftarrow a_j - W$.\n\nThis mechanism is consistent with the well-tested design of smooth weighted round robin: it produces allocations close to $c_i \\approx S \\cdot \\dfrac{w_i}{W}$ when $W > 0$, and exactly equal allocations when all $w_i$ are equal. Consequently, it is suitable for stress-testing fairness and identifying starvation.\n\nOnce the completion counts $c_i$ are determined, we compute $r_i = \\dfrac{c_i}{T}$ and $r^{*} = \\dfrac{K}{M}$. The starvation flag for each $i$ is then\n$$\ns_i = \n\\begin{cases}\n0, & r^{*} = 0, \\\\\n1, & r_i < \\alpha \\, r^{*}, \\\\\n0, & \\text{otherwise.}\n\\end{cases}\n$$\nWe return the list of indices $i$ for which $s_i = 1$.\n\nApplying this to the test suite:\n\n1. Case $1$: $M=4$, $T=120$, $K=2$, $\\alpha=0.9$, $w=\\{1,1,1,1\\}$. Here $S = 240$, $r^{*} = \\dfrac{2}{4} = 0.5$. Smooth weighted round robin yields $c_i = 60$ for each $i$, so $r_i = \\dfrac{60}{120} = 0.5$. Since $0.5 \\not< 0.9 \\cdot 0.5$, no descriptor is starved. The result is $[]$.\n\n2. Case $2$: $M=4$, $T=100$, $K=2$, $\\alpha=0.5$, $w=\\{0,1,1,1\\}$. Here $S = 200$, $r^{*} = \\dfrac{2}{4} = 0.5$, $W = 3$. Descriptor $0$ has $w_0=0$, hence never receives completions: $c_0 = 0$, giving $r_0 = 0 < 0.5 \\cdot 0.5 = 0.25$, so descriptor $0$ is starved. The other descriptors split $S$ approximately equally: $c_1 \\approx 67$, $c_2 \\approx 67$, $c_3 \\approx 66$, yielding $r_1 \\approx 0.67$, $r_2 \\approx 0.67$, $r_3 \\approx 0.66$, none of which are below $0.25$. The result is $[0]$.\n\n3. Case $3$: $M=4$, $T=7$, $K=1$, $\\alpha=0.6$, $w=\\{1,1,1,1\\}$. Here $S = 7$, $r^{*} = \\dfrac{1}{4} = 0.25$. Discrete effects lead to $c = \\{2,2,2,1\\}$ by smooth cycling, so $r = \\{\\dfrac{2}{7}, \\dfrac{2}{7}, \\dfrac{2}{7}, \\dfrac{1}{7}\\} \\approx \\{0.2857, 0.2857, 0.2857, 0.1429\\}$. The threshold is $\\alpha \\, r^{*} = 0.6 \\cdot 0.25 = 0.15$. Only the descriptor with $r_i \\approx 0.1429$ is below $0.15$, which is index $3$. The result is $[3]$.\n\n4. Case $4$: $M=3$, $T=50$, $K=0$, $\\alpha=0.9$, $w=\\{1,1,1\\}$. Here $S = 0$, $r^{*} = \\dfrac{0}{3} = 0$, and by definition we return the empty set because no completions occur. The result is $[]$.\n\n5. Case $5$: $M=3$, $T=60$, $K=3$, $\\alpha=0.9$, $w=\\{5,1,1\\}$. Here $S = 180$, $r^{*} = \\dfrac{3}{3} = 1$, $W = 7$. The proportional allocation is close to $c \\approx \\{180 \\cdot \\dfrac{5}{7}, 180 \\cdot \\dfrac{1}{7}, 180 \\cdot \\dfrac{1}{7}\\} \\approx \\{128.57, 25.71, 25.71\\}$. A deterministic smooth weighted round robin will yield integer counts that sum to $180$ and are close to these values, such as $\\{129, 26, 25\\}$ or $\\{128, 26, 26\\}$. In all cases, $r_0 \\gtrsim \\dfrac{128}{60} \\approx 2.1333$ is not starved, while $r_1 \\lesssim \\dfrac{26}{60} \\approx 0.4333$ and $r_2 \\lesssim \\dfrac{26}{60} \\approx 0.4333$ are strictly below $\\alpha \\, r^{*} = 0.9$. The result is $[1,2]$.\n\nAggregating the starved index lists for the five cases yields the single-line output:\n$$\n[[],[0],[3],[],[1,2]]\n$$\nwhich your program must print exactly, without spaces, followed by a newline.",
            "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int M;                 // number of file descriptors\n    int T;                 // number of discrete time steps\n    int K;                 // capacity (completions per time step)\n    double alpha;          // starvation tolerance factor in [0,1]\n    const char *weights_csv; // comma-separated weights string of length M\n} TestCase;\n\n// Parse a CSV of integers into an array; returns count parsed.\nstatic int parse_weights(const char *csv, int maxM, int *w_out) {\n    int count = 0;\n    const char *p = csv;\n    while (*p && count < maxM) {\n        // Skip leading spaces (though we expect none)\n        while (*p == ' ') p++;\n        char buf[32];\n        int bi = 0;\n        // Read until comma or end\n        while (*p && *p != ',' && bi < (int)(sizeof(buf) - 1)) {\n            buf[bi++] = *p++;\n        }\n        buf[bi] = '\\0';\n        // Convert to int\n        if (bi > 0) {\n            w_out[count++] = atoi(buf);\n        }\n        if (*p == ',') p++; // skip comma\n    }\n    return count;\n}\n\n// Smooth Weighted Round Robin to produce completion counts.\n// If total weight W is 0 or S is 0, counts remain zero.\nstatic void swrr_counts(int M, int S, const int *w, long long *counts) {\n    // Initialize counts and accumulators\n    long long W = 0;\n    for (int i = 0; i < M; ++i) {\n        counts[i] = 0;\n        W += (long long)w[i];\n    }\n    if (S <= 0 || W == 0) {\n        // No selections possible or no capacity or no weights\n        return;\n    }\n    long long *acc = (long long *)calloc((size_t)M, sizeof(long long));\n    if (!acc) {\n        // Fallback: no memory, do nothing\n        return;\n    }\n    for (int s = 0; s < S; ++s) {\n        // Update accumulators\n        for (int i = 0; i < M; ++i) {\n            acc[i] += (long long)w[i];\n        }\n        // Choose index with maximum accumulator, tie-break by smallest index\n        int pick = 0;\n        long long best = acc[0];\n        for (int i = 1; i < M; ++i) {\n            if (acc[i] > best) {\n                best = acc[i];\n                pick = i;\n            }\n        }\n        // Attribute completion and adjust accumulator\n        counts[pick] += 1;\n        acc[pick] -= W;\n    }\n    free(acc);\n}\n\n// Detect starved indices according to r_i < alpha * r_star.\n// If r_star == 0, return empty set (no starvation detection).\nstatic int detect_starvation(int M, int T, int K, double alpha,\n                             const long long *counts, int *starved_idx) {\n    double r_star = (M > 0) ? ((double)K / (double)M) : 0.0;\n    if (r_star == 0.0) {\n        return 0; // special-case: no throughput => empty set\n    }\n    int n = 0;\n    for (int i = 0; i < M; ++i) {\n        double r_i = (T > 0) ? ((double)counts[i] / (double)T) : 0.0;\n        if (r_i < alpha * r_star) {\n            starved_idx[n++] = i;\n        }\n    }\n    return n;\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        // 1. Happy path (equal weights, sufficient capacity)\n        { 4, 120, 2, 0.9, \"1,1,1,1\" },\n        // 2. Single descriptor with zero weight (clear starvation)\n        { 4, 100, 2, 0.5, \"0,1,1,1\" },\n        // 3. Boundary near threshold with discrete effects\n        { 4, 7, 1, 0.6, \"1,1,1,1\" },\n        // 4. Zero throughput boundary\n        { 3, 50, 0, 0.9, \"1,1,1\" },\n        // 5. Heavily skewed weights (multiple starvation)\n        { 3, 60, 3, 0.9, \"5,1,1\" }\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = (int)(sizeof(test_cases) / sizeof(test_cases[0]));\n\n    // Prepare output printing\n    printf(\"[\");\n\n    for (int tc = 0; tc < num_cases; ++tc) {\n        TestCase t = test_cases[tc];\n\n        // Parse weights\n        int M = t.M;\n        int weights[128];\n        for (int i = 0; i < 128; ++i) weights[i] = 0;\n        int parsed = parse_weights(t.weights_csv, M, weights);\n        // If fewer than M weights parsed, remaining are zeros (already set).\n        (void)parsed; // we rely on M; ignoring mismatch for deterministic behavior\n\n        // Compute total selections S = K * T\n        long long S = (long long)t.K * (long long)t.T;\n        long long counts[128];\n        for (int i = 0; i < M; ++i) counts[i] = 0;\n\n        // Produce counts using smooth weighted round robin\n        swrr_counts(M, (int)S, weights, counts);\n\n        // Detect starvation\n        int starved_idx[128];\n        int starved_n = detect_starvation(M, t.T, t.K, t.alpha, counts, starved_idx);\n\n        // Print the list for this test case\n        printf(\"[\");\n        for (int i = 0; i < starved_n; ++i) {\n            printf(\"%d\", starved_idx[i]);\n            if (i + 1 < starved_n) printf(\",\");\n        }\n        printf(\"]\");\n        if (tc + 1 < num_cases) printf(\",\");\n    }\n\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```"
        }
    ]
}