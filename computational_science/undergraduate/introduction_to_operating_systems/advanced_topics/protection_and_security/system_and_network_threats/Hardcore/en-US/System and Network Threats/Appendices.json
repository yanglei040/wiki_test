{
    "hands_on_practices": [
        {
            "introduction": "Before an attacker can exploit a vulnerability, they must first discover it. Network port scanning is a fundamental reconnaissance technique used to identify running services on a target system. This exercise challenges you to model the total time required for a port scan, considering how different system and firewall responses—such as an open port, a closed port, or a silently dropped packet—affect the attacker's efficiency. By building a quantitative model from first principles, you can better understand how security measures like `DROP` firewall policies increase the cost and effort for an adversary .",
            "id": "3685793",
            "problem": "A single-host system runs Remote Procedure Call (RPC) services with the portmapper implemented by the `rpcbind` program. The host’s firewall is configured with default-deny inbound rules that silently drop unsolicited packets unless they target a small whitelist of service ports. Additionally, rpcbind is configured to bind only to the loopback interface, so that TCP port $111$ (the standard RPC portmapper) is unreachable from external networks. An external adversary performs a Transmission Control Protocol (TCP) port scan sequentially over a set of $m$ distinct ports. Let $k$ be the number of externally reachable, whitelisted open service ports, and let $r$ be the number of ports that are filtered (either by the firewall’s drop policy or because rpcbind listens only on loopback). The remaining $m - k - r$ ports are closed but unfiltered (responding with a reset rather than being silently dropped).\n\nAssume the following timing model for a single probe:\n- For an open port (including any non-RPC whitelisted services), the time to complete the initial handshake is a random variable that follows an exponential distribution with rate parameter $\\lambda_{o}$.\n- For a closed but unfiltered port, the time to receive a reset is a random variable that follows an exponential distribution with rate parameter $\\lambda_{c}$.\n- For a filtered port, the scanner observes a fixed timeout of $\\tau_{f}$ seconds due to silent drop behavior.\n\nAll probes are performed sequentially, and network conditions for different probes are independent. Starting from first principles about sequential composition of times and expectations of independent random variables, derive a closed-form analytic expression for the expected total scan time $t$ over the $m$ ports as a function of $m$, $k$, $r$, $\\lambda_{o}$, $\\lambda_{c}$, and $\\tau_{f}$. Express your final answer in seconds. No numerical evaluation is required; provide the exact expression.",
            "solution": "The problem asks for the expected total scan time for $m$ ports. We can calculate this using the principle of linearity of expectation. The total expected time is the sum of the expected times for each individual port probe.\n\nLet $T_{total}$ be the random variable for the total scan time. It is the sum of the times for each of the $m$ probes:\n$$T_{total} = \\sum_{i=1}^{m} T_i$$\nwhere $T_i$ is the time for the $i$-th probe.\n\nBy the linearity of expectation, the expected total time $t = E[T_{total}]$ is:\n$$t = E\\left[\\sum_{i=1}^{m} T_i\\right] = \\sum_{i=1}^{m} E[T_i]$$\n\nThe set of $m$ ports is partitioned into three disjoint categories based on their response type:\n1.  **Open ports**: There are $k$ such ports. The time to scan follows an exponential distribution with rate $\\lambda_o$. The expected time for a single probe is $E[T_{open}] = 1/\\lambda_o$.\n2.  **Closed, unfiltered ports**: There are $m - k - r$ such ports. The time to scan follows an exponential distribution with rate $\\lambda_c$. The expected time for a single probe is $E[T_{closed}] = 1/\\lambda_c$.\n3.  **Filtered ports**: There are $r$ such ports. The time to scan is a fixed timeout $\\tau_f$. The expected time for a single probe is $E[T_{filtered}] = \\tau_f$.\n\nWe can group the sum of expectations by these three categories:\n$$t = k \\cdot E[T_{open}] + (m - k - r) \\cdot E[T_{closed}] + r \\cdot E[T_{filtered}]$$\n\nSubstituting the expected time for each category:\n$$t = k \\cdot \\left(\\frac{1}{\\lambda_o}\\right) + (m - k - r) \\cdot \\left(\\frac{1}{\\lambda_c}\\right) + r \\cdot (\\tau_f)$$\n\nThis gives the final closed-form expression for the expected total scan time:\n$$t = \\frac{k}{\\lambda_{o}} + \\frac{m - k - r}{\\lambda_{c}} + r \\tau_{f}$$",
            "answer": "$$\n\\boxed{\\frac{k}{\\lambda_{o}} + \\frac{m - k - r}{\\lambda_{c}} + r \\tau_{f}}\n$$"
        },
        {
            "introduction": "Modern operating systems deploy a variety of defenses to make exploiting memory corruption vulnerabilities more difficult, and Address Space Layout Randomization (ASLR) is a primary example. Rather than eliminating bugs, ASLR makes their exploitation probabilistic. This practice asks you to quantify the exact strength of ASLR by calculating its 'entropy' in bits for both 32-bit and 64-bit systems, providing a concrete measure of its effectiveness. You will then use this to calculate the success probability of a brute-force attack, gaining a deeper appreciation for how architectural choices impact system security .",
            "id": "3685862",
            "problem": "A contemporary operating system uses Address Space Layout Randomization (ASLR) to randomize the base address of a Position-Independent Executable (PIE) at each program start. Consider two architectures: a $32$-bit system and a $64$-bit system. In both systems, the loader chooses the PIE base uniformly at random from a contiguous virtual address window, constrained to page alignment. Specifically, on the $32$-bit system the window width is $256$ MiB and on the $64$-bit system the window width is $128$ GiB. The page size is $4$ KiB. Assume the window endpoints are chosen so that the count of page-aligned base positions is an integer in both cases, and that every page-aligned position within the window is equally likely.\n\nDefine the runtime ASLR “entropy” for the PIE base, $E$, as the base-$2$ logarithm of the number of equiprobable base positions actually achievable at runtime. Starting only from the fundamental facts that a uniform discrete choice over $N$ outcomes has probability $1/N$ for each outcome, that the number of page-aligned positions in a window of width $W$ with alignment $a$ equals the count of alignment quanta that fit in the window, and that $\\log_{2}$ measures entropy in bits for $N$ equiprobable states, do the following:\n\n- Determine symbolically how $E$ depends on the window width $W$ and alignment $a$.\n- Compute the achieved runtime entropy values $E_{32}$ and $E_{64}$ for the $32$-bit and $64$-bit systems given the parameters above.\n- Now consider a remote memory-corruption attack that succeeds only if the attacker’s single guess of the PIE base on each connection exactly matches the actual base. Each failed guess crashes the process, which is immediately restarted, and a fresh connection yields an independent ASLR draw from the same distribution. Using only the axioms of independent Bernoulli trials and the complement rule, derive the success probability after $m$ independent attempts as a function of $m$ and the number of base positions $N$. Then, using the $64$-bit parameters above, evaluate this probability numerically for $m = 10^{6}$ attempts. Express this success probability as a decimal rounded to four significant figures.\n\nReport your final answer as a row matrix $\\begin{pmatrix} E_{32} & E_{64} & p_{64}(m) \\end{pmatrix}$, where $p_{64}(m)$ denotes the requested $64$-bit success probability for $m = 10^{6}$.",
            "solution": "The problem is validated as scientifically sound, well-posed, complete, and relevant. The solution proceeds in three parts as requested.\n\nFirst, we determine the symbolic relationship between the ASLR entropy $E$, the randomization window width $W$, and the alignment size $a$.\nThe number of possible choices for the base address, $N$, is given by the number of non-overlapping alignment blocks that fit within the total randomization window. The problem states this as \"the count of alignment quanta that fit in the window\". This is calculated by dividing the window width $W$ by the alignment size $a$.\n$$N = \\frac{W}{a}$$\nThe problem defines the ASLR \"entropy\" $E$ as the base-$2$ logarithm of the number of equiprobable base positions, which is the standard definition for Shannon entropy in bits for a uniform distribution over $N$ states.\n$$E = \\log_{2}(N)$$\nSubstituting the expression for $N$ into the definition of $E$, we obtain the symbolic dependence of the entropy on $W$ and $a$.\n$$E = \\log_{2}\\left(\\frac{W}{a}\\right)$$\n\nSecond, we compute the achieved runtime entropy values $E_{32}$ and $E_{64}$ for the given system parameters. To do this, we must first express the window widths and the page size in a consistent unit, such as bytes. We use the standard binary prefixes: $1 \\text{ KiB} = 2^{10}$ bytes, $1 \\text{ MiB} = 2^{20}$ bytes, and $1 \\text{ GiB} = 2^{30}$ bytes.\n\nThe page size, which dictates the alignment $a$, is given as $4$ KiB.\n$$a = 4 \\text{ KiB} = 4 \\times 2^{10} \\text{ bytes} = 2^2 \\times 2^{10} \\text{ bytes} = 2^{12} \\text{ bytes}$$\n\nFor the $32$-bit system, the window width $W_{32}$ is $256$ MiB.\n$$W_{32} = 256 \\text{ MiB} = 256 \\times 2^{20} \\text{ bytes} = 2^8 \\times 2^{20} \\text{ bytes} = 2^{28} \\text{ bytes}$$\nThe number of possible base positions, $N_{32}$, is:\n$$N_{32} = \\frac{W_{32}}{a} = \\frac{2^{28} \\text{ bytes}}{2^{12} \\text{ bytes}} = 2^{28-12} = 2^{16}$$\nThe entropy for the $32$-bit system, $E_{32}$, is therefore:\n$$E_{32} = \\log_{2}(N_{32}) = \\log_{2}(2^{16}) = 16$$\n\nFor the $64$-bit system, the window width $W_{64}$ is $128$ GiB.\n$$W_{64} = 128 \\text{ GiB} = 128 \\times 2^{30} \\text{ bytes} = 2^7 \\times 2^{30} \\text{ bytes} = 2^{37} \\text{ bytes}$$\nThe number of possible base positions, $N_{64}$, is:\n$$N_{64} = \\frac{W_{64}}{a} = \\frac{2^{37} \\text{ bytes}}{2^{12} \\text{ bytes}} = 2^{37-12} = 2^{25}$$\nThe entropy for the $64$-bit system, $E_{64}$, is:\n$$E_{64} = \\log_{2}(N_{64}) = \\log_{2}(2^{25}) = 25$$\n\nThird, we derive the success probability of a remote memory-corruption attack after $m$ independent attempts. The attack model assumes an attacker makes a single guess per attempt, and a failed attempt results in a process restart with a new, independent random base address. This setup corresponds to a sequence of independent Bernoulli trials.\nLet $N$ be the total number of possible base addresses. As the choice is uniform, the probability of success on any single attempt is:\n$$p_{success} = \\frac{1}{N}$$\nThe probability of failure on a single attempt is the complement:\n$$p_{fail} = 1 - p_{success} = 1 - \\frac{1}{N}$$\nSince each of the $m$ attempts is independent, the probability of failing on all $m$ attempts is the product of their individual probabilities:\n$$P(\\text{fail on all } m \\text{ attempts}) = (p_{fail})^m = \\left(1 - \\frac{1}{N}\\right)^m$$\nThe event of \"success after $m$ attempts\" means succeeding at least once. This is the complement of the event \"failing on all $m$ attempts\". Using the complement rule, the probability of at least one success in $m$ attempts, denoted $p(m)$, is:\n$$p(m) = 1 - P(\\text{fail on all } m \\text{ attempts}) = 1 - \\left(1 - \\frac{1}{N}\\right)^m$$\nNow, we evaluate this probability for the $64$-bit system with $m = 10^6$ attempts. For this system, we found $N = N_{64} = 2^{25}$.\n$$p_{64}(m) = 1 - \\left(1 - \\frac{1}{2^{25}}\\right)^{10^6}$$\nWe calculate the numerical value:\n$$N_{64} = 2^{25} = 33,554,432$$\n$$p_{64}(10^6) = 1 - \\left(1 - \\frac{1}{33,554,432}\\right)^{1,000,000}$$\nEvaluating this expression yields:\n$$p_{64}(10^6) \\approx 1 - (0.9999999701976776)^{1000000} \\approx 1 - 0.970636936 \\approx 0.029363064$$\nRounding this result to four significant figures gives:\n$$p_{64}(10^6) \\approx 0.02936$$\n\nThe final results are $E_{32}=16$, $E_{64}=25$, and $p_{64}(10^6) \\approx 0.02936$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 16 & 25 & 0.02936 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Security vulnerabilities don't always stem from simple programming errors; they can also emerge from the fundamental design of core system components like the filesystem. This exercise puts you in the mindset of both an attacker and a system designer, exploring how the interaction between filesystem journaling modes, device caches, and application behavior can create subtle race conditions. Your task is to analyze various configurations to determine which ones can guarantee that an attacker, by inducing a crash at a critical moment, cannot cause the system to expose sensitive data with incorrect permissions .",
            "id": "3685788",
            "problem": "A storage server uses a journaling file system that supports three journaling modes: metadata-only with writeback, metadata-only with ordered data writes, and full data journaling. The device beneath the file system has a volatile write-back cache. When enabled, write barriers (cache flush or Force Unit Access) force persistence and ordering across the device cache. The journal is a write-ahead log: metadata updates are grouped into a transaction $T_k$ whose commit record is written last; after a crash, only fully committed transactions are replayed. Application data blocks are not part of the journal in metadata-only modes and may be written to the main area at any time by background Input/Output (I/O), subject to each mode’s ordering rules. A file synchronization system call (fsync) requests the file system to force the calling file’s dirty data and metadata to stable storage before returning, according to the file system’s guarantees. Access Control List (ACL) changes are metadata associated with the inode.\n\nConsider a single file $f$ initially world-readable by a group $G$. A user intends to make $f$ confidential and to overwrite its contents with a secret string. The user performs the following high-level steps without crashes in between: first, write new contents to existing allocated blocks of $f$; then, set a restrictive ACL so that only the owner can read $f$. An attacker can cut power at any chosen time $t$ during the actual write-out to storage. Assume no application-level rename or temporary-file swap is used unless stated, and assume no explicit fsync is invoked unless stated. The attacker’s goal is to cause, after reboot, a state in which the new contents are visible while the old, permissive ACL remains in effect.\n\nFrom first principles of journaling and storage ordering, select all configurations below that guarantee that, for any adversarially chosen crash time $t$, the system will not reboot into a state where the new contents of $f$ are visible while the restrictive ACL is not yet durable.\n\nA. Full data journaling mode with write barriers enabled; the application performs both the data write and the ACL change and then calls fsync on $f$ once.\n\nB. Metadata-only journaling in ordered mode with write barriers enabled; the application does not call fsync.\n\nC. Metadata-only journaling in writeback mode with write barriers disabled.\n\nD. Full data journaling mode with write barriers disabled on a device with a volatile write-back cache; the application calls fsync on $f$ once after both updates.\n\nE. Metadata-only journaling in ordered mode with write barriers enabled; the application calls fsync on $f$ immediately after the data write, then performs the ACL change without a subsequent fsync.\n\nF. Metadata-only journaling in ordered mode with write barriers enabled; the application first changes the ACL, calls fsync on $f$, then writes the new contents and calls fsync on $f$ again.",
            "solution": "The problem statement is analyzed for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- **System**: A storage server with a journaling file system.\n- **Journaling Modes**:\n    1. Metadata-only with writeback.\n    2. Metadata-only with ordered data writes.\n    3. Full data journaling.\n- **Device**: Contains a volatile write-back cache.\n- **Write Barriers**: When enabled, force persistence and ordering (e.g., cache flush, Force Unit Access).\n- **Journal**: A write-ahead log (WAL). Metadata updates are grouped in a transaction `$T_k$`. A commit record is written last. Only fully committed transactions are replayed after a crash.\n- **Metadata-only Modes**: Data blocks are not in the journal and are written to the main area by background I/O, subject to each mode's ordering rules.\n- **ACLs**: Access Control Lists are metadata.\n- **`fsync`**: A system call to force a file's dirty data and metadata to stable storage.\n- **Initial State**: A file `$f$` is world-readable by group `$G$`.\n- **User Action Sequence**:\n    1. Write new secret contents to existing blocks of `$f$`.\n    2. Set a restrictive ACL on `$f$`.\n- **Attacker Goal**: To cause a post-reboot state where the new contents of `$f$` are visible while the old, permissive ACL remains.\n- **Assumptions**: No application-level atomic replacement (e.g., `rename`), and no `fsync` unless explicitly stated.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientific Grounding**: The problem is built on core, standard concepts from operating systems and computer architecture, including journaling file systems (write-ahead logging, different journaling modes), storage device caching (volatile write-back caches), and data consistency primitives (write barriers, `fsync`). These concepts are factual and well-established in the field of computer science.\n- **Well-Posedness**: The initial state, user actions, and the attacker's desired outcome (the \"vulnerable state\") are all defined with precision. The question asks for configurations that *guarantee* the prevention of this state for *any* adversarial crash time `$t$`. This sets a clear, unambiguous criterion for evaluating each option. A unique answer set can be derived through logical deduction based on the provided principles.\n- **Objectivity**: The language is technical and free of subjectivity or ambiguity. Terms like \"volatile write-back cache\", \"metadata-only with ordered data writes\", and \"Force Unit Access\" have precise technical meanings.\n\nThe problem does not violate any of the invalidity criteria. It is a valid, solvable problem based on first principles of system design.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\n### Principle-Based Derivation\nLet `$D_{new}$` represent the new, secret data content, and `$M_{new}$` represent the new, restrictive ACL metadata. The user performs the operations corresponding to `$D_{new}$` first, then `$M_{new}$`.\nLet `$W(X)$` denote the event that item `$X$` has been durably written to stable storage, meaning it will survive a power failure.\nThe attacker's goal is to achieve the vulnerable state: `$W(D_{new}) \\land \\neg W(M_{new})$`.\nA configuration is \"safe\" if it guarantees that this state is impossible for any crash time `$t$`. This requires ensuring that for any execution, the condition `$W(D_{new}) \\implies W(M_{new})$` holds true. This implication can be satisfied by one of two general mechanisms:\n1.  **Atomicity**: `$D_{new}$` and `$M_{new}$` are written as part of a single atomic transaction. The outcome of recovery is either `$W(D_{new}) \\land W(M_{new})$` or `$\\neg W(D_{new}) \\land \\neg W(M_{new})$`. The mixed state is impossible.\n2.  **Ordering**: The system enforces an ordering such that `$W(M_{new})$` must occur before `$W(D_{new})$`. If this order is guaranteed, then a state where `$W(D_{new})$` is true necessarily implies that `$W(M_{new})$` is also true.\n\nWe now analyze each option against these principles.\n\n### Option-by-Option Analysis\n\n**A. Full data journaling mode with write barriers enabled; the application performs both the data write and the ACL change and then calls fsync on $f$ once.**\n\nIn full data journaling, both file data (`$D_{new}$`) and metadata (`$M_{new}$`) are written to the journal as part of the same transaction, `$T_k$`. The file system ensures that the log entries for `$D_{new}$` and `$M_{new}$` are written, followed by a commit record for `$T_k$`. The enabling of write barriers is crucial: it guarantees that these writes occur on the stable storage medium in the correct order, preventing the commit record from being persisted before the transaction's content. Because `$D_{new}$` and `$M_{new}$` are part of the same atomic transaction, crash recovery will either replay the entire transaction (applying both changes) or discard it (applying neither). It is impossible for recovery to result in a state where the data change is applied but the metadata change is not. This provides the atomicity guarantee discussed above. The `$fsync$` call forces this transaction to be committed, but the safety guarantee derives from the fundamental atomicity of the full data journaling mode itself.\n\n**Verdict:** Correct.\n\n**B. Metadata-only journaling in ordered mode with write barriers enabled; the application does not call fsync.**\n\nIn ordered mode, the file system enforces a specific dependency: data blocks (`$D_{new}$`) must be written to their final location on stable storage *before* the metadata transaction (`$T_k$`, containing `$M_{new}$`) that references them is committed to the journal. The operations are: ($1$) background I/O writes `$D_{new}$` to disk, making `$W(D_{new})$` true; ($2$) the file system commits `$T_k$`, making `$W(M_{new})$` true. There exists a time window after step ($1$) but before step ($2$). If an attacker cuts power during this window, the system reboots into a state where `$W(D_{new})$` is true but, since `$T_k$` was not committed, `$\\neg W(M_{new})$` is true. This is precisely the vulnerable state. The lack of an `$fsync$` call leaves the timing of these operations to the OS, which an attacker can exploit.\n\n**Verdict:** Incorrect.\n\n**C. Metadata-only journaling in writeback mode with write barriers disabled.**\n\nThis is the weakest consistency configuration. In writeback mode, there is no required ordering between data writes and metadata journal commits. The system is free to write `$D_{new}$` to stable storage long before it commits the transaction for `$M_{new}$`. This creates the same vulnerable window as in ordered mode, and it is typically much larger. Furthermore, with write barriers disabled on a device with a volatile cache, the device itself can reorder writes, potentially corrupting the journal structure and leading to undefined file system states, which cannot be considered safe. This configuration does not prevent the vulnerable state.\n\n**Verdict:** Incorrect.\n\n**D. Full data journaling mode with write barriers disabled on a device with a volatile write-back cache; the application calls fsync on $f$ once after both updates.**\n\nWhile full data journaling provides logical atomicity, this guarantee depends on the integrity of the write-ahead log on stable storage. The problem states the device has a volatile write-back cache. Disabling write barriers means the file system cannot command the device to flush its cache or enforce write ordering. The device is therefore free to reorder writes. It could write the transaction's commit block to stable storage before writing the transaction's data (`$D_{new}`) or metadata (`$M_{new}$`) blocks, which may still be in the volatile cache. A power crash at this moment would leave a committed transaction in the journal whose contents are missing. Upon reboot, the recovery process would read garbage from the journal log and replay it, leading to file system corruption. This configuration does not guarantee safety; it actively risks catastrophic data corruption and cannot guarantee the prevention of any specific state.\n\n**Verdict:** Incorrect.\n\n**E. Metadata-only journaling in ordered mode with write barriers enabled; the application calls fsync on $f$ immediately after the data write, then performs the ACL change without a subsequent fsync.**\n\nThe application logic is `$write(f, D_{new})$; `$fsync(f)`; `$set\\_acl(f, M_{new})$`. The `$fsync(f)$` call forces all dirty data for `$f$` (which is `$D_{new}$`) to be written to stable storage. After this `$fsync$` call returns successfully, the condition `$W(D_{new})$` is true. The application then proceeds to change the ACL, but an attacker can trigger a power failure after the `$fsync$` returns but before the new metadata transaction for `$M_{new}$` is committed to the journal. On reboot, the system state will be `$W(D_{new}) \\land \\neg W(M_{new})$`, which is the vulnerable state. This application logic explicitly creates the vulnerability.\n\n**Verdict:** Incorrect.\n\n**F. Metadata-only journaling in ordered mode with write barriers enabled; the application first changes the ACL, calls fsync on $f$, then writes the new contents and calls fsync on $f$ again.**\n\nThis option reverses the application logic to `$set\\_acl(f, M_{new})$; `$fsync(f)`; `$write(f, D_{new})$; `$fsync(f)$`. The first `$fsync(f)$` forces the ACL metadata change (`$M_{new}$`) to stable storage by ensuring its transaction is committed to the journal. After this call returns, `$W(M_{new})$` is guaranteed to be true. Any crash that occurs before this point will not cause the data leak because `$D_{new}$` has not even been written. Any crash that occurs after this point happens when `$W(M_{new})$` is already true. The vulnerable state is `$W(D_{new}) \\land \\neg W(M_{new})$`. This state is impossible to reach because any situation where `$W(D_{new})$` could be true must occur after the first `$fsync$` has completed, at which point `$\\neg W(M_{new})$` is false. This application logic correctly implements the ordering principle for safety.\n\n**Verdict:** Correct.",
            "answer": "$$\\boxed{AF}$$"
        }
    ]
}