{
    "hands_on_practices": [
        {
            "introduction": "This first practice grounds your understanding in the fundamental mechanics of Round-Robin (RR) scheduling. By manually tracing the execution of several processes, you will directly calculate core performance metrics like CPU utilization and average turnaround time. This exercise highlights the tangible cost of context switching and introduces a realistic nuance: how hardware phenomena like CPU cache state can influence scheduler performance .",
            "id": "3630387",
            "problem": "A single-core Central Processing Unit (CPU) runs a batch workload of $3$ compute-bound processes $\\{P_{1},P_{2},P_{3}\\}$ that all arrive at time $t=0$ and do not perform input/output or blocking. The operating system uses Round-Robin (RR) scheduling with a fixed time quantum $q=2\\,\\text{ms}$. A context switch is performed immediately before each time slice to dispatch the next process, and this dispatch overhead is fully serialized (no overlap with useful execution). The context switch cost depends on the cache state as follows: if the next process’s working set is still resident, the switch cost is $c_{\\text{hot}}$, otherwise it is $c_{\\text{cold}}$.\n\nDefine the process CPU burst demands as $b_{1}=7\\,\\text{ms}$, $b_{2}=3\\,\\text{ms}$, and $b_{3}=5\\,\\text{ms}$. At each dispatch, the executing process runs for $\\min\\{q,\\text{remaining burst}\\}$.\n\nConsider two preemption patterns that induce different cache states at dispatch:\n\n- Pattern $\\mathcal{H}$ (hot-retaining RR): the first dispatch at $t=0$ incurs $c_{\\text{cold}}$, and every subsequent dispatch incurs $c_{\\text{hot}}$.\n- Pattern $\\mathcal{C}$ (cold-dominated RR): every dispatch, including the first, incurs $c_{\\text{cold}}$.\n\nUse $c_{\\text{hot}}=0.1\\,\\text{ms}$ and $c_{\\text{cold}}=0.6\\,\\text{ms}$.\n\nFor this experiment, define the effective CPU utilization $U$ as the fraction of the total wall-clock time until all processes complete that is spent executing the processes’ CPU bursts (that is, excluding time spent in dispatch overhead). Define the turnaround time of process $i$ as $C_{i}-A_{i}$, where $A_{i}$ is the arrival time and $C_{i}$ is the completion time; since all arrivals are at $t=0$, the average turnaround time is $\\overline{T}=\\frac{1}{3}\\sum_{i=1}^{3}C_{i}$.\n\nCompute $U_{\\mathcal{H}}$ and $\\overline{T}_{\\mathcal{H}}$ under Pattern $\\mathcal{H}$, and $U_{\\mathcal{C}}$ and $\\overline{T}_{\\mathcal{C}}$ under Pattern $\\mathcal{C}$. Then form the combined improvement factor\n$$\nM \\;=\\; \\frac{U_{\\mathcal{H}}}{U_{\\mathcal{C}}}\\,\\cdot\\,\\frac{\\overline{T}_{\\mathcal{C}}}{\\overline{T}_{\\mathcal{H}}}\\,,\n$$\nwhich is dimensionless. Round your final value of $M$ to four significant figures and report it as a pure number with no units.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. It describes a standard CPU scheduling scenario from operating systems theory with all necessary parameters provided. A unique solution can be derived by simulating the described scheduling model.\n\nThe solution requires a step-by-step simulation of the Round-Robin (RR) scheduling algorithm for the two specified context switch cost patterns, $\\mathcal{C}$ and $\\mathcal{H}$. For each pattern, we will determine the completion time $C_i$ for each process $P_i$, the total wall-clock time, the effective CPU utilization $U$, and the average turnaround time $\\overline{T}$.\n\nThe given parameters are:\n- Number of processes: $3$, namely $\\{P_1, P_2, P_3\\}$.\n- Arrival times: $A_1=A_2=A_3=0\\,\\text{ms}$.\n- CPU burst demands: $b_1=7\\,\\text{ms}$, $b_2=3\\,\\text{ms}$, and $b_3=5\\,\\text{ms}$.\n- Scheduling algorithm: Round-Robin (RR) with a time quantum $q=2\\,\\text{ms}$.\n- Context switch costs: $c_{\\text{hot}}=0.1\\,\\text{ms}$ and $c_{\\text{cold}}=0.6\\,\\text{ms}$.\n- Assumed scheduling order for the ready queue at $t=0$: $P_1 \\to P_2 \\to P_3$.\n\nThe total number of required time slices (and thus context switches) is the sum of the turns for each process:\n$N_{\\text{slices}} = \\lceil \\frac{b_1}{q} \\rceil + \\lceil \\frac{b_2}{q} \\rceil + \\lceil \\frac{b_3}{q} \\rceil = \\lceil \\frac{7}{2} \\rceil + \\lceil \\frac{3}{2} \\rceil + \\lceil \\frac{5}{2} \\rceil = 4 + 2 + 3 = 9$.\nThere will be a total of $9$ context switches.\n\nFirst, we analyze Pattern $\\mathcal{C}$ (cold-dominated RR), where every context switch incurs a cost of $c_{\\text{cold}}=0.6\\,\\text{ms}$.\n\nLet $t$ be the current time in $\\text{ms}$, initialized to $t=0$. Let $b_{i,r}$ be the remaining burst time for process $P_i$.\nInitially, $b_{1,r}=7$, $b_{2,r}=3$, $b_{3,r}=5$.\n1. Dispatch $P_1$: Overhead cost is $c_{\\text{cold}}=0.6$. The time is now $t=0.6$. $P_1$ runs for $q=2$. The time becomes $t=0.6+2=2.6$. Remaining burst for $P_1$ is $b_{1,r}=7-2=5$.\n2. Dispatch $P_2$: Overhead is $c_{\\text{cold}}=0.6$. $t=2.6+0.6=3.2$. $P_2$ runs for $q=2$. $t=3.2+2=5.2$. $b_{2,r}=3-2=1$.\n3. Dispatch $P_3$: Overhead is $c_{\\text{cold}}=0.6$. $t=5.2+0.6=5.8$. $P_3$ runs for $q=2$. $t=5.8+2=7.8$. $b_{3,r}=5-2=3$.\n4. Dispatch $P_1$: Overhead is $c_{\\text{cold}}=0.6$. $t=7.8+0.6=8.4$. $P_1$ runs for $q=2$. $t=8.4+2=10.4$. $b_{1,r}=5-2=3$.\n5. Dispatch $P_2$: Overhead is $c_{\\text{cold}}=0.6$. $t=10.4+0.6=11.0$. $P_2$ runs for its remaining $1\\,\\text{ms}$. $t=11.0+1=12.0$. $b_{2,r}=0$. Process $P_2$ completes, so its completion time is $C_{2, \\mathcal{C}}=12.0\\,\\text{ms}$.\n6. Dispatch $P_3$: Overhead is $c_{\\text{cold}}=0.6$. $t=12.0+0.6=12.6$. $P_3$ runs for $q=2$. $t=12.6+2=14.6$. $b_{3,r}=3-2=1$.\n7. Dispatch $P_1$: Overhead is $c_{\\text{cold}}=0.6$. $t=14.6+0.6=15.2$. $P_1$ runs for $q=2$. $t=15.2+2=17.2$. $b_{1,r}=3-2=1$.\n8. Dispatch $P_3$: Overhead is $c_{\\text{cold}}=0.6$. $t=17.2+0.6=17.8$. $P_3$ runs for its remaining $1\\,\\text{ms}$. $t=17.8+1=18.8$. $b_{3,r}=0$. Process $P_3$ completes, $C_{3, \\mathcal{C}}=18.8\\,\\text{ms}$.\n9. Dispatch $P_1$: Overhead is $c_{\\text{cold}}=0.6$. $t=18.8+0.6=19.4$. $P_1$ runs for its remaining $1\\,\\text{ms}$. $t=19.4+1=20.4$. $b_{1,r}=0$. Process $P_1$ completes, $C_{1, \\mathcal{C}}=20.4\\,\\text{ms}$.\n\nThe total time for Pattern $\\mathcal{C}$ is $T_{\\text{total}, \\mathcal{C}}=20.4\\,\\text{ms}$.\nThe total CPU burst execution time is $B_{\\text{total}} = 7+3+5=15\\,\\text{ms}$.\nThe effective CPU utilization for Pattern $\\mathcal{C}$ is $U_{\\mathcal{C}} = \\frac{B_{\\text{total}}}{T_{\\text{total}, \\mathcal{C}}} = \\frac{15}{20.4}$.\nThe completion times are $C_{1, \\mathcal{C}}=20.4$, $C_{2, \\mathcal{C}}=12.0$, $C_{3, \\mathcal{C}}=18.8$. Since all processes arrive at $A_i=0$, their turnaround times are equal to their completion times.\nThe average turnaround time for Pattern $\\mathcal{C}$ is $\\overline{T}_{\\mathcal{C}} = \\frac{1}{3}(20.4 + 12.0 + 18.8) = \\frac{51.2}{3}\\,\\text{ms}$.\n\nNext, we analyze Pattern $\\mathcal{H}$ (hot-retaining RR), where the first switch costs $c_{\\text{cold}}=0.6\\,\\text{ms}$ and the subsequent $8$ switches cost $c_{\\text{hot}}=0.1\\,\\text{ms}$.\n\n1. Dispatch $P_1$: Overhead is $c_{\\text{cold}}=0.6$. $t=0.6$. $P_1$ runs for $q=2$. $t=2.6$. $b_{1,r}=5$.\n2. Dispatch $P_2$: Overhead is $c_{\\text{hot}}=0.1$. $t=2.6+0.1=2.7$. $P_2$ runs for $q=2$. $t=4.7$. $b_{2,r}=1$.\n3. Dispatch $P_3$: Overhead is $c_{\\text{hot}}=0.1$. $t=4.7+0.1=4.8$. $P_3$ runs for $q=2$. $t=6.8$. $b_{3,r}=3$.\n4. Dispatch $P_1$: Overhead is $c_{\\text{hot}}=0.1$. $t=6.8+0.1=6.9$. $P_1$ runs for $q=2$. $t=8.9$. $b_{1,r}=3$.\n5. Dispatch $P_2$: Overhead is $c_{\\text{hot}}=0.1$. $t=8.9+0.1=9.0$. $P_2$ runs for $1\\,\\text{ms}$. $t=10.0$. $b_{2,r}=0$. $P_2$ completes, $C_{2, \\mathcal{H}}=10.0\\,\\text{ms}$.\n6. Dispatch $P_3$: Overhead is $c_{\\text{hot}}=0.1$. $t=10.0+0.1=10.1$. $P_3$ runs for $q=2$. $t=12.1$. $b_{3,r}=1$.\n7. Dispatch $P_1$: Overhead is $c_{\\text{hot}}=0.1$. $t=12.1+0.1=12.2$. $P_1$ runs for $q=2$. $t=14.2$. $b_{1,r}=1$.\n8. Dispatch $P_3$: Overhead is $c_{\\text hot}=0.1$. $t=14.2+0.1=14.3$. $P_3$ runs for $1\\,\\text{ms}$. $t=15.3$. $b_{3,r}=0$. $P_3$ completes, $C_{3, \\mathcal{H}}=15.3\\,\\text{ms}$.\n9. Dispatch $P_1$: Overhead is $c_{\\text{hot}}=0.1$. $t=15.3+0.1=15.4$. $P_1$ runs for $1\\,\\text{ms}$. $t=16.4$. $b_{1,r}=0$. $P_1$ completes, $C_{1, \\mathcal{H}}=16.4\\,\\text{ms}$.\n\nThe total time for Pattern $\\mathcal{H}$ is $T_{\\text{total}, \\mathcal{H}}=16.4\\,\\text{ms}$.\nTotal overhead is $c_{\\text{cold}} + (9-1)c_{\\text{hot}} = 0.6 + 8 \\times 0.1 = 1.4\\,\\text{ms}$.\nTotal time check: $B_{\\text{total}} + \\text{Overhead} = 15 + 1.4 = 16.4\\,\\text{ms}$, which matches.\nThe effective CPU utilization for Pattern $\\mathcal{H}$ is $U_{\\mathcal{H}} = \\frac{B_{\\text{total}}}{T_{\\text{total}, \\mathcal{H}}} = \\frac{15}{16.4}$.\nThe completion times are $C_{1, \\mathcal{H}}=16.4$, $C_{2, \\mathcal{H}}=10.0$, $C_{3, \\mathcal{H}}=15.3$.\nThe average turnaround time for Pattern $\\mathcal{H}$ is $\\overline{T}_{\\mathcal{H}} = \\frac{1}{3}(16.4 + 10.0 + 15.3) = \\frac{41.7}{3}\\,\\text{ms}$.\n\nFinally, we compute the combined improvement factor $M$:\n$$\nM = \\frac{U_{\\mathcal{H}}}{U_{\\mathcal{C}}}\\,\\cdot\\,\\frac{\\overline{T}_{\\mathcal{C}}}{\\overline{T}_{\\mathcal{H}}}\n$$\nSubstituting the derived values:\n$$\nM = \\frac{15/16.4}{15/20.4} \\cdot \\frac{51.2/3}{41.7/3} = \\frac{20.4}{16.4} \\cdot \\frac{51.2}{41.7}\n$$\n$$\nM = \\frac{20.4 \\times 51.2}{16.4 \\times 41.7} = \\frac{1044.48}{683.88} \\approx 1.5272633\n$$\nRounding the result to four significant figures, we get $1.527$.",
            "answer": "$$\\boxed{1.527}$$"
        },
        {
            "introduction": "Moving beyond uniform workloads, this exercise explores how RR scheduling performs in a more realistic scenario with a mix of compute-bound and interactive (I/O-bound) tasks. You will see firsthand how a fixed time quantum $q$ can lead to an uneven distribution of CPU resources. The goal is to formalize this observation by calculating each task's effective CPU share and evaluating the system's overall fairness using the standard Jain's Fairness Index .",
            "id": "3678396",
            "problem": "Consider a uniprocessor system using round-robin scheduling with time quantum $q$ and negligible context-switch overhead. At time $t=0$, there are $N$ compute-bound tasks that are always ready to run and $M$ interactive tasks that voluntarily block for Input/Output (I/O) after consuming a short burst of central processing unit (CPU) time. Each interactive task, once scheduled, runs for a fixed duration $s$ with $0lt;slt;q$ and then sleeps long enough that it does not reappear during the interval of interest. The scheduler visits each ready task at most once in cyclic order, allowing each task to run until either it has executed for $q$ units of time or it voluntarily relinquishes the CPU, whichever occurs first.\n\nDefine the effective CPU share $x_i$ of task $i$ over the considered interval as the ratio of its actual CPU running time to the total CPU running time accumulated by all tasks in that same interval:\n$$\nx_i \\;=\\; \\frac{\\text{running time of task } i}{\\sum\\limits_{j=1}^{N+M} \\text{running time of task } j}.\n$$\nUsing this definition, derive the fairness index $J(q)$ of the resulting CPU share vector $x = (x_1,\\dots,x_{N+M})$ as a function of the time quantum $q$, where the fairness index is defined by the well-known Jain’s fairness index\n$$\nJ(x)\\;=\\;\\frac{\\left(\\sum\\limits_{i=1}^{N+M} x_i\\right)^{2}}{(N+M)\\left(\\sum\\limits_{i=1}^{N+M} x_i^{2}\\right)}.\n$$\nAssume $N\\geq 1$, $M\\geq 1$, $q0$, and $0sq$. Express your final answer as a single closed-form analytic expression in terms of $N$, $M$, $q$, and $s$. No numerical evaluation is required and no rounding is needed.",
            "solution": "The problem is first critically validated to ensure it is scientifically sound, well-posed, and objective before any attempt at a solution is made.\n\n**Step 1: Extract Givens**\n- System: Uniprocessor system with round-robin scheduling.\n- Time quantum: $q$.\n- Context-switch overhead: negligible.\n- Number of compute-bound tasks: $N$, with $N \\geq 1$.\n- Number of interactive tasks: $M$, with $M \\geq 1$.\n- Behavior of compute-bound tasks: Always ready to run.\n- Behavior of interactive tasks: Run for a fixed duration $s$, where $0  s  q$, then block and do not reappear.\n- Scheduler logic: Visits each task in cyclic order; runs until quantum $q$ expires or task voluntarily relinquishes CPU.\n- Definition of CPU share $x_i$: $x_i = \\frac{\\text{running time of task } i}{\\sum_{j=1}^{N+M} \\text{running time of task } j}$.\n- Definition of Jain's fairness index $J(x)$: $J(x) = \\frac{(\\sum_{i=1}^{N+M} x_i)^{2}}{(N+M)(\\sum_{i=1}^{N+M} x_i^{2})}$.\n- Task: Derive the fairness index $J(q)$ as a function of $N$, $M$, $q$, and $s$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, utilizing standard concepts from the field of operating systems, such as round-robin scheduling, time quanta, compute-bound versus I/O-bound processes, and a well-established performance metric (Jain's fairness index). The model presented, while a simplification (e.g., negligible context switching, deterministic task behavior), is a common and valid abstraction for theoretical analysis. The problem is well-posed; all parameters and constraints are clearly defined, leading to a determinable, unique solution. The language is objective and devoid of ambiguity. The phrase “interval of interest” is implicitly and sufficiently defined by the problem's context: since the $M$ interactive tasks are specified to run only once, the only logical interval for evaluating the fairness among all $N+M$ tasks is the single, initial scheduling round where every task is given a chance to execute. After this round, the set of active tasks changes, altering the system's dynamics. Thus, the problem is self-contained, consistent, and solvable.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The derivation of the solution will now proceed.\n\nThe core of the problem is to calculate the CPU share $x_i$ for each task and then substitute these shares into the formula for Jain's fairness index. We analyze the system over a single, complete round of scheduling where each of the $N+M$ initial tasks is serviced once.\n\nFirst, we determine the CPU time consumed by each type of task in this interval.\nThere are $N$ compute-bound tasks. Being always ready, each will be scheduled and will run for its entire time quantum, $q$. The running time for any one of these $N$ tasks is $q$.\nThere are $M$ interactive tasks. Each is specified to run for a duration $s$ before blocking. Since the problem states $0  s  q$, each interactive task will run for a time $s$ and then voluntarily relinquish the CPU before its quantum expires. The running time for any one of these $M$ tasks is $s$.\n\nThe total CPU time, $T_{\\text{total}}$, accumulated by all tasks during this interval is the sum of the times for all $N$ compute-bound and $M$ interactive tasks:\n$$ T_{\\text{total}} = (N \\times q) + (M \\times s) = Nq + Ms $$\nNext, we calculate the CPU share for each task using its definition, $x_i = (\\text{running time of task } i) / T_{\\text{total}}$.\nFor each of the $N$ compute-bound tasks, the share, which we can denote $x_{\\text{c}}$, is identical:\n$$ x_{\\text{c}} = \\frac{q}{Nq + Ms} $$\nFor each of the $M$ interactive tasks, the share, which we can denote $x_{\\text{int}}$, is also identical within its group:\n$$ x_{\\text{int}} = \\frac{s}{Nq + Ms} $$\nNow, we apply the formula for Jain's fairness index, $J(q)$:\n$$ J(q) = \\frac{\\left(\\sum\\limits_{i=1}^{N+M} x_i\\right)^{2}}{(N+M)\\left(\\sum\\limits_{i=1}^{N+M} x_i^{2}\\right)} $$\nWe evaluate the two summation terms. First, the sum of the shares in the numerator:\n$$ \\sum_{i=1}^{N+M} x_i = N \\cdot x_{\\text{c}} + M \\cdot x_{\\text{int}} = N \\left( \\frac{q}{Nq + Ms} \\right) + M \\left( \\frac{s}{Nq + Ms} \\right) = \\frac{Nq + Ms}{Nq + Ms} = 1 $$\nThis confirms the property that the sum of all shares is $1$. The numerator of $J(q)$ is therefore $(1)^{2} = 1$. The formula for $J(q)$ simplifies to:\n$$ J(q) = \\frac{1}{(N+M)\\left(\\sum\\limits_{i=1}^{N+M} x_i^{2}\\right)} $$\nNext, we evaluate the sum of the squares of the shares for the denominator:\n$$ \\sum_{i=1}^{N+M} x_i^{2} = N \\cdot x_{\\text{c}}^{2} + M \\cdot x_{\\text{int}}^{2} = N \\left( \\frac{q}{Nq + Ms} \\right)^{2} + M \\left( \\frac{s}{Nq + Ms} \\right)^{2} $$\n$$ \\sum_{i=1}^{N+M} x_i^{2} = \\frac{Nq^{2}}{(Nq + Ms)^{2}} + \\frac{Ms^{2}}{(Nq + Ms)^{2}} = \\frac{Nq^{2} + Ms^{2}}{(Nq + Ms)^{2}} $$\nFinally, we substitute this expression back into the simplified formula for $J(q)$:\n$$ J(q) = \\frac{1}{(N+M) \\left( \\frac{Nq^{2} + Ms^{2}}{(Nq + Ms)^{2}} \\right)} $$\nInverting the fraction in the denominator gives the final closed-form expression for the fairness index:\n$$ J(q) = \\frac{(Nq + Ms)^{2}}{(N+M)(Nq^{2} + Ms^{2})} $$\nThis expression gives the fairness index as a function of the given parameters $N$, $M$, $q$, and $s$.",
            "answer": "$$\n\\boxed{\\frac{(Nq + Ms)^{2}}{(N+M)(Nq^{2} + Ms^{2})}}\n$$"
        },
        {
            "introduction": "The choice of the time quantum $q$ embodies a classic system design trade-off. This final practice moves from analysis to optimization, challenging you to find the ideal value for $q$. You will build a mathematical model that captures the balance between minimizing system call overhead (which favors a large $q$) and ensuring low latency for interactive tasks (which favors a small $q$), and then use it to derive the optimal quantum size .",
            "id": "3678402",
            "problem": "Consider a time-shared Operating System (OS) using Round-Robin (RR) scheduling with $N$ runnable interactive processes. Each process alternates between short compute bursts and issuing Input/Output (I/O) to the kernel. To reduce kernel overhead, each process attempts to batch its I/O: in the absence of preemption, a typical compute burst of length $B$ (measured in seconds of CPU time) ends with a single batched system call, whose kernel execution time cost is $c_{sys}$ (measured in seconds of CPU time). However, if the RR time quantum $q$ is shorter than $B$, the burst is fragmented into multiple scheduled slices, and to maintain timely output, the process issues a system call at the end of each fragment. This fragmentation increases the number of system calls per burst and therefore increases total system call time spent in the kernel.\n\nAssume the following idealizations:\n- Context switching overhead is negligible compared to $c_{sys}$ and is ignored.\n- Each unfragmented compute burst of length $B$ ends with exactly one system call of cost $c_{sys}$; if the burst is fragmented by RR preemption, the number of system calls equals the number of fragments.\n- For $q \\leq B$, approximate $\\lceil B/q \\rceil$ by $B/q$ to obtain a differentiable cost model; additive constants independent of $q$ may be dropped when minimizing over $q$.\n- Interactive events for a given process arrive independently of scheduling and uniformly over the RR cycle. If an event arrives while the process is running, it can be handled immediately; otherwise it must wait until the process’s next scheduled slice.\n\nUsing only standard definitions of RR and the uniform-arrival assumption, derive an expression for the time quantum $q$ that minimizes the following composite objective:\n- The expected additional system call time per unit CPU time caused by fragmentation when $q \\leq B$, and\n- A weighted expected start latency for an interactive event, with weight $w$ (measured in cost per second) that converts expected latency (in seconds) to the same cost units as system call time.\n\nExpress your final answer as a single closed-form analytic expression $q^{\\star}$ in terms of $N$, $c_{sys}$, and $w$. No numerical evaluation is required, and no rounding is needed. State no units in your final answer.",
            "solution": "We begin from the core Round-Robin (RR) definitions and the uniform-arrival assumption. In RR with $N$ runnable processes and negligible overhead, the scheduler cycles through the processes, giving each up to $q$ seconds of CPU time. One full cycle length is $N q$ seconds.\n\nFirst, we model the fragmentation-induced system call cost. In the unfragmented case, one compute burst of length $B$ ends with a single system call of cost $c_{sys}$. If the time quantum is $q \\leq B$, then the burst is split into approximately $B/q$ fragments (replacing $\\lceil B/q \\rceil$ by $B/q$ for differentiability), and one system call is issued at the end of each fragment. Thus, the total number of system calls per burst is approximately $B/q$, and the total system call time per burst is approximately $(B/q) c_{sys}$. Compared to the unfragmented single-call cost $c_{sys}$, the additional system call time per burst caused by fragmentation is\n$$\n\\left(\\frac{B}{q} - 1\\right) c_{sys}.\n$$\nTo obtain a cost per unit of CPU time, divide by the burst length $B$:\n$$\n\\frac{1}{B} \\left(\\frac{B}{q} - 1\\right) c_{sys} \\;=\\; \\frac{c_{sys}}{q} \\;-\\; \\frac{c_{sys}}{B}.\n$$\nWhen minimizing with respect to $q$, the constant term $-c_{sys}/B$ does not affect the optimal $q$, so we drop it. Thus, the fragmentation-induced system call cost per unit CPU time has the form\n$$\nJ_{\\text{sys}}(q) \\;=\\; \\frac{c_{sys}}{q}.\n$$\n\nSecond, we model the expected interactive start latency under RR with uniform arrival. Consider a fixed process. Over one RR cycle of length $N q$, its own quantum occupies $q$ seconds, and the other $N-1$ processes occupy $(N-1) q$ seconds. Assume an interactive event for the process arrives uniformly over the cycle. If the event arrives during the process’s own quantum, it can be handled immediately, so the latency is $0$. If the event arrives during one of the other $N-1$ quanta, the process must wait until its next scheduled slice. Conditioned on arrival within another process’s quantum, the expected remaining time in that current quantum is $q/2$ (by uniformity within the interval), and the expected number of complete intervening quanta before the target process’s next slice is uniformly distributed over $\\{0,1,\\dots,N-2\\}$, which has mean $(N-2)/2$. Therefore, the conditional expected waiting time is\n$$\n\\frac{q}{2} \\;+\\; \\frac{N-2}{2}\\, q \\;=\\; \\frac{N-1}{2}\\, q.\n$$\nThe probability of arriving during another process’s quantum is $(N-1)/N$, and during the process’s own quantum is $1/N$. Hence, the unconditional expected start latency is\n$$\n\\mathbb{E}[T(q)] \\;=\\; \\frac{N-1}{N} \\cdot \\frac{N-1}{2}\\, q \\;=\\; \\frac{(N-1)^{2}}{2N}\\, q.\n$$\nWe convert this expected latency into the same cost units as system call time using a weight $w$ (measured in cost per second). The latency cost is\n$$\nJ_{\\text{lat}}(q) \\;=\\; w \\cdot \\mathbb{E}[T(q)] \\;=\\; w \\cdot \\frac{(N-1)^{2}}{2N}\\, q.\n$$\n\nThe total objective to minimize as a function of $q$ is the sum\n$$\nJ(q) \\;=\\; J_{\\text{sys}}(q) \\;+\\; J_{\\text{lat}}(q) \\;=\\; \\frac{c_{sys}}{q} \\;+\\; w \\cdot \\frac{(N-1)^{2}}{2N}\\, q.\n$$\nThis function is strictly convex for $q0$ because it is the sum of a convex term in $q$ ($\\propto q$) and a convex term in $1/q$ ($\\propto 1/q$). The unique minimizer $q^{\\star}$ satisfies the first-order optimality condition $J'(q^{\\star})=0$.\n\nCompute the derivative:\n$$\nJ'(q) \\;=\\; -\\, \\frac{c_{sys}}{q^{2}} \\;+\\; w \\cdot \\frac{(N-1)^{2}}{2N}.\n$$\nSet $J'(q)=0$ and solve for $q$:\n$$\n-\\, \\frac{c_{sys}}{q^{2}} \\;+\\; w \\cdot \\frac{(N-1)^{2}}{2N} \\;=\\; 0\n\\;\\;\\Longrightarrow\\;\\;\n\\frac{c_{sys}}{q^{2}} \\;=\\; w \\cdot \\frac{(N-1)^{2}}{2N}\n\\;\\;\\Longrightarrow\\;\\;\nq^{2} \\;=\\; \\frac{2N\\, c_{sys}}{w\\, (N-1)^{2}}.\n$$\nTaking the positive square root (since $q0$), the optimal time quantum is\n$$\nq^{\\star} \\;=\\; \\sqrt{\\frac{2N\\, c_{sys}}{w\\, (N-1)^{2}}}.\n$$\n\nThis $q^{\\star}$ balances the $1/q$ increase in system call time due to fragmentation when $q$ is small against the linear-in-$q$ increase in expected interactive start latency when $q$ is large, under the stated RR and uniform-arrival assumptions.",
            "answer": "$$\\boxed{\\sqrt{\\frac{2 N\\, c_{sys}}{w\\, (N-1)^{2}}}}$$"
        }
    ]
}