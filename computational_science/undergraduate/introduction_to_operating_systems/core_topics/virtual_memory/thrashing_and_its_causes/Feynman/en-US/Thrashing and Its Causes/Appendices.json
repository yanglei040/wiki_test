{
    "hands_on_practices": [
        {
            "introduction": "Thrashing occurs when a system spends more time servicing page faults than executing useful work, leading to a collapse in CPU utilization. This first practice provides a quantitative look at the root of this problem: the page fault service time ($t_{pf}$). By calculating and comparing $t_{pf}$ for a traditional Hard Disk Drive (HDD) versus a modern Solid-State Drive (SSD), you will see firsthand how storage hardware characteristics directly influence the system's resilience to page faults and determine the boundary at which thrashing begins .",
            "id": "3688430",
            "problem": "A single-core system runs a memory-intensive workload whose instruction stream generates a steady sequence of memory references. In the absence of page faults, each reference costs a fixed compute time of $t_{c}$ from the Central Processing Unit (CPU). When a page fault occurs, the process is blocked until the fault is serviced, after which it resumes. Assume there is no useful overlap between page fault service and useful instruction execution across the workload (for example, because all runnable processes are statistically identical and tend to be simultaneously blocked when faults are frequent), and ignore prefetching and write-back effects. The average page fault service time $t_{pf}$ is the sum of a fixed operating system overhead $t_{os}$ and the device service time, which is itself the sum of access latency and transfer time for the page.\n\nConsider two swap storage technologies: a Hard Disk Drive (HDD) and a Solid-State Drive (SSD). The page size is $S=8\\ \\mathrm{KB}$. For the HDD, the average seek time is $t_{\\mathrm{seek,H}}=6.00\\ \\mathrm{ms}$, the average rotational latency is $t_{\\mathrm{rot,H}}=4.17\\ \\mathrm{ms}$, and the sequential transfer bandwidth is $B_{\\mathrm{H}}=160\\ \\mathrm{MB/s}$. For the SSD, the access latency (controller and flash access) is $t_{\\mathrm{acc,S}}=0.060\\ \\mathrm{ms}$ and the sequential transfer bandwidth is $B_{\\mathrm{S}}=1000\\ \\mathrm{MB/s}$. The operating system overhead is the same for both devices, $t_{os}=0.100\\ \\mathrm{ms}$. Take $1\\ \\mathrm{KB}=1024\\ \\mathrm{bytes}$ and $1\\ \\mathrm{MB}=10^{6}\\ \\mathrm{bytes}$.\n\nLet the per-reference compute time be $t_{c}=100\\ \\mathrm{ns}$ under no faults, and suppose the probability of a page fault per reference under a given memory pressure is $p$. Using first principles and the above parameters:\n\n- Derive an expression for the average page fault service time $t_{pf}$ for each device and compute its value.\n- Using only the definition that the CPU utilization $C$ equals the fraction of time spent doing useful computation, express $C$ in terms of $t_{c}$, $p$, and $t_{pf}$, and evaluate $C$ for each device at $p=1.0\\times10^{-3}$.\n- Define the onset of thrashing as the point where CPU utilization drops to the threshold $C_{\\min}=0.50$. For each device, derive the critical page fault probability per reference $p^{\\star}$ at which $C=C_{\\min}$. Then, define the thrashing boundary shift factor $s$ as the ratio of the SSD’s critical probability to the HDD’s critical probability, $s = p^{\\star}_{\\mathrm{SSD}}/p^{\\star}_{\\mathrm{HDD}}$.\n\nReport only the value of $s$ as your final answer, rounded to three significant figures. Do not include any unit in your reported final answer. In your derivation and intermediate computations, use milliseconds for time and megabytes per second for bandwidth, and express any intermediate CPU utilizations as pure decimal fractions between $0$ and $1$.",
            "solution": "The problem is validated as self-contained, scientifically grounded in the principles of operating systems performance modeling, and well-posed. We may proceed with a formal solution.\n\nThe objective is to determine the thrashing boundary shift factor, $s$, defined as the ratio of the critical page fault probabilities of a Solid-State Drive (SSD) versus a Hard Disk Drive (HDD), $s = p^{\\star}_{\\mathrm{SSD}}/p^{\\star}_{\\mathrm{HDD}}$. This requires a multi-step derivation.\n\nFirst, we derive an expression for the average page fault service time, $t_{pf}$, for a given storage device. The problem states that $t_{pf}$ is the sum of a fixed operating system overhead, $t_{os}$, and the device service time. The device service time is the sum of access latency and data transfer time.\n$$t_{pf} = t_{os} + t_{\\text{access}} + t_{\\text{transfer}}$$\nThe transfer time, $t_{\\text{transfer}}$, is the page size, $S$, divided by the device's sequential transfer bandwidth, $B$.\n$$t_{\\text{transfer}} = \\frac{S}{B}$$\nWe must first express the page size $S=8\\ \\mathrm{KB}$ in units of megabytes (MB) consistent with the given bandwidth units ($\\mathrm{MB/s}$). The problem specifies $1\\ \\mathrm{KB}=1024\\ \\mathrm{bytes}$ and $1\\ \\mathrm{MB}=10^{6}\\ \\mathrm{bytes}$.\n$$S = 8\\ \\mathrm{KB} = 8 \\times 1024\\ \\mathrm{bytes} = 8192\\ \\mathrm{bytes}$$\n$$S = \\frac{8192}{10^{6}}\\ \\mathrm{MB} = 0.008192\\ \\mathrm{MB}$$\n\nNow, we compute $t_{pf}$ for each device.\n\nFor the Hard Disk Drive (HDD):\nThe access latency is the sum of seek time and rotational latency: $t_{\\text{access,H}} = t_{\\mathrm{seek,H}} + t_{\\mathrm{rot,H}}$.\nGiven values are $t_{\\mathrm{seek,H}}=6.00\\ \\mathrm{ms}$ and $t_{\\mathrm{rot,H}}=4.17\\ \\mathrm{ms}$.\n$$t_{\\text{access,H}} = 6.00\\ \\mathrm{ms} + 4.17\\ \\mathrm{ms} = 10.17\\ \\mathrm{ms}$$\nThe transfer time is calculated using the bandwidth $B_{\\mathrm{H}}=160\\ \\mathrm{MB/s}$.\n$$t_{\\text{transfer,H}} = \\frac{0.008192\\ \\mathrm{MB}}{160\\ \\mathrm{MB/s}} = 0.0000512\\ \\mathrm{s} = 0.0512\\ \\mathrm{ms}$$\nThe total page fault service time for the HDD, with $t_{os}=0.100\\ \\mathrm{ms}$, is:\n$$t_{pf,\\mathrm{H}} = t_{os} + t_{\\text{access,H}} + t_{\\text{transfer,H}} = 0.100\\ \\mathrm{ms} + 10.17\\ \\mathrm{ms} + 0.0512\\ \\mathrm{ms} = 10.3212\\ \\mathrm{ms}$$\n\nFor the Solid-State Drive (SSD):\nThe access latency is given directly as $t_{\\text{access,S}} = t_{\\mathrm{acc,S}} = 0.060\\ \\mathrm{ms}$.\nThe transfer time is calculated using the bandwidth $B_{\\mathrm{S}}=1000\\ \\mathrm{MB/s}$.\n$$t_{\\text{transfer,S}} = \\frac{0.008192\\ \\mathrm{MB}}{1000\\ \\mathrm{MB/s}} = 0.000008192\\ \\mathrm{s} = 0.008192\\ \\mathrm{ms}$$\nThe total page fault service time for the SSD, with $t_{os}=0.100\\ \\mathrm{ms}$, is:\n$$t_{pf,\\mathrm{S}} = t_{os} + t_{\\text{access,S}} + t_{\\text{transfer,S}} = 0.100\\ \\mathrm{ms} + 0.060\\ \\mathrm{ms} + 0.008192\\ \\mathrm{ms} = 0.168192\\ \\mathrm{ms}$$\n\nNext, we derive the expression for CPU utilization, $C$. CPU utilization is the fraction of total time that the CPU is engaged in useful computation. Let's consider the average time elapsed per memory reference. With probability $p$, a reference causes a page fault, and with probability $(1-p)$, it does not.\nThe time for a non-faulting reference is the compute time $t_c$.\nThe time for a faulting reference includes the compute time $t_c$ plus the page fault service time $t_{pf}$, during which the CPU is blocked (idle). The total elapsed time for a faulting reference event is $t_c + t_{pf}$.\nThe average total time per reference, $T_{\\text{avg}}$, is the weighted average:\n$$T_{\\text{avg}} = (1-p)t_c + p(t_c + t_{pf}) = t_c - pt_c + pt_c + pt_{pf} = t_c + p \\cdot t_{pf}$$\nThe useful computation time per reference is always $t_c$.\nTherefore, the CPU utilization $C$ is the ratio of useful computation time to the average total time:\n$$C = \\frac{t_c}{T_{\\text{avg}}} = \\frac{t_c}{t_c + p \\cdot t_{pf}}$$\nWe are asked to evaluate $C$ for each device at $p = 1.0 \\times 10^{-3}$. We are given $t_c = 100\\ \\mathrm{ns} = 1.0 \\times 10^{-4}\\ \\mathrm{ms}$.\nFor the HDD:\n$$C_{\\mathrm{H}} = \\frac{1.0 \\times 10^{-4}\\ \\mathrm{ms}}{1.0 \\times 10^{-4}\\ \\mathrm{ms} + (1.0 \\times 10^{-3}) \\cdot (10.3212\\ \\mathrm{ms})} = \\frac{1.0 \\times 10^{-4}}{1.0 \\times 10^{-4} + 0.0103212} = \\frac{1.0 \\times 10^{-4}}{0.0104212} \\approx 0.00960$$\nFor the SSD:\n$$C_{\\mathrm{S}} = \\frac{1.0 \\times 10^{-4}\\ \\mathrm{ms}}{1.0 \\times 10^{-4}\\ \\mathrm{ms} + (1.0 \\times 10^{-3}) \\cdot (0.168192\\ \\mathrm{ms})} = \\frac{1.0 \\times 10^{-4}}{1.0 \\times 10^{-4} + 0.000168192} = \\frac{1.0 \\times 10^{-4}}{0.000268192} \\approx 0.3729$$\n\nNow, we find the critical page fault probability, $p^{\\star}$, at which thrashing begins, defined by $C=C_{\\min}=0.50$.\nWe set our expression for $C$ equal to $C_{\\min}$ and solve for $p^{\\star}$:\n$$C_{\\min} = \\frac{t_c}{t_c + p^{\\star} \\cdot t_{pf}}$$\n$$t_c + p^{\\star} \\cdot t_{pf} = \\frac{t_c}{C_{\\min}}$$\n$$p^{\\star} \\cdot t_{pf} = \\frac{t_c}{C_{\\min}} - t_c = t_c \\left(\\frac{1}{C_{\\min}} - 1\\right) = t_c \\frac{1-C_{\\min}}{C_{\\min}}$$\n$$p^{\\star} = \\frac{t_c}{t_{pf}} \\left(\\frac{1-C_{\\min}}{C_{\\min}}\\right)$$\nWith $C_{\\min}=0.50$, the term $\\frac{1-C_{\\min}}{C_{\\min}} = \\frac{1-0.50}{0.50} = \\frac{0.50}{0.50} = 1$. The expression for the critical probability simplifies to:\n$$p^{\\star} = \\frac{t_c}{t_{pf}}$$\n\nFinally, we derive the thrashing boundary shift factor, $s$, which is the ratio of the critical probabilities:\n$$s = \\frac{p^{\\star}_{\\mathrm{SSD}}}{p^{\\star}_{\\mathrm{HDD}}}$$\nSubstituting the derived expression for $p^{\\star}$:\n$$s = \\frac{t_c / t_{pf,\\mathrm{S}}}{t_c / t_{pf,\\mathrm{H}}} = \\frac{t_{pf,\\mathrm{H}}}{t_{pf,\\mathrm{S}}}$$\nThe shift factor is simply the ratio of the page fault service times. We can now compute the value of $s$ using our previously calculated values for $t_{pf,\\mathrm{H}}$ and $t_{pf,\\mathrm{S}}$:\n$$s = \\frac{10.3212\\ \\mathrm{ms}}{0.168192\\ \\mathrm{ms}} \\approx 61.3655...$$\nRounding to three significant figures, as requested, we obtain:\n$$s \\approx 61.4$$\nThis result signifies that the system can tolerate a page fault probability over $61$ times higher when using an SSD compared to an HDD before its CPU utilization drops to the thrashing threshold of $50\\%$.",
            "answer": "$$\\boxed{61.4}$$"
        },
        {
            "introduction": "While the previous exercise focused on the cost of a single page fault, thrashing is truly a system-wide bottleneck caused by the *aggregate* demand on the I/O subsystem. This practice models the swap device as a service center with a finite capacity, where page faults generate a stream of I/O requests. By applying principles of queueing theory, you will derive the maximum sustainable page fault rate ($PFR_{\\max}$) before the swap device becomes saturated, leading to unbounded wait times and the characteristic performance collapse of thrashing .",
            "id": "3688426",
            "problem": "A single swap device backs the virtual memory of a multiprogrammed system. The swap device is a Solid State Drive (SSD) with a peak service capacity of $C = 6.0 \\times 10^{4}$ Input/Output Operations Per Second (IOPS). The operating system uses demand paging with clustered prefetch: on each page fault, an average of $k = 3$ pages are read into memory. The page replacement policy is Least Recently Used (LRU) and, due to a small free-frame pool, an average fraction $p_{d} = 0.4$ of evictions are dirty and require a synchronous write-back at the time of the fault. The swap device is shared with a steady background file cache write-back that consumes $B = 1.2 \\times 10^{4}$ IOPS continuously. Assume that I/O requests from page faults and background traffic are independent and that the swap device can be modeled as a single-server queue with a well-defined long-run average service rate.\n\nStarting from first principles of queue stability grounded in operating system performance and single-server queue behavior, derive an expression for the maximum aggregate page fault rate $PFR_{\\max}$, measured in faults per second, that avoids unbounded queue growth in the swap device. Then compute the numerical value of $PFR_{\\max}$ for the given parameters. Express the final rate in faults per second and round your answer to four significant figures.",
            "solution": "The problem requires the derivation of the maximum aggregate page fault rate, $PFR_{\\max}$, that a multiprogrammed system can sustain without causing its swap device queue to grow without bound. The solution will be derived from the first principles of single-server queue stability.\n\nThe fundamental principle for the stability of a single-server queue is that the long-run average arrival rate of requests, $\\lambda$, must be less than or equal to the long-run average service rate, $\\mu$. Unbounded queue growth is avoided if $\\lambda < \\mu$. The maximum theoretical capacity is reached at the boundary condition $\\lambda = \\mu$.\n\nLet $C$ be the peak service capacity of the swap device, given as $C = 6.0 \\times 10^{4}$ Input/Output Operations Per Second (IOPS). This represents the maximum service rate, $\\mu$, of the server.\n$$ \\mu = C $$\n\nThe total arrival rate of I/O requests at the swap device, $\\lambda_{total}$, is the sum of requests originating from two independent sources: background file system activity and page fault servicing.\n$$ \\lambda_{total} = \\lambda_{PF} + \\lambda_{BG} $$\nwhere $\\lambda_{PF}$ is the I/O rate due to page faults and $\\lambda_{BG}$ is the I/O rate from background activity.\n\nThe problem states that there is a steady background file cache write-back that consumes $B = 1.2 \\times 10^{4}$ IOPS. This constitutes the background arrival rate.\n$$ \\lambda_{BG} = B $$\n\nNext, we must formulate the arrival rate due to page faults, $\\lambda_{PF}$, as a function of the aggregate page fault rate, which we denote as $PFR$ (in faults per second). Each page fault generates a certain number of I/O operations on the swap device. These operations consist of reads to bring pages into memory and writes to evict dirty pages.\n\n1.  **Read Operations**: The operating system uses demand paging with clustered prefetch. On each page fault, an average of $k = 3$ pages are read into memory from the swap device. Assuming each page read corresponds to a single I/O operation, the number of read I/Os per page fault is $k$.\n    $$ \\text{I/Os}_{\\text{read}}/\\text{fault} = k $$\n\n2.  **Write Operations**: A page fault necessitates freeing a page frame in memory. The problem specifies that the Least Recently Used (LRU) policy is in effect, and on average, a fraction $p_{d} = 0.4$ of these evicted page frames are dirty. A dirty page must be written back to the swap device before its frame can be reused. This is specified as a synchronous write-back. A clean page does not require a write-back. Therefore, the average number of write I/Os per page fault is $p_{d}$.\n    $$ \\text{I/Os}_{\\text{write}}/\\text{fault} = p_{d} \\times 1 + (1 - p_{d}) \\times 0 = p_{d} $$\n\nThe total average number of I/O operations generated per page fault is the sum of the average read and write operations.\n$$ \\text{I/Os}/\\text{fault} = k + p_{d} $$\nThe total I/O arrival rate from page faults, $\\lambda_{PF}$, is the product of the page fault rate ($PFR$) and the average number of I/Os per fault.\n$$ \\lambda_{PF} = PFR \\times (k + p_{d}) $$\n\nNow, we can write the expression for the total arrival rate at the swap device:\n$$ \\lambda_{total} = PFR \\times (k + p_{d}) + B $$\n\nTo avoid unbounded queue growth, the total arrival rate must not exceed the device's service capacity. The maximum sustainable page fault rate, $PFR_{\\max}$, occurs when the total arrival rate equals the service rate.\n$$ \\lambda_{total} = \\mu $$\n$$ PFR_{\\max} \\times (k + p_{d}) + B = C $$\n\nWe can now solve for $PFR_{\\max}$:\n$$ PFR_{\\max} \\times (k + p_{d}) = C - B $$\n$$ PFR_{\\max} = \\frac{C - B}{k + p_{d}} $$\nThis is the derived expression for the maximum aggregate page fault rate. The term $C - B$ represents the available I/O capacity for page fault servicing, and $k + p_{d}$ is the I/O cost per page fault.\n\nNow, we compute the numerical value using the given parameters:\n- $C = 6.0 \\times 10^{4}$ IOPS\n- $B = 1.2 \\times 10^{4}$ IOPS\n- $k = 3$\n- $p_{d} = 0.4$\n\nFirst, calculate the denominator, which is the average number of I/Os per fault:\n$$ k + p_{d} = 3 + 0.4 = 3.4 $$\n\nNext, calculate the numerator, which is the available I/O service rate for paging:\n$$ C - B = (6.0 \\times 10^{4}) - (1.2 \\times 10^{4}) = 4.8 \\times 10^{4} \\text{ IOPS} $$\n\nFinally, compute $PFR_{\\max}$:\n$$ PFR_{\\max} = \\frac{4.8 \\times 10^{4}}{3.4} \\approx 14117.647... \\text{ faults/second} $$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$ PFR_{\\max} \\approx 14120 \\text{ faults/second} $$\nIn standard scientific notation, this is $1.412 \\times 10^{4}$ faults/second.",
            "answer": "$$ \\boxed{1.412 \\times 10^{4}} $$"
        },
        {
            "introduction": "The causes of thrashing are not limited to I/O bottlenecks; they can also arise from subtleties in memory management policy. This final practice explores the complex trade-offs of using large pages, an optimization designed to improve Translation Lookaside Buffer (TLB) performance. You will analyze a scenario that reveals a counter-intuitive outcome: how using large pages can reduce TLB misses but simultaneously increase total memory demand due to internal fragmentation, pushing an otherwise stable system into a state of thrashing .",
            "id": "3688450",
            "problem": "A computing system runs three independent processes, denoted by $P_1$, $P_2$, and $P_3$, each cycling over disjoint memory regions in a tight loop. The system uses demand paging with a fixed amount of physical memory available to these three processes, denoted by $B$, and the memory manager may choose between two page sizes. The Translation Lookaside Buffer (TLB) capacity per process time slice is $C$ entries.\n\nDefinitions for the scenario:\n- The working set model of Peter J. Denning defines the working set $W_i(t,\\Delta)$ of process $i$ over a window $[t,t+\\Delta]$ as the set of distinct virtual pages referenced by process $i$ in that time window; the working set size is $|W_i(t,\\Delta)|$ in pages. The total working set bytes demanded by process $i$ in that window equals $|W_i(t,\\Delta)| \\cdot S_{\\text{page}}$, where $S_{\\text{page}}$ is the current page size.\n- Thrashing is a regime in which the paging subsystem dominates execution due to excessive page faults, commonly triggered when the aggregate resident demand across processes exceeds available physical memory $B$ so that pages are continually evicted and re-faulted.\n- The Translation Lookaside Buffer (TLB) is a cache of recent virtual-to-physical page translations. Its capacity $C$ entries bounds how many distinct page translations can be held at once during a time slice; if $|W_i(t,\\Delta)| \\gg C$, sustained TLB misses are expected.\n\nWorkload and parameters:\n- Each process $P_i$ repeatedly loops over $k_i$ disjoint regions, each of length $L$, with a stride equal to the small page size, so that every small page that lies in the region is touched during $[t,t+\\Delta]$.\n- The parameters are $L = 1.5\\,\\mathrm{MiB}$, $k_1 = 100$, $k_2 = 80$, $k_3 = 60$, $B = 400\\,\\mathrm{MiB}$, and $C = 128$.\n- Two page sizes are considered: a small page $p_s = 4\\,\\mathrm{KiB}$ and a large page $p_\\ell = 2\\,\\mathrm{MiB}$.\n\nAssume $[t,t+\\Delta]$ is long enough that each process touches all addresses in all of its regions during the window, and that the operating system gives these three processes exclusive access to $B$ bytes of physical memory (other uses of memory are excluded from $B$). For the TLB, assume that during a process’s time slice its entries are warmed only by that process’s references, and the relevant measure of coverage is whether $|W_i(t,\\Delta)| \\leq C$ versus $|W_i(t,\\Delta)| \\gg C$.\n\nWhich of the following statements are correct for this workload?\n\nA. Under $p_\\ell$, the TLB miss rate for each process drops significantly relative to $p_s$, yet the system crosses the thrashing threshold within $[t,t+\\Delta]$ because the aggregate working set in bytes exceeds $B$; under $p_s$ the system does not thrash.\n\nB. The cardinality $|W_i(t,\\Delta)|$ in pages is unchanged by page size for this workload, so changing from $p_s$ to $p_\\ell$ cannot push the system into thrashing earlier.\n\nC. With $p_\\ell$, each process’s $|W_i(t,\\Delta)|$ in pages is below $C$, so after TLB warm-up within a time slice, misses remain low; with $p_s$, $|W_i(t,\\Delta)|$ in pages far exceeds $C$, so sustained TLB misses are expected.\n\nD. Increasing page size always delays the onset of thrashing because fewer pages are needed; therefore crossing the thrash threshold earlier with $p_\\ell$ is impossible.\n\nE. For the given parameters, the total working set in bytes under $p_s$ is $360\\,\\mathrm{MiB}$, whereas under $p_\\ell$ it is $480\\,\\mathrm{MiB}$; hence only $p_\\ell$ crosses the thrashing threshold $B = 400\\,\\mathrm{MiB}$.",
            "solution": "The problem statement is analyzed for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- **Processes:** $P_1$, $P_2$, $P_3$ (independent, cycling over disjoint memory regions).\n- **Physical Memory:** $B = 400\\,\\mathrm{MiB}$.\n- **TLB Capacity:** $C = 128$ entries.\n- **Workload:** Process $P_i$ loops over $k_i$ disjoint regions.\n- **Region Size:** $L = 1.5\\,\\mathrm{MiB}$.\n- **Process Parameters:** $k_1 = 100$, $k_2 = 80$, $k_3 = 60$.\n- **Page Sizes:** Small page $p_s = 4\\,\\mathrm{KiB}$, Large page $p_\\ell = 2\\,\\mathrm{MiB}$.\n- **Working Set Definition:** $W_i(t,\\Delta)$ is the set of distinct virtual pages referenced by process $i$ over $[t,t+\\Delta]$.\n- **Working Set Bytes:** $|W_i(t,\\Delta)| \\cdot S_{\\text{page}}$.\n- **Thrashing Condition:** Aggregate resident demand (total working set in bytes) $> B$.\n- **TLB Miss Condition:** Sustained misses if $|W_i(t,\\Delta)| \\gg C$.\n- **Assumptions:** The time window $[t,t+\\Delta]$ is sufficient for each process to touch all its regions. The processes have exclusive access to the $B$ bytes of memory.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of operating system memory management, including demand paging, working sets, thrashing, and Translation Lookaside Buffers (TLBs). The definitions provided are standard and consistent with the literature (e.g., Denning's working set model). The problem is well-posed, providing all necessary numerical parameters ($L, k_i, B, C, p_s, p_\\ell$) and clear definitions to allow for a unique, calculable solution. The language is objective and precise. The parameters are not physically impossible or contradictory. The problem does not contain any of the invalidating flaws listed in the instructions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Derivation\nThe core of the problem is to evaluate the system's performance under two different page size configurations: small pages ($p_s$) and large pages ($p_\\ell$). For each configuration, we must calculate:\n1.  The working set size in pages, $|W_i(t,\\Delta)|$, for each process to analyze TLB performance.\n2.  The aggregate working set size in bytes, $\\sum_i |W_i(t,\\Delta)| \\cdot S_{\\text{page}}$, to analyze for thrashing.\n\nFirst, let's establish the unit conversions:\n$1\\,\\mathrm{MiB} = 2^{20}$ bytes.\n$1\\,\\mathrm{KiB} = 2^{10}$ bytes.\n$p_s = 4\\,\\mathrm{KiB} = 4 \\cdot 2^{10}$ bytes.\n$p_\\ell = 2\\,\\mathrm{MiB} = 2 \\cdot 2^{20}$ bytes.\n$L = 1.5\\,\\mathrm{MiB} = 1.5 \\cdot 2^{20}$ bytes.\n$B = 400\\,\\mathrm{MiB}$.\n\nThe total memory *referenced* by each process $P_i$ is $M_i = k_i \\cdot L$, as the regions are disjoint.\n$M_1 = 100 \\cdot 1.5\\,\\mathrm{MiB} = 150\\,\\mathrm{MiB}$.\n$M_2 = 80 \\cdot 1.5\\,\\mathrm{MiB} = 120\\,\\mathrm{MiB}$.\n$M_3 = 60 \\cdot 1.5\\,\\mathrm{MiB} = 90\\,\\mathrm{MiB}$.\n\n**Scenario 1: Small Pages ($S_{\\text{page}} = p_s = 4\\,\\mathrm{KiB}$)**\n\n**Working Set Size (in pages) and TLB Analysis:**\nThe number of pages in the working set for process $P_i$ is the number of distinct small pages required to cover the total referenced memory $M_i$.\n$|W_i(t,\\Delta)|_s = \\frac{M_i}{p_s}$\n$|W_1(t,\\Delta)|_s = \\frac{150\\,\\mathrm{MiB}}{4\\,\\mathrm{KiB}} = \\frac{150 \\cdot 2^{20}}{4 \\cdot 2^{10}} = \\frac{150 \\cdot 1024}{4} = 150 \\cdot 256 = 38400$ pages.\n$|W_2(t,\\Delta)|_s = \\frac{120\\,\\mathrm{MiB}}{4\\,\\mathrm{KiB}} = \\frac{120 \\cdot 1024}{4} = 120 \\cdot 256 = 30720$ pages.\n$|W_3(t,\\Delta)|_s = \\frac{90\\,\\mathrm{MiB}}{4\\,\\mathrm{KiB}} = \\frac{90 \\cdot 1024}{4} = 90 \\cdot 256 = 23040$ pages.\n\nFor all three processes, $|W_i(t,\\Delta)|_s$ is in the tens of thousands, which is much greater than the TLB capacity $C=128$.\n$|W_i(t,\\Delta)|_s \\gg C$.\nTherefore, with small pages, all processes will experience sustained, high rates of TLB misses.\n\n**Aggregate Working Set Size (in bytes) and Thrashing Analysis:**\nThe problem states \"every small page that lies in the region is touched,\" which implies that the working set size in bytes is equal to the total referenced memory, as internal fragmentation is minimal.\nTotal working set bytes = $\\sum M_i = 150\\,\\mathrm{MiB} + 120\\,\\mathrm{MiB} + 90\\,\\mathrm{MiB} = 360\\,\\mathrm{MiB}$.\nWe compare this to the available physical memory $B=400\\,\\mathrm{MiB}$.\nSince $360\\,\\mathrm{MiB} < 400\\,\\mathrm{MiB}$, the aggregate demand does not exceed available memory. The system does not thrash.\n\n**Scenario 2: Large Pages ($S_{\\text{page}} = p_\\ell = 2\\,\\mathrm{MiB}$)**\n\n**Working Set Size (in pages) and TLB Analysis:**\nProcess $P_i$ accesses $k_i$ disjoint regions, each of size $L = 1.5\\,\\mathrm{MiB}$. The page size is $p_\\ell = 2\\,\\mathrm{MiB}$. Since each region's size $L$ is less than the page size $p_\\ell$, each region must be mapped into memory using at least one large page. Because the regions are disjoint, we assume each region requires its own unique large page(s). The most economical mapping in terms of page count is to align each region within a single large page. This gives a lower bound on the working set size.\n$|W_i(t,\\Delta)|_\\ell = (\\text{number of regions}) \\times (\\text{pages per region}) = k_i \\times 1 = k_i$.\n$|W_1(t,\\Delta)|_\\ell = k_1 = 100$ pages.\n$|W_2(t,\\Delta)|_\\ell = k_2 = 80$ pages.\n$|W_3(t,\\Delta)|_\\ell = k_3 = 60$ pages.\n\nWe compare this to the TLB capacity $C=128$.\nFor all three processes, $|W_i(t,\\Delta)|_\\ell \\le 128$.\nTherefore, with large pages, the working set of each process fits within the TLB. After an initial warm-up period, the TLB miss rate for each process is expected to be low.\n\n**Aggregate Working Set Size (in bytes) and Thrashing Analysis:**\nThe aggregate working set in bytes is the total number of pages used across all processes, multiplied by the page size. This accounts for internal fragmentation, where a full $2\\,\\mathrm{MiB}$ page is allocated for a smaller $1.5\\,\\mathrm{MiB}$ region.\nTotal number of large pages = $\\sum_i |W_i(t,\\Delta)|_\\ell = 100 + 80 + 60 = 240$ pages.\nTotal working set bytes = $240 \\text{ pages} \\times 2\\,\\mathrm{MiB/page} = 480\\,\\mathrm{MiB}$.\nWe compare this demand to the available physical memory $B=400\\,\\mathrm{MiB}$.\nSince $480\\,\\mathrm{MiB} > 400\\,\\mathrm{MiB}$, the aggregate demand exceeds available memory. The system will thrash.\n\n### Evaluation of Options\n\n**A. Under $p_\\ell$, the TLB miss rate for each process drops significantly relative to $p_s$, yet the system crosses the thrashing threshold within $[t,t+\\Delta]$ because the aggregate working set in bytes exceeds $B$; under $p_s$ the system does not thrash.**\n- **TLB performance:** With $p_s$, $|W_i|_s \\gg 128$ (high misses). With $p_\\ell$, $|W_i|_\\ell \\le 128$ (low misses). The miss rate indeed drops significantly. This part is correct.\n- **Thrashing with $p_\\ell$:** The aggregate working set is $480\\,\\mathrm{MiB}$, which exceeds $B=400\\,\\mathrm{MiB}$. The system thrashes. This part is correct.\n- **Thrashing with $p_s$:** The aggregate working set is $360\\,\\mathrm{MiB}$, which is less than $B=400\\,\\mathrm{MiB}$. The system does not thrash. This part is correct.\nThe entire statement is consistent with the derived results.\n**Verdict: Correct**\n\n**B. The cardinality $|W_i(t,\\Delta)|$ in pages is unchanged by page size for this workload, so changing from $p_s$ to $p_\\ell$ cannot push the system into thrashing earlier.**\nThe premise \"$|W_i(t,\\Delta)|$ in pages is unchanged by page size\" is false. For $P_1$, $|W_1|_s = 38400$ pages, while $|W_1|_\\ell = 100$ pages. The number of pages changes dramatically. The conclusion is therefore unsupported and also incorrect, as our analysis shows the system does thrash with $p_\\ell$.\n**Verdict: Incorrect**\n\n**C. With $p_\\ell$, each process’s $|W_i(t,\\Delta)|$ in pages is below $C$, so after TLB warm-up within a time slice, misses remain low; with $p_s$, $|W_i(t,\\Delta)|$ in pages far exceeds $C$, so sustained TLB misses are expected.**\n- **With $p_\\ell$:** $|W_1|_\\ell=100$, $|W_2|_\\ell=80$, $|W_3|_\\ell=60$. All are less than or equal to $C=128$. This leads to low miss rates, as stated. This part is correct.\n- **With $p_s$:** $|W_1|_s=38400$, $|W_2|_s=30720$, $|W_3|_s=23040$. All far exceed $C=128$. This leads to sustained high miss rates, as stated. This part is correct.\nThe statement accurately describes the TLB behavior for both page sizes.\n**Verdict: Correct**\n\n**D. Increasing page size always delays the onset of thrashing because fewer pages are needed; therefore crossing the thrash threshold earlier with $p_\\ell$ is impossible.**\nThe premise \"Increasing page size always delays the onset of thrashing\" is a flawed generalization. While fewer pages may be used, larger pages can significantly increase total memory demand due to internal fragmentation, as demonstrated in this problem. The total demand increases from $360\\,\\mathrm{MiB}$ to $480\\,\\mathrm{MiB}$. The conclusion that thrashing with $p_\\ell$ is \"impossible\" is directly contradicted by our derivation.\n**Verdict: Incorrect**\n\n**E. For the given parameters, the total working set in bytes under $p_s$ is $360\\,\\mathrm{MiB}$, whereas under $p_\\ell$ it is $480\\,\\mathrm{MiB}$; hence only $p_\\ell$ crosses the thrashing threshold $B = 400\\,\\mathrm{MiB}$.**\n- **Working set with $p_s$:** Calculated as $\\sum M_i = 360\\,\\mathrm{MiB}$. This is correct.\n- **Working set with $p_\\ell$:** Calculated as $(\\sum k_i) \\cdot p_\\ell = 240 \\cdot 2\\,\\mathrm{MiB} = 480\\,\\mathrm{MiB}$. This is correct.\n- **Conclusion on thrashing:** $360\\,\\mathrm{MiB} < 400\\,\\mathrm{MiB}$ (no thrash with $p_s$). $480\\,\\mathrm{MiB} > 400\\,\\mathrm{MiB}$ (thrash with $p_\\ell$). The conclusion is correct.\nThe statement provides the correct numerical results and draws the correct conclusion from them.\n**Verdict: Correct**",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}