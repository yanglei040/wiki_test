{
    "hands_on_practices": [
        {
            "introduction": "Understanding Page-Fault Frequency (PFF) begins with seeing how it is influenced by the operating system's core memory management policies. This exercise explores a classic scenario where the memory access pattern of a process interacts poorly with certain page replacement algorithms, leading to a severe performance degradation known as thrashing. By comparing the behavior of LRU, CLOCK, and Random Replacement policies under this stressful workload, you can gain a fundamental intuition for why policy choice is critical for system stability and efficiency .",
            "id": "3667744",
            "problem": "A single process repeatedly accesses a loop of $K$ distinct virtual pages in a fixed cyclic order, one reference per page per cycle, with uniform revisit frequency among the $K$ pages. The process is allocated $f$ physical page frames, with $f < K$. There is no prefetching, and the initial contents of memory are empty; consider the long-run steady state after any transient warm-up has passed. The operating system may use one of three page-replacement policies: Least Recently Used (LRU), the Clock page replacement algorithm (CLOCK), or Random Replacement (RR). Define Page-Fault Frequency (PFF) as the long-run average number of page faults per memory reference: $PFF = \\lim_{N \\to \\infty} \\frac{F(N)}{N}$, where $F(N)$ counts page faults in the first $N$ references.\n\nFrom the basic definitions of these replacement policies and the described workload, reason about the steady-state $PFF$ under each policy when $f < K$. Then, for the specific case $K = 10$ and $f = 4$, select the option that best predicts the steady-state $PFF$ ordering across policies and provides a correct numerical prediction for RR.\n\nA. Under LRU and CLOCK, $PFF$ approaches $1$ per reference in steady state; under RR, $PFF$ is strictly less than $1$ and is approximately $0.90$ when $K = 10$ and $f = 4$.\n\nB. Under LRU and CLOCK, $PFF$ approaches $1$ per reference in steady state; under RR, $PFF$ is approximately $1 - \\frac{f}{K} = 0.60$ when $K = 10$ and $f = 4$.\n\nC. Under LRU, CLOCK, and RR, $PFF$ approaches $1$ per reference whenever $f < K$.\n\nD. Under LRU, $PFF$ is strictly less than under CLOCK, and both are strictly less than under RR, because LRU exploits recency to avoid thrashing when $f < K$.",
            "solution": "### Analysis of Page-Fault Frequency (PFF)\n\nLet the sequence of page references be $P_1, P_2, \\dots, P_K, P_1, P_2, \\dots$. We are given $f < K$ frames.\n\n**Least Recently Used (LRU) Policy:**\nThe LRU policy replaces the page that has not been used for the longest amount of time.\n1.  Initially, the first $f$ references ($P_1, \\dots, P_f$) will each cause a page fault, filling the $f$ frames. The memory will contain $\\{P_1, P_2, \\dots, P_f\\}$.\n2.  The next reference is to page $P_{f+1}$. Since $f < K$, this page is not in memory, causing a fault. The least recently used page is $P_1$ (referenced $f$ steps ago). LRU evicts $P_1$ and loads $P_{f+1}$. Memory now contains $\\{P_2, P_3, \\dots, P_{f+1}\\}$.\n3.  The next reference is to $P_{f+2}$. This is also a fault. The least recently used page is now $P_2$. LRU evicts $P_2$ and loads $P_{f+2}$. Memory becomes $\\{P_3, P_4, \\dots, P_{f+2}\\}$.\nThis pattern continues. For any reference to page $P_i$, the $f$ pages currently resident in memory are precisely $\\{P_{i-f}, \\dots, P_{i-1}\\}$ (indices are interpreted cyclically). Since $f \\ge 1$, the page $P_i$ is never in this set.\nTherefore, in the steady state, every single memory reference results in a page fault. This is a classic thrashing scenario for LRU.\nThe number of faults $F(N)$ for $N$ references will be $N$ (after the initial warm-up).\n$$PFF_{LRU} = \\lim_{N \\to \\infty} \\frac{N}{N} = 1$$\n\n**Clock (CLOCK) Policy:**\nThe CLOCK algorithm is an approximation of LRU. It maintains a circular list of pages in memory and a pointer (the \"clock hand\"). Each page has a reference bit, initially set to $1$. On a fault, the algorithm scans from the clock hand, looking for a page with a reference bit of $0$. If it encounters a bit of $1$, it clears it to $0$ and advances the hand.\nIn this specific cyclic workload, the behavior of CLOCK mimics LRU's worst-case performance.\n1.  Assume the $f$ frames are full with pages $\\{P_1, \\dots, P_f\\}$, all with reference bits set to $1$.\n2.  A reference to $P_{f+1}$ causes a fault. The clock hand begins to scan. It finds $P_1$ (or whichever page is at the hand's starting position), sees its reference bit is $1$, clears it to $0$, and advances. It will do this for all $f$ pages in memory, $\\{P_1, \\dots, P_f\\}$, as they have all been referenced recently.\n3.  After one full circle, the hand returns to its starting page (e.g., $P_1$), which now has a reference bit of $0$. This page is chosen for replacement. $P_1$ is evicted, and $P_{f+1}$ is loaded with its reference bit set to $1$.\nThe state of memory remains the set of the $f$ most recently used pages. The next page in the cyclic sequence is never present. Consequently, just like LRU, every reference results in a page fault.\n$$PFF_{CLOCK} = 1$$\n\n**Random Replacement (RR) Policy:**\nWhen a fault occurs, a resident page is chosen uniformly at random for eviction. Unlike LRU and CLOCK, this random choice prevents a persistent, pathological synchronization with the cyclic access pattern.\nA page fault occurs if the requested page is not in memory. The PFF is the steady-state probability of this event.\nFor a cyclic workload, the most accurate model for PFF involves survival analysis. Let $p_{hit}$ be the steady-state probability of a hit, so $PFF = 1 - p_{hit}$.\nA reference to a page, say $P_i$, will be a hit only if $P_i$ has remained in memory since its last reference. The last reference to $P_i$ occurred $K$ steps prior. So, for a hit to occur on the current reference to $P_i$, it must have survived the $K-1$ intervening memory references.\nLet's find the probability that a specific page in memory survives a single memory reference step. A page is evicted only if a fault occurs and that specific page is chosen for replacement.\nThe probability of a fault at any step is $PFF$. If a fault occurs, one of the $f$ pages in memory is chosen for eviction. The probability of any single page being chosen is $1/f$. So, the probability that a given page is evicted at any step is $P(\\text{eviction}) = PFF \\times \\frac{1}{f}$.\nThe probability that the page *survives* one step is $1 - P(\\text{eviction}) = 1 - \\frac{PFF}{f}$.\nFor a hit on page $P_i$, it must survive $K-1$ steps. The probability of this is:\n$$p_{hit} = \\left(1 - \\frac{PFF}{f}\\right)^{K-1}$$\nSubstituting $p_{hit} = 1 - PFF$, we get a recursive equation for $PFF$:\n$$1 - PFF = \\left(1 - \\frac{PFF}{f}\\right)^{K-1}$$\nFor the specific case $K = 10$ and $f = 4$:\n$$1 - PFF = \\left(1 - \\frac{PFF}{4}\\right)^{9}$$\nWe can solve this numerically or test the values provided in the options.\nLet's test $PFF \\approx 0.90$, as suggested by option A.\n*   Left-hand side (LHS): $1 - 0.90 = 0.10$.\n*   Right-hand side (RHS): $\\left(1 - \\frac{0.90}{4}\\right)^{9} = (1 - 0.225)^{9} = (0.775)^{9}$.\nCalculating $(0.775)^9$:\n$(0.775)^2 \\approx 0.6006$\n$(0.775)^4 \\approx (0.6006)^2 \\approx 0.3607$\n$(0.775)^8 \\approx (0.3607)^2 \\approx 0.1301$\n$(0.775)^9 = (0.775)^8 \\times 0.775 \\approx 0.1301 \\times 0.775 \\approx 0.1008$\nThe LHS ($0.10$) is approximately equal to the RHS ($0.1008$). Thus, $PFF_{RR} \\approx 0.90$ is the correct prediction from this more accurate model.\nSince $0.90 < 1$, the PFF for RR is strictly less than for LRU and CLOCK.\n\nAn alternative, simpler model assumes the next page referenced is chosen uniformly at random from the $K$ pages. The probability that this page is in memory is $f/K$. This gives $PFF = 1 - f/K = 1 - 4/10 = 0.6$. However, this model ignores the \"fixed cyclic order\" and is less accurate for this specific workload than the survival analysis model.\n\n### Evaluation of Options\n\n**A. Under LRU and CLOCK, $PFF$ approaches $1$ per reference in steady state; under RR, $PFF$ is strictly less than $1$ and is approximately $0.90$ when $K = 10$ and $f = 4$.**\n*   The statement that $PFF$ approaches $1$ for LRU and CLOCK is consistent with our analysis.\n*   The statement that $PFF$ for RR is strictly less than $1$ is also correct.\n*   The prediction that $PFF_{RR} \\approx 0.90$ for $K=10, f=4$ matches the result from the more accurate survival analysis model, which is the best prediction for the given cyclic workload.\n*   Verdict: **Correct**.\n\n**B. Under LRU and CLOCK, $PFF$ approaches $1$ per reference in steady state; under RR, $PFF$ is approximately $1 - \\frac{f}{K} = 0.60$ when $K = 10$ and $f = 4$.**\n*   The first part of the statement is correct.\n*   The numerical prediction for RR, $0.60$, is derived from a simplified model that assumes uniform random access, not a fixed cyclic order. The survival model, which yields $\\approx 0.90$, provides a better prediction for the specified workload. Therefore, this option is not the best prediction.\n*   Verdict: **Incorrect**.\n\n**C. Under LRU, CLOCK, and RR, $PFF$ approaches $1$ per reference whenever $f < K$.**\n*   This is false. Our analysis shows that for Random Replacement (RR), the PFF is strictly less than $1$. There is always a non-zero probability of a hit because the random eviction choice does not pathologically synchronize with the cyclic reference pattern.\n*   Verdict: **Incorrect**.\n\n**D. Under LRU, $PFF$ is strictly less than under CLOCK, and both are strictly less than under RR, because LRU exploits recency to avoid thrashing when $f < K$.**\n*   The PFF ordering is claimed as $PFF_{LRU} < PFF_{CLOCK} < PFF_{RR}$. Our analysis gives $PFF_{LRU} = PFF_{CLOCK} = 1$ and $PFF_{RR} \\approx 0.90$. The correct ordering is $PFF_{RR} < PFF_{LRU} = PFF_{CLOCK}$. The claimed ordering is false.\n*   The reasoning provided is also false. For this cyclic workload with $f < K$, LRU's exploitation of recency leads directly to the worst-case thrashing scenario ($PFF=1$), it does not avoid it.\n*   Verdict: **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Beyond abstract policies, PFF is a practical metric for analyzing the performance of real-world algorithms. This practice bridges the gap between algorithm design and operating systems by examining the memory behavior of Quicksort, a fundamental sorting algorithm . By modeling the memory references during its partition phase, you will learn to estimate a process's working set size and predict its PFF, demonstrating how an algorithm's structure directly impacts its memory footprint and performance.",
            "id": "3667713",
            "problem": "A single-threaded in-place Quicksort partitions an array of size $N$ elements stored in contiguous virtual memory. The system uses demand paging with fixed page size $p$ bytes and Least Recently Used (LRU) page replacement. Each array element has size $b$ bytes. Each recursive call of Quicksort allocates a stack frame of size $s$ bytes, and at its maximum recursion depth the algorithm reaches depth $d$. During a partition of a large subarray, assume the access pattern is a sequential forward scan of that subarray. Assume further that, during partition, each element induces on average $\\gamma$ memory references that target data on its own page (reads and writes combined), and that pivot selection and index variables are contained within the resident stack pages. At the beginning of a partition on a large subarray, none of the subarray’s data pages are resident. The process has $F$ frames allocated and its resident stack pages occupy frames throughout the partition. You may assume $F \\ge \\left\\lceil \\frac{d s}{p} \\right\\rceil + 1$, so that at least $1$ frame is always available for data pages during the scan.\n\nUsing only the core definition of working set and the definition of page-fault frequency, do the following:\n\n- Estimate the peak working set size during the partition at recursion depth $d$ as a function of $d$, $s$, and $p$.\n- Then, under the stated conditions, derive a closed-form analytic expression for the expected page-fault frequency (page faults per memory reference) during the partition scan of a large subarray in terms of $b$, $\\gamma$, and $p$.\n\nProvide only the final expression for the expected page-fault frequency. No units are required. Do not round.",
            "solution": "The problem requires two distinct derivations. First, an estimation of the peak working set size, and second, an expression for the page-fault frequency. The final answer requires only the latter.\n\nPart 1: Peak Working Set Size Estimation\n\nThe working set of a process, in this context, refers to the set of pages it requires to be resident in memory for efficient execution without thrashing. The peak working set size corresponds to the maximum number of pages needed simultaneously during the specified phase of execution. At recursion depth `$d$`, the process utilizes memory for its execution stack and for the array data it is partitioning.\n\n1.  Stack Pages: The Quicksort algorithm is at a recursion depth of `$d$`. Each recursive call allocates a stack frame of size `$s$` bytes. Therefore, the total memory consumed by the stack is `$d \\times s$` bytes. Given a page size of `$p$` bytes, the number of pages required to store the entire call stack at this depth is given by the ceiling of the total stack size divided by the page size. Let `$WSS_{stack}$` be the working set size for the stack.\n    $$WSS_{stack} = \\left\\lceil \\frac{d s}{p} \\right\\rceil$$\n    The problem states that these pages are resident, so they are part of the working set.\n\n2.  Data Pages: The partition step involves a sequential scan of a subarray. For a simple sequential scan, the principle of locality implies that references are concentrated on a small number of pages at any given time. As the scan progresses from one element to the next, it moves linearly through memory. At any point, the algorithm is actively reading or writing elements that reside on a single page. When the scan crosses a page boundary, a new page becomes active. Given the Least Recently Used (LRU) page replacement policy and the sequential, non-repeating nature of the scan, the minimum number of data pages required in memory to make progress is just `$1$` for the currently accessed page. The assumption that `$F \\ge \\left\\lceil \\frac{d s}{p} \\right\\rceil + 1$` explicitly guarantees that at least one frame is available for data pages, preventing the stack from evicting the active data page. Thus, the working set size for the data portion, `$WSS_{data}$`, can be estimated as `$1$` page.\n\n3.  Total Peak Working Set Size: The total peak working set, `$W$`, is the sum of the pages required for the stack and the data.\n    $$W(d, s, p) = WSS_{stack} + WSS_{data} = \\left\\lceil \\frac{d s}{p} \\right\\rceil + 1$$\n    This expression represents the estimated peak working set size in pages during the partition at recursion depth `$d$`.\n\nPart 2: Page-Fault Frequency Derivation\n\nPage-fault frequency (PFF) is defined as the number of page faults per memory reference.\n$$PFF = \\frac{\\text{Total Number of Page Faults}}{\\text{Total Number of Memory References}}$$\nWe can calculate this frequency by analyzing the events over a representative interval. During the partition's sequential scan of a large subarray, the most convenient interval is the processing of all elements contained within a single page of data.\n\n1.  Number of Elements per Page: A page has a size of `$p$` bytes. Each array element has a size of `$b$` bytes. Assuming elements are packed contiguously, the number of elements per page, `$E_{page}$`, is:\n    $$E_{page} = \\frac{p}{b}$$\n\n2.  Total Memory References per Page: The problem states that each element induces, on average, `$\\gamma$` memory references to data on its own page. References to pivot and index variables are handled by the stack pages, which are already resident and thus do not contribute to data page faults. Therefore, the total number of memory references, `$R_{page}$`, generated while processing the elements on a single page is:\n    $$R_{page} = E_{page} \\times \\gamma = \\frac{p}{b} \\gamma$$\n\n3.  Page Faults per Page: The problem specifies that at the beginning of the partition scan, none of the subarray's data pages are resident in memory. The scan accesses pages sequentially. Due to the demand paging mechanism, the first attempt to access any data on a new, non-resident page will trigger a page fault. Once the page is loaded into a frame, subsequent accesses to that same page (of which there are `$R_{page}$` in total) will not cause a fault, as the page is now resident. Since the scan is sequential and the replacement policy is LRU, and we have enough frames, a page will not be evicted before the scan is finished with it. Thus, for each new data page encountered during the scan, exactly one page fault will occur. Let `$F_{page}$` be the number of faults associated with processing one page.\n    $$F_{page} = 1$$\n\n4.  Calculation of PFF: We can now compute the PFF as the ratio of faults per page to references per page. This ratio represents the average fault rate during the steady-state sequential scan.\n    $$PFF = \\frac{F_{page}}{R_{page}} = \\frac{1}{\\frac{p \\gamma}{b}}$$\n    Simplifying this expression yields the closed-form analytic expression for the expected page-fault frequency.\n    $$PFF = \\frac{b}{p \\gamma}$$\n    This expression depends only on the element size `$b$`, the page size `$p$`, and the reference density `$\\gamma$`, as requested.",
            "answer": "$$\\boxed{\\frac{b}{p\\gamma}}$$"
        },
        {
            "introduction": "Effective memory management is not just about choosing the right replacement policy; it's also about optimally distributing limited resources. This exercise delves into the problem of resource allocation, where a fixed number of memory frames must be divided between different regions of a process, such as the stack and the heap . You will use a mathematical model of memory locality to determine the allocation that minimizes the total PFF, illustrating the principle of marginal gains, a key concept in system optimization.",
            "id": "3667671",
            "problem": "A single process divides its memory accesses between a call-stack region and a heap region. Let the fraction of all references that go to the stack be $r_{s}$ and to the heap be $r_{h}=1-r_{s}$. Page-Fault Frequency (PFF) is defined as the number of page-faults per memory reference, measured over a sufficiently long observation window so that ergodic averages coincide with expected values. Assume that each region’s per-reference miss probability under the Least Recently Used (LRU) policy can be empirically modeled as a strictly decreasing, convex function of the number of page frames allocated to that region. Specifically, for the stack and heap, the miss probabilities are\n$$m_{s}(f_{s})=\\exp(-a_{s} f_{s}), \\quad m_{h}(f_{h})=\\exp(-a_{h} f_{h}),$$\nwhere $f_{s}$ and $f_{h}$ are the frames allocated to the stack and heap, respectively, and $a_{s}>0$, $a_{h}>0$ are region-specific parameters capturing locality strength. The process is subject to a fixed total frame budget $F$, so that $f_{s}+f_{h}=F$ with $f_{s}\\ge 0$ and $f_{h}\\ge 0$.\n\nYou are given $r_{s}=0.4$, hence $r_{h}=0.6$, as well as $a_{s}=0.35$, $a_{h}=0.15$, and a total frame budget $F=30$.\n\nTasks:\n- Using only the definition of Page-Fault Frequency (PFF) as expected faults per reference and the given miss-probability models, derive symbolic expressions for $PFF_{stack}(f_{s})$, $PFF_{heap}(f_{h})$, and the total PFF as a function of $f_{s}$ only, given the constraint $f_{h}=F-f_{s}$.\n- From first principles, explain how a policy that “prioritizes the region with higher PFF” translates into a per-frame allocation decision rule in terms of the marginal reduction in total PFF when one more frame is assigned to either region.\n- Compute the value of the stack allocation $f_{s}^{\\star}$ that minimizes the total PFF subject to $f_{s}+f_{h}=F$, using the given numerical parameters. Round your answer to three significant figures and express it in frames.",
            "solution": "The solution proceeds by addressing the three tasks outlined in the problem statement.\n\nFirst, we derive the symbolic expressions for the Page-Fault Frequency (PFF) components. PFF is defined as the expected number of page faults per memory reference. The total PFF is the sum of contributions from the stack and heap regions.\n\nThe contribution of the stack to the total PFF, denoted $PFF_{stack}$, is the probability that a randomly chosen memory reference is to the stack AND it causes a page fault. This is the product of the fraction of references to the stack, $r_{s}$, and the miss probability for the stack, $m_{s}(f_{s})$.\n$$PFF_{stack}(f_{s}) = r_{s} m_{s}(f_{s}) = r_{s} \\exp(-a_{s} f_{s})$$\nSimilarly, the contribution of the heap to the total PFF, denoted $PFF_{heap}$, is the product of the fraction of references to the heap, $r_{h}$, and the miss probability for the heap, $m_{h}(f_{h})$.\n$$PFF_{heap}(f_{h}) = r_{h} m_{h}(f_{h}) = r_{h} \\exp(-a_{h} f_{h})$$\nThe total PFF for the process is the sum of these two contributions:\n$$PFF(f_{s}, f_{h}) = PFF_{stack}(f_{s}) + PFF_{heap}(f_{h}) = r_{s} \\exp(-a_{s} f_{s}) + r_{h} \\exp(-a_{h} f_{h})$$\nUsing the constraint that the total number of frames is fixed at $F$, we have $f_{s} + f_{h} = F$, which implies $f_{h} = F - f_{s}$. Substituting this into the expression for the total PFF yields the total PFF as a function of $f_{s}$ only:\n$$PFF(f_{s}) = r_{s} \\exp(-a_{s} f_{s}) + r_{h} \\exp(-a_{h} (F - f_{s}))$$\n\nSecond, we explain the allocation decision rule. A naive policy that \"prioritizes the region with higher PFF\" would mean allocating a frame to the stack if $PFF_{stack}(f_s) > PFF_{heap}(f_h)$, and to the heap otherwise. However, this policy is not optimal. The optimal resource allocation policy aims to achieve the greatest possible improvement (i.e., reduction) in the overall objective function, which is the total PFF.\n\nThe correct decision rule is based on the marginal reduction in total PFF obtained by allocating one additional frame to a region. For a continuous approximation of frame allocation, this is captured by the partial derivative of the total PFF with respect to the number of frames allocated to each region. The marginal reduction in total PFF from adding a frame to the stack is $-\\frac{\\partial PFF}{\\partial f_{s}}$, and for the heap it is $-\\frac{\\partial PFF}{\\partial f_{h}}$.\n\nLet's compute these marginal reductions from their respective contributions to the total PFF:\nThe marginal reduction for the stack is:\n$$R_{s}(f_{s}) = -\\frac{d}{d f_{s}} (PFF_{stack}(f_{s})) = -\\frac{d}{d f_{s}} [r_{s} \\exp(-a_{s} f_{s})] = a_{s} r_{s} \\exp(-a_{s} f_{s})$$\nThe marginal reduction for the heap is:\n$$R_{h}(f_{h}) = -\\frac{d}{d f_{h}} (PFF_{heap}(f_{h})) = -\\frac{d}{d f_{h}} [r_{h} \\exp(-a_{h} f_{h})] = a_{h} r_{h} \\exp(-a_{h} f_{h})$$\nThe decision rule is to allocate the next frame to the region with the higher marginal reduction. The optimal static allocation is achieved when the marginal reductions are equalized: $R_{s}(f_{s}^{\\star}) = R_{h}(f_{h}^{\\star})$. This condition ensures that no frame could be reallocated from one region to another to achieve a greater reduction in total PFF.\n\nThird, we compute the optimal stack allocation $f_{s}^{\\star}$ that minimizes the total PFF. To find the minimum of $PFF(f_s)$, we set its first derivative with respect to $f_s$ to zero.\n$$PFF(f_{s}) = r_{s} \\exp(-a_{s} f_{s}) + r_{h} \\exp(-a_{h} (F - f_{s}))$$\n$$\\frac{d PFF(f_{s})}{d f_{s}} = -a_{s} r_{s} \\exp(-a_{s} f_{s}) + a_{h} r_{h} \\exp(-a_{h} (F - f_{s}))$$\nSetting the derivative to zero:\n$$-a_{s} r_{s} \\exp(-a_{s} f_{s}^{\\star}) + a_{h} r_{h} \\exp(-a_{h} (F - f_{s}^{\\star})) = 0$$\n$$a_{s} r_{s} \\exp(-a_{s} f_{s}^{\\star}) = a_{h} r_{h} \\exp(-a_{h} (F - f_{s}^{\\star}))$$\nThis equation is identical to the equilibrium condition where the marginal reductions are equal. To solve for $f_{s}^{\\star}$, we take the natural logarithm of both sides:\n$$\\ln(a_{s} r_{s}) - a_{s} f_{s}^{\\star} = \\ln(a_{h} r_{h}) - a_{h} (F - f_{s}^{\\star})$$\n$$\\ln(a_{s} r_{s}) - a_{s} f_{s}^{\\star} = \\ln(a_{h} r_{h}) - a_{h} F + a_{h} f_{s}^{\\star}$$\nRearranging the terms to isolate $f_{s}^{\\star}$:\n$$a_{h} F + \\ln(a_{s} r_{s}) - \\ln(a_{h} r_{h}) = (a_{s} + a_{h}) f_{s}^{\\star}$$\n$$f_{s}^{\\star} = \\frac{a_{h} F + \\ln\\left(\\frac{a_{s} r_{s}}{a_{h} r_{h}}\\right)}{a_{s} + a_{h}}$$\nNow, we substitute the given numerical values: $r_{s}=0.4$, $r_{h}=0.6$, $a_{s}=0.35$, $a_{h}=0.15$, and $F=30$.\nThe denominator is $a_{s} + a_{h} = 0.35 + 0.15 = 0.5$.\nThe numerator terms are:\n$a_{h} F = 0.15 \\times 30 = 4.5$.\nThe argument of the logarithm is $\\frac{a_{s} r_{s}}{a_{h} r_{h}} = \\frac{0.35 \\times 0.4}{0.15 \\times 0.6} = \\frac{0.14}{0.09} = \\frac{14}{9}$.\nSo, $\\ln\\left(\\frac{14}{9}\\right) \\approx 0.44183$.\nSubstituting these values into the expression for $f_s^{\\star}$:\n$$f_{s}^{\\star} = \\frac{4.5 + \\ln\\left(\\frac{14}{9}\\right)}{0.5} \\approx \\frac{4.5 + 0.44183}{0.5} = \\frac{4.94183}{0.5} \\approx 9.88366$$\nThe second derivative of $PFF(f_s)$ is $a_{s}^2 r_{s} \\exp(-a_{s} f_{s}) + a_{h}^2 r_{h} \\exp(-a_{h} (F - f_{s}))$, which is strictly positive for all $f_s$, confirming that this critical point is a global minimum.\nRounding the result to three significant figures, we get $9.88$. This value is within the valid range $[0, 30]$.",
            "answer": "$$\\boxed{9.88}$$"
        }
    ]
}