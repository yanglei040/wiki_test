{
    "hands_on_practices": [
        {
            "introduction": "在构建可靠的应用程序时，确保数据在意外崩溃后仍保持一致性是一个核心挑战。一个看似简单的原子更新操作，由于操作系统和硬件层面的复杂缓冲和重排行为，可能会隐藏着微妙的失败模式。这个练习  将引导你分析一个直观但错误的更新协议，通过识别导致不一致状态的具体崩溃场景，你将深刻理解为何需要 `fsync` 这样的系统调用来强制实现持久化和顺序保证。",
            "id": "3631038",
            "problem": "您正在审查一个应用层更新协议，该协议旨在原子性地发布一个新的不可变数据对象和一个指明当前对象的小型清单文件。该系统运行在典型的可移植操作系统接口（POSIX）文件系统上。假设以下标准且经过充分测试的语义作为您的基础：一个 `write` 系统调用在数据进入页缓存时返回，并且这些数据稍后可以以任意顺序到达存储设备；一个 `rename` 系统调用相对于目录命名空间是原子性的，但若无进一步操作则不一定是持久的；对常规文件使用的文件同步系统调用（`fsync`）会将其文件内容和元数据刷写到稳定存储中；而对目录使用的 `fsync` 会刷写目录条目的变更，例如 `create`、`unlink` 和 `rename`。\n\n文件和不变量：\n- 该目录包含名为 \"obj.v_$k$\" 的不可变内容文件和一个名为 \"manifest\" 的清单文件。\n- 清单文件只包含一行内容：当前对象文件的基本名称，例如 \"obj.v_{17}\"。\n- 不变量：在任何崩溃和随后的重启之后，清单文件必须只包含同一目录中一个已存在的、已完全写入的对象文件的基本名称。\n\n有吸引力但错误的更新协议 $P$（全程无 `fsync` 调用）：\n- 步骤 $1$：创建新对象并将其写入临时文件 \"obj.tmp\"；关闭它。\n- 步骤 $2$：在同一目录中将 \"obj.tmp\" 重命名为最终名称 \"obj.v_{k+1}\"。\n- 步骤 $3$：创建 \"manifest.tmp\"，将 ASCII 名称 \"obj.v_{k+1}\" 写入其中；关闭它。\n- 步骤 $4$：在同一目录中将 \"manifest.tmp\" 重命名覆盖 \"manifest\"；返回成功。\n\n问题。哪个选项指出了一个在所述语义下违反不变量的具体崩溃交错情况，并给出了一个正确的、最小化的 `fsync` 调用布局来修复协议 $P$，从而在任何崩溃情况下都能保持不变量？在此，“最小化”意味着使用最少数量的必要 `fsync` 调用来防止不变量被违反，而不引入单独的预写日志或更改文件布局。\n\n选择一个：\n\nA. 没有崩溃交错可以违反不变量，因为 `rename` 是原子性的；因此协议 $P$ 已经是正确的。不需要 `fsync` 调用。\n\nB. 崩溃交错：系统在步骤 $4$ 后立即崩溃；存储持久化了 \"manifest.tmp\" 到 \"manifest\" 的重命名，但没有持久化 \"obj.tmp\" 到 \"obj.v_{k+1}\" 的重命名。恢复时，\"manifest\" 指向 \"obj.v_{k+1}\"，但该文件不存在。修复：在步骤 $4$ 之后对 \"manifest\" 添加一个 `fsync` 调用；不需要其他 `fsync`。\n\nC. 崩溃交错：系统在步骤 $4$ 后立即崩溃；由于乱序持久化，步骤 $4$ 中的重命名到达了存储设备，但步骤 $2$ 中的重命名没有。恢复时，\"manifest\" 指向 \"obj.v_{k+1}\"，但该文件缺失。修复（最小化）：在步骤 $2$ 之前对新对象的文件描述符执行 `fsync`，使其内容持久化，然后执行步骤 $2$ 并对包含目录执行 `fsync`，使 \"obj.v_{k+1}\" 的目录条目持久化。接下来，执行步骤 $3$ 并对 \"manifest.tmp\" 文件执行 `fsync`，在发布它之前使其内容持久化。最后，执行步骤 $4$。在步骤 $4$ 之后对目录进行最终的 `fsync` 对于返回值的持久性是可选的，但对于保持不变量不是必需的。\n\nD. 崩溃交错：系统在步骤 $1$ 和 $2$ 之间崩溃。恢复时，不变量被违反，因为 \"manifest\" 可能命名为 \"obj.v_{k+1}\"，而新对象不存在。修复：在步骤 $1$ 之后对 \"obj.tmp\" 插入一个 `fsync`。\n\nE. 崩溃交错：系统在步骤 $4$ 后立即崩溃，尽管两次重命名都已持久化，但 \"manifest\" 的内容是空的，因为对 \"manifest.tmp\" 的写入没有被持久化。修复：使用同步写入标志打开 \"obj.tmp\" 和 \"manifest.tmp\"，并省略所有 `fsync` 调用；仅同步写入就足够了。",
            "solution": "我们从所述的基础语义开始。一个 `write` 系统调用仅保证数据到达页缓存；操作系统可能会在稍后将脏页推送到存储设备，并可能对不同文件的写入进行重排序。一个 `rename` 系统调用相对于目录命名空间是原子性的，即读取者永远不会观察到部分更新的目录条目；但是，除非使用 `fsync` 同步包含目录，否则 `rename` 不保证新目录条目的持久性。对常规文件使用的文件同步系统调用（`fsync`）会刷写文件的内容和元数据到存储设备。为了使 `create`、`unlink` 和 `rename` 等目录条目持久化，必须对包含这些条目的目录执行 `fsync`。最后，为了防止暴露一个内容尚未持久化的文件，必须在命名空间中发布对该文件的引用之前，确保其内容已持久化。\n\n不变量要求在任何崩溃后，清单文件必须只包含一个已存在的、已完全写入的对象文件的基本名称。一个自然的失败模式是寻找发布顺序异常：一个引用（清单文件）在被引用的对象（新对象文件）持久存在之前就变得持久化，或者清单文件本身的内容在 `rename` 使其可见时还不是持久的。\n\n逐项分析：\n\n- 选项 A：该选项声称协议 $P$ 是安全的，因为 `rename` 是原子性的。这混淆了原子性与持久性。协议 $P$ 在步骤 $2$ 和 $4$ 中对两个不同的文件执行了两次重命名，没有任何顺序或持久性保证。由于乱序持久化，从 \"manifest.tmp\" 到 \"manifest\" 的重命名可能已经到达设备，而从 \"obj.tmp\" 到 \"obj.v_{k+1}\" 的重命名却没有，导致崩溃后清单文件指向一个不存在的对象。因此，声称没有崩溃可以违反不变量是错误的。结论 — 不正确。\n\n- 选项 B：这种交错是可能的：清单文件的重命名可以持久化，而对象文件的重命名却没有，这导致 \"manifest\" 指向一个缺失的 \"obj.v_{k+1}\"。然而，建议的修复方案是在步骤 $4$ 之后仅对 \"manifest\" 添加一个 `fsync` 调用。这没有解决核心风险。对 \"manifest\" 执行 `fsync` 会刷写清单文件的内容及其元数据；除非包含它的目录被 `fsync`，否则它不会使目录条目的变更持久化。更重要的是，它完全不能确保在清单文件指向 \"obj.v_{k+1}\" 时，该文件已经存在或是持久的；清单文件仍然可能在 \"obj.v_{k+1}\" 目录条目存在于磁盘上之前就变得持久化。因此，不变量仍然可能被违反。结论 — 不正确。\n\n- 选项 C：所描述的交错情况符合现实中的风险：步骤 $4$ 持久化了，而步骤 $2$ 没有。建议的修复方案在最小发布边界处使用了三个 `fsync` 调用：\n  - 在步骤 $2$ 中通过 `rename` 发布新对象文件之前，对其进行 `fsync`。这确保了对象的数据和元数据是持久的。\n  - 步骤 $2$ 之后，对包含目录进行 `fsync`，以使 \"obj.v_{k+1}\" 目录条目持久化。现在，即使清单文件稍后变得可见，它也将引用一个持久存在的对象。\n  - 在步骤 $4$ 中通过 `rename` 发布新清单文件之前，对 \"manifest.tmp\" 文件进行 `fsync`，以确保清单文件的内容（路径名 \"obj.v_{k+1}\"）在暴露之前是持久的。这可以防止在重命名到达设备后，崩溃导致留下一个零长度或损坏的新清单文件。\n  - 在步骤 $4$ 之后对目录进行最终的 `fsync` 对于保持不变量不是必需的：如果它没有发生并且发生了崩溃，系统要么将保留旧的清单文件（安全），要么可能已经持久化了新的清单文件，而该清单文件的内容通过构造已是持久的，并且指向一个持久存在的对象（也安全）。只有当应用程序需要保证更新在返回成功的那一刻是持久的时候，才需要最终的目录 `fsync`。\n  这个布局对于不变量来说是最小的：省略其中任何一个 `fsync` 调用都可能重新引入一个时间窗口，在这个窗口中，一个持久的清单文件可能指向一个非持久或缺失的对象，或者一个持久的重命名可能暴露一个内容非持久的清单文件。结论 — 正确。\n\n- 选项 D：该交错假设在步骤 $1$ 和 $2$ 之间发生崩溃，并声称不变量被违反。在步骤 $1$ 和 $2$ 之间，没有任何内容被发布：旧的清单文件仍然指向 \"obj.v_$k$\"，而新对象仅存在于 \"obj.tmp\" 中。此时发生崩溃会使旧状态保持不变。因此，这里不会出现不变量违反。此外，建议的修复方案（在步骤 $1$ 之后 `fsync` \"obj.tmp\"）在那个时间点对于正确性是不必要的，因为临时文件还不能通过命名空间访问到；它既没有解决正确性上的缺陷，也没有处理发布边界问题。结论 — 不正确。\n\n- 选项 E：该交错指出了一个关于清单文件内容的真实风险：如果对 \"manifest.tmp\" 的写入不是持久的，`rename` 可能会暴露一个内容为空或陈旧的清单文件。然而，建议的修复方案（使用同步写入标志打开文件并省略 `fsync`）是不充分的。对常规文件的同步写入不会使目录条目的变更持久化；因此，目录重命名仍然可能丢失，从而产生一个指向缺失对象或尚未持久存在的对象的清单文件。此外，除非仔细控制顺序并同步目录，否则仅依赖同步写入并不能确保对象的内容在通过 `rename` 发布之前是持久的。因此，这个修复方案不能在所有崩溃交错情况下满足不变量。结论 — 不正确。\n\n因此，只有选项 C 既指出了一个具体的违规交错情况，又提供了一个正确的、最小化的 `fsync` 布局，用以修复协议 $P$ 以满足所述的不变量。",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "为了解决应用层面的难题，文件系统通常采用日志（Journaling）技术来提供崩溃一致性。然而，这种保障并非没有代价。此练习  将带你量化日志记录的一个关键开销——写放大（Write Amplification）。通过推导和比较两种常见的日志策略（仅元数据日志和全数据日志）的写放大公式，你将掌握分析存储系统性能权衡的基本方法。",
            "id": "3631096",
            "problem": "一个存储栈使用日志文件系统来提供崩溃一致性。日志以大小为 $j$ 的固定大小块写入，而应用程序写入的数据块大小为 $b$。考虑一个随机写入工作负载，其中每个逻辑写入恰好更新一个大小为 $b$ 的数据块，并且由于随机性，无法与其他写入合并到共享的日志事务中。因此，每个逻辑写入都构成其自己的日志事务。系统使用以下两种策略之一：\n- 仅元数据日志（Metadata-only journaling）：在变更被视为已提交之前，仅将描述变更的元数据写入日志；数据块直接写入其原始位置。\n- 完整数据日志（Full data journaling）：在提交之前，数据和元数据都写入日志；随后，数据被传播到其原始位置。\n\n假设关于日志记录存在以下广为接受的事实：\n1. 在这两种策略中，每个事务都会写入一条元数据日志记录，占用一个大小为 $j$ 的日志块，以及一条提交记录，也占用一个大小为 $j$ 的日志块。\n2. 在完整数据日志策略中，大小为 $b$ 的数据负载首先被写入日志，占用 $\\lceil b / j \\rceil$ 个日志块，之后再被写入其原始位置一次。\n3. 在仅元数据日志策略中，大小为 $b$ 的数据负载直接写入其原始位置一次，而不会写入日志。\n4. 写放大（Write amplification）定义为每次逻辑写入中写入存储设备的总字节数与该逻辑写入的应用负载字节数之比。\n\n仅使用这些事实和定义，推导出在仅元数据日志策略下的写放大 $W_{\\text{meta}}(b,j)$ 和在完整数据日志策略下的写放大 $W_{\\text{full}}(b,j)$ 的精确、封闭形式表达式，用 $b$ 和 $j$ 表示。将每种策略的最终答案表示为纯数字（无量纲）。如果您的表达式需要舍入操作，请使用向上取整函数 $\\lceil \\cdot \\rceil$；不要进行近似或数值舍入。将这两个表达式作为一个单行矩阵提供，其中 $W_{\\text{meta}}(b,j)$ 在前，$W_{\\text{full}}(b,j)$ 在后。",
            "solution": "我们从写放大的定义开始。对于单个有效负载大小为 $b$ 的逻辑写入，写放大 $W$ 定义为写入设备的总字节数与应用程序写入的有效负载字节数之比：\n$$\nW \\equiv \\frac{\\text{每次逻辑写入的总设备写入字节数}}{\\text{每次逻辑写入的有效负载字节数}} = \\frac{\\text{设备字节数}}{b}。\n$$\n\n在给定的假设下，我们列举每种策略下写入设备的字节数。\n\n仅元数据日志：\n- 应用程序数据块被写入其原始位置一次，贡献了 $b$ 字节。\n- 日志接收一条元数据记录，占用一个大小为 $j$ 的日志块，贡献了 $j$ 字节。\n- 日志接收一条提交记录，占用一个大小为 $j$ 的日志块，又贡献了 $j$ 字节。\n将这些相加，在仅元数据日志策略下，每次逻辑写入的总设备字节数为\n$$\nb + j + j = b + 2j.\n$$\n因此，在仅元数据日志策略下的写放大为\n$$\nW_{\\text{meta}}(b,j) = \\frac{b + 2j}{b}.\n$$\n\n完整数据日志：\n- 大小为 $b$ 的数据负载首先被写入日志，该日志以大小为 $j$ 的块组织。向日志写入 $b$ 字节会消耗 $\\lceil b / j \\rceil$ 个日志块，总共为 $\\lceil b / j \\rceil \\cdot j$ 字节。\n- 日志接收一条元数据记录，占用一个大小为 $j$ 的日志块，贡献了 $j$ 字节。\n- 日志接收一条提交记录，占用一个大小为 $j$ 的日志块，又贡献了 $j$ 字节。\n- 提交后，数据被传播到其原始位置一次，贡献了 $b$ 字节。\n将这些相加，在完整数据日志策略下，每次逻辑写入的总设备字节数为\n$$\n\\left\\lceil \\frac{b}{j} \\right\\rceil \\cdot j + j + j + b = \\left\\lceil \\frac{b}{j} \\right\\rceil j + 2j + b.\n$$\n因此，在完整数据日志策略下的写放大为\n$$\nW_{\\text{full}}(b,j) = \\frac{\\left\\lceil \\frac{b}{j} \\right\\rceil j + 2j + b}{b}.\n$$\n\n这两个表达式都是无量纲的比率，与写放大的定义一致。没有进行数值舍入；向上取整函数 $\\lceil \\cdot \\rceil$ 精确地捕捉了将 $b$ 字节写入日志时日志块的粒度。",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{b+2j}{b}  \\frac{\\left\\lceil \\frac{b}{j} \\right\\rceil j + 2j + b}{b}\\end{pmatrix}}$$"
        },
        {
            "introduction": "在理论上理解了持久化的成本之后，下一步是学会在实践中准确地衡量它。天真的基准测试可能会产生极具误导性的高性能数据，因为它衡量的可能只是内存缓存的速度，而非真正的持久化吞吐量。本练习  要求你设计一个严谨的实验，以揭示确保数据持久性的真实性能影响，从而培养你对性能数据进行批判性思考的能力，并理解系统保证背后的实际代价。",
            "id": "3630999",
            "problem": "要求您评估常见的文件系统微基准测试在崩溃一致性方面是否可能具有欺骗性，并设计一个实验来揭示正确持久化实践的效果。您可以假定的关键基本原则是：(i) 可移植操作系统接口 (POSIX) 要求调用 `fsync` 只有在给定描述符的所有文件数据和元数据都已传输到稳定存储介质后才能返回，(ii) 现代操作系统在页缓存中缓冲写入，并在持久化之前确认应用程序的写入，(iii) 存储设备可能会在内部对写入进行重排序和缓存，除非显式的刷新或屏障指令得到遵守，以及 (iv) 崩溃一致性要求应用程序可见的状态必须有序且持久化，以便在断电或系统崩溃后，磁盘上的状态只反映已完成的操作并遵守必要的不变式。您必须选择一个选项，该选项既提出了一个科学合理的实验来隔离正确使用 `fsync` 对基准测试吞吐量的影响，又对剧烈的性能变化对于崩溃一致性意味着什么给出了正确的解释。\n\n哪个选项最能实现这一目标？\n\nA. 实现一个微基准测试，该测试将 $4\\,\\mathrm{KB}$ 的记录追加到单个文件中，并对每个逻辑操作执行：写入记录，对文件调用 `fsync`，然后在创建新文件或重命名文件时对包含该文件的目录调用 `fsync`，以确保元数据持久性。使用一个日志文件系统（如 ext4），启用写屏障，并使用一个其缓存遵守刷新指令的固态硬盘（SSD）。预热随机存取存储器（RAM）的页缓存并预分配文件，以避免分配开销。测量以下情况下的每秒操作数：（i）每条记录后调用 `fsync`（$N=1$），以及（ii）在两次 `fsync` 调用之间批处理 $N$ 条记录（针对几个不同的 $N$ 值）。预计在典型硬件上（例如，刷新延迟为 $1$–$5\\,\\mathrm{ms}$），当 $N=1$ 时，每秒操作数将从不调用 `fsync` 时的大约 $10^5$ 下降到大约 $10^2$–$10^3$，并且随着 $N$ 的增长，吞吐量会因分摊效应而增加。解释：性能的大幅下降表明，不使用 `fsync` 的基准测试衡量的是内存缓冲而非持久化进度；正确使用 `fsync` 暴露了使每个操作达到崩溃一致性的延迟成本，因此如果不使用 `fsync` 获得的高分在要求持久性的情况下是具有欺骗性的。\n\nB. 使用命令行工具，通过缓冲 I/O 将一个 $200\\,\\mathrm{GB}$ 的文件复制到同一分区上的一个新文件中，并仅在最后调用一次 `fsync`。比较有无最后一次 `fsync` 调用时每秒的兆字节数。如果数字相似，则得出结论：`fsync` 的成本很小，且崩溃一致性在实践中不是一个性能问题。\n\nC. 编写一个程序，将 $512\\,\\mathrm{B}$ 的记录追加到文件中，并在每条记录后调用 C 标准 I/O 函数 `fflush`。如果观察到的吞吐量相对于不调用 `fflush` 时有所下降，则得出结论：这反映了崩溃一致性的成本，并且调用 `fflush` 足以使每个操作在崩溃后保持持久性。\n\nD. 挂载文件系统时禁用写屏障，并使用带有易失性回写缓存的机械硬盘（HDD）。运行一个在每次追加 $8\\,\\mathrm{KB}$ 记录后调用 `fsync` 的基准测试，并观察到吞吐量仍然非常高，接近不使用 `fsync` 的情况。得出结论：现代文件系统使 `fsync` 没有成本，并且即使在普通硬盘上也可以实现崩溃一致性而没有可测量的性能成本。\n\n选择最佳选项。",
            "solution": "用户要求对一个关于文件系统崩溃一致性和基准测试设计的问题进行评估。\n\n**问题陈述验证**\n\n步骤 1：提取已知条件\n问题陈述提供了以下关键信息和原则：\n- **目标**：评估常见文件系统微基准测试在崩溃一致性方面的欺骗性，并设计一个实验来揭示正确持久化实践的效果。\n- **原则 (i)**：POSIX 标准要求 `fsync` 系统调用只有在给定文件描述符的所有文件数据和元数据都已传输到稳定存储介质后才能返回。\n- **原则 (ii)**：现代操作系统使用页缓存来缓冲写入，在数据持久化到存储设备之前确认应用程序的写入请求。\n- **原则 (iii)**：存储设备可能有自己的内部缓存，并且可能会对写入进行重排序，除非使用了显式的刷新命令或写屏障并得到遵守。\n- **原则 (iv)**：崩溃一致性要求崩溃后的磁盘状态只反映已完成的操作并维护系统不变式，这需要有序和持久化的写入。\n- **任务**：选择一个选项，该选项提出了一个科学合理的实验来隔离 `fsync` 对吞吐量的影响，并结合崩溃一致性的背景对结果提供正确的解释。\n\n步骤 2：使用提取的已知条件进行验证\n根据所需标准对问题陈述进行评估：\n- **科学依据**：该问题牢固地植根于计算机科学的基本概念，特别是操作系统和数据存储。所提供的四个原则是对 POSIX 标准、操作系统 I/O 缓冲、现代存储设备行为以及崩溃一致性定义的准确描述。所有概念都是该领域的标准概念。\n- **适定性**：该问题是适定的。它提出了一个明确的目标：在一组选项中确定最佳的实验设计和解释，以展示一个特定的、明确定义的现象（持久化的性能成本）。在这个领域的多项选择题中，存在一个“最佳”选项是一个合理的前提。\n- **客观性**：语言技术性强、精确且不带主观性。像 `fsync`、page cache 和 write barriers 这样的术语在操作系统的上下文中具有清晰、明确的含义。\n- **缺陷**：问题陈述没有表现出任何列出的缺陷。它不是科学上不合理、不完整、自相矛盾或模棱两可的。它解决了一个在系统性能分析中既重要又复杂的问题。\n\n步骤 3：结论与行动\n问题陈述是**有效的**。这是一个表述良好的问题，它测试了对应用程序、操作系统和存储硬件在实现数据持久性方面相互作用的理解。解决方案将基于已确立的原则，通过分析所提供的选项来进行。\n\n**解决方案推导**\n\n这些原则所描述的核心矛盾在于性能与持久性之间。原则 (ii) 解释了为什么基准测试可以很快：写入主内存页缓存的速度极快。原则 (i)、(iii) 和 (iv) 描述了实现持久性所需做的：将数据从页缓存强制写入到存储设备的非易失性介质（通过`fsync`），并确保设备本身不会在完成状态上说谎（通过遵守刷新/屏障指令）。因此，一个科学合理的实验必须对比这两种情况：一种是测量缓冲写入的高性能，另一种是测量真正持久化写入的较低性能。性能上的巨大差异并非异常，而是*一致性的代价*。一个未能展示这一代价或对其进行错误解读的实验是有缺陷的。\n\n**逐项分析**\n\n**A. 实现一个微基准测试...**\n- **实验设计**：该选项提出了一个事务性的微基准测试，其中小的记录（$4\\,\\mathrm{KB}$）被追加到一个文件中。它正确地指出了确保持久性的关键操作：在 `write` 后对文件描述符调用`fsync`，以及在元数据更改时对包含该文件的目录调用`fsync`。它指定了一个受控的环境（日志文件系统、启用写屏障、遵守刷新指令的 SSD），在这种环境下，`fsync` 应该能提供其 POSIX 保证。使用缓存预热和文件预分配是方法论上合理的基准测试的标志，因为它们将 I/O 成本与其他系统开销隔离开来。比较 $N=1$（每次操作同步）与批量同步（分摊）的性能是研究这种权衡的正确方法。\n- **解释**：预测的性能从大约 $10^5$ 操作/秒下降到 $10^2$–$10^3$ 操作/秒在数量上是现实的，并直接说明了将数据强制写入稳定存储的成本。解释是无可挑剔的：不使用 `fsync` 的基准测试具有欺骗性，因为它们测量的是内存性能，而不是持久化吞öt量。性能下降是使每个操作达到崩溃一致性的真实成本。\n- **结论**：**正确**。该选项提出了一个科学严谨的实验和一个完全准确的解释，与所有给定原则相符。\n\n**B. 使用命令行工具复制一个 $200\\,\\mathrm{GB}$ 的文件...**\n- **实验设计**：这提出了一个批量吞吐量基准测试，而不是对延迟敏感的事务性测试。在一次非常大的文件复制（需要数分钟）结束时调用一次 `fsync` 的效果是微乎其微的。总时间主要由设备的持续读/写带宽决定，在此期间操作系统已在后台将缓冲区刷新到磁盘。这个实验并非旨在测量 `fsync` 的每次操作延迟成本。\n- **解释**：基于这个实验得出 `fsync` 成本很小的结论是一个严重的泛化错误。它混淆了批量传输中的分摊成本与事务性工作负载中的高边际成本。这未能揭示对于需要每次操作都持久化的应用（例如数据库）而言，基准测试的欺骗性。\n- **结论**：**不正确**。实验设计不适用于当前问题，且解释存在根本性缺陷。\n\n**C. 编写一个程序，追加 $512\\,\\mathrm{B}$ 的记录...并调用...`fflush`...**\n- **实验设计**：该选项错误地用 C 标准库函数 `fflush` 替代了 POSIX 系统调用 `fsync`。根据 C 标准，`fflush(stream)` 强制将与 `stream` 关联的用户空间缓冲区的数据写入内核。它并*不*要求内核将数据写入物理存储设备。\n- **解释**：认为调用 `fflush` 足以使操作在崩溃后保持持久性的结论在事实上是错误的，并且是危险的。它直接违反了原则 (i)，该原则正确地指出 `fsync` 是保证数据传输到稳定存储所需的调用。任何观察到的性能下降都是由于用户空间到内核的缓冲区管理，而不是磁盘 I/O 的成本，并且不反映崩溃一致性的成本。\n- **结论**：**不正确**。该选项基于对 I/O API 栈的严重误解。\n\n**D. 挂载文件系统时禁用写屏障，并使用带有易失性回写缓存的机械硬盘（HDD）...**\n- **实验设计**：这个设置被明确地配置为*打破*持久性的信任链。在文件系统中禁用写屏障，并使用一个不遵守刷新指令且带有易失性缓存的驱动器，意味着当操作系统作为 `fsync` 的一部分发出刷新命令时，驱动器可能（而且很可能）在数据一到达其易失性 DRAM 缓存时就报告“完成”，而不是在数据到达物理盘片时。\n- **解释**：在这种情况下观察到高吞吐量并不能证明 `fsync` 是没有成本的；它证明了 `fsync` 并*没有*按照 POSIX 规范工作。系统通过牺牲持久性来提供具有欺骗性的性能。基于这种有缺陷的设置得出崩溃一致性是“免费”的结论，正是问题要求揭示的那个误解。这个实验展示了一种失败模式，而其解释得出了与正确教训相反的结论。\n- **结论**：**不正确**。该实验旨在产生误导性结果，其解释从根本上歪曲了所测量的对象。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}