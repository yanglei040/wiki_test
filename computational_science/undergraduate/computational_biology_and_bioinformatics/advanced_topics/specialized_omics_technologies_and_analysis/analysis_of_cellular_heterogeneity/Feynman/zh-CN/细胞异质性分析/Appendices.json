{
    "hands_on_practices": [
        {
            "introduction": "在分析任何单细胞数据之前，确保其质量至关重要。本练习不仅仅是应用一个过滤器，而是挑战你从第一性原理出发，使用统计模型生成一个带有已知技术偏差（如测序深度不足）的数据集。然后，你将应用一个标准的质量控制聚类方法来检测你亲手植入的人工痕迹，从而深刻理解实验过程、统计模型和数据分析结果之间密不可分的联系。",
            "id": "2371686",
            "problem": "您必须编写一个完整、可运行的程序。该程序在一个生成模型下模拟单细胞RNA测序 (scRNA-seq) 数据，其中一种技术性偏差（例如，某个测序通道的测序质量不佳）导致一部分细胞的捕获效率全局性降低，从而在质量控制 (QC) 特征空间中产生一个伪聚类。该程序随后必须仅使用基于QC指标的逻辑派生标准来检测是否存在这种由偏差驱动的聚类。\n\n请从以下基本定义和经过充分检验的事实开始。在单细胞RNA测序 (scRNA-seq) 中，信使核糖核酸 (mRNA) 分子被反转录，并通过唯一分子标识符 (UMI) 标签进行计数；每个细胞中每个基因的UMI计数通常被建模为来自泊松分布的抽样，这反映了一个计数过程，其均值与潜在的表达水平和总抽样深度成正比。具体来说，令 $X_{i,g}$ 表示细胞 $i$ 和基因 $g$ 的UMI计数。给定细胞 $i$ 所属的生物学聚类，其每个基因的表达均值为 $\\mu_{b(i),g} > 0$，以及一个捕获了抽样深度和捕获效率的细胞特异性大小因子 $s_i > 0$，标准模型为\n$$\nX_{i,g} \\sim \\mathrm{Poisson}\\!\\left(s_i \\,\\mu_{b(i),g}\\right),\n$$\n在给定 $(s_i,\\mu_{b(i),\\cdot})$ 的条件下，各基因 $g$ 之间相互独立。一个降低测序深度的技术性通道偏差可以表示为对受影响通道中所有细胞的 $s_i$ 乘以一个因子 $a$（其中 $0 < a < 1$）。为了进行质量控制 (QC)，将细胞 $i$ 的文库大小定义为 $L_i = \\sum_{g=1}^{G} X_{i,g}$，零值比例定义为 $Z_i = \\frac{1}{G} \\sum_{g=1}^{G} \\mathbf{1}\\{X_{i,g} = 0\\}$。在泊松模型下，独立泊松随机变量之和仍为泊松分布，其均值等于各均值之和，因此 $\\mathbb{E}[L_i] = s_i \\sum_{g=1}^{G} \\mu_{b(i),g}$，并且单个基因为零的概率是 $\\mathbb{P}(X_{i,g}=0) = \\exp(-s_i \\mu_{b(i),g})$。因此，乘法性缩减 $s_i \\mapsto a s_i$ 会使 $\\mathbb{E}[L_i]$ 减少因子 $a$ 并增加期望的零值比例，倾向于在由 $\\log_{10}(L_i+1)$ 和 $Z_i$ 构成的QC特征空间中形成一个独特的聚类。\n\n您必须实现以下任务：\n\n1. 模拟生物学异质性和通道偏差：\n   - 模拟 $N$ 个细胞和 $G$ 个基因。存在 $B$ 个生物学聚类。对于每个生物学聚类 $b \\in \\{1,\\dots,B\\}$，为每个基因 $g$ 生成聚类特异性的平均表达量 $\\mu_{b,g}$。首先从Gamma分布中抽取一个基线表达谱 $\\mu_{1,g}$（其形状和尺度参数的选择应能产生符合实际的均值），然后通过独立的对数正态乘数对每个聚类进行扰动，以反映生物学变异。将细胞均匀随机地分配到各个生物学聚类中。\n   - 从对数正态分布中抽取细胞大小因子 $s_i$，以反映测序深度的变异。选出一部分细胞（一个“偏差通道”），比例为 $p$，并将其 $s_i$ 乘以一个标量 $a$（其中 $0 < a \\le 1$，$a < 1$ 表示存在偏差）。\n   - 在基因间独立地生成计数 $X_{i,g} \\sim \\mathrm{Poisson}(s_i \\mu_{b(i),g})$。\n   - 计算每个细胞的QC特征：$F_i = \\left[\\log_{10}(L_i+1), Z_i\\right]$。\n\n2. 在QC空间中进行无监督偏差检测：\n   - 使用 $k$-means 算法（$k=2$）在二维QC特征空间中对细胞进行聚类。将两个质心确定性地初始化为具有最小和最大 $\\log_{10}(L_i+1)$ 值的点，然后进行迭代，直到收敛或达到固定的迭代上限。\n   - 设两个聚类的质心为 $C_{\\text{small}}$ 和 $C_{\\text{large}}$，其中 $C_{\\text{small}}$ 对应于细胞数较少的聚类，$C_{\\text{large}}$ 对应于另一个聚类。将它们的坐标表示为 $C_{\\text{small}} = [\\ell_s, z_s]$ 和 $C_{\\text{large}} = [\\ell_\\ell, z_\\ell]$。\n   - 当且仅当以下所有条件都成立时，宣布“检测到”由偏差驱动的聚类：\n     - 质心差异超过最小间隔：$\\ell_\\ell - \\ell_s \\ge \\tau_\\ell$ 且 $z_s - z_\\ell \\ge \\tau_z$。\n     - 较小聚类的大小比例在界限之内：$f_{\\min} \\le \\frac{n_{\\text{small}}}{N} \\le f_{\\max}$。\n   - 使用固定阈值 $\\tau_\\ell = 0.2$、$\\tau_z = 0.05$、$f_{\\min} = 0.05$ 和 $f_{\\max} = 0.6$。\n\n3. 确定性：\n   - 对每个测试用例使用带有固定种子的伪随机数生成器，以确保确定性。\n\n您的程序必须评估以下参数集测试套件（每个参数集写成一个有序元组 $(N,G,B,p,a,\\text{seed})$），进行模拟，然后为每个案例输出一个布尔值，指示是否根据上述规则检测到了由偏差驱动的聚类：\n- 案例A（明显的偏差，显著的深度损失，中等流行率）：$(N,G,B,p,a,\\text{seed}) = (\\,600,\\,1500,\\,2,\\,0.3,\\,0.25,\\,1\\,)$。\n- 案例B（中等偏差，较低流行率，增加了生物学复杂性）：$(N,G,B,p,a,\\text{seed}) = (\\,500,\\,1200,\\,3,\\,0.2,\\,0.5,\\,2\\,)$。\n- 案例C（无偏差对照组）：$(N,G,B,p,a,\\text{seed}) = (\\,500,\\,1200,\\,2,\\,0.0,\\,1.0,\\,3\\,)$。\n- 案例D（偏差过于罕见，无法形成一个连贯的聚类）：$(N,G,B,p,a,\\text{seed}) = (\\,400,\\,1000,\\,2,\\,0.02,\\,0.2,\\,4\\,)$。\n\n要求与输出：\n- 您的实现必须精确遵循上述建模和检测设计。\n- 程序的最终输出必须是单行文本，其中包含一个由方括号括起来的、逗号分隔的4个布尔检测结果列表，结果之间没有空格，顺序为A、B、C、D。例如，形如 $[{\\tt True},{\\tt False},{\\tt False},{\\tt False}]$ 的输出是可接受的，当且仅当它与您的实现针对指定测试用例产生的结果相匹配。",
            "solution": "经审阅，问题陈述是有效的。它构成了生物信息学中一个适定 (well-posed) 的计算任务，具体而言，是单细胞RNA测序 (scRNA-seq) 数据的模拟与分析。其基础模型——用于UMI计数的泊松模型、通过大小因子缩放来表示技术性偏差、以及使用质量控制 (QC) 指标进行聚类检测——都基于该领域已确立的原则。问题的目标陈述清晰、规范，足以得出一个唯一且可验证的解。问题提供了一套参数和一个确定性程序，确保了结果是可复现的。\n\n该解决方案通过遵循指定的算法来实现，该算法分为两个主要阶段：数据模拟和偏差检测。\n\n**1. 数据模拟**\n\n模拟过程会生成一个合成的 scRNA-seq 计数矩阵 $X \\in \\mathbb{N}_0^{N \\times G}$，它代表了 $N$ 个细胞和 $G$ 个基因，该矩阵包含了生物学和技术性两种变异来源。\n\n首先，通过定义 $B$ 个不同的细胞聚类来建立生物学异质性。通过从Gamma分布中抽取数值来生成一个基线平均表达谱 $\\{\\mu_{1,g}\\}_{g=1}^G$，选择Gamma分布是因为它适合于建模像基因表达水平这样的非负偏态数据。具体来说，$\\mu_{1,g} \\sim \\text{Gamma}(k=2.0, \\theta=0.5)$。对于其余的 $B-1$ 个生物学聚类，它们的平均表达谱 $\\{\\mu_{b,g}\\}_{g=1}^G$ 是通过对基线谱应用基因特异性的乘法扰动来创建的。这些乘数从对数正态分布 $\\text{LogNormal}(\\mu=0, \\sigma^2=0.25)$ 中抽取，用以模拟不同细胞类型中基因的上调或下调。然后，将 $N$ 个细胞中的每一个都均匀随机地分配到 $B$ 个生物学聚类之一。\n\n其次，通过大小因子 $\\{s_i\\}_{i=1}^N$ 引入细胞特异性的技术性变异，这些因子解释了mRNA捕获和测序效率的差异。它们从对数正态分布 $s_i \\sim \\text{LogNormal}(\\mu=0, \\sigma^2=0.25)$ 中抽取。为了模拟指定的技术性偏差，选取一个占总细胞群体比例为 $p$ 的细胞子集。这些被指定为“偏差”细胞的大小因子被一个乘法因子 $a \\in (0, 1]$ 进行缩放。对于无偏差的情况，$a=1$ 且 $p=0$。\n\n最后，细胞 $i$ 和基因 $g$ 的UMI计数（表示为 $X_{i,g}$）通过从泊松分布中进行独立抽样生成，其速率参数 $\\lambda_{i,g}$ 由该细胞的有效大小因子与该细胞所属生物学聚类中该基因的平均表达量之积给出。\n$$\nX_{i,g} \\sim \\mathrm{Poisson}(s_i \\mu_{b(i),g})\n$$\n其中 $b(i)$ 是细胞 $i$ 的生物学聚类身份。对所有 $N \\times G$ 个细胞-基因对执行此过程，以形成完整的计数矩阵 $X$。\n\n**2. 偏差检测**\n\n检测阶段在从计数矩阵派生的二维QC特征空间上操作。对每个细胞 $i$ 计算两个QC指标：文库大小 $L_i = \\sum_{g=1}^{G} X_{i,g}$，和零值比例 $Z_i = G^{-1} \\sum_{g=1}^{G} \\mathbf{1}\\{X_{i,g}=0\\}$。细胞 $i$ 的QC特征向量定义为 $F_i = [\\log_{10}(L_i + 1), Z_i]$。\n\n检测算法的核心是将 $k$-means 聚类（$k=2$）应用于所有特征向量的集合 $\\{F_i\\}_{i=1}^N$。按照要求，该过程被确定性地初始化。两个初始质心分别设置为拥有最小和最大 $\\log_{10}(L_i+1)$ 值的细胞的特征向量。然后，标准的迭代 $k$-means 算法会一直运行，直到聚类质心收敛。\n\n收敛后，根据大小标记两个生成的聚类。包含较少细胞的聚类被指定为“小”聚类，另一个被指定为“大”聚类。设它们各自的细胞数分别为 $n_{\\text{small}}$ 和 $n_{\\text{large}}$，质心分别为 $C_{\\text{small}} = [\\ell_s, z_s]$ 和 $C_{\\text{large}} = [\\ell_\\ell, z_\\ell]$。\n\n当且仅当一组三个逻辑条件同时满足时，宣布“检测到”由偏差驱动的聚类。这些条件形式化了低质量细胞聚类的预期特征。\n1.  **文库大小轴上的充分分离：** 大聚类的质心必须比小聚类具有足够大的对数文库大小。\n    $$ \\ell_\\ell - \\ell_s \\ge \\tau_\\ell $$\n    阈值为 $\\tau_\\ell = 0.2$。\n2.  **零值比例轴上的充分分离：** 小聚类的质心必须比大聚类具有足够大的零值比例。这与低质量细胞检测到的基因较少的情况相符。\n    $$ z_s - z_\\ell \\ge \\tau_z $$\n    阈值为 $\\tau_z = 0.05$。\n3.  **合理的聚类大小：** 小聚类的比例大小 $n_{\\text{small}} / N$ 必须落在预定义的范围内，以便被视为一个连贯的群体，而不是可忽略的离群点集或大部分数据。\n    $$ f_{\\min} \\le \\frac{n_{\\text{small}}}{N} \\le f_{\\max} $$\n    阈值为 $f_{\\min} = 0.05$ 和 $f_{\\max} = 0.6$。\n\n通过对这三个条件进行逻辑与运算，为每个测试用例计算一个指示检测状态的布尔结果。",
            "answer": "```python\nimport numpy as np\n\ndef run_simulation(N, G, B, p, a, seed):\n    \"\"\"\n    Simulates scRNA-seq data and detects an artifact-driven cluster.\n\n    Args:\n        N (int): Number of cells.\n        G (int): Number of genes.\n        B (int): Number of biological clusters.\n        p (float): Proportion of cells in the artifact lane.\n        a (float): Multiplicative scaling factor for the artifact.\n        seed (int): Seed for the pseudorandom number generator.\n\n    Returns:\n        bool: True if an artifact-driven cluster is detected, False otherwise.\n    \"\"\"\n    # 3. Determinism: Use a seeded RNG\n    rng = np.random.default_rng(seed)\n\n    # 1. Simulation of biological heterogeneity and lane artifact\n    \n    # Generate biological means mu_b,g\n    # These parameters are chosen to be reasonable but are not specified in the problem.\n    gamma_shape = 2.0\n    gamma_scale = 0.5\n    lognorm_sigma = 0.5\n    \n    # Baseline profile for the first biological cluster\n    mu_baseline = rng.gamma(gamma_shape, gamma_scale, size=G)\n    \n    # Generate profiles for all B clusters\n    mu_profiles = np.zeros((B, G))\n    mu_profiles[0, :] = mu_baseline\n    for b in range(1, B):\n        perturbations = rng.lognormal(mean=0.0, sigma=lognorm_sigma, size=G)\n        mu_profiles[b, :] = mu_baseline * perturbations\n\n    # Assign cells uniformly at random to biological clusters\n    cell_bio_clusters = rng.integers(0, B, size=N)\n\n    # Draw cell size factors s_i from a log-normal distribution\n    # These parameters are chosen to be reasonable. Mean=0 gives a median of 1.\n    size_factors = rng.lognormal(mean=0.0, sigma=lognorm_sigma, size=N)\n    \n    # Select a subset of cells for the artifact lane and apply the artifact\n    num_artifact_cells = int(np.floor(N * p))\n    if num_artifact_cells > 0:\n        artifact_indices = rng.choice(N, size=num_artifact_cells, replace=False)\n        size_factors[artifact_indices] *= a\n\n    # Generate count matrix X_i,g ~ Poisson(s_i * mu_b(i),g)\n    # The rates matrix lambda_ig has dimensions N x G\n    rates = size_factors[:, np.newaxis] * mu_profiles[cell_bio_clusters, :]\n    X = rng.poisson(rates)\n\n    # Compute QC features per cell\n    L = X.sum(axis=1)\n    Z = (X == 0).mean(axis=1)\n    F = np.vstack([np.log10(L + 1), Z]).T\n\n    # 2. Unsupervised artifact detection in QC space\n    \n    # k-means clustering with k=2\n    # Deterministic initialization\n    idx_min_l = np.argmin(F[:, 0])\n    idx_max_l = np.argmax(F[:, 0])\n    centroids = np.array([F[idx_min_l, :], F[idx_max_l, :]])\n\n    # Iterate until convergence or max iterations\n    max_iter = 100\n    for _ in range(max_iter):\n        old_centroids = centroids.copy()\n        \n        # Assign points to the nearest centroid (Euclidean distance)\n        dist_sq_0 = np.sum((F - centroids[0])**2, axis=1)\n        dist_sq_1 = np.sum((F - centroids[1])**2, axis=1)\n        labels = (dist_sq_1 < dist_sq_0).astype(int)\n        \n        # Handle case where a cluster becomes empty\n        if np.sum(labels == 0) == 0 or np.sum(labels == 1) == 0:\n            # If a cluster is empty, re-initialization is needed.\n            # However, for this problem's setup, it is highly unlikely.\n            # We can stop here, as centroids cannot be computed.\n            return False # No valid two-cluster structure found\n\n        # Update centroids\n        centroids[0] = F[labels == 0].mean(axis=0)\n        centroids[1] = F[labels == 1].mean(axis=0)\n        \n        if np.allclose(old_centroids, centroids):\n            break\n\n    # Label clusters as 'small' and 'large' based on cell count\n    n_0 = np.sum(labels == 0)\n    n_1 = np.sum(labels == 1)\n\n    if n_0 < n_1:\n        n_small, C_small = n_0, centroids[0]\n        n_large, C_large = n_1, centroids[1]\n    else:\n        n_small, C_small = n_1, centroids[1]\n        n_large, C_large = n_0, centroids[0]\n    \n    l_s, z_s = C_small\n    l_l, z_l = C_large\n\n    # Define detection thresholds\n    tau_l = 0.2\n    tau_z = 0.05\n    f_min = 0.05\n    f_max = 0.6\n\n    # Declare an artifact-driven cluster \"detected\" if all criteria are met\n    cond1 = (l_l - l_s) >= tau_l\n    cond2 = (z_s - z_l) >= tau_z\n    frac_small = n_small / N\n    cond3 = (f_min <= frac_small) and (frac_small <= f_max)\n\n    return cond1 and cond2 and cond3\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case A: Clear artifact, substantial depth loss, moderate prevalence\n        (600, 1500, 2, 0.3, 0.25, 1),\n        # Case B: Moderate artifact, lower prevalence, added biological complexity\n        (500, 1200, 3, 0.2, 0.5, 2),\n        # Case C: No artifact control\n        (500, 1200, 2, 0.0, 1.0, 3),\n        # Case D: Artifact too rare to be a coherent cluster\n        (400, 1000, 2, 0.02, 0.2, 4),\n    ]\n\n    results = []\n    for params in test_cases:\n        N, G, B, p, a, seed = params\n        detection_result = run_simulation(N, G, B, p, a, seed)\n        results.append(detection_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "细胞群体并非总是离散的，它们可以沿着一个连续的谱系存在。本练习将教你如何在一个看似均一的细胞簇内，通过寻找表达模式呈现双峰分布的基因来发现隐藏的细胞状态分化。你将利用贝叶斯信息准则 ($BIC$) 进行模型选择，判断一个基因的表达是由单一高斯分布还是双高斯混合模型能更好地解释，这是分析动态生物过程的关键一步。",
            "id": "2371636",
            "problem": "给定几组实数值的基因表达量测量数据，每组数据代表已经被分配到一个看似同质的单一簇中的多个单细胞的测量值。对于每个测试用例，数据以矩阵形式呈现，其中每一行对应一个基因，并包含该基因在各个细胞中的表达值。目标是，对于每个基因在其簇内，判断其表达分布用单峰模型解释更优，还是用双峰混合模型解释更优，后者可能预示着存在隐藏的分叉。\n\n请将此决策问题构建为一个模型选择问题，在以下两个概率模型之间为具有观测值 $\\{x_i\\}_{i=1}^{n}$ 的单个基因进行选择：\n\n- 单峰模型 $\\mathcal{U}$：一个单一的高斯（正态）分布，其均值为 $\\mu \\in \\mathbb{R}$，方差为 $\\sigma^2 \\in \\mathbb{R}_{>0}$，似然函数为\n$$\nL_{\\mathcal{U}}(\\mu,\\sigma^2 \\mid x_{1:n}) \\;=\\; \\prod_{i=1}^{n} \\phi(x_i \\,;\\, \\mu, \\sigma^2),\n$$\n其中 $\\phi(\\cdot \\,;\\, \\mu, \\sigma^2)$ 表示高斯概率密度函数。\n\n- 双峰模型 $\\mathcal{M}$：一个双组分高斯混合模型（GMM; Gaussian Mixture Model），其混合比例为 $p \\in (0,1)$，组分均值为 $\\mu_1,\\mu_2 \\in \\mathbb{R}$，组分方差为 $\\sigma_1^2,\\sigma_2^2 \\in \\mathbb{R}_{>0}$，似然函数为\n$$\nL_{\\mathcal{M}}(p,\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2 \\mid x_{1:n}) \\;=\\; \\prod_{i=1}^{n} \\Big( p \\,\\phi(x_i \\,;\\, \\mu_1, \\sigma_1^2) \\;+\\; (1-p)\\,\\phi(x_i \\,;\\, \\mu_2, \\sigma_2^2) \\Big).\n$$\n\n对于每个模型 $\\mathcal{A} \\in \\{\\mathcal{U},\\mathcal{M}\\}$，设 $\\hat{\\ell}_{\\mathcal{A}}$ 为其参数空间上的最大化对数似然，并设 $k_{\\mathcal{A}}$ 表示其自由参数的数量。使用贝叶斯信息准则（BIC; Bayesian Information Criterion）\n$$\n\\mathrm{BIC}(\\mathcal{A}) \\;=\\; k_{\\mathcal{A}} \\,\\log n \\;-\\; 2\\,\\hat{\\ell}_{\\mathcal{A}},\n$$\n其中 $k_{\\mathcal{U}} = 2$ 且 $k_{\\mathcal{M}} = 5$。对于一个基因在其簇内的表达向量，当且仅当 $\\mathrm{BIC}(\\mathcal{M}) < \\mathrm{BIC}(\\mathcal{U})$ 时，将其声明为“双峰”（bimodal），否则声明为“非双峰”（not bimodal）。\n\n你的程序必须为每个提供的测试用例中的每个基因计算此决策，并报告被声明为双峰的基因的从零开始的索引。\n\n测试套件（每个测试用例都是一个基因×细胞的实数矩阵）：\n\n- 测试用例 1（三个基因，每个基因有 30 个细胞的数据）：\n    - 基因 0： $[\\, 1.18, 1.27, 1.33, 1.38, 1.42, 1.45, 1.47, 1.50, 1.53, 1.55, 1.58, 1.62, 1.66, 1.72, 1.81, 1.19, 1.29, 1.35, 1.40, 1.44, 1.46, 1.48, 1.51, 1.54, 1.56, 1.60, 1.64, 1.70, 1.78, 1.85 \\,]$\n    - 基因 1： $[\\, 0.05, 0.12, 0.18, 0.22, 0.26, 0.28, 0.30, 0.32, 0.34, 0.36, 0.40, 0.43, 0.47, 0.52, 0.58, 1.85, 1.92, 1.98, 2.02, 2.06, 2.08, 2.10, 2.12, 2.14, 2.16, 2.20, 2.23, 2.27, 2.32, 2.38 \\,]$\n    - 基因 2： $[\\, 0.65, 0.72, 0.78, 0.84, 0.88, 0.90, 0.92, 0.94, 0.98, 1.02, 1.06, 1.12, 1.62, 1.70, 1.75, 1.80, 1.84, 1.88, 1.90, 1.92, 1.94, 1.96, 2.00, 2.04, 2.08, 2.12, 2.18, 2.22, 2.28, 2.34 \\,]$\n\n- 测试用例 2（三个基因，每个基因有 30 个细胞的数据）：\n    - 基因 0： $[\\, 0.96, 0.98, 1.00, 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.10, 1.11, 1.12, 0.97, 0.99, 1.00, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.10, 1.11, 1.12, 1.13 \\,]$\n    - 基因 1： $[\\, 0.62, 0.66, 0.70, 0.74, 0.76, 0.78, 0.80, 0.82, 0.84, 0.86, 0.88, 0.90, 0.92, 0.94, 0.96, 0.98, 1.00, 1.02, 1.04, 1.06, 1.08, 1.10, 1.12, 1.14, 1.16, 1.18, 1.20, 1.22, 1.24, 1.26 \\,]$\n    - 基因 2： $[\\, 0.05, 0.08, 0.12, 0.16, 0.20, 0.22, 0.24, 0.26, 0.28, 0.32, 0.95, 1.00, 1.04, 1.08, 1.12, 1.14, 1.16, 1.18, 1.20, 1.22, 1.24, 1.26, 1.28, 1.30, 1.32, 1.34, 1.36, 1.40, 1.44, 1.48 \\,]$\n\n- 测试用例 3（三个基因，每个基因有 8 个细胞的数据）：\n    - 基因 0： $[\\, 0.92, 0.95, 0.98, 1.00, 1.02, 1.05, 1.08, 1.10 \\,]$\n    - 基因 1： $[\\, 0.20, 0.24, 0.28, 0.32, 1.68, 1.72, 1.76, 1.80 \\,]$\n    - 基因 2： $[\\, 1.00, 1.02, 1.04, 1.06, 1.14, 1.16, 1.18, 1.20 \\,]$\n\n任务与答案规范：\n\n- 对于每个测试用例中的每个基因，计算 $\\mathrm{BIC}(\\mathcal{U})$ 和 $\\mathrm{BIC}(\\mathcal{M})$，并且当且仅当 $\\mathrm{BIC}(\\mathcal{M}) < \\mathrm{BIC}(\\mathcal{U})$ 时，判定为“双峰”。\n- 对于每个测试用例，以整数列表的形式输出被声明为双峰的基因的从零开始的索引。\n- 最终输出格式：你的程序应生成单行输出，其中包含所有测试用例的结果，形式为由逗号分隔的列表所组成的列表，并用方括号括起来；例如，$[ [\\dots], [\\dots], [\\dots] ]$。具体而言，输出必须是形如 \"[[result\\_tc1],[result\\_tc2],[result\\_tc3]]\" 的单行字符串，其中每个 result\\_tc$k$ 是一个从零开始的基因索引列表。\n\n所有数值计算均为无单位的实数。不涉及角度。要求输出中不出现百分比。每个测试用例的答案必须是一个整数列表。最终答案必须将这些列表聚合成如上所述的单行。",
            "solution": "所提出的问题是统计模型选择中的一个定义明确的练习，这是定量科学中的一种基本实践。我们的任务是确定给定基因的一组观测值 $\\{x_i\\}_{i=1}^{n}$ 是用单峰分布还是双峰分布能更好地表示。这个决策通过使用贝叶斯信息准则（BIC）比较两个概率模型来形式化。\n\nBIC 为模型选择提供了一种严谨的方法，它对模型的复杂性进行惩罚，从而减轻过拟合的风险。对于一个模型 $\\mathcal{A}$，BIC 定义为：\n$$\n\\mathrm{BIC}(\\mathcal{A}) = k_{\\mathcal{A}} \\log n - 2\\hat{\\ell}_{\\mathcal{A}}\n$$\n其中 $k_{\\mathcal{A}}$ 是模型中自由参数的数量，$n$ 是数据点的数量，$\\hat{\\ell}_{\\mathcal{A}}$ 是给定数据下模型的最大化对数似然。BIC 值较低的模型更优。\n\n我们将分析指定的两个模型中的每一个。\n\n**1. 单峰模型 ($\\mathcal{U}$)**\n\n该模型假定数据是从单一高斯分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 中抽取的。对数似然函数为：\n$$\n\\ell_{\\mathcal{U}}(\\mu, \\sigma^2 \\mid x_{1:n}) = \\sum_{i=1}^{n} \\log \\phi(x_i \\,;\\, \\mu, \\sigma^2) = -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i - \\mu)^2\n$$\n自由参数的数量为 $k_{\\mathcal{U}} = 2$，对应于均值 $\\mu$ 和方差 $\\sigma^2$。这些参数的最大似然估计（MLE）具有众所周知的闭式解：样本均值和样本方差。\n$$\n\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n$$\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\hat{\\mu})^2\n$$\n将这些估计值代入对数似然函数，得到最大化对数似然 $\\hat{\\ell}_{\\mathcal{U}}$：\n$$\n\\hat{\\ell}_{\\mathcal{U}} = -\\frac{n}{2}\\log(2\\pi\\hat{\\sigma}^2) - \\frac{n}{2}\n$$\n据此，我们可以计算 $\\mathrm{BIC}(\\mathcal{U}) = 2 \\log n - 2\\hat{\\ell}_{\\mathcal{U}}$。\n\n**2. 双峰模型 ($\\mathcal{M}$)**\n\n该模型将数据描述为两个高斯组分的混合。其概率密度函数为：\n$$\nf(x_i) = p \\,\\phi(x_i \\,;\\, \\mu_1, \\sigma_1^2) + (1-p)\\,\\phi(x_i \\,;\\, \\mu_2, \\sigma_2^2)\n$$\n该模型有五个自由参数：$\\theta = \\{p, \\mu_1, \\sigma_1^2, \\mu_2, \\sigma_2^2\\}$，因此 $k_{\\mathcal{M}} = 5$。对数似然函数为：\n$$\n\\ell_{\\mathcal{M}}(\\theta \\mid x_{1:n}) = \\sum_{i=1}^{n} \\log \\Big( p \\,\\phi(x_i \\,;\\, \\mu_1, \\sigma_1^2) + (1-p)\\,\\phi(x_i \\,;\\, \\mu_2, \\sigma_2^2) \\Big)\n$$\n与单峰模型不同，参数 $\\theta$ 的最大似然估计没有闭式解。我们必须采用迭代数值优化过程。解决该问题的标准算法是期望最大化（EM）算法。\n\nEM 算法的流程如下：\n- **初始化**：为参数 $\\theta^{(0)}$ 赋初值。一种稳健的启发式方法是将数据排序，将其划分为两半，并从每一半计算混合比例（$p^{(0)}=0.5$）、均值和方差，作为两个组分的初始估计值。\n\n- **迭代**：对 $t = 0, 1, 2, \\dots$ 重复以下两个步骤，直到收敛。\n    - **E步（期望）**：在给定当前参数估计 $\\theta^{(t)}$ 的条件下，计算每个观测值 $x_i$ 由组分 $j \\in \\{1, 2\\}$ 生成的后验概率，或称“责任”（responsibility）。\n      $$\n      \\gamma_{ij}^{(t+1)} = \\frac{p_j^{(t)} \\phi(x_i ; \\mu_j^{(t)}, \\sigma_j^{2(t)})}{\\sum_{k=1}^{2} p_k^{(t)} \\phi(x_i ; \\mu_k^{(t)}, \\sigma_k^{2(t)})}\n      $$\n      其中 $p_1=p$ 且 $p_2=1-p$。为了数值稳定性，这些计算最好在对数空间中进行，使用 log-sum-exp 技巧来处理分母。\n\n    - **M步（最大化）**：使用计算出的责任来更新参数，以最大化期望对数似然。\n      设 $n_j = \\sum_{i=1}^{n} \\gamma_{ij}^{(t+1)}$。\n      $$\n      p^{(t+1)} = \\frac{n_1}{n}\n      $$\n      $$\n      \\mu_j^{(t+1)} = \\frac{1}{n_j} \\sum_{i=1}^{n} \\gamma_{ij}^{(t+1)} x_i\n      $$\n      $$\n      \\sigma_j^{2(t+1)} = \\frac{1}{n_j} \\sum_{i=1}^{n} \\gamma_{ij}^{(t+1)} (x_i - \\mu_j^{(t+1)})^2\n      $$\n      必须向方差估计中添加一个小的正则化常数，以防止当某个组分的方差趋近于零时发生数值崩溃。\n\n- **收敛**：当连续迭代之间的对数似然变化量小于预定义的容差时（例如，$|\\ell^{(t+1)} - \\ell^{(t)}| < 10^{-6}$），算法即收敛。最终的对数似然值即为最大化对数似然 $\\hat{\\ell}_{\\mathcal{M}}$。\n\n最后，我们计算 $\\mathrm{BIC}(\\mathcal{M}) = 5 \\log n - 2\\hat{\\ell}_{\\mathcal{M}}$。\n\n**3. 决策准则**\n对于每个基因，我们比较两个 BIC 分数。当且仅当双峰模型优于单峰模型时，基因的表达被声明为“双峰”：\n$$\n\\mathrm{BIC}(\\mathcal{M}) < \\mathrm{BIC}(\\mathcal{U})\n$$\n这个不等式表明，双组分模型在拟合优度上的提升（体现在更高的 $\\hat{\\ell}_{\\mathcal{M}}$）足以弥补其额外三个参数（$k_{\\mathcal{M}} - k_{\\mathcal{U}} = 3$）所带来的惩罚。否则，该基因被分类为“非双峰”。该算法将被应用于所提供的测试用例中的每个基因，以确定其分类。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the problem of identifying bimodal genes using BIC model selection.\n    \"\"\"\n    \n    test_cases = [\n        # Test case 1\n        np.array([\n            [1.18, 1.27, 1.33, 1.38, 1.42, 1.45, 1.47, 1.50, 1.53, 1.55, 1.58, 1.62, 1.66, 1.72, 1.81, 1.19, 1.29, 1.35, 1.40, 1.44, 1.46, 1.48, 1.51, 1.54, 1.56, 1.60, 1.64, 1.70, 1.78, 1.85],\n            [0.05, 0.12, 0.18, 0.22, 0.26, 0.28, 0.30, 0.32, 0.34, 0.36, 0.40, 0.43, 0.47, 0.52, 0.58, 1.85, 1.92, 1.98, 2.02, 2.06, 2.08, 2.10, 2.12, 2.14, 2.16, 2.20, 2.23, 2.27, 2.32, 2.38],\n            [0.65, 0.72, 0.78, 0.84, 0.88, 0.90, 0.92, 0.94, 0.98, 1.02, 1.06, 1.12, 1.62, 1.70, 1.75, 1.80, 1.84, 1.88, 1.90, 1.92, 1.94, 1.96, 2.00, 2.04, 2.08, 2.12, 2.18, 2.22, 2.28, 2.34],\n        ]),\n        # Test case 2\n        np.array([\n            [0.96, 0.98, 1.00, 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.10, 1.11, 1.12, 0.97, 0.99, 1.00, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.10, 1.11, 1.12, 1.13],\n            [0.62, 0.66, 0.70, 0.74, 0.76, 0.78, 0.80, 0.82, 0.84, 0.86, 0.88, 0.90, 0.92, 0.94, 0.96, 0.98, 1.00, 1.02, 1.04, 1.06, 1.08, 1.10, 1.12, 1.14, 1.16, 1.18, 1.20, 1.22, 1.24, 1.26],\n            [0.05, 0.08, 0.12, 0.16, 0.20, 0.22, 0.24, 0.26, 0.28, 0.32, 0.95, 1.00, 1.04, 1.08, 1.12, 1.14, 1.16, 1.18, 1.20, 1.22, 1.24, 1.26, 1.28, 1.30, 1.32, 1.34, 1.36, 1.40, 1.44, 1.48],\n        ]),\n        # Test case 3\n        np.array([\n            [0.92, 0.95, 0.98, 1.00, 1.02, 1.05, 1.08, 1.10],\n            [0.20, 0.24, 0.28, 0.32, 1.68, 1.72, 1.76, 1.80],\n            [1.00, 1.02, 1.04, 1.06, 1.14, 1.16, 1.18, 1.20],\n        ]),\n    ]\n    \n    results = []\n    for gene_matrix in test_cases:\n        bimodal_indices = []\n        for i, gene_data in enumerate(gene_matrix):\n            bic_u = _calculate_bic_unimodal(gene_data)\n            bic_m = _calculate_bic_bimodal_gmm(gene_data)\n            if bic_m < bic_u:\n                bimodal_indices.append(i)\n        results.append(bimodal_indices)\n\n    # Format output according to specification\n    inner_results = [\",\".join(map(str, r)) for r in results]\n    inner_strings = [f\"[{s}]\" for s in inner_results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\ndef _calculate_bic_unimodal(x):\n    \"\"\"Calculates BIC for a single Gaussian model.\"\"\"\n    n = len(x)\n    k_U = 2\n    \n    mu = np.mean(x)\n    # MLE for variance uses n in the denominator\n    var = np.var(x)\n    \n    if var < 1e-9:\n        var = 1e-9 # Prevent log(0)\n    \n    log_likelihood = np.sum(norm.logpdf(x, loc=mu, scale=np.sqrt(var)))\n    \n    bic = k_U * np.log(n) - 2 * log_likelihood\n    return bic\n\ndef _calculate_bic_bimodal_gmm(x, max_iter=100, tol=1e-6):\n    \"\"\"Calculates BIC for a two-component GMM using the EM algorithm.\"\"\"\n    n = len(x)\n    k_M = 5\n    reg_const = 1e-9 # Regularization constant for variance\n\n    # 1. Initialization\n    x_sorted = np.sort(x)\n    \n    # Check for trivial cases\n    if n < 4: return np.inf\n\n    split_idx = n // 2\n    group1 = x_sorted[:split_idx]\n    group2 = x_sorted[split_idx:]\n    \n    p = 0.5\n    mu1, mu2 = np.mean(group1), np.mean(group2)\n    var1, var2 = np.var(group1), np.var(group2)\n\n    var1 = max(var1, reg_const)\n    var2 = max(var2, reg_const)\n\n    prev_log_likelihood = -np.inf\n\n    for _ in range(max_iter):\n        # 2. E-Step: calculate responsibilities using log probabilities for stability\n        log_pdf1 = norm.logpdf(x, loc=mu1, scale=np.sqrt(var1))\n        log_pdf2 = norm.logpdf(x, loc=mu2, scale=np.sqrt(var2))\n        \n        log_p = np.log(p)\n        log_1_minus_p = np.log(1 - p)\n\n        log_w1 = log_p + log_pdf1\n        log_w2 = log_1_minus_p + log_pdf2\n\n        log_likelihood_points = np.logaddexp(log_w1, log_w2)\n        current_log_likelihood = np.sum(log_likelihood_points)\n        \n        # Check for convergence\n        if abs(current_log_likelihood - prev_log_likelihood) < tol:\n            break\n        prev_log_likelihood = current_log_likelihood\n        \n        # Responsibilities\n        log_gamma1 = log_w1 - log_likelihood_points\n        gamma1 = np.exp(log_gamma1)\n        \n        # 3. M-Step: update parameters\n        n1 = np.sum(gamma1)\n        n2 = n - n1\n        \n        if n1 < 1e-9 or n2 < 1e-9:\n            # Component collapse, indicates a poor fit for bimodal model\n            return np.inf\n\n        p = n1 / n\n        mu1 = np.sum(gamma1 * x) / n1\n        mu2 = np.sum((1 - gamma1) * x) / n2\n        var1 = np.sum(gamma1 * (x - mu1)**2) / n1 + reg_const\n        var2 = np.sum((1 - gamma1) * (x - mu2)**2) / n2 + reg_const\n    \n    final_log_likelihood = prev_log_likelihood\n    if not np.isfinite(final_log_likelihood):\n        return np.inf\n\n    bic = k_M * np.log(n) - 2 * final_log_likelihood\n    return bic\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "识别细胞类型是单细胞分析的核心目标之一，但单个标记基因常因技术噪音（如基因脱落，$dropout$）而不够可靠。本练习将指导你构建一个更稳健的“标记基因模块”，方法是识别与已知标记基因共表达的基因集。通过对模块内多个基因的信号进行平均，你可以获得一个更稳定、更能抵抗噪音的细胞类型识别分数，这在生物信息学分析中是一种强大且广泛应用的技术。",
            "id": "2371687",
            "problem": "您的任务是形式化并实现一个稳健的泛化方法，将单个“标记基因”推广为“标记基因模块”，用于在单细胞基因表达数据中识别目标细胞类型。其核心思想是利用共表达：与一个种子标记基因在统计上共表达的一小组基因，在异质性细胞中能产生比任何单个基因更稳定的信号。\n\n从以下基本基础开始：\n- 分子生物学中心法则：基因转录为信使核糖核酸 (mRNA)，其数量可以被量化以估算基因表达。\n- 一个基因表达实验产生一个矩阵，其中行代表基因，列代表细胞。条目 $X_{g,c} \\ge 0$ 是基因 $g$ 在细胞 $c$ 中测得的丰度（例如，计数）。\n- 共表达可以用皮尔逊相关系数来量化。跨细胞的标准化将原始表达量转换为可在不同基因间比较的无量纲分数。\n\n您的程序必须为测试套件中的每个数据集实现以下流程。\n\n定义与程序：\n1. 数据模型。设 $G = \\{g_1,\\dots,g_p\\}$ 为 $p$ 个基因的集合， $C = \\{c_1,\\dots,c_n\\}$ 为 $n$ 个细胞的集合。给定一个非负矩阵 $X \\in \\mathbb{R}_{\\ge 0}^{p \\times n}$ 和一个二元标签向量 $y \\in \\{0,1\\}^n$，该向量指示每个细胞 $c$ 是否为目标类型 ($y_c = 1$) 或不是 ($y_c = 0$)。此外，还给定一个种子标记基因 $g^\\ast \\in G$ 和一个相关性阈值 $\\tau \\in [0,1]$。\n2. 共表达与模块构建。\n   - 对每个基因 $g \\in G$，使用总体公式计算向量 $X_{g^\\ast,\\cdot}$ 和 $X_{g,\\cdot}$ 在 $n$ 个细胞间的皮尔逊相关性 $r(g^\\ast,g)$：即对中心化变量使用总体标准差（分母为 $n$）。\n   - 排除任何在细胞间方差为零（总体标准差等于 $0$）的基因，使其不参与相关性计算和后续评分。\n   - 将阈值 $\\tau$ 下的标记基因模块定义为\n     $$ M(\\tau) \\equiv \\{ g \\in G \\,:\\, r(g^\\ast,g) \\ge \\tau \\ \\text{and}\\ r(g^\\ast,g) > 0 \\} \\cup \\{ g^\\ast \\}. $$\n     如果 $M(\\tau)$ 中的任何基因方差为零，则将其从 $M(\\tau)$ 中移除。种子基因 $g^\\ast$ 总是被包含在内，除非其方差为零；如果发生这种情况，则仅将其用于单基因基线比较，并在必要时将其从模块中排除，以避免除以零。\n3. 标准化与评分。\n   - 对于每个方差不为零的基因 $g$，使用总体均值和总体标准差计算其在各细胞中的标准化 $z$-分数：\n     $$ z_{g,c} \\equiv \\frac{X_{g,c} - \\mu_g}{\\sigma_g}, \\quad \\mu_g \\equiv \\frac{1}{n}\\sum_{c=1}^n X_{g,c}, \\quad \\sigma_g \\equiv \\sqrt{\\frac{1}{n}\\sum_{c=1}^n (X_{g,c} - \\mu_g)^2}. $$\n   - 将每个细胞 $c$ 的模块分数定义为模块内各基因标准化表达量的平均值：\n     $$ s_c \\equiv \\frac{1}{|M(\\tau)|}\\sum_{g \\in M(\\tau)} z_{g,c}. $$\n   - 仅使用种子基因定义每个细胞 $c$ 的单基因分数：\n     $$ s_c^{(1)} \\equiv z_{g^\\ast,c}. $$\n4. 分类规则。\n   - 使用分数的符号，通过模块和单基因来预测目标细胞类型：\n     $$ \\widehat{y}^{(M)}_c \\equiv \\mathbb{I}[\\, s_c > 0 \\,], \\qquad \\widehat{y}^{(1)}_c \\equiv \\mathbb{I}[\\, s_c^{(1)} > 0 \\,], $$\n     其中 $\\mathbb{I}[\\cdot]$ 是指示函数，当其参数为真时等于 $1$，否则等于 $0$。\n   - 计算每种情况下正确预测的数量：\n     $$ N^{(M)} \\equiv \\sum_{c=1}^n \\mathbb{I}[\\, \\widehat{y}^{(M)}_c = y_c \\,], \\qquad N^{(1)} \\equiv \\sum_{c=1}^n \\mathbb{I}[\\, \\widehat{y}^{(1)}_c = y_c \\,]. $$\n5. 通过合并标准化差异（科恩 $d$ 值）进行效应量比较。计算模块分数和单基因分数的效应量。设 $S = \\{ c : y_c = 1 \\}$ 和 $T = \\{ c : y_c = 0 \\}$，其大小分别为 $n_S$ 和 $n_T$。对于一个分数向量 $u \\in \\mathbb{R}^n$，令\n   $$ \\overline{u}_S \\equiv \\frac{1}{n_S}\\sum_{c \\in S} u_c, \\quad \\overline{u}_T \\equiv \\frac{1}{n_T}\\sum_{c \\in T} u_c, $$\n   $$ s_S^2 \\equiv \\frac{1}{n_S - 1} \\sum_{c \\in S} (u_c - \\overline{u}_S)^2, \\quad s_T^2 \\equiv \\frac{1}{n_T - 1} \\sum_{c \\in T} (u_c - \\overline{u}_T)^2, $$\n   $$ s_p \\equiv \\sqrt{ \\frac{(n_S - 1)s_S^2 + (n_T - 1)s_T^2}{n_S + n_T - 2} }, \\quad d(u) \\equiv \\frac{\\overline{u}_S - \\overline{u}_T}{s_p}. $$\n   将此公式应用于 $u = s$（模块）和 $u = s^{(1)}$（单基因）。\n6. 每个数据集的输出规范。报告列表\n   $$ \\big[\\, |M(\\tau)|,\\ \\mathrm{round}(d(s^{(1)}), 3),\\ \\mathrm{round}(d(s), 3),\\ N^{(M)} - N^{(1)} \\,\\big], $$\n   其中 $\\mathrm{round}(\\cdot,3)$ 表示四舍五入到三位小数。\n\n测试套件。请在以下三个数据集上实现您的解决方案。行按 $(g_1,g_2,g_3,g_4,g_5,g_6)$ 排序，列按 $(c_1,\\dots,c_n)$ 排序。种子基因始终为 $g^\\ast = g_1$。每个数据集都提供了标签向量 $y$。\n\n- 数据集 A（理想路径；强共表达模块）：\n  $$ X^{(A)} = \\begin{bmatrix}\n  10 & 11 & 9 & 10 & 1 & 2 & 1 & 1 \\\\\n  9 & 10 & 8 & 9 & 1 & 1 & 2 & 1 \\\\\n  1 & 1 & 1 & 2 & 9 & 8 & 10 & 9 \\\\\n  1 & 2 & 1 & 1 & 8 & 9 & 9 & 8 \\\\\n  2 & 1 & 2 & 2 & 2 & 2 & 1 & 2 \\\\\n  6 & 7 & 5 & 6 & 1 & 1 & 1 & 2\n  \\end{bmatrix}, \\quad y^{(A)} = [\\,1,1,1,1,0,0,0,0\\,], \\quad \\tau^{(A)} = 0.6. $$\n- 数据集 B（边界条件；阈值强制形成单基因模块）：\n  $$ X^{(B)} = X^{(A)}, \\quad y^{(B)} = y^{(A)}, \\quad \\tau^{(B)} = 1.0. $$\n- 数据集 C（dropout 边缘情况；模块辅助恢复）：\n  $$ X^{(C)} = \\begin{bmatrix}\n  0 & 0 & 8 & 1 & 1 & 1 \\\\\n  7 & 6 & 7 & 1 & 1 & 1 \\\\\n  1 & 1 & 1 & 6 & 7 & 6 \\\\\n  1 & 1 & 1 & 5 & 6 & 5 \\\\\n  2 & 2 & 2 & 2 & 2 & 2 \\\\\n  5 & 5 & 6 & 1 & 1 & 1\n  \\end{bmatrix}, \\quad y^{(C)} = [\\,1,1,1,0,0,0\\,], \\quad \\tau^{(C)} = 0.3. $$\n\n最终输出格式。您的程序应为数据集 A、B 和 C 生成单行输出，其中包含三个对应于各数据集的结果列表，并严格采用以下格式（不含空格）：一个用方括号括起来的、逗号分隔的列表，例如\n$$ \\text{\"[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3]]\"} $$\n其中，每个 $a_i$ 是一个整数，每个 $b_i,c_i$ 是一个四舍五入到三位小数的浮点数，而 $d_i$ 是一个整数。不得有任何其他打印文本。\n\n注：\n- 以上所有数学实体（符号、变量、函数、运算符和数字）均以 LaTeX 格式书写，但您的实现必须遵循其计算定义。\n- 角度和物理单位不适用。",
            "solution": "我们通过聚合标准化的共表达基因，来形式化一个稳健的标记基因模块。推理过程从分子生物学和统计学的基础定义出发，最终形成一个具体的算法。\n\n基础和动机。分子生物学中心法则指出，基因转录为信使核糖核酸（mRNA），可以通过测量其数量来获得定量的基因表达。单细胞测量产生一个表达矩阵 $X_{g,c}$，其中跨细胞的变异性既反映了生物异质性，也反映了技术噪声。单个标记基因 $g^\\ast$ 在遇到 dropout 或细微变化时可能会失效，而一小组共表达基因则可以平均掉噪声并放大真实的生物信号。从统计学上讲，如果共表达基因共享信号但噪声部分独立，那么根据类似于独立性下方差可加性的论证，对其标准化表达量进行平均，可以将方差大致按模块大小的比例减小。\n\n通过相关性实现共表达。共表达的一个标准度量是皮尔逊相关性，它对于跨细胞的两个基因向量，可以量化其线性一致性。对均值和方差均使用总体标准化（分母为 $n$），可以得到总体相关系数。将中心化向量表示为 $X^\\circ_{g,c} \\equiv X_{g,c} - \\mu_g$，总体标准差为 $\\sigma_g \\equiv \\sqrt{\\frac{1}{n} \\sum_c (X_{g,c} - \\mu_g)^2}$，相关性为\n$$ r(g^\\ast,g) \\equiv \\frac{1}{n}\\sum_{c=1}^n \\frac{(X_{g^\\ast,c} - \\mu_{g^\\ast})(X_{g,c} - \\mu_g)}{\\sigma_{g^\\ast}\\sigma_g}. $$\n如果 $\\sigma_g = 0$，则相关性未定义，该基因必须从相关性计算和后续评分中排除，以避免除以零。\n\n模块定义。对于一个阈值 $\\tau \\in [0,1]$，定义\n$$ M(\\tau) \\equiv \\{ g \\in G \\,:\\, r(g^\\ast,g) \\ge \\tau \\ \\text{and}\\ r(g^\\ast,g) > 0 \\} \\cup \\{ g^\\ast \\}, $$\n并移除其中任何方差为零的基因（如果存在）。正值约束确保了包含共同上调的基因，并排除了反向标记基因。种子基因 $g^\\ast$ 总是被包含，除非其方差为零；这保证了至少单基因基线是可用的。\n\n标准化与评分。对于每个保留的基因，计算其总体 $z$-分数\n$$ z_{g,c} \\equiv \\frac{X_{g,c} - \\mu_g}{\\sigma_g}. $$\n模块分数是标准化表达量的平均值\n$$ s_c \\equiv \\frac{1}{|M(\\tau)|}\\sum_{g \\in M(\\tau)} z_{g,c}, $$\n单基因基线是 $s_c^{(1)} \\equiv z_{g^\\ast,c}$。由于每个 $z_{g,\\cdot}$ 在所有细胞中的总体均值为 0，因此平均值 $s_c$ 的总体均值也为 0，所以一个自然的、用于分类的非参数阈值是在 0 处的符号检验：\n$$ \\widehat{y}^{(M)}_c \\equiv \\mathbb{I}[\\, s_c > 0 \\,], \\qquad \\widehat{y}^{(1)}_c \\equiv \\mathbb{I}[\\, s_c^{(1)} > 0 \\,]. $$\n\n性能量化。我们计算两个指标：\n1. 正确预测的数量\n   $$ N^{(M)} \\equiv \\sum_{c=1}^n \\mathbb{I}[\\, \\widehat{y}^{(M)}_c = y_c \\,], \\qquad N^{(1)} \\equiv \\sum_{c=1}^n \\mathbb{I}[\\, \\widehat{y}^{(1)}_c = y_c \\,]. $$\n   提升量为 $N^{(M)} - N^{(1)}$。\n2. 标准化均值差异（科恩 $d$ 值），反映了目标细胞与非目标细胞之间的分离度。对于任何分数向量 $u \\in \\mathbb{R}^n$，令 $S = \\{ c : y_c = 1 \\}$，$T = \\{ c : y_c = 0 \\}$，均值为 $\\overline{u}_S$、$\\overline{u}_T$，样本方差为 $s_S^2$、$s_T^2$（分母分别为 $n_S - 1$ 和 $n_T - 1$），合并标准差为\n   $$ s_p \\equiv \\sqrt{ \\frac{(n_S - 1)s_S^2 + (n_T - 1)s_T^2}{n_S + n_T - 2} }. $$\n   那么\n   $$ d(u) \\equiv \\frac{\\overline{u}_S - \\overline{u}_T}{s_p}. $$\n   我们报告单基因基线的 $d(s^{(1)})$ 和模块的 $d(s)$，均四舍五入到三位小数。\n\n每个数据集的算法步骤：\n- 为每个基因计算总体均值 $\\mu_g$ 和标准差 $\\sigma_g$；在相关性计算和评分中丢弃零方差基因。\n- 为所有方差不为零的基因 $g$ 计算总体皮尔逊相关性 $r(g^\\ast,g)$。\n- 通过包含 $g^\\ast$ 和所有满足 $r(g^\\ast,g) \\ge \\tau$ 且严格为正的基因来构建 $M(\\tau)$。\n- 为 $g \\in M(\\tau) \\cup \\{g^\\ast\\}$ 计算 $z_{g,c}$，然后计算 $s_c$ 和 $s_c^{(1)}$，接着计算 $\\widehat{y}^{(M)}_c$、$\\widehat{y}^{(1)}_c$、$N^{(M)}$、$N^{(1)}$ 以及 $d(s)$、$d(s^{(1)})$。\n\n测试套件预期：\n- 数据集 A 的 $\\tau = 0.6$，会产生一个有意义的模块，其中包含多个与 $g^\\ast = g_1$ 正共表达的基因，因此 $|M(\\tau)|$ 大于 1，且 $d(s)$ 和分类准确率都很高。\n- 数据集 B 使用与 A 相同的数据，但 $\\tau = 1.0$，因此只有 $g^\\ast$ 满足阈值（其他基因无法达到精确为 1 的相关性），因此 $|M(\\tau)| = 1$，$d(s) = d(s^{(1)})$ 且 $N^{(M)} - N^{(1)} = 0$。\n- 数据集 C 中，$g^\\ast$ 在一些目标细胞中出现 dropout，而其共表达伙伴基因则保持高表达。当 $\\tau = 0.3$ 时，至少有两个共表达基因会加入模块；对 $z$-分数求平均可以恢复目标细胞，从而相对于单基因基线，提升了 $d(s)$ 和 $N^{(M)} - N^{(1)}$。\n\n程序精确实现了这些步骤，并为数据集 A、B 和 C 分别打印了包含三个列表\n$$ \\big[\\, |M(\\tau)|,\\ \\mathrm{round}(d(s^{(1)}), 3),\\ \\mathrm{round}(d(s), 3),\\ N^{(M)} - N^{(1)} \\,\\big] $$\n的单行输出，这些列表按要求连接成一个逗号分隔且不含空格的列表。",
            "answer": "```python\nimport numpy as np\n\ndef population_mean_std(X, axis):\n    \"\"\"\n    Compute population mean and population standard deviation (ddof=0).\n    Returns (mean, std).\n    \"\"\"\n    mu = np.mean(X, axis=axis)\n    sigma = np.std(X, axis=axis, ddof=0)\n    return mu, sigma\n\ndef population_pearson_corr(x, Y):\n    \"\"\"\n    Compute population Pearson correlation between a 1D vector x (length n)\n    and each row of 2D array Y (m x n). Uses population std (ddof=0).\n    Returns a 1D array of length m with correlations; returns 0.0 for zero-variance rows.\n    \"\"\"\n    # Center x and Y\n    x = np.asarray(x, dtype=float)\n    Y = np.asarray(Y, dtype=float)\n    n = x.shape[0]\n    x_mu = np.mean(x)\n    x_std = np.std(x, ddof=0)\n    # Handle zero variance in x (rare by construction)\n    if x_std == 0:\n        return np.zeros(Y.shape[0], dtype=float)\n    Xc = x - x_mu\n    Y_mu = np.mean(Y, axis=1)\n    Y_std = np.std(Y, axis=1, ddof=0)\n    Yc = Y - Y_mu[:, None]\n    # Compute covariance: mean of product of centered variables\n    cov = (Yc @ Xc) / n  # shape (m,)\n    # Avoid division by zero: where Y_std==0 set corr to 0\n    denom = x_std * Y_std\n    with np.errstate(divide='ignore', invalid='ignore'):\n        r = np.where(denom > 0, cov / denom, 0.0)\n    return r\n\ndef build_module(X, seed_idx, tau):\n    \"\"\"\n    Build marker gene module M(tau) around seed gene index seed_idx with threshold tau.\n    Exclude genes with zero population variance from module and correlation.\n    Only include positively correlated genes with r >= tau.\n    Always include the seed gene unless its variance is zero.\n    Returns a sorted list of unique gene indices in the module.\n    \"\"\"\n    X = np.asarray(X, dtype=float)\n    p, n = X.shape\n    # Compute per-gene population std to filter zero-variance genes\n    mu_g = np.mean(X, axis=1)\n    std_g = np.std(X, axis=1, ddof=0)\n    nonzero_var = std_g > 0\n    # Compute correlations for eligible genes\n    r = population_pearson_corr(X[seed_idx, :], X)\n    module = set()\n    # Include genes with positive correlation >= tau and nonzero variance\n    for g in range(p):\n        if nonzero_var[g] and (g == seed_idx or (r[g] > 0 and r[g] >= tau)):\n            module.add(g)\n    # Ensure seed inclusion if it has nonzero variance; if zero, exclude to avoid div-by-zero\n    if nonzero_var[seed_idx]:\n        module.add(seed_idx)\n    else:\n        module.discard(seed_idx)\n    # Remove any zero-variance genes (safety)\n    module = [g for g in module if nonzero_var[g]]\n    module.sort()\n    return module\n\ndef z_scores(X):\n    \"\"\"\n    Compute population z-scores per gene across cells.\n    X is (p x n). Returns Z of same shape.\n    For zero-variance genes, set z-scores to 0 (they will be excluded upstream anyway).\n    \"\"\"\n    mu, sigma = population_mean_std(X, axis=1)\n    # Avoid division by zero: where sigma==0, set to 1 to produce zeros\n    sigma_safe = np.where(sigma == 0, 1.0, sigma)\n    Z = (X - mu[:, None]) / sigma_safe[:, None]\n    return Z, mu, sigma\n\ndef cohen_d(u, y):\n    \"\"\"\n    Compute Cohen's d between groups y==1 and y==0 using pooled sample standard deviation.\n    u: 1D array of scores length n\n    y: 1D array of 0/1 labels length n\n    Returns float d. Assumes both groups have at least 2 samples and nonzero pooled variance.\n    \"\"\"\n    u = np.asarray(u, dtype=float)\n    y = np.asarray(y, dtype=int)\n    S = (y == 1)\n    T = (y == 0)\n    uS = u[S]\n    uT = u[T]\n    nS = uS.size\n    nT = uT.size\n    mS = np.mean(uS) if nS > 0 else 0.0\n    mT = np.mean(uT) if nT > 0 else 0.0\n    # Sample variances\n    sS2 = np.var(uS, ddof=1) if nS > 1 else 0.0\n    sT2 = np.var(uT, ddof=1) if nT > 1 else 0.0\n    # Pooled standard deviation\n    denom_df = (nS + nT - 2)\n    if denom_df <= 0:\n        sp = 0.0\n    else:\n        sp = np.sqrt(((nS - 1) * sS2 + (nT - 1) * sT2) / denom_df)\n    if sp == 0.0:\n        return 0.0\n    return (mS - mT) / sp\n\ndef evaluate_dataset(X, y, seed_idx, tau):\n    \"\"\"\n    For a dataset (X, y), seed gene index, and threshold tau:\n    - Build module\n    - Compute z-scores\n    - Compute module score and single-gene score\n    - Classify with threshold > 0\n    - Count correct predictions\n    - Compute Cohen's d for both scores\n    Returns [module_size, d_single_rounded, d_module_rounded, improvement_int]\n    \"\"\"\n    X = np.asarray(X, dtype=float)\n    y = np.asarray(y, dtype=int)\n    p, n = X.shape\n    module = build_module(X, seed_idx, tau)\n    Z, _, _ = z_scores(X)\n    # Single-gene score\n    s_single = Z[seed_idx, :]\n    # Module score: average across genes in module\n    if len(module) == 0:\n        s_module = s_single.copy()\n    else:\n        s_module = np.mean(Z[module, :], axis=0)\n    # Predictions with threshold > 0\n    yhat_single = (s_single > 0).astype(int)\n    yhat_module = (s_module > 0).astype(int)\n    correct_single = int(np.sum(yhat_single == y))\n    correct_module = int(np.sum(yhat_module == y))\n    # Effect sizes\n    d_single = cohen_d(s_single, y)\n    d_module = cohen_d(s_module, y)\n    # Round to 3 decimals for reporting\n    d_single_r = round(float(d_single), 3)\n    d_module_r = round(float(d_module), 3)\n    improvement = int(correct_module - correct_single)\n    return [len(module), d_single_r, d_module_r, improvement]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Dataset A\n    XA = np.array([\n        [10, 11,  9, 10, 1, 2, 1, 1],\n        [ 9, 10,  8,  9, 1, 1, 2, 1],\n        [ 1,  1,  1,  2, 9, 8,10, 9],\n        [ 1,  2,  1,  1, 8, 9, 9, 8],\n        [ 2,  1,  2,  2, 2, 2, 1, 2],\n        [ 6,  7,  5,  6, 1, 1, 1, 2]\n    ], dtype=float)\n    yA = np.array([1,1,1,1,0,0,0,0], dtype=int)\n    seed_idx = 0  # g1\n    tauA = 0.6\n\n    # Dataset B (same X and y, higher tau)\n    XB = XA.copy()\n    yB = yA.copy()\n    tauB = 1.0\n\n    # Dataset C\n    XC = np.array([\n        [0, 0, 8, 1, 1, 1],\n        [7, 6, 7, 1, 1, 1],\n        [1, 1, 1, 6, 7, 6],\n        [1, 1, 1, 5, 6, 5],\n        [2, 2, 2, 2, 2, 2],\n        [5, 5, 6, 1, 1, 1]\n    ], dtype=float)\n    yC = np.array([1,1,1,0,0,0], dtype=int)\n    tauC = 0.3\n\n    test_cases = [\n        (XA, yA, seed_idx, tauA),\n        (XB, yB, seed_idx, tauB),\n        (XC, yC, seed_idx, tauC),\n    ]\n\n    results = []\n    for X, y, seed, tau in test_cases:\n        res = evaluate_dataset(X, y, seed, tau)\n        results.append(res)\n\n    # Final print statement in the exact required format (no spaces).\n    # Example: [[a1,b1,c1,d1],[a2,b2,c2,d2],[a3,b3,c3,d3]]\n    # Convert to string without spaces.\n    def to_str_list(lst):\n        return \"[\" + \",\".join(str(x) for x in lst) + \"]\"\n    output = \"[\" + \",\".join(to_str_list(r) for r in results) + \"]\"\n    print(output)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}