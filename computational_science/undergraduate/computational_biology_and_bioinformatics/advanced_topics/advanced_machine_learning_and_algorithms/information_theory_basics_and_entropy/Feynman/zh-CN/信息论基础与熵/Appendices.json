{
    "hands_on_practices": [
        {
            "introduction": "想象一下，整个人体是由海量细胞组成的集合。要确定其中一个随机细胞的类型，需要多少信息呢？这个练习将让你亲手计算一个（简化的）生物系统中信息的基本量。通过应用香农熵（Shannon entropy）的定义来处理一个假设的细胞类型分布，你将直接体会到熵是如何用“比特”来量化不确定性的 。",
            "id": "2399729",
            "problem": "一份健康成年人单细胞RNA测序（scRNA-seq）图谱汇总了所有器官的细胞计数，并将每个细胞分配到八个大的细胞类型类别中。将从该全身图谱中随机抽样的细胞类型视为一个离散随机变量。在本练习中，假设该图谱估计了这八个类别的以下分数（每个值都是一个概率，且列表总和为 $1$）：\n- 红细胞：$0.80$\n- 中性粒细胞：$0.05$\n- 淋巴细胞：$0.04$\n- 内皮细胞：$0.03$\n- 上皮细胞：$0.03$\n- 成纤维细胞：$0.025$\n- 肝细胞：$0.015$\n- 神经元：$0.01$\n\n仅使用信息论中自信息和离散随机变量熵的基本定义，推导从该图谱中随机抽取一个细胞时，指定其细胞类型所需的二进制数字的期望数量。最终答案以比特（bits）为单位，并四舍五入到四位有效数字。",
            "solution": "题目断言，仅使用信息论中自信息和离散随机变量熵的基本定义即可解决此问题。我将验证这一说法。\n问题要求计算指定一个随机抽样细胞的类型所需的二进制数字的期望数量。在信息论的框架下，这个量正是细胞类型概率分布的香农熵，其单位为比特（bits）。\n\n设 $X$ 是一个表示细胞类型的离散随机变量。$X$ 的可能结果集合为 $\\mathcal{X} = \\{x_1, x_2, \\dots, x_8\\}$，其中每个 $x_i$ 对应八种指定细胞类型之一。题目给出了每个状态 $x_i$ 的概率质量函数 $P(X=x_i) = p_i$。给定的概率如下：\n- $p_1 = P(x_1=\\text{红细胞}) = 0.80$\n- $p_2 = P(x_2=\\text{中性粒细胞}) = 0.05$\n- $p_3 = P(x_3=\\text{淋巴细胞}) = 0.04$\n- $p_4 = P(x_4=\\text{内皮细胞}) = 0.03$\n- $p_5 = P(x_5=\\text{上皮细胞}) = 0.03$\n- $p_6 = P(x_6=\\text{成纤维细胞}) = 0.025$\n- $p_7 = P(x_7=\\text{肝细胞}) = 0.015$\n- $p_8 = P(x_8=\\text{神经元}) = 0.01$\n\n这些概率总和为1是一个必要条件：$\\sum_{i=1}^{8} p_i = 0.80 + 0.05 + 0.04 + 0.03 + 0.03 + 0.025 + 0.015 + 0.01 = 1.00$。此条件已满足。\n\n自信息（或称“惊奇度”）的基本定义量化了单个特定结果的信息内容。对于一个概率为 $p_i$ 的结果 $x_i$，其自信息 $I(x_i)$ 定义为：\n$$I(x_i) = -\\log_b(p_i)$$\n对数的底 $b$ 决定了信息的单位。题目要求结果以“二进制数字”表示，这对应于单位“比特”（bits）。这要求使用以2为底的对数，即 $b=2$。因此，结果 $x_i$ 的自信息为：\n$$I(x_i) = -\\log_2(p_i)$$\n\n离散随机变量 $X$ 的熵，记为 $H(X)$，定义为在所有可能结果上计算的自信息的期望值。它代表了该分布的平均信息内容，等同于对该随机变量的结果进行最优编码所需的平均比特数。其定义为：\n$$H(X) = E[I(X)] = \\sum_{i \\in \\mathcal{X}} P(X=x_i) I(x_i)$$\n将 $P(X=x_i)$ 和 $I(x_i)$ 的具体定义代入，得到香农熵的公式：\n$$H(X) = \\sum_{i=1}^{8} p_i (-\\log_2(p_i)) = -\\sum_{i=1}^{8} p_i \\log_2(p_i)$$\n这正是我们必须计算的量。\n\n我们将给定的数值概率代入熵公式：\n$$H(X) = - \\left[ 0.80 \\log_2(0.80) + 0.05 \\log_2(0.05) + 0.04 \\log_2(0.04) + 2 \\times (0.03 \\log_2(0.03)) + 0.025 \\log_2(0.025) + 0.015 \\log_2(0.015) + 0.01 \\log_2(0.01) \\right]$$\n我们计算每一项 $p_i \\log_2(p_i)$ 的值：\n- $0.80 \\log_2(0.80) \\approx 0.80 \\times (-0.321928) \\approx -0.257542$\n- $0.05 \\log_2(0.05) \\approx 0.05 \\times (-4.321928) \\approx -0.216096$\n- $0.04 \\log_2(0.04) \\approx 0.04 \\times (-4.643856) \\approx -0.185754$\n- $0.03 \\log_2(0.03) \\approx 0.03 \\times (-5.058894) \\approx -0.151767$\n- $0.025 \\log_2(0.025) \\approx 0.025 \\times (-5.321928) \\approx -0.133048$\n- $0.015 \\log_2(0.015) \\approx 0.015 \\times (-6.058894) \\approx -0.090883$\n- $0.01 \\log_2(0.01) \\approx 0.01 \\times (-6.643856) \\approx -0.066439$\n\n现在，我们将这些值相加，并应用公式中的负号：\n$$H(X) \\approx - [ -0.257542 - 0.216096 - 0.185754 + 2 \\times (-0.151767) - 0.133048 - 0.090883 - 0.066439 ]$$\n$$H(X) \\approx - [ -0.257542 - 0.216096 - 0.185754 - 0.303534 - 0.133048 - 0.090883 - 0.066439 ]$$\n$$H(X) \\approx - [ -1.253296 ]$$\n$$H(X) \\approx 1.253296 \\text{ 比特}$$\n题目要求最终答案四舍五入到四位有效数字。前四位有效数字是 $1$、$2$、$5$ 和 $3$。第五位是 $2$，所以我们向下舍入。\n$$H(X) \\approx 1.253 \\text{ 比特}$$\n这个值代表了对从该图谱中随机抽取的细胞的类型进行编码所需的平均比特数的理论下限。",
            "answer": "$$\n\\boxed{1.253}\n$$"
        },
        {
            "introduction": "蛋白质是细胞功能的执行者，但构成它们的氨基酸是被平等使用的吗？本练习将引导你从手动计算转向一项核心的生物信息学技能：编写代码来计算生物序列的经验熵（empirical entropy）。你将实现熵的公式，并用它来比较一种真实蛋白质（肌联蛋白，titin）与理论上的随机序列在氨基酸组成上的差异。这个过程不仅能让你掌握如何量化序列的复杂性，还能揭示生物进化选择是如何降低蛋白质组成的“随机性”的 。",
            "id": "2399685",
            "problem": "你的任务是编写一个程序，该程序使用在序列中观察到的经验氨基酸频率分布，计算并比较氨基酸序列的香农熵，结果以每个残基的比特数表示。计算必须基于第一性原理：对于一个由 $20$ 种标准氨基酸组成的序列，设字母表为 $\\{ \\text{A}, \\text{C}, \\text{D}, \\text{E}, \\text{F}, \\text{G}, \\text{H}, \\text{I}, \\text{K}, \\text{L}, \\text{M}, \\text{N}, \\text{P}, \\text{Q}, \\text{R}, \\text{S}, \\text{T}, \\text{V}, \\text{W}, \\text{Y} \\}$。给定每种氨基酸 $a$ 的非负整数计数 $\\{c_a\\}_{a}$，其总和为序列长度 $N = \\sum_a c_a$，定义经验概率为 $p_a = c_a / N$。香农熵（以每个残基的比特数计）为\n$$\nH = - \\sum_{a} p_a \\log_2 p_a,\n$$\n约定当 $p_a = 0$ 时，该项贡献为 $0$，因为 $0 \\log_2 0$ 定义为 $0$。所有对数均以 $2$ 为底，最终的熵单位是“比特/残基”。\n\n你的程序必须为以下每个测试用例计算 $H$，每个用例都由氨基酸计数指定，这些计数应被视为精确值。所有序列长度和计数均为整数，必须按给定的数值精确解释。\n\n测试套件（以浮点数形式提供熵，四舍五入到小数点后恰好 $6$ 位）：\n- 案例 $1$ （在长度 $100$ 上实例化的独立同分布（i.i.d.）均匀模型）：一个包含 $100$ 个残基的多重集，在 $20$ 种氨基酸上呈完全均匀分布，即对每种氨基酸 $a \\in \\{\\text{A},\\text{C},\\text{D},\\text{E},\\text{F},\\text{G},\\text{H},\\text{I},\\text{K},\\text{L},\\text{M},\\text{N},\\text{P},\\text{Q},\\text{R},\\text{S},\\text{T},\\text{V},\\text{W},\\text{Y}\\}$ 都有 $c_a = 5$，因此 $N = 100$。\n- 案例 $2$ （人类 titin，提供典型计数）：使用以下 Homo sapiens titin 蛋白的典型氨基酸计数来定义 $p_a = c_a / N$，其中 $N = 34350$，\n  $\\text{A}: 1900,\\ \\text{C}: 250,\\ \\text{D}: 1900,\\ \\text{E}: 3200,\\ \\text{F}: 850,\\ \\text{G}: 2100,\\ \\text{H}: 450,\\ \\text{I}: 2100,\\ \\text{K}: 3250,\\ \\text{L}: 2500,\\ \\text{M}: 500,\\ \\text{N}: 1400,\\ \\text{P}: 3400,\\ \\text{Q}: 1300,\\ \\text{R}: 1300,\\ \\text{S}: 2100,\\ \\text{T}: 1900,\\ \\text{V}: 3200,\\ \\text{W}: 150,\\ \\text{Y}: 600$。这些计数的总和为 $34350$。\n- 案例 $3$ （边界情况，零熵）：一个长度为 $100$ 的均聚物，其计数为 $\\text{A}: 100$ 且 $\\text{C}=\\text{D}=\\text{E}=\\text{F}=\\text{G}=\\text{H}=\\text{I}=\\text{K}=\\text{L}=\\text{M}=\\text{N}=\\text{P}=\\text{Q}=\\text{R}=\\text{S}=\\text{T}=\\text{V}=\\text{W}=\\text{Y}: 0$，因此 $N=100$。\n- 案例 $4$ （边缘情况，长度为 $100$ 的高度偏斜二元组分）：计数为 $\\text{A}: 99,\\ \\text{G}: 1$，所有其他氨基酸均为 $0$，因此 $N=100$。\n\n你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果按上述案例的顺序排列。每个熵值必须四舍五入到小数点后恰好 $6$ 位。例如，一个包含四个结果的输出必须像\n\"[h1,h2,h3,h4]\"\n这样，其中每个 $h_i$ 是一个小数点后恰好有 $6$ 位的小数。不应打印任何其他文本。不涉及物理单位，也不涉及角度单位。不得使用百分比；所有量都按定义以小数表示。",
            "solution": "我们旨在通过将香农熵的定义直接应用于从整数计数中导出的经验氨基酸频率，来计算以“比特/残基”为单位的香农熵。设序列长度为 $N = \\sum_{a} c_a$，其中 $c_a \\ge 0$ 是标准 $20$ 字母氨基酸字母表 $\\{\\text{A},\\text{C},\\text{D},\\text{E},\\text{F},\\text{G},\\text{H},\\text{I},\\text{K},\\text{L},\\text{M},\\text{N},\\text{P},\\text{Q},\\text{R},\\text{S},\\text{T},\\text{V},\\text{W},\\text{Y}\\}$ 中氨基酸 $a$ 的计数。字母 $a$ 的经验概率为 $p_a = c_a / N$。以比特为单位的香农熵定义为\n$$\nH = - \\sum_{a} p_a \\log_2 p_a,\n$$\n遵循约定 $0 \\log_2 0 = 0$，这在数学上可以通过极限 $\\lim_{x \\to 0^+} x \\log_2 x = 0$ 来证明是合理的。\n\n计算 $H$ 的基于原理的步骤：\n1. 计算总长度 $N = \\sum_{a} c_a$。这是获取归一化常数所需的基础计数聚合。\n2. 对每种氨基酸 $a$，计算经验概率 $p_a = c_a / N$。这是相对频率定义的直接应用。\n3. 对每个 $p_a > 0$ 的氨基酸，计算其贡献 $- p_a \\log_2 p_a$，然后在整个字母表上求和。当 $p_a = 0$ 时，跳过该项，以实现 $0 \\log_2 0 = 0$ 的约定。\n4. 结果 $H$ 的单位是“比特/残基”。\n\n应用于测试套件：\n- 案例 $1$：在 $20$ 个字母上的计数完全均匀，即 $c_a = 5$ 且 $N = 100$，因此对所有 $a$ 都有 $p_a = 5/100 = 1/20$。代入定义可得\n  $$\n  H = - \\sum_{a=1}^{20} \\frac{1}{20} \\log_2 \\left(\\frac{1}{20}\\right) = - 20 \\cdot \\frac{1}{20} \\cdot \\log_2 \\left(\\frac{1}{20}\\right) = \\log_2(20).\n  $$\n  这可作为 $20$ 字母表上最大混合分布的参考。\n- 案例 $2$：对于人类 titin，我们获得了总和为 $N = 34350$ 的典型计数。我们使用提供的计数为每种氨基酸 $a$ 计算 $p_a = c_a / 34350$，然后计算\n  $$\n  H = - \\sum_{a} \\left(\\frac{c_a}{34350}\\right) \\log_2 \\left(\\frac{c_a}{34350}\\right).\n  $$\n  这将得出所提供的 titin 组分的经验每残基熵（以比特计）。\n- 案例 $3$：均聚物的所有质量都集中在一个字母上：$p_{\\text{A}} = 100/100 = 1$，且对于 $a \\ne \\text{A}$ 有 $p_a = 0$。熵计算为\n  $$\n  H = - 1 \\cdot \\log_2(1) + \\sum_{a \\ne \\text{A}} 0 = 0,\n  $$\n  因为 $\\log_2(1) = 0$。\n- 案例 $4$：一个长度为 $100$ 的高度偏斜二元组分，其 $p_{\\text{A}} = 99/100$ 和 $p_{\\text{G}} = 1/100$，而所有其他项均为 $0$。其熵为\n  $$\n  H = - \\frac{99}{100} \\log_2 \\left(\\frac{99}{100}\\right) - \\frac{1}{100} \\log_2 \\left(\\frac{1}{100}\\right),\n  $$\n  这是一个小的正数，反映了低可变性。在数值上，这接近于 $p = 0.99$ 时的二元熵。\n\n反映这些原理的算法设计：\n- 将字母表表示为包含 $20$ 种标准氨基酸的固定有序列表，以确保对零计数的一致处理。\n- 对每个测试用例，将计数存储在从氨基酸到 $c_a$ 的映射中，计算 $N$，然后计算 $p_a$，并仅对 $p_a > 0$ 的项累加 $- p_a \\log_2 p_a$。\n- 使用以 $2$ 为底的对数以生成以比特为单位的熵，并将最终结果四舍五入到小数点后恰好 $6$ 位，以匹配指定的输出格式。\n- 按规定顺序将四个结果聚合到一个列表中，并以所需格式单行打印。\n\n此方法严格遵循香农熵的定义，正确处理零概率，并为所有提供的案例生成可复现的数值输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef shannon_entropy_bits(counts_dict, alphabet):\n    \"\"\"\n    Compute Shannon entropy H = -sum p * log2 p in bits per residue\n    from integer counts over a fixed alphabet. Counts may include zeros.\n    \"\"\"\n    counts = np.array([counts_dict.get(a, 0) for a in alphabet], dtype=np.float64)\n    total = counts.sum()\n    if total <= 0:\n        # Degenerate case: no residues; define entropy as 0.0\n        return 0.0\n    p = counts / total\n    # Mask zero probabilities to avoid log2(0)\n    mask = p > 0\n    H = -np.sum(p[mask] * np.log2(p[mask]))\n    return float(H)\n\ndef solve():\n    # Define the standard 20-amino-acid alphabet in a fixed order.\n    alphabet = list(\"ACDEFGHIKLMNPQRSTVWY\")\n\n    # Test Case 1: Uniform over 20 amino acids, length 100 -> 5 of each.\n    counts_case1 = {a: 5 for a in alphabet}  # sums to 100\n\n    # Test Case 2: Human titin canonical counts provided (sum to 34350).\n    counts_case2 = {\n        'A': 1900, 'C': 250,  'D': 1900, 'E': 3200, 'F': 850,\n        'G': 2100, 'H': 450,  'I': 2100, 'K': 3250, 'L': 2500,\n        'M': 500,  'N': 1400, 'P': 3400, 'Q': 1300, 'R': 1300,\n        'S': 2100, 'T': 1900, 'V': 3200, 'W': 150,  'Y': 600\n    }\n\n    # Test Case 3: Homopolymer of length 100 (all A).\n    counts_case3 = {a: 0 for a in alphabet}\n    counts_case3['A'] = 100\n\n    # Test Case 4: Skewed binary composition at length 100: A:99, G:1.\n    counts_case4 = {a: 0 for a in alphabet}\n    counts_case4['A'] = 99\n    counts_case4['G'] = 1\n\n    test_cases = [counts_case1, counts_case2, counts_case3, counts_case4]\n\n    results = []\n    for counts in test_cases:\n        H = shannon_entropy_bits(counts, alphabet)\n        results.append(f\"{H:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "我们肠道微生物组的构成会发生剧烈变化，例如在抗生素治疗后。我们如何定量地衡量这种变化的程度？这个实践引入了一个更高级的工具——库尔贝克-莱布勒散度（Kullback-Leibler (KL) divergence），它衡量从一个概率分布到另一个的“距离”或信息增益。通过编写代码计算治疗前后微生物组分布之间的KL散度，你将学会一种强大的方法来比较生物状态和量化生态系统层面的变化 。",
            "id": "2399737",
            "problem": "一位患者的肠道微生物组组成在两个时间点进行了分析：抗生素治疗前和治疗后。每个分析结果都通过分配给同一组分类单元的测序读数计数来概括，从而产生两个非负整数向量，这些向量可被视为关于分类单元的经验分布。设治疗前的计数向量为 $\\mathbf{x} \\in \\mathbb{N}_0^m$，治疗后的计数向量为 $\\mathbf{y} \\in \\mathbb{N}_0^m$，其中 $m$ 是分类单元的数量，第 $i$ 个条目是第 $i$ 个分类单元的计数。对于给定的加性平滑参数 $\\lambda \\geq 0$，平滑后的相对丰度分布 $\\mathbf{p}$ 和 $\\mathbf{q}$ 定义如下：\n$$\np_i \\;=\\; \\frac{x_i + \\lambda}{\\sum_{j=1}^{m} (x_j + \\lambda)} \\quad \\text{and} \\quad q_i \\;=\\; \\frac{y_i + \\lambda}{\\sum_{j=1}^{m} (y_j + \\lambda)} \\quad \\text{for } i=1,\\dots,m.\n$$\n使用自然对数，从 $\\mathbf{p}$ 到 $\\mathbf{q}$ 的 Kullback–Leibler 散度（Kullback–Leibler (KL) 散度）以奈特（nats）为单位，定义为：\n$$\nD_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) \\;=\\; \\sum_{i=1}^{m} p_i \\,\\ln\\!\\left(\\frac{p_i}{q_i}\\right).\n$$\n假设向量 $\\mathbf{x}$ 和 $\\mathbf{y}$ 以相同的顺序列出相同的分类单元。对于下方的每个测试用例，使用指定的 $\\lambda$ 计算 $D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q})$，并将每个结果表示为四舍五入到 $6$ 位小数的实数。\n\n测试套件：\n- 用例 $1$：$m = 2$, $\\mathbf{x} = (2,2)$, $\\mathbf{y} = (2,2)$, $\\lambda = 0.5$。\n- 用例 $2$：$m = 2$, $\\mathbf{x} = (3,1)$, $\\mathbf{y} = (2,2)$, $\\lambda = 0$。\n- 用例 $3$：$m = 2$, $\\mathbf{x} = (1,0)$, $\\mathbf{y} = (0,1)$, $\\lambda = 0.5$。\n- 用例 $4$：$m = 2$, $\\mathbf{x} = (1,1)$, $\\mathbf{y} = (0,2)$, $\\lambda = 0.5$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序与测试用例相同（例如，$[r_1,r_2,r_3,r_4]$），每个 $r_k$ 都四舍五入到 $6$ 位小数，且不含空格。",
            "solution": "所提出的问题要求计算从微生物组计数数据派生的两个平滑概率分布之间的 Kullback-Leibler (KL) 散度。在进行求解之前，有必要对问题陈述进行严格的验证。\n\n### 步骤1：提取已知信息\n问题提供了以下数据和定义：\n- 治疗前计数向量：$\\mathbf{x} \\in \\mathbb{N}_0^m$。\n- 治疗后计数向量：$\\mathbf{y} \\in \\mathbb{N}_0^m$。\n- 分类单元数量：$m$。\n- 加性平滑参数：$\\lambda \\geq 0$。\n- 平滑后的相对丰度分布 $\\mathbf{p}$：$p_i = \\frac{x_i + \\lambda}{\\sum_{j=1}^{m} (x_j + \\lambda)}$。\n- 平滑后的相对丰度分布 $\\mathbf{q}$：$q_i = \\frac{y_i + \\lambda}{\\sum_{j=1}^{m} (y_j + \\lambda)}$。\n- 使用自然对数，从 $\\mathbf{p}$ 到 $\\mathbf{q}$ 的 Kullback-Leibler 散度：$D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) = \\sum_{i=1}^{m} p_i \\,\\ln\\!\\left(\\frac{p_i}{q_i}\\right)$。\n- 测试套件：\n    - 用例 $1$：$m = 2$, $\\mathbf{x} = (2,2)$, $\\mathbf{y} = (2,2)$, $\\lambda = 0.5$。\n    - 用例 $2$：$m = 2$, $\\mathbf{x} = (3,1)$, $\\mathbf{y} = (2,2)$, $\\lambda = 0$。\n    - 用例 $3$：$m = 2$, $\\mathbf{x} = (1,0)$, $\\mathbf{y} = (0,1)$, $\\lambda = 0.5$。\n    - 用例 $4$：$m = 2$, $\\mathbf{x} = (1,1)$, $\\mathbf{y} = (0,2)$, $\\lambda = 0.5$。\n\n### 步骤2：使用提取的已知信息进行验证\n根据既定标准对问题进行评估：\n- **科学依据**：该问题基于计算生物学和信息论中标准且成熟的概念。使用计数向量表示微生物组组成、应用加性（拉普拉斯）平滑处理零计数，以及计算 KL 散度来衡量概率分布之间的差异，都是该领域的常规程序。所用公式是正确且标准的。\n- **适定性**：该问题是适定的。对于每个测试用例，都提供了所有必要的输入（$\\mathbf{x}$、$\\mathbf{y}$、$\\lambda$）。用于计算 $\\mathbf{p}$、$\\mathbf{q}$ 和 $D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q})$ 的函数都有明确定义。对于给定的用例，KL 散度是良定义的。当 $\\lambda > 0$（用例 $1$、$3$、$4$）时，$\\mathbf{p}$ 和 $\\mathbf{q}$ 的所有分量都严格为正，因此项 $\\ln(p_i/q_i)$ 始终有定义。对于用例 $2$，其中 $\\lambda = 0$，计数向量 $\\mathbf{y}=(2,2)$ 没有零项，这确保了分布 $\\mathbf{q}$ 的所有分量都严格为正，再次避免了除以零或对零取对数的情况。因此，该问题规范在数学上是合理的。\n- **客观性**：该问题使用精确、客观的数学语言陈述。没有主观或模糊的术语。\n\n该问题没有表现出任何诸如科学上不合理、不完整、矛盾或不可行之类的缺陷。\n\n### 步骤3：结论与行动\n该问题被认定为**有效**。将推导解决方案。\n\n每个测试用例的计算过程如下：\n$1$. 给定计数向量 $\\mathbf{x}$、计数向量 $\\mathbf{y}$ 和平滑参数 $\\lambda$。\n$2$. 计算平滑后的计数向量 $\\mathbf{x}' = \\mathbf{x} + \\lambda$ 和 $\\mathbf{y}' = \\mathbf{y} + \\lambda$。\n$3$. 计算平滑后总计数 $S_x = \\sum_j x'_j$ 和 $S_y = \\sum_j y'_j$。\n$4$. 归一化以获得概率分布 $\\mathbf{p} = \\mathbf{x}' / S_x$ 和 $\\mathbf{q} = \\mathbf{y}' / S_y$。\n$5$. 计算 KL 散度 $D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) = \\sum_{i=1}^{m} p_i \\ln(p_i/q_i)$。\n$6$. 将最终数值结果四舍五入到 $6$ 位小数。\n\n让我们演示用例 $3$ 的计算过程：$m = 2$, $\\mathbf{x} = (1,0)$, $\\mathbf{y} = (0,1)$, $\\lambda = 0.5$。\n- $\\mathbf{x}$ 的平滑后计数向量：$(1+0.5, 0+0.5) = (1.5, 0.5)$。\n- 平滑后总计数 $S_x = 1.5 + 0.5 = 2.0$。\n- 平滑后分布 $\\mathbf{p}$：$(1.5/2.0, 0.5/2.0) = (0.75, 0.25)$。\n- $\\mathbf{y}$ 的平滑后计数向量：$(0+0.5, 1+0.5) = (0.5, 1.5)$。\n- 平滑后总计数 $S_y = 0.5 + 1.5 = 2.0$。\n- 平滑后分布 $\\mathbf{q}$：$(0.5/2.0, 1.5/2.0) = (0.25, 0.75)$。\n- KL 散度为：\n$$ D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) = p_1 \\ln\\left(\\frac{p_1}{q_1}\\right) + p_2 \\ln\\left(\\frac{p_2}{q_2}\\right) $$\n$$ D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) = 0.75 \\ln\\left(\\frac{0.75}{0.25}\\right) + 0.25 \\ln\\left(\\frac{0.25}{0.75}\\right) $$\n$$ D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) = 0.75 \\ln(3) + 0.25 \\ln(1/3) $$\n$$ D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) = 0.75 \\ln(3) - 0.25 \\ln(3) = 0.5 \\ln(3) $$\n使用值 $\\ln(3) \\approx 1.09861228867$，我们得到：\n$$ D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) \\approx 0.5 \\times 1.09861228867 \\approx 0.54930614433 $$\n四舍五入到 $6$ 位小数，结果是 $0.549306$。\n\n对所有测试用例应用相同的过程。\n- **用例 1**：$\\mathbf{x}=(2,2)$, $\\mathbf{y}=(2,2)$, $\\lambda=0.5$。此时，$\\mathbf{p} = \\mathbf{q} = (0.5, 0.5)$。因此，$D_{\\mathrm{KL}}(\\mathbf{p}\\,\\|\\,\\mathbf{q}) = \\sum p_i \\ln(1) = 0$。结果：$0.000000$。\n- **用例 2**：$\\mathbf{x}=(3,1)$, $\\mathbf{y}=(2,2)$, $\\lambda=0$。此时，$\\mathbf{p}=(0.75, 0.25)$ 且 $\\mathbf{q}=(0.5, 0.5)$。$D_{\\mathrm{KL}} = 0.75 \\ln(0.75/0.5) + 0.25 \\ln(0.25/0.5) \\approx 0.130812$。\n- **用例 4**：$\\mathbf{x}=(1,1)$, $\\mathbf{y}=(0,2)$, $\\lambda=0.5$。此时，$\\mathbf{p}=(0.5, 0.5)$ 且 $\\mathbf{q}=(0.5/3, 2.5/3) \\approx (0.1667, 0.8333)$。$D_{\\mathrm{KL}} = 0.5 \\ln(0.5 / (0.5/3)) + 0.5 \\ln(0.5 / (2.5/3)) \\approx 0.293893$。\n\n该实现将使用数值库以确保精度和效率。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Kullback-Leibler divergence for given microbiome count vectors.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (x_counts, y_counts, lambda_val)\n        (np.array([2, 2]), np.array([2, 2]), 0.5),\n        (np.array([3, 1]), np.array([2, 2]), 0.0),\n        (np.array([1, 0]), np.array([0, 1]), 0.5),\n        (np.array([1, 1]), np.array([0, 2]), 0.5),\n    ]\n\n    results = []\n    for x_counts, y_counts, lambda_val in test_cases:\n        # Step 1: Apply additive smoothing to the count vectors.\n        # x_i + lambda\n        smoothed_x = x_counts + lambda_val\n        # y_i + lambda\n        smoothed_y = y_counts + lambda_val\n\n        # Step 2: Compute the total sum for normalization.\n        # sum_j(x_j + lambda)\n        total_x = np.sum(smoothed_x)\n        # sum_j(y_j + lambda)\n        total_y = np.sum(smoothed_y)\n        \n        # Step 3: Compute the smoothed relative abundance distributions p and q.\n        # p_i = (x_i + lambda) / sum_j(x_j + lambda)\n        p = smoothed_x / total_x\n        # q_i = (y_i + lambda) / sum_j(y_j + lambda)\n        q = smoothed_y / total_y\n\n        # Step 4: Compute the KL divergence D_KL(p || q).\n        # The term p_i * log(p_i/q_i) is 0 if p_i is 0.\n        # The sum is over non-zero elements of p.\n        # Given the problem constraints (lambda >= 0), and specifically\n        # for these test cases, p_i and q_i are always > 0,\n        # so we do not need to handle p_i=0 cases explicitly.\n        kl_divergence = np.sum(p * np.log(p / q))\n        \n        # Step 5: Round the result to 6 decimal places.\n        rounded_result = round(kl_divergence, 6)\n        results.append(f\"{rounded_result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}