{
    "hands_on_practices": [
        {
            "introduction": "In biological networks, a node's importance can be multifaceted, and distinguishing between different roles is key to understanding function. This exercise  introduces a fundamental distinction between \"hubs,\" which have high local connectivity (degree), and \"bottlenecks,\" which are crucial for global communication (betweenness). By calculating a simple discrepancy score that weighs these two properties, you will practice classifying proteins and gain a quantitative understanding of how these distinct topological roles contribute to network architecture.",
            "id": "2409607",
            "problem": "In a Protein–Protein Interaction (PPI) network modeled as an undirected, unweighted graph, the degree centrality of node $i$ is the number of its interaction partners, and the betweenness centrality of node $i$ is the fraction of all shortest paths in the network that pass through $i$. Let $D_i$ denote the degree centrality of node $i$ normalized to the interval $[0,1]$ (for example, by dividing by the maximum degree), and let $B_i$ denote the betweenness centrality of node $i$ normalized to the interval $[0,1]$ (for example, by dividing by the maximum possible betweenness in the network). Consider the hub–bottleneck discrepancy score\n$$\nS_i \\;=\\; k_d \\cdot D_i \\;-\\; k_b \\cdot B_i,\n$$\nwhere $k_d>0$ and $k_b>0$ are user-chosen weights that quantify the relative emphasis placed on hubness and bottleneckness, respectively. Larger positive $S_i$ indicates greater hub dominance relative to bottleneckness under the chosen weights, while more negative $S_i$ indicates greater bottleneck dominance relative to hubness.\n\nSuppose $k_d = 1.0$ and $k_b = 1.5$. For four proteins $P_1, P_2, P_3, P_4$, the normalized centralities are:\n- $P_1$: $D_1 = 0.80$, $B_1 = 0.20$.\n- $P_2$: $D_2 = 0.30$, $B_2 = 0.60$.\n- $P_3$: $D_3 = 0.70$, $B_3 = 0.70$.\n- $P_4$: $D_4 = 0.10$, $B_4 = 0.05$.\n\nWhich of the following statements about $S_i$ and its biological interpretation are correct? Select all that apply.\n\nA. With the given weights, $P_1$ has the largest positive $S_i$ and is hub-dominated; its removal would eliminate many local interactions but is comparatively less likely than a negative-$S_i$ node to disrupt inter-module shortest-path traffic.\n\nB. With the given weights, $P_2$ is bottleneck-dominated and, relative to $P_1$, is more likely to mediate inter-module communication via shortest paths; consequently, it may exhibit stronger effects in perturbations that assay path-dependent signal transfer.\n\nC. Although both $D_3$ and $B_3$ are high, $S_3<0$ under the given weights, illustrating that $S_i$ reflects relative emphasis; increasing $k_d$ above $k_b\\cdot \\dfrac{B_3}{D_3}$ would flip the sign of $S_3$.\n\nD. If $k_b$ is increased by a factor of $2$, then for all nodes with $B_i>0$, $S_i$ increases because a higher $k_b$ rewards bottleneckness.\n\nE. If $S_i \\approx 0$, then it must be that $D_i \\approx 0$ and $B_i \\approx 0$; therefore $P_4$ is necessarily a peripheral, non-influential node.",
            "solution": "The problem statement is subjected to validation.\n\n**1. Extraction of Givens:**\n- A Protein-Protein Interaction (PPI) network is modeled as an undirected, unweighted graph.\n- Degree centrality of a node $i$ is the number of its interaction partners. This is normalized to $D_i \\in [0, 1]$.\n- Betweenness centrality of a node $i$ is the fraction of all shortest paths that pass through $i$. This is normalized to $B_i \\in [0, 1]$.\n- A hub-bottleneck discrepancy score is defined as $S_i = k_d \\cdot D_i - k_b \\cdot B_i$.\n- $k_d > 0$ and $k_b > 0$ are user-chosen weights.\n- A larger positive $S_i$ indicates hub dominance; a more negative $S_i$ indicates bottleneck dominance.\n- The specific weights are given as $k_d = 1.0$ and $k_b = 1.5$.\n- Normalized centrality values for four proteins are provided:\n  - $P_1$: $D_1 = 0.80$, $B_1 = 0.20$.\n  - $P_2$: $D_2 = 0.30$, $B_2 = 0.60$.\n  - $P_3$: $D_3 = 0.70$, $B_3 = 0.70$.\n  - $P_4$: $D_4 = 0.10$, $B_4 = 0.05$.\n\n**2. Validation:**\n- **Scientific Grounding**: The concepts of PPI networks, degree centrality, betweenness centrality, hubs, and bottlenecks are fundamental and well-established in computational biology and network science. The formulation of a discrepancy score to weigh these two properties is a valid and common approach in composite metric design. The problem is scientifically sound.\n- **Well-Posedness**: The problem provides a clear mathematical definition for the score $S_i$, all necessary numerical data ($D_i$, $B_i$), and the parameters ($k_d$, $k_b$) required for calculation. The question is unambiguous and asks for an evaluation of statements based on these data and definitions.\n- **Objectivity**: The problem is stated in precise, objective language. The interpretations of \"hub-dominated\" and \"bottleneck-dominated\" are explicitly tied to the sign of the calculated score $S_i$.\n\n**3. Verdict:**\nThe problem statement is valid. It is scientifically grounded, self-contained, and well-posed. I will proceed with the solution.\n\n**Derivation**\n\nThe primary task is to compute the hub-bottleneck discrepancy score $S_i$ for each protein $P_i$ using the formula $S_i = k_d \\cdot D_i - k_b \\cdot B_i$ with the given weights $k_d = 1.0$ and $k_b = 1.5$.\n\nFor protein $P_1$:\n$$S_1 = (1.0 \\cdot 0.80) - (1.5 \\cdot 0.20) = 0.80 - 0.30 = 0.50$$\n\nFor protein $P_2$:\n$$S_2 = (1.0 \\cdot 0.30) - (1.5 \\cdot 0.60) = 0.30 - 0.90 = -0.60$$\n\nFor protein $P_3$:\n$$S_3 = (1.0 \\cdot 0.70) - (1.5 \\cdot 0.70) = 0.70 - 1.05 = -0.35$$\n\nFor protein $P_4$:\n$$S_4 = (1.0 \\cdot 0.10) - (1.5 \\cdot 0.05) = 0.10 - 0.075 = 0.025$$\n\nSummary of scores: $S_1 = 0.50$, $S_2 = -0.60$, $S_3 = -0.35$, $S_4 = 0.025$.\nA positive score ($S_i > 0$) indicates hub dominance. A negative score ($S_i < 0$) indicates bottleneck dominance.\n\n**Option-by-Option Analysis**\n\n**A. With the given weights, $P_1$ has the largest positive $S_i$ and is hub-dominated; its removal would eliminate many local interactions but is comparatively less likely than a negative-$S_i$ node to disrupt inter-module shortest-path traffic.**\n- We calculated $S_1 = 0.50$ and $S_4 = 0.025$. Both are positive. $S_1$ is the largest positive score. This is correct.\n- Since $S_1 > 0$, $P_1$ is classified as hub-dominated. This is correct.\n- $P_1$ has a very high degree centrality, $D_1 = 0.80$, the highest among the four proteins. High degree implies many direct interaction partners (\"local interactions\"). Its removal would indeed eliminate these interactions. This is a correct interpretation.\n- The negative-$S_i$ nodes are $P_2$ ($S_2 = -0.60$) and $P_3$ ($S_3 = -0.35$). These are bottleneck-dominated. Their betweenness centralities are high ($B_2 = 0.60$, $B_3 = 0.70$), while $P_1$'s is low ($B_1 = 0.20$). Nodes with high betweenness are critical for connecting different network modules, so their removal disproportionately affects shortest-path traffic. Thus, removing $P_1$ is less likely to disrupt this traffic than removing $P_2$ or $P_3$. The statement is entirely consistent with network theory.\n**Verdict: Correct**\n\n**B. With the given weights, $P_2$ is bottleneck-dominated and, relative to $P_1$, is more likely to mediate inter-module communication via shortest paths; consequently, it may exhibit stronger effects in perturbations that assay path-dependent signal transfer.**\n- We calculated $S_2 = -0.60$. Since $S_2 < 0$, $P_2$ is bottleneck-dominated. This is correct.\n- Comparing $P_2$ to $P_1$: $B_2 = 0.60$ is significantly higher than $B_1 = 0.20$. High betweenness centrality is the defining feature of nodes that \"mediate inter-module communication via shortest paths.\" Thus, $P_2$ is more likely to play this role than $P_1$. This is correct.\n- \"Path-dependent signal transfer\" relies on the integrity of communication paths. A perturbation to a node with high betweenness, such as $P_2$, will sever a large number of shortest paths, leading to a stronger disruptive effect on such processes compared to perturbing a low-betweenness node like $P_1$. This conclusion is a logical consequence.\n**Verdict: Correct**\n\n**C. Although both $D_3$ and $B_3$ are high, $S_3<0$ under the given weights, illustrating that $S_i$ reflects relative emphasis; increasing $k_d$ above $k_b\\cdot \\dfrac{B_3}{D_3}$ would flip the sign of $S_3$.**\n- For $P_3$, $D_3 = 0.70$ and $B_3 = 0.70$ are high values relative to the $[0, 1]$ scale.\n- We calculated $S_3 = -0.35$, which is indeed negative. This is because the weight for bottleneckness ($k_b=1.5$) is greater than the weight for hubness ($k_d=1.0$), so for equal centrality scores, the bottleneck term dominates. This correctly illustrates that $S_i$ measures relative, weighted importance.\n- To flip the sign of $S_3$ from negative to positive, we require $S_3 > 0$. The condition is $k_d D_3 - k_b B_3 > 0$. Rearranging for $k_d$, we get $k_d D_3 > k_b B_3$. Since $D_3=0.70>0$, we can divide by it to obtain $k_d > k_b \\frac{B_3}{D_3}$. This mathematical derivation is flawless.\n**Verdict: Correct**\n\n**D. If $k_b$ is increased by a factor of $2$, then for all nodes with $B_i>0$, $S_i$ increases because a higher $k_b$ rewards bottleneckness.**\n- Let the initial score be $S_i = k_d D_i - k_b B_i$.\n- Let the new weight be $k_b' = 2k_b$. The new score is $S_i' = k_d D_i - k_b' B_i = k_d D_i - 2k_b B_i$.\n- The change in score is $\\Delta S_i = S_i' - S_i = (k_d D_i - 2k_b B_i) - (k_d D_i - k_b B_i) = -k_b B_i$.\n- Since it is given that $k_b > 0$, and the option considers nodes with $B_i > 0$, the change $\\Delta S_i$ is strictly negative.\n- Therefore, increasing $k_b$ *decreases* the value of $S_i$. The statement claims $S_i$ increases, which is false. The reasoning provided is also misleading; in the context of this specific formula, increasing $k_b$ gives a larger penalty to the score, making it more negative (more bottleneck-dominated), not increasing it.\n**Verdict: Incorrect**\n\n**E. If $S_i \\approx 0$, then it must be that $D_i \\approx 0$ and $B_i \\approx 0$; therefore $P_4$ is necessarily a peripheral, non-influential node.**\n- The condition $S_i \\approx 0$ means $k_d D_i - k_b B_i \\approx 0$, or $k_d D_i \\approx k_b B_i$.\n- This is a balance equation. It does not require that $D_i$ and $B_i$ are both close to $0$. For example, with $k_d=1.0$ and $k_b=1.5$, a node with $D_i=0.6$ and $B_i=0.4$ would have $S_i = 1.0(0.6) - 1.5(0.4) = 0.6 - 0.6 = 0$. Here, $D_i$ and $B_i$ are substantial, not close to zero. The first part of the statement is a logical fallacy.\n- For $P_4$, we calculated $S_4=0.025$, which is close to $0$. We are given $D_4=0.10$ and $B_4=0.05$. These values are indeed low, consistent with a peripheral node. However, the word \"therefore\" implies a causal link from a flawed premise. The conclusion that $P_4$ is peripheral is not a necessary consequence of $S_4 \\approx 0$. A node with $S_i \\approx 0$ can be highly influential if it has significant, but balanced, degree and betweenness. The statement's logic is unsound.\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{ABC}$$"
        },
        {
            "introduction": "A high number of connections does not always mean a node is critical for a network's overall integrity, a concept this practice explores. This exercise  introduces the \"fragile hub\"—a node with a high degree that, due to network redundancy, has little impact on overall connectivity when removed. You will implement an algorithm to calculate a \"loss\" metric, $L(v)$, based on network fragmentation, providing a hands-on method for distinguishing truly essential hubs from those whose importance is less pronounced.",
            "id": "2409629",
            "problem": "A biological interaction network can be modeled as a finite, undirected, simple graph $G=(V,E)$, where $V$ is the set of nodes (biomolecules) and $E$ is the set of undirected edges (interactions). For a node $v \\in V$, the degree $\\deg(v)$ is the number of edges incident to $v$. A node $v$ is called a hub if $\\deg(v) \\ge k_{\\text{hub}}$ for a specified integer threshold $k_{\\text{hub}} \\ge 1$. Define the removal effect of a node $v$ as follows: remove $v$ and all its incident edges to obtain a residual graph $G'=(V',E')$ with $V'=V \\setminus \\{v\\}$. Let the connected components of $G'$ have sizes $s_1,s_2,\\dots,s_m$ (so that $\\sum_{i=1}^{m} s_i = |V'|$). The number of unordered node pairs in $V'$ that remain mutually reachable is $\\sum_{i=1}^{m} \\binom{s_i}{2}$. The total number of unordered node pairs in $V'$ is $\\binom{|V'|}{2}$. Define the reachability fraction $R(v)$ by\n$$\nR(v) = \n\\begin{cases}\n1, & \\text{if } |V'| \\le 1,\\\\\n\\displaystyle \\frac{\\sum_{i=1}^{m} \\binom{s_i}{2}}{\\binom{|V'|}{2}}, & \\text{if } |V'| \\ge 2,\n\\end{cases}\n$$\nand the loss $L(v) = 1 - R(v)$. For a specified tolerance $\\tau \\in [0,1]$, a fragile hub is any hub $v$ with $L(v) \\le \\tau$. Your task is to determine, for each test case, the list of node indices that are fragile hubs, sorted in ascending order.\n\nUse the following test suite. In all cases, the graph is undirected and simple, node indices are integers, and all edges are unordered pairs of distinct node indices.\n\nTest case $1$ (redundantly bridged modules):\n- Nodes: $V_1 = \\{0,1,2,3,4,5,6,7,8\\}$, so $|V_1|=9$.\n- Edges: $E_1$ consists of all $\\binom{5}{2}$ edges among $\\{0,1,2,3,4\\}$, all $\\binom{4}{2}$ edges among $\\{5,6,7,8\\}$, and two inter-module edges $(2,5)$ and $(3,6)$. Explicitly,\n$$\nE_1 = \\{(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),\n(5,6),(5,7),(5,8),(6,7),(6,8),(7,8),(2,5),(3,6)\\}.\n$$\n- Hub threshold: $k_{\\text{hub}}=5$.\n- Tolerance: $\\tau=0.05$.\n\nTest case $2$ (star topology):\n- Nodes: $V_2=\\{0,1,2,3,4,5,6\\}$, so $|V_2|=7$.\n- Edges: $E_2=\\{(0,1),(0,2),(0,3),(0,4),(0,5),(0,6)\\}$.\n- Hub threshold: $k_{\\text{hub}}=5$.\n- Tolerance: $\\tau=0.1$.\n\nTest case $3$ (redundant high-degree node on a cycle):\n- Nodes: $V_3=\\{0,1,2,3,4,5\\}$, so $|V_3|=6$.\n- Edges: $E_3$ is the $6$-cycle plus extra chords from node $0$ to nodes $2$, $3$, and $4$:\n$$\nE_3=\\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,0),(0,2),(0,3),(0,4)\\}.\n$$\n- Hub threshold: $k_{\\text{hub}}=5$.\n- Tolerance: $\\tau=0.0$.\n\nFor each test case $i \\in \\{1,2,3\\}$, compute the set of fragile hubs as all nodes $v$ such that $\\deg(v) \\ge k_{\\text{hub}}$ and $L(v) \\le \\tau$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the list (in ascending order) of fragile hub node indices for the corresponding test case. For example, the output format must be\n$$\n[\\,[\\text{case 1 indices}],\\,[\\text{case 2 indices}],\\,[\\text{case 3 indices}]\\,].\n$$\nIf a case has no fragile hubs, output an empty list $[\\,]$ for that case. No physical units or angles are involved in this problem. The required output types are lists of integers for each test case, aggregated as specified into a single line.",
            "solution": "The problem statement is subjected to a rigorous validation process before a solution is attempted.\n\n**Step 1: Extracted Givens**\n\nThe problem provides the following definitions and data:\n- A network is modeled as a finite, undirected, simple graph $G=(V,E)$.\n- The degree of a node $v$ is $\\deg(v)$.\n- A node $v$ is a hub if $\\deg(v) \\ge k_{\\text{hub}}$, for an integer threshold $k_{\\text{hub}} \\ge 1$.\n- Removing a node $v$ yields a residual graph $G'=(V \\setminus \\{v\\}, E')$.\n- The connected components of $G'$ have sizes $s_1, s_2, \\dots, s_m$. The total number of nodes in $G'$ is $|V'| = \\sum_{i=1}^{m} s_i$.\n- The reachability fraction $R(v)$ is defined as:\n$$\nR(v) = \n\\begin{cases}\n1, & \\text{if } |V'| \\le 1,\\\\\n\\displaystyle \\frac{\\sum_{i=1}^{m} \\binom{s_i}{2}}{\\binom{|V'|}{2}}, & \\text{if } |V'| \\ge 2.\n\\end{cases}\n$$\n- The loss is $L(v) = 1 - R(v)$.\n- A fragile hub is a hub $v$ for which $L(v) \\le \\tau$, where $\\tau \\in [0,1]$ is a given tolerance.\n- The task is to identify all fragile hubs for three specific test cases.\n\nTest Case $1$:\n- Nodes $V_1 = \\{0, 1, 2, 3, 4, 5, 6, 7, 8\\}$ ($|V_1|=9$).\n- Edges $E_1 = \\{(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4), (5,6),(5,7),(5,8),(6,7),(6,8),(7,8),(2,5),(3,6)\\}$.\n- Parameters: $k_{\\text{hub}}=5$, $\\tau=0.05$.\n\nTest Case $2$:\n- Nodes $V_2=\\{0, 1, 2, 3, 4, 5, 6\\}$ ($|V_2|=7$).\n- Edges $E_2=\\{(0,1),(0,2),(0,3),(0,4),(0,5),(0,6)\\}$.\n- Parameters: $k_{\\text{hub}}=5$, $\\tau=0.1$.\n\nTest Case $3$:\n- Nodes $V_3=\\{0, 1, 2, 3, 4, 5\\}$ ($|V_3|=6$).\n- Edges $E_3=\\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,0),(0,2),(0,3),(0,4)\\}$.\n- Parameters: $k_{\\text{hub}}=5$, $\\tau=0.0$.\n\n**Step 2: Validation Using Extracted Givens**\n\nThe problem is evaluated against the criteria for validity.\n1.  **Scientifically Grounded**: The problem uses standard graph-theoretical concepts to model network properties. This is a conventional and valid approach in computational biology and bioinformatics. The metrics $R(v)$ and $L(v)$ are well-defined mathematical constructs that quantify network fragmentation. No scientific or logical flaws are present.\n2.  **Well-Posed**: All terms are defined with mathematical precision. The inputs (graphs and parameters) for each test case are explicitly provided. The objective—to find a specific set of nodes—is unambiguous. For a given graph and parameters, the solution is unique and deterministically computable.\n3.  **Objective**: The problem statement is free of subjective or opinion-based claims. It poses a clear computational task.\n4.  **Complete and Consistent**: Each test case is fully specified with nodes, edges, and parameters. The descriptions of the graphs are consistent with the explicit edge lists. There are no missing data or contradictions.\n5.  **Feasible**: The graphs are of small size, making the required computations feasible. No physically impossible or inconsistent data are given.\n\n**Step 3: Verdict and Action**\n\nThe problem is scientifically sound, mathematically well-posed, and completely specified. It is therefore deemed **valid**. We proceed to derive the solution.\n\n**Methodology**\n\nThe solution for each test case is obtained by executing the following algorithm:\n1.  For the given graph $G=(V,E)$, construct an adjacency list representation.\n2.  For each node $v \\in V$, compute its degree, $\\deg(v)$.\n3.  Identify the set of hubs, $V_{\\text{hub}} = \\{v \\in V \\mid \\deg(v) \\ge k_{\\text{hub}}\\}$.\n4.  For each hub $v \\in V_{\\text{hub}}$:\n    a. Determine the set of nodes in the residual graph, $V' = V \\setminus \\{v\\}$. The size is $|V'| = |V|-1$.\n    b. Find the connected components of the residual graph $G'$ on the node set $V'$. This can be done using a standard graph traversal algorithm, such as Breadth-First Search (BFS) or Depth-First Search (DFS), to find the sizes $s_1, s_2, \\dots, s_m$ of these components.\n    c. Calculate the loss $L(v)$. If $|V'| < 2$, $L(v) = 0$. Otherwise, compute the total number of pairs of distinct nodes in $G'$, which is $\\binom{|V'|}{2}$, and the number of pairs that remain connected, which is $\\sum_{i=1}^{m} \\binom{s_i}{2}$. The reachability fraction is $R(v) = (\\sum_{i=1}^{m} \\binom{s_i}{2}) / \\binom{|V'|}{2}$, and the loss is $L(v) = 1 - R(v)$. The binomial coefficient $\\binom{n}{2}$ is calculated as $n(n-1)/2$.\n    d. Compare the loss with the tolerance: if $L(v) \\le \\tau$, then $v$ is a fragile hub.\n5.  Collect all identified fragile hub indices for the test case and present them as a sorted list.\n\n**Application to Test Cases**\n\n**Test Case 1:**\n- Graph $G_1=(V_1, E_1)$ with $|V_1|=9$, $k_{\\text{hub}}=5$, $\\tau=0.05$.\n- Degree calculation:\n  - $\\deg(0)=4$, $\\deg(1)=4$, $\\deg(2)=5$, $\\deg(3)=5$, $\\deg(4)=4$.\n  - $\\deg(5)=4$, $\\deg(6)=4$, $\\deg(7)=3$, $\\deg(8)=3$.\n- The hubs (nodes with degree $\\ge 5$) are $\\{2, 3\\}$.\n- For hub $v=2$: Remove node $2$. The residual graph $G_1'$ has nodes $V_1' = V_1 \\setminus \\{2\\}$, so $|V_1'|=8$. The edge $(3,6)$ remains, preserving connectivity between the two original modules. Thus, $G_1'$ is fully connected, having one component of size $s_1=8$.\n  - Number of pairs in connected components: $\\binom{8}{2} = 28$.\n  - Total pairs in $V_1'$: $\\binom{8}{2} = 28$.\n  - $R(2) = 28/28 = 1$.\n  - $L(2) = 1 - 1 = 0$. Since $0 \\le 0.05$, node $2$ is a fragile hub.\n- For hub $v=3$: Remove node $3$. The residual graph $G_1''$ has $|V_1''|=8$. The edge $(2,5)$ remains, keeping the graph connected. It has one component of size $s_1=8$.\n  - $L(3) = 0$. Since $0 \\le 0.05$, node $3$ is a fragile hub.\n- The fragile hubs for case $1$ are $\\{2, 3\\}$, sorted as $[2, 3]$.\n\n**Test Case 2:**\n- Graph $G_2=(V_2, E_2)$ with $|V_2|=7$, $k_{\\text{hub}}=5$, $\\tau=0.1$. This is a star graph with center $0$.\n- Degree calculation: $\\deg(0)=6$, and $\\deg(v)=1$ for $v \\in \\{1, \\dots, 6\\}$.\n- The only hub is node $0$.\n- For hub $v=0$: Remove node $0$. The residual graph $G_2'$ has nodes $V_2' = \\{1, 2, 3, 4, 5, 6\\}$, so $|V_2'|=6$. Removing the center node removes all edges.\n  - The components are $6$ isolated nodes, each of size $s_i=1$.\n  - Number of pairs in connected components: $\\sum_{i=1}^6 \\binom{1}{2} = 0$.\n  - Total pairs in $V_2'$: $\\binom{6}{2} = 15$.\n  - $R(0) = 0/15 = 0$.\n  - $L(0) = 1 - 0 = 1$. Since $1 \\not\\le 0.1$, node $0$ is not a fragile hub.\n- There are no fragile hubs for case $2$. The result is an empty list, $[\\,]$.\n\n**Test Case 3:**\n- Graph $G_3=(V_3, E_3)$ with $|V_3|=6$, $k_{\\text{hub}}=5$, $\\tau=0.0$.\n- Degree calculation:\n  - $\\deg(0)=5$, $\\deg(1)=2$, $\\deg(2)=3$, $\\deg(3)=3$, $\\deg(4)=3$, $\\deg(5)=2$.\n- The only hub is node $0$.\n- For hub $v=0$: Remove node $0$. The residual graph $G_3'$ has nodes $V_3'=\\{1, 2, 3, 4, 5\\}$, so $|V_3'|=5$. The remaining edges are $(1,2), (2,3), (3,4), (4,5)$, which form a path graph.\n  - The graph is connected, so there is one component of size $s_1=5$.\n  - Number of pairs in connected components: $\\binom{5}{2} = 10$.\n  - Total pairs in $V_3'$: $\\binom{5}{2} = 10$.\n  - $R(0) = 10/10 = 1$.\n  - $L(0) = 1 - 1 = 0$. Since $0 \\le 0.0$, node $0$ is a fragile hub.\n- The fragile hub for case $3$ is $\\{0\\}$, sorted as $[0]$.\n\n**Consolidated Results**\n- Case 1: $[2, 3]$\n- Case 2: $[\\,]$\n- Case 3: $[0]$\nThe final output is constructed by aggregating these lists.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\n\ndef solve():\n    \"\"\"\n    Solves the fragile hub identification problem for a given suite of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"nodes\": list(range(9)),\n            \"edges\": [(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),\n                      (5,6),(5,7),(5,8),(6,7),(6,8),(7,8),(2,5),(3,6)],\n            \"k_hub\": 5,\n            \"tau\": 0.05\n        },\n        {\n            \"nodes\": list(range(7)),\n            \"edges\": [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6)],\n            \"k_hub\": 5,\n            \"tau\": 0.1\n        },\n        {\n            \"nodes\": list(range(6)),\n            \"edges\": [(0,1),(1,2),(2,3),(3,4),(4,5),(5,0),(0,2),(0,3),(0,4)],\n            \"k_hub\": 5,\n            \"tau\": 0.0\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        nodes = case[\"nodes\"]\n        edges = case[\"edges\"]\n        k_hub = case[\"k_hub\"]\n        tau = case[\"tau\"]\n        num_nodes = len(nodes)\n\n        # Build adjacency list\n        adj = {node: [] for node in nodes}\n        for u, v in edges:\n            adj[u].append(v)\n            adj[v].append(u)\n\n        # Calculate degrees and find hubs\n        degrees = {node: len(neighbors) for node, neighbors in adj.items()}\n        hubs = [node for node, deg in degrees.items() if deg >= k_hub]\n\n        fragile_hubs = []\n\n        for hub in hubs:\n            # 1. Define the residual graph\n            residual_nodes = [node for node in nodes if node != hub]\n            num_residual_nodes = len(residual_nodes)\n\n            if num_residual_nodes < 2:\n                loss = 0.0\n            else:\n                # 2. Find connected components in the residual graph using DFS\n                visited = set()\n                component_sizes = []\n                for start_node in residual_nodes:\n                    if start_node not in visited:\n                        component_size = 0\n                        stack = [start_node]\n                        visited.add(start_node)\n                        while stack:\n                            current_node = stack.pop()\n                            component_size += 1\n                            for neighbor in adj[current_node]:\n                                # neighbor must be in the residual graph and not visited\n                                if neighbor != hub and neighbor not in visited:\n                                    visited.add(neighbor)\n                                    stack.append(neighbor)\n                        component_sizes.append(component_size)\n\n                # 3. Calculate Loss L(v)\n                sum_of_pairs_in_components = sum(comb(s, 2, exact=True) for s in component_sizes)\n                total_pairs_in_residual = comb(num_residual_nodes, 2, exact=True)\n                \n                if total_pairs_in_residual == 0:\n                    reachability_fraction = 1.0\n                else:\n                    reachability_fraction = sum_of_pairs_in_components / total_pairs_in_residual\n                \n                loss = 1.0 - reachability_fraction\n\n            # 4. Check if the hub is fragile\n            if loss <= tau:\n                fragile_hubs.append(hub)\n\n        fragile_hubs.sort()\n        final_results.append(fragile_hubs)\n\n    # Format output as specified: [[...], [...], [...]]\n    # str(list) can add spaces, e.g., '[2, 3]'. remove spaces.\n    results_str = [str(res).replace(\" \", \"\") for res in final_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Just as some hubs are fragile, some bottlenecks can be surprisingly robust, representing a sophisticated feature of network resilience. This advanced exercise  introduces the \"robust bottleneck\"—a node that lies on many shortest paths but whose removal causes only a minimal drop in the network's overall communication efficiency. To identify these nodes, you will develop an algorithm that combines the computation of betweenness centrality, $b(v)$, with an analysis of the relative efficiency drop, $\\Delta(v)$, offering deep insight into the principles of network plasticity and compensation.",
            "id": "2409636",
            "problem": "You are given undirected, unweighted graphs representing interaction networks, and you are asked to formalize and detect an example of a “robust bottleneck” in the sense used in computational biology and bioinformatics: a node with high betweenness centrality whose removal is effectively compensated by network plasticity through redundant routes. Your task is to write a program that, for each provided test graph, returns the list of all nodes that satisfy this property under a precise, mathematically defined criterion.\n\nThe fundamental bases to use are: the definition of an undirected graph, shortest paths, betweenness centrality, and network efficiency. Specifically, use the following definitions.\n\n- A graph is specified by an adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$, where $A_{ij} = 1$ if and only if there is an undirected edge between nodes $i$ and $j$, with $A_{ii} = 0$ and $A_{ij} = A_{ji}$ for all $i,j$. Nodes are $0$-indexed from $\\{0,1,\\dots,n-1\\}$.\n- For nodes $s,t$, a shortest path is any path that realizes the minimal number of edges $d(s,t)$ between $s$ and $t$. If $s$ and $t$ are disconnected, define $d(s,t) = \\infty$.\n- The betweenness centrality $b(v)$ of node $v$ is the sum, over all unordered pairs $\\{s,t\\}$ with $s \\neq t$, $s \\neq v$, $t \\neq v$, of the fraction of shortest paths from $s$ to $t$ that pass through $v$. That is,\n$$\nb(v) = \\sum_{\\substack{s < t\\\\ s \\neq v \\neq t}} \\frac{\\sigma_{st}(v)}{\\sigma_{st}},\n$$\nwhere $\\sigma_{st}$ is the number of shortest paths between $s$ and $t$ and $\\sigma_{st}(v)$ is the number of such paths that pass through $v$.\n- The global efficiency of a graph on node set $V$ is\n$$\nE(V) = \\frac{2}{|V|(|V|-1)} \\sum_{\\substack{i<j\\\\ i,j \\in V}} \\frac{1}{d(i,j)},\n$$\nwith the convention that $1/\\infty = 0$.\n\nTo formalize “effectively compensated by network plasticity,” for each candidate node $v$ we compare the efficiency among the remaining nodes $V \\setminus \\{v\\}$ before and after removing $v$:\n- Let $E_{\\text{before}}(v)$ denote the average of $1/d(i,j)$ over all unordered pairs $\\{i,j\\}$ with $i<j$ and $i,j \\in V \\setminus \\{v\\}$, where $d(i,j)$ is computed in the original graph (with $v$ present).\n- Let $E_{\\text{after}}(v)$ denote the same average but with distances computed in the graph obtained by removing $v$ (i.e., the induced subgraph on $V \\setminus \\{v\\}$).\n- Define the relative efficiency drop\n$$\n\\Delta(v) = \\begin{cases}\n\\frac{E_{\\text{before}}(v)-E_{\\text{after}}(v)}{E_{\\text{before}}(v)}, & \\text{if } E_{\\text{before}}(v) > 0,\\\\\n0, & \\text{if } E_{\\text{before}}(v) = 0.\n\\end{cases}\n$$\n\nA node $v$ qualifies as a “robust bottleneck” if and only if it satisfies both:\n- High-betweenness criterion: $b(v) \\ge Q_q(b)$ and $b(v) > 0$, where $Q_q(b)$ is the $q$-quantile of the multiset $\\{b(0),b(1),\\dots,b(n-1)\\}$ for a specified $q \\in (0,1)$.\n- Compensation criterion: $\\Delta(v) \\le \\tau$, for a specified tolerance $\\tau \\in [0,1]$.\n\nImplement an algorithm that, given a graph and the parameters $q$ and $\\tau$, returns the sorted list of all nodes that satisfy both criteria. Use exact shortest paths for unweighted graphs via breadth-first search and compute betweenness centrality exactly (for example, by a correct implementation of the unweighted variant of the Brandes algorithm). You must not assume any particular graph structure beyond what is given.\n\nTest Suite and Required Output:\n- Use the following three test cases, each given by an adjacency matrix with entries in $\\{0,1\\}$, and shared parameters $q$ and $\\tau$.\n\n- Test case $1$ (two modules connected by redundant middle layers):\n  - $n = 8$, nodes $\\{0,1,2,3,4,5,6,7\\}$.\n  - Adjacency matrix $A^{(1)}$ whose rows for nodes $0$ through $7$ are:\n    - Node $0$: $[0,1,1,0,0,0,1,1]$\n    - Node $1$: $[1,0,1,0,0,0,1,1]$\n    - Node $2$: $[1,1,0,0,0,0,1,1]$\n    - Node $3$: $[0,0,0,0,1,1,1,1]$\n    - Node $4$: $[0,0,0,1,0,1,1,1]$\n    - Node $5$: $[0,0,0,1,1,0,1,1]$\n    - Node $6$: $[1,1,1,1,1,1,0,0]$\n    - Node $7$: $[1,1,1,1,1,1,0,0]$\n  - Parameters: $q = 0.8$, $\\tau = 0.01$.\n\n- Test case $2$ (star graph):\n  - $n = 6$, nodes $\\{0,1,2,3,4,5\\}$.\n  - Adjacency matrix $A^{(2)}$ whose rows for nodes $0$ through $5$ are:\n    - Node $0$: $[0,1,1,1,1,1]$\n    - Node $1$: $[1,0,0,0,0,0]$\n    - Node $2$: $[1,0,0,0,0,0]$\n    - Node $3$: $[1,0,0,0,0,0]$\n    - Node $4$: $[1,0,0,0,0,0]$\n    - Node $5$: $[1,0,0,0,0,0]$\n  - Parameters: $q = 0.8$, $\\tau = 0.01$.\n\n- Test case $3$ (complete graph on four nodes):\n  - $n = 4$, nodes $\\{0,1,2,3\\}$.\n  - Adjacency matrix $A^{(3)}$ whose rows for nodes $0$ through $3$ are:\n    - Node $0$: $[0,1,1,1]$\n    - Node $1$: $[1,0,1,1]$\n    - Node $2$: $[1,1,0,1]$\n    - Node $3$: $[1,1,1,0]$\n  - Parameters: $q = 0.8$, $\\tau = 0.01$.\n\nFor each test case, output the zero-indexed list of nodes that satisfy both criteria, sorted in ascending order. Your program should produce a single line of output containing the results as a comma-separated list of lists, enclosed in square brackets, for the three test cases in order. For example, a format like $[[a,b],[c],[\\,]]$ with integers $a,b,c$ is required. There are no physical units or angles involved in this problem. All results must be integers, lists of integers, or empty lists; no percentages should be printed.\n\nYour program must be self-contained and take no input. It must implement correct shortest-path counting and exact betweenness centrality for unweighted, undirected graphs and apply the above definitions precisely. The final printed line should be exactly the specified aggregate list, with no extra text.",
            "solution": "The user has provided a problem that is scientifically grounded, well-posed, objective, and self-contained. The definitions of graph-theoretic concepts such as betweenness centrality and network efficiency are standard. The proposed formalization of a \"robust bottleneck\" is a clear and operational criterion based on these standard measures. The problem provides all necessary data, including graph structures and parameters, and specifies a clear computational objective. There are no contradictions, ambiguities, or reliance on non-scientific claims. Therefore, the problem is valid and a solution can be derived.\n\nThe task is to identify a specific type of node in a network, termed a \"robust bottleneck\". This requires a two-part characterization: the node must be a significant crossroads for network traffic (high betweenness centrality), but its removal must not catastrophically disrupt network connectivity, as measured by a small drop in global efficiency (effective compensation). We will construct an algorithm to identify all such nodes in a given graph.\n\nThe overall algorithm proceeds as follows. For each graph, we first identify the set of nodes that satisfy the high-betweenness criterion. Then, for each node in the graph, we calculate the network's resilience to its removal. Finally, the set of robust bottlenecks is the intersection of nodes satisfying both criteria.\n\n**1. High-Betweenness Criterion**\n\nA node $v$ is considered to have high betweenness if its betweenness centrality $b(v)$ is both positive and greater than or equal to a statistical threshold. The betweenness centrality is defined as:\n$$\nb(v) = \\sum_{\\substack{s < t\\\\ s \\neq v \\neq t}} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n$$\nwhere $\\sigma_{st}$ is the total number of shortest paths between nodes $s$ and $t$, and $\\sigma_{st}(v)$ is the number of such paths that pass through node $v$. For an undirected graph, this sum is over all unordered pairs of distinct nodes $\\{s,t\\}$, neither of which is $v$.\n\nTo compute $b(v)$ for all nodes $v$ in the graph, we employ the Brandes algorithm, which is an efficient method for unweighted graphs. The algorithm operates by iterating through each node $s$ as a source and performing the following steps:\n- A Breadth-First Search (BFS) is initiated from $s$ to compute the shortest path distances $d(s,u)$ and the number of shortest paths $\\sigma_{su}$ to all other nodes $u$. During the BFS, we also record the predecessors $P_s(u)$ of each node $u$ on shortest paths from $s$.\n- After the BFS, nodes are processed in decreasing order of their distance from $s$. For each node $w$, a dependency score $\\delta_s(w)$ is calculated. This score quantifies how much the shortest paths from $s$ to other nodes depend on $w$. The dependency is accumulated \"backwards\" from the farthest nodes towards the source $s$. The formula for updating the dependency of a predecessor $v \\in P_s(w)$ is:\n$$\n\\delta_s(v) \\leftarrow \\delta_s(v) + \\frac{\\sigma_{sv}}{\\sigma_{sw}} (1 + \\delta_{s}(w))\n$$\n- The betweenness centrality $b(w)$ is the sum of these dependency scores over all possible sources $s$. As the problem specifies an undirected graph and the centrality definition is over unordered pairs, the result from the standard Brandes algorithm (which sums over ordered pairs) must be divided by $2$.\n\nOnce all $b(v)$ values are computed, we determine the threshold $Q_q(b)$, which is the $q$-quantile of the set of all centrality values $\\{b(0), b(1), ..., b(n-1)\\}$. A node $v$ satisfies the high-betweenness criterion if $b(v) \\ge Q_q(b)$ and $b(v) > 0$.\n\n**2. Compensation Criterion**\n\nThis criterion measures the network's plasticity, or its ability to reroute traffic when a node is removed. We quantify this using the relative drop in network efficiency, $\\Delta(v)$. The efficiency of a graph is a measure of how easily information can be exchanged across the network. For a set of nodes $U$, it is related to the average inverse shortest path distance between all pairs of nodes in $U$.\n\nFor each candidate node $v$, we define two efficiency-related sums, calculated on the set of remaining nodes $V' = V \\setminus \\{v\\}$:\n- $S_{\\text{before}}(v) = \\sum_{\\substack{i<j\\\\ i,j \\in V'}} \\frac{1}{d(i,j)}$, where distances $d(i,j)$ are computed in the full, original graph.\n- $S_{\\text{after}}(v) = \\sum_{\\substack{i<j\\\\ i,j \\in V'}} \\frac{1}{d_v(i,j)}$, where distances $d_v(i,j)$ are computed in the graph with node $v$ and its incident edges removed.\n\nThe relative efficiency drop is then:\n$$\n\\Delta(v) = \\frac{S_{\\text{before}}(v)-S_{\\text{after}}(v)}{S_{\\text{before}}(v)}\n$$\nprovided $S_{\\text{before}}(v) > 0$. If $S_{\\text{before}}(v) = 0$, then $\\Delta(v) = 0$. Note that the normalization factor for calculating the average efficiency cancels out in this ratio.\n\nTo compute these sums, we need all-pairs shortest path (APSP) distances. Since the graphs are unweighted, this is achieved by running a separate BFS from every node in the corresponding graph (the original graph for $d(i,j)$ and the reduced graph for $d_v(i,j)$).\n\nA node $v$ satisfies the compensation criterion if its removal causes a small efficiency drop, i.e., $\\Delta(v) \\le \\tau$, where $\\tau$ is a given tolerance.\n\n**3. Synthesis of the Algorithm**\n\nThe complete algorithm for a given graph with parameters $q$ and $\\tau$ is:\n1.  Compute the betweenness centrality $b(v)$ for all nodes $v \\in V$ using the Brandes algorithm.\n2.  Calculate the threshold $Q_q(b)$ as the $q$-quantile of the centrality values.\n3.  Identify the set of high-betweenness nodes $V_{\\text{high-b}} = \\{v \\in V \\mid b(v) \\ge Q_q(b) \\land b(v) > 0\\}$.\n4.  Compute the APSP distance matrix for the original graph.\n5.  Initialize an empty set of compensated nodes, $V_{\\text{comp}}$.\n6.  For each node $v \\in V$:\n    a. Compute $S_{\\text{before}}(v)$ using the pre-computed APSP distances.\n    b. Construct the subgraph induced by $V \\setminus \\{v\\}$.\n    c. Compute the APSP distance matrix for this subgraph and use it to find $S_{\\text{after}}(v)$.\n    d. Calculate $\\Delta(v)$. If $\\Delta(v) \\le \\tau$, add $v$ to $V_{\\text{comp}}$.\n7.  The final list of a robust bottleneck is the sorted list of nodes in the intersection $V_{\\text{high-b}} \\cap V_{\\text{comp}}$.\n\nThis procedure is deterministic and directly implements the provided definitions, guaranteeing a correct solution for any given input graph.",
            "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef _bfs_for_brandes(adj, s, n):\n    \"\"\"Performs BFS from source s to compute shortest paths info.\"\"\"\n    S = []\n    P = {i: [] for i in range(n)}\n    sigma = {i: 0 for i in range(n)}\n    sigma[s] = 1\n    d = {i: -1 for i in range(n)}\n    d[s] = 0\n    \n    Q = deque([s])\n    \n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        \n        for w in adj.get(v, []):\n            if d[w] < 0:\n                Q.append(w)\n                d[w] = d[v] + 1\n            \n            if d[w] == d[v] + 1:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return S, P, sigma\n\ndef compute_betweenness_centrality(A):\n    \"\"\"Computes betweenness centrality using Brandes' algorithm for unweighted graphs.\"\"\"\n    n = A.shape[0]\n    if n == 0:\n        return {}\n    \n    adj = {i: [j for j, connected in enumerate(row) if connected] for i, row in enumerate(A)}\n    betweenness = {i: 0.0 for i in range(n)}\n\n    for s in range(n):\n        S, P, sigma = _bfs_for_brandes(adj, s, n)\n        delta = {i: 0.0 for i in range(n)}\n        \n        while S:\n            w = S.pop()\n            for v in P.get(w, []):\n                if sigma.get(w, 0) != 0:\n                    delta[v] += (sigma.get(v, 0) / sigma[w]) * (1.0 + delta.get(w, 0.0))\n            if w != s:\n                betweenness[w] += delta.get(w, 0.0)\n\n    # For undirected graphs, divide by 2\n    for v in range(n):\n        betweenness[v] /= 2.0\n    return betweenness\n\ndef get_apsp_distances(A):\n    \"\"\"Computes all-pairs shortest path distances using BFS from each node.\"\"\"\n    n = A.shape[0]\n    dist = np.full((n, n), np.inf, dtype=float)\n    \n    adj = {i: [j for j, connected in enumerate(row) if connected] for i, row in enumerate(A)}\n\n    for i in range(n):\n        dist[i, i] = 0\n        q = deque([(i, 0)])\n        visited = {i}\n        \n        while q:\n            u, d = q.popleft()\n            for v in adj.get(u, []):\n                if v not in visited:\n                    visited.add(v)\n                    dist[i, v] = d + 1\n                    q.append((v, d + 1))\n    return dist\n\ndef find_robust_bottlenecks(A, q, tau):\n    \"\"\"Finds robust bottlenecks in a graph based on centrality and efficiency criteria.\"\"\"\n    n = A.shape[0]\n    nodes = list(range(n))\n\n    # 1. High-betweenness criterion\n    centralities = compute_betweenness_centrality(A)\n    b_values = np.array(list(centralities.values()))\n    \n    if n <= 1 or np.all(b_values == 0):\n        q_threshold = 0.0\n    else:\n        q_threshold = np.quantile(b_values, q, method='linear')\n    \n    high_b_nodes = {v for v, b in centralities.items() if b >= q_threshold and b > 0}\n    \n    if not high_b_nodes:\n        return []\n\n    # 2. Compensation criterion\n    dist_original = get_apsp_distances(A)\n    compensated_nodes = set()\n    \n    for v in nodes:\n        nodes_minus_v = [i for i in nodes if i != v]\n        \n        if len(nodes_minus_v) < 2:\n            delta_v = 0.0\n        else:\n            sum_inv_dist_before = 0.0\n            for i_idx, i in enumerate(nodes_minus_v):\n                for j in nodes_minus_v[i_idx + 1:]:\n                    dist = dist_original[i, j]\n                    if np.isfinite(dist) and dist > 0:\n                        sum_inv_dist_before += 1.0 / dist\n            \n            if sum_inv_dist_before == 0.0:\n                delta_v = 0.0\n            else:\n                adj_minus_v = np.delete(np.delete(A, v, axis=0), v, axis=1)\n                dist_after = get_apsp_distances(adj_minus_v)\n                \n                sum_inv_dist_after = 0.0\n                for i in range(len(nodes_minus_v) - 1):\n                    for j in range(i + 1, len(nodes_minus_v)):\n                        dist = dist_after[i, j]\n                        if np.isfinite(dist) and dist > 0:\n                            sum_inv_dist_after += 1.0 / dist\n                \n                delta_v = (sum_inv_dist_before - sum_inv_dist_after) / sum_inv_dist_before\n        \n        if delta_v <= tau:\n            compensated_nodes.add(v)\n            \n    result_nodes = sorted(list(high_b_nodes.intersection(compensated_nodes)))\n    return result_nodes\n\ndef solve():\n    \"\"\"Main function to run test cases and print results.\"\"\"\n    \n    # Shared parameters from the problem description\n    q = 0.8\n    tau = 0.01\n\n    # Test Case 1\n    A1 = np.array([\n        [0, 1, 1, 0, 0, 0, 1, 1],\n        [1, 0, 1, 0, 0, 0, 1, 1],\n        [1, 1, 0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 0, 1, 1, 1, 1],\n        [0, 0, 0, 1, 0, 1, 1, 1],\n        [0, 0, 0, 1, 1, 0, 1, 1],\n        [1, 1, 1, 1, 1, 1, 0, 0],\n        [1, 1, 1, 1, 1, 1, 0, 0]\n    ])\n\n    # Test Case 2\n    A2 = np.array([\n        [0, 1, 1, 1, 1, 1],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0]\n    ])\n\n    # Test Case 3\n    A3 = np.array([\n        [0, 1, 1, 1],\n        [1, 0, 1, 1],\n        [1, 1, 0, 1],\n        [1, 1, 1, 0]\n    ])\n\n    test_cases = [A1, A2, A3]\n    \n    all_results = []\n    for A in test_cases:\n        result = find_robust_bottlenecks(A, q, tau)\n        all_results.append(str(result).replace(\" \", \"\"))\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        }
    ]
}