{
    "hands_on_practices": [
        {
            "introduction": "Our first hands-on practice addresses a common scenario where a function's direct definition is numerically fragile. We will explore the hyperbolic tangent function, $\\tanh(x)$, whose standard formula is mathematically sound but fails in a floating-point environment due to its reliance on the rapidly growing exponential function. This exercise will guide you through a simple but powerful algebraic rearrangement that results in a perfectly stable algorithm, illustrating a fundamental technique for robust function implementation. ",
            "id": "3260871",
            "problem": "You are tasked with designing a numerically stable algorithm to evaluate the hyperbolic tangent function on real inputs. The goal is to produce accurate values for the function across a wide range of input magnitudes while avoiding overflow and underflow. The fundamental base for this task is the definition of the hyperbolic functions in terms of the exponential function and the properties of the floating-point arithmetic specified by the Institute of Electrical and Electronics Engineers (IEEE) 754 standard.\n\nStarting from first principles, use the definitions based on the exponential function:\n- The hyperbolic sine is defined by $$\\sinh(x) = \\frac{e^{x} - e^{-x}}{2}.$$\n- The hyperbolic cosine is defined by $$\\cosh(x) = \\frac{e^{x} + e^{-x}}{2}.$$\n- The hyperbolic tangent is defined by $$\\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)}.$$\n\nYour task is to rewrite the expression for $$\\tanh(x)$$ in a way that avoids numerical overflow for large positive $$x$$ (where naive computation of $$e^{x}$$ can exceed representable bounds) and avoids numerical underflow for large negative $$x$$ (where naive computation of $$e^{-x}$$ can flush to zero). You must then implement this stable expression in a complete, runnable program.\n\nThe final program must:\n- Implement a function that evaluates $$\\tanh(x)$$ using a numerically stable expression derived from the above definitions and sound floating-point reasoning under the IEEE 754 model.\n- Apply the function to the following test suite of inputs that cover typical and extreme cases:\n  1. $$x = 0.0$$\n  2. $$x = 10^{-12}$$\n  3. $$x = -10^{-12}$$\n  4. $$x = 1.0$$\n  5. $$x = -1.0$$\n  6. $$x = 709.0$$\n  7. $$x = -709.0$$\n  8. $$x = 750.0$$\n  9. $$x = -750.0$$\n- Produce the outputs as floating-point numbers with no units (the quantity is dimensionless).\n- Output format specification: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). No other text should be printed.\n\nYour design and implementation should explicitly avoid expressions that trigger overflow for large positive inputs or cause unnecessary underflow-induced loss of accuracy for large negative inputs, adhering to the constraints of floating-point arithmetic.",
            "solution": "The problem as stated is valid. It is scientifically grounded in the principles of numerical analysis and floating-point arithmetic, is well-posed, and is expressed with objective and formal language. We may therefore proceed with a solution.\n\nThe objective is to formulate a numerically stable algorithm for computing the hyperbolic tangent function, $\\tanh(x)$, for a real input $x$. The derivation begins from the fundamental definitions of the hyperbolic sine, $\\sinh(x)$, and hyperbolic cosine, $\\cosh(x)$, in terms of the exponential function.\n\nThe definitions are:\n$$ \\sinh(x) = \\frac{e^{x} - e^{-x}}{2} $$\n$$ \\cosh(x) = \\frac{e^{x} + e^{-x}}{2} $$\n\nFrom these, the hyperbolic tangent is defined as their ratio:\n$$ \\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)} = \\frac{\\frac{e^{x} - e^{-x}}{2}}{\\frac{e^{x} + e^{-x}}{2}} = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $$\n\nThis last expression, $\\tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$, constitutes the naive computational formula. We must analyze its behavior under the constraints of finite-precision floating-point arithmetic, specifically the IEEE 754 standard for double-precision numbers.\n\nA key limitation of floating-point arithmetic is its finite range. For standard double-precision, the maximum representable value is approximately $1.797 \\times 10^{308}$. The exponential function $e^x$ grows very rapidly. The value of $x$ for which $e^x$ exceeds this maximum is $x > \\ln(1.797 \\times 10^{308}) \\approx 709.78$. Any attempt to compute $e^x$ for $x$ beyond this threshold will result in a numerical overflow, typically represented as infinity ($\\infty$).\n\nLet us analyze the naive formula in light of this limitation:\n1.  For large positive $x$ (e.g., $x > 709.78$): The term $e^x$ overflows to $\\infty$. The term $e^{-x}$ correctly evaluates to a very small positive number (or underflows to $0$). The expression becomes $\\frac{\\infty - 0}{\\infty + 0}$, which is an indeterminate form $\\frac{\\infty}{\\infty}$ that evaluates to `NaN` (Not a Number). This is numerically incorrect, as the mathematical limit is $\\lim_{x \\to \\infty} \\tanh(x) = 1$.\n\n2.  For large-magnitude negative $x$ (e.g., $x < -709.78$): Let $x = -y$ where $y$ is large and positive. The term $e^x = e^{-y}$ correctly evaluates to a very small positive number (or $0$). However, the term $e^{-x} = e^y$ overflows to $\\infty$. The expression becomes $\\frac{0 - \\infty}{0 + \\infty}$, an indeterminate form $\\frac{-\\infty}{\\infty}$ that also results in `NaN`. This is again incorrect, as the mathematical limit is $\\lim_{x \\to -\\infty} \\tanh(x) = -1$.\n\nTo construct a stable algorithm, we must reformulate the expression to avoid computing the exponential of a large positive number. This can be achieved by algebraic manipulation, leading to a piecewise function based on the sign of $x$.\n\n**Case 1: $x \\ge 0$**\nFor non-negative $x$, the term $e^x$ is the source of potential overflow. We can eliminate it by multiplying the numerator and denominator by $e^{-x}$:\n$$ \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\cdot \\frac{e^{-x}}{e^{-x}} = \\frac{e^x e^{-x} - e^{-x} e^{-x}}{e^x e^{-x} + e^{-x} e^{-x}} = \\frac{1 - e^{-2x}}{1 + e^{-2x}} $$\nIn this form, $\\tanh(x) = \\frac{1 - e^{-2x}}{1 + e^{-2x}}$, the argument of the exponential function is $-2x$. Since $x \\ge 0$, the argument $-2x$ is always non-positive. The computation of $e^{-2x}$ will never overflow. For large positive $x$, $-2x$ becomes a large-magnitude negative number, and $e^{-2x}$ will harmlessly underflow to $0$. In this limit, the expression correctly evaluates to $\\frac{1 - 0}{1 + 0} = 1$. This form is numerically stable for all $x \\ge 0$.\n\n**Case 2: $x < 0$**\nFor negative $x$, the term $e^{-x}$ is the source of potential overflow. We can eliminate this term by multiplying the numerator and denominator of the original expression by $e^x$:\n$$ \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\cdot \\frac{e^x}{e^x} = \\frac{e^x e^x - e^{-x} e^x}{e^x e^x + e^{-x} e^x} = \\frac{e^{2x} - 1}{e^{2x} + 1} $$\nIn this form, $\\tanh(x) = \\frac{e^{2x} - 1}{e^{2x} + 1}$, the argument of the exponential function is $2x$. Since $x < 0$, the argument $2x$ is always negative. The computation of $e^{2x}$ will never overflow. For large-magnitude negative $x$, $2x$ becomes a large-magnitude negative number, and $e^{2x}$ will harmlessly underflow to $0$. In this limit, the expression correctly evaluates to $\\frac{0 - 1}{0 + 1} = -1$. This form is numerically stable for all $x < 0$. This result is also consistent with the odd-function property $\\tanh(x) = -\\tanh(-x)$, which would yield the same expression.\n\n**Final Algorithm**\nThe derived numerically stable algorithm for evaluating $\\tanh(x)$ is a piecewise function:\n$$\n\\tanh(x) =\n\\begin{cases}\n    \\frac{1 - e^{-2x}}{1 + e^{-2x}} & \\text{if } x \\ge 0 \\\\\n    \\frac{e^{2x} - 1}{e^{2x} + 1} & \\text{if } x < 0\n\\end{cases}\n$$\nThis algorithm avoids numerical overflow for all real inputs $x$ by ensuring that the argument to the exponential function is always non-positive.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef stable_tanh(x):\n    \"\"\"\n    Computes tanh(x) using a numerically stable algorithm to avoid\n    overflow and underflow issues for large magnitude inputs.\n\n    This function implements a piecewise expression for tanh(x) derived\n    from first principles to ensure that the argument to the exponential\n    function is always non-positive, thus preventing overflow.\n    \"\"\"\n    # Ensure the input is treated as a 64-bit float for consistency\n    # with standard double-precision floating-point arithmetic (IEEE 754).\n    x_f64 = np.float64(x)\n\n    # For non-negative x, use the form tanh(x) = (1 - exp(-2x)) / (1 + exp(-2x)).\n    # The exponent (-2x) is guaranteed to be non-positive, thus np.exp\n    # will not overflow. It may underflow to 0 for large x, which is\n    # the desired behavior, yielding a result of 1.0.\n    if x_f64 >= 0.0:\n        exp_val = np.exp(-2.0 * x_f64)\n        return (1.0 - exp_val) / (1.0 + exp_val)\n    \n    # For negative x, use the form tanh(x) = (exp(2x) - 1) / (exp(2x) + 1).\n    # The exponent (2x) is guaranteed to be negative, thus np.exp\n    # will not overflow. It may underflow to 0 for large-magnitude\n    # negative x, which is the desired behavior, yielding a result of -1.0.\n    else:\n        exp_val = np.exp(2.0 * x_f64)\n        return (exp_val - 1.0) / (exp_val + 1.0)\n\ndef solve():\n    \"\"\"\n    Main function to execute the test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        0.0,\n        1e-12,\n        -1e-12,\n        1.0,\n        -1.0,\n        709.0,\n        -709.0,\n        750.0,\n        -750.0,\n    ]\n\n    results = []\n    for case in test_cases:\n        # Calculate the result for one case using the stable function.\n        result = stable_tanh(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) function converts each float in the results list\n    # to its string representation before joining them with commas.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the main function.\nsolve()\n```"
        },
        {
            "introduction": "While algebraic manipulation is effective for some expressions, many problems involving large products require a more systematic approach. This practice demonstrates how to tame extreme values by transforming the entire computation into logarithmic space, a cornerstone technique in scientific computing. You will develop a robust method to calculate the factorial $n!$ for very large $n$, where direct multiplication would instantly overflow, by converting the product into a manageable sum of logarithms. ",
            "id": "3260852",
            "problem": "You are to design and implement a robust computation in a floating-point environment that avoids overflow and underflow when evaluating the factorial function. The fundamental base for your derivation is the definition of factorial as a product and the general properties of logarithms and the gamma function. The context is the Institute of Electrical and Electronics Engineers (IEEE) $754$ double-precision floating-point arithmetic. In such a system, the representable magnitude of normalized numbers is limited, and direct evaluation of $n!$ or its reciprocal can overflow or underflow for large $n$. Your task is to reason from first principles to reformulate the computation so that it stays well within the representable range at all intermediate steps.\n\nStart from the definition of factorial $n!$ as a finite product $\\prod_{k=1}^{n} k$ for integer $n \\ge 0$, and the general properties of the gamma function $\\Gamma(x)$ and logarithms $\\log(x)$ without assuming any shortcut formulas. You may assume that a black-box function is available which returns $\\log(\\Gamma(x))$ for $x > 0$, and you may treat it as numerically stable in the double-precision setting. Your algorithm must operate in a base-$10$ logarithmic representation in order to summarize both $n!$ and $1/n!$ without causing numerical overflow or underflow.\n\nSpecification:\n- For each integer input $n \\ge 0$, compute a base-$10$ scientific-notation representation of $n!$ and $1/n!$ of the form $m \\times 10^{e}$, where $m \\in [1,10)$ and $e \\in \\mathbb{Z}$. Let $m_f$ and $e_f$ denote the mantissa and exponent for $n!$, and let $m_r$ and $e_r$ denote the mantissa and exponent for $1/n!$.\n- Use only the base-$10$ logarithm values derived from $\\log(\\Gamma(\\cdot))$ and properties of logarithms to obtain $m_f$, $e_f$, $m_r$, and $e_r$ without directly computing $n!$ or $1/n!$ in standard floating-point form.\n- Round both mantissas $m_f$ and $m_r$ to $10$ decimal places, leaving exponents $e_f$ and $e_r$ as exact integers.\n\nTest suite:\n- Use the following list of test values for $n$: $[0, 10, 170, 171, 100000]$. These values are chosen to cover multiple facets:\n  - $n = 0$ checks the boundary condition at the factorial identity.\n  - $n = 10$ is a typical case where naive computation would be safe, serving as a consistency check.\n  - $n = 170$ is near the upper boundary for finite representation of $n!$ in IEEE $754$ double precision.\n  - $n = 171$ exceeds the overflow threshold for $n!$ in IEEE $754$ double precision.\n  - $n = 100000$ is extremely large and stresses the logarithmic method.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element in the list corresponds to one test case and must itself be a list of four values in the order $[m_f, e_f, m_r, e_r]$. For example, the output format must be exactly like:\n  - $[[m_{f,0}, e_{f,0}, m_{r,0}, e_{r,0}], [m_{f,1}, e_{f,1}, m_{r,1}, e_{r,1}], \\dots]$\n- All mantissas must be floats rounded to $10$ decimal places, and all exponents must be integers.\n\nDo not include any physical units in your answer, and do not use percentages. All angles, if they were to appear (they do not in this task), would be in radians by default.",
            "solution": "The problem requires the design of a numerically stable algorithm to compute the scientific notation representation, $m \\times 10^e$, of $n!$ and its reciprocal $1/n!$ for non-negative integers $n$. The core challenge is to avoid the overflow and underflow issues that arise from the direct computation of $n!$ in standard floating-point arithmetic, particularly for large values of $n$. The specified methodology is to reason from first principles, utilizing the properties of logarithms and a provided stable function for the logarithm of the gamma function, $\\log(\\Gamma(x))$. For the purpose of this derivation, we will assume $\\log(x)$ denotes the natural logarithm, $\\ln(x)$, as is standard in scientific computing contexts and function libraries.\n\n### Principle of Logarithmic Computation\n\nThe fundamental strategy to manage extremely large or small numbers resulting from products is to transform the computation into the logarithmic domain. A product of terms becomes a sum of their logarithms:\n$$ \\log\\left(\\prod_{i=1}^{n} x_i\\right) = \\sum_{i=1}^{n} \\log(x_i) $$\nFor the factorial function, which is defined as $n! = \\prod_{k=1}^{n} k$ for $n \\ge 1$, this property implies:\n$$ \\ln(n!) = \\ln\\left(\\prod_{k=1}^{n} k\\right) = \\sum_{k=1}^{n} \\ln(k) $$\nA sum of logarithms grows much more slowly than the corresponding product of the numbers themselves. For instance, while $171!$ exceeds the maximum representable value in IEEE $754$ double-precision arithmetic (approximately $1.8 \\times 10^{308}$), its natural logarithm, $\\ln(171!) \\approx 711.8$, is a perfectly manageable number. This transformation from multiplication to addition is the key to preventing overflow. Similarly, it prevents underflow when dealing with the reciprocal, $1/n!$.\n\n### Connection to the Gamma Function\n\nThe problem provides a black-box function to compute $\\ln(\\Gamma(x))$ in a numerically stable manner. The Gamma function, $\\Gamma(x)$, is a generalization of the factorial function to complex numbers. For any non-negative integer $n$, it satisfies the identity:\n$$ \\Gamma(n+1) = n! $$\nTaking the natural logarithm of both sides gives a direct method to find $\\ln(n!)$ without computing a potentially unstable sum:\n$$ \\ln(n!) = \\ln(\\Gamma(n+1)) $$\nWe can therefore use the provided stable `log-gamma` function to obtain an accurate value for $\\ln(n!)$, even for very large $n$.\n\n### Conversion to Base-10 Scientific Notation\n\nThe objective is to express a number $X$ (which will be $n!$ or $1/n!$) in base-$10$ scientific notation, $X = m \\times 10^e$, where the mantissa $m$ is in the range $[1, 10)$ and the exponent $e$ is an integer.\n\nTo find $m$ and $e$, we take the base-$10$ logarithm of the equation:\n$$ \\log_{10}(X) = \\log_{10}(m \\times 10^e) = \\log_{10}(m) + \\log_{10}(10^e) = \\log_{10}(m) + e $$\nThe constraint on the mantissa, $1 \\le m < 10$, implies that its base-$10$ logarithm is in the range $0 \\le \\log_{10}(m) < 1$. This means $\\log_{10}(m)$ is the fractional part of $\\log_{10}(X)$, and $e$ is the integer part.\n\nLet $L = \\log_{10}(X)$. The exponent $e$ and mantissa $m$ can be extracted as follows:\n- The exponent is the floor of $L$: $e = \\lfloor L \\rfloor$.\n- The mantissa is derived from the fractional part of $L$: $m = 10^{(L - \\lfloor L \\rfloor)}$.\n\n### Algorithm for $n!$ and $1/n!$\n\nWe now apply this decomposition to $n!$ and $1/n!$.\n\n1.  **Compute the base-10 logarithm of $n!$**:\n    First, we find $\\ln(n!)$ using the log-gamma function: $\\ln(n!) = \\ln(\\Gamma(n+1))$.\n    Then, we convert this to base-$10$ using the change of base formula, $\\log_{10}(x) = \\frac{\\ln(x)}{\\ln(10)}$. Let this value be $L_f$.\n    $$ L_f = \\log_{10}(n!) = \\frac{\\ln(\\Gamma(n+1))}{\\ln(10)} $$\n\n2.  **Extract mantissa and exponent for $n!$**:\n    Using the logic derived above, the mantissa $m_f$ and exponent $e_f$ for $n!$ are:\n    $$ e_f = \\lfloor L_f \\rfloor $$\n    $$ m_f = 10^{(L_f - e_f)} = 10^{(L_f - \\lfloor L_f \\rfloor)} $$\n\n3.  **Extract mantissa and exponent for $1/n!$**:\n    For the reciprocal $1/n!$, its base-$10$ logarithm, $L_r$, is simply the negative of $L_f$:\n    $$ L_r = \\log_{10}(1/n!) = \\log_{10}(n!^{-1}) = - \\log_{10}(n!) = -L_f $$\n    We apply the same decomposition to $L_r$ to find the mantissa $m_r$ and exponent $e_r$:\n    $$ e_r = \\lfloor L_r \\rfloor = \\lfloor -L_f \\rfloor $$\n    $$ m_r = 10^{(L_r - e_r)} = 10^{(-L_f - \\lfloor -L_f \\rfloor)} $$\n\n4.  **Handling the case $n=0$**:\n    By definition, $0! = 1$. The algorithm must also handle this base case correctly.\n    For $n=0$, we have $\\Gamma(0+1) = \\Gamma(1) = 1$.\n    Then $\\ln(\\Gamma(1)) = \\ln(1) = 0$.\n    This gives $L_f = \\log_{10}(1) = 0$.\n    For $n!$: $e_f = \\lfloor 0 \\rfloor = 0$ and $m_f = 10^{(0-0)} = 1$. This corresponds to $1 \\times 10^0$, which is correct.\n    For $1/n!$: $L_r = -0 = 0$. So, $e_r = \\lfloor 0 \\rfloor = 0$ and $m_r = 10^{(0-0)} = 1$. This is also correct.\n    The algorithm is thus valid for all $n \\ge 0$.\n\nThis procedure computes the mantissa and exponent for $n!$ and $1/n!$ using only logarithmic-domain operations on well-behaved numbers, thereby robustly avoiding any overflow or underflow. The final implementation will round the computed mantissas to $10$ decimal places as required.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Computes the scientific notation representation for n! and 1/n!\n    for a list of test cases, avoiding overflow and underflow.\n    \"\"\"\n\n    test_cases = [0, 10, 170, 171, 100000]\n    \n    # Pre-calculate the natural logarithm of 10 for change of base.\n    LN_10 = math.log(10)\n\n    def calculate_sci_notation(n: int) -> list:\n        \"\"\"\n        Calculates m_f, e_f, m_r, e_r for a given integer n.\n        \n        Args:\n            n: A non-negative integer.\n\n        Returns:\n            A list containing [m_f, e_f, m_r, e_r], where m_f and m_r are\n            mantissas rounded to 10 decimal places, and e_f and e_r are\n            integer exponents.\n        \"\"\"\n        if n == 0:\n            # Base case: 0! = 1.\n            # 1 = 1.0 * 10^0. Reciprocal is the same.\n            return [1.0, 0, 1.0, 0]\n\n        # Use the identity ln(n!) = ln(Gamma(n+1)).\n        # math.lgamma(x) computes ln(|Gamma(x)|) stably.\n        ln_factorial = math.lgamma(n + 1)\n        \n        # Convert to base-10 logarithm: log10(x) = ln(x) / ln(10).\n        log10_factorial = ln_factorial / LN_10\n        \n        # --- For n! ---\n        # The exponent is the integer part of the base-10 logarithm.\n        e_f = math.floor(log10_factorial)\n        # The mantissa is 10 raised to the power of the fractional part.\n        m_f = 10**(log10_factorial - e_f)\n        \n        # --- For 1/n! ---\n        # log10(1/n!) = -log10(n!)\n        log10_reciprocal = -log10_factorial\n        \n        # The exponent is the integer part.\n        e_r = math.floor(log10_reciprocal)\n        # The mantissa is 10 raised to the power of the fractional part.\n        m_r = 10**(log10_reciprocal - e_r)\n        \n        # Return the results, rounded and typed as specified.\n        return [\n            round(m_f, 10),\n            int(e_f),\n            round(m_r, 10),\n            int(e_r)\n        ]\n\n    results = []\n    for n in test_cases:\n        results.append(calculate_sci_notation(n))\n\n    # The format requires no spaces inside the inner lists' string representation.\n    # Python's default str(list) includes spaces. This custom formatting avoids them.\n    formatted_results = []\n    for res in results:\n        # Format \"m_f\" as a float string, \"e_f\" as an int, etc.\n        # The rounding to 10 places is handled in the function, so we just format.\n        formatted_inner_list = f\"[{res[0]},{res[1]},{res[2]},{res[3]}]\"\n        formatted_results.append(formatted_inner_list)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Overflow and underflow errors do not only appear in single-shot calculations; they can also emerge from the cumulative behavior of iterative algorithms. In this final practice, we will investigate how a numerical method can become unstable and produce overflowing results, even when the exact analytical solution is perfectly bounded. By applying the forward Euler method to a simple ordinary differential equation, you will see firsthand how an inappropriate choice of a parameter—the step size $h$—can lead to catastrophic failure, highlighting the crucial link between numerical stability and overflow. ",
            "id": "3260938",
            "problem": "Construct and analyze a scalar ordinary differential equation where a naive forward explicit Euler method exhibits numerical overflow even though the analytical solution remains bounded. Use the following fundamental bases: the definition of a scalar linear ordinary differential equation, the forward explicit Euler method derived from the first-order Taylor approximation, and the behavior of Institute of Electrical and Electronics Engineers (IEEE) $754$ double-precision floating-point arithmetic regarding overflow and underflow.\n\nYou must work with the scalar linear test problem $$\\frac{dy}{dt}=\\lambda y,$$ with constant parameter $\\lambda\\in\\mathbb{R}$ and initial value $y(0)=y_0$. The analytical solution obtained by separation of variables is $$y(t)=y_0 e^{\\lambda t}.$$ The forward explicit Euler method applied on a uniform grid with step size $h>0$ produces the recurrence $$y_{n+1}=y_n+h f(t_n,y_n)=y_n+h \\lambda y_n=(1+h\\lambda)\\,y_n,$$ where $t_n=n h$. In finite precision arithmetic, if $|1+h\\lambda|>1$ and $n$ is sufficiently large, the sequence $\\{y_n\\}$ can grow in magnitude and exceed the largest representable IEEE $754$ double-precision number, causing overflow to a special value representing $+\\infty$ or $-\\infty$. In contrast, for $\\lambda<0$, the analytical solution $y(t)=y_0 e^{\\lambda t}$ is bounded and decays to $0$ as $t\\to\\infty$. Your program must demonstrate this phenomenon and verify overflow conditions.\n\nYour program must:\n- Implement the explicit Euler method update $y_{n+1}=(1+h\\lambda)\\,y_n$ for $n=0,1,\\dots,N-1$ in IEEE $754$ double-precision arithmetic, using a standard floating-point type.\n- Detect numerical overflow during the Euler iteration by checking finiteness of $y_n$ at each step; treat non-finite values (infinite or not-a-number) as overflow.\n- Compute the analytical value $y(T)$ at final time $T=N h$ as $y(T)=y_0 e^{\\lambda T}$ and check whether this analytical value is finite (bounded) in IEEE $754$ double-precision arithmetic.\n- For each test case, report a boolean indicating whether the Euler iteration overflowed while the analytical solution remained bounded, i.e., report $\\text{True}$ exactly when the Euler iteration produced a non-finite value at some step and the analytical value $y(T)$ is finite; otherwise report $\\text{False}$.\n\nUse the following test suite, which is designed to cover distinct behaviors:\n- Case $1$ (unstable Euler, overflow): $\\lambda=-1000$, $y_0=1$, $h=0.01$, $N=400$.\n- Case $2$ (stable Euler, no overflow): $\\lambda=-1$, $y_0=1$, $h=0.1$, $N=200$.\n- Case $3$ (stability boundary, no overflow): $\\lambda=-1$, $y_0=1$, $h=2.0$, $N=1000$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3]$), where each $result_i$ is a boolean computed as specified above. No physical units are involved in this problem, and no angles are used. All parameters and computations are purely numerical. The output must be deterministic and reproducible without any external input.",
            "solution": "The problem requires an analysis of the forward explicit Euler method for a specific scalar ordinary differential equation (ODE), demonstrating how numerical instability can lead to overflow even when the true analytical solution is bounded. We will first establish the theoretical basis and then apply it to the given test cases.\n\nThe problem is centered on the scalar linear test equation:\n$$\n\\frac{dy}{dt} = \\lambda y\n$$\nwith a real constant parameter $\\lambda$ and an initial condition $y(t=0) = y_0$.\n\nThe analytical solution to this ODE can be found by separation of variables:\n$$\n\\frac{dy}{y} = \\lambda dt \\implies \\int_{y_0}^{y(t)} \\frac{d\\tilde{y}}{\\tilde{y}} = \\int_0^t \\lambda d\\tilde{t} \\implies \\ln\\left(\\frac{y(t)}{y_0}\\right) = \\lambda t\n$$\nExponentiating both sides yields the exact solution:\n$$\ny(t) = y_0 e^{\\lambda t}\n$$\nFor the cases considered in this problem, $\\lambda < 0$. In this scenario, the analytical solution $y(t)$ is an exponentially decaying function. As $t \\to \\infty$, $y(t) \\to 0$. For any finite time $T$, the value $y(T) = y_0 e^{\\lambda T}$ is a well-defined, finite number.\n\nThe forward explicit Euler method is a numerical scheme for approximating the solution of an ODE. It is derived from a first-order Taylor series expansion of the solution $y(t)$ around time $t_n$:\n$$\ny(t_{n+1}) = y(t_n + h) \\approx y(t_n) + h y'(t_n)\n$$\nwhere $h$ is the time step size. Substituting the ODE $y'(t_n) = f(t_n, y(t_n)) = \\lambda y(t_n)$, we obtain the recurrence relation for the numerical approximation $y_n \\approx y(t_n)$:\n$$\ny_{n+1} = y_n + h (\\lambda y_n) = (1 + h\\lambda) y_n\n$$\nThis is a geometric progression. Unwinding the recurrence gives the explicit formula for $y_n$:\n$$\ny_n = (1 + h\\lambda)^n y_0\n$$\nThe behavior of the numerical solution $\\{y_n\\}$ depends entirely on the amplification factor $R = 1 + h\\lambda$. The numerical solution is considered stable if its magnitude does not grow unboundedly. This occurs if and only if $|R| \\le 1$, which is the condition for absolute stability of the forward Euler method for this test problem.\n$$\n|1 + h\\lambda| \\le 1\n$$\nSince the problem specifies $\\lambda < 0$, we can write this as:\n$$\n-1 \\le 1 + h\\lambda \\le 1\n$$\nThe right-hand inequality, $1 + h\\lambda \\le 1$, simplifies to $h\\lambda \\le 0$, which is always true for $h > 0$ and $\\lambda < 0$. The critical condition comes from the left-hand inequality:\n$$\n-1 \\le 1 + h\\lambda \\implies -2 \\le h\\lambda \\implies h \\le -\\frac{2}{\\lambda}\n$$\nIf the step size $h$ violates this condition, i.e., $h > -2/\\lambda$, the method becomes unstable. In this case, $1 + h\\lambda < -1$, so the amplification factor $R$ has a magnitude greater than $1$. The numerical solution $y_n = R^n y_0$ will oscillate with exponentially increasing amplitude. In finite-precision arithmetic, such as IEEE $754$ double-precision, this rapid growth will eventually cause the value of $|y_n|$ to exceed the largest representable finite number (approximately $1.8 \\times 10^{308}$), leading to a numerical overflow, typically represented as `inf` or `-inf`.\n\nThe task is to identify cases where this numerical overflow occurs ($y_n$ becomes non-finite) while the analytical solution $y(T)=y_0e^{\\lambda T}$ remains finite. This phenomenon highlights a purely numerical artifact where the chosen discretization (step size $h$) is inappropriate for the stiffness of the problem (magnitude of $\\lambda$).\n\nLet us analyze the given test cases:\n\nCase $1$: $\\lambda=-1000$, $y_0=1$, $h=0.01$, $N=400$.\n- Stability boundary: $h \\le -2/\\lambda = -2/(-1000) = 0.002$.\n- The chosen step size is $h=0.01$. Since $0.01 > 0.002$, the method is unstable.\n- The amplification factor is $R = 1 + (0.01)(-1000) = 1 - 10 = -9$.\n- The numerical solution is $y_n = (-9)^n$. The magnitude $|y_n| = 9^n$ grows very quickly. For a sufficiently large $n < N$, the value of $y_n$ will overflow. For instance, $9^{324}$ is larger than $10^{308}$, so overflow will occur well before the final step $N=400$.\n- The analytical solution at the final time $T = N h = 400 \\times 0.01 = 4.0$ is $y(4.0) = 1 \\cdot e^{-1000 \\times 4.0} = e^{-4000}$. This is an exceedingly small positive number, which is finite and representable (it will underflow to $0.0$ in double precision, but $0.0$ is a finite number).\n- Conclusion: The Euler method overflows, while the analytical solution is finite. The result is $\\text{True}$.\n\nCase $2$: $\\lambda=-1$, $y_0=1$, $h=0.1$, $N=200$.\n- Stability boundary: $h \\le -2/\\lambda = -2/(-1) = 2.0$.\n- The chosen step size is $h=0.1$. Since $0.1 \\le 2.0$, the method is stable.\n- The amplification factor is $R = 1 + (0.1)(-1) = 0.9$.\n- The numerical solution is $y_n = (0.9)^n$. Since $|R| < 1$, the solution decays towards $0$ and will not overflow.\n- The analytical solution at $T = N h = 200 \\times 0.1 = 20.0$ is $y(20.0) = 1 \\cdot e^{-1 \\times 20.0} = e^{-20}$, which is a small but finite positive number.\n- Conclusion: The Euler method does not overflow, and the analytical solution is finite. The result is $\\text{False}$.\n\nCase $3$: $\\lambda=-1$, $y_0=1$, $h=2.0$, $N=1000$.\n- Stability boundary: $h \\le -2/\\lambda = -2/(-1) = 2.0$.\n- The chosen step size is $h=2.0$, which is exactly on the boundary of stability.\n- The amplification factor is $R = 1 + (2.0)(-1) = -1$.\n- The numerical solution is $y_n = (-1)^n y_0 = (-1)^n$. The values will alternate between $1$ and $-1$. The magnitude remains constant and does not grow, so no overflow will occur.\n- The analytical solution at $T = N h = 1000 \\times 2.0 = 2000.0$ is $y(2000.0) = 1 \\cdot e^{-1 \\times 2000.0} = e^{-2000}$. This is an extremely small positive number that will evaluate to $0.0$ in double-precision arithmetic, which is a finite value.\n- Conclusion: The Euler method does not overflow, and the analytical solution is finite. The result is $\\text{False}$.\n\nThe implementation will follow this logic, iterating the Euler step, checking for non-finite values, computing the analytical solution at the final time, and combining the checks to produce the required boolean outputs.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(lambda_val, y0, h, N):\n    \"\"\"\n    Runs the forward Euler simulation for the ODE y' = lambda * y and checks for overflow.\n\n    Args:\n        lambda_val (float): The parameter lambda in the ODE.\n        y0 (float): The initial value y(0).\n        h (float): The time step size.\n        N (int): The number of steps.\n\n    Returns:\n        bool: True if Euler overflowed and the analytical solution is finite, False otherwise.\n    \"\"\"\n    # Use numpy.float64 for explicit IEEE 754 double-precision arithmetic.\n    y = np.float64(y0)\n    lambda_val_f64 = np.float64(lambda_val)\n    h_f64 = np.float64(h)\n\n    euler_overflowed = False\n    \n    # Calculate the amplification factor once.\n    amplification_factor = 1.0 + h_f64 * lambda_val_f64\n\n    # Perform the Euler iterations\n    for _ in range(N):\n        # Update the numerical solution\n        y = amplification_factor * y\n        \n        # Check for overflow (inf) or invalid number (nan)\n        if not np.isfinite(y):\n            euler_overflowed = True\n            break\n            \n    # Calculate the final time T\n    T = N * h_f64\n    \n    # Compute the analytical solution y(T) = y0 * exp(lambda * T)\n    # np.exp handles large negative exponents by underflowing to 0.0, which is finite.\n    analytical_val = np.float64(y0) * np.exp(lambda_val_f64 * T)\n    \n    # Check if the analytical solution is a finite number\n    analytical_is_finite = np.isfinite(analytical_val)\n    \n    # The problem asks to report True only if Euler overflowed AND the analytical solution is finite.\n    return euler_overflowed and analytical_is_finite\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases as tuples of (lambda, y0, h, N).\n    test_cases = [\n        # Case 1: Unstable Euler, should overflow\n        (-1000.0, 1.0, 0.01, 400),\n        # Case 2: Stable Euler, no overflow\n        (-1.0, 1.0, 0.1, 200),\n        # Case 3: Stability boundary, no overflow\n        (-1.0, 1.0, 2.0, 1000),\n    ]\n\n    results = []\n    for case in test_cases:\n        lambda_val, y0, h, N = case\n        result = run_simulation(lambda_val, y0, h, N)\n        # The output format requires lowercase booleans.\n        results.append(str(result).lower())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}