{
    "hands_on_practices": [
        {
            "introduction": "数字计算机使用有限的位数来表示数字，这引入了固有的精度限制。本实践将通过对谐波级数求和来直观地展示这一基本限制，即当累加和相对于要添加的项变得非常大时，计算将停滞。通过这个练习，您将亲眼目睹并量化一个看似无限的数学过程如何在有限精度的算术中达到实际的终点，从而揭示数值计算的一个核心挑战 。",
            "id": "3258052",
            "problem": "考虑由部分和 $H_n = \\sum_{k=1}^{n} \\frac{1}{k}$ 定义的调和级数。在一个遵循美国电气和电子工程师协会 (IEEE) 754 标准的向最近舍入的有限精度浮点系统中，加上一个非常小的正增量可能不会改变存储的和，因为该增量小于当前和的量级下的最后一位单位 (half-ulp) 的一半。设机器 epsilon $\\varepsilon$ 为 $1$ 与下一个更大的可表示数之间的距离，并将单位舍入误差 $u$ 定义为 $u = \\varepsilon/2$。对于规格化数，正量级 $S$ 下的半 ulp 约为 $u \\cdot S$。当将 $\\frac{1}{n}$ 添加到累积的调和级数和中不再改变存储的和时，其阈值索引 $n$ 满足不等式 $\\frac{1}{n} \\le u \\cdot H_{n-1}$。调和数具有渐近展开式 $H_n = \\ln(n) + \\gamma + \\frac{1}{2n} - \\frac{1}{12 n^2} + O(n^{-4})$，其中 $\\gamma$ 是欧拉-马歇罗尼常数。\n\n您的任务是编写一个完整、可运行的程序，完成以下任务。\n\n1. 低精度下的经验检测：\n   - 对于 IEEE 754 半精度（binary16，视为 $\\texttt{np.float16}$），使用目标精度对 $k = 1, 2, 3, \\dots$ 的 $\\frac{1}{k}$ 进行前向求和。当计算出的和 $S$ 因该精度下的舍入而满足 $S + \\frac{1}{n} = S$ 时，在最小的索引 $n$ 处停止。以整数形式报告这个 $n$。\n   - 对于 IEEE 754 单精度（binary32，视为 $\\texttt{np.float32}$），执行相同的前向求和和停止准则。以整数形式报告最小的 $n$。\n\n2. 基于理论的阈值估计：\n   - 使用条件 $\\frac{1}{n} \\le u \\cdot H_n$ 和渐近展开式 $H_n \\approx \\ln(n) + \\gamma + \\frac{1}{2n} - \\frac{1}{12 n^2}$，计算使该不等式对 IEEE 754 单精度成立的最小整数 $n$，其中 $\\varepsilon = 2^{-23}$ 且 $u = 2^{-24}$。以整数形式报告这个 $n$。\n   - 使用相同的不等式和渐近展开式，计算 IEEE 754 双精度（binary64）的最小整数 $n$，其中 $\\varepsilon = 2^{-52}$ 且 $u = 2^{-53}$。以整数形式报告这个 $n$。\n\n使用的基本原理：\n- 调和数 $H_n$ 的定义。\n- IEEE 754 浮点模型，采用向最近舍入，以及机器 epsilon $\\varepsilon$、单位舍入误差 $u$ 和对于规格化数量级 $S$ 下的半 ulp 近似为 $u \\cdot S$ 的概念。\n- 如上所述的 $H_n$ 的渐近展开式。\n\n约束和科学现实性：\n- 所有计算都必须使用指定的浮点精度。在进行经验求和时，确保每次加法都在目标精度下执行，以便正确模拟舍入效应。\n- 对于基于理论的阈值，使用 $H_n$ 的渐近展开式定义一个关于 $n$ 的单调不等式，并通过数学上可靠的求根方法（例如对整数进行二分法）来确定满足 $\\frac{1}{n} \\le u \\cdot H_n$ 的最小 $n$。\n\n测试套件：\n- 情况 A：$\\texttt{np.float16}$ 前向求和的经验阈值。\n- 情况 B：$\\texttt{np.float32}$ 前向求和的经验阈值。\n- 情况 C：使用 $\\varepsilon = 2^{-23}$ 和 $u = 2^{-24}$ 的 $\\texttt{np.float32}$ 的理论阈值。\n- 情况 D：使用 $\\varepsilon = 2^{-52}$ 和 $u = 2^{-53}$ 的 $\\texttt{np.float64}$ 的理论阈值。\n\n答案规范：\n- 对于每种情况，答案必须是一个整数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[resultA,resultB,resultC,resultD]”）。",
            "solution": "该问题要求我们确定一个阈值索引 $n$，当调和级数 $H_n = \\sum_{k=1}^{n} \\frac{1}{k}$ 的前向求和在有限精度浮点运算中实际上停滞时，该索引 $n$ 的值是多少。这种情况发生在下一个要加的项 $\\frac{1}{n}$ 太小以至于加法运算无法记录时。我们将采用两种不同的方法来解决这个问题：直接经验模拟和基于渐近近似的理论分析。\n\n**第 1 部分：求和停滞的经验检测**\n\n对于情况 A 和 B，我们执行直接的迭代求和，以找到在指定浮点精度下满足条件 $S + \\frac{1}{n} = S$ 的最小整数 $n$。这里，$S$ 表示计算出的部分和 $H_{n-1} = \\sum_{k=1}^{n-1} \\frac{1}{k}$。\n\n算法流程如下：\n$1$. 在目标精度（情况 A 为 `np.float16`，情况 B 为 `np.float32`）下，将和变量 $S$ 初始化为 $0.0$。\n$2$. 将整数索引 $n$ 初始化为 $1$。\n$3$. 进入一个循环，直到满足停止条件：\n    a. 计算当前索引的项 $\\text{term} = \\frac{1}{n}$。此计算必须在目标精度内执行，以准确模拟舍入。\n    b. 计算下一个可能的和 $S_{next} = S + \\text{term}$。此加法受目标精度的舍入规则影响。\n    c. 检查 $S_{next}$ 在数值上是否等于 $S$。如果 $S_{next} = S$，则意味着项 $\\frac{1}{n}$ 小于 $S$ 的最后一位单位 (ulp) 的一半，并被舍去。当前索引 $n$ 就是我们寻找的阈值。循环终止，并报告 $n$。\n    d. 如果和发生变化，则更新 $S \\leftarrow S_{next}$ 并递增索引 $n \\leftarrow n + 1$。\n\n这个迭代过程直接模拟了浮点累加器的行为，并精确地确定了前向求和的停滞点。\n\n**第 2 部分：停滞阈值的理论估计**\n\n对于情况 C 和 D，我们采用理论模型来估计阈值索引 $n$。其基本原理是，在向最近舍入的浮点系统中，如果 $|\\delta|$ 小于 $S$ 的 ulp 的一半，则加法 $S + \\delta$ 不会改变 $S$ 的值。正浮点数 $S$ 的半 ulp 约等于 $u \\cdot S$，其中 $u$ 是单位舍入误差，定义为 $u = \\varepsilon/2$，而 $\\varepsilon$ 是机器 epsilon。\n\n在我们的问题中，和为 $S = H_{n-1}$，增量为 $\\delta = \\frac{1}{n}$。当 $\\frac{1}{n} \\le u \\cdot H_{n-1}$ 时，求和停滞。对于大的 $n$，$H_{n-1}$ 约等于 $H_n$，因此条件简化为：\n$$ \\frac{1}{n} \\le u \\cdot H_n $$\n\n为了求解 $n$，我们使用所提供的调和数渐近展开式：\n$$ H_n \\approx \\ln(n) + \\gamma + \\frac{1}{2n} - \\frac{1}{12 n^2} $$\n其中 $\\gamma$ 是欧拉-马歇罗尼常数。\n\n将此展开式代入我们的不等式中，得到：\n$$ \\frac{1}{n} \\le u \\cdot \\left( \\ln(n) + \\gamma + \\frac{1}{2n} - \\frac{1}{12 n^2} \\right) $$\n\n为了找到满足此条件的最小整数 $n$，我们定义一个函数并求其根。在数值上，重新整理不等式以避免在 $n$ 很大时除以 $n$ 会更稳定。将不等式两边乘以 $n$（对于 $n>0$）得到：\n$$ 1 \\le u \\cdot n \\cdot \\left( \\ln(n) + \\gamma + \\frac{1}{2n} - \\frac{1}{12 n^2} \\right) $$\n我们定义函数 $g(n) = u \\cdot n \\cdot H_n^{\\text{approx}} - 1$，其中 $H_n^{\\text{approx}}$ 是渐近近似。我们正在寻找使 $g(n) \\ge 0$ 的最小整数 $n$。由于 $g(n)$ 对于 $n \\ge 1$ 是一个单调递增函数，我们可以通过在合适的整数范围内使用二分搜索来高效地找到这个最小整数。\n\n单位舍入误差 $u$ 的值由问题给出：\n-   对于情况 C (IEEE $754$ 单精度): $u = 2^{-24}$。\n-   对于情况 D (IEEE $754$ 双精度): $u = 2^{-53}$。\n\n该程序实现了这种整数二分搜索来寻找理论阈值。搜索算法内部的计算本身是使用标准的双精度（$64$位）浮点数进行的，以确保有足够的精度来找到可能非常大的整数根 $n$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the four parts of the problem concerning the stagnation of the\n    harmonic series sum in finite-precision arithmetic.\n    \"\"\"\n\n    # --- Part 1: Empirical Detection ---\n\n    def find_empirical_threshold(dtype):\n        \"\"\"\n        Performs a forward summation of the harmonic series in the specified\n        numpy data type (dtype) and finds the minimal index n where the\n        sum no longer changes.\n        \"\"\"\n        s = dtype(0.0)\n        n = 1\n        while True:\n            # All calculations are performed in the specified precision.\n            term = dtype(1.0) / dtype(n)\n            s_next = s + term\n            if s_next == s:\n                return n\n            s = s_next\n            n += 1\n\n    # Case A: Empirical threshold for np.float16\n    resultA = find_empirical_threshold(np.float16)\n\n    # Case B: Empirical threshold for np.float32\n    resultB = find_empirical_threshold(np.float32)\n\n    # --- Part 2: Theory-based Threshold Estimation ---\n\n    def h_n_asymptotic(n):\n        \"\"\"\n        Calculates the value of the n-th harmonic number using the provided\n        asymptotic expansion. The calculation is done in high precision (float64)\n        as n can be very large.\n        \"\"\"\n        n_f = float(n)\n        return (np.log(n_f) + np.euler_gamma + 1.0 / (2.0 * n_f) - 1.0 / (12.0 * n_f**2))\n\n    def find_minimal_integer_root(predicate_fn, low, high):\n        \"\"\"\n        Finds the smallest integer 'n' in the range [low, high] for which\n        predicate_fn(n) is True, using a bisection search.\n        It assumes predicate_fn is monotonically increasing (False to True).\n        \"\"\"\n        ans = high + 1\n        while low = high:\n            # Use standard integer division to avoid potential Python 2 float division.\n            # Safely calculate mid to prevent overflow for very large low/high.\n            mid = low + (high - low) // 2\n            if mid == 0:  # The problem domain starts at n=1\n                low = 1\n                continue\n\n            if predicate_fn(mid):\n                ans = mid\n                high = mid - 1\n            else:\n                low = mid + 1\n        return ans\n\n    def find_theoretical_threshold(u, search_range):\n        \"\"\"\n        Finds the theoretical threshold n by solving the inequality\n        1/n = u * H_n, rearranged as u * n * H_n_approx >= 1.\n        \"\"\"\n        # The predicate is True when the stagnation condition is met.\n        predicate = lambda n: u * n * h_n_asymptotic(n) >= 1.0\n        low, high = search_range\n        return find_minimal_integer_root(predicate, low, high)\n    \n    # Case C: Theory-based threshold for np.float32 (single precision)\n    u_single = 2**-24\n    # The search range is chosen based on an analytical estimate.\n    # n * ln(n) >= 1/u_single = 2^24 approx 1.67e7, so n is around 1.2e6.\n    search_range_c = (1, 2 * 10**7)\n    resultC = find_theoretical_threshold(u_single, search_range_c)\n\n    # Case D: Theory-based threshold for np.float64 (double precision)\n    u_double = 2**-53\n    # n * ln(n) >= 1/u_double = 2^53 approx 9e15, so n is around 2.7e14.\n    search_range_d = (1, 10**16)\n    resultD = find_theoretical_threshold(u_double, search_range_d)\n\n    # Compile the results into the required output format.\n    results = [resultA, resultB, resultC, resultD]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "即使是像一元二次方程求根公式这样基本且广为人知的数学公式，在有限精度计算中也可能出现严重的数值问题。这个练习将引导您探索一种被称为“灾难性相消”的数值误差，当两个几乎相等的数相减时，这种误差会急剧放大。通过实施和比较标准求根公式与基于韦达定理的稳定替代算法，您将掌握识别和纠正数值不稳定性的关键技能 。",
            "id": "3258060",
            "problem": "请考虑二次方程 $a x^2 + b x + c = 0$，并分析在有限精度算术中计算其实根时产生的数值误差。此分析的基础必须从两个事实出发：(i) 二次方程的两个根 $r_1$ 和 $r_2$ 的韦达定理，即 $r_1 + r_2 = -\\frac{b}{a}$ 和 $r_1 r_2 = \\frac{c}{a}$；(ii) 电气与电子工程师协会 (IEEE) 754 二进制浮点算术中的标准浮点舍入模型，其中基本运算（加、减、乘、除）的舍入相对误差的绝对值以单位舍入误差 $u$ 为界，而 $u$ 取决于格式的二进制精度。您的任务是基于这些基础进行推理，研究当 $b^2 \\approx 4 a c$ (根几乎相等) 时的有效位损失，并设计和实现一个数值稳定的算法来计算根，该算法在适当时能避免分子中的减法相消。\n\n具体而言，请执行以下操作：\n\n1. 分析在有限精度下计算判别式 $\\Delta = b^2 - 4 a c$ 时，当 $b^2$ 和 $4 a c$ 非常接近时，为何会产生巨大的相对误差，并解释为什么减去几乎相等的量会放大 $\\Delta$ 的相对误差。\n\n2. 仅使用上述基本事实（韦达定理和浮点舍入模型），推导出一个能避免分子中减法相消的求根策略。您的推导必须从恒等式 $r_1 + r_2 = -\\frac{b}{a}$ 和 $r_1 r_2 = \\frac{c}{a}$ 出发，不得在问题陈述中引入任何快捷公式。该策略应以一种避免相消的方式计算一个根，然后利用根之积恒等式求得第二个根。\n\n3. 在一个程序中实现两种方法：\n   - 直接法：使用双精度算术和教科书中的二次求根公式计算两个根，即计算 $\\Delta$，然后由 $-\\frac{b \\pm \\sqrt{\\Delta}}{2 a}$ 计算 $r_1$ 和 $r_2$。\n   - 替代法：在步骤 $2$ 中推导出的方法，用双精度算术实现，该方法避免了一个根的减法相消，并利用根之积恒等式恢复第二个根。\n\n4. 为进行验证，使用在基数为 $10$ 的任意精度算术中计算的高精度参考值来近似真实实根。为此，请使用 Python 标准库的 decimal 算术，精度至少为 $80$ 位。使用高精度参考值来量化每种双精度方法在两个根上的最大相对误差。对于一对计算出的根 $(\\tilde{r}_1, \\tilde{r}_2)$ 和参考根 $(r_1, r_2)$，将每个根的相对误差定义为 $\\frac{|\\tilde{r}-r|}{\\max(1, |r|)}$，并将该方法的分数定义为两个根误差中的最大值。因为不同方法之间的根的顺序可能不同，请以最小化最大相对误差的方式将计算出的根与参考根进行匹配。\n\n5. 使用以下参数值测试套件，其中涵盖了几乎相等的根、边界条件、大尺度系数以及一个经典的相消场景。每个三元组为 $(a,b,c)$，所有量均为无量纲：\n   - 测试 $1$：$a = 1$，$b = 2$，$c = 1 - 10^{-15}$。\n   - 测试 $2$：$a = 1$，$b = 2$，$c = 1 - 10^{-30}$。\n   - 测试 $3$：$a = 1$，$b = 10^8$，$c = \\frac{b^2}{4}\\left(1 - 10^{-16}\\right)$。\n   - 测试 $4$：$a = 1$，$b = 10^8$，$c = 1$。\n   - 测试 $5$：$a = -1$，$b = 2$，$c = -1 + 10^{-15}$。\n\n6. 您的程序应为每个测试用例，并按相同顺序，输出一行内容，该内容包含一个布尔值，指示替代方法是否比直接法获得了严格更小的最大相对误差。要求的最终输出格式是一行 Python 风格的布尔值列表，例如，`[True,False,...]`。不得打印任何其他文本。\n\n不涉及物理单位或角度单位。所有误差量均为纯数字，必须以小数形式计算和报告（无百分号）。实现必须是自包含的，不得读取输入或访问任何外部资源。",
            "solution": "该问题被评估为有效。其科学基础扎根于数值分析这一成熟领域，特别是关于浮点算术和算法稳定性。问题陈述清晰，为得到唯一且可验证的解提供了所有必要的数据、定义和约束。语言客观、正式。\n\n任务是分析求解二次方程 $a x^2 + b x + c = 0$ 时的数值误差，并实现和比较两种求解实根的方法：标准的直接公式和一种由韦达定理推导出的数值稳定替代方法。\n\n### 第 1 部分：判别式中数值误差的分析\n\nIEEE 754 浮点算术的标准模型指出，对于任何基本算术运算 $\\circ \\in \\{+, -, \\times, \\div\\}$，对两个实数 $x$ 和 $y$ 进行运算的浮点结果由 $fl(x \\circ y) = (x \\circ y)(1 + \\delta)$ 给出，其中相对误差 $\\delta$ 的绝对值以单位舍入误差 $u$ 为界（对于双精度，约等于 $1.11 \\times 10^{-16}$）。\n\n我们需要分析当 $b^2 \\approx 4ac$ 时判别式 $\\Delta = b^2 - 4ac$ 的计算。设 $X = b^2$ 和 $Y = 4ac$。在有限精度下，这些量的计算会带有一定误差。设 $\\tilde{X}$ 和 $\\tilde{Y}$ 为它们的浮点表示。我们可以将其建模为：\n$$ \\tilde{X} = fl(b^2) = b^2(1 + \\delta_1) $$\n$$ \\tilde{Y} = fl(4ac) = 4ac(1 + \\delta_2) $$\n其中 $|\\delta_1|$ 和 $|\\delta_2|$ 的量级与 $u$ 相当。然后，减法计算如下：\n$$ \\tilde{\\Delta} = fl(\\tilde{X} - \\tilde{Y}) = (\\tilde{X} - \\tilde{Y})(1 + \\delta_3) \\quad \\text{其中 } |\\delta_3| \\le u $$\n代入 $\\tilde{X}$ 和 $\\tilde{Y}$ 的表达式：\n$$ \\tilde{\\Delta} = (b^2(1 + \\delta_1) - 4ac(1 + \\delta_2))(1 + \\delta_3) $$\n$$ \\tilde{\\Delta} = (b^2 - 4ac + b^2\\delta_1 - 4ac\\delta_2)(1 + \\delta_3) $$\n忽略高阶误差项，$\\Delta$ 的绝对误差为：\n$$ E_{abs} = \\tilde{\\Delta} - \\Delta \\approx b^2\\delta_1 - 4ac\\delta_2 $$\n相对误差为 $E_{rel} = \\frac{E_{abs}}{\\Delta}$：\n$$ E_{rel} \\approx \\frac{b^2\\delta_1 - 4ac\\delta_2}{b^2 - 4ac} $$\n当 $b^2 \\approx 4ac$ 时，分母 $b^2 - 4ac$ 变得非常小。然而，分子约为 $b^2(\\delta_1 - \\delta_2)$。由于 $\\delta_1$ 和 $\\delta_2$ 是独立的舍入误差，它们的差通常不为零。因此，我们是用一个非常小的量去除一个常规大小的误差，这可能导致相对误差 $E_{rel}$ 变得任意大。这种现象被称为减法相消或有效位损失。如果 $b^2$ 和 $4ac$ 非常接近，以至于它们的差小于浮点格式的精度，计算出的判别式 $\\tilde{\\Delta}$ 甚至可能变为零，从而丢失所有关于真实、微小但非零的差值的信息。\n\n### 第 2 部分：稳定求根算法的推导\n\n标准的二次求根公式给出的根 $r_{1}, r_{2}$ 为：\n$$ r = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{-b \\pm \\sqrt{\\Delta}}{2a} $$\n当 $\\sqrt{\\Delta}$ 接近 $|b|$ 时，分子 $-b \\pm \\sqrt{\\Delta}$ 中可能出现另一种数值不稳定性。这种情况发生在 $\\Delta = b^2 - 4ac$ 接近 $b^2$ 时，这意味着 $|4ac| \\ll b^2$。\n\n让我们假设 $b>0$。项 $\\sqrt{\\Delta} = \\sqrt{b^2 - 4ac} = b\\sqrt{1-4ac/b^2} \\approx b(1 - 2ac/b^2) = b - 2ac/b$。在这种情况下，$\\sqrt{\\Delta} \\approx b$。\n- 计算 $-b - \\sqrt{\\Delta}$ 涉及两个负数相加，这在数值上是稳定的。\n- 计算 $-b + \\sqrt{\\Delta}$ 涉及两个几乎相等的数相减，导致灾难性的减法相消。\n\n如果 $b0$，那么 $-b>0$，情况则相反：$-b + \\sqrt{\\Delta}$ 是稳定的（正数之和），而 $-b - \\sqrt{\\Delta}$ 会遭受相消影响。\n\n为了构建一个稳定的算法，我们必须始终选择分子中构成有效加法的运算（即，避免减去符号相同且量级相似的数）。这可以通过选择根号的符号与 $-b$ 的符号相匹配来实现。一种紧凑的写法是使用符号函数 $\\text{sign}(b)$：\n$$ r_1 = \\frac{-b - \\text{sign}(b)\\sqrt{\\Delta}}{2a} $$\n这个公式可以高精度地计算一个根 $r_1$，无论 $a$、$b$ 和 $c$ 的值如何（假设 $\\Delta \\ge 0$）。\n\n现在，我们使用韦达定理来找到第二个根 $r_2$。问题强制要求使用这种基础方法。韦达定理为：\n1. $r_1 + r_2 = -b/a$\n2. $r_1 r_2 = c/a$\n\n如果我们使用和的关系，我们会得到 $r_2 = -b/a - r_1$。代入我们为 $r_1$ 找到的稳定表达式：\n$$ r_2 = -\\frac{b}{a} - \\frac{-b - \\text{sign}(b)\\sqrt{\\Delta}}{2a} = \\frac{-2b - (-b - \\text{sign}(b)\\sqrt{\\Delta})}{2a} = \\frac{-b + \\text{sign}(b)\\sqrt{\\Delta}}{2a} $$\n这个推导直接回到了我们试图避免的不稳定公式。\n\n因此，我们必须使用积的关系，$r_1 r_2 = c/a$。这得出：\n$$ r_2 = \\frac{c/a}{r_1} = \\frac{c}{a r_1} $$\n这个计算涉及除以精确计算出的根 $r_1$。由于除法在浮点算术中是数值稳定的运算，这种方法将为 $r_2$ 产生一个精确的值。\n\n因此，稳定化的算法是：\n1. 计算 $\\Delta = b^2 - 4ac$。\n2. 计算稳定根 $r_1 = \\frac{-b - \\text{sign}(b)\\sqrt{\\Delta}}{2a}$。\n3. 使用韦达乘积法则计算第二个根：$r_2 = \\frac{c}{ar_1}$。\n\n### 第 3 和 4 部分：实现与验证\n\n对于每个测试用例 $(a,b,c)$，实现将包括三个部分：\n1.  **高精度参考：** 使用 Python 的 `decimal` 库以 $80$ 位精度近似计算真实根，为误差测量提供基准。\n2.  **直接法：** 使用标准的双精度浮点算术和教科书公式 $r = \\frac{-b \\pm \\sqrt{\\Delta}}{2a}$ 计算两个根。\n3.  **替代法：** 在双精度算术中实现上述推导的稳定算法。\n\n每种方法的性能由其最大相对误差来评分。对于一个计算出的根 $\\tilde{r}$ 和参考根 $r$，相对误差为 $\\frac{|\\tilde{r}-r|}{\\max(1, |r|)}$。该度量能稳健地处理接近零的根。由于根的顺序 $(\\tilde{r}_1, \\tilde{r}_2)$ 可能与参考顺序 $(r_1, r_2)$ 不匹配，我们测试两种可能的配对，并选择使该对的最大误差最小化的配对。最后，一个布尔值指示替代方法的分数（最大相对误差）是否严格小于直接方法的分数。程序将为给定的测试套件输出一个包含这些布尔值的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Computes and compares the numerical accuracy of two methods for solving\n    quadratic equations, producing a boolean list indicating if the alternative\n    method is more accurate than the direct method for a given test suite.\n    \"\"\"\n    # 1. Set up high precision context and test cases\n    getcontext().prec = 80\n\n    # Define test cases for double-precision calculations\n    b3_float = 1e8\n    c3_float = (b3_float**2 / 4.0) * (1.0 - 1e-16)\n    test_cases_float = [\n        (1.0, 2.0, 1.0 - 1e-15),\n        (1.0, 2.0, 1.0 - 1e-30),\n        (1.0, b3_float, c3_float),\n        (1.0, 1e8, 1.0),\n        (-1.0, 2.0, -1.0 + 1e-15),\n    ]\n\n    # Define corresponding test cases for high-precision reference calculations\n    b3_dec = Decimal('1e8')\n    c3_dec = (b3_dec**2 / Decimal(4)) * (Decimal(1) - Decimal('1e-16'))\n    test_cases_dec = [\n        (Decimal('1'), Decimal('2'), Decimal('1') - Decimal('1e-15')),\n        (Decimal('1'), Decimal('2'), Decimal('1') - Decimal('1e-30')),\n        (Decimal('1'), b3_dec, c3_dec),\n        (Decimal('1'), Decimal('1e8'), Decimal('1')),\n        (Decimal('-1'), Decimal('2'), Decimal('-1') + Decimal('1e-15')),\n    ]\n\n    results = []\n\n    for i in range(len(test_cases_float)):\n        a_f, b_f, c_f = test_cases_float[i]\n        a_d, b_d, c_d = test_cases_dec[i]\n\n        # 2. High-precision reference calculation\n        delta_d = b_d**2 - 4 * a_d * c_d\n        if delta_d  0:\n            # This should not occur for the given test cases, as they are\n            # designed to have real roots. If it did happen due to some\n            # unforeseen issue, we treat the roots as coalescing at -b/(2a).\n            sqrt_delta_d = Decimal(0)\n        else:\n            sqrt_delta_d = delta_d.sqrt()\n        \n        ref_r1 = (-b_d + sqrt_delta_d) / (2 * a_d)\n        ref_r2 = (-b_d - sqrt_delta_d) / (2 * a_d)\n        ref_roots = [ref_r1, ref_r2]\n\n        # 3. Direct method (double-precision)\n        delta_f = b_f**2 - 4 * a_f * c_f\n        # Prevent math domain error for sqrt from small negative delta due to rounding\n        if delta_f  0:\n            delta_f = 0.0\n        sqrt_delta_f = np.sqrt(delta_f)\n        \n        direct_r1 = (-b_f + sqrt_delta_f) / (2 * a_f)\n        direct_r2 = (-b_f - sqrt_delta_f) / (2 * a_f)\n        direct_roots = [direct_r1, direct_r2]\n\n        # 4. Alternative stabilized method (double-precision)\n        # The numerator term avoids cancellation by matching the sign of the radical\n        # to the sign of -b. np.copysign(1.0, b_f) gives a 1.0 with the sign of b_f.\n        q = -b_f - np.copysign(1.0, b_f) * sqrt_delta_f\n        \n        # Handle the case where q can be zero (e.g., if b=0 and c=0)\n        if q == 0.0:\n            # Roots are both 0.\n            alt_r1 = 0.0\n            alt_r2 = 0.0\n        else:\n            # First root is calculated from the stable numerator q\n            alt_r1 = q / (2 * a_f)\n            # Second root is from Vieta's product relation: r1*r2 = c/a\n            alt_r2 = c_f / (a_f * alt_r1)\n        alt_roots = [alt_r1, alt_r2]\n\n        # 5. Error calculation and comparison\n        def calculate_max_rel_error(computed_roots, reference_roots):\n            # Using str() when converting float to Decimal is crucial to avoid\n            # representing the float's binary approximation error in the Decimal.\n            r1_comp_d = Decimal(str(computed_roots[0]))\n            r2_comp_d = Decimal(str(computed_roots[1]))\n            r1_ref, r2_ref = reference_roots\n\n            def rel_err(comp, ref):\n                # Use max(1, |ref|) as the denominator to handle roots near zero gracefully\n                denominator = max(Decimal(1), ref.copy_abs())\n                if denominator == 0:\n                    return Decimal(0) if comp == ref else Decimal('inf')\n                return (comp - ref).copy_abs() / denominator\n            \n            # Since root order is arbitrary, check both pairings and take the minimum max error.\n            # Pairing 1: (r1_comp, r1_ref), (r2_comp, r2_ref)\n            err11 = rel_err(r1_comp_d, r1_ref)\n            err22 = rel_err(r2_comp_d, r2_ref)\n            match1_max_err = max(err11, err22)\n            \n            # Pairing 2: (r1_comp, r2_ref), (r2_comp, r1_ref)\n            err12 = rel_err(r1_comp_d, r2_ref)\n            err21 = rel_err(r2_comp_d, r1_ref)\n            match2_max_err = max(err12, err21)\n            \n            return min(match1_max_err, match2_max_err)\n\n        direct_error = calculate_max_rel_error(direct_roots, ref_roots)\n        alt_error = calculate_max_rel_error(alt_roots, ref_roots)\n        \n        results.append(alt_error  direct_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "对于许多科学计算中出现的递归关系，计算顺序的选择至关重要，它可能决定了结果的正确性与完全失效。本练习以球贝塞尔函数为例，展示了一个数学上完全正确的递推公式在“前向”计算时如何迅速放大微小的舍入误差，导致结果发散。与之形成鲜明对比的是，“后向”递推（米勒算法）能够抑制误差并产生稳定、准确的结果，这有力地证明了算法稳定性在数值计算中的核心地位 。",
            "id": "3258009",
            "problem": "考虑第一类球贝塞尔函数，记为 $j_n(x)$，它是球贝塞尔微分方程 $x^2 y'' + 2 x y' + \\left(x^2 - n(n+1)\\right) y = 0$ 的解。相关的三项递推关系的两个线性无关解构成一个数值上敏感的对：在某个递推方向下，任何舍入误差都可能激发增长解（对于 $j_n$ 是非物理的）。根据基本性质，球贝塞尔函数满足三项递推关系 $j_{n+1}(x) = \\frac{2n+1}{x} j_n(x) - j_{n-1}(x)$（对 $n \\ge 1$ 成立），以及闭式表达式 $j_0(x) = \\frac{\\sin(x)}{x}$ 和 $j_1(x) = \\frac{\\sin(x)}{x^2} - \\frac{\\cos(x)}{x}$。角度应以弧度为单位进行解释。所有计算必须使用双精度浮点运算。\n\n你的任务是实现两种算法来计算序列 $\\{j_n(x)\\}_{n=0}^N$：\n- 一种数学上正确但数值不稳定的前向递推算法，从 $j_0(x)$ 和 $j_1(x)$ 开始，对 $n = 1, 2, \\ldots, N-1$ 使用 $j_{n+1}(x) = \\frac{2n+1}{x} j_n(x) - j_{n-1}(x)$ 来计算 $j_{n+1}(x)$。\n- 一种数值稳定的逆序计算（Miller算法），它从一个大的索引 $L \\gg N$ 开始，使用反向递推 $j_{n-1}(x) = \\frac{2n+1}{x} j_n(x) - j_{n+1}(x)$ 向下进行，起始于任意种子值 $j_{L+1}(x) = 0$ 和 $j_L(x) = 1$（注意整体尺度是任意的），一直计算到 $n = 0$，然后用一个因子重新缩放整个序列，使得计算出的 $j_0(x)$ 与已知的闭式表达式 $j_0(x) = \\frac{\\sin(x)}{x}$ 匹配。重新缩放后的值 $j_n(x)$（对于 $n \\le N$）构成了稳定序列。\n\n你的推理和实现应基于以下核心定义：\n- 球贝塞尔微分方程 $x^2 y'' + 2 x y' + \\left(x^2 - n(n+1)\\right) y = 0$ 将 $j_n(x)$ 定义为一个保持有界的物理​​解。\n- 三项递推关系 $j_{n+1}(x) = \\frac{2n+1}{x} j_n(x) - j_{n-1}(x)$ 是一个从微分方程及其解结构导出的、经过充分检验的恒等式。\n\n除这些定义外，不允许使用任何捷径公式。分析递推关系在前向和后向方向上固有的数值误差传播，并利用这一点来设计你的稳定算法。通过使用合理的参数大小和明确处理弧度单位来确保科学真实性。\n\n实现一个程序，针对以下测试套件，计算不稳定前向递推和稳定后向（Miller）序列在所有阶数 $n \\in \\{0, 1, \\ldots, N\\}$ 上的最大绝对偏差：\n- 测试用例 1：$x = 1.0$ (弧度)，$N = 50$。\n- 测试用例 2：$x = 10.0$ (弧度)，$N = 30$。\n- 测试用例 3：$x = 0.1$ (弧度)，$N = 20$。\n- 测试用例 4：$x = 50.0$ (弧度)，$N = 40$。\n\n对于后向（Miller）计算，在所有测试用例中均使用 $L = N + 60$。每个测试用例的结果必须是单个浮点数，等于 $\\max_{0 \\le n \\le N} \\left| j_n^{\\text{forward}}(x) - j_n^{\\text{backward}}(x) \\right|$，其中 $j_n^{\\text{forward}}(x)$ 是通过从 $j_0(x)$ 和 $j_1(x)$ 进行前向递推计算的，而 $j_n^{\\text{backward}}(x)$ 是通过Miller算法计算并重新缩放以匹配 $j_0(x)$ 的。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，并按上述测试用例的顺序列出（例如，$[r_1,r_2,r_3,r_4]$）。角度必须以弧度处理，除此角度单位外不涉及其他物理单位。输出为浮点数。",
            "solution": "该问题陈述已被验证且被认为是合理的。其科学基础是关于特殊函数及其数值计算的成熟理论，特别是关于球贝塞尔函数。该问题是适定的，为两种指定算法提供了所有必要的定义、递推关系、初始条件和参数。目标明确，语言精确。它代表了数值分析中一个关于递推关系稳定性的经典的、非平凡的问题。\n\n问题的核心在于三项递推关系的数值性质：\n$$\nj_{n+1}(x) = \\frac{2n+1}{x} j_n(x) - j_{n-1}(x)\n$$\n这是一个线性二阶齐次差分方程。因此，其通解 $y_n(x)$ 是两个线性无关解的线性组合：$y_n(x) = A f_n(x) + B g_n(x)$。对于球贝塞尔方程，这两个解是第一类球贝塞尔函数 $j_n(x)$ 和第二类球贝塞尔函数 $y_n(x)$。\n\n理解数值稳定性的关键在于它们在固定参数 $x$ 下，当阶数 $n$ 变大时的渐进行为。\n- 所需的解 $j_n(x)$ 是“最小”解或“隐性”解。对于任何固定的 $x$，当 $n \\to \\infty$ 时，它会快速衰减至零。\n- 另一个解 $y_n(x)$ 是“主导”解。当 $n \\to \\infty$ 时，它会无界增长。\n\n任何数值计算都会引入小的浮点舍入误差。一个计算出的序列，记为 $\\tilde{j}_n(x)$，将不可避免地成为两种解的组合：\n$$\n\\tilde{j}_n(x) \\approx j_n(x) + \\epsilon y_n(x)\n$$\n其中 $\\epsilon$ 是一个表示初始累积误差的小系数。\n\n**前向递推（不稳定方法）**\n前向递推算法根据前两项 $j_n(x)$ 和 $j_{n-1}(x)$ 来计算 $j_{n+1}(x)$。我们从已知的 $j_0(x)$ 和 $j_1(x)$ 的值开始。\n1.  初始化一个数组来存储序列 $\\{j_n(x)\\}_{n=0}^N$。\n2.  使用提供的闭式表达式计算初始值：\n    $$\n    j_0(x) = \\frac{\\sin(x)}{x}\n    $$\n    $$\n    j_1(x) = \\frac{\\sin(x)}{x^2} - \\frac{\\cos(x)}{x}\n    $$\n    即使是这些初始值也会有微小的舍入误差，这实际上引入了主导解 $y_n(x)$ 的一个微小分量。\n3.  对 $k = 1, 2, \\ldots, N-1$ 迭代应用递推关系 $j_{k+1}(x) = \\frac{2k+1}{x} j_k(x) - j_{k-1}(x)$。\n随着 $n$ 的增加，特别是当 $2n+1 > x$ 时，因子 $\\frac{2n+1}{x}$ 会变大，从而放大任何已存在的误差。最初微小的 $\\epsilon y_n(x)$ 分量（它也满足该递推关系）由于 $y_n(x)$ 的主导性质而迅速增长。最终，这个误差项会压倒真实的、衰减的 $j_n(x)$ 解，导致完全错误且常常是发散的结果。因此，对于递增的 $n$，该方法是数值不稳定的。\n\n**后向递推（Miller算法 - 稳定方法）**\n前向递推的不稳定性可以通过反向应用递推关系来克服。这是Miller算法的基础。当按 $n$ 递减迭代时，递推关系会自然地抑制主导解 $y_n(x)$ 并增强所需的最小解 $j_n(x)$。\n1.  重写递推关系以求解索引最小的项：\n    $$\n    j_{n-1}(x) = \\frac{2n+1}{x} j_n(x) - j_{n+1}(x)\n    $$\n2.  选择一个远大于所需最大阶数 $N$ 的起始索引 $L$（这里，$L=N+60$）。在如此大的索引下，$j_L(x)$ 的真实值极度接近于零。\n3.  我们通过设置 $f_{L+1}(x) = 0$ 和 $f_L(x) = 1$（或任何小的、任意的非零常数）来初始化一个未缩放的序列，我们称之为 $f_n$。这些初始条件与真实值不符，但这是该算法的关键所在。\n4.  从 $n = L, L-1, \\ldots, 1$ 向下迭代递推，以计算序列 $\\{f_k(x)\\}_{k=0}^L$。因为我们是在稳定方向上进行递推，所以对于所有 $n \\ll L$，得到的序列 $f_n(x)$ 将与真实的最小解 $j_n(x)$ 成比例。即，$f_n(x) \\approx C \\cdot j_n(x)$，其中 $C$ 是某个未知的比例常数。\n5.  为了找到 $C$，我们使用真实序列的一个已知值。最方便的是 $j_0(x)$。我们有计算出的 $f_0(x)$ 和已知的解析值 $j_0^{\\text{true}}(x) = \\frac{\\sin(x)}{x}$。因此，缩放因子为 $S = \\frac{j_0^{\\text{true}}(x)}{f_0(x)}$。\n6.  稳定序列通过重新缩放所有计算值得到：$j_n^{\\text{backward}}(x) = S \\cdot f_n(x)$，其中 $n=0, 1, \\ldots, N$。由于 $j_0^{\\text{backward}}(x)$ 被重新缩放以匹配真实值，因此在 $n=0$ 处的绝对误差将为零（在机器精度范围内）。\n\n**最终计算**\n目标是通过与稳定的后向方法进行比较来量化前向方法的失败程度。对于每个测试用例，我们计算两个序列 $\\{j_n^{\\text{forward}}(x)\\}_{n=0}^N$ 和 $\\{j_n^{\\text{backward}}(x)\\}_{n=0}^N$，然后找出它们在所有计算阶数上的最大绝对偏差：\n$$\n\\text{偏差} = \\max_{0 \\le n \\le N} \\left| j_n^{\\text{forward}}(x) - j_n^{\\text{backward}}(x) \\right|\n$$\n这个值可作为不稳定前向递推所累积误差的度量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the maximum absolute deviation between unstable forward recurrence\n    and stable backward recurrence (Miller's algorithm) for spherical Bessel\n    functions j_n(x).\n    \"\"\"\n\n    def compute_forward(x, N):\n        \"\"\"\n        Computes the sequence {j_n(x)} for n=0 to N using forward recurrence.\n        This method is numerically unstable for n > x.\n        \"\"\"\n        # All computations use double precision (np.float64) by default.\n        j_fwd = np.zeros(N + 1, dtype=np.float64)\n\n        if x == 0.0:\n            j_fwd[0] = 1.0\n            return j_fwd\n\n        j_fwd[0] = np.sin(x) / x\n        if N > 0:\n            j_fwd[1] = (np.sin(x) / x**2) - (np.cos(x) / x)\n\n        for n in range(1, N):\n            term1 = ((2.0 * n + 1.0) / x) * j_fwd[n]\n            term2 = j_fwd[n - 1]\n            # Check for potential overflow before assignment\n            if np.isinf(term1):\n                j_fwd[n + 1:] = np.inf\n                break\n            j_fwd[n + 1] = term1 - term2\n\n        return j_fwd\n\n    def compute_backward(x, N):\n        \"\"\"\n        Computes the sequence {j_n(x)} for n=0 to N using backward recurrence\n        (Miller's algorithm). This method is numerically stable.\n        \"\"\"\n        L = N + 60\n        j_bwd_unscaled = np.zeros(L + 2, dtype=np.float64)\n\n        if x == 0.0:\n            j_bwd = np.zeros(N + 1, dtype=np.float64)\n            j_bwd[0] = 1.0\n            return j_bwd\n\n        # Set initial arbitrary values at a large index L\n        j_bwd_unscaled[L + 1] = 0.0\n        j_bwd_unscaled[L] = 1.0  # An arbitrary small number; 1.0 is fine.\n\n        # Recur downwards from n=L to n=1\n        for n in range(L, 0, -1):\n            term1 = ((2.0 * n + 1.0) / x) * j_bwd_unscaled[n]\n            term2 = j_bwd_unscaled[n + 1]\n            j_bwd_unscaled[n - 1] = term1 - term2\n\n        # Calculate the true j_0(x) for normalization\n        j0_true = np.sin(x) / x\n\n        # The computed sequence is proportional to the true sequence.\n        # Find the scaling factor by comparing the computed j_0 with the true j_0.\n        f0_computed = j_bwd_unscaled[0]\n        \n        # This case is highly unlikely for the given x values.\n        if f0_computed == 0.0:\n            scale_factor = 0.0\n        else:\n            scale_factor = j0_true / f0_computed\n\n        # Rescale the sequence to get the final result\n        j_bwd = j_bwd_unscaled[:N + 1] * scale_factor\n        return j_bwd\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 50),\n        (10.0, 30),\n        (0.1, 20),\n        (50.0, 40),\n    ]\n\n    results = []\n    for x_val, N_val in test_cases:\n        j_forward = compute_forward(x_val, N_val)\n        j_backward = compute_backward(x_val, N_val)\n\n        # Compute the maximum absolute deviation between the two sequences\n        deviation = np.max(np.abs(j_forward - j_backward))\n        results.append(deviation)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}