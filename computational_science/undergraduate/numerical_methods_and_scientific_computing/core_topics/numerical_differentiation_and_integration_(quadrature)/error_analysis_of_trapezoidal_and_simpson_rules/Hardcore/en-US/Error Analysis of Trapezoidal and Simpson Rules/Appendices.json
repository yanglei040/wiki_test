{
    "hands_on_practices": [
        {
            "introduction": "The best way to build confidence in a numerical method is to see its theoretical promises in action. This first exercise  asks you to implement the trapezoidal and Simpson's rules and apply them to a well-behaved function, $f(x)=e^x$. By analyzing the error as you refine the integration grid, you will use a log-log plot to empirically measure the order of convergence and confirm that Simpson's rule, with its error proportional to $h^4$, indeed converges much faster than the trapezoidal rule, whose error is proportional to $h^2$, for functions that are sufficiently smooth.",
            "id": "3224834",
            "problem": "Consider the function $f(x)=e^x$ on the interval $[0,1]$. Let $I=\\int_{0}^{1} f(x)\\,dx$ denote the exact integral. For a uniform partition with $n$ subintervals and step size $h=(1-0)/n$, define the composite trapezoidal rule approximation $T_n$ and the composite Simpson's rule approximation $S_n$ by their standard summation definitions over the nodes $x_k=0+kh$ for $k=0,1,\\dots,n$:\n- Composite trapezoidal rule:\n$$\nT_n = h\\left(\\frac{f(0)}{2} + \\sum_{k=1}^{n-1} f(x_k) + \\frac{f(1)}{2}\\right).\n$$\n- Composite Simpson's rule (require $n$ even):\n$$\nS_n = \\frac{h}{3}\\left(f(0) + f(1) + 4\\sum_{k=1,\\,k\\text{ odd}}^{n-1} f(x_k) + 2\\sum_{k=2,\\,k\\text{ even}}^{n-2} f(x_k)\\right).\n$$\n\nStarting from fundamental definitions in numerical quadrature and the smoothness of $f(x)=e^x$, the global error $E(h)$ of each composite rule as a function of $h$ exhibits an asymptotic power-law behavior $E(h)\\approx C\\,h^p$ when $h$ is sufficiently small, where $p$ is the convergence order and $C$ is a nonzero constant depending on $f$ and the rule. Theoretical upper bounds for the global errors can be established using the supremum of appropriate derivatives of $f$ over $[0,1]$, specifically $\\sup_{x\\in[0,1]}|f''(x)|$ for the composite trapezoidal rule and $\\sup_{x\\in[0,1]}|f^{(4)}(x)|$ for the composite Simpson's rule.\n\nYour program must:\n1. Compute $I$ exactly from the definition of the exponential function and the Fundamental Theorem of Calculus.\n2. For each specified list of $n$ values (the test suite below), compute $T_n$ and $S_n$ (with Simpson's rule applied only to even $n$), their absolute global errors $|I-T_n|$ and $|I-S_n|$, and the step sizes $h=1/n$.\n3. For each rule and for each list of $n$ values, perform a linear regression on the pairs $\\left(\\log(h),\\log(|E(h)|)\\right)$ using the natural logarithm to estimate the slope $p$ and the intercept $\\log(C)$ of the best-fit line, thereby obtaining empirical estimates of $p$ and $C=e^{\\text{intercept}}$.\n4. Compute the theoretical derivative suprema $\\sup_{x\\in[0,1]}|f''(x)|$ and $\\sup_{x\\in[0,1]}|f^{(4)}(x)|$, and use the standard global error upper-bound forms involving these suprema to check, for every $n$ in each list, whether the absolute global errors of the corresponding rule are less than or equal to their bound. Report a boolean indicating whether all bounds hold for all $n$ in the list for both rules simultaneously.\n\nTest suite:\n- Case A (happy path): $n\\in\\{4,8,16,32,64\\}$.\n- Case B (moderately coarse): $n\\in\\{2,4,6,8,10,12\\}$.\n- Case C (fine grid): $n\\in\\{128,256,512,1024\\}$.\n\nFinal output specification:\n- For each case, produce a list $[p_T, C_T, p_S, C_S, \\text{bound\\_ok}]$ where $p_T$ and $C_T$ are the empirical slope and constant for the composite trapezoidal rule, $p_S$ and $C_S$ are the empirical slope and constant for the composite Simpson's rule, and $\\text{bound\\_ok}$ is a boolean that is true if and only if, for all $n$ in the case, both $|I-T_n|$ and $|I-S_n|$ are less than or equal to their respective theoretical upper bounds derived from $\\sup_{x\\in[0,1]}|f''(x)|$ and $\\sup_{x\\in[0,1]}|f^{(4)}(x)|$.\n- Your program should produce a single line of output containing the three case results as a comma-separated list enclosed in square brackets, for example:\n$$\n[\\,[p_T^{(A)},C_T^{(A)},p_S^{(A)},C_S^{(A)},\\text{bound\\_ok}^{(A)}],\\,[p_T^{(B)},C_T^{(B)},p_S^{(B)},C_S^{(B)},\\text{bound\\_ok}^{(B)}],\\,[p_T^{(C)},C_T^{(C)},p_S^{(C)},C_S^{(C)},\\text{bound\\_ok}^{(C)}]\\,].\n$$\nAll numerical results must be reported as raw floats and booleans in this aggregated list. No physical units or angle units apply in this problem.",
            "solution": "The problem requires an analysis of the convergence properties of the composite trapezoidal and Simpson's numerical integration rules for the function $f(x) = e^x$ on the interval $[0,1]$. This analysis involves computing the numerical approximations, their errors, comparing them to theoretical bounds, and empirically estimating the order of convergence.\n\nFirst, we establish the ground truth for the integral. The function to be integrated is $f(x) = e^x$ over the interval $[0,1]$. The exact value of the integral, denoted by $I$, is computed using the Fundamental Theorem of Calculus:\n$$\nI = \\int_{0}^{1} e^x \\,dx = \\left[e^x\\right]_{0}^{1} = e^1 - e^0 = e - 1\n$$\nThis value serves as the reference against which the numerical approximations $T_n$ and $S_n$ are compared.\n\nNext, we establish the theoretical error bounds. The standard error bound formulas for the composite trapezoidal and Simpson's rules depend on the supremum of the magnitudes of certain derivatives of the function $f(x)$ over the integration interval. The interval is $[a,b]=[0,1]$ and the step size is $h=(b-a)/n = 1/n$.\n\nFor the composite trapezoidal rule, the error bound involves the second derivative.\nThe derivatives of $f(x)=e^x$ are $f'(x)=e^x$, $f''(x)=e^x$, and so on. All derivatives are $e^x$.\nThe function $e^x$ is positive and monotonically increasing on $[0,1]$. Therefore, the supremum of its derivatives on this interval occurs at $x=1$.\n$$\nM_2 = \\sup_{x\\in[0,1]}|f''(x)| = \\sup_{x\\in[0,1]}|e^x| = e^1 = e\n$$\nThe theoretical error bound for the composite trapezoidal rule is:\n$$\n|I - T_n| \\le \\frac{(b-a)h^2}{12} M_2 = \\frac{1 \\cdot (1/n)^2}{12} e = \\frac{e}{12n^2}\n$$\nFor the composite Simpson's rule, the error bound involves the fourth derivative.\n$$\nM_4 = \\sup_{x\\in[0,1]}|f^{(4)}(x)| = \\sup_{x\\in[0,1]}|e^x| = e^1 = e\n$$\nThe theoretical error bound for the composite Simpson's rule (for even $n$) is:\n$$\n|I - S_n| \\le \\frac{(b-a)h^4}{180} M_4 = \\frac{1 \\cdot (1/n)^4}{180} e = \\frac{e}{180n^4}\n$$\nThe program must verify for each $n$ in each test case whether the computed absolute errors $|I-T_n|$ and $|I-S_n|$ are less than or equal to these respective bounds.\n\nThe problem also requires an empirical estimation of the convergence order $p$ and the error constant $C$ from the asymptotic relationship $|E(h)| \\approx C h^p$, where $E(h)$ is the global error for a given step size $h$. Taking the natural logarithm of both sides yields a linear relationship:\n$$\n\\ln(|E(h)|) \\approx \\ln(C) + p \\ln(h)\n$$\nThis equation is of the form $y = m x + c$, where $y = \\ln(|E(h)|)$, $x = \\ln(h)$, the slope is $m=p$, and the y-intercept is $c=\\ln(C)$. By computing the errors for a sequence of step sizes $h_i=1/n_i$, we can generate a set of data points $(\\ln(h_i), \\ln(|E(h_i)|))$. A simple linear regression on these points provides estimates for the slope $p$ and the intercept $\\ln(C)$, from which we can find $C = e^{\\ln(C)}$. This procedure is performed separately for the trapezoidal and Simpson's rules.\n\nThe computational procedure for each test case is as follows:\n1.  Define the exact integral $I=e-1$ and the derivative suprema $M_2=e$ and $M_4=e$. Initialize a boolean flag `bound_ok` to true.\n2.  For each number of subintervals $n$ in the given list:\n    a. Calculate the step size $h=1/n$.\n    b. Generate the nodes $x_k = kh$ for $k=0, 1, \\dots, n$ and evaluate $y_k = f(x_k)$.\n    c. Compute the trapezoidal approximation $T_n$ using its summation formula.\n    d. Calculate the absolute error $|E_{T_n}| = |I-T_n|$ and the theoretical error bound $B_{T_n} = e h^2 / 12$. If $|E_{T_n}| > B_{T_n}$, set `bound_ok` to false.\n    e. If $n$ is even, compute the Simpson's approximation $S_n$, its error $|E_{S_n}|=|I-S_n|$, and its bound $B_{S_n} = e h^4 / 180$. If $|E_{S_n}| > B_{S_n}$, set `bound_ok` to false.\n    f. Store $h$, $|E_{T_n}|$, and (if applicable) $|E_{S_n}|$ for the regression analysis.\n3.  Perform linear regression on the collected natural log-log data for the trapezoidal rule to find its empirical parameters $p_T$ and $C_T$.\n4.  Perform linear regression on the collected natural log-log data for Simpson's rule to find its empirical parameters $p_S$ and $C_S$.\n5.  Consolidate the results into the list $[p_T, C_T, p_S, C_S, \\text{bound\\_ok}]$.\nThis process is repeated for each of the three specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical integration error analysis problem for three test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        [4, 8, 16, 32, 64],        # Case A\n        [2, 4, 6, 8, 10, 12],      # Case B\n        [128, 256, 512, 1024],      # Case C\n    ]\n\n    # The function to integrate f(x) = e^x\n    f = lambda x: np.exp(x)\n    \n    # Exact value of the integral over [0, 1]\n    I_exact = np.e - 1.0\n\n    # Supremum of derivatives on [0, 1] for error bounds\n    # f''(x) = e^x, sup|f''(x)| = e^1 = e\n    # f^(4)(x) = e^x, sup|f^(4)(x)| = e^1 = e\n    M2 = np.e\n    M4 = np.e\n\n    interval_a = 0.0\n    interval_b = 1.0\n\n    all_results = []\n\n    for n_values in test_cases:\n        h_T_vals, errors_T = [], []\n        h_S_vals, errors_S = [], []\n        bounds_hold = True\n\n        for n in n_values:\n            h = (interval_b - interval_a) / n\n            x_nodes = np.linspace(interval_a, interval_b, n + 1)\n            y_values = f(x_nodes)\n\n            # Composite Trapezoidal Rule\n            T_n = h * (np.sum(y_values[1:-1]) + (y_values[0] + y_values[-1]) / 2.0)\n            error_T = np.abs(I_exact - T_n)\n            \n            # Theoretical bound for Trapezoidal Rule\n            bound_T = M2 * h**2 / 12.0\n            if error_T > bound_T:\n                bounds_hold = False\n            \n            h_T_vals.append(h)\n            errors_T.append(error_T)\n\n            # Composite Simpson's Rule (for even n)\n            if n % 2 == 0:\n                # S_n = h/3 * (f(x_0) + f(x_n) + 4*sum(odd terms) + 2*sum(even terms))\n                # Odd terms indices: 1, 3, ..., n-1\n                # Even terms indices: 2, 4, ..., n-2\n                odd_sum = np.sum(y_values[1:n:2])\n                even_sum = np.sum(y_values[2:n-1:2])\n                S_n = (h / 3.0) * (y_values[0] + y_values[-1] + 4.0 * odd_sum + 2.0 * even_sum)\n                error_S = np.abs(I_exact - S_n)\n                \n                # Theoretical bound for Simpson's Rule\n                bound_S = M4 * h**4 / 180.0\n                if error_S > bound_S:\n                    bounds_hold = False\n                \n                h_S_vals.append(h)\n                errors_S.append(error_S)\n        \n        # Perform linear regression on log-log data\n        # For Trapezoidal Rule\n        log_h_T = np.log(np.array(h_T_vals))\n        log_err_T = np.log(np.array(errors_T))\n        p_T, log_C_T = np.polyfit(log_h_T, log_err_T, 1)\n        C_T = np.exp(log_C_T)\n\n        # For Simpson's Rule\n        log_h_S = np.log(np.array(h_S_vals))\n        log_err_S = np.log(np.array(errors_S))\n        p_S, log_C_S = np.polyfit(log_h_S, log_err_S, 1)\n        C_S = np.exp(log_C_S)\n        \n        case_result = [p_T, C_T, p_S, C_S, bounds_hold]\n        all_results.append(case_result)\n\n\n    # Final print statement in the exact required format.\n    # We convert the list of lists to its string representation and remove spaces for compactness.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "Is a higher-order method always superior? This thought-provoking exercise  challenges that common assumption by asking you to design a specific function where the supposedly less accurate trapezoidal rule outperforms Simpson's rule. Solving this problem requires moving beyond rote formula application and thinking about how these rules actually work: by integrating simple polynomial interpolants. This will reveal the crucial role of the function's behavior relative to the sampling grid and highlight the implicit assumptions we make when choosing a high-order method.",
            "id": "3284359",
            "problem": "Consider numerical integration of a smooth function over the interval $[0,1]$ using a fixed budget of $9$ function evaluations at uniformly spaced nodes $x_j = j/8$ for $j = 0,1,\\dots,8$. For this node set, one may construct composite quadrature rules by interpolating $f(x)$ locally with polynomials and integrating those interpolants to approximate the definite integral $\\int_{0}^{1} f(x)\\,dx$. Two widely used such rules are based on linear interpolation (composite trapezoidal rule) and quadratic interpolation (composite Simpson's rule), both on a uniform grid. \n\nStarting strictly from these core definitions of numerical quadrature (interpolatory formulas constructed on uniform nodes) and without invoking any pre-stated error constants or closed-form error formulas, design a specific, continuously differentiable function $f(x)$ on $[0,1]$ such that, when both rules use the same $9$ function evaluations at the nodes $\\{x_j\\}_{j=0}^{8}$, the composite trapezoidal rule yields an approximation to $\\int_{0}^{1} f(x)\\,dx$ that is more accurate than the composite Simpson's rule. \n\nYour answer must be an explicit analytic expression for $f(x)$, and you must demonstrate in your reasoning why, for this $f(x)$ and the specified nodes, the composite trapezoidal rule is strictly closer to the true integral than the composite Simpson's rule. No rounding is required, and no units are involved; provide exact values in your reasoning.",
            "solution": "The user wants me to act as a meticulous STEM professor to solve a numerical methods problem, strictly adhering to formatting and validation rules.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Task**: Design a continuously differentiable function $f(x)$ on $[0,1]$.\n- **Integral**: $I = \\int_{0}^{1} f(x)\\,dx$.\n- **Nodes**: A set of $9$ uniformly spaced nodes, $x_j = j/8$ for $j = 0, 1, \\dots, 8$.\n- **Method 1**: Composite trapezoidal rule ($T$) using all $9$ nodes.\n- **Method 2**: Composite Simpson's rule ($S$) using all $9$ nodes.\n- **Condition**: The absolute error of the trapezoidal rule must be strictly less than the absolute error of Simpson's rule, i.e., $|I - T| < |I - S|$.\n- **Constraint**: The derivation must be from the fundamental definitions of the quadrature rules as integrals of local polynomial interpolants on uniform nodes, without using standard, pre-stated error formulas (e.g., those involving constants like $\\frac{1}{12}$ or $\\frac{1}{180}$ and high-order derivatives).\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the well-established field of numerical analysis. It is well-posed, asking for the construction of a function that satisfies a specific, verifiable property. The language is objective and the constraints are clear and consistent. The problem is a standard, albeit insightful, exercise to demonstrate that a higher-order numerical method is not universally superior to a lower-order one. The required constraint of avoiding pre-stated error formulas is a pedagogical directive to ensure a first-principles-based demonstration, which does not invalidate the problem. The problem is non-trivial and requires a correct understanding of how quadrature rules behave. It is fully formalizable and verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. Proceeding to the solution.\n\n### Solution\n\nThe objective is to find a continuously differentiable function $f(x)$ on $[0,1]$ such that the composite trapezoidal rule yields a more accurate approximation of $I = \\int_0^1 f(x) dx$ than the composite Simpson's rule, given a uniform grid of $9$ points. The grid spacing is $h = (1-0)/8 = 1/8$, with nodes $x_j = j/8$ for $j \\in \\{0, 1, \\dots, 8\\}$.\n\nWe must show that $|I - T| < |I - S|$. The path to a solution without using pre-stated error formulas is to propose a suitable candidate function and then explicitly compute the true integral $I$ and the two approximations $T$ and $S$ to verify the inequality.\n\nA key insight is that the accuracy of these rules is tied to how well their underlying polynomial interpolants capture the behavior of the function. Simpson's rule uses piecewise quadratic interpolants over panels of width $2h$, while the trapezoidal rule uses piecewise linear interpolants over panels of width $h$. A function whose behavior is poorly captured by quadratic interpolation at the given node spacing, but well-approximated by linear interpolation, is a promising candidate. Highly oscillatory functions can exhibit such properties.\n\nLet us propose the function $f(x) = \\cos(8\\pi x)$. This function is continuously differentiable (in fact, $C^\\infty$) on $[0,1]$.\n\nFirst, we evaluate the function at the specified nodes $x_j = j/8$:\n$$f(x_j) = f\\left(\\frac{j}{8}\\right) = \\cos\\left(8\\pi \\frac{j}{8}\\right) = \\cos(j\\pi) = (-1)^j$$\nThe sequence of function values $\\{f_j\\}_{j=0}^8$ is:\n$$f_0=1, f_1=-1, f_2=1, f_3=-1, f_4=1, f_5=-1, f_6=1, f_7=-1, f_8=1$$\n\nNext, we calculate the exact value of the integral, $I$:\n$$I = \\int_{0}^{1} \\cos(8\\pi x) \\,dx = \\left[ \\frac{\\sin(8\\pi x)}{8\\pi} \\right]_{0}^{1} = \\frac{\\sin(8\\pi) - \\sin(0)}{8\\pi} = \\frac{0-0}{8\\pi} = 0$$\n\nNow, we compute the approximation using the composite trapezoidal rule. The rule is defined as:\n$$T = h \\left( \\frac{1}{2}f_0 + \\sum_{j=1}^{N-1} f_j + \\frac{1}{2}f_N \\right)$$\nWith $N=8$, $h=1/8$, and our nodal values:\n$$T = \\frac{1}{8} \\left( \\frac{1}{2}f_0 + f_1 + f_2 + f_3 + f_4 + f_5 + f_6 + f_7 + \\frac{1}{2}f_8 \\right)$$\n$$T = \\frac{1}{8} \\left( \\frac{1}{2}(1) + (-1) + 1 + (-1) + 1 + (-1) + 1 + (-1) + \\frac{1}{2}(1) \\right)$$\n$$T = \\frac{1}{8} \\left( \\frac{1}{2} - 1 + 1 - 1 + 1 - 1 + 1 - 1 + \\frac{1}{2} \\right) = \\frac{1}{8} \\left( \\left(\\frac{1}{2} + \\frac{1}{2}\\right) + (-1+1-1+1-1+1) \\right)$$\n$$T = \\frac{1}{8} (1 + 0) = \\frac{1}{8}. \\text{ Wait, calculation error.}$$\n$$T = \\frac{1}{8} \\left( \\frac{1}{2} -1 +1 -1+1 -1+1 -1 + \\frac{1}{2} \\right) = \\frac{1}{8} \\left( (\\frac{1}{2} + \\frac{1}{2}) + 4 \\cdot (-1) + 3 \\cdot (1) \\right) = \\frac{1}{8}(1-4+3) = 0$$\nLet's re-sum carefully: $\\frac{1}{2} + (-1+1) + (-1+1) + (-1+1) -1 + \\frac{1}{2} = \\frac{1}{2}+0+0+0-1+\\frac{1}{2}=0$. Correct.\n$$T=0$$\n\nNext, we compute the approximation using the composite Simpson's rule. For $N=8$ subintervals (an even number), the rule is:\n$$S = \\frac{h}{3} \\left( f_0 + 4f_1 + 2f_2 + 4f_3 + 2f_4 + 4f_5 + 2f_6 + 4f_7 + f_8 \\right)$$\nUsing our nodal values:\n$$S = \\frac{1/8}{3} \\left( 1 + 4(-1) + 2(1) + 4(-1) + 2(1) + 4(-1) + 2(1) + 4(-1) + 1 \\right)$$\n$$S = \\frac{1}{24} \\left( 1 - 4 + 2 - 4 + 2 - 4 + 2 - 4 + 1 \\right)$$\n$$S = \\frac{1}{24} \\left( (1+2+2+2+1) + (4 \\times (-4)) \\right) = \\frac{1}{24} (8 - 16) = \\frac{-8}{24} = -\\frac{1}{3}$$\n$$S = -\\frac{1}{3}$$\n\nFinally, we compare the absolute errors.\nThe absolute error for the trapezoidal rule is:\n$$|E_T| = |I - T| = |0 - 0| = 0$$\nThe absolute error for Simpson's rule is:\n$$|E_S| = |I - S| = \\left|0 - \\left(-\\frac{1}{3}\\right)\\right| = \\left|\\frac{1}{3}\\right| = \\frac{1}{3}$$\nComparing the two absolute errors, we find:\n$$0 < \\frac{1}{3}$$\nThus, $|E_T| < |E_S|$.\n\nThe function $f(x)=\\cos(8\\pi x)$ is continuously differentiable and, for the given nodes, the composite trapezoidal rule is perfectly accurate while the composite Simpson's rule yields a substantial error. This demonstrates that the trapezoidal rule is more accurate than Simpson's rule in this specific case, satisfying all conditions of the problem. This occurs because the frequency of the function is precisely the Nyquist frequency of the grid, $1/(2h)$. The trapezoidal rule is exact because the error term on each subinterval, $\\int_{x_j}^{x_{j+1}} (f(x) - L_j(x))dx$, happens to be zero due to the symmetry of the cosine function within each subinterval. Simpson's rule, however, is designed for polynomials and is severely misled by the oscillatory nature of the function relative to its three-point sampling panels, leading to a large error.",
            "answer": "$$\\boxed{\\cos(8\\pi x)}$$"
        },
        {
            "introduction": "Real-world problems often involve functions with mixed behaviorâ€”smooth in some regions but with sharp kinks or rapid oscillations in others. Building on the insights from the previous exercises, this final, advanced practice  guides you in designing a \"smart\" hybrid algorithm. You will create a routine that uses a local \"smoothness detector\" to automatically switch between the fast-converging Simpson's rule in smooth regions and the more robust trapezoidal rule near sharp features, combining the best of both worlds into a single, powerful tool.",
            "id": "3215316",
            "problem": "You are to design and implement a hybrid numerical integration scheme on a closed interval $\\left[a,b\\right]$ that adaptively selects the composite Simpson's rule in locally smooth regions and the composite trapezoidal rule near detected sharp changes. The goal is to reason from first principles: start from the definition of the definite integral as the limit of Riemann sums, interpret Simpson's rule as the exact integral of a quadratic interpolant over local subintervals, interpret the trapezoidal rule as the exact integral of a linear interpolant over a single subinterval, and then combine these elements with a principled smoothness detector based on finite differences.\n\nYour hybrid scheme must satisfy the following design requirements.\n\n- Begin with a uniform partition of $\\left[a,b\\right]$ into $N$ subintervals of width $h = \\dfrac{b-a}{N}$ with nodes $x_i = a + i h$ for $i=0,1,\\dots,N$, where $N$ is an even integer. Let $f_i = f(x_i)$ denote the sampled values of $f$ at nodes.\n- For each adjacent triple of nodes $\\left(x_i,x_{i+1},x_{i+2}\\right)$, define a dimensionless curvature indicator\n$$\n\\kappa_i \\;=\\; \\frac{\\left|\\, f_i - 2 f_{i+1} + f_{i+2}\\,\\right|}{\\max\\!\\left(1,\\; \\left|f_i\\right| + \\left|f_{i+1}\\right| + \\left|f_{i+2}\\right|\\right)} \\, .\n$$\nIntuitively, the numerator is a scaled second-order finite difference that is proportional to $h^2 f''(\\xi)$ for some $\\xi$ in $\\left[x_i,x_{i+2}\\right]$, while the denominator normalizes by a local amplitude scale to make $\\kappa_i$ dimensionless and robust across functions and magnitudes.\n- On each pair of consecutive subintervals $\\left[x_i,x_{i+2}\\right]$ with $i=0,2,4,\\dots,N-2$, decide the local quadrature as follows:\n    - If $\\kappa_i \\le \\tau$ for a given threshold $\\tau > 0$, approximate $\\int_{x_i}^{x_{i+2}} f(x)\\,dx$ by integrating the quadratic interpolant through $\\left(x_i,f_i\\right)$, $\\left(x_{i+1},f_{i+1}\\right)$, and $\\left(x_{i+2},f_{i+2}\\right)$.\n    - Otherwise, approximate $\\int_{x_i}^{x_{i+2}} f(x)\\,dx$ by summing the integrals of the linear interpolants on $\\left[x_i,x_{i+1}\\right]$ and $\\left[x_{i+1},x_{i+2}\\right]$.\n- The full hybrid integral on $\\left[a,b\\right]$ is the sum of the chosen local approximations over all pairs $\\left[x_i,x_{i+2}\\right]$.\n- For comparison, also compute on the same grid:\n    - The composite Simpson's rule approximation that uses the quadratic interpolant on every pair $\\left[x_i,x_{i+2}\\right]$ with $i$ even.\n    - The composite trapezoidal rule approximation that uses linear interpolants on every single subinterval $\\left[x_i,x_{i+1}\\right]$.\n\nAngle unit requirement: when trigonometric functions appear, angles must be interpreted in radians.\n\nYour program must implement this hybrid scheme and evaluate it on the following test suite. In each case, compute three approximations: the hybrid integral, the composite Simpson's integral, and the composite trapezoidal integral. Then compute the absolute error of each approximation with respect to the exact integral. All input values below are given exactly and must be used as-is.\n\nTest suite:\n- Case A (smooth, exponentially varying): $f(x) = e^{x}$ on $\\left[a,b\\right] = \\left[0,1\\right]$, with $N = 200$ and $\\tau = 0.010$. Exact integral: $\\int_{0}^{1} e^{x}\\,dx = e - 1$.\n- Case B (nonsmooth kink): $f(x) = \\left|x\\right|$ on $\\left[a,b\\right] = \\left[-1,1\\right]$, with $N = 200$ and $\\tau = 0.005$. Exact integral: $\\int_{-1}^{1} \\left|x\\right|\\,dx = 1$.\n- Case C (rapid oscillations; angles in radians): $f(x) = \\sin\\!\\left(50 x\\right)$ on $\\left[a,b\\right] = \\left[0,2\\pi\\right]$, with $N = 2000$ and $\\tau = 0.020$. Exact integral: $\\int_{0}^{2\\pi} \\sin\\!\\left(50 x\\right)\\,dx = 0$.\n- Case D (endpoint singular derivative): $f(x) = \\sqrt{x}$ on $\\left[a,b\\right] = \\left[0,1\\right]$, with $N = 200$ and $\\tau = 0.010$. Exact integral: $\\int_{0}^{1} \\sqrt{x}\\,dx = \\dfrac{2}{3}$.\n- Case E (rational decay): $f(x) = \\dfrac{1}{1+x^{2}}$ on $\\left[a,b\\right] = \\left[-5,5\\right]$, with $N = 400$ and $\\tau = 0.010$. Exact integral: $\\int_{-5}^{5} \\dfrac{1}{1+x^{2}}\\,dx = 2 \\arctan(5)$.\n- Case F (boundary-size partition; angles in radians): $f(x) = \\cos(x)$ on $\\left[a,b\\right] = \\left[0,\\pi\\right]$, with $N = 2$ and $\\tau = 0.010$. Exact integral: $\\int_{0}^{\\pi} \\cos(x)\\,dx = 0$.\n\nFinal output format requirement:\n- For each case, produce a list of six floating-point numbers in the following order: $\\left[I_{\\text{hybrid}}, I_{\\text{Simpson}}, I_{\\text{trapezoid}}, E_{\\text{hybrid}}, E_{\\text{Simpson}}, E_{\\text{trapezoid}}\\right]$, where $E_{\\cdot}$ denotes the absolute error with respect to the exact integral.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each case's six-tuple is itself a bracketed, comma-separated list. For example: $[\\,[\\cdots],\\,[\\cdots],\\,[\\cdots]\\,]$.\n- For numerical reproducibility, print each floating-point number rounded to exactly $10$ decimal places.",
            "solution": "We begin from the Riemann integral of a function $f$ on $\\left[a,b\\right]$, defined as the limit of Riemann sums over partitions as the mesh size tends to zero. On a uniform grid with $N$ subintervals, let $h = \\dfrac{b-a}{N}$ and nodes $x_i = a + i h$ for $i=0,1,\\dots,N$. Approximating $\\int_{a}^{b} f(x)\\,dx$ numerically amounts to replacing $f$ by simpler local surrogates whose integrals we can compute exactly.\n\nThe trapezoidal rule arises from locally approximating $f$ by the unique linear interpolant $\\ell(x)$ through endpoint values at $x_i$ and $x_{i+1}$. Since $\\ell(x)$ is linear, its integral on $\\left[x_i,x_{i+1}\\right]$ is exactly\n$$\n\\int_{x_i}^{x_{i+1}} \\ell(x)\\,dx \\;=\\; \\frac{h}{2}\\Big(f(x_i) + f(x_{i+1})\\Big),\n$$\nso the composite trapezoidal rule sums this over all subintervals:\n$$\nI_{\\text{trap}} \\;=\\; \\sum_{i=0}^{N-1} \\frac{h}{2}\\Big(f_i + f_{i+1}\\Big).\n$$\nBy Taylor expansion around $x_i$ with $x_{i+1} = x_i + h$, one can show that the local truncation error on a single subinterval is proportional to $- \\dfrac{h^3}{12} f''(\\xi_i)$ for some $\\xi_i \\in \\left[x_i,x_{i+1}\\right]$, leading to a global error of order $\\mathcal{O}(h^2)$ for sufficiently smooth $f$.\n\nSimpson's rule is obtained by approximating $f$ on a pair of subintervals $\\left[x_i,x_{i+2}\\right]$ with the unique quadratic interpolant $q(x)$ through the three points $\\left(x_i,f_i\\right)$, $\\left(x_{i+1},f_{i+1}\\right)$, and $\\left(x_{i+2},f_{i+2}\\right)$. Using Lagrange interpolation polynomials or direct construction of $q(x)$ and integrating, one derives the exact integral of $q$ on $\\left[x_i,x_{i+2}\\right]$:\n$$\n\\int_{x_i}^{x_{i+2}} q(x)\\,dx \\;=\\; \\frac{h}{3}\\,\\Big(f_i + 4 f_{i+1} + f_{i+2}\\Big).\n$$\nSumming over even indices $i=0,2,\\dots,N-2$ yields the composite Simpson's rule\n$$\nI_{\\text{simp}} \\;=\\; \\sum_{\\substack{i=0 \\\\ i\\text{ even}}}^{N-2} \\frac{h}{3}\\,\\Big(f_i + 4 f_{i+1} + f_{i+2}\\Big).\n$$\nA Taylor series analysis shows that Simpson's rule has local error proportional to $-\\dfrac{h^5}{90} f^{(4)}(\\xi_i)$ for some $\\xi_i \\in \\left[x_i,x_{i+2}\\right]$, leading to a global error of order $\\mathcal{O}(h^4)$ for sufficiently smooth $f$ with a continuous fourth derivative.\n\nNear nondifferentiable points or sharp changes, quadratic interpolation can become unreliable: the higher-order formula presumes local smoothness. To adaptively choose between these surrogates, we design a smoothness indicator using second-order finite differences. On a uniform grid, the centered second finite difference\n$$\n\\Delta^2 f_{i} \\;=\\; f_i - 2 f_{i+1} + f_{i+2}\n$$\nsatisfies $\\Delta^2 f_{i} \\approx h^{2} f''(\\xi_i)$ for some $\\xi_i \\in \\left[x_i,x_{i+2}\\right]$ under sufficient smoothness. Its magnitude reflects local curvature. To make this detection dimensionless and scale-robust across functions with different amplitudes, we normalize by a local amplitude scale, yielding\n$$\n\\kappa_i \\;=\\; \\frac{\\left|\\, f_i - 2 f_{i+1} + f_{i+2}\\,\\right|}{\\max\\!\\left(1,\\; \\left|f_i\\right| + \\left|f_{i+1}\\right| + \\left|f_{i+2}\\right|\\right)}.\n$$\nWhen $f$ is locally nearly linear or gently curved across $\\left[x_i,x_{i+2}\\right]$, we expect $\\kappa_i$ to be small (since $\\Delta^2 f_i = \\mathcal{O}(h^2)$ and the denominator is at least $\\mathcal{O}(1)$). Conversely, near kinks, sharp curvature, or rapid variation, $\\kappa_i$ will be relatively larger. We choose a user-specified threshold $\\tau > 0$ and, for each pair $\\left[x_i,x_{i+2}\\right]$ with $i$ even, apply:\n- If $\\kappa_i \\le \\tau$, we use the Simpson quadratic surrogate on $\\left[x_i,x_{i+2}\\right]$.\n- If $\\kappa_i > \\tau$, we revert to the sum of two trapezoids on $\\left[x_i,x_{i+1}\\right]$ and $\\left[x_{i+1},x_{i+2}\\right]$, corresponding to integrating linear surrogates, which are more robust near nondifferentiabilities.\n\nThis yields the hybrid approximation\n$$\nI_{\\text{hyb}} \\;=\\; \\sum_{\\substack{i=0 \\\\ i\\text{ even}}}^{N-2}\n\\begin{cases}\n\\dfrac{h}{3}\\,\\Big(f_i + 4 f_{i+1} + f_{i+2}\\Big), & \\text{if } \\kappa_i \\le \\tau \\\\[10pt]\n\\dfrac{h}{2}\\,\\Big(f_i + 2 f_{i+1} + f_{i+2}\\Big), & \\text{if } \\kappa_i > \\tau\n\\end{cases}\n$$\nwhere the trapezoidal contribution on the pair is the sum of two subinterval trapezoids:\n$$\n\\frac{h}{2}\\Big(f_i + f_{i+1}\\Big) + \\frac{h}{2}\\Big(f_{i+1} + f_{i+2}\\Big) \\;=\\; \\frac{h}{2}\\,\\Big(f_i + 2 f_{i+1} + f_{i+2}\\Big).\n$$\n\nAlgorithmic design:\n- Input: a function handle $f$, endpoints $a$ and $b$, an even integer $N$, and threshold $\\tau$.\n- Compute $h = \\dfrac{b-a}{N}$ and sample $f_i = f(a + i h)$.\n- Initialize sums for $I_{\\text{hyb}}$, $I_{\\text{simp}}$, and $I_{\\text{trap}}$.\n- For $i=0,2,\\dots,N-2$:\n    - Compute $\\kappa_i$ from $\\left(f_i,f_{i+1},f_{i+2}\\right)$.\n    - If $\\kappa_i \\le \\tau$, add the Simpson pair to $I_{\\text{hyb}}$; else, add the pair of trapezoids.\n    - Regardless of $\\kappa_i$, add the Simpson pair to $I_{\\text{simp}}$.\n- Separately, compute $I_{\\text{trap}}$ by summing all single-subinterval trapezoids over $i=0,1,\\dots,N-1$.\n- For each test function, compute the exact integral $I_{\\text{exact}}$ using elementary antiderivatives:\n    - For $f(x) = e^{x}$ on $\\left[0,1\\right]$: $I_{\\text{exact}} = e - 1$.\n    - For $f(x) = \\left|x\\right|$ on $\\left[-1,1\\right]$: by symmetry, $I_{\\text{exact}} = 1$.\n    - For $f(x) = \\sin\\!\\left(50 x\\right)$ on $\\left[0,2\\pi\\right]$: the integral of a full number of periods is $0$ in radians, so $I_{\\text{exact}} = 0$.\n    - For $f(x) = \\sqrt{x}$ on $\\left[0,1\\right]$: with antiderivative $\\dfrac{2}{3} x^{3/2}$, $I_{\\text{exact}} = \\dfrac{2}{3}$.\n    - For $f(x) = \\dfrac{1}{1+x^{2}}$ on $\\left[-5,5\\right]$: antiderivative $\\arctan(x)$ gives $I_{\\text{exact}} = \\arctan(5) - \\arctan(-5) = 2 \\arctan(5)$.\n    - For $f(x) = \\cos(x)$ on $\\left[0,\\pi\\right]$: antiderivative $\\sin(x)$ gives $I_{\\text{exact}} = 0$.\n- Compute absolute errors $E_{\\text{hyb}} = \\left|I_{\\text{hyb}} - I_{\\text{exact}}\\right|$, and similarly for Simpson and trapezoid.\n\nComplexity and behavior:\n- The algorithm is $\\mathcal{O}(N)$ with a single pass over the samples and constant work per subinterval or pair.\n- In smooth regions where $f^{(4)}$ is bounded and small relative to the local amplitude, $\\kappa_i$ tends to be small, hence Simpson's rule (with $\\mathcal{O}(h^4)$ global accuracy) predominates.\n- Near kinks, corners, or steep localized transitions, $\\kappa_i$ tends to exceed the threshold, triggering the trapezoidal fallback, which is more robust for functions lacking sufficient smoothness for quadratic interpolation to be reliable.\n- The threshold $\\tau$ balances sensitivity to curvature against false positives; because $\\kappa_i$ is dimensionless and includes a normalization by local amplitude, the same $\\tau$ can be used across diverse functions.\n\nThe output must list, for each test case, the triplet of approximations and their absolute errors, rounded to exactly $10$ decimal places, aggregated into a single line as a bracketed, comma-separated list of bracketed six-tuples.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef composite_trapezoid(f, a, b, N):\n    h = (b - a) / N\n    s = 0.0\n    x = a\n    fx_prev = f(x)\n    for i in range(1, N + 1):\n        x = a + i * h\n        fx = f(x)\n        s += 0.5 * h * (fx_prev + fx)\n        fx_prev = fx\n    return s\n\ndef composite_simpson(f, a, b, N):\n    # N must be even\n    h = (b - a) / N\n    s = 0.0\n    for i in range(0, N, 2):\n        x0 = a + i * h\n        x1 = x0 + h\n        x2 = x0 + 2 * h\n        f0 = f(x0)\n        f1 = f(x1)\n        f2 = f(x2)\n        s += (h / 3.0) * (f0 + 4.0 * f1 + f2)\n    return s\n\ndef hybrid_simpson_trapezoid(f, a, b, N, tau):\n    # N must be even\n    h = (b - a) / N\n    # Precompute samples to reuse in indicators\n    xs = np.linspace(a, b, N + 1)\n    fs = np.array([f(x) for x in xs], dtype=float)\n    s = 0.0\n    for i in range(0, N, 2):\n        f0 = fs[i]\n        f1 = fs[i + 1]\n        f2 = fs[i + 2]\n        denom = max(1.0, abs(f0) + abs(f1) + abs(f2))\n        kappa = abs(f0 - 2.0 * f1 + f2) / denom\n        if kappa = tau:\n            s += (h / 3.0) * (f0 + 4.0 * f1 + f2)\n        else:\n            s += 0.5 * h * (f0 + 2.0 * f1 + f2)\n    return s\n\ndef format_number(x):\n    # Round and format to exactly 10 decimal places without scientific notation\n    return f\"{x:.10f}\"\n\ndef format_results_no_spaces(results):\n    # results is a list of lists of floats\n    inner_strings = []\n    for res in results:\n        nums = \",\".join(format_number(v) for v in res)\n        inner_strings.append(f\"[{nums}]\")\n    return \"[\" + \",\".join(inner_strings) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: function f, a, b, N (even), tau, exact integral exact_val\n    test_cases = [\n        # Case A: f(x) = exp(x), [0,1], N=200, tau=0.010, exact = e - 1\n        (lambda x: float(np.exp(x)), 0.0, 1.0, 200, 0.010, float(np.e - 1.0)),\n        # Case B: f(x) = |x|, [-1,1], N=200, tau=0.005, exact = 1\n        (lambda x: abs(x), -1.0, 1.0, 200, 0.005, 1.0),\n        # Case C: f(x) = sin(50 x) radians, [0, 2*pi], N=2000, tau=0.020, exact = 0\n        (lambda x: float(np.sin(50.0 * x)), 0.0, float(2.0 * np.pi), 2000, 0.020, 0.0),\n        # Case D: f(x) = sqrt(x), [0,1], N=200, tau=0.010, exact = 2/3\n        (lambda x: float(np.sqrt(x)), 0.0, 1.0, 200, 0.010, 2.0 / 3.0),\n        # Case E: f(x) = 1/(1+x^2), [-5,5], N=400, tau=0.010, exact = 2*atan(5)\n        (lambda x: 1.0 / (1.0 + x * x), -5.0, 5.0, 400, 0.010, float(2.0 * np.arctan(5.0))),\n        # Case F: f(x) = cos(x), [0,pi], N=2, tau=0.010, exact = 0\n        (lambda x: float(np.cos(x)), 0.0, float(np.pi), 2, 0.010, 0.0),\n    ]\n\n    results = []\n    for f, a, b, N, tau, exact_val in test_cases:\n        # Hybrid\n        I_hyb = hybrid_simpson_trapezoid(f, a, b, N, tau)\n        # Simpson\n        I_simp = composite_simpson(f, a, b, N)\n        # Trapezoid\n        I_trap = composite_trapezoid(f, a, b, N)\n        # Errors\n        E_hyb = abs(I_hyb - exact_val)\n        E_simp = abs(I_simp - exact_val)\n        E_trap = abs(I_trap - exact_val)\n        results.append([I_hyb, I_simp, I_trap, E_hyb, E_simp, E_trap])\n\n    # Final print statement in the exact required format: one line, bracketed, comma-separated, no spaces,\n    # each number printed to exactly 10 decimal places.\n    print(format_results_no_spaces(results))\n\nsolve()\n```"
        }
    ]
}