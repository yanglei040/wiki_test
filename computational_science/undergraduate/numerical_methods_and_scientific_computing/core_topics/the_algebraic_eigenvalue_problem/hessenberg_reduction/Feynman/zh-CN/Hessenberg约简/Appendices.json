{
    "hands_on_practices": [
        {
            "introduction": "理论是实践的基础。在编写复杂的数值算法之前，通过手动计算来深入理解其核心机制是至关重要的。这个练习将带你“亲手”执行Hessenberg约化的第一步，使用Householder变换来处理一个精心设计的对称矩阵。通过这个过程，你不仅能掌握Householder向量和反射矩阵的构造方法，还能理解为何对于特定矩阵，整个约化过程可以完全在有理数域内完成，从而深刻体会该算法的代数结构。",
            "id": "3238489",
            "problem": "考虑使用由 Householder 反射构成的正交相似变换将一个实矩阵约化为 Hessenberg 型的任务。回忆一下，对于一个实对称矩阵，其上 Hessenberg 型就是三对角型。构建以下特定的整数矩阵\n$$\nA \\;=\\;\n\\begin{pmatrix}\n7  1  2  2 \\\\\n1  1  0  0 \\\\\n2  0  1  0 \\\\\n2  0  0  1\n\\end{pmatrix},\n$$\n该矩阵是对称的，大小为 $4 \\times 4$。从正交矩阵和 Householder 反射的基本定义出发（不借助任何预先包装好的算法捷径），执行第一步相似变换，该变换仅非平凡地作用于末尾的 $(4-1) \\times (4-1)$ 子块（即索引为 2 到 4 的行和列），以便在第 1 列的次对角线下方引入零。然后，仔细论证为什么对于这个特定的矩阵 $A$，可以使用纯有理数运算完成整个三对角化过程。\n\n设 $T$ 表示通过此 Hessenberg (三对角) 约化从 $A$ 得到的最终三对角矩阵。计算 $T$ 的 $(2,1)$ 元素的精确值。你的最终答案需要是精确值，不需要四舍五入。",
            "solution": "该问题要求做两件事：首先，计算通过 Householder 约化从给定对称矩阵 $A$ 得到的最终三对角矩阵 $T$ 的 $(2,1)$ 元素；其次，仔细论证为什么对于这个特定的矩阵，整个三对角化过程可以仅使用有理数运算来完成。\n\n给定的矩阵是：\n$$\nA \\;=\\;\n\\begin{pmatrix}\n7  1  2  2 \\\\\n1  1  0  0 \\\\\n2  0  1  0 \\\\\n2  0  0  1\n\\end{pmatrix}\n$$\n这是一个实的、$4 \\times 4$ 的对称矩阵。对对称矩阵进行 Hessenberg 约化会产生一个三对角矩阵。该过程涉及一系列使用 Householder 矩阵的相似变换。对于一个 $n \\times n$ 矩阵，这需要 $n-2$ 步。在我们的例子中，$n=4$，所以最多需要 2 步。\n\n约化的第一步旨在在 $A$ 的第一列的位置 $(3,1)$ 和 $(4,1)$ 处引入零。这是通过相似变换 $A_1 = P_1 A P_1$ 实现的。矩阵 $P_1$ 是一个正交矩阵，其形式为：\n$$\nP_1 = \\begin{pmatrix}\n1  \\mathbf{0}^T \\\\\n\\mathbf{0}  H\n\\end{pmatrix}\n$$\n其中 $H$ 是一个 $3 \\times 3$ 的 Householder 矩阵。选择矩阵 $H$ 是为了作用于我们想要修改的 $A$ 的第一列的子向量。设 $a_1$ 为 $A$ 的第一列。我们将 $a_1$ 划分为：\n$$\na_1 = \\begin{pmatrix} a_{11} \\\\ x \\end{pmatrix} = \\begin{pmatrix} 7 \\\\ 1 \\\\ 2 \\\\ 2 \\end{pmatrix}, \\quad \\text{其中} \\quad x = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}.\n$$\nHouseholder 矩阵 $H$ 的构造方式是，它将向量 $x$ 映射为第一个标准基向量 $e_1 = (1, 0, 0)^T$ 的一个倍数。即，对于某个标量 $\\alpha$，有 $Hx = \\alpha e_1$。\n\nHouseholder 反射是一种正交变换，因此它保持欧几里得范数不变。因此，我们必须有 $\\|Hx\\|_2 = \\|x\\|_2$。这意味着 $|\\alpha| = \\|x\\|_2$。我们计算 $x$ 的范数：\n$$\n\\|x\\|_2 = \\sqrt{1^2 + 2^2 + 2^2} = \\sqrt{1 + 4 + 4} = \\sqrt{9} = 3.\n$$\n为了数值稳定性，$\\alpha$ 的符号选择为与 $x$ 的第一个分量的符号相反。这里，$x_1=1$ 是正数。所以我们选择 $\\alpha = -\\text{sgn}(x_1)\\|x\\|_2 = -(+1)(3) = -3$。\n目标向量是 $Hx = \\begin{pmatrix} -3 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n\n变换后的矩阵 $A_1 = P_1 A P_1$ 的第一列由 $P_1 A (P_1 e_1)$ 给出。由于 $P_1$ 的第一列是 $e_1$，所以 $P_1 e_1 = e_1$。因此 $A_1$ 的第一列是 $P_1 a_1$。\n$$\nP_1 a_1 = \\begin{pmatrix} 1  \\mathbf{0}^T \\\\ \\mathbf{0}  H \\end{pmatrix} \\begin{pmatrix} a_{11} \\\\ x \\end{pmatrix} = \\begin{pmatrix} a_{11} \\\\ Hx \\end{pmatrix} = \\begin{pmatrix} 7 \\\\ -3 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n矩阵 $A$ 是对称的，Householder 矩阵 $P_1$ 也是对称的（$P_1^T = P_1$）和正交的（$P_1^{-1} = P_1^T = P_1$）。因此，变换后的矩阵 $A_1 = P_1 A P_1$ 也是对称的。这意味着 $A_1$ 的第一行必须是其第一列的转置：$(7, -3, 0, 0)$。\n所以，在第一步之后，矩阵 $A_1$ 的形式为：\n$$\nA_1 = \\begin{pmatrix}\n7  -3  0  0 \\\\\n-3  A_1(2,2)  A_1(2,3)  A_1(2,4) \\\\\n0  A_1(3,2)  A_1(3,3)  A_1(3,4) \\\\\n0  A_1(4,2)  A_1(4,3)  A_1(4,4)\n\\end{pmatrix}.\n$$\n元素 $A_1(2,1)$ 是 $-3$。\n\n三对角化过程的第二步（如果需要）将应用一个变换 $A_2 = P_2 A_1 P_2$，其中 $P_2$ 的形式为：\n$$\nP_2 = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  \\tilde{H}  \\\\\n0  0  \n\\end{pmatrix}.\n$$\n这个变换作用于第 3 和第 4 行及列，并保持前两行和前两列不变。具体来说，$A_2$ 的 $(2,1)$ 元素将与 $A_1$ 的 $(2,1)$ 元素相同。\n因此，最终三对角矩阵 $T$ 的 $(2,1)$ 元素仅由第一步确定。该值为 $T(2,1) = A_1(2,1) = -3$。\n\n现在，我们必须论证为什么三对角化过程可以仅使用有理数运算来完成。\n对于一个向量 $y$，其一般的 Householder 变换由矩阵 $P = I - 2 \\frac{vv^T}{v^Tv}$ 给出，其中 Householder 向量为 $v = y \\pm \\|y\\|_2 e_1$。对于一个具有有理数元素的向量 $y$，要使变换矩阵 $P$ 具有有理数元素，其充分必要条件是 $\\|y\\|_2$ 是一个有理数。如果在每一步中这个条件都成立，并且初始矩阵 $A$ 是有理的，那么整个过程都保持在有理数域 $\\mathbb{Q}$ 内。\n\n初始矩阵 $A$ 的元素都是整数，因此是有理数。\n\n在第一步中，被变换的向量是 $x = (1, 2, 2)^T$。它的元素是有理数。它的范数是 $\\|x\\|_2 = 3$，这是一个有理数。\n因此，Householder 向量 $v = x - (-3)e_1 = (1,2,2)^T + (3,0,0)^T = (4,2,2)^T$ 具有有理数元素。相应的 $3 \\times 3$ 矩阵 $H = I_3 - 2\\frac{vv^T}{v^Tv}$ 和完整的 $4 \\times 4$ 矩阵 $P_1$ 都具有有理数元素。因此，矩阵 $A_1 = P_1 A P_1$ 的所有元素也必须在 $\\mathbb{Q}$ 中。\n\n对于 $4 \\times 4$ 约化的第二步（也是最后一步），我们将应用一个变换来将元素 $A_1(4,2)$ 置零。这一步作用于向量 $y = (A_1(3,2), A_1(4,2))^T$。让我们计算这个向量。\n根据 $A_1$ 的对称性，我们有 $A_1(3,2) = A_1(2,3)$ 和 $A_1(4,2) = A_1(2,4)$。我们需要计算 $A_1$ 的末尾 $3\\times3$ 主子矩阵。一种计算变换后矩阵的高效方法是使用 $A_1 = A - P_1' A - A P_1' + P_1' A P_1'$，其中 $P_1' = P_1 - I$。或者更直接地，$A_1=A-\\frac{1}{\\|v\\|_2^2/2}(v_{ext}w^T+wv_{ext}^T)+\\frac{v_{ext}^T A v_{ext}}{(\\|v\\|_2^2/2)^2}v_{ext}v_{ext}^T$，其中 $v_{ext}=(0,4,2,2)^T$ 且 $w=Av_{ext}=(12,4,2,2)^T$。然而，由于我们已经证明 $A_1$ 是对称的，且其第一行为 $(7, -3, 0, 0)$，如果 $A_1(2,3)=0$ 和 $A_1(2,4)=0$，我们可以推断出 $A_1(3,2)=0$ 和 $A_1(4,2)=0$。由于第一步将第一列主对角线下方的元素置零，并且由于对称性，第一行主对角线上方的元素也被置零（上对角元素除外）。实际上，$A_1$ 的第一行是 $(7, -3, 0, 0)$。因此 $A_1(1,3)=0$ 且 $A_1(1,4)=0$。根据对称性，$A_1(3,1)=0$ 且 $A_1(4,1)=0$。这正是我们已经确定的。\n\n第二步要考虑的向量是 $y = \\begin{pmatrix} A_1(3,2) \\\\ A_1(4,2) \\end{pmatrix}$。根据对称性，$A_1(3,2) = A_1(2,3)$ 且 $A_1(4,2) = A_1(2,4)$。\n让我们计算 $A_1(2,3)$ 和 $A_1(2,4)$。$A_1=P_1AP_1$。$A_1$ 的第二行是 $e_2^T P_1 A P_1$。\n使用 $H = \\frac{1}{3}\\begin{pmatrix}-1  -2  -2 \\\\ -2  2  -1 \\\\ -2  -1  2\\end{pmatrix}$，我们得到向量 $p_{1,2}^T = e_2^T P_1 = (0, -1/3, -2/3, -2/3)$。\n然后 $p_{1,2}^T A = (0, -1/3, -2/3, -2/3) \\begin{pmatrix} 7  1  2  2 \\\\ 1  1  0  0 \\\\ 2  0  1  0 \\\\ 2  0  0  1 \\end{pmatrix} = (-1/3-4/3-4/3, -1/3, -2/3, -2/3) = (-3, -1/3, -2/3, -2/3)$。\n最后，$(p_{1,2}^T A)P_1 = (-3, -1/3, -2/3, -2/3) \\begin{pmatrix} 1  0  0  0 \\\\ 0  -1/3  -2/3  -2/3 \\\\ 0  -2/3  2/3  -1/3 \\\\ 0  -2/3  -1/3  2/3 \\end{pmatrix}$。\n$A_1(2,3) = (-3)(0) + (-1/3)(-2/3) + (-2/3)(2/3) + (-2/3)(-1/3) = 2/9 - 4/9 + 2/9 = 0$。\n$A_1(2,4) = (-3)(0) + (-1/3)(-2/3) + (-2/3)(-1/3) + (-2/3)(2/3) = 2/9 + 2/9 - 4/9 = 0$。\n所以第二步的向量是 $y = (0, 0)^T$。\n\n其范数为 $\\|y\\|_2 = 0$，这是一个有理数。对于零向量的 Householder 变换是单位矩阵（或者，在实践中，这一步被跳过）。这意味着 $A_1$ 已经是三对角矩阵了。\n由于约化过程中每个阶段的向量范数都是有理数（$3$ 和 $0$），整个三对角化过程可以仅使用有理数运算来完成。\n\n最终的三对角矩阵是 $T=A_1$。其 $(2,1)$ 元素是 $-3$。",
            "answer": "$$\\boxed{-3}$$"
        },
        {
            "introduction": "从手动计算过渡到代码实现时，我们必须面对数值稳定性的挑战——这是科学计算的中心议题之一。本练习旨在通过对比两种不同的Hessenberg约化方法，来揭示数值稳定性的重要性。你将分别实现基于经典Gram-Schmidt正交化的Arnoldi过程和基于Householder反射的方法。通过在一个特制的、会引发数值问题的矩阵上测试这两种算法，你将直观地看到为何Householder方法因其卓越的稳定性而成为现代数值软件库的标准选择。",
            "id": "3238560",
            "problem": "您的任务是对比两种针对实方阵的上Hessenberg约简方法：一种是基于嵌入在Arnoldi过程中的经典Gram-Schmidt正交化的朴素方法，另一种是基于作为双边相似变换应用的Householder反射的稳定方法。目标是构建并分析一些矩阵，对于这些矩阵，经典Gram-Schmidt方法会表现出数值不稳定性，而基于Householder的方法则保持鲁棒性。\n\n基本和核心定义：\n- 如果一个矩阵 $H \\in \\mathbb{R}^{n \\times n}$ 对于所有 $i \\ge j + 2$ 都满足 $H_{i,j} = 0$，则该矩阵是上Hessenberg矩阵。\n- 对于一个向量序列 $\\{w_j\\}$，经典Gram-Schmidt正交化构建 $v_1 = w_1 / \\|w_1\\|_2$，并且对于 $j \\ge 1$，定义\n$$\nh_{i,j} = v_i^\\top w_j, \\quad \\tilde{w}_j = w_j - \\sum_{i=1}^{j} h_{i,j} v_i, \\quad v_{j+1} = \\tilde{w}_j / \\|\\tilde{w}_j\\|_2,\n$$\n只要 $\\|\\tilde{w}_j\\|_2 \\ne 0$。Arnoldi过程将此应用于 $w_j = A v_j$（对于一个矩阵 $A \\in \\mathbb{R}^{n \\times n}$），生成一个标准正交基 $V_k = [v_1,\\dots,v_k]$ 和一个上Hessenberg矩阵 $H_k \\in \\mathbb{R}^{k \\times k}$，满足 $A V_k \\approx V_k H_k$。\n- Householder反射镜是 $P = I - 2 u u^\\top$，其中 $u \\in \\mathbb{R}^m$ 的选择使得对于任意给定的 $x \\in \\mathbb{R}^m$ 和某个标量 $\\alpha \\in \\mathbb{R}$，都有 $P x = \\alpha e_1$。基于Householder的Hessenberg约简在左侧和右侧应用一系列此类反射镜，以计算一个正交矩阵 $Q$ 和一个上Hessenberg矩阵 $H$，使得 $A = Q H Q^\\top$。\n\n您的任务：\n1. 实现一个经典的Gram-Schmidt Arnoldi程序，给定 $A \\in \\mathbb{R}^{n \\times n}$、一个起始单位向量 $v_1 \\in \\mathbb{R}^n$ 和目标维度 $k$，该程序返回一个标准正交矩阵 $V \\in \\mathbb{R}^{n \\times m}$（其中 $m \\le k$ 取决于是否发生中断）和一个上Hessenberg矩阵 $H \\in \\mathbb{R}^{m \\times m}$，使得 $A V \\approx V H$。使用单遍经典Gram-Schmidt，不进行任何重正交化。使用以下指标量化数值稳定性：\n   - 正交性损失度量 $o = \\max_{i \\ne j} |(V^\\top V)_{i,j}|$。\n   - Arnoldi残差比 $r_A = \\|A V - V H\\|_F / \\|A\\|_F$。\n   - 如果一个新向量的范数低于阈值 $\\tau = 10^{-14}$，则声明发生中断，导致 $m  k$。\n\n2. 实现一个基于Householder的完整Hessenberg约简，计算满足 $A = Q H Q^\\top$ 的 $Q \\in \\mathbb{R}^{n \\times n}$ 和 $H \\in \\mathbb{R}^{n \\times n}$。应用一系列Householder反射镜 $P_j = I - 2 u_j u_j^\\top$（对于 $j = 0,1,\\dots,n-3$），每个反射镜旨在将第 $j$ 列中第一副对角线以下的元素置零。使用以下指标量化数值上的成功：\n   - 第二副对角线以下范数 $b = \\sqrt{\\sum_{i \\ge j+2} \\sum_j H_{i,j}^2}$。\n   - 重构残差比 $r_H = \\|A - Q H Q^\\top\\|_F / \\|A\\|_F$。\n\n3. 构建并分析以下测试矩阵和起始向量组：\n   - 情况 1（病态的近单位Jordan扰动）：令 $n = 25$，$\\varepsilon = 10^{-16}$，且 $J \\in \\mathbb{R}^{n \\times n}$ 为Jordan块，其中对所有 $i$，有 $J_{i,i} = 0$，对 $i = 1,\\dots,n-1$，有 $J_{i,i+1} = 1$，所有其他元素为 $0$。定义 $A_1 = I + \\varepsilon J$。使用起始向量 $v_1$，其所有元素 $(v_1)_i = 1$，并归一化到单位 $2$-范数。选择这个矩阵是为了使Krylov序列 $\\{A_1^j v_1\\}$ 变得近似共线，从而在经典Gram-Schmidt Arnoldi过程中引发数值不稳定性。\n   - 情况 2（良态的对称三对角Toeplitz矩阵）：令 $n = 20$，并定义 $A_2 \\in \\mathbb{R}^{n \\times n}$ 为 $(A_2)_{i,i} = 2$，$(A_2)_{i,i+1} = -1$，$(A_2)_{i+1,i} = -1$（对于 $i = 1,\\dots,n-1$），所有其他元素为 $0$。使用起始向量 $v_1$，其元素为 $(v_1)_i = \\sin(i)$，并归一化到单位 $2$-范数。\n   - 情况 3（中等大小的良态三对角矩阵）：令 $n = 6$，并以与 $A_2$ 相同的方式定义 $A_3$，尺寸为 $n = 6$。使用起始向量 $v_1$，其所有元素 $(v_1)_i = 1$，并归一化到单位 $2$-范数。\n\n每种情况的判定规则：\n- 如果以下任一条件成立，则声明经典Gram-Schmidt Arnoldi方法失败：$m  n$，$o > 10^{-3}$，或 $r_A > 10^{-8}$。\n- 如果 $b  10^{-12}$ 和 $r_H  10^{-12}$ 同时成立，则声明Householder方法成功。\n- 对于每种情况，程序必须输出一个布尔值，指示朴素的基于Gram-Schmidt的Hessenberg约简是否因数值不稳定性而失败，而基于Householder的方法是否成功。即，如果经典Gram-Schmidt Arnoldi失败而Householder成功，则输出 $\\text{True}$，否则输出 $\\text{False}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[result1,result2,result3]”），其中每个结果是对应于 $A_1$、$A_2$、$A_3$ 三种情况的布尔值。\n\n本问题不涉及物理单位、角度或百分比；所有量均为无量纲的实数和矩阵。程序必须完全自包含，无需用户输入。",
            "solution": "问题陈述已经过严格评估并被确定为有效。它在科学上基于数值线性代数的原理，定义清晰，标准客观，问题设定合理，并且内部逻辑一致。它提出了一个对两种基本的Hessenberg约简算法进行比较分析的标准（尽管很重要）问题。\n\n任务是比较计算实方阵 $A \\in \\mathbb{R}^{n \\times n}$ 的上Hessenberg分解的两种方法的数值稳定性。第一种方法是采用经典Gram-Schmidt（CGS）且不进行重正交化的Arnoldi过程。第二种方法是一系列Householder相似变换。\n\n### 方法1：经典Gram-Schmidt Arnoldi（CGS-Arnoldi）过程\n\nArnoldi过程是一种迭代方法，用于构建Krylov子空间 $\\mathcal{K}_k(A, v_1) = \\text{span}\\{v_1, A v_1, \\dots, A^{k-1} v_1\\}$ 的一个标准正交基。当使用经典Gram-Schmidt过程实现时，它会生成一个标准正交向量序列 $v_1, v_2, \\dots, v_k$ 和一个上Hessenberg矩阵 $H_k \\in \\mathbb{R}^{k \\times k}$，它们满足Arnoldi关系式 $A V_k = V_k H_k + f_k e_k^\\top$，其中 $V_k = [v_1, \\dots, v_k]$，$f_k$ 是残差向量，$e_k$ 是第 $k$ 个标准基向量。\n\n给定 $A \\in \\mathbb{R}^{n \\times n}$、一个起始单位向量 $v_1 \\in \\mathbb{R}^n$ 和一个目标维度 $k$，算法流程如下：\n1. 初始化一个 $n \\times k$ 矩阵 $V$ 和一个 $k \\times k$ 矩阵 $H$。将 $V$ 的第一列设置为 $v_1$。\n2. 对于 $j = 1, \\dots, k$：\n   a. 计算下一个Krylov向量，$w = A v_j$。\n   b. 将 $w$ 与先前计算出的基向量 $\\{v_1, \\dots, v_j\\}$ 正交化：\n      对于 $i = 1, \\dots, j$：\n      i. 计算投影系数：$h_{i,j} = v_i^\\top w$。\n      ii. 从 $w$ 中减去投影：$w \\leftarrow w - h_{i,j} v_i$。\n   c. 如果 $j  k$：\n      i. 计算新向量的范数：$h_{j+1,j} = \\|w\\|_2$。\n      ii. 如果 $h_{j+1,j}$ 低于某个阈值 $\\tau$（例如 $10^{-14}$），则称过程发生中断。Krylov子空间是不变的，算法终止，得到一个维度为 $n \\times j$ 的矩阵 $V$ 和一个维度为 $j \\times j$ 的矩阵 $H$。\n      iii. 归一化以获得下一个基向量：$v_{j+1} = w / h_{j+1,j}$。\n\nCGS的核心数值问题出现在步骤2b。如果向量 $A v_j$ 与之前的基向量 $\\{v_1, \\dots, v_j\\}$ 近似线性相关，那么正交化后的向量 $w$ 将是两个巨大且几乎相等的量相减的结果。这会导致灾难性抵消和计算出的 $w$ 出现巨大的相对误差。因此，新计算的向量 $v_{j+1}$ 将不与先前的向量正交，导致基 $V$ 失去正交性。这种不稳定性通过正交性损失度量 $o = \\max_{i \\ne j} |(V^\\top V)_{i,j}|$ 来量化。Arnoldi残差比 $r_A = \\|A V - V H\\|_F / \\|A\\|_F$ 衡量了该分解在 $V$ 所张成的子空间上对 $A$ 的作用的近似程度。\n\n### 方法2：Householder Hessenberg约简\n\n该方法通过一系列使用Householder反射镜的相似变换，将一个稠密矩阵 $A$ 约简为上Hessenberg形式 $H$。目标是找到一个正交矩阵 $Q$，使得 $A = Q H Q^\\top$。Householder反射镜是一个形如 $P = I - 2 u u^\\top$ 的正交矩阵，其中 $u$ 是一个单位向量。对于给定的向量 $x$，可以选择 $u$ 使得 $P x$ 是第一个标准基向量 $e_1$ 的倍数。\n\n对于 $A \\in \\mathbb{R}^{n \\times n}$ 的完整约简算法流程如下：\n1. 初始化 $H = A$ 和 $Q = I_n$。\n2. 对于 $j = 0, 1, \\dots, n-3$：\n   a. 考虑由第 $j$ 列第一副对角线下方元素组成的向量 $x$：$x = H_{j+2:n, j}$。\n   b. 构建一个Householder向量 $u_j \\in \\mathbb{R}^{n-j-1}$，使得相应的反射镜 $P'_j = I - 2 u_j u_j^\\top$ 能将 $x$ 除第一个元素外的所有元素置零。中间向量 $v$ 的一个稳定选择是 $v = x + \\text{sign}(x_1) \\|x\\|_2 e_1$，由此可得 $u_j=v/\\|v\\|_2$。\n   c. 通过将 $P'_j$ 嵌入到一个单位矩阵中来形成完整的 $n \\times n$ 反射镜 $P_j$：\n      $$ P_j = \\begin{pmatrix} I_{j+1}  0 \\\\ 0  P'_{j} \\end{pmatrix} $$\n   d. 对矩阵应用相似变换：$H \\leftarrow P_j H P_j^\\top$。由于 $P_j$ 是自身的逆，所以 $P_j^\\top=P_j$。这通过一次左乘 $H \\leftarrow P_j H$ 和一次右乘 $H \\leftarrow H P_j$ 来完成。\n   e. 累积正交变换：$Q \\leftarrow Q P_j$。\n\n经过 $n-2$ 步后，得到的矩阵 $H$ 是上Hessenberg形式。最终的正交矩阵是 $Q = P_0 P_1 \\dots P_{n-3}$。由于每个变换 $P_j$ 都是正交的，它们的乘积 $Q$ 也是正交的。这一性质使得Householder约简是后向稳定的。计算出的 $H$ 是一个与原始矩阵 $A$ 非常接近的矩阵的精确Hessenberg形式。这种稳定性通过重构残差比 $r_H = \\|A - Q H Q^\\top\\|_F / \\|A\\|_F$ 来评估，而 $H$ 的结构则通过第二副对角线以下范数 $b = \\sqrt{\\sum_{i \\ge j+2} \\sum_j H_{i,j}^2}$ 来检验。\n\n### 测试案例分析\n\n所提供的测试案例旨在突显这两种方法的不同稳定性。\n\n**情况 1: $A_1 = I + \\varepsilon J$，其中 $\\varepsilon = 10^{-16}, n=25$**\n矩阵 $J$ 是一个幂零Jordan块。$J$ 的幂 $J^m$ 将非零的“1”对角线向右上角推移，当 $m \\ge n$ 时变为零矩阵。对于一个小的 $\\varepsilon$，$A_1^m v_1 = (I + \\varepsilon J)^m v_1 \\approx (I + m \\varepsilon J) v_1$。构成Krylov序列的向量 $v_1, A_1 v_1, A_1^2 v_1, \\dots$ 将很快变得近似共线。这是CGS因灾难性抵消而失败的典型情景。我们预期会出现严重的正交性损失（大的 $o$）和高的Arnoldi残差（大的 $r_A$）。相反，Householder约简通过稳定的正交变换进行操作，应不受影响，成功地将 $A_1$ 高精度地约简为Hessenberg形式。因此，预计CGS-Arnoldi会失败，而Householder会成功。\n\n**情况 2: 对称三对角Toeplitz矩阵, $n=20$**\n这个矩阵 $A_2$ 是一维离散拉普拉斯算子的负矩阵。它是对称且良态的。对于对称矩阵，Arnoldi过程（在精确算术下）会变成Lanczos算法，产生一个对称三对角矩阵 $H$。$A_2$ 的特征值分布良好，这通常会导致一个良态的Krylov基。因此，预计CGS-Arnoldi会表现良好，保持良好的正交性。Householder方法具有普适的稳定性，也将会成功。测试条件为 `True`（CGS失败且Householder成功）将不会被满足。\n\n**情况 3: 对称三对角Toeplitz矩阵, $n=6$**\n这是情况2的一个较小版本。同样的逻辑适用：$A_3$ 是一个良态的对称矩阵，对于它，CGS-Arnoldi是稳定的。两种方法都将成功。测试条件将不会被满足。\n\n现在，实现将开始以计算方式验证这些理论预测。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef classical_gram_schmidt_arnoldi(A, v1_start, k, tau=1e-14):\n    \"\"\"\n    Performs Hessenberg reduction using the classical Gram-Schmidt Arnoldi process.\n    \"\"\"\n    n = A.shape[0]\n    V = np.zeros((n, k), dtype=np.float64)\n    H = np.zeros((k, k), dtype=np.float64)\n    \n    # Normalize the starting vector\n    V[:, 0] = v1_start / np.linalg.norm(v1_start)\n    \n    m = k\n    for j in range(k):\n        w = A @ V[:, j]\n        \n        for i in range(j + 1):\n            H[i, j] = V[:, i].T @ w\n            w = w - H[i, j] * V[:, i]\n            \n        if j + 1  k:\n            norm_w = np.linalg.norm(w)\n            if norm_w  tau:\n                # Breakdown\n                m = j + 1\n                break\n            H[j + 1, j] = norm_w\n            V[:, j + 1] = w / H[j + 1, j]\n\n    if m  k:\n        V = V[:, :m]\n        H = H[:m, :m]\n    \n    # Calculate stability metrics\n    # Orthogonality loss\n    ortho_matrix = V.T @ V - np.eye(m)\n    np.fill_diagonal(ortho_matrix, 0)\n    ortho_loss = np.max(np.abs(ortho_matrix)) if m  1 else 0.0\n\n    # Arnoldi residual ratio\n    norm_A_F = np.linalg.norm(A, 'fro')\n    if norm_A_F == 0:\n        norm_A_F = 1.0 # Avoid division by zero\n    \n    residual_matrix = A @ V - V @ H\n    arnoldi_residual = np.linalg.norm(residual_matrix, 'fro') / norm_A_F\n    \n    return m, ortho_loss, arnoldi_residual\n\ndef householder_hessenberg(A):\n    \"\"\"\n    Performs full Hessenberg reduction using Householder transformations.\n    \"\"\"\n    n = A.shape[0]\n    H = A.copy()\n    Q = np.eye(n, dtype=np.float64)\n\n    for j in range(n - 2):\n        x = H[j + 1:, j].copy()\n        norm_x = np.linalg.norm(x)\n        \n        # Construct Householder vector\n        v = x.copy()\n        # Stable choice for sign\n        v[0] += np.copysign(norm_x, x[0]) if x[0] != 0 else norm_x\n        \n        norm_v = np.linalg.norm(v)\n        if norm_v  1e-15: # No reflection needed if already zero\n            continue\n            \n        u = v / norm_v\n        u = u.reshape(-1, 1)\n\n        # Apply similarity transformation H = P H P\n        # Left multiplication: H_sub = H_sub - 2 * u * (u.T @ H_sub)\n        H_sub = H[j + 1:, j:]\n        H[j + 1:, j:] -= 2 * u @ (u.T @ H_sub)\n        \n        # Right multiplication: H_sub = H_sub - 2 * (H_sub @ u) * u.T\n        H_sub = H[:, j + 1:]\n        H[:, j + 1:] -= 2 * (H_sub @ u) @ u.T\n\n        # Accumulate Q: Q = Q P\n        Q_sub = Q[:, j + 1:]\n        Q[:, j + 1:] -= 2 * (Q_sub @ u) @ u.T\n\n    # Calculate success metrics\n    # Below-second-subdiagonal norm\n    b_norm = 0.0\n    for j in range(n - 2):\n        for i in range(j + 2, n):\n            b_norm += H[i, j]**2\n    b_norm = np.sqrt(b_norm)\n\n    # Reconstruction residual ratio\n    norm_A_F = np.linalg.norm(A, 'fro')\n    if norm_A_F == 0:\n        norm_A_F = 1.0\n    \n    reconstruction_residual = np.linalg.norm(A - Q @ H @ Q.T, 'fro') / norm_A_F\n\n    return b_norm, reconstruction_residual\n\ndef solve():\n    \"\"\"\n    Sets up test cases, runs the analyses, and prints the final result.\n    \"\"\"\n    \n    # Case 1: Ill-conditioned near-identity Jordan perturbation\n    n1 = 25\n    eps1 = 1e-16\n    A1 = np.eye(n1, dtype=np.float64) + eps1 * np.diag(np.ones(n1 - 1), 1)\n    v1_1_unnormalized = np.ones(n1, dtype=np.float64)\n    v1_1 = v1_1_unnormalized / np.linalg.norm(v1_1_unnormalized)\n\n    # Case 2: Well-conditioned symmetric tridiagonal Toeplitz\n    n2 = 20\n    diag2 = 2 * np.ones(n2)\n    off_diag2 = -1 * np.ones(n2 - 1)\n    A2 = np.diag(diag2) + np.diag(off_diag2, 1) + np.diag(off_diag2, -1)\n    v1_2_unnormalized = np.sin(np.arange(1, n2 + 1, dtype=np.float64))\n    v1_2 = v1_2_unnormalized / np.linalg.norm(v1_2_unnormalized)\n\n    # Case 3: Moderately sized well-behaved tridiagonal\n    n3 = 6\n    diag3 = 2 * np.ones(n3)\n    off_diag3 = -1 * np.ones(n3 - 1)\n    A3 = np.diag(diag3) + np.diag(off_diag3, 1) + np.diag(off_diag3, -1)\n    v1_3_unnormalized = np.ones(n3, dtype=np.float64)\n    v1_3 = v1_3_unnormalized / np.linalg.norm(v1_3_unnormalized)\n\n    test_cases = [\n        (A1, v1_1, n1),\n        (A2, v1_2, n2),\n        (A3, v1_3, n3)\n    ]\n\n    results = []\n    for A, v1, n in test_cases:\n        # Run Classical Gram-Schmidt Arnoldi\n        m, o, rA = classical_gram_schmidt_arnoldi(A, v1, k=n)\n        \n        # Check for CGS-Arnoldi failure\n        cgs_failed = (m  n) or (o  1e-3) or (rA  1e-8)\n\n        # Run Householder Hessenberg\n        b, rH = householder_hessenberg(A)\n\n        # Check for Householder success\n        hh_succeeded = (b  1e-12) and (rH  1e-12)\n\n        # Final decision for the case\n        decision = cgs_failed and hh_succeeded\n        results.append(str(decision))\n\n    # Print results in the required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "即便我们已经有了一个数值稳定的算法，总有空间可以进一步提升其鲁棒性。这个练习在前一个实践的基础上，为Householder Hessenberg约化算法引入了一个关键的增强技术：列主元选择。通过在每一步动态选择范数最大的列作为主元，该算法能更好地处理那些列尺度差异悬殊的“病态”矩阵。完成这个练习后，你将掌握如何构建一个更加稳健、适用于更广泛应用场景的Hessenberg约化程序，并理解其$A P = Q H$分解形式的含义。",
            "id": "3238599",
            "problem": "要求您为实方阵设计、实现并验证一个列主元Hessenberg约化算法。其目标是构造一个分解，该分解重组给定矩阵的列，然后从左侧应用正交变换以产生一个上Hessenberg矩阵。此问题的基础必须从以下定义和经过充分检验的事实开始：置换矩阵是正交的，正交矩阵保持欧几里得范数不变，Householder反射是正交的且可以将向量的分量置零，上Hessenberg矩阵在其第一副对角线下方所有元素均为零。\n\n给定一个实方阵 $A \\in \\mathbb{R}^{n \\times n}$，按如下方式将列主元选择引入到左乘Hessenberg约化中。对于从 $0$ 到 $n-2$ 的每个约化步骤 $k$，选择一个主元列索引 $j \\in \\{k, k+1, \\dots, n-1\\}$，使得第 $j$ 列从第 $k+1$ 行到第 $n-1$ 行的尾部欧几里得范数最大化，交换第 $k$ 列和第 $j$ 列，然后构造一个作用于第 $k+1$ 行到第 $n-1$ 行的Householder反射，以消去第 $k$ 列中第 $k+1$ 行下方的元素。将右侧的列交换累积成一个置换矩阵 $P \\in \\mathbb{R}^{n \\times n}$，并将左侧的Householder反射累积成一个正交矩阵 $Q \\in \\mathbb{R}^{n \\times n}$，使得最终关系为 $A P = Q H$，其中 $H \\in \\mathbb{R}^{n \\times n}$ 是上Hessenberg矩阵。通过将其与构造的 $A P = Q H$ 关联，分析分解 $P A = Q H$ 的性质，并描述列主元选择在稳定性和结构中的作用。\n\n您必须实现一个程序，该程序：\n- 对每个输入矩阵 $A$，计算矩阵 $Q$、$H$ 和 $P$，使得 $A P = Q H$，其中 $Q$ 是正交矩阵，$H$ 是上Hessenberg矩阵，并使用以下基于基础事实的步骤：\n  1. 在步骤 $k$，选择主元列索引 $j$ 以最大化 $\\|A_{k+1:n-1,j}\\|_2$。\n  2. 形成交换第 $k$ 列和第 $j$ 列的置换，并通过右乘此置换来更新 $A$ 和 $P$。\n  3. 构造一个Householder向量 $v \\in \\mathbb{R}^{n-k-1}$，将向量 $x = A_{k+1:n-1,k}$ 映射到第一个标准基向量的倍数，并定义作用于第 $k+1$ 行至第 $n-1$ 行子空间上的反射 $L_k = I - 2 v v^\\top$。\n  4. 应用左变换以更新 $A$，并从所有左反射中累积正交因子 $Q$，以使输出满足 $A P = Q H$。\n- 对每个测试矩阵，计算并报告以下三个量：\n  1. Frobenius残差 $r = \\|A P - Q H\\|_F$。\n  2. 正交性误差 $e = \\|Q^\\top Q - I\\|_F$。\n  3. 一个布尔标志 $b$，如果 $H$ 在 $10^{-10}$ 的容差内是上Hessenberg矩阵，即对于所有 $i  j + 1$ 都有 $|H_{i,j}| \\le 10^{-10}$，则为 $\\text{True}$，否则为 $\\text{False}$。\n\n您必须使用以下固定的测试矩阵套件，它们共同涵盖了典型、边界和边缘情况的行为：\n- 测试 $1$ (通用 $5 \\times 5$ 情况):\n  $$A_1 = \\begin{bmatrix}\n  4  1  -2  2  3 \\\\\n  3  6  -1  -3  2 \\\\\n  2  -1  8  1  -4 \\\\\n  1  0  -3  7  5 \\\\\n  5  -2  1  -1  9\n  \\end{bmatrix}.$$\n- 测试 $2$ (单位 $4 \\times 4$ 情况):\n  $$A_2 = I_4.$$\n- 测试 $3$ (列优势秩-$1$ 的 $4 \\times 4$ 情况，以测试主元选择):\n  $$A_3 = \\begin{bmatrix}\n  0  100  0  0 \\\\\n  0  -50  0  0 \\\\\n  0  25  0  0 \\\\\n  0  -12.5  0  0\n  \\end{bmatrix}.$$\n- 测试 $4$ ($1 \\times 1$ 情况):\n  $$A_4 = \\begin{bmatrix} 7 \\end{bmatrix}.$$\n- 测试 $5$ ($2 \\times 2$ 情况):\n  $$A_5 = \\begin{bmatrix} 0  1 \\\\ 2  3 \\end{bmatrix}.$$\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是该测试用例的 $[r, e, b]$ 形式的列表，顺序不变。此问题不涉及物理单位。角度不适用。百分比不适用；所有数值输出必须以标准十进制数形式呈现。程序必须完全自包含，不得读取输入，且只能使用指定的库。",
            "solution": "该问题要求为实方阵 $A \\in \\mathbb{R}^{n \\times n}$ 设计并实现一个列主元Hessenberg约化算法。目标是计算一个正交矩阵 $Q$、一个置换矩阵 $P$ 和一个上Hessenberg矩阵 $H$，使得分解式 $A P = Q H$ 成立。解决方案必须通过计算残差的Frobenius范数 $r = \\|A P - Q H\\|_F$、正交性误差 $e = \\|Q^\\top Q - I\\|_F$ 以及一个指示 $H$ 是否在结构上为上Hessenberg矩阵的布尔标志 $b$ 来进行验证。\n\n指定的算法是对输入矩阵 $A$ 应用的一系列变换。设初始矩阵为 $A^{(0)} = A$。该过程对步骤 $k = 0, 1, \\dots, n-2$ 进行迭代。在每个步骤 $k$，我们修改当前矩阵 $A^{(k)}$，在第 $k$ 列的第一副对角线下方引入零。\n\n**算法分步推导**\n\n设 $H_0 = A$，$Q_0 = I_n$，$P_0 = I_n$。我们将生成一系列矩阵 $H_k, Q_k, P_k$，使得在过程结束时，$H = H_{n-1}$，$Q = Q_{n-1}$，$P = P_{n-1}$。\n\n对于 $k = 0, 1, \\dots, n-2$：\n\n1.  **列主元选择**: 为增强数值稳定性，我们选择一个主元列。步骤 $k$ 的变换将作用于从第 $k$ 列中取出的一个向量。如果此向量具有较大的范数，则稳定性会得到改善。因此，我们检查当前矩阵 $H_k$ 从索引 $k$ 到 $n-1$ 的各列。选择主元列（索引为 $j_{pivot}$），使其满足第 $k$ 行下方的子列向量的欧几里得范数最大化：\n    $$ j_{pivot} = \\underset{j \\in \\{k, k+1, \\dots, n-1\\}}{\\text{argmax}} \\| (H_k)_{k+1:n-1, j} \\|_2 $$\n    设 $\\Pi_k$ 是交换第 $k$ 列和第 $j_{pivot}$ 列的基本置换矩阵。我们通过从右侧应用此置换来更新矩阵 $H_k$：$H_k \\leftarrow H_k \\Pi_k$。总置换矩阵被累积：$P_{k+1} = P_k \\Pi_k$。\n\n2.  **Householder变换**: 选择主元后，新的第 $k$ 列用于构造一个Householder反射。设 $x = (H_k)_{k+1:n-1, k}$ 是待变换的向量。此向量 $x$ 的维度为 $m = n-(k+1)$。Householder反射是一个正交矩阵 $L_k$，它将 $x$ 变换为一个与 $\\mathbb{R}^m$ 中第一个标准基向量 $e_1$ 平行的向量。具体来说，$L_k x = \\sigma e_1$。\n    该反射定义为 $L_k = I_m - \\beta v v^\\top$，其中 $v$ 是Householder向量。为确保稳定性并避免相减抵消，$v$ 的构造如下：\n    $$ v = x + \\text{sign}(x_0) \\|x\\|_2 e_1 $$\n    其中 $x_0$ 是 $x$ 的第一个分量。系数 $\\beta$ 由 $\\beta = 2 / (v^\\top v)$ 给出。如果 $x$ 是零向量，则变换为单位矩阵，此步骤将被跳过。\n\n3.  **应用变换**: 将 $m \\times m$ 的反射 $L_k$ 嵌入一个 $n \\times n$ 的矩阵中，我们记作 $\\mathcal{Q}_k$，方法是将其放置在右下角块中：\n    $$ \\mathcal{Q}_k = \\begin{pmatrix} I_{k+1}  0 \\\\ 0  L_k \\end{pmatrix} $$\n    这个正交变换从左侧应用于当前矩阵 $H_k$。此操作仅影响第 $k+1$ 行到第 $n-1$ 行。关键在于，因为 $H_k$ 的前 $k$ 列已经具有所需的零结构，并且变换 $\\mathcal{Q}_k$ 不会混合第 $0, \\dots, k$ 行与第 $k+1, \\dots, n-1$ 行，所以该结构得以保留。\n    矩阵的更新规则是：$H_{k+1} = \\mathcal{Q}_k H_k$。\n    总的正交矩阵 $Q$ 通过用 $\\mathcal{Q}_k$ 更新 $Q_k$ 来累积。经过 $n-2$ 步后的最终分解将是 $H = (\\mathcal{Q}_{n-2} \\dots \\mathcal{Q}_0) A (\\Pi_0 \\dots \\Pi_{n-2})$。设 $P = \\Pi_0 \\dots \\Pi_{n-2}$ 且 $Q^T = \\mathcal{Q}_{n-2} \\dots \\mathcal{Q}_0$。则 $H = Q^T A P$，可整理为 $A P = Q H$。要从反射矩阵获得 $Q$，我们可以从 $Q=I$ 开始，并在每一步中更新它，即 $Q \\leftarrow Q \\mathcal{Q}_k^T = Q \\mathcal{Q}_k$（因为反射是自对称的）。\n\n**$P A = Q H$ 关系的分析**\n\n问题要求基于构造的分解 $A P = Q H$ 来分析一个假设的分解 $P A = Q H$ 的性质。根据我们的算法，我们有 $A P = Q H$。我们可以利用 $P$ 的正交性（即 $P^{-1} = P^T$）来分离出 $A$：\n$$ A = Q H P^T $$\n将此方程左乘 $P$ 得到矩阵乘积 $P A$ 的表达式：\n$$ P A = P (Q H P^T) = (P Q) H P^T $$\n这里，$P Q$ 是两个正交矩阵的乘积，其本身也是一个正交矩阵。$H$ 是上Hessenberg矩阵，$P^T$ 是正交矩阵。这给出了 $P A$ 分解为三个具有特定结构矩阵的乘积，但它不是 $P A$ 的标准形式 $(U H' U^T)$ 的Hessenberg分解，也不是 $Q H$ 的形式。问题陈述中的这个询问可能是一个小的误述。推导出的关系 $P A = (P Q) H P^T$ 是计算出的 $A P = Q H$ 分解的正确结果。\n\n**列主元选择的作用**\n\n列主元选择在算法的数值稳定性中起着关键作用。Householder向量 $v$ 的构造和反射的应用涉及浮点运算。如果被变换的向量 $x$ 的范数非常小，舍入误差的相对影响可能会变得显著。通过选择使 $\\|x\\|_2 = \\|(H_k)_{k+1:n-1, j}\\|_2$ 最大化的列，我们确保了用于生成反射的向量尽可能大。这最小化了浮点误差对计算出的正交矩阵 $Q$ 和Hessenberg矩阵 $H$ 的影响，从而导致更小的正交性误差 $e = \\|Q^\\top Q - I\\|_F$ 和更小的最终残差 $r = \\|A P - Q H\\|_F$。\n\n实现将遵循这一详细过程，处理提供的测试用例并计算所需的验证指标。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef column_pivoted_hessenberg(A):\n    \"\"\"\n    Computes the column-pivoted Hessenberg decomposition A P = Q H of a real\n    square matrix A.\n\n    Args:\n        A (np.ndarray): The input square matrix.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple (Q, H, P) where\n        Q is orthogonal, H is upper Hessenberg, P is a permutation matrix,\n        and A P = Q H.\n    \"\"\"\n    H = A.copy().astype(np.float64)\n    n = H.shape[0]\n    \n    if n == 0:\n        return np.array([[]]), np.array([[]]), np.array([[]])\n        \n    Q = np.identity(n, dtype=np.float64)\n    P = np.identity(n, dtype=np.float64)\n\n    for k in range(n - 2):\n        # Step 1: Pivot selection\n        # Select column j in {k, ..., n-1} that maximizes the norm of H[k+1:n, j].\n        sub_matrix_for_pivot = H[k + 1:n, k:n]\n        if sub_matrix_for_pivot.size  0:\n            col_norms = np.linalg.norm(sub_matrix_for_pivot, axis=0)\n            j_rel = np.argmax(col_norms)\n            j_pivot = k + j_rel\n        else:\n            # This branch is for robustness, but the loop range n-2 prevents it for n  2.\n            # For n=2, the loop does not run.\n            continue\n            \n        # Step 2: Column swap\n        if j_pivot != k:\n            H[:, [k, j_pivot]] = H[:, [j_pivot, k]]\n            P[:, [k, j_pivot]] = P[:, [j_pivot, k]]\n\n        # Step 3: Householder reflector construction\n        x = H[k + 1:n, k]\n        norm_x = np.linalg.norm(x)\n\n        # Use a tolerance to check if the vector is effectively zero\n        if norm_x  1e-15:\n            # Define sigma to avoid catastrophic cancellation in v's first component\n            sigma = -np.copysign(norm_x, x[0]) if x[0] != 0 else -norm_x\n            \n            # Construct the un-normalized Householder vector v\n            v = x.copy()\n            v[0] -= sigma  # This corresponds to v = x - sigma * e_1\n            \n            v_dot_v = v @ v\n            if v_dot_v  1e-15:\n                # If v is a zero vector, the reflector is the identity.\n                continue\n            \n            beta = 2.0 / v_dot_v\n\n            # Step 4: Apply the transformation\n            # Apply reflector to H: H_new = (I - beta*v*v.T) * H_sub\n            # which is calculated as H_sub - beta * v * (v.T * H_sub)\n            sub_H = H[k + 1:n, k:n]\n            vT_subH = v @ sub_H\n            update_H = np.outer(v, vT_subH)\n            H[k + 1:n, k:n] -= beta * update_H\n\n            # Accumulate reflector in Q: Q_new = Q_old * (I - beta*v*v.T)_embedded\n            # which is Q_old - beta * (Q_old * v_embedded) * v_embedded.T\n            sub_Q = Q[:, k + 1:n]\n            Q_v = sub_Q @ v\n            update_Q = np.outer(Q_v, v)\n            Q[:, k + 1:n] -= beta * update_Q\n\n    return Q, H, P\n\ndef check_hessenberg(H, tol=1e-10):\n    \"\"\"\n    Checks if a matrix is upper Hessenberg within a given tolerance.\n    |H_ij| = tol for all i  j + 1.\n    \"\"\"\n    n = H.shape[0]\n    if n = 2:\n        return True\n    # np.tril(H, k=-2) gives the part of H below the first subdiagonal.\n    return np.all(np.abs(np.tril(H, k=-2)) = tol)\n\ndef solve():\n    \"\"\"\n    Main function to run the algorithm on the test suite and print results.\n    \"\"\"\n    test_cases = [\n        np.array([\n            [4, 1, -2, 2, 3],\n            [3, 6, -1, -3, 2],\n            [2, -1, 8, 1, -4],\n            [1, 0, -3, 7, 5],\n            [5, -2, 1, -1, 9]\n        ]),\n        np.identity(4),\n        np.array([\n            [0, 100, 0, 0],\n            [0, -50, 0, 0],\n            [0, 25, 0, 0],\n            [0, -12.5, 0, 0]\n        ]),\n        np.array([[7]]),\n        np.array([[0, 1], [2, 3]])\n    ]\n\n    results = []\n    for A in test_cases:\n        n = A.shape[0]\n        \n        Q, H, P = column_pivoted_hessenberg(A)\n        \n        if n  0:\n            residual = np.linalg.norm(A @ P - Q @ H, 'fro')\n            orth_error = np.linalg.norm(Q.T @ Q - np.identity(n), 'fro')\n            is_hessenberg = check_hessenberg(H, tol=1e-10)\n        else:\n            residual, orth_error, is_hessenberg = 0.0, 0.0, True\n\n        results.append([residual, orth_error, bool(is_hessenberg)])\n    \n    formatted_results = []\n    for res in results:\n        # Format [r, e, b] as a string, with boolean as True/False\n        formatted_results.append(f\"[{res[0]},{res[1]},{str(res[2])}]\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}