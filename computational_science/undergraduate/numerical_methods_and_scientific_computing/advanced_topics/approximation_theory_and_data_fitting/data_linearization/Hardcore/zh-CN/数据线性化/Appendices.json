{
    "hands_on_practices": [
        {
            "introduction": "从实验数据中估计物理常数是科学研究中的一项常见任务，但物理定律本身通常不是线性的。本练习将探讨如何处理一个基本的非线性关系——波的频率与波长成反比。通过将自变量巧妙地重塑为 $x = 1/\\lambda$，模型 $f = v/\\lambda$ 就转换成了一个简单的线性关系 $f = v \\cdot x$，其斜率正是我们想要估计的波速 $v$。这项练习  为您提供了通过变量变换来应用线性回归进行参数估计的基础实践。",
            "id": "3221525",
            "problem": "给定一组波的波长和频率的带噪声测量值，这些波遵循基本色散关系 $f = v / \\lambda$，其中 $f$ 是频率（单位：赫兹），$\\lambda$ 是波长（单位：米），$v$ 是波速（单位：米/秒）。您的任务是线性化此反比关系，并使用基于原理的数值方法从数据中估计 $v$。\n\n基本原理：使用核心物理模型 $f = v / \\lambda$ 和最小二乘法作为残差平方和最小化的定义。不要使用任何预封装或简化的拟合公式。您的程序必须通过变换变量来计算线性化拟合，使模型在未知数上变为线性，然后通过最小化该线性化空间中的误差平方和来估计未知数。为符合物理现实，约束拟合直线通过原点，这与当 $v$ 为常数且 $f$ 无偏移时，$\\lambda \\to \\infty$ 则 $f = 0$ 的情况相符。\n\n算法任务说明：\n- 将模型线性化为关于 $v$ 的线性形式。\n- 使用普通最小二乘法（定义为最小化残差平方和），在线性化数据的基础上计算估计值 $\\hat{v}$，并满足拟合直线通过原点的约束。\n- 直接根据最小二乘法的定义实现此计算，不要依赖任何库中的拟合函数。\n- 所有估计值必须以米/秒为单位表示，并四舍五入到小数点后恰好六位。\n\n测试套件：\n为以下五个独立数据集中的每一个计算 $\\hat{v}$。每个数据集提供以米为单位的波长值和以赫兹为单位的频率值。数据中存在少量乘性测量噪声，以确保场景的真实性。\n\n- 案例 A（理想路径，中等波长）：\n  - 波长（米）：$[0.5, 0.8, 1.2, 1.5, 2.0]$\n  - 频率（赫兹）：$[689.1456, 427.713, 286.572, 227.656, 171.7716]$\n\n- 案例 B（大波长，低频率）：\n  - 波长（米）：$[2.5, 5.0, 7.5, 10.0, 12.5]$\n  - 频率（赫兹）：$[592.8, 296.9928, 197.4024, 148.6446, 118.32288]$\n\n- 案例 C（极小波长，极高频率）：\n  - 波长（米）：$[4.0\\times 10^{-7}, 5.0\\times 10^{-7}, 6.0\\times 10^{-7}, 7.0\\times 10^{-7}]$\n  - 频率（赫兹）：$[7.5\\times 10^{14}, 5.9994\\times 10^{14}, 5.001\\times 10^{14}, 4.285071428571429\\times 10^{14}]$\n\n- 案例 D（两个点的边界情况）：\n  - 波长（米）：$[3.0, 4.0]$\n  - 频率（赫兹）：$[40.4, 29.85]$\n\n- 案例 E（异常值的影响）：\n  - 波长（米）：$[1.0, 2.0, 3.0, 4.0, 5.0]$\n  - 频率（赫兹）：$[1000.0, 500.0, 366.6666666666667, 250.0, 200.0]$\n\n输出格式：\n- 您的程序必须生成单行输出，其中包含一个 Python 风格的列表，内含五个估计速度值，每个值都以米/秒为单位，并四舍五入到小数点后恰好六位，顺序为案例 A、B、C、D、E。例如，输出必须看起来像 $[a,b,c,d,e]$，其中 a、b、c、d、e 均为小数点后恰好有六位的浮点数。\n\n不应从标准输入读取任何内容。所有常数和数据集均已在上方提供。不涉及角度。所有输出都必须以米/秒为单位，并必须四舍五入到小数点后恰好六位。最终输出必须是符合指定格式的单行列表。",
            "solution": "该问题要求根据波长 $\\lambda$ 和频率 $f$ 的带噪声测量值集合来估计波速 $v$。其控制物理模型是基本色散关系：\n$$\nf = \\frac{v}{\\lambda}\n$$\n这个关系是非线性的，具体来说是 $f$ 和 $\\lambda$ 之间的反比关系。为了应用线性估计方法，我们必须首先将该模型线性化。\n\n让我们定义一组新的变量。设自变量为 $x = 1/\\lambda$，因变量为 $y = f$。将这些代入物理模型可得：\n$$\ny = v \\cdot x\n$$\n这个变换后的方程表示 $y$ 和 $x$ 之间的线性关系。它描述了在 $(x, y)$ 平面上通过原点 $(0, 0)$ 的一条直线。这条线的斜率就是波速 $v$，也就是我们希望估计的参数。拟合直线必须通过原点的约束在物理上是合理的，因为对于有限的波速 $v$，当波长 $\\lambda$ 趋于无穷大时（即 $x = 1/\\lambda$ 趋于 0），频率 $f$ 趋于 0。\n\n任务是使用普通最小二乘法（OLS）原理对通过原点的回归来估计 $v$。给定一组 $N$ 个数据点 $(\\lambda_i, f_i)$，我们首先将它们转换为 $(x_i, y_i) = (1/\\lambda_i, f_i)$。模型预测，对于给定的 $x_i$，相应的 $y$ 值应为 $\\hat{y}_i = v x_i$。观测值 $y_i$ 和预测值 $\\hat{y}_i$ 之间的差异是残差 $r_i$：\n$$\nr_i = y_i - \\hat{y}_i = y_i - v x_i\n$$\nOLS 方法旨在找到参数 $v$ 的值，以最小化这些残差的平方和，记为 $S(v)$：\n$$\nS(v) = \\sum_{i=1}^{N} r_i^2 = \\sum_{i=1}^{N} (y_i - v x_i)^2\n$$\n为了找到最小值，我们计算 $S(v)$ 对 $v$ 的导数并将其设为零。\n$$\n\\frac{dS}{dv} = \\frac{d}{dv} \\sum_{i=1}^{N} (y_i - v x_i)^2\n$$\n根据微分的线性性质，我们可以将导数移到求和号内部：\n$$\n\\frac{dS}{dv} = \\sum_{i=1}^{N} \\frac{d}{dv} (y_i - v x_i)^2\n$$\n使用链式法则，其中内函数是 $g(v) = y_i - v x_i$，外函数是 $h(g) = g^2$：\n$$\n\\frac{d}{dv} (y_i - v x_i)^2 = 2(y_i - v x_i) \\cdot \\frac{d}{dv}(y_i - v x_i) = 2(y_i - v x_i)(-x_i) = -2(y_i x_i - v x_i^2)\n$$\n将此代回 $S(v)$ 的导数表达式中：\n$$\n\\frac{dS}{dv} = \\sum_{i=1}^{N} -2(y_i x_i - v x_i^2) = -2 \\left( \\sum_{i=1}^{N} y_i x_i - v \\sum_{i=1}^{N} x_i^2 \\right)\n$$\n将导数设为零，以找到使 $S(v)$ 最小化的 $v$ 值（我们称之为估计值 $\\hat{v}$）：\n$$\n-2 \\left( \\sum_{i=1}^{N} y_i x_i - \\hat{v} \\sum_{i=1}^{N} x_i^2 \\right) = 0\n$$\n$$\n\\sum_{i=1}^{N} y_i x_i - \\hat{v} \\sum_{i=1}^{N} x_i^2 = 0\n$$\n解出 $\\hat{v}$：\n$$\n\\hat{v} \\sum_{i=1}^{N} x_i^2 = \\sum_{i=1}^{N} x_i y_i\n$$\n$$\n\\hat{v} = \\frac{\\sum_{i=1}^{N} x_i y_i}{\\sum_{i=1}^{N} x_i^2}\n$$\n这是强制通过原点的回归线斜率的 OLS 估计量。注意，二阶导数为 $\\frac{d^2S}{dv^2} = \\sum_{i=1}^{N} 2x_i^2$，只要不是所有的 $x_i$ 都为零，它就是正的，这确保了该临界点确实是一个最小值。\n\n将原始变量 $x_i = 1/\\lambda_i$ 和 $y_i = f_i$ 代回，估计波速的公式变为：\n$$\n\\hat{v} = \\frac{\\sum_{i=1}^{N} (1/\\lambda_i) f_i}{\\sum_{i=1}^{N} (1/\\lambda_i)^2}\n$$\n现在将此公式应用于所提供的五个数据集中的每一个。对于每种情况，使用波长 $\\lambda_i$ 和频率 $f_i$ 来计算分子 $\\sum (f_i/\\lambda_i)$ 和分母 $\\sum (1/\\lambda_i^2)$，以求得估计值 $\\hat{v}$。计算将使用浮点运算执行，最终结果将按要求四舍五入到小数点后六位。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the wave speed v from noisy (wavelength, frequency) data.\n\n    The method involves linearizing the model f = v / lambda to y = v*x,\n    where y = f and x = 1/lambda. The estimate for v is then found by\n    ordinary least squares for a line forced through the origin, which\n    minimizes the sum of squared residuals. The derived formula is:\n    v_hat = sum(x*y) / sum(x*x).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (happy path, moderate wavelengths)\n        (np.array([0.5, 0.8, 1.2, 1.5, 2.0]), \n         np.array([689.1456, 427.713, 286.572, 227.656, 171.7716])),\n        \n        # Case B (large wavelengths, low frequencies)\n        (np.array([2.5, 5.0, 7.5, 10.0, 12.5]), \n         np.array([592.8, 296.9928, 197.4024, 148.6446, 118.32288])),\n        \n        # Case C (very small wavelengths, very high frequencies)\n        (np.array([4.0e-7, 5.0e-7, 6.0e-7, 7.0e-7]), \n         np.array([7.5e14, 5.9994e14, 5.001e14, 4.285071428571429e14])),\n        \n        # Case D (boundary case with two points)\n        (np.array([3.0, 4.0]), \n         np.array([40.4, 29.85])),\n        \n        # Case E (influence of an outlier)\n        (np.array([1.0, 2.0, 3.0, 4.0, 5.0]), \n         np.array([1000.0, 500.0, 366.6666666666667, 250.0, 200.0]))\n    ]\n\n    results = []\n    for wavelengths, frequencies in test_cases:\n        # Transform variables for linearization: x = 1/lambda, y = f\n        x = 1.0 / wavelengths\n        y = frequencies\n\n        # Calculate the terms for the OLS estimator\n        # v_hat = sum(x_i * y_i) / sum(x_i^2)\n        sum_xy = np.sum(x * y)\n        sum_x_squared = np.sum(x**2)\n\n        # Compute the estimated wave speed\n        v_hat = sum_xy / sum_x_squared\n        \n        results.append(v_hat)\n\n    # Format the results to exactly six decimal places\n    formatted_results = [f\"{res:.6f}\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "指数函数是描述许多自然过程的通用模型，例如放射性衰变或本例中的牛顿冷却定律。对数变换是线性化指数关系的一项强大技术，通过对描述温度衰减的方程中的温差取自然对数，我们可以将其转化为一个关于时间的线性方程。这项练习  不仅将演示对数变换的威力，还会强调实际操作中的重要考量，例如必须确保变换定义域的有效性（即不能对非正数取对数）。",
            "id": "3221524",
            "problem": "一杯咖啡在恒定室温的房间里因与环境的热交换而冷却。描述这一过程的唯象定律是牛顿冷却定律，该定律指出，咖啡温度的瞬时变化率与咖啡温度和环境温度之差成正比。在数学上，其控制常微分方程为 $\\,\\dfrac{dT}{dt} = -k\\,(T - T_{\\mathrm{env}})\\,$，其中 $\\,T\\,$ 是咖啡温度，$\\,t\\,$ 是时间，$\\,T_{\\mathrm{env}}\\,$ 是环境温度，$\\,k > 0\\,$ 是衰减常数。您的任务是使用数据线性化方法，根据实验测量数据来估计衰减常数 $\\,k\\,$。\n\n实现一个完整、可运行的程序，该程序：\n- 以控制常微分方程 $\\,\\dfrac{dT}{dt} = -k\\,(T - T_{\\mathrm{env}})\\,$ 作为基本出发点。\n- 推导并应用适合指数衰减的线性化策略，从而将估计 $\\,k\\,$ 的问题简化为使用普通最小二乘法 (OLS) 拟合一条直线。\n- 通过排除任何 $\\,T - T_{\\mathrm{env}} \\le 0\\,$ 的数据点来处理自然对数的定义域限制。\n- 根据线性化数据计算 OLS 斜率，并为每个测试用例返回相应的 $\\,k\\,$ 估计值。\n\n所有时间值必须以分钟为单位，所有温度以摄氏度为单位，$\\,k\\,$ 的最终估计值必须以逆分钟（即 $\\,\\mathrm{min}^{-1}\\,$）表示。此任务不涉及角度或百分比。\n\n使用以下测量的时间-温度数据集测试套件，每个数据集都与一个已知的环境温度配对。每个元组的形式为 $\\,(\\text{时间}, \\text{温度}, T_{\\mathrm{env}})\\,$，其中列表是有序的，时间单位为分钟：\n- 测试用例 $\\,1\\,$ (带有轻微噪声的一般情况)：$\\,([0,2,4,6,8,10,12],\\,[85.0,\\,71.86,\\,61.48,\\,52.86,\\,45.666,\\,41.063,\\,36.724],\\,22.0)\\,$。\n- 测试用例 $\\,2\\,$ (边缘情况，包含一个等于环境温度的读数；排除非正温差)：$\\,([0,5,10,15,20],\\,[90.0,\\,66.52,\\,51.65,\\,41.07,\\,20.0],\\,20.0)\\,$。\n- 测试用例 $\\,3\\,$ (边界情况，具有线性拟合所需的最少可用数据点)：$\\,([0,7],\\,[80.0,\\,52.6],\\,25.0)\\,$。\n- 测试用例 $\\,4\\,$ (后期读数，其中 $\\,T - T_{\\mathrm{env}}\\,$ 很小但为正)：$\\,([0,12,24,36],\\,[70.0,\\,49.145,\\,37.946,\\,31.399],\\,24.0)\\,$。\n\n您的程序应：\n- 对于每个测试用例，根据控制常微分方程构建线性化数据集，并应用普通最小二乘法估计斜率。\n- 将估计的斜率映射到衰减常数 $\\,k\\,$，单位为 $\\,\\mathrm{min}^{-1}\\,$。\n- 在线性化过程中排除任何 $\\,T - T_{\\mathrm{env}} \\le 0\\,$ 的数据点；如果排除后剩余的数据点少于 $\\,2\\,$ 个，则为该测试用例返回一个浮点数 Not-a-Number (NaN)。\n\n最终输出格式规范：\n- 您的程序应生成一行输出，其中包含一个方括号内的逗号分隔列表，例如 $\\,\\,[k_1,k_2,k_3,k_4]\\,$，其中每个 $\\,k_i\\,$ 是从相应测试用例计算出的浮点估计值，单位为 $\\,\\mathrm{min}^{-1}\\,$。\n\n覆盖率设计：\n- 测试用例 $\\,1\\,$ 验证了具有多个数据点和轻微测量噪声的常规“理想路径”。\n- 测试用例 $\\,2\\,$ 通过包含一个等于环境温度的值来检查是否正确排除了无效的对数输入。\n- 测试用例 $\\,3\\,$ 确保在恰好有两个可用点（这是线性拟合的最低要求）时行为正确。\n- 测试用例 $\\,4\\,$ 探测在温差较小但仍为正的后期读数下的稳定性。\n\n确保程序是自包含的，按指定格式生成输出，并且不需要用户输入。所有计算出的 $\\,k\\,$ 值必须以 $\\,\\mathrm{min}^{-1}\\,$ 表示。",
            "solution": "该问题要求使用实验数据估计牛顿冷却定律中的衰减常数 $k$。指定的方法是数据线性化，然后进行普通最小二乘法 (OLS) 回归。解决方案的开发过程是首先推导理论模型，然后形式化数据线性化过程，最后设计一个算法来计算 $k$ 的估计值。\n\n**1. 理论模型与线性化**\n\n物理过程由牛顿冷却定律的一阶常微分方程 (ODE) 描述：\n$$\n\\frac{dT}{dt} = -k(T - T_{\\mathrm{env}})\n$$\n其中 $T(t)$ 是物体在时间 $t$ 的温度，$T_{\\mathrm{env}}$ 是恒定的环境温度，$k > 0$ 是待确定的衰减常数。\n\n为了线性化此模型，我们首先求解该 ODE。令 $\\Delta T(t) = T(t) - T_{\\mathrm{env}}$。由于 $T_{\\mathrm{env}}$ 是常数，因此 $\\frac{d(\\Delta T)}{dt} = \\frac{dT}{dt}$。该 ODE 可以重写为：\n$$\n\\frac{d(\\Delta T)}{dt} = -k(\\Delta T)\n$$\n这是一个可分离微分方程。我们可以分离变量并积分：\n$$\n\\int \\frac{d(\\Delta T)}{\\Delta T} = \\int -k \\, dt\n$$\n$$\n\\ln|\\Delta T| = -kt + C_1\n$$\n其中 $C_1$ 是积分常数。由于物体正在冷却，$T(t) \\ge T_{\\mathrm{env}}$，所以 $\\Delta T \\ge 0$。我们可以去掉绝对值，并注意对数仅在 $\\Delta T > 0$ 时有定义。对两边取指数可得：\n$$\n\\Delta T = e^{-kt + C_1} = e^{C_1}e^{-kt}\n$$\n令常数 $A = e^{C_1}$。解为 $\\Delta T(t) = A e^{-kt}$。如果我们考虑初始条件 $T(0) = T_0$，则 $\\Delta T(0) = T_0 - T_{\\mathrm{env}} = A e^0 = A$。因此，特解为：\n$$\nT(t) - T_{\\mathrm{env}} = (T_0 - T_{\\mathrm{env}}) e^{-kt}\n$$\n为了线性化此指数关系，我们对两边取自然对数。此步骤仅对 $T(t) > T_{\\mathrm{env}}$ 或 $T(t) - T_{\\mathrm{env}} > 0$ 的数据点有效。\n$$\n\\ln(T(t) - T_{\\mathrm{env}}) = \\ln\\left((T_0 - T_{\\mathrm{env}}) e^{-kt}\\right)\n$$\n利用对数性质 $\\ln(ab) = \\ln(a) + \\ln(b)$ 和 $\\ln(e^x) = x$，我们得到：\n$$\n\\ln(T(t) - T_{\\mathrm{env}}) = \\ln(T_0 - T_{\\mathrm{env}}) - kt\n$$\n此方程现在是直线形式 $Y = mX + c$：\n- 令因变量为 $Y = \\ln(T - T_{\\mathrm{env}})$。\n- 令自变量为 $X = t$。\n- 直线的斜率为 $m = -k$。\n- y轴截距为 $c = \\ln(T_0 - T_{\\mathrm{env}})$。\n\n关键的见解是，衰减常数 $k$ 可以通过对变换后数据的线性拟合的斜率来估计：$k = -m$。\n\n**2. 参数估计算法设计**\n\n给定一组 $N$ 个实验数据点 $(t_i, T_i)$ 和一个已知的 $T_{\\mathrm{env}}$，我们可以按照以下步骤估计 $k$：\n\n**步骤 2.1：数据转换和筛选**\n首先，我们将原始数据转换为线性化坐标系 $(X_i, Y_i)$。\n1.  对于每个测量对 $(t_i, T_i)$，计算温差 $\\Delta T_i = T_i - T_{\\mathrm{env}}$。\n2.  问题要求处理自然对数的定义域。我们必须筛选数据集，只包括 $\\Delta T_i > 0$ 的点。任何 $\\Delta T_i \\le 0$ 的点都将被丢弃。\n3.  线性拟合至少需要两个点。如果在筛选后，剩余的数据点少于两个，则无法估计斜率。在这种情况下，对于给定的数据集，该问题是不适定的，结果应为 Not-a-Number (NaN)。\n4.  对于剩余的有效点，构建线性化数据集：\n    $$\n    X_i = t_i\n    $$\n    $$\n    Y_i = \\ln(\\Delta T_i) = \\ln(T_i - T_{\\mathrm{env}})\n    $$\n\n**步骤 2.2：普通最小二乘法 (OLS) 回归**\n我们对筛选和变换后的数据点 $(X_i, Y_i)$ 应用 OLS 来找到最佳拟合直线的斜率 $m$。最小化残差平方和的 OLS 斜率公式为：\n$$\nm = \\frac{\\sum_{i=1}^{N'} (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{N'} (X_i - \\bar{X})^2}\n$$\n其中 $N'$ 是筛选后的有效数据点数量，$\\bar{X}$ 和 $\\bar{Y}$ 分别是 $X_i$ 和 $Y_i$ 值的样本均值。\n\n**步骤 2.3：参数恢复**\n最后，我们从估计的斜率 $m$ 中恢复衰减常数 $k$ 的估计值：\n$$\nk = -m\n$$\n由于温度 $T$ 随时间降低，变换后的变量 $Y = \\ln(T - T_{\\mathrm{env}})$ 也会随时间 $X=t$ 减小。因此，斜率 $m$ 将为负，确保估计的 $k = -m$ 为正，这与其作为衰减常数的物理定义一致。\n\n这套完整的流程提供了一种基于系统基础物理学和标准数值技术的稳健方法，用于从实验数据中估计 $k$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_k_from_data(times, temperatures, T_env):\n    \"\"\"\n    Estimates the decay constant k from time-temperature data using linearization.\n\n    The function linearizes the solution to Newton's law of cooling,\n    T(t) - T_env = (T0 - T_env) * exp(-k*t), by taking the natural log:\n    ln(T - T_env) = -k*t + ln(T0 - T_env).\n    This is a linear equation y = m*x + c, where y = ln(T - T_env), \n    x = t, and the slope m = -k.\n\n    Args:\n        times (list or np.ndarray): A list of time points in minutes.\n        temperatures (list or np.ndarray): A list of temperature readings in Celsius.\n        T_env (float): The constant ambient temperature in Celsius.\n\n    Returns:\n        float: The estimated decay constant k in min^-1, or np.nan if a fit is not possible.\n    \"\"\"\n    # Convert inputs to numpy arrays for vectorized operations\n    times = np.array(times, dtype=float)\n    temperatures = np.array(temperatures, dtype=float)\n\n    # Calculate the temperature difference\n    delta_T = temperatures - T_env\n\n    # Filter out data points where delta_T is not positive, as ln(x) is defined for x > 0.\n    # The problem specifies T - T_env = 0 should be excluded.\n    valid_indices = np.where(delta_T > 0)\n    \n    filtered_times = times[valid_indices]\n    filtered_delta_T = delta_T[valid_indices]\n\n    # A line fit requires at least 2 points.\n    if len(filtered_times)  2:\n        return np.nan\n\n    # Create the variables for the linear regression\n    # X = t\n    # Y = ln(T - T_env)\n    x_data = filtered_times\n    y_data = np.log(filtered_delta_T)\n\n    # Perform Ordinary Least Squares (OLS) to find the slope m.\n    # m = Cov(x, y) / Var(x)\n    # Using the direct summation formula for clarity:\n    # m = sum((x - x_bar)(y - y_bar)) / sum((x - x_bar)^2)\n    x_mean = np.mean(x_data)\n    y_mean = np.mean(y_data)\n    \n    numerator = np.sum((x_data - x_mean) * (y_data - y_mean))\n    denominator = np.sum((x_data - x_mean)**2)\n\n    # Avoid division by zero, although not expected if len(x_data) = 2 and times are not identical\n    if denominator == 0:\n        return np.nan\n\n    slope_m = numerator / denominator\n\n    # The decay constant k is the negative of the slope\n    k = -slope_m\n    \n    return k\n\ndef solve():\n    \"\"\"\n    Runs the estimation for all test cases and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple: (times, temperatures, T_env)\n    test_cases = [\n        # Test case 1 (general case with mild noise)\n        ([0, 2, 4, 6, 8, 10, 12], [85.0, 71.86, 61.48, 52.86, 45.666, 41.063, 36.724], 22.0),\n        # Test case 2 (edge case with T = T_env)\n        ([0, 5, 10, 15, 20], [90.0, 66.52, 51.65, 41.07, 20.0], 20.0),\n        # Test case 3 (boundary case with minimum points)\n        ([0, 7], [80.0, 52.6], 25.0),\n        # Test case 4 (late-time readings with small but positive delta_T)\n        ([0, 12, 24, 36], [70.0, 49.145, 37.946, 31.399], 24.0)\n    ]\n\n    results = []\n    for case in test_cases:\n        times, temperatures, T_env = case\n        k_estimate = estimate_k_from_data(times, temperatures, T_env)\n        results.append(k_estimate)\n\n    # Format output as a comma-separated list in brackets\n    # Use a custom formatter to handle floating point representation\n    formatted_results = [f'{r:.7f}' if np.isfinite(r) else 'nan' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然数据线性化是一种强大的工具，但它的应用并非总是直接了当的。这项进阶练习旨在培养您的批判性思维，探讨一个核心问题：线性化变换不仅作用于数据变量，也改变了潜在的误差结构。通过比较直接拟合与对数线性化拟合在处理带有加性噪声的模型时的表现 ，您将发现，如果所选的变换与实验误差的性质不符，一个看似正确的线性化方法反而可能导致估计结果出现偏差。",
            "id": "3221622",
            "problem": "给定一个由方程 $y = a x^3 + \\epsilon$ 定义的合成数据生成过程，其中 $a$ 是一个正标量参数，$x$ 是一个正输入，$\\epsilon$ 是加性噪声，每个样本独立地从均值为 $0$、方差为 $\\sigma^2$ 的正态分布中抽取。目标是使用两种不同的方法来估计参数 $a$：一种是遵循原始模型的直接拟合，另一种是基于对数变换的线性化拟合。请从第一性原理出发，使用最小二乘准则为这两种方法设计估计量，并比较它们在估计 $a$ 时的准确性。\n\n基本原理：\n- 数据由模型 $y_i = a x_i^3 + \\epsilon_i$ 生成，其中 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 独立同分布。\n- 估计是基于在每种建模方法下最小化残差平方和（普通最小二乘法 (OLS)）。\n\n方法1（直接三次拟合）：\n- 将回归视为 $y_i = b z_i + \\eta_i$，其中 $z_i = x_i^3$，并强制截距为 $0$。使用 OLS 通过最小化关于 $b$ 的 $\\sum_i (y_i - b z_i)^2$ 来获得估计量 $\\hat{a}_{\\text{direct}}$。\n\n方法2（对数线性化）：\n- 使用自然对数变换数据，即 $u_i = \\log(x_i)$ 和 $v_i = \\log(y_i)$，并使用带有自由截距的 OLS 拟合线性模型 $v_i = \\beta_0 + \\beta_1 u_i + \\xi_i$。然后 $a$ 的估计值为 $\\hat{a}_{\\log} = \\exp(\\hat{\\beta}_0)$。\n- 由于 $\\log(y_i)$ 仅在 $y_i  0$ 时有定义，因此在对数线性化拟合中需丢棄任何 $y_i \\le 0$ 的样本。丢棄样本的操作仅适用于对数线性化方法；直接拟合方法必须使用所有生成的样本。\n- 使用自然对数 $\\log(\\cdot)$。\n\n平局打破规则：\n- 将每种方法的绝对估计误差定义为 $e_{\\text{direct}} = |\\hat{a}_{\\text{direct}} - a|$ 和 $e_{\\log} = |\\hat{a}_{\\log} - a|$。\n- 对于一个测试用例，当且仅当 $e_{\\log}  e_{\\text{direct}}$ 时，判定对数线性化方法“更好”。如果 $e_{\\log} = e_{\\text{direct}}$ 或 $e_{\\log}  e_{\\text{direct}}$，则判定其为“更差”。\n\n测试套件的数据生成细节：\n- 对于每个测试用例，从 $[x_{\\min}, x_{\\max}]$ 上均匀抽取 $n$ 个独立样本 $x_i$，独立地从 $\\mathcal{N}(0,\\sigma^2)$ 中抽取 $\\epsilon_i$，并计算 $y_i = a x_i^3 + \\epsilon_i$。\n- 使用指定的伪随机数生成器种子以使结果可复现。\n- 根据构造，所有 $x_i$ 均为严格正数。\n\n测试套件（每个元组为 $(a,\\sigma,n,x_{\\min},x_{\\max},\\text{seed})$）：\n- 用例 1：$(2.0, 0.1, 100, 1.0, 5.0, 1)$\n- 用例 2：$(0.2, 0.5, 100, 0.1, 5.0, 2)$\n- 用例 3：$(5.0, 5.0, 100, 1.0, 2.0, 42)$\n- 用例 4（边界情况，无噪声）：$(3.0, 0.0, 50, 0.5, 3.0, 3)$\n- 用例 5（边缘情况，大量小 $x$ 和大噪声）：$(0.1, 1.0, 100, 0.01, 1.0, 4)$\n\n程序所需行为：\n- 精确地实现所描述的两种估计量。\n- 对于直接拟合，对 $z_i = x_i^3$ 使用零截距的 OLS 计算 $\\hat{a}_{\\text{direct}}$。\n- 对于对数线性化拟合，在 $y_i  0$ 的过滤后样本集上，使用带有自由截距的 OLS 计算 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$，并设置 $\\hat{a}_{\\log} = \\exp(\\hat{\\beta}_0)$。如果过滤后剩余的样本少于 $2$ 个（这将导致 OLS 估计不适定），则将 $e_{\\log}$ 设置为一个被认为大于 $e_{\\text{direct}}$ 的值，从而将对数线性化方法视为“更差”。\n- 对于每个测试用例，根据严格不等式 $e_{\\log}  e_{\\text{direct}}$ 输出一个布尔值，指示对数线性化方法是否更好。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试套件用例的顺序排列结果，例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]$，其中每个 $\\text{result}_k$ 是一个布尔值。",
            "solution": "我们从最小二乘原理出发，该原理指出对于线性模型，普通最小二乘法（OLS）估计量能最小化残差平方和。在线性关系下，该原理能导出闭式估计量。我们分别将其应用于直接三次拟合和对数线性化拟合。\n\n直接三次拟合推导：\n考虑回归模型 $y_i = b z_i + \\eta_i$，其中 $z_i = x_i^3$ 且截距固定为 $0$。OLS 估计量 $\\hat{b}$ 最小化\n$$\nS(b) = \\sum_{i=1}^n (y_i - b z_i)^2.\n$$\n对 $b$ 求导并令导数等于零，可得\n$$\n\\frac{dS}{db} = -2 \\sum_{i=1}^n z_i (y_i - b z_i) = 0 \\quad \\Rightarrow \\quad \\sum_{i=1}^n z_i y_i = b \\sum_{i=1}^n z_i^2,\n$$\n从而得到\n$$\n\\hat{b} = \\frac{\\sum_{i=1}^n z_i y_i}{\\sum_{i=1}^n z_i^2}.\n$$\n由于模型是 $y_i = a x_i^3 + \\epsilon_i$，且 $z_i = x_i^3$，我们关注的参数是 $a$。因此，从此直接拟合得到的估计量为\n$$\n\\hat{a}_{\\text{direct}} = \\frac{\\sum_{i=1}^n x_i^3 y_i}{\\sum_{i=1}^n x_i^6}.\n$$\n这是在正确的加性噪声模型和零截距条件下的 OLS 解。\n\n对数线性化推导：\n定义 $u_i = \\log(x_i)$ 和 $v_i = \\log(y_i)$。在变换下（对于 $y_i  0$），\n$$\nv_i = \\log(a x_i^3 + \\epsilon_i) \\approx \\log(a x_i^3) + \\text{transformed noise},\n$$\n如果变换后的关系是严格线性的，我们会有\n$$\nv_i = \\beta_0 + \\beta_1 u_i + \\xi_i, \\quad \\text{其中} \\quad \\beta_0 = \\log(a), \\quad \\beta_1 = 3.\n$$\n我们使用带截距的 OLS 来拟合线性模型 $v_i = \\beta_0 + \\beta_1 u_i + \\xi_i$。OLS 正规方程组给出\n$$\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^m (u_i - \\bar{u})(v_i - \\bar{v})}{\\sum_{i=1}^m (u_i - \\bar{u})^2}, \\quad \\hat{\\beta}_0 = \\bar{v} - \\hat{\\beta}_1 \\bar{u},\n$$\n其中 $m$ 是 $y_i  0$ 的保留样本数，$\\bar{u} = \\frac{1}{m}\\sum_{i=1}^m u_i$，且 $\\bar{v} = \\frac{1}{m}\\sum_{i=1}^m v_i$。从对数线性化得到的 $a$ 的估计值为\n$$\n\\hat{a}_{\\log} = \\exp(\\hat{\\beta}_0).\n$$\n\n加性噪声和对数变换下的偏差：\n当原始噪声是加性时，对数变换引入了噪声的非线性变换。对数函数在 $a x_i^3$ 附近的二阶泰勒展开，对于 $y_i = a x_i^3 + \\epsilon_i$ 和较小的 $\\epsilon_i$，给出\n$$\n\\log(y_i) = \\log(a x_i^3 + \\epsilon_i) \\approx \\log(a x_i^3) + \\frac{\\epsilon_i}{a x_i^3} - \\frac{\\epsilon_i^2}{2 (a x_i^3)^2} + \\cdots.\n$$\n取期望，利用 $\\mathbb{E}[\\epsilon_i] = 0$ 和 $\\mathbb{E}[\\epsilon_i^2] = \\sigma^2$，我们得到\n$$\n\\mathbb{E}[\\log(y_i)] \\approx \\log(a x_i^3) - \\frac{\\sigma^2}{2 (a x_i^3)^2}.\n$$\n这表明存在一个负偏差，该偏差在 $x_i$ 较小和 $\\sigma$ 较大时更强。因此，在加性噪声下，对数线性化方法通常是模型设定错误的，并且可能是有偏的，特别是当 $a x_i^3$相对于$\\sigma$较小时。相反，直接三次拟合与真实的加性噪声结构一致，并且在经典假设下，能产生 $a$ 的无偏 OLS 估计量。\n\n算法设计：\n- 对于每个测试用例，使用给定的种子生成 $n$ 个样本 $x_i \\sim \\text{Uniform}(x_{\\min}, x_{\\max})$ 和 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。计算 $y_i = a x_i^3 + \\epsilon_i$。\n- 使用所有样本，通过公式 $\\hat{a}_{\\text{direct}} = \\frac{\\sum x_i^3 y_i}{\\sum x_i^6}$ 计算 $\\hat{a}_{\\text{direct}}$。\n- 对于对数线性化方法，筛选出 $y_i  0$ 的索引，并计算 $u_i = \\log(x_i)$ 和 $v_i = \\log(y_i)$。如果剩余样本少于 2 个，则将此用例的对数线性化方法标记为“更差”。否则，通过带截距的 OLS 计算 $\\hat{\\beta}_1$ 和 $\\hat{\\beta}_0$，并设置 $\\hat{a}_{\\log} = \\exp(\\hat{\\beta}_0)$。\n- 计算绝对误差 $e_{\\text{direct}} = |\\hat{a}_{\\text{direct}} - a|$ 和 $e_{\\log} = |\\hat{a}_{\\log} - a|$。\n- 为每个测试用例输出一个布尔值，指示 $e_{\\log}  e_{\\text{direct}}$ 是否成立。\n\n所提供套件中的边界情况：\n- 用例 4 中 $\\sigma = 0$，这在对数尺度上产生完美的线性关系，在原始尺度上也正确对齐。在理想算术中，两种方法都应该能精确恢复 $a$，因此比较使用严格不等式，除非数值舍入导致严格更小的误差，否则不会将对数线性化方法标记为“更好”。\n- $a$ 值小而 $\\sigma$ 值大的用例可能会为某些样本产生 $y_i \\le 0$，导致对数线性化拟合丢弃数据并可能降低估计性能。这一点得到了明确处理。\n\n最终程序实现了这一逻辑，并按指定格式生成单行输出：一个包含五个布尔值的列表，对应五个测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_a_direct(x, y):\n    \"\"\"\n    Estimate 'a' in y = a*x^3 + epsilon via OLS through the origin:\n    a_hat = sum(x^3 * y) / sum(x^6)\n    \"\"\"\n    z = x**3\n    denom = np.dot(z, z)\n    if denom == 0.0:\n        return np.nan\n    a_hat = np.dot(z, y) / denom\n    return a_hat\n\ndef estimate_a_log(x, y):\n    \"\"\"\n    Estimate 'a' via log-linearization:\n    Fit log(y) = beta0 + beta1 * log(x) on samples with y0\n    Return a_hat = exp(beta0).\n    If fewer than 2 samples remain or degenerate variance, return np.nan.\n    \"\"\"\n    mask = (y > 0)  (x > 0)\n    if np.count_nonzero(mask)  2:\n        return np.nan\n    u = np.log(x[mask])\n    v = np.log(y[mask])\n    u_mean = u.mean()\n    v_mean = v.mean()\n    du = u - u_mean\n    dv = v - v_mean\n    denom = np.sum(du**2)\n    if denom == 0.0:\n        return np.nan\n    beta1 = np.sum(du * dv) / denom\n    beta0 = v_mean - beta1 * u_mean\n    a_hat = np.exp(beta0)\n    return a_hat\n\ndef run_case(a, sigma, n, xmin, xmax, seed):\n    rng = np.random.default_rng(seed)\n    x = rng.uniform(xmin, xmax, size=n)\n    eps = rng.normal(loc=0.0, scale=sigma, size=n)\n    y = a * x**3 + eps\n\n    a_hat_direct = estimate_a_direct(x, y)\n    a_hat_log = estimate_a_log(x, y)\n\n    err_direct = abs(a_hat_direct - a) if np.isfinite(a_hat_direct) else float('inf')\n    err_log = abs(a_hat_log - a) if np.isfinite(a_hat_log) else float('inf')\n\n    return err_log  err_direct\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (a, sigma, n, xmin, xmax, seed)\n    test_cases = [\n        (2.0, 0.1, 100, 1.0, 5.0, 1),\n        (0.2, 0.5, 100, 0.1, 5.0, 2),\n        (5.0, 5.0, 100, 1.0, 2.0, 42),\n        (3.0, 0.0, 50, 0.5, 3.0, 3),\n        (0.1, 1.0, 100, 0.01, 1.0, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        a, sigma, n, xmin, xmax, seed = case\n        better = run_case(a, sigma, n, xmin, xmax, seed)\n        results.append(str(better))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}