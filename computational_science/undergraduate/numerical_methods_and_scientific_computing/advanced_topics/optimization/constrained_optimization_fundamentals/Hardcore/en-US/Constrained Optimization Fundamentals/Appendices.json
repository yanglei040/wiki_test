{
    "hands_on_practices": [
        {
            "introduction": "The Karush-Kuhn-Tucker (KKT) conditions are the fundamental language of constrained optimization, defining the necessary properties of any optimal solution. This exercise challenges you to apply these conditions to a classic problem: projecting a point onto the probability simplex, a task central to fields like machine learning and statistics. Working through the derivation will reveal how the KKT conditions elegantly expose the underlying structure of the solution, reducing a complex problem to a simple thresholding operation.",
            "id": "3217521",
            "problem": "Consider the Euclidean projection of a vector $v \\in \\mathbb{R}^{n}$ onto the probability simplex, defined as the set $\\Delta^{n} = \\{ x \\in \\mathbb{R}^{n} : x_{i} \\ge 0 \\text{ for all } i, \\ \\sum_{i=1}^{n} x_{i} = 1 \\}$. The projection is the solution of the optimization problem\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2} \\| x - v \\|^{2} \\quad \\text{subject to} \\quad x_{i} \\ge 0 \\ \\text{for all } i, \\ \\sum_{i=1}^{n} x_{i} = 1.\n$$\nStarting from first principles of convex optimization, use the Karush–Kuhn–Tucker (KKT) conditions to derive the necessary and sufficient optimality conditions for this problem. In particular, introduce a single Lagrange multiplier for the equality constraint and appropriate multipliers for the nonnegativity constraints, and then eliminate the inequality multipliers using complementary slackness to obtain an explicit structural form of the optimizer in terms of $v$ and a scalar threshold. \n\nThen, apply your derivation to the specific case $n = 6$ with \n$$\nv = \\begin{pmatrix} 1.2 \\\\ 0.9 \\\\ 0.7 \\\\ 0.4 \\\\ 0.05 \\\\ -0.2 \\end{pmatrix}.\n$$\nCompute the value of the equality-constraint multiplier (the scalar threshold) that enforces the simplex constraint in your explicit form. Provide the exact value. Your final answer must be a single real number.",
            "solution": "We begin from the foundational principles of convex optimization. The objective function $f(x) = \\frac{1}{2} \\| x - v \\|^{2}$ is strictly convex because its Hessian is the identity matrix, which is positive definite. The constraints $x_{i} \\ge 0$ for all $i$ and $\\sum_{i=1}^{n} x_{i} = 1$ are affine, hence convex. Therefore, the problem is a convex optimization problem with a strictly convex objective and affine constraints, and the Karush–Kuhn–Tucker (KKT) conditions are necessary and sufficient for optimality.\n\nForm the Lagrangian with a single multiplier $\\nu \\in \\mathbb{R}$ for the equality constraint and multipliers $\\lambda_{i} \\ge 0$ for the nonnegativity constraints:\n$$\n\\mathcal{L}(x,\\nu,\\lambda) = \\frac{1}{2} \\sum_{i=1}^{n} (x_{i} - v_{i})^{2} + \\nu \\left( \\sum_{i=1}^{n} x_{i} - 1 \\right) - \\sum_{i=1}^{n} \\lambda_{i} x_{i}.\n$$\nThe KKT conditions are:\n- Primal feasibility: $x_{i} \\ge 0$ for all $i$, and $\\sum_{i=1}^{n} x_{i} = 1$.\n- Dual feasibility: $\\lambda_{i} \\ge 0$ for all $i$.\n- Complementary slackness: $\\lambda_{i} x_{i} = 0$ for all $i$.\n- Stationarity: $\\nabla_{x} \\mathcal{L} = 0$, which componentwise yields\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial x_{i}} = x_{i} - v_{i} + \\nu - \\lambda_{i} = 0 \\quad \\Longrightarrow \\quad x_{i} = v_{i} - \\nu + \\lambda_{i}.\n$$\n\nUse complementary slackness to eliminate $\\lambda_{i}$. There are two cases for each index $i$:\n- If $x_{i}  0$, then complementary slackness implies $\\lambda_{i} = 0$, hence $x_{i} = v_{i} - \\nu$ and thus $v_{i}  \\nu$.\n- If $x_{i} = 0$, then the stationarity condition gives $\\lambda_{i} = \\nu - v_{i}$, and dual feasibility implies $\\nu - v_{i} \\ge 0$, hence $v_{i} \\le \\nu$.\n\nCombining these, the optimizer has the explicit form\n$$\nx_{i}^{\\star} = \\max(v_{i} - \\nu, 0).\n$$\nLet $\\tau := \\nu$ denote the scalar threshold. Enforcing the equality constraint $\\sum_{i=1}^{n} x_{i}^{\\star} = 1$ yields the scalar equation\n$$\n\\sum_{i=1}^{n} \\max(v_{i} - \\tau, 0) = 1.\n$$\nEquivalently, if $A = \\{ i : v_{i}  \\tau \\}$ is the active set of indices with $x_{i}^{\\star}  0$, then\n$$\n\\sum_{i \\in A} (v_{i} - \\tau) = 1 \\quad \\Longrightarrow \\quad \\tau = \\frac{\\sum_{i \\in A} v_{i} - 1}{|A|},\n$$\nwith the consistency conditions $v_{i}  \\tau$ for $i \\in A$ and $v_{j} \\le \\tau$ for $j \\notin A$.\n\nWe now apply this to the given instance with $n = 6$ and\n$$\nv = \\begin{pmatrix} 1.2 \\\\ 0.9 \\\\ 0.7 \\\\ 0.4 \\\\ 0.05 \\\\ -0.2 \\end{pmatrix}.\n$$\nSort the entries of $v$ in nonincreasing order to test possible active set sizes $k \\in \\{1,2,\\dots,6\\}$:\n$$\nv_{(1)} = 1.2, \\quad v_{(2)} = 0.9, \\quad v_{(3)} = 0.7, \\quad v_{(4)} = 0.4, \\quad v_{(5)} = 0.05, \\quad v_{(6)} = -0.2.\n$$\nFor each $k$, define\n$$\n\\tau_{k} = \\frac{\\sum_{i=1}^{k} v_{(i)} - 1}{k},\n$$\nand check the consistency condition $v_{(k)}  \\tau_{k} \\ge v_{(k+1)}$ (with the convention $v_{(7)} = -\\infty$).\n\nCompute candidates:\n- For $k = 1$: $\\tau_{1} = \\frac{1.2 - 1}{1} = 0.2$. Check $v_{(1)}  \\tau_{1}$ is $1.2  0.2$ (true), but $\\tau_{1} \\ge v_{(2)}$ requires $0.2 \\ge 0.9$ (false). So $k = 1$ is invalid.\n- For $k = 2$: $\\tau_{2} = \\frac{1.2 + 0.9 - 1}{2} = \\frac{1.1}{2} = 0.55$. Check $v_{(2)}  \\tau_{2}$ is $0.9  0.55$ (true), but $\\tau_{2} \\ge v_{(3)}$ requires $0.55 \\ge 0.7$ (false). So $k = 2$ is invalid.\n- For $k = 3$: $\\tau_{3} = \\frac{1.2 + 0.9 + 0.7 - 1}{3} = \\frac{2.8 - 1}{3} = \\frac{1.8}{3} = 0.6$. Check $v_{(3)}  \\tau_{3}$ is $0.7  0.6$ (true), and $\\tau_{3} \\ge v_{(4)}$ is $0.6 \\ge 0.4$ (true). Thus $k = 3$ is consistent.\n\nTherefore, the equality-constraint multiplier (threshold) is $\\tau = \\tau_{3} = 0.6$. This uniquely determines the projection via $x_{i}^{\\star} = \\max(v_{i} - 0.6, 0)$, and the sum of the positive parts is indeed $1$:\n$$\n(1.2 - 0.6) + (0.9 - 0.6) + (0.7 - 0.6) = 0.6 + 0.3 + 0.1 = 1.\n$$\nHence, the required scalar threshold is exactly $0.6$.",
            "answer": "$$\\boxed{0.6}$$"
        },
        {
            "introduction": "While KKT conditions define what an optimal point looks like, algorithms provide the roadmap to get there. This exercise zooms in on a critical decision point within the active-set method for quadratic programming. By calculating the Lagrange multipliers for the current working set, you will see how these values are not just theoretical checks, but practical guides that tell the algorithm when to relax a constraint to find a better solution.",
            "id": "3217327",
            "problem": "Consider the convex quadratic program\nminimize over $x \\in \\mathbb{R}^2$: $f(x) = \\dfrac{1}{2} x^\\top x$\nsubject to three linear inequality constraints:\n$1)$ $x_1 \\ge 0$,\n$2)$ $x_2 \\ge 0$,\n$3)$ $x_1 + x_2 \\ge 1$.\nAssume an active-set method for quadratic programming is applied. The initial feasible point is $x^{(0)} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$. The initial working set is chosen as $\\mathcal{W}^{(0)} = \\{1, 3\\}$, that is, the constraints $x_1 \\ge 0$ and $x_1 + x_2 \\ge 1$ are enforced as equalities at $x^{(0)}$.\n\nUsing only fundamental definitions for convex quadratic programming and the Karush–Kuhn–Tucker (KKT) conditions, determine the correct next action of a classical feasible active-set iteration starting from $x^{(0)}$ with $\\mathcal{W}^{(0)}$. In particular, decide whether a constraint must be dropped from the working set to strictly improve the objective, and if so, which one.\n\nChoose exactly one option:\n\nA. Declare optimality at $x^{(0)}$ because all Lagrange multipliers associated with the active constraints in $\\mathcal{W}^{(0)}$ are nonnegative; no constraint should be dropped.\n\nB. Drop constraint $1$ (the constraint $x_1 \\ge 0$), then compute the equality-constrained search direction that maintains $x_1 + x_2 = 1$ and move along it to strictly reduce $f(x)$, reaching $x = \\begin{bmatrix} \\tfrac{1}{2} \\\\ \\tfrac{1}{2} \\end{bmatrix}$.\n\nC. Drop constraint $3$ (the constraint $x_1 + x_2 \\ge 1$), then compute the equality-constrained search direction that maintains $x_1 = 0$ and move along it to strictly reduce $f(x)$.\n\nD. Keep both constraints in the working set and take a nonzero descent step along the one-dimensional null space of the active constraints to strictly reduce $f(x)$ without modifying the working set.",
            "solution": "## PROBLEM VALIDATION\n\n### Step 1: Extract Givens\nThe problem statement provides the following information:\n- **Objective function**: minimize $f(x) = \\dfrac{1}{2} x^\\top x$ over $x \\in \\mathbb{R}^2$.\n- **Constraints**:\n    1. $x_1 \\ge 0$\n    2. $x_2 \\ge 0$\n    3. $x_1 + x_2 \\ge 1$\n- **Method**: Active-set method for quadratic programming.\n- **Initial feasible point**: $x^{(0)} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$.\n- **Initial working set**: $\\mathcal{W}^{(0)} = \\{1, 3\\}$, corresponding to constraints $x_1 \\ge 0$ and $x_1 + x_2 \\ge 1$ being treated as equalities.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard convex quadratic program (QP).\n- **Scientifically Grounded**: The problem is mathematically well-defined. The objective function $f(x) = \\frac{1}{2} x^\\top x$ has a Hessian matrix $H = I$ (the identity matrix), which is positive definite. This makes the objective function strictly convex. The constraints are linear, defining a convex feasible region. Thus, this is a convex optimization problem, which guarantees that a local minimum is also a global minimum. The active-set method is a classical and standard algorithm for solving such problems. The problem is firmly grounded in the theory of mathematical optimization.\n- **Well-Posed**: The feasible region is non-empty (e.g., $x^{(0)}$ is a feasible point) and closed. The objective function is strictly convex and grows unboundedly as $\\|x\\| \\to \\infty$. Therefore, a unique solution exists.\n- **Objective**: The problem is stated using precise mathematical language without ambiguity or subjective elements.\n\nThe initial point $x^{(0)} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ is feasible:\n- $x_1^{(0)} = 0 \\ge 0$\n- $x_2^{(0)} = 1 \\ge 0$\n- $x_1^{(0)} + x_2^{(0)} = 0 + 1 = 1 \\ge 1$\nThe constraints that are active at $x^{(0)}$ are $x_1=0$ (constraint $1$) and $x_1+x_2=1$ (constraint $3$). The specified initial working set $\\mathcal{W}^{(0)} = \\{1, 3\\}$ is consistent with the initial point.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is a well-posed, self-contained, and scientifically sound problem in the field of numerical optimization. We can proceed with the solution.\n\n## DERIVATION OF SOLUTION\n\nThe problem asks for the next action in a classical feasible active-set iteration. The current iterate is $x^{(0)} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ and the working set is $\\mathcal{W}^{(0)} = \\{1, 3\\}$. The constraints in the working set are treated as equalities:\n$x_1 = 0$\n$x_1 + x_2 = 1$\nThe point $x^{(0)}$ is the unique solution to this system of equations. In an active-set method, when the iterate satisfies the equality constraints of the working set and no feasible descent direction exists that maintains these equalities (i.e., the null space of the active constraint matrix is trivial), we must check the signs of the Lagrange multipliers to determine if we are at an optimal point or if a constraint should be dropped.\n\nThe stationarity condition of the Karush-Kuhn-Tucker (KKT) system for the equality-constrained subproblem defined by the working set states that the gradient of the objective function must be a linear combination of the gradients of the active constraints. Let's write the constraints in the form $c_i(x) \\ge 0$:\n$c_1(x) = x_1 \\ge 0$\n$c_2(x) = x_2 \\ge 0$\n$c_3(x) = x_1 + x_2 - 1 \\ge 0$\n\nThe gradient of the objective function is $\\nabla f(x) = x$.\nThe gradients of the constraints are:\n$\\nabla c_1(x) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$\n$\\nabla c_2(x) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$\n$\\nabla c_3(x) = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n\nAt the point $x^{(0)} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, the stationarity condition is $\\nabla f(x^{(0)}) = \\sum_{i \\in \\mathcal{W}^{(0)}} \\lambda_i \\nabla c_i(x^{(0)})$, where $\\lambda_i$ are the Lagrange multipliers. For our working set $\\mathcal{W}^{(0)} = \\{1, 3\\}$, this becomes:\n$$\n\\nabla f(x^{(0)}) = \\lambda_1 \\nabla c_1(x^{(0)}) + \\lambda_3 \\nabla c_3(x^{(0)})\n$$\nSubstituting the values:\n$$\n\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\lambda_1 \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + \\lambda_3 \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\n$$\nThis vector equation is equivalent to the following system of two linear equations for $\\lambda_1$ and $\\lambda_3$:\n1. $0 = \\lambda_1 + \\lambda_3$\n2. $1 = (0)\\lambda_1 + \\lambda_3$\n\nFrom equation (2), we immediately find $\\lambda_3 = 1$.\nSubstituting this into equation (1), we get $0 = \\lambda_1 + 1$, which gives $\\lambda_1 = -1$.\n\nThe calculated Lagrange multipliers for the active constraints are $\\lambda_1 = -1$ and $\\lambda_3 = 1$. The KKT conditions for optimality of the original inequality-constrained problem require all Lagrange multipliers to be non-negative ($\\lambda_i \\ge 0$ for all active constraints $i$). Since $\\lambda_1 = -1  0$, the point $x^{(0)}$ is not the optimal solution.\n\nThe active-set strategy dictates that if one or more Lagrange multipliers are negative, we should drop one of the corresponding constraints from the working set to allow for a feasible descent direction that improves the objective function. Typically, the constraint associated with the most negative multiplier is chosen. In this case, $\\lambda_1 = -1$ is the only negative multiplier, so we must drop constraint $1$ ($x_1 \\ge 0$) from the working set.\n\nThe new working set is $\\mathcal{W}^{(1)} = \\{3\\}$. The next step is to compute a search direction $p$ from $x^{(0)}$ that minimizes the objective function while remaining on the hyperplane defined by the single active constraint in $\\mathcal{W}^{(1)}$, i.e., $x_1 + x_2 = 1$.\n\nThe goal is to find $x = x^{(0)} + p$ that minimizes $f(x)$ subject to $x_1 + x_2 = 1$. This is equivalent to finding the point on the line $x_1 + x_2 = 1$ that is closest to the origin. The solution to this subproblem is the orthogonal projection of the origin onto the line.\nLet $x^*_{\\text{sub}}$ be the solution to this subproblem. The KKT conditions for this new equality-constrained problem are:\n$\\nabla f(x^*_{\\text{sub}}) = \\mu_3 \\nabla c_3(x^*_{\\text{sub}})$\n$\\begin{bmatrix} x_1^* \\\\ x_2^* \\end{bmatrix} = \\mu_3 \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, which implies $x_1^* = x_2^* = \\mu_3$.\nThe point must also satisfy the constraint: $x_1^* + x_2^* = 1$.\nSubstituting $x_1^* = x_2^*$ into the constraint gives $2x_1^* = 1$, so $x_1^* = \\frac{1}{2}$. Thus, $x_2^* = \\frac{1}{2}$.\nThe minimizer of the subproblem is $x^*_{\\text{sub}} = \\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix}$.\n\nThe search direction is $p = x^*_{\\text{sub}} - x^{(0)} = \\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix} - \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2} \\\\ -\\frac{1}{2} \\end{bmatrix}$.\nThe new iterate will be $x^{(1)} = x^{(0)} + \\alpha p$. The step length $\\alpha$ is chosen to be the smaller of $1$ (the step to the subproblem minimizer) and the maximum feasible step length that does not violate any inactive constraints.\nThe inactive constraints are $c_1(x) = x_1 \\ge 0$ and $c_2(x) = x_2 \\ge 0$.\nWe need $x^{(0)} + \\alpha p \\ge 0$ component-wise (for these specific constraints).\n$x_1(\\alpha) = 0 + \\alpha(\\frac{1}{2}) \\ge 0 \\implies \\alpha \\ge 0$.\n$x_2(\\alpha) = 1 + \\alpha(-\\frac{1}{2}) \\ge 0 \\implies 1 \\ge \\frac{\\alpha}{2} \\implies \\alpha \\le 2$.\nThe maximum feasible step is $\\alpha_{\\text{max}} = 2$.\nThe step to the subproblem's minimizer is $\\alpha = 1$.\nSince $1  2$, no new constraint becomes active. We take the full step, $\\alpha=1$.\nThe new point is $x^{(1)} = x^{(0)} + 1 \\cdot p = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix} \\frac{1}{2} \\\\ -\\frac{1}{2} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix}$.\nThe objective function value is reduced from $f(x^{(0)}) = \\frac{1}{2}(0^2+1^2) = \\frac{1}{2}$ to $f(x^{(1)}) = \\frac{1}{2}((\\frac{1}{2})^2+(\\frac{1}{2})^2) = \\frac{1}{2}(\\frac{1}{4}+\\frac{1}{4}) = \\frac{1}{4}$.\n\n## OPTION-BY-OPTION ANALYSIS\n\n**A. Declare optimality at $x^{(0)}$ because all Lagrange multipliers associated with the active constraints in $\\mathcal{W}^{(0)}$ are nonnegative; no constraint should be dropped.**\nOur calculation showed that the Lagrange multiplier for constraint $1$ is $\\lambda_1 = -1$, which is negative. Therefore, the premise of this option is false. The point $x^{(0)}$ is not optimal.\n**Verdict: Incorrect.**\n\n**B. Drop constraint $1$ (the constraint $x_1 \\ge 0$), then compute the equality-constrained search direction that maintains $x_1 + x_2 = 1$ and move along it to strictly reduce $f(x)$, reaching $x = \\begin{bmatrix} \\tfrac{1}{2} \\\\ \\tfrac{1}{2} \\end{bmatrix}$.**\nOur analysis showed that because $\\lambda_1 = -1  0$, constraint $1$ must be dropped. The new subproblem involves minimizing $f(x)$ subject to the remaining active constraint, $x_1 + x_2 = 1$. The solution to this subproblem is indeed $x = \\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix}$. The move from $x^{(0)}$ to this new point constitutes a single iteration of the active-set method, involving a search direction and a full step of $\\alpha=1$. This option correctly describes the entire sequence of actions for this iteration.\n**Verdict: Correct.**\n\n**C. Drop constraint $3$ (the constraint $x_1 + x_2 \\ge 1$), then compute the equality-constrained search direction that maintains $x_1 = 0$ and move along it to strictly reduce $f(x)$.**\nThe Lagrange multiplier associated with constraint $3$ is $\\lambda_3 = 1$, which is non-negative. A standard active-set method does not drop a constraint with a non-negative multiplier. Therefore, this action is incorrect.\n**Verdict: Incorrect.**\n\n**D. Keep both constraints in the working set and take a nonzero descent step along the one-dimensional null space of the active constraints to strictly reduce $f(x)$ without modifying the working set.**\nThe active constraints are $x_1=0$ and $x_1+x_2=1$. The matrix of active constraint gradients is $A = \\begin{bmatrix} \\nabla c_1^\\top \\\\ \\nabla c_3^\\top \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 1  1 \\end{bmatrix}$. In $\\mathbb{R}^2$, these two gradients are linearly independent. The null space of $A$ contains vectors $p$ such that $Ap=0$. Since $A$ is invertible, the only solution is $p=0$. The null space is zero-dimensional (it contains only the zero vector). Therefore, no nonzero descent step can be taken while keeping both constraints active.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Choosing the right algorithm involves understanding the trade-offs between simplicity and numerical robustness. This exercise provides a direct comparison between the quadratic penalty method and the augmented Lagrangian method for handling equality constraints. By analyzing a simple but illuminating problem, you will see firsthand how the penalty method's reliance on a large penalty parameter can lead to ill-conditioning, and how the augmented Lagrangian method cleverly avoids this pitfall.",
            "id": "3217528",
            "problem": "Consider the equality-constrained optimization problem of minimizing the quadratic function subject to a linear constraint:\nMinimize $f(x) = \\tfrac{1}{2} x_1^2 + \\tfrac{1}{2} x_2^2$ subject to $c(x) = x_1 - 1 = 0$, where $x = (x_1, x_2) \\in \\mathbb{R}^2$. You will examine two classical approaches: the standard quadratic penalty method and the augmented Lagrangian method.\n\nBy first principles, the constrained minimizer $(x^\\star, \\lambda^\\star)$ satisfies the Karush-Kuhn-Tucker (KKT) conditions, which for an equality constraint are the stationarity and feasibility conditions\n$\\nabla f(x^\\star) + \\lambda^\\star \\nabla c(x^\\star) = 0$ and $c(x^\\star) = 0$,\nwhere $\\lambda^\\star$ is the Lagrange multiplier.\n\nThe quadratic penalty method solves a sequence of unconstrained problems of the form\n$\\min_x \\, \\phi_\\rho(x) = f(x) + \\tfrac{\\rho}{2} \\, c(x)^2$ with penalty parameter $\\rho  0$.\nThe augmented Lagrangian method solves subproblems of the form\n$\\min_x \\, \\mathcal{L}_\\rho(x, \\lambda) = f(x) + \\lambda \\, c(x) + \\tfrac{\\rho}{2} \\, c(x)^2$ with a fixed moderate $\\rho  0$ while updating the multiplier by $\\lambda_{k+1} = \\lambda_k + \\rho \\, c(x_k)$.\n\nAssume you want the constraint violation $|c(x)| = |x_1 - 1|$ to be at most a tolerance $t = 10^{-8}$. For the penalty method, let $x_\\rho$ denote the exact minimizer of $\\phi_\\rho$. For the augmented Lagrangian method, consider a fixed $\\rho = 10$ and the exact minimizer $x(\\lambda)$ of $\\mathcal{L}_\\rho(\\cdot, \\lambda)$ at each iteration with multiplier update $\\lambda_{k+1} = \\lambda_k + \\rho \\, c(x(\\lambda_k))$.\n\nWhich of the following statements is correct?\n\nA. In the penalty method, achieving $|x_{1,\\rho} - 1| \\le t$ requires $\\rho \\ge 10^8$, which makes the Hessian of $\\phi_\\rho$ equal to $\\nabla^2 \\phi_\\rho(x) = \\begin{pmatrix} 1 + \\rho  0 \\\\ 0  1 \\end{pmatrix}$ and yields a condition number $\\kappa(\\nabla^2 \\phi_\\rho) \\approx 10^8$, causing ill-conditioning; in contrast, the augmented Lagrangian method with $\\rho = 10$ has subproblem Hessian $\\nabla^2_x \\mathcal{L}_\\rho = \\begin{pmatrix} 1 + \\rho  0 \\\\ 0  1 \\end{pmatrix}$ with condition number $\\kappa \\approx 11$ and the multiplier update contracts the error by a factor $1/(1+\\rho) = 1/11$ per iteration, so it converges robustly.\n\nB. Both the penalty and augmented Lagrangian methods require taking $\\rho \\to \\infty$ to drive $|x_1 - 1| \\to 0$, so both Hessians necessarily become severely ill-conditioned.\n\nC. The quadratic penalty method yields a Hessian independent of $\\rho$, so it does not suffer ill-conditioning; meanwhile, the augmented Lagrangian method’s Hessian becomes ill-conditioned as $\\rho$ grows, making it less robust.\n\nD. The augmented Lagrangian method cannot handle linear equality constraints; only the penalty method applies in this case.\n\nSelect the correct option.",
            "solution": "The user has provided a problem in constrained optimization, requiring a comparative analysis of the quadratic penalty method and the augmented Lagrangian method.\n\n### Step 1: Problem Validation\n\nThe problem statement is analyzed for validity.\n\n-   **Givens Extracted**:\n    -   Objective function: $f(x) = \\tfrac{1}{2} x_1^2 + \\tfrac{1}{2} x_2^2$\n    -   Constraint function: $c(x) = x_1 - 1 = 0$\n    -   Domain: $x = (x_1, x_2) \\in \\mathbb{R}^2$\n    -   KKT conditions: $\\nabla f(x^\\star) + \\lambda^\\star \\nabla c(x^\\star) = 0$ and $c(x^\\star) = 0$\n    -   Quadratic penalty function: $\\phi_\\rho(x) = f(x) + \\tfrac{\\rho}{2} \\, c(x)^2$\n    -   Augmented Lagrangian function: $\\mathcal{L}_\\rho(x, \\lambda) = f(x) + \\lambda \\, c(x) + \\tfrac{\\rho}{2} \\, c(x)^2$\n    -   Augmented Lagrangian multiplier update: $\\lambda_{k+1} = \\lambda_k + \\rho \\, c(x_k)$\n    -   Constraint violation tolerance: $t = 10^{-8}$\n    -   Augmented Lagrangian penalty parameter: $\\rho = 10$\n\n-   **Validation Assessment**:\n    -   The problem is **scientifically grounded** and **objective**. It presents a standard, canonical problem from the field of numerical optimization, a sub-discipline of numerical methods and scientific computing.\n    -   The definitions of the methods (quadratic penalty, augmented Lagrangian) and the analytical tools (KKT conditions) are correct and standard.\n    -   The problem is **well-posed** and **self-contained**. The objective function is strictly convex and the constraint is linear, which guarantees a unique solution. All necessary data and definitions are provided.\n    -   The problem does not violate any scientific principles, is not based on false premises, and contains no ambiguities.\n\n-   **Verdict**: The problem statement is valid. The analysis may proceed.\n\n### Step 2: Derivation of the Exact Solution\n\nFirst, we find the exact solution $(x^\\star, \\lambda^\\star)$ to the constrained problem using the Karush-Kuhn-Tucker (KKT) conditions. The gradients of the objective and constraint functions are:\n$$\n\\nabla f(x) = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}, \\quad \\nabla c(x) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nThe KKT conditions are:\n1.  **Feasibility**: $c(x^\\star) = x_1^\\star - 1 = 0 \\implies x_1^\\star = 1$.\n2.  **Stationarity**: $\\nabla f(x^\\star) + \\lambda^\\star \\nabla c(x^\\star) = 0 \\implies \\begin{pmatrix} x_1^\\star \\\\ x_2^\\star \\end{pmatrix} + \\lambda^\\star \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\nFrom the stationarity condition, we get two scalar equations:\n$x_1^\\star + \\lambda^\\star = 0$\n$x_2^\\star = 0$\n\nUsing $x_1^\\star = 1$ from the feasibility condition, we find $\\lambda^\\star = -x_1^\\star = -1$.\nThus, the unique minimizer is $x^\\star = (1, 0)$ with the corresponding Lagrange multiplier $\\lambda^\\star = -1$.\n\n### Step 3: Analysis of the Quadratic Penalty Method\n\nThe quadratic penalty method involves solving a sequence of unconstrained problems for $\\min_x \\phi_\\rho(x)$, where:\n$$\n\\phi_\\rho(x) = f(x) + \\frac{\\rho}{2} c(x)^2 = \\frac{1}{2} x_1^2 + \\frac{1}{2} x_2^2 + \\frac{\\rho}{2} (x_1 - 1)^2\n$$\nThe minimizer $x_\\rho$ is found by setting the gradient of $\\phi_\\rho(x)$ to zero:\n$$\n\\nabla \\phi_\\rho(x) = \\begin{pmatrix} x_1 + \\rho(x_1 - 1) \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} (1+\\rho)x_1 - \\rho \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nSolving this system gives the minimizer $x_\\rho = (x_{1,\\rho}, x_{2,\\rho})$:\n$x_{1,\\rho} = \\frac{\\rho}{1+\\rho}$\n$x_{2,\\rho} = 0$\n\nThe constraint violation at this point is:\n$$\nc(x_\\rho) = x_{1,\\rho} - 1 = \\frac{\\rho}{1+\\rho} - 1 = \\frac{\\rho - (1+\\rho)}{1+\\rho} = -\\frac{1}{1+\\rho}\n$$\nTo satisfy the tolerance requirement $|c(x_\\rho)| \\le t = 10^{-8}$:\n$$\n\\left| -\\frac{1}{1+\\rho} \\right| = \\frac{1}{1+\\rho} \\le 10^{-8} \\implies 1+\\rho \\ge 10^8 \\implies \\rho \\ge 10^8 - 1\n$$\nThis confirms that the penalty parameter $\\rho$ must be very large (approximately $10^8$) to achieve high accuracy.\n\nNow, we analyze the conditioning of the subproblem by computing the Hessian of $\\phi_\\rho(x)$:\n$$\n\\nabla^2 \\phi_\\rho(x) = \\begin{pmatrix} 1+\\rho  0 \\\\ 0  1 \\end{pmatrix}\n$$\nThe eigenvalues of this Hessian matrix are $\\mu_1 = 1+\\rho$ and $\\mu_2 = 1$. The condition number is the ratio of the largest to the smallest eigenvalue:\n$$\n\\kappa(\\nabla^2 \\phi_\\rho) = \\frac{\\mu_{\\text{max}}}{\\mu_{\\text{min}}} = \\frac{1+\\rho}{1} = 1+\\rho\n$$\nFor $\\rho \\ge 10^8 - 1$, the condition number is $\\kappa(\\nabla^2 \\phi_\\rho) \\ge 10^8$. This extremely large condition number signifies that the unconstrained minimization subproblems become severely ill-conditioned as $\\rho \\to \\infty$.\n\n### Step 4: Analysis of the Augmented Lagrangian Method\n\nThe augmented Lagrangian method solves subproblems of the form $\\min_x \\mathcal{L}_\\rho(x, \\lambda)$ for a fixed, moderate $\\rho  0$, followed by a multiplier update. Here, $\\rho = 10$.\n$$\n\\mathcal{L}_\\rho(x, \\lambda) = f(x) + \\lambda c(x) + \\frac{\\rho}{2} c(x)^2 = \\frac{1}{2} x_1^2 + \\frac{1}{2} x_2^2 + \\lambda(x_1 - 1) + \\frac{\\rho}{2}(x_1 - 1)^2\n$$\nLet $x_k = x(\\lambda_k)$ be the minimizer of $\\mathcal{L}_\\rho(x, \\lambda_k)$. We find it by setting the gradient with respect to $x$ to zero:\n$$\n\\nabla_x \\mathcal{L}_\\rho(x, \\lambda_k) = \\begin{pmatrix} x_1 + \\lambda_k + \\rho(x_1 - 1) \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} (1+\\rho)x_1 - \\rho + \\lambda_k \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nSolving for $x_{1,k}$ and $x_{2,k}$:\n$x_{1,k} = \\frac{\\rho - \\lambda_k}{1+\\rho}$\n$x_{2,k} = 0$\n\nThe multiplier update rule is $\\lambda_{k+1} = \\lambda_k + \\rho c(x_k)$. The constraint value at $x_k$ is:\n$$\nc(x_k) = x_{1,k} - 1 = \\frac{\\rho - \\lambda_k}{1+\\rho} - 1 = \\frac{\\rho - \\lambda_k - (1+\\rho)}{1+\\rho} = \\frac{-1 - \\lambda_k}{1+\\rho}\n$$\nSubstituting this into the update rule:\n$$\n\\lambda_{k+1} = \\lambda_k + \\rho \\left( \\frac{-1 - \\lambda_k}{1+\\rho} \\right) = \\frac{(1+\\rho)\\lambda_k - \\rho(1+\\lambda_k)}{1+\\rho} = \\frac{\\lambda_k - \\rho}{1+\\rho}\n$$\nTo analyze convergence, we examine the error $\\lambda_k - \\lambda^\\star = \\lambda_k - (-1) = \\lambda_k + 1$:\n$$\n\\lambda_{k+1} + 1 = \\frac{\\lambda_k - \\rho}{1+\\rho} + 1 = \\frac{\\lambda_k - \\rho + 1 + \\rho}{1+\\rho} = \\frac{\\lambda_k + 1}{1+\\rho}\n$$\nThis shows that the error in the Lagrange multiplier estimate, $(\\lambda_k - \\lambda^\\star)$, is reduced by a factor of $\\frac{1}{1+\\rho}$ at each iteration. With $\\rho=10$, the contraction factor is $\\frac{1}{11}$. This demonstrates linear convergence to the true multiplier $\\lambda^\\star = -1$ without requiring $\\rho \\to \\infty$. Consequently, the constraint violation $c(x_k) = -\\frac{1}{1+\\rho}(\\lambda_k+1)$ also converges linearly to $0$.\n\nNow, we analyze the conditioning of the augmented Lagrangian subproblem. The Hessian of $\\mathcal{L}_\\rho(x, \\lambda)$ with respect to $x$ is:\n$$\n\\nabla^2_x \\mathcal{L}_\\rho(x, \\lambda) = \\begin{pmatrix} 1+\\rho  0 \\\\ 0  1 \\end{pmatrix}\n$$\nThis is the same form as the penalty Hessian. However, the key difference is that $\\rho$ is a fixed, moderate constant. For $\\rho = 10$:\n$$\n\\nabla^2_x \\mathcal{L}_{10}(x, \\lambda) = \\begin{pmatrix} 11  0 \\\\ 0  1 \\end{pmatrix}\n$$\nThe eigenvalues are $\\mu_1 = 11$ and $\\mu_2 = 1$. The condition number is:\n$$\n\\kappa(\\nabla^2_x \\mathcal{L}_{10}) = \\frac{11}{1} = 11\n$$\nThis is a small, constant condition number, meaning the subproblems are well-conditioned and robustly solvable.\n\n### Step 5: Option-by-Option Analysis\n\n-   **A. In the penalty method, achieving $|x_{1,\\rho} - 1| \\le t$ requires $\\rho \\ge 10^8$, which makes the Hessian of $\\phi_\\rho$ equal to $\\nabla^2 \\phi_\\rho(x) = \\begin{pmatrix} 1 + \\rho  0 \\\\ 0  1 \\end{pmatrix}$ and yields a condition number $\\kappa(\\nabla^2 \\phi_\\rho) \\approx 10^8$, causing ill-conditioning; in contrast, the augmented Lagrangian method with $\\rho = 10$ has subproblem Hessian $\\nabla^2_x \\mathcal{L}_\\rho = \\begin{pmatrix} 1 + \\rho  0 \\\\ 0  1 \\end{pmatrix}$ with condition number $\\kappa \\approx 11$ and the multiplier update contracts the error by a factor $1/(1+\\rho) = 1/11$ per iteration, so it converges robustly.**\n    -   This statement accurately summarizes the findings of our analysis. The penalty method requires $\\rho \\approx 10^8$, leading to a condition number of $\\approx 10^8$. The augmented Lagrangian method uses a fixed $\\rho=10$, leading to a well-conditioned Hessian with $\\kappa=11$, and converges via multiplier updates with an error contraction factor of $1/11$.\n    -   Verdict: **Correct**.\n\n-   **B. Both the penalty and augmented Lagrangian methods require taking $\\rho \\to \\infty$ to drive $|x_1 - 1| \\to 0$, so both Hessians necessarily become severely ill-conditioned.**\n    -   This is incorrect. The augmented Lagrangian method achieves convergence for a fixed, finite $\\rho$ by updating the Lagrange multiplier estimate. It does not require $\\rho \\to \\infty$. Consequently, its Hessian does not necessarily become ill-conditioned.\n    -   Verdict: **Incorrect**.\n\n-   **C. The quadratic penalty method yields a Hessian independent of $\\rho$, so it does not suffer ill-conditioning; meanwhile, the augmented Lagrangian method’s Hessian becomes ill-conditioned as $\\rho$ grows, making it less robust.**\n    -   This is incorrect. The penalty method's Hessian, $\\nabla^2 \\phi_\\rho$, is directly dependent on $\\rho$ and becomes ill-conditioned as $\\rho \\to \\infty$. While the ALM Hessian also depends on $\\rho$, the method is designed so that $\\rho$ does not need to grow. The statement reverses the properties of the two methods.\n    -   Verdict: **Incorrect**.\n\n-   **D. The augmented Lagrangian method cannot handle linear equality constraints; only the penalty method applies in this case.**\n    -   This is factually false. The augmented Lagrangian method is specifically designed for equality-constrained problems and is highly effective for them, including those with linear constraints, as demonstrated in our analysis.\n    -   Verdict: **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}