{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握延拓方法，最好的方式莫过于亲手实现其核心算法。本练习将指导你从零开始构建一个“预测-校正”算法，这是伪弧长延拓方法的心脏。通过为参数化非线性系统编写代码，你将深入理解算法的两个关键步骤：如何沿着解曲线的切线方向进行“预测”，以及如何利用增广的牛顿法进行“校正”，从而精确地回到解流形上。这项实践将让你直观地感受延拓方法如何巧妙地绕过简单参数延拓法会失败的“转折点”，为你后续的理论学习和应用打下坚实的实践基础。",
            "id": "3282840",
            "problem": "考虑参数化非线性系统 $F(x,\\lambda)=0$，其中 $x\\in\\mathbb{R}^2$，$\\lambda\\in\\mathbb{R}$，且 $F:\\mathbb{R}^2\\times\\mathbb{R}\\to\\mathbb{R}^2$ 定义为\n$$\nF_1(x,\\lambda) = x_1^3 - x_1 + x_2,\\quad F_2(x,\\lambda) = x_2 + \\lambda - x_1^2.\n$$\n$F$在$(x,\\lambda)$处关于$x$的雅可比矩阵记为$\\dfrac{\\partial F}{\\partial x}(x,\\lambda)$，关于$\\lambda$的偏导数记为$\\dfrac{\\partial F}{\\partial \\lambda}(x,\\lambda)$。您的任务是实现一个使用预测-校正方案的延拓方法，以追踪满足$F(x,\\lambda)=0$的三元组$(x,\\lambda)$的解曲线。该方法必须显式地使用雅可比矩阵来计算局部线性化并执行校正。\n\n基本原理与约束：\n- 使用雅可比矩阵的定义和非线性系统的线性化，在有效解$(x,\\lambda)$处构造解流形的局部切线方向。切线方向在概念上由以下要求定义：沿该方向的移动保持约束$F(x,\\lambda)=0$的一阶有效性。\n- 使用基于牛顿法 (Newton's method) 的校正步骤，该方法应用于一个增广系统，该系统同时强制执行原始约束和一个定义沿选定切线方向运动的标量约束。\n- 使用基于线性代数和雅可比矩阵的数值稳定方法计算任何所需的零空间方向。\n\n算法要求：\n- 实现一个预测步骤，使用预先选择的步长，沿局部计算出的切线方向推进近似解。\n- 实现一个校正步骤，将牛顿法 (Newton's method) 应用于一个由原始约束和一个标量弧长类约束构成的增广系统，该弧长类约束将运动固定在由切线定义的预测超平面上。\n- 使用雅可比矩阵$\\dfrac{\\partial F}{\\partial x}(x,\\lambda)$和$\\dfrac{\\partial F}{\\partial \\lambda}(x,\\lambda)$来组装切线计算和牛顿校正器所需的线性系统。\n- 为保证鲁棒性，如果由于接近奇异而无法直接求解牛顿系统，则使用与线性化一致的最小二乘替代方法。\n\n测试套件：\n实现您的程序以运行以下三个测试用例，每个用例由满足$F(x_0,\\lambda_0)=0$的初始解$(x_0,\\lambda_0)$、步长$\\Delta s$、延拓步数$N$以及牛顿求解器参数（容差$\\varepsilon$和最大迭代次数$k_{\\max}$）指定。此问题中不出现角度，因此不需要角度单位。此问题中没有物理单位。\n\n- 情况 $1$（一般顺利路径）：\n  - 初始解：$x_0 = (0.0, 0.0)$, $\\lambda_0 = 0.0$。\n  - 步长：$\\Delta s = 0.2$。\n  - 步数：$N = 12$。\n  - 牛顿容差：$\\varepsilon = 10^{-12}$。\n  - 最大牛顿迭代次数：$k_{\\max} = 20$。\n\n- 情况 $2$（接近一个局部参数延拓会失败的转折点）：\n  - 初始解：$x_0 = (0.3, 0.273)$, $\\lambda_0 = -0.183$。\n  - 步长：$\\Delta s = 0.1$。\n  - 步数：$N = 20$。\n  - 牛顿容差：$\\varepsilon = 10^{-12}$。\n  - 最大牛顿迭代次数：$k_{\\max} = 20$。\n\n- 情况 $3$（接近另一个转折点）：\n  - 初始解：$x_0 = (-0.8, -0.288)$, $\\lambda_0 = 0.928$。\n  - 步长：$\\Delta s = 0.1$。\n  - 步数：$N = 15$。\n  - 牛顿容差：$\\varepsilon = 10^{-12}$。\n  - 最大牛顿迭代次数：$k_{\\max} = 25$。\n\n答案规范：\n- 对于每种情况，精确运行$N$个预测-校正步骤的延拓方法，并返回最终的三元组$(x_{\\text{end}},\\lambda_{\\text{end}})$。\n- 将每个最终三元组表示为包含三个实数的列表$[x_{1,\\text{end}}, x_{2,\\text{end}}, \\lambda_{\\text{end}}]$，其中每个数字都四舍五入到六位小数。\n- 您的程序应生成单行输出，其中包含所有三种情况的结果，格式为一个用方括号括起来的逗号分隔列表，每个情况的结果本身也是一个用方括号括起来的逗号分隔列表。例如，格式必须与$[[a_1,a_2,a_3],[b_1,b_2,b_3],[c_1,c_2,c_3]]$完全一样，其中每个$a_i$、$b_i$和$c_i$都是四舍五入到六位小数的浮点数。\n\n科学真实性与推导期望：\n- 从雅可比矩阵的核心定义和$F(x,\\lambda)=0$的线性化出发，证明基于解点处切线方向的预测步骤的合理性。\n- 通过构造一个增广系统来证明校正步骤的合理性，该系统强制执行原始约束和一个定义在与基于切线的预测正交的超平面内运动的标量约束。\n- 推导使用稳定线性代数（如奇异值分解 (Singular Value Decomposition, SVD)）以在折叠点附近也能获得可靠切线方向的必要性，并解释增广牛顿步骤如何克服在转折点处$\\dfrac{\\partial F}{\\partial x}(x,\\lambda)$的奇异性。",
            "solution": "该问题要求实现一种预测-校正延拓方法，以追踪参数化非线性系统的解曲线。该系统定义为 $F(x,\\lambda)=0$，其中 $x \\in \\mathbb{R}^2$，$\\lambda \\in \\mathbb{R}$，且函数 $F:\\mathbb{R}^2\\times\\mathbb{R}\\to\\mathbb{R}^2$ 由下式给出\n$$\nF(x,\\lambda) = \\begin{pmatrix} F_1(x,\\lambda) \\\\ F_2(x,\\lambda) \\end{pmatrix} = \\begin{pmatrix} x_1^3 - x_1 + x_2 \\\\ x_2 + \\lambda - x_1^2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\n解集 $(x_1, x_2, \\lambda)$ 在 $\\mathbb{R}^3$ 中构成一个一维流形（一条曲线）。目标是数值地追踪这条曲线。为方便起见，我们定义一个统一的状态向量 $y = (x_1, x_2, \\lambda)^T \\in \\mathbb{R}^3$，从而可以将系统紧凑地写为 $F(y)=0$，其中 $F: \\mathbb{R}^3 \\to \\mathbb{R}^2$。\n\n延拓方法的基础在于解曲线的局部几何性质。通过对恒等式$F(y(s))=0$关于弧长参数$s$求导，我们得到条件$DF(y(s))\\frac{dy}{ds} = 0$，其中$DF(y)$是$F$关于$y$的雅可比矩阵。这意味着曲线的切向量$\\tau = \\frac{dy}{ds}$必须位于雅可比矩阵$DF(y)$的零空间中。给定系统的雅可比矩阵是一个$2 \\times 3$的矩阵：\n$$\nDF(y) = \\left[ \\frac{\\partial F}{\\partial x} \\middle| \\frac{\\partial F}{\\partial \\lambda} \\right] = \\begin{pmatrix} \\frac{\\partial F_1}{\\partial x_1} & \\frac{\\partial F_1}{\\partial x_2} & \\frac{\\partial F_1}{\\partial \\lambda} \\\\ \\frac{\\partial F_2}{\\partial x_1} & \\frac{\\partial F_2}{\\partial x_2} & \\frac{\\partial F_2}{\\partial \\lambda} \\end{pmatrix} = \\begin{pmatrix} 3x_1^2 - 1 & 1 & 0 \\\\ -2x_1 & 1 & 1 \\end{pmatrix}.\n$$\n假设$DF(y)$具有满秩（秩为$2$），其零空间是一维的，从而唯一地定义了点$y$处的切线方向。\n\n该算法分为两个主要步骤：预测步骤和校正步骤。\n\n**预测步骤**：\n给定曲线上一个已知解点$y_k$，预测步骤通过沿切线方向$\\tau_k$前进一个固定距离$\\Delta s$来外插得到下一个近似点$y_{k+1}^*$。\n$$\ny_{k+1}^* = y_k + \\Delta s \\cdot \\tau_k.\n$$\n切向量$\\tau_k$被计算为$DF(y_k)$零空间的归一化基向量。寻找该向量的一种数值鲁棒的方法是奇异值分解（Singular Value Decomposition, SVD）。对于矩阵$DF(y_k) = U \\Sigma V^T$，正交矩阵$V$的最后一列（对应最小的奇异值）提供了零空间的一个基。因此，我们将$\\tau_k$设为此向量。为确保延拓方法沿曲线以一致的方向行进，我们选择$\\tau_k$的符号，使其与前一个切向量$\\tau_{k-1}$的点积为非负：$\\tau_k^T \\tau_{k-1} \\ge 0$。对于初始步骤（$k=0$），一个常规的选择是定向$\\tau_0$，使其$\\lambda$分量（如果可能）为非负。\n\n**校正步骤**：\n预测点$y_{k+1}^*$通常不满足$F(y_{k+1}^*)=0$。校正步骤对该预测进行精化，以在其附近找到一个真实解点$y_{k+1}$。为确保局部唯一解，我们施加一个附加约束。在伪弧长延拓方法中，此约束强制最终点$y_{k+1}$位于穿过$y_{k+1}^*$并与切向量$\\tau_k$正交的超平面上。该约束的数学形式为：\n$$\n\\tau_k^T (y_{k+1} - y_{k+1}^*) = 0.\n$$\n该方程与原始系统$F(y_{k+1})=0$相结合，形成一个关于$y_{k+1}$中3个未知数的增广方阵系统，包含3个方程。令$y \\equiv y_{k+1}$，我们求解系统$G(y)=0$：\n$$\nG(y) = \\begin{pmatrix} F(y) \\\\ \\tau_k^T (y - y_{k+1}^*) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n该系统使用牛顿法 (Newton's method) 求解，以预测点$y_{k+1}^*$作为初始猜测。牛顿迭代定义为$y^{(j+1)} = y^{(j)} - [DG(y^{(j)})]^{-1} G(y^{(j)})$，其中$DG(y)$是增广系统的雅可比矩阵：\n$$\nDG(y) = \\begin{pmatrix} DF(y) \\\\ \\tau_k^T \\end{pmatrix} = \\begin{pmatrix} 3x_1^2 - 1 & 1 & 0 \\\\ -2x_1 & 1 & 1 \\\\ (\\tau_k)_1 & (\\tau_k)_2 & (\\tau_k)_3 \\end{pmatrix}.\n$$\n此公式的一个关键特征是，增广雅可比矩阵$DG(y)$通常是非奇异的，即使在解曲线的转折点处（此处状态空间雅可比矩阵$\\frac{\\partial F}{\\partial x}$变为奇异）也是如此。这使得该方法能够追踪通过折叠点的曲线，而更简单的方法（如自然参数延拓）在这些点会失败。根据问题的鲁棒性要求，牛顿步骤的线性系统$DG(y^{(j)}) \\Delta y = -G(y^{(j)})$使用最小二乘法求解，以处理潜在的数值不稳定性或病态条件。迭代过程持续进行，直到残差的欧几里得范数$\\|G(y^{(j)})\\|_2$小于给定的容差$\\varepsilon$。收敛的点被接受为解曲线上的下一个点$y_{k+1}$。这个预测-校正循环重复指定的步数$N$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a predictor-corrector continuation method to trace solution curves\n    of a parameterized nonlinear system F(x, lambda) = 0.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general happy path)\n        {'y0': [0.0, 0.0, 0.0], 'ds': 0.2, 'N': 12, 'tol': 1e-12, 'k_max': 20},\n        # Case 2 (near a turning point)\n        {'y0': [0.3, 0.273, -0.183], 'ds': 0.1, 'N': 20, 'tol': 1e-12, 'k_max': 20},\n        # Case 3 (approaching another turning point)\n        {'y0': [-0.8, -0.288, 0.928], 'ds': 0.1, 'N': 15, 'tol': 1e-12, 'k_max': 25},\n    ]\n\n    def F_func(y):\n        \"\"\"Computes the value of the nonlinear system F(y).\"\"\"\n        x1, x2, lam = y\n        F1 = x1**3 - x1 + x2\n        F2 = x2 + lam - x1**2\n        return np.array([F1, F2])\n\n    def DF_func(y):\n        \"\"\"Computes the 2x3 Jacobian matrix DF(y).\"\"\"\n        x1, _, _ = y\n        return np.array([\n            [3 * x1**2 - 1, 1, 0],\n            [-2 * x1, 1, 1]\n        ])\n\n    def run_continuation(y0, ds, N, tol, k_max):\n        \"\"\"\n        Executes the continuation algorithm for a single test case.\n\n        Args:\n            y0 (list): Initial solution [x1, x2, lambda].\n            ds (float): Step size along the curve.\n            N (int): Number of continuation steps.\n            tol (float): Tolerance for Newton's method convergence.\n            k_max (int): Maximum iterations for Newton's method.\n\n        Returns:\n            np.ndarray: The final solution point after N steps.\n        \"\"\"\n        y_current = np.array(y0, dtype=float)\n        # To maintain direction, we store the previous tangent.\n        # An initial orientation that favors increasing lambda helps start the process.\n        tau_prev = np.array([0.0, 0.0, 1.0])\n\n        for _ in range(N):\n            # --- Predictor Step ---\n            DF_current = DF_func(y_current)\n            \n            # Use Singular Value Decomposition (SVD) to find the null space of the 2x3 Jacobian.\n            # The null space is 1D and its basis vector is our tangent.\n            # For DF = U * Sigma * Vh, the last row of Vh (V transpose) is the normalized vector \n            # spanning the null space.\n            _, _, Vh = np.linalg.svd(DF_current)\n            tau_current = Vh[-1, :]\n            \n            # Orient the tangent vector to prevent the path from reversing.\n            if np.dot(tau_current, tau_prev)  0:\n                tau_current = -tau_current\n            tau_prev = tau_current\n\n            # Predict the next point along the tangent.\n            y_pred = y_current + ds * tau_current\n\n            # --- Corrector Step ---\n            # Use Newton's method to solve the augmented system G(y) = 0.\n            # G(y) = [F(y); tau^T * (y - y_pred)]\n            y_j = y_pred.copy()\n            \n            for _ in range(k_max):\n                F_val = F_func(y_j)\n                g_val = np.dot(tau_current, y_j - y_pred)\n                G_val = np.append(F_val, g_val)\n                \n                if np.linalg.norm(G_val)  tol:\n                    break  # Convergence achieved\n\n                # Jacobian of the augmented system DG(y)\n                DF_j = DF_func(y_j)\n                DG_j = np.vstack([DF_j, tau_current])\n\n                # Solve the linear system DG * delta_y = -G for the Newton step.\n                # np.linalg.lstsq is used for robustness as requested, handling near-singular cases.\n                delta_y = np.linalg.lstsq(DG_j, -G_val, rcond=None)[0]\n                \n                y_j += delta_y\n            \n            y_current = y_j  # Update point for the next continuation step\n        \n        return y_current\n\n    results = []\n    for case in test_cases:\n        y0, ds, N, tol, k_max = case['y0'], case['ds'], case['N'], case['tol'], case['k_max']\n        final_y = run_continuation(y0, ds, N, tol, k_max)\n        \n        # Format the result as a string with 6 decimal places.\n        rounded_y_str = [f\"{val:.6f}\" for val in final_y]\n        results.append(f\"[{','.join(rounded_y_str)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在实现了功能强大的伪弧长延拓方法后，一个自然的问题是：我们为什么需要这种相对复杂的机制？本练习通过一个经典的二次转折点问题，引导你从理论上剖析简单的“自然参数延拓法”的根本缺陷。通过对比两种方法在转折点附近的表现，你将清晰地看到，当系统的雅可比矩阵变得奇异时，自然参数法为何会效率剧降甚至完全失效，而伪弧长法又是如何通过构建一个始终非奇异的增广系统来保持其鲁棒性的。这个思辨练习是理解延拓方法设计哲学和其数值优势的关键一步。",
            "id": "3217902",
            "problem": "考虑单参数非线性方程族 $F(x,\\lambda)=0$ 的解的延拓，其中 $x\\in\\mathbb{R}$ 是状态变量，$\\lambda\\in\\mathbb{R}$ 是延拓参数。当 $F(x^{\\ast},\\lambda^{\\ast})=0$, $F_{x}(x^{\\ast},\\lambda^{\\ast})=0$, $F_{\\lambda}(x^{\\ast},\\lambda^{\\ast})\\neq 0$ 且 $F_{xx}(x^{\\ast},\\lambda^{\\ast})\\neq 0$ 时，在点 $(x^{\\ast},\\lambda^{\\ast})$ 处出现一个简单二次转向点（也称为简单折叠点）。有两种标准的预测-校正策略用于延拓解曲线：自然参数延拓（将 $\\lambda$ 视为自变量，并使用 Newton 法对 $x$ 进行校正）和伪弧长延拓（PALC）（使用弧长 $s$ 来参数化解曲线，其校正子求解由 $F(x,\\lambda)=0$ 和一个基于前一点切线方向的线性化弧长约束组成的增广系统）。\n\n为了比较它们在转向点附近的效率，我们分析标量测试问题 $F(x,\\lambda)=x^{2}-\\lambda$，其解集为曲线 $\\lambda=x^{2}$。从 $(x_{0},\\lambda_{0})=(1,1)$ 出发，假设我们尝试向较小的 $\\lambda$ 值延拓，并最终接近位于 $(x,\\lambda)=(0,0)$ 的转向点。对于自然参数延拓，在固定的目标 $\\lambda$ 下，Newton 校正子通过 Newton 法求解 $F(x,\\lambda)=0$ 来更新 $x$。对于伪弧长延拓，校正子求解一个 $2\\times 2$ 系统，该系统由 $F(x,\\lambda)=0$ 和一个基于前一点处解曲线切线 $(t_{x},t_{\\lambda})$ 的线性化弧长约束给出，其中切线满足 $F_{x}t_{x}+F_{\\lambda}t_{\\lambda}=0$ 和一个归一化条件（例如 $\\sqrt{t_{x}^{2}+t_{\\lambda}^{2}}=1$）。\n\n对于这个测试问题，以下哪个陈述最好地比较了自然参数延拓和伪弧长延拓在转向点附近的效率？\n\nA. 在二次转向点附近，自然参数延拓变得低效，因为 Newton 校正子面临一个病态的雅可比矩阵 $F_{x}\\approx 0$，因此需要越来越小的参数步长才能收敛；伪弧长延拓则保持了一个良态的校正雅可比矩阵，并且可以在转向点两侧采取相当大小的步长。\n\nB. 两种方法的条件数相同，因为问题是标量的；因此在转向点附近的效率差异可以忽略不计。\n\nC. 自然参数延拓在转向点附近更有效，因为它求解一个更小的系统；伪弧长延拓增加了一个方程和一个未知数，使得雅可比矩阵更大，从而更慢，这超过了任何条件数问题带来的影响。\n\nD. 只有伪弧长延拓能够通过从 $x>0$ 的分支跨越到 $x0$ 的分支，在有限步内稳健地穿过转向点，同时保持 Newton 收敛性，因为增广雅可比矩阵在简单二次转向点处保持非奇异；而自然参数延拓由于 $F_{x}=0$ 在转向点处通常无法收敛，并且不能仅使用 $\\lambda$ 作为参数稳健地跨越到另一个分支。",
            "solution": "问题陈述在内部是一致的，并且在科学上是合理的，提出了一个数值分析中用于比较延拓方法的标准问题。我们将针对给定的测试问题，分析其在转向点附近时自然参数延拓和伪弧长延拓的行为。\n\n测试问题由标量方程 $F(x, \\lambda) = x^2 - \\lambda = 0$ 给出。其解集是抛物线 $\\lambda = x^2$。转向点位于 $(x^{\\ast}, \\lambda^{\\ast}) = (0, 0)$，在该点，曲线相对于参数 $\\lambda$ “折返”。我们通过检查定义的条件来验证这是一个简单二次转向点：\n$F(0, 0) = 0^2 - 0 = 0$。\n偏导数为 $F_x(x, \\lambda) = 2x$、$F_\\lambda(x, \\lambda) = -1$ 和 $F_{xx}(x, \\lambda) = 2$。\n在转向点 $(0, 0)$ 处：\n$F_x(0, 0) = 2(0) = 0$。\n$F_\\lambda(0, 0) = -1 \\neq 0$。\n$F_{xx}(0, 0) = 2 \\neq 0$。\n简单二次转向点的所有条件都得到满足。\n\n**自然参数延拓分析**\n在自然参数延拓中，$\\lambda$ 被视为自变量。为了找到一个新的解点，首先固定一个新的参数值，例如 $\\lambda_{k+1}$，然后对状态变量 $x$ 求解方程 $F(x, \\lambda_{k+1}) = 0$。这通常使用牛顿法 (Newton's method) 完成。牛顿校正子的迭代更新规则是：\n$$x^{(j+1)} = x^{(j)} - \\frac{F(x^{(j)}, \\lambda_{k+1})}{F_x(x^{(j)}, \\lambda_{k+1})}$$\n该系统的雅可比矩阵是标量函数 $F_x(x, \\lambda) = 2x$。\n当解曲线 $(x, x^2)$ 接近转向点 $(0, 0)$ 时，我们必然有 $x \\to 0$。这意味着雅可比矩阵 $F_x \\to 0$。一个趋于零的雅可比矩阵在极限处是奇异的，在附近是病态的。\n这样做的后果是严重的：\n$1$. 对于重数大于 $1$ 的根，牛顿法的收敛速度从二次退化为线性（对于 $\\lambda=0$，$x^2=0$ 有一个重数为 $2$ 的根 $x=0$）。\n$2$. 由于除以一个接近于零的数，该方法变得数值不稳定。\n$3$. 参数步长 $\\Delta \\lambda = \\lambda_{k+1} - \\lambda_k$ 必须逐渐减小，以保持在牛顿求解器缩小的吸引盆内。\n$4$. 该方法无法穿过转向点。当我们从 $(1, 1)$ 向较小的 $\\lambda$ 接近时，我们沿着 $x>0$ 的分支移动。在转向点处，$\\lambda$ 达到其最小值 $0$。要继续到 $x0$ 的分支上，$\\lambda$ 必须再次增加。仅通过 $\\lambda$ 进行参数化不允许这种穿越。如果尝试选择一个 $\\lambda_{k+1}0$，方程 $x^2 - \\lambda_{k+1} = 0$ 没有实数解，方法完全失败。\n\n总而言之，自然参数延拓在转向点附近变得极其低效，并最终无法计算出超过该点的解曲线。\n\n**伪弧长延拓（PALC）分析**\n在 PALC 中，$x$ 和 $\\lambda$ 都被视为一个新参数，即伪弧长 $s$ 的因变量。校正步求解一个增广的 $2 \\times 2$ 方程组来确定新点 $(x, \\lambda)$：\n$$\n\\mathbf{G}(x, \\lambda) = \\begin{pmatrix} F(x, \\lambda) \\\\ N(x, \\lambda) \\end{pmatrix} = \\begin{pmatrix} x^2 - \\lambda \\\\ (x-x_k)t_x + (\\lambda-\\lambda_k)t_\\lambda - \\Delta s \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n这里，$N(x,\\lambda)=0$ 是线性化弧长约束。它约束新点 $(x, \\lambda)$ 位于一条与前一点 $(x_k, \\lambda_k)$ 处的切向量 $(t_x, t_\\lambda)$ 垂直的线上，距离为 $\\Delta s$。该系统的牛顿法使用雅可比矩阵：\n$$\n\\mathbf{J}(x, \\lambda) = \\nabla \\mathbf{G} = \\begin{pmatrix} F_x  F_\\lambda \\\\ N_x  N_\\lambda \\end{pmatrix} = \\begin{pmatrix} 2x  -1 \\\\ t_x  t_\\lambda \\end{pmatrix}\n$$\n切向量 $(t_x, t_\\lambda)$ 在校正迭代期间是常数，它是在前一点 $(x_k, \\lambda_k)$ 处计算得到的。\n关键的洞察是分析这个雅可比矩阵 $\\mathbf{J}$ 在转向点 $(0, 0)$ 处的条件。在该点，雅可比矩阵变为：\n$$\n\\mathbf{J}(0, 0) = \\begin{pmatrix} 0  -1 \\\\ t_x  t_\\lambda \\end{pmatrix}\n$$\n其行列式为 $\\det(\\mathbf{J}(0, 0)) = 0 \\cdot t_\\lambda - (-1) \\cdot t_x = t_x$。\n雅可比矩阵是非奇异的当且仅当 $t_x \\neq 0$。切向量 $(t_x, t_\\lambda)$ 是在前一点 $(x_k, \\lambda_k)$ 计算的，满足 $F_x t_x + F_\\lambda t_\\lambda = 0$，即 $2x_k t_x - 1 \\cdot t_\\lambda = 0$。对于曲线上除转向点本身以外的任何点 $(x_k, \\lambda_k)$，$x_k \\neq 0$。一个归一化的切向量是 $(t_x, t_\\lambda) \\propto (1, 2x_k)$。分量 $t_x$ 是非零的。当延拓接近转向点时，$x_k \\to 0$，切向量 $(t_x, t_\\lambda)$ 接近 $(\\pm 1, 0)$。因此，增广雅可比矩阵在转向点处的行列式接近 $\\pm 1$，它有界且不为零。\n因此，PALC 的增广雅可比矩阵在穿越简单转向点的整个过程中保持非奇异和良态。这确保了牛顿校正子保持其二次收敛率，从而允许在折叠点两侧采取大小相当的稳健步长 ($\\Delta s$)。该方法自然地沿着抛物线的 U 形轨迹进行，自动处理 $\\lambda$ 方向的变化，并从 $x>0$ 的分支跨越到 $x0$ 的分支。\n\n**选项评估**\n\nA. 在二次转向点附近，自然参数延拓变得低效，因为 Newton 校正子面临一个病态的雅可比矩阵 $F_{x}\\approx 0$，因此需要越来越小的参数步长才能收敛；伪弧长延拓则保持了一个良态的校正雅可比矩阵，并且可以在转向点两侧采取相当大小的步长。\n这个陈述是我们分析的精确总结。自然延拓的低效源于其雅可比矩阵 $F_x$ 的奇异性，而 PALC 的稳健性则归功于其增广雅可比矩阵的非奇异性。**正确**。\n\nB. 两种方法的条件数相同，因为问题是标量的；因此在转向点附近的效率差异可以忽略不计。\n这根本上是错误的。虽然原始问题涉及一个标量状态变量 $x$，但 PALC 将其转换为一个关于对 $(x, \\lambda)$ 的二维问题。$1 \\times 1$ 雅可比矩阵 $F_x$ 的条件与 $2 \\times 2$ 增广雅可比矩阵 $\\mathbf{J}$ 的条件完全不同。效率上的差异不可忽略；这是一个有效方法和一个失效方法之间的区别。**错误**。\n\nC. 自然参数延拓在转向点附近更有效，因为它求解一个更小的系统；伪弧长延拓增加了一个方程和一个未知数，使得雅可比矩阵更大，从而更慢，这超过了任何条件数问题带来的影响。\n这个陈述错误地权衡了计算成本。虽然 PALC 每次迭代确实求解一个更大的系统（一个 $2 \\times 2$ 系统对一个标量除法），但与自然延拓需要趋于无穷的步数（当步长趋于零时）来接近转向点，并且根本无法穿过它这一事实相比，这点稍高的每步成本是微不足道的。条件数问题是灾难性的，其影响不能被“超过”。**错误**。\n\nD. 只有伪弧长延拓能够通过从 $x>0$ 的分支跨越到 $x0$ 的分支，在有限步内稳健地穿过转向点，同时保持 Newton 收敛性，因为增广雅可比矩阵在简单二次转向点处保持非奇异；而自然参数延拓由于 $F_{x}=0$ 在转向点处通常无法收敛，并且不能仅使用 $\\lambda$ 作为参数稳健地跨越到另一个分支。\n这个陈述也是一个完整而准确的描述。它正确地指出了 PALC 的关键能力（稳健穿越、分支切换）及其根本原因（非奇异的增广雅可比矩阵）。它也正确地描述了自然延拓的失效模式（由于 $F_x=0$ 导致的收敛失败、无法跨越）。这抓住了比较的精髓。**正确**。\n\n陈述 A 和 D 都是对情况的正确描述。它们相辅相成，A 侧重于步长方面的效率，而 D 侧重于穿越能力与失效这一根本能力。由于两者都正确，它们都应该是最终答案的一部分。",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "掌握了跟踪单条解曲线的技巧后，我们可以开始探索更激动人心的应用：分析复杂系统的分岔行为。现实世界中的模型常常存在分岔点，即解曲线在此处“分叉”，衍生出新的解分支。本练习将向你展示如何扩展延拓方法框架，实现“分支切换”。你将学习如何通过引入一个微扰的辅助系统，巧妙地从一个已知的解分支“跳”到一个新的、由对称性破缺产生的解分支上。这项高级实践不仅是延拓方法功能的自然延伸，更是通向完整分岔分析和理解非线性现象丰富性的重要门户。",
            "id": "3217736",
            "problem": "要求您在延拓法的框架内，通过使用微扰辅助系统，在一个简单的叉式分岔点上实现分支切换算法。考虑由标量残差给出的、包含两个变量 $u$ 和 $\\lambda$ 的非线性代数方程\n$$\nF(u,\\lambda) = \\lambda\\,u - u^3,\n$$\n该方程具有对称性 $u \\mapsto -u$，并在点 $(u,\\lambda)=(0,0)$ 处表现出一个简单的叉式分岔。您的任务是编写一个完整、可运行的程序，该程序：\n- 实现伪弧长延拓以跟踪 $F(u,\\lambda)=0$ 的解曲线。\n- 通过求解一个微扰辅助系统，在分岔点进行分支切换，该系统使用一个小的目标值 $u=\\sigma$ 来为非平凡分支提供种子点。\n- 沿着选定的非平凡分支进行延拓，并计算在指定的目标参数值 $\\lambda_{\\text{target}}$ 处对应的解值 $u$。\n\n推导必须从基础数值分析原理和核心定义开始：\n- 延拓法是一种系统化的程序，通过沿着解曲线步进并通过求解局部适定问题进行校正，来追踪非线性方程的解流形。\n- 伪弧长法通过一个线性化的弧长约束来增广非线性系统，以在原始变量的雅可比矩阵接近奇异时仍能正则化校正步。\n- 在对称破缺的叉式分岔附近的分支切换事件可以通过施加一个辅助约束来引发，该约束会微扰对称平衡，例如，通过将状态变量 $u$ 固定到一个小的非零目标值 $u=\\sigma$。\n\n您必须实现以下算法组件：\n1. 构建微扰辅助系统\n$$\nG(u,\\lambda;\\sigma) = \\begin{bmatrix}\nF(u,\\lambda)\\\\\nu - \\sigma\n\\end{bmatrix} = \\begin{bmatrix}\n\\lambda\\,u - u^3\\\\\nu - \\sigma\n\\end{bmatrix},\n$$\n并通过牛顿法求解，以获得非平凡分支上的一个种子点 $(u_0,\\lambda_0)$。$\\sigma$ 的符号选择分支。\n2. 对于延拓，给定当前解 $(u_k,\\lambda_k)$，使用基本正交条件（即切线位于 $F$ 梯度零空间中）计算解曲线的单位切线 $(t_u, t_\\lambda)$。使用固定弧长步长 $\\Delta s$ 的预测子 $(u_{\\text{pred}},\\lambda_{\\text{pred}})=(u_k,\\lambda_k) + \\Delta s\\,(t_u,t_\\lambda)$。然后应用牛顿校正子求解增广系统\n$$\nH(u,\\lambda) = \\begin{bmatrix}\nF(u,\\lambda)\\\\\nt_u (u - u_{\\text{pred}}) + t_\\lambda (\\lambda - \\lambda_{\\text{pred}})\n\\end{bmatrix} = \\mathbf{0},\n$$\n使用由 $F$ 的偏导数和切线分量组成的 $2\\times 2$ 雅可比矩阵。对切线进行归一化，并使用一个驱动 $t_\\lambda > 0$ 的方向以增加 $\\lambda$。\n3. 一旦您沿着分支前进，通过牛顿法求解 $F(u,\\lambda_{\\text{target}})=0$ 来精确化在指定 $\\lambda_{\\text{target}}$ 处的解 $u$，从最新的延拓点开始迭代；保持 $u$ 的符号与由 $\\sigma$ 编码的所选分支一致。\n\n数值要求：\n- 使用固定的预测步长 $\\Delta s = 0.05$（弧长单位）。\n- 在每次校正和辅助求解中，使用牛顿法，收敛判据为校正量的范数小于 $10^{-12}$，最大迭代次数为 $12$。\n- 尽可能确保切线方向满足 $t_\\lambda > 0$，以便延拓朝向更大的 $\\lambda$ 值进行。\n- 在输出中将最终的 $u$ 值四舍五入到六位小数。\n\n测试套件和输出规范：\n- 您的程序必须运行由 $(\\sigma, \\lambda_{\\text{target}})$ 对指定的四个测试用例，这些用例探测了不同方面，包括正负分支以及与分岔点的邻近程度：\n    1. $(\\sigma, \\lambda_{\\text{target}}) = (0.01, 0.25)$。\n    2. $(\\sigma, \\lambda_{\\text{target}}) = (-0.02, 0.49)$。\n    3. $(\\sigma, \\lambda_{\\text{target}}) = (0.001, 0.0004)$。\n    4. $(\\sigma, \\lambda_{\\text{target}}) = (-0.0015, 0.0009)$。\n- 对每个测试用例，在 $(u,\\lambda)=(0,0)$ 处通过求解微扰辅助系统以获得 $(u_0,\\lambda_0)$ 来执行分支切换，然后使用伪弧长延拓步进，直到达到或超过 $\\lambda_{\\text{target}}$，最后使用单变量牛顿法精确化在 $\\lambda=\\lambda_{\\text{target}}$ 处的 $u$。\n- 您的程序应产生单行输出，其中包含四个结果 $u$ 值，四舍五入到六位小数，形式为用方括号括起来的逗号分隔列表，例如：“[u1,u2,u3,u4]”。不允许有多余的文本或空格。\n\n不使用角度，也没有物理单位。所有数值结果必须打印为纯十进制浮点数。",
            "solution": "该问题是有效的，因为它提出了一个数值分析领域内适定的、有科学依据的任务，特别是在应用于分岔理论的延拓方法领域。所有参数、方程和算法步骤都得到了精确定义，并与已建立的数值方法一致，从而可以得到一个唯一且可验证的解。\n\n该问题要求为非线性方程 $F(u,\\lambda) = \\lambda u - u^3 = 0$ 实现一个分支切换算法，该方程在原点 $(u,\\lambda) = (0,0)$ 处表现出叉式分岔。解曲线由一个对所有 $\\lambda$ 都成立的平凡分支 $u=0$ 和两个对 $\\lambda \\ge 0$ 成立的非平凡分支 $u = \\pm\\sqrt{\\lambda}$ 组成。目标是计算由参数 $\\sigma$ 选择的其中一个非平凡分支上的点。指定的算法包括三个主要阶段：为分支提供种子点、沿分支进行延拓以及精确化到目标参数值。\n\n**1. 通过微扰辅助系统进行分支切换（种子点生成）**\n\n在分岔点（如 $(u,\\lambda)=(0,0)$）的核心挑战是多条解分支在此相交，使得方向的选择变得模糊不清。标准的延拓方法通常会沿着平凡分支 $u=0$ 进行。为了切换到非平凡分支，我们引入一个微扰。该问题指定构建一个辅助系统 $G(u, \\lambda; \\sigma)$ 来打破原始问题的对称性。这是通过施加一个约束来实现的，即解必须通过一个具有小的非零 $u$ 值（$u=\\sigma$）的点。\n\n该系统定义为：\n$$\nG(u,\\lambda;\\sigma) = \\begin{bmatrix}\nF(u,\\lambda)\\\\\nu - \\sigma\n\\end{bmatrix} = \\begin{bmatrix}\n\\lambda u - u^3\\\\\nu - \\sigma\n\\end{bmatrix} = \\mathbf{0}\n$$\n这个系统的解为延拓过程提供了一个起始点 $(u_0, \\lambda_0)$。通过观察可知，解为 $u_0 = \\sigma$ 且 $\\lambda_0\\sigma - \\sigma^3 = 0$，对于 $\\sigma \\ne 0$ 这会导出 $\\lambda_0 = \\sigma^2$。因此，种子点是 $(u_0, \\lambda_0) = (\\sigma, \\sigma^2)$。\n\n尽管可以解析求解，但该问题要求使用牛顿法。对于状态向量 $\\mathbf{x} = [u, \\lambda]^T$，迭代格式为：\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - [J_G(\\mathbf{x}_k)]^{-1} G(\\mathbf{x}_k; \\sigma)\n$$\n其中 $J_G$ 是 $G$ 的雅可比矩阵：\n$$\nJ_G(u, \\lambda) = \\begin{bmatrix}\n\\frac{\\partial F}{\\partial u}  \\frac{\\partial F}{\\partial \\lambda} \\\\\n1  0\n\\end{bmatrix} = \\begin{bmatrix}\n\\lambda - 3u^2  u \\\\\n1  0\n\\end{bmatrix}\n$$\n对于这个牛顿求解，一个鲁棒的初始猜测是 $(\\sigma, 0)$，对于小的 $\\sigma$ 来说，它接近于精确解 $(\\sigma, \\sigma^2)$。\n\n**2. 伪弧长延拓**\n\n一旦在期望的分支上找到了一个点 $(u_k, \\lambda_k)$，我们使用预测-校正格式来追踪解曲线。采用伪弧长法来处理参数化问题，尤其是在转折点附近，此时参数 $\\lambda$ 不再是曲线的良好局部坐标。\n\n**2.1. 预测步**\n首先，我们在当前点 $(u_k, \\lambda_k)$ 计算解曲线的切向量 $(t_u, t_\\lambda)$。解曲线是 $F(u,\\lambda)=0$ 的一个水平集，因此切向量必须与梯度向量 $\\nabla F = (\\frac{\\partial F}{\\partial u}, \\frac{\\partial F}{\\partial \\lambda})$ 正交。一个与 $(\\frac{\\partial F}{\\partial u}, \\frac{\\partial F}{\\partial \\lambda})$ 正交的向量由 $(\\frac{\\partial F}{\\partial \\lambda}, -\\frac{\\partial F}{\\partial u})$ 给出。对于我们的问题，这便是：\n$$\n(t_u, t_\\lambda)_{\\text{unnormalized}} \\propto (u_k, -(\\lambda_k - 3u_k^2)) = (u_k, 3u_k^2 - \\lambda_k)\n$$\n为确保沿路径方向的一致性，该向量被归一化为单位长度，并且其方向被固定为 $t_\\lambda  0$，从而在可能的情况下强制延拓向着 $\\lambda$ 增大的方向进行。\n\n利用单位切线 $(t_u, t_\\lambda)$，通过从 $(u_k, \\lambda_k)$ 沿切线方向迈出大小为 $\\Delta s$ 的一步来计算预测点 $(u_{\\text{pred}}, \\lambda_{\\text{pred}})$：\n$$\n(u_{\\text{pred}}, \\lambda_{\\text{pred}}) = (u_k, \\lambda_k) + \\Delta s (t_u, t_\\lambda)\n$$\n其中 $\\Delta s = 0.05$ 是指定的弧长步长。\n\n**2.2. 校正步**\n预测点位于切线上，通常不在解曲线本身上。校正步的作用是找到曲线上附近的一个点。这被表述为求解一个增广系统 $H(u, \\lambda) = \\mathbf{0}$，该系统由原始方程和一个约束条件组成，该约束条件要求校正发生在垂直于切向量的方向上，并穿过预测点：\n$$\nH(u,\\lambda) = \\begin{bmatrix}\nF(u,\\lambda)\\\\\nt_u (u - u_{\\text{pred}}) + t_\\lambda (\\lambda - \\lambda_{\\text{pred}})\n\\end{bmatrix} = \\mathbf{0}\n$$\n该系统使用牛顿法求解，以 $(u_{\\text{pred}}, \\lambda_{\\text{pred}})$ 作为初始猜测。此系统的雅可比矩阵 $J_H$ 为：\n$$\nJ_H(u, \\lambda) = \\begin{bmatrix}\n\\frac{\\partial F}{\\partial u}  \\frac{\\partial F}{\\partial \\lambda} \\\\\nt_u  t_\\lambda\n\\end{bmatrix} = \\begin{bmatrix}\n\\lambda - 3u^2  u \\\\\nt_u  t_\\lambda\n\\end{bmatrix}\n$$\n该雅可比矩阵在正则点和简单转折点处都是非奇异的，这使得伪弧长法很鲁棒。此牛顿迭代的解给出曲线上的下一个点 $(u_{k+1}, \\lambda_{k+1})$。重复此预测-校正循环，直到参数值 $\\lambda$ 超过目标值，即 $\\lambda_{k+1} \\ge \\lambda_{\\text{target}}$。\n\n**3. 解的精确化**\n\n最后的延拓点，记为 $(u_c, \\lambda_c)$，有 $\\lambda_c \\ge \\lambda_{\\text{target}}$ 但通常 $\\lambda_c \\ne \\lambda_{\\text{target}}$。为了在 $\\lambda = \\lambda_{\\text{target}}$ 处找到精确解 $u$，我们求解参数固定的原始标量方程：\n$$\nf(u) = F(u, \\lambda_{\\text{target}}) = \\lambda_{\\text{target}} u - u^3 = 0\n$$\n这是一个关于单变量 $u$ 的求根问题。它通过标量函数的牛顿法求解：\n$$\nu_{m+1} = u_m - \\frac{f(u_m)}{f'(u_m)} = u_m - \\frac{\\lambda_{\\text{target}} u_m - u_m^3}{\\lambda_{\\text{target}} - 3u_m^2}\n$$\n本次迭代的初始猜测 $u_0$ 取自最后计算出的延拓点 $u_c$。这确保了迭代收敛到所追踪分支上的正确根（即与 $\\sigma$ 符号相同的根）。收敛后的 $u$ 值即为给定测试用例的最终答案。\n\n对于测试套件中提供的每个 $(\\sigma, \\lambda_{\\text{target}})$ 对，实现将遵循这三个阶段。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Global constants for the numerical methods\nTOL = 1e-12\nMAX_ITER = 12\nDS = 0.05\n\ndef F_func(u, lam):\n    \"\"\"The residual function F(u, lambda).\"\"\"\n    return lam * u - u**3\n\ndef dF_du(u, lam):\n    \"\"\"Partial derivative of F with respect to u.\"\"\"\n    return lam - 3 * u**2\n\ndef dF_dlam(u, lam):\n    \"\"\"Partial derivative of F with respect to lambda.\"\"\"\n    return u\n\ndef newton_2d(func, jac, x0, tol, max_iter):\n    \"\"\"Solves a 2D system f(x)=0 using Newton's method.\"\"\"\n    x = np.array(x0, dtype=np.float64)\n    for _ in range(max_iter):\n        J = jac(x)\n        F_val = func(x)\n        if np.abs(np.linalg.det(J))  1e-20:\n            return x, False\n        delta = np.linalg.solve(J, -F_val)\n        x += delta\n        if np.linalg.norm(delta)  tol:\n            return x, True\n    return x, False\n\ndef newton_1d(func, deriv, x0, tol, max_iter):\n    \"\"\"Solves a 1D equation f(x)=0 using Newton's method.\"\"\"\n    x = np.float64(x0)\n    for _ in range(max_iter):\n        f_val = func(x)\n        df_val = deriv(x)\n        if abs(df_val)  1e-20:\n            return x, False\n        delta = -f_val / df_val\n        x += delta\n        if abs(delta)  tol:\n            return x, True\n    return x, False\n\ndef trace_branch(sigma, lambda_target, ds):\n    \"\"\"\n    Performs branch-switching, pseudo-arclength continuation, and refinement.\n    \"\"\"\n    # Stage 1: Branch Switching (Seeding)\n    def G_seed(x):\n        u, lam = x\n        return np.array([F_func(u, lam), u - sigma], dtype=np.float64)\n\n    def J_G_seed(x):\n        u, lam = x\n        return np.array([\n            [dF_du(u, lam), dF_dlam(u, lam)],\n            [1.0, 0.0]\n        ], dtype=np.float64)\n\n    seed_guess = np.array([sigma, 0.0])\n    seed_point, converged = newton_2d(G_seed, J_G_seed, seed_guess, TOL, MAX_ITER)\n    if not converged:\n        raise RuntimeError(f\"Seeding Newton failed for sigma={sigma}\")\n    \n    u_k, lambda_k = seed_point\n\n    # Stage 2: Pseudo-Arclength Continuation\n    while lambda_k  lambda_target:\n        # --- Predictor Step ---\n        tu_un = dF_dlam(u_k, lambda_k)\n        tlam_un = -dF_du(u_k, lambda_k)\n        \n        if tlam_un  0:\n            tu_un *= -1.0\n            tlam_un *= -1.0\n            \n        norm = np.sqrt(tu_un**2 + tlam_un**2)\n        if norm  1e-15:\n            raise RuntimeError(\"Tangent norm is zero during continuation.\")\n        t_u = tu_un / norm\n        t_lambda = tlam_un / norm\n\n        u_pred = u_k + ds * t_u\n        lambda_pred = lambda_k + ds * t_lambda\n        \n        # --- Corrector Step ---\n        def H_corr(x):\n            u, lam = x\n            return np.array([\n                F_func(u, lam),\n                t_u * (u - u_pred) + t_lambda * (lam - lambda_pred)\n            ], dtype=np.float64)\n        \n        def J_H_corr(x):\n            u, lam = x\n            return np.array([\n                [dF_du(u, lam), dF_dlam(u, lam)],\n                [t_u, t_lambda]\n            ], dtype=np.float64)\n            \n        corr_guess = np.array([u_pred, lambda_pred])\n        next_point, converged = newton_2d(H_corr, J_H_corr, corr_guess, TOL, MAX_ITER)\n        \n        if not converged:\n            raise RuntimeError(f\"Corrector Newton failed for target lambda={lambda_target}\")\n            \n        u_k, lambda_k = next_point\n    \n    # Stage 3: Refinement\n    def f_refine(u):\n        return F_func(u, lambda_target)\n        \n    def df_refine(u):\n        return dF_du(u, lambda_target)\n        \n    refine_guess = u_k\n    final_u, converged = newton_1d(f_refine, df_refine, refine_guess, TOL, MAX_ITER)\n    \n    if not converged:\n        raise RuntimeError(f\"Refinement Newton failed for target lambda={lambda_target}\")\n        \n    return final_u\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (sigma, lambda_target)\n        (0.01, 0.25),\n        (-0.02, 0.49),\n        (0.001, 0.0004),\n        (-0.0015, 0.0009),\n    ]\n\n    results = []\n    for sigma, lambda_target in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        u_final = trace_branch(sigma, lambda_target, DS)\n        results.append(f\"{u_final:.6f}\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}