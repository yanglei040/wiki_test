{
    "hands_on_practices": [
        {
            "introduction": "我们从一个基础练习开始。该问题将引导您从第一性原理出发，一步步推导使用一个简单的线性控制变体所能实现的方差缩减。通过完成这个练习 ，您将巩固对控制变体核心机制的理解，包括如何计算最优系数 $c^{\\star}$ 以及如何量化由此带来的效率提升。",
            "id": "3218918",
            "problem": "考虑使用蒙特卡洛（MC）方法估计定积分 $I = \\int_{0}^{1} x^{2} \\, dx$ ，其中有 $n$ 个从 $\\text{Uniform}[0,1]$ 分布中抽取的独立同分布样本 $U_{1}, \\dots, U_{n}$。定义普通MC估计量为 $\\hat{I}_{\\text{MC}} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i}$，其中 $X_{i} = U_{i}^{2}$。现在应用控制变量（CV）技术，使用已知均值 $\\mathbb{E}[Y] = \\frac{1}{2}$ 的控制变量 $Y = U$，并定义调整后样本 $Z_{c} = X - c\\,(Y - \\mathbb{E}[Y])$ 和相应的估计量 $\\hat{I}_{\\text{CV}}(c) = \\frac{1}{n} \\sum_{i=1}^{n} Z_{c,i}$。\n\n从期望、方差和协方差的定义出发，利用微积分和代数基础，推导使 $\\operatorname{Var}(Z_{c})$ 最小化的值 $c^{\\star}$，然后计算方差缩减因子\n$$\nR = \\frac{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{CV}}(c^{\\star})\\big)}{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{MC}}\\big)}.\n$$\n以单个有理数的形式提供 $R$ 的精确值。不需要四舍五入；将最终答案表示为有理数。",
            "solution": "用户希望找到一个蒙特卡洛积分问题的最优控制变量系数以及由此产生的方差缩减。\n\n### 步骤 1：提取已知条件\n- 待估计的积分为 $I = \\int_{0}^{1} x^{2} \\, dx$。\n- 抽样分布为 $U_i \\sim \\text{Uniform}[0,1]$，其中 $i = 1, \\dots, n$。\n- 普通蒙特卡洛估计量为 $\\hat{I}_{\\text{MC}} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i}$，其中 $X_i = U_i^2$。\n- 控制变量为 $Y = U$，其已知均值为 $\\mathbb{E}[Y] = \\frac{1}{2}$。\n- 控制变量随机变量为 $Z_c = X - c(Y - \\mathbb{E}[Y])$。\n- 控制变量估计量为 $\\hat{I}_{\\text{CV}}(c) = \\frac{1}{n} \\sum_{i=1}^{n} Z_{c,i}$。\n- 目标是找到使 $\\operatorname{Var}(Z_c)$ 最小化的值 $c^{\\star}$，然后计算方差缩减因子 $R = \\frac{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{CV}}(c^{\\star})\\big)}{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{MC}}\\big)}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题是数值方法领域，特别是蒙特卡洛技术中的一个定义明确的标准练习。\n- **科学依据：** 该问题基于概率论、统计学和微积分的既定原则。所有概念（蒙特卡洛积分、控制变量、方差、协方差）都是标准的。\n- **适定性：** 该问题提供了推导 $c^{\\star}$ 和 $R$ 的唯一解所需的所有信息。目标清晰明确。\n- **客观性：** 该问题以精确的数学语言陈述，不含主观或定性陈述。\n\n该问题不违反任何无效性标准。它在科学计算的范围内是一个完整、一致且可解的问题。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整解答。\n\n### 解题推导\n\n目标是找到最小化控制变量估计量方差的最优系数 $c^{\\star}$，然后计算方差缩减因子。\n\n控制变量估计量的随机变量为 $Z_c = X - c(Y - \\mathbb{E}[Y])$。其方差是 $c$ 的函数。由于 $\\mathbb{E}[Y]$ 是一个常数，它不影响方差。\n$$\n\\operatorname{Var}(Z_c) = \\operatorname{Var}(X - cY)\n$$\n利用方差的性质，我们可以展开这个表达式：\n$$\n\\operatorname{Var}(Z_c) = \\operatorname{Var}(X) + \\operatorname{Var}(cY) - 2\\operatorname{Cov}(X, cY)\n$$\n$$\n\\operatorname{Var}(Z_c) = \\operatorname{Var}(X) + c^2\\operatorname{Var}(Y) - 2c\\operatorname{Cov}(X, Y)\n$$\n这个表达式是关于 $c$ 的二次函数。为了找到使该方差最小化的值 $c^{\\star}$，我们对 $c$ 求导并令其为 $0$：\n$$\n\\frac{d}{dc}\\operatorname{Var}(Z_c) = 2c\\operatorname{Var}(Y) - 2\\operatorname{Cov}(X, Y)\n$$\n将导数设为零，得到：\n$$\n2c^{\\star}\\operatorname{Var}(Y) - 2\\operatorname{Cov}(X, Y) = 0\n$$\n$$\nc^{\\star} = \\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}\n$$\n为了计算 $c^{\\star}$，我们必须计算 $\\operatorname{Var}(Y)$ 和 $\\operatorname{Cov}(X, Y)$。这需要计算随机变量 $X = U^2$ 和 $Y = U$ 的矩，其中 $U \\sim \\text{Uniform}[0,1]$。\n\n一个随机变量 $U \\sim \\text{Uniform}[0,1]$ 的 $k$ 阶矩由下式给出：\n$$\n\\mathbb{E}[U^k] = \\int_{0}^{1} u^k \\cdot 1 \\, du = \\left[ \\frac{u^{k+1}}{k+1} \\right]_{0}^{1} = \\frac{1}{k+1}\n$$\n首先，我们计算 $Y=U$ 的矩和方差。\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[U] = \\frac{1}{1+1} = \\frac{1}{2}\n$$\n$$\n\\mathbb{E}[Y^2] = \\mathbb{E}[U^2] = \\frac{1}{2+1} = \\frac{1}{3}\n$$\n$Y$ 的方差是：\n$$\n\\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2 = \\frac{1}{3} - \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{3} - \\frac{1}{4} = \\frac{4-3}{12} = \\frac{1}{12}\n$$\n接下来，我们计算 $X=U^2$ 的矩和方差。\n$$\n\\mathbb{E}[X] = \\mathbb{E}[U^2] = \\frac{1}{2+1} = \\frac{1}{3}\n$$\n这就是积分 $I = \\int_0^1 x^2 dx$ 的真实值。\n$$\n\\mathbb{E}[X^2] = \\mathbb{E}[(U^2)^2] = \\mathbb{E}[U^4] = \\frac{1}{4+1} = \\frac{1}{5}\n$$\n$X$ 的方差是：\n$$\n\\operatorname{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = \\frac{1}{5} - \\left(\\frac{1}{3}\\right)^2 = \\frac{1}{5} - \\frac{1}{9} = \\frac{9-5}{45} = \\frac{4}{45}\n$$\n现在，我们计算 $X$ 和 $Y$ 之间的协方差。\n$$\n\\operatorname{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n$$\n$\\mathbb{E}[XY]$ 项是：\n$$\n\\mathbb{E}[XY] = \\mathbb{E}[U^2 \\cdot U] = \\mathbb{E}[U^3] = \\frac{1}{3+1} = \\frac{1}{4}\n$$\n所以，协方差是：\n$$\n\\operatorname{Cov}(X, Y) = \\frac{1}{4} - \\left(\\frac{1}{3}\\right)\\left(\\frac{1}{2}\\right) = \\frac{1}{4} - \\frac{1}{6} = \\frac{3-2}{12} = \\frac{1}{12}\n$$\n我们现在可以计算最优系数 $c^{\\star}$：\n$$\nc^{\\star} = \\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)} = \\frac{1/12}{1/12} = 1\n$$\n下一步是计算方差缩减因子 $R$。\n估计量 $\\hat{I}_{\\text{MC}}$ 和 $\\hat{I}_{\\text{CV}}(c)$ 是 $n$ 个独立同分布样本的平均值。因此，它们的方差与单个样本的方差关系如下：\n$$\n\\operatorname{Var}(\\hat{I}_{\\text{MC}}) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}(X_i) = \\frac{n \\operatorname{Var}(X)}{n^2} = \\frac{\\operatorname{Var}(X)}{n}\n$$\n$$\n\\operatorname{Var}(\\hat{I}_{\\text{CV}}(c^{\\star})) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n Z_{c^{\\star},i}\\right) = \\frac{\\operatorname{Var}(Z_{c^{\\star}})}{n}\n$$\n方差缩减因子 $R$ 是这两个方差的比值：\n$$\nR = \\frac{\\operatorname{Var}(\\hat{I}_{\\text{CV}}(c^{\\star}))}{\\operatorname{Var}(\\hat{I}_{\\text{MC}})} = \\frac{\\operatorname{Var}(Z_{c^{\\star}})/n}{\\operatorname{Var}(X)/n} = \\frac{\\operatorname{Var}(Z_{c^{\\star}})}{\\operatorname{Var}(X)}\n$$\n我们需要找到最小化后的方差 $\\operatorname{Var}(Z_{c^{\\star}})$。我们将 $c^{\\star}$ 代入 $\\operatorname{Var}(Z_c)$ 的表达式中：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\operatorname{Var}(X) + (c^{\\star})^2\\operatorname{Var}(Y) - 2c^{\\star}\\operatorname{Cov}(X, Y)\n$$\n代入 $c^{\\star} = \\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}$：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\operatorname{Var}(X) + \\left(\\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}\\right)^2 \\operatorname{Var}(Y) - 2\\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}\\operatorname{Cov}(X, Y)\n$$\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\operatorname{Var}(X) + \\frac{\\operatorname{Cov}(X, Y)^2}{\\operatorname{Var}(Y)} - 2\\frac{\\operatorname{Cov}(X, Y)^2}{\\operatorname{Var}(Y)} = \\operatorname{Var}(X) - \\frac{\\operatorname{Cov}(X, Y)^2}{\\operatorname{Var}(Y)}\n$$\n现在，我们代入计算出的数值：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\frac{4}{45} - \\frac{(1/12)^2}{1/12} = \\frac{4}{45} - \\frac{1}{12}\n$$\n为了进行分数减法，我们找到一个公分母，即 $180$：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\frac{4 \\cdot 4}{180} - \\frac{1 \\cdot 15}{180} = \\frac{16 - 15}{180} = \\frac{1}{180}\n$$\n最后，我们计算方差缩减因子 $R$：\n$$\nR = \\frac{\\operatorname{Var}(Z_{c^{\\star}})}{\\operatorname{Var}(X)} = \\frac{1/180}{4/45} = \\frac{1}{180} \\cdot \\frac{45}{4} = \\frac{45}{720}\n$$\n化简该分数：\n$$\nR = \\frac{1 \\cdot 45}{16 \\cdot 45} = \\frac{1}{16}\n$$\n方差被缩减了 16 倍。",
            "answer": "$$\n\\boxed{\\frac{1}{16}}\n$$"
        },
        {
            "introduction": "一个常见的误区是认为零相关性意味着在缩减方差方面不存在有用的关系。本练习  通过构建一个场景来挑战这一观念，其中两个变量的线性相关性为零，但其中一个变量可以作为另一个变量的高效非线性控制变体。这个思想实验将深化您对方法有效性的直觉，揭示其关键在于变量间潜在的函数依赖关系，而不仅仅是线性相关系数。",
            "id": "3218904",
            "problem": "考虑一个均值 $\\mu = \\mathbb{E}[X]$ 的蒙特卡洛估计问题，其中您可以获取两个随机变量 $X$ 和 $Y$ 的样本。您将构造一个 $(X,Y)$ 的联合分布，其中皮尔逊相关系数 $\\rho(X,Y)$ 为零，但一个非线性控制变量 $Z = g(Y)$ 却能带来非常大的方差缩减。仅使用期望、方差、协方差的基本定义以及正态分布的性质。\n\n设 $Y \\sim \\mathcal{N}(0,1)$ 且 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，与 $Y$ 独立，其中 $\\sigma^{2} = 0.01$。定义\n$$\nX = (Y^{2} - 1) + \\varepsilon\n$$\n并考虑非线性控制变量\n$$\nZ = g(Y) = Y^{2} - 1,\n$$\n其均值 $\\mathbb{E}[Z]$ 可从 $Y$ 的分布中得知。\n\n任务：\n- 使用协方差的核心定义和标准正态分布的矩的性质，验证协方差 $\\operatorname{Cov}(X,Y)$ 等于 $0$，因此相关系数 $\\rho(X,Y)$ 等于 $0$。\n- 从方差和协方差的定义出发，不假设任何特定公式，推导使 $\\mu$ 的调整后估计量 $X - \\beta(Z - \\mathbb{E}[Z])$ 的方差最小化的系数 $\\beta$ 的值。\n- 计算在最优 $\\beta$ 选择下，调整后估计量的单样本方差，以及方差缩减因子\n$$\nR = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big)}。\n$$\n\n以有序对 $(\\beta^{\\star}, R)$ 的精确形式提供您的最终答案。无需四舍五入。最终答案必须是按规定进行的计算。",
            "solution": "该问题陈述经核实具有科学依据，问题提出得当且客观。它构成了一个概率论和数值方法的正式练习。所有必要信息均已提供，任务定义明确。我们可以开始求解。\n\n该问题要求完成与蒙特卡洛估计情景相关的三个任务。我们已知随机变量 $Y \\sim \\mathcal{N}(0,1)$ 和 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，其中 $\\sigma^{2} = 0.01$。随机变量 $Y$ 和 $\\varepsilon$ 是独立的。我们关心的变量是 $X = (Y^{2} - 1) + \\varepsilon$，控制变量是 $Z = g(Y) = Y^{2} - 1$。\n\n首先，我们确定标准正态变量 $Y$ 的必要矩。\n$Y$ 的概率密度函数关于 $0$ 对称。因此，$Y$ 的所有奇数阶矩均为零。\n$\\mathbb{E}[Y] = 0$\n$\\mathbb{E}[Y^3] = 0$\n偶数阶矩是众所周知的。由于均值为零，二阶矩即为方差：\n$\\mathbb{E}[Y^2] = \\operatorname{Var}(Y) = 1$\n标准正态分布的四阶矩是：\n$\\mathbb{E}[Y^4] = 3$\n\n有了这些，我们就可以确定 $X$ 和 $Z$ 的性质。\n$Z$ 的均值是：\n$\\mathbb{E}[Z] = \\mathbb{E}[Y^2 - 1] = \\mathbb{E}[Y^2] - 1 = 1 - 1 = 0$。\n$X$ 的均值，即待估计的量 $\\mu$，是：\n$\\mu = \\mathbb{E}[X] = \\mathbb{E}[(Y^2 - 1) + \\varepsilon] = \\mathbb{E}[Y^2 - 1] + \\mathbb{E}[\\varepsilon] = \\mathbb{E}[Z] + 0 = 0$。\n\n**任务1：验证 $\\operatorname{Cov}(X,Y) = 0$**\n\n协方差定义为 $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$。\n我们有 $\\mathbb{E}[Y] = 0$，所以第二项消失：\n$\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X] \\cdot 0 = \\mathbb{E}[XY]$。\n我们通过代入 $X$ 的定义来计算 $\\mathbb{E}[XY]$：\n$\\mathbb{E}[XY] = \\mathbb{E}[((Y^2 - 1) + \\varepsilon)Y] = \\mathbb{E}[Y^3 - Y + \\varepsilon Y]$。\n根据期望的线性性质：\n$\\mathbb{E}[XY] = \\mathbb{E}[Y^3] - \\mathbb{E}[Y] + \\mathbb{E}[\\varepsilon Y]$。\n如前所述，$\\mathbb{E}[Y^3] = 0$ 且 $\\mathbb{E}[Y] = 0$。对于最后一项，由于 $\\varepsilon$ 和 $Y$ 是独立的，$\\mathbb{E}[\\varepsilon Y] = \\mathbb{E}[\\varepsilon]\\mathbb{E}[Y]$。我们知道 $\\mathbb{E}[\\varepsilon]=0$ 和 $\\mathbb{E}[Y]=0$，所以 $\\mathbb{E}[\\varepsilon Y] = 0 \\cdot 0 = 0$。\n因此，$\\mathbb{E}[XY] = 0 - 0 + 0 = 0$。\n这证实了 $\\operatorname{Cov}(X,Y) = 0$。\n皮尔逊相关系数为 $\\rho(X,Y) = \\frac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}$。由于分子为 $0$ 且方差非零（稍后将证明），所以 $\\rho(X,Y) = 0$。\n\n**任务2：推导最优系数 $\\beta^{\\star}$**\n\n我们的任务是找到 $\\beta$ 的值，记作 $\\beta^{\\star}$，以最小化调整后估计量 $X_{\\beta} = X - \\beta(Z - \\mathbb{E}[Z])$ 的方差。令 $V(\\beta) = \\operatorname{Var}(X_{\\beta})$。\n由于 $\\mathbb{E}[Z] = 0$，估计量为 $X_{\\beta} = X - \\beta Z$。\n需要最小化的方差是：\n$V(\\beta) = \\operatorname{Var}(X - \\beta Z)$。\n利用方差的性质，其中 $\\beta$ 是一个常数：\n$V(\\beta) = \\operatorname{Var}(X) + \\operatorname{Var}(-\\beta Z) + 2\\operatorname{Cov}(X, -\\beta Z)$。\n$V(\\beta) = \\operatorname{Var}(X) + \\beta^{2}\\operatorname{Var}(Z) - 2\\beta\\operatorname{Cov}(X, Z)$。\n这是一个关于 $\\beta$ 的二次函数。为了找到最小值，我们计算其关于 $\\beta$ 的导数并令其为零：\n$\\frac{d V}{d\\beta} = \\frac{d}{d\\beta} \\left( \\operatorname{Var}(X) + \\beta^{2}\\operatorname{Var}(Z) - 2\\beta\\operatorname{Cov}(X, Z) \\right) = 2\\beta\\operatorname{Var}(Z) - 2\\operatorname{Cov}(X, Z)$。\n令导数为零：\n$2\\beta\\operatorname{Var}(Z) - 2\\operatorname{Cov}(X, Z) = 0$。\n求解最优系数 $\\beta^{\\star}$：\n$\\beta^{\\star} = \\frac{\\operatorname{Cov}(X, Z)}{\\operatorname{Var}(Z)}$。\n二阶导数 $\\frac{d^2 V}{d\\beta^2} = 2\\operatorname{Var}(Z)$ 为正，因为方差是非负的（在本例中为非零），这确认了该点为最小值。\n\n**任务3：计算 $\\beta^{\\star}$ 和方差缩减因子 $R$**\n\n要计算 $\\beta^{\\star}$，我们需要计算 $\\operatorname{Var}(Z)$ 和 $\\operatorname{Cov}(X,Z)$。\n首先，我们求控制变量 $Z$ 的方差：\n$\\operatorname{Var}(Z) = \\mathbb{E}[Z^2] - (\\mathbb{E}[Z])^2$。由于 $\\mathbb{E}[Z]=0$，$\\operatorname{Var}(Z) = \\mathbb{E}[Z^2]$。\n$\\operatorname{Var}(Z) = \\mathbb{E}[(Y^2-1)^2] = \\mathbb{E}[Y^4 - 2Y^2 + 1]$。\n利用期望的线性和 $Y$ 的矩：\n$\\operatorname{Var}(Z) = \\mathbb{E}[Y^4] - 2\\mathbb{E}[Y^2] + 1 = 3 - 2(1) + 1 = 2$。\n\n接下来，我们计算 $X$ 和 $Z$ 之间的协方差：\n$\\operatorname{Cov}(X,Z) = \\mathbb{E}[XZ] - \\mathbb{E}[X]\\mathbb{E}[Z]$。\n由于 $\\mathbb{E}[X] = 0$ 且 $\\mathbb{E}[Z] = 0$，我们有 $\\operatorname{Cov}(X,Z) = \\mathbb{E}[XZ]$。\n代入 $X = Z + \\varepsilon$：\n$\\operatorname{Cov}(X,Z) = \\mathbb{E}[(Z+\\varepsilon)Z] = \\mathbb{E}[Z^2 + \\varepsilon Z] = \\mathbb{E}[Z^2] + \\mathbb{E}[\\varepsilon Z]$。\n我们知道 $\\mathbb{E}[Z^2] = \\operatorname{Var}(Z) = 2$。\n对于项 $\\mathbb{E}[\\varepsilon Z]$，我们利用 $\\varepsilon$ 和 $Y$ 的独立性。由于 $Z = Y^2-1$ 是 $Y$ 的函数，所以 $Z$ 和 $\\varepsilon$ 也是独立的。\n因此，$\\mathbb{E}[\\varepsilon Z] = \\mathbb{E}[\\varepsilon]\\mathbb{E}[Z] = 0 \\cdot 0 = 0$。\n所以，$\\operatorname{Cov}(X,Z) = 2 + 0 = 2$。\n\n现在我们可以计算最优系数 $\\beta^{\\star}$：\n$\\beta^{\\star} = \\frac{\\operatorname{Cov}(X, Z)}{\\operatorname{Var}(Z)} = \\frac{2}{2} = 1$。\n\n最后，我们计算方差缩减因子 $R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big)}$。\n首先，是分子 $\\operatorname{Var}(X)$：\n$X = Z + \\varepsilon$。由于 $Z$ 和 $\\varepsilon$ 是独立的，它们和的方差等于它们方差的和：\n$\\operatorname{Var}(X) = \\operatorname{Var}(Z) + \\operatorname{Var}(\\varepsilon) = 2 + \\sigma^2 = 2 + 0.01 = 2.01$。\n\n接下来是分母，即最优 $\\beta^{\\star}=1$ 和 $\\mathbb{E}[Z]=0$ 时调整后估计量的方差：\n$\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big) = \\operatorname{Var}(X - 1 \\cdot (Z - 0)) = \\operatorname{Var}(X-Z)$。\n代入 $X = Z + \\varepsilon$：\n$\\operatorname{Var}(X-Z) = \\operatorname{Var}((Z+\\varepsilon) - Z) = \\operatorname{Var}(\\varepsilon)$。\n我们已知 $\\operatorname{Var}(\\varepsilon) = \\sigma^2 = 0.01$。\n\n现在，我们可以计算方差缩减因子 $R$：\n$R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(X-Z)} = \\frac{2.01}{0.01} = 201$。\n\n最终答案是有序对 $(\\beta^{\\star}, R)$。\n$\\beta^{\\star} = 1$\n$R = 201$\n最终的对是 $(1, 201)$。",
            "answer": "$$\n\\boxed{(1, 201)}\n$$"
        },
        {
            "introduction": "控制变体最强大的应用之一是估计期望值对参数变化的敏感性。这个实践问题  将指导您实现一种常用技术，即利用基线模拟结果作为控制变体来高效地估计由参数变化引起的期望值变动。这项编码练习展示了一种在金融和工程等领域广泛使用的方法，为您在复杂模型中高效计算导数或有限差分提供了实用工具。",
            "id": "3218894",
            "problem": "您的任务是使用蒙特卡洛模拟和控制变量方法来估计期望值的变化。目标是通过使用 $f(X; \\theta_0)$ 作为估计 $E[f(X; \\theta_1)]$ 的控制变量，来高效地估计差值 $E[f(X; \\theta_1)] - E[f(X; \\theta_0)]$。请在以下数学定义的设置中进行操作。\n\n基本基础：\n- 令 $X$ 是一个服从标准正态分布的随机变量，即 $X \\sim \\mathcal{N}(0, 1)$。\n- 令 $f(x; \\theta) = \\exp(\\theta x)$，其中 $\\theta$ 为实数参数。\n- 对于任何实数 $\\theta$，期望 $E[f(X; \\theta)]$ 都是有明确定义且有限的。\n- 期望、方差和协方差定义如下：$E[Y] = \\int y \\, dP$，$ \\operatorname{Var}(Y) = E\\left[(Y - E[Y])^2\\right]$，以及 $\\operatorname{Cov}(Y, Z) = E\\left[(Y - E[Y])(Z - E[Z])\\right]$，其中 $P$ 是底层的概率测度。\n\n任务：\n1. 仅从期望的线性性质以及方差和协方差的定义出发，推导出一个使用 $f(X; \\theta_0)$ 作为控制变量来估计 $E[f(X; \\theta_1)]$ 的线性控制变量估计量的系数。考虑形式如下的估计量\n   $$\\widehat{\\mu}(\\beta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right),$$\n   其中 $Y_i = f(X_i; \\theta_1)$，$G_i = f(X_i; \\theta_0)$，$\\mu_0 = E[f(X; \\theta_0)]$，且 $X_i$ 是从 $X$ 中抽取的独立同分布样本。推导使 $\\widehat{\\mu}(\\beta)$ 方差最小化的 $\\beta$ 的选择，并证明 $\\widehat{\\mu}(\\beta)$ 对于 $E[f(X; \\theta_1)]$ 是无偏的。\n2. 实现一个蒙特卡洛算法，该算法：\n   - 从 $X$ 生成 $N$ 个独立样本 $X_i$。\n   - 计算朴素差分估计量 $\\widehat{\\Delta}_{\\mathrm{naive}} = \\overline{Y} - \\overline{G}$，其中 $\\overline{Y} = \\frac{1}{N}\\sum_{i=1}^{N} Y_i$ 且 $\\overline{G} = \\frac{1}{N}\\sum_{i=1}^{N} G_i$。\n   - 使用任务1中推导出的最优系数计算 $E[f(X; \\theta_1)]$ 的控制变量估计，然后计算差分估计 $\\widehat{\\Delta}_{\\mathrm{cv}} = \\widehat{\\mu}(\\widehat{\\beta}) - \\mu_0$，其中 $\\widehat{\\beta}$ 是最优系数的基于样本的估计。\n   - 当 $\\mu_0$ 的精确值和精确差值 $E[f(X; \\theta_1)] - E[f(X; \\theta_0)]$ 可以从经过充分检验的公式和事实中获得时，使用这些精确值。对于 $X \\sim \\mathcal{N}(0, 1)$ 和 $f(x; \\theta) = \\exp(\\theta x)$，使用已知的正态分布矩生成函数来提供用于比较的精确值。\n3. 使用以下参数值测试套件来评估您的算法。每个测试用例是一个元组 $(\\theta_0, \\theta_1, N, \\text{seed})$：\n   - 用例1（理想情况，参数接近）：(0.50, 0.60, 200000, 12345)。\n   - 用例2（边界情况，无变化）：(0.75, 0.75, 50000, 54321)。\n   - 用例3（相关性较低，变化较大）：(0.00, 1.50, 150000, 2023)。\n   - 用例4（边缘情况，样本数最少）：(0.25, 0.30, 1, 7)。\n   对于每个用例，$N$ 是蒙特卡洛样本大小，$\\text{seed}$ 是伪随机数生成器种子。\n4. 最终输出格式：您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。每个测试用例应生成一个包含三个浮点数的列表 $[\\widehat{\\Delta}_{\\mathrm{naive}}, \\widehat{\\Delta}_{\\mathrm{cv}}, \\Delta_{\\mathrm{exact}}]$，最终输出应为这些列表的列表，其顺序与测试套件中的顺序相同。例如，输出应如下所示\n   $$[[a_1, b_1, c_1], [a_2, b_2, c_2], [a_3, b_3, c_3], [a_4, b_4, c_4]],$$\n   其中每个 $a_i$、$b_i$ 和 $c_i$ 都是浮点数。如果由于 $N$ 太小导致控制变量的方差估计为零，则将控制变量系数设置为 $\\beta = 0$。\n\n注：\n- 不涉及角度；无需角度单位。\n- 不涉及物理量；无需物理单位。\n- 算法的实现必须确保在给定种子的情况下，所有结果都是确定性的。",
            "solution": "目标是使用控制变量方法来估计期望的变化量 $E[f(X; \\theta_1)] - E[f(X; \\theta_0)]$，以提高蒙特卡洛模拟的效率。给定函数 $f(x; \\theta) = \\exp(\\theta x)$，其中 $X$ 是一个标准正态随机变量，$X \\sim \\mathcal{N}(0, 1)$。我们将首先推导控制变量估计量的最优系数并证明其性质，然后详细说明其数值实现的算法。\n\n### 任务1：最优控制变量系数的推导\n\n给定 $\\mu_1 = E[f(X; \\theta_1)]$ 的一个控制变量估计量：\n$$\n\\widehat{\\mu}(\\beta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right)\n$$\n其中 $Y_i = f(X_i; \\theta_1)$，$G_i = f(X_i; \\theta_0)$，且 $\\mu_0 = E[G_i] = E[f(X; \\theta_0)]$。样本 $X_i$ 是独立同分布（i.i.d.）的。\n\n#### 估计量的无偏性\n首先，我们证明对于任何常数系数 $\\beta$，$\\widehat{\\mu}(\\beta)$ 是 $\\mu_1$ 的一个无偏估计量。我们计算 $\\widehat{\\mu}(\\beta)$ 的期望：\n$$\nE[\\widehat{\\mu}(\\beta)] = E\\left[\\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right)\\right]\n$$\n根据期望的线性性质，我们可以将期望算子移到求和内部：\n$$\nE[\\widehat{\\mu}(\\beta)] = \\frac{1}{N} \\sum_{i=1}^{N} E\\left[Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right]\n$$\n再次对求和内的项应用线性性质：\n$$\nE\\left[Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right] = E[Y_i] - \\beta E[G_i - \\mu_0]\n$$\n根据定义，$E[Y_i] = \\mu_1$ 且 $E[G_i] = \\mu_0$。因此：\n$$\nE[G_i - \\mu_0] = E[G_i] - E[\\mu_0] = \\mu_0 - \\mu_0 = 0\n$$\n将此代回，我们得到：\n$$\nE\\left[Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right] = \\mu_1 - \\beta(0) = \\mu_1\n$$\n由于这对每个样本 $i=1, \\dots, N$ 都成立，该估计量的期望是：\n$$\nE[\\widehat{\\mu}(\\beta)] = \\frac{1}{N} \\sum_{i=1}^{N} \\mu_1 = \\frac{1}{N} (N \\mu_1) = \\mu_1\n$$\n因此，无论 $\\beta$ 如何选择，$\\widehat{\\mu}(\\beta)$ 都是 $\\mu_1$ 的无偏估计量。\n\n#### 方差最小化\n接下来，我们求使 $\\widehat{\\mu}(\\beta)$ 的方差最小化的 $\\beta$ 值。方差为：\n$$\n\\operatorname{Var}(\\widehat{\\mu}(\\beta)) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right)\\right)\n$$\n由于求和中的各项是独立同分布的，样本均值的方差是单项方差的 $\\frac{1}{N}$：\n$$\n\\operatorname{Var}(\\widehat{\\mu}(\\beta)) = \\frac{1}{N} \\operatorname{Var}\\left(Y_1 - \\beta \\left(G_1 - \\mu_0\\right)\\right)\n$$\n常数项 $-\\beta \\mu_0$ 不影响方差，所以我们可以将其简化为：\n$$\n\\operatorname{Var}(\\widehat{\\mu}(\\beta)) = \\frac{1}{N} \\operatorname{Var}\\left(Y - \\beta G\\right)\n$$\n其中 $Y = f(X; \\theta_1)$ 且 $G = f(X; \\theta_0)$。使用随机变量线性组合的方差标准公式：\n$$\n\\operatorname{Var}(Y - \\beta G) = \\operatorname{Var}(Y) + \\operatorname{Var}(-\\beta G) + 2 \\operatorname{Cov}(Y, -\\beta G) = \\operatorname{Var}(Y) + \\beta^2 \\operatorname{Var}(G) - 2\\beta \\operatorname{Cov}(Y, G)\n$$\n为了使此方差相对于 $\\beta$ 最小化，我们对这个关于 $\\beta$ 的二次函数求导，并令其等于零：\n$$\n\\frac{d}{d\\beta} \\operatorname{Var}(Y - \\beta G) = \\frac{d}{d\\beta} \\left( \\operatorname{Var}(Y) + \\beta^2 \\operatorname{Var}(G) - 2\\beta \\operatorname{Cov}(Y, G) \\right) = 2\\beta \\operatorname{Var}(G) - 2 \\operatorname{Cov}(Y, G)\n$$\n令导数为零，得到最优系数 $\\beta^*$：\n$$\n2\\beta^* \\operatorname{Var}(G) - 2 \\operatorname{Cov}(Y, G) = 0 \\implies \\beta^* = \\frac{\\operatorname{Cov}(Y, G)}{\\operatorname{Var}(G)}\n$$\n二阶导数 $2\\operatorname{Var}(G)$ 是非负的，这证实了此 $\\beta$ 值对应于一个最小值（前提是 $\\operatorname{Var}(G) > 0$）。\n\n### 任务2：算法与实现细节\n\n实现需要为每个测试用例计算三个量：朴素差分估计 $\\widehat{\\Delta}_{\\mathrm{naive}}$、控制变量差分估计 $\\widehat{\\Delta}_{\\mathrm{cv}}$ 和精确差分 $\\Delta_{\\mathrm{exact}}$。\n\n#### 从矩生成函数得到的精确值\n对于一个标准正态随机变量 $X \\sim \\mathcal{N}(0, 1)$，其矩生成函数（MGF）是 $M_X(t) = E[\\exp(tX)] = \\exp(t^2/2)$。因此，我们的目标函数 $f(x; \\theta) = \\exp(\\theta x)$ 的期望是：\n$$\n\\mu_\\theta = E[f(X; \\theta)] = E[\\exp(\\theta X)] = M_X(\\theta) = \\exp(\\theta^2/2)\n$$\n使用此公式，所需的精确值为：\n- $\\mu_0 = E[f(X; \\theta_0)] = \\exp(\\theta_0^2/2)$\n- $\\mu_1 = E[f(X; \\theta_1)] = \\exp(\\theta_1^2/2)$\n- $\\Delta_{\\mathrm{exact}} = \\mu_1 - \\mu_0 = \\exp(\\theta_1^2/2) - \\exp(\\theta_0^2/2)$\n\n#### 需要计算的估计量\n1.  **朴素差分估计量**：这是 $Y$ 和 $G$ 的样本均值之差：\n    $$\n    \\widehat{\\Delta}_{\\mathrm{naive}} = \\overline{Y} - \\overline{G} = \\left(\\frac{1}{N}\\sum_{i=1}^{N} Y_i\\right) - \\left(\\frac{1}{N}\\sum_{i=1}^{N} G_i\\right)\n    $$\n2.  **控制变量差分估计量**：该估计量使用 $\\mu_1$ 的控制变量估计，并减去 $\\mu_0$ 的精确值。最优系数 $\\beta^*$ 是未知的，必须从样本中估计。基于样本的估计 $\\widehat{\\beta}$ 是：\n    $$\n    \\widehat{\\beta} = \\frac{\\widehat{\\operatorname{Cov}}(Y, G)}{\\widehat{\\operatorname{Var}}(G)} = \\frac{\\frac{1}{N-1}\\sum_{i=1}^N (Y_i - \\overline{Y})(G_i - \\overline{G})}{\\frac{1}{N-1}\\sum_{i=1}^N (G_i - \\overline{G})^2}\n    $$\n    $\\mu_1$ 的控制变量估计是 $\\widehat{\\mu}_1(\\widehat{\\beta}) = \\overline{Y} - \\widehat{\\beta}(\\overline{G} - \\mu_0)$。最终的差分估计量是：\n    $$\n    \\widehat{\\Delta}_{\\mathrm{cv}} = \\widehat{\\mu}_1(\\widehat{\\beta}) - \\mu_0 = \\overline{Y} - \\widehat{\\beta}(\\overline{G} - \\mu_0) - \\mu_0\n    $$\n\n#### 处理边缘情况\n根据说明，如果控制变量的样本方差 $\\widehat{\\operatorname{Var}}(G)$ 为零，则系数 $\\widehat{\\beta}$ 被设置为 $0$。当 $N \\le 1$ 或所有生成的样本 $G_i$ 都相同时（例如，当 $\\theta_0=0$ 时），就会出现这种情况。在这种情况下，控制变量项消失，估计量 $\\widehat{\\mu}_1(\\widehat{\\beta})$ 简化为简单样本均值 $\\overline{Y}$。\n\n每个测试用例 $(\\theta_0, \\theta_1, N, \\text{seed})$ 的处理步骤如下：\n1.  使用 `seed` 为随机数生成器设置种子。\n2.  生成 $N$ 个样本 $X_i \\sim \\mathcal{N}(0, 1)$。\n3.  计算向量 $Y_i = \\exp(\\theta_1 X_i)$ 和 $G_i = \\exp(\\theta_0 X_i)$。\n4.  计算样本均值 $\\overline{Y}$ 和 $\\overline{G}$。\n5.  计算 $\\widehat{\\Delta}_{\\mathrm{naive}} = \\overline{Y} - \\overline{G}$。\n6.  计算 $\\widehat{\\beta}$。如果 $N > 1$ 且 $\\widehat{\\operatorname{Var}}(G) > 0$，则使用基于样本的公式。否则，设置 $\\widehat{\\beta} = 0$。\n7.  计算精确值 $\\mu_0 = \\exp(\\theta_0^2/2)$。\n8.  计算 $\\widehat{\\Delta}_{\\mathrm{cv}} = \\overline{Y} - \\widehat{\\beta}(\\overline{G} - \\mu_0) - \\mu_0$。\n9.  计算 $\\Delta_{\\mathrm{exact}} = \\exp(\\theta_1^2/2) - \\exp(\\theta_0^2/2)$。\n10. 收集三元组 $[\\widehat{\\Delta}_{\\mathrm{naive}}, \\widehat{\\Delta}_{\\mathrm{cv}}, \\Delta_{\\mathrm{exact}}]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Monte Carlo simulation to estimate the change in an expected value\n    using both a naive estimator and a control variate estimator, and compares them\n    to the exact analytical solution.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (theta_0, theta_1, N, seed)\n    test_cases = [\n        (0.50, 0.60, 200000, 12345),\n        (0.75, 0.75, 50000, 54321),\n        (0.00, 1.50, 150000, 2023),\n        (0.25, 0.30, 1, 7),\n    ]\n\n    results = []\n    \n    for theta_0, theta_1, N, seed in test_cases:\n        # Set the seed for the pseudorandom number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        # 1. Generate N independent samples from the standard normal distribution.\n        X_samples = rng.normal(loc=0.0, scale=1.0, size=N)\n        \n        # 2. Compute Y and G values.\n        # Y_i = f(X_i; theta_1)\n        # G_i = f(X_i; theta_0)\n        Y = np.exp(theta_1 * X_samples)\n        G = np.exp(theta_0 * X_samples)\n        \n        # 3. Compute sample means.\n        Y_bar = np.mean(Y)\n        G_bar = np.mean(G)\n        \n        # 4. Compute the naive difference estimator.\n        # delta_naive = E[Y] - E[G] estimated by mean(Y) - mean(G).\n        delta_naive = Y_bar - G_bar\n        \n        # 5. Compute the control variate estimator.\n        # First, estimate the optimal coefficient beta.\n        # beta_hat = Cov(Y, G) / Var(G).\n        beta_hat = 0.0\n        # The sample variance and covariance are undefined for N = 1.\n        # The problem also specifies to set beta=0 if the variance is zero.\n        if N > 1:\n            var_G = np.var(G, ddof=1)\n            # Avoid division by zero if Var(G) is zero (e.g., if theta_0 = 0).\n            if var_G > 0:\n                # np.cov with 1D arrays Y, G returns a 2x2 covariance matrix.\n                # cov_matrix[0, 1] is Cov(Y, G).\n                cov_YG = np.cov(Y, G, ddof=1)[0, 1]\n                beta_hat = cov_YG / var_G\n\n        # 6. Compute exact value for mu_0 = E[G]\n        # For X ~ N(0, 1), E[exp(t*X)] = exp(t^2 / 2).\n        mu_0_exact = np.exp(theta_0**2 / 2.0)\n        \n        # 7. Compute the control variate estimate for mu_1 = E[Y].\n        # mu1_cv = mean(Y) - beta_hat * (mean(G) - mu_0)\n        mu_1_cv = Y_bar - beta_hat * (G_bar - mu_0_exact)\n        \n        # 8. Compute the control variate difference estimator.\n        # delta_cv = mu1_cv - mu_0\n        delta_cv = mu_1_cv - mu_0_exact\n        \n        # 9. Compute the exact difference.\n        mu_1_exact = np.exp(theta_1**2 / 2.0)\n        delta_exact = mu_1_exact - mu_0_exact\n        \n        # 10. Store the triplet of results for the current test case.\n        results.append([delta_naive, delta_cv, delta_exact])\n\n    # Final print statement in the exact required format.\n    # The format is a string representation of a list of lists of floats.\n    output_str = '[' + ','.join([f\"[{a},{b},{c}]\" for a, b, c in results]) + ']'\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}