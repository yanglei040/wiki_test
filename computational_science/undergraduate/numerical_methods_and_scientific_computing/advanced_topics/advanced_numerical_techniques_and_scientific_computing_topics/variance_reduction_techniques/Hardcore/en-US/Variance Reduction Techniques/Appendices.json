{
    "hands_on_practices": [
        {
            "introduction": "The control variates method is a powerful technique for reducing variance in Monte Carlo estimation by leveraging information from a correlated variable with a known expectation. Instead of just averaging our target quantity, we adjust it using a \"control\" whose random fluctuations we can perfectly account for. This practice () guides you through the core mechanics of this method, challenging you to derive the optimal correction factor and precisely calculate the resulting efficiency gain.",
            "id": "1348989",
            "problem": "An analyst is trying to estimate the value of $\\theta = \\mathbb{E}[(U+1)^2]$, where $U$ is a random variable uniformly distributed on the interval $[0, 1]$. The standard approach is to use a simple Monte Carlo estimator, where one generates samples of $X = (U+1)^2$ and averages them. The precision of this estimator is determined by the variance of a single sample, $\\operatorname{Var}(X)$.\n\nTo improve the efficiency of the estimation, a control variate technique is proposed. A new estimator is constructed using a related random variable $C = U$, for which the expected value is known. The new estimator for a single sample is given by $X(b) = X - b(C - \\mathbb{E}[C])$, where $b$ is a real-valued constant coefficient to be optimized.\n\nYour task is to determine the theoretical improvement offered by this technique. First, find the optimal coefficient $b^*$ that minimizes the variance of the new estimator, $\\operatorname{Var}(X(b))$. Then, calculate the variance reduction factor, which is the ratio of the variance of a single optimized control variate sample to the variance of a single simple sample.\n\nExpress this variance reduction factor, $\\frac{\\operatorname{Var}(X(b^*))}{\\operatorname{Var}(X)}$, as an exact fraction.",
            "solution": "Let $U \\sim \\mathrm{Unif}[0,1]$, $X=(U+1)^{2}$, and $C=U$. For $k \\geq 0$, $\\mathbb{E}[U^{k}]=\\frac{1}{k+1}$. Hence $\\mathbb{E}[U]=\\frac{1}{2}$, $\\mathbb{E}[U^{2}]=\\frac{1}{3}$, $\\mathbb{E}[U^{3}]=\\frac{1}{4}$, $\\mathbb{E}[U^{4}]=\\frac{1}{5}$, and $\\operatorname{Var}(U)=\\frac{1}{12}$.\n\nExpand $X$ as $X=U^{2}+2U+1$. Then\n$$\n\\mathbb{E}[X]=\\mathbb{E}[U^{2}]+2\\mathbb{E}[U]+1=\\frac{1}{3}+1+1=\\frac{7}{3}.\n$$\nAlso\n$$\nX^{2}=(U^{2}+2U+1)^{2}=U^{4}+4U^{3}+6U^{2}+4U+1,\n$$\nso\n$$\n\\mathbb{E}[X^{2}]=\\frac{1}{5}+4\\cdot\\frac{1}{4}+6\\cdot\\frac{1}{3}+4\\cdot\\frac{1}{2}+1=\\frac{31}{5}.\n$$\nTherefore\n$$\n\\operatorname{Var}(X)=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2}=\\frac{31}{5}-\\left(\\frac{7}{3}\\right)^{2}=\\frac{34}{45}.\n$$\n\nCompute the covariance with $C=U$:\n$$\n\\operatorname{Cov}(U^{2},U)=\\mathbb{E}[U^{3}]-\\mathbb{E}[U^{2}]\\mathbb{E}[U]=\\frac{1}{4}-\\frac{1}{3}\\cdot\\frac{1}{2}=\\frac{1}{12},\n$$\nso\n$$\n\\operatorname{Cov}(X,C)=\\operatorname{Cov}(U^{2}+2U+1,U)=\\frac{1}{12}+2\\cdot\\operatorname{Var}(U)=\\frac{1}{12}+2\\cdot\\frac{1}{12}=\\frac{1}{4},\n$$\nand $\\operatorname{Var}(C)=\\operatorname{Var}(U)=\\frac{1}{12}$.\n\nFor the control variate estimator $X(b)=X-b(C-\\mathbb{E}[C])$, the variance is\n$$\n\\operatorname{Var}(X(b))=\\operatorname{Var}(X)-2b\\,\\operatorname{Cov}(X,C)+b^{2}\\operatorname{Var}(C).\n$$\nMinimizing the quadratic in $b$ yields\n$$\nb^{*}=\\frac{\\operatorname{Cov}(X,C)}{\\operatorname{Var}(C)}=\\frac{\\frac{1}{4}}{\\frac{1}{12}}=3,\n$$\nand the minimized variance\n$$\n\\operatorname{Var}(X(b^{*}))=\\operatorname{Var}(X)-\\frac{\\operatorname{Cov}(X,C)^{2}}{\\operatorname{Var}(C)}=\\frac{34}{45}-\\frac{\\left(\\frac{1}{4}\\right)^{2}}{\\frac{1}{12}}=\\frac{34}{45}-\\frac{3}{4}=\\frac{1}{180}.\n$$\n\nHence the variance reduction factor is\n$$\n\\frac{\\operatorname{Var}(X(b^{*}))}{\\operatorname{Var}(X)}=\\frac{\\frac{1}{180}}{\\frac{34}{45}}=\\frac{1}{136}.\n$$",
            "answer": "$$\\boxed{\\frac{1}{136}}$$"
        },
        {
            "introduction": "Antithetic variates offer an intuitive and often simple way to reduce variance by exploiting symmetry in the problem's formulation. The core idea is that if a function is monotonic, pairing a random input $u$ with its antithesis $1-u$ creates negatively correlated outputs whose average is more stable than that of two independent samples. In this hands-on exercise (), you will apply this technique to a practical physics model, providing a concrete example of how induced negative correlation can improve estimation efficiency.",
            "id": "1349000",
            "problem": "A team of engineers is designing a novel micro-catapult system. In this system, projectiles are launched at a fixed angle $\\theta$ with respect to the horizontal. Due to fluctuations in the energy source, the initial launch speed, $v_0$, is a random variable. It is known to be uniformly distributed between a minimum speed $v_{min}$ and a maximum speed $v_{max}$. The maximum height $H$ reached by a projectile is given by the formula $H(v_0) = \\frac{(v_0 \\sin\\theta)^2}{2g}$, where $g$ is the acceleration due to gravity.\n\nTo estimate the expected maximum height, $\\mathbb{E}[H]$, the team employs the antithetic variates method, a variance reduction technique. A specific launch speed $v$ is generated from a standard uniform random variable $u \\sim U(0,1)$ using the inverse transform sampling formula: $v = v_{min} + (v_{max} - v_{min})u$. An antithetic pair of speeds, $(v_1, v'_1)$, is then generated using a single draw $u_1$ and its antithetic counterpart $u'_1 = 1 - u_1$.\n\nYou are given the following parameters for the system:\n- Launch angle: $\\theta = 30^{\\circ}$\n- Minimum speed: $v_{min} = 20.0$ m/s\n- Maximum speed: $v_{max} = 50.0$ m/s\n- Acceleration due to gravity: $g = 9.81 \\, \\text{m/s}^2$\n\nBased on a single random draw $u_1 = 0.300$ from the standard uniform distribution $U(0,1)$, calculate the antithetic variate estimate for the expected maximum height. Express your answer in meters, rounded to three significant figures.",
            "solution": "We seek the antithetic variate estimate of the expected maximum height using one antithetic pair. The maximum height as a function of launch speed is given by\n$$\nH(v_{0})=\\frac{(v_{0}\\sin\\theta)^{2}}{2g}.\n$$\nThe inverse transform sampling for a uniform speed on $[v_{\\min},v_{\\max}]$ is\n$$\nv(u)=v_{\\min}+(v_{\\max}-v_{\\min})u,\n$$\nand the antithetic pair uses $u_{1}$ and $u_{1}'=1-u_{1}$, giving speeds\n$$\nv_{1}=v(u_{1}),\\qquad v_{1}'=v(u_{1}').\n$$\nThe antithetic variate estimator based on one pair is the average\n$$\n\\widehat{E}_{\\text{AV}}=\\frac{H(v_{1})+H(v_{1}')}{2}.\n$$\n\nWith $\\theta=30^{\\circ}$, we use $\\sin(30^{\\circ})=\\frac{1}{2}$, hence\n$$\nH(v)=\\frac{v^{2}\\sin^{2}(30^{\\circ})}{2g}=\\frac{v^{2}}{8g}.\n$$\nGiven $v_{\\min}=20.0$, $v_{\\max}=50.0$, and $u_{1}=0.300$,\n$$\nv_{1}=20.0+(50.0-20.0)\\cdot 0.300=20.0+30.0\\cdot 0.300=29.0,\n$$\n$$\nu_{1}'=1-0.300=0.700,\\qquad v_{1}'=20.0+30.0\\cdot 0.700=41.0.\n$$\nThus\n$$\nH(v_{1})=\\frac{29.0^{2}}{8g}=\\frac{841}{8g},\\qquad H(v_{1}')=\\frac{41.0^{2}}{8g}=\\frac{1681}{8g}.\n$$\nThe antithetic estimate is\n$$\n\\widehat{E}_{\\text{AV}}=\\frac{1}{2}\\left(\\frac{841}{8g}+\\frac{1681}{8g}\\right)=\\frac{841+1681}{16g}=\\frac{2522}{16g}.\n$$\nWith $g=9.81$, this yields\n$$\n\\widehat{E}_{\\text{AV}}=\\frac{2522}{16\\times 9.81}=\\frac{2522}{156.96}\\approx 16.0678.\n$$\nRounded to three significant figures, the estimate is $16.1$ meters.",
            "answer": "$$\\boxed{16.1}$$"
        },
        {
            "introduction": "Importance sampling is one of the most fundamental and powerful variance reduction techniques, which works by changing the probability distribution from which we draw samples. By concentrating the sampling effort in the \"important\" regions of the state space, we can obtain more precise estimates with fewer samples. This advanced practice () takes this idea to its theoretical limit, asking you to find an optimal proposal distribution that, in this idealized case, reduces the estimator's variance to zero.",
            "id": "2446710",
            "problem": "Consider the task of computing the expectation of the exponential of a normally distributed random variable in a Monte Carlo setting relevant to computational economics and finance. Let $X \\sim \\mathcal{N}(0, 100)$, and define $h(x) = \\exp(x)$. You will estimate the quantity $\\mathbb{E}[\\exp(X)]$ via importance sampling using a proposal distribution $Q$ given by $Y \\sim \\mathcal{N}(\\mu, 100)$ with unknown shift parameter $\\mu \\in \\mathbb{R}$. Let $p(x)$ and $q_{\\mu}(x)$ denote the probability density functions of $\\mathcal{N}(0, 100)$ and $\\mathcal{N}(\\mu, 100)$, respectively. The importance sampling estimator based on $n$ independent and identically distributed samples $\\{Y_i\\}_{i=1}^{n}$ from $q_{\\mu}$ is\n$$\nI_n(\\mu) \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} h(Y_i)\\, w_{\\mu}(Y_i), \\quad \\text{where } w_{\\mu}(y) \\;=\\; \\frac{p(y)}{q_{\\mu}(y)}.\n$$\nWorking from first principles and without invoking any specific variance reduction formulas, do the following:\n1. Derive a closed-form expression for $\\mathbb{E}[\\exp(X)]$.\n2. Derive $\\operatorname{Var}_{q_{\\mu}}(h(Y)\\,w_{\\mu}(Y))$ as a function of $\\mu$ and identify the value $\\mu^{\\star}$ that minimizes this variance over $\\mu \\in \\mathbb{R}$.\n\nProvide your final answer as a single ordered pair consisting of the exact value of $\\mathbb{E}[\\exp(X)]$ and the optimal shift $\\mu^{\\star}$. No numerical rounding is required, and your answer should be exact with no units.",
            "solution": "We begin by recalling the definitions. The target distribution is $X \\sim \\mathcal{N}(0, 100)$ with density\n$$\np(x) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\, \\sigma}\\,\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right), \\quad \\sigma^{2} = 100,\n$$\nand the proposal distribution is $Y \\sim \\mathcal{N}(\\mu, 100)$ with density\n$$\nq_{\\mu}(x) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\, \\sigma}\\,\\exp\\!\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right), \\quad \\sigma^{2} = 100.\n$$\nThe importance weight is $w_{\\mu}(x) = p(x)/q_{\\mu}(x)$.\n\nStep 1: Compute $\\mathbb{E}[\\exp(X)]$ in closed form. By definition,\n$$\n\\mathbb{E}[\\exp(X)] \\;=\\; \\int_{-\\infty}^{\\infty} \\exp(x)\\, p(x)\\, dx \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\, \\sigma} \\int_{-\\infty}^{\\infty} \\exp\\!\\left(x - \\frac{x^{2}}{2\\sigma^{2}}\\right) dx.\n$$\nComplete the square in the exponent. Write\n$$\nx - \\frac{x^{2}}{2\\sigma^{2}} \\;=\\; -\\frac{1}{2\\sigma^{2}}\\left(x^{2} - 2\\sigma^{2} x \\right) \\;=\\; -\\frac{1}{2\\sigma^{2}}\\left[(x - \\sigma^{2})^{2} - \\sigma^{4}\\right] \\;=\\; -\\frac{(x - \\sigma^{2})^{2}}{2\\sigma^{2}} + \\frac{\\sigma^{2}}{2}.\n$$\nTherefore,\n$$\n\\mathbb{E}[\\exp(X)] \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\, \\sigma} \\exp\\!\\left(\\frac{\\sigma^{2}}{2}\\right) \\int_{-\\infty}^{\\infty} \\exp\\!\\left(-\\frac{(x - \\sigma^{2})^{2}}{2\\sigma^{2}}\\right) dx \\;=\\; \\exp\\!\\left(\\frac{\\sigma^{2}}{2}\\right),\n$$\nsince the integral equals $\\sqrt{2\\pi}\\, \\sigma$. With $\\sigma^{2} = 100$, this yields\n$$\n\\mathbb{E}[\\exp(X)] \\;=\\; \\exp(50).\n$$\n\nStep 2: Derive $\\operatorname{Var}_{q_{\\mu}}(h(Y)\\, w_{\\mu}(Y))$ and minimize it over $\\mu$. Note that\n$$\n\\operatorname{Var}_{q_{\\mu}}(h(Y)\\, w_{\\mu}(Y)) \\;=\\; \\mathbb{E}_{q_{\\mu}}\\!\\left[h(Y)^{2}\\, w_{\\mu}(Y)^{2}\\right] \\;-\\; \\left(\\mathbb{E}[\\exp(X)]\\right)^{2}.\n$$\nThe second term does not depend on $\\mu$, so minimizing the variance over $\\mu$ is equivalent to minimizing the second moment\n$$\nM(\\mu) \\;=\\; \\mathbb{E}_{q_{\\mu}}\\!\\left[h(Y)^{2}\\, w_{\\mu}(Y)^{2}\\right] \\;=\\; \\int_{-\\infty}^{\\infty} \\exp(2x)\\, \\frac{p(x)^{2}}{q_{\\mu}(x)}\\, dx.\n$$\nUsing the explicit forms of $p$ and $q_{\\mu}$ with common variance $\\sigma^{2}$,\n$$\n\\frac{p(x)^{2}}{q_{\\mu}(x)} \\;=\\; \\frac{\\left(\\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right)\\right)^{2}}{\\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right)} \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{x^{2}}{\\sigma^{2}} + \\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right).\n$$\nHence,\n$$\nM(\\mu) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\int_{-\\infty}^{\\infty} \\exp\\!\\left(2x - \\frac{x^{2}}{\\sigma^{2}} + \\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right) dx.\n$$\nCombine exponents:\n$$\n2x - \\frac{x^{2}}{\\sigma^{2}} + \\frac{(x-\\mu)^{2}}{2\\sigma^{2}} \\;=\\; -\\frac{x^{2}}{2\\sigma^{2}} + \\left(2 - \\frac{\\mu}{\\sigma^{2}}\\right) x + \\frac{\\mu^{2}}{2\\sigma^{2}}.\n$$\nComplete the square by defining\n$$\nm \\;=\\; 2\\sigma^{2} - \\mu,\n$$\nso that\n$$\n-\\frac{x^{2}}{2\\sigma^{2}} + \\left(2 - \\frac{\\mu}{\\sigma^{2}}\\right) x \\;=\\; -\\frac{(x - m)^{2}}{2\\sigma^{2}} + \\frac{m^{2}}{2\\sigma^{2}}.\n$$\nTherefore,\n$$\nM(\\mu) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\!\\left(\\frac{m^{2}}{2\\sigma^{2}} + \\frac{\\mu^{2}}{2\\sigma^{2}}\\right) \\int_{-\\infty}^{\\infty} \\exp\\!\\left(-\\frac{(x - m)^{2}}{2\\sigma^{2}}\\right) dx \\;=\\; \\exp\\!\\left(\\frac{m^{2} + \\mu^{2}}{2\\sigma^{2}}\\right).\n$$\nSubstituting $m = 2\\sigma^{2} - \\mu$,\n$$\nm^{2} + \\mu^{2} \\;=\\; (2\\sigma^{2} - \\mu)^{2} + \\mu^{2} \\;=\\; 4\\sigma^{4} - 4\\mu \\sigma^{2} + 2\\mu^{2},\n$$\nhence\n$$\nM(\\mu) \\;=\\; \\exp\\!\\left(\\frac{4\\sigma^{4} - 4\\mu \\sigma^{2} + 2\\mu^{2}}{2\\sigma^{2}}\\right) \\;=\\; \\exp\\!\\left(2\\sigma^{2} - 2\\mu + \\frac{\\mu^{2}}{\\sigma^{2}}\\right).\n$$\nAs a function of $\\mu$, minimizing $M(\\mu)$ is equivalent to minimizing the exponent\n$$\ng(\\mu) \\;=\\; \\frac{\\mu^{2}}{\\sigma^{2}} - 2\\mu + 2\\sigma^{2}.\n$$\nThis is a convex quadratic in $\\mu$ with derivative\n$$\ng'(\\mu) \\;=\\; \\frac{2\\mu}{\\sigma^{2}} - 2,\n$$\nwhich vanishes at\n$$\n\\mu^{\\star} \\;=\\; \\sigma^{2}.\n$$\nSince $g''(\\mu) = 2/\\sigma^{2} > 0$, this critical point is the unique minimizer. With $\\sigma^{2} = 100$, the optimal shift is\n$$\n\\mu^{\\star} \\;=\\; 100.\n$$\nAt $\\mu^{\\star} = \\sigma^{2}$, the proposal density $q_{\\mu^{\\star}}$ is proportional to $h(x)\\, p(x)$, which yields a zero-variance importance sampling estimator, consistent with\n$$\n\\operatorname{Var}_{q_{\\mu^{\\star}}}(h(Y)\\,w_{\\mu^{\\star}}(Y)) \\;=\\; M(\\mu^{\\star}) - \\left(\\mathbb{E}[\\exp(X)]\\right)^{2} \\;=\\; \\exp(\\sigma^{2}) - \\exp(\\sigma^{2}) \\;=\\; 0.\n$$\nCollecting results, the exact expectation is $\\exp(50)$ and the optimal shift is $\\mu^{\\star} = 100$.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\exp(50)  100\\end{pmatrix}}$$"
        }
    ]
}