{
    "hands_on_practices": [
        {
            "introduction": "Truth tables are not just abstract mathematical tools; they are the bedrock for designing circuits that make computer systems reliable. This practice explores the design of a 3-input majority voter, a simple yet critical component in fault-tolerant architectures like Triple Modular Redundancy (TMR). By constructing the voter's truth table and analyzing its behavior under fault conditions, you will gain insight into how simple logic can mask hardware errors, ensuring a system continues to function correctly even when one of its components fails . This exercise provides a direct link between fundamental Boolean principles and the practical engineering of robust, mission-critical hardware.",
            "id": "3686334",
            "problem": "In a fault-tolerant datapath using Triple Modular Redundancy (TMR), three nominally identical modules produce binary outputs $A$, $B$, and $C$ that are combined by a $3$-input majority voter $M(A,B,C)$. By definition, a majority voter outputs $1$ if and only if at least $2$ of its inputs are $1$, and outputs $0$ otherwise. Using only fundamental definitions from Boolean algebra and the method of truth tables (enumerating all input combinations and identifying when the output is $1$), complete the following tasks:\n- Construct the truth table for $M(A,B,C)$ from first principles and from it obtain a minimal sum-of-products Boolean implementation.\n- Analyze the effect on the realized function when input $A$ is stuck-at-$0$ and when input $A$ is stuck-at-$1$ by substituting the constant into your implementation and simplifying using Boolean algebra.\n- Using your results and the definition of TMR, reason whether a single stuck-at fault on one module’s output can be fully masked by the voter when the other two modules are fault-free and identical for all input combinations.\n\nSelect all statements that are correct:\n\nA. The minimal sum-of-products implementation of the majority voter is $M(A,B,C)=AB+BC+AC$.\n\nB. If input $A$ is stuck-at-$0$, the majority voter’s output reduces to $M(0,B,C)=B\\lor C$.\n\nC. If input $A$ is stuck-at-$1$, the majority voter’s output reduces to $M(1,B,C)=B\\lor C$.\n\nD. In TMR, if two modules are fault-free and identical, a single stuck-at fault on the third module is fully masked by the majority voter for all input combinations.\n\nE. The majority voter equals the parity function: $M(A,B,C)=A\\oplus B\\oplus C$.",
            "solution": "The problem statement is a valid exercise in digital logic design and fault-tolerant computing. It is scientifically grounded, well-posed, objective, and complete. I will proceed with a solution.\n\nThe primary task is to analyze a $3$-input majority voter, $M(A,B,C)$, its implementation, its behavior under faults, and its role in Triple Modular Redundancy (TMR). The problem defines the voter's output as $1$ if and only if at least $2$ of its inputs are $1$, and $0$ otherwise.\n\n**Part 1: Truth Table and Minimal Sum-of-Products (SOP) Implementation**\n\nFirst, let us construct the truth table for $M(A,B,C)$ by enumerating all $2^3 = 8$ possible combinations of the binary inputs $A$, $B$, and $C$. The output $M$ is $1$ when the sum of the inputs is greater than or equal to $2$.\n\n| $A$ | $B$ | $C$ | Number of $1$s | $M(A,B,C)$ |\n|---|---|---|---|---|\n| $0$ | $0$ | $0$ | $0$ | $0$ |\n| $0$ | $0$ | $1$ | $1$ | $0$ |\n| $0$ | $1$ | $0$ | $1$ | $0$ |\n| $0$ | $1$ | $1$ | $2$ | $1$ |\n| $1$ | $0$ | $0$ | $1$ | $0$ |\n| $1$ | $0$ | $1$ | $2$ | $1$ |\n| $1$ | $1$ | $0$ | $2$ | $1$ |\n| $1$ | $1$ | $1$ | $3$ | $1$ |\n\nFrom the truth table, the function $M(A,B,C)$ is true for the input combinations (minterms) $(0,1,1)$, $(1,0,1)$, $(1,1,0)$, and $(1,1,1)$. This gives the canonical sum-of-products (SOP) expression:\n$$ M(A,B,C) = \\overline{A}BC + A\\overline{B}C + AB\\overline{C} + ABC $$\n\nTo find the minimal SOP expression, we can use Boolean algebra. We can add the term $ABC$ twice more to the expression, since $X+X=X$.\n$$ M(A,B,C) = \\overline{A}BC + A\\overline{B}C + AB\\overline{C} + ABC + ABC + ABC $$\nRearranging the terms to group adjacent minterms:\n$$ M(A,B,C) = (\\overline{A}BC + ABC) + (A\\overline{B}C + ABC) + (AB\\overline{C} + ABC) $$\nFactoring out common terms using the distributive law:\n$$ M(A,B,C) = BC(\\overline{A}+A) + AC(\\overline{B}+B) + AB(\\overline{C}+C) $$\nUsing the identity $X+\\overline{X}=1$:\n$$ M(A,B,C) = BC(1) + AC(1) + AB(1) $$\n$$ M(A,B,C) = AB + BC + AC $$\nThis is the minimal SOP implementation for the $3$-input majority function.\n\n**Part 2: Analysis of Stuck-At Faults**\n\nNext, we analyze the voter's behavior when its input $A$ is stuck.\n\n**Case 1: Input $A$ is stuck-at-$0$.**\nWe substitute $A=0$ into the minimal SOP expression:\n$$ M(0,B,C) = (0)B + BC + (0)C $$\n$$ M(0,B,C) = 0 + BC + 0 $$\n$$ M(0,B,C) = BC $$\nThe output reduces to the logical AND of inputs $B$ and $C$.\n\n**Case 2: Input $A$ is stuck-at-$1$.**\nWe substitute $A=1$ into the minimal SOP expression:\n$$ M(1,B,C) = (1)B + BC + (1)C $$\n$$ M(1,B,C) = B + BC + C $$\nUsing the absorption law of Boolean algebra, $X+XY = X$, we can simplify $B+BC$:\n$$ B+BC = B $$\nSo the expression becomes:\n$$ M(1,B,C) = (B+BC) + C = B + C $$\nIn standard logical notation, this is $B \\lor C$. The output reduces to the logical OR of inputs $B$ and $C$.\n\n**Part 3: Fault Masking in TMR**\n\nIn a TMR system, three identical modules produce outputs that are fed into the majority voter. If two modules are fault-free, their outputs will be identical. Let this correct output value be $X$. The third module has a single stuck-at fault, so its output is a constant ($0$ or $1$). We must determine if the voter output, $M$, equals the correct value $X$.\n\nThere are two scenarios for the correct output $X$:\n\n*   **Scenario 1: The correct output is $X=0$.**\n    The two fault-free modules output $0$. The inputs to the voter are $(A,B,C)$, where two of the inputs are $0$.\n    *   If the fault is stuck-at-$0$, the inputs are $(0,0,0)$. $M(0,0,0) = 0$. The output is correct.\n    *   If the fault is stuck-at-$1$, the inputs are $(1,0,0)$ in some permutation. $M(1,0,0) = 1 \\cdot 0 + 0 \\cdot 0 + 1 \\cdot 0 = 0$. The output is correct.\n\n*   **Scenario 2: The correct output is $X=1$.**\n    The two fault-free modules output $1$. The inputs to the voter are $(A,B,C)$, where two of the inputs are $1$.\n    *   If the fault is stuck-at-$0$, the inputs are $(0,1,1)$ in some permutation. $M(0,1,1) = 0 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 1 = 1$. The output is correct.\n    *   If the fault is stuck-at-$1$, the inputs are $(1,1,1)$. $M(1,1,1) = 1 \\cdot 1 + 1 \\cdot 1 + 1 \\cdot 1 = 1$. The output is correct.\n\nIn all cases where two inputs are correct and one is faulty (stuck-at-$0$ or stuck-at-$1$), the majority voter produces the correct output $X$. Therefore, a single stuck-at fault on one module's output is fully masked.\n\n**Evaluation of Options**\n\n*   **A. The minimal sum-of-products implementation of the majority voter is $M(A,B,C)=AB+BC+AC$.**\n    As derived in Part 1, this statement is accurate. The minimal SOP expression for the $3$-input majority function is indeed $AB+BC+AC$.\n    **Verdict: Correct.**\n\n*   **B. If input $A$ is stuck-at-$0$, the majority voter’s output reduces to $M(0,B,C)=B\\lor C$.**\n    As derived in Part 2, when $A$ is stuck-at-$0$, the output reduces to $M(0,B,C)=BC$. The expression $BC$ represents a logical AND, not a logical OR ($B \\lor C$, which is $B+C$). For instance, if $B=1$ and $C=0$, $BC=0$ while $B \\lor C = 1$.\n    **Verdict: Incorrect.**\n\n*   **C. If input $A$ is stuck-at-$1$, the majority voter’s output reduces to $M(1,B,C)=B\\lor C$.**\n    As derived in Part 2, when $A$ is stuck-at-$1$, the output reduces to $M(1,B,C)=B+C$. The expression $B+C$ is the Boolean algebra representation for logical OR, $B \\lor C$.\n    **Verdict: Correct.**\n\n*   **D. In TMR, if two modules are fault-free and identical, a single stuck-at fault on the third module is fully masked by the majority voter for all input combinations.**\n    As demonstrated in Part 3, the output of the majority voter will always match the value of the two identical, correct inputs, effectively masking the single faulty input. This is the fundamental principle of TMR.\n    **Verdict: Correct.**\n\n*   **E. The majority voter equals the parity function: $M(A,B,C)=A\\oplus B\\oplus C$.**\n    The $3$-input XOR (parity) function, $P(A,B,C)=A\\oplus B\\oplus C$, outputs $1$ if an odd number of inputs are $1$. Let's compare its output to the majority voter for the input $(0,1,1)$.\n    *   $M(0,1,1) = 0 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 1 = 1$ (since two inputs are $1$).\n    *   $P(0,1,1) = 0 \\oplus 1 \\oplus 1 = 1 \\oplus 1 = 0$ (since two, an even number, of inputs are $1$).\n    Since $M(0,1,1) \\neq P(0,1,1)$, the two functions are not equal.\n    **Verdict: Incorrect.**",
            "answer": "$$\\boxed{ACD}$$"
        },
        {
            "introduction": "Processors must perform a wide range of arithmetic, some of which goes beyond standard addition and subtraction. This exercise challenges you to use a truth table to define a custom arithmetic operation: 2-bit signed saturating addition. Unlike conventional two's complement arithmetic that \"wraps around\" on overflow, saturating arithmetic clamps the result to the maximum or minimum representable value, a behavior essential in applications like digital signal processing and graphics to prevent data corruption. This practice  illustrates how truth tables serve as the definitive blueprint for implementing any bespoke logic function, translating precise arithmetic rules into a hardware specification.",
            "id": "3686422",
            "problem": "Consider fixed-width signed integer arithmetic using two-bit two's complement representation. In two's complement with width $n=2$, the representable integers are $-2$, $-1$, $0$, and $1$, encoded by the bit patterns $10$, $11$, $00$, and $01$, respectively, where the most significant bit is the sign bit. Define saturating addition on these two-bit integers as follows: given inputs $A=a_{1}a_{0}$ and $B=b_{1}b_{0}$, let the mathematical sum be $V(A)+V(B)$, where $V(\\cdot)$ maps a two-bit pattern to its two's complement integer value. The saturating sum $S$ is defined to be the normal sum $V(A)+V(B)$ if $V(A)+V(B)\\in[-2,1]$, the maximum representable integer $+1$ (bit pattern $01$) if $V(A)+V(B)>1$, and the minimum representable integer $-2$ (bit pattern $10$) if $V(A)+V(B)<-2$.\n\nTasks:\n- Construct the complete truth table that maps every input pair $(A,B)$ over all $16$ combinations of two-bit inputs to the saturating sum output $S$, written both as a two-bit pattern and as its two's complement integer value.\n- Assume the inputs $A$ and $B$ are independent and uniformly distributed over the four representable values $\\{-2,-1,0,1\\}$. Using your truth table, compute the exact expected value of the saturating sum $S$ interpreted as a two's complement integer.\n\nExpress the final expected value as a single exact fraction. Do not round.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of computer arithmetic, is well-posed with all necessary information provided, and is stated objectively.\n\nThe problem asks for two results: first, a complete truth table for two-bit two's complement saturating addition, and second, the expected value of the saturated sum assuming uniformly distributed inputs.\n\nThe two-bit two's complement representation covers the integer range from $-2^{2-1}$ to $2^{2-1}-1$, which is $[-2, 1]$. The problem provides the mapping between the two-bit patterns and their integer values:\n- $00_2 \\rightarrow V(00) = 0$\n- $01_2 \\rightarrow V(01) = 1$\n- $10_2 \\rightarrow V(10) = -2$\n- $11_2 \\rightarrow V(11) = -1$\n\nSaturating addition is defined for two inputs $A$ and $B$. Let $V(A)$ and $V(B)$ be their integer values. The mathematical sum is $Z = V(A) + V(B)$. The saturating sum, $S$, has an integer value $V(S)$ defined as:\n- $V(S) = Z$ if $-2 \\le Z \\le 1$\n- $V(S) = 1$ (maximum representable value) if $Z > 1$\n- $V(S) = -2$ (minimum representable value) if $Z < -2$\n\n**Part 1: Constructing the Truth Table**\n\nWe need to evaluate the saturating sum for all $4 \\times 4 = 16$ possible pairs of inputs for $A=a_1a_0$ and $B=b_1b_0$. The complete truth table is constructed below. The columns show the bit patterns for inputs $A$ and $B$, their corresponding integer values $V(A)$ and $V(B)$, the mathematical sum $Z=V(A)+V(B)$, the resulting integer value of the saturating sum $V(S)$, and the bit pattern for the saturating sum $S$.\n\n| **A** | **V(A)** | **B** | **V(B)** | **Z = V(A)+V(B)** | **V(S)** | **S** |\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| 00  | 0   | 00  | 0   | 0   | 0   | 00  |\n| 00  | 0   | 01  | 1   | 1   | 1   | 01  |\n| 00  | 0   | 10  | -2  | -2  | -2  | 10  |\n| 00  | 0   | 11  | -1  | -1  | -1  | 11  |\n| 01  | 1   | 00  | 0   | 1   | 1   | 01  |\n| 01  | 1   | 01  | 1   | 2   | 1   | 01  |\n| 01  | 1   | 10  | -2  | -1  | -1  | 11  |\n| 01  | 1   | 11  | -1  | 0   | 0   | 00  |\n| 10  | -2  | 00  | 0   | -2  | -2  | 10  |\n| 10  | -2  | 01  | 1   | -1  | -1  | 11  |\n| 10  | -2  | 10  | -2  | -4  | -2  | 10  |\n| 10  | -2  | 11  | -1  | -3  | -2  | 10  |\n| 11  | -1  | 00  | 0   | -1  | -1  | 11  |\n| 11  | -1  | 01  | 1   | 0   | 0   | 00  |\n| 11  | -1  | 10  | -2  | -3  | -2  | 10  |\n| 11  | -1  | 11  | -1  | -2  | -2  | 10  |\n\n**Part 2: Calculating the Expected Value**\n\nThe inputs $A$ and $B$ are assumed to be independent and uniformly distributed over the four possible values $\\{-2, -1, 0, 1\\}$. The probability of any specific integer value for $V(A)$ or $V(B)$ is $P = \\frac{1}{4}$.\nSince $A$ and $B$ are independent, the probability of any specific pair of input values $(V(A), V(B))$ is the product of their individual probabilities:\n$$P(V(A)=v_a, V(B)=v_b) = P(V(A)=v_a) \\times P(V(B)=v_b) = \\frac{1}{4} \\times \\frac{1}{4} = \\frac{1}{16}$$\nThis means that each of the $16$ rows in the truth table is equally likely.\n\nThe expected value of the saturating sum, $E[S]$, is the sum of all possible output values $V(S)$ weighted by their probabilities. Since each of the $16$ outcomes has a probability of $\\frac{1}{16}$, the expected value is the arithmetic mean of all $16$ values in the $V(S)$ column of the table.\n\n$$E[S] = \\sum_{i=1}^{16} V(S_i) \\cdot P_i = \\frac{1}{16} \\sum_{i=1}^{16} V(S_i)$$\n\nWe sum the values from the $V(S)$ column:\n$$\n\\sum_{i=1}^{16} V(S_i) = (0+1-2-1) + (1+1-1+0) + (-2-1-2-2) + (-1+0-2-2)\n$$\n$$\n\\sum_{i=1}^{16} V(S_i) = (-2) + (1) + (-7) + (-5) = -13\n$$\n\nAlternatively, we can count the frequency of each output value:\n- The value $V(S)=1$ occurs $3$ times.\n- The value $V(S)=0$ occurs $3$ times.\n- The value $V(S)=-1$ occurs $4$ times.\n- The value $V(S)=-2$ occurs $6$ times.\n(Check: $3+3+4+6 = 16$).\n\nThe sum of the values is:\n$$\n\\sum V(S) = (3 \\times 1) + (3 \\times 0) + (4 \\times -1) + (6 \\times -2) = 3 + 0 - 4 - 12 = -13\n$$\nBoth methods yield the same sum.\nNow, we can compute the expected value:\n$$\nE[S] = \\frac{1}{16} \\sum_{i=1}^{16} V(S_i) = \\frac{-13}{16}\n$$\n\nThe exact expected value of the saturating sum $S$ is $-\\frac{13}{16}$.",
            "answer": "$$\n\\boxed{-\\frac{13}{16}}\n$$"
        },
        {
            "introduction": "Efficiency is paramount in digital design, and optimizing logic is a key skill for any computer architect. This advanced practice introduces the design of a radix-4 Booth recoder, a key component that accelerates multiplication, and the powerful optimization technique of using \"don't-care\" conditions. Don't-cares arise from input patterns that are guaranteed not to occur in a specific circuit's context, and they provide flexibility to simplify the logic significantly. By applying this concept to specialized recoders at the boundaries of a multiplier , you will practice a technique fundamental to modern logic synthesis, learning how to create smaller, faster, and more efficient hardware.",
            "id": "3686319",
            "problem": "A radix-$4$ Booth recoder consumes overlapping $3$-bit groups $\\left(x_2,x_1,x_0\\right)$ of a two's complement multiplier and commands a partial product multiplexer to select one of $\\{0,+M,-M,+2M,-2M\\}$, where $M$ is the multiplicand. In radix-$4$ Booth recoding, each $3$-bit group is interpreted using the canonical rules of Booth recoding, and one-hot control signals are produced for the multiplexer: $S_{+2}$, $S_{+1}$, $S_{0}$, $S_{-1}$, $S_{-2}$, where exactly one is asserted for each valid input combination. The base cases for the mapping are the eight combinations of $\\left(x_2,x_1,x_0\\right)\\in\\{0,1\\}^3$ and the standard radix-$4$ Booth interpretation of these triples.\n\nUsing the fundamental definition of a truth table in Boolean logic and the standard radix-$4$ Booth recoding semantics, do the following:\n\n1. Construct the canonical truth table that maps each $\\left(x_2,x_1,x_0\\right)$ to the one-hot outputs $\\left(S_{+2},S_{+1},S_{0},S_{-1},S_{-2}\\right)$, consistent with the classical radix-$4$ Booth rules for a two's complement multiplier.\n\n2. Incorporate boundary conditions as don't-care patterns for specialized recoders at the least significant bit (LSB) and most significant bit (MSB):\n   - At the LSB boundary, the implicit bit below the least significant multiplier bit is $x_{-1}=0$, so for the LSB group $\\left(x_2,x_1,x_0\\right)$ one has $x_0=0$; therefore, any input with $x_0=1$ is an unused pattern and must be treated as a don't-care.\n   - At the MSB boundary, the sign extension implies $x_2=x_1$ for the topmost group; therefore, any input with $x_2\\neq x_1$ is an unused pattern and must be treated as a don't-care.\n\n3. From the resulting truth table and boundary don't-care sets, derive minimized sum-of-products implementations for:\n   - $S_{+1}$ in the LSB-specialized recoder using the LSB don't-care set.\n   - $S_{-1}$ in the MSB-specialized recoder using the MSB don't-care set.\n\n   Let a literal be defined as an appearance of a variable $x_i$ or its complement $\\bar{x}_i$ in a product term. The literal count of an expression is the sum of the number of literals across all product terms in its sum-of-products form.\n\nCompute the sum of the literal counts of the two minimized expressions found in step $3$. Report this single number. No rounding is required and no units apply.",
            "solution": "The problem has been validated and is deemed scientifically grounded, well-posed, and objective. It is a standard problem in digital logic design as applied to computer arithmetic. The problem statement is self-contained and provides sufficient information to derive a unique numerical answer.\n\nThe solution proceeds in three steps as outlined in the problem description.\n\n**Step 1: Canonical Truth Table for Radix-4 Booth Recoding**\n\nA radix-$4$ Booth recoder examines a $3$-bit group of the multiplier, denoted by the generic inputs $(x_2, x_1, x_0)$. The group consists of two adjacent multiplier bits and one bit from the next lower-order pair, i.e., $(y_{i+1}, y_i, y_{i-1})$ becomes $(x_2, x_1, x_0)$. The value of the recoded digit is given by the formula $$V = x_0 + x_1 - 2x_2$$ This value determines which multiple of the multiplicand $M$ to use for the partial product: $\\{0, +1, -1, +2, -2\\}$. The control logic generates five one-hot signals: $(S_{+2}, S_{+1}, S_{0}, S_{-1}, S_{-2})$, where only the signal corresponding to the computed value $V$ is asserted (equal to $1$).\n\nThe canonical truth table mapping the input bits $(x_2, x_1, x_0)$ to the recoded value $V$ and the one-hot outputs is as follows:\n\n| Minterm | $x_2$ | $x_1$ | $x_0$ | $V = x_0 + x_1 - 2x_2$ | Operation      | $S_{+2}$ | $S_{+1}$ | $S_{0}$ | $S_{-1}$ | $S_{-2}$ |\n|---------|-------|-------|-------|--------------------------|----------------|----------|----------|---------|----------|----------|\n| $m_0$   | $0$   | $0$   | $0$   | $0$                      | $0 \\times M$   | $0$      | $0$      | $1$     | $0$      | $0$      |\n| $m_1$   | $0$   | $0$   | $1$   | $1$                      | $+1 \\times M$  | $0$      | $1$      | $0$     | $0$      | $0$      |\n| $m_2$   | $0$   | $1$   | $0$   | $1$                      | $+1 \\times M$  | $0$      | $1$      | $0$     | $0$      | $0$      |\n| $m_3$   | $0$   | $1$   | $1$   | $2$                      | $+2 \\times M$  | $1$      | $0$      | $0$     | $0$      | $0$      |\n| $m_4$   | $1$   | $0$   | $0$   | $-2$                     | $-2 \\times M$  | $0$      | $0$      | $0$     | $0$      | $1$      |\n| $m_5$   | $1$   | $0$   | $1$   | $-1$                     | $-1 \\times M$  | $0$      | $0$      | $0$     | $1$      | $0$      |\n| $m_6$   | $1$   | $1$   | $0$   | $-1$                     | $-1 \\times M$  | $0$      | $0$      | $0$     | $1$      | $0$      |\n| $m_7$   | $1$   | $1$   | $1$   | $0$                      | $0 \\times M$   | $0$      | $0$      | $1$     | $0$      | $0$      |\n\n**Step 2: Boundary Conditions and Don't-Care Sets**\n\nFor specialized recoders at the least significant bit (LSB) and most significant bit (MSB) positions, certain input patterns to the generic recoder logic are impossible. These unused patterns can be treated as don't-care conditions ($X$) to simplify the logic.\n\n-   **LSB Recoder**: At the LSB, the input group is formed from multiplier bits $(y_1, y_0, y_{-1})$. The bit $y_{-1}$ is an implicit $0$ padded below the LSB. When mapped to the generic recoder inputs $(x_2, x_1, x_0)$, we have $x_0 = y_{-1} = 0$. Therefore, any input combination where $x_0=1$ is an unused pattern. The LSB don't-care set is $D_{LSB} = \\{m_1, m_3, m_5, m_7\\}$.\n-   **MSB Recoder**: At the MSB, sign extension is used for a two's complement multiplier. For the topmost group, the two most significant bits fed to the recoder are identical. In terms of the generic inputs $(x_2, x_1, x_0)$, this means $x_2 = x_1$. Therefore, any input combination where $x_2 \\neq x_1$ is an unused pattern. The MSB don't-care set is $D_{MSB} = \\{m_2, m_3, m_4, m_5\\}$.\n\n**Step 3: Minimized Sum-of-Products (SOP) Implementations**\n\nWe will use Karnaugh maps to derive the minimized SOP expressions.\n\n**A. $S_{+1}$ for the LSB-Specialized Recoder**\n\nThe function to be implemented must produce the correct outputs for all occurring inputs (where $x_0=0$) and can produce any output for don't-care inputs (where $x_0=1$).\n\nFrom the canonical truth table, the required behavior for occurring inputs is:\n-   $S_{+1}(m_0) = S_{+1}(0,0,0) = 0$\n-   $S_{+1}(m_2) = S_{+1}(0,1,0) = 1$\n-   $S_{+1}(m_4) = S_{+1}(1,0,0) = 0$\n-   $S_{+1}(m_6) = S_{+1}(1,1,0) = 0$\n\nThe on-set for minimization is $\\{m_2\\}$. The don't-care set is $D_{LSB} = \\{m_1, m_3, m_5, m_7\\}$.\n\nThe Karnaugh map for $S_{+1}$ with LSB don't-cares is:\n\n| $x_2 \\backslash x_1x_0$ | 00 | 01 | 11 | 10 |\n|---|---|---|---|---|\n| **0** | 0 | X | X | 1 |\n| **1** | 0 | X | X | 0 |\n\nTo cover the single '1' at $m_2 = \\bar{x_2}x_1\\bar{x_0}$, we form the largest possible group. We can group $m_2$ with the adjacent don't-care minterm $m_3 = \\bar{x_2}x_1x_0$. This creates a group of two, $\\{m_2, m_3\\}$, which corresponds to the product term where $x_2=0$ and $x_1=1$. The variable $x_0$ is eliminated.\n\nThe minimized SOP expression for $S_{+1}$ in the LSB recoder is:\n$$S_{+1, LSB} = \\bar{x_2}x_1$$\nThis expression contains two literals: $\\bar{x_2}$ and $x_1$. The literal count is $2$.\n\n**B. $S_{-1}$ for the MSB-Specialized Recoder**\n\nThe function must be correct for all occurring inputs (where $x_2=x_1$).\nFrom the canonical truth table, the required behavior for occurring inputs is:\n-   $S_{-1}(m_0) = S_{-1}(0,0,0) = 0$\n-   $S_{-1}(m_1) = S_{-1}(0,0,1) = 0$\n-   $S_{-1}(m_6) = S_{-1}(1,1,0) = 1$\n-   $S_{-1}(m_7) = S_{-1}(1,1,1) = 0$\n\nThe on-set for minimization is $\\{m_6\\}$. The don't-care set is $D_{MSB} = \\{m_2, m_3, m_4, m_5\\}$.\n\nThe Karnaugh map for $S_{-1}$ with MSB don't-cares is:\n\n| $x_2 \\backslash x_1x_0$ | 00 | 01 | 11 | 10 |\n|---|---|---|---|---|\n| **0** | 0 | 0 | X | X |\n| **1** | X | X | 0 | 1 |\n\nTo cover the single '1' at $m_6 = x_2x_1\\bar{x_0}$, we form the largest possible group. There are two options for forming a group of two with adjacent don't-care minterms:\n1.  Group $\\{m_6, m_2\\}$. This covers $(1,1,0)$ and $(0,1,0)$, eliminating $x_2$ and yielding the term $x_1\\bar{x_0}$.\n2.  Group $\\{m_6, m_4\\}$. This covers $(1,1,0)$ and $(1,0,0)$, eliminating $x_1$ and yielding the term $x_2\\bar{x_0}$.\n\nBoth options result in a valid minimal SOP with a single product term.\n$$S_{-1, MSB} = x_1\\bar{x_0}$$\n$$S_{-1, MSB} = x_2\\bar{x_0}$$\n\nIn either case, the minimized expression contains two literals. For example, $x_1\\bar{x_0}$ has literals $x_1$ and $\\bar{x_0}$. The literal count is $2$.\n\n**Final Calculation: Sum of Literal Counts**\n\nThe problem asks for the sum of the literal counts of the two minimized expressions.\n-   Literal count for $S_{+1, LSB}$ is $2$.\n-   Literal count for $S_{-1, MSB}$ is $2$.\n\nThe sum of the literal counts is $2 + 2 = 4$.",
            "answer": "$$\\boxed{4}$$"
        }
    ]
}