{
    "hands_on_practices": [
        {
            "introduction": "More complex protocols are not always superior; their benefits often depend on the specific workload. This first exercise challenges you to rigorously analyze a \"ping-pong\" scenario of back-to-back writes, a common source of contention in parallel programs . By counting the exact number of coherence messages, you will discover whether the advanced 'Owned' state in the MOESI protocol provides any advantage over the simpler MESI protocol in this situation, sharpening your intuition about protocol-level performance.",
            "id": "3635489",
            "problem": "Consider a directory-based cache coherence system with a centralized directory that maintains, for each cache line, a sharer vector and (if applicable) a single owner identifier. The interconnect is reliable and ordered, and the directory issues coherence actions by sending messages to nodes and receiving corresponding acknowledgments or data. Two protocols are considered: Modified-Exclusive-Shared-Invalid (MESI) and Modified-Owner-Exclusive-Shared-Invalid (MOESI), where the MOESI protocol adds the Owned state to allow a dirty line to be supplied to sharers without writing it back to memory. Assume two cores, denoted by $C_0$ and $C_1$, alternately perform writes to the same cache line $x$ in back-to-back fashion, starting from a cold state in which line $x$ is not cached by any core and the directory marks it as uncached. Specifically, there are $10$ writes total: $C_0$ writes, then $C_1$ writes, and this pair repeats until each core has written $5$ times.\n\nTreat a \"round trip\" as one request-response pair initiated by the directory to any node, namely, the memory controller or a core. A round trip thereby consists of one directory-to-node coherence action message followed by the corresponding node-to-directory acknowledgment or data message needed to complete that action. Count only directory-initiated round trips; do not count core-to-directory requests, directory-to-core data responses, or any local cache hit processing. Ignore capacity evictions and assume all necessary cache-to-cache transfers are orchestrated by the directory without involving the memory controller except when fetching from memory on a cold miss.\n\nUsing the fundamental definitions of the MESI and MOESI protocols and the semantics of directory-based ownership transfers, analyze the complete $10$-write back-to-back sequence and compute the total number of directory-initiated round trips under MESI, denoted $R_{\\text{MESI}}$, and under MOESI, denoted $R_{\\text{MOESI}}$. Then, quantify whether the Owned state can reduce write ping-pong by evaluating the relative improvement\n$$I \\equiv \\frac{R_{\\text{MESI}} - R_{\\text{MOESI}}}{R_{\\text{MESI}}}.$$\nReport $I$ as a single real number. No rounding is required. Assume the following system properties: the directory performs owner interventions for lines in the Modified or Owned states by sending a forward/invalidate to the current owner, the owner responds directly with the required acknowledgment or data to the directory, and sharer invalidations (if any) require acknowledgments to the directory before completion. There are no concurrent third-party sharers beyond $C_0$ and $C_1$ in this workload.",
            "solution": "The problem requires an analysis of a specific workload on a directory-based cache coherence system to compare the performance of the MESI and MOESI protocols. The performance metric is the total number of directory-initiated round trips, $R$, over a sequence of $10$ alternating writes to the same cache line $x$ by two cores, $C_0$ and $C_1$. The relative improvement $I$ of MOESI over MESI must then be calculated.\n\nFirst, we must precisely define what constitutes a \"round trip\" according to the problem statement. A round trip is a request-response pair initiated by the directory to another node (a core or the memory controller). Specifically, it is a directory-to-node message followed by the corresponding node-to-directory acknowledgment or data message. Core-to-directory requests and directory-to-core data-only responses are explicitly excluded from this count.\n\nThe workload consists of $10$ total writes to a single cache line $x$. The sequence is: $C_0$ writes, $C_1$ writes, $C_0$ writes, etc., for $5$ writes per core. Initially, the line is uncached by any core (both cores hold it in the Invalid (I) state), and the directory marks it as Uncached.\n\nLet us analyze the sequence for the MESI protocol first to determine $R_{\\text{MESI}}$.\n\n**Analysis for MESI Protocol**\n\n*   **Write 1 ($C_0$ writes to $x$):**\n    1.  $C_0$ has the line in state I, resulting in a write miss. It sends a Get Exclusive (GetX) request to the directory. This is not counted.\n    2.  The directory receives the GetX request. It sees the line is Uncached. To service the miss, the directory must fetch the data from main memory.\n    3.  The directory sends a \"Get Data\" request to the memory controller. The memory controller responds with the data block. This constitutes a directory-initiated request and a corresponding response, so it is counted as $1$ round trip.\n    4.  The directory updates its internal state, marking $C_0$ as the owner in the Modified (M) state. It then sends the data to $C_0$ (not counted).\n    5.  $C_0$ receives the data, caches the line in state M, and performs the write.\n    *   Round trips for this step: $1$.\n    *   State after Write 1: Directory=(M, Owner=$C_0$, Sharers={}), $C_0$=(M), $C_1$=(I).\n\n*   **Write 2 ($C_1$ writes to $x$):**\n    1.  $C_1$ has the line in state I, resulting in a write miss. It sends a GetX request to the directory (not counted).\n    2.  The directory receives the GetX. It sees the line is in state M, with owner $C_0$. To grant exclusive access to $C_1$, the directory must retrieve the most recent data from $C_0$ and invalidate $C_0$'s copy.\n    3.  The directory sends a \"Forward/Invalidate\" request to the current owner, $C_0$. $C_0$ receives this request, invalidates its copy (transitioning from M to I), and sends the data block back to the directory. This request-response pair initiated by the directory is counted as $1$ round trip.\n    4.  The directory receives the data from $C_0$, updates its state to mark $C_1$ as the new owner in state M, and forwards the data to $C_1$ (not counted).\n    5.  $C_1$ caches the line in M state and performs the write.\n    *   Round trips for this step: $1$.\n    *   State after Write 2: Directory=(M, Owner=$C_1$, Sharers={}), $C_0$=(I), $C_1$=(M).\n\n*   **Subsequent Writes (3 through 10):**\n    The pattern established in Write 2 repeats for every subsequent write. Each write is from the core that does not currently own the line. This core will have the line in state I, causing a write miss. The directory will identify the other core as the owner in state M and initiate a Forward/Invalidate round trip to that owner to retrieve the data and enforce exclusivity. For example, for Write 3, $C_0$ sends GetX, the directory sends a Forward/Invalidate to $C_1$, and $C_1$ responds to the directory. This costs $1$ round trip. This \"ping-pong\" behavior continues for all remaining writes.\n\n*   **Total Round Trips for MESI ($R_{\\text{MESI}}$):**\n    There is $1$ write that is a cold miss and $10-1 = 9$ writes that result in ownership transfers between the two cores.\n    $$R_{\\text{MESI}} = \\underbrace{1}_{\\text{Write 1}} + \\underbrace{9 \\times 1}_{\\text{Writes 2-10}} = 10$$\n    The total number of directory-initiated round trips under MESI is $R_{\\text{MESI}} = 10$.\n\nNow, we analyze the sequence for the MOESI protocol to determine $R_{\\text{MOESI}}$.\n\n**Analysis for MOESI Protocol**\n\nThe MOESI protocol adds the Owned (O) state. The O state is a *shared dirty* state, which allows a core to hold a modified copy of a cache line while other cores hold read-only (Shared, S) copies. This is beneficial in workloads with read-sharing of dirty data, as it allows the owner to supply the data to other readers without first writing it back to memory.\n\nHowever, the specified workload consists exclusively of writes. A write operation by a core requires exclusive ownership of the cache line. To obtain this, a core sends a Get Exclusive (GetX) request. Upon receiving a GetX, the directory's primary obligation is to ensure that no other cores retain a copy of the line, thereby granting exclusivity to the requestor.\n\nLet's examine the state transitions for the given workload under MOESI:\n*   **Write 1 ($C_0$ writes to $x$):** The behavior is identical to MESI. A cold miss is serviced from memory. $C_0$ obtains the line in state M. This costs $1$ round trip (Dir $\\leftrightarrow$ Mem).\n*   **Write 2 ($C_1$ writes to $x$):** $C_1$ sends a GetX request. The directory sees that $C_0$ owns the line in state M. To satisfy the GetX, the directory must invalidate $C_0$'s copy. The transition M $\\rightarrow$ O is not applicable here because that would imply sharing, which is contrary to the exclusive access required for the write by $C_1$. Therefore, the directory sends a Forward/Invalidate request to $C_0$, which responds with the data and transitions its state from M to I. This is identical to the MESI case and costs $1$ round trip.\n*   **Subsequent Writes (3 through 10):** The same logic applies. Each write is a GetX request from a core that does not have a valid copy. The directory must invalidate the current M-state owner to transfer exclusive ownership. The Owned state is never entered because there is never a Get Shared (GetS) request for a dirty line that would trigger the M $\\rightarrow$ O transition.\n\nThe sequence of operations and messages under MOESI for this specific pure-write, ping-pong workload is identical to that under MESI.\n\n*   **Total Round Trips for MOESI ($R_{\\text{MOESI}}$):**\n    The calculation is identical to the MESI case.\n    $$R_{\\text{MOESI}} = \\underbrace{1}_{\\text{Write 1}} + \\underbrace{9 \\times 1}_{\\text{Writes 2-10}} = 10$$\n    The total number of directory-initiated round trips under MOESI is $R_{\\text{MOESI}} = 10$.\n\nFinally, we compute the relative improvement, $I$.\n\n**Calculation of Relative Improvement ($I$)**\n\nThe relative improvement is defined as:\n$$I = \\frac{R_{\\text{MESI}} - R_{\\text{MOESI}}}{R_{\\text{MESI}}}$$\nSubstituting the calculated values:\n$$I = \\frac{10 - 10}{10} = \\frac{0}{10} = 0$$\nThe result $I=0$ indicates that for this specific workload of back-to-back writes, the MOESI protocol offers no improvement over the MESI protocol in terms of directory-initiated round trips. The Owned state, which is the key feature of MOESI, is not leveraged by a workload that does not involve read-sharing of dirty data.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "Effective system performance depends on the seamless interaction between different components. This practice explores how a private cache's local policy—specifically, write-back versus write-through—can dramatically alter the traffic patterns seen by the central directory. By modeling a classic producer-consumer workload , you will quantify how these policies impact message counts and learn how workload characteristics, such as data reuse within a cache line, determine the most efficient approach.",
            "id": "3635552",
            "problem": "A computer system implements a centralized directory-based cache coherence protocol with the Modified–Exclusive–Shared–Invalid (MESI) states tracked at a shared last-level cache that also houses the directory. Consider a single-producer/single-consumer queue implemented as a ring buffer in shared memory. The producer core writes one scalar value per queue slot and the consumer core reads each produced value exactly once, in program order. Define the line reuse rate $u$ as the expected number of consecutive items (produced values) that map to and are written into the same cache line by the producer before the consumer performs its first read of that cache line; assume $u \\ge 1$ and that $u$ may be treated as a real-valued parameter representing an average. Assume the following microarchitectural and protocol conditions, each of which is standard and scientifically realistic:\n\n- The directory is inclusive and co-located with the last-level cache, which supplies data to requestors unless some private cache holds the line in the Modified state.\n- The producer and consumer cores are the only caches that ever touch the queue lines. There are no other sharers.\n- After the consumer finishes reading a cache line, both caches may retain the line in the Shared state. Before the producer writes that line again, it holds the line in the Shared state and must upgrade to the Modified state. There are no capacity evictions during the interval considered, and there is no prefetching.\n- The consumer’s first read to a line that the producer just updated causes a read miss at the consumer’s private cache. Subsequent reads by the consumer to the same line hit locally and generate no coherence traffic.\n- Count only point-to-point coherence messages transiting between a private cache and the directory, or between the directory and a private cache. Memory array accesses internal to the last-level cache are not separately counted. Each distinct coherence or data message counts as exactly $1$ message.\n\nThe private level-$1$ caches can be configured in one of two policies while keeping the directory protocol unchanged:\n\n- Write-back policy (WB): a store to a line in the Modified state does not send data to the directory until a downgrade or write-back is required by coherence.\n- Write-through policy (WT): a store to a line in the Modified state sends the updated data to the directory/last-level cache immediately. Assume write-allocate and that each store generates exactly $1$ write-through data message to the directory.\n\nUnder these assumptions, for a single cache line’s producer-consumer “handoff” cycle (producer writes the line, then consumer reads it once), the following coherence actions occur:\n\n- Producer upgrade from Shared to Modified before its first store to that line in the new cycle: exactly $1$ upgrade request from the producer to the directory, exactly $1$ invalidate from the directory to the consumer, and exactly $1$ acknowledgment from the consumer to the directory. No data is sent to the producer on upgrade because it already holds a valid Shared copy.\n- Consumer’s first read miss to that line in the cycle:\n  - Under WB: exactly $1$ read request from the consumer to the directory; because the producer holds the latest data in the Modified state, the directory sends exactly $1$ recall to the producer, receives exactly $1$ write-back data message from the producer, and then sends exactly $1$ data response to the consumer, which also downgrades the producer to Shared.\n  - Under WT: exactly $1$ read request from the consumer to the directory; the last-level cache already holds the most recent data due to write-through, so the directory sends exactly $1$ data response to the consumer and also sends exactly $1$ downgrade to the producer, which replies with exactly $1$ acknowledgment.\n\nDesign a microbenchmark consisting of a long steady-state run of such handoff cycles and derive, from first principles and the definitions above, a closed-form expression for the expected total number of directory-visible messages per produced item as a function of the line reuse rate $u$, for both the write-back and write-through policies. Your derivation must:\n\n- Start from the definitions of the MESI states and directory-mediated transitions, and the stipulated message sequences above.\n- Account for the fact that the consumer’s subsequent reads to the same line after its first miss do not incur coherence messages.\n- Under WT, account for the fact that each of the producer’s $u$ stores in the line generates a write-through data message to the directory, while under WB no per-store message occurs in the steady state.\n\nReport your final result as a single row matrix whose first entry is the expected messages-per-item under write-back and whose second entry is the expected messages-per-item under write-through. No numerical rounding is required, and the final result should be an exact analytic expression in terms of $u$.",
            "solution": "The objective is to derive a closed-form expression for the expected number of directory-visible messages per produced item for a single-producer/single-consumer queue. The derivation will be performed for two private cache policies: write-back (WB) and write-through (WT). The analysis is based on a steady-state handoff cycle for a single cache line, which corresponds to the production of $u$ items, where $u$ is the line reuse rate.\n\nThe problem defines a handoff cycle as the sequence of events starting from the producer preparing to write to a shared cache line, writing $u$ items, and the consumer subsequently reading those $u$ items. We will calculate the total number of coherence messages for one such cycle and then divide by $u$ to find the average number of messages per item.\n\nLet's analyze the cycle in distinct phases as described in the problem statement. A cycle begins with both the producer and consumer caches holding the line in the Shared (S) state from a previous cycle.\n\nPhase 1: Producer Upgrade\nTo write to the cache line, the producer must first gain exclusive ownership by upgrading its state from Shared (S) to Modified (M). According to the problem, this action requires:\n- $1$ upgrade request message from the producer to the directory.\n- $1$ invalidate message from the directory to the consumer cache.\n- $1$ acknowledgment message from the consumer to the directory.\nThe total number of messages for the upgrade phase, $N_{upg}$, is constant for both policies:\n$$N_{upg} = 1 + 1 + 1 = 3$$\n\nPhase 2: Producer Stores\nAfter gaining Modified status, the producer writes $u$ distinct scalar values into the cache line. The message cost of these stores depends on the cache policy.\n\nPhase 3: Consumer Reads\nThe consumer reads the $u$ items produced. The first read to the updated line by the consumer will cause a read miss, as its copy was invalidated in Phase 1. Subsequent reads of the other $u-1$ items from the same line will be local hits and, as stated, generate no coherence traffic. We only need to account for the messages generated by the initial read miss.\n\nLet's now calculate the total messages per cycle and per item for each policy.\n\n**Write-Back (WB) Policy**\n\nIn the WB policy, stores to a line in the Modified state are handled locally at the producer's private cache and do not generate network traffic.\n- Phase 2 (Producer Stores): The $u$ stores generate no messages.\n$$N_{stores, WB} = 0$$\n- Phase 3 (Consumer's First Read): The consumer's read miss is serviced. The problem specifies the sequence for WB: the directory must recall the data from the producer, which holds the only up-to-date copy in the Modified state.\n  - $1$ read request from the consumer to the directory.\n  - $1$ recall message from the directory to the producer.\n  - $1$ write-back data message from the producer to the directory.\n  - $1$ data response message from the directory to the consumer.\nThe total number of messages for the consumer's read miss under WB is:\n$$N_{read, WB} = 1 + 1 + 1 + 1 = 4$$\n\nThe total number of messages for one full handoff cycle ($N_{cycle, WB}$) is the sum of messages from all phases:\n$$N_{cycle, WB} = N_{upg} + N_{stores, WB} + N_{read, WB} = 3 + 0 + 4 = 7$$\nThis cycle corresponds to the production of $u$ items. The expected number of messages per item, $M_{item, WB}$, is the total number of messages per cycle divided by $u$:\n$$M_{item, WB} = \\frac{N_{cycle, WB}}{u} = \\frac{7}{u}$$\n\n**Write-Through (WT) Policy**\n\nIn the WT policy, every store to a line in the Modified state also sends the data to the directory.\n- Phase 2 (Producer Stores): Each of the $u$ stores generates one write-through data message to the directory.\n$$N_{stores, WT} = u \\times 1 = u$$\n- Phase 3 (Consumer's First Read): The consumer's read miss is serviced. For WT, the directory/L3 already has the up-to-date data. The problem specifies the sequence:\n  - $1$ read request from the consumer to the directory.\n  - $1$ data response from the directory to the consumer.\n  - $1$ downgrade message from the directory to the producer (to change its state from M to S).\n  - $1$ acknowledgment message from the producer to the directory.\nThe total number of messages for the consumer's read miss under WT is:\n$$N_{read, WT} = 1 + 1 + 1 + 1 = 4$$\n\nThe total number of messages for one full handoff cycle ($N_{cycle, WT}$) is the sum of messages from all phases:\n$$N_{cycle, WT} = N_{upg} + N_{stores, WT} + N_{read, WT} = 3 + u + 4 = u + 7$$\nThis cycle also corresponds to the production of $u$ items. The expected number of messages per item, $M_{item, WT}$, is the total number of messages per cycle divided by $u$:\n$$M_{item, WT} = \\frac{u + 7}{u} = 1 + \\frac{7}{u}$$\n\nThe final result is a row matrix containing the expressions for the expected messages per item for the WB and WT policies, respectively.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{7}{u} & 1 + \\frac{7}{u} \\end{pmatrix} } $$"
        },
        {
            "introduction": "This final exercise places you in the role of a system architect seeking to optimize performance for a critical application: parallel matrix multiplication. You will construct a performance model that captures a fundamental architectural trade-off: the effect of cache-line size on both compulsory read misses and expensive false sharing . This practice demonstrates how to translate high-level algorithmic behavior into a mathematical model and use it to derive an optimal hardware configuration.",
            "id": "3635600",
            "problem": "Consider a shared-memory multiprocessor running a directory-based cache coherence protocol with invalidation on writes (e.g., Modified–Exclusive–Shared–Invalid, MESI). There are $T$ hardware threads, each with a private write-back level-one data cache whose cache-line size is $\\ell$ bytes. All arrays are stored in row-major order. A parallel, blocked matrix multiplication computes $C \\leftarrow A \\times B$ for three dense $M \\times M$ matrices of elements of size $s$ bytes. The computation is scheduled so that:\n- Each thread owns a contiguous vertical strip of columns of $C$; strips partition the $M$ columns evenly across the $T$ threads without overlap.\n- Each thread computes its assigned elements of $C$ using register accumulation and writes each element of $C$ exactly once at the end of its computation.\n- Arrays $A$ and $B$ are read-only during the multiplication.\n\nTo capture coherence and directory overheads at scale without enumerating fine-grained reuse, adopt the following scientifically grounded and simplified model of directory traffic:\n1. For read misses of $A$ and $B$, the aggregate number of distinct read-miss cache lines over the entire multiplication is modeled as $\\alpha \\frac{M^{3} s}{\\ell}$, where $\\alpha$ is a dimensionless constant reflecting algorithmic tiling and reuse. Each such read miss generates, on average, $c_{r}$ bytes of directory control traffic (sum of request, directory reply, and coherence bookkeeping), independent of data payload size.\n2. For writes to $C$, false sharing across threads can occur along the vertical strip boundaries. In each row, there are $T-1$ such boundaries between neighboring strips. For a given row-boundary and a given cache-line size $\\ell$, model the offset of the boundary relative to cache-line alignment as uniformly distributed over the $\\ell/s$ element positions within a cache line. Under this model, the probability that the boundary falls strictly inside a cache line (so that two different threads write different words within the same cache line) is $p_{\\mathrm{fs}}(\\ell) = 1 - \\frac{s}{\\ell}$ for $\\ell \\ge s$. When false sharing occurs at a boundary in a row, exactly one cache-to-cache transfer of the cache line occurs between the two threads, incurring $\\ell$ bytes of data motion plus $c_{w}$ bytes of directory control traffic (write miss request, invalidation to prior owner, and acknowledgment), before the second writer can obtain exclusive ownership.\n\nAssume that the alignment of the boundary with respect to cache-line boundaries is independent across rows, and that cache evictions do not suppress this single transfer for a boundary where false sharing occurs. Define the total expected directory traffic, $D(\\ell)$, as the sum of the read-miss control traffic for $A$ and $B$ and the false-sharing traffic for $C$. You may ignore any $\\ell$-independent constant data payload traffic (such as the compulsory data fetched from memory for read misses), since it does not affect the optimization over $\\ell$.\n\nStarting only from the above definitions and model assumptions, and taking $\\ell$ as a continuous variable with $\\ell \\ge s$, derive a closed-form expression for the cache-line size $\\ell^{\\star}$ that minimizes $D(\\ell)$. State any regularity conditions you require for an interior minimum to exist. Express your final answer as a symbolic function of the parameters $T$, $M$, $s$, $\\alpha$, $c_{r}$, and $c_{w}$. No numerical substitution is required, and no rounding is needed. The final answer must be a single analytic expression.",
            "solution": "The objective is to find the optimal cache-line size, denoted as $\\ell^{\\star}$, that minimizes the total expected directory traffic, $D(\\ell)$. The problem specifies that $\\ell$ is a continuous variable such that $\\ell \\ge s$, where $s$ is the size of a matrix element in bytes. We assume the number of threads $T > 1$, as the concept of coherence traffic is relevant only in a multiprocessor context.\n\nFirst, we must formulate the function for the total expected directory traffic, $D(\\ell)$. As defined in the problem, $D(\\ell)$ is the sum of two components: the read-miss control traffic for matrices $A$ and $B$, which we denote $D_{\\text{read}}(\\ell)$, and the false-sharing traffic for matrix $C$, denoted $D_{\\text{write}}(\\ell)$.\n$$ D(\\ell) = D_{\\text{read}}(\\ell) + D_{\\text{write}}(\\ell) $$\n\nLet us derive the expression for each component based on the provided model.\n\n1.  **Read-Miss Control Traffic, $D_{\\text{read}}(\\ell)$**\nThe model states that the aggregate number of distinct read-miss cache lines for matrices $A$ and $B$ over the entire computation is $\\alpha \\frac{M^3 s}{\\ell}$. Each such read miss generates an average of $c_r$ bytes of directory control traffic. Therefore, the total read-miss control traffic is the product of these two quantities:\n$$ D_{\\text{read}}(\\ell) = \\left(\\alpha \\frac{M^3 s}{\\ell}\\right) c_r = \\frac{\\alpha c_r M^3 s}{\\ell} $$\nThe problem permits ignoring $\\ell$-independent data payload traffic. The data payload for these read misses would be proportional to $(\\alpha \\frac{M^3 s}{\\ell}) \\times \\ell = \\alpha M^3 s$, which is independent of $\\ell$ and thus correctly omitted from the optimization function.\n\n2.  **False-Sharing Traffic, $D_{\\text{write}}(\\ell)$**\nFalse sharing on matrix $C$ occurs at the vertical boundaries between strips of columns assigned to different threads. There are $M$ rows in matrix $C$ and $T-1$ such boundaries in each row. The total number of locations where false sharing can occur is thus $M(T-1)$.\n\nFor each boundary, the model provides the probability of false sharing, $p_{\\mathrm{fs}}(\\ell)$, as:\n$$ p_{\\mathrm{fs}}(\\ell) = 1 - \\frac{s}{\\ell} $$\nWhen false sharing occurs at a boundary, it incurs a traffic cost of $\\ell + c_w$ bytes, which includes $\\ell$ bytes for the cache-to-cache data transfer and $c_w$ bytes for directory control traffic.\n\nThe expected traffic for a single boundary is the product of the probability of the event and its cost:\n$$ E[\\text{traffic per boundary}] = p_{\\mathrm{fs}}(\\ell) \\times (\\ell + c_w) = \\left(1 - \\frac{s}{\\ell}\\right)(\\ell + c_w) $$\nExpanding this expression, we get:\n$$ E[\\text{traffic per boundary}] = \\ell + c_w - s - \\frac{sc_w}{\\ell} $$\nThe total expected false-sharing traffic, $D_{\\text{write}}(\\ell)$, is the expected traffic per boundary multiplied by the total number of boundaries, $M(T-1)$, as the alignment is assumed to be independent across rows.\n$$ D_{\\text{write}}(\\ell) = M(T-1) \\left(\\ell + c_w - s - \\frac{sc_w}{\\ell}\\right) $$\n\n3.  **Total Expected Directory Traffic, $D(\\ell)$**\nCombining the two components, the total traffic function $D(\\ell)$ is:\n$$ D(\\ell) = D_{\\text{read}}(\\ell) + D_{\\text{write}}(\\ell) = \\frac{\\alpha c_r M^3 s}{\\ell} + M(T-1) \\left(\\ell + c_w - s - \\frac{sc_w}{\\ell}\\right) $$\nTo facilitate minimization, we group terms based on their dependence on $\\ell$:\n$$ D(\\ell) = M(T-1)\\ell + \\left( \\alpha c_r M^3 s - M(T-1)sc_w \\right)\\frac{1}{\\ell} + M(T-1)(c_w - s) $$\nThe term $M(T-1)(c_w - s)$ is a constant with respect to $\\ell$ and will not influence the location of the minimum.\n\n4.  **Minimization of $D(\\ell)$**\nTo find the value of $\\ell$ that minimizes $D(\\ell)$, we compute the first derivative of $D(\\ell)$ with respect to $\\ell$ and set it to zero.\n$$ \\frac{dD}{d\\ell} = \\frac{d}{d\\ell} \\left( M(T-1)\\ell + \\frac{\\alpha c_r M^3 s - M(T-1)sc_w}{\\ell} + \\text{constant} \\right) $$\n$$ \\frac{dD}{d\\ell} = M(T-1) - \\frac{\\alpha c_r M^3 s - M(T-1)sc_w}{\\ell^2} $$\nSetting the derivative to zero to find the optimal line size $\\ell^{\\star}$:\n$$ M(T-1) - \\frac{\\alpha c_r M^3 s - M(T-1)sc_w}{(\\ell^{\\star})^2} = 0 $$\n$$ M(T-1) = \\frac{\\alpha c_r M^3 s - M(T-1)sc_w}{(\\ell^{\\star})^2} $$\nSolving for $(\\ell^{\\star})^2$:\n$$ (\\ell^{\\star})^2 = \\frac{\\alpha c_r M^3 s - M(T-1)sc_w}{M(T-1)} = \\frac{\\alpha c_r M^3 s}{M(T-1)} - \\frac{M(T-1)sc_w}{M(T-1)} $$\n$$ (\\ell^{\\star})^2 = \\frac{\\alpha c_r M^2 s}{T-1} - sc_w $$\nTaking the square root gives the expression for $\\ell^{\\star}$:\n$$ \\ell^{\\star} = \\sqrt{\\frac{\\alpha c_r M^2 s}{T-1} - sc_w} $$\n\n5.  **Regularity Conditions for an Interior Minimum**\nFor this expression to represent a valid interior minimum, certain conditions must be met.\n-   First, the second derivative must be positive.\n    $$ \\frac{d^2D}{d\\ell^2} = \\frac{2(\\alpha c_r M^3 s - M(T-1)sc_w)}{\\ell^3} $$\n    For $\\ell > 0$, we require the numerator to be positive: $\\alpha c_r M^3 s - M(T-1)sc_w > 0$, which simplifies to $\\alpha c_r M^2 > (T-1)c_w$. This also ensures that the term inside the square root for $\\ell^{\\star}$ is positive, so $\\ell^{\\star}$ is a real number.\n-   Second, the problem domain specifies $\\ell \\ge s$. The derived $\\ell^{\\star}$ is an interior minimum only if $\\ell^{\\star} > s$. This requires:\n    $$ \\sqrt{\\frac{\\alpha c_r M^2 s}{T-1} - sc_w} > s $$\n    $$ \\frac{\\alpha c_r M^2 s}{T-1} - sc_w > s^2 $$\n    $$ \\frac{\\alpha c_r M^2}{T-1} > s + c_w $$\nThis is the regularity condition for an interior minimum to exist. If this condition is not met, the minimum of $D(\\ell)$ on the domain $[\\_s, \\infty)$ occurs at the boundary $\\ell = s$, assuming the function is convex.\n\nThe problem asks for the closed-form expression for $\\ell^{\\star}$ assuming an interior minimum exists. The derived expression is the answer under these conditions.\nFinal expression can be written as:\n$$ \\ell^{\\star} = \\sqrt{s \\left( \\frac{\\alpha c_r M^2}{T-1} - c_w \\right)} $$\nThis form clearly shows the dependence on the model parameters.",
            "answer": "$$\\boxed{\\sqrt{\\frac{\\alpha c_r M^2 s}{T-1} - sc_w}}$$"
        }
    ]
}