{
    "hands_on_practices": [
        {
            "introduction": "Classifying a computer system is not always straightforward, as its operational behavior might mask its true architectural nature. This first practice challenges you to look beyond surface-level synchronization and apply Flynn's taxonomy from first principles. By analyzing a fault-tolerant system, you will learn to identify the number of instruction and data streams based on fundamental hardware components like program counters, which is essential for accurate architectural classification .",
            "id": "3643557",
            "problem": "A reliability-oriented computer system uses Triple Modular Redundancy (TMR), where $N=3$ identical processing replicas execute the same compiled binary on the same sensor input stream. Each replica has its own program counter, instruction cache, and pipeline, and they run on independent clocks. The input distributor feeds each replica an identical copy of the sensor data, so each replica reads its own buffer containing the same values at the same times. After every epoch of $K$ instructions, a majority voter compares the three outputs to mask a single faulty replica if present.\n\nTo attempt lockstep coordination, the system software inserts a barrier after each instruction that forces all replicas to wait until the slowest replica has retired that instruction. Let the base per-instruction retirement time be $\\tau$ for each replica in fault-free operation, and let the synchronization overhead per instruction be $\\beta > 0$, representing measurable delay due to barrier coordination messages. There is no hardware instruction broadcast unit; each replica fetches and decodes instructions independently.\n\nUsing the core definitions from Flynn’s taxonomy:\n- Single Instruction Single Data (SISD): one instruction stream operating on one data stream.\n- Single Instruction Multiple Data (SIMD): one instruction stream broadcast to multiple processing elements operating on multiple data streams in lockstep.\n- Multiple Instruction Single Data (MISD): multiple instruction streams operating on a single data stream.\n- Multiple Instruction Multiple Data (MIMD): multiple instruction streams operating on multiple data streams, generally asynchronously,\n\nclassify the TMR system as one of these categories. Your classification must be based on first principles: the structural presence or absence of a single control unit issuing one instruction stream, the count of distinct instruction streams implied by independent program counters, and the nature of the data streams delivered by the input distributor. Consider the role of the synchronization overhead $\\beta$ in distinguishing structural broadcast from software lockstep.\n\nChoose the most appropriate classification.\n\nA. $SIMD$: a single instruction stream controls three execution lanes processing multiple data streams; per-instruction synchronization $\\beta$ does not alter the SIMD nature.\n\nB. $MIMD$: three independent instruction streams (one per replica) execute the same code over three replicated data streams; the per-instruction synchronization $\\beta$ is a coordination cost but the structure remains $MIMD$.\n\nC. $SISD$: the same program and same data imply one instruction stream and one data stream in aggregate despite physical replication.\n\nD. $MISD$: three distinct instruction streams operate on a single shared data stream to achieve fault masking; timing skew yields effectively different instruction sequences across replicas.",
            "solution": "The classification of the described TMR system according to Flynn's taxonomy depends on a structural analysis of its instruction and data streams, as dictated by the hardware implementation.\n\n**1. Analysis of Instruction Streams:**\n\nFlynn's taxonomy distinguishes between single and multiple instruction streams based on the number of control units in the system. A system with a single instruction stream has one control unit that fetches, decodes, and issues instructions to one or more processing elements. Conversely, a system with multiple instruction streams has multiple, independent control units.\n\nThe problem states that \"Each replica has its own program counter, instruction cache, and pipeline\" and that \"each replica fetches and decodes instructions independently.\" This is the definitive feature of a system with multiple control units. Each replica's program counter determines the flow of control for that specific replica. Even though all replicas execute the same compiled binary, they do so via separate, independent fetch-decode-execute cycles. Small variations in clock speeds, memory access latencies, or cache behavior can cause their program counters to temporarily point to different instructions, confirming their independence. The absence of a \"hardware instruction broadcast unit\" further solidifies that there is no single source of instructions.\n\nTherefore, the system has **multiple instruction streams** (specifically, $3$ of them). This conclusion immediately rules out the SISD (Single Instruction, Single Data) and SIMD (Single Instruction, Multiple Data) classifications.\n\n**2. Analysis of Data Streams:**\n\nFlynn's taxonomy distinguishes between single and multiple data streams based on the number of distinct sequences of data being processed.\n\nThe problem states that \"The input distributor feeds each replica an identical copy of the sensor data, so each replica reads its own buffer containing the same values\". From a hardware perspective, this means there are $3$ separate memory buffers, and each of the $3$ processing replicas accesses its own buffer. Although the *content* of these data streams is identical, they are physically distinct streams. Each processor operates on its own private copy of the data.\n\nTherefore, the system has **multiple data streams**. This conclusion, combined with the finding of multiple instruction streams, points toward a MIMD classification.\n\n**3. Synthesizing the Classification and the Role of Synchronization:**\n\n- **Multiple Instruction Streams** and **Multiple Data Streams** is the definition of **MIMD** (Multiple Instruction, Multiple Data).\n- The system described is a specific, common subclass of MIMD known as SPMD (Single Program, Multiple Data), where all processors execute the same program. Flynn's original taxonomy does not include SPMD as a top-level category, so MIMD is the correct general classification.\n- The role of the software barrier and its associated overhead $\\beta > 0$ must be considered. This barrier forces the replicas into a form of lockstep execution. One might argue this makes the system behave like a SIMD machine. However, this is incorrect. The lockstep in a true SIMD architecture is a fundamental structural property resulting from a single control unit broadcasting instructions. The synchronization is implicit and highly efficient. In the described system, the lockstep is *enforced by software* upon a hardware architecture that is inherently asynchronous (independent clocks, independent PCs). The existence of a non-zero synchronization overhead, $\\beta$, is evidence of this software-enforced coordination on top of a MIMD structure. It is a cost to make a MIMD system behave synchronously for the purpose of voting, not a feature that changes its fundamental architectural classification.\n\n**Conclusion:** The TMR system, with its independent control units (program counters) and replicated data streams, is structurally a MIMD architecture.\n\n### Option-by-Option Analysis\n\n**A. SIMD: a single instruction stream controls three execution lanes processing multiple data streams; per-instruction synchronization $\\beta$ does not alter the SIMD nature.**\n\n**Incorrect.** The premise \"a single instruction stream\" is false. The problem explicitly states that each of the $N=3$ replicas has its own program counter and fetches instructions independently. This defines a system with multiple instruction streams, which contradicts the definition of SIMD.\n\n**B. MIMD: three independent instruction streams (one per replica) execute the same code over three replicated data streams; the per-instruction synchronization $\\beta$ is a coordination cost but the structure remains MIMD.**\n\n**Correct.** This option accurately reflects the analysis.\n- \"three independent instruction streams\": Correct, due to the independent program counters and fetch units.\n- \"execute the same code\": Correct, this is the SPMD nature of the system.\n- \"over three replicated data streams\": Correct, as each replica has its own buffer with a copy of the data.\n- \"synchronization ... is a coordination cost but the structure remains MIMD\": Correct. The software barrier enforces a behavior but does not alter the underlying MIMD hardware architecture with its multiple control units.\n\n**C. SISD: the same program and same data imply one instruction stream and one data stream in aggregate despite physical replication.**\n\n**Incorrect.** This option confuses the logical function (one program, one conceptual data source) with the physical hardware structure. Flynn's taxonomy classifies the hardware implementation. A system with $3$ processors, $3$ program counters, and $3$ data buffers is not a single-stream system. SISD describes a single, non-replicated uniprocessor.\n\n**D. MISD: three distinct instruction streams operate on a single shared data stream to achieve fault masking; timing skew yields effectively different instruction sequences across replicas.**\n\n**Incorrect.** While the system does have \"three distinct instruction streams,\" the claim of a \"single shared data stream\" is less accurate than the \"multiple replicated data streams\" in option B. The problem describes separate buffers for each replica. Furthermore, the canonical MISD model (e.g., a systolic array) involves different processors performing *different* operations on a single stream of data as it passes through them. Here, the processors perform the *same* operation on identical copies of data, which is more characteristic of an SPMD-style MIMD computation.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "The Single Instruction, Multiple Data (SIMD) paradigm is central to the immense power of modern GPUs, but handling conditional logic (`if-else` statements) presents a unique challenge known as branch divergence. This exercise delves into the Single Instruction, Multiple Threads (SIMT) model, the elegant solution used by GPUs to manage this issue via lane masking. By calculating the \"warp execution efficiency,\" you will gain a concrete, quantitative understanding of the performance impact of divergence, a critical consideration for any developer aiming to write high-performance GPU code .",
            "id": "3643609",
            "problem": "A graphics processing unit (GPU, Graphics Processing Unit) executes Single Instruction Multiple Threads (SIMT, Single Instruction Multiple Threads) code by issuing one common instruction to a fixed-size group of lanes called a warp and dynamically masking lanes that are not active for the current instruction. According to Flynn's taxonomy, Single Instruction Multiple Data (SIMD, Single Instruction Multiple Data), Single Instruction Single Data (SISD, Single Instruction Single Data), Multiple Instruction Single Data (MISD, Multiple Instruction Single Data), and Multiple Instruction Multiple Data (MIMD, Multiple Instruction Multiple Data) are the four architectural categories that classify parallel execution. In the SIMT model, a warp issues one instruction at a time; under control-flow divergence, the warp serializes the paths, issuing the instructions of each path with a lane mask that enables only the lanes assigned to that path. Consider the following scientifically realistic scenario for a single warp.\n\nThe warp size is $w = 64$. A SIMT conditional splits the warp into three disjoint path groups of sizes $a = 10$, $b = 22$, and $c = 32$, respectively, with $a + b + c = w$. Before the conditional, there are $u = 12$ instructions that are uniform across all lanes. Path $1$ executes $l_{1} = 40$ instructions, path $2$ executes $l_{2} = 18$ instructions, and path $3$ executes $l_{3} = 10$ instructions. After reconvergence, there are $v = 28$ instructions that are again uniform across all lanes. Assume each issued instruction consumes one issue slot and has equal latency, the warp executes the three paths serially with appropriate masks, and there are no stalls or hidden parallelism across paths.\n\nUsing the definitions of Flynn's taxonomy and the described SIMT masking behavior, decide whether the masked execution in the divergent region is still an instance of Single Instruction Multiple Data (SIMD) at the hardware instruction-issue level, and justify your decision qualitatively. Then, define the warp execution efficiency over this whole region as the fraction of useful lane-operations divided by the total available lane slots issued in the region, where a useful lane-operation is counted for each active lane at each instruction issue. Compute this efficiency for the given values. Express the final efficiency as a reduced fraction with no units. No rounding is required.",
            "solution": "The fundamental base for reasoning is Flynn's taxonomy, which classifies machines by the multiplicity of instructions and data they process simultaneously, and the SIMT execution rule that a GPU warp issues one common instruction at a time to all its lanes, with dynamic masking enabling only the lanes that should execute that instruction.\n\nBy definition, Single Instruction Multiple Data (SIMD) is characterized by issuing a single instruction that is applied to multiple data elements in parallel lanes. In a warp under SIMT, even with divergence, the hardware issues one instruction per cycle, and a lane mask determines which lanes are active for that instruction. Although paths are serialized across time, at any given instruction issue the hardware still applies one instruction to multiple data elements in the set of currently active lanes. Therefore, at the hardware instruction-issue level, masked execution remains an instance of Single Instruction Multiple Data (SIMD). It is not Single Instruction Single Data (SISD), because more than one lane can be active; it is not Multiple Instruction Single Data (MISD), because only one instruction is issued at a time; and it is not Multiple Instruction Multiple Data (MIMD), because multiple distinct instructions are not issued simultaneously to different lanes.\n\nWe now compute the efficiency. Let the efficiency $E$ be defined as\n$$\nE = \\frac{\\text{total useful lane-operations over the region}}{\\text{total available lane slots issued over the region}}.\n$$\nEach issued instruction provides $w$ lane slots. A useful lane-operation occurs for each active lane at each issued instruction. We sum over the uniform and divergent segments:\n\n- Before divergence, there are $u$ uniform instructions with all $w$ lanes active, contributing $u \\cdot w$ useful lane-operations.\n- During divergent execution, the warp serializes the $3$ paths. Path $1$ issues $l_{1}$ instructions with $a$ active lanes, contributing $a \\cdot l_{1}$ useful lane-operations. Path $2$ contributes $b \\cdot l_{2}$, and path $3$ contributes $c \\cdot l_{3}$.\n- After reconvergence, there are $v$ uniform instructions with all $w$ lanes active, contributing $v \\cdot w$ useful lane-operations.\n\nThe total number of issued instructions in the region is $u + l_{1} + l_{2} + l_{3} + v$, and each instruction provides $w$ lane slots, so the denominator is $\\left(u + l_{1} + l_{2} + l_{3} + v\\right) \\cdot w$.\n\nThus,\n$$\nE = \\frac{u \\cdot w + a \\cdot l_{1} + b \\cdot l_{2} + c \\cdot l_{3} + v \\cdot w}{\\left(u + l_{1} + l_{2} + l_{3} + v\\right) \\cdot w}.\n$$\n\nSubstitute the given values $w = 64$, $a = 10$, $b = 22$, $c = 32$, $u = 12$, $l_{1} = 40$, $l_{2} = 18$, $l_{3} = 10$, $v = 28$:\n$$\n\\text{numerator} = 12 \\cdot 64 + 10 \\cdot 40 + 22 \\cdot 18 + 32 \\cdot 10 + 28 \\cdot 64.\n$$\nCompute each term numerically:\n$$\n12 \\cdot 64 = 768,\\quad 10 \\cdot 40 = 400,\\quad 22 \\cdot 18 = 396,\\quad 32 \\cdot 10 = 320,\\quad 28 \\cdot 64 = 1792.\n$$\nSum:\n$$\n768 + 400 + 396 + 320 + 1792 = 3676.\n$$\nThe denominator is\n$$\n\\left(12 + 40 + 18 + 10 + 28\\right) \\cdot 64 = 108 \\cdot 64 = 6912.\n$$\nTherefore,\n$$\nE = \\frac{3676}{6912}.\n$$\nWe reduce the fraction by dividing the numerator and denominator by their greatest common divisor, which is $4$:\n$$\nE = \\frac{3676 / 4}{6912 / 4} = \\frac{919}{1728}.\n$$\nThis is the reduced fraction. No units are required because efficiency is dimensionless.",
            "answer": "$$\\boxed{\\frac{919}{1728}}$$"
        },
        {
            "introduction": "Building on our understanding of branch divergence, we now explore how to proactively optimize code for SIMD architectures. This final practice introduces \"branchless programming,\" a powerful software technique that transforms complex conditional logic into a straight-line sequence of data-flow operations perfectly suited for SIMD execution. You will perform a quantitative trade-off analysis, comparing the performance of this software transformation against the hardware's default masked execution, revealing how clever algorithm design can unlock greater hardware performance .",
            "id": "3643519",
            "problem": "A data-parallel kernel originally designed for Multiple Instruction Multiple Data (MIMD) execution contains a conditional with two paths per element. To exploit Single Instruction Multiple Data (SIMD) hardware, a branchless transformation is considered: compute both paths and then blend results via a data-select. Using the definitions in Flynn’s taxonomy—Single Instruction Single Data (SISD), Single Instruction Multiple Data (SIMD), Multiple Instruction Single Data (MISD), and Multiple Instruction Multiple Data (MIMD)—you must reason from first principles about whether this branchless transformation recasts divergent MIMD behavior into code amenable to SIMD execution, and then quantify the performance trade-off.\n\nAssume the following machine and workload model:\n- The SIMD vector width is $w=8$ lanes.\n- For each element, the conditional is true with probability $p=0.7$, independently across lanes.\n- The true path performs $C_{T}=12$ scalar-equivalent operations per element; the false path performs $C_{F}=6$ scalar-equivalent operations per element.\n- On SIMD with masked execution and divergent lanes, both paths are executed (under masks) and a fixed reconvergence overhead of $r=4$ vector-cycles is incurred per vector when at least one lane takes each path. When all $w$ lanes agree (all true or all false), only the taken path is executed and no reconvergence overhead is incurred.\n- Under the branchless (if-conversion) transformation, both paths are always computed for every element and blended at cost $C_{\\text{sel}}=1$ scalar-equivalent operation per element. This eliminates any reconvergence overhead.\n\nTreat one scalar-equivalent operation as one vector-cycle when executed as a SIMD vector instruction, so that a path cost measured in scalar-equivalent operations per element maps to the same number of vector-cycles per vector instruction stream. Let the expected masked-branch SIMD cost per vector be the probability-weighted sum over the three mutually exclusive cases (all true, all false, mixed), and let the branchless SIMD cost per vector be the unconditional sum of both paths plus the select.\n\nDefine the extra work introduced by branchless programming per element as $\\Delta OP$, the difference between the branchless per-element operation count and the expected per-element operation count when only the actually taken path executes. Define the net benefit as the dimensionless speedup $E$, the ratio of the expected masked-branch SIMD cost per vector to the branchless SIMD cost per vector.\n\nCompute $E$ using the parameters above. Round your answer to $4$ significant figures. Express the final answer as a dimensionless number with no units.",
            "solution": "The core of the problem lies in the distinction between Multiple Instruction, Multiple Data (MIMD) and Single Instruction, Multiple Data (SIMD) execution models, as defined by Flynn's taxonomy. An MIMD system can execute different instructions on different data streams simultaneously. A conditional branch, where different data elements follow different execution paths (`true` vs. `false`), is inherently an MIMD-style operation at the element level. In contrast, a SIMD system must execute the same instruction across all data elements (lanes) in a vector at any given time. This creates a challenge for handling conditional logic, known as branch divergence.\n\nThe problem presents two strategies for a SIMD architecture to handle this divergence:\n\n1.  **Masked-Branch Execution**: The hardware effectively serializes the two divergent paths. The instruction stream for the `true` path is executed, followed by the instruction stream for the `false` path. Predicate masks are used to ensure that only the appropriate lanes commit their results for each path. This maintains a single instruction stream but introduces a performance penalty: when lanes diverge, the total execution cost is the sum of both paths' costs, potentially plus a reconvergence overhead. This approach keeps the control flow logic but pays a performance price for divergence.\n\n2.  **Branchless Transformation (If-Conversion)**: This software approach fundamentally alters the code structure. It eliminates the conditional branch entirely. Instead, the computations for both the `true` and `false` paths are performed for all data elements unconditionally. The results are stored in temporary registers. Finally, a conditional-select instruction (akin to a ternary operator `C = cond ? A : B`) is used to choose the correct result for each element based on the original condition. This transforms control-flow dependency into data-flow dependency. The resulting code is a single, non-branching sequence of instructions, which is perfectly suited for SIMD execution. This transformation recasts the MIMD-like behavior into a strictly SIMD-amenable form.\n\nNow, we quantify the performance trade-off by calculating the net benefit, $E$, defined as the ratio of the expected masked-branch SIMD cost to the branchless SIMD cost.\n\nFirst, we calculate the cost of the branchless SIMD execution per vector, denoted as $C_{\\text{branchless}}$. In this model, both paths are always executed, and a final selection is performed. The cost is the sum of the operations for the true path, the false path, and the selection.\n$$C_{\\text{branchless}} = C_{T} + C_{F} + C_{\\text{sel}}$$\nUsing the given values $C_{T}=12$, $C_{F}=6$, and $C_{\\text{sel}}=1$:\n$$C_{\\text{branchless}} = 12 + 6 + 1 = 19$$\nThis cost is constant, measured in vector-cycles per vector.\n\nSecond, we calculate the expected cost of the masked-branch SIMD execution per vector, $C_{\\text{masked}}$. This cost depends on whether the $w=8$ lanes in a vector diverge. The outcome for each lane is an independent Bernoulli trial with probability $p=0.7$ of being true.\n\nThere are three mutually exclusive cases:\n1.  **All lanes True**: All $w$ lanes follow the true path. This occurs with probability $P_{\\text{all\\_true}} = p^w$. The cost is only that of the true path, $Cost_{\\text{all\\_true}} = C_T$.\n2.  **All lanes False**: All $w$ lanes follow the false path. This occurs with probability $P_{\\text{all\\_false}} = (1-p)^w$. The cost is only that of the false path, $Cost_{\\text{all\\_false}} = C_F$.\n3.  **Mixed (Divergent)**: At least one lane is true and at least one is false. This occurs with probability $P_{\\text{mixed}} = 1 - p^w - (1-p)^w$. In this case, both paths are executed under masks, and the reconvergence overhead $r$ is incurred. The cost is $Cost_{\\text{mixed}} = C_T + C_F + r$.\n\nThe expected cost $C_{\\text{masked}}$ is the probability-weighted sum of the costs of these three cases:\n$$C_{\\text{masked}} = P_{\\text{all\\_true}} \\cdot Cost_{\\text{all\\_true}} + P_{\\text{all\\_false}} \\cdot Cost_{\\text{all\\_false}} + P_{\\text{mixed}} \\cdot Cost_{\\text{mixed}}$$\n$$C_{\\text{masked}} = (p^w)(C_T) + ((1-p)^w)(C_F) + (1 - p^w - (1-p)^w)(C_T + C_F + r)$$\n\nSubstituting the given values:\n- $w=8$\n- $p=0.7$, so $1-p=0.3$\n- $C_T=12$\n- $C_F=6$\n- $r=4$\n\nWe first calculate the probabilities:\n$$P_{\\text{all\\_true}} = (0.7)^8 \\approx 0.05764801$$\n$$P_{\\text{all\\_false}} = (0.3)^8 = 0.00006561$$\n$$P_{\\text{mixed}} = 1 - 0.05764801 - 0.00006561 = 0.94228638$$\n\nNext, we determine the cost for each case:\n$$Cost_{\\text{all\\_true}} = C_T = 12$$\n$$Cost_{\\text{all\\_false}} = C_F = 6$$\n$$Cost_{\\text{mixed}} = C_T + C_F + r = 12 + 6 + 4 = 22$$\n\nNow, we compute the expected cost:\n$$C_{\\text{masked}} \\approx (0.05764801 \\times 12) + (0.00006561 \\times 6) + (0.94228638 \\times 22)$$\n$$C_{\\text{masked}} \\approx 0.69177612 + 0.00039366 + 20.73030036$$\n$$C_{\\text{masked}} \\approx 21.42247014$$\n\nThe extra work per element, $\\Delta OP$, is the difference between the branchless operation count and the expected operation count for an ideal taken path:\n$\\Delta OP = (C_T + C_F + C_{\\text{sel}}) - (p C_T + (1-p) C_F) = 19 - ((0.7)(12) + (0.3)(6)) = 19 - (8.4 + 1.8) = 19 - 10.2 = 8.8$ operations per element.\n\nFinally, we compute the net benefit (speedup) $E$, which is the ratio of the expected masked-branch cost to the branchless cost.\n$$E = \\frac{C_{\\text{masked}}}{C_{\\text{branchless}}}$$\n$$E \\approx \\frac{21.42247014}{19} \\approx 1.127498428$$\n\nRounding to $4$ significant figures, we get $E \\approx 1.127$. Since $E > 1$, the branchless transformation provides a net performance benefit for this specific set of parameters. The benefit comes from eliminating the high cost of divergence (executing both paths plus reconvergence overhead), which occurs with high probability ($P_{\\text{mixed}} \\approx 94\\%$).",
            "answer": "$$\\boxed{1.127}$$"
        }
    ]
}