{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp how a scoreboard orchestrates out-of-order execution, there is no substitute for a detailed simulation. This first practice invites you to step into the role of the processor's control logic, meticulously tracking a sequence of instructions as they navigate the pipeline . By charting the state of each instruction from issue to write-back, you will gain a concrete understanding of how Write-After-Write (WAW) and Write-After-Read (WAR) hazards are detected and resolved.",
            "id": "3638650",
            "problem": "Consider a toy Instruction Set Architecture (ISA) with three-address integer instructions and a classic scoreboard-based dynamic scheduler. The machine supports out-of-order execution subject to the scoreboard’s hazards and stage rules. The ISA and microarchitectural rules are as follows.\n\n- Instruction Set Architecture (ISA): Instructions have the form $\\mathrm{OP}\\;R_{d}, R_{s1}, R_{s2}$, with semantics $R_{d} \\leftarrow R_{s1}\\;\\mathrm{OP}\\;R_{s2}$. Supported operations and latencies:\n  - $\\mathrm{ADD}$ on an Integer Arithmetic Logic Unit (ALU): latency $L_{A} = 2$ cycles.\n  - $\\mathrm{MUL}$ on a Multiplier: latency $L_{M} = 5$ cycles.\n  - $\\mathrm{LD}$ on a Load Unit: format $\\mathrm{LD}\\;R_{d}, [R_{s1}]$ with latency $L_{L} = 3$ cycles. Assume addresses are formed by using the value in $R_{s1}$; there are no memory bank conflicts.\n\n- Microarchitecture and Scoreboard:\n  - Functional Units (FU): $2$ ALUs, $1$ Multiplier, $1$ Load Unit. Each FU can host at most one instruction at a time; an FU is reserved at the Issue stage and is released after the Write Result stage.\n  - Pipeline stages per instruction: Issue $\\rightarrow$ Read Operands $\\rightarrow$ Execute $\\rightarrow$ Write Result. Issue and Read Operands each take $1$ cycle; Execute takes $L$ cycles depending on operation; Write Result takes $1$ cycle.\n  - Stage ordering within a cycle: First perform all eligible Write Result actions, then all eligible Read Operands actions, then perform a single Issue of at most one instruction. Operand readiness for Read Operands is evaluated at the beginning of the cycle, prior to any writes in that cycle; a value written in cycle $t$ becomes available to be read no earlier than cycle $t+1$.\n  - Hazards enforced by the scoreboard:\n    - Write-After-Write (WAW): At Issue, stall if any active (issued but not yet completed) instruction has destination register equal to the incoming instruction’s destination.\n    - Read-After-Write (RAW): At Read Operands, stall until every source register is ready (i.e., its last earlier writer has completed Write Result).\n    - Write-After-Read (WAR): At Write Result, stall if any earlier active instruction has not yet performed Read Operands and uses the writer’s destination register as one of its sources.\n  - Result bus: There is a single global write port; at most one Write Result can occur per cycle. If more than one instruction is ready to write in the same cycle, all but one are structurally stalled. For the question below, these structural stalls on the write port must not be counted toward WAW or WAR stalls.\n\n- Initial conditions: At cycle $1$, all architectural registers $R_{0}, R_{1}, \\dots$ have valid initial values (i.e., they are considered ready) except for registers that will be defined by the program itself. There are no cache misses or additional memory delays beyond $L_{L}$, and there are no branch instructions.\n\nProgram to execute (in program order, with instruction identifiers $I_{1}$ through $I_{5}$):\n1. $I_{1}: \\mathrm{LD}\\;R_{9}, [R_{10}]$\n2. $I_{2}: \\mathrm{ADD}\\;R_{7}, R_{5}, R_{9}$\n3. $I_{3}: \\mathrm{ADD}\\;R_{5}, R_{1}, R_{2}$\n4. $I_{4}: \\mathrm{MUL}\\;R_{5}, R_{3}, R_{4}$\n5. $I_{5}: \\mathrm{ADD}\\;R_{8}, R_{5}, R_{6}$\n\nNotes:\n- The two instructions $I_{3}$ and $I_{4}$ both write to $R_{5}$, creating destination aliasing.\n- The instruction $I_{2}$ reads $R_{5}$ but must wait for $R_{9}$ from $I_{1}$, which interacts with WAR constraints when a later instruction attempts to write $R_{5}$.\n- Schedule the execution as aggressively as allowed by the rules to minimize total time: each stage should occur at the earliest cycle permitted by scoreboard constraints and FU availability.\n\nTask:\nCompute the total number of stall cycles that are attributed exclusively to Write-After-Write (WAW) and Write-After-Read (WAR) hazards during the complete execution of $I_{1}$ through $I_{5}$ under the above model. Do not count stall cycles caused by Read-After-Write (RAW) hazards or by structural constraints such as the single write port or FU availability. Express your final answer as a single integer. No rounding is required.",
            "solution": "To determine the total number of stall cycles caused exclusively by Write-After-Write (WAW) and Write-After-Read (WAR) hazards, we perform a cycle-by-cycle simulation of the provided code sequence on the described scoreboard-based processor.\n\n### Step 1: Identify Dependencies\n\nFirst, we identify the dependencies between the instructions in the sequence:\n-   $I_1: \\mathrm{LD}\\;R_9, [R_{10}]$\n-   $I_2: \\mathrm{ADD}\\;R_7, R_5, R_9$\n-   $I_3: \\mathrm{ADD}\\;R_5, R_1, R_2$\n-   $I_4: \\mathrm{MUL}\\;R_5, R_3, R_4$\n-   $I_5: \\mathrm{ADD}\\;R_8, R_5, R_6$\n\nThe key dependencies are:\n*   **RAW:** $I_2$ depends on $I_1$ for register $R_9$. $I_5$ depends on $I_4$ for register $R_5$.\n*   **WAW:** $I_4$ depends on $I_3$ because both write to register $R_5$.\n*   **WAR:** $I_3$ depends on $I_2$ because $I_3$ writes to $R_5$ which $I_2$ reads.\n\n### Step 2: Cycle-by-Cycle Execution Analysis\n\nWe will track the progress of each instruction through the pipeline stages: Issue (I), Read Operands (RO), Execute (E), and Write Result (WR). A stall is denoted by '(S)'.\n\n*   **Cycle 1:** $I_1$ issues (Load FU occupied).\n*   **Cycle 2:** $I_1$ reads operands. $I_2$ issues (ALU1 occupied).\n*   **Cycle 3:** $I_1$ begins execution (cycle 1/3). $I_2$ stalls at RO (RAW hazard on $R_9$). $I_3$ issues (ALU2 occupied).\n*   **Cycle 4:** $I_1$ executes (cycle 2/3). $I_2$ remains stalled (RAW on $R_9$). $I_3$ reads operands. $I_4$ attempts to issue but is blocked by a **WAW hazard**: $I_3$ is an active instruction also writing to $R_5$. (WAW stall cycles for $I_4$: 1).\n*   **Cycle 5:** $I_1$ executes (cycle 3/3), completing at the end of this cycle. $I_2$ remains stalled (RAW on $R_9$). $I_3$ begins execution (cycle 1/2). $I_4$ remains stalled on Issue due to the **WAW hazard**. (WAW stall cycles for $I_4$: 2).\n*   **Cycle 6:** $I_1$ performs Write Result. $R_9$ will be available in cycle 7. $I_2$ remains stalled (RAW on $R_9$). $I_3$ executes (cycle 2/2), completing at the end of this cycle. $I_4$ remains stalled on Issue due to the **WAW hazard**. (WAW stall cycles for $I_4$: 3).\n*   **Cycle 7:**\n    *   $I_3$ is ready for Write Result. However, it encounters a **WAR hazard**: an earlier instruction, $I_2$, has not yet read its operands and uses $R_5$ (the destination of $I_3$) as a source. $I_3$ must stall. (WAR stall cycles for $I_3$: 1).\n    *   $I_2$ now reads its operands, as $R_9$ is available.\n    *   $I_4$ remains stalled on Issue due to the **WAW hazard** from $I_3$, which is still active as it has not completed WR. (WAW stall cycles for $I_4$: 4).\n*   **Cycle 8:**\n    *   The WAR condition for $I_3$ is now clear because $I_2$ read its operands in the previous cycle. $I_3$ performs Write Result. The register reservation on $R_5$ by $I_3$ is released.\n    *   $I_2$ begins execution (cycle 1/2).\n    *   Following the WR of $I_3$ in this same cycle, the WAW hazard on $I_4$ is cleared. $I_4$ issues (Multiplier FU occupied).\n*   **Cycle 9:** $I_2$ executes (cycle 2/2), completing at the end of this cycle. $I_4$ reads operands. $I_5$ issues (ALU2 occupied).\n*   **Cycle 10:** $I_2$ performs Write Result. $I_4$ begins execution (cycle 1/5). $I_5$ stalls at RO (RAW hazard on $R_5$, which is being computed by $I_4$).\n*   **Cycles 11-14:** $I_4$ continues execution (cycles 2-5). $I_5$ remains stalled (RAW). At the end of cycle 14, $I_4$ completes execution.\n*   **Cycle 15:** $I_4$ performs Write Result. No WAR stall occurs because $I_5$, which reads $R_5$, is a later, not an earlier, instruction. $R_5$ will be available in cycle 16. $I_5$ reads its operands.\n*   **Cycles 16-17:** $I_5$ executes.\n*   **Cycle 18:** $I_5$ performs Write Result. All instructions are complete.\n\n### Step 3: Tally the Stalls\n\nWe now sum the stall cycles that were explicitly identified as being caused by WAW or WAR hazards, per the problem's instructions.\n\n*   **WAW Stalls:**\n    *   Instruction $I_4$ stalled at the Issue stage during cycles 4, 5, 6, and 7 due to the active write to $R_5$ by $I_3$.\n    *   Total WAW stall cycles = 4.\n\n*   **WAR Stalls:**\n    *   Instruction $I_3$ stalled at the Write Result stage during cycle 7 because an earlier instruction, $I_2$, had not yet read its source operand $R_5$.\n    *   Total WAR stall cycles = 1.\n\n*   **Total Stall Cycles (WAW + WAR):**\n    *   The total number of stall cycles attributed exclusively to WAW and WAR hazards is the sum of the individual counts.\n    *   Total = (WAW stalls) + (WAR stalls) = $4 + 1 = 5$.\n\nThe stall cycles experienced by $I_2$ and $I_5$ were due to RAW hazards and are not counted.",
            "answer": "$$\n\\boxed{5}\n$$"
        },
        {
            "introduction": "With the mechanics of tracing in hand, we can now move to a higher level of analysis. This exercise presents a seemingly simple sequence of instructions that harbors a tight chain of data dependencies . Your task is to determine if any parallelism can be extracted and to calculate the total execution time, revealing how a combination of true dependencies (RAW) and anti-dependencies (WAR) can conspire to serialize execution and nullify the benefits of multiple functional units.",
            "id": "3638642",
            "problem": "Consider a classic scoreboard-based dynamically scheduled processor in the style of the CDC 6600. The scoreboard implements the following four-stage lifetime for each instruction: Issue, Read Operands, Execute, Write Result. The rules are:\n\n- Issue: The instruction may issue in program order only if a suitable functional unit is free and there is no write-after-write (WAW) hazard on its destination register.\n- Read Operands: The instruction may read its source registers when both are marked ready (no pending producer) and all RAW constraints are satisfied.\n- Execute: The instruction occupies its functional unit for a fixed latency specific to the operation.\n- Write Result: The instruction may write its destination when there is no write-after-read (WAR) hazard with any earlier instruction that has not yet read its operands.\n\nAssume the machine has two identical integer adders. Each add instruction uses one adder and has an execute latency of $3$ cycles. Each Issue stage takes $1$ cycle, each Read Operands stage takes $1$ cycle, and each Write Result stage takes $1$ cycle. Only one instruction can be issued per cycle. A functional unit is allocated at Issue and remains occupied until Write Result completes. At the end of a Write Result stage in cycle $t$, the functional unit becomes available to Issue in cycle $t+1$. All initial register values are available at cycle $0$.\n\nConsider the following three integer add instructions, in program order, with explicit dataflow:\n\n- Instruction $\\mathrm{I1}$: $R1 \\leftarrow R2 + R3$\n- Instruction $\\mathrm{I2}$: $R2 \\leftarrow R1 + R4$\n- Instruction $\\mathrm{I3}$: $R3 \\leftarrow R2 + R5$\n\nwhere $R2$, $R3$, $R4$, and $R5$ are ready at cycle $0$ with valid initial values.\n\nStarting only from the scoreboard rules above and the semantics of read-after-write (RAW), write-after-read (WAR), and write-after-write (WAW) hazards, reason whether any parallelism in the Execute stages is possible for this sequence, and determine the minimal completion time (the cycle in which the final Write Result completes) for all three instructions under the given latencies and resource constraints. Express the final time in cycles. No rounding is required.",
            "solution": "The problem asks to determine if parallelism is possible in the Execute stages for a sequence of three instructions on a scoreboard-based processor and to find the minimal completion time. The analysis requires a step-by-step simulation of the processor's state, governed by the scoreboard rules and constrained by data dependencies and resource availability.\n\nFirst, we identify the data dependencies between the instructions:\n- $I_1: R1 \\leftarrow R2 + R3$\n- $I_2: R2 \\leftarrow R1 + R4$\n- $I_3: R3 \\leftarrow R2 + R5$\n\n1.  **Read-After-Write (RAW) or True Data Dependencies**:\n    - $I_1 \\xrightarrow{\\text{RAW}, R1} I_2$: $I_2$ reads $R1$, which is written by $I_1$. $I_2$ cannot read its operands until $I_1$ has completed its Write Result stage.\n    - $I_2 \\xrightarrow{\\text{RAW}, R2} I_3$: $I_3$ reads $R2$, which is written by $I_2$. $I_3$ cannot read its operands until $I_2$ has completed its Write Result stage.\n    These dependencies form a chain: $I_1 \\rightarrow I_2 \\rightarrow I_3$.\n\n2.  **Write-After-Read (WAR) or Anti-Dependencies**:\n    - $I_1 \\xrightarrow{\\text{WAR}, R2} I_2$: $I_2$ writes to $R2$, which is read by $I_1$. $I_2$ cannot write its result until $I_1$ has read its operands.\n    - $I_1 \\xrightarrow{\\text{WAR}, R3} I_3$: $I_3$ writes to $R3$, which is read by $I_1$. $I_3$ cannot write its result until $I_1$ has read its operands.\n\n3.  **Write-After-Write (WAW) or Output Dependencies**:\n    - The instructions $I_1, I_2, I_3$ write to distinct registers ($R1, R2, R3$), so there are no WAW hazards.\n\nWe can construct a timing chart to track the progress of each instruction through the four pipeline stages: Issue ($I$), Read Operands ($RO$), Execute ($EX$), and Write Result ($WR$).\n\n| Instruction | Stage $I$ | Stage $RO$ | Stage $EX$ | Stage $WR$ | FU | Comments |\n| :--- | :---: | :---: | :---: | :---: | :---: | :--- |\n| $I_1: R1 \\leftarrow R2+R3$ | 1 | 2 | 3-5 | 6 | $FU_1$ | Issues in cycle 1. Sources ready, so RO is in cycle 2. |\n| $I_2: R2 \\leftarrow R1+R4$ | 2 | 7 | 8-10 | 11 | $FU_2$ | Issues in cycle 2. Stalls for RAW on $R1$. $I_1$ WR at cycle 6, so $I_2$ RO starts in cycle 7. |\n| $I_3: R3 \\leftarrow R2+R5$ | 7 | 12 | 13-15 | 16 | $FU_1$ | Stalls for FU. $FU_1$ is free in cycle 7. Stalls for RAW on $R2$. $I_2$ WR at cycle 11, so $I_3$ RO starts in cycle 12. |\n\n**Cycle-by-Cycle Analysis:**\n\n- **Cycle 1**: $I_1$ issues, allocating $FU_1$.\n- **Cycle 2**: $I_1$ completes Read Operands ($RO$). $I_2$ issues, allocating $FU_2$.\n- **Cycles 3-5**: $I_1$ is in its 3-cycle execution. $I_2$ stalls in $RO$ due to the RAW dependency on $R1$. $I_3$ waits to issue (1 issue/cycle).\n- **Cycle 6**: $I_1$ completes Write Result ($WR$). $R1$ is available at cycle end. $FU_1$ remains occupied.\n- **Cycle 7**: $FU_1$ is now free. $I_3$ issues, allocating $FU_1$. In parallel, $I_2$ detects $R1$ is ready and completes its $RO$ stage.\n- **Cycles 8-10**: $I_2$ is in its 3-cycle execution. $I_3$ stalls in $RO$ due to the RAW dependency on $R2$.\n- **Cycle 11**: $I_2$ completes $WR$. The WAR check ($I_1 \\xrightarrow{\\text{WAR}} I_2$) passes because $I_1$ completed $RO$ in cycle 2. $R2$ is available at cycle end. $FU_2$ remains occupied.\n- **Cycle 12**: $FU_2$ is now free. $I_3$ detects $R2$ is ready and completes its $RO$ stage.\n- **Cycles 13-15**: $I_3$ is in its 3-cycle execution.\n- **Cycle 16**: $I_3$ completes $WR$. The WAR check ($I_1 \\xrightarrow{\\text{WAR}} I_3$) passes as $I_1$ completed $RO$ in cycle 2. $I_3$ finishes, and all instructions are complete.\n\n**Conclusion on Parallelism and Completion Time:**\n\nThe Execute stages for the three instructions occur during the following cycle intervals:\n- $I_{1, \\text{EX}}$: cycles 3-5\n- $I_{2, \\text{EX}}$: cycles 8-10\n- $I_{3, \\text{EX}}$: cycles 13-15\n\nThese intervals are disjoint. Therefore, **no parallelism is achieved in the Execute stages**. The strong chain of RAW dependencies ($I_1 \\xrightarrow{\\text{RAW}} I_2 \\xrightarrow{\\text{RAW}} I_3$) serializes the execution, forcing the instructions to proceed one after another despite the availability of two functional units.\n\nThe final instruction, $I_3$, completes its Write Result stage at the end of cycle 16. Thus, the minimal completion time for all three instructions is 16 cycles.",
            "answer": "$$ \\boxed{16} $$"
        },
        {
            "introduction": "Our final practice expands the scope from a single sequence to the steady-state performance of a loop, a critical scenario in real-world programs. You will first analyze how a classic scoreboard is hobbled by a cycle of dependencies that reoccurs in every iteration, forcing serial execution . Then, by re-evaluating the loop under the assumption of ideal register renaming, you will quantify the powerful performance gains achieved by eliminating these 'false' dependencies and unlocking hidden instruction-level parallelism.",
            "id": "3638623",
            "problem": "A central processing unit (CPU) implements a classic scoreboard with in-order issue, out-of-order read and write, and the following properties. An instruction goes through four conceptual stages: Issue, Read Operands, Execute, and Write Result. The scoreboard enforces hazards as follows: at Issue, it prevents write-after-write (WAW) hazards by disallowing multiple active writers to the same architectural register; at Read Operands, it prevents read-after-write (RAW) hazards by delaying operand reads until the most recent earlier producer of each source register has written its result; at Write Result, it prevents write-after-read (WAR) hazards by delaying a write until all earlier instructions that read that register have performed their reads. Functional unit availability is tracked; each instruction must acquire a functional unit at Issue. Assume fully pipelined functional units with fixed execution latencies and no structural conflicts on the register file or writeback ports beyond what the scoreboard already models.\n\nConsider the infinite-loop microbenchmark consisting of the iteration body of three instructions:\n- $I_1$: $R_1 \\leftarrow R_2 + R_3$ (uses the adder),\n- $I_2$: $R_2 \\leftarrow R_1 + R_4$ (uses the adder),\n- $I_3$: $R_3 \\leftarrow R_2 \\times R_5$ (uses the multiplier),\n\nwhere $R_4$ and $R_5$ are loop-invariant. The adder has an execution latency of $L_A$ cycles and the multiplier has an execution latency of $L_M$ cycles. An instruction’s result becomes available to dependent consumers in the cycle immediately following the completion of its execution latency. Assume that the loop is scheduled so that in each iteration the three instructions appear in the program order $I_1$, $I_2$, $I_3$, and that there are no other instructions in the loop.\n\nTasks:\n- Starting from the fundamental definitions of data dependences and hazards (RAW, WAR, WAW), construct the dependence relations within a single iteration and the loop-carried dependences across successive iterations. Explain why, under a scoreboard without register renaming (register renaming (RR) being the dynamic mapping of architectural registers to distinct physical registers to eliminate false dependences), these relations create a directed cycle that forces serial initiation of iterations, even though functional units are fully pipelined.\n- Then, assuming ideal register renaming that eliminates all anti-dependences (WAR) and output dependences (WAW) while preserving true data dependences (RAW), derive from first principles the minimum steady-state initiation interval, measured in cycles per iteration, that the loop can achieve as a function of $L_A$ and $L_M$.\n- Finally, evaluate your expression for $L_A = 2$ and $L_M = 4$ and report the steady-state initiation interval as a single number. Express your final answer as the number of cycles per iteration (no units). No rounding is required.",
            "solution": "The analysis is divided into three parts: first, an examination of the loop execution without register renaming; second, the derivation of the minimum initiation interval with ideal register renaming; and third, a numerical evaluation of the result.\n\n### Part 1: Analysis without Register Renaming\n\nA data dependence exists between two instructions when they access the same register and at least one access is a write. There are three types: Read-After-Write (RAW), Write-After-Read (WAR), and Write-After-Write (WAW). RAW dependences are true data flows, while WAR and WAW are \"false\" or \"name\" dependences caused by reusing register names.\n\nLet $I_j^k$ denote instruction $I_j$ in iteration $k$. The instructions are:\n- $I_1^k: R_1 \\leftarrow R_2 + R_3$\n- $I_2^k: R_2 \\leftarrow R_1 + R_4$\n- $I_3^k: R_3 \\leftarrow R_2 \\times R_5$\n\n**Dependences within a single iteration ($k$):**\n-   $I_1^k \\xrightarrow{\\text{RAW}, R_1} I_2^k$: $I_2^k$ reads $R_1$ after $I_1^k$ writes it.\n-   $I_2^k \\xrightarrow{\\text{RAW}, R_2} I_3^k$: $I_3^k$ reads $R_2$ after $I_2^k$ writes it.\n-   $I_1^k \\xrightarrow{\\text{WAR}, R_2} I_2^k$: $I_2^k$ writes $R_2$ after $I_1^k$ reads it.\n-   $I_1^k \\xrightarrow{\\text{WAR}, R_3} I_3^k$: $I_3^k$ writes $R_3$ after $I_1^k$ reads it.\n\n**Loop-carried dependences (from iteration $k$ to $k+1$):**\nThe values of registers $R_2$ and $R_3$ read by $I_1^{k+1}$ are those produced in iteration $k$.\n-   $I_2^k \\xrightarrow{\\text{RAW}, R_2} I_1^{k+1}$: $I_1^{k+1}$ reads the value of $R_2$ produced by $I_2^k$.\n-   $I_3^k \\xrightarrow{\\text{RAW}, R_3} I_1^{k+1}$: $I_1^{k+1}$ reads the value of $R_3$ produced by $I_3^k$.\n\nFalse dependences also exist across iterations due to the reuse of register names $R_1, R_2, R_3$.\n-   $I_j^k \\xrightarrow{\\text{WAW}, R_j} I_j^{k+1}$ for $j \\in \\{1, 2, 3\\}$. For example, both $I_2^k$ and $I_2^{k+1}$ write to $R_2$.\n\nA classic scoreboard serializes iterations due to the interaction of these dependences. A directed cycle of constraints is formed. For example, on register $R_2$:\n1.  **RAW Hazard**: $I_2^k \\xrightarrow{\\text{RAW}} I_1^{k+1}$. The scoreboard stalls $I_1^{k+1}$ until $I_2^k$ completes.\n2.  **WAR Hazard**: $I_1^{k+1} \\xrightarrow{\\text{WAR}} I_2^{k+1}$. The scoreboard stalls the write of $I_2^{k+1}$ until $I_1^{k+1}$ has read the old value of $R_2$.\n3.  **WAW Hazard**: $I_2^k \\xrightarrow{\\text{WAW}} I_2^{k+1}$. The scoreboard stalls the issue of $I_2^{k+1}$ until $I_2^k$ completes its write.\n\nThe net effect of these inter-iteration RAW, WAR, and WAW hazards on the same register names is that iteration $k+1$ cannot substantially overlap with iteration $k$. The start of iteration $k+1$ is dependent on the completion of iteration $k$, forcing serial initiation of iterations.\n\n### Part 2: Analysis with Ideal Register Renaming\n\nIdeal register renaming eliminates all WAR and WAW hazards, leaving only true data (RAW) dependences. The minimum steady-state initiation interval, $II$, is the time between the start of successive loop iterations. It is constrained by recurrences in the dataflow graph ($II_{rec}$) and hardware resource limitations ($II_{res}$). The achievable $II$ is the maximum of these two lower bounds: $II = \\max(II_{rec}, II_{res})$.\n\n**Recurrence-Constrained Minimum Initiation Interval ($II_{rec}$):**\nWe analyze the RAW dependences to find loops in the dependence graph that cross iteration boundaries. Let $S_j(k)$ be the start-of-execution time for instruction $I_j$ in iteration $k$. An instruction's result is available after its latency.\nThe RAW dependences give the following inequalities:\n1.  $S_2(k) \\ge S_1(k) + L_A$\n2.  $S_3(k) \\ge S_2(k) + L_A$\n3.  $S_1(k+1) \\ge S_2(k) + L_A$\n4.  $S_1(k+1) \\ge S_3(k) + L_M$\n\nTo find the minimum $II$, we find the longest dependence path that forms a recurrence. The critical path is $I_1^k \\rightarrow I_2^k \\rightarrow I_3^k \\rightarrow I_1^{k+1}$.\nFrom (4), we have the start of $I_1$ in iteration $k+1$ depending on the completion of $I_3$ in iteration $k$.\n$$ S_1(k+1) \\ge S_3(k) + L_M $$\nSubstitute (2) into this expression:\n$$ S_1(k+1) \\ge (S_2(k) + L_A) + L_M $$\nSubstitute (1) into this expression:\n$$ S_1(k+1) \\ge ( (S_1(k) + L_A) + L_A ) + L_M $$\n$$ S_1(k+1) \\ge S_1(k) + 2L_A + L_M $$\nIn steady state, $S_1(k+1) = S_1(k) + II$. Substituting this into the inequality gives:\n$$ S_1(k) + II \\ge S_1(k) + 2L_A + L_M $$\n$$ II \\ge 2L_A + L_M $$\nThis establishes the recurrence-constrained lower bound: $II_{rec} = 2L_A + L_M$.\n\n**Resource-Constrained Minimum Initiation Interval ($II_{res}$):**\nThis bound is determined by the demand for each type of functional unit. The functional units are fully pipelined, meaning they can accept a new operation every cycle.\n-   **Adder:** Used by $I_1$ and $I_2$ (2 uses per iteration). With 1 adder unit, the minimum interval is $II_{res}(\\text{adder}) = \\frac{2 \\text{ uses}}{1 \\text{ unit}} = 2$ cycles/iteration.\n-   **Multiplier:** Used by $I_3$ (1 use per iteration). With 1 multiplier unit, the minimum interval is $II_{res}(\\text{multiplier}) = \\frac{1 \\text{ use}}{1 \\text{ unit}} = 1$ cycle/iteration.\n\nThe overall resource-constrained MII is the maximum over all resource types:\n$$ II_{res} = \\max(2, 1) = 2 $$\n\n**Minimum Initiation Interval ($II$):**\nThe achievable initiation interval is the maximum of the recurrence and resource constraints.\n$$ II = \\max(II_{rec}, II_{res}) = \\max(2L_A + L_M, 2) $$\nSince the execution latencies $L_A$ and $L_M$ are positive integers, the term $2L_A + L_M$ will be at least $2(1) + 1 = 3$. Therefore, the recurrence is always the limiting factor.\n$$ II = 2L_A + L_M $$\n\n### Part 3: Numerical Evaluation\n\nGiven the latencies $L_A = 2$ cycles and $L_M = 4$ cycles, we substitute these values into our derived expression for the minimum initiation interval:\n$$ II = 2(2) + 4 $$\n$$ II = 4 + 4 $$\n$$ II = 8 $$\nThe minimum steady-state initiation interval is 8 cycles per iteration.",
            "answer": "$$\\boxed{8}$$"
        }
    ]
}