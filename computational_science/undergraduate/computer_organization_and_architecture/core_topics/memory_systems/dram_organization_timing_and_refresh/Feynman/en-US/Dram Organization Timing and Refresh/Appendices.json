{
    "hands_on_practices": [
        {
            "introduction": "Modern DRAM is not a single monolithic entity but is structured into multiple banks and bank groups to enable parallel operations. Accessing different bank groups in succession is significantly faster than repeatedly accessing the same one due to timing parameters like $t_{\\text{CCD_S}}$ (short) and $t_{\\text{CCD_L}}$ (long). This exercise  provides a concrete, quantitative look at this principle by asking you to compare the throughput of two different memory access patterns, demonstrating how crucial memory-aware data layout is for performance.",
            "id": "3637036",
            "problem": "A processor issues a sustained stream of read column commands to a single channel of Double Data Rate fourth generation Synchronous Dynamic Random-Access Memory (DDR4 SDRAM). The channel is $64$-bit wide and operates at a data rate of DDR4-$2400$, which implies a command clock frequency of $f_{\\text{CK}} = 1200 \\times 10^{6} \\text{ s}^{-1}$. The device uses burst length (BL) $8$, and all requests are row hits with no row activation or precharge required; ignore bus turnarounds and any timing other than the column-to-column delay (CCD).\n\nThe DDR4 device has $4$ bank groups. The memory controller maps the bank group index $g(A)$ from the physical address $A$ by low-order interleaving across cache-line granularity such that\n$$\ng(A) = \\left(\\left\\lfloor \\frac{A}{64}\\right\\rfloor \\bmod 4\\right),\n$$\nwhere $64$ denotes the cache-line size in bytes. Consider two sequential access patterns over addresses $A_{0}, A_{1}, A_{2}, \\dots$:\n- Pattern $\\mathcal{S}$ with stride $S = 256\\ \\text{B}$, that is $A_{k+1} = A_{k} + S$, which keeps $g(A_{k})$ constant across consecutive commands.\n- Pattern $\\mathcal{S}^{\\star}$ with stride $S^{\\star} = 64\\ \\text{B}$, that is $A_{k+1} = A_{k} + S^{\\star}$, which causes round-robin alternation across the $4$ bank groups.\n\nIn DDR4, the minimum separation between consecutive column commands depends on whether those commands target the same bank group or different bank groups. Let $t_{\\text{CCD\\_L}}$ denote the longer CCD (same bank group) and $t_{\\text{CCD\\_S}}$ denote the shorter CCD (different bank groups). Assume $t_{\\text{CCD\\_L}} = 5$ cycles and $t_{\\text{CCD\\_S}} = 4$ cycles.\n\nStarting from first principles that relate sustained throughput to the amount of data transferred per command and the minimum command spacing dictated by $t_{\\text{CCD}}$, determine the fractional throughput drop of pattern $\\mathcal{S}$ relative to pattern $\\mathcal{S}^{\\star}$. Define the drop as\n$$\n\\Delta = \\frac{T_{\\mathcal{S}^{\\star}} - T_{\\mathcal{S}}}{T_{\\mathcal{S}^{\\star}}},\n$$\nwhere $T_{\\mathcal{S}}$ and $T_{\\mathcal{S}^{\\star}}$ are the sustained throughputs under patterns $\\mathcal{S}$ and $\\mathcal{S}^{\\star}$, respectively. Express your final answer as a unitless decimal and round to four significant figures.",
            "solution": "The sustained throughput $T$ is defined as the amount of data transferred per unit time. For a continuous stream of commands, this can be expressed as the ratio of the data transferred per command to the time elapsed per command.\n$$\nT = \\frac{\\text{Data per command}}{\\text{Time per command}}\n$$\n\nFirst, let's determine the amount of data transferred by a single read column command. The channel width is $64$ bits, which is equal to $8$ bytes. A single command initiates a burst transfer of length $BL=8$. This means $8$ transfers, each of the channel width, are performed.\n$$\nD_{\\text{cmd}} = (\\text{Channel Width}) \\times (\\text{Burst Length}) = (8\\ \\text{Bytes}) \\times 8 = 64\\ \\text{Bytes}\n$$\nThis amount of data corresponds to a typical cache-line size, which is consistent with the problem's address mapping function.\n\nNext, we determine the time per command for each access pattern. The problem specifies that the minimum time between two consecutive column commands is determined by the column-to-column delay, $t_{\\text{CCD}}$. This time is given in clock cycles. The duration of one clock cycle is $T_{\\text{CK}} = 1/f_{\\text{CK}}$. Therefore, the time interval between consecutive commands is $\\tau = t_{\\text{CCD}} \\times T_{\\text{CK}}$.\n\nThe throughput can now be written as:\n$$\nT = \\frac{D_{\\text{cmd}}}{\\tau} = \\frac{D_{\\text{cmd}}}{t_{\\text{CCD}} \\cdot T_{\\text{CK}}} = \\frac{D_{\\text{cmd}} \\cdot f_{\\text{CK}}}{t_{\\text{CCD}}}\n$$\nThis equation shows that for a given memory system, the sustained throughput is inversely proportional to the applicable column-to-column delay, $t_{\\text{CCD}}$.\n\nFor access pattern $\\mathcal{S}$, consecutive commands are issued to the same bank group. The governing timing parameter is therefore the longer column-to-column delay, $t_{\\text{CCD\\_L}}$.\n$$\nt_{\\text{CCD}}(\\mathcal{S}) = t_{\\text{CCD\\_L}} = 5\\ \\text{cycles}\n$$\nThe throughput for pattern $\\mathcal{S}$ is:\n$$\nT_{\\mathcal{S}} = \\frac{D_{\\text{cmd}} \\cdot f_{\\text{CK}}}{t_{\\text{CCD\\_L}}}\n$$\n\nFor access pattern $\\mathcal{S}^{\\star}$, consecutive commands are issued to different bank groups due to bank group interleaving. The governing timing parameter is the shorter column-to-column delay, $t_{\\text{CCD\\_S}}$.\n$$\nt_{\\text{CCD}}(\\mathcal{S}^{\\star}) = t_{\\text{CCD\\_S}} = 4\\ \\text{cycles}\n$$\nThe throughput for pattern $\\mathcal{S}^{\\star}$ is:\n$$\nT_{\\mathcal{S}^{\\star}} = \\frac{D_{\\text{cmd}} \\cdot f_{\\text{CK}}}{t_{\\text{CCD\\_S}}}\n$$\n\nWe are asked to find the fractional throughput drop of pattern $\\mathcal{S}$ relative to pattern $\\mathcal{S}^{\\star}$, which is defined as:\n$$\n\\Delta = \\frac{T_{\\mathcal{S}^{\\star}} - T_{\\mathcal{S}}}{T_{\\mathcal{S}^{\\star}}} = 1 - \\frac{T_{\\mathcal{S}}}{T_{\\mathcal{S}^{\\star}}}\n$$\nSubstituting the expressions for $T_{\\mathcal{S}}$ and $T_{\\mathcal{S}^{\\star}}$:\n$$\n\\frac{T_{\\mathcal{S}}}{T_{\\mathcal{S}^{\\star}}} = \\frac{\\frac{D_{\\text{cmd}} \\cdot f_{\\text{CK}}}{t_{\\text{CCD\\_L}}}}{\\frac{D_{\\text{cmd}} \\cdot f_{\\text{CK}}}{t_{\\text{CCD\\_S}}}} = \\frac{t_{\\text{CCD\\_S}}}{t_{\\text{CCD\\_L}}}\n$$\nThe terms $D_{\\text{cmd}}$ and $f_{\\text{CK}}$ cancel out, simplifying the expression for $\\Delta$:\n$$\n\\Delta = 1 - \\frac{t_{\\text{CCD\\_S}}}{t_{\\text{CCD\\_L}}}\n$$\nNow, we substitute the specified numerical values for the timing parameters: $t_{\\text{CCD\\_L}} = 5$ cycles and $t_{\\text{CCD\\_S}} = 4$ cycles.\n$$\n\\Delta = 1 - \\frac{4}{5} = 1 - 0.8 = 0.2\n$$\nThe problem requires the answer as a unitless decimal rounded to four significant figures.\n$$\n\\Delta = 0.2000\n$$\nThis result indicates a $20\\%$ drop in throughput when the access pattern fails to exploit bank group interleaving, forcing all accesses to the same bank group and thus incurring the longer $t_{\\text{CCD\\_L}}$ latency between commands.",
            "answer": "$$\n\\boxed{0.2000}\n$$"
        },
        {
            "introduction": "A memory controller must efficiently serve both read and write requests on a shared data bus, but switching the bus direction incurs an idle-time penalty ($t_{\\text{RTW}}$ and $t_{\\text{WTR}}$). To improve efficiency, writes are often grouped into batches to amortize this turnaround cost. This practice  explores the classic trade-off this creates: larger write batches improve write throughput but can starve pending reads, increasing their latency. Your task is to find the optimal batch size that maximizes efficiency without violating a critical read latency constraint.",
            "id": "3637027",
            "problem": "A memory controller for Dynamic Random-Access Memory (DRAM) using Double Data Rate (DDR) signaling employs a simple policy: it services reads whenever any read requests are pending, and when it switches to writes, it executes a fixed-size write batch of exactly $B_{w}$ consecutive writes before switching back to reads. Switching bus direction from reads to writes incurs a read-to-write turnaround of $t_{\\text{RTW}}$ idle bus cycles, and switching from writes to reads incurs a write-to-read turnaround of $t_{\\text{WTR}}$ idle bus cycles. Each write consumes the data bus for exactly $t_{\\text{BURST}}$ cycles. A read, once it begins service, takes $t_{R}$ cycles from issuance to the first data. Treat the bus as the bottleneck resource and assume the controller does not preempt a write batch once started.\n\nDefine “lost cycles” as the total number of bus cycles during which no useful write or read data is transferred due solely to direction turnarounds. For a long stream with many writes, batching writes amortizes these lost cycles across the batch.\n\nYou are given:\n- $t_{\\text{RTW}} = 6$ cycles,\n- $t_{\\text{WTR}} = 4$ cycles,\n- $t_{\\text{BURST}} = 4$ cycles,\n- $t_{R} = 14$ cycles,\n- a maximum allowable read tail latency $L_{\\max} = 100$ cycles, defined as the maximum time from the arrival of a read request to the first data returned, measured in bus cycles.\n\nAssume the worst-case read tail latency occurs when a read arrives at the most unfavorable instant relative to a write batch. Choose an integer write batch size $B_{w}$ that minimizes the total lost cycles attributable to direction turnarounds while guaranteeing that the worst-case read tail latency does not exceed $L_{\\max}$. Report the optimal $B_{w}$ as a single integer. No rounding is required because $B_{w}$ is a count.",
            "solution": "The problem requires finding the optimal integer write batch size $B_{w}$ that minimizes lost cycles while satisfying a maximum read latency constraint. The lost cycles due to bus turnaround, $t_{\\text{RTW}}$ and $t_{\\text{WTR}}$, are fixed for each write batch. To minimize their impact, these fixed costs must be amortized over the largest possible number of writes. Therefore, minimizing the proportion of lost cycles is equivalent to maximizing the write batch size, $B_w$. The problem is thus to find the maximum integer value of $B_w$ that adheres to the read latency constraint.\n\nThe constraint is given by the maximum allowable read tail latency, $L_{\\max} = 100$ cycles. We must first formulate an expression for the worst-case read tail latency, $L_{\\text{worst}}$, as a function of $B_w$. The worst-case scenario for a read request occurs when it arrives at the most inopportune moment. Given the controller's policy (reads are prioritized, but write batches are non-preemptive), the worst time for a read to arrive is just after the controller has finished serving a series of reads and has committed to starting a write batch.\n\nLet's trace the timeline for this unfortunate read request which arrives at time $t_{arrival}$:\n$1.$ The memory controller decides to switch from serving reads to writes. At this moment, our read request arrives. Since the controller has already committed to the switch, the read request must wait. The first delay incurred is the read-to-write turnaround time, $t_{\\text{RTW}}$.\n$2.$ Following the turnaround, the controller executes the entire batch of $B_w$ writes. Since each write takes $t_{\\text{BURST}}$ cycles, this phase lasts for a total of $B_w \\cdot t_{\\text{BURST}}$ cycles.\n$3.$ After the last write in the batch completes, the controller must switch the bus direction back to reads to service the pending read request. This incurs the write-to-read turnaround time, $t_{\\text{WTR}}$.\n$4.$ At this point, the bus is ready to accept a read command. The read request, which has been waiting, is now issued to the DRAM. From the moment of issuance, it takes $t_{R}$ cycles for the first piece of data to be returned.\n\nThe total latency for this worst-case read is the sum of all these time components. We can express the worst-case latency, $L_{\\text{worst}}$, as:\n$$L_{\\text{worst}} = t_{\\text{RTW}} + (B_w \\cdot t_{\\text{BURST}}) + t_{\\text{WTR}} + t_{R}$$\n\nThe problem states that this latency must not exceed the maximum allowable latency, $L_{\\max}$. This gives us the governing inequality:\n$$L_{\\text{worst}} \\le L_{\\max}$$\n$$t_{\\text{RTW}} + (B_w \\cdot t_{\\text{BURST}}) + t_{\\text{WTR}} + t_{R} \\le L_{\\max}$$\n\nTo find the maximum possible value for $B_w$, we solve this inequality for $B_w$:\n$$(B_w \\cdot t_{\\text{BURST}}) \\le L_{\\max} - t_{\\text{RTW}} - t_{\\text{WTR}} - t_{R}$$\n$$B_w \\le \\frac{L_{\\max} - t_{\\text{RTW}} - t_{\\text{WTR}} - t_{R}}{t_{\\text{BURST}}}$$\n\nNow, we substitute the given numerical values into the inequality:\n-   $L_{\\max} = 100$\n-   $t_{\\text{RTW}} = 6$\n-   $t_{\\text{WTR}} = 4$\n-   $t_{\\text{BURST}} = 4$\n-   $t_{R} = 14$\n\n$$B_w \\le \\frac{100 - 6 - 4 - 14}{4}$$\n$$B_w \\le \\frac{100 - (6 + 4 + 14)}{4}$$\n$$B_w \\le \\frac{100 - 24}{4}$$\n$$B_w \\le \\frac{76}{4}$$\n$$B_w \\le 19$$\n\nSince $B_w$ must be an integer, and our goal is to maximize $B_w$ to achieve the best amortization of turnaround costs, we choose the largest integer value that satisfies this condition. The maximum integer value for $B_w$ is $19$.\nThis means a write batch size up to $19$ is permissible. To minimize the relative cost of turnarounds, the optimal choice is $B_w = 19$. Any larger value would violate the latency constraint. For example, if $B_w=20$, the latency would be $6 + (20 \\cdot 4) + 4 + 14 = 6+80+4+14 = 104$ cycles, which exceeds $L_{\\max} = 100$.\n\nThe optimal write batch size is therefore $19$.",
            "answer": "$$\n\\boxed{19}\n$$"
        },
        {
            "introduction": "The need for periodic refresh is a fundamental characteristic of DRAM, but this essential operation renders a bank temporarily unavailable, potentially stalling memory requests and degrading performance. This hands-on problem  quantifies the bandwidth penalty caused by refresh cycles in a high-throughput streaming scenario. Furthermore, it challenges you to evaluate a common mitigation technique—using bank-level parallelism to hide refresh latency—thereby connecting the concepts of bank organization and timing overheads.",
            "id": "3637083",
            "problem": "A single rank of Double Data Rate fourth-generation Synchronous Dynamic Random-Access Memory (DDR4 SDRAM) is used by a streaming Direct Memory Access (DMA) engine that continuously issues long, back-to-back read transfers. Consider the following facts and constraints:\n\n- The memory bus is $64$ bits wide and runs at a data rate of $2.4 \\times 10^{9}$ transfers per second, so each transfer carries $8$ bytes of data.\n- The device uses per-bank refresh (one bank refreshed at a time). Each bank must be refreshed once every interval $t_{\\text{REFI}} = 7.8 \\times 10^{-6} \\text{ s}$, and the per-bank refresh command occupies that bank for $t_{\\text{RFCpb}} = 260 \\times 10^{-9} \\text{ s}$.\n- The DMA engine’s application-level transfer granularity is $64 \\text{ KiB}$ per burst. By default, all $64 \\text{ KiB}$ are placed in a single bank and read as a single contiguous burst.\n- A proposed mitigation splits each $64 \\text{ KiB}$ burst into two equal $32 \\text{ KiB}$ sub-bursts, placing one $32 \\text{ KiB}$ sub-burst in bank $0$ and the other $32 \\text{ KiB}$ sub-burst in bank $1$. The memory controller always schedules sub-bursts so that no sub-burst overlaps its target bank’s per-bank refresh window. Switching between banks for consecutive read sub-bursts requires a read-to-read inter-bank spacing equal to $t_{\\text{CCD_L}} = 5$ command cycles at a $1.2 \\times 10^{9} \\text{ Hz}$ command clock, during which the data bus is idle. Assume no other timing overheads limit the steady-state stream.\n- Assume that the controller can keep the data bus continuously busy whenever a bank is available (that is, the stream is otherwise bandwidth-bound). Also, assume that per-bank refreshes are serialized such that at most one bank is in refresh at a time.\n\nUsing only the definitions that (i) Dynamic Random-Access Memory (DRAM) refresh renders the target bank unavailable to service commands for a duration $t_{\\text{RFC}}$ each $t_{\\text{REFI}}$, (ii) sustained bandwidth equals data moved per unit time, and (iii) any interval in which the bus cannot transfer data reduces sustained bandwidth in direct proportion to the fraction of time the bus is idle, compute the multiplicative improvement in sustained bandwidth achieved by the mitigation relative to the baseline. Specifically, let $R_{\\text{base}}$ denote the sustained bandwidth when the entire $64 \\text{ KiB}$ burst resides in a single bank, and let $R_{\\text{mit}}$ denote the sustained bandwidth when bursts are split across two banks as described. Compute the ratio $R_{\\text{mit}} / R_{\\text{base}}$.\n\nExpress your final answer as a unitless decimal number and round your answer to four significant figures.",
            "solution": "The user wants to compute the multiplicative improvement in sustained bandwidth, defined as the ratio $R_{\\text{mit}} / R_{\\text{base}}$, where $R_{\\text{base}}$ is the sustained bandwidth of a baseline memory access pattern and $R_{\\text{mit}}$ is the sustained bandwidth of a mitigated pattern.\n\nThe problem provides a critical definition: \"any interval in which the bus cannot transfer data reduces sustained bandwidth in direct proportion to the fraction of time the bus is idle.\" Let $B_{\\text{peak}}$ denote the theoretical peak bandwidth of the memory bus. Let $f_{\\text{idle}}$ be the fraction of time the bus is idle. The sustained bandwidth $R$ can be expressed as:\n$$R = B_{\\text{peak}} (1 - f_{\\text{idle}})$$\nThe ratio we need to compute is therefore:\n$$\\frac{R_{\\text{mit}}}{R_{\\text{base}}} = \\frac{B_{\\text{peak}} (1 - f_{\\text{idle, mit}})}{B_{\\text{peak}} (1 - f_{\\text{idle, base}})} = \\frac{1 - f_{\\text{idle, mit}}}{1 - f_{\\text{idle, base}}}$$\nOur task reduces to calculating the bus idle-time fraction for both the baseline ($f_{\\text{idle, base}}$) and mitigated ($f_{\\text{idle, mit}}$) scenarios.\n\nFirst, we analyze the baseline scenario. In this case, a continuous stream of $64 \\text{ KiB}$ bursts targets a single memory bank. The only source of bus idleness is the periodic per-bank refresh command, which makes the target bank unavailable. The problem states that each bank must be refreshed for a duration $t_{\\text{RFCpb}} = 260 \\times 10^{-9} \\text{ s}$ once every interval $t_{\\text{REFI}} = 7.8 \\times 10^{-6} \\text{ s}$. Since the entire data stream depends on this single bank, the bus will be forced idle whenever that bank is refreshing. The fraction of time the bus is idle is the ratio of the refresh time to the refresh interval.\n$$f_{\\text{idle, base}} = \\frac{t_{\\text{RFCpb}}}{t_{\\text{REFI}}}$$\nSubstituting the given values:\n$$f_{\\text{idle, base}} = \\frac{260 \\times 10^{-9} \\text{ s}}{7.8 \\times 10^{-6} \\text{ s}} = \\frac{260}{7800} = \\frac{26}{780} = \\frac{1}{30}$$\n\nNext, we analyze the mitigation scenario. Each $64 \\text{ KiB}$ burst is split into two $32 \\text{ KiB}$ sub-bursts, placed in bank $0$ and bank $1$. The controller interleaves access to these banks. The problem states that the controller schedules sub-bursts to avoid refresh windows. Since per-bank refreshes are serialized (at most one bank refreshes at a time), when bank $0$ is refreshing, the controller can access bank $1$, and vice versa. Therefore, per-bank refresh no longer causes the data bus to be idle.\nHowever, a new source of idleness is introduced: the read-to-read inter-bank spacing, $t_{\\text{CCD_L}}$, which is required when switching between banks. The bus is idle during this time. This switching occurs after every $32 \\text{ KiB}$ sub-burst transfer.\nThe fraction of idle time is the ratio of the idle switching time to the total time of one cycle (transfer + switch).\n$$f_{\\text{idle, mit}} = \\frac{T_{\\text{idle, switch}}}{T_{\\text{transfer, sub}} + T_{\\text{idle, switch}}}$$\nWe must calculate the two time components, $T_{\\text{idle, switch}}$ and $T_{\\text{transfer, sub}}$.\n\nThe idle time for switching is given as $t_{\\text{CCD_L}} = 5$ command cycles. The command clock frequency is $f_{\\text{CMD}} = 1.2 \\times 10^9 \\text{ Hz}$.\n$$T_{\\text{idle, switch}} = \\frac{t_{\\text{CCD_L}}}{f_{\\text{CMD}}} = \\frac{5}{1.2 \\times 10^9 \\text{ s}^{-1}} = \\frac{5}{1.2} \\times 10^{-9} \\text{ s} = \\frac{25}{6} \\times 10^{-9} \\text{ s}$$\n\nThe time to transfer a sub-burst depends on the sub-burst size and the peak bus bandwidth.\nThe sub-burst size is $32 \\text{ KiB} = 32 \\times 2^{10} \\text{ bytes} = 32768 \\text{ bytes}$.\nThe peak bandwidth, $B_{\\text{peak}}$, is the product of the data rate and the bus width. The bus is $64 \\text{ bits}$ ($8 \\text{ bytes}$) wide and runs at $2.4 \\times 10^9$ transfers per second.\n$$B_{\\text{peak}} = (2.4 \\times 10^9 \\text{ s}^{-1}) \\times (8 \\text{ bytes}) = 19.2 \\times 10^9 \\text{ bytes/s}$$\nThe time to transfer one sub-burst is:\n$$T_{\\text{transfer, sub}} = \\frac{32768 \\text{ bytes}}{19.2 \\times 10^9 \\text{ bytes/s}} = \\frac{32768}{19.2} \\times 10^{-9} \\text{ s} = \\frac{5120}{3} \\times 10^{-9} \\text{ s}$$\n\nNow we can calculate $f_{\\text{idle, mit}}$:\n$$f_{\\text{idle, mit}} = \\frac{\\frac{25}{6} \\times 10^{-9} \\text{ s}}{\\frac{5120}{3} \\times 10^{-9} \\text{ s} + \\frac{25}{6} \\times 10^{-9} \\text{ s}} = \\frac{\\frac{25}{6}}{\\frac{10240}{6} + \\frac{25}{6}} = \\frac{25}{10240 + 25} = \\frac{25}{10265} = \\frac{5}{2053}$$\n\nFinally, we compute the required ratio:\n$$\\frac{R_{\\text{mit}}}{R_{\\text{base}}} = \\frac{1 - f_{\\text{idle, mit}}}{1 - f_{\\text{idle, base}}} = \\frac{1 - \\frac{5}{2053}}{1 - \\frac{1}{30}}$$\n$$\\frac{R_{\\text{mit}}}{R_{\\text{base}}} = \\frac{\\frac{2053 - 5}{2053}}{\\frac{30 - 1}{30}} = \\frac{\\frac{2048}{2053}}{\\frac{29}{30}} = \\frac{2048}{2053} \\times \\frac{30}{29} = \\frac{61440}{59537}$$\nPerforming the division to obtain a decimal value:\n$$\\frac{61440}{59537} \\approx 1.03196348$$\nRounding the result to four significant figures as required by the problem statement gives $1.032$. This represents a multiplicative improvement of approximately $3.2\\%$.",
            "answer": "$$\\boxed{1.032}$$"
        }
    ]
}