{
    "hands_on_practices": [
        {
            "introduction": "Understanding how a processor determines a branch's destination is fundamental to grasping control flow. This exercise demystifies PC-relative addressing, a common and efficient method where the target address is encoded as a small offset from the current instruction. By working through this problem, you will see how an assembler translates a symbolic label into the precise numerical offset the CPU needs to execute a jump, a core task in the compilation and linking process .",
            "id": "3629897",
            "problem": "A computer system implements a MIPS-like Instruction Set Architecture (ISA) in which each instruction has size $4$ bytes and conditional branches use a $16$-bit signed offset field that is interpreted in units of instructions. The hardware computes the branch target address as $PC + 4 + (\\text{offset} \\times 4)$, where $PC$ is the Program Counter (PC) pointing to the branch instruction, the $+4$ reflects that the PC advances by $+4$ before adding the offset, and $\\text{offset}$ is sign-extended to $32$ bits and multiplied by $4$ when forming the target.\n\nA relocatable object file contains a single code section (text) whose section-relative byte offsets for assembler labels are recorded. At load time, the operating system loader maps the entire text section at an absolute base address $B_{\\text{text}}$ and also applies a process-wide load bias $\\Delta$, so the absolute base of the text section in memory is $\\tilde{B} = B_{\\text{text}} + \\Delta$. All label addresses in the text section are relocated by adding $\\tilde{B}$ to their section-relative offsets.\n\nConsider the following concrete instance:\n- The absolute base of the text section after mapping is $\\tilde{B} = B_{\\text{text}} + \\Delta$, where $B_{\\text{text}} = 0x0001\\,8000$ and $\\Delta = 0x0000\\,4000$.\n- A branch instruction is assembled at section-relative offset $o_b = 0x0000\\,012C$ and the assembler label it targets, named $\\text{target}$, is at section-relative offset $o_t = 0x0000\\,00D8$.\n\nCompute the exact signed integer value to place in the $16$-bit branch offset field such that, after relocation and using the architecture’s $PC$ bias of $+4$, the branch reaches $\\text{target}$. Express your final answer as a single integer. No rounding is required and no units are to be included in the answer.",
            "solution": "The problem specifies a MIPS-like branch semantics: the branch target address is computed by hardware as\n$$\nA_{\\text{branch-target}} = PC + 4 + (\\text{offset} \\times 4)\n$$\nHere, $\\text{offset}$ is the $16$-bit signed immediate in the instruction, sign-extended to $32$ bits, and multiplying it by $4$ is because instructions are $4$ bytes.\n\nWe are given relocation details. The text section is placed at an absolute base $\\tilde{B}$ defined by\n$$\n\\tilde{B} = B_{\\text{text}} + \\Delta,\n$$\nwith $B_{\\text{text}} = 0x0001\\,8000$ and $\\Delta = 0x0000\\,4000$. The absolute base $\\tilde{B}$ is therefore\n$$\n\\tilde{B} = 0x0001\\,8000 + 0x0000\\,4000 = 0x0001\\,C000.\n$$\nHowever, for PC-relative branches within the same relocated section, the absolute base cancels out when computing the offset. We will show this explicitly.\n\nLet $o_b$ be the section-relative byte offset of the branch instruction and $o_t$ be the section-relative byte offset of the target label. The absolute addresses are\n$$\nA_b = \\tilde{B} + o_b,\\quad A_t = \\tilde{B} + o_t.\n$$\nBecause the PC points to the branch instruction, the PC used in branch computation is $PC = A_b$. The hardware first adds the bias $+4$, so\n$$\nPC + 4 = A_b + 4 = \\tilde{B} + o_b + 4.\n$$\nWe need the branch to land at $A_t$. Setting the hardware-computed target equal to $A_t$ gives\n$$\nA_t = (PC + 4) + (\\text{offset} \\times 4) = (\\tilde{B} + o_b + 4) + (\\text{offset} \\times 4).\n$$\nSolve for $\\text{offset}$:\n$$\n\\text{offset} \\times 4 = A_t - (\\tilde{B} + o_b + 4) = (\\tilde{B} + o_t) - (\\tilde{B} + o_b + 4) = o_t - (o_b + 4),\n$$\nso\n$$\n\\text{offset} = \\frac{o_t - (o_b + 4)}{4}.\n$$\nAs anticipated, the relocation base $\\tilde{B}$ cancels, leaving a difference purely in section-relative offsets adjusted by the $+4$ bias.\n\nNow substitute the given offsets, with $o_b = 0x0000\\,012C$ and $o_t = 0x0000\\,00D8$. Convert to arithmetic:\n$$\no_b = 0x012C = 300,\\quad o_t = 0x00D8 = 216.\n$$\nCompute $o_t - (o_b + 4)$:\n$$\no_t - (o_b + 4) = 216 - (300 + 4) = 216 - 304 = -88.\n$$\nDivide by $4$ to obtain the offset in instruction units:\n$$\n\\text{offset} = \\frac{-88}{4} = -22.\n$$\nCheck range against a $16$-bit signed immediate: $-22$ is within $[-32768, 32767]$, so it is representable without overflow. This is the exact integer to encode in the branch offset field.",
            "answer": "$$\\boxed{-22}$$"
        },
        {
            "introduction": "In modern pipelined processors, correctly guessing a branch's outcome is critical for performance, as a misprediction can stall the pipeline and waste clock cycles. This practice explores the behavior of simple dynamic branch predictors, which use past outcomes to forecast future ones. By comparing a 1-bit predictor with a 2-bit saturating counter on common loop structures, you'll gain a quantitative understanding of why adding just one bit of state can dramatically improve prediction accuracy .",
            "id": "3629826",
            "problem": "A single static conditional branch in a Central Processing Unit (CPU) controls the back edge of a loop. In such a loop, the branch outcome is taken for a fixed number of consecutive iterations and then not taken once to exit, after which the loop repeats. Consider two code regions that each exercise this same static branch but with different taken biases, defined as the long-run fraction of outcomes that are taken.\n\n- Loop A has taken bias $p_{A} = 0.9$.\n- Loop B has taken bias $p_{B} = 0.5$.\n\nAssume the branch predictor is local and dynamic, using either:\n- a $1$-bit memory predictor that predicts the next outcome to equal the most recent outcome of this static branch, or\n- a $2$-bit saturating counter predictor with four states, where prediction is taken in the two upper states and not taken in the two lower states, and state transitions increment on taken and decrement on not taken without going out of range.\n\nAssume the measurement window begins after warm-up in the taken-biased regime: the $1$-bit predictor initially predicts taken for the first measured outcome of this branch, and the $2$-bit predictor initially starts in the most strongly taken state. Using only the fundamental semantics of loop branches (taken on each iteration except the final one) and the definitions above, derive from first principles the expected number of mispredictions per $1000$ branch outcomes for each predictor on each loop. Provide the final results as a single row matrix in the order $(M_{1\\text{-bit},\\,A},\\,M_{2\\text{-bit},\\,A},\\,M_{1\\text{-bit},\\,B},\\,M_{2\\text{-bit},\\,B})$, where $M_{\\cdot}$ denotes the mispredictions counted over $1000$ outcomes. No rounding is required, and report raw counts without any unit.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of computer architecture, specifically branch prediction, and is well-posed with a unique, derivable solution. All terms are formally defined, and the data are consistent.\n\nThe core of the problem is to determine the expected number of mispredictions for two types of branch predictors on two different loops. The analysis proceeds in two stages: first, characterizing the branch outcome patterns for each loop based on the given taken biases; second, simulating the behavior of each predictor on these patterns to find the misprediction rates.\n\n**1. Derivation of Loop Branch Patterns**\n\nThe problem states that a static conditional branch controls a loop's back edge. This implies a repeating pattern of outcomes: the branch is taken for a fixed number of iterations, say $N$, and then not taken once to exit the loop. A complete cycle of the loop's branch outcomes thus consists of $N$ taken branches followed by $1$ not-taken branch. The total number of branches in one cycle is $N+1$.\n\nThe taken bias, $p$, is defined as the long-run fraction of outcomes that are taken. For this loop structure, the bias is given by the ratio of taken branches to the total number of branches in a cycle:\n$$p = \\frac{N}{N+1}$$\nWe can solve this equation for $N$ in terms of $p$:\n$$p(N+1) = N$$\n$$pN + p = N$$\n$$p = N - pN = N(1-p)$$\n$$N = \\frac{p}{1-p}$$\n\nUsing this formula, we can determine the value of $N$ for each loop.\n\n*   **Loop A**: The taken bias is $p_A = 0.9$. The number of consecutive taken branches, $N_A$, is:\n    $$N_A = \\frac{p_A}{1-p_A} = \\frac{0.9}{1-0.9} = \\frac{0.9}{0.1} = 9$$\n    Thus, the branch pattern for Loop A is a cycle of $9$ taken outcomes (T) followed by $1$ not-taken outcome (NT). The cycle length is $N_A + 1 = 10$ branches.\n\n*   **Loop B**: The taken bias is $p_B = 0.5$. The number of consecutive taken branches, $N_B$, is:\n    $$N_B = \\frac{p_B}{1-p_B} = \\frac{0.5}{1-0.5} = \\frac{0.5}{0.5} = 1$$\n    Thus, the branch pattern for Loop B is a cycle of $1$ taken outcome (T) followed by $1$ not-taken outcome (NT). The cycle length is $N_B + 1 = 2$ branches.\n\n**2. Analysis of Predictor Performance**\n\nWe now analyze the steady-state performance of each predictor for each loop pattern to determine the expected number of mispredictions per $1000$ outcomes. The term \"expected number\" implies using the long-run misprediction rate.\n\n**Case 1: 1-bit Predictor**\n\nThis predictor uses a 1-bit history, predicting that the next outcome will be the same as the most recent one.\n\n*   **On Loop A (9 T's, 1 NT)**: The repeating outcome sequence is T, T, T, T, T, T, T, T, T, NT.\n    Let's trace a steady-state cycle. The outcome of the last branch of the previous cycle was NT. So, the predictor's state entering the new cycle is 'predict not-taken'.\n    1.  Branch 1 (Outcome T): The prediction is NT. **Mispredict**. The predictor's state is updated to T.\n    2.  Branches 2-9 (Outcome T): The prediction is T. All $8$ are correct. The state remains T.\n    3.  Branch 10 (Outcome NT): The prediction is T. **Mispredict**. The predictor's state is updated to NT.\n    In each cycle of $10$ branches, there are $2$ mispredictions.\n    The misprediction rate is $\\frac{2}{10} = 0.2$.\n    The expected number of mispredictions per $1000$ outcomes is $M_{1\\text{-bit},\\,A} = 1000 \\times 0.2 = 200$.\n\n*   **On Loop B (1 T, 1 NT)**: The repeating outcome sequence is T, NT.\n    Let's trace a steady-state cycle. The predictor's state entering the cycle, after the previous NT, is 'predict not-taken'.\n    1.  Branch 1 (Outcome T): The prediction is NT. **Mispredict**. The state is updated to T.\n    2.  Branch 2 (Outcome NT): The prediction is T. **Mispredict**. The state is updated to NT.\n    Every branch is mispredicted. In each cycle of $2$ branches, there are $2$ mispredictions.\n    The misprediction rate is $\\frac{2}{2} = 1.0$.\n    The expected number of mispredictions per $1000$ outcomes is $M_{1\\text{-bit},\\,B} = 1000 \\times 1.0 = 1000$.\n\n**Case 2: 2-bit Saturating Counter Predictor**\n\nThis predictor uses a 4-state counter: {3: Strongly Taken, 2: Weakly Taken, 1: Weakly Not-Taken, 0: Strongly Not-Taken}. It predicts 'Taken' in states 3 and 2, and 'Not Taken' in states 1 and 0. The counter increments for a taken outcome (saturating at 3) and decrements for a not-taken outcome (saturating at 0). The initial state is given as state 3.\n\n*   **On Loop A (9 T's, 1 NT)**:\n    1.  Branches 1-9 (Outcome T): The initial state is 3. The prediction is T. This is correct. For each of the $9$ taken branches, the counter attempts to increment but is already saturated at 3. The prediction is correct for all $9$ branches.\n    2.  Branch 10 (Outcome NT): The state is 3. The prediction is T. **Mispredict**. The state decrements to 2.\n    The next cycle begins with the predictor in state 2.\n    3.  Branch 1 of next cycle (Outcome T): The state is 2. The prediction is T. This is correct. The state increments to 3.\n    The predictor quickly returns to the strongly taken state. In each cycle of $10$ branches, only the single not-taken branch is mispredicted.\n    The misprediction rate is $\\frac{1}{10} = 0.1$.\n    The expected number of mispredictions per $1000$ outcomes is $M_{2\\text{-bit},\\,A} = 1000 \\times 0.1 = 100$.\n\n*   **On Loop B (1 T, 1 NT)**:\n    1.  Branch 1 (Outcome T): The initial state is 3. The prediction is T. This is correct. The state remains 3 (saturates).\n    2.  Branch 2 (Outcome NT): The state is 3. The prediction is T. **Mispredict**. The state decrements to 2.\n    The next cycle begins with the predictor in state 2.\n    3.  Branch 1 of next cycle (Outcome T): The state is 2. The prediction is T. This is correct. The state increments to 3.\n    4.  Branch 2 of next cycle (Outcome NT): The state is 3. The prediction is T. **Mispredict**. The state decrements to 2.\n    In steady state, the predictor's state alternates between 3 and 2. Since both states predict 'Taken', the prediction is always T. The outcome sequence alternates T, NT. Therefore, every T branch is correctly predicted, and every NT branch is mispredicted.\n    In each cycle of $2$ branches, there is $1$ misprediction.\n    The misprediction rate is $\\frac{1}{2} = 0.5$.\n    The expected number of mispredictions per $1000$ outcomes is $M_{2\\text{-bit},\\,B} = 1000 \\times 0.5 = 500$.\n\n**Summary of Results**\n\nThe calculated number of mispredictions per $1000$ outcomes for each scenario are:\n*   $M_{1\\text{-bit},\\,A} = 200$\n*   $M_{2\\text{-bit},\\,A} = 100$\n*   $M_{1\\text{-bit},\\,B} = 1000$\n*   $M_{2\\text{-bit},\\,B} = 500$\n\nThese results are to be provided in a single row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n200 & 100 & 1000 & 500\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Beyond raw performance, ensuring the logical correctness of control flow is paramount, especially when dealing with complex data types. This problem explores the subtle but critical interaction between floating-point arithmetic and conditional branching, governed by the IEEE 754 standard. You will tackle the challenge of implementing a high-level comparison that correctly handles special values like Not-a-Number (NaN), revealing how a naive mapping of high-level logic to assembly instructions can lead to subtle bugs .",
            "id": "3629890",
            "problem": "A processor implements a floating-point compare instruction that writes condition codes, followed by conditional branches that read those condition codes. You are asked to judge the correctness of several branch sequences when the comparison may encounter Not-a-Number (NaN) values. The desired high-level semantics are those of the C language on Institute of Electrical and Electronics Engineers (IEEE) $754$ binary floating point: for relational operators such as $\\leq$, the outcome is false if either operand is NaN (the comparison is unordered).\n\nFundamental base and definitions:\n- Under IEEE $754$, a comparison is called ordered if neither operand is NaN and unordered if at least one operand is NaN. For relational operators such as $<$, $\\leq$, $>$, $\\geq$, the result is true if the relation holds for an ordered comparison and false if unordered; for equality $==$ the result is false if unordered; for inequality $\\neq$ the result is true if unordered.\n- The processor’s instruction $\\text{FCMP.S}\\;R_{x},R_{y}$ compares the single-precision floating-point values in $R_{x}$ and $R_{y}$ and sets three condition-code flags: zero $Z$, carry $C$, and parity $P$, with meanings aligned to well-known conventions:\n  - If $R_{x} < R_{y}$: $C=1$, $Z=0$, $P=0$.\n  - If $R_{x} = R_{y}$: $C=0$, $Z=1$, $P=0$.\n  - If $R_{x} > R_{y}$: $C=0$, $Z=0$, $P=0$.\n  - If unordered (at least one operand is NaN): $C=1$, $Z=1$, $P=1$.\n- Conditional branches interpret flags as follows:\n  - $\\text{JBE}\\;L$: jump if below-or-equal, i.e., if $(C=1)\\lor(Z=1)$.\n  - $\\text{JA}\\;L$: jump if above, i.e., if $(C=0)\\land(Z=0)$.\n  - $\\text{JP}\\;L$: jump if parity, i.e., if $P=1$ (unordered).\n  - $\\text{JNP}\\;L$: jump if no parity, i.e., if $P=0$ (ordered).\n  - $\\text{JE}\\;L$: jump if equal, i.e., if $Z=1$.\n  - $\\text{JNE}\\;L$: jump if not equal, i.e., if $Z=0$.\n\nGoal:\nImplement control flow for the C-style conditional “if $(R_{x} \\leq R_{y})$ then go to label $L_{\\text{true}}$ else go to label $L_{\\text{false}}$,” with the IEEE $754$ rule that unordered evaluates to false. Assume the code sequence always begins with $\\text{FCMP.S}\\;R_{x},R_{y}$, and that a final unconditional jump to the remaining label is permitted. Choose all option(s) below that correctly implement the desired control flow for all cases, including when either input is NaN.\n\nConsider these candidate sequences (each begins immediately after $\\text{FCMP.S}\\;R_{x},R_{y}$):\n- A.\n  - $\\text{JBE}\\;L_{\\text{true}}$\n  - $\\text{JMP}\\;L_{\\text{false}}$\n- B.\n  - $\\text{JP}\\;L_{\\text{false}}$\n  - $\\text{JBE}\\;L_{\\text{true}}$\n  - $\\text{JMP}\\;L_{\\text{false}}$\n- C.\n  - $\\text{JNP}\\;L_{\\text{ordered}}$\n  - $\\text{JMP}\\;L_{\\text{false}}$\n  - $L_{\\text{ordered}}$:\n  - $\\text{JBE}\\;L_{\\text{true}}$\n  - $\\text{JMP}\\;L_{\\text{false}}$\n- D.\n  - $\\text{JA}\\;L_{\\text{false}}$\n  - $\\text{JP}\\;L_{\\text{false}}$\n  - $\\text{JMP}\\;L_{\\text{true}}$\n\nSelect all correct options. Distractors reflect common misconceptions about using below-or-equal directly after a floating-point compare, and about failing to explicitly exclude unordered cases.",
            "solution": "### Solution Derivation\n\nThe goal is to implement the logic for `if ($R_{x} \\leq R_{y}$) then goto $L_{\\text{true}}$ else goto $L_{\\text{false}}$`. According to the specified IEEE $754$ semantics, the condition ($R_{x} \\leq R_{y}$) is true only if the comparison is ordered and the relation holds. It is false if the comparison is unordered (i.e., NaN is involved) or if $R_{x} > R_{y}$.\n\nWe can summarize the desired control flow based on the result of $\\text{FCMP.S}\\;R_{x},R_{y}$:\n\n| Comparison Result | Flags ($C, Z, P$) | Desired Target |\n| :---------------- | :------------------ | :------------- |\n| $R_x < R_y$       | $C=1, Z=0, P=0$     | $L_{\\text{true}}$     |\n| $R_x = R_y$       | $C=0, Z=1, P=0$     | $L_{\\text{true}}$     |\n| $R_x > R_y$       | $C=0, Z=0, P=0$     | $L_{\\text{false}}$    |\n| Unordered (NaN)   | $C=1, Z=1, P=1$     | $L_{\\text{false}}$    |\n\nThe task is to evaluate each proposed instruction sequence against this table.\n\n### Option-by-Option Analysis\n\n#### Option A\nSequence:\n```\nJBE  L_{\\text{true}}\nJMP  L_{\\text{false}}\n```\nThe $\\text{JBE}$ instruction jumps if $(C=1) \\lor (Z=1)$.\n*   **Case $R_{x} < R_{y}$ ($C=1, Z=0$):** The condition $(1=1) \\lor (0=1)$ is true. The code jumps to $L_{\\text{true}}$. **Correct.**\n*   **Case $R_{x} = R_{y}$ ($C=0, Z=1$):** The condition $(0=1) \\lor (1=1)$ is true. The code jumps to $L_{\\text{true}}$. **Correct.**\n*   **Case $R_{x} > R_{y}$ ($C=0, Z=0$):** The condition $(0=1) \\lor (0=1)$ is false. The code falls through to $\\text{JMP}\\;L_{\\text{false}}$. **Correct.**\n*   **Case Unordered ($C=1, Z=1$):** The condition $(1=1) \\lor (1=1)$ is true. The code jumps to $L_{\\text{true}}$. This is **incorrect**, as the desired outcome is to go to $L_{\\text{false}}$.\n\n**Verdict for A:** **Incorrect**. This sequence fails to handle the unordered (NaN) case correctly, which is a common error when mapping floating-point comparisons to integer-style branches.\n\n#### Option B\nSequence:\n```\nJP   L_{\\text{false}}\nJBE  L_{\\text{true}}\nJMP  L_{\\text{false}}\n```\nThe $\\text{JP}$ instruction jumps if $P=1$, which specifically targets the unordered case.\n*   **Case Unordered ($P=1$):** The condition $P=1$ is true. The code jumps to $L_{\\text{false}}$. **Correct.**\n*   For all other cases ($R_{x} < R_{y}$, $R_{x} = R_{y}$, $R_{x} > R_{y}$), $P=0$, so the $\\text{JP}$ is not taken. Control proceeds to the $\\text{JBE}$ instruction.\n*   **Case $R_{x} < R_{y}$ ($C=1, Z=0$):** The $\\text{JBE}$ condition $(1=1) \\lor (0=1)$ is true. The code jumps to $L_{\\text{true}}$. **Correct.**\n*   **Case $R_{x} = R_{y}$ ($C=0, Z=1$):** The $\\text{JBE}$ condition $(0=1) \\lor (1=1)$ is true. The code jumps to $L_{\\text{true}}$. **Correct.**\n*   **Case $R_{x} > R_{y}$ ($C=0, Z=0$):** The $\\text{JBE}$ condition $(0=1) \\lor (0=1)$ is false. The code falls through to $\\text{JMP}\\;L_{\\text{false}}$. **Correct.**\n\n**Verdict for B:** **Correct**. This sequence correctly handles all four cases by first explicitly checking for and branching on the unordered condition.\n\n#### Option C\nSequence:\n```\nJNP  L_{\\text{ordered}}\nJMP  L_{\\text{false}}\nL_{\\text{ordered}}:\nJBE  L_{\\text{true}}\nJMP  L_{\\text{false}}\n```\nThe $\\text{JNP}$ instruction jumps if $P=0$, which targets all ordered cases.\n*   **Case Unordered ($P=1$):** The condition $P=0$ is false. The $\\text{JNP}$ is not taken. The code falls through to $\\text{JMP}\\;L_{\\text{false}}$. **Correct.**\n*   For all other cases ($R_{x} < R_{y}$, $R_{x} = R_{y}$, $R_{x} > R_{y}$), $P=0$, so the $\\text{JNP}$ is taken, and control transfers to the label $L_{\\text{ordered}}$.\n*   At $L_{\\text{ordered}}$, we have the sequence `JBE L_true; JMP L_false`, which we previously analyzed for ordered cases in Option A.\n    *   **Case $R_{x} < R_{y}$ ($C=1, Z=0$):** $\\text{JBE}$ is taken. Jumps to $L_{\\text{true}}$. **Correct.**\n    *   **Case $R_{x} = R_{y}$ ($C=0, Z=1$):** $\\text{JBE}$ is taken. Jumps to $L_{\\text{true}}$. **Correct.**\n    *   **Case $R_{x} > R_{y}$ ($C=0, Z=0$):** $\\text{JBE}$ is not taken. Falls through to $\\text{JMP}\\;L_{\\text{false}}$. **Correct.**\n\n**Verdict for C:** **Correct**. This sequence is logically equivalent to Option B. It explicitly isolates the logic for ordered cases from the unordered case.\n\n#### Option D\nSequence:\n```\nJA   L_{\\text{false}}\nJP   L_{\\text{false}}\nJMP  L_{\\text{true}}\n```\nThis sequence uses a different strategy: it identifies all conditions that should result in a `false` outcome and jumps to $L_{\\text{false}}$, letting the `true` outcomes fall through to an unconditional jump to $L_{\\text{true}}$.\nThe condition should be false for ($R_{x} > R_{y}$) and for (Unordered).\n*   **Case $R_{x} > R_{y}$ ($C=0, Z=0, P=0$):** The $\\text{JA}$ instruction checks if $(C=0) \\land (Z=0)$. Here, $(0=0) \\land (0=0)$ is true. The code jumps to $L_{\\text{false}}$. **Correct.**\n*   **Case Unordered ($C=1, Z=1, P=1$):** The $\\text{JA}$ condition $(1=0) \\land (1=0)$ is false. The $\\text{JA}$ is not taken. Control proceeds to $\\text{JP}$. The $\\text{JP}$ condition $P=1$ is true. The code jumps to $L_{\\text{false}}$. **Correct.**\n*   **Case $R_{x} < R_{y}$ ($C=1, Z=0, P=0$):** The $\\text{JA}$ condition $(1=0) \\land (0=0)$ is false. The code falls through. The $\\text{JP}$ condition $P=1$ is false. The code falls through to $\\text{JMP}\\;L_{\\text{true}}$. **Correct.**\n*   **Case $R_{x} = R_{y}$ ($C=0, Z=1, P=0$):** The $\\text{JA}$ condition $(0=0) \\land (1=0)$ is false. The code falls through. The $\\text{JP}$ condition $P=1$ is false. The code falls through to $\\text{JMP}\\;L_{\\text{true}}$. **Correct.**\n\n**Verdict for D:** **Correct**. This sequence correctly implements the logic by filtering out the false conditions and defaulting to true.",
            "answer": "$$\\boxed{BCD}$$"
        }
    ]
}