{
    "hands_on_practices": [
        {
            "introduction": "Understanding processor performance begins with analyzing the timing of its most fundamental operations. This first practice focuses on the Program Counter ($PC$) update path, specifically how a target address for a jump instruction is calculated. You will explore how simple bit-level manipulations like shifting and concatenation are realized in hardware and compare their timing costs against core logical components like an adder and a multiplexer. This exercise  provides a foundational look at timing analysis and the distinction between routing delays and gate delays in a datapath.",
            "id": "3677861",
            "problem": "A $32$-bit single-cycle datapath for an architecture that uses a fixed-format jump instruction forms the jump target address by combining the high-order bits of the Program Counter (PC) and the low-order bits from the Instruction Register (IR), with word-aligned low bits. Concretely, the target bus is assembled as $ \\{ PC[31:28],\\, IR[25:0],\\, 00 \\} $, where $IR[25:0]$ is shifted left by $2$ (to account for word alignment), the two low-order bits are zeros, and the top four bits come from $PC[31:28]$. This datapath includes a $32$-bit adder that computes $PC + 4$ and a $32$-bit $2$-to-$1$ Multiplexer (MUX) that selects either $PC + 4$ or the formed jump target to feed the next $PC$.\n\nUsing first principles for synchronous combinational timing—namely that total propagation delay through serially composed combinational stages is the sum of the stage delays—and the hardware fact that fixed left-shifts and bit-concatenations can be realized by wiring (with no logic gates), construct the bit-concatenation hardware at the bus level and model its delay as the sum of routing contributions. Then, quantify how the delay to form the jump target by concatenation compares to the combined delay of the $PC$ adder and the output-selection MUX.\n\nAssume the following physically reasonable delays:\n- $t_{\\text{add}} = 0.36\\,\\text{ns}$ for the $32$-bit adder that produces $PC+4$,\n- $t_{\\text{mux}} = 0.11\\,\\text{ns}$ for the $32$-bit $2$-to-$1$ MUX,\n- $t_{\\text{shift}} = 0.02\\,\\text{ns}$ for routing $IR[25:0]$ into bus positions $[27:2]$ (wired left-shift by $2$),\n- $t_{\\text{top}} = 0.01\\,\\text{ns}$ for routing $PC[31:28]$ into bus positions $[31:28]$,\n- $t_{\\text{concat}} = 0.03\\,\\text{ns}$ for stitching the three sub-buses $\\{ PC[31:28] \\}$, $\\{ IR[25:0] \\ll 2 \\}$, and $\\{ 00 \\}$ into one $32$-bit target bus.\n\nDefine the relative delay $R$ to be the ratio of the delay solely attributable to forming the jump target by bit-concatenation to the sum of the adder and MUX delays. Derive $R$ from the stated principles and compute its numerical value using the parameters above. Round your answer to four significant figures. The answer is unitless; provide the final value of $R$ with no units.",
            "solution": "The objective is to determine the relative delay $R$, defined as the ratio of the delay to form the jump target address to the combined delay of the Program Counter ($PC$) adder and the output-selection multiplexer (MUX).\n\nThe relative delay $R$ is given by the formula:\n$$\nR = \\frac{T_{\\text{jump\\_formation}}}{T_{\\text{adder\\_mux}}}\n$$\nwhere $T_{\\text{jump\\_formation}}$ is the delay solely attributable to forming the jump target address, and $T_{\\text{adder\\_mux}}$ is the sum of the adder and MUX delays.\n\nFirst, we determine the delay for forming the jump target, $T_{\\text{jump\\_formation}}$. The problem specifies that the jump target address is assembled by concatenating three fields: $\\{ PC[31:28], IR[25:0] \\ll 2, 00_2 \\}$. The total delay for this operation is the sum of the routing and stitching contributions. The given delays are:\n-   $t_{\\text{top}} = 0.01\\,\\text{ns}$: The delay to route the high-order bits of the PC.\n-   $t_{\\text{shift}} = 0.02\\,\\text{ns}$: The delay for the wired left-shift of the instruction register bits.\n-   $t_{\\text{concat}} = 0.03\\,\\text{ns}$: The delay to stitch the sub-buses into the final bus.\n\nThe total delay for jump target formation is the sum of these serial contributions:\n$$\nT_{\\text{jump\\_formation}} = t_{\\text{top}} + t_{\\text{shift}} + t_{\\text{concat}}\n$$\nSubstituting the given numerical values:\n$$\nT_{\\text{jump\\_formation}} = 0.01\\,\\text{ns} + 0.02\\,\\text{ns} + 0.03\\,\\text{ns} = 0.06\\,\\text{ns}\n$$\n\nNext, we calculate the combined delay of the adder and the MUX, $T_{\\text{adder\\_mux}}$. The given delays are:\n-   $t_{\\text{add}} = 0.36\\,\\text{ns}$: The propagation delay of the $32$-bit adder.\n-   $t_{\\text{mux}} = 0.11\\,\\text{ns}$: The propagation delay of the $32$-bit $2$-to-$1$ MUX.\n\nThe sum of these delays is:\n$$\nT_{\\text{adder\\_mux}} = t_{\\text{add}} + t_{\\text{mux}}\n$$\nSubstituting the given numerical values:\n$$\nT_{\\text{adder\\_mux}} = 0.36\\,\\text{ns} + 0.11\\,\\text{ns} = 0.47\\,\\text{ns}\n$$\n\nFinally, we compute the relative delay $R$ by taking the ratio of $T_{\\text{jump\\_formation}}$ to $T_{\\text{adder\\_mux}}$:\n$$\nR = \\frac{T_{\\text{jump\\_formation}}}{T_{\\text{adder\\_mux}}} = \\frac{0.06\\,\\text{ns}}{0.47\\,\\text{ns}}\n$$\nThe units of nanoseconds ($\\text{ns}$) cancel out, leaving a dimensionless ratio.\n$$\nR = \\frac{0.06}{0.47} \\approx 0.12765957...\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\nR \\approx 0.1277\n$$\nThis result quantifies that the delay to form the jump address via wiring and concatenation is approximately $12.77\\%$ of the combined delay of the adder and selection MUX stages.",
            "answer": "$$\n\\boxed{0.1277}\n$$"
        },
        {
            "introduction": "Effective datapath design often involves making critical trade-offs between component complexity, cost, and performance. In this exercise, we move from the control flow path to the data path, examining where to place sign-extension logic for immediate operands destined for the ALU. By analyzing two distinct design options, you will quantify how this decision impacts the structure and propagation delay of the input multiplexers. This practice  will sharpen your skills in critical path analysis and evaluating design alternatives based on quantitative evidence.",
            "id": "3633277",
            "problem": "A thirty-two-bit datapath implements an Arithmetic Logic Unit (ALU) whose two inputs are each driven by a set of sources selected by input Multiplexers (MUXes). One ALU input, denoted as the $B$ input, can be driven by either the Register File (RF) output or an immediate field from the instruction. The immediate field is $16$ bits and must be either sign-extended or zero-extended to $32$ bits depending on the instruction.\n\nConsider two design options for placing the sign/zero-extension hardware relative to the ALU $B$-input MUX:\n\n- Option $\\mathcal{P}$ (extension before MUX): The datapath contains two separate $32$-bit extension sources, one for sign-extension and one for zero-extension, both feeding a single $B$-input MUX that also receives the $32$-bit RF output. Thus the $B$-input MUX in this option has $m_{\\mathcal{P}} = 3$ inputs, each of width $w_{\\text{ALU}} = 32$ bits.\n\n- Option $\\mathcal{Q}$ (extension after immediate selection and before ALU input MUX): The datapath first uses a $16$-bit MUX to select between the raw $16$-bit immediate field and a $16$-bit zero constant and then applies a single $32$-bit extension unit that produces either sign-extension or zero-extension under instruction control. The $32$-bit output of this extension unit then feeds a $2$-input $B$-input MUX together with the $32$-bit RF output. Thus the immediate-selection MUX has $m_{\\text{imm}} = 2$ inputs of width $w_{\\text{imm}} = 16$ bits, and the $B$-input MUX has $m_{\\mathcal{Q}} = 2$ inputs of width $w_{\\text{ALU}} = 32$ bits.\n\nAssume the following fundamental combinational models:\n\n1. Any $m$-to-$1$ MUX is built from a tree of $2$-to-$1$ bit-slice stages, requiring $n = \\lceil \\log_{2}(m) \\rceil$ cascaded stages on the data path. The propagation delay across cascaded stages is the sum of stage delays.\n\n2. A $2$-to-$1$ MUX bit-slice stage has a data-path propagation delay composed of a gate term $t_{\\text{bit}}$ and a select-load term linear in the bit-width $w$, namely $k \\cdot w$. Hence the per-stage delay is $t_{\\text{stage}}(w) = t_{\\text{bit}} + k \\cdot w$.\n\n3. Sign/zero-extension hardware is purely combinational; its data-path delay is $t_{\\text{ext}}$ regardless of the extension mode. Replicating the Most Significant Bit (MSB) for sign-extension or inserting zeros for zero-extension incurs the same delay.\n\nNeglect wire delays and any ALU-internal delay; focus only on the path up to the ALU input. Use the following parameter values for numerical evaluation:\n\n- $t_{\\text{bit}} = 45 \\,\\text{ps}$,\n- $k = 0.12 \\,\\text{ps}$,\n- $t_{\\text{ext}} = 20 \\,\\text{ps}$,\n- $w_{\\text{imm}} = 16$,\n- $w_{\\text{ALU}} = 32$.\n\nUsing these models, derive expressions for the worst-case immediate-operand path delay to the ALU $B$ input for Option $\\mathcal{P}$ and Option $\\mathcal{Q}$, and compute the difference $\\Delta t = t_{\\mathcal{P}} - t_{\\mathcal{Q}}$. Express the final delay difference in picoseconds and round your answer to four significant figures. Do not include units in your final boxed answer.",
            "solution": "The objective is to compute the difference in the worst-case propagation delay for the immediate operand, $\\Delta t = t_{\\mathcal{P}} - t_{\\mathcal{Q}}$, between two datapath design options. We will derive symbolic expressions for the delays $t_{\\mathcal{P}}$ and $t_{\\mathcal{Q}}$ based on the provided component models.\n\nThe fundamental delay model for an $m$-to-$1$ MUX of width $w$ is $t_{\\text{MUX}}(m, w) = \\lceil \\log_{2}(m) \\rceil \\cdot (t_{\\text{bit}} + k \\cdot w)$. The delay of the extension hardware is a constant, $t_{\\text{ext}}$.\n\nFirst, we analyze Option $\\mathcal{P}$.\nIn this design, the $16$-bit immediate is first extended to $32$ bits (delay $t_{\\text{ext}}$). The result is then fed into a $3$-input MUX. The delay of this MUX is the critical component after the extension.\nThe MUX has $m_{\\mathcal{P}} = 3$ inputs and a width of $w_{\\text{ALU}} = 32$ bits. The number of stages is $n_{\\mathcal{P}} = \\lceil \\log_{2}(3) \\rceil = 2$.\nThe delay of this MUX is:\n$t_{\\text{MUX}, \\mathcal{P}} = 2 \\cdot (t_{\\text{bit}} + k \\cdot w_{\\text{ALU}})$\nThe total delay for the immediate operand path in Option $\\mathcal{P}$ is the sum of the extension delay and the MUX delay:\n$$t_{\\mathcal{P}} = t_{\\text{ext}} + t_{\\text{MUX}, \\mathcal{P}} = t_{\\text{ext}} + 2(t_{\\text{bit}} + k \\cdot w_{\\text{ALU}})$$\n\nNext, we analyze Option $\\mathcal{Q}$.\nIn this design, the $16$-bit immediate first passes through a $2$-input MUX of width $w_{\\text{imm}} = 16$. The number of stages is $n_{\\text{imm}} = \\lceil \\log_{2}(2) \\rceil = 1$. The delay of this first MUX is:\n$t_{\\text{MUX, imm}} = 1 \\cdot (t_{\\text{bit}} + k \\cdot w_{\\text{imm}})$\nThe output is then fed into an extension unit (delay $t_{\\text{ext}}$). Finally, the $32$-bit result enters a second, $2$-input MUX of width $w_{\\text{ALU}} = 32$. The number of stages is $n_{\\mathcal{Q}} = \\lceil \\log_{2}(2) \\rceil = 1$. The delay of this second MUX is:\n$t_{\\text{MUX}, \\mathcal{Q}} = 1 \\cdot (t_{\\text{bit}} + k \\cdot w_{\\text{ALU}})$\nThe total delay for Option $\\mathcal{Q}$ is the sum of delays of all components in series:\n$$t_{\\mathcal{Q}} = t_{\\text{MUX, imm}} + t_{\\text{ext}} + t_{\\text{MUX}, \\mathcal{Q}} = (t_{\\text{bit}} + k \\cdot w_{\\text{imm}}) + t_{\\text{ext}} + (t_{\\text{bit}} + k \\cdot w_{\\text{ALU}})$$\n$$t_{\\mathcal{Q}} = t_{\\text{ext}} + 2t_{\\text{bit}} + k(w_{\\text{imm}} + w_{\\text{ALU}})$$\n\nNow, we compute the difference $\\Delta t = t_{\\mathcal{P}} - t_{\\mathcal{Q}}$.\n$$t_{\\mathcal{P}} = t_{\\text{ext}} + 2t_{\\text{bit}} + 2k \\cdot w_{\\text{ALU}}$$\n$$t_{\\mathcal{Q}} = t_{\\text{ext}} + 2t_{\\text{bit}} + k \\cdot w_{\\text{imm}} + k \\cdot w_{\\text{ALU}}$$\nSubtracting the expression for $t_{\\mathcal{Q}}$ from $t_{\\mathcal{P}}$, the terms $t_{\\text{ext}}$ and $2t_{\\text{bit}}$ cancel out:\n$$\\Delta t = (2k \\cdot w_{\\text{ALU}}) - (k \\cdot w_{\\text{imm}} + k \\cdot w_{\\text{ALU}})$$\n$$\\Delta t = k \\cdot w_{\\text{ALU}} - k \\cdot w_{\\text{imm}} = k(w_{\\text{ALU}} - w_{\\text{imm}})$$\n\nFinally, we substitute the given numerical values: $k = 0.12 \\,\\text{ps}$, $w_{\\text{ALU}} = 32$, and $w_{\\text{imm}} = 16$.\n$$\\Delta t = 0.12 \\cdot (32 - 16)$$\n$$\\Delta t = 0.12 \\cdot 16 = 1.92 \\,\\text{ps}$$\nThe problem requires the answer to be rounded to four significant figures. The calculated value is $1.92$, which can be written as $1.920$ to meet this requirement. A positive value for $\\Delta t$ indicates that Option $\\mathcal{P}$ has a longer delay for the immediate operand path than Option $\\mathcal{Q}$.",
            "answer": "$$\n\\boxed{1.920}\n$$"
        },
        {
            "introduction": "A robust processor must not only compute correct results but also correctly handle exceptional situations, such as arithmetic overflow. This final practice delves into the logic within the ALU itself and its crucial interface with the processor's control unit. You will determine the correct Boolean conditions for detecting signed overflow and analyze the precise sequence of events required to trigger an exception without corrupting the machine's state. This problem  bridges the gap between datapath computation and high-level control, demonstrating how hardware events initiate software exception handlers.",
            "id": "3633263",
            "problem": "A processor implements two's complement arithmetic on $32$-bit words. The Arithmetic Logic Unit (ALU) must detect signed arithmetic overflow for addition and subtraction and propagate an Overflow flag (OVF) into a Status Register (SR). The control unit must also support an instruction $ADDV\\ R_d, R_s, R_t$ that traps on overflow: if the addition overflows, the instruction must not write its destination register, must save the faulting Program Counter (PC) into an Exception Program Counter (EPC), set $SR.OVF$, and vector control to a fixed overflow handler address. Assume the ALU exposes to the control unit the following per-operation outputs: the result $R$, the carry into the most significant bit (MSB) $C_{in}^{31}$, the carry out of the MSB $C_{out}^{31}$, and the sign bits $A_{31}$, $B_{31}$, $R_{31}$ of the operands $A$, $B$, and the result $R$, respectively. Assume a simple in-order pipeline that performs the arithmetic in an execute stage and commits state (register file and SR writes and PC update) in a later write-back stage.\n\nStarting from first principles of two's complement arithmetic and the definition of signed overflow as producing a result outside the representable range $\\left[-2^{31}, 2^{31}-1\\right]$, choose the option that correctly specifies:\n- A hardware-implementable boolean condition to detect overflow for $ADD$ and for $SUB$ inside the ALU using only $A_{31}$, $B_{31}$, $R_{31}$, $C_{in}^{31}$, and $C_{out}^{31}$.\n- How the $OVF$ flag is latched into $SR$ without corrupting non-arithmetic instructions.\n- How the control unit sequences $ADDV$ on overflow so that the destination register is not updated, $SR.OVF$ is set, $EPC$ is recorded, and $PC$ vectors to a fixed handler address $VEC_{OVF}$, while preserving precise exceptions.\n\nOptions:\nA) Overflow detection:\n- For $ADD$: $OVF = C_{in}^{31} \\oplus C_{out}^{31}$ (equivalently, $OVF = \\left(\\neg A_{31} \\land \\neg B_{31} \\land R_{31}\\right) \\lor \\left(A_{31} \\land B_{31} \\land \\neg R_{31}\\right)$).\n- For $SUB$ (compute $A - B$ as $A + \\left(\\neg B + 1\\right)$): $OVF = \\left(A_{31} \\oplus B_{31}\\right) \\land \\left(R_{31} \\oplus A_{31}\\right)$.\nPropagation: In the write-back stage, if and only if the decoded operation is arithmetic, latch the ALU's $OVF$ into $SR.OVF$; otherwise leave $SR.OVF$ unchanged.\n$ADDV$ handling: In the execute stage compute $R$ and $OVF$. In the write-back stage, if $OVF = 1$, suppress the register-file write to $R_d$, set $SR.OVF \\leftarrow 1$, set $EPC \\leftarrow PC + 4$, set $PC \\leftarrow VEC_{OVF}$, and flush younger in-flight instructions; if $OVF = 0$, commit $R$ to $R_d$ and continue normally.\nB) Overflow detection:\n- For $ADD$: $OVF = C_{out}^{31}$.\n- For $SUB$: $OVF = \\neg C_{out}^{31}$.\nPropagation: Always write the current $OVF$ into $SR.OVF$ during decode for any instruction to keep SR up to date.\n$ADDV$ handling: Perform the register write to $R_d$ first, then, if $OVF = 1$, set $SR.OVF \\leftarrow 1$ and branch to $VEC_{OVF}$ without saving $EPC$ because the next $PC$ is implicit.\nC) Overflow detection:\n- For both $ADD$ and $SUB$: $OVF = \\left(A_{31} \\oplus B_{31}\\right) \\land \\left(R_{31} \\oplus B_{31}\\right)$.\nPropagation: Latch $OVF$ into $SR.OVF$ at the end of execute for all instructions to minimize latency.\n$ADDV$ handling: If $OVF = 1$, execute one delay-slot instruction, then set $EPC \\leftarrow PC$, write $SR.OVF \\leftarrow 1$, and set $PC \\leftarrow VEC_{OVF}$; the destination register $R_d$ is still written to preserve architectural state.\nD) Overflow detection:\n- For both $ADD$ and $SUB$: $OVF = R_{31} \\oplus C_{out}^{31}$; also compute a secondary overflow as the reduction-OR of all bit-level carries to catch multi-bit overflow.\nPropagation: Drive $SR.OVF$ combinationally as $OVF$ so it always reflects the most recent ALU activity, regardless of instruction type.\n$ADDV$ handling: Trap only if both $SR.OVF = 1$ and the global interrupt enable bit $SR.IE = 1$; on trap, set $PC \\leftarrow VEC_{OVF}$ but do not modify $EPC$ because the handler can recompute it from $SR$ and $PC$.",
            "solution": "The problem requires a three-part analysis: the logic for signed overflow detection, the mechanism for propagating the overflow status into the Status Register ($SR$), and the control sequence for handling a trapping instruction ($ADDV$).\n\n**1. Signed Overflow Detection**\n\nThe processor uses $32$-bit two's complement arithmetic, with a representable range of $[-2^{31}, 2^{31}-1]$. Signed overflow occurs when a result falls outside this range.\n\n**For Addition ($A+B$):** Overflow occurs if and only if two numbers of the same sign are added and the result has the opposite sign.\n- Positive Overflow: $A_{31}=0, B_{31}=0, R_{31}=1$.\n- Negative Overflow: $A_{31}=1, B_{31}=1, R_{31}=0$.\nThis logic is captured by the boolean expression: $OVF_{\\text{ADD}} = (\\neg A_{31} \\land \\neg B_{31} \\land R_{31}) \\lor (A_{31} \\land B_{31} \\land \\neg R_{31})$.\nAn equivalent hardware implementation is to check if the carry-in to the sign bit differs from the carry-out: $OVF_{\\text{ADD}} = C_{in}^{31} \\oplus C_{out}^{31}$. Both formulations are correct.\n\n**For Subtraction ($A-B$):** This is computed as $A + (\\neg B + 1)$. Overflow occurs if and only if the operands $A$ and $B$ have *different* signs, and the sign of the result $R$ is different from the sign of $A$. This can be expressed as: $(A_{31} \\neq B_{31}) \\land (R_{31} \\neq A_{31})$, which is equivalent to $OVF_{\\text{SUB}} = (A_{31} \\oplus B_{31}) \\land (A_{31} \\oplus R_{31})$. The expression given in option A, $OVF = (A_{31} \\oplus B_{31}) \\land (R_{31} \\oplus A_{31})$, is identical due to the commutative property of XOR.\n\n**2. Status Flag ($SR.OVF$) Propagation**\n\nTo maintain a precise architectural state in a pipelined processor, status flags must only be updated when an instruction commits, typically in the write-back stage. Furthermore, only instructions for which the flag is semantically meaningful (i.e., arithmetic operations) should modify it. Therefore, the correct mechanism is to latch the ALU's $OVF$ signal into $SR.OVF$ in the write-back stage, but only if the instruction is a signed arithmetic operation.\n\n**3. Exception Handling for `ADDV`**\n\nA precise exception requires that if the instruction faults, it has no effect on the user-visible architectural state (except for the trap-related registers like $EPC$ and $SR$).\nWhen an `ADDV` instruction reaches the write-back stage and its pipelined $OVF$ signal is 1, the control unit must:\n1.  **Suppress** the write to the destination register $R_d$.\n2.  **Save context**: Write the faulting instruction's address (or $PC+4$) to the $EPC$.\n3.  **Record cause**: Set the appropriate status bit, $SR.OVF \\leftarrow 1$.\n4.  **Transfer control**: Force the $PC$ to the handler address, $PC \\leftarrow VEC_{OVF}$.\n5.  **Flush the pipeline** of any younger instructions that were fetched assuming normal execution.\n\n**Evaluation of Options**\n\n*   **A)** This option correctly specifies the overflow detection logic for both ADD and SUB. It correctly describes the propagation mechanism for $SR.OVF$ (latching in write-back only for arithmetic instructions). It also perfectly describes the sequence for a precise exception on overflow. This option is entirely correct.\n*   **B)** The overflow detection logic is for unsigned arithmetic, which is incorrect for this problem. The propagation and handling logic are also flawed, violating the principles of precise exceptions by updating state incorrectly.\n*   **C)** The overflow detection logic is incorrect for both ADD and SUB. The propagation and handling logic are also flawed, updating state in the wrong pipeline stage and failing to suppress the register write on an exception.\n*   **D)** The overflow detection logic is incorrect. The propagation mechanism (combinational driving) would make the architectural state imprecise. The handling logic is also flawed, as the $EPC$ cannot be recomputed after the $PC$ is overwritten.\n\nBased on the analysis, Option A is the only one that presents a correct and coherent design that adheres to the principles of two's complement arithmetic and precise exception handling in a pipelined processor.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}