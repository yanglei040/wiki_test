{
    "hands_on_practices": [
        {
            "introduction": "The root of many floating-point surprises lies in the fact that common decimal fractions, like $0.1$, cannot be represented exactly in binary. This first exercise provides a direct, hands-on comparison between binary and decimal floating-point formats, revealing how this fundamental representational difference leads to accumulating errors even in simple arithmetic . By working through the conversion and a series of additions, you will gain a concrete understanding of why binary floating-point arithmetic can behave in non-intuitive ways.",
            "id": "3642002",
            "problem": "A computing system implements the Institute of Electrical and Electronics Engineers (IEEE) 754 Standard for Floating-Point Arithmetic in both binary single precision ($\\text{binary32}$) and decimal single precision ($\\text{decimal32}$). The system uses \"rounding to nearest, ties to even\", and each elementary operation is correctly rounded to the destination format. The $\\text{binary32}$ format encodes a real value as $(-1)^{s} \\cdot (1.f) \\cdot 2^{E - 127}$ for normal numbers, where $s$ is the sign bit, $E$ is the $8$-bit exponent field with bias $127$, and $f$ is the $23$-bit fraction. The $\\text{decimal32}$ format encodes a real value as $(-1)^{s} \\cdot c \\cdot 10^{q}$, where $c$ is a base-$10$ coefficient with up to $7$ decimal digits and $q$ is a base-$10$ exponent, and it is capable of representing decimal fractions such as $0.1$ exactly.\n\nStarting from these definitions, and without assuming any precomputed constants, perform the following:\n\n1. Derive the exact real value produced when encoding $0.1_{10}$ in $\\text{binary32}$ under \"rounding to nearest, ties to even\". Specifically, determine the normalized exponent and the nearest representable normalized significand, and express the resulting $\\text{binary32}$ value as an exact rational number.\n\n2. Derive the exact real value produced when encoding $0.1_{10}$ in $\\text{decimal32}$ under the same rounding mode, and express it as an exact rational number.\n\n3. In each format, compute the result of the sequential sum $0.1 + 0.1 + 0.1$, where each addition is performed in that format with correct rounding after the operation. Express each final sum as an exact rational number.\n\n4. Compute the absolute difference between the two final sums obtained in part $3$.\n\nRound your final numeric answer to four significant figures. No units are required.",
            "solution": "The problem requires a detailed analysis of floating-point arithmetic in two different IEEE 754 formats, $\\text{binary32}$ and $\\text{decimal32}$, focusing on the representation and summation of the value $0.1$. The analysis will be conducted in four parts, as stipulated.\n\n**Part 1: Derivation of the $\\text{binary32}$ representation of $0.1_{10}$**\n\nThe number to be represented is $0.1_{10}$, which is the rational number $\\frac{1}{10}$. The $\\text{binary32}$ format for a normalized number is $(-1)^s \\cdot (1.f) \\cdot 2^{E-127}$. First, we must determine the exponent. We seek an integer exponent $e$ such that $1 \\le \\frac{1}{10} \\times 2^{-e}  2$. Since $2^3 = 8$ and $2^4 = 16$, we have $2^3  10  2^4$. Taking the reciprocal, $2^{-4}  \\frac{1}{10}  2^{-3}$. To normalize $\\frac{1}{10}$, we write it as $M \\times 2^{-4}$, where $M = \\frac{1}{10} \\times 2^4 = \\frac{16}{10} = 1.6$. Thus, the true exponent is $e = -4$. The biased exponent is $E = e + 127 = -4 + 127 = 123$.\n\nThe significand to be encoded is $1.6_{10}$. The $\\text{binary32}$ format has $1$ implicit bit and $23$ explicit fraction bits, for a total precision of $24$ bits. To determine the $24$-bit representation of the significand, we scale the value $1.6$ by $2^{23}$ and round the result to the nearest integer.\nThe scaled significand is $1.6 \\times 2^{23} = \\frac{16}{10} \\times 2^{23} = \\frac{8}{5} \\times 2^{23} = \\frac{2^3 \\times 2^{23}}{5} = \\frac{2^{26}}{5} = \\frac{67108864}{5} = 13421772.8$.\n\nThe rounding mode is \"rounding to nearest, ties to even\". The value $13421772.8$ is not a tie (i.e., not halfway between two integers). It is closer to $13421773$ than to $13421772$. Thus, we round up to $13421773$.\nThis integer, $13421773$, represents the $24$ bits of the significand. The value of the significand is therefore this integer divided by $2^{23}$.\n$M_{\\text{b32}} = \\frac{13421773}{2^{23}}$.\n\nThe final value represented in $\\text{binary32}$ format, which we denote as $x_{\\text{b32}}$, is the product of this significand and the exponential part:\n$x_{\\text{b32}} = M_{\\text{b32}} \\times 2^{-4} = \\frac{13421773}{2^{23}} \\times 2^{-4} = \\frac{13421773}{2^{27}}$.\nAs a rational number, the $\\text{binary32}$ representation of $0.1$ is $\\frac{13421773}{134217728}$.\n\n**Part 2: Derivation of the $\\text{decimal32}$ representation of $0.1_{10}$**\n\nThe $\\text{decimal32}$ format represents a number as $(-1)^s \\cdot c \\cdot 10^q$, where $c$ is a base-$10$ coefficient of up to $7$ digits. The value $0.1_{10}$ can be expressed as $1 \\times 10^{-1}$. This fits the format perfectly. We can set the sign $s=0$, the coefficient $c=1$, and the exponent $q=-1$. Since the coefficient $c=1$ requires only one digit, it is well within the $7$-digit limit. Therefore, the $\\text{decimal32}$ format represents $0.1$ exactly.\nThe value, which we denote as $x_{\\text{d32}}$, is exactly $0.1$, or the rational number $\\frac{1}{10}$.\n\n**Part 3: Computation of the sequential sum $0.1 + 0.1 + 0.1$**\n\nWe compute the sum in each format, with rounding after each of the two additions.\n\nFor the **$\\text{decimal32}$ format**:\nThe initial value is $x_{\\text{d32}} = \\frac{1}{10}$.\nFirst addition: $S_1 = x_{\\text{d32}} + x_{\\text{d32}} = \\frac{1}{10} + \\frac{1}{10} = \\frac{2}{10} = 0.2$. This value can be represented exactly in $\\text{decimal32}$ format (with $c=2, q=-1$). No rounding is necessary.\nSecond addition: $S_2 = S_1 + x_{\\text{d32}} = \\frac{2}{10} + \\frac{1}{10} = \\frac{3}{10} = 0.3$. This value can also be represented exactly in $\\text{decimal32}$ format (with $c=3, q=-1$). No rounding is necessary.\nThe final sum in the $\\text{decimal32}$ format is $S_{\\text{d32}} = \\frac{3}{10}$.\n\nFor the **$\\text{binary32}$ format**:\nThe initial value is $x_{\\text{b32}} = \\frac{13421773}{2^{27}}$.\nFirst addition: $S'_1 = x_{\\text{b32}} + x_{\\text{b32}} = 2 \\times \\frac{13421773}{2^{27}} = \\frac{13421773}{2^{26}}$.\nThis operation corresponds to incrementing the exponent of $x_{\\text{b32}}$ by $1$ while keeping the significand unchanged. The result $\\frac{13421773}{2^{26}}$ is a valid $\\text{binary32}$ number, so it is stored exactly without rounding.\n\nSecond addition: $S'_2 = S'_1 + x_{\\text{b32}} = \\frac{13421773}{2^{26}} + \\frac{13421773}{2^{27}}$.\nTo perform this addition, we find a common denominator:\n$S'_2 = \\frac{2 \\cdot 13421773}{2^{27}} + \\frac{13421773}{2^{27}} = \\frac{3 \\cdot 13421773}{2^{27}} = \\frac{40265319}{134217728}$.\nThis is the exact mathematical result of the sum. Now, it must be rounded to the $\\text{binary32}$ format. The value is approximately $0.3$. The true exponent $e$ will be $-2$, since $2^{-2} = 0.25$ and $2^{-1} = 0.5$. The normalized form is $M' \\times 2^{-2}$.\nThe significand is $M' = S'_2 \\times 2^2 = \\frac{40265319}{134217728} \\times 4 = \\frac{40265319}{33554432}$.\nTo round this to $24$ bits of precision, we scale it by $2^{23}$:\nScaled significand integer $= M' \\times 2^{23} = \\frac{40265319}{33554432} \\times 2^{23} = \\frac{40265319}{2^{25}} \\times 2^{23} = \\frac{40265319}{2^2} = \\frac{40265319}{4} = 10066329.75$.\nThis result is exactly halfway between the integers $10066329$ and $10066330$, constituting a tie. The \"ties to even\" rule requires rounding to the even integer. The integer $10066329$ is odd. Therefore, we must round up to the nearest even integer, which is $10066330$.\nThe rounded $24$-bit significand corresponds to the integer $10066330$. Its value is $M'_{\\text{b32}} = \\frac{10066330}{2^{23}}$.\nThe final sum in the $\\text{binary32}$ format, $S_{\\text{b32}}$, is:\n$S_{\\text{b32}} = M'_{\\text{b32}} \\times 2^{-2} = \\frac{10066330}{2^{23}} \\times 2^{-2} = \\frac{10066330}{2^{25}} = \\frac{5033165}{16777216}$.\n\n**Part 4: Computation of the absolute difference**\n\nThe final sums are $S_{\\text{d32}} = \\frac{3}{10}$ and $S_{\\text{b32}} = \\frac{5033165}{16777216}$. The absolute difference $\\Delta$ is:\n$\\Delta = |S_{\\text{d32}} - S_{\\text{b32}}| = |\\frac{3}{10} - \\frac{5033165}{16777216}|$.\nWe place the terms over a common denominator:\n$\\Delta = |\\frac{3 \\cdot 16777216 - 10 \\cdot 5033165}{10 \\cdot 16777216}| = |\\frac{50331648 - 50331650}{167772160}|$.\n$\\Delta = |\\frac{-2}{167772160}| = \\frac{2}{167772160} = \\frac{1}{83886080}$.\nThis is the exact rational value of the difference.\n\nTo provide the final answer, we must express this value in decimal form and round it to four significant figures.\n$\\Delta = \\frac{1}{83886080} = 0.000000011920928955078125$.\nIn scientific notation, this is $1.19209289... \\times 10^{-8}$.\nRounding to four significant figures gives $1.192 \\times 10^{-8}$.",
            "answer": "$$\n\\boxed{1.192 \\times 10^{-8}}\n$$"
        },
        {
            "introduction": "Once an exact arithmetic result is computed, it must be rounded to the nearest representable floating-point number. But what happens when the result is precisely halfway between two representable values? This practice explores the 'round to nearest, ties to even' rule, the default method in IEEE 754 used to resolve such ties in an unbiased way . Mastering this concept is key to understanding the deterministic and statistically sound nature of floating-point computations.",
            "id": "3641967",
            "problem": "Consider addition in the Institute of Electrical and Electronics Engineers (IEEE) Standard $754$ binary32 format under the default rounding mode \"round to nearest, ties to even.\" In binary32, a normalized floating-point number has $1$ sign bit, an $8$-bit exponent field with bias $127$, and a $23$-bit fraction field, giving a total significand precision of $p=24$ bits when including the implicit leading $1$. The value of a normalized number is given by $(-1)^{s} \\times m \\times 2^{E}$, where $E$ is the true exponent, calculated as $E = e - 127$ from the stored 8-bit exponent value $e$. The significand $m$ is in the range $[1,2)$.\n\nLet $x = 1.0$ and $y = 2^{-24}$, both viewed as exact real numbers and also exactly representable in binary32. The floating-point adder computes the exact real sum $x+y$ and then rounds it to the nearest representable binary32 value, breaking ties by choosing the candidate whose least significant bit of the stored significand is even. Using only the above fundamentals and standard properties of binary32 spacing near $x=1.0$, determine the rounded floating-point result of $x + y$ as a real number.\n\nGive your final answer as a single real number. No unit is required. Do not round; give the exact value that the IEEE Standard $754$ binary32 adder would produce.",
            "solution": "The problem requires the computation of the floating-point sum of two numbers, $x = 1.0$ and $y = 2^{-24}$, using the Institute of Electrical and Electronics Engineers (IEEE) Standard $754$ binary32 format. The rounding mode is specified as \"round to nearest, ties to even.\"\n\nFirst, we express the operand $x$ in the binary32 format. The number $x = 1.0$ can be written in scientific notation as $1.0 \\times 2^0$.\nThe general form of a normalized binary32 number is $(-1)^{s} \\times m \\times 2^{E}$, where $s$ is the sign bit, $E$ is the true exponent, and $m$ is the significand which lies in the range $[1, 2)$.\nFor $x = 1.0$, the sign is positive, so the sign bit $s=0$. The true exponent is $E=0$. The stored exponent $e$ is calculated as $e = E + \\text{bias} = 0 + 127 = 127$. The significand is $m=1.0$. In binary, this is $1.000..._2$. The format stores a $23$-bit fraction, which for $m=1.0$ is a sequence of $23$ zeros. The leading $1$ of the significand is implicit for normalized numbers.\n\nThe operand $y = 2^{-24}$ is also exactly representable. In scientific notation, this is $1.0 \\times 2^{-24}$.\nFor $y=2^{-24}$, the sign is positive, so $s=0$. The true exponent is $E=-24$. The stored exponent is $e = E + \\text{bias} = -24 + 127 = 103$. The significand is $m=1.0$.\n\nThe floating-point addition process begins by calculating the exact real sum, $S = x + y$.\n$S = 1.0 + 2^{-24}$.\n\nNext, we must round this exact sum $S$ to the nearest representable binary32 number. To do this, we need to identify the two representable numbers that bracket $S$.\nThe number $x=1.0$ is already a representable number. Its significand is $1.\\underbrace{000...0}_{23 \\text{ zeros}}$.\nFor numbers with a true exponent $E=0$ (like $x=1.0$), the precision of the binary32 format allows for a $23$-bit fractional part. The smallest possible change in value is determined by the least significant bit (LSB) of the fraction, which corresponds to a value of $2^{-23}$. This quantity is known as the unit in the last place (ULP) for numbers of this magnitude.\nThe representable numbers around $1.0$ are therefore of the form $1.0 + k \\cdot 2^{-23}$ for integer values of $k$.\n\nLet's find the two representable numbers, which we will call $z_{-}$ and $z_{+}$, that are immediately below and above the exact sum $S$.\nThe number immediately below or equal to $S$ is $z_{-} = 1.0$. This corresponds to $k=0$.\nThe number immediately above $S$ is $z_{+} = 1.0 + 2^{-23}$. This corresponds to $k=1$.\n\nThe exact sum is $S = 1.0 + 2^{-24}$. We must determine whether $S$ is closer to $z_{-}$ or $z_{+}$.\nThe distance from $S$ to $z_{-}$ is:\n$$ |S - z_{-}| = |(1.0 + 2^{-24}) - 1.0| = 2^{-24} $$\nThe distance from $S$ to $z_{+}$ is:\n$$ |S - z_{+}| = |(1.0 + 2^{-24}) - (1.0 + 2^{-23})| = |2^{-24} - 2 \\cdot 2^{-24}| = |-2^{-24}| = 2^{-24} $$\nThe distances are equal. This means that the exact sum $S$ is exactly halfway between the two representable numbers $z_{-}$ and $z_{+}$. This is a tie case.\nWe can also see this by computing the midpoint of the interval $[z_{-}, z_{+}]$:\n$$ M = \\frac{z_{-} + z_{+}}{2} = \\frac{1.0 + (1.0 + 2^{-23})}{2} = \\frac{2.0 + 2^{-23}}{2} = 1.0 + 2^{-24} $$\nSince $S=M$, it is a tie.\n\nThe specified rounding mode is \"round to nearest, ties to even.\" For a tie, the standard dictates rounding to the number whose significand has a least significant bit of $0$.\nLet's examine the significands of our two candidates, $z_{-}$ and $z_{+}$. The precision is $p=24$ bits, so the significand has the form $1.f_1 f_2 ... f_{23}$. The least significant bit of the fraction is $f_{23}$.\nFor $z_{-} = 1.0$, the significand is $1.\\underbrace{000...00}_{23 \\text{ bits}}$. The LSB of the fraction, $f_{23}$, is $0$.\nFor $z_{+} = 1.0 + 2^{-23}$, the significand is $1.\\underbrace{000...01}_{23 \\text{ bits}}$. The LSB of the fraction, $f_{23}$, is $1$.\n\nThe \"even\" number is the one whose significand, when its trailing bit is considered, is even. This corresponds to the significand ending in a $0$. In our case, this is $z_{-}$.\nTherefore, according to the \"ties to even\" rule, the result of the rounding operation is $z_{-}$.\n\nThe final rounded result of the floating-point addition of $x+y$ is $1.0$.",
            "answer": "$$\n\\boxed{1.0}\n$$"
        },
        {
            "introduction": "In standard algebra, the identity $(a+b)-a = b$ is always true, but this is not the case in floating-point arithmetic. This final exercise demonstrates the critical phenomenon of 'swamping' or 'loss of significance,' where adding a very small number to a very large one can result in the smaller value being completely discarded . Understanding this common pitfall is essential for writing numerically stable and accurate code, especially when dealing with data of widely varying magnitudes.",
            "id": "3641990",
            "problem": "A software engineer writes a numerical kernel in compliance with the Institute of Electrical and Electronics Engineers (IEEE) Standard for Floating-Point Arithmetic (IEEE 754) binary32 (single precision), using the rounding mode \"round to nearest, ties to even.\" Let $\\operatorname{fl}(\\cdot)$ denote the floating-point result of a single operation in this format. Consider the computed quantity\n$$\ny \\;=\\; \\operatorname{fl}\\!\\left(\\,\\operatorname{fl}(a + b)\\;-\\;a\\,\\right),\n$$\nwhich mirrors a naive code pattern for residuals. The engineer notices that in real arithmetic $((a+b)-a)=b$, but in floating-point arithmetic this identity can fail.\n\nWork in the following model:\n- A normalized binary32 number has the form $x = (-1)^{s}\\,(1.f)_2\\,2^{E-127}$, where $s \\in \\{0,1\\}$, $f$ is a $23$-bit fraction, and $E \\in \\{1,2,\\dots,254\\}$ is the biased exponent. The precision is $p=24$ significant bits (including the implicit leading $1$).\n- The \"Unit in the Last Place (ULP)\" at a normalized magnitude $x$ with unbiased exponent $e$ is $\\operatorname{ulp}(x)=2^{e-(p-1)}$.\n- A single correctly rounded operation $\\operatorname{fl}(x \\circ y)$ for $\\circ \\in \\{+,-,\\times,\\div\\}$ returns the unique floating-point number nearest to the exact result, with ties broken toward the even significand.\n\nTasks:\n1. Starting from these definitions, derive an expression for $y$ in terms of $a$, $b$, and the rounding error of the single addition. Use only the definitions above and basic properties of exponent alignment in floating-point addition. Conclude a necessary and sufficient condition under which $y=b$ in this model, expressed in terms of exact representability of $a+b$ in binary32.\n2. Specialize your conclusion to the case where $a$ is a normalized number and $b$ has the same sign as $a$ and satisfies $|b| \\ll |a|$. Express your condition using $\\operatorname{ulp}(a)$ and explain its meaning in terms of the exponent alignment step of a floating-point adder.\n3. Now take $a=10^8$ and $b=1$, interpret these as real inputs to a binary32 computation, and evaluate the binary32 value of $y=\\operatorname{fl}(\\operatorname{fl}(a+b)-a)$ exactly. Your final answer must be a single real number. No rounding is required for the final answer.",
            "solution": "We begin from the core definitions of IEEE 754 binary32 (single precision) and the semantics of correctly rounded arithmetic. A normalized floating-point number has the form $x = (-1)^{s}\\,(1.f)_2\\,2^{E-127}$, with $p=24$ significant bits. The \"Unit in the Last Place (ULP)\" near a normalized $x$ with unbiased exponent $e$ is $\\operatorname{ulp}(x)=2^{e-(p-1)}=2^{e-23}$, which is the spacing between consecutive floating-point numbers in the binade defined by $e$.\n\nStep 1: Expressing $y$ via the rounding error of a single addition and a subtraction.\n\nLet us denote the exact real sum by $s = a+b$. By correct rounding to nearest, ties to even, there exists a rounding error $\\delta$ such that\n$$\n\\operatorname{fl}(a+b) \\;=\\; s + \\delta \\;=\\; a + b + \\delta,\n$$\nwith the constraint $|\\delta| \\le \\tfrac{1}{2}\\,\\operatorname{ulp}(s)$. For $|b|\\ll |a|$ and $a$ normalized, the binade of $s$ typically coincides with that of $a$ (no exponent overflow into the next binade), and then $|\\delta| \\le \\tfrac{1}{2}\\,\\operatorname{ulp}(a)$.\n\nThe computed quantity is\n$$\ny \\;=\\; \\operatorname{fl}\\!\\left(\\operatorname{fl}(a+b) - a\\right) \\;=\\; \\operatorname{fl}\\!\\left((a+b+\\delta)-a\\right) \\;=\\; \\operatorname{fl}\\!\\left(b+\\delta\\right).\n$$\nNow we use the well-known exactness property of subtraction in floating-point arithmetic when two floating-point numbers are within a factor of $2$ of each other. Specifically, by the Sterbenz lemma (a standard result derivable from exponent alignment and normalization), if $x$ and $y$ are floating-point and $\\tfrac{1}{2}\\le \\tfrac{x}{y}\\le 2$, then $x-y$ is exactly representable in the same format. In our setting, $\\operatorname{fl}(a+b)$ and $a$ are both floating-point numbers, and when $|b||a|$ they lie within a factor of $2$ of each other, so the subtraction $\\operatorname{fl}(a+b)-a$ is exact. Therefore,\n$$\ny \\;=\\; \\left(\\operatorname{fl}(a+b)\\right)-a \\;=\\; (a+b+\\delta)-a \\;=\\; b+\\delta.\n$$\nIt follows that $y=b$ if and only if $\\delta=0$, that is, if and only if $\\operatorname{fl}(a+b)=a+b$ (exact representability of the sum in binary32 with no rounding). This establishes the necessary and sufficient condition:\n$$\ny=b \\quad\\Longleftrightarrow\\quad a+b \\text{ is exactly representable in binary32}.\n$$\n\nStep 2: Specialization using $\\operatorname{ulp}(a)$ and exponent alignment.\n\nIn a binary adder, to compute $a+b$, the significands are aligned by shifting the significand of the operand with smaller unbiased exponent right by $d$ bit positions, where $d$ is the exponent difference. If $|b|\\ll |a|$ and $a$ and $b$ have the same sign, then after alignment, the contribution of $b$ to the sum at the scale of $a$ is effectively quantized on the $\\operatorname{ulp}(a)$ grid. Concretely, when $a$ remains in the same binade after addition, we have\n$$\n\\operatorname{ulp}(a)=2^{e-23}, \\quad \\text{where } e=\\lfloor \\log_{2}|a| \\rfloor,\n$$\nand the sum $a+b$ is exactly representable if and only if $b$ is an integer multiple of $\\operatorname{ulp}(a)$ and the addition does not cause a renormalization of the exponent to $e+1$. Equivalently, the rounding error $\\delta$ vanishes if and only if $b \\in \\operatorname{ulp}(a)\\,\\mathbb{Z}$ and $a+b$ stays in the binade with unbiased exponent $e$. Intuitively, this states that equality $y=b$ holds precisely when $b$ is \"scaled\" to the local grid defined by the spacing of representable numbers near $a$; if $b$ lies off that grid, alignment plus rounding forces a nonzero $\\delta$ and $y \\ne b$.\n\nStep 3: Computation for $a=10^8$ and $b=1$.\n\nWe now evaluate $y=\\operatorname{fl}(\\operatorname{fl}(a+b)-a)$ in binary32 for $a=10^8$ and $b=1$.\n\nFirst, determine the unbiased exponent $e$ of $a$:\n$$\n2^{26} \\;=\\; 67{,}108{,}864 \\;\\; 10^{8} \\;\\; 134{,}217{,}728 \\;=\\; 2^{27},\n$$\nso $e=\\lfloor \\log_{2}(10^{8}) \\rfloor = 26$. Hence the local spacing at $a$ is\n$$\n\\operatorname{ulp}(a) \\;=\\; 2^{e-23} \\;=\\; 2^{3} \\;=\\; 8.\n$$\nBecause $|b|=1\\tfrac{1}{2}\\operatorname{ulp}(a)=4$, the correctly rounded sum satisfies\n$$\n\\operatorname{fl}(a+b) \\;=\\; a \\quad\\text{(round to nearest, ties to even)}.\n$$\nThus the rounding error on the addition is $\\delta = \\operatorname{fl}(a+b) - (a+b) = a - (a+b) = -b = -1$. As established in Step 1, the subtraction is exact, yielding\n$$\ny \\;=\\; b+\\delta \\;=\\; 1+(-1) \\;=\\; 0.\n$$\nTherefore the computed value $y$ in binary32 is exactly $0$. This exhibits the counterexample in which $((a+b)-a)$ fails to equal $b$ because $b$ is not an integer multiple of $\\operatorname{ulp}(a)$ (here $\\operatorname{ulp}(a)=8$, and $b=1$ is not an integer multiple of $8$).",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}