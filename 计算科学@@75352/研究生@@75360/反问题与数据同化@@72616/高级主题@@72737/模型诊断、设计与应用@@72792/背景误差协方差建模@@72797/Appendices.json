{"hands_on_practices": [{"introduction": "在变分数据同化中，背景误差协方差矩阵 $B$ 不仅代表了我们对背景场先验知识的不确定性，还直接决定了最优化问题的数值特性。这个练习将通过一个简化的二维案例，引导你推导三维变分（3D-Var）目标函数的 Hessian 矩阵，并计算其条件数。通过这个实践 [@problem_id:3366744]，你将亲身体会到 $B$ 矩阵的结构如何影响数值求解的稳定性和效率。", "problem": "考虑一个二维状态向量 $x \\in \\mathbb{R}^{2}$ 的三维变分资料同化 (3D-Var) 目标函数，\n$$\nJ(x) = \\frac{1}{2}\\,(x - x_{b})^\\top B^{-1} (x - x_{b}) + \\frac{1}{2}\\,(y - H x)^\\top R^{-1} (y - H x),\n$$\n其中 $x_{b}$ 是背景场，$B$ 是背景误差协方差，$y$ 是观测值，$H$ 是线性观测算子，$R$ 是观测误差协方差。假设存在单个标量观测，其 $H = [\\,1\\ \\ 0\\,]$，$R = \\sigma_{o}^{2}$（一个正常数），且背景误差协方差为对角矩阵 $B = \\mathrm{diag}(\\lambda_{1}, \\lambda_{2})$，其中 $\\lambda_{1} > 0$ 且 $\\lambda_{2} > 0$。从 $J(x)$ 的此定义出发，推导其海森矩阵 $\\nabla^{2} J(x)$ 并计算其谱条件数，该条件数定义为最大特征值与最小特征值之比。请以 $\\lambda_{1}$、$\\lambda_{2}$ 和 $\\sigma_{o}^{2}$ 表示的闭式解析表达式给出您的最终答案。此外，请用文字解释 $\\lambda_{1}$ 和 $\\lambda_{2}$ 如何影响最小化 $J(x)$ 过程的数值稳定性，但最终报告的答案必须仅为条件数表达式。无需四舍五入，也不涉及任何单位。", "solution": "经评估，用户提供的问题是有效的。这是一个在资料同化领域内具有科学依据、适定且客观的问题。所有必要的数据和定义均已提供，且没有矛盾或含糊之处。因此，我们可以开始求解。\n\n对于一个状态向量 $x \\in \\mathbb{R}^{n}$，三维变分 (3D-Var) 目标函数由下式给出：\n$$\nJ(x) = \\frac{1}{2}\\,(x - x_{b})^\\top B^{-1} (x - x_{b}) + \\frac{1}{2}\\,(y - H x)^\\top R^{-1} (y - H x)\n$$\n这是关于 $x$ 的二次函数。为求海森矩阵，我们首先计算 $J(x)$ 关于 $x$ 的梯度。如果 $M$ 是对称矩阵，二次型 $\\frac{1}{2}(z-c)^\\top M(z-c)$ 关于 $z$ 的梯度是 $M(z-c)$。同样，$\\frac{1}{2}(d-Az)^\\top N(d-Az)$ 关于 $z$ 的梯度是 $-A^\\top N(d-Az) = A^\\top N(Az-d)$。\n背景项为 $J_b(x) = \\frac{1}{2}\\,(x - x_{b})^\\top B^{-1} (x - x_{b})$。其梯度为：\n$$\n\\nabla J_b(x) = B^{-1} (x - x_{b})\n$$\n观测项为 $J_o(x) = \\frac{1}{2}\\,(y - H x)^\\top R^{-1} (y - H x)$。其梯度为：\n$$\n\\nabla J_o(x) = -H^\\top R^{-1} (y - H x) = H^\\top R^{-1} (H x - y)\n$$\n总梯度 $\\nabla J(x)$ 是这两项之和：\n$$\n\\nabla J(x) = \\nabla J_b(x) + \\nabla J_o(x) = B^{-1} (x - x_{b}) + H^\\top R^{-1} (H x - y)\n$$\n海森矩阵 $\\nabla^2 J(x)$ 是通过将梯度对 $x^\\top$ 求导得到的。\n$$\n\\nabla^2 J(x) = \\frac{\\partial}{\\partial x^\\top} \\left( B^{-1} x - B^{-1} x_{b} + H^\\top R^{-1} H x - H^\\top R^{-1} y \\right)\n$$\n项 $-B^{-1} x_{b}$ 和 $-H^\\top R^{-1} y$ 关于 $x$ 是常数，因此它们的导数为零。$B^{-1}x$ 关于 $x^\\top$ 的导数是 $B^{-1}$。$(H^\\top R^{-1} H)x$ 关于 $x^\\top$ 的导数是 $H^\\top R^{-1} H$。\n因此，海森矩阵为：\n$$\n\\nabla^2 J(x) = B^{-1} + H^\\top R^{-1} H\n$$\n这是一个常数矩阵，这对于二次目标函数是预期的。我们将海森矩阵记为 $\\mathcal{H}$。\n\n现在，我们代入问题中给出的具体形式。状态向量为 $x \\in \\mathbb{R}^{2}$。\n背景误差协方差为 $B = \\mathrm{diag}(\\lambda_{1}, \\lambda_{2}) = \\begin{pmatrix} \\lambda_{1} & 0 \\\\ 0 & \\lambda_{2} \\end{pmatrix}$。其逆矩阵为：\n$$\nB^{-1} = \\begin{pmatrix} \\frac{1}{\\lambda_{1}} & 0 \\\\ 0 & \\frac{1}{\\lambda_{2}} \\end{pmatrix}\n$$\n观测算子为 $H = [\\,1\\ \\ 0\\,]$，所以其转置为 $H^\\top = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n观测误差协方差是标量 $R = \\sigma_{o}^{2}$，所以其逆为 $R^{-1} = \\frac{1}{\\sigma_{o}^{2}}$。\n\n我们计算项 $H^\\top R^{-1} H$：\n$$\nH^\\top R^{-1} H = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\frac{1}{\\sigma_{o}^{2}} [\\,1\\ \\ 0\\,] = \\frac{1}{\\sigma_{o}^{2}} \\begin{pmatrix} 1 \\cdot 1 & 1 \\cdot 0 \\\\ 0 \\cdot 1 & 0 \\cdot 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sigma_{o}^{2}} & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n海森矩阵 $\\mathcal{H}$ 是 $B^{-1}$ 与 $H^\\top R^{-1} H$ 的和：\n$$\n\\mathcal{H} = \\begin{pmatrix} \\frac{1}{\\lambda_{1}} & 0 \\\\ 0 & \\frac{1}{\\lambda_{2}} \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{\\sigma_{o}^{2}} & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\lambda_{1}} + \\frac{1}{\\sigma_{o}^{2}} & 0 \\\\ 0 & \\frac{1}{\\lambda_{2}} \\end{pmatrix}\n$$\n对角矩阵的特征值是其对角线上的元素。因此，海森矩阵 $\\mathcal{H}$ 的两个特征值为：\n$$\n\\mu_{1} = \\frac{1}{\\lambda_{1}} + \\frac{1}{\\sigma_{o}^{2}}\n$$\n$$\n\\mu_{2} = \\frac{1}{\\lambda_{2}}\n$$\n因为 $\\lambda_{1} > 0$，$\\lambda_{2} > 0$ 且 $\\sigma_{o}^{2} > 0$，所以两个特征值 $\\mu_1$ 和 $\\mu_2$ 都是正的，这证实了海森矩阵是正定的，并且目标函数 $J(x)$ 有唯一的最小值。\n\n谱条件数 $\\kappa(\\mathcal{H})$ 定义为最大特征值与最小特征值之比。\n$$\n\\kappa(\\mathcal{H}) = \\frac{\\lambda_{\\text{max}}}{\\lambda_{\\text{min}}} = \\frac{\\max(\\mu_{1}, \\mu_{2})}{\\min(\\mu_{1}, \\mu_{2})}\n$$\n代入 $\\mu_{1}$ 和 $\\mu_{2}$ 的表达式，我们得到条件数的最终表达式：\n$$\n\\kappa(\\mathcal{H}) = \\frac{\\max\\left(\\frac{1}{\\lambda_{1}} + \\frac{1}{\\sigma_{o}^{2}}, \\frac{1}{\\lambda_{2}}\\right)}{\\min\\left(\\frac{1}{\\lambda_{1}} + \\frac{1}{\\sigma_{o}^{2}}, \\frac{1}{\\lambda_{2}}\\right)}\n$$\n\n关于 $\\lambda_{1}$ 和 $\\lambda_{2}$ 对数值稳定性的影响：\n海森矩阵的条件数是用于寻找 $J(x)$ 的最小值的迭代优化算法（如梯度下降法）收敛速率的关键因素。大的条件数意味着一个病态问题，其中 $J(x)$ 的等值线被高度拉长，导致收敛缓慢。接近1的条件数意味着一个良态问题，其等值线近似圆形且收敛速度快。\n\n参数 $\\lambda_{1}$ 和 $\\lambda_{2}$ 代表背景误差的方差，对应于状态向量的两个分量。它们量化了背景场 $x_b$ 的不确定性。它们的值直接影响特征值 $\\mu_1 = 1/\\lambda_1 + 1/\\sigma_o^2$ 和 $\\mu_2 = 1/\\lambda_2$。\n如果 $\\mu_1$ 和 $\\mu_2$ 的量级存在显著差异，条件数会变大。\n- $\\lambda_1$ 或 $\\lambda_2$ 的一个非常小的值对应于对背景场相应分量的高度信任。这导致 $1/\\lambda_1$ 或 $1/\\lambda_2$ 的值非常大，从而增加了相应特征值（$\\mu_1$ 或 $\\mu_2$）的量级。\n- 相反地，$\\lambda_1$ 或 $\\lambda_2$ 的一个大的值（低信任度）会使相应的倒数项变小。\n病态条件，以及因此导致的差的数值稳定性，会在状态空间中不确定性的尺度差异很大时出现。例如，如果 $\\lambda_1$ 非常大（对状态分量1的背景约束弱）而 $\\lambda_2$ 非常小（对状态分量2的背景约束强），那么 $\\mu_1 \\approx 1/\\sigma_o^2$ 而 $\\mu_2 = 1/\\lambda_2$ 会非常大。这会导致一个大的条件数 $\\kappa \\approx \\mu_2/\\mu_1$。类似地，如果 $\\lambda_1$ 非常小，$\\mu_1$ 会变得非常大，而如果选择的 $\\lambda_2$ 使得 $\\mu_2$ 相对较小（例如 $\\lambda_2$ 较大），条件数同样会很大。\n本质上，背景误差方差 $\\lambda_1$ 和 $\\lambda_2$ 之间的巨大不匹配可以在海森矩阵的特征值中产生显著的差异，从而导致一个病态的优化问题并损害数值稳定性。", "answer": "$$\n\\boxed{\\frac{\\max\\left(\\frac{1}{\\lambda_{1}} + \\frac{1}{\\sigma_{o}^{2}}, \\frac{1}{\\lambda_{2}}\\right)}{\\min\\left(\\frac{1}{\\lambda_{1}} + \\frac{1}{\\sigma_{o}^{2}}, \\frac{1}{\\lambda_{2}}\\right)}}\n$$", "id": "3366744"}, {"introduction": "理论上构建的背景和观测误差协方差矩阵（$B$ 和 $R$）在实际应用中是否恰当？Desroziers 诊断法提供了一套强大的事后检验工具，利用新息（innovation）和分析残差（analysis residual）的统计特性来评估和调整这些协方差矩阵。这个练习 [@problem_id:3366745] 将模拟一个真实场景，你将使用给定的样本数据，通过最小二乘法来估计协方差模型的标量乘子，从而掌握一种实用的协方差调优方法。", "problem": "考虑一个线性高斯数据同化设定，其中包含一个线性观测算子 $H \\in \\mathbb{R}^{p \\times n}$，以及背景误差和观测误差协方差矩阵分别为 $B \\in \\mathbb{R}^{n \\times n}$ 和 $R \\in \\mathbb{R}^{p \\times p}$。新息定义为 $v = y - H x^{b}$，分析残差定义为 $w = y - H x^{a}$。在 Desroziers 诊断的框架中，使用以下经过充分检验的关系式将新息和分析残差的二阶统计量与误差协方差联系起来：新息的二阶矩近似于 $H B H^\\top + R$，分析残差与新息的交叉二阶矩近似于 $R$。假设实际误差协方差被建模为给定模板的标量倍数，即 $B = \\alpha B_{0}$ 和 $R = \\beta R_{0}$，其中 $\\alpha, \\beta \\in \\mathbb{R}$ 是未知标量，$B_{0}$ 和 $R_{0}$ 是已知的对称正定模板。\n\n令观测维度为 $p = 2$，观测算子为 $H = I_{2}$，即 $2 \\times 2$ 单位矩阵。令协方差模板为\n$$\nB_{0} = \\begin{pmatrix} 3 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\qquad R_{0} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}.\n$$\n给定 $m = 4$ 组新息和分析残差的配对样本 $\\{(v_{i}, w_{i})\\}_{i=1}^{4}$，其中\n$$\nv_{1} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\quad v_{2} = \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix}, \\quad v_{3} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}, \\quad v_{4} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix},\n$$\n$$\nw_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad w_{2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad w_{3} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad w_{4} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\n构建样本二阶矩矩阵\n$$\nS_{vv} = \\frac{1}{m} \\sum_{i=1}^{m} v_{i} v_{i}^\\top, \\qquad S_{wv} = \\frac{1}{m} \\sum_{i=1}^{m} w_{i} v_{i}^\\top.\n$$\n使用 Desroziers 关系式作为建模基础，通过最小化弗罗贝尼乌斯范数残差的平方和，以最小二乘意义确定最能同时满足这两个关系式的标量 $\\alpha$ 和 $\\beta$\n$$\nJ(\\alpha, \\beta) = \\left\\| S_{vv} - H (\\alpha B_{0}) H^\\top - \\beta R_{0} \\right\\|_{F}^{2} + \\left\\| S_{wv} - \\beta R_{0} \\right\\|_{F}^{2},\n$$\n其中 $\\| X \\|_{F}^{2} = \\operatorname{tr}(X^\\top X)$。计算最小化 $J(\\alpha, \\beta)$ 的 $\\alpha$ 和 $\\beta$ 的精确值，并将您的最终答案表示为一个分别包含 $\\alpha$ 和 $\\beta$ 的 $1 \\times 2$ 行矩阵。无需四舍五入，不涉及单位。", "solution": "我们从线性高斯数据同化设定和 Desroziers 诊断开始，它们提供了新息和分析残差的二阶统计量与误差协方差之间经过充分检验的关系。具体来说，在正确的设定和线性假设下，新息的二阶矩满足 $\\mathbb{E}[v v^\\top] \\approx H B H^\\top + R$，分析残差与新息之间的交叉二阶矩满足 $\\mathbb{E}[w v^\\top] \\approx R$。当使用应用于已知模板 $B_{0}$ 和 $R_{0}$ 的标量乘子建模 $B = \\alpha B_{0}$ 和 $R = \\beta R_{0}$ 时，这些关系建议拟合\n$$\nS_{vv} \\approx H (\\alpha B_{0}) H^\\top + \\beta R_{0}, \\qquad S_{wv} \\approx \\beta R_{0},\n$$\n在弗罗贝尼乌斯范数的最小二乘意义下，得到目标函数\n$$\nJ(\\alpha, \\beta) = \\left\\| S_{vv} - \\alpha A - \\beta R_{0} \\right\\|_{F}^{2} + \\left\\| S_{wv} - \\beta R_{0} \\right\\|_{F}^{2},\n$$\n其中 $A = H B_{0} H^\\top$。在本问题中，$H = I_{2}$，因此 $A = B_{0}$。\n\n步骤 1：根据提供的数据计算样本二阶矩矩阵 $S_{vv}$ 和 $S_{wv}$。\n\n对于 $S_{vv}$，计算每个 $v_{i} v_{i}^\\top$：\n$$\nv_{1} v_{1}^\\top = \\begin{pmatrix} 4 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\quad\nv_{2} v_{2}^\\top = \\begin{pmatrix} 0 & 0 \\\\ 0 & 4 \\end{pmatrix}, \\quad\nv_{3} v_{3}^\\top = \\begin{pmatrix} 4 & 4 \\\\ 4 & 4 \\end{pmatrix}, \\quad\nv_{4} v_{4}^\\top = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}.\n$$\n求和并除以 $m = 4$ 得\n$$\nS_{vv} = \\frac{1}{4} \\left( \\begin{pmatrix} 4 & 0 \\\\ 0 & 0 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 4 \\end{pmatrix} + \\begin{pmatrix} 4 & 4 \\\\ 4 & 4 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} \\right)\n= \\frac{1}{4} \\begin{pmatrix} 8 & 4 \\\\ 4 & 8 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}.\n$$\n对于 $S_{wv}$，计算每个 $w_{i} v_{i}^\\top$：\n$$\nw_{1} v_{1}^\\top = \\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\quad\nw_{2} v_{2}^\\top = \\begin{pmatrix} 0 & 0 \\\\ 0 & 2 \\end{pmatrix}, \\quad\nw_{3} v_{3}^\\top = \\begin{pmatrix} 2 & 2 \\\\ 2 & 2 \\end{pmatrix}, \\quad\nw_{4} v_{4}^\\top = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}.\n$$\n求和并除以 $m = 4$ 得\n$$\nS_{wv} = \\frac{1}{4} \\left( \\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 2 \\end{pmatrix} + \\begin{pmatrix} 2 & 2 \\\\ 2 & 2 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} \\right)\n= \\frac{1}{4} \\begin{pmatrix} 4 & 2 \\\\ 2 & 4 \\end{pmatrix} = \\begin{pmatrix} 1 & \\frac{1}{2} \\\\ \\frac{1}{2} & 1 \\end{pmatrix}.\n$$\n\n步骤 2：设 $A = H B_{0} H^\\top = B_{0} = \\begin{pmatrix} 3 & 1 \\\\ 1 & 2 \\end{pmatrix}$ 且 $R_{0} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}$。引入弗罗贝尼乌斯内积 $\\langle X, Y \\rangle = \\operatorname{tr}(X^\\top Y)$，因此 $\\| X \\|_{F}^{2} = \\langle X, X \\rangle$。目标函数可以展开为\n$$\nJ(\\alpha, \\beta) = \\left\\langle S_{vv} - \\alpha A - \\beta R_{0},\\, S_{vv} - \\alpha A - \\beta R_{0} \\right\\rangle + \\left\\langle S_{wv} - \\beta R_{0},\\, S_{wv} - \\beta R_{0} \\right\\rangle.\n$$\n对 $\\alpha$ 和 $\\beta$ 求导并将梯度设为零，得到最小二乘最小化量的正规方程组：\n$$\n\\frac{\\partial J}{\\partial \\alpha} = -2 \\langle S_{vv}, A \\rangle + 2 \\alpha \\langle A, A \\rangle + 2 \\beta \\langle A, R_{0} \\rangle = 0,\n$$\n$$\n\\frac{\\partial J}{\\partial \\beta} = -2 \\langle S_{vv}, R_{0} \\rangle + 2 \\alpha \\langle A, R_{0} \\rangle + 2 \\beta \\langle R_{0}, R_{0} \\rangle - 2 \\langle S_{wv}, R_{0} \\rangle + 2 \\beta \\langle R_{0}, R_{0} \\rangle = 0.\n$$\n将两个方程都除以 2，得到 $2 \\times 2$ 线性系统\n$$\n\\alpha \\langle A, A \\rangle + \\beta \\langle A, R_{0} \\rangle = \\langle S_{vv}, A \\rangle,\n$$\n$$\n\\alpha \\langle A, R_{0} \\rangle + 2 \\beta \\langle R_{0}, R_{0} \\rangle = \\langle S_{vv}, R_{0} \\rangle + \\langle S_{wv}, R_{0} \\rangle.\n$$\n\n步骤 3：计算所需的内积。\n首先，计算 $\\langle A, A \\rangle$：\n$$\n\\langle A, A \\rangle = 3^{2} + 1^{2} + 1^{2} + 2^{2} = 9 + 1 + 1 + 4 = 15.\n$$\n接下来，计算 $\\langle A, R_{0} \\rangle$：\n$$\n\\langle A, R_{0} \\rangle = 3 \\cdot 1 + 1 \\cdot 0 + 1 \\cdot 0 + 2 \\cdot 2 = 3 + 0 + 0 + 4 = 7.\n$$\n计算 $\\langle S_{vv}, A \\rangle$：\n$$\n\\langle S_{vv}, A \\rangle = 2 \\cdot 3 + 1 \\cdot 1 + 1 \\cdot 1 + 2 \\cdot 2 = 6 + 1 + 1 + 4 = 12.\n$$\n计算 $\\langle R_{0}, R_{0} \\rangle$：\n$$\n\\langle R_{0}, R_{0} \\rangle = 1^{2} + 0^{2} + 0^{2} + 2^{2} = 1 + 0 + 0 + 4 = 5.\n$$\n计算 $\\langle S_{vv}, R_{0} \\rangle$：\n$$\n\\langle S_{vv}, R_{0} \\rangle = 2 \\cdot 1 + 1 \\cdot 0 + 1 \\cdot 0 + 2 \\cdot 2 = 2 + 0 + 0 + 4 = 6.\n$$\n计算 $\\langle S_{wv}, R_{0} \\rangle$：\n$$\n\\langle S_{wv}, R_{0} \\rangle = 1 \\cdot 1 + \\frac{1}{2} \\cdot 0 + \\frac{1}{2} \\cdot 0 + 1 \\cdot 2 = 1 + 0 + 0 + 2 = 3.\n$$\n\n步骤 4：解线性系统\n$$\n15 \\alpha + 7 \\beta = 12, \\qquad 7 \\alpha + 10 \\beta = 9.\n$$\n求解 $\\alpha$ 和 $\\beta$。将第一个方程乘以 $10$，第二个方程乘以 $7$：\n$$\n150 \\alpha + 70 \\beta = 120, \\qquad 49 \\alpha + 70 \\beta = 63.\n$$\n第一个方程减去第二个方程：\n$$\n(150 - 49) \\alpha = 120 - 63 \\quad \\Rightarrow \\quad 101 \\alpha = 57 \\quad \\Rightarrow \\quad \\alpha = \\frac{57}{101}.\n$$\n代入 $7 \\alpha + 10 \\beta = 9$：\n$$\n10 \\beta = 9 - 7 \\alpha = 9 - 7 \\cdot \\frac{57}{101} = \\frac{909 - 399}{101} = \\frac{510}{101},\n$$\n因此\n$$\n\\beta = \\frac{51}{101}.\n$$\n\n这些精确的有理数值最小化了指定的最小二乘目标函数，并为在给定设置中与 Desroziers 关系一致的 $B$ 和 $R$ 提供了标量乘子。", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{57}{101} & \\frac{51}{101}\\end{pmatrix}}$$", "id": "3366745"}]}