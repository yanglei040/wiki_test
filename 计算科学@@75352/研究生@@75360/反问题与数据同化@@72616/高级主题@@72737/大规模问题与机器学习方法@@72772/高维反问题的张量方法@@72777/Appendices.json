{"hands_on_practices": [{"introduction": "在高维问题中，许多线性算子（例如，在张量积网格上离散化的偏微分方程）天然具有可分离结构，通常可以表示为克罗内克积（Kronecker product）。本练习旨在建立这种常见算子结构与强大的张量链（Tensor Train, TT）格式之间的桥梁。通过亲手为克罗内克积算子构建其张量链表示 [@problem_id:3424557]，您将从根本上理解为何这类高维算子是可压缩的，并证明其张量链秩（TT-rank）非常小，这为后续的高效计算奠定了基础。", "problem": "考虑一个可分的高维逆问题中的线性正演算子，其形式为克罗内克积 $A = A_1 \\otimes \\cdots \\otimes A_d$，其中每个 $A_k \\in \\mathbb{R}^{m_k \\times n_k}$。这类算子出现在具有可分先验和似然的高斯贝叶斯数据同化中，以及在张量积网格上的偏微分方程离散化中。你将证明该算子允许使用张量链 (TT) 矩阵格式表示，并仅使用核心定义来量化其 TT 秩。\n\n从以下基本定义出发：\n- 克罗内克积的定义：对于 $B \\in \\mathbb{R}^{p \\times q}$ 和 $C \\in \\mathbb{R}^{r \\times s}$，克罗内克积 $B \\otimes C \\in \\mathbb{R}^{pr \\times qs}$ 满足 $(B \\otimes C)_{(i-1)r+\\alpha,(j-1)s+\\beta} = B_{ij} C_{\\alpha \\beta}$。\n- 张量链矩阵 (TT-matrix) 的定义：一个矩阵 $A \\in \\mathbb{R}^{(m_1 \\cdots m_d) \\times (n_1 \\cdots n_d)}$ 处于 TT 矩阵格式，如果存在四阶核心张量 $G^{(k)} \\in \\mathbb{R}^{r_{k-1} \\times m_k \\times n_k \\times r_k}$，其中 $r_0 = r_d = 1$，使得对于多重索引 $i = (i_1,\\dots,i_d)$ 和 $j = (j_1,\\dots,j_d)$，\n$$\nA_{i,j} \\;=\\; \\sum_{\\alpha_0,\\dots,\\alpha_d} G^{(1)}_{\\alpha_0,i_1,j_1,\\alpha_1} \\cdots G^{(d)}_{\\alpha_{d-1},i_d,j_d,\\alpha_d},\n$$\n其中求和遍历 $\\alpha_0 = 1$ 和 $\\alpha_d = 1$，$r_k$ 是 TT 秩。\n\n任务：\n1. 仅使用这些定义以及矩阵秩和克罗内克积的标准性质，为 $A = A_1 \\otimes \\cdots \\otimes A_d$ 构建一个 TT 矩阵表示，并根据因子 $A_k$ 的经典矩阵秩证明每个 TT 秩 $r_s$ 的先验界。你的论证不得假设因子存在任何预先的 TT 表示，并且必须通过将 $A$ 等同于一个 $2d$ 阶张量并分析其秩（等于 TT 秩）的适当矩阵化来进行。\n2. 特化到每个 $A_k$ 都是对角矩阵的情况，即 $(A_k)_{i_k j_k} = a^{(k)}_{i_k} \\,\\delta_{i_k j_k}$，其中对角线元素为 $a^{(k)}_{1},\\dots,a^{(k)}_{n_k}$，$\\delta_{i_k j_k}$ 是克罗内克 δ。显式计算 TT 矩阵核心张量，即给出非零核心张量元素 $G^{(k)}_{1,i_k,j_k,1}$ 的闭式表达式，该表达式在 TT 收缩下能精确地重现 $A$。\n\n答案规格：\n- 在对角情况下，以 $a^{(k)}_{i_k}$ 和 $\\delta_{i_k j_k}$ 表示的 TT 核心张量元素 $G^{(k)}_{1,i_k,j_k,1}$ 的单一解析表达式的形式提供你的最终答案。\n- 不需要进行数值舍入。\n- 不要包含单位。", "solution": "该问题被评估为有效，因为它具有科学依据、问题明确、客观且内部一致。它提出了一个数值线性代数和张量方法中的标准、可验证的问题。\n\n按要求，该问题分两部分进行解答。\n\n**第一部分：通用 TT 矩阵表示和秩界**\n\n令 $A = A_1 \\otimes \\cdots \\otimes A_d$ 为正演算子，其中每个 $A_k \\in \\mathbb{R}^{m_k \\times n_k}$。矩阵 $A$ 的维度为 $(\\prod_{k=1}^d m_k) \\times (\\prod_{k=1}^d n_k)$。$A$ 的一个元素由一个行多重索引 $i = (i_1, \\dots, i_d)$ 和一个列多重索引 $j = (j_1, \\dots, j_d)$ 索引，其中 $1 \\le i_k \\le m_k$ 且 $1 \\le j_k \\le n_k$。克罗内克积的定义意味着元素 $A_{i,j}$ 由因子矩阵的相应元素的乘积给出：\n$$\nA_{i,j} = \\prod_{k=1}^d (A_k)_{i_k, j_k}\n$$\n问题要求为 $A$ 构建一个张量链 (TT) 矩阵表示，并找到其 TT 秩的一个界。如果一个矩阵 $A$ 的元素可以表示为以下形式，则该矩阵处于 TT 矩阵格式：\n$$\nA_{i,j} = G^{(1)}(i_1, j_1) G^{(2)}(i_2, j_2) \\cdots G^{(d)}(i_d, j_d)\n$$\n其中 $G^{(k)}(i_k, j_k)$ 是一个大小为 $r_{k-1} \\times r_k$ 的矩阵，其元素为 $(G^{(k)}(i_k, j_k))_{\\alpha_{k-1}, \\alpha_k} = G^{(k)}_{\\alpha_{k-1}, i_k, j_k, \\alpha_k}$。对于 $k=1, \\dots, d-1$ 的标量 $r_k$ 是 TT 秩，边界秩固定为 $r_0=r_d=1$。\n\n矩阵 $A$ 的第 $s$ 个 TT 秩 $r_s$ 定义为其第 $s$ 次矩阵化（表示为 $\\mathbf{A}_{(s)}$）的秩。这次矩阵化是通过将矩阵 $A$ 等同于一个大小为 $(m_1 n_1) \\times \\dots \\times (m_d n_d)$ 的 $d$ 阶张量 $\\mathcal{T}$ 获得的，其元素为 $\\mathcal{T}_{(i_1,j_1), \\dots, (i_d,j_d)} = A_{i,j}$。矩阵 $\\mathbf{A}_{(s)}$ 是 $\\mathcal{T}$ 的展开，它将前 $s$ 个模与其余 $d-s$ 个模分组。\n\n矩阵 $\\mathbf{A}_{(s)}$ 的维度为 $(\\prod_{k=1}^s m_k n_k) \\times (\\prod_{k=s+1}^d m_k n_k)$。其行由多重索引 $((i_1,j_1), \\dots, (i_s,j_s))$ 索引，列由 $((i_{s+1},j_{s+1}), \\dots, (i_d,j_d))$ 索引。该矩阵的一个元素由下式给出：\n$$\n(\\mathbf{A}_{(s)})_{\\left((i_1,j_1), \\dots, (i_s,j_s)\\right), \\left((i_{s+1},j_{s+1}), \\dots, (i_d,j_d)\\right)} = A_{i,j} = \\left(\\prod_{k=1}^s (A_k)_{i_k, j_k}\\right) \\left(\\prod_{k=s+1}^d (A_k)_{i_k, j_k}\\right)\n$$\n这种结构表明矩阵 $\\mathbf{A}_{(s)}$ 是两个向量 $u \\in \\mathbb{R}^{\\prod_{k=1}^s m_k n_k}$ 和 $v \\in \\mathbb{R}^{\\prod_{k=s+1}^d m_k n_k}$ 的外积。这些向量的分量是：\n$$\nu_{(i_1,j_1), \\dots, (i_s,j_s)} = \\prod_{k=1}^s (A_k)_{i_k, j_k}\n$$\n$$\nv_{(i_{s+1},j_{s+1}), \\dots, (i_d,j_d)} = \\prod_{k=s+1}^d (A_k)_{i_k, j_k}\n$$\n这些向量可以被识别为相应部分克罗内克积的向量化形式，即 $u = \\mathrm{vec}(A_1 \\otimes \\cdots \\otimes A_s)$ 和 $v = \\mathrm{vec}(A_{s+1} \\otimes \\cdots \\otimes A_d)$。\n因此，矩阵 $\\mathbf{A}_{(s)}$ 由 $\\mathbf{A}_{(s)} = u v^T$ 给出。两个向量外积的秩最多为 $1$。如果 $u$ 和 $v$ 都不是零向量（即，如果没有任何矩阵 $A_k$ 是零矩阵），则秩恰好为 $1$。因此，第 $s$ 个 TT 秩是：\n$$\nr_s = \\mathrm{rank}(\\mathbf{A}_{(s)}) \\le 1\n$$\n这对所有 $s=1, \\dots, d-1$ 提供了先验界 $r_s \\le 1$。这个界是最紧的，并且由于是常数，它不依赖于因子 $A_k$ 的经典矩阵秩。\n\n当所有 TT 秩都为 $1$ 时（即 $r_0=r_1=\\dots=r_d=1$），TT 核心张量 $G^{(k)}$ 是大小为 $1 \\times m_k \\times n_k \\times 1$ 的张量。TT 矩阵乘积简化为标量积：\n$$\nA_{i,j} = G^{(1)}_{1,i_1,j_1,1} \\, G^{(2)}_{1,i_2,j_2,1} \\cdots G^{(d)}_{1,i_d,j_d,1}\n$$\n为了构建该表示，我们可以选择核心张量的元素为因子矩阵本身的元素：\n$$\nG^{(k)}_{1,i_k,j_k,1} = (A_k)_{i_k, j_k}\n$$\n通过这种选择，乘积变为 $\\prod_{k=1}^d (A_k)_{i_k, j_k}$，这正是 $A_{i,j}$ 的表达式。这为 TT 表示提供了一个构造性证明，并证实了秩界。\n\n**第二部分：特化为对角因子**\n\n我们考虑每个因子矩阵 $A_k$ 都是对角矩阵的特殊情况：\n$$\n(A_k)_{i_k, j_k} = a^{(k)}_{i_k} \\delta_{i_k, j_k}\n$$\n其中 $a^{(k)}_{i_k}$ 是对角线元素，$\\delta_{i_k,j_k}$ 是克罗内克 δ。\n\n为了找到这种情况下 TT 矩阵核心张量的显式形式，我们使用第一部分中推导的通用构造。秩全为 $1$，核心张量的元素由因子矩阵的元素给出。将 $(A_k)_{i_k, j_k}$ 的具体形式代入我们的通用核心张量定义，得到：\n$$\nG^{(k)}_{1,i_k,j_k,1} = a^{(k)}_{i_k} \\delta_{i_k,j_k}\n$$\n该表达式为大小为 $1 \\times m_k \\times n_k \\times 1$ 的 TT 核心张量提供了元素。核心张量 $G^{(k)}$ 是一个对角的“矩阵之矩阵”，其中对于每个 $i_k \\ne j_k$ 的 $(i_k, j_k)$，元素为 $0$；对于 $i_k = j_k$，元素为 $a^{(k)}_{i_k}$。这就是所要求的闭式表达式。", "answer": "$$\n\\boxed{a^{(k)}_{i_k} \\delta_{i_k, j_k}}\n$$", "id": "3424557"}, {"introduction": "在了解了如何用紧凑的张量格式表示高维算子之后，一个自然的问题是：这种表示在计算上究竟有何优势？本练习将探讨一个常作为逆问题正则化项出现的克罗内克和（Kronecker sum）算子。您的任务是分析将该算子作用于一个以张量链格式表示的向量所需的浮点运算（flop）次数 [@problem_id:3424565]，从而精确地量化计算收益。这个练习将具体展示张量方法如何有效避免“维度灾难”，将指数复杂度的计算缩减为线性复杂度。", "problem": "考虑一个高维贝叶斯逆问题，其中张量化的参数场上的负对数先验精度算子是一个克罗内克和\n$$\n\\mathcal{L} \\;=\\; \\sum_{k=1}^{d} I \\otimes \\cdots \\otimes L_k \\otimes \\cdots \\otimes I,\n$$\n其中每个 $L_k \\in \\mathbb{R}^{n_k \\times n_k}$ 是一个作用于模态 $k$ 的稠密矩阵，而 $I$ 表示适当大小的单位矩阵。参数向量 $x$ 以张量链 (TT) 格式表示，其核为 $\\mathcal{X}^{(k)} \\in \\mathbb{R}^{r_{k-1} \\times n_k \\times r_k}$（对于 $k \\in \\{1,\\ldots,d\\}$），边界秩为 $r_0 = r_d = 1$。您可以假设采用标准浮点运算 (flop) 模型，其中每次标量加法或乘法计为一次浮点运算。\n\n从克罗内克和、张量链格式以及基本稠密矩阵-向量乘法成本的定义出发，通过将每个 $L_k$ 与 $x$ 的模态-$k$ 纤维进行缩并，推导计算作用 $y = \\mathcal{L} x$ 所需总浮点运算次数的闭式表达式。忽略将 $d$ 个贡献项相加的成本、任何张量链舍入或重压缩的成本，以及与应用单位矩阵相关的任何成本。您的答案应仅用 $\\{n_k\\}_{k=1}^{d}$ 和 $\\{r_k\\}_{k=0}^{d}$ 表示，并以单一解析公式的形式给出最终表达式。无需进行数值计算，也不涉及单位。最终答案必须是单一的解析表达式。", "solution": "问题要求计算克罗内克和算子 $\\mathcal{L}$ 作用于以张量链 (TT) 格式表示的向量 $x$ 的总浮点运算 (flop) 次数。我们已知算子的结构和向量的表示形式，并且必须基于基本计算步骤推导出成本。\n\n首先，我们分析计算 $y = \\mathcal{L}x$ 的结构。算子 $\\mathcal{L}$ 是 $d$ 个算子的和：\n$$\n\\mathcal{L} \\;=\\; \\sum_{k=1}^{d} \\mathcal{L}_k, \\quad \\text{其中} \\quad \\mathcal{L}_k \\;=\\; I \\otimes \\cdots \\otimes I \\otimes L_k \\otimes I \\otimes \\cdots \\otimes I\n$$\n在 $\\mathcal{L}_k$ 的表达式中，矩阵 $L_k \\in \\mathbb{R}^{n_k \\times n_k}$ 位于克罗内克积的第 $k$ 个位置，所有其他矩阵都是适当大小的单位矩阵 $I$。\n\n因此，总计算为 $y = \\sum_{k=1}^{d} \\mathcal{L}_k x$。问题陈述指示我们忽略将 $d$ 个结果项相加的成本。因此，总浮点运算次数是计算每个项 $y_k = \\mathcal{L}_k x$ (对于 $k = 1, \\ldots, d$) 的成本之和。设 $C_k$ 为计算 $y_k$ 的成本。那么总成本 $C_{\\text{total}}$ 为：\n$$\nC_{\\text{total}} = \\sum_{k=1}^{d} C_k\n$$\n\n接下来，我们确定单个项 $y_k = \\mathcal{L}_k x$ 的成本 $C_k$。向量 $x$ 以 TT 格式给出，其核为 $\\mathcal{X}^{(j)} \\in \\mathbb{R}^{r_{j-1} \\times n_j \\times r_j}$ (对于 $j=1, \\ldots, d$) 。算子 $\\mathcal{L}_k$ 在除第 $k$ 阶模态之外的所有模态上都作为单位算子，而在第 $k$ 阶模态上应用稠密矩阵 $L_k$。TT 格式的一个关键性质是，这种模态-$k$ 操作可以通过仅修改第 $k$ 个 TT 核 $\\mathcal{X}^{(k)}$ 来执行。结果张量 $y_k$ 将具有 TT 核 $\\mathcal{Y}^{(j)}$，其中对于所有 $j \\neq k$，$\\mathcal{Y}^{(j)} = \\mathcal{X}^{(j)}$。问题陈述中要求忽略与应用单位矩阵相关的成本，这使得这一观察正式化。\n\n计算 $y_k$ 所需的唯一计算工作是计算新的第 $k$ 个核，我们将其表示为 $\\mathcal{Y}^{(k)}$。这是通过沿着物理模态（核的第二模态，大小为 $n_k$）将核 $\\mathcal{X}^{(k)}$ 与矩阵 $L_k$ 进行缩并来实现的。核 $\\mathcal{X}^{(k)}$ 是一个三维张量，其元素为 $(\\mathcal{X}^{(k)})_{i,j,p}$，其中索引范围为 $i \\in \\{1, \\ldots, r_{k-1}\\}$，$j \\in \\{1, \\ldots, n_k\\}$ 和 $p \\in \\{1, \\ldots, r_k\\}$。矩阵 $L_k$ 的元素为 $(L_k)_{m,j}$。结果核 $\\mathcal{Y}^{(k)}$ 的元素由以下缩并给出：\n$$\n(\\mathcal{Y}^{(k)})_{i,m,p} = \\sum_{j=1}^{n_k} (L_k)_{m,j} (\\mathcal{X}^{(k)})_{i,j,p}\n$$\n此操作必须对索引 $i$、$m$ 和 $p$ 的所有组合执行。\n\n让我们分析一下此缩并的浮点运算次数。对于每个固定的索引对 $(i, p)$，该操作等效于一次矩阵-向量乘法。向量是长度为 $n_k$ 的模态-2 纤维 $(\\mathcal{X}^{(k)})_{i,:,p}$，矩阵是 $L_k \\in \\mathbb{R}^{n_k \\times n_k}$。一个稠密的 $n_k \\times n_k$ 矩阵与一个长度为 $n_k$ 的向量相乘的成本是 $n_k^2$ 次乘法和 $n_k(n_k-1)$ 次加法。根据问题的浮点运算模型（每次加法或乘法计为一次浮点运算），每次这样的矩阵-向量乘积的成本为 $n_k^2 + (n_k^2 - n_k) = 2n_k^2 - n_k$ 次浮点运算。\n\n另外，我们可以计算每个元素 $(\\mathcal{Y}^{(k)})_{i,m,p}$ 的浮点运算次数。求和 $\\sum_{j=1}^{n_k} (L_k)_{m,j} (\\mathcal{X}^{(k)})_{i,j,p}$ 涉及 $n_k$ 次乘法和 $n_k-1$ 次加法。这需要每个输出核元素总共 $n_k + (n_k-1) = 2n_k - 1$ 次浮点运算。输出核 $\\mathcal{Y}^{(k)}$（其维度 $r_{k-1} \\times n_k \\times r_k$ 与输入核相同）中的元素总数为 $r_{k-1} n_k r_k$。因此，总成本 $C_k$ 为：\n$$\nC_k = (r_{k-1} n_k r_k) \\times (2n_k - 1) = (2n_k^2 - n_k) r_{k-1} r_k\n$$\n这证实了从矩阵-向量乘积角度推导出的成本，因为需要计算 $r_{k-1}r_k$ 个这样的乘积。\n\n最后，为了求得总浮点运算次数 $C_{\\text{total}}$，我们将所有模态 $k=1$ 到 $d$ 的成本 $C_k$ 相加：\n$$\nC_{\\text{total}} = \\sum_{k=1}^{d} C_k = \\sum_{k=1}^{d} (2n_k^2 - n_k) r_{k-1} r_k\n$$\n边界秩给定为 $r_0=1$ 和 $r_d=1$。求和式正确地将这些值用于 $k=1$ 和 $k=d$ 的项。该公式表示了在指定条件下的完整浮点运算次数。它也可以写成 $\\sum_{k=1}^{d} n_k(2n_k-1)r_{k-1}r_k$。", "answer": "$$\n\\boxed{\\sum_{k=1}^{d} (2n_k^2 - n_k) r_{k-1} r_k}\n$$", "id": "3424565"}, {"introduction": "最后的这项练习将前述概念融会贯通，应用于一个完整且实际的贝叶斯逆问题中。我们考虑一个高斯贝叶斯框架，其中未知场的先验知识由一个可分离的协方差矩阵（即克罗内克积）来描述，这在模拟空间相关场时是一种常见的设定。您将推导后验分布的精确结构，并利用该结构高效计算在传统方法中难以处理的关键统计量——后验迹（posterior trace）[@problem_id:3424594]。这项实践深刻揭示了张量方法在贝叶斯推断中的威力：它不仅使高维问题变得计算可行，还为解的结构提供了深刻的解析洞见。", "problem": "考虑一个线性高斯贝叶斯逆问题，其未知状态向量为 $x \\in \\mathbb{R}^{N}$，观测值为 $y \\in \\mathbb{R}^{N}$，由可分离模型 $y = x + \\varepsilon$ 给出，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{N})$ 且 $\\sigma > 0$。假设一个具有克罗内克结构的高斯先验 $x \\sim \\mathcal{N}(0, C)$，其协方差为 $C = C_{1} \\otimes \\cdots \\otimes C_{d}$，其中 $d \\in \\mathbb{N}$，$N = \\prod_{k=1}^{d} n_{k}$，并且每个因子 $C_{k} \\in \\mathbb{R}^{n_{k} \\times n_{k}}$ 都是对称正定 (SPD) 的。您可以使用关于多元高斯条件作用和基本克罗内克积性质的标准事实，但除了可分离性外，不假设任何其他特殊结构。\n\n1. 从后验的贝叶斯线性高斯更新出发，证明后验精度 $C_{\\text{post}}^{-1}$ 是两个克罗内克积之和。请用 $C_{1}, \\ldots, C_{d}$ 和 $\\sigma^{2}$ 显式地写出这个后验精度。\n\n2. 设每个先验因子 $C_{k}$ 的特征分解为 $C_{k} = U_{k} \\Lambda_{k} U_{k}^{\\top}$，其中 $U_{k}$ 是正交矩阵，$\\Lambda_{k} = \\operatorname{diag}(\\lambda_{k,1}, \\ldots, \\lambda_{k,n_{k}})$ 且 $\\lambda_{k,i} > 0$。仅利用这些特征分解和模型的可分离性，推导出后验迹 $\\operatorname{tr}(C_{\\text{post}})$ 的一个关于 $\\{\\lambda_{k,i}\\}$ 和 $\\sigma^{2}$ 的闭式表达式。您的最终答案必须是一个单一的解析表达式。\n\n将最终答案表示为单个无单位的解析表达式。不要进行四舍五入。", "solution": "该问题要求推导一个具有可分离（克罗内克结构）先验的线性高斯贝叶斯逆问题的后验精度和后验迹。\n\n一般的线性高斯逆问题由未知状态 $x$ 的先验分布 $p(x) = \\mathcal{N}(x_0, C)$ 和给定状态下观测值 $y$ 的似然 $p(y|x) = \\mathcal{N}(Hx, R)$ 定义。这里，$x \\in \\mathbb{R}^{N}$，$y \\in \\mathbb{R}^{M}$，$x_0$ 是先验均值，$C$ 是先验协方差，$H$ 是正向算子，$R$ 是观测噪声协方差。根据贝叶斯定理，后验分布 $p(x|y)$ 也是高斯分布，$p(x|y) = \\mathcal{N}(x_{\\text{post}}, C_{\\text{post}})$，其后验协方差 $C_{\\text{post}}$ 和后验均值 $x_{\\text{post}}$ 由以下公式给出：\n$$C_{\\text{post}}^{-1} = C^{-1} + H^{\\top} R^{-1} H$$\n$$x_{\\text{post}} = C_{\\text{post}} (C^{-1}x_0 + H^{\\top} R^{-1} y)$$\n这些是标准的贝叶斯线性高斯更新方程。\n\n第1部分：后验精度 $C_{\\text{post}}^{-1}$ 的推导。\n\n在给定的问题中，状态向量是 $x \\in \\mathbb{R}^{N}$，观测向量是 $y \\in \\mathbb{R}^{N}$。模型是 $y = x + \\varepsilon$，这对应于一个正向算子 $H=I_N$，其中 $I_N$ 是大小为 $N \\times N$ 的单位矩阵。噪声 $\\varepsilon$ 的分布为 $\\mathcal{N}(0, \\sigma^{2} I_{N})$，所以噪声协方差是 $R = \\sigma^2 I_N$。$x$ 的先验被给出为 $\\mathcal{N}(0, C)$，这意味着先验均值为 $x_0 = 0$，先验协方差为 $C = C_1 \\otimes \\cdots \\otimes C_d$。\n\n我们可以将这些具体形式代入后验精度 $C_{\\text{post}}^{-1}$ 的通用公式中：\n$$C_{\\text{post}}^{-1} = C^{-1} + (I_N)^{\\top} (\\sigma^2 I_N)^{-1} (I_N)$$\n$$C_{\\text{post}}^{-1} = C^{-1} + I_N \\left(\\frac{1}{\\sigma^2} I_N\\right) I_N = C^{-1} + \\frac{1}{\\sigma^2} I_N$$\n先验协方差为 $C = C_1 \\otimes \\cdots \\otimes C_d$。利用克罗内克积的逆的性质 $(A \\otimes B)^{-1} = A^{-1} \\otimes B^{-1}$，先验精度 $C^{-1}$ 为：\n$$C^{-1} = (C_1 \\otimes \\cdots \\otimes C_d)^{-1} = C_1^{-1} \\otimes \\cdots \\otimes C_d^{-1}$$\n由于每个因子 $C_k$ 都是对称正定 (SPD) 的，其逆矩阵 $C_k^{-1}$ 存在。\n将此代入后验精度的表达式中得到：\n$$C_{\\text{post}}^{-1} = (C_1^{-1} \\otimes \\cdots \\otimes C_d^{-1}) + \\frac{1}{\\sigma^2} I_N$$\n第一项 $C_1^{-1} \\otimes \\cdots \\otimes C_d^{-1}$ 是 $d$ 个矩阵的克罗内克积。第二项 $\\frac{1}{\\sigma^2} I_N$ 是一个缩放的单位矩阵。由于 $I_N = I_{n_1} \\otimes \\cdots \\otimes I_{n_d}$，第二项也可以被看作是一个（缩放的）克罗内克积。因此，后验精度是两个都具有克罗内克积结构的矩阵之和。用 $C_1, \\ldots, C_d$ 和 $\\sigma^2$ 表示的后验精度的显式表达式为：\n$$C_{\\text{post}}^{-1} = (C_1 \\otimes \\cdots \\otimes C_d)^{-1} + \\frac{1}{\\sigma^2} I_N$$\n或等价地，用因子的逆矩阵表示为：\n$$C_{\\text{post}}^{-1} = C_1^{-1} \\otimes \\cdots \\otimes C_d^{-1} + \\frac{1}{\\sigma^2} I_N$$\n\n第2部分：后验迹 $\\operatorname{tr}(C_{\\text{post}})$ 的推导。\n\n我们需要计算后验协方差的迹，即 $\\operatorname{tr}(C_{\\text{post}})$。我们从上面推导出的逆后验协方差的表达式开始：\n$$C_{\\text{post}} = \\left( C^{-1} + \\frac{1}{\\sigma^2} I_N \\right)^{-1}$$\n矩阵的迹是其特征值之和。我们将通过首先找到 $C_{\\text{post}}^{-1}$ 的特征值来找到 $C_{\\text{post}}$ 的特征值。\n问题给出了每个先验因子 $C_k$ 的特征分解 $C_k = U_k \\Lambda_k U_k^{\\top}$，其中 $U_k$ 是正交矩阵，$\\Lambda_k = \\operatorname{diag}(\\lambda_{k,1}, \\ldots, \\lambda_{k,n_k})$ 是一个由正特征值组成的对角矩阵。\n完整先验协方差 $C$ 的特征分解可以使用克罗内克积的性质来构建：\n$$C = C_1 \\otimes \\cdots \\otimes C_d = (U_1 \\Lambda_1 U_1^{\\top}) \\otimes \\cdots \\otimes (U_d \\Lambda_d U_d^{\\top})$$\n使用混合积性质 $(A \\otimes B)(C \\otimes D) = (AC) \\otimes (BD)$，上式变为：\n$$C = (U_1 \\otimes \\cdots \\otimes U_d) (\\Lambda_1 \\otimes \\cdots \\otimes \\Lambda_d) (U_1^{\\top} \\otimes \\cdots \\otimes U_d^{\\top})$$\n设 $U = U_1 \\otimes \\cdots \\otimes U_d$ 和 $\\Lambda_{\\text{prior}} = \\Lambda_1 \\otimes \\cdots \\otimes \\Lambda_d$。矩阵 $U$ 是正交的，因为它是正交矩阵的克罗内克积。矩阵 $\\Lambda_{\\text{prior}}$ 是对角的。因此，$C = U \\Lambda_{\\text{prior}} U^{\\top}$ 是 $C$ 的特征分解。$C$ 的特征值是 $\\Lambda_{\\text{prior}}$ 的对角元素，它们是因子 $C_k$ 的特征值的乘积。$C$ 的一个特征值 $\\lambda$ 具有形式 $\\lambda = \\prod_{k=1}^d \\lambda_{k,i_k}$，对于某个指标选择 $(i_1, \\ldots, i_d)$，其中 $i_k \\in \\{1, \\ldots, n_k\\}$。\n\n现在，我们可以使用这个特征分解来表示后验精度 $C_{\\text{post}}^{-1}$。先验精度为 $C^{-1} = (U \\Lambda_{\\text{prior}} U^{\\top})^{-1} = U \\Lambda_{\\text{prior}}^{-1} U^{\\top}$。\n$$C_{\\text{post}}^{-1} = U \\Lambda_{\\text{prior}}^{-1} U^{\\top} + \\frac{1}{\\sigma^2} I_N$$\n由于 $U$ 是正交的，$I_N = U U^{\\top}$。我们可以提出因子 $U$ 和 $U^{\\top}$：\n$$C_{\\text{post}}^{-1} = U \\Lambda_{\\text{prior}}^{-1} U^{\\top} + \\frac{1}{\\sigma^2} U U^{\\top} = U \\left( \\Lambda_{\\text{prior}}^{-1} + \\frac{1}{\\sigma^2} I_N \\right) U^{\\top}$$\n这个表达式给出了 $C_{\\text{post}}^{-1}$ 的特征分解。特征向量是 $U$ 的列，特征值是对角矩阵 $\\Lambda_{\\text{prior}}^{-1} + \\frac{1}{\\sigma^2} I_N$ 的对角元素。因此，$C_{\\text{post}}^{-1}$ 的特征值形式为 $\\lambda^{-1} + \\frac{1}{\\sigma^2}$，其中 $\\lambda$ 是 $C$ 的一个特征值。\n\n后验协方差是后验精度的逆：\n$$C_{\\text{post}} = (C_{\\text{post}}^{-1})^{-1} = \\left( U \\left( \\Lambda_{\\text{prior}}^{-1} + \\frac{1}{\\sigma^2} I_N \\right) U^{\\top} \\right)^{-1} = U \\left( \\Lambda_{\\text{prior}}^{-1} + \\frac{1}{\\sigma^2} I_N \\right)^{-1} U^{\\top}$$\n这是 $C_{\\text{post}}$ 的特征分解。$C_{\\text{post}}$ 的特征值是矩阵 $(\\Lambda_{\\text{prior}}^{-1} + \\frac{1}{\\sigma^2} I_N)^{-1}$ 的对角元素。这些就是 $C_{\\text{post}}^{-1}$ 特征值的倒数。$C_{\\text{post}}$ 的一个特征值，我们记为 $\\lambda_{\\text{post}}$，由下式给出：\n$$\\lambda_{\\text{post}} = \\left( \\lambda^{-1} + \\frac{1}{\\sigma^2} \\right)^{-1} = \\left( \\frac{1}{\\lambda} + \\frac{1}{\\sigma^2} \\right)^{-1} = \\left( \\frac{\\sigma^2 + \\lambda}{\\lambda \\sigma^2} \\right)^{-1} = \\frac{\\lambda \\sigma^2}{\\lambda + \\sigma^2}$$\n其中 $\\lambda$ 是先验协方差 $C$ 的一个特征值。\n\n$C_{\\text{post}}$ 的迹是其特征值之和。我们必须对所有 $N = \\prod_{k=1}^d n_k$ 个特征值求和。$C$ 的每个特征值 $\\lambda$ 都是形如 $\\prod_{k=1}^d \\lambda_{k,i_k}$ 的乘积。因此，后验协方差的迹为：\n$$\\operatorname{tr}(C_{\\text{post}}) = \\sum_{\\text{all eigenvalues } \\lambda \\text{ of } C} \\frac{\\lambda \\sigma^2}{\\lambda + \\sigma^2}$$\n代入 $C$ 的特征值的结构，我们得到一个对所有指标组合 $(i_1, \\ldots, i_d)$ 的求和：\n$$\\operatorname{tr}(C_{\\text{post}}) = \\sum_{i_1=1}^{n_1} \\sum_{i_2=1}^{n_2} \\cdots \\sum_{i_d=1}^{n_d} \\frac{\\left(\\prod_{k=1}^d \\lambda_{k, i_k}\\right) \\sigma^2}{\\left(\\prod_{k=1}^d \\lambda_{k, i_k}\\right) + \\sigma^2}$$\n这便是以后验因子的特征值 $\\{\\lambda_{k,i}\\}$ 和噪声方差 $\\sigma^2$ 表示的后验迹的最终闭式表达式。\n为清晰起见，将表达式稍作改写：\n$$\\operatorname{tr}(C_{\\text{post}}) = \\sum_{i_1=1}^{n_1} \\cdots \\sum_{i_d=1}^{n_d} \\frac{\\sigma^2 \\prod_{k=1}^d \\lambda_{k, i_k}}{\\sigma^2 + \\prod_{k=1}^d \\lambda_{k, i_k}}$$\n推导完毕。", "answer": "$$\n\\boxed{\\sum_{i_1=1}^{n_1} \\cdots \\sum_{i_d=1}^{n_d} \\frac{\\sigma^2 \\prod_{k=1}^d \\lambda_{k, i_k}}{\\sigma^2 + \\prod_{k=1}^d \\lambda_{k, i_k}}}\n$$", "id": "3424594"}]}