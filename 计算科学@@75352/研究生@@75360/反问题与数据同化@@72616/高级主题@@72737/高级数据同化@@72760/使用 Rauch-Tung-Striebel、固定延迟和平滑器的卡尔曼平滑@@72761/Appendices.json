{"hands_on_practices": [{"introduction": "卡尔曼平滑问题可以从两个核心视角来理解：一个是递归贝叶斯推断（如RTS平滑器），另一个是批量优化。本练习将深入探讨后一种视角，将固定区间平滑问题构建为一个最大后验（MAP）估计问题。通过从MAP代价函数出发，推导其一阶最优性条件，您将揭示平滑问题与求解一个大型稀疏线性方程组（即正规方程）之间的深刻联系。这项练习旨在强化您对概率推断和线性代数之间等价性的理解，并展示状态空间模型中的马尔可夫结构如何自然地产生高效求解的块三对角系统 [@problem_id:3393989]。", "problem": "考虑一个建立在固定区间 $k=0,1,\\dots,T$ 上的线性、时变、离散时间高斯状态空间模型，其先验、动态和观测由以下公式给出：\n$$\nx_0 \\sim \\mathcal{N}(m_0,P_0), \\quad x_{k+1} = F_k x_k + w_k, \\quad w_k \\sim \\mathcal{N}(0,Q_k), \\quad y_k = H_k x_k + v_k, \\quad v_k \\sim \\mathcal{N}(0,R_k),\n$$\n其中 $x_k \\in \\mathbb{R}^n$，$y_k \\in \\mathbb{R}^p$，矩阵 $P_0 \\in \\mathbb{R}^{n \\times n}$、$Q_k \\in \\mathbb{R}^{n \\times n}$ 和 $R_k \\in \\mathbb{R}^{p \\times p}$ 是对称正定矩阵，而 $F_k \\in \\mathbb{R}^{n \\times n}$ 和 $H_k \\in \\mathbb{R}^{p \\times n}$ 是已知的。在 $k=0{:}T$ 上的固定区间平滑可以通过最小化严格凸二次代价函数，来公式化为最大后验估计问题：\n$$\nJ(x_{0:T}) \\;=\\; \\frac{1}{2}\\|x_0 - m_0\\|_{P_0^{-1}}^2 \\;+\\; \\sum_{k=0}^{T-1} \\frac{1}{2}\\|x_{k+1} - F_k x_k\\|_{Q_k^{-1}}^2 \\;+\\; \\sum_{k=0}^{T} \\frac{1}{2}\\|y_k - H_k x_k\\|_{R_k^{-1}}^2,\n$$\n其中堆叠决策向量为 $x_{0:T} \\equiv \\mathrm{col}(x_0,\\dots,x_T) \\in \\mathbb{R}^{n(T+1)}$，加权范数为 $\\|a\\|_{M}^2 \\equiv a^{\\top} M a$。通过对每个 $x_k$ 取一阶最优性条件并组合各项，正规方程可以写成块三对角形式：\n$$\n\\mathcal{H}\\,x_{0:T} \\;=\\; b,\n$$\n其中 $\\mathcal{H} \\in \\mathbb{R}^{n(T+1)\\times n(T+1)}$ 是一个由 $n\\times n$ 块组成的对称块三对角矩阵，而 $b \\in \\mathbb{R}^{n(T+1)}$ 是汇集了先验和测量信息的右侧项。仅使用给定的概率模型和 $J(x_{0:T})$ 的定义，从第一性原理出发推导 $\\mathcal{H}$ 和 $b$，并确定对角块、非对角块以及 $b$ 的分量的显式表达式。\n\n完成此推导后，仅报告对于通用内部索引 $k \\in \\{1,\\dots,T\\}$，$\\mathcal{H}$ 中将 $x_{k}$ 与 $x_{k-1}$ 耦合的次对角块的闭式解析表达式。你的最终答案必须是一个单一的解析表达式。不需要四舍五入，也不涉及单位。", "solution": "该问题要求推导一个固定区间平滑问题的块三对角正规方程，并确定关联信息矩阵 $\\mathcal{H}$ 的一个特定块。这个问题是有效的，因为它代表了线性高斯状态空间模型的标准最大后验 (MAP) 估计公式，这是估计理论中一个适定且基本的问题。\n\n目标是找到最小化代价函数 $J(x_{0:T})$ 的状态轨迹 $x_{0:T} = \\mathrm{col}(x_0, \\dots, x_T)$。由于 $J(x_{0:T})$ 是关于 $x_{0:T}$ 的一个严格凸二次函数（因为 $P_0$, $Q_k$, 和 $R_k$ 的正定性），存在唯一的最小值，可以通过将 $J$ 关于每个分量 $x_k$ 的梯度设为零来找到。完整的梯度为 $\\nabla_{x_{0:T}} J = \\mathrm{col}(\\frac{\\partial J}{\\partial x_0}, \\dots, \\frac{\\partial J}{\\partial x_T})$。\n\n代价函数由下式给出：\n$$\nJ(x_{0:T}) = \\frac{1}{2}\\|x_0 - m_0\\|_{P_0^{-1}}^2 + \\sum_{k=0}^{T-1} \\frac{1}{2}\\|x_{k+1} - F_k x_k\\|_{Q_k^{-1}}^2 + \\sum_{k=0}^{T} \\frac{1}{2}\\|y_k - H_k x_k\\|_{R_k^{-1}}^2\n$$\n展开加权范数，我们得到：\n$$\nJ(x_{0:T}) = \\frac{1}{2}(x_0 - m_0)^{\\top}P_0^{-1}(x_0 - m_0) + \\sum_{k=0}^{T-1} \\frac{1}{2}(x_{k+1} - F_k x_k)^{\\top}Q_k^{-1}(x_{k+1} - F_k x_k) + \\sum_{k=0}^{T} \\frac{1}{2}(y_k - H_k x_k)^{\\top}R_k^{-1}(y_k - H_k x_k)\n$$\n为了找到最小值，我们对 $k = 0, \\dots, T$ 中的每个 $x_k$ 求 $J$ 的偏导数，并将其设为零。我们利用矩阵微积分恒等式 $\\frac{\\partial}{\\partial z} (a-Az)^{\\top}B(a-Az) = -2A^{\\top}B(a-Az)$（对于对称矩阵 $B$）。\n\n让我们首先考虑一个通用内部时间索引 $k \\in \\{1, \\dots, T-1\\}$。状态向量 $x_k$ 出现在代价函数 $J$ 的三个项中：\n1. 从 $k-1$ 到 $k$ 的动态项：$\\frac{1}{2}\\|x_k - F_{k-1} x_{k-1}\\|_{Q_{k-1}^{-1}}^2$\n2. 从 $k$ 到 $k+1$ 的动态项：$\\frac{1}{2}\\|x_{k+1} - F_k x_k\\|_{Q_k^{-1}}^2$\n3. 在时间 $k$ 的测量项：$\\frac{1}{2}\\|y_k - H_k x_k\\|_{R_k^{-1}}^2$\n\n$J$ 关于 $x_k$ 的偏导数是这三项导数的和，因为 $J$ 中的其他项不依赖于 $x_k$：\n$$\n\\frac{\\partial J}{\\partial x_k} = \\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2}(x_k - F_{k-1}x_{k-1})^{\\top}Q_{k-1}^{-1}(x_k - F_{k-1}x_{k-1}) \\right) + \\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2}(x_{k+1} - F_k x_k)^{\\top}Q_k^{-1}(x_{k+1} - F_k x_k) \\right) + \\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2}(y_k - H_k x_k)^{\\top}R_k^{-1}(y_k - H_k x_k) \\right)\n$$\n计算每个导数：\n- $\\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2}(x_k - F_{k-1}x_{k-1})^{\\top}Q_{k-1}^{-1}(x_k - F_{k-1}x_{k-1}) \\right) = Q_{k-1}^{-1}(x_k - F_{k-1}x_{k-1})$\n- $\\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2}(x_{k+1} - F_k x_k)^{\\top}Q_k^{-1}(x_{k+1} - F_k x_k) \\right) = -F_k^{\\top}Q_k^{-1}(x_{k+1} - F_k x_k)$\n- $\\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2}(y_k - H_k x_k)^{\\top}R_k^{-1}(y_k - H_k x_k) \\right) = -H_k^{\\top}R_k^{-1}(y_k - H_k x_k)$\n\n将这些项相加并设为零，得到关于 $x_k$ 的一阶最优性条件：\n$$\n\\frac{\\partial J}{\\partial x_k} = Q_{k-1}^{-1}(x_k - F_{k-1}x_{k-1}) - F_k^{\\top}Q_k^{-1}(x_{k+1} - F_k x_k) - H_k^{\\top}R_k^{-1}(y_k - H_k x_k) = 0\n$$\n为了构造正规方程 $\\mathcal{H}x_{0:T}=b$，我们按状态向量 $x_{k-1}$、$x_k$ 和 $x_{k+1}$ 对各项进行分组：\n$$\n(-Q_{k-1}^{-1}F_{k-1})x_{k-1} + (Q_{k-1}^{-1} + F_k^{\\top}Q_k^{-1}F_k + H_k^{\\top}R_k^{-1}H_k)x_k + (-F_k^{\\top}Q_k^{-1})x_{k+1} = H_k^{\\top}R_k^{-1}y_k\n$$\n这个方程对应于系统 $\\mathcal{H}x_{0:T}=b$ 的第 $k$ 个块行。由此，我们可以确定对于 $k \\in \\{1, \\dots, T-1\\}$，$\\mathcal{H}$ 和 $b$ 的各个块：\n- 次对角块：$\\mathcal{H}_{k,k-1} = -Q_{k-1}^{-1}F_{k-1}$\n- 对角块：$\\mathcal{H}_{k,k} = Q_{k-1}^{-1} + F_k^{\\top}Q_k^{-1}F_k + H_k^{\\top}R_k^{-1}H_k$\n- 超对角块：$\\mathcal{H}_{k,k+1} = -F_k^{\\top}Q_k^{-1}$\n- 右侧向量分量：$b_k = H_k^{\\top}R_k^{-1}y_k$\n\n为了完整性，我们考察边界条件。\n对于 $k=0$：\n$$\n\\frac{\\partial J}{\\partial x_0} = P_0^{-1}(x_0 - m_0) - F_0^{\\top}Q_0^{-1}(x_1 - F_0 x_0) - H_0^{\\top}R_0^{-1}(y_0 - H_0 x_0) = 0\n$$\n$$\n(P_0^{-1} + F_0^{\\top}Q_0^{-1}F_0 + H_0^{\\top}R_0^{-1}H_0)x_0 + (-F_0^{\\top}Q_0^{-1})x_1 = P_0^{-1}m_0 + H_0^{\\top}R_0^{-1}y_0\n$$\n因此，$\\mathcal{H}_{0,0} = P_0^{-1} + F_0^{\\top}Q_0^{-1}F_0 + H_0^{\\top}R_0^{-1}H_0$，$\\mathcal{H}_{0,1} = -F_0^{\\top}Q_0^{-1}$，以及 $b_0 = P_0^{-1}m_0 + H_0^{\\top}R_0^{-1}y_0$。\n\n对于 $k=T$：\n$$\n\\frac{\\partial J}{\\partial x_T} = Q_{T-1}^{-1}(x_T - F_{T-1}x_{T-1}) - H_T^{\\top}R_T^{-1}(y_T - H_T x_T) = 0\n$$\n$$\n(-Q_{T-1}^{-1}F_{T-1})x_{T-1} + (Q_{T-1}^{-1} + H_T^{\\top}R_T^{-1}H_T)x_T = H_T^{\\top}R_T^{-1}y_T\n$$\n因此，$\\mathcal{H}_{T,T-1} = -Q_{T-1}^{-1}F_{T-1}$，$\\mathcal{H}_{T,T} = Q_{T-1}^{-1} + H_T^{\\top}R_T^{-1}H_T$，以及 $b_T = H_T^{\\top}R_T^{-1}y_T$。\n\n问题要求的是 $\\mathcal{H}$ 中将 $x_k$ 与 $x_{k-1}$ 耦合的次对角块。这是在线性系统的第 $k$ 个块行中乘以 $x_{k-1}$ 的块 $\\mathcal{H}_{k, k-1}$。根据我们对内部点 ($k \\in \\{1,\\dots,T-1\\}$) 和端点 ($k=T$) 的推导，这个块具有相同的通用形式。对于任何 $k \\in \\{1, \\dots, T\\}$，该表达式为：\n$$\n\\mathcal{H}_{k,k-1} = -Q_{k-1}^{-1}F_{k-1}\n$$\n此表达式代表了在指定范围内的通用索引 $k$ 所要求的次对角块。", "answer": "$$\n\\boxed{-Q_{k-1}^{-1}F_{k-1}}\n$$", "id": "3393989"}, {"introduction": "尽管完整的固定区间平滑器能提供理论上最优的估计，但它要求处理整个时间序列的数据，这在实时或在线应用中可能计算成本过高。因此，一个实际的替代方案是自适应固定滞后平滑，其核心思想是在未来的观测所能提供的信息增益变得微不足道时，提前终止向后传递的递归过程。在这个结合了理论推导与编程实践的练习中，您将首先推导出一个衡量“信息增益”的准则，并从理论上分析这种截断所引入的估计偏差，然后通过编程实现该自适应策略，以量化探索计算效率与估计精度之间的权衡 [@problem_id:3393965]。", "problem": "考虑一个状态维度为 $n$、观测维度为 $p$ 的线性、时不变、离散时间的高斯状态空间模型。潜状态 $\\mathbf{x}_t \\in \\mathbb{R}^n$ 和观测 $\\mathbf{y}_t \\in \\mathbb{R}^p$ 满足\n$$\n\\mathbf{x}_{t+1} = \\mathbf{A}\\,\\mathbf{x}_t + \\mathbf{w}_t,\\quad \\mathbf{w}_t \\sim \\mathcal{N}(\\mathbf{0},\\,\\mathbf{Q}),\n$$\n$$\n\\mathbf{y}_t = \\mathbf{H}\\,\\mathbf{x}_t + \\mathbf{v}_t,\\quad \\mathbf{v}_t \\sim \\mathcal{N}(\\mathbf{0},\\,\\mathbf{R}),\n$$\n其中 $\\mathbf{w}_t$ 和 $\\mathbf{v}_t$ 相互独立且在时间上独立，并且 $\\mathbf{x}_0 \\sim \\mathcal{N}(\\mathbf{m}_0,\\,\\mathbf{P}_0)$。所有矩阵 $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$、$\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$、$\\mathbf{H} \\in \\mathbb{R}^{p \\times n}$ 和 $\\mathbf{R} \\in \\mathbb{R}^{p \\times p}$ 均为已知，其中 $\\mathbf{Q}$ 和 $\\mathbf{R}$ 是对称正定矩阵。卡尔曼滤波器 (KF) 生成滤波估计 $\\mathbf{m}_{t|t}$ 和 $\\mathbf{P}_{t|t}$，而 Rauch-Tung-Striebel (RTS) 固定区间平滑器生成平滑估计 $\\mathbf{m}_{t|T}$ 和 $\\mathbf{P}_{t|T}$，适用于 $t = 0, 1, \\dots, T$，其中 $T$ 是终止时间索引。\n\n将时间 $t$ 的反向信息内容定义为由平滑引起的协方差减小量\n$$\n\\Delta \\mathbf{P}_t \\triangleq \\mathbf{P}_{t|t} - \\mathbf{P}_{t|T},\\quad \\Delta \\mathbf{P}_t \\succeq \\mathbf{0}.\n$$\n我们为反向 RTS 递归提出一个自适应停止准则：在满足以下条件的最早时间 $t^\\star$ 停止递归\n$$\n\\mathrm{tr}\\!\\left( \\Delta \\mathbf{P}_t \\right) \\le \\varepsilon,\n$$\n其中 $\\varepsilon > 0$ 是用户指定的阈值。对于所有 $k \\le t^\\star$，设置 $\\mathbf{m}_{k|T}^{\\text{stop}} \\triangleq \\mathbf{m}_{k|k}$ 和 $\\mathbf{P}_{k|T}^{\\text{stop}} \\triangleq \\mathbf{P}_{k|k}$，而对于 $k > t^\\star$ 则保留完整的 RTS 值。这产生了一个近似平滑器，该平滑器仅使用回溯到停止索引的未来信息。\n\n您的任务是：\n- 从高斯条件化、卡尔曼滤波器和 RTS 递归的基本定义出发，推导一个基于反向信息内容 $\\Delta \\mathbf{P}_t$ 的、数学上合理的自适应延迟选择准则。证明 $\\Delta \\mathbf{P}_t$ 是半正定的，并且其迹是从时间 $t$ 之后的观测中获得的反向信息的标量摘要。\n- 证明所提出的停止准则对平滑均值截断引入的一种自然偏差概念给出了界定。具体来说，将时间 $t$ 的截断偏差定义为 $\\mathbf{b}_t \\triangleq \\mathbf{m}_{t|T} - \\mathbf{m}_{t|T}^{\\text{stop}}$，并证明在状态和观测的联合分布上平均的均方截断偏差满足\n$$\n\\mathbb{E}\\!\\left[\\|\\mathbf{b}_t\\|_2^2\\right] = \\mathrm{tr}\\!\\left( \\mathbf{P}_{t|T}^{\\text{stop}} - \\mathbf{P}_{t|T} \\right),\n$$\n并且，在递归于 $t^\\star$ 停止的特定情况下，对于所有 $t \\le t^\\star$，\n$$\n\\mathbb{E}\\!\\left[\\|\\mathbf{b}_t\\|_2^2\\right] = \\mathrm{tr}\\!\\left( \\Delta \\mathbf{P}_t \\right).\n$$\n- 实现一个完整的程序，该程序从指定的模型模拟数据，并为一组阈值 $\\varepsilon$ 计算整个轨迹上的总均方截断偏差，\n$$\nB(\\varepsilon) \\triangleq \\sum_{t=0}^{T} \\mathrm{tr}\\!\\left( \\mathbf{P}_{t|T}^{\\text{stop}(\\varepsilon)} - \\mathbf{P}_{t|T} \\right),\n$$\n其中 $\\mathbf{P}_{t|T}^{\\text{stop}(\\varepsilon)}$ 表示在阈值 $\\varepsilon$ 下使用自适应停止准则的平滑协方差。程序必须使用单个固定模型和单个具有固定随机种子的模拟数据实现。\n\n使用以下固定的模型和模拟参数，必须完全按照规定实现：\n- 状态维度 $n = 2$，观测维度 $p = 2$。\n- 终止时间 $T = 60$。\n- 系统矩阵\n$$\n\\mathbf{A} = \\begin{bmatrix} 0.9  0.3 \\\\ 0.0  0.7 \\end{bmatrix},\\quad\n\\mathbf{H} = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}.\n$$\n- 协方差\n$$\n\\mathbf{Q} = \\begin{bmatrix} 0.05  0.01 \\\\ 0.01  0.05 \\end{bmatrix},\\quad\n\\mathbf{R} = \\begin{bmatrix} 0.10  0.00 \\\\ 0.00  0.10 \\end{bmatrix}.\n$$\n- 初始条件\n$$\n\\mathbf{m}_0 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix},\\quad\n\\mathbf{P}_0 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}.\n$$\n- 使用单个随机种子 $\\texttt{seed} = 12345$ 并相应地抽取 $\\mathbf{x}_0$、$\\{\\mathbf{w}_t\\}_{t=0}^{T-1}$ 和 $\\{\\mathbf{v}_t\\}_{t=0}^{T}$。\n\n您的测试套件必须为以下阈值评估总均方截断偏差 $B(\\varepsilon)$：\n- 阈值 $\\varepsilon \\in \\{0.0,\\;10^{-5},\\;10^{-3},\\;10^{2}\\}$。\n\n为覆盖性而设计：\n- 情况 $\\varepsilon = 0.0$ 测试无截断的完全平滑的边界条件。\n- 情况 $\\varepsilon = 10^{-5}$ 测试具有最小截断的近乎完全平滑的场景。\n- 情况 $\\varepsilon = 10^{-3}$ 测试典型的自适应延迟截断。\n- 情况 $\\varepsilon = 10^{2}$ 测试提早停止的边缘情况，近似于无平滑。\n\n您的程序必须生成单行输出，其中包含测试套件的结果，格式为方括号括起来的逗号分隔的 Python 浮点数列表，其顺序与上面给出的阈值相匹配，例如 $\\texttt{[r_1,r_2,r_3,r_4]}$。此问题不涉及物理单位，也未使用角度，因此除了此处描述的数学模型外，不需要任何单位规范。程序必须是自包含的，不需要任何输入，并且仅使用指定的运行时环境。", "solution": "用户提供的问题陈述是有效的。它在科学上基于贝叶斯滤波和平滑的成熟理论，特别是针对线性高斯状态空间模型。该问题是适定的，提供了所有必要的参数和一组清晰但复杂的任务。理论推导、证明和数值实现的结合构成了统计信号处理领域的一项标准且实质性的练习。\n\n我们将解决方案分为两部分：理论推导与证明，以及数值实验的实现。\n\n### 第 1 部分：理论基础与推导\n\n本部分为所提出的 Rauch-Tung-Striebel (RTS) 平滑器的自适应停止准则奠定了理论基础。我们首先陈述卡尔曼滤波器和 RTS 平滑器的标准方程。\n\n设状态空间模型由以下公式给出：\n$$\n\\mathbf{x}_{t+1} = \\mathbf{A}\\,\\mathbf{x}_t + \\mathbf{w}_t,\\quad \\mathbf{w}_t \\sim \\mathcal{N}(\\mathbf{0},\\,\\mathbf{Q})\n$$\n$$\n\\mathbf{y}_t = \\mathbf{H}\\,\\mathbf{x}_t + \\mathbf{v}_t,\\quad \\mathbf{v}_t \\sim \\mathcal{N}(\\mathbf{0},\\,\\mathbf{R})\n$$\n在给定截至时间 $\\tau$ 的观测值 $\\mathbf{y}_{0:\\tau} \\triangleq \\{\\mathbf{y}_0, \\dots, \\mathbf{y}_\\tau\\}$ 的条件下，状态 $\\mathbf{x}_t$ 的后验分布是高斯分布：$p(\\mathbf{x}_t|\\mathbf{y}_{0:\\tau}) = \\mathcal{N}(\\mathbf{x}_t | \\mathbf{m}_{t|\\tau}, \\mathbf{P}_{t|\\tau})$。\n\n**卡尔曼滤波器（前向过程）**\n卡尔曼滤波器为 $t=0, \\dots, T$ 递归计算滤波后验 $p(\\mathbf{x}_t|\\mathbf{y}_{0:t})$。从先验 $\\mathbf{m}_{0|-1} = \\mathbf{m}_0$ 和 $\\mathbf{P}_{0|-1} = \\mathbf{P}_0$ 开始，对于每个时间步 $t=0, \\dots, T$：\n\n1.  **预测步骤** (对于 $t > 0$):\n    $$ \\mathbf{m}_{t|t-1} = \\mathbf{A}\\,\\mathbf{m}_{t-1|t-1} $$\n    $$ \\mathbf{P}_{t|t-1} = \\mathbf{A}\\,\\mathbf{P}_{t-1|t-1} \\mathbf{A}^\\top + \\mathbf{Q} $$\n    对于 $t=0$，我们直接使用初始先验：$\\mathbf{m}_{0|-1}=\\mathbf{m}_0, \\mathbf{P}_{0|-1}=\\mathbf{P}_0$。\n\n2.  **更新步骤**:\n    $$ \\mathbf{S}_t = \\mathbf{H}\\,\\mathbf{P}_{t|t-1} \\mathbf{H}^\\top + \\mathbf{R} $$\n    $$ \\mathbf{K}_t = \\mathbf{P}_{t|t-1} \\mathbf{H}^\\top \\mathbf{S}_t^{-1} $$\n    $$ \\mathbf{m}_{t|t} = \\mathbf{m}_{t|t-1} + \\mathbf{K}_t (\\mathbf{y}_t - \\mathbf{H}\\,\\mathbf{m}_{t|t-1}) $$\n    $$ \\mathbf{P}_{t|t} = (\\mathbf{I} - \\mathbf{K}_t \\mathbf{H}) \\mathbf{P}_{t|t-1} $$\n\n**Rauch-Tung-Striebel (RTS) 平滑器（后向过程）**\nRTS 平滑器为 $t=T-1, \\dots, 0$ 计算平滑后验 $p(\\mathbf{x}_t|\\mathbf{y}_{0:T})$。它使用最终的滤波估计 $\\mathbf{m}_{T|T}$ 和 $\\mathbf{P}_{T|T}$ 进行初始化，并向后递归：\n\n1.  **平滑器增益**:\n    $$ \\mathbf{G}_t = \\mathbf{P}_{t|t} \\mathbf{A}^\\top \\mathbf{P}_{t+1|t}^{-1} $$\n\n2.  **平滑器更新**:\n    $$ \\mathbf{m}_{t|T} = \\mathbf{m}_{t|t} + \\mathbf{G}_t (\\mathbf{m}_{t+1|T} - \\mathbf{m}_{t+1|t}) $$\n    $$ \\mathbf{P}_{t|T} = \\mathbf{P}_{t|t} + \\mathbf{G}_t (\\mathbf{P}_{t+1|T} - \\mathbf{P}_{t+1|t}) \\mathbf{G}_t^\\top $$\n\n**任务 1：反向信息内容 $\\Delta \\mathbf{P}_t$**\n\n反向信息内容定义为 $\\Delta \\mathbf{P}_t \\triangleq \\mathbf{P}_{t|t} - \\mathbf{P}_{t|T}$。\n\n首先，我们证明 $\\Delta \\mathbf{P}_t$ 是半正定的，即 $\\Delta \\mathbf{P}_t \\succeq \\mathbf{0}$。滤波协方差 $\\mathbf{P}_{t|t} = \\mathrm{Cov}(\\mathbf{x}_t | \\mathbf{y}_{0:t})$ 是 $\\mathbf{x}_t$ 在给定截至时间 $t$ 的观测值条件下的协方差。平滑协方差 $\\mathbf{P}_{t|T} = \\mathrm{Cov}(\\mathbf{x}_t | \\mathbf{y}_{0:T})$ 是 $\\mathbf{x}_t$ 在给定所有观测值（包括来自未来的观测值 $\\{\\mathbf{y}_{t+1}, \\dots, \\mathbf{y}_T\\}$）条件下的协方差。条件化的一个基本性质是，更多的信息不会增加不确定性（方差）。对于任意两个随机变量集合 $\\mathcal{D}_1$ 和 $\\mathcal{D}_2$，若 $\\mathcal{D}_1 \\subseteq \\mathcal{D}_2$，则条件协方差满足 $\\mathrm{Cov}(\\mathbf{x}|\\mathcal{D}_1) \\succeq \\mathrm{Cov}(\\mathbf{x}|\\mathcal{D}_2)$。在我们的情境中，设 $\\mathbf{x} = \\mathbf{x}_t$，$\\mathcal{D}_1 = \\mathbf{y}_{0:t}$，且 $\\mathcal{D}_2 = \\mathbf{y}_{0:T}$，我们有 $\\mathbf{P}_{t|t} \\succeq \\mathbf{P}_{t|T}$，这直接意味着 $\\mathbf{P}_{t|t} - \\mathbf{P}_{t|T} = \\Delta \\mathbf{P}_t \\succeq \\mathbf{0}$。\n\n协方差矩阵的迹给出了状态分量方差之和，即相应估计的均方误差 (MSE)。因此，$\\mathrm{tr}(\\mathbf{P}_{t|t})$ 是滤波估计 $\\mathbf{m}_{t|t}$ 的 MSE，而 $\\mathrm{tr}(\\mathbf{P}_{t|T})$ 是平滑估计 $\\mathbf{m}_{t|T}$ 的 MSE。量 $\\mathrm{tr}(\\Delta \\mathbf{P}_t) = \\mathrm{tr}(\\mathbf{P}_{t|t}) - \\mathrm{tr}(\\mathbf{P}_{t|T})$ 表示通过融入未来观测值 $\\{\\mathbf{y}_{t+1}, \\dots, \\mathbf{y}_T\\}$ 所实现的状态方差（或 MSE）的总减少量。因此，它是从后向过程中获得的信息的一个自然标量摘要。使用它作为停止准则 $\\mathrm{tr}(\\Delta \\mathbf{P}_t) \\le \\varepsilon$，将“当从剩余未来观测中获得的信息增益变得可以忽略不计时，可以停止反向递归”这一直觉形式化。\n\n**任务 2：截断偏差分析**\n\n截断偏差定义为 $\\mathbf{b}_t \\triangleq \\mathbf{m}_{t|T} - \\mathbf{m}_{t|T}^{\\text{stop}}$。我们需要证明 $\\mathbb{E}[\\|\\mathbf{b}_t\\|_2^2] = \\mathrm{tr}(\\mathbf{P}_{t|T}^{\\text{stop}} - \\mathbf{P}_{t|T})$，其中期望是在状态和观测的联合分布上计算的。\n\n估计值 $\\mathbf{m}_{t|T}$ 和 $\\mathbf{m}_{t|T}^{\\text{stop}}$ 是给定不同观测集的 $\\mathbf{x}_t$ 的条件期望。设 $\\mathcal{Y}^{\\text{full}} = \\mathbf{y}_{0:T}$，并设 $\\mathcal{Y}^{\\text{stop}}$ 是用于截断平滑器的观测集。这两个条件期望之差的均方范数可以与其各自的条件协方差相关联。对于联合高斯随机变量 $(X, Y, Z)$，一个标准结果是 $\\mathbb{E}[ \\| \\mathbb{E}[X|Y,Z] - \\mathbb{E}[X|Y] \\|^2 ] = \\mathrm{tr}(\\mathrm{Cov}(X|Y) - \\mathrm{Cov}(X|Y,Z))$。\n\n在我们的例子中，令 $X = \\mathbf{x}_t$。两组条件变量是 $Y = \\mathcal{Y}^{\\text{stop}}$ 和 $\\{Y,Z\\} = \\mathcal{Y}^{\\text{full}}$。由于状态空间模型是线性高斯的，条件协方差与观测的具体值无关。我们有：\n$$ \\mathrm{Cov}(\\mathbf{x}_t | \\mathcal{Y}^{\\text{stop}}) = \\mathbf{P}_{t|T}^{\\text{stop}} $$\n$$ \\mathrm{Cov}(\\mathbf{x}_t | \\mathcal{Y}^{\\text{full}}) = \\mathbf{P}_{t|T} $$\n应用该恒等式，均方截断偏差变为：\n$$ \\mathbb{E}[\\|\\mathbf{b}_t\\|_2^2] = \\mathbb{E}[\\|\\mathbf{m}_{t|T} - \\mathbf{m}_{t|T}^{\\text{stop}}\\|_2^2] = \\mathrm{tr}(\\mathrm{Cov}(\\mathbf{x}_t | \\mathcal{Y}^{\\text{stop}}) - \\mathrm{Cov}(\\mathbf{x}_t | \\mathcal{Y}^{\\text{full}})) = \\mathrm{tr}(\\mathbf{P}_{t|T}^{\\text{stop}} - \\mathbf{P}_{t|T}) $$\n这就证明了第一个所需的恒等式。\n\n现在，我们考虑递归在 $t^\\star$ 停止的特定情况。根据问题定义，对于所有 $t \\le t^\\star$，截断平滑器使用滤波估计：$\\mathbf{m}_{t|T}^{\\text{stop}} = \\mathbf{m}_{t|t}$ 和 $\\mathbf{P}_{t|T}^{\\text{stop}} = \\mathbf{P}_{t|t}$。滤波估计的观测集是 $\\mathcal{Y}^{\\text{stop}} = \\mathbf{y}_{0:t}$。\n对于 $t \\le t^\\star$，将 $\\mathbf{P}_{t|T}^{\\text{stop}} = \\mathbf{P}_{t|t}$ 代入已证明的恒等式，我们得到：\n$$ \\mathbb{E}[\\|\\mathbf{b}_t\\|_2^2] = \\mathrm{tr}(\\mathbf{P}_{t|t} - \\mathbf{P}_{t|T}) $$\n根据定义，$\\Delta \\mathbf{P}_t = \\mathbf{P}_{t|t} - \\mathbf{P}_{t|T}$。因此，对于所有 $t \\le t^\\star$：\n$$ \\mathbb{E}[\\|\\mathbf{b}_t\\|_2^2] = \\mathrm{tr}(\\Delta \\mathbf{P}_t) $$\n这样就完成了证明。总偏差 $B(\\varepsilon)$ 是这些期望平方误差在整个轨迹上的总和。\n\n### 第 2 部分：实现策略\n\n实现过程分为四个主要步骤：\n1.  **数据模拟**：根据指定的模型、参数和随机种子，生成状态和观测轨迹 $\\{\\mathbf{x}_t\\}_{t=0}^T$ 和 $\\{\\mathbf{y}_t\\}_{t=0}^T$ 的单个实现。\n2.  **卡尔曼滤波**：从 $t=0$ 到 $t=T$ 按时间正向运行标准卡尔曼滤波器，以计算滤波均值 $\\mathbf{m}_{t|t}$ 和协方差 $\\mathbf{P}_{t|t}$ 的序列，以及平滑器所需的预测均值 $\\mathbf{m}_{t+1|t}$ 和协方差 $\\mathbf{P}_{t+1|t}$。\n3.  **RTS 平滑**：从 $t=T-1$ 到 $t=0$ 按时间反向运行标准 RTS 平滑器，以计算完全平滑的均值 $\\mathbf{m}_{t|T}$ 和协方差 $\\mathbf{P}_{t|T}$ 的序列。\n4.  **偏差计算**：对于每个指定的阈值 $\\varepsilon$：a. 确定停止时间 $t^\\star$。根据问题的描述性文本（对于 $\\varepsilon=0.0$ 是“无截断的完全平滑”），正确的解释是找到从反向过程 $t \\in \\{T-1, \\dots, 0\\}$ 中第一个满足停止准则的时间。设这个时间为 $t^\\star$。如果不存在这样的时间，则设置 $t^\\star = -1$。 b. 计算总偏差 $B(\\varepsilon) = \\sum_{t=0}^{T} \\mathrm{tr}(\\mathbf{P}_{t|T}^{\\text{stop}(\\varepsilon)} - \\mathbf{P}_{t|T})$。根据我们的证明和截断平滑器的定义，这可以简化为 $B(\\varepsilon) = \\sum_{t=0}^{t^\\star} \\mathrm{tr}(\\Delta \\mathbf{P}_t)$。如果 $t^\\star = -1$，则此和为零。\n\n此计算过程精确地实现了问题所要求的分析。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates a linear-Gaussian state-space model, runs a Kalman filter and RTS smoother,\n    and computes the aggregate mean-squared truncation bias for an adaptive smoother\n    based on a set of thresholds.\n    \"\"\"\n\n    # --- Model and Simulation Parameters ---\n    n = 2  # State dimension\n    p = 2  # Observation dimension\n    T = 60 # Terminal time index\n\n    A = np.array([[0.9, 0.3], [0.0, 0.7]])\n    H = np.array([[1.0, 0.0], [0.0, 1.0]])\n    Q = np.array([[0.05, 0.01], [0.01, 0.05]])\n    R = np.array([[0.10, 0.00], [0.00, 0.10]])\n    m0 = np.array([0.0, 0.0])\n    P0 = np.array([[1.0, 0.0], [0.0, 1.0]])\n    seed = 12345\n    \n    thresholds = [0.0, 1e-5, 1e-3, 100.0]\n\n    # --- 1. Data Simulation ---\n    rng = np.random.default_rng(seed)\n    \n    # State and observation arrays (T+1 steps from 0 to T)\n    states = np.zeros((T + 1, n))\n    observations = np.zeros((T + 1, p))\n    \n    # Draw initial state\n    states[0] = rng.multivariate_normal(m0, P0)\n    \n    # Generate state trajectory\n    for t in range(T):\n        w = rng.multivariate_normal(np.zeros(n), Q)\n        states[t+1] = A @ states[t] + w\n        \n    # Generate observation trajectory\n    for t in range(T + 1):\n        v = rng.multivariate_normal(np.zeros(p), R)\n        observations[t] = H @ states[t] + v\n        \n    # --- 2. Kalman Filter (Forward Pass) ---\n    m_pred = np.zeros((T + 1, n))\n    P_pred = np.zeros((T + 1, n, n))\n    m_filt = np.zeros((T + 1, n))\n    P_filt = np.zeros((T + 1, n, n))\n    \n    # Initialize with the prior for t=0\n    m_pred[0] = m0\n    P_pred[0] = P0\n    \n    # Run filter from t = 0 to T\n    for t in range(T + 1):\n        # Prediction step (for t>0, updates m_pred[t], P_pred[t])\n        if t > 0:\n            m_pred[t] = A @ m_filt[t-1]\n            P_pred[t] = A @ P_filt[t-1] @ A.T + Q\n        \n        # Update step (produces filtered estimate for time t)\n        S_t = H @ P_pred[t] @ H.T + R\n        S_t_inv = np.linalg.inv(S_t)\n        K_t = P_pred[t] @ H.T @ S_t_inv\n        \n        m_filt[t] = m_pred[t] + K_t @ (observations[t] - H @ m_pred[t])\n        P_filt[t] = (np.eye(n) - K_t @ H) @ P_pred[t]\n        \n    # --- 3. RTS Smoother (Backward Pass) ---\n    m_smooth = np.zeros((T + 1, n))\n    P_smooth = np.zeros((T + 1, n, n))\n    \n    # Initialize with the final filtered estimate\n    m_smooth[T] = m_filt[T]\n    P_smooth[T] = P_filt[T]\n    \n    # Run smoother backward from t = T-1 to 0\n    for t in range(T - 1, -1, -1):\n        # Smoother gain\n        G_t = P_filt[t] @ A.T @ np.linalg.inv(P_pred[t+1])\n        \n        # Smoother update\n        m_smooth[t] = m_filt[t] + G_t @ (m_smooth[t+1] - m_pred[t+1])\n        P_smooth[t] = P_filt[t] + G_t @ (P_smooth[t+1] - P_pred[t+1]) @ G_t.T\n        \n    # --- 4. Compute Aggregate Bias for each Threshold ---\n    results = []\n    \n    # Pre-compute backward information content for all t\n    delta_P = P_filt - P_smooth\n    trace_delta_P = np.array([np.trace(dp) for dp in delta_P])\n        \n    for eps in thresholds:\n        # Determine the stopping time t_star by searching backward\n        t_star = -1\n        for t in range(T - 1, -1, -1):\n            if trace_delta_P[t] = eps:\n                t_star = t\n                break\n        \n        # Calculate aggregate bias B(eps) = sum_{t=0 to t_star} tr(Delta_P_t)\n        # If t_star is -1, the sum is empty (0.0).\n        total_bias = 0.0\n        if t_star != -1:\n            total_bias = np.sum(trace_delta_P[:t_star + 1])\n        \n        results.append(total_bias)\n        \n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3393965"}, {"introduction": "在掌握了卡尔曼平滑的理论基础和实用算法变体之后，我们现在将这些概念应用于机器人学中的一个核心问题：同时定位与地图构建（SLAM）。在这个问题中，状态向量被增广，以同时包含机器人的位姿和静态地标的位置，从而实现对两者的联合估计。这项综合性练习要求您为一个线性化的SLAM问题，分别实现递归式的RTS平滑器和批量式的正规方程求解器。通过直接比较两者的结果，您将具体地理解这两种强大范式之间的等价性，并在一个真实的应用场景中，深入探究正则化（如Levenberg-Marquardt阻尼）以及固定滞后平滑近似等实际问题 [@problem_id:3394031]。", "problem": "考虑一个用于平面机器人和两个静态路标的离散时间线性化同步定位与建图 (SLAM) 模型。时间索引 $t$ 处的增广状态为：机器人位姿 $x_t \\in \\mathbb{R}^2$ 和堆叠的路标位置 $l \\in \\mathbb{R}^4$，因此时间 $t$ 处的增广向量为 $s_t = \\begin{bmatrix} x_t \\\\ l \\end{bmatrix} \\in \\mathbb{R}^6$。机器人动力学是线性的，具有已知的控制输入序列，且路标是静态的。每个时间步的测量也是线性的，提供从机器人到每个路标的相对位置观测。所有噪声均为零均值高斯噪声，且协方差已知。要求您实现固定区间 Rauch–Tung–Striebel (RTS) 平滑，并将其得到的联合后验均值和边际协方差，与通过求解带 Levenberg–Marquardt 阻尼的批量稀疏正规方程组得到的结果进行比较。此外，您还将实现一个固定延迟平滑器，并量化其与固定区间平滑器的偏差。目标是在线性高斯情况下，展示并量化固定区间 RTS 平滑与无阻尼批量正规方程解之间的等价性，并分析阻尼和延迟对估计值和协方差恢复的影响。\n\n使用以下科学上一致且数值上合理的设置：\n\n- 时间 $t=0$ 时的初始真值位姿：$x_0^{\\text{true}} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n- 真值路标位置：$l_1^{\\text{true}} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$ 和 $l_2^{\\text{true}} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}$，因此 $l^{\\text{true}} = \\begin{bmatrix} 2 \\\\ 0 \\\\ 3 \\\\ 1 \\end{bmatrix}$。\n- 在 $t=0,1,2$ 时的控制输入：$u_0 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$，$u_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$，$u_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$。这产生了真值轨迹 $x_1^{\\text{true}} = x_0^{\\text{true}} + u_0$，$x_2^{\\text{true}} = x_1^{\\text{true}} + u_1$，$x_3^{\\text{true}} = x_2^{\\text{true}} + u_2$。\n- 机器人的过程噪声协方差：$Q_x = \\operatorname{diag}(0.01, 0.01)$。路标动力学是静态的（单位矩阵），路标的过程噪声为零。\n- 每个路标相对位置测量的测量噪声协方差：$R = \\operatorname{diag}(0.05, 0.05)$。在每个时间 $t \\in \\{0,1,2,3\\}$，堆叠的测量值为 $z_t = \\begin{bmatrix} l_1^{\\text{true}} - x_t^{\\text{true}} \\\\ l_2^{\\text{true}} - x_t^{\\text{true}} \\end{bmatrix} \\in \\mathbb{R}^4$。\n- $t=0$ 时增广状态的先验均值：$m_0 = \\begin{bmatrix} -0.5 \\\\ 0.2 \\\\ 1.5 \\\\ 0.5 \\\\ 2.5 \\\\ 2.0 \\end{bmatrix}$，对应于 $x_0$ 和 $l$。先验协方差是块对角矩阵 $P_0 = \\operatorname{diag}(0.5, 0.5, 0.5, 0.5, 0.5, 0.5)$。\n\n使用的基础理论：\n- 线性高斯状态空间建模和高斯-马尔可夫定理。\n- 针对高斯噪声线性系统的贝叶斯估计。\n- 线性模型的最小二乘最优性和正规方程。\n- Levenberg–Marquardt (LM) 阻尼，作为线性最小二乘中的 Tikhonov 正则化（无需在问题陈述中提供公式）。\n\n需要从头开始实现的任务：\n1. 根据上述设置，构建增广线性动力学模型和测量模型，对机器人和路标均使用单位转移矩阵，并将确定性控制输入应用于机器人分量。确保过程噪声仅作用于机器人分量，测量噪声作用于每个时间的两个路标相对位置测量。\n2. 实现固定区间 Rauch–Tung–Striebel (RTS) 平滑器。首先对时间 $t \\in \\{0,1,2,3\\}$ 执行卡尔曼滤波器前向传播，然后执行后向平滑传播，以获得每个时间索引处的平滑后验均值和协方差。通过对增广状态进行操作，联合平滑机器人位姿和路标。\n3. 为未知堆叠向量 $y = \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\\\ x_3 \\\\ l \\end{bmatrix} \\in \\mathbb{R}^{12}$ 构建批量最小二乘正规方程组，其来源包括：\n   - $x_0$ 和 $l$ 的先验，\n   - 动力学约束 $x_{t+1} - x_t = u_t$（对于 $t \\in \\{0,1,2\\}$），\n   - 测量方程 $z_t = \\begin{bmatrix} l_1 - x_t \\\\ l_2 - x_t \\end{bmatrix}$（对于 $t \\in \\{0,1,2,3\\}$）。\n   通过向正规方程的海森矩阵（Hessian）中加入 $\\lambda I$ 来施加 Levenberg–Marquardt 阻尼（标量参数 $\\lambda \\ge 0$）。求解批量估计值，并计算批量后验协方差，即为阻尼后海森矩阵的逆。\n4. 实现一个延迟为 $L=1$ 的固定延迟平滑器。该平滑器通过运行前向卡尔曼滤波器至时间 $t+L$，然后执行从 $t+L$ 到 $t$ 的截断后向传播，来计算时间 $t=1$ 处的平滑均值，且仅使用截至时间 $t+L=2$ 的数据。\n5. 定量比较：\n   - 在三个阻尼值 $\\lambda \\in \\{0.0, 10^{-4}, 1.0\\}$下，固定区间 RTS 在时间 $t=3$ 时对增广状态 $\\begin{bmatrix} x_3 \\\\ l \\end{bmatrix}$ 的平滑均值与批量解对应分片之间的差值的欧几里得范数。\n   - 在相同的 $\\lambda$ 值下，RTS 在时间 $t=3$ 时对 $l$ 的平滑边际协方差与批量法得到的 $l$ 的边际协方差之间差值的弗罗贝尼乌斯范数。\n   - 固定延迟（$L=1$）在时间 $t=1$ 时对增广状态 $\\begin{bmatrix} x_1 \\\\ l \\end{bmatrix}$ 的平滑均值与固定区间 RTS 在时间 $t=1$ 时的平滑均值之间差值的欧几里得范数。\n\n您的程序必须实现上述模型和计算，并为以下测试套件生成数值结果：\n- 测试用例 1：$\\lambda = 0.0$（无阻尼）。\n- 测试用例 2：$\\lambda = 10^{-4}$（轻微阻尼）。\n- 测试用例 3：$\\lambda = 1.0$（强阻尼）。\n\n对于每个测试用例，按第 5 项中指定的顺序计算三个浮点数。将三个测试用例产生的所有九个浮点数聚合到单行输出中。不涉及物理单位或角度；所有值都是无单位的。您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果（例如，$[r_1,r_2,r_3,r_4,r_5,r_6,r_7,r_8,r_9]$），其中每个 $r_i$ 是由您的实现计算出的浮点数。\n\n通过遵循给定的协方差和先验，确保科学真实性和内部一致性。从基础理论出发实现算法，不要在问题陈述中使用任何快捷公式。", "solution": "我们使用状态 $s_t = \\begin{bmatrix} x_t \\\\ l \\end{bmatrix} \\in \\mathbb{R}^6$ 对增广线性高斯系统进行建模，其中 $x_t \\in \\mathbb{R}^2$ 且 $l \\in \\mathbb{R}^4$ 堆叠了两个路标的位置。其动力学模型为\n$$\ns_{t+1} = F s_t + B u_t + w_t,\n$$\n其中 $F \\in \\mathbb{R}^{6 \\times 6}$ 是单位转移矩阵，$B \\in \\mathbb{R}^{6 \\times 2}$ 将控制 $u_t \\in \\mathbb{R}^2$ 注入到机器人位姿分量中，$w_t \\sim \\mathcal{N}(0, Q)$ 是过程噪声，且 $Q = \\operatorname{blockdiag}(Q_x, 0_{4 \\times 4})$，$Q_x = \\operatorname{diag}(0.01, 0.01)$。时间 $t$ 的测量是堆叠的相对路标位置，\n$$\nz_t = H_t s_t + v_t, \\quad v_t \\sim \\mathcal{N}(0, R_{\\text{blk}}),\n$$\n其中\n$$\nH_t = \\begin{bmatrix} -I_2  I_2  0_{2 \\times 2} \\\\ -I_2  0_{2 \\times 2}  I_2 \\end{bmatrix} \\in \\mathbb{R}^{4 \\times 6}, \\quad R_{\\text{blk}} = \\operatorname{blockdiag}(R, R), \\quad R = \\operatorname{diag}(0.05, 0.05).\n$$\n$t=0$ 时的先验为 $s_0 \\sim \\mathcal{N}(m_0, P_0)$，其中 $m_0 = \\begin{bmatrix} -0.5 \\\\ 0.2 \\\\ 1.5 \\\\ 0.5 \\\\ 2.5 \\\\ 2.0 \\end{bmatrix}$ 且 $P_0 = \\operatorname{diag}(0.5, 0.5, 0.5, 0.5, 0.5, 0.5)$。\n\n我们使用基本原理：线性高斯模型意味着后验分布也是高斯的。基于高斯假设的贝叶斯滤波产生卡尔曼滤波器，而固定区间平滑则基于高斯-马尔可夫定理和条件线性高斯关系使用后向递归。\n\n前向卡尔曼滤波器。在每个时间 $t$，我们计算预测均值和协方差：\n$$\n\\hat{m}_{t|t-1} = F m_{t-1|t-1} + B u_{t-1}, \\quad \\hat{P}_{t|t-1} = F P_{t-1|t-1} F^\\top + Q,\n$$\n按照惯例，对于 $t=0$ 有 $\\hat{m}_{0| -1} = m_0$ 和 $\\hat{P}_{0| -1} = P_0$。测量更新为\n$$\nS_t = H_t \\hat{P}_{t|t-1} H_t^\\top + R_{\\text{blk}}, \\quad K_t = \\hat{P}_{t|t-1} H_t^\\top S_t^{-1},\n$$\n$$\nm_{t|t} = \\hat{m}_{t|t-1} + K_t (z_t - H_t \\hat{m}_{t|t-1}), \\quad P_{t|t} = (I - K_t H_t) \\hat{P}_{t|t-1}.\n$$\n\n后向 Rauch–Tung–Striebel (RTS) 平滑器。对于 $t=T$（此处 $T=3$），有 $m_{T|T}^s = m_{T|T}$ 和 $P_{T|T}^s = P_{T|T}$。对于 $t=T-1,\\dots,0$，RTS 增益为\n$$\nJ_t = P_{t|t} F^\\top \\hat{P}_{t+1|t}^{-1},\n$$\n平滑后的估计值为\n$$\nm_{t|T}^s = m_{t|t} + J_t \\left(m_{t+1|T}^s - \\hat{m}_{t+1|t}\\right), \\quad P_{t|T}^s = P_{t|t} + J_t \\left(P_{t+1|T}^s - \\hat{P}_{t+1|t}\\right) J_t^\\top.\n$$\n因为 $F$ 是单位矩阵且路标是静态的，这个递归过程联合平滑了机器人和路标。\n\n批量最小二乘与正规方程。我们组合一个全局未知向量\n$$\ny = \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\\\ x_3 \\\\ l \\end{bmatrix} \\in \\mathbb{R}^{12}.\n$$\n我们构建线性方程：\n- 先验：$x_0 \\approx m_{0,x}$，协方差为 $\\operatorname{diag}(0.5, 0.5)$；$l \\approx m_{0,l}$，协方差为 $\\operatorname{diag}(0.5, 0.5, 0.5, 0.5)$。\n- $t=0,1,2$ 时的动力学：$x_{t+1} - x_t \\approx u_t$，协方差为 $Q_x$。\n- $t=0,1,2,3$ 时的测量：$l_1 - x_t \\approx z_t^{(1)}$ 和 $l_2 - x_t \\approx z_t^{(2)}$，每个 2 维向量分量的协方差为 $R$，得到一个协方差为 $R_{\\text{blk}}$ 的 4 维堆叠向量。\n\n将这些方程堆叠成 $A y \\approx b$ 的形式，并通过 $W^{1/2}$ 进行预白化，其中 $W = \\operatorname{blockdiag}(P_0^{-1}, Q_x^{-1}, R^{-1}, \\dots)$，从而得到一个加权最小二乘问题。正规方程为\n$$\nH y = g, \\quad H = A^\\top W A, \\quad g = A^\\top W b.\n$$\n使用参数 $\\lambda \\ge 0$ 的 Levenberg–Marquardt 阻尼将系统修改为\n$$\n(H + \\lambda I) y = g,\n$$\n在线性情况下这等同于 Tikhonov 正则化。批量后验协方差（在线性模型一致的高斯近似下）为\n$$\n\\Sigma_{\\text{batch}} = (H + \\lambda I)^{-1}.\n$$\n\n等价性与比较。在线性高斯情况下，当 $\\lambda = 0$ 时，固定区间 RTS 在时间 $t=3$ 处的平滑均值（限于 $\\begin{bmatrix} x_3 \\\\ l \\end{bmatrix}$）等于批量最小二乘解 $y$ 的相应分片。RTS 在时间 $t=3$ 处对 $l$ 的平滑协方差块等于从逆海森矩阵中恢复出的、限于 $l$ 索引的批量边际协方差。当 $\\lambda  0$ 时，阻尼会使批量解向零偏移，并相对于无阻尼情况增大了协方差，从而破坏了其与从原始概率模型推导出的 RTS 解的精确等价性。\n\n在时间 $t=1$ 处，延迟为 $L=1$ 的固定延迟平滑仅以截至时间 $t+L=2$ 的数据为条件。它可以这样实现：运行前向滤波器直到 $t+L$，然后应用从 $t+L$ 到 $t$ 的截断后向 RTS 递归。在时间 $t=1$ 处的固定延迟均值通常与固定区间均值不同，因为后者以更多数据（此处为时间 $t=3$ 的测量值）为条件，这为机器人和路标都引入了额外的信息。\n\n测试套件的数值实现细节：\n- 我们使用给定的真值 $x_t^{\\text{true}}$ 和 $l^{\\text{true}}$ 精确计算 $z_t$（与期望值兼容的无噪声实现）。\n- 对于每个 $\\lambda \\in \\{0.0, 10^{-4}, 1.0\\}$，我们求解批量正规方程以获得 $y_{\\lambda}$ 和 $\\Sigma_{\\text{batch},\\lambda}$。我们提取 $\\begin{bmatrix} x_3 \\\\ l \\end{bmatrix}$ 和 $l$ 的边际协方差。\n- 我们运行前向卡尔曼滤波器和后向 RTS 平滑器以获得 $m_{t|T}^s$ 和 $P_{t|T}^s$（对于 $t \\in \\{0,1,2,3\\}$），然后计算：\n  1. 欧几里得范数 $\\left\\| \\begin{bmatrix} x_3 \\\\ l \\end{bmatrix}_{\\text{RTS}} - \\begin{bmatrix} x_3 \\\\ l \\end{bmatrix}_{\\text{batch},\\lambda} \\right\\|_2$。\n  2. 弗罗贝尼乌斯范数 $\\left\\| P_{l,\\text{RTS}}(t=3) - \\Sigma_{l,\\text{batch},\\lambda} \\right\\|_F$，其中 $\\Sigma_{l,\\text{batch},\\lambda}$ 是从 $\\Sigma_{\\text{batch},\\lambda}$ 中提取的 $4 \\times 4$ 边际协方差，而 $P_{l,\\text{RTS}}(t=3)$ 是 $P_{3|T}^s$ 中对应于 $l$ 的 $4 \\times 4$ 块。\n  3. 欧几里得范数 $\\left\\| \\begin{bmatrix} x_1 \\\\ l \\end{bmatrix}_{\\text{fixed-lag},L=1} - \\begin{bmatrix} x_1 \\\\ l \\end{bmatrix}_{\\text{RTS}} \\right\\|_2$。\n\n最终程序在单行中输出九个浮点数，每个 $\\lambda$ 对应一个三元组。这展示了在无阻尼情况（$\\lambda = 0$）下的等价性、阻尼效应以及固定延迟平滑引入的偏差，同时通过 RTS 平滑和批量公式的逆海森矩阵正确地处理了边际协方差的恢复。", "answer": "```python\nimport numpy as np\n\ndef build_models():\n    # Dimensions\n    d = 2  # robot pose dimension\n    n_landmarks = 2\n    ldim = 2 * n_landmarks\n    aug_dim = d + ldim  # 6\n\n    # Ground-truth trajectory and landmarks\n    x0_true = np.array([0.0, 0.0])\n    u_list = [np.array([1.0, 0.0]), np.array([1.0, 0.0]), np.array([0.0, 1.0])]\n    x_true = [x0_true]\n    for u in u_list:\n        x_true.append(x_true[-1] + u)\n    # Now x_true: t=0..3\n    l_true = np.array([2.0, 0.0, 3.0, 1.0])  # [l1; l2]\n\n    # Measurements z_t = [l1 - x_t; l2 - x_t]\n    z_list = []\n    for t in range(4):\n        x_t = x_true[t]\n        l1 = l_true[0:2]\n        l2 = l_true[2:4]\n        z = np.concatenate([l1 - x_t, l2 - x_t])\n        z_list.append(z)\n\n    # Prior\n    m0 = np.array([-0.5, 0.2, 1.5, 0.5, 2.5, 2.0])  # [x0; l]\n    P0 = np.diag([0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n\n    # Process and measurement covariances\n    Qx = np.diag([0.01, 0.01])\n    Q_aug = np.block([\n        [Qx,               np.zeros((d, ldim))],\n        [np.zeros((ldim, d)), np.zeros((ldim, ldim))]\n    ])\n    R = np.diag([0.05, 0.05])\n    R_block = np.block([\n        [R,               np.zeros((d, d))],\n        [np.zeros((d, d)), R]\n    ])\n\n    # Dynamics matrices\n    F = np.eye(aug_dim)\n    B = np.zeros((aug_dim, d))\n    B[0:d, 0:d] = np.eye(d)\n\n    # Measurement matrix H_t is constant here\n    # H = [[-I, I, 0], [-I, 0, I]]\n    H = np.zeros((2 * d, aug_dim))\n    # block for l1 - x: rows 0:2\n    H[0:d, 0:d] = -np.eye(d)\n    H[0:d, d:d + d] = np.eye(d)\n    # block for l2 - x: rows 2:4\n    H[d:2 * d, 0:d] = -np.eye(d)\n    H[d:2 * d, d + d:d + d + d] = np.eye(d)\n    H_list = [H for _ in range(4)]\n\n    return {\n        \"d\": d,\n        \"ldim\": ldim,\n        \"aug_dim\": aug_dim,\n        \"x_true\": x_true,\n        \"l_true\": l_true,\n        \"z_list\": z_list,\n        \"m0\": m0,\n        \"P0\": P0,\n        \"Qx\": Qx,\n        \"Q_aug\": Q_aug,\n        \"R\": R,\n        \"R_block\": R_block,\n        \"F\": F,\n        \"B\": B,\n        \"H_list\": H_list,\n        \"u_list\": u_list\n    }\n\ndef kalman_rts(models):\n    d = models[\"d\"]\n    aug_dim = models[\"aug_dim\"]\n    F = models[\"F\"]\n    B = models[\"B\"]\n    Q_aug = models[\"Q_aug\"]\n    R_block = models[\"R_block\"]\n    H_list = models[\"H_list\"]\n    u_list = models[\"u_list\"]\n    z_list = models[\"z_list\"]\n    m0 = models[\"m0\"]\n    P0 = models[\"P0\"]\n\n    T = 3  # last time index\n    # Storage\n    m_pred = [None] * (T + 1)\n    P_pred = [None] * (T + 1)\n    m_filt = [None] * (T + 1)\n    P_filt = [None] * (T + 1)\n\n    # Initialize prediction at t=0 from prior\n    m_pred[0] = m0.copy()\n    P_pred[0] = P0.copy()\n\n    # Filter loop\n    for t in range(T + 1):\n        H = H_list[t]\n        z = z_list[t]\n        # Update\n        S = H @ P_pred[t] @ H.T + R_block\n        K = P_pred[t] @ H.T @ np.linalg.inv(S)\n        innov = z - H @ m_pred[t]\n        m_filt[t] = m_pred[t] + K @ innov\n        P_filt[t] = (np.eye(aug_dim) - K @ H) @ P_pred[t]\n        # Predict for next time if not last\n        if t  T:\n            u = u_list[t]\n            m_pred[t + 1] = F @ m_filt[t] + B @ u\n            P_pred[t + 1] = F @ P_filt[t] @ F.T + Q_aug\n\n    # RTS backward pass\n    m_smooth = [None] * (T + 1)\n    P_smooth = [None] * (T + 1)\n    m_smooth[T] = m_filt[T].copy()\n    P_smooth[T] = P_filt[T].copy()\n    for t in range(T - 1, -1, -1):\n        J = P_filt[t] @ F.T @ np.linalg.inv(P_pred[t + 1])\n        m_smooth[t] = m_filt[t] + J @ (m_smooth[t + 1] - m_pred[t + 1])\n        P_smooth[t] = P_filt[t] + J @ (P_smooth[t + 1] - P_pred[t + 1]) @ J.T\n\n    return m_filt, P_filt, m_smooth, P_smooth, m_pred, P_pred\n\ndef fixed_lag_smoother(models, t_query, L):\n    # Compute smoothed mean at time t_query using data only up to t_query + L\n    d = models[\"d\"]\n    aug_dim = models[\"aug_dim\"]\n    F = models[\"F\"]\n    B = models[\"B\"]\n    Q_aug = models[\"Q_aug\"]\n    R_block = models[\"R_block\"]\n    H_list = models[\"H_list\"]\n    u_list = models[\"u_list\"]\n    z_list = models[\"z_list\"]\n    m0 = models[\"m0\"]\n    P0 = models[\"P0\"]\n\n    T_end = t_query + L\n    # Forward filter up to T_end\n    m_pred = [None] * (T_end + 1)\n    P_pred = [None] * (T_end + 1)\n    m_filt = [None] * (T_end + 1)\n    P_filt = [None] * (T_end + 1)\n\n    m_pred[0] = m0.copy()\n    P_pred[0] = P0.copy()\n\n    for t in range(T_end + 1):\n        H = H_list[t]\n        z = z_list[t]\n        S = H @ P_pred[t] @ H.T + R_block\n        K = P_pred[t] @ H.T @ np.linalg.inv(S)\n        innov = z - H @ m_pred[t]\n        m_filt[t] = m_pred[t] + K @ innov\n        P_filt[t] = (np.eye(aug_dim) - K @ H) @ P_pred[t]\n        if t  T_end:\n            u = u_list[t]\n            m_pred[t + 1] = F @ m_filt[t] + B @ u\n            P_pred[t + 1] = F @ P_filt[t] @ F.T + Q_aug\n\n    # Backward smoothing from T_end down to t_query\n    m_smooth = [None] * (T_end + 1)\n    P_smooth = [None] * (T_end + 1)\n    m_smooth[T_end] = m_filt[T_end].copy()\n    P_smooth[T_end] = P_filt[T_end].copy()\n    for t in range(T_end - 1, t_query - 1, -1):\n        J = P_filt[t] @ F.T @ np.linalg.inv(P_pred[t + 1])\n        m_smooth[t] = m_filt[t] + J @ (m_smooth[t + 1] - m_pred[t + 1])\n        P_smooth[t] = P_filt[t] + J @ (P_smooth[t + 1] - P_pred[t + 1]) @ J.T\n\n    return m_smooth[t_query], P_smooth[t_query]\n\ndef batch_normal_equations(models, lam):\n    # Build A and b for prior, dynamics, measurements, then solve (H + lam I) y = g\n    d = models[\"d\"]\n    ldim = models[\"ldim\"]\n    x_true = models[\"x_true\"]\n    z_list = models[\"z_list\"]\n    Qx = models[\"Qx\"]\n    R = models[\"R\"]\n    m0 = models[\"m0\"]\n    P0 = models[\"P0\"]\n\n    # Unknown stacking: y = [x0, x1, x2, x3, l] of length 12\n    # Column index helpers\n    def idx_x(t):\n        return 2 * t, 2 * t + 2  # slice indices\n    idx_l1 = 2 * 4  # start at 8\n    idx_l2 = idx_l1 + 2  # start at 10\n\n    # Collect weighted rows\n    A_blocks = []\n    b_blocks = []\n\n    # Prior on x0\n    A_prior_x0 = np.zeros((2, 12))\n    s, e = idx_x(0)\n    A_prior_x0[:, s:e] = np.eye(2)\n    b_prior_x0 = m0[0:2]\n    # Whitening with P0_x inverse sqrt\n    P0_x = np.diag([P0[0, 0], P0[1, 1]])\n    L_prior_x = np.diag(1.0 / np.sqrt(np.diag(P0_x)))\n    A_blocks.append(L_prior_x @ A_prior_x0)\n    b_blocks.append(L_prior_x @ b_prior_x0)\n\n    # Prior on l1\n    A_prior_l1 = np.zeros((2, 12))\n    A_prior_l1[:, idx_l1:idx_l1 + 2] = np.eye(2)\n    b_prior_l1 = m0[2:4]\n    P0_l1 = np.diag([P0[2, 2], P0[3, 3]])\n    L_prior_l1 = np.diag(1.0 / np.sqrt(np.diag(P0_l1)))\n    A_blocks.append(L_prior_l1 @ A_prior_l1)\n    b_blocks.append(L_prior_l1 @ b_prior_l1)\n\n    # Prior on l2\n    A_prior_l2 = np.zeros((2, 12))\n    A_prior_l2[:, idx_l2:idx_l2 + 2] = np.eye(2)\n    b_prior_l2 = m0[4:6]\n    P0_l2 = np.diag([P0[4, 4], P0[5, 5]])\n    L_prior_l2 = np.diag(1.0 / np.sqrt(np.diag(P0_l2)))\n    A_blocks.append(L_prior_l2 @ A_prior_l2)\n    b_blocks.append(L_prior_l2 @ b_prior_l2)\n\n    # Dynamics: x_{t+1} - x_t = u_t, t=0..2\n    for t in range(3):\n        A_dyn = np.zeros((2, 12))\n        s0, e0 = idx_x(t)\n        s1, e1 = idx_x(t + 1)\n        A_dyn[:, s1:e1] = np.eye(2)\n        A_dyn[:, s0:e0] = -np.eye(2)\n        b_dyn = models[\"u_list\"][t]\n        L_dyn = np.diag(1.0 / np.sqrt(np.diag(Qx)))\n        A_blocks.append(L_dyn @ A_dyn)\n        b_blocks.append(L_dyn @ b_dyn)\n\n    # Measurements: for t=0..3, z_t = [l1 - x_t; l2 - x_t]\n    for t in range(4):\n        # First measurement: l1 - x_t = z_t[0:2]\n        A_meas1 = np.zeros((2, 12))\n        s, e = idx_x(t)\n        A_meas1[:, s:e] = -np.eye(2)\n        A_meas1[:, idx_l1:idx_l1 + 2] = np.eye(2)\n        b_meas1 = z_list[t][0:2]\n        L_meas = np.diag(1.0 / np.sqrt(np.diag(R)))\n        A_blocks.append(L_meas @ A_meas1)\n        b_blocks.append(L_meas @ b_meas1)\n\n        # Second measurement: l2 - x_t = z_t[2:4]\n        A_meas2 = np.zeros((2, 12))\n        A_meas2[:, s:e] = -np.eye(2)\n        A_meas2[:, idx_l2:idx_l2 + 2] = np.eye(2)\n        b_meas2 = z_list[t][2:4]\n        A_blocks.append(L_meas @ A_meas2)\n        b_blocks.append(L_meas @ b_meas2)\n\n    # Stack\n    A_w = np.vstack(A_blocks)\n    b_w = np.concatenate(b_blocks)\n\n    # Normal equations\n    H = A_w.T @ A_w\n    g = A_w.T @ b_w\n\n    # Damped solve\n    H_damped = H + lam * np.eye(H.shape[0])\n    y_hat = np.linalg.solve(H_damped, g)\n    Sigma_batch = np.linalg.inv(H_damped)\n\n    return y_hat, Sigma_batch\n\ndef compute_metrics(models, lam, m_smooth, P_smooth):\n    # Compare RTS smoothed [x3; l] vs batch solution slice\n    y_hat, Sigma_batch = batch_normal_equations(models, lam)\n    # Extract slices\n    x3_batch = y_hat[6:8]\n    l_batch = y_hat[8:12]\n    # RTS at t=3\n    x3_rts = m_smooth[3][0:2]\n    l_rts = m_smooth[3][2:6]\n    # Metric 1: Euclidean norm of mean difference\n    mean_diff = np.linalg.norm(np.concatenate([x3_rts, l_rts]) - np.concatenate([x3_batch, l_batch]))\n\n    # Metric 2: Frobenius norm of marginal covariance difference for l\n    Sigma_l_batch = Sigma_batch[8:12, 8:12]\n    P_l_rts = P_smooth[3][2:6, 2:6]\n    cov_l_diff = np.linalg.norm(P_l_rts - Sigma_l_batch, ord='fro')\n\n    # Metric 3: Fixed-lag mean deviation at t=1 (L=1) vs fixed-interval\n    m_lag_1, _ = fixed_lag_smoother(models, t_query=1, L=1)\n    mean_lag_diff = np.linalg.norm(m_lag_1 - m_smooth[1])\n\n    return mean_diff, cov_l_diff, mean_lag_diff\n\ndef solve():\n    models = build_models()\n    # Run RTS once (independent of damping)\n    _, _, m_smooth, P_smooth, _, _ = kalman_rts(models)\n\n    # Test suite lambdas\n    test_cases = [0.0, 1e-4, 1.0]\n\n    results = []\n    for lam in test_cases:\n        m1, m2, m3 = compute_metrics(models, lam, m_smooth, P_smooth)\n        results.extend([m1, m2, m3])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3394031"}]}