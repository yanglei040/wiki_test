{"hands_on_practices": [{"introduction": "在理论上理解了最优$k$的存在性后，我们需要转向实际应用，在实际应用中噪声的统计特性通常是未知的。本练习介绍了一种数据驱动的方法，通过监测SVD系数中的“尖峰”来确定噪声开始主导解的临界点，从而估计一个合适的截断水平。这个方法模拟了应用TSVD时的一个常见挑战，即如何在没有先验知识的情况下选择正则化参数。[@problem_id:3201000]", "problem": "给定一个线性逆问题族，其模型为 $A x \\approx b$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是病态的，而 $b \\in \\mathbb{R}^{m}$ 可能被加性噪声污染。考虑使用截断奇异值分解 (truncated SVD) 作为一种正则化策略。$A$ 的奇异值分解定义为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角元（奇异值）为非负值，满足 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_n > 0$。对于一个截断水平 $k \\in \\{1,2,\\dots,n\\}$，定义截断子空间 $\\mathcal{S}_k = \\mathrm{span}\\{v_1,\\dots,v_k\\}$，其中 $v_i$ 是右奇异向量（$V$ 的列向量），并令 $x_k$ 为 $\\mathcal{S}_k$ 中使残差范数 $\\|A x - b\\|_2$ 在 $x \\in \\mathcal{S}_k$ 上最小化的元素。\n\n你的任务是分析当 $k$ 增加时解的路径 $x_k$，特别关注具有大系数的、沿 $v_i$ 方向的分量何时进入解中。$x_k$ 中 $v_i$ 的系数是 $x_k$ 在基 $\\{v_i\\}$ 中展开的第 $i$ 个分量。对于每个 $i$，将系数幅值序列定义为随着 $k$ 增长的这些系数的绝对值。在实践中，当 $b$ 含有噪声时，对应于小奇异值的系数可能会变得很大，因为残差分量与左奇异向量对齐，并被 $1/\\sigma_i$ 放大。这种现象与不稳定性的出现有关，并通常在系数序列中表现为“系数尖峰”。\n\n按如下纯粹的算法术语定义一个尖峰检测规则。令 $c_i$ 表示当截断从 $k=i-1$ 扩展到 $k=i$ 时出现的、与 $v_i$ 相关联的系数（因此 $c_i$ 是 $x_i$ 中乘以 $v_i$ 的系数）。设 $p=5$、$\\alpha=3$ 和 $\\beta=2$。令基线为前 $p$ 个系数绝对值的均值，即 $\\mathrm{baseline} = \\frac{1}{p} \\sum_{i=1}^{p} |c_i|$。在第一个满足 $|c_i| > \\alpha \\cdot \\mathrm{baseline}$ 和 $|c_i| > \\beta \\cdot |c_{i-1}|$ 两个条件的索引 $i>p$ 处，声明存在一个尖峰。如果不存在这样的索引，则报告 $-1$。\n\n你的程序必须仅从奇异值分解和限制于子空间的最小二乘最小化的定义出发：\n- 通过利用 $U$ 和 $V$ 的正交性求解在 $\\mathcal{S}_k$ 上的约束最小二乘问题，推导随着 $k$ 增加而进入 $x_k$ 的系数 $c_i$ 的形式。\n- 实现上述尖峰检测规则，以确定第一个尖峰索引 $k_{\\star}$。\n\n测试套件。实现以下3个测试用例，每个用例都通过确定性伪随机构造完全指定。在每个用例中，奇异值都是严格递减的，并由一个确保病态性的方案生成。通过显式奇异值分解来构造 $A$：通过对具有给定随机种子的标准正态矩阵应用 QR 分解，生成独立的类 Haar 正交矩阵 $U$ 和 $V$；定义 $\\Sigma$ 使其对角线上具有指定的奇异值；然后设置 $A = U_{[:,1:n]} \\Sigma V^{\\top}$。通过指定系数 $\\hat{x}_i$ 并在右奇异向量基中构造真实解 $x_{\\mathrm{true}} = V \\hat{x}$，其中 $\\hat{x} = (\\hat{x}_1,\\dots,\\hat{x}_n)^{\\top}$。然后设置 $b = A x_{\\mathrm{true}} + \\varepsilon$，其中噪声向量 $\\varepsilon$ 具有零均值和标准差 $\\sigma_{\\mathrm{noise}}$ 的独立正态分布分量；定义 $\\sigma_{\\mathrm{noise}} = \\mathrm{level} \\cdot \\|A x_{\\mathrm{true}}\\|_2 / \\sqrt{m}$，因此噪声相对于干净数据进行缩放。本问题不使用角度。不涉及物理单位。\n\n- 用例1（理想情况）：$m=50$，$n=40$，随机种子 $1234$，奇异值 $\\sigma_i = 10^{-(i-1)/8}$（$i=1,\\dots,n$），系数 $\\hat{x}_i = \\exp(-(i-1)/7)$（$i=1,\\dots,n$），噪声水平 $\\mathrm{level} = 10^{-3}$。\n- 用例2（边界情况，无噪声）：$m=50$，$n=40$，随机种子 $2021$，奇异值 $\\sigma_i = 10^{-(i-1)/8}$，系数 $\\hat{x}_i = \\exp(-(i-1)/7)$，噪声水平 $\\mathrm{level} = 0$。\n- 用例3（边缘情况，更强的病态性和更大的噪声）：$m=80$，$n=60$，随机种子 $999$，奇异值 $\\sigma_i = 10^{-(i-1)/6}$，系数 $\\hat{x}_i = \\exp(-(i-1)/10)$，噪声水平 $\\mathrm{level} = 2 \\cdot 10^{-2}$。\n\n对于每个用例，计算与 $v_i$ 的增量包含相关联的系数序列 $c_i$，并应用 $p=5, \\alpha=3, \\beta=2$ 的尖峰检测规则。每个用例所需的输出是第一个尖峰出现的整数索引 $k_{\\star}$（对 $i$ 使用从1开始的索引）；如果未检测到尖峰，则该用例输出 $-1$。\n\n最终输出格式。你的程序应生成单行输出，其中包含三个用例按顺序排列的结果，形式为方括号内以逗号分隔的列表，例如 $[k_1,k_2,k_3]$。不应打印任何额外文本。", "solution": "所提出的问题是有效的。这是计算科学中一个定义明确的任务，它基于线性逆问题和使用截断奇异值分解（TSVD）进行正则化的既定理论。该问题在科学上是合理的、自洽的、客观的，并为得到唯一解提供了所有必要的数据和算法定义。\n\n问题的核心是确定 TSVD 解的系数，然后应用一个特定的算法规则来检测由噪声引起的不稳定性。我们首先从第一性原理出发推导这些系数的公式。\n\n问题在于找到在给定截断水平 $k$ 下使残差范数最小化的解 $x_k$。解 $x_k$ 被约束在子空间 $\\mathcal{S}_k = \\mathrm{span}\\{v_1, \\dots, v_k\\}$ 中，其中 $v_i$ 是矩阵 $A$ 的右奇异向量。\n$$\nx_k = \\arg\\min_{x \\in \\mathcal{S}_k} \\|A x - b\\|_2^2\n$$\n任何向量 $x \\in \\mathcal{S}_k$ 都可以唯一地表示为标准正交基向量 $\\{v_1, \\dots, v_k\\}$ 的线性组合：\n$$\nx = \\sum_{i=1}^k c_i v_i\n$$\n其中 $c_i$ 是我们需要确定的系数。将此表示代入目标函数，我们寻求最小化：\n$$\n\\left\\| A \\left(\\sum_{i=1}^k c_i v_i\\right) - b \\right\\|_2^2 = \\left\\| \\left(\\sum_{i=1}^k c_i A v_i\\right) - b \\right\\|_2^2\n$$\n根据奇异值分解的定义 $A = U \\Sigma V^{\\top}$，我们有基本关系 $A v_i = \\sigma_i u_i$（$i=1, \\dots, n$），其中 $u_i$ 是左奇异向量，$\\sigma_i$ 是奇异值。将此代入表达式得到：\n$$\n\\left\\| \\left(\\sum_{i=1}^k c_i \\sigma_i u_i\\right) - b \\right\\|_2^2\n$$\n左奇异向量 $\\{u_i\\}_{i=1}^m$ 构成 $\\mathbb{R}^m$ 的一个标准正交基。一个向量的欧几里得范数的平方是其在任何标准正交基中坐标的平方和。我们可以将范数内的向量 $r = (\\sum_{i=1}^k c_i \\sigma_i u_i) - b$ 在左奇异向量基中表示。$r$ 沿着 $u_j$ 的坐标是 $u_j^{\\top} r$。\n因此，范数的平方为：\n$$\n\\|r\\|_2^2 = \\sum_{j=1}^m (u_j^{\\top} r)^2 = \\sum_{j=1}^m \\left( u_j^{\\top} \\left( \\sum_{i=1}^k c_i \\sigma_i u_i \\right) - u_j^{\\top} b \\right)^2\n$$\n利用标准正交性 $u_j^{\\top} u_i = \\delta_{ij}$（克罗内克 δ），表达式得以简化。\n对于 $j \\in \\{1, \\dots, k\\}$，项 $u_j^{\\top} (\\sum_{i=1}^k c_i \\sigma_i u_i)$ 变为 $c_j \\sigma_j$。\n对于 $j \\in \\{k+1, \\dots, m\\}$，项 $u_j^{\\top} (\\sum_{i=1}^k c_i \\sigma_i u_i)$ 变为 $0$。\n这使我们可以将对 $j$ 的求和拆分：\n$$\n\\|r\\|_2^2 = \\sum_{j=1}^k (c_j \\sigma_j - u_j^{\\top} b)^2 + \\sum_{j=k+1}^m (- u_j^{\\top} b)^2\n$$\n为了使该表达式相对于系数 $\\{c_1, \\dots, c_k\\}$ 最小化，我们只需考虑第一个和式，因为第二个和式与这些系数无关。第一个和式是非负项之和。当每一项单独为零时，该和式达到其最小值 $0$。因此，对于每个 $j \\in \\{1, \\dots, k\\}$，我们必须有：\n$$\nc_j \\sigma_j - u_j^{\\top} b = 0\n$$\n解出 $c_j$ 得到 TSVD 解系数的著名公式：\n$$\nc_j = \\frac{u_j^{\\top} b}{\\sigma_j}\n$$\n问题将 $c_i$ 定义为当截断水平从 $i-1$ 增加到 $i$ 时进入解的系数。我们的推导表明，基向量 $v_i$ 的系数由上述公式给出，并且不依赖于总的截断水平 $k$（只要 $k \\ge i$）。因此，要分析的系数序列就是 $\\{c_i\\}_{i=1}^n$。\n\n在确定了系数的形式之后，问题的其余部分是算法性的。\n1.  对于每个测试用例，我们从其指定的奇异值分解构造矩阵 $A$。这涉及生成随机正交矩阵 $U$ 和 $V$ 以及具有指定奇异值的对角矩阵 $\\Sigma$。矩阵 $A$ 由 $A = U_{econ} \\Sigma_{n \\times n} V^{\\top}$ 形成，其中 $U_{econ}$ 由 $U$ 的前 $n$ 列组成。\n2.  在右奇异向量基中构造“真实”解 $x_{\\mathrm{true}}$，并计算“干净”数据向量 $b_{\\mathrm{clean}} = A x_{\\mathrm{true}}$。\n3.  添加噪声以获得最终数据向量 $b = b_{\\mathrm{clean}} + \\varepsilon$，其中噪声标准差相对于干净信号的范数进行缩放。\n4.  使用推导出的公式 $c_i = (u_i^{\\top} b)/\\sigma_i$ 计算系数 $c_i$（$i=1, \\dots, n$）。\n5.  将指定的尖峰检测规则应用于系数绝对值序列 $|c_i|$。使用参数 $p=5$, $\\alpha=3$ 和 $\\beta=2$，我们从前 $p$ 个系数计算基线：$\\mathrm{baseline} = \\frac{1}{p} \\sum_{i=1}^{p} |c_i|$。然后我们搜索第一个满足 $|c_i| > \\alpha \\cdot \\mathrm{baseline}$ 和 $|c_i| > \\beta \\cdot |c_{i-1}|$ 两个条件的索引 $i > p$。首次出现的位置的基于1的索引即为结果。如果未找到这样的索引，结果为 $-1$。\n\n对问题陈述中指定的三个测试用例中的每一个都实施此流程。", "answer": "```python\nimport numpy as np\n\ndef run_case(m, n, seed, sigma_denominator, x_hat_denominator, level, p, alpha, beta):\n    \"\"\"\n    Runs a single test case for spike detection in TSVD.\n\n    Args:\n        m (int): Number of rows for matrix A.\n        n (int): Number of columns for matrix A.\n        seed (int): Random seed for reproducibility.\n        sigma_denominator (float): Denominator in the exponent for singular values.\n        x_hat_denominator (float): Denominator in the exponent for true coefficients.\n        level (float): Relative noise level.\n        p (int): Number of initial coefficients for baseline calculation.\n        alpha (float): Multiplier for the baseline threshold.\n        beta (float): Multiplier for the previous coefficient threshold.\n\n    Returns:\n        int: The 1-based index of the first detected spike, or -1 if no spike is found.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Construct matrices U, Sigma, V\n    # Generate Haar-like orthogonal matrices from QR of standard normal matrices\n    U_full, _ = np.linalg.qr(rng.standard_normal((m, m)))\n    V, _ = np.linalg.qr(rng.standard_normal((n, n)))\n    \n    # Use the economy-size U, which has orthonormal columns\n    U_econ = U_full[:, :n]\n\n    # Singular values (sigma_i = 10**(-(i-1)/C))\n    indices = np.arange(1, n + 1)\n    s_vals = 10.0**(-(indices - 1) / sigma_denominator)\n    Sigma_n = np.diag(s_vals)\n\n    # 2. Construct A, x_true, and b\n    A = U_econ @ Sigma_n @ V.T\n\n    # True solution coefficients in the V basis (x_hat_i = exp(-(i-1)/C))\n    x_hat = np.exp(-(indices - 1) / x_hat_denominator)\n    \n    # True solution vector\n    x_true = V @ x_hat\n\n    # Clean data vector b\n    b_clean = A @ x_true\n\n    # Additive noise\n    if level > 0.0:\n        norm_b_clean = np.linalg.norm(b_clean)\n        sigma_noise = level * norm_b_clean / np.sqrt(m)\n        noise = rng.normal(0.0, sigma_noise, size=m)\n        b = b_clean + noise\n    else:\n        b = b_clean\n\n    # 3. Compute TSVD solution coefficients\n    # c_i = (u_i^T b) / sigma_i\n    uT_b = U_econ.T @ b\n    c = uT_b / s_vals\n    c_abs = np.abs(c)\n\n    # 4. Apply spike detection rule\n    if n = p:\n        return -1\n\n    # Baseline using the first p coefficients (0-indexed to p-1)\n    baseline = np.mean(c_abs[0:p])\n\n    # Search for spike for indices i > p (1-based), which is i >= p (0-based)\n    for i in range(p, n):\n        cond1 = c_abs[i] > alpha * baseline\n        cond2 = c_abs[i] > beta * c_abs[i-1]\n        \n        if cond1 and cond2:\n            return i + 1  # Return 1-based index\n\n    return -1\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define spike detection parameters\n    p = 5\n    alpha = 3.0\n    beta = 2.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: m=50, n=40, seed=1234, sigma_i=10^-(i-1)/8, x_hat_i=exp(-(i-1)/7), level=1e-3\n        {\"m\": 50, \"n\": 40, \"seed\": 1234, \"sigma_denom\": 8.0, \"x_hat_denom\": 7.0, \"level\": 1e-3},\n        # Case 2: m=50, n=40, seed=2021, sigma_i=10^-(i-1)/8, x_hat_i=exp(-(i-1)/7), level=0\n        {\"m\": 50, \"n\": 40, \"seed\": 2021, \"sigma_denom\": 8.0, \"x_hat_denom\": 7.0, \"level\": 0.0},\n        # Case 3: m=80, n=60, seed=999, sigma_i=10^-(i-1)/6, x_hat_i=exp(-(i-1)/10), level=2e-2\n        {\"m\": 80, \"n\": 60, \"seed\": 999, \"sigma_denom\": 6.0, \"x_hat_denom\": 10.0, \"level\": 2e-2},\n    ]\n\n    results = []\n    for case in test_cases:\n        k_star = run_case(\n            m=case[\"m\"],\n            n=case[\"n\"],\n            seed=case[\"seed\"],\n            sigma_denominator=case[\"sigma_denom\"],\n            x_hat_denominator=case[\"x_hat_denom\"],\n            level=case[\"level\"],\n            p=p,\n            alpha=alpha,\n            beta=beta\n        )\n        results.append(k_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3201000"}, {"introduction": "最后，我们将关注TSVD的数值实现问题。虽然TSVD解可以从正规方程 $A^\\top A x = A^\\top b$ 推导得出，但这种方法在数值上通常是不稳定的。本练习将通过一个受控实验，直接比较基于矩阵$A$的SVD和基于$A^\\top A$的特征值分解这两种计算方法的表现，从而揭示后一种方法如何放大误差，尤其是在原问题本身是病态或含噪的情况下。[@problem_id:3428383]", "problem": "考虑一个线性逆问题，其目标是从由矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 产生的含噪数据 $b \\in \\mathbb{R}^m$ 中恢复未知向量 $x \\in \\mathbb{R}^n$。基本依据是以下一组经过充分检验的事实和定义：\n\n- 矩阵 $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角线上包含非负奇异值。\n- 最小二乘的法方程为 $A^\\top A x = A^\\top b$，其中 $A^\\top A$ 是对称半正定矩阵。\n- 截断奇异值分解 (TSVD) 正则化通过投影到由主奇异向量张成的子空间来构造一个估计量，抑制与小奇异值相关的方向，以减少噪声放大。\n- 构建法方程 $A^\\top A$ 会使奇异值平方，这会增大条件数，并可能放大噪声引起的扰动，尤其是在奇异值聚集或近似相等时。\n- 在没有噪声的情况下，$A^\\top A$ 的特征向量与 $A$ 的右奇异向量一致；然而，$A$ 中的噪声会使 $A^\\top A$ 的特征空间变得病态，因此在 $A^\\top A$ 上进行截断特征分解可能比直接在 $A$ 上进行 TSVD 的数值稳定性差。\n\n你的任务是在一个受控数值实验中，评估以下两种用于 $x$ 的正则化估计量的稳定性和准确性：\n- 直接通过含噪矩阵 $A$ 的 SVD 计算的 TSVD 估计量，\n- 通过 $A^\\top A$ (法方程) 的特征分解计算的截断特征分解估计量。\n\n构造具有指定奇异值谱的合成矩阵，该谱按幂律衰减，并可选择性地嵌入近似相等的奇异值簇以引发特征空间病态。向 $A$ 中添加受控噪声，并可选择性地向 $b$ 中添加噪声。对于每个测试用例，使用相同的截断水平计算两种估计量，并比较它们相对于真实值 $x_{\\mathrm{true}}$ 的相对重构误差。\n\n将使用的定义：\n- 令 $A_{\\mathrm{true}} = U_{m \\times n} \\Sigma V^\\top$ 是一个合成矩阵，其中 $U_{m \\times n}$ ( $\\mathbb{R}^{m \\times m}$ 中正交矩阵的前 $n$ 列) 是标准正交的，$V \\in \\mathbb{R}^{n \\times n}$ 是标准正交的，奇异值 $\\sigma_i$ 遵循 $\\sigma_i = i^{-p}$ 并被归一化以使 $\\max_i \\sigma_i = 1$。可选择通过为一组连续的索引设置相等的 $\\sigma_i$ 来创建一个奇异值簇。\n- 令 $A = A_{\\mathrm{true}} + \\alpha E$ 为含噪前向算子，其中 $E$ 的元素是独立同分布的、均值为零、方差为一的高斯分布，并经过缩放使其均方根大小为 $1/\\sqrt{mn}$，从而噪声水平由 $\\alpha$ 控制。\n- 令 $x_{\\mathrm{true}} \\in \\mathbb{R}^n$ 是从单位球面上均匀随机抽取的单位范数向量。\n- 令 $b = A_{\\mathrm{true}} x_{\\mathrm{true}} + \\beta \\eta$，其中 $\\eta \\in \\mathbb{R}^m$ 是与 $E$ 具有相同缩放约定高斯噪声，$\\beta$ 控制数据噪声。\n- 具有截断参数 $k$ 的 TSVD 估计量为\n$$\nx_{\\mathrm{TSVD}}(k) \\;=\\; V_k \\Sigma_k^{-1} U_k^\\top b,\n$$\n其中 $U_k$、$\\Sigma_k$ 和 $V_k$ 表示 $A$ 的前 $k$ 个主奇异向量和奇异值。\n- 具有截断参数 $k$ 的截断特征分解估计量由 $A^\\top A = Q \\Lambda Q^\\top$ 计算得出\n$$\nx_{\\mathrm{TE}}(k) \\;=\\; Q_k \\Lambda_k^{-1} Q_k^\\top A^\\top b,\n$$\n其中 $Q_k$ 和 $\\Lambda_k$ 表示与 $A^\\top A$ 的 $k$ 个最大特征值对应的特征向量和特征值。\n\n对于每个测试用例，计算相对误差\n$$\n\\varepsilon_{\\mathrm{TSVD}} \\;=\\; \\frac{\\| x_{\\mathrm{TSVD}}(k) - x_{\\mathrm{true}} \\|_2}{\\|x_{\\mathrm{true}}\\|_2}, \n\\qquad\n\\varepsilon_{\\mathrm{TE}} \\;=\\; \\frac{\\| x_{\\mathrm{TE}}(k) - x_{\\mathrm{true}} \\|_2}{\\|x_{\\mathrm{true}}\\|_2}\n$$\n并报告比率 $\\rho = \\varepsilon_{\\mathrm{TE}} / \\varepsilon_{\\mathrm{TSVD}}$。\n\n实现以下步骤：\n1. 通过对随机高斯矩阵进行 $QR$ 分解来生成正交矩阵 $U$ 和 $V$，并使用指定的奇异值谱和任何指定的奇异值簇来构造 $A_{\\mathrm{true}}$。\n2. 如上所述形成含噪矩阵 $A$，并从 $A_{\\mathrm{true}}$ 和 $x_{\\mathrm{true}}$ 构造 $b$，可选择性加入数据噪声。\n3. 通过 $A$ 的 SVD 计算 $x_{\\mathrm{TSVD}}(k)$，通过 $A^\\top A$ 的特征分解计算 $x_{\\mathrm{TE}}(k)$。\n4. 为每个测试用例计算比率 $\\rho$。\n\n程序必须为以下五个旨在探究不同稳定性区间的测试用例生成比率：\n- 案例 1 (理想情况，低算子噪声): $m=80$, $n=60$, $p=2.0$, $\\alpha=10^{-3}$, $\\beta=10^{-6}$, $k=10$, 无奇异值簇。\n- 案例 2 (中等算子噪声): $m=80$, $n=60$, $p=2.0$, $\\alpha=5 \\times 10^{-2}$, $\\beta=10^{-6}$, $k=10$, 无奇异值簇。\n- 案例 3 (高算子噪声，小截断): $m=120$, $n=100$, $p=2.5$, $\\alpha=10^{-1}$, $\\beta=0$, $k=5$, 无奇异值簇。\n- 案例 4 (方阵系统，更强衰减，中等噪声，大截断): $m=60$, $n=60$, $p=3.0$, $\\alpha=10^{-2}$, $\\beta=10^{-6}$, $k=25$, 无奇异值簇。\n- 案例 5 (聚集奇异值以引发特征空间病态): $m=100$, $n=80$, $p=3.0$, $\\alpha=5 \\times 10^{-2}$, $\\beta=10^{-6}$, $k=15$, 索引 $i \\in \\{12,13,\\dots,19\\}$ 处有连续的相等奇异值簇。\n\n你的程序应生成单行输出，其中包含五个测试用例的比率 $\\rho$，格式为方括号内以逗号分隔的列表 (例如，\"[r1,r2,r3,r4,r5]\")。不涉及物理单位。不适用角度。不得使用百分比；所有输出必须是原始浮点数。\n\n该数值实验应突显出，特别是在存在算子噪声和聚集奇异值的情况下，基于 $A^\\top A$ 特征分解的截断可能比直接应用于 $A$ 的 TSVD 稳定性差，通常会导致更大的重构误差。通过在生成随机矩阵和向量之前固定随机种子来确保可复现性。", "solution": "任务是进行一个数值实验，比较解决线性逆问题的两种正则化方法的稳定性和准确性：直接应用于系统矩阵 $A$ 的截断奇异值分解 (TSVD)，以及应用于法方程矩阵 $A^\\top A$ 的截断特征分解。其核心假设基于成熟的数值分析原理，即构建法方程矩阵 $A^\\top A$ 会使 $A$ 的奇异值平方，从而使其条件数也平方。这会放大数值误差，尤其是在存在噪声和奇异值聚集的情况下，使得 $A^\\top A$ 的特征分解成为一个比 $A$ 本身的 SVD 更不稳定的正则化基础。\n\n该实验结构严谨。我们将生成具有受控属性的合成数据，包括“真实”矩阵的奇异值谱、损坏矩阵的噪声水平以及数据向量中的噪声水平。对于一组预定义的测试用例，我们将计算两种方法的解估计，并通过比较它们的相对重构误差来评估其性能。\n\n该方法实现如下：\n\n1.  **合成数据生成**：我们为每个案例构建一个测试环境。\n    - **真实矩阵 $A_{\\mathrm{true}}$**：创建一个具有预定义奇异值谱的矩阵 $A_{\\mathrm{true}} \\in \\mathbb{R}^{m \\times n}$。这是通过构造其奇异值分解 $A_{\\mathrm{true}} = U \\Sigma_{\\mathrm{true}} V^\\top$ 来实现的。\n        - 正交矩阵 $U \\in \\mathbb{R}^{m \\times n}$ (具有标准正交列) 和 $V \\in \\mathbb{R}^{n \\times n}$ 是通过对适当大小的随机高斯矩阵应用 QR 分解生成的。这是生成随机正交矩阵的标准方法。\n        - 奇异值 $\\sigma_i$ 根据幂律衰减设置，即 $\\sigma_i = i^{-p}$，其中 $i=1, \\dots, n$。由于当 $i=1$ 时最大值为 $1^{-p}=1$，该序列已按要求归一化。\n        - 对于特定的测试用例，通过将一组连续索引的 $\\sigma_i$ 设置为常数值来创建一个奇异值簇，旨在在 $A^\\top A$ 中产生病态的特征空间。\n    - **真实解 $x_{\\mathrm{true}}$**：通过创建一个元素来自标准正态分布的随机向量，并将其归一化以使其欧几里得范数为 $1$，来生成一个真实值向量 $x_{\\mathrm{true}} \\in \\mathbb{R}^n$。\n    - **噪声生成**：引入加性高斯噪声。\n        - 噪声矩阵 $E \\in \\mathbb{R}^{m \\times n}$ 的元素从 $\\mathcal{N}(0, 1/(mn))$ 中抽取。这种缩放确保了噪声元素的预期均方根大小受到控制。\n        - 噪声向量 $\\eta \\in \\mathbb{R}^m$ 的元素从 $\\mathcal{N}(0, 1/m)$ 中抽取，遵循一致的缩放约定。\n    - **含噪系统**：最终的前向算子和数据向量形成为 $A = A_{\\mathrm{true}} + \\alpha E$ 和 $b = A_{\\mathrm{true}} x_{\\mathrm{true}} + \\beta \\eta$，其中 $\\alpha$ 和 $\\beta$ 是控制噪声水平的参数。\n\n2.  **估计量计算**：\n    - **TSVD 估计量 $x_{\\mathrm{TSVD}}(k)$**：计算含噪矩阵 $A$ 的 SVD，$A = U_A \\Sigma_A V_A^\\top$。然后使用截断伪逆的公式估计解：\n    $$x_{\\mathrm{TSVD}}(k) = V_{A,k} \\Sigma_{A,k}^{-1} U_{A,k}^\\top b$$\n    其中 $U_{A,k}$、$\\Sigma_{A,k}$ 和 $V_{A,k}$ 代表与 $A$ 的 $k$ 个最大奇异值对应的分量。\n    - **截断特征分解 (TE) 估计量 $x_{\\mathrm{TE}}(k)$**：首先，形成法方程矩阵 $C = A^\\top A$。然后计算其特征分解 $C = Q \\Lambda Q^\\top$。解估计为：\n    $$x_{\\mathrm{TE}}(k) = Q_k \\Lambda_k^{-1} Q_k^\\top A^\\top b$$\n    其中 $Q_k$ 和 $\\Lambda_k$ 对应于 $k$ 个最大的特征值及其相关联的特征向量。由于 $C$ 是对称半正定的，我们使用 `scipy.linalg.eigh`，它对此类矩阵进行了优化。它返回的特征值按升序排序，因此必须反转它们以获得最大的特征值。\n\n3.  **误差评估与比较**：对于每个估计量，计算相对重构误差。由于 $\\|x_{\\mathrm{true}}\\|_2 = 1$，公式简化为：\n    $$\\varepsilon_{\\mathrm{TSVD}} = \\| x_{\\mathrm{TSVD}}(k) - x_{\\mathrm{true}} \\|_2$$\n    $$\\varepsilon_{\\mathrm{TE}} = \\| x_{\\mathrm{TE}}(k) - x_{\\mathrm{true}} \\|_2$$\n    TE 方法相对于 TSVD 方法的性能通过比率 $\\rho = \\varepsilon_{\\mathrm{TE}} / \\varepsilon_{\\mathrm{TSVD}}$ 来量化。比率 $\\rho > 1$ 表示在该特定情况下 TSVD 估计量更准确。\n\n为确保实验的可复现性，在运行测试用例之前，为伪随机数生成器使用一个固定的种子。该实现将整个过程整合到一个脚本中，该脚本迭代五个指定的测试用例，为每个用例计算比率 $\\rho$，并报告结果。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import qr, svd, eigh\n\ndef solve():\n    \"\"\"\n    Solves the problem by running a numerical experiment to compare TSVD and\n    truncated eigendecomposition on the normal equations for a series of test cases.\n    \"\"\"\n    # Fix the random seed for reproducibility as required by the problem.\n    np.random.seed(0)\n\n    # Define the five test cases specified in the problem statement.\n    # Format: (m, n, p, alpha, beta, k, cluster_range)\n    # cluster_range is a tuple (start, end) for 0-based indexing or None.\n    test_cases = [\n        # Case 1: Happy path, low operator noise\n        (80, 60, 2.0, 1e-3, 1e-6, 10, None),\n        # Case 2: Moderate operator noise\n        (80, 60, 2.0, 5e-2, 1e-6, 10, None),\n        # Case 3: High operator noise, small truncation\n        (120, 100, 2.5, 1e-1, 0.0, 5, None),\n        # Case 4: Square system, stronger decay, larger truncation\n        (60, 60, 3.0, 1e-2, 1e-6, 25, None),\n        # Case 5: Clustered singular values\n        (100, 80, 3.0, 5e-2, 1e-6, 15, (11, 19)),\n    ]\n\n    results = []\n\n    for case_params in test_cases:\n        m, n, p, alpha, beta, k, cluster_range = case_params\n\n        # 1. Generate synthetic data (A_true, x_true)\n        # Generate random orthogonal matrices U and V via QR decomposition\n        G_m = np.random.randn(m, m)\n        U_full, _ = qr(G_m)\n        U = U_full[:, :n]\n\n        G_n = np.random.randn(n, n)\n        V, _ = qr(G_n)\n\n        # Generate true singular values\n        indices = np.arange(1, n + 1)\n        s_true = indices**(-p)\n        # The sequence is already normalized with max(s_true) = 1.\n\n        # Apply cluster if specified\n        if cluster_range:\n            start, end = cluster_range\n            s_true[start:end] = s_true[start]\n\n        # Construct A_true using thin SVD representation\n        A_true = U @ (np.diag(s_true) @ V.T)\n\n        # Generate true solution vector x_true\n        x_true_unnormalized = np.random.randn(n)\n        x_true = x_true_unnormalized / np.linalg.norm(x_true_unnormalized)\n\n        # 2. Form noisy operator A and data vector b\n        # Generate noise matrix E and noise vector eta\n        E = np.random.randn(m, n) / np.sqrt(m * n)\n        A = A_true + alpha * E\n        \n        b = A_true @ x_true\n        if beta > 0:\n            eta = np.random.randn(m) / np.sqrt(m)\n            b += beta * eta\n\n        # 3. Compute TSVD estimator x_tsvd\n        Ua, sa, Vta = svd(A, full_matrices=False)\n        U_k = Ua[:, :k]\n        s_inv_k = 1.0 / sa[:k]\n        V_k = Vta[:k, :].T\n        \n        # Efficient computation of x_tsvd = V_k @ diag(s_inv_k) @ U_k.T @ b\n        tmp_tsvd = U_k.T @ b\n        tmp_tsvd = tmp_tsvd * s_inv_k\n        x_tsvd = V_k @ tmp_tsvd\n\n        # 4. Compute Truncated Eigendecomposition estimator x_te\n        AtA = A.T @ A\n        # eigh returns eigenvalues in ascending order\n        eigvals, eigvecs = eigh(AtA)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        eigvals_sorted = eigvals[::-1]\n        eigvecs_sorted = eigvecs[:, ::-1]\n\n        # Truncate to the k largest eigenpairs\n        Lambda_k_inv_diag = 1.0 / eigvals_sorted[:k]\n        Q_k = eigvecs_sorted[:, :k]\n        Atb = A.T @ b\n\n        # Efficient computation of x_te = Q_k @ diag(Lambda_k_inv) @ Q_k.T @ Atb\n        tmp_te = Q_k.T @ Atb\n        tmp_te = tmp_te * Lambda_k_inv_diag\n        x_te = Q_k @ tmp_te\n\n        # 5. Compute relative errors and their ratio\n        # Since ||x_true||_2 = 1, relative error is ||x_hat - x_true||_2\n        eps_tsvd = np.linalg.norm(x_tsvd - x_true)\n        eps_te = np.linalg.norm(x_te - x_true)\n\n        # Handle the case where eps_tsvd might be zero to avoid division by zero\n        if eps_tsvd == 0:\n            ratio = 1.0 if eps_te == 0 else np.inf\n        else:\n            ratio = eps_te / eps_tsvd\n        \n        results.append(ratio)\n\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3428383"}]}