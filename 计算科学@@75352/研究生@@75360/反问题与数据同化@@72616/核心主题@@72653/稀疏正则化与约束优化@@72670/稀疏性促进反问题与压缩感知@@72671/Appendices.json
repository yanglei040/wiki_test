{"hands_on_practices": [{"introduction": "本节练习将我们带回凸优化的基础，以建立坚实的理论根基。在使用数值算法解决大规模问题之前，通过对偶理论手动求解一个小规模问题，可以获得宝贵的直觉。通过推导一个简单基追踪问题的对偶问题，并利用最优性条件找到解，您将精确地看到 $\\ell_1$ 范数的结构如何引导出稀疏解 [@problem_id:3420230]。", "problem": "考虑一个数据同化场景，其中一个未知的二维状态向量 $x \\in \\mathbb{R}^{2}$ 由单个线性传感器观测。观测算子由矩阵 $A \\in \\mathbb{R}^{1 \\times 2}$ 表示，测量数据为 $y \\in \\mathbb{R}$。为了促进恢复状态的稀疏性，我们求解基追踪（Basis Pursuit, BP）逆问题，该问题在满足观测约束的条件下最小化 $x$ 的 $\\ell_{1}$ 范数。具体来说，取\n$$\nA = \\begin{pmatrix} 2  -1 \\end{pmatrix}, \\quad y = 3,\n$$\n并考虑BP问题\n$$\n\\min_{x \\in \\mathbb{R}^{2}} \\|x\\|_{1} \\quad \\text{subject to} \\quad A x = y.\n$$\n从凸分析和对偶性的基本原理出发，利用凸共轭、对偶范数和鞍点最优性条件的定义来：\n1. 通过拉格朗日函数消去原始变量，并借助 $\\ell_{\\infty}$ 范数确定对偶可行集，从而推导出与上述BP公式相关的对偶问题。\n2. 显式地求解得到的对偶问题，以获得最优乘子。\n3. 通过 $\\ell_{1}$ 范数的次梯度刻画来强制执行可行性和互补松弛性，从而恢复原始最小化子。\n\n将你的最终答案表示为原始最小化子 $x^{\\star}$，并精确地写成一个具有有理数元素的单行向量。不需要四舍五入，也无需报告单位。", "solution": "用户希望我使用对偶理论来解决一个基追踪（BP）问题。\n\n**问题分解：**\n\n1.  **原始问题：**\n    -   对 $x \\in \\mathbb{R}^2$ 最小化 $\\|x\\|_1$。\n    -   约束条件为 $Ax = y$。\n    -   给定：$A = \\begin{pmatrix} 2  -1 \\end{pmatrix}$ 且 $y = 3$。\n\n2.  **任务：**\n    -   **任务1：推导对偶问题。**\n        -   使用拉格朗日函数。\n        -   消去原始变量 $x$。\n        -   使用 $\\ell_\\infty$ 范数确定对偶可行集。这暗示了 $\\ell_1$ 范数和 $\\ell_\\infty$ 范数互为对偶的关系。\n    -   **任务2：求解对偶问题。**\n        -   找到最优对偶变量（拉格朗日乘子）。\n    -   **任务3：恢复原始解。**\n        -   使用可行性（$Ax^\\star = y$）。\n        -   使用互补松弛性，这将涉及到 $\\ell_1$ 范数的次梯度。\n\n**分步计划：**\n\n**第一部分：验证**\n\n1.  **提取已知条件：**\n    -   $x \\in \\mathbb{R}^2$ 是未知状态向量。\n    -   $A = \\begin{pmatrix} 2  -1 \\end{pmatrix} \\in \\mathbb{R}^{1 \\times 2}$ 是观测算子。\n    -   $y = 3 \\in \\mathbb{R}$ 是测量数据。\n    -   问题是：$\\min_{x \\in \\mathbb{R}^{2}} \\|x\\|_{1} \\quad \\text{subject to} \\quad A x = y$。\n    -   $\\|x\\|_1 = |x_1| + |x_2|$。\n    -   任务要求使用凸分析、对偶性、凸共轭、对偶范数、鞍点最优性、次梯度等概念。\n\n2.  **验证：**\n    -   **科学依据：** 该问题是凸优化领域的一个标准练习，特别是在压缩感知和逆问题领域。所涉及的概念（基追踪、$\\ell_1$ 范数、拉格朗日对偶）在数学和信号处理中是公认的。是的，它是有根据的。\n    -   **适定性：** 这是一个线性规划问题（可以重写为线性规划）。目标函数是凸的（$\\ell_1$ 范数），约束集是一个非空仿射子空间（$\\mathbb{R}^2$ 中的一条直线）。最小化子保证存在。其是否唯一是该问题的一个有趣之处，但寻找*一个*最小化子的问题是适定的。在这种情况下，该问题的构造使其具有唯一解，我们很可能会看到这一点。\n    -   **客观性：** 语言精确且数学化。没有主观陈述。\n    -   **无效性检查清单：**\n        1.  没有科学/事实上的不健全之处。\n        2.  与稀疏性促进逆问题的主题直接相关。这是一个经典例子。\n        3.  设置是完整的。$A$ 和 $y$ 已给出。问题已完全指定。\n        4.  条件在物理上并非不可能。这是一个数学问题。\n        5.  不是不适定的。\n        6.  不是微不足道的。它需要对对偶理论有扎实的理解。这不是伪深刻的问题，而是一个标准的教科书级别问题。\n        7.  可以通过数学推导进行验证。\n\n3.  **结论：** 该问题是**有效**的。我将继续进行求解。\n\n**第二部分：求解推导**\n\n**任务1：推导对偶问题**\n\n1.  **构造拉格朗日函数：**\n    问题是 $\\min_x \\|x\\|_1$ 约束于 $Ax - y = 0$。\n    拉格朗日函数为 $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\lambda^T(Ax - y)$。\n    这里，$x \\in \\mathbb{R}^2$ 是原始变量，$\\lambda \\in \\mathbb{R}^1$（一个标量）是对偶变量（拉格朗日乘子）。\n    $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\lambda(Ax - y) = \\|x\\|_1 + \\lambda A x - \\lambda y$。\n    由于 $\\lambda$ 是标量，$A$ 是行向量，所以 $\\lambda A$ 是行向量。所以这里应该是 $\\lambda (A_{11} x_1 + A_{12} x_2 - y)$。\n    更标准的写法是内积形式 $\\langle \\lambda, Ax - y \\rangle$。\n    因为 $\\mathbb{R}^1$ 的对偶空间是 $\\mathbb{R}^1$，所以 $\\lambda$ 只是一个标量。\n    $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\lambda ( (2, -1) \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} - 3 ) = \\|x\\|_1 + \\lambda(2x_1 - x_2 - 3)$。\n    整理各项：\n    $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + (2\\lambda x_1 - \\lambda x_2) - 3\\lambda$。\n    这可以用点积写成：$\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\langle A^T \\lambda, x \\rangle - \\langle y, \\lambda \\rangle$。\n    这里，$A^T = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$。$A^T \\lambda = \\begin{pmatrix} 2\\lambda \\\\ -\\lambda \\end{pmatrix}$。\n    所以，$\\langle A^T \\lambda, x \\rangle = (2\\lambda) x_1 + (-\\lambda) x_2$。这与前面一致。\n\n2.  **求拉格朗日对偶函数：**\n    对偶函数 $g(\\lambda)$ 是拉格朗日函数关于原始变量 $x$ 的下确界：\n    $g(\\lambda) = \\inf_{x \\in \\mathbb{R}^2} \\mathcal{L}(x, \\lambda) = \\inf_{x \\in \\mathbb{R}^2} (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle - y \\lambda)$。\n    项 $-y\\lambda$ 相对于 $x$ 是常数。\n    $g(\\lambda) = -y \\lambda + \\inf_{x \\in \\mathbb{R}^2} (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle)$。\n\n3.  **使用凸共轭：**\n    一个函数 $f(x)$ 的凸共轭是 $f^*(z) = \\sup_x (\\langle z, x \\rangle - f(x))$。\n    所以，$\\inf_x (f(x) - \\langle z, x \\rangle) = - \\sup_x (\\langle z, x \\rangle - f(x)) = -f^*(z)$。\n    在我们的问题中，$f(x) = \\|x\\|_1$。我们有 $\\inf_x (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle)$。\n    这可以写成 $\\inf_x(f(x) - \\langle -A^T\\lambda, x \\rangle)$。\n    所以，我们需要 $\\ell_1$ 范数的共轭。\n    令 $z = -A^T \\lambda$。我们需要计算 $f^*(z)$。\n    $f^*(z) = \\sup_x (\\langle z, x \\rangle - \\|x\\|_1) = \\sup_x \\left( \\sum_i z_i x_i - \\sum_i |x_i| \\right) = \\sum_i \\sup_{x_i} (z_i x_i - |x_i|)$。\n    考虑项 $\\sup_{x_i} (z_i x_i - |x_i|)$。\n    - 如果 $|z_i|  1$，比如说 $z_i  1$，我们可以选择 $x_i  0$。那么 $z_i x_i - |x_i| = (z_i - 1)x_i$。当 $x_i \\to \\infty$ 时，该式趋于 $\\infty$。\n    - 如果 $z_i  -1$，我们可以选择 $x_i  0$。那么 $z_i x_i - |x_i| = z_i x_i - (-x_i) = (z_i+1)x_i$。当 $x_i \\to -\\infty$ 时，该式趋于 $\\infty$。\n    - 如果 $|z_i| \\le 1$，那么 $z_i x_i \\le |z_i||x_i| \\le |x_i|$。所以 $z_i x_i - |x_i| \\le 0$。上确界在 $x_i=0$ 时达到，值为 $0$。\n    所以，$\\ell_1$ 范数的共轭是一个示性函数：\n    $f^*(z) = (\\|\\cdot\\|_1)^*(z) = \\begin{cases} 0  \\text{if } \\|z\\|_{\\infty} \\le 1 \\\\ \\infty  \\text{if } \\|z\\|_{\\infty}  1 \\end{cases}$。\n    这里，$\\|z\\|_\\infty = \\max_i |z_i|$。\n\n4.  **回到对偶函数：**\n    $g(\\lambda) = -y \\lambda + \\inf_{x \\in \\mathbb{R}^2} (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle)$。\n    令 $v = A^T \\lambda$。下确界项是 $\\inf_x (\\|x\\|_1 + \\langle v, x \\rangle) = -\\sup_x(-\\langle v, x \\rangle - \\|x\\|_1) = -\\sup_x(\\langle -v, x \\rangle - \\|x\\|_1)$。\n    这是 $\\|\\cdot\\|_1$ 的共轭在 $-v = -A^T\\lambda$ 处取值的负数。\n    所以，$\\inf_x (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle) = -(\\|\\cdot\\|_1)^*(-A^T\\lambda)$。\n    根据上一步，这等于：\n    $\\begin{cases} 0  \\text{if } \\|-A^T\\lambda\\|_{\\infty} \\le 1 \\\\ -\\infty  \\text{if } \\|-A^T\\lambda\\|_{\\infty}  1 \\end{cases}$。\n    注意 $\\| -v \\|_\\infty = \\|v\\|_\\infty$，所以条件是 $\\|A^T\\lambda\\|_{\\infty} \\le 1$。\n\n5.  **构建对偶问题：**\n    对偶问题是最大化对偶函数 $g(\\lambda)$：\n    $\\max_{\\lambda \\in \\mathbb{R}} g(\\lambda)$。\n    由于在可行集之外 $g(\\lambda) = -\\infty$，这等价于：\n    $\\max_{\\lambda \\in \\mathbb{R}} \\quad -y \\lambda$\n    约束于 $\\quad \\|A^T \\lambda\\|_{\\infty} \\le 1$。\n\n    至此完成任务1。让我们用具体数值写出来。\n    $A = \\begin{pmatrix} 2  -1 \\end{pmatrix}$，所以 $A^T = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$。\n    $A^T \\lambda = \\begin{pmatrix} 2\\lambda \\\\ -\\lambda \\end{pmatrix}$。\n    $\\|A^T \\lambda\\|_{\\infty} = \\max(|2\\lambda|, |-\\lambda|) = \\max(2|\\lambda|, |\\lambda|) = 2|\\lambda|$。\n    约束条件是 $2|\\lambda| \\le 1$，即 $|\\lambda| \\le 1/2$。\n    对偶问题是：\n    $\\max_{\\lambda \\in \\mathbb{R}} \\quad -3\\lambda$\n    约束于 $\\quad -1/2 \\le \\lambda \\le 1/2$。\n\n**任务2：求解对偶问题**\n\n-   我们需要在区间 $[-1/2, 1/2]$ 上最大化函数 $f(\\lambda) = -3\\lambda$。\n-   函数 $f(\\lambda)$ 是一个关于 $\\lambda$ 的递减线性函数。\n-   要最大化它，我们必须选择 $\\lambda$ 的最小可能值。\n-   在可行集 $[-1/2, 1/2]$ 中 $\\lambda$ 的最小值是 $\\lambda = -1/2$。\n-   所以，对偶最优解是 $\\lambda^\\star = -1/2$。\n-   对偶问题的最优值是 $-3(\\lambda^\\star) = -3(-1/2) = 3/2$。\n-   根据强对偶性（对于这个凸问题成立，例如Slater条件满足），原始问题的最优值也是 $3/2$。所以，$\\|x^\\star\\|_1 = 3/2$。这是一个很好的检验。\n\n**任务3：恢复原始解**\n\n我们使用Karush-Kuhn-Tucker（KKT）条件，或更一般地，鞍点最优性条件。\n在最优点 $(x^\\star, \\lambda^\\star)$，我们有：\n$\\mathcal{L}(x^\\star, \\lambda^\\star) = \\inf_x \\mathcal{L}(x, \\lambda^\\star) = \\sup_\\lambda \\mathcal{L}(x^\\star, \\lambda)$。\n\n第一个条件 $\\mathcal{L}(x^\\star, \\lambda^\\star) = \\inf_x \\mathcal{L}(x, \\lambda^\\star)$ 意味着 $x^\\star$ 在固定最优对偶变量的情况下最小化拉格朗日函数。\n$x^\\star \\in \\arg\\min_x (\\|x\\|_1 + \\langle A^T \\lambda^\\star, x \\rangle - y\\lambda^\\star)$。\n这等价于 $x^\\star \\in \\arg\\min_x (\\|x\\|_1 + \\langle A^T \\lambda^\\star, x \\rangle)$。\n这个无约束最小化问题的最优性条件是 $0$ 必须在目标函数于 $x^\\star$ 处的次微分中。\n$0 \\in \\partial (\\|x^\\star\\|_1 + \\langle A^T \\lambda^\\star, x^\\star \\rangle) = \\partial \\|x^\\star\\|_1 + A^T \\lambda^\\star$。\n这给出了条件：\n$-A^T \\lambda^\\star \\in \\partial \\|x^\\star\\|_1$。\n\n让我们计算 $-A^T \\lambda^\\star$：\n$\\lambda^\\star = -1/2$。\n$A^T = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$。\n$-A^T \\lambda^\\star = - \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} (-1/2) = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} (1/2) = \\begin{pmatrix} 1 \\\\ -1/2 \\end{pmatrix}$。\n令这个向量为 $z = \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1/2 \\end{pmatrix}$。\n\n现在我们需要 $\\ell_1$ 范数的次微分。\n$\\partial \\|x\\|_1 = \\{ z \\in \\mathbb{R}^n \\mid z_i = \\text{sgn}(x_i) \\text{ if } x_i \\ne 0, \\text{ and } z_i \\in [-1, 1] \\text{ if } x_i=0 \\}$。\n条件 $z \\in \\partial \\|x^\\star\\|_1$ 意味着：\n- 从 $z_1 = 1$：由于 $|z_1|=1$，我们知道如果 $x_1^\\star \\ne 0$，那么 $\\text{sgn}(x_1^\\star)=1$。因此 $x_1^\\star \\ge 0$。\n- 从 $z_2 = -1/2$：由于 $|z_2|1$，我们必须有 $x_2^\\star=0$。\n\n到目前为止，$x^\\star = \\begin{pmatrix} x^\\star_1 \\\\ 0 \\end{pmatrix}$ 且 $x^\\star_1 \\ge 0$。\n\n原始可行性：\n$A x^\\star = y$。\n$(2, -1) \\begin{pmatrix} x^\\star_1 \\\\ 0 \\end{pmatrix} = 3$。\n$2 x^\\star_1 = 3$。\n$x^\\star_1 = 3/2$。\n\n这个结果 $x_1^\\star=3/2$ 与条件 $x_1^\\star \\ge 0$ 一致。\n因此，原始最小化子是 $x^\\star = \\begin{pmatrix} 3/2 \\\\ 0 \\end{pmatrix}$。\n最终答案必须是一个具有有理数元素的行向量：$\\begin{pmatrix} \\frac{3}{2}  0 \\end{pmatrix}$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3}{2}  0\n\\end{pmatrix}\n}\n$$", "id": "3420230"}, {"introduction": "在对稀疏解有了理论理解的基础上，本实践将焦点转移到一个实用且广泛应用的算法上。我们将处理 LASSO 问题，它在数据保真度与稀疏性之间取得平衡，这在现实世界应用中非常常见。您将从零开始实现迭代软阈值算法（ISTA），并在不同情况下进行测试，观察其收敛行为，并理解步长等关键参数所扮演的重要角色 [@problem_id:3420203]。", "problem": "考虑复合凸目标函数 $f(x) = g(x) + \\lambda \\|x\\|_{1}$，其中 $g(x)$ 是一个可微凸函数，其梯度 $\\nabla g$ 是 Lipschitz 连续的，并且 $\\lambda \\geq 0$。在标准的稀疏线性逆问题模型中，令 $g(x) = \\tfrac{1}{2}\\|A x - b\\|_{2}^{2}$，其中给定 $A \\in \\mathbb{R}^{m \\times n}$ 和 $b \\in \\mathbb{R}^{m}$。梯度为 $\\nabla g(x) = A^{\\top}(A x - b)$，$\\nabla g$ 的一个有效 Lipschitz 常数为 $L = \\lambda_{\\max}(A^{\\top}A)$，其中 $\\lambda_{\\max}$ 表示最大特征值。用于求解 $f(x)$ 的迭代软阈值算法 (ISTA) 在步长 $\\alpha$ 满足 $\\alpha \\leq 1/L$ 的条件下，通过以下方式更新 $x$：\n$$\nx^{k+1} = S_{\\lambda \\alpha}\\left(x^{k} - \\alpha \\nabla g(x^{k})\\right),\n$$\n其中 $S_{\\tau}$ 是坐标级软阈值算子，其定义为 $S_{\\tau}(u)_{i} = \\operatorname{sign}(u_{i}) \\max(|u_{i}| - \\tau, 0)$。\n\n从零向量 $x^{0} = 0$ 开始，对以下每个测试用例，实现固定迭代次数 $T$ 的 ISTA 算法。对于每个测试用例，精确计算 $L = \\lambda_{\\max}(A^{\\top}A)$，使用提供的因子 $\\eta$ 设置 $\\alpha = \\eta/L$，运行 ISTA 算法 $T$ 次迭代，并记录目标函数值序列 $f(x^{k})$，其中 $k = 0, 1, \\dots, T$。使用欧几里得范数 $\\|\\cdot\\|_{2}$ 和 1-范数 $\\|\\cdot\\|_{1}$。下面的条目是精确的有理数值。不适用任何物理单位。\n\n测试套件：\n- 用例 1 (一般良态，边界步长)：\n  - $A \\in \\mathbb{R}^{4 \\times 6}$ 为\n    $$\n    A = \\begin{bmatrix}\n    1  0  1  0  2  -1 \\\\\n    0  1  -1  2  0  1 \\\\\n    2  -1  0  1  1  0 \\\\\n    0  2  1  -1  0  1\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{4}$ 为 $b = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ -1 \\end{bmatrix}$。\n  - $\\lambda = 0.1$。\n  - $T = 10$。\n  - $\\eta = 1.0$ (因此 $\\alpha = 1/L$)。\n- 用例 2 (秩亏传感，零数据，保守步长)：\n  - $A \\in \\mathbb{R}^{3 \\times 5}$ 为\n    $$\n    A = \\begin{bmatrix}\n    1  0  1  0  2 \\\\\n    0  1  0  1  1 \\\\\n    1  0  1  0  2\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{3}$ 为 $b = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$。\n  - $\\lambda = 0.2$。\n  - $T = 8$。\n  - $\\eta = 0.9$ (因此 $\\alpha = 0.9/L$)。\n- 用例 3 (对角传感，强稀疏性惩罚，边界步长)：\n  - $A \\in \\mathbb{R}^{5 \\times 5}$ 为\n    $$\n    A = \\begin{bmatrix}\n    1  0  0  0  0 \\\\\n    0  0.5  0  0  0 \\\\\n    0  0  2  0  0 \\\\\n    0  0  0  1.5  0 \\\\\n    0  0  0  0  0.8\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{5}$ 为 $b = \\begin{bmatrix} 1 \\\\ -1 \\\\ 2 \\\\ -2 \\\\ 0.5 \\end{bmatrix}$。\n  - $\\lambda = 0.5$。\n  - $T = 8$。\n  - $\\eta = 1.0$ (因此 $\\alpha = 1/L$)。\n- 用例 4 (中度正则化关闭，低于边界)：\n  - $A \\in \\mathbb{R}^{4 \\times 4}$ 为\n    $$\n    A = \\begin{bmatrix}\n    2  -1  0  1 \\\\\n    0  1  2  -1 \\\\\n    1  0  -1  2 \\\\\n    -2  1  0  1\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{4}$ 为 $b = \\begin{bmatrix} 1 \\\\ -2 \\\\ 0 \\\\ 3 \\end{bmatrix}$。\n  - $\\lambda = 0$。\n  - $T = 6$。\n  - $\\eta = 0.8$ (因此 $\\alpha = 0.8/L$)。\n\n对于每个用例，输出两项：目标函数值列表 $[f(x^{0}), f(x^{1}), \\dots, f(x^{T})]$ 和一个布尔值，该布尔值指示序列是否为非增的（即对于所有 $k$ 都满足 $f(x^{k+1}) \\leq f(x^{k})$ 的单调递减）。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身是一个形式为 $[\\text{目标序列}, \\text{是否单调}]$ 的双元素列表。例如，总输出格式为 $[[\\cdots, \\cdots],[\\cdots, \\cdots],[\\cdots, \\cdots],[\\cdots, \\cdots]]$，不含任何额外文本。", "solution": "这个问题要求我们实现迭代软阈值算法（ISTA）来解决LASSO问题，并在四个不同的测试用例上运行它。对于每个用例，我们需要计算目标函数值在迭代过程中的序列，并验证该序列是否单调非增。\n\n**算法核心步骤**\n\n对于每个测试用例，我们遵循以下步骤：\n\n1.  **参数初始化**：\n    -   根据问题描述，获取矩阵 $A$、向量 $b$、正则化参数 $\\lambda$、迭代次数 $T$ 以及步长因子 $\\eta$。\n    -   初始化解向量为零向量：$x^0 = 0$。\n\n2.  **计算利普希茨常数 $L$**：\n    -   计算矩阵 $A^\\top A$。\n    -   由于 $A^\\top A$ 是一个实对称半正定矩阵，其所有特征值都是非负实数。我们计算其最大特征值 $\\lambda_{\\max}(A^\\top A)$，这便是梯度 $\\nabla g(x)$ 的一个有效利普希茨常数 $L$。\n\n3.  **设置算法参数**：\n    -   根据公式 $\\alpha = \\eta / L$ 计算步长。\n    -   计算软阈值算子所需的阈值 $\\tau = \\lambda \\alpha$。\n\n4.  **执行ISTA迭代**：\n    -   创建一个空列表来存储目标函数值。\n    -   循环 $k$ 从 0 到 $T$：\n        a.  **计算目标函数值**：计算当前迭代点 $x^k$ 的目标函数值 $f(x^k) = \\frac{1}{2}\\|A x^k - b\\|_{2}^{2} + \\lambda \\|x^k\\|_{1}$，并将其存入列表中。\n        b.  **更新解向量**（如果 $k  T$）：\n            i.  计算梯度：$\\nabla g(x^k) = A^{\\top}(A x^k - b)$。\n            ii. 执行梯度下降步骤：$u = x^k - \\alpha \\nabla g(x^k)$。\n            iii. 执行近端步骤（软阈值）：$x^{k+1} = S_{\\tau}(u)$，其中 $S_\\tau$ 是按元素应用的软阈值算子。\n\n5.  **检查单调性**：\n    -   迭代完成后，检查存储的目标函数值序列是否满足 $f(x^{k+1}) \\le f(x^{k})$ 对所有 $k \\in \\{0, \\dots, T-1\\}$ 成立。理论上，当步长 $\\alpha \\le 1/L$ 时（即 $\\eta \\le 1$），ISTA保证目标函数值非增。所有测试用例都满足此条件。\n\n6.  **格式化输出**：\n    -   将得到的目标函数值序列和单调性检查的布尔值组合成一个列表。\n    -   对所有四个测试用例重复此过程，并将所有结果汇总成最终要求的格式。\n\n**用例分析**\n- **用例1**: 一个通用的、良态的问题，步长设置在收敛理论的边界上（$\\eta=1.0$）。\n- **用例2**: 一个秩亏的传感矩阵（第一行和第三行相同），数据为零。这模拟了测量信息不足的情况。由于 $b=0$ 且 $\\lambda > 0$，LASSO的唯一解是 $x=0$。算法应迅速收敛到零解，目标函数值保持为零。\n- **用例3**: 传感矩阵是对角阵，这使得问题可以按分量分解。我们可以预期算法会快速收敛。\n- **用例4**: 正则化被关闭（$\\lambda=0$），问题退化为标准的最小二乘问题。ISTA也因此退化为梯度下降法。", "answer": "[[[3.0,1.597349141014902,1.2599728512530132,1.109315513476313,1.0260485981504938,0.9754876611382413,0.9431872166948074,0.9213190802287908,0.9056260742587572,0.8938928091176228,0.8849081267568541],True],[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],True],[[5.445,1.25,0.7625,0.7625,0.7625,0.7625,0.7625,0.7625,0.7625],True],[[7.0,1.967999999999999,1.07725952,0.803774641604096,0.7107128522779878,0.679165248530356,0.6680459955776633],True]]", "id": "3420203"}, {"introduction": "稀疏性促进方法的有效性取决于一个关键假设：我们所寻找的信号是“可压缩的”。本练习将这一关键概念形式化。通过分析一个系数按特定速率衰减的信号模型，您将推导出一个关于信号能被其最大的少数分量近似得多好的量化界限，从而将可压缩性的抽象概念与最佳 k 项逼近误差的具体衰减率联系起来 [@problem_id:3420224]。", "problem": "考虑一个在标准正交基中表示的信号 $x \\in \\ell_{2}$，其系数经过非增重排后的幅值 $|x_{(1)}| \\ge |x_{(2)}| \\ge \\cdots$ 满足 $|x_{(i)}| \\le C i^{-p}$（对所有 $i \\in \\mathbb{N}$），其中常数 $C0$ 且 $p1$。在反问题和压缩感知（CS）的背景下，最佳k项$\\ell_{2}$逼近误差定义为\n$$\n\\sigma_{k}(x)_{2} := \\min_{\\substack{S \\subset \\mathbb{N} \\\\ |S| = k}} \\left\\|x - x_{S}\\right\\|_{2},\n$$\n其中 $x_{S}$ 表示在索引集 $S$ 上与 $x$ 一致而在其他位置为零的向量。请从核心定义以及关于非增重排和级数比较的成熟结论出发，推导 $\\sigma_{k}(x)_{2}$ 关于 $k$、$C$ 和 $p$ 的一个显式上界，然后确定其当 $k \\to \\infty$ 时的主阶渐近衰减率。请将此衰减率解释为 $x$ 的可压缩性的一种度量，即最佳k项逼近误差随 $k$ 下降的速度，并说明 $p$ 在此解释中的作用。你的最终答案必须是单个关于 $k$、$C$ 和 $p$ 的闭式解析表达式，该表达式能捕捉 $\\sigma_{k}(x)_{2}$ 在 $k \\to \\infty$ 时的主阶渐近行为。无需四舍五入，也不涉及物理单位。", "solution": "首先对问题进行验证，以确保其具有科学依据、是适定的且客观的。\n\n### 步骤1：提取已知条件\n-   信号：$x \\in \\ell_{2}$。\n-   假设在标准正交基中表示。\n-   系数幅值的非增重排：$|x_{(1)}| \\ge |x_{(2)}| \\ge \\cdots$。\n-   系数衰减上界：对所有 $i \\in \\mathbb{N}$，$|x_{(i)}| \\le C i^{-p}$。\n-   常数：$C  0$ 且 $p  1$。\n-   最佳k项$\\ell_{2}$逼近误差的定义：$\\sigma_{k}(x)_{2} := \\min_{\\substack{S \\subset \\mathbb{N} \\\\ |S| = k}} \\left\\|x - x_{S}\\right\\|_{2}$，其中 $x_S$ 保留 $x$ 在索引集 $S$ 上的系数，而在其他位置为零。\n\n### 步骤2：使用已知条件进行验证\n该问题在数学上是严谨的，并且完全属于逼近理论在反问题和压缩感知中的应用领域。其中系数呈多项式衰减的信号模型是可压缩信号的标准模型。条件 $p  1$ 确保了信号属于 $\\ell_2$，因为 $\\|x\\|_2^2 = \\sum_{i=1}^\\infty |x_{(i)}|^2 \\le \\sum_{i=1}^\\infty (C i^{-p})^2 = C^2 \\sum_{i=1}^\\infty i^{-2p}$，这是一个收敛的p级数，因为指数 $2p  2  1$。最佳k项逼近误差的定义是标准的。该问题是自洽的、无歧义的，并要求基于基本原理进行推导。它没有违反任何科学或数学定律，是适定的。\n\n### 步骤3：结论与行动\n该问题有效。将提供完整解答。\n\n### 上界与渐近率的推导\n\n最佳k项$\\ell_{2}$逼近误差 $\\sigma_{k}(x)_{2}$ 通过选择 $x$ 的 $k$ 个最大幅值系数的索引集 $S$ 来最小化。这是逼近理论中的一个基础结论。非增重排 $|x_{(1)}| \\ge |x_{(2)}| \\ge \\cdots$ 恰好提供了这些最大的系数。因此，最优集 $S$ 对应于这个重排序列的前 $k$ 项。\n\n误差向量 $x - x_S$ 由不属于前 $k$ 个最大系数的那些系数组成。在标准正交基中，$\\ell_2$ 范数的平方是系数幅值平方的和（Parseval 恒等式）。因此，误差平方是“尾部”系数的平方和：\n$$\n(\\sigma_{k}(x)_{2})^2 = \\sum_{i=k+1}^{\\infty} |x_{(i)}|^2\n$$\n我们已知重排后系数幅值的界：$|x_{(i)}| \\le C i^{-p}$，其中常数 $C  0$ 且 $p  1$。将此不等式代入误差平方的表达式中，得到一个上界：\n$$\n(\\sigma_{k}(x)_{2})^2 \\le \\sum_{i=k+1}^{\\infty} (C i^{-p})^2 = C^2 \\sum_{i=k+1}^{\\infty} i^{-2p}\n$$\n为了求此上界的闭式表达式，我们可以用积分来界定这个和。对于一个正的、递减的函数 $f(t)$，和 $\\sum_{i=n+1}^{\\infty} f(i)$ 的上界是积分 $\\int_{n}^{\\infty} f(t) dt$。这里，我们使用函数 $f(t) = t^{-2p}$，它在 $t  0$ 时是正的且递减的，并且我们的和从 $i = k+1$ 开始。因此，我们有：\n$$\n\\sum_{i=k+1}^{\\infty} i^{-2p} \\le \\int_{k}^{\\infty} t^{-2p} dt\n$$\n现在我们计算该积分。由于 $p  1$，指数 $2p  2$，这确保了积分收敛。\n$$\n\\int_{k}^{\\infty} t^{-2p} dt = \\left[ \\frac{t^{-2p+1}}{-2p+1} \\right]_{k}^{\\infty} = \\lim_{b \\to \\infty} \\frac{b^{1-2p}}{1-2p} - \\frac{k^{1-2p}}{1-2p}\n$$\n由于 $1-2p  -1$，极限项为 $0$。该积分的计算结果为：\n$$\n\\int_{k}^{\\infty} t^{-2p} dt = - \\frac{k^{1-2p}}{1-2p} = \\frac{k^{1-2p}}{2p-1}\n$$\n将此结果代回我们的误差平方不等式，得到：\n$$\n(\\sigma_{k}(x)_{2})^2 \\le C^2 \\left( \\frac{k^{1-2p}}{2p-1} \\right)\n$$\n对两边取平方根，得到 $\\sigma_{k}(x)_{2}$ 的显式上界：\n$$\n\\sigma_{k}(x)_{2} \\le \\sqrt{C^2 \\frac{k^{1-2p}}{2p-1}} = \\frac{C}{\\sqrt{2p-1}} k^{\\frac{1-2p}{2}}\n$$\n这个上界也决定了当 $k \\to \\infty$ 时的主阶渐近衰减率。和 $\\sum_{i=k+1}^{\\infty} i^{-2p}$ 与积分 $\\int_{k}^{\\infty} t^{-2p} dt$ 是渐近等价的。也就是说，当 $k \\to \\infty$ 时，$\\sum_{i=k+1}^{\\infty} i^{-2p} \\sim \\frac{k^{1-2p}}{2p-1}$。因此，表达式 $\\frac{C}{\\sqrt{2p-1}} k^{\\frac{1-2p}{2}}$ 代表了最紧的一般渐近上界，并捕捉了这类信号逼近误差的主阶行为。\n\n### 衰减率的解释\n\n逼近误差的渐近行为是 $\\sigma_{k}(x)_{2} \\sim O(k^{\\frac{1-2p}{2}})$。$k$ 的指数是 $\\frac{1}{2}-p$。由于 $p  1$，指数 $\\frac{1}{2}-p$ 是一个负数，具体来说小于 $-\\frac{1}{2}$。这证实了随着逼近项数 $k$ 的增加，逼近误差 $\\sigma_{k}(x)_{2}$ 收敛到 $0$，这对于任何 $\\ell_2$ 中的信号都是必需的。\n\n参数 $p$ 决定了这种收敛的速度。一个更大的 $p$ 值对应于信号系数更快的衰减。这导致了一个更负的指数 $\\frac{1}{2}-p$，从而意味着随着 $k$ 的增加，逼近误差 $\\sigma_{k}(x)_{2}$ 的衰减更为迅速。\n\n在压缩感知的背景下，如果一个信号的最佳k项逼近误差衰减得很快，则该信号被认为是“可压缩的”。因此，参数 $p$ 可作为信号可压缩性的度量。具有较大 $p$ 值的信号更具可压缩性，这意味着它们可以被极少数的基函数精确逼近。这种性质是从有限数量的测量值中恢复此类信号的能力的基础。", "answer": "$$\\boxed{\\frac{C}{\\sqrt{2p-1}} k^{\\frac{1-2p}{2}}}$$", "id": "3420224"}]}