{"hands_on_practices": [{"introduction": "在贝叶斯反问题中，一种常见且直观的MCMC策略是使用先验分布作为提议机制。本练习将引导你推导由此产生的接受概率，揭示似然函数如何“校正”或重新加权先验样本。这在数据同化中，尤其是在完美模型情景下，是一项基础技术 [@problem_id:3362467]。", "problem": "考虑一个贝叶斯序贯数据同化问题，其中包含 $t=0,1,\\dots,T$ 的隐状态 $x_t \\in \\mathbb{R}^d$ 和观测值 $y_{1:T} = (y_1,\\dots,y_T)$。假设在一个完美模型设定中，隐动态是确定性的：存在一个已知的映射 $F_t:\\mathbb{R}^d \\to \\mathbb{R}^d$，使得对于 $t=1,\\dots,T$，有 $x_t = F_t(x_{t-1})$，并且在 $x_0$ 上有一个初始先验密度 $p_0(x_0)$。在给定隐状态的条件下，观测值是条件独立的，其似然因子为 $\\ell_t(x_t) = p(y_t \\mid x_t)$，$t=1,\\dots,T$。因此，在给定观测值的条件下，初始条件的贝叶斯后验正比于 $p_0(x_0)\\prod_{t=1}^T \\ell_t(x_t(x_0))$，其中 $x_t(x_0)$ 表示通过模型从 $x_0$ 传播得到的在时间 $t$ 的确定性状态。\n\n您在初始条件 $x_0$ 上实现一个独立 Metropolis–Hastings (IMH) 算法，使用建议分布 $q(x_0') = p_0(x_0')$。在提出 $x_0'$ 后，您通过模型对其进行确定性传播，以获得候选轨迹 $x_{1:T}'$。请仅使用基本原理（贝叶斯法则、模型-观测结构的马尔可夫性质，以及刻画 Metropolis-Hastings 接受准则的细致平衡条件），推导 Metropolis–Hastings 接受概率 $\\alpha(x_0 \\to x_0')$ 的闭式解析表达式，该概率在这种完美模型设定下使得 $x_0$ 的后验分布保持不变。\n\n然后，仍然从第一性原理出发，解释如果隐动态包含具有转移密度 $f(x_t \\mid x_{t-1})$ 的模型误差，并且您使用一个独立的建议分布，该分布通过 $x_0' \\sim p_0(\\cdot)$ 采样，然后通过一个可能不同的转移密度 $g(x_t \\mid x_{t-1})$ 进行传播以生成一条完整的建议路径 $x_{1:T}'$，那么 Hastings 比率将如何修改。您必须清楚地说明在 Hastings 比率中哪些因子被抵消，哪些因子保留下来。您的最终答案必须是针对完美模型接受概率 $\\alpha(x_0 \\to x_0')$ 的单一闭式解析表达式；不需要数值，也无需四舍五入。", "solution": "问题陈述已经过验证，被认为是可靠、适定且有科学依据的。它展示了 Metropolis-Hastings 算法在贝叶斯数据同化背景下的一个标准应用，尽管并非微不足道。我们将基于第一性原理进行完整推导。\n\n任何 Metropolis-Hastings (MH) 算法的核心是细致平衡条件，该条件确保了所生成的马尔可夫链具有期望的目标后验分布 $\\pi(x)$ 作为其平稳分布。对于一个建议分布 $q(x' \\mid x)$，细致平衡条件由以下公式给出：\n$$ \\pi(x) P(x' \\mid x) = \\pi(x') P(x \\mid x') $$\n其中 $P(x' \\mid x) = q(x' \\mid x) \\alpha(x \\to x')$ 是马尔可夫链的转移概率。这导出了接受概率 $\\alpha(x \\to x')$ 的著名表达式：\n$$ \\alpha(x \\to x') = \\min\\left(1, \\frac{\\pi(x')q(x \\mid x')}{\\pi(x)q(x' \\mid x)}\\right) $$\n最小值函数中的分数被称为 Hastings 比率。\n\n**第一部分：完美模型接受概率**\n\n在问题的第一部分，我们在完美模型假设下进行操作。系统的状态完全由其初始条件 $x_0$ 决定。因此，采样问题定义在初始条件的空间 $\\mathbb{R}^d$ 上。\n\n目标分布 $\\pi$ 是在给定观测值 $y_{1:T}$ 的条件下，初始条件 $x_0$ 的后验概率密度。根据问题陈述和贝叶斯法则，这可表示为：\n$$ \\pi(x_0) = p(x_0 \\mid y_{1:T}) \\propto p(y_{1:T} \\mid x_0) p_0(x_0) $$\n项 $p(y_{1:T} \\mid x_0)$ 是在给定初始状态 $x_0$ 的条件下，观测值的总似然。由于模型是确定性的（$x_t = x_t(x_0)$）且观测值是条件独立的，该似然是各个似然因子的乘积：\n$$ p(y_{1:T} \\mid x_0) = \\prod_{t=1}^T p(y_t \\mid x_t(x_0)) = \\prod_{t=1}^T \\ell_t(x_t(x_0)) $$\n因此，未归一化的目标后验是：\n$$ \\tilde{\\pi}(x_0) = p_0(x_0) \\prod_{t=1}^T \\ell_t(x_t(x_0)) $$\nMH 算法即使只使用其未归一化的形式 $\\tilde{\\pi}(x_0)$ 也能正确地从 $\\pi(x_0)$ 中采样，因为归一化常数在 Hastings 比率中会被抵消。\n\n建议分布 $q$ 是一个独立 Metropolis-Hastings (IMH) 提议，其中建议状态 $x_0'$ 的抽样独立于当前状态 $x_0$。具体的建议分布就是先验分布本身：\n$$ q(x_0' \\mid x_0) = q(x_0') = p_0(x_0') $$\n因此，逆向建议概率为：\n$$ q(x_0 \\mid x_0') = q(x_0) = p_0(x_0) $$\n\n我们现在构建从当前状态 $x_0$ 转移到建议状态 $x_0'$ 的 Hastings 比率：\n$$ \\frac{\\pi(x_0')q(x_0 \\mid x_0')}{\\pi(x_0)q(x_0' \\mid x_0)} = \\frac{\\tilde{\\pi}(x_0')q(x_0 \\mid x_0')}{\\tilde{\\pi}(x_0)q(x_0' \\mid x_0)} $$\n代入目标密度和建议密度的表达式：\n$$ \\frac{\\left( p_0(x_0') \\prod_{t=1}^T \\ell_t(x_t(x_0')) \\right) \\left( p_0(x_0) \\right)}{\\left( p_0(x_0) \\prod_{t=1}^T \\ell_t(x_t(x_0)) \\right) \\left( p_0(x_0') \\right)} $$\n我们可以看到先验密度项 $p_0(x_0)$ 和 $p_0(x_0')$ 被抵消了。来自逆向建议的项 $p_0(x_0)$ 与目标密度在 $x_0$ 处的先验项抵消，对于 $p_0(x_0')$ 也是如此。简化后的比率变为：\n$$ \\frac{\\prod_{t=1}^T \\ell_t(x_t(x_0'))}{\\prod_{t=1}^T \\ell_t(x_t(x_0))} $$\n这是建议轨迹与当前轨迹的总似然之比。\n\n因此，最终的接受概率 $\\alpha(x_0 \\to x_0')$ 是：\n$$ \\alpha(x_0 \\to x_0') = \\min\\left(1, \\frac{\\prod_{t=1}^T \\ell_t(x_t(x_0'))}{\\prod_{t=1}^T \\ell_t(x_t(x_0))}\\right) $$\n这个结果在直觉上是令人满意的：因为建议分布就是先验分布，MH 接受步骤的唯一作用就是根据数据提供的信息对样本重新加权，而这些信息完全封装在似然函数中。\n\n**第二部分：针对随机模型的修改**\n\n在第二种情景中，模型动态是随机的，这意味着整个路径 $X = x_{0:T} = (x_0, x_1, \\dots, x_T)$ 是隐变量。现在的采样问题是在维度高得多的轨迹空间上进行的。\n\n目标分布 $\\pi(X)$ 是在给定观测值的条件下，整个路径的后验，$p(x_{0:T} \\mid y_{1:T})$。从第一性原理（贝叶斯法则和马尔可夫结构）出发：\n$$ \\pi(X) = p(x_{0:T} \\mid y_{1:T}) \\propto p(y_{1:T} \\mid x_{0:T}) p(x_{0:T}) $$\n似然项 $p(y_{1:T} \\mid x_{0:T})$ 和之前一样，简化为似然因子的乘积：\n$$ p(y_{1:T} \\mid x_{0:T}) = \\prod_{t=1}^T p(y_t \\mid x_t) = \\prod_{t=1}^T \\ell_t(x_t) $$\n路径上的先验 $p(x_{0:T})$ 由概率链式法则给出，它结合了初始先验和真实模型的转移密度 $f(x_t \\mid x_{t-1})$：\n$$ p(x_{0:T}) = p_0(x_0) \\prod_{t=1}^T f(x_t \\mid x_{t-1}) $$\n结合这些，路径 $X$ 的未归一化目标后验是：\n$$ \\tilde{\\pi}(X) = p_0(x_0) \\left( \\prod_{t=1}^T f(x_t \\mid x_{t-1}) \\right) \\left( \\prod_{t=1}^T \\ell_t(x_t) \\right) $$\n\n提议机制独立于当前路径 $X$ 生成一条完整的路径 $X' = x_{0:T}'$。建议密度 $q(X')$ 的构建方式是：首先采样 $x_0' \\sim p_0(\\cdot)$，然后用一个可能不同的转移密度 $g(x_t \\mid x_{t-1})$ 向前传播：\n$$ q(X') = p_0(x_0') \\prod_{t=1}^T g(x_t' \\mid x_{t-1}') $$\n由于这是一个独立采样器，所以 $q(X' \\mid X) = q(X')$ 且逆向建议为 $q(X \\mid X') = q(X)$。\n\nHastings 比率是 $\\frac{\\pi(X')q(X)}{\\pi(X)q(X')}$。代入未归一化的表达式：\n$$ \\frac{\\tilde{\\pi}(X') q(X)}{\\tilde{\\pi}(X) q(X')} = \\frac{\\left[ p_0(x_0') \\prod_{t=1}^T f(x_t' \\mid x_{t-1}') \\prod_{t=1}^T \\ell_t(x_t') \\right] \\left[ p_0(x_0) \\prod_{t=1}^T g(x_t \\mid x_{t-1}) \\right]}{\\left[ p_0(x_0) \\prod_{t=1}^T f(x_t \\mid x_{t-1}) \\prod_{t=1}^T \\ell_t(x_t) \\right] \\left[ p_0(x_0') \\prod_{t=1}^T g(x_t' \\mid x_{t-1}') \\right]} $$\n初始先验的因子 $p_0(x_0)$ 和 $p_0(x_0')$ 被抵消，因为它被用作初始状态的建议分布。保留下来的项构成了修改后的 Hastings 比率：\n$$ \\frac{\\left(\\prod_{t=1}^T \\ell_t(x_t')\\right) \\left(\\prod_{t=1}^T f(x_t' \\mid x_{t-1}')\\right) \\left(\\prod_{t=1}^T g(x_t \\mid x_{t-1})\\right)}{\\left(\\prod_{t=1}^T \\ell_t(x_t)\\right) \\left(\\prod_{t=1}^T f(x_t \\mid x_{t-1})\\right) \\left(\\prod_{t=1}^T g(x_t' \\mid x_{t-1}')\\right)} $$\n这可以很有启发性地表示为重要性权重的比率 $\\frac{w(X')}{w(X)}$，其中路径 $X$ 的权重是 $w(X) = \\frac{\\tilde{\\pi}(X)}{q(X)}$：\n$$ w(X) = \\frac{p_0(x_0) \\left(\\prod_{t=1}^T f(x_t \\mid x_{t-1})\\right) \\left(\\prod_{t=1}^T \\ell_t(x_t)\\right)}{p_0(x_0) \\prod_{t=1}^T g(x_t \\mid x_{t-1})} = \\left(\\prod_{t=1}^T \\ell_t(x_t)\\right) \\left(\\prod_{t=1}^T \\frac{f(x_t \\mid x_{t-1})}{g(x_t \\mid x_{t-1})}\\right) $$\n因此，Hastings 比率是：\n$$ \\frac{w(X')}{w(X)} = \\frac{\\left(\\prod_{t=1}^T \\ell_t(x_t')\\right) \\left(\\prod_{t=1}^T \\frac{f(x_t' \\mid x_{t-1}')}{g(x_t' \\mid x_{t-1}')}\\right)}{\\left(\\prod_{t=1}^T \\ell_t(x_t)\\right) \\left(\\prod_{t=1}^T \\frac{f(x_t \\mid x_{t-1})}{g(x_t \\mid x_{t-1})}\\right)}$$\n与完美模型情况相比，总似然的比率 $\\frac{\\prod \\ell_t'}{\\prod \\ell_t}$ 保留了下来。然而，它现在被乘以一个新的因子。这个新因子是路径动态权重的比率 $\\frac{\\prod_t (f'/g')}{\\prod_t (f/g)}$，它校正了建议动态 $g$ 和真实模型动态 $f$ 之间的差异。这个校正项是必要的，因为路径几何的建议 $\\prod_t g(\\cdot \\mid \\cdot)$ 与路径几何的先验 $\\prod_t f(\\cdot \\mid \\cdot)$ 不同。在完美模型的情况下，这个校正是不必要的，因为唯一的随机分量 $x_0$ 的建议分布正是其先验分布 $p_0$。", "answer": "$$\\boxed{\\min\\left(1, \\frac{\\prod_{t=1}^T \\ell_t(x_t(x_0'))}{\\prod_{t=1}^T \\ell_t(x_t(x_0))}\\right)}$$", "id": "3362467"}, {"introduction": "现实世界中的反问题常常产生具有多个独立模式的后验分布，这给标准MCMC采样器带来了挑战。本练习通过分析双峰分布中模式间跳跃的接受概率，来探讨亚稳态的概念。它为我们理解采样器为何会“卡住”提供了量化视角，并突显了提议步长与目标分布结构之间的相互作用 [@problem_id:3362440]。", "problem": "考虑一个源于数据同化的一维逆问题，其中标量参数 $x$ 需要在两种相互竞争的物理机制下根据观测进行推断。参数 $x$ 的后验密度被建模为一个高斯混合模型，\n$$\n\\pi(x) \\propto w_{1}\\,\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{1}}\\exp\\!\\left(-\\frac{(x-\\mu_{1})^{2}}{2\\sigma_{1}^{2}}\\right) + w_{2}\\,\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{2}}\\exp\\!\\left(-\\frac{(x-\\mu_{2})^{2}}{2\\sigma_{2}^{2}}\\right),\n$$\n其中 $w_{1},w_{2}\\in(0,1)$ 且 $w_{1}+w_{2}=1$，均值 $\\mu_{1},\\mu_{2}\\in\\mathbb{R}$ 是充分分离的，即 $\\Delta\\equiv|\\mu_{2}-\\mu_{1}|\\gg \\max\\{\\sigma_{1},\\sigma_{2}\\}$，而 $\\sigma_{1},\\sigma_{2}0$ 是各分量的标准差。假设使用 Metropolis–Hastings (MH) 马尔可夫链蒙特卡洛 (MCMC) 算法，其提议密度为对称高斯随机游走 $q(y\\,|\\,x)=\\frac{1}{\\sqrt{2\\pi}\\,s}\\exp\\!\\big(-\\frac{(y-x)^{2}}{2s^{2}}\\big)$，其中步长 $s0$ 是固定的且满足 $s\\ll \\Delta$。因此，该提议是对称的，即 $q(y\\,|\\,x)=q(x\\,|\\,y)$。\n\n从马尔可夫链的细致平衡条件出发，并仅使用后验的贝叶斯法则和 Metropolis–Hastings 转移核的定义等基本原理，推导对此对称提议强制满足细致平衡的接受准则。然后，通过对试图在模态之间跳跃的提议进行形式化的条件化，来刻画由多模态性和固定步长引起的亚稳态：定义事件 $A_{\\varepsilon}$ 表示从一个满足 $|x-\\mu_{1}|\\le \\varepsilon$ 的当前状态 $x$ 提议一个满足 $|y-\\mu_{2}|\\le \\varepsilon$ 的新状态 $y$，其中 $\\varepsilon0$ 是一个小的邻域半径，满足 $\\varepsilon\\ll \\min\\{\\sigma_{1},\\sigma_{2}\\}$ 和 $\\varepsilon\\ll \\Delta$。在 $\\varepsilon\\to 0$ 的极限下，计算给定固定步长为 $s$ 的 MH 算法在事件 $A_{\\varepsilon}$ 条件下的期望接受概率。\n\n你的最终答案必须是仅含 $w_{1}$、$w_{2}$、$\\sigma_{1}$ 和 $\\sigma_{2}$ 的单个闭式解析表达式。不需要数值近似。此外，请从第一性原理出发，简要解释在此背景下，多模态性和亚稳态是如何通过接受率和提议机制引入的。最终答案必须严格以解析表达式的形式提供；不要包含任何单位。", "solution": "后验密度被指定为一个高斯混合模型。根据贝叶斯法则，对于数据同化问题，有 $\\pi(x)\\propto p(y_{\\text{obs}}\\,|\\,x)\\,p(x)$，在这里该后验被该混合模型明确表示。Metropolis–Hastings (MH) 算法定义了一个马尔可夫链，其提议密度为 $q(y\\,|\\,x)$，接受概率为 $\\alpha(x,y)$，从而对于 $y\\neq x$ 产生一个从 $x$ 到 $y$ 的转移概率 $P(x\\to y)=q(y\\,|\\,x)\\,\\alpha(x,y)$，以及 $P(x\\to x)=1-\\int q(z\\,|\\,x)\\,\\alpha(x,z)\\,\\mathrm{d}z$。要求该链以 $\\pi$ 为其不变分布，并且关于 $\\pi$ 可逆，这就是细致平衡条件：\n$$\n\\pi(x)\\,P(x\\to y)=\\pi(y)\\,P(y\\to x),\\quad \\text{for all }x,y.\n$$\n对于 $x\\neq y$，代入 $P$ 得到\n$$\n\\pi(x)\\,q(y\\,|\\,x)\\,\\alpha(x,y) = \\pi(y)\\,q(x\\,|\\,y)\\,\\alpha(y,x).\n$$\n标准的 MH 构造选择\n$$\n\\alpha(x,y)=\\min\\!\\left(1,\\frac{\\pi(y)\\,q(x\\,|\\,y)}{\\pi(x)\\,q(y\\,|\\,x)}\\right),\n$$\n这种选择满足细致平衡条件，并在该约束下最大化了接受概率。因为提议是对称的，即 $q(y\\,|\\,x)=q(x\\,|\\,y)$，所以上式简化为\n$$\n\\alpha(x,y)=\\min\\!\\left(1,\\frac{\\pi(y)}{\\pi(x)}\\right).\n$$\n\n我们被要求计算在试图于两个模态之间跳跃的提议条件下的期望接受概率。形式上，将 $A_{\\varepsilon}$ 定义为\n$$\nA_{\\varepsilon}=\\left\\{|x-\\mu_{1}|\\le \\varepsilon,\\;|y-\\mu_{2}|\\le \\varepsilon\\right\\},\\quad \\varepsilon\\ll \\min\\{\\sigma_{1},\\sigma_{2}\\},\\;\\varepsilon\\ll \\Delta.\n$$\n在充分分离条件 $\\Delta\\gg \\max\\{\\sigma_{1},\\sigma_{2}\\}$ 和半径为 $\\varepsilon$ 的小邻域下，另一个高斯分量对每个模态附近后验的贡献可以忽略不计。因此，对于满足 $|x-\\mu_{1}|\\le \\varepsilon$ 的 $x$，\n$$\n\\pi(x)\\approx C\\, w_{1}\\,\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{1}}\\exp\\!\\left(-\\frac{(x-\\mu_{1})^{2}}{2\\sigma_{1}^{2}}\\right),\n$$\n而对于满足 $|y-\\mu_{2}|\\le \\varepsilon$ 的 $y$，\n$$\n\\pi(y)\\approx C\\, w_{2}\\,\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{2}}\\exp\\!\\left(-\\frac{(y-\\mu_{2})^{2}}{2\\sigma_{2}^{2}}\\right),\n$$\n其中 $C0$ 是后验分布的（未知）归一化常数，它在计算比率时会被消去。在 $\\varepsilon\\to 0$ 的极限下，我们有 $x\\to \\mu_{1}$ 和 $y\\to \\mu_{2}$，因此指数因子趋向于 $\\exp(0)=1$，我们得到\n$$\n\\frac{\\pi(y)}{\\pi(x)} \\xrightarrow[\\varepsilon\\to 0]{} \\frac{w_{2}\\,\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{2}}}{w_{1}\\,\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{1}}}=\\frac{w_{2}\\,\\sigma_{1}}{w_{1}\\,\\sigma_{2}}.\n$$\n因此，对于对称提议，\n$$\n\\alpha(x,y)\\xrightarrow[\\varepsilon\\to 0]{}\\min\\!\\left(1,\\frac{w_{2}\\,\\sigma_{1}}{w_{1}\\,\\sigma_{2}}\\right).\n$$\n因为当 $\\varepsilon\\to 0$ 时，这个极限值在 $A_{\\varepsilon}$ 上是常数，所以给定 $A_{\\varepsilon}$ 的条件下，接受概率的条件期望就等于这个常数：\n$$\n\\lim_{\\varepsilon\\to 0}\\,\\mathbb{E}\\!\\left[\\alpha(X,Y)\\,\\big|\\,A_{\\varepsilon}\\right] = \\min\\!\\left(1,\\frac{w_{2}\\,\\sigma_{1}}{w_{1}\\,\\sigma_{2}}\\right).\n$$\n\n最后，我们从第一性原理出发，解释多模态性和亚稳态与接受率及固定步长之间的相互作用。多模态性的出现是因为 $\\pi$ 在 $\\mu_{1}$ 和 $\\mu_{2}$ 处有两个充分分离的峰。马尔可夫链中的亚稳态是提议机制具有固定步长 $s$ 的结果，该步长相对于分离距离 $\\Delta$ 很小。在高斯随机游走下，从 $\\mu_{1}$ 的邻域提议一次跳跃到 $\\mu_{2}$ 邻域的概率，在 $\\Delta^{2}/s^{2}$ 上是指数级小的；更精确地说，如果 $X\\approx \\mu_{1}$，那么 $Y\\sim \\mathcal{N}(X,s^{2})$ 必须实现一个罕见的尾部事件 $|Y-\\mu_{2}|\\le \\varepsilon$，其概率在多项式因子以内与 $\\exp\\!\\big(-\\Delta^{2}/(2s^{2})\\big)$ 成比例。因此，即使这种跨模态提议（当它们发生时）的接受概率很高（如上面的表达式所示），成功的模态间转移的总体速率仍然由提议跨模态移动的稀有性所主导。这导致了在单个模态内的长停留时间（亚稳态）、慢混合，以及模态间转移时间对比例 $\\Delta/s$ 的强依赖性。接受准则本身由细致平衡条件决定，并取决于两个模态附近局部后验质量的比率，这里由高斯分量的权重和尺度所体现；而提议机制则决定了这种有利的提议被实际尝试的频率。", "answer": "$$\\boxed{\\min\\!\\left(1,\\frac{w_{2}\\,\\sigma_{1}}{w_{1}\\,\\sigma_{2}}\\right)}$$", "id": "3362440"}, {"introduction": "反问题中的许多物理参数都受到约束，例如非负性。这个动手编程练习将演示如何设计尊重这些边界的自定义MCMC提议。你将推导并实现“反射”和“折射”提议的接受准则，这需要仔细计算非对称的提议密度以确保细致平衡得以保持 [@problem_id:3362451]。", "problem": "考虑以下带有硬可行性约束的约束贝叶斯逆问题。一个标量参数 $\\theta \\in \\mathbb{R}$ 具有高斯似然和高斯先验，但其后验支撑集被一个凸不等式约束所截断。数据模型为 $d \\mid \\theta \\sim \\mathcal{N}(\\theta,\\sigma_y^2)$，先验为 $\\theta \\sim \\mathcal{N}(0,\\sigma_0^2)$，并服从约束 $C(\\theta) \\le 0$，其中 $C(\\theta) = -\\theta$，因此可行集为 $\\{\\theta \\in \\mathbb{R} : \\theta \\ge 0\\}$。因此，未归一化的截断后验为\n$$\n\\pi_T(\\theta) \\propto \\exp\\left(-\\tfrac{1}{2}\\bigg(\\frac{(d-\\theta)^2}{\\sigma_y^2} + \\frac{\\theta^2}{\\sigma_0^2}\\bigg)\\right)\\,\\mathbf{1}_{\\{\\theta \\ge 0\\}},\n$$\n其中 $\\mathbf{1}_{\\{\\cdot\\}}$ 是指示函数。\n\n我们寻求一个 Metropolis-Hastings (MH) 转移核，它能相对于 $\\pi_T(\\theta)$ 保持细致平衡，同时使用在边界附近被修改以强制执行约束的高斯随机游走来提议移动。\n\n从当前的可行状态 $x \\ge 0$ 开始，抽取一个无约束的高斯增量 $\\varepsilon \\sim \\mathcal{N}(0,\\tau^2)$，并设置无约束的提议 $u = x + \\varepsilon$。定义两种不同的边界处理映射，以从 $u$ 生成一个可行的提议状态 $y \\ge 0$：\n\n1. 反射：$y = |u|$。\n\n2. 折射，压缩因子为 $\\rho \\in (0,1]$：\n   $$\n   y = \n   \\begin{cases}\n   u,   \\text{if } u \\ge 0,\\\\\n   -\\rho\\,u,   \\text{if } u  0.\n   \\end{cases}\n   $$\n\n令 $\\varphi_\\tau(z) = \\dfrac{1}{\\sqrt{2\\pi}\\tau}\\exp\\!\\left(-\\dfrac{z^2}{2\\tau^2}\\right)$ 表示标准差为 $\\tau$ 的高斯密度。由此产生的提议密度 $q(x \\to y)$ 是 $\\varepsilon$ 通过从 $u$到 $y$ 的映射的前推，并且由于边界处的折叠可能具有多个原像。通过明确计算每种边界处理映射的 $q(x \\to y)$，从第一性原理出发，且不借助任何预先推导的接受准则，推导正确的 Metropolis-Hastings 接受概率\n$$\n\\alpha(x \\to y) = \\min\\!\\left(1,\\; \\frac{\\pi_T(y)\\,q(y \\to x)}{\\pi_T(x)\\,q(x \\to y)}\\right),\n$$\n您的推导必须从基本的细致平衡条件开始，对于目标密度 $\\pi_T$ 和马尔可夫转移核 $K$，该条件要求\n$$\n\\pi_T(x)\\,K(x,dy) = \\pi_T(y)\\,K(y,dx),\n$$\n对于带有提议核 $q$ 和接受率 $\\alpha$ 的 Metropolis-Hastings 算法，此条件简化为\n$$\n\\pi_T(x)\\,q(x \\to y)\\,\\alpha(x \\to y) = \\pi_T(y)\\,q(y \\to x)\\,\\alpha(y \\to x).\n$$\n由此，得出 $\\alpha(x \\to y)$ 的表达式。\n\n在边界为 $0$ 的标量半直线情况下，具体化您的提议密度 $q(x \\to y)$ 的表达式如下：\n\n- 对于反射，证明\n$$\nq_{\\mathrm{refl}}(x \\to y) = \\varphi_\\tau(y-x) + \\varphi_\\tau(y+x), \\quad \\text{for } x \\ge 0,\\, y \\ge 0.\n$$\n\n- 对于因子为 $\\rho \\in (0,1]$ 的折射，证明\n$$\nq_{\\mathrm{refr},\\rho}(x \\to y) = \\varphi_\\tau(y-x) + \\frac{1}{\\rho}\\,\\varphi_\\tau\\!\\Big(-\\frac{y}{\\rho} - x\\Big), \\quad \\text{for } x \\ge 0,\\, y \\ge 0.\n$$\n\n然后，实现一个程序，对于给定的参数，使用推导出的表达式计算接受概率 $\\alpha(x \\to y)$，并通过标量\n$$\n\\Delta(x,y) = \\frac{\\pi_T(x)\\,q(x \\to y)\\,\\alpha(x \\to y) - \\pi_T(y)\\,q(y \\to x)\\,\\alpha(y \\to x)}{\\max\\big(\\pi_T(x)\\,q(x \\to y)\\,\\alpha(x \\to y),\\; \\pi_T(y)\\,q(y \\to x)\\,\\alpha(y \\to x)\\big)},\n$$\n对配对 $(x,y)$ 的细致平衡进行数值验证，当细致平衡成立时，其绝对值应接近于 $0$。\n\n使用以下固定的数据和超参数：$d = 1$，$\\sigma_y = 0.5$（所以 $\\sigma_y^2 = 0.25$），以及 $\\sigma_0 = 1$（所以 $\\sigma_0^2 = 1$）。为了数值稳定性，您可以使用对数和稳定求和来实现所有量的计算。\n\n您的程序必须评估以下包含五个案例的测试套件，每个案例指定为一个元组 $(\\text{method}, x, y, \\tau, \\rho)$，其中对于反射方法，折射因子 $\\rho$ 被忽略：\n\n1. 反射内部移动：$(\\text{reflect},\\, 0.8,\\, 0.9,\\, 0.3,\\, 1.0)$。\n\n2. 反射主导穿越移动：$(\\text{reflect},\\, 0.2,\\, 0.7,\\, 0.5,\\, 1.0)$。\n\n3. 边界处反射：$(\\text{reflect},\\, 0.0,\\, 0.1,\\, 0.4,\\, 1.0)$。\n\n4. 压缩率为 $\\rho = 0.5$ 的折射穿越：$(\\text{refract},\\, 0.2,\\, 0.9,\\, 0.6,\\, 0.5)$。\n\n5. 压缩率为 $\\rho = 0.5$ 的折射内部移动：$(\\text{refract},\\, 0.9,\\, 1.1,\\, 0.4,\\, 0.5)$。\n\n对于每个测试用例，计算并报告如上定义的浮点数对 $[\\alpha(x \\to y), \\Delta(x,y)]$。您的程序应生成单行输出，其中包含所有结果，这些结果按测试套件的顺序平铺成一个用方括号括起来的逗号分隔列表，每个测试用例贡献两个连续的条目。即，所需的输出格式为\n\"[a1,d1,a2,d2,a3,d3,a4,d4,a5,d5]\"\n无附加文本。所有角度（如果存在）都将以弧度为单位，但此问题不包含角度。所有量均为无量纲。输出值必须是表示为标准十进制浮点数的实数。", "solution": "该问题被评估为有效，因为它科学地基于贝叶斯统计和马尔可夫链蒙特卡洛（MCMC）方法的原理，问题阐述清晰，目标明确，并为其解决提供了完整且一致的信息集。\n\n问题的核心是为两种旨在处理边界约束的不同提议机制推导 Metropolis-Hastings (MH) 接受概率 $\\alpha(x \\to y)$。这需要为每种机制推导提议转移密度 $q(x \\to y)$。\n\n目标分布是在 $\\theta \\ge 0$ 上的截断后验：\n$$\n\\pi_T(\\theta) \\propto \\exp\\left(-\\tfrac{1}{2}\\bigg(\\frac{(d-\\theta)^2}{\\sigma_y^2} + \\frac{\\theta^2}{\\sigma_0^2}\\bigg)\\right)\\,\\mathbf{1}_{\\{\\theta \\ge 0\\}}\n$$\n为方便起见，我们定义势能函数 $U(\\theta)$，使得对于 $\\theta \\ge 0$ 有 $\\pi_T(\\theta) \\propto \\exp(-U(\\theta))$。\n$$\nU(\\theta) = \\frac{1}{2}\\left(\\frac{(d-\\theta)^2}{\\sigma_y^2} + \\frac{\\theta^2}{\\sigma_0^2}\\right)\n$$\n那么目标密度的比值为 $\\frac{\\pi_T(y)}{\\pi_T(x)} = \\exp(U(x) - U(y))$，其中 $x, y \\ge 0$。\n\n### 接受概率形式的推导\nMetropolis-Hastings 更新的细致平衡条件给出如下：\n$$\n\\pi_T(x)\\,q(x \\to y)\\,\\alpha(x \\to y) = \\pi_T(y)\\,q(y \\to x)\\,\\alpha(y \\to x)\n$$\n其中 $x$ 和 $y$ 是可行域中的状态，即 $x \\ge 0$ 和 $y \\ge 0$。我们寻求一个在范围 $[0, 1]$ 内满足此方程的接受函数 $\\alpha$。让我们定义 Metropolis 比率 $R$：\n$$\nR(x, y) = \\frac{\\pi_T(y)\\,q(y \\to x)}{\\pi_T(x)\\,q(x \\to y)}\n$$\n细致平衡方程可以重写为 $\\alpha(x \\to y) = R(x, y) \\cdot \\alpha(y \\to x)$。为了最大化接受率，从而提高采样器的效率，我们应该为 $\\alpha(x \\to y)$ 和 $\\alpha(y \\to x)$ 选择满足此关系的最大可能值，同时受限于它们是概率（即小于或等于 $1$）的约束。\n\n如果 $R(x, y)  1$，我们可以设置 $\\alpha(y \\to x) = 1$（其最大可能值）。这个选择随后决定了 $\\alpha(x \\to y) = R(x, y)$。\n如果 $R(x, y) \\ge 1$，我们可以设置 $\\alpha(x \\to y) = 1$。这意味着 $\\alpha(y \\to x) = 1 / R(x, y)$。由于 $R(x, y) \\ge 1$，这个 $\\alpha(y \\to x)$ 的值也小于或等于 $1$。\n\n结合这两种情况，我们得到标准的 Metropolis-Hastings 接受概率：\n$$\n\\alpha(x \\to y) = \\min\\left(1, R(x,y)\\right) = \\min\\left(1, \\frac{\\pi_T(y)\\,q(y \\to x)}{\\pi_T(x)\\,q(x \\to y)}\\right)\n$$\n此推导满足了从给定的细致平衡方程中获得 $\\alpha(x \\to y)$ 表达式的要求。\n\n### 提议密度 $q(x \\to y)$ 的推导\n下一步是找出提议密度 $q(x \\to y)$ 的表达式。提议是通过首先从概率密度函数（PDF）$\\varphi_\\tau(\\varepsilon)$ 中抽取一个增量 $\\varepsilon \\sim \\mathcal{N}(0, \\tau^2)$，形成一个无约束的提议 $u = x + \\varepsilon$，然后将 $u$ 映射到一个可行状态 $y = M(u) \\ge 0$ 来生成的。给定 $x$ 时 $u$ 的密度是 $p(u|x) = \\varphi_\\tau(u-x)$。\n\n提议密度 $q(x \\to y)$ 是在映射 $M$ 下 $u$ 的密度前推。对于一个给定的提议状态 $y > 0$，可能存在多个无约束值 $u_i$ 使得 $M(u_i) = y$。$y$ 处的密度是来自所有这些原像的贡献之和。根据概率密度的变量替换公式，来自每个原像 $u_i$ 的贡献是 $p(u_i|x) \\left| \\frac{du_i}{dy} \\right|$。因此，\n$$\nq(x \\to y) = \\sum_{i \\text{ s.t. } M(u_i)=y} p(u_i|x) \\left| \\frac{du_i}{dy} \\right| = \\sum_{i \\text{ s.t. } M(u_i)=y} \\varphi_\\tau(u_i - x) \\left| \\frac{du_i}{dy} \\right|\n$$\n此密度是相对于可行域 $[0, \\infty)$ 上的勒贝格测度而言的。\n\n#### 1. 反射映射：$y = |u|$\n对于一个给定的 $y>0$，在绝对值映射 $M(u)=|u|$ 下的原像是 $u_1 = y$ 和 $u_2 = -y$。\n\n- 对于 $u_1 = y$，所需的增量是 $\\varepsilon_1 = y-x$。雅可比项是 $|\\frac{du_1}{dy}| = |1| = 1$。对密度的贡献是 $\\varphi_\\tau(y-x)$。\n- 对于 $u_2 = -y$，所需的增量是 $\\varepsilon_2 = -y-x$。雅可比项是 $|\\frac{du_2}{dy}| = |-1| = 1$。对密度的贡献是 $\\varphi_\\tau(-y-x)$。由于高斯概率密度函数是偶函数，$\\varphi_\\tau(-z) = \\varphi_\\tau(z)$，因此这等于 $\\varphi_\\tau(y+x)$。\n\n将这两个贡献相加，得到对 $x \\ge 0, y \\ge 0$ 有效的反射提议密度：\n$$\nq_{\\mathrm{refl}}(x \\to y) = \\varphi_\\tau(y-x) + \\varphi_\\tau(y+x)\n$$\n这证实了问题陈述中提供的表达式。\n\n#### 2. 折射映射：当 $u \\ge 0$ 时 $y = u$，当 $u  0$ 时 $y = -\\rho u$\n对于一个给定的 $y>0$ 和压缩因子 $\\rho \\in (0,1]$，我们找到折射映射下的原像。\n\n- 如果无约束提议 $u$ 是非负的 ($u \\ge 0$)，则 $y=u$。原像是 $u_1 = y$。因为我们考虑的是 $y>0$，所以 $u_1>0$，这与条件 $u \\ge 0$ 一致。雅可比行列式是 $|\\frac{du_1}{dy}| = 1$。密度贡献是 $\\varphi_\\tau(y-x)$。\n- 如果无约束提议 $u$ 是负的 ($u  0$)，则 $y = -\\rho u$。原像是 $u_2 = -y/\\rho$。因为 $y>0$ 且 $\\rho>0$，所以 $u_20$，这与条件 $u0$ 一致。雅可比行列式是 $|\\frac{du_2}{dy}| = |-1/\\rho| = 1/\\rho$。密度贡献是 $\\varphi_\\tau(-y/\\rho - x) \\cdot \\frac{1}{\\rho}$。\n\n将这两个贡献相加，得到对 $x \\ge 0, y \\ge 0$ 有效的折射提议密度：\n$$\nq_{\\mathrm{refr},\\rho}(x \\to y) = \\varphi_\\tau(y-x) + \\frac{1}{\\rho}\\,\\varphi_\\tau\\!\\Big(-\\frac{y}{\\rho} - x\\Big)\n$$\n这也证实了问题陈述中提供的表达式。\n\n### 数值实现\n计算在对数域中执行以增强数值稳定性。接受概率 $\\alpha(x \\to y)$ 通过以下方式计算：\n$$\n\\log R(x,y) = (U(x) - U(y)) + (\\log q(y \\to x) - \\log q(x \\to y))\n$$\n$$\n\\alpha(x \\to y) = \\min(1, \\exp(\\log R(x,y)))\n$$\n项 $\\log q(x \\to y)$ 使用稳定的 `log-sum-exp` 操作计算，即 $\\log(A+B) = \\log(\\exp(\\log A) + \\exp(\\log B))$。\n\n细致平衡检查量 $\\Delta(x,y)$ 定义为：\n$$\n\\Delta(x,y) = \\frac{T_1 - T_2}{\\max(T_1, T_2)}, \\quad \\text{where } T_1 = \\pi_T(x)\\,q(x \\to y)\\,\\alpha(x \\to y) \\text{ and } T_2 = \\pi_T(y)\\,q(y \\to x)\\,\\alpha(y \\to x)\n$$\n根据构造，$T_1$ 和 $T_2$ 应该相同。任何偏差都源于浮点算术误差。为了稳定地计算 $\\Delta(x,y)$，我们计算它们的对数 $\\log T_1$ 和 $\\log T_2$。令 $\\text{diff} = \\log T_1 - \\log T_2$。那么，如果 $T_2 > T_1$，$\\Delta(x,y)$ 可以计算为 $\\exp(\\text{diff})-1$；如果 $T_1 > T_2$，则可以计算为 $1-\\exp(-\\text{diff})$。使用 `numpy.expm1` 函数，该函数能为小的 $z$ 精确计算 $\\exp(z)-1$，提供了一个鲁棒的实现。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes MH acceptance probabilities and detailed balance checks for a\n    constrained Bayesian inverse problem.\n    \"\"\"\n    # Fixed parameters\n    d = 1.0\n    sigma_y = 0.5\n    sigma_0 = 1.0\n    sigma_y2 = sigma_y**2\n    sigma_02 = sigma_0**2\n\n    # Test cases from the problem statement\n    test_cases = [\n        ('reflect', 0.8, 0.9, 0.3, 1.0),\n        ('reflect', 0.2, 0.7, 0.5, 1.0),\n        ('reflect', 0.0, 0.1, 0.4, 1.0),\n        ('refract', 0.2, 0.9, 0.6, 0.5),\n        ('refract', 0.9, 1.1, 0.4, 0.5),\n    ]\n\n    def log_potential(theta):\n        \"\"\"Computes the log-potential U(theta) for theta >= 0.\"\"\"\n        if theta  0:\n            return np.inf\n        return 0.5 * (((d - theta)**2 / sigma_y2) + (theta**2 / sigma_02))\n\n    def log_phi_tau(z, tau):\n        \"\"\"Computes the log of the Gaussian PDF with std dev tau.\"\"\"\n        return -np.log(tau * np.sqrt(2 * np.pi)) - (z**2) / (2 * tau**2)\n\n    def log_q(method, x, y, tau, rho):\n        \"\"\"Computes the log of the proposal density q(x -> y).\"\"\"\n        if method == 'reflect':\n            log_term1 = log_phi_tau(y - x, tau)\n            log_term2 = log_phi_tau(y + x, tau)\n            return np.logaddexp(log_term1, log_term2)\n        elif method == 'refract':\n            log_term1 = log_phi_tau(y - x, tau)\n            log_term2 = -np.log(rho) + log_phi_tau(-y / rho - x, tau)\n            return np.logaddexp(log_term1, log_term2)\n        else:\n            raise ValueError(\"Unknown method\")\n\n    results = []\n    for case in test_cases:\n        method, x, y, tau, rho = case\n\n        # Calculate acceptance probability alpha(x -> y)\n        U_x = log_potential(x)\n        U_y = log_potential(y)\n        log_pi_ratio = U_x - U_y\n\n        log_q_forward = log_q(method, x, y, tau, rho)\n        log_q_reverse = log_q(method, y, x, tau, rho)\n        \n        log_R_forward = log_pi_ratio + log_q_reverse - log_q_forward\n        alpha_forward = min(1.0, np.exp(log_R_forward))\n        \n        results.append(alpha_forward)\n\n        # Calculate detailed balance check Delta(x, y)\n        log_alpha_forward = np.log(alpha_forward)\n        \n        # We also need alpha(y -> x)\n        log_R_reverse = (U_y - U_x) + log_q_forward - log_q_reverse\n        alpha_reverse = min(1.0, np.exp(log_R_reverse))\n        log_alpha_reverse = np.log(alpha_reverse)\n\n        # Compute log transition probabilities T1 = pi(x)K(x,y) and T2 = pi(y)K(y,x)\n        log_T1 = -U_x + log_q_forward + log_alpha_forward\n        log_T2 = -U_y + log_q_reverse + log_alpha_reverse\n        \n        # Stably compute Delta = (T1-T2)/max(T1,T2)\n        diff = log_T1 - log_T2\n        if diff > 0:\n            # Delta = 1 - T2/T1 = 1 - exp(log_T2 - log_T1) = 1 - exp(-diff)\n            # -expm1(-x) is more numerically stable for small x than 1-exp(-x)\n            delta = -np.expm1(-diff)\n        else:\n            # Delta = T1/T2 - 1 = exp(log_T1 - log_T2) - 1 = exp(diff) - 1\n            delta = np.expm1(diff)\n            \n        results.append(delta)\n\n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.15g}' for r in results)}]\")\n\nsolve()\n```", "id": "3362451"}]}