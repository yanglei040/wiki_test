{"hands_on_practices": [{"introduction": "扩展卡尔曼滤波（EKF）的核心在于通过局部线性化来近似处理非线性系统。这一过程使得我们能够沿用标准卡尔曼滤波的框架来传播状态的均值和协方差。本练习旨在提供EKF核心预测步骤的直接实践，你将亲自计算状态转移和观测模型的雅可比矩阵（Jacobian matrices），并利用它们在不同噪声假设下，推算预测协方差和新息协方差。通过这项基础练习[@problem_id:3380750]，你将对滤波器内部的数学运作机制建立起坚实的直观理解。", "problem": "考虑一个用于数据同化的非线性离散时间状态空间系统，该系统采用扩展卡尔曼滤波器（EKF, Extended Kalman Filter）。设状态为二维，$x \\in \\mathbb{R}^2$，过程模型 $f:\\mathbb{R}^2 \\to \\mathbb{R}^2$ 和观测模型 $h:\\mathbb{R}^2 \\to \\mathbb{R}^2$ 定义如下\n$$\nf(x) = \\begin{bmatrix}\nx_1 + \\sin(x_2) \\\\\nx_2 \\exp(0.1 x_1)\n\\end{bmatrix}, \\quad\nh(x) = \\begin{bmatrix}\nx_1^2 + \\cos(x_2) \\\\\n\\tanh(x_1 - x_2)\n\\end{bmatrix}.\n$$\n所有三角函数的角度参数都必须以弧度为单位进行解释。EKF 将非线性映射在当前状态估计 $x$ 附近线性化，以获得用于传播协方差的雅可比矩阵 $F_k = \\left.\\dfrac{\\partial f}{\\partial x}\\right|_{x}$ 和 $H_k = \\left.\\dfrac{\\partial h}{\\partial x}\\right|_{x}$。在本问题中，请使用自动微分（AD, Automatic Differentiation）在点\n$$\nx = \\begin{bmatrix} 0.5 \\\\ -0.2 \\end{bmatrix}.\n$$\n处计算这些雅可比矩阵。然后，对于每种给定的协方差配置，根据标准的 EKF 协方差传播和新息定义，计算 EKF 的预测协方差 $P_{k|k-1}$ 和新息协方差 $S_k$。您必须以纯数学术语执行所有计算，不引入任何物理单位。\n\n测试套件包含三种情况。在每种情况下，您将获得 $P_{k-1|k-1}$、$Q_k$ 和 $R_k$。对于所有情况，都使用在给定点 $x$ 处计算出的相同的 $F_k$ 和 $H_k$。这些矩阵是：\n- 情况 $1$（标称协方差）：\n$$\nP_{k-1|k-1}^{(1)} = \\begin{bmatrix} 0.2  0.05 \\\\ 0.05  0.1 \\end{bmatrix}, \\quad\nQ_k^{(1)} = \\begin{bmatrix} 0.01  0 \\\\ 0  0.01 \\end{bmatrix}, \\quad\nR_k^{(1)} = \\begin{bmatrix} 0.05  0.01 \\\\ 0.01  0.02 \\end{bmatrix}.\n$$\n- 情况 $2$（接近确定性的过程，先验协方差非常小）：\n$$\nP_{k-1|k-1}^{(2)} = \\begin{bmatrix} 10^{-6}  0 \\\\ 0  10^{-6} \\end{bmatrix}, \\quad\nQ_k^{(2)} = \\begin{bmatrix} 0  0 \\\\ 0  0 \\end{bmatrix}, \\quad\nR_k^{(2)} = \\begin{bmatrix} 10^{-3}  0 \\\\ 0  10^{-3} \\end{bmatrix}.\n$$\n- 情况 $3$（大的先验和过程噪声）：\n$$\nP_{k-1|k-1}^{(3)} = \\begin{bmatrix} 5  2 \\\\ 2  3 \\end{bmatrix}, \\quad\nQ_k^{(3)} = \\begin{bmatrix} 0.5  0.2 \\\\ 0.2  0.5 \\end{bmatrix}, \\quad\nR_k^{(3)} = \\begin{bmatrix} 0.3  0 \\\\ 0  0.3 \\end{bmatrix}.\n$$\n\n您的任务：\n- 使用 AD 在 $x = \\begin{bmatrix} 0.5 \\\\ -0.2 \\end{bmatrix}$ 处计算 $F_k$ 和 $H_k$。\n- 对于每种情况 $i \\in \\{1,2,3\\}$，计算\n$$\nP_{k|k-1}^{(i)} \\quad \\text{和} \\quad S_k^{(i)}.\n$$\n\n对于每种情况 $i$，您的程序必须输出四个标量\n$$\n\\operatorname{tr}\\!\\left(P_{k|k-1}^{(i)}\\right), \\quad \\operatorname{tr}\\!\\left(S_k^{(i)}\\right), \\quad \\det\\!\\left(P_{k|k-1}^{(i)}\\right), \\quad \\det\\!\\left(S_k^{(i)}\\right),\n$$\n并按此顺序。将所有三种情况的结果汇总到一行输出中，该行包含一个由三个子列表组成的逗号分隔列表，每个子列表是相应情况计算出的四个量，不含空格。例如，输出格式必须为\n$$\n\\text{[[$a_1$,$a_2$,$a_3$,$a_4$],[$b_1$,$b_2$,$b_3$,$b_4$],[$c_1$,$c_2$,$c_3$,$c_4$]]}.\n$$", "solution": "用户在非线性状态估计领域提供了一个定义明确且科学合理的问题。该问题是有效的，因为它是自洽的、一致的，并且基于扩展卡尔曼滤波器（EKF）的既定原理。所有必要的函数、参数和矩阵都已提供，从而可以得到一个唯一且可验证的解。\n\n任务是为一个给定的非线性系统执行 EKF 的一个预测步骤。这涉及两个主要阶段：\n$1$. 将非线性过程和观测模型线性化，以获得在特定状态下的雅可比矩阵 $F_k$ 和 $H_k$。问题指定使用自动微分（AD），我们将采用其数学基础：符号微分。\n$2$. 针对三种不同的初始协方差配置，通过线性化模型传播状态误差协方差矩阵。这涉及计算预测协方差 $P_{k|k-1}$ 和新息协方差 $S_k$。\n\n每种情况的最终输出将是这两个计算出的协方差矩阵的迹和行列式。\n\n**1. 雅可比矩阵计算**\n\n过程模型 $f(x)$ 和观测模型 $h(x)$ 如下所示：\n$$\nf(x) = \\begin{bmatrix} f_1(x_1, x_2) \\\\ f_2(x_1, x_2) \\end{bmatrix} = \\begin{bmatrix}\nx_1 + \\sin(x_2) \\\\\nx_2 \\exp(0.1 x_1)\n\\end{bmatrix}, \\quad\nh(x) = \\begin{bmatrix} h_1(x_1, x_2) \\\\ h_2(x_1, x_2) \\end{bmatrix} = \\begin{bmatrix}\nx_1^2 + \\cos(x_2) \\\\\n\\tanh(x_1 - x_2)\n\\end{bmatrix}\n$$\n状态向量为 $x = [x_1, x_2]^T$。雅可比矩阵通过计算这些函数对状态变量的偏导数得到。\n\n**过程模型雅可比矩阵, $F_k$**\n雅可比矩阵 $F_k$ 定义为 $F_k = \\left.\\dfrac{\\partial f}{\\partial x}\\right|_{x}$。\n$$\nF_k = \\begin{bmatrix}\n\\frac{\\partial f_1}{\\partial x_1}  \\frac{\\partial f_1}{\\partial x_2} \\\\\n\\frac{\\partial f_2}{\\partial x_1}  \\frac{\\partial f_2}{\\partial x_2}\n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{\\partial}{\\partial x_1}(x_1 + \\sin(x_2))  \\frac{\\partial}{\\partial x_2}(x_1 + \\sin(x_2)) \\\\\n\\frac{\\partial}{\\partial x_1}(x_2 e^{0.1 x_1})  \\frac{\\partial}{\\partial x_2}(x_2 e^{0.1 x_1})\n\\end{bmatrix} = \\begin{bmatrix}\n1  \\cos(x_2) \\\\\n0.1 x_2 e^{0.1 x_1}  e^{0.1 x_1}\n\\end{bmatrix}\n$$\n我们在点 $x = [0.5, -0.2]^T$ 处对其求值：\n$x_1 = 0.5$, $x_2 = -0.2$ (弧度)。\n$$\nF_k = \\begin{bmatrix}\n1  \\cos(-0.2) \\\\\n0.1(-0.2) e^{0.1(0.5)}  e^{0.1(0.5)}\n\\end{bmatrix} = \\begin{bmatrix}\n1  \\cos(0.2) \\\\\n-0.02 e^{0.05}  e^{0.05}\n\\end{bmatrix}\n$$\n使用数值（为方便展示而近似；计算中使用全精度）：\n$\\cos(0.2) \\approx 0.980067$\n$e^{0.05} \\approx 1.051271$\n$$\nF_k \\approx \\begin{bmatrix}\n1.0  0.980067 \\\\\n-0.021025  1.051271\n\\end{bmatrix}\n$$\n\n**观测模型雅可比矩阵, $H_k$**\n雅可比矩阵 $H_k$ 定义为 $H_k = \\left.\\dfrac{\\partial h}{\\partial x}\\right|_{x}$。\n$$\nH_k = \\begin{bmatrix}\n\\frac{\\partial h_1}{\\partial x_1}  \\frac{\\partial h_1}{\\partial x_2} \\\\\n\\frac{\\partial h_2}{\\partial x_1}  \\frac{\\partial h_2}{\\partial x_2}\n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{\\partial}{\\partial x_1}(x_1^2 + \\cos(x_2))  \\frac{\\partial}{\\partial x_2}(x_1^2 + \\cos(x_2)) \\\\\n\\frac{\\partial}{\\partial x_1}(\\tanh(x_1 - x_2))  \\frac{\\partial}{\\partial x_2}(\\tanh(x_1 - x_2))\n\\end{bmatrix}\n$$\n使用导数 $\\frac{d}{du}(\\tanh(u)) = \\text{sech}^2(u)$ 和链式法则：\n$$\nH_k = \\begin{bmatrix}\n2x_1  -\\sin(x_2) \\\\\n\\text{sech}^2(x_1 - x_2)  -\\text{sech}^2(x_1 - x_2)\n\\end{bmatrix}\n$$\n我们在 $x = [0.5, -0.2]^T$ 处对其求值：\n$x_1 - x_2 = 0.5 - (-0.2) = 0.7$。\n$$\nH_k = \\begin{bmatrix}\n2(0.5)  -\\sin(-0.2) \\\\\n\\text{sech}^2(0.7)  -\\text{sech}^2(0.7)\n\\end{bmatrix} = \\begin{bmatrix}\n1  \\sin(0.2) \\\\\n\\text{sech}^2(0.7)  -\\text{sech}^2(0.7)\n\\end{bmatrix}\n$$\n使用数值：\n$\\sin(0.2) \\approx 0.198669$\n$\\text{sech}^2(0.7) = (1/\\cosh(0.7))^2 \\approx 0.634737$\n$$\nH_k \\approx \\begin{bmatrix}\n1.0  0.198669 \\\\\n0.634737  -0.634737\n\\end{bmatrix}\n$$\n\n**2. 协方差传播**\n\nEKF 预测步骤的方程为：\n- 预测状态协方差：$P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k$\n- 新息协方差：$S_k = H_k P_{k|k-1} H_k^T + R_k$\n\n我们现在使用计算出的雅可比矩阵 $F_k$ 和 $H_k$ 将这些方程应用于三种测试情况中的每一种。\n\n**情况 1：标称协方差**\n给定：\n$$\nP_{k-1|k-1}^{(1)} = \\begin{bmatrix} 0.2  0.05 \\\\ 0.05  0.1 \\end{bmatrix}, \\quad\nQ_k^{(1)} = \\begin{bmatrix} 0.01  0 \\\\ 0  0.01 \\end{bmatrix}, \\quad\nR_k^{(1)} = \\begin{bmatrix} 0.05  0.01 \\\\ 0.01  0.02 \\end{bmatrix}\n$$\n计算：\n$P_{k|k-1}^{(1)} = F_k P_{k-1|k-1}^{(1)} F_k^T + Q_k^{(1)} \\approx \\begin{bmatrix} 0.347590  0.144986 \\\\ 0.144986  0.129335 \\end{bmatrix}$\n$S_k^{(1)} = H_k P_{k|k-1}^{(1)} H_k^T + R_k^{(1)} \\approx \\begin{bmatrix} 0.533221  0.133277 \\\\ 0.133277  0.113038 \\end{bmatrix}$\n\n情况 1 的结果：\n- $\\operatorname{tr}(P_{k|k-1}^{(1)}) \\approx 0.476924$\n- $\\operatorname{tr}(S_k^{(1)}) \\approx 0.646259$\n- $\\det(P_{k|k-1}^{(1)}) \\approx 0.023847$\n- $\\det(S_k^{(1)}) \\approx 0.042512$\n\n**情况 2：接近确定性的过程**\n给定：\n$$\nP_{k-1|k-1}^{(2)} = \\begin{bmatrix} 10^{-6}  0 \\\\ 0  10^{-6} \\end{bmatrix}, \\quad\nQ_k^{(2)} = \\begin{bmatrix} 0  0 \\\\ 0  0 \\end{bmatrix}, \\quad\nR_k^{(2)} = \\begin{bmatrix} 10^{-3}  0 \\\\ 0  10^{-3} \\end{bmatrix}\n$$\n计算：\n$P_{k|k-1}^{(2)} = F_k P_{k-1|k-1}^{(2)} F_k^T + Q_k^{(2)} \\approx \\begin{bmatrix} 1.9605 \\times 10^{-6}  8.8752 \\times 10^{-7} \\\\ 8.8752 \\times 10^{-7}  1.1056 \\times 10^{-6} \\end{bmatrix}$\n$S_k^{(2)} = H_k P_{k|k-1}^{(2)} H_k^T + R_k^{(2)} \\approx \\begin{bmatrix} 0.003463  0.000676 \\\\ 0.000676  0.001000 \\end{bmatrix}$\n\n情况 2 的结果：\n- $\\operatorname{tr}(P_{k|k-1}^{(2)}) \\approx 3.0661 \\times 10^{-6}$\n- $\\operatorname{tr}(S_k^{(2)}) \\approx 0.004464$\n- $\\det(P_{k|k-1}^{(2)}) \\approx 1.3814 \\times 10^{-12}$\n- $\\det(S_k^{(2)}) \\approx 3.0062 \\times 10^{-6}$\n\n**情况 3：大的先验和过程噪声**\n给定：\n$$\nP_{k-1|k-1}^{(3)} = \\begin{bmatrix} 5  2 \\\\ 2  3 \\end{bmatrix}, \\quad\nQ_k^{(3)} = \\begin{bmatrix} 0.5  0.2 \\\\ 0.2  0.5 \\end{bmatrix}, \\quad\nR_k^{(3)} = \\begin{bmatrix} 0.3  0 \\\\ 0  0.3 \\end{bmatrix}\n$$\n计算：\n$P_{k|k-1}^{(3)} = F_k P_{k-1|k-1}^{(3)} F_k^T + Q_k^{(3)} \\approx \\begin{bmatrix} 11.516569  7.683617 \\\\ 7.683617  5.378907 \\end{bmatrix}$\n$S_k^{(3)} = H_k P_{k|k-1}^{(3)} H_k^T + R_k^{(3)} \\approx \\begin{bmatrix} 17.568431  2.879784 \\\\ 2.879784  2.756264 \\end{bmatrix}$\n\n情况 3 的结果：\n- $\\operatorname{tr}(P_{k|k-1}^{(3)}) \\approx 16.895476$\n- $\\operatorname{tr}(S_k^{(3)}) \\approx 20.324694$\n- $\\det(P_{k|k-1}^{(3)}) \\approx 2.874458$\n- $\\det(S_k^{(3)}) \\approx 40.117946$\n\n这些结果将在随附的程序中以全精度计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Jacobians and performs EKF covariance propagation for three test cases.\n    \"\"\"\n    # 1. Define the point of linearization\n    x = np.array([0.5, -0.2])\n    x1, x2 = x\n\n    # 2. Compute Jacobian matrices F_k and H_k\n    # The problem asks for Jacobians via Automatic Differentiation (AD).\n    # For this system, symbolic differentiation is straightforward and yields\n    # the exact same result as an AD tool would.\n\n    # Process model Jacobian F_k\n    F_k = np.array([\n        [1.0, np.cos(x2)],\n        [0.1 * x2 * np.exp(0.1 * x1), np.exp(0.1 * x1)]\n    ])\n\n    # Observation model Jacobian H_k\n    sech_sq_val = 1.0 / (np.cosh(x1 - x2)**2)\n    H_k = np.array([\n        [2 * x1, -np.sin(x2)],\n        [sech_sq_val, -sech_sq_val]\n    ])\n\n    # 3. Define test cases\n    test_cases = [\n        # Case 1 (nominal covariances)\n        {\n            \"P_prev\": np.array([[0.2, 0.05], [0.05, 0.1]]),\n            \"Q\": np.array([[0.01, 0], [0, 0.01]]),\n            \"R\": np.array([[0.05, 0.01], [0.01, 0.02]])\n        },\n        # Case 2 (near-deterministic process)\n        {\n            \"P_prev\": np.array([[1e-6, 0], [0, 1e-6]]),\n            \"Q\": np.array([[0, 0], [0, 0]]),\n            \"R\": np.array([[1e-3, 0], [0, 1e-3]])\n        },\n        # Case 3 (large prior and process noise)\n        {\n            \"P_prev\": np.array([[5, 2], [2, 3]]),\n            \"Q\": np.array([[0.5, 0.2], [0.2, 0.5]]),\n            \"R\": np.array([[0.3, 0], [0, 0.3]])\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        P_prev = case[\"P_prev\"]\n        Q = case[\"Q\"]\n        R = case[\"R\"]\n\n        # 4. EKF covariance propagation step\n        # Predicted (a priori) state covariance: P_k|k-1 = F_k * P_k-1|k-1 * F_k^T + Q_k\n        P_pred = F_k @ P_prev @ F_k.T + Q\n\n        # Innovation (or residual) covariance: S_k = H_k * P_k|k-1 * H_k^T + R_k\n        S_k = H_k @ P_pred @ H_k.T + R\n\n        # 5. Compute the required quantities (trace and determinant)\n        tr_P_pred = np.trace(P_pred)\n        tr_S_k = np.trace(S_k)\n        det_P_pred = np.linalg.det(P_pred)\n        det_S_k = np.linalg.det(S_k)\n\n        case_results = [tr_P_pred, tr_S_k, det_P_pred, det_S_k]\n        all_results.append(case_results)\n\n    # 6. Format the output string precisely as required, with no spaces.\n    # We manually build the string representation of the list of lists.\n    sublist_strings = []\n    for sublist in all_results:\n        # Convert each number in the sublist to a string\n        items_as_strings = [str(item) for item in sublist]\n        # Join them with commas and wrap in brackets\n        sublist_str = '[' + ','.join(items_as_strings) + ']'\n        sublist_strings.append(sublist_str)\n\n    # Join the sublist strings with commas and wrap in outer brackets\n    final_output_str = '[' + ','.join(sublist_strings) + ']'\n\n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```", "id": "3380750"}, {"introduction": "扩展卡尔曼滤波的简洁和高效源于其线性化近似，但这同样是其主要的误差来源。本练习深刻地揭示了这一权衡，它将EKF的预测结果与另一种常用的非线性滤波方法——无迹卡尔曼滤波（UKF）以及一个简单二次非线性系统的精确解析解进行对比。通过推导EKF的预测偏差项[@problem_id:3380789]，你将从量化的角度深入理解系统模型中的非线性（特别是曲率）是如何影响EKF预测精度的，从而认识到该方法的基本局限性。", "problem": "考虑一个标量、离散时间、噪声驱动的非线性动力学系统，其状态 $x \\in \\mathbb{R}$ 由下式给出\n$$\nx_{k+1} = f(x_k) + w_k, \\quad f(x) = x + \\beta x^{2},\n$$\n其中 $\\beta \\in \\mathbb{R}$ 是一个已知参数，$w_k$ 是独立于 $x_k$ 的零均值过程噪声。假设在时刻 $k$ 的先验分布是高斯分布，其均值和方差为\n$$\nx_k \\sim \\mathcal{N}(m, P), \\quad P > 0.\n$$\n要求您在两种高斯滤波近似下分析预测均值。\n\n任务：\n1. 使用扩展卡尔曼滤波器（EKF）的定义，将 $f$ 在先验均值处进行一阶线性化，推导出预测均值 $\\mu_{\\mathrm{EKF}}$。\n2. 使用无迹卡尔曼滤波器（UKF）和无迹变换（UT），在维度 $L=1$ 以及通用缩放参数 $\\alpha > 0$ 和 $\\kappa \\in \\mathbb{R}$ 的条件下，推导出预测均值 $\\mu_{\\mathrm{UKF}}$。使用 $L=1$ 的标准sigma点构造方法：\n   - 定义 $\\lambda = \\alpha^{2}(L+\\kappa) - L$。\n   - 定义sigma点\n     $$\n     \\chi_{0} = m, \\quad \\chi_{1} = m + \\sqrt{(L+\\lambda)P}, \\quad \\chi_{2} = m - \\sqrt{(L+\\lambda)P}.\n     $$\n   - 使用均值权重\n     $$\n     W_{0}^{(m)} = \\frac{\\lambda}{L+\\lambda}, \\quad W_{1}^{(m)} = W_{2}^{(m)} = \\frac{1}{2(L+\\lambda)}.\n     $$\n   此处不需要协方差公式中出现的第三个UT参数。请明确显示结果与UT参数的相关性或无关性。\n3. 仅使用高斯多项式期望的性质，将精确的预测均值 $\\mu_{\\mathrm{exact}} = \\mathbb{E}[f(x_k)]$ 写成 $m$、$P$ 和 $\\beta$ 的函数。\n4. 通过比较您的EKF和UKF表达式，量化二阶偏差差异，此处定义为预测均值之差 $\\mu_{\\mathrm{UKF}} - \\mu_{\\mathrm{EKF}}$，并将其表示为 $P$、$m$ 和 $\\beta$ 的函数。请以单个简化的解析表达式形式提供您的最终答案。无需进行数值评估。\n\n答案形式要求：您最终提交的答案必须是单个封闭形式的解析表达式。不包含单位。不要四舍五入。", "solution": "该问题要求在三种不同的计算方法下，对一个标量非线性系统的预测均值进行分析：扩展卡尔曼滤波器（EKF）、无迹卡尔曼滤波器（UKF）和精确解析期望。最终目标是量化UKF和EKF预测均值之间的差异。\n\n该系统由状态空间模型 $x_{k+1} = f(x_k) + w_k$ 描述，其中非线性函数为 $f(x) = x + \\beta x^2$。在时刻 $k$ 的状态 $x_k$ 是一个服从高斯分布的随机变量，$x_k \\sim \\mathcal{N}(m, P)$，其中 $m$ 是均值，$P$ 是方差。过程噪声 $w_k$ 是零均值的，即 $\\mathbb{E}[w_k] = 0$，且独立于 $x_k$。在时刻 $k+1$ 的预测均值为 $\\mathbb{E}[x_{k+1}] = \\mathbb{E}[f(x_k) + w_k] = \\mathbb{E}[f(x_k)] + \\mathbb{E}[w_k] = \\mathbb{E}[f(x_k)]$。因此，任务简化为使用指定方法计算变换后状态的期望 $\\mathbb{E}[f(x_k)]$。\n\n1. EKF预测均值 $\\mu_{\\mathrm{EKF}}$ 的推导\n\n扩展卡尔曼滤波器通过在状态均值 $m$ 附近对非线性函数 $f(x)$ 进行一阶泰勒级数展开来近似该函数。近似式为：\n$$\nf(x_k) \\approx f(m) + f'(m)(x_k - m)\n$$\n函数 $f(x) = x + \\beta x^2$ 关于 $x$ 的导数为 $f'(x) = 1 + 2\\beta x$。在 $x=m$ 处求值得到 $f'(m) = 1 + 2\\beta m$。\n\nEKF预测均值 $\\mu_{\\mathrm{EKF}}$ 是这个线性化函数的期望：\n$$\n\\mu_{\\mathrm{EKF}} = \\mathbb{E}[f(m) + f'(m)(x_k - m)]\n$$\n根据期望的线性性质：\n$$\n\\mu_{\\mathrm{EKF}} = \\mathbb{E}[f(m)] + \\mathbb{E}[f'(m)(x_k - m)]\n$$\n由于 $m$ 是常数，因此 $f(m)$ 和 $f'(m)$ 相对于关于 $x_k$ 的期望也是常数。因此，我们可以写出：\n$$\n\\mu_{\\mathrm{EKF}} = f(m) + f'(m)\\mathbb{E}[x_k - m]\n$$\n根据定义，$x_k$ 的期望是 $m$，所以 $\\mathbb{E}[x_k - m] = \\mathbb{E}[x_k] - m = m - m = 0$。因此，第二项消失：\n$$\n\\mu_{\\mathrm{EKF}} = f(m) = m + \\beta m^2\n$$\n\n2. UKF预测均值 $\\mu_{\\mathrm{UKF}}$ 的推导\n\n无迹卡尔曼滤波器使用无迹变换（UT）来估计变换后分布的均值。该过程包括将一组确定性选择的sigma点通过真实的非线性函数 $f(x)$ 进行传播，并计算加权平均值。\n\n维度 $L=1$ 的UT参数如下：\n- 缩放参数 $\\lambda = \\alpha^2(L+\\kappa) - L = \\alpha^2(1+\\kappa) - 1$。\n- 项 $L+\\lambda = \\alpha^2(1+\\kappa)$。\n- sigma点为：\n  - $\\chi_0 = m$\n  - $\\chi_1 = m + \\sqrt{(L+\\lambda)P} = m + \\sqrt{\\alpha^2(1+\\kappa)P}$\n  - $\\chi_2 = m - \\sqrt{(L+\\lambda)P} = m - \\sqrt{\\alpha^2(1+\\kappa)P}$\n- 均值权重为：\n  - $W_0^{(m)} = \\frac{\\lambda}{L+\\lambda} = \\frac{\\lambda}{1+\\lambda}$\n  - $W_1^{(m)} = W_2^{(m)} = \\frac{1}{2(L+\\lambda)} = \\frac{1}{2(1+\\lambda)}$\n\n权重之和为 $W_0^{(m)} + W_1^{(m)} + W_2^{(m)} = \\frac{\\lambda}{1+\\lambda} + 2\\left(\\frac{1}{2(1+\\lambda)}\\right) = \\frac{\\lambda+1}{1+\\lambda} = 1$。\n\nUKF预测均值为 $\\mu_{\\mathrm{UKF}} = \\sum_{i=0}^{2} W_i^{(m)} f(\\chi_i)$。首先，在每个sigma点处计算 $f(x) = x + \\beta x^2$ 的值：\n- $f(\\chi_0) = f(m) = m + \\beta m^2$\n- $f(\\chi_1) = (m + \\sqrt{(1+\\lambda)P}) + \\beta(m + \\sqrt{(1+\\lambda)P})^2 = m + \\sqrt{(1+\\lambda)P} + \\beta(m^2 + 2m\\sqrt{(1+\\lambda)P} + (1+\\lambda)P)$\n- $f(\\chi_2) = (m - \\sqrt{(1+\\lambda)P}) + \\beta(m - \\sqrt{(1+\\lambda)P})^2 = m - \\sqrt{(1+\\lambda)P} + \\beta(m^2 - 2m\\sqrt{(1+\\lambda)P} + (1+\\lambda)P)$\n\n现在，我们计算加权和：\n$$\n\\mu_{\\mathrm{UKF}} = W_0^{(m)}f(\\chi_0) + W_1^{(m)}f(\\chi_1) + W_2^{(m)}f(\\chi_2)\n$$\n由于 $W_1^{(m)} = W_2^{(m)}$，我们可以将各项分组：\n$$\n\\mu_{\\mathrm{UKF}} = W_0^{(m)}f(\\chi_0) + W_1^{(m)}(f(\\chi_1) + f(\\chi_2))\n$$\n我们来计算和 $f(\\chi_1) + f(\\chi_2)$：\n$$\nf(\\chi_1) + f(\\chi_2) = (2m) + \\beta( (m^2 + 2m\\sqrt{\\dots} + (1+\\lambda)P) + (m^2 - 2m\\sqrt{\\dots} + (1+\\lambda)P) )\n$$\n$$\nf(\\chi_1) + f(\\chi_2) = 2m + \\beta(2m^2 + 2(1+\\lambda)P) = 2(m + \\beta m^2) + 2\\beta(1+\\lambda)P\n$$\n将此结果代回 $\\mu_{\\mathrm{UKF}}$ 的表达式中：\n$$\n\\mu_{\\mathrm{UKF}} = W_0^{(m)}(m + \\beta m^2) + W_1^{(m)}[2(m + \\beta m^2) + 2\\beta(1+\\lambda)P]\n$$\n$$\n\\mu_{\\mathrm{UKF}} = (W_0^{(m)} + 2W_1^{(m)})(m + \\beta m^2) + 2W_1^{(m)}\\beta(1+\\lambda)P\n$$\n由于权重之和为 $W_0^{(m)} + 2W_1^{(m)} = 1$，且 $2W_1^{(m)} = 2\\left(\\frac{1}{2(1+\\lambda)}\\right) = \\frac{1}{1+\\lambda}$，表达式可简化为：\n$$\n\\mu_{\\mathrm{UKF}} = 1 \\cdot (m + \\beta m^2) + \\frac{1}{1+\\lambda}\\beta(1+\\lambda)P = m + \\beta m^2 + \\beta P\n$$\nUKF预测均值为 $\\mu_{\\mathrm{UKF}} = m + \\beta m^2 + \\beta P$。值得注意的是，这个结果与UT的缩放参数 $\\alpha$ 和 $\\kappa$ 无关。\n\n3. 精确预测均值 $\\mu_{\\mathrm{exact}}$ 的推导\n\n精确预测均值是在 $x_k \\sim \\mathcal{N}(m, P)$ 条件下 $f(x_k)$ 的真实期望。\n$$\n\\mu_{\\mathrm{exact}} = \\mathbb{E}[f(x_k)] = \\mathbb{E}[x_k + \\beta x_k^2]\n$$\n利用期望的线性性质：\n$$\n\\mu_{\\mathrm{exact}} = \\mathbb{E}[x_k] + \\beta \\mathbb{E}[x_k^2]\n$$\n已知 $\\mathbb{E}[x_k] = m$。二阶矩 $\\mathbb{E}[x_k^2]$ 通过公式 $\\mathrm{Var}(x_k) = \\mathbb{E}[x_k^2] - (\\mathbb{E}[x_k])^2$ 与均值和方差相关联。\n由于 $\\mathrm{Var}(x_k) = P$，我们有：\n$$\n\\mathbb{E}[x_k^2] = \\mathrm{Var}(x_k) + (\\mathbb{E}[x_k])^2 = P + m^2\n$$\n将此结果代入 $\\mu_{\\mathrm{exact}}$ 的表达式中：\n$$\n\\mu_{\\mathrm{exact}} = m + \\beta (P + m^2) = m + \\beta m^2 + \\beta P\n$$\n这表明对于二次非线性，无迹变换能够提供精确的预测均值，即 $\\mu_{\\mathrm{UKF}} = \\mu_{\\mathrm{exact}}$。\n\n4. 二阶偏差差异的计算\n\n问题将二阶偏差差异定义为UKF和EKF预测均值之差，即 $\\mu_{\\mathrm{UKF}} - \\mu_{\\mathrm{EKF}}$。使用前面部分的结果：\n- $\\mu_{\\mathrm{EKF}} = m + \\beta m^2$\n- $\\mu_{\\mathrm{UKF}} = m + \\beta m^2 + \\beta P$\n\n差值为：\n$$\n\\mu_{\\mathrm{UKF}} - \\mu_{\\mathrm{EKF}} = (m + \\beta m^2 + \\beta P) - (m + \\beta m^2)\n$$\n$$\n\\mu_{\\mathrm{UKF}} - \\mu_{\\mathrm{EKF}} = \\beta P\n$$\n这一项 $\\beta P$ 代表了EKF均值预测中的主阶误差或偏差。产生这种偏差的原因是EKF近似对函数进行了线性化，从而忽略了其曲率（二阶导数）对变换后分布均值的影响。而UKF通过其对称的sigma点集，正确地捕捉到了这个二阶项，从而得到了一个更准确的均值估计，在本例的二次函数情况下，这个估计是精确的。两种滤波器预测值之间的差异正是这个二阶项。\n最终要求的表达式就是这个差异的解析形式。", "answer": "$$\\boxed{\\beta P}$$", "id": "3380789"}, {"introduction": "一个滤波器的性能优劣，很大程度上取决于其模型参数的准确性，尤其是过程噪声和测量噪声的协方差。这个练习将引导你从简单地“应用”滤波器，转向“改进”滤波器。我们将探讨如何利用滤波器自身的输出——新息（innovations）序列，来反向估计测量噪声的大小。通过构建并求解一个最大似然估计问题[@problem_id:3380804]，你将掌握一种基于数据、有理论依据的滤波器调优方法，这是将卡尔曼滤波应用于真实世界问题的关键一步。", "problem": "考虑一个扩展卡尔曼滤波器（EKF），应用于一个离散时间非线性观测模型，该模型在每个时间步长进行 $m$ 维测量。令时间步长 $k$ 的新息定义为 $\\tilde{y}_k = y_k - h(x_{k|k-1})$，其中 $h(\\cdot)$ 是在先验状态估计上求值的观测函数。假设高斯新息假设成立：以滤波器的预测协方差为条件，$\\tilde{y}_k$ 是一个零均值高斯变量，其新息协方差为 $S_k$。在线性化条件下，新息协方差的形式为 $S_k = H_k P_{k|k-1} H_k^\\top + R_k$，其中 $H_k$ 是 $h(\\cdot)$ 在先验估计处的雅可比矩阵，$P_{k|k-1}$ 是先验状态协方差，$R_k$ 是测量噪声协方差。\n\n假设测量噪声协方差是各向同性且时不变的，即 $R_k = r I_m$，其中未知标量方差 $r \\ge 0$。此外，假设在线性化和先验在用于估计的 $M$ 个同化步骤中是恒定的，即 $H_k = H$ 和 $P_{k|k-1} = P$，并且 $H P H^\\top = \\Sigma$ 是已知的各向同性矩阵，$\\Sigma = \\sigma^2 I_m$，其中已知标量 $\\sigma^2 > 0$。因此，每个步骤的新息协方差为 $S(r) = \\Sigma + r I_m = (\\sigma^2 + r) I_m$。\n\n给定观测到的新息集合 $\\{\\tilde{y}_k\\}_{k=1}^M$，假设以 $r$ 为条件，$\\tilde{y}_k$ 是独立同分布的。仅使用多元高斯密度和独立性的基本性质，为 $r$ 构建最大似然估计问题，并在容许集 $r \\ge 0$ 上推导出最大似然估计 $\\hat{r}$ 的闭式表达式。您的最终答案必须是关于 $M$、$m$、$\\sigma^2$ 和 $\\{\\tilde{y}_k\\}_{k=1}^M$ 的单一解析表达式。无需进行数值四舍五入。", "solution": "用户希望求出测量噪声方差参数 $r$ 的最大似然估计（MLE）。\n\n### 步骤 1：提取已知条件\n-   **系统模型**：离散时间非线性观测模型。\n-   **新息**：$\\tilde{y}_k = y_k - h(x_{k|k-1})$ 是时间步长 $k$ 的新息。$\\tilde{y}_k$ 是一个 $m$ 维向量。\n-   **新息分布**：以滤波器的预测协方差为条件，$\\tilde{y}_k$ 是一个零均值高斯随机变量，即 $\\tilde{y}_k \\sim \\mathcal{N}(0, S_k)$。\n-   **新息协方差**：$S_k = H_k P_{k|k-1} H_k^\\top + R_k$。\n-   **测量噪声协方差**：$R_k = r I_m$，其中 $r \\ge 0$ 是一个未知标量方差，$I_m$ 是 $m \\times m$ 单位矩阵。\n-   **简化假设**：\n    -   一组包含 $M$ 个新息的数据 $\\{\\tilde{y}_k\\}_{k=1}^M$ 可用。\n    -   雅可比矩阵 $H_k$ 和先验状态协方差 $P_{k|k-1}$ 对于 $k=1, \\dots, M$ 是恒定的，即 $H_k = H$ 且 $P_{k|k-1} = P$。\n    -   项 $H P H^\\top$ 是已知的各向同性矩阵：$H P H^\\top = \\Sigma = \\sigma^2 I_m$，其中 $\\sigma^2 > 0$ 是一个已知标量。\n-   **最终的新息协方差**：$S(r) = \\Sigma + r I_m = \\sigma^2 I_m + r I_m = (\\sigma^2 + r) I_m$。\n-   **统计假设**：以 $r$ 为条件，新息 $\\{\\tilde{y}_k\\}_{k=1}^M$ 是独立同分布（i.i.d.）的。\n-   **目标**：在容许集 $r \\ge 0$ 上推导出 $r$ 的最大似然估计 $\\hat{r}$ 的闭式表达式。该表达式应以 $M$、$m$、$\\sigma^2$ 和 $\\{\\tilde{y}_k\\}_{k=1}^M$ 表示。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学依据**：该问题是卡尔曼滤波和数据同化背景下的一个标准参数估计任务。使用最大似然估计来调整噪声协方差矩阵是一种成熟且科学合理的技术。所有概念都是统计信号处理和控制理论的基础。\n-   **适定性**：该问题提供了唯一确定最大似然估计（MLE）所需的所有信息（分布、独立同分布假设、简化的协方差结构、已知量和未知量）。对于方差参数而言，约束 $r \\ge 0$ 具有物理意义。\n-   **目标**：问题以精确的数学语言陈述，没有歧义或主观元素。\n-   **缺陷核查清单**：该问题不违反任何无效性标准。它科学合理、自洽、一致，并提出了一个可形式化的问题。所做的假设虽然简化了问题，但明确指出是为了使问题在分析上易于处理。\n\n### 步骤 3：结论与行动\n该问题有效。将提供一个完整的、有理有据的解答。\n\n### 最大似然估计的推导\n\n目标是找到使观测到给定新息集合 $\\{\\tilde{y}_k\\}_{k=1}^M$ 的似然最大的 $r$ 值。\n\n单个 $m$ 维多元高斯随机变量 $\\mathbf{z}$ 的概率密度函数（PDF），其均值向量为 $\\boldsymbol{\\mu}$，协方差矩阵为 $\\mathbf{\\Sigma}$，由下式给出：\n$$p(\\mathbf{z}) = \\frac{1}{(2\\pi)^{m/2} |\\mathbf{\\Sigma}|^{1/2}} \\exp\\left(-\\frac{1}{2} (\\mathbf{z}-\\boldsymbol{\\mu})^\\top \\mathbf{\\Sigma}^{-1} (\\mathbf{z}-\\boldsymbol{\\mu})\\right)$$\n在我们的问题中，对于单个新息 $\\tilde{y}_k$，均值为 $\\boldsymbol{\\mu} = 0$，协方差为 $S(r) = (\\sigma^2 + r) I_m$。我们必须首先计算 $S(r)$ 的行列式和逆矩阵。\n\n行列式为：\n$$|S(r)| = |(\\sigma^2 + r) I_m| = (\\sigma^2 + r)^m$$\n逆矩阵为：\n$$S(r)^{-1} = ((\\sigma^2 + r) I_m)^{-1} = \\frac{1}{\\sigma^2 + r} I_m$$\n指数中的二次型为：\n$$\\tilde{y}_k^\\top S(r)^{-1} \\tilde{y}_k = \\tilde{y}_k^\\top \\left(\\frac{1}{\\sigma^2 + r} I_m\\right) \\tilde{y}_k = \\frac{\\tilde{y}_k^\\top \\tilde{y}_k}{\\sigma^2 + r}$$\n项 $\\tilde{y}_k^\\top \\tilde{y}_k$ 是向量 $\\tilde{y}_k$ 的欧几里得范数的平方。\n\n将这些代入PDF公式，单个观测值 $\\tilde{y}_k$ 的似然函数为：\n$$p(\\tilde{y}_k|r) = \\frac{1}{(2\\pi)^{m/2} ((\\sigma^2 + r)^m)^{1/2}} \\exp\\left(-\\frac{\\tilde{y}_k^\\top \\tilde{y}_k}{2(\\sigma^2 + r)}\\right) = \\frac{1}{(2\\pi(\\sigma^2 + r))^{m/2}} \\exp\\left(-\\frac{\\tilde{y}_k^\\top \\tilde{y}_k}{2(\\sigma^2 + r)}\\right)$$\n由于新息 $\\{\\tilde{y}_k\\}_{k=1}^M$ 是独立同分布的，联合似然函数 $L(r)$ 是各个似然函数的乘积：\n$$L(r; \\{\\tilde{y}_k\\}) = \\prod_{k=1}^M p(\\tilde{y}_k|r) = \\prod_{k=1}^M \\left[ \\frac{1}{(2\\pi(\\sigma^2 + r))^{m/2}} \\exp\\left(-\\frac{\\tilde{y}_k^\\top \\tilde{y}_k}{2(\\sigma^2 + r)}\\right) \\right]$$\n$$L(r) = \\left( \\frac{1}{(2\\pi(\\sigma^2 + r))^{m/2}} \\right)^M \\exp\\left(-\\sum_{k=1}^M \\frac{\\tilde{y}_k^\\top \\tilde{y}_k}{2(\\sigma^2 + r)}\\right)$$\n$$L(r) = (2\\pi)^{-Mm/2} (\\sigma^2 + r)^{-Mm/2} \\exp\\left(-\\frac{1}{2(\\sigma^2 + r)} \\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k\\right)$$\n为了求最大值，使用对数似然函数 $\\mathcal{L}(r) = \\ln(L(r))$ 更为方便：\n$$\\mathcal{L}(r) = \\ln\\left((2\\pi)^{-Mm/2}\\right) + \\ln\\left((\\sigma^2 + r)^{-Mm/2}\\right) + \\ln\\left(\\exp\\left(-\\frac{1}{2(\\sigma^2 + r)} \\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k\\right)\\right)$$\n$$\\mathcal{L}(r) = -\\frac{Mm}{2}\\ln(2\\pi) - \\frac{Mm}{2}\\ln(\\sigma^2 + r) - \\frac{1}{2(\\sigma^2 + r)}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k$$\n为了找到使 $\\mathcal{L}(r)$ 最大化的 $r$ 值，我们对 $r$ 求导并将导数置为零。第一项是常数，其导数为零。\n$$\\frac{d\\mathcal{L}}{dr} = \\frac{d}{dr}\\left( - \\frac{Mm}{2}\\ln(\\sigma^2 + r) - \\frac{1}{2}(\\sigma^2 + r)^{-1}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k \\right)$$\n$$\\frac{d\\mathcal{L}}{dr} = - \\frac{Mm}{2} \\cdot \\frac{1}{\\sigma^2 + r} - \\left( -1 \\cdot (\\sigma^2 + r)^{-2} \\right) \\frac{1}{2}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k$$\n$$\\frac{d\\mathcal{L}}{dr} = -\\frac{Mm}{2(\\sigma^2 + r)} + \\frac{1}{2(\\sigma^2 + r)^2}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k$$\n将导数置为零以找到无约束最大化器 $r^*$：\n$$\\frac{Mm}{2(\\sigma^2 + r^*)} = \\frac{1}{2(\\sigma^2 + r^*)^2}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k$$\n假设 $\\sigma^2 + r^* > 0$（这是对数似然函数有定义所必需的，并且由于 $\\sigma^2 > 0$ 和 $r \\ge 0$ 而成立），我们可以将两边同乘以 $2(\\sigma^2 + r^*)^2$：\n$$Mm(\\sigma^2 + r^*) = \\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k$$\n求解 $r^*$：\n$$\\sigma^2 + r^* = \\frac{1}{Mm}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k$$\n$$r^* = \\frac{1}{Mm}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k - \\sigma^2$$\n这是 $r$ 的无约束估计。然而，问题指定了约束 $r \\ge 0$，因为方差不能为负。最大似然估计 $\\hat{r}$ 必须满足此约束。\n\n对数似然函数 $\\mathcal{L}(r)$ 是单峰的，其最大值在 $r^*$ 处。我们有两种情况：\n1.  如果 $r^* \\ge 0$，则无约束最大值位于容许集 $[0, \\infty)$ 内。因此，有约束最大值为 $\\hat{r} = r^*$。\n2.  如果 $r^*  0$，则无约束最大值位于容许集之外。由于函数 $\\mathcal{L}(r)$ 对于所有 $r > r^*$ 都是单调递减的，因此在区间 $[0, \\infty)$ 上的最大值必须出现在边界点 $r = 0$ 处。\n\n这两种情况可以使用最大值函数合并成一个单一的表达式：\n$$\\hat{r} = \\max\\left(0, r^*\\right) = \\max\\left(0, \\frac{1}{Mm}\\sum_{k=1}^M \\tilde{y}_k^\\top \\tilde{y}_k - \\sigma^2\\right)$$\n这就是 $r$ 的最大似然估计的闭式表达式。它用给定的量 $M$、$m$、$\\sigma^2$ 和新息集合 $\\{\\tilde{y}_k\\}_{k=1}^M$ 表示。", "answer": "$$\\boxed{\\max\\left(0, \\frac{1}{Mm}\\sum_{k=1}^{M} \\tilde{y}_k^\\top \\tilde{y}_k - \\sigma^2\\right)}$$", "id": "3380804"}]}