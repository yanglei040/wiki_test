{"hands_on_practices": [{"introduction": "理论联系实践的最佳方式是亲手计算。本练习将引导你逐步完成卡尔曼滤波器在一个简单标量系统中的核心运算。你将通过计算“新息”(innovation)——即观测值与预测值之差——及其方差，来深入理解预测-校正框架的内部机制。这项练习不仅能巩固你对滤波器工作流程的理解，还揭示了如何利用新息序列计算整个观测数据的似然函数，这在模型选择和参数估计等高级应用中至关重要。[@problem_id:3413392]", "problem": "考虑一个标量线性高斯状态空间模型，其由随机游走动态和直接带噪观测给出：\n- 状态演化：$x_{k} = x_{k-1} + w_{k}$，其中过程噪声为 $w_{k} \\sim \\mathcal{N}(0, Q)$。\n- 观测：$y_{k} = x_{k} + v_{k}$，其中观测噪声为 $v_{k} \\sim \\mathcal{N}(0, R)$。\n假设 $w_{k}$ 和 $v_{k}$ 在时间上独立且相互独立。状态转移矩阵为 $F = 1$，观测矩阵为 $H = 1$。过程噪声方差和观测噪声方差已知，分别为 $Q = 0.2$ 和 $R = 0.5$。初始状态的先验分布是高斯分布，其均值为 $m_{0|0} = 0$，方差为 $P_{0|0} = 1$。\n\n给定观测序列 $\\{y_{k}\\}_{k=1}^{4}$，其值为 $y_{1} = 0.3$, $y_{2} = -0.1$, $y_{3} = 0.5$, 和 $y_{4} = 0.2$。\n\n使用预测-校正框架，定义一步预测器 $(m_{k|k-1}, P_{k|k-1})$、新息 $\\nu_{k} = y_{k} - m_{k|k-1}$ 和新息方差 $S_{k}$。从线性高斯模型和高斯条件密度的第一性原理出发，推导增量对数似然 $\\ell_{k} = \\ln p(y_{k} \\mid y_{1:k-1})$ 关于 $\\nu_{k}$ 和 $S_{k}$ 的表达式，然后对给定的数据计算当 $k = 1, 2, 3, 4$ 时的 $\\nu_{k}$、$S_{k}$ 和 $\\ell_{k}$。最后，报告总对数似然 $L = \\sum_{k=1}^{4} \\ell_{k}$。\n\n将您报告的最终 $L$ 值四舍五入到四位有效数字。答案以纯数字形式表示（无单位）。", "solution": "该问题要求计算来自标量线性高斯状态空间模型的给定观测序列的总对数似然。求解方法基于预测-校正框架，通常称为卡尔曼滤波器，该框架允许顺序评估增量对数似然。\n\n首先，我们为增量对数似然建立理论基础。观测序列 $y_{1:T} = \\{y_1, y_2, \\ldots, y_T\\}$ 的总对数似然 $L$ 由概率的链式法则给出：\n$$ L = \\ln p(y_{1:T}) = \\ln \\left( p(y_1) \\prod_{k=2}^{T} p(y_k \\mid y_{1:k-1}) \\right) = \\sum_{k=1}^{T} \\ln p(y_k \\mid y_{1:k-1}) $$\n其中我们将 $p(y_1 \\mid y_{1:0})$ 定义为 $p(y_1)$。项 $\\ell_k = \\ln p(y_k \\mid y_{1:k-1})$ 是在时间步 $k$ 的增量对数似然。\n\n在线性高斯状态空间模型中，所有条件分布都是高斯分布。在时间 $k-1$ 的滤波分布为 $p(x_{k-1} \\mid y_{1:k-1}) = \\mathcal{N}(x_{k-1} ; m_{k-1|k-1}, P_{k-1|k-1})$。\n\n滤波器的预测步骤计算状态的一步向前预测分布 $p(x_k \\mid y_{1:k-1})$。\n给定 $x_k = F x_{k-1} + w_k$ 其中 $w_k \\sim \\mathcal{N}(0, Q)$，$x_k$ 的预测分布是均值为 $m_{k|k-1}$、方差为 $P_{k|k-1}$ 的高斯分布：\n$$ m_{k|k-1} = \\mathbb{E}[x_k \\mid y_{1:k-1}] = \\mathbb{E}[F x_{k-1} + w_k \\mid y_{1:k-1}] = F m_{k-1|k-1} $$\n$$ P_{k|k-1} = \\text{Var}(x_k \\mid y_{1:k-1}) = \\text{Var}(F x_{k-1} + w_k \\mid y_{1:k-1}) = F P_{k-1|k-1} F^T + Q $$\n数对 $(m_{k|k-1}, P_{k|k-1})$ 是一步预测器。\n\n接下来，我们确定在给定过去观测值 $y_{1:k-1}$ 的情况下，观测值 $y_k$ 的条件分布。给定观测模型 $y_k = H x_k + v_k$ 其中 $v_k \\sim \\mathcal{N}(0, R)$，$y_k$ 的预测分布也是高斯分布。其均值为：\n$$ \\mathbb{E}[y_k \\mid y_{1:k-1}] = \\mathbb{E}[H x_k + v_k \\mid y_{1:k-1}] = H m_{k|k-1} $$\n其方差，我们表示为新息方差 $S_k$，是：\n$$ S_k = \\text{Var}(y_k \\mid y_{1:k-1}) = \\text{Var}(H x_k + v_k \\mid y_{1:k-1}) = H P_{k|k-1} H^T + R $$\n因此，$p(y_k \\mid y_{1:k-1}) = \\mathcal{N}(y_k ; H m_{k|k-1}, S_k)$。\n\n新息定义为实际观测值与其预测均值之差：\n$$ \\nu_k = y_k - \\mathbb{E}[y_k \\mid y_{1:k-1}] = y_k - H m_{k|k-1} $$\n对于均值为 $\\mu$、方差为 $\\sigma^2$ 的标量高斯变量 $z$，其概率密度函数为 $p(z) = (2\\pi\\sigma^2)^{-1/2} \\exp(-\\frac{(z-\\mu)^2}{2\\sigma^2})$。对于 $p(y_k \\mid y_{1:k-1})$，我们有 $z=y_k$，$\\mu=H m_{k|k-1}$ 和 $\\sigma^2=S_k$。因此，增量对数似然为：\n$$ \\ell_k = \\ln p(y_k \\mid y_{1:k-1}) = -\\frac{1}{2} \\ln(2\\pi S_k) - \\frac{(y_k - H m_{k|k-1})^2}{2S_k} = -\\frac{1}{2}\\left(\\ln(2\\pi S_k) + \\frac{\\nu_k^2}{S_k}\\right) $$\n这就是所要求的表达式。为了进行计算，我们还需要校正步骤的方程，以便在观测到 $y_k$ 后更新状态估计：\n- 卡尔曼增益：$K_k = P_{k|k-1} H^T S_k^{-1}$\n- 校正后均值：$m_{k|k} = m_{k|k-1} + K_k \\nu_k$\n- 校正后方差：$P_{k|k} = (I - K_k H) P_{k|k-1}$\n\n现在，我们使用给定的参数将这些方程应用于 $k=1, 2, 3, 4$：\n- 模型参数：$F=1, H=1, Q=0.2, R=0.5$。\n- 初始状态：$m_{0|0} = 0, P_{0|0} = 1$。\n- 观测值：$y_1=0.3, y_2=-0.1, y_3=0.5, y_4=0.2$。\n\n**步骤 k=1：**\n- 预测：\n  - $m_{1|0} = F m_{0|0} = 1 \\cdot 0 = 0$\n  - $P_{1|0} = F P_{0|0} F^T + Q = 1 \\cdot 1 \\cdot 1 + 0.2 = 1.2$\n- 新息和似然：\n  - $\\nu_1 = y_1 - H m_{1|0} = 0.3 - 1 \\cdot 0 = 0.3$\n  - $S_1 = H P_{1|0} H^T + R = 1 \\cdot 1.2 \\cdot 1 + 0.5 = 1.7$\n  - $\\ell_1 = -\\frac{1}{2}\\left(\\ln(2\\pi \\cdot 1.7) + \\frac{0.3^2}{1.7}\\right) \\approx -\\frac{1}{2}(2.36850 + 0.05294) \\approx -1.21072$\n- 校正：\n  - $K_1 = P_{1|0} H^T S_1^{-1} = 1.2 \\cdot 1 \\cdot (1.7)^{-1} = \\frac{1.2}{1.7}$\n  - $m_{1|1} = m_{1|0} + K_1 \\nu_1 = 0 + \\frac{1.2}{1.7} \\cdot 0.3 = \\frac{0.36}{1.7} \\approx 0.21176$\n  - $P_{1|1} = (1 - K_1 H) P_{1|0} = (1 - \\frac{1.2}{1.7} \\cdot 1) \\cdot 1.2 = \\frac{0.5}{1.7} \\cdot 1.2 = \\frac{0.6}{1.7} \\approx 0.35294$\n\n**步骤 k=2：**\n- 预测：\n  - $m_{2|1} = F m_{1|1} = 1 \\cdot \\frac{0.36}{1.7} = \\frac{0.36}{1.7} \\approx 0.21176$\n  - $P_{2|1} = F P_{1|1} F^T + Q = 1 \\cdot \\frac{0.6}{1.7} \\cdot 1 + 0.2 = \\frac{0.6 + 0.2 \\cdot 1.7}{1.7} = \\frac{0.94}{1.7} \\approx 0.55294$\n- 新息和似然：\n  - $\\nu_2 = y_2 - H m_{2|1} = -0.1 - \\frac{0.36}{1.7} = \\frac{-0.17 - 0.36}{1.7} = -\\frac{0.53}{1.7} \\approx -0.31176$\n  - $S_2 = H P_{2|1} H^T + R = \\frac{0.94}{1.7} + 0.5 = \\frac{0.94 + 0.5 \\cdot 1.7}{1.7} = \\frac{1.79}{1.7} \\approx 1.05294$\n  - $\\ell_2 = -\\frac{1}{2}\\left(\\ln(2\\pi S_2) + \\frac{\\nu_2^2}{S_2}\\right) = -\\frac{1}{2}\\left(\\ln(2\\pi \\frac{1.79}{1.7}) + \\frac{(-0.53/1.7)^2}{1.79/1.7}\\right) \\approx -0.99087$\n- 校正：\n  - $K_2 = P_{2|1} H^T S_2^{-1} = \\frac{0.94}{1.7} \\cdot (\\frac{1.79}{1.7})^{-1} = \\frac{0.94}{1.79}$\n  - $m_{2|2} = m_{2|1} + K_2 \\nu_2 = \\frac{0.36}{1.7} + \\frac{0.94}{1.79} \\cdot (-\\frac{0.53}{1.7}) \\approx 0.04804$\n  - $P_{2|2} = (1 - K_2 H) P_{2|1} = (1 - \\frac{0.94}{1.79}) \\frac{0.94}{1.7} = \\frac{0.85}{1.79} \\frac{0.94}{1.7} \\approx 0.26258$\n\n**步骤 k=3：**\n- 预测：\n  - $m_{3|2} = F m_{2|2} \\approx 0.04804$\n  - $P_{3|2} = F P_{2|2} F^T + Q \\approx 0.26258 + 0.2 = 0.46258$\n- 新息和似然：\n  - $\\nu_3 = y_3 - H m_{3|2} = 0.5 - 0.04804 = 0.45196$\n  - $S_3 = H P_{3|2} H^T + R = 0.46258 + 0.5 = 0.96258$\n  - $\\ell_3 = -\\frac{1}{2}\\left(\\ln(2\\pi \\cdot 0.96258) + \\frac{0.45196^2}{0.96258}\\right) \\approx -\\frac{1}{2}(1.79965 + 0.21220) \\approx -1.00593$\n- 校正：\n  - $K_3 = P_{3|2} S_3^{-1} = \\frac{0.46258}{0.96258} \\approx 0.48055$\n  - $m_{3|3} = m_{3|2} + K_3 \\nu_3 \\approx 0.04804 + 0.48055 \\cdot 0.45196 \\approx 0.26522$\n  - $P_{3|3} = (1 - K_3 H) P_{3|2} \\approx (1 - 0.48055) \\cdot 0.46258 \\approx 0.24030$\n\n**步骤 k=4：**\n- 预测：\n  - $m_{4|3} = F m_{3|3} \\approx 0.26522$\n  - $P_{4|3} = F P_{3|3} F^T + Q \\approx 0.24030 + 0.2 = 0.44030$\n- 新息和似然：\n  - $\\nu_4 = y_4 - H m_{4|3} = 0.2 - 0.26522 = -0.06522$\n  - $S_4 = H P_{4|3} H^T + R = 0.44030 + 0.5 = 0.94030$\n  - $\\ell_4 = -\\frac{1}{2}\\left(\\ln(2\\pi \\cdot 0.94030) + \\frac{(-0.06522)^2}{0.94030}\\right) \\approx -\\frac{1}{2}(1.77631 + 0.00452) \\approx -0.89042$\n\n最后，总对数似然 $L$ 是增量对数似然的总和：\n$$ L = \\sum_{k=1}^{4} \\ell_k = \\ell_1 + \\ell_2 + \\ell_3 + \\ell_4 $$\n$$ L \\approx -1.21072 + (-0.99087) + (-1.00593) + (-0.89042) \\approx -4.09794 $$\n四舍五入到四位有效数字，我们得到 $L \\approx -4.098$。", "answer": "$$\n\\boxed{-4.098}\n$$", "id": "3413392"}, {"introduction": "现实世界中的动力学和观测过程往往是非线性的，这使得标准卡尔曼滤波器不再适用。本练习将带你进入非线性滤波领域，通过编程实现无迹卡尔曼滤波器 (Unscented Kalman Filter, UKF) 的一个完整步骤。你将应用无迹变换 (Unscented Transform) 这一核心思想，通过一组精心选择的“sigma点”来近似状态的概率分布，从而在无需线性化模型的情况下执行预测和校正。通过这项实践，你不仅能深刻理解 UKF 的工作原理，还能获得将复杂滤波算法转化为实用代码的宝贵经验。[@problem_id:3413348]", "problem": "考虑一个离散时间非线性状态空间模型，其二维状态在一个预测-校正框架下进行滤波演化。状态动力学由一个非线性映射 $f:\\mathbb{R}^2\\to\\mathbb{R}^2$ 给出，观测由一个非线性映射 $h:\\mathbb{R}^2\\to\\mathbb{R}^2$ 给出。假设过程噪声和观测噪声是加性的、独立的、零均值的高斯噪声，其协方差分别为 $Q\\in\\mathbb{R}^{2\\times 2}$ 和 $R\\in\\mathbb{R}^{2\\times 2}$。三角函数必须以弧度为单位进行解释。设定的目标是，对于从时间 $k=0$ 到时间 $k=1$ 的单个同化时间步，使用依赖于无迹变换（UT）的无迹卡尔曼滤波器（UKF）计算滤波后的状态均值和协方差。设计和实现必须从状态估计的基本概率规则出发，并且不得假定线性性或小噪声近似。\n\n需要使用的基础知识包括以下元素：状态空间模型的定义，给定新数据时更新概率密度函数的贝叶斯法则，以及随机向量的均值和协方差的定义。目标概念是无迹变换和无迹卡尔曼滤波器；sigma点或权重的具体公式未提供，必须从基本原则推导。状态动力学和观测模型定义如下：\n$$\nf(x) = \\begin{bmatrix}\nx_1 + 0.2\\,\\sin(x_2)\\\\\nx_2 + 0.1\\,x_1\\,x_2\n\\end{bmatrix},\\qquad\nh(x) = \\begin{bmatrix}\n\\frac{1}{2}x_1^2 + \\cos(x_2)\\\\\n\\exp(0.3\\,x_1) + \\frac{1}{2}x_2^2\n\\end{bmatrix},\n$$\n其中 $x = \\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}\\in\\mathbb{R}^2$ 并且三角函数中的所有角度均以弧度为单位。\n\n给定时间 $k=0$ 时的初始高斯先验，其均值为 $m_0\\in\\mathbb{R}^2$，协方差为 $P_0\\in\\mathbb{R}^{2\\times 2}$。过程噪声协方差为 $Q\\in\\mathbb{R}^{2\\times 2}$，时间 $k=1$ 时的观测为 $y_1\\in\\mathbb{R}^2$，观测噪声协方差为 $R\\in\\mathbb{R}^{2\\times 2}$。无迹变换必须由缩放参数 $\\alpha\\in\\mathbb{R}_{>0}$、$\\beta\\in\\mathbb{R}$ 和 $\\kappa\\in\\mathbb{R}$ 参数化，这些参数影响无迹变换中sigma点的分布和权重。无迹卡尔曼滤波器必须执行以下步骤：通过非线性动力学预测状态分布，并使用通过测量模型得到的观测进行校正，聚合相应的均值和协方差，同时遵循概率结构。\n\n你的任务是编写一个完整的、可运行的程序，对于以下测试套件中的每个测试用例，使用无迹变换计算从时间 $k=0$ 到 $k=1$ 的无迹卡尔曼滤波器的一个同化步骤。对于每个用例，输出滤波后的均值分量和滤波后协方差的迹，即向量 $\\left[m_1^{(1)},\\,m_1^{(2)},\\,\\mathrm{tr}(P_1)\\right]$，其中 $m_1\\in\\mathbb{R}^2$ 和 $P_1\\in\\mathbb{R}^{2\\times 2}$ 表示在同化 $y_1$ 后时间 $k=1$ 的后验均值和协方差。\n\n使用以下参数值的测试套件，其中所有矩阵都是对称的，所有协方差都是正定的：\n\n- 情况1（一般情况）：\n  - $m_0 = \\begin{bmatrix}0.3\\\\-0.6\\end{bmatrix}$，\n  - $P_0 = \\begin{bmatrix}0.25  0.05\\\\0.05  0.2\\end{bmatrix}$，\n  - $Q = \\begin{bmatrix}0.01  0.005\\\\0.005  0.02\\end{bmatrix}$，\n  - $R = \\begin{bmatrix}0.02  0\\\\0  0.02\\end{bmatrix}$，\n  - $y_1 = \\begin{bmatrix}0.7\\\\1.2\\end{bmatrix}$，\n  - $\\alpha = 0.5$，$\\beta = 2$，$\\kappa = 0$。\n\n- 情况2（近简并先验协方差，小噪声）：\n  - $m_0 = \\begin{bmatrix}-0.1\\\\0.1\\end{bmatrix}$，\n  - $P_0 = \\begin{bmatrix}10^{-6}  0\\\\0  10^{-6}\\end{bmatrix}$，\n  - $Q = \\begin{bmatrix}10^{-8}  0\\\\0  10^{-8}\\end{bmatrix}$，\n  - $R = \\begin{bmatrix}10^{-4}  5\\cdot 10^{-5}\\\\5\\cdot 10^{-5}  10^{-4}\\end{bmatrix}$，\n  - $y_1 = \\begin{bmatrix}0\\\\0\\end{bmatrix}$，\n  - $\\alpha = 0.05$，$\\beta = 2$，$\\kappa = 1$。\n\n- 情况3（高度非线性区域，不寻常的分布参数）：\n  - $m_0 = \\begin{bmatrix}2.0\\\\-2.0\\end{bmatrix}$，\n  - $P_0 = \\begin{bmatrix}0.5  -0.1\\\\-0.1  0.3\\end{bmatrix}$，\n  - $Q = \\begin{bmatrix}0.02  0\\\\0  0.02\\end{bmatrix}$，\n  - $R = \\begin{bmatrix}0.05  0.01\\\\0.01  0.05\\end{bmatrix}$，\n  - $y_1 = \\begin{bmatrix}-0.5\\\\2.5\\end{bmatrix}$，\n  - $\\alpha = 0.9$，$\\beta = 2$，$\\kappa = -1$。\n\n所有三角量必须使用弧度。最终输出格式必须是单行，包含一个方括号括起来的逗号分隔列表，其中每个元素对应一个测试用例的结果向量，顺序与上面相同。例如，程序应打印一行形如 $\\left[\\left[\\cdot,\\cdot,\\cdot\\right],\\left[\\cdot,\\cdot,\\cdot\\right],\\left[\\cdot,\\cdot,\\cdot\\right]\\right]$ 的内容。每个条目必须是一个浮点数。不应打印任何其他文本。", "solution": "该问题要求为离散时间非线性状态空间系统实现无迹卡尔曼滤波器（UKF）的单个预测-校正步骤。解决方案必须从贝叶斯滤波和无迹变换（UT）的基本原理推导。\n\n**1. 基础框架：贝叶斯滤波**\n\n我们考虑一个由过程方程和测量方程定义的状态空间模型：\n$$x_k = f(x_{k-1}) + w_{k-1}$$\n$$y_k = h(x_k) + v_k$$\n其中 $x_k \\in \\mathbb{R}^{n_x}$ 是时间 $k$ 的状态向量，$y_k \\in \\mathbb{R}^{n_y}$ 是观测值，$f$ 和 $h$ 是非线性函数，$w_k \\sim \\mathcal{N}(0, Q_k)$ 和 $v_k \\sim \\mathcal{N}(0, R_k)$ 是独立的、零均值的高斯噪声过程，其协方差分别为 $Q_k$ 和 $R_k$。在这个问题中，状态维度为 $n_x=2$，观测维度为 $n_y=2$。\n\n滤波的目标是估计给定截至时间 $k$ 的所有观测值时当前状态的后验概率密度函数（PDF）$p(x_k | y_{1:k})$。这是通过基于贝叶斯法则的递归预测-校正循环实现的。\n\n*   **预测步骤**：给定时间 $k-1$ 的后验 $p(x_{k-1} | y_{1:k-1})$，时间 $k$ 的状态的预测（或先验）分布通过 Chapman-Kolmogorov 方程计算：\n    $$p(x_k | y_{1:k-1}) = \\int p(x_k | x_{k-1}) p(x_{k-1} | y_{1:k-1}) dx_{k-1}$$\n    其中 $p(x_k | x_{k-1})$ 由过程模型 $x_k = f(x_{k-1}) + w_{k-1}$ 定义。\n\n*   **校正步骤**：在接收到新的观测值 $y_k$ 后，使用贝叶斯法则将预测的PDF更新为后验PDF：\n    $$p(x_k | y_{1:k}) = \\frac{p(y_k | x_k) p(x_k | y_{1:k-1})}{p(y_k | y_{1:k-1})}$$\n    其中 $p(y_k | x_k)$ 是由测量模型 $y_k = h(x_k) + v_k$ 定义的似然。\n\n对于非线性函数 $f$ 和 $h$，这些积分通常是难以处理的。UKF提供了一种方法来近似状态均值和协方差的演化，而无需像扩展卡尔曼滤波器（EKF）那样对系统动力学进行线性化。\n\n**2. 无迹变换（UT）**\n\nUKF的核心是无迹变换，这是一种通过非线性函数传播随机变量统计特性的技术。UT不是近似函数，而是用一组确定性选择的点（称为sigma点）来近似概率分布。这些点被选择来捕捉原始分布的均值和协方差。\n\n给定一个随机变量 $x \\in \\mathbb{R}^{n_x}$，其均值为 $m$，协方差为 $P$，UT的流程如下：\n\n1.  **生成Sigma点**：生成一组 $2n_x+1$ 个sigma点 $\\mathcal{X}_i$ 和相关的权重 $W_i^{(m)}$（用于均值）和 $W_i^{(c)}$（用于协方差）。选择由 $\\alpha$、$\\beta$ 和 $\\kappa$ 参数化。一个标准的公式是：\n    *   定义一个缩放参数 $\\lambda = \\alpha^2 (n_x + \\kappa) - n_x$。\n    *   sigma点为：\n        $$\\mathcal{X}_0 = m$$\n        $$\\mathcal{X}_i = m + (\\sqrt{(n_x+\\lambda)P})_i, \\quad i=1, \\dots, n_x$$\n        $$\\mathcal{X}_{i+n_x} = m - (\\sqrt{(n_x+\\lambda)P})_i, \\quad i=1, \\dots, n_x$$\n        其中 $(\\sqrt{(n_x+\\lambda)P})_i$ 是 $(n_x+\\lambda)P$ 的矩阵平方根的第 $i$ 列，通常通过Cholesky分解计算。\n\n    *   权重为：\n        $$W_0^{(m)} = \\frac{\\lambda}{n_x+\\lambda}$$\n        $$W_0^{(c)} = \\frac{\\lambda}{n_x+\\lambda} + (1 - \\alpha^2 + \\beta)$$\n        $$W_i^{(m)} = W_i^{(c)} = \\frac{1}{2(n_x+\\lambda)}, \\quad i=1, \\dots, 2n_x$$\n    这种点和权重的选择确保了sigma点的样本均值和协方差与原始均值 $m$ 和协方差 $P$ 完全匹配。\n\n2.  **传播点**：sigma点通过非线性函数 $g(\\cdot)$ 传播：\n    $$\\mathcal{Y}_i = g(\\mathcal{X}_i)$$\n\n3.  **估计输出统计量**：变换后变量的均值和协方差被估计为传播后点的加权样本均值和协方差：\n    $$m_y \\approx \\sum_{i=0}^{2n_x} W_i^{(m)} \\mathcal{Y}_i$$\n    $$P_y \\approx \\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{Y}_i - m_y)(\\mathcal{Y}_i - m_y)^T$$\n\n**3. 无迹卡尔曼滤波器算法（单步）**\n\nUKF将UT应用于贝叶斯滤波的预测和校正步骤。我们给定 $k=0$ 时的初始状态均值 $m_0$ 和协方差 $P_0$，以及 $k=1$ 时的观测值 $y_1$。状态维度为 $n_x=2$。\n\n**A. 预测步骤（时间更新）**\n\n目标是计算在观测到 $y_1$ 之前，$k=1$ 时状态的预测均值 $m_{1|0}$ 和协方差 $P_{1|0}$。\n\n1.  **生成Sigma点**：使用 $n_x=2$ 和给定的 $\\alpha, \\beta, \\kappa$ 计算UT参数 $\\lambda$、$W^{(m)}$ 和 $W^{(c)}$。从初始分布 $\\mathcal{N}(m_0, P_0)$ 生成 $2n_x+1 = 5$ 个sigma点 $\\mathcal{X}_{0,i}$。\n2.  **通过动力学传播**：将每个sigma点通过状态转移函数 $f(\\cdot)$ 传播：\n    $$\\mathcal{X}_{1|0,i} = f(\\mathcal{X}_{0,i})$$\n3.  **计算预测均值和协方差**：预测均值 $m_{1|0}$ 是传播后点的加权平均。预测协方差 $P_{1|0}$ 是加权样本协方差加上过程噪声协方差 $Q$，因为噪声是加性的。\n    $$m_{1|0} = \\sum_{i=0}^{2n_x} W_i^{(m)} \\mathcal{X}_{1|0,i}$$\n    $$P'_{1|0} = \\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{X}_{1|0,i} - m_{1|0})(\\mathcal{X}_{1|0,i} - m_{1|0})^T$$\n    $$P_{1|0} = P'_{1|0} + Q$$\n\n**B. 校正步骤（测量更新）**\n\n目标是使用观测值 $y_1$ 更新预测状态，以找到后验均值 $m_1$ 和协方差 $P_1$。\n\n1.  **重新生成Sigma点**：从预测分布 $\\mathcal{N}(m_{1|0}, P_{1|0})$ 生成一组新的 $2n_x+1=5$ 个sigma点，我们记为 $\\mathcal{Z}_{1|0,i}$。\n2.  **通过观测模型传播**：将这些新的sigma点通过观测函数 $h(\\cdot)$ 传播：\n    $$\\mathcal{Y}_i = h(\\mathcal{Z}_{1|0,i})$$\n3.  **计算观测统计量**：\n    *   预测观测均值：$m_y = \\sum_{i=0}^{2n_x} W_i^{(m)} \\mathcal{Y}_i$\n    *   新息（或残差）协方差：$P_{yy} = \\left(\\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{Y}_i - m_y)(\\mathcal{Y}_i - m_y)^T\\right) + R$\n    *   状态-观测互协方差：$P_{xy} = \\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{Z}_{1|0,i} - m_{1|0})(\\mathcal{Y}_i - m_y)^T$\n\n4.  **计算更新量**：\n    *   卡尔曼增益：$K = P_{xy} P_{yy}^{-1}$\n    *   更新（滤波）后的状态均值：$m_1 = m_{1|0} + K(y_1 - m_y)$\n    *   更新（滤波）后的状态协方差：$P_1 = P_{1|0} - K P_{yy} K^T$\n\n每个测试用例的最终结果是向量 $[m_1^{(1)}, m_1^{(2)}, \\mathrm{tr}(P_1)]$，其中 $m_1 = [m_1^{(1)}, m_1^{(2)}]^T$，$\\mathrm{tr}(P_1)$ 是最终后验协方差矩阵的迹。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Unscented Kalman Filter problem for the given test cases.\n    \"\"\"\n\n    def f(x):\n        \"\"\"State transition function.\"\"\"\n        x1, x2 = x\n        return np.array([\n            x1 + 0.2 * np.sin(x2),\n            x2 + 0.1 * x1 * x2\n        ])\n\n    def h(x):\n        \"\"\"Observation function.\"\"\"\n        x1, x2 = x\n        return np.array([\n            0.5 * x1**2 + np.cos(x2),\n            np.exp(0.3 * x1) + 0.5 * x2**2\n        ])\n\n    def ukf_step(m0, P0, y1, Q, R, alpha, beta, kappa):\n        \"\"\"\n        Performs one step of the Unscented Kalman Filter.\n        \"\"\"\n        # Setup\n        nx = m0.shape[0]\n        \n        # Calculate UT weights and parameters\n        lambda_ = alpha**2 * (nx + kappa) - nx\n        \n        wm = np.full(2 * nx + 1, 1 / (2 * (nx + lambda_)))\n        wm[0] = lambda_ / (nx + lambda_)\n        \n        wc = np.full(2 * nx + 1, 1 / (2 * (nx + lambda_)))\n        wc[0] = lambda_ / (nx + lambda_) + (1 - alpha**2 + beta)\n\n        # --- Prediction Step ---\n        \n        # 1. Generate sigma points from initial state (m0, P0)\n        # Using Cholesky decomposition for the matrix square root\n        P_sqrt_term = (nx + lambda_) * P0\n        L = np.linalg.cholesky(P_sqrt_term)\n\n        sigma_points_0 = np.zeros((2 * nx + 1, nx))\n        sigma_points_0[0] = m0\n        for i in range(nx):\n            sigma_points_0[i + 1]      = m0 + L[:, i]\n            sigma_points_0[i + 1 + nx] = m0 - L[:, i]\n\n        # 2. Propagate sigma points through the state transition function f\n        propagated_sigma_points = np.array([f(sp) for sp in sigma_points_0])\n        \n        # 3. Calculate predicted mean (m1_pred)\n        m1_pred = np.sum(wm[:, np.newaxis] * propagated_sigma_points, axis=0)\n        \n        # 4. Calculate predicted covariance (P1_pred)\n        # The process noise Q is added at the end for the additive noise model\n        P1_pred = np.zeros((nx, nx))\n        for i in range(2 * nx + 1):\n            diff = propagated_sigma_points[i] - m1_pred\n            P1_pred += wc[i] * np.outer(diff, diff)\n        P1_pred += Q\n\n        # --- Correction Step ---\n        \n        # 1. Generate new sigma points from the predicted state (m1_pred, P1_pred)\n        P1_pred_sqrt_term = (nx + lambda_) * P1_pred\n        L1 = np.linalg.cholesky(P1_pred_sqrt_term)\n            \n        sigma_points_1 = np.zeros((2 * nx + 1, nx))\n        sigma_points_1[0] = m1_pred\n        for i in range(nx):\n            sigma_points_1[i + 1]      = m1_pred + L1[:, i]\n            sigma_points_1[i + 1 + nx] = m1_pred - L1[:, i]\n\n        # 2. Propagate new sigma points through the observation function h\n        obs_sigma_points = np.array([h(sp) for sp in sigma_points_1])\n        \n        # 3. Calculate predicted observation mean (my_pred)\n        my_pred = np.sum(wm[:, np.newaxis] * obs_sigma_points, axis=0)\n\n        # 4. Calculate innovation covariance (Pyy) and cross-covariance (Pxy)\n        # The observation noise R is added at the end\n        ny = y1.shape[0]\n        Pyy = np.zeros((ny, ny))\n        Pxy = np.zeros((nx, ny))\n        \n        for i in range(2 * nx + 1):\n            diff_y = obs_sigma_points[i] - my_pred\n            diff_x = sigma_points_1[i] - m1_pred\n            Pyy += wc[i] * np.outer(diff_y, diff_y)\n            Pxy += wc[i] * np.outer(diff_x, diff_y)\n        Pyy += R\n\n        # 5. Calculate Kalman gain (K)\n        K = Pxy @ np.linalg.inv(Pyy)\n        \n        # 6. Update state mean (m1)\n        m1 = m1_pred + K @ (y1 - my_pred)\n        \n        # 7. Update state covariance (P1)\n        # This form is numerically stable and ensures P1 is symmetric\n        P1 = P1_pred - K @ Pyy @ K.T\n        \n        return [m1[0], m1[1], np.trace(P1)]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"m0\": np.array([0.3, -0.6]),\n            \"P0\": np.array([[0.25, 0.05], [0.05, 0.2]]),\n            \"Q\": np.array([[0.01, 0.005], [0.005, 0.02]]),\n            \"R\": np.array([[0.02, 0], [0, 0.02]]),\n            \"y1\": np.array([0.7, 1.2]),\n            \"alpha\": 0.5, \"beta\": 2, \"kappa\": 0\n        },\n        # Case 2\n        {\n            \"m0\": np.array([-0.1, 0.1]),\n            \"P0\": np.array([[1e-6, 0], [0, 1e-6]]),\n            \"Q\": np.array([[1e-8, 0], [0, 1e-8]]),\n            \"R\": np.array([[1e-4, 5e-5], [5e-5, 1e-4]]),\n            \"y1\": np.array([0, 0]),\n            \"alpha\": 0.05, \"beta\": 2, \"kappa\": 1\n        },\n        # Case 3\n        {\n            \"m0\": np.array([2.0, -2.0]),\n            \"P0\": np.array([[0.5, -0.1], [-0.1, 0.3]]),\n            \"Q\": np.array([[0.02, 0], [0, 0.02]]),\n            \"R\": np.array([[0.05, 0.01], [0.01, 0.05]]),\n            \"y1\": np.array([-0.5, 2.5]),\n            \"alpha\": 0.9, \"beta\": 2, \"kappa\": -1\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = ukf_step(\n            case[\"m0\"], case[\"P0\"], case[\"y1\"], case[\"Q\"], case[\"R\"],\n            case[\"alpha\"], case[\"beta\"], case[\"kappa\"]\n        )\n        results.append(result)\n\n    # Format the final output string exactly as required.\n    formatted_results = []\n    for res in results:\n        # Format each sublist without spaces inside the brackets.\n        formatted_res = f\"[{res[0]},{res[1]},{res[2]}]\"\n        formatted_results.append(formatted_res)\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3413348"}, {"introduction": "除了我们已经熟悉的标准状态-协方差表示法，滤波问题还存在一种优雅的对偶形式。本练习旨在引导你推导信息滤波器（Information Filter）的更新方程，它不直接传递状态均值和协方差，而是传递“信息”——即协方差矩阵的逆。通过将贝叶斯法则与费雪信息（Fisher Information）的概念相结合，你将发现后验信息等于先验信息与新观测所含信息之和。掌握这一视角不仅能为特定问题提供计算上的优势，更能加深你对预测-校正框架理论基础的理解。[@problem_id:3413388]", "problem": "考虑在滤波的预测-校正框架中使用的标量线性高斯状态空间模型：\n- 状态动力学：$x_{k} = a\\,x_{k-1} + w_{k}$，其中 $w_{k} \\sim \\mathcal{N}(0,q)$。\n- 观测模型：$y_{k} = h\\,x_{k} + v_{k}$，其中 $v_{k} \\sim \\mathcal{N}(0,r)$。\n假设在给定截至时刻 $k-1$ 的所有观测值的条件下，状态的后验分布是高斯分布，$x_{k-1}\\,|\\,y_{1:k-1} \\sim \\mathcal{N}(m_{k-1},P_{k-1})$，并定义相关的信息（精度）为 $J_{k-1} \\equiv P_{k-1}^{-1}$。仅使用以下基本要素：\n- 贝叶斯法则以及过程噪声和观测噪声的独立性，\n- 高斯卷积和条件化的性质，\n- 对于来自似然 $p(y\\,|\\,x)$ 的标量参数 $x$ 的费雪信息（FI）的定义，即对数似然的二阶导数的负期望值，$I(x) \\equiv -\\mathbb{E}\\!\\left[\\frac{\\partial^{2}}{\\partial x^{2}} \\ln p(y\\,|\\,x)\\right]$，\n在预测-校正框架内，推导出一个关于时刻 $k$ 的后验信息（记为 $J_{k}$）的闭式解析表达式，该表达式是 $J_{k-1}$、$a$、$q$、$h$ 和 $r$ 的函数。您的最终答案必须是仅包含这些符号的单个解析表达式，不进行任何数值代入。只表达 $J_{k}$，不要报告任何中间量。", "solution": "我们从时刻 $k-1$ 的假定高斯后验分布开始，即 $x_{k-1}\\,|\\,y_{1:k-1} \\sim \\mathcal{N}(m_{k-1},P_{k-1})$，其信息为 $J_{k-1} \\equiv P_{k-1}^{-1}$。预测步骤使用线性高斯状态动力学 $x_{k} = a\\,x_{k-1} + w_{k}$，其中 $w_{k} \\sim \\mathcal{N}(0,q)$ 且独立于 $x_{k-1}$。通过线性映射的高斯传播，时刻 $k$ 的先验（预测）分布是高斯分布：\n$$\nx_{k}\\,|\\,y_{1:k-1} \\sim \\mathcal{N}\\!\\big(a\\,m_{k-1},\\,a^{2}P_{k-1} + q\\big).\n$$\n将预测方差记为 $P_{k}^{-} \\equiv a^{2}P_{k-1} + q$。相应的预测信息（精度）为\n$$\nJ_{k}^{-} \\equiv \\left(P_{k}^{-}\\right)^{-1} = \\left(a^{2}P_{k-1} + q\\right)^{-1} = \\left(\\frac{a^{2}}{J_{k-1}} + q\\right)^{-1},\n$$\n其中我们使用了 $P_{k-1} = J_{k-1}^{-1}$。\n\n接下来，我们考虑使用观测模型 $y_{k} = h\\,x_{k} + v_{k}$ 进行校正步骤，其中 $v_{k} \\sim \\mathcal{N}(0,r)$ 且独立于 $x_{k}$。似然函数为\n$$\np(y_{k}\\,|\\,x_{k}) = \\frac{1}{\\sqrt{2\\pi r}} \\exp\\!\\left(-\\frac{(y_{k} - h\\,x_{k})^{2}}{2r}\\right).\n$$\n其对数似然为\n$$\n\\ln p(y_{k}\\,|\\,x_{k}) = -\\frac{1}{2}\\ln(2\\pi r) - \\frac{(y_{k} - h\\,x_{k})^{2}}{2r}.\n$$\n对 $x_{k}$ 求导，我们得到\n$$\n\\frac{\\partial}{\\partial x_{k}} \\ln p(y_{k}\\,|\\,x_{k}) = \\frac{h\\,(y_{k} - h\\,x_{k})}{r}, \\qquad\n\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(y_{k}\\,|\\,x_{k}) = -\\frac{h^{2}}{r}.\n$$\n因此，由似然函数贡献的费雪信息（FI），定义为 $I(x_{k}) \\equiv -\\mathbb{E}\\!\\left[\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(y_{k}\\,|\\,x_{k})\\right]$，等于\n$$\nI(x_{k}) = -\\left(-\\frac{h^{2}}{r}\\right) = \\frac{h^{2}}{r},\n$$\n因为对于这个线性高斯模型，二阶导数对于 $y_{k}$ 和 $x_{k}$ 是一个常数，这使得期望运算是多余的。\n\n根据贝叶斯法则，后验密度与先验和似然的乘积成正比：\n$$\np(x_{k}\\,|\\,y_{1:k}) \\propto p(x_{k}\\,|\\,y_{1:k-1})\\,p(y_{k}\\,|\\,x_{k}).\n$$\n取对数，\n$$\n\\ln p(x_{k}\\,|\\,y_{1:k}) = \\ln p(x_{k}\\,|\\,y_{1:k-1}) + \\ln p(y_{k}\\,|\\,x_{k}) + C,\n$$\n其中 $C$ 是一个与 $x_{k}$ 无关的常数。对 $x_{k}$ 求二阶导数并取负号，后验信息（对数后验的负二阶导数）等于先验信息与似然的费雪信息之和：\n$$\nJ_{k} \\equiv -\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(x_{k}\\,|\\,y_{1:k}) = \\underbrace{-\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(x_{k}\\,|\\,y_{1:k-1})}_{J_{k}^{-}} + \\underbrace{-\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(y_{k}\\,|\\,x_{k})}_{I(x_{k})}.\n$$\n对于方差为 $P_{k}^{-}$ 的高斯先验，其对数密度关于 $x_{k}$ 的负二阶导数是常数精度 $J_{k}^{-} = (P_{k}^{-})^{-1}$。我们已经计算出 $I(x_{k}) = h^{2}/r$。因此，\n$$\nJ_{k} = J_{k}^{-} + \\frac{h^{2}}{r} = \\left(\\frac{a^{2}}{J_{k-1}} + q\\right)^{-1} + \\frac{h^{2}}{r}.\n$$\n这就是所求的、以 $J_{k-1}$、$a$、$q$、$h$ 和 $r$ 表示的时刻 $k$ 后验信息的闭式解析表达式。", "answer": "$$\\boxed{\\left(\\frac{a^{2}}{J_{k-1}}+q\\right)^{-1}+\\frac{h^{2}}{r}}$$", "id": "3413388"}]}