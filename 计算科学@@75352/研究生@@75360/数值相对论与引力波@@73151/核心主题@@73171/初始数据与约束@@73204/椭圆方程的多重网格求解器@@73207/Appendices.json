{"hands_on_practices": [{"introduction": "多重网格方法的核心在于“平滑器”，它能高效地衰减误差中的高频分量。加权雅可比方法是一种经典的平滑器，但其效果严重依赖于松弛参数 $\\omega$ 的选择。本练习 [@problem_id:3480279] 将指导你使用局部傅里叶分析（Local Fourier Analysis, LFA）这一强大工具，为一维泊松问题推导出能最大程度抑制高频误差的最优 $\\omega$ 值，从而为平滑器的设计提供坚实的理论基础。", "problem": "考虑一维泊松方程 $-u^{\\prime \\prime}(x) = f(x)$ 在均匀无限网格 $\\{ x_{i} = i h : i \\in \\mathbb{Z} \\}$ (网格间距为 $h$) 上的标准二阶有限差分离散。离散算子 $A$ 作用于网格函数 $\\{ u_{i} \\}$ 的方式如下：\n$$\n(A u)_{i} = \\frac{1}{h^{2}}\\left( - u_{i-1} + 2 u_{i} - u_{i+1} \\right).\n$$\n在为求解广义相对论 $3 + 1$ 分解中出现的椭圆约束方程而设计的多重网格算法中，加权雅可比松弛常被用作高频误差分量的光滑子。加权雅可比松弛通过以下方式更新误差 $e^{(k)}$：\n$$\ne^{(k+1)} = S_{\\omega} \\, e^{(k)}, \\quad S_{\\omega} = I - \\omega D^{-1} A,\n$$\n其中 $D$ 是 $A$ 的对角部分，$\\omega \\in (0,1)$ 是松弛参数。\n\n使用局域傅里叶分析 (LFA)，将误差视为波数 $\\theta \\in [-\\pi, \\pi]$ 的傅里叶模式 $e_{i}(\\theta) = \\exp(\\mathrm{i} \\theta i)$ 的叠加。为了多重网格光滑的目的，关注在下一层更粗的网格上无法表示的高频子空间，即 $\\theta \\in [\\pi/2, \\pi]$。推导作用于傅里叶模式的误差传播算子 $S_{\\omega}$ 的符号，并将限制在高频子空间上的 $S_{\\omega}$ 的谱半径表示为 $\\omega$ 的函数。然后确定使该受限谱半径最小化的 $\\omega$ 值。请将最终答案表示为一个精确的实数。无需四舍五入，且 $\\omega$ 没有物理单位。", "solution": "首先验证问题的科学性、良定性和客观性。问题陈述为将加权雅可比光滑子应用于一维泊松方程提供了一个标准的局域傅里叶分析 (LFA) 任务。所有定义，包括离散算子、光滑子、傅里叶模式和高频子空间，都是标准的，并与多重网格方法的文献一致。数值相对论中椭圆方程的背景是恰当的。因此，该问题被认为是有效的。\n\n求解过程分四步：首先，我们确定对角算子 $D$；其次，我们使用 LFA 求出误差传播算子 $S_{\\omega}$ 的符号；第三，我们确定限制在高频子空间上的 $S_{\\omega}$ 的谱半径；第四，我们求出使该谱半径最小化的松弛参数 $\\omega$。\n\n第一步：确定算子 $D$。\n离散算子 $A$ 由下式给出\n$$ (A u)_{i} = \\frac{1}{h^{2}}\\left( - u_{i-1} + 2 u_{i} - u_{i+1} \\right) = \\frac{2}{h^2} u_i - \\frac{1}{h^2}(u_{i-1} + u_{i+1}) $$\n$A$ 的对角部分，记为 $D$，由所有乘以 $u_i$ 的项组成。因此，$D$ 作用于网格函数 $u$ 的方式由下式给出\n$$ (D u)_i = \\frac{2}{h^2} u_i $$\n这意味着 $D$ 是单位算子的一个标量倍，$D = \\frac{2}{h^2} I$。其逆算子 $D^{-1}$ 则为 $D^{-1} = \\frac{h^2}{2} I$。\n\n第二步：推导误差传播算子 $S_{\\omega}$ 的符号。\n局域傅里叶分析考察网格算子对单个傅里叶模式 $e_i(\\theta) = \\exp(\\mathrm{i} \\theta i)$（其中波数 $\\theta \\in [-\\pi, \\pi]$）的作用。算子对应于此模式的特征值称为其符号。\n我们来求 $A$ 的符号，记为 $\\hat{A}(\\theta)$。将 $A$ 作用于 $e_i(\\theta)$：\n$$ (A e(\\theta))_i = \\frac{1}{h^2} \\left( - e_{i-1}(\\theta) + 2 e_i(\\theta) - e_{i+1}(\\theta) \\right) $$\n利用性质 $e_{i \\pm 1}(\\theta) = \\exp(\\mathrm{i} \\theta (i \\pm 1)) = \\exp(\\pm \\mathrm{i} \\theta) e_i(\\theta)$，我们得到\n$$ (A e(\\theta))_i = \\frac{1}{h^2} \\left( - \\exp(-\\mathrm{i} \\theta) + 2 - \\exp(\\mathrm{i} \\theta) \\right) e_i(\\theta) = \\frac{1}{h^2} \\left( 2 - (\\exp(\\mathrm{i} \\theta) + \\exp(-\\mathrm{i} \\theta)) \\right) e_i(\\theta) $$\n利用欧拉公式 $\\cos(\\theta) = \\frac{1}{2}(\\exp(\\mathrm{i} \\theta) + \\exp(-\\mathrm{i} \\theta))$，上式可化简为\n$$ (A e(\\theta))_i = \\frac{2}{h^2} (1 - \\cos(\\theta)) e_i(\\theta) $$\n利用半角恒等式 $1 - \\cos(\\theta) = 2 \\sin^2(\\theta/2)$，我们求得 $A$ 的符号：\n$$ \\hat{A}(\\theta) = \\frac{4}{h^2} \\sin^2\\left(\\frac{\\theta}{2}\\right) $$\n加权雅可比的误差传播算子是 $S_{\\omega} = I - \\omega D^{-1} A$。$S_{\\omega}$ 的符号，记为 $\\hat{S}_{\\omega}(\\theta)$，通过将每个算子替换为其符号来求得。$I$ 的符号是 $1$，$D^{-1} = \\frac{h^2}{2} I$ 的符号是 $\\frac{h^2}{2}$。\n$$ \\hat{S}_{\\omega}(\\theta) = 1 - \\omega \\left(\\frac{h^2}{2}\\right) \\hat{A}(\\theta) = 1 - \\omega \\left(\\frac{h^2}{2}\\right) \\left( \\frac{4}{h^2} \\sin^2\\left(\\frac{\\theta}{2}\\right) \\right) = 1 - 2\\omega \\sin^2\\left(\\frac{\\theta}{2}\\right) $$\n这是波数为 $\\theta$ 的傅里叶模式经过一步加权雅可比光滑后的放大因子。\n\n第三步：确定受限谱半径。\n光滑子的目标是衰减高频误差分量。在此背景下，高频子空间对应于在更粗的网格上无法表示的波数 $\\theta$，即 $\\theta \\in [\\pi/2, \\pi]$。我们需要求出 $S_{\\omega}$ 限制在该子空间上的谱半径，也就是其符号在该范围内的最大绝对值。设其为 $\\mu(\\omega)$。\n$$ \\mu(\\omega) = \\max_{\\theta \\in [\\pi/2, \\pi]} \\left| \\hat{S}_{\\omega}(\\theta) \\right| = \\max_{\\theta \\in [\\pi/2, \\pi]} \\left| 1 - 2\\omega \\sin^2\\left(\\frac{\\theta}{2}\\right) \\right| $$\n令 $x = \\sin^2(\\theta/2)$。对于 $\\theta \\in [\\pi/2, \\pi]$，自变量 $\\theta/2$ 的范围是 $[\\pi/4, \\pi/2]$。函数 $\\sin(\\phi)$ 在此区间上是单调递增的。\n当 $\\theta = \\pi/2$ 时，$x = \\sin^2(\\pi/4) = (\\frac{\\sqrt{2}}{2})^2 = \\frac{1}{2}$。\n当 $\\theta = \\pi$ 时，$x = \\sin^2(\\pi/2) = 1^2 = 1$。\n所以，$x$ 的取值范围是 $[1/2, 1]$。问题简化为\n$$ \\mu(\\omega) = \\max_{x \\in [1/2, 1]} |1 - 2\\omega x| $$\n函数 $g(x) = 1 - 2\\omega x$ 是关于 $x$ 的线性函数。对于正的松弛参数 $\\omega$，它是一个递减函数。因此，它在区间 $[1/2, 1]$ 上的绝对值将在端点之一，$x=1/2$ 或 $x=1$ 处取得最大值。\n在 $x=1/2$ 处：$|g(1/2)| = |1 - 2\\omega(1/2)| = |1 - \\omega|$。\n在 $x=1$ 处：$|g(1)| = |1 - 2\\omega(1)| = |1 - 2\\omega|$。\n所以，受限谱半径为 $\\mu(\\omega) = \\max(|1-\\omega|, |1-2\\omega|)$。\n\n第四步：最小化谱半径。\n我们想找到使 $\\mu(\\omega) = \\max(|1-\\omega|, |1-2\\omega|)$ 最小化的 $\\omega \\in (0,1)$ 的值。\n给定 $\\omega \\in (0,1)$，我们知道 $1-\\omega > 0$，所以 $|1-\\omega| = 1-\\omega$。\n对于项 $|1-2\\omega|$，我们考虑两种情况：\n1. 如果 $\\omega \\in (0, 1/2]$，那么 $1-2\\omega \\ge 0$，所以 $|1-2\\omega| = 1-2\\omega$。在此范围内，$1-\\omega \\ge 1-2\\omega$，所以 $\\mu(\\omega) = 1-\\omega$。此函数在 $(0, 1/2]$ 上是递减的。\n2. 如果 $\\omega \\in (1/2, 1)$，那么 $1-2\\omega  0$，所以 $|1-2\\omega| = -(1-2\\omega) = 2\\omega-1$。在此范围内，$\\mu(\\omega) = \\max(1-\\omega, 2\\omega-1)$。\n\n为了找到 $\\mu(\\omega)$ 的最小值，我们寻找两个函数 $1-\\omega$ 和 $2\\omega-1$ 相等的点，因为一个函数是递减的，另一个是递增的。\n$$ 1 - \\omega = 2\\omega - 1 \\implies 3\\omega = 2 \\implies \\omega = \\frac{2}{3} $$\n这个值 $\\omega = 2/3$ 位于区间 $(1/2, 1)$ 内，所以这是一个有效的最小值候选值。\n我们来分析 $\\mu(\\omega)$ 在 $(1/2, 1)$ 上的行为：\n- 如果 $\\omega \\in (1/2, 2/3)$，那么 $3\\omega  2$，这意味着 $1-\\omega > 2\\omega-1$。所以 $\\mu(\\omega) = 1-\\omega$，这是一个递减函数。\n- 如果 $\\omega \\in (2/3, 1)$，那么 $3\\omega > 2$，这意味着 $1-\\omega  2\\omega-1$。所以 $\\mu(\\omega) = 2\\omega-1$，这是一个递增函数。\n\n综合所有分段，函数 $\\mu(\\omega)$ 在 $(0, 2/3)$ 上递减，在 $(2/3, 1)$ 上递增。因此，当 $\\omega \\in (0,1)$ 时，$\\mu(\\omega)$ 的全局最小值在 $\\omega = 2/3$ 处达到。\n谱半径的最小值为 $\\mu(2/3) = 1 - 2/3 = 1/3$。\n问题要求的是使该半径最小化的 $\\omega$ 的值。", "answer": "$$\n\\boxed{\\frac{2}{3}}\n$$", "id": "3480279"}, {"introduction": "在理论上理解了平滑器的作用后，通过数值实验来观察其效果是至关重要的一步。本练习 [@problem_id:3480320] 将理论付诸实践，你将亲手实现另一种在多重网格中广泛应用的迭代法——高斯-赛德尔（Gauss-Seidel）松弛——作为平滑器。通过将其应用于特定的高频误差模式，并直接计算误差衰减因子，你将对平滑器如何“抚平”误差获得直观且定量的认识。", "problem": "考虑单位正方形上的二维泊松方程，其带有齐次狄利克雷边界条件，写作：$$\\nabla^2 u(x,y) = 0 \\quad \\text{for} \\quad (x,y)\\in(0,1)\\times(0,1), \\quad \\text{with} \\quad u(x,y)=0 \\quad \\text{on} \\quad \\partial\\Omega.$$ 使用标准的二阶中心差分格式，在一个均匀间距为 $h=1/(N+1)$ 的 $N\\times N$ 内部网格上，得到离散线性系统：$$A \\mathbf{u} = \\mathbf{f},$$ 其中 $A$ 是五点离散拉普拉斯算子，$\\mathbf{u}$ 是内部未知数的数组。在多重网格方法中，高斯-赛德尔 (GS) 松弛被用作光滑子，以衰减高频误差分量。其光滑特性可以通过类傅里叶误差模态的放大因子来量化。\n\n您的任务是从基本的离散算子和高斯-赛德尔的线性迭代分裂出发，推导在齐次系统（即 $\\mathbf{f}=\\mathbf{0}$，因此精确解为 $\\mathbf{u}^\\ast=\\mathbf{0}$）上的字典序高斯-赛德尔松弛的逐点更新公式，然后对由单个离散正弦模态给出的初始误差，实施两个预光滑和两个后光滑步骤（总共四次 GS 扫描）。具体而言：\n\n- 构建离散正弦模态：$$\\phi_{i,j}^{(k,\\ell)} = \\sin\\!\\bigg(\\frac{k\\pi i}{N+1}\\bigg)\\,\\sin\\!\\bigg(\\frac{\\ell\\pi j}{N+1}\\bigg),\\quad 1\\le i,j\\le N,$$ 并在离散 $\\ell^2$ 范数下对其进行归一化，使得 $$\\sum_{i=1}^N\\sum_{j=1}^N \\left(\\phi_{i,j}^{(k,\\ell)}\\right)^2 = 1.$$ 使用这个归一化后的模态作为初始误差 $\\mathbf{e}^{(0)}=\\phi^{(k,\\ell)}$。\n\n- 从离散拉普拉斯算子的矩阵分裂推导出字典序高斯-赛德尔松弛，并将其应用于齐次系统 $A\\mathbf{u}=\\mathbf{0}$，从 $\\mathbf{u}^{(0)}=\\mathbf{e}^{(0)}$ 开始，共进行四次扫描。令 $\\mathbf{u}^{(4)}$ 表示四次扫描后的结果。\n\n- 通过将最终误差 $\\mathbf{u}^{(4)}$ 投影到原始模态上，来量化所选模态的衰减，并将特定模态的放大因子定义为：$$\\alpha_{k,\\ell}(N) = \\left|\\frac{\\sum_{i=1}^N\\sum_{j=1}^N \\phi_{i,j}^{(k,\\ell)}\\,u^{(4)}_{i,j}}{\\sum_{i=1}^N\\sum_{j=1}^N \\phi_{i,j}^{(k,\\ell)}\\,u^{(0)}_{i,j}}\\right|.$$ 由于初始模态是归一化的，分母在数值舍入误差范围内等于 $1$。报告绝对值以衡量阻尼效果，不考虑任何相位反转。\n\n使用此构造方法来评估一组代表性模态的放大因子，这些模态用于探测高频和各向异性行为。您的程序必须从第一性原理（离散算子和迭代分裂）出发，实现字典序高斯-赛德尔更新，并计算以下测试集的放大因子：\n\n- 情况 1（理想情况，低频参考）：$N=32$, $k=1$, $\\ell=1$。\n- 情况 2（中高频，各向同性）：$N=32$, $k=16$, $\\ell=16$。\n- 情况 3（近奈奎斯特，各向同性极端情况）：$N=32$, $k=32$, $\\ell=32$。\n- 情况 4（$x$ 方向上的各向异性高频）：$N=32$, $k=32$, $\\ell=1$。\n- 情况 5（更大的网格，中高频，各向同性）：$N=64$, $k=32$, $\\ell=32$。\n- 情况 6（小网格边缘情况，近奈奎斯特）：$N=4$, $k=4$, $\\ell=4$。\n\n所有计算均为纯数值计算，不涉及物理单位。正弦模态中的角度以弧度为单位。您的程序应生成单行输出，其中包含六个放大因子，以逗号分隔的列表形式包含在方括号内，四舍五入到六位小数，并按上述情况的顺序排列。例如，输出格式必须与 \"[result1,result2,result3,result4,result5,result6]\" 完全一样。", "solution": "用户提供了一个数值分析领域的问题，具体涉及评估高斯-赛德尔光滑子性能，这是椭圆偏微分方程多重网格求解器的关键组成部分。该问题在科学和数学上是合理的、适定的，并且为解决它提供了所有必要的参数和定义。\n\n问题的核心是数值评估字典序高斯-赛德尔 (GS) 松弛方案对二维泊松方程的阻尼特性。这是通过测量固定次数 GS 扫描后特定误差模态的衰减来实现的。\n\n问题始于单位正方形上的齐次泊松方程 $\\nabla^2 u(x,y) = 0$，其边界条件为齐次狄利克雷条件 $u=0$。我们在一个具有 $N \\times N$ 个内部点和网格间距 $h=1/(N+1)$ 的均匀网格上离散化此方程。在网格点 $(i,j)$ 处，对拉普拉斯算子的标准五点中心差分近似为：\n$$ (L_h u)_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} $$\n对于所有内部点 $1 \\le i,j \\le N$ 设置 $(L_h u)_{i,j} = 0$，得到离散线性系统 $A\\mathbf{u} = \\mathbf{0}$。每个点 $(i,j)$ 的方程为：\n$$ 4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = 0 $$\n其中因子 $h^2$ 已被舍去，因为它对整个系统进行缩放。\n\n高斯-赛德尔是求解此类线性系统的迭代方法。对于系统 $A\\mathbf{u}=\\mathbf{f}$，矩阵 $A$ 被分解为其对角 ($D$)、严格下三角 ($L$) 和严格上三角 ($U$) 部分，即 $A=L+D+U$。GS 迭代则定义为 $(L+D)\\mathbf{u}^{(m+1)} = \\mathbf{f} - U\\mathbf{u}^{(m)}$。在我们的例子中，右侧为零，因此 $(L+D)\\mathbf{u}^{(m+1)} = -U\\mathbf{u}^{(m)}$。\n\n这种矩阵形式可以表示为逐点更新规则。为了计算迭代步骤 $m+1$ 的新值 $u_{i,j}^{(m+1)}$，我们重排离散方程：\n$$ u_{i,j} = \\frac{1}{4}\\left( u_{i-1,j} + u_{i+1,j} + u_{i,j-1} + u_{i,j+1} \\right) $$\n在字典序（逐行、逐列）扫描中，当我们更新 $u_{i,j}$ 时，“过去”邻居（例如 $u_{i-1,j}$ 和 $u_{i,j-1}$）的值已在当前扫描中更新，而“未来”邻居（例如 $u_{i+1,j}$ 和 $u_{i,j+1}$）的值则来自上一次扫描。这导致了更新规则：\n$$ u_{i,j}^{(m+1)} = \\frac{1}{4}\\left( u_{i-1,j}^{(m+1)} + u_{i,j-1}^{(m+1)} + u_{i+1,j}^{(m)} + u_{i,j+1}^{(m)} \\right) $$\n这是通过遍历网格点 $i=1,\\dots,N$ 和 $j=1,\\dots,N$ 并就地更新网格值来实现的。\n\n初始误差由单个离散正弦模态给出，这些是该网格上离散拉普拉斯算子的特征函数：\n$$ \\phi_{i,j}^{(k,\\ell)} = \\sin\\!\\bigg(\\frac{k\\pi i}{N+1}\\bigg)\\,\\sin\\!\\bigg(\\frac{\\ell\\pi j}{N+1}\\bigg), \\quad 1 \\le i,j,k,\\ell \\le N $$\n这个初始模态 $\\mathbf{e}^{(0)}$ 首先在离散 $\\ell^2$ 范数下进行归一化，得到 $\\boldsymbol{\\phi}^{(k,\\ell)}$，使得 $\\sum_{i,j} (\\phi_{i,j}^{(k,\\ell)})^2 = 1$。这个归一化后的模态作为迭代的初始网格状态，$\\mathbf{u}^{(0)} = \\boldsymbol{\\phi}^{(k,\\ell)}$。\n\n然后，我们对这个初始状态应用四次完整的字典序高斯-赛德尔松弛扫描，产生最终状态 $\\mathbf{u}^{(4)}$。问题要求通过将最终误差场 $\\mathbf{u}^{(4)}$ 投影回初始归一化模态 $\\boldsymbol{\\phi}^{(k,\\ell)}$ 来量化原始模态的阻尼。特定模态的放大因子定义为：\n$$ \\alpha_{k,\\ell}(N) = \\left|\\frac{\\langle \\mathbf{u}^{(4)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle}{\\langle \\mathbf{u}^{(0)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle}\\right| $$\n其中 $\\langle \\cdot, \\cdot \\rangle$ 表示离散内积 $\\sum_{i,j} a_{i,j}b_{i,j}$。由于 $\\mathbf{u}^{(0)} = \\boldsymbol{\\phi}^{(k,\\ell)}$ 且 $\\boldsymbol{\\phi}^{(k,\\ell)}$ 是归一化的，分母为 $\\langle \\boldsymbol{\\phi}^{(k,\\ell)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle=1$。因此，放大因子简化为投影的幅度：\n$$ \\alpha_{k,\\ell}(N) = \\left| \\sum_{i=1}^N\\sum_{j=1}^N u^{(4)}_{i,j}\\,\\phi_{i,j}^{(k,\\ell)} \\right| $$\n对于每个指定的测试案例 $(N,k,\\ell)$，此过程以数值方式执行。使用一个 $(N+2) \\times (N+2)$ 的网格，通过将边界上的值固定为 $0$ 来自然地包含齐次狄利克雷边界条件。迭代和投影仅在 $N \\times N$ 的内部网格点上执行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Gauss-Seidel amplification factor for specific sine modes.\n\n    This function iterates through a set of test cases, each defined by a grid\n    size N and mode numbers (k, l). For each case, it:\n    1. Constructs the initial error as a normalized discrete sine mode.\n    2. Applies four sweeps of lexicographic Gauss-Seidel relaxation.\n    3. Computes the amplification factor by projecting the final error onto\n       the initial mode.\n    The results are collected and printed in the specified format.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, 1, 1),    # Case 1: Low-frequency reference\n        (32, 16, 16),  # Case 2: Mid-high-frequency, isotropic\n        (32, 32, 32),  # Case 3: Near-Nyquist, isotropic extreme\n        (32, 32, 1),   # Case 4: Anisotropic high-frequency\n        (64, 32, 32),  # Case 5: Larger grid, mid-high-frequency\n        (4, 4, 4),     # Case 6: Small grid edge case, near-Nyquist\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, k, l = case\n\n        # Grid spacing h.\n        h = 1.0 / (N + 1)\n        \n        # 1. Construct the initial error mode on an (N+2)x(N+2) grid to\n        #    include boundaries. Boundaries are initialized to 0.\n        \n        # Create coordinate arrays for the interior grid.\n        i_vals = np.arange(1, N + 1)\n        j_vals = np.arange(1, N + 1)\n        ii, jj = np.meshgrid(i_vals, j_vals, indexing='ij')\n\n        # Calculate the un-normalized sine mode on the interior.\n        phi_interior = np.sin(k * np.pi * ii * h) * np.sin(l * np.pi * jj * h)\n\n        # 2. Normalize the mode in the discrete l2 norm.\n        norm = np.linalg.norm(phi_interior)\n        \n        # Check for zero norm to prevent division by zero, although not expected here.\n        if norm == 0:\n            normalized_phi_interior = phi_interior\n        else:\n            normalized_phi_interior = phi_interior / norm\n\n        # The initial state u_0 is the normalized mode.\n        # This grid will be modified by the GS sweeps.\n        u = np.zeros((N + 2, N + 2))\n        u[1:N+1, 1:N+1] = normalized_phi_interior\n\n        # Store a copy of the normalized initial mode for the final projection.\n        phi_normalized = u.copy()\n        \n        # 3. Apply four sweeps of lexicographic Gauss-Seidel relaxation.\n        num_sweeps = 4\n        for _ in range(num_sweeps):\n            # The loops must be in lexicographic order (row-by-row, col-by-col).\n            # The update is done in-place, which is the definition of GS.\n            for i in range(1, N + 1):\n                for j in range(1, N + 1):\n                    # Pointwise update rule derived from the 5-point stencil.\n                    u[i, j] = 0.25 * (u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1])\n\n        # 4. Quantify the amplification factor.\n        # The final state of the grid is u (which is u^(4)).\n        # We project u^(4) onto the initial normalized mode phi_normalized.\n        # The denominator is 1 due to normalization.\n        numerator = np.sum(phi_normalized * u)\n        \n        amplification_factor = np.abs(numerator)\n        \n        results.append(amplification_factor)\n\n    # Final print statement in the exact required format.\n    # Round results to six decimal places.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3480320"}, {"introduction": "在处理天体物理和数值相对论等前沿领域的实际问题时，我们遇到的椭圆方程往往包含可变的系数，这使得粗网格算子的构造变得不再简单。本练习 [@problem_id:3480295] 聚焦于这一高级应用场景，要求你构建并比较两种主流的粗网格算子生成方法：直接在粗网格上重新离散化，以及采用更为稳健的伽辽金（Galerkin）构造。通过计算这两种算子之间的差异，你将深刻理解计算科学家在算法的简易性与复杂物理问题下的精确性之间所需做出的权衡。", "problem": "考虑一个变系数类泊松算子，它出现在数值相对论的椭圆约束中，例如在构建引力波初始数据时。该算子由偏微分方程 $- \\nabla \\cdot (\\kappa(x,y) \\nabla u(x,y)) = f(x,y)$ 给出，定义在开放单位正方形 $\\Omega = (0,1) \\times (0,1)$上，并在边界 $\\partial \\Omega$ 上满足齐次狄利克雷边界条件 $u(x,y) = 0$。定义一个大小为 $N \\times N$（包括边界节点）的均匀节点网格，其间距为 $h = 1/(N-1)$，内部索引集为 $\\{1,2,\\dots,N-2\\} \\times \\{1,2,\\dots,N-2\\}$。使用基于面心系数的保守二阶有限差分格式来构建一个对称正定矩阵算子 $A_f \\in \\mathbb{R}^{n_f \\times n_f}$，其中 $n_f = (N_f-2)^2$。该算子作用于细网格的内部未知数向量，$N_f$ 是细网格的节点数。\n\n内部节点 $(i,j)$ 处的离散算子由以下通量形式定义\n$$\n(L_h u)_{i,j} = -\\frac{1}{h^2} \\Big( \\kappa_{i+\\frac{1}{2},j} (u_{i+1,j} - u_{i,j}) - \\kappa_{i-\\frac{1}{2},j} (u_{i,j} - u_{i-1,j}) + \\kappa_{i,j+\\frac{1}{2}} (u_{i,j+1} - u_{i,j}) - \\kappa_{i,j-\\frac{1}{2}} (u_{i,j} - u_{i,j-1}) \\Big),\n$$\n其中，面心系数由 $\\kappa_{i+\\frac{1}{2},j} = \\kappa(x_{i+\\frac{1}{2}}, y_j)$ 和 $\\kappa_{i,j+\\frac{1}{2}} = \\kappa(x_i, y_{j+\\frac{1}{2}})$ 给出，其中 $x_{i+\\frac{1}{2}} = x_i + h/2$ 且 $y_{j+\\frac{1}{2}} = y_j + h/2$。连续系数定义为\n$$\n\\kappa(x,y) = 1 + a \\sin(2\\pi m x)\\cos(2\\pi m y),\n$$\n其中振幅 $a \\in [0,1)$，整数频率 $m \\geq 1$，这确保了 $\\kappa(x,y)  0$。\n\n设粗网格是几何嵌套的，其节点数为 $N_c = (N_f + 1)/2$，间距为 $H = 1/(N_c-1)$，内部大小为 $n_c = (N_c - 2)^2$。定义标准的双线性插值（延长）算子 $P \\in \\mathbb{R}^{n_f \\times n_c}$，它将粗网格内部未知数映射到细网格内部未知数，具体如下：对于每个细网格内部节点 $(i,j)$，插值是其周围粗网格节点值的双线性组合；当所需的粗网格节点位于边界上时，由于齐次狄利克雷边界条件，其贡献为零。使用以与粗网格节点重合的细网格节点为中心的 $3 \\times 3$ 模板权重来定义全加权限制算子 $R \\in \\mathbb{R}^{n_c \\times n_f}$\n$$\n\\frac{1}{16}\n\\begin{bmatrix}\n1  2  1 \\\\\n2  4  2 \\\\\n1  2  1\n\\end{bmatrix}\n$$。\n\n利用这些，Galerkin 粗网格算子为 $A_c^{\\mathrm{Gal}} = R A_f P \\in \\mathbb{R}^{n_c \\times n_c}$。重新离散化的粗网格算子 $A_c^{\\mathrm{Red}} \\in \\mathbb{R}^{n_c \\times n_c}$ 是通过在间距为 $H$ 的粗网格上应用相同的保守二阶格式，并在粗网格面上计算连续函数 $\\kappa(x,y)$ 的值得到的。\n\n您的任务：\n- 在细网格上，使用指定的通量形式离散化以及从 $\\kappa(x,y)$ 计算出的面心系数来构建 $A_f$。\n- 使用与齐次狄利克雷边界一致的双线性插值构建 $P$，并使用指定的全加权方法构建 $R$。\n- 计算 Galerkin 粗算子 $A_c^{\\mathrm{Gal}} = R A_f P$。\n- 通过在粗网格上使用相同的格式和来自相同 $\\kappa(x,y)$ 的面心系数进行重新离散化来构建 $A_c^{\\mathrm{Red}}$。\n- 对每个测试用例，计算相对 Frobenius 范数差\n$$\n\\delta = \\frac{\\lVert A_c^{\\mathrm{Gal}} - A_c^{\\mathrm{Red}} \\rVert_F}{\\lVert A_c^{\\mathrm{Red}} \\rVert_F}.\n$$\n\n推导和算法的基本要求：\n- 从结构化网格上 $- \\nabla \\cdot (\\kappa \\nabla u)$ 的保守二阶离散化定义开始。\n- 使用 Galerkin 粗网格算子、双线性插值和全加权限制的几何多重网格定义。\n- 在适用的情况下，通过零边界贡献确保与齐次狄利克雷边界条件的一致性。\n\n测试套件：\n- 用例1（一般变系数，中等网格）：$N_f = 33, a = 0.5, m = 1$。\n- 用例2（常系数，基准）：$N_f = 33, a = 0.0, m = 1$。\n- 用例3（变系数，较小网格）：$N_f = 17, a = 0.9, m = 1$。\n- 用例4（较高频率系数，中等网格）：$N_f = 33, a = 0.7, m = 4$。\n\n输出规范：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，其中包含与上述四个测试用例按顺序列出的四个浮点值 $\\delta$。例如，格式必须与 $[\\delta_1,\\delta_2,\\delta_3,\\delta_4]$ 完全一样，每个 $\\delta$ 都以 Python 浮点数形式打印。", "solution": "该问题要求比较在多重网格方法中用于求解变系数椭圆偏微分方程的两种不同粗网格算子。该比较基于 Galerkin 粗网格算子 $A_c^{\\mathrm{Gal}}$ 和重新离散化的粗网格算子 $A_c^{\\mathrm{Red}}$ 之间的相对 Frobenius 范数差。\n\n该问题在数值分析领域是适定的且有科学依据的，特别是在应用于求解数值相对论中的椭圆约束方程时。所有参数和定义都已提供，可以进行直接而明确的实现。我将着手系统地构建所需的矩阵。\n\n### 1. 连续算子的离散化\n\n连续问题是求解偏微分方程（PDE）\n$$\n- \\nabla \\cdot (\\kappa(x,y) \\nabla u(x,y)) = f(x,y)\n$$\n在单位正方形 $\\Omega = (0,1) \\times (0,1)$ 上，并满足齐次狄利克雷边界条件 $u(x,y) = 0$ 在边界 $\\partial \\Omega$ 上。系数 $\\kappa(x,y)$ 由 $\\kappa(x,y) = 1 + a \\sin(2\\pi m x)\\cos(2\\pi m y)$ 给出。\n\n我们在一​​个具有 $N \\times N$ 个节点和间距 $h = 1/(N-1)$ 的均匀网格上离散化此方程。令 $u_{i,j}$ 表示解在网格节点 $(x_i, y_j) = (ih, jh)$ 处的值。该问题指定了一个保守的二阶有限差分格式。对于 $i,j \\in \\{1, \\dots, N-2\\}$，内部节点 $(i,j)$ 处的离散算子 $L_h$ 为\n$$\n(L_h u)_{i,j} = -\\frac{1}{h^2} \\Big( \\kappa_{i+\\frac{1}{2},j} (u_{i+1,j} - u_{i,j}) - \\kappa_{i-\\frac{1}{2},j} (u_{i,j} - u_{i-1,j}) + \\kappa_{i,j+\\frac{1}{2}} (u_{i,j+1} - u_{i,j}) - \\kappa_{i,j-\\frac{1}{2}} (u_{i,j} - u_{i,j-1}) \\Big).\n$$\n面心系数是 $\\kappa(x,y)$ 在节点中点处的求值，例如 $\\kappa_{i+\\frac{1}{2},j} = \\kappa(x_i + h/2, y_j)$。\n\n离散方程组为 $A \\mathbf{u} = \\mathbf{f}$，其中 $\\mathbf{u}$ 是 $n = (N-2)^2$ 个内部网格点上未知值的向量。矩阵 $A$ 表示离散算子的负值，即 $-L_h$。通过重排 $(L_h u)_{i,j}$ 的各项，我们可以确定矩阵 $A$ 的模板：\n$$\n(A \\mathbf{u})_{i,j} = \\frac{1}{h^2} \\Big[ (\\kappa_{i+\\frac{1}{2},j} + \\kappa_{i-\\frac{1}{2},j} + \\kappa_{i,j+\\frac{1}{2}} + \\kappa_{i,j-\\frac{1}{2}}) u_{i,j} - \\kappa_{i+\\frac{1}{2},j} u_{i+1,j} - \\kappa_{i-\\frac{1}{2},j} u_{i-1,j} - \\kappa_{i,j+\\frac{1}{2}} u_{i,j+1} - \\kappa_{i,j-\\frac{1}{2}} u_{i,j-1} \\Big].\n$$\n向量 $\\mathbf{u}$ 是通过按特定顺序（通常是行主序）排列 $u_{i,j}$ 值形成的。对于内部索引 $i,j \\in \\{1, \\dots, N-2\\}$，从二维网格索引 $(i,j)$ 到一维向量索引 $k$ 的映射为 $k = (i-1)(N-2) + (j-1)$。这种结构定义了一个大小为 $n \\times n$ 的稀疏对称正定矩阵 $A$。齐次狄利克雷边界条件的处理方式是注意到，当 $i$ 或 $j$ 为 $0$ 或 $N-1$ 时，任何 $u_{i,j}$ 都为零，因此这些项在邻近边界的内部节点的方程中会消失。\n\n细网格算子 $A_f$ 和粗网格重新离散化算子 $A_c^{\\mathrm{Red}}$ 都使用此方法构建，但分别使用不同的网格参数（$N_f, h$）和（$N_c, H$）。\n\n### 2. 网格间传递算子：延长与限制\n\n我们给定一个每维有 $N_f$ 个点的细网格和一个有 $N_c = (N_f+1)/2$ 个点的粗网格。相应的内部问题大小为 $n_f = (N_f-2)^2$ 和 $n_c = (N_c-2)^2$。\n\n**延长（插值）算子 $P$**：延长算子 $P \\in \\mathbb{R}^{n_f \\times n_c}$ 将粗网格内部值的向量映射到细网格内部值的向量。我们使用双线性插值。对于一个细网格内部点 $(i_f, j_f)$，其值是周围四个粗网格点插值的结果。权重取决于细网格点相对于粗网格的位置。\n- 与粗网格点 $(2i_c, 2j_c)$ 重合的细网格点取该粗网格点的值。\n- 位于网格边上的细网格点，例如 $(2i_c+1, 2j_c)$，是两个相邻粗网格点的平均值。\n- 位于单元中心的细网格点 $(2i_c+1, 2j_c+1)$，是周围四个粗网格点的平均值。\n由于齐次狄利克雷条件，来自粗网格边界点的贡献为零。矩阵 $P$ 的每一行都是通过为相应的细网格点确定这些权重来构建的。\n\n**限制算子 $R$**：限制算子 $R \\in \\mathbb{R}^{n_c \\times n_f}$ 将细网格向量映射到粗网格向量。我们使用全加权限制。粗网格内部点 $(i_c, j_c)$ 处的值是其对应细网格位置 $(2i_c, 2j_c)$ 为中心的 $3 \\times 3$ 细网格点块的值的加权平均。权重由以下模板给出：\n$$\n\\frac{1}{16}\n\\begin{bmatrix}\n1  2  1 \\\\\n2  4  2 \\\\\n1  2  1\n\\end{bmatrix}.\n$$\n与延长算子一样，边界上的细网格点值为零，对求和没有贡献。\n\n### 3. 粗网格算子与比较\n\n使用两种方法来定义粗网格算子。\n\n**重新离散化算子 $A_c^{\\mathrm{Red}}$**：此算子通过直接在间距为 $H = 1/(N_c-1)$ 的粗网格上应用相同的有限差分格式来构建。系数函数 $\\kappa(x,y)$ 在粗网格单元的面心处求值。这种方法很简单，但可能无法捕捉到在粗网格上发生混叠的 $\\kappa(x,y)$ 的细尺度变化。\n\n**Galerkin 算子 $A_c^{\\mathrm{Gal}}$**：此算子由所谓的 Galerkin 投影定义：$A_c^{\\mathrm{Gal}} = R A_f P$。它表示从粗网格“视角”下的细网格算子。这种构建方式计算成本更高，但保证能捕捉到细网格算子 $A_f$ 的特性，使其对于具有复杂或快速变化系数的问题具有鲁棒性。\n\n这两种算子之间的根本区别在于数值误差的来源。$A_c^{\\mathrm{Red}}$ 的属性继承自粗网格上离散化的截断误差。$A_c^{\\mathrm{Gal}}$ 的属性通过投影继承自细网格算子。对于常系数 $\\kappa$，两者并不相同；$A_c^{\\mathrm{Red}}$ 通常具有 5 点模板，而 $A_c^{\\mathrm{Gal}}$ 具有 9 点模板。对于变系数 $\\kappa$，差异可能更为显著。\n\n需要计算的量是相对 Frobenius 范数差：\n$$\n\\delta = \\frac{\\lVert A_c^{\\mathrm{Gal}} - A_c^{\\mathrm{Red}} \\rVert_F}{\\lVert A_c^{\\mathrm{Red}} \\rVert_F},\n$$\n其中 $\\lVert M \\rVert_F = \\sqrt{\\sum_{i,j} |M_{ij}|^2}$。该度量标准量化了两种粗网格算子定义之间的差异。\n\n算法的流程是：首先为给定参数实现构建四个矩阵（$A_f$、$A_c^{\\mathrm{Red}}$、$P$、$R$）的函数，然后执行矩阵乘法以获得 $A_c^{\\mathrm{Gal}}$，最后计算 $\\delta$。对四个测试用例中的每一个重复此过程。", "answer": "```python\nimport numpy as np\n\ndef kappa(x, y, a, m):\n    \"\"\"Computes the continuous coefficient kappa(x,y).\"\"\"\n    return 1.0 + a * np.sin(2 * np.pi * m * x) * np.cos(2 * np.pi * m * y)\n\ndef construct_operator(N, a, m):\n    \"\"\"\n    Constructs the discrete operator matrix A for a given grid size N\n    and coefficient parameters a, m.\n    \"\"\"\n    if N = 2:\n        return np.array([[]])\n    \n    n = (N - 2)**2\n    h = 1.0 / (N - 1)\n    A = np.zeros((n, n))\n    \n    width = N - 2\n    coords = np.linspace(0, 1, N)\n\n    for i in range(1, N - 1):      # 1-based row index\n        for j in range(1, N - 1):  # 1-based column index\n            k = (i - 1) * width + (j - 1) # 0-based 1D index\n            \n            x_i, y_j = coords[i], coords[j]\n            \n            k_ip12 = kappa(x_i + h / 2.0, y_j, a, m)\n            k_im12 = kappa(x_i - h / 2.0, y_j, a, m)\n            k_jp12 = kappa(x_i, y_j + h / 2.0, a, m)\n            k_jm12 = kappa(x_i, y_j - h / 2.0, a, m)\n\n            # Diagonal entry\n            A[k, k] = (k_ip12 + k_im12 + k_jp12 + k_jm12) / h**2\n            \n            # Off-diagonal entries (connections to neighbors)\n            # Connection to u_{i, j+1} (North)\n            if j  N - 2:\n                A[k, k + 1] = -k_jp12 / h**2\n            # Connection to u_{i, j-1} (South)\n            if j > 1:\n                A[k, k - 1] = -k_jm12 / h**2\n            # Connection to u_{i+1, j} (East)\n            if i  N - 2:\n                A[k, k + width] = -k_ip12 / h**2\n            # Connection to u_{i-1, j} (West)\n            if i > 1:\n                A[k, k - width] = -k_im12 / h**2\n                \n    return A\n\ndef construct_prolongation(N_f, N_c):\n    \"\"\"Constructs the bilinear interpolation (prolongation) operator P.\"\"\"\n    n_f = (N_f - 2)**2\n    n_c = (N_c - 2)**2\n    if n_f == 0 or n_c == 0:\n        return np.zeros((n_f, n_c))\n\n    P = np.zeros((n_f, n_c))\n    width_f = N_f - 2\n    width_c = N_c - 2\n    \n    for i_f in range(1, N_f - 1):\n        for j_f in range(1, N_f - 1):\n            k_f = (i_f - 1) * width_f + (j_f - 1)\n            \n            is_i_f_even = (i_f % 2 == 0)\n            is_j_f_even = (j_f % 2 == 0)\n\n            if is_i_f_even and is_j_f_even:\n                # Type 1: Fine node coincides with a coarse node\n                i_c, j_c = i_f // 2, j_f // 2\n                if 1 = i_c = N_c - 2 and 1 = j_c = N_c - 2:\n                    k_c = (i_c - 1) * width_c + (j_c - 1)\n                    P[k_f, k_c] = 1.0\n\n            elif not is_i_f_even and is_j_f_even:\n                # Type 2: Fine node on a vertical coarse-grid edge\n                j_c = j_f // 2\n                i_c_lo = (i_f - 1) // 2\n                i_c_hi = i_c_lo + 1\n                if 1 = j_c = N_c - 2:\n                    if 1 = i_c_lo = N_c - 2:\n                        k_c1 = (i_c_lo - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c1] = 0.5\n                    if 1 = i_c_hi = N_c - 2:\n                        k_c2 = (i_c_hi - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c2] = 0.5\n            \n            elif is_i_f_even and not is_j_f_even:\n                # Type 3: Fine node on a horizontal coarse-grid edge\n                i_c = i_f // 2\n                j_c_lo = (j_f - 1) // 2\n                j_c_hi = j_c_lo + 1\n                if 1 = i_c = N_c - 2:\n                    if 1 = j_c_lo = N_c - 2:\n                        k_c1 = (i_c - 1) * width_c + (j_c_lo - 1)\n                        P[k_f, k_c1] = 0.5\n                    if 1 = j_c_hi = N_c - 2:\n                        k_c2 = (i_c - 1) * width_c + (j_c_hi - 1)\n                        P[k_f, k_c2] = 0.5\n\n            elif not is_i_f_even and not is_j_f_even:\n                # Type 4: Fine node at a coarse-cell center\n                i_c_lo, j_c_lo = (i_f - 1) // 2, (j_f - 1) // 2\n                i_c_hi, j_c_hi = i_c_lo + 1, j_c_lo + 1\n                \n                nodes = [(i_c_lo, j_c_lo), (i_c_hi, j_c_lo), \n                         (i_c_lo, j_c_hi), (i_c_hi, j_c_hi)]\n                for i_c, j_c in nodes:\n                    if 1 = i_c = N_c - 2 and 1 = j_c = N_c - 2:\n                        k_c = (i_c - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c] = 0.25\n    return P\n\ndef construct_restriction(N_f, N_c):\n    \"\"\"Constructs the full-weighting restriction operator R.\"\"\"\n    n_f = (N_f - 2)**2\n    n_c = (N_c - 2)**2\n    if n_f == 0 or n_c == 0:\n        return np.zeros((n_c, n_f))\n        \n    R = np.zeros((n_c, n_f))\n    width_f = N_f - 2\n    width_c = N_c - 2\n    \n    weights = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16.0\n    \n    for i_c in range(1, N_c - 1):\n        for j_c in range(1, N_c - 1):\n            k_c = (i_c - 1) * width_c + (j_c - 1)\n            i_f_center, j_f_center = 2 * i_c, 2 * j_c\n            \n            for di in range(-1, 2):\n                for dj in range(-1, 2):\n                    i_f, j_f = i_f_center + di, j_f_center + dj\n                    \n                    if 1 = i_f = N_f - 2 and 1 = j_f = N_f - 2:\n                        k_f = (i_f - 1) * width_f + (j_f - 1)\n                        R[k_c, k_f] = weights[di + 1, dj + 1]\n    return R\n\ndef compute_delta(N_f, a, m):\n    \"\"\"\n    Computes the relative Frobenius-norm difference for a given test case.\n    \"\"\"\n    # Grid parameters\n    N_c = (N_f + 1) // 2\n    \n    # Construct operators\n    A_f = construct_operator(N_f, a, m)\n    P = construct_prolongation(N_f, N_c)\n    R = construct_restriction(N_f, N_c)\n    A_c_red = construct_operator(N_c, a, m)\n    \n    # Compute Galerkin operator\n    A_c_gal = R @ A_f @ P\n    \n    # Compute relative difference\n    diff_norm = np.linalg.norm(A_c_gal - A_c_red, 'fro')\n    red_norm = np.linalg.norm(A_c_red, 'fro')\n    \n    if red_norm == 0:\n        return 0.0 if diff_norm == 0 else np.inf\n        \n    return diff_norm / red_norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (33, 0.5, 1),\n        (33, 0.0, 1),\n        (17, 0.9, 1),\n        (33, 0.7, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        Nf, a, m = case\n        delta = compute_delta(Nf, a, m)\n        results.append(delta)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3480295"}]}