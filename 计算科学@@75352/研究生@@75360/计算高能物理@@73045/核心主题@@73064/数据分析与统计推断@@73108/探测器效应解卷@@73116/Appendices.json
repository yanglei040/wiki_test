{"hands_on_practices": [{"introduction": "任何解卷积（unfolding）分析的第一步都是精确地描述探测器效应。本练习将指导您如何将蒙特卡洛（Monte Carlo）模拟的原始计数转化为解卷积问题的核心数学工具：接收度矩阵（acceptance matrix）、效率（efficiency）和经过接收度校正的响应矩阵（acceptance-corrected response）。通过这个基础计算（[@problem_id:3540787]），您将为后续更复杂的解卷积算法和正则化研究奠定坚实的基础。", "problem": "一个探测器通过蒙特卡洛（MC）方法模拟一个过程，该过程的粒子层面（真相）相空间被划分为三个由 $i \\in \\{1,2,3\\}$ 索引的区间，其重建（reco）相空间被划分为四个由 $j \\in \\{1,2,3,4\\}$ 索引的区间。设 $N_{i}^{\\text{truth}}$ 表示在真相区间 $i$ 中生成的 MC 真相事件的总数，设 $N_{ji}$ 表示那些真相区间为 $i$ 的事件中，被探测器模拟重建到重建区间 $j$ 的事件数。MC 产额如下：\n- 真相计数：$N_{1}^{\\text{truth}}=1000$，$N_{2}^{\\text{truth}}=1200$，$N_{3}^{\\text{truth}}=800$。\n- 迁移计数（给定真相的重建）：对于 $i=1$，$(N_{1,1},N_{2,1},N_{3,1},N_{4,1})=(320,280,100,50)$；对于 $i=2$，$(N_{1,2},N_{2,2},N_{3,2},N_{4,2})=(150,420,360,90)$；对于 $i=3$，$(N_{1,3},N_{2,3},N_{3,3},N_{4,3})=(40,160,280,120)$。\n\n从概率和条件概率的频率学派定义出发，并将 MC 视为这些概率的大样本估计量，推导并计算：\n1. 接受度（也称为包含无效率的响应）矩阵 $A_{ji}$，其概念上定义为，给定事件在真相区间 $i$ 的条件下，其在重建区间 $j$ 被重建的条件概率，该概率通过 MC 计数估计得出。\n2. 每个真相区间 $i$ 的效率 $\\epsilon_{i}$，其概念上定义为，一个在真相区间 $i$ 中的事件被重建到四个重建区间中任意一个的总概率。\n3. 接受度修正后的响应 $\\tilde{R}_{ji}$，其概念上定义为，给定事件在真相区间 $i$ 中且被重建（即，以接受度为条件）的条件下，其在重建区间 $j$ 中的条件概率，通过将 $A_{ji}$ 的每个真相列除以其对应的 $\\epsilon_{i}$ 来进行归一化得到。\n\n假设所有估计都是计数的精确比率，不进行任何进一步的正则化或平滑。将所有概率表示为精确的有理数，不进行四舍五入。使用 $\\mathrm{pmatrix}$ 环境，将您的最终答案报告为一个单一的行向量，按以下顺序列出各项：\n- 首先是矩阵 $A_{ji}$，按真相区间 $i=1,2,3$ 逐列排列，每列内按 $j=1,2,3,4$ 排列；\n- 然后是效率 $(\\epsilon_{1},\\epsilon_{2},\\epsilon_{3})$；\n- 然后是接受度修正后的响应矩阵 $\\tilde{R}_{ji}$，按相同的逐列顺序列出。", "solution": "问题陈述已经过验证，被认为是自洽的、科学上合理的且格式正确的。它提出了高能物理中与探测器模拟和展开相关的标准计算任务。所有必要的数据和定义都已提供，且没有内部矛盾。因此，我们可以着手求解。\n\n问题要求计算描述探测器效应的三个相关量：接受度矩阵 $A_{ji}$、真相区间效率 $\\epsilon_i$ 以及接受度修正后的响应矩阵 $\\tilde{R}_{ji}$。我们将基于应用于所提供的蒙特卡洛（MC）事件计数的概率频率学派解释，依次推导并计算每个量。\n\n设 $T_i$ 为粒子在真相区间 $i$ 中生成的事件，设 $R_j$ 为其在重建区间 $j$ 中被重建的事件。给定的计数为：\n- 在真相区间 $i$ 中生成的事件总数：$N(\\text{T}_i) = N_{i}^{\\text{truth}}$。\n- 在真相区间 $i$ 中生成且在重建区间 $j$ 中重建的事件数：$N(\\text{R}_j \\cap \\text{T}_i) = N_{ji}$。\n\n提供的数值为：\n- $N_{1}^{\\text{truth}} = 1000$，$N_{2}^{\\text{truth}} = 1200$，$N_{3}^{\\text{truth}} = 800$。\n- 对于 $i=1$：$(N_{1,1}, N_{2,1}, N_{3,1}, N_{4,1}) = (320, 280, 100, 50)$。\n- 对于 $i=2$：$(N_{1,2}, N_{2,2}, N_{3,2}, N_{4,2}) = (150, 420, 360, 90)$。\n- 对于 $i=3$：$(N_{1,3}, N_{2,3}, N_{3,3}, N_{4,3}) = (40, 160, 280, 120)$。\n\n所有概率都估计为计数的比率。\n\n**1. 接受度矩阵 $A_{ji}$**\n\n接受度矩阵 $A_{ji}$ 定义为，给定一个事件起源于真相区间 $i$，它在重建区间 $j$ 被重建的条件概率。这表示为 $P(\\text{R}_j | \\text{T}_i)$。使用条件概率的频率学派定义，我们将其估计为：\n$$\nA_{ji} = P(\\text{R}_j | \\text{T}_i) = \\frac{N(\\text{R}_j \\cap \\text{T}_i)}{N(\\text{T}_i)} = \\frac{N_{ji}}{N_{i}^{\\text{truth}}}\n$$\n我们对每个真相区间 $i \\in \\{1,2,3\\}$ 逐列计算这个 $4 \\times 3$ 矩阵的元素。\n\n对于真相区间 $i=1$ ($N_{1}^{\\text{truth}}=1000$):\n$A_{11} = \\frac{N_{11}}{N_{1}^{\\text{truth}}} = \\frac{320}{1000} = \\frac{8}{25}$\n$A_{21} = \\frac{N_{21}}{N_{1}^{\\text{truth}}} = \\frac{280}{1000} = \\frac{7}{25}$\n$A_{31} = \\frac{N_{31}}{N_{1}^{\\text{truth}}} = \\frac{100}{1000} = \\frac{1}{10}$\n$A_{41} = \\frac{N_{41}}{N_{1}^{\\text{truth}}} = \\frac{50}{1000} = \\frac{1}{20}$\n\n对于真相区间 $i=2$ ($N_{2}^{\\text{truth}}=1200$):\n$A_{12} = \\frac{N_{12}}{N_{2}^{\\text{truth}}} = \\frac{150}{1200} = \\frac{1}{8}$\n$A_{22} = \\frac{N_{22}}{N_{2}^{\\text{truth}}} = \\frac{420}{1200} = \\frac{7}{20}$\n$A_{32} = \\frac{N_{32}}{N_{2}^{\\text{truth}}} = \\frac{360}{1200} = \\frac{3}{10}$\n$A_{42} = \\frac{N_{42}}{N_{2}^{\\text{truth}}} = \\frac{90}{1200} = \\frac{3}{40}$\n\n对于真相区间 $i=3$ ($N_{3}^{\\text{truth}}=800$):\n$A_{13} = \\frac{N_{13}}{N_{3}^{\\text{truth}}} = \\frac{40}{800} = \\frac{1}{20}$\n$A_{23} = \\frac{N_{23}}{N_{3}^{\\text{truth}}} = \\frac{160}{800} = \\frac{1}{5}$\n$A_{33} = \\frac{N_{33}}{N_{3}^{\\text{truth}}} = \\frac{280}{800} = \\frac{7}{20}$\n$A_{43} = \\frac{N_{43}}{N_{3}^{\\text{truth}}} = \\frac{120}{800} = \\frac{3}{20}$\n\n**2. 效率 $\\epsilon_i$**\n\n真相区间 $i$ 的效率 $\\epsilon_i$ 是来自该区间的事件被重建到*任意一个*重建区间的总概率。这是对所有可能的重建结果 $j$ 的条件概率之和。\n$$\n\\epsilon_i = P(\\text{reconstructed} | \\text{T}_i) = \\sum_{j=1}^{4} P(\\text{R}_j | \\text{T}_i) = \\sum_{j=1}^{4} A_{ji}\n$$\n等效地，它是起源于真相区间 $i$ 的重建事件总数除以在真相区间 $i$ 中生成的事件总数。\n$$\n\\epsilon_i = \\frac{\\sum_{j=1}^{4} N_{ji}}{N_{i}^{\\text{truth}}}\n$$\n我们计算每个真相区间 $i \\in \\{1,2,3\\}$ 的 $\\epsilon_i$。\n\n对于真相区间 $i=1$:\n$\\epsilon_1 = \\frac{320+280+100+50}{1000} = \\frac{750}{1000} = \\frac{3}{4}$\n\n对于真相区间 $i=2$:\n$\\epsilon_2 = \\frac{150+420+360+90}{1200} = \\frac{1020}{1200} = \\frac{17}{20}$\n\n对于真相区间 $i=3$:\n$\\epsilon_3 = \\frac{40+160+280+120}{800} = \\frac{600}{800} = \\frac{3}{4}$\n\n**3. 接受度修正后的响应 $\\tilde{R}_{ji}$**\n\n接受度修正后的响应 $\\tilde{R}_{ji}$ 是指，给定一个事件起源于真相区间 $i$ *且*被重建的条件下，该事件在重建区间 $j$ 中被重建的条件概率。设‘Reco'd’为粒子在任意一个区间被重建的事件。那么 $\\tilde{R}_{ji} = P(\\text{R}_j | \\text{T}_i \\cap \\text{Reco'd})$。\n根据条件概率的定义：\n$$\n\\tilde{R}_{ji} = \\frac{P(\\text{R}_j \\cap (\\text{T}_i \\cap \\text{Reco'd}))}{P(\\text{T}_i \\cap \\text{Reco'd})}\n$$\n由于事件 $\\text{R}_j$ 蕴含了事件‘Reco'd’，交集 $\\text{R}_j \\cap \\text{Reco'd}$ 就是 $\\text{R}_j$。因此，分子变为 $P(\\text{R}_j \\cap \\text{T}_i)$。表达式简化为：\n$$\n\\tilde{R}_{ji} = \\frac{P(\\text{R}_j \\cap \\text{T}_i)}{P(\\text{Reco'd} \\cap \\text{T}_i)}\n$$\n将分子和分母同除以 $P(\\text{T}_i)$ 得：\n$$\n\\tilde{R}_{ji} = \\frac{P(\\text{R}_j \\cap \\text{T}_i) / P(\\text{T}_i)}{P(\\text{Reco'd} \\cap \\text{T}_i) / P(\\text{T}_i)} = \\frac{P(\\text{R}_j | \\text{T}_i)}{P(\\text{Reco'd} | \\text{T}_i)} = \\frac{A_{ji}}{\\epsilon_i}\n$$\n这证实了将 $A_{ji}$ 的每一列除以对应的效率 $\\epsilon_i$ 进行归一化的方法。对于每个真相区间 $i$，列 $\\tilde{R}_{ji}$ 是一个正确的归一化概率分布，即 $\\sum_{j=1}^{4} \\tilde{R}_{ji} = 1$。\n\n对于真相区间 $i=1$ ($\\epsilon_1 = 3/4$):\n$\\tilde{R}_{11} = \\frac{A_{11}}{\\epsilon_1} = \\frac{8/25}{3/4} = \\frac{32}{75}$\n$\\tilde{R}_{21} = \\frac{A_{21}}{\\epsilon_1} = \\frac{7/25}{3/4} = \\frac{28}{75}$\n$\\tilde{R}_{31} = \\frac{A_{31}}{\\epsilon_1} = \\frac{1/10}{3/4} = \\frac{4}{30} = \\frac{2}{15}$\n$\\tilde{R}_{41} = \\frac{A_{41}}{\\epsilon_1} = \\frac{1/20}{3/4} = \\frac{4}{60} = \\frac{1}{15}$\n\n对于真相区间 $i=2$ ($\\epsilon_2 = 17/20$):\n$\\tilde{R}_{12} = \\frac{A_{12}}{\\epsilon_2} = \\frac{1/8}{17/20} = \\frac{20}{136} = \\frac{5}{34}$\n$\\tilde{R}_{22} = \\frac{A_{22}}{\\epsilon_2} = \\frac{7/20}{17/20} = \\frac{7}{17}$\n$\\tilde{R}_{32} = \\frac{A_{32}}{\\epsilon_2} = \\frac{3/10}{17/20} = \\frac{60}{170} = \\frac{6}{17}$\n$\\tilde{R}_{42} = \\frac{A_{42}}{\\epsilon_2} = \\frac{3/40}{17/20} = \\frac{60}{680} = \\frac{3}{34}$\n\n对于真相区间 $i=3$ ($\\epsilon_3 = 3/4$):\n$\\tilde{R}_{13} = \\frac{A_{13}}{\\epsilon_3} = \\frac{1/20}{3/4} = \\frac{4}{60} = \\frac{1}{15}$\n$\\tilde{R}_{23} = \\frac{A_{23}}{\\epsilon_3} = \\frac{1/5}{3/4} = \\frac{4}{15}$\n$\\tilde{R}_{33} = \\frac{A_{33}}{\\epsilon_3} = \\frac{7/20}{3/4} = \\frac{28}{60} = \\frac{7}{15}$\n$\\tilde{R}_{43} = \\frac{A_{43}}{\\epsilon_3} = \\frac{3/20}{3/4} = \\frac{12}{60} = \\frac{1}{5} = \\frac{3}{15}$\n\n按照要求将所有结果合并成一个单一的行向量，即可完成任务。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{8}{25}  \\frac{7}{25}  \\frac{1}{10}  \\frac{1}{20}  \\frac{1}{8}  \\frac{7}{20}  \\frac{3}{10}  \\frac{3}{40}  \\frac{1}{20}  \\frac{1}{5}  \\frac{7}{20}  \\frac{3}{20}  \\frac{3}{4}  \\frac{17}{20}  \\frac{3}{4}  \\frac{32}{75}  \\frac{28}{75}  \\frac{2}{15}  \\frac{1}{15}  \\frac{5}{34}  \\frac{7}{17}  \\frac{6}{17}  \\frac{3}{34}  \\frac{1}{15}  \\frac{4}{15}  \\frac{7}{15}  \\frac{3}{15}\n\\end{pmatrix}\n}\n$$", "id": "3540787"}, {"introduction": "在理解了响应矩阵的构建之后，我们便可以应用一个具体的解卷积算法。本练习（[@problem_id:3540819]）将深入探讨在高能物理中广泛应用的 G. D'Agostini 迭代贝叶斯方法。通过推导其单步更新规则并解析地计算解卷积结果对初始先验分布的敏感度，您将对该方法中的正则化机制及其对先验选择的依赖性获得更深刻的定量理解。", "problem": "考虑一个计算高能物理中的计数测量，其中一个具有两个区间（由 $j \\in \\{1,2\\}$ 索引）的真值分布，在两个重建区间（由 $i \\in \\{1,2\\}$ 索引）中以有限的分辨率和非效率被观测到。探测器响应由条件概率 $A_{ij} = P(i \\mid j)$ 表征，真值区间 $j$ 中的探测效率为 $\\epsilon_{j} = \\sum_{i} A_{ij}$，且 $0 \\leq \\epsilon_{j} \\leq 1$。设测得的重建计数为 $m_{1} = 1000$ 和 $m_{2} = 800$。初始先验真值计数为 $f_{1}^{(0)} = 900$ 和 $f_{2}^{(0)} = 700$。响应矩阵为\n$$\nA \\;=\\; \\begin{pmatrix}\n0.8  0.2 \\\\\n0.2  0.6\n\\end{pmatrix},\n$$\n其中 $A_{11} = 0.8$, $A_{12} = 0.2$, $A_{21} = 0.2$ 及 $A_{22} = 0.6$。\n\n假设解卷过程使用由 G. D'Agostini 引入的迭代贝叶斯方法，其更新规则源自贝叶斯定理和已知的探测效率。从贝叶斯定理的基本关系式 $P(j \\mid i) = \\frac{P(i \\mid j)\\,P(j)}{\\sum_{k} P(i \\mid k)\\,P(k)}$ 以及预期重建计数是由真值通过响应矩阵折叠得到这一事实出发，推导出第一次迭代的解卷估计 $f_{j}^{(1)}$，用 $f_{j}^{(0)}$、$m_{i}$、$A_{ij}$ 和 $\\epsilon_{j}$ 表示。然后，解析计算第一次迭代时，真值区间 $j=1$ 中的解卷结果对真值区间 $\\ell=2$ 中初始先验的灵敏度，即计算在给定数值下的 $\\frac{\\partial f_{1}^{(1)}}{\\partial f_{2}^{(0)}}$。将您的最终数值答案四舍五入到四位有效数字。您的最终答案不带单位。", "solution": "### 步骤 1：提取已知条件\n题目提供了以下数据和定义：\n-   真值区间数：$j \\in \\{1,2\\}$\n-   重建区间数：$i \\in \\{1,2\\}$\n-   条件概率的响应矩阵 $A_{ij} = P(i \\mid j)$：\n    $$ A = \\begin{pmatrix} 0.8  0.2 \\\\ 0.2  0.6 \\end{pmatrix} $$\n    这意味着 $A_{11} = 0.8$, $A_{12} = 0.2$, $A_{21} = 0.2$, 以及 $A_{22} = 0.6$。\n-   真值区间 $j$ 中的探测效率：$\\epsilon_{j} = \\sum_{i} A_{ij}$，其中 $0 \\leq \\epsilon_{j} \\leq 1$。\n-   测得的重建计数：$m_{1} = 1000$ 和 $m_{2} = 800$。\n-   初始先验真值计数（迭代 0）：$f_{1}^{(0)} = 900$ 和 $f_{2}^{(0)} = 700$。\n-   解卷方法是 G. D'Agostini 的迭代贝叶斯方法。\n-   推导的起点是贝叶斯定理：$P(j \\mid i) = \\frac{P(i \\mid j)\\,P(j)}{\\sum_{k} P(i \\mid k)\\,P(k)}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准评估问题陈述。\n-   **科学依据（关键）**：该问题基于由 G. D'Agostini 开发的迭代贝叶斯解卷技术，这是实验高能物理中一个标准且有据可查的方法。其基本原理是贝叶斯统计和矩阵运算，这些在数学上和科学上都是合理的。\n-   **适定性**：该问题要求进行推导和后续计算。所有必要的数值（$m_i$, $f_j^{(0)}$, $A_{ij}$）和定义都已提供。问题明确，可以得出一个唯一的解析和数值答案。\n-   **客观性（关键）**：问题以精确、定量和无偏见的语言陈述。没有主观或基于意见的成分。\n-   **不完整或矛盾的设定**：设定是完整且自洽的。响应矩阵元素是概率（$0 \\leq A_{ij} \\leq 1$），由此产生的效率 $\\epsilon_j = \\sum_i A_{ij}$ 也处于有效范围 $[0, 1]$ 内。具体来说，$\\epsilon_1 = A_{11} + A_{21} = 0.8 + 0.2 = 1.0$，$ \\epsilon_2 = A_{12} + A_{22} = 0.2 + 0.6 = 0.8$。这些值在物理上是一致的。\n-   **不切实际或不可行**：所提供的计数、先验和响应概率的数值对于一个典型的物理计数实验是合理的。\n-   **未检测到其他缺陷。** 该问题结构严谨，并与指定的计算高能物理领域的标准实践保持一致。\n\n### 步骤 3：结论与行动\n问题有效。将提供一个完整的、有理有据的解答。\n\n### 解答推导与计算\n\n问题要求推导第一次迭代的解卷估计 $f_{j}^{(1)}$，并计算一个特定的灵敏度 $\\frac{\\partial f_{1}^{(1)}}{\\partial f_{2}^{(0)}}$。\n\n**第 1 部分：解卷公式的推导**\n\nD'Agostini 解卷方法的核心是应用贝叶斯定理来迭代更新对真实分布的估计。我们按照指示，从贝叶斯定理开始，该定理描述了给定一个效应（在重建区间 $i$ 中观测到的事件）下，一个原因（来自真值区间 $j$ 的事件）的概率：\n$$ P(j \\mid i) = \\frac{P(i \\mid j) P(j)}{\\sum_{k} P(i \\mid k) P(k)} $$\n在本问题的背景下：\n-   $P(i \\mid j)$ 是给定事件起源于真值区间 $j$ 时，在重建区间 $i$ 中观测到该事件的概率。这由响应矩阵给出，$P(i \\mid j) = A_{ij}$。\n-   $P(j)$ 是事件起源于真值区间 $j$ 的先验概率。这被认为与我们当前对该区间中真实事件数的最佳估计 $f_j^{(0)}$ 成正比。即，$P(j) = \\frac{f_j^{(0)}}{\\sum_l f_l^{(0)}}$。\n\n将这些代入贝叶斯定理，归一化常数 $\\sum_l f_l^{(0)}$ 在分子和分母中被消去：\n$$ P(j \\mid i) = \\frac{A_{ij} f_j^{(0)}}{\\sum_{k} A_{ik} f_k^{(0)}} $$\n这个表达式 $P(j \\mid i)$ 代表在重建区间 $i$ 中观测到的事件中，估计起源于真值区间 $j$ 的事件所占的比例。\n\n给定在重建区间 $i$ 中测得的 $m_i$ 个事件，其中被归属到真值区间 $j$ 的事件数为 $m_i P(j \\mid i)$。为了找到与真值区间 $j$ 相关联的*观测到*的总事件数，我们对所有重建区间 $i$ 求和：\n$$ n_{\\text{obs}, j} = \\sum_{i} m_i P(j \\mid i) = \\sum_{i} m_i \\frac{A_{ij} f_j^{(0)}}{\\sum_{k} A_{ik} f_k^{(0)}} $$\n这个量 $n_{\\text{obs}, j}$ 代表了从真值区间 $j$ 发出并被实际探测到的事件数。起源于真值区间 $j$ 的总事件数，我们记作更新后的估计值 $f_j^{(1)}$，通过探测效率 $\\epsilon_j$ 与 $n_{\\text{obs}, j}$ 相关联：\n$$ n_{\\text{obs}, j} = \\epsilon_j f_j^{(1)} $$\n其中 $\\epsilon_j = \\sum_i A_{ij}$ 是一个来自真值区间 $j$ 的事件在*任意*重建区间被探测到的概率。\n\n解出 $f_j^{(1)}$，我们得到单步迭代贝叶斯解卷公式：\n$$ f_j^{(1)} = \\frac{1}{\\epsilon_j} n_{\\text{obs}, j} = \\frac{1}{\\epsilon_j} \\sum_{i} m_i \\frac{A_{ij} f_j^{(0)}}{\\sum_{k} A_{ik} f_k^{(0)}} $$\n这就是推导出的第一次迭代解卷估计的表达式。\n\n**第 2 部分：灵敏度的解析计算**\n\n我们被要求计算在真值区间 $j=1$ 中的解卷结果对真值区间 $\\ell=2$ 中初始先验的灵敏度，即偏导数 $\\frac{\\partial f_{1}^{(1)}}{\\partial f_{2}^{(0)}}$。\n对于我们的 2 区间情况（$j, k, \\ell \\in \\{1,2\\}$），$f_1^{(1)}$ 的表达式是：\n$$ f_1^{(1)} = \\frac{1}{\\epsilon_1} \\left( m_1 \\frac{A_{11} f_1^{(0)}}{A_{11} f_1^{(0)} + A_{12} f_2^{(0)}} + m_2 \\frac{A_{21} f_1^{(0)}}{A_{21} f_1^{(0)} + A_{22} f_2^{(0)}} \\right) $$\n我们现在将此表达式对 $f_2^{(0)}$ 求导，将 $f_1^{(0)}$、$m_1$ 和 $m_2$ 视为常数。我们对形如 $\\frac{c}{u(x)}$ 的项使用链式法则，其中 $\\frac{d}{dx}(\\frac{c}{u(x)}) = -\\frac{c}{u(x)^2} \\frac{du}{dx}$。\n\n对于和式中的第一项：\n$$ \\frac{\\partial}{\\partial f_2^{(0)}} \\left( m_1 \\frac{A_{11} f_1^{(0)}}{A_{11} f_1^{(0)} + A_{12} f_2^{(0)}} \\right) = m_1 A_{11} f_1^{(0)} \\left( - \\frac{A_{12}}{(A_{11} f_1^{(0)} + A_{12} f_2^{(0)})^2} \\right) = - \\frac{m_1 A_{11} A_{12} f_1^{(0)}}{(A_{11} f_1^{(0)} + A_{12} f_2^{(0)})^2} $$\n对于和式中的第二项：\n$$ \\frac{\\partial}{\\partial f_2^{(0)}} \\left( m_2 \\frac{A_{21} f_1^{(0)}}{A_{21} f_1^{(0)} + A_{22} f_2^{(0)}} \\right) = m_2 A_{21} f_1^{(0)} \\left( - \\frac{A_{22}}{(A_{21} f_1^{(0)} + A_{22} f_2^{(0)})^2} \\right) = - \\frac{m_2 A_{21} A_{22} f_1^{(0)}}{(A_{21} f_1^{(0)} + A_{22} f_2^{(0)})^2} $$\n结合这些结果，完整的偏导数是：\n$$ \\frac{\\partial f_1^{(1)}}{\\partial f_2^{(0)}} = \\frac{1}{\\epsilon_1} \\left( - \\frac{m_1 A_{11} A_{12} f_1^{(0)}}{(A_{11} f_1^{(0)} + A_{12} f_2^{(0)})^2} - \\frac{m_2 A_{21} A_{22} f_1^{(0)}}{(A_{21} f_1^{(0)} + A_{22} f_2^{(0)})^2} \\right) $$\n\n**第 3 部分：数值计算**\n\n我们将给定的数值代入推导出的表达式中。\n首先，计算效率 $\\epsilon_1$：\n$$ \\epsilon_1 = \\sum_{i=1}^2 A_{i1} = A_{11} + A_{21} = 0.8 + 0.2 = 1.0 $$\n给定的值为：\n-   $m_1 = 1000$, $m_2 = 800$\n-   $f_1^{(0)} = 900$, $f_2^{(0)} = 700$\n-   $A_{11} = 0.8$, $A_{12} = 0.2$\n-   $A_{21} = 0.2$, $A_{22} = 0.6$\n\n现在，我们计算导数中的两项：\n**第 1 项：**\n-   分母：$(A_{11} f_1^{(0)} + A_{12} f_2^{(0)})^2 = (0.8 \\times 900 + 0.2 \\times 700)^2 = (720 + 140)^2 = 860^2 = 739600$。\n-   分子：$-m_1 A_{11} A_{12} f_1^{(0)} = -1000 \\times 0.8 \\times 0.2 \\times 900 = -1000 \\times 0.16 \\times 900 = -144000$。\n-   第一个分数：$\\frac{-144000}{739600}$。\n\n**第 2 项：**\n-   分母：$(A_{21} f_1^{(0)} + A_{22} f_2^{(0)})^2 = (0.2 \\times 900 + 0.6 \\times 700)^2 = (180 + 420)^2 = 600^2 = 360000$。\n-   分子：$-m_2 A_{21} A_{22} f_1^{(0)} = -800 \\times 0.2 \\times 0.6 \\times 900 = -800 \\times 0.12 \\times 900 = -86400$。\n-   第二个分数：$\\frac{-86400}{360000}$。\n\n现在，我们计算总和：\n$$ \\frac{\\partial f_1^{(1)}}{\\partial f_2^{(0)}} = \\frac{1}{1.0} \\left( \\frac{-144000}{739600} + \\frac{-86400}{360000} \\right) $$\n$$ \\frac{\\partial f_1^{(1)}}{\\partial f_2^{(0)}} = -0.19469983... - 0.24 $$\n$$ \\frac{\\partial f_1^{(1)}}{\\partial f_2^{(0)}} = -0.43469983... $$\n将最终结果四舍五入到四位有效数字，得到 $-0.4347$。负号表示，随着对真值区间 2 中事件数的先验信念增加，对真值区间 1 中事件数的解卷估计值会减少，这是解卷过程的一个预期特征，因为它重新归属了共享的测量计数。", "answer": "$$\n\\boxed{-0.4347}\n$$", "id": "3540819"}, {"introduction": "解卷积本质上是一个病态逆问题（ill-posed inverse problem），而正则化是获得物理上有意义解的关键。本动手编程练习（[@problem_id:3540846]）旨在对比两种强大的正则化范式：Tikhonov 正则化（$L_2$ 范数）和全变分正则化（Total Variation, $L_1$ 范数）。通过在一个包含尖锐结构的光谱上实现并应用这些方法，您将直接观察到它们的不同行为——$L_2$ 正则化倾向于平滑所有特征，而 $L_1$ 正则化则能更好地保持边缘锋利——从而学会在具体物理问题中选择合适的工具。", "problem": "您面临一个一维展开问题，该问题模拟了探测器模糊效应以及在阈值处的效率急剧下降。其基本基础是连接未知真实谱与测量谱的线性正演模型。设 $N$ 表示分箱数，$\\mathbf{t} \\in \\mathbb{R}^{N}$ 表示未知的真实分箱含量，$\\mathbf{m} \\in \\mathbb{R}^{N}$ 表示测量的分箱含量。探测器响应由矩阵 $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ 建模，因此正演模型为\n$$\n\\mathbf{m} = \\mathbf{A} \\mathbf{t}.\n$$\n响应矩阵包含了逐箱效率 $\\varepsilon_i$ 和分辨率模糊效应。模糊效应通过分箱空间中宽度为 $\\sigma$ 的高斯核进行建模，而效率则对每个真实分箱以乘法方式施加。对于每个真实分箱索引 $i \\in \\{0,\\dots,N-1\\}$，$\\mathbf{A}$ 的第 $i$ 列由下式给出\n$$\nA_{j i} = \\varepsilon_i \\, \\frac{\\exp\\left( -\\frac{(j-i)^2}{2 \\sigma^2} \\right)}{\\sum\\limits_{k=0}^{N-1} \\exp\\left( -\\frac{(k-i)^2}{2 \\sigma^2} \\right)}, \\quad j \\in \\{0,\\dots,N-1\\}.\n$$\n效率模型在阈值分箱索引 $\\theta$ 处包含一个急剧下降。具体来说，\n$$\n\\varepsilon_i = \\begin{cases}\n1, & i < \\theta, \\\\\n\\varepsilon_{\\mathrm{drop}}, & i \\ge \\theta,\n\\end{cases}\n$$\n其中 $0 < \\varepsilon_{\\mathrm{drop}} < 1$。\n\n您的任务是基于上述定义构建响应矩阵，从已知的真实谱合成测量谱，并使用三种方法进行展开：无正则化最小二乘法、使用一阶差分二次惩罚的 Tikhonov 正则化，以及使用一阶差分 $\\ell_1$ 惩罚的总变差 (TV) 正则化。展开后的谱估计分别表示为 $\\widehat{\\mathbf{t}}_{\\mathrm{LS}}$、$\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}$ 和 $\\widehat{\\mathbf{t}}_{\\mathrm{TV}}$。\n\n1. 正演模型和真实谱：\n   - 使用 $N = 50$ 个分箱。\n   - 使用真实谱 $\\mathbf{t}$，其分量为 $t_i = 1$，适用于所有 $i \\in \\{0,\\dots,N-1\\}$。\n   - 使用测试套件中指定的高斯模糊宽度 $\\sigma$ 以及阈值为 $\\theta$ 和下降值为 $\\varepsilon_{\\mathrm{drop}}$ 的效率模型来构建 $\\mathbf{A}$。\n\n2. 展开方法：\n   - 无正则化最小二乘法：求解\n     $$\n     \\widehat{\\mathbf{t}}_{\\mathrm{LS}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2.\n     $$\n   - Tikhonov 正则化（一阶差分二次）：设 $\\mathbf{D} \\in \\mathbb{R}^{(N-1)\\times N}$ 为由 $(\\mathbf{D}\\mathbf{x})_i = x_{i+1} - x_i$ 定义的一阶差分算子。对于给定的正则化强度 $\\alpha > 0$，求解\n     $$\n     \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\frac{\\alpha}{2} \\lVert \\mathbf{D}\\mathbf{x} \\rVert_2^2.\n     $$\n     这会得到正规方程组\n     $$\n     \\left( \\mathbf{A}^\\top \\mathbf{A} + \\alpha \\mathbf{D}^\\top \\mathbf{D} \\right) \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\mathbf{A}^\\top \\mathbf{m}.\n     $$\n   - 总变差 (TV) 正则化（一阶差分 $\\ell_1$）：对于给定的 TV 强度 $\\tau > 0$，求解\n     $$\n     \\widehat{\\mathbf{t}}_{\\mathrm{TV}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\tau \\lVert \\mathbf{D}\\mathbf{x} \\rVert_1.\n     $$\n     通过交替方向乘子法 (ADMM) 实现此方法，引入辅助变量 $\\mathbf{z} = \\mathbf{D}\\mathbf{x}$ 和惩罚参数 $\\rho > 0$，迭代过程如下\n     $$\n     \\mathbf{x}^{k+1} = \\left( \\mathbf{A}^\\top \\mathbf{A} + \\rho \\mathbf{D}^\\top \\mathbf{D} \\right)^{-1}\\left( \\mathbf{A}^\\top \\mathbf{m} + \\rho \\mathbf{D}^\\top(\\mathbf{z}^k - \\mathbf{u}^k) \\right),\n     $$\n     $$\n     \\mathbf{z}^{k+1} = \\operatorname{soft}\\left(\\mathbf{D}\\mathbf{x}^{k+1} + \\mathbf{u}^k, \\frac{\\tau}{\\rho}\\right),\n     $$\n     $$\n     \\mathbf{u}^{k+1} = \\mathbf{u}^k + \\mathbf{D}\\mathbf{x}^{k+1} - \\mathbf{z}^{k+1},\n     $$\n     其中软阈值算子按分量定义为 $\\operatorname{soft}(v, \\kappa) = \\operatorname{sign}(v)\\max(|v| - \\kappa, 0)$。\n\n3. 用于量化正则化器如何处理诱导边缘的指标：\n   对于每个展开谱 $\\widehat{\\mathbf{t}}$ 和每个测试用例，计算：\n   - 均方误差 (MSE)：\n     $$\n     \\mathrm{MSE}(\\widehat{\\mathbf{t}}) = \\frac{1}{N} \\sum_{i=0}^{N-1} \\left( \\widehat{t}_i - t_i \\right)^2.\n     $$\n   - 阈值处的边缘残差幅度：\n     将阈值索引定义为 $\\theta$。如果 $\\theta \\in \\{0,\\dots,N-2\\}$，使用\n     $$\n     E(\\widehat{\\mathbf{t}}) = \\left| \\widehat{t}_{\\theta+1} - \\widehat{t}_{\\theta} \\right|.\n     $$\n     如果 $\\theta = N-1$，使用\n     $$\n     E(\\widehat{\\mathbf{t}}) = \\left| \\widehat{t}_{\\theta} - \\widehat{t}_{\\theta-1} \\right|.\n     $$\n   - 相对于真实谱的高区域平均偏差：\n     $$\n     B(\\widehat{\\mathbf{t}}) = \\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} \\widehat{t}_i - \\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} t_i.\n     $$\n     由于 $t_i = 1$，这可简化为 $B(\\widehat{\\mathbf{t}}) = \\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} \\widehat{t}_i - 1$。\n\n4. 测试套件：\n   使用以下三组参数来构建响应矩阵，合成 $\\mathbf{m} = \\mathbf{A}\\mathbf{t}$，并进行展开：\n   - 情况 1（一般情况）：$N = 50$，$\\sigma = 1.5$，$\\theta = 30$，$\\varepsilon_{\\mathrm{drop}} = 0.05$，$\\alpha = 10^{-2}$，$\\tau = 10^{-2}$，$\\rho = 0.5$。\n   - 情况 2（边界阈值在最后一个分箱）：$N = 50$，$\\sigma = 1.5$，$\\theta = 49$，$\\varepsilon_{\\mathrm{drop}} = 0.05$，$\\alpha = 10^{-2}$，$\\tau = 10^{-2}$，$\\rho = 0.5$。\n   - 情况 3（最小模糊，极端下降）：$N = 50$，$\\sigma = 0.5$，$\\theta = 25$，$\\varepsilon_{\\mathrm{drop}} = 0.01$，$\\alpha = 10^{-2}$，$\\tau = 10^{-2}$，$\\rho = 0.5$。\n\n5. 要求的最终输出格式：\n   您的程序应生成单行输出，其中包含一个列表的列表形式的结果，每个内部列表对应一个测试用例。对于每个测试用例，输出一个包含 9 个浮点数的列表，顺序如下：\n   $$\n   \\left[ \\mathrm{MSE}(\\widehat{\\mathbf{t}}_{\\mathrm{LS}}), \\, E(\\widehat{\\mathbf{t}}_{\\mathrm{LS}}), \\, B(\\widehat{\\mathbf{t}}_{\\mathrm{LS}}), \\, \\mathrm{MSE}(\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}), \\, E(\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}), \\, B(\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}), \\, \\mathrm{MSE}(\\widehat{\\mathbf{t}}_{\\mathrm{TV}}), \\, E(\\widehat{\\mathbf{t}}_{\\mathrm{TV}}), \\, B(\\widehat{\\mathbf{t}}_{\\mathrm{TV}}) \\right].\n   $$\n   将三个测试用例按上述顺序汇总为一个列表，产生以下形式的输出\n   $$\n   \\left[ [\\cdots], [\\cdots], [\\cdots] \\right].\n   $$\n   不应打印任何其他文本。", "solution": "所提出的问题是计算高能物理学中一个明确定义的练习，具体涉及从测得的一维谱中解卷积或“展开”探测器效应。该问题具有科学依据，数学上一致，并提供了进行求解所需的所有信息。\n\n问题的核心是线性正演模型，它通过探测器响应矩阵 $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ 将真实的未知分布 $\\mathbf{t} \\in \\mathbb{R}^N$ 与测量到的分布 $\\mathbf{m} \\in \\mathbb{R}^N$ 联系起来。此关系由下式给出：\n$$\n\\mathbf{m} = \\mathbf{A} \\mathbf{t}\n$$\n展开的目标是在给定测量谱 $\\mathbf{m}$ 和响应矩阵 $\\mathbf{A}$ 的情况下，估计真实谱 $\\mathbf{t}$。这是一个逆问题，由于 $\\mathbf{A}$ 的性质，它通常是病态的 (ill-posed)。\n\n响应矩阵 $\\mathbf{A}$ 模拟了两种主要的探测器效应：分辨率模糊和探测效率。\n对于每个真实分箱 $i$，$\\mathbf{A}$ 的相应列描述了源于分箱 $i$ 的事件如何在测量的分箱 $j$ 之间分布。\n模糊效应通过宽度为 $\\sigma$ 的归一化高斯核进行建模，表示探测器的有限分辨率，这会使尖锐特征变得模糊。效率 $\\varepsilon_i$ 是每个真实分箱的乘法因子，表示分箱 $i$ 中的事件被探测到的总概率。问题指定了在阈值分箱 $\\theta$ 处效率会急剧下降。因此，$\\mathbf{A}$ 的元素定义如下：\n$$\nA_{j i} = \\varepsilon_i \\, \\frac{\\exp\\left( -\\frac{(j-i)^2}{2 \\sigma^2} \\right)}{\\sum_{k=0}^{N-1} \\exp\\left( -\\frac{(k-i)^2}{2 \\sigma^2} \\right)}\n$$\n其中效率 $\\varepsilon_i$ 是一个阶跃函数：\n$$\n\\varepsilon_i = \\begin{cases}\n1, & \\text{if } i < \\theta \\\\\n\\varepsilon_{\\mathrm{drop}}, & \\text{if } i \\ge \\theta\n\\end{cases}\n$$\n利用已知的真实谱 $\\mathbf{t}$（一个 $t_i = 1$ 的平坦分布），测量谱 $\\mathbf{m}$ 被合成为 $\\mathbf{m} = \\mathbf{A} \\mathbf{t}$。\n\n采用三种展开方法从 $\\mathbf{m}$ 和 $\\mathbf{A}$ 估计 $\\mathbf{t}$。\n\n1.  **无正则化最小二乘法 (LS)**：这是解决逆问题最直接的方法。它旨在寻找一个估计值 $\\widehat{\\mathbf{t}}_{\\mathrm{LS}}$，以最小化重新卷积后的估计值 $\\mathbf{A}\\mathbf{x}$ 与测量数据 $\\mathbf{m}$ 之间的平方差。目标函数是：\n    $$\n    \\widehat{\\mathbf{t}}_{\\mathrm{LS}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2\n    $$\n    这是一个标准的线性最小二乘问题，其解可通过求解正规方程组找到：\n    $$\n    \\mathbf{A}^\\top \\mathbf{A} \\, \\widehat{\\mathbf{t}}_{\\mathrm{LS}} = \\mathbf{A}^\\top \\mathbf{m}\n    $$\n    然而，矩阵 $\\mathbf{A}^\\top \\mathbf{A}$ 通常是病态的 (ill-conditioned)，导致解对微小扰动高度敏感，这通常表现为大的、不符合物理规律的振荡。\n\n2.  **Tikhonov 正则化**：该方法通过添加一个惩罚项来扩展最小二乘法，该惩罚项可对解进行正则化，抑制振荡。这里使用的一个常见选择是惩罚解向量一阶差分的平方 $\\ell_2$-范数，以促进平滑性。一阶差分算子是一个矩阵 $\\mathbf{D} \\in \\mathbb{R}^{(N-1)\\times N}$。目标函数是：\n    $$\n    \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\frac{\\alpha}{2} \\lVert \\mathbf{D}\\mathbf{x} \\rVert_2^2\n    $$\n    这里，$\\alpha > 0$ 是正则化强度，它在拟合优度与解的平滑度之间进行权衡。这也有一个通过修正的正规方程组得到的闭式解：\n    $$\n    \\left( \\mathbf{A}^\\top \\mathbf{A} + \\alpha \\mathbf{D}^\\top \\mathbf{D} \\right) \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\mathbf{A}^\\top \\mathbf{m}\n    $$\n    添加项 $\\alpha \\mathbf{D}^\\top \\mathbf{D}$ 通常会改善矩阵的条件数，从而得到更稳定的解。然而，这种正则化可能会过度平滑尖锐特征，例如由效率下降引起的边缘。\n\n3.  **总变差 (TV) 正则化**：该方法对一阶差分使用 $\\ell_1$-范数惩罚，该方法以其在平滑平坦区域的同时保留尖锐边缘的能力而闻名。目标函数是：\n    $$\n    \\widehat{\\mathbf{t}}_{\\mathrm{TV}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\tau \\lVert \\mathbf{D}\\mathbf{x} \\rVert_1\n    $$\n    参数 $\\tau > 0$ 控制 TV 正则化的强度。与 Tikhonov 正则化不同，由于不可微的 $\\ell_1$-范数，此问题没有简单的闭式解。这里使用交替方向乘子法 (ADMM) 进行求解。这种迭代算法引入一个辅助变量 $\\mathbf{z}$，并通过交替更新主变量 $\\mathbf{x}$、辅助变量 $\\mathbf{z}$ 和对偶变量 $\\mathbf{u}$ 来解决问题。按规定实现了更新步骤：\n    $\\mathbf{x}$-更新涉及求解一个类似于 Tikhonov 情况的线性系统。$\\mathbf{z}$-更新涉及一个分量级别的软阈值操作，这是促进差分 $\\mathbf{D}\\mathbf{x}$ 稀疏性的关键步骤，从而保留边缘。$\\mathbf{u}$-更新是一个强制执行约束 $\\mathbf{z} = \\mathbf{D}\\mathbf{x}$ 的简单步骤。\n\n最后，使用三个指标评估每种展开方法的性能：\n-   **均方误差 (MSE)**：$\\frac{1}{N} \\sum (\\widehat{t}_i - t_i)^2$。这提供了展开谱准确性的全局度量。\n-   **边缘残差幅度 ($E$)**：$|\\widehat{t}_{\\theta+1} - \\widehat{t}_{\\theta}|$（或在边界处的类似形式）。这特别量化了真实谱中的急剧下降（由效率模型隐含引入）被重建得如何。由于真实谱是平坦的（$t_i=1$），理想的差异是 $0$，但展开必须抵消效率阶跃的影响。这测试了正则化器对边缘的处理能力。\n-   **高区域平均偏差 ($B$)**：$\\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} \\widehat{t}_i - 1$。这测量了在受效率下降影响的区域中，展开解的平均值与真实平均值的系统性偏差，量化了展开过程引入的任何偏差。\n\n实现将通过系统地构建矩阵、合成数据、应用三种展开算法中的每一种，并为每个测试用例计算九个指定的指标来进行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_case(N, sigma, theta, eps_drop, alpha, tau, rho):\n    \"\"\"\n    Runs a single test case for the unfolding problem.\n    \"\"\"\n    # 1. Setup: Define the true spectrum\n    t_true = np.ones(N)\n\n    # 2. Construct model matrices\n\n    # Construct efficiency vector\n    eps = np.ones(N)\n    if theta < N:\n        eps[theta:] = eps_drop\n\n    # Construct response matrix A\n    A = np.zeros((N, N))\n    indices = np.arange(N)\n    for i in range(N):\n        # Gaussian smearing kernel for column i\n        kernel_col = np.exp(-(indices - i)**2 / (2 * sigma**2))\n        # The kernel must be normalized to conserve events before efficiency\n        norm = np.sum(kernel_col)\n        if norm > 0:\n            kernel_col /= norm\n        # Apply efficiency\n        A[:, i] = eps[i] * kernel_col\n\n    # Construct first-difference operator D\n    D = np.zeros((N - 1, N))\n    row_indices = np.arange(N - 1)\n    D[row_indices, row_indices] = -1\n    D[row_indices, row_indices + 1] = 1\n\n    # 3. Synthesize measured data\n    m = A @ t_true\n\n    # 4. Perform unfolding with the three methods\n\n    # 4.1. Unregularized Least Squares\n    # Solve (A^T A) x = A^T m\n    try:\n        lhs_ls = A.T @ A\n        rhs_ls = A.T @ m\n        t_hat_ls = np.linalg.solve(lhs_ls, rhs_ls)\n    except np.linalg.LinAlgError:\n        # Use pseudo-inverse for singular matrices\n        t_hat_ls = np.linalg.pinv(A) @ m\n\n    # 4.2. Tikhonov Regularization\n    # Solve (A^T A + alpha D^T D) x = A^T m\n    lhs_tik = A.T @ A + alpha * (D.T @ D)\n    rhs_tik = A.T @ m\n    t_hat_tik = np.linalg.solve(lhs_tik, rhs_tik)\n\n    # 4.3. Total Variation Regularization via ADMM\n    def soft_threshold(v, kappa):\n        \"\"\"Soft-thresholding operator.\"\"\"\n        return np.sign(v) * np.maximum(np.abs(v) - kappa, 0)\n    \n    # Initialize ADMM variables\n    x = np.zeros(N)\n    z = np.zeros(N - 1)\n    u = np.zeros(N - 1)\n    \n    # Pre-compute the inverse matrix for the x-update step for efficiency\n    x_update_matrix = A.T @ A + rho * (D.T @ D)\n    x_update_matrix_inv = np.linalg.inv(x_update_matrix)\n    \n    # ADMM iterations\n    num_iterations = 200\n    for _ in range(num_iterations):\n        # x-update\n        rhs_x = A.T @ m + rho * D.T @ (z - u)\n        x = x_update_matrix_inv @ rhs_x\n        \n        # z-update\n        z_arg = D @ x + u\n        z = soft_threshold(z_arg, tau / rho)\n        \n        # u-update\n        u = u + D @ x - z\n    \n    t_hat_tv = x\n\n    # 5. Calculate and collect metrics\n    \n    all_results = []\n    for t_hat in [t_hat_ls, t_hat_tik, t_hat_tv]:\n        # Metric 1: Mean Squared Error (MSE)\n        mse = np.mean((t_hat - t_true)**2)\n        \n        # Metric 2: Edge Residual Magnitude (E)\n        if theta == N - 1:\n            edge_residual = np.abs(t_hat[theta] - t_hat[theta - 1])\n        elif theta < N - 1:\n            edge_residual = np.abs(t_hat[theta + 1] - t_hat[theta])\n        else: # Case where theta >= N, not in tests, but for completeness.\n            edge_residual = 0.0\n\n        # Metric 3: High-Region Mean Bias (B)\n        # The true mean in the high region is 1.0 since t_true is all ones.\n        if N > theta:\n            bias = np.mean(t_hat[theta:]) - 1.0\n        else: # Case theta >= N\n            bias = 0.0\n\n        all_results.extend([mse, edge_residual, bias])\n        \n    return all_results\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general case)\n        {'N': 50, 'sigma': 1.5, 'theta': 30, 'eps_drop': 0.05, \n         'alpha': 1e-2, 'tau': 1e-2, 'rho': 0.5},\n        # Case 2 (boundary threshold)\n        {'N': 50, 'sigma': 1.5, 'theta': 49, 'eps_drop': 0.05, \n         'alpha': 1e-2, 'tau': 1e-2, 'rho': 0.5},\n        # Case 3 (minimal smearing, extreme drop)\n        {'N': 50, 'sigma': 0.5, 'theta': 25, 'eps_drop': 0.01, \n         'alpha': 1e-2, 'tau': 1e-2, 'rho': 0.5},\n    ]\n\n    results = []\n    for params in test_cases:\n        case_result = run_case(**params)\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # We construct the string manually to avoid spaces python's default str() adds.\n    case_strings = []\n    for res_list in results:\n        case_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n\n```", "id": "3540846"}]}