{"hands_on_practices": [{"introduction": "在启动一个复杂的模拟之前，估算所需的计算资源至关重要。这第一个练习提供了一个设计多层分裂模拟的基础性训练，展示了如何确定所需的层级数和每层的样本量，以使最终估计达到预期的统计精度 [@problem_id:3346498]。通过解决这个问题，您将深入理解控制分裂方法效率的基本权衡关系。", "problem": "考虑使用多层分离法来估计稀有事件概率。令目标稀有事件概率为 $p$，并假设我们在每一层选择一个恒定的层级条件存活概率 $p_0$。该算法使用 $K$ 个层级，其中 $K$ 的选择使得各层级概率的乘积能够重现目标 $p$。每一层使用 $n$ 个独立样本，通过经验分数来估计其条件存活概率。假设各层级间的抽样是独立的，并将每层的经验分数建模为二项式估计量。$p$ 的估计量是 $K$ 个经验分数的乘积，每层一个。\n\n从变异系数 (CV) 的定义，即 $\\mathrm{CV} = \\sqrt{\\mathrm{Var}(\\widehat{p})}/\\mathbb{E}[\\widehat{p}]$，以及关于比例的二项式估计量的标准性质出发，使用一阶线性化方法，推导乘积估计量的变异系数关于 $K$、$p_0$ 和 $n$ 的近似表达式。然后，使用这个近似表达式，根据给定的以下量，确定每层所需的最小整数样本量 $n$，以满足预设的变异系数目标 $c$：\n- $p = 10^{-6}$，\n- $p_0 = 10^{-1}$，\n- $c = 3 \\times 10^{-1}$。\n\n计算：\n1. 层级数 $K = \\lceil \\ln(p) / \\ln(p_0) \\rceil$，其中 $\\ln$ 表示自然对数。\n2. 每层的最小整数样本量 $n$，使得乘积估计量的变异系数不超过 $c$。\n\n以有序对 $(K, n)$ 的形式给出您的最终答案。除了为 $n$ 选择整数外，无需进行其他舍入。", "solution": "目标是为多层分离模拟找到层级数 $K$ 和每层的样本数 $n$，同时满足对最终概率估计量的变异系数的约束。\n\n首先，我们推导变异系数 (CV) 的近似表达式。稀有事件概率 $p$ 的估计量是 $K$ 个层级估计量的乘积：\n$$ \\widehat{p} = \\prod_{i=1}^{K} \\widehat{p}_i $$\n每个 $\\widehat{p}_i$ 是来自 $n$ 次试验的成功经验分数，用于估计真实的条件概率 $p_0$。因此，$\\widehat{p}_i$ 服从一个缩放的二项分布。具体来说，如果 $S_i \\sim \\mathrm{Binomial}(n, p_0)$，那么 $\\widehat{p}_i = S_i/n$。其期望值为 $\\mathbb{E}[\\widehat{p}_i] = p_0$，方差为 $\\mathrm{Var}(\\widehat{p}_i) = \\frac{p_0(1-p_0)}{n}$。由于各层级间的抽样是独立的，因此对于 $i=1, \\dots, K$，估计量 $\\widehat{p}_i$ 是独立同分布的。\n\n变异系数的定义是 $\\mathrm{CV}(\\widehat{p}) = \\frac{\\sqrt{\\mathrm{Var}(\\widehat{p})}}{\\mathbb{E}[\\widehat{p}]}$。其平方为 $\\mathrm{CV}^2(\\widehat{p}) = \\frac{\\mathrm{Var}(\\widehat{p})}{(\\mathbb{E}[\\widehat{p}])^2}$。\n\n题目要求使用一阶线性化方法。最有效的方法是考虑估计量的对数。对于一个集中在其均值 $\\mu$ 附近的正随机变量 $X$，对 $\\ln(X)$ 进行一阶泰勒展开（delta 方法）可以得到近似式 $\\mathrm{Var}(\\ln(X)) \\approx \\frac{\\mathrm{Var}(X)}{\\mu^2} = \\mathrm{CV}^2(X)$。\n将此近似应用于我们的估计量 $\\widehat{p}$，我们得到：\n$$ \\mathrm{CV}^2(\\widehat{p}) \\approx \\mathrm{Var}(\\ln(\\widehat{p})) $$\n我们来计算 $\\mathrm{Var}(\\ln(\\widehat{p}))$。\n$$ \\ln(\\widehat{p}) = \\ln\\left(\\prod_{i=1}^{K} \\widehat{p}_i\\right) = \\sum_{i=1}^{K} \\ln(\\widehat{p}_i) $$\n由于 $\\widehat{p}_i$ 的独立性，和的方差等于方差的和：\n$$ \\mathrm{Var}(\\ln(\\widehat{p})) = \\sum_{i=1}^{K} \\mathrm{Var}(\\ln(\\widehat{p}_i)) $$\n由于所有层级都是相同的，$\\mathrm{Var}(\\ln(\\widehat{p}_i))$ 对所有 $i$ 都相同。我们将其记为 $\\mathrm{Var}(\\ln(\\widehat{p}_1))$。\n$$ \\mathrm{Var}(\\ln(\\widehat{p})) = K \\cdot \\mathrm{Var}(\\ln(\\widehat{p}_1)) $$\n我们再次对应用于随机变量 $\\widehat{p}_1$ 的函数 $g(x) = \\ln(x)$ 使用 delta 方法。其近似值为 $\\mathrm{Var}(g(\\widehat{p}_1)) \\approx (g'(\\mathbb{E}[\\widehat{p}_1]))^2 \\mathrm{Var}(\\widehat{p}_1)$。\n这里，$\\mathbb{E}[\\widehat{p}_1] = p_0$ 且 $g'(x) = 1/x$，所以 $g'(p_0) = 1/p_0$。\n$$ \\mathrm{Var}(\\ln(\\widehat{p}_1)) \\approx \\left(\\frac{1}{p_0}\\right)^2 \\mathrm{Var}(\\widehat{p}_1) = \\frac{1}{p_0^2} \\frac{p_0(1-p_0)}{n} = \\frac{1-p_0}{np_0} $$\n将其代回，我们得到变异系数平方的期望近似值：\n$$ \\mathrm{CV}^2(\\widehat{p}) \\approx K \\frac{1-p_0}{np_0} $$\n接下来，我们计算层级数 $K$。给定的值为 $p = 10^{-6}$ 和 $p_0 = 10^{-1}$。\n$$ K = \\left\\lceil \\frac{\\ln(p)}{\\ln(p_0)} \\right\\rceil = \\left\\lceil \\frac{\\ln(10^{-6})}{\\ln(10^{-1})} \\right\\rceil = \\left\\lceil \\frac{-6 \\ln(10)}{-1 \\ln(10)} \\right\\rceil = \\lceil 6 \\rceil = 6 $$\n所以，层级数为 $K=6$。\n\n最后，我们确定每层所需的最小整数样本量 $n$，以满足变异系数目标 $c = 3 \\times 10^{-1}$。条件是 $\\mathrm{CV}(\\widehat{p}) \\le c$，根据我们的近似，即为：\n$$ \\sqrt{K \\frac{1-p_0}{np_0}} \\le c $$\n两边平方并重新整理以解出 $n$：\n$$ K \\frac{1-p_0}{np_0} \\le c^2 \\implies n \\ge \\frac{K}{c^2} \\frac{1-p_0}{p_0} $$\n我们代入已知值：$K=6$，$p_0=10^{-1}=0.1$，以及 $c=3 \\times 10^{-1}=0.3$。\n$$ n \\ge \\frac{6}{(3 \\times 10^{-1})^2} \\frac{1 - 10^{-1}}{10^{-1}} $$\n$$ n \\ge \\frac{6}{9 \\times 10^{-2}} \\frac{0.9}{0.1} $$\n$$ n \\ge \\frac{6}{0.09} \\times 9 = \\frac{54}{0.09} = \\frac{5400}{9} = 600 $$\n不等式为 $n \\ge 600$。因此，$n$ 的最小整数值为 $600$。\n\n所需的量是层级数 $K=6$ 和每层的最小样本数 $n=600$。结果为有序对 $(K, n)$。", "answer": "$$ \\boxed{\\begin{pmatrix} 6  600 \\end{pmatrix}} $$", "id": "3346498"}, {"introduction": "分裂方法，特别是其自适应变体，通常依赖于一个被演化和重采样的“粒子”群体。一个常见的实际挑战是“粒子群退化”，即少数粒子主导了估计值，导致模拟效率低下。本练习介绍了一个关键的诊断工具——有效样本量（ESS），用以量化此问题，并指导您应用一个有原则的准则，来决定何时执行“重采样”步骤以维持模拟的健康和效率 [@problem_id:3346519]。", "problem": "考虑一个用于稀有事件估计的自适应水平分裂方案，其中使用一系列中间阈值水平 $\\{b_{\\ell}\\}_{\\ell=0}^{L}$ 来引导粒子朝向失效集。在水平 $\\ell$，假设我们有 $N$ 个粒子，其位置为 $\\{X_{i}^{(\\ell)}\\}_{i=1}^{N}$，这些粒子是通过一个保持水平 $\\ell$ 目标条件分布的马尔可夫核从水平 $\\ell-1$ 传播而来的。跨水平的增量重要性权重由目标密度与提议密度之比定义（相差一个共同的归一化常数），并用于校正粒子群，以近似水平 $\\ell$ 的条件分布。\n\n目标是确定粒子群的退化程度是否严重到足以在水平 $\\ell$ 进行重采样的地步。一种有原则的方法是，使用源于自归一化重要性抽样估计量方差的有效样本量（ESS）概念来衡量归一化权重的集中程度，并根据 ESS 相对于 $N$ 的阈值来触发重采样。\n\n在特定的水平 $\\ell$，给定 $N=10$ 个粒子的未归一化增量重要性权重如下列表所示：\n$$\n\\{r_{i}\\}_{i=1}^{10} = \\left\\{2,\\ 1,\\ \\frac{1}{2},\\ \\frac{1}{2},\\ \\frac{1}{5},\\ \\frac{1}{5},\\ \\frac{1}{5},\\ \\frac{1}{10},\\ \\frac{1}{10},\\ \\frac{1}{10}\\right\\}.\n$$\n从第一性原理出发，以自归一化重要性权重及相应估计量方差的定义为起点，推导水平 $\\ell$ 的有效样本量（ESS）关于归一化权重的表达式，为给定的 $\\{r_{i}\\}$ 计算 ESS 的数值，然后计算归一化 ESS 分数 $\\mathrm{ESS}/N$。\n\n利用权重集中度、估计量方差和粒子群退化之间的关系，阐述一个基于归一化 ESS 分数的有原则的重采样准则，并讨论如果在水平 $\\ell$ 使用目标阈值 $\\tau=0.6$ 是否会触发重采样。\n\n将您的最终答案表示为归一化 ESS 分数 $\\mathrm{ESS}/N$ 的单个值，四舍五入到四位有效数字。不需要单位。", "solution": "该问题要求我们从与自归一化重要性抽样相关的第一性原理出发，推导有效样本量（ESS）的表达式，为给定的一组权重计算其值，并用它来决定是否执行重采样。\n\n首先，我们推导 ESS 的表达式。在重要性抽样中，我们的目标是使用从提议分布 $q(x)$ 中抽取的样本 $\\{X_i\\}_{i=1}^{N}$ 来估计期望 $\\mathbb{E}_{\\pi}[\\phi(X)]$。期望的自归一化重要性抽样估计量由下式给出：\n$$\n\\hat{\\mu}_{SN} = \\frac{\\sum_{i=1}^{N} r_i \\phi(X_i)}{\\sum_{j=1}^{N} r_j} = \\sum_{i=1}^{N} w_i \\phi(X_i)\n$$\n其中 $r_i$ 是未归一化的重要性权重 $r(X_i) \\propto \\pi(X_i)/q(X_i)$，而 $w_i$ 是归一化的重要性权重：\n$$\nw_i = \\frac{r_i}{\\sum_{j=1}^{N} r_j}\n$$\n该估计量的方差决定了其质量。重要性抽样理论中的一个关键结果，通过对该比率估计量进行一阶 Taylor 级数展开（delta 方法）推导得出，给出了 $\\hat{\\mu}_{SN}$ 的近似方差：\n$$\n\\mathrm{Var}(\\hat{\\mu}_{SN}) \\approx \\frac{\\mathrm{Var}_{\\pi}(\\phi(X))}{N} \\left(1 + \\mathrm{CV}_q^2(r)\\right)\n$$\n其中 $\\mathrm{Var}_{\\pi}(\\phi(X))$ 是在目标分布 $\\pi$ 下 $\\phi(X)$ 的方差，而 $\\mathrm{CV}_q^2(r)$ 是权重的变异系数的平方，定义为 $\\mathrm{CV}_q^2(r) = \\mathrm{Var}_q(r) / (\\mathbb{E}_q[r])^2$。\n\n有效样本量（ESS）的概念源于将重要性抽样估计量的方差与一个理想的蒙特卡洛估计量的方差进行比较，后者使用直接从目标分布 $\\pi$ 中抽取的 $\\mathrm{ESS}$ 个独立样本。这样一个理想估计量的方差将是：\n$$\n\\mathrm{Var}(\\hat{\\mu}_{ideal}) = \\frac{\\mathrm{Var}_{\\pi}(\\phi(X))}{\\mathrm{ESS}}\n$$\n通过令方差相等，$\\mathrm{Var}(\\hat{\\mu}_{ideal}) \\approx \\mathrm{Var}(\\hat{\\mu}_{SN})$，我们可以解出 ESS：\n$$\n\\frac{\\mathrm{Var}_{\\pi}(\\phi(X))}{\\mathrm{ESS}} = \\frac{\\mathrm{Var}_{\\pi}(\\phi(X))}{N} \\left(1 + \\mathrm{CV}_q^2(r)\\right) \\implies \\mathrm{ESS} = \\frac{N}{1 + \\mathrm{CV}_q^2(r)}\n$$\n为了使用这个公式，我们需要从我们的权重样本 $\\{r_i\\}_{i=1}^{N}$ 中估计 $\\mathrm{CV}_q^2(r)$。一个相合估计量是：\n$$\n\\widehat{\\mathrm{CV}^2(r)} = \\frac{\\widehat{\\mathrm{Var}}_q(r)}{(\\hat{\\mathbb{E}}_q[r])^2} \\approx \\frac{\\frac{1}{N}\\sum_{i=1}^N (r_i - \\bar{r})^2}{\\bar{r}^2}\n$$\n其中 $\\bar{r} = \\frac{1}{N}\\sum_{i=1}^N r_i$。这可以简化为：\n$$\n\\widehat{\\mathrm{CV}^2(r)} = \\frac{\\frac{1}{N}(\\sum r_i^2 - N\\bar{r}^2)}{\\bar{r}^2} = \\frac{\\frac{1}{N}(\\sum r_i^2) - (\\frac{1}{N}\\sum r_i)^2}{(\\frac{1}{N}\\sum r_i)^2} = \\frac{N\\sum r_i^2 - (\\sum r_i)^2}{(\\sum r_i)^2} = N \\frac{\\sum r_i^2}{(\\sum r_i)^2} - 1\n$$\n将这个估计值代回 ESS 的表达式中，得到：\n$$\n\\mathrm{ESS} \\approx \\frac{N}{1 + \\left(N \\frac{\\sum r_i^2}{(\\sum r_i)^2} - 1\\right)} = \\frac{N}{N \\frac{\\sum r_i^2}{(\\sum r_i)^2}} = \\frac{(\\sum r_i)^2}{\\sum r_i^2}\n$$\n这个表达式可以用归一化权重 $w_i = r_i / \\sum_j r_j$ 来表示：\n$$\n\\mathrm{ESS} = \\frac{(\\sum r_i)^2}{\\sum r_i^2} = \\frac{1}{\\frac{\\sum r_i^2}{(\\sum r_i)^2}} = \\frac{1}{\\sum_i \\left(\\frac{r_i}{\\sum_j r_j}\\right)^2} = \\frac{1}{\\sum_{i=1}^{N} w_i^2}\n$$\n这就是从自归一化估计量的方差推导出的有效样本量的期望表达式。\n\n接下来，我们为给定的数据计算 ESS 的数值。我们有 $N=10$ 个粒子，其未归一化的增量权重为：\n$$\n\\{r_{i}\\}_{i=1}^{10} = \\left\\{2,\\ 1,\\ \\frac{1}{2},\\ \\frac{1}{2},\\ \\frac{1}{5},\\ \\frac{1}{5},\\ \\frac{1}{5},\\ \\frac{1}{10},\\ \\frac{1}{10},\\ \\frac{1}{10}\\right\\}\n$$\n首先，我们计算权重的总和：\n$$\n\\sum_{i=1}^{10} r_i = 2 + 1 + 2\\left(\\frac{1}{2}\\right) + 3\\left(\\frac{1}{5}\\right) + 3\\left(\\frac{1}{10}\\right) = 3 + 1 + \\frac{3}{5} + \\frac{3}{10} = 4 + \\frac{6}{10} + \\frac{3}{10} = 4 + \\frac{9}{10} = \\frac{49}{10} = 4.9\n$$\n接下来，我们计算权重的平方和：\n$$\n\\sum_{i=1}^{10} r_i^2 = 2^2 + 1^2 + 2\\left(\\frac{1}{2}\\right)^2 + 3\\left(\\frac{1}{5}\\right)^2 + 3\\left(\\frac{1}{10}\\right)^2\n$$\n$$\n\\sum_{i=1}^{10} r_i^2 = 4 + 1 + 2\\left(\\frac{1}{4}\\right) + 3\\left(\\frac{1}{25}\\right) + 3\\left(\\frac{1}{100}\\right) = 5 + \\frac{1}{2} + \\frac{3}{25} + \\frac{3}{100}\n$$\n$$\n\\sum_{i=1}^{10} r_i^2 = 5 + \\frac{50}{100} + \\frac{12}{100} + \\frac{3}{100} = 5 + \\frac{65}{100} = 5.65\n$$\n现在我们可以计算 ESS：\n$$\n\\mathrm{ESS} = \\frac{(\\sum r_i)^2}{\\sum r_i^2} = \\frac{(4.9)^2}{5.65} = \\frac{24.01}{5.65} = \\frac{2401}{565} \\approx 4.2495575\n$$\n问题要求的是归一化 ESS 分数，$\\mathrm{ESS}/N$：\n$$\n\\frac{\\mathrm{ESS}}{N} = \\frac{1}{10} \\left(\\frac{2401}{565}\\right) = \\frac{2401}{5650} \\approx 0.42495575\n$$\n四舍五入到四位有效数字，我们得到 $0.4250$。\n\n最后，我们阐述一个有原则的重采样准则并应用它。ESS 衡量了加权粒子集所代表的等效独立样本数量。$\\mathrm{ESS} \\approx N$ 的值表示一个权重均匀的健康粒子群，而 $\\mathrm{ESS} \\ll N$ 则预示着“粒子群退化”或“样本贫化”，即少数粒子具有非常高的权重并主导了估计，使得其他粒子变得无效。归一化 ESS 分数 $\\mathrm{ESS}/N$ 的范围从 $1/N$（最差情况）到 $1$（最佳情况），是衡量退化程度的标准度量。\n\n一个有原则的重采样准则是，每当该分数低于预定义阈值 $\\tau$ 时，就触发重采样步骤。准则是：**如果 $\\mathrm{ESS}/N  \\tau$，则进行重采样**。重采样会丢弃权重低的粒子，并复制权重高的粒子，通过将下一阶段的权重重置为均匀分布来有效地“恢复”粒子群的活力。\n\n在这个问题中，目标阈值给定为 $\\tau=0.6$。我们比较计算出的值：\n$$\n\\frac{\\mathrm{ESS}}{N} \\approx 0.4250\n$$\n由于 $0.4250  0.6$，条件得到满足。因此，在水平 $\\ell$ 会触发重采样。这表明权重的集中程度已经足够严重，有效粒子数已降至名义粒子群大小的约 $42.5\\%$，这为维持模拟的效率和稳定性而执行重采样步骤提供了理由。", "answer": "$$\\boxed{0.4250}$$", "id": "3346519"}, {"introduction": "将分裂方法应用于现实世界的物理或金融系统，通常意味着处理连续时间模型，例如随机微分方程（SDE）。这个高级编程练习将挑战您为一个SDE实现分裂算法，通过使用路径似然比校正来解决模拟偏差的关键问题。您还将探索如何利用布朗桥条件化等技术进一步减少误差，从而弥合离散时间模拟与连续时间现实之间的差距 [@problem_id:3346543]。", "problem": "考虑由Itô动力学定义的一维Ornstein–Uhlenbeck随机微分方程 (SDE)\n$$\n\\mathrm{d}X_t = -\\kappa X_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t,\\quad X_0 = x_0,\n$$\n其中 $W_t$ 是标准布朗运动，$\\kappa  0$ 是均值回归率，$\\sigma  0$ 是扩散系数。设 $T  0$ 为一个固定的时间范围， $b  0$ 为一个固定的壁垒。我们感兴趣的稀有事件是触碰壁垒事件\n$$\nA = \\left\\{ \\sup_{0 \\le t \\le T} X_t \\ge b \\right\\}.\n$$\n\n你将使用分裂法（splitting method）和固定的中间水平，在真实的连续时间SDE下估计概率 $\\mathbb{P}(A)$，并采用路径似然比校正（pathwise likelihood ratio correction）来解释由Euler–Maruyama提议引入的时间离散化偏差。此外，你还将此方法与一个使用布朗桥条件化（Brownian bridge conditioning）的变体进行比较，以减少最终壁垒穿越检测中的时间离散化误差。\n\n基本原理：\n- Ornstein–Uhlenbeck过程在时间步长 $\\Delta t$ 上的精确离散时间转移是高斯的：\n$$\nX_{t+\\Delta t} \\mid X_t = x \\sim \\mathcal{N}\\left( x e^{-\\kappa \\Delta t}, \\; \\frac{\\sigma^2}{2\\kappa}\\left(1 - e^{-2\\kappa \\Delta t}\\right) \\right).\n$$\n- 对于相同的SDE，步长为 $\\Delta t$ 的Euler–Maruyama提议产生：\n$$\n\\tilde{X}_{t+\\Delta t} \\mid \\tilde{X}_t = x \\sim \\mathcal{N}\\left( x - \\kappa x \\,\\Delta t, \\; \\sigma^2 \\Delta t \\right).\n$$\n- 在Euler提议下进行模拟，同时以真实的Ornstein–Uhlenbeck转移为目标时，用于校正的每步路径似然比（Radon–Nikodym导数）由相应的高斯密度之比给出：\n$$\nL(x \\to y; \\Delta t) = \\frac{\\phi\\left(y; \\, x e^{-\\kappa \\Delta t}, \\, \\frac{\\sigma^2}{2\\kappa}\\left(1 - e^{-2\\kappa \\Delta t}\\right) \\right)}{\\phi\\left(y; \\, x - \\kappa x \\Delta t, \\, \\sigma^2 \\Delta t \\right)},\n$$\n其中 $\\phi(\\cdot;\\,m,v)$ 表示均值为 $m$、方差为 $v$ 的高斯概率密度函数。\n- 对于一个时间步内的布朗桥，在给定端点 $x$ 和 $y$ 的条件下，当两个端点都满足 $x  \\ell$ 和 $y  \\ell$ 时，连续路径在该步内穿越水平 $\\ell$ 的概率由反射原理公式给出：\n$$\np_{\\mathrm{BB}}(x,y;\\ell,\\Delta t) = \\exp\\left( -\\frac{2(\\ell - x)(\\ell - y)}{\\sigma^2 \\Delta t} \\right).\n$$\n如果 $\\max(x,y) \\ge \\ell$，则该步内的穿越概率为 $1$。对于具有加性噪声的Ornstein–Uhlenbeck过程，给定端点的路径片段的条件定律是一个具有相同方差缩放的布朗桥，这使得该公式适用于步内穿越检测。\n\n分裂设计：\n- 使用一组固定的严格递增的中间水平 $\\ell_1  \\ell_2  \\cdots  \\ell_{m-1}  \\ell_m = b$ 和一个均匀的时间网格 $t_n = n\\,\\Delta t$，$n = 0,1,\\dots,\\lfloor T/\\Delta t \\rfloor$。\n- 在状态 $x_0$ 和时间索引 $n=0$ 处初始化 $N$ 个独立副本，每个副本携带一个初始对数权重 $w^{(0)} = 0$。\n- 对于阶段 $k = 1,2,\\dots,m$：\n  1. 对于每个副本，在Euler–Maruyama提议下向前模拟，直到离散时间状态 $X_{t_n}$ 首次满足 $X_{t_n} \\ge \\ell_k$（命中），或达到时间范围 $T$（未命中）。在每一步中通过对 $\\log L(x \\to y;\\Delta t)$ 求和来累积片段对数似然比。对于阶段 $k  m$，仅使用离散时间网格状态来检测命中。对于最终阶段 $k = m$，实现两种检测变体：\n     - 无布朗桥的变体（仅网格）：当离散时间状态超过 $b$ 时检测命中。\n     - 有布朗桥的变体：在每一步，如果两个端点都低于 $b$，则通过抛掷一个成功概率为 $p_{\\mathrm{BB}}(x,y;b,\\Delta t)$ 的伯努利随机变量来进行步内穿越检测；成功表示在该步内连续时间内发生了命中。\n  2. 设 $H_k$ 表示在此阶段命中水平 $\\ell_k$ 的副本集合。计算阶段 $k$ 的加权条件概率估计量，\n     $$\n     \\hat{p}_k = \\frac{\\sum_{i=1}^{N} \\exp\\left(w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}}\\right) \\,\\mathbf{1}\\{i \\in H_k\\}}{\\sum_{i=1}^{N} \\exp\\left(w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}}\\right)},\n     $$\n     其中 $w_i^{\\mathrm{parent}}$ 是副本 $i$ 从前几个阶段带入阶段 $k$ 的累积对数权重，$w_i^{\\mathrm{seg}}$ 是在阶段 $k$ 期间累积的片段对数权重。\n  3. 如果 $H_k$ 为空，则将剩余的条件概率乘积设为 $0$ 并终止。否则，通过从 $H_k$ 中有放回地抽取，以与 $\\exp\\left(w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}}\\right)$ 成正比的概率，为下一阶段重采样 $N$ 个副本，并将每个重采样副本的新父对数权重设置为 $w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}}$，其状态设置为命中时的状态，其时间索引设置为命中时的时间索引。\n- $\\mathbb{P}(A)$ 的分裂估计量是乘积 $\\prod_{k=1}^{m} \\hat{p}_k$。\n\n任务：\n- 实现带有每阶段路径似然比加权的分裂估计量：\n  - 估计量 $E_{\\mathrm{LR,grid}}$：在所有阶段，包括最终壁垒阶段 $k=m$，都使用离散时间网格检测。\n  - 估计量 $E_{\\mathrm{LR,BB}}$：使用相同的分裂过程，但在最终壁垒阶段 $k=m$ 时，使用布朗桥条件化进行步内壁垒穿越检测。\n- 为了似然比求和的数值稳定性，使用log-sum-exp计算。\n\n你的程序必须为以下每个测试用例计算估计量 $E_{\\mathrm{LR,grid}}$ 和 $E_{\\mathrm{LR,BB}}$。所有数学常数和参数必须严格按照指定处理。\n\n测试套件：\n- 用例 1：$\\kappa = 1.5$, $\\sigma = 0.6$, $x_0 = 0.0$, $T = 1.0$, $\\Delta t = 0.01$, 水平 $\\ell = [0.6, 1.2, 1.5, 1.8]$, $N = 800$。\n- 用例 2：$\\kappa = 1.5$, $\\sigma = 0.6$, $x_0 = 0.0$, $T = 1.0$, $\\Delta t = 0.05$, 水平 $\\ell = [0.6, 1.2, 1.5, 1.8]$, $N = 1000$。\n- 用例 3：$\\kappa = 2.5$, $\\sigma = 0.5$, $x_0 = 0.0$, $T = 1.5$, $\\Delta t = 0.02$, 水平 $\\ell = [0.7, 1.3, 1.8, 2.2]$, $N = 1000$。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含测试套件的结果，形式为列表的列表，其中每个内部列表是相应案例的 $\\left[E_{\\mathrm{LR,grid}}, E_{\\mathrm{LR,BB}}\\right]$，顺序与上面列出的案例顺序一致。例如，打印如下形式的单行：\n$$\n\\left[ [a_1, b_1], [a_2, b_2], [a_3, b_3] \\right]\n$$\n其中 $a_i$ 和 $b_i$ 为数值浮点数。", "solution": "我们的目标是在真实的连续时间动力学下估计Ornstein–Uhlenbeck过程的稀有事件概率 $\\mathbb{P}(A)$，而模拟则由Euler–Maruyama提议驱动。该估计框架使用跨越一系列水平的分裂法、用于校正离散时间转移中提议-目标不匹配的路径似然比，以及一个在最后阶段通过布朗桥条件化来减少时间离散化误差的选项。\n\n原理和推导：\n\n1. 转移核与似然比：\n   Ornstein–Uhlenbeck过程在一个步长 $\\Delta t$ 内具有已知的精确离散时间转移：\n   $$\n   X_{t+\\Delta t} \\mid X_t = x \\sim \\mathcal{N}\\left( \\mu_{\\mathrm{OU}}(x), \\, v_{\\mathrm{OU}} \\right),\n   $$\n   其中 $\\mu_{\\mathrm{OU}}(x) = x e^{-\\kappa \\Delta t}$ 且 $v_{\\mathrm{OU}} = \\frac{\\sigma^2}{2\\kappa}\\left(1 - e^{-2\\kappa \\Delta t}\\right)$。Euler–Maruyama提议产生\n   $$\n   \\tilde{X}_{t+\\Delta t} \\mid \\tilde{X}_t = x \\sim \\mathcal{N}\\left( \\mu_{\\mathrm{EM}}(x), \\, v_{\\mathrm{EM}} \\right),\n   $$\n   其中 $\\mu_{\\mathrm{EM}}(x) = x - \\kappa x \\Delta t$ 且 $v_{\\mathrm{EM}} = \\sigma^2 \\Delta t$。当在提议下逐步模拟时，按步离散化的路径Radon–Nikodym导数是每步似然比的乘积\n   $$\n   L(x \\to y; \\Delta t) = \\frac{\\phi\\left(y; \\mu_{\\mathrm{OU}}(x), v_{\\mathrm{OU}} \\right)}{\\phi\\left(y; \\mu_{\\mathrm{EM}}(x), v_{\\mathrm{EM}} \\right)}.\n   $$\n   在一个状态为 $\\{x_0, x_1, \\dots, x_n\\}$ 的片段上累积，得到片段权重 $W = \\prod_{j=0}^{n-1} L(x_j \\to x_{j+1}; \\Delta t)$，或等价地，为保证数值稳定性，使用片段对数权重 $w = \\sum_{j=0}^{n-1} \\log L(x_j \\to x_{j+1}; \\Delta t)$。\n\n2. 分裂估计量：\n   考虑一个固定的层级 $\\ell_1  \\ell_2  \\cdots  \\ell_m = b$。在阶段 $k$，副本从已达到 $\\ell_{k-1}$ 的状态开始，并尝试在时间范围结束前达到 $\\ell_k$。设 $w_i^{\\mathrm{parent}}$ 是截至此阶段开始时累积的对数权重，$w_i^{\\mathrm{seg}}$ 是额外的片段对数权重。该阶段的加权条件概率估计量为\n   $$\n   \\hat{p}_k = \\frac{\\sum_{i=1}^{N} \\exp(w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}})\\,\\mathbf{1}\\{i \\in H_k\\}}{\\sum_{i=1}^{N} \\exp(w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}})},\n   $$\n   这是在真实动力学下 $\\mathbb{P}(\\text{命中 } \\ell_k \\mid \\text{从 } \\ell_{k-1} \\text{开始})$ 的重要性抽样估计，其中使用了由提议生成并通过路径似然比校正的样本。总体的分裂估计量是\n   $$\n   \\widehat{\\mathbb{P}}(A) = \\prod_{k=1}^{m} \\hat{p}_k.\n   $$\n   计算完 $\\hat{p}_k$ 后，我们从命中者 $H_k$ 中为下一阶段重采样 $N$ 个副本，其概率与 $\\exp(w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}})$ 成正比。这种重采样将经验分布推向更接近于命中 $\\ell_k$ 的目标条件分布（在真实动力学下）。\n\n3. 用于时间离散化的布朗桥条件化：\n   离散时间网格检测会低估壁垒穿越概率，因为穿越可能发生在时间步之间。对于加性噪声扩散过程，给定端点 $x$ 和 $y$ 的路径片段的条件定律是一个布朗桥。在给定两个端点都低于 $\\ell$ 的情况下，一个布朗桥在一步长 $\\Delta t$ 内穿越水平 $\\ell$ 的概率是\n   $$\n   p_{\\mathrm{BB}}(x,y;\\ell,\\Delta t) = \\exp\\left( -\\frac{2(\\ell - x)(\\ell - y)}{\\sigma^2 \\Delta t} \\right).\n   $$\n   对于最终壁垒阶段 $k=m$，我们引入布朗桥：在每一步，如果网格端点 $x$ 和 $y$ 都位于 $b$ 以下，我们抛掷一个成功概率为 $p_{\\mathrm{BB}}(x,y;b,\\Delta t)$ 的伯努利随机变量；成功表示在步内发生了连续时间穿越。如果任一端点超过 $b$，我们确定性地宣布命中。这在最后阶段的检测中减少了时间离散化误差，同时保留了对模拟提议转移的路径似然比校正。\n\n4. 数值稳定性与实现细节：\n   - 在对数空间中计算片段权重以避免下溢：\n     $$\n     w_i^{\\mathrm{seg}} = \\sum \\left[ \\log \\phi\\left(y; \\mu_{\\mathrm{OU}}(x), v_{\\mathrm{OU}}\\right) - \\log \\phi\\left(y; \\mu_{\\mathrm{EM}}(x), v_{\\mathrm{EM}}\\right) \\right].\n     $$\n   - 对于阶段加权概率 $\\hat{p}_k$，使用log-sum-exp技巧：\n     $$\n     \\hat{p}_k = \\frac{\\sum_{i} \\exp(\\ell_i)\\,\\mathbf{1}\\{i \\in H_k\\}}{\\sum_{i} \\exp(\\ell_i)} = \\frac{\\sum_{i} \\exp(\\ell_i - M)\\,\\mathbf{1}\\{i \\in H_k\\}}{\\sum_{i} \\exp(\\ell_i - M)},\n     $$\n     其中 $\\ell_i = w_i^{\\mathrm{parent}} + w_i^{\\mathrm{seg}}$ 且 $M = \\max_i \\ell_i$。\n   - 以与 $\\exp(\\ell_i)$ 成正比的概率重采样 $N$ 个命中者，并将新的父对数权重 $w_i^{\\mathrm{parent}} \\gets \\ell_i$ 以及命中状态和时间索引作为下一水平阶段的起始点。\n\n5. 估计量的比较：\n   - $E_{\\mathrm{LR,grid}}$ 在所有阶段 $k=1,\\dots,m$ 都使用离散网格检测。\n   - $E_{\\mathrm{LR,BB}}$ 使用相同的分裂和似然比方案，但将最终阶段的检测替换为布朗桥条件化。因为在最后阶段正确处理了步内穿越概率，$E_{\\mathrm{LR,BB}}$ 相对于 $E_{\\mathrm{LR,grid}}$ 减少了时间离散化误差，特别是对于较粗的 $\\Delta t$。\n\n每个测试用例的算法步骤：\n- 使用固定种子初始化随机数生成器以保证可复现性。\n- 对于每个用例，使用对数权重和跨水平 $\\ell_1,\\dots,\\ell_m$ 的重采样运行分裂法两次：\n  - 一次在所有水平上都使用仅网格检测，以获得 $E_{\\mathrm{LR,grid}}$。\n  - 一次在最终水平上使用布朗桥检测，以获得 $E_{\\mathrm{LR,BB}}$。\n- 将结果汇总为指定的单行列表的列表格式。\n\n测试套件中的差异旨在揭示：\n- 一个具有相对精细 $\\Delta t$（$\\Delta t = 0.01$）的“理想路径”情况，此时两个估计量应该很接近。\n- 一个粗糙的 $\\Delta t$（$\\Delta t = 0.05$），此时预计布朗桥校正会比仅网格检测增加估计的命中概率。\n- 一个更强均值回归（$\\kappa = 2.5$）且 $\\Delta t$ 中等（$\\Delta t = 0.02$）的情况，此时稀有事件的性质更显著，带有似然比校正的分裂法对于稳定估计至关重要。\n\n所有输出都是没有物理单位的浮点数，且不涉及角度。最终输出是一个列表的列表，每个列表包含每个用例的两个浮点数 $\\left[E_{\\mathrm{LR,grid}}, E_{\\mathrm{LR,BB}}\\right]$，打印为单行。", "answer": "```python\nimport numpy as np\n\n# Fixed RNG for reproducibility\nrng = np.random.default_rng(123456789)\n\ndef normal_log_pdf(y, mean, var):\n    # Numerically stable log pdf for Gaussian\n    return -0.5 * (np.log(2.0 * np.pi * var) + ((y - mean) ** 2) / var)\n\ndef ou_true_params(x, kappa, sigma, dt):\n    mean_true = x * np.exp(-kappa * dt)\n    var_true = (sigma * sigma) / (2.0 * kappa) * (1.0 - np.exp(-2.0 * kappa * dt))\n    # Guard against numerical zero variance\n    var_true = max(var_true, 1e-16)\n    return mean_true, var_true\n\ndef euler_params(x, kappa, sigma, dt):\n    mean_euler = x * (1.0 - kappa * dt)\n    var_euler = sigma * sigma * dt\n    var_euler = max(var_euler, 1e-16)\n    return mean_euler, var_euler\n\ndef brownian_bridge_cross_prob(x, y, level, sigma, dt):\n    # If either endpoint is already above level, crossing is certain\n    if x = level or y = level:\n        return 1.0\n    # Both endpoints below: use reflection principle for Brownian bridge\n    return np.exp(-2.0 * (level - x) * (level - y) / (sigma * sigma * dt))\n\nclass Replica:\n    __slots__ = (\"x\", \"idx\", \"logw\")\n    def __init__(self, x, idx, logw):\n        self.x = x\n        self.idx = idx\n        self.logw = logw\n\ndef simulate_stage_segment(replica, level, T, dt, kappa, sigma, use_bb=False, is_final_stage=False):\n    \"\"\"\n    Simulate one replica forward from its current state/time until it hits the given level\n    or reaches time T. Accumulate the segment log-weight via pathwise likelihood ratios.\n    Detection:\n      - For non-final stages: grid-based detection only.\n      - For final stage: if use_bb=True, apply Brownian bridge within-step crossing detection.\n    Returns:\n      hit (bool), new_x (float), new_idx (int), seg_logw (float)\n    If hit=True, new_x/new_idx represent the discrete-time hit state/index used to seed next stage.\n    \"\"\"\n    x = replica.x\n    idx = replica.idx\n    n_steps = int(np.floor(T / dt))\n    seg_logw = 0.0\n\n    # If starting already above level (unlikely in splitting), treat as immediate hit\n    if x = level:\n        return True, x, idx, seg_logw\n\n    while idx  n_steps:\n        # Propose next step via Euler\n        mean_e, var_e = euler_params(x, kappa, sigma, dt)\n        y = mean_e + np.sqrt(var_e) * rng.standard_normal()\n        # Compute per-step log-likelihood ratio\n        mean_t, var_t = ou_true_params(x, kappa, sigma, dt)\n        seg_logw += normal_log_pdf(y, mean_t, var_t) - normal_log_pdf(y, mean_e, var_e)\n\n        # Detection\n        if not is_final_stage or not use_bb:\n            # Grid-only detection\n            if y = level:\n                # Hit at discrete time\n                return True, y, idx + 1, seg_logw\n        else:\n            # Final stage with Brownian bridge detection\n            if x = level or y = level:\n                return True, y, idx + 1, seg_logw\n            # Both endpoints below: stochastic within-step hit\n            p_hit = brownian_bridge_cross_prob(x, y, level, sigma, dt)\n            u = rng.random()\n            if u  p_hit:\n                # Hit occurred within the step; we do not know precise crossing point,\n                # but for final stage we only need to record hit. Use y and idx+1 as placeholder.\n                return True, y, idx + 1, seg_logw\n\n        # Move forward\n        x = y\n        idx += 1\n\n    # Reached time horizon without hitting\n    return False, x, idx, seg_logw\n\ndef logsumexp(log_values):\n    if len(log_values) == 0:\n        return -np.inf\n    m = np.max(log_values)\n    return m + np.log(np.sum(np.exp(log_values - m)))\n\ndef splitting_estimate(kappa, sigma, x0, T, dt, levels, N, use_bb_final):\n    \"\"\"\n    Perform splitting across fixed levels with pathwise likelihood ratio correction.\n    Returns the product of weighted conditional probability estimates across stages.\n    If use_bb_final=True, apply Brownian bridge detection only at the final barrier level.\n    \"\"\"\n    # Initialize replicas at x0, time 0, logw=0\n    replicas = [Replica(x0, 0, 0.0) for _ in range(N)]\n    est = 1.0\n\n    m = len(levels)\n    for k in range(m):\n        level = levels[k]\n        # Simulate each replica's segment to reach current level\n        hit_logLs = []\n        hit_states = []\n        hit_indices = []\n        all_logLs = []\n\n        for rep in replicas:\n            is_final = (k == m - 1)\n            hit, new_x, new_idx, seg_logw = simulate_stage_segment(rep, level, T, dt, kappa, sigma,\n                                                                   use_bb=use_bb_final, is_final_stage=is_final)\n            total_logw = rep.logw + seg_logw\n            all_logLs.append(total_logw)\n            if hit:\n                hit_logLs.append(total_logw)\n                hit_states.append(new_x)\n                hit_indices.append(new_idx)\n\n        # Compute weighted conditional probability for this stage via log-sum-exp\n        if len(hit_logLs) == 0:\n            est *= 0.0\n            break\n\n        denom_log = logsumexp(np.array(all_logLs))\n        numer_log = logsumexp(np.array(hit_logLs))\n        p_k = np.exp(numer_log - denom_log)\n        est *= p_k\n\n        # Resample N replicas from hitters with weights proportional to exp(total_logw)\n        # Normalize weights stably\n        hit_logLs_arr = np.array(hit_logLs)\n        w_max = np.max(hit_logLs_arr)\n        weights = np.exp(hit_logLs_arr - w_max)\n        probs = weights / np.sum(weights)\n        # Multinomial resampling indices\n        resample_idx = rng.choice(len(hit_states), size=N, replace=True, p=probs)\n\n        # Prepare replicas for next stage; carry forward parent log-weight and hit state/index\n        new_replicas = []\n        for j in resample_idx:\n            r = Replica(hit_states[j], hit_indices[j], hit_logLs[j])\n            new_replicas.append(r)\n        replicas = new_replicas\n\n    return est\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"kappa\": 1.5, \"sigma\": 0.6, \"x0\": 0.0, \"T\": 1.0, \"dt\": 0.01,\n            \"levels\": [0.6, 1.2, 1.5, 1.8], \"N\": 800\n        },\n        # Case 2\n        {\n            \"kappa\": 1.5, \"sigma\": 0.6, \"x0\": 0.0, \"T\": 1.0, \"dt\": 0.05,\n            \"levels\": [0.6, 1.2, 1.5, 1.8], \"N\": 1000\n        },\n        # Case 3\n        {\n            \"kappa\": 2.5, \"sigma\": 0.5, \"x0\": 0.0, \"T\": 1.5, \"dt\": 0.02,\n            \"levels\": [0.7, 1.3, 1.8, 2.2], \"N\": 1000\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        kappa = case[\"kappa\"]\n        sigma = case[\"sigma\"]\n        x0 = case[\"x0\"]\n        T = case[\"T\"]\n        dt = case[\"dt\"]\n        levels = case[\"levels\"]\n        N = case[\"N\"]\n\n        # Estimator with LR and grid-only detection (all stages)\n        est_grid = splitting_estimate(kappa, sigma, x0, T, dt, levels, N, use_bb_final=False)\n        # Estimator with LR and Brownian bridge detection at final barrier\n        est_bb = splitting_estimate(kappa, sigma, x0, T, dt, levels, N, use_bb_final=True)\n\n        results.append([est_grid, est_bb])\n\n    # Final print statement in the exact required format.\n    # Single line containing list of lists of floats.\n    def format_list(lst):\n        # Ensure standard Python list formatting without extra spaces\n        return \"[\" + \",\".join(str(x) if not isinstance(x, list) else format_list(x) for x in lst) + \"]\"\n    print(format_list(results))\n\nsolve()\n```", "id": "3346543"}]}