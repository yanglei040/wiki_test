{"hands_on_practices": [{"introduction": "在多项式混沌展开 (PCE) 中，核心任务是计算展开系数，这构成了我们近似模型的基石。这些系数通过将目标函数投影到正交多项式基上获得，其计算本质上是一个积分问题。本练习 [@problem_id:3330111] 旨在通过一个具体示例，将系数的理论定义与高斯求积这一强大的数值计算工具联系起来，这是非侵入式 PCE 方法的核心。", "problem": "考虑单个随机输入 $X \\sim \\text{Uniform}([-1,1])$ 以及关注的标量 $u(x) = x^{3}$。设 $\\{P_{n}(x)\\}_{n \\ge 0}$ 表示 $[-1,1]$ 上的经典勒让德多项式，其特征是正交关系 $\\int_{-1}^{1} P_{m}(x) P_{n}(x) \\, dx = \\frac{2}{2n+1} \\delta_{mn}$，其中 $\\delta_{mn}$ 是克罗内克 δ。定义勒让德-混沌基 $\\{\\psi_{n}(x)\\}_{n \\ge 0}$ 关于 $X$ 的概率测度是标准正交的，即内积为 $\\langle f, g \\rangle := \\mathbb{E}[f(X) g(X)] = \\int_{-1}^{1} \\frac{1}{2} f(x) g(x) \\, dx$，使得 $\\mathbb{E}[\\psi_{m}(X)\\psi_{n}(X)] = \\delta_{mn}$。考虑 $u(X)$ 在此基下的多项式混沌展开 $u(X) = \\sum_{n=0}^{\\infty} c_{n} \\psi_{n}(X)$，其中 $c_{n} = \\mathbb{E}[u(X)\\psi_{n}(X)]$。\n\n1. 仅使用勒让德多项式的定义正交性质和 $\\{\\psi_{n}\\}$ 关于 $X$ 分布的标准正交化，推导 $u(X)$ 展开式中系数 $c_{3}$ 的精确闭式表达式。\n\n2. 将 $c_{3}$ 视为期望积分 $c_{3} = \\int_{-1}^{1} \\frac{1}{2} u(x) \\psi_{3}(x) \\, dx$，确定高斯-勒让德求积法为精确计算该特定被积函数的积分所需的最小节点数。然后验证，使用具有该最小节点数的高斯-勒让德法则可以得到精确的 $c_{3}$。您可以通过高斯-勒让德求积法的精度阶性质来证明其精确性，并且您还应通过在相应的高斯-勒让德节点上直接求值来证明，少一个节点对此被积函数是无效的。\n\n以精确的符号表达式报告 $c_{3}$。无需四舍五入。", "solution": "我们从正交性和标准正交性的核心定义开始。经典勒让德多项式 $\\{P_{n}\\}$ 满足\n$$\n\\int_{-1}^{1} P_{m}(x) P_{n}(x) \\, dx \\;=\\; \\frac{2}{2n+1} \\, \\delta_{mn}.\n$$\n对于 $X \\sim \\text{Uniform}([-1,1])$，相关的内积是\n$$\n\\langle f, g \\rangle \\;=\\; \\mathbb{E}[f(X) g(X)] \\;=\\; \\int_{-1}^{1} \\frac{1}{2} f(x) g(x) \\, dx.\n$$\n为了获得关于此内积的标准正交基 $\\{\\psi_{n}\\}$，定义\n$$\n\\psi_{n}(x) \\;=\\; \\sqrt{2n+1}\\, P_{n}(x).\n$$\n确实，\n$$\n\\mathbb{E}[\\psi_{n}(X)^{2}] \\;=\\; \\int_{-1}^{1} \\frac{1}{2} \\left(\\sqrt{2n+1}\\, P_{n}(x)\\right)^{2} \\, dx\n\\;=\\; \\frac{2n+1}{2} \\int_{-1}^{1} P_{n}(x)^{2} \\, dx\n\\;=\\; \\frac{2n+1}{2} \\cdot \\frac{2}{2n+1} \\;=\\; 1,\n$$\n并且根据 $\\{P_{n}\\}$ 的正交性，对于 $m \\ne n$ 有 $\\mathbb{E}[\\psi_{m}(X)\\psi_{n}(X)] = 0$。\n\n多项式混沌系数定义为\n$$\nc_{n} \\;=\\; \\mathbb{E}\\!\\left[ u(X) \\, \\psi_{n}(X) \\right].\n$$\n对于 $u(x) = x^{3}$，我们求解 $c_{3} = \\mathbb{E}\\!\\left[ X^{3} \\, \\psi_{3}(X) \\right]$。使用 $\\psi_{3}(x) = \\sqrt{7}\\, P_{3}(x)$ 和显式公式 $P_{3}(x) = \\tfrac{1}{2}\\left(5x^{3} - 3x\\right)$，我们得到\n$$\nc_{3} \\;=\\; \\sqrt{7} \\, \\mathbb{E}\\!\\left[ X^{3} \\, P_{3}(X) \\right]\n\\;=\\; \\sqrt{7} \\int_{-1}^{1} \\frac{1}{2} \\, x^{3} \\cdot \\frac{1}{2}\\left(5x^{3} - 3x\\right) \\, dx\n\\;=\\; \\frac{\\sqrt{7}}{4} \\int_{-1}^{1} \\left(5x^{6} - 3x^{4}\\right) \\, dx.\n$$\n我们直接计算积分：\n$$\n\\int_{-1}^{1} (5x^6 - 3x^4) dx = \\left[ 5\\frac{x^7}{7} - 3\\frac{x^5}{5} \\right]_{-1}^1 = \\left(\\frac{5}{7} - \\frac{3}{5}\\right) - \\left(-\\frac{5}{7} + \\frac{3}{5}\\right) = 2\\left(\\frac{25-21}{35}\\right) = \\frac{8}{35}.\n$$\n代入得，\n$$\nc_3 = \\frac{\\sqrt{7}}{4} \\cdot \\frac{8}{35} = \\frac{2\\sqrt{7}}{35}.\n$$\n\n我们现在验证通过使用最少节点数的高斯-勒让德求积法恢复结果。$c_{3}$ 的积分可以写为\n$$\nc_{3} \\;=\\; \\int_{-1}^{1} \\frac{1}{2} \\, u(x) \\, \\psi_{3}(x) \\, dx.\n$$\n此积分中的被积函数 $f(x) := \\frac{1}{2} u(x) \\psi_3(x) = \\frac{\\sqrt{7}}{4}(5x^6 - 3x^4)$ 是一个 6 次多项式。一个 $n$ 点高斯-勒让德求积法对于积分 $\\int_{-1}^1 g(x) dx$ 是精确的，如果被积函数 $g(x)$ 的次数至多为 $2n - 1$。因此，为保证对 6 次多项式的精确性，我们需要 $2n - 1 \\ge 6$，即 $n \\ge 3.5$，这意味着最小节点数为 $n = 4$。\n\n为了确认 $n = 3$ 个节点对于这个特定的被积函数是不够的，考虑 3 点高斯-勒让德节点 $\\{ -\\sqrt{3/5}, 0, \\sqrt{3/5} \\}$ 及其对应的权重。在这些节点上计算被积函数 $f(x)$ 的值。对于 $x = 0$，$f(0) = 0$。对于 $x = \\pm \\sqrt{3/5}$，注意到 $x^{2} = 3/5$，所以 $x^{4} = 9/25$ 且 $x^{6} = 27/125$，因此\n$$\nf\\!\\left(\\pm \\sqrt{\\frac{3}{5}}\\right) \\;=\\; \\frac{\\sqrt{7}}{4} \\left(5 \\cdot \\frac{27}{125} \\;-\\; 3 \\cdot \\frac{9}{25}\\right)\n\\;=\\; \\frac{\\sqrt{7}}{4} \\left(\\frac{27}{25} \\;-\\; \\frac{27}{25}\\right)\n\\;=\\; 0.\n$$\n因此，$\\int_{-1}^{1} f(x) \\, dx$ 的 3 点高斯-勒让德近似值恰好为零，这不等于真实值 $c_3 = \\frac{2\\sqrt{7}}{35}$。因此 $n = 3$ 失败，而 $n = 4$ 确实是保证精确性所需的最小节点数。\n\n根据精度阶性质，4 点高斯-勒让德法可以精确地积分被积函数 $f(x)$，因此求积法将恢复精确值 $c_3 = \\frac{2\\sqrt{7}}{35}$。\n\n因此，所求系数为\n$$\nc_{3} \\;=\\; \\frac{2 \\sqrt{7}}{35}.\n$$", "answer": "$$\\boxed{\\frac{2\\sqrt{7}}{35}}$$", "id": "3330111"}, {"introduction": "了解了如何计算 PCE 系数后，我们必须警惕数值计算中可能出现的陷阱。当用于计算投影积分的求积法则精度不足时，就会发生“混叠” (aliasing) 现象，即高阶多项式分量的信息会“泄露”并错误地表现为低阶系数。这个练习 [@problem_id:3330105] 将通过一个精心设计的案例，清晰地揭示这一过程，让您亲手计算出因数值积分不准确而产生的虚假系数，从而深刻理解为 PCE 选择合适求积规则的重要性。", "problem": "考虑一个标量响应函数 $f(\\xi)$ 关于一个在区间 $[-1,1]$ 上均匀分布的标量随机输入 $\\xi$ 的一维多项式混沌展开 (PCE)。使用标准勒让德多项式 $\\{P_{n}(\\xi)\\}_{n \\geq 0}$ 作为多项式基。在此非归一化勒让德基中，精确的第 $n$ 阶投影系数定义为\n$$\nc_{n} \\equiv \\frac{2n+1}{2} \\int_{-1}^{1} f(\\xi)\\,P_{n}(\\xi)\\,d\\xi,\n$$\n该定义源于勒让德多项式的正交关系和基的完备性。\n\n当内积积分由一个其精确度不足以覆盖被积函数阶数的求积法则来近似时，系数恢复过程中会出现混叠现象。为证明这一点，设 $f(\\xi) = P_{7}(\\xi)$，即7阶勒让德多项式。根据正交性，对于 $n \\ne 7$ 的低阶系数 $c_{n}$ 的精确值为零。然而，使用具有 $n=3$ 个点（在 $[-1,1]$ 上的三点法则）的高斯-勒让德求积法则进行近似恢复时，积分被替换为在 $n=3$ 个节点上的加权和。该法则仅对阶数最高为 $2n-1=5$ 的多项式被积函数是精确的，因此，阶数为 $8$ 的内积被积函数 $P_{7}(\\xi)P_{1}(\\xi)$ 无法被精确积分，并可能产生混叠。\n\n使用在 $[-1,1]$ 上的三点高斯-勒让德求积法则，计算系数 $c_{1}$ 的基于求积的近似值，并以单个最简有理数的形式给出其精确值。这个值展示了因使用 $n=3$ 点的求积法则对一个7阶多项式进行积分而导致的低阶系数的错误恢复（混叠）。\n\n无需四舍五入；请提供精确的最简分数作为最终答案。", "solution": "我们的目标是计算当使用3点高斯-勒让德求积法则近似函数 $f(\\xi) = P_7(\\xi)$ 的一阶PCE系数 $c_1$ 时产生的混叠误差。我们记这个近似值为 $\\hat{c}_1$。\n\n根据勒让德多项式的正交性，精确的系数 $c_1$ 为：\n$$\nc_1 = \\frac{2(1)+1}{2} \\int_{-1}^{1} f(\\xi) P_1(\\xi) d\\xi = \\frac{3}{2} \\int_{-1}^{1} P_7(\\xi) P_1(\\xi) d\\xi = 0\n$$\n近似系数 $\\hat{c}_1$ 是通过用3点高斯-勒让德求积法则（节点为 $\\{\\xi_i\\}_{i=1}^3$，权重为 $\\{w_i\\}_{i=1}^3$）来计算这个积分得到的：\n$$\n\\hat{c}_1 = \\frac{3}{2} \\sum_{i=1}^{3} w_i P_7(\\xi_i) P_1(\\xi_i)\n$$\n被积函数 $P_7(\\xi) P_1(\\xi)$ 是一个8阶多项式。而一个3点高斯求积法则仅对阶数最高为 $2 \\times 3 - 1 = 5$ 的多项式是精确的。由于 $8 > 5$，该求积法则是不精确的，从而导致混叠现象。\n\n高斯求积的一个关键性质是，其节点 $\\{\\xi_i\\}$ 是 $P_3(\\xi)$ 的根。因此，在这些节点上计算 $P_7(\\xi)$ 的值，等价于计算 $P_7(\\xi)$ 除以 $P_3(\\xi)$ 所得的余式 $R(\\xi)$ 的值。即 $P_7(\\xi_i) = R(\\xi_i)$。\n因此，求积和可以重写为：\n$$\n\\hat{c}_1 = \\frac{3}{2} \\sum_{i=1}^{3} w_i R(\\xi_i) P_1(\\xi_i)\n$$\n新的被积函数 $R(\\xi) P_1(\\xi)$ 的阶数最高为 $2+1=3$。因为 $3 \\le 5$，3点求积法则可以精确地计算这个新积分。所以，求积和等于积分：\n$$\n\\hat{c}_1 = \\frac{3}{2} \\int_{-1}^{1} R(\\xi) P_1(\\xi) d\\xi\n$$\n我们的任务简化为求 $P_7(\\xi)$ 除以 $P_3(\\xi)$ 的余式 $R(\\xi)$。通过多项式除法，可以得到 $P_7(\\xi) = Q(\\xi)P_3(\\xi) - \\frac{22}{125}\\xi$，其中 $Q(\\xi)$ 是商多项式。因此，余式为 $R(\\xi) = -\\frac{22}{125}\\xi$。\n\n现在我们计算 $\\hat{c}_1$：\n$$\n\\hat{c}_1 = \\frac{3}{2} \\int_{-1}^{1} \\left(-\\frac{22}{125}\\xi\\right) P_1(\\xi) d\\xi\n$$\n由于 $P_1(\\xi) = \\xi$，我们有：\n$$\n\\hat{c}_1 = -\\frac{3}{2} \\frac{22}{125} \\int_{-1}^{1} \\xi^2 d\\xi = -\\frac{33}{125} \\left[\\frac{\\xi^3}{3}\\right]_{-1}^{1} = -\\frac{33}{125} \\left(\\frac{2}{3}\\right) = -\\frac{22}{125}\n$$\n这个非零值 $-\\frac{22}{125}$ 就是由于求积法则精度不足而产生的混叠系数。", "answer": "$$\\boxed{-\\frac{22}{125}}$$", "id": "3330105"}, {"introduction": "建立一个优秀的 PCE 模型不仅涉及计算系数，更关键的是要选择合适的模型复杂度，特别是多项式的阶数。留一法 (Leave-one-out, LOO) 交叉验证是一种强大的统计方法，可用于评估模型的预测性能并选择最佳阶数，而无需进行 $N$ 次重复训练。这个高级实践任务 [@problem_id:3330068] 将理论与编程实践相结合，引导您推导并实现一个高效且数值稳定的 LOO 交叉验证算法，最终构建一个能够自动选择最优多项式阶数的完整程序，这是在不确定性量化应用中构建可靠代理模型的关键一步。", "problem": "给定一个随机配置回归设置，用于构建多项式混沌展开 (PCE)，其输入为在区间 $\\left[-1,1\\right]$ 上均匀分布的独立变量，并使用正交勒让德基。目标是设计并实现一个有原则的、数值稳定的留一法 (LOO) 交叉验证程序，以选择总多项式阶数。该程序需要从第一性原理出发，利用最小二乘拟合的帽子矩阵进行推导。\n\n从以下基本要素开始：\n- 输入是 $s$ 元随机变量 $\\boldsymbol{X} = \\left(X_{1},\\dots,X_{s}\\right)$，其分量相互独立，且均服从 $\\left[-1,1\\right]$ 上的均匀分布。\n- 对于PCE，使用相对于概率测度的正交多项式；在 $1$ 维情况下，$n$ 阶正交勒让德多项式为 $\\phi_{n}\\left(x\\right) = \\sqrt{2n+1}\\,P_{n}\\left(x\\right)$，其中 $P_{n}$ 是经典勒让德多项式。\n- 在 $s$ 维情况下，多元基函数是张量积形式 $\\Psi_{\\boldsymbol{\\alpha}}\\left(\\boldsymbol{x}\\right) = \\prod_{j=1}^{s}\\phi_{\\alpha_{j}}\\left(x_{j}\\right)$，其中多重指标 $\\boldsymbol{\\alpha}\\in\\mathbb{N}_{0}^{s}$，总阶数满足 $\\left\\lVert \\boldsymbol{\\alpha}\\right\\rVert_{1} \\le p$，其中 $p$ 为总多项式阶数。\n- 在基于回归的随机配置中，给定 $N$ 个确定性节点 $\\left\\{\\boldsymbol{x}^{(i)}\\right\\}_{i=1}^{N}$ 和响应 $\\left\\{y^{(i)}\\right\\}_{i=1}^{N}$，最小二乘估计量拟合模型 $y^{(i)} \\approx \\sum_{\\left\\lVert \\boldsymbol{\\alpha}\\right\\rVert_{1}\\le p} c_{\\boldsymbol{\\alpha}}\\,\\Psi_{\\boldsymbol{\\alpha}}\\left(\\boldsymbol{x}^{(i)}\\right)$。设 $A\\in\\mathbb{R}^{N\\times P}$ 为设计矩阵，其元素为 $A_{i,k}=\\Psi_{\\boldsymbol{\\alpha}_{k}}\\left(\\boldsymbol{x}^{(i)}\\right)$，其中 $P$ 个基函数采用固定排序（$P$ 是总阶数至多为 $p$ 的多重指标的数量），并设 $\\boldsymbol{y}\\in\\mathbb{R}^{N}$ 为响应向量。最小二乘估计量最小化 $\\left\\lVert A\\boldsymbol{c}-\\boldsymbol{y}\\right\\rVert_{2}^{2}$。\n- 当 $A$ 具有满列秩时，帽子矩阵定义为 $H = A\\left(A^{\\mathsf{T}}A\\right)^{-1}A^{\\mathsf{T}}$，拟合响应满足 $\\widehat{\\boldsymbol{y}} = H\\boldsymbol{y}$。\n\n您的任务：\n1. 使用最小二乘法、帽子矩阵和标准线性代数恒等式的定义，从第一性原理出发，推导样本 $i$ 的留一法预测误差的闭式表达式。该公式必须仅依赖于全数据残差和帽子矩阵的对角线元素，并且必须避免显式地重新拟合模型 $N$ 次。\n2. 证明如果 $A$ 有一个瘦 $QR$ 分解 $A = QR$，其中 $Q\\in\\mathbb{R}^{N\\times P}$ 具有正交列，而 $R\\in\\mathbb{R}^{P\\times P}$ 是上三角矩阵，那么帽子矩阵的对角线满足 $\\mathrm{diag}\\!\\left(H\\right) = \\left(\\left\\lVert \\boldsymbol{q}_{1}^{\\mathsf{T}}\\right\\rVert_{2}^{2},\\dots,\\left\\lVert \\boldsymbol{q}_{N}^{\\mathsf{T}}\\right\\rVert_{2}^{2}\\right)$，其中 $\\boldsymbol{q}_{i}^{\\mathsf{T}}$ 是 $Q$ 的第 $i$ 行。\n3. 基于第1项和第2项，设计并实现一个数值稳定的算法，该算法：\n   - 在 $s=\\;2$ 维中，构建总阶数最高为 $p$ 的多元正交勒让德基。\n   - 在给定的配置节点上构建设计矩阵 $A$。\n   - 使用帽子矩阵的对角线和全数据残差，为候选阶数 $p$ 计算LOO均方误差，而无需重新拟合 $N$ 次。\n   - 使用一个防护机制来排除欠定或秩亏的拟合。具体来说，如果基函数的数量 $P$ 大于或等于 $N$，或者如果 $\\mathrm{rank}\\!\\left(A\\right) \\lt P$，则将该 $p$ 的LOO误差定义为 $+\\infty$。\n   - 从给定的有限候选集合中，选择具有最小LOO误差的阶数 $\\widehat{p}$，若出现平局，则选择最小的阶数。\n4. 在 $\\left[-1,1\\right]^{2}$ 上使用确定性的高斯-勒让德张量积配置节点，其中 $n\\times n$ 个节点由每个维度上 $n$ 点高斯-勒让德横坐标的笛卡尔积给出。回归只需要节点，不需要权重。\n5. 实现以上内容，并为以下三个测试用例中的每一个报告所选的阶数 $\\widehat{p}$。在所有情况下，输入维度为 $s=\\;2$，角度以弧度为单位。\n   - 测试用例 A（平滑的非多项式目标，良好解析）：\n     - 节点：每个维度 $n=\\;5$ 个，总共 $N=\\;25$ 个。\n     - 响应函数：$f_{A}\\!\\left(x_{1},x_{2}\\right) = \\exp\\!\\left(0.7\\,x_{1} - 0.3\\,x_{2}\\right) + 0.1\\,\\sin\\!\\left(\\pi\\,x_{1}x_{2}\\right)$。\n     - 候选阶数：$\\left\\{1,2,3,4,5,6\\right\\}$。\n   - 测试用例 B（正交勒让德基中的精确3阶PCE，无噪声）：\n     - 节点：每个维度 $n=\\;5$ 个，总共 $N=\\;25$ 个。\n     - 响应函数：$f_{B}\\!\\left(x_{1},x_{2}\\right) = 1.0\\,\\Psi_{(0,0)} + 0.8\\,\\Psi_{(1,0)} - 0.5\\,\\Psi_{(0,1)} + 0.3\\,\\Psi_{(2,0)} + 0.2\\,\\Psi_{(1,1)} - 0.1\\,\\Psi_{(0,2)} + 0.05\\,\\Psi_{(2,1)}$，其中 $\\Psi_{(a,b)}\\!\\left(x_{1},x_{2}\\right) = \\phi_{a}\\!\\left(x_{1}\\right)\\phi_{b}\\!\\left(x_{2}\\right)$ 且 $\\phi_{n}\\!\\left(x\\right) = \\sqrt{2n+1}\\,P_{n}\\!\\left(x\\right)$。\n     - 候选阶数：$\\left\\{1,2,3,4,5,6\\right\\}$。\n   - 测试用例 C（粗糙设计边界，防护行为）：\n     - 节点：每个维度 $n=\\;3$ 个，总共 $N=\\;9$ 个。\n     - 响应函数：$f_{C}\\!\\left(x_{1},x_{2}\\right) = \\tanh\\!\\left(0.8\\,x_{1} - 0.6\\,x_{2}\\right) + 0.05\\,\\cos\\!\\left(5\\,x_{1}\\right)\\sin\\!\\left(3\\,x_{2}\\right)$。\n     - 候选阶数：$\\left\\{1,2,3,4\\right\\}$。\n6. 数值稳定性要求：\n   - 通过稳定的例程或递推关系实现勒让德多项式。\n   - 使用第2项中的 $QR$ 分解计算帽子矩阵的对角线，而不是通过显式构造 $H$。\n   - 在计算LOO误差时，使用容差进行秩确定和除法防护。如果您的公式所需的任何分母在数值容差范围内接近于零，则对该阶数返回 $+\\infty$。\n7. 输出规范：\n   - 您的程序应生成单行输出，其中包含测试用例 A、B 和 C 的所选阶数，形式为逗号分隔的列表并用方括号括起来。例如，您的输出必须具有 $\\left[\\text{resultA},\\text{resultB},\\text{resultC}\\right]$ 的形式，其中每个条目都是一个整数。\n\n所有计算都是无量纲的。您的最终程序必须完全确定，不需要外部输入，并且必须严格按照上述描述生成一行输出。", "solution": "该问题要求推导、证明并实现一个留一法（LOO）交叉验证程序，用于选择多项式混沌展开（PCE）的总多项式阶数。该程序必须数值稳定，并基于线性回归的第一性原理，特别是使用帽子矩阵。\n\n### 第1部分：闭式LOO误差的推导\n\n目标是推导在样本点 $i$ 处的留一法预测误差 $e^{(-i)}$ 的表达式，而无需重新拟合模型 $N$ 次。第 $i$ 个观测值的LOO预测 $\\widehat{y}^{(-i)}$ 是通过在除 $(\\boldsymbol{x}^{(i)}, y^{(i)})$ 之外的所有数据点上训练的模型获得的。LOO误差则为 $e^{(-i)} = y^{(i)} - \\widehat{y}^{(-i)}$。\n\n设完整线性模型为 $\\boldsymbol{y} = A\\boldsymbol{c} + \\boldsymbol{\\epsilon}$，其中 $A \\in \\mathbb{R}^{N \\times P}$ 是设计矩阵，$\\boldsymbol{y} \\in \\mathbb{R}^{N}$ 是响应向量。拟合值向量为 $\\widehat{\\boldsymbol{y}} = H\\boldsymbol{y}$，其中 $H = A(A^{\\mathsf{T}}A)^{-1}A^{\\mathsf{T}}$ 是帽子矩阵。第 $i$ 个拟合值为 $\\widehat{y}^{(i)} = \\sum_{j=1}^{N} H_{ij} y^{(j)}$，普通残差为 $e^{(i)} = y^{(i)} - \\widehat{y}^{(i)}$。\n\n一个关键的观察是，对除第 $i$ 个数据点之外的数据进行最小二乘拟合，等价于对一个修改后的问题进行拟合，其中响应 $y^{(i)}$ 被替换为 $\\widehat{y}^{(-i)}$。应用帽子矩阵到这个修改后的问题，其第 $i$ 个分量为：\n$$\n\\widehat{y}^{(-i)} = \\sum_{j \\ne i} H_{ij} y^{(j)} + H_{ii} \\widehat{y}^{(-i)}\n$$\n整理后得到：\n$$\n\\widehat{y}^{(-i)} (1 - H_{ii}) = \\sum_{j \\ne i} H_{ij} y^{(j)}\n$$\n从原始的全数据拟合中，我们知道 $\\widehat{y}^{(i)} = \\sum_{j=1}^{N} H_{ij} y^{(j)} = H_{ii} y^{(i)} + \\sum_{j \\ne i} H_{ij} y^{(j)}$。因此，$\\sum_{j \\ne i} H_{ij} y^{(j)} = \\widehat{y}^{(i)} - H_{ii} y^{(i)}$。\n将此式代入上面的方程：\n$$\n\\widehat{y}^{(-i)} (1 - H_{ii}) = \\widehat{y}^{(i)} - H_{ii} y^{(i)}\n$$\n假设 $H_{ii} \\neq 1$，我们可以解出LOO预测 $\\widehat{y}^{(-i)}$。然后，LOO误差 $e^{(-i)} = y^{(i)} - \\widehat{y}^{(-i)}$ 可推导为：\n$$\ne^{(-i)} = y^{(i)} - \\frac{\\widehat{y}^{(i)} - H_{ii} y^{(i)}}{1 - H_{ii}} = \\frac{y^{(i)}(1-H_{ii}) - (\\widehat{y}^{(i)} - H_{ii} y^{(i)})}{1 - H_{ii}} = \\frac{y^{(i)} - \\widehat{y}^{(i)}}{1 - H_{ii}}\n$$\n这简化为所需的表达式：\n$$ e^{(-i)} = \\frac{e^{(i)}}{1 - H_{ii}} $$\nLOO均方误差（MSE）则为 $E_{\\text{LOO}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( e^{(-i)} \\right)^2$。\n\n### 第2部分：从QR分解证明帽子矩阵对角线\n\n对于设计矩阵的瘦QR分解 $A = QR$（其中 $Q^{\\mathsf{T}}Q = I_P$），帽子矩阵 $H$ 可以写为：\n$$\nH = A(A^{\\mathsf{T}}A)^{-1}A^{\\mathsf{T}} = (QR)((QR)^{\\mathsf{T}}QR)^{-1}(QR)^{\\mathsf{T}} = QR(R^{\\mathsf{T}}Q^{\\mathsf{T}}QR)^{-1}R^{\\mathsf{T}}Q^{\\mathsf{T}}\n$$\n$$\nH = QR(R^{\\mathsf{T}}R)^{-1}R^{\\mathsf{T}}Q^{\\mathsf{T}} = QRR^{-1}(R^{\\mathsf{T}})^{-1}R^{\\mathsf{T}}Q^{\\mathsf{T}} = QQ^{\\mathsf{T}}\n$$\n因此，帽子矩阵的对角线元素 $H_{ii}$ 就是 $Q$ 的第 $i$ 行向量 $\\boldsymbol{q}_{i}^{\\mathsf{T}}$ 与其自身的点积：\n$$ H_{ii} = \\boldsymbol{q}_{i}^{\\mathsf{T}} \\boldsymbol{q}_{i} = \\sum_{k=1}^{P} (Q_{ik})^2 = \\left\\lVert \\boldsymbol{q}_{i}^{\\mathsf{T}} \\right\\rVert_2^2 $$\n这完成了证明，并提供了一种数值稳定的计算 $H$ 对角线的方法。\n\n### 第3-7部分：算法实现\n以下Python代码实现了所描述的算法，并为三个测试用例计算最优阶数。\n\n```python\nimport numpy as np\nfrom scipy.special import eval_legendre\nimport itertools\n\ndef _generate_multi_indices(p, s):\n    \"\"\"Generates all multi-indices in `s` dimensions with total degree up to `p`.\"\"\"\n    if s == 0:\n        return [[]] if p >= 0 else []\n    if s == 1:\n        return [[i] for i in range(p + 1)]\n    \n    indices = []\n    for i in range(p + 1):\n        sub_indices = _generate_multi_indices(p - i, s - 1)\n        for sub_index in sub_indices:\n            indices.append([i] + sub_index)\n    return indices\n\ndef _eval_ortho_legendre_poly_vec(n, x):\n    \"\"\"Evaluates the orthonormal Legendre polynomial of degree `n` at points `x`.\"\"\"\n    return np.sqrt(2 * n + 1) * eval_legendre(n, x)\n\ndef _calculate_loo_mse(p, s, nodes, responses):\n    \"\"\"\n    Calculates the Leave-One-Out Mean Squared Error for a PCE of total degree `p`.\n    \"\"\"\n    N = nodes.shape[0]\n    \n    multi_indices = _generate_multi_indices(p, s)\n    P = len(multi_indices)\n\n    if P >= N:\n        return np.inf\n\n    A = np.zeros((N, P))\n    for i in range(N):\n        for k, alpha in enumerate(multi_indices):\n            val = 1.0\n            for dim in range(s):\n                val *= _eval_ortho_legendre_poly_vec(alpha[dim], nodes[i, dim])\n            A[i, k] = val\n    \n    try:\n        Q, R = np.linalg.qr(A, mode='reduced')\n    except np.linalg.LinAlgError:\n        return np.inf\n\n    tol_rank = N * P * np.finfo(R.dtype).eps\n    if np.any(np.abs(np.diag(R)) < tol_rank):\n        return np.inf\n\n    y_hat = Q @ (Q.T @ responses)\n    residuals = responses - y_hat\n    \n    h_diag = np.sum(Q**2, axis=1)\n\n    tol_denom = 1e-12\n    if np.any((1.0 - h_diag) < tol_denom):\n        return np.inf\n        \n    loo_errors = residuals / (1.0 - h_diag)\n    loo_mse = np.mean(loo_errors**2)\n    \n    return loo_mse\n\ndef _find_best_degree(s, nodes, responses, candidate_degrees):\n    \"\"\"\n    Finds the best polynomial degree from a set of candidates by minimizing LOO-MSE.\n    \"\"\"\n    best_p = -1\n    min_loo_error = np.inf\n\n    for p in candidate_degrees:\n        loo_error = _calculate_loo_mse(p, s, nodes, responses)\n        \n        if loo_error < min_loo_error:\n            min_loo_error = loo_error\n            best_p = p\n    \n    return best_p\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    s = 2\n\n    # --- Test Case A ---\n    n_A = 5\n    candidate_degrees_A = [1, 2, 3, 4, 5, 6]\n    nodes_1d_A, _ = np.polynomial.legendre.leggauss(n_A)\n    x1_A, x2_A = np.meshgrid(nodes_1d_A, nodes_1d_A)\n    nodes_A = np.vstack([x1_A.ravel(), x2_A.ravel()]).T\n    \n    def f_A(x1, x2):\n        return np.exp(0.7 * x1 - 0.3 * x2) + 0.1 * np.sin(np.pi * x1 * x2)\n\n    responses_A = f_A(nodes_A[:, 0], nodes_A[:, 1])\n    result_A = _find_best_degree(s, nodes_A, responses_A, candidate_degrees_A)\n\n    # --- Test Case B ---\n    n_B = 5\n    candidate_degrees_B = [1, 2, 3, 4, 5, 6]\n    nodes_1d_B, _ = np.polynomial.legendre.leggauss(n_B)\n    x1_B, x2_B = np.meshgrid(nodes_1d_B, nodes_1d_B)\n    nodes_B = np.vstack([x1_B.ravel(), x2_B.ravel()]).T\n\n    def f_B(x1, x2):\n        psi_00 = _eval_ortho_legendre_poly_vec(0, x1) * _eval_ortho_legendre_poly_vec(0, x2)\n        psi_10 = _eval_ortho_legendre_poly_vec(1, x1) * _eval_ortho_legendre_poly_vec(0, x2)\n        psi_01 = _eval_ortho_legendre_poly_vec(0, x1) * _eval_ortho_legendre_poly_vec(1, x2)\n        psi_20 = _eval_ortho_legendre_poly_vec(2, x1) * _eval_ortho_legendre_poly_vec(0, x2)\n        psi_11 = _eval_ortho_legendre_poly_vec(1, x1) * _eval_ortho_legendre_poly_vec(1, x2)\n        psi_02 = _eval_ortho_legendre_poly_vec(0, x1) * _eval_ortho_legendre_poly_vec(2, x2)\n        psi_21 = _eval_ortho_legendre_poly_vec(2, x1) * _eval_ortho_legendre_poly_vec(1, x2)\n        \n        return (1.0 * psi_00 + 0.8 * psi_10 - 0.5 * psi_01 + 0.3 * psi_20 +\n                0.2 * psi_11 - 0.1 * psi_02 + 0.05 * psi_21)\n\n    responses_B = f_B(nodes_B[:, 0], nodes_B[:, 1])\n    result_B = _find_best_degree(s, nodes_B, responses_B, candidate_degrees_B)\n    \n    # --- Test Case C ---\n    n_C = 3\n    candidate_degrees_C = [1, 2, 3, 4]\n    nodes_1d_C, _ = np.polynomial.legendre.leggauss(n_C)\n    x1_C, x2_C = np.meshgrid(nodes_1d_C, nodes_1d_C)\n    nodes_C = np.vstack([x1_C.ravel(), x2_C.ravel()]).T\n    \n    def f_C(x1, x2):\n        return np.tanh(0.8 * x1 - 0.6 * x2) + 0.05 * np.cos(5 * x1) * np.sin(3 * x2)\n        \n    responses_C = f_C(nodes_C[:, 0], nodes_C[:, 1])\n    result_C = _find_best_degree(s, nodes_C, responses_C, candidate_degrees_C)\n\n    results = [result_A, result_B, result_C]\n    # This print statement is for verification and not part of the final XML.\n    # print(f\"[{','.join(map(str, results))}]\")\n\n```", "answer": "[4,3,2]", "id": "3330068"}]}