{"hands_on_practices": [{"introduction": "多变量正态分布是多变量统计的基石，而从第一性原理推导其条件分布是一项至关重要的技能。这个练习将巩固对联合密度、边缘密度和条件密度之间关系的理解，这项技术对于吉布斯采样等算法至关重要。通过完成这个推导[@problem_id:3297685]，你将掌握处理高斯模型的核心代数技巧。", "problem": "考虑一个联合高斯分布的随机变量对 $(X,Y)$，其均值向量为 $(\\mu_{X},\\mu_{Y})$，协方差矩阵为\n$$\n\\Sigma \\;=\\; \\begin{pmatrix}\n\\sigma_{X}^{2}  \\rho\\,\\sigma_{X}\\sigma_{Y} \\\\\n\\rho\\,\\sigma_{X}\\sigma_{Y}  \\sigma_{Y}^{2}\n\\end{pmatrix},\n$$\n其中 $\\sigma_{X}0$，$\\sigma_{Y}0$，且 $|\\rho|1$。在一个用于模拟多元正态分布的马尔可夫链蒙特卡洛（MCMC）算法的吉布斯采样步骤中，需要知道一个分量在给定另一个分量下的条件分布。请仅从联合高斯密度的定义和通过比率 $f_{X|Y}(x|y) = f_{X,Y}(x,y)/f_{Y}(y)$ 定义的条件密度出发，并使用标准的线性代数恒等式（用于求协方差矩阵的逆和配方法），推导出对于固定的 $y$ 的条件密度 $f_{X|Y}(x|y)$。然后，推断出条件期望 $E[X|Y=y]$。\n\n你的推理必须从核心定义和已验证的事实出发，通过明确的代数推导进行，不能使用任何关于条件正态分布的快捷公式。最终答案必须是 $E[X|Y=y]$ 的单一闭式符号表达式。不要提供任何数值近似。", "solution": "该问题是有效的，因为它在概率论中有科学依据，信息完备、问题适定，且其表述是客观的。该任务是多元统计学中的一个标准推导。\n\n令随机向量 $\\mathbf{Z} = \\begin{pmatrix} X \\\\ Y \\end{pmatrix}$ 服从二元正态分布，其均值向量为 $\\mathbf{\\mu} = \\begin{pmatrix} \\mu_X \\\\ \\mu_Y \\end{pmatrix}$，协方差矩阵为 $\\Sigma = \\begin{pmatrix} \\sigma_X^2  \\rho \\sigma_X \\sigma_Y \\\\ \\rho \\sigma_X \\sigma_Y  \\sigma_Y^2 \\end{pmatrix}$。联合概率密度函数（PDF）由下式给出：\n$$ f_{\\mathbf{Z}}(\\mathbf{z}) = \\frac{1}{\\sqrt{(2\\pi)^2 \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (\\mathbf{z}-\\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{z}-\\mathbf{\\mu})\\right) $$\n其中 $\\mathbf{z} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$。\n\n首先，我们计算协方差矩阵 $\\Sigma$ 的行列式和逆矩阵。行列式为：\n$$ \\det(\\Sigma) = (\\sigma_X^2)(\\sigma_Y^2) - (\\rho \\sigma_X \\sigma_Y)^2 = \\sigma_X^2 \\sigma_Y^2 (1-\\rho^2) $$\n条件 $|\\rho|  1$ 确保 $\\det(\\Sigma) > 0$，因此该矩阵是可逆的。其逆矩阵为：\n$$ \\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)} \\begin{pmatrix} \\sigma_Y^2  -\\rho \\sigma_X \\sigma_Y \\\\ -\\rho \\sigma_X \\sigma_Y  \\sigma_X^2 \\end{pmatrix} = \\frac{1}{\\sigma_X^2 \\sigma_Y^2 (1-\\rho^2)} \\begin{pmatrix} \\sigma_Y^2  -\\rho \\sigma_X \\sigma_Y \\\\ -\\rho \\sigma_X \\sigma_Y  \\sigma_X^2 \\end{pmatrix} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1/\\sigma_X^2  -\\rho/(\\sigma_X \\sigma_Y) \\\\ -\\rho/(\\sigma_X \\sigma_Y)  1/\\sigma_Y^2 \\end{pmatrix} $$\n指数中的二次型是 $Q(x,y) = (\\mathbf{z}-\\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{z}-\\mathbf{\\mu})$，展开为：\n$$ Q(x,y) = \\begin{pmatrix} x-\\mu_X  y-\\mu_Y \\end{pmatrix} \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1/\\sigma_X^2  -\\rho/(\\sigma_X \\sigma_Y) \\\\ -\\rho/(\\sigma_X \\sigma_Y)  1/\\sigma_Y^2 \\end{pmatrix} \\begin{pmatrix} x-\\mu_X \\\\ y-\\mu_Y \\end{pmatrix} $$\n$$ Q(x,y) = \\frac{1}{1-\\rho^2} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] $$\n因此，联合概率密度函数 $f_{X,Y}(x,y)$ 是：\n$$ f_{X,Y}(x,y) = \\frac{1}{2\\pi \\sigma_X \\sigma_Y \\sqrt{1-\\rho^2}} \\exp\\left(-\\frac{1}{2(1-\\rho^2)} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right]\\right) $$\n$Y$ 的边缘分布是一个均值为 $\\mu_Y$、方差为 $\\sigma_Y^2$ 的正态分布。其概率密度函数为：\n$$ f_Y(y) = \\frac{1}{\\sqrt{2\\pi \\sigma_Y^2}} \\exp\\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right) = \\frac{1}{\\sigma_Y \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right) $$\n根据定义，条件密度 $f_{X|Y}(x|y)$ 是联合密度与边缘密度的比值：\n$$ f_{X|Y}(x|y) = \\frac{f_{X,Y}(x,y)}{f_Y(y)} $$\n条件概率密度函数的常数部分是：\n$$ \\frac{1 / (2\\pi \\sigma_X \\sigma_Y \\sqrt{1-\\rho^2})}{1 / (\\sigma_Y \\sqrt{2\\pi})} = \\frac{\\sigma_Y \\sqrt{2\\pi}}{2\\pi \\sigma_X \\sigma_Y \\sqrt{1-\\rho^2}} = \\frac{1}{\\sigma_X \\sqrt{2\\pi} \\sqrt{1-\\rho^2}} $$\n条件概率密度函数的指数部分是联合概率密度函数的指数部分与边缘概率密度函数的指数部分之差：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] - \\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right) $$\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2} \\left\\{ \\frac{1}{1-\\rho^2} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] - \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right\\} $$\n我们合并包含 $(y-\\mu_Y)^2$ 的项：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2} \\left\\{ \\frac{1}{1-\\rho^2}\\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} \\right] + \\left(\\frac{1}{1-\\rho^2} - 1\\right)\\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right\\} $$\n由于 $\\frac{1}{1-\\rho^2} - 1 = \\frac{1 - (1-\\rho^2)}{1-\\rho^2} = \\frac{\\rho^2}{1-\\rho^2}$，表达式变为：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2} \\left\\{ \\frac{1}{1-\\rho^2}\\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\rho^2\\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] \\right\\} $$\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)} \\left[ \\left(\\frac{x-\\mu_X}{\\sigma_X}\\right)^2 - 2\\rho\\left(\\frac{x-\\mu_X}{\\sigma_X}\\right)\\left(\\frac{y-\\mu_Y}{\\sigma_Y}\\right) + \\rho^2\\left(\\frac{y-\\mu_Y}{\\sigma_Y}\\right)^2 \\right] $$\n方括号中的项是一个完全平方。我们对变量 $x$ 进行配方：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)} \\left( \\frac{x-\\mu_X}{\\sigma_X} - \\rho\\frac{y-\\mu_Y}{\\sigma_Y} \\right)^2 $$\n为了确定均值和方差，我们将此表达式重新整理成标准形式 $-\\frac{(x-\\mu)^2}{2\\sigma^2}$：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)\\sigma_X^2} \\left( (x-\\mu_X) - \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y) \\right)^2 $$\n$$ \\text{Exp}_{X|Y} = -\\frac{\\left( x - \\left[\\mu_X + \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y)\\right] \\right)^2}{2\\sigma_X^2(1-\\rho^2)} $$\n因此，条件密度 $f_{X|Y}(x|y)$ 为：\n$$ f_{X|Y}(x|y) = \\frac{1}{\\sigma_X \\sqrt{2\\pi(1-\\rho^2)}} \\exp\\left( -\\frac{\\left( x - \\left[\\mu_X + \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y)\\right] \\right)^2}{2\\sigma_X^2(1-\\rho^2)} \\right) $$\n这是关于 $x$ 的正态分布的概率密度函数。通过将其与正态概率密度函数的一般形式 $f(z) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(z-\\mu)^2}{2\\sigma^2}\\right)$ 进行比较，我们可以确定条件均值和条件方差。\n条件均值是给定 $Y=y$ 时 $X$ 的期望：\n$$ E[X|Y=y] = \\mu_{X|Y} = \\mu_X + \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y) $$\n条件方差为：\n$$ \\text{Var}(X|Y=y) = \\sigma_{X|Y}^2 = \\sigma_X^2(1-\\rho^2) $$\n问题特别要求条件期望 $E[X|Y=y]$。根据上述推导，这就是上面推导出的条件正态分布的均值。", "answer": "$$ \\boxed{\\mu_X + \\rho \\frac{\\sigma_X}{\\sigma_Y}(y - \\mu_Y)} $$", "id": "3297685"}, {"introduction": "理论概念如何带来实际的显著改进？Rao-Blackwell定理提供了一种利用充分统计量上的条件期望来系统性地改进估计量的方法。这项动手练习[@problem_id:3297654]将理论推导与蒙特卡洛模拟相结合，让你亲眼见证方差缩减的效果，并深刻理解条件期望在统计估计中的力量。", "problem": "考虑以下通过条件期望对 Rao–Blackwell (RB) 改进进行的蒙特卡洛 (MC) 研究。设 $\\{Y_i\\}_{i=1}^n$ 是独立同分布的，其中 $Y_i \\sim \\mathrm{Poisson}(\\lambda)$，$\\lambda  0$ 是一个固定但未知的参数。您需要使用一个无偏估计量 $X$ 及其 Rao-Blackwell 化版本 $\\mathbb{E}[X \\mid \\sigma(T)]$ 来估计泛函 $\\theta(\\lambda) = \\mathbb{E}_\\lambda[X] = e^{-\\lambda}$，其中 $T$ 是 $\\lambda$ 的一个充分统计量。任务是从第一性原理出发推导 $\\mathbb{E}[X \\mid \\sigma(T)]$，然后在多个样本大小下，比较 $X$ 的 MC 方差与 $\\mathbb{E}[X \\mid \\sigma(T)]$ 的 MC 方差。\n\n定义和设置：\n- 设 $X = \\mathbf{1}\\{Y_1 = 0\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。注意 $\\mathbb{E}_\\lambda[X] = \\mathbb{P}_\\lambda(Y_1 = 0) = e^{-\\lambda}$。\n- 设 $T = \\sum_{i=1}^n Y_i$。使用因子分解定理来证明 $T$ 对于 $\\lambda$ 是充分的。\n- 使用条件期望的定义，通过将 $X$ 投影到 $\\sigma(T)$ 上来构造 RB 估计量，即，明确地将 $\\mathbb{E}[X \\mid \\sigma(T)]$ 推导为 $T$ 和 $n$ 的函数。\n\n您的任务：\n1. 从 $(Y_1,\\dots,Y_n)$ 的联合概率质量函数 (PMF) 和充分性的定义出发，证明 $T$ 对于 $\\lambda$ 是充分的。然后，使用给定 $T=t$ 时 $Y_1$ 的条件分布，推导出 $\\mathbb{E}[X \\mid T=t]$ 的闭式形式，进而得出 $\\mathbb{E}[X \\mid \\sigma(T)]$ 的闭式形式。\n2. 解释为什么 $\\mathbb{E}[X \\mid \\sigma(T)]$ 对于 $\\theta(\\lambda)$ 仍然是无偏的，并（使用 Rao–Blackwell 定理）证明为什么对于任何 $n \\in \\mathbb{N}$ 和 $\\lambda  0$，都有 $\\mathrm{Var}(\\mathbb{E}[X \\mid \\sigma(T)]) \\le \\mathrm{Var}(X)$。\n3. 实现一个 MC 实验，通过模拟来估计和比较 $\\mathrm{Var}(X)$ 和 $\\mathrm{Var}(\\mathbb{E}[X \\mid \\sigma(T)])$。对于给定的配对 $(\\lambda,n)$，生成 $M$ 个独立同分布的 $(Y_1,\\dots,Y_n)$ 复制，为每个复制计算相应的 $X$ 和 $\\mathbb{E}[X \\mid \\sigma(T)]$，然后计算 $X$ 和 $\\mathbb{E}[X \\mid \\sigma(T)]$ 的无偏 MC 样本方差（使用贝塞尔校正）。报告比率\n$$\nR(\\lambda,n) = \\frac{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(\\mathbb{E}[X \\mid \\sigma(T)])}{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(X)}.\n$$\n4. 对所有测试用例使用以下 MC 设置：$M = 100000$ 和一个固定的随机种子 $0$ 以确保可复现性。\n5. 测试套件：按以下列表中的确切顺序，为参数对 $(\\lambda,n)$ 计算 $R(\\lambda,n)$：\n   - $(\\lambda,n) = (0.3,1)$，\n   - $(\\lambda,n) = (0.3,2)$，\n   - $(\\lambda,n) = (1.0,5)$，\n   - $(\\lambda,n) = (3.0,10)$，\n   - $(\\lambda,n) = (5.0,25)$。\n6. 最终输出格式：您的程序必须打印单行，其中包含一个 Python 风格的列表，内含按上述顺序排列的五个比率 $[R(\\lambda,n),\\dots]$，每个比率四舍五入到 $6$ 位小数。此问题中没有物理单位，没有角度，也没有百分比；数值答案必须是实数。\n\n额外要求：\n- 您的程序必须是一个完整的、可运行的脚本，执行 MC 模拟，无需用户输入。\n- 仅使用最终答案部分详述的指定运行时环境和库。", "solution": "此问题被判定为有效。这是一个形式良好且具有科学依据的计算统计学练习，具体通过蒙特卡洛模拟演示了 Rao-Blackwell 定理的应用。所有必要信息，包括模型、估计量、参数和模拟设置，都以清晰一致的方式提供。\n\n解决方案分三部分进行：\n1.  推导 Rao–Blackwell 估计量。\n2.  其性质（无偏性和方差缩减）的理论证明。\n3.  用于比较方差的蒙特卡洛模拟设计描述。\n\n### 1. Rao–Blackwell 估计量的推导\n\n设 $\\{Y_i\\}_{i=1}^n$ 是独立同分布的随机变量，且 $Y_i \\sim \\mathrm{Poisson}(\\lambda)$。$\\theta(\\lambda) = e^{-\\lambda}$ 的初始估计量是 $X = \\mathbf{1}\\{Y_1 = 0\\}$。Rao–Blackwell 定理指出，如果 $T$ 是 $\\lambda$ 的一个充分统计量，那么估计量 $\\tilde{X} = \\mathbb{E}[X \\mid \\sigma(T)]$ 对 $\\theta(\\lambda)$ 也是无偏的，并且其方差不大于 $X$ 的方差。\n\n**$T = \\sum_{i=1}^n Y_i$ 的充分性：**\n\n由于独立性，样本 $\\mathbf{Y} = (Y_1, \\dots, Y_n)$ 的联合概率质量函数 (PMF) 是单个泊松 PMF 的乘积：\n$$ f(\\mathbf{y}; \\lambda) = \\prod_{i=1}^n \\mathbb{P}(Y_i = y_i) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!} $$\n这可以重写为：\n$$ f(\\mathbf{y}; \\lambda) = \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} $$\n令 $t = \\sum_{i=1}^n y_i$。该 PMF 可以分解为：\n$$ f(\\mathbf{y}; \\lambda) = \\left( e^{-n\\lambda} \\lambda^t \\right) \\cdot \\left( \\frac{1}{\\prod_{i=1}^n y_i!} \\right) $$\n这是 $g(t; \\lambda)h(\\mathbf{y})$ 的形式，其中 $g(t; \\lambda) = e^{-n\\lambda} \\lambda^t$ 仅通过统计量 $T$ 依赖于数据，而 $h(\\mathbf{y}) = (\\prod_{i=1}^n y_i!)^{-1}$ 不依赖于 $\\lambda$。根据 Fisher-Neyman 因子分解定理，这证明了 $T = \\sum_{i=1}^n Y_i$ 是 $\\lambda$ 的充分统计量。\n\n**$\\mathbb{E}[X \\mid T=t]$ 的推导：**\n\nRao-Blackwell 化估计量 $\\tilde{X}$ 是给定充分统计量 $T$ 时 $X$ 的条件期望。对于给定的观测值 $T=t$，我们有：\n$$ \\mathbb{E}[X \\mid T=t] = \\mathbb{E}[\\mathbf{1}\\{Y_1=0\\} \\mid T=t] = \\mathbb{P}(Y_1=0 \\mid T=t) $$\n使用条件概率的定义：\n$$ \\mathbb{P}(Y_1=0 \\mid \\sum_{i=1}^n Y_i = t) = \\frac{\\mathbb{P}(Y_1=0, \\sum_{i=1}^n Y_i = t)}{\\mathbb{P}(\\sum_{i=1}^n Y_i = t)} $$\n分子中的事件等价于 $\\{Y_1=0 \\text{ 且 } \\sum_{i=2}^n Y_i = t\\}$。\n独立泊松随机变量之和本身也是一个泊松随机变量。具体来说，$S_k = \\sum_{i=1}^k Y_i \\sim \\mathrm{Poisson}(k\\lambda)$。\n因此，$T = \\sum_{i=1}^n Y_i \\sim \\mathrm{Poisson}(n\\lambda)$，其 PMF 为 $\\mathbb{P}(T=t) = \\frac{e^{-n\\lambda}(n\\lambda)^t}{t!}$。\n分子中的项可以使用独立性来计算：\n$$ \\mathbb{P}(Y_1=0, \\sum_{i=2}^n Y_i = t) = \\mathbb{P}(Y_1=0) \\cdot \\mathbb{P}\\left(\\sum_{i=2}^n Y_i = t\\right) $$\n其中 $\\mathbb{P}(Y_1=0) = e^{-\\lambda}$ 且 $\\sum_{i=2}^n Y_i \\sim \\mathrm{Poisson}((n-1)\\lambda)$。这在 $n > 1$ 时成立。\n分子为：\n$$ (e^{-\\lambda}) \\cdot \\left( \\frac{e^{-(n-1)\\lambda}((n-1)\\lambda)^t}{t!} \\right) = \\frac{e^{-n\\lambda}((n-1)\\lambda)^t}{t!} $$\n将分子和分母代入条件概率公式：\n$$ \\mathbb{P}(Y_1=0 \\mid T=t) = \\frac{\\frac{e^{-n\\lambda}((n-1)\\lambda)^t}{t!}}{\\frac{e^{-n\\lambda}(n\\lambda)^t}{t!}} = \\frac{((n-1)\\lambda)^t}{(n\\lambda)^t} = \\left(\\frac{n-1}{n}\\right)^t $$\n此推导适用于 $n > 1$。对于 $n=1$ 的情况，我们有 $T=Y_1$。估计量为 $\\mathbb{E}[\\mathbf{1}\\{Y_1=0\\} \\mid Y_1=t]$。如果 $t=0$，此值为 $1$，如果 $t \\ne 0$，则为 $0$，可以写成 $\\mathbf{1}\\{t=0\\}$。将公式 $\\left(\\frac{n-1}{n}\\right)^t$ 应用于 $n=1$ 会得到 $0^t$，按照惯例，当 $t=0$ 时为 $1$，当 $t>0$ 时为 $0$。因此，该表达式对于 $n=1$ 也成立。\n\n因此，Rao-Blackwell 估计量为 $\\tilde{X} = \\mathbb{E}[X \\mid \\sigma(T)] = \\left(\\frac{n-1}{n}\\right)^T$。\n\n### 2. 估计量的性质\n\n**无偏性：**\n根据全期望定律（或称塔性质），条件期望的期望等于无条件期望：\n$$ \\mathbb{E}[\\tilde{X}] = \\mathbb{E}\\left[\\mathbb{E}[X \\mid \\sigma(T)]\\right] = \\mathbb{E}[X] $$\n由于原始估计量 $X = \\mathbf{1}\\{Y_1=0\\}$ 对 $\\theta(\\lambda) = e^{-\\lambda}$ 是无偏的（因为 $\\mathbb{E}[X] = \\mathbb{P}(Y_1=0) = e^{-\\lambda}$），Rao-Blackwell 化估计量 $\\tilde{X}$ 对 $\\theta(\\lambda)$ 也是无偏的。\n\n**方差缩减：**\n全方差定律表明：\n$$ \\mathrm{Var}(X) = \\mathbb{E}[\\mathrm{Var}(X \\mid T)] + \\mathrm{Var}(\\mathbb{E}[X \\mid T]) $$\n我们的改进估计量的方差是 $\\mathrm{Var}(\\tilde{X}) = \\mathrm{Var}(\\mathbb{E}[X \\mid T])$。$\\mathbb{E}[\\mathrm{Var}(X \\mid T)]$ 项是条件方差的期望。由于方差总是非负的，$\\mathrm{Var}(X \\mid T) \\ge 0$，因此其期望也非负，即 $\\mathbb{E}[\\mathrm{Var}(X \\mid T)] \\ge 0$。\n这意味着：\n$$ \\mathrm{Var}(X) \\ge \\mathrm{Var}(\\mathbb{E}[X \\mid T]) \\quad \\text{或} \\quad \\mathrm{Var}(X) \\ge \\mathrm{Var}(\\tilde{X}) $$\n等号成立当且仅当 $\\mathrm{Var}(X \\mid T) = 0$ 几乎必然成立，这意味着 $X$ 是 $T$ 的函数。在我们的例子中，对于 $n=1$，$T=Y_1$，所以 $X=\\mathbf{1}\\{Y_1=0\\}$ 是 $T$ 的函数。因此对于 $n=1$，$\\mathrm{Var}(X) = \\mathrm{Var}(\\tilde{X})$，方差比将为 $1$。对于 $n>1$，$X$ 不是 $T$ 的函数，所以我们预期严格不等式 $\\mathrm{Var}(X)  \\mathrm{Var}(\\tilde{X})$ 成立，且方差比小于 $1$。\n\n### 3. 蒙特卡洛模拟设计\n\n该模拟将为指定的参数对 $(\\lambda, n)$ 估计和比较 $X$ 和 $\\tilde{X}$ 的方差。\n对于每对 $(\\lambda, n)$ 的过程如下：\n1.  为保证可复现性，将随机数生成器种子设置为 $0$。\n2.  生成 $M=100000$ 个独立的样本 $(Y_1, \\dots, Y_n)$ 的复制，其中每个 $Y_i \\sim \\mathrm{Poisson}(\\lambda)$。这将产生 $M$ 个长度为 $n$ 的向量。\n3.  对于 $M$ 个复制中的每一个：\n    a.  计算原始估计量 $X = \\mathbf{1}\\{Y_1=0\\}$。\n    b.  计算充分统计量 $T = \\sum_{i=1}^n Y_i$。\n    c.  计算 Rao-Blackwell 化估计量 $\\tilde{X} = \\left(\\frac{n-1}{n}\\right)^T$。\n4.  这将产生两组 $M$ 个样本：$\\{X_j\\}_{j=1}^M$ 和 $\\{\\tilde{X}_j\\}_{j=1}^M$。\n5.  使用无偏估计量（使用贝塞尔校正，$ddof=1$）计算样本方差：\n    $$ \\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(X) = \\frac{1}{M-1}\\sum_{j=1}^M (X_j - \\bar{X})^2 \\quad \\text{和} \\quad \\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(\\tilde{X}) = \\frac{1}{M-1}\\sum_{j=1}^M (\\tilde{X}_j - \\bar{\\tilde{X}})^2 $$\n6.  计算比率 $R(\\lambda,n) = \\frac{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(\\tilde{X})}{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(X)}$。\n7.  将对以下测试用例重复此过程：\n    - $(\\lambda,n) = (0.3, 1)$\n    - $(\\lambda,n) = (0.3, 2)$\n    - $(\\lambda,n) = (1.0, 5)$\n    - $(\\lambda,n) = (3.0, 10)$\n    - $(\\lambda,n) = (5.0, 25)$\n最终输出将是一个包含这些比率的列表，四舍五入到 $6$ 位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Monte Carlo study to compare the variance of an estimator\n    with its Rao-Blackwellized version.\n    \"\"\"\n    # Define simulation parameters as specified in the problem statement.\n    M = 100000\n    SEED = 0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.3, 1),\n        (0.3, 2),\n        (1.0, 5),\n        (3.0, 10),\n        (5.0, 25),\n    ]\n\n    results = []\n\n    # Initialize the random number generator for reproducibility.\n    rng = np.random.default_rng(SEED)\n\n    for lam, n in test_cases:\n        # Generate M independent replicates of n i.i.d. Poisson samples.\n        # The shape of Y_samples will be (M, n).\n        Y_samples = rng.poisson(lam=lam, size=(M, n))\n\n        # Calculate the original estimator X = 1{Y_1 = 0} for each of the M replicates.\n        # This results in a 1D array of length M.\n        x_values = (Y_samples[:, 0] == 0).astype(np.float64)\n\n        # Calculate the sufficient statistic T = sum(Y_i) for each of the M replicates.\n        # This results in a 1D array of length M.\n        t_values = np.sum(Y_samples, axis=1)\n\n        # Calculate the Rao-Blackwellized estimator E[X|T] = ((n-1)/n)^T.\n        # For n=1, the base is 0. np.power(0, 0) correctly evaluates to 1,\n        # which is the value of E[X|T] when T=0. For T>0, np.power(0, T) is 0.\n        # This handles the n=1 case correctly where E[X|T] = 1{T=0}.\n        if n == 1:\n            base = 0.0\n        else:\n            base = (n - 1) / n\n        \n        x_tilde_values = np.power(base, t_values)\n\n        # Calculate the sample variances of the M estimates for both estimators.\n        # ddof=1 provides Bessel's correction for an unbiased estimate of the variance.\n        var_x = np.var(x_values, ddof=1)\n        var_x_tilde = np.var(x_tilde_values, ddof=1)\n\n        # Calculate the ratio of the variances.\n        # For n=1, X and E[X|T] are identical, so their variances are identical\n        # and the ratio is 1.0. For other cases, Var(X) will be non-zero for\n        # the given lambda values.\n        if var_x == 0:\n            # This case occurs if all x_values are identical.\n            # If Var(X) = 0, then X is constant, so Var(E[X|T]) also must be 0.\n            # The ratio should be 1, as E[X|T] = X in this case.\n            ratio = 1.0\n        else:\n            ratio = var_x_tilde / var_x\n\n        results.append(round(ratio, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3297654"}, {"introduction": "吉布斯采样是一个强大的工具，但它的有效性依赖于一个基本前提：所有满条件分布必须是“相容的”（coherent），即它们必须对应于一个有效的联合分布。本练习[@problem_id:3297655]将引导你设计一个基于模拟的精巧诊断工具，来凭经验检验这一关键条件。这突显了条件分布理论与现代MCMC算法的有效性之间深刻的内在联系。", "problem": "给定一个二元随机向量 $(X_{1},X_{2})$ 的全条件分布族，其形式为如下的线性高斯分布：\n$$\nX_{1} \\mid X_{2}=x_{2} \\sim \\mathcal{N}(\\mu_{1} + a x_{2}, s_{1}^{2}), \\qquad X_{2} \\mid X_{1}=x_{1} \\sim \\mathcal{N}(\\mu_{2} + b x_{1}, s_{2}^{2})\n$$\n其中 $a,b\\in\\mathbb{R}$，$s_{1}^{2}0$，$s_{2}^{2}0$ 和 $\\mu_{1},\\mu_{2}\\in\\mathbb{R}$ 是固定参数。核心问题是这些全条件分布是否相容，即是否存在某个在 $\\mathbb{R}^{2}$ 上的联合分布，其条件分布与上述分布族一致。由于精确的解析相容性条件可能很微妙，您将使用蒙特卡洛模拟，基于不同吉布斯扫描顺序下迭代条件的不变性，对相容性的一个必要体现进行经验性检验。\n\n使用的基本原理和定义：\n- 对于任何可积函数 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$，条件期望 $E[f\\mid X_{i}]$ 是 $f$ 在由 $X_{i}$（$i\\in\\{1,2\\}$）生成的 $\\sigma$-代数上的正交投影。\n- 从状态 $(x_{1},x_{2})$ 开始，按 $1\\to 2$ 顺序的一次扫描两步吉布斯更新包括采样 $X_{1}'\\sim p(\\cdot\\mid X_{2}=x_{2})$，然后采样 $X_{2}'\\sim p(\\cdot\\mid X_{1}=X_{1}')$。应用于 $f$ 的相应马尔可夫算子是在 $(x_{1},x_{2})$ 处求值的迭代条件期望 $K_{12}f(x_{1},x_{2})=E[E[f\\mid X_{1}]\\mid X_{2}]$。类似地，对于 $2\\to 1$ 顺序，有 $K_{21}f(x_{1},x_{2})=E[E[f\\mid X_{2}]\\mid X_{1}]$。\n- 如果全条件分布是相容的（即，来自 $\\mathbb{R}^{2}$ 上的某个联合分布 $\\Pi$），那么两种扫描顺序定义的马尔可夫链都共享相同的平稳分布 $\\Pi$，并且对于任何可积函数 $f$ 和任一扫描顺序，平稳期望都满足 $E_{\\Pi}[f]=E_{\\Pi}[K_{12}f]=E_{\\Pi}[K_{21}f]$。因此，在相容性条件下，一组检验函数的平稳期望对于扫描顺序是不变的。\n\n设计一个蒙特卡洛相容性诊断程序，对于给定的参数集 $(a,b,s_{1},s_{2},\\mu_{1},\\mu_{2})$，执行以下操作：\n- 使用给定的全条件分布构建两种吉布斯扫描顺序：$1\\to 2$ 和 $2\\to 1$。\n- 对每条链进行 $N_{\\mathrm{burn}}$ 步的预烧期模拟，然后收集 $N$ 个预烧期后的迭代值。\n- 对于以下五个检验函数\n$$\nf_{1}(x_{1},x_{2})=x_{1},\\quad\nf_{2}(x_{1},x_{2})=x_{2},\\quad\nf_{3}(x_{1},x_{2})=x_{1}x_{2},\\quad\nf_{4}(x_{1},x_{2})=x_{1}^{2},\\quad\nf_{5}(x_{1},x_{2})=x_{2}^{2},\n$$\n计算它们在每种扫描顺序下的平稳期望的蒙特卡洛估计，并使用非重叠批次均值法计算蒙特卡洛标准误。使用批次大小 $B$ 和 $M=\\lfloor N/B\\rfloor$ 个批次。\n- 对每个 $f_{k}$，计算标准化差异\n$$\nZ_{k}=\\frac{\\left|\\widehat{E}_{12}[f_{k}]-\\widehat{E}_{21}[f_{k}]\\right|}{\\sqrt{\\widehat{\\mathrm{Var}}_{12}(\\bar{f}_{k})+\\widehat{\\mathrm{Var}}_{21}(\\bar{f}_{k})}},\n$$\n其中 $\\widehat{E}_{12}[f_{k}]$ 和 $\\widehat{E}_{21}[f_{k}]$ 分别是来自 $1\\to 2$ 和 $2\\to 1$ 扫描的样本均值，而 $\\widehat{\\mathrm{Var}}(\\bar{f}_{k})$ 是它们对样本均值的批次均值方差估计量。如果对于一个固定的阈值 $\\tau$，满足 $\\max_{k\\in\\{1,\\dots,5\\}} Z_{k}\\le \\tau$，则宣告该参数集为“经验性相容”。\n\n使用固定的模拟设置：\n- 使用 $N_{\\mathrm{burn}}=20000$，$N=120000$，$B=600$ 和 $\\tau=5$。\n- 将两条链都在 $(0,0)$ 处初始化。\n- 使用固定的伪随机数生成器种子，以使结果完全可复现。\n- 不使用角度；没有需要报告的物理单位。\n\n测试套件：\n为以下四个参数集 $(a,b,s_{1},s_{2},\\mu_{1},\\mu_{2})$ 提供结果：\n- 情况1（相容，源于一个均值为 $(m_{1},m_{2})=(0.5,-0.3)$、方差为 $(v_{1},v_{2})=(1.5,0.7)$、协方差为 $c=0.6$ 的真实二元正态分布）：\n$$\na=\\frac{0.6}{0.7},\\quad b=\\frac{0.6}{1.5},\\quad s_{1}=\\sqrt{1.5-\\frac{0.6^{2}}{0.7}},\\quad s_{2}=\\sqrt{0.7-\\frac{0.6^{2}}{1.5}},\n$$\n$$\n\\mu_{1}=0.5-a(-0.3),\\quad \\mu_{2}=-0.3-b(0.5).\n$$\n- 情况2（通过斜率/方差不匹配故意设置为不相容）：\n$$\na=0.8,\\quad b=0.2,\\quad s_{1}=1.0,\\quad s_{2}=\\sqrt{0.9},\\quad \\mu_{1}=0.0,\\quad \\mu_{2}=0.0.\n$$\n- 情况3（通过均值不匹配故意设置为不相容，而斜率/方差与某个零均值联合分布相容）：\n$$\na=0.25,\\quad b=0.5,\\quad s_{1}=\\sqrt{0.875},\\quad s_{2}=\\sqrt{1.75},\\quad \\mu_{1}=0.6,\\quad \\mu_{2}=1.5.\n$$\n- 情况4（相容，接近边界 $ab \\approx 1$）：\n$$\na=b=\\sqrt{0.95},\\quad s_{1}=s_{2}=\\sqrt{1-0.95},\\quad \\mu_{1}=0.0,\\quad \\mu_{2}=0.0.\n$$\n\n您的程序必须对所有四种情况实现上述诊断，并输出单行，其中包含一个含四个布尔值的列表，每个布尔值指示相应的参数集根据标准 $\\max_{k} Z_{k}\\le \\tau$ 是否为经验性相容。格式必须严格为用方括号括起来的逗号分隔列表，例如 $[{\\mathrm{True}}, {\\mathrm{False}}, {\\mathrm{False}}, {\\mathrm{True}}]$。", "solution": "给出的问题是有效的。它在科学上基于马尔可夫链蒙特卡洛（MCMC）方法和条件概率分布的理论。该问题是适定的，提供了所有必要的参数、常数以及待实现算法的完整规范。术语精确，目标明确。\n\n问题的核心是为一组全条件分布的相容性设计一个经验性诊断方法。如果存在一个联合概率分布 $p(x_1, \\dots, x_d)$，其条件分布就是给定的全条件分布族 $\\{p(x_i | x_{-i})\\}_{i=1}^d$，那么该分布族就是相容的。对于给定的线性高斯情况，\n$$\nX_1 \\mid X_2=x_2 \\sim \\mathcal{N}(\\mu_1 + a\\,x_2, s_1^2)\n$$\n$$\nX_2 \\mid X_1=x_1 \\sim \\mathcal{N}(\\mu_2 + b\\,x_1, s_2^2)\n$$\n一个联合二元正态分布存在当且仅当 $ab \\ge 0$，$ab  1$ 且 $as_2^2 = bs_1^2$。如果这些条件成立，那么由这些条件分布构建的吉布斯采样器将以相应的联合正态分布作为其唯一的平稳分布 $\\Pi$。这种采样器的一个关键性质是其平稳分布对变量的扫描顺序是不变的。也就是说，按 $X_1 \\to X_2$ 或 $X_2 \\to X_1$ 的顺序更新变量会产生两条不同的马尔可夫链，但它们共享相同的平稳分布 $\\Pi$。\n\n这种不变性提供了一个强大的诊断工具。如果条件分布是相容的，那么任何可积检验函数 $f(X_1, X_2)$ 的长期平均值必须相同，无论扫描顺序如何。设 $E_{12}[f]$ 和 $E_{21}[f]$ 分别表示在 $1 \\to 2$ 和 $2 \\to 1$ 扫描顺序下 $f$ 的平稳期望。相容性意味着 $E_{12}[f] = E_{21}[f] = E_\\Pi[f]$。所提出的诊断方法使用蒙特卡洛模拟来检验这一推论。\n\n算法流程如下：\n\n1.  **吉布斯采样器模拟**：运行两条并行的吉布斯采样链，每条链对应一种扫描顺序。\n    -   **链 1（顺序 $1 \\to 2$）**：从一个状态 $(x_1^{(t)}, x_2^{(t)})$，通过采样 $x_{1, \\text{new}} \\sim \\mathcal{N}(\\mu_1 + a\\,x_2^{(t)}, s_1^2)$，然后采样 $x_2^{(t+1)} \\sim \\mathcal{N}(\\mu_2 + b\\,x_{1, \\text{new}}, s_2^2)$ 来生成下一个状态 $(x_1^{(t+1)}, x_2^{(t+1)})$，并设 $x_1^{(t+1)} = x_{1, \\text{new}}$。\n    -   **链 2（顺序 $2 \\to 1$）**：更新首先包括采样 $x_{2, \\text{new}} \\sim \\mathcal{N}(\\mu_2 + b\\,x_1^{(t)}, s_2^2)$，然后采样 $x_1^{(t+1)} \\sim \\mathcal{N}(\\mu_1 + a\\,x_{2, \\text{new}}, s_1^2)$，并设 $x_2^{(t+1)} = x_{2, \\text{new}}$。\n\n    两条链都从 $(x_1^{(0)}, x_2^{(0)}) = (0,0)$ 开始初始化。它们运行 $N_{\\mathrm{burn}} = 20000$ 次迭代以丢弃初始的瞬态样本（预烧期）。随后，从每条链收集 $N = 120000$ 个样本。\n\n2.  **期望的蒙特卡洛估计**：对于五个检验函数中的每一个 $f_k$ 和每条链（由扫描顺序 $j \\in \\{12, 21\\}$ 表示），使用在 $N$ 个预烧期后样本 $\\{(x_{1,j}^{(i)}, x_{2,j}^{(i)})\\}_{i=1}^N$ 上评估的函数值的样本均值来估计平稳期望 $E_j[f_k]$：\n    $$\n    \\widehat{E}_j[f_k] = \\frac{1}{N} \\sum_{i=1}^{N} f_k(x_{1,j}^{(i)}, x_{2,j}^{(i)})\n    $$\n\n3.  **通过批次均值法估计标准误**：来自MCMC链的样本内在地相关，这使得用于独立同分布样本均值的简单方差公式失效。为了获得 $\\widehat{E}_j[f_k]$ 方差的有效估计，采用非重叠批次均值法（NOBM）。将 $N$ 个预烧期后的 $f_k$ 样本划分为 $M = \\lfloor N/B \\rfloor = \\lfloor 120000/600 \\rfloor = 200$ 个非重叠批次，每个批次大小为 $B=600$。对每个批次 $m \\in \\{1, \\dots, M\\}$，计算批次均值 $\\bar{f}_{k,j}^{(m)}$。然后，总样本均值 $\\widehat{E}_j[f_k]$ 的方差估计为：\n    $$\n    \\widehat{\\mathrm{Var}}_j(\\bar{f}_k) = \\frac{1}{M} \\cdot \\frac{1}{M-1} \\sum_{m=1}^{M} \\left( \\bar{f}_{k,j}^{(m)} - \\widehat{E}_j[f_k] \\right)^2\n    $$\n    此公式计算批次均值的样本方差，并按 $1/M$ 进行缩放。对于足够大的批次大小 $B$，批次均值近似不相关，并且根据中心极限定理，服从正态分布。\n\n4.  **标准化差异检验**：对于每个检验函数 $f_k$，计算来自两条链的估计值之间的标准化差异 $Z_k$。这类似于双样本Z检验：\n    $$\n    Z_k = \\frac{\\left|\\widehat{E}_{12}[f_k] - \\widehat{E}_{21}[f_k]\\right|}{\\sqrt{\\widehat{\\mathrm{Var}}_{12}(\\bar{f}_k) + \\widehat{\\mathrm{Var}}_{21}(\\bar{f}_k)}}\n    $$\n    在相容性的零假设下，$\\widehat{E}_{12}[f_k]$ 和 $\\widehat{E}_{21}[f_k]$ 是同一数量的估计值。它们的差应很小，且 $Z_k$ 统计量应是近似标准正态随机变量的实现。一个大的 $Z_k$ 值提供了反对相容性的证据。如果所有检验函数中观测到的最大差异在统计上不显著，即 $\\max_{k\\in\\{1,\\dots,5\\}} Z_k \\le \\tau$（给定阈值 $\\tau=5$），则该参数集被宣告为“经验性相容”。\n\n这整个过程使用Python中的`numpy`库实现，用于数值计算和随机数生成，并使用固定的种子以确保可复现性。该诊断方法应用于四个指定的参数集中的每一个，以确定其经验相容性状态。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_gibbs_sampler(params, settings, scan_order, rng):\n    \"\"\"\n    Runs a Gibbs sampler for a given scan order and returns the collected samples.\n    \"\"\"\n    a, b, s1, s2, mu1, mu2 = params\n    N_burn, N = settings['N_burn'], settings['N']\n    x1, x2 = 0.0, 0.0\n\n    # Burn-in phase\n    for _ in range(N_burn):\n        if scan_order == '12':\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n        elif scan_order == '21':\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n\n    # Sample collection phase\n    samples = np.zeros((N, 2))\n    for i in range(N):\n        if scan_order == '12':\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n        elif scan_order == '21':\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n        samples[i, :] = [x1, x2]\n\n    return samples\n\ndef calculate_stats(samples, settings):\n    \"\"\"\n    Computes Monte Carlo estimates and their batch-means variances.\n    \"\"\"\n    N, B = settings['N'], settings['B']\n    M = N // B\n\n    x1_s = samples[:, 0]\n    x2_s = samples[:, 1]\n\n    # Evaluate the five test functions over the samples\n    f_values = [\n        x1_s,\n        x2_s,\n        x1_s * x2_s,\n        x1_s**2,\n        x2_s**2\n    ]\n\n    means = []\n    vars_of_mean = []\n\n    for f_vec in f_values:\n        # Overall sample mean\n        overall_mean = np.mean(f_vec)\n        means.append(overall_mean)\n\n        # Reshape for batching\n        reshaped_f = f_vec.reshape((M, B))\n        batch_means = np.mean(reshaped_f, axis=1)\n\n        # Variance of the sample mean using batch means\n        # This is Var(batch_means) / M\n        var_of_batch_means = np.var(batch_means, ddof=1)\n        var_of_mean = var_of_batch_means / M\n        vars_of_mean.append(var_of_mean)\n\n    return means, vars_of_mean\n\ndef run_coherence_diagnostic(params, settings):\n    \"\"\"\n    Performs the full coherence diagnostic for a single parameter set.\n    \"\"\"\n    rng = np.random.default_rng(settings['seed'])\n\n    # Run sampler for scan order 1-2\n    samples_12 = run_gibbs_sampler(params, settings, '12', rng)\n    means_12, vars_12 = calculate_stats(samples_12, settings)\n\n    # Run sampler for scan order 2-1\n    samples_21 = run_gibbs_sampler(params, settings, '21', rng)\n    means_21, vars_21 = calculate_stats(samples_21, settings)\n\n    Z_scores = []\n    for k in range(5):  # For each of the five test functions\n        numerator = np.abs(means_12[k] - means_21[k])\n        denominator = np.sqrt(vars_12[k] + vars_21[k])\n        \n        if denominator == 0.0:\n            Z_k = 0.0 if numerator == 0.0 else np.inf\n        else:\n            Z_k = numerator / denominator\n        Z_scores.append(Z_k)\n    \n    max_Z = np.max(Z_scores)\n    return max_Z = settings['tau']\n\ndef solve():\n    # Define the fixed simulation settings\n    simulation_settings = {\n        'N_burn': 20000,\n        'N': 120000,\n        'B': 600,\n        'tau': 5.0,\n        'seed': 42 # Fixed seed for reproducibility\n    }\n\n    # Define the test cases from the problem statement.\n    # Case 1 (coherent)\n    c1_v1, c1_v2, c1_c = 1.5, 0.7, 0.6\n    c1_m1, c1_m2 = 0.5, -0.3\n    c1_a = c1_c / c1_v2\n    c1_b = c1_c / c1_v1\n    c1_s1 = np.sqrt(c1_v1 - c1_c**2 / c1_v2)\n    c1_s2 = np.sqrt(c1_v2 - c1_c**2 / c1_v1)\n    c1_mu1 = c1_m1 - c1_a * c1_m2\n    c1_mu2 = c1_m2 - c1_b * c1_m1\n    case1 = (c1_a, c1_b, c1_s1, c1_s2, c1_mu1, c1_mu2)\n\n    # Case 2 (incoherent)\n    case2 = (0.8, 0.2, 1.0, np.sqrt(0.9), 0.0, 0.0)\n\n    # Case 3 (incoherent)\n    case3 = (0.25, 0.5, np.sqrt(0.875), np.sqrt(1.75), 0.6, 1.5)\n\n    # Case 4 (coherent, near boundary)\n    a_b_4 = np.sqrt(0.95)\n    s_4 = np.sqrt(1.0 - 0.95)\n    case4 = (a_b_4, a_b_4, s_4, s_4, 0.0, 0.0)\n\n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for case in test_cases:\n        is_coherent = run_coherence_diagnostic(case, simulation_settings)\n        results.append(is_coherent)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\nsolve()\n```", "id": "3297655"}]}