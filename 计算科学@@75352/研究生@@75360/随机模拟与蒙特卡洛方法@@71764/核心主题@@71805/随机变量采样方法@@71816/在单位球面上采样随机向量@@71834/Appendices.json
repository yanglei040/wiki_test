{"hands_on_practices": [{"introduction": "拒绝采样是一种直观且通用的蒙特卡洛方法，但其效率在处理高维空间时可能急剧下降。本练习将通过一个看似简单的方案——从包围单位球体的超立方体中进行采样——来深入探讨这一现象。通过从第一性原理出发，推导该方法在任意维度 $d$ 下的接受概率，并分析其在 $d \\to \\infty$ 时的渐近行为，我们将具体地揭示“维度灾难”的影响。这项分析练习不仅能够磨练你的数学推导能力，也为理解为何必须开发更复杂的球体采样算法提供了根本性的见解。[@problem_id:3337215]", "problem": "考虑以下拒绝采样方案，该方案用于在 $\\mathbb{R}^{d}$ 的单位球面上生成一个均匀分布的随机方向。抽取一个提议 $\\mathbf{u} \\sim \\mathrm{Unif}([-1,1]^{d})$。如果 $\\|\\mathbf{u}\\|_{2} \\leq 1$，则接受该提议并设置 $\\mathbf{x} = \\mathbf{u}/\\|\\mathbf{u}\\|_{2}$；否则，拒绝并重新采样。令 $a_{d}$ 表示该过程在维度 $d$ 下的接受概率。\n\n从 $\\mathbb{R}^{d}$ 中均匀分布和勒贝格体积的基本定义出发，通过将 $a_d$ 与单位 $\\ell_{2}$-球和超立方体 $[-1,1]^{d}$ 之间的体积之比联系起来，推导出 $a_{d}$ 关于 $d$ 的精确表达式。然后，仅使用从第一性原理证明的、经过充分检验的渐近工具，推导出当 $d \\to \\infty$ 时 $a_{d}$ 的主阶渐近表达式。\n\n给出单一的闭式解析表达式 $c_{d}$ 作为最终答案，使得当 $d \\to \\infty$ 时，$a_{d} \\sim c_{d}$。无需进行数值四舍五入。", "solution": "问题陈述被评估为有效。这是一个在高维概率论和蒙特卡洛方法领域中提出来的、适定的、有科学依据的问题，使用了精确和客观的数学语言。所有必要信息都已提供，不存在矛盾或歧义。\n\n所提出的拒绝采样方案的接受概率 $a_{d}$ 是接受区域的体积与提议区域的体积之比。这是因为提议分布在其支撑集上是均匀的。\n\n提议区域是超立方体 $C_{d} = [-1,1]^{d}$。该超立方体在 $d$ 个维度中每个维度上的边长为 $1 - (-1) = 2$。因此，该超立方体的体积为：\n$$\n\\mathrm{Volume}(C_{d}) = 2^{d}\n$$\n\n接受区域是点集 $\\mathbf{u} \\in [-1,1]^{d}$，这些点的欧几里得范数满足 $\\|\\mathbf{u}\\|_{2} \\leq 1$。这正是 $\\mathbb{R}^{d}$ 中的单位 $\\ell_{2}$-球，我们将其记为 $B_{d}$。问题陈述隐含地假设接受区域完全包含在提议区域之内，这是正确的，因为对于 $B_{d}$ 中的任意点 $\\mathbf{u} = (u_1, \\dots, u_d)$，我们有 $\\|\\mathbf{u}\\|_{2}^2 = \\sum_{i=1}^d u_i^2 \\leq 1$。这意味着对所有 $i$ 都有 $u_i^2 \\leq 1$，所以 $|u_i| \\leq 1$，即 $\\mathbf{u} \\in [-1,1]^{d}$。\n\n半径为 $R$ 的 $d$ 维球体的体积由以下公式给出：\n$$\nV_{d}(R) = \\frac{\\pi^{d/2} R^{d}}{\\Gamma(\\frac{d}{2} + 1)}\n$$\n其中 $\\Gamma(z)$ 是伽马函数。对于单位球 $B_{d}$，半径为 $R=1$，所以其体积为：\n$$\n\\mathrm{Volume}(B_{d}) = V_{d}(1) = \\frac{\\pi^{d/2}}{\\Gamma(\\frac{d}{2} + 1)}\n$$\n\n接受概率 $a_{d}$ 是这些体积之比：\n$$\na_{d} = \\frac{\\mathrm{Volume}(B_{d})}{\\mathrm{Volume}(C_{d})} = \\frac{\\pi^{d/2} / \\Gamma(\\frac{d}{2} + 1)}{2^{d}} = \\frac{\\pi^{d/2}}{2^{d} \\Gamma(\\frac{d}{2} + 1)}\n$$\n这就是 $a_{d}$ 的精确表达式。\n\n接下来，我们推导当 $d \\to \\infty$ 时 $a_{d}$ 的主阶渐近表达式。这需要使用伽马函数的斯特林近似，该近似表明，对于大的 $z$：\n$$\n\\Gamma(z+1) \\sim \\sqrt{2\\pi z} \\left(\\frac{z}{e}\\right)^{z}\n$$\n我们将此公式应用于 $z = d/2$。当 $d \\to \\infty$ 时，$z \\to \\infty$，所以该近似是有效的。\n$$\n\\Gamma\\left(\\frac{d}{2} + 1\\right) \\sim \\sqrt{2\\pi \\frac{d}{2}} \\left(\\frac{d/2}{e}\\right)^{d/2} = \\sqrt{\\pi d} \\left(\\frac{d}{2e}\\right)^{d/2}\n$$\n\n现在，我们将此渐近形式代回到 $a_{d}$ 的表达式中：\n$$\na_{d} \\sim \\frac{\\pi^{d/2}}{2^{d} \\sqrt{\\pi d} \\left(\\frac{d}{2e}\\right)^{d/2}}\n$$\n我们继续简化此表达式。\n$$\na_{d} \\sim \\frac{\\pi^{d/2}}{2^{d} \\sqrt{\\pi d} \\frac{d^{d/2}}{(2e)^{d/2}}} = \\frac{\\pi^{d/2} (2e)^{d/2}}{2^{d} \\sqrt{\\pi d} d^{d/2}}\n$$\n将项 $(2e)^{d/2}$ 展开得到 $2^{d/2}e^{d/2}$：\n$$\na_{d} \\sim \\frac{\\pi^{d/2} 2^{d/2} e^{d/2}}{2^{d} \\sqrt{\\pi d} d^{d/2}}\n$$\n我们可以简化 2 的幂：$2^{d/2}/2^{d} = 2^{d/2 - d} = 2^{-d/2}$。\n$$\na_{d} \\sim \\frac{\\pi^{d/2} e^{d/2}}{2^{d/2} \\sqrt{\\pi d} d^{d/2}}\n$$\n现在，我们将幂为 $d/2$ 的项组合在一起：\n$$\na_{d} \\sim \\frac{1}{\\sqrt{\\pi d}} \\left( \\frac{\\pi e}{2d} \\right)^{d/2}\n$$\n这个表达式，记为 $c_{d}$，代表了当维度 $d$ 趋于无穷大时接受概率 $a_{d}$ 的主阶渐近行为。它表明，随着维度的增加，该概率会急剧下降，这是“维度灾难”的一种表现。\n\n最终答案是推导出的渐近表达式 $c_{d}$。\n$$\nc_{d} = \\frac{1}{\\sqrt{\\pi d}} \\left( \\frac{\\pi e}{2d} \\right)^{d/2}\n$$", "answer": "$$\\boxed{\\frac{1}{\\sqrt{\\pi d}} \\left(\\frac{\\pi e}{2d}\\right)^{d/2}}$$", "id": "3337215"}, {"introduction": "鉴于简单拒绝采样在高维下的失效，我们需要一种既高效又在理论上可靠的方法。利用标准正态分布的球对称性进行归一化，是生成单位球面上均匀分布点的“黄金标准”方法。本练习的核心不仅是实现这一强大算法，更是要让你亲自设计并实现一个精密的诊断工具，以经验性地验证其输出样本是否满足旋转不变性这一关键性质。通过比较随机旋转前后样本在球冠内的分布情况，你将学会如何量化和评估采样器的均匀性，这是计算科学中验证模型和算法正确性的关键实践。[@problem_id:3337173]", "problem": "您的任务是设计并实现一种旋转不变性诊断方法，用于检验在$\\mathbb{R}^d$的单位球面上均匀采样随机向量的算法。该诊断方法必须源自随机模拟的基本原理，并通过比较随机旋转前后经验球冠计数的方式来量化单位球面上的均匀性。您必须从一个有效的基础原理出发，确立一种在球面上采样的算法的旋转不变性，然后构建一个可实现的检验统计量。\n\n基本原理：\n- $d$维标准多元正态分布的密度函数为 $f(\\mathbf{z}) = (2\\pi)^{-d/2}\\exp(-\\|\\mathbf{z}\\|_2^2/2)$，该分布是球面对称的，这意味着对于任何旋转$\\mathbf{R}\\in SO(d)$（其中$SO(d)$表示特殊正交群，即行列式为1的$d\\times d$正交矩阵的集合），$\\mathbf{R}\\mathbf{z}$的分布与$\\mathbf{z}$的分布相同。\n- $SO(d)$上唯一的旋转不变概率测度是哈尔测度（紧群上的左右不变概率测度）。\n- 单位球面$S^{d-1}=\\{\\mathbf{x}\\in\\mathbb{R}^d:\\|\\mathbf{x}\\|_2=1\\}$上的一个球冠，其中心为单位向量$\\mathbf{u}\\in S^{d-1}$，半角为$\\theta\\in[0,\\pi]$（以弧度为单位），定义为$C(\\mathbf{u},\\theta)=\\{\\mathbf{x}\\in S^{d-1}:\\arccos(\\mathbf{u}^\\top \\mathbf{x})\\le \\theta\\}$，等价于$\\{\\mathbf{x}\\in S^{d-1}:\\mathbf{u}^\\top \\mathbf{x}\\ge \\cos\\theta\\}$。\n\n任务：\n- 基于上述原理，通过将$\\mathbb{R}^d$中的一个旋转不变分布转换为$S^{d-1}$上的一个分布，推导并论证一个在$S^{d-1}$上采样$\\mathbf{x}$的算法。\n- 利用哈尔测度的唯一性，推导一个对随机旋转$\\mathbf{R}\\in SO(d)$进行采样的实用程序。\n- 定义一个诊断方法，该方法通过将一个哈尔分布的随机旋转应用于$S^{d-1}$上的一个采样点集，并比较旋转前后的球冠计数。对于一组$m$个单位方向$\\{\\mathbf{u}_j\\}_{j=1}^m$和一个固定的半角$\\theta$，计算计数$c_{j}^{\\text{pre}}=\\sum_{i=1}^n \\mathbf{1}\\{\\mathbf{u}_j^\\top \\mathbf{x}^{(i)}\\ge \\cos\\theta\\}$和$c_{j}^{\\text{post}}=\\sum_{i=1}^n \\mathbf{1}\\{\\mathbf{u}_j^\\top (\\mathbf{R}\\mathbf{x}^{(i)})\\ge \\cos\\theta\\}$。构建一个标量检验统计量$T$，该统计量将所有球冠的差异汇总成一个单一、可解释的数值，以反映旋转不变性。您的统计量必须数值稳定，并考虑到采样可变性；角度以弧度为单位。\n\n实现要求：\n- 为保证可复现性，使用固定的伪随机种子$1729$。\n- 实现以下具体选择：\n  - 通过独立抽取$\\mathbf{z}^{(i)}\\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}_d)$并设置$\\mathbf{x}^{(i)}=\\mathbf{z}^{(i)}/\\|\\mathbf{z}^{(i)}\\|_2$来采样$\\mathbf{x}^{(i)}$。\n  - 使用与哈尔测度一致的方法采样$\\mathbf{R}\\in SO(d)$。\n  - 通过相同的球面采样方法，将球冠方向$\\mathbf{u}_j$采样为$S^{d-1}$上的独立单位向量。\n  - 定义诊断统计量如下。对于每个球冠$j$，令$\\widehat{p}_j=(c_j^{\\text{pre}}+c_j^{\\text{post}})/(2n)$，合并标准误估计为$s_j=\\sqrt{2\\widehat{p}_j(1-\\widehat{p}_j)/n}$。定义归一化差异$z_j = \\begin{cases} \\frac{|c_j^{\\text{pre}}/n - c_j^{\\text{post}}/n|}{s_j},  \\text{if } s_j > 0 \\\\ 0,  \\text{if } s_j = 0 \\end{cases}$，以及诊断量$T=\\max_{1\\le j\\le m} z_j$。\n\n测试套件：\n- 对于每个测试用例，输入参数为$(d,n,m,\\theta)$，角度以弧度为单位。使用以下5个用例来检验诊断方法在典型、边界和高维情况下的表现：\n  - 用例1：$(d,n,m,\\theta)=(3,10000,12,0.5)$。\n  - 用例2：$(d,n,m,\\theta)=(2,15000,16,0.2)$。\n  - 用例3：$(d,n,m,\\theta)=(10,12000,24,0.3)$。\n  - 用例4：$(d,n,m,\\theta)=(50,8000,40,0.25)$。\n  - 用例5：$(d,n,m,\\theta)=(5,300,10,0.4)$。\n- 为了保证各用例间的可复现性，使用固定的基础种子$1729$，并对于用例索引$k\\in\\{1,2,3,4,5\\}$，在用例$k$内部的所有随机性操作中使用种子$1729+k$。\n\n最终输出格式：\n- 您的程序必须输出一行，其中包含5个测试用例的诊断值列表$[T_1,T_2,T_3,T_4,T_5]$，格式为方括号内逗号分隔的列表。不允许有其他输出。", "solution": "该问题要求推导、论证并实现一种诊断方法，用于检验在$\\mathbb{R}^d$单位球面上均匀采样随机向量的算法的旋转不变性。解决方案根据指定的基本原理构建。\n\n### 1. 在单位球面$S^{d-1}$上的均匀采样\n在单位球面$S^{d-1} = \\{\\mathbf{x} \\in \\mathbb{R}^d : \\|\\mathbf{x}\\|_2 = 1\\}$上进行均匀采样的基本原理是标准多元正态分布的球面对称性。从标准正态分布$\\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$中抽取的随机向量$\\mathbf{z} \\in \\mathbb{R}^d$的概率密度函数为$f(\\mathbf{z}) = (2\\pi)^{-d/2}\\exp(-\\|\\mathbf{z}\\|_2^2/2)$。该密度函数仅依赖于向量的模长$\\|\\mathbf{z}\\|_2$，而与其方向无关。此性质被称为球面对称性。\n\n这种对称性意味着向量$\\mathbf{z}$的方向（由单位向量$\\mathbf{x} = \\mathbf{z} / \\|\\mathbf{z}\\|_2$给出）必然在$S^{d-1}$上均匀分布。为了形式化地说明这一点，考虑任意旋转矩阵$\\mathbf{R} \\in SO(d)$。由于$\\mathbf{z}$的分布是球面对称的，旋转后的向量$\\mathbf{Rz}$的分布与$\\mathbf{z}$的分布相同。旋转后向量的方向是$\\mathbf{Rz} / \\|\\mathbf{Rz}\\|_2$。由于旋转是等距变换，$\\|\\mathbf{Rz}\\|_2 = \\|\\mathbf{z}\\|_2$，因此新方向为$\\mathbf{R}(\\mathbf{z} / \\|\\mathbf{z}\\|_2) = \\mathbf{Rx}$。因为$\\mathbf{z}$和$\\mathbf{Rz}$的分布相同，所以它们对应方向向量$\\mathbf{x}$和$\\mathbf{Rx}$的分布也必须相同。在$S^{d-1}$上，唯一在所有旋转下保持不变的概率分布是均匀分布。因此，方向向量$\\mathbf{x}$在$S^{d-1}$上是均匀分布的。\n\n由此产生的算法，通常归功于 G. E. P. Box 和 M. E. Muller，如下所示：\n1. 生成一个$d$维向量$\\mathbf{z} = (z_1, z_2, \\ldots, z_d)^\\top$，其中每个分量$z_i$都是从标准正态分布$\\mathcal{N}(0, 1)$中独立抽取的。\n2. 计算欧几里得范数$\\|\\mathbf{z}\\|_2 = \\sqrt{\\sum_{i=1}^d z_i^2}$。对于连续分布，$\\mathbf{z} = \\mathbf{0}$的概率为$0$，因此$\\|\\mathbf{z}\\|_2  0$几乎必然成立。\n3. 在$S^{d-1}$上均匀分布的随机向量由归一化$\\mathbf{x} = \\mathbf{z} / \\|\\mathbf{z}\\|_2$给出。\n\n### 2. 从特殊正交群$SO(d)$中采样随机旋转\n任务要求根据其唯一的旋转不变概率测度——哈尔测度，从特殊正交群$SO(d)$中采样一个随机旋转矩阵$\\mathbf{R}$。一种标准且计算高效的方法是利用QR分解。\n\n设$\\mathbf{A}$是一个$d \\times d$矩阵，其元素是来自$\\mathcal{N}(0, 1)$的独立同分布(i.i.d.)随机变量。$\\mathbf{A}$的元素在$\\mathbb{R}^{d^2}$中的联合分布是球面对称的。$\\mathbf{A}$的QR分解将其表示为乘积$\\mathbf{A} = \\mathbf{QR}_{\\text{upper}}$，其中$\\mathbf{Q}$是一个正交矩阵($\\mathbf{Q}^\\top\\mathbf{Q} = \\mathbf{I}_d$)，$\\mathbf{R}_{\\text{upper}}$是一个上三角矩阵。可以证明，得到的矩阵$\\mathbf{Q}$在正交群$O(d)$上服从哈尔测度。\n\n群$O(d)$包含行列式等于$+1$或$-1$的矩阵。特殊正交群$SO(d)$是$O(d)$中只包含行列式为$+1$的矩阵的子群。要从$SO(d)$中获取样本，我们首先从$O(d)$中采样$\\mathbf{Q}$，然后在必要时将其映射到$SO(d)$。如果$\\det(\\mathbf{Q}) = +1$，那么$\\mathbf{Q}$已经在$SO(d)$中。如果$\\det(\\mathbf{Q}) = -1$，我们可以通过将任意一列（或行）乘以$-1$来将其转换为$SO(d)$的一个元素。这个操作会翻转行列式的符号，同时保持$SO(d)$上分布的哈尔测度性质。\n\n采样$\\mathbf{R} \\in SO(d)$的算法如下：\n1. 生成一个$d \\times d$矩阵$\\mathbf{A}$，其元素为来自$\\mathcal{N}(0, 1)$的独立同分布随机变量。\n2. 计算$\\mathbf{A}$的QR分解，得到正交矩阵$\\mathbf{Q}$。\n3. 计算行列式$s = \\det(\\mathbf{Q})$。\n4. 如果$s  0$，则将$\\mathbf{Q}$的第一列乘以$-1$，形成最终的旋转矩阵$\\mathbf{R}$。否则，设$\\mathbf{R} = \\mathbf{Q}$。\n\n### 3. 旋转不变性诊断统计量\n该诊断方法旨在验证在$S^{d-1}$上采样的点集$\\{\\mathbf{x}^{(i)}\\}_{i=1}^n$的旋转不变性。如果采样方法真正均匀，那么点集的统计特性在施加一个随机旋转$\\mathbf{R} \\sim \\text{Haar}(SO(d))$后应保持不变。\n\n我们通过测量落入$m$个固定球冠中的点的数量来探查点的分布。球冠$C_j$由一个中心方向$\\mathbf{u}_j \\in S^{d-1}$和一个半角$\\theta \\in [0, \\pi]$定义，使得$C_j = \\{\\mathbf{x} \\in S^{d-1} : \\mathbf{u}_j^\\top \\mathbf{x} \\ge \\cos\\theta\\}$。我们计算旋转前后的计数：\n- 旋转前球冠$j$的计数：$c_{j}^{\\text{pre}} = \\sum_{i=1}^n \\mathbf{1}\\{\\mathbf{u}_j^\\top \\mathbf{x}^{(i)} \\ge \\cos\\theta\\}$\n- 旋转后球冠$j$的计数：$c_{j}^{\\text{post}} = \\sum_{i=1}^n \\mathbf{1}\\{\\mathbf{u}_j^\\top (\\mathbf{R}\\mathbf{x}^{(i)}) \\ge \\cos\\theta\\}$\n\n对于每个球冠$j$，我们有两个样本比例，$\\hat{p}_j^{\\text{pre}} = c_{j}^{\\text{pre}}/n$和$\\hat{p}_j^{\\text{post}} = c_{j}^{\\text{post}}/n$。零假设$H_0$是，底层的采样分布是旋转不变的，这意味着一个点落入球冠$C_j$的真实概率$p_j$对于原始点集和旋转后点集是相同的。这是一个关于比例相等的双样本检验。\n\n诊断统计量$T$的构建如下：\n1. 在$H_0$下，共同比例$p_j$的最佳估计是合并比例：$\\widehat{p}_j = (c_j^{\\text{pre}} + c_j^{\\text{post}}) / (2n)$。\n2. 两个样本比例之差$\\hat{p}_j^{\\text{pre}} - \\hat{p}_j^{\\text{post}}$的方差使用合并比例进行估计。这个差值的标准误由$s_j = \\sqrt{\\frac{\\widehat{p}_j(1-\\widehat{p}_j)}{n} + \\frac{\\widehat{p}_j(1-\\widehat{p}_j)}{n}} = \\sqrt{2\\widehat{p}_j(1-\\widehat{p}_j)/n}$给出。\n3. 每个球冠的归一化差异，或称Z值，为$z_j = \\frac{|\\hat{p}_j^{\\text{pre}} - \\hat{p}_j^{\\text{post}}|}{s_j} = \\frac{|c_j^{\\text{pre}}/n - c_j^{\\text{post}}/n|}{s_j}$。如果$s_j=0$（当$\\widehat{p}_j$为$0$或$1$时发生），则分子也为$0$，我们定义$z_j = 0$。对于大样本$n$，$z_j$在$H_0$下近似服从半正态分布。\n4. 为了将所有$m$个球冠的结果汇总成一个单一数值，诊断量被定义为观测到的最大Z值：$T = \\max_{1 \\le j \\le m} z_j$。一个大的$T$值表明在至少一个测试的球冠方向上存在与旋转不变性的显著偏离，从而对采样方法的均匀性提出质疑。由于指定的采样方法在理论上是可靠的，我们预期$T$值会很小，与随机波动一致。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_diagnostic_case(d, n, m, theta, seed):\n    \"\"\"\n    Runs the rotational invariance diagnostic for a single test case.\n\n    Args:\n        d (int): Dimension of the space.\n        n (int): Number of points to sample on the sphere.\n        m (int): Number of spherical caps to use for the test.\n        theta (float): Half-angle of the spherical caps in radians.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        float: The computed diagnostic statistic T.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Helper function to sample k points uniformly on the unit sphere S^(d-1)\n    def sample_sphere(k, dim, random_state):\n        z = random_state.standard_normal(size=(k, dim))\n        norm = np.linalg.norm(z, axis=1, keepdims=True)\n        # Avoid division by zero, though Pr(norm=0) is 0 for continuous dist.\n        norm[norm == 0] = 1.0\n        return z / norm\n\n    # 1. Sample n data points X on S^(d-1)\n    X = sample_sphere(n, d, rng)\n\n    # 2. Sample m cap directions U on S^(d-1)\n    U = sample_sphere(m, d, rng)\n\n    # 3. Sample a random rotation R from SO(d) via QR decomposition\n    A = rng.standard_normal(size=(d, d))\n    Q, _ = np.linalg.qr(A)\n    # Ensure determinant is +1 for SO(d)\n    if np.linalg.det(Q)  0:\n        Q[:, 0] *= -1\n    R = Q\n\n    # 4. Apply the rotation to the data points\n    # For row vectors x in X, the rotated vectors are x @ R.T\n    RX = X @ R.T\n\n    # 5. Compute the diagnostic statistic T\n    cos_theta = np.cos(theta)\n\n    # Vectorized computation of counts\n    # Dot products for pre-rotation points: X @ U.T gives an (n, m) matrix\n    dot_pre = X @ U.T\n    # Dot products for post-rotation points: RX @ U.T gives an (n, m) matrix\n    dot_post = RX @ U.T\n\n    # Counts for each cap (sum over points axis=0) -> vector of size m\n    c_pre_vec = np.sum(dot_pre >= cos_theta, axis=0)\n    c_post_vec = np.sum(dot_post >= cos_theta, axis=0)\n\n    # Pooled proportion estimate for each cap\n    p_hat_vec = (c_pre_vec + c_post_vec) / (2 * n)\n    \n    # Pooled standard error estimate for each cap\n    # The term inside sqrt can be negative due to float precision, so clip at 0.\n    s_vec_numerator = 2 * p_hat_vec * (1 - p_hat_vec) / n\n    s_vec = np.sqrt(np.maximum(0, s_vec_numerator))\n\n    # Difference in proportions for each cap\n    diff_vec = np.abs(c_pre_vec / n - c_post_vec / n)\n\n    # Normalized differences (z-scores)\n    z_vec = np.zeros_like(s_vec)\n    # Avoid division by zero where s_vec is 0\n    # If s_vec is 0, p_hat is 0 or 1, meaning c_pre and c_post were same (0 or n)\n    # so diff_vec is also 0. z_j=0 is correct in this case.\n    nonzero_s_mask = s_vec > 0\n    z_vec[nonzero_s_mask] = diff_vec[nonzero_s_mask] / s_vec[nonzero_s_mask]\n\n    # The final diagnostic is the maximum z-score\n    T = np.max(z_vec)\n    return T\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (d, n, m, theta)\n        (3, 10000, 12, 0.5),   # Case 1\n        (2, 15000, 16, 0.2),   # Case 2\n        (10, 12000, 24, 0.3),  # Case 3\n        (50, 8000, 40, 0.25),  # Case 4\n        (5, 300, 10, 0.4),     # Case 5\n    ]\n    \n    base_seed = 1729\n    results = []\n\n    for i, case in enumerate(test_cases):\n        d, n, m, theta = case\n        case_seed = base_seed + (i + 1)\n        # Using numpy 1.23.5, np.random.seed is legacy. Use default_rng.\n        # The behavior for a given seed is consistent.\n        T = run_diagnostic_case(d, n, m, theta, case_seed)\n        results.append(T)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3337173"}, {"introduction": "掌握了高斯归一化方法后，一个自然的问题是：是否存在其他方法？它们各自有何优劣？本综合练习将引导你实现并对比三种用于球体采样的代表性算法：直接的高斯归一化、基于群论的哈尔（Haar）旋转，以及迭代的马尔可夫链蒙特卡洛（MCMC）方法——“碰撞与运行”（Hit-and-Run）。通过对这些算法的统计准确性、数值稳定性和计算成本进行量化评估，你将对算法设计中的权衡有更深刻的认识。这项实践旨在培养你在面对仿真任务时，能够根据具体需求（如精度、速度、维度）选择最合适工具的专业判断力。[@problem_id:3337225]", "problem": "你需要实现并比较三种随机采样器，用于在单位球面 $\\mathbb{S}^{d-1} \\subset \\mathbb{R}^{d}$ 上生成随机向量。这三种方法是：\n\n1.  哈尔旋转采样器：根据不变哈尔测度抽取一个随机旋转矩阵 $R \\in \\mathrm{SO}(d)$，并输出 $\\mathbf{x} = R \\mathbf{e}_{1}$，其中 $\\mathbf{e}_{1}$ 是 $\\mathbb{R}^{d}$ 中的第一个标准基向量。\n2.  归一化高斯采样器：抽取 $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, I_{d})$ 并输出 $\\mathbf{x} = \\mathbf{z} / \\lVert \\mathbf{z} \\rVert_{2}$。\n3.  球面上的Hit-and-run（命中-脱离）采样器：在 $\\mathbb{S}^{d-1}$ 上构造一个可逆马尔可夫链，其平稳分布为球面上的均匀分布。从 $\\mathbf{x}_{0} = \\mathbf{e}_{1}$ 开始，在每一步于 $\\mathbf{x}_{t}$ 处的切空间中采样一个随机方向，然后移动到由 $\\mathbf{x}_{t}$ 和该方向确定的大圆上的一个均匀选择的点。\n\n从适用于随机模拟和蒙特卡洛方法的基本原理出发，你的程序必须：\n\n- 实现所有三种采样器。\n- 对于每种采样器和下面的每个测试用例，生成所请求数量的样本，并计算以下诊断指标：\n  - 均匀性诊断 A（一维柯尔莫哥洛夫-斯米尔诺夫统计量）：如果 $\\mathbf{x} = (x_{1}, \\dots, x_{d})$ 在 $\\mathbb{S}^{d-1}$ 上均匀分布，那么 $x_1$ 在 $[-1,1]$ 上的密度与 $(1 - s^{2})^{(d-3)/2}$ 成正比，等价地，$Y = (x_{1}+1)/2$ 服从参数为 $\\left(\\frac{d-1}{2}, \\frac{d-1}{2}\\right)$ 的Beta分布。计算 $x_1$ 值样本与此理论分布之间的经验柯尔莫哥洛夫-斯米尔诺夫统计量，该统计量表示为经验累积分布函数与由正则化不完全贝塔函数给出的理论累积分布函数之间绝对差的上确界。\n  - 均匀性诊断 B（协方差各向同性）：对于 $\\mathbb{S}^{d-1}$ 上的均匀分布，$\\mathbb{E}[\\mathbf{x}] = \\mathbf{0}$ 且 $\\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}] = \\frac{1}{d} I_{d}$。计算经验协方差矩阵 $\\widehat{\\Sigma} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{x}_{i}\\mathbf{x}_{i}^{\\top} - \\widehat{\\mu}\\widehat{\\mu}^{\\top}$（其中 $\\widehat{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{x}_{i}$），并报告弗罗贝尼乌斯范数 $\\lVert \\widehat{\\Sigma} - \\frac{1}{d} I_{d} \\rVert_{\\mathrm{F}}$。\n  - 数值稳定性度量：报告平均绝对范数误差 $\\frac{1}{n}\\sum_{i=1}^{n} \\lvert \\lVert \\mathbf{x}_{i} \\rVert_{2} - 1 \\rvert$ 和最大绝对范数误差 $\\max_{1 \\le i \\le n} \\lvert \\lVert \\mathbf{x}_{i} \\rVert_{2} - 1 \\rvert$。\n- 使用每个样本的两个确定性代理指标比较计算成本：\n  - 每个样本的随机变量数（按设计精确计数）：\n    - 归一化高斯：$d$ 个独立标准正态变量。\n    - 通过一个 $d \\times d$ 标准高斯矩阵的 $QR$ 分解实现的哈尔旋转 $R \\in \\mathrm{SO}(d)$：$d^{2}$ 个独立标准正态变量。\n    - 球面上的Hit-and-run，稀疏化参数为 $s$（每个保留样本的步数等于 $s+1$）：每一步使用 $d$ 个独立标准正态变量来确定方向，以及一个在 $[-\\pi,\\pi]$ 上的独立均匀变量来确定角度（角度以弧度为单位）。因此，每个保留样本总共需要 $(s+1) (d + 1)$ 个随机变量。\n  - 浮点运算代理（每个样本的flop单位数，相差一个比例常数）：\n    - 归一化高斯：$3d$ 单位（范数计算和归一化）。\n    - 通过 $QR$ 的哈尔旋转：$\\frac{2}{3} d^{3}$ 单位（主要的 $QR$ 分解成本）。\n    - 带稀疏化参数 $s$ 的Hit-and-run：$7d (s+1)$ 单位（每步的切空间投影、归一化和旋转更新）。\n  这些代理指标用于确定性地比较计算成本，而不依赖于实际运行时间。\n\n实现约束和定义：\n\n- 使用定义球面和特殊正交群 $\\mathrm{SO}(d)$ 上均匀性的不变性原理作为你的基本依据。除了基本的线性代数和随机变量生成外，不要使用任何直接从 $\\mathrm{SO}(d)$ 或球面上采样的预封装例程。\n- 对于哈尔采样器，通过对一个具有独立标准正态分布条目的 $d \\times d$ 矩阵进行 $QR$ 分解来生成 $R$，调整列的符号以使 $R$ 的对角线为正，如果 $\\det(Q) = -1$，则翻转一列以获得 $\\det(Q) = +1$；然后返回 $\\mathbf{x} = Q \\mathbf{e}_{1}$。\n- 对于球面上的hit-and-run采样器，从 $\\mathbf{x}$ 开始的每一步：\n  1.  抽取 $\\mathbf{v} \\sim \\mathcal{N}(\\mathbf{0}, I_{d})$，设置切线方向 $\\mathbf{u} = \\mathbf{v} - (\\mathbf{v}^{\\top}\\mathbf{x}) \\mathbf{x}$，并归一化 $\\mathbf{u} \\leftarrow \\mathbf{u} / \\lVert \\mathbf{u} \\rVert_{2}$。\n  2.  以弧度为单位抽取 $\\phi \\sim \\mathrm{Uniform}([-\\pi,\\pi])$ 并设置下一个状态 $\\mathbf{x}^{\\prime} = \\cos(\\phi)\\,\\mathbf{x} + \\sin(\\phi)\\,\\mathbf{u}$，该点位于 $\\mathbb{S}^{d-1}$ 上。\n  3.  按照指定的预烧期和稀疏化计划重复。\n\n测试套件：\n\n你的程序必须使用固定的伪随机种子 $20231011$ 运行以下三个测试用例，以确保可复现性。对于每个用例，使用指定的维度 $d$、每种采样器的样本数量，以及hit-and-run的预烧期和稀疏化参数：\n\n- 用例 A: $d = 3$，归一化高斯采样器 $n_{\\mathrm{G}} = 20000$，哈尔采样器 $n_{\\mathrm{H}} = 1500$，hit-and-run采样器 $n_{\\mathrm{HR}} = 20000$，预烧期 $b = 2000$，稀疏化 $s = 2$。\n- 用例 B: $d = 10$，归一化高斯采样器 $n_{\\mathrm{G}} = 20000$，哈尔采样器 $n_{\\mathrm{H}} = 800$，hit-and-run采样器 $n_{\\mathrm{HR}} = 20000$，预烧期 $b = 3000$，稀疏化 $s = 5$。\n- 用例 C (小样本边缘情况): $d = 3$，归一化高斯采样器 $n_{\\mathrm{G}} = 400$，哈尔采样器 $n_{\\mathrm{H}} = 60$，hit-and-run采样器 $n_{\\mathrm{HR}} = 400$，预烧期 $b = 50$，稀疏化 $s = 1$。\n\n要求的输出：\n\n- 对于每个测试用例，为每个采样器计算一个包含六个浮点数的向量：\n  - $S_{\\mathrm{KS}}$：$x_1$ 经由 $y = \\frac{x_1+1}{2}$ 从 $[-1,1]$ 映射到 $[0,1]$ 后，与 $\\mathrm{Beta}\\!\\left(\\tfrac{d-1}{2}, \\tfrac{d-1}{2}\\right)$ 模型的柯尔莫哥洛夫-斯米尔诺夫统计量。\n  - $E_{\\mathrm{cov}}$：弗罗贝尼乌斯范数 $\\lVert \\widehat{\\Sigma} - \\tfrac{1}{d} I_{d} \\rVert_{\\mathrm{F}}$。\n  - $\\overline{E}_{\\mathrm{norm}}$：平均绝对范数误差。\n  - $E_{\\mathrm{norm}}^{\\max}$：最大绝对范数误差。\n  - $N_{\\mathrm{rv}}$：每个样本的理论随机变量数（如上文指定的精确计数）。\n  - $C_{\\mathrm{flop}}$：每个样本的flop单位代理数（如上文指定）。\n- 最终的程序输出必须是单行，包含一个长度为 $3$ 的列表（对应三个测试用例）。每个元素本身是一个长度为 $3$ 的列表（按归一化高斯、哈尔、hit-and-run的顺序排列），每个采样器的条目是按上述顺序排列的包含 $6$ 个浮点数的列表。该行必须格式化为逗号分隔的列表，不含空格，例如：\n  \"[[...[六个浮点数]...,[...[六个浮点数]...,[...[六个浮点数]...]],[...],[...]]\"。你的程序必须精确地产生这样一行输出，无其他内容。\n\n角度必须以弧度为单位。此问题中没有物理单位。\n\n所有随机数生成必须使用固定的种子 $20231011$ 来执行，以确保确定性的可复现性。\n\n你提交的必须是最终答案部分指定的完整、可运行的程序。", "solution": "在单位球面 $\\mathbb{S}^{d-1} = \\{\\mathbf{x} \\in \\mathbb{R}^d : \\lVert\\mathbf{x}\\rVert_2 = 1\\}$ 上生成均匀分布的随机向量问题是随机模拟、计算物理学和统计学中的一个基本任务。球面上均匀分布的定义性属性是其旋转不变性：如果 $\\mathbf{x}$ 在 $\\mathbb{S}^{d-1}$ 上均匀分布，那么对于任何正交变换 $M \\in \\mathrm{O}(d)$，向量 $M\\mathbf{x}$ 的分布与 $\\mathbf{x}$ 相同。下文介绍了三种不同采样方法的理论基础和算法实现，随后描述了用于评估其质量和成本的诊断指标。\n\n**1. 归一化高斯采样器**\n\n此方法利用了标准多元正态分布的球对称性。\n\n*   **原理：** 从 $\\mathbb{R}^d$ 中的标准正态分布（表示为 $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, I_d)$）抽取的随机向量 $\\mathbf{z} = (z_1, \\dots, z_d)^\\top$ 的概率密度函数为 $p(\\mathbf{z}) = (2\\pi)^{-d/2} \\exp(-\\frac{1}{2} \\mathbf{z}^\\top \\mathbf{z})$。该密度仅取决于向量的欧几里得范数的平方 $\\lVert \\mathbf{z} \\rVert_2^2$。对于任何旋转矩阵 $R \\in \\mathrm{SO}(d)$，有 $\\lVert R\\mathbf{z} \\rVert_2 = \\lVert \\mathbf{z} \\rVert_2$，这意味着 $\\mathbf{z}$ 的分布是旋转不变的。此不变性属性被传递到归一化向量 $\\mathbf{x} = \\mathbf{z} / \\lVert \\mathbf{z} \\rVert_2$。由于 $\\mathbf{x}$ 的分布在旋转下是不变的，且其支撑集为 $\\mathbb{S}^{d-1}$，因此它必定是球面上的均匀分布。\n\n*   **算法：**\n    1.  生成一个向量 $\\mathbf{z} \\in \\mathbb{R}^d$，其中每个分量 $z_i$ 是从标准正态分布 $\\mathcal{N}(0, 1)$ 中独立抽取的样本。\n    2.  计算欧几里得范数 $r = \\lVert \\mathbf{z} \\rVert_2$。以概率 $1$ 成立的条件是 $r  0$。\n    3.  得到的样本是归一化向量 $\\mathbf{x} = \\frac{1}{r} \\mathbf{z}$。\n\n**2. 哈尔旋转采样器**\n\n此方法依赖于特殊正交群 $\\mathrm{SO}(d)$ 在球面上的群作用。\n\n*   **原理：** 旋转群 $\\mathrm{SO}(d)$ 可传递地作用于球面 $\\mathbb{S}^{d-1}$，这意味着球面上的任何一点都可以通过旋转从任何其他点到达。群论中的一个基本结果指出，$\\mathrm{SO}(d)$ 拥有一个唯一的概率测度，即哈尔测度，它在群乘法（即旋转）下是不变的。如果从这个哈尔测度中采样一个旋转矩阵 $R$，并将其应用于任何固定的单位向量（例如第一个标准基向量 $\\mathbf{e}_1 = (1, 0, \\dots, 0)^\\top$），则得到的向量 $\\mathbf{x} = R \\mathbf{e}_1$ 保证在 $\\mathbb{S}^{d-1}$ 上均匀分布。\n\n*   **算法：** 生成一个哈尔分布的正交矩阵的标准方法是对一组 $d$ 个线性无关的向量应用格拉姆-施密特过程。如题目所指定，一种数值上稳定的方法是通过QR分解。\n    1.  生成一个 $d \\times d$ 矩阵 $A$，其条目独立地从 $\\mathcal{N}(0, 1)$ 中抽取。其列的联合分布是球对称的。\n    2.  执行QR分解 $A = QR$，其中 $Q$ 是一个正交矩阵（$Q^\\top Q = I_d$），$R$ 是一个上三角矩阵。矩阵 $Q$ 根据正交群 $\\mathrm{O}(d)$ 上的哈尔测度分布。\n    3.  为了确保分解的唯一性并得到一个在 $\\mathrm{SO}(d)$ 中的矩阵（旋转，而非反射），我们进行两次调整。首先，对于 $Q$ 的每一列 $i$，如果对应的对角元素 $R_{ii}$ 为负，我们将 $Q$ 的第 $i$ 列和 $R$ 的第 $i$ 行乘以 $-1$。这使得 $R$ 的所有对角线元素都为非负，而不改变乘积 $QR$。\n    4.  其次，我们计算调整后的 $Q$ 的行列式。如果 $\\det(Q) = -1$，则该矩阵表示一个反射。我们通过将其一列（例如第一列）乘以 $-1$ 将其转换为旋转。这样得到一个同样是哈尔分布的矩阵 $Q' \\in \\mathrm{SO}(d)$。\n    5.  样本是最终旋转矩阵的第一列，即 $\\mathbf{x} = Q' \\mathbf{e}_1$。\n\n**3. 球面上的Hit-and-run（命中-脱离）**\n\n这是一种马尔可夫链蒙特卡洛（MCMC）方法，它在球面上构造一个随机游走，其平衡分布是所需的目标均匀分布。\n\n*   **原理：** 该算法在 $\\mathbb{S}^{d-1}$ 上构造一个可逆马尔可夫链。如果转移核 $P(\\mathbf{x}, A) = \\int_A p(\\mathbf{x}, \\mathbf{y}) d\\sigma(\\mathbf{y})$ 满足细致平衡条件：对于所有 $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{S}^{d-1}$ 都有 $p(\\mathbf{x}, \\mathbf{y}) = p(\\mathbf{y}, \\mathbf{x})$，则球面上的均匀分布 $\\sigma$ 是该链的平稳分布。所指定的采样器通过提议移动到一个新点来满足此条件，该新点是从通过当前点 $\\mathbf{x}_t$ 并沿随机选择方向的大圆上均匀选择的。由于大圆的选择和其上点的选择是对称的，该过程是可逆的，并收敛到均匀分布。\n\n*   **算法：** 从初始点 $\\mathbf{x}_0 = \\mathbf{e}_1$ 开始，每一步 $t \\to t+1$ 按如下方式进行：\n    1.  生成一个随机方向向量 $\\mathbf{v} \\sim \\mathcal{N}(\\mathbf{0}, I_d)$。\n    2.  这个方向被投影到当前点 $\\mathbf{x}_t$ 的切空间上。切空间是与 $\\mathbf{x}_t$ 正交的超平面。投影由 $\\mathbf{v}_{\\perp} = \\mathbf{v} - (\\mathbf{v}^\\top \\mathbf{x}_t) \\mathbf{x}_t$ 给出。$\\mathbf{v}$ 的球对称性确保了得到的切线方向是均匀的。\n    3.  归一化切线方向：$\\mathbf{u} = \\mathbf{v}_{\\perp} / \\lVert \\mathbf{v}_{\\perp} \\rVert_2$。\n    4.  向量 $\\mathbf{x}_t$ 和 $\\mathbf{u}$ 是标准正交的，并定义一个大圆。通过沿此圆移动一个随机角度来选择一个新点。从 $[-\\pi, \\pi]$ 上的均匀分布中采样一个角度 $\\phi$。\n    5.  下一个状态是 $\\mathbf{x}_{t+1} = \\cos(\\phi) \\mathbf{x}_t + \\sin(\\phi) \\mathbf{u}$。根据构造，$\\lVert \\mathbf{x}_{t+1} \\rVert_2 = 1$。\n    该链运行一个“预烧期”（$b$ 步），使其接近平稳分布。随后，以“稀疏化”间隔 $s$ 收集样本，意味着每 $s+1$ 步存储一个样本，以减少它们之间的自相关。\n\n**诊断指标与成本代理**\n\n为评估采样器，我们计算一组诊断指标和确定性成本代理。\n\n*   **均匀性诊断 A ($S_{\\mathrm{KS}}$):** 如果 $\\mathbf{x} = (x_1, \\dots, x_d)$ 在 $\\mathbb{S}^{d-1}$ 上均匀分布，其第一个分量 $x_1$ 在 $[-1, 1]$ 上有一个特定的边际分布，其密度与 $(1-t^2)^{(d-3)/2}$ 成正比。变换后的变量 $Y = (x_1+1)/2$ 服从 $\\mathrm{Beta}(\\frac{d-1}{2}, \\frac{d-1}{2})$ 分布。柯尔莫哥洛夫-斯米尔诺夫统计量 $S_{\\mathrm{KS}}$ 衡量样本的经验累积分布函数（CDF）与理论Beta CDF之间的最大差异。值越小表示一致性越好。\n\n*   **均匀性诊断 B ($E_{\\mathrm{cov}}$):** 对于 $\\mathbb{S}^{d-1}$ 上的均匀分布，理论期望为 $\\mathbb{E}[\\mathbf{x}] = \\mathbf{0}$，协方差矩阵是各向同性的：$\\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] = \\frac{1}{d}I_d$。我们计算样本均值 $\\widehat{\\mu}$ 和样本协方差矩阵 $\\widehat{\\Sigma}$，并报告差异的弗罗贝尼乌斯范数，$E_{\\mathrm{cov}} = \\lVert \\widehat{\\Sigma} - \\frac{1}{d}I_d \\rVert_{\\mathrm{F}}$。值越小表示样本的二阶矩与理论值越接近。\n\n*   **数值稳定性 ($\\overline{E}_{\\mathrm{norm}}$, $E_{\\mathrm{norm}}^{\\max}$):** 根据定义，所有样本都应位于球面上，即范数为 $1$。计算与 $1$ 的平均和最大绝对偏差 $\\lvert \\lVert \\mathbf{x}_i \\rVert_2 - 1 \\rvert$，以评估数值误差。\n\n*   **计算成本 ($N_{\\mathrm{rv}}$, $C_{\\mathrm{flop}}$):** 我们不使用实际运行时间，而是使用确定性代理。$N_{\\mathrm{rv}}$ 统计每个样本所需的随机变量数量（例如，来自 $\\mathcal{N}(0,1)$ 或 $\\mathrm{Uniform}$）。$C_{\\mathrm{flop}}$ 是浮点运算次数的代理，根据每种算法的主要计算步骤进行缩放。这些为计算开销提供了一个标准化的比较。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import beta as beta_dist\nimport json\n\ndef get_diagnostics(samples, d):\n    \"\"\"\n    Computes a vector of diagnostics for a given set of samples.\n    Args:\n        samples (np.ndarray): An (n, d) array of n samples in d dimensions.\n        d (int): The dimension.\n    Returns:\n        tuple: (ks_stat, cov_error, mean_norm_error, max_norm_error)\n    \"\"\"\n    n = samples.shape[0]\n    if n == 0:\n        return 0.0, 0.0, 0.0, 0.0\n\n    # Uniformity Diagnostic A: Kolmogorov-Smirnov statistic\n    # The first coordinate x_1 transformed as y = (x_1+1)/2 follows a Beta distribution.\n    x1_samples = samples[:, 0]\n    y_samples = (x1_samples + 1) / 2\n    y_samples.sort()\n    \n    alpha = (d - 1) / 2\n    # For d=1, alpha=0, which is invalid for Beta. But d>=2 always in these cases.\n    cdf_vals = beta_dist.cdf(y_samples, alpha, alpha)\n    \n    i = np.arange(1, n + 1)\n    d_plus = np.max(i / n - cdf_vals) if n > 0 else 0\n    d_minus = np.max(cdf_vals - (i - 1) / n) if n > 0 else 0\n    ks_stat = np.max([d_plus, d_minus])\n    \n    # Uniformity Diagnostic B: Covariance isotropy\n    mu_hat = np.mean(samples, axis=0)\n    mu_hat_reshaped = mu_hat.reshape(-1, 1)\n    sigma_hat = (samples.T @ samples) / n - mu_hat_reshaped @ mu_hat_reshaped.T\n        \n    Id = np.eye(d)\n    cov_error = np.linalg.norm(sigma_hat - (1/d) * Id, 'fro')\n\n    # Numerical Stability Metrics\n    norms = np.linalg.norm(samples, axis=1)\n    abs_norm_errors = np.abs(norms - 1)\n    mean_norm_error = np.mean(abs_norm_errors)\n    max_norm_error = np.max(abs_norm_errors)\n\n    return ks_stat, cov_error, mean_norm_error, max_norm_error\n\ndef normalized_gaussian_sampler(d, n, rng):\n    \"\"\"Normalized Gaussian sampler.\"\"\"\n    z = rng.standard_normal(size=(n, d))\n    norms = np.linalg.norm(z, axis=1, keepdims=True)\n    # Avoid division by zero, although it has probability zero.\n    norms[norms == 0] = 1.0 \n    return z / norms\n\ndef haar_rotation_sampler(d, n, rng):\n    \"\"\"Haar-rotation sampler via QR decomposition.\"\"\"\n    samples = np.zeros((n, d))\n    for i in range(n):\n        A = rng.standard_normal(size=(d, d))\n        Q, R = np.linalg.qr(A)\n        \n        # Adjust signs so diagonal of R is positive\n        s_diag = np.diag(np.sign(np.diag(R)))\n        Q = Q @ s_diag\n        \n        # Ensure determinant is +1\n        if np.linalg.det(Q)  0:\n            Q[:, 0] = -Q[:, 0]\n            \n        samples[i] = Q[:, 0]\n    return samples\n\ndef hit_and_run_sampler(d, n, burn_in, thinning, rng):\n    \"\"\"Hit-and-run sampler on the sphere.\"\"\"\n    samples = np.zeros((n, d))\n    \n    # Initial state\n    x = np.zeros(d)\n    x[0] = 1.0\n\n    total_steps = burn_in + n * (thinning + 1)\n    sample_idx = 0\n    \n    for i in range(total_steps):\n        # 1. Get random tangent direction\n        v = rng.standard_normal(size=d)\n        u = v - np.dot(v, x) * x\n        u_norm = np.linalg.norm(u)\n        if u_norm  1e-15: # Highly unlikely event\n            # if v is parallel to x, u is zero. Stay put.\n            pass\n        else:\n            u /= u_norm\n        \n            # 2. Move along great circle\n            phi = rng.uniform(-np.pi, np.pi)\n            x = np.cos(phi) * x + np.sin(phi) * u\n        \n        # 3. Store sample after burn-in and thinning\n        if i >= burn_in and (i - burn_in) % (thinning + 1) == thinning:\n            if sample_idx  n:\n                samples[sample_idx] = x\n                sample_idx += 1\n                \n    return samples\n\ndef solve():\n    # Fixed seed for reproducibility\n    rng = np.random.default_rng(20231011)\n\n    # Test cases: (d, n_G, n_H, n_HR, burn_in, thinning)\n    test_cases = [\n        (3, 20000, 1500, 20000, 2000, 2),\n        (10, 20000, 800, 20000, 3000, 5),\n        (3, 400, 60, 400, 50, 1)\n    ]\n\n    all_results = []\n    \n    for d, n_g, n_h, n_hr, b, s in test_cases:\n        case_results = []\n\n        # 1. Normalized Gaussian Sampler\n        samples_g = normalized_gaussian_sampler(d, n_g, rng)\n        ks_g, cov_g, mean_err_g, max_err_g = get_diagnostics(samples_g, d)\n        n_rv_g = float(d)\n        c_flop_g = float(3 * d)\n        case_results.append([ks_g, cov_g, mean_err_g, max_err_g, n_rv_g, c_flop_g])\n        \n        # 2. Haar Rotation Sampler\n        samples_h = haar_rotation_sampler(d, n_h, rng)\n        ks_h, cov_h, mean_err_h, max_err_h = get_diagnostics(samples_h, d)\n        n_rv_h = float(d**2)\n        c_flop_h = float((2/3) * d**3)\n        case_results.append([ks_h, cov_h, mean_err_h, max_err_h, n_rv_h, c_flop_h])\n\n        # 3. Hit-and-Run Sampler\n        samples_hr = hit_and_run_sampler(d, n_hr, b, s, rng)\n        ks_hr, cov_hr, mean_err_hr, max_err_hr = get_diagnostics(samples_hr, d)\n        n_rv_hr = float((s + 1) * (d + 1))\n        c_flop_hr = float(7 * d * (s + 1))\n        case_results.append([ks_hr, cov_hr, mean_err_hr, max_err_hr, n_rv_hr, c_flop_hr])\n        \n        all_results.append(case_results)\n    \n    # Format the final output string exactly as required\n    print(json.dumps(all_results, separators=(',', ':')))\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3337225"}]}