{"hands_on_practices": [{"introduction": "这个首次实践是一项基础练习。通过使用一个给定的随机数手动追踪反演算法的每一步，你将具体理解累积概率检验如何将一个均匀分布的随机数转换为离散的泊松样本。在进入自动化生成和验证之前，这项基础技能至关重要。[@problem_id:3329682]", "problem": "考虑使用来自 $(0,1)$ 上连续均匀分布的单个实现值 $U$，通过逆变换法生成一个速率参数为 $\\lambda$ 的泊松分布随机变量。从基本原理出发：泊松分布的概率质量函数 (PMF) 为 $p(k)=\\mathbb{P}(X=k)$，累积分布函数 (CDF) 为 $F(k)=\\mathbb{P}(X\\le k)=\\sum_{j=0}^{k}p(j)$。当 $U\\sim\\text{Uniform}(0,1)$ 时，逆变换原理通过 $X=\\min\\{k\\in\\mathbb{Z}_{\\ge 0}:F(k)\\ge U\\}$ 定义了一个随机变量 $X$。\n\n任务：基于上述基本定义，推导一个操作最简的逆变换序列，该序列：\n- 从基础概率 $p(0)$ 开始，该概率等于零事件的概率，并且\n- 仅使用通过连续 PMF 项的比率获得的相邻 PMF 值之间的乘法更新，来更新 $p(k)$ 和运行中的 CDF $F(k)$，\n- 采用一个根据 $U$ 和运行中的 CDF 构建的停止准则，在满足逆变换定义的第一个 $k$ 值处停止。\n\n然后，将您推导的过程应用于 $\\lambda=7.3$ 和给定的均匀分布随机变量 $U=0.513$ 的具体情况，并执行该序列直至满足停止准则。将返回的样本 $X$ 报告为单个整数。无需四舍五入，也无需单位。", "solution": "推导过程从概率质量函数 (PMF)、累积分布函数 (CDF) 和逆变换原理的定义开始。对于速率为 $\\lambda$ 的泊松随机变量，其 PMF 为\n$$\np(k)=\\mathbb{P}(X=k)=\\exp(-\\lambda)\\frac{\\lambda^{k}}{k!},\\quad k\\in\\mathbb{Z}_{\\ge 0}.\n$$\nCDF 为\n$$\nF(k)=\\sum_{j=0}^{k}p(j).\n$$\n根据逆变换原理，对于 $U\\sim\\text{Uniform}(0,1)$，随机变量\n$$\nX=\\min\\{k\\in\\mathbb{Z}_{\\ge 0}:\\,F(k)\\ge U\\}\n$$\n服从期望的分布，因为\n$$\n\\mathbb{P}(X\\le k)=\\mathbb{P}\\big(U\\le F(k)\\big)=F(k),\n$$\n利用了对于 $U\\sim\\text{Uniform}(0,1)$，当 $t\\in[0,1]$ 时有 $\\mathbb{P}(U\\le t)=t$ 这一事实。\n\n为了获得一个操作最简的逆变换序列，我们通过利用连续 PMF 值的比率来避免在每一步重新计算阶乘或幂：\n$$\n\\frac{p(k)}{p(k-1)}=\\frac{\\exp(-\\lambda)\\lambda^{k}/k!}{\\exp(-\\lambda)\\lambda^{k-1}/(k-1)!}=\\frac{\\lambda}{k},\\quad k\\ge 1.\n$$\n这得出了乘法更新式\n$$\np(k)=p(k-1)\\frac{\\lambda}{k},\\quad k\\ge 1,\n$$\n其初始值为基础概率\n$$\np(0)=\\exp(-\\lambda).\n$$\n为 CDF 定义一个运行中的部分和，\n$$\nF(k)=F(k-1)+p(k),\\quad F(-1)=0,\n$$\n因此，程序步骤如下：\n- 初始化 $k\\leftarrow 0$, $p\\leftarrow \\exp(-\\lambda)$, $F\\leftarrow p$。\n- 当 $UF$ 时，递增 $k\\leftarrow k+1$，更新 $p\\leftarrow p\\cdot \\lambda/k$，并更新 $F\\leftarrow F+p$。\n- 在第一个满足 $U\\le F$ 的 $k$ 值处停止，并返回 $X\\leftarrow k$。\n\n这个过程在操作上是最简的，因为每一步仅用一次乘法和一次除法从 $p(k-1)$ 得到 $p(k)$，再加上一次加法来更新 $F(k)$。\n\n现在将该序列应用于 $\\lambda=7.3$ 和 $U=0.513$。初始化\n$$\np(0)=\\exp(-7.3)\\approx 0.0006754629,\\quad F(0)=0.0006754629.\n$$\n由于 $U=0.513F(0)$，继续。使用 $p(k)=p(k-1)\\cdot \\lambda/k$ 和 $F(k)=F(k-1)+p(k)$：\n- $k=1$: $p(1)=p(0)\\cdot 7.3/1\\approx 0.004930876$, $F(1)\\approx 0.0006754629+0.004930876=0.0056063389$。\n- $k=2$: $p(2)=p(1)\\cdot 7.3/2\\approx 0.017997697$, $F(2)\\approx 0.0236040359$。\n- $k=3$: $p(3)=p(2)\\cdot 7.3/3\\approx 0.043794397$, $F(3)\\approx 0.067398433$。\n- $k=4$: $p(4)=p(3)\\cdot 7.3/4\\approx 0.079924775$, $F(4)\\approx 0.147323208$。\n- $k=5$: $p(5)=p(4)\\cdot 7.3/5\\approx 0.116690171$, $F(5)\\approx 0.264013379$。\n- $k=6$: $p(6)=p(5)\\cdot 7.3/6\\approx 0.141973041$, $F(6)\\approx 0.405986420$。\n- $k=7$: $p(7)=p(6)\\cdot 7.3/7\\approx 0.148057600$, $F(7)\\approx 0.554044020$。\n\n在 $k=6$ 时，$F(6) \\approx 0.405986420  0.513$。当 $k=7$ 时，$F(7) \\approx 0.554044020 \\ge 0.513$，满足停止条件。因此，返回的样本为7。", "answer": "$$\\boxed{7}$$", "id": "3329682"}, {"introduction": "一个正确的算法本身是不够的；我们必须能够从统计上验证其输出。这项练习将我们的重点转移到实验设计上，并提出了一个关键问题：需要多少样本才能自信地检测出生成器输出均值中的一个微小系统性偏差？掌握这种计算是设计高效且有效的验证方案的关键。[@problem_id:3329694]", "problem": "一个泊松随机变量生成器旨在从目标均值为 $\\lambda_{0} = 200$ 的泊松分布中生成独立同分布的样本。您希望设计一个验证实验，以检测生成器均值中 $\\delta = 0.01$ 的相对偏差（即，检测真实均值是等于 $(1+\\delta)\\lambda_{0}$ 而不是 $\\lambda_{0}$），实验使用基于中心极限定理（CLT）所蕴含的样本均值正态近似的置信陈述。\n\n仅从泊松分布的基本性质和中心极限定理下样本均值的渐近正态性出发，推導出一个关于样本大小 $n$ 的准则，使得均值的双边 $95\\%$ 正态近似置信区间的半宽至多为 $\\delta \\lambda_{0}$。然后，使用标准正态双边 $95\\%$ 分位数，计算当 $\\lambda_{0} = 200$ 和 $\\delta = 0.01$ 时满足此准则的最小整数 $n$。报告 $n$ 为满足该准则的最小整数，除了向上取整外不进行其他舍入。\n\n最后，提出了一个在实践中测量此偏差的科学合理的实验方案，明确说明估计量、置信区间的构造方法，以及在 $95\\%$ 置信度下宣告检测到 $1\\%$ 偏差的决策规则。您的描述应与推导出的准则保持一致。\n\n最终答案必须僅为单个整数 $n$。", "solution": "问题陈述经评估是科学合理、适定、客观且自洽的。它提出了一个统计实验设计中的标准问题，并且没有任何使其无效的缺陷。因此，我们可以进行完整解答。\n\n设 $X_1, X_2, \\dots, X_n$ 是一个由 $n$ 个独立同分布（i.i.d.）的随机变量组成的序列，代表来自泊松随机变量生成器的样本。每个 $X_i$ 服从一个未知真实均值为 $\\lambda$ 的泊松分布，记为 $X_i \\sim \\text{Pois}(\\lambda)$。该生成器被设计为具有 $\\lambda_0 = 200$ 的目标均值。\n\n泊松分布的基本性质是其期望和方差均等于其均值参数。因此，对于每个样本 $X_i$：\n$$ E[X_i] = \\lambda $$\n$$ \\text{Var}(X_i) = \\lambda $$\n\n真实均值 $\\lambda$ 的估计量是样本均值 $\\bar{X}_n$，定义为：\n$$ \\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i $$\n\n样本均值的期望为 $E[\\bar{X}_n] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right] = \\frac{1}{n} \\sum_{i=1}^{n} E[X_i] = \\frac{1}{n}(n\\lambda) = \\lambda$。由于样本的独立性，样本均值的方差为 $\\text{Var}(\\bar{X}_n) = \\text{Var}\\left(\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\text{Var}(X_i) = \\frac{1}{n^2}(n\\lambda) = \\frac{\\lambda}{n}$。因此，样本均值的标准差为 $\\sigma_{\\bar{X}_n} = \\sqrt{\\frac{\\lambda}{n}}$。\n\n根据中心极限定理（CLT），对于足够大的样本大小 $n$，标准化样本均值的分布收敛于标准正态分布：\n$$ \\frac{\\bar{X}_n - \\lambda}{\\sigma_{\\bar{X}_n}} = \\frac{\\bar{X}_n - \\lambda}{\\sqrt{\\lambda/n}} \\xrightarrow{d} N(0, 1) $$\n\n均值 $\\lambda$ 的一个双边 $100(1-\\alpha)\\%$ 置信区间是基于此正态近似构造的：\n$$ \\bar{X}_n \\pm z_{1-\\alpha/2} \\sigma_{\\bar{X}_n} $$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。该区间的半宽为 $H = z_{1-\\alpha/2} \\sigma_{\\bar{X}_n} = z_{1-\\alpha/2} \\sqrt{\\frac{\\lambda}{n}}$。\n\n为了在收集数据*之前*设计实验和确定样本大小 $n$，真实均值 $\\lambda$ 是未知的。一种标准且合理的方法是使用均值的目标值或假设值 $\\lambda_0$ 来估计期望方差。这是因为主要目标是在假设生成器按预期运行的情况下确保一定的精度。因此，我们将半宽近似为：\n$$ H \\approx z_{1-\\alpha/2} \\sqrt{\\frac{\\lambda_0}{n}} $$\n问题要求此半宽至多为 $\\delta \\lambda_0$。这给了我们不等式：\n$$ z_{1-\\alpha/2} \\sqrt{\\frac{\\lambda_0}{n}} \\le \\delta \\lambda_0 $$\n\n我们现在对样本大小 $n$ 解此不等式。\n$$ \\sqrt{\\frac{\\lambda_0}{n}} \\le \\frac{\\delta \\lambda_0}{z_{1-\\alpha/2}} $$\n两边平方得到：\n$$ \\frac{\\lambda_0}{n} \\le \\frac{\\delta^2 \\lambda_0^2}{z_{1-\\alpha/2}^2} $$\n两边同乘以 $n$ 并除以右侧项（为正数）得到：\n$$ \\frac{z_{1-\\alpha/2}^2 \\lambda_0}{\\delta^2 \\lambda_0^2} \\le n $$\n$$ n \\ge \\frac{z_{1-\\alpha/2}^2}{\\delta^2 \\lambda_0} $$\n这就是推導出的关于样本大小 $n$ 的准则。\n\n接下来，我们使用给定的值计算满足此准則的最小整数 $n$。\n目标均值为 $\\lambda_0 = 200$。\n相对偏差为 $\\delta = 0.01$。\n置信水平为 $95\\%$，对应于 $\\alpha = 0.05$。所需的分位数为 $1 - \\alpha/2 = 1 - 0.025 = 0.975$。标准正态双边 $95\\%$ 分位数是 $z_{0.975} \\approx 1.96$。\n\n将这些值代入准则中：\n$$ n \\ge \\frac{(1.96)^2}{(0.01)^2 (200)} $$\n$$ n \\ge \\frac{3.8416}{(0.0001)(200)} $$\n$$ n \\ge \\frac{3.8416}{0.02} $$\n$$ n \\ge 192.08 $$\n由于样本大小 $n$ 必须是整数，我们必须选择满足此条件的最小整数，即对计算值向上取整：\n$$ n = \\lceil 192.08 \\rceil = 193 $$\n\n最后，我们提出了一个与这些发现一致的验证实验。\n1.  **实验步骤**：使用被测的泊松变量生成器生成 $n=193$ 個样本，记为 $x_1, x_2, \\dots, x_{193}$。\n2.  **估计量**：计算收集到的数据的样本均值。它作为生成器真实均值 $\\lambda$ 的点估计。\n    $$ \\hat{\\lambda} = \\bar{x} = \\frac{1}{193} \\sum_{i=1}^{193} x_i $$\n3.  **置信区间构造**：为真实均值 $\\lambda$ 构造一个双边 $95\\%$ 置信区间。均值的标准误使用样本数据进行估计，$SE(\\hat{\\lambda}) = \\sqrt{\\frac{\\hat{\\lambda}}{n}} = \\sqrt{\\frac{\\bar{x}}{193}}$。置信区间为：\n    $$ \\left[ \\bar{x} - z_{0.975} \\sqrt{\\frac{\\bar{x}}{193}}, \\quad \\bar{x} + z_{0.975} \\sqrt{\\frac{\\bar{x}}{193}} \\right] $$\n    $$ \\left[ \\bar{x} - 1.96 \\sqrt{\\frac{\\bar{x}}{193}}, \\quad \\bar{x} + 1.96 \\sqrt{\\frac{\\bar{x}}{193}} \\right] $$\n4.  **决策规则**：目标是检测与目标均值 $\\lambda_0 = 200$ 的显著偏差。这对应于一个假设检验，其原假设为 $H_0: \\lambda = 200$，备擇假设为 $H_1: \\lambda \\neq 200$。基于 $95\\%$ 置信水平（或 $5\\%$ 显著性水平）的置信区间的决策规则如下：\n    - 如果目标均值 $\\lambda_0 = 200$ 落在计算出的置信区间**之外**，我们拒绝原假设 $H_0$。我们得出结论，有统计上显著的证据表明生成器的均值存在偏差。观测到的偏差大于在很大一部分时间内偶然预期的偏差。\n    - 如果目标均值 $\\lambda_0 = 200$ 落在计算出的置信区间**之内**，我们未能拒绝原假设 $H_0$。我们得出结论，证据不足以声稱生成器的均值不同于 $200$。\n该实验设计的功效(power)使得大小为 $\\delta \\lambda_0 = 2$ 的真实偏差会将真实均值置于以 $\\lambda_0$ 为中心的置信区间的边缘附近，从而提供合理的检测机会。具体来说，该样本大小确保了检验有大约 $50\\%$ 的功效来检测到均值为 $\\lambda_0(1+\\delta) = 202$ 或 $\\lambda_0(1-\\delta) = 198$ 的情况。", "answer": "$$\\boxed{193}$$", "id": "3329694"}, {"introduction": "随机模拟中最隐蔽的错误通常涉及样本之间缺乏独立性，这是一个简单的矩检验可能会忽略的缺陷。这项高级实践要求你通过检验样本对之差的分布，来构建一个复杂的独立性测试。你将使用Skellam分布作为理论基准，并采用蒙特卡洛校准来创建一个稳健的、适用于有限样本的测试。[@problem_id:3329715]", "problem": "您的任务是构建一个稳健的测试框架，用于检测因在泊松变量生成器中复用随机数生成器（RNG）而引入的微弱相关性。当 $X \\sim \\mathrm{Poisson}(\\lambda)$ 且 $X' \\sim \\mathrm{Poisson}(\\lambda)$ 时，您必须通过检验差值 $D = X - X'$ 的分布来检查独立性条件 $X \\perp X'$，从而执行此检测。在独立的条件下，$D$ 服从速率相等的斯凯拉姆分布，记为 $\\mathrm{Skellam}(\\lambda,\\lambda)$。您的程序必须实现一个针对 $D$ 的分布的、经过校准的拟合优度检验，该检验能恰当处理有限样本效应，从而将假阳性率控制在预定水平。\n\n解决此问题的基础理论包括：\n- 泊松分布的定义：一个取非负整数值的随机变量 $X$，其概率质量函数为 $P(X = k) = e^{-\\lambda} \\lambda^{k} / k!$（其中 $k \\in \\{0,1,2,\\dots\\}$），参数为 $\\lambda  0$。\n- 两个泊松随机变量 $X$ 和 $X'$ 的独立性意味着差值 $D = X - X'$ 的分布为斯凯拉姆分布，这是概率论中一个经过充分检验并被广泛接受的事实。$\\mathrm{Skellam}(\\lambda,\\lambda)$ 的概率质量函数涉及第一类修正贝塞尔函数，在计算时必须注意，当 $\\lambda$ 很大时要保证数值稳定性。\n- 针对有限样本的标准频率派校准：原假设下检验统计量的分布可以通过蒙特卡洛模拟来近似，从而为给定的显著性水平生成经验临界值。\n\n您必须在一个单一、完整、可运行的程序中实现以下内容：\n- 一个生成独立对 $(X,X')$ 的生成器，其中 $X \\sim \\mathrm{Poisson}(\\lambda)$ 且 $X' \\sim \\mathrm{Poisson}(\\lambda)$。\n- 一个有缺陷的生成器，它通过RNG复用引入相关性，该相关性被建模为一个带有共享分量的二元泊松分布：$X = A + C$ 和 $X' = B + C$，其中 $A \\sim \\mathrm{Poisson}(\\lambda(1-\\rho))$、$B \\sim \\mathrm{Poisson}(\\lambda(1-\\rho))$ 和 $C \\sim \\mathrm{Poisson}(\\lambda \\rho)$ 相互独立。这种构造在科学上是合理的，并能生成 $X \\sim \\mathrm{Poisson}(\\lambda)$ 和 $X' \\sim \\mathrm{Poisson}(\\lambda)$，其协方差为 $\\mathrm{Cov}(X, X') = \\lambda \\rho$。参数 $\\rho \\in (0,1)$ 控制所引入相关性的微弱程度。\n- 一个拟合优度检验，用于将 $D = X-X'$ 的分布与 $\\mathrm{Skellam}(\\lambda,\\lambda)$ 分布进行比较：\n  - 使用皮尔逊卡方统计量，该统计量是根据对整数值 $D$ 进行对称截断分箱计算得出的。设 $K$ 为一个非负整数截断参数。中心箱对应于 $k \\in \\{-K,-K+1,\\dots,0,\\dots,K-1,K\\}$，两个尾部箱则聚合了 $k  -K$ 和 $k > K$ 的情况。该统计量为\n    $$ T = \\sum_{k=-K}^{K} \\frac{\\left(O_k - n p_k\\right)^2}{n p_k} + \\sum_{\\text{tails}} \\frac{\\left(O_{\\text{tail}} - n p_{\\text{tail}}\\right)^2}{n p_{\\text{tail}}}, $$\n    其中 $n$ 是样本大小，$O_k$ 是箱 $k$ 中的观测计数，$p_k$ 是对应的理论斯凯拉姆概率，$p_{\\text{tail}}$ 是聚合的尾部概率。您必须自适应地设计 $K$，以确保所有期望计数 $n p_k$ 和 $n p_{\\text{tail}}$ 至少为 $5$，如有必要则缩小 $K$ 的值。\n  - 使用指数缩放的第一类修正贝塞尔函数来稳定地计算斯凯拉姆概率 $p_k$，以避免当 $\\lambda$ 很大时出现数值下溢或上溢。\n- 在原假设 $X \\perp X'$ 下，针对 $T$ 的有限样本校准程序：\n  - 对于给定的 $(\\lambda,n)$，在原假设下（即使用独立的泊松对）生成 $R$ 个独立的蒙特卡洛复制样本，对每个复制样本使用相同的分箱方法计算 $T$，并将经验 $(1-\\alpha)$ 分位数设为临界值 $c_{\\alpha}$。\n  - 使用这个 $c_{\\alpha}$ 来检验新样本：如果 $T \\leq c_{\\alpha}$，则接受独立性假设；如果 $T > c_{\\alpha}$，则拒绝独立性假设。\n\n您的程序必须实现并评估以下测试套件，该套件探索了不同 $\\lambda$ 和样本大小 $n$ 的情形：\n- 案例1：$\\lambda = 0.1$, $n = 2000$, $\\rho = 0.2$, $\\alpha = 0.05$, $R = 150$。\n- 案例2：$\\lambda = 3$, $n = 2000$, $\\rho = 0.2$, $\\alpha = 0.05$, $R = 150$。\n- 案例3：$\\lambda = 30$, $n = 2000$, $\\rho = 0.2$, $\\alpha = 0.05$, $R = 150$。\n- 案例4：$\\lambda = 120$, $n = 2000$, $\\rho = 0.2$, $\\alpha = 0.05$, $R = 150$。\n\n对每个案例，您的程序必须：\n- 通过在独立性假设下进行 $R$ 次蒙特卡洛复制来校准 $c_{\\alpha}$。\n- 为一个独立样本计算一次 $T$ 的实现值，并报告是否接受独立性（一个布尔值）。\n- 为一个具有指定 $\\rho$ 的相关样本计算一次 $T$ 的实现值，并报告是否拒绝独立性（一个布尔值）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。该列表必须按案例1到4的顺序包含每个案例的两个布尔值：首先是使用正确生成器时接受独立性的布尔值，然后是使用相关生成器时拒绝独立性的布尔值。例如，输出格式为\n  $$ [b_{1,\\mathrm{indep}}, b_{1,\\mathrm{corr}}, b_{2,\\mathrm{indep}}, b_{2,\\mathrm{corr}}, b_{3,\\mathrm{indep}}, b_{3,\\mathrm{corr}}, b_{4,\\mathrm{indep}}, b_{4,\\mathrm{corr}}]. $$\n\n此问题不涉及物理单位或角度单位。所有答案均为指定的布尔值。\n\n实现约束：\n- 程序必须通过固定的RNG种子实现完全的确定性。\n- 在卡方统计量中，使用为斯凯拉姆分布稳定计算出的概率。\n- 通过自适应地选择K，确保分箱策略产生的所有期望计数至少为5。", "solution": "该问题要求构建并实现一个统计检验，用以检测两个泊松随机变量 $X$ 和 $X'$ 之间的相关性。这两个变量据称是独立同分布的，均服从 $\\mathrm{Poisson}(\\lambda)$ 分布。该检验基于它们差值 $D = X - X'$ 的分布，并使用蒙特卡洛程序针对有限样本进行校准。\n\n### 1. 理论基础\n\n该检测方法的核心在于，将观测到的 $D$ 的分布与独立性原假设下的理论分布进行比较。\n\n**原假设 ($H_0$): $X$ 和 $X'$ 相互独立。**\n如果 $X \\sim \\mathrm{Poisson}(\\lambda)$ 和 $X' \\sim \\mathrm{Poisson}(\\lambda)$ 相互独立，那么它们的差值 $D = X - X'$ 服从参数为 $(\\lambda, \\lambda)$ 的斯凯拉姆（Skellam）分布。对于一个整数结果 $k$，其概率质量函数（PMF）由下式给出：\n$$ P(D=k | H_0) = p_k = e^{-2\\lambda} I_{|k|}(2\\lambda) $$\n其中 $I_{\\nu}(z)$ 是第一类修正贝塞尔函数。该分布关于0对称，即 $p_k = p_{-k}$。为了数值稳定性，尤其是在 $\\lambda$ 值很大时，使用指数缩放的贝塞尔函数 $I_{\\nu}(z)e^{-|z|}$。`scipy.special.ive` 函数直接计算此值，因此 $p_k = \\mathrm{ive}(|k|, 2\\lambda)$。\n\n**备择假设 ($H_1$): $X$ 和 $X'$ 相关。**\n该问题使用一个二元泊松模型来指定一个共因相关结构。变量构造如下：\n$$ X = A + C \\quad \\text{和} \\quad X' = B + C $$\n其中 $A, B, C$ 是相互独立的泊松随机变量：\n- $A \\sim \\mathrm{Poisson}(\\lambda(1-\\rho))$\n- $B \\sim \\mathrm{Poisson}(\\lambda(1-\\rho))$\n- $C \\sim \\mathrm{Poisson}(\\lambda\\rho)$\n\n参数 $\\rho \\in (0,1)$ 控制相关程度。独立泊松变量之和也为泊松变量，因此边际分布是正确的：\n$$ X \\sim \\mathrm{Poisson}(\\lambda(1-\\rho) + \\lambda\\rho) = \\mathrm{Poisson}(\\lambda) $$\n$$ X' \\sim \\mathrm{Poisson}(\\lambda(1-\\rho) + \\lambda\\rho) = \\mathrm{Poisson}(\\lambda) $$\n协方差不为零，证实了相关性：\n$$ \\mathrm{Cov}(X, X') = \\mathrm{Cov}(A+C, B+C) = \\mathrm{Var}(C) = \\lambda\\rho $$\n在此备择假设下，差值为 $D = (A+C) - (B+C) = A - B$。由于 $A$ 和 $B$ 是独立的 $\\mathrm{Poisson}(\\lambda(1-\\rho))$ 变量，因此 $H_1$ 下 $D$ 的分布是 $\\mathrm{Skellam}(\\lambda(1-\\rho), \\lambda(1-\\rho))$。该分布与原假设下的分布 $\\mathrm{Skellam}(\\lambda, \\lambda)$ 不同，而这种差异正是检验所要检测的目标。\n\n### 2. 拟合优度检验\n\n使用皮尔逊卡方（$\\chi^2$）检验来衡量来自大小为 $n$ 的样本的 $D$ 的观测计数与原假设下的期望计数之间的差异。\n\n**检验统计量 ($T$):**\n$D$ 的定义域（所有整数）被划分为有限数量的箱。采用对称分箱方案，中心箱对应于从 $-K$ 到 $K$ 的每个整数 $k$，两个尾部箱则对应于结果 $k  -K$ 和 $k > K$。检验统计量为：\n$$ T = \\sum_{\\text{bins}} \\frac{(\\text{Observed} - \\text{Expected})^2}{\\text{Expected}} = \\sum_{k=-K}^{K} \\frac{(O_k - n p_k)^2}{n p_k} + \\sum_{\\text{tails}} \\frac{(O_{\\text{tail}} - n p_{\\text{tail}})^2}{n p_{\\text{tail}}} $$\n其中 $O_i$ 是一个箱中的观测计数，$E_i = n p_i$ 是期望计数。\n\n**自适应分箱：**\n$\\chi^2$ 检验的有效性依赖于每个箱中具有足够大的期望计数。一个标准的经验法则是 $E_i \\ge 5$。参数 $K$ 针对每个 $(\\lambda, n)$ 对进行自适应确定，以满足此标准。算法从一个足够大的 $K$ 开始，并迭代地减小它，直到边缘箱（$k=\\pm K$）和尾部箱的期望计数都满足最低阈值 $5$。\n$$ n \\cdot p_K \\ge 5 \\quad \\text{且} \\quad n \\cdot p_{\\text{tail}} \\ge 5 $$\n其中 $p_{\\text{tail}} = P(D > K) = P(D  -K) = \\frac{1}{2} (1 - \\sum_{j=-K}^{K} p_j)$。\n\n### 3. 有限样本校准\n\n皮尔逊 $T$ 统计量的渐近分布是卡方分布。然而，对于有限样本，特别是考虑到自适应分箱，这种近似可能不准确。一个更可靠的方法是通过蒙特卡洛模拟来推导检验的临界值。\n\n**校准程序：**\n给定显著性水平 $\\alpha$，临界值 $c_{\\alpha}$ 的确定方法如下：\n1. 在原假设下（即使用独立的泊松对），生成 $R$ 个独立的蒙特卡洛复制数据集，每个数据集的大小为 $n$。\n2. 对每个复制样本，使用为给定 $(\\lambda, n)$ 预先确定的分箱方案计算检验统计量 $T$。这会产生一个在 $H_0$ 下该统计量分布的经验样本：$\\{T_1, T_2, \\dots, T_R\\}$。\n3. 临界值 $c_{\\alpha}$ 被设为该经验分布的 $(1-\\alpha)$-分位数。\n\n**假设检验：**\n对于任何新样本，计算其检验统计量 $T_{\\text{new}}$。\n- 如果 $T_{\\text{new}} \\le c_{\\alpha}$，我们不拒绝独立性的原假设。\n- 如果 $T_{\\text{new}}  c_{\\alpha}$，我们拒绝原假设，并断定数据可能存在相关性。\n\n程序将对每个指定的测试案例执行此过程。它将首先进行校准以找到 $c_{\\alpha}$，然后测试一个来自独立生成器的样本和一个来自相关生成器的样本，并按要求报告假设检验的布尔值结果。一个固定的随机数生成器种子确保整个过程是确定性的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import ive\n\ndef get_skellam_bins(lam, n, min_expected_count=5.0):\n    \"\"\"\n    Determines the adaptive binning parameter K for the chi-square test.\n\n    It finds the largest integer K such that the expected counts for the\n    central bins from -K to K and the two tail bins are all at least\n    min_expected_count.\n\n    Returns:\n        K (int): The truncation parameter.\n        p_central (np.ndarray): Array of probabilities for bins [-K, ..., K].\n        p_tail (float): The probability for each tail bin.\n    \"\"\"\n    # Start with a K that safely covers the distribution's mass.\n    # Skellam(lam, lam) has mean 0 and variance 2*lam.\n    # An initial K based on mean + standard deviations is a good heuristic.\n    # Add a constant to handle lam=0 case gracefully, if it were to occur.\n    initial_K = int(np.ceil(10 + 8 * np.sqrt(2 * lam)))\n\n    for K in range(initial_K, -1, -1):\n        k_vals = np.arange(0, K + 1)\n        # Use ive for stable computation of exp(-2*lam)*I_k(2*lam)\n        p_k_vals = ive(k_vals, 2 * lam)\n\n        # Check condition for outermost central bin(s) k = +/- K\n        if n * p_k_vals[-1]  min_expected_count:\n            continue\n\n        # Check condition for tail bins\n        p_central_sum = p_k_vals[0] + 2 * np.sum(p_k_vals[1:])\n        # Handle potential floating point inaccuracies where sum slightly > 1\n        if p_central_sum >= 1.0:\n            p_central_sum = 1.0\n        \n        p_tail = (1.0 - p_central_sum) / 2.0\n        if n * p_tail  min_expected_count:\n            continue\n\n        # If all conditions are met, we found a valid K.\n        # Construct the full probability vector for bins [-K, ..., K]\n        # It must have length 2*K + 1.\n        p_central = np.zeros(2 * K + 1)\n        p_central[K] = p_k_vals[0]  # Bin for k=0\n        for i in range(1, K + 1):\n            p_central[K + i] = p_k_vals[i] # Bin for k=i\n            p_central[K - i] = p_k_vals[i] # Bin for k=-i\n\n        return K, p_central, p_tail\n\n    # This part should be unreachable for the problem's parameters\n    raise ValueError(f\"Could not find a valid binning for lambda={lam}, n={n}.\")\n\ndef compute_chi2_statistic(D, n, K, p_central, p_tail):\n    \"\"\"\n    Computes the Pearson chi-square statistic for a sample D.\n\n    Args:\n        D (np.ndarray): Sample of differences X - X'.\n        n (int): Sample size.\n        K (int): Binning truncation parameter.\n        p_central (np.ndarray): Probabilities for central bins [-K, ..., K].\n        p_tail (float): Probability for a single tail bin.\n\n    Returns:\n        float: The chi-square statistic value.\n    \"\"\"\n    # 1. Tally observed counts for all bins: -K, -K, ..., K, >K\n    offset = K + 1\n    # Clip values to fall into [-K-1, K+1] range for binning\n    # D  -K -> -K-1 (index 0)\n    # D > K  ->  K+1 (index 2K+2)\n    # D=k    ->  k   (index k+offset-1)\n    clipped_D = np.clip(D, -offset, offset)\n    obs_counts = np.bincount(clipped_D + offset, minlength=2 * K + 3)\n\n    # 2. Compute expected counts\n    exp_counts = np.zeros(2 * K + 3)\n    exp_counts[0] = n * p_tail        # Tail bin D  -K\n    exp_counts[-1] = n * p_tail       # Tail bin D > K\n    exp_counts[1:-1] = n * p_central  # Central bins D in [-K, K]\n    \n    # 3. Compute the chi-square statistic, sum((O-E)^2/E)\n    # Denominators are guaranteed to be >= 5 by the binning rule.\n    # Add a small epsilon to avoid division by zero in pathological cases,\n    # though binning rule should prevent it.\n    term = (obs_counts - exp_counts)**2 / (exp_counts + 1e-9)\n    \n    return np.sum(term)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    # Fixed RNG seed for deterministic results\n    rng = np.random.default_rng(seed=42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda, n, rho, alpha, R)\n        (0.1, 2000, 0.2, 0.05, 150),\n        (3.0, 2000, 0.2, 0.05, 150),\n        (30.0, 2000, 0.2, 0.05, 150),\n        (120.0, 2000, 0.2, 0.05, 150),\n    ]\n\n    results = []\n    for lam, n, rho, alpha, R in test_cases:\n        # 1. Determine the binning based on (lam, n)\n        K, p_central, p_tail = get_skellam_bins(lam, n)\n\n        # 2. Calibrate to find the critical value c_alpha\n        T_stats_calib = []\n        for _ in range(R):\n            X = rng.poisson(lam, size=n)\n            X_prime = rng.poisson(lam, size=n)\n            D_calib = X - X_prime\n            T = compute_chi2_statistic(D_calib, n, K, p_central, p_tail)\n            T_stats_calib.append(T)\n        \n        c_alpha = np.quantile(T_stats_calib, 1 - alpha)\n\n        # 3. Test a truly independent sample\n        X_indep = rng.poisson(lam, size=n)\n        X_prime_indep = rng.poisson(lam, size=n)\n        D_indep = X_indep - X_prime_indep\n        T_indep = compute_chi2_statistic(D_indep, n, K, p_central, p_tail)\n        \n        # Test for accepting independence: T = c_alpha\n        b_indep = (T_indep = c_alpha)\n        results.append(b_indep)\n\n        # 4. Test a correlated sample\n        lam_A_B = lam * (1 - rho)\n        lam_C = lam * rho\n        A = rng.poisson(lam_A_B, size=n)\n        B = rng.poisson(lam_A_B, size=n)\n        C = rng.poisson(lam_C, size=n)\n        # D_corr = (A + C) - (B + C) = A - B\n        D_corr = A - B\n        T_corr = compute_chi2_statistic(D_corr, n, K, p_central, p_tail)\n\n        # Test for rejecting independence: T > c_alpha\n        b_corr = (T_corr > c_alpha)\n        results.append(b_corr)\n\n    # Final print statement in the exact required format.\n    # The output format requests boolean values like 'True'/'False'\n    # which str() produces.\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\nsolve()\n```", "id": "3329715"}]}