{"hands_on_practices": [{"introduction": "要真正掌握拉丁超立方采样（LHS），第一步是理解其算法构造。本练习将指导您从零开始构建一个可复现的LHS生成器，这对于任何严谨的科学计算和模拟都至关重要。通过控制用于生成分层排列和层内抖动的随机种子，您将学会如何实现可重复的实验并进行方差分析。", "problem": "要求您实现一个独立的程序，构建一个可复现的拉丁超立方抽样 (LHS) 生成器，该生成器能够存储并重用其底层的排列，以支持重复运行和方差估计。此问题必须基于随机模拟和蒙特卡洛方法的基本原理来解决，并且程序必须确定性地执行。最终输出必须是单行文本，包含所有测试用例的结果，形式为方括号括起来的逗号分隔列表。\n\n基本原理：您必须仅依赖于核心定义和经过充分检验的性质：\n- $d$维单位超立方体是$[0,1]^d$。\n- 在$[0,1]$上的均匀随机变量$U$的分布函数为$F_U(u) = u$，其中$u \\in [0,1]$。\n- 集合$\\{0,1,\\dots,n-1\\}$上的一个排列是一个重排索引的双射。\n- 分层：将$[0,1]$划分成$n$个测度相等的不相交区间，即$I_k = [k/n,(k+1)/n)$，其中$k \\in \\{0,1,\\dots,n-1\\}$。\n- 使用固定种子的伪随机数生成是可复现的。\n\n目标构造：一个大小为$n$、维度为$d$的拉丁超立方抽样 (LHS) 设计，对每个样本的每个维度使用一个不同的层。具体来说：\n- 对每个维度$j \\in \\{1,\\dots,d\\}$，选择一个$\\{0,1,\\dots,n-1\\}$的随机排列$\\pi_j$。\n- 对每个样本索引$i \\in \\{1,\\dots,n\\}$和维度$j$，定义一个抖动$U_{i,j} \\sim \\text{Uniform}(0,1)$，这些抖动在$i$和$j$上是独立的，并且与排列无关。\n- 接着，点$X_{i,j} \\in [0,1]$按$X_{i,j} = \\left(\\pi_j(i-1)+U_{i,j}\\right)/n$构建，从而得到样本矩阵$X \\in [0,1]^{n \\times d}$，其性质为在每一列$j$中，每个层$I_k$内恰好有一个点。\n\n可复现性与重复运行：程序必须区分两种随机输入：\n- 一个基础种子，用于确定和存储排列$\\{\\pi_j\\}_{j=1}^d$。\n- 一个抖动种子，用于确定均匀抖动矩阵$\\{U_{i,j}\\}$。\n通过存储和重用$\\{\\pi_j\\}$，同时仅改变抖动种子，可以获得保留了层占用情况但又在每个层内生成不同点的重复运行结果。这使得能够在具有共同分层的重复LHS运行中，对蒙特卡洛估计量进行方差估计。\n\n程序要求：\n- 实现一个LHS生成器，当给定$n$、$d$和一个基础种子时，返回样本和存储的排列。\n- 实现一个重构函数，该函数接收存储的排列和一个抖动种子，并重用这些确切的排列，仅改变抖动来生成一个新的LHS样本。\n- 实现一个函数，用于计算函数$f:[0,1]^d \\to \\mathbb{R}$积分的蒙特卡洛估计量。使用简单的样本均值$\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^n f(X_i)$。\n- 实现一个函数，用于生成多个重复的LHS估计量，可以选择对每个重复样本使用固定的存储排列，或使用独立重新生成的排列。对于跨$R$个重复样本的方差估计，使用估计值$\\{\\hat{\\mu}_r\\}_{r=1}^R$计算无偏样本方差$s^2 = \\frac{1}{R-1}\\sum_{r=1}^R (\\hat{\\mu}_r - \\bar{\\mu})^2$，其中$\\bar{\\mu} = \\frac{1}{R}\\sum_{r=1}^R \\hat{\\mu}_r$。\n\n用于方差估计的函数：\n- 定义$f_1(x) = \\sum_{j=1}^d x_j^2$，其中$x \\in [0,1]^d$。\n- 对于边界情况，仅对$x \\in [0,1]^1$使用$f_0(x) = x_1$。\n\n测试套件和要求的输出：\n您的程序必须实现以下四个测试用例并输出相应的结果：\n\n- 测试 $1$ (正常路径覆盖性检查)：\n  - 参数：$n=5$，$d=3$，基础种子 $=314159$，抖动种子 $=271828$。\n  - 任务：生成一个LHS样本，并验证每个维度的分层覆盖是精确的，即对每个维度$j$，多重集$\\{\\lfloor n X_{i,j}\\rfloor : i=1,\\dots,n\\}$等于$\\{0,1,2,3,4\\}$。\n  - 输出：一个布尔值，当且仅当所有三个维度都通过时为$true$。\n\n- 测试 $2$ (跨重复样本使用固定排列进行方差估计)：\n  - 参数：$n=50$，$d=4$，基础种子 $=12345$，抖动种子 $\\in \\{100,101,102,103,104\\}$ (五个重复样本使用相同的存储排列)，以及函数$f_1$。\n  - 任务：重用存储的排列生成五个重复的LHS样本，并计算$\\int_{[0,1]^d} f_1(x)\\,dx$的五个蒙特卡洛估计值的无偏样本方差$s^2$。\n  - 输出：一个浮点数$s^2$。\n\n- 测试 $3$ (跨重复样本使用独立排列进行方差比较)：\n  - 参数：$n=50$，$d=4$，基础种子 $\\in \\{200,201,202,203,204\\}$ (五个重复样本，每个使用独立重新生成的排列)，抖动种子与测试 $2$相同，以及函数$f_1$。\n  - 任务：计算使用独立重新生成的排列的五个蒙特卡洛估计值的无偏样本方差$s^2_{\\text{indep}}$，并输出比率$r = s^2_{\\text{fixed}}/s^2_{\\text{indep}}$，其中$s^2_{\\text{fixed}}$来自测试 $2$。\n  - 输出：一个浮点数$r$。\n\n- 测试 $4$ (边界情况 $n=1, d=1$)：\n  - 参数：$n=1$，$d=1$，基础种子 $=777$，抖动种子 $=888$，以及函数$f_0$。\n  - 任务：生成单点LHS样本并报告样本值$X_{1,1}$。\n  - 输出：一个等于$X_{1,1}$的浮点数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含测试 $1$ 到 $4$ 的结果，格式为方括号括起来的逗号分隔列表。列表项必须按测试顺序排列；例如，一个布尔值后跟三个浮点数的列表必须看起来像 $[true,0.12345,0.6789,0.2468]$。不应打印任何其他文本。\n\n角度单位：不适用。 物理单位：不适用。 百分比：不适用。\n\n您的解决方案在描述中必须与语言无关，但在最终答案部分必须以实际可运行的程序形式呈现。请确保科学真实性、内部一致性，并确保所有浮点输出都是从指定的种子确定性地派生出来的，因此是可复现的。", "solution": "该问题要求从基本原理出发，实现一个可复现的拉丁超立方抽样 (LHS) 生成器，重点在于能够将层排列的随机化与层内抖动的随机化分离开来。这种分离对于蒙特卡洛方法中的方差缩减技术至关重要，在这些技术中会使用具有共同随机数（在此情况下是共同分层）的重复样本。\n\n一个大小为$n$、维度为$d$的拉丁超立方样本是在单位超立方体$[0,1]^d$中的$n$个点的集合$\\{X_1, X_2, \\dots, X_n\\}$。LHS 的核心特性是它对边际分布进行分层。对于每个维度$j \\in \\{1, \\dots, d\\}$，将域$[0,1]$分成$n$个等长的互不相交的区间，$I_k = [k/n, (k+1)/n)$，其中$k \\in \\{0, \\dots, n-1\\}$。抽样设计确保对于每个维度，这$n$个区间中的每一个都恰好包含一个样本点。\n\n样本矩阵$X \\in \\mathbb{R}^{n \\times d}$的构造如下。\n首先，对每个维度$j \\in \\{1, \\dots, d\\}$，我们生成索引集$\\{0, 1, \\dots, n-1\\}$的一个随机排列$\\pi_j$。这$d$个排列定义了样本的分层结构。\n其次，我们生成一个$n \\times d$的抖动值矩阵$U$，其中每个元素$U_{i,j}$是从$[0,1]$上的均匀分布中抽取的独立随机变量，即$U_{i,j} \\sim \\text{Uniform}(0,1)$。\n\n第$i$个样本点的第$j$个坐标$X_{i,j}$是通过组合排列和抖动来构造的：\n$$X_{i,j} = \\frac{\\pi_j(i-1) + U_{i,j}}{n}$$\n这里，我们将$\\pi_j(i-1)$解释为表示第$j$个排列的数组的第$i$个元素（对$i$使用 1-基索引，因此对于 0-基数组索引是第 $(i-1)$ 个）。这确保了对于任何固定的维度$j$，值集合$\\{\\lfloor n X_{i,j} \\rfloor\\}_{i=1}^n$恰好是集合$\\{0, 1, \\dots, n-1\\}$，从而满足分层属性。\n\n可复现性和方差分析依赖于对随机性来源的控制。问题指定了两个种子：\n1.  一个 `base_seed`，用于控制$d$个排列集合$\\{\\pi_j\\}_{j=1}^d$的生成。\n2.  一个 `jitter_seed`，用于控制抖动矩阵$U = \\{U_{i,j}\\}$的生成。\n\n通过固定 `base_seed`（从而固定排列），同时对多次运行使用不同的 `jitter_seed`，我们生成共享相同分层结构的重复样本。这通常会在估计量的输出之间引入正相关，从而导致平均性能估计量的方差减小。问题通过比较两种情景下蒙特卡洛估计的方差来测试这一点：\n- **固定排列**：生成一组排列并在所有重复样本中重复使用，仅重新抽样抖动。对于许多被积函数，预计这将产生较低的方差。\n- **独立排列**：每个重复样本都使用一组新的、独立的排列和抖动生成。这对应于整个LHS实验的标准独立重复。\n\n积分$I = \\int_{[0,1]^d} f(x) \\, dx$的蒙特卡洛估计量是在LHS点上求值的函数值的样本均值：\n$$\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n f(X_i)$$\n给定来自$R$个重复样本的$R$个此类估计值$\\{\\hat{\\mu}_r\\}_{r=1}^R$，无偏样本方差计算如下：\n$$s^2 = \\frac{1}{R-1} \\sum_{r=1}^R (\\hat{\\mu}_r - \\bar{\\mu})^2$$\n其中$\\bar{\\mu} = \\frac{1}{R} \\sum_{r=1}^R \\hat{\\mu}_r$是估计值的均值。\n\n实现将包括使用 `numpy` 的伪随机数生成器（按规定设置种子）确定性地执行这些步骤的函数。\n\n**测试用例 1** 直接验证所生成的LHS样本的基本分层属性。对于大小为$n=5$、维度为$d=3$的样本，它检查对于 3 个维度中的每一个，样本在 5 个层$[0/5, 1/5), [1/5, 2/5), \\dots, [4/5, 5/5)$中的每一个都恰好包含一个点。\n\n**测试用例 2** 使用单个 `base_seed`（固定排列）和五个不同的 `jitter_seed`，计算跨$R=5$个重复样本的方差$s^2_{\\text{fixed}}$。这衡量了当仅改变层内随机性时估计量的变异性。\n\n**测试用例 3** 计算跨$R=5$个重复样本的方差$s^2_{\\text{indep}}$，其中每个重复样本使用独立的 `base_seed` 和 `jitter_seed`。这代表了估计量的总变异性。比率$r = s^2_{\\text{fixed}} / s^2_{\\text{indep}}$量化了通过固定分层实现的方差缩减。对于像$f_1(x) = \\sum_{j=1}^d x_j^2$这样的可加函数，LHS 已知特别有效，因此我们预计该比率将小于 1。\n\n**测试用例 4** 检验$n=1$和$d=1$的边界情况。对于$n=1$，唯一的层是$[0,1)$，$\\{0\\}$的唯一排列是$(0)$。公式变为$X_{1,1} = (0 + U_{1,1})/1 = U_{1,1}$。输出只是由 `jitter_seed`确定的一个均匀分布的单次抽样。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ... is not used.\n\ndef generate_lhs_permutations(n, d, base_seed):\n    \"\"\"\n    Generates d random permutations of {0, 1, ..., n-1} using a base seed.\n    These permutations define the stratification for the LHS design.\n    \"\"\"\n    base_rng = np.random.default_rng(base_seed)\n    # A list of d arrays, where each array is a permutation of arange(n).\n    permutations = [base_rng.permutation(n) for _ in range(d)]\n    return permutations\n\ndef construct_lhs_sample(permutations, n, d, jitter_seed):\n    \"\"\"\n    Constructs an LHS sample using pre-computed permutations and a jitter seed.\n    \"\"\"\n    jitter_rng = np.random.default_rng(jitter_seed)\n    # Generate an n x d matrix of uniform random numbers for jitter.\n    jitters = jitter_rng.uniform(size=(n, d))\n    \n    # Initialize the sample matrix.\n    sample = np.empty((n, d))\n    \n    # Construct the sample column by column.\n    for j in range(d):\n        perm_j = permutations[j]\n        jitter_j = jitters[:, j]\n        sample[:, j] = (perm_j + jitter_j) / n\n        \n    return sample\n\ndef f1(x):\n    \"\"\"Integrand for Tests 2 and 3: f(x) = sum(x_j^2).\"\"\"\n    # x is an n x d matrix. sum over the second axis (d dimensions).\n    return np.sum(x**2, axis=1)\n\ndef f0(x):\n    \"\"\"Integrand for Test 4: f(x) = x_1.\"\"\"\n    # x is an n x 1 matrix.\n    return x[:, 0]\n\ndef monte_carlo_estimator(func, sample):\n    \"\"\"Computes the Monte Carlo estimate for a given function and sample.\"\"\"\n    f_values = func(sample)\n    return np.mean(f_values)\n\ndef solve():\n    \"\"\"\n    Executes the four test cases and prints the results in the required format.\n    \"\"\"\n    results = []\n\n    # --- Test 1: Happy path coverage check ---\n    n1, d1, base_seed1, jitter_seed1 = 5, 3, 314159, 271828\n    perms1 = generate_lhs_permutations(n1, d1, base_seed1)\n    sample1 = construct_lhs_sample(perms1, n1, d1, jitter_seed1)\n    \n    is_valid_lhs = True\n    expected_strata = np.arange(n1)\n    for j in range(d1):\n        strata_indices = np.floor(n1 * sample1[:, j])\n        if not np.array_equal(np.sort(strata_indices), expected_strata):\n            is_valid_lhs = False\n            break\n    results.append(str(is_valid_lhs).lower())\n\n    # --- Test 2: Variance with fixed permutations ---\n    n2, d2, base_seed2 = 50, 4, 12345\n    jitter_seeds2 = [100, 101, 102, 103, 104]\n    \n    perms2 = generate_lhs_permutations(n2, d2, base_seed2)\n    estimates_fixed = []\n    for js in jitter_seeds2:\n        sample = construct_lhs_sample(perms2, n2, d2, js)\n        estimate = monte_carlo_estimator(f1, sample)\n        estimates_fixed.append(estimate)\n    \n    s2_fixed = np.var(estimates_fixed, ddof=1)\n    results.append(s2_fixed)\n\n    # --- Test 3: Variance with independent permutations and ratio ---\n    n3, d3 = 50, 4\n    base_seeds3 = [200, 201, 202, 203, 204]\n    jitter_seeds3 = [100, 101, 102, 103, 104]\n    \n    estimates_indep = []\n    for bs, js in zip(base_seeds3, jitter_seeds3):\n        perms = generate_lhs_permutations(n3, d3, bs)\n        sample = construct_lhs_sample(perms, n3, d3, js)\n        estimate = monte_carlo_estimator(f1, sample)\n        estimates_indep.append(estimate)\n        \n    s2_indep = np.var(estimates_indep, ddof=1)\n    ratio = s2_fixed / s2_indep\n    results.append(ratio)\n\n    # --- Test 4: Edge case n=1, d=1 ---\n    n4, d4, base_seed4, jitter_seed4 = 1, 1, 777, 888\n    \n    perms4 = generate_lhs_permutations(n4, d4, base_seed4)\n    # perms4 will be [array([0])]\n    sample4 = construct_lhs_sample(perms4, n4, d4, jitter_seed4)\n    # For n=1, sample value X_11 is just the jitter U_11.\n    result4 = sample4[0, 0]\n    results.append(result4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3317057"}, {"introduction": "理解了LHS的构造之后，下一个关键问题是：它为何如此有效？本练习通过一个经典的理论分析，揭示了LHS在估计可加函数积分时的卓越方差缩减能力。通过将LHS的方差与二维分层采样进行解析比较，您将亲手推导出LHS的效率优势，并理解其在特定条件下为何能超越其他采样方法。", "problem": "考虑在单位正方形上，关于两个独立的 Uniform$(0,1)$ 随机变量的乘积测度，估计函数$f(x,y)=x+y$的积分$\\mu$。也就是说，令$(X,Y)$相互独立，其中$X \\sim \\text{Uniform}(0,1)$且$Y \\sim \\text{Uniform}(0,1)$，并定义$\\mu = \\mathbb{E}[f(X,Y)]$。你将比较在由函数求值次数量化的固定计算预算下，两种抽样策略。\n\n策略 A：拉丁超立方抽样 (LHS)。抽取$N$个样本$\\{(X_{i},Y_{\\pi(i)})\\}_{i=1}^{N}$，其中$\\{X_{i}\\}_{i=1}^{N}$相互独立且$X_{i} \\sim \\text{Uniform}\\!\\left(\\frac{i-1}{N},\\frac{i}{N}\\right)$，$\\{Y_{j}\\}_{j=1}^{N}$相互独立且$Y_{j} \\sim \\text{Uniform}\\!\\left(\\frac{j-1}{N},\\frac{j}{N}\\right)$，而$\\pi$是独立于抽样的$\\{1,2,\\dots,N\\}$的一个随机置换。估计量是样本均值$\\hat{\\mu}_{\\text{LHS}}=\\frac{1}{N}\\sum_{i=1}^{N}f\\!\\left(X_{i},Y_{\\pi(i)}\\right)$。\n\n策略 B：在$m \\times m$网格上进行二维分层抽样，每层一个样本，其中$N$是一个完全平方数且$m=\\sqrt{N}$。将$[0,1]^{2}$划分为$m \\times m$个相等的方形单元，在每个单元内随机均匀地抽取一个点。估计量是样本均值$\\hat{\\mu}_{\\text{STRAT}}=\\frac{1}{N}\\sum_{k=1}^{N}f\\!\\left(X^{(k)},Y^{(k)}\\right)$，其中$(X^{(k)},Y^{(k)})$在第$k$个单元上均匀分布，且$N$个单元的抽样是相互独立的。\n\n仅使用期望和方差的基本定义、均匀抽样下坐标的独立性，以及区间上均匀分布的性质，推导每种估计量的方差，然后通过比率\n$$\\mathcal{R}(N) = \\frac{\\operatorname{Var}\\!\\left(\\hat{\\mu}_{\\text{STRAT}}\\right)}{\\operatorname{Var}\\!\\left(\\hat{\\mu}_{\\text{LHS}}\\right)}$$\n来量化策略 A 相对于策略 B 的改进。\n将$\\mathcal{R}(N)$表示为关于$N$的封闭形式解析表达式。基于函数的结构和抽样设计，对结果进行简要解释。你的最终答案必须是$\\mathcal{R}(N)$的单一表达式；不要求四舍五入，也不涉及单位。", "solution": "该问题陈述清晰且有科学依据，因此我们着手求解。\n\n待估计的积分是$\\mu = \\mathbb{E}[f(X,Y)]$，其中$f(x,y)=x+y$，$X, Y$是服从$\\text{Uniform}(0,1)$分布的独立随机变量。根据期望的线性性质，可得$\\mu = \\mathbb{E}[X] + \\mathbb{E}[Y] = \\frac{1}{2} + \\frac{1}{2} = 1$。\n\n我们将推导每种估计量$\\hat{\\mu}_{\\text{STRAT}}$和$\\hat{\\mu}_{\\text{LHS}}$的方差，然后计算它们的比率。\n\n### 分层抽样估计量的方差 ($\\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}})$)\n\n策略 B 使用$m \\times m$网格上的分层抽样，其中$N=m^2$是总样本数。从$N$个方形单元中的每一个单元内均匀抽取一个样本。估计量由下式给出：\n$$ \\hat{\\mu}_{\\text{STRAT}} = \\frac{1}{N} \\sum_{k=1}^{N} f(X^{(k)}, Y^{(k)}) $$\n其中$(X^{(k)}, Y^{(k)})$是从第$k$个单元中均匀抽取的样本。不同单元的抽样是相互独立的。由于这种独立性，估计量的方差为：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}}) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{k=1}^{N} f(X^{(k)}, Y^{(k)})\\right) = \\frac{1}{N^2} \\sum_{k=1}^{N} \\operatorname{Var}(f(X^{(k)}, Y^{(k)})) $$\n我们将单元表示为$S_{ij} = [\\frac{i-1}{m}, \\frac{i}{m}] \\times [\\frac{j-1}{m}, \\frac{j}{m}]$，其中$i,j \\in \\{1, 2, \\dots, m\\}$。从单元$S_{ij}$中抽取的样本$(X_{ij}, Y_{ij})$由两个独立的随机变量组成：$X_{ij} \\sim \\text{Uniform}(\\frac{i-1}{m}, \\frac{i}{m})$和$Y_{ij} \\sim \\text{Uniform}(\\frac{j-1}{m}, \\frac{j}{m})$。\n对于函数$f(x,y)=x+y$，单元$S_{ij}$内的方差为：\n$$ \\operatorname{Var}(f(X_{ij}, Y_{ij})) = \\operatorname{Var}(X_{ij} + Y_{ij}) $$\n由于$X_{ij}$和$Y_{ij}$相互独立，这变为：\n$$ \\operatorname{Var}(X_{ij} + Y_{ij}) = \\operatorname{Var}(X_{ij}) + \\operatorname{Var(Y_{ij})} $$\n长度为$L$的区间上的均匀分布的方差为$\\frac{L^2}{12}$。$X_{ij}$和$Y_{ij}$的区间长度均为$L = \\frac{1}{m}$。\n$$ \\operatorname{Var}(X_{ij}) = \\frac{(1/m)^2}{12} = \\frac{1}{12m^2} $$\n$$ \\operatorname{Var}(Y_{ij}) = \\frac{(1/m)^2}{12} = \\frac{1}{12m^2} $$\n因此，任何单元内的方差为：\n$$ \\operatorname{Var}(f(X_{ij}, Y_{ij})) = \\frac{1}{12m^2} + \\frac{1}{12m^2} = \\frac{2}{12m^2} = \\frac{1}{6m^2} $$\n对于所有$N=m^2$个单元，这个方差是相同的。我们称之为$\\sigma_{\\text{cell}}^2$。\n估计量的总方差为：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}}) = \\frac{1}{N^2} \\sum_{k=1}^{N} \\sigma_{\\text{cell}}^2 = \\frac{1}{N^2} (N \\cdot \\frac{1}{6m^2}) = \\frac{1}{6Nm^2} $$\n代入$m^2=N$，我们得到：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}}) = \\frac{1}{6N \\cdot N} = \\frac{1}{6N^2} $$\n\n### 拉丁超立方抽样估计量的方差 ($\\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}})$)\n\n策略 A 使用拉丁超立方抽样，有$N$个样本。估计量是：\n$$ \\hat{\\mu}_{\\text{LHS}} = \\frac{1}{N} \\sum_{i=1}^{N} f(X_i, Y_{\\pi(i)}) = \\frac{1}{N} \\sum_{i=1}^{N} (X_i + Y_{\\pi(i)}) $$\n其中$X_i \\sim \\text{Uniform}(\\frac{i-1}{N}, \\frac{i}{N})$，$Y_j \\sim \\text{Uniform}(\\frac{j-1}{N}, \\frac{j}{N})$，$\\pi$是$\\{1, 2, \\dots, N\\}$的一个随机置换。变量集合$\\{X_i\\}_{i=1}^N$和$\\{Y_j\\}_{j=1}^N$相互独立，并且都独立于置换$\\pi$。\n\n由于函数$f(x,y)$的可加性，估计量可以被拆分：\n$$ \\hat{\\mu}_{\\text{LHS}} = \\frac{1}{N}\\sum_{i=1}^{N} X_i + \\frac{1}{N}\\sum_{i=1}^{N} Y_{\\pi(i)} $$\n第二个和是变量$\\{Y_1, \\dots, Y_N\\}$的一个置换，所以$\\sum_{i=1}^{N} Y_{\\pi(i)} = \\sum_{j=1}^{N} Y_j$。因此，估计量是：\n$$ \\hat{\\mu}_{\\text{LHS}} = \\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) + \\left(\\frac{1}{N}\\sum_{j=1}^{N} Y_j\\right) $$\n变量集合$\\{X_i\\}$独立于集合$\\{Y_j\\}$。因此，和的方差是方差的和：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}}) = \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) + \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{j=1}^{N} Y_j\\right) $$\n变量$X_1, \\dots, X_N$是独立的。$Y_1, \\dots, Y_N$也是独立的。\n$$ \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\operatorname{Var}(X_i) $$\n对于每个$i$，$X_i$在长度为$\\frac{1}{N}$的区间上均匀分布。其方差为$\\operatorname{Var}(X_i) = \\frac{(1/N)^2}{12} = \\frac{1}{12N^2}$。\n$$ \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\frac{1}{12N^2} = \\frac{1}{N^2} \\left(N \\cdot \\frac{1}{12N^2}\\right) = \\frac{1}{12N^3} $$\n类似地，对于$Y$分量：\n$$ \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{j=1}^{N} Y_j\\right) = \\frac{1}{12N^3} $$\n将两个方差相加，得到 LHS 估计量的总方差：\n$$ \\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}}) = \\frac{1}{12N^3} + \\frac{1}{12N^3} = \\frac{2}{12N^3} = \\frac{1}{6N^3} $$\n注意，对于这个可加函数，方差与随机置换$\\pi$无关。\n\n### 方差之比\n\n最后，我们计算比率$\\mathcal{R}(N) = \\frac{\\operatorname{Var}(\\hat{\\mu}_{\\text{STRAT}})}{\\operatorname{Var}(\\hat{\\mu}_{\\text{LHS}})}$：\n$$ \\mathcal{R}(N) = \\frac{1/(6N^2)}{1/(6N^3)} = \\frac{6N^3}{6N^2} = N $$\n\n对于这个特定问题，LHS 相对于分层抽样的改进是一个因子$N$。这一显著改进是由于被积函数$f(x,y)=x+y$的可加结构。LHS 有效地确保了样本在每个轴上的投影被完美地分层到$N$个区间中。这等同于对$\\mathbb{E}[X]$和$\\mathbb{E}[Y]$分别进行两个独立的、各有$N$层的一维分层抽样估计。对于线性函数，这种一维估计量的方差尺度为$O(N^{-3})$。相比之下，$m \\times m$的分层抽样在每个轴上仅投影到$m=\\sqrt{N}$个层，导致方差尺度为$O(m^{-4}) = O(N^{-2})$。因此，两种方差之比为$O(N)$。", "answer": "$$\\boxed{N}$$", "id": "3285740"}, {"introduction": "虽然标准的LHS保证了在每个维度上的良好边缘分布，但在高维空间中，它仍可能产生不必要的列间相关性。为了进一步提升样本质量，我们可以优化其空间填充属性。本练习将引导您实现一种旨在最小化列间相关性的高级LHS设计算法，通过迭代交换样本点来改进设计，这在不确定性量化和计算机实验设计中是一个重要的实践课题。", "problem": "给定任务是对拉丁超立方采样（LHS）的形式化并实现一种相关性最小化方案，该方案适用于高维随机模拟和蒙特卡洛方法。一个在$m$维空间中大小为$N$的拉丁超立方样本（LHS）是一个矩阵$X \\in \\mathbb{R}^{N \\times m}$，对于每一列$j \\in \\{1,\\dots,m\\}$，其$N$个条目$X_{1j},\\dots,X_{Nj}$占据了通过将单位区间$[0,1]$划分为$N$个相等子区间而形成的$N$个不相交的层。一个标准的随机化构造方法为每一行$i \\in \\{1,\\dots,N\\}$和每一列$j \\in \\{1,\\dots,m\\}$分配一个形式为$(\\pi_j(i) + U_{ij}) / N$的值，其中$\\pi_j$是$\\{0,1,\\dots,N-1\\}$的一个排列，而$U_{ij}$是在$[0,1)$上均匀分布的独立同分布随机变量。这确保了每一列中每个层都恰好被占据一次。\n\n对于任意列$j$，令$\\mu_j$表示样本均值，令$\\sigma_j$表示样本标准差（除数为$N$）。定义标准化矩阵$Z \\in \\mathbb{R}^{N \\times m}$为$Z_{ij} = (X_{ij} - \\mu_j)/\\sigma_j$。列$j$和$k$之间的皮尔逊相关系数由下式给出\n$$\nr_{jk} \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} Z_{ij} Z_{ik}.\n$$\n定义最小列相关性准则（目标函数）为\n$$\n\\Phi(X) \\;=\\; \\sum_{1 \\le j  k \\le m} \\left| r_{jk} \\right|.\n$$\n目标是通过保持LHS性质的交换操作来减小$\\Phi(X)$。\n\n您必须实现以下目标性交换算法方案以减少列相关性：\n\n- 初始化：\n  - 使用上述的分层均匀抖动方法，构造一个初始的随机化拉丁超立方样本$X \\in [0,1]^{N \\times m}$。\n  - 标准化各列以获得$Z$。\n  - 计算相关矩阵条目$r_{jk}$和$\\Phi(X)$。\n\n- 迭代式目标性交换过程：\n  - 在每次迭代中，为每一列$j$计算其相关性负担$s_j = \\sum_{k \\ne j} |r_{jk}|$。\n  - 选择具有最大$s_c$的列$c$。\n  - 考虑交换列$c$中位于两个不同行$i$和$k$的两个条目。这样的交换操作保持了LHS性质，因为它是在一列内排列条目，并且不改变该列所占据的层的多重集。\n  - 在所有可能的行对$(i,k)$（其中$1 \\le i  k \\le N$）中，选择在列$c$中能产生最大$\\Phi(X)$严格减小的单次交换。如果没有交换能产生严格减小，则终止该过程。否则，执行该交换，更新相关性量，并重复此过程，直到终止或达到最大接受交换次数$S_{\\max}$。\n\n您的程序必须实现上述算法，并为所提供的测试套件中的每组参数返回算法终止后的最终$\\Phi(X)$值。所有随机化必须通过指定的种子使其可复现。\n\n测试套件。对于每种情况，输入为LHS大小$N$、维度$m$、用于构造LHS的生成器的随机种子，以及最大接受交换次数$S_{\\max}$：\n- 情况 A（通用）：$N = 20$, $m = 5$, 种子 $= 314159$, $S_{\\max} = 2000$。\n- 情况 B（边界，一维）：$N = 8$, $m = 1$, 种子 $= 271828$, $S_{\\max} = 2000$。\n- 情况 C（更高维度，有迭代上限）：$N = 30$, $m = 10$, 种子 $= 424242$, $S_{\\max} = 300$。\n\n最终输出格式。您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表的结果，顺序为 [情况A结果, 情况B结果, 情况C结果]，其中每个结果是算法终止后$\\Phi(X)$的最终值，表示为小数点后保留六位的小数（例如，$[0.123456,0.000000,0.654321]$）。不应打印任何额外文本。", "solution": "该问题要求实现一个特定的迭代算法，以减少拉丁超立方样本（LHS）中的伪相关。该算法是一个贪婪的局部搜索过程，旨在最小化一个目标函数$\\Phi(X)$，该函数定义为样本矩阵各列之间成对皮尔逊相关系数绝对值之和。搜索过程通过迭代地交换对总相关性贡献最大的列中的元素对来进行。\n\n解决方案是按照问题陈述中概述的算法步骤来开发的：初始化，以及一个迭代式目标性交换过程。\n\n### 1. 初始化\n\n首先，必须构造一个初始的拉丁超立方样本矩阵$X \\in \\mathbb{R}^{N \\times m}$。根据问题描述，对于一个在$m$维空间中大小为$N$的样本，每一列$j \\in \\{1, \\dots, m\\}$必须包含来自$N$个不相交层$[k/N, (k+1)/N)$（其中$k \\in \\{0, \\dots, N-1\\}$）中的一个值。这是通过一个随机化的分层抽样过程实现的。\n\n对于每一列$j$：\n1.  生成整数集$\\{0, 1, \\dots, N-1\\}$的一个随机排列$\\pi_j$。这将一个唯一的层索引分配给$N$行中的每一行。\n2.  从$[0, 1)$上的均匀分布中抽取一个包含$N$个独立随机数的向量$U_{ij}$，其中$i \\in \\{1, \\dots, N\\}$。\n3.  然后，矩阵$X$的第$j$列的条目计算如下：\n    $$\n    X_{ij} = \\frac{\\pi_j(i) + U_{ij}}{N}\n    $$\n这种构造保证了LHS性质。所有的随机化都使用种子以确保可复现性。\n\n接下来，对样本矩阵$X$进行标准化。对于每一列$j$，我们计算样本均值$\\mu_j$和样本标准差$\\sigma_j$（按规定使用除数$N$）。\n$$\n\\mu_j = \\frac{1}{N}\\sum_{i=1}^{N} X_{ij} \\quad \\text{和} \\quad \\sigma_j = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} (X_{ij} - \\mu_j)^2}\n$$\n然后通过以下方式获得标准化矩阵$Z \\in \\mathbb{R}^{N \\times m}$：\n$$\nZ_{ij} = \\frac{X_{ij} - \\mu_j}{\\sigma_j}\n$$\n根据构造，$Z$的每一列的均值为$0$，标准差为$1$。\n\n任意两列$j$和$k$之间的皮尔逊相关系数$r_{jk}$是从标准化矩阵计算得出的。这些系数构成的矩阵$R$可以通过矩阵乘法高效计算：\n$$\nr_{jk} = \\frac{1}{N}\\sum_{i=1}^{N} Z_{ij} Z_{ik} \\quad \\implies \\quad R = \\frac{1}{N} Z^T Z\n$$\n注意，对角线元素$r_{jj}$恒等于$1$。\n\n最后，计算目标函数$\\Phi(X)$的初始值：\n$$\n\\Phi(X) = \\sum_{1 \\le j  k \\le m} |r_{jk}|\n$$\n这代表了非对角线相关性的总幅度，算法旨在将其最小化。对于$m=1$的边缘情况，这个和是空的，其值为$0$。\n\n### 2. 迭代式目标性交换过程\n\n算法的核心是一个迭代循环，它执行贪婪搜索以寻找能减少相关性的交换。循环持续进行，直到找不到进一步的改进或达到最大接受交换次数$S_{\\max}$。\n\n在每次迭代中，执行以下步骤：\n\n1.  **选择目标列**：识别对目标函数贡献最大的列。每列$j$的这种“相关性负担”$s_j$定义为与所有其他列的绝对相关性之和：\n    $$\n    s_j = \\sum_{k \\neq j} |r_{jk}|\n    $$\n    选择负担最大的列$c = \\arg\\max_j s_j$作为优化的目标。\n\n2.  **寻找最佳交换**：算法搜索一对行$(i, k)$，使得在目标列$c$中交换条目$X_{ic}$和$X_{kc}$能产生$\\Phi(X)$的最大可能严格减小。在单列内交换两个元素会保持该列中的值集合，因此其均值$\\mu_c$和标准差$\\sigma_c$保持不变。因此，标准化的值$Z_{ic}$和$Z_{kc}$也只是简单地交换。这种交换只影响涉及列$c$的相关性，即$r_{cl}$对于$l \\neq c$。\n\n    让我们推导当条目$Z_{ic}$和$Z_{kc}$被交换时，相关系数$r_{cl}$的变化。设$Z'$是交换后的矩阵。新的相关性$r'_{cl}$是：\n    $$\n    r'_{cl} = \\frac{1}{N}\\sum_{p=1}^{N} Z'_{pc} Z_{pl} = \\frac{1}{N} \\left( \\sum_{p \\notin \\{i,k\\}} Z_{pc}Z_{pl} + Z_{kc}Z_{il} + Z_{ic}Z_{kl} \\right)\n    $$\n    因此，变化量$\\Delta r_{cl} = r'_{cl} - r_{cl}$是：\n    $$\n    \\Delta r_{cl} = \\frac{1}{N} \\left( (Z_{kc}Z_{il} + Z_{ic}Z_{kl}) - (Z_{ic}Z_{il} + Z_{kc}Z_{kl}) \\right) = \\frac{1}{N} (Z_{kc} - Z_{ic})(Z_{il} - Z_{kl})\n    $$\n    当$j$和$k$都不等于$c$时，相关性$r_{jk}$不受影响。对于在列$c$中行$i$和$k$之间的交换，目标函数的总变化量$\\Delta \\Phi$是：\n    $$\n    \\Delta \\Phi_{i,k,c} = \\sum_{l \\neq c} \\left( |r_{cl} + \\Delta r_{cl}| - |r_{cl}| \\right)\n    $$\n    算法为所有可能的对$(i, k)$（其中$1 \\le i  k \\le N$）计算$\\Delta \\Phi_{i,k,c}$，并识别出产生最负值（最大减小）的那个。\n\n3.  **更新状态或终止**：\n    *   如果找到的最佳交换导致了严格减小（$\\Delta \\Phi  0$），则接受该交换。矩阵$Z$和$R$以及目标函数$\\Phi$都将被更新。我们不是重新计算整个矩阵$R$，而是应用计算出的变化量：对于所有$l \\neq c$，通过加上对应于最佳交换的$\\Delta r_{cl}$来更新$r_{cl}$。$\\Phi$的值通过加上最佳的$\\Delta \\Phi$来更新。交换计数器加一。\n    *   如果没有任何交换能够产生严格减小（对于所有对，$\\Delta \\Phi \\ge 0$），则对于当前目标列不可能有改进。算法的贪婪性质决定了此时终止。主循环被中断。\n\n该过程重复进行，直到满足其中一个终止条件。然后报告$\\Phi(X)$的最终值。\n\n### 3. 实现与向量化\n\n为了高效地实现这一点，特别是对最佳交换的搜索，我们使用向量化。对于选定的列$c$，我们可以使用 `numpy` 数组操作同时计算所有对$(i, k)$和所有其他列$l$的变化量$\\Delta r_{cl}$。这避免了在 Python 中使用缓慢的嵌套循环。具体来说，对于所有$N(N-1)/2$个行对，计算一个相关性变化矩阵。由此，可以导出一个$\\Delta \\Phi$值的向量，并且其最小值确定了最佳交换。然后基于这单个最佳交换，高效地执行对矩阵$Z$和$R$以及标量$\\Phi$的更新。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs the correlation-minimizing LHS algorithm for the given test suite.\n    \"\"\"\n    test_cases = [\n        # (N, m, seed, S_max)\n        (20, 5, 314159, 2000),  # Case A\n        (8, 1, 271828, 2000),   # Case B\n        (30, 10, 424242, 300),  # Case C\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, m, seed, S_max = case\n        rng = np.random.default_rng(seed)\n\n        # Handle the trivial 1D case. The objective function sum is empty.\n        if m == 1:\n            results.append(0.0)\n            continue\n\n        # --- 1. Initialization ---\n        \n        # Create the initial Latin Hypercube Sample matrix X\n        X = np.empty((N, m))\n        for j in range(m):\n            perm = rng.permutation(N)\n            u = rng.random(size=N)\n            X[:, j] = (perm + u) / N\n\n        # Standardize the matrix X to get Z\n        mu = np.mean(X, axis=0, keepdims=True)\n        # Use ddof=0 for divisor N as specified\n        sigma = np.std(X, axis=0, ddof=0, keepdims=True)\n        Z = (X - mu) / sigma\n        \n        # Compute the initial correlation matrix R and objective phi\n        R = (Z.T @ Z) / N\n        phi = np.sum(np.abs(np.triu(R, k=1)))\n        \n        # --- 2. Iterative Targeted-Swap Procedure ---\n        \n        num_swaps_accepted = 0\n        for _ in range(S_max):\n            # Select target column 'c' with the highest correlation burden\n            R_abs = np.abs(R)\n            np.fill_diagonal(R_abs, 0)\n            s = np.sum(R_abs, axis=1)\n            c = np.argmax(s)\n            \n            # Find the best swap in column 'c'\n            best_delta_phi = 0.0\n            best_swap_indices = None\n            best_delta_r = None\n\n            # Get all unique row pairs (i, k) where i  k\n            i_indices, k_indices = np.triu_indices(N, k=1)\n            \n            # Vectorized computation of potential changes\n            # For each potential swap (i,k), calculate the change in correlations r_cl\n            Z_col_c = Z[:, c]\n            Z_col_c_diffs = Z_col_c[k_indices] - Z_col_c[i_indices] # Shape: (num_pairs,)\n            \n            Z_row_diffs = Z[i_indices, :] - Z[k_indices, :] # Shape: (num_pairs, m)\n            \n            # Matrix of correlation changes. Shape: (num_pairs, m)\n            # Each row corresponds to a swap (i,k) and contains delta_r_cl for all l.\n            delta_r_matrix = (1 / N) * Z_col_c_diffs[:, np.newaxis] * Z_row_diffs\n            delta_r_matrix[:, c] = 0.0 # Change in r_cc is 0\n            \n            # Calculate the change in phi for each potential swap\n            mask = np.ones(m, dtype=bool)\n            mask[c] = False\n            \n            r_c_vec = R[c, mask]\n            r_c_new_matrix = r_c_vec[np.newaxis, :] + delta_r_matrix[:, mask]\n            \n            delta_phi_vec = np.sum(np.abs(r_c_new_matrix), axis=1) - np.sum(np.abs(r_c_vec))\n            \n            # Find the best swap among all pairs\n            min_idx = np.argmin(delta_phi_vec)\n            current_best_delta_phi = delta_phi_vec[min_idx]\n\n            if current_best_delta_phi  0:\n                best_delta_phi = current_best_delta_phi\n                best_swap_indices = (i_indices[min_idx], k_indices[min_idx])\n                best_delta_r = delta_r_matrix[min_idx, :]\n\n            # If no improvement found, terminate the algorithm\n            if best_swap_indices is None:\n                break\n            \n            # --- 3. Update State ---\n            \n            # Perform the best swap and update all relevant quantities\n            i, k = best_swap_indices\n            \n            # Update phi\n            phi += best_delta_phi\n            \n            # Update standardized matrix Z\n            Z[i, c], Z[k, c] = Z[k, c], Z[i, c]\n            \n            # Update correlation matrix R\n            R[c, :] += best_delta_r\n            R[:, c] = R[c, :]\n            \n            num_swaps_accepted += 1\n            if num_swaps_accepted >= S_max:\n                break\n\n        results.append(phi)\n\n    # Format output as specified\n    print(f\"[{','.join(f'{res:.6f}' for res in results)}]\")\n\nsolve()\n```", "id": "3317028"}]}