{"hands_on_practices": [{"introduction": "标准的蒙特卡洛方法在估计稀有事件概率时效率通常很低，因为绝大多数样本无法提供有效信息。这个动手实践练习 [@problem_id:3312679] 将指导你构建并实现一个基于指数倾斜策略的强大重要性采样估计器。这是一种基础技术，它通过改变采样分布使得稀有事件变得不再稀有，从而显著降低估计的方差。", "problem": "考虑独立同分布的随机变量 $X_1, X_2, \\dots, X_n$，每个变量都服从标准正态分布。定义稀有事件概率\n$$\np(n,a) \\equiv \\mathbb{P}\\left\\{\\frac{1}{n}\\sum_{i=1}^n X_i \\ge a\\right\\} = \\mathbb{P}\\left\\{\\sum_{i=1}^n X_i \\ge n a\\right\\}。\n$$\n从期望、概率的基本定义以及通过拉东-尼科迪姆（Radon–Nikodým）导数实现的测度变换原理出发，推导并实现一个使用重要性采样（IS）的 $p(n,a)$ 估计器。设计必须仅遵循以下经过充分检验的事实：\n- 标准正态随机变量的矩生成函数对任意实数参数 $t$ 都存在，并且其累积量生成函数 $\\psi(t)$ 对所有实数 $t$ 都是有限的。\n- 独立正态随机变量之和仍为正态分布，其均值和方差分别为各变量均值与方差之和。\n- 蒙特卡洛方法通过独立样本的经验平均值来估计期望。\n\n您必须：\n- 为 $p(n,a)$ 构建一个直接蒙特卡洛估计器（有时称为“原始”估计器）。\n- 通过指数倾斜测度变换为 $p(n,a)$ 构建一个重要性采样估计器，该变换使得稀有事件在采样分布下变得典型。您的推导必须从拉东-尼科迪姆（Radon–Nikodým）导数定义和累积量生成函数出发，并且必须使用基于累积量生成函数凸性性质的第一性原理最优性论证来证明倾斜参数选择的合理性。\n- 通过直接对和 $\\sum_{i=1}^n X_i$ 进行采样，而不是对 $n$ 维向量进行采样，来高效地实现这两种估计器。明确利用以下事实：如果 $Y_i$ 是均值为 $\\mu$、方差为 1 的独立正态随机变量，则 $\\sum_{i=1}^n Y_i$ 服从均值为 $n\\mu$、方差为 $n$ 的正态分布。\n\n不涉及物理单位。如果您的推理中出现任何角度，都必须以弧度为单位，但此处不需要角度。最终输出为浮点数。\n\n测试套件：\n- 案例 1：$n=100$，$a=0.5$，蒙特卡洛样本量 $M=200000$，随机种子 $s=12345$。\n- 案例 2：$n=100$，$a=0.0$，蒙特卡洛样本量 $M=100000$，随机种子 $s=54321$。\n- 案例 3：$n=50$，$a=0.3$，蒙特卡洛样本量 $M=50000$，随机种子 $s=2025$。\n- 案例 4：$n=200$，$a=1.0$，蒙特卡洛样本量 $M=300000$，随机种子 $s=777$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于每个测试案例，按顺序先输出原始蒙特卡洛估计值，然后输出重要性采样估计值。也就是说，该单行输出必须如下所示\n$$\n[\\widehat{p}_{\\text{crude},1},\\widehat{p}_{\\text{IS},1},\\widehat{p}_{\\text{crude},2},\\widehat{p}_{\\text{IS},2},\\widehat{p}_{\\text{crude},3},\\widehat{p}_{\\text{IS},3},\\widehat{p}_{\\text{crude},4},\\widehat{p}_{\\text{IS},4}],\n$$\n其中每个 $\\widehat{p}$ 都是一个浮点数。", "solution": "该问题已经过验证，并被确定为计算统计学和蒙特卡洛方法领域中一个有效且适定的问题。它具有科学依据，内容完整且客观。因此，我们可以进行完整的推导和求解。\n\n待估计的量是稀有事件概率\n$$\np(n,a) = \\mathbb{P}\\left\\{\\frac{1}{n}\\sum_{i=1}^n X_i \\ge a\\right\\}\n$$\n其中 $X_1, X_2, \\dots, X_n$ 是独立同分布 (i.i.d.) 的标准正态随机变量，$X_i \\sim \\mathcal{N}(0, 1)$。令 $S_n = \\sum_{i=1}^n X_i$。根据正态分布的性质，独立正态随机变量的和也服从正态分布。和的均值是均值的和，$\\mathbb{E}[S_n] = \\sum_{i=1}^n \\mathbb{E}[X_i] = \\sum_{i=1}^n 0 = 0$。和的方差是方差的和，$\\text{Var}(S_n) = \\sum_{i=1}^n \\text{Var}(X_i) = \\sum_{i=1}^n 1 = n$。因此，$S_n \\sim \\mathcal{N}(0, n)$。\n\n该概率可以用 $S_n$ 重写为 $p(n,a) = \\mathbb{P}\\{S_n \\ge na\\}$。这个概率可以表示为一个示性函数的期望，这构成了蒙特卡洛估计的基础：\n$$\np(n,a) = \\mathbb{E}\\left[\\mathbb{I}\\{S_n \\ge na\\}\\right]\n$$\n其中 $\\mathbb{I}\\{\\cdot\\}$ 是示性函数，当条件为真时其值为 1，否则为 0。该期望是关于 $S_n$ 的概率分布计算的，其概率密度函数 (PDF) 为 $f_{S_n}(s) = \\frac{1}{\\sqrt{2\\pi n}} \\exp\\left(-\\frac{s^2}{2n}\\right)$。\n\n**原始蒙特卡洛估计器**\n\n原始蒙特卡洛方法直接应用大数定律来估计期望。我们从 $S_n$ 的分布 $\\mathcal{N}(0, n)$ 中生成 $M$ 个独立样本，记为 $S_n^{(1)}, S_n^{(2)}, \\dots, S_n^{(M)}$。$p(n,a)$ 的估计器就是对这些样本求值的示性函数的样本均值：\n$$\n\\widehat{p}_{\\text{crude}}(n,a) = \\frac{1}{M}\\sum_{j=1}^M \\mathbb{I}\\left\\{S_n^{(j)} \\ge na\\right\\}\n$$\n该估计器是无偏的，即 $\\mathbb{E}[\\widehat{p}_{\\text{crude}}(n,a)] = p(n,a)$。然而，如果事件 $\\{S_n \\ge na\\}$ 是稀有事件，大多数样本 $S_n^{(j)}$ 将导致 $\\mathbb{I}\\{S_n^{(j)} \\ge na\\} = 0$，从而导致高方差和低效的估计。\n\n**重要性采样 (IS) 估计器**\n\n重要性采样的核心思想是改变概率测度，使稀有事件在新的测度下变得更频繁。我们引入一个带有 PDF $g(s)$ 的新采样分布，并重写期望：\n$$\np(n,a) = \\int_{-\\infty}^\\infty \\mathbb{I}\\{s \\ge na\\} f_{S_n}(s) ds = \\int_{-\\infty}^\\infty \\mathbb{I}\\{s \\ge na\\} \\frac{f_{S_n}(s)}{g(s)} g(s) ds = \\mathbb{E}_g\\left[\\mathbb{I}\\{Y \\ge na\\} L(Y)\\right]\n$$\n这里，$Y$ 是一个 PDF 为 $g(s)$ 的随机变量，$L(s) = \\frac{f_{S_n}(s)}{g(s)}$ 是似然比，也就是原始测度相对于新测度的拉东-尼科迪姆（Radon–Nikodým）导数。\n\nIS 估计器通过从新分布 $g(s)$ 中抽取 $M$ 个样本 $Y^{(1)}, \\dots, Y^{(M)}$ 并计算样本均值来构成：\n$$\n\\widehat{p}_{\\text{IS}}(n,a) = \\frac{1}{M}\\sum_{j=1}^M \\mathbb{I}\\left\\{Y^{(j)} \\ge na\\right\\} L(Y^{(j)})\n$$\n对于任何其支撑集覆盖被积函数非零积分域的 $g(s)$，该估计器也是无偏的。\n\n**指数倾斜与最优参数选择**\n\n新分布 $g(s)$ 的一个强大选择是对原始分布 $f_{S_n}(s)$ 进行指数倾斜。这通过一个倾斜参数 $\\theta$ 来定义：\n$$\ng_\\theta(s) = f_{S_n}(s) e^{\\theta s - \\Psi_{S_n}(\\theta)}\n$$\n其中 $\\Psi_{S_n}(\\theta) = \\ln \\mathbb{E}[e^{\\theta S_n}]$ 是 $S_n$ 的累积量生成函数 (CGF)。项 $e^{-\\Psi_{S_n}(\\theta)}$ 是归一化常数。由于 $X_i$ 是独立同分布的，$\\Psi_{S_n}(\\theta) = n \\psi(\\theta)$，其中 $\\psi(\\theta)$ 是单个 $X_i \\sim \\mathcal{N}(0, 1)$ 的 CGF。对于标准正态变量，矩生成函数为 $M_X(t) = e^{t^2/2}$，因此 CGF 为 $\\psi(t) = \\ln(M_X(t)) = t^2/2$。因此，$S_n$ 的 CGF 为 $\\Psi_{S_n}(\\theta) = n\\theta^2/2$。\n\n将 PDF 和 CGF 代入 $g_\\theta(s)$ 的定义中：\n$$\ng_\\theta(s) = \\left[\\frac{1}{\\sqrt{2\\pi n}} e^{-s^2/(2n)}\\right] e^{\\theta s - n\\theta^2/2} = \\frac{1}{\\sqrt{2\\pi n}} \\exp\\left(-\\frac{s^2 - 2n\\theta s + n^2\\theta^2}{2n}\\right) = \\frac{1}{\\sqrt{2\\pi n}} \\exp\\left(-\\frac{(s - n\\theta)^2}{2n}\\right)\n$$\n这是均值为 $n\\theta$、方差为 $n$ 的正态分布的 PDF，即 $Y \\sim \\mathcal{N}(n\\theta, n)$。似然比为 $L(s) = \\frac{f_{S_n}(s)}{g_\\theta(s)} = e^{-\\theta s + \\Psi_{S_n}(\\theta)} = e^{-\\theta s + n\\theta^2/2}$。\n\n$\\theta$ 的最优选择是使 IS 估计器方差最小化的那个。估计器的方差由随机变量 $Z = \\mathbb{I}\\{Y \\ge na\\}L(Y)$ 的二阶矩决定。一种在大偏差理论背景下渐进最优的有效启发式方法是，选择 $\\theta$ 使得新分布的均值位于事件的“最重要”区域中心。对于单边事件 $\\{S_n \\ge na\\}$，这对应于将新分布的中心置于事件区域的边界。\n\n我们将采样分布的均值设为阈值 $na$：\n$$\n\\mathbb{E}_\\theta[Y] = na\n$$\n指数族的一个基本性质是，倾斜分布的均值是 CGF 的导数：$\\mathbb{E}_\\theta[Y] = \\Psi'_{S_n}(\\theta)$。因此，我们求解方程中的 $\\theta$：\n$$\n\\Psi'_{S_n}(\\theta) = na\n$$\n已知 $\\Psi_{S_n}(\\theta) = n\\theta^2/2$，其导数为 $\\Psi'_{S_n}(\\theta) = n\\theta$。方程变为：\n$$\nn\\theta = na \\implies \\theta = a\n$$\nCGF $\\Psi_{S_n}(\\theta)$ 是严格凸的，因为其二阶导数 $\\Psi''_{S_n}(\\theta) = n > 0$。这种严格凸性保证了方程 $\\Psi'_{S_n}(\\theta) = na$ 对于 $\\theta$ 有唯一解。\n\n使用最优参数 $\\theta = a$，我们的 IS 步骤如下：\n1.  从分布 $\\mathcal{N}(na, n)$ 中采样 $Y^{(j)}$。\n2.  计算每个样本的似然比：$L(Y^{(j)}) = \\exp\\left(-a Y^{(j)} + na^2/2\\right)$。\n3.  计算估计值：\n    $$\n    \\widehat{p}_{\\text{IS}}(n,a) = \\frac{1}{M}\\sum_{j=1}^M \\mathbb{I}\\left\\{Y^{(j)} \\ge na\\right\\} e^{-a Y^{(j)} + na^2/2}\n    $$\n通过将采样分布的中心置于事件边界，我们确保了相当一部分样本（约 50%）将落入事件区域 $\\{Y \\ge na\\}$，这与原始方法相比，极大地减小了估计器的方差，尤其是在 $p(n,a)$ 非常小的情况下。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements crude Monte Carlo and Importance Sampling estimators\n    for a rare-event probability involving a sum of standard normal variables.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, a, M, random_seed)\n        (100, 0.5, 200000, 12345),\n        (100, 0.0, 100000, 54321),\n        (50, 0.3, 50000, 2025),\n        (200, 1.0, 300000, 777),\n    ]\n\n    results = []\n    for n, a, M, s in test_cases:\n        # Initialize a random number generator with the specified seed for reproducibility.\n        rng = np.random.default_rng(s)\n\n        # The target event is sum(X_i) >= n*a.\n        threshold = n * a\n\n        # The sum S_n = sum(X_i) is distributed as Normal(0, n).\n        mean_original = 0.0\n        # The standard deviation is sqrt(n).\n        std_dev = np.sqrt(n)\n\n        # --- Crude Monte Carlo Estimator ---\n        # Generate M samples from the original distribution N(0, n).\n        samples_crude = rng.normal(loc=mean_original, scale=std_dev, size=M)\n        \n        # The estimate is the fraction of samples that fall into the event region.\n        p_crude = np.mean(samples_crude >= threshold)\n        results.append(p_crude)\n\n        # --- Importance Sampling (IS) Estimator ---\n        # The optimal tilting parameter is theta = a.\n        theta = a\n\n        # The mean of the IS sampling distribution N(n*theta, n).\n        mean_is = n * theta\n        # The standard deviation is the same, sqrt(n).\n        \n        # Generate M samples from the tilted (IS) distribution.\n        samples_is = rng.normal(loc=mean_is, scale=std_dev, size=M)\n        \n        # Calculate the likelihood ratio for each sample.\n        # L(s) = exp(-theta*s + n*psi(theta)), where psi(theta) = theta^2/2 for N(0,1).\n        # CGF of the sum is n*psi(theta).\n        log_likelihood_ratios = -theta * samples_is + n * theta**2 / 2.0\n        likelihood_ratios = np.exp(log_likelihood_ratios)\n\n        # The IS estimate is the average of the indicator function times the likelihood ratio.\n        # The indicator function is 1 if sample >= threshold, and 0 otherwise.\n        indicators = (samples_is >= threshold)\n        p_is = np.mean(indicators * likelihood_ratios)\n        results.append(p_is)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3312679"}, {"introduction": "一个好的重要性采样估计器依赖于一个能紧密模仿目标分布的提议分布，但我们如何量化这种“紧密”程度呢？本练习 [@problem_id:3312707] 引入了有效样本量 (Effective Sample Size, ESS) 这一评估估计器效率的关键指标，并要求你在一个理想化的场景中，通过解析方法找到最优的提议分布。这将加深你对“理想的提议分布就是目标分布本身”这一核心原则的理解。", "problem": "考虑一个在 $\\,\\mathbb{R}^{d}\\,$ 上的目标概率密度 $\\,\\pi(x)\\,$，它由一个均值为 $\\,\\mu \\in \\mathbb{R}^{d}\\,$、协方差矩阵为正定矩阵 $\\,\\Sigma \\in \\mathbb{R}^{d \\times d}\\,$ 的多元正态分布给出，即 $\\,\\pi(x) = \\mathcal{N}(x;\\mu,\\Sigma)\\,$。对于重要性采样（IS），从一个提议分布族 $\\,q_{\\theta}(x)\\,$ 中抽取 $\\,n\\,$ 个独立样本 $\\,X_{1},\\dots,X_{n}\\,$，该分布族也是一个多元正态分布，具有相同的协方差，但其均值参数 $\\,\\theta \\in \\mathbb{R}^{d}\\,$ 是可调的，即 $\\,q_{\\theta}(x) = \\mathcal{N}(x;\\theta,\\Sigma)\\,$。定义重要性采样权重为 $\\,w(x) = \\pi(x)/q_{\\theta}(x)\\,$，这 $\\,n\\,$ 个样本的有效样本量（ESS）为\n$$\n\\mathrm{ESS} \\;=\\; \\frac{\\left(\\sum_{i=1}^{n} w(X_{i})\\right)^{2}}{\\sum_{i=1}^{n} w(X_{i})^{2}}.\n$$\n从第一性原理出发——即重要性采样的定义、多元正态分布的性质以及大数定律——推导出一个对 $\\,\\mathbb{E}[\\mathrm{ESS}]\\,$ 的解析易处理的近似，该近似仅依赖于 $\\,w(X)\\,$ 在 $\\,q_{\\theta}\\,$ 下的一阶矩和二阶矩。然后，对于指定的 $\\,\\pi\\,$ 和 $\\,q_{\\theta}\\,$，关于 $\\,\\theta\\,$ 最大化这个易处理的近似。为优化器 $\\,\\theta^{\\star}\\,$ 提供一个单一的闭式解析表达式。无需进行数值计算，也无需四舍五入。最终答案无需单位。", "solution": "用户希望我解决以下问题。\n- **问题陈述**：\n考虑一个在 $\\,\\mathbb{R}^{d}\\,$ 上的目标概率密度 $\\,\\pi(x)\\,$，它由一个均值为 $\\,\\mu \\in \\mathbb{R}^{d}\\,$、协方差矩阵为正定矩阵 $\\,\\Sigma \\in \\mathbb{R}^{d \\times d}\\,$ 的多元正态分布给出，即 $\\,\\pi(x) = \\mathcal{N}(x;\\mu,\\Sigma)\\,$。对于重要性采样（IS），从一个提议分布族 $\\,q_{\\theta}(x)\\,$ 中抽取 $\\,n\\,$ 个独立样本 $\\,X_{1},\\dots,X_{n}\\,$，该分布族也是一个多元正态分布，具有相同的协方差，但其均值参数 $\\,\\theta \\in \\mathbb{R}^{d}\\,$ 是可调的，即 $\\,q_{\\theta}(x) = \\mathcal{N}(x;\\theta,\\Sigma)\\,$。定义重要性采样权重为 $\\,w(x) = \\pi(x)/q_{\\theta}(x)\\,$，这 $\\,n\\,$ 个样本的有效样本量（ESS）为\n$$\n\\mathrm{ESS} \\;=\\; \\frac{\\left(\\sum_{i=1}^{n} w(X_{i})\\right)^{2}}{\\sum_{i=1}^{n} w(X_{i})^{2}}.\n$$\n从第一性原理出发——即重要性采样的定义、多元正态分布的性质以及大数定律——推导出一个对 $\\,\\mathbb{E}[\\mathrm{ESS}]\\,$ 的解析易处理的近似，该近似仅依赖于 $\\,w(X)\\,$ 在 $\\,q_{\\theta}\\,$ 下的一阶矩和二阶矩。然后，对于指定的 $\\,\\pi\\,$ 和 $\\,q_{\\theta}\\,$，关于 $\\,\\theta\\,$ 最大化这个易处理的近似。为优化器 $\\,\\theta^{\\star}\\,$ 提供一个单一的闭式解析表达式。无需进行数值计算，也无需四舍五入。最终答案无需单位。\n\n### 步骤1：提取已知条件\n- 目标分布：$\\pi(x) = \\mathcal{N}(x; \\mu, \\Sigma)$，其中 $\\mu \\in \\mathbb{R}^d$，$\\Sigma \\in \\mathbb{R}^{d \\times d}$ 是正定矩阵。\n- 提议分布：$q_{\\theta}(x) = \\mathcal{N}(x; \\theta, \\Sigma)$，其中 $\\theta \\in \\mathbb{R}^d$ 是一个可调参数。\n- 样本：$X_1, \\dots, X_n$ 是从 $q_{\\theta}(x)$ 中抽取的独立同分布（i.i.d.）样本。\n- 重要性权重函数：$w(x) = \\pi(x) / q_{\\theta}(x)$。\n- 有效样本量（ESS）定义：$\\mathrm{ESS} = \\frac{(\\sum_{i=1}^{n} w(X_{i}))^{2}}{\\sum_{i=1}^{n} w(X_{i})^{2}}$。\n- 任务1：使用 $w(X)$ 在 $q_{\\theta}$ 下的一阶矩和二阶矩，推导一个对 $\\mathbb{E}[\\mathrm{ESS}]$ 的解析易处理的近似。\n- 任务2：关于 $\\theta$ 最大化此近似，以找到最优参数 $\\theta^{\\star}$。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学上合理**：该问题在随机模拟和蒙特卡洛方法领域是成熟的。重要性采样、多元正态分布和有效样本量的概念是标准的、数学上合理的。\n- **良态的**：问题陈述清晰，包含所有必要的定义。目标明确：推导近似并求其最大值。鉴于问题的结构，唯一解的存在是合理的。\n- **客观的**：语言正式、精确，不含任何主观性。\n\n该问题没有表现出任何无效性缺陷：\n1. 它在科学上和数学上是合理的。\n2. 它是一个正式的问题，与主题直接相关。\n3. 它是自洽的，没有矛盾。$\\Sigma$ 是正定的条件陈述正确。\n4. 该设置是用于研究重要性采样性质的标准理想化情景；它并非物理上不切实际。\n5. 它结构良好，能导出一个唯一的、有意义的解。\n6. 问题并非微不足道；它需要一个涉及统计理论和微积分的多步推导。\n7. 结果在数学上是可验证的。\n\n### 步骤3：结论与行动\n问题是有效的。我将开始求解。\n\n###\n问题要求我们首先推导有效样本量期望 $\\mathbb{E}[\\mathrm{ESS}]$ 的一个易处理近似，然后关于提议参数 $\\theta$ 最大化这个近似。\n\n首先，我们推导 $\\mathbb{E}[\\mathrm{ESS}]$ 的近似。给定的 ESS 表达式是随机变量总和的比率：\n$$\n\\mathrm{ESS} = \\frac{\\left(\\sum_{i=1}^{n} w(X_{i})\\right)^{2}}{\\sum_{i=1}^{n} w(X_{i})^{2}}\n$$\n其中 $X_i \\sim q_{\\theta}(x)$ 是独立同分布样本。\n我们可以通过将分子和分母分别除以 $n^2$ 和 $n$ 来重写此表达式：\n$$\n\\mathrm{ESS} = n \\frac{\\left(\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i})\\right)^{2}}{\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i})^{2}}\n$$\n根据大数定律，对于大样本量 $n$，样本均值依概率收敛于其各自的期望：\n$$\n\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i}) \\xrightarrow{p} \\mathbb{E}_{q_{\\theta}}[w(X)]\n$$\n$$\n\\frac{1}{n}\\sum_{i=1}^{n} w(X_{i})^{2} \\xrightarrow{p} \\mathbb{E}_{q_{\\theta}}[w(X)^2]\n$$\n其中期望是关于提议分布 $q_{\\theta}$ 计算的。利用此收敛性，我们可以构建一个对 $\\mathrm{ESS}$ 的近似，当 $n \\to \\infty$ 时，这个近似越来越精确。比率的期望可以用期望的比率来近似。因此，$\\mathbb{E}[\\mathrm{ESS}]$ 的易处理近似由下式给出：\n$$\n\\mathbb{E}[\\mathrm{ESS}] \\approx n \\frac{\\left(\\mathbb{E}_{q_{\\theta}}[w(X)]\\right)^{2}}{\\mathbb{E}_{q_{\\theta}}[w(X)^2]}\n$$\n此表达式仅依赖于权重 $w(X)$ 在 $q_{\\theta}$ 下的前两阶矩，符合要求。\n\n接下来，我们必须为指定的分布计算这两个矩。\n一阶矩是重要性采样的一个基本性质：\n$$\n\\mathbb{E}_{q_{\\theta}}[w(X)] = \\int w(x) q_{\\theta}(x) \\, dx = \\int \\frac{\\pi(x)}{q_{\\theta}(x)} q_{\\theta}(x) \\, dx = \\int \\pi(x) \\, dx = 1\n$$\n因为 $\\pi(x)$ 是一个概率密度函数。\n\n现在，我们计算二阶矩 $\\mathbb{E}_{q_{\\theta}}[w(X)^2]$。权重函数是两个多元正态密度的比率：\n$$\nw(x) = \\frac{\\mathcal{N}(x;\\mu,\\Sigma)}{\\mathcal{N}(x;\\theta,\\Sigma)} = \\frac{\\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu)\\right)}{\\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\theta)^T \\Sigma^{-1} (x-\\theta)\\right)}\n$$\n$$\nw(x) = \\exp\\left(-\\frac{1}{2}\\left[(x-\\mu)^T \\Sigma^{-1} (x-\\mu) - (x-\\theta)^T \\Sigma^{-1} (x-\\theta)\\right]\\right)\n$$\n我们来简化指数中的项：\n$$\n(x-\\mu)^T \\Sigma^{-1} (x-\\mu) - (x-\\theta)^T \\Sigma^{-1} (x-\\theta) = (x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\mu + \\mu^T\\Sigma^{-1}\\mu) - (x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\theta + \\theta^T\\Sigma^{-1}\\theta)\n$$\n$$\n= 2x^T\\Sigma^{-1}(\\theta-\\mu) + \\mu^T\\Sigma^{-1}\\mu - \\theta^T\\Sigma^{-1}\\theta\n$$\n所以，权重为 $w(x) = \\exp\\left(-x^T\\Sigma^{-1}(\\theta-\\mu) - \\frac{1}{2}(\\mu^T\\Sigma^{-1}\\mu - \\theta^T\\Sigma^{-1}\\theta)\\right)$。\n因此，$w(x)^2$ 是：\n$$\nw(x)^2 = \\exp\\left(-2x^T\\Sigma^{-1}(\\theta-\\mu) - (\\mu^T\\Sigma^{-1}\\mu - \\theta^T\\Sigma^{-1}\\theta)\\right)\n$$\n二阶矩是此量在 $q_{\\theta}(x) = \\mathcal{N}(x;\\theta,\\Sigma)$ 下的期望：\n$$\n\\mathbb{E}_{q_{\\theta}}[w(X)^2] = \\int w(x)^2 q_{\\theta}(x) \\, dx\n$$\n$$\n= \\int \\exp\\left(-2x^T\\Sigma^{-1}(\\theta-\\mu) - (\\mu^T\\Sigma^{-1}\\mu - \\theta^T\\Sigma^{-1}\\theta)\\right) \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\theta)^T \\Sigma^{-1} (x-\\theta)\\right) dx\n$$\n我们合并指数中的项。总的指数为：\n$$\n-2x^T\\Sigma^{-1}(\\theta-\\mu) - (\\mu^T\\Sigma^{-1}\\mu - \\theta^T\\Sigma^{-1}\\theta) - \\frac{1}{2}(x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\theta + \\theta^T\\Sigma^{-1}\\theta)\n$$\n$$\n= -\\frac{1}{2}x^T\\Sigma^{-1}x + (2x^T\\Sigma^{-1}\\mu - 2x^T\\Sigma^{-1}\\theta + x^T\\Sigma^{-1}\\theta) - \\mu^T\\Sigma^{-1}\\mu + \\theta^T\\Sigma^{-1}\\theta - \\frac{1}{2}\\theta^T\\Sigma^{-1}\\theta\n$$\n$$\n= -\\frac{1}{2}x^T\\Sigma^{-1}x + x^T\\Sigma^{-1}(2\\mu - \\theta) - \\mu^T\\Sigma^{-1}\\mu + \\frac{1}{2}\\theta^T\\Sigma^{-1}\\theta\n$$\n我们对含有 $x$ 的项进行配方：\n$$\n-\\frac{1}{2}x^T\\Sigma^{-1}x + x^T\\Sigma^{-1}(2\\mu - \\theta) = -\\frac{1}{2}\\left(x - (2\\mu-\\theta)\\right)^T\\Sigma^{-1}\\left(x-(2\\mu-\\theta)\\right) + \\frac{1}{2}(2\\mu-\\theta)^T\\Sigma^{-1}(2\\mu-\\theta)\n$$\n将此代回完整的指数表达式：\n$$\n\\text{指数} = -\\frac{1}{2}\\left(x - (2\\mu-\\theta)\\right)^T\\Sigma^{-1}\\left(x-(2\\mu-\\theta)\\right) + \\frac{1}{2}(2\\mu-\\theta)^T\\Sigma^{-1}(2\\mu-\\theta) - \\mu^T\\Sigma^{-1}\\mu + \\frac{1}{2}\\theta^T\\Sigma^{-1}\\theta\n$$\n指数的常数部分简化为：\n$$\n\\frac{1}{2}(4\\mu^T\\Sigma^{-1}\\mu - 4\\mu^T\\Sigma^{-1}\\theta + \\theta^T\\Sigma^{-1}\\theta) - \\mu^T\\Sigma^{-1}\\mu + \\frac{1}{2}\\theta^T\\Sigma^{-1}\\theta\n$$\n$$\n= 2\\mu^T\\Sigma^{-1}\\mu - 2\\mu^T\\Sigma^{-1}\\theta + \\frac{1}{2}\\theta^T\\Sigma^{-1}\\theta - \\mu^T\\Sigma^{-1}\\mu + \\frac{1}{2}\\theta^T\\Sigma^{-1}\\theta\n$$\n$$\n= \\mu^T\\Sigma^{-1}\\mu - 2\\mu^T\\Sigma^{-1}\\theta + \\theta^T\\Sigma^{-1}\\theta = (\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\n$$\n二阶矩的积分变为：\n$$\n\\mathbb{E}_{q_{\\theta}}[w(X)^2] = \\int \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}\\left(x - (2\\mu-\\theta)\\right)^T\\Sigma^{-1}\\left(x-(2\\mu-\\theta)\\right) \\right) \\exp\\left((\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right) dx\n$$\n项 $\\exp\\left((\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)$ 相对于 $x$ 是一个常数。剩余的积分是一个正态密度 $\\mathcal{N}(x; 2\\mu-\\theta, \\Sigma)$ 在其定义域上的积分，其值为 $1$。\n因此，二阶矩为：\n$$\n\\mathbb{E}_{q_{\\theta}}[w(X)^2] = \\exp\\left((\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)\n$$\n现在，将矩代回 $\\mathbb{E}[\\mathrm{ESS}]$ 的近似式中：\n$$\n\\mathbb{E}[\\mathrm{ESS}] \\approx n \\frac{1^2}{\\exp\\left((\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)} = n \\exp\\left(-(\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)\n$$\n我们的最终任务是关于 $\\theta$ 最大化此表达式。设目标函数为 $J(\\theta)$：\n$$\nJ(\\theta) = n \\exp\\left(-(\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\\right)\n$$\n由于 $n$ 是一个正常数，且指数函数 $\\exp(z)$ 是严格单调递增的，最大化 $J(\\theta)$ 等价于最大化其参数，这又等价于最小化二次型：\n$$\nQ(\\theta) = (\\theta-\\mu)^T\\Sigma^{-1}(\\theta-\\mu)\n$$\n项 $Q(\\theta)$ 是向量 $\\theta$ 和 $\\mu$ 之间的马氏距离的平方。矩阵 $\\Sigma$ 被给定为正定协方差矩阵，这意味着其逆矩阵 $\\Sigma^{-1}$ 也是正定的。\n对于任何正定矩阵 $A$ 和任何非零向量 $v$，二次型 $v^T A v$ 严格为正。此二次型的最小值为 $0$，当且仅当 $v = 0$ 时取到。\n在我们的例子中，令 $v = \\theta - \\mu$。$Q(\\theta)$ 的最小值为 $0$，这当且仅当以下条件发生时：\n$$\n\\theta - \\mu = 0\n$$\n这意味着参数 $\\theta$ 的最优选择是：\n$$\n\\theta^{\\star} = \\mu\n$$\n这个结果是直观正确的。有效样本量是采样效率的一种度量。当提议分布 $q_{\\theta}(x)$ 与目标分布 $\\pi(x)$ 完全相同时，效率达到最大。在这个问题中，两个分布都属于同一分布族 $\\mathcal{N}(\\cdot, \\Sigma)$，因此，要使它们相同，需要将它们的均值设为相等，即 $\\theta = \\mu$。在这种情况下，对所有 $x$ 都有 $w(x)=1$，真实的ESS恰好为 $n$，这是其可能的最大值。我们的近似也得出了这个最大值：$J(\\mu) = n \\exp(0) = n$。", "answer": "$$ \\boxed{\\mu} $$", "id": "3312707"}, {"introduction": "尽管指数倾斜等常见的提议分布设计策略非常强大，但它们也有其局限性。本练习 [@problem_id:3312692] 揭示了一种关键的失效模式：一个看似合理的倾斜提议分布，由于其与目标分布的尾部行为不匹配，会导致权重无界和估计器方差无穷大。通过将其与一种更稳健的输运映射 (transport map) 方法进行比较，你将更深刻地理解提议分布的尾部行为如何决定重要性采样估计器的稳定性和可靠性。", "problem": "考虑在重要性采样 (IS) 背景下的以下稀有事件估计问题。设目标分布为位置参数为 $0$、尺度参数为 $1$ 的拉普拉斯分布，其概率密度函数对所有 $x \\in \\mathbb{R}$ 为 $p(x) = \\frac{1}{2}\\exp(-|x|)$。稀有事件为左尾超出事件 $\\{x \\le -a\\}$，其中 $a  0$ 是一个固定值。考虑两种提议分布构建策略：\n\n1. 指数族倾斜：对于一个固定的倾斜参数 $\\theta \\in (-1,0)$，定义提议分布 $q_{\\theta}(x)$ 为 $q_{\\theta}(x) \\propto p(x)\\exp(\\theta x)$，并将其归一化为 $\\mathbb{R}$ 上的一个概率密度。\n\n2. 变换映射提议：取基础提议分布 $q_{0}$ 为 $[0,\\infty)$ 上率参数为 $\\lambda  0$ 的指数分布 (Exponential$(\\lambda)$)，其密度为 $q_{0}(u) = \\lambda \\exp(-\\lambda u)$。定义确定性变换 $T:[0,\\infty) \\to (-\\infty,-a]$ 为 $T(u) = -a - u$，并设 $q_{T} = T_{\\#}q_{0}$ 为由 $T$ 在 $(-\\infty,-a]$ 上导出的推前密度。\n\n你需要比较这两种提议分布构建方法，用于通过重要性采样估计稀有事件概率 $\\mathbb{P}(X \\le -a)$。请从第一性原理和以下基本定义出发：\n\n- 对于提议分布 $q$，其重要性采样权重在其支撑集上为 $w(x) = \\frac{p(x)}{q(x)}$。\n- 当 $x = T(u)$ 且 $T$ 在其值域上可微且可逆时，推前 $q_{T} = T_{\\#}q_{0}$ 满足 $q_{T}(x) = q_{0}(u)\\left|\\frac{d u}{d x}\\right|$。\n- Laplace$(0,1)$ 分布的矩生成函数 $M_{X}(\\theta) = \\mathbb{E}[\\exp(\\theta X)]$ 在 $|\\theta|  1$ 时存在，且等于 $M_{X}(\\theta) = \\frac{1}{1 - \\theta^{2}}$。\n\n任务：\n- 使用这些定义，证明对于 $\\theta \\in (-1,0)$，与指数族倾斜 $q_{\\theta}$ 相关的重要性采样权重 $w_{\\theta}(x)$ 在事件 $\\{x \\le -a\\}$ 上是无界的。\n- 对于变换映射提议 $q_{T}$，推导在 $(-\\infty,-a]$ 上的精确重要性采样权重 $w_{T}(x)$，并确定在该事件上的上确界 $\\sup_{x \\le -a} w_{T}(x)$。\n\n将最终答案报告为 $\\sup_{x \\le -a} w_{T}(x)$ 关于 $a$ 和 $\\lambda$ 的精确闭式表达式。无需四舍五入。", "solution": "用户想要分析和比较两种不同的重要性采样提议策略，用于在 $X$ 服从拉普拉斯分布的情况下估计稀有事件概率 $\\mathbb{P}(X \\le -a)$。\n\n### 步骤 1：问题验证\n\n**提取的已知条件：**\n- 目标分布密度：$p(x) = \\frac{1}{2}\\exp(-|x|)$，对于 $x \\in \\mathbb{R}$。\n- 稀有事件：$\\{x \\le -a\\}$，对于一个固定的 $a  0$。\n- 提议 1 (指数族倾斜)：$q_{\\theta}(x) \\propto p(x)\\exp(\\theta x)$，对于一个固定的 $\\theta \\in (-1,0)$。\n- 提议 2 (变换映射)：\n    - 基础分布密度：$q_{0}(u) = \\lambda \\exp(-\\lambda u)$，对于 $u \\in [0,\\infty)$，其中 $\\lambda  0$。\n    - 变换映射：$T:[0,\\infty) \\to (-\\infty,-a]$，定义为 $T(u) = -a - u$。\n    - 提议密度：$q_{T} = T_{\\#}q_{0}$。\n- 重要性采样权重定义：$w(x) = \\frac{p(x)}{q(x)}$。\n- 推前密度公式：$q_{T}(x) = q_{0}(u)\\left|\\frac{d u}{d x}\\right|$，当 $x = T(u)$ 时。\n- Laplace$(0,1)$ 的矩生成函数：$M_{X}(\\theta) = \\mathbb{E}[\\exp(\\theta X)] = \\frac{1}{1 - \\theta^{2}}$，对于 $|\\theta|  1$。\n\n**验证：**\n1.  **科学依据：** 该问题基于概率论和随机模拟的既定原则，特别是重要性采样、拉普拉斯分布、指数族倾斜和变换映射。所涉及的概念和定义都是标准的、科学上合理的。\n2.  **适定性：** 任务定义清晰：证明一种提议分布的权重无界，并为另一种提议分布推导权重及其上确界。给定信息足以完成这些任务。\n3.  **客观性：** 问题以精确、客观的数学语言陈述。\n4.  **一致性和完整性：** 问题是自洽的。$q_{\\theta}(x)$ 的归一化常数可以使用提供的矩生成函数找到。变换映射提议的细节都已指定。没有矛盾之处。\n\n**结论：** 问题有效。我们继续进行求解。\n\n### 步骤 2：解题推导\n\n解题过程分为两部分，每部分对应一种提议分布构建策略。\n\n**第一部分：指数族倾斜提议 $q_{\\theta}(x)$**\n\n首先，我们必须归一化提议密度 $q_{\\theta}(x)$。根据定义，$q_{\\theta}(x) \\propto p(x)\\exp(\\theta x)$。归一化常数 $C_{\\theta}$ 是未归一化密度在 $\\mathbb{R}$ 上的积分：\n$$C_{\\theta} = \\int_{-\\infty}^{\\infty} p(x)\\exp(\\theta x) \\,dx$$\n根据定义，这个积分是密度为 $p(x)$ 的随机变量 $X$ 的矩生成函数 (MGF) 在 $\\theta$ 处的值。问题中提供了该矩生成函数：\n$$C_{\\theta} = M_{X}(\\theta) = \\frac{1}{1 - \\theta^{2}}$$\n这在 $|\\theta|  1$ 时成立，该范围包含了指定的 $\\theta \\in (-1,0)$。\n因此，归一化后的提议密度为：\n$$q_{\\theta}(x) = \\frac{p(x)\\exp(\\theta x)}{M_{X}(\\theta)} = (1 - \\theta^{2})p(x)\\exp(\\theta x)$$\n现在，我们可以计算重要性采样权重 $w_{\\theta}(x)$：\n$$w_{\\theta}(x) = \\frac{p(x)}{q_{\\theta}(x)} = \\frac{p(x)}{(1 - \\theta^{2})p(x)\\exp(\\theta x)} = \\frac{1}{1 - \\theta^{2}}\\exp(-\\theta x)$$\n题目要求我们证明这些权重在事件 $\\{x \\le -a\\}$ 上是无界的。该事件对应于区间 $(-\\infty, -a]$。我们必须分析当 $x \\to -\\infty$ 时 $w_{\\theta}(x)$ 的行为。\n问题指定 $\\theta \\in (-1,0)$，这意味着 $-\\theta$ 是严格为正的，即 $-\\theta \\in (0,1)$。\n考虑当 $x$ 趋近于 $-\\infty$ 时 $w_{\\theta}(x)$ 的极限：\n$$\\lim_{x \\to -\\infty} w_{\\theta}(x) = \\lim_{x \\to -\\infty} \\frac{1}{1 - \\theta^{2}}\\exp(-\\theta x)$$\n由于 $-\\theta  0$，当 $x \\to -\\infty$ 时，指数的参数 $-\\theta x$ 趋近于 $+\\infty$。因此，指数项发散：\n$$\\lim_{x \\to -\\infty} \\exp(-\\theta x) = +\\infty$$\n这意味着权重函数也发散：\n$$\\lim_{x \\to -\\infty} w_{\\theta}(x) = +\\infty$$\n由于函数 $w_{\\theta}(x)$ 是连续的，并且它在区间 $(-\\infty, -a]$ 的一端极限为无穷大，因此它在该区间上是无界的。这证明了对于 $\\theta \\in (-1,0)$ 的任何选择，指数族倾斜提议都会导致针对该指定稀有事件的重要性采样估计量具有无穷大的方差。\n\n**第二部分：变换映射提议 $q_{T}(x)$**\n\n首先，我们推导提议密度 $q_T(x) = (T_{\\#}q_0)(x)$。变换映射为 $x = T(u) = -a - u$。基础分布 $q_0$ 的支撑集为 $u \\in [0,\\infty)$，因此 $q_T$ 的支撑集是这个集合在 $T$ 变换下的像，即 $(-\\infty, -a]$。\n为了使用推前公式，我们必须找到逆映射 $u = T^{-1}(x)$ 和该变换的雅可比行列式。\n从 $x = -a - u$，我们得到逆映射：\n$$u = -a - x$$\n导数为 $\\frac{du}{dx} = -1$。雅可比行列式的绝对值是 $\\left|\\frac{du}{dx}\\right| = |-1| = 1$。\n使用推前公式，对于 $x \\in (-\\infty, -a]$：\n$$q_{T}(x) = q_{0}(T^{-1}(x))\\left|\\frac{du}{dx}\\right| = q_{0}(-a-x) \\cdot 1$$\n代入 $q_0(u) = \\lambda \\exp(-\\lambda u)$ 的密度表达式：\n$$q_{T}(x) = \\lambda \\exp(-\\lambda(-a-x)) = \\lambda \\exp(\\lambda a + \\lambda x)$$\n这是 $x \\le -a$ 时的提议密度。对于 $x  -a$，$q_T(x) = 0$。\n\n接下来，我们推导在 $q_T$ 的支撑集 $(-\\infty, -a]$ 上的重要性采样权重 $w_T(x) = \\frac{p(x)}{q_T(x)}$。在这个区间上，$x$ 是负数，因此目标密度 $p(x)$ 中的绝对值 $|x|$ 等于 $-x$。\n$$p(x) = \\frac{1}{2}\\exp(-(-x)) = \\frac{1}{2}\\exp(x) \\quad \\text{for } x \\le -a$$\n现在我们可以构建权重函数：\n$$w_T(x) = \\frac{p(x)}{q_T(x)} = \\frac{\\frac{1}{2}\\exp(x)}{\\lambda \\exp(\\lambda a + \\lambda x)} = \\frac{1}{2\\lambda} \\exp(x - (\\lambda a + \\lambda x)) = \\frac{1}{2\\lambda} \\exp(-\\lambda a + (1-\\lambda)x)$$\n\n最后，我们确定 $w_T(x)$ 在事件域 $x \\in (-\\infty, -a]$ 上的上确界。$w_T(x)$ 的行为取决于指数中 $x$ 的系数 $(1-\\lambda)$ 的符号。\n- **情况 1： $\\lambda  1$。** 在这种情况下，$1-\\lambda  0$。函数 $w_T(x)$ 与 $\\exp((1-\\lambda)x)$ 成正比。当 $x \\to -\\infty$ 时，参数 $(1-\\lambda)x \\to +\\infty$。因此，$\\lim_{x \\to -\\infty} w_T(x) = +\\infty$。权重是无界的，上确界为无穷大。这样的提议分布对于方差缩减是无用的。\n- **情况 2： $\\lambda \\le 1$。** 在这种情况下，$1-\\lambda \\ge 0$。函数 $\\exp((1-\\lambda)x)$ 是 $x$ 的一个非减函数。因此，它在区间 $(-\\infty, -a]$ 上的上确界必定出现在右边界，即 $x = -a$。\n\n问题要求给出上确界的表达式。一个重要性采样提议只有在得到的权重有界时才被认为是有效的，这确保了重要性采样估计量具有有限方差。这就要求上确界是有限的，从而将我们的关注点限制在 $\\lambda \\le 1$ 的情况。因此，我们计算 $\\lambda$ 在此范围内的上确界。\n对于任何 $\\lambda \\in (0,1]$，上确界在 $x=-a$ 处取得：\n$$\\sup_{x \\le -a} w_{T}(x) = w_{T}(-a) = \\frac{1}{2\\lambda} \\exp(-\\lambda a + (1-\\lambda)(-a))$$\n$$= \\frac{1}{2\\lambda} \\exp(-\\lambda a - a + \\lambda a)$$\n$$= \\frac{1}{2\\lambda} \\exp(-a)$$\n这个表达式给出了在这个变换映射族中任何有效提议（以 $\\lambda \\in (0,1]$ 为特征）的重要性权重的有限上确界。注意，当 $\\lambda$ 最大化时，即 $\\lambda=1$ 时，此上确界最小化，此时得到最优的常数权重 $w_T(x) = \\frac{1}{2}\\exp(-a)$。\n问题要求用 $a$ 和 $\\lambda$ 表示上确界。提供上确界为有限情况下的结果，是按要求提供一个有意义的闭式表达式的唯一方法。", "answer": "$$\\boxed{\\frac{\\exp(-a)}{2\\lambda}}$$", "id": "3312692"}]}