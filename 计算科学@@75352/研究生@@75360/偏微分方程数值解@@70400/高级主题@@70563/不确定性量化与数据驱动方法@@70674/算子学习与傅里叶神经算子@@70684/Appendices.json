{"hands_on_practices": [{"introduction": "在为偏微分方程（PDEs）学习算子时，我们通常会遇到两种不同来源的误差：模型本身的近似误差（泛化误差）和用于生成训练数据或评估模型的数值求解器的误差（离散化误差）。本练习 [@problem_id:3426971] 提供了一种动手实践的方法，通过网格加密实验来区分这两种误差。掌握这项技能对于验证任何科学机器学习模型的有效性至关重要。", "problem": "考虑单位区间上具有齐次狄利克雷边界条件的一维泊松方程的边值问题。设希尔伯特空间 $U = L^{2}(0,1)$ 和 $V = H_{0}^{1}(0,1)$。按以下规则定义线性算子 $T : U \\to V$：对于任意源项 $f \\in U$，函数 $u = T(f)$ 是该边值问题的唯一弱解\n$$\n- u''(x) = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0.\n$$\n假设 $f$ 可展开为傅里叶正弦级数 $f(x) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)$，且该级数在 $L^2(0,1)$ 中收敛；类似地，$u$ 可展开为正弦级数 $u(x) = \\sum_{n=1}^{\\infty} b_n \\sin(n \\pi x)$。\n\n一个受傅里叶神经算子（FNO）启发的算子学习代理 $\\hat{T}$，其定义为将输出的傅里叶正弦表示截断至最低的 $k$ 个模态。更准确地说，$\\hat{T}$ 的作用是仅保留 $u$ 的前 $k$ 个正弦模态，其系数在 $n \\le k$ 时与 $u$ 的系数相同，在 $n > k$ 时为零。这可以理解为 $U$ 上的一个算子，它将 $f$ 映射到由截断正弦级数给出的 $\\hat{u} = \\hat{T}(f)$。\n\n算子范数下的泛化误差定义为\n$$\nE_{\\mathrm{gen}} = \\| T - \\hat{T} \\|_{\\mathcal{L}(U,V)} = \\sup_{f \\in U, \\, \\| f \\|_{U} = 1} \\| T(f) - \\hat{T}(f) \\|_{V}.\n$$\n在实践中，人们使用一个有代表性的输入族，相对于输出的 $L^2(0,1)$ 范数来估计 $E_{\\mathrm{gen}}$。\n\n另外，当在网格上用离散数值求解器逼近连续算子 $T$ 时，会产生离散化误差。考虑一个具有 $N$ 个节点、网格间距 $h = 1/(N-1)$ 的均匀网格，以及在内部点处对 $-u''(x)$ 采用标准的二阶中心有限差分格式。令 $T_{N}$ 表示将网格函数 $f$（通过在网格点上采样 $f$ 得到）映射到网格函数 $u_{N}$（通过求解带有 $u(0)=u(1)=0$ 的有限差分线性系统得到）的离散算子。对于给定的网格尺寸 $N$，离散化误差定义为\n$$\nE_{\\mathrm{disc}}(N) = \\sup_{f \\in \\mathcal{F}} \\| T(f) - T_{N}(f) \\|_{L^{2}(0,1)},\n$$\n其中范数通过网格上的数值求积进行评估，$\\mathcal{F}$ 是 $U$ 中一个指定的测试族。\n\n您的任务是：\n- 从第一性原理出发，推导 $T$ 如何作用于 $f$ 的傅里叶正弦系数 $a_n$，并解释相对于 $L^2(0,1)$ 的算子范数 $E_{\\mathrm{gen}}$ 的定义。\n- 在概念上和数量上区分 $E_{\\mathrm{gen}}$ 和 $E_{\\mathrm{disc}}(N)$。\n- 提出并实现一个网格细化实验，通过比较粗网格和细网格上的测量值，来分离 $E_{\\mathrm{gen}}$ 和 $E_{\\mathrm{disc}}(N)$ 的贡献。\n\n实验设置：\n- 使用由具有齐次狄利克雷条件的一维泊松方程确定的精确连续算子 $T$。\n- 定义代理算子 $\\hat{T}$，它截断截止频率 $k$ 之外的输出正弦模态。\n- 通过在所选网格上使用复合梯形法则来评估 $\\| \\cdot \\|_{L^2(0,1)}$。\n- 为 $T_N$ 构建一个有限差分求解器，该求解器使用标准的用于二阶导数逼近的三对角矩阵，并满足边界条件 $u(0)=u(1)=0$。\n\n测试套件：\n对于每组参数，定义测试族 $\\mathcal{F}$ 由三个输入组成，每个输入都是一个归一化的正弦模态 $f(x) = \\sqrt{2} \\sin(n \\pi x)$，其 $L^2(0,1)$ 范数等于 $1$。对于每组参数，测量以下四个量：\n- $E_{\\mathrm{gen}}(N_{\\mathrm{low}})$：在具有 $N_{\\mathrm{low}}$ 个节点的粗网格上计算的 $\\| T(f) - \\hat{T}(f) \\|_{L^2(0,1)}$ 在 $\\mathcal{F}$ 上的最大值。\n- $E_{\\mathrm{gen}}(N_{\\mathrm{high}})$：在具有 $N_{\\mathrm{high}}$ 个节点的细网格上计算的相同最大值。\n- $E_{\\mathrm{disc}}(N_{\\mathrm{low}})$：在粗网格上计算的 $\\| T(f) - T_{N_{\\mathrm{low}}}(f) \\|_{L^2(0,1)}$ 在 $\\mathcal{F}$ 上的最大值。\n- $E_{\\mathrm{disc}}(N_{\\mathrm{high}})$：在细网格上的相同最大值。\n\n然后，对于每组参数，通过检查以下两个条件来判断网格细化是否分离了这两个误差源：\n- $|E_{\\mathrm{gen}}(N_{\\mathrm{low}}) - E_{\\mathrm{gen}}(N_{\\mathrm{high}})| \\le \\tau_{\\mathrm{gen}}$，其中 $\\tau_{\\mathrm{gen}}$ 是一个小的容差。\n- $E_{\\mathrm{disc}}(N_{\\mathrm{low}}) > \\gamma \\, E_{\\mathrm{disc}}(N_{\\mathrm{high}})$，其中 $\\gamma > 1$ 表示离散化误差随网格细化有显著减小。\n\n使用以下三组参数作为测试套件，每组以元组 $(M, k, N_{\\mathrm{low}}, N_{\\mathrm{high}}, \\text{frequencies})$ 的形式提供：\n- $\\left(64, 5, 33, 257, [6, 64, 2]\\right)$\n- $\\left(64, 64, 33, 257, [10, 20, 40]\\right)$\n- $\\left(64, 10, 17, 33, [11, 64, 5]\\right)$\n这里，$M$ 是用于评估 $T$ 的连续级数的最大正弦模态数，$k$ 是代理算子 $\\hat{T}$ 的截断截止频率，$N_{\\mathrm{low}}$ 和 $N_{\\mathrm{high}}$ 是粗细网格尺寸（节点数），列表 \"frequencies\" 指定了 $\\mathcal{F}$ 中的三个单模态输入。\n\n最终输出规范：\n您的程序应生成单行输出，其中包含一个以方括号括起来的逗号分隔列表形式的结果。每个元素都应是对应于一组参数的五个值的列表，顺序为\n$$\n\\left[ E_{\\mathrm{gen}}(N_{\\mathrm{low}}), \\, E_{\\mathrm{gen}}(N_{\\mathrm{high}}), \\, E_{\\mathrm{disc}}(N_{\\mathrm{low}}), \\, E_{\\mathrm{disc}}(N_{\\mathrm{high}}), \\, \\text{separation\\_flag} \\right],\n$$\n其中前四个是浮点数，最后一个是布尔值，表示两个分离条件是否都成立。程序不得读取任何输入，并且必须完全按照指定使用所提供的测试套件。此任务中没有物理单位，如果出现任何角度，则必须视为以弧度为单位。容差应固定为 $\\tau_{\\mathrm{gen}} = 10^{-3}$，离散化改进因子应为 $\\gamma = 1.1$。", "solution": "该问题被评估为有效，因为它在数值分析和算子理论领域有科学依据，问题设定良好，客观，并包含得出唯一解所需的所有信息。\n\n在此，提供一个完整的、有理有据的解答。在本文中，每个数学实体都按要求以 LaTeX 格式呈现。\n\n### 1. 连续算子 $T$ 和代理算子 $\\hat{T}$\n\n该问题考虑具有齐次狄利克雷边界条件的一维泊松方程：\n$$\n-u''(x) = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0\n$$\n线性算子 $T$ 将一个源项 $f \\in L^2(0,1)$ 映射到唯一的弱解 $u \\in H_0^1(0,1)$。为了理解 $T$ 在傅里叶域中的作用，我们将 $f(x)$ 和 $u(x)$ 都表示为其傅里叶正弦级数，这些级数构成了 $(0,1)$ 上满足边界条件的函数的一个完备正交基：\n$$\nf(x) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)\n$$\n$$\nu(x) = \\sum_{n=1}^{\\infty} b_n \\sin(n \\pi x)\n$$\n假设具有足够的正则性可以逐项微分，则 $u(x)$ 的二阶导数为：\n$$\nu''(x) = \\sum_{n=1}^{\\infty} b_n \\frac{d^2}{dx^2} \\sin(n \\pi x) = \\sum_{n=1}^{\\infty} b_n (-(n \\pi)^2) \\sin(n \\pi x)\n$$\n将这些级数代入泊松方程，得到：\n$$\n- \\left( \\sum_{n=1}^{\\infty} -b_n (n \\pi)^2 \\sin(n \\pi x) \\right) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)\n$$\n$$\n\\sum_{n=1}^{\\infty} b_n (n \\pi)^2 \\sin(n \\pi x) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)\n$$\n根据傅里叶级数系数的唯一性，我们可以对每个模态 $n$ 的系数进行等价：\n$$\nb_n (n \\pi)^2 = a_n \\implies b_n = \\frac{a_n}{(n \\pi)^2}\n$$\n这个基本关系表明，算子 $T$ 在傅里叶基中充当一个对角算子。它通过将输入 $f$ 的第 $n$ 个傅里叶系数 $a_n$ 乘以一个因子 $1/(n \\pi)^2$，将其转换为输出 $u$ 的第 $n$ 个系数 $b_n$。这种缩放会迅速衰减高频分量。\n\n代理算子 $\\hat{T}$ 受到傅里叶神经算子（FNO）的启发，其定义为在截止模态 $k$ 处截断输出的傅里叶级数。对于一个解 $u = T(f)$，其系数为 $b_n$，代理算子的解 $\\hat{u} = \\hat{T}(f)$ 为：\n$$\n\\hat{u}(x) = \\sum_{n=1}^{k} b_n \\sin(n \\pi x)\n$$\n$\\hat{u}$ 的系数对于模态 $n \\le k$ 与 $u$ 的系数相同，对于 $n > k$ 则为零。\n\n### 2. 泛化误差与离散化误差\n\n该问题要求在概念和数量上对泛化误差 $E_{\\mathrm{gen}}$ 和离散化误差 $E_{\\mathrm{disc}}(N)$ 进行区分。\n\n**泛化误差（$E_{\\mathrm{gen}}$）：** 这是一种**建模误差**，内在于代理模型 $\\hat{T}$。它量化了简化模型 $\\hat{T}$ 对真实连续算子 $T$ 的逼近程度。该误差是真实解 $u$ 和代理算子解 $\\hat{u}$ 之间的差：\n$$\nT(f) - \\hat{T}(f) = u(x) - \\hat{u}(x) = \\sum_{n=k+1}^{\\infty} b_n \\sin(n \\pi x) = \\sum_{n=k+1}^{\\infty} \\frac{a_n}{(n \\pi)^2} \\sin(n \\pi x)\n$$\n此误差源于丢弃所有频率指数 $n > k$ 的解模态所造成的信息损失。至关重要的是，$E_{\\mathrm{gen}}$ 是连续算子 $T$ 和 $\\hat{T}$ 的一个属性，不依赖于任何数值离散化或网格尺寸 $N$。对于一个固定的测试族 $\\mathcal{F}$，其值是恒定的。在网格上对此误差进行数值计算是一种近似，但随着网格的细化，这种近似应该收敛到真实的恒定值。\n\n**离散化误差（$E_{\\mathrm{disc}}(N)$）：** 这是一种**数值逼近误差**，内在于离散求解器 $T_N$。它量化了在具有 $N$ 个节点的网格上的数值解 $u_N$ 对真实连续解 $u = T(f)$ 的逼近程度。此误差源于用有限差分逼近替换连续微分算子 $-d^2/dx^2$。对于指定的二阶中心差分格式，局部截断误差的阶数为 $O(h^2)$，其中 $h=1/(N-1)$ 是网格间距。因此，解的全局误差 $\\|T(f) - T_N(f)\\|_{L^2(0,1)}$ 也预期会随着 $N$ 的增加而减小，其收敛阶数通常与格式的精度有关。我们期望当 $N \\to \\infty$（或 $h \\to 0$）时，$E_{\\mathrm{disc}}(N) \\to 0$。\n\n总而言之，$E_{\\mathrm{gen}}$ 衡量的是**模型**的缺陷，而 $E_{\\mathrm{disc}}(N)$ 衡量的是**数值方法**的缺陷。\n\n### 3. 网格细化实验\n\n所提出的实验旨在通过经验方法分离这两种不同的误差来源。它依赖于它们对网格尺寸 $N$ 的不同依赖性。\n\n1.  **测量 $E_{\\mathrm{gen}}$：** 泛化误差 $\\|T(f) - \\hat{T}(f)\\|_{L^2(0,1)}$ 是算子的一个内在属性，与网格无关。当我们在粗网格（$N_{\\mathrm{low}}$）和细网格（$N_{\\mathrm{high}}$）上进行数值计算时，我们引入了由于梯形法则逼近积分而产生的测量误差。然而，如果两个网格都足够精细以解析所涉及的函数，数值结果应该非常接近，并且接近真实的解析值。条件 $|E_{\\mathrm{gen}}(N_{\\mathrm{low}}) - E_{\\mathrm{gen}}(N_{\\mathrm{high}})| \\le \\tau_{\\mathrm{gen}}$ 检查 $E_{\\mathrm{gen}}$ 的测量是否已经稳定，表明测量的离散化方面与 $E_{\\mathrm{gen}}$ 本身的大小相比可以忽略不计。\n\n2.  **测量 $E_{\\mathrm{disc}}(N)$：** 根据定义，离散化误差 $\\|T(f) - T_N(f)\\|_{L^2(0,1)}$ 依赖于网格尺寸 $N$。随着网格从 $N_{\\mathrm{low}}$ 细化到 $N_{\\mathrm{high}}$，二阶有限差分格式的误差应该会减小。误差比值预期约为 $(h_{\\mathrm{low}}/h_{\\mathrm{high}})^2 = ((N_{\\mathrm{high}}-1)/(N_{\\mathrm{low}}-1))^2$。对于一个因子 $\\gamma > 1$，条件 $E_{\\mathrm{disc}}(N_{\\mathrm{low}}) > \\gamma \\, E_{\\mathrm{disc}}(N_{\\mathrm{high}})$ 证实了在网格细化时误差的预期减少。\n\n通过观察到一个误差度量几乎保持不变，而另一个随着网格细化系统性地减小，该实验有效地辨别并分离了建模误差和数值求解器误差。\n\n值得注意的是，参数 $M$ 通过在 $M$ 个模态处截断其级数表示来定义我们“基准真相”算子 $T$ 的保真度。对于特定的测试输入 $f(x) = \\sqrt{2} \\sin(n \\pi x)$，精确解 $u(x)$ 也是一个单一的正弦模态。由于所有测试频率 $n$ 都小于或等于给定的 $M$ 值，这种截断没有影响，可以直接使用解析解。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve():\n    \"\"\"\n    Main function to run the mesh refinement experiment for the given test suite.\n    \"\"\"\n    test_cases = [\n        # (M, k, N_low, N_high, frequencies)\n        (64, 5, 33, 257, [6, 64, 2]),\n        (64, 64, 33, 257, [10, 20, 40]),\n        (64, 10, 17, 33, [11, 64, 5]),\n    ]\n    tau_gen = 1e-3\n    gamma = 1.1\n\n    final_results = []\n\n    for M, k, N_low, N_high, freqs in test_cases:\n        \n        errors_gen_low, errors_disc_low = [], []\n        errors_gen_high, errors_disc_high = [], []\n\n        for n in freqs:\n            # --- Coarse Mesh Calculations ---\n            egen_low, edisc_low = calculate_errors(n, k, M, N_low)\n            errors_gen_low.append(egen_low)\n            errors_disc_low.append(edisc_low)\n            \n            # --- Fine Mesh Calculations ---\n            egen_high, edisc_high = calculate_errors(n, k, M, N_high)\n            errors_gen_high.append(egen_high)\n            errors_disc_high.append(edisc_high)\n\n        # Find the maximum error over the family of test functions\n        E_gen_low = np.max(errors_gen_low)\n        E_gen_high = np.max(errors_gen_high)\n        E_disc_low = np.max(errors_disc_low)\n        E_disc_high = np.max(errors_disc_high)\n\n        # Check separation conditions\n        cond1 = np.abs(E_gen_low - E_gen_high) = tau_gen\n        cond2 = E_disc_low > gamma * E_disc_high if E_disc_high > 0 else E_disc_low > 0\n        \n        separation_flag = cond1 and cond2\n\n        final_results.append(\n            f\"[{E_gen_low:.6f},{E_gen_high:.6f},{E_disc_low:.6f},{E_disc_high:.6f},{separation_flag}]\"\n        )\n    \n    print(f\"[{','.join(final_results)}]\")\n\ndef calculate_errors(n, k, M, N):\n    \"\"\"\n    Calculates generalization and discretization errors for a given frequency n,\n    surrogate cutoff k, and grid size N.\n    \n    Args:\n        n (int): The frequency mode of the input function.\n        k (int): The cutoff mode for the surrogate operator.\n        M (int): The cutoff for the 'true' continuous operator.\n        N (int): The number of nodes in the grid.\n\n    Returns:\n        tuple: A tuple containing (E_gen, E_disc).\n    \"\"\"\n    # 1. Define grid and analytical solutions\n    x_grid = np.linspace(0.0, 1.0, N)\n    h = 1.0 / (N - 1)\n\n    # Input function f(x) = sqrt(2) * sin(n*pi*x)\n    f_input = lambda x: np.sqrt(2.0) * np.sin(n * np.pi * x)\n\n    # True solution u(x) = T(f)\n    # The 'true' operator T is approximated by a series up to M modes.\n    # For an input mode n, if n > M, the output is 0.\n    if n = M:\n        u_true_func = lambda x: np.sqrt(2.0) / (n * np.pi)**2 * np.sin(n * np.pi * x)\n    else:\n        u_true_func = lambda x: np.zeros_like(x)\n\n    # Surrogate solution u_hat(x) = hat{T}(f)\n    # This is the true solution truncated at mode k.\n    if n = k:\n        u_surr_func = u_true_func\n    else:\n        u_surr_func = lambda x: np.zeros_like(x)\n    \n    # Evaluate analytical solutions on the grid\n    u_true_grid = u_true_func(x_grid)\n    u_surr_grid = u_surr_func(x_grid)\n\n    # 2. Calculate Generalization Error (E_gen)\n    # E_gen = || T(f) - hat{T}(f) ||_L2 = || u_true - u_surr ||_L2\n    # Norm is computed using composite trapezoidal rule.\n    err_vec_gen = u_true_grid - u_surr_grid\n    norm_sq_gen = np.trapz(err_vec_gen**2, x_grid)\n    E_gen = np.sqrt(norm_sq_gen)\n\n    # 3. Calculate Discretization Error (E_disc)\n    # First, find the numerical solution u_N = T_N(f)\n    \n    # Set up the finite difference system Au = f_interior\n    num_interior_points = N - 2\n    if num_interior_points > 0:\n        # Forcing function on interior grid points\n        f_interior = f_input(x_grid[1:-1])\n\n        # Tridiagonal matrix A for -u'' is (1/h^2) * diag(-1, 2, -1)\n        # For scipy.linalg.solve_banded, we represent A in banded format.\n        # It has 1 lower and 1 upper diagonal.\n        ab = np.zeros((3, num_interior_points))\n        ab[0, 1:] = -1.0  # Upper diagonal\n        ab[1, :] = 2.0   # Main diagonal\n        ab[2, :-1] = -1.0 # Lower diagonal\n        \n        # Solve the linear system A * u_interior = h^2 * f_interior\n        u_interior = solve_banded((1, 1), ab, h**2 * f_interior)\n        \n        # Add boundary conditions u(0)=0, u(1)=0\n        u_N_grid = np.pad(u_interior, 1, 'constant')\n    else: # Handles N=1 or N=2 cases\n        u_N_grid = np.zeros(N)\n\n    # E_disc = || T(f) - T_N(f) ||_L2 = || u_true - u_N ||_L2\n    err_vec_disc = u_true_grid - u_N_grid\n    norm_sq_disc = np.trapz(err_vec_disc**2, x_grid)\n    E_disc = np.sqrt(norm_sq_disc)\n\n    return E_gen, E_disc\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3426971"}, {"introduction": "傅里叶神经算子（FNO）的核心思想是在频域进行截断，这自然会引入近似误差。一个自然而深刻的问题是：这种近似在最坏情况下表现如何？本练习 [@problem_id:3426953] 将指导你构建“对抗性”输入，这些输入会最大程度地暴露 FNO 的截断缺陷，从而将算子范数这一抽象理论概念与模型最坏情况性能的量化评估联系起来。", "problem": "考虑在区间 $[0,2\\pi]$ 上的周期函数，这些函数由 $N$ 个等距网格点 $x_n = \\frac{2\\pi n}{N}$（其中 $n \\in \\{0,1,\\dots,N-1\\}$）进行离散化。设序列的离散傅里叶变换 (DFT) 由标准快速傅里叶变换的惯例定义：正变换 $\\mathcal{F}$ 未经缩放，而逆变换 $\\mathcal{F}^{-1}$ 包含一个因子 $1/N$。用整数数组 $k \\in \\{-\\lfloor N/2 \\rfloor, \\dots, -1, 0, 1, \\dots, \\lfloor (N-1)/2 \\rfloor\\}$ 按规范 DFT 排序表示离散波数。\n\n设一个线性的、平移不变的算子 $\\mathcal{T}$ 通过一个实值谱乘子 $m(k)$ 在傅里叶空间中对角作用，因此对于任何输入函数 $f$，输出的傅里叶系数满足 $\\widehat{(\\mathcal{T} f)}(k) = m(k)\\,\\widehat{f}(k)$。考虑傅里叶神经算子 (Fourier Neural Operator, FNO) 中使用的近似，这里定义为对截止波数 $K \\in \\mathbb{N}$ 的谱截断，该截断会丢弃所有 $|k|  K$ 的频率。截断算子 $\\mathcal{T}_K$ 的作用方式为：当 $|k| \\le K$ 时，$\\widehat{(\\mathcal{T}_K f)}(k) = m(k)\\,\\widehat{f}(k)$；当 $|k|  K$ 时，$\\widehat{(\\mathcal{T}_K f)}(k) = 0$。定义误差算子 $\\mathcal{E} := \\mathcal{T} - \\mathcal{T}_K$。\n\n我们研究利用截断 $K$ 来最大化输出误差 $\\|\\mathcal{E} f\\|_2$ 的对抗性输入，其约束条件为 $\\|f\\|_2 = 1$，其中 $\\|\\cdot\\|_2$ 是物理空间中的离散 $\\ell^2$ 范数。使用基本定义和经过充分检验的事实（DFT、Parseval 恒等式、线性映射的算子范数以及傅里叶空间中对角算子的基本性质），推导并实现一个算法来构造此类最坏情况输入，并刻画输入函数空间中的最坏情况方向。您的推导必须从第一性原理（上述定义）出发，并且不能使用任何快捷公式。\n\n您必须设计并实现一个程序，对于每个给定的测试用例，在指定的 $N$、$K$ 和谱乘子 $m(k)$ 选择下执行以下操作：\n- 以离散 $\\ell^2$ 意义计算 $\\mathcal{E}$ 的算子范数。\n- 构造一个满足 $\\|f\\|_2 = 1$ 且能最大化 $\\|\\mathcal{E} f\\|_2$ 的对抗性输入 $f$，并确定傅里叶空间中对应的波数 $k^\\star$（最坏情况方向）。\n- 计算所构造的对抗性输入所达到的误差范数 $\\|\\mathcal{E} f\\|_2$。\n- 计算比率 $\\frac{\\|\\mathcal{E} f\\|_2}{\\|\\mathcal{E}\\|_{\\text{op}}}$ 以及一个布尔值，指示该比率是否在数值公差 $10^{-12}$ 内等于 $1$。\n\n使用以下两类谱乘子：\n- 平滑（高斯卷积）：$m(k) = \\exp\\big(-\\sigma^2\\,k^2\\big)$，参数 $\\sigma  0$。\n- $q$ 阶导数：$m(k) = |k|^q$，整数 $q \\ge 1$。\n\n为以下测试套件（四个案例）实现您的算法，确保科学真实性并覆盖一般和边缘场景：\n- 案例 1：$N = 128$，$K = 10$，$m(k) = \\exp\\big(-\\sigma^2\\,k^2\\big)$，其中 $\\sigma = 0.5$。\n- 案例 2：$N = 128$，$K = 20$，$m(k) = |k|^2$，其中 $q = 2$。\n- 案例 3：$N = 64$，$K = 0$，$m(k) = |k|^3$，其中 $q = 3$。\n- 案例 4：$N = 256$，$K = 60$，$m(k) = \\exp\\big(-\\sigma^2\\,k^2\\big)$，其中 $\\sigma = 0.2$。\n\n您的程序必须生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身是一个形式为 $[k^\\star,\\|\\mathcal{E} f\\|_2,\\|\\mathcal{E}\\|_{\\text{op}},\\text{ratio},\\text{is\\_equal}]$ 的逗号分隔列表。条目必须按上述测试套件的顺序排列。例如，最终输出格式必须与 $[[\\dots],[\\dots],[\\dots],[\\dots]]$ 完全一样，不含空格。", "solution": "该问题要求刻画谱截断线性算子的最坏情况误差，这是分析傅里叶神经算子的一个核心概念。目标是找到一个具有单位 $\\ell^2$ 范数 $\\|f\\|_2 = 1$ 的输入函数 $f$，使得误差的 $\\ell^2$ 范数 $\\|\\mathcal{E} f\\|_2$ 最大化，其中 $\\mathcal{E} = \\mathcal{T} - \\mathcal{T}_K$。在对 $f$ 的约束下，待最大化的量 $\\|\\mathcal{E} f\\|_2$ 定义了 $\\mathcal{E}$ 的算子范数，记为 $\\|\\mathcal{E}\\|_{\\text{op}}$。\n\n推导从第一性原理出发，始于物理空间和傅里叶空间中操作之间的关系。\n\n设 $f$ 是一个在 $N$ 个网格点上离散化的函数，由向量 $(f_0, f_1, \\dots, f_{N-1})$ 表示。其离散 $\\ell^2$ 范数为 $\\|f\\|_2 = (\\sum_{n=0}^{N-1} |f_n|^2)^{1/2}$。设 $\\hat{f} = \\mathcal{F}(f)$ 是其离散傅里叶变换 (DFT)，系数为 $(\\hat{f}_0, \\hat{f}_1, \\dots, \\hat{f}_{N-1})$。问题指定了一种 DFT 惯例，其中逆变换 $\\mathcal{F}^{-1}$ 包含一个归一化因子 $1/N$。对于此惯例，Parseval 定理提供了物理空间中的范数与傅里叶系数范数之间的关键联系：\n$$ \\|f\\|_2^2 = \\sum_{n=0}^{N-1} |f_n|^2 = \\frac{1}{N} \\sum_{k=0}^{N-1} |\\hat{f}_k|^2 = \\frac{1}{N} \\|\\hat{f}\\|_2^2 $$\n对 $k$ 的求和是在标准 DFT 索引 $\\{0, 1, \\dots, N-1\\}$ 上进行的，这些索引对应于问题描述中提到的整数波数。我们将使用标准数值库提供的规范 DFT 排序下的这些整数波数 $k$。\n\n误差算子 $\\mathcal{E} = \\mathcal{T} - \\mathcal{T}_K$ 是线性的。其在傅里叶域中的作用可以通过检查它对傅里叶系数 $\\hat{f}(k)$ 的影响来找到。对于任意函数 $f$，令 $g = \\mathcal{E} f$。其傅里叶系数 $\\hat{g}(k)$ 为：\n$$ \\hat{g}(k) = \\widehat{(\\mathcal{E} f)}(k) = \\widehat{(\\mathcal{T}f)}(k) - \\widehat{(\\mathcal{T}_K f)}(k) $$\n根据 $\\mathcal{T}$ 和 $\\mathcal{T}_K$ 的定义：\n- 对于波数 $|k| \\le K$，截断保留了 $\\mathcal{T}$ 的作用。因此，$\\widehat{(\\mathcal{T}_K f)}(k) = m(k)\\hat{f}(k)$，所以 $\\hat{g}(k) = m(k)\\hat{f}(k) - m(k)\\hat{f}(k) = 0$。\n- 对于波数 $|k|  K$，截断会丢弃这些模式。因此，$\\widehat{(\\mathcal{T}_K f)}(k) = 0$，所以 $\\hat{g}(k) = m(k)\\hat{f}(k) - 0 = m(k)\\hat{f}(k)$。\n\n这表明 $\\mathcal{E}$ 本身在傅里叶基中是一个对角算子。其谱乘子，我们称之为 $\\lambda_{\\mathcal{E}}(k)$，由下式给出：\n$$\n\\lambda_{\\mathcal{E}}(k) =\n\\begin{cases}\n0  \\text{if } |k| \\le K \\\\\nm(k)  \\text{if } |k|  K\n\\end{cases}\n$$\n现在，我们可以利用 Parseval 定理在傅里叶域中表示误差的范数 $\\|\\mathcal{E} f\\|_2$：\n$$ \\|\\mathcal{E} f\\|_2^2 = \\frac{1}{N} \\|\\widehat{\\mathcal{E} f}\\|_2^2 = \\frac{1}{N} \\sum_k |\\lambda_{\\mathcal{E}}(k) \\hat{f}(k)|^2 = \\frac{1}{N} \\sum_{|k|K} |m(k)|^2 |\\hat{f}(k)|^2 $$\n优化问题是在约束条件 $\\|f\\|_2 = 1$ 下最大化此量。该约束也可以写在傅里叶域中：\n$$ \\|f\\|_2^2 = 1 \\implies \\frac{1}{N} \\sum_k |\\hat{f}(k)|^2 = 1 \\implies \\sum_k |\\hat{f}(k)|^2 = N $$\n因此，该问题可以正式表述为：\n$$ \\text{最大化} \\quad \\frac{1}{N} \\sum_{|k|K} |m(k)|^2 |\\hat{f}(k)|^2 \\quad \\text{约束条件为} \\quad \\sum_k |\\hat{f}(k)|^2 = N $$\n令 $c_k = |\\hat{f}(k)|^2 \\ge 0$。我们希望在 $\\sum_k c_k = N$ 的约束下最大化 $\\frac{1}{N} \\sum_{|k|K} |m(k)|^2 c_k$。\n为了在固定总预算 $\\sum c_k = N$ 下最大化这个加权和，我们必须将全部预算分配给权重最大的项。对于 $|k|K$ 的项，权重为 $\\frac{1}{N}|m(k)|^2$，否则为 $0$。\n令 $k^\\star$ 为集合 $\\{k \\in \\mathbb{Z} : |k|  K\\}$ 中使 $|m(k)|$ 最大的波数。由于问题陈述 $m(k)$ 是实数，这等价于 $m(k)^2$ 最大的地方。\n$$ |m(k^\\star)| = \\max_{|k|K} |m(k)| $$\n最优策略是将输入函数 $f$ 的所有谱能量集中在这个单一的最坏情况波数 $k^\\star$ 上。相应的傅里叶系数为：\n$$\n\\hat{f}(k) =\n\\begin{cases}\n\\sqrt{N}  \\text{if } k=k^\\star \\\\\n0  \\text{if } k \\ne k^\\star\n\\end{cases}\n$$\n（$\\hat{f}(k^\\star)$ 的相位是任意的；为简单起见，我们选择它为零。）$\\hat{f}$ 的这种选择满足约束条件：$\\sum_k |\\hat{f}(k)|^2 = |\\sqrt{N}|^2 = N$。\n\n对于这个最优输入，我们称之为对抗性输入 $f^\\star$，其误差范数的平方为：\n$$ \\|\\mathcal{E} f^\\star\\|_2^2 = \\frac{1}{N} \\sum_{|k|K} |m(k)|^2 |\\hat{f^\\star}(k)|^2 = \\frac{1}{N} |m(k^\\star)|^2 |\\hat{f^\\star}(k^\\star)|^2 = \\frac{1}{N} |m(k^\\star)|^2 (\\sqrt{N})^2 = |m(k^\\star)|^2 $$\n因此，可实现的最大误差范数为 $\\|\\mathcal{E} f^\\star\\|_2 = |m(k^\\star)|$。\n\n根据定义，$\\mathcal{E}$ 的算子范数是所有单位范数函数 $f$ 的 $\\|\\mathcal{E} f\\|_2$ 的最大值。我们已经找到了这个最大值。\n$$ \\|\\mathcal{E}\\|_{\\text{op}} = \\sup_{\\|f\\|_2=1} \\|\\mathcal{E} f\\|_2 = |m(k^\\star)| = \\max_{|k|K} |m(k)| $$\n这证实了为所构造的对抗性输入达到的误差范数 $\\|\\mathcal{E} f^\\star\\|_2$ 与算子范数 $\\|\\mathcal{E}\\|_{\\text{op}}$ 完全相同。因此它们的比率恰好为 $1$。\n\n为每个测试用例实现的算法如下：\n1. 给定 $N$ 和 $K$，生成与 DFT 对应的离散整数波数 $k$。\n2. 识别波数集合 $S = \\{k : |k|  K\\}$。\n3. 给定谱乘子 $m(k)$，在集合 $S$ 中找到使 $|m(k)|$ 最大化的波数 $k^\\star$。对于给定的乘子，这涉及找到 $S$ 中最小的 $|k|$（对于高斯平滑）或最大的 $|k|$（对于导数）。\n4. 算子范数为 $\\|\\mathcal{E}\\|_{\\text{op}} = |m(k^\\star)|$。\n5. 构造对抗性输入 $f^\\star$。其傅里叶系数 $\\hat{f^\\star}$ 在各处均为零，除了对应于 $k^\\star$ 的索引处，其值为 $\\sqrt{N}$。然后 $f^\\star = \\mathcal{F}^{-1}(\\hat{f^\\star})$。\n6. 计算误差 $g^\\star = \\mathcal{E} f^\\star$。其傅里叶系数为 $\\hat{g^\\star}(k^\\star) = m(k^\\star)\\hat{f^\\star}(k^\\star)$，其他地方为零。物理空间误差为 $g^\\star = \\mathcal{F}^{-1}(\\hat{g^\\star})$。\n7. 数值计算所达到的误差范数 $\\|g^\\star\\|_2$。\n8. 计算比率 $\\frac{\\|g^\\star\\|_2}{\\|\\mathcal{E}\\|_{\\text{op}}}$ 并验证其在一个小的数值公差 $10^{-12}$ 内是否等于 $1$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef analyze_operator_error(N, K, m_func, m_params):\n    \"\"\"\n    Analyzes the worst-case error for a spectrally truncated operator.\n\n    Args:\n        N (int): Number of discretization points.\n        K (int): Truncation cutoff wavenumber.\n        m_func (callable): Function defining the spectral multiplier m(k).\n        m_params (dict): Parameters for the multiplier function.\n\n    Returns:\n        list: A list containing [k_star, achieved_error, op_norm, ratio, is_equal].\n    \"\"\"\n    # 1. Generate discrete integer wavenumbers k in standard FFT order.\n    # np.fft.fftfreq(N) gives frequencies in cycles/sample. Multiply by N to get integer wavenumbers.\n    k_vec = np.fft.fftfreq(N, d=1.0/N)\n    \n    # 2. Identify indices of wavenumbers outside the truncation band.\n    high_freq_indices = np.where(np.abs(k_vec) > K)[0]\n    \n    # Handle the case where no frequencies are truncated.\n    if len(high_freq_indices) == 0:\n        # The error operator is the zero operator.\n        k_star = 0  # No unique k_star, convention is 0.\n        op_norm = 0.0\n        achieved_error = 0.0\n        ratio = 1.0 # 0/0 is undefined, but 1.0 is a reasonable convention here.\n        is_equal = True\n        return [k_star, achieved_error, op_norm, ratio, is_equal]\n\n    k_high_freq = k_vec[high_freq_indices]\n    \n    # 3. Find the wavenumber k_star in the high-frequency set that maximizes |m(k)|.\n    m_vals_high_freq = m_func(k_high_freq, **m_params)\n    abs_m_vals = np.abs(m_vals_high_freq)\n    \n    max_idx_local = np.argmax(abs_m_vals)\n    k_star_idx = high_freq_indices[max_idx_local]\n    k_star = k_vec[k_star_idx]\n    \n    # 4. The operator norm is |m(k_star)|.\n    op_norm = np.abs(m_func(k_star, **m_params))\n    \n    # 5. Construct the adversarial input f_star.\n    # Its Fourier coefficients are zero everywhere except at k_star_idx.\n    f_hat = np.zeros(N, dtype=np.complex128)\n    f_hat[k_star_idx] = np.sqrt(N)\n    \n    # f_star is the inverse FFT of f_hat.\n    # np.fft.ifft implicitly handles the 1/N scaling.\n    f_star = np.fft.ifft(f_hat)\n    \n    # 6. Compute the error g_star = E(f_star).\n    # This is done most easily in Fourier space.\n    g_hat = np.zeros(N, dtype=np.complex128)\n    # The error operator E only acts on modes with |k| > K.\n    # Our adversarial input f_star only has one such mode, at k_star.\n    g_hat[k_star_idx] = m_func(k_star, **m_params) * f_hat[k_star_idx]\n    \n    # Transform back to physical space.\n    g_star = np.fft.ifft(g_hat)\n    \n    # 7. Numerically compute the achieved error norm.\n    achieved_error = np.linalg.norm(g_star)\n    \n    # 8. Compute the ratio and check for equality within tolerance.\n    if op_norm == 0:\n        # This case should only be hit if achieved_error is also 0.\n        ratio = 1.0 if np.isclose(achieved_error, 0.0) else np.inf\n    else:\n        ratio = achieved_error / op_norm\n    \n    tolerance = 1e-12\n    is_equal = np.abs(ratio - 1.0)  tolerance\n    \n    # Convert k_star to an integer for the output format.\n    return [int(np.round(k_star)), achieved_error, op_norm, ratio, is_equal]\n\n# Define the spectral multiplier functions.\ndef m_gaussian(k, sigma):\n    return np.exp(-sigma**2 * k**2)\n\ndef m_derivative(k, q):\n    return np.power(np.abs(k), q)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N': 128, 'K': 10, 'm_func': m_gaussian, 'm_params': {'sigma': 0.5}},\n        {'N': 128, 'K': 20, 'm_func': m_derivative, 'm_params': {'q': 2}},\n        {'N': 64, 'K': 0, 'm_func': m_derivative, 'm_params': {'q': 3}},\n        {'N': 256, 'K': 60, 'm_func': m_gaussian, 'm_params': {'sigma': 0.2}},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = analyze_operator_error(case['N'], case['K'], case['m_func'], case['m_params'])\n        # Format the result list into a string representation for the final output\n        str_result = (f\"[{result[0]},\"\n                      f\"{result[1]:.17g},\"\n                      f\"{result[2]:.17g},\"\n                      f\"{result[3]:.17g},\"\n                      f\"{str(result[4]).lower()}]\")\n        results.append(str_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3426953"}, {"introduction": "对训练分布之外的数据进行预测，即外推（extrapolation），是数据驱动模型面临的一大挑战。本练习 [@problem_id:3427041] 将通过实验揭示一个朴素的 FNO 在面对未见过的输入频率时的外推失败模式。更重要的是，它展示了如何通过引入物理知识（即对算子权重进行正则化）来构建一个能够更稳健地泛化到未知情况的模型。", "problem": "考虑单位区间上的一维周期性泊松问题，其中未知场 $u(x)$ 满足二阶常微分方程 $-u''(x) = f_{\\mu}(x)$，具有周期性边界条件和零均值。在此设定中，参数 $\\mu$ 选择一个强迫模式 $f_{\\mu}(x)$，解算子将输入场 $f_{\\mu}(x)$ 映射到输出场 $u(x)$。目标是研究傅里叶神经算子（FNO）的算子外推能力。FNO被定义为一种在频域中操作的算子，它通过缩放输入场的傅里叶模态，然后变换回空间域来产生输出。\n\n您必须完全在代码中实现以下流程：\n\n1. 在定义域 $[0,1)$ 上构造一个包含 $N$ 个点的周期性网格，其中 $N$ 为有限且适中的数值，使用等距离散化。定义一个由整数值组成的训练参数范围 $[\\mu_{\\min}, \\mu_{\\max}]$ 用于训练。强迫项 $f_{\\mu}(x)$ 必须是与整数频率下的周期性一致的单频实信号。\n\n2. 对于给定的输入 $f_{\\mu}(x)$，仅基于周期性问题的傅里叶级数基本原理，使用数值稳健的谱方法计算基准解 $u(x)$。该谱方法必须在您的代码中明确实现。\n\n3. 设计一个简化的单层傅里叶神经算子（FNO）模型，该模型将输入的每个傅里叶模态 $\\hat{f}(k)$ 乘以一个学习到的复数标量权重 $w(k)$，该权重仅依赖于整数波数的模 $|k|$，然后应用傅里叶逆变换生成输出预测 $\\hat{u}(k) = w(k)\\hat{f}(k)$。限制 FNO 在频域中对角操作（逐模态缩放），不进行跨模态混合。\n\n4. 训练 FNO 的两个变体：\n   - 基线 FNO：仅对训练波数 $k \\in \\{\\mu_{\\min},\\mu_{\\min}+1,\\dots,\\mu_{\\max}\\}$，通过训练集的数据驱动拟合来估计离散权重 $w(k)$。对于训练中未出现的所有其他波数，令 $w(k)$ 为零。\n   - 支持外推的正则化 FNO：通过在训练集上为一个物理驱动的 $w(k)$ 函数族拟合单个标量参数，对学习到的权重施加一个频率相关的衰减结构，然后将此结构化权重推广到所有频率 $k$（包括不在训练范围内的频率）。该结构化形式必须编码权重随 $|k|$ 增大的单调衰减特性，并且其选择应与控制微分算子的阶数一致。正则化必须以可通过代码验证的方式实现，且不依赖任何外部数据或预先计算的常数。\n\n5. 通过对训练范围之外的参数值 $\\mu$ 进行测试，刻画外推失效模式。每次测试至少计算以下定量诊断指标：\n   - 预测场与基准场之间的相对 $\\ell^2$ 误差，计算为预测误差的 $\\ell^2$ 范数与基准解的 $\\ell^2$ 范数之比。\n   - 一个布尔指示符，用于判断误差的谱能量是否主要集中在大于最大训练波数的波数上（例如，超过固定比例的误差能量位于 $|k|\\mu_{\\max}$）。\n\n6. 提供一个紧凑的测试套件，用于检验以下情况：\n   - 一个严格小于 $\\mu_{\\min}$ 的参数 $\\mu$（范围外低频）。\n   - 边界参数 $\\mu=\\mu_{\\min}$ 和 $\\mu=\\mu_{\\max}$（范围内边界）。\n   - 一个严格大于 $\\mu_{\\max}$ 的参数 $\\mu$（范围外高频）。\n\n在您的程序中使用以下固定的数值选择：\n- 网格大小 $N=128$。\n- 训练范围 $[\\mu_{\\min}, \\mu_{\\max}] = [2,6]$，训练参数为整数 $\\mu \\in \\{2,3,4,5,6\\}$。\n- 强迫项定义 $f_{\\mu}(x)$ 必须是 $f_{\\mu}(x) = \\sin(2\\pi \\mu x)$，以确保与单位区间上的周期性兼容。\n- 测试套件参数 $\\mu \\in \\{1,2,6,9\\}$。\n- 将谱失效模式的布尔阈值定义为：由波数 $|k|\\mu_{\\max}$ 承载的误差能量严格大于 $0.6$。\n\n您的程序必须为每个测试参数生成一个包含四个条目的列表：\n- 基线 FNO 的相对 $\\ell^2$ 误差（一个浮点数）。\n- 正则化 FNO 的相对 $\\ell^2$ 误差（一个浮点数）。\n- 一个布尔值，指示正则化误差是否严格低于基线误差。\n- 一个布尔值，指示根据上述定义的阈值，基线预测是否表现出高频误差失效模式。\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。此列表的每个元素本身必须是对应于测试参数 $\\mu \\in \\{1,2,6,9\\}$（按此顺序）的四个值的列表。例如：\"[$[r_{1}^{\\mathrm{base}},r_{1}^{\\mathrm{reg}},b_{1}^{\\mathrm{improve}},b_{1}^{\\mathrm{fail}}],[r_{2}^{\\mathrm{base}},r_{2}^{\\mathrm{reg}},b_{2}^{\\mathrm{improve}},b_{2}^{\\mathrm{fail}}],\\dots$]\"。不涉及任何物理单位；所有量都是无量纲的。若有角度，则根据构造为弧度。最终输出必须仅为指定的基本类型（浮点数和布尔值）。", "solution": "该问题经评估有效。它在科学上是合理的、适定的、客观的，并包含了构建一个唯一的、可验证的解决方案所需的所有信息。我们着手进行求解。\n\n该问题要求研究一个简化的傅里叶神经算子（FNO）在一维周期性泊松问题上的外推能力。核心任务是比较一个仅在特定输入频率范围内训练的基线 FNO 与一个引入了物理驱动结构的正则化 FNO。\n\n**1. 控制方程及其谱解**\n\n该问题由二阶常微分方程定义：\n$$\n-u''(x) = f_{\\mu}(x)\n$$\n在定义域 $x \\in [0, 1)$ 上，具有周期性边界条件 $u(0)=u(1)$ 和 $u'(0)=u'(1)$。施加了零均值的附加约束 $\\int_0^1 u(x) dx = 0$，以确保解的唯一性。强迫项是单频正弦函数 $f_{\\mu}(x) = \\sin(2\\pi \\mu x)$，其中 $\\mu$ 是一个整数。\n\n对于周期性问题，傅里叶级数提供了一个自然的基。一个函数 $g(x)$ 可以表示为复指数的和：\n$$\ng(x) = \\sum_{k=-\\infty}^{\\infty} \\hat{g}(k) e^{2\\pi i k x}\n$$\n其中 $\\hat{g}(k)$ 是傅里叶系数，$k$ 是整数波数。傅里叶变换的一个关键性质是，空间域中的微分在频域中变为乘法。具体来说，二阶导数变换为：\n$$\n\\mathcal{F}\\{g''(x)\\} = (2\\pi i k)^2 \\hat{g}(k) = -(2\\pi k)^2 \\hat{g}(k)\n$$\n将傅里叶变换逐项应用于泊松方程，我们将微分方程转换为代数方程：\n$$\n- (-(2\\pi k)^2 \\hat{u}(k)) = \\hat{f}_{\\mu}(k) \\implies (2\\pi k)^2 \\hat{u}(k) = \\hat{f}_{\\mu}(k)\n$$\n这使我们能够直接求解解 $u(x)$ 的傅里叶系数：\n$$\n\\hat{u}(k) = \\frac{1}{(2\\pi k)^2} \\hat{f}_{\\mu}(k) \\quad \\text{for } k \\neq 0\n$$\n对于 $k=0$（零频率）模态，它代表均值，对于整数 $\\mu$，条件 $\\int_0^1 f_{\\mu}(x) dx = 0$ 确保了 $\\hat{f}_{\\mu}(0)=0$。问题对 $u(x)$ 具有零均值的约束意味着 $\\hat{u}(0)=0$。因此，该解是良定义的。\n\n因此，将 $f$ 映射到 $u$ 的解析解算子是在傅里叶域中与格林函数（或滤波器）$G(k)$ 的对角乘法：\n$$\n\\hat{u}(k) = G(k) \\hat{f}_{\\mu}(k) \\quad \\text{其中} \\quad G(k) = \\begin{cases} \\frac{1}{(2\\pi k)^2}  k \\neq 0 \\\\ 0  k=0 \\end{cases}\n$$\n这个解析结果构成了我们基准数值求解器的基础。\n\n**2. 数值离散化与基准解求解器**\n\n我们将域 $[0,1)$ 离散化为 $N=128$ 个等距点 $x_j = j/N$，其中 $j=0, 1, \\dots, N-1$。连续傅里叶变换被离散傅里叶变换（DFT）取代，后者通过快速傅里叶变换（FFT）算法高效计算。离散波数 $k$ 由标准的 FFT 频率生成例程提供。\n\n基准解求解器以数值方式实现了解析谱解：\n1.  计算输入网格函数 $f_{\\mu}(x_j)$ 的 DFT，得到 $\\hat{f}_{\\mu}(k)$。\n2.  将每个系数 $\\hat{f}_{\\mu}(k)$ 乘以对应的离散滤波器权重 $G(k)$。\n3.  对得到的系数 $\\hat{u}(k)$ 进行逆 DFT 计算，以获得网格上的解 $u(x_j)$。\n\n**3. 傅里叶神经算子模型与训练**\n\n简化的 FNO 模型由操作 $\\hat{u}_{pred}(k) = w(k)\\hat{f}(k)$ 定义，其中 $w(k)$ 是依赖于波数模 $|k|$ 的学习到的复数权重。\n\n**基线 FNO：** 该模型使用由整数频率 $\\mu \\in \\{2, 3, 4, 5, 6\\}$ 的强迫项生成的数据进行训练。输入 $f_{\\mu}(x) = \\sin(2\\pi \\mu x)$ 的谱能量完全集中在波数 $k=\\pm\\mu$ 处。因此，“训练”过程只能确定 $|k| \\in \\{2, 3, 4, 5, 6\\}$ 的权重。由于已知真实算子，我们可以直接将权重设置为其理想值：对于 $|k| \\in \\{2, \\dots, 6\\}$，$w_{base}(k) = G(k)$。对于训练期间未见过的所有其他波数 $|k|$，权重设置为零，即 $w_{base}(k)=0$。该模型有效地记住了算子在训练频率上的行为，并假设在其他所有地方的响应为零。\n\n**正则化 FNO：** 该模型对权重施加了一个物理驱动的结构。格林函数 $G(k) \\propto k^{-2}$ 的解析形式是基于算子是二阶微分算子的逆这一事实。我们选择函数族 $w_{reg}(k) = C/k^2$（对于 $k \\ne 0$），其中 $C$ 是一个待拟合的标量参数。为了“拟合”$C$，我们对训练波数 $|k| \\in \\{2, \\dots, 6\\}$ 的理想权重 $G(k)$ 进行最小二乘回归。由于我们的模型族与真实算子完美匹配，该拟合过程解析地得出 $C = 1/(4\\pi^2)$。得到的正则化权重为 $w_{reg}(k) = G(k)$（对于所有 $k \\ne 0$）。通过引入正确的物理缩放规律，这个 FNO 学习到了适用于所有频率的真实算子，而不仅仅是训练集中的频率。\n\n**4. 测试用例评估**\n\n这两个模型在一个包含 $\\mu \\in \\{1, 2, 6, 9\\}$ 的测试套件上进行评估。\n\n*   **分布内（$\\mu=2, \\mu=6$）：** 输入频率在训练集内。基线 FNO 和正则化 FNO 在这些频率上都具有正确的权重。两个模型都将产生与基准解相同的预测，导致误差接近于零。\n\n*   **外推（低频，$\\mu=1$）：** 输入频率 $\\mu=1$ 在训练范围 $[\\mu_{min}, \\mu_{max}]=[2,6]$ 之外。基线 FNO 对 $|k|=1$ 有 $w_{base}(k)=0$，因此其预测为 $u_{base}(x)=0$。得到的相对误差为 $1.0$。正则化 FNO 由于学习了通用的 $k^{-2}$ 缩放定律，具有正确的权重，并产生一个误差接近于零的近乎完美的预测。基线模型的误差集中在 $|k|=1$ 处，这不大于 $\\mu_{max}=6$，因此不会触发高频失效模式。\n\n*   **外推（高频，$\\mu=9$）：** 输入频率 $\\mu=9$ 也在训练范围之外。基线 FNO 再次预测 $u_{base}(x)=0$，产生 $1.0$ 的相对误差。正则化 FNO 再次成功。在这种情况下，基线模型的误差完全集中在 $|k|=9$ 处。由于 $9  \\mu_{max}=6$，该能量位于高频带，谱失效诊断将被触发，正确识别出模型无法泛化到未见过的高频。\n\n这个实验设计清晰地展示了朴素的数据驱动模型的一个主要失效模式——外推能力差——并演示了如何通过施加物理知识启发的正则化来获得鲁棒的泛化能力。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the full pipeline for training and evaluating FNOs on a 1D Poisson problem.\n    \"\"\"\n    # Fixed numerical choices from the problem statement\n    N = 128\n    mu_train_min = 2\n    mu_train_max = 6\n    mu_train = list(range(mu_train_min, mu_train_max + 1))\n    mu_test = [1, 2, 6, 9]\n    failure_threshold = 0.6\n\n    # Step 1: Construct a periodic grid and corresponding wavenumbers\n    x = np.arange(N) / N\n    k = np.fft.fftfreq(N, d=1.0/N)\n\n    # Step 2: Implement the ground-truth spectral solver\n    def solve_poisson_spectral(f_in, k_in):\n        \"\"\"Computes the solution to -u''=f using a spectral method.\"\"\"\n        f_hat = np.fft.fft(f_in)\n        \n        # The solution operator in Fourier space is multiplication by G(k) = 1/((2*pi*k)^2) for k!=0.\n        u_hat = np.zeros_like(f_hat)\n        nonzero_k_mask = k_in != 0\n        \n        k_nonzero = k_in[nonzero_k_mask]\n        # The analytical solution for the Fourier coefficients u_hat\n        u_hat[nonzero_k_mask] = (1.0 / (2 * np.pi * k_nonzero)**2) * f_hat[nonzero_k_mask]\n        \n        # Transform back to the spatial domain\n        u_out = np.fft.ifft(u_hat)\n        return u_out.real\n\n    # Step 3: Design and \"train\" the FNO models\n    # Baseline FNO: learns weights only for training wavenumbers\n    w_base = np.zeros(N, dtype=np.complex128)\n    for mu in mu_train:\n        # The ideal weight is from the Green's function\n        weight_val = 1.0 / (2 * np.pi * mu)**2\n        # Set weights for positive and negative wavenumbers (+mu, -mu)\n        w_base[mu] = weight_val\n        w_base[N - mu] = weight_val\n\n    # Regularized FNO: learns a structured physical model for the weights.\n    # The physically motivated family is w(k) = C/k^2. Fitting C to the training\n    # data analytically yields C = 1/(4*pi^2). Thus, the regularized model\n    # learns the exact analytical Green's function for all k.\n    w_reg = np.zeros(N, dtype=np.complex128)\n    nonzero_k_mask = k != 0\n    k_nonzero = k[nonzero_k_mask]\n    w_reg[nonzero_k_mask] = 1.0 / (2 * np.pi * k_nonzero)**2\n\n    # Step 4  5: Test models on the test suite and compute diagnostics\n    results = []\n    for mu in mu_test:\n        # Generate the forcing function for the current test case\n        f = np.sin(2 * np.pi * mu * x)\n        \n        # Compute the ground-truth solution\n        u_true = solve_poisson_spectral(f, k)\n        u_hat_true = np.fft.fft(u_true)\n\n        # Get predictions from both FNO models\n        f_hat = np.fft.fft(f)\n        \n        # Baseline FNO prediction\n        u_hat_base = w_base * f_hat\n        u_base = np.fft.ifft(u_hat_base).real\n        \n        # Regularized FNO prediction\n        u_hat_reg = w_reg * f_hat\n        u_reg = np.fft.ifft(u_hat_reg).real\n        \n        # Compute quantitative diagnostics\n        norm_u_true = np.linalg.norm(u_true)\n        \n        # Relative l2 error for both models\n        # A small epsilon is added to the denominator to prevent division by zero\n        # if the true solution norm is zero (not the case here, but good practice).\n        rel_err_base = np.linalg.norm(u_base - u_true) / (norm_u_true + 1e-12)\n        rel_err_reg = np.linalg.norm(u_reg - u_true) / (norm_u_true + 1e-12)\n        \n        # Boolean indicator of whether regularized error is strictly lower\n        is_improved = rel_err_reg  rel_err_base\n        \n        # Boolean indicator of the high-frequency error failure mode for the baseline FNO\n        e_hat_base = u_hat_base - u_hat_true\n        e_hat_base_energy = np.abs(e_hat_base)**2\n        total_energy = np.sum(e_hat_base_energy)\n        \n        if total_energy  1e-24:  # If error is numerically zero, no failure mode\n            is_fail_mode = False\n        else:\n            high_freq_mask = np.abs(k) > mu_train_max\n            high_freq_energy = np.sum(e_hat_base_energy[high_freq_mask])\n            is_fail_mode = (high_freq_energy / total_energy) > failure_threshold\n            \n        results.append([rel_err_base, rel_err_reg, is_improved, is_fail_mode])\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list in Python includes spaces,\n    # which is consistent with the problem's boilerplate skeleton.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3427041"}]}