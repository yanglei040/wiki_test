{"hands_on_practices": [{"introduction": "在求解偏微分方程（PDEs）产生的大型非线性系统时，我们通常采用（例如 Krylov 方法之类的）迭代法，这类方法无需构建完整的雅可比矩阵。这些求解器只需要计算雅可比矩阵与向量的乘积，即雅可比-向量积（$Jv$）。本练习将指导你实现并比较计算 $Jv$ 的两种关键技术：解析 Gâteaux 导数法和数值有限差分近似法 [@problem_id:3412631]，这对于理解现代非线性求解器中计算成本与准确性之间的权衡至关重要。", "problem": "考虑在区间 $[0,1]$ 上的稳态一维非线性偏微分方程（PDE），其带有齐次狄利克雷边界条件，\n$$\n-\\frac{d}{dx}\\Big( \\big(1 + a\\,u(x)^2\\big)\\,\\frac{du}{dx}(x) \\Big) + b\\,u(x)^3 = 0,\\quad x\\in(0,1),\\qquad u(0)=0,\\;u(1)=0,\n$$\n其中 $a$ 和 $b$ 是实数参数。令 $V_h$ 为在一个包含 $N$ 个节点、间距为 $h = 1/(N-1)$ 的均匀网格上的连续分段线性函数空间，并使用节点基函数。使用标准的伽辽金弱形式和在每个单元上的一点中点求积法，定义仅限于内部节点的离散非线性残差算子 $F(u_h)\\in\\mathbb{R}^{N-2}$，使得对于任何内部测试函数 $v_h\\in V_h$，其单元贡献都是使用 $u_h$ 及其梯度在单元中点的值来计算的。\n\n您的任务是，仅使用局部单元核并且不组装任何全局稀疏矩阵，通过两种方式推导并实现雅可比矩阵 $J(u_h)$ 对向量 $v_h$ 的无矩阵应用：\n\n1. 一种低阶解析线性化方法，计算中点求积残差在方向 $v_h$ 上的 Gâteaux 导数，即通过对中点处的局部单元贡献求和来计算作用 $J(u_h)v_h := \\left.\\frac{d}{d\\epsilon}F(u_h + \\epsilon v_h)\\right|_{\\epsilon=0}$。\n\n2. 一种使用单次前向差分的有限差分雅可比-向量积近似，\n$$\nJ(u_h)\\,v_h \\approx \\frac{F(u_h + \\epsilon\\,v_h) - F(u_h)}{\\epsilon},\n$$\n其中标量步长 $\\epsilon$ 选择为\n$$\n\\epsilon = \\tau\\,\\frac{1 + \\|u_h\\|_2}{\\|v_h\\|_2},\n$$\n其中 $\\tau$ 是一个正常数缩放参数。\n\n您必须使用的基本和建模假设：\n- 使用标准的一维连续伽辽金公式，配以分段线性基函数和单元中点求积法。在长度为 $h$ 的网格单元上，局部基函数的梯度是常数，等于 $\\pm 1/h$。局部中点值 $u_m$ 是单元上节点值的平均值，局部中点梯度是节点值之差除以 $h$。\n- 离散残差 $F(u_h)$ 是通过将扩散项和反应项的单元贡献求和到与内部节点相关的节点残差中得到的。狄利克雷边界值在 $x=0$ 和 $x=1$ 处被强加，未知数仅为内部节点值。\n- 解析雅可比-向量积 $J(u_h)v_h$ 定义为离散残差算子关于 $u_h$ 在方向 $v_h$ 上的 Gâteaux 导数，并使用相同的中点求积法进行一致计算。这必须通过局部单元核实现，在每个单元上仅使用 $u_h$ 和 $v_h$ 的节点值。\n- 有限差分近似在 $u_h + \\epsilon v_h$ 处使用指定的步长 $\\epsilon$ 进行恰好一次额外的 $F$ 求值。\n\n为每个测试用例计算的精度度量：\n- 相对误差\n$$\n\\mathrm{err} = \\frac{\\|J_{\\mathrm{analytic}}(u_h)v_h - J_{\\mathrm{FD}}(u_h)v_h\\|_2}{\\max\\left(\\|J_{\\mathrm{analytic}}(u_h)v_h\\|_2,\\,10^{-16}\\right)}.\n$$\n\n用于比较方法的成本模型：\n- 只计算基本的浮点加法和乘法。对于单个单元，基于直接的中点实现，假设每个单元的操作计数如下：\n  - 对于一次残差 $F(u_h)$ 的求值：$C_F = 16$ 次基本运算，解释为 $7$ 次加法和 $9$ 次乘法。\n  - 对于一次解析雅可比-向量积 $J(u_h)v_h$ 的求值：$C_J = 28$ 次基本运算，解释为 $11$ 次加法和 $17$ 次乘法。\n- 对于一个有 $N$ 个节点和 $N_e = N-1$ 个单元的网格，解析雅可比-向量积的总操作计数为 $N_e\\,C_J$。\n- 对于使用一次额外残差求值的有限差分雅可比-向量积，总操作计数模型为：额外残差的 $N_e\\,C_F$ 加上形成 $u_h + \\epsilon v_h$ 的向量更新成本以及对内部未知数进行差分和缩放的成本，这增加了 $4\\,(N-2)$ 次基本运算。因此总计为 $N_e\\,C_F + 4\\,(N-2)$。\n\n对于所有测试用例，使用以下试验场来评估两种方法：\n- $u(x) = \\sin\\!\\left( 2\\pi x \\right)$ 使得 $u(0)=u(1)=0$。\n- $v(x) = x\\,(1-x)$ 使得 $v(0)=v(1)=0$。\n\n在网格节点上离散化 $u(x)$ 和 $v(x)$，在 $x=0$ 和 $x=1$ 处强制施加边界值，并仅将内部节点值视为未知数和方向。在所有计算中，角度均以弧度为单位。\n\n测试套件：\n- 用例 1：$(N, a, b, \\tau) = (33, 1.0, 1.0, \\sqrt{\\epsilon_{\\mathrm{mach}}})$, 其中 $\\epsilon_{\\mathrm{mach}}$ 是双精度浮点数的机器精度。\n- 用例 2：$(N, a, b, \\tau) = (9, 10.0, 0.0, \\sqrt{\\epsilon_{\\mathrm{mach}}})$。\n- 用例 3：$(N, a, b, \\tau) = (65, 0.0, 5.0, \\sqrt{\\epsilon_{\\mathrm{mach}}})$。\n- 用例 4：$(N, a, b, \\tau) = (17, 1.0, 1.0, 10^{-3})$。\n\n对每个测试用例，计算：\n- 如上定义的相对误差 $\\mathrm{err}$。\n- 成本比率 $\\rho = \\dfrac{\\text{有限差分操作数}}{\\text{解析操作数}} = \\dfrac{N_e\\,C_F + 4\\,(N-2)}{N_e\\,C_J}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含结果，格式为逗号分隔的列表的列表，每个测试用例包含两个浮点数，并按上述测试套件的顺序排列，即 $[\\,[\\mathrm{err}_1,\\rho_1],[\\mathrm{err}_2,\\rho_2],\\ldots\\,]$，不含空格。", "solution": "用户在偏微分方程数值分析领域提供了一个有效且适定的问题。任务是推导、实现并比较两种用于计算离散化非线性偏微分方程的无矩阵雅可比-向量积的方法。该问题在科学上是合理的，并包含了所有必要的信息。我现在将给出完整的解决方案。\n\n问题围绕区间 $[0,1]$ 上的一维非线性边值问题展开：\n$$\n-\\frac{d}{dx}\\Big( \\big(1 + a\\,u(x)^2\\big)\\,\\frac{du}{dx}(x) \\Big) + b\\,u(x)^3 = 0, \\quad u(0)=0,\\;u(1)=0.\n$$\n\n首先，我们建立伽辽金弱形式。令 $V_h$ 为在一个均匀网格上的连续分段线性函数空间，该网格节点为 $x_i = i h$（其中 $i \\in \\{0, 1, \\dots, N-1\\}$），网格间距为 $h = 1/(N-1)$。我们寻求一个离散解 $u_h \\in V_h$，它满足齐次狄利克雷边界条件 $u_h(0)=0$ 和 $u_h(1)=0$。弱形式要求对于所有测试函数 $v_h \\in V_h$（也满足齐次边界条件），以下积分方程成立：\n$$\n\\int_0^1 \\left( \\left(1 + a\\,u_h^2\\right)\\frac{du_h}{dx}\\frac{dv_h}{dx} + b\\,u_h^3 v_h \\right) dx = 0.\n$$\n此方程为 $u_h$ 的内部节点值定义了一个非线性代数方程组。令 $\\mathbf{u} \\in \\mathbb{R}^{N-2}$ 为这些内部节点值的向量。该系统可以写成 $F(\\mathbf{u}) = \\mathbf{0}$，其中 $F: \\mathbb{R}^{N-2} \\to \\mathbb{R}^{N-2}$ 是离散残差算子。\n\n问题指定积分需在每个网格单元 $e_k = [x_k, x_{k+1}]$ 上使用单点中点求积法则进行近似。这意味着 $\\int_{e_k} g(x) dx \\approx h \\cdot g(x_{k+1/2})$，其中 $x_{k+1/2}$ 是单元的中点。\n\n对于一个在单元 $e_k$ 上节点值为 $f_k$ 和 $f_{k+1}$ 的函数 $f_h \\in V_h$，其在中点的值和梯度由以下公式给出：\n- 中点值：$f_m = f_h(x_{k+1/2}) = \\frac{f_k + f_{k+1}}{2}$\n- 中点梯度：$f'_m = \\frac{df_h}{dx}(x_{k+1/2}) = \\frac{f_{k+1} - f_k}{h}$\n\n全局残差 $F(\\mathbf{u})$ 是通过对每个单元的贡献求和来组装的。对于一个节点值为 $u_k$ 和 $u_{k+1}$ 的单元 $e_k$，中点值为 $u_m = (u_k+u_{k+1})/2$ 和 $u'_m = (u_{k+1}-u_k)/h$。该单元对节点 $k$ 和 $k+1$ 处残差的贡献，是通过用相应的基函数测试弱形式得到的。这导致了以下的单元更新：\n扩散项在中点的贡献为 $D_m = (1+a u_m^2)u'_m$。\n反应项在中点的贡献为 $R_m = b u_m^3$。\n单元 $e_k$ 对节点 $k$ 处残差的贡献（如果该节点是内部节点）是 $F_{left}^{(k)} = -D_m + \\frac{h}{2}R_m$。\n单元 $e_k$ 对节点 $k+1$ 处残差的贡献（如果该节点是内部节点）是 $F_{right}^{(k)} = D_m + \\frac{h}{2}R_m$。\n将所有单元的这些贡献相加，形成全局残差向量 $F(\\mathbf{u})$。\n\n**1. 解析雅可比-向量积**\n\n第一个任务是解析地计算雅可比-向量积 $J(\\mathbf{u})\\mathbf{v}$，它被定义为 $F(\\mathbf{u})$ 在方向 $\\mathbf{v}$ 上的 Gâteaux 导数：\n$$\nJ(\\mathbf{u})\\mathbf{v} = \\left.\\frac{d}{d\\epsilon}F(\\mathbf{u} + \\epsilon \\mathbf{v})\\right|_{\\epsilon=0}.\n$$\n我们通过线性化单元贡献来计算它。令 $u_h$ 和 $v_h$ 为与向量 $\\mathbf{u}$ 和 $\\mathbf{v}$ 对应的离散函数。在单元 $e_k$ 上，令扰动解为 $u_h(\\epsilon) = u_h + \\epsilon v_h$。中点值成为 $\\epsilon$ 的函数：\n- $u_m(\\epsilon) = \\frac{(u_k+\\epsilon v_k) + (u_{k+1}+\\epsilon v_{k+1})}{2} = u_m + \\epsilon v_m$\n- $u'_m(\\epsilon) = \\frac{(u_{k+1}+\\epsilon v_{k+1}) - (u_k+\\epsilon v_k)}{h} = u'_m + \\epsilon v'_m$\n其中 $v_m = (v_k+v_{k+1})/2$ 且 $v'_m = (v_{k+1}-v_k)/h$。\n\n扩散项 $D_m(\\epsilon) = (1+a u_m(\\epsilon)^2)u'_m(\\epsilon)$ 的 Gâteaux 导数是：\n$$\n\\delta D_m = \\left.\\frac{d D_m(\\epsilon)}{d\\epsilon}\\right|_{\\epsilon=0} = (2 a u_m v_m)u'_m + (1+a u_m^2) v'_m.\n$$\n反应项 $R_m(\\epsilon) = b u_m(\\epsilon)^3$ 的 Gâteaux 导数是：\n$$\n\\delta R_m = \\left.\\frac{d R_m(\\epsilon)}{d\\epsilon}\\right|_{\\epsilon=0} = 3 b u_m^2 v_m.\n$$\n单元 $e_k$ 对节点 $k$ 处雅可比-向量积的贡献是 $(J\\mathbf{v})_{left}^{(k)} = -\\delta D_m + \\frac{h}{2} \\delta R_m$，对节点 $k+1$ 的贡献是 $(J\\mathbf{v})_{right}^{(k)} = \\delta D_m + \\frac{h}{2} \\delta R_m$。这些贡献以与残差相同的方式组装，形成全局向量 $J(\\mathbf{u})\\mathbf{v}$。\n\n**2. 有限差分雅可比-向量积**\n\n第二个任务是使用前向有限差分来近似雅可比-向量积：\n$$\nJ(\\mathbf{u})\\,\\mathbf{v} \\approx \\frac{F(\\mathbf{u} + \\epsilon\\,\\mathbf{v}) - F(\\mathbf{u})}{\\epsilon}.\n$$\n步长 $\\epsilon$ 是基于平衡截断误差和舍入误差的启发式方法选择的：\n$$\n\\epsilon = \\tau\\,\\frac{1 + \\|\\mathbf{u}\\|_2}{\\|\\mathbf{v}\\|_2},\n$$\n其中 $\\mathbf{u}$ 和 $\\mathbf{v}$ 是内部节点值的向量，$\\tau$ 是一个给定的缩放参数。此方法需要在扰动状态 $\\mathbf{u} + \\epsilon\\mathbf{v}$ 处对残差函数 $F$ 进行一次额外求值。\n\n**3. 比较度量**\n\n这两种方法使用相对误差度量和成本比率进行比较。\n- 相对误差 $\\mathrm{err}$ 衡量解析结果和有限差分结果之间的差异：\n$$\n\\mathrm{err} = \\frac{\\|J_{\\mathrm{analytic}}(\\mathbf{u})\\mathbf{v} - J_{\\mathrm{FD}}(\\mathbf{u})\\mathbf{v}\\|_2}{\\max\\left(\\|J_{\\mathrm{analytic}}(\\mathbf{u})\\mathbf{v}\\|_2,\\,10^{-16}\\right)}.\n$$\n- 计算成本比率 $\\rho$ 根据提供的模型比较两种方法的操作成本：\n$$\n\\rho = \\frac{\\text{有限差分操作数}}{\\text{解析操作数}} = \\frac{N_e\\,C_F + 4\\,(N-2)}{N_e\\,C_J},\n$$\n其中 $N_e = N-1$ 是单元数量，$N$ 是节点数量，$C_F=16$ 是每次残差求值的单元操作计数，$C_J=28$ 是每次解析雅可比-向量积求值的计数。\n\n对于测试，函数 $u(x)=\\sin(2\\pi x)$ 和 $v(x)=x(1-x)$ 在网格上被离散化，以提供内部节点值的向量 $\\mathbf{u}$ 和 $\\mathbf{v}$。", "answer": "```python\nimport numpy as np\n\ndef calculate_residual(u_int, N, a, b):\n    \"\"\"\n    Computes the discrete residual vector F(u) for the interior nodes.\n\n    Args:\n        u_int (np.ndarray): Vector of interior nodal values of u_h.\n        N (int): Total number of mesh nodes.\n        a (float): Parameter 'a' from the PDE.\n        b (float): Parameter 'b' from the PDE.\n\n    Returns:\n        np.ndarray: The residual vector F(u).\n    \"\"\"\n    h = 1.0 / (N - 1)\n    u_full = np.pad(u_int, 1, 'constant')\n    F = np.zeros(N - 2)\n\n    for k in range(N - 1):  # Loop over elements\n        u_k = u_full[k]\n        u_k1 = u_full[k + 1]\n\n        u_m = 0.5 * (u_k + u_k1)\n        u_prime_m = (u_k1 - u_k) / h\n\n        D_m = (1.0 + a * u_m**2) * u_prime_m\n        R_m = b * u_m**3\n        \n        F_left = -D_m + 0.5 * h * R_m\n        F_right = D_m + 0.5 * h * R_m\n\n        if k > 0:\n            F[k - 1] += F_left\n        if k  N - 2:\n            F[k] += F_right\n            \n    return F\n\ndef analytic_Jv(u_int, v_int, N, a, b):\n    \"\"\"\n    Computes the analytic Jacobian-vector product J(u)v.\n\n    Args:\n        u_int (np.ndarray): Vector of interior nodal values of u_h.\n        v_int (np.ndarray): Vector of interior nodal values of v_h.\n        N (int): Total number of mesh nodes.\n        a (float): Parameter 'a' from the PDE.\n        b (float): Parameter 'b' from the PDE.\n\n    Returns:\n        np.ndarray: The Jacobian-vector product J(u)v.\n    \"\"\"\n    h = 1.0 / (N - 1)\n    u_full = np.pad(u_int, 1, 'constant')\n    v_full = np.pad(v_int, 1, 'constant')\n    Jv = np.zeros(N - 2)\n\n    for k in range(N - 1):  # Loop over elements\n        u_k, u_k1 = u_full[k], u_full[k + 1]\n        v_k, v_k1 = v_full[k], v_full[k + 1]\n\n        u_m = 0.5 * (u_k + u_k1)\n        u_prime_m = (u_k1 - u_k) / h\n        v_m = 0.5 * (v_k + v_k1)\n        v_prime_m = (v_k1 - v_k) / h\n\n        dD_m = (2.0 * a * u_m * v_m) * u_prime_m + (1.0 + a * u_m**2) * v_prime_m\n        dR_m = 3.0 * b * u_m**2 * v_m\n        \n        Jv_left = -dD_m + 0.5 * h * dR_m\n        Jv_right = dD_m + 0.5 * h * dR_m\n\n        if k > 0:\n            Jv[k - 1] += Jv_left\n        if k  N - 2:\n            Jv[k] += Jv_right\n            \n    return Jv\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute specified metrics.\n    \"\"\"\n    # Use double precision machine epsilon\n    eps_mach = np.finfo(float).eps\n\n    test_cases = [\n        # (N, a, b, tau)\n        (33, 1.0, 1.0, np.sqrt(eps_mach)),\n        (9, 10.0, 0.0, np.sqrt(eps_mach)),\n        (65, 0.0, 5.0, np.sqrt(eps_mach)),\n        (17, 1.0, 1.0, 1e-3),\n    ]\n\n    results = []\n    \n    C_F = 16\n    C_J = 28\n\n    for N, a, b, tau in test_cases:\n        x_nodes = np.linspace(0, 1, N)\n        \n        # Discretize trial fields u(x) and v(x)\n        u_full = np.sin(2 * np.pi * x_nodes)\n        v_full = x_nodes * (1 - x_nodes)\n        \n        # Extract interior nodal values\n        u_int = u_full[1:-1]\n        v_int = v_full[1:-1]\n\n        # 1. Compute analytic Jacobian-vector product\n        jv_analytic = analytic_Jv(u_int, v_int, N, a, b)\n        \n        # 2. Compute finite-difference Jacobian-vector product\n        norm_u = np.linalg.norm(u_int)\n        norm_v = np.linalg.norm(v_int)\n\n        if norm_v  1e-16: # Avoid division by zero\n            eps = tau * (1.0 + norm_u)\n        else:\n            eps = tau * (1.0 + norm_u) / norm_v\n\n        u_pert = u_int + eps * v_int\n        \n        F_u = calculate_residual(u_int, N, a, b)\n        F_u_pert = calculate_residual(u_pert, N, a, b)\n        \n        jv_fd = (F_u_pert - F_u) / eps\n\n        # 3. Compute accuracy metric 'err'\n        norm_jv_analytic = np.linalg.norm(jv_analytic)\n        diff_norm = np.linalg.norm(jv_analytic - jv_fd)\n        err = diff_norm / max(norm_jv_analytic, 1e-16)\n\n        # 4. Compute cost ratio 'rho'\n        N_e = N - 1\n        cost_analytic = N_e * C_J\n        cost_fd = N_e * C_F + 4 * (N - 2)\n        rho = cost_fd / cost_analytic\n\n        results.append([err, rho])\n\n    # Format output string to match requirement (no spaces)\n    def format_pair(pair):\n        return f\"[{pair[0]},{pair[1]}]\"\n    \n    formatted_results = [format_pair(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3412631"}, {"introduction": "通过数值方法计算的雅可比矩阵，其准确性不仅取决于解析推导，还受到其他离散化选择的影响，例如用于积分的求积法则。本练习中，我们将借鉴拟牛顿法的思想，用割线方程来“修正”一个因积分精度不足而产生的廉价但不准确的雅可比矩阵。这项实践将展示作为拟牛顿法基石的割线条件，如何成为一个强大的工具来提升近似雅可比矩阵的质量，从而有效补偿模型误差 [@problem_id:3412714]。", "problem": "考虑在单位区间上的一维空间中的非线性偏微分方程（PDE）的边值问题，\n$$-u''(x) + R(u(x)) = 0 \\quad \\text{for } x \\in (0,1), \\quad u(0) = 0, \\; u(1) = 0,$$\n其中非线性反应项由 $R(u) = \\alpha \\exp(u)$ 给出，参数 $\\alpha  0$。设在具有 $N$ 个单元和 $N+1$ 个节点的均匀网格上，使用连续的分片线性基函数进行有限元（FE）离散化。其弱形式为：寻找 $u \\in H_0^1(0,1)$，使得对于所有 $v \\in H_0^1(0,1)$，\n$$\\int_0^1 u'(x) v'(x) \\, dx + \\int_0^1 R(u(x)) \\, v(x) \\, dx = 0.$$\n对于与有限元近似 $u_h$ 对应的内部节点值 $U \\in \\mathbb{R}^{N-1}$，定义离散残差映射 $F(U) \\in \\mathbb{R}^{N-1}$ 及其雅可比矩阵 $J(U) \\in \\mathbb{R}^{N-1 \\times N-1}$，其条目为\n$$F_i(U) = \\int_0^1 u_h'(x) \\, \\varphi_i'(x) \\, dx + \\int_0^1 R(u_h(x)) \\, \\varphi_i(x) \\, dx,$$\n$$J_{ij}(U) = \\frac{\\partial F_i}{\\partial U_j}(U) = \\int_0^1 \\varphi_j'(x) \\, \\varphi_i'(x) \\, dx + \\int_0^1 R'(u_h(x)) \\, \\varphi_j(x) \\, \\varphi_i(x) \\, dx,$$\n其中 $\\{\\varphi_i\\}$ 是与内部节点相关的标准帽状基函数，且 $R'(u) = \\alpha \\exp(u)$。对于 $F(U)$ 和 $J(U)$，扩散项的贡献对于分片线性单元是精确积分的。反应项的贡献将通过数值积分计算。为反应项积分定义两种积分方案：\n- 参考积分方案：在每个单元上使用五点 Gauss–Legendre 积分，这被认为对于此目的足够精确。\n- 降阶积分方案：在每个单元上使用中点法则（单元中点的单点积分）。\n\n您的任务是，在从一个给定的光滑函数采样的离散状态 $U$ 下，检验降阶积分如何影响雅可比矩阵的精度，并设计一个使用割线方程补偿的拟牛顿（QN）校正。具体来说：\n\n1. 网格、基函数和状态采样：\n   - 使用具有 $N$ 个单元的均匀网格，节点为 $x_k = k/N$，其中 $k=0,1,\\dots,N$。\n   - 通过在节点处采样 $u^\\star(x) = 0.5 \\sin(\\pi x) + 0.2 \\sin(2\\pi x)$ 并强制施加 Dirichlet 边值 $u^\\star(0) = u^\\star(1) = 0$ 来规定一个光滑的内部状态。令 $U \\in \\mathbb{R}^{N-1}$ 为该采样函数在内部节点处的值所组成的向量。\n2. 残差和雅可比矩阵的形成：\n   - 使用五点 Gauss–Legendre 法则计算反应项，从而组装残差 $F(U)$。\n   - 使用五点 Gauss–Legendre 法则计算反应项以组装雅可比矩阵 $J_{\\text{ref}}(U)$，并使用中点法则计算反应项以组装 $J_{\\text{under}}(U)$。两者都包含扩散项的精确单元刚度。\n3. 降阶积分的误差量化：\n   - 计算相对 Frobenius 范数误差\n     $$E_0 = \\frac{\\|J_{\\text{under}}(U) - J_{\\text{ref}}(U)\\|_F}{\\|J_{\\text{ref}}(U)\\|_F}.$$\n4. 基于割线残差的拟牛顿校正：\n   - 为内部节点 $x_i$ 定义一个确定性的割线方向 $s \\in \\mathbb{R}^{N-1}$，其条目为 $s_i = \\delta \\sin(2\\pi x_i)$，其中 $\\delta = 10^{-2}$ 是固定的。\n   - 在两次 $F$ 的求值中都使用五点 Gauss–Legendre 法则计算反应项，从而形成割线残差 $y = F(U + s) - F(U)$。\n   - 构造一个对 $J_{\\text{under}}(U)$ 的秩一校正，该校正强制满足割线条件 $J_{\\text{corr}}(U) \\, s = y$，同时在 Frobenius 范数下对 $J_{\\text{under}}(U)$ 的改变尽可能小。您必须推导并实现满足此约束的最小变化更新。\n5. 校正后误差：\n   - 计算校正后的相对 Frobenius 范数误差，\n     $$E_1 = \\frac{\\|J_{\\text{corr}}(U) - J_{\\text{ref}}(U)\\|_F}{\\|J_{\\text{ref}}(U)\\|_F},$$\n     以及缩减比 $r = E_1 / E_0$。\n\n设计一个程序，对以下参数值 $(N,\\alpha)$ 的测试套件执行上述步骤：\n- $(N,\\alpha) = (16, 1)$，中等网格与弱非线性。\n- $(N,\\alpha) = (16, 50)$，中等网格与强非线性。\n- $(N,\\alpha) = (64, 50)$，精细网格与强非线性。\n- $(N,\\alpha) = (8, 50)$，粗糙网格与强非线性（边界情况）。\n- $(N,\\alpha) = (64, 1)$，精细网格与弱非线性。\n\n对于每个测试用例，以实数形式报告三元组 $[E_0, E_1, r]$。最终程序输出必须是单行，包含一个按给定顺序排列的、类似 JSON 的三元组数组，不含空格，其中每个浮点数都采用小数点后八位的科学记数法格式（Python 格式说明符 \"%.8e\"）。例如，两个用例的输出应如下所示：\n[[1.23456789e-03,9.87654321e-04,7.99999999e-01],[...],...]\n此问题不涉及物理单位。三角函数中出现的所有角度均以弧度为单位。\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的这些三元组列表，不得包含任何额外文本。", "solution": "该问题是有效的。它提出了一个计算科学中定义明確的任务，具体涉及使用有限元法（FEM）求解非线性偏微分方程（PDE）。所有参数和步骤都已足够精确地指定，从而可以得到唯一且可验证的解。\n\n该问题研究了使用不同数值积分法则组装的雅可比矩阵的精度，并探讨了使用拟牛顿校正来改进一个精度较低的雅可比矩阵。其方法如下。\n\n**1. 有限元离散化**\n\n研究的对象是非线性边值问题（BVP）：\n$$ -u''(x) + \\alpha \\exp(u(x)) = 0, \\quad x \\in (0,1) $$\n其齐次 Dirichlet 边值条件为 $u(0) = u(1) = 0$。参数 $\\alpha  0$ 控制非线性的强度。\n\n该偏微分方程在宽度为 $h = 1/N$ 的均匀网格上，使用连续的分片线性基函数 $\\{\\varphi_i(x)\\}_{i=1}^{N-1}$，通过 Galerkin 有限元法进行离散化。这些基函数通常被称为“帽状函数”，其定义为对于内部节点 $x_j=j/N$ 满足 $\\varphi_i(x_j) = \\delta_{ij}$。解 $u(x)$ 的有限元近似 $u_h(x)$ 表示为这些基函数的线性组合：\n$$ u_h(x) = \\sum_{j=1}^{N-1} U_j \\varphi_j(x) $$\n其中 $U \\in \\mathbb{R}^{N-1}$ 是未知系数向量，代表解在内部节点处的值。\n\n将 $u_h$ 代入 PDE 的弱形式，并用每个基函数 $\\varphi_i$ 进行测试，得到一个非线性代数方程组 $F(U) = 0$，其中残差向量 $F(U)$ 的第 $i$ 个分量为：\n$$ F_i(U) = \\int_0^1 u_h'(x) \\varphi_i'(x) \\, dx + \\int_0^1 \\alpha \\exp(u_h(x)) \\varphi_i(x) \\, dx $$\n该方程组通常使用 Newton's method 求解，这需要残差 $F(U)$ 的雅可比矩阵 $J(U)$。雅可比矩阵的条目由 $J_{ij}(U) = \\partial F_i / \\partial U_j$ 给出：\n$$ J_{ij}(U) = \\int_0^1 \\varphi_j'(x) \\varphi_i'(x) \\, dx + \\int_0^1 \\alpha \\exp(u_h(x)) \\varphi_j(x) \\varphi_i(x) \\, dx $$\n\n**2. 组装与数值积分**\n\n定义 $F(U)$ 和 $J(U)$ 的积分是通过对每个单元 $[x_k, x_{k+1}]$ 的贡献求和来计算的。\n两个表达式中涉及导数的第一项构成了刚度矩阵 $A$。对于均匀网格和分片线性单元，该矩阵是常数、三对角的，并且可以精确计算。其条目为 $A_{ii} = 2/h$ 和 $A_{i,i\\pm 1} = -1/h$。\n\n源于非线性反应项 $R(u)=\\alpha\\exp(u)$ 的第二项依赖于状态 $U$，需要进行数值积分。计算出的残差和雅可比矩阵的精度关键取决于所选的积分法则。问题为这些反应项积分指定了两种法则：\n- **参考法则 ($J_{\\text{ref}}$)**：在每个单元上使用五点 Gauss-Legendre 积分。这是一种高阶法则，在此背景下被认为具有很高的精度。\n- **降阶积分法则 ($J_{\\text{under}}$)**：在每个单元上使用单点中点法则。这种法则计算成本更低但精度也更差，尤其对于非线性被积函数或粗糙网格。\n\n由降阶积分雅可比矩阵引入的误差通过相对 Frobenius 范数差来量化：\n$$ E_0 = \\frac{\\|J_{\\text{under}}(U) - J_{\\text{ref}}(U)\\|_F}{\\|J_{\\text{ref}}(U)\\|_F} $$\n\n**3. 擬牛頓校正**\n\n拟牛顿法构建雅可比矩阵的近似。我们可以借鉴这一思想来“校正”一个不精确但计算成本低的雅可比矩阵 $J_{\\text{under}}(U)$。对于任何雅可比矩阵近似 $B$，一个理想的性质是它满足割线方程 $B s = y$，其中 $s$ 是步长向量，$y$ 是残差的变化量，即 $y = F(U+s) - F(U)$。\n\n问题引导我们通过在 Frobenius 范数下对 $J_{\\text{under}}(U)$ 进行最小的改动，来找到一个校正后的雅可比矩阵 $J_{\\text{corr}}(U)$，使其满足给定方向 $s$ 的割线方程。这是一个约束优化问题：\n$$ \\min_{J_{\\text{corr}}} \\frac{1}{2} \\|J_{\\text{corr}} - J_{\\text{under}}\\|_F^2 \\quad \\text{subject to} \\quad J_{\\text{corr}} s = y $$\n该问题的唯一解是一个秩一更新，由以下公式给出：\n$$ J_{\\text{corr}}(U) = J_{\\text{under}}(U) + \\frac{(y - J_{\\text{under}}(U) s) s^T}{s^T s} $$\n此更新通过添加两个向量的外积来修改 $J_{\\text{under}}(U)$，从而确保满足割线条件，同时尽可能小地扰动原始矩阵。向量 $s$ 和 $y$ 定义如下：\n- 对于内部节点 $x_i$，$s_i = \\delta \\sin(2\\pi x_i)$，其中 $\\delta=10^{-2}$。\n- $y = F(U+s) - F(U)$，其中 $F(U+s)$ 和 $F(U)$ 均使用精确的五点 Gauss-Legendre 法则计算。\n\n**4. 校正后误差**\n\n此校正的有效性通过计算校正后的雅可比矩阵相对于参考雅可比矩阵的相对 Frobenius 范数误差来衡量：\n$$ E_1 = \\frac{\\|J_{\\text{corr}}(U) - J_{\\text{ref}}(U)\\|_F}{\\|J_{\\text{ref}}(U)\\|_F} $$\n缩减比 $r = E_1 / E_0$ 表示改进的程度，其中 $r  1$ 意味着校正成功。\n\n**5. 算法摘要**\n\n对于每对参数 $(N, \\alpha)$：\n1.  定义步长为 $h=1/N$ 的网格并确定内部节点。\n2.  从 $u^\\star(x) = 0.5 \\sin(\\pi x) + 0.2 \\sin(2\\pi x)$ 采样指定的状态 $U$。\n3.  实现一个组装程序，该程序能根据给定的积分法则（点数）计算残差向量 $F(U)$ 和雅可比矩阵 $J(U)$。\n4.  使用 5 点积分法组装参考雅可比矩阵 $J_{\\text{ref}}(U)$ 和参考残差 $F_{\\text{ref}}(U)$。\n5.  使用 1 点（中点）积分法组装降阶积分雅可比矩阵 $J_{\\text{under}}(U)$。\n6.  计算初始误差 $E_0$。\n7.  定义割线向量 $s$，并使用 5 点积分法计算相应的残差差值 $y = F(U+s) - F(U)$。\n8.  使用秩一更新公式计算校正后的雅可比矩阵 $J_{\\text{corr}}(U)$。\n9.  计算校正后误差 $E_1$ 和缩减比 $r=E_1/E_0$。\n10. 存储结果三元组 $[E_0, E_1, r]$。\n最终输出是所有指定测试用例的这些三元组的集合。", "answer": "```python\nimport numpy as np\n\ndef assemble(U_vec, N, alpha, num_quad_points):\n    \"\"\"\n    Assembles the residual vector F and Jacobian matrix J for the given problem.\n\n    Args:\n        U_vec (np.ndarray): Vector of interior nodal values, shape (N-1,).\n        N (int): Number of elements in the mesh.\n        alpha (float): Parameter in the nonlinear reaction term.\n        num_quad_points (int): Number of quadrature points for reaction term integration.\n\n    Returns:\n        F (np.ndarray): The residual vector, shape (N-1,).\n        J (np.ndarray): The Jacobian matrix, shape (N-1, N-1).\n    \"\"\"\n    n_dof = N - 1\n    h = 1.0 / N\n    nodes = np.linspace(0, 1, N + 1)\n    \n    # 1. Stiffness matrix (diffusion term) - exact integration\n    diag_main = np.full(n_dof, 2.0 / h)\n    diag_off = np.full(n_dof - 1, -1.0 / h)\n    A = np.diag(diag_main) + np.diag(diag_off, k=1) + np.diag(diag_off, k=-1)\n    \n    # Initialize reaction term contributions\n    F_reac = np.zeros(n_dof)\n    J_reac = np.zeros((n_dof, n_dof))\n    \n    # Create a full vector of nodal values, including boundary conditions\n    U_full = np.zeros(N + 1)\n    U_full[1:N] = U_vec\n    \n    # Get quadrature points and weights on reference interval [-1, 1]\n    if num_quad_points == 1: # Midpoint rule\n        quad_pts_ref, quad_w_ref = np.array([0.0]), np.array([2.0])\n    else:\n        quad_pts_ref, quad_w_ref = np.polynomial.legendre.leggauss(num_quad_points)\n\n    # 2. Loop over elements to assemble reaction terms\n    for e in range(N):\n        # Global indices of nodes for element e\n        node_idx_1, node_idx_2 = e, e + 1\n        \n        # Nodal values for the element\n        u1, u2 = U_full[node_idx_1], U_full[node_idx_2]\n        \n        # Map quadrature points from [-1, 1] to element [x_e, x_{e+1}]\n        x_e = nodes[e]\n        quad_pts_elem = x_e + (h / 2.0) * (quad_pts_ref + 1.0)\n        quad_w_elem = (h / 2.0) * quad_w_ref\n\n        # Quadrature loop\n        for qp, qw in zip(quad_pts_elem, quad_w_elem):\n            # Local coordinate on element \\xi in [0, h]\n            xi = qp - x_e\n            \n            # Values of local basis functions at quad point\n            phi1_val = 1.0 - xi / h\n            phi2_val = xi / h\n            \n            # Value of u_h and its derivative at quad point\n            u_h_val = u1 * phi1_val + u2 * phi2_val\n            R_val = alpha * np.exp(u_h_val)\n            R_prime_val = R_val # R'(u) = alpha * exp(u)\n            \n            # Add contributions to local reaction vector and matrix\n            # Indices i and j correspond to basis functions phi_1 and phi_2 on the element\n            f1 = qw * R_val * phi1_val\n            f2 = qw * R_val * phi2_val\n            \n            m11 = qw * R_prime_val * phi1_val * phi1_val\n            m12 = qw * R_prime_val * phi1_val * phi2_val\n            m22 = qw * R_prime_val * phi2_val * phi2_val\n            \n            # Assemble into global F_reac and J_reac\n            # node_idx_1 corresponds to DOF `node_idx_1 - 1` if interior\n            if node_idx_1 > 0: \n                dof1 = node_idx_1 - 1\n                F_reac[dof1] += f1\n                J_reac[dof1, dof1] += m11\n            \n            # node_idx_2 corresponds to DOF `node_idx_2 - 1` if interior\n            if node_idx_2  N:\n                dof2 = node_idx_2 - 1\n                F_reac[dof2] += f2\n                J_reac[dof2, dof2] += m22\n            \n            # Off-diagonal term\n            if node_idx_1 > 0 and node_idx_2  N:\n                dof1, dof2 = node_idx_1 - 1, node_idx_2 - 1\n                J_reac[dof1, dof2] += m12\n                J_reac[dof2, dof1] += m12\n\n    # Combine diffusion and reaction terms\n    F = A @ U_vec + F_reac\n    J = A + J_reac\n    \n    return F, J\n\ndef solve():\n    \"\"\"\n    Main driver function to run the analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        (16, 1.0),\n        (16, 50.0),\n        (64, 50.0),\n        (8, 50.0),\n        (64, 1.0),\n    ]\n\n    results = []\n\n    for N, alpha in test_cases:\n        # 1. Mesh, basis, and state sampling\n        n_dof = N - 1\n        x_int = np.linspace(0, 1, N + 1)[1:-1]\n        U = 0.5 * np.sin(np.pi * x_int) + 0.2 * np.sin(2 * np.pi * x_int)\n        \n        # 2. Residual and Jacobian formation\n        F_ref, J_ref = assemble(U, N, alpha, num_quad_points=5)\n        _, J_under = assemble(U, N, alpha, num_quad_points=1)\n\n        # 3. Error quantification for under-integration\n        norm_J_ref = np.linalg.norm(J_ref, 'fro')\n        E0 = np.linalg.norm(J_under - J_ref, 'fro') / norm_J_ref\n\n        # 4. Quasi-Newton correction from a secant residual\n        delta = 1e-2\n        s = delta * np.sin(2 * np.pi * x_int)\n        U_plus_s = U + s\n        \n        F_plus_s, _ = assemble(U_plus_s, N, alpha, num_quad_points=5)\n        y = F_plus_s - F_ref\n        \n        # Least-change rank-one update\n        resid_s = y - (J_under @ s)\n        sTs = s @ s\n        J_corr = J_under + np.outer(resid_s, s) / sTs\n        \n        # 5. Post-correction error\n        E1 = np.linalg.norm(J_corr - J_ref, 'fro') / norm_J_ref\n        r = E1 / E0 if E0 > 0 else 0.0\n\n        results.append([E0, E1, r])\n\n    # Format the final output string exactly as specified\n    case_strings = []\n    for res_triple in results:\n        case_strings.append(f\"[{res_triple[0]:.8e},{res_triple[1]:.8e},{res_triple[2]:.8e}]\")\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3412714"}, {"introduction": "在许多物理问题中，显著的非线性行为往往局限于特定区域，例如边界。如果系统的绝大部分是线性的，那么在每一步都更新完整的雅可比矩阵将非常低效。本练习将探讨一种结构化的拟牛顿法，利用问题的这一结构特性，我们保持雅可比矩阵的线性部分精确不变，同时仅对与非线性边界条件相关的部分应用高效的割线更新 [@problem_id:3412696]。这项动手任务将教会你如何通过结合精确的解析信息和数据驱动的割线近似来设计量身定制的高效求解器，这是高级计算科学中的一项关键策略。", "problem": "考虑一个源于一维偏微分方程（PDE）的非线性边值问题，具体而言，是一个带有非线性Robin型边界条件的泊松方程。令 $u : [0,1] \\to \\mathbb{R}$ 为一个充分光滑的函数，满足\n$$\n-\\frac{d^2 u}{dx^2} = f(x) \\quad \\text{for } x \\in (0,1),\n$$\n非线性边界条件为\n$$\n\\partial_n u(0) + h(u(0)) = 0, \\qquad \\partial_n u(1) + h(u(1)) = 0,\n$$\n其中 $\\partial_n$ 表示外法向导数，$h(u) = \\alpha u + \\beta u^3$，且 $f(x) \\equiv 0$。外法向导数满足 $\\partial_n u(0) = -u'(0)$ 和 $\\partial_n u(1) = u'(1)$。\n\n您的任务是在一个均匀网格上使用 $n$ 个区间对该偏微分方程进行离散化，该网格有 $n+1$ 个节点 $x_i = i h$（$i = 0,1,\\dots,n$），间距为 $h = 1/n$。对内部点使用二阶中心有限差分格式，对边界导数使用二阶单边公式：\n$$\nu'(0) \\approx \\frac{-3 u_0 + 4 u_1 - u_2}{2h}, \\qquad u'(1) \\approx \\frac{3 u_n - 4 u_{n-1} + u_{n-2}}{2h}.\n$$\n定义残差向量 $R(u) \\in \\mathbb{R}^{n+1}$，其分量为\n$$\nR_0(u) = \\frac{3 u_0 - 4 u_1 + u_2}{2h} + h(u_0),\n$$\n$$\nR_i(u) = -\\frac{u_{i-1} - 2 u_i + u_{i+1}}{h^2} \\quad \\text{for } i = 1,2,\\dots,n-1,\n$$\n$$\nR_n(u) = \\frac{3 u_n - 4 u_{n-1} + u_{n-2}}{2h} + h(u_n).\n$$\n1. 通过对 $R(u)$ 关于 $u$ 求导，构建雅可比矩阵 $J(u) \\in \\mathbb{R}^{(n+1)\\times(n+1)}$。显式地导出 $J(u)$ 内部行和边界行的非零项，用 $h$、$\\alpha$、$\\beta$ 和 $u$ 表示。\n2. 实现一个牛顿法 (Newton method) 来求解 $R(u) = 0$，使用初始猜测 $u^{(0)}_i = 0.1 \\sin(\\pi x_i)$（对所有 $i$），并采用回溯线搜索，当欧几里得范数 $\\|R(u)\\|_2$ 减小时接受步长。最多使用 $25$ 次牛顿迭代，当 $\\|R(u)\\|_2 \\le 10^{-10}$ 时宣布收敛。\n3. 提出并实现一种针对此问题的部分割线拟牛顿 (partial secant quasi-Newton) 策略：当边界非线性相对于内部线性刚度占主导地位时，仅使用 $h'(u)$ 的割线近似来更新与边界相关的雅可比行（第 $0$ 行和第 $n$ 行），同时保持内部行精确且固定。具体来说：\n   - 定义主导性判据\n     $$\n     \\max\\left(|h'(u_0)|, |h'(u_n)|\\right)  \\kappa \\cdot \\frac{2}{h},\n     $$\n     其中 $h'(u) = \\alpha + 3\\beta u^2$ 且固定阈值 $\\kappa = 5$。\n   - 如果主导性成立且存在前一次的迭代值 $u^{(k-1)}$，则通过割线斜率来近似边界导数：\n     $$\n     s_0^{(k)} = \\frac{h(u^{(k)}_0) - h(u^{(k-1)}_0)}{u^{(k)}_0 - u^{(k-1)}_0}, \\qquad\n     s_n^{(k)} = \\frac{h(u^{(k)}_n) - h(u^{(k-1)}_n)}{u^{(k)}_n - u^{(k-1)}_n},\n     $$\n     前提是分母不为零；否则，退回到使用精确的 $h'(u)$。\n   - 仅使用这些割线斜率替换 $J(u)$ 边界行对角线元素中的 $h'(u)$，并保持有限差分系数不变。\n4. 比较全牛顿法（每次迭代使用精确雅可比矩阵）和部分割线拟牛顿法（根据判据仅对边界进行割线更新）。对于每个测试用例，报告：\n   - 全牛顿法收敛所需的牛顿迭代次数，\n   - 部分割线法收敛所需的牛顿迭代次数，\n   - 全牛顿法中，雅可比矩阵使用精确边界导数 $h'(u)$ 的次数（即边界精确求值的次数），\n   - 部分割线法中，雅可比矩阵使用精确边界导数 $h'(u)$ 的次数，\n   - 全牛顿法的最终残差范数 $\\|R(u)\\|_2$，\n   - 部分割线法的最终残差范数 $\\|R(u)\\|_2$。\n\n您的程序必须实现这两种策略，并运行以下测试套件，在所有情况下 $f(x) \\equiv 0$：\n- 测试用例 1：$n = 64$，$\\alpha = 1$，$\\beta = 5$，$\\kappa = 5$。\n- 测试用例 2：$n = 64$，$\\alpha = 0.5$，$\\beta = 50$，$\\kappa = 5$。\n- 测试用例 3：$n = 32$，$\\alpha = 1$，$\\beta = 0$，$\\kappa = 5$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按顺序包含每个测试用例的上述六个值，并将所有测试用例的结果连接在一起。例如，输出格式为\n$$\n[\\text{it\\_full\\_1}, \\text{it\\_partial\\_1}, \\text{evals\\_full\\_1}, \\text{evals\\_partial\\_1}, \\text{norm\\_full\\_1}, \\text{norm\\_partial\\_1}, \\dots, \\text{it\\_full\\_3}, \\text{it\\_partial\\_3}, \\text{evals\\_full\\_3}, \\text{evals\\_partial\\_3}, \\text{norm\\_full\\_3}, \\text{norm\\_partial\\_3}],\n$$\n其中每个条目是布尔值、整数、浮点数或这些基本类型的列表。此问题不涉及物理单位或角度单位。", "solution": "用户提出了一个有效的数值分析问题，涉及使用有限差分和牛顿型方法求解非线性边值问题。该问题具有科学依据，是适定的，并提供了所有必要的参数和条件。因此，我将提供完整的解答。\n\n该问题要求解由以下微分方程给出的非线性边值问题（BVP）：\n$$\n-\\frac{d^2 u}{dx^2} = 0, \\quad x \\in (0,1)\n$$\n其非线性Robin型边界条件为：\n$$\n-u'(0) + h(u(0)) = 0\n$$\n$$\nu'(1) + h(u(1)) = 0\n$$\n其中 $h(u) = \\alpha u + \\beta u^3$。\n\n将域 $[0,1]$ 离散化为 $n$ 个大小为 $h=1/n$ 的区间，得到 $n+1$ 个网格点 $x_i = i h$（$i=0, 1, \\dots, n$）。解 $u(x)$ 由一个向量 $u \\in \\mathbb{R}^{n+1}$ 近似，其中 $u_i \\approx u(x_i)$。\n\n使用给定的有限差分格式，我们构建了一个包含 $n+1$ 个非线性代数方程的系统 $R(u) = 0$，其中 $R(u)$ 是残差向量。\n残差的分量如下：\n- 对于 $i=0$（在 $x=0$ 处）：在第一个边界条件 $-u'(0) + h(u_0) = 0$ 中使用 $u'(0)$ 的二阶单边差分，得到\n$$\nR_0(u) = -\\left(\\frac{-3 u_0 + 4 u_1 - u_2}{2h}\\right) + h(u_0) = \\frac{3 u_0 - 4 u_1 + u_2}{2h} + \\alpha u_0 + \\beta u_0^3\n$$\n- 对于 $i=1, 2, \\dots, n-1$（内部点）：对偏微分方程 $-u''(x_i)=0$ 使用二阶中心差分，得到\n$$\nR_i(u) = -\\frac{u_{i-1} - 2 u_i + u_{i+1}}{h^2}\n$$\n- 对于 $i=n$（在 $x=1$ 处）：在第二个边界条件 $u'(1) + h(u_n) = 0$ 中使用 $u'(1)$ 的二阶单边差分，得到\n$$\nR_n(u) = \\frac{3 u_n - 4 u_{n-1} + u_{n-2}}{2h} + h(u_n) = \\frac{3 u_n - 4 u_{n-1} + u_{n-2}}{2h} + \\alpha u_n + \\beta u_n^3\n$$\n这个方程组 $R(u)=0$ 使用牛顿法 (Newton's method) 求解。\n\n### 1. 雅可比矩阵推导\n牛顿法需要雅可比矩阵 $J(u) \\in \\mathbb{R}^{(n+1) \\times (n+1)}$，其中 $J_{ij}(u) = \\frac{\\partial R_i}{\\partial u_j}$。非线性项的导数为 $h'(u) = \\frac{d h}{d u} = \\alpha + 3\\beta u^2$。\n\n雅可比矩阵的非零项推导如下：\n\n**边界行 ($i=0$)：**\n$$\nJ_{00} = \\frac{\\partial R_0}{\\partial u_0} = \\frac{3}{2h} + h'(u_0) = \\frac{3}{2h} + \\alpha + 3\\beta u_0^2\n$$\n$$\nJ_{01} = \\frac{\\partial R_0}{\\partial u_1} = -\\frac{4}{2h} = -\\frac{2}{h}\n$$\n$$\nJ_{02} = \\frac{\\partial R_0}{\\partial u_2} = \\frac{1}{2h}\n$$\n\n**内部行 ($i=1, \\dots, n-1$)：**\n$$\nJ_{i, i-1} = \\frac{\\partial R_i}{\\partial u_{i-1}} = -\\frac{1}{h^2}\n$$\n$$\nJ_{i, i} = \\frac{\\partial R_i}{\\partial u_i} = \\frac{2}{h^2}\n$$\n$$\nJ_{i, i+1} = \\frac{\\partial R_i}{\\partial u_{i+1}} = -\\frac{1}{h^2}\n$$\n\n**边界行 ($i=n$)：**\n$$\nJ_{n, n-2} = \\frac{\\partial R_n}{\\partial u_{n-2}} = \\frac{1}{2h}\n$$\n$$\nJ_{n, n-1} = \\frac{\\partial R_n}{\\partial u_{n-1}} = -\\frac{4}{2h} = -\\frac{2}{h}\n$$\n$$\nJ_{n, n} = \\frac{\\partial R_n}{\\partial u_n} = \\frac{3}{2h} + h'(u_n) = \\frac{3}{2h} + \\alpha + 3\\beta u_n^2\n$$\n\n$J(u)$ 的所有其他项均为零。由于边界导数使用了三点格式，该矩阵具有五对角结构。\n\n### 2. 数值求解策略\n牛顿法是一种求解 $R(u) = 0$ 根的迭代过程。从一个初始猜测 $u^{(0)}$ 开始，后续的迭代值计算如下：\n$$\nu^{(k+1)} = u^{(k)} + \\Delta u^{(k)}\n$$\n其中更新步长 $\\Delta u^{(k)}$ 是以下线性方程组的解：\n$$\nJ(u^{(k)}) \\Delta u^{(k)} = -R(u^{(k)})\n$$\n重复此过程，直到残差的欧几里得范数 $\\|R(u^{(k)})\\|_2$ 低于指定的容差（$10^{-10}$）。\n采用回溯线搜索以确保每一步都减小残差范数。首先尝试一个完整步长 $\\Delta u^{(k)}$。如果 $\\|R(u^{(k)} + \\Delta u^{(k)})\\|_2 \\ge \\|R(u^{(k)})\\|_2$，则步长将连续减半，直到范数减小或达到最小步长。\n\n### 3. 全牛顿法 vs. 部分割线拟牛顿法\n\n**全牛顿法 (Full Newton Method)：** 在每次迭代 $k$ 中，使用上述公式精确计算雅可比矩阵 $J(u^{(k)})$。如果导数 $h'(u)$ 的计算成本很高，这种方法的计算量会很大。我们跟踪对边界行执行此精确求值的迭代次数 `evals_full`，该次数等于迭代次数 `it_full`。\n\n**部分割线拟牛顿法 (Partial Secant Quasi-Newton Method)：** 此方法旨在通过近似雅可比矩阵的部分来降低计算成本。\n- 雅可比矩阵的内部行，对应于偏微分方程的线性部分，保持精确和恒定。\n- 与边界相关的项 $J_{00}$ 和 $J_{nn}$ 会被选择性地更新。\n- 在每次迭代中检查一个**主导性判据**：$\\max(|h'(u_0)|, |h'(u_n)|)  \\kappa \\cdot \\frac{2}{h}$。这个启发式方法比较了非线性边界项的“刚度”与内部网格格式的“刚度”。\n- 如果满足该判据且 $k  0$，则精确导数 $h'(u_0)$ 和 $h'(u_n)$ 将被割线近似所取代：\n$$\ns_0^{(k)} = \\frac{h(u^{(k)}_0) - h(u^{(k-1)}_0)}{u^{(k)}_0 - u^{(k-1)}_0}, \\qquad s_n^{(k)} = \\frac{h(u^{(k)}_n) - h(u^{(k-1)}_n)}{u^{(k)}_n - u^{(k-1)}_n}\n$$\n- 在以下情况下，会对边界点使用精确导数 $h'(u)$：\n    1. 这是第一次迭代（$k=0$）。\n    2. 未满足主导性判据。\n    3. 割线近似的分母接近于零，以防止除以零。\n- 精确边界求值的次数 `evals_partial` 记录了因上述任何原因而对至少一个边界点使用精确导数的迭代次数。这个计数提供了一个衡量“昂贵”求值需要多频繁的指标。\n\n通过比较迭代次数（`it_full` vs. `it_partial`）和精确导数求值次数（`evals_full` vs. `evals_partial`），我们可以评估拟牛顿策略的效率。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test suite and print results.\n    \"\"\"\n\n    def h_func(u, alpha, beta):\n        \"\"\"Computes the nonlinear boundary function h(u).\"\"\"\n        return alpha * u + beta * u**3\n\n    def h_prime_func(u, alpha, beta):\n        \"\"\"Computes the derivative of the boundary function h'(u).\"\"\"\n        return alpha + 3 * beta * u**2\n\n    def calculate_residual(u, n, h_val, alpha, beta):\n        \"\"\"Computes the residual vector R(u).\"\"\"\n        dim = n + 1\n        R = np.zeros(dim)\n        \n        # R_0\n        R[0] = (3 * u[0] - 4 * u[1] + u[2]) / (2 * h_val) + h_func(u[0], alpha, beta)\n        \n        # R_i for i = 1, ..., n-1 (since f(x)=0)\n        for i in range(1, n):\n            R[i] = -(u[i-1] - 2 * u[i] + u[i+1]) / h_val**2\n            \n        # R_n\n        R[n] = (3 * u[n] - 4 * u[n-1] + u[n-2]) / (2 * h_val) + h_func(u[n], alpha, beta)\n        \n        return R\n\n    def run_solvers_for_case(params):\n        \"\"\"\n        Runs both full Newton and partial secant methods for a given test case.\n        \"\"\"\n        n, alpha, beta, kappa = params\n        h = 1.0 / n\n        dim = n + 1\n        x = np.linspace(0, 1, dim)\n        max_iter = 25\n        tol = 1e-10\n        \n        # --- Full Newton Method ---\n        u_full = 0.1 * np.sin(np.pi * x)\n        it_full = 0\n        for k in range(max_iter):\n            R = calculate_residual(u_full, n, h, alpha, beta)\n            norm_R = np.linalg.norm(R)\n            if norm_R = tol:\n                break\n            \n            J = np.zeros((dim, dim))\n            for i in range(1, n):\n                J[i, i-1], J[i, i], J[i, i+1] = -1/h**2, 2/h**2, -1/h**2\n            \n            J[0, 0] = 1.5/h + h_prime_func(u_full[0], alpha, beta)\n            J[0, 1], J[0, 2] = -2/h, 0.5/h\n            J[n, n] = 1.5/h + h_prime_func(u_full[n], alpha, beta)\n            J[n, n-1], J[n, n-2] = -2/h, 0.5/h\n            \n            delta_u = np.linalg.solve(J, -R)\n            \n            lambda_ls = 1.0\n            u_prev_ls = np.copy(u_full)\n            for _ in range(10): # Max 10 line search steps\n                u_new = u_prev_ls + lambda_ls * delta_u\n                if np.linalg.norm(calculate_residual(u_new, n, h, alpha, beta))  norm_R:\n                    break\n                lambda_ls /= 2.0\n            u_full = u_new\n            it_full += 1\n        \n        norm_full = np.linalg.norm(calculate_residual(u_full, n, h, alpha, beta))\n        evals_full = it_full\n\n        # --- Partial Secant Method ---\n        u_partial = 0.1 * np.sin(np.pi * x)\n        u_prev = np.copy(u_partial)\n        it_partial = 0\n        evals_partial = 0\n\n        for k in range(max_iter):\n            R = calculate_residual(u_partial, n, h, alpha, beta)\n            norm_R = np.linalg.norm(R)\n            if norm_R = tol:\n                break\n\n            J = np.zeros((dim, dim))\n            for i in range(1, n):\n                J[i, i-1], J[i, i], J[i, i+1] = -1/h**2, 2/h**2, -1/h**2\n            J[0, 1], J[0, 2] = -2/h, 0.5/h\n            J[n, n-1], J[n, n-2] = -2/h, 0.5/h\n\n            is_exact_update = False\n            h_prime_0 = h_prime_func(u_partial[0], alpha, beta)\n            h_prime_n = h_prime_func(u_partial[n], alpha, beta)\n            is_dominant = max(abs(h_prime_0), abs(h_prime_n)) > kappa * 2.0 / h\n\n            if k == 0 or not is_dominant:\n                is_exact_update = True\n                J[0, 0] = 1.5/h + h_prime_0\n                J[n, n] = 1.5/h + h_prime_n\n            else: # Attempt secant\n                s0, sn = None, None\n                denom0 = u_partial[0] - u_prev[0]\n                if abs(denom0) > 1e-12:\n                    s0 = (h_func(u_partial[0], alpha, beta) - h_func(u_prev[0], alpha, beta)) / denom0\n                denom_n = u_partial[n] - u_prev[n]\n                if abs(denom_n) > 1e-12:\n                    sn = (h_func(u_partial[n], alpha, beta) - h_func(u_prev[n], alpha, beta)) / denom_n\n\n                if s0 is not None:\n                    J[0, 0] = 1.5/h + s0\n                else:\n                    J[0, 0] = 1.5/h + h_prime_0\n                    is_exact_update = True\n                \n                if sn is not None:\n                    J[n, n] = 1.5/h + sn\n                else:\n                    J[n, n] = 1.5/h + h_prime_n\n                    is_exact_update = True\n            \n            if is_exact_update:\n                evals_partial += 1\n\n            u_prev = np.copy(u_partial)\n            delta_u = np.linalg.solve(J, -R)\n            \n            lambda_ls = 1.0\n            u_prev_ls = np.copy(u_partial)\n            for _ in range(10):\n                u_new = u_prev_ls + lambda_ls * delta_u\n                if np.linalg.norm(calculate_residual(u_new, n, h, alpha, beta))  norm_R:\n                    break\n                lambda_ls /= 2.0\n            u_partial = u_new\n            it_partial += 1\n\n        norm_partial = np.linalg.norm(calculate_residual(u_partial, n, h, alpha, beta))\n\n        return [it_full, it_partial, evals_full, evals_partial, norm_full, norm_partial]\n\n    test_cases = [\n        (64, 1, 5, 5),      # Test case 1\n        (64, 0.5, 50, 5),   # Test case 2\n        (32, 1, 0, 5),      # Test case 3\n    ]\n\n    final_results = []\n    for case in test_cases:\n        case_results = run_solvers_for_case(case)\n        final_results.extend(case_results)\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3412696"}]}