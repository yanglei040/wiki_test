{"hands_on_practices": [{"introduction": "在尝试估计参数之前，评估实验数据是否能唯一地确定它们至关重要。费雪信息矩阵 (Fisher Information Matrix, FIM) 通过近似似然函数表面的曲率，为此提供了强有力的工具。本练习将演示如何使用 FIM 的属性，特别是其条件数，来诊断实际的不可辨识性问题，并理解其对优化算法的深远影响 ([@problem_id:3336646])。", "problem": "考虑一个用于基因表达调控实验中单一测量物种的双参数动力学模型，该模型由常微分方程 $ \\frac{dx(t)}{dt} = -k_{1} x(t) + k_{2} u(t) $ 和初始条件 $ x(0) = x_{0} $ 定义，其中 $ u(t) $ 是一个已知的输入曲线，$ \\theta = (k_{1}, k_{2}) $ 是待估计的未知参数。可观测量由 $ y(t_{i}) = x(t_{i}; \\theta) + \\varepsilon_{i} $ 给出，其中 $ \\varepsilon_{i} $ 是独立同分布的高斯噪声项，对于 $ i = 1, \\dots, N $ 个时间点，其均值为零，方差为 $ \\sigma^{2} $。此外，在恒定输入 $ u(t) \\equiv u_{0} $ 下采集了一个稳态测量值 $ y_{\\mathrm{ss}} = x_{\\mathrm{ss}}(\\theta) + \\varepsilon_{\\mathrm{ss}} $，其中 $ x_{\\mathrm{ss}}(\\theta) = \\frac{k_{2}}{k_{1}} u_{0} $ 且 $ \\varepsilon_{\\mathrm{ss}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{ss}}^{2}) $ 与时间序列噪声独立。联合估计问题被构建为一个加权最小二乘问题，它结合了时间序列残差和稳态残差，其权重由噪声方差的倒数确定。\n\n在非线性最小二乘的标准局部渐近正态性假设下，期望的高斯-牛顿法向矩阵等于费雪信息矩阵（FIM），此处定义为灵敏度加权曲率 $ J(\\theta)^{\\top} W J(\\theta) $ 的期望值，其中 $ J(\\theta) $ 是残差向量关于 $ \\theta $ 的雅可比矩阵，$ W $ 是正定对角权重矩阵，其对角线元素对于时间序列残差为 $ 1/\\sigma^{2} $，对于稳态残差为 $ 1/\\sigma_{\\mathrm{ss}}^{2} $。对于上述组合设计，假设在名义参数矢量 $ \\theta^{\\ast} $ 处计算出的费雪信息矩阵（FIM）是对称正定的，并具有两个特征值 $ \\lambda_{\\max} $ 和 $ \\lambda_{\\min} $，满足 $ \\lambda_{\\max} / \\lambda_{\\min} = 10^{6} $。\n\n使用谱条件数的基本定义 $ \\kappa_{2}(A) = \\|A\\|_{2} \\|A^{-1}\\|_{2} $，以及在给定假设下高斯-牛顿法向矩阵与费雪信息矩阵（FIM）之间的对应关系，以精确形式计算在 $ \\theta^{\\ast} $ 处的高斯-牛顿步长的期望谱条件数。然后，从非线性最小二乘的信赖域框架出发，解释在求解高斯-牛顿子问题时，这种条件数如何影响信赖域半径和度量的选择，并阐明在存在组合时间序列和稳态数据的情况下，对步长接受和收敛行为的后果。\n\n将最终数值答案表示为精确的无量纲值；无需四舍五入。", "solution": "该问题需要进行验证。\n\n**步骤1：提取已知条件**\n-   动力学模型: $ \\frac{dx(t)}{dt} = -k_{1} x(t) + k_{2} u(t) $\n-   初始条件: $ x(0) = x_{0} $\n-   参数: $ \\theta = (k_{1}, k_{2}) $\n-   输入: $ u(t) $ 是一个已知函数。\n-   时间序列观测值: $ y(t_{i}) = x(t_{i}; \\theta) + \\varepsilon_{i} $，对于 $ i = 1, \\dots, N $。\n-   时间序列噪声: $ \\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2}) $，独立同分布。\n-   稳态观测值: $ y_{\\mathrm{ss}} = x_{\\mathrm{ss}}(\\theta) + \\varepsilon_{\\mathrm{ss}} $，在恒定输入 $ u(t) \\equiv u_{0} $ 下。\n-   稳态模型: $ x_{\\mathrm{ss}}(\\theta) = \\frac{k_{2}}{k_{1}} u_{0} $。\n-   稳态噪声: $ \\varepsilon_{\\mathrm{ss}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{ss}}^{2}) $。\n-   估计框架: 加权最小二乘，结合两种数据类型。\n-   假设: 期望的高斯-牛顿法向矩阵等于费雪信息矩阵（FIM）。\n-   FIM 定义: $ J(\\theta)^{\\top} W J(\\theta) $。\n-   权重矩阵 $W$: 对角矩阵，元素为 $ 1/\\sigma^{2} $ 和 $ 1/\\sigma_{\\mathrm{ss}}^{2} $。\n-   在名义参数矢量 $ \\theta^{\\ast} $ 处的 FIM: 对称正定。\n-   在 $ \\theta^{\\ast} $ 处的 FIM 的特征值: $ \\lambda_{\\max} $ 和 $ \\lambda_{\\min} $。\n-   特征值比率: $ \\lambda_{\\max} / \\lambda_{\\min} = 10^{6} $。\n-   谱条件数的定义: $ \\kappa_{2}(A) = \\|A\\|_{2} \\|A^{-1}\\|_{2} $。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题在科学上和数学上是合理的。该模型是一个标准的一阶线性常微分方程，在系统生物学中被广泛使用。涉及加权最小二乘、高斯噪声和费雪信息矩阵的统计公式是参数估计的一种典型方法。所有提供的信息都是自洽、一致且相关的。稳态解 $ x_{\\mathrm{ss}}(\\theta) $ 的推导是正确的，因为在常微分方程中设置 $ \\frac{dx(t)}{dt} = 0 $ 会得到 $ 0 = -k_{1} x_{\\mathrm{ss}} + k_{2} u_{0} $，解得 $ x_{\\mathrm{ss}} = (k_{2}/k_{1})u_{0} $。该问题将 FIM 的一个理论性质（其条件数）与数值优化的实际方面（信赖域方法）联系起来，这是计算科学中的一个核心课题。该问题是适定的，并要求进行特定的数值计算和随后的概念性解释。\n\n**步骤3：结论与行动**\n该问题有效。将提供完整解答。\n\n该问题要求分为两部分：首先，计算高斯-牛顿法向矩阵的期望谱条件数；其次，解释其对信赖域优化算法的后果。\n\n**第一部分：谱条件数的计算**\n\n问题指出，在给定假设下，期望的高斯-牛顿法向矩阵等于费雪信息矩阵（FIM）。我们用 $ A = \\text{FIM}(\\theta^{\\ast}) $ 表示该矩阵。问题还指明该矩阵是对称正定的。\n\n矩阵 $ A $ 的谱条件数定义为 $ \\kappa_{2}(A) = \\|A\\|_{2} \\|A^{-1}\\|_{2} $，其中 $ \\| \\cdot \\|_{2} $ 表示矩阵的 $2$-范数（或谱范数）。\n\n对于对称矩阵，其 $2$-范数等于其谱半径，即最大特征值的模。由于 $ A $ 是正定的，其所有特征值均为正。设 $ A $ 的特征值为 $ \\lambda_{i} > 0 $。最大特征值为 $ \\lambda_{\\max} $。因此，\n$$\n\\|A\\|_{2} = \\max_{i} |\\lambda_{i}| = \\lambda_{\\max}\n$$\n$ A $ 的逆矩阵，记为 $ A^{-1} $，也是对称正定的。$ A^{-1} $ 的特征值是 $ A $ 特征值的倒数，即 $ 1/\\lambda_{i} $。因此，$ A^{-1} $ 的最大特征值是 $ A $ 的最小特征值的倒数。\n$$\n\\|A^{-1}\\|_{2} = \\max_{i} \\left|\\frac{1}{\\lambda_{i}}\\right| = \\frac{1}{\\min_{i} |\\lambda_{i}|} = \\frac{1}{\\lambda_{\\min}}\n$$\n将这些代入条件数的定义中，可得：\n$$\n\\kappa_{2}(A) = \\|A\\|_{2} \\|A^{-1}\\|_{2} = \\lambda_{\\max} \\cdot \\frac{1}{\\lambda_{\\min}} = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}}\n$$\n问题给出，在名义参数矢量 $ \\theta^{\\ast} $ 处，FIM 的最大和最小特征值之比为 $ \\lambda_{\\max} / \\lambda_{\\min} = 10^{6} $。\n\n因此，在 $ \\theta^{\\ast} $ 处，高斯-牛顿法向矩阵的期望谱条件数为：\n$$\n\\kappa_{2}(\\text{FIM}(\\theta^{\\ast})) = 10^{6}\n$$\n\n**第二部分：对信赖域方法的影响**\n\n条件数为 $ 10^{6} $ 表明高斯-牛顿法向矩阵是严重病态的。在非线性最小二乘的信赖域框架中，这对优化过程具有深远的影响。\n\n在每次迭代 $k$ 中，信赖域子问题是寻找一个步长 $ p $，该步长在由半径 $ \\Delta_{k} $ 定义的信赖区域内最小化目标函数的二次模型 $ m_{k}(p) $：\n$$\n\\min_{p} m_{k}(p) = f(\\theta_{k}) + g_{k}^{\\top}p + \\frac{1}{2} p^{\\top}B_{k}p \\quad \\text{subject to} \\quad \\|D_{k}p\\|_{2} \\le \\Delta_{k}\n$$\n这里，$ g_{k} $ 是残差平方和的梯度，$ B_{k} $ 是对海森矩阵的高斯-牛顿近似，在本问题中对应于 FIM，即 $ B_{k} = J(\\theta_{k})^{\\top} W J(\\theta_{k}) $。矩阵 $ D_{k} $ 定义了信赖域的度量。\n\n一个条件数为 $ \\kappa_{2}(B_{k}) = 10^{6} $ 的病态矩阵 $ B_k $ 意味着二次模型 $ m_{k}(p) $ 具有高度拉长的椭圆形水平集。目标函数近似的曲率在与 $ \\lambda_{\\max} $ 相关联的特征向量方向上极高，而在与 $ \\lambda_{\\min} $ 相关联的特征向量方向上极低（平坦）。\n\n对信赖域半径和度量的影响：\n1.  **信赖域半径 ($ \\Delta_{k} $):** 信赖域方法的基本原理是根据模型预测的目标函数减少量与试探步长实现的实际减少量之间的一致性来调整半径 $ \\Delta_{k} $。病态的 $ B_{k} $ 意味着二次模型对真实函数的近似非常差，尤其是在对应于小特征值的平坦“谷”方向上。在模型中看似合理的一个步长 $ p $ 可能会导致真实目标函数发生大的、意外的变化，甚至常常是增加。这导致了较差的一致性比率 $ \\rho_{k} $。标准的信赖域更新规则规定，当 $ \\rho_{k} $ 低或为负时，拒绝该步长，并急剧减小信赖域半径 $ \\Delta_{k} $。因此，算法被迫采取非常小的步长以确保二次模型保持有效近似，从而严重减慢收敛速度。\n\n2.  **信赖域度量 ($ D_{k} $):** 如果使用标准的欧几里得度量（$ D_{k} $ 是单位矩阵），则信赖域是一个球体。对于具有高度椭圆形等值线的目标函数，球形信赖域是一个糟糕的几何选择。指向二次模型最小值的牛顿方向 $ p_{N} = -B_{k}^{-1} g_{k} $，可能非常大，并远远超出合理大小的球形信赖域。球内的最优步长可能与牛顿方向大相径庭，导致在目标函数的狭窄谷底上出现低效的“之”字形行为。为解决此问题，使用一个缩放矩阵 $ D_{k} $ 通过 $ \\|D_{k}p\\|_{2} \\le \\Delta_{k} $ 来定义一个椭圆形信赖域。一个精心选择的 $ D_{k} $（例如，从 $ B_k $ 的对角线导出的对角矩阵，或一个更复杂的预条件子）会重塑信赖域，使其与 $ m_{k}(p) $ 的椭圆形等值线对齐。这允许沿着谷底的平坦地面采取更大、更有效的步长，从而提高算法效率。病态性使得该度量的选择对性能至关重要。\n\n对收敛和步长接受的后果：\n-   **步长接受和收敛行为：** 由于模型与真实函数之间频繁不匹配，试探步长经常被拒绝，信赖域半径不断缩小。这导致一系列非常小的、被接受的步长，使得算法“停滞”或以非常慢的线性速率收敛，而不是所期望的二次或超线性速率。算法在参数空间的平坦方向上进展甚微。\n\n-   **与数据和可辨识性的联系：** FIM 的高条件数表示实际上的不可辨识性。与 $ \\lambda_{\\min} $ 相关联的特征向量表示了参数（$ k_{1} $ 和 $ k_{2} $）的一种组合，该组合对模型输出 $ x(t; \\theta) $ 的影响非常小。这意味着组合的时间序列和稳态数据为约束这一特定参数组合提供的信息非常少。例如，稳态数据约束了比率 $ k_{2}/k_{1} $，但如果时间序列数据对时间尺度（取决于 $ k_{1} $）的信息不足，那么 $ k_{1} $ 和 $ k_{2} $ 可以在保持其比率近似恒定的情况下，沿着似然曲面上的一个“山脊”一起变化，而不会显著改变模型与数据的一致性。优化器难以沿着这个平坦的谷底找到精确的最小值，这正是这种统计不确定性的数值表现。", "answer": "$$\n\\boxed{10^{6}}\n$$", "id": "3336646"}, {"introduction": "基于梯度的优化是参数估计的主要方法，但梯度的准确性至关重要。本练习探讨了一个常见的陷阱：在生物学中普遍存在的刚性系统中使用有限差分近似梯度。你将分析刚性如何破坏梯度计算，从而导致优化失败，并体会到如伴随灵敏度法等精确方法的价值 ([@problem_id:3336629])。", "problem": "考虑一个基因调控子系统的最小双时间尺度模块，该模块被建模为一个线性常微分方程（ODE）系统，具有上游生产项和下游激活：\n$$\n\\frac{d x_1}{d t} \\;=\\; -\\,p\\,x_1 \\;+\\; u, \n\\qquad\n\\frac{d x_2}{d t} \\;=\\; -\\,\\lambda\\,x_2 \\;+\\; \\beta\\,x_1,\n$$\n初始条件为 $x_1(0) \\,=\\, 0$ 和 $x_2(0) \\,=\\, 0$。这里 $p \\,>\\, 0$ 是一个待估计的未知快速率参数，$\\lambda \\,>\\, 0$ 是一个已知的慢衰减率，且 $p \\gg \\lambda$（刚性状态），$u \\,>\\, 0$ 是一个已知的生产输入，$\\beta \\,>\\, 0$ 是一个已知的耦合系数。\n\n参数估计目标结合了时间序列和稳态信息。定义确定性目标函数\n$$\nJ(p) \\;=\\; a_1\\,\\big(x_2(t_1;p)\\big)^2 \\;+\\; a_2\\,\\big(x_2(t_2;p)\\big)^2 \\;+\\; w\\,\\big(x_{2,\\text{ss}}(p) - y_{\\text{ss}}\\big)^2,\n$$\n其中 $a_1, a_2, w \\,>\\, 0$ 是权重，$t_1$ 和 $t_2$ 是测量时间，选择 $t_1$ 以探测快速瞬态，选择 $t_2$ 以探测慢速阶段，$y_{\\text{ss}}$ 是测得的 $x_2$ 的稳态浓度。假设 $p \\gg \\lambda$，$t_1$ 满足 $p\\,t_1 = \\mathcal{O}(1)$ 和 $\\lambda\\,t_1 \\ll 1$（快速瞬态窗口），$t_2$ 满足 $\\lambda\\,t_2 = \\mathcal{O}(1)$ 和 $p\\,t_2 \\gg 1$（慢速阶段窗口）。\n\n你可以使用以下经过充分检验的事实和基本定义作为你的基本依据：\n- 对于常系数和常数输入的线性 ODE 解（常数变易法）和代数稳态。\n- 光滑函数的链式法则和泰勒展开。\n- 步长为 $\\delta$ 的导数的前向有限差分近似：对于光滑的 $J$，$(J(p+\\delta) - J(p))/\\delta = J'(p) + \\frac{\\delta}{2}\\,J''(p) + \\mathcal{O}(\\delta^2)$。\n- 对于光滑的 ODE 约束目标函数，精确伴随灵敏度等于真实导数 $J'(p)$。\n- 沿搜索方向 $d$ 的标准回溯 Armijo 线搜索条件：如果 $J(p+\\alpha d) \\leq J(p) + c\\,\\alpha\\,\\nabla J(p)^\\top d$ 对于 $c \\in (0,1)$ 成立，则接受步长 $\\alpha>0$；在实践中，对于梯度下降法，$d = -g$，其中 $g$ 是选定的梯度。\n\n任务：\n1. 推导 $x_1(t;p)$、$x_2(t;p)$ 和稳态 $x_{2,\\text{ss}}(p)$ 的闭式表达式。使用这些表达式，以 $p$、$\\lambda$、$t_1$、$t_2$、$u$ 和 $\\beta$ 的形式符号化地表示 $J'(p)$ 和 $J''(p)$，无需简化为单个标量常数。你的推导必须从所述的基本依据开始。\n\n2. 使用 $J$ 的泰勒展开，推导前向有限差分梯度 $g_{\\mathrm{fd}}(p;\\delta) := \\frac{J(p+\\delta) - J(p)}{\\delta}$ 相对于伴随法提供的精确梯度 $J'(p)$ 的主阶偏差。将偏差 $b(p;\\delta) := g_{\\mathrm{fd}}(p;\\delta) - J'(p)$ 表示到 $\\delta$ 的主阶项。\n\n3. 使用上面给出的刚性状态时间尺度假设，通过分离在 $t_1$ 处的快速瞬态和在 $t_2$ 处的慢速阶段以及稳态项的贡献，来分析 $J'(p)$ 和 $J''(p)$ 的尺度。根据此分析，得出一个关于有限差分步长 $\\delta$ 的条件，在该条件下 $g_{\\mathrm{fd}}(p;\\delta)$ 的符号与 $J'(p)$ 的符号不同（即符号翻转）。你的条件必须用 $J'(p)$、$J''(p)$ 和 $\\delta$ 明确陈述。\n\n4. 在回溯 Armijo 线搜索中，搜索方向为 $d = -g_{\\mathrm{fd}}(p;\\delta)$，并且当初始试探步长未能通过 Armijo 检验时，步长截断会将 $\\alpha$ 减小到小值。解释刚性和偏差 $b(p;\\delta)$ 如何共同误导线搜索。你的解释必须从 Armijo 不等式和在 $\\alpha = 0$ 处的方向导数开始，并以当发生符号翻转时对小 $\\alpha$ 的截断失败的机制结束。\n\n选择唯一正确的陈述，该陈述最好地概括了由于刚性和有限差分导致的步长截断的线搜索失败机制和偏差的定量比较：\n\nA. 前向差分梯度满足 $g_{\\mathrm{fd}}(p;\\delta) = J'(p) + \\frac{\\delta}{2}\\,J''(p) + \\mathcal{O}(\\delta^2)$，并且在 $p \\gg \\lambda$ 的刚性状态下，当测量侧重于快速瞬态时，只要 $\\delta > \\frac{2\\,|J'(p)|}{|J''(p)|}$，就会发生符号翻转 $g_{\\mathrm{fd}}(p;\\delta)\\,J'(p)  0$；在这种情况下，使用 $d = -g_{\\mathrm{fd}}(p;\\delta)$ 的 Armijo 回溯会将 $\\alpha$ 截断为小值并失败，因为在 $\\alpha = 0$ 处的真实方向导数为正。\n\nB. 在刚性状态下，伴随梯度 $g_{\\mathrm{ad}}(p)$ 的偏差与 $g_{\\mathrm{fd}}(p;\\delta)$ 相同，因为伴随方程继承了刚性；因此，线搜索行为不受使用 $g_{\\mathrm{fd}}$ 还是 $g_{\\mathrm{ad}}$ 的影响。\n\nC. 刚性总是抑制曲率，使得 $|J''(p)|$ 相对于 $p$ 是指数级小的，这使得有限差分梯度比伴随梯度更可靠；因此，对于任何 $\\delta$，$g_{\\mathrm{fd}}(p;\\delta)$ 相对于 $J'(p)$ 都不能翻转符号。\n\nD. 在任何情况下，如果使用有偏梯度，Armijo 回溯都可以接受一个使 $J$ 增大的步长，因为接受条件使用 $g_{\\mathrm{fd}}(p;\\delta)$ 代替 $J'(p)$。", "solution": "用户提供了一个关于刚性常微分方程（ODE）系统参数估计的多部分问题。我将首先验证问题陈述，然后进行完整的推导和分析。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n-   **ODE 系统**：\n    $$\n    \\frac{d x_1}{d t} \\;=\\; -\\,p\\,x_1 \\;+\\; u \\\\\n    \\frac{d x_2}{d t} \\;=\\; -\\,\\lambda\\,x_2 \\;+\\; \\beta\\,x_1\n    $$\n-   **初始条件**：$x_1(0) = 0$，$x_2(0) = 0$。\n-   **参数和常数**：\n    -   $p  0$：未知的快速率参数。\n    -   $\\lambda  0$：已知的慢衰减率。\n    -   $u  0$：已知的生产输入。\n    -   $\\beta  0$：已知的耦合系数。\n    -   $a_1, a_2, w  0$：权重。\n    -   $t_1, t_2$：测量时间。\n    -   $y_{\\text{ss}}$：测得的 $x_2$ 的稳态浓度。\n-   **状态假设**：\n    -   刚性状态：$p \\gg \\lambda$。\n    -   快速瞬态窗口：$p\\,t_1 = \\mathcal{O}(1)$ 且 $\\lambda\\,t_1 \\ll 1$。\n    -   慢速阶段窗口：$\\lambda\\,t_2 = \\mathcal{O}(1)$ 且 $p\\,t_2 \\gg 1$。\n-   **目标函数**：\n    $$\n    J(p) \\;=\\; a_1\\,\\big(x_2(t_1;p)\\big)^2 \\;+\\; a_2\\,\\big(x_2(t_2;p)\\big)^2 \\;+\\; w\\,\\big(x_{2,\\text{ss}}(p) - y_{\\text{ss}}\\big)^2\n    $$\n-   **已知事实**：\n    -   线性 ODE 解。\n    -   链式法则和泰勒展开。\n    -   前向有限差分近似：$(J(p+\\delta) - J(p))/\\delta = J'(p) + \\frac{\\delta}{2}\\,J''(p) + \\mathcal{O}(\\delta^2)$。\n    -   伴随灵敏度等于真实导数 $J'(p)$。\n    -   Armijo 线搜索条件：$J(p+\\alpha d) \\leq J(p) + c\\,\\alpha\\,\\nabla J(p)^\\top d$ 对于 $c \\in (0,1)$。\n\n**步骤2：使用提取的已知条件进行验证**\n\n-   **科学上合理**：该问题描述了一个基因调控级联的简单线性模型，这是系统生物学中的一个标准模体。由时间尺度分离引起的刚性（$p \\gg \\lambda$）概念在该领域是基础性的。目标函数是标准的加权平方误差和。该问题在科学上是合理的。\n-   **适定的**：该问题是适定的。具有常系数和零初始条件的线性 ODE 系统有唯一的解析解。目标函数是参数 $p$ 的光滑函数。任务是具体的，并且可以数学形式化。\n-   **客观性**：该问题以精确、客观的数学语言陈述。\n-   **其他缺陷**：该问题是自洽的、一致的，并且需要非平凡的推导和分析。它不是不适定的、同义反复的或无法验证的。\n\n**步骤3：结论和行动**\n\n问题陈述是**有效的**。我将继续进行解答。\n\n### 推导与分析\n\n**任务1：闭式表达式和导数**\n\n首先，我们求解 ODE 系统。$x_1$ 的方程是一个具有常数输入的标准一阶线性 ODE：\n$$\n\\frac{d x_1}{d t} + p\\,x_1 = u, \\quad x_1(0)=0\n$$\n使用积分因子 $e^{pt}$ 求得解：\n$$\nx_1(t;p) = \\frac{u}{p}(1 - e^{-pt})\n$$\n接下来，我们将其代入 $x_2$ 的方程：\n$$\n\\frac{d x_2}{d t} + \\lambda\\,x_2 = \\beta x_1(t;p) = \\frac{\\beta u}{p}(1 - e^{-pt}), \\quad x_2(0)=0\n$$\n这是另一个一阶线性 ODE。使用积分因子 $e^{\\lambda t}$ 或拉普拉斯变换可以得到解。使用拉普拉斯变换，令 $X_2(s) = \\mathcal{L}\\{x_2(t)\\}$。\n$$\nsX_2(s) + \\lambda X_2(s) = \\beta \\mathcal{L}\\{x_1(t)\\} = \\beta \\frac{u}{s(s+p)}\n$$\n$$\nX_2(s) = \\frac{\\beta u}{s(s+p)(s+\\lambda)}\n$$\n使用部分分式展开，$X_2(s) = \\frac{A}{s} + \\frac{B}{s+p} + \\frac{C}{s+\\lambda}$：\n$$\nA = \\frac{\\beta u}{p\\lambda}, \\quad B = \\frac{\\beta u}{p(p-\\lambda)}, \\quad C = -\\frac{\\beta u}{\\lambda(p-\\lambda)}\n$$\n进行拉普拉斯逆变换得到时域解：\n$$\nx_2(t;p) = \\frac{\\beta u}{p\\lambda} + \\frac{\\beta u}{p(p-\\lambda)}e^{-pt} - \\frac{\\beta u}{\\lambda(p-\\lambda)}e^{-\\lambda t}\n$$\n稳态浓度可以通过将时间导数设为零，或取极限 $t\\to\\infty$ 来找到。当 $t\\to\\infty$ 时，指数项衰减到零（$p, \\lambda  0$）：\n$$\nx_{1,\\text{ss}}(p) = \\frac{u}{p}\n$$\n$$\nx_{2,\\text{ss}}(p) = \\frac{\\beta}{\\lambda}x_{1,\\text{ss}}(p) = \\frac{\\beta u}{\\lambda p}\n$$\n现在，我们表示目标函数 $J(p)$ 的导数。令 $s_2(t;p) = \\frac{\\partial x_2(t;p)}{\\partial p}$ 和 $s_{2,ss}(p) = \\frac{\\partial x_{2,ss}(p)}{\\partial p}$。使用链式法则：\n$$\nJ'(p) = 2a_1 x_2(t_1;p) s_2(t_1;p) + 2a_2 x_2(t_2;p) s_2(t_2;p) + 2w \\big(x_{2,\\text{ss}}(p) - y_{\\text{ss}}\\big) s_{2,ss}(p)\n$$\n对于二阶导数：\n$$\n\\begin{align*}\nJ''(p) = 2a_1 \\left[ (s_2(t_1;p))^2 + x_2(t_1;p) \\frac{\\partial^2 x_2(t_1;p)}{\\partial p^2} \\right] \\\\\n+ 2a_2 \\left[ (s_2(t_2;p))^2 + x_2(t_2;p) \\frac{\\partial^2 x_2(t_2;p)}{\\partial p^2} \\right] \\\\\n+ 2w \\left[ (s_{2,ss}(p))^2 + \\big(x_{2,\\text{ss}}(p) - y_{\\text{ss}}\\big) \\frac{\\partial^2 x_{2,ss}(p)}{\\partial p^2} \\right]\n\\end{align*}\n$$\n这些是任务1所要求的符号表达式。偏导数的显式形式在代数上很复杂，但对于后续分析不是必需的。\n\n**任务2：有限差分梯度的偏差**\n\n问题提供了梯度 $g_{\\mathrm{fd}}(p;\\delta)$ 的前向有限差分近似的泰勒展开：\n$$\ng_{\\mathrm{fd}}(p;\\delta) := \\frac{J(p+\\delta) - J(p)}{\\delta} = J'(p) + \\frac{\\delta}{2}\\,J''(p) + \\mathcal{O}(\\delta^2)\n$$\n精确梯度是 $J'(p)$。偏差定义为 $b(p;\\delta) = g_{\\mathrm{fd}}(p;\\delta) - J'(p)$。根据上面的表达式，偏差是：\n$$\nb(p;\\delta) = \\left( J'(p) + \\frac{\\delta}{2}\\,J''(p) + \\mathcal{O}(\\delta^2) \\right) - J'(p) = \\frac{\\delta}{2}\\,J''(p) + \\mathcal{O}(\\delta^2)\n$$\n主阶偏差是 $\\frac{\\delta}{2}\\,J''(p)$。\n\n**任务3：符号翻转的条件**\n\n当 $g_{\\mathrm{fd}}(p;\\delta)$ 和 $J'(p)$ 的符号相反时，即 $g_{\\mathrm{fd}}(p;\\delta) \\cdot J'(p)  0$，就会发生符号翻转。\n代入 $g_{\\mathrm{fd}}(p;\\delta)$ 的表达式：\n$$\n\\left( J'(p) + \\frac{\\delta}{2}\\,J''(p) \\right) \\cdot J'(p)  0\n$$\n我们考虑使这个不等式成立的两种情况：\n1.  $J'(p)  0$：我们需要 $J'(p) + \\frac{\\delta}{2}\\,J''(p)  0$。这意味着 $J''(p)$ 必须为负，并且 $\\frac{\\delta}{2}(-J''(p))  J'(p) \\implies \\delta  \\frac{-2J'(p)}{J''(p)} = \\frac{2|J'(p)|}{|J''(p)|}$。\n2.  $J'(p)  0$：我们需要 $J'(p) + \\frac{\\delta}{2}\\,J''(p)  0$。这意味着 $J''(p)$ 必须为正，并且 $\\frac{\\delta}{2}J''(p)  -J'(p) \\implies \\delta  \\frac{-2J'(p)}{J''(p)} = \\frac{2|J'(p)|}{|J''(p)|}$。\n\n在两种情况下，当偏差项 $\\frac{\\delta}{2}J''(p)$ 的符号与 $J'(p)$ 相反且幅度更大时，就会发生符号翻转。截至 $\\delta$ 的主阶项，条件是：\n$$\n\\delta  \\frac{2|J'(p)|}{|J''(p)|}\n$$\n在刚性系统中，目标函数相对于刚性参数 $p$ 可能表现出快速变化。这可能导致相对于梯度 $|J'(p)|$ 的大曲率 $|J''(p)|$，特别是当 $J(p)$ 中的不同项产生的梯度很小（或几乎抵消）而相应的曲率项相长地相加时。这使得对于合理大小的有限差分步长 $\\delta$，符号翻转的条件是可满足的。\n\n**任务4：Armijo 线搜索失败机制**\n\nArmijo 回溯线搜索要求步长 $\\alpha$ 满足充分下降条件：\n$$\nJ(p+\\alpha d) \\leq J(p) + c\\,\\alpha\\,\\nabla J(p)^\\top d\n$$\n其中 $d$ 是搜索方向，$c \\in (0,1)$。在这个问题中，搜索方向是使用有偏的有限差分梯度计算的：$d = -g_{\\mathrm{fd}}(p;\\delta)$。\n\n项 $\\nabla J(p)^\\top d$ 是真实目标函数 $J$ 沿搜索方向 $d$ 的方向导数。让我们在 $\\alpha=0$ 处对其求值：\n$$\n\\nabla J(p)^\\top d = J'(p) \\cdot (-g_{\\mathrm{fd}}(p;\\delta)) = -J'(p) \\cdot g_{\\mathrm{fd}}(p;\\delta)\n$$\n如果发生了符号翻转，如任务3中所分析，那么根据定义 $J'(p) \\cdot g_{\\mathrm{fd}}(p;\\delta)  0$。因此，真实方向导数为正：\n$$\n\\nabla J(p)^\\top d = -J'(p) \\cdot g_{\\mathrm{fd}}(p;\\delta)  0\n$$\n这意味着搜索方向 $d = -g_{\\mathrm{fd}}(p;\\delta)$ 对于真实目标函数 $J$ 实际上是一个*上升*方向。对于任何小的正 $\\alpha$，函数值将会增加：$J(p+\\alpha d)  J(p)$。\n\nArmijo 条件变为：\n$$\nJ(p+\\alpha d) \\leq J(p) + c\\,\\alpha\\,(\\text{一个正数})\n$$\n对于足够小的 $\\alpha  0$，我们可以对左侧进行泰勒展开：$J(p+\\alpha d) \\approx J(p) + \\alpha \\nabla J(p)^\\top d$。将此代入不等式中：\n$$\nJ(p) + \\alpha \\nabla J(p)^\\top d \\leq J(p) + c\\,\\alpha\\,\\nabla J(p)^\\top d\n$$\n因为 $\\alpha  0$ 且我们已经确定 $\\nabla J(p)^\\top d  0$，我们可以除以 $\\alpha \\nabla J(p)^\\top d$ 得到：\n$$\n1 \\leq c\n$$\n这与 $c \\in (0,1)$ 的要求相矛盾。因此，对于任何足够小的 $\\alpha$，Armijo 条件将失败。一个在失败时减小 $\\alpha$ 的回溯算法将反复失败并将 $\\alpha$ 截断至趋近于零，导致线搜索无法找到可接受的步长。\n\n### 选项评估\n\n-   **A. 前向差分梯度满足 $g_{\\mathrm{fd}}(p;\\delta) = J'(p) + \\frac{\\delta}{2}\\,J''(p) + \\mathcal{O}(\\delta^2)$，并且在 $p \\gg \\lambda$ 的刚性状态下，当测量侧重于快速瞬态时，只要 $\\delta  \\frac{2\\,|J'(p)|}{|J''(p)|}$，就会发生符号翻转 $g_{\\mathrm{fd}}(p;\\delta)\\,J'(p)  0$；在这种情况下，使用 $d = -g_{\\mathrm{fd}}(p;\\delta)$ 的 Armijo 回溯会将 $\\alpha$ 截断为小值并失败，因为在 $\\alpha = 0$ 处的真实方向导数为正。**\n    该陈述与我们的推导完全一致。它正确地陈述了偏差公式、符号翻转的条件以及 Armijo 线搜索失败的机制。刚性可能导致大的 $|J''|/|J'|$ 比率这一前提是此类系统数值优化中的一个已知病态问题。因此，该陈述提供了一个完整而正确的描述。**正确**。\n\n-   **B. 在刚性状态下，伴随梯度 $g_{\\mathrm{ad}}(p)$ 的偏差与 $g_{\\mathrm{fd}}(p;\\delta)$ 相同，因为伴随方程继承了刚性；因此，线搜索行为不受使用 $g_{\\mathrm{fd}}$ 还是 $g_{\\mathrm{ad}}$ 的影响。**\n    这是不正确的。伴随法在解析地或以足够的数值精度求解时，计算的是精确梯度 $J'(p)$。它不受有限差分法固有的截断误差偏差的影响。虽然伴随 ODE 也可能是刚性的且数值求解困难，但这会引入数值误差，而不是一个形式为 $\\frac{\\delta}{2}J''(p)$ 的系统偏差。**不正确**。\n\n-   **C. 刚性总是抑制曲率，使得 $|J''(p)|$ 相对于 $p$ 是指数级小的，这使得有限差分梯度比伴随梯度更可靠；因此，对于任何 $\\delta$，$g_{\\mathrm{fd}}(p;\\delta)$ 相对于 $J'(p)$ 都不能翻转符号。**\n    这在多个方面都是不正确的。刚性通过引入快速的函数变化，可能导致大的而非被抑制的曲率。有限差分梯度比伴随梯度更可靠的说法通常是错误的；伴随法通常因其在高维参数空间中的准确性和效率而更受青睐。符号翻转是不可能的这一结论与优化刚性系统的已知挑战相反。**不正确**。\n\n-   **D. 在任何情况下，如果使用有偏梯度，Armijo 回溯都可以接受一个使 $J$ 增大的步长，因为接受条件使用 $g_{\\mathrm{fd}}(p;\\delta)$ 代替 $J'(p)$。**\n    这是不正确的。Armijo 条件是 $J(p+\\alpha d) \\le J(p) + c \\alpha \\nabla J(p)^\\top d$。即使规则的某个变体在右侧项中使用近似梯度，即 $J(p+\\alpha d) \\le J(p) + c \\alpha g_{\\mathrm{fd}}^\\top d$，项 $g_{\\mathrm{fd}}^\\top d = g_{\\mathrm{fd}}^\\top (-g_{\\mathrm{fd}}) = -\\|g_{\\mathrm{fd}}\\|^2$ 也总是负的。这将使条件变为 $J(p+\\alpha d) \\le J(p) - c \\alpha \\|g_{\\mathrm{fd}}\\|^2$，这严格要求 $J$ 下降。线搜索算法旨在确保充分下降，不会接受一个增加目标函数值的步长。**不正确**。\n\n唯一正确且完整的陈述是 A。", "answer": "$$\\boxed{A}$$", "id": "3336629"}, {"introduction": "寻找单一的最佳拟合参数集通常只能提供一幅不完整的图景，因为它忽略了估计中固有的不确定性。最后的这个练习将从点估计转向全面的贝叶斯分析，通过实现马尔可夫链蒙特卡洛 (MCMC) 算法的核心部分。你将构建一个 Metropolis-Hastings 采样器，从后验分布中生成样本，学习如何将似然、先验和提议机制结合起来，以描绘参数不确定性的完整图景 ([@problem_id:3336664])。", "problem": "考虑一个计算系统生物学中的单物种基因调控系统，该系统由一个非线性常微分方程 (ODE) 建模。浓度 $X(t)$（单位为 $\\mathrm{mol\\,L^{-1}}$）的变化遵循以下方程：\n$$\n\\frac{dX}{dt} \\;=\\; \\frac{k_{\\mathrm{syn}}}{1 + \\left(\\frac{X}{K}\\right)^{n}} \\;-\\; k_{\\mathrm{deg}}\\,X,\n$$\n其中 $k_{\\mathrm{syn}}$ 是合成速率，$k_{\\mathrm{deg}}$ 是降解速率，$n$ 是希尔系数，$K$ 是解离常数（一个正常数）。假设 $k_{\\mathrm{syn}} = 2.0$（单位为 $\\mathrm{mol\\,L^{-1}\\,s^{-1}}$），$k_{\\mathrm{deg}} = 0.4$（单位为 $\\mathrm{s^{-1}}$），$n = 2$（无量纲），初始条件为 $X(0) = 0$（单位为 $\\mathrm{mol\\,L^{-1}}$）。\n\n合成数据按以下方式生成。令 $K_{\\mathrm{true}} = 0.8$（单位为 $\\mathrm{mol\\,L^{-1}}$）。对 ODE 进行数值积分，以获得在时间点 $t_i \\in \\{0,1,2,3,5,8,12,16,20\\}$（单位为 $\\mathrm{s}$）以及在稳态探测时间 $T_{\\mathrm{ss}} = 40$（单位为 $\\mathrm{s}$）的无噪声轨迹 $X(t_i; K_{\\mathrm{true}})$。然后，使用固定的随机种子 $123$，为时间序列点和稳态探测点分别抽取标准差为 $\\sigma = 0.05$（单位为 $\\mathrm{mol\\,L^{-1}}$）和 $\\sigma_{\\mathrm{ss}} = 0.05$（单位为 $\\mathrm{mol\\,L^{-1}}$）的高斯测量噪声。观测数据为\n$$\ny_i \\;=\\; X(t_i; K_{\\mathrm{true}}) + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2),\n$$\n以及\n$$\ny_{\\mathrm{ss}} \\;=\\; X(T_{\\mathrm{ss}}; K_{\\mathrm{true}}) + \\varepsilon_{\\mathrm{ss}},\\quad \\varepsilon_{\\mathrm{ss}} \\sim \\mathcal{N}(0,\\sigma_{\\mathrm{ss}}^2).\n$$\n\n我们考虑使用时间序列数据和稳态数据对单个参数 $K$ 进行贝叶斯参数估计。设后验概率正比于 $L(p)\\,\\pi(p)$，其中 $p$ 表示完整的参数向量，$L(p)$ 是从时间序列 $\\{y_i\\}$ 和稳态探测 $y_{\\mathrm{ss}}$ 的高斯噪声模型导出的似然函数，$\\pi(p)$ 是先验。在这里，其他参数是固定的（$k_{\\mathrm{syn}},k_{\\mathrm{deg}},n$ 已知），$p$ 简化为 $K$。假设 $K$ 服从对数正态先验，$K \\sim \\mathrm{LogNormal}(\\mu,\\tau^2)$，其中 $\\mu = \\ln(0.8)$ 且 $\\tau = 0.3$。\n\n你必须为参数 $K$ 实现一个 Metropolis-Hastings (MH) 更新步骤，使用一个由 $\\ln K' = \\ln K + s\\,Z$ 定义的对数正态随机游走提议 $q(K' \\mid K)$，其中 $Z \\sim \\mathcal{N}(0,1)$ 且提议尺度 $s  0$。MH 步骤必须根据第一性原理（贝叶斯法则和 Metropolis-Hastings 算法）计算接受概率，并考虑到 $q(K' \\mid K)$ 的不对称性。\n\n算法要求：\n- 使用科学合理的方法对 ODE 进行数值积分，以计算 $X(t_i;K)$ 和 $X(T_{\\mathrm{ss}};K)$。使用适合刚性或非刚性问题的 ODE 求解器。\n- 根据时间序列和稳态观测的高斯噪声模型构建对数似然函数。对数似然必须包含两部分的贡献，并且必须与指定的 $\\sigma$ 和 $\\sigma_{\\mathrm{ss}}$ 一致。\n- 为 $K$ 的对数正态先验构建对数先验。\n- 从贝叶斯法则和 Metropolis-Hastings 接受准则推导 MH 步骤的接受概率，明确考虑由不对称的对数正态提议引起的 Hastings 校正。\n- 实现一个单一的 MH 更新，该更新从 $q(K' \\mid K)$ 提出 $K'$，计算接受概率，并报告该概率。为保证确定性行为，在生成提议时使用固定的随机种子 $2025$。\n- 如果 ODE 积分失败或 $K' \\le 0$，则视该提议为无效，并将接受概率设为 $0$。\n\n测试套件：\n对于每个测试用例，你会获得 $K$ 的当前值和提议尺度 $s$。使用上面定义的共享合成数据集（由你的程序内部生成）和共享的先验参数。为每个用例评估单次 MH 更新的接受概率。\n\n- 测试用例 1（正常路径）：当前 $K = 0.5$，提议尺度 $s = 0.2$。\n- 测试用例 2（边界探索）：当前 $K = 0.05$，提议尺度 $s = 0.6$。\n- 测试用例 3（从较远值进行的保守提议）：当前 $K = 2.0$，提议尺度 $s = 0.1$。\n- 测试用例 4（接近真实值且提议相对激进）：当前 $K = 0.8$，提议尺度 $s = 0.5$。\n\n你的程序应生成一行输出，其中包含上述测试用例的接受概率，形式为方括号括起来的逗号分隔列表（例如，$[a_1,a_2,a_3,a_4]$）。每个接受概率必须报告为区间 $[0,1]$ 内的浮点数（无单位）。不应打印任何额外文本。", "solution": "该问题要求在一个基因调控的非线性常微分方程 (ODE) 模型中，计算参数 $K$ 的单次 Metropolis-Hastings (MH) 更新的接受概率。此估计在贝叶斯框架下进行，利用合成的时间序列数据和稳态数据。\n\n### 1. 问题验证\n\n问题已经过验证，并被确定为 **有效**。\n- **给定条件**:\n    - **ODE 模型**: $\\frac{dX}{dt} = \\frac{k_{\\mathrm{syn}}}{1 + (X/K)^n} - k_{\\mathrm{deg}}X$，初始条件 $X(0) = 0$。\n    - **固定常数**: $k_{\\mathrm{syn}} = 2.0\\,\\mathrm{mol\\,L^{-1}\\,s^{-1}}$，$k_{\\mathrm{deg}} = 0.4\\,\\mathrm{s^{-1}}$，$n = 2$。\n    - **数据生成**: 使用真实参数 $K_{\\mathrm{true}} = 0.8\\,\\mathrm{mol\\,L^{-1}}$。数据点位于 $t_i \\in \\{0, 1, 2, 3, 5, 8, 12, 16, 20\\}\\,\\mathrm{s}$ 和 $T_{\\mathrm{ss}} = 40\\,\\mathrm{s}$。测量噪声为高斯噪声，标准差 $\\sigma = \\sigma_{\\mathrm{ss}} = 0.05\\,\\mathrm{mol\\,L^{-1}}$。用于数据生成的随机种子固定为 $123$。\n    - **贝叶斯设置**: 待估计参数为 $K  0$。$K$ 的先验为对数正态分布，$K \\sim \\mathrm{LogNormal}(\\mu, \\tau^2)$，其中 $\\mu = \\ln(0.8)$ 且 $\\tau = 0.3$。\n    - **MH 提议**: 对数正态随机游走，$\\ln K' = \\ln K + sZ$，其中 $Z \\sim \\mathcal{N}(0, 1)$。用于生成提议的随机种子固定为 $2025$。\n    - **测试用例**: 指定了四个用例，包含 $K$ 的初始值和提议尺度 $s$。\n- **结论**: 该问题具有科学依据，定义明确，客观且完整。它代表了计算系统生物学中的一项标准任务。\n\n### 2. 贝叶斯模型构建\n\n给定观测数据 $D = \\{y_i\\} \\cup \\{y_{\\mathrm{ss}}\\}$，参数 $K$ 的后验分布由贝叶斯定理给出：\n$$\np(K | D) \\propto L(D | K) \\pi(K)\n$$\n其中 $L(D | K)$ 是似然函数，$\\pi(K)$ 是先验。在计算上，使用对数后验更为稳定：\n$$\n\\log p(K | D) = \\log L(D | K) + \\log \\pi(K) + \\mathrm{const}.\n$$\n\n**对数似然 (Log-Likelihood):**\n假设测量噪声是独立同分布的高斯噪声，均值为 $0$，标准差为 $\\sigma = 0.05$。令 $\\mathbf{t}_{\\mathrm{obs}}$ 为所有观测时间的向量，包括 $T_{\\mathrm{ss}}$，令 $X(\\mathbf{t}_{\\mathrm{obs}}; K)$ 为使用参数 $K$ 对 ODE 进行数值积分得到的相应模型预测。对数似然为：\n$$\n\\log L(D | K) = -\\frac{1}{2\\sigma^2} \\sum_{j} (y_j - X(t_j; K))^2 + \\mathrm{const}.\n$$\n求和遍及所有数据点。常数项可以忽略，因为它在 MH 接受率的计算中会被抵消。\n\n**对数先验 (Log-Prior):**\n参数 $K$ 被赋予一个对数正态先验，$K \\sim \\mathrm{LogNormal}(\\mu, \\tau^2)$。这等价于说 $\\ln K$ 服从正态分布，$\\ln K \\sim \\mathcal{N}(\\mu, \\tau^2)$。$K$ 的概率密度函数为：\n$$\n\\pi(K) = \\frac{1}{K\\tau\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln K - \\mu)^2}{2\\tau^2}\\right)\n$$\n忽略常数项，对数先验为：\n$$\n\\log \\pi(K) \\propto -\\ln K - \\frac{(\\ln K - \\mu)^2}{2\\tau^2}\n$$\n\n### 3. Metropolis-Hastings 接受概率\n\nMH 算法用于从后验分布中抽样。给定当前参数值 $K$，从一个分布 $q(K' | K)$ 中提出一个新值 $K'$。该提议以概率 $\\alpha$ 被接受：\n$$\n\\alpha(K' | K) = \\min\\left(1, \\frac{p(K'|D)q(K|K')}{p(K|D)q(K'|K)}\\right)\n$$\n$\\frac{q(K|K')}{q(K'|K)}$ 这一项是 Hastings 校正，它解释了提议分布中的任何不对称性。\n\n**提议分布和 Hastings 校正:**\n提议是一个对数正态随机游走：$K' = K e^{sZ}$，其中 $Z \\sim \\mathcal{N}(0, 1)$。这可以写成 $\\ln K' = \\ln K + sZ$。令 $v = \\ln K$ 和 $v' = \\ln K'$。对 $v$ 的提议是 $v' \\sim \\mathcal{N}(v, s^2)$，这是对称的：$f(v'|v) = f(v|v')$。\n为了找到提议密度 $q(K'|K)$，我们使用变量替换公式：$q(K'|K) = f(v'|v) \\left| \\frac{dv'}{dK'} \\right| = f(v'|v) \\frac{1}{K'}$。\n因此，Hastings 校正为：\n$$\n\\frac{q(K|K')}{q(K'|K)} = \\frac{f(v|v')/K}{f(v'|v)/K'} = \\frac{1/K}{1/K'} = \\frac{K'}{K}\n$$\n\n**通过重参数化进行推导:**\n一个更优雅的方法是，通过 $\\kappa = \\ln K$ 对模型进行重参数化。\n- **变换后的先验**: $\\kappa$ 的先验现在是正态分布，$\\kappa \\sim \\mathcal{N}(\\mu, \\tau^2)$，所以 $\\log \\pi(\\kappa) \\propto -\\frac{(\\kappa - \\mu)^2}{2\\tau^2}$。\n- **变换后的提议**: 提议是 $\\kappa' = \\kappa + sZ$，这是一个对称的随机游走。提议密度 $q(\\kappa'|\\kappa)$ 是对称的，意味着 $q(\\kappa'|\\kappa) = q(\\kappa|\\kappa')$，因此 Hastings 校正为 $1$。\n- **变换后的似然**: 似然是原始参数 $K=e^\\kappa$ 的函数，所以 $\\log L(D|\\kappa) = \\log L(D|K=e^\\kappa)$。\n- **变换后的后验**: $\\kappa$ 的对数后验为 $\\log p(\\kappa|D) \\propto \\log L(D|e^\\kappa) - \\frac{(\\kappa-\\mu)^2}{2\\tau^2}$。\n\n以 $\\kappa$ 表示的接受率为：\n$$\nA = \\frac{p(\\kappa'|D)}{p(\\kappa|D)} = \\frac{L(D|e^{\\kappa'}) \\pi(\\kappa')}{L(D|e^{\\kappa}) \\pi(\\kappa)}\n$$\n取对数，我们得到对数接受率：\n$$\n\\log A = \\log p(\\kappa'|D) - \\log p(\\kappa|D)\n$$\n$$\n\\log A = \\left(\\log L(D|e^{\\kappa'}) - \\frac{(\\kappa' - \\mu)^2}{2\\tau^2}\\right) - \\left(\\log L(D|e^{\\kappa}) - \\frac{(\\kappa - \\mu)^2}{2\\tau^2}\\right)\n$$\n代入 $\\kappa = \\ln K$ 和 $\\kappa' = \\ln K'$：\n$$\n\\log A = \\left(\\log L(D|K') - \\frac{(\\ln K' - \\mu)^2}{2\\tau^2}\\right) - \\left(\\log L(D|K) - \\frac{(\\ln K - \\mu)^2}{2\\tau^2}\\right)\n$$\n这个计算正确地结合了似然、先验和隐含的 Hastings 校正。接受概率 $\\alpha$ 于是为 $\\min(1, \\exp(\\log A))$。\n\n### 4. 算法实现\n\n1.  **生成合成数据**:\n    -   将随机种子设为 $123$。\n    -   使用固定参数和 $K_{\\mathrm{true}} = 0.8$ 定义 ODE 系统。\n    -   使用 `scipy.integrate.solve_ivp` 在时间跨度 $[0, 40]$ 内，在所有指定的观测时间 $t_j$ 上对 ODE 进行积分。\n    -   生成高斯噪声 $\\varepsilon_j \\sim \\mathcal{N}(0, \\sigma^2)$ 并将其加到真实轨迹点 $X(t_j; K_{\\mathrm{true}})$ 上，以获得观测数据 $y_j$。\n\n2.  **定义对数后验函数**:\n    -   创建一个函数 `log_posterior(K)`，返回对数后验值（至多相差一个常数）。\n    -   该函数检查是否 $K \\le 0$。如果是，则返回 $-\\infty$，对应于后验概率为 $0$。\n    -   它使用给定的 $K$ 调用 `solve_ivp`。如果积分失败，也返回 $-\\infty$。\n    -   如果成功，它计算模型预测与观测数据之间的误差平方和。\n    -   它计算对数似然项：$-\\frac{SSE}{2\\sigma^2}$。\n    -   它使用 $\\kappa = \\ln K$ 的形式计算对数先验项：$-\\frac{(\\ln K - \\mu)^2}{2\\tau^2}$。\n    -   该函数返回这两项的和。\n\n3.  **为每个测试用例执行 MH 更新**:\n    -   将用于生成提议的随机种子设为 $2025$。\n    -   对于每个测试用例 `(K_current, s)`：\n        a. 计算当前状态的对数后验：`log_post_current = log_posterior(K_current)`。\n        b. 生成一个标准正态随机变量 $Z$。\n        c. 提出一个新状态：$K_{\\mathrm{prop}} = K_{\\mathrm{current}} \\cdot \\exp(s \\cdot Z)$。\n        d. 计算提议状态的对数后验：`log_post_prop = log_posterior(K_prop)`。\n        e. `log_posterior` 函数通过返回 $-\\infty$ 来处理无效提议（$K_{\\mathrm{prop}} \\le 0$ 或求解器失败）。如果 `log_post_prop` 是 $-\\infty$，接受概率为 $0$。\n        f. 否则，计算对数接受率：`log_A = log_post_prop - log_post_current`。\n        g. 接受概率为 $\\alpha = \\min(1.0, \\exp(\\log A))$。\n    -   收集所有测试用例计算出的 $\\alpha$。\n\n4.  **最终输出**:\n    -   将接受概率列表格式化为所需的字符串 `[p1,p2,p3,p4]`。", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian parameter estimation problem for a gene regulation model.\n    \"\"\"\n\n    # --- 1. Define Model Constants and Parameters ---\n    K_SYN = 2.0  # mol L^-1 s^-1\n    K_DEG = 0.4  # s^-1\n    N_HILL = 2.0  # dimensionless\n    X0 = 0.0  # mol L^-1\n\n    # Data generation parameters\n    K_TRUE = 0.8  # mol L^-1\n    TIME_POINTS_TS = np.array([0, 1, 2, 3, 5, 8, 12, 16, 20], dtype=float) # s\n    TIME_POINT_SS = 40.0 # s\n    OBS_TIMES = np.sort(np.unique(np.append(TIME_POINTS_TS, TIME_POINT_SS)))\n    T_SPAN = (0, OBS_TIMES[-1])\n    \n    SIGMA = 0.05  # mol L^-1 (same for time-series and steady-state)\n    DATA_SEED = 123\n    \n    # Bayesian inference parameters\n    PRIOR_MU = np.log(0.8)\n    PRIOR_TAU = 0.3\n    PROPOSAL_SEED = 2025\n\n    # Test cases\n    test_cases = [\n        (0.5, 0.2),  # K_current, proposal_scale_s\n        (0.05, 0.6),\n        (2.0, 0.1),\n        (0.8, 0.5),\n    ]\n\n    # --- 2. Define the ODE System ---\n    def ode_system(t, x, K, k_syn, k_deg, n):\n        if K == 0:\n            # Physically meaningless, but as a safeguard.\n            return [np.nan]\n        \n        # Ensure x is not negative for the model evaluation\n        x_val = max(0, x[0])\n        \n        dxdt = (k_syn / (1 + (x_val / K)**n)) - k_deg * x_val\n        return [dxdt]\n\n    # --- 3. Generate Synthetic Data ---\n    # This is done once and shared across all test cases.\n    def generate_data():\n        rng = np.random.default_rng(DATA_SEED)\n        \n        # Integrate ODE to get noise-free data\n        sol = solve_ivp(\n            ode_system,\n            T_SPAN,\n            [X0],\n            method='RK45',\n            t_eval=OBS_TIMES,\n            args=(K_TRUE, K_SYN, K_DEG, N_HILL)\n        )\n        \n        if not sol.success or sol.y.shape[1] != len(OBS_TIMES):\n             raise RuntimeError(\"ODE integration failed during data generation.\")\n        \n        x_true = sol.y[0]\n        \n        # Add Gaussian noise\n        noise = rng.normal(0, SIGMA, size=len(x_true))\n        y_obs = x_true + noise\n        \n        # Data at t=0 must be exactly X(0) if observed.\n        if 0 in OBS_TIMES:\n            y_obs[np.where(OBS_TIMES == 0)] = X0\n            \n        return y_obs, OBS_TIMES\n\n    y_observed, t_observed = generate_data()\n    \n    # --- 4. Define Log-Posterior Calculation ---\n    # This computation is central to the MH step.\n    memo = {}\n    def calculate_log_posterior(K):\n        # Memoization to avoid re-computing for the same K\n        if K in memo:\n            return memo[K]\n            \n        # Prior check: K must be positive\n        if K = 0:\n            return -np.inf\n\n        # Calculate log-prior based on ln(K) ~ N(mu, tau^2)\n        log_prior_val = norm.logpdf(np.log(K), loc=PRIOR_MU, scale=PRIOR_TAU)\n\n        # Numerically integrate the ODE for the given K\n        sol = solve_ivp(\n            ode_system,\n            T_SPAN,\n            [X0],\n            method='RK45',\n            t_eval=t_observed,\n            args=(K, K_SYN, K_DEG, N_HILL)\n        )\n\n        # Handle integration failure\n        if not sol.success or sol.y.shape[1] != len(t_observed) or np.any(np.isnan(sol.y)):\n            memo[K] = -np.inf\n            return -np.inf\n\n        # Calculate log-likelihood\n        x_predicted = sol.y[0]\n        sum_sq_err = np.sum((y_observed - x_predicted)**2)\n        log_likelihood_val = -sum_sq_err / (2 * SIGMA**2)\n\n        result = log_likelihood_val + log_prior_val\n        memo[K] = result\n        return result\n\n    # --- 5. Perform MH Update for Each Test Case ---\n    rng_proposal = np.random.default_rng(PROPOSAL_SEED)\n    results = []\n\n    for k_current, s in test_cases:\n        memo.clear() # Clear memoization for each independent test case\n        \n        # Calculate log posterior for the current state\n        log_post_current = calculate_log_posterior(k_current)\n        \n        # Propose a new state using log-normal random walk\n        z = rng_proposal.normal(0, 1)\n        k_proposal = k_current * np.exp(s * z)\n        \n        # Calculate log posterior for the proposed state\n        log_post_proposal = calculate_log_posterior(k_proposal)\n\n        # If proposal is invalid (log_post = -inf), acceptance probability is 0\n        if np.isneginf(log_post_proposal):\n             acceptance_prob = 0.0\n        else:\n            # Calculate acceptance probability in log-space to avoid underflow\n            log_acceptance_ratio = log_post_proposal - log_post_current\n            acceptance_prob = min(1.0, np.exp(log_acceptance_ratio))\n        \n        results.append(acceptance_prob)\n\n    # --- 6. Final Output ---\n    # Format the output as a comma-separated list in brackets\n    print(f\"[{','.join(f'{p:.7f}' for p in results)}]\")\n\nsolve()\n```", "id": "3336664"}]}