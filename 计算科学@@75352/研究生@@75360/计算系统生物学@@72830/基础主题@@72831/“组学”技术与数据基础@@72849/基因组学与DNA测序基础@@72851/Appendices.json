{"hands_on_practices": [{"introduction": "理想情况下，测序数据应能均匀、无偏地反映样本中的所有DNA片段。然而，在文库制备等实验步骤中，系统性偏差是不可避免的，其中聚合酶链式反应（PCR）扩增就是主要来源之一。本练习将引导你从第一性原理（如热力学和动力学）出发，建立一个量化模型，以探索GC含量如何影响引物结合和聚合酶延伸效率，从而导致测序覆盖度的偏差。通过这个实践，你将能更深入地理解并批判性地评估测序数据的质量。", "problem": "考虑一个简化的、基于第一性原理的聚合酶链式反应 (PCR) 扩增模型，该模型用于测序文库制备过程，并捕捉局部鸟嘌呤-胞嘧啶 (GC) 含量对引物杂交动力学和脱氧核糖核酸 (DNA) 聚合酶持续合成能力的影响。目标是推导、实现并评估一个预测函数，该函数能将局部 GC 分数映射到经过固定数量 PCR 循环后的预期覆盖度偏倚。仅使用以下基本原理。\n\n- 引物-模板结合的质量作用平衡，采用单一位点结合模型：平衡解离常数为 $K_d = \\exp\\!\\left(\\Delta G/(R T)\\right)$，其中 $\\Delta G$ 是标准吉布斯自由能变，$R$ 是普适气体常数，$T$ 是以开尔文为单位的绝对温度。对于引物浓度 $C_p$ (摩尔/升)，达到平衡时，已结合引物的靶标分数是 $f_{\\mathrm{bind}} = \\dfrac{C_p}{C_p + K_d}$。\n- 在固定离子强度下，一个粗粒度的、序列依赖的自由能模型：对于长度为 $L_p$、局部 GC 分数为 $g \\in [0,1]$ 的引物，其结合自由能近似为 $\\Delta G(g) = L_p\\big[g\\,\\delta g_{\\mathrm{GC}} + (1-g)\\,\\delta g_{\\mathrm{AT}}\\big] + \\delta g_{\\mathrm{init}}$，其中 $\\delta g_{\\mathrm{GC}}$ 和 $\\delta g_{\\mathrm{AT}}$ 是每碱基的贡献（单位：千卡/摩尔），而 $\\delta g_{\\mathrm{init}}$ 是一个起始项（单位：千卡/摩尔）。\n- 一个关于持续合成能力的每碱基延续模型：设每碱基的脱落概率为 $p_{\\mathrm{drop}}(g) = p_0\\big[1 + \\beta\\,(g - 0.5)\\big]$，并裁剪到区间 $[0,1)$。每碱基的延续概率是 $q(g) = 1 - p_{\\mathrm{drop}}(g)$。聚合酶完成长度为 $L_{\\mathrm{ext}}$ 个碱基的扩增子延伸的概率是 $p_{\\mathrm{ext}}(g) = \\big(q(g)\\big)^{L_{\\mathrm{ext}}}$。\n- 预期的每循环扩增倍数因子：一个循环产生预期的倍数变化 $F(g) = 1 + f_{\\mathrm{bind}}(g)\\,p_{\\mathrm{ext}}(g)$，其值界于 $[1,2]$。经过 $C$ 个循环后，预期的拷贝数乘以 $\\big(F(g)\\big)^{C}$。\n\n将相对于参考 GC 分数 $g_{\\mathrm{ref}}$ 的 GC 依赖性覆盖度偏倚定义为比率\n$$\nB(g) = \\left(\\frac{F(g)}{F(g_{\\mathrm{ref}})}\\right)^{C}。\n$$\n您的任务是：\n- 仅从上述基本原理出发，推导出 $B(g)$ 关于参数 $\\{L_p,L_{\\mathrm{ext}},\\delta g_{\\mathrm{GC}},\\delta g_{\\mathrm{AT}},\\delta g_{\\mathrm{init}},T,C_p,p_0,\\beta,C,g_{\\mathrm{ref}},R\\}$ 的闭式表达式。\n- 实现一个程序，根据下述数值和单位约定，为几个指定的 $g$ 值和参数集计算 $B(g)$。\n\n数值和单位约定：\n- 使用能量单位千卡/摩尔。使用温度单位开尔文。使用浓度单位摩尔/升。如果引物浓度以纳摩尔/升为单位给出，使用 $1\\,\\mathrm{nM} = 10^{-9}\\,\\mathrm{M}$ 进行转换。\n- 使用 $R = 1.987\\times 10^{-3}\\,\\mathrm{kcal}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$。\n- 所有输出均为无量纲比率。将报告的每个偏倚值四舍五入到小数点后 $6$ 位。\n\n待实现和评估的测试套件：\n对于每个测试用例，使用给定的参数，计算并返回针对所提供 GC 分数的列表 $\\big[B(g_1),B(g_2),\\ldots\\big]$。\n\n- 测试用例 $1$ (正常路径)：\n  - GC 分数：$[0.2, 0.5, 0.8]$。\n  - $L_p = 20$，$L_{\\mathrm{ext}} = 300$，$\\delta g_{\\mathrm{GC}} = -2.5$ 千卡/摩尔，$\\delta g_{\\mathrm{AT}} = -1.0$ 千卡/摩尔，$\\delta g_{\\mathrm{init}} = +1.0$ 千卡/摩尔。\n  - $T = 333$ 开尔文，$C_p = 250$ 纳摩尔/升，$p_0 = 0.005$，$\\beta = 0.8$，$C = 15$，$g_{\\mathrm{ref}} = 0.5$。\n\n- 测试用例 $2$ (低引物浓度和高温)：\n  - GC 分数：$[0.2, 0.5, 0.8]$。\n  - $L_p = 20$，$L_{\\mathrm{ext}} = 300$，$\\delta g_{\\mathrm{GC}} = -2.5$，$\\delta g_{\\mathrm{AT}} = -1.0$，$\\delta g_{\\mathrm{init}} = +1.0$。\n  - $T = 343$，$C_p = 1$ 纳摩尔/升，$p_0 = 0.005$，$\\beta = 0.8$，$C = 15$，$g_{\\mathrm{ref}} = 0.5$。\n\n- 测试用例 $3$ (强 GC 依赖性脱落，包括极端的 GC 边界)：\n  - GC 分数：$[0.0, 0.5, 1.0]$。\n  - $L_p = 20$，$L_{\\mathrm{ext}} = 300$，$\\delta g_{\\mathrm{GC}} = -2.5$，$\\delta g_{\\mathrm{AT}} = -1.0$，$\\delta g_{\\mathrm{init}} = +1.0$。\n  - $T = 333$，$C_p = 250$ 纳摩尔/升，$p_0 = 0.005$，$\\beta = 2.0$，$C = 15$，$g_{\\mathrm{ref}} = 0.5$。\n\n- 测试用例 $4$ (长扩增子、较高脱落率和更多循环)：\n  - GC 分数：$[0.2, 0.5, 0.8]$。\n  - $L_p = 20$，$L_{\\mathrm{ext}} = 1000$，$\\delta g_{\\mathrm{GC}} = -2.5$，$\\delta g_{\\mathrm{AT}} = -1.0$，$\\delta g_{\\mathrm{init}} = +1.0$。\n  - $T = 333$，$C_p = 250$ 纳摩尔/升，$p_0 = 0.010$，$\\beta = 0.8$，$C = 20$，$g_{\\mathrm{ref}} = 0.5$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，格式为方括号括起来的逗号分隔列表。每个元素对应一个测试用例，其本身也是一个方括号括起来的、针对指定 GC 分数的四舍五入偏倚值的逗号分隔列表。例如，输出应类似于 $[[b_{1,1},b_{1,2},b_{1,3}],[b_{2,1},b_{2,2},b_{2,3}],\\ldots]$，其中每个 $b_{i,j}$ 都四舍五入到小数点后 $6$ 位。", "solution": "该问题要求推导并实现一个函数 $B(g)$，该函数用于量化聚合酶链式反应 (PCR) 中预期的覆盖度偏倚，此偏倚是局部鸟嘌呤-胞嘧啶 (GC) 分数 $g$ 的函数。推导必须根据问题陈述中定义的第一性原理进行。\n\n分析以自下而上的方式进行，从模型最基本的组成部分开始，系统地将它们组合起来，以得出偏倚 $B(g)$ 的最终表达式。\n\n**1. 引物结合的吉布斯自由能, $\\Delta G(g)$**\n\nPCR 扩增的初始步骤是引物与其靶标模板链的杂交。这种结合的稳定性由标准吉布斯自由能变 $\\Delta G$ 决定。问题提供了一个粗粒度的 $\\Delta G$ 线性模型，该模型依赖于引物结合位点的局部 GC 分数 $g$。\n\n对于长度为 $L_p$、局部 GC 分数为 $g \\in [0,1]$ 的引物，其自由能由下式给出：\n$$\n\\Delta G(g) = L_p\\big[g\\,\\delta g_{\\mathrm{GC}} + (1-g)\\,\\delta g_{\\mathrm{AT}}\\big] + \\delta g_{\\mathrm{init}}\n$$\n此处，$\\delta g_{\\mathrm{GC}}$ 和 $\\delta g_{\\mathrm{AT}}$ 分别是每个 GC 和腺嘌呤-胸腺嘧啶 (AT) 碱基对的平均自由能贡献，而 $\\delta g_{\\mathrm{init}}$ 是一个常数，代表起始杂交的能量成本。单位是千卡/摩尔 ($kcal \\cdot mol^{-1}$) 。\n\n**2. 平衡解离常数, $K_d(g)$**\n\n吉布斯自由能通过以下基本热力学关系与平衡解离常数 $K_d$ 相关联：\n$$\nK_d(g) = \\exp\\left(\\frac{\\Delta G(g)}{R T}\\right)\n$$\n其中 $R$ 是普适气体常数 ($1.987 \\times 10^{-3} \\, \\mathrm{kcal} \\cdot \\mathrm{mol}^{-1} \\cdot \\mathrm{K}^{-1}$)，$T$ 是以开尔文 (K) 为单位的绝对温度。更负的 $\\Delta G$ 会导致更小的 $K_d$，表示更强的结合。\n\n**3. 结合引物的分数, $f_{\\mathrm{bind}}(g)$**\n\n利用单一位点结合模型的质量作用动力学原理，在平衡状态下，与引物结合的靶 DNA 分子的分数 $f_{\\mathrm{bind}}$ 是引物浓度 $C_p$ 和解离常数 $K_d$ 的函数。\n$$\nf_{\\mathrm{bind}}(g) = \\frac{C_p}{C_p + K_d(g)}\n$$\n代入 $K_d(g)$ 的表达式，得到依赖于 GC 的结合引物分数：\n$$\nf_{\\mathrm{bind}}(g) = \\frac{C_p}{C_p + \\exp\\left(\\frac{\\Delta G(g)}{R T}\\right)}\n$$\n该项代表引物退火步骤的效率。\n\n**4. 聚合酶延伸概率, $p_{\\mathrm{ext}}(g)$**\n\n一旦引物结合，DNA 聚合酶必须将其延伸，以创建扩增子的全长拷贝。该模型假设了一个依赖于 GC 的、每碱基的脱落概率 $p_{\\mathrm{drop}}(g)$。这个唯象模型假设了一个线性关系：\n$$\np_{\\mathrm{drop, raw}}(g) = p_0\\big[1 + \\beta\\,(g - 0.5)\\big]\n$$\n其中 $p_0$ 是在 GC 含量为中性值 $g=0.5$ 时的基线脱落概率，而 $\\beta$ 是一个调节 GC 依赖性的系数。由于概率必须在区间 $[0,1]$ 内，这个原始值被裁剪：\n$$\np_{\\mathrm{drop}}(g) = \\mathrm{clip}\\big(p_{\\mathrm{drop, raw}}(g), [0, 1)\\big)\n$$\n聚合酶在给定碱基处*不*脱落的概率（延续概率）是 $q(g) = 1 - p_{\\mathrm{drop}}(g)$。为了让聚合酶成功合成一个长度为 $L_{\\mathrm{ext}}$ 的完整扩增子，它在 $L_{\\mathrm{ext}}$ 个碱基中的任何一个都不能脱落。假设这是一个无记忆的伯努利过程，该概率为：\n$$\np_{\\mathrm{ext}}(g) = \\big(q(g)\\big)^{L_{\\mathrm{ext}}} = \\left(1 - p_{\\mathrm{drop}}(g)\\right)^{L_{\\mathrm{ext}}}\n$$\n该项代表聚合酶延伸步骤的效率。\n\n**5. 每循环扩增因子, $F(g)$**\n\n一个 PCR 循环理想情况下会使 DNA 量加倍。然而，结合和延伸过程中的低效率会降低产量。一个循环中的预期倍数变化 $F(g)$ 建模为：\n$$\nF(g) = 1 + f_{\\mathrm{bind}}(g) \\cdot p_{\\mathrm{ext}}(g)\n$$\n项“1”代表原始模板分子，而乘积 $f_{\\mathrm{bind}}(g) \\cdot p_{\\mathrm{ext}}(g)$ 代表成功转化为新拷贝的模板分数。该因子界于 $[1, 2]$ 之间。\n\n**6. 累积覆盖度偏倚, $B(g)$**\n\n经过 $C$ 个 PCR 循环后，GC 分数为 $g$ 的初始分子数量被放大 $(F(g))^C$ 倍。覆盖度偏倚 $B(g)$ 定义为 GC 分数为 $g$ 的区域相对于 GC 分数为 $g_{\\mathrm{ref}}$ 的参考区域的扩增率。\n$$\nB(g) = \\frac{(F(g))^C}{(F(g_{\\mathrm{ref}}))^C} = \\left(\\frac{F(g)}{F(g_{\\mathrm{ref}})}\\right)^C\n$$\n\n**7. 最终闭式表达式**\n\n通过代入推导出的各个组成部分，我们得到覆盖度偏倚 $B(g)$ 的完整表达式：\n$$\nB(g) = \\left( \\frac{1 + f_{\\mathrm{bind}}(g) \\cdot p_{\\mathrm{ext}}(g)}{1 + f_{\\mathrm{bind}}(g_{\\mathrm{ref}}) \\cdot p_{\\mathrm{ext}}(g_{\\mathrm{ref}})} \\right)^C\n$$\n其中：\n- $f_{\\mathrm{bind}}(x) = \\dfrac{C_p}{C_p + \\exp\\left(\\dfrac{L_p[x\\,\\delta g_{\\mathrm{GC}} + (1-x)\\,\\delta g_{\\mathrm{AT}}] + \\delta g_{\\mathrm{init}}}{R T}\\right)}$\n- $p_{\\mathrm{ext}}(x) = \\left(1 - \\mathrm{clip}\\left(p_0[1 + \\beta(x - 0.5)], [0, 1)\\right)\\right)^{L_{\\mathrm{ext}}}$\n\n这个最终表达式包含了所有指定的参数 $\\{L_p, L_{\\mathrm{ext}}, \\delta g_{\\mathrm{GC}}, \\delta g_{\\mathrm{AT}}, \\delta g_{\\mathrm{init}}, T, C_p, p_0, \\beta, C, g_{\\mathrm{ref}}, R\\}$，并且可以通过计算实现。\n\n从测试用例中提供的参数值可以得出一个值得注意的观察结果。$\\delta g_{\\mathrm{GC}}$ 和 $\\delta g_{\\mathrm{AT}}$ 的值是强负值，导致了高度有利（非常负）的 $\\Delta G$ 值。这导致了极小的解离常数 $K_d$，以至于在很宽的条件下都有 $K_d \\ll C_p$。因此，引物结合分数 $f_{\\mathrm{bind}}(g)$ 在几个测试用例中实际上饱和在 1.0，包括被描述为“低引物浓度和高温”的案例2。在这种情况下，覆盖度偏倚完全由聚合酶持续合成能力 $p_{\\mathrm{ext}}(g)$ 的差异主导，而不是结合和持续合成效应的组合。虽然该问题定义明确且可按所述解决，但这种参数化旨在分离两种建模偏倚来源中的一种。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the PCR bias problem for all test cases.\n    \"\"\"\n\n    # Universal gas constant in kcal mol^-1 K^-1\n    R = 1.987e-3\n\n    test_cases = [\n        {\n            \"name\": \"Test Case 1 (happy path)\",\n            \"params\": {\n                \"L_p\": 20, \"L_ext\": 300, \"delta_g_GC\": -2.5, \"delta_g_AT\": -1.0, \n                \"delta_g_init\": 1.0, \"T\": 333, \"C_p_nM\": 250, \"p_0\": 0.005, \n                \"beta\": 0.8, \"C\": 15, \"g_ref\": 0.5\n            },\n            \"gc_fractions\": [0.2, 0.5, 0.8]\n        },\n        {\n            \"name\": \"Test Case 2 (low primer concentration and high temperature)\",\n            \"params\": {\n                \"L_p\": 20, \"L_ext\": 300, \"delta_g_GC\": -2.5, \"delta_g_AT\": -1.0, \n                \"delta_g_init\": 1.0, \"T\": 343, \"C_p_nM\": 1, \"p_0\": 0.005, \n                \"beta\": 0.8, \"C\": 15, \"g_ref\": 0.5\n            },\n            \"gc_fractions\": [0.2, 0.5, 0.8]\n        },\n        {\n            \"name\": \"Test Case 3 (strong GC-dependent drop-off, including extreme GC bounds)\",\n            \"params\": {\n                \"L_p\": 20, \"L_ext\": 300, \"delta_g_GC\": -2.5, \"delta_g_AT\": -1.0, \n                \"delta_g_init\": 1.0, \"T\": 333, \"C_p_nM\": 250, \"p_0\": 0.005, \n                \"beta\": 2.0, \"C\": 15, \"g_ref\": 0.5\n            },\n            \"gc_fractions\": [0.0, 0.5, 1.0]\n        },\n        {\n            \"name\": \"Test Case 4 (long amplicon with elevated drop-off and more cycles)\",\n            \"params\": {\n                \"L_p\": 20, \"L_ext\": 1000, \"delta_g_GC\": -2.5, \"delta_g_AT\": -1.0, \n                \"delta_g_init\": 1.0, \"T\": 333, \"C_p_nM\": 250, \"p_0\": 0.010, \n                \"beta\": 0.8, \"C\": 20, \"g_ref\": 0.5\n            },\n            \"gc_fractions\": [0.2, 0.5, 0.8]\n        }\n    ]\n\n    all_results = []\n\n    def calculate_F(g, L_p, L_ext, delta_g_GC, delta_g_AT, delta_g_init, T, C_p_M, p_0, beta):\n        \"\"\"Calculates the per-cycle amplification factor F(g).\"\"\"\n        \n        # 1. Gibbs Free Energy of Primer Binding, delta_G(g)\n        delta_G = L_p * (g * delta_g_GC + (1 - g) * delta_g_AT) + delta_g_init\n        \n        # 2. Equilibrium Dissociation Constant, K_d(g)\n        K_d = np.exp(delta_G / (R * T))\n        \n        # 3. Fraction of Bound Primers, f_bind(g)\n        f_bind = C_p_M / (C_p_M + K_d)\n        \n        # 4. Polymerase Extension Probability, p_ext(g)\n        # The problem states clipping to [0,1). In floating point arithmetic,\n        # an upper bound of 1.0 is acceptable for np.clip.\n        p_drop_raw = p_0 * (1 + beta * (g - 0.5))\n        p_drop = np.clip(p_drop_raw, 0.0, 1.0)\n        q = 1.0 - p_drop\n        p_ext = q**L_ext\n        \n        # 5. Per-Cycle Amplification Factor, F(g)\n        F_g = 1.0 + f_bind * p_ext\n        \n        return F_g\n\n    for case in test_cases:\n        params = case[\"params\"]\n        gc_fractions = case[\"gc_fractions\"]\n        \n        # Convert primer concentration from nM to M\n        C_p_M = params[\"C_p_nM\"] * 1e-9\n        \n        # Calculate F for the reference GC fraction\n        F_g_ref = calculate_F(\n            g=params[\"g_ref\"],\n            L_p=params[\"L_p\"],\n            L_ext=params[\"L_ext\"],\n            delta_g_GC=params[\"delta_g_GC\"],\n            delta_g_AT=params[\"delta_g_AT\"],\n            delta_g_init=params[\"delta_g_init\"],\n            T=params[\"T\"],\n            C_p_M=C_p_M,\n            p_0=params[\"p_0\"],\n            beta=params[\"beta\"]\n        )\n        \n        case_results = []\n        for g in gc_fractions:\n            # Calculate F for the current GC fraction\n            F_g = calculate_F(\n                g=g,\n                L_p=params[\"L_p\"],\n                L_ext=params[\"L_ext\"],\n                delta_g_GC=params[\"delta_g_GC\"],\n                delta_g_AT=params[\"delta_g_AT\"],\n                delta_g_init=params[\"delta_g_init\"],\n                T=params[\"T\"],\n                C_p_M=C_p_M,\n                p_0=params[\"p_0\"],\n                beta=params[\"beta\"]\n            )\n            \n            # 6. Cumulative Coverage Bias, B(g)\n            if F_g_ref == 0:\n                # Avoid division by zero, though unlikely with F(g) >= 1\n                bias = np.inf if F_g > 0 else 1.0\n            else:\n                bias = (F_g / F_g_ref)**params[\"C\"]\n            \n            case_results.append(bias)\n\n        all_results.append(case_results)\n\n    # Format the final output string exactly as required\n    formatted_results = []\n    for res_list in all_results:\n        # Round each result to 6 decimal places and format as a string\n        formatted_list = [f\"{r:.6f}\" for r in res_list]\n        formatted_results.append(f\"[{','.join(formatted_list)}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3310818"}, {"introduction": "在了解了文库制备中的潜在偏差后，我们现在将目光投向测序仪本身。现代测序仪并非直接“读取”DNA碱基，而是测量与每个碱基掺入相关的物理信号，例如荧光强度。本练习将揭开“碱基识别”（base calling）这一关键过程的神秘面纱，你将通过一个概率模型，学习如何将这些充满噪声的模拟信号转化为离散的数字碱基（$A$, $C$, $G$, $T$）及其对应的置信度分数（Phred分值）。", "problem": "给定一个用于“边合成边测序”信号的概率模型，该模型针对一个四通道Illumina系统。在系统中，每个测序循环会发出一个强度向量，该向量位于与核苷酸腺嘌呤(A)、胞嘧啶(C)、鸟嘌呤(G)和胸腺嘧啶(T)相对应的通道空间中。在循环索引为$i$时，观测到的强度向量表示为$\\mathbf{y}_i \\in \\mathbb{R}^4$，每个循环的标量缩放因子为$s_i \\in \\mathbb{R}_{\\ge 0}$，背景基线向量为$\\boldsymbol{\\beta} \\in \\mathbb{R}^4$，各通道的噪声方差汇集在对角协方差矩阵$\\operatorname{diag}(\\boldsymbol{\\sigma}^2)$中，其中$\\boldsymbol{\\sigma}^2 \\in \\mathbb{R}^4_{>0}$。校准（串扰）矩阵$\\mathbf{C} \\in \\mathbb{R}^{4 \\times 4}$将一个one-hot碱基向量映射到预期的归一化通道均值，使得对于碱基$b \\in \\{A,C,G,T\\}$，预期的平均强度是列向量$\\boldsymbol{\\mu}_b = \\mathbf{C}_{:,b}$。生成信号模型由缩放后的均值、基线以及加性噪声之和给出：\n$$\n\\mathbf{y}_i = s_i \\boldsymbol{\\mu}_b + \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}_i, \\quad \\boldsymbol{\\varepsilon}_i \\sim \\mathcal{N}\\!\\left(\\mathbf{0}, \\operatorname{diag}(\\boldsymbol{\\sigma}^2)\\right).\n$$\n假设通道噪声是独立且服从高斯分布的，并且在给定每个循环的碱基的条件下，各循环之间是独立的。碱基的先验概率集合为$\\mathbf{p} = [p(A),p(C),p(G),p(T)]$，其中$p(A)+p(C)+p(G)+p(T)=1$且对于每个碱基$b$都有$p(b)>0$。\n\n您的任务是为每个循环$i$计算：\n1. 最大似然碱基判读，定义为在所述高斯模型下，使似然$p(\\mathbf{y}_i \\mid b)$最大化的碱基$\\hat{b}_i$。如果在容忍度阈值$\\tau$内出现相等的情况，则选择在字典顺序$A \\rightarrow 0$、$C \\rightarrow 1$、$G \\rightarrow 2$、$T \\rightarrow 3$中索引最小的碱基。\n2. 所选碱基判读的Phred质量得分$Q_i$，由后验错误概率通过标准转换定义：\n$$\nQ_i = -10 \\log_{10}\\!\\left(P_{\\text{err},i}\\right),\n$$\n其中$P_{\\text{err},i} = 1 - P(\\hat{b}_i \\mid \\mathbf{y}_i)$，而$P(b \\mid \\mathbf{y}_i)$是使用贝叶斯定理，结合所提供的先验概率$\\mathbf{p}$和上述生成模型所隐含的高斯似然$p(\\mathbf{y}_i \\mid b)$来计算的。请使用数值稳定的方法计算概率，当$P_{\\text{err},i}$在数值上为零时，将其视为$10^{-300}$以避免未定义的对数。所有质量得分都表示为四舍五入到两位小数的浮点数。\n\n碱基索引如下：$A \\rightarrow 0$，$C \\rightarrow 1$，$G \\rightarrow 2$，$T \\rightarrow 3$。在本问题中，强度没有物理单位。\n\n请实现一个完整的程序，给定以下参数集测试套件，生成指定的输出。对于每个测试用例，输出一个包含两个列表的对：第一个列表包含每个循环的碱基判读结果（以$\\{0,1,2,3\\}$中的整数表示），第二个列表包含相应的$Q$-score（以四舍五入到两位小数的浮点数表示）。将所有提供的测试用例的结果聚合到单行中，形式为一个包含在方括号内的逗号分隔列表，其中顶层列表的每个元素对应一个测试用例，并且本身是一个如上所述的双元素列表。\n\n对所有测试用例使用相等容忍度$\\tau = 10^{-12}$。\n\n测试套件：\n- 测试用例1（理想路径，低噪声）：\n  - 校准矩阵：\n    $$\n    \\mathbf{C}^{(1)} = \\begin{bmatrix}\n    1.0  0.1  0.1  0.1 \\\\\n    0.1  1.0  0.1  0.1 \\\\\n    0.1  0.1  1.0  0.1 \\\\\n    0.1  0.1  0.1  1.0\n    \\end{bmatrix}.\n    $$\n  - 方差：$\\boldsymbol{\\sigma}^{2\\,(1)} = [0.05, 0.05, 0.05, 0.05]$。\n  - 基线：$\\boldsymbol{\\beta}^{(1)} = [0.0, 0.0, 0.0, 0.0]$。\n  - 每个循环的缩放因子：$\\mathbf{s}^{(1)} = [1.0, 1.0, 1.0, 1.0, 1.0]$。\n  - 先验概率：$\\mathbf{p}^{(1)} = [0.25, 0.25, 0.25, 0.25]$。\n  - 观测值：\n    $$\n    \\mathbf{Y}^{(1)} = \\begin{bmatrix}\n    1.20  0.10  0.10  0.10 \\\\\n    0.10  1.10  0.10  0.10 \\\\\n    0.20  0.10  1.30  0.10 \\\\\n    0.10  0.10  0.10  1.25 \\\\\n    0.30  0.20  0.90  0.20\n    \\end{bmatrix}.\n    $$\n- 测试用例2（高噪声，模糊信号）：\n  - 校准矩阵：\n    $$\n    \\mathbf{C}^{(2)} = \\begin{bmatrix}\n    1.0  0.1  0.1  0.1 \\\\\n    0.1  1.0  0.1  0.1 \\\\\n    0.1  0.1  1.0  0.1 \\\\\n    0.1  0.1  0.1  1.0\n    \\end{bmatrix}.\n    $$\n  - 方差：$\\boldsymbol{\\sigma}^{2\\,(2)} = [0.5, 0.5, 0.5, 0.5]$。\n  - 基线：$\\boldsymbol{\\beta}^{(2)} = [0.0, 0.0, 0.0, 0.0]$。\n  - 每个循环的缩放因子：$\\mathbf{s}^{(2)} = [1.0, 1.0, 1.0]$。\n  - 先验概率：$\\mathbf{p}^{(2)} = [0.25, 0.25, 0.25, 0.25]$。\n  - 观测值：\n    $$\n    \\mathbf{Y}^{(2)} = \\begin{bmatrix}\n    0.50  0.50  0.50  0.50 \\\\\n    0.60  0.50  0.50  0.40 \\\\\n    0.50  0.40  0.60  0.50\n    \\end{bmatrix}.\n    $$\n- 测试用例3（非均匀先验，异构校准和方差）：\n  - 校准矩阵：\n    $$\n    \\mathbf{C}^{(3)} = \\begin{bmatrix}\n    0.9  0.2  0.2  0.2 \\\\\n    0.2  0.9  0.3  0.2 \\\\\n    0.2  0.3  0.9  0.2 \\\\\n    0.2  0.2  0.2  0.9\n    \\end{bmatrix}.\n    $$\n  - 方差：$\\boldsymbol{\\sigma}^{2\\,(3)} = [0.1, 0.2, 0.1, 0.2]$。\n  - 基线：$\\boldsymbol{\\beta}^{(3)} = [0.05, 0.05, 0.05, 0.05]$。\n  - 每个循环的缩放因子：$\\mathbf{s}^{(3)} = [1.0, 0.8, 1.2]$。\n  - 先验概率：$\\mathbf{p}^{(3)} = [0.10, 0.40, 0.40, 0.10]$。\n  - 观测值：\n    $$\n    \\mathbf{Y}^{(3)} = \\begin{bmatrix}\n    0.95  0.13  0.10  0.10 \\\\\n    0.20  0.75  0.30  0.20 \\\\\n    0.20  0.25  1.10  0.20\n    \\end{bmatrix}.\n    $$\n- 测试用例4（边界情况：零强度，低噪声）：\n  - 校准矩阵：\n    $$\n    \\mathbf{C}^{(4)} = \\begin{bmatrix}\n    1.0  0.1  0.1  0.1 \\\\\n    0.1  1.0  0.1  0.1 \\\\\n    0.1  0.1  1.0  0.1 \\\\\n    0.1  0.1  0.1  1.0\n    \\end{bmatrix}.\n    $$\n  - 方差：$\\boldsymbol{\\sigma}^{2\\,(4)} = [0.05, 0.05, 0.05, 0.05]$。\n  - 基线：$\\boldsymbol{\\beta}^{(4)} = [0.0, 0.0, 0.0, 0.0]$。\n  - 每个循环的缩放因子：$\\mathbf{s}^{(4)} = [1.0, 1.0]$。\n  - 先验概率：$\\mathbf{p}^{(4)} = [0.25, 0.25, 0.25, 0.25]$。\n  - 观测值：\n    $$\n    \\mathbf{Y}^{(4)} = \\begin{bmatrix}\n    0.00  0.00  0.00  0.00 \\\\\n    0.00  0.00  0.00  0.00\n    \\end{bmatrix}.\n    $$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。列表中的每个元素对应一个测试用例，并且本身也是一个双元素列表：第一个列表包含每个循环的整数碱基判读结果（使用映射$A \\rightarrow 0$、$C \\rightarrow 1$、$G \\rightarrow 2$、$T \\rightarrow 3$），第二个列表包含每个循环对应的Phred质量得分（四舍五入到两位小数）。例如，输出格式必须是\n$$\n[\\,[\\,[\\text{calls}^{(1)}],\\,[\\text{qscores}^{(1)}]\\,],\\,\\ldots,\\,[\\,[\\text{calls}^{(4)}],\\,[\\text{qscores}^{(4)}]\\,]\\,].\n$$", "solution": "该问题要求为一个简化的四通道“边合成边测序”系统实现一个统计碱基判读算法。我们需要确定每个测序循环中最可能的DNA碱基，并使用Phred质量得分来量化该判读的置信度。这将通过将概率论原理，特别是最大似然估计和贝叶斯推断，应用于所提供的生成信号模型来完成。\n\n对于每个循环$i$，过程涉及两个主要计算：\n1.  **最大似然（ML）碱基判读**：找到最可能生成观测强度向量$\\mathbf{y}_i$的碱基$\\hat{b}_i$。\n2.  **Phred质量得分（$Q_i$）计算**：基于其后验错误概率，为判读$\\hat{b}_i$计算一个质量得分。\n\n我们将基于基本原理分析每个步骤。\n\n**原理1：高斯信号模型与似然**\n\n对于给定的碱基$b \\in \\{A,C,G,T\\}$，在循环$i$观测到的强度向量$\\mathbf{y}_i \\in \\mathbb{R}^4$的生成模型为：\n$$\n\\mathbf{y}_i = s_i \\boldsymbol{\\mu}_b + \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}_i, \\quad \\boldsymbol{\\varepsilon}_i \\sim \\mathcal{N}\\!\\left(\\mathbf{0}, \\operatorname{diag}(\\boldsymbol{\\sigma}^2)\\right)\n$$\n其中$\\boldsymbol{\\mu}_b$是校准矩阵$\\mathbf{C}$中对应于碱基$b$的列。该方程表明，观测到的信号是一个缩放后的理想信号$s_i \\boldsymbol{\\mu}_b$、一个恒定的背景基线$\\boldsymbol{\\beta}$以及加性高斯噪声$\\boldsymbol{\\varepsilon}_i$的和。\n\n该模型意味着，在给定碱基$b$的条件下观测到$\\mathbf{y}_i$的条件概率遵循一个多元正态分布：\n$$\n\\mathbf{y}_i \\mid b \\sim \\mathcal{N}\\!\\left(s_i \\boldsymbol{\\mu}_b + \\boldsymbol{\\beta}, \\operatorname{diag}(\\boldsymbol{\\sigma}^2)\\right)\n$$\n作为似然$p(\\mathbf{y}_i \\mid b)$的概率密度函数（PDF）为：\n$$\np(\\mathbf{y}_i \\mid b) = \\frac{1}{\\sqrt{(2\\pi)^4 \\det(\\operatorname{diag}(\\boldsymbol{\\sigma}^2))}} \\exp\\left(-\\frac{1}{2} (\\mathbf{y}_i - (s_i \\boldsymbol{\\mu}_b + \\boldsymbol{\\beta}))^T (\\operatorname{diag}(\\boldsymbol{\\sigma}^2))^{-1} (\\mathbf{y}_i - (s_i \\boldsymbol{\\mu}_b + \\boldsymbol{\\beta}))\\right)\n$$\n由于噪声协方差矩阵$\\boldsymbol{\\Sigma} = \\operatorname{diag}(\\boldsymbol{\\sigma}^2)$是对角矩阵，所以各通道是独立的。指数的参数，即马氏距离的平方，简化为加权平方误差和（WSSE）：\n$$\n\\chi^2(\\mathbf{y}_i, b) = \\sum_{j=0}^{3} \\frac{(y_{i,j} - (s_i C_{j,b} + \\beta_j))^2}{\\sigma_j^2}\n$$\n其中碱基索引$b$映射到$\\mathbf{C}$的相应列，而$j \\in \\{0,1,2,3\\}$索引四个通道。\n\n**原理2：最大似然碱基判读**\n\nML碱基判读$\\hat{b}_i$是使似然函数最大化的碱基：\n$$\n\\hat{b}_i = \\arg\\max_{b \\in \\{A,C,G,T\\}} p(\\mathbf{y}_i \\mid b)\n$$\n最大化似然$p(\\mathbf{y}_i \\mid b)$等同于最大化其自然对数$\\ln p(\\mathbf{y}_i \\mid b)$，后者在计算上更为稳定。\n$$\n\\ln p(\\mathbf{y}_i \\mid b) = -\\frac{1}{2} \\sum_{j=0}^{3} \\ln(2\\pi \\sigma_j^2) - \\frac{1}{2} \\sum_{j=0}^{3} \\frac{(y_{i,j} - (s_i C_{j,b} + \\beta_j))^2}{\\sigma_j^2}\n$$\n由于第一项相对于碱基$b$是常数，因此最大化对数似然等同于最小化WSSE项$\\chi^2(\\mathbf{y}_i, b)$。\n\nML碱基判读的算法如下：\n1.  对于每个循环$i$和四个碱基中的每一个$b$，计算对数似然$\\ln p(\\mathbf{y}_i \\mid b)$。\n2.  将对数似然转换为线性尺度的似然值：$L_b = \\exp(\\ln p(\\mathbf{y}_i \\mid b))$。\n3.  找到最大似然值，$L_{max} = \\max_{b} L_b$。\n4.  识别候选碱基集合$S_{cand} = \\{ b \\mid L_{max} - L_b  \\tau \\}$，其中$\\tau=10^{-12}$是给定的容忍度。\n5.  最终的碱基判读$\\hat{b}_i$是$S_{cand}$中具有最小字典索引（$A \\rightarrow 0, C \\rightarrow 1, G \\rightarrow 2, T \\rightarrow 3$）的碱基。\n\n**原理3：贝叶斯推断与Phred质量得分**\n\nPhred质量得分$Q_i$源自后验错误概率$P_{\\text{err},i}$。为了计算这个值，我们首先需要给定观测值$\\mathbf{y}_i$时每个碱基$b$的后验概率，记为$P(b \\mid \\mathbf{y}_i)$。使用贝叶斯定理：\n$$\nP(b \\mid \\mathbf{y}_i) = \\frac{p(\\mathbf{y}_i \\mid b) p(b)}{p(\\mathbf{y}_i)} = \\frac{p(\\mathbf{y}_i \\mid b) p(b)}{\\sum_{b'} p(\\mathbf{y}_i \\mid b') p(b')}\n$$\n其中$p(b)$是给定的每个碱基的先验概率，分母是边际似然（证据），一个确保后验概率总和为1的归一化常数。\n\n判读$\\hat{b}_i$的后验错误概率是真实碱基为任何其他碱基的概率：\n$$\nP_{\\text{err},i} = P(\\text{base} \\neq \\hat{b}_i \\mid \\mathbf{y}_i) = 1 - P(\\hat{b}_i \\mid \\mathbf{y}_i) = \\sum_{b \\neq \\hat{b}_i} P(b \\mid \\mathbf{y}_i)\n$$\n然后Phred得分定义为：\n$$\nQ_i = -10 \\log_{10}(P_{\\text{err},i})\n$$\n\n**原理4：数值稳定的计算**\n\n直接计算似然和后验概率可能导致数值下溢，因为这些值可能非常小。标准做法是在对数空间中进行计算。令$\\lambda_b = \\ln(p(\\mathbf{y}_i \\mid b) p(b)) = \\ln p(\\mathbf{y}_i \\mid b) + \\ln p(b)$为对数联合概率。后验概率的对数为：\n$$\n\\ln P(b \\mid \\mathbf{y}_i) = \\lambda_b - \\ln\\left(\\sum_{b'} \\exp(\\lambda_{b'})\\right)\n$$\n求和项使用log-sum-exp技巧进行稳定计算。令$\\lambda_{max} = \\max_{b'} \\lambda_{b'}$。那么：\n$$\n\\ln\\left(\\sum_{b'} \\exp(\\lambda_{b'})\\right) = \\lambda_{max} + \\ln\\left(\\sum_{b'} \\exp(\\lambda_{b'} - \\lambda_{max})\\right)\n$$\n这可以避免指数运算中的上溢和求和中的下溢。一旦计算出对数后验概率$\\ln P(b \\mid \\mathbf{y}_i)$，我们就可以求得$P(\\hat{b}_i \\mid \\mathbf{y}_i) = \\exp(\\ln P(\\hat{b}_i \\mid \\mathbf{y}_i))$，并随后求得$P_{\\text{err},i}$。问题规定，如果$P_{\\text{err},i}$在数值上为零，应将其视为$10^{-300}$，以防止在计算$Q_i$时出现未定义的对数。\n\n通过结合这些原理，我们可以构建一个算法来处理提供的测试套件，并生成所需的碱基判读和质量得分。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the DNA sequencing base calling problem for all test cases.\n    \"\"\"\n    \n    # Base mapping and problem constants\n    base_map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n    bases = ['A', 'C', 'G', 'T']\n    num_bases = 4\n    tau = 1e-12\n    p_err_floor = 1e-300\n\n    # Test Suite\n    test_cases = [\n        # Test case 1\n        {\n            \"C\": np.array([\n                [1.0, 0.1, 0.1, 0.1],\n                [0.1, 1.0, 0.1, 0.1],\n                [0.1, 0.1, 1.0, 0.1],\n                [0.1, 0.1, 0.1, 1.0]\n            ]),\n            \"sigma_sq\": np.array([0.05, 0.05, 0.05, 0.05]),\n            \"beta\": np.array([0.0, 0.0, 0.0, 0.0]),\n            \"s\": np.array([1.0, 1.0, 1.0, 1.0, 1.0]),\n            \"p\": np.array([0.25, 0.25, 0.25, 0.25]),\n            \"Y\": np.array([\n                [1.20, 0.10, 0.10, 0.10],\n                [0.10, 1.10, 0.10, 0.10],\n                [0.20, 0.10, 1.30, 0.10],\n                [0.10, 0.10, 0.10, 1.25],\n                [0.30, 0.20, 0.90, 0.20]\n            ])\n        },\n        # Test case 2\n        {\n            \"C\": np.array([\n                [1.0, 0.1, 0.1, 0.1],\n                [0.1, 1.0, 0.1, 0.1],\n                [0.1, 0.1, 1.0, 0.1],\n                [0.1, 0.1, 0.1, 1.0]\n            ]),\n            \"sigma_sq\": np.array([0.5, 0.5, 0.5, 0.5]),\n            \"beta\": np.array([0.0, 0.0, 0.0, 0.0]),\n            \"s\": np.array([1.0, 1.0, 1.0]),\n            \"p\": np.array([0.25, 0.25, 0.25, 0.25]),\n            \"Y\": np.array([\n                [0.50, 0.50, 0.50, 0.50],\n                [0.60, 0.50, 0.50, 0.40],\n                [0.50, 0.40, 0.60, 0.50]\n            ])\n        },\n        # Test case 3\n        {\n            \"C\": np.array([\n                [0.9, 0.2, 0.2, 0.2],\n                [0.2, 0.9, 0.3, 0.2],\n                [0.2, 0.3, 0.9, 0.2],\n                [0.2, 0.2, 0.2, 0.9]\n            ]),\n            \"sigma_sq\": np.array([0.1, 0.2, 0.1, 0.2]),\n            \"beta\": np.array([0.05, 0.05, 0.05, 0.05]),\n            \"s\": np.array([1.0, 0.8, 1.2]),\n            \"p\": np.array([0.10, 0.40, 0.40, 0.10]),\n            \"Y\": np.array([\n                [0.95, 0.13, 0.10, 0.10],\n                [0.20, 0.75, 0.30, 0.20],\n                [0.20, 0.25, 1.10, 0.20]\n            ])\n        },\n        # Test case 4\n        {\n            \"C\": np.array([\n                [1.0, 0.1, 0.1, 0.1],\n                [0.1, 1.0, 0.1, 0.1],\n                [0.1, 0.1, 1.0, 0.1],\n                [0.1, 0.1, 0.1, 1.0]\n            ]),\n            \"sigma_sq\": np.array([0.05, 0.05, 0.05, 0.05]),\n            \"beta\": np.array([0.0, 0.0, 0.0, 0.0]),\n            \"s\": np.array([1.0, 1.0]),\n            \"p\": np.array([0.25, 0.25, 0.25, 0.25]),\n            \"Y\": np.array([\n                [0.00, 0.00, 0.00, 0.00],\n                [0.00, 0.00, 0.00, 0.00]\n            ])\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        C, sigma_sq, beta, s_vec, p, Y = case[\"C\"], case[\"sigma_sq\"], case[\"beta\"], case[\"s\"], case[\"p\"], case[\"Y\"]\n        \n        calls_per_case = []\n        qscores_per_case = []\n        \n        num_cycles = Y.shape[0]\n        \n        log_priors = np.log(p)\n        log_likelihood_const = -0.5 * np.sum(np.log(2 * np.pi * sigma_sq))\n\n        for i in range(num_cycles):\n            y_i = Y[i, :]\n            s_i = s_vec[i]\n            \n            log_likelihoods = np.zeros(num_bases)\n            \n            for b_idx in range(num_bases):\n                mu_b = C[:, b_idx]\n                expected_mean = s_i * mu_b + beta\n                \n                # Calculate WSSE (chi-squared)\n                wsse = np.sum(((y_i - expected_mean)**2) / sigma_sq)\n                \n                # Log likelihood\n                log_likelihoods[b_idx] = log_likelihood_const - 0.5 * wsse\n            \n            # --- Maximum Likelihood Base Call ---\n            likelihoods = np.exp(log_likelihoods)\n            max_likelihood = np.max(likelihoods)\n            tied_indices = np.where(max_likelihood - likelihoods  tau)[0]\n            ml_base_call = np.min(tied_indices)\n            calls_per_case.append(ml_base_call)\n            \n            # --- Phred Quality Score Calculation ---\n            # Log joint probabilities\n            log_joint = log_likelihoods + log_priors\n            \n            # Log-sum-exp for normalization\n            log_joint_max = np.max(log_joint)\n            log_marginal = log_joint_max + np.log(np.sum(np.exp(log_joint - log_joint_max)))\n            \n            # Log posteriors\n            log_posteriors = log_joint - log_marginal\n            posteriors = np.exp(log_posteriors)\n            \n            p_correct = posteriors[ml_base_call]\n            p_err = 1.0 - p_correct\n            \n            # Handle numerical zero\n            if p_err = p_err_floor:\n                p_err = p_err_floor\n            \n            q_score = -10 * np.log10(p_err)\n            qscores_per_case.append(round(q_score, 2))\n            \n        all_results.append([calls_per_case, qscores_per_case])\n\n    # Format the final output string\n    result_strings = []\n    for calls, qscores in all_results:\n        calls_str = f\"[{','.join(map(str, calls))}]\"\n        qscores_str = f\"[{','.join([f'{q:.2f}' for q in qscores])}]\"\n        result_strings.append(f\"[{calls_str},{qscores_str}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3310871"}, {"introduction": "一旦原始信号被转换成带有质量分数的测序读段（reads），下一步的核心任务通常是确定它们在参考基因组中的来源位置，这一过程称为读段比对（read mapping）。面对数以亿计的读段和庞大的基因组，这是一个巨大的计算挑战。本练习将让你亲手实现现代比对算法的核心思想——“种子-延伸”（seed-and-extend）策略，并利用高效的数据结构FM索引来加速种子搜索，从而深入理解如何高效地解决这个海量搜索问题。", "problem": "给定一个参考脱氧核糖核酸（DNA）字符串，要求您使用 Ferragina–Manzini (FM) 索引实现一个符合原理的种子延伸候选比对位置枚举器。任务是为每个提供的读段计算其在参考序列中的所有候选起始位置，在满足由精确种子匹配约束定义的种子过滤条件下，该读段在这些位置上与参考序列的比对最多允许 $k$ 个错配。\n\n需要使用的基本基础和定义：\n- DNA 被建模为一个基于字母表 $\\Sigma = \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$ 的字符串。\n- 分子生物学中心法则确立了 DNA 序列编码遗传信息；在计算层面，读段比对被公式化为在参考基因组内搜索子串。\n- FM 索引源自 Burrows–Wheeler 变换（BWT），并允许通过后向搜索进行高效的精确子串搜索。在字符串 $S\\$$ 上构建 FM 索引，其中 $S$ 是参考序列，$\\$$ 是一个在字典序上小于 $\\Sigma$ 中任何字符的哨兵字符。\n- 令 $n = |S\\$|$ 表示附加哨兵字符后文本的长度。FM 索引包括：\n  1. BWT 字符串 $B$，定义为 $B[i] = S\\$\\big[(\\mathrm{SA}[i] - 1) \\bmod n\\big]$，其中 $\\mathrm{SA}$ 是 $S\\$$ 的后缀数组。\n  2. 数组 $C(c)$，给出 $S\\$$ 中字典序小于 $c$ 的字符总数。\n  3. 出现次数函数 $\\mathrm{Occ}(c, i)$，返回字符 $c$ 在前缀 $B[0:i)$ 中出现的次数，其中 $0 \\le i \\le n$。\n- 后向搜索使用末首（LF）映射执行。对于一个模式 $P$ 和一个后缀数组排名区间 $[l, r)$，使用字符 $c$ 进行更新会产生一个新的区间\n  $$l' = C(c) + \\mathrm{Occ}(c, l), \\quad r' = C(c) + \\mathrm{Occ}(c, r),$$\n  从 $P$ 的最后一个字符迭代到第一个字符。如果在任何步骤中 $l' \\ge r'$，则模式不存在。否则，$P$ 的精确出现位置由后缀数组位置 $\\mathrm{SA}[l:r)$ 给出。\n\n种子延伸过滤：\n- 给定一个长度为 $L$ 的读段 $R$，一个种子长度 $m$，以及一个整数 $f \\ge 1$，通过在偏移量 $o_j = jm$ 处取子串 $R[o_j : o_j + m]$ 来形成不相交的种子，适用于所有满足 $o_j + m \\le L$ 的整数 $j$。令 $t = \\left\\lfloor \\frac{L}{m} \\right\\rfloor$ 表示这样的种子数量。\n- 如果至少有 $f$ 个这些种子在 $S$ 中有精确匹配，且这些匹配与在 $x$ 处比对一致，则 $S$ 中的一个候选起始位置 $x$ 通过过滤。形式上，对于偏移量为 $o$ 的种子，该种子在 $S$ 中的任何精确匹配位置 $p$ 都意味着一个候选比对起始位置 $x = p - o$。计算有多少种子支持一个给定的 $x$，并且仅当该计数至少为 $f$ 时保留 $x$。\n- 过滤后，执行延伸：计算 $R$ 和 $S[x : x + L]$ 之间的错配数量，如果此数量最多为 $k$，则保留 $x$。有效的起始位置必须满足 $0 \\le x \\le |S| - L$。\n\n用于参数选择的原理性保证：\n- 为了允许最多 $k$ 个错配，一个经典的鸽巢原理论证确保，如果读段被划分为 $k + 1$ 个不相交的片段，则至少有一个片段必须是无错配的。这启发我们取 $m \\approx \\left\\lfloor \\frac{L}{k + 1} \\right\\rfloor$ 和过滤要求 $f = 1$ 以保证完整性。更强的过滤标准（$f  1$）是有效的，但当存在错配时可能会排除真实的比对。\n\n算法要求：\n- 为提供的参考序列 $S$ 构建 FM 索引。\n- 对于每个读段和参数集 $(L, k, m, f)$，计算 $S$ 中满足过滤和错配约束的候选起始位置集合，仅使用精确的 FM 索引种子搜索加上通过直接比较进行的延伸。\n- 所有区间和索引必须是自洽的。对 $S$ 中的位置使用零基索引。必须丢弃哨兵索引和超出范围的候选位置。\n\n测试套件：\n- 使用参考序列 $S = \\text{\"ACGTACGTACGTACGTACGTACGT\"}$，其中 $|S| = 24$。\n- 对于每个测试用例，程序应按升序产生排序后的有效候选起始位置列表。\n- 测试用例：\n  1.  用例 A（理想情况）：$R_1 = \\text{\"ACGTACGTACG\"}$，$L = 11$，$k = 1$，$m = 5$，$f = 1$。\n  2.  用例 B（边界情况 $k=0$）：$R_2 = \\text{\"GTACGT\"}$，$L = 6$，$k = 0$，$m = 3$，$f = 2$。\n  3.  用例 C（靠近两端的边界情况）：$R_3 = \\text{\"ACGTACG\"}$，$L = 7$，$k = 2$，$m = 3$，$f = 1$。\n  4.  用例 D（严格过滤的边缘情况）：$R_4 = \\text{\"AAGTACGTA\"}$，$L = 9$，$k = 1$，$m = 4$，$f = 2$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$\\text{[result1,result2,result3,result4]}$），其中每个 $\\text{result}$ 本身是一个表示相应测试用例的候选起始位置的整数列表。\n- 列表必须按升序排序，并且整体输出必须是精确的一行，不含任何额外文本。", "solution": "该任务是实现一个种子延伸读段比对算法，用于枚举给定 DNA 读段在参考序列中的所有候选起始位置。该解决方案必须遵循指定的算法原理，采用 Ferragina–Manzini (FM) 索引进行高效的种子搜索。该过程包括三个主要阶段：FM 索引构建、基于种子的过滤和基于延伸的验证。\n\n### 1. FM 索引构建\n\nFM 索引是一种压缩的全文本索引，能够高效地对文本中的任意模式进行计数和定位。其构建是比对算法的先决条件。我们从参考 DNA 字符串 $S$ 开始。\n\n_步骤 1：文本准备_\n首先，将一个哨兵字符 `$` 追加到参考字符串 $S$ 的末尾，该字符在字典序上小于 DNA 字母表 $\\Sigma = \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$ 中的任何字符。这会创建一个文本 $T = S\\$$，其长度为 $n = |S| + 1$。哨兵字符确保了 $T$ 的每个后缀都是唯一的，并且后缀数组对应于从 $0$ 到 $n-1$ 的索引的一个排列。\n\n_步骤 2：后缀数组 (SA)_\n$T$ 的后缀数组 $\\mathrm{SA}$ 是一个长度为 $n$ 的整数数组。$\\mathrm{SA}[i]$ 存储了 $T$ 的第 $i$ 个字典序最小的后缀的起始位置。对于像所提供的这样的小文本，可以通过生成所有后缀，将它们与起始索引配对，然后对这些配对进行排序来构建 SA。\n\n_步骤 3：Burrows–Wheeler 变换 (BWT)_\nBWT 生成 $T$ 的字符的一个排列，表示为字符串 $B$。它由关系 $B[i] = T[(\\mathrm{SA}[i] - 1) \\bmod n]$ 定义，其中 $i \\in [0, n-1]$。从概念上讲，$B$ 是一个矩阵的最后一列，该矩阵的行是 $T$ 的所有循环移位并按字典序排序。字符串 $B$ 具有一个关键特性，即倾向于将相同的字符组合在一起，这使其高度可压缩并适合高效查询。\n\n_步骤 4：C 表和出现次数函数_\n为了实现高效搜索，构建了两个辅助数据结构：\n1.  **C 表**：数组 $C(c)$ 存储了文本 $T$ 中字典序小于字符 $c$ 的字符总数。该表使我们能够即时找到后缀数组中所有以特定字符 $c$ 开头的后缀的起始排名块。\n2.  **出现次数函数 ($\\mathrm{Occ}$)**：函数 $\\mathrm{Occ}(c, i)$ 返回字符 $c$ 在 BWT 字符串前缀 $B[0:i)$ 中出现的次数。为提高计算效率，此信息被预先计算并存储在一个二维数组中，其中一个维度代表字母表中的字符，另一个维度代表 $B$ 中的位置。\n\n### 2. 通过后向搜索进行精确种子搜索\n\n构建好 FM 索引后，我们可以使用一种称为后向搜索的算法来执行高效的精确字符串匹配。该算法找到与所有以前缀 $P$ 开头的后缀相对应的后缀数组区间 $[l, r)$。\n\n搜索过程通过从右到左迭代模式 $P$ 的字符来进行。从完整的 SA 区间 $[l, r) = [0, n)$ 开始，来自 $P$ 的每个字符 $c$ 根据末首（LF）映射属性更新区间：\n$$l_{\\text{new}} = C(c) + \\mathrm{Occ}(c, l_{\\text{old}})$$\n$$r_{\\text{new}} = C(c) + \\mathrm{Occ}(c, r_{\\text{old}})$$\n如果在任何时候 $l_{\\text{new}} \\ge r_{\\text{new}}$，则模式 $P$ 不存在于文本 $T$ 中。如果循环完成，最终的区间 $[l, r)$ 标识了以 $P$ 为前缀的后缀范围 $\\mathrm{SA}[l \\dots r-1]$。对于 $i \\in [l, r)$，值 $\\mathrm{SA}[i]$ 是 $P$ 在 $T$ 中精确匹配的起始位置。\n\n### 3. 种子延伸过滤与验证\n\n该策略使用短的精确匹配（种子）来快速识别一小组有希望的候选比对位置，然后在一个成本更高的延伸步骤中对这些位置进行验证。\n\n_步骤 1：播种_\n给定一个长度为 $L$ 的读段 $R$、一个种子长度 $m$ 和一个过滤阈值 $f$，将读段划分为 $t = \\lfloor L/m \\rfloor$ 个不相交的种子。第 $j$ 个种子（使用零基索引）是子串 $R[o_j : o_j + m]$，其中偏移量为 $o_j = jm$，适用于 $j \\in [0, t-1]$。\n\n_步骤 2：过滤_\n对于 $t$ 个种子中的每一个，我们使用 FM 索引上的后向搜索算法来查找其在参考字符串 $S$ 中的所有精确匹配位置 $\\{p_0, p_1, \\ldots\\}$。对于读段中偏移量为 $o_j$ 的种子，每个匹配位置 $p$ 都意味着整个读段的一个候选起始位置，计算方式为 $x = p - o_j$。\n为每个潜在的起始位置 $x$ 维护一个计数器。我们遍历所有种子及其所有匹配，每次推断出相应的 $x$ 时，就增加其计数器。处理完所有种子后，我们应用过滤标准：仅当候选起始位置 $x$ 的计数器至少为 $f$ 时才保留它。这意味着读段中至少有 $f$ 个不同的种子支持从 $x$ 开始的比对。\n\n_步骤 3：延伸与验证_\n最后阶段验证通过过滤的候选位置。对于每个通过过滤的候选起始位置 $x$，我们执行两个检查：\n1.  **边界检查**：比对必须完全位于参考序列 $S$ 内。这要求 $0 \\le x \\le |S| - L$。超出此范围的候选位置将被丢弃。\n2.  **错配计数**：计算读段 $R$ 与相应参考子串 $S[x : x + L]$ 之间的错配数。如果该计数小于或等于允许的最大值 $k$，则位置 $x$ 被接受为有效的比对位置。\n\n每个读段的最终输出是所有经过验证的起始位置的排序列表。这种压缩索引和启发式过滤的原则性组合，实现了一个高效而灵敏的读段比对过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import Counter\n\nclass FMIndex:\n    \"\"\"\n    An implementation of the Ferragina–Manzini (FM) index.\n    \"\"\"\n    def __init__(self, text, alphabet):\n        \"\"\"\n        Constructs the FM index for a given text.\n        Args:\n            text (str): The input string, ending with a sentinel '$'.\n            alphabet (list): A list of characters in the alphabet, sorted lexicographically.\n        \"\"\"\n        self.text = text\n        self.alphabet = alphabet\n        self.n = len(text)\n        self.char_map = {c: i for i, c in enumerate(self.alphabet)}\n\n        # 1. Suffix Array (SA) construction\n        suffixes = sorted([(self.text[i:], i) for i in range(self.n)])\n        self.sa = np.array([s[1] for s in suffixes], dtype=np.int32)\n\n        # 2. Burrows–Wheeler Transform (BWT) string B\n        bwt_chars = []\n        for i in range(self.n):\n            bwt_chars.append(self.text[(self.sa[i] - 1) % self.n])\n        self.bwt = \"\".join(bwt_chars)\n\n        # 3. C-Table (counts of chars lexicographically smaller than c)\n        self.c_table = {}\n        counts = Counter(self.text)\n        total = 0\n        for char in self.alphabet:\n            self.c_table[char] = total\n            total += counts.get(char, 0)\n        \n        # 4. Occurrence (Occ) table\n        self.occ = np.zeros((len(self.alphabet), self.n + 1), dtype=np.int32)\n        for i in range(self.n):\n            self.occ[:, i + 1] = self.occ[:, i]\n            if self.bwt[i] in self.char_map:\n                char_idx = self.char_map[self.bwt[i]]\n                self.occ[char_idx, i + 1] += 1\n\n    def _get_occ(self, char, index):\n        \"\"\" Helper to query the Occ table. \"\"\"\n        return self.occ[self.char_map[char], index]\n\n    def search(self, pattern):\n        \"\"\"\n        Performs backward search to find exact matches of a pattern.\n        Args:\n            pattern (str): The pattern to search for.\n        Returns:\n            list: A sorted list of starting positions of the pattern in the original text.\n        \"\"\"\n        if not pattern:\n            return []\n        \n        l, r = 0, self.n\n        for char in reversed(pattern):\n            if char not in self.char_map:\n                return []\n            \n            l = self.c_table[char] + self._get_occ(char, l)\n            r = self.c_table[char] + self._get_occ(char, r)\n            \n            if l >= r:\n                return []\n        \n        return sorted([self.sa[i] for i in range(l, r)])\n\ndef find_candidates(fm_index, S, R, k, m, f):\n    \"\"\"\n    Implements the seed-and-extend mapping algorithm.\n    Args:\n        fm_index (FMIndex): The pre-computed FM index of the reference.\n        S (str): The reference DNA string.\n        R (str): The read DNA string.\n        k (int): Maximum allowed mismatches.\n        m (int): Seed length.\n        f (int): Minimum number of seeds required to support a candidate.\n    Returns:\n        list: A sorted list of valid start positions.\n    \"\"\"\n    L = len(R)\n    s_len = len(S)\n    \n    candidate_supports = Counter()\n    num_seeds = L // m\n    \n    for j in range(num_seeds):\n        offset = j * m\n        seed = R[offset : offset + m]\n        \n        match_positions = fm_index.search(seed)\n        \n        for p in match_positions:\n            candidate_start = p - offset\n            candidate_supports[candidate_start] += 1\n            \n    filtered_starts = []\n    for start_pos, count in candidate_supports.items():\n        if count >= f:\n            filtered_starts.append(start_pos)\n            \n    valid_starts = []\n    for x in sorted(filtered_starts):\n        if 0 = x = s_len - L:\n            mismatches = 0\n            ref_substring = S[x : x + L]\n            for i in range(L):\n                if R[i] != ref_substring[i]:\n                    mismatches += 1\n            if mismatches = k:\n                valid_starts.append(x)\n                \n    return valid_starts\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    S = \"ACGTACGTACGTACGTACGTACGT\"\n    alphabet = ['$', 'A', 'C', 'G', 'T']\n    \n    text_with_sentinel = S + '$'\n    fm_index = FMIndex(text_with_sentinel, alphabet)\n\n    test_cases = [\n        # (R, L, k, m, f) - L is provided but len(R) is used as it's equivalent\n        (\"ACGTACGTACG\", 11, 1, 5, 1), # Case A\n        (\"GTACGT\", 6, 0, 3, 2),       # Case B\n        (\"ACGTACG\", 7, 2, 3, 1),       # Case C\n        (\"AAGTACGTA\", 9, 1, 4, 2)     # Case D\n    ]\n\n    results = []\n    for R, L, k, m, f in test_cases:\n        result = find_candidates(fm_index, S, R, k, m, f)\n        results.append(result)\n\n    # Format the output string to be exactly as required\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n```", "id": "3310867"}]}