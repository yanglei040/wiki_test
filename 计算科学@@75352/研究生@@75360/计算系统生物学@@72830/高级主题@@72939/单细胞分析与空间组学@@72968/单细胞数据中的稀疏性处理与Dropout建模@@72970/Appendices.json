{"hands_on_practices": [{"introduction": "在处理单细胞数据的稀疏性时，一个核心挑战是区分真实的生物性零表达和技术性脱落。这个练习通过一个思想实验，阐明了当数据实际上是“非随机缺失”（Missing Not At Random, MNAR）而被错误地假设为“随机缺失”（Missing At Random, MAR）时所产生的后果。通过推导一个简化的脱落模型中的估计偏差，您将深刻理解为何对脱落机制的准确建模至关重要 [@problem_id:3349850]。", "problem": "考虑一个在大量单细胞群体中通过唯一分子标识符（UMI）计数测量的单个低表达基因。假设每个细胞的真实计数是独立同分布的，服从均值为 $\\lambda$ 的泊松分布，因此 $X \\sim \\mathrm{Poisson}(\\lambda)$ 模拟了单个细胞中的真实计数。观测计数 $Y$ 受到一个依赖于未观测到的 $X$ 的丢失机制的影响（即，非随机缺失 (MNAR)）：如果 $X=0$，则 $Y=0$；如果 $X=1$，则 $Y=0$ 的概率为 $d \\in (0,1)$，否则 $Y=1$；如果 $X \\ge 2$，则 $Y=X$（无丢失）。该机制是低计数存在更强丢失效应的一种概念验证性表示。\n\n一位从业者错误地假设了一个随机缺失 (MAR) 机制，其丢失概率为恒定的 $r \\in (0,1)$ 且与 $X$ 无关，并通过逆概率加权来校正观测均值，将基因的平均表达量估计为\n$$\n\\mu_{\\mathrm{MAR}} \\equiv \\frac{\\mathbb{E}[Y]}{1-r}.\n$$\n假设这位从业者以某种方式得知了该基因确切的总丢失概率 $r$，该概率定义为在真实数据生成过程中，一个随机选择的细胞发生丢失事件的概率。你可以假设 $r$ 是已知的，并且与上述 MAR 校正中出现的 $r$ 是同一个。仅使用泊松分布的基本性质以及随机缺失 (MAR) 和非随机缺失 (MNAR) 的定义，推导这个基于 MAR 的估计量相对于真实均值的偏差，定义为\n$$\n\\mathrm{Bias}(\\lambda,r) \\equiv \\mu_{\\mathrm{MAR}} - \\lambda,\n$$\n并将其表示为仅包含 $\\lambda$ 和 $r$ 的封闭形式函数，消去无关参数 $d$。你的最终答案必须是 $\\mathrm{Bias}(\\lambda,r)$ 的一个仅用 $\\lambda$ 和 $r$ 表示的单一封闭形式解析表达式。无需进行数值计算，也无需进行四舍五入。", "solution": "该问题要求计算当真实数据生成过程为非随机缺失 (MNAR) 时，一个基于随机缺失 (MAR) 的平均表达量估计量的偏差。偏差定义为 $\\mathrm{Bias}(\\lambda,r) \\equiv \\mu_{\\mathrm{MAR}} - \\lambda$，其中 $\\mu_{\\mathrm{MAR}} = \\frac{\\mathbb{E}[Y]}{1-r}$。在这里，$\\lambda$ 是未观测计数 $X$ 的真实均值，$Y$ 是观测计数，$r$ 是总丢失概率。为了求得偏差，我们必须首先在真实的 MNAR 数据生成过程下，推导出观测计数期望值 $\\mathbb{E}[Y]$ 的表达式。\n\n真实计数 $X$ 是一个服从均值为 $\\lambda$ 的泊松分布的随机变量，记为 $X \\sim \\mathrm{Poisson}(\\lambda)$。其概率质量函数 (PMF) 为 $P(X=k) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$，其中 $k \\in \\{0, 1, 2, \\dots\\}$。\n\n观测计数 $Y$ 和真实计数 $X$ 之间的关系由 MNAR 机制给出：\n1. 如果 $X=0$，则 $Y=0$。\n2. 如果 $X=1$，则 $Y=0$ 的概率为 $d$，$Y=1$ 的概率为 $1-d$，其中 $d \\in (0,1)$。\n3. 如果 $X \\ge 2$，则 $Y=X$。\n\n我们可以使用全期望定律计算 $Y$ 的期望值：$\\mathbb{E}[Y] = \\sum_{k=0}^{\\infty} \\mathbb{E}[Y | X=k] P(X=k)$。\n让我们根据 MNAR 模型确定条件期望 $\\mathbb{E}[Y | X=k]$：\n- 当 $k=0$ 时：$\\mathbb{E}[Y | X=0] = 0$。\n- 当 $k=1$ 时：$\\mathbb{E}[Y | X=1] = 0 \\cdot P(Y=0|X=1) + 1 \\cdot P(Y=1|X=1) = 0 \\cdot d + 1 \\cdot (1-d) = 1-d$。\n- 当 $k \\ge 2$ 时：$\\mathbb{E}[Y | X=k] = k$。\n\n将这些代入全期望定律：\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[Y | X=0]P(X=0) + \\mathbb{E}[Y | X=1]P(X=1) + \\sum_{k=2}^{\\infty} \\mathbb{E}[Y | X=k]P(X=k)\n$$\n$$\n\\mathbb{E}[Y] = (0)P(X=0) + (1-d)P(X=1) + \\sum_{k=2}^{\\infty} k P(X=k)\n$$\n服从泊松分布的变量 $X$ 的期望为 $\\mathbb{E}[X] = \\lambda$，可以写成：\n$$\n\\mathbb{E}[X] = \\sum_{k=0}^{\\infty} k P(X=k) = (0)P(X=0) + (1)P(X=1) + \\sum_{k=2}^{\\infty} k P(X=k) = P(X=1) + \\sum_{k=2}^{\\infty} k P(X=k)\n$$\n由此，我们可以将和式 $\\sum_{k=2}^{\\infty} k P(X=k)$ 表示为 $\\lambda - P(X=1)$。将此代入 $\\mathbb{E}[Y]$ 的表达式中：\n$$\n\\mathbb{E}[Y] = (1-d)P(X=1) + (\\lambda - P(X=1))\n$$\n$$\n\\mathbb{E}[Y] = P(X=1) - dP(X=1) + \\lambda - P(X=1)\n$$\n$$\n\\mathbb{E}[Y] = \\lambda - dP(X=1)\n$$\n问题要求最终的偏差是 $\\lambda$ 和 $r$ 的函数，因此我们必须消去无关参数 $d$。参数 $r$ 被定义为总丢失概率。丢失事件是指一个真实的非零计数被观测为零。根据 MNAR 模型，这种情况只在 $X=1$ 时发生。\n因此，$r$ 是联合事件 $\\{Y=0 \\text{ and } X>0\\}$ 的概率。\n$$\nr = P(Y=0, X>0)\n$$\n条件 $X>0$ 和 $Y=0$ 只有在 $X=1$ 且发生丢失时才能满足。对于 $X \\ge 2$ 的情况，$Y=X \\ge 2$，因此 $Y$ 不可能为 $0$。对于 $X=0$ 的情况，$X$ 不大于 $0$。因此，事件 $\\{Y=0, X>0\\}$ 等同于事件 $\\{Y=0, X=1\\}$。\n$$\nr = P(Y=0, X=1) = P(Y=0 | X=1) P(X=1)\n$$\n根据模型定义，$P(Y=0 | X=1) = d$。因此，我们有以下关系式：\n$$\nr = dP(X=1)\n$$\n现在我们可以将此直接代入我们关于 $\\mathbb{E}[Y]$ 的表达式中：\n$$\n\\mathbb{E}[Y] = \\lambda - r\n$$\n有了 $\\mathbb{E}[Y]$ 这个简洁的表达式，我们就可以求出基于 MAR 的估计量的总体值 $\\mu_{\\mathrm{MAR}}$：\n$$\n\\mu_{\\mathrm{MAR}} = \\frac{\\mathbb{E}[Y]}{1-r} = \\frac{\\lambda - r}{1-r}\n$$\n最后，我们可以通过减去真实均值 $\\lambda$ 来计算偏差 $\\mathrm{Bias}(\\lambda,r)$：\n$$\n\\mathrm{Bias}(\\lambda,r) = \\mu_{\\mathrm{MAR}} - \\lambda = \\frac{\\lambda - r}{1-r} - \\lambda\n$$\n为了简化，我们进行通分：\n$$\n\\mathrm{Bias}(\\lambda,r) = \\frac{\\lambda - r - \\lambda(1-r)}{1-r}\n$$\n$$\n\\mathrm{Bias}(\\lambda,r) = \\frac{\\lambda - r - \\lambda + \\lambda r}{1-r}\n$$\n$$\n\\mathrm{Bias}(\\lambda,r) = \\frac{\\lambda r - r}{1-r}\n$$\n从分子中提取因子 $r$ 得到偏差的最终封闭形式表达式：\n$$\n\\mathrm{Bias}(\\lambda,r) = \\frac{r(\\lambda - 1)}{1-r}\n$$\n该表达式仅依赖于 $\\lambda$ 和 $r$，符合题目要求。", "answer": "$$\n\\boxed{\\frac{r(\\lambda - 1)}{1-r}}\n$$", "id": "3349850"}, {"introduction": "在确定需要使用更复杂的零膨胀模型之前，我们必须首先有方法地检测数据中是否存在“过多的零”。这个实践任务将指导您实现一个统计上的拟合优度检验，用于判断观测到的零计数是否显著超出了标准负二项分布模型的预期。完成这项练习将为您提供一个关键的诊断工具，用以评估和选择合适的单细胞数据分析模型 [@problem_id:3349885]。", "problem": "您的任务是为单细胞基因表达计数数据中的零膨胀（zero inflation）设计并实现一个离散拟合优度检验。设定是在有限数量的细胞中测量单个基因。单细胞计数表现出稀疏性，必须将具有生物学意义的低表达与技术性脱落（technical dropouts）区分开来。建模基础是负二项 (Negative Binomial, NB) 分布，这是一种在单细胞基因组学中广泛使用的计数模型，用于捕捉细胞间的过度离散（overdispersion）。您的程序必须对提供的测试套件中的每个案例执行以下步骤。\n\n从以下基础且广为接受的定义开始：\n- 负二项 (NB) 分布用于对非负整数值计数进行建模。在使用大小 (size) $r$ 和成功概率 $p$ 进行参数化的 NB 分布下，$X \\in \\{0,1,2,\\dots\\}$ 的概率质量函数为 $P(X=x) = \\binom{x+r-1}{x} p^{r} (1-p)^{x}$。其均值为 $E[X] = r \\frac{1-p}{p}$，方差为 $\\mathrm{Var}[X] = r \\frac{1-p}{p^{2}}$。在计算生物学背景下，通常通过均值 $\\mu$ 和大小 $r$ 对 NB 分布进行重新参数化，其中 $p = \\frac{r}{r+\\mu}$，得到 $E[X]=\\mu$ 和 $\\mathrm{Var}[X]=\\mu + \\frac{\\mu^{2}}{r}$。\n- 对于一个在 $N$ 个细胞中测量的基因，索引 $i \\in \\{1,\\dots,N\\}$，假设计数 $X_{i}$ 是从一个跨细胞的 NB 模型中独立抽取的样本，构成一个基线生成模型。在此基线 NB 模型下，任何单个细胞中出现精确零的概率是 $P(X_{i}=0) = p^{r}$，而在 $N$ 个细胞中零的期望数量是 $N \\cdot p^{r}$。\n- 在没有超出 NB 分布的额外零膨胀的原假设下，零的个数 $Z = \\sum_{i=1}^{N} \\mathbf{1}\\{X_{i}=0\\}$ 服从参数为 $(N, q)$ 的二项分布 (Binomial distribution)，其中 $q = p^{r}$。\n- 为了检验超出 NB 分布的零膨胀（过量零值），适合采用单侧检验，将观测到的零计数 $z$ 与 NB 期望的零计数 $N q$ 进行比较。两种标准的离散检验策略是可接受的：对 $Z$ 进行精确二项上尾检验 (exact Binomial upper-tail test)，以及使用连续性校正的校准 Pearson 卡方检验 (calibrated Pearson chi-square test)，该检验仅评估上尾，因为感兴趣的科学备择假设是存在过量零值。当 $q$ 接近 $0$ 或 $1$ 时，为保证科学真实性，需要进行连续性校正和谨慎的边界处理。\n- 对于单基因数据的实际应用，必须使用广为接受的 NB 方差分解，通过矩估计法 (method-of-moments) 从观测计数中估计参数 $(\\mu, r)$。给定样本均值 $\\hat{\\mu}$ 和样本方差 $\\hat{v}$，当 $\\hat{v} > \\hat{\\mu}$ 时，一个有效的 NB 大小估计为 $\\hat{r} = \\frac{\\hat{\\mu}^{2}}{\\hat{v} - \\hat{\\mu}}$。当 $\\hat{v} \\le \\hat{\\mu}$ 时，数据至多是泊松离散的 (Poisson dispersed)；在这种边界情况下，您必须使用一个大的替代值 $\\hat{r}$ 来近似泊松极限，从而得到 NB 零概率 $q \\approx \\exp(-\\hat{\\mu})$，这是当 $p = \\frac{\\hat{r}}{\\hat{r} + \\hat{\\mu}}$ 且 $\\hat{r} \\to \\infty$ 时 $p^{r}$ 的极限行为。\n\n您的程序必须为每个测试案例执行以下操作：\n1. 为了真实性，使用零膨胀负二项 (Zero-Inflated Negative Binomial, ZINB) 数据生成器，在 $N$ 个细胞中生成合成的单基因计数：以概率 $\\pi$ 产生一个额外的零，否则从上文定义的均值为 $\\mu$、大小为 $r$ 的 NB 分布中抽样。为了保证所有案例的可复现性，请使用固定的伪随机数生成器种子 $12345$。该生成器严格用于生成测试数据；推断过程必须使用 NB 模型，并且不能获取 $\\pi$ 的值。\n2. 从生成的计数中，计算样本均值 $\\hat{\\mu}$ 和样本方差 $\\hat{v}$，然后通过矩估计法估计 NB 大小参数 $\\hat{r}$，在 $\\hat{v} \\le \\hat{\\mu}$ 时使用一个大的替代值 $\\hat{r}$ 来近似泊松极限。根据 $(\\hat{\\mu}, \\hat{r})$，计算 $p = \\frac{\\hat{r}}{\\hat{r} + \\hat{\\mu}}$ 和 NB 零概率估计值 $q = p^{\\hat{r}}$。通过对数进行指数运算，以数值稳定的方式计算 $q$。最后，计算观测到的零计数 $z$ 和 NB 期望的零计数 $\\hat{z}^{\\mathrm{NB}} = N q$。\n3. 执行单侧零膨胀检验：\n   - 精确二项上尾检验：在 $Z \\sim \\mathrm{Binomial}(N, q)$ 的条件下，计算 $p$-值 $P(Z \\ge z)$。为减少离散性带来的保守性，可以接受中点p值 (mid-$p$) 调整 $P(Z > z) + \\tfrac{1}{2} P(Z = z)$。\n   - 校准 Pearson 卡方检验：使用连续性校正，仅当 $z \\ge N q$ 时定义统计量为 $$X^{2} = \\frac{\\left(|z - N q| - 0.5\\right)^{2}}{N q (1-q)}.$$ 当 $z  N q$ 时，将单侧上尾 $p$-值设为 $1$。为了在 $q$ 极度接近 $0$ 或 $1$ 时保证数值安全，应退回到使用精确二项上尾 $p$-值，以避免除以极小的分母。\n4. 将得到的 $p$-值与给定的显著性水平 $\\alpha$ 进行比较，如果检验检测到显著的零膨胀（即 $p  \\alpha$），则返回布尔决策 $True$，否则返回 $False$。\n\n不涉及物理单位。所有角度（如果有的话）均不相关。将任何比率阈值或水平表示为小数（例如，需要时将 $\\alpha$ 写为 $0.05$）。您的实现必须纯粹基于数学和逻辑术语，并通过指定的伪随机种子保证可复现性。\n\n测试套件：\n对于每个元组，参数为 $(N, \\mu, r, \\pi, \\alpha, \\text{test})$，其中 $N$ 是细胞数量，$\\mu$ 是 NB 均值， $r$ 是 NB 大小，$\\pi$ 是零膨胀概率，$\\alpha$ 是显著性水平，$\\text{test}$ 是精确二项检验或校准卡方检验。请使用以下案例：\n- 案例 1：$(200, 1.5, 4.0, 0.0, 0.05, \\text{Binomial})$。\n- 案例 2：$(200, 1.5, 4.0, 0.20, 0.05, \\text{Binomial})$。\n- 案例 3：$(50, 0.2, 2.0, 0.0, 0.05, \\text{Binomial})$。\n- 案例 4：$(50, 0.2, 2.0, 0.70, 0.05, \\text{Binomial})$。\n- 案例 5：$(100, 5.0, 10.0, 0.0, 0.01, \\text{ChiSquare})$。\n- 案例 6：$(150, 2.0, 10^{6}, 0.30, 0.01, \\text{ChiSquare})$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个布尔值对应一个测试案例，指示是否在其指定的水平上检测到显著的零膨胀，例如 $[True,False,\\dots]$。程序必须且仅能打印此单行内容。", "solution": "用户提供的问题经评估是有效的。它在科学上基于统计基因组学的既定原则，问题阐述清晰，对所需程序有明确和完整的说明，并且其表述是客观的。任务是为单细胞计数数据中的零膨胀实现一个拟合优度检验，这是计算系统生物学中的一个标准问题。解决方案将首先实现数据生成和参数估计，然后执行指定的统计检验。\n\n每个测试案例的总体流程如下：生成一个合成数据集，从该数据中估计原假设模型（负二项分布）的参数，执行统计检验以评估原假设模型在多大程度上解释了观测到的零的数量，最后做出关于统计显著性的决策。\n\n**步骤 1：合成数据生成**\n对于每个测试案例，我们从一个零膨胀负二项 (ZINB) 分布中为 $N$ 个细胞生成合成的单基因表达计数。ZINB 模型由零膨胀概率 $\\pi$、负二项 (NB) 均值 $\\mu$ 和 NB 大小参数 $r$ 定义。对于每个细胞 $i=1, \\dots, N$：1. 从参数为 $\\pi$ 的伯努利分布 (Bernoulli distribution) 中抽取一个值。2. 如果结果为成功（概率为 $\\pi$），则计数 $X_i$ 是一个“额外”的零，即 $X_i=0$。3. 如果结果为失败（概率为 $1-\\pi$），则计数 $X_i$ 从负二项分布 $\\mathrm{NB}(\\mu, r)$ 中抽取。\n\nNB 分布由其均值 $\\mu$ 和大小 $r$ 参数化。NB 过程底层伯努利试验的成功概率由 $p = \\frac{r}{r+\\mu}$ 给出。其概率质量函数为 $P(X=x) = \\binom{x+r-1}{x} p^{r} (1-p)^{x}$。使用单一的、以 $12345$ 为种子的伪随机数生成器进行所有随机抽样，以确保所有测试案例的可复现性。\n\n**步骤 2：从数据中进行参数估计**\n从生成的 $N$ 个计数的向量中，我们使用矩估计法估计纯 NB 模型（原假设模型）的参数。此过程故意忽略用于生成数据的零膨胀成分（如果存在），因为检验的目的正是为了检测其是否存在。\n\n1.  从 $N$ 个计数中计算样本均值 $\\hat{\\mu}$ 和样本方差 $\\hat{v}$（使用贝塞尔校正 (Bessel's correction)，即分母为 $N-1$）。\n2.  NB 的理论方差为 $\\mathrm{Var}[X] = \\mu + \\frac{\\mu^2}{r}$。通过代入样本估计值，我们可以求解 $r$：\n    $$ \\hat{r} = \\frac{\\hat{\\mu}^2}{\\hat{v} - \\hat{\\mu}} $$\n    此估计仅对过度离散的数据有效，即 $\\hat{v} > \\hat{\\mu}$。\n3.  在低度离散或类泊松离散 ($\\hat{v} \\le \\hat{\\mu}$) 的情况下，数据不支持具有有限正值 $r$ 的 NB 模型。这对应于 $r \\to \\infty$ 的极限情况，此时 NB 分布收敛于泊松分布 (Poisson distribution)。在这种情况下，我们为 $\\hat{r}$ 分配一个非常大的替代值，如 $10^{12}$，以近似此极限。\n4.  利用估计值 $\\hat{\\mu}$ 和 $\\hat{r}$，我们计算在拟合的 NB 模型下观测到零的概率。成功概率为 $p = \\frac{\\hat{r}}{\\hat{r} + \\hat{\\mu}}$。零计数的概率为 $q = p^{\\hat{r}}$。为了保持数值稳定性，特别是当 $\\hat{r}$ 很大时，$q$ 通过其对数进行计算：\n    $$ q = \\exp\\left(\\hat{r} \\log p\\right) = \\exp\\left(\\hat{r} \\log\\left(\\frac{\\hat{r}}{\\hat{r} + \\hat{\\mu}}\\right)\\right) = \\exp\\left(-\\hat{r} \\log\\left(1 + \\frac{\\hat{\\mu}}{\\hat{r}}\\right)\\right) $$\n    这种形式在数值上是稳健的，并且对于大的 $\\hat{r}$，能正确计算出 $q \\approx e^{-\\hat{\\mu}}$。\n5.  最后，我们统计数据中观测到的零的数量 $z$，并计算在拟合的 NB 模型下期望的零的数量 $\\hat{z}^{\\mathrm{NB}} = N \\cdot q$。\n\n**步骤 3：单侧拟合优度检验**\n我们检验原假设 $H_0$：观测到的零计数 $z$ 与从二项分布 $Z \\sim \\mathrm{Binomial}(N, q)$ 中抽取的样本一致。备择假设 $H_1$ 是存在零膨胀，即零值过多，因此我们执行一个单侧上尾检验。\n\n按规定实现两种检验策略：\n\n1.  **精确二项检验**: $p$-值是在原假设下观测到至少 $z$ 个零的概率。\n    $$ p\\text{-value} = P(Z \\ge z) = \\sum_{k=z}^{N} \\binom{N}{k} q^k (1-q)^{N-k} $$\n    这通过计算二项分布在 $z-1$ 处的生存函数 (survival function) 得到。\n\n2.  **校准 Pearson 卡方检验**: 此检验是基于二项分布的正态近似。包含耶茨连续性校正 (Yates's continuity correction) 的检验统计量仅在观测零计数 $z$ 超过期望计数 $Nq$ 时计算。\n    $$ X^2 = \\frac{\\left(|z - N q| - 0.5\\right)^2}{N q (1-q)} $$\n    如果 $z  Nq$，则没有证据表明存在过量的零，因此单侧 $p$-值设为 $1$。如果 $z \\ge Nq$，$p$-值是概率 $P(\\chi^2_1 \\ge X^2)$，其中 $\\chi^2_1$ 是一个自由度为 $1$ 的卡方随机变量。\n\n    卡方近似仅在两类（‘零’和‘非零’）的期望计数都足够大时才有效。一个标准的启发式法则是期望计数应至少为 $5$。因此，如果 $N q  5$ 或 $N (1-q)  5$，我们将退回到更精确的精确二项检验，以确保数值稳定性和统计有效性。\n\n**步骤 4：决策**\n对于每个测试案例，将计算出的 $p$-值与给定的显著性水平 $\\alpha$ 进行比较。如果 $p$-值小于 $\\alpha$，则拒绝无零膨胀的原假设，结果为 `True`。否则，不拒绝原假设，结果为 `False`。所有测试案例的布尔结果被编译成一个列表，并格式化为最终输出。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import binom, chi2\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the problem of detecting zero inflation in single-gene count data.\n    \"\"\"\n    \n    # Test cases: (N, mu, r, pi, alpha, test_type)\n    test_cases = [\n        (200, 1.5, 4.0, 0.0, 0.05, 'Binomial'),\n        (200, 1.5, 4.0, 0.20, 0.05, 'Binomial'),\n        (50, 0.2, 2.0, 0.0, 0.05, 'Binomial'),\n        (50, 0.2, 2.0, 0.70, 0.05, 'Binomial'),\n        (100, 5.0, 10.0, 0.0, 0.01, 'ChiSquare'),\n        (150, 2.0, 10**6, 0.30, 0.01, 'ChiSquare'),\n    ]\n\n    # Initialize a single random number generator for reproducibility across all cases.\n    rng = np.random.default_rng(12345)\n    \n    results = []\n\n    for N, mu, r, pi, alpha, test_type in test_cases:\n        \n        # Step 1: Generate synthetic ZINB data\n        counts = np.zeros(N, dtype=int)\n        is_dropout = rng.uniform(0, 1, size=N)  pi\n        counts[is_dropout] = 0\n        \n        n_non_dropout = N - np.sum(is_dropout)\n        if n_non_dropout > 0:\n            # For NB(mu, r), success probability p = r / (r + mu)\n            nb_p = r / (r + mu)\n            # numpy's `negative_binomial` has mean n*(1-p)/p.\n            # With our p, mean = r*(1 - r/(r+mu)) / (r/(r+mu)) = r*(mu/(r+mu)) / (r/(r+mu)) = mu. This is correct.\n            nb_draws = rng.negative_binomial(n=r, p=nb_p, size=n_non_dropout)\n            counts[~is_dropout] = nb_draws\n\n        # Step 2: Parameter estimation\n        if N > 1:\n            mu_hat = np.mean(counts)\n            v_hat = np.var(counts, ddof=1)\n        else: # Handle edge case of N=1\n            mu_hat = counts[0] if N == 1 else 0.0\n            v_hat = 0.0\n\n        if mu_hat == 0: # All counts are 0\n            r_hat = 1e12\n        elif v_hat > mu_hat:\n            r_hat = mu_hat**2 / (v_hat - mu_hat)\n        else: # Underdispersed or Poisson-like case\n            r_hat = 1e12 # Surrogate for r -> infinity\n\n        # Numerically stable calculation of q = p^r\n        if mu_hat >= 0 and r_hat > 0:\n            # q = (r/(r+mu))^r = exp(r * log(r/(r+mu))) = exp(-r * log(1 + mu/r))\n            # np.log1p(x) computes log(1+x) accurately for small x.\n            log_q = -r_hat * np.log1p(mu_hat / r_hat)\n            q = np.exp(log_q)\n        else: # Should not happen with mu_hat >= 0\n            q = 1.0 if mu_hat == 0 else 0.0\n\n        # Clip q to be within a valid probability range\n        q = np.clip(q, 0.0, 1.0)\n            \n        z_obs = np.sum(counts == 0)\n        z_exp = N * q\n\n        # Step 3: Perform one-sided test\n        p_value = -1.0 # Initialize\n\n        def compute_binomial_p_value(z, n_trials, prob):\n            # P(Z >= z) = 1 - P(Z = z-1) = sf(z-1)\n            # Handle z=0 edge case where z-1 is negative.\n            if z == 0:\n                return 1.0\n            return binom.sf(z - 1, n_trials, prob)\n\n        if test_type == 'Binomial':\n            p_value = compute_binomial_p_value(z_obs, N, q)\n\n        elif test_type == 'ChiSquare':\n            # Fallback condition for chi-square approximation validity\n            chi2_fallback = (N * q  5) or (N * (1 - q)  5)\n            \n            if chi2_fallback:\n                p_value = compute_binomial_p_value(z_obs, N, q)\n            else:\n                if z_obs  z_exp:\n                    # One-sided test: no evidence for *excess* zeros\n                    p_value = 1.0\n                else:\n                    numerator = (abs(z_obs - z_exp) - 0.5)**2\n                    denominator = N * q * (1 - q)\n                    chi2_stat = numerator / denominator\n                    p_value = chi2.sf(chi2_stat, df=1)\n        \n        # Step 4: Compare p-value with alpha\n        is_significant = p_value  alpha\n        results.append(is_significant)\n    \n    # Final output formatting\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3349885"}, {"introduction": "拟合一个复杂的统计模型只是分析过程的一半，验证该模型是否准确地捕捉了数据的关键特征同等重要。本练习将引导您实施一个后验预测检验，这是一种强大的贝叶斯模型评估技术。您将学习如何通过模拟生成的数据与真实数据进行比较，来评估零膨胀泊松（Zero-Inflated Poisson, ZIP）模型对基因表达零比例的拟合程度，从而确保我们模型的可靠性 [@problem_id:3349820]。", "problem": "给定一个单细胞计数分析场景，其中一个离散计数矩阵是在一个机制性 dropout 过程中生成的。目标是构建一个后验预测检验，该检验将每个基因的经验零分数与从拟合模型中进行的模拟抽样进行比较，并定义和计算一个惩罚过度插补的校准度量。您的程序必须实现以下定义和计算，并将它们应用于下面指定的固定测试套件。\n\n假设每个基因的零膨胀泊松 (ZIP) 生成模型如下。对于每个基因索引 $g \\in \\{1,\\ldots,G\\}$ 和细胞索引 $i \\in \\{1,\\ldots,N\\}$，观测到的计数 $X_{g,i} \\in \\mathbb{N}_{0}$ 由以下方式生成\n$$\nZ_{g,i} \\sim \\mathrm{Bernoulli}(\\pi_g), \\quad\nY_{g,i} \\sim \\mathrm{Poisson}(\\lambda_g), \\quad\nX_{g,i} = \\begin{cases}\n0  \\text{ if } Z_{g,i} = 1,\\\\\nY_{g,i}  \\text{ if } Z_{g,i} = 0.\n\\end{cases}\n$$\n这里 $\\pi_g \\in [0,1]$ 是每个基因的 dropout 概率，$\\lambda_g > 0$ 是每个基因的平均计数率。我们关注每个基因的经验零分数\n$$\n\\hat{z}_g = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{1}\\{X_{g,i} = 0\\}.\n$$\n对于后验预测模拟，假设对于每个基因 $g$，您有 $D$ 个独立的后验抽样 $\\{\\pi_g^{(d)}, \\lambda_g^{(d)}\\}_{d=1}^{D}$，其中 $\\pi_g^{(d)} \\sim \\mathrm{Beta}(a_g,b_g)$ 且 $\\lambda_g^{(d)} \\sim \\mathrm{Gamma}(k_g,\\theta_g)$，形状参数为 $k_g$，尺度参数为 $\\theta_g$。对于给定的抽样 $d$，单个细胞的模型隐含零概率为\n$$\nq_g^{(d)} = \\pi_g^{(d)} + \\left(1 - \\pi_g^{(d)}\\right) \\exp(-\\lambda_g^{(d)}),\n$$\n并且 $N$ 个细胞上的模拟零分数可以通过以下方式获得\n$$\n\\tilde{z}_g^{(d)} = \\frac{1}{N} \\cdot U_g^{(d)}, \\quad \\text{with } U_g^{(d)} \\sim \\mathrm{Binomial}(N, q_g^{(d)}).\n$$\n\n将每个基因的零分数的双边后验预测检验定义为\n$$\np_g = \\Pr\\left(\\tilde{z}_g \\le \\hat{z}_g\\right), \\quad\nt_g = 2 \\cdot \\min\\left(p_g, 1 - p_g\\right),\n$$\n其中平局处理实现为\n$$\np_g = \\Pr\\left(\\tilde{z}_g  \\hat{z}_g\\right) + \\tfrac{1}{2}\\Pr\\left(\\tilde{z}_g = \\hat{z}_g\\right),\n$$\n通过对 $D$ 次抽样进行蒙特卡洛近似。同时定义一个惩罚过度插补的校准度量\n$$\n\\mathrm{OPS} = \\frac{1}{G}\\sum_{g=1}^{G} \\left( \\frac{1}{D} \\sum_{d=1}^{D} \\max\\left(0, \\hat{z}_g - \\tilde{z}_g^{(d)}\\right) \\right),\n$$\n当模拟的零分数系统性地小于经验零分数时，该度量的值会增加。最后，通过以下方式聚合所有基因的后验预测检验\n$$\n\\bar{t} = \\frac{1}{G} \\sum_{g=1}^{G} t_g.\n$$\n\n实现一个程序，对于下面的每个测试用例，使用以下固定的蒙特卡洛方案计算浮点数对 $(\\bar{t}, \\mathrm{OPS})$：设置一个固定的随机种子 $s$，对于每个基因，从指定的 Beta 分布和 Gamma 分布中精确抽取 $D$ 个样本，对于每次抽取，通过上述的二项分布机制模拟零的数量，然后计算所需的度量。所有浮点输出必须四舍五入到 $6$ 位小数。使用形状参数为 $k$ 和尺度参数为 $\\theta$ 的 Gamma 分布参数化，使其均值为 $k \\theta$。此计算不涉及任何物理单位。\n\n您必须对每个基因使用恰好 $D = 400$ 次蒙特卡洛抽样，并在任何抽样之前将伪随机数生成器的种子设置为 $s = 314159$。对于每个测试用例，您将获得观测计数矩阵 $X \\in \\mathbb{N}_{0}^{G \\times N}$ 和后验超参数 $\\{(a_g,b_g,k_g,\\theta_g)\\}_{g=1}^{G}$。\n\n测试套件：\n\n测试用例 1 (理想路径，混合 dropout 水平)：\n- 维度：$G=3$, $N=30$。\n- 按基因分的观测计数 $X$ (每行有 $N=30$ 个条目)：\n  - 基因 1：$[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,1,4,2,1,3,2,5,1,2,3,2,4]$。\n  - 基因 2：$[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,2,1,1,3]$。\n  - 基因 3：$[0,0,0,1,2,2,1,3,1,2,4,1,2,3,1,2,1,1,3,2,2,4,3,1,2,1,2,3,1,2]$。\n- 每个基因的后验超参数：\n  - 基因 1：$(a_1,b_1,k_1,\\theta_1) = (5,5,5,0.5)$。\n  - 基因 2：$(a_2,b_2,k_2,\\theta_2) = (8,2,2,0.5)$。\n  - 基因 3：$(a_3,b_3,k_3,\\theta_3) = (1,9,5,0.5)$。\n\n测试用例 2 (过度插补压力测试：对于一个基因，经验零值高，模型 dropout 低)：\n- 维度：$G=2$, $N=40$。\n- 观测计数 $X$：\n  - 基因 1：$[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,2]$。\n  - 基因 2：$[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,1,3,1,2,2,1,3,1,2,1,3,2,1,2,3,1,2,1]$。\n- 每个基因的后验超参数：\n  - 基因 1：$(a_1,b_1,k_1,\\theta_1) = (2,8,3,0.5)$。\n  - 基因 2：$(a_2,b_2,k_2,\\theta_2) = (3,3,4,0.5)$。\n\n测试用例 3 (边缘情况：一个全零基因)：\n- 维度：$G=2$, $N=25$。\n- 观测计数 $X$：\n  - 基因 1：$[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$。\n  - 基因 2：$[0,0,0,0,0,1,1,2,1,3,2,1,2,1,3,1,2,1,2,1,3,1,2,1,2]$。\n- 每个基因的后验超参数：\n  - 基因 1：$(a_1,b_1,k_1,\\theta_1) = (1,4,2,0.5)$。\n  - 基因 2：$(a_2,b_2,k_2,\\theta_2) = (1,4,3,0.5)$。\n\n测试用例 4 (边缘情况：一个无零基因)：\n- 维度：$G=1$, $N=20$。\n- 观测计数 $X$：\n  - 基因 1：$[1,1,2,1,2,1,1,2,1,2,1,1,3,2,1,2,1,2,1,3]$。\n- 每个基因的后验超参数：\n  - 基因 1：$(a_1,b_1,k_1,\\theta_1) = (1,19,4,0.5)$。\n\n实现和输出要求：\n- 对每个基因使用恰好 $D=400$ 次后验抽样，并为伪随机数生成器设置固定种子 $s=314159$。\n- 对于每个测试用例，计算如上定义的 $(\\bar{t}, \\mathrm{OPS})$。将每个浮点数四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含所有结果，格式为方括号括起来的逗号分隔列表，顺序为 $[\\bar{t}_{1}, \\mathrm{OPS}_{1}, \\bar{t}_{2}, \\mathrm{OPS}_{2}, \\bar{t}_{3}, \\mathrm{OPS}_{3}, \\bar{t}_{4}, \\mathrm{OPS}_{4}]$，其中下标表示测试用例索引。", "solution": "该问题是有效的，因为它提出了一个在计算系统生物学中定义良好且具有科学依据的任务。它是内容完整的，提供了所有必要的数据、定义和计算方案。底层的零膨胀泊松 (ZIP) 模型和后验预测检验的使用是单细胞数据分析领域的标准且适当的方法。该问题是客观的，其解决方案可以被确定性地复现。\n\n目标是为几个测试用例计算两个汇总统计量，即平均双边后验预测 p 值 $\\bar{t}$ 和过度插补惩罚分数 $\\mathrm{OPS}$。这些度量用于评估拟合的 ZIP 模型在单细胞数据中复现观测到的零计数分数的能力。该计算遵循一个固定的蒙特卡洛模拟方案。\n\n总体过程包括遍历每个提供的测试用例，并在每个用例中遍历每个基因。对于每个基因，我们执行后验预测模拟以生成检验统计量（零分数）的分布，然后将其与该统计量的经验观测值进行比较。\n\n分步算法如下：\n\n1.  **初始化**：为每个测试用例初始化分析。给定基因数 $G$、细胞数 $N$、观测计数矩阵 $X \\in \\mathbb{N}_{0}^{G \\times N}$，以及一组后验超参数 $\\{(a_g,b_g,k_g,\\theta_g)\\}_{g=1}^{G}$。使用指定的值 $s = 314159$ 为伪随机数生成器设定种子，以确保可复现性。蒙特卡洛抽样次数固定为 $D = 400$。\n\n2.  **按基因计算**：计算的核心是按基因逐个执行的，对于 $g = 1, \\dots, G$。\n\n    a. **计算经验零计数**：首先，从数据矩阵 $X$ 中确定基因 $g$ 的观测零计数值：\n    $$\n    \\hat{U}_g = \\sum_{i=1}^{N} \\mathbf{1}\\{X_{g,i} = 0\\}\n    $$\n    经验零分数则为 $\\hat{z}_g = \\hat{U}_g / N$。\n\n    b. **后验预测模拟**：接下来，我们从模型的后验预测分布中生成 $D$ 组模拟数据。\n    \n    i.  从其后验分布 $\\mathrm{Beta}(a_g, b_g)$ 中抽取 $D$ 个 dropout 概率样本 $\\{\\pi_g^{(d)}\\}_{d=1}^D$。\n    \n    ii. 从其后验分布 $\\mathrm{Gamma}(k_g, \\theta_g)$ 中抽取 $D$ 个平均计数率样本 $\\{\\lambda_g^{(d)}\\}_{d=1}^D$。Gamma 分布由形状参数 $k_g$ 和尺度参数 $\\theta_g$ 参数化。\n    \n    iii. 对于每次后验抽样 $d$，计算观测到零的模型隐含概率。零可能源于 dropout 事件（概率 $\\pi_g^{(d)}$）或源于泊松分量产生零计数（概率 $(1 - \\pi_g^{(d)}) \\cdot \\exp(-\\lambda_g^{(d)})$）。零的总概率是这些互斥事件的概率之和：\n    $$\n    q_g^{(d)} = \\pi_g^{(d)} + (1 - \\pi_g^{(d)}) \\exp(-\\lambda_g^{(d)})\n    $$\n    \n    iv. 对于每个 $d$，通过从二项分布中抽样，模拟在 $N$ 个细胞样本中将观测到的零的数量 $U_g^{(d)}$：\n    $$\n    U_g^{(d)} \\sim \\mathrm{Binomial}(N, q_g^{(d)})\n    $$\n    这个集合 $\\{U_g^{(d)}\\}_{d=1}^D$ 代表基因 $g$ 的零计数的后验预测分布。模拟的零分数为 $\\tilde{z}_g^{(d)} = U_g^{(d)} / N$。\n\n    c. **计算各基因的度量**：使用经验零计数 $\\hat{U}_g$ 和模拟的零计数 $\\{U_g^{(d)}\\}_{d=1}^D$，我们计算基因 $g$ 所需的度量。为了数值稳定性，比较是在整数计数 $U_g$ 上进行的，而不是在分数值 $z_g$ 上。\n    \n    i. **双边 P 值 ($t_g$)**：单边 p 值 $p_g$ 是根据蒙特卡洛抽样估计的，并包含了指定的平局处理规则：\n    $$\n    p_g \\approx \\frac{1}{D} \\left( \\sum_{d=1}^D \\mathbf{1}\\{U_g^{(d)}  \\hat{U}_g\\} + \\frac{1}{2} \\sum_{d=1}^D \\mathbf{1}\\{U_g^{(d)} = \\hat{U}_g\\} \\right)\n    $$\n    然后双边 p 值 $t_g$ 计算如下：\n    $$\n    t_g = 2 \\cdot \\min(p_g, 1 - p_g)\n    $$\n    $t_g$ 的小值表明模型的预测与观测数据之间存在差异。\n    \n    ii. **过度插补惩罚分数项**：计算基因 $g$ 对总 $\\mathrm{OPS}$ 的贡献。该项衡量了模型的模拟零分数 $\\tilde{z}_g^{(d)}$ 小于经验零分数 $\\hat{z}_g$ 的平均程度。\n    $$\n    \\text{OPS}_g = \\frac{1}{D} \\sum_{d=1}^{D} \\max(0, \\hat{z}_g - \\tilde{z}_g^{(d)}) = \\frac{1}{N \\cdot D} \\sum_{d=1}^{D} \\max(0, \\hat{U}_g - U_g^{(d)})\n    $$\n\n3.  **度量聚合**：在计算完一个测试用例中所有 $G$ 个基因的度量后，将它们进行聚合。\n\n    a. 平均双边 p 值通过对单个 $t_g$ 值求平均来计算：\n    $$\n    \\bar{t} = \\frac{1}{G} \\sum_{g=1}^{G} t_g\n    $$\n\n    b. 最终的 $\\mathrm{OPS}$ 通过对每个基因的贡献求平均来计算：\n    $$\n    \\mathrm{OPS} = \\frac{1}{G} \\sum_{g=1}^{G} \\mathrm{OPS}_g\n    $$\n\n4.  **最终输出**：对于每个测试用例，计算得到的值对 $(\\bar{t}, \\mathrm{OPS})$。每个值都四舍五入到 6 位小数并格式化为字符串。然后将所有结果连接成一个指定的逗号分隔列表。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    为零膨胀泊松模型计算后验预测检验。\n    对于每个测试用例，它根据一个固定的蒙特卡洛模拟方案\n    计算平均双边 p 值 (t_bar) 和一个过度插补惩罚分数 (OPS)。\n    \"\"\"\n    # Set the fixed random seed for reproducibility\n    s = 314159\n    rng = np.random.default_rng(s)\n    # Number of Monte Carlo draws per gene\n    D = 400\n\n    test_cases = [\n        # Case 1: happy path, mixed dropout levels\n        {\n            \"G\": 3, \"N\": 30,\n            \"X\": np.array([\n                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,1,4,2,1,3,2,5,1,2,3,2,4],\n                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,2,1,1,3],\n                [0,0,0,1,2,2,1,3,1,2,4,1,2,3,1,2,1,1,3,2,2,4,3,1,2,1,2,3,1,2]\n            ]),\n            \"hyperparams\": [(5, 5, 5, 0.5), (8, 2, 2, 0.5), (1, 9, 5, 0.5)]\n        },\n        # Case 2: overimputation stress\n        {\n            \"G\": 2, \"N\": 40,\n            \"X\": np.array([\n                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,2],\n                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,1,3,1,2,2,1,3,1,2,1,3,2,1,2,3,1,2,1]\n            ]),\n            \"hyperparams\": [(2, 8, 3, 0.5), (3, 3, 4, 0.5)]\n        },\n        # Case 3: edge case, an all-zeros gene\n        {\n            \"G\": 2, \"N\": 25,\n            \"X\": np.array([\n                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n                [0,0,0,0,0,1,1,2,1,3,2,1,2,1,3,1,2,1,2,1,3,1,2,1,2]\n            ]),\n            \"hyperparams\": [(1, 4, 2, 0.5), (1, 4, 3, 0.5)]\n        },\n        # Case 4: edge case, no zeros gene\n        {\n            \"G\": 1, \"N\": 20,\n            \"X\": np.array([\n                [1,1,2,1,2,1,1,2,1,2,1,1,3,2,1,2,1,2,1,3]\n            ]),\n            \"hyperparams\": [(1, 19, 4, 0.5)]\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        G = case[\"G\"]\n        N = case[\"N\"]\n        X_matrix = case[\"X\"]\n        hyperparams = case[\"hyperparams\"]\n        \n        gene_t_values = []\n        gene_ops_terms = []\n\n        for g in range(G):\n            # Step 1: Calculate empirical zero count\n            observed_counts = X_matrix[g]\n            hat_U_g = np.sum(observed_counts == 0)\n            \n            # Step 2: Posterior predictive simulation\n            a_g, b_g, k_g, theta_g = hyperparams[g]\n            \n            pi_g_draws = rng.beta(a_g, b_g, size=D)\n            lambda_g_draws = rng.gamma(k_g, theta_g, size=D)\n            \n            q_g_draws = pi_g_draws + (1 - pi_g_draws) * np.exp(-lambda_g_draws)\n            q_g_draws = np.clip(q_g_draws, 0, 1) # Safeguard for floating point precision\n\n            U_g_draws = rng.binomial(N, q_g_draws)\n            \n            # Step 3: Calculate per-gene metrics\n            \n            # Two-sided p-value (t_g)\n            n_less = np.sum(U_g_draws  hat_U_g)\n            n_equal = np.sum(U_g_draws == hat_U_g)\n            p_g = (n_less + 0.5 * n_equal) / D\n            t_g = 2 * min(p_g, 1 - p_g)\n            gene_t_values.append(t_g)\n            \n            # Overimputation-Penalizing Score (OPS) term\n            ops_term_g = np.mean(np.maximum(0, hat_U_g - U_g_draws)) / N\n            gene_ops_terms.append(ops_term_g)\n            \n        # Step 4: Aggregate metrics for the test case\n        t_bar = np.mean(gene_t_values)\n        ops_metric = np.mean(gene_ops_terms)\n        \n        all_results.append(\"{:.6f}\".format(t_bar))\n        all_results.append(\"{:.6f}\".format(ops_metric))\n\n    # Final output formatting\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3349820"}]}