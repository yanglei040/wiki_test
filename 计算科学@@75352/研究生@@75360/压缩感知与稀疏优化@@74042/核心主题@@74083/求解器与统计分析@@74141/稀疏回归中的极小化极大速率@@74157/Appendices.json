{"hands_on_practices": [{"introduction": "正交模型虽然是一种理想化情况，但它为我们分析稀疏回归问题提供了一个至关重要的起点。通过消除不同预测变量之间的相关性，该模型使我们能够将稀疏性带来的统计挑战与代数复杂性分离开来。本练习将引导你推导出著名的 $s \\log(p/s)$ 速率及其精确的前导常数，从而揭示在高维空间中进行变量选择所需付出的基本代价 [@problem_id:3460036]。", "problem": "考虑正交线性模型 $y = X \\beta^{\\star} + \\varepsilon$，其中 $X \\in \\mathbb{R}^{n \\times p}$ 满足 $X^{\\top} X = n I_{p}$，噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$，参数 $\\beta^{\\star} \\in \\mathbb{R}^{p}$ 服从硬稀疏性约束 $\\|\\beta^{\\star}\\|_{0} \\le s$。设估计风险为最坏情况下的均方误差 $R_{n,p,s} = \\inf_{\\widehat{\\beta}} \\sup_{\\|\\beta\\|_{0} \\le s} \\mathbb{E}\\big[\\|\\widehat{\\beta} - \\beta\\|_{2}^{2}\\big]$。在 $p \\to \\infty$、$s = s(p) \\to \\infty$ 且 $s = o(p)$ 的渐近状态下进行分析，并假设估计量可以依赖于 $(n,p,s,\\sigma)$ 但不依赖于 $\\beta^{\\star}$。\n\n通过正交设计将模型简化为高斯序列形式，并分析应用于最小二乘得分 $z = \\frac{1}{n} X^{\\top} y$ 的逐坐标阈值估计量类别。在所有此类阈值估计量中，优化调整阈值（作为 $(n,p,s,\\sigma)$ 的函数）以最小化最坏情况下的风险。从极小化极大风险、信息论下界和高斯尾部近似的核心定义出发，推导 $R_{n,p,s}$ 的渐近精确首项并确定其首项系数。你的最终答案必须是该首项关于 $(n,p,s,\\sigma)$ 的单个闭式解析表达式，无需四舍五入，也无单位。", "solution": "该问题要求在一个正交线性模型中，为稀疏参数向量的极小化极大估计风险找到其渐近精确首项。我们将首先验证问题陈述，然后从基本原理推导解答。\n\n### 第 1 步：提取已知条件\n- **模型**：正交线性模型 $y = X \\beta^{\\star} + \\varepsilon$。\n- **设计矩阵**：$X \\in \\mathbb{R}^{n \\times p}$，其性质为 $X^{\\top} X = n I_{p}$。\n- **噪声**：$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。\n- **参数空间**：真实参数向量 $\\beta^{\\star} \\in \\mathbb{R}^{p}$ 是稀疏的，满足约束 $\\|\\beta^{\\star}\\|_{0} \\le s$，其中 $\\|\\cdot\\|_0$ 是计算非零元素数量的 $\\ell_0$-“范数”。\n- **风险函数**：估计风险是在指定参数空间上的最坏情况均方误差 (MSE)：$R_{n,p,s} = \\inf_{\\widehat{\\beta}} \\sup_{\\|\\beta\\|_{0} \\le s} \\mathbb{E}\\big[\\|\\widehat{\\beta} - \\beta\\|_{2}^{2}\\big]$。\n- **估计量约束**：估计量 $\\widehat{\\beta}$ 可以依赖于已知量 $(n,p,s,\\sigma)$，但不能依赖于未知的真实参数 $\\beta^{\\star}$。\n- **渐近状态**：我们考虑 $p \\to \\infty$、$s = s(p) \\to \\infty$ 且 $s = o(p)$ 的情况。\n\n### 第 2 步：使用提取的已知条件进行验证\n根据指定标准对问题进行验证。\n- **科学依据**：该问题是理论高维统计和压缩感知中的一个经典设定。正交线性模型是分析维度、稀疏性和统计风险之间基本权衡的标准框架。所有概念（极小化极大风险、$\\ell_0$-稀疏性、高斯噪声）在数理统计学中都有严格的定义。\n- **良构性**：该问题是良构的。它要求在一个明确指定的参数空间上，对于一个特定的损失函数（平方 $\\ell_2$-误差），求一个明确定义的数学量（极小化极大风险）的渐近值。唯一极限值的存在性是一个已知的理论结果。\n- **客观性**：问题陈述完全客观，并使用精确的数学语言。没有主观或基于意见的成分。\n- **完整性和一致性**：该问题提供了进行推导所需的所有必要信息。正交设计简化了协方差结构，稀疏性约束恰当地定义了参数空间。给定信息中没有矛盾之处。\n- **现实性**：虽然正交设计 ($X^\\top X = nI_p$) 是一种理想化情况，但它作为一个关键的理论模型，将稀疏性的统计困难与相关预测变量的代数困难分离开来。它是该领域的基石。\n- **非平凡性**：该问题并非平凡。推导极小化极大率，特别是其精确的首项系数，需要统计决策理论中的高级概念，包括信息论下界和最优估计量的分析。\n\n### 第 3 步：结论与行动\n问题陈述是理论统计学中一个有效、良构且非平凡的问题。我们将着手全面推导其解。\n\n### 解的推导\n\n推导过程主要分三步：\n1.  将线性模型简化为等价的高斯序列模型。\n2.  通过一个已知的等价原理，将频率学派的极小化极大风险与相应的贝叶斯极小化极大风险联系起来。\n3.  解决更简单的单参数贝叶斯问题，以找到收敛率和常数。\n\n**1. 简化为高斯序列模型**\n\n我们首先变换观测向量 $y$ 以简化问题结构。我们定义最小二乘得分向量 $z \\in \\mathbb{R}^p$ 为：\n$$ z = \\frac{1}{n} X^{\\top} y $$\n代入模型方程 $y = X \\beta^{\\star} + \\varepsilon$，我们得到：\n$$ z = \\frac{1}{n} X^{\\top} (X \\beta^{\\star} + \\varepsilon) = \\frac{1}{n} (X^{\\top} X) \\beta^{\\star} + \\frac{1}{n} X^{\\top} \\varepsilon $$\n使用正交性条件 $X^{\\top} X = n I_{p}$，上式简化为：\n$$ z = \\beta^{\\star} + \\frac{1}{n} X^{\\top} \\varepsilon $$\n我们将这个新模型中的噪声项定义为 $w = \\frac{1}{n} X^{\\top} \\varepsilon$。由于 $\\varepsilon$ 是一个高斯随机向量，$w$ 作为 $\\varepsilon$ 的线性变换，也是高斯的。我们计算它的均值和协方差：\n$$ \\mathbb{E}[w] = \\frac{1}{n} X^{\\top} \\mathbb{E}[\\varepsilon] = \\frac{1}{n} X^{\\top} 0 = 0 $$\n$$ \\text{Cov}(w) = \\mathbb{E}[w w^{\\top}] = \\mathbb{E}\\left[ \\left(\\frac{1}{n} X^{\\top} \\varepsilon\\right) \\left(\\frac{1}{n} \\varepsilon^{\\top} X\\right) \\right] = \\frac{1}{n^2} X^{\\top} \\mathbb{E}[\\varepsilon \\varepsilon^{\\top}] X = \\frac{1}{n^2} X^{\\top} (\\sigma^2 I_n) X = \\frac{\\sigma^2}{n^2} (X^{\\top} X) $$\n再次使用 $X^{\\top} X = n I_p$，我们得到协方差：\n$$ \\text{Cov}(w) = \\frac{\\sigma^2}{n^2} (n I_p) = \\frac{\\sigma^2}{n} I_p $$\n这意味着向量 $w$ 的分量 $w_j$ 是独立同分布的，服从 $w_j \\sim \\mathcal{N}(0, \\frac{\\sigma^2}{n})$。\n\n因此，原始线性模型等价于规范的高斯序列模型：\n$$ z_j = \\beta^{\\star}_j + w_j, \\quad \\text{对于 } j = 1, \\dots, p $$\n其中 $w_j \\stackrel{i.i.d.}{\\sim} \\mathcal{N}(0, \\sigma_n^2)$ 且 $\\sigma_n^2 = \\frac{\\sigma^2}{n}$。由于 $z = \\frac{1}{n}X^\\top y$ 是 $\\beta^\\star$ 的一个充分统计量，风险保持不变：\n$$ R_{n,p,s} = \\inf_{\\widehat{\\beta}} \\sup_{\\|\\beta\\|_{0} \\le s} \\mathbb{E}\\big[\\|\\widehat{\\beta}(z) - \\beta\\|_{2}^{2}\\big] $$\n\n**2. 与贝叶斯极小化极大风险的联系**\n\n统计理论中的一个深刻结果（特别是 Johnstone 和 Silverman 的工作）将稀疏集上的频率学派极小化极大风险与一个更简单的贝叶斯风险问题联系起来。$p$ 维问题的风险渐近地等于单个坐标的极小化极大贝叶斯风险的 $s$ 倍，其中坐标非零的先验概率为 $\\epsilon = s/p$。\n\n设 $r(\\epsilon)$ 是在先验条件下，从观测值 $y \\sim \\mathcal{N}(\\theta, \\sigma_n^2)$ 估计单个参数 $\\theta$ 的极小化极大贝叶斯风险，该先验条件为 $\\theta = 0$ 的概率是 $1-\\epsilon$，$\\theta \\sim G$ 的概率是 $\\epsilon$。风险为 $r(\\epsilon) = \\sup_G \\inf_{\\hat{\\theta}} \\mathbb{E}[(\\hat{\\theta}-\\theta)^2]$，其中 $G$ 是非零分量的任意分布。该等价关系表明：\n$$ R_{n,p,s} \\sim s \\cdot r(s/p) \\quad \\text{当 } p \\to \\infty, s \\to \\infty, s/p \\to 0 $$\n\n我们的任务现在简化为找到 $r(\\epsilon)$ 在 $\\epsilon \\to 0$ 时的渐近形式。\n\n**3. 单参数贝叶斯风险的渐近分析**\n\n我们来分析一个标准高斯变量 $y \\sim \\mathcal{N}(\\theta, 1)$ 的单参数问题，并在最后重新引入方差 $\\sigma_n^2$。先验是 $\\theta=0$ 的概率为 $1-\\epsilon$，$\\theta \\sim G$ 的概率为 $\\epsilon$。贝叶斯估计量是后验均值 $\\hat\\theta(y) = \\mathbb{E}[\\theta|y]$。\n\n区分信号与噪声的最坏情况（最不利先验）发生在信号幅度难以检测时。对于小的 $\\epsilon$，最不利先验 $G$ 将其质量集中在一个临界幅度周围。具体来说，它是在 $\\pm \\mu_\\epsilon$ 处有原子的两点先验。\n所以，我们考虑先验分布：\n$$ \\theta = \\begin{cases} 0  \\text{概率为 } 1-\\epsilon \\\\ \\mu_\\epsilon  \\text{概率为 } \\epsilon/2 \\\\ -\\mu_\\epsilon  \\text{概率为 } \\epsilon/2 \\end{cases} $$\n问题的核心是确定临界幅度 $\\mu_\\epsilon$，它使得在 $\\theta=0$ 和 $\\theta \\in \\{\\pm \\mu_\\epsilon\\}$ 之间的假设检验最为困难。当似然比的量级为 1 时，达到这种平衡。检验 $\\theta = \\mu_\\epsilon$ 与 $\\theta = 0$ 的对数似然比是 $\\mu_\\epsilon y - \\mu_\\epsilon^2/2$。为了使检验非平凡，原假设和备择假设下检验统计量的分布必须有显著重叠。这导致信号强度 $\\mu_\\epsilon^2$ 必须与备择假设的对数优势比（即 $\\log((1-\\epsilon)/\\epsilon) \\approx \\log(1/\\epsilon)$）成比例。\n详细分析表明，可检测性阈值由下式给出：\n$$ \\mu_\\epsilon^2 \\sim 2 \\log(1/\\epsilon) $$\n当信号幅度选择接近此临界值时，可以计算此单参数问题的贝叶斯风险。风险主要由被错误识别为噪声的信号所贡献。对于幅度为 $\\mu_\\epsilon$ 的信号，如果它被漏检，则平方误差为 $\\mu_\\epsilon^2$。在最困难的配置中，漏检的概率约为 $1/2$。可以证明，在这种情况下，贝叶斯规则的风险为：\n$$ r(\\epsilon) \\sim \\mu_\\epsilon^2 \\sim 2\\log(1/\\epsilon) \\quad \\text{当 } \\epsilon \\to 0 $$\n将此结果按噪声方差 $\\sigma_n^2$进行缩放，单参数的极小化极大贝叶斯风险为：\n$$ r(\\epsilon) \\sim 2\\sigma_n^2 \\log(1/\\epsilon) $$\n\n**4. 整合最终结果**\n\n现在我们将其代回总极小化极大风险 $R_{n,p,s}$ 的表达式中。我们有 $\\epsilon = s/p$ 和 $\\sigma_n^2 = \\sigma^2/n$：\n$$ R_{n,p,s} \\sim s \\cdot r(s/p) \\sim s \\cdot \\left[ 2 \\sigma_n^2 \\log\\left(\\frac{1}{s/p}\\right) \\right] $$\n$$ R_{n,p,s} \\sim s \\cdot \\left[ 2 \\frac{\\sigma^2}{n} \\log\\left(\\frac{p}{s}\\right) \\right] $$\n整理各项，得到渐近极小化极大风险首项的最终表达式：\n$$ R_{n,p,s} \\sim 2 \\frac{\\sigma^2}{n} s \\log\\left(\\frac{p}{s}\\right) $$\n该表达式量化了高维估计的基本代价。风险取决于噪声水平 ($\\sigma^2$)、样本量 ($n$)、稀疏度 ($s$)，以及关键的对数因子 $\\log(p/s)$，它代表了在 $p$ 种可能性中不知道 $s$ 个非零系数位置的惩罚。最优估计量是一种基于阈值的方法，其阈值调整为 $\\lambda \\sim \\sqrt{2\\sigma_n^2 \\log(p/s)}$，它渐近地达到这个风险，从而证实了这就是极小化极大率。首项系数是 2。", "answer": "$$\\boxed{2 \\frac{\\sigma^{2}}{n} s \\log\\left(\\frac{p}{s}\\right)}$$", "id": "3460036"}, {"introduction": "在实际应用中，我们很少遇到具有完美正交性的设计矩阵。本练习旨在探讨设计矩阵的性质如何影响 minimax 下界，这通常通过受限特征值（Restricted Eigenvalue, RE）条件来刻画。通过比较一般固定设计与随机高斯设计，你将运用信息论工具来理解设计矩阵的“质量”如何直接影响最终可达到的估计精度 [@problem_id:3460032]。", "problem": "考虑带有高斯噪声的线性回归模型，其中观测向量为 $y \\in \\mathbb{R}^{n}$，满足 $y = X \\beta^{\\star} + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。未知的回归向量 $\\beta^{\\star} \\in \\mathbb{R}^{p}$ 是 $s$-稀疏的，意味着它属于参数类 $\\Theta_{s} = \\{ \\beta \\in \\mathbb{R}^{p} : \\|\\beta\\|_{0} \\leq s \\}$。\n\n考虑两种设计情景：\n- 高斯设计：$X$ 的行独立同分布于 $\\mathcal{N}(0, I_{p})$，因此对于任何固定的 $v \\in \\mathbb{R}^{p}$，$\\|X v\\|_{2}^{2}$ 集中在 $n \\|v\\|_{2}^{2}$ 附近。\n- 固定设计：矩阵 $X$ 是确定性的，并满足在所有大小至多为 $s$ 的支撑集上的一个一致受限上特征值界，定义为\n$$\n\\psi_{+}(s) := \\max_{S \\subseteq \\{1,\\dots,p\\},\\, |S|\\le s} \\lambda_{\\max}\\!\\left( \\frac{X_{S}^{\\top} X_{S}}{n} \\right) = \\gamma,\n$$\n对于一个已知常数 $\\gamma > 0$，其中 $X_{S}$ 表示由 $X$ 中以 $S$ 为索引的列所形成的子矩阵。\n\n从信息论原理出发，特别是高斯位置模型的 Kullback–Leibler 散度和 Fano 方法，并利用对 $s$-稀疏参数类 $\\Theta_{s}$ 的体积或组合堆积论证，推导在每种设计情景下，对 $\\Theta_{s}$ 的均方 $\\ell_{2}$ 估计误差的主阶极小化极大下界（在普适绝对常数范围内）。然后，计算这两个主阶下界的比率（固定设计除以高斯设计），并将其纯粹表示为 $\\gamma$ 的函数。\n\n你的最终答案必须是单一的封闭形式解析表达式。不需要四舍五入，也不适用物理单位。", "solution": "目标是在线性模型 $y = X \\beta^{\\star} + \\varepsilon$（其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$）中，为一个 $s$-稀疏向量 $\\beta^{\\star} \\in \\Theta_s = \\{ \\beta \\in \\mathbb{R}^{p} : \\|\\beta\\|_{0} \\leq s \\}$ 的均方 $\\ell_2$ 估计误差推导其极小化极大下界。极小化极大风险定义为：\n$$ R_s := \\inf_{\\hat{\\beta}} \\sup_{\\beta^{\\star} \\in \\Theta_s} \\mathbb{E}[\\|\\hat{\\beta} - \\beta^{\\star}\\|_2^2] $$\n其中下确界取遍 $\\beta^{\\star}$ 的所有可能估计量 $\\hat{\\beta}$。\n\n我们将使用信息论工具，特别是 Fano 方法，来推导该下界。Fano 方法将多重假设检验问题中的错误概率与分布之间的 Kullback-Leibler (KL) 散度联系起来。\n\n### 通用下界框架\n\nFano 方法需要在参数空间 $\\Theta_s$ 内构造一个由良好分离的点组成的“堆积集”。设 $\\{\\beta_1, \\ldots, \\beta_M\\}$ 是 $\\Theta_s$ 的一个子集，使得对于某个 $\\delta > 0$，对所有 $j \\neq k$ 都有两两间距 $\\|\\beta_j - \\beta_k\\|_2 \\ge 2\\delta$。设 $\\hat{\\beta}$ 为任意估计量。我们可以定义一个决策规则 $\\hat{\\jmath} = \\arg\\min_{j \\in \\{1,\\dots,M\\}} \\|\\hat{\\beta} - \\beta_j\\|_2$。如果 $\\|\\hat{\\beta} - \\beta_j\\|_2  \\delta$，那么根据三角不等式，对于任何 $k \\neq j$，有 $\\|\\hat{\\beta} - \\beta_k\\|_2 \\ge \\|\\beta_j - \\beta_k\\|_2 - \\|\\hat{\\beta} - \\beta_j\\|_2  2\\delta - \\delta = \\delta$。因此，如果估计误差 $\\|\\hat{\\beta} - \\beta_j\\|_2 \\ge \\delta$，则会发生解码索引错误，即 $\\hat{\\jmath} \\neq j$。\n\n在这个特定集合上的平均风险是极小化极大风险的一个下界：\n$$ \\sup_{\\beta \\in \\Theta_s} \\mathbb{E}[\\|\\hat{\\beta} - \\beta\\|_2^2] \\ge \\frac{1}{M} \\sum_{j=1}^M \\mathbb{E}_j[\\|\\hat{\\beta} - \\beta_j\\|_2^2] \\ge \\frac{1}{M} \\sum_{j=1}^M \\delta^2 P_j(\\|\\hat{\\beta} - \\beta_j\\|_2 \\ge \\delta) \\ge \\delta^2 P_e $$\n其中 $P_e = \\min_j P_j(\\hat{\\jmath} \\neq j)$ 是最小错误概率。\n\nFano 不等式给出了 $P_e$ 的一个下界：\n$$ P_e \\ge 1 - \\frac{I(Y; J) + \\log 2}{\\log M} $$\n其中 $J$ 是从 $\\{1, \\dots, M\\}$ 中均匀选取的一个随机变量，$I(Y; J)$ 是数据 $Y$ 和索引 $J$ 之间的互信息。互信息可以由分布 $P_j = \\mathcal{N}(X\\beta_j, \\sigma^2 I_n)$ 之间的最大成对 KL 散度来界定：\n$$ I(Y; J) \\le \\max_{j, k \\in \\{1, \\dots, M\\}} D_{KL}(P_j \\| P_k) $$\n我们的高斯模型的 KL 散度为：\n$$ D_{KL}(P_j \\| P_k) = \\frac{1}{2\\sigma^2} \\|X\\beta_j - X\\beta_k\\|_2^2 = \\frac{1}{2\\sigma^2} \\|X(\\beta_j - \\beta_k)\\|_2^2 $$\n为了获得一个非平凡的下界（即 $P_e  0$），我们需要 $I(Y; J)  \\log(M/2)$。\n\n### 堆积集的构造\n\n一个关键要素是构造堆积集 $\\{\\beta_j\\}$。我们依赖于对 $s$-稀疏向量集的组合堆积论证。一个标准结果是，对于 $s \\le p/2$，可以构造一个 $s$-稀疏向量集 $\\{\\beta_1, \\dots, \\beta_M\\}$，使其满足：\n1.  对所有 $j=1, \\dots, M$，有 $\\|\\beta_j\\|_0 \\le s$。\n2.  该集合是分离的：对所有 $j \\neq k$，有 $\\|\\beta_j - \\beta_k\\|_2^2 \\ge \\Delta^2$。\n3.  集合的大小 $M$ 很大，满足 $\\log M \\ge C_0 s \\log(p/s)$，其中 $C_0  0$ 是某个普适常数。\n\n对于这样的集合，如果我们能满足 Fano 条件 $\\max_{j,k} D_{KL}(P_j \\| P_k) \\lesssim s \\log(p/s)$，则我们有极小化极大下界 $R_s \\gtrsim \\Delta^2$。\n\n### 界定 KL 散度\n\n让我们来界定 KL 散度。设 $v_{jk} = \\beta_j - \\beta_k$。$v_{jk}$ 的支撑集大小至多为 $2s$。设 $S_{jk} = \\text{supp}(v_{jk})$。\n$$ \\|X v_{jk}\\|_2^2 = v_{jk}^T X^T X v_{jk} = n \\cdot v_{jk}^T \\left(\\frac{X^T X}{n}\\right) v_{jk} \\le n \\|v_{jk}\\|_2^2 \\lambda_{\\max}\\left(\\frac{X_{S_{jk}}^T X_{S_{jk}}}{n}\\right) $$\n根据 $\\psi_+(s')$ 的定义，我们有 $\\lambda_{\\max}\\left(\\frac{X_{S_{jk}}^T X_{S_{jk}}}{n}\\right) \\le \\psi_+(|S_{jk}|) \\le \\psi_+(2s)$。因此，\n$$ D_{KL}(P_j \\| P_k) \\le \\frac{n}{2\\sigma^2} \\|\\beta_j - \\beta_k\\|_2^2 \\psi_+(2s) $$\n堆积集的构造可以被精细化，以确保 $\\|\\beta_j - \\beta_k\\|_2^2$ 不会过大。将此构造与 Fano 条件相结合，详细分析表明我们可以选择间距 $\\Delta^2$ 使得：\n$$ \\Delta^2 \\asymp \\frac{\\sigma^2 s \\log(p/s)}{n \\psi_+(2s)} $$\n此处，“$\\asymp$” 表示在普适常数意义下的相等。风险的下界与此间距同阶：\n$$ R_s \\gtrsim \\frac{\\sigma^2 s \\log(p/s)}{n \\psi_+(2s)} $$\n在这种情况下，标准做法是假设受限特征值常数不会随着稀疏度的变化而显著改变，即 $\\psi_+(2s)$ 与 $\\psi_+(s)$ 同阶。因此，我们将主阶下界写为：\n$$ L = C \\frac{\\sigma^2 s \\log(p/s)}{n \\psi_+(s)} $$\n其中 $C$ 是一个普适常数。\n\n### 在两种设计情景中的应用\n\n我们现在将这个一般性结果应用于两种指定的情景。\n\n**1. 固定设计：**\n问题陈述中给出，对于固定设计矩阵 $X$，我们有：\n$$ \\psi_{+}(s) = \\max_{S \\subseteq \\{1,\\dots,p\\},\\, |S|\\le s} \\lambda_{\\max}\\!\\left( \\frac{X_{S}^{\\top} X_{S}}{n} \\right) = \\gamma $$\n将此直接代入我们的一般下界表达式，得到固定设计情况下的主阶下界：\n$$ L_{\\text{fixed}} = C \\frac{\\sigma^2 s \\log(p/s)}{n \\gamma} $$\n\n**2. 高斯设计：**\n设计矩阵 $X$ 的各行是独立同分布的 $\\mathcal{N}(0, I_p)$。问题指出，对于任意固定向量 $v \\in \\mathbb{R}^p$，$\\|Xv\\|_2^2$ 集中在 $n\\|v\\|_2^2$ 附近。这个性质，当一致地推广到所有 $s$-稀疏向量时，被称为受限等距性质 (Restricted Isometry Property, RIP)。对于一个具有独立同分布高斯项的随机矩阵，根据随机矩阵理论的一个公认结果，当 $n \\gtrsim s\\log(p/s)$ 时，量 $\\psi_+(s)$ 会以高概率强集中在其期望值 1 附近。\n$$ \\psi_{+}(s) = \\max_{|S|\\le s} \\lambda_{\\max}\\!\\left( \\frac{X_{S}^{\\top} X_{S}}{n} \\right) \\approx 1 $$\n这个矩阵集合的极小化极大率反映了这种典型行为。因此，对于高斯设计，我们在公式中使用 $\\psi_+(s)=1$。\n高斯设计情况下的主阶下界是：\n$$ L_{\\text{Gauss}} = C \\frac{\\sigma^2 s \\log(p/s)}{n \\cdot 1} = C \\frac{\\sigma^2 s \\log(p/s)}{n} $$\n\n### 下界之比\n\n最后，我们计算固定设计的主阶下界与高斯设计的主阶下界之比。\n$$ \\text{Ratio} = \\frac{L_{\\text{fixed}}}{L_{\\text{Gauss}}} = \\frac{C \\frac{\\sigma^2 s \\log(p/s)}{n \\gamma}}{C \\frac{\\sigma^2 s \\log(p/s)}{n}} $$\n项 $C$, $\\sigma^2$, $s$, $n$, 和 $\\log(p/s)$ 相互抵消，得到：\n$$ \\text{Ratio} = \\frac{1}{\\gamma} $$\n这个比率纯粹表示为给定常数 $\\gamma$ 的函数。", "answer": "$$\\boxed{\\frac{1}{\\gamma}}$$", "id": "3460032"}, {"introduction": "经典线性回归理论通常假设噪声服从高斯分布，然而这一假设在许多真实场景中并不成立。本练习将带你应对重尾噪声分布的挑战，在这种情况下，传统的最小二乘法可能会失效。你将通过分析一种稳健的M估计量——Huber-Lasso，学习如何调整估计算法以适应非理想的噪声环境，并分析其性能，这是进行可靠数据分析的一项关键技能 [@problem_id:3460066]。", "problem": "考虑一个稀疏线性回归模型，其观测值为独立同分布的 $\\{(x_i, y_i)\\}_{i=1}^{n}$，\n$$\ny_i \\;=\\; x_i^{\\top} \\beta^{\\star} \\;+\\; \\varepsilon_i,\\quad i \\in \\{1,\\dots,n\\},\n$$\n其中 $x_i \\in \\mathbb{R}^{p}$ 是独立的特征向量，其分布以零为中心，协方差为单位矩阵，并且在 $s$-稀疏方向上满足通常的限制性特征值条件，而 $\\beta^{\\star} \\in \\mathbb{R}^{p}$ 是 $s$-稀疏的。假设噪声 $\\varepsilon_i$ 独立于 $x_i$，并服从形状参数 $\\alpha = 3$、尺度参数 $\\lambda  0$ 的对称 Lomax (第二类帕累托) 分布；也就是说，对于 $t \\geq 0$，\n$$\n\\mathbb{P}\\!\\left(|\\varepsilon_i|  t\\right) \\;=\\; \\left(1 + \\frac{t}{\\lambda}\\right)^{-3}.\n$$\n我们考虑一类结合了 Huber 损失和 $\\ell_{1}$ 惩罚项的凸 M-估计量 (Huber-Lasso)。阈值为 $\\tau  0$ 的 Huber 损失定义为\n$$\n\\rho_{\\tau}(u) \\;=\\; \\begin{cases}\n\\frac{1}{2} u^{2},  |u| \\leq \\tau,\\\\\n\\tau |u| \\;-\\; \\frac{1}{2} \\tau^{2},  |u|  \\tau,\n\\end{cases}\n$$\n其影响函数为 $\\psi_{\\tau}(u) \\;=\\; \\rho_{\\tau}'(u) \\;=\\; \\begin{cases}\nu,  |u| \\leq \\tau,\\\\\n\\tau \\,\\mathrm{sign}(u),  |u|  \\tau,\n\\end{cases}\n$，导数为 $\\psi'_{\\tau}(u) \\;=\\; \\mathbf{1}\\{|u| \\leq \\tau\\}$（几乎处处成立）。在针对独立设计和误差的 M-估计渐近理论中，局部曲率（类费雪信息）因子为 $\\mathbb{E}\\!\\left[\\psi'_{\\tau}(\\varepsilon)\\right]$，而进入得分波动的有效噪声尺度为 $\\sqrt{\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right]}$。对于在限制性特征值和适当正则化水平下的稀疏回归，极小化极大 $\\ell_{2}$ 率中的前导常数由有效噪声尺度与曲率的比值控制。\n\n定义\n$$\nc(\\tau, \\lambda) \\;=\\; \\frac{\\sqrt{\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right]}}{\\mathbb{E}\\!\\left[\\psi'_{\\tau}(\\varepsilon)\\right]},\n$$\n其中 $\\varepsilon \\sim \\mathrm{Symmetric\\ Lomax}(3, \\lambda)$。设\n$$\nc^{\\star}(\\lambda) \\;=\\; \\inf_{\\tau  0} c(\\tau, \\lambda).\n$$\n从给定的模型和上述定义出发，仅使用稳健 M-估计中经过充分检验的事实，根据第一性原理推导出 $c^{\\star}(\\lambda)$ 的闭式解。将最终答案表示为关于 $\\lambda$ 的单个解析表达式。无需四舍五入，也不应包含单位。最终答案必须是一个计算结果。", "solution": "目标是计算 $c^{\\star}(\\lambda) = \\inf_{\\tau  0} c(\\tau, \\lambda)$，其中函数 $c(\\tau, \\lambda)$ 定义为：\n$$\nc(\\tau, \\lambda) \\;=\\; \\frac{\\sqrt{\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right]}}{\\mathbb{E}\\!\\left[\\psi'_{\\tau}(\\varepsilon)\\right]}\n$$\n噪声项 $\\varepsilon$ 服从形状参数为 $\\alpha = 3$、尺度参数为 $\\lambda  0$ 的对称 Lomax 分布，其特征是对于 $t \\ge 0$ 的尾部概率为 $\\mathbb{P}(|\\varepsilon|  t) = (1 + t/\\lambda)^{-3}$。函数 $\\psi_{\\tau}$ 和 $\\psi'_{\\tau}$ 与 Huber 损失相关，由 $\\psi_{\\tau}(u) = \\min(|u|, \\tau) \\mathrm{sign}(u)$ 和 $\\psi'_{\\tau}(u) = \\mathbf{1}\\{|u| \\le \\tau\\}$ 给出。\n\n首先，我们推导 $\\varepsilon$ 的概率密度函数 (PDF)。设 $F_{\\varepsilon}(t) = \\mathbb{P}(\\varepsilon \\le t)$ 为累积分布函数 (CDF)。由于对称性，对于 $t  0$，我们有 $\\mathbb{P}(\\varepsilon  t) = \\frac{1}{2}\\mathbb{P}(|\\varepsilon|  t) = \\frac{1}{2}(1 + t/\\lambda)^{-3}$。\n对于 $t  0$ 的 CDF 是 $F_{\\varepsilon}(t) = 1 - \\mathbb{P}(\\varepsilon  t) = 1 - \\frac{1}{2}(1 + t/\\lambda)^{-3}$。\n对于 $t  0$ 的 PDF 是 $f_{\\varepsilon}(t) = F'_{\\varepsilon}(t) = -\\frac{1}{2}(-3)(1 + t/\\lambda)^{-4}(\\frac{1}{\\lambda}) = \\frac{3}{2\\lambda}(1 + t/\\lambda)^{-4}$。\n根据对称性，对于任意 $t \\in \\mathbb{R}$，PDF 由以下公式给出：\n$$\nf_{\\varepsilon}(t) \\;=\\; \\frac{3}{2\\lambda}\\left(1 + \\frac{|t|}{\\lambda}\\right)^{-4}\n$$\n\n接下来，我们计算 $c(\\tau, \\lambda)$ 的分母，即局部曲率 $\\mathbb{E}\\!\\left[\\psi'_{\\tau}(\\varepsilon)\\right]$。\n$$\n\\mathbb{E}\\!\\left[\\psi'_{\\tau}(\\varepsilon)\\right] \\;=\\; \\mathbb{E}\\!\\left[\\mathbf{1}\\{|\\varepsilon| \\le \\tau\\}\\right] \\;=\\; \\mathbb{P}(|\\varepsilon| \\le \\tau) \\;=\\; 1 - \\mathbb{P}(|\\varepsilon|  \\tau)\n$$\n使用给定的尾部概率，我们得到：\n$$\n\\mathbb{E}\\!\\left[\\psi'_{\\tau}(\\varepsilon)\\right] \\;=\\; 1 - \\left(1 + \\frac{\\tau}{\\lambda}\\right)^{-3}\n$$\n\n现在，我们计算分子中的项 $\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right]$。函数 $\\psi_{\\tau}(u)^2$ 在 $|u| \\le \\tau$ 时为 $u^2$，在 $|u|  \\tau$ 时为 $\\tau^2$。\n$$\n\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right] \\;=\\; \\int_{-\\infty}^{\\infty} \\psi_{\\tau}(t)^2 f_{\\varepsilon}(t) dt \\;=\\; \\int_{-\\tau}^{\\tau} t^2 f_{\\varepsilon}(t) dt + \\int_{|t|\\tau} \\tau^2 f_{\\varepsilon}(t) dt\n$$\n第二项是 $\\tau^2 \\mathbb{P}(|\\varepsilon|  \\tau) = \\tau^2 (1 + \\tau/\\lambda)^{-3}$。\n对于第一项，我们利用 $t^2$ 和 $f_{\\varepsilon}(t)$ 的偶对称性：\n$$\n\\int_{-\\tau}^{\\tau} t^2 f_{\\varepsilon}(t) dt \\;=\\; 2 \\int_{0}^{\\tau} t^2 \\left(\\frac{3}{2\\lambda}\\left(1 + \\frac{t}{\\lambda}\\right)^{-4}\\right) dt \\;=\\; \\frac{3}{\\lambda} \\int_{0}^{\\tau} t^2 \\left(1 + \\frac{t}{\\lambda}\\right)^{-4} dt\n$$\n为了简化计算，我们引入变量 $z = 1 + \\tau/\\lambda$。\n分母是 $1 - z^{-3}$。\n项 $\\tau^2 \\mathbb{P}(|\\varepsilon|  \\tau)$ 变为 $(\\lambda(z-1))^2 z^{-3} = \\lambda^2 (z^2-2z+1)z^{-3} = \\lambda^2(z^{-1} - 2z^{-2} + z^{-3})$。\n\n对于积分部分，我们使用换元法 $u = 1 + t/\\lambda$，这意味着 $t = \\lambda(u-1)$ 且 $dt = \\lambda du$。积分限从 $[0, \\tau]$ 变为 $[1, z]$。\n\\begin{align*}\n\\frac{3}{\\lambda} \\int_{0}^{\\tau} t^2 \\left(1 + \\frac{t}{\\lambda}\\right)^{-4} dt  \\;=\\; \\frac{3}{\\lambda} \\int_{1}^{z} (\\lambda(u-1))^2 u^{-4} (\\lambda du) \\\\\n \\;=\\; 3\\lambda^2 \\int_{1}^{z} (u-1)^2 u^{-4} du \\\\\n \\;=\\; 3\\lambda^2 \\int_{1}^{z} (u^2 - 2u + 1) u^{-4} du \\\\\n \\;=\\; 3\\lambda^2 \\int_{1}^{z} (u^{-2} - 2u^{-3} + u^{-4}) du \\\\\n \\;=\\; 3\\lambda^2 \\left[ -u^{-1} + u^{-2} - \\frac{1}{3}u^{-3} \\right]_{1}^{z} \\\\\n \\;=\\; 3\\lambda^2 \\left( \\left(-z^{-1} + z^{-2} - \\frac{1}{3}z^{-3}\\right) - \\left(-1 + 1 - \\frac{1}{3}\\right) \\right) \\\\\n \\;=\\; 3\\lambda^2 \\left(-z^{-1} + z^{-2} - \\frac{1}{3}z^{-3} + \\frac{1}{3}\\right) \\\\\n \\;=\\; \\lambda^2 \\left(-3z^{-1} + 3z^{-2} - z^{-3} + 1\\right)\n\\end{align*}\n现在，我们将 $\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right]$ 的两部分相加：\n\\begin{align*}\n\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right]  \\;=\\; \\lambda^2 \\left(1 - 3z^{-1} + 3z^{-2} - z^{-3}\\right) + \\lambda^2 \\left(z^{-1} - 2z^{-2} + z^{-3}\\right) \\\\\n \\;=\\; \\lambda^2 \\left(1 - 2z^{-1} + z^{-2}\\right) \\\\\n \\;=\\; \\lambda^2 \\left(1 - z^{-1}\\right)^2\n\\end{align*}\n有效噪声尺度是该数量的平方根。由于 $\\tau  0$，我们有 $z = 1+\\tau/\\lambda  1$，因此 $1 - z^{-1}  0$。\n$$\n\\sqrt{\\mathbb{E}\\!\\left[\\psi_{\\tau}(\\varepsilon)^{2}\\right]} \\;=\\; \\sqrt{\\lambda^2(1 - z^{-1})^2} \\;=\\; \\lambda(1 - z^{-1})\n$$\n我们现在可以用 $z$ 来表示 $c(\\tau, \\lambda)$ 的表达式：\n$$\nc(\\tau, \\lambda) \\;=\\; \\frac{\\lambda(1 - z^{-1})}{1 - z^{-3}}\n$$\n使用因式分解 $a^3-b^3 = (a-b)(a^2+ab+b^2)$，我们简化分母 $1-z^{-3} = (1-z^{-1})(1+z^{-1}+z^{-2})$。\n对于 $\\tau  0$，$z1$，所以 $1-z^{-1} \\ne 0$。我们可以消去这一项：\n$$\nc(\\tau, \\lambda) \\;=\\; \\frac{\\lambda(1 - z^{-1})}{(1 - z^{-1})(1 + z^{-1} + z^{-2})} \\;=\\; \\frac{\\lambda}{1 + z^{-1} + z^{-2}}\n$$\n问题是要求解 $c^{\\star}(\\lambda) = \\inf_{\\tau  0} c(\\tau, \\lambda)$。这等价于求解以 $z = 1 + \\tau/\\lambda$ 表示的表达式的下确界。由于 $\\tau$ 的取值范围是 $(0, \\infty)$，所以 $z$ 的取值范围是 $(1, \\infty)$。\n我们想要求解 $\\inf_{z  1} \\frac{\\lambda}{1 + z^{-1} + z^{-2}}$。\n这等价于在 $z \\in (1, \\infty)$ 上最大化分母 $g(z) = 1 + z^{-1} + z^{-2}$。\n让我们分析 $g(z)$ 的导数：\n$$\ng'(z) \\;=\\; -z^{-2} - 2z^{-3} \\;=\\; - \\frac{1}{z^3}(z+2)\n$$\n对于 $z  1$，$g'(z)  0$，这意味着 $g(z)$ 在区间 $(1, \\infty)$ 上是一个严格递减函数。\n$g(z)$ 在 $(1, \\infty)$ 上的上确界在 $z$ 趋近于其定义域的下界时达到，即当 $z \\to 1^+$ 时。\n$$\n\\sup_{z  1} g(z) \\;=\\; \\lim_{z \\to 1^+} (1 + z^{-1} + z^{-2}) \\;=\\; 1 + 1^{-1} + 1^{-2} \\;=\\; 3\n$$\n由于 $c(\\tau, \\lambda) = \\lambda/g(z)$，最小化 $c(\\tau, \\lambda)$ 等价于最大化 $g(z)$。因此，$c(\\tau, \\lambda)$ 的下确界是：\n$$\nc^{\\star}(\\lambda) \\;=\\; \\frac{\\lambda}{\\sup_{z  1} g(z)} \\;=\\; \\frac{\\lambda}{3}\n$$\n这个下确界是当 $\\tau \\to 0^+$ 时的极限。", "answer": "$$\n\\boxed{\\frac{\\lambda}{3}}\n$$", "id": "3460066"}]}