{"hands_on_practices": [{"introduction": "本次练习将提供一种直接的动手方法来探索两个基本概念。我们首先将实现对精确恢复条件（Exact Recovery Condition, ERC）的检验，这是一个针对*特定*信号支撑集的理论保证。接着，我们将通过计算来估算*经验弱阈值*，它描述了给定测量矩阵的典型恢复性能。这项实践将一个特定的理论条件与一个更广泛的性能统计量度联系起来。[@problem_id:3494376]", "problem": "给定一个固定的线性逆模型，其传感矩阵为 $A \\in \\mathbb{R}^{m \\times n}$，支撑集为 $S \\subset \\{0,1,\\dots,n-1\\}$。您面临的是一个经典的稀疏恢复问题：通过求解称为基追踪（Basis Pursuit）的凸规划，从无噪声数据 $y = A x$ 中恢复 $x \\in \\mathbb{R}^n$。您的任务是实现一个计算过程，为指定的支撑集数值验证精确恢复条件（ERC），并通过对随机支撑集和信号进行采样，经验性地估计给定矩阵实例的弱恢复阈值。所有计算纯属数学范畴，不涉及任何物理单位。\n\n从以下基本定义和事实开始：\n- 对于矩阵 $A \\in \\mathbb{R}^{m \\times n}$，如果一个 $k$-稀疏向量 $x \\in \\mathbb{R}^n$ 恰好有 $k$ 个非零坐标，则满足 $\\|x\\|_0 = k$。对于无噪声测量 $y = A x$，凸规划基追踪（BP）是以下优化问题\n$$\n\\min_{z \\in \\mathbb{R}^n} \\|z\\|_1 \\quad \\text{subject to} \\quad A z = y.\n$$\n- 对于大小为 $|S|=k$ 的支撑集 $S$，精确恢复条件（ERC）定义为\n$$\n\\max_{j \\notin S} \\left\\| A_S^\\dagger a_j \\right\\|_1 < 1,\n$$\n其中 $A_S$ 是由 $S$ 索引的列构成的 $A$ 的子矩阵，$A_S^\\dagger$ 是 $A_S$ 的 Moore–Penrose 伪逆，而 $a_j$ 表示 $A$ 的第 $j$ 列。当此严格不等式成立时，BP 可以恢复所有支撑在 $S$ 上且在 $S$ 上具有任意系数的 $k$-稀疏向量。\n- 对于一个固定的矩阵实例，经验弱阈值在操作上定义如下。对于预设集合中的每个稀疏度 $k$，抽取多个大小为 $k$ 的独立随机支撑集 $S$（在所有支撑集上均匀抽取），并在每个 $S$ 上抽取随机非零系数（从关于零点对称的连续分布中抽取）。对每个实例，生成 $y = A x$ 并尝试通过 BP 进行恢复。令稀疏度为 $k$ 时的经验成功率为精确恢复的试验所占的比例。经验弱阈值 $k_{\\mathrm{weak}}$ 是预设集合中，其经验成功率至少为 $0.5$（表示为小数）的最大 $k$ 值。\n\n您的程序必须实现以下内容：\n1. 通过计算量\n$$\n\\theta(S;A) \\triangleq \\max_{j \\notin S} \\left\\| A_S^\\dagger a_j \\right\\|_1,\n$$\n为提供的 $(A,S)$ 对数值验证 ERC，并且如果在一个由小数值容差强化的严格不等式检查中 $\\theta(S;A) < 1$，则声明 ERC 得到满足。如果 $A_S$ 不是满列秩，则声明 ERC 未得到满足。\n2. 通过以下方式经验性地估计给定 $A$ 的弱阈值 $k_{\\mathrm{weak}}$：\n   - 固定一个有限的稀疏度候选集 $\\mathcal{K}$。\n   - 对每个 $k \\in \\mathcal{K}$，执行 $T$ 次随机试验。在每次试验中，均匀随机地选择一个大小为 $k$ 的支撑集 $S$，在 $S$ 上独立地从标准正态分布中抽取系数，构成 $x$，计算 $y = A x$，并求解 BP。如果恢复出的 $\\hat{x}$ 的支撑集与 $S$ 匹配（在对元素的小幅值阈值下），并且相对误差 $\\|\\hat{x} - x\\|_2 / \\|x\\|_2$ 低于一个小的数值容差，则记为一次成功。经验弱阈值是 $\\mathcal{K}$ 中其经验成功率至少为 $0.5$（以小数表示）的最大 $k$。\n3. 按照末尾指定的精确格式输出所有测试用例的结果。\n\n实现细节和约束：\n- 使用 BP 的线性规划重构形式，将任意 $z \\in \\mathbb{R}^n$ 写为 $z = u - v$，其中 $u,v \\in \\mathbb{R}^n$，$u \\ge 0$，$v \\ge 0$。那么 BP 等价于\n$$\n\\min_{u,v \\in \\mathbb{R}^n} \\mathbf{1}^\\top (u+v) \\quad \\text{subject to} \\quad A(u - v) = y, \\quad u \\ge 0, \\; v \\ge 0,\n$$\n这是一个标准的线性规划（LP）问题。\n- 为保证数值稳定性，在所有计算之前，将 $A$ 的列归一化为单位欧几里得范数。在检查 $\\theta(S;A) < 1$ 时，使用带有小数值容差的严格不等式。在成功测试中，使用小容差来判断支撑集是否相等以及相对误差。\n\n测试套件：\n您必须为以下三个矩阵实例及相关的支撑集实现您的解决方案。对于每个实例，计算给定 $S$ 的 ERC 结论，以及在指定的候选集上使用每个 $k$ 指定的试验次数计算出的经验弱阈值 $k_{\\mathrm{weak}}$。\n- 测试用例 1（随机高斯，中等维度）：\n  - 维度：$m = 20$, $n = 40$。\n  - 构造：使用伪随机种子 $7$ 抽取 $A$ 的元素，使其为独立同分布的标准正态分布，然后将各列归一化为单位范数。\n  - ERC 的支撑集：$S = \\{0,7,13\\}$。\n  - 经验弱阈值设置：候选集 $\\mathcal{K} = \\{1,2,3,4,5,6\\}$，每个 $k$ 的试验次数：$T = 12$，使用固定的伪随机种子 $101$ 以保证试验的可复现性。\n- 测试用例 2（重复列，对于 1-稀疏支撑集的 ERC 是病态的）：\n  - 维度：$m = 10$, $n = 12$。\n  - 构造：使用伪随机种子 $3$ 抽取一个基础矩阵 $A$，其元素为独立同分布的标准正态分布。然后将列索引为 $5$ 的列设置为与列索引为 $0$ 的列完全相同。最后，将所有列归一化为单位范数。\n  - ERC 的支撑集：$S = \\{0\\}$。\n  - 经验弱阈值设置：候选集 $\\mathcal{K} = \\{1,2,3,4,5\\}$，每个 $k$ 的试验次数：$T = 12$，使用固定的伪随机种子 $202$。\n- 测试用例 3（具有预设相关性的近似重复列）：\n  - 维度：$m = 10$, $n = 12$。\n  - 构造：使用伪随机种子 $4$ 抽取一个基础矩阵 $A$，其元素为独立同分布的标准正态分布。令 $a_0$ 表示索引为 $0$ 的列。通过将一个随机标准正态向量投影到 $\\mathrm{span}\\{a_0\\}$ 的正交补上并进行归一化，构造一个与 $a_0$ 正交的单位范数向量 $r$。将列索引为 $5$ 的列设置为 $0.99\\,a_0 + \\sqrt{1 - 0.99^2}\\, r$，然后将所有列归一化为单位范数。\n  - ERC 的支撑集：$S = \\{0\\}$。\n  - 经验弱阈值设置：候选集 $\\mathcal{K} = \\{1,2,3,4,5\\}$，每个 $k$ 的试验次数：$T = 12$，使用固定的伪随机种子 $303$。\n\n成功标准与数值容差：\n- ERC 严格不等式检查容差：如果 $\\theta(S;A) < 1 - 10^{-9}$，则声明 ERC 得到满足，否则声明未得到满足。如果 $A_S$ 不是满列秩，声明未得到满足。\n- 经验弱阈值的恢复成功测试：当对绝对值大于 $10^{-4}$ 的元素进行阈值处理后，如果 $\\hat{x}$ 的支撑集与真实支撑集匹配，并且相对误差满足 $\\|\\hat{x} - x\\|_2 / \\|x\\|_2 < 10^{-3}$，则声明成功。\n- 使用线性规划求解器精确计算上述 BP。\n\n最终输出格式：\n- 对三个测试用例中的每一个，按顺序生成一个包含 ERC 结论和经验弱阈值的对：$[\\text{erc\\_bool}, k_{\\mathrm{weak}}]$，其中 $\\text{erc\\_bool}$ 是一个布尔值，$k_{\\mathrm{weak}}$ 是一个非负整数。\n- 您的程序应生成单行输出，包含一个逗号分隔且无空格的列表，其中含有这三对结果，例如：$[[\\text{True},3],[\\text{False},2],[\\text{True},4]]$。\n\n您的程序必须是自包含的，不得读取任何输入，并且只能使用指定的运行时环境。通过完全按照描述使用指定的伪随机种子来确保确定性行为。此问题不涉及角度和物理单位。百分比必须表示为小数；阈值标准使用 $0.5$ 作为成功率的截止值。", "solution": "所提出的问题是在压缩感知和稀疏信号恢复的数学框架内一个定义明确的计算练习。它在科学上是合理的、自包含的，并且所有参数和过程都得到了明确的规定。因此，该问题被认为是有效的。我们将继续提供一个完整的解决方案。\n\n任务是双重的：首先，为给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和一个特定的支撑集 $S$ 验证精确恢复条件（ERC）；其次，为同一矩阵 $A$ 经验性地估计弱恢复阈值 $k_{\\mathrm{weak}}$。我们将有条不紊地处理每个部分。\n\n**第一部分：精确恢复条件（ERC）的验证**\n\n精确恢复条件为通过基追踪（BP）凸规划从无噪声测量 $y=Ax$ 中唯一地恢复任何具有支撑集 $S$ 的稀疏信号 $x$ 提供了一个充分（且通常是必要）的条件：\n$$\n\\min_{z \\in \\mathbb{R}^n} \\|z\\|_1 \\quad \\text{subject to} \\quad A z = y.\n$$\n$x$ 的支撑集是其非零项的索引集合，$S = \\{i : x_i \\neq 0\\}$。令 $|S| = k$。\n\n一个支撑集 $S$ 的 ERC 满足当且仅当\n$$\n\\theta(S;A) \\triangleq \\max_{j \\notin S} \\left\\| A_S^\\dagger a_j \\right\\|_1 < 1,\n$$\n其中 $A_S$ 是由 $S$ 索引的列构成的 $A$ 的子矩阵，$a_j$ 是 $A$ 的第 $j$ 列，而 $A_S^\\dagger$ 是 $A_S$ 的 Moore-Penrose 伪逆。这个条件仅在 $A_S$ 具有满列秩（即 $\\mathrm{rank}(A_S) = k$）时才有明确定义。如果 $A_S$ 是秩亏的，它的列是线性相关的，并且不可能从 $A_Sx_S$ 中唯一确定支撑在 $S$ 上的信号的系数。在这种情况下，ERC 被认为不满足。\n\n验证 ERC 的计算步骤如下：\n1.  **矩阵归一化**：按照规定，我们首先将矩阵 $A$ 的每一列 $a_j$ 归一化为单位欧几里得范数：对于所有 $j \\in \\{0, \\dots, n-1\\}$，$a_j \\leftarrow a_j / \\|a_j\\|_2$。所有后续计算都使用这个归一化后的矩阵。\n2.  **子矩阵提取**：给定支撑集 $S$，我们构造子矩阵 $A_S \\in \\mathbb{R}^{m \\times k}$。不在 $S$ 中的索引构成补集 $S^c = \\{0, \\dots, n-1\\} \\setminus S$。\n3.  **秩检查**：我们验证 $A_S$ 是否具有满列秩，即 $\\mathrm{rank}(A_S) = k$。这可以通过检查 $A_S$ 的大于某个小容差的奇异值数量是否等于 $k$ 来完成。如果 $\\mathrm{rank}(A_S) < k$，则声明 ERC 不满足。\n4.  **伪逆计算**：如果 $A_S$ 是满列秩，我们计算其伪逆 $A_S^\\dagger$。对于一个满秩矩阵 $A_S$，这由 $A_S^\\dagger = (A_S^\\top A_S)^{-1} A_S^\\top$ 给出。在数值上，使用一种稳定的方法，如奇异值分解（SVD），这在标准数值库中已有实现。\n5.  **ERC 量计算**：对于索引 $j \\in S^c$ 的每一列 $a_j$，我们计算向量 $v_j = A_S^\\dagger a_j$。然后我们计算其 $\\ell_1$-范数，$\\|v_j\\|_1 = \\sum_i |(v_j)_i|$。\n6.  **最大值与比较**：我们找到这些范数的最大值，$\\theta(S;A) = \\max_{j \\in S^c} \\|v_j\\|_1$。\n7.  **结论**：如果这个最大值严格小于 1，则 ERC 满足。为了考虑有限精度算术，我们对照一个容差进行检查：$\\theta(S;A) < 1 - \\epsilon$，其中问题规定 $\\epsilon = 10^{-9}$。\n\n**第二部分：弱恢复阈值的经验估计**\n\n对于给定矩阵 $A$，弱恢复阈值 $k_{\\mathrm{weak}}$ 是一个经验性度量，表示恢复“通常”能成功达到的稀疏度水平。对于一个固定的矩阵实例，它是一个随机选择的 $k$-稀疏信号能够以高概率被恢复的最大稀疏度 $k$。问题给出了一个操作性定义，我们将其形式化为以下算法。\n\n1.  **矩阵归一化**：和之前一样，将 $A$ 的列归一化为单位 $\\ell_2$-范数。为试验初始化一个独立、可复现的随机数流。\n2.  **遍历稀疏度**：我们遍历每个候选稀疏度 $k \\in \\mathcal{K}$。\n3.  **蒙特卡洛模拟**：对每个 $k$，我们执行 $T$ 次独立试验：\n    a. **生成一个随机稀疏信号**：\n        i.  从所有 $\\binom{n}{k}$ 个可能的大小为 $k$ 的支撑集中，均匀随机地选择一个支撑集 $S$。\n        ii. 构造一个信号 $x \\in \\mathbb{R}^n$。它在 $S$ 之外处处为零。$k$ 个非零项 $x_S$ 从标准正态分布 $\\mathcal{N}(0,1)$ 中独立抽取。\n    b. **生成测量值**：计算无噪声测量向量 $y = Ax$。\n    c. **通过基追踪尝试恢复**：我们求解 BP 优化问题以找到估计值 $\\hat{x}$。按照规定，我们使用等价的线性规划（LP）：\n        $$\n        \\min_{u,v} \\sum_{i=0}^{n-1} (u_i+v_i) \\quad \\text{subject to} \\quad A(u-v) = y, \\quad u \\ge 0, \\; v \\ge 0.\n        $$\n        使用一个标准的 LP 求解器。解向量 $[u^\\star; v^\\star]$ 给出恢复的信号 $\\hat{x} = u^\\star - v^\\star$。\n    d. **检查成功与否**：如果同时满足以下两个标准，则试验被视为成功：\n        i.  **支撑集恢复**：估计值的支撑集 $\\hat{S} = \\{i : |\\hat{x}_i| > 10^{-4}\\}$ 必须与真实支撑集 $S$ 完全相同。\n        ii. **信号保真度**：相对重构误差必须很小：$\\|\\hat{x} - x\\|_2 / \\|x\\|_2 < 10^{-3}$。\n4.  **计算成功率**：对于每个 $k$，经验成功率是成功试验的比例：$P_k = (\\text{成功次数}) / T$。\n5.  **确定弱阈值**：在计算了所有 $k \\in \\mathcal{K}$ 的成功率之后，弱阈值 $k_{\\mathrm{weak}}$ 是 $\\mathcal{K}$ 中使得 $P_k \\ge 0.5$ 的最大 $k$ 值。如果 $\\mathcal{K}$ 中没有 $k$ 满足此标准，则 $k_{\\mathrm{weak}}$ 取为 $0$。\n\n这两个过程将应用于指定的三个测试用例。测试用例 2 提出了一个具有两个相同列的矩阵，这保证了对于任何包含其中一列但不包含另一列的支撑集，ERC 都会失败，因为 $\\|A_S^\\dagger a_j\\|_1$ 将恰好为 $1$。测试用例 3 涉及高度相关但非完全相关的列，提供了一个在 ERC 边界附近的测试。实现将忠实地遵循指定的随机种子，以实现完全的可复现性。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1\n        {\n            \"m\": 20, \"n\": 40, \"A_seed\": 7, \"erc_support\": {0, 7, 13},\n            \"k_set\": [1, 2, 3, 4, 5, 6], \"trials_per_k\": 12, \"trial_seed\": 101,\n            \"case_id\": 1\n        },\n        # Test case 2\n        {\n            \"m\": 10, \"n\": 12, \"A_seed\": 3, \"erc_support\": {0},\n            \"k_set\": [1, 2, 3, 4, 5], \"trials_per_k\": 12, \"trial_seed\": 202,\n            \"case_id\": 2\n        },\n        # Test case 3\n        {\n            \"m\": 10, \"n\": 12, \"A_seed\": 4, \"erc_support\": {0},\n            \"k_set\": [1, 2, 3, 4, 5], \"trials_per_k\": 12, \"trial_seed\": 303,\n            \"case_id\": 3\n        },\n    ]\n\n    results = []\n    for params in test_cases:\n        A = generate_matrix(params)\n        erc_verdict = compute_erc_verdict(A, params[\"erc_support\"])\n        k_weak = estimate_weak_threshold(A, params[\"k_set\"], params[\"trials_per_k\"], params[\"trial_seed\"])\n        results.append([erc_verdict, k_weak])\n    \n    # Format output to be exactly [[Bool,int],[Bool,int],...] with no spaces\n    output_str = str(results).replace(\" \", \"\")\n    print(output_str)\n\ndef generate_matrix(params):\n    \"\"\"\n    Generates the sensing matrix A based on test case parameters.\n    \"\"\"\n    m, n, seed = params[\"m\"], params[\"n\"], params[\"A_seed\"]\n    case_id = params[\"case_id\"]\n    rng = np.random.default_rng(seed)\n    \n    if case_id == 1:\n        A = rng.standard_normal((m, n))\n    elif case_id == 2:\n        A = rng.standard_normal((m, n))\n        A[:, 5] = A[:, 0]\n    elif case_id == 3:\n        A_base = rng.standard_normal((m, n))\n        a0_unnorm = A_base[:, 0].copy()\n        \n        # Construct a random vector orthogonal to a0_unnorm\n        rand_vec = rng.standard_normal(m)\n        proj_a0_rand = (rand_vec @ a0_unnorm) / (a0_unnorm @ a0_unnorm) * a0_unnorm\n        r_unorth = rand_vec - proj_a0_rand\n        r = r_unorth / np.linalg.norm(r_unorth)\n        \n        # Construct the new highly correlated column\n        a5_new = 0.99 * a0_unnorm + np.sqrt(1 - 0.99**2) * r\n        A = A_base.copy()\n        A[:, 5] = a5_new\n\n    # Normalize all columns to unit Euclidean norm\n    norms = np.linalg.norm(A, axis=0)\n    # Avoid division by zero for zero columns, although not expected here\n    norms[norms == 0] = 1\n    A = A / norms\n\n    return A\n\ndef compute_erc_verdict(A, S_set):\n    \"\"\"\n    Numerically verifies the Exact Recovery Condition (ERC).\n    \"\"\"\n    m, n = A.shape\n    S = sorted(list(S_set))\n    k = len(S)\n\n    if k == 0:\n        # ERC is trivially true for k=0 but let's handle it\n        return True\n\n    A_S = A[:, S]\n    \n    # Check if A_S is full column rank\n    if np.linalg.matrix_rank(A_S) < k:\n        return False\n    \n    # Compute pseudoinverse of A_S\n    A_S_dagger = np.linalg.pinv(A_S)\n    \n    # Get indices not in S\n    S_c = sorted(list(set(range(n)) - S_set))\n    \n    max_norm = 0.0\n    for j in S_c:\n        a_j = A[:, j]\n        v_j = A_S_dagger @ a_j\n        norm_v_j = np.linalg.norm(v_j, 1)\n        if norm_v_j > max_norm:\n            max_norm = norm_v_j\n            \n    erc_tolerance = 1e-9\n    return max_norm < 1.0 - erc_tolerance\n\ndef estimate_weak_threshold(A, k_set, T, seed):\n    \"\"\"\n    Empirically estimates the weak threshold of recovery.\n    \"\"\"\n    m, n = A.shape\n    rng = np.random.default_rng(seed)\n    \n    k_weak = 0\n    \n    for k in k_set:\n        if k == 0: continue\n        success_count = 0\n        for _ in range(T):\n            # 1. Generate random sparse signal\n            S_indices = rng.choice(n, k, replace=False)\n            S = set(S_indices)\n            x = np.zeros(n)\n            x[S_indices] = rng.standard_normal(k)\n            \n            # 2. Generate measurements\n            y = A @ x\n            \n            # 3. Solve Basis Pursuit via LP\n            c = np.ones(2 * n)\n            A_eq = np.hstack([A, -A])\n            b_eq = y\n            \n            # Scipy's linprog with 'highs' is robust\n            res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=(0, None), method='highs-ds')\n            \n            if not res.success:\n                continue\n                \n            x_hat = res.x[:n] - res.x[n:]\n\n            # 4. Check for success\n            support_tol = 1e-4\n            error_tol = 1e-3\n            \n            S_hat = set(np.where(np.abs(x_hat) > support_tol)[0])\n            \n            support_recovered = (S == S_hat)\n            \n            # Avoid division by zero if x is zero vector\n            norm_x = np.linalg.norm(x)\n            if norm_x == 0:\n                relative_error = np.linalg.norm(x_hat) # Should also be near zero\n            else:\n                relative_error = np.linalg.norm(x_hat - x) / norm_x\n            \n            error_small = (relative_error < error_tol)\n            \n            if support_recovered and error_small:\n                success_count += 1\n\n        success_rate = success_count / T\n        \n        if success_rate >= 0.5:\n            k_weak = k\n            \n    return k_weak\n\nsolve()\n```", "id": "3494376"}, {"introduction": "虽然弱阈值和强阈值为我们提供了性能的高层视角，但究竟是测量矩阵$A$的哪些性质决定了这些阈值呢？本练习将深入探讨这一问题。我们将比较两个特殊构造的矩阵，它们具有相同的互相关性$\\mu$，但Spark值却不同。通过计算这些性质并观察贪婪算法的恢复性能，你将深刻理解为何简单的度量指标有时会产生误导，以及更深层次的结构特性如何决定实际的恢复成功率。[@problem_id:3494441]", "problem": "考虑一个确定性的、无噪声的压缩感知模型，其传感矩阵为 $A \\in \\mathbb{R}^{m \\times n}$，信号为 $x \\in \\mathbb{R}^{n}$，测量值为 $y = A x$。设 $A$ 的列为 $\\{a_i\\}_{i=1}^n$，并假设它们已被归一化为单位 $\\ell_2$-范数。有两个结构不变量对恢复分析至关重要：互相关性 $\\mu$ 和 $A$ 的spark。互相关性定义为 $\\mu = \\max_{i \\neq j} \\left| \\langle a_i, a_j \\rangle \\right|$，spark定义为 $\\operatorname{spark}(A) = \\min \\left\\{ s : \\text{存在一个包含 } s \\text{ 个 } A \\text{ 的列的集合，这些列是线性相关的} \\right\\}$。对于通过 $\\ell_1$-最小化精确恢复每个 $k$-稀疏信号，一个经典的充分条件（有时称为强阈值）仅取决于 $\\mu$。相比之下，弱经验阈值量化了给定算法和有限实例集下的典型可恢复性，并且当spark变化时，即使 $\\mu$ 保持不变，也可能偏离基于相关性的保证。\n\n您的任务是通过构造两个具有相同互相关性但不同spark的矩阵来检验 $\\mu$ 和 $\\operatorname{spark}(A)$ 之间的相互作用，然后量化基于相关性的强阈值与通过正交匹配追踪（OMP）评估的弱经验阈值之间的差异。仅使用纯数学和算法推理；不涉及物理单位。\n\n您的程序需要实现并使用的定义和要求：\n1. 互相关性 $\\mu$ 必须根据 $A$ 的归一化列使用定义 $\\mu = \\max_{i \\neq j} \\left| \\langle a_i, a_j \\rangle \\right|$ 计算。\n2. 对于所提供的小矩阵，spark必须通过对所有列子集进行穷举搜索，并使用线性代数秩检验来检测相关性来精确计算。\n3. 基于相关性的强阈值 $k_{\\mu,\\text{strong}}$ 是经典互相关性充分条件所保证的、能够通过 $\\ell_1$-最小化（基追踪）精确恢复每个 $k$-稀疏信号的最大整数 $k$。\n4. 弱经验阈值 $k_{\\text{empirical}}$ 必须通过在具有指定支撑集和系数的有限稀疏信号测试套件上运行正交匹配追踪（OMP），并选择OMP能够（在数值容差范围内）精确重构相应 $k$-套件中所有信号的最大 $k$ 值来计算。\n5. 正交匹配追踪（OMP）被定义为一种贪心算法，给定 $A$、$y$ 和迭代上限 $k_{\\max}$：它迭代地选择与当前残差具有最大绝对内积的列，在所选支撑集上通过最小二乘法重新拟合，并更新残差；如果残差的 $\\ell_2$-范数低于一个小的容差，它会提前停止。\n\n测试套件和矩阵：\n- 矩阵 $A^{(1)} \\in \\mathbb{R}^{3 \\times 4}$ 的列为\n  $c_1 = [\\,1,\\,0,\\,0\\,]^\\top$,\n  $c_2 = [\\,-0.5,\\,\\sqrt{3}/2,\\,0\\,]^\\top$,\n  $c_3 = [\\,0.5,\\,0.2886751345948129,\\,0.816496580927726\\,]^\\top$,\n  $c_4 = [\\,-0.5,\\,-0.2886751345948129,\\,0.816496580927726\\,]^\\top$。\n  矩阵 $A^{(1)}$ 由这些列堆叠而成。\n- 矩阵 $A^{(2)} \\in \\mathbb{R}^{3 \\times 4}$ 的列为\n  $c_1 = [\\,1,\\,0,\\,0\\,]^\\top$,\n  $c_2 = [\\,-0.5,\\,\\sqrt{3}/2,\\,0\\,]^\\top$,\n  $c_3 = [\\,0.5,\\,\\sqrt{3}/2,\\,0\\,]^\\top$,\n  $c_4 = [\\,-0.5,\\,-0.2886751345948129,\\,0.816496580927726\\,]^\\top$。\n  注意 $c_3 = c_1 + c_2$ 且具有单位范数，因为 $\\langle c_1, c_2 \\rangle = -0.5$，这确保了 $A^{(2)}$ 中存在一个相关的三元组。\n\n对于这两个矩阵，必须使用以下确定性信号套件来评估弱经验阈值：\n- 对于 $k = 1$：支撑集 $\\{\\,\\{1\\},\\,\\{2\\},\\,\\{3\\},\\,\\{4\\}\\,\\}$，支撑集上的系数为 $1$，其他地方为 $0$。\n- 对于 $k = 2$：支撑集 $\\{\\,\\{1,2\\},\\,\\{1,3\\}\\,\\}$，支撑集中每个索引上的系数为 $1$，其他地方为 $0$。\n\n程序必须：\n- 在计算相关性、spark以及执行OMP之前，内部将列归一化为单位 $\\ell_2$-范数。提供的列已经是单位范数，但应应用归一化以确保鲁棒性。\n- 为每个矩阵计算 $\\mu$、$\\operatorname{spark}(A)$、$k_{\\mu,\\text{strong}}$ 和 $k_{\\text{empirical}}$。\n- 在OMP中，当比较重构的 $x$ 与真实值 $x$ 时，以及对于残差停止条件，使用 $10^{-8}$ 的数值容差。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，列表被方括号括起来。列表中的每个条目对应一个矩阵，其本身是一个形如 $[\\mu, \\operatorname{spark}(A), k_{\\mu,\\text{strong}}, k_{\\text{empirical}}]$ 的列表。例如，输出必须看起来像 $[[\\text{for } A^{(1)}],[\\text{for } A^{(2)}]]$，其中占位符被数字替换。\n\n该测试套件涵盖：\n- 一个一般情况，其中相同的互相关性与更大的spark重合，并产生更高的弱经验可恢复性。\n- 一个边界情况，其中相同的互相关性由于一个显式的相关三元组而与更小的spark重合，产生更低的弱经验阈值。\n- 用于 $k=1$ 和 $k=2$ 的确定性 $k$-稀疏信号族，用于探测成功路径和失败场景。\n\n您的程序必须是一个完整的、可在现代语言中运行的实现，并精确生成指定的最终输出格式。", "solution": "在尝试给出解决方案之前，问题经过了严格的验证过程。\n\n### 步骤1：提取已知信息\n\n- **模型**：确定性的、无噪声的压缩感知模型，$y = A x$，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x \\in \\mathbb{R}^{n}$。\n- **矩阵列**：$\\{a_i\\}_{i=1}^n$ 是 $A$ 的列，被归一化为单位 $\\ell_2$-范数。\n- **互相关性**：$\\mu = \\max_{i \\neq j} \\left| \\langle a_i, a_j \\rangle \\right|$。\n- **Spark**：$\\operatorname{spark}(A) = \\min \\left\\{ s : \\text{存在一个包含 } s \\text{ 个 } A \\text{ 的列的集合，这些列是线性相关的} \\right\\}$。\n- **强阈值 ($k_{\\mu,\\text{strong}}$)**：由经典互相关性充分条件 $k < \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right)$ 所保证的、能够通过 $\\ell_1$-最小化精确恢复每个 $k$-稀疏信号的最大整数 $k$。\n- **弱经验阈值 ($k_{\\text{empirical}}$)**：正交匹配追踪（OMP）算法能够精确重构指定有限 $k$-套件中所有信号的最大整数 $k$。\n- **正交匹配追踪 (OMP)**：一种贪心算法，给定 $A$、$y$ 和迭代上限 $k_{\\max}$，它迭代地选择与当前残差具有最大绝对内积的列，在所选支撑集上通过最小二乘法重新拟合，并更新残差。如果残差的 $\\ell_2$-范数低于一个容差，则停止。\n- **矩阵 $A^{(1)}$**：$A^{(1)} \\in \\mathbb{R}^{3 \\times 4}$ 的列为：\n    $c_1 = [\\,1,\\,0,\\,0\\,]^\\top$\n    $c_2 = [\\,-0.5,\\,\\sqrt{3}/2,\\,0\\,]^\\top$\n    $c_3 = [\\,0.5,\\,0.2886751345948129,\\,0.816496580927726\\,]^\\top$\n    $c_4 = [\\,-0.5,\\,-0.2886751345948129,\\,0.816496580927726\\,]^\\top$\n- **矩阵 $A^{(2)}$**：$A^{(2)} \\in \\mathbb{R}^{3 \\times 4}$ 的列为：\n    $c_1 = [\\,1,\\,0,\\,0\\,]^\\top$\n    $c_2 = [\\,-0.5,\\,\\sqrt{3}/2,\\,0\\,]^\\top$\n    $c_3 = [\\,0.5,\\,\\sqrt{3}/2,\\,0\\,]^\\top$\n    $c_4 = [\\,-0.5,\\,-0.2886751345948129,\\,0.816496580927726\\,]^\\top$\n    其性质为第三列是前两列之和。\n- **信号测试套件**：\n    - $k=1$：支撑集 $\\{\\,\\{1\\},\\,\\{2\\},\\,\\{3\\},\\,\\{4\\}\\,\\}$，系数为 $1$。\n    - $k=2$：支撑集 $\\{\\,\\{1,2\\},\\,\\{1,3\\}\\,\\}$，每个支撑集索引上的系数为 $1$。\n- **数值容差**：$10^{-8}$，用于OMP残差停止和最终重构的相等性检查。\n- **计算要求**：\n    1.  内部归一化列。\n    2.  为两个矩阵计算 $\\mu$、$\\operatorname{spark}(A)$、$k_{\\mu,\\text{strong}}$ 和 $k_{\\text{empirical}}$。\n    3.  通过穷举搜索列子集和秩检验来计算spark。\n- **最终输出格式**：单行：`[[mu_1, spark_1, k_strong_1, k_empirical_1],[mu_2, spark_2, k_strong_2, k_empirical_2]]`。\n\n### 步骤2：使用提取的已知信息进行验证\n\n- **科学性**：该问题位于压缩感知和稀疏恢复的既定数学框架内。所有定义——互相关性、spark、OMP和恢复条件——都是该领域的标准定义。矩阵是基于有效的几何和代数原理构造的。该问题具有科学合理性。\n- **良构性**：所有待计算量（$\\mu$、spark、$k_{\\mu,\\text{strong}}$、$k_{\\text{empirical}}$）都有明確的定义。输入（矩阵、测试信号）是明确的，足以进行计算。对于给定的 $3 \\times 4$ 矩阵，穷举搜索spark是可行的。该问题允许一个唯一的、可计算的解。\n- **客观性**：问题陈述使用精确的数学语言表达，没有主观或带偏见的术语。\n- **缺陷清单**：\n    1.  **科学上不合理**：无。数学前提是正确的。\n    2.  **无法形式化/不相关**：无。该问题是对稀疏恢复中阈值的一个形式化且相关的探索。\n    3.  **不完整/矛盾**：无。提供了所有必要信息。$A^{(2)}$ 中陈述的线性相关性是一个特性，而非矛盾。\n    4.  **不切实际/不可行**：无。计算是可行的。问题是纯数学的。\n    5.  **病态**：无。解是唯一的且稳定的。\n    6.  **故弄玄虚/ trivial**：无。该问题 thoughtfully 地构建了一个场景，以突出基于相关性的保证与经验性能之间的非平凡区别，这是该领域的核心概念。\n    7aws **无法验证**：无。所有结果都可以通过算法计算和验证。\n\n### 步骤3：结论与行动\n\n该问题是**有效的**。将提供一个完整的解决方案。\n\n### 解决方案\n\n目标是为两个指定的矩阵 $A^{(1)}$ 和 $A^{(2)}$ 计算并比较四个关键指标——互相关性($\\mu$)、spark、基于相关性的强恢复阈值 ($k_{\\mu,\\text{strong}}$) 和基于OMP的弱经验恢复阈值 ($k_{\\text{empirical}}$)。此分析将展示具有相同相关性的矩阵如何因spark值的不同而表现出不同的恢复性能。\n\n首先，我们确定这四个指标的计算程序。\n\n1.  **互相关性, $\\mu$**：首先将输入矩阵 $A$ 的列归一化为单位 $\\ell_2$-范数。设归一化后的矩阵为 $\\tilde{A}$。计算格拉姆矩阵 $G = \\tilde{A}^T \\tilde{A}$。互相关性 $\\mu$ 是 $G$ 的非对角线元素绝对值的最大值：$\\mu = \\max_{i \\neq j} |G_{ij}|$。\n\n2.  **Spark, $\\operatorname{spark}(A)$**：对于一个 $m \\times n$ 矩阵 $A$，我们寻找最小的整数 $s$，使得 $A$ 的某个包含 $s$ 列的子集是线性相关的。这通过从 $s=1$ 迭代到 $m+1$ 来完成。对于每个 $s$，我们构建 $A$ 的所有 $\\binom{n}{s}$ 个包含 $s$ 列的子矩阵。如果任何这样的子矩阵的秩小于 $s$，则 $\\operatorname{spark}(A) = s$，搜索终止。给定 $m=3, n=4$，spark最多为 $m+1=4$。\n\n3.  **强阈值, $k_{\\mu,\\text{strong}}$**：这是对 $\\ell_1$-最小化的理论保证。唯一恢复任何 $k$-稀疏信号的充分条件是 $k < \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right)$。因此，$k_{\\mu,\\text{strong}}$ 是满足此严格不等式的最大整数 $k$。\n\n4.  **弱经验阈值, $k_{\\text{empirical}}$**：这是通过在特定的、有限的信号集上测试正交匹配追踪（OMP）算法来确定的。对于给定的稀疏度 $k$，生成一个 $k$-稀疏信号套件 $\\{x_i\\}$。对于每个 $x_i$，我们计算 $y_i = Ax_i$ 并运行OMP得到一个重构 $\\hat{x}_i$。如果在数值容差范围内，对于 $k$-套件中的所有信号都有 $\\hat{x}_i$ 等于 $x_i$，则对于级别 $k$ 的恢复是成功的。$k_{\\text{empirical}}$ 是恢复成功的相应套件的最大 $k$ 值。\n\nOMP算法本身对于信号 $y$ 和稀疏度 $S$ 的流程如下：\n- 初始化残差 $r_0 = y$，支撑集 $\\Lambda_0 = \\emptyset$。\n- 对于 $t = 1, \\dots, S$：\n    - 找到与当前残差最相关的 $A$ 的列的索引 $j_t$：$j_t = \\arg\\max_j |\\langle a_j, r_{t-1} \\rangle|$。\n    - 扩大支撑集：$\\Lambda_t = \\Lambda_{t-1} \\cup \\{j_t\\}$。\n    - 解决一个最小二乘问题，以找到支撑集上的新信号估计：$x_t = \\arg\\min_z \\|y - A_{\\Lambda_t}z\\|_2$，其中 $A_{\\Lambda_t}$ 是由 $\\Lambda_t$ 中的列组成的 $A$ 的子矩阵。\n    - 更新残差：$r_t = y - A_{\\Lambda_t}x_t$。\n- 最终估计在索引 $\\Lambda_S$ 处具有来自 $x_S$ 的非零项。\n\n我们现在将此框架应用于 $A^{(1)}$ 和 $A^{(2)}$。提供的列向量已经归一化，但我们仍将归一化作为一个程序性步骤。\n\n**矩阵 $A^{(1)}$ 的分析**\n\n- **列**：四个列 $a_1, a_2, a_3, a_4$ 是 $\\mathbb{R}^3$ 中的向量。\n- **互相关性 $\\mu^{(1)}$**：计算两两之间的内积。最大绝对非对角线值为 $|\\langle a_1, a_2 \\rangle| = |\\langle a_1, a_3 \\rangle| = |\\langle a_1, a_4 \\rangle| = 0.5$。因此，$\\mu^{(1)} = 0.5$。\n- **强阈值 $k_{\\mu,\\text{strong}}^{(1)}$**：当 $\\mu = 0.5$ 时，我们有条件 $k < \\frac{1}{2}\\left(1 + \\frac{1}{0.5}\\right) = \\frac{1}{2}(1 + 2) = 1.5$。满足此条件的最大整数 $k$ 是 $k=1$。所以，$k_{\\mu,\\text{strong}}^{(1)} = 1$。\n- **Spark $\\operatorname{spark}(A^{(1)})$**：我们检查列子集的线性相关性。\n    - 大小为 $s=1, 2$ 的子集：所有列都非零，且没有两列是共线的，所以它们是独立的。\n    - 大小为 $s=3$ 的子集：我们测试所有 $\\binom{4}{3}=4$ 个 $3 \\times 3$ 子矩阵的秩。可以证明所有四个子矩阵的秩都为 $3$（即它们是可逆的）。例如，子矩阵 $[a_1, a_2, a_3]$ 是一个对角线非零的上三角矩阵，因此是满秩的。所有其他组合也被发现是满秩的。\n    - 因为没有大小为 $3$ 的子集是线性相关的，所以spark必须大于 $3$。由于列是 $\\mathbb{R}^3$ 中的向量，任何 $4$ 列的集合都必须是线性相关的。因此，$\\operatorname{spark}(A^{(1)}) = 4$。\n- **经验阈值 $k_{\\text{empirical}}^{(1)}$**：\n    - $k=1$ 套件：OMP完美地恢复了所有 $1$-稀疏信号（它们只是 $A^{(1)}$ 的列乘以 $1$），因为它在第一步就选择了正确的列。\n    - $k=2$ 套件：测试信号是 $x_a = [1,1,0,0]^T$ 和 $x_b = [1,0,1,0]^T$。对于这两个信号，OMP都正确地识别了真实的支撑集 $\\{1,2\\}$ 和 $\\{1,3\\}$，并精确地重构了信号。例如，对于 $y_a = a_1 + a_2$，OMP在两次迭代中正确地找到了支撑集 $\\{1,2\\}$。\n    - 由于OMP对 $k=1$ 和 $k=2$ 都成功，所以 $k_{\\text{empirical}}^{(1)} = 2$。\n\n**矩阵 $A^{(2)}$ 的分析**\n\n- **列**：设列为 $b_1, b_2, b_3, b_4$。除了第三列 $b_3 = [0.5, \\sqrt{3}/2, 0]^T$ 外，它们与 $A^{(1)}$ 的列相同。\n- **互相关性 $\\mu^{(2)}$**：计算两两之间的内积。最大绝对非对角线值同样被发现为 $0.5$（例如，$|\\langle b_1, b_2 \\rangle| = 0.5$，$|\\langle b_2, b_3 \\rangle| = 0.5$，$|\\langle b_3, b_4 \\rangle| = 0.5$）。因此，$\\mu^{(2)} = 0.5$。\n- **强阈值 $k_{\\mu,\\text{strong}}^{(2)}$**：由于 $\\mu^{(2)} = \\mu^{(1)} = 0.5$，强阈值是相同的：$k_{\\mu,\\text{strong}}^{(2)} = 1$。\n- **Spark $\\operatorname{spark}(A^{(2)})$**：\n    - 问题构造使得 $b_3 = b_1 + b_2$，这意味着存在线性相关性 $b_1 + b_2 - b_3 = 0$。这是一个包含 $3$ 个线性相关列的集合。\n    - 没有两列是共线的，所以相关集的最小大小不是 $2$。\n    - 因此，$\\operatorname{spark}(A^{(2)}) = 3$。\n- **经验阈值 $k_{\\text{empirical}}^{(2)}$**：\n    - $k=1$ 套件：与 $A^{(1)}$ 一样，恢复成功。\n    - $k=2$ 套件：考虑信号 $x = [1,1,0,0]^T$。测量值为 $y = 1 \\cdot b_1 + 1 \\cdot b_2 = b_1 + b_2$。由于矩阵的构造，$y=b_3$。当使用这个 $y$ 运行OMP时：\n        - 它计算相关性 $|\\langle b_i, y \\rangle| = |\\langle b_i, b_3 \\rangle|$。由于 $\\langle b_3, b_3 \\rangle = 1$ 而所有其他的 $|\\langle b_i, b_3 \\rangle| \\le \\mu = 0.5$，OMP将明确地首先选择第 $3$ 列。\n        - 算法将索引 $3$ 放入支撑集。此支撑集上的最小二乘解是 $x_3=1$。残差变为 $y - 1 \\cdot b_3 = b_3 - b_3 = 0$。\n        - 由于残差为零，OMP终止并返回 $1$-稀疏解 $\\hat{x} = [0,0,1,0]^T$。\n        - 这与真实的 $2$-稀疏信号 $x = [1,1,0,0]^T$ 不匹配。\n    - 由于OMP在 $k=2$ 套件中的一个信号上失败，因此未满足 $k=2$ 的经验阈值。所有测试都通过的最大 $k$ 值为 $1$。因此，$k_{\\text{empirical}}^{(2)} = 1$。\n\n**结论**\n\n| 矩阵 | $\\mu$ | $\\operatorname{spark}(A)$ | $k_{\\mu,\\text{strong}}$ | $k_{\\text{empirical}}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| $A^{(1)}$ | $0.5$ | $4$ | $1$ | $2$ |\n| $A^{(2)}$ | $0.5$ | $3$ | $1$ | $1$ |\n\n结果证实了中心论点。两个矩阵共享相同的互相关性 $\\mu=0.5$，导致相同且悲观的强阈值 $k_{\\mu,\\text{strong}}=1$。然而，它们的结构特性，如spark所捕获的，是不同的。$A^{(1)}$ 具有其维度可能的最大spark ($4$)，而 $A^{(2)}$ 由于一个明确的线性相关性而具有较低的spark ($3$)。这种差异直接影响了OMP的经验性能。$A^{(1)}$ 允许恢复某些 $2$-稀疏信号，得到 $k_{\\text{empirical}}^{(1)}=2$，而 $A^{(2)}$ 的特定结构导致OMP在某个 $2$-稀疏信号上失败，将其经验阈值限制为 $k_{\\text{empirical}}^{(2)}=1$。这说明了虽然相关性提供了一个通用的、最坏情况的保证，但spark为矩阵的稀疏恢复性能提供了一个更精细（尽管计算上更困难）的预测指标。", "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to solve the compressed sensing problem.\n    It computes and compares metrics for two matrices A1 and A2.\n    \"\"\"\n\n    # --- Helper Functions ---\n\n    def normalize_columns(A):\n        \"\"\"Normalizes the columns of a matrix to unit l2-norm.\"\"\"\n        norms = np.linalg.norm(A, axis=0)\n        # Avoid division by zero for zero columns\n        norms[norms == 0] = 1\n        return A / norms\n\n    def compute_mu(A):\n        \"\"\"Computes the mutual coherence of a matrix with normalized columns.\"\"\"\n        G = A.T @ A\n        np.fill_diagonal(G, 0)\n        return np.max(np.abs(G))\n\n    def compute_spark(A):\n        \"\"\"Computes the spark of a matrix by exhaustive search.\"\"\"\n        m, n = A.shape\n        # Iterate over subset sizes s from 1 to m+1 (or n+1, whichever is smaller)\n        for s in range(1, min(m, n) + 2):\n            for indices in combinations(range(n), s):\n                sub_matrix = A[:, list(indices)]\n                if np.linalg.matrix_rank(sub_matrix) < s:\n                    return s\n        # This part should theoretically not be reached for m < n\n        return m + 1\n\n    def omp(A, y, k_max, tol=1e-8):\n        \"\"\"\n        Orthogonal Matching Pursuit algorithm.\n        \n        Args:\n            A (np.ndarray): Sensing matrix.\n            y (np.ndarray): Measurement vector.\n            k_max (int): Maximum number of iterations (sparsity level).\n            tol (float): Tolerance for residual norm to stop.\n\n        Returns:\n            np.ndarray: The recovered sparse signal.\n        \"\"\"\n        m, n = A.shape\n        x_rec = np.zeros(n)\n        residual = np.copy(y)\n        support = []\n\n        for _ in range(k_max):\n            if np.linalg.norm(residual) < tol:\n                break\n            \n            # Find the atom that is most correlated with the residual\n            correlations = np.abs(A.T @ residual)\n            # Break ties by choosing the smallest index\n            new_idx = np.argmax(correlations)\n            \n            if new_idx not in support:\n                support.append(new_idx)\n            \n            # Solve least squares on the current support\n            A_support = A[:, support]\n            try:\n                # Use pseudoinverse for stable solution\n                x_support = np.linalg.pinv(A_support) @ y\n            except np.linalg.LinAlgError:\n                # This should not happen with pinv, but as a safeguard\n                break\n\n            # Update residual\n            residual = y - A_support @ x_support\n        \n        # Construct the final sparse signal\n        if support:\n            x_rec[support] = x_support\n            \n        return x_rec\n\n    def compute_strong_threshold(mu):\n        \"\"\"\n        Calculates the largest integer k satisfying k < 0.5 * (1 + 1/mu).\n        \"\"\"\n        if mu == 0:\n            return np.inf  # Or a very large number, practically limited by dimensions\n        val = 0.5 * (1.0 + 1.0 / mu)\n        # We need the largest integer strictly less than val\n        return int(np.floor(val - 1e-9))\n\n    def compute_empirical_threshold(A, signal_suites, tol=1e-8):\n        \"\"\"\n        Computes the weak empirical threshold k_empirical.\n        \"\"\"\n        max_k_passed = 0\n        for k in sorted(signal_suites.keys()):\n            all_passed_for_k = True\n            for x_true in signal_suites[k]:\n                y = A @ x_true\n                # Run OMP with iteration cap equal to the true sparsity\n                x_rec = omp(A, y, k_max=k, tol=tol)\n                \n                # Check if reconstruction is accurate\n                if np.linalg.norm(x_true - x_rec) > tol:\n                    all_passed_for_k = False\n                    break\n            \n            if all_passed_for_k:\n                max_k_passed = k\n            else:\n                # If it fails for k, it can't be higher\n                break\n        return max_k_passed\n    \n    # --- Problem Setup ---\n    \n    # Define matrices\n    A1_cols = [\n        [1.0, 0.0, 0.0],\n        [-0.5, np.sqrt(3)/2, 0.0],\n        [0.5, 0.2886751345948129, 0.816496580927726],\n        [-0.5, -0.2886751345948129, 0.816496580927726]\n    ]\n    A1 = np.array(A1_cols).T\n\n    A2_cols = [\n        [1.0, 0.0, 0.0],\n        [-0.5, np.sqrt(3)/2, 0.0],\n        [0.5, np.sqrt(3)/2, 0.0],\n        [-0.5, -0.2886751345948129, 0.816496580927726]\n    ]\n    A2 = np.array(A2_cols).T\n    \n    matrices = [A1, A2]\n\n    # Define signal suites\n    n_dims = 4\n    signal_suites = {\n        1: [np.eye(n_dims)[i] for i in range(n_dims)],\n        2: [\n            np.array([1.0, 1.0, 0.0, 0.0]),\n            np.array([1.0, 0.0, 1.0, 0.0])\n        ]\n    }\n    \n    # --- Main Calculation Loop ---\n    \n    results = []\n    for A in matrices:\n        A_norm = normalize_columns(A)\n        \n        mu = compute_mu(A_norm)\n        spark = compute_spark(A_norm)\n        k_strong = compute_strong_threshold(mu)\n        k_empirical = compute_empirical_threshold(A_norm, signal_suites)\n        \n        results.append([mu, spark, k_strong, k_empirical])\n\n    # --- Final Output ---\n    \n    # Format the results exactly as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3494441"}, {"introduction": "在超越了典型情况（弱）阈值之后，我们的最后一个练习将挑战一项更艰巨的任务：估算*强阈值*。强阈值要求对给定稀疏度的*所有*支撑集都能实现一致恢复。这项任务在计算上要求很高，并且充满了统计陷阱。本练习将指导你设计一个复杂的模拟实验，它使用对偶认证进行高效检验，校正有限采样带来的偏差，并采用自举法（bootstrapping）来量化最终估计值的不确定性，让你一窥研究级计算分析的精髓。[@problem_id:3494353]", "problem": "要求您设计并实现一个完整的、基于模拟的程序，用于从有限样本数据中估计压缩感知中精确恢复的强阈值。考虑一个无噪声模型，其中一个稀疏度为 $k$ 的未知信号 $\\boldsymbol{x}_0 \\in \\mathbb{R}^n$ 通过线性测量 $\\boldsymbol{y} = A \\boldsymbol{x}_0$ 被观测，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个随机测量矩阵。恢复是通过求解一个凸规划问题来执行的，该问题在满足线性等式约束的条件下最小化 $\\boldsymbol{x}$ 的 $\\ell_1$ 范数。在采样率 $\\delta = m/n$ 下的强阈值，通俗地讲，是最大的归一化稀疏度 $\\rho = k/n$，使得对于随机矩阵 $A$ ，精确恢复以高概率对所有大小为 $k$ 的 $\\boldsymbol{x}_0$ 的支撑集和符号模式一致成立。\n\n您的估计器必须基于第一性原理，并包含以下所有组成部分：\n- 一个有限-$n$ 模拟协议，对于固定的 $(n,m,k)$，该协议测试跨随机采样的支撑集和符号模式的精确恢复，而不直接求解凸规划问题；相反，它应使用从凸对偶和 $\\ell_1$ 最小化问题的 Karush–Kuhn–Tucker (KKT) 条件推导出的最优性证书。\n- 对支撑集枚举偏差的修正，承认只能测试有限数量的支撑集/符号。将在一批支撑集样本上观察到的失败视为二项过程的实现，并在用户指定的置信水平下，使用无分布方法计算失败比例的一个保守置信上界。使用此界限来确定一个矩阵是否在选定的不良支撑集比例容忍度下表现出有效的一致恢复。\n- 在测量矩阵集合上进行非参数自助法，通过有放回地重采样矩阵级结果，在用户指定的置信水平下为估计的阈值构建一个置信区间 (CI)。\n\n程序设计要求：\n- 对于每个测试用例，生成 $T$ 个独立的矩阵 $A$，其元素为独立同分布，从均值为零、方差按 $1/m$ 缩放以保持一致能量尺度的高斯分布中抽取。对于每个矩阵 $A$ 和给定的稀疏度 $k$，抽取 $S$ 个大小为 $k$ 的独立随机支撑集（在所有子集上均匀分布）和独立的符号模式（在 $\\{-1,+1\\}^k$ 上均匀分布）。使用源于 KKT 条件的最优性证书来判断每个采样的支撑集/符号模式是否能精确恢复，而无需解决优化问题本身。将 $S$ 个采样支撑集上的失败汇总为每个矩阵的单个失败计数。\n- 按如下方式修正支撑集枚举偏差：给定 $S$ 次试验中的矩阵级失败计数，在指定的置信水平下计算真实失败比例的单边置信上界。当且仅当一个矩阵的上界小于或等于容忍度 $\\varepsilon$ 时，将其分类为表现出有效一致恢复。\n- 对于一个归一化稀疏度网格 $\\{\\rho_i\\}$，在固定的 $\\delta$ 下，确定经验强阈值估计 $\\widehat{\\rho}$，其值为网格中最大的 $\\rho_i$，使得在容忍度 $\\varepsilon$ 下被分类为有效一致恢复的矩阵比例至少达到目标水平 $q_0$。通过有放回地重采样 $T$ 个矩阵级分类，并在 $B$ 个 bootstrap 复制上重新计算 $\\widehat{\\rho}$，为 $\\widehat{\\rho}$ 构建一个 bootstrap 置信区间。\n\n您的程序必须实现上述内容，是完全自包含的，并遵守以下数值规范和测试套件。此问题不涉及物理单位。所有角度（如果出现）必须以弧度为单位，但本题不需要角度。\n\n实施该估计器并为以下三个测试用例生成结果：\n- 测试用例 1 (一般情况)：$n = 30$， $m = 18$， 稀疏度网格 $\\rho \\in \\{0.10, 0.15, 0.20, 0.25, 0.30, 0.35\\}$，$T = 12$，$S = 40$，置信水平参数 $\\alpha = 0.05$，容忍度 $\\varepsilon = 0.10$，目标水平 $q_0 = 0.80$，bootstrap 复制数 $B = 150$。\n- 测试用例 2 (边界情况)：$n = 28$， $m = 14$， 稀疏度网格 $\\rho \\in \\{0.10, 0.15, 0.20, 0.25\\}$，$T = 12$，$S = 50$，置信水平参数 $\\alpha = 0.05$，容忍度 $\\varepsilon = 0.05$，目标水平 $q_0 = 0.80$，bootstrap 复制数 $B = 150$。\n- 测试用例 3 (小样本边缘情况)：$n = 24$， $m = 16$， 稀疏度网格 $\\rho \\in \\{0.20, 0.25, 0.30, 0.35, 0.40\\}$，$T = 10$，$S = 30$，置信水平参数 $\\alpha = 0.05$，容忍度 $\\varepsilon = 0.10$，目标水平 $q_0 = 0.75$，bootstrap 复制数 $B = 100$。\n\n程序输出规范：\n- 对于每个测试用例，您必须返回一个包含三个浮点数的列表 $[\\widehat{\\rho}, \\mathrm{CI}_{\\mathrm{low}}, \\mathrm{CI}_{\\mathrm{high}}]$，其中 $\\widehat{\\rho}$ 是如上定义的估计强阈值，而 $\\mathrm{CI}_{\\mathrm{low}}$ 和 $\\mathrm{CI}_{\\mathrm{high}}$ 是在名义覆盖率为 $1-\\alpha$ 时的 bootstrap 置信区间的下界和上界。\n- 您的程序应生成单行输出，其中包含结果，格式为方括号括起来的逗号分隔列表，每个测试用例一个条目，顺序与上面相同；例如，形式为 $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3]]$ 的输出，其中每个元素都是一个浮点数。\n\n为确保科学上的现实性，请确保模拟严格遵守所述的随机建模假设，并且所有线性代数运算在数值上都是鲁棒的。不要直接求解凸规划问题；您的程序必须基于凸最优性原理和有效的对偶证书。估计器必须在您实现的解决方案叙述中从第一性原理进行论证。", "solution": "该问题要求设计并实现一个基于模拟的估计器，用于估计无噪声压缩感知中的强恢复阈值。该估计过程建立在凸优化、统计推断和计算方法的基本原理之上。该过程包括三个主要部分：一个基于对偶证书的恢复验证测试，一个针对失败模式有限采样的统计修正，以及一个用于量化最终阈值估计不确定性的基于 bootstrap 的方法。\n\n物理模型考虑从 $m$ 个线性测量 $\\boldsymbol{y} = A\\boldsymbol{x}_0 \\in \\mathbb{R}^m$ 中恢复一个 $k$-稀疏信号 $\\boldsymbol{x}_0 \\in \\mathbb{R}^n$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个测量矩阵，其元素独立同分布于高斯分布 $N(0, 1/m)$。信号通过求解基追踪（Basis Pursuit）凸规划来恢复：\n$$\n\\min_{\\boldsymbol{x} \\in \\mathbb{R}^n} \\|\\boldsymbol{x}\\|_1 \\quad \\text{subject to} \\quad A\\boldsymbol{x} = \\boldsymbol{y}\n$$\n强恢复阈值是在给定采样率 $\\delta = m/n$ 下的最大归一化稀疏度 $\\rho = k/n$，在该稀疏度下，上述规划保证能够精确恢复 $\\boldsymbol{x}_0$，这对于矩阵 $A$ 的抽取以高概率成立，并且对 $\\boldsymbol{x}_0$ 的所有支撑集和符号模式选择一致成立。\n\n步骤 1：用于精确恢复的对偶证书\n\n我们无需直接求解 $\\ell_1$-最小化问题，而是可以通过构造一个对偶证书来验证候选信号 $\\boldsymbol{x}_0$ 是否是唯一解。Karush-Kuhn-Tucker (KKT) 最优性条件指出，如果存在一个对偶向量 $\\boldsymbol{\\nu} \\in \\mathbb{R}^m$ 满足以下条件，那么 $\\boldsymbol{x}_0$ 就是一个唯一解：\n$1$. $A_{T_0}^T \\boldsymbol{\\nu} = \\boldsymbol{s}_0$\n$2$. $\\| (A^T \\boldsymbol{\\nu})_{T_0^c} \\|_\\infty < 1$\n\n此处，$T_0$ 是 $\\boldsymbol{x}_0$ 的支撑集（即索引 $j$ 的集合，其中 $(x_0)_j \\neq 0$），$T_0^c$ 是其补集，$A_{T_0}$ 是由 $T_0$ 索引的列组成的 $A$ 的子矩阵，而 $\\boldsymbol{s}_0 = \\text{sign}((\\boldsymbol{x}_0)_{T_0})$ 是 $\\boldsymbol{x}_0$ 非零项的符号向量。\n\n第一个条件指定了对偶多项式 $A^T \\boldsymbol{\\nu}$ 在支撑集 $T_0$ 上的值，而第二个（严格）不等式确保没有其他稀疏信号可以是解。为了使这个测试可操作，我们必须构造这样一个 $\\boldsymbol{\\nu}$。方程 $A_{T_0}^T \\boldsymbol{\\nu} = \\boldsymbol{s}_0$ 是一个包含 $m$ 个变量的 $k$ 个方程的线性系统。对于 $k < m$ 的情况，该系统是欠定的。对 $\\boldsymbol{\\nu}$ 的一个典范选择是具有最小欧几里得范数 $\\|\\boldsymbol{\\nu}\\|_2$ 的解，可以使用 $A_{T_0}^T$ 的伪逆来找到：\n$$\n\\boldsymbol{\\nu} = (A_{T_0}^T)^+ \\boldsymbol{s}_0 = A_{T_0} (A_{T_0}^T A_{T_0})^{-1} \\boldsymbol{s}_0\n$$\n这就是我们用来检查唯一性条件的向量。对于给定的支撑集 $T_0$ 和符号模式 $\\boldsymbol{s}_0$，如果 $A_{T_0}^T A_{T_0}$ 是奇异的，或者 $\\| (A^T \\boldsymbol{\\nu})_{T_0^c} \\|_\\infty \\ge 1$，则测试失败。\n\n步骤 2：模拟协议和统计修正\n\n对于给定的矩阵 $A$ 和稀疏度 $k$，我们无法测试所有 $\\binom{n}{k} 2^k$ 种可能的支撑集/符号组合。相反，我们测试一个包含 $S$ 个随机选择的支撑集和符号模式对的有限样本。设 $F$ 为这 $S$ 次试验中观察到的失败次数。比率 $F/S$ 是该特定矩阵 $A$ 的真实失败概率 $p_A$ 的点估计。为了考虑有限采样带来的不确定性，我们计算 $p_A$ 的一个保守的单边置信上界。将 $S$ 次试验视为一个二项过程， $p_A$ 的 $(1-\\alpha)$ Clopper-Pearson 置信区间的上端点提供了这样一个界限。这个值 $p_{\\text{upper}}$ 是方程 $P(\\text{Binomial}(S, p_{\\text{upper}}) \\le F) = \\alpha$ 的解，并且可以使用 Beta 分布的分位数函数来计算：\n$$\np_{\\text{upper}} = \\text{Beta.ppf}(1 - \\alpha, F + 1, S - F)\n$$\n如果一个矩阵 $A$ 的失败概率的这个上界低于指定的容忍度 $\\varepsilon$，即 $p_{\\text{upper}} \\le \\varepsilon$，那么它就被分类为提供“有效一致恢复”。\n\n步骤 3：阈值估计和不确定性量化\n\n完整的估计过程如下。对于一个归一化稀疏度网格 $\\{\\rho_i\\}$，以及对于每个 $\\rho_i$，我们执行以下操作：\n$1$. 我们生成 $T$ 个独立的测量矩阵 $A$。\n$2$. 对于每个矩阵，我们根据上述准则 $p_{\\text{upper}} \\le \\varepsilon$ 来确定其分类（“通过”或“失败”），其中 $k = \\lfloor \\rho_i n \\rfloor$。\n$3$. 我们计算通过的矩阵的比例 $\\hat{q}_i$。\n$4$. 经验强阈值估计 $\\widehat{\\rho}$ 被确定为网格中最大的 $\\rho_i$，使得通过的矩阵比例至少为目标水平 $q_0$，即 $\\widehat{\\rho} = \\max\\{\\rho_i \\mid \\hat{q}_i \\ge q_0\\}$。如果没有 $\\rho_i$ 满足该条件，则 $\\widehat{\\rho}$ 取为 $0$。\n\n为了量化此估计 $\\widehat{\\rho}$ 的不确定性，我们采用非参数自助法。我们生成 $B$ 个 bootstrap 复制。对于每个复制，我们通过从原始的 $T$ 个分类集合中有放回地抽样，为每个 $\\rho_i$ 创建一个包含 $T$ 个矩阵分类的新数据集。然后我们为此 bootstrap 样本重新计算阈值 $\\widehat{\\rho}^*$。这个过程产生了一个包含 $B$ 个 bootstrap 阈值估计的分布 $\\{\\widehat{\\rho}^*_1, \\ldots, \\widehat{\\rho}^*_B\\}$。然后通过取该经验 bootstrap 分布的 $\\alpha/2$ 和 $1 - \\alpha/2$ 分位数来构造 $\\widehat{\\rho}$ 的 $(1-\\alpha)$ 百分位数置信区间。这就提供了最终的输出：点估计 $\\widehat{\\rho}$ 及其置信区间 $[\\mathrm{CI}_{\\mathrm{low}}, \\mathrm{CI}_{\\mathrm{high}}]$。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import beta\n\ndef estimate_strong_threshold(n, m, rho_grid, T, S, alpha, epsilon, q0, B, rng):\n    \"\"\"\n    Estimates the strong recovery threshold and its confidence interval.\n\n    Args:\n        n (int): Signal dimension.\n        m (int): Number of measurements.\n        rho_grid (list): Grid of normalized sparsity levels to test.\n        T (int): Number of random matrices to generate.\n        S (int): Number of support/sign patterns to test per matrix.\n        alpha (float): Confidence level parameter for CIs.\n        epsilon (float): Tolerance for the fraction of bad supports.\n        q0 (float): Target level for the fraction of good matrices.\n        B (int): Number of bootstrap replicates.\n        rng (np.random.Generator): A numpy random number generator.\n\n    Returns:\n        list: A list containing [rho_hat, CI_low, CI_high].\n    \"\"\"\n    all_matrix_classifications = {}\n\n    # Part 1: Main simulation to get original classifications for each rho\n    for rho in rho_grid:\n        k = int(rho * n)\n        if k == 0 or k > m:\n            # Skip trivial case or impossible case (k > m)\n            all_matrix_classifications[rho] = np.array([False] * T)\n            continue\n\n        matrix_classifications_for_rho = []\n        for _ in range(T):\n            # Generate a random measurement matrix A\n            A = rng.normal(loc=0.0, scale=1.0 / np.sqrt(m), size=(m, n))\n            \n            failures = 0\n            for _ in range(S):\n                # Sample a random support and sign pattern\n                support = rng.choice(n, k, replace=False)\n                signs = rng.choice([-1.0, 1.0], size=k)\n                \n                A_support = A[:, support]\n                \n                # Check recovery using the dual certificate.\n                # We need to find the minimum L2-norm solution to A_support.T @ nu = signs.\n                # np.linalg.lstsq is a numerically stable way to do this.\n                try:\n                    nu, _, rank, _ = np.linalg.lstsq(A_support.T, signs, rcond=None)\n                    \n                    # The rank check ensures A_support has full column rank k.\n                    if rank < k:\n                        failures += 1\n                        continue\n\n                    # Construct the dual polynomial and check the off-support condition\n                    dual_poly = A.T @ nu\n                    \n                    off_support_indices = np.ones(n, dtype=bool)\n                    off_support_indices[support] = False\n                    \n                    max_abs_off_support = np.max(np.abs(dual_poly[off_support_indices]))\n                    \n                    if max_abs_off_support >= 1.0:\n                        failures += 1\n                        \n                except np.linalg.LinAlgError:\n                    # This happens if lstsq fails, count as a failure.\n                    failures += 1\n\n            # Correct for support enumeration bias\n            # Compute a one-sided upper confidence bound on the failure fraction.\n            p_upper = beta.ppf(1 - alpha, failures + 1, S - failures)\n            \n            # Classify the matrix based on the tolerance epsilon.\n            is_pass = (p_upper <= epsilon)\n            matrix_classifications_for_rho.append(is_pass)\n        \n        all_matrix_classifications[rho] = np.array(matrix_classifications_for_rho, dtype=bool)\n\n    # Part 2: Calculate the empirical threshold rho_hat\n    q_hat_values = {rho: np.mean(classifications) for rho, classifications in all_matrix_classifications.items()}\n    passing_rhos = [rho for rho, q_hat in q_hat_values.items() if q_hat >= q0]\n    rho_hat = max(passing_rhos) if passing_rhos else 0.0\n\n    # Part 3: Nonparametric bootstrap for the confidence interval\n    bootstrap_thresholds = []\n    for _ in range(B):\n        bootstrap_q_hats = {}\n        for rho in rho_grid:\n            # Resample matrix classifications with replacement\n            bootstrap_indices = rng.choice(T, T, replace=True)\n            bootstrap_sample = all_matrix_classifications[rho][bootstrap_indices]\n            bootstrap_q_hats[rho] = np.mean(bootstrap_sample)\n        \n        # Recompute the threshold for this bootstrap replicate\n        passing_rhos_star = [rho for rho, q_star in bootstrap_q_hats.items() if q_star >= q0]\n        rho_star = max(passing_rhos_star) if passing_rhos_star else 0.0\n        bootstrap_thresholds.append(rho_star)\n\n    # Part 4: Calculate CI from the bootstrap distribution using percentiles\n    ci_low = np.percentile(bootstrap_thresholds, 100 * alpha / 2.0)\n    ci_high = np.percentile(bootstrap_thresholds, 100 * (1 - alpha / 2.0))\n    \n    return [rho_hat, ci_low, ci_high]\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test Case 1\n        {\"n\": 30, \"m\": 18, \"rho_grid\": [0.10, 0.15, 0.20, 0.25, 0.30, 0.35], \n         \"T\": 12, \"S\": 40, \"alpha\": 0.05, \"epsilon\": 0.10, \"q0\": 0.80, \"B\": 150},\n        # Test Case 2\n        {\"n\": 28, \"m\": 14, \"rho_grid\": [0.10, 0.15, 0.20, 0.25], \n         \"T\": 12, \"S\": 50, \"alpha\": 0.05, \"epsilon\": 0.05, \"q0\": 0.80, \"B\": 150},\n        # Test Case 3\n        {\"n\": 24, \"m\": 16, \"rho_grid\": [0.20, 0.25, 0.30, 0.35, 0.40], \n         \"T\": 10, \"S\": 30, \"alpha\": 0.05, \"epsilon\": 0.10, \"q0\": 0.75, \"B\": 100},\n    ]\n\n    # Use a fixed random seed for reproducibility of the output\n    rng = np.random.default_rng(seed=42)\n    \n    results = []\n    for params in test_cases:\n        result = estimate_strong_threshold(\n            n=params[\"n\"],\n            m=params[\"m\"],\n            rho_grid=params[\"rho_grid\"],\n            T=params[\"T\"],\n            S=params[\"S\"],\n            alpha=params[\"alpha\"],\n            epsilon=params[\"epsilon\"],\n            q0=params[\"q0\"],\n            B=params[\"B\"],\n            rng=rng\n        )\n        results.append(result)\n\n    # Format the final output string exactly as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3494353"}]}