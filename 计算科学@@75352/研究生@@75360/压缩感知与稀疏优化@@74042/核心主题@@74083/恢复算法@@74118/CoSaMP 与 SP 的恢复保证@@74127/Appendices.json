{"hands_on_practices": [{"introduction": "像CoSaMP和SP这类算法的理论恢复保证通常使用限制等距性质（RIP）来表述。本练习提供了一种将这些抽象的、基于RIP的条件转化为对传感矩阵的互相关性 $\\mu$ 的更具体要求。通过解决这个问题，你将从确定性矩阵性质的角度，对CoSaMP和SP的性能保证如何进行量化比较获得深入理解。[@problem_id:3473289]", "problem": "考虑一个传感矩阵 $ \\Phi \\in \\mathbb{R}^{m \\times n} $，其列为单位范数列，用于通过 $y = \\Phi x + e$ 测量一个 $k$-稀疏信号 $x \\in \\mathbb{R}^{n}$，其中 $e$ 是测量噪声。令阶数为 $s$ 的有限等距性质 (Restricted Isometry Property, RIP) 常数表示为 $ \\delta_{s} $，其定义为满足对于所有 $s$-稀疏向量 $z$ 都有 $ (1 - \\delta_{s}) \\|z\\|_{2}^{2} \\le \\|\\Phi z\\|_{2}^{2} \\le (1 + \\delta_{s}) \\|z\\|_{2}^{2} $ 成立的最小非负数。令 $ \\Phi $ 的互相关性为 $ \\mu := \\max_{i \\ne j} |\\langle \\phi_{i}, \\phi_{j} \\rangle| $，其中 $ \\phi_{i} $ 表示 $ \\Phi $ 的第 $i$ 列。已知对于具有单位范数列的确定性矩阵，形式为 $ \\delta_{s} \\le (s-1)\\mu $ 的通用上界成立。\n\n假设当 RIP 条件 $ \\delta_{4k} \\le \\alpha $ 成立时，压缩采样匹配追踪 (Compressive Sampling Matching Pursuit, CoSaMP) 算法保证能够稳定地恢复任何 $k$-稀疏信号，并且当 RIP 条件 $ \\delta_{3k} \\le \\beta $ 成立时，子空间追踪 (Subspace Pursuit, SP) 算法保证能够稳定地恢复任何 $k$-稀疏信号，其中 $ \\alpha \\in (0,1) $ 和 $ \\beta \\in (0,1) $ 是与 $ \\mu $ 和 $k$ 无关的固定常数。\n\n仅使用上述定义和界 $ \\delta_{s} \\le (s-1)\\mu $，将这些基于 RIP 的保证转换为充分的互相关性条件，该条件将 CoSaMP 和 SP 的可容许稀疏度水平 $k$ 上限表示为 $ \\mu, \\alpha, \\beta $ 的显式函数。然后，为了在高度不相关矩阵（即 $ \\mu \\to 0 $）的情况下量化这些基于相关性条件的相对保守性，计算当 $ \\mu \\to 0 $ 时，SP 的最大允许稀疏度与 CoSaMP 的最大允许稀疏度之比的极限。你的最终答案必须是仅含 $ \\alpha $ 和 $ \\beta $ 的单个闭式解析表达式。不包含单位。不提供不等式。不要四舍五入。", "solution": "用户希望我验证问题陈述，如果有效，则提供解决方案。\n\n### 第一步：提取已知条件\n-   传感矩阵：$ \\Phi \\in \\mathbb{R}^{m \\times n} $，其列 $ \\phi_{i} $ 为单位范数列。\n-   信号模型：$ y = \\Phi x + e $，其中 $ x \\in \\mathbb{R}^{n} $ 是一个 $k$-稀疏信号，$ e $ 是测量噪声。\n-   阶数为 $ s $ 的有限等距性质 (RIP) 常数：$ \\delta_{s} $ 是满足对于所有 $s$-稀疏向量 $ z $ 都有 $ (1 - \\delta_{s}) \\|z\\|_{2}^{2} \\le \\|\\Phi z\\|_{2}^{2} \\le (1 + \\delta_{s}) \\|z\\|_{2}^{2} $ 的最小数。\n-   互相关性：$ \\mu := \\max_{i \\ne j} |\\langle \\phi_{i}, \\phi_{j} \\rangle| $。\n-   RIP 与互相关性之间的关系：$ \\delta_{s} \\le (s-1)\\mu $。\n-   CoSaMP 恢复保证：如果 $ \\delta_{4k} \\le \\alpha $ 成立，则保证成立，其中 $ \\alpha \\in (0,1) $。\n-   SP 恢复保证：如果 $ \\delta_{3k} \\le \\beta $ 成立，则保证成立，其中 $ \\beta \\in (0,1) $。\n-   任务1：推导基于互相关性的充分条件，为 CoSaMP 和 SP 的可容许稀疏度 $k$ 提供上界。\n-   任务2：计算 $ \\lim_{\\mu \\to 0} \\frac{k_{SP}}{k_{C}} $，其中 $k_C$ 和 $k_{SP}$ 分别是从基于相关性的条件中推导出的 CoSaMP 和 SP 的最大允许稀疏度。最终答案应以 $ \\alpha $ 和 $ \\beta $ 表示。\n\n### 第二步：使用提取的已知条件进行验证\n问题陈述在已建立的压缩感知理论框架内具有科学依据。所有定义（$ \\delta_s $，$ \\mu $）和关系（$ \\delta_s \\le (s-1)\\mu $）都是该领域的标准内容。CoSaMP 和 SP 的恢复保证以一种标准的、尽管是通用的形式呈现，使用了符号常数 $ \\alpha $ 和 $ \\beta $。该问题是适定的、自包含的，并且可以形式化为一个可解的数学问题。它没有矛盾、歧义或事实错误。任务清晰，并能导出一个唯一的、有意义的解。\n\n### 第三步：结论与行动\n问题有效。我将继续进行解答。\n\n解题过程包括两个主要部分：首先，为每种算法推导基于互相关性的稀疏度 $k$ 的上界；其次，计算这些上界之比的极限。\n\n第一部分：基于互相关性的稀疏度界推导\n\n对于压缩采样匹配追踪 (Compressive Sampling Matching Pursuit, CoSaMP) 算法，所述的稳定恢复的充分条件由基于 RIP 的不等式给出：\n$$ \\delta_{4k} \\le \\alpha $$\n我们已知关联 RIP 常数 $ \\delta_s $ 与互相关性 $ \\mu $ 的通用界：\n$$ \\delta_{s} \\le (s-1)\\mu $$\n为了找到一个基于互相关性的充分条件来保证 CoSaMP 的恢复条件，我们可以将 $ s = 4k $ 代入此界：\n$$ \\delta_{4k} \\le (4k-1)\\mu $$\n因此，如果我们强制执行条件 $ (4k-1)\\mu \\le \\alpha $，就意味着 $ \\delta_{4k} \\le \\alpha $ 得到满足。这给了我们一个基于 $ \\mu $ 的充分条件。我们现在可以求解满足此条件的最大允许稀疏度水平，记为 $ k_C $。\n$$ (4k_C - 1)\\mu \\le \\alpha $$\n假设 $ \\mu  0 $，我们可以重排不等式：\n$$ 4k_C - 1 \\le \\frac{\\alpha}{\\mu} $$\n$$ 4k_C \\le \\frac{\\alpha}{\\mu} + 1 $$\n$$ k_C \\le \\frac{1}{4} \\left( \\frac{\\alpha}{\\mu} + 1 \\right) $$\n该表达式表示在基于相关性的条件下 CoSaMP 的稀疏度水平的上界。最大允许稀疏度的尺度为 $ k_C(\\mu) = \\frac{1}{4} \\left( \\frac{\\alpha}{\\mu} + 1 \\right) $。\n\n类似地，对于子空间追踪 (Subspace Pursuit, SP) 算法，稳定恢复的充分条件由以下公式给出：\n$$ \\delta_{3k} \\le \\beta $$\n使用相同的界 $ \\delta_s \\le (s-1)\\mu $，我们代入 $ s = 3k $：\n$$ \\delta_{3k} \\le (3k-1)\\mu $$\n因此，SP 恢复的一个基于互相关性的充分条件是 $ (3k-1)\\mu \\le \\beta $。我们求解最大允许稀疏度水平，记为 $ k_{SP} $：\n$$ (3k_{SP} - 1)\\mu \\le \\beta $$\n$$ 3k_{SP} - 1 \\le \\frac{\\beta}{\\mu} $$\n$$ 3k_{SP} \\le \\frac{\\beta}{\\mu} + 1 $$\n$$ k_{SP} \\le \\frac{1}{3} \\left( \\frac{\\beta}{\\mu} + 1 \\right) $$\n在此条件下，SP 的最大允许稀疏度的尺度为 $ k_{SP}(\\mu) = \\frac{1}{3} \\left( \\frac{\\beta}{\\mu} + 1 \\right) $。\n\n第二部分：比率极限的计算\n\n问题要求我们计算在高度不相关矩阵（即 $ \\mu \\to 0 $）的情况下，SP 的最大允许稀疏度与 CoSaMP 的最大允许稀疏度之比的极限。\n该比率由以下公式给出：\n$$ \\frac{k_{SP}(\\mu)}{k_C(\\mu)} = \\frac{\\frac{1}{3} \\left( \\frac{\\beta}{\\mu} + 1 \\right)}{\\frac{1}{4} \\left( \\frac{\\alpha}{\\mu} + 1 \\right)} $$\n我们可以简化这个表达式：\n$$ \\frac{k_{SP}(\\mu)}{k_C(\\mu)} = \\frac{4}{3} \\cdot \\frac{\\frac{\\beta}{\\mu} + 1}{\\frac{\\alpha}{\\mu} + 1} $$\n为了评估 $ \\mu \\to 0 $ 时的极限，我们可以将分数的分子和分母同乘以 $ \\mu $：\n$$ \\frac{k_{SP}(\\mu)}{k_C(\\mu)} = \\frac{4}{3} \\cdot \\frac{\\mu \\left( \\frac{\\beta}{\\mu} + 1 \\right)}{\\mu \\left( \\frac{\\alpha}{\\mu} + 1 \\right)} = \\frac{4}{3} \\cdot \\frac{\\beta + \\mu}{\\alpha + \\mu} $$\n现在，我们可以取 $ \\mu \\to 0 $ 的极限。由于 $ \\alpha \\in (0,1) $ 且 $ \\beta \\in (0,1) $，该函数在 $ \\mu = 0 $ 处是连续的。\n$$ \\lim_{\\mu \\to 0} \\frac{k_{SP}(\\mu)}{k_C(\\mu)} = \\lim_{\\mu \\to 0} \\left( \\frac{4}{3} \\cdot \\frac{\\beta + \\mu}{\\alpha + \\mu} \\right) $$\n代入 $ \\mu = 0 $：\n$$ \\lim_{\\mu \\to 0} \\frac{k_{SP}(\\mu)}{k_C(\\mu)} = \\frac{4}{3} \\cdot \\frac{\\beta + 0}{\\alpha + 0} = \\frac{4\\beta}{3\\alpha} $$\n该结果量化了在互相关性很小的情况下，SP 和 CoSaMP 的基于相关性的恢复条件的相对性能。", "answer": "$$\\boxed{\\frac{4\\beta}{3\\alpha}}$$", "id": "3473289"}, {"introduction": "虽然不同的贪婪算法遵循共同的设计理念，但它们具体的执行机制可能导致截然不同的结果。这个实践问题提供了一个极具启发性的案例研究：在同一场景下，较为简单的正交匹配追踪（OMP）算法成功恢复了信号，而更复杂的子空间追踪（SP）算法却失败了。通过逐步模拟这两种算法的执行过程，你将揭示高互相关性是如何误导SP的选择策略的，从而具体地展示了理论保证旨在防止的失败模式。[@problem_id:3473283]", "problem": "考虑线性模型 $y = A x^{\\star} + e$，其中感知矩阵为 $A \\in \\mathbb{R}^{m \\times n}$，未知$k$-稀疏信号为 $x^{\\star} \\in \\mathbb{R}^{n}$（其支撑集为 $S^{\\star}$），噪声为 $e \\in \\mathbb{R}^{m}$。对于一个矩阵 $A$，其常数为 $\\delta_s$ 的 $s$ 阶有限等距性质 (Restricted Isometry Property, RIP) 定义为：对于所有 $s$-稀疏向量 $z$，满足 $(1-\\delta_s)\\|z\\|_2^2 \\le \\|A z\\|_2^2 \\le (1+\\delta_s)\\|z\\|_2^2$。互相关性 $\\mu(A)$ 定义为 $\\mu(A) = \\max_{i \\neq j} |a_i^\\top a_j|$，其中 $\\{a_i\\}$ 是 $A$ 的单位范数列。\n\n正交匹配追踪 (Orthogonal Matching Pursuit, OMP) 在每次迭代中选择 $A$ 中与当前残差具有最大绝对相关性的单个列，然后将测量值正交投影到所选列的张成空间上。子空间追踪 (Subspace Pursuit, SP) 维护一个大小为 $k$ 的支撑集估计；在每次迭代中，它通过选取与残差具有最大 $k$ 个相关性的索引来扩展支撑集（形成一个大小最多为 $2k$ 的候选集），然后在这个候选集上求解一个最小二乘问题，接着将解向量剪枝至 $k$ 个最大的元素，并相应地更新残差。在无噪声设置下，当残差变为零时，SP 通常会终止。\n\n给定以下四个候选实例 $(A, x^{\\star}, e)$，所有实例中 $m=3$，$n=4$，$k=2$，$A$ 的列均被归一化为单位 $\\ell_2$ 范数，且 $e=0$。在每个实例中，都指定了 $A = [a_1, a_2, a_3, a_4]$ 和 $x^{\\star} \\in \\mathbb{R}^4$。请确定在相同的 $A$ 和 $e$ 条件下，哪个实例表现出以下现象：OMP 在恰好 $k$ 次迭代中精确恢复了真实支撑集 $S^{\\star}$，而 SP 却失败了，返回了一个不同的支撑集（但仍然实现了零残差）。你的推理应基于上述定义，并应解释该示例如何与已知的 SP 的 RIP 类型均匀恢复保证相一致。\n\n选项 A:\n- $a_1 = [1,0,0]^\\top$, $a_2 = [0,1,0]^\\top$, $a_3 = \\dfrac{1}{\\sqrt{26}}[1,5,0]^\\top$, $a_4 = [0,0,1]^\\top$.\n- $x^{\\star} = [1,\\,0.8,\\,0,\\,0]^\\top$，因此 $S^{\\star} = \\{1,2\\}$。\n- $e = 0$。\n\n选项 B:\n- $a_1 = [1,0,0]^\\top$, $a_2 = [0,1,0]^\\top$, $a_3 = \\dfrac{1}{\\sqrt{1.04}}[1,0.2,0]^\\top$, $a_4 = [0,0,1]^\\top$.\n- $x^{\\star} = [1,\\,0.8,\\,0,\\,0]^\\top$，因此 $S^{\\star} = \\{1,2\\}$。\n- $e = 0$。\n\n选项 C:\n- $a_1 = [1,0,0]^\\top$, $a_2 = [0,1,0]^\\top$, $a_3 = \\dfrac{1}{\\sqrt{2}}[1,0,1]^\\top$, $a_4 = [0,0,1]^\\top$.\n- $x^{\\star} = [1,\\,0.8,\\,0,\\,0]^\\top$，因此 $S^{\\star} = \\{1,2\\}$。\n- $e = 0$。\n\n选项 D:\n- $a_1 = [1,0,0]^\\top$, $a_2 = [0,1,0]^\\top$, $a_3 = \\dfrac{1}{\\sqrt{26}}[1,-5,0]^\\top$, $a_4 = [0,0,1]^\\top$.\n- $x^{\\star} = [1,\\,0.8,\\,0,\\,0]^\\top$，因此 $S^{\\star} = \\{1,2\\}$。\n- $e = 0$。\n\n选项：\nA. 只有选项 A 表现出在相同的 A 和 e 条件下，OMP 成功而 SP 失败。\nB. 只有选项 B 表现出在相同的 A 和 e 条件下，OMP 成功而 SP 失败。\nC. 只有选项 C 表现出在相同的 A 和 e 条件下，OMP 成功而 SP 失败。\nD. 只有选项 D 表现出在相同的 A 和 e 条件下，OMP 成功而 SP 失败。", "solution": "该问题陈述是稀疏恢复算法分析中的一个有效练习。它在科学上基于压缩感知的原理，问题设置得当，预期在选项中有一个唯一答案，并且使用标准的数学定义进行了客观陈述。执行分析所需的所有数据均已提供。因此，我们可以着手求解。\n\n问题要求从四个选项中找出一个实例，在该实例中，正交匹配追踪 (OMP) 在 $k=2$ 次迭代中成功恢复了真实支撑集 $S^{\\star}$，而子空间追踪 (SP) 失败了，返回了一个不同的支撑集。该设置为无噪声 ($e=0$)。\n\n对于所有四个选项，参数为：\n- 维度: $m=3$, $n=4$\n- 稀疏度: $k=2$\n- 真实信号: $x^{\\star} = [1, 0.8, 0, 0]^\\top$\n- 真实支撑集: $S^{\\star} = \\{1, 2\\}$\n- $A$ 的列被归一化为单位 $\\ell_2$ 范数。\n- 测量向量 $y$ 由 $y = A x^{\\star} = a_1 x_1^{\\star} + a_2 x_2^{\\star}$ 给出。由于所有选项中 $a_1 = [1,0,0]^\\top$ 且 $a_2 = [0,1,0]^\\top$，因此测量向量在所有实例中都是恒定的：\n$$y = 1 \\cdot \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + 0.8 \\cdot \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0.8 \\\\ 0 \\end{pmatrix}$$\n\nOMP 和 SP 都首先计算 $A$ 的列与初始残差 $r_0=y$ 的相关性。令 $c_i = a_i^\\top r_0 = a_i^\\top y$。对于所有选项，我们有：\n- $c_1 = a_1^\\top y = [1,0,0] [1, 0.8, 0]^\\top = 1$。\n- $c_2 = a_2^\\top y = [0,1,0] [1, 0.8, 0]^\\top = 0.8$。\n- 问题指定所有选项的 $a_4 = [0,0,1]^\\top$，所以 $c_4 = a_4^\\top y = [0,0,1] [1, 0.8, 0]^\\top = 0$。\n分析将取决于每个选项中 $c_3 = a_3^\\top y$ 的值。\n\n### 选项 A 的分析\n\n- **已知条件**: $a_3 = \\frac{1}{\\sqrt{26}}[1,5,0]^\\top$。\n- **初始相关性**: $c_3 = a_3^\\top y = \\frac{1}{\\sqrt{26}}[1,5,0] [1, 0.8, 0]^\\top = \\frac{1(1) + 5(0.8)}{\\sqrt{26}} = \\frac{5}{\\sqrt{26}}$。\n数值上， $|c_3| = \\frac{5}{\\sqrt{26}} \\approx 0.9806$。\n初始相关性的量值排序如下：$|c_1| = 1  |c_3| \\approx 0.9806  |c_2| = 0.8  |c_4| = 0$。\n\n- **OMP 模拟**:\n  1. **迭代 1**: 最大的相关性是 $|c_1|=1$。OMP 选择索引 $i_1 = 1$。新的支撑集估计为 $S_1 = \\{1\\}$。通过将 $y$ 投影到 $a_1$ 的张成空间上来更新残差：\n  $r_1 = y - a_1 (a_1^\\top y) = [1, 0.8, 0]^\\top - [1,0,0]^\\top(1) = [0, 0.8, 0]^\\top$。\n  2. **迭代 2**: 我们计算与新残差 $r_1$ 的相关性：\n     - $|\\langle a_2, r_1 \\rangle| = |[0,1,0] [0, 0.8, 0]^\\top| = 0.8$。\n     - $|\\langle a_3, r_1 \\rangle| = |\\frac{1}{\\sqrt{26}}[1,5,0] [0, 0.8, 0]^\\top| = |\\frac{5(0.8)}{\\sqrt{26}}| = \\frac{4}{\\sqrt{26}} \\approx 0.7845$。\n     - $|\\langle a_4, r_1 \\rangle| = |[0,0,1] [0, 0.8, 0]^\\top| = 0$。\n  最大的相关性是 $0.8$，对应索引 $i_2 = 2$。OMP 将此索引添加到支撑集中：$S_2 = \\{1, 2\\}$。\n- **OMP 结论**: OMP 在 $k=2$ 步后终止，得到正确的支撑集 $S_2 = S^{\\star}$。因此，**OMP 成功**。\n\n- **SP 模拟**:\n  1. **迭代 1**:\n     - **识别**: SP 识别出具有最大初始相关性的 $k=2$ 个索引。根据我们的排序，这些是索引 $1$ 和 $3$。候选集为 $T_{cand} = \\{1, 3\\}$。\n     - **合并**: 候选支撑集为 $S_{cand} = S_0 \\cup T_{cand} = \\{1, 3\\}$。\n     - **最小二乘**: SP 求解最小二乘问题 $\\min_z \\|y - A_{S_{cand}} z\\|_2^2$。这里，$A_{S_{cand}} = [a_1, a_3] = \\begin{pmatrix} 1  1/\\sqrt{26} \\\\ 0  5/\\sqrt{26} \\\\ 0  0 \\end{pmatrix}$。通过求解 $A_{S_{cand}}z = y$ 来找到解 $z = [z_1, z_3]^\\top$：\n     $$ \\begin{pmatrix} 1  1/\\sqrt{26} \\\\ 0  5/\\sqrt{26} \\end{pmatrix} \\begin{pmatrix} z_1 \\\\ z_3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0.8 \\end{pmatrix} $$\n     从第二行，$(5/\\sqrt{26}) z_3 = 0.8 \\implies z_3 = 0.8 \\sqrt{26} / 5 = 0.16\\sqrt{26}$。\n     从第一行，$z_1 + (1/\\sqrt{26})z_3 = 1 \\implies z_1 = 1 - 0.16 = 0.84$。\n     所以，临时信号向量仅在 $\\{1,3\\}$ 上非零，其值为 $z_1 = 0.84$ 和 $z_3 = 0.16\\sqrt{26} \\approx 0.8158$。\n     - **剪枝**: SP 将支撑集 $S_{cand}$ 剪枝到 $z$ 中 $k=2$ 个最大量值的元素。由于只有两个元素，新的支撑集估计为 $S_1=\\{1, 3\\}$。\n     - **更新残差**: $r_1 = y - A_{S_1} z$。由于 $A_{S_1}z$ 精确等于 $y$，残差 $r_1$ 是零向量。\n- **SP 结论**: SP 在一次迭代后终止，因为残差为零。它返回的支撑集是 $S_1=\\{1, 3\\}$，而不是真实的支撑集 $S^{\\star}=\\{1, 2\\}$。因此，**SP 失败**。\n\n- **结论**: 选项 A 表现出指定的行为：OMP 成功，而 SP 失败。\n\n### 其他选项的分析\n\n- **选项 B**: $a_3 = \\frac{1}{\\sqrt{1.04}}[1,0.2,0]^\\top$。\n  $c_3 = a_3^\\top y = \\frac{1}{\\sqrt{1.04}}(1(1) + 0.2(0.8)) = \\frac{1.16}{\\sqrt{1.04}} \\approx 1.137$。\n  初始相关性的排序为 $|c_3| \\approx 1.137  |c_1|=1  |c_2|=0.8  |c_4|=0$。\n  OMP 的第一步选择索引 3，该索引不在真实支撑集 $S^{\\star}=\\{1,2\\}$ 中。因此，OMP 未能恢复 $S^{\\star}$。此选项不正确。\n\n- **选项 C**: $a_3 = \\frac{1}{\\sqrt{2}}[1,0,1]^\\top$。\n  $c_3 = a_3^\\top y = \\frac{1}{\\sqrt{2}}(1(1) + 0(0.8) + 1(0)) = \\frac{1}{\\sqrt{2}} \\approx 0.707$。\n  初始相关性的排序为 $|c_1|=1  |c_2|=0.8  |c_3|\\approx0.707  |c_4|=0$。\n  **OMP**: 将选择索引 1，然后是索引 2。OMP 成功。\n  **SP**: 在其识别步骤中，它选择了前 $k=2$ 个最大的相关性，这对应于索引 1 和 2。SP 在第一次迭代中正确地识别了支撑集。SP 成功。\n  此选项不正确，因为两种算法都成功了。\n\n- **选项 D**: $a_3 = \\frac{1}{\\sqrt{26}}[1,-5,0]^\\top$。\n  $c_3 = a_3^\\top y = \\frac{1}{\\sqrt{26}}(1(1) - 5(0.8)) = \\frac{1-4}{\\sqrt{26}} = \\frac{-3}{\\sqrt{26}}$。\n  $|c_3| = \\frac{3}{\\sqrt{26}} \\approx 0.588$。\n  初始相关性的排序为 $|c_1|=1  |c_2|=0.8  |c_3|\\approx0.588  |c_4|=0$。\n  与选项 C 类似，OMP 和 SP 都会首先选择索引 1 和 2，并将成功恢复真实支撑集。此选项不正确。\n\n### 与恢复保证的一致性\n\n选项 A 中 SP 的失败与已知的恢复保证是一致的，这些保证通常依赖于有限等距性质 (RIP)。SP 保证恢复任何 $k$-稀疏信号的一个常见充分条件是 RIP 常数 $\\delta_{2k}$ 必须足够小（例如，$\\delta_{2k}  \\sqrt{2}-1$）。\n在我们的例子中，$k=2$，所以条件涉及 $\\delta_4$。感知矩阵 $A$ 属于 $\\mathbb{R}^{3 \\times 4}$。$\\mathbb{R}^3$ 中的任意 4 个向量集合必然是线性相关的。这意味着存在一个非零向量 $z \\in \\mathbb{R}^4$（它是 4-稀疏的），使得 $Az=0$。\nRIP 定义指出 $(1-\\delta_4)\\|z\\|_2^2 \\le \\|Az\\|_2^2$。对于这个 $z$，我们有 $(1-\\delta_4)\\|z\\|_2^2 \\le 0$。由于 $\\|z\\|_2^2  0$，这迫使 $1-\\delta_4 \\le 0$，即 $\\delta_4 \\ge 1$。\nRIP 常数 $\\delta_4$ 不满足任何 $c1$ 的条件 $\\delta_4  c$。因此，SP 的均匀恢复保证不适用于该矩阵 $A$。因此，存在一个 SP 失败的实例 $(x^{\\star}, e)$ 与理论是完全一致的。失败是由列之间的高互相关性引起的（例如， $|a_2^\\top a_3| = 5/\\sqrt{26} \\approx 0.98$），这导致了一种“共谋”，即一个错误的支撑集可以解释测量值。\n\n基于详尽的分析，只有选项 A 展示了在给定条件下 OMP 成功而 SP 失败的现象。", "answer": "$$\\boxed{A}$$", "id": "3473283"}, {"introduction": "恢复保证通常为成功恢复提供了*充分*条件，但理解其*必要*条件也同样重要。本练习将指导你构建一个特殊的传感矩阵，它从根本上违背了稀疏信号恢复的核心原则，导致两个不同的稀疏信号产生了完全相同的测量值。通过计算该矩阵的RIP常数，你将看到当其值达到一个临界阈值时，无论使用何种算法，唯一的信号恢复都将变得不可能。[@problem_id:3473250]", "problem": "设 $k \\in \\mathbb{N}$ 且 $m \\geq 4k$。考虑一个矩阵 $\\boldsymbol{B} \\in \\mathbb{R}^{m \\times 4k}$，其列是标准正交的，因此 $\\boldsymbol{B}^{\\top}\\boldsymbol{B} = \\boldsymbol{I}_{4k}$。构建测量矩阵\n$$\n\\boldsymbol{A} \\triangleq \\begin{bmatrix}\\boldsymbol{B}  \\boldsymbol{B}\\end{bmatrix} \\in \\mathbb{R}^{m \\times 8k},\n$$\n即，$\\boldsymbol{A}$ 由 $\\boldsymbol{B}$ 的列的两个相同副本组成。设 $\\delta_{s}(\\boldsymbol{A})$ 表示阶数为 $s$ 的受限等距常数（RIC），定义为最小的 $\\delta \\geq 0$，使得对于所有 $s$-稀疏向量 $\\boldsymbol{z} \\in \\mathbb{R}^{8k}$，满足\n$$\n(1-\\delta)\\|\\boldsymbol{z}\\|_{2}^{2} \\leq \\|\\boldsymbol{A}\\boldsymbol{z}\\|_{2}^{2} \\leq (1+\\delta)\\|\\boldsymbol{z}\\|_{2}^{2}.\n$$\n设 $\\tau \\in (0,1)$ 表示一个贪婪稀疏恢复算法（例如 Compressive Sampling Matching Pursuit (CoSaMP) 或 Subspace Pursuit (SP)）的任意固定充分条件阈值，其意义在于当 $\\delta_{4k}(\\boldsymbol{A}) \\leq \\tau$ 时，该算法有已知的正确性保证。定义 $\\varepsilon \\triangleq 1 - \\tau  0$。\n\n任务：\n- 仅使用受限等距性质的定义和基础线性代数，计算 $\\delta_{4k}(\\boldsymbol{A})$ 的精确值。\n- 从第一性原理出发，简要论证为何存在两个不同的 $k$-稀疏向量 $\\boldsymbol{x}, \\boldsymbol{x}' \\in \\mathbb{R}^{8k}$ 满足 $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{A}\\boldsymbol{x}'$，即使在无噪声测量的情况下，从而证明当 $\\delta_{4k}(\\boldsymbol{A}) = \\tau + \\varepsilon$ 时，精确恢复可能会失败。\n\n答案规范：\n- 你的最终答案必须是 $\\delta_{4k}(\\boldsymbol{A})$ 的值，它是一个无单位的精确实数。", "solution": "我们从受限等距性质（RIP）的定义和格拉姆矩阵的基本谱分析入手。\n\n步骤 1：测量矩阵的结构及其在大小至多为 $4k$ 的支撑集上的格拉姆形式。\n\n根据构造，$\\boldsymbol{A} = [\\boldsymbol{B}\\ \\boldsymbol{B}]$ 且 $\\boldsymbol{B}^{\\top}\\boldsymbol{B} = \\boldsymbol{I}_{4k}$。对于任意索引集 $\\mathcal{S} \\subset \\{1,2,\\dots,8k\\}$，用 $\\boldsymbol{A}_{\\mathcal{S}}$ 表示通过选择 $\\boldsymbol{A}$ 中由 $\\mathcal{S}$ 索引的列构成的子矩阵。在 $\\mathcal{S}$ 上的受限格拉姆矩阵是\n$$\n\\boldsymbol{G}_{\\mathcal{S}} \\triangleq \\boldsymbol{A}_{\\mathcal{S}}^{\\top}\\boldsymbol{A}_{\\mathcal{S}}.\n$$\n由于 $\\boldsymbol{A}$ 的列由 $\\boldsymbol{B}$ 的列的两个相同副本组成，$\\boldsymbol{G}_{\\mathcal{S}}$ 的结构取决于 $\\mathcal{S}$ 如何从第一个或第二个副本中选择列。\n\n如果 $\\mathcal{S}$ 不包含任何重复列对（即，从不同时包含第一个副本的第 $j$ 列和第二个副本的第 $j$ 列），那么所选列是标准正交的：$\\boldsymbol{G}_{\\mathcal{S}} = \\boldsymbol{I}_{|\\mathcal{S}|}$。\n\n如果对于某个索引 $j \\in \\{1,\\dots,4k\\}$，$\\mathcal{S}$ 包含列 $j$ 的两个副本，则 $\\boldsymbol{G}_{\\mathcal{S}}$ 中对应这两列的 $2 \\times 2$ 主子矩阵等于\n$$\n\\begin{bmatrix}\n1  1\\\\\n1  1\n\\end{bmatrix},\n$$\n因为这两列是相同的且范数为单位1。这个 $2 \\times 2$ 块的特征值为 $\\lambda_{+} = 2$ 和 $\\lambda_{-} = 0$，对应的标准正交特征向量分别为 $\\frac{1}{\\sqrt{2}}[1,1]^{\\top}$ 和 $\\frac{1}{\\sqrt{2}}[1,-1]^{\\top}$。\n\n由于任何大小至多为 $4k$ 的支撑集 $\\mathcal{S}$ 最多可包含 $4k$ 个索引，因此可以为某个 $j$ 选择一个大小为 $2$ 且包含重复对的支撑集 $\\mathcal{S}$。因此，要计算 $\\delta_{4k}(\\boldsymbol{A})$，我们必须考虑在所有 $|\\mathcal{S}| \\leq 4k$ 中 $\\boldsymbol{G}_{\\mathcal{S}}$ 与单位矩阵的最坏情况偏差。\n\n步骤 2：通过极值特征值计算受限等距常数。\n\n根据受限等距常数的定义，对于任何支撑在 $\\mathcal{S}$ 上且 $|\\mathcal{S}| \\leq s$ 的 $s$-稀疏向量 $\\boldsymbol{z}$，我们有\n$$\n\\|\\boldsymbol{A}\\boldsymbol{z}\\|_{2}^{2} = \\boldsymbol{z}_{\\mathcal{S}}^{\\top}\\boldsymbol{G}_{\\mathcal{S}} \\boldsymbol{z}_{\\mathcal{S}},\n$$\n且最小的 $\\delta_{s}$ 是\n$$\n\\delta_{s}(\\boldsymbol{A}) = \\max_{|\\mathcal{S}| \\leq s} \\max\\left\\{\\, 1 - \\lambda_{\\min}(\\boldsymbol{G}_{\\mathcal{S}}),\\ \\lambda_{\\max}(\\boldsymbol{G}_{\\mathcal{S}}) - 1 \\,\\right\\}.\n$$\n从步骤 1 可知，如果 $\\mathcal{S}$ 包含一个重复对，这个 $2 \\times 2$ 块会贡献特征值 $0$ 和 $2$。由于 $\\boldsymbol{G}_{\\mathcal{S}}$ 是半正定的并且是块嵌入到更大的格拉姆矩阵中，其极值特征值满足\n$$\n\\lambda_{\\min}(\\boldsymbol{G}_{\\mathcal{S}}) \\leq 0, \\qquad \\lambda_{\\max}(\\boldsymbol{G}_{\\mathcal{S}}) \\geq 2.\n$$\n反之，如果 $\\mathcal{S}$ 不包含重复对，则 $\\boldsymbol{G}_{\\mathcal{S}} = \\boldsymbol{I}$，且两个极值特征值都等于 $1$。\n\n因此，最坏情况偏差发生在 $\\mathcal{S}$ 包含一个重复对时，得到\n$$\n1 - \\lambda_{\\min}(\\boldsymbol{G}_{\\mathcal{S}}) = 1 - 0 = 1, \\qquad \\lambda_{\\max}(\\boldsymbol{G}_{\\mathcal{S}}) - 1 = 2 - 1 = 1.\n$$\n因此，\n$$\n\\delta_{4k}(\\boldsymbol{A}) = 1.\n$$\n\n步骤 3：证明在无噪声测量下精确恢复失败。\n\n我们现在展示两个不同的 $k$-稀疏向量 $\\boldsymbol{x}, \\boldsymbol{x}' \\in \\mathbb{R}^{8k}$，它们产生相同的无噪声测量结果。设 $\\mathcal{T} \\subset \\{1,\\dots,4k\\}$ 是任意大小为 $k$ 的集合。定义 $\\boldsymbol{x} \\in \\mathbb{R}^{8k}$，方法是在第一个副本中位置为 $\\{j\\}_{j \\in \\mathcal{T}}$ 的索引上放置任意非零系数 $\\{c_{j}\\}_{j \\in \\mathcal{T}}$，其他位置为零；即，\n$$\nx_{j} = c_{j} \\text{ for } j \\in \\mathcal{T}, \\quad x_{\\ell} = 0 \\text{ otherwise}.\n$$\n定义 $\\boldsymbol{x}' \\in \\mathbb{R}^{8k}$，方法是在第二个副本中的重复索引上放置相同的系数，其他位置为零；即，\n$$\nx'_{4k + j} = c_{j} \\text{ for } j \\in \\mathcal{T}, \\quad x'_{\\ell} = 0 \\text{ otherwise}.\n$$\n那么两者都是 $k$-稀疏的，并且\n$$\n\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{B}\\boldsymbol{c} + \\boldsymbol{B}\\boldsymbol{0} = \\boldsymbol{B}\\boldsymbol{c}, \\qquad \\boldsymbol{A}\\boldsymbol{x}' = \\boldsymbol{B}\\boldsymbol{0} + \\boldsymbol{B}\\boldsymbol{c} = \\boldsymbol{B}\\boldsymbol{c},\n$$\n其中 $\\boldsymbol{c} \\in \\mathbb{R}^{4k}$ 汇集了在索引 $j \\in \\mathcal{T}$ 处的系数 $c_{j}$，其他位置为零。因此，$\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{A}\\boldsymbol{x}'$ 且 $\\boldsymbol{x} \\neq \\boldsymbol{x}'$，尽管没有测量噪声。这表明对 $k$-稀疏向量的精确恢复可能会失败：没有任何算法规则能够仅凭 $\\boldsymbol{A}\\boldsymbol{x}$ 来区分 $\\boldsymbol{x}$ 和 $\\boldsymbol{x}'$。\n\n步骤 4：与阈值和 $\\varepsilon$ 的关系。\n\n设 $\\tau \\in (0,1)$ 是所选贪婪算法的任意充分条件阈值。计算出的值 $\\delta_{4k}(\\boldsymbol{A}) = 1$ 满足\n$$\n\\delta_{4k}(\\boldsymbol{A}) = \\tau + \\varepsilon \\quad \\text{其中} \\quad \\varepsilon = 1 - \\tau  0.\n$$\n因此，受限等距常数超过阈值一个严格为正的 $\\varepsilon$，并且我们已经明确表明，即使在无噪声测量的情况下，精确恢复也可能失败。\n\n所要求的值是 $\\delta_{4k}(\\boldsymbol{A})$，它是一个精确的实数。", "answer": "$$\\boxed{1}$$", "id": "3473250"}]}