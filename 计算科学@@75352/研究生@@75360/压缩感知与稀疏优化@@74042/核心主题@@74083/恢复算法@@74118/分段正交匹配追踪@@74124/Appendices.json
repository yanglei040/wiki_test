{"hands_on_practices": [{"introduction": "理解一个算法最好的方式之一就是亲手执行一遍。这个练习提供了一个具体的小规模场景，引导你完整地走过分步正交匹配追踪（StOMP）的一个阶段。通过这个练习，你将具体地看到相关性计算、阈值设定和最小二乘更新这些步骤是如何在实践中协同工作的，从而巩固对 StOMP 核心机制的理解。[@problem_id:3481077]", "problem": "考虑线性测量模型 $y = A x^{\\star} + w$，其中包含加性高斯白噪声 $w \\sim \\mathcal{N}(0, \\sigma^{2} I)$，并假设我们应用分步正交匹配追踪 (Stagewise Orthogonal Matching Pursuit, StOMP) 的第一阶段。设传感矩阵 $A \\in \\mathbb{R}^{4 \\times 4}$ 的列为单位范数列，由归一化的哈达玛系统给出\n$$\nA \\;=\\; \\frac{1}{2}\\begin{bmatrix}\n1  & 1 &  1 &  1\\\\\n1  & 1 & -1 & -1\\\\\n1  & -1 & 1 & -1\\\\\n1  & -1 & -1 &  1\n\\end{bmatrix}.\n$$\n设观测数据为\n$$\ny \\;=\\; \\begin{bmatrix} 2 \\\\ 0 \\\\ 0.5 \\\\ -1 \\end{bmatrix},\n$$\n且噪声标准差为 $\\sigma = 0.2$。在初始阶段，StOMP 使用残差 $r^{(0)} = y$，相关向量 $c^{(0)} = A^{\\top} r^{(0)}$，以及一个通用高斯阈值\n$$\n\\tau_0 \\;=\\; \\sigma \\sqrt{2 \\ln n},\n$$\n其中 $n$ 是矩阵 $A$ 的列数，它选择索引集\n$$\nJ_0 \\;=\\; \\{\\, j \\in \\{1,\\dots,n\\} \\;\\colon\\; |c^{(0)}_j| > \\tau_0 \\,\\}.\n$$\n然后，它在支撑集 $S_0 = J_0$ 上执行最小二乘更新，得到 $x^{(1)}_{S_0} = \\arg\\min_{x \\in \\mathbb{R}^{|S_0|}} \\|\\, y - A_{S_0} x \\,\\|_{2}^{2}$（并在 $S_0$ 之外取零），然后计算新的残差 $r^{(1)} = y - A_{S_0} x^{(1)}_{S_0}$。\n\n从这些定义以及每个条目上的高斯噪声方差为 $\\sigma^{2}$ 的假设出发，明确计算：\n- $c^{(0)}$，\n- $\\tau_0$，\n- $J_0$，\n- 在 $S_0$ 上的最小二乘估计，\n- 以及新的残差 $r^{(1)}$。\n\n最后，报告单个标量值 $\\| r^{(1)} \\|_{2}^{2}$。请以精确实数形式给出答案（不要四舍五入）。", "solution": "该问题要求计算分步正交匹配追踪 (StOMP) 算法第一阶段后残差的 $L_2$ 范数的平方。我们将按照问题描述中定义的步骤计算中间量。\n\n给定的线性模型是 $y = A x^{\\star} + w$，其中传感矩阵为 $A \\in \\mathbb{R}^{4 \\times 4}$，观测数据为 $y$，噪声标准差为 $\\sigma$。\n$$\nA = \\frac{1}{2}\\begin{bmatrix}\n1  & 1 &  1 &  1\\\\\n1  & 1 & -1 & -1\\\\\n1  & -1 & 1 & -1\\\\\n1  & -1 & -1 &  1\n\\end{bmatrix}, \\quad y = \\begin{bmatrix} 2 \\\\ 0 \\\\ 0.5 \\\\ -1 \\end{bmatrix}, \\quad \\sigma = 0.2\n$$\n$A$ 的列数为 $n=4$。矩阵 $A$ 是一个缩放的哈达玛矩阵。我们可以验证它是对称的，$A^{\\top} = A$，并且其列是标准正交的，即 $A^{\\top}A = I$。这使得 $A$ 成为一个正交矩阵。\n\n- **步骤 1：计算初始相关向量 $c^{(0)}$**\n初始残差为 $r^{(0)} = y$。相关向量为 $c^{(0)} = A^{\\top} r^{(0)} = A^{\\top} y$。由于 $A$ 是对称的，因此 $c^{(0)} = A y$。\n$$\nc^{(0)} = \\frac{1}{2}\\begin{bmatrix}\n1  & 1 &  1 &  1\\\\\n1  & 1 & -1 & -1\\\\\n1  & -1 & 1 & -1\\\\\n1  & -1 & -1 &  1\n\\end{bmatrix}\n\\begin{bmatrix} 2 \\\\ 0 \\\\ 0.5 \\\\ -1 \\end{bmatrix}\n= \\frac{1}{2}\\begin{bmatrix}\n1(2) + 1(0) + 1(0.5) + 1(-1) \\\\\n1(2) + 1(0) - 1(0.5) - 1(-1) \\\\\n1(2) - 1(0) + 1(0.5) - 1(-1) \\\\\n1(2) - 1(0) - 1(0.5) + 1(-1)\n\\end{bmatrix}\n= \\frac{1}{2}\\begin{bmatrix}\n1.5 \\\\\n2.5 \\\\\n3.5 \\\\\n0.5\n\\end{bmatrix}\n= \\begin{bmatrix}\n0.75 \\\\\n1.25 \\\\\n1.75 \\\\\n0.25\n\\end{bmatrix}\n$$\n以分数形式（这是精确的）表示，$c^{(0)} = \\begin{bmatrix} 3/4 \\\\ 5/4 \\\\ 7/4 \\\\ 1/4 \\end{bmatrix}$。\n\n- **步骤 2：计算阈值 $\\tau_0$**\n阈值定义为 $\\tau_0 = \\sigma \\sqrt{2 \\ln n}$。当 $\\sigma = 0.2$ 且 $n=4$ 时，我们有：\n$$\n\\tau_0 = 0.2 \\sqrt{2 \\ln 4} = 0.2 \\sqrt{2 \\ln(2^2)} = 0.2 \\sqrt{4 \\ln 2} = 0.4 \\sqrt{\\ln 2}\n$$\n\n- **步骤 3：确定索引集 $J_0$**\n索引集 $J_0$ 包含满足 $|c^{(0)}_j| > \\tau_0$ 的索引 $j$。我们将相关系数的模长平方 $|c^{(0)}_j|^2$ 与 $\\tau_0^2 = (0.4)^2 \\ln 2 = 0.16 \\ln 2$ 进行比较。\n使用近似值 $\\ln 2 \\approx 0.6931$，我们得到 $\\tau_0^2 \\approx 0.16 \\times 0.6931 \\approx 0.1109$。\n相关系数的模长平方为：\n$|c^{(0)}_1|^2 = (0.75)^2 = 0.5625$\n$|c^{(0)}_2|^2 = (1.25)^2 = 1.5625$\n$|c^{(0)}_3|^2 = (1.75)^2 = 3.0625$\n$|c^{(0)}_4|^2 = (0.25)^2 = 0.0625$\n\n将这些值与 $\\tau_0^2 \\approx 0.1109$ 进行比较：\n$|c^{(0)}_1|^2 > \\tau_0^2$\n$|c^{(0)}_2|^2 > \\tau_0^2$\n$|c^{(0)}_3|^2 > \\tau_0^2$\n$|c^{(0)}_4|^2 < \\tau_0^2$\n因此，选定的索引集为 $J_0 = \\{1, 2, 3\\}$。第一次迭代的支撑集为 $S_0 = J_0 = \\{1, 2, 3\\}$。\n\n- **步骤 4：计算最小二乘估计 $x^{(1)}_{S_0}$ 和新残差 $r^{(1)}$**\n在支撑集 $S_0$ 上的最小二乘估计由 $x^{(1)}_{S_0} = \\arg\\min_{x} \\| y - A_{S_0} x \\|_{2}^{2}$ 给出，其中 $A_{S_0}$ 是由 $A$ 的第 $\\{1, 2, 3\\}$ 列组成的矩阵。解由正规方程给出：$x^{(1)}_{S_0} = (A_{S_0}^{\\top} A_{S_0})^{-1} A_{S_0}^{\\top} y$。\n如前所述，$A$ 的列是标准正交的。设 $a_j$ 表示 $A$ 的第 $j$ 列。那么 $a_i^{\\top} a_j = \\delta_{ij}$（克罗内克δ函数）。\n对于 $S_0 = \\{1, 2, 3\\}$，子矩阵为 $A_{S_0} = [a_1, a_2, a_3]$。其格拉姆矩阵为 $A_{S_0}^{\\top} A_{S_0} = I_3$，即 $3 \\times 3$ 单位矩阵。\n最小二乘解简化为 $x^{(1)}_{S_0} = A_{S_0}^{\\top} y$。该向量的分量为 $(A_{S_0}^{\\top} y)_i = a_i^{\\top} y = c_i^{(0)}$，其中 $i \\in S_0$。\n所以，$x^{(1)}_{S_0} = \\begin{bmatrix} c_1^{(0)} \\\\ c_2^{(0)} \\\\ c_3^{(0)} \\end{bmatrix} = \\begin{bmatrix} 0.75 \\\\ 1.25 \\\\ 1.75 \\end{bmatrix}$。\n\n新残差为 $r^{(1)} = y - A_{S_0} x^{(1)}_{S_0}$。项 $A_{S_0} x^{(1)}_{S_0} = A_{S_0} A_{S_0}^{\\top} y$ 是 $y$ 在由 $A_{S_0}$ 的列所张成的子空间（即 $\\mathrm{span}\\{a_1, a_2, a_3\\}$）上的正交投影。\n因此，残差 $r^{(1)}$ 是 $y$ 在该子空间的正交补上的投影。由于 $\\{a_1, a_2, a_3, a_4\\}$ 构成 $\\mathbb{R}^4$ 的一个标准正交基，该正交补由向量 $a_4$ 张成。\n$y$ 在由 $a_4$ 张成的子空间上的投影由下式给出：\n$$ r^{(1)} = (a_4^{\\top} y) a_4 $$\n项 $a_4^{\\top} y$ 正是相关向量的第四个分量 $c_4^{(0)}$。\n从步骤 1 可知，$c_4^{(0)} = 0.25 = \\frac{1}{4}$。\n因此，$r^{(1)} = c_4^{(0)} a_4 = \\frac{1}{4} a_4$。\n\n- **步骤 5：计算最终量 $\\| r^{(1)} \\|_{2}^{2}$**\n我们需要计算残差 $r^{(1)}$ 的 $L_2$ 范数的平方。\n$$\n\\|r^{(1)}\\|_2^2 = \\left\\| \\frac{1}{4} a_4 \\right\\|_2^2 = \\left(\\frac{1}{4}\\right)^2 \\|a_4\\|_2^2\n$$\n由于根据构造（如问题所述并已验证），$A$ 的列是单位范数的，我们有 $\\|a_4\\|_2^2 = 1$。\n因此，残差的范数平方简化为：\n$$\n\\|r^{(1)}\\|_2^2 = \\left(\\frac{1}{4}\\right)^2 \\times 1 = \\frac{1}{16}\n$$\n最终答案是一个精确的实数。\n以分数形式表示为 $\\frac{1}{16}$，或以小数形式表示为 $0.0625$。我们将提供分数形式。", "answer": "$$\n\\boxed{\\frac{1}{16}}\n$$", "id": "3481077"}, {"introduction": "在每次迭代中简单地重新计算最小二乘解，其计算成本可能非常高昂。这个练习将介绍一种使用 QR 分解更新的高效方法，这是开发高性能稀疏恢复算法的关键技术。通过这个练习，你将把算法理论与可扩展的实际应用联系起来，学习如何高效地更新解而不是从头开始计算。[@problem_id:3481065]", "problem": "考虑压缩感知中的线性模型，其测量值为 $\\mathbf{y} \\in \\mathbb{R}^{m}$，传感矩阵为 $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$，未知稀疏向量为 $\\mathbf{x}_{0} \\in \\mathbb{R}^{n}$，其中 $\\mathbf{y} = \\mathbf{A}\\mathbf{x}_{0} + \\mathbf{e}$。分步正交匹配追踪（Stagewise Orthogonal Matching Pursuit, StOMP）是一种贪婪追踪方法，在迭代 $t$ 时，通过一批索引 $J_{t}$ 来扩充当前的支撑集 $S_{t-1}$，形成 $S_{t} = S_{t-1} \\cup J_{t}$，然后重新计算在 $\\mathbf{A}_{S_{t}}$ 上的最小二乘估计。\n\n从最小二乘问题和瘦QR分解的基本定义出发，并仅使用已确立的线性代数事实，推导当添加多列 $\\mathbf{A}_{J_{t}}$ 时，如何更新瘦QR分解 $\\mathbf{A}_{S_{t-1}} = \\mathbf{Q}\\mathbf{R}$ 的正交因子 $\\mathbf{Q}$ 和上三角因子 $\\mathbf{R}$，而无需从头重新计算完整的QR分解。明确展示如何从这些更新后的因子计算最小二乘解 $\\hat{\\mathbf{x}}_{S_{t}}$ 和下一个残差 $\\mathbf{r}^{(t+1)}$。\n\n然后，将您的推导应用于以下具体实例以产生一个数值。令 $m = 4, n = 5$，并设 $\\mathbf{A}$ 的列为 $\\mathbf{a}_{1}, \\mathbf{a}_{2}, \\mathbf{a}_{3}, \\mathbf{a}_{4}, \\mathbf{a}_{5} \\in \\mathbb{R}^{4}$，其中\n$$\n\\mathbf{a}_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\mathbf{a}_{2} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\mathbf{a}_{3} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix},\n$$\n其余列 $\\mathbf{a}_{4}, \\mathbf{a}_{5}$ 是任意的，并且在此次迭代中未使用。假设在迭代 $t-1$ 时支撑集为 $S_{t-1} = \\{1\\}$，其瘦QR因子为 $\\mathbf{A}_{S_{t-1}} = \\mathbf{Q}\\mathbf{R}$，在迭代 $t$ 时分段选择得出 $J_{t} = \\{2,3\\}$，因此 $S_{t} = \\{1,2,3\\}$。设测量值为\n$$\n\\mathbf{y} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\\\ 7 \\end{pmatrix}.\n$$\n\n使用推导出的 $\\mathbf{Q}$ 和 $\\mathbf{R}$ 的更新机制以及 $\\hat{\\mathbf{x}}_{S_{t}}$ 和 $\\mathbf{r}^{(t+1)}$ 的相应公式，计算下一个残差的欧几里得范数 $\\|\\mathbf{r}^{(t+1)}\\|_{2}$。将最终答案表示为一个实数。无需四舍五入。", "solution": "我们从最小二乘公式和瘦QR分解开始。给定一个满列秩为 $k$ 的矩阵 $\\mathbf{A}_{S} \\in \\mathbb{R}^{m \\times k}$ 及其瘦QR分解 $\\mathbf{A}_{S} = \\mathbf{Q}\\mathbf{R}$，其中 $\\mathbf{Q} \\in \\mathbb{R}^{m \\times k}$ 具有标准正交列，$\\mathbf{R} \\in \\mathbb{R}^{k \\times k}$ 是具有正对角线元的上三角矩阵，则\n$$\n\\min_{\\mathbf{x} \\in \\mathbb{R}^{k}} \\|\\mathbf{y} - \\mathbf{A}_{S}\\mathbf{x}\\|_{2}\n$$\n的最小二乘解由下式给出\n$$\n\\hat{\\mathbf{x}}_{S} = \\mathbf{R}^{-1}\\mathbf{Q}^{\\top}\\mathbf{y},\n$$\n残差为\n$$\n\\mathbf{r} = \\mathbf{y} - \\mathbf{A}_{S}\\hat{\\mathbf{x}}_{S} = \\mathbf{y} - \\mathbf{Q}\\mathbf{R}\\left(\\mathbf{R}^{-1}\\mathbf{Q}^{\\top}\\mathbf{y}\\right) = \\mathbf{y} - \\mathbf{Q}\\mathbf{Q}^{\\top}\\mathbf{y} = \\left(\\mathbf{I} - \\mathbf{Q}\\mathbf{Q}^{\\top}\\right)\\mathbf{y}.\n$$\n因此，残差是 $\\mathbf{y}$ 在 $\\mathbf{A}_{S}$ 列空间的正交补上的正交投影。\n\n我们现在推导用于添加多列的块QR更新。假设在分步正交匹配追踪（StOMP）的迭代 $t-1$ 中，我们有 $S_{t-1}$ 和瘦QR因子 $\\mathbf{A}_{S_{t-1}} = \\mathbf{Q}\\mathbf{R}$，并且我们添加一批由 $J_{t}$ 索引的列，形成 $\\mathbf{A}_{S_{t}} = [\\mathbf{A}_{S_{t-1}} \\ \\mathbf{A}_{J_{t}}]$。我们寻求更新后的因子 $\\mathbf{Q}_{+}$ 和 $\\mathbf{R}_{+}$ 使得\n$$\n\\mathbf{A}_{S_{t}} = \\mathbf{Q}_{+}\\mathbf{R}_{+}.\n$$\n使用正交投影，将新块 $\\mathbf{A}_{J_{t}}$ 分解为平行于 $\\operatorname{range}(\\mathbf{Q})$ 和正交于 $\\operatorname{range}(\\mathbf{Q})$ 的分量：\n$$\n\\mathbf{W} := \\mathbf{Q}^{\\top}\\mathbf{A}_{J_{t}} \\in \\mathbb{R}^{k \\times r}, \\quad \\mathbf{Z} := \\mathbf{A}_{J_{t}} - \\mathbf{Q}\\mathbf{W} \\in \\mathbb{R}^{m \\times r},\n$$\n其中 $k = |S_{t-1}|$ 且 $r = |J_{t}|$。矩阵 $\\mathbf{Z}$ 收集了新列中正交于 $\\operatorname{range}(\\mathbf{Q})$ 的分量。对 $\\mathbf{Z}$ 进行瘦QR分解：\n$$\n\\mathbf{Z} = \\tilde{\\mathbf{Q}}\\tilde{\\mathbf{R}},\n$$\n其中 $\\tilde{\\mathbf{Q}} \\in \\mathbb{R}^{m \\times s}$ 具有张成 $\\operatorname{range}(\\mathbf{Z})$ 的标准正交列，$\\tilde{\\mathbf{R}} \\in \\mathbb{R}^{s \\times r}$ 是上三角矩阵（这里 $s \\le r$ 是 $\\mathbf{Z}$ 的秩）。那么更新后的瘦QR因子为\n$$\n\\mathbf{Q}_{+} = [\\mathbf{Q} \\ \\tilde{\\mathbf{Q}}] \\in \\mathbb{R}^{m \\times (k+s)}, \\quad\n\\mathbf{R}_{+} = \\begin{pmatrix}\n\\mathbf{R}  & \\mathbf{W} \\\\\n\\mathbf{0} & \\tilde{\\mathbf{R}}\n\\end{pmatrix} \\in \\mathbb{R}^{(k+s) \\times (k+r)}.\n$$\n为了验证，注意\n$$\n\\mathbf{Q}_{+}\\mathbf{R}_{+} = [\\mathbf{Q} \\ \\tilde{\\mathbf{Q}}]\n\\begin{pmatrix}\n\\mathbf{R}  & \\mathbf{W} \\\\\n\\mathbf{0} & \\tilde{\\mathbf{R}}\n\\end{pmatrix}\n= \\mathbf{Q}\\mathbf{R} \\ \\ \\ \\ \\ \\ \\text{(第一块)} \\quad \\text{和} \\quad \\mathbf{Q}\\mathbf{W} + \\tilde{\\mathbf{Q}}\\tilde{\\mathbf{R}} = \\mathbf{Q}\\mathbf{Q}^{\\top}\\mathbf{A}_{J_{t}} + \\left(\\mathbf{A}_{J_{t}} - \\mathbf{Q}\\mathbf{Q}^{\\top}\\mathbf{A}_{J_{t}}\\right) = \\mathbf{A}_{J_{t}},\n$$\n因此 $\\mathbf{Q}_{+}\\mathbf{R}_{+} = [\\mathbf{A}_{S_{t-1}} \\ \\mathbf{A}_{J_{t}}] = \\mathbf{A}_{S_{t}}$。\n\n给定 $\\mathbf{Q}_{+}$ 和 $\\mathbf{R}_{+}$，在 $S_{t}$ 上的最小二乘解为\n$$\n\\hat{\\mathbf{x}}_{S_{t}} = \\mathbf{R}_{S_{t}}^{-1}\\mathbf{Q}_{S_{t}}^{\\top}\\mathbf{y},\n$$\n其中 $\\mathbf{R}_{S_{t}}$ 是对应于 $S_{t}$ 中所选列的方阵上三角因子；如果所选列是满列秩的，则 $\\mathbf{R}_{S_{t}}$ 是可逆的，并且可以通过回代求解。残差为\n$$\n\\mathbf{r}^{(t+1)} = \\mathbf{y} - \\mathbf{A}_{S_{t}}\\hat{\\mathbf{x}}_{S_{t}} = \\left(\\mathbf{I} - \\mathbf{Q}_{S_{t}}\\mathbf{Q}_{S_{t}}^{\\top}\\right)\\mathbf{y}.\n$$\n\n我们现在将此应用于具体实例。令\n$$\n\\mathbf{a}_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\mathbf{a}_{2} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\mathbf{a}_{3} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad\n\\mathbf{y} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\\\ 7 \\end{pmatrix}.\n$$\n在迭代 $t-1$ 时，$S_{t-1} = \\{1\\}$。$\\mathbf{A}_{S_{t-1}} = \\mathbf{a}_{1}$ 的瘦QR分解为\n$$\n\\mathbf{Q} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{R} = (1).\n$$\n在迭代 $t$ 时，$J_{t} = \\{2,3\\}$，所以 $\\mathbf{A}_{J_{t}} = [\\mathbf{a}_{2} \\ \\mathbf{a}_{3}]$。计算\n$$\n\\mathbf{W} = \\mathbf{Q}^{\\top}\\mathbf{A}_{J_{t}} = \\begin{pmatrix} 1 &  0 &  0 &  0 \\end{pmatrix}\n\\begin{pmatrix}\n0  & 1 \\\\\n1  & 1 \\\\\n0  & 1 \\\\\n0  & 0\n\\end{pmatrix}\n= \\begin{pmatrix} 0 &  1 \\end{pmatrix}.\n$$\n计算正交分量\n$$\n\\mathbf{Z} = \\mathbf{A}_{J_{t}} - \\mathbf{Q}\\mathbf{W}\n= \\begin{pmatrix}\n0  & 1 \\\\\n1  & 1 \\\\\n0  & 1 \\\\\n0  & 0\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ 0 \\\\ 0\n\\end{pmatrix}\n\\begin{pmatrix} 0 &  1 \\end{pmatrix}\n= \\begin{pmatrix}\n0  & 0 \\\\\n1  & 1 \\\\\n0  & 1 \\\\\n0  & 0\n\\end{pmatrix}.\n$$\n对 $\\mathbf{Z}$ 进行瘦QR分解。令 $\\mathbf{z}_{1} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$ 且 $\\mathbf{z}_{2} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$。使用Gram–Schmidt方法，\n$$\n\\|\\mathbf{z}_{1}\\|_{2} = 1, \\quad \\mathbf{u}_{1} = \\mathbf{z}_{1}, \\quad r_{12} = \\mathbf{u}_{1}^{\\top}\\mathbf{z}_{2} = 1, \\quad \\mathbf{v}_{2} = \\mathbf{z}_{2} - r_{12}\\mathbf{u}_{1} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix},\n$$\n和\n$$\n\\|\\mathbf{v}_{2}\\|_{2} = 1, \\quad \\mathbf{u}_{2} = \\mathbf{v}_{2}.\n$$\n因此，\n$$\n\\tilde{\\mathbf{Q}} = \\begin{pmatrix}\n0  & 0 \\\\\n1  & 0 \\\\\n0  & 1 \\\\\n0  & 0\n\\end{pmatrix}, \\quad\n\\tilde{\\mathbf{R}} = \\begin{pmatrix}\n1  & 1 \\\\\n0  & 1\n\\end{pmatrix}.\n$$\n$S_{t} = \\{1,2,3\\}$ 的更新后因子为\n$$\n\\mathbf{Q}_{+} = [\\mathbf{Q} \\ \\tilde{\\mathbf{Q}}] =\n\\begin{pmatrix}\n1  & 0 &  0 \\\\\n0  & 1 &  0 \\\\\n0  & 0 &  1 \\\\\n0  & 0 &  0\n\\end{pmatrix}, \\quad\n\\mathbf{R}_{+} =\n\\begin{pmatrix}\n1  & 0 &  1 \\\\\n0  & 1 &  1 \\\\\n0  & 0 &  1\n\\end{pmatrix}.\n$$\n检查 $\\mathbf{Q}_{+}\\mathbf{R}_{+} = [\\mathbf{a}_{1} \\ \\mathbf{a}_{2} \\ \\mathbf{a}_{3}]$：\n列分别为 $\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$、$\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$ 和 $\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$，符合要求。\n\n计算 $S_{t}$ 上的最小二乘解：\n$$\n\\hat{\\mathbf{x}}_{S_{t}} = \\mathbf{R}_{+}^{-1}\\mathbf{Q}_{+}^{\\top}\\mathbf{y}.\n$$\n我们有\n$$\n\\mathbf{Q}_{+}^{\\top}\\mathbf{y} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\end{pmatrix}.\n$$\n通过回代求解 $\\mathbf{R}_{+}\\hat{\\mathbf{x}}_{S_{t}} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\end{pmatrix}$：\n$$\nx_{3} = 5, \\quad x_{2} + x_{3} = 3 \\Rightarrow x_{2} = 3 - 5 = -2, \\quad x_{1} + x_{3} = 2 \\Rightarrow x_{1} = 2 - 5 = -3.\n$$\n因此，\n$$\n\\hat{\\mathbf{x}}_{S_{t}} = \\begin{pmatrix} -3 \\\\ -2 \\\\ 5 \\end{pmatrix}.\n$$\n拟合向量为\n$$\n\\mathbf{A}_{S_{t}}\\hat{\\mathbf{x}}_{S_{t}} = \\mathbf{Q}_{+}\\mathbf{R}_{+}\\hat{\\mathbf{x}}_{S_{t}} = \\mathbf{Q}_{+}\\mathbf{Q}_{+}^{\\top}\\mathbf{y} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\\\ 0 \\end{pmatrix},\n$$\n残差为\n$$\n\\mathbf{r}^{(t+1)} = \\mathbf{y} - \\mathbf{A}_{S_{t}}\\hat{\\mathbf{x}}_{S_{t}} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\\\ 7 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 7 \\end{pmatrix}.\n$$\n因此，残差的欧几里得范数为\n$$\n\\|\\mathbf{r}^{(t+1)}\\|_{2} = \\sqrt{0^{2} + 0^{2} + 0^{2} + 7^{2}} = 7.\n$$", "answer": "$$\\boxed{7}$$", "id": "3481065"}, {"introduction": "StOMP 算法的标志性特征是其“批量”原子选择策略。这个思想实验探讨了这一设计选择的深刻含义，尤其是在传感矩阵包含高度相关列的非理想情况下。通过将 StOMP 的行为与经典的正交匹配追踪（OMP）进行对比，这个练习将加深你对该算法优缺点及其在特定条件下的行为模式的理解。[@problem_id:3481088]", "problem": "考虑一个感知矩阵（字典），其维度为 $m=3$ 和 $n=4$，其单位范数列 $\\{a_j\\}_{j=1}^4 \\subset \\mathbb{R}^3$ 由下式明确给出\n$$\na_1=\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix},\\quad\na_2=\\begin{bmatrix}0.9\\\\ \\sqrt{1-0.9^2}\\\\ 0\\end{bmatrix},\\quad\na_3=\\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix},\\quad\na_4=\\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}.\n$$\n设未知信号为 $x^\\star\\in\\mathbb{R}^4$，其支撑集为 $k$-稀疏的 $\\operatorname{supp}(x^\\star)=\\{1,3\\}$，值为 $x^\\star_1=1$、$x^\\star_3=1$ 以及 $x^\\star_2=x^\\star_4=0$。无噪声测量值为 $y=Ax^\\star=a_1+a_3=\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$。\n\n比较两种贪婪方法：\n\n- 正交匹配追踪 (Orthogonal Matching Pursuit, OMP)：在每次迭代 $t$ 中，计算残差 $r^{(t)}=y-A_{S^{(t)}}\\hat{c}^{(t)}$，其中 $S^{(t)}$ 是 $t$ 次迭代后选择的支撑集，$\\hat{c}^{(t)}$ 是在 $S^{(t)}$ 上的最小二乘解；然后选择新索引 $j^{(t+1)}\\in\\arg\\max_j |\\langle a_j,r^{(t)}\\rangle|$，扩充支撑集 $S^{(t+1)}=S^{(t)}\\cup\\{j^{(t+1)}\\}$，在 $S^{(t+1)}$ 上通过最小二乘法重新拟合，然后重复。假设在 $\\arg\\max$ 中出现平局时，选择最小的索引。\n\n- 分步正交匹配追踪 (Stagewise Orthogonal Matching Pursuit, StOMP)：在第 1 阶段，计算所有 $j$ 的相关性 $c_j=\\langle a_j,y\\rangle$，并使用固定的阈值因子 $\\alpha=0.85$ 选择批次 $S=\\{j:\\,|c_j|\\ge \\alpha \\max_k |c_k|\\}$。然后在 $S$ 上执行一次最小二乘重新拟合以获得系数 $\\hat{c}_S$，设置残差 $r=y-A_S\\hat{c}_S$，如果 $r=0$ 则终止。\n\n根据这些定义以及内积和正交投影的线性代数性质，分析这两种方法在给定的 $A$ 和 $y$ 上的第一阶段/次迭代。下列哪个/哪些陈述是正确的？\n\nA. StOMP 的第一阶段选择 $S=\\{1,2,3\\}$，因为 $|a_1^\\top y|=|a_3^\\top y|=1$ 且 $|a_2^\\top y|=0.9\\ge 0.85\\cdot 1$，其在 $S$ 上的最小二乘重新拟合返回的系数为 $\\hat{c}_2=0$，从而在一个阶段内精确恢复了真实支撑集 $\\{1,3\\}$；OMP 在规定的平局打破规则下，在第一次迭代中选择 $1$，将残差投影到 $\\operatorname{span}\\{a_1\\}$ 的正交补上得到 $r^{(1)}=a_3$，然后选择 $3$，也实现了精确恢复。\n\nB. OMP 可能在第一次迭代中选择 $2$，因为 $|a_2^\\top y|$ 等于 $1$，与 $|a_1^\\top y|$ 和 $|a_3^\\top y|$ 相等。\n\nC. StOMP 批次 $S=\\{1,2,3\\}$ 上的最小二乘问题由于 $a_1$ 和 $a_2$ 之间的高相干性而是奇异的，因此 StOMP 在此阶段无法唯一地恢复系数。\n\nD. 因为 StOMP 在第一阶段包含了一个高相干性但虚假的原子 $a_2$，其在最小二乘法后的残差在无噪声设置下不能为零，而 OMP 可以将残差驱动到零。\n\nE. 如果 OMP 通过首先选择 $3$ 来打破初始平局，那么在第二次迭代中它必须在 $1$ 之前选择 $2$，因为 $a_2$ 与更新后的残差的相关性仍然高于 $a_1$。\n\n选择所有适用项。", "solution": "用户提供了一个压缩感知领域的问题，要求分析两种贪婪恢复算法——分步正交匹配追踪 (StOMP) 和正交匹配追踪 (OMP) 的第一阶段/次迭代。\n\n### 问题陈述验证\n\n首先，我将验证问题陈述。\n\n**步骤 1：提取已知条件**\n- 感知矩阵（字典）$A \\in \\mathbb{R}^{3 \\times 4}$，其中 $m=3$ 且 $n=4$。\n- $A$ 的列，记为 $\\{a_j\\}_{j=1}^4$，是 $\\mathbb{R}^3$ 中的单位范数向量：\n$$a_1=\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix},\\quad a_2=\\begin{bmatrix}0.9\\\\ \\sqrt{1-0.9^2}\\\\ 0\\end{bmatrix},\\quad a_3=\\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix},\\quad a_4=\\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}.$$\n注意 $\\sqrt{1-0.9^2} = \\sqrt{1-0.81} = \\sqrt{0.19}$。\n- 未知信号为 $x^\\star\\in\\mathbb{R}^4$。\n- 信号是 $k$-稀疏的，其中 $k=2$。\n- 支撑集是 $\\operatorname{supp}(x^\\star)=\\{1,3\\}$。\n- 非零值为 $x^\\star_1=1$ 和 $x^\\star_3=1$。零值为 $x^\\star_2=x^\\star_4=0$。\n- 无噪声测量向量为 $y=Ax^\\star=a_1x^\\star_1 + a_3x^\\star_3 = a_1+a_3=\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$。\n- OMP 算法定义：在每次迭代 $t$ 中，计算残差 $r^{(t)}=y-A_{S^{(t)}}\\hat{c}^{(t)}$，选择下一个索引 $j^{(t+1)}\\in\\arg\\max_j |\\langle a_j,r^{(t)}\\rangle|$，扩充支撑集 $S^{(t+1)}=S^{(t)}\\cup\\{j^{(t+1)}\\}$，然后重新拟合。平局通过选择最小的索引来打破。\n- StOMP 算法定义：在第 1 阶段，计算相关性 $c_j=\\langle a_j,y\\rangle$，使用阈值因子 $\\alpha=0.85$ 选择批次 $S=\\{j:\\,|c_j|\\ge \\alpha \\max_k |c_k|\\}$。在 $S$ 上执行一次最小二乘重新拟合。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：**该问题是稀疏信号恢复中的一个标准的、定义明确的练习，这是信号处理和优化的一个子领域。OMP 和 StOMP 算法是该领域的经典方法。其基础数学基于线性代数。该问题是合理的。\n- **适定性：**所有必要的数据（矩阵 $A$、信号 $x^\\star$、测量 $y$）和算法规范（参数 $\\alpha$、平局打破规则）都已提供。问题要求直接分析算法的行为，这是一个给定输入的确定性过程。\n- **客观性：**问题使用精确的数学语言陈述，没有任何主观或模棱两可的术语。\n- **完整性和一致性：**我们来检查给定的值。列被说明为单位范数。\n  - $\\|a_1\\|_2 = \\sqrt{1^2+0^2+0^2}=1$。\n  - $\\|a_2\\|_2 = \\sqrt{0.9^2 + (\\sqrt{0.19})^2 + 0^2} = \\sqrt{0.81+0.19} = \\sqrt{1} = 1$。\n  - $\\|a_3\\|_2 = \\sqrt{0^2+0^2+1^2}=1$。\n  - $\\|a_4\\|_2 = \\sqrt{0^2+1^2+0^2}=1$。\n列确实是单位范数的。测量向量的计算 $y = a_1+a_3 = \\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix} + \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix} = \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$ 是正确的。所有数据都是一致且定义明确的。\n\n**步骤 3：结论和行动**\n问题陈述是有效的。它在科学上是合理的、适定的、客观的、完整的且内部一致的。我将继续分析这些算法。\n\n### 推导与分析\n\n我们将根据提供的数据分别分析 StOMP 和 OMP。\n\n**分步正交匹配追踪 (StOMP) 分析**\n\nStOMP 算法分阶段进行。我们分析第一阶段。\n1.  **计算相关性：**我们计算每个字典原子 $a_j$ 与测量向量 $y=\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$ 的内积。\n    - $c_1 = \\langle a_1, y \\rangle = a_1^T y = \\begin{bmatrix}1&0&0\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 1$。\n    - $c_2 = \\langle a_2, y \\rangle = a_2^T y = \\begin{bmatrix}0.9&\\sqrt{0.19}&0\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 0.9$。\n    - $c_3 = \\langle a_3, y \\rangle = a_3^T y = \\begin{bmatrix}0&0&1\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 1$。\n    - $c_4 = \\langle a_4, y \\rangle = a_4^T y = \\begin{bmatrix}0&1&0\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 0$。\n\n2.  **阈值处理：**我们确定绝对相关性 $|c_j|$ 超过阈值的索引集合 $S$。\n    - 最大绝对相关性为 $\\max_k |c_k| = \\max\\{|1|, |0.9|, |1|, |0|\\} = 1$。\n    - 阈值因子给定为 $\\alpha = 0.85$。\n    - 阈值为 $\\alpha \\max_k |c_k| = 0.85 \\cdot 1 = 0.85$。\n    - 我们选择满足 $|c_j| \\ge 0.85$ 的索引 $j$：\n        - $|c_1| = 1 \\ge 0.85 \\implies 1 \\in S$。\n        - $|c_2| = 0.9 \\ge 0.85 \\implies 2 \\in S$。\n        - $|c_3| = 1 \\ge 0.85 \\implies 3 \\in S$。\n        - $|c_4| = 0  0.85 \\implies 4 \\notin S$。\n    - 选择的索引批次为 $S = \\{1, 2, 3\\}$。\n\n3.  **最小二乘重新拟合：**我们求解最小化 $\\|y - A_S c\\|_2^2$ 的系数 $\\hat{c}_S$，其中 $A_S = \\begin{bmatrix}a_1  a_2  a_3\\end{bmatrix}$。\n    - $A_S = \\begin{bmatrix} 1  0.9  0 \\\\ 0  \\sqrt{0.19}  0 \\\\ 0  0  1 \\end{bmatrix}$。\n    - 最小二乘问题是求解 $A_S \\hat{c}_S = y$。由于 $A_S$ 是一个 $3 \\times 3$ 矩阵，我们可以检查它是否可逆。行列式为 $\\det(A_S) = 1 \\cdot (\\sqrt{0.19} \\cdot 1 - 0 \\cdot 0) = \\sqrt{0.19} \\neq 0$。该矩阵是可逆的，因此存在唯一解。\n    - 我们求解线性方程组以得到 $\\hat{c}_S = \\begin{bmatrix}\\hat{c}_1  \\hat{c}_2  \\hat{c}_3\\end{bmatrix}^T$：\n    $$ \\begin{bmatrix} 1  0.9  0 \\\\ 0  \\sqrt{0.19}  0 \\\\ 0  0  1 \\end{bmatrix} \\begin{bmatrix} \\hat{c}_1 \\\\ \\hat{c}_2 \\\\ \\hat{c}_3 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix} $$\n    - 从第三行得到：$\\hat{c}_3 = 1$。\n    - 从第二行得到：$\\sqrt{0.19} \\cdot \\hat{c}_2 = 0 \\implies \\hat{c}_2 = 0$。\n    - 从第一行得到：$1 \\cdot \\hat{c}_1 + 0.9 \\cdot \\hat{c}_2 = 1 \\implies \\hat{c}_1 + 0.9 \\cdot 0 = 1 \\implies \\hat{c}_1 = 1$。\n    - 支撑集 $S$ 上的系数向量为 $\\hat{c}_S = \\begin{bmatrix}1  0  1\\end{bmatrix}^T$。\n    - 残差为 $r = y - A_S \\hat{c}_S = y - (1 \\cdot a_1 + 0 \\cdot a_2 + 1 \\cdot a_3) = y - (a_1+a_3)$。由于 $y=a_1+a_3$，残差 $r=0$。\n    - 恢复的信号在索引 $\\{1, 3\\}$ 处有非零项，这与真实支撑集 $\\operatorname{supp}(x^\\star)$ 完全匹配。因此，StOMP 在一个阶段内实现了精确恢复。\n\n**正交匹配追踪 (OMP) 分析**\n\nOMP 算法迭代进行。\n- **初始化：** $S^{(0)} = \\emptyset$，残差 $r^{(0)} = y = \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$。\n\n- **迭代 1：**\n    1. **选择：**找到最大化 $|\\langle a_j, r^{(0)} \\rangle|$ 的索引 $j^{(1)}$。相关性与 StOMP 分析中的相同：$|\\langle a_1, y \\rangle| = 1$，$|\\langle a_2, y \\rangle| = 0.9$，$|\\langle a_3, y \\rangle| = 1$，$|\\langle a_4, y \\rangle| = 0$。\n    2. 最大值为 $1$，在索引 $j=1$ 和 $j=3$ 之间出现平局。问题规定，平局通过选择最小的索引来打破。因此，$j^{(1)} = 1$。\n    3. **扩充支撑集：** $S^{(1)} = S^{(0)} \\cup \\{1\\} = \\{1\\}$。\n    4. **重新拟合：**求解最小化 $\\|y - A_{S^{(1)}} c\\|_2^2$ 的 $\\hat{c}^{(1)}$，其中 $A_{S^{(1)}} = a_1$。解为 $\\hat{c}_1^{(1)} = \\frac{\\langle a_1, y \\rangle}{\\|a_1\\|_2^2} = \\frac{1}{1} = 1$。\n    5. **更新残差：** $r^{(1)} = y - A_{S^{(1)}}\\hat{c}^{(1)} = y - 1 \\cdot a_1 = (a_1+a_3) - a_1 = a_3$。所以，$r^{(1)} = \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}$。\n\n- **迭代 2：**\n    1. **选择：**找到最大化 $|\\langle a_j, r^{(1)} \\rangle|$ 的索引 $j^{(2)}$。\n       - $|\\langle a_1, r^{(1)} \\rangle| = |\\langle a_1, a_3 \\rangle| = 0$。\n       - $|\\langle a_2, r^{(1)} \\rangle| = |\\langle a_2, a_3 \\rangle| = \\left| \\begin{bmatrix}0.9  \\sqrt{0.19}  0\\end{bmatrix} \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix} \\right| = 0$。\n       - $|\\langle a_3, r^{(1)} \\rangle| = |\\langle a_3, a_3 \\rangle| = \\|a_3\\|_2^2 = 1$。\n       - $|\\langle a_4, r^{(1)} \\rangle| = |\\langle a_4, a_3 \\rangle| = \\left| \\begin{bmatrix}0  1  0\\end{bmatrix} \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix} \\right| = 0$。\n    2. 最大相关性明确为 $1$，对应索引 $j^{(2)} = 3$。\n    3. **扩充支撑集：** $S^{(2)} = S^{(1)} \\cup \\{3\\} = \\{1, 3\\}$。\n    4. **重新拟合：**求解最小化 $\\|y - A_{S^{(2)}} c\\|_2^2$ 的 $\\hat{c}^{(2)}$，其中 $A_{S^{(2)}} = \\begin{bmatrix} a_1  a_3 \\end{bmatrix}$。正规方程为 $(A_{S^{(2)}})^T A_{S^{(2)}} \\hat{c}^{(2)} = (A_{S^{(2)}})^T y$。\n       由于 $a_1$ 和 $a_3$ 是正交的（$\\langle a_1, a_3 \\rangle = 0$），$(A_{S^{(2)}})^T A_{S^{(2)}} = \\begin{bmatrix} \\|a_1\\|^2  0 \\\\ 0  \\|a_3\\|^2 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$。\n       解为 $\\hat{c}^{(2)} = (A_{S^{(2)}})^T y = \\begin{bmatrix} \\langle a_1, y \\rangle \\\\ \\langle a_3, y \\rangle \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n    5. **更新残差：** $r^{(2)} = y - A_{S^{(2)}}\\hat{c}^{(2)} = y - (1 \\cdot a_1 + 1 \\cdot a_3) = (a_1+a_3) - (a_1+a_3) = 0$。\n    - 现在残差为零，因此 OMP 终止。它已正确识别出支撑集 $\\{1, 3\\}$ 和系数，在 2 次迭代中实现了精确恢复。\n\n### 逐项分析\n\n**A. StOMP 的第一阶段选择 $S=\\{1,2,3\\}$，因为 $|a_1^\\top y|=|a_3^\\top y|=1$ 且 $|a_2^\\top y|=0.9\\ge 0.85\\cdot 1$，其在 $S$ 上的最小二乘重新拟合返回的系数为 $\\hat{c}_2=0$，从而在一个阶段内精确恢复了真实支撑集 $\\{1,3\\}$；OMP 在规定的平局打破规则下，在第一次迭代中选择 $1$，将残差投影到 $\\operatorname{span}\\{a_1\\}$ 的正交补上得到 $r^{(1)}=a_3$，然后选择 $3$，也实现了精确恢复。**\n- StOMP 的分析表明，选择的 $S=\\{1,2,3\\}$。给出的原因是正确的。\n- StOMP 的最小二乘重新拟合得到 $\\hat{c}_S = \\begin{bmatrix}101\\end{bmatrix}^T$，所以 $\\hat{c}_2=0$。这恢复了真实的稀疏支撑集 $\\{1,3\\}$。\n- OMP 的分析表明，由于平局打破规则，首先选择索引 1。\n- OMP 第一步后的更新残差是 $r^{(1)} = y - \\text{Proj}_{\\text{span}\\{a_1\\}}(y) = y - a_1 = a_3$。\n- 第二次 OMP 迭代接着选择索引 3，从而实现精确恢复。\n- 此陈述中的每一个主张都与我们的推导一致。\n- 结论：**正确**。\n\n**B. OMP 可能在第一次迭代中选择 $2$，因为 $|a_2^\\top y|$ 等于 $1$，与 $|a_1^\\top y|$ 和 $|a_3^\\top y|$ 相等。**\n- 在 OMP 的第一次迭代中，我们计算了与 $y$ 的相关性。我们发现 $|\\langle a_2, y \\rangle| = 0.9$。\n- 索引 1 和 3 的值为 $|\\langle a_1, y \\rangle|=1$ 和 $|\\langle a_3, y \\rangle|=1$。\n- 由于 $0.9 \\neq 1$，声称 $|\\langle a_2, y \\rangle|$ 等于 $1$ 是错误的。因此，OMP 不可能在第一次迭代中选择索引 2。\n- 结论：**不正确**。\n\n**C. StOMP 批次 $S=\\{1,2,3\\}$ 上的最小二乘问题由于 $a_1$ 和 $a_2$ 之间的高相干性而是奇异的，因此 StOMP 在此阶段无法唯一地恢复系数。**\n- 最小二乘问题涉及矩阵 $A_S = \\begin{bmatrix}a_1  a_2  a_3\\end{bmatrix}$。我们计算出其行列式为 $\\det(A_S) = \\sqrt{0.19} \\neq 0$。\n- 行列式非零的方阵是非奇异的（可逆的）。因此，列 $\\{a_1, a_2, a_3\\}$ 是线性无关的。\n- 非奇异矩阵确保最小二乘问题有唯一解。该问题不是奇异的。虽然相干性 $|\\langle a_1, a_2 \\rangle| = 0.9$ 很高，但它小于 $1$，因此向量不是共线的，集合 $\\{a_1, a_2, a_3\\}$ 是线性无关的。\n- 结论：**不正确**。\n\n**D. 因为 StOMP 在第一阶段包含了一个高相干性但虚假的原子 $a_2$，其在最小二乘法后的残差在无噪声设置下不能为零，而 OMP 可以将残差驱动到零。**\n- 我们对 StOMP 的分析表明，在支撑集 $S=\\{1,2,3\\}$ 上的最小二乘拟合得到的系数为 $\\hat{c}_S = \\begin{bmatrix}101\\end{bmatrix}^T$。\n- 重建的信号是 $A_S \\hat{c}_S = 1 \\cdot a_1 + 0 \\cdot a_2 + 1 \\cdot a_3 = a_1 + a_3 = y$。\n- 残差是 $r = y - A_S \\hat{c}_S = y-y=0$。\n- “残差不能为零”的说法是错误的。当真实信号 $y$ 位于所选原子的张成空间中时（这里是正确的，因为 $y=a_1+a_3$ 在 $\\text{span}\\{a_1, a_2, a_3\\}$ 中），$y$ 在该空间上的最小二乘投影就是 $y$ 本身，残差为零。\n- 结论：**不正确**。\n\n**E. 如果 OMP 通过首先选择 $3$ 来打破初始平局，那么在第二次迭代中它必须在 $1$ 之前选择 $2$，因为 $a_2$ 与更新后的残差的相关性仍然高于 $a_1$。**\n- 让我们分析这种假设情景。\n- **迭代 1（假设）：** 选择 $j^{(1)}=3$。残差为 $r'^{(1)} = y - \\text{Proj}_{\\text{span}\\{a_3\\}}(y) = y - \\frac{\\langle a_3, y \\rangle}{\\|a_3\\|^2}a_3 = (a_1+a_3) - \\frac{1}{1}a_3 = a_1$。\n- **迭代 2（假设）：** 我们计算与新残差 $r'^{(1)} = a_1$ 的相关性。感兴趣的剩余原子是 $1$ 和 $2$。\n  - $|\\langle a_1, r'^{(1)} \\rangle| = |\\langle a_1, a_1 \\rangle| = \\|a_1\\|^2 = 1$。\n  - $|\\langle a_2, r'^{(1)} \\rangle| = |\\langle a_2, a_1 \\rangle| = |0.9|$。\n- 比较相关性，$1  0.9$。OMP 会选择索引 $1$，而不是索引 $2$。\n- “$a_2$ 与更新后的残差的相关性仍然高于 $a_1$”的说法是错误的。\n- 结论：**不正确**。\n\n根据详细分析，只有陈述 A 是正确的。", "answer": "$$\\boxed{A}$$", "id": "3481088"}]}