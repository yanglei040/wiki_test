{"hands_on_practices": [{"introduction": "要深入理解相干性在噪声环境下的作用，最好的起点是分析一个基本问题：我们能否可靠地从测量数据中分辨出信号真实存在的位置？本练习将指导你从第一性原理出发，推导出一个确保相关性阈值法能够成功恢复信号支撑集的充分条件。通过这个计算，你将亲手建立起信号最小振幅、测量矩阵的互相关性、信号稀疏度以及噪声水平之间的量化关系，这是理解基于相干性的恢复理论的基石。[@problem_id:3462322]", "problem": "考虑压缩感知中的一个线性传感模型，其测量矩阵为 $A \\in \\mathbb{R}^{m \\times n}$，该矩阵的列 $\\{a_i\\}_{i=1}^{n}$ 均为单位范数，且其相互干性为 $\\mu(A) = \\max_{i \\neq j} |a_i^{\\top} a_j|$。一个 $k$-稀疏信号 $x \\in \\mathbb{R}^{n}$ 被测量为 $y = A x + w$，其中噪声 $w \\in \\mathbb{R}^{m}$ 满足能量界 $\\|w\\|_{2} \\leq \\Delta$。假设 $x$ 的非零项具有相等的幅值 $a  0$，并定义支撑集 $S \\subset \\{1, \\dots, n\\}$ 且 $|S| = k$。相关阈值法规则将一个索引 $i$ 声明为活动索引，如果其绝对相关值 $|a_i^{\\top} y|$ 超过一个阈值，该阈值被选择用于仅使用 $\\mu(A)$、$\\|x\\|_{1}$ 和 $\\Delta$ 来将真实支撑集与其补集分离开。\n\n从相互干性和单位范数列相关的定义出发，并结合三角不等式和柯西-施瓦茨不等式，推导出一个关于最小非零幅值 $a_{\\min}$ 的充分下界，该下界能确保在有噪声的情况下通过相关阈值法实现精确的支撑集恢复。然后，对于给定的数值实例 $\\Delta = 10^{-3}$、$m = 500$、$n = 5000$、$\\mu(A) = 0.08$ 和 $k = 6$，计算你的界所对应的 $a_{\\min}$ 的精确值。将最终答案表示为一个无单位的最简分数。同时，在你的推导过程中，验证给定的参数是否满足使该界有意义所需的基于相干性的稀疏度要求。\n\n你的最终答案必须是单个计算结果（一个数字或一个闭式表达式）。无需四舍五入。", "solution": "该问题要求在有噪声的压缩感知场景下，为保证精确的支撑集恢复，稀疏信号非零项幅值所需满足的一个充分下界。我们首先将成功恢复的条件形式化，然后使用所提供的工具推导出该界。\n\n线性测量模型由 $y = A x + w$ 给出，其中 $y \\in \\mathbb{R}^{m}$ 是测量向量，$A \\in \\mathbb{R}^{m \\times n}$ 是测量矩阵，$x \\in \\mathbb{R}^{n}$ 是 $k$-稀疏信号，$w \\in \\mathbb{R}^{m}$ 是能量有界 $\\|w\\|_{2} \\leq \\Delta$ 的噪声向量。$A$ 的列，记为 $\\{a_i\\}_{i=1}^{n}$，是单位范数的，即对所有 $i \\in \\{1, \\dots, n\\}$ 都有 $\\|a_i\\|_{2} = 1$。$A$ 的相互干性为 $\\mu(A) = \\max_{i \\neq j} |a_i^{\\top} a_j|$。信号 $x$ 是 $k$-稀疏的，意味着它最多有 $k$ 个非零项。设 $S = \\text{supp}(x)$ 是 $x$ 的支撑集，且 $|S|=k$。给定对于任何 $j \\in S$，其项的幅值为 $|x_j| = a  0$。\n\n恢复过程通过相关阈值法进行：如果一个索引 $i$ 与测量向量的相关性幅值 $|a_i^{\\top} y|$ 超过某个阈值 $\\tau$，则该索引被识别为支撑集的一部分。为了实现精确的支撑集恢复，必须存在一个阈值 $\\tau$ 能够完美地区分对应于真实支撑集 $S$ 的相关值与对应于其补集 $S^c$ 的相关值。这要求以下条件成立：\n$$ \\min_{i \\in S} |a_i^{\\top} y|  \\max_{j \\notin S} |a_j^{\\top} y| $$\n我们将推导左侧项的下界和右侧项的上界。\n\n首先，考虑一个索引 $i \\in S$。其相关值为：\n$$ a_i^{\\top} y = a_i^{\\top} (A x + w) = a_i^{\\top} \\left( \\sum_{l=1}^{n} x_l a_l \\right) + a_i^{\\top} w $$\n由于当 $l \\notin S$ 时 $x_l = 0$，我们可以将求和写在支撑集 $S$上：\n$$ a_i^{\\top} y = \\sum_{l \\in S} x_l (a_i^{\\top} a_l) + a_i^{\\top} w $$\n我们可以分离出 $l=i$ 的项：\n$$ a_i^{\\top} y = x_i (a_i^{\\top} a_i) + \\sum_{l \\in S, l \\neq i} x_l (a_i^{\\top} a_l) + a_i^{\\top} w $$\n由于列 $a_i$ 是单位范数的，所以 $a_i^{\\top} a_i = \\|a_i\\|_{2}^2 = 1$。这使得表达式简化为：\n$$ a_i^{\\top} y = x_i + \\sum_{l \\in S, l \\neq i} x_l (a_i^{\\top} a_l) + a_i^{\\top} w $$\n为了找到 $|a_i^{\\top} y|$ 的下界，我们使用反三角不等式 $|u+v| \\ge |u| - |v|$：\n$$ |a_i^{\\top} y| \\ge |x_i| - \\left| \\sum_{l \\in S, l \\neq i} x_l (a_i^{\\top} a_l) + a_i^{\\top} w \\right| $$\n对被减去的项应用三角不等式：\n$$ |a_i^{\\top} y| \\ge |x_i| - \\left( \\left| \\sum_{l \\in S, l \\neq i} x_l (a_i^{\\top} a_l) \\right| + |a_i^{\\top} w| \\right) $$\n我们对每一项进行界定。给定 $|x_i|=a$。求和项可以通过三角不等式和相互干性的定义来界定：\n$$ \\left| \\sum_{l \\in S, l \\neq i} x_l (a_i^{\\top} a_l) \\right| \\le \\sum_{l \\in S, l \\neq i} |x_l| |a_i^{\\top} a_l| \\le \\sum_{l \\in S, l \\neq i} a \\cdot \\mu(A) = (k-1) a \\mu(A) $$\n噪声项可以通过柯西-施瓦茨不等式来界定：\n$$ |a_i^{\\top} w| \\le \\|a_i\\|_{2} \\|w\\|_{2} \\le 1 \\cdot \\Delta = \\Delta $$\n代入这些界，我们得到支撑集内相关值的下界：\n$$ \\min_{i \\in S} |a_i^{\\top} y| \\ge a - ((k-1) a \\mu(A) + \\Delta) = a(1 - (k-1)\\mu(A)) - \\Delta $$\n接下来，考虑一个索引 $j \\notin S$。其相关值为：\n$$ a_j^{\\top} y = \\sum_{l \\in S} x_l (a_j^{\\top} a_l) + a_j^{\\top} w $$\n为了找到 $|a_j^{\\top} y|$ 的上界，我们使用三角不等式：\n$$ |a_j^{\\top} y| \\le \\left| \\sum_{l \\in S} x_l (a_j^{\\top} a_l) \\right| + |a_j^{\\top} w| $$\n我们对求和项进行界定。由于 $j \\notin S$ 且 $l \\in S$，我们有 $j \\neq l$，所以 $|a_j^{\\top} a_l| \\le \\mu(A)$。\n$$ \\left| \\sum_{l \\in S} x_l (a_j^{\\top} a_l) \\right| \\le \\sum_{l \\in S} |x_l| |a_j^{\\top} a_l| \\le \\sum_{l \\in S} a \\cdot \\mu(A) = k a \\mu(A) $$\n噪声项的界定和之前一样：$|a_j^{\\top} w| \\le \\Delta$。\n代入这些界，我们得到支撑集外相关值的上界：\n$$ \\max_{j \\notin S} |a_j^{\\top} y| \\le k a \\mu(A) + \\Delta $$\n精确支撑集恢复的一个充分条件是，最小的支撑集内相关值的下界大于最大的支撑集外相关值的上界：\n$$ a(1 - (k-1)\\mu(A)) - \\Delta  k a \\mu(A) + \\Delta $$\n我们对 $a$ 解这个不等式：\n$$ a - a(k-1)\\mu(A) - k a \\mu(A)  2\\Delta $$\n$$ a(1 - (k-1)\\mu(A) - k\\mu(A))  2\\Delta $$\n$$ a(1 - k\\mu(A) + \\mu(A) - k\\mu(A))  2\\Delta $$\n$$ a(1 - (2k-1)\\mu(A))  2\\Delta $$\n为了使这个不等式能得到一个有意义的 $a$ 的正下界，$a$ 的系数必须为正。这就给出了众所周知的基于相干性的稀疏度要求：\n$$ 1 - (2k-1)\\mu(A)  0 \\implies (2k-1)\\mu(A)  1 $$\n如果此条件成立，我们可以通过除法找到 $a$ 的下界：\n$$ a  \\frac{2\\Delta}{1 - (2k-1)\\mu(A)} $$\n因此，所需的最小幅值 $a_{\\min}$ 为：\n$$ a_{\\min} = \\frac{2\\Delta}{1 - (2k-1)\\mu(A)} $$\n现在我们使用给定的数值：$\\Delta = 10^{-3}$，$k = 6$，以及 $\\mu(A) = 0.08$。其他参数 $m=500$ 和 $n=5000$ 与压缩感知设置一致，但并未进入本次特定的界计算。\n\n首先，我们验证基于相干性的稀疏度要求：\n$$ (2k-1)\\mu(A) = (2 \\cdot 6 - 1) \\cdot 0.08 = (11) \\cdot 0.08 = 0.88 $$\n由于 $0.88  1$，该要求得到满足，我们推导的 $a_{\\min}$ 的界是有效且有意义的。\n\n现在，我们计算 $a_{\\min}$ 的值：\n$$ a_{\\min} = \\frac{2 \\cdot 10^{-3}}{1 - 0.88} = \\frac{2 \\cdot 10^{-3}}{0.12} $$\n为了将其表示为最简分数：\n$$ a_{\\min} = \\frac{2 \\times \\frac{1}{1000}}{\\frac{12}{100}} = \\frac{\\frac{2}{1000}}{\\frac{12}{100}} = \\frac{2}{1000} \\cdot \\frac{100}{12} = \\frac{200}{12000} = \\frac{2}{120} = \\frac{1}{60} $$\n因此，在这些条件下保证支撑集恢复所需的最小非零幅值为 $\\frac{1}{60}$。", "answer": "$$\\boxed{\\frac{1}{60}}$$", "id": "3462322"}, {"introduction": "在成功识别信号的支撑集之后，下一个自然而然的问题是：我们能以多高的精度估计出这些非零元素的幅值？此练习将我们的关注点从支撑集恢复转移到估计误差的稳定性上。你将使用Gershgorin圆盘定理这一强大的谱分析工具，来探究互相关性如何影响相关子矩阵的谱特性，并最终决定噪声在估计过程中的放大程度。通过比较不同相干性水平下的误差上界，你将对测量过程中的微小变化如何影响最终恢复质量获得深刻的直观认识。[@problem_id:3462319]", "problem": "考虑一个线性传感模型，其测量值由 $y = A x + w$ 给出，其中 $A \\in \\mathbb{R}^{m \\times n}$ 具有单位范数列，$x \\in \\mathbb{R}^{n}$ 是一个 $k$-稀疏向量，其支撑集为一个未知的索引集 $S$，且 $|S| = k$，并且 $w \\in \\mathbb{R}^{m}$ 是一个满足 $\\|w\\|_{2} \\leq \\varepsilon$ 的加性噪声向量。$A$ 的互相关性定义为 $\\mu(A) = \\max_{i \\neq j} |\\langle a_{i}, a_{j} \\rangle|$，其中 $a_{i}$ 表示 $A$ 的第 $i$ 列。假设一个基于相关性的恢复过程（例如，阈值法或正交匹配追踪 (OMP)）正确地识别了支撑集 $S$，然后通过在 $A_{S}$ 上进行最小二乘去偏步骤来估计幅度。\n\n从互相关性定义和Gershgorin圆盘定理出发，推导一个形式为\n$$\n\\|x^{\\star} - x\\|_{2} \\leq c(\\mu(A), k)\\,\\varepsilon,\n$$\n的幅度估计误差的确定性上界，其中 $x^{\\star}$ 是在真实支撑集 $S$ 上的最小二乘估计，而 $c(\\mu(A), k)$ 是一个由格拉姆矩阵 $A_{S}^{\\top} A_{S}$ 的谱界产生的常数，用 $\\mu(A)$ 和 $k$ 明确表示。然后，对于初始相关性 $\\mu(A) = 0.2$ 和稀疏度 $k = 4$，计算 $c(\\mu(A), k)$ 的值。接下来，假设传感过程中的一个扰动使互相关性增加了 $0.05$，即 $\\mu(A)$ 变为 $0.25$。在扰动后的相关性下重新计算 $c(\\mu(A), k)$，并确定界中的乘性退化因子，该因子定义为扰动后的常数与原始常数的比率。\n\n将乘性退化因子以单一封闭形式表达式报告。不要对答案进行四舍五入。", "solution": "该问题要求在已知正确支撑集的情况下，推导稀疏信号最小二乘估计的误差界。设 $S$ 是 $k$-稀疏信号 $x$ 的支撑集，并设 $x_S \\in \\mathbb{R}^k$ 是 $x$ 的非零项组成的向量。类似地，设 $A_S \\in \\mathbb{R}^{m \\times k}$ 是由 $S$ 索引的列组成的 $A$ 的子矩阵。限制在支撑集上的测量模型为\n$$\ny = A_S x_S + w\n$$\n通过求解正规方程组得到 $x_S$ 的最小二乘估计 $x^{\\star}_S$，结果为：\n$$\nx^{\\star}_S = (A_S^{\\top} A_S)^{-1} A_S^{\\top} y\n$$\n为了求估计误差，我们代入 $y$ 的表达式：\n$$\nx^{\\star}_S = (A_S^{\\top} A_S)^{-1} A_S^{\\top} (A_S x_S + w) = (A_S^{\\top} A_S)^{-1} (A_S^{\\top} A_S) x_S + (A_S^{\\top} A_S)^{-1} A_S^{\\top} w\n$$\n化简后得到：\n$$\nx^{\\star}_S = x_S + (A_S^{\\top} A_S)^{-1} A_S^{\\top} w\n$$\n估计误差是差值 $x^{\\star}_S - x_S$。其欧几里得范数有如下界：\n$$\n\\|x^{\\star} - x\\|_{2} = \\|x^{\\star}_S - x_S\\|_{2} = \\|(A_S^{\\top} A_S)^{-1} A_S^{\\top} w\\|_{2} \\leq \\|(A_S^{\\top} A_S)^{-1}\\|_{2} \\|A_S^{\\top} w\\|_{2}\n$$\n我们可以进一步界定 $\\|A_S^{\\top} w\\|_{2} \\le \\|A_S^{\\top}\\|_{2} \\|w\\|_{2}$。令 $G = A_S^{\\top} A_S$ 为大小为 $k \\times k$ 的格拉姆矩阵。其逆矩阵的谱范数为 $\\|G^{-1}\\|_{2} = 1/\\sigma_{\\min}(G)$，其中 $\\sigma_{\\min}(G)$ 是 $G$ 的最小奇异值。由于 $G$ 是一个对称半正定矩阵，其奇异值就是其特征值，因此 $\\sigma_{\\min}(G) = \\lambda_{\\min}(G)$。类似地，$A_S^{\\top}$ 的谱范数为 $\\|A_S^{\\top}\\|_{2} = \\|A_S\\|_{2} = \\sqrt{\\lambda_{\\max}(A_S^{\\top}A_S)} = \\sqrt{\\lambda_{\\max}(G)}$。误差界变为：\n$$\n\\|x^{\\star} - x\\|_{2} \\leq \\frac{\\sqrt{\\lambda_{\\max}(G)}}{\\lambda_{\\min}(G)} \\|w\\|_{2}\n$$\n我们使用Gershgorin圆盘定理来界定 $G$ 的特征值。$G$ 的元素为 $G_{ij} = \\langle a_i, a_j \\rangle$，其中 $i,j \\in S$。对角线元素为 $G_{ii} = \\|a_i\\|_2^2 = 1$，因为 $A$ 的列是单位范数。非对角线元素的大小由互相关性界定：对于 $i \\neq j$，$|G_{ij}| \\leq \\mu(A)$。\n\nGershgorin圆盘定理指出，对于 $G$ 的任意特征值 $\\lambda$，至少存在一个对角元素 $G_{ii}$ 使得 $|\\lambda - G_{ii}| \\leq \\sum_{j \\neq i, j\\in S} |G_{ij}|$。由于对所有 $i$ 都有 $G_{ii} = 1$ 并且求和中有 $k-1$ 项，我们得到：\n$$\n|\\lambda - 1| \\leq \\sum_{j \\neq i, j\\in S} \\mu(A) = (k-1)\\mu(A)\n$$\n这个不等式意味着 $G$ 的所有特征值都必须位于区间 $[1 - (k-1)\\mu(A), 1 + (k-1)\\mu(A)]$ 内。因此，我们得到最小和最大特征值的界：\n$$\n\\lambda_{\\min}(G) \\geq 1 - (k-1)\\mu(A)\n$$\n$$\n\\lambda_{\\max}(G) \\leq 1 + (k-1)\\mu(A)\n$$\n将这些界代入误差不等式，并使用给定条件 $\\|w\\|_{2} \\leq \\varepsilon$：\n$$\n\\|x^{\\star} - x\\|_{2} \\leq \\frac{\\sqrt{1 + (k-1)\\mu(A)}}{1 - (k-1)\\mu(A)} \\varepsilon\n$$\n这就是所求的界，其中常数 $c(\\mu(A), k)$ 被确定为：\n$$\nc(\\mu(A), k) = \\frac{\\sqrt{1 + (k-1)\\mu(A)}}{1 - (k-1)\\mu(A)}\n$$\n现在，我们进行所需的计算。\n\n首先，对于初始情况，我们有 $\\mu(A) = \\mu_1 = 0.2$ 和 $k=4$。\n$$\nc_1 = c(0.2, 4) = \\frac{\\sqrt{1 + (4-1)(0.2)}}{1 - (4-1)(0.2)} = \\frac{\\sqrt{1 + 3(0.2)}}{1 - 3(0.2)} = \\frac{\\sqrt{1+0.6}}{1-0.6} = \\frac{\\sqrt{1.6}}{0.4}\n$$\n为了简化，我们将数字写成分数形式：$\\sqrt{1.6} = \\sqrt{16/10} = 4/\\sqrt{10}$ 以及 $0.4 = 4/10$。\n$$\nc_1 = \\frac{4/\\sqrt{10}}{4/10} = \\frac{4}{\\sqrt{10}} \\cdot \\frac{10}{4} = \\frac{10}{\\sqrt{10}} = \\sqrt{10}\n$$\n接下来，对于扰动情况，相关性增加了 $0.05$，因此 $\\mu(A) = \\mu_2 = 0.2 + 0.05 = 0.25$。稀疏度保持为 $k=4$。\n$$\nc_2 = c(0.25, 4) = \\frac{\\sqrt{1 + (4-1)(0.25)}}{1 - (4-1)(0.25)} = \\frac{\\sqrt{1 + 3(0.25)}}{1 - 3(0.25)} = \\frac{\\sqrt{1+0.75}}{1-0.75} = \\frac{\\sqrt{1.75}}{0.25}\n$$\n再次，我们使用分数：$\\sqrt{1.75} = \\sqrt{7/4} = \\sqrt{7}/2$ 以及 $0.25 = 1/4$。\n$$\nc_2 = \\frac{\\sqrt{7}/2}{1/4} = \\frac{\\sqrt{7}}{2} \\cdot 4 = 2\\sqrt{7}\n$$\n最后，我们计算乘性退化因子，即扰动后的常数与原始常数的比率：\n$$\n\\text{退化因子} = \\frac{c_2}{c_1} = \\frac{2\\sqrt{7}}{\\sqrt{10}}\n$$\n为了将其表示为单一封闭形式表达式，我们对分母进行有理化：\n$$\n\\frac{c_2}{c_1} = \\frac{2\\sqrt{7}\\sqrt{10}}{\\sqrt{10}\\sqrt{10}} = \\frac{2\\sqrt{70}}{10} = \\frac{\\sqrt{70}}{5}\n$$", "answer": "$$\\boxed{\\frac{\\sqrt{70}}{5}}$$", "id": "3462319"}, {"introduction": "理论分析为我们提供了关于稀疏恢复性能的保证，但这些理论界限在实践中表现如何？本练习是一个计算性实验，旨在连接理论与实践的桥梁。你将亲手实现正交匹配追踪（OMP）算法，并通过数值模拟来观测支撑集恢复的“相变”现象——即恢复成功率随信噪比和稀疏度急剧变化的边界。通过将模拟结果与基于相干性的理论预测进行对比，你将直观地理解理论保证的“充分但非必要”特性，并体会到为何随机矩阵在实践中通常表现更优。[@problem_id:3462348]", "problem": "考虑压缩感知中的标准线性测量模型，其中测量向量 $y \\in \\mathbb{R}^m$ 是通过 $y = A x + e$ 从稀疏信号 $x \\in \\mathbb{R}^n$ 获取的，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是测量矩阵，$e \\in \\mathbb{R}^m$ 是加性噪声。假设 $x$ 是 $k$-稀疏的，意味着它恰好有 $k$ 个非零项。设 $A$ 的列是单位范数的。将 $A$ 的互相关性定义为 $\\mu(A) = \\max_{i \\neq j} |\\langle a_i, a_j \\rangle|$，其中 $a_i$ 表示 $A$ 的第 $i$ 列。支撑集恢复指的是精确识别 $x$ 的非零项的索引集。\n\n本问题在固定的互相关性 $\\mu(A)$ 下，分析了支撑集恢复在 $(k/m, \\mathrm{SNR})$ 平面上的相变，并验证了基于相关性的阈值与使用在约束等距性质 (RIP) 下表现良好的矩阵进行的仿真相比，是否能预测恢复边界。\n\n基于以下基本定义和事实进行推导和算法设计：\n- 互相关性 $\\mu(A)$ 控制了 $A$ 的不同列之间的最大相关性。\n- 像正交匹配追踪 (OMP) 这样的稀疏恢复算法根据与残差的相关性进行贪婪选择。\n- 在无噪声情况下，经典的基于相关性的保证为精确支撑集恢复提供了一个充分的稀疏度界限（以 $\\mu(A)$ 表示）。\n- 对于带噪测量，信噪比 (SNR) 定义为 $\\mathrm{SNR} = \\|A x\\|_2^2 / \\|e\\|_2^2$，这是一个无量纲比率。更高的 $\\mathrm{SNR}$ 通常会改善恢复性能。\n- 对于合适的维度和稀疏度，具有归一化列的高斯随机矩阵以高概率满足约束等距性质，从而在经验上实现鲁棒恢复。\n\n您的程序必须实现以下内容：\n- 使用正交匹配追踪 (OMP) 进行支撑集恢复，迭代次数固定为真实稀疏度 $k$。在每次迭代中，选择与当前残差的绝对相关性最大的 $A$ 的列，更新支撑集，并在所选支撑集上重新计算最小二乘估计。\n- 对于每个具有固定互相关性 $\\mu(A)$ 的测试矩阵，按如下方式构造 $A$：\n  - 选择一个单位向量 $u \\in \\mathbb{R}^m$ 和一个单位向量 $w \\in \\mathbb{R}^m$，使得 $\\langle u, w \\rangle = 0$。\n  - 设定两个列 $a_1 = u$ 和 $a_2 = \\alpha u + \\sqrt{1 - \\alpha^2}\\, w$，其中 $\\alpha \\in (0,1)$ 是一个预设的目标值，因此 $\\langle a_1, a_2 \\rangle = \\alpha$。\n  - 在 $\\mathrm{span}\\{u, w\\}$ 的正交补空间中生成其余的 $n-2$ 个列作为单位向量（以确保与 $a_1$ 和 $a_2$ 的内积为零），并对其进行归一化。\n  - 生成的矩阵具有固定的 $\\mu(A)$，其值主要由对 $(a_1, a_2)$ 决定，即 $\\mu(A) \\approx \\alpha$。\n- 对于每个测试用例，还需构造一个比较矩阵，其具有独立同分布的高斯条目和归一化的列（一个典型的 RIP 友好模型）。\n- 对于噪声 $e$，使用独立的、方差经选择的高斯条目，以使期望能量满足 $\\mathrm{SNR} = \\|A x\\|_2^2 / \\|e\\|_2^2$。所有测试中的 SNR 值都是无量纲比率（不是分贝），并且必须如此处理。\n\n将固定 $\\mathrm{SNR}$ 下的相变边界定义为（在递增的 $k$ 的扫描范围内）精确支撑集恢复的经验成功率至少达到指定阈值的最大 $k$。以比率 $k/m$ 来衡量该边界。\n\n验证标准：\n- 根据互相关性的经典充分条件，计算无噪声情况下的预测稀疏度极限 $K_{\\mathrm{coh}}$（问题陈述中不包含或假设任何数值常数；在解决方案中推导它们）。将此视为边界的预测下界。\n- 对于每个测试用例和最高 $\\mathrm{SNR}$ 水平，比较：\n  1. 固定 $\\mu(A)$ 矩阵的观测边界是否至少为预测的 $K_{\\mathrm{coh}}$（下界验证）。\n  2. RIP 友好（高斯）矩阵的观测边界是否大于或等于固定 $\\mu(A)$ 矩阵的边界（RIP 优越性）。\n- 此外，验证边界作为 $\\mathrm{SNR}$ 函数的单调性：边界应随 $\\mathrm{SNR}$ 的增加而非递减。\n\n实验方案：\n- 在所有测试中，生成具有恰好 $k$ 个非零项和单位幅值、随机符号系数的稀疏信号 $x$。对于固定 $\\mu(A)$ 矩阵，当 $k \\geq 2$ 时，在支撑集中包含两个高度相关的列 $a_1$ 和 $a_2$，以探究在给定 $\\mu(A)$ 下的最坏情况行为；对于 RIP 友好矩阵，则均匀随机地选择支撑集，不强制包含任何特定列。\n- 对于每个 $(k, \\mathrm{SNR})$ 对，运行多次独立试验并估计成功率。将成功定义为恢复的支撑集与真实支撑集完全相等。\n\n测试套件和参数：\n- 使用以下三个测试用例，每个用例都有一个固定的互相关性目标：\n  - 用例 1: $m = 120, n = 180$，目标 $\\alpha = 0.45, \\mathrm{SNR} \\in \\{5.0, 10.0, 20.0\\}$。\n  - 用例 2: $m = 120, n = 180$，目标 $\\alpha = 0.35, \\mathrm{SNR} \\in \\{5.0, 10.0, 20.0\\}$。\n  - 用例 3: $m = 140, n = 160$，目标 $\\alpha = 0.30, \\mathrm{SNR} \\in \\{5.0, 10.0, 20.0\\}$。\n- 对于每个用例，在 $k \\in \\{1, 2, \\dots, \\lfloor 0.12\\, m \\rfloor\\}$ 范围内扫描 $k$。\n- 每个 $(k, \\mathrm{SNR})$ 对使用 $25$ 次独立试验。\n- 使用 $0.8$ 的成功率阈值（以小数形式表示）来定义每个 $\\mathrm{SNR}$ 下的边界。\n\n所需输出：\n- 对于每个测试用例，按顺序生成三个布尔值：\n  1. 下界验证：在 $\\mathrm{SNR}=20.0$ 时，固定 $\\mu(A)$ 矩阵的观测边界是否至少为预测的 $K_{\\mathrm{coh}}$。\n  2. RIP 优越性：在 $\\mathrm{SNR}=20.0$ 时，RIP 友好矩阵的观测边界是否大于或等于固定 $\\mu(A)$ 矩阵的边界。\n  3. SNR 单调性：固定 $\\mu(A)$ 矩阵的边界是否随着 $\\mathrm{SNR}$ 的增加（从 $5.0$ 到 $10.0$ 再到 $20.0$）而非递减。\n- 您的程序应生成单行输出，包含所有九个布尔值（每个测试用例三个），以逗号分隔，并用方括号括起来（例如，\"[True,False,True,True,True,False,False,True,True]\"）。\n\n不涉及物理单位。不出现角度。所有百分比必须以小数或分数报告；成功阈值以 $0.8$ 给出。", "solution": "此问题是一个关于压缩感知的计算实验，旨在通过数值仿真来检验理论预测、比较不同类型测量矩阵的性能，并分析信噪比对恢复性能的影响。本解决方案分为三个主要部分：首先，推导无噪声情况下基于互相关性的理论稀疏度极限$K_{\\mathrm{coh}}$；其次，详细阐述实验方案，包括正交匹配追踪（OMP）算法的实现细节和指定测量矩阵的构造方法；最后，明确仿真结果需要满足的验证标准。\n\n### 1. 基于互相关性的理论稀疏度极限\n\n问题要求我们推导一个预测的稀疏度极限 $K_{\\mathrm{coh}}$，它是一个充分条件，保证像OMP这样的贪心算法在无噪声的情况下能完美恢复一个$k$-稀疏信号$x$的支撑集。该条件基于测量矩阵$A$的互相关性 $\\mu(A) = \\max_{i \\neq j} |\\langle a_i, a_j \\rangle|$。\n\nOMP算法在每一步都贪婪地选择与当前残差最相关的原子。为了保证成功恢复，在第一步中，算法必须选择一个属于真实支撑集 $S_0$ 的原子。让我们分析这个过程。无噪声的测量值为 $y = Ax = \\sum_{j \\in S_0} x_j a_j$。\n\n对于一个不正确的原子 $a_i$ ($i \\notin S_0$)，其与$y$的相关性为：\n$|c_{\\text{incorrect}}| = |\\langle a_i, y \\rangle| = |\\sum_{j \\in S_0} x_j \\langle a_i, a_j \\rangle| \\le \\sum_{j \\in S_0} |x_j| |\\langle a_i, a_j \\rangle| \\le \\mu(A) \\sum_{j \\in S_0} |x_j| = \\mu(A) \\|x\\|_1$\n\n对于一个正确的原子 $a_i$ ($i \\in S_0$)，其相关性为：\n$c_{\\text{correct}} = \\langle a_i, y \\rangle = x_i + \\sum_{j \\in S_0, j \\neq i} x_j \\langle a_i, a_j \\rangle$\n其幅值的下界为：\n$|c_{\\text{correct}}| \\ge |x_i| - |\\sum_{j \\in S_0, j \\neq i} x_j \\langle a_i, a_j \\rangle| \\ge |x_i| - \\mu(A) \\sum_{j \\in S_0, j \\neq i} |x_j|$\n\n一个严格的成功恢复充分条件是，任何正确原子的相关性都大于任何不正确原子的相关性，即 $\\min_{i \\in S_0} |c_{\\text{correct}}| > \\max_{l \\notin S_0} |c_{\\text{incorrect}}|$。对于问题中定义的信号（非零项幅值为1），$\\|x\\|_1 = k$ 且 $|x_i|=1$。不等式变为：\n$1 - \\mu(A) (k-1) > \\mu(A) k$\n$1 > \\mu(A) (2k - 1) \\implies k  \\frac{1}{2}\\left(1 + \\frac{1}{\\mu(A)}\\right)$\n\n这个条件是多种贪心算法在无噪声情况下精确恢复的经典保证。因此，我们将理论稀疏度极限 $K_{\\mathrm{coh}}$ 定义为满足此严格不等式的最大整数。\n\n### 2. 实验设计与算法\n\n仿真实验的核心是找到支撑集恢复的经验“相变”边界，并进行验证。\n\n#### 正交匹配追踪 (OMP)\n给定稀疏度$k$，OMP算法流程如下：\n1.  初始化：残差 $r_0 = y$，支撑集 $S = \\emptyset$。\n2.  迭代 $k$ 次：\n    a.  **匹配**：找到与当前残差$r_{t-1}$相关性最大的原子索引 $i_t = \\arg\\max_{j \\notin S} |\\langle a_j, r_{t-1} \\rangle|$。\n    b.  **更新**：将索引加入支撑集 $S = S \\cup \\{i_t\\}$。\n    c.  **投影**：求解最小二乘问题 $\\hat{x}_S = \\arg\\min_{z} \\|y - A_S z\\|_2^2$，其中$A_S$是$A$中由$S$索引的列构成的子矩阵。\n    d.  **更新残差**：$r_t = y - A_S \\hat{x}_S$。\n3.  输出：最终的支撑集$S$。\n\n#### 矩阵构造\n-   **固定$\\mu(A)$矩阵**：为构造一个在两列之间具有受控高相关性的矩阵，我们对给定的 $m, n, \\alpha$ 按如下方式进行：\n    1.  选择两个正交单位向量 $u, w \\in \\mathbb{R}^m$。\n    2.  定义前两列为 $a_1 = u$ 和 $a_2 = \\alpha u + \\sqrt{1 - \\alpha^2} w$。这样可确保 $\\|a_1\\|_2 = 1, \\|a_2\\|_2 = 1, \\langle a_1, a_2 \\rangle = \\alpha$。\n    3.  其余 $n-2$ 列在 $\\mathrm{span}\\{u, w\\}$ 的正交补空间中随机生成并归一化，以确保它们与 $a_1, a_2$ 正交。这样，矩阵的互相关性 $\\mu(A) \\approx \\alpha$。\n\n-   **RIP友好（高斯）矩阵**：通过生成一个 $m \\times n$ 的高斯随机矩阵并将其每列归一化为单位范数来构造。\n\n#### 仿真方案\n对于每个测试用例，我们扫描稀疏度 $k$。对于每个 $(k, \\mathrm{SNR})$ 对，运行25次独立试验：\n1.  **信号生成**：创建一个 $k$-稀疏信号 $x$。对于固定$\\mu(A)$矩阵，为测试最坏情况，若 $k \\ge 2$，则支撑集 $S_0$ 强制包含两个高相关列的索引 $\\{0, 1\\}$。对于高斯矩阵，支撑集随机选择。非零系数的幅值为1，符号随机。\n2.  **噪声生成**：噪声向量 $e$ 的分量从高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取，其中方差 $\\sigma^2$ 根据信噪比公式 $\\mathrm{SNR} = \\frac{\\|Ax\\|_2^2}{m \\sigma^2}$ 确定。\n3.  **恢复与评估**：构造测量值 $y = Ax + e$，运行OMP得到估计的支撑集 $\\hat{S}$。若 $\\hat{S}$ 与 $S_0$ 完全相同，则试验成功。\n4.  **边界定义**：对于给定的SNR，相变边界是使得经验成功率（成功试验的比例）不小于0.8的最大$k$值。\n\n### 3. 验证标准\n对每个测试用例的仿真结果执行三项检查：\n\n1.  **下界验证**：在最高SNR ($20.0$)下，比较固定$\\mu(A)$矩阵的经验边界 $k^*_{\\mu, 20}$ 与理论预测 $K_{\\mathrm{coh}}$。验证 $k^*_{\\mu, 20} \\ge K_{\\mathrm{coh}}$ 是否成立。\n\n2.  **RIP优越性**：在最高SNR ($20.0$)下，比较高斯矩阵的经验边界 $k^*_{G, 20}$ 与固定$\\mu(A)$矩阵的经验边界 $k^*_{\\mu, 20}$。验证 $k^*_{G, 20} \\ge k^*_{\\mu, 20}$ 是否成立。\n\n3.  **SNR单调性**：对于固定$\\mu(A)$矩阵，检查其经验边界是否随SNR的增加（从5.0到10.0再到20.0）而非递减。验证 $k^*_{\\mu, 5} \\le k^*_{\\mu, 10} \\le k^*_{\\mu, 20}$ 是否成立。\n\n最终输出将是对应于三个测试用例的九个布尔值。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import lstsq\nimport random\n\ndef omp(A, y, k):\n    \"\"\"\n    Orthogonal Matching Pursuit algorithm.\n    :param A: Measurement matrix (m x n)\n    :param y: Measurement vector (m x 1)\n    :param k: Sparsity level\n    :return: A list of indices of the recovered support.\n    \"\"\"\n    m, n = A.shape\n    support = []\n    residual = y.copy()\n\n    for _ in range(k):\n        correlations = np.abs(A.T @ residual)\n        # Mask out already selected columns\n        if support:\n            correlations[support] = -1.0\n        \n        new_idx = np.argmax(correlations)\n        if new_idx in support:\n            break\n        support.append(new_idx)\n        \n        A_s = A[:, sorted(support)]\n        \n        x_s, _, _, _ = lstsq(A_s, y)\n        \n        residual = y - A_s @ x_s\n    \n    return sorted(support)\n\ndef construct_fixed_mu_matrix(m, n, alpha):\n    \"\"\"Constructs a matrix with two columns having coherence `alpha`.\"\"\"\n    u = np.zeros(m)\n    u[0] = 1.0\n    w = np.zeros(m)\n    w[1] = 1.0\n    \n    a1 = u\n    a2 = alpha * u + np.sqrt(1 - alpha**2) * w\n    \n    A = np.zeros((m, n))\n    A[:, 0] = a1\n    if n > 1:\n        A[:, 1] = a2\n    \n    if n > 2:\n        rem_cols = np.random.randn(m - 2, n - 2)\n        if rem_cols.shape[1] > 0:\n            rem_cols /= np.linalg.norm(rem_cols, axis=0, keepdims=True)\n            A[2:, 2:] = rem_cols\n        \n    return A\n\ndef construct_gaussian_matrix(m, n):\n    \"\"\"Constructs a matrix with normalized i.i.d. Gaussian columns.\"\"\"\n    A = np.random.randn(m, n)\n    A /= np.linalg.norm(A, axis=0, keepdims=True)\n    return A\n\ndef find_boundary(m, n, k_range, snr, matrix_type, alpha):\n    \"\"\"Finds the maximum k for which recovery success rate is >= threshold.\"\"\"\n    num_trials = 25\n    success_threshold = 0.8\n\n    if matrix_type == 'fixed_mu':\n        A = construct_fixed_mu_matrix(m, n, alpha)\n    else: # 'gaussian'\n        A = construct_gaussian_matrix(m, n)\n\n    for k in reversed(k_range):\n        success_count = 0\n        for _ in range(num_trials):\n            x = np.zeros(n)\n            if matrix_type == 'fixed_mu':\n                if k == 1:\n                    true_support_list = random.sample(range(2), 1)\n                else: # k >= 2\n                    support_set = {0, 1}\n                    if k > 2:\n                        other_indices = random.sample(range(2, n), k - 2)\n                        support_set.update(other_indices)\n                    true_support_list = sorted(list(support_set))\n            else: # 'gaussian'\n                true_support_list = sorted(random.sample(range(n), k))\n            \n            x[true_support_list] = np.random.choice([-1.0, 1.0], size=k)\n\n            Ax = A @ x\n            norm_Ax_sq = np.sum(Ax**2)\n            \n            if snr > 0:\n                noise_var = norm_Ax_sq / (m * snr)\n                sigma = np.sqrt(noise_var) if noise_var > 0 else 0\n                e = np.random.normal(0, sigma, size=m)\n                y = Ax + e\n            else:\n                y = Ax\n            \n            recovered_support = omp(A, y, k)\n            \n            if recovered_support == true_support_list:\n                success_count += 1\n        \n        if success_count / num_trials >= success_threshold:\n            return k\n            \n    return 0\n\ndef solve():\n    \"\"\"Main function to run the simulation and validation.\"\"\"\n    test_cases = [\n        (120, 180, 0.45, [5.0, 10.0, 20.0]),\n        (120, 180, 0.35, [5.0, 10.0, 20.0]),\n        (140, 160, 0.30, [5.0, 10.0, 20.0]),\n    ]\n    np.random.seed(42)\n    random.seed(42)\n\n    final_results = []\n    \n    for m, n, alpha, snrs in test_cases:\n        K_coh = int(np.floor(0.5 * (1.0 / alpha + 1.0)))\n        \n        k_max = int(np.floor(0.12 * m))\n        k_range = list(range(1, k_max + 1))\n        \n        boundaries_mu = []\n        for snr in snrs:\n            boundary = find_boundary(m, n, k_range, snr, 'fixed_mu', alpha)\n            boundaries_mu.append(boundary)\n            \n        highest_snr = snrs[-1]\n        boundary_G_high_snr = find_boundary(m, n, k_range, highest_snr, 'gaussian', alpha)\n\n        boundary_mu_high_snr = boundaries_mu[-1]\n        val1 = boundary_mu_high_snr >= K_coh\n        \n        val2 = boundary_G_high_snr >= boundary_mu_high_snr\n        \n        val3 = (boundaries_mu[0] = boundaries_mu[1]) and (boundaries_mu[1] = boundaries_mu[2])\n        \n        final_results.extend([val1, val2, val3])\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "3462348"}]}