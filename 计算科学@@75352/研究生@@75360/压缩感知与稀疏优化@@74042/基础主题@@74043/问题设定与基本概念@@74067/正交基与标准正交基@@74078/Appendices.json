{"hands_on_practices": [{"introduction": "理解正交基不仅仅在于其定义，更在于掌握如何构建它们。本实践将指导您使用Householder变换实现QR分解，这是一种从任意给定矩阵的列向量构造其列空间标准正交基的稳健数值方法。通过从头开始构建这一基本工具，您将深入理解正交化过程的几何与代数基础 [@problem_id:3464402]。", "problem": "给定一个实数矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其中 $m \\ge n$。请构建一个程序，使用 Householder 反射计算 $A$ 的正交三角（QR）分解，得到 $A = Q R$，其中 $Q \\in \\mathbb{R}^{m \\times n}$ 具有标准正交列，$R \\in \\mathbb{R}^{n \\times n}$ 是一个上三角矩阵。您的程序必须基于以下基本原理进行设计：\n- 一个矩阵 $Q$ 具有标准正交列，当且仅当 $Q^\\top Q = I_n$，其中 $I_n$ 是 $n \\times n$ 的单位矩阵。\n- Householder 反射是一种线性变换，它将向量关于一个与某个单位向量正交的超平面进行反射。这样的变换 $H$ 满足 $H^\\top H = I$ 和 $H = H^\\top$。\n- 正交矩阵的乘积仍然是正交矩阵。\n- 通过连续应用反射来消除一列中的次对角线元素，可以得到一个上三角形式。\n\n您的程序必须：\n1. 通过连续应用 Householder 反射来消除次对角线元素，从而构建分解 $A = Q R$。在主要构建过程中，不得使用任何直接返回 $A$ 的 QR 分解的库函数。\n2. 通过适当调整 $Q$ 的列和 $R$ 相应行的符号，强制执行 $R$ 的对角线元素在非零时为非负的约定（以使 $A = Q R$ 仍然有效）。\n3. 对每个测试用例验证以下属性：\n   - 标准正交性：在指定的容差 $t$ 内，$Q^\\top Q \\approx I_n$。\n   - 上三角性：$R$ 中所有严格位于主对角线下方的元素的绝对值至多为 $t$。\n   - 满列秩时的唯一性：如果 $\\operatorname{rank}(A) = n$，则在非负对角线约定下，$R$ 是唯一确定的。请通过独立计算同一矩阵 $A$ 的另一个正交三角分解 $\\tilde{Q} \\tilde{R}$（使用任何与您的 Householder 构建方法不同且正确的其他方法），对 $\\tilde{R}$ 强制执行相同的非负对角线约定，并检查在容差 $t$ 内是否有 $R \\approx \\tilde{R}$，来数值上验证这一点。如果 $\\operatorname{rank}(A)  n$，则将此唯一性指标设置为布尔值 $False$。\n4. 对所有近似比较使用绝对容差 $t = 10^{-10}$，如果需要进行任何角度计算（此处未明确要求），请使用弧度。\n5. 将您的程序应用于以下矩阵测试套件，每个矩阵都指定为行列表（其中元素为实数）；对于每个矩阵，$m \\ge n$：\n   - 测试 $1$：$A \\in \\mathbb{R}^{6 \\times 4}$，\n     $$\n     A = \\begin{bmatrix}\n     2  -1  0  3\\\\\n     0  4  1  -2\\\\\n     1  2  0  0\\\\\n     3  -3  5  1\\\\\n     0  2  -1  4\\\\\n     1  0  2  -1\n     \\end{bmatrix}.\n     $$\n   - 测试 $2$：$A \\in \\mathbb{R}^{4 \\times 4}$（具有不同节点的范德蒙型矩阵），\n     $$\n     A = \\begin{bmatrix}\n     1  1  1  1\\\\\n     1  2  4  8\\\\\n     1  3  9  27\\\\\n     1  4  16  64\n     \\end{bmatrix}.\n     $$\n   - 测试 $3$：$A \\in \\mathbb{R}^{5 \\times 3}$，列线性相关（秩为 $2$），\n     $$\n     A = \\begin{bmatrix}\n     1  0  1\\\\\n     0  1  1\\\\\n     2  1  3\\\\\n     0  3  3\\\\\n     1  0  1\n     \\end{bmatrix}.\n     $$\n   - 测试 $4$：$A \\in \\mathbb{R}^{3 \\times 1}$（单非零列），\n     $$\n     A = \\begin{bmatrix}\n     3\\\\\n     4\\\\\n     0\n     \\end{bmatrix}.\n     $$\n   - 测试 $5$：$A \\in \\mathbb{R}^{7 \\times 5}$，\n     $$\n     A = \\begin{bmatrix}\n     1  0  2  1  -1\\\\\n     0  1  1  -1  2\\\\\n     2  1  0  3  1\\\\\n     1  -1  3  0  2\\\\\n     0  2  -1  1  1\\\\\n     3  0  1  2  0\\\\\n     1  1  1  1  1\n     \\end{bmatrix}.\n     $$\n6. 对每个测试用例，按顺序生成一个包含三个布尔值的列表：标准正交性检查、上三角性检查、如上定义的唯一性检查。将所有测试用例的结果汇总到单行输出中，该输出包含这些三布尔值列表的逗号分隔列表，并用方括号括起来。例如，最终输出必须类似于\n   $$\n   [ [b_{1,1}, b_{1,2}, b_{1,3}], [b_{2,1}, b_{2,2}, b_{2,3}], \\dots ]\n   $$\n   但打印在单行中，不含任何额外文本。这里的每个 $b_{i,j}$ 均为字面量 $True$ 或 $False$。\n\n您的实现应是数值稳定的，并遵守指定的容差。此构建的预期背景是为了强调正交和标准正交基在压缩感知和稀疏优化中的作用，其中稳定的正交分解用于为列空间形成数值鲁棒的基，并分析满列秩下的可识别性和唯一性属性。此问题不涉及任何物理单位。如果使用任何三角函数运算，角度应以弧度为单位。", "solution": "对于一个矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\ge n$），构造其正交三角（$QR$）分解是数值线性代数中的一项基本任务。期望的分解形式为 $A = QR$，其中 $Q \\in \\mathbb{R}^{m \\times n}$ 具有标准正交列（即 $Q^\\top Q = I_n$），$R \\in \\mathbb{R}^{n \\times n}$ 是一个上三角矩阵。该解决方案是通过实现 Householder 反射方法来开发的，并遵循了问题陈述中概述的原则。\n\n### 基于原则的算法设计\n\n该算法基于以下核心原则进行设计：\n\n1.  **通过正交变换进行分解**：核心思想是找到一系列正交矩阵 $H_0, H_1, \\dots, H_{n-1}$，当它们应用于 $A$ 时，会逐步在主对角线下方引入零，将 $A$ 转换为上梯形形式。\n    $$\n    R_{m \\times n} = H_{n-1} \\dots H_1 H_0 A\n    $$\n    由于每个 $H_j$ 都是正交的（$H_j^\\top H_j = I$），它们的乘积也是正交的。完整的正交矩阵 $Q_{m \\times m}$ 由反射本身的乘积给出，因为 $H_j = H_j^{-1} = H_j^\\top$。\n    $$\n    A = (H_0 H_1 \\dots H_{n-1}) R_{m \\times n}\n    $$\n    令 $Q_{full} = H_0 H_1 \\dots H_{n-1}$，我们有 $A = Q_{full} R_{m \\times n}$。“瘦”QR 分解是通过取 $Q_{full}$ 的前 $n$ 列构成 $Q \\in \\mathbb{R}^{m \\times n}$，并取 $R_{m \\times n}$ 的前 $n$ 行构成 $R \\in \\mathbb{R}^{n \\times n}$ 来获得的。\n\n2.  **Householder 反射**：每个变换 $H_j$ 都是一个 Householder 反射。对于给定的非零向量 $x$，Householder 反射可以将其映射到一个与标准基向量（如 $e_1$）平行的向量。该反射是关于一个与向量 $u$ 正交的超平面进行的。变换矩阵为 $P = I - 2 \\frac{u u^\\top}{u^\\top u}$。对于向量 $x \\in \\mathbb{R}^k$，为了将其映射到 $e_1 \\in \\mathbb{R}^k$ 的一个倍数，为保证数值稳定性，反射向量 $u$ 的选择如下：\n    $$\n    u = x + \\text{sign}(x_1) \\|x\\|_2 e_1\n    $$\n    其中 $x_1$ 是 $x$ 的第一个分量。当 $x$ 近似平行于 $e_1$ 时，这种选择可以避免相减造成的精度损失。该变换将 $x$ 映射到 $-\\text{sign}(x_1) \\|x\\|_2 e_1$。\n\n3.  **算法实现**：该实现包括两个主要阶段：\n    -   **阶段 1：将 $A$ 三角化为 $R$**：算法从 $j = 0$ 迭代到 $n-1$。在每次迭代 $j$ 中，我们考虑子列向量 $x = A_j[j:m, j]$，其中 $A_j$ 是经过 $j$ 次反射后的矩阵。我们计算相应的 Householder 向量 $v_j$（$u$ 的归一化版本），其大小为 $m-j$。此反射应用于子矩阵 $A_j[j:m, j:n]$，以将第 $j$ 列对角线下方的元素清零。计算出的 Householder 向量 $\\{v_j\\}_{j=0}^{n-1}$ 被存储起来。\n    -   **阶段 2：构造 $Q$**：完整的正交矩阵 $Q_{full} \\in \\mathbb{R}^{m \\times m}$ 是通过将变换应用于单位矩阵 $I_m$ 来构造的。由于 $Q_{full} = H_0 H_1 \\dots H_{n-1}$，这些变换的应用顺序可能与直觉相反：$Q_{full} = H_0(H_1(\\dots(H_{n-1}I_m)\\dots))$。实现从 $Q=I_m$ 开始，并相继应用反射 $H_{n-1}, \\dots, H_0$。在步骤 $j$（从 $n-1$ 向下迭代到 $0$），由 $v_j$ 定义的反射被应用于当前 $Q$ 矩阵的第 $j$ 行到第 $m-1$ 行。在所有反射都应用完毕后，提取前 $n$ 列作为瘦矩阵 $Q \\in \\mathbb{R}^{m \\times n}$。\n\n4.  **唯一性与规范化**：对于一个满秩矩阵 $A$，如果 $R$ 的对角线元素受到限制（例如，为正数），则 QR 分解是唯一的。问题要求一个约定，即对于所有 $R_{jj}$ 非零的 $j$，$R_{jj} \\ge 0$。我们稳定的 Householder 实现产生的对角线元素 $R_{jj}$ 可能为负。一个后处理步骤会检查 $R$ 对角线元素的符号。如果 $R_{jj}  0$，则将 $R$ 的第 $j$ 行和 $Q$ 的第 $j$ 列乘以 $-1$。此操作保持了乘积 $A = QR$ 不变，因为对于对角符号矩阵 $D$ 且 $D=D^{-1}$，有 $(Q D)(D^{-1} R) = Q R$。\n\n5.  **验证逻辑**：\n    -   **标准正交性**：通过检查 $Q^\\top Q$ 是否接近单位矩阵 $I_n$ 来验证，具体为 $\\max_{i,j} |(Q^\\top Q - I_n)_{ij}| \\le t$（容差 $t=10^{-10}$）。\n    -   **上三角性**：通过确保 $R$ 中所有严格位于主对角线下方的元素的绝对值不大于 $t$ 来验证。\n    -   **唯一性**：$R$ 的唯一性（在非负对角线约定下）当且仅当 $A$ 具有满列秩时成立。我们首先通过计算 $A$ 的奇异值来评估其秩。如果最小奇异值大于容差 $t$，则认为矩阵是满秩的。如果是，则使用一个不同的、可信的库函数（`scipy.linalg.qr`）计算一个参考分解 $(\\tilde{Q}, \\tilde{R})$。在对 $\\tilde{R}$ 强制执行相同的非负对角线约定后，我们检查 $R$ 是否在容差 $t$ 内与 $\\tilde{R}$ 逐元素近似相等。如果 $A$ 不是满秩的，则唯一性检查结果为 `False`。\n\n这种结构化的、基于原则的方法确保了 Householder QR 分解的正确和数值稳定的实现，并完成了问题所要求的验证。", "answer": "```python\n# The final stand-alone Python code for the problem.\nimport numpy as np\nfrom scipy.linalg import qr as scipy_qr\n\ndef householder_qr(A, tol=1e-10):\n    \"\"\"\n    Computes the thin QR factorization of a matrix A using Householder reflections.\n    A = QR, where Q is m x n with orthonormal columns and R is n x n upper triangular.\n    This function is built from first principles and does not use a library QR function.\n    \"\"\"\n    A_work = A.copy().astype(np.float64)\n    m, n = A_work.shape\n    \n    householder_vectors = []\n\n    # Phase 1: Transform A to R, storing Householder vectors.\n    for j in range(n):\n        x = A_work[j:, j]\n        norm_x = np.linalg.norm(x)\n        \n        if norm_x  tol:\n            # Column is (close to) zeroed out, no reflection needed.\n            v = np.zeros_like(x)\n            householder_vectors.append(v)\n            continue\n            \n        sign_x0 = np.copysign(1.0, x[0]) if x[0] != 0 else 1.0\n        \n        # Standard numerically stable choice for Householder vector u.\n        u = x.copy()\n        u[0] += sign_x0 * norm_x\n        \n        norm_u = np.linalg.norm(u)\n        if norm_u  tol:\n            # If u is zero vector, reflection is identity.\n            v = np.zeros_like(u)\n        else:\n            v = u / norm_u\n        \n        householder_vectors.append(v)\n        \n        # Apply reflection P = I - 2*v*v^T to the remaining submatrix of A.\n        # P * B = B - 2 * v * (v^T * B)\n        sub_matrix = A_work[j:, j:]\n        A_work[j:, j:] = sub_matrix - 2 * np.outer(v, v.T @ sub_matrix)\n        \n    R = A_work[:n, :]\n\n    # Phase 2: Form Q by applying reflections to the identity matrix.\n    # Q = H_0 * H_1 * ... * H_{n-1}. We apply them backwards to Identity.\n    Q = np.eye(m, dtype=np.float64)\n    for j in range(n - 1, -1, -1):\n        v = householder_vectors[j]\n        if np.linalg.norm(v)  tol:\n            continue\n            \n        # Apply P_j to the relevant submatrix of Q.\n        # Q_new = H_j * Q_old = P_j applies to rows j..m of Q_old.\n        sub_Q = Q[j:, :]\n        Q[j:, :] = sub_Q - 2 * np.outer(v, v.T @ sub_Q)\n        \n    return Q[:, :n], R\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    t = 1e-10\n\n    test_cases = [\n        np.array([\n            [2, -1, 0, 3], [0, 4, 1, -2], [1, 2, 0, 0], \n            [3, -3, 5, 1], [0, 2, -1, 4], [1, 0, 2, -1]\n        ], dtype=float),\n        np.array([\n            [1, 1, 1, 1], [1, 2, 4, 8], [1, 3, 9, 27], [1, 4, 16, 64]\n        ], dtype=float),\n        np.array([\n            [1, 0, 1], [0, 1, 1], [2, 1, 3], [0, 3, 3], [1, 0, 1]\n        ], dtype=float),\n        np.array([\n            [3], [4], [0]\n        ], dtype=float),\n        np.array([\n            [1, 0, 2, 1, -1], [0, 1, 1, -1, 2], [2, 1, 0, 3, 1],\n            [1, -1, 3, 0, 2], [0, 2, -1, 1, 1], [3, 0, 1, 2, 0],\n            [1, 1, 1, 1, 1]\n        ], dtype=float)\n    ]\n    \n    results = []\n    \n    for A in test_cases:\n        m, n = A.shape\n        \n        # 1. Construct QR factorization using the custom Householder function.\n        Q, R = householder_qr(A, tol=t)\n        \n        # 2. Enforce nonnegative diagonals on R.\n        for j in range(n):\n            if R[j, j]  0 and abs(R[j, j]) > t:\n                R[j, :] *= -1\n                Q[:, j] *= -1\n        \n        # 3. Perform verification checks.\n        \n        # Check 1: Orthonormality of Q (Q^T * Q approx I_n).\n        ortho_check = np.allclose(Q.T @ Q, np.eye(n), atol=t, rtol=0) if n > 0 else True\n\n        # Check 2: Upper triangularity of R.\n        tri_check = np.max(np.abs(np.tril(R, k=-1))) = t if n > 0 else True\n\n        # Check 3: Uniqueness of R (if A has full column rank).\n        # Determine rank by checking singular values.\n        singular_values = np.linalg.svd(A, compute_uv=False)\n        rank_is_full = (n == 0) or (len(singular_values) >= n and singular_values[n-1] > t)\n        \n        if rank_is_full:\n            # Compute a reference QR factorization using a distinct method.\n            Q_ref, R_ref = scipy_qr(A, mode='economic')\n            \n            # Enforce nonnegative diagonals on the reference factorization.\n            for j in range(n):\n                if R_ref[j, j]  0 and abs(R_ref[j, j]) > t:\n                    R_ref[j, :] *= -1\n                    Q_ref[:, j] *= -1\n            \n            # Compare our R with the reference R.\n            uniqueness_check = np.allclose(R, R_ref, atol=t, rtol=0)\n        else:\n            uniqueness_check = False\n            \n        results.append([ortho_check, tri_check, uniqueness_check])\n\n    # 4. Format and print the final output as a single-line string.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3464402"}, {"introduction": "在压缩感知理论中，测量矩阵的“质量”通常通过其受限等距性质 (Restricted Isometry Property, RIP) 来量化，这是确保稀疏信号能够被稳定恢复的关键。本练习提供了一种直接的计算方法来揭示这一抽象概念的内涵。您将通过为离散傅里叶变换 (DFT) 矩阵的子集计算精确的RIP常数，从而获得对这一核心性质具体行为的直观理解 [@problem_id:3464411]。", "problem": "设 $A \\in \\mathbb{C}^{m \\times n}$ 是一个测量算子，其行向量标准正交，即 $A A^{\\ast} = I_m$，其中 $A^{\\ast}$ 表示共轭转置，$I_m$ 是 $m \\times m$ 的单位矩阵。阶数为 $s$ 的有限等距性质 (Restricted Isometry Property, RIP) 常数，记为 $\\delta_s$，定义为最小的 $\\delta \\in [0,1]$，使得对于所有 $s$-稀疏向量 $x \\in \\mathbb{C}^n$ (即最多有 $s$ 个非零项的向量)，满足\n$$(1 - \\delta)\\,\\|x\\|_2^2 \\le \\|A x\\|_2^2 \\le (1 + \\delta)\\,\\|x\\|_2^2.$$\n仅从这些定义和事实出发，不假设任何超出这些范畴的专门公式，实现一个程序，为几个具体的玩具示例计算 $\\delta_s$ 的精确值，并利用这些计算出的值来支持一个关于 $\\delta_s$ 如何随 $m$ 和 $n$ 变化的简短讨论（在您的推理中，而非在程序输出中）。\n\n您必须使用以下具体的玩具算子族 $A$：对于每对 $(m,n)$，令 $F_n \\in \\mathbb{C}^{n \\times n}$ 为酉离散傅里叶变换 (DFT) 矩阵，其元素为\n$$ (F_n)_{k,j} \\;=\\; \\frac{1}{\\sqrt{n}} \\exp\\!\\left( - 2 \\pi i \\frac{k j}{n} \\right), \\quad 0 \\le k,j \\le n-1.$$\n令 $R \\subset \\{0,1,\\dots,n-1\\}$ 为一个大小为 $m$ 的索引集，其中列出了不同的行索引。定义 $A$ 为通过选择 $F_n$ 中由 $R$ 索引的行而形成的 $m \\times n$ 矩阵。这种构造保证了 $A$ 的行是标准正交的。\n\n任务：对于下述每个测试用例，计算指定列表中每个 $s$ 的精确 $\\delta_s$ 值。“精确”在这里指与上述定义一致的、真正的最小化 $\\delta_s$，而不是启发式或概率性估计。\n\n测试套件：\n- 情形 1：$n = 8$, $R = \\{0,1,2,3\\}$，且 $s \\in \\{1,2,3\\}$。\n- 情形 2：$n = 8$, $R = \\{0,2,4\\}$，且 $s \\in \\{1,2,3\\}$。\n- 情形 3：$n = 8$, $R = \\{0,4\\}$，且 $s \\in \\{1,2,3\\}$。\n- 情形 4：$n = 12$, $R = \\{0,1,2,3\\}$，且 $s \\in \\{1,2,3\\}$。\n- 情形 5：$n = 8$, $R = \\{0,1,2,3,4,5,6,7\\}$，且 $s \\in \\{1,2,3\\}$。\n\n要求与限制：\n- 您的计算必须忠实于 $\\delta_s$ 的定义，因此必须对所有支撑集大小至多为 $s$ 的 $s$-稀疏向量 $x$ 都是正确的。除了行的标准正交性和 $A$ 作为部分离散傅里叶变换 (DFT) 的定义外，不要假设任何特殊结构。\n- 如果出现角度，应以弧度为单位解释；但是，规定的构造和输出是无单位的，因此不需要物理单位。\n- 最终输出必须是单行，包含用方括号括起来的逗号分隔列表形式的结果。具体来说，您的程序应输出一个列表的列表，每个子列表对应一个测试用例，其中每个子列表按该用例给定的 $s$ 值的顺序包含 $[\\delta_{s_1}, \\delta_{s_2}, \\dots]$ 值。每个浮点值必须四舍五入到六位小数。例如，包含两个用例的输出可能看起来像 $[[0.125000,0.250000],[0.500000,0.750000]]$。\n\n覆盖范围理据：\n- 集合 $s=\\{1,2,3\\}$ 覆盖了基准情形 $s=1$ 和小的多稀疏情形。\n- 情形 3 中 $m=2$ 且 $s=3$ 探讨了 $sm$ 时的边界现象，这在有限等距性质 (RIP) 分析中非常重要。\n- 情形 1 和 5 对比了相同 $n$ 下的部分和完全酉采样，阐明了将 $m$ 增加到 $n$ 如何影响 $\\delta_s$。\n- 情形 4 改变了 $n$，以在固定 $m$ 的情况下考察随环境维度变化的缩放规律。\n\n您的程序应生成单行输出，其中包含如上所述的、用方括号括起来的逗号分隔列表形式的结果（例如 $[[\\delta_{1},\\delta_{2},\\delta_{3}],\\dots]$）。不应打印任何额外的文本或格式。", "solution": "我们从有限等距性质 (RIP) 常数 $\\delta_s$ 的定义开始。对于一个矩阵 $A \\in \\mathbb{C}^{m \\times n}$ 和一个稀疏度 $s \\in \\mathbb{N}$，RIP 常数 $\\delta_s$ 是使得下式成立的最小 $\\delta \\in [0,1]$：\n$$(1 - \\delta)\\,\\|x\\|_2^2 \\le \\|A x\\|_2^2 \\le (1 + \\delta)\\,\\|x\\|_2^2 \\quad \\text{对于所有 $s$-稀疏向量 } x \\in \\mathbb{C}^n.$$\n令 $S \\subset \\{1,2,\\dots,n\\}$ 为一个大小为 $t \\le s$ 的索引集，并用 $A_S$ 表示由 $A$ 中索引为 $S$ 的列组成的 $m \\times t$ 子矩阵。对于支撑集在 $S$ 上的向量 $x$，我们可以用 $x_S \\in \\mathbb{C}^t$ 表示其非零项，并且有\n$$ \\|A x\\|_2^2 \\;=\\; \\|A_S x_S\\|_2^2 \\;=\\; x_S^{\\ast} (A_S^{\\ast} A_S) x_S.$$\n令 $G_S := A_S^{\\ast} A_S \\in \\mathbb{C}^{t \\times t}$ 表示与子集 $S$ 相关联的格拉姆矩阵 (Gram matrix)；$G_S$ 是厄米半正定的 (Hermitian positive semidefinite)。瑞利商 (Rayleigh quotient) 的刻画意味着对于所有非零的 $x_S$，\n$$ \\lambda_{\\min}(G_S) \\,\\|x_S\\|_2^2 \\;\\le\\; x_S^{\\ast} G_S x_S \\;\\le\\; \\lambda_{\\max}(G_S)\\, \\|x_S\\|_2^2,$$\n其中 $\\lambda_{\\min}(G_S)$ 和 $\\lambda_{\\max}(G_S)$ 分别是 $G_S$ 的最小和最大特征值。因此，$\\delta_s$ 的定义等价于要求对于所有 $|S|\\le s$ 的 $S$ 同时满足\n$$ 1 - \\delta_s \\;\\le\\; \\lambda_{\\min}(G_S) \\;\\le\\; \\lambda_{\\max}(G_S) \\;\\le\\; 1 + \\delta_s.$$\n由此可得\n$$ \\delta_s \\;=\\; \\max_{\\substack{S \\subset \\{1,\\dots,n\\} \\\\ |S| \\le s}} \\max\\!\\Big\\{\\, 1 - \\lambda_{\\min}(G_S),\\; \\lambda_{\\max}(G_S) - 1 \\,\\Big\\}.$$\n这个恒等式是 RIP 定义和二次型的谱刻画的直接推论，这些都是基础的线性代数事实。特别地，当 $A$ 的行是标准正交的，即 $A A^{\\ast} = I_m$ 时， $A$ 的算子范数满足 $\\|A\\|_{2 \\to 2} \\le 1$。因此，对于每个子集 $S$ 和每个向量 $x_S$，我们有 $\\|A_S x_S\\|_2 \\le \\|x_S\\|_2$，这意味着 $\\lambda_{\\max}(G_S) \\le 1$。因此，对于这样的 $A$，主要的偏差是 $1 - \\lambda_{\\min}(G_S)$，且 $\\delta_s = \\max_{|S|\\le s} (1 - \\lambda_{\\min}(G_S))$。尽管如此，直接计算 $\\max\\{1 - \\lambda_{\\min}, \\lambda_{\\max} - 1\\}$ 是正确且数值安全的。\n\n算法设计。对于每个测试用例，我们构造 $A$ 为一个部分离散傅里叶变换 (DFT)，即 $A = R F_n$，其中 $F_n$ 是酉矩阵，其元素为 $(F_n)_{k,j} = \\frac{1}{\\sqrt{n}}\\exp\\!\\big(- 2 \\pi i \\frac{k j}{n}\\big)$，$R$ 选择指定的行。对于任意给定的 $s_{\\max}$，我们枚举所有大小为 $t = 1,2,\\dots,s_{\\max}$ 的列子集 $S$，形成每个格拉姆矩阵 $G_S = A_S^{\\ast} A_S$，计算其极值特征值，并累积最坏情况下的偏差 $\\max\\{1 - \\lambda_{\\min}(G_S), \\lambda_{\\max}(G_S) - 1\\}$。每个 $s$ 的精确 $\\delta_s$ 是这些偏差在所有 $t \\le s$ 上的最大值。由于每个 $G_S$ 都是厄米矩阵，我们使用针对厄米矩阵的特征值求解器来稳健地获得 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$。\n\n正确性论证。该计算完全遵循了上述通过谱界得到的 RIP 定义。由于每个 $s$-稀疏向量的支撑集 $S$ 的大小 $|S|\\le s$，枚举所有这样的支撑集并应用 $G_S$ 上的极值瑞利商，可以捕获与等距性的精确最坏情况偏差。对于行标准正交的矩阵，对所有 $S$ 都有 $\\lambda_{\\max}(G_S) \\le 1$，所以下谱边缘控制着 $\\delta_s$，但我们的实现计算了两个边缘以保持通用性和数值稳定性。\n\n基于第一性原理的缩放规律洞察。在部分 DFT 构造中，$F_n$ 的每个元素的模为 $1/\\sqrt{n}$。选择 $m$ 行得到的列向量的平方范数恰好为 $m/n$，因此对于 $s=1$，\n$$ \\delta_1 \\;=\\; \\max_{j} \\big| \\|A e_j\\|_2^2 - 1 \\big| \\;=\\; \\big| \\tfrac{m}{n} - 1 \\big| \\;=\\; 1 - \\tfrac{m}{n},$$\n当 $m$ 增加到 $n$ 时，这个值线性减小到 $0$。对于更高的 $s$，格拉姆矩阵的非对角线元素是模至多为 $m/n$ 的复指数的部分和，因此相干性约为 $m/n$ 的量级。格什戈林型 (Gershgorin-type) 推理则表明，对于小的 $s$，特征值偏差的缩放规律类似于 $1 - \\tfrac{m}{n} + \\mathcal{O}(s \\tfrac{m}{n})$，它随着 $m$ 的增加（固定 $n$）而减小，并随着 $n$ 的增加（固定 $m$）而增加。当 $s > m$ 时，存在 $A$ 的零空间中的非零 $s$-稀疏向量，因此 $\\delta_s$ 必须至少为 $1$ 以满足 $(1 - \\delta_s) \\|x\\|_2^2 \\le 0$，因此在该区域 $\\delta_s = 1$。反之，当 $m = n$（完全 DFT）时，$A$ 是酉矩阵，对于所有 $s \\le n$，$\\delta_s = 0$。\n\n该程序为指定的测试套件实现了上述的精确计算，并将结果打印为单行，其中包含一个列表的列表，每个内部列表对应一个测试用例的 $\\delta_s$ 值，每个浮点值四舍五入到六位小数。", "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef dft_matrix(n: int) - np.ndarray:\n    \"\"\"\n    Construct the n x n unitary Discrete Fourier Transform (DFT) matrix F_n\n    with entries (F_n)_{k,j} = (1/sqrt(n)) * exp(-2*pi*i*k*j/n).\n    \"\"\"\n    k = np.arange(n).reshape(-1, 1)\n    j = np.arange(n).reshape(1, -1)\n    omega = np.exp(-2j * np.pi * (k @ j) / n)\n    return omega / np.sqrt(n)\n\n\ndef build_partial_dft(n: int, rows: list[int]) - np.ndarray:\n    \"\"\"\n    Build the m x n partial DFT matrix by selecting the given rows from F_n.\n    \"\"\"\n    F = dft_matrix(n)\n    return F[rows, :]\n\n\ndef subset_eigen_deviation(A: np.ndarray, cols: tuple[int, ...]) - float:\n    \"\"\"\n    For a given subset of columns 'cols', compute the deviation\n    max{1 - lambda_min, lambda_max - 1} where eigenvalues are of G_S = A_S^* A_S.\n    \"\"\"\n    A_S = A[:, cols]\n    # Gram matrix G_S\n    G = A_S.conj().T @ A_S\n    # Ensure Hermitian numerical symmetry\n    G = (G + G.conj().T) / 2.0\n    # Eigenvalues of Hermitian matrix\n    evals = np.linalg.eigvalsh(G)\n    lam_min = float(np.min(evals).real)\n    lam_max = float(np.max(evals).real)\n    # Numerical safeguarding\n    if lam_min  0 and lam_min > -1e-12:\n        lam_min = 0.0\n    if lam_max  1 and lam_max > 1 - 1e-12:\n        lam_max = 1.0\n    dev = max(1.0 - lam_min, lam_max - 1.0)\n    # Clamp tiny negatives to zero\n    if dev  0 and dev > -1e-12:\n        dev = 0.0\n    # Theoretical upper bound for orthonormal-row A is 1.0\n    if dev > 1.0 and dev  1.0 + 1e-9:\n        dev = 1.0\n    return float(dev)\n\n\ndef compute_delta_s_exact(A: np.ndarray, s_values: list[int]) - list[float]:\n    \"\"\"\n    Compute exact RIP constants delta_s for all s in s_values, using the definition:\n    delta_s = max_{|S| = s} max{1 - lambda_min(G_S), lambda_max(G_S) - 1},\n    where G_S = A_S^* A_S.\n    \"\"\"\n    n = A.shape[1]\n    s_max = max(s_values)\n    # Initialize maxima for each s from 1..s_max\n    deltas = [0.0 for _ in range(s_max + 1)]  # index by s, ignore index 0\n\n    # Enumerate subsets by size t = 1..s_max\n    for t in range(1, s_max + 1):\n        for cols in combinations(range(n), t):\n            dev = subset_eigen_deviation(A, cols)\n            # Update for all s >= t (since supports of size = s)\n            for s in range(t, s_max + 1):\n                if dev > deltas[s]:\n                    deltas[s] = dev\n\n    # Extract requested s_values and round to 6 decimals\n    result = [round(deltas[s], 12) for s in s_values]  # keep higher precision before formatting\n    return result\n\n\ndef format_results_nested(results: list[list[float]]) - str:\n    \"\"\"\n    Format a list of lists of floats into a single-line string with each float\n    rounded to six decimal places, e.g., [[0.123456,0.234567],[...],...]\n    \"\"\"\n    inner_strs = []\n    for lst in results:\n        nums = \",\".join(f\"{x:.6f}\" for x in lst)\n        inner_strs.append(f\"[{nums}]\")\n    return f\"[{','.join(inner_strs)}]\"\n\n\ndef solve():\n    # Define the test cases:\n    # Each case: (n, rows, s_values)\n    test_cases = [\n        (8,  [0, 1, 2, 3], [1, 2, 3]),          # Case 1\n        (8,  [0, 2, 4],    [1, 2, 3]),          # Case 2\n        (8,  [0, 4],       [1, 2, 3]),          # Case 3 (includes s = m + 1 edge behavior)\n        (12, [0, 1, 2, 3], [1, 2, 3]),          # Case 4\n        (8,  list(range(8)), [1, 2, 3])         # Case 5 (full unitary)\n    ]\n\n    results = []\n    for n, rows, s_values in test_cases:\n        A = build_partial_dft(n, rows)\n        # Sanity check: orthonormal rows within numerical tolerance\n        # Not printed, but could be used internally if needed\n        deltas = compute_delta_s_exact(A, s_values)\n        results.append(deltas)\n\n    print(format_results_nested(results))\n\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3464411"}, {"introduction": "虽然理想的系统拥有完美的正交性，但实际应用中的字典或基通常会表现出一定程度的相关性，这种相关性可以通过互相关性 (mutual coherence) 来衡量。本实践旨在探究这种“不完美”所带来的实际后果。您将通过模拟正交匹配追踪 (Orthogonal Matching Pursuit, OMP) 算法，并观察其恢复性能如何随着字典互相关性的增加而系统性地下降，从而建立起理论性质与算法行为之间的直接联系 [@problem_id:3464443]。", "problem": "您必须编写一个完整、可运行的程序，该程序构造具有近乎标准正交列的显式字典，对固定的稀疏信号运行正交匹配追踪（OMP），并量化残差相关性如何随着互相关性的增加而变化。分析必须基于压缩感知和稀疏优化的基本定义。具体来说，使用互相关性的定义、字典的单位范数列假设以及正交匹配追踪（OMP）的选择规则。目标是衡量当字典偏离标准正交基时，残差与已选原子以及真假原子之间的相关性如何变化，并将这些经验行为与正确支撑集选择的互相关性充分条件进行比较。\n\n必须使用的定义：\n- 字典是一个矩阵 $D \\in \\mathbb{R}^{m \\times n}$，其列 $\\{d_j\\}_{j=1}^n$ 是单位范数的，即对于所有 $j$，$\\|d_j\\|_2 = 1$。\n- $D$ 的互相关性为 $\\mu(D) = \\max_{i \\neq j} |\\langle d_i, d_j \\rangle|$，其中 $\\langle \\cdot, \\cdot \\rangle$ 表示标准内积。\n- 正交匹配追踪（OMP）以残差 $r_0 = y$ 开始，并迭代选择一个索引 $j_t$，该索引在尚未选择的索引中最大化 $|\\langle d_{j}, r_{t-1} \\rangle|$。选择索引后，OMP 通过最小二乘法在所选集合上重新拟合系数，产生新的残差 $r_t = y - D_{S_t} x_{S_t}^{\\text{LS}}$，其中 $S_t$ 是已选索引的集合，$x_{S_t}^{\\text{LS}}$ 表示最小二乘解。在精确计算中，正规方程可得 $D_{S_t}^\\top r_t = 0$。\n\n程序要求：\n1. 构造具有 $m = n$ 和单位范数列的字典 $D$。从 $\\mathbb{R}^n$ 中的标准基开始，并在选定的列对之间引入受控的成对相互作用。对于指定的对 $(p,q)$，替换列为 $d_p \\leftarrow \\frac{e_p + \\varepsilon e_q}{\\|e_p + \\varepsilon e_q\\|_2}$ 和 $d_q \\leftarrow \\frac{e_q + \\varepsilon e_p}{\\|e_q + \\varepsilon e_p\\|_2}$，其中 $e_j$ 表示第 $j$ 个标准基向量，$\\varepsilon \\ge 0$ 是一个小的实数。所有其他列必须保持为 $e_j$，并且所有列都必须重新归一化为单位范数。\n2. 对于每个测试用例，构建一个 $k$-稀疏信号 $x \\in \\mathbb{R}^n$，其在指定的支撑集 $T \\subset \\{0,1,\\dots,n-1\\}$ 上恰好有 $k$ 个非零项等于 $1$，并计算无噪声测量值 $y = D x$。\n3. 实现正交匹配追踪（OMP）算法，迭代 $k$ 次，使用标准选择规则 $j_t = \\arg\\max_{j \\notin S_{t-1}} |\\langle d_j, r_{t-1} \\rangle|$ 和残差更新 $r_t = y - D_{S_t} x_{S_t}^{\\text{LS}}$（使用在所选列上的最小二乘法）。确保索引不会被重复选择。\n4. 对于每次迭代 $t$，计算以下量：\n   - 相对于已选集合的残差正交性缺陷，定义为 $\\delta_t = \\max_{j \\in S_t} |\\langle d_j, r_t \\rangle|$。在精确计算中，$\\delta_t = 0$，但数值计算会引入非零值。将此总结为所有迭代中的 $\\delta_{\\max} = \\max_t \\delta_t$。\n   - 真假相关性余量，在每次迭代 $t$ 定义为 $\\rho_t = \\left( \\max_{j \\in T \\setminus S_t} |\\langle d_j, r_t \\rangle| \\right) - \\left( \\max_{j \\notin T} |\\langle d_j, r_t \\rangle| \\right)$，限定于 $T \\setminus S_t \\neq \\emptyset$ 的迭代。将此总结为在这些迭代中的 $\\rho_{\\min} = \\min_t \\rho_t$。负的 $\\rho_{\\min}$ 表示在某次迭代中，最大的相关性属于一个假原子，这有错误选择的风险。\n5. 通过成对列内积，根据字典经验性地计算互相关性 $\\mu(D)$。\n6. 与经典互相关性充分条件进行比较，该条件用于具有等幅非零值的信号的精确支撑集选择，即如果 $\\mu(D)  \\frac{1}{2k - 1}$，则 OMP 在每一步都会选择一个正确的原子。计算阈值 $\\tau = \\frac{1}{2k - 1}$ 并报告最终选择的支撑集是否等于真实支撑集，即 $S_k = T$ 是否成立。\n\n测试套件：\n使用 $m = n = 32$ 并考虑以下四种情况，每种情况由 $(\\varepsilon, \\text{pairs}, k, T)$ 指定：\n- 情况 A (标准正交基线): $\\varepsilon = 0$, $\\text{pairs} = \\{(0,1),(2,3)\\}$, $k = 3$, $T = \\{0,2,5\\}$。\n- 情况 B (顺利路径，小互相关性): $\\varepsilon = 0.05$, $\\text{pairs} = \\{(0,1),(2,3)\\}$, $k = 3$, $T = \\{0,2,5\\}$。\n- 情况 C (接近互相关性阈值): $\\varepsilon = 0.1$, $\\text{pairs} = \\{(0,1),(2,3)\\}$, $k = 3$, $T = \\{0,2,5\\}$。\n- 情况 D (显著互相关性，可能失败): $\\varepsilon = 0.45$, $\\text{pairs} = \\{(0,1),(2,3)\\}$, $k = 3$, $T = \\{0,2,5\\}$。\n\n对于每种情况，您的程序必须：\n- 构建 $D$，形成 $x$ 和 $y$，运行 OMP 进行 $k$ 次迭代，计算 $\\delta_{\\max}$、$\\rho_{\\min}$、$\\mu(D)$、$\\tau$ 以及一个指示 $S_k = T$ 是否成立的布尔值。\n- 生成单行输出，包含一个结果列表，每种情况一个结果，其中每个情况的结果是列表 $[\\text{success}, \\delta_{\\max}, \\mu(D), \\tau, \\rho_{\\min}]$。最终打印的行必须是严格用方括号括起来的逗号分隔列表，例如 $[[\\text{True},0.0,0.0,0.2,0.0],[\\dots],\\dots]$。不得打印任何其他文本。", "solution": "用户提供的问题是有效的。它在科学上植根于压缩感知和稀疏优化的原理，定义和参数齐全，问题陈述良好，并且其表述是客观的。\n\n任务是执行一个数值实验，以分析正交匹配追踪（OMP）算法在不同字典互相关性水平下的性能。\n\n分析的核心是观察随着字典偏离标准正交基，OMP 正确识别稀疏信号支撑集的能力如何下降。这种偏离由互相关性 $\\mu(D)$ 来量化，其影响通过残差相关性的演变来衡量。\n\n解决方案分为四个主要阶段：字典构建、信号模拟、OMP 执行和度量计算。\n\n**1. 字典构建**\n\n字典 $D \\in \\mathbb{R}^{n \\times n}$ 是通过在一个初始的标准正交基（由单位矩阵 $I = [e_0, e_1, \\dots, e_{n-1}]$ 表示的标准基）中引入受控的相关性来构建的。对于给定的索引对 $(p, q)$ 和一个扰动参数 $\\varepsilon \\ge 0$，相应的列 $e_p$ 和 $e_q$ 被替换为新的向量，然后进行归一化。新的列 $d_p$ 和 $d_q$ 定义为：\n$$\nd_p = \\frac{e_p + \\varepsilon e_q}{\\|e_p + \\varepsilon e_q\\|_2} \\quad \\text{and} \\quad d_q = \\frac{e_q + \\varepsilon e_p}{\\|e_q + \\varepsilon e_p\\|_2}\n$$\n分母中的范数计算为 $\\|e_j + \\varepsilon e_k\\|_2 = \\sqrt{\\langle e_j + \\varepsilon e_k, e_j + \\varepsilon e_k \\rangle} = \\sqrt{\\|e_j\\|_2^2 + 2\\varepsilon\\langle e_j, e_k \\rangle + \\varepsilon^2\\|e_k\\|_2^2}$。由于 $\\{e_j\\}$ 是标准正交的，这简化为 $\\sqrt{1^2 + 0 + \\varepsilon^2} = \\sqrt{1 + \\varepsilon^2}$。因此，新的列是：\n$$\nd_p = \\frac{1}{\\sqrt{1+\\varepsilon^2}}(e_p + \\varepsilon e_q) \\quad \\text{and} \\quad d_q = \\frac{1}{\\sqrt{1+\\varepsilon^2}}(e_q + \\varepsilon e_p)\n$$\n所有其他列 $d_j$（对于 $j \\notin \\{p, q\\}$）保持为标准基向量 $e_j$。这种构造确保所有列都是单位范数，即 $\\|d_j\\|_2 = 1$。\n\n互相关性 $\\mu(D) = \\max_{i \\neq j} |\\langle d_i, d_j \\rangle|$ 主要由耦合列的内积决定：\n$$\n\\langle d_p, d_q \\rangle = \\left\\langle \\frac{e_p + \\varepsilon e_q}{\\sqrt{1+\\varepsilon^2}}, \\frac{e_q + \\varepsilon e_p}{\\sqrt{1+\\varepsilon^2}} \\right\\rangle = \\frac{1}{1+\\varepsilon^2} \\left( \\langle e_p, e_q \\rangle + \\langle e_p, \\varepsilon e_p \\rangle + \\langle \\varepsilon e_q, e_q \\rangle + \\langle \\varepsilon e_q, \\varepsilon e_p \\rangle \\right) = \\frac{2\\varepsilon}{1+\\varepsilon^2}\n$$\n随着 $\\varepsilon$ 的增加，互相关性也增加，使得字典的列变得不那么正交。当 $\\varepsilon=0$ 时，字典是单位矩阵，且 $\\mu(D)=0$。\n\n**2. 稀疏信号模型**\n\n对于给定的稀疏度 $k$ 和支撑集 $T \\subset \\{0, 1, \\dots, n-1\\}$（其中 $|T|=k$），我们定义一个 $k$-稀疏信号 $x \\in \\mathbb{R}^n$。$x$ 的非零项在支撑集 $T$ 上被设置为 $1$：\n$$\nx_j = \\begin{cases} 1  \\text{if } j \\in T \\\\ 0  \\text{if } j \\notin T \\end{cases}\n$$\n然后合成无噪声测量值 $y = Dx = \\sum_{j \\in T} d_j$。\n\n**3. 正交匹配追踪（OMP）**\n\nOMP 是一种用于稀疏恢复的迭代贪婪算法。它一次一个地识别 $x$ 的支撑集索引。从初始残差 $r_0 = y$ 和空支撑集 $S_0 = \\emptyset$ 开始，它执行 $k$ 次迭代。在迭代 $t = 1, \\dots, k$ 时：\n1.  **原子选择：** 在尚未选择的原子中，找到与当前残差最相关的 $D$ 的列：\n    $$\n    j_t = \\arg\\max_{j \\notin S_{t-1}} |\\langle d_j, r_{t-1} \\rangle|\n    $$\n2.  **支撑集更新：** 将选定的索引添加到支撑集中：$S_t = S_{t-1} \\cup \\{j_t\\}$。\n3.  **信号重构：** 通过最小二乘拟合在当前支撑集 $S_t$ 上重新估计信号系数：\n    $$\n    x_{S_t}^{\\text{LS}} = \\arg\\min_{z \\in \\mathbb{R}^{|S_t|}} \\|y - D_{S_t} z\\|_2^2 = (D_{S_t}^\\top D_{S_t})^{-1} D_{S_t}^\\top y\n    $$\n    其中 $D_{S_t}$ 是由 $S_t$ 索引的列组成的子字典。\n4.  **残差更新：** 将残差更新为 $y$ 在由 $D_{S_t}$ 中的列所张成的子空间上的正交分量：\n    $$\n    r_t = y - D_{S_t} x_{S_t}^{\\text{LS}}\n    $$\n    在精确计算中，这确保了新的残差与所有先前选择的原子正交，即 $D_{S_t}^\\top r_t = 0$。\n\n**4. 性能度量**\n\n为分析算法的行为，在每次迭代 $t$ 中计算以下几个量：\n-   **互相关性阈值 ($\\tau$)：** 对于具有等幅非零项的信号，OMP 在每一步正确识别一个新的支撑集元素的著名充分条件是 $\\mu(D)  \\frac{1}{2k-1}$。我们计算这个阈值为 $\\tau = \\frac{1}{2k-1}$。如果 $\\mu(D)  \\tau$，OMP 保证成功。如果 $\\mu(D) \\ge \\tau$，则不保证成功，失败成为可能。\n-   **残差正交性缺陷 ($\\delta_{\\max}$):** 在实践中，由于浮点数运算，条件 $D_{S_t}^\\top r_t = 0$ 只能近似满足。我们测量所有迭代中的最大偏差：$\\delta_{\\max} = \\max_{t=1,\\dots,k} \\left( \\max_{j \\in S_t} |\\langle d_j, r_t \\rangle| \\right)$。这量化了正交化步骤的数值精度。\n-   **真假相关性余量 ($\\rho_{\\min}$):** OMP 成功的关键在于，残差与下一个正确（真）原子的相关性大于与任何不正确（假）原子的相关性。我们在每一步 $t$ 之后测量这个余量：\n    $$\n    \\rho_t = \\left( \\max_{j \\in T \\setminus S_t} |\\langle d_j, r_t \\rangle| \\right) - \\left( \\max_{j \\notin T} |\\langle d_j, r_t \\rangle| \\right)\n    $$\n    这是在仍有真原子待寻找的迭代中计算的（$T \\setminus S_t \\neq \\emptyset$）。正的 $\\rho_t$ 意味着下一步选择的条件有利于成功。负的 $\\rho_t$ 则表示一个假原子与残差的相关性比任何剩余的真原子都大，预示着下一步选择很可能出错。我们通过 $\\rho_{\\min} = \\min_t \\rho_t$ 来总结这一点。\n-   **成功标志：** 最终的性能度量是最终估计的支撑集 $S_k$ 是否与真实支撑集 $T$ 匹配。\n\n所提供的测试用例旨在探究 OMP 在从理想的标准正交情况（$\\varepsilon=0$）到高互相关性情况（$\\varepsilon=0.45$，其中 $\\mu(D)$ 显著超过理论阈值 $\\tau$）下的性能。通过观察这些度量，特别是 $\\rho_{\\min}$，我们可以将理论条件与算法的实际行为联系起来。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the OMP analysis for all test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (epsilon, pairs_to_correlate, k, True_Support)\n        (0.0,  {(0, 1), (2, 3)}, 3, {0, 2, 5}),  # Case A: Orthonormal baseline\n        (0.05, {(0, 1), (2, 3)}, 3, {0, 2, 5}),  # Case B: Small coherence\n        (0.1,  {(0, 1), (2, 3)}, 3, {0, 2, 5}),  # Case C: Near threshold\n        (0.45, {(0, 1), (2, 3)}, 3, {0, 2, 5}),  # Case D: Significant coherence\n    ]\n\n    m = n = 32\n    results = []\n\n    for case in test_cases:\n        epsilon, pairs, k, T = case\n\n        # 1. Construct the dictionary D\n        D = np.identity(n)\n        e = np.identity(n)\n        norm_factor = np.sqrt(1 + epsilon**2)\n        if epsilon > 0: # Avoid division by zero if epsilon is 0\n            for p, q in pairs:\n                d_p = (e[:, p] + epsilon * e[:, q]) / norm_factor\n                d_q = (e[:, q] + epsilon * e[:, p]) / norm_factor\n                D[:, p] = d_p\n                D[:, q] = d_q\n\n        # 2. Form the sparse signal x and measurements y\n        x = np.zeros(n)\n        x[list(T)] = 1.0\n        y = D @ x\n\n        # 3. Implement OMP and compute metrics\n        S = set()\n        S_list = []\n        r = y.copy()\n        \n        delta_list = []\n        rho_list = []\n        \n        all_indices = set(range(n))\n        false_atom_indices = list(all_indices - T)\n\n        # OMP loop for k iterations\n        for t in range(k):\n            # Selection step (using residual from previous iteration, r_t-1 which is `r`)\n            correlations = np.abs(D.T @ r)\n            \n            # Exclude already selected indices\n            if S:\n                correlations[list(S)] = -1.0\n            \n            j_t = np.argmax(correlations)\n            \n            # Update support set\n            S.add(j_t)\n            S_list.append(j_t)\n            \n            # Least squares refitting\n            D_S = D[:, S_list]\n            try:\n                # Use least squares to find coefficients on the selected support\n                x_S, _, _, _ = np.linalg.lstsq(D_S, y, rcond=None)\n            except np.linalg.LinAlgError:\n                # This should not happen with this problem's setup\n                # but is good practice for singular D_S\n                success = False\n                delta_max = float('nan')\n                rho_min = float('nan')\n                break\n\n            # Update residual (r_t)\n            r = y - D_S @ x_S\n\n            # 4. Compute per-iteration metrics\n            # delta_t: residual orthogonality defect\n            delta_t = np.max(np.abs(D_S.T @ r))\n            delta_list.append(delta_t)\n            \n            # rho_t: true vs false correlation margin\n            unselected_true_indices = T - S\n            if unselected_true_indices:\n                # Correlation with remaining true atoms\n                true_corrs = np.abs(D[:, list(unselected_true_indices)].T @ r)\n                max_true_corr = np.max(true_corrs)\n                \n                # Correlation with all false atoms\n                false_corrs = np.abs(D[:, false_atom_indices].T @ r) if false_atom_indices else np.array([0.0])\n                max_false_corr = np.max(false_corrs) if false_corrs.size > 0 else 0.0\n\n                rho_t = max_true_corr - max_false_corr\n                rho_list.append(rho_t)\n        \n        else: # This block runs if the loop completes without `break`\n            # Summarize metrics\n            delta_max = max(delta_list) if delta_list else 0.0\n            rho_min = min(rho_list) if rho_list else float('inf') # Should not be empty for k > 1\n            success = (S == T)\n\n        # 5. Compute mutual coherence mu(D)\n        G = D.T @ D\n        np.fill_diagonal(G, 0)\n        mu_D = np.max(np.abs(G))\n\n        # 6. Compute mutual coherence threshold tau\n        tau = 1.0 / (2 * k - 1)\n\n        # Append results for this case\n        results.append([success, delta_max, mu_D, tau, rho_min])\n\n    # Final print statement in the exact required format\n    # The format requires python bools to be capitalized, which is default.\n    output_str = \"[\" + \",\".join([\n        f\"[{s},{d:.6e},{m:.6e},{t:.6e},{r:.6e}]\" for s, d, m, t, r in results\n    ]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3464443"}]}