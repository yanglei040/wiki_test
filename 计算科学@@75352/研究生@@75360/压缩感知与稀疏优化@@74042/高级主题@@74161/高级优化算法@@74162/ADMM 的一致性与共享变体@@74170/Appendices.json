{"hands_on_practices": [{"introduction": "在优化算法之前，理解其计算成本至关重要。本练习 [@problem_id:3438216] 将引导您详细分析一致性ADMM单次迭代所需的浮点运算次数（flops）。通过分解局部变量更新和全局一致性步骤，您将为算法的复杂度建立一个精确模型，这是预测性能和识别计算瓶颈的一项关键技能。", "problem": "考虑在压缩感知和稀疏优化中的一个二次损失的一致性公式，其中$N$个代理（agent）持有局部数据矩阵$A_i \\in \\mathbb{R}^{m_i \\times n}$和向量$b_i \\in \\mathbb{R}^{m_i}$，并寻求在一个全局变量$v \\in \\mathbb{R}^{n}$上达成一致。交替方向乘子法（Alternating Direction Method of Multipliers, ADMM）通过求解对称正定线性系统来更新局部变量$x_i \\in \\mathbb{R}^{n}$\n$$\n\\left(A_i^{\\top}A_i + \\rho I\\right)x_i = A_i^{\\top} b_i + \\rho \\left(v - u_i\\right),\n$$\n其中$u_i \\in \\mathbb{R}^{n}$是缩放对偶变量，并通过平均化来更新一致性变量\n$$\nv \\leftarrow \\frac{1}{N}\\sum_{i=1}^{N}\\left(x_i + u_i\\right).\n$$\n假设以下每次迭代的场景和计数模型：\n- $A_i^{\\top}A_i$和$A_i^{\\top}b_i$已离线预先计算并存储，但惩罚参数$\\rho$在每次迭代时都会自适应更新，因此$\\left(A_i^{\\top}A_i + \\rho I\\right)$的Cholesky分解必须在每次迭代中重新计算。\n- 矩阵$A_i^{\\top}A_i + \\rho I$是$n \\times n$维的稠密对称正定矩阵；求解每个系统是通过Cholesky分解，然后进行两次三角求解来完成的。\n- 在标准稠密代价模型下计算浮点运算次数（flops）：每次标量加法或乘法代价为1 flop；将$\\rho$加到对角线上的代价为$n$ flops；一个稠密$n \\times n$对称正定矩阵的Cholesky分解代价为$\\frac{n^{3}}{3}$ flops；每次用一个稠密$n \\times n$三角矩阵和一个稠密$n$维向量进行三角求解的代价为$n^{2}$ flops；构造右侧项$A_i^{\\top}b_i + \\rho(v - u_i)$的代价为$3n$ flops；全局平均步骤$v \\leftarrow \\frac{1}{N}\\sum_{i=1}^{N}(x_i + u_i)$是通过单次遍历将$(x_i + u_i)$累加到$v$中，然后将$v$乘以$\\frac{1}{N}$来计算的，代价为$2Nn + n$ flops。\n\n在这些假设下，计算每次迭代的总浮点运算次数的精确值，以一个关于$N$和$n$的闭式表达式给出，该表达式应包括：\n- 所有$N$个局部$x_i$的更新，包括每个代理的对角线调整、Cholesky分解、右侧项构造和两次三角求解，\n- 加上对$v$的全局平均步骤。\n\n将您的最终答案表示为单个解析表达式。无需四舍五入。不涉及物理单位。答案必须是单个表达式，而不是不等式或方程式。", "solution": "我们从一致性公式开始，其中每个代理$i \\in \\{1, \\dots, N\\}$通过求解对称正定系统来执行$x_i$的局部更新\n$$\n\\left(A_i^{\\top}A_i + \\rho I\\right)x_i = A_i^{\\top} b_i + \\rho \\left(v - u_i\\right).\n$$\n鉴于$A_i^{\\top}A_i$和$A_i^{\\top}b_i$已经离线预计算，每个代理每次迭代的操作包括：\n- 对角线调整：将$\\rho$加到$A_i^{\\top}A_i$的$n$个对角线元素上，代价为$n$ flops；\n- $\\left(A_i^{\\top}A_i + \\rho I\\right)$的Cholesky分解，代价为$\\frac{n^{3}}{3}$ flops；\n- 构造右侧项$r_i = A_i^{\\top}b_i + \\rho(v - u_i)$，代价为$3n$ flops（$v - u_i$的一次减法，与$\\rho$的一次标量乘法，与$A_i^{\\top}b_i$的一次加法）；\n- 使用Cholesky因子通过两次三角求解来解该系统：\n  - 使用下三角因子进行前向求解：$n^{2}$ flops，\n  - 使用转置（上三角）进行后向求解：$n^{2}$ flops，\n  总计为$2n^{2}$ flops。\n\n将单个代理的这些代价相加，得到\n$$\n\\text{每个代理的局部代价} = n + \\frac{n^{3}}{3} + 3n + 2n^{2} = \\frac{n^{3}}{3} + 2n^{2} + 4n.\n$$\n对于所有$N$个代理，总的局部更新代价是\n$$\nN\\left(\\frac{n^{3}}{3} + 2n^{2} + 4n\\right).\n$$\n\n接下来，考虑全局平均步骤\n$$\nv \\leftarrow \\frac{1}{N}\\sum_{i=1}^{N}\\left(x_i + u_i\\right).\n$$\n单次遍历累加策略通过遍历$i$并将$x_i + u_i$加到一个运行总和中，然后乘以$\\frac{1}{N}$来计算$v$。此步骤每次迭代的flop计数为：\n- 对每个$i$计算$x_i + u_i$：$Nn$次加法，\n- 对每个$i$累加到$v$中：另外$Nn$次加法，\n- 将$v$乘以$\\frac{1}{N}$：$n$次乘法，\n总计为\n$$\n2Nn + n\n$$\nflops。\n\n因此，每次迭代的总flop计数，即结合所有局部更新和全局平均步骤的代价，为\n$$\nN\\left(\\frac{n^{3}}{3} + 2n^{2} + 4n\\right) + \\left(2Nn + n\\right) = \\frac{N}{3}n^{3} + 2Nn^{2} + 6Nn + n.\n$$\n这是一个关于$N$和$n$的闭式解析表达式，符合要求。", "answer": "$$\\boxed{\\frac{N}{3}n^{3} + 2Nn^{2} + 6Nn + n}$$", "id": "3438216"}, {"introduction": "在实践中，使用ADMM的一项关键技能是监控其收敛过程并调整参数以获得最佳性能。本练习 [@problem_id:3438215] 设定了一个真实场景，您需要分析一份包含原始残差和对偶残差的日志，以决定何时停止算法以及如何调整惩罚参数 $\\rho$。通过此练习，您将掌握平衡原始与对偶收敛速度的标准启发式方法，从而直接影响算法的执行效率和稳定性。", "problem": "考虑应用于具有 $M$ 个代理的压缩感知模型的交替方向乘子法（ADMM）的分布式一致性形式，其中求解 $\\min_{x_1,\\ldots,x_M,z}\\sum_{i=1}^M f_i(x_i)+g(z)$，约束条件为对所有 $i\\in\\{1,\\ldots,M\\}$ 都有 $x_i=z$。设使用缩放形式的ADMM，缩放对偶变量为 $u_i$，原始残差为堆叠的一致性误差 $r^k=\\big(x_1^k-z^k,\\ldots,x_M^k-z^k\\big)$，对偶残差为 $s^k=\\rho\\big(z^k-z^{k-1}\\big)$（广播到每个块，因此报告的范数是堆叠向量的范数）。给定以下在使用固定惩罚参数 $\\rho$ 时，这些残差的欧几里得范数在 $k\\in\\{1,\\ldots,11\\}$ 时的迭代日志：\n- 迭代索引：$k=\\{1,2,3,4,5,6,7,8,9,10,11\\}$。\n- 原始残差范数：$\\{\\lVert r^1\\rVert_2,\\ldots,\\lVert r^{11}\\rVert_2\\}=\\{1.0\\times 10^{0},\\,5.0\\times 10^{-1},\\,2.5\\times 10^{-1},\\,1.2\\times 10^{-1},\\,6.0\\times 10^{-2},\\,3.0\\times 10^{-2},\\,1.5\\times 10^{-2},\\,7.0\\times 10^{-3},\\,3.5\\times 10^{-3},\\,1.7\\times 10^{-3},\\,8.0\\times 10^{-4}\\}$。\n- 对偶残差范数：$\\{\\lVert s^1\\rVert_2,\\ldots,\\lVert s^{11}\\rVert_2\\}=\\{1.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,8.0\\times 10^{-4},\\,1.6\\times 10^{-3},\\,8.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,1.0\\times 10^{-4},\\,5.0\\times 10^{-5},\\,2.5\\times 10^{-5}\\}$。\n\n假设绝对和相对停止容限在每次迭代时都评估为固定阈值，即 $\\varepsilon_{\\mathrm{pri}}=1.0\\times 10^{-3}$ 和 $\\varepsilon_{\\mathrm{dual}}=1.0\\times 10^{-3}$。你需要仅根据上述日志和标准的一致性ADMM实践来决定，你将在何时停止算法，以及是否以及如何调整惩罚参数 $\\rho$ 以提高收敛速度同时保持稳定性。特别地，你的答案应遵循以下原则：\n- 停止应反映与Karush–Kuhn–Tucker条件相关的原始和对偶可行性近似满足。\n- 调整 $\\rho$ 应由增广拉格朗日动力学中原始和对偶进展之间的相互作用来证明其合理性。\n\n选择下面唯一的最佳策略。\n\nA. 不在迭代 $k=11$ 之前停止，因为你需要同时满足 $\\lVert r^k\\rVert_2\\le \\varepsilon_{\\mathrm{pri}}$ 和 $\\lVert s^k\\rVert_2\\le \\varepsilon_{\\mathrm{dual}}$，这在 $k=11$ 时首次发生。为了加速早期迭代中 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 的情况（例如，对于 $k\\in\\{1,2,3,4,5,6,7,8,9,10\\}$），每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时，将 $\\rho$ 乘性增加（例如，乘以因子 $2$），并通过乘以逆因子来重新缩放缩放对偶变量以保持等价性。这增加了对一致性的权重，更积极地缩小 $\\lVert r^k\\rVert_2$，并平衡残差，通常能在不牺牲稳定性的情况下提高收敛速度。\n\nB. 在迭代 $k=5$ 时停止，因为在那之后 $\\lVert r^k\\rVert_2$ 继续下降到低于 $\\varepsilon_{\\mathrm{pri}}$，而 $\\lVert s^k\\rVert_2$ 达到峰值；为避免在 $k=5$ 时的对偶残差峰值，每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时减小 $\\rho$，这可以防止对偶残差增长并提高稳定性。\n\nC. 在迭代 $k=11$ 时停止，但为了在早期阶段 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 时提高稳定性，对 $k\\in\\{1,2,3,4\\}$ 减小 $\\rho$（例如，除以因子 $2$），以使增广拉格朗日惩罚更温和；这降低了 $z$ 更新的刚度，从而加速了原始可行性。\n\nD. 全程保持 $\\rho$ 不变以避免不稳定性，并在迭代 $k=8$ 时停止，因为尽管 $\\lVert s^8\\rVert_2>\\varepsilon_{\\mathrm{dual}}$，但 $\\lVert r^8\\rVert_2\\varepsilon_{\\mathrm{pri}}$；在一致性ADMM中，原始残差满足其容限就足够了，因为对偶残差最终会衰减。", "solution": "用户希望我扮演一位严格的STEM教授，分析一个关于交替方向乘子法（ADMM）的问题。\n\n### 第一步：提取已知条件\n\n-   **问题：** 分布式一致性ADMM，用于求解 $\\min_{x_1,\\ldots,x_M,z}\\sum_{i=1}^M f_i(x_i)+g(z)$，约束条件为对所有 $i$ 都有 $x_i=z$。\n-   **算法：** 缩放形式的ADMM，惩罚参数为 $\\rho$，缩放对偶变量为 $u_i$。\n-   **原始残差：** $r^k=\\big(x_1^k-z^k,\\ldots,x_M^k-z^k\\big)$。\n-   **对偶残差：** $s^k=\\rho\\big(z^k-z^{k-1}\\big)$。\n-   **迭代日志 ($k=1, \\dots, 11$):**\n    -   原始残差范数，$\\lVert r^k\\rVert_2$: $\\{1.0\\times 10^{0},\\,5.0\\times 10^{-1},\\,2.5\\times 10^{-1},\\,1.2\\times 10^{-1},\\,6.0\\times 10^{-2},\\,3.0\\times 10^{-2},\\,1.5\\times 10^{-2},\\,7.0\\times 10^{-3},\\,3.5\\times 10^{-3},\\,1.7\\times 10^{-3},\\,8.0\\times 10^{-4}\\}$。\n    -   对偶残差范数，$\\lVert s^k\\rVert_2$: $\\{1.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,8.0\\times 10^{-4},\\,1.6\\times 10^{-3},\\,8.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,1.0\\times 10^{-4},\\,5.0\\times 10^{-5},\\,2.5\\times 10^{-5}\\}$。\n-   **停止容限：** $\\varepsilon_{\\mathrm{pri}}=1.0\\times 10^{-3}$ 和 $\\varepsilon_{\\mathrm{dual}}=1.0\\times 10^{-3}$。\n-   **目标：** 确定正确的停止迭代次数和调整 $\\rho$ 的适当策略。\n\n### 第二步：使用提取的已知条件进行验证\n\n-   **科学上 обоснованный：** 问题设置在一致性ADMM的背景下，这是一种在分布式优化和信号处理中广泛使用的标准算法。问题表述、原始和对偶残差的定义以及惩罚参数自适应的概念都是ADMM理论和实践的标准要素。所提供的数值数据，显示了较大的初始原始残差和较小的对偶残差，是一种常见情况。\n-   **定义明确：** 问题是定义明确的。它提供了一个特定的数据集，并要求基于已建立的算法实践进行解释。在存在一种标准的、被广泛接受的针对所描述情况的启发式方法的意义上，存在一个唯一的“最佳策略”。\n-   **客观性：** 问题是客观陈述的，使用了精确的数学定义并提供了数值数据。它要求根据标准实践做出决策，这是一个可验证的标准。\n\n问题陈述没有违反任何无效性标准。它是科学合理的、定义明确的、客观的，并且对于手头的任务是完整的。\n\n### 第三步：结论和行动\n\n问题是**有效的**。我将继续进行解答。\n\n### 推导与分析\n\n问题需要做出两个主要决策：何时停止算法以及如何调整惩罚参数 $\\rho$ 以获得更好的性能。\n\n**1. 停止准则**\n\nADMM的标准停止条件基于原始和对偶残差，它们衡量了Karush-Kuhn-Tucker（KKT）条件的满足程度。算法在迭代 $k$ 处终止，如果以下两个条件都满足：\n$$ \\lVert r^k \\rVert_2 \\le \\varepsilon_{\\mathrm{pri}} $$\n$$ \\lVert s^k \\rVert_2 \\le \\varepsilon_{\\mathrm{dual}} $$\n我们已知 $\\varepsilon_{\\mathrm{pri}} = 1.0 \\times 10^{-3}$ 和 $\\varepsilon_{\\mathrm{dual}} = 1.0 \\times 10^{-3}$。让我们检查提供的迭代日志，找出第一个同时满足这两个条件的迭代 $k$。\n\n-   **原始残差条件：** $\\lVert r^k \\rVert_2 \\le 1.0 \\times 10^{-3}$\n    -   对于 $k=1, \\dots, 10$，范数分别为 $1.0, 0.5, 0.25, 0.12, 0.06, 0.03, 0.015, 7.0 \\times 10^{-3}, 3.5 \\times 10^{-3}, 1.7 \\times 10^{-3}$。所有这些都大于 $1.0 \\times 10^{-3}$。\n    -   对于 $k=11$，我们有 $\\lVert r^{11} \\rVert_2 = 8.0 \\times 10^{-4}$。因为 $8.0 \\times 10^{-4}  1.0 \\times 10^{-3}$，所以在 $k=11$ 时满足原始条件。\n\n-   **对偶残差条件：** $\\lVert s^k \\rVert_2 \\le 1.0 \\times 10^{-3}$\n    -   对于 $k=1,2,3,4$：范数分别为 $\\{1.0, 2.0, 4.0, 8.0\\} \\times 10^{-4}$，都 $\\le 1.0 \\times 10^{-3}$。条件满足。\n    -   对于 $k=5$：范数为 $\\lVert s^5 \\rVert_2 = 1.6 \\times 10^{-3}$，大于 $1.0 \\times 10^{-3}$。条件不满足。\n    -   对于 $k=6, \\dots, 11$：范数分别为 $\\{8.0, 4.0, 2.0, 1.0\\} \\times 10^{-4}$、$5.0 \\times 10^{-5}$ 和 $2.5 \\times 10^{-5}$。所有这些都 $\\le 1.0 \\times 10^{-3}$。条件满足。\n\n算法必须在**两个**条件首次同时满足时停止。\n-   在 $k=1, \\dots, 4$：原始条件失败，对偶条件通过。不停止。\n-   在 $k=5$：原始条件失败，对偶条件失败。不停止。\n-   在 $k=6, \\dots, 10$：原始条件失败，对偶条件通过。不停止。\n-   在 $k=11$：原始条件通过（$\\lVert r^{11} \\rVert_2 = 8.0 \\times 10^{-4} \\le 1.0 \\times 10^{-3}$）且对偶条件通过（$\\lVert s^{11} \\rVert_2 = 2.5 \\times 10^{-5} \\le 1.0 \\times 10^{-3}$）。两个条件都满足。\n\n因此，正确的停止迭代是 $k=11$。\n\n**2. 惩罚参数调整**\n\n原始和对偶残差的相对大小为调整 $\\rho$ 的策略提供了信息。目标是平衡残差，因为这通常会导致更快的收敛。标准的启发式方法如下：\n-   如果原始残差远大于对偶残差，即 $\\lVert r^k \\rVert_2 > \\mu \\lVert s^k \\rVert_2$ 对于某个 $\\mu > 1$（例如，$\\mu=10$），这表明原始可行性（在这种情况下是一致性）是瓶颈。为了解决这个问题，惩罚参数 $\\rho$ 应该**增加**（例如，$\\rho \\to \\tau\\rho$ 对于 $\\tau>1$，例如 $\\tau=2$）。这会对违反约束 $x_i = z$ 的行为施加更高的惩罚，从而促使原始残差更快地减小。\n-   如果对偶残差远大于原始残差，即 $\\lVert s^k \\rVert_2 > \\mu \\lVert r^k \\rVert_2$，则应**减小** $\\rho$（$\\rho \\to \\rho/\\tau$）。\n\n让我们使用 $\\mu=10$ 作为典型阈值，检查日志中 $\\lVert r^k \\rVert_2 / \\lVert s^k \\rVert_2$ 的比率。\n-   $k=1$: $1.0 / (1.0 \\times 10^{-4}) = 10000 \\gg 10$\n-   $k=2$: $0.5 / (2.0 \\times 10^{-4}) = 2500 \\gg 10$\n-   $k=3$: $0.25 / (4.0 \\times 10^{-4}) = 625 \\gg 10$\n-   $k=4$: $0.12 / (8.0 \\times 10^{-4}) = 150 \\gg 10$\n-   $k=5$: $(6.0 \\times 10^{-2}) / (1.6 \\times 10^{-3}) = 37.5 \\gg 10$\n-   ...\n-   $k=11$: $(8.0 \\times 10^{-4}) / (2.5 \\times 10^{-5}) = 32 \\gg 10$\n\n在日志中的每一次迭代中，原始残差范数都显著大于对偶残差范数。条件 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 总是满足。这表明 $\\rho$ 的初始选择太小，导致在满足一致性约束方面进展缓慢。正确的自适应策略是**增加 $\\rho$**。\n\n在缩放形式的ADMM中调整 $\\rho$ 时，至关重要的是也要重新缩放对偶变量 $u_i$ 以维持等价性 $y_i = \\rho u_i$，其中 $y_i$ 是未缩放的对偶变量。如果 $\\rho$ 更新为 $\\rho_{\\text{new}} = \\tau \\rho_{\\text{old}}$，则缩放对偶变量必须更新为 $u_{i, \\text{new}} = u_{i, \\text{old}} / \\tau$。这对应于通过逆因子进行重新缩放。\n\n### 逐选项分析\n\n**A. 不在迭代 $k=11$ 之前停止，因为你需要同时满足 $\\lVert r^k\\rVert_2\\le \\varepsilon_{\\mathrm{pri}}$ 和 $\\lVert s^k\\rVert_2\\le \\varepsilon_{\\mathrm{dual}}$，这在 $k=11$ 时首次发生。为了加速早期迭代中 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 的情况（例如，对于 $k\\in\\{1,2,3,4,5,6,7,8,9,10\\}$），每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时，将 $\\rho$ 乘性增加（例如，乘以因子 $2$），并通过乘以逆因子来重新缩放缩放对偶变量以保持等价性。这增加了对一致性的权重，更积极地缩小 $\\lVert r^k\\rVert_2$，并平衡残差，通常能在不牺牲稳定性的情况下提高收敛速度。**\n-   **停止：** 正确地将 $k=11$ 确定为停止迭代。\n-   **调整：** 正确地识别出 $\\lVert r^k\\rVert_2 \\gg \\lVert s^k\\rVert_2$，并提出了增加 $\\rho$ 的标准、正确的启发式方法。\n-   **重新缩放：** 正确地提到了对缩放对偶变量进行必要的重新缩放。\n-   **理由：** 所提供的推理完全合理，并与ADMM理论一致。\n此选项是**正确的**。\n\n**B. 在迭代 $k=5$ 时停止，因为在那之后 $\\lVert r^k\\rVert_2$ 继续下降到低于 $\\varepsilon_{\\mathrm{pri}}$，而 $\\lVert s^k\\rVert_2$ 达到峰值；为避免在 $k=5$ 时的对偶残差峰值，每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时减小 $\\rho$，这可以防止对偶残差增长并提高稳定性。**\n-   **停止：** 停止迭代 $k=5$ 是不正确的。在 $k=5$ 时，$\\lVert r^5 \\rVert_2 = 6.0 \\times 10^{-2} \\gg \\varepsilon_{\\mathrm{pri}}$ 且 $\\lVert s^5 \\rVert_2 = 1.6 \\times 10^{-3} > \\varepsilon_{\\mathrm{dual}}$。\n-   **调整：** 减小 $\\rho$ 的建议与针对观察到的残差不平衡的正确策略相反。\n此选项是**不正确的**。\n\n**C. 在迭代 $k=11$ 时停止，但为了在早期阶段 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 时提高稳定性，对 $k\\in\\{1,2,3,4\\}$ 减小 $\\rho$（例如，除以因子 $2$），以使增广拉格朗日惩罚更温和；这降低了 $z$ 更新的刚度，从而加速了原始可行性。**\n-   **停止：** 停止迭代 $k=11$ 是正确的。\n-   **调整：** 减小 $\\rho$ 的建议是不正确的。它会加剧原始/对偶残差的不平衡，并减慢而不是加速原始可行性的满足。其理由是有缺陷的。\n此选项是**不正确的**。\n\n**D. 全程保持 $\\rho$ 不变以避免不稳定性，并在迭代 $k=8$ 时停止，因为尽管 $\\lVert s^8\\rVert_2>\\varepsilon_{\\mathrm{dual}}$，但 $\\lVert r^8\\rVert_2\\varepsilon_{\\mathrm{pri}}$；在一致性ADMM中，原始残残满足其容限就足够了，因为对偶残差最终会衰减。**\n-   **停止：** 停止迭代 $k=8$ 是不正确的。声称 $\\lVert r^8\\rVert_2  \\varepsilon_{\\mathrm{pri}}$ 是事实错误的，因为 $\\lVert r^8\\rVert_2 = 7.0 \\times 10^{-3} > 1.0 \\times 10^{-3}$。\n-   **原则：** 断言仅满足原始容限就足够了是根本错误的。收敛需要原始和对偶可行性。\n-   **调整：** 虽然保持 $\\rho$ 不变是一种有效（尽管次优）的策略，但自适应 $\\rho$ 方案是标准实践，并且如果做得正确，通常能提高性能而不会导致不稳定性。\n此选项是**不正确的**。\n\n基于此全面分析，选项A是唯一提出完全正确且理由充分的策略的选项，该策略与标准ADMM实践一致。", "answer": "$$\\boxed{A}$$", "id": "3438215"}, {"introduction": "在许多大规模应用中，通过直接因式分解来求解局部ADMM子问题是不可行的，此时通常采用预条件共轭梯度（PCG）等迭代方法。本练习 [@problem_id:3438192] 深入探讨了如何设计一个有效的预条件算子来加速这些内部求解过程。您将学习一个简单的对角预条件算子如何能够改善子问题的条件数，减少内部PCG的迭代次数，进而在不改变ADMM收敛点的前提下提升算法的整体效率。", "problem": "考虑一个用于稀疏回归任务的分布式一致性交替方向乘子法 (ADMM) 公式，其中工作节点 $i$ 持有数据矩阵 $A_i \\in \\mathbb{R}^{m_i \\times n}$ 和观测值 $b_i \\in \\mathbb{R}^{m_i}$。全局问题是在一致性分裂的约束下最小化 $\\sum_{i=1}^N \\tfrac{1}{2}\\lVert A_i x - b_i \\rVert_2^2 + \\lambda \\lVert x \\rVert_1$，其中每个工作节点维护一个局部副本 $x_i$，并约束其等于一个全局变量 $z$。在 ADMM 的缩放形式中，第 $k$ 次迭代的 $x_i$ 更新需要求解对称正定线性系统\n$$(A_i^\\top A_i + \\rho I) x_i^{k+1} = A_i^\\top b_i + \\rho (z^k - u_i^k),$$\n其中 $\\rho > 0$ 是增广拉格朗日惩罚参数，$u_i^k$ 是缩放对偶变量。假设该系统通过预条件共轭梯度法 (PCG) 的内部迭代以固定的相对容差进行非精确求解。\n\n从以下经过充分检验的事实出发：\n- 对于任何对称正定矩阵 $H$，其条件数为 $\\kappa(H) := \\lambda_{\\max}(H)/\\lambda_{\\min}(H)$，其中 $\\lambda_{\\max}(H)$ 和 $\\lambda_{\\min}(H)$ 分别是最大和最小特征值。\n- 对于应用于 $H x = b$、使用对称正定预条件子 $M$ 的 PCG 方法，其收敛速率由 $\\kappa(M^{-1/2} H M^{-1/2})$ 决定；具体来说，将误差的 $H$-范数减小一个因子 $\\epsilon \\in (0,1)$ 所需的迭代次数 $t(\\epsilon)$ 满足 $t(\\epsilon) = \\mathcal{O}\\!\\left(\\sqrt{\\kappa(M^{-1/2} H M^{-1/2})} \\log(1/\\epsilon)\\right)$。\n- 盖尔圆盘定理：一个方阵的每个特征值都至少位于一个圆盘内，该圆盘以某个对角线元素为中心，半径等于该行非对角线元素绝对值之和。\n\n您的目标是为内部 PCG 求解选择一个对角预条件子，该预条件子能够改善 $A_i^\\top A_i + \\rho I$ 的条件数，同时保持 ADMM 的不动点。哪个选项最好地提出了这样一个预条件子，并正确阐述了其对内部迭代次数和整体 ADMM 效率的影响？\n\n选择下面唯一的最佳策略。\n\nA. 使用雅可比预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i) + \\rho I$ 并应用对称预处理得到 PCG 系统 $M_i^{-1/2} (A_i^\\top A_i + \\rho I) M_i^{-1/2}$。预处理后矩阵的特征值位于以 1 为中心的盖尔圆盘的并集中，半径为 $r_i := \\sum_{j \\ne i} \\frac{|(A_i^\\top A_i)_{ij}|}{(A_i^\\top A_i)_{ii} + \\rho}$。因此，如果 $\\max_i r_i = r  1$，那么 $\\kappa \\le \\frac{1+r}{1-r}$，该值随着 $\\rho$ 的增加而减小。因此，对于固定的容差，PCG 迭代次数以 $\\mathcal{O}(\\sqrt{\\kappa})$ 的速度下降，并且由于求解的精确线性系统没有改变，ADMM 不动点得以保持；当对角预处理的开销可以忽略不计时，每次 ADMM 迭代的总体运行时间会减少，从而提高端到端的效率。\n\nB. 使用标量预条件子 $M_i := \\rho I$；这使得预处理后矩阵的条件数等于 1，与 $A_i$ 无关，因此 PCG 对于任何容差都能在 1 次迭代内收敛，从而极大地加速 ADMM。\n\nC. 使用完整预条件子 $M_i := A_i^\\top A_i + \\rho I$，这样预处理后系统的条件数正好为 1；在 PCG 中应用 $M_i^{-1}$ 的成本相对于与 $A_i$ 和 $A_i^\\top$ 的矩阵向量乘法可以忽略不计，因此内部求解实际上只需要 1 次迭代，而不会对整体效率产生不利影响。\n\nD. 使用对角预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i)$（不含 $\\rho I$ 项）。尽管 PCG 迭代次数可能会减少，但对角缩放会改变局部子问题，从而改变 ADMM 的不动点；外部 ADMM 的收敛可能会加速，但会收敛到一个与未使用预处理方法不同的解。", "solution": "我们利用核心原理来分析所提出的预条件子：对称正定系统的条件数、基于盖尔圆盘的对角缩放矩阵的界、以及预条件共轭梯度法收敛对预处理算子谱的依赖性。我们还利用了当同一线性系统被求解至固定容差时，ADMM 不动点在内部线性求解器预处理下的不变性。\n\n设 $H_i := A_i^\\top A_i + \\rho I$，对于任何 $\\rho > 0$，该矩阵都是对称正定的。带有对称正定预条件子 $M_i$ 的 PCG 方法有效地求解 $M_i^{-1/2} H_i M_i^{-1/2} \\tilde{x} = M_i^{-1/2} b$，其条件数 $\\kappa(M_i^{-1/2} H_i M_i^{-1/2})$ 得到了改善。\n\n我们对预处理后的矩阵应用盖尔圆盘定理。对于对角预条件子 $M_i = \\operatorname{diag}(H_i)$（雅可比选择），预处理后的矩阵 $M_i^{-1} H_i$ 的对角线元素等于 1，非对角线元素为 $\\frac{(H_i)_{ij}}{(H_i)_{ii}}$（其中 $i \\ne j$）。由于 $M_i$ 是对角矩阵，使用 $M_i^{-1/2}$ 进行对称预处理会保留 $M_i^{-1} H_i$ 的特征值。然后，盖尔圆盘定理将 $M_i^{-1/2} H_i M_i^{-1/2}$ 的每个特征值 $\\lambda$ 定位在某个圆盘 $D(1, r_i)$ 内，其中\n$$r_i := \\sum_{j \\ne i} \\left| \\frac{(H_i)_{ij}}{(H_i)_{ii}} \\right| = \\sum_{j \\ne i} \\frac{|(A_i^\\top A_i)_{ij}|}{(A_i^\\top A_i)_{ii} + \\rho}.$$\n如果 $r := \\max_i r_i  1$（严格对角占优），那么所有特征值都位于 $[1-r, 1+r]$ 区间内，并且条件数服从\n$$\\kappa\\!\\left(M_i^{-1/2} H_i M_i^{-1/2}\\right) \\le \\frac{1 + r}{1 - r}.$$\n由于随着 $\\rho$ 的增加（分母 $(A_i^\\top A_i)_{ii} + \\rho$ 增长，而非对角项固定），$r$ 单调递减，因此界变得更紧，谱更紧密地聚集在 1 附近。达到固定相对容差 $\\epsilon$ 所需的 PCG 迭代次数大致与 $\\sqrt{\\kappa}$ 成比例减少：\n$$t(\\epsilon) = \\mathcal{O}\\!\\left( \\sqrt{ \\kappa\\!\\left(M_i^{-1/2} H_i M_i^{-1/2}\\right)} \\log(1/\\epsilon) \\right).$$\n预处理不改变被求解的线性系统；它只改变构建克雷洛夫搜索方向时所用的度量。因此，假设使用相同的停止准则，带预处理的 PCG 所产生的 $x_i$ 更新是对局部子问题同一个精确最小化子的近似，因此 ADMM 不动点保持不变。如果应用 $M_i^{-1}$（一次对角缩放）的成本相对于乘以 $A_i$ 和 $A_i^\\top$ 的主要成本可以忽略不计（通常是这种情况），那么每次迭代的运行时间就会得到改善。这确立了其对内部迭代次数和整体 ADMM 效率的预期效果。\n\n现在我们评估每个选项：\n\nA. 雅可比预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i) + \\rho I$ 正是 $H_i$ 的对角部分。对称预处理 $M_i^{-1/2} H_i M_i^{-1/2}$ 产生一个对角线元素为单位 1 的矩阵，盖尔圆盘定理可以直接应用于该矩阵，其半径为 $r_i = \\sum_{j \\ne i} \\frac{|(A_i^\\top A_i)_{ij}|}{(A_i^\\top A_i)_{ii} + \\rho}$。如果 $r  1$，则界 $\\kappa \\le \\frac{1+r}{1-r}$ 成立，并随着 $\\rho$ 的增长而改善。对于固定的容差，PCG 迭代次数以 $\\mathcal{O}(\\sqrt{\\kappa})$ 的速度减少。因为求解的是同一个线性系统（在规定的容差内），ADMM 不动点不受影响。对角预条件子的应用成本低廉，因此每次 ADMM 迭代的总体运行时间减少，提高了端到端的效率。结论：正确。\n\nB. 标量预条件子 $M_i := \\rho I$ 只是在预处理矩阵 $M_i^{-1/2} H_i M_i^{-1/2} = \\rho^{-1} H_i$ 中将 $H_i$ 按常数缩放，这不会改变条件数：$\\kappa(\\rho^{-1} H_i) = \\kappa(H_i)$。声称条件数变为 1 且 PCG 在 1 次迭代内收敛是错误的，除非 $H_i$ 与单位矩阵成比例，而通常情况并非如此。结论：不正确。\n\nC. 完整预条件子 $M_i := H_i$ 确实会产生一个条件数为 1 的预处理矩阵，意味着在精确算术中 1 次迭代即可收敛。然而，这不符合题目要求的对角预条件子，并且在 PCG 内部应用 $M_i^{-1}$ 需要求解 $H_i$（例如，通过因式分解或内部迭代求解），这个开销是不可忽略的，也违背了使用 PCG 来避免昂贵因式分解的初衷。声称开销可以忽略不计在预设情境下是不合理的。结论：不正确。\n\nD. 对角预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i)$ 忽略了 $\\rho I$ 项，因此是对 $A_i^\\top A_i$ 而非 $H_i$ 进行预处理。虽然可以用这个 $M_i$ 来分析 $M_i^{-1/2} H_i M_i^{-1/2}$，但该陈述声称对角缩放会改变 ADMM 不动点。这是错误的：预处理只加速了对相同最优性条件的迭代求解，并不会改变局部二次子问题的最小化子，因此它不会改变 ADMM 的不动点。此外，从 $M_i$ 中省略 $\\rho I$ 通常会导致比使用 $\\operatorname{diag}(H_i)$ 更弱的对角占优性，因此在改善条件数方面效果较差。结论：不正确。\n\n因此，只有选项 A 既提出了一个合适的对角预条件子，又正确地评估了其对内部求解器迭代和整体 ADMM 效率的影响。", "answer": "$$\\boxed{A}$$", "id": "3438192"}]}