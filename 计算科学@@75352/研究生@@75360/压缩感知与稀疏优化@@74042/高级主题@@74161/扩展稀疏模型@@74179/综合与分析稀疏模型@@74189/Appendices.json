{"hands_on_practices": [{"introduction": "理论学习的最佳伴侣是动手实践。本章节将通过一系列精心设计的问题，引导你将稀疏表示的理论应用于具体场景。我们从一个压缩感知领域的经典问题开始：从部分傅里叶测量中恢复信号。这个场景不仅是理论的基石，也直接对应着磁共振成像（MRI）等重要应用。通过这个练习[@problem_id:3485055]，你将亲自推导在合成稀疏模型下，确保精确恢复所需的最少测量数与信号稀疏度之间的基本关系。", "problem": "考虑一个维度为 $n \\in \\mathbb{N}$ 的离散信号空间。设 $F \\in \\mathbb{C}^{n \\times n}$ 为酉离散傅里叶变换矩阵，其元素为 $F_{k\\ell} = \\frac{1}{\\sqrt{n}} \\exp\\!\\big(-2\\pi i \\frac{k\\ell}{n}\\big)$，其中 $k,\\ell \\in \\{0,1,\\dots,n-1\\}$，因此 $F$ 的每一行和每一列都具有单位 $\\ell_2$ 范数。通过从 $F$ 中均匀随机地选择 $m$ 个不同的行来构成一个测量矩阵 $A \\in \\mathbb{C}^{m \\times n}$，其中 $1 \\leq m \\leq n$。考虑合成稀疏模型，其中固定字典 $D \\in \\mathbb{C}^{n \\times n}$ 等于单位矩阵，因此任何合成系数向量 $x \\in \\mathbb{C}^{n}$ 生成一个信号 $z = D x = x$，且 $s$-稀疏合成信号满足 $|\\operatorname{supp}(x)| \\leq s$。\n\n定义测量矩阵 $A$ 和字典 $D$ 之间的缩放互相关性为\n$$\n\\mu(A,D) := \\sqrt{n} \\, \\max_{i \\in \\{1,\\dots,m\\}} \\max_{j \\in \\{1,\\dots,n\\}} \\left| \\langle a_{i}, d_{j} \\rangle \\right|,\n$$\n其中 $a_{i} \\in \\mathbb{C}^{n}$ 表示视为 $\\mathbb{C}^{n}$ 中单位范数向量的 $A$ 的第 $i$ 行，而 $d_{j} \\in \\mathbb{C}^{n}$ 表示 $D$ 的第 $j$ 列，同样是单位范数。假设测量是无噪声的 $y = A z = A D x$。\n\n从压缩感知中关于合成稀疏性的非相干测量的成熟理论出发，并且不使用任何未从这些理论逻辑推导出的快捷公式，分析此设置下的 $\\mu(A,D)$，然后推导通过 $\\ell_{1}$ 最小化精确重构任何 $s$-稀疏合成向量 $x$ 的最坏情况充分恢复保证，该保证是关于 $m$、$n$ 和一个绝对常数 $C > 0$ 的函数。将此保证可以认证的最大稀疏度 $s_{\\max}(m,n,C)$ 表示为单个闭式解析表达式。不需要数值舍入，也不涉及物理单位。您的最终答案必须是单个解析表达式。", "solution": "该问题要求在给定的压缩感知设置下，推导通过 $\\ell_1$ 最小化能保证精确恢复 $s$-稀疏信号的最大稀疏度 $s_{\\max}$。推导必须从基本原理和对所提供量的仔细分析开始。\n\n首先，我们验证并分析问题陈述中定义的量。\n信号空间是 $\\mathbb{C}^{n}$。合成字典是单位矩阵 $D = I_n \\in \\mathbb{C}^{n \\times n}$。这意味着信号在标准（规范）基中是稀疏的。一个 $s$-稀疏信号 $z \\in \\mathbb{C}^n$ 可以写成 $z = D x = x$，其中 $x \\in \\mathbb{C}^n$ 是一个最多有 $s$ 个非零项的系数向量，即 $\\|x\\|_0 = |\\operatorname{supp}(x)| \\leq s$。字典 $D=I_n$ 的列是规范基向量 $\\{e_j\\}_{j=0}^{n-1}$，记为 $d_j$。每个 $d_j$ 都是单位范数向量，$\\|d_j\\|_2 = 1$。\n\n测量过程由一个矩阵 $A \\in \\mathbb{C}^{m \\times n}$ 定义，该矩阵通过从 $n \\times n$ 酉离散傅里叶变换（DFT）矩阵 $F$ 中均匀随机地选择 $m$ 个不同的行来构建。$F$ 的元素由 $F_{k\\ell} = \\frac{1}{\\sqrt{n}} \\exp\\big(-2\\pi i \\frac{k\\ell}{n}\\big)$ 给出，其中 $k,\\ell \\in \\{0, 1, \\dots, n-1\\}$。$F$ 的行是标准正交的，因此每行都有单位 $\\ell_2$ 范数。因此，$A$ 的行作为 $F$ 行的一个子集，也是 $\\mathbb{C}^n$ 中的单位范数向量。设所选行索引的集合为 $\\Omega \\subset \\{0, 1, \\dots, n-1\\}$，且 $|\\Omega| = m$。\n\n问题将测量矩阵 $A$ 和字典 $D$ 之间的缩放互相关性定义为\n$$\n\\mu(A,D) := \\sqrt{n} \\, \\max_{i \\in \\{1,\\dots,m\\}} \\max_{j \\in \\{1,\\dots,n\\}} \\left| \\langle a_{i}, d_{j} \\rangle \\right|.\n$$\n此处，$a_i$ 表示视为 $\\mathbb{C}^n$ 中向量的 $A$ 的第 $i$ 行，$d_j$ 是 $D$ 的第 $j$ 列。我们来分析内积 $\\langle a_i, d_j \\rangle$。设 $A$ 的第 $i$ 行对应于 $F$ 的第 $k$ 行，其中 $k \\in \\Omega$。我们将此行表示为 $\\mathbb{C}^n$ 中的一个向量。$\\mathbb{C}^n$ 中的标准内积是 $\\langle u, v \\rangle = v^* u$。然而，在当前语境下，$\\langle a_i, d_j \\rangle$ 最自然的解释是行向量 $a_i$ 和列向量 $d_j$ 的矩阵乘积，或者是行向量 $a_i$ 的列向量表示与列向量 $d_j$ 之间的内积。两种解释都得到相同的模值。\n\n设 $a_i$ 是对应于 $F$ 的第 $k$ 行的行向量。其分量为 $(a_i)_{\\ell} = F_{k\\ell}$。向量 $d_j$ 是规范基向量 $e_j$。内积 $\\langle a_i^T, d_j \\rangle = d_j^* a_i^T = e_j^T a_i^T = (a_i e_j^T)^T$。这种解释在符号上很繁琐。一个更标准的方法是考虑行向量 $a_i$ 的共轭转置构成的向量（我们称之为 $a_i^{\\text{vec}}$）与列向量 $d_j$ 之间的内积。让我们采用这种标准解释：我们取行向量，比如 $r_k^T$，并将其视为列向量 $r_k$。那么内积就是 $\\langle r_k, e_j \\rangle = e_j^* r_k$。这给出了向量 $r_k$ 的第 $j$ 个分量。$F$ 的第 $k$ 行的第 $j$ 个分量是 $F_{kj}$。因此，$|\\langle a_i, d_j \\rangle| = |F_{kj}|$。\nDFT矩阵 $F$ 的任意元素的模为\n$$\n|F_{k\\ell}| = \\left| \\frac{1}{\\sqrt{n}} \\exp\\left(-2\\pi i \\frac{k\\ell}{n}\\right) \\right| = \\frac{1}{\\sqrt{n}} \\left| \\exp\\left(-2\\pi i \\frac{k\\ell}{n}\\right) \\right| = \\frac{1}{\\sqrt{n}}.\n$$\n这个值对所有元素都是恒定的。因此，这些模的最大值也是 $\\frac{1}{\\sqrt{n}}$。\n$$\n\\max_{i \\in \\{1,\\dots,m\\}} \\max_{j \\in \\{1,\\dots,n\\}} \\left| \\langle a_{i}, d_{j} \\rangle \\right| = \\frac{1}{\\sqrt{n}}.\n$$\n这个结果与 $m$ 行的具体选择无关。现在我们可以计算缩放互相关性：\n$$\n\\mu(A,D) = \\sqrt{n} \\cdot \\left( \\frac{1}{\\sqrt{n}} \\right) = 1.\n$$\n这个量，在问题中被标记为 $\\mu(A,D)$，更准确地说是全傅里叶基 $F$ 和标准基 $D=I_n$ 之间的相关性，它量化了它们的最大非相干性。\n\n下一步是利用这个结果来推导恢复保证。问题陈述我们应从“压缩感知中经过充分检验的事实”出发。由 Candès、Romberg 和 Tao 建立的一项压缩感知的基石性成果，为在一个非相干基中稀疏的信号的随机部分测量设置提供了这样的保证。\n该定理指出，如果一个测量矩阵 $\\mathcal{A} \\in \\mathbb{C}^{m \\times n}$ 是通过从一个 $n \\times n$ 的酉矩阵 $U$ 中均匀随机选择 $m$ 行构成的，那么任何相对于一个标准正交基 $\\Psi$ 是 $s$-稀疏的信号 $z$（即 $z = \\Psi x$ 且 $\\|x\\|_0 \\le s$），都可以通过 $\\ell_1$ 最小化从测量值 $y = \\mathcal{A} z$ 中精确且稳定地恢复。为使此恢复以高概率成立，对测量数量 $m$ 的一个充分条件是：\n$$\nm \\geq C \\cdot (\\mu(U, \\Psi))^2 \\cdot s \\cdot \\ln(n)\n$$\n其中 $C > 0$ 是一个绝对常数，$\\mu(U, \\Psi) = \\sqrt{n} \\max_{k,\\ell} |\\langle u_k, \\psi_\\ell \\rangle|$ 是 $U$ 的行 $u_k$ 和 $\\Psi$ 的列 $\\psi_\\ell$ 之间的互相关性。\n\n在我们的具体问题中：\n1. 酉矩阵是DFT矩阵，$U=F$。\n2. 测量矩阵 $A$ 是通过选择 $F$ 的 $m$ 行构成的。\n3. 信号 $z=x$ 在标准基中是稀疏的，这意味着合成字典是单位矩阵，$\\Psi = D = I_n$。\n4. 相关性参数 $\\mu(U, \\Psi)$ 精确对应于问题中定义的量 $\\mu(A,D)$，我们已经计算过这个量。\n所以，我们有 $\\mu(F, I_n) = 1$。\n\n将此结果代入定理中的条件，我们得到：\n$$\nm \\geq C \\cdot (1)^2 \\cdot s \\cdot \\ln(n)\n$$\n$$\nm \\geq C s \\ln(n)\n$$\n这个不等式为成功恢复任何 $s$-稀疏信号提供了关于 $m$ 的一个充分条件。问题要求的是这个保证可以认证的最大稀疏度 $s_{\\max}(m,n,C)$。我们可以通过重新整理不等式来求解 $s$ 来找到它：\n$$\ns \\leq \\frac{m}{C \\ln(n)}\n$$\n该保证对任何稀疏度 $s$ 直到这个界限都成立。因此，最大稀疏度是：\n$$\ns_{\\max}(m,n,C) = \\frac{m}{C \\ln(n)}\n$$\n这是最坏情况下的充分恢复保证，意味着对于一个随机选择的 $A$（其中 $m$ 满足条件），任何 $s$-稀疏信号都可以被恢复。该保证对于 $A$ 的选择是概率性的，但一旦 $A$ 被固定，它对所有 $s$-稀疏信号都成立。该表达式是关于 $m$、$n$ 和 $C$ 的闭式解析函数，符合要求。", "answer": "$$\\boxed{\\frac{m}{C \\ln(n)}}$$", "id": "3485055"}, {"introduction": "在掌握了合成稀疏模型的基础后，我们来探讨其对偶的视角：分析稀疏模型。虽然这两个模型都旨在利用信号的稀疏性，但它们的适用范围和恢复能力并不完全相同。这个练习[@problem_id:3485109]提供了一个绝佳的实例，通过一个具体的数值反例，你将清晰地看到分析模型在某些情况下可以成功恢复信号，而合成模型却会失败。亲手完成这个计算将帮助你深刻理解两种模型之间的关键差异，并认识到选择正确稀疏模型的重要性。", "problem": "考虑一个压缩感知中的有限维线性逆问题，其中测量算子为 $\\Phi \\in \\mathbb{R}^{m \\times n}$，合成字典为 $D \\in \\mathbb{R}^{n \\times q}$，分析算子为 $\\Omega \\in \\mathbb{R}^{p \\times n}$。合成模型假设信号 $x \\in \\mathbb{R}^{n}$ 具有一个稀疏表示 $x = D \\alpha$，其中 $\\alpha \\in \\mathbb{R}^{q}$ 是某个系数向量，并且可以通过求解 $\\min_{\\alpha} \\|\\alpha\\|_{1}$（约束条件为 $y = \\Phi D \\alpha$）来尝试重建，其中 $y \\in \\mathbb{R}^{m}$ 是测量值。分析模型假设向量 $\\Omega x$ 是稀疏的，并且可以通过求解 $\\min_{x} \\|\\Omega x\\|_{1}$（约束条件为 $y = \\Phi x$）来尝试重建。$\\Omega x$ 的协支撑集定义为 $\\Omega$ 中使得 $(\\Omega x)_{i} = 0$ 成立的行的索引集合。\n\n构建一个反例，其中对于分析模型可以实现精确恢复，但对于合成模型却失败了，其原因是 $\\Omega x$ 的协支撑集与 $D$ 中 $\\alpha$ 的支撑集之间存在不匹配，尽管测量值 $y = \\Phi x$ 是相同的。使用以下具体设置：\n- 设 $n = 3$ 且 $m = 2$。\n- 设 $\\Phi \\in \\mathbb{R}^{2 \\times 3}$ 由下式给出\n$$\n\\Phi = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0\n\\end{pmatrix}.\n$$\n- 设真实信号为 $x_{0} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$，因此 $y = \\Phi x_{0} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n- 设分析算子 $\\Omega \\in \\mathbb{R}^{2 \\times 3}$ 为\n$$\n\\Omega = \\begin{pmatrix}\n1  -1  0 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\n- 设合成字典 $D \\in \\mathbb{R}^{3 \\times 2}$ 的列为 $v_{1} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$ 和 $v_{2} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$，即\n$$\nD = \\begin{pmatrix}\n1  0 \\\\\n1  0 \\\\\n1  1\n\\end{pmatrix}.\n$$\n\n任务：\n1. 使用分析模型，求解凸规划问题 $\\min_{x \\in \\mathbb{R}^{3}} \\|\\Omega x\\|_{1}$（约束条件为 $y = \\Phi x$），并确定其唯一的极小化子 $x_{A}^{\\star}$。\n2. 使用合成模型，求解凸规划问题 $\\min_{\\alpha \\in \\mathbb{R}^{2}} \\|\\alpha\\|_{1}$（约束条件为 $y = \\Phi D \\alpha$），并确定其唯一的极小化子 $x_{S}^{\\star} = D \\alpha^{\\star}$。\n3. 计算欧几里得距离的平方 $\\|x_{A}^{\\star} - x_{S}^{\\star}\\|_{2}^{2}$ 并将结果表示为一个精确的实数。无需四舍五入。如果引入任何角度，请以弧度表示。\n\n你的构造必须明确地展示出分析模型实现了对 $x_{0}$ 的精确恢复，而合成模型在相同的测量值 $y$ 下未能恢复 $x_{0}$，并且 $\\Omega x$ 的协支撑集与 $\\alpha$ 的支撑集之间的不匹配应从你的推导中清晰可见。最终答案必须是等于 $\\|x_{A}^{\\star} - x_{S}^{\\star}\\|_{2}^{2}$ 的单个实数。", "solution": "用户提供了一个问题陈述，在尝试解答之前需要进行验证。\n\n### 步骤 1：提取已知条件\n- 信号维度：$n = 3$\n- 测量维度：$m = 2$\n- 测量算子：$\\Phi = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} \\in \\mathbb{R}^{2 \\times 3}$\n- 真实信号：$x_{0} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} \\in \\mathbb{R}^{3}$\n- 测量值：$y = \\Phi x_{0} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\in \\mathbb{R}^{2}$\n- 分析算子：$\\Omega = \\begin{pmatrix} 1  -1  0 \\\\ 0  0  1 \\end{pmatrix} \\in \\mathbb{R}^{2 \\times 3}$\n- 合成字典：$D = \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 1  1 \\end{pmatrix} \\in \\mathbb{R}^{3 \\times 2}$\n- 分析模型问题：$\\min_{x \\in \\mathbb{R}^{3}} \\|\\Omega x\\|_{1}$，约束条件为 $y = \\Phi x$。\n- 合成模型问题：$\\min_{\\alpha \\in \\mathbb{R}^{2}} \\|\\alpha\\|_{1}$，约束条件为 $y = \\Phi D \\alpha$。\n- 任务 1：找到分析问题的极小化子 $x_{A}^{\\star}$。\n- 任务 2：找到合成问题的极小化子 $x_{S}^{\\star}$。\n- 任务 3：计算欧几里得距离的平方 $\\|x_{A}^{\\star} - x_{S}^{\\star}\\|_{2}^{2}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题是压缩感知中的一个标准练习，比较了分析和合成稀疏模型。所有概念，包括 $\\ell_1$ 最小化、算子和字典，都是线性代数和优化中的标准概念。该问题在科学上和数学上是合理的。\n2.  **适定性**：这些问题是凸优化问题（在线性等式约束下最小化 $\\ell_1$ 范数）。此类问题有解。解的唯一性将在求解过程中确定，但问题结构是适定的。\n3.  **目标**：问题使用了精确、无歧义的数学术语进行陈述。\n4.  **完整性和一致性**：所有必需的矩阵、向量和问题表述都已提供。维度是一致的：$\\Phi \\in \\mathbb{R}^{2 \\times 3}$，$x \\in \\mathbb{R}^{3}$，$y \\in \\mathbb{R}^{2}$；$\\Omega \\in \\mathbb{R}^{2 \\times 3}$；$D \\in \\mathbb{R}^{3 \\times 2}$，$\\alpha \\in \\mathbb{R}^{2}$。\n5.  **未检测到其他缺陷**：该问题是一个有效的、精心构造的反例，旨在说明稀疏恢复中的一个关键概念。\n\n### 步骤 3：结论和行动\n问题有效。将提供完整解答。\n\n### 解答\n\n目标是解决两个不同的稀疏恢复问题，一个基于分析模型，另一个基于合成模型，并针对给定的真实信号 $x_{0}$ 和测量设置比较它们的解。\n\n**1. 分析模型恢复**\n\n分析模型旨在找到一个与测量值 $y = \\Phi x$ 一致且具有尽可能稀疏的分析表示 $\\Omega x$ 的信号 $x$。优化问题是：\n$$\n\\min_{x \\in \\mathbb{R}^{3}} \\|\\Omega x\\|_{1} \\quad \\text{subject to} \\quad y = \\Phi x\n$$\n给定 $y = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ 和 $\\Phi = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix}$。设 $x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$。约束条件 $y = \\Phi x$ 变为：\n$$\n\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}\n$$\n这意味着任何可行解都必须满足 $x_1 = 1$ 和 $x_2 = 1$。可行集是所有形如 $x = \\begin{pmatrix} 1 \\\\ 1 \\\\ z \\end{pmatrix}$（其中 $z \\in \\mathbb{R}$）的向量构成的仿射子空间。\n\n现在，我们对此类向量计算目标函数 $\\|\\Omega x\\|_{1}$：\n$$\n\\Omega x = \\begin{pmatrix} 1  -1  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ z \\end{pmatrix} = \\begin{pmatrix} (1)(1) + (-1)(1) + (0)(z) \\\\ (0)(1) + (0)(1) + (1)(z) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ z \\end{pmatrix}\n$$\n$\\ell_1$ 范数为 $\\|\\Omega x\\|_{1} = |0| + |z| = |z|$。\n优化问题简化为找到使 $|z|$ 最小的 $z$：\n$$\n\\min_{z \\in \\mathbb{R}} |z|\n$$\n最小值为 $0$，在 $z=0$ 时唯一达到。\n因此，分析问题的唯一极小化子是：\n$$\nx_{A}^{\\star} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n这正是真实信号 $x_{0}$。分析模型实现了精确恢复。对于此解，分析表示为 $\\Omega x_{A}^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，这是最稀疏的。$\\Omega x_{A}^{\\star}$ 的协支撑集是 $\\{1, 2\\}$。\n\n**2. 合成模型恢复**\n\n合成模型假设信号可以稀疏地表示为 $x = D\\alpha$，并寻求与测量值一致的最稀疏系数向量 $\\alpha$。问题是：\n$$\n\\min_{\\alpha \\in \\mathbb{R}^{2}} \\|\\alpha\\|_{1} \\quad \\text{subject to} \\quad y = \\Phi D \\alpha\n$$\n首先，我们计算有效测量矩阵 $\\Phi D$：\n$$\n\\Phi D = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\end{pmatrix}\n$$\n对于 $y = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ 和 $\\alpha = \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix}$，约束条件 $y = \\Phi D \\alpha$ 是：\n$$\n\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\end{pmatrix} \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix} = \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_1 \\end{pmatrix}\n$$\n这意味着 $\\alpha_1=1$，而 $\\alpha_2$ 可以是任何实数。$\\alpha$ 的可行集由所有形如 $\\alpha = \\begin{pmatrix} 1 \\\\ w \\end{pmatrix}$（其中 $w \\in \\mathbb{R}$）的向量组成。\n\n我们在此可行集上最小化目标函数 $\\|\\alpha\\|_{1}$：\n$$\n\\|\\alpha\\|_{1} = \\left\\| \\begin{pmatrix} 1 \\\\ w \\end{pmatrix} \\right\\|_{1} = |1| + |w| = 1 + |w|\n$$\n问题简化为 $\\min_{w \\in \\mathbb{R}} (1 + |w|)$。最小值为 $1$，在 $w=0$ 时唯一达到。\n因此，唯一的最优系数向量是：\n$$\n\\alpha^{\\star} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n通过合成模型恢复的信号是 $x_{S}^{\\star} = D \\alpha^{\\star}$：\n$$\nx_{S}^{\\star} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\n这个结果，$x_{S}^{\\star} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$，不等于真实信号 $x_{0} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$。合成模型未能实现精确恢复。\n\n失败的原因是真实信号 $x_0$ 在字典 $D$ 中没有稀疏表示。我们可以找到真实的系数向量 $\\alpha_0$ 使得 $x_0 = D\\alpha_0$：\n$$\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 1  1 \\end{pmatrix} \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix} \\implies \\alpha_1=1, \\alpha_1+\\alpha_2=0 \\implies \\alpha_2=-1\n$$\n所以，$\\alpha_0 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。$\\alpha_0$ 的支撑集是 $\\{1, 2\\}$。其 $\\ell_1$ 范数是 $\\|\\alpha_0\\|_{1} = |1| + |-1| = 2$。然而，合成恢复找到了一个不同的解 $\\alpha^{\\star} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，其范数更小，为 $\\|\\alpha^{\\star}\\|_{1} = 1$。对应于这个更稀疏表示的信号 $x_{S}^{\\star}$ 也满足测量值，因为 $\\Phi x_{S}^{\\star} = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = y$。$\\ell_1$ 最小化自然地偏好对应于范数较小的系数向量的解，但在本例中这是不正确的解。\n\n**3. 最终计算**\n\n我们计算两个恢复信号 $x_{A}^{\\star}$ 和 $x_{S}^{\\star}$ 之间的欧几里得距离的平方：\n$$\nx_{A}^{\\star} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad x_{S}^{\\star} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\n差向量是：\n$$\nx_{A}^{\\star} - x_{S}^{\\star} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -1 \\end{pmatrix}\n$$\n欧几里得距离的平方是：\n$$\n\\|x_{A}^{\\star} - x_{S}^{\\star}\\|_{2}^{2} = \\left\\| \\begin{pmatrix} 0 \\\\ 0 \\\\ -1 \\end{pmatrix} \\right\\|_{2}^{2} = 0^{2} + 0^{2} + (-1)^{2} = 1\n$$\n最终结果是 $1$。", "answer": "$$\\boxed{1}$$", "id": "3485109"}, {"introduction": "在理想的无噪声情况下，我们追求精确恢复。然而，在更现实的带噪场景中，我们通常使用诸如分析LASSO等正则化方法来求解。这些方法在增强稳定性的同时，会不可避免地引入估计偏差（bias）。这个练习[@problem_id:3485107]将引导你深入分析这一现象。你将首先从优化问题的KKT条件中识别出偏差的来源，然后推导并实施一种重要的“去偏”（debiasing）技术，通过在估计的零空间上求解最小二乘问题来校正初始估计。这个过程展示了从一个初步的稀疏估计到一个更精确结果的提炼过程，是信号处理实践中的一个核心技能。", "problem": "考虑线性观测模型 $y = A x_{0} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是已知测量矩阵，$x_{0} \\in \\mathbb{R}^{n}$ 是未知信号，$w \\in \\mathbb{R}^{m}$ 是噪声，以及一个固定的分析算子 $\\Omega \\in \\mathbb{R}^{p \\times n}$。对于正则化参数 $\\lambda > 0$，分析 $\\ell_{1}$ 估计量定义为解 $ \\widehat{x}_{\\lambda} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ \\tfrac{1}{2} \\|A x - y\\|_{2}^{2} + \\lambda \\|\\Omega x\\|_{1} \\right\\}$。令估计的余支撑集为索引集 $\\Lambda \\subset \\{1,\\dots,p\\}$，使得对所有 $i \\in \\Lambda$，都有 $(\\Omega \\widehat{x}_{\\lambda})_{i} = 0$，并定义余支撑子空间 $\\mathcal{S}_{\\Lambda} := \\{ x \\in \\mathbb{R}^{n} : \\Omega_{\\Lambda} x = 0 \\}$，其中 $\\Omega_{\\Lambda}$ 是由 $\\Omega$ 中索引为 $\\Lambda$ 的行组成的子矩阵。\n\n从凸最优化和线性代数的基本原理出发，完成以下任务。首先，使用 Karush–Kuhn–Tucker (KKT) 条件来刻画分析 $\\ell_{1}$ 问题的平稳性条件，并识别出相对于无正则化最小二乘解引入偏差的项。接下来，推导一个有原则的去偏步骤，该步骤通过在估计的余支撑子空间上求解一个约束最小二乘问题来重新拟合信号，即\n$$\nx_{\\mathrm{db}} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\|A x - y\\|_{2}^{2} \\quad \\text{约束条件为} \\quad \\Omega_{\\Lambda} x = 0,\n$$\n并在 $A$ 具有满列秩和 $\\Omega_{\\Lambda}$ 具有满行秩的假设下，获得 $x_{\\mathrm{db}}$ 的闭式表达式。\n\n最后，在一个具体案例中计算您得到的一般表达式，该案例中 $n = 3$, $m = 3$, $A = I_{3}$，$\\Omega \\in \\mathbb{R}^{2 \\times 3}$ 由下式给出\n$$\n\\Omega = \\begin{pmatrix}\n1  -1  0 \\\\\n0  1  -1\n\\end{pmatrix},\n$$\n数据无噪声 $w = 0$，测量向量 $y = \\begin{pmatrix} 3 \\\\ 1 \\\\ 2 \\end{pmatrix}$，以及一个估计的余支撑集 $\\Lambda = \\{1\\}$（意味着第一个分析系数被估计为零）。计算此实例的精确去偏估计 $x_{\\mathrm{db}}$。将最终答案表示为使用精确值的单个行向量。无需四舍五入。", "solution": "问题陈述已经过验证，被认为是科学上合理的、适定的和客观的。这是稀疏优化和信号处理领域的一个标准问题。所有必要的信息和条件都已提供，以得出一个唯一且有意义的解。\n\n按照要求，解答分为三个部分：分析 $\\ell_1$ 估计量的平稳性条件刻画，闭式去偏估计量的推导，以及针对一个具体实例的求值。\n\n**第一部分：平稳性条件和偏差识别**\n\n分析 $\\ell_1$ 估计问题定义为：\n$$\n\\widehat{x}_{\\lambda} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ F(x) := \\tfrac{1}{2} \\|A x - y\\|_{2}^{2} + \\lambda \\|\\Omega x\\|_{1} \\right\\}\n$$\n这是一个凸优化问题，因为目标函数 $F(x)$ 是一个凸二次项和一个凸（但不可微）的 $\\ell_1$ 项之和。一个向量 $\\widehat{x}_{\\lambda}$ 是 $F(x)$ 的一个极小值点，当且仅当零向量属于 $F$ 在 $\\widehat{x}_{\\lambda}$ 处的次微分。最优性条件是：\n$$\n0 \\in \\partial F(\\widehat{x}_{\\lambda})\n$$\n$F(x)$ 的次微分由可微部分的梯度和不可微部分的次微分之和给出：\n$$\n\\partial F(x) = \\nabla \\left( \\tfrac{1}{2} \\|A x - y\\|_{2}^{2} \\right) + \\lambda \\partial \\left( \\|\\Omega x\\|_{1} \\right)\n$$\n最小二乘项的梯度是 $A^T(Ax - y)$。复合函数 $\\|\\Omega x\\|_{1}$ 的次微分由次梯度的链式法则给出：$\\partial (\\|\\Omega \\cdot\\|_{1})(x) = \\Omega^T \\partial (\\|\\cdot\\|_{1})(\\Omega x)$。\n\n一个向量 $u \\in \\mathbb{R}^p$ 的 $\\ell_1$ 范数（记作 $\\partial \\|u\\|_1$）的次微分是向量 $s \\in \\mathbb{R}^p$ 的集合，使得对于每个分量 $i=1,\\dots,p$：\n$$\ns_i = \\begin{cases}\n\\text{sign}(u_i)  \\text{若 } u_i \\neq 0 \\\\\n\\in [-1, 1]  \\text{若 } u_i = 0\n\\end{cases}\n$$\n其中 $\\text{sign}(\\cdot)$ 是符号函数。\n\n因此，$\\widehat{x}_{\\lambda}$ 的最优性条件是必须存在一个向量 $s \\in \\partial (\\|\\cdot\\|_{1})(\\Omega \\widehat{x}_{\\lambda})$，使得：\n$$\nA^T(A \\widehat{x}_{\\lambda} - y) + \\lambda \\Omega^T s = 0\n$$\n这就是分析 $\\ell_1$ 问题的 Karush–Kuhn–Tucker (KKT) 平稳性条件。重新整理这个方程得到：\n$$\nA^T A \\widehat{x}_{\\lambda} = A^T y - \\lambda \\Omega^T s\n$$\n为了比较，我们记无正则化的最小二乘解为 $x_{\\text{LS}}$，它是正规方程组的解：\n$$\nA^T A x_{\\text{LS}} = A^T y\n$$\n通过比较这两个方程组，项 $-\\lambda \\Omega^T s$ 被识别为分析 $\\ell_1$ 估计量 $\\widehat{x}_{\\lambda}$ 相对于最小二乘解的偏差来源。该项系统地收缩分析系数 $\\Omega x$，这反过来又使 $x$ 本身的估计产生偏差。\n\n**第二部分：去偏估计量的推导**\n\n去偏步骤涉及求解以下约束最小二乘问题：\n$$\nx_{\\mathrm{db}} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\|A x - y\\|_{2}^{2} \\quad \\text{约束条件为} \\quad \\Omega_{\\Lambda} x = 0\n$$\n为了找到解，我们采用拉格朗日乘子法。目标函数是 $\\frac{1}{2}\\|Ax - y\\|_2^2$（因子 $\\frac{1}{2}$ 不改变极小值点，但简化了求导）。拉格朗日函数 $\\mathcal{L}(x, \\mu)$ 是：\n$$\n\\mathcal{L}(x, \\mu) = \\tfrac{1}{2} \\|A x - y\\|_{2}^{2} + \\mu^T (\\Omega_{\\Lambda} x)\n$$\n其中 $\\mu$ 是拉格朗日乘子向量。通过将拉格朗日函数对 $x$ 和 $\\mu$ 的梯度设为零，可以得到最优性的 KKT 条件。\n\n1.  $\\nabla_x \\mathcal{L}(x, \\mu) = A^T(A x - y) + \\Omega_{\\Lambda}^T \\mu = 0$\n2.  $\\nabla_\\mu \\mathcal{L}(x, \\mu) = \\Omega_{\\Lambda} x = 0$\n\n从第一个方程，我们可以用 $\\mu$ 来表示 $x$：\n$$\nA^T A x = A^T y - \\Omega_{\\Lambda}^T \\mu\n$$\n问题假设 $A$ 具有满列秩，这意味着 $A^T A$ 是可逆的。因此：\n$$\nx = (A^T A)^{-1} (A^T y - \\Omega_{\\Lambda}^T \\mu)\n$$\n将这个 $x$ 的表达式代入第二个 KKT 条件（约束方程）：\n$$\n\\Omega_{\\Lambda} \\left[ (A^T A)^{-1} (A^T y - \\Omega_{\\Lambda}^T \\mu) \\right] = 0\n$$\n展开并重新整理以求解 $\\mu$：\n$$\n\\Omega_{\\Lambda} (A^T A)^{-1} A^T y - \\Omega_{\\Lambda} (A^T A)^{-1} \\Omega_{\\Lambda}^T \\mu = 0\n$$\n$$\n\\left( \\Omega_{\\Lambda} (A^T A)^{-1} \\Omega_{\\Lambda}^T \\right) \\mu = \\Omega_{\\Lambda} (A^T A)^{-1} A^T y\n$$\n矩阵 $M = \\Omega_{\\Lambda} (A^T A)^{-1} \\Omega_{\\Lambda}^T$ 是可逆的。这是因为 $A^T A$ 是正定的，所以它的逆也是正定的。由于假设 $\\Omega_{\\Lambda}$ 具有满行秩，对于任何非零向量 $v$，我们有 $\\Omega_{\\Lambda}^T v \\neq 0$。因此，$v^T M v = (\\Omega_{\\Lambda}^T v)^T (A^T A)^{-1} (\\Omega_{\\Lambda}^T v) > 0$，这意味着 $M$ 是正定的，因此是可逆的。\n\n我们现在可以解出 $\\mu$：\n$$\n\\mu = \\left( \\Omega_{\\Lambda} (A^T A)^{-1} \\Omega_{\\Lambda}^T \\right)^{-1} \\Omega_{\\Lambda} (A^T A)^{-1} A^T y\n$$\n最后，我们将这个 $\\mu$ 的表达式代回 $x$ 的方程中，以获得去偏估计量 $x_{\\mathrm{db}}$ 的闭式解：\n$$\nx_{\\mathrm{db}} = (A^T A)^{-1} A^T y - (A^T A)^{-1} \\Omega_{\\Lambda}^T \\left( \\Omega_{\\Lambda} (A^T A)^{-1} \\Omega_{\\Lambda}^T \\right)^{-1} \\Omega_{\\Lambda} (A^T A)^{-1} A^T y\n$$\n\n**第三部分：具体案例的求值**\n\n我们被给予以下具体值：\n-   $n = 3$, $m = 3$\n-   $A = I_3$（$3 \\times 3$ 单位矩阵）\n-   $y = \\begin{pmatrix} 3 \\\\ 1 \\\\ 2 \\end{pmatrix}$\n-   $\\Omega = \\begin{pmatrix} 1  -1  0 \\\\ 0  1  -1 \\end{pmatrix}$\n-   $\\Lambda = \\{1\\}$\n\n$A$ 具有满列秩的假设是满足的，因为 $I_3$ 是可逆的。\n余支撑集 $\\Lambda = \\{1\\}$ 意味着我们选择 $\\Omega$ 的第一行来构成 $\\Omega_{\\Lambda}$：\n$$\n\\Omega_{\\Lambda} = \\begin{pmatrix} 1  -1  0 \\end{pmatrix}\n$$\n这个 $1 \\times 3$ 矩阵的秩为 $1$，因此它具有所要求的满行秩。\n\n当 $A = I_3$ 时，$x_{\\mathrm{db}}$ 的一般表达式中的各项显著简化：\n-   $A^T A = I_3^T I_3 = I_3$\n-   $(A^T A)^{-1} = I_3^{-1} = I_3$\n-   $(A^T A)^{-1} A^T y = I_3 y = y$\n\n将这些代入通用公式得到：\n$$\nx_{\\mathrm{db}} = y - I_3 \\Omega_{\\Lambda}^T (\\Omega_{\\Lambda} I_3 \\Omega_{\\Lambda}^T)^{-1} \\Omega_{\\Lambda} I_3 y = y - \\Omega_{\\Lambda}^T (\\Omega_{\\Lambda} \\Omega_{\\Lambda}^T)^{-1} \\Omega_{\\Lambda} y\n$$\n这是将 $y$ 正交投影到 $\\Omega_{\\Lambda}$ 的零空间（即子空间 $\\mathcal{S}_{\\Lambda}$）上的公式。\n\n现在，我们计算各个分量：\n-   $\\Omega_{\\Lambda} = \\begin{pmatrix} 1  -1  0 \\end{pmatrix}$\n-   $\\Omega_{\\Lambda}^T = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$\n-   $\\Omega_{\\Lambda} \\Omega_{\\Lambda}^T = \\begin{pmatrix} 1  -1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} = (1)(1) + (-1)(-1) + (0)(0) = 2$\n-   $(\\Omega_{\\Lambda} \\Omega_{\\Lambda}^T)^{-1} = (2)^{-1} = \\frac{1}{2}$\n-   $\\Omega_{\\Lambda} y = \\begin{pmatrix} 1  -1  0 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 1 \\\\ 2 \\end{pmatrix} = (1)(3) + (-1)(1) + (0)(2) = 2$\n\n现在，我们组合修正项：\n$$\n\\Omega_{\\Lambda}^T (\\Omega_{\\Lambda} \\Omega_{\\Lambda}^T)^{-1} \\Omega_{\\Lambda} y = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} \\left(\\frac{1}{2}\\right) (2) = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}\n$$\n最后，我们计算 $x_{\\mathrm{db}}$：\n$$\nx_{\\mathrm{db}} = y - \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 1 \\\\ 2 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 - 1 \\\\ 1 - (-1) \\\\ 2 - 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\\\ 2 \\end{pmatrix}\n$$\n问题要求将答案表示为单个行向量。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  2  2\n\\end{pmatrix}\n}\n$$", "id": "3485107"}]}