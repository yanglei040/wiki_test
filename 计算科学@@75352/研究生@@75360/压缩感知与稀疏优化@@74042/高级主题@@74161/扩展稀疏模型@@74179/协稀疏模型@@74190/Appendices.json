{"hands_on_practices": [{"introduction": "在理想情况下，如果我们预先知道了信号的真实余支撑（co-support），我们能达到的最佳恢复效果是什么？“神谕估计器”（oracle estimator）正是为了回答这个问题。这个练习将指导你求解一个约束最小二乘问题，这是在已知余支撑下恢复信号的核心方法，通过它你可以掌握分析模型中的基本优化技巧。[@problem_id:3486309]", "problem": "考虑压缩感知中的余稀疏性分析模型，其中分析算子 $\\Omega \\in \\mathbb{R}^{p \\times n}$ 作用于信号 $x \\in \\mathbb{R}^{n}$，余支撑集 $\\Lambda \\subseteq \\{1,2,\\dots,p\\}$ 是分析系数为零的索引集合，即 $\\Omega_{\\Lambda} x = 0$。当真实的余支撑集 $\\Lambda$ 已知时，神谕估计量定义为等式约束最小二乘问题 $\\min_{x \\in \\mathbb{R}^{n}} \\|A x - y\\|_{2}^{2}$（约束条件为 $\\Omega_{\\Lambda} x = 0$）的唯一最小化子 $x^{\\star}$。\n\n求解以下维度 $n=5$ 且测量次数 $m=3$ 的小实例。设分析算子 $\\Omega \\in \\mathbb{R}^{4 \\times 5}$ 为一阶差分算子\n$$\n\\Omega \\;=\\;\n\\begin{pmatrix}\n1  -1  0  0  0 \\\\\n0  1  -1  0  0 \\\\\n0  0  1  -1  0 \\\\\n0  0  0  1  -1\n\\end{pmatrix},\n$$\n设余支撑集为 $\\Lambda = \\{1,3,4\\}$，那么精确的线性约束为\n$$\n\\Omega_{\\Lambda} x = 0 \\quad \\Longleftrightarrow \\quad\n\\begin{cases}\nx_{1} - x_{2} = 0, \\\\\nx_{3} - x_{4} = 0, \\\\\nx_{4} - x_{5} = 0.\n\\end{cases}\n$$\n设测量算子 $A \\in \\mathbb{R}^{3 \\times 5}$ 和测量向量 $y \\in \\mathbb{R}^{3}$ 为\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1  0  1  0  0 \\\\\n0  1  0  1  0 \\\\\n0  0  0  0  1\n\\end{pmatrix},\n\\qquad\ny \\;=\\;\n\\begin{pmatrix}\n2 \\\\\n2 \\\\\n3\n\\end{pmatrix}.\n$$\n\n任务：\n1. 从第一性原理出发，通过构建拉格朗日函数和 Karush-Kuhn-Tucker (KKT) 系统，推导等式约束最小二乘的最优性条件，并显式求解得到的堆叠线性系统以获得神谕估计量 $x^{\\star}$。\n2. 通过计算垂直堆叠矩阵 $\\begin{pmatrix} A \\\\ \\Omega_{\\Lambda} \\end{pmatrix}$ 的秩来验证解的唯一性，并根据零空间的交集来解释结果。\n3. 报告神谕估计量第三个分量 $x^{\\star}_{3}$ 的值作为最终答案。\n\n无需四舍五入。请提交一个不带单位的实数作为最终答案。", "solution": "该问题经验证具有科学依据、是良定的、客观且完整的。这是压缩感知背景下优化和线性代数的一个标准练习。我将开始解题。\n\n该问题要求解神谕估计量 $x^{\\star} \\in \\mathbb{R}^{n}$，它是以下等式约束最小二乘问题的唯一解：\n$$ \\min_{x \\in \\mathbb{R}^{n}} \\|A x - y\\|_{2}^{2} \\quad \\text{subject to} \\quad \\Omega_{\\Lambda} x = 0 $$\n其中 $n=5$。测量算子 $A \\in \\mathbb{R}^{3 \\times 5}$ 和向量 $y \\in \\mathbb{R}^{3}$ 由下式给出：\n$$ A = \\begin{pmatrix} 1  0  1  0  0 \\\\ 0  1  0  1  0 \\\\ 0  0  0  0  1 \\end{pmatrix}, \\qquad y = \\begin{pmatrix} 2 \\\\ 2 \\\\ 3 \\end{pmatrix} $$\n分析算子为 $\\Omega \\in \\mathbb{R}^{4 \\times 5}$，余支撑集为 $\\Lambda = \\{1,3,4\\}$。约束矩阵 $\\Omega_{\\Lambda}$ 由 $\\Omega$ 中由 $\\Lambda$ 索引的行组成：\n$$ \\Omega_{\\Lambda} = \\begin{pmatrix} 1  -1  0  0  0 \\\\ 0  0  1  -1  0 \\\\ 0  0  0  1  -1 \\end{pmatrix} $$\n约束 $\\Omega_{\\Lambda} x = 0$ 对应于以下线性方程组：\n$$ \\begin{cases} x_{1} - x_{2} = 0 \\\\ x_{3} - x_{4} = 0 \\\\ x_{4} - x_{5} = 0 \\end{cases} $$\n\n**1. 最优性条件的推导与求解**\n\n为求解此约束优化问题，我们构建拉格朗日函数 $\\mathcal{L}(x, \\nu)$，其中 $\\nu \\in \\mathbb{R}^{3}$ 是拉格朗日乘子向量。目标函数为 $f(x) = \\|A x - y\\|_{2}^{2} = (Ax-y)^T(Ax-y)$。\n$$ \\mathcal{L}(x, \\nu) = \\|A x - y\\|_{2}^{2} + \\nu^T (\\Omega_{\\Lambda} x) $$\n最优性的 Karush-Kuhn-Tucker (KKT) 条件通过将拉格朗日函数关于 $x$ 和 $\\nu$ 的梯度设为零得到。\n\n关于 $x$ 的梯度为：\n$$ \\nabla_{x} \\mathcal{L}(x, \\nu) = \\nabla_{x} (x^T A^T A x - 2y^T A x + y^T y) + \\nabla_{x} (\\nu^T \\Omega_{\\Lambda} x) = 2A^T A x - 2A^T y + \\Omega_{\\Lambda}^T \\nu $$\n将其设为零，得到平稳性条件：\n$$ 2A^T A x + \\Omega_{\\Lambda}^T \\nu = 2A^T y $$\n关于 $\\nu$ 的梯度给出了原始可行性条件，即原始的约束条件：\n$$ \\nabla_{\\nu} \\mathcal{L}(x, \\nu) = \\Omega_{\\Lambda} x = 0 $$\n这两个条件构成了一个关于 $x$ 和 $\\nu$ 的线性方程组，称为 KKT 系统：\n$$ \\begin{pmatrix} 2A^T A  \\Omega_{\\Lambda}^T \\\\ \\Omega_{\\Lambda}  0 \\end{pmatrix} \\begin{pmatrix} x \\\\ \\nu \\end{pmatrix} = \\begin{pmatrix} 2A^T y \\\\ 0 \\end{pmatrix} $$\n这就完成了所要求的从第一性原理出发的推导。\n\n为了求解 $x^{\\star}$，我们可以直接利用约束来简化问题。约束条件意味着 $x_1 = x_2$ 和 $x_3 = x_4 = x_5$。这意味着解向量 $x^{\\star}$ 位于由向量 $(1, 1, 0, 0, 0)^T$ 和 $(0, 0, 1, 1, 1)^T$ 张成的子空间中。此子空间中的任意向量 $x$ 都可以参数化为 $x = (c_1, c_1, c_2, c_2, c_2)^T$，其中 $c_1, c_2 \\in \\mathbb{R}$ 为标量。\n\n将这种形式的 $x$ 代入表达式 $Ax$ 中：\n$$ Ax = \\begin{pmatrix} 1  0  1  0  0 \\\\ 0  1  0  1  0 \\\\ 0  0  0  0  1 \\end{pmatrix} \\begin{pmatrix} c_1 \\\\ c_1 \\\\ c_2 \\\\ c_2 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} c_1 + c_2 \\\\ c_1 + c_2 \\\\ c_2 \\end{pmatrix} $$\n目标函数变为关于 $c_1$ 和 $c_2$ 的函数：\n$$ \\|Ax - y\\|_{2}^{2} = \\left\\| \\begin{pmatrix} c_1 + c_2 \\\\ c_1 + c_2 \\\\ c_2 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 2 \\\\ 3 \\end{pmatrix} \\right\\|_{2}^{2} = 2(c_1 + c_2 - 2)^2 + (c_2 - 3)^2 $$\n这是一个关于 $c_1$ 和 $c_2$ 的无约束二次最小化问题。我们通过将偏导数设为零来求最小值：\n$$ \\frac{\\partial}{\\partial c_1} [2(c_1 + c_2 - 2)^2 + (c_2 - 3)^2] = 4(c_1 + c_2 - 2) = 0 $$\n$$ \\frac{\\partial}{\\partial c_2} [2(c_1 + c_2 - 2)^2 + (c_2 - 3)^2] = 4(c_1 + c_2 - 2) + 2(c_2 - 3) = 0 $$\n从第一个方程，我们得到 $c_1 + c_2 - 2 = 0$。将此代入第二个方程，得到：\n$$ 4(0) + 2(c_2 - 3) = 0 \\implies c_2 = 3 $$\n将 $c_2 = 3$ 代回 $c_1 + c_2 - 2 = 0$，得到 $c_1 + 3 - 2 = 0$，这意味着 $c_1 = -1$。\n\n因此，最优系数为 $c_1 = -1$ 和 $c_2 = 3$。神谕估计量为：\n$$ x^{\\star} = \\begin{pmatrix} c_1 \\\\ c_1 \\\\ c_2 \\\\ c_2 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\\\ 3 \\\\ 3 \\\\ 3 \\end{pmatrix} $$\n\n**2. 唯一性验证**\n\n如果由 $A$ 和 $\\Omega_{\\Lambda}$ 垂直堆叠而成的矩阵具有满列秩，那么解 $x^{\\star}$ 的唯一性就得到保证。设该矩阵为 $M$：\n$$ M = \\begin{pmatrix} A \\\\ \\Omega_{\\Lambda} \\end{pmatrix} = \\begin{pmatrix}\n1  0  1  0  0 \\\\\n0  1  0  1  0 \\\\\n0  0  0  0  1 \\\\\n1  -1  0  0  0 \\\\\n0  0  1  -1  0 \\\\\n0  0  0  1  -1\n\\end{pmatrix} $$\n这是一个 $6 \\times 5$ 的矩阵。如果它的秩为 $5$，则它具有满列秩，这等价于其零空间是平凡的，即 $\\text{ker}(M) = \\{0\\}$。我们来求解 $Mx=0$（其中 $x \\in \\mathbb{R}^5$）：\n1. $x_1 + x_3 = 0$\n2. $x_2 + x_4 = 0$\n3. $x_5 = 0$\n4. $x_1 - x_2 = 0 \\implies x_1 = x_2$\n5. $x_3 - x_4 = 0 \\implies x_3 = x_4$\n6. $x_4 - x_5 = 0 \\implies x_4 = x_5$\n\n从(3)式，得 $x_5 = 0$。利用(6)式，我们发现 $x_4 = 0$。利用(5)式，我们发现 $x_3 = 0$。利用(2)式，我们有 $x_2 + 0 = 0$，所以 $x_2 = 0$。最后，利用(4)式，我们得到 $x_1 = 0$。\n$Mx=0$ 的唯一解是 $x=(0,0,0,0,0)^T$。因此，$\\text{ker}(M)=\\{0\\}$ 且 $\\text{rank}(M) = 5$。\n这个条件等价于 $A$ 和 $\\Omega_{\\Lambda}$ 的零空间的交集是平凡的：$\\text{ker}(A) \\cap \\text{ker}(\\Omega_{\\Lambda}) = \\{0\\}$。这确保了最多只有一个向量 $x$ 同时满足测量模型和余稀疏性约束，从而保证了神谕问题的解的唯一性。\n\n**3. 最终答案**\n\n神谕估计量为 $x^{\\star} = (-1, -1, 3, 3, 3)^T$。第三个分量是 $x_3^{\\star}$。\n$$ x_3^{\\star} = 3 $$", "answer": "$$\\boxed{3}$$", "id": "3486309"}, {"introduction": "在实践中，确定信号的余支撑本身就是一个挑战。一个更深层次的问题是：一个信号的余支撑是唯一的吗？这个练习揭示了一个核心的模糊性问题：单个信号可能同时被多个不同的余支撑所零化。通过计算一个具体的“模糊性指数”，你将亲身体会到为何余支撑的估计本质上是困难的，并理解信号如何可能存在于多个分析子空间的交集中。[@problem_id:3486316]", "problem": "考虑压缩感知和稀疏优化中的余稀疏（分析）模型，其中分析算子 $\\Omega \\in \\mathbb{R}^{p \\times n}$ 通过对信号 $x \\in \\mathbb{R}^{n}$ 的消失约束 $\\Omega_{\\Lambda} x = 0$ 导出一个余支撑 $\\Lambda \\subset \\{1,\\dots,p\\}$。相关的分析子空间为 $\\mathcal{U}_{\\Lambda} \\triangleq \\{x \\in \\mathbb{R}^{n} : \\Omega_{\\Lambda} x = 0\\}$。对于不同的余支撑 $\\Lambda_{1} \\neq \\Lambda_{2}$，位于交集 $\\mathcal{U}_{\\Lambda_{1}} \\cap \\mathcal{U}_{\\Lambda_{2}}$ 中的信号表现出固有的余支撑模糊性。\n\n在 $\\mathbb{R}^{4}$ 中，考虑分析算子 $\\Omega \\in \\mathbb{R}^{5 \\times 4}$，其行向量为\n$$\nr_{1} = \\begin{bmatrix}1  0  0  0\\end{bmatrix},\\quad\nr_{2} = \\begin{bmatrix}0  1  0  0\\end{bmatrix},\\quad\nr_{3} = \\begin{bmatrix}0  1  1  0\\end{bmatrix},\\quad\nr_{4} = \\begin{bmatrix}1  0  -1  0\\end{bmatrix},\\quad\nr_{5} = \\begin{bmatrix}0  0  0  1\\end{bmatrix},\n$$\n因此\n$$\n\\Omega \\triangleq \\begin{bmatrix}\n1  0  0  0\\\\\n0  1  0  0\\\\\n0  1  1  0\\\\\n1  0  -1  0\\\\\n0  0  0  1\n\\end{bmatrix}.\n$$\n令 $x \\in \\mathbb{R}^{4}$ 为向量 $x = \\begin{bmatrix}0  0  0  1\\end{bmatrix}^{\\top}$。定义两个余支撑 $\\Lambda_{1} \\triangleq \\{1,2\\}$ 和 $\\Lambda_{2} \\triangleq \\{3,4\\}$。要求你仅根据余稀疏模型和线性代数子空间的定义进行推理，而不引用任何专门的辨识定理。\n\n定义 $x$ 的尺寸为 $\\ell$ 的模糊性指数为\n$$\nA_{\\ell}(x) \\triangleq \\left|\\left\\{\\Lambda \\subset \\{1,\\dots,5\\} : |\\Lambda| = \\ell,\\ \\Omega_{\\Lambda} x = 0\\right\\}\\right|,\n$$\n即，零化 $x$ 的势为 $\\ell$ 的不同余支撑的数量。\n\n仅使用基本定义和线性代数，确定对于上面给出的 $\\Omega$ 和 $x$，$A_{2}(x)$ 的值。在你的推理中，解释包含 $x$ 的两个不同子空间 $\\mathcal{U}_{\\Lambda_{1}}$ 和 $\\mathcal{U}_{\\Lambda_{2}}$ 的非平凡交集的存在，如何为那些通过选择在 $x$ 上响应为零的 $\\Omega$ 的行来显式估计余支撑的算法带来模糊性。你的最终输出必须是一个整数。不需要四舍五入，也不涉及单位。", "solution": "问题要求确定特定信号 $x \\in \\mathbb{R}^{4}$ 和分析算子 $\\Omega \\in \\mathbb{R}^{5 \\times 4}$ 的尺寸为 $2$ 的模糊性指数，记为 $A_{2}(x)$。分析算子 $\\Omega$ 由 $p=5$ 个行向量组成，记为 $r_i$（其中 $i \\in \\{1, 2, 3, 4, 5\\}$），并作用于 $n=4$ 维空间中的信号。\n\n尺寸为 $\\ell$ 的模糊性指数 $A_{\\ell}(x)$ 定义为零化信号 $x$ 的势为 $\\ell$ 的不同余支撑的数量。形式上，\n$$\nA_{\\ell}(x) \\triangleq \\left|\\left\\{\\Lambda \\subset \\{1,\\dots,p\\} : |\\Lambda| = \\ell,\\ \\Omega_{\\Lambda} x = 0\\right\\}\\right|\n$$\n对于本问题，我们关心的是 $\\ell=2$ 和 $p=5$ 的情况。因此，我们需要求出以下表达式的值：\n$$\nA_{2}(x) \\triangleq \\left|\\left\\{\\Lambda \\subset \\{1,\\dots,5\\} : |\\Lambda| = 2,\\ \\Omega_{\\Lambda} x = 0\\right\\}\\right|\n$$\n对于一个余支撑 $\\Lambda$，条件 $\\Omega_{\\Lambda} x = 0$ 等价于：对于 $\\Lambda$ 中的每个行索引 $i$，$\\Omega$ 的第 $i$ 行 $r_i$ 与向量 $x$ 的点积为零。也就是说，对于所有 $i \\in \\Lambda$，都有 $r_i x = 0$。\n\n我们的第一步是确定零化给定信号 $x = \\begin{bmatrix}0  0  0  1\\end{bmatrix}^{\\top}$ 的所有行索引的集合。记该集合为 $S_{x} \\triangleq \\{i \\in \\{1, \\dots, 5\\} : r_i x = 0\\}$。我们计算给定矩阵 $\\Omega$ 的每一行与 $x$ 的点积 $r_i x$：\n$$\n\\Omega = \\begin{bmatrix}\n1  0  0  0\\\\\n0  1  0  0\\\\\n0  1  1  0\\\\\n1  0  -1  0\\\\\n0  0  0  1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nr_1 \\\\ r_2 \\\\ r_3 \\\\ r_4 \\\\ r_5\n\\end{bmatrix}\n$$\n\n点积计算如下：\n$r_1 x = \\begin{bmatrix}1  0  0  0\\end{bmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix} = (1)(0) + (0)(0) + (0)(0) + (0)(1) = 0$。\n$r_2 x = \\begin{bmatrix}0  1  0  0\\end{bmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix} = (0)(0) + (1)(0) + (0)(0) + (0)(1) = 0$。\n$r_3 x = \\begin{bmatrix}0  1  1  0\\end{bmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix} = (0)(0) + (1)(0) + (1)(0) + (0)(1) = 0$。\n$r_4 x = \\begin{bmatrix}1  0  -1  0\\end{bmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix} = (1)(0) + (0)(0) + (-1)(0) + (0)(1) = 0$。\n$r_5 x = \\begin{bmatrix}0  0  0  1\\end{bmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix} = (0)(0) + (0)(0) + (0)(0) + (1)(1) = 1$。\n\n根据这些计算，我们看到零化 $x$ 的行是 $r_1, r_2, r_3$ 和 $r_4$。第五行 $r_5$ 不满足此条件。因此，零化行索引的集合是 $S_{x} = \\{1, 2, 3, 4\\}$。\n\n为了求得 $A_{2}(x)$，我们需要计算满足 $\\Omega_{\\Lambda} x = 0$ 的大小为 $|\\Lambda|=2$ 的子集 $\\Lambda \\subset \\{1, \\dots, 5\\}$ 的数量。该条件成立当且仅当 $\\Lambda$ 中的两个索引都来自集合 $S_x$。换句话说，$\\Lambda$ 必须是 $S_x$ 的一个包含2个元素的子集。\n\n集合 $S_{x}$ 是 $\\{1, 2, 3, 4\\}$，其势为 $|S_{x}| = 4$。我们需要求出 $S_{x}$ 的大小为 $2$ 的不同子集的数量。这是一个组合问题，可通过二项式系数“4选2”来解决：\n$$\nA_{2}(x) = \\binom{|S_x|}{2} = \\binom{4}{2} = \\frac{4!}{2!(4-2)!} = \\frac{4!}{2!2!} = \\frac{4 \\times 3}{2 \\times 1} = 6\n$$\n这六个大小为 $2$ 的不同余支撑是：$\\{1,2\\}, \\{1,3\\}, \\{1,4\\}, \\{2,3\\}, \\{2,4\\}$ 和 $\\{3,4\\}$。\n\n问题陈述给出了两个示例余支撑，$\\Lambda_1=\\{1,2\\}$ 和 $\\Lambda_2=\\{3,4\\}$。我们的计算证实了它们确实是信号 $x$ 的有效余支撑。存在不止一个（本例中有六个）这样的余支撑，这说明了余支撑模糊性的概念。信号 $x$ 位于多个不同分析子空间的交集中，例如 $x \\in \\mathcal{U}_{\\Lambda_1} \\cap \\mathcal{U}_{\\Lambda_2}$。如果一个算法试图通过观察 $\\Omega$ 的哪些行零化了 $x$ 来估计余支撑，它会发现索引为 $\\{1,2,3,4\\}$ 的所有行都产生零响应。如果该算法旨在寻找一个大小为 2 的余支撑，它将面临 6 个同样有效的选择，并且没有进一步的信息来区分它们。这种由 $A_2(x)=6$ 量化的模糊性是余稀疏模型中的一个基本挑战，表明信号 $x$ 不能通过单个大小为 2 的余支撑被唯一辨识。", "answer": "$$\\boxed{6}$$", "id": "3486316"}, {"introduction": "从理论走向实践，我们将探讨分析稀疏模型最成功的应用之一：全变分（Total Variation, TV）正则化。当无法获得“神谕”信息时，我们通过求解一个凸优化问题来估计信号，该问题在数据保真度和分析系数的稀疏性之间取得平衡。这个练习将带你推导并求解一个TV正则化问题，这是处理非光滑优化和恢复分段常数信号的关键技术。[@problem_id:3486321]", "problem": "考虑压缩感知中的分析稀疏模型，其目标是寻找一个信号 $x \\in \\mathbb{R}^{n}$，使得其分析系数 $B x$ 相对于一个固定的线性算子 $B$ 是稀疏的。在一维情况下，一个常见的选择是一阶差分算子，它通过全变分（TV）正则化来导出分段常数解。给定一个测量算子 $A \\in \\mathbb{R}^{m \\times n}$ 和观测数据 $y \\in \\mathbb{R}^{m}$，TV正则化估计量被定义为以下凸目标函数的唯一最小化子：\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|B x\\|_{1},\n$$\n其中 $\\lambda > 0$ 是一个正则化参数，$B \\in \\mathbb{R}^{(n-1) \\times n}$ 是一维前向差分矩阵。\n\n求解特定情况 $n=5$, $A = I_{5}$, $\\lambda = 2$ 且\n$$\ny = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\n令 $B \\in \\mathbb{R}^{4 \\times 5}$ 为一维差分矩阵，其行向量分别为 $(-1, 1, 0, 0, 0)$、$(0, -1, 1, 0, 0)$、$(0, 0, -1, 1, 0)$ 和 $(0, 0, 0, -1, 1)$，使得 $(B x)_{i} = x_{i+1} - x_{i}$ (其中 $i=1,2,3,4$)。\n\n从凸优化的基本原理和次梯度的定义出发，推导此问题的 Karush–Kuhn–Tucker (KKT) 条件，为给定的 $n=5$ 实例显式地写出这些条件，并用它们来计算 TV 正则化估计量 $\\widehat{x}$。将最终估计量表示为一个各项为有理数的精确行向量。无需四舍五入，也不涉及单位。", "solution": "用户给出的问题是一个基于压缩感知和凸优化原理的有效优化问题。所有参数都定义良好，且该问题是适定的。\n\n该问题是找到目标函数 $F(x)$ 的唯一最小化子 $\\widehat{x}$：\n$$\nF(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|B x\\|_{1}\n$$\n根据给定的参数 $n=5$、$A=I_5$、$\\lambda=2$ 和 $y = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\\\ 1 \\\\ 0 \\end{pmatrix}$，目标函数变为：\n$$\nF(x) = \\frac{1}{2}\\|x - y\\|_{2}^{2} + 2 \\|B x\\|_{1}\n$$\n其中 $x \\in \\mathbb{R}^{5}$ 且 $B \\in \\mathbb{R}^{4 \\times 5}$ 是一阶前向差分矩阵。项 $\\frac{1}{2}\\|x - y\\|_{2}^{2}$ 是严格凸且可微的。项 $2\\|Bx\\|_{1}$ 是凸的，但并非处处可微。因此，和函数 $F(x)$ 是严格凸的，这保证了唯一最小化子 $\\widehat{x}$ 的存在性。\n\n一个点 $\\widehat{x}$ 成为 $F(x)$ 的最小化子的一阶充要条件是，零向量必须包含在 $F(x)$ 于 $\\widehat{x}$ 处的次微分中：\n$$\n0 \\in \\partial F(\\widehat{x})\n$$\n两个凸函数之和的次微分是它们各自次微分的和（根据 Moreau-Rockafellar 定理）。第一项是可微的，所以它的次微分就是它的梯度。\n$$\n\\partial F(x) = \\nabla \\left(\\frac{1}{2}\\|x - y\\|_{2}^{2}\\right) + \\partial \\left(2\\|B x\\|_{1}\\right)\n$$\n第一项的梯度是 $\\nabla \\left(\\frac{1}{2}\\|x-y\\|_2^2\\right) = x-y$。\n对于第二项，我们使用次微分的链式法则。如果 $h(x) = g(L(x))$，其中 $g(z) = 2\\|z\\|_1$ 且 $L(x) = Bx$，那么 $\\partial h(x) = L^T \\partial g(L(x))$。这里，$L^T = B^T$。\n$g(z) = 2\\|z\\|_1$ 的次微分是一个向量集合 $v \\in \\mathbb{R}^{4}$，使得对于每个分量 $v_i$：\n\\begin{itemize}\n    \\item 如果 $z_i \\neq 0$，则 $v_i = 2 \\cdot \\text{sign}(z_i)$\n    \\item 如果 $z_i = 0$，则 $v_i \\in [-2, 2]$\n\\end{itemize}\n其中 $z=Bx$。综合这些，最优性条件 $0 \\in \\partial F(\\widehat{x})$ 变为：\n$$\n0 \\in (\\widehat{x} - y) + B^T v\n$$\n其中 $v$ 是 $\\mathbb{R}^4$ 中的一个向量，其分量 $v_i$ 在 $z=B\\widehat{x}$ 的情况下满足上述条件。这可以写成：\n$$\ny - \\widehat{x} = B^T v\n$$\n这些就是该问题的 Karush–Kuhn–Tucker (KKT) 条件。让我们为 $n=5$ 的情况显式地写出它们。矩阵 $B^T$ 是：\n$$\nB^T = \\begin{pmatrix} -1  0  0  0 \\\\ 1  -1  0  0 \\\\ 0  1  -1  0 \\\\ 0  0  1  -1 \\\\ 0  0  0  1 \\end{pmatrix}\n$$\n方程 $y - \\widehat{x} = B^T v$ 按分量写出是：\n\\begin{align*}\ny_1 - \\widehat{x}_1 = -v_1 \\\\\ny_2 - \\widehat{x}_2 = v_1 - v_2 \\\\\ny_3 - \\widehat{x}_3 = v_2 - v_3 \\\\\ny_4 - \\widehat{x}_4 = v_3 - v_4 \\\\\ny_5 - \\widehat{x}_5 = v_4\n\\end{align*}\n$B^T$ 的一个关键性质是其列向量之和为零向量，这意味着 $\\mathbf{1}^T B^T = \\mathbf{0}^T$。因此，用 $\\mathbf{1}^T$ 左乘 KKT 方程：\n$$\n\\mathbf{1}^T (y - \\widehat{x}) = \\mathbf{1}^T (B^T v) = (\\mathbf{1}^T B^T) v = \\mathbf{0}^T v = 0\n$$\n这给出了关于解 $\\widehat{x}$ 的一个重要条件：\n$$\n\\sum_{i=1}^{5} (y_i - \\widehat{x}_i) = 0 \\implies \\sum_{i=1}^{5} \\widehat{x}_i = \\sum_{i=1}^{5} y_i\n$$\n给定数据向量 $y$ 的分量之和为 $\\sum y_i = 1+2+2+1+0 = 6$。因此，我们必须有 $\\sum \\widehat{x}_i = 6$。\n\n全变分正则化的性质表明解 $\\widehat{x}$ 是分段常数。一个简单的假设是解是完全常数的，即对于所有 $i=1, \\dots, 5$，都有 $\\widehat{x}_i = c$。\n如果 $\\widehat{x} = c \\cdot \\mathbf{1}$，则 $\\sum \\widehat{x}_i = 5c$。根据上述条件，$5c = 6$，可得 $c = \\frac{6}{5}$。\n所以，我们来检验候选解 $\\widehat{x} = (\\frac{6}{5}, \\frac{6}{5}, \\frac{6}{5}, \\frac{6}{5}, \\frac{6}{5})^T$。\n\n对于这个候选解，所有的差分都为零：$(B\\widehat{x})_i = \\widehat{x}_{i+1} - \\widehat{x}_i = 0$ (其中 $i=1,2,3,4$)。\n根据 KKT 条件，这要求存在一个向量 $v \\in \\mathbb{R}^4$，使得 $y - \\widehat{x} = B^T v$ 并且其所有分量都满足 $|v_i| \\le \\lambda=2$。\n\n让我们计算残差向量 $r = y - \\widehat{x}$：\n$$\nr = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\\\ 1 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 6/5 \\\\ 6/5 \\\\ 6/5 \\\\ 6/5 \\\\ 6/5 \\end{pmatrix} = \\begin{pmatrix} 1 - 6/5 \\\\ 2 - 6/5 \\\\ 2 - 6/5 \\\\ 1 - 6/5 \\\\ 0 - 6/5 \\end{pmatrix} = \\begin{pmatrix} -1/5 \\\\ 4/5 \\\\ 4/5 \\\\ -1/5 \\\\ -6/5 \\end{pmatrix}\n$$\n现在我们必须从系统 $r = B^T v$ 中求解 $v$：\n\\begin{align*}\n-v_1 = r_1 = -1/5 \\implies v_1 = 1/5 \\\\\nv_1 - v_2 = r_2 = 4/5 \\implies 1/5 - v_2 = 4/5 \\implies v_2 = -3/5 \\\\\nv_2 - v_3 = r_3 = 4/5 \\implies -3/5 - v_3 = 4/5 \\implies v_3 = -7/5 \\\\\nv_3 - v_4 = r_4 = -1/5 \\implies -7/5 - v_4 = -1/5 \\implies v_4 = -6/5 \\\\\nv_4 = r_5 = -6/5\n\\end{align*}\n该系统是相容的，并给出 $v$ 的唯一解：\n$$\nv = \\begin{pmatrix} 1/5 \\\\ -3/5 \\\\ -7/5 \\\\ -6/5 \\end{pmatrix}\n$$\n最后一步是检查该向量 $v$ 是否满足次梯度条件，在本例中该条件为对所有 $i=1,2,3,4$ 都有 $|v_i| \\le 2$。\n\\begin{itemize}\n    \\item $|v_1| = |1/5| = 1/5 \\le 2$\n    \\item $|v_2| = |-3/5| = 3/5 \\le 2$\n    \\item $|v_3| = |-7/5| = 7/5 \\le 2$\n    \\item $|v_4| = |-6/5| = 6/5 \\le 2$\n\\end{itemize}\n所有条件都得到满足。因为我们找到了一个满足此严格凸问题 KKT 条件的解对 $(\\widehat{x}, v)$，所以我们已经找到了唯一的最小化子。\n\nTV 正则化估计量是 $\\widehat{x} = (\\frac{6}{5}, \\frac{6}{5}, \\frac{6}{5}, \\frac{6}{5}, \\frac{6}{5})^T$。问题要求将答案表示为一个各项为有理数的精确行向量。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{6}{5}  \\frac{6}{5}  \\frac{6}{5}  \\frac{6}{5}  \\frac{6}{5} \\end{pmatrix}}\n$$", "id": "3486321"}]}