{"hands_on_practices": [{"introduction": "高斯过程（Gaussian Processes, GPs）是构建机器学习势（MLP）的一种强大的非参数贝叶斯方法。它不仅能预测原子系统的能量，还能为其预测提供一个有理论原则的、量化的不确定性度量，即后验方差。本练习将指导你从基本原理出发，推导该方差的表达式，并实践如何通过计算覆盖率来检验模型的预测不确定性是否经过良好校准，这是建立对模型预测信任度的关键步骤。[@problem_id:3500259]", "problem": "您面临一个原子间能量的监督学习问题，其中高斯过程（GP）回归模型被用作非参数化机器学习势（MLP），以模拟密度泛函理论（DFT）的能量。设潜在能量函数由 $f(\\mathbf{R})$ 表示，对应于构型描述符 $\\mathbf{R}$。设训练观测值为 $y_i = f(\\mathbf{R}_i) + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma_n^2)$ 是独立的高斯测量误差。假设一个零均值高斯过程（GP）先验 $f \\sim \\mathcal{GP}(0, k(\\cdot,\\cdot))$，其核函数为平方指数核：\n$$\nk(\\mathbf{R},\\mathbf{R}') = s^2 \\exp\\left(-\\tfrac{1}{2}\\left\\|\\tfrac{\\mathbf{R}-\\mathbf{R}'}{\\ell}\\right\\|^2\\right),\n$$\n其中 $s^2$ 是信号方差，$\\ell$ 是特征长度尺度。在此问题中，您将 (i) 推导在测试输入下潜函数的 GP 后验方差，以及 (ii) 通过计算 DFT 能量在两倍标准差贝叶斯可信区间内的经验覆盖率来评估模型的校准性。\n\n请从基本原理出发：训练潜输出和测试潜输出的先验的联合高斯性，以及观测值的加性高斯噪声模型。使用多元正态条件作用和高斯线性性质，不要引用任何未经证明的简便公式。\n\n您必须实现一个完整、可运行的程序，该程序能够：\n- 根据提供的核函数和超参数构建格拉姆矩阵。\n- 计算测试描述符 $\\mathbf{R}_*$ 处潜函数 $f(\\mathbf{R}_*)$ 的后验均值 $\\mu(\\mathbf{R}_*)$ 和后验方差 $\\sigma^2(\\mathbf{R}_*)$。\n- 为了计算覆盖率，将密度泛函理论（DFT）能量视为潜函数的无噪声实现。也就是说，在定义2-标准差区间时，仅使用潜函数预测方差（不包括观测噪声）。\n- 计算每个构型组（体相、表面、缺陷）的经验覆盖率，以小数形式表示，定义为该组中 DFT 能量落在 $[\\mu(\\mathbf{R}_*) - 2\\sigma(\\mathbf{R}_*), \\mu(\\mathbf{R}_*) + 2\\sigma(\\mathbf{R}_*)]$ 区间内的测试点所占的比例。\n- 计算所有组的总覆盖率。\n- 打印单独一行，内容为一个方括号括起来的逗号分隔列表，顺序为 $[\\text{体相覆盖率}, \\text{表面覆盖率}, \\text{缺陷覆盖率}, \\text{总覆盖率}]$，其中每个条目四舍五入到三位小数，不含百分号。\n\n所有能量必须以电子伏特（缩写为 $\\text{eV}$）为单位进行处理和报告。不使用角度。覆盖率值必须表示为四舍五入到三位小数的小数形式。\n\n请使用以下核函数超参数和数据集。描述符是一维无量纲的（因此将 $\\mathbf{R}$ 写为 $R$）。核函数超参数为：\n- 信号方差 $s^2 = 0.25$（单位 $\\text{eV}^2$），\n- 长度尺度 $\\ell = 0.6$（无量纲），\n- 观测噪声标准差 $\\sigma_n = 0.02$（单位 $\\text{eV}$），因此 $\\sigma_n^2 = 0.0004$（单位 $\\text{eV}^2$）。\n\n训练数据 $(R_i, E_i)$，其中 $E_i$ 的单位为 $\\text{eV}$：\n- $R_{\\text{train}} = [0.00, 0.25, 0.55, 0.90, 1.20, 1.50]$,\n- $E_{\\text{train}} = [1.00000, 0.90625, 0.81025, 0.72100, 0.66400, 0.62500]$.\n\n按构型类别分组的测试集，其中 $R$ 无量纲，$E$ 的单位为 $\\text{eV}$：\n- 体相：$R_{\\text{bulk}} = [0.10, 0.60, 1.00]$, $E_{\\text{bulk}} = [0.96100, 0.79600, 0.70000]$.\n- 表面：$R_{\\text{surface}} = [1.10, 1.20, 1.60]$, $E_{\\text{surface}} = [0.68100, 0.66400, 0.61600]$.\n- 缺陷：$R_{\\text{defect}} = [1.80, 2.20, 2.60]$, $E_{\\text{defect}} = [0.60400, 0.60400, 0.63600]$.\n\n您的程序应生成单行输出，包含一个方括号括起来的逗号分隔列表形式的结果（例如，$[0.667,0.667,1.000,0.778]$）。这些条目必须按顺序对应于体相、表面、缺陷和总覆盖率的小数形式，每个值都四舍五入到三位小数。不允许有其他输出。", "solution": "该问题是有效的，因为它具有科学依据、提法明确且客观。它为高斯过程（GP）回归在计算材料科学中的一个标准应用提供了一套完整且一致的数据和参数。任务定义清晰且计算上是可行的。我们将着手解决此问题。\n\n问题的核心是，给定一组带噪声的训练观测值，为一个由高斯过程建模的潜在能量函数 $f(R)$ 推导其后验分布，然后利用该后验分布评估模型的不确定性校准情况。\n\n设训练数据为一组 $N$ 对样本 $\\{ (R_i, y_i) \\}_{i=1}^N$，其中 $R_i$ 是描述符值，$y_i$ 是相应的带噪声的能量观测值。我们将训练输入的集合表示为 $X = \\{R_1, \\dots, R_N\\}$，训练观测值的向量表示为 $\\mathbf{y} = [y_1, \\dots, y_N]^T$。同样，设测试输入为 $M$ 个新的描述符值，表示为 $X_* = \\{R_{*,1}, \\dots, R_{*,M}\\}$，我们希望在这些点上预测潜函数值 $\\mathbf{f}_* = [f(R_{*,1}), \\dots, f(R_{*,M})]^T$。\n\n该模型由两个主要部分定义：GP 先验和似然。\n\n1.  **GP 先验**：假设潜函数 $f$ 服从高斯过程先验，$f \\sim \\mathcal{GP}(m(R), k(R, R'))$。问题指定了零均值先验，因此 $m(R) = 0$。核函数为平方指数核：\n    $$\n    k(R, R') = s^2 \\exp\\left(-\\frac{(R-R')^2}{2\\ell^2}\\right)\n    $$\n    其中 $s^2$ 是信号方差，$\\ell$ 是特征长度尺度。根据 GP 的定义，任何有限个函数值的集合都服从联合高斯分布。设 $\\mathbf{f}$ 为训练输入 $X$ 处的潜函数值向量。在训练输入 $\\mathbf{f}$ 和测试输入 $\\mathbf{f}_*$ 上的潜函数值的联合先验分布由下式给出：\n    $$\n    \\begin{pmatrix} \\mathbf{f} \\\\ \\mathbf{f}_* \\end{pmatrix}\n    \\sim \\mathcal{N} \\left(\n        \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix},\n        \\begin{pmatrix} K(X, X)  K(X, X_*) \\\\ K(X_*, X)  K(X_*, X_*) \\end{pmatrix}\n    \\right)\n    $$\n    这里，$K(A, B)$ 表示集合 $A$ 和 $B$ 中所有点之间核函数求值组成的矩阵。为简洁起见，我们使用记号 $K = K(X, X)$、$K_* = K(X, X_*)$ 和 $K_{**} = K(X_*, X_*)$。注意 $K(X_*, X) = K_*^T$。\n\n2.  **似然**：训练观测值 $y_i$ 通过一个加性的、独立同分布的高斯噪声模型与潜函数值 $f(R_i)$ 相关联：\n    $$\n    y_i = f(R_i) + \\varepsilon_i, \\quad \\text{其中} \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2)\n    $$\n    以向量形式表示为 $\\mathbf{y} = \\mathbf{f} + \\boldsymbol{\\varepsilon}$，其中 $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_n^2 I)$，$I$ 是 $N \\times N$ 的单位矩阵。\n\n从这两个部分，我们推导后验分布 $p(\\mathbf{f}_* | X, \\mathbf{y}, X_*)$。推导过程首先需要找到可观测值 $\\mathbf{y}$ 和待预测量 $\\mathbf{f}_*$ 的联合分布。由于 $\\mathbf{f}$ 和 $\\boldsymbol{\\varepsilon}$ 是独立的高斯向量，它们的和 $\\mathbf{y}$ 也是高斯分布的。因此，$(\\mathbf{y}, \\mathbf{f}_*)$ 的联合分布是一个多元正态分布。其均值为：\n$$\nE\\left[\\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{f}_* \\end{pmatrix}\\right] = \\begin{pmatrix} E[\\mathbf{f} + \\boldsymbol{\\varepsilon}] \\\\ E[\\mathbf{f}_*] \\end{pmatrix} = \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix}\n$$\n协方差矩阵为：\n$$\n\\text{Cov}\\left(\\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{f}_* \\end{pmatrix}\\right) =\n\\begin{pmatrix}\n\\text{Cov}(\\mathbf{y})  \\text{Cov}(\\mathbf{y}, \\mathbf{f}_*) \\\\\n\\text{Cov}(\\mathbf{f}_*, \\mathbf{y})  \\text{Cov}(\\mathbf{f}_*)\n\\end{pmatrix}\n$$\n该矩阵的块为：\n- $\\text{Cov}(\\mathbf{y}) = \\text{Cov}(\\mathbf{f} + \\boldsymbol{\\varepsilon}) = \\text{Cov}(\\mathbf{f}) + \\text{Cov}(\\boldsymbol{\\varepsilon}) = K + \\sigma_n^2 I$。\n- $\\text{Cov}(\\mathbf{f}_*) = K_{**}$。\n- $\\text{Cov}(\\mathbf{y}, \\mathbf{f}_*) = \\text{Cov}(\\mathbf{f} + \\boldsymbol{\\varepsilon}, \\mathbf{f}_*) = \\text{Cov}(\\mathbf{f}, \\mathbf{f}_*) + \\text{Cov}(\\boldsymbol{\\varepsilon}, \\mathbf{f}_*) = K_* + \\mathbf{0} = K_*$。\n- $\\text{Cov}(\\mathbf{f}_*, \\mathbf{y}) = \\text{Cov}(\\mathbf{y}, \\mathbf{f}_*)^T = K_*^T$。\n所以，联合分布为：\n$$\n\\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{f}_* \\end{pmatrix}\n\\sim \\mathcal{N} \\left(\n    \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix},\n    \\begin{pmatrix} K + \\sigma_n^2 I  K_* \\\\ K_*^T  K_{**} \\end{pmatrix}\n\\right)\n$$\n为了找到给定观测值 $\\mathbf{y}$ 时 $\\mathbf{f}_*$ 的后验分布，我们使用标准的多元高斯条件分布规则。对于一个联合高斯分布 $\\begin{pmatrix} \\mathbf{a} \\\\ \\mathbf{b} \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} \\boldsymbol{\\mu}_a \\\\ \\boldsymbol{\\mu}_b \\end{pmatrix}, \\begin{pmatrix} \\Sigma_{aa}  \\Sigma_{ab} \\\\ \\Sigma_{ba}  \\Sigma_{bb} \\end{pmatrix} \\right)$，条件分布 $p(\\mathbf{b}|\\mathbf{a})$ 是一个高斯分布，其均值为 $\\boldsymbol{\\mu}_{b|a} = \\boldsymbol{\\mu}_b + \\Sigma_{ba} \\Sigma_{aa}^{-1} (\\mathbf{a} - \\boldsymbol{\\mu}_a)$，协方差为 $\\Sigma_{b|a} = \\Sigma_{bb} - \\Sigma_{ba} \\Sigma_{aa}^{-1} \\Sigma_{ab}$。\n\n将此规则应用于我们的情况（令 $\\mathbf{a}=\\mathbf{y}$ 和 $\\mathbf{b}=\\mathbf{f}_*$, 且均值为零），后验分布 $p(\\mathbf{f}_* | X, \\mathbf{y}, X_*)$ 是一个高斯分布 $\\mathcal{N}(\\boldsymbol{\\mu}_*, \\Sigma_*)$，其中：\n- 后验均值：$\\boldsymbol{\\mu}_* = K_*^T (K + \\sigma_n^2 I)^{-1} \\mathbf{y}$\n- 后验协方差：$\\Sigma_* = K_{**} - K_*^T (K + \\sigma_n^2 I)^{-1} K_*$\n\n对于单个测试点 $R_*$，这些表达式得以简化。$K_*$ 变成一个向量 $\\mathbf{k}_* = [k(R_1, R_*), \\dots, k(R_N, R_*)]^T$，$K_{**}$ 变成标量 $k_{**} = k(R_*, R_*)$。潜函数值 $f(R_*)$ 的后验分布为 $\\mathcal{N}(\\mu(R_*), \\sigma^2(R_*))$，其中：\n- 后验均值：$\\mu(R_*) = \\mathbf{k}_*^T (K + \\sigma_n^2 I)^{-1} \\mathbf{y}$\n- 后验方差（潜函数的）：$\\sigma^2(R_*) = k_{**} - \\mathbf{k}_*^T (K + \\sigma_n^2 I)^{-1} \\mathbf{k}_*$\n\n这个后验方差 $\\sigma^2(R_*)$ 量化了模型对*潜函数值* $f(R_*)$ 估计的不确定性，不包括观测噪声。问题要求基于此潜函数方差构建一个可信区间。对于 $f(R_*)$ 的一个 $2$-标准差可信区间由 $[\\mu(R_*) - 2\\sigma(R_*), \\mu(R_*) + 2\\sigma(R_*)]$ 给出。\n\n然后为每组测试构型计算经验覆盖率。对于一个给定的包含 $M$ 个测试点的组，我们计算有多少个真实的 DFT 能量 $E_{*,j}$ 落在它们对应的可信区间内：\n$$\n\\text{覆盖率} = \\frac{1}{M} \\sum_{j=1}^M \\mathbb{I} \\left( E_{*,j} \\in [\\mu(R_{*,j}) - 2\\sigma(R_{*,j}), \\mu(R_{*,j}) + 2\\sigma(R_{*,j})] \\right)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。实现将为“体相”、“表面”和“缺陷”组以及所有测试点的组合计算此值。为了数值稳定性，矩阵求逆 $(K + \\sigma_n^2 I)^{-1}$ 通过求解线性方程组来完成，最好是使用 Cholesky 分解。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import cholesky, cho_solve\n\ndef solve():\n    \"\"\"\n    Computes the empirical coverage of a Gaussian Process regression model\n    for emulating Density Functional Theory (DFT) energies.\n    \"\"\"\n    \n    # 1. Define kernel hyperparameters and dataset as per the problem statement.\n    # All energies are in eV. Descriptor R is dimensionless.\n    s2 = 0.25         # Signal variance, in eV^2\n    ell = 0.6         # Characteristic length scale, dimensionless\n    sigma_n2 = 0.0004 # Observation noise variance, in eV^2\n    \n    # Training data\n    R_train = np.array([0.00, 0.25, 0.55, 0.90, 1.20, 1.50]).reshape(-1, 1)\n    E_train = np.array([1.00000, 0.90625, 0.81025, 0.72100, 0.66400, 0.62500])\n\n    # Test suite grouped by configuration class\n    test_suite = {\n        \"bulk\": (np.array([0.10, 0.60, 1.00]), np.array([0.96100, 0.79600, 0.70000])),\n        \"surface\": (np.array([1.10, 1.20, 1.60]), np.array([0.68100, 0.66400, 0.61600])),\n        \"defect\": (np.array([1.80, 2.20, 2.60]), np.array([0.60400, 0.60400, 0.63600]))\n    }\n\n    # 2. Define the squared-exponential kernel function.\n    def squared_exp_kernel(X1, X2, s2_param, l2_param):\n        \"\"\"\n        Computes the squared-exponential kernel matrix between two sets of 1D inputs.\n        X1: (N, 1) array\n        X2: (M, 1) array\n        Returns: (N, M) kernel matrix\n        \"\"\"\n        # Broadcasting (X1 - X2.T) creates an (N, M) matrix of pairwise differences.\n        sq_dist_matrix = (X1 - X2.T)**2\n        return s2_param * np.exp(-0.5 * sq_dist_matrix / l2_param)\n\n    # 3. Perform one-time pre-computation for the GP model.\n    l2 = ell**2\n    K_train = squared_exp_kernel(R_train, R_train, s2, l2)\n    Ky = K_train + sigma_n2 * np.eye(len(R_train))\n\n    # For numerical stability, use Cholesky decomposition to solve linear systems\n    # involving the inverse of Ky. L is the lower-triangular Cholesky factor.\n    try:\n        L = cholesky(Ky, lower=True)\n    except np.linalg.LinAlgError:\n        # This case should not be reached with the given valid parameters.\n        # Fallback for robustness.\n        print(\"Error: The covariance matrix Ky is not positive definite.\")\n        return\n\n    # Pre-compute alpha = Ky^-1 * y\n    alpha = cho_solve((L, True), E_train)\n\n    # 4. Calculate coverage for each test group and overall.\n    coverages = {}\n    all_R_test = []\n    all_E_test = []\n\n    def calculate_coverage(R_test, E_test):\n        \"\"\"Helper function to compute coverage for a given test set.\"\"\"\n        if len(R_test) == 0:\n            return 0.0\n\n        M = len(R_test)\n        R_test_reshaped = R_test.reshape(-1, 1)\n        \n        # Vectorized prediction for all test points\n        k_star_matrix = squared_exp_kernel(R_train, R_test_reshaped, s2, l2)\n        \n        # Posterior mean\n        mu_star_vector = k_star_matrix.T @ alpha\n        \n        # Posterior variance (of the latent function)\n        # We need the diagonal of K_** - K_*^T Ky^-1 K_*.\n        # diag(K_**): is just s2 for all test points.\n        # diag(K_*^T Ky^-1 K_*): can be computed efficiently.\n        # Let v = Ky^-1 K_*. Then the diagonal is sum(K_* * v, axis=0).\n        v = cho_solve((L, True), k_star_matrix)\n        var_star_vector = s2 - np.sum(k_star_matrix * v, axis=0)\n        \n        # Correct for potential minor numerical precision issues\n        var_star_vector[var_star_vector < 0] = 0\n        sigma_star_vector = np.sqrt(var_star_vector)\n\n        # Define 2-sigma credible intervals\n        lower_bounds = mu_star_vector - 2 * sigma_star_vector\n        upper_bounds = mu_star_vector + 2 * sigma_star_vector\n        \n        # Check which true energies fall within the intervals\n        covered_mask = (E_test >= lower_bounds) & (E_test <= upper_bounds)\n        \n        return np.mean(covered_mask)\n\n    for group_name, (R_group, E_group) in test_suite.items():\n        coverages[group_name] = calculate_coverage(R_group, E_group)\n        all_R_test.append(R_group)\n        all_E_test.append(E_group)\n        \n    # Overall coverage calculation\n    R_overall = np.concatenate(all_R_test)\n    E_overall = np.concatenate(all_E_test)\n    coverages['overall'] = calculate_coverage(R_overall, E_overall)\n    \n    # 5. Format and print the final result.\n    output_values = [\n        round(coverages['bulk'], 3),\n        round(coverages['surface'], 3),\n        round(coverages['defect'], 3),\n        round(coverages['overall'], 3),\n    ]\n\n    # Print in the required format: [val1,val2,val3,val4]\n    print(f\"[{','.join(f'{x:.3f}' for x in output_values)}]\")\n\nsolve()\n```", "id": "3500259"}, {"introduction": "共形预测（Conformal Prediction, CP）是另一种主流的不确定性量化框架，它无需对数据分布做严格假设。其核心优势在于能够为有限样本提供具有理论保证的预测覆盖率，这与依赖特定概率模型的贝叶斯方法形成鲜明对比。本练习将演示如何将共形预测应用于机器学习势中的标量（能量）和矢量（力）输出，并通过构造具有严格覆盖保证的预测集，来处理材料模拟中的实际挑战。[@problem_id:3500185]", "problem": "给定从机器学习势（MLP）中派生出的用于计算材料建模中原子间能量和力的校准数据和测试数据。任务是在非符合性分数的标准可交换性假设下，为名义水平为 $1-\\alpha = 0.9$ 构建分裂保形预测集。具体来说，将能量视为标量目标，将力视为每个原子构型具有三个分量的矢量目标。\n\n您必须从核心定义出发：\n- 目标 $y$ 的机器学习预测表示为 $\\hat{y}$，绝对残差定义为 $r = |y - \\hat{y}|$。\n- 标量目标的非符合性分数可以取绝对残差 $a = r$。\n- 在由输入 $x$ 的可用不确定性代理 $s(x)$ 驱动的异方差性下，可以定义一个尺度自适应的非符合性分数 $a = r / s(x)$，并且保形集的半宽度按 $s(x)$ 进行缩放。\n- 对于具有分量 $f \\in \\mathbb{R}^3$ 的矢量值力和预测 $\\hat{f} \\in \\mathbb{R}^3$，使用最大范数非符合性 $a = \\max_{j \\in \\{1,2,3\\}} |f_j - \\hat{f}_j|$。\n\n给定一个在独立于测试集的数据上计算的非符合性分数校准集，并将其视为与测试非符合性分数可交换，为测试点构建分裂保形集，以在水平 $1-\\alpha$ 下实现有限样本边际覆盖。\n\n您的程序必须：\n1. 对于每个测试用例，使用有限样本分裂保形构造方法，从校准非符合性分数中计算保形阈值。\n2. 将阈值应用于测试集以形成预测集：\n   - 对于标量能量，该集合是一个以预测为中心的闭区间，其半宽度等于阈值（在异方差情况下为缩放后的半宽度）。\n   - 对于力，该集合是一个以预测为中心的三维轴对齐超矩形，其每个分量的半宽度等于阈值。\n3. 计算测试集上的经验覆盖率，即落入其保形集内的测试目标的比例。将覆盖率表示为小数。\n4. 计算平均集合大小：\n   - 对于标量能量，报告以电子伏特（eV）为单位的平均区间宽度。\n   - 对于矢量力，报告以 $(\\mathrm{eV}/\\mathrm{\\AA})^3$ 为单位的平均超矩形体积。\n5. 对所有测试用例使用 $1-\\alpha = 0.9$（即 $\\alpha = 0.1$）。\n6. 生成单行输出，其中包含一个逗号分隔的列表的列表，其中每个内部列表包含两个浮点数 $[\\text{coverage}, \\text{average\\_set\\_size}]$，并用方括号括起来（例如，$[[0.9,0.06],[0.95,0.05]]$）。\n\n物理单位：\n- 能量以电子伏特 $\\mathrm{eV}$ 表示。\n- 力以 $\\mathrm{eV}/\\mathrm{\\AA}$ 表示。\n- 力集體積以 $(\\mathrm{eV}/\\mathrm{\\AA})^3$ 表示。\n- 此问题不涉及角度。\n- 将覆盖率表示为小数；不要使用百分号。\n\n测试套件：\n实现以下四个测试用例。所有数值必须完全按照提供的值使用。\n\n情况 $1$（标量能量，同方差绝对残差）：\n- 校准残差 $r_{\\text{cal}}$（单位：$\\mathrm{eV}$）：\n  $[0.012, 0.015, 0.017, 0.020, 0.022, 0.018, 0.025, 0.027, 0.019, 0.021, 0.023, 0.026, 0.028, 0.024, 0.016, 0.030, 0.029, 0.013, 0.014, 0.031]$。\n- 测试预测能量 $\\hat{y}_{\\text{test}}$（单位：$\\mathrm{eV}$）：\n  $[1.250, 0.980, 1.105, 1.320, 0.875, 1.050, 1.200, 1.015, 1.275, 0.940]$。\n- 测试真实能量 $y_{\\text{test}}$（单位：$\\mathrm{eV}$）：\n  $[1.270, 0.960, 1.125, 1.315, 0.900, 1.040, 1.195, 1.040, 1.290, 0.905]$。\n\n情况 $2$（标量能量，带尺度因子的异方差）：\n- 校准尺度 $s_{\\text{cal}}$（无单位不确定性代理）：\n  $[0.8, 1.2, 1.0, 1.5, 0.9, 1.1, 0.7, 1.3, 1.4, 0.6, 0.95, 1.25, 0.85, 1.35, 1.05, 1.15, 0.75, 1.05, 1.2, 0.9]$。\n- 校准残差 $r_{\\text{cal}}$（单位：$\\mathrm{eV}$）：\n  $[0.016, 0.030, 0.030, 0.0525, 0.036, 0.0495, 0.035, 0.0715, 0.084, 0.039, 0.0665, 0.09375, 0.068, 0.11475, 0.0945, 0.10925, 0.075, 0.11025, 0.132, 0.1035]$。\n- 测试尺度 $s_{\\text{test}}$：\n  $[1.0, 0.8, 1.2, 0.9, 1.5, 1.1, 0.7, 1.3, 0.6, 1.4]$。\n- 测试预测能量 $\\hat{y}_{\\text{test}}$（单位：$\\mathrm{eV}$）：\n  $[0.50, 1.00, 0.80, 1.20, 1.10, 0.90, 1.30, 1.00, 0.70, 1.40]$。\n- 测试真实能量 $y_{\\text{test}}$（单位：$\\mathrm{eV}$）通过设置为以下值来得到指定的绝对残差 $[0.09, 0.08, 0.10, 0.07, 0.18, 0.08, 0.06, 0.14, 0.05, 0.13]$：\n  $[0.59, 0.92, 0.90, 1.27, 0.92, 0.98, 1.24, 1.14, 0.65, 1.53]$。\n\n情况 $3$（标量能量，带有零残差的退化校准）：\n- 校准残差 $r_{\\text{cal}}$（单位：$\\mathrm{eV}$）：\n  $[0.0, 0.0, 0.0, 0.0, 0.0]$。\n- 测试预测能量 $\\hat{y}_{\\text{test}}$（单位：$\\mathrm{eV}$）：\n  $[0.50, 0.60, 0.70, 0.80, 0.90]$。\n- 测试真实能量 $y_{\\text{test}}$（单位：$\\mathrm{eV}$）：\n  $[0.52, 0.58, 0.74, 0.79, 0.94]$。\n\n情况 $4$（矢量力，最大范数非符合性）：\n- 校准预测力 $\\hat{f}_{\\text{cal}}$（每个条目单位为 $\\mathrm{eV}/\\mathrm{\\AA}$）：\n  $[[0.10, -0.05, 0.02], [0.08, 0.03, -0.01], [0.12, -0.02, 0.00], [-0.06, 0.07, 0.05], [0.03, -0.04, 0.02], [-0.02, 0.01, -0.05], [0.00, 0.02, 0.03], [-0.04, -0.02, 0.01], [0.02, 0.00, -0.03], [0.06, -0.06, 0.04], [0.01, 0.05, -0.02], [-0.03, 0.00, 0.02]]$。\n- 校准真实力 $f_{\\text{cal}}$（每个条目单位为 $\\mathrm{eV}/\\mathrm{\\AA}$）：\n  $[[0.11, -0.07, 0.02], [0.05, 0.03, -0.01], [0.12, 0.02, -0.04], [-0.01, 0.06, 0.03], [0.065, -0.04, 0.02], [-0.02, -0.05, -0.05], [0.025, 0.01, 0.03], [0.015, -0.02, 0.00], [-0.025, 0.00, -0.045], [0.06, 0.01, 0.02], [0.075, 0.04, -0.02], [0.05, 0.00, 0.02]]$。\n- 测试预测力 $\\hat{f}_{\\text{test}}$（每个条目单位为 $\\mathrm{eV}/\\mathrm{\\AA}$）：\n  $[[0.02, -0.01, 0.00], [0.00, 0.03, -0.02], [0.05, -0.04, 0.01], [0.01, 0.00, 0.03], [-0.02, 0.02, -0.01], [0.04, -0.03, 0.00]]$。\n- 测试真实力 $f_{\\text{test}}$（每个条目单位为 $\\mathrm{eV}/\\mathrm{\\AA}$）：\n  $[[0.07, -0.01, 0.00], [0.00, 0.07, -0.02], [0.11, -0.04, 0.01], [-0.02, 0.00, 0.03], [-0.09, 0.02, -0.01], [0.12, -0.03, 0.00]]$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例的结果总结为 $[\\text{coverage},\\text{average\\_set\\_size}]$，按四个情况的顺序排列。例如：$[[\\text{cov1},\\text{size1}],[\\text{cov2},\\text{size2}],[\\text{cov3},\\text{size3}],[\\text{cov4},\\text{size4}]]$。", "solution": "该问题要求使用分裂保形预测方法，为机器学习的原子间能量和力构建和评估预测集。该方法在校准数据和测试数据之间可交换的假设下，为边际覆盖率提供有限样本保证。我们给定的名义覆盖水平为 $1-\\alpha = 0.9$，这意味着错误覆盖率为 $\\alpha = 0.1$。\n\n分裂保形预测的核心在于使用一组非符合性分数来校准模型的不确定性。非符合性分数，表示为 $a(x, y)$，量化了模型对输入 $x$ 的预测与相应真实目标 $y$ 之间的不一致性。基本假设是，在留出的校准集上计算的非符合性分数与新测试点的分数是可交换的。\n\n设校准集为 $\\{ (x_i, y_i) \\}_{i=1}^{n}$。我们首先计算一组 $n$ 个非符合性分数 $\\{a_1, a_2, \\dots, a_n\\}$，其中 $a_i = a(x_i, y_i)$。对于期望的覆盖水平 $1-\\alpha$，保形阈值 $q$ 由这些校准分数的经验分布确定。具体来说，$q$ 是校准分数的第 $k$ 个顺序统计量，其中秩 $k$ 由以下公式给出：\n$$k = \\lceil(n+1)(1-\\alpha)\\rceil$$\n设排序后的校准分数为 $a_{(1)} \\le a_{(2)} \\le \\dots \\le a_{(n)}$。阈值为 $q = a_{(k)}$。如果计算结果为 $k > n$（这可能在 $n$ 较小和 $1-\\alpha$ 较高时发生），则无法保证期望的覆盖水平。在这种实际实现中，阈值通常取为观测到的最大校准分数 $q = a_{(n)}$，对应于最保守的有限选择。对于一个从0开始索引的已排序分数数组，这对应于选择索引为 $\\min(k-1, n-1)$ 的元素。\n\n一旦确定了 $q$，就为新的测试点 $x_{\\text{test}}$ 构建一个预测集 $C(x_{\\text{test}})$，该集合包含所有可能的目標值 $y'$，其非符合性分数不超过阈值 $q$：\n$$C(x_{\\text{test}}) = \\{ y' \\mid a(x_{\\text{test}}, y') \\le q \\}$$\n通过这种构造，保证真实目标 $y_{\\text{test}}$ 落入此集合的概率至少为 $1-\\alpha$。\n\n该问题提出了四种不同的情况，它们利用了非符合性分数和目标变量类型的不同定义。\n\n**情况1：同方差标量能量**\n非符合性分数是绝对残差：$a = |y - \\hat{y}|$。校准分数是所提供的残差 $r_{\\text{cal}}$。对于测试预测 $\\hat{y}_{\\text{test}}$，其预测集是一个区间：\n$$C(\\hat{y}_{\\text{test}}) = \\{y' \\mid |y' - \\hat{y}_{\\text{test}}| \\le q \\} = [\\hat{y}_{\\text{test}} - q, \\hat{y}_{\\text{test}} + q]$$\n此区间的宽度为 $2q$。经验覆盖率是真实能量 $y_{\\text{test}}$ 满足 $|y_{\\text{test}} - \\hat{y}_{\\text{test}}| \\le q$ 的测试点的比例。\n\n**情况2：异方差标量能量**\n模型的不确定性随输入而变化，由一个尺度因子 $s(x)$ 捕捉。非符合性分数是缩放后的绝对残差：$a = |y - \\hat{y}| / s(x)$。预测集是一个区间，其宽度由测试点的不确定性代理 $s_{\\text{test}}$ 进行缩放：\n$$C(\\hat{y}_{\\text{test}}) = \\{y' \\mid |y' - \\hat{y}_{\\text{test}}|/s_{\\text{test}} \\le q \\} = [\\hat{y}_{\\text{test}} - q \\cdot s_{\\text{test}}, \\hat{y}_{\\text{test}} + q \\cdot s_{\\text{test}}]$$\n对于一个测试点 $i$，区间的宽度为 $2q \\cdot s_{\\text{test},i}$。平均集合大小是测试集上这些宽度的平均值。通过测试是否满足 $|y_{\\text{test}} - \\hat{y}_{\\text{test}}| / s_{\\text{test}} \\le q$ 来检查覆盖率。\n\n**情况3：退化校准**\n此情况在形式上与情况1相同，但其校准集中的所有残差均为 $0$。这测试了在退化条件下对阈值计算的处理。\n\n**情况4：矢量力**\n目标是一个三维力矢量 $f \\in \\mathbb{R}^3$。非符合性分数是矢量分量上的最大绝对误差（残差矢量的 $L_\\infty$ 范数或最大范数）：\n$$a = \\max_{j \\in \\{1,2,3\\}} |f_j - \\hat{f}_j|$$\n预测集是一个以预测 $\\hat{f}_{\\text{test}}$ 为中心的轴对齐超矩形（在此3D情况下为一个立方体）：\n$$C(\\hat{f}_{\\text{test}}) = \\{f' \\mid \\max_{j} |f'_j - \\hat{f}_{\\text{test},j}| \\le q \\}$$\n这等效于为每个分量 $j$ 构建一个区间 $[\\hat{f}_{\\text{test},j} - q, \\hat{f}_{\\text{test},j} + q]$。如果真实力矢量 $f_{\\text{test}}$ 完全位于此立方体内，则测试点被覆盖，这当且仅当 $\\max_j |f_{\\text{test},j} - \\hat{f}_{\\text{test},j}| \\le q$ 时成立。此超矩形的体积为 $(2q)^3$。\n\n对于所有情况，我们的步骤如下：\n1.  计算 $n$ 个校准非符合性分数集合 $\\{a_i\\}_{i=1}^n$。\n2.  当 $\\alpha=0.1$ 时，计算分位数秩 $k = \\lceil(n+1)(1-\\alpha)\\rceil$。\n3.  对分数进行排序，在适当的索引处找到阈值 $q$，并处理 $k>n$ 的边界情况。\n4.  对每个测试点，构建预测集并检查是否包含真实值。这是通过将测试非符合性分数与 $q$ 进行比较来完成的。\n5.  计算经验覆盖率，即被覆盖的测试点的比例。\n6.  计算整个测试集的平均集合大小（标量为宽度，矢量为体积）。\n此程序应用于所提供的四个测试用例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the conformal prediction problem for four specified test cases.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n\n    test_cases = [\n        # Case 1: scalar energies, homoscedastic\n        {\n            \"type\": \"scalar_homoscedastic\",\n            \"r_cal\": np.array([0.012, 0.015, 0.017, 0.020, 0.022, 0.018, 0.025, 0.027, 0.019, 0.021, 0.023, 0.026, 0.028, 0.024, 0.016, 0.030, 0.029, 0.013, 0.014, 0.031]),\n            \"y_hat_test\": np.array([1.250, 0.980, 1.105, 1.320, 0.875, 1.050, 1.200, 1.015, 1.275, 0.940]),\n            \"y_test\": np.array([1.270, 0.960, 1.125, 1.315, 0.900, 1.040, 1.195, 1.040, 1.290, 0.905]),\n        },\n        # Case 2: scalar energies, heteroscedastic\n        {\n            \"type\": \"scalar_heteroscedastic\",\n            \"s_cal\": np.array([0.8, 1.2, 1.0, 1.5, 0.9, 1.1, 0.7, 1.3, 1.4, 0.6, 0.95, 1.25, 0.85, 1.35, 1.05, 1.15, 0.75, 1.05, 1.2, 0.9]),\n            \"r_cal\": np.array([0.016, 0.030, 0.030, 0.0525, 0.036, 0.0495, 0.035, 0.0715, 0.084, 0.039, 0.0665, 0.09375, 0.068, 0.11475, 0.0945, 0.10925, 0.075, 0.11025, 0.132, 0.1035]),\n            \"s_test\": np.array([1.0, 0.8, 1.2, 0.9, 1.5, 1.1, 0.7, 1.3, 0.6, 1.4]),\n            \"y_hat_test\": np.array([0.50, 1.00, 0.80, 1.20, 1.10, 0.90, 1.30, 1.00, 0.70, 1.40]),\n            \"y_test\": np.array([0.59, 0.92, 0.90, 1.27, 0.92, 0.98, 1.24, 1.14, 0.65, 1.53]),\n        },\n        # Case 3: scalar energies, degenerate calibration\n        {\n            \"type\": \"scalar_homoscedastic\",\n            \"r_cal\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]),\n            \"y_hat_test\": np.array([0.50, 0.60, 0.70, 0.80, 0.90]),\n            \"y_test\": np.array([0.52, 0.58, 0.74, 0.79, 0.94]),\n        },\n        # Case 4: vector forces, max norm\n        {\n            \"type\": \"vector_max_norm\",\n            \"f_hat_cal\": np.array([[0.10, -0.05, 0.02], [0.08, 0.03, -0.01], [0.12, -0.02, 0.00], [-0.06, 0.07, 0.05], [0.03, -0.04, 0.02], [-0.02, 0.01, -0.05], [0.00, 0.02, 0.03], [-0.04, -0.02, 0.01], [0.02, 0.00, -0.03], [0.06, -0.06, 0.04], [0.01, 0.05, -0.02], [-0.03, 0.00, 0.02]]),\n            \"f_cal\": np.array([[0.11, -0.07, 0.02], [0.05, 0.03, -0.01], [0.12, 0.02, -0.04], [-0.01, 0.06, 0.03], [0.065, -0.04, 0.02], [-0.02, -0.05, -0.05], [0.025, 0.01, 0.03], [0.015, -0.02, 0.00], [-0.025, 0.00, -0.045], [0.06, 0.01, 0.02], [0.075, 0.04, -0.02], [0.05, 0.00, 0.02]]),\n            \"f_hat_test\": np.array([[0.02, -0.01, 0.00], [0.00, 0.03, -0.02], [0.05, -0.04, 0.01], [0.01, 0.00, 0.03], [-0.02, 0.02, -0.01], [0.04, -0.03, 0.00]]),\n            \"f_test\": np.array([[0.07, -0.01, 0.00], [0.00, 0.07, -0.02], [0.11, -0.04, 0.01], [-0.02, 0.00, 0.03], [-0.09, 0.02, -0.01], [0.12, -0.03, 0.00]]),\n        }\n    ]\n\n    alpha = 0.1\n    results = []\n\n    for case in test_cases:\n        # Step 1: Compute calibration nonconformity scores\n        if case[\"type\"] == \"scalar_homoscedastic\":\n            cal_scores = case[\"r_cal\"]\n        elif case[\"type\"] == \"scalar_heteroscedastic\":\n            cal_scores = case[\"r_cal\"] / case[\"s_cal\"]\n        elif case[\"type\"] == \"vector_max_norm\":\n            cal_residuals = np.abs(case[\"f_cal\"] - case[\"f_hat_cal\"])\n            cal_scores = np.max(cal_residuals, axis=1)\n        else:\n            raise ValueError(f\"Unknown case type: {case['type']}\")\n\n        # Step 2: Compute the conformal threshold q\n        n = len(cal_scores)\n        q_level_rank = np.ceil((n + 1) * (1 - alpha))\n        # For 0-based indexing, the index is rank-1.\n        # Handle the edge case where rank > n by taking the max score.\n        q_index = min(int(q_level_rank) - 1, n - 1)\n        \n        sorted_cal_scores = np.sort(cal_scores)\n        q = sorted_cal_scores[q_index]\n\n        # Step 3: Compute empirical coverage on the test set\n        if case[\"type\"] == \"scalar_homoscedastic\":\n            test_residuals = np.abs(case[\"y_test\"] - case[\"y_hat_test\"])\n            test_scores = test_residuals\n        elif case[\"type\"] == \"scalar_heteroscedastic\":\n            test_residuals = np.abs(case[\"y_test\"] - case[\"y_hat_test\"])\n            test_scores = test_residuals / case[\"s_test\"]\n        elif case[\"type\"] == \"vector_max_norm\":\n            test_residuals = np.abs(case[\"f_test\"] - case[\"f_hat_test\"])\n            test_scores = np.max(test_residuals, axis=1)\n        \n        covered = test_scores <= q\n        coverage = np.mean(covered)\n\n        # Step 4: Compute average set size\n        if case[\"type\"] == \"scalar_homoscedastic\":\n            avg_set_size = 2 * q\n        elif case[\"type\"] == \"scalar_heteroscedastic\":\n            set_widths = 2 * q * case[\"s_test\"]\n            avg_set_size = np.mean(set_widths)\n        elif case[\"type\"] == \"vector_max_norm\":\n            avg_set_size = (2 * q)**3\n            \n        results.append([coverage, avg_set_size])\n\n    # Final print statement in the exact required format.\n    print(f\"{results}\")\n\nsolve()\n```", "id": "3500185"}, {"introduction": "在不确定性量化中，区分偶然不确定性（aleatoric uncertainty，源于数据固有的噪声）和认知不确定性（epistemic uncertainty，源于模型自身的局限性）至关重要。理解不确定性的来源是指导模型改进（例如通过主动学习）和评估模型可靠性的关键。这项高级实践将引导你运用一种精妙的统计方法，通过分析来自两种不同标记协议的残差数据，来分离这两种不确定性成分，从而让你能更深入地洞察模型的性能瓶颈。[@problem_id:3500186]", "problem": "给定来自密度泛函理论 (DFT) 的两种标注方案，它们应用于一个固定的机器学习势 (MLP) 架构的同一批留出构型。对于每个构型索引 $i \\in \\{1,\\dots,n\\}$，两种标注方案为相同的原子构型生成标量标签 $y_{1,i}$ 和 $y_{2,i}$，而 MLP 预测一个标量值 $\\mu_i$。定义残差 $r_{1,i} = y_{1,i} - \\mu_i$ 和 $r_{2,i} = y_{2,i} - \\mu_i$。假设一个加性随机效应模型，其中残差分解为 $r_{k,i} = e_i + \\varepsilon_{k,i}$（$k \\in \\{1,2\\}$）。这里，$e_i$ 是与 MLP 对构型 $i$ 的预测相关的认知误差分量，而 $\\varepsilon_{k,i}$ 是与第 $k$ 种 DFT 标注方案在构型 $i$ 上的偶然噪声分量。假设 $e_i$ 和 $\\varepsilon_{k,i}$ 在留出集上是零均值的，$\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 在给定 $i$ 的条件下是条件独立的，并且 $e_i$ 与每个 $\\varepsilon_{k,i}$ 都是独立的。\n\n您的任务是设计并实现一个单边假设检验，以评估在留出集中是否偶然噪声主导认知误差。使用方差、协方差和独立性的定义，根据一个能清晰比较认知方差与两种标注方案的平均偶然方差的参数来建立假设。仅依赖基本统计定义和经过充分检验的程序，从基本原理推导出一个检验统计量和一个在显著性水平 $\\alpha = 0.05$ 下的决策规则。您可以假设使用非参数配对自助法来量化抽样不确定性。\n\n您编写的程序必须为每个测试用例实现以下过程：\n- 根据提供的参数，使用指定的随机种子和分布，生成留出残差对 $\\{(r_{1,i}, r_{2,i})\\}_{i=1}^n$。\n- 使用生成的残差，仅基于方差和协方差的定义，构建认知方差的估计量以及两种标注方案的偶然方差的估计量。\n- 构建一个显著性水平为 $\\alpha = 0.05$ 的单边假设检验，其中选择的原假设使得“偶然噪声主导认知误差”对应于备择假设。使用具有 $B$ 次重采样的配对非参数自助法来评估检验统计量的不确定性，并实现一个决策规则，为每个测试用例返回一个布尔值，指示数据是否在 $\\alpha$ 水平上提供足够证据表明偶然噪声主导认知误差。\n- 在所有情况下，均使用恰好 $B = 2000$ 次自助法重采样。\n\n您必须考虑以下测试套件，其中所有随机数生成都必须使用指定的种子以确保确定性。每个测试用例指定 $n$ 和 $(e_i, \\varepsilon_{1,i}, \\varepsilon_{2,i})$ 的生成模型，程序必须相应地生成 $r_{k,i} = e_i + \\varepsilon_{k,i}$。\n\n- 案例 A（理想情况，偶然噪声明显主导）：$n = 800$。从方差为 $\\sigma_{\\mathrm{e}}^2 = 0.05$ 的正态分布中独立抽取 $e_i$，从方差为 $\\sigma_{\\mathrm{a1}}^2 = 0.20$ 的正态分布中独立抽取 $\\varepsilon_{1,i}$，从方差为 $\\sigma_{\\mathrm{a2}}^2 = 0.25$ 的正态分布中独立抽取 $\\varepsilon_{2,i}$。使用种子 $s = 10$。\n- 案例 B（认知误差主导）：$n = 800$。从方差为 $\\sigma_{\\mathrm{e}}^2 = 0.50$ 的正态分布中独立抽取 $e_i$，从方差为 $\\sigma_{\\mathrm{a1}}^2 = 0.05$ 的正态分布中独立抽取 $\\varepsilon_{1,i}$，从方差为 $\\sigma_{\\mathrm{a2}}^2 = 0.05$ 的正态分布中独立抽取 $\\varepsilon_{2,i}$。使用种子 $s = 20$。\n- 案例 C（边界情况，量级可比）：$n = 300$。从方差为 $\\sigma_{\\mathrm{e}}^2 = 0.10$ 的正态分布中独立抽取 $e_i$，从方差为 $\\sigma_{\\mathrm{a1}}^2 = 0.10$ 的正态分布中独立抽取 $\\varepsilon_{1,i}$，从方差为 $\\sigma_{\\mathrm{a2}}^2 = 0.10$ 的正态分布中独立抽取 $\\varepsilon_{2,i}$。使用种子 $s = 30$。\n- 案例 D（异方差偶然噪声，仍为偶然噪声主导）：$n = 1000$。从方差为 $\\sigma_{\\mathrm{e}}^2 = 0.02$ 的正态分布中独立抽取 $e_i$。对于 $i \\in \\{1,\\dots,n\\}$，从方差为 $\\sigma_{\\mathrm{a1},i}^2 = 0.20 \\times \\left(1 + 0.5 \\sin\\left(2\\pi i / n\\right)\\right)$ 的正态分布中独立抽取 $\\varepsilon_{1,i}$，并从方差为 $\\sigma_{\\mathrm{a2},i}^2 = 0.18 \\times \\left(1 - 0.5 \\cos\\left(2\\pi i / n\\right)\\right)$ 的正态分布中独立抽取 $\\varepsilon_{2,i}$。使用种子 $s = 40$。\n- 案例 E（零偶然噪声）：$n = 500$。从方差为 $\\sigma_{\\mathrm{e}}^2 = 0.10$ 的正态分布中独立抽取 $e_i$。对于所有 $i$，确定性地设置 $\\varepsilon_{1,i} = 0$ 和 $\\varepsilon_{2,i} = 0$。使用种子 $s = 50$。\n- 案例 F（具有小认知方差的重尾偶然噪声）：$n = 800$。从方差为 $\\sigma_{\\mathrm{e}}^2 = 0.01$ 的正态分布中独立抽取 $e_i$。从自由度为 $\\nu = 3$ 的学生t分布中独立抽取 $\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$，并分别进行缩放以使方差达到 $\\sigma_{\\mathrm{a1}}^2 = 0.25$ 和 $\\sigma_{\\mathrm{a2}}^2 = 0.25$。使用种子 $s = 60$。\n\n对于所有案例，将“偶然噪声主导认知误差”精确地解释为两种标注方案的平均偶然方差大于留出集上的认知方差，并据此设计您在显著性水平 $\\alpha = 0.05$ 下的单边假设检验。\n\n您的程序应生成单行输出，其中包含六个案例的结果，形式为方括号内以逗号分隔的布尔值列表（例如，`[True,False,True,True,False,True]`）。当且仅当您的检验在显著性水平 $\\alpha = 0.05$ 下得出案例 $k$ 的偶然噪声主导认知误差的结论时，第 $k$ 个布尔值必须为 `True`，否则为 `False`。不允许有其他输出。", "solution": "该问题要求设计并实现一个单边假设检验，以根据来自两种不同标注方案的残差，判断一个机器学习势的偶然噪声是否主导认知误差。对问题陈述的验证确认了其具有科学依据、是良定的，并包含了进行求解所需的所有必要信息。\n\n我们分析的基础是为标注方案 $k \\in \\{1, 2\\}$ 和构型 $i \\in \\{1, \\dots, n\\}$ 的残差 $r_{k,i}$ 所提供的加性随机效应模型：\n$$r_{k,i} = e_i + \\varepsilon_{k,i}$$\n此处，$e_i$ 是机器学习势在构型 $i$ 上的认知误差，而 $\\varepsilon_{k,i}$ 是来自第 $k$ 种标注方案的偶然噪声。问题陈述了关于这些误差分量的几个关键假设：\n1.  它们在总体上是零均值的：$E[e_i] = 0$ 且 $E[\\varepsilon_{k,i}] = 0$（对于 $k=1,2$）。\n2.  认知误差 $e_i$ 与两个偶然噪声分量 $\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 均独立。这意味着 $Cov(e_i, \\varepsilon_{k,i}) = 0$。\n3.  两个偶然噪声分量 $\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 在给定构型 $i$ 的条件下是条件独立的。这意味着 $Cov(\\varepsilon_{1,i}, \\varepsilon_{2,i}) = 0$。\n\n令 $\\sigma_e^2 = \\text{Var}(e_i)$、$\\sigma_{a1}^2 = \\text{Var}(\\varepsilon_{1,i})$ 和 $\\sigma_{a2}^2 = \\text{Var}(\\varepsilon_{2,i})$ 分别表示认知误差和偶然误差的总体方差。注意，对于具有异方差噪声的情况（如案例 D），$\\sigma_{ak}^2$ 表示所有构型上的平均方差。使用独立性假设，我们可以推导出每个残差序列的方差及其协方差的表达式。\n\n第一个残差序列的方差为：\n$$\\text{Var}(r_1) = \\text{Var}(e + \\varepsilon_1) = \\text{Var}(e) + \\text{Var}(\\varepsilon_1) + 2\\text{Cov}(e, \\varepsilon_1) = \\sigma_e^2 + \\sigma_{a1}^2$$\n类似地，第二个残差序列的方差为：\n$$\\text{Var}(r_2) = \\text{Var}(e + \\varepsilon_2) = \\text{Var}(e) + \\text{Var}(\\varepsilon_2) + 2\\text{Cov}(e, \\varepsilon_2) = \\sigma_e^2 + \\sigma_{a2}^2$$\n两个残差序列之间的协方差为：\n$$\\text{Cov}(r_1, r_2) = \\text{Cov}(e + \\varepsilon_1, e + \\varepsilon_2) = \\text{Cov}(e,e) + \\text{Cov}(e,\\varepsilon_2) + \\text{Cov}(\\varepsilon_1,e) + \\text{Cov}(\\varepsilon_1,\\varepsilon_2)$$\n根据独立性假设，所有交叉项均为零，且 $\\text{Cov}(e,e) = \\text{Var}(e)$。因此：\n$$\\text{Cov}(r_1, r_2) = \\sigma_e^2$$\n这提供了一种从可观测残差的协方差中直接识别认知方差的方法。然后我们可以求解偶然方差：\n$$\\sigma_{a1}^2 = \\text{Var}(r_1) - \\sigma_e^2 = \\text{Var}(r_1) - \\text{Cov}(r_1, r_2)$$\n$$\\sigma_{a2}^2 = \\text{Var}(r_2) - \\sigma_e^2 = \\text{Var}(r_2) - \\text{Cov}(r_1, r_2)$$\n问题将“偶然噪声主导认知误差”定义为平均偶然方差大于认知方差。令 $\\sigma_A^2 = (\\sigma_{a1}^2 + \\sigma_{a2}^2)/2$。该条件为 $\\sigma_A^2 > \\sigma_e^2$。\n\n我们构建一个单边假设检验。备择假设 $H_1$ 对应于我们感兴趣的主张：\n$$H_1: \\sigma_A^2 > \\sigma_e^2$$\n原假设 $H_0$ 是其补集：\n$$H_0: \\sigma_A^2 \\le \\sigma_e^2$$\n为了构建检验，我们定义一个参数 $\\theta = \\sigma_A^2 - \\sigma_e^2$。于是假设变为 $H_0: \\theta \\le 0$ 对 $H_1: \\theta > 0$。我们用可观测残差的矩来表示 $\\theta$：\n$$\\theta = \\frac{(\\text{Var}(r_1) - \\text{Cov}(r_1, r_2)) + (\\text{Var}(r_2) - \\text{Cov}(r_1, r_2))}{2} - \\text{Cov}(r_1, r_2)$$\n$$\\theta = \\frac{\\text{Var}(r_1) + \\text{Var}(r_2)}{2} - 2\\text{Cov}(r_1, r_2)$$\n我们的检验统计量 $\\hat{\\theta}$ 是 $\\theta$ 的矩估计量，使用从数据对 $\\{(r_{1,i}, r_{2,i})\\}_{i=1}^n$ 计算出的样本统计量得到。令 $\\widehat{\\text{Var}}$ 和 $\\widehat{\\text{Cov}}$ 表示标准无偏样本方差和协方差估计量（分母为 $n-1$）：\n$$\\hat{\\theta} = \\frac{\\widehat{\\text{Var}}(r_1) + \\widehat{\\text{Var}}(r_2)}{2} - 2\\widehat{\\text{Cov}}(r_1, r_2)$$\n一个大的正值 $\\hat{\\theta}$ 为 $H_1$ 提供了证据。我们需要确定观测值 $\\hat{\\theta}_{obs}$ 是否具有统计显著性。我们使用具有 $B=2000$ 次重采样的非参数配对自助法来评估 $\\hat{\\theta}$ 的抽样不确定性。假设检验将在 $\\alpha = 0.05$ 的显著性水平下进行。\n\n对 $H_0: \\theta \\le 0$ 与 $H_1: \\theta > 0$ 的检验可以通过反转 $\\theta$ 的单边置信区间来执行。我们将为 $\\theta$ 构建一个 $(1-\\alpha)$ 的置信下界。如果该下界大于 0，我们则拒绝 $H_0$。使用基本（枢轴）自助法，$\\hat{\\theta} - \\theta$ 的抽样分布可以通过 $\\hat{\\theta}^* - \\hat{\\theta}_{obs}$ 的自助分布来近似，其中 $\\hat{\\theta}^*$ 是在自助样本上计算的统计量。这导出了 $\\theta$ 的一个 $(1-\\alpha)$ 单边置信区间为 $[2\\hat{\\theta}_{obs} - q_{1-\\alpha}, \\infty)$，其中 $q_{1-\\alpha}$ 是自助分布 $\\{\\hat{\\theta}^*_b\\}_{b=1}^B$ 的 $(1-\\alpha)$-分位数。\n\n如果下界大于 0，我们拒绝 $H_0$：\n$$2\\hat{\\theta}_{obs} - q_{1-\\alpha} > 0 \\implies 2\\hat{\\theta}_{obs} > q_{1-\\alpha}$$\n对于 $\\alpha=0.05$，决策规则是：如果 $2\\hat{\\theta}_{obs}$ 大于 $\\hat{\\theta}^*$ 自助分布的第95百分位数，则拒绝 $H_0$。如果我们拒绝 $H_0$，我们得出结论：数据提供了充分的证据表明偶然噪声主导认知误差。\n\n每个测试用例的实现将按以下步骤进行：\n1.  根据指定的分布和随机种子生成 $n$ 个数据三元组 $(e_i, \\varepsilon_{1,i}, \\varepsilon_{2,i})$。\n2.  计算可观测残差 $r_{1,i} = e_i + \\varepsilon_{1,i}$ 和 $r_{2,i} = e_i + \\varepsilon_{2,i}$。\n3.  从数据对 $(r_{1,i}, r_{2,i})$ 计算观测到的检验统计量 $\\hat{\\theta}_{obs}$。\n4.  生成 $B = 2000$ 个配对自助样本。对每个自助样本，计算统计量 $\\hat{\\theta}^*_b$。\n5.  确定 $\\{\\hat{\\theta}^*_b\\}$ 经验分布的第95百分位数 $q_{0.95}$。\n6.  应用决策规则：如果 $2 \\times \\hat{\\theta}_{obs} > q_{0.95}$，则结果为 True；否则为 False。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to run hypothesis tests for all specified cases.\n    \"\"\"\n    test_cases = [\n        {\n            'case_id': 'A', 'n': 800, 'seed': 10, 'model': 'normal',\n            'params': {'var_e': 0.05, 'var_a1': 0.20, 'var_a2': 0.25}\n        },\n        {\n            'case_id': 'B', 'n': 800, 'seed': 20, 'model': 'normal',\n            'params': {'var_e': 0.50, 'var_a1': 0.05, 'var_a2': 0.05}\n        },\n        {\n            'case_id': 'C', 'n': 300, 'seed': 30, 'model': 'normal',\n            'params': {'var_e': 0.10, 'var_a1': 0.10, 'var_a2': 0.10}\n        },\n        {\n            'case_id': 'D', 'n': 1000, 'seed': 40, 'model': 'heteroscedastic',\n            'params': {'var_e': 0.02, 'var_a1_func': lambda i, n: 0.20 * (1 + 0.5 * np.sin(2 * np.pi * (i + 1) / n)),\n                       'var_a2_func': lambda i, n: 0.18 * (1 - 0.5 * np.cos(2 * np.pi * (i + 1) / n))}\n        },\n        {\n            'case_id': 'E', 'n': 500, 'seed': 50, 'model': 'zero_aleatoric',\n            'params': {'var_e': 0.10}\n        },\n        {\n            'case_id': 'F', 'n': 800, 'seed': 60, 'model': 'student_t',\n            'params': {'var_e': 0.01, 'var_a1': 0.25, 'var_a2': 0.25, 'df': 3}\n        },\n    ]\n\n    results = []\n    B = 2000  # Number of bootstrap resamples\n\n    for case in test_cases:\n        rng = np.random.default_rng(case['seed'])\n        n = case['n']\n        params = case['params']\n\n        # Generate error components based on the case model\n        if case['model'] == 'normal':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            eps1 = rng.normal(loc=0, scale=np.sqrt(params['var_a1']), size=n)\n            eps2 = rng.normal(loc=0, scale=np.sqrt(params['var_a2']), size=n)\n        elif case['model'] == 'heteroscedastic':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            indices = np.arange(n)\n            var_a1_i = params['var_a1_func'](indices, n)\n            var_a2_i = params['var_a2_func'](indices, n)\n            eps1 = rng.normal(loc=0, scale=np.sqrt(var_a1_i))\n            eps2 = rng.normal(loc=0, scale=np.sqrt(var_a2_i))\n        elif case['model'] == 'zero_aleatoric':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            eps1 = np.zeros(n)\n            eps2 = np.zeros(n)\n        elif case['model'] == 'student_t':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            df = params['df']\n            # Scale standard t-distribution to achieve target variance\n            # Var(c * T_df) = c^2 * df / (df - 2)\n            # c = sqrt(target_var * (df - 2) / df)\n            scale1 = np.sqrt(params['var_a1'] * (df - 2) / df)\n            scale2 = np.sqrt(params['var_a2'] * (df - 2) / df)\n            eps1 = scale1 * rng.standard_t(df, size=n)\n            eps2 = scale2 * rng.standard_t(df, size=n)\n\n        # Compute residuals\n        r1 = e + eps1\n        r2 = e + eps2\n\n        # Perform the hypothesis test\n        decision = perform_hypothesis_test(r1, r2, rng, B)\n        results.append(decision)\n\n    # Convert boolean to lowercase string for output\n    str_results = [str(r) for r in results]\n    print(f\"[{','.join(str_results)}]\")\n\ndef get_theta_hat(r1, r2):\n    \"\"\"\n    Calculates the test statistic theta_hat from a sample of residuals.\n    This function is designed to handle 2D arrays of resamples.\n    \"\"\"\n    n = r1.shape[-1]\n    \n    # Calculate means for each resample\n    mean1 = np.mean(r1, axis=-1, keepdims=True)\n    mean2 = np.mean(r2, axis=-1, keepdims=True)\n\n    # Calculate variances for each resample\n    var1 = np.sum((r1 - mean1)**2, axis=-1) / (n - 1)\n    var2 = np.sum((r2 - mean2)**2, axis=-1) / (n - 1)\n    \n    # Calculate covariances for each resample\n    cov12 = np.sum((r1 - mean1) * (r2 - mean2), axis=-1) / (n - 1)\n    \n    return (var1 + var2) / 2.0 - 2.0 * cov12\n\ndef perform_hypothesis_test(r1, r2, rng, B, alpha=0.05):\n    \"\"\"\n    Performs the one-sided hypothesis test using a paired nonparametric bootstrap.\n    \"\"\"\n    n = len(r1)\n\n    # Calculate observed test statistic\n    theta_obs = get_theta_hat(r1, r2)\n\n    # Generate bootstrap indices\n    bootstrap_indices = rng.integers(0, n, size=(B, n))\n\n    # Create bootstrap resamples\n    r1_resamples = r1[bootstrap_indices]\n    r2_resamples = r2[bootstrap_indices]\n\n    # Calculate test statistic for all bootstrap resamples (vectorized)\n    bootstrap_thetas = get_theta_hat(r1_resamples, r2_resamples)\n\n    # Find the (1-alpha) quantile of the bootstrap distribution\n    q_1_minus_alpha = np.percentile(bootstrap_thetas, 100 * (1 - alpha))\n\n    # Apply the decision rule\n    return 2 * theta_obs > q_1_minus_alpha\n\n# Calling the main function to produce the output\nsolve()\n```", "id": "3500186"}]}