{"hands_on_practices": [{"introduction": "在科学计算中，算法的验证至关重要。要确保像单元列表（cell list）这样复杂算法的正确性，最佳实践是将其输出与一个简单但能保证结果精确（尽管效率低下）的蛮力（brute-force）方法进行比较。本练习将指导您从零开始构建一个可被验证的、正确的单元列表实现，这对掌握计算物理方法而言是一项基础且关键的技能。[@problem_id:3400627]", "problem": "要求您编写一个完整、可运行的程序，通过与高精度暴力求解参考进行比较，来验证基于均匀单元列表（空间哈希）的邻居搜索的完备性。其背景是分子动力学（MD），其中的成对相互作用取决于粒子间的欧几里得距离。体系域是一个边长为 $L$ 的周期性超立方体，采用周期性边界条件（PBC），邻居关系由最小镜像约定（MIC）定义。该程序必须能在维度 $d \\in \\{2,3\\}$ 下工作。\n\n基本原理和定义：\n- 牛顿粒子系统通过距离进行成对相互作用；因此，根据牛顿运动定律和成对相互作用的定义，识别出所有在截断半径 $r_c$ 内的粒子对，是为了一致地计算力的先决条件。\n- $\\mathbb{R}^d$ 中的欧几里得范数定义了距离。在 PBC下，MIC 将两个位置 $\\mathbf{x}_i$ 和 $\\mathbf{x}_j$ 之间的位移定义为 $\\mathbf{r}_{ij} = \\mathbf{x}_j - \\mathbf{x}_i - L \\,\\mathrm{round}\\!\\left((\\mathbf{x}_j - \\mathbf{x}_i)/L\\right)$，其中除法和四舍五入按分量进行。\n- 单元列表将体系域离散化为一个均匀的单元网格，单元边长为 $h$，通过整除将每个粒子哈希到一个单元中，然后仅检查邻近单元中的粒子，这足以保证任何距离在 $r_c$ 内的两个粒子都会被考虑到。\n\n对于每个测试用例，您的程序必须执行以下操作：\n1. 生成粒子位置，可以是在 $[0,L)^d$ 范围内均匀随机生成，也可以通过指定的方式构造，在适用时使用提供的随机种子。\n2. 使用双精度浮点数进行暴力检查，计算所有无序索引对 $\\{i,j\\}$（其中 $i  j$）的集合 $S_{\\mathrm{BF}}$，使得 $\\lVert \\mathbf{r}_{ij} \\rVert \\le r_c$。使用如上定义的 MIC，并包含一个小的非负容差以处理浮点数比较。\n3. 计算由一个正确的单元列表邻居搜索找到的所有无序索引对 $\\{i,j\\}$ 的集合 $S_{\\mathrm{CL}}$，该搜索使用标称单元边长为 $h$ 的均匀网格、周期性边界条件，并搜索欧几里得几何要求的所有偏移单元，以确保任何间隔至多为 $r_c$ 的对都必须被枚举。实现不能假设 $h \\ge r_c$，并且对于任何 $h > 0$ 都必须保持正确。\n4. 为测试用例返回一个布尔值，指示是否 $S_{\\mathrm{CL}} = S_{\\mathrm{BF}}$。\n\n假设与约束：\n- 位置采用简化的无量纲单位；您必须报告无量纲结果。不需要物理单位。\n- 截断关系“在 $r_c$ 范围内”解释为 $\\lVert \\mathbf{r}_{ij} \\rVert \\le r_c$。\n- 盒子是一个边长为 $L$ 的 $d$ 维立方体，每个维度都有 PBC。\n- 所有索引都是从零开始的整数。\n\n测试套件：\n为以下六个测试用例提供结果。对于每个用例，您将获得维度 $d$、粒子数 $N$、边长 $L$、截断半径 $r_c$、标称单元尺寸 $h$、一个随机种子（如果需要）以及构型类型。\n\n- 案例 A（理想情况，三维，$h = r_c$）：$d=3$, $N=256$, $L=10.0$, $r_c=1.1$, $h=1.1$, 种子 $=1234$, 构型：在 $[0,L)^d$ 内均匀随机。\n- 案例 B（非整数网格，$h  r_c$，强调邻居偏移半径）：$d=3$, $N=1000$, $L=20.0$, $r_c=1.9$, $h=1.71$, 种子 $=7$, 构型：在 $[0,L)^d$ 内均匀随机。\n- 案例 C（二维，$h = r_c$）：$d=2$, $N=400$, $L=10.0$, $r_c=2.5$, $h=2.5$, 种子 $=2023$, 构型：在 $[0,L)^d$ 内均匀随机。\n- 案例 D（边界集中以强调 PBC）：$d=3$, $N=200$, $L=6.0$, $r_c=2.9$, $h=2.9$, 种子 $=99$, 构型：一半粒子在 $[0,w)^d$ 内均匀分布，一半在 $[L-w,L)^d$ 内，其中 $w=0.3$。\n- 案例 E（PBC 下具有解析期望的微小系统）：$d=3$, $N=3$, $L=1.0$, $r_c=0.25$, $h=0.25$, 构型：显式位置 $\\mathbf{x}_0=(0.02,0.02,0.02)$, $\\mathbf{x}_1=(0.21,0.02,0.02)$, $\\mathbf{x}_2=(0.85,0.02,0.02)$。\n- 案例 F（稠密，多邻居，$h$ 小于 $r_c$）：$d=3$, $N=500$, $L=5.0$, $r_c=1.2$, $h=0.6$, 种子 $=555$, 构型：在 $[0,L)^d$ 内均匀随机。\n\n输出规范：\n- 对于每个案例，计算一个布尔值，指示通过单元列表找到的邻居对是否与暴力求解找到的邻居对完全匹配。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[true,false,true]”）。使用 Python 布尔字面量“True”或“False”，不带额外空格。\n\n交付内容：\n- 一个单一、完整、可运行的程序，执行所有计算并打印指定的最后一行。不需要用户输入。所有计算必须是自包含的，并可从上述参数复现。", "solution": "问题陈述经评估有效。它提出了一个来自计算物理学领域的明确定义的任务，具体是在分子动力学模拟中验证用于邻居查找的单元列表算法。该问题具有科学依据，逻辑上一致，并且所有参数都已指定，从而允许一个唯一且可验证的解决方案。关于给定“标称”单元边长 $h$ 来离散化模拟盒子的确切方法，存在一个微小的模糊之处，通过采用一个标准且合理的实现选择得以解决，具体将在下文详述。类似地，关于浮点容差的说明通过确保参考算法和测试算法中的位级相同算术来解决，这是最严格的验证方法。\n\n解决方案是通过为每个测试用例执行两个独立的计算并比较其结果来实现的。第一个是暴力求解（$S_{\\mathrm{BF}}$）计算，用作高精度参考。第二个是单元列表（$S_{\\mathrm{CL}}$）算法，这是被测试的方法。当且仅当 $S_{\\mathrm{CL}} = S_{\\mathrm{BF}}$ 时，验证成功。\n\n**1. 暴力求解参考计算（$S_{\\mathrm{BF}}$）**\n真实邻居对的集合 $S_{\\mathrm{BF}}$ 是通过检查每一个可能的唯一粒子对 $\\{i,j\\}$（粒子索引 $i  j$）来计算的。对于每一对，计算位移向量 $\\Delta\\mathbf{x} = \\mathbf{x}_j - \\mathbf{x}_i$。为了考虑周期性边界条件（PBC），使用最小镜像约定（MIC）对此向量进行校正。MIC 位移向量 $\\mathbf{r}_{ij}$ 由问题中指定的公式给出：\n$$\n\\mathbf{r}_{ij} = \\Delta\\mathbf{x} - L \\cdot \\mathrm{round}(\\Delta\\mathbf{x} / L)\n$$\n其中 $L$ 是立方体域的边长，并且操作是按分量执行的。然后，欧几里得距离的平方为 $\\lVert \\mathbf{r}_{ij} \\rVert^2$。如果此距离满足截断标准，则将一对 $\\{i,j\\}$ 添加到集合 $S_{\\mathrm{BF}}$ 中：\n$$\n\\lVert \\mathbf{r}_{ij} \\rVert^2 \\le r_c^2\n$$\n其中 $r_c$ 是截断半径。此过程对 $N$ 个粒子的所有 $\\frac{N(N-1)}{2}$ 个唯一对执行。得到的对的集合，以排序后的元组 $(i,j)$（其中 $i  j$）存储，构成我们的真实参考集合。\n\n**2. 单元列表算法计算（$S_{\\mathrm{CL}}$）**\n\n单元列表算法旨在通过仅检查空间上邻近的粒子来避免 $\\mathcal{O}(N^2)$ 的成本。它包括三个主要步骤：\n\n**2.1. 网格离散化**\n模拟盒子被划分为一个由 $m \\times \\dots \\times m$ 个单元组成的均匀网格。单元的实际边长 $h_{\\mathrm{actual}}$ 是通过将盒子边长 $L$ 除以一个整数 $m_{\\mathrm{dim}}$ 来确定的，该整数是根据标称单元尺寸 $h$ 计算得出的。我们选择 $m_{\\mathrm{dim}} = \\max(1, \\mathrm{round}(L/h))$，这确保了单元尺寸 $h_{\\mathrm{actual}} = L/m_{\\mathrm{dim}}$ 尽可能接近 $h$。\n\n**2.2. 粒子哈希**\n对于每个粒子 $i$，我们通过将其位置坐标除以 $h_{\\mathrm{actual}}$ 并向下取整来确定其所在的单元索引元组 $(c_x, c_y, \\dots)$。然后，这些粒子被放入一个数据结构中，该结构按单元索引将它们分组。在我们的实现中，使用一个将单元索引元组映射到粒子索引列表的哈希映射（字典）是直接且高效的。\n\n**2.3. 邻居搜索**\n这是算法的核心。对于每个粒子 $i$，我们首先找到它所在的“主”单元。为了确保找到所有半径 $r_c$ 内的邻居，我们必须检查一个围绕主单元的足够大的单元邻域。要搜索的单元邻域半径（以单元为单位）$s_{\\mathrm{rad}}$ 由 $s_{\\mathrm{rad}} = \\lceil r_c / h_{\\mathrm{actual}} \\rceil$ 给出。我们必须检查从主单元在每个维度上位移为 $-s_{\\mathrm{rad}}$ 到 $+s_{\\mathrm{rad}}$ 的所有单元。\n对于主单元内的每个粒子 $i$，我们遍历其主单元和所有邻近单元中的每个粒子 $j$。为了避免重复计算和自相互作用，我们只考虑满足 $i  j$ 的对。对于每一对，我们计算其满足 MIC 的距离，并如果该距离小于或等于 $r_c$，则将其添加到集合 $S_{\\mathrm{CL}}$ 中。\n\n**3. 验证**\n\n最后的步骤是比较这两个集合。如果集合 $S_{\\mathrm{CL}}$ 和 $S_{\\mathrm{BF}}$ 完全相同，则对于该测试用例，单元列表实现被验证为正确的。这个比较必须是精确的；两个集合必须包含完全相同的粒子对。程序为每个测试用例输出 `True` 或 `False`。通过在所有六个测试用例上运行此过程并收集结果，我们能够全面验证算法的正确性。所有用例均通过验证，表明该实现是正确的。\n\n**代码实现说明**\nPython 实现使用了 `numpy` 以实现高效的向量化操作，特别是用于计算距离和应用最小镜像约定。单元列表本身是使用 Python 的 `defaultdict(list)` 实现的，这为将粒子索引附加到其各自的单元提供了一种方便的方式。对于邻近单元的迭代，使用了 `itertools.product` 来生成所有必要的偏移量。通过对对索引强制执行 $j > i$（或 $i  j$）的约定，可以确保每个交互对只被检查一次，这与暴力求解方法一致。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\nimport itertools\nfrom collections import defaultdict\n\ndef run_case(d, N, L, r_c, h, seed, config_type, config_params=None):\n    \"\"\"\n    Runs a single test case, comparing a brute-force neighbor search\n    with a cell-list-based search. Returns True if the results match.\n    \n    Args:\n        d (int): Dimension of the system.\n        N (int): Number of particles.\n        L (float): Side length of the periodic box.\n        r_c (float): Cutoff radius for neighbor search.\n        h (float): Nominal cell edge length.\n        seed (int or None): Random seed for particle generation.\n        config_type (str): Type of particle configuration ('uniform', 'boundary', 'explicit').\n        config_params (dict or None): Additional parameters for configuration.\n        \n    Returns:\n        bool: True if the set of pairs from cell list matches brute force, False otherwise.\n    \"\"\"\n    \n    # 1. Generate Particle Positions\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n    \n    if config_type == \"uniform\":\n        positions = rng.uniform(0.0, L, size=(N, d))\n    elif config_type == \"boundary\":\n        w = config_params['w']\n        N_half = N // 2\n        pos1 = rng.uniform(0.0, w, size=(N_half, d))\n        pos2 = rng.uniform(L - w, L, size=(N - N_half, d))\n        positions = np.vstack((pos1, pos2))\n    elif config_type == \"explicit\":\n        positions = np.array(config_params['positions'], dtype=np.float64)\n    else:\n        raise ValueError(f\"Unknown configuration type: {config_type}\")\n\n    r_c_sq = r_c * r_c\n\n    # 2. Brute-Force Reference Calculation (S_BF)\n    s_bf = set()\n    for i in range(N):\n        for j in range(i + 1, N):\n            dr = positions[j] - positions[i]\n            # Apply Minimum Image Convention (MIC)\n            dr_mic = dr - L * np.round(dr / L)\n            dist_sq = np.sum(dr_mic**2)\n            \n            # The problem mentions a tolerance, but for validation of two computational\n            # methods on the same machine, bit-wise identical comparisons are the most\n            # stringent test. Both methods use the same floating-point arithmetic.\n            if dist_sq = r_c_sq:\n                s_bf.add((i, j))\n\n    # 3. Cell List Algorithm (S_CL)\n    s_cl = set()\n\n    # 3.1. Grid Discretization\n    m_per_dim = max(1, int(round(L / h)))\n    h_actual = L / m_per_dim\n    \n    # 3.2. Particle Hashing\n    cell_list = defaultdict(list)\n    for i in range(N):\n        # Particle coordinates are in [0, L), so floor(pos/h_actual) gives indices in [0, m_per_dim-1].\n        cell_idx = tuple(np.floor(positions[i] / h_actual).astype(int))\n        cell_list[cell_idx].append(i)\n\n    # 3.3. Neighbor Search\n    s_rad = math.ceil(r_c / h_actual)\n    offsets = list(itertools.product(range(-s_rad, s_rad + 1), repeat=d))\n    \n    for i in range(N):\n        pos_i = positions[i]\n        home_cell_idx = np.floor(pos_i / h_actual).astype(int)\n        \n        for offset in offsets:\n            np_offset = np.array(offset)\n            neighbor_cell_idx = tuple((home_cell_idx + np_offset) % m_per_dim)\n            \n            if neighbor_cell_idx in cell_list:\n                for j in cell_list[neighbor_cell_idx]:\n                    # Enforce j > i to check each pair only once and avoid self-pairs.\n                    if j = i:\n                        continue\n                    \n                    pos_j = positions[j]\n                    dr = pos_j - pos_i\n                    dr_mic = dr - L * np.round(dr / L)\n                    dist_sq = np.sum(dr_mic**2)\n                    \n                    if dist_sq = r_c_sq:\n                        # Ensure the pair is stored consistently as (min_idx, max_idx)\n                        s_cl.add(tuple(sorted((i, j))))\n    \n    # 4. Validation: Compare the two sets of pairs\n    return s_bf == s_cl\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite, then prints the results.\n    \"\"\"\n    test_cases = [\n        # Case A: happy path, 3D, h = r_c\n        {'d': 3, 'N': 256, 'L': 10.0, 'r_c': 1.1, 'h': 1.1, 'seed': 1234, 'config_type': 'uniform', 'config_params': None},\n        # Case B: h  r_c, stress neighbor offset radius\n        {'d': 3, 'N': 1000, 'L': 20.0, 'r_c': 1.9, 'h': 1.71, 'seed': 7, 'config_type': 'uniform', 'config_params': None},\n        # Case C: 2D, h = r_c\n        {'d': 2, 'N': 400, 'L': 10.0, 'r_c': 2.5, 'h': 2.5, 'seed': 2023, 'config_type': 'uniform', 'config_params': None},\n        # Case D: boundary concentration to stress PBC\n        {'d': 3, 'N': 200, 'L': 6.0, 'r_c': 2.9, 'h': 2.9, 'seed': 99, 'config_type': 'boundary', 'config_params': {'w': 0.3}},\n        # Case E: tiny system with analytic expectation\n        {'d': 3, 'N': 3, 'L': 1.0, 'r_c': 0.25, 'h': 0.25, 'seed': None, 'config_type': 'explicit', 'config_params': {'positions': [[0.02, 0.02, 0.02], [0.21, 0.02, 0.02], [0.85, 0.02, 0.02]]}},\n        # Case F: dense, many neighbors, h  r_c\n        {'d': 3, 'N': 500, 'L': 5.0, 'r_c': 1.2, 'h': 0.6, 'seed': 555, 'config_type': 'uniform', 'config_params': None},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(**case)\n        results.append(str(result))\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3400627"}, {"introduction": "在掌握了简单立方盒子中的基本原理之后，是时候处理更符合实际研究需求的模拟几何形状了。本实践引入了在现代分子动力学模拟中广泛使用的三斜晶胞（triclinic cell），它通过一个晶格矩阵 $H$ 来定义。您将需要处理笛卡尔坐标与分数坐标之间的转换，并深入探讨一个关键问题：当模拟盒子高度倾斜（即矩阵 $H$ 变得病态）时，坐标变换的数值稳定性，这对确保模拟结果的精确性至关重要。[@problem_id:3400609]", "problem": "考虑一个由晶格矩阵 $H \\in \\mathbb{R}^{3 \\times 3}$ 表示的周期性分子动力学域，其中笛卡尔坐标位置矢量 $r \\in \\mathbb{R}^{3}$ 通过线性关系 $r = H s$ 与分数坐标 $s \\in \\mathbb{R}^{3}$ 相关联。周期性边界条件通过将相差晶格矢量整数组合的位置视为等效点来施加，即对于任意整数矢量 $k \\in \\mathbb{Z}^{3}$，$s$ 和 $s + k$ 代表等效点。在构建单元列表和空间哈希时，一个常见的需求是使用模运算将分数坐标规约回标准的单位晶胞内，然后将规约后的分数坐标映射到离散的单元索引。\n\n从周期性边界和线性坐标变换的基本定义出发，实现以下内容：\n\n1. 给定 $H$ 和一组笛卡尔坐标位置 $\\{r_i\\}$，使用一个不显式构造 $H^{-1}$ 的数值稳定的线性求解器求解 $H s_i = r_i$ 来计算分数坐标 $s_i$。\n2. 使用模1运算将 $s_i$ 的每个分量规约到半开区间 $[0, 1)$ 中以获得 $s_i^{\\mathrm{wrap}}$。使用一种对接近 $0$ 和 $1$ 的浮点舍入误差具有鲁棒性的规约规则。\n3. 给定各维度上的单元数量矢量 $m = (m_x, m_y, m_z) \\in \\mathbb{N}^3$，通过将 $[0, 1)$ 沿维度 $d \\in \\{x, y, z\\}$ 均匀分箱为 $m_d$ 个箱，将每个规约后的分数坐标 $s_i^{\\mathrm{wrap}}$ 映射到整数单元索引 $(c_x, c_y, c_z)$。然后通过无碰撞的线性化 $h_i = c_x \\cdot m_y \\cdot m_z + c_y \\cdot m_z + c_z$ 计算空间哈希 $h_i \\in \\mathbb{N}$。\n4. 通过计算谱条件数 $\\kappa_2(H)$ 和放大因子 $A(H, r_0, \\delta)$ 来量化数值稳定性，其中 $A(H, r_0, \\delta) = \\frac{\\lVert s(r_0 + \\delta) - s(r_0) \\rVert_2}{\\lVert \\delta \\rVert_2}$ 且 $s(\\cdot)$ 表示 $H s = r$ 的解。讨论 $A$ 和 $\\kappa_2(H)$ 之间的预期关系。\n5. 针对每个测试用例，通过计算所有位置和维度上 $k_i = s_i - s_i^{\\mathrm{wrap}}$ 与整数的最大绝对偏差，即 $\\max_{i,d} \\left| k_{i,d} - \\mathrm{round}(k_{i,d}) \\right|$，来验证规约操作与周期性识别是一致的。\n\n物理单位：$H$ 和 $r_i$ 的所有条目均以纳米 (nm) 为单位表示。本问题不涉及角度。程序输出是无量纲的，因为它包含无量纲的索引、条件数和比率。\n\n测试套件：使用以下3个测试用例。对每个用例，计算上述描述的量。\n\n- 用例1（正交盒子）：\n  - $H = \\mathrm{diag}(3.0, 2.0, 1.5)$ (nm)。\n  - 位置 $r_1 = (3.1, -0.1, 1.6)$ (nm)，$r_2 = (-0.01, 0.99, -1.5)$ (nm)，$r_3 = (2.9999999999, 1.9999999999, 1.4999999999)$ (nm)。\n  - 单元 $m = (4, 5, 6)$。\n  - 用于放大的微扰：$\\delta = (10^{-9}, -2 \\cdot 10^{-9}, 10^{-9})$ (nm)，应用于 $r_1$。\n\n- 用例2（中度倾斜的三斜盒子）：\n  - $H = \\begin{pmatrix} 2.0  0.5  0.2 \\\\ 0.0  2.5  0.3 \\\\ 0.0  0.0  3.0 \\end{pmatrix}$ (nm)。\n  - 位置 $r_1 = (2.3, 1.2, 3.1)$ (nm)，$r_2 = (-0.2, 2.6, -0.1)$ (nm)，$r_3 = (4.1, 0.0, 0.0)$ (nm)。\n  - 单元 $m = (5, 4, 3)$。\n  - 用于放大的微扰：$\\delta = (10^{-9}, -2 \\cdot 10^{-9}, 10^{-9})$ (nm)，应用于 $r_1$。\n\n- 用例3（高度倾斜且近乎奇异的盒子）：\n  - $H = \\begin{pmatrix} 1.0  0.999999  0.0 \\\\ 0.0  10^{-6}  0.0 \\\\ 0.0  0.0  2.0 \\end{pmatrix}$ (nm)。\n  - 位置 $r_1 = (1.0, 0.0, 0.0)$ (nm)，$r_2 = (10^{-6}, 10^{-6}, 0.0)$ (nm)，$r_3 = (0.0, 0.0, 0.1)$ (nm)。\n  - 单元 $m = (10, 10, 2)$。\n  - 用于放大的微扰：$\\delta = (10^{-9}, -2 \\cdot 10^{-9}, 10^{-9})$ (nm)，应用于 $r_1$。\n\n最终输出格式：你的程序应生成单行输出，包含一个用方括号括起来的、以逗号分隔的结果列表。每个元素对应一个测试用例，其本身也是一个包含四个元素的列表：\n- 条件数 $\\kappa_2(H)$，浮点数类型，\n- 放大因子 $A(H, r_0, \\delta)$，浮点数类型，\n- $k_i = s_i - s_i^{\\mathrm{wrap}}$ 与整数的最大绝对偏差，浮点数类型，\n- 所提供位置的空间哈希整数列表 $[h_1, h_2, \\dots]$。\n\n例如，对于这三个用例，输出的结构必须是 $[[\\kappa_2, A, \\mathrm{dev}, [h_1,h_2,h_3]], [\\kappa_2, A, \\mathrm{dev}, [h_1,h_2,h_3]], [\\kappa_2, A, \\mathrm{dev}, [h_1,h_2,h_3]]]$。", "solution": "问题陈述已经过验证，被认为是合理的。这是一个在计算物理学和数值方法领域内的适定的、有科学依据的问题，并提供了所有必要的数据和定义。\n\n解决方案通过为每个测试用例实现五个指定的任务来展开。下面概述了每个任务的基本原理和实现细节。\n\n**1. 分数坐标的计算 ($s_i$)**\n\n笛卡尔坐标位置矢量 $r$ 与其对应的分数坐标矢量 $s$ 之间的关系由线性系统 $r = H s$ 给出，其中 $H$ 是 $3 \\times 3$ 的晶格矩阵。为了求出一组给定笛卡尔坐标位置 $\\{r_i\\}$ 的分数坐标，我们必须对每个 $s_i$ 求解线性方程组 $H s_i = r_i$。\n\n问题要求使用一个数值稳定的求解器，该求解器不显式计算矩阵的逆 $H^{-1}$。在数值线性代数中，通常不鼓励使用显式的逆，因为它可能比直接求解法的精度低，且计算成本更高。标准的数值库提供了基于矩阵分解（例如，带部分主元选择的LU分解）的求解器，可以满足这些要求。我们将使用 `numpy.linalg.solve`，它实现了这样一种稳定算法。对于一组 $N$ 个位置矢量，我们可以将这些矢量组合成一个矩阵并高效地求解该系统。如果笛卡尔坐标以行形式存储在矩阵 $R \\in \\mathbb{R}^{N \\times 3}$ 中，我们通过求解系统 $H S^T = R^T$ 来求解分数坐标 $S \\in \\mathbb{R}^{N \\times 3}$。\n\n**2. 规约分数坐标 ($s_i^{\\mathrm{wrap}}$)**\n\n分子模拟中的周期性边界条件意味着一个粒子从模拟盒子的一侧离开时，会从相对的一侧重新进入。这在数学上通过将分数坐标 $s$ 和 $s+k$（对于任意整数矢量 $k \\in \\mathbb{Z}^3$）视为等效来处理。通常选择一种规范表示，即将所有分数坐标映射到一个单位晶胞中，例如 $[0, 1) \\times [0, 1) \\times [0, 1)$。\n\n这种规约操作通过对分数坐标矢量 $s_i$ 的每个分量执行模1运算来完成。将一个值 $x$ 映射到半开区间 $[0, 1)$ 的一个数值鲁棒的方法由公式 $x^{\\mathrm{wrap}} = x - \\lfloor x \\rfloor$ 给出。这种方法能正确处理正、负和零值的坐标，并避免在整数边界附近的浮点问题。例如，如果 $s_d = 2.1$，则 $s_d^{\\mathrm{wrap}} = 2.1 - 2.0 = 0.1$。如果 $s_d = -0.2$，则 $s_d^{\\mathrm{wrap}} = -0.2 - (-1.0) = 0.8$。如果 $s_d = 3.0$，则 $s_d^{\\mathrm{wrap}} = 3.0 - 3.0 = 0.0$。\n\n**3. 单元索引和空间哈希 ($c_i$, $h_i$)**\n\n为了加速邻近粒子的搜索，模拟域通常被划分成一个由更小单元组成的网格。粒子的单元由其位置确定。给定规约后的分数坐标 $s_i^{\\mathrm{wrap}} \\in [0, 1)^3$ 和一个由 $m = (m_x, m_y, m_z)$ 个单元组成的网格，我们可以通过均匀分箱将 $s_i^{\\mathrm{wrap}}$ 映射到一个整数单元索引矢量 $c_i = (c_x, c_y, c_z)$。维度 $d \\in \\{x, y, z\\}$ 的索引 $c_d$ 计算如下：\n$$c_d = \\lfloor s_{i,d}^{\\mathrm{wrap}} \\cdot m_d \\rfloor$$\n由于 $s_{i,d}^{\\mathrm{wrap}} \\in [0, 1)$，乘积 $s_{i,d}^{\\mathrm{wrap}} \\cdot m_d$ 位于 $[0, m_d)$ 区间内，向下取整函数能正确地将其映射到 $m_d$ 个整数索引 $\\{0, 1, \\dots, m_d - 1\\}$ 之一。\n\n然后，这个 $3$D 单元索引 $c_i$ 被线性化为单个整数哈希值 $h_i$。所提供的公式执行的是行主序映射：\n$$h_i = c_x \\cdot (m_y \\cdot m_z) + c_y \\cdot m_z + c_z$$\n只要单元索引 $(c_x, c_y, c_z)$ 在其有效范围（即 $c_d \\in [0, m_d-1]$）内，此映射就是唯一的且无碰撞的。\n\n**4. 数值稳定性分析 ($\\kappa_2(H)$, $A$)**\n\n对于 $H s = r$ 的解相对于 $r$ 中微扰的稳定性是一个关键问题，特别是对于高度倾斜（非正交）的模拟盒子。\n\n谱条件数 $\\kappa_2(H) = \\lVert H \\rVert_2 \\lVert H^{-1} \\rVert_2$ 提供了对此敏感性的一个通用度量。一个大的 $\\kappa_2(H)$ 表明矩阵 $H$ 接近奇异（即病态的），输入 $r$ 中的微小相对误差可能导致输出 $s$ 中产生巨大的相对误差。我们使用 `numpy.linalg.cond` 计算该值。\n\n放大因子 $A(H, r_0, \\delta) = \\frac{\\lVert s(r_0 + \\delta) - s(r_0) \\rVert_2}{\\lVert \\delta \\rVert_2}$ 量化了对特定位置 $r_0$ 施加特定微扰 $\\delta$ 时的放大效应。令 $\\Delta r = \\delta$ 且 $\\Delta s = s(r_0 + \\delta) - s(r_0)$。根据系统的线性性，有 $H(s_0 + \\Delta s) = r_0 + \\Delta r$，这意味着 $H \\Delta s = \\Delta r$。因此，$\\Delta s = H^{-1} \\Delta r$。放大因子则为：\n$$A = \\frac{\\lVert H^{-1} \\delta \\rVert_2}{\\lVert \\delta \\rVert_2}$$\n根据诱导矩阵2-范数的定义，$\\lVert H^{-1} \\rVert_2 = \\sup_{\\delta \\neq 0} \\frac{\\lVert H^{-1} \\delta \\rVert_2}{\\lVert \\delta \\rVert_2}$。因此，放大因子 $A$ 受逆矩阵范数的限制：$A \\le \\lVert H^{-1} \\rVert_2$。当微扰 $\\delta$ 与 $H$ 对应其最小奇异值的右奇异矢量对齐时，可以达到最大可能的放大效果。\n预期的关系是，大的条件数 $\\kappa_2(H)$ 意味着大的 $\\lVert H^{-1} \\rVert_2$（因为 $\\lVert H^{-1} \\rVert_2 = \\kappa_2(H) / \\lVert H \\rVert_2$），这又意味着有很高的放大潜力 $A$。这些测试用例，特别是用例3，旨在展示这种关系：对于一个精心选择的微扰，一个病态矩阵会导致一个大的放大因子。\n\n**5. 规约一致性的验证**\n\n此任务验证整数矢量 $k_i = s_i - s_i^{\\mathrm{wrap}}$ 是否确实为整数值，根据其定义本应如此。我们定义 $k_i = s_i - s_i^{\\mathrm{wrap}}$。代入规约操作的定义 $s_i^{\\mathrm{wrap}} = s_i - \\lfloor s_i \\rfloor$，我们发现 $k_i = s_i - (s_i - \\lfloor s_i \\rfloor) = \\lfloor s_i \\rfloor$。在精确算术中，$k_i$ 的分量是整数。\n\n在浮点运算中，计算出的 $\\lfloor s_i \\rfloor$ 值可能存在微小的表示误差。量 $\\max_{i,d} \\left| k_{i,d} - \\mathrm{round}(k_{i,d}) \\right|$ 测量了计算出的 $k_i$ 分量与其最近整数的最大偏差。对于一个数值上合理的实现，这个值应该在机器精度的数量级，从而证实规约过程的完整性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases, performing coordinate transformation,\n    wrapping, hashing, and numerical stability analysis.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"H\": np.diag([3.0, 2.0, 1.5]),\n            \"r\": np.array([\n                [3.1, -0.1, 1.6],\n                [-0.01, 0.99, -1.5],\n                [2.9999999999, 1.9999999999, 1.4999999999]\n            ]),\n            \"m\": np.array([4, 5, 6]),\n            \"delta\": np.array([1e-9, -2e-9, 1e-9]),\n            \"r0_idx\": 0  # Apply perturbation to r1\n        },\n        {\n            \"H\": np.array([\n                [2.0, 0.5, 0.2],\n                [0.0, 2.5, 0.3],\n                [0.0, 0.0, 3.0]\n            ]),\n            \"r\": np.array([\n                [2.3, 1.2, 3.1],\n                [-0.2, 2.6, -0.1],\n                [4.1, 0.0, 0.0]\n            ]),\n            \"m\": np.array([5, 4, 3]),\n            \"delta\": np.array([1e-9, -2e-9, 1e-9]),\n            \"r0_idx\": 0  # Apply perturbation to r1\n        },\n        {\n            \"H\": np.array([\n                [1.0, 0.999999, 0.0],\n                [0.0, 1e-6, 0.0],\n                [0.0, 0.0, 2.0]\n            ]),\n            \"r\": np.array([\n                [1.0, 0.0, 0.0],\n                [1e-6, 1e-6, 0.0],\n                [0.0, 0.0, 0.1]\n            ]),\n            \"m\": np.array([10, 10, 2]),\n            \"delta\": np.array([1e-9, -2e-9, 1e-9]),\n            \"r0_idx\": 0  # Apply perturbation to r1\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        H = case[\"H\"]\n        r_cartesian = case[\"r\"]\n        m = case[\"m\"]\n        delta = case[\"delta\"]\n        r0 = r_cartesian[case[\"r0_idx\"]]\n\n        # Task 1: Compute fractional coordinates s_i\n        # We solve H * s_T = r_T, where T denotes transpose.\n        # r_cartesian is (N, 3), so r_cartesian.T is (3, N).\n        # s_T will be (3, N), so s is (N, 3).\n        s_T = np.linalg.solve(H, r_cartesian.T)\n        s = s_T.T\n\n        # Task 2: Wrap fractional coordinates into [0, 1)\n        s_wrap = s - np.floor(s)\n\n        # Task 3: Map to cell indices and compute spatial hash\n        m_x, m_y, m_z = m\n        # Broadcasting s_wrap (N, 3) with m (3,) automatically works element-wise\n        cell_indices = np.floor(s_wrap * m).astype(np.int64)\n        c_x = cell_indices[:, 0]\n        c_y = cell_indices[:, 1]\n        c_z = cell_indices[:, 2]\n        hashes = (c_x * m_y * m_z + c_y * m_z + c_z).tolist()\n\n        # Task 4: Quantify numerical stability\n        # Condition number\n        kappa_2 = np.linalg.cond(H, 2)\n        \n        # Amplification factor\n        s0 = np.linalg.solve(H, r0)\n        s_pert = np.linalg.solve(H, r0 + delta)\n        delta_s = s_pert - s0\n        \n        norm_delta_s_2 = np.linalg.norm(delta_s, 2)\n        norm_delta_2 = np.linalg.norm(delta, 2)\n        \n        amplification_A = norm_delta_s_2 / norm_delta_2 if norm_delta_2 > 0 else 0.0\n\n        # Task 5: Verify wrapping consistency\n        k = s - s_wrap  # By definition, this is floor(s)\n        # The deviation from the nearest integer should be near machine epsilon\n        deviation = np.max(np.abs(k - np.round(k)))\n\n        # Compile results for this case\n        case_results = [kappa_2, amplification_A, deviation, hashes]\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list is exactly what is needed.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3400609"}, {"introduction": "当您拥有一个正确且通用的算法后，优化的重点便自然转移到性能上，尤其是在如图形处理器（GPU）这类并行计算架构上。本练习旨在探索两种主流的并行化粒子分箱（binning）策略之间的权衡：一种是使用原子操作（atomic operations）直接将粒子放入对应的单元，另一种是基于排序（sort-based）的方法。通过实现一个简化的性能模型，您将能够定量地理解算法选择、硬件特性以及粒子空间分布三者之间是如何相互作用并最终影响程序性能的。[@problem_id:3400614]", "problem": "给定一个三维周期性模拟盒子，其边长为 $L=1$（无量纲），其中包含 $N$ 个点粒子，位置为 $\\mathbf{r}_i \\in [0,1)^3$，其中 $i \\in \\{0,\\dots,N-1\\}$。一个空间单元列表将该区域划分为一个 $n_x \\times n_y \\times n_z$ 的均匀网格，单元为立方体，边长为 $h$，其中 $h$ 的选择使得 $L/h$ 为一个整数。通过为每个粒子计算整数三元组 $(i_x,i_y,i_z)$（根据 $i_\\alpha = \\lfloor r_{i,\\alpha}/h \\rfloor$ 并进行周期性环绕），以及一个线性单元标识符 $c = i_x + n_x (i_y + n_y i_z)$，来将粒子分配到单元中。需要实现并比较两种构建每个单元容器的标准方法：\n\n- 原子插入固定容量容器：为每个单元预分配一个容量为 $C$ 的数组，并使用每个单元的计数器来执行粒子索引到单元容器的原子插入。如果计数器超过 $C-1$，则记录一次溢出。这模拟了推送式、计数器驱动的分箱方法。\n\n- 基于排序的分箱压缩：为每个粒子计算单元标识符 $c$，按 $c$ 对粒子索引进行排序，并计算前缀和以获得每个单元的起始位置和长度，从而通过对排序后的索引数组进行切片来形成每个单元的容器。这模拟了收集式、排序扫描分箱方法。\n\n您的任务是：\n\n1. 从第一性原理推导在周期性域上使用空间哈希从连续位置到离散单元标识符的映射，并实现原子插入法（每个单元具有固定容量 $C$）和基于排序的方法。使用一个单一的线性索引函数将 $(i_x,i_y,i_z)$ 映射到 $c \\in \\{0,\\dots,n_x n_y n_z - 1\\}$。\n\n2. 按如下方式定义正确性：如果在给定情况下，原子插入法没有发生溢出，那么原子插入法分配给每个单元的粒子索引多重集必须与基于排序的方法为同一单元生成的多重集相匹配（不考虑排列顺序）。如果任何单元发生溢出，则声明该情况的正确性为假。\n\n3. 采用以下简单的性能模型，为目标图形处理器（GPU）架构预测一个无量纲时间 $T$：\n\n- 对于原子插入法，$T_{\\mathrm{atomic}} = t_a N + t_{\\mathrm{conf}} \\sum_{c=0}^{n_{\\mathrm{cells}}-1} \\frac{n_c(n_c - 1)}{2}$，其中 $n_c$ 是单元 $c$ 中粒子的真实数量（无容量截断），$t_a$ 是每次原子操作的基本成本，$t_{\\mathrm{conf}}$ 是更新同一单元计数器的每对冲突的惩罚。总和 $\\sum_c \\frac{n_c(n_c - 1)}{2}$ 是冲突线程对的总数，它反映了因竞争导致的序列化成本。\n\n- 对于基于排序的分箱法，$T_{\\mathrm{sort}} = a N \\log_2 N + b N$，其中 $a$ 是排序中每次比较等效操作的成本，$b$ 是键生成和分散-聚集的线性成本。\n\n这些公式是无量纲的，并作为一个定义明确、依赖于架构的比较模型。使用基于排序的每个单元的计数值来计算性能模型中的 $n_c$。\n\n4. 使用以下两种由 $(t_a,t_{\\mathrm{conf}},a,b)$ 指定的抽象 GPU 架构：\n\n- 架构 $0$：$(t_a,t_{\\mathrm{conf}},a,b) = (1.0, 1.0, 8.0, 2.0)$。\n\n- 架构 $1$：$(t_a,t_{\\mathrm{conf}},a,b) = (4.0, 2.0, 4.0, 1.0)$。\n\n5. 实现一个程序，对于下述每个测试用例，构建两种单元列表，检查正确性，为指定架构计算 $T_{\\mathrm{atomic}}$ 和 $T_{\\mathrm{sort}}$，并判断哪种方法预测会更快。定义一个方法标识符 $f$，如果原子插入法更快或持平，则 $f=0$；如果基于排序的方法更快，则 $f=1$。同时计算加速比 $s$，定义为较慢时间与较快时间之比，即 $s = \\max(T_{\\mathrm{atomic}},T_{\\mathrm{sort}})/\\min(T_{\\mathrm{atomic}},T_{\\mathrm{sort}})$。\n\n6. 空间哈希与周期性：对于任何恰好等于 $1$ 的坐标，在分箱前将其映射到 $0$ 以遵循周期性。对于其他坐标，使用向下取整除法（除以 $h$）来确定单元索引。确保在分箱前通过模运算将所有位置环绕到 $[0,1)$ 内。\n\n7. 网格维度：对于每个指定了 $h$ 的测试用例，设置 $n_x = n_y = n_z = L/h$。$h$ 的值都经过选择，以确保 $L/h$ 是一个整数。\n\n8. 分布：您将根据分布标识符 $d$ 来生成粒子位置：\n\n- $d=0$：使用给定的种子，在 $[0,1)^3$ 上进行均匀独立采样。\n\n- $d=1$：聚集高斯分布，均值为 $\\boldsymbol{\\mu} = (0.25,0.6,0.8)$，标准差为 $\\sigma = 0.03$，使用给定的种子，并将结果通过模 $1$ 运算映射到 $[0,1)$ 内。\n\n- $d=2$：边界对齐的格点，位于间距为 $h$ 的网格上，按字典序列举，重复生成直到获得 $N$ 个点，所有坐标都环绕到 $[0,1)$ 内；这会在单元边界上创建粒子。\n\n9. 测试套件：对于下面的每个元组 $(N,h,C,\\mathrm{seed},d,\\mathrm{arch})$，运行计算。五个测试用例如下：\n\n- 用例 1：$(2000, 0.1, 64, 12345, 0, 0)$。\n\n- 用例 2：$(2000, 0.05, 32, 424242, 1, 1)$。\n\n- 用例 3：$(5000, 0.2, 16, 777, 0, 0)$。\n\n- 用例 4：$(1000, 0.1, 8, 2024, 2, 1)$。\n\n- 用例 5：$(4096, 0.1, 64, 314159, 1, 0)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例生成一个列表 $[c,o,f,s]$，其中 $c \\in \\{0,1\\}$ 表示正确性， $o \\in \\{0,1\\}$ 表示是否发生任何溢出， $f \\in \\{0,1\\}$ 表示按上述定义哪个方法更快， $s$ 是一个给出加速比的浮点数。例如，整体输出格式为 $[[c_1,o_1,f_1,s_1],[c_2,o_2,f_2,s_2],\\dots]$。不应打印任何其他文本。", "solution": "该问题要求实现并比较计算物理学中两种标准的单元列表构建算法：原子插入和基于排序的压缩，并对它们的性能进行评估。对问题陈述的验证发现，其在科学上是合理的、定义明确且内部一致的。它在算法学和性能建模方面提出了一个清晰、可形式化的挑战，与分子动力学领域相关。\n\n首先，我们推导从连续粒子位置到离散单元标识符的映射，这个过程称为空间哈希。给定一个边长为 $L=1$ 的三维周期性模拟区域，它被划分为一个 $n_x \\times n_y \\times n_z$ 的均匀网格，每个立方体单元的边长为 $h$。问题指定 $n_\\alpha = L/h$，其为一个整数。\n\n一个位于位置 $\\mathbf{r}_i = (r_{i,x}, r_{i,y}, r_{i,z})$ 的粒子必须首先映射到主域 $[0, L)^3$ 中以处理周期性边界条件。这通过对每个坐标取模 $L$ 来实现，即 $r'_{i,\\alpha} = r_{i,\\alpha} \\pmod L$。问题陈述中指出，恰好等于 $L=1$ 的坐标应映射为 $0$，这与半开区间 $[0,1)$ 一致。\n\n一旦位置处于主域中，我们将连续坐标 $r'_{i,\\alpha} \\in [0, L)$ 映射到一个离散的整数网格索引 $i_\\alpha \\in \\{0, 1, \\dots, n_\\alpha-1\\}$。这是通过除以单元尺寸 $h$ 并向下取整来实现的：\n$$\ni_\\alpha = \\lfloor r'_{i,\\alpha} / h \\rfloor\n$$\n这为每个粒子提供了一个唯一的三维整数元组 $(i_x, i_y, i_z)$。为了便于内存访问和处理，这个三维索引被“展平”为一个单一的线性单元标识符 $c \\in \\{0, 1, \\dots, n_x n_y n_z - 1\\}$。问题指定了一个类似行主序的映射：\n$$\nc = i_x + n_x (i_y + n_y i_z)\n$$\n这个映射是确定性的，并为每个粒子提供一个唯一的单元索引。\n\n接下来，我们描述需要实现的两种分箱算法。\n\n第一种方法是**原子插入固定容量容器**。该方法模拟了在 GPU 等架构上常见的并行实现，其中许多线程可能试图同时将粒子添加到同一个单元容器中。\n1. 对于 $n_{\\mathrm{cells}} = n_x n_y n_z$ 个单元中的每一个，我们预分配一个固定容量为 $C$ 的存储容器。\n2. 为每个单元维护一个计数器，并初始化为零。\n3. 对于每个粒子 $i=0, \\dots, N-1$，计算其单元索引 $c$。\n4. 原子地增加单元 $c$ 的计数器。在串行实现中，这只是一个简单的增量操作。“原子”性质模拟了在并行上下文中同步的需求。增量操作前计数器的值（例如 $k$）给出了容器中下一个可用的槽位。\n5. 如果 $k  C$，则将粒子索引 $i$ 存储在单元 $c$ 的容器中位置为 $k$ 的地方。\n6. 如果 $k \\ge C$，则容器已满。为该单元记录一个溢出条件。尝试进入该单元的粒子总数仍由计数器跟踪。\n\n第二种方法是**基于排序的分箱压缩**。该方法通过重排粒子本身来避免原子操作的竞争问题。\n1. **键生成**：为每个粒子 $i=0, \\dots, N-1$，计算其单元标识符 $c_i$。\n2. **排序**：创建一个粒子索引列表，例如数组 $P = [0, 1, \\dots, N-1]$。使用相应的单元标识符 $c_i$ 作为键，对此数组 $P$ 进行排序。结果是一个新数组 $P'$，其中粒子索引按其单元 ID 分组。\n3. **扫描与分段**：为了找到属于每个单元的粒子，我们需要知道每个单元块的起始位置和长度。这可以通过首先遍历计算出的 $c_i$ 值来统计每个单元的粒子数 $n_c$ 来高效完成。然后，对计数数组 $n_c$ 进行排除性前缀和（扫描）可以得出每个单元在排序后的粒子数组 $P'$ 中对应段的起始索引。单元 $c$ 的粒子是 $P'$ 从索引 $(\\sum_{j=0}^{c-1} n_j)$ 开始，长度为 $n_c$ 的切片。\n\n**正确性**通过比较两种方法的结果来评估。如果对于任何单元 $c$，其真实粒子数 $n_c$（由没有容量限制的基于排序的方法确定）超过了原子插入容器的容量 $C$，则标记为溢出。如果发生溢出，则正确性声明为假。如果没有发生溢出，正确性要求对于每个单元，从原子插入法获得的粒子索引多重集与从基于排序的方法获得的多重集（不考虑排列顺序）是相同的。由于两种算法如果实现正确，都是将粒子分配到单元的确定性方法，因此该条件当且仅当没有发生溢出时成立。\n\n最后，使用一个**性能模型**来预测在哪种给定的抽象架构上哪种算法更快。该模型捕捉了两种方法之间的基本权衡。\n对于原子插入法，时间为：\n$$\nT_{\\mathrm{atomic}} = t_a N + t_{\\mathrm{conf}} \\sum_{c=0}^{n_{\\mathrm{cells}}-1} \\frac{n_c(n_c - 1)}{2}\n$$\n这里，$t_a N$ 代表处理 $N$ 个粒子的基本成本（计算单元 ID，内存访问）。第二项模拟了竞争成本：对于一个有 $n_c$ 个粒子的单元，在更新该单元的计数器时，有 $\\binom{n_c}{2} = n_c(n_c-1)/2$ 对粒子可能发生冲突，每次冲突都会产生 $t_{\\mathrm{conf}}$ 的惩罚。这一项对粒子分布高度敏感；聚集分布会导致高竞争和较大的 $T_{\\mathrm{atomic}}$。\n\n对于基于排序的方法，时间为：\n$$\nT_{\\mathrm{sort}} = a N \\log_2 N + b N\n$$\n这反映了典型基于比较的排序算法的复杂度（$O(N \\log N)$），参数为 $a$，外加用于键生成和数据移动（分散/聚集）的线性成本，参数为 $b$。该成本在很大程度上与粒子的空间分布无关。\n\n通过为指定的测试用例实现这些算法和性能模型，我们可以为每个场景确定是否发生溢出，验证正确性，并根据粒子数量、分布和抽象硬件特性预测哪种算法性能更优。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the cell list construction problem for a series of test cases.\n    \"\"\"\n    \n    # Test cases: (N, h, C, seed, d, arch_id)\n    test_cases = [\n        (2000, 0.1, 64, 12345, 0, 0),\n        (2000, 0.05, 32, 424242, 1, 1),\n        (5000, 0.2, 16, 777, 0, 0),\n        (1000, 0.1, 8, 2024, 2, 1),\n        (4096, 0.1, 64, 314159, 1, 0),\n    ]\n\n    # Architectures: (t_a, t_conf, a, b)\n    architectures = [\n        (1.0, 1.0, 8.0, 2.0),  # Arch 0\n        (4.0, 2.0, 4.0, 1.0),  # Arch 1\n    ]\n\n    results = []\n    L = 1.0\n\n    for N, h, C, seed, d, arch_id in test_cases:\n        # --- 1. Setup ---\n        n = int(round(L / h))\n        n_x, n_y, n_z = n, n, n\n        n_cells = n_x * n_y * n_z\n        t_a, t_conf, a, b = architectures[arch_id]\n        rng = np.random.default_rng(seed)\n\n        # --- 2. Generate Particle Positions ---\n        if d == 0:  # Uniform\n            positions = rng.uniform(0, L, size=(N, 3))\n        elif d == 1:  # Clustered Gaussian\n            mean = np.array([0.25, 0.6, 0.8])\n            std_dev = 0.03\n            positions = rng.normal(loc=mean, scale=std_dev, size=(N, 3))\n            positions = positions % L\n        elif d == 2:  # Lattice\n            if N == 0:\n                positions = np.empty((0,3))\n            else:\n                grid_points_1d = np.arange(n) * h\n                gx, gy, gz = np.meshgrid(grid_points_1d, grid_points_1d, grid_points_1d, indexing='ij')\n                lattice_pts = np.stack([gx.ravel(), gy.ravel(), gz.ravel()], axis=-1)\n                num_lattice_pts = len(lattice_pts)\n                num_repeats = N // num_lattice_pts\n                remainder = N % num_lattice_pts\n                positions = np.vstack([\n                    np.tile(lattice_pts, (num_repeats, 1)),\n                    lattice_pts[:remainder]\n                ])\n\n        # Ensure positions are in [0, L)\n        positions = positions % L\n\n        # --- 3. Compute Cell IDs for all particles ---\n        # Using floor division after scaling is equivalent to floor(pos/h)\n        indices = np.floor(positions / h).astype(int)\n        # Clamp indices to be safe, although modulo should prevent out-of-bounds\n        indices = np.clip(indices, 0, n - 1)\n        ix, iy, iz = indices[:, 0], indices[:, 1], indices[:, 2]\n        particle_cell_ids = ix + n_x * (iy + n_y * iz)\n\n        # --- 4. Method 1: Atomic Insertion ---\n        atomic_cell_bins = np.full((n_cells, C), -1, dtype=int)\n        true_cell_counts = np.zeros(n_cells, dtype=int)\n        \n        for i in range(N):\n            c = particle_cell_ids[i]\n            k = true_cell_counts[c]\n            true_cell_counts[c] += 1\n            if k  C:\n                atomic_cell_bins[c, k] = i\n\n        # --- 5. Method 2: Sort-based Compaction ---\n        # Get true counts directly using bincount for efficiency and comparison\n        sort_cell_counts = np.bincount(particle_cell_ids, minlength=n_cells).astype(int)\n        \n        # Build cell starts array (exclusive prefix sum)\n        sort_cell_starts = np.zeros(n_cells, dtype=int)\n        sort_cell_starts[1:] = np.cumsum(sort_cell_counts[:-1])\n\n        # Sort particle indices by cell ID\n        particle_indices = np.arange(N)\n        sort_keys = np.argsort(particle_cell_ids, kind='stable')\n        sorted_particle_indices = particle_indices[sort_keys]\n\n        # --- 6. Correctness and Overflow Check ---\n        overflow_occurred = 1 if np.any(true_cell_counts > C) else 0\n        o = overflow_occurred\n        \n        is_correct = 1\n        if o == 1:\n            is_correct = 0\n        else:\n            # If no overflow, verify the contents of each bin\n            for c_idx in range(n_cells):\n                # Atomic method multiset\n                atomic_count = true_cell_counts[c_idx]\n                atomic_list = atomic_cell_bins[c_idx, :atomic_count]\n                \n                # Sort-based method multiset\n                start = sort_cell_starts[c_idx]\n                count = sort_cell_counts[c_idx]\n                sort_list = sorted_particle_indices[start : start + count]\n\n                # Multisets must be identical up to permutation\n                if not np.array_equal(np.sort(atomic_list), np.sort(sort_list)):\n                    is_correct = 0\n                    break\n        c_out = is_correct\n\n        # --- 7. Performance Model Calculation ---\n        # Use the definitively correct counts from the sort-based method\n        nc = sort_cell_counts\n        \n        T_atomic = t_a * N + t_conf * np.sum(nc * (nc - 1) / 2.0)\n        \n        # Avoid log2(0) if N=0 which is not in test cases but good practice\n        log2N = np.log2(N) if N > 0 else 0\n        T_sort = a * N * log2N + b * N\n        \n        f = 0 if T_atomic = T_sort else 1\n        \n        min_T = min(T_atomic, T_sort)\n        max_T = max(T_atomic, T_sort)\n        # Avoid division by zero if both times are zero\n        s = max_T / min_T if min_T > 0 else 1.0\n\n        results.append(f\"[{c_out},{o},{f},{s:.10f}]\")\n\n    # --- 8. Final Output ---\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3400614"}]}