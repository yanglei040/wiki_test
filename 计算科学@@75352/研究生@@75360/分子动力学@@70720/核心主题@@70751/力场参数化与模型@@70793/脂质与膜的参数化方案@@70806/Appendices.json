{"hands_on_practices": [{"introduction": "在验证脂质力场时，一个关键步骤是计算可与核磁共振（NMR）实验结果直接比较的物理量。氘序参数（$S_{CD}$）正是这样一个核心观测量，它量化了脂质酰基链中碳氢键相对于膜法线的平均取向。这项练习将指导你从第一性原理出发，通过处理模拟轨迹中的原子坐标，实现计算 $S_{CD}$ 的算法，这是评估和优化膜模型准确性的基本功。[@problem_id:3422101]", "problem": "要求您从第一性原理出发，实现一个算法，根据合成轨迹计算脂质酰基链的氘序参数（$S_{CD}$）。在分子动力学（MD）的脂质和膜参数化方案中，氘序参数用于对照核磁共振（NMR）测量结果来验证力场。氘序参数量化了碳-氢键相对于膜双层法向量的平均取向。\n\n从以下基本原理开始：\n- 在第 $f$ 帧中，双层法向量是一个向量 $\\mathbf{n}^{(f)}$，不一定被归一化。\n- 在第 $f$ 帧中，碳 $i$ 和氢 $h$ 的键向量为 $\\mathbf{v}_{i,h}^{(f)} = \\mathbf{r}_{i,h}^{(f)} - \\mathbf{r}_{i}^{(f)}$，其中 $\\mathbf{r}_{i}^{(f)}$ 是碳原子的位置，而 $\\mathbf{r}_{i,h}^{(f)}$ 是与其成键的氢原子的位置。\n- 瞬时取向由归一化键向量 $\\hat{\\mathbf{u}}_{i,h}^{(f)} = \\mathbf{v}_{i,h}^{(f)} / \\|\\mathbf{v}_{i,h}^{(f)}\\|$ 与归一化双层法向量 $\\hat{\\mathbf{n}}^{(f)} = \\mathbf{n}^{(f)} / \\|\\mathbf{n}^{(f)}\\|$ 之间夹角 $\\theta_{i,h}^{(f)}$ 的余弦值来表征，即 $\\cos \\theta_{i,h}^{(f)} = \\hat{\\mathbf{u}}_{i,h}^{(f)} \\cdot \\hat{\\mathbf{n}}^{(f)}$。\n- 氘序参数定义为 $\\cos \\theta$ 的二阶勒让德多项式 $P_{2}(x)$ 的系综平均值。二阶勒让德多项式为 $P_{2}(x) = \\frac{1}{2}\\left(3x^{2} - 1\\right)$。\n- 每键瞬时序为 $S_{i,h}^{(f)} = P_{2}\\!\\left(\\cos \\theta_{i,h}^{(f)}\\right)$。\n- 每碳瞬时序是在该帧中对与该碳成键的所有氢原子求平均值，即 $S_{i}^{(f)} = \\frac{1}{|H_{i}|} \\sum_{h \\in H_{i}} S_{i,h}^{(f)}$，而最终的每碳序参数是时间平均值 $S_{i} = \\frac{1}{F} \\sum_{f=1}^{F} S_{i}^{(f)}$。\n\n您必须实现一个程序，该程序：\n- 对于每个测试用例，接收一个帧列表。对于每一帧 $f$，给定一个双层法向量 $\\mathbf{n}^{(f)}$，并且对于每个碳 $i$，给定一个碳位置 $\\mathbf{r}_{i}^{(f)}$ 和一组氢位置 $\\{\\mathbf{r}_{i,h}^{(f)}\\}_{h \\in H_{i}}$。\n- 计算 $\\hat{\\mathbf{n}}^{(f)}$、每个 $\\hat{\\mathbf{u}}_{i,h}^{(f)}$、余弦值 $\\cos \\theta_{i,h}^{(f)}$、瞬时 $S_{i,h}^{(f)}$、每帧的 $S_{i}^{(f)}$，以及通过对所有帧求平均值得到的最终每碳 $S_{i}$。\n- 如果您显式计算任何角度 $\\theta$（这是可选的），则必须使用弧度。但是，建议您通过点积直接计算 $\\cos \\theta$ 以避免任何角度计算。\n- 对于每个测试用例，输出一个最终的每碳 $S_{i}$ 列表，四舍五入到六位小数。\n- 将所有测试用例的输出聚合到单行中，格式为一个由方括号括起来的逗号分隔列表，其中包含每个测试用例的一个列表，且没有空格（例如，$[list\\_1,list\\_2,list\\_3]$）。每个测试用例的列表本身必须是一个由方括号括起来、逗号分隔的六位小数浮点数列表。\n\n所有位置均以任意长度单位的笛卡尔坐标给出。序参数 $S_{i}$ 是无量纲的，必须报告为四舍五入到六位小数的浮点数。不使用外部输入；所有测试用例都嵌入在您的代码中。\n\n需要实现的测试套件：\n\n- 测试用例 1（两个碳，两帧，法向量固定）：\n  - 帧 1：\n    - 双层法向量：$\\mathbf{n}^{(1)} = (0.0, 0.0, 1.0)$。\n    - 碳 1：$\\mathbf{r}_{1}^{(1)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{1,1}^{(1)} = (0.866025403784, 0.0, 0.5)$ 和 $\\mathbf{r}_{1,2}^{(1)} = (0.0, 0.866025403784, 0.5)$。\n    - 碳 2：$\\mathbf{r}_{2}^{(1)} = (1.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{2,1}^{(1)} = (1.5, 0.0, 0.866025403784)$ 和 $\\mathbf{r}_{2,2}^{(1)} = (2.0, 0.0, 0.0)$。\n  - 帧 2：\n    - 双层法向量：$\\mathbf{n}^{(2)} = (0.0, 0.0, 1.0)$。\n    - 碳 1：$\\mathbf{r}_{1}^{(2)} = (0.1, 0.1, 0.0)$；氢原子 $\\mathbf{r}_{1,1}^{(2)} = (0.807106781187, 0.1, 0.707106781187)$ 和 $\\mathbf{r}_{1,2}^{(2)} = (0.1, 0.807106781187, 0.707106781187)$。\n    - 碳 2：$\\mathbf{r}_{2}^{(2)} = (1.0, 0.2, 0.0)$；氢原子 $\\mathbf{r}_{2,1}^{(2)} = (2.0, 0.2, 0.0)$ 和 $\\mathbf{r}_{2,2}^{(2)} = (1.0, 1.2, 0.0)$。\n\n- 测试用例 2（边界取向以及变化的法向量大小和符号）：\n  - 帧 1：\n    - 双层法向量：$\\mathbf{n}^{(1)} = (0.0, 0.0, 2.0)$。\n    - 碳 3：$\\mathbf{r}_{3}^{(1)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{3,1}^{(1)} = (0.0, 0.0, 1.0)$ 和 $\\mathbf{r}_{3,2}^{(1)} = (0.0, 0.0, 2.0)$。\n    - 碳 4：$\\mathbf{r}_{4}^{(1)} = (1.0, 1.0, 0.0)$；氢原子 $\\mathbf{r}_{4,1}^{(1)} = (2.0, 1.0, 0.0)$ 和 $\\mathbf{r}_{4,2}^{(1)} = (1.0, 2.0, 0.0)$。\n  - 帧 2：\n    - 双层法向量：$\\mathbf{n}^{(2)} = (0.0, 0.0, -3.0)$。\n    - 碳 3：$\\mathbf{r}_{3}^{(2)} = (0.0, 0.0, 0.5)$；氢原子 $\\mathbf{r}_{3,1}^{(2)} = (0.0, 0.0, 1.5)$ 和 $\\mathbf{r}_{3,2}^{(2)} = (0.0, 0.0, 2.5)$。\n    - 碳 4：$\\mathbf{r}_{4}^{(2)} = (1.0, 1.0, 0.5)$；氢原子 $\\mathbf{r}_{4,1}^{(2)} = (2.0, 1.0, 0.5)$ 和 $\\mathbf{r}_{4,2}^{(2)} = (1.0, 2.0, 0.5)$。\n\n- 测试用例 3（确定性地实现各向同性取向，使得期望平均值恰好为零）：\n  - 帧 1：\n    - 双层法向量：$\\mathbf{n}^{(1)} = (0.0, 0.0, 1.0)$。\n    - 碳 5：$\\mathbf{r}_{5}^{(1)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{5,1}^{(1)} = (0.0, 0.0, 1.0)$ 和 $\\mathbf{r}_{5,2}^{(1)} = (0.0, 0.0, -1.0)$。\n  - 帧 2：\n    - 双层法向量：$\\mathbf{n}^{(2)} = (0.0, 0.0, 1.0)$。\n    - 碳 5：$\\mathbf{r}_{5}^{(2)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{5,1}^{(2)} = (1.0, 0.0, 0.0)$ 和 $\\mathbf{r}_{5,2}^{(2)} = (-1.0, 0.0, 0.0)$。\n  - 帧 3：\n    - 双层法向量：$\\mathbf{n}^{(3)} = (0.0, 0.0, 1.0)$。\n    - 碳 5：$\\mathbf{r}_{5}^{(3)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{5,1}^{(3)} = (0.0, 1.0, 0.0)$ 和 $\\mathbf{r}_{5,2}^{(3)} = (0.0, -1.0, 0.0)$。\n\n您的程序必须生成单行输出，其中包含三个测试用例的结果，格式为由方括号括起的逗号分隔列表，无空格，其中每个数字都四舍五入到六位小数，例如：$[[$s_{1,1}$,$s_{1,2}] , [ $s_{2,1}$,$s_{2,2}] , [ $s_{3,1}$ ]]$ 但不含空格。具体来说，确切的格式必须类似于 $[[0.000000,0.000000],[0.000000,0.000000],[0.000000]]$。", "solution": "该问题是有效的，因为它具有科学依据、定义明确且客观。它提供了计算氘序参数 $S_{CD}$ 所需的正式定义和所有必要数据，该参数是脂质双层分子动力学模拟中的一个标准度量。\n\n计算最终每碳序参数 $S_i$ 的过程涉及一个分层平均过程，从瞬时键取向开始，对等效的氢原子和时间（模拟帧）进行平均。该算法通过直接应用所提供的公式来实现。\n\n首先，我们定义基本量。对于一个包含 $F$ 帧的轨迹中的每一帧 $f$，给定一个双层法向量 $\\mathbf{n}^{(f)}$，以及对于每个碳原子 $i$，其位置 $\\mathbf{r}_i^{(f)}$ 和与其成键的氢原子的位置 $\\{\\mathbf{r}_{i,h}^{(f)}\\}_{h \\in H_i}$。\n\n关键的取向度量是特定碳-氢键向量与双层法向量之间的夹角 $\\theta_{i,h}^{(f)}$。使用归一化向量的点积来计算是最高效的方法。\n\n双层法向量 $\\mathbf{n}^{(f)}$ 被归一化以获得单位向量 $\\hat{\\mathbf{n}}^{(f)}$：\n$$\n\\hat{\\mathbf{n}}^{(f)} = \\frac{\\mathbf{n}^{(f)}}{\\|\\mathbf{n}^{(f)}\\|}\n$$\n类似地，对于每个碳-氢对 $(i, h)$，通过从氢原子的位置减去碳原子的位置来计算键向量 $\\mathbf{v}_{i,h}^{(f)}$：\n$$\n\\mathbf{v}_{i,h}^{(f)} = \\mathbf{r}_{i,h}^{(f)} - \\mathbf{r}_{i}^{(f)}\n$$\n然后将此键向量归一化以获得单位向量 $\\hat{\\mathbf{u}}_{i,h}^{(f)}$：\n$$\n\\hat{\\mathbf{u}}_{i,h}^{(f)} = \\frac{\\mathbf{v}_{i,h}^{(f)}}{\\|\\mathbf{v}_{i,h}^{(f)}\\|}\n$$\n这两个单位向量之间夹角 $\\theta_{i,h}^{(f)}$ 的余弦值是它们的点积：\n$$\n\\cos \\theta_{i,h}^{(f)} = \\hat{\\mathbf{u}}_{i,h}^{(f)} \\cdot \\hat{\\mathbf{n}}^{(f)}\n$$\n氘序参数基于二阶勒让德多项式 $P_2(x) = \\frac{1}{2}(3x^2 - 1)$ 定义。在第 $f$ 帧中，单根键 $(i, h)$ 的瞬时序参数为：\n$$\nS_{i,h}^{(f)} = P_2(\\cos \\theta_{i,h}^{(f)}) = \\frac{1}{2}\\left(3(\\cos \\theta_{i,h}^{(f)})^2 - 1\\right)\n$$\n注意，因为 $\\cos^2(\\theta) = \\cos^2(\\pi-\\theta)$，序参数对法向量的方向不敏感（例如，$(0,0,1)$ vs. $(0,0,-1)$），这是一个物理上必需的性质。\n\n下一步是对与给定碳原子 $i$ 成键的所有氢原子求该量的平均值。这是必要的，因为对于像甲基（$CH_3$）或亚甲基（$CH_2$）这样的基团，在模拟旨在复现的实验（NMR）的时间尺度上，各个C-H键通常是动态等效的。因此，每碳瞬时序 $S_i^{(f)}$ 为：\n$$\nS_{i}^{(f)} = \\frac{1}{|H_i|} \\sum_{h \\in H_i} S_{i,h}^{(f)}\n$$\n其中 $|H_i|$ 是与碳 $i$ 成键的氢原子数量。\n\n最后，模拟提供了这些瞬时值的时间序列。碳 $i$ 的最终序参数 $S_i$ 是系综平均值，其计算方法是作为轨迹中所有 $F$ 帧的时间平均值：\n$$\nS_{i} = \\left\\langle S_i^{(f)} \\right\\rangle_f = \\frac{1}{F} \\sum_{f=1}^{F} S_{i}^{(f)}\n$$\n此过程被系统地应用于每个测试用例中指定的每个碳原子。实现将使用像 NumPy 这样的数值库来高效地执行向量运算，例如减法、范数计算和点积。每个碳的最终结果被收集并以要求的格式呈现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the deuterium order parameter (S_CD) for lipid acyl chains \n    from synthetic trajectory data provided in predefined test cases.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: Two carbons, two frames, normal fixed.\n        [\n            # Frame 1\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.866025403784, 0.0, 0.5]), np.array([0.0, 0.866025403784, 0.5])] },\n                    { \"r_c\": np.array([1.0, 0.0, 0.0]), \"r_hs\": [np.array([1.5, 0.0, 0.866025403784]), np.array([2.0, 0.0, 0.0])] }\n                ]\n            },\n            # Frame 2\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.1, 0.1, 0.0]), \"r_hs\": [np.array([0.807106781187, 0.1, 0.707106781187]), np.array([0.1, 0.807106781187, 0.707106781187])] },\n                    { \"r_c\": np.array([1.0, 0.2, 0.0]), \"r_hs\": [np.array([2.0, 0.2, 0.0]), np.array([1.0, 1.2, 0.0])] }\n                ]\n            }\n        ],\n        # Test Case 2: Boundary orientations and varying normal.\n        [\n            # Frame 1\n            {\n                \"n\": np.array([0.0, 0.0, 2.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.0, 0.0, 1.0]), np.array([0.0, 0.0, 2.0])] },\n                    { \"r_c\": np.array([1.0, 1.0, 0.0]), \"r_hs\": [np.array([2.0, 1.0, 0.0]), np.array([1.0, 2.0, 0.0])] }\n                ]\n            },\n            # Frame 2\n            {\n                \"n\": np.array([0.0, 0.0, -3.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.5]), \"r_hs\": [np.array([0.0, 0.0, 1.5]), np.array([0.0, 0.0, 2.5])] },\n                    { \"r_c\": np.array([1.0, 1.0, 0.5]), \"r_hs\": [np.array([2.0, 1.0, 0.5]), np.array([1.0, 2.0, 0.5])] }\n                ]\n            }\n        ],\n        # Test Case 3: Isotropic orientation.\n        [\n            # Frame 1\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.0, 0.0, 1.0]), np.array([0.0, 0.0, -1.0])] }\n                ]\n            },\n            # Frame 2\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([1.0, 0.0, 0.0]), np.array([-1.0, 0.0, 0.0])] }\n                ]\n            },\n            # Frame 3\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.0, 1.0, 0.0]), np.array([0.0, -1.0, 0.0])] }\n                ]\n            }\n        ]\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        num_frames = len(case_data)\n        num_carbons = len(case_data[0][\"carbons\"])\n        s_i_sum_over_frames = np.zeros(num_carbons)\n\n        for frame in case_data:\n            n_vec = frame[\"n\"]\n            # Normalize the bilayer normal\n            n_norm = np.linalg.norm(n_vec)\n            if n_norm == 0: continue # Should not happen with valid data\n            n_hat = n_vec / n_norm\n\n            for i, carbon_data in enumerate(frame[\"carbons\"]):\n                r_c = carbon_data[\"r_c\"]\n                r_hs = carbon_data[\"r_hs\"]\n                num_hydrogens = len(r_hs)\n                s_ih_sum_for_carbon = 0.0\n\n                for r_h in r_hs:\n                    # Calculate and normalize the C-H bond vector\n                    v_ih = r_h - r_c\n                    v_norm = np.linalg.norm(v_ih)\n                    if v_norm == 0: continue # Should not happen\n                    u_hat_ih = v_ih / v_norm\n                    \n                    # Calculate cos(theta) using the dot product\n                    cos_theta = np.dot(u_hat_ih, n_hat)\n                    \n                    # Calculate the instantaneous order parameter for the bond\n                    s_ih = 0.5 * (3 * cos_theta**2 - 1)\n                    s_ih_sum_for_carbon += s_ih\n                \n                # Average over hydrogens for the current carbon and frame\n                s_i_f = s_ih_sum_for_carbon / num_hydrogens if num_hydrogens > 0 else 0.0\n                s_i_sum_over_frames[i] += s_i_f\n        \n        # Average over frames for each carbon\n        final_s_i_values = s_i_sum_over_frames / num_frames if num_frames > 0 else np.zeros(num_carbons)\n        all_results.append(final_s_i_values)\n\n    # Format the final output string exactly as required\n    formatted_case_results = []\n    for result_list in all_results:\n        formatted_numbers = [f\"{val:.6f}\" for val in result_list]\n        formatted_case_results.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    final_output = f\"[{','.join(formatted_case_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3422101"}, {"introduction": "成功的力场参数化不仅仅是匹配单个实验数据，而是在多个相互关联的物理属性之间寻求最佳平衡。这项练习模拟了一个真实的优化过程：通过调节一个关键参数——磷脂头基与水之间的 Lennard-Jones 相互作用强度（$\\epsilon$），来同时满足膜的结构（厚度、粗糙度）和力学（面积压缩模量）目标。你将学习如何构建一个包含惩罚项的多目标优化函数，并利用线性响应模型来高效地探索参数空间，找到能够最佳复现多个实验目标的新参数。[@problem_id:3422074]", "problem": "您需要实现一个自洽的计算方案，该方案用于在分子动力学（MD）中调节磷脂双分子层的 Lennard-Jones 头基-水势阱深度参数，以满足其结构和力学目标。该方案必须表述为一个算法，在线性响应近似下将一个标量参数映射到测量可观测量，并通过面积压缩模量关系施加一个力学约束。该算法必须通过最小化一个明确定义的目标函数，为每个测试案例生成一个调节后的参数值，并且其实现必须以一个完整的、可运行的程序形式交付。\n\n头基-水之间的非键相互作用通过 Lennard-Jones (LJ) 势进行建模，其势阱深度为 $\\epsilon$，距离参数为 $\\sigma$。LJ 势的表达式为\n$$\nU_{\\mathrm{LJ}}(r;\\epsilon,\\sigma)=4\\,\\epsilon\\left[\\left(\\frac{\\sigma}{r}\\right)^{12}-\\left(\\frac{\\sigma}{r}\\right)^{6}\\right].\n$$\n在该方案中，头基-水的 LJ $\\epsilon$ 参数控制着水合作用和界面混合，并假定其调节三个可观测量：头基-头基厚度 $D_{HH}$、界面粗糙度 $w$（一维界面宽度）以及面积压缩模量 $K_A$。力学约束通过涨落关系施加\n$$\nK_A = \\frac{k_B\\,T\\,\\langle A\\rangle}{\\langle A^2\\rangle-\\langle A\\rangle^2},\n$$\n其中 $k_B$ 是玻尔兹曼常数，$T$ 是绝对温度，$A$ 是投影的双分子层面积。在参考力场状态附近的弱微扰下，该方案采用一个线性响应代理模型，将 $\\epsilon$ 映射到可观测量，具体如下：\n- 厚度响应：$D_{HH}(\\epsilon)=D_{\\mathrm{ref}}+\\chi_D\\left(\\epsilon-\\epsilon_{\\mathrm{ref}}\\right)$。\n- 界面宽度响应：$w(\\epsilon)=w_{\\mathrm{ref}}+\\chi_w\\left(\\epsilon-\\epsilon_{\\mathrm{ref}}\\right)$。\n- 平均面积响应：$\\langle A\\rangle(\\epsilon)=N_{\\ell}\\left(A_{\\mathrm{ref}}+\\chi_A\\left(\\epsilon-\\epsilon_{\\mathrm{ref}}\\right)\\right)$。\n- 面积方差响应：$\\mathrm{Var}(A)(\\epsilon)=\\mathrm{Var}_{\\mathrm{ref}}\\exp\\left[-\\beta_A\\left(\\epsilon-\\epsilon_{\\mathrm{ref}}\\right)\\right]$。\n\n所有可观测量必须使用一致的单位进行处理。以下提供的物理常数、参考值和响应系数必须精确使用：\n- 玻尔兹曼常数：$k_B = 1.380649\\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}$。\n- 温度：$T = 310\\,\\mathrm{K}$。\n- 双分子层中的脂质数量：$N_{\\ell}=128$。\n- 参考 LJ 势阱深度：$\\epsilon_{\\mathrm{ref}}=0.65\\,\\mathrm{kJ\\,mol^{-1}}$。\n- 参考厚度：$D_{\\mathrm{ref}}=3.60\\,\\mathrm{nm}$。\n- 参考界面宽度：$w_{\\mathrm{ref}}=0.35\\,\\mathrm{nm}$。\n- 参考每个脂质的面积：$A_{\\mathrm{ref}}=0.64\\,\\mathrm{nm^2}$。\n- 参考总面积方差：$\\mathrm{Var}_{\\mathrm{ref}}=1.40\\,\\mathrm{nm^4}$。\n- 厚度敏感系数：$\\chi_D=-0.25\\,\\mathrm{nm}\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$。\n- 宽度敏感系数：$\\chi_w=+0.15\\,\\mathrm{nm}\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$。\n- 面积敏感系数：$\\chi_A=+0.05\\,\\mathrm{nm^2}\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$。\n- 方差刚度参数：$\\beta_A=2.0\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$。\n\n该方案必须在物理上合理的边界内确定 $\\epsilon$ 的唯一值\n$$\n\\epsilon_{\\min}=0.20\\,\\mathrm{kJ\\,mol^{-1}},\\quad \\epsilon_{\\max}=1.20\\,\\mathrm{kJ\\,mol^{-1}},\n$$\n以最小化以下标量目标函数：\n$$\n\\mathcal{L}(\\epsilon)=w_D\\left(\\frac{D_{HH}(\\epsilon)-D_{HH}^{\\star}}{D_{HH}^{\\star}}\\right)^2+w_w\\left(\\frac{w(\\epsilon)-w^{\\star}}{w^{\\star}}\\right)^2+\\Pi_K(\\epsilon),\n$$\n其中 $D_{HH}^{\\star}$ 和 $w^{\\star}$ 是目标结构值，$w_D$ 和 $w_w$ 是正权重，$\\Pi_K(\\epsilon)$ 是一个力学约束惩罚项，用于强制实现目标面积压缩模量 $K_A^{\\star}$。当力学约束在容差 $\\delta_K$ 内得到满足时，惩罚项必须为零；否则，惩罚项必须随归一化偏差呈二次方增长：\n$$\n\\Pi_K(\\epsilon)=\n\\begin{cases}\n0,  \\text{如果 } \\left|K_A(\\epsilon)-K_A^{\\star}\\right| \\le \\delta_K \\\\[6pt]\nw_K\\left(\\dfrac{\\left|K_A(\\epsilon)-K_A^{\\star}\\right|-\\delta_K}{K_A^{\\star}}\\right)^2,  \\text{其他情况}\n\\end{cases}\n$$\n其中 $w_K0$ 是一个较大的权重。程序必须使用上面给出的涨落关系计算 $K_A(\\epsilon)$。为计算 $K_A$，您必须将 $\\langle A\\rangle$ 和 $\\mathrm{Var}(A)$ 转换为国际单位制（SI）：使用 $1\\,\\mathrm{nm^2}=10^{-18}\\,\\mathrm{m^2}$ 和 $1\\,\\mathrm{nm^4}=10^{-36}\\,\\mathrm{m^4}$。模量单位必须是 $\\mathrm{N\\,m^{-1}}$。\n\n惩罚权重和容差的数值规范：\n- 厚度权重：$w_D=1.0$。\n- 宽度权重：$w_w=1.0$。\n- 力学权重：$w_K=10^{6}$。\n- 模量容差：$\\delta_K=0.010\\,\\mathrm{N\\,m^{-1}}$。\n\n您的任务是实现一个程序，对于每个测试案例，在 $[\\epsilon_{\\min},\\epsilon_{\\max}]$ 区间内找到最小化 $\\mathcal{L}(\\epsilon)$ 的 $\\epsilon$ 值，并输出得到的 $\\epsilon$ 值。请使用一个稳健的有界标量优化方法。\n\n单位和输出要求：\n- 以 $\\mathrm{kJ\\,mol^{-1}}$ 为单位报告调节后的 LJ 势阱深度，四舍五入到三位小数。\n- 此问题不涉及角度。\n- 最终输出必须是一行，其中包含所有测试案例的调节后的 $\\epsilon$ 值，形式为用方括号括起来的逗号分隔列表，例如：$[\\epsilon_1,\\epsilon_2,\\epsilon_3]$。\n\n测试套件：\n对于每个测试案例 $i$，给定 $(D_{HH}^{\\star}, w^{\\star}, K_A^{\\star})$ 如下。所有厚度和宽度单位均为 $\\mathrm{nm}$，$K_A^{\\star}$ 单位为 $\\mathrm{N\\,m^{-1}}$。\n- 案例 1：$D_{HH}^{\\star}=3.58\\,\\mathrm{nm}$，$w^{\\star}=0.36\\,\\mathrm{nm}$，$K_A^{\\star}=0.25\\,\\mathrm{N\\,m^{-1}}$。\n- 案例 2：$D_{HH}^{\\star}=3.54\\,\\mathrm{nm}$，$w^{\\star}=0.40\\,\\mathrm{nm}$，$K_A^{\\star}=0.30\\,\\mathrm{N\\,m^{-1}}$。\n- 案例 3：$D_{HH}^{\\star}=3.70\\,\\mathrm{nm}$，$w^{\\star}=0.30\\,\\mathrm{nm}$，$K_A^{\\star}=0.20\\,\\mathrm{N\\,m^{-1}}$。\n- 案例 4：$D_{HH}^{\\star}=3.45\\,\\mathrm{nm}$，$w^{\\star}=0.44\\,\\mathrm{nm}$，$K_A^{\\star}=0.35\\,\\mathrm{N\\,m^{-1}}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[\\epsilon_1,\\epsilon_2,\\epsilon_3,\\epsilon_4]$），其中每个 $\\epsilon_i$ 是案例 $i$ 调节后的 LJ 势阱深度（单位为 $\\mathrm{kJ\\,mol^{-1}}$），四舍五入到三位小数。程序必须能够“按原样”运行，无需用户输入，且仅使用允许的库。", "solution": "该问题被认为是有效的，因为它具有科学依据、提法明确、客观且自洽。它基于分子动力学模拟和统计力学中的既定原理，提出了一个清晰的计算任务。所有需要的数据、常数和函数形式均已提供，不存在内部矛盾或歧义。\n\n该解决方案旨在为磷脂双分子层模拟中的头基-水相互作用找到 Lennard-Jones 势阱深度参数 $\\epsilon$ 的最优值。这是通过在指定区间 $[\\epsilon_{\\min}, \\epsilon_{\\max}]$ 上最小化一个多项目标函数 $\\mathcal{L}(\\epsilon)$ 来实现的。该过程可以系统地分解为几个阶段：定义物理模型、构建目标函数和执行数值优化。\n\n首先，我们建立系统性质作为参数 $\\epsilon$ 的函数的数学表示。问题提供了线性响应和指数衰减模型，描述了关键可观测量相对于参考状态（$\\epsilon_{\\mathrm{ref}}$）如何随 $\\epsilon$ 变化。这些可观测量是头基-头基厚度 $D_{HH}$、界面宽度 $w$、平均双分子层总面积 $\\langle A\\rangle$ 以及总面积的方差 $\\mathrm{Var}(A) = \\langle A^2\\rangle - \\langle A \\rangle^2$。\n\n头基-头基厚度模型为：\n$$\nD_{HH}(\\epsilon) = D_{\\mathrm{ref}} + \\chi_D (\\epsilon - \\epsilon_{\\mathrm{ref}})\n$$\n其中 $D_{\\mathrm{ref}}=3.60\\,\\mathrm{nm}$ 是参考厚度，$\\epsilon_{\\mathrm{ref}}=0.65\\,\\mathrm{kJ\\,mol^{-1}}$ 是参考 LJ 参数，而 $\\chi_D=-0.25\\,\\mathrm{nm}\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$ 是厚度敏感系数。\n\n界面宽度模型为：\n$$\nw(\\epsilon) = w_{\\mathrm{ref}} + \\chi_w (\\epsilon - \\epsilon_{\\mathrm{ref}})\n$$\n其参考宽度为 $w_{\\mathrm{ref}}=0.35\\,\\mathrm{nm}$，敏感系数为 $\\chi_w=+0.15\\,\\mathrm{nm}\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$。\n\n由 $N_{\\ell}=128$ 个脂质组成的双分子层平均总面积模型为：\n$$\n\\langle A \\rangle(\\epsilon) = N_{\\ell} \\left( A_{\\mathrm{ref}} + \\chi_A (\\epsilon - \\epsilon_{\\mathrm{ref}}) \\right)\n$$\n其中 $A_{\\mathrm{ref}}=0.64\\,\\mathrm{nm^2}$ 是参考每个脂质的面积，$\\chi_A=+0.05\\,\\mathrm{nm^2}\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$ 是面积敏感系数。\n\n总面积方差的模型由指数关系给出：\n$$\n\\mathrm{Var}(A)(\\epsilon) = \\mathrm{Var}_{\\mathrm{ref}} \\exp \\left[ -\\beta_A (\\epsilon - \\epsilon_{\\mathrm{ref}}) \\right]\n$$\n其参考方差为 $\\mathrm{Var}_{\\mathrm{ref}}=1.40\\,\\mathrm{nm^4}$，刚度参数为 $\\beta_A=2.0\\,\\mathrm{(kJ\\,mol^{-1})^{-1}}$。\n\n一个关键的力学性质，即面积压缩模量 $K_A$，是利用统计力学中的涨落关系从这些量推导出来的：\n$$\nK_A(\\epsilon) = \\frac{k_B T \\langle A \\rangle(\\epsilon)}{\\mathrm{Var}(A)(\\epsilon)}\n$$\n这里，$k_B = 1.380649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}$ 是玻尔兹曼常数，$T=310\\,\\mathrm{K}$ 是温度。对于此计算，单位一致性至关重要。面积 $\\langle A \\rangle$ 必须从 $\\mathrm{nm^2}$ 转换为 $\\mathrm{m^2}$（使用 $1\\,\\mathrm{nm^2} = 10^{-18}\\,\\mathrm{m^2}$），方差 $\\mathrm{Var}(A)$ 必须从 $\\mathrm{nm^4}$ 转换为 $\\mathrm{m^4}$（使用 $1\\,\\mathrm{nm^4} = 10^{-36}\\,\\mathrm{m^4}$）。这确保了 $K_A$ 的计算单位为 $\\mathrm{J\\,m^{-2}}$，等效于 $\\mathrm{N\\,m^{-1}}$。\n\n任务的核心是最小化目标函数 $\\mathcal{L}(\\epsilon)$：\n$$\n\\mathcal{L}(\\epsilon) = w_D \\left( \\frac{D_{HH}(\\epsilon) - D_{HH}^{\\star}}{D_{HH}^{\\star}} \\right)^2 + w_w \\left( \\frac{w(\\epsilon) - w^{\\star}}{w^{\\star}} \\right)^2 + \\Pi_K(\\epsilon)\n$$\n该函数量化了每个测试案例中模型预测的可观测量与其各自目标值 $(D_{HH}^{\\star}, w^{\\star}, K_A^{\\star})$ 的偏差。这些项的权重为 $w_D=1.0$ 和 $w_w=1.0$。\n\n第三项 $\\Pi_K(\\epsilon)$ 是一个惩罚函数，旨在对 $K_A$ 施加力学约束。其定义为：\n$$\n\\Pi_K(\\epsilon) =\n\\begin{cases}\n0,  \\text{如果 } |K_A(\\epsilon) - K_A^{\\star}| \\le \\delta_K \\\\\nw_K \\left( \\frac{|K_A(\\epsilon) - K_A^{\\star}| - \\delta_K}{K_A^{\\star}} \\right)^2,  \\text{其他情况}\n\\end{cases}\n$$\n当计算出的模量 $K_A(\\epsilon)$ 与目标值 $K_A^{\\star}$ 的偏差超过指定的容差 $\\delta_K=0.010\\,\\mathrm{N\\,m^{-1}}$ 时，此函数会施加一个大的二次惩罚。惩罚权重很大，为 $w_K=10^6$，以强力施加该约束。\n\n总体算法如下：\n1. 对于由一组目标值 $(D_{HH}^{\\star}, w^{\\star}, K_A^{\\star})$ 定义的每个测试案例：\n2. 定义目标函数 $\\mathcal{L}(\\epsilon)$，该函数封装了该特定案例的所有模型方程和目标值。\n3. 使用数值优化算法，在有界区间 $[\\epsilon_{\\min}, \\epsilon_{\\max}] = [0.20, 1.20]\\,\\mathrm{kJ\\,mol^{-1}}$ 中找到最小化 $\\mathcal{L}(\\epsilon)$ 的 $\\epsilon$ 值。一个合适的方法是有界标量最小化器，例如 `scipy.optimize` 库中提供的方法。\n4. 最小化该函数的 $\\epsilon$ 值即为该测试案例的调节参数。\n5. 将结果四舍五入到三位小数并报告。\n\n此过程是确定性的，在计算上简单明了，为每组目标值产生唯一的最佳参数 $\\epsilon$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Implements the full computational protocol to find the optimal LJ parameter epsilon\n    for several test cases by minimizing a defined objective function.\n    \"\"\"\n\n    # --- Step 1: Define all constants, reference values, and parameters ---\n    # Physical constants\n    KB_J_K = 1.380649e-23  # Boltzmann constant in J/K\n    T_K = 310.0            # Temperature in K\n    K_B_T_J = KB_J_K * T_K # Thermal energy in Joules\n\n    # System and reference parameters\n    N_LIPIDS = 128\n    EPS_REF_KJ_MOL = 0.65     # Reference epsilon in kJ/mol\n    D_REF_NM = 3.60           # Reference thickness in nm\n    W_REF_NM = 0.35           # Reference width in nm\n    A_REF_PER_LIPID_NM2 = 0.64 # Reference area per lipid in nm^2\n    VAR_A_REF_NM4 = 1.40      # Reference total area variance in nm^4\n\n    # Response coefficients\n    CHI_D = -0.25  # nm / (kJ/mol)\n    CHI_W = 0.15   # nm / (kJ/mol)\n    CHI_A = 0.05   # nm^2 / (kJ/mol)\n    BETA_A = 2.0   # (kJ/mol)^-1\n\n    # Optimization bounds for epsilon\n    EPS_MIN_KJ_MOL = 0.20\n    EPS_MAX_KJ_MOL = 1.20\n\n    # Objective function weights and penalty parameters\n    W_D = 1.0\n    W_W = 1.0\n    W_K = 1.0e6\n    DELTA_K_N_M = 0.010  # Tolerance for K_A in N/m\n\n    # Unit conversion factors\n    NM2_TO_M2 = 1.0e-18\n    NM4_TO_M4 = 1.0e-36\n\n    # Test suite: (D_HH_star_nm, w_star_nm, K_A_star_N_m)\n    test_cases = [\n        (3.58, 0.36, 0.25),\n        (3.54, 0.40, 0.30),\n        (3.70, 0.30, 0.20),\n        (3.45, 0.44, 0.35),\n    ]\n\n    # --- Step 2: Define the response functions for observables ---\n    def get_D_HH(eps):\n        # Calculates headgroup-headgroup thickness D_HH in nm\n        return D_REF_NM + CHI_D * (eps - EPS_REF_KJ_MOL)\n\n    def get_w(eps):\n        # Calculates interfacial width w in nm\n        return W_REF_NM + CHI_W * (eps - EPS_REF_KJ_MOL)\n\n    def get_mean_A(eps):\n        # Calculates mean total area in nm^2\n        area_per_lipid = A_REF_PER_LIPID_NM2 + CHI_A * (eps - EPS_REF_KJ_MOL)\n        return N_LIPIDS * area_per_lipid\n\n    def get_var_A(eps):\n        # Calculates variance of total area in nm^4\n        return VAR_A_REF_NM4 * np.exp(-BETA_A * (eps - EPS_REF_KJ_MOL))\n\n    def get_K_A(eps):\n        # Calculates area compressibility modulus K_A in N/m\n        mean_A_nm2 = get_mean_A(eps)\n        var_A_nm4 = get_var_A(eps)\n        \n        mean_A_m2 = mean_A_nm2 * NM2_TO_M2\n        var_A_m4 = var_A_nm4 * NM4_TO_M4\n        \n        if var_A_m4 == 0:\n            return float('inf')\n            \n        k_a = (K_B_T_J * mean_A_m2) / var_A_m4\n        return k_a\n\n    def objective_function(eps, D_HH_star, w_star, K_A_star):\n        # The full objective function L(epsilon)\n        \n        # Calculate predicted observables\n        D_HH_pred = get_D_HH(eps)\n        w_pred = get_w(eps)\n        K_A_pred = get_K_A(eps)\n        \n        # Structural loss terms\n        loss_D = W_D * ((D_HH_pred - D_HH_star) / D_HH_star)**2\n        loss_W = W_W * ((w_pred - w_star) / w_star)**2\n        \n        # Mechanical penalty term\n        K_A_deviation = abs(K_A_pred - K_A_star)\n        if K_A_deviation = DELTA_K_N_M:\n            penalty_K = 0.0\n        else:\n            penalty_K = W_K * (((K_A_deviation - DELTA_K_N_M) / K_A_star)**2)\n            \n        return loss_D + loss_W + penalty_K\n\n    # --- Step 3: Run the optimization for each test case ---\n    optimal_epsilons = []\n    for D_HH_star, w_star, K_A_star in test_cases:\n        res = minimize_scalar(\n            objective_function,\n            bounds=(EPS_MIN_KJ_MOL, EPS_MAX_KJ_MOL),\n            args=(D_HH_star, w_star, K_A_star),\n            method='bounded'\n        )\n        optimal_epsilons.append(res.x)\n\n    # --- Step 4: Format and print the final output ---\n    formatted_results = [f\"{val:.3f}\" for val in optimal_epsilons]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3422074"}, {"introduction": "一个参数化方案的最终成功标准是其预测能力，即模型能否准确描述训练数据之外的新情况。为避免“过拟合”——模型仅能记住训练数据而失去普适性——我们必须评估其泛化能力。这项高级练习将引导你实现一个交叉验证框架，通过系统性地在不同类型的物理目标（如结构与力学性质）和不同的脂质组分之间进行训练和验证，来量化模型的泛化误差，从而为力场的可靠性和可移植性提供严格的统计评估。[@problem_id:3422163]", "problem": "要求您形式化并实现一个用于脂质和膜力场参数化的交叉验证框架，该框架通过循环使用训练目标和验证目标，来量化不同独立脂质组分间的过拟合程度。该框架必须使用一个关于参数的可观测量的一阶线性响应模型、一个源于高斯误差假设且符合统计原理的加权最小二乘目标，以及 Tikhonov 正则化。您编写的程序必须为多个测试用例中的每一个计算一个标量泛化误差，并按规定将结果以单行单个列表的形式打印出来。\n\n从以下基本依据和定义开始：\n- 在小的参数变化下，分子动力学可观测量预测值可以通过围绕一个参考点的线性响应来近似，即 $y \\approx y_0 + J p$，其中 $p \\in \\mathbb{R}^d$ 是参数校正向量，$y \\in \\mathbb{R}^m$ 是可观测量，$J \\in \\mathbb{R}^{m \\times d}$ 是灵敏度（雅可比）矩阵，$y_0$ 是参考预测值。\n- 在具有已知标准差 $\\sigma_i$ 的独立高斯测量误差下，加权最小二乘法是最优的，其损失函数正比于 $\\sum_i \\left(\\frac{r_i}{\\sigma_i}\\right)^2$，其中 $r_i$ 是残差。这构建了一个无量纲、单位一致的目标函数。\n- Tikhonov 正则化等效于对参数施加高斯先验，即在损失函数中加入 $\\lambda \\lVert \\Gamma p \\rVert_2^2$ 项，其中正则化强度 $\\lambda \\ge 0$，$\\Gamma$ 是一个矩阵。\n\n您将实现一个双向目标循环的留一（组分）法交叉验证：\n- 对于每个留出的组分 $c^\\star$，执行两轮操作：\n  1. 使用除 $c^\\star$ 外所有组分的结构目标 $T=\\{A_\\mathrm{lipid}, S_{CD}\\}$ 的聚合数据进行训练，并在留出的组分 $c^\\star$ 的力学目标 $V=\\{K_A, K_C\\}$ 上进行验证。\n  2. 使用除 $c^\\star$ 外所有组分的 $V$ 的聚合数据进行训练，并在留出的组分 $c^\\star$ 的 $T$ 上进行验证。\n- 对于每一轮训练，通过在训练集上最小化正则化加权最小二乘目标函数来获得参数估计值 $\\hat p$。具体来说，如果堆叠的训练系统是 $W J \\in \\mathbb{R}^{M \\times d}$ 和 $W b \\in \\mathbb{R}^{M}$，其中 $b = y - y_0$ 是残差目标向量，$W$ 是对角元素为 $1/\\sigma_i$ 的对角矩阵，那么正规方程为\n$$\n\\left( (WJ)^\\top (WJ) + \\lambda \\Gamma^\\top \\Gamma \\right)\\hat p = (WJ)^\\top (Wb).\n$$\n- 将每个组分、每个目标的平均归一化（无量纲）损失定义如下。对于任意组分 $c$ 和目标集 $X \\in \\{T,V\\}$，令 $n_X$ 为一个组分中 $X$ 的可观测量数量。定义\n$$\n\\mathcal{L}_X(c;\\hat p) = \\frac{1}{n_X}\\left\\lVert W_X^{(c)}\\left(J_X^{(c)} \\hat p - b_X^{(c)}\\right)\\right\\rVert_2^2,\n$$\n其中 $W_X^{(c)}$ 是目标集 $X$ 中标准差倒数的对角矩阵，$J_X^{(c)}$ 和 $b_X^{(c)}$ 是组分 $c$ 的特定于目标的灵敏度矩阵和残差向量。\n- 对于给定的留出组分 $c^\\star$，将在所包含的组分 $S = \\{c \\ne c^\\star\\}$ 上的训练平均归一化损失定义为\n$$\n\\overline{\\mathcal{L}}_X^{\\mathrm{train}}(\\hat p) = \\frac{1}{|S|} \\sum_{c \\in S} \\mathcal{L}_X(c;\\hat p).\n$$\n- 将留出组分 $c^\\star$ 的特定轮次的泛化差距定义为\n$$\n\\Delta_{T \\rightarrow V}(c^\\star) = \\mathcal{L}_V(c^\\star;\\hat p_T) - \\overline{\\mathcal{L}}_T^{\\mathrm{train}}(\\hat p_T),\n$$\n$$\n\\Delta_{V \\rightarrow T}(c^\\star) = \\mathcal{L}_T(c^\\star;\\hat p_V) - \\overline{\\mathcal{L}}_V^{\\mathrm{train}}(\\hat p_V),\n$$\n其中 $\\hat p_T$ 是使用 $S$ 在 $T$ 上训练得到的，$\\hat p_V$ 是使用 $S$ 在 $V$ 上训练得到的。\n- 该折的泛化误差是对称化平均值\n$$\n\\mathcal{E}(c^\\star) = \\frac{1}{2}\\left[\\Delta_{T \\rightarrow V}(c^\\star) + \\Delta_{V \\rightarrow T}(c^\\star)\\right].\n$$\n- 最终泛化误差是所有留出组分的平均值：\n$$\n\\mathcal{E} = \\frac{1}{C} \\sum_{c^\\star=1}^C \\mathcal{E}(c^\\star).\n$$\n\n所有计算必须使用提供的数值测试套件完成。所有残差向量 $b$ 都是差值 $y - y_0$，因此您不需要显式地使用 $y_0$。权重始终是所提供标准差的倒数，并且所有损失通过此归一化都变为无量纲。使用提供的 $\\lambda$ 和 $\\Gamma$ 进行 Tikhonov 正则化。如果正规方程的矩阵是病态的，请使用数值上稳定的方法（例如，Moore–Penrose 伪逆）来获取 $\\hat p$。\n\n物理单位和换算：\n- $A_\\mathrm{lipid}$ 的单位是 $\\mathrm{nm}^2$，标准差的单位是 $\\mathrm{nm}^2$。\n- $S_{CD}$ 是无量纲的，其标准差也是无量纲的。\n- $K_A$ 的单位是 $\\mathrm{mN}/\\mathrm{m}$，标准差的单位是 $\\mathrm{mN}/\\mathrm{m}$。\n- $K_C$ 的单位是 $k_B T$，标准差的单位是 $k_B T$。\n- 所有损失由于通过标准差加权而无单位。\n\n本问题不涉及角度单位。\n\n您的程序必须实现上述内容，并为每个测试用例生成最终泛化误差 $\\mathcal{E}$。每个结果必须是四舍五入到六位小数的单个浮点数。最终输出必须是单行，其中包含一个用方括号括起来的、逗号分隔的结果列表，例如 $[0.123456,0.000001,2.718282]$。\n\n测试套件：\n- 测试用例 1（良态，现实尺度）：\n  - 参数：$d=2$, $C=3$, $\\lambda = 0.1$, $\\Gamma = \\mathrm{diag}(1,1)$。\n  - 组分 1：\n    - $J_T^{(1)} = \\begin{bmatrix} -0.08  -0.02 \\\\ 0.15  0.05 \\end{bmatrix}$, $b_T^{(1)} = \\begin{bmatrix} 0.05 \\\\ -0.08 \\end{bmatrix}$, $\\sigma_T^{(1)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(1)} = \\begin{bmatrix} 30.0  10.0 \\\\ 1.8  0.6 \\end{bmatrix}$, $b_V^{(1)} = \\begin{bmatrix} -20.0 \\\\ -1.0 \\end{bmatrix}$, $\\sigma_V^{(1)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 2：\n    - $J_T^{(2)} = \\begin{bmatrix} -0.09  -0.01 \\\\ 0.12  0.04 \\end{bmatrix}$, $b_T^{(2)} = \\begin{bmatrix} 0.03 \\\\ -0.05 \\end{bmatrix}$, $\\sigma_T^{(2)} = \\begin{bmatrix} 0.012 \\\\ 0.012 \\end{bmatrix}$。\n    - $J_V^{(2)} = \\begin{bmatrix} 28.0  9.0 \\\\ 1.6  0.5 \\end{bmatrix}$, $b_V^{(2)} = \\begin{bmatrix} -15.0 \\\\ -0.8 \\end{bmatrix}$, $\\sigma_V^{(2)} = \\begin{bmatrix} 12.0 \\\\ 1.2 \\end{bmatrix}$。\n  - 组分 3：\n    - $J_T^{(3)} = \\begin{bmatrix} -0.07  -0.015 \\\\ 0.10  0.03 \\end{bmatrix}$, $b_T^{(3)} = \\begin{bmatrix} 0.04 \\\\ -0.07 \\end{bmatrix}$, $\\sigma_T^{(3)} = \\begin{bmatrix} 0.011 \\\\ 0.011 \\end{bmatrix}$。\n    - $J_V^{(3)} = \\begin{bmatrix} 26.0  8.5 \\\\ 1.4  0.45 \\end{bmatrix}$, $b_V^{(3)} = \\begin{bmatrix} -18.0 \\\\ -0.9 \\end{bmatrix}$, $\\sigma_V^{(3)} = \\begin{bmatrix} 11.0 \\\\ 1.1 \\end{bmatrix}$。\n- 测试用例 2（接近奇异的训练雅可比矩阵；测试正则化鲁棒性）：\n  - 参数：$d=2$, $C=3$, $\\lambda = 0.05$, $\\Gamma = \\mathrm{diag}(1,1)$。\n  - 组分 1：\n    - $J_T^{(1)} = \\begin{bmatrix} -0.08  -0.04 \\\\ 0.16  0.08 \\end{bmatrix}$, $b_T^{(1)} = \\begin{bmatrix} 0.02 \\\\ -0.04 \\end{bmatrix}$, $\\sigma_T^{(1)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(1)} = \\begin{bmatrix} 20.0  5.0 \\\\ 1.0  0.25 \\end{bmatrix}$, $b_V^{(1)} = \\begin{bmatrix} -10.0 \\\\ -0.5 \\end{bmatrix}$, $\\sigma_V^{(1)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 2：\n    - $J_T^{(2)} = \\begin{bmatrix} -0.081  -0.0405 \\\\ 0.162  0.081 \\end{bmatrix}$, $b_T^{(2)} = \\begin{bmatrix} 0.018 \\\\ -0.036 \\end{bmatrix}$, $\\sigma_T^{(2)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(2)} = \\begin{bmatrix} 21.0  5.2 \\\\ 1.05  0.26 \\end{bmatrix}$, $b_V^{(2)} = \\begin{bmatrix} -9.0 \\\\ -0.45 \\end{bmatrix}$, $\\sigma_V^{(2)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 3：\n    - $J_T^{(3)} = \\begin{bmatrix} -0.079  -0.0395 \\\\ 0.158  0.079 \\end{bmatrix}$, $b_T^{(3)} = \\begin{bmatrix} 0.022 \\\\ -0.044 \\end{bmatrix}$, $\\sigma_T^{(3)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(3)} = \\begin{bmatrix} 19.0  4.8 \\\\ 0.95  0.24 \\end{bmatrix}$, $b_V^{(3)} = \\begin{bmatrix} -11.0 \\\\ -0.55 \\end{bmatrix}$, $\\sigma_V^{(3)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n- 测试用例 3（完全一致的线性模型；预期泛化误差接近于零）：\n  - 参数：$d=2$, $C=3$, $\\lambda = 0.000001$, $\\Gamma = \\mathrm{diag}(1,1)$。存在一个真实参数向量 $p^\\star = \\begin{bmatrix} 0.5 \\\\ -0.2 \\end{bmatrix}$。残差目标生成为 $b = J p^\\star$，以使每个组分的训练和验证目标联合一致。\n  - 组分 1：\n    - $J_T^{(1)} = \\begin{bmatrix} -0.06  0.01 \\\\ 0.12  -0.02 \\end{bmatrix}$, $b_T^{(1)} = \\begin{bmatrix} -0.032 \\\\ 0.064 \\end{bmatrix}$, $\\sigma_T^{(1)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(1)} = \\begin{bmatrix} 25.0  -2.0 \\\\ 1.3  -0.12 \\end{bmatrix}$, $b_V^{(1)} = \\begin{bmatrix} 12.9 \\\\ 0.674 \\end{bmatrix}$, $\\sigma_V^{(1)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 2：\n    - $J_T^{(2)} = \\begin{bmatrix} -0.065  0.015 \\\\ 0.11  -0.018 \\end{bmatrix}$, $b_T^{(2)} = \\begin{bmatrix} -0.0355 \\\\ 0.0586 \\end{bmatrix}$, $\\sigma_T^{(2)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(2)} = \\begin{bmatrix} 27.0  -1.8 \\\\ 1.5  -0.10 \\end{bmatrix}$, $b_V^{(2)} = \\begin{bmatrix} 13.86 \\\\ 0.77 \\end{bmatrix}$, $\\sigma_V^{(2)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 3：\n    - $J_T^{(3)} = \\begin{bmatrix} -0.055  0.012 \\\\ 0.105  -0.017 \\end{bmatrix}$, $b_T^{(3)} = \\begin{bmatrix} -0.0299 \\\\ 0.0559 \\end{bmatrix}$, $\\sigma_T^{(3)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(3)} = \\begin{bmatrix} 24.0  -2.2 \\\\ 1.2  -0.13 \\end{bmatrix}$, $b_V^{(3)} = \\begin{bmatrix} 12.44 \\\\ 0.626 \\end{bmatrix}$, $\\sigma_V^{(3)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n\n答案规格：\n- 对于每个测试用例，按上述定义计算 $\\mathcal{E}$。每个输出必须是四舍五入到六位小数的浮点数。\n- 最终输出格式：您的程序必须生成单行输出，其中包含一个用方括号括起来的、逗号分隔的结果列表（例如，$[0.123456,0.000001,2.718282]$）。", "solution": "该问题提出了一个定义明确且有科学依据的任务：形式化并实现一个用于量化脂质力场参数化中泛化误差的交叉验证框架。该方法论基于计算化学中的既定原则，包括线性响应理论、加权最小二乘优化和 Tikhonov 正则化。问题陈述是完整、一致的，并提供了进行求解所需的所有数学定义和数值数据。\n\n问题的核心是实现一个留一（组分）法交叉验证 (LOOCV) 方案。对于一组 $C$ 个不同的脂质组分，我们迭代地将一个组分 $c^\\star$ 留出用于验证，并使用其余的 $S = C-1$ 个组分进行训练。该方案的独特之处在于 LOOCV 的每一折中执行的“目标循环”方法。这涉及两个独立的训练和验证轮次：一轮使用结构性质 ($T$) 进行训练，用力学性质 ($V$) 进行验证；第二轮则角色互换。此过程旨在评估在一个类型的物理可观测量上训练的参数，能多好地预测另一个独立类型的可观测量，这是对过拟合和模型可移植性的关键测试。\n\n最终度量指标，即泛化误差 $\\mathcal{E}$，是在所有折上计算的对称化“泛化差距”的平均值。这提供了一个单一、鲁棒的标量，用于量化模型在未见过的数据和未见过的可观测量类型上的预测能力。\n\n解决方案首先定义数学组件，然后概述算法步骤。\n\n**1. 数学框架**\n\n参数优化基于最小化一个正则化的、加权的最小二乘目标函数。可观测量 $y_i$ 的预测值通过围绕一个参考参数集的一阶泰勒展开来近似：$y \\approx y_0 + J p$。我们的目标是找到参数校正向量 $p \\in \\mathbb{R}^d$，使其能最佳拟合目标值，这些目标值以残差向量 $b = y^{\\mathrm{exp}} - y_0$ 的形式给出，其中 $y^{\\mathrm{exp}}$ 是实验目标值。\n\n给定一组训练目标，其残差为 $b_i$，相应的测量不确定度为 $\\sigma_i$，要最小化的目标函数是：\n$$ \\mathcal{O}(p) = \\sum_{i \\in \\text{train}} \\left(\\frac{(J p - b)_i}{\\sigma_i}\\right)^2 + \\lambda \\lVert \\Gamma p \\rVert_2^2 $$\n此处，第一项是加权残差平方和，在假设高斯误差的情况下，它构成一个无量纲量。第二项是 Tikhonov 正则化惩罚项，其中 $\\lambda \\ge 0$ 是正则化强度，$\\Gamma$ 是一个可用于缩放不同参数惩罚的矩阵。\n\n用矩阵表示法，令 $W$ 为一个对角元素为 $W_{ii} = 1/\\sigma_i$ 的对角矩阵。目标函数变为：\n$$ \\mathcal{O}(p) = \\lVert W(Jp - b) \\rVert_2^2 + \\lambda \\lVert \\Gamma p \\rVert_2^2 $$\n对 $p$ 最小化此目标函数可得到正规方程：\n$$ \\left( J^\\top W^\\top W J + \\lambda \\Gamma^\\top \\Gamma \\right) \\hat p = J^\\top W^\\top W b $$\n令 $\\tilde{J} = WJ$ 和 $\\tilde{b} = Wb$，最优参数估计 $\\hat p$ 的方程简化为：\n$$ \\left( \\tilde{J}^\\top \\tilde{J} + \\lambda \\Gamma^\\top \\Gamma \\right) \\hat p = \\tilde{J}^\\top \\tilde{b} $$\n这是一个标准线性系统 $A\\hat p = B$，可以求解得到 $\\hat p$。正则化项 $\\lambda \\Gamma^\\top \\Gamma$ 确保了当 $\\lambda  0$ 时矩阵 $A$ 是正定的，因而是可逆的，即使 $\\tilde{J}^\\top \\tilde{J}$ 是奇异的，也能保证唯一解。\n\n问题为给定的组分 $c$ 和目标集 $X \\in \\{T, V\\}$ 定义了一个特定的无量纲损失函数：\n$$ \\mathcal{L}_X(c; \\hat p) = \\frac{1}{n_X} \\left\\lVert W_X^{(c)} \\left( J_X^{(c)} \\hat p - b_X^{(c)} \\right) \\right\\rVert_2^2 $$\n其中 $n_X$ 是单个组分中集合 $X$ 的可观测量数量。\n\n**2. 算法实现**\n\n总体泛化误差 $\\mathcal{E}$ 是通过对所有可能的留出组分 $c^\\star$ 的折特定误差 $\\mathcal{E}(c^\\star)$进行平均来计算的。算法如下：\n\n令 $C$ 为组分总数。对于从 $1$ 到 $C$ 由 $c^\\star$ 索引的每一折：\n\n**步骤 A：定义训练集和验证集**\n- 验证集是组分 $c^\\star$。\n- 训练集 $S$ 由所有组分 $\\{c \\mid c \\ne c^\\star\\}$ 组成。\n\n**步骤 B：第 1 轮（在 $T$ 上训练，在 $V$ 上验证）**\n1.  **组装训练数据**：串联训练集 $S$ 和目标类型 $T$ 的数据。这涉及堆叠所有 $c \\in S$ 的雅可比矩阵 $J_T^{(c)}$、残差向量 $b_T^{(c)}$ 和标准差 $\\sigma_T^{(c)}$。令堆叠后的矩阵和向量为 $J_{S,T}$、$b_{S,T}$ 和 $\\sigma_{S,T}$。\n2.  **求解参数 $\\hat p_T$**：\n    - 构建对角权重矩阵 $W_{S,T}$，其元素为训练集中所有可观测量的 $1/\\sigma_i$。\n    - 形成加权雅可比矩阵 $\\tilde{J}_{S,T} = W_{S,T} J_{S,T}$ 和加权残差向量 $\\tilde{b}_{S,T} = W_{S,T} b_{S,T}$。\n    - 求解正规方程得到 $\\hat p_T$：\n      $$ \\left( \\tilde{J}_{S,T}^\\top \\tilde{J}_{S,T} + \\lambda \\Gamma^\\top \\Gamma \\right) \\hat p_T = \\tilde{J}_{S,T}^\\top \\tilde{b}_{S,T} $$\n3.  **计算损失**：\n    - **训练损失**：计算训练集组分上的平均损失：\n      $$ \\overline{\\mathcal{L}}_T^{\\mathrm{train}}(\\hat p_T) = \\frac{1}{|S|} \\sum_{c \\in S} \\mathcal{L}_T(c; \\hat p_T) $$\n    - **验证损失**：计算在留出的验证数据上的损失：\n      $$ \\mathcal{L}_V(c^\\star; \\hat p_T) = \\frac{1}{n_V} \\left\\lVert W_V^{(c^\\star)} \\left( J_V^{(c^\\star)} \\hat p_T - b_V^{(c^\\star)} \\right) \\right\\rVert_2^2 $$\n4.  **计算泛化差距**：计算差值：\n    $$ \\Delta_{T \\rightarrow V}(c^\\star) = \\mathcal{L}_V(c^\\star; \\hat p_T) - \\overline{\\mathcal{L}}_T^{\\mathrm{train}}(\\hat p_T) $$\n\n**步骤 C：第 2 轮（在 $V$ 上训练，在 $T$ 上验证）**\n此轮与第 1 轮对称。\n1.  **组装训练数据**：串联训练集 $S$ 和目标类型 $V$ 的数据得到 $J_{S,V}$、$b_{S,V}$ 和 $\\sigma_{S,V}$。\n2.  **求解参数 $\\hat p_V$**：类似地，求解正规方程得到 $\\hat p_V$。\n3.  **计算损失**：\n    - **训练损失**：\n      $$ \\overline{\\mathcal{L}}_V^{\\mathrm{train}}(\\hat p_V) = \\frac{1}{|S|} \\sum_{c \\in S} \\mathcal{L}_V(c; \\hat p_V) $$\n    - **验证损失**：\n      $$ \\mathcal{L}_T(c^\\star; \\hat p_V) = \\frac{1}{n_T} \\left\\lVert W_T^{(c^\\star)} \\left( J_T^{(c^\\star)} \\hat p_V - b_T^{(c^\\star)} \\right) \\right\\rVert_2^2 $$\n4.  **计算泛化差距**：\n    $$ \\Delta_{V \\rightarrow T}(c^\\star) = \\mathcal{L}_T(c^\\star; \\hat p_V) - \\overline{\\mathcal{L}}_V^{\\mathrm{train}}(\\hat p_V) $$\n\n**步骤 D：计算折泛化误差**\n当前折 $c^\\star$ 的误差是两个差距的对称化平均值：\n$$ \\mathcal{E}(c^\\star) = \\frac{1}{2} \\left[ \\Delta_{T \\rightarrow V}(c^\\star) + \\Delta_{V \\rightarrow T}(c^\\star) \\right] $$\n此值被存储。\n\n**步骤 E：计算最终泛化误差**\n在遍历所有 $C$ 个折之后，最终泛化误差 $\\mathcal{E}$ 是各折误差的平均值：\n$$ \\mathcal{E} = \\frac{1}{C} \\sum_{c^\\star=1}^C \\mathcal{E}(c^\\star) $$\n\n对三个提供的测试用例中的每一个都实施此程序，以计算最终的标量值 $\\mathcal{E}$。然后将结果按指定格式进行格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the computation for all test cases.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: well-conditioned, realistic scales\n        {\n            \"d\": 2, \"C\": 3, \"lambda\": 0.1, \"Gamma\": np.diag([1, 1]),\n            \"compositions\": [\n                {\n                    \"J_T\": np.array([[-0.08, -0.02], [0.15, 0.05]]), \"b_T\": np.array([0.05, -0.08]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[30.0, 10.0], [1.8, 0.6]]), \"b_V\": np.array([-20.0, -1.0]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.09, -0.01], [0.12, 0.04]]), \"b_T\": np.array([0.03, -0.05]), \"sigma_T\": np.array([0.012, 0.012]),\n                    \"J_V\": np.array([[28.0, 9.0], [1.6, 0.5]]), \"b_V\": np.array([-15.0, -0.8]), \"sigma_V\": np.array([12.0, 1.2]),\n                },\n                {\n                    \"J_T\": np.array([[-0.07, -0.015], [0.10, 0.03]]), \"b_T\": np.array([0.04, -0.07]), \"sigma_T\": np.array([0.011, 0.011]),\n                    \"J_V\": np.array([[26.0, 8.5], [1.4, 0.45]]), \"b_V\": np.array([-18.0, -0.9]), \"sigma_V\": np.array([11.0, 1.1]),\n                }\n            ]\n        },\n        # Test Case 2: near-singular training Jacobians\n        {\n            \"d\": 2, \"C\": 3, \"lambda\": 0.05, \"Gamma\": np.diag([1, 1]),\n            \"compositions\": [\n                {\n                    \"J_T\": np.array([[-0.08, -0.04], [0.16, 0.08]]), \"b_T\": np.array([0.02, -0.04]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[20.0, 5.0], [1.0, 0.25]]), \"b_V\": np.array([-10.0, -0.5]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.081, -0.0405], [0.162, 0.081]]), \"b_T\": np.array([0.018, -0.036]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[21.0, 5.2], [1.05, 0.26]]), \"b_V\": np.array([-9.0, -0.45]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.079, -0.0395], [0.158, 0.079]]), \"b_T\": np.array([0.022, -0.044]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[19.0, 4.8], [0.95, 0.24]]), \"b_V\": np.array([-11.0, -0.55]), \"sigma_V\": np.array([10.0, 1.0]),\n                }\n            ]\n        },\n        # Test Case 3: perfectly consistent linear model\n        {\n            \"d\": 2, \"C\": 3, \"lambda\": 1e-6, \"Gamma\": np.diag([1, 1]),\n            \"compositions\": [\n                {\n                    \"J_T\": np.array([[-0.06, 0.01], [0.12, -0.02]]), \"b_T\": np.array([-0.032, 0.064]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[25.0, -2.0], [1.3, -0.12]]), \"b_V\": np.array([12.9, 0.674]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.065, 0.015], [0.11, -0.018]]), \"b_T\": np.array([-0.0355, 0.0586]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[27.0, -1.8], [1.5, -0.10]]), \"b_V\": np.array([13.86, 0.77]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.055, 0.012], [0.105, -0.017]]), \"b_T\": np.array([-0.0299, 0.0559]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[24.0, -2.2], [1.2, -0.13]]), \"b_V\": np.array([12.44, 0.626]), \"sigma_V\": np.array([10.0, 1.0]),\n                }\n            ]\n        }\n    ]\n    \n    results = [compute_generalization_error(case) for case in test_cases]\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef compute_loss(J, b, sigma, p_hat):\n    \"\"\"\n    Computes the per-composition, per-target average normalized loss L_X(c; p_hat).\n    \"\"\"\n    n_X = len(b)\n    if n_X == 0: return 0.0\n    W = np.diag(1.0 / sigma)\n    weighted_residual = W @ (J @ p_hat - b)\n    norm_sq = np.linalg.norm(weighted_residual)**2\n    return norm_sq / n_X\n\ndef solve_params(compositions, train_indices, target_type, lambda_reg, Gamma):\n    \"\"\"\n    Solves the regularized weighted least-squares problem for p_hat.\n    \"\"\"\n    J_list, b_list, sigma_list = [], [], []\n    for idx in train_indices:\n        comp = compositions[idx]\n        J_list.append(comp[f\"J_{target_type}\"])\n        b_list.append(comp[f\"b_{target_type}\"])\n        sigma_list.append(comp[f\"sigma_{target_type}\"])\n\n    if not J_list:\n        d = compositions[0][f\"J_{target_type}\"].shape[1]\n        return np.zeros(d)\n\n    J_stacked = np.vstack(J_list)\n    b_stacked = np.concatenate(b_list)\n    sigma_stacked = np.concatenate(sigma_list)\n    \n    W_stacked = np.diag(1.0 / sigma_stacked)\n    J_tilde = W_stacked @ J_stacked\n    b_tilde = W_stacked @ b_stacked\n\n    M = J_tilde.T @ J_tilde + lambda_reg * (Gamma.T @ Gamma)\n    v = J_tilde.T @ b_tilde\n    \n    p_hat = np.linalg.solve(M, v)\n    return p_hat\n\ndef compute_avg_train_loss(p_hat, compositions, train_indices, target_type):\n    \"\"\"\n    Computes the average training loss over the training compositions.\n    \"\"\"\n    if not train_indices: return 0.0\n    total_loss = 0\n    for idx in train_indices:\n        comp = compositions[idx]\n        J = comp[f\"J_{target_type}\"]\n        b = comp[f\"b_{target_type}\"]\n        sigma = comp[f\"sigma_{target_type}\"]\n        total_loss += compute_loss(J, b, sigma, p_hat)\n    return total_loss / len(train_indices)\n\ndef compute_generalization_error(case):\n    \"\"\"\n    Computes the final generalization error E for a single test case.\n    \"\"\"\n    C = case[\"C\"]\n    compositions = case[\"compositions\"]\n    lambda_reg = case[\"lambda\"]\n    Gamma = case[\"Gamma\"]\n    \n    fold_errors = []\n\n    for c_star_idx in range(C):\n        train_indices = [i for i in range(C) if i != c_star_idx]\n        val_comp = compositions[c_star_idx]\n        \n        # --- Round 1: Train on T, Validate on V ---\n        p_hat_T = solve_params(compositions, train_indices, 'T', lambda_reg, Gamma)\n        \n        train_loss_T = compute_avg_train_loss(p_hat_T, compositions, train_indices, 'T')\n        val_loss_V = compute_loss(val_comp[\"J_V\"], val_comp[\"b_V\"], val_comp[\"sigma_V\"], p_hat_T)\n        \n        delta_T_to_V = val_loss_V - train_loss_T\n        \n        # --- Round 2: Train on V, Validate on T ---\n        p_hat_V = solve_params(compositions, train_indices, 'V', lambda_reg, Gamma)\n        \n        train_loss_V = compute_avg_train_loss(p_hat_V, compositions, train_indices, 'V')\n        val_loss_T = compute_loss(val_comp[\"J_T\"], val_comp[\"b_T\"], val_comp[\"sigma_T\"], p_hat_V)\n        \n        delta_V_to_T = val_loss_T - train_loss_V\n\n        # --- Fold Generalization Error ---\n        E_c_star = 0.5 * (delta_T_to_V + delta_V_to_T)\n        fold_errors.append(E_c_star)\n\n    # --- Final Generalization Error ---\n    if not fold_errors: return 0.0\n    E_final = np.mean(fold_errors)\n    return E_final\n\nsolve()\n```", "id": "3422163"}]}