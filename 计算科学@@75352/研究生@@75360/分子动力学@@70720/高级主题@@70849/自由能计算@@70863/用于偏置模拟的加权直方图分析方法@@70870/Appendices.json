{"hands_on_practices": [{"introduction": "将理论付诸实践时，我们遇到的首要挑战之一是数值稳定性。加权直方图分析方法（WHAM）的方程涉及对指数项求和，当温度较低（即 $\\beta$ 较大）或偏置势很强时，这些项的数值可能变得极大，超出标准浮点数的表示范围，导致计算溢出。本练习将指导你推导一种名为“log-sum-exp”的技巧，这是确保WHAM代码在各种条件下都能稳健运行的关键一步 [@problem_id:3461097]。", "problem": "考虑一组在恒定温度 $T$ 和逆热能 $\\beta = 1/(k_B T)$（其中 $k_B$ 是玻尔兹曼常数）下进行的 $K$ 次有偏分子动力学 (MD) 模拟。每次模拟 $k$ 都会对一个标量集体变量 $s$ 施加一个偏置势 $W_k(s)$。设 $s$ 被离散化为由索引 $i$ 标记的多个区间，区间中心为 $s_i$。加权直方图分析方法 (WHAM) 结合这些模拟来估计 $s$ 上的无偏概率分布。在此背景下，对区间 $i$ 的 WHAM 重加权涉及一个分母，该分母聚合了所有模拟的贡献，定义为\n$$\nD_i = \\sum_{k=1}^{K} n_k \\exp\\!\\left[\\beta f_k - \\beta W_k(s_i)\\right],\n$$\n其中 $n_k \\geq 1$ 是模拟 $k$ 贡献的非相关样本数量，$f_k$ 是通过 WHAM 内部的自洽性确定的约化自由能偏移量。对于大的 $\\beta$ 或陡峭的偏置势 $W_k(s)$，由于指数项中存在大的正参数，直接计算 $D_i$ 可能会导致上溢。从正则系综以及指数和对数的基本性质（$\\exp(\\cdot)$ 的单调性和恒等式 $\\ln(\\exp(x)) = x$）出发，推导一个 $\\ln D_i$ 的数值稳定表达式。该表达式通过对指数进行重新中心化来避免上溢和下溢，同时不改变 $D_i$ 的值。你的推导必须只引入 $D_i$ 定义中已有的量，并使用标准数值库中可用的基本运算。请提供 $\\ln D_i$ 的最终闭式解析表达式，该表达式仅用 $\\beta$、$f_k$、$W_k(s_i)$ 和 $n_k$ 表示。无需进行四舍五入，最终答案中不应包含任何物理单位。", "solution": "问题要求为加权直方图分析方法 (WHAM) 的分母的自然对数 $\\ln(D_i)$ 推导一个数值稳定的表达式。给定的 $D_i$ 表达式为：\n$$\nD_i = \\sum_{k=1}^{K} n_k \\exp\\!\\left[\\beta f_k - \\beta W_k(s_i)\\right]\n$$\n在此，$\\beta$ 是逆热能，$n_k$ 是模拟 $k$ 的样本数，$f_k$ 是模拟 $k$ 的约化自由能偏移量，$W_k(s_i)$ 是模拟 $k$ 的偏置势在区间 $i$ 中心处的值。\n\n当指数函数的参数 $\\beta f_k - \\beta W_k(s_i)$ 对任何模拟 $k$ 来说是一个大的正数时，挑战就出现了。在这种情况下，项 $\\exp[\\beta f_k - \\beta W_k(s_i)]$ 可能会超出计算机的浮点表示能力，这种情况被称为数值上溢。直接计算 $D_i$ 然后再取对数将会失败。\n\n为了推导 $\\ln(D_i)$ 的一个稳定表达式，我们可以使用一个常见的代数技巧，通常称为“log-sum-exp”技巧。该技巧包括找出和中的最大指数项，将其作为公因子提取出来，然后应用对数的性质。这个过程不会改变 $D_i$ 的数学值，而是将计算重构成一种数值稳定的形式。\n\n让我们将第 $k$ 项的指数定义为 $A_k(s_i) = \\beta f_k - \\beta W_k(s_i)$。$D_i$ 的表达式变为：\n$$\nD_i = \\sum_{k=1}^{K} n_k \\exp(A_k(s_i))\n$$\n现在，我们为每个区间 $i$ 定义一个常数 $C_i$，作为所有 $K$ 次模拟中这些指数的最大值：\n$$\nC_i = \\max_{k' \\in \\{1, \\dots, K\\}} \\left\\{ A_{k'}(s_i) \\right\\} = \\max_{k' \\in \\{1, \\dots, K\\}} \\left\\{ \\beta f_{k'} - \\beta W_{k'}(s_i) \\right\\}\n$$\n我们使用 $k'$ 作为最大化过程中的哑索引，以区别于求和索引 $k$。\n\n现在我们可以通过在每个指数内加上再减去 $C_i$ 来重写 $D_i$ 的表达式。这是一个保持每项值不变的空操作。\n$$\nD_i = \\sum_{k=1}^{K} n_k \\exp\\left[ A_k(s_i) - C_i + C_i \\right]\n$$\n使用指数的性质 $\\exp(a+b) = \\exp(a)\\exp(b)$，我们可以将指数拆分：\n$$\nD_i = \\sum_{k=1}^{K} n_k \\exp\\left[ A_k(s_i) - C_i \\right] \\exp(C_i)\n$$\n由于 $\\exp(C_i)$ 是一个相对于求和索引 $k$ 的常数，它可以从求和中提取出来：\n$$\nD_i = \\exp(C_i) \\left( \\sum_{k=1}^{K} n_k \\exp\\left[ A_k(s_i) - C_i \\right] \\right)\n$$\n这个表达式在数学上与 $D_i$ 的原始定义完全相同。现在，我们可以对两边取自然对数来求 $\\ln(D_i)$：\n$$\n\\ln(D_i) = \\ln\\left( \\exp(C_i) \\left( \\sum_{k=1}^{K} n_k \\exp\\left[ A_k(s_i) - C_i \\right] \\right) \\right)\n$$\n使用对数的性质 $\\ln(xy) = \\ln(x) + \\ln(y)$，我们将两个因子分开：\n$$\n\\ln(D_i) = \\ln\\left( \\exp(C_i) \\right) + \\ln\\left( \\sum_{k=1}^{K} n_k \\exp\\left[ A_k(s_i) - C_i \\right] \\right)\n$$\n根据基本恒等式 $\\ln(\\exp(x)) = x$，第一项简化为 $C_i$：\n$$\n\\ln(D_i) = C_i + \\ln\\left( \\sum_{k=1}^{K} n_k \\exp\\left[ A_k(s_i) - C_i \\right] \\right)\n$$\n这种形式是数值稳定的。求和内部的指数函数参数现在是 $A_k(s_i) - C_i = A_k(s_i) - \\max_{k'}\\{A_{k'}(s_i)\\}$。根据最大值的定义，对于所有的 $k$，这个差值总是小于或等于零。因此，$\\exp[A_k(s_i) - C_i]$ 的值将在 $0$ 和 $1$ 之间，从而防止了上溢。指数最大的那一项将有一个调整后为 $0$ 的指数，得到 $\\exp(0)=1$，这保证了最终对数的参数至少为 $1$（因为 $n_k \\ge 1$），从而防止了对数计算中的下溢。\n\n为了提供一个仅用初始量表示的最终表达式，我们将 $A_k(s_i)$ 和 $C_i$ 的完整表达式代入。由于 $\\beta > 0$，它可以从最大化运算中提出来：\n$$\nC_i = \\beta \\max_{k' \\in \\{1, \\dots, K\\}} \\left\\{ f_{k'} - W_{k'}(s_i) \\right\\}\n$$\n将这个和 $A_k(s_i)$ 代入我们推导出的表达式，得出最终答案：\n$$\n\\ln(D_i) = \\beta \\max_{k' \\in \\{1, \\dots, K\\}} \\left\\{ f_{k'} - W_{k'}(s_i) \\right\\} + \\ln\\left( \\sum_{k=1}^{K} n_k \\exp\\left[ \\beta(f_k - W_k(s_i)) - \\beta \\max_{k'' \\in \\{1, \\dots, K\\}} \\left\\{ f_{k''} - W_{k''}(s_i) \\right\\} \\right] \\right)\n$$\n这个表达式提供了一种计算 $\\ln(D_i)$ 的数值鲁棒方法，避免了直接计算原始公式时固有的上溢和下溢问题。", "answer": "$$\n\\boxed{\\beta \\max_{k' \\in \\{1, \\dots, K\\}} \\left( f_{k'} - W_{k'}(s_i) \\right) + \\ln\\left( \\sum_{k=1}^{K} n_k \\exp\\left( \\beta \\left( f_k - W_k(s_i) \\right) - \\beta \\max_{k'' \\in \\{1, \\dots, K\\}} \\left( f_{k''} - W_{k''}(s_i) \\right) \\right) \\right)}\n$$", "id": "3461097"}, {"introduction": "许多重要的集体变量，例如二面角，天然具有周期性。在处理这类周期性系统时，必须特别注意边界条件，以避免在自由能曲线上产生人为的“接缝”或不连续点。本练习探讨了在伞形采样分析中正确处理周期性边界的标准做法，包括如何计算偏置能量以及如何对跨越边界的样本进行计数 [@problem_id:3461108]。", "problem": "一个测量扭转角的一维集体变量 $s$ 具有严格的周期性，周期为 $L$，因此物理上不同的状态对应于 $s \\in [0,L)$，并且两个值之间的距离是在圆上定义的。在伞形采样中，窗口 $i$ 施加一个中心位于 $s_{0,i}$ 的谐波偏置 $w_i(s)$，并根据逆温度为 $\\beta$、总势能为 $U(s) + w_i(s)$ 的正则系综对构型进行采样。因此，窗口 $i$ 中的正则偏置概率密度正比于 $\\exp\\!\\left[-\\beta\\left(U(s)+w_i(s)\\right)\\right]$，而无偏目标密度 $p(s)$ 正比于 $\\exp\\!\\left[-\\beta U(s)\\right]$。加权直方图分析法旨在通过对每个采样构型对直方图各区间的贡献进行重加权，从多个窗口中重构 $p(s)$，然后通过 $F(s) = -k_{\\mathrm{B}} T \\ln p(s)$ 估算自由能 $F(s)$（结果相差一个加性常数），其中 $k_{\\mathrm{B}}$ 是玻尔兹曼常数，$T$ 是绝对温度。\n\n考虑中心 $s_{0,i}$ 位于周期性边界附近的伞形窗口，例如对于小的 $\\Delta > 0$，有 $s_{0,i} \\approx L - \\Delta$。在采样过程中，许多构型的 $s$ 值会跨越边界，例如，在卷绕处理前连续表示时，值会略大于 $L$ 或略小于零。你的任务是从第一性原理出发，决定这些样本的贡献应如何计入跨越边界的直方图区间，以及如何防止重构的 $F(s)$ 中出现人为的不连续性。\n\n在确保跨边界计数的科学一致性并防止 $F(s)$ 中出现人为不连续性方面，以下哪些程序是正确的？\n\nA. 在 $[0,L)$ 上建立直方图，不进行任何卷绕处理，将任何 $s>L$ 的样本分配到 $L$ 之外的区间，并在归一化过程中丢弃这些贡献，以避免在边界处重复计数。\n\nB. 通过 $s' = s - L \\left\\lfloor s/L \\right\\rfloor$ 将每个采样值 $s$ 映射到其在 $[0,L)$ 中的代表值 $s'$，使用 $s'$ 分配直方图区间，并使用最小镜像距离 $d(s',s_{0,i}) = \\min_{n \\in \\mathbb{Z}} \\left| s' - s_{0,i} + nL \\right|$ 计算谐波偏置，从而使重加权因子在边界上平滑地变化。\n\nC. 为了强制实现连续性，将 $s$ 值位于任一边界的小阈值 $\\delta$ 内的任何样本同时计入第一个和最后一个区间，并在两者之间平均其权重，以减少边界伪影。\n\nD. 当从重加权直方图估算 $F(s)$ 时，明确施加周期性约束 $F(0) = F(L)$，并且，如果对 $p(s)$ 或 $F(s)$ 应用平滑处理，则使用在圆上定义并采用流形上的测地距离的核（即周期性核），而不是区间上的欧几里得核。\n\nE. 在分析过程中，将任何靠近 $L$ 的窗口中心 $s_{0,i}$ 平移 $\\pm L$，使得 $|s - s_{0,i}|$ 看起来很小而无需使用最小镜像约定，并保持所有采样 $s$ 值不作卷绕处理，使得直方图在 $s=0$ 和 $s=L$ 处有清晰的边界。\n\n选择所有适用项。", "solution": "首先验证问题陈述，以确保其科学上合理、问题定义明确且客观。\n\n### 步骤 1：提取已知条件\n-   **系统**：一个一维集体变量 $s$，具有严格的周期性，周期为 $L$。\n-   **状态空间**：物理上不同的状态对应于 $s \\in [0,L)$。距离度量定义在圆上。\n-   **模拟方法**：使用伞形采样。\n-   **偏置势**：窗口 $i$ 施加一个中心位于 $s_{0,i}$ 的谐波偏置 $w_i(s)$。\n-   **系综**：在正则系综中进行采样，逆温度为 $\\beta = (k_{\\mathrm{B}} T)^{-1}$。\n-   **偏置概率密度**：在窗口 $i$ 中，概率密度正比于 $\\exp[-\\beta(U(s)+w_i(s))]$。\n-   **无偏概率密度**：目标量为 $p(s) \\propto \\exp[-\\beta U(s)]$。\n-   **自由能**：自由能定义为 $F(s) = -k_{\\mathrm{B}} T \\ln p(s)$（结果相差一个加性常数）。\n-   **分析方法**：使用加权直方图分析法 (WHAM) 重构 $p(s)$。\n-   **挑战**：对于中心 $s_{0,i}$ 靠近周期性边界（例如，$s_{0,i} \\approx L$）的窗口，样本会跨越边界（例如，$s > L$ 或 $s  0$）。任务是确定处理这些样本的正确程序，以确保计数一致并防止 $F(s)$ 中出现人为的不连续性。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学上合理**：该问题牢固地植根于统计力学和计算物理学的原理。伞形采样、加权直方图分析法 (WHAM)、周期性集体变量（如二面角）的概念以及自由能的定义都是标准的且描述准确。处理周期性边界条件的挑战是分子模拟中一个真实且重要的问题。\n-   **问题定义明确**：该问题定义明确。它要求给出处理分子模拟数据分析中一个具体、常见技术挑战的正确程序。目标清晰，上下文也给出了足够的细节。\n-   **客观性**：问题陈述使用精确、客观和标准的科学术语表达。没有主观或含糊的陈述。\n\n该问题没有表现出任何无效性缺陷。它是计算分子科学领域一个标准的、有效的问题。\n\n### 步骤 3：结论与行动\n问题陈述是有效的。将推导解决方案。\n\n### 周期性系统的原理推导\n\n问题的核心在于正确处理其坐标 $s$ 是周期性的系统。集体变量的空间不是实数线 $\\mathbb{R}$，而是一个周长为 $L$ 的圆 $S^1$。所有的物理量和数学运算都必须遵循这种拓扑结构。\n\n1.  **拓扑等价性**：如果对于某个整数 $n \\in \\mathbb{Z}$ 有 $s_1 = s_2 + nL$，那么任意两点 $s_1$ 和 $s_2$ 在物理上是相同的。因此，任何物理状态的单值函数，例如无偏势能 $U(s)$ 和自由能 $F(s)$，都必须是周期为 $L$ 的周期函数：$U(s) = U(s+L)$ 和 $F(s) = F(s+L)$。\n\n2.  **距离度量**：圆上两点 $s_a$ 和 $s_b$ 之间的距离是它们之间的最短弧长。这被称为最小镜像距离，由 $d(s_a, s_b) = \\min_{n \\in \\mathbb{Z}} |s_a - s_b + nL|$ 给出。谐波偏置势 $w_i(s) = \\frac{1}{2}k_i (\\text{distance from } s_{0,i})^2$ 必须使用这个度量，才能成为圆上的一个平滑且具有物理意义的函数：$w_i(s) = \\frac{1}{2}k_i [d(s, s_{0,i})]^2$。对于中心靠近周期性边界的窗口，使用简单的欧几里得距离 $|s - s_{0,i}|$ 会在周期性边界处产生一个不符合物理的能量尖峰。\n\n3.  **直方图区间划分**：模拟轨迹产生一系列 $s$ 值，这些值通常是“未卷绕”的，可能会落在基本域 $[0, L)$ 之外。为了在圆上构建概率密度 $p(s)$ 的直方图，每个采样值 $s$ 必须映射到所选基本域（例如 $s' \\in [0, L)$）中的唯一代表值 $s'$。正确的映射是 $s' = s \\pmod L$，可以实现为 $s' = s - L \\lfloor s/L \\rfloor$。使用这些卷绕后的坐标 $s'$ 来填充直方图。\n\n4.  **连续性和后处理**：得到的自由能曲线 $F(s)$ 必须是周期性的，即 $F(0) = F(L)$。虽然对无限数据的完美分析可以保证这一点，但有限数据和数值方法可能会引入微小的不匹配。强制实现这种周期性是有效的一步。此外，如果对数据（例如对 $p(s)$ 或 $F(s)$）应用任何平滑处理，平滑核也必须遵循圆形拓扑。这需要一个周期性核（例如，卷绕高斯函数），它通过承认边界附近点（例如 $s=\\epsilon$ 处）与区间另一端点（例如 $s=L-\\epsilon$ 处）的邻近性来正确处理这些点。\n\n基于这些第一性原理，我们现在可以评估每个选项。\n\n### 逐项分析\n\n**A. 在 $[0,L)$ 上建立直方图，不进行任何卷绕处理，将任何 $sL$ 的样本分配到 $L$ 之外的区间，并在归一化过程中丢弃这些贡献，以避免在边界处重复计数。**\n\n这个程序存在根本性缺陷。$s = L + \\epsilon$ 处的样本在物理上与 $s=\\epsilon$ 处的样本是相同的。丢弃 $s=L+\\epsilon$ 处的样本意味着丢弃了有效的统计信息。这人为地减少了 $s=0$ 附近区间的采样，导致不正确的概率密度和自由能曲线上相应的人为势垒。这种方法将周期性变量当作被限制在盒子中处理，这与问题定义相矛盾。\n**结论：不正确。**\n\n**B. 通过 $s' = s - L \\left\\lfloor s/L \\right\\rfloor$ 将每个采样值 $s$ 映射到其在 $[0,L)$ 中的代表值 $s'$，使用 $s'$ 分配直方图区间，并使用最小镜像距离 $d(s',s_{0,i}) = \\min_{n \\in \\mathbb{Z}} \\left| s' - s_{0,i} + nL \\right|$ 计算谐波偏置，从而使重加权因子在边界上平滑地变化。**\n\n这个程序正确地解决了核心问题。\n1.  映射 $s' = s - L \\lfloor s/L \\rfloor$ 正确地将所有采样坐标折叠到基本域 $[0,L)$ 中，这与原理3一致。这确保了每个样本都在其物理上正确的位置被计数。\n2.  使用最小镜像距离 $d(s', s_{0,i})$ 来定义谐波偏置势至关重要，如原理2中所解释。这确保了偏置能 $w_i(s)$ 是圆上的一个连续平滑函数，这对于重加权因子 $\\exp[\\beta w_i(s)]$ 在周期性边界上表现良好是必要的。这可以防止人为的能量跳跃，并确保偏置模拟的物理过程是正确的。\n该选项描述了对具有周期性变量的伞形采样的标准、正确的实现方法。\n**结论：正确。**\n\n**C. 为了强制实现连续性，将 $s$ 值位于任一边界的小阈值 $\\delta$ 内的任何样本同时计入第一个和最后一个区间，并在两者之间平均其权重，以减少边界伪影。**\n\n这是一个临时的、启发式的程序，没有建立在严格的统计原理之上。它违反了直方图的基本规则，即每个样本只对一个区间做出贡献。复制和平均样本贡献是一种数据操纵形式，它会扭曲底层的概率分布。它试图在表面上平滑由不正确处理引起的边界伪影，而不是通过尊重系统拓扑从根本上解决问题。实现连续性的正确方法是从一开始就使用周期性表示。\n**结论：不正确。**\n\n**D. 当从重加权直方图估算 $F(s)$ 时，明确施加周期性约束 $F(0) = F(L)$，并且，如果对 $p(s)$ 或 $F(s)$ 应用平滑处理，则使用在圆上定义并采用流形上的测地距离的核（即周期性核），而不是区间上的欧几里得核。**\n\n该选项描述了正确且通常必要的后处理步骤，与原理4一致。\n1.  真实的自由能 $F(s)$ 必须是周期性的。施加约束 $F(0) = F(L)$ 可确保最终结果具有物理意义，纠正了由有限采样可能引起的微小差异。\n2.  如果执行平滑处理，使用周期性核是必不可少的。标准的欧几里得核会将 $s=0$ 和 $s=L$ 处的点视为相距很远，从而在边界处产生平滑伪影。周期性核正确地认识到域是圆形的，并且 $s=0$ 与 $s=L$ 相邻，从而保持了曲线的连续性和周期性。\n这两种做法都是合理的，并且与周期性数据的严格处理方法相一致。\n**结论：正确。**\n\n**E. 在分析过程中，将任何靠近 $L$ 的窗口中心 $s_{0,i}$ 平移 $\\pm L$，使得 $|s - s_{0,i}|$ 看起来很小而无需使用最小镜像约定，并保持所有采样 $s$ 值不作卷绕处理，使得直方图在 $s=0$ 和 $s=L$ 处有清晰的边界。**\n\n这是一个不正确且繁琐的变通方法，不能作为通用解决方案。保持 $s$ 值不作卷绕处理是在实数线上构建直方图，这是错误的拓扑结构。平移中心 $s_{0,i}$ 是一个“技巧”，旨在使简单的欧几里得距离计算 $|s-s_{0,i}|$ 得出正确的最小镜像距离，但它只对靠近平移后中心的样本 $s$ 有效。它不适用于所有可能的 $s$ 值，并且不等同于正确的最小镜像计算。例如，如果 $s_{0,i}=0.9L$ 被平移到 $-0.1L$，一个位于 $s=0.4L$ 的样本到中心的距离将被错误地计算得很大。稳健的方法是始终计算最小镜像距离。该选项明确回避了正确的约定，也未能正确地对数据进行分箱。\n**结论：不正确。**", "answer": "$$\\boxed{BD}$$", "id": "3461108"}, {"introduction": "计算出自由能曲线只是分析的一部分，验证结果的可靠性同样至关重要。一个强有力的验证方法是“自洽性检验”，即检查从全局无偏分布反推得到的各窗口内的分布，是否与原始的偏置采样直方图在统计误差范围内一致。本练习将引导你设计并实现一个这样的数值检验，以确保你的WHAM结果与输入数据是自洽的，从而大大增强结果的可信度 [@problem_id:3461103]。", "problem": "给定一组对标量反应坐标 $s$ 进行采样的带偏分子动力学窗口，每个窗口都受到一个已知的谐波伞形势的影响。任务是设计并实现一个基于统计力学第一性原理的数值自洽性检验，以验证从单一的全局无偏分布重构的各窗口分布在统计误差范围内与观测到的直方图相匹配。\n\n从正则系综和带偏模拟的重要性采样概念开始。考虑一个在一组包含 $M$ 个离散区间（bin）的集合上的未知无偏概率密度 $p(s)$，这些区间的中心为 $s_i$，并具有均匀的区间宽度 $\\Delta s$。每个窗口 $k$ 施加一个已知的偏置势 $W_k(s)$，并在这些区间上生成一个计数直方图 $n_{k,i}$，总样本数为 $N_k = \\sum_{i=1}^M n_{k,i}$。逆热能为 $\\beta$，单位为 $1/\\text{energy}$，所有能量均采用一致的任意单位。沿 $s$ 的无偏自由能为 $F(s)$，使得 $p(s) \\propto \\exp[-\\beta F(s)]$。偏置势是谐波形式的，$W_k(s) = \\frac{1}{2} K (s - c_k)^2$，其中劲度系数为 $K$，中心为 $c_k$。\n\n你的程序必须：\n- 从正则系综和重要性采样原理出发，推导出一个实用的算法，以联合地从所有窗口估计全局无偏离散分布 $p_i \\approx p(s_i)$ 以及确保每个带偏分布归一化的各窗口归一化常数 $f_k$。\n- 对每个窗口 $k$，计算一个反算出的离散分布 $\\tilde{p}_{k,i}$，该分布是在全局 $p_i$ 正确且在逆温度 $\\beta$ 下施加偏置 $W_k$ 时窗口 $k$ 中期望出现的分布。这个反算出的分布必须在 $s$ 上使用测度 $\\Delta s$ 归一化为1，即 $\\sum_i \\tilde{p}_{k,i} \\Delta s = 1$。\n- 使用一个考虑了有限采样噪声的、有统计学原理依据的标准，将 $\\tilde{p}_{k,i}$ 与观测到的经验性各窗口直方图 $\\hat{p}_{k,i} = n_{k,i} / N_k$ 进行比较。假设各区间的计数是独立的，并近似服从泊松分布，其均值为每个区间的 $N_k \\tilde{p}_{k,i}$，因此每个区间的标准差为 $\\sqrt{N_k \\tilde{p}_{k,i}}$。定义一个决策规则，声明一个窗口 $k$ 是自洽的，当且仅当对于所有区间 $i$，\n$$\n\\left| n_{k,i} - N_k \\tilde{p}_{k,i} \\right| \\le z \\sqrt{N_k \\tilde{p}_{k,i}},\n$$\n其中 $z = 3$ 是一个固定的阈值。如果一个测试用例中的每个窗口都是自洽的，则该用例通过测试。\n\n你的实现必须是完全确定性的，并且只使用提供的参数。为了可复现性，每当需要合成计数时，请为随机数生成器使用固定的种子，以从每个窗口的多项分布中抽取计数；否则，以确定性的方式对期望计数进行四舍五入，并调整最后一个区间以保持 $N_k$。你推导的算法必须在科学上是合理的，并从第一性原理出发；不要依赖未经证明的黑箱公式。\n\n测试套件：\n对于所有情况，无偏自由能为 $F(s) = \\frac{1}{2} k_{\\text{ub}} s^2$，偏置势为谐波形式 $W_k(s) = \\frac{1}{2} K (s - c_k)^2$。使用一个包含 $M$ 个区间的均匀网格，中心 $s_i$ 跨越 $[s_{\\min}, s_{\\max}]$，且 $\\Delta s = (s_{\\max} - s_{\\min})/M$。所有能量都采用相同的任意单位，$\\beta$ 的单位为 $1/\\text{energy}$。\n\n- 情况A（采样良好且一致）：\n    - $\\beta = 1.0$\n    - $k_{\\text{ub}} = 3.0$\n    - $K = 10.0$\n    - $c_k = [-1.0, 0.0, 1.0]$ 对应 $k = 1,2,3$\n    - $N_k = [8000, 6000, 7000]$ 对应 $k = 1,2,3$\n    - $s_{\\min} = -2.5$, $s_{\\max} = 2.5$, $M = 81$\n    - 使用随机数种子 $12345$ 生成合成计数。\n    - 所有窗口在物理上与给定的 $\\beta$ 一致。\n\n- 情况B（采样较少但一致）：\n    - $\\beta = 1.0$\n    - $k_{\\text{ub}} = 3.0$\n    - $K = 10.0$\n    - $c_k = [-1.0, 0.0, 1.0]$\n    - $N_k = [1500, 800, 1000]$\n    - $s_{\\min} = -2.5$, $s_{\\max} = 2.5$, $M = 81$\n    - 使用随机数种子 $24680$ 生成合成计数。\n    - 所有窗口在物理上与给定的 $\\beta$ 一致。\n\n- 情况C（故意不一致以引发失败）：\n    - 分析假设 $\\beta = 1.0$\n    - $k_{\\text{ub}} = 3.0$\n    - $K = 10.0$\n    - $c_k = [-1.0, 0.0, 1.0]$\n    - $N_k = [7000, 9000, 7000]$\n    - $s_{\\min} = -2.5$, $s_{\\max} = 2.5$, $M = 81$\n    - 使用随机数种子 $13579$ 生成合成计数。\n    - 窗口 $k=2$ 的合成计数是在 $\\beta_{\\text{gen},2} = 0.5$（不匹配）下生成的，而 $k=1$ 和 $k=3$ 使用 $\\beta_{\\text{gen},1} = \\beta_{\\text{gen},3} = 1.0$。\n\n程序要求：\n- 实现一个科学上合理的算法，以联合地从所有窗口的观测直方图中估计 $p_i$ 和 $f_k$。\n- 构建反算出的各窗口分布 $\\tilde{p}_{k,i}$，并使用 $z=3$ 评估泊松偏差规则。\n- 对每种情况，输出一个布尔值，指示该情况是通过（所有窗口都自洽）还是失败。\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔结果列表（例如，“[True,False,True]”）。\n\n不涉及角度；输出中没有其他物理单位，纯粹是布尔值。最终结果必须根据给定参数计算得出，不得使用外部输入或文件。", "solution": "用户要求基于加权直方图分析方法（WHAM）的原理，为来自带偏分子模拟的数据设计并实现一个数值自洽性检验。该问题被认为是有效的，因为它科学地基于已建立的统计力学，问题陈述清晰，并且为获得唯一的、可验证的解提供了所有必需的参数。问题决策规则中一个微小的符号歧义将基于量纲一致性和第一性原理进行解决。\n\n### 1. 理论基础\n\n该问题的核心是将来自多个模拟（窗口）的数据结合起来，每个模拟都用一个势 $W_k(s)$ 进行偏置，以重构出反应坐标 $s$ 的单一、潜在的无偏概率分布 $p(s)$。\n\n在正则系综中，系统在坐标 $s$ 处的无偏概率密度与自由能 $F(s)$ 的关系为：\n$$p(s) = \\frac{e^{-\\beta F(s)}}{\\int e^{-\\beta F(s')} ds'}$$\n其中 $\\beta$ 是逆热能。当在模拟 $k$ 中施加一个偏置势 $W_k(s)$ 时，观测到的（带偏）概率密度 $p_k(s)$ 变为：\n$$p_k(s) = \\frac{e^{-\\beta (F(s) + W_k(s))}}{\\int e^{-\\beta (F(s') + W_k(s'))} ds'}$$\n从这两个方程，我们可以关联带偏和无偏密度：\n$$p_k(s) = p(s) e^{-\\beta W_k(s)} \\frac{\\int e^{-\\beta F(s')} ds'}{\\int e^{-\\beta (F(s') + W_k(s'))} ds'} = p(s) e^{-\\beta W_k(s)} e^{\\beta f_k}$$\n这里，$f_k = -\\frac{1}{\\beta} \\ln \\left( \\int p(s') e^{-\\beta W_k(s')} ds' \\right)$ 是与施加偏置势 $W_k(s)$ 相关的自由能变化。项 $e^{\\beta f_k}$ 作为归一化因子。\n\n### 2. 加权直方图分析方法 (WHAM)\n\nWHAM 提供了一套自洽方程组，用于从一组直方图中找到无偏概率分布和自由能偏移 $f_k$ 的最优估计。我们将坐标 $s$ 离散化为 $M$ 个区间（bin），用索引 $i$ 表示，中心为 $s_i$。设 $P_i$ 为在区间 $i$ 中的概率质量（使得 $\\sum_i P_i = 1$），$n_{k,i}$ 为模拟 $k$ 中在区间 $i$ 的样本数，而 $N_k = \\sum_i n_{k,i}$ 为模拟 $k$ 的总样本数。\n\n通过最大化观测到给定直方图 $\\{n_{k,i}\\}$ 的似然函数，可以推导出关于 $P_i$ 和自由能偏移量 $f_k$ 的一组自洽方程：\n\n1.  **无偏概率质量的估计：**\n    $$P_i = \\frac{\\sum_{k=1}^K n_{k,i}}{\\sum_{k=1}^K N_k e^{\\beta(f_k - W_{k,i})}}$$\n    这个方程给出了未归一化的概率。在实际计算中，会先计算右侧，然后对所有 $i$ 的结果进行归一化，以确保 $\\sum_i P_i = 1$。\n\n2.  **自由能偏移的估计：**\n    $$e^{-\\beta f_k} = \\sum_{i=1}^M P_i e^{-\\beta W_{k,i}}$$\n\n这两个方程相互依赖，必须通过迭代求解，直到 $P_i$ 和 $f_k$ 收敛。\n\n### 3. 算法实现\n\n**第1步：数据生成**\n对于每个测试用例，必须首先生成合成的直方图数据 $n_{k,i}$。\n- 真实的无偏自由能给定为 $F_{\\text{true}}(s) = \\frac{1}{2} k_{\\text{ub}} s^2$。\n- 窗口 $k$ 在区间 $i$ 中的真实带偏概率质量为 $P_{k, \\text{true}, i} \\propto e^{-\\beta_{\\text{gen}}(F_{\\text{true}}(s_i) + W_k(s_i))}$。请注意，对于情况C，一个窗口的生成温度 $\\beta_{\\text{gen}}$ 与分析温度 $\\beta$ 不同。\n- 这些概率被归一化，使得 $\\sum_i P_{k, \\text{true}, i} = 1$。\n- 对于每个窗口 $k$，使用一个带种子的随机数生成器，从一个概率为 $P_{k, \\text{true}, i}$ 的多项分布中抽取 $N_k$ 个样本，以产生计数 $n_{k,i}$。\n\n**第2步：迭代 WHAM 求解**\nWHAM 方程通过自洽求解：\n1.  初始化所有 $f_k = 0$。\n2.  开始一个迭代循环：\n    a. 使用当前的 $f_k$ 值和提供的 $n_{k,i}$ 直方图，通过方程(1)计算所有区间的（未归一化的）$P_i$。\n    b. 对得到的 $P_i$ 进行归一化，使得 $\\sum_i P_i = 1$。这是确保稳定性的关键步骤。\n    c. 使用更新后的 $P_i$，通过方程(2)计算所有窗口的新值 $f_k^{\\text{new}}$。为防止 $f_k$ 值发生一致性漂移，将一个值固定（例如，$f_1 = 0$），方法是将所有 $f_k^{\\text{new}}$ 平移一个常数。\n    d. 检查 $f_k$ 值的变化，例如 $\\max_k |f_k^{\\text{new}} - f_k|$，是否低于一个小的容差。如果是，则退出循环。否则，更新 $f_k \\leftarrow f_k^{\\text{new}}$ 并继续。\n数值稳定性通过使用 log-sum-exp 技巧来处理指数项的求和，从而防止溢出错误。\n\n**第3步：自洽性验证**\n一旦获得收敛的全局概率分布 $P_i$，我们对每个窗口 $k$ 执行一致性检查：\n1.  获得无偏概率*密度* $p_i = P_i / \\Delta s$。\n2.  对于每个窗口 $k$，计算“反算”或重构的带偏概率密度 $\\tilde{p}_{k,i}$，这是在我们的模型下期望得到的：\n    $$\\tilde{p}_{k,i} = \\frac{p_i e^{-\\beta W_{k,i}}}{\\sum_{j} p_j e^{-\\beta W_{k,j}} \\Delta s}$$\n    分母确保了 $\\sum_i \\tilde{p}_{k,i} \\Delta s = 1$，正如所要求。\n3.  计算窗口 $k$ 在区间 $i$ 中的期望计数值：$\\langle n_{k,i} \\rangle = N_k \\tilde{p}_{k,i} \\Delta s$。\n4.  应用统计决策规则。问题将该规则指定为 $\\left| n_{k,i} - N_k \\tilde{p}_{k,i} \\right| \\le z \\sqrt{N_k \\tilde{p}_{k,i}}$。该表达式在量纲上不一致，因为 $n_{k,i}$ 是一个无量纲的计数，而 $N_k \\tilde{p}_{k,i}$ 的单位是 $1/\\text{length}$。基于计数数据的泊松统计，其明确的科学意图是比较观测到的计数值 $n_{k,i}$ 与期望计数值 $\\langle n_{k,i} \\rangle$。因此，该规则被修正为：\n    $$|n_{k,i} - \\langle n_{k,i} \\rangle| \\le z \\sqrt{\\langle n_{k,i} \\rangle}$$\n    其中 $z=3$。一个窗口 $k$ 被认为是自洽的，当且仅当这个不等式对所有区间 $i$ 都成立。\n5.  如果一个测试用例的所有组成窗口都被发现是自洽的，则该用例通过测试。对于情况C，来自窗口2的不一致数据（在不同温度下生成）预计会导致该窗口的观测计数与期望计数之间出现巨大偏差，从而导致测试失败。\n\n这个程序提供了一个严谨的、基于第一性原理的方法来验证一组带偏模拟数据的内部一致性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_case(case_params):\n    \"\"\"\n    Processes a single test case for WHAM self-consistency.\n\n    This function performs three main steps:\n    1. Generates synthetic histogram data based on a true underlying free energy profile.\n    2. Uses the Weighted Histogram Analysis Method (WHAM) to compute a global,\n       unbiased probability distribution from the biased histograms.\n    3. Performs a self-consistency check by back-calculating the expected distribution\n       in each window and comparing it to the observed histogram using a statistical criterion.\n    \"\"\"\n    # Unpack parameters for the test case\n    beta_gen = case_params['beta']\n    analysis_beta = case_params['analysis_beta']\n    k_ub = case_params['k_ub']\n    K = case_params['K']\n    c_k = np.array(case_params['c_k'])\n    N_k = np.array(case_params['N_k'])\n    s_min, s_max, M = case_params['s_min'], case_params['s_max'], case_params['M']\n    seed = case_params['seed']\n\n    num_windows = len(c_k)\n\n    # Step 1: Setup grid and generate synthetic count data (n_ki)\n    s_i, delta_s = np.linspace(s_min, s_max, M, retstep=True)\n    if M == 1 and delta_s == 0: delta_s = s_max - s_min\n    \n    n_ki = np.zeros((num_windows, M))\n    rng = np.random.default_rng(seed)\n\n    F_true_i = 0.5 * k_ub * s_i**2\n    W_ki_matrix = 0.5 * K * (s_i[np.newaxis, :] - c_k[:, np.newaxis])**2\n\n    for k in range(num_windows):\n        current_gen_beta = beta_gen[k] if isinstance(beta_gen, list) else beta_gen\n        \n        # Biased free energy for data generation\n        F_biased_true_i = F_true_i + W_ki_matrix[k, :]\n        log_prob_mass = -current_gen_beta * F_biased_true_i\n        \n        # Stabilize with log-sum-exp before taking exp\n        log_prob_mass -= np.max(log_prob_mass)\n        prob_mass = np.exp(log_prob_mass)\n        prob_mass /= np.sum(prob_mass)\n        \n        # Generate counts using multinomial distribution\n        n_ki[k, :] = rng.multinomial(N_k[k], prob_mass)\n\n    # Step 2: WHAM analysis using the specified analysis_beta\n    beta = analysis_beta\n    f_k = np.zeros(num_windows)\n    \n    max_iter = 5000\n    tol = 1e-10\n\n    for _ in range(max_iter):\n        f_k_old = f_k.copy()\n        \n        # Update unbiased probability mass P_i\n        # Calculate unnormalized probability (density-like)\n        log_denom_terms = beta * (f_k[:, np.newaxis] - W_ki_matrix)\n        max_log_denom = np.max(log_denom_terms, axis=0)\n        # Use log-sum-exp for stability\n        denom_sum = np.sum(N_k[:, np.newaxis] * np.exp(log_denom_terms - max_log_denom), axis=0)\n        \n        n_i = np.sum(n_ki, axis=0)\n        \n        # P_i here is an unnormalized probability density\n        P_i_unnorm = np.zeros(M)\n        valid_bins = denom_sum > 0\n        P_i_unnorm[valid_bins] = n_i[valid_bins] / (np.exp(max_log_denom[valid_bins]) * denom_sum[valid_bins])\n        \n        # Normalize to get probability mass P_i\n        P_i_sum = np.sum(P_i_unnorm)\n        if P_i_sum > 0:\n            P_i = P_i_unnorm / P_i_sum\n        else:\n            P_i = np.zeros(M)\n\n        # Update free energy shifts f_k\n        log_sum_terms = -beta * W_ki_matrix\n        max_log_sum = np.max(log_sum_terms, axis=1)\n        # Use log-sum-exp for stability, using P_i as probability mass\n        sum_val = np.sum(P_i[np.newaxis, :] * np.exp(log_sum_terms - max_log_sum[:, np.newaxis]), axis=1)\n        \n        f_k_new = np.zeros_like(f_k)\n        valid_f_k = sum_val > 0\n        f_k_new[valid_f_k] = - (1 / beta) * (max_log_sum[valid_f_k] + np.log(sum_val[valid_f_k]))\n        \n        f_k_new -= f_k_new[0]  # Pin f_1 to 0 to prevent drift\n        \n        if np.max(np.abs(f_k_new - f_k_old))  tol:\n            break\n        f_k = f_k_new\n\n    # Step 3: Self-consistency check\n    z = 3.0\n    case_is_consistent = True\n    p_i = P_i / delta_s # Convert probability mass P_i to probability density p_i\n\n    for k in range(num_windows):\n        log_p_tilde_unnorm = np.log(p_i, where=p_i > 0, out=np.full_like(p_i, -np.inf)) - beta * W_ki_matrix[k, :]\n        \n        max_log_p = np.max(log_p_tilde_unnorm)\n        if np.isinf(max_log_p):\n            p_tilde_ki = np.zeros_like(p_i)\n        else:\n            log_Z_k = max_log_p + np.log(np.sum(np.exp(log_p_tilde_unnorm - max_log_p)) * delta_s)\n            p_tilde_ki = np.exp(log_p_tilde_unnorm - log_Z_k)\n            \n        expected_n_ki = N_k[k] * p_tilde_ki * delta_s\n        \n        diff = np.abs(n_ki[k, :] - expected_n_ki)\n        threshold = z * np.sqrt(expected_n_ki)\n        \n        if not np.all(diff = threshold):\n            case_is_consistent = False\n            break\n            \n    return case_is_consistent\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'beta': 1.0,\n            'analysis_beta': 1.0,\n            'k_ub': 3.0, 'K': 10.0, 'c_k': [-1.0, 0.0, 1.0], 'N_k': [8000, 6000, 7000],\n            's_min': -2.5, 's_max': 2.5, 'M': 81, 'seed': 12345\n        },\n        {\n            'beta': 1.0,\n            'analysis_beta': 1.0,\n            'k_ub': 3.0, 'K': 10.0, 'c_k': [-1.0, 0.0, 1.0], 'N_k': [1500, 800, 1000],\n            's_min': -2.5, 's_max': 2.5, 'M': 81, 'seed': 24680\n        },\n        {\n            'beta': [1.0, 0.5, 1.0],\n            'analysis_beta': 1.0,\n            'k_ub': 3.0, 'K': 10.0, 'c_k': [-1.0, 0.0, 1.0], 'N_k': [7000, 9000, 7000],\n            's_min': -2.5, 's_max': 2.5, 'M': 81, 'seed': 13579\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3461103"}]}