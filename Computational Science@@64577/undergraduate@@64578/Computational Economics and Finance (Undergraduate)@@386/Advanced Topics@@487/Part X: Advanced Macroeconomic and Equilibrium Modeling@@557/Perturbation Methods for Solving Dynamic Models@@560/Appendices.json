{"hands_on_practices": [{"introduction": "Perturbation methods hinge on linearizing a model's dynamics around its steady state. But what happens if the chosen expansion point is not a true steady state of the system? This foundational exercise [@problem_id:2418938] provides a crucial hands-on lesson in the importance of this prerequisite, tasking you with observing the pathological and unstable dynamics that arise from linearizing around an incorrect point.", "id": "2418938", "problem": "Consider the standard one-sector Real Business Cycle (RBC) model with inelastic labor and logarithmic utility. Time is discrete. The representative household maximizes expected discounted utility subject to a resource constraint and firms operate a Cobb-Douglas technology. The structural environment is:\n- Preferences: $\\sum_{t=0}^{\\infty} \\beta^{t} \\log(c_{t})$ with discount factor $\\beta \\in (0,1)$.\n- Technology: $y_{t} = \\exp(z_{t}) k_{t}^{\\alpha}$ with capital share $\\alpha \\in (0,1)$.\n- Capital accumulation and resource feasibility: $c_{t} + k_{t+1} = (1-\\delta) k_{t} + y_{t}$ with depreciation rate $\\delta \\in (0,1)$.\n- Productivity shock: $z_{t+1} = \\rho z_{t} + \\sigma \\varepsilon_{t+1}$ with $|\\rho|<1$, $\\sigma>0$, and $\\varepsilon_{t+1} \\sim \\mathcal{N}(0,1)$.\n\nThe fundamental equilibrium first-order conditions are:\n- Euler equation: $\\dfrac{1}{c_{t}} = \\beta \\, \\mathbb{E}_{t} \\left[ \\dfrac{1}{c_{t+1}} \\left( \\alpha \\exp(z_{t+1}) k_{t+1}^{\\alpha-1} + 1 - \\delta \\right) \\right]$.\n- Resource feasibility: $c_{t} + k_{t+1} - (1-\\delta)k_{t} - \\exp(z_{t}) k_{t}^{\\alpha} = 0$.\n\nLet the vector of predetermined endogenous variables be $x_{t} = k_{t}$, the vector of non-predetermined endogenous (jump) variables be $y_{t} = c_{t}$, and the vector of exogenous states be $z_{t}$ (scalar). Define the equilibrium residual vector $f(\\cdot)$ at time $t$ on the variables $(x_{t+1},y_{t+1},x_{t},y_{t},z_{t+1},z_{t})$ by stacking the Euler equation residual and the resource feasibility residual evaluated at those arguments.\n\nFirst-order perturbation around a steady state requires linearization of the equilibrium conditions around a point that satisfies the steady-state conditions. In this exercise, you are asked to implement a naive first-order perturbation that ignores the constant residual and linearizes around possibly incorrect “pseudo steady states” that do not satisfy the steady-state conditions. The goal is to illustrate the pathologies that can occur when the expansion point is incorrect, by computing the resulting impulse response functions (IRFs) and stability properties.\n\nTasks to implement:\n1. For a given expansion point $(\\bar{x},\\bar{y},\\bar{z}) = (\\bar{k},\\bar{c},0)$ and its “next-period” counterpart $(\\bar{x}^{+},\\bar{y}^{+},\\bar{z}^{+}) = (\\bar{k},\\bar{c},0)$, numerically compute the Jacobian blocks of $f$ using central finite differences:\n   - $f_{x^{+}} = \\frac{\\partial f}{\\partial x_{t+1}}(\\bar{\\cdot})$, $f_{y^{+}} = \\frac{\\partial f}{\\partial y_{t+1}}(\\bar{\\cdot})$, $f_{x} = \\frac{\\partial f}{\\partial x_{t}}(\\bar{\\cdot})$, $f_{y} = \\frac{\\partial f}{\\partial y_{t}}(\\bar{\\cdot})$, $f_{z} = \\frac{\\partial f}{\\partial z_{t}}(\\bar{\\cdot})$, $f_{z^{+}} = \\frac{\\partial f}{\\partial z_{t+1}}(\\bar{\\cdot})$.\n   Use a step size that scales with the magnitude of the variable being perturbed to avoid numerical underflow and ensure $y$ stays strictly positive in the perturbations.\n2. Form the linearized expectational system (in deviations from the expansion point) by combining the $z_{t+1}$ term via its conditional expectation:\n   - Let $F_{x^{+}} = f_{x^{+}}$, $F_{y^{+}} = f_{y^{+}}$, $F_{x} = f_{x}$, $F_{y} = f_{y}$, and $F_{z} = f_{z} + f_{z^{+}} \\rho$.\n   - The linearized equilibrium is $F_{x^{+}} x_{t+1} + F_{y^{+}} y_{t+1} + F_{x} x_{t} + F_{y} y_{t} + F_{z} z_{t} = 0$, where expectations apply to $y_{t+1}$ via the policy function.\n3. Assume linear policy functions for a naive first-order solution (ignoring any constant term induced by linearizing at a non-solution):\n   - $x_{t+1} = p \\, x_{t} + q \\, z_{t}$,\n   - $y_{t} = r \\, x_{t} + s \\, z_{t}$,\n   - and hence $\\mathbb{E}_{t} y_{t+1} = r \\, x_{t+1} + s \\, \\rho \\, z_{t}$.\n   Impose that the coefficients on $x_{t}$ and $z_{t}$ in the linearized system are identically zero in each equation to obtain two vector conditions. Solve for $(p,r)$ from the $x_{t}$-coefficient conditions and then for $(q,s)$ from the $z_{t}$-coefficient conditions. Use a robust numerical root finder for $(p,r)$ and a linear solver for $(q,s)$. If the solver fails to converge to a finite solution, treat the case as “no valid solution.”\n4. Using the obtained $(p,q,r,s)$, compute the impulse response functions (IRFs) of $(x_{t},y_{t})$ to a one-time initial exogenous state deviation of size $\\Delta z_{0} = \\sigma$ at $t=0$, with $x_{0}=0$, and $z_{t+1} = \\rho z_{t}$ for $t \\ge 0$ and no further shocks. That is, set $z_{0} = \\sigma$, then iterate:\n   - $y_{t} = r \\, x_{t} + s \\, z_{t}$,\n   - $x_{t+1} = p \\, x_{t} + q \\, z_{t}$,\n   - $z_{t+1} = \\rho \\, z_{t}$,\n   for $t = 0,1,\\dots,T-1$ over a finite horizon $T$.\n5. Diagnose “pathology” using the following quantitative metrics:\n   - Stability flag: set to $1$ if $|p| < 1$ and to $0$ otherwise.\n   - Sign-consistency flag for the impact response of consumption: set to $1$ if $y_{0} \\ge 0$ when $\\Delta z_{0} > 0$, and $0$ otherwise.\n   - Divergence flag: compute the Euclidean norms $\\| (x_{t},y_{t}) \\|$ over the horizon; set to $1$ if either the solver failed, or $|p| \\ge 1$, or if the ratio $\\max_{t \\in \\{T-5,\\dots,T-1\\}} \\| (x_{t},y_{t}) \\| \\big/ \\max_{t \\in \\{0,\\dots,4\\}} \\| (x_{t},y_{t}) \\|$ exceeds $100$, and set to $0$ otherwise.\n\nParameter values:\n- $\\beta = 0.96$, $\\alpha = 0.36$, $\\delta = 0.08$, $\\rho = 0.90$, $\\sigma = 0.01$, $T = 40$.\n- The correct steady state (expansion point) satisfies $1 = \\beta \\left( \\alpha \\bar{k}^{\\alpha-1} + 1 - \\delta \\right)$, so $\\bar{k} = \\left( \\dfrac{\\alpha}{\\beta^{-1} - 1 + \\delta} \\right)^{\\frac{1}{1-\\alpha}}$, $\\bar{y} = \\bar{k}^{\\alpha}$, $\\bar{c} = \\bar{y} - \\delta \\bar{k}$, and $\\bar{z} = 0$.\n\nTest suite of expansion points (linearize “naively” around each, treating it as if it were a steady state):\n- Case A (correct expansion point): $(\\bar{k}, \\bar{c}, 0)$ computed from the above formulas.\n- Case B (incorrect but resource-consistent): $(\\tilde{k}, \\tilde{c}, 0)$ with $\\tilde{k} = 0.5 \\, \\bar{k}$ and $\\tilde{c} = \\tilde{k}^{\\alpha} - \\delta \\tilde{k}$.\n- Case C (incorrect and resource-inconsistent): $(\\hat{k}, \\hat{c}, 0)$ with $\\hat{k} = 5.0 \\, \\bar{k}$ and $\\hat{c} = 0.2 \\, \\bar{c}$.\n\nYour program must:\n- Numerically compute the Jacobians, solve for $(p,q,r,s)$ using the method described, simulate the IRFs for each case under the one-time initial deviation $\\Delta z_{0} = \\sigma$, and compute the three flags for each case in the order: stability flag, sign-consistency flag, divergence flag.\n- Produce a single line of output containing all results as a comma-separated list enclosed in square brackets, in the order: Case A flags followed by Case B flags followed by Case C flags. For example, the output format must be exactly like: $[a_{1},a_{2},a_{3},b_{1},b_{2},b_{3},c_{1},c_{2},c_{3}]$ where each $a_{i}$, $b_{i}$, $c_{i}$ is an integer $0$ or $1$.\n\nNo physical units or angle units are involved. Express all numeric outputs as integers $0$ or $1$ exactly, not as decimals.", "solution": "The problem requires an implementation and evaluation of a first-order perturbation method for a standard Real Business Cycle (RBC) model. The unique aspect of the problem is the directive to perform the linearization (perturbation) around points that are not necessarily the true deterministic steady state of the model. This is a pedagogical exercise to demonstrate the pathologies that arise from an incorrect expansion point, which is a common error in practical application. My response will present the systematic procedure to solve this problem, adhering to the specified numerical methods.\n\nFirst, the structural equations of the economic environment must be clearly defined. The representative household's problem under the given preferences, technology, and constraints yields two fundamental first-order conditions that must hold in equilibrium at all times $t$:\n1.  The Euler equation, which governs the intertemporal consumption-savings trade-off:\n    $$ \\dfrac{1}{c_{t}} = \\beta \\, \\mathbb{E}_{t} \\left[ \\dfrac{1}{c_{t+1}} \\left( \\alpha \\exp(z_{t+1}) k_{t+1}^{\\alpha-1} + 1 - \\delta \\right) \\right] $$\n2.  The resource constraint, ensuring market clearing:\n    $$ c_{t} + k_{t+1} = (1-\\delta) k_{t} + \\exp(z_{t}) k_{t}^{\\alpha} $$\n\nThese two equations form a system of nonlinear stochastic difference equations. To solve this system using perturbation, we first express them as a vector of residual functions, $f$, which must equal zero in equilibrium. Let the state vector be partitioned into predetermined variables $x_t = k_t$, non-predetermined (jump) variables $y_t = c_t$, and exogenous shocks $z_t$. The system can be written abstractly as:\n$$ \\mathbb{E}_t [f(x_{t+1}, y_{t+1}, x_t, y_t, z_{t+1}, z_t)] = 0 $$\nSpecifically, the two components of $f$ are:\n$$ f_1 = \\dfrac{1}{y_{t}} - \\beta \\dfrac{1}{y_{t+1}} \\left( \\alpha \\exp(z_{t+1}) x_{t+1}^{\\alpha-1} + 1 - \\delta \\right) $$\n$$ f_2 = y_{t} + x_{t+1} - (1-\\delta)x_{t} - \\exp(z_{t}) x_{t}^{\\alpha} $$\nNote that the expectation operator is handled at a later stage.\n\nA first-order perturbation approximates the solution by taking a first-order Taylor series expansion of this system around a specified expansion point, denoted $(\\bar{x}, \\bar{y}, \\bar{z})$. A crucial detail is that a correct application of perturbation theory requires this expansion point to be a steady state, i.e., a point where $f(\\bar{x}, \\bar{y}, \\bar{x}, \\bar{y}, \\bar{z}, \\bar{z}) = 0$ when $\\bar{z}=0$. The problem instructs us to proceed \"naively\" by ignoring the constant term that arises when this condition is not met. The linearized system is thus approximated as:\n$$ F_{x^{+}} \\hat{x}_{t+1} + F_{y^{+}} \\mathbb{E}_{t} \\hat{y}_{t+1} + F_{x} \\hat{x}_{t} + F_{y} \\hat{y}_{t} + F_{z^{+}} \\mathbb{E}_{t} \\hat{z}_{t+1} + F_{z} \\hat{z}_{t} = 0 $$\nwhere $\\hat{v} = v - \\bar{v}$ denotes a deviation from the expansion point, and the matrices $F_{v}$ are the Jacobians of $f$ with respect to variable $v$, evaluated at the expansion point. As per the problem, these Jacobians are computed numerically using a central finite difference scheme.\n\nThe autoregressive nature of the shock process, $z_{t+1} = \\rho z_t + \\sigma \\varepsilon_{t+1}$, implies $\\mathbb{E}_t[\\hat{z}_{t+1}] = \\rho \\hat{z}_t$. Substituting this collapses the shock terms into one:\n$$ F_{x^{+}} \\hat{x}_{t+1} + F_{y^{+}} \\mathbb{E}_{t} \\hat{y}_{t+1} + F_{x} \\hat{x}_{t} + F_{y} \\hat{y}_{t} + (F_{z} + F_{z^{+}}\\rho) \\hat{z}_{t} = 0 $$\n\nThe term $\\mathbb{E}_{t} \\hat{y}_{t+1}$ is endogenous and unknown. To solve the system, we assume a linear policy function for the deviations:\n$$ \\hat{x}_{t+1} = p \\hat{x}_{t} + q \\hat{z}_{t} $$\n$$ \\hat{y}_{t} = r \\hat{x}_{t} + s \\hat{z}_{t} $$\nThis implies a rule for the expectation of the future jump variable:\n$$ \\mathbb{E}_{t} \\hat{y}_{t+1} = \\mathbb{E}_{t} [r \\hat{x}_{t+1} + s \\hat{z}_{t+1}] = r \\hat{x}_{t+1} + s (\\rho \\hat{z}_t) = r(p \\hat{x}_{t} + q \\hat{z}_{t}) + s \\rho \\hat{z}_t $$\n\nSubstituting these policy rules into the linearized system and grouping terms by the independent state variables $\\hat{x}_t$ and $\\hat{z}_t$ gives two conditions, as the equation must hold for any state realization:\n1.  Coefficient on $\\hat{x}_t$: $F_{x^{+}}p + F_{y^{+}}rp + F_x + F_y r = 0$\n2.  Coefficient on $\\hat{z}_t$: $F_{x^{+}}q + F_{y^{+}}(rq + s\\rho) + F_y s + (F_z + F_{z^{+}}\\rho) = 0$\n\nThe first is a system of two equations, nonlinear in the two unknowns $(p,r)$ due to the product $rp$. It must be solved numerically, for instance, with a robust root-finding algorithm. The second is a linear system in $(q,s)$ that can be solved directly once $(p,r)$ are known.\n\nOnce the policy function coefficients $(p,q,r,s)$ are determined, we can assess the properties of the resulting \"solution\". Failure to find a finite, real solution with the numerical solver is the first indicator of pathology. If a solution is found, we evaluate it against three criteria:\n1.  **Stability**: A stable dynamic system requires that the endogenous state variable does not explode in response to a temporary shock. For this model, this corresponds to the condition $|\\,p\\,| < 1$.\n2.  **Sign-Consistency**: Standard economic theory dictates that a positive productivity shock ($\\Delta z_0 > 0$) should lead to an increase in consumption, i.e., $y_0 \\ge 0$. The initial response is $\\hat{y}_0 = r \\hat{x}_0 + s \\hat{z}_0 = s \\sigma$. Given $\\sigma>0$, this reduces to checking if $s \\ge 0$.\n3.  **Divergence**: This is a composite flag. It is triggered if the solver fails, if the stability condition $|\\,p\\,| \\ge 1$ is met, or if the simulated impulse response functions (IRFs) show explosive behavior, quantitatively measured by comparing the norm of the state vector at the end of the simulation horizon to its norm at the beginning.\n\nThe implementation will apply this entire procedure to three distinct expansion points: the correct steady state (Case A), an incorrect but resource-consistent point (Case B), and an incorrect point violating all steady-state conditions (Case C). This will quantitatively demonstrate that only linearization around the true steady state yields a coherent dynamic system.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import root\n\ndef process_case(expansion_point, params):\n    \"\"\"\n    Computes Jacobians, solves for policy functions, and evaluates pathologies for a given expansion point.\n    \"\"\"\n    # Unpack parameters\n    beta, alpha, delta, rho, sigma, T = params\n    k_bar, c_bar, z_bar = expansion_point\n\n    # Ensure expansion point itself is valid for calculation (c>0)\n    if c_bar <= 0:\n        # Cannot proceed, mark as total failure\n        return 0, 0, 1\n\n    # 1. Define the residual functions for the two equilibrium conditions\n    def f_residuals(xp, yp, x, y, zp, z):\n        # xp=k_{t+1}, yp=c_{t+1}, x=k_t, y=c_t, zp=z_{t+1}, z=z_t\n        if yp <= 0:\n            return np.array([1e12, 1e12]) # Return large penalty if consumption is non-positive\n        \n        # Euler equation residual\n        f1 = 1.0 / y - beta / yp * (alpha * np.exp(zp) * xp**(alpha - 1) + 1.0 - delta)\n        # Resource constraint residual\n        f2 = y + xp - (1.0 - delta) * x - np.exp(z) * x**alpha\n        return np.array([f1, f2])\n\n    # 2. Compute Jacobians numerically via central finite differences\n    def compute_jacobians(eval_point):\n        k_eval, c_eval, z_eval = eval_point\n        vars_base = [k_eval, c_eval, k_eval, c_eval, z_eval, z_eval]\n        jacobians = {}\n        var_names = ['xp', 'yp', 'x', 'y', 'zp', 'z']\n        \n        for i, name in enumerate(var_names):\n            # Scaled step size to handle variables of different magnitudes\n            h = 1e-6 * np.abs(vars_base[i]) + 1e-8\n            \n            vars_plus = list(vars_base)\n            vars_plus[i] += h\n            f_plus = f_residuals(*vars_plus)\n\n            vars_minus = list(vars_base)\n            vars_minus[i] -= h\n            f_minus = f_residuals(*vars_minus)\n            \n            jacobians[name] = (f_plus - f_minus) / (2.0 * h)\n            \n        return (jacobians['xp'], jacobians['yp'], jacobians['x'],\n                jacobians['y'], jacobians['zp'], jacobians['z'])\n\n    f_xp, f_yp, f_x, f_y, f_zp, f_z = compute_jacobians(expansion_point)\n\n    # 3. Solve for policy function coefficients (p, r, q, s)\n    p, q, r, s = None, None, None, None\n    solver_success = False\n    \n    # Define the nonlinear system for (p, r)\n    def pol_sys_pr(pr_vec):\n        p_val, r_val = pr_vec\n        # Eq1: Coefficient on x_t from Euler residual must be zero\n        eq1 = f_xp[0] * p_val + f_yp[0] * r_val * p_val + f_x[0] + f_y[0] * r_val\n        # Eq2: Coefficient on x_t from Resource residual must be zero\n        eq2 = f_xp[1] * p_val + f_yp[1] * r_val * p_val + f_x[1] + f_y[1] * r_val\n        return [eq1, eq2]\n    \n    # Solve for (p,r) using a numerical root finder\n    initial_guess_pr = [0.95, 0.5]\n    sol_pr = root(pol_sys_pr, initial_guess_pr, method='hybr', options={'xtol': 1e-9})\n    \n    if sol_pr.success and np.all(np.isfinite(sol_pr.x)):\n        p, r = sol_pr.x\n        \n        # Once (p,r) are found, solve the linear system for (q,s)\n        Fz_eff = f_z + f_zp * rho\n        \n        A = np.zeros((2, 2))\n        A[:, 0] = f_xp + f_yp * r      # Coefficient on q\n        A[:, 1] = f_y + f_yp * rho    # Coefficient on s\n        \n        b = -Fz_eff\n        \n        try:\n            # Check if matrix A is singular\n            if np.linalg.det(A) == 0:\n                solver_success = False\n            else:\n                q, s = np.linalg.solve(A, b)\n                if np.all(np.isfinite([q, s])):\n                    solver_success = True\n        except np.linalg.LinAlgError:\n            solver_success = False\n\n    # 4. Diagnose pathologies and compute flags\n    divergence_flag = 0\n    if not solver_success:\n        divergence_flag = 1\n        stability_flag = 0\n        sign_consistency_flag = 0\n        return stability_flag, sign_consistency_flag, divergence_flag\n\n    stability_flag = 1 if np.abs(p) < 1.0 else 0\n    sign_consistency_flag = 1 if s >= 0.0 else 0\n    \n    if np.abs(p) >= 1.0:\n        divergence_flag = 1\n\n    # Simulate IRF to check for long-term divergence only if not already flagged\n    if divergence_flag == 0:\n        x_irf = np.zeros(T)\n        y_irf = np.zeros(T)\n        z_irf = np.zeros(T)\n        \n        z_irf[0] = sigma\n        # x_irf[0] is 0 by problem specification\n\n        for t in range(T - 1):\n            y_irf[t] = r * x_irf[t] + s * z_irf[t]\n            x_irf[t+1] = p * x_irf[t] + q * z_irf[t]\n            z_irf[t+1] = rho * z_irf[t]\n        y_irf[T-1] = r * x_irf[T-1] + s * z_irf[T-1]\n\n        norms = np.sqrt(x_irf**2 + y_irf**2)\n        \n        max_early = np.max(norms[0:5])\n        max_late = np.max(norms[T-5:T])\n        \n        # If initial impact is virtually zero, system is stable, so avoid division by zero\n        if max_early > 1e-12:\n            if max_late / max_early > 100.0:\n                divergence_flag = 1\n    \n    return stability_flag, sign_consistency_flag, divergence_flag\n\n\ndef solve():\n    # Structural parameters of the RBC model\n    beta = 0.96\n    alpha = 0.36\n    delta = 0.08\n    rho = 0.90\n    sigma = 0.01\n    T = 40\n    params = (beta, alpha, delta, rho, sigma, T)\n\n    # Calculate the correct steady state (for Case A and as a reference)\n    k_bar = (alpha / (1.0/beta - 1.0 + delta))**(1.0 / (1.0 - alpha))\n    c_bar = k_bar**alpha - delta * k_bar\n    z_bar = 0.0\n    \n    # Define the three test cases as expansion points (k, c, z)\n    test_cases = [\n        # Case A: Correct expansion point\n        (k_bar, c_bar, z_bar),\n        # Case B: Incorrect but resource-consistent point\n        (0.5 * k_bar, (0.5 * k_bar)**alpha - delta * (0.5 * k_bar), z_bar),\n        # Case C: Incorrect and resource-inconsistent point\n        (5.0 * k_bar, 0.2 * c_bar, z_bar)\n    ]\n\n    all_results = []\n    for expansion_point in test_cases:\n        flags = process_case(expansion_point, params)\n        all_results.extend(flags)\n        \n    # Format and print the final output as a single-line list\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"}, {"introduction": "While first-order perturbations provide a powerful and tractable way to analyze dynamic models, it is essential to understand their limitations. This practice [@problem_id:2418979] delves into the accuracy of such solutions by asking you to derive the Euler equation error for a simple policy. Your result will reveal how second-order terms, related to risk $\\sigma$, quantify the \"precautionary\" behavior that a first-order approximation misses.", "id": "2418979", "problem": "Consider a representative, infinitely lived agent in discrete time who maximizes expected lifetime utility with Constant Relative Risk Aversion (CRRA) period utility given by $u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}$ where $\\gamma \\gt 0$. The agent discounts the future at factor $\\beta \\in (0,1)$. Let the gross return on saving be stochastic and i.i.d. (independent and identically distributed) each period with\n$$\n\\ln R_{t+1} = \\ln \\bar{R} + \\sigma \\varepsilon_{t+1},\n$$\nwhere $\\bar{R} \\gt 0$ is the nonstochastic benchmark gross return, $\\sigma \\ge 0$ is a small volatility parameter, and $\\varepsilon_{t+1} \\sim \\mathcal{N}(0,1)$ is standard normal and independent over time. The deterministic steady state is characterized by constant consumption $\\bar{c} \\gt 0$ and the equilibrium condition $\\beta \\bar{R} = 1$. Consider the Euler equation\n$$\nu'(c_t) = \\beta \\,\\mathbb{E}_t\\!\\left[u'(c_{t+1}) R_{t+1}\\right].\n$$\nSuppose the agent implements the certainty-equivalent, first-order accurate policy $c_t = \\bar{c}$ for all $t$.\n\nDefine the Euler equation residual at time $t$ by\n$$\n\\mathcal{E}_t \\equiv u'(c_t) - \\beta \\,\\mathbb{E}_t\\!\\left[u'(c_{t+1}) R_{t+1}\\right].\n$$\n\nDerive, up to and including terms of order $\\sigma^2$, the second-order approximation in $\\sigma$ to the expected Euler equation residual evaluated at the nonstochastic steady state under the policy $c_t=\\bar{c}$. Express your final answer as a closed-form analytic expression in terms of $\\bar{c}$, $\\gamma$, and $\\sigma$ only. Do not substitute numerical values. Provide only the final expression; no units are required.", "solution": "The problem requires the derivation of a second-order approximation in the parameter $\\sigma$ for the expected Euler equation residual, evaluated at the nonstochastic steady state.\n\nThe Euler equation residual at time $t$ is defined by the problem statement as:\n$$\n\\mathcal{E}_t \\equiv u'(c_t) - \\beta \\,\\mathbb{E}_t\\!\\left[u'(c_{t+1}) R_{t+1}\\right]\n$$\nThe problem specifies that the agent's policy is to maintain consumption at its nonstochastic steady state level, $\\bar{c}$, at all times. Therefore, we have $c_t = \\bar{c}$ and $c_{t+1} = \\bar{c}$. Substituting this policy into the definition of the residual yields:\n$$\n\\mathcal{E}_t = u'(\\bar{c}) - \\beta \\,\\mathbb{E}_t\\!\\left[u'(\\bar{c}) R_{t+1}\\right]\n$$\nSince the marginal utility at the steady state, $u'(\\bar{c})$, is a constant value, it can be factored out of the expectation operator:\n$$\n\\mathcal{E}_t = u'(\\bar{c}) \\left(1 - \\beta \\,\\mathbb{E}_t\\!\\left[R_{t+1}\\right]\\right)\n$$\nThe expectation $\\mathbb{E}_t$ is conditional on the information available at time $t$. The stochastic gross return $R_{t+1}$ is a function of the shock $\\varepsilon_{t+1}$, which is specified to be i.i.d. and thus independent of any information at time $t$. Consequently, the conditional expectation is equal to the unconditional expectation, i.e., $\\mathbb{E}_t[R_{t+1}] = \\mathbb{E}[R_{t+1}]$. This implies that the residual $\\mathcal{E}_t$ is not a random variable but a constant, which we can denote as $\\mathcal{E}$. The problem asks for the expected value of the residual, $\\mathbb{E}[\\mathcal{E}_t]$, which is simply $\\mathcal{E}$ itself.\n$$\n\\mathcal{E} = u'(\\bar{c}) \\left(1 - \\beta \\,\\mathbb{E}\\!\\left[R_{t+1}\\right]\\right)\n$$\nThe next step is to calculate the unconditional expectation $\\mathbb{E}[R_{t+1}]$. We are given the process for the logarithm of the gross return:\n$$\n\\ln R_{t+1} = \\ln \\bar{R} + \\sigma \\varepsilon_{t+1}, \\quad \\text{where} \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0,1)\n$$\nThis indicates that $\\ln R_{t+1}$ follows a normal distribution with mean $\\mathbb{E}[\\ln R_{t+1}] = \\ln \\bar{R}$ and variance $\\text{Var}(\\ln R_{t+1}) = \\sigma^2$. A random variable $X$ is log-normally distributed if $\\ln X$ is normally distributed. If $\\ln X \\sim \\mathcal{N}(\\mu, \\nu^2)$, its expectation is given by the formula $\\mathbb{E}[X] = \\exp(\\mu + \\frac{1}{2}\\nu^2)$. Applying this formula to $R_{t+1}$ with $\\mu = \\ln \\bar{R}$ and $\\nu^2 = \\sigma^2$, we find:\n$$\n\\mathbb{E}[R_{t+1}] = \\exp\\left(\\ln \\bar{R} + \\frac{1}{2}\\sigma^2\\right) = \\exp(\\ln \\bar{R}) \\exp\\left(\\frac{1}{2}\\sigma^2\\right) = \\bar{R} \\exp\\left(\\frac{1}{2}\\sigma^2\\right)\n$$\nSubstituting this result into the expression for the residual $\\mathcal{E}$:\n$$\n\\mathcal{E} = u'(\\bar{c}) \\left(1 - \\beta \\bar{R} \\exp\\left(\\frac{1}{2}\\sigma^2\\right)\\right)\n$$\nWe now use the deterministic steady-state condition given in the problem, $\\beta \\bar{R} = 1$. This simplifies the expression for $\\mathcal{E}$ to:\n$$\n\\mathcal{E} = u'(\\bar{c}) \\left(1 - \\exp\\left(\\frac{1}{2}\\sigma^2\\right)\\right)\n$$\nThe problem requires an approximation of this expression that is accurate up to and including terms of order $\\sigma^2$. This is achieved by performing a Taylor series expansion of the exponential term around $\\sigma = 0$. The expansion of $\\exp(x)$ around $x=0$ is $\\exp(x) = 1 + x + \\frac{x^2}{2!} + O(x^3)$. We set $x = \\frac{1}{2}\\sigma^2$. To obtain an approximation up to order $\\sigma^2$, we only need the first two terms of the expansion:\n$$\n\\exp\\left(\\frac{1}{2}\\sigma^2\\right) \\approx 1 + \\left(\\frac{1}{2}\\sigma^2\\right)\n$$\nSubstituting this linear approximation into the expression for $\\mathcal{E}$:\n$$\n\\mathcal{E} \\approx u'(\\bar{c}) \\left(1 - \\left(1 + \\frac{1}{2}\\sigma^2\\right)\\right) = u'(\\bar{c}) \\left(1 - 1 - \\frac{1}{2}\\sigma^2\\right) = u'(\\bar{c}) \\left(-\\frac{1}{2}\\sigma^2\\right)\n$$\nThe final step is to find the explicit form of the marginal utility $u'(\\bar{c})$. The given utility function is the CRRA form, $u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}$. Its first derivative with respect to $c$ is the marginal utility:\n$$\nu'(c) = \\frac{d}{dc} \\left(\\frac{c^{1-\\gamma}}{1-\\gamma}\\right) = \\frac{(1-\\gamma)c^{(1-\\gamma)-1}}{1-\\gamma} = c^{-\\gamma}\n$$\nEvaluating this at the steady-state consumption level $\\bar{c}$ gives $u'(\\bar{c}) = \\bar{c}^{-\\gamma}$.\nSubstituting this into our approximation for $\\mathcal{E}$, we arrive at the final result for the expected Euler equation residual, accurate to the second order in $\\sigma$:\n$$\n\\mathbb{E}[\\mathcal{E}_t] = \\mathcal{E} \\approx -\\frac{1}{2} \\bar{c}^{-\\gamma} \\sigma^2\n$$\nThis expression is in terms of $\\bar{c}$, $\\gamma$, and $\\sigma$ as required.", "answer": "$$\n\\boxed{-\\frac{1}{2} \\bar{c}^{-\\gamma} \\sigma^2}\n$$"}, {"introduction": "Moving beyond first-order solutions to incorporate valuable second-order effects introduces new implementation challenges. A naive simulation of a second-order policy can paradoxically become unstable due to the accumulation of spurious higher-order terms. This advanced exercise [@problem_id:2418999] will guide you through implementing and comparing a naive simulation with a theoretically sound \"pruning\" algorithm, demonstrating how to achieve stable and accurate higher-order dynamics.", "id": "2418999", "problem": "Consider a univariate second-order perturbation policy function for the deviation of capital from its non-stochastic steady state, denoted by $k_t$. The second-order approximation around the steady state takes the form\n$$\nk_{t+1} \\;=\\; h\\,k_t \\;+\\; r\\,\\sigma\\,\\varepsilon_{t+1} \\;+\\; \\tfrac{1}{2}H\\,k_t^2 \\;+\\; \\tfrac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 \\;+\\; N\\,k_t\\,(\\sigma\\,\\varepsilon_{t+1}),\n$$\nwhere $h$, $r$, $H$, $M$, and $N$ are real-valued coefficients, $\\sigma \\ge 0$ is the shock scale, and $\\varepsilon_{t}$ are independent and identically distributed standard normal shocks with $\\varepsilon_t \\sim \\mathcal{N}(0,1)$.\n\nTwo simulation conventions are to be implemented over a finite horizon of length $T$ with initial condition $k_0 = 0$:\n\n1. Direct iteration of the approximation:\n$$\n\\text{for } t = 0,1,\\dots,T-1:\\quad k_{t+1}^{\\text{dir}} \\;=\\; h\\,k_t^{\\text{dir}} \\;+\\; r\\,\\sigma\\,\\varepsilon_{t+1} \\;+\\; \\tfrac{1}{2}H\\,(k_t^{\\text{dir}})^2 \\;+\\; \\tfrac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 \\;+\\; N\\,k_t^{\\text{dir}}\\,(\\sigma\\,\\varepsilon_{t+1}).\n$$\n\n2. Order-consistent simulation that enforces truncation to second order by separating first-order and second-order components:\n$$\nz_{t+1} \\;=\\; h\\,z_t \\;+\\; r\\,\\sigma\\,\\varepsilon_{t+1},\n$$\n$$\nw_{t+1} \\;=\\; H\\,z_t^2 \\;+\\; M\\,(\\sigma\\,\\varepsilon_{t+1})^2 \\;+\\; 2\\,N\\,z_t\\,(\\sigma\\,\\varepsilon_{t+1}),\n$$\n$$\nk_{t+1}^{\\text{oc}} \\;=\\; z_{t+1} \\;+\\; \\tfrac{1}{2}w_{t+1},\n$$\nwith $z_0 = 0$ and $w_0 = 0$.\n\nFor numerical reproducibility, use a fixed random seed $s = 2025$ for generating the sequence $\\{\\varepsilon_t\\}_{t=1}^T$, and take $\\varepsilon_t$ to be independent and identically distributed draws from the standard normal distribution. Define a numerical bound $B = 10^6$. A simulated path $\\{k_t\\}_{t=0}^T$ is said to be \"divergent\" if it ever attains a non-finite value (not-a-number or infinite) or if $\\max_{0 \\le t \\le T} |k_t| > B$; it is \"bounded\" otherwise.\n\nYour task is to write a program that, for each parameter set in the test suite below, generates the same shock sequence for both simulations and decides whether the direct iteration produces a divergent path while the order-consistent simulation remains bounded. For each parameter set $i$, output the integer $1$ if and only if the direct iteration diverges and the order-consistent simulation remains bounded; otherwise output the integer $0$.\n\nTest suite (each line lists $(h,r,H,M,N,\\sigma,T)$):\n- Case A (general case designed to expose divergence under direct iteration): $(0.95,\\,0.8,\\,1.2,\\,0.8,\\,0.6,\\,0.6,\\,20000)$\n- Case B (boundary case with no stochasticity): $(0.95,\\,0.8,\\,1.2,\\,0.8,\\,0.6,\\,0.0,\\,1000)$\n- Case C (near-linear case with weak nonlinearities): $(0.90,\\,0.3,\\,0.05,\\,0.02,\\,0.01,\\,0.2,\\,5000)$\n\nYour program should produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets. For example, an output with three cases must look like \"[x1,x2,x3]\" where $x_i \\in \\{0,1\\}$.", "solution": "The problem statement is subjected to validation and is found to be valid. It is scientifically grounded within the field of computational economics, specifically regarding the numerical implementation of perturbation methods for dynamic stochastic models. The problem is well-posed, providing all necessary equations, parameters, initial conditions, and a clear, objective criterion for evaluation. It is free from ambiguity, contradiction, and factual error. We may therefore proceed with a solution.\n\nThe core of this problem lies in the distinction between two methods for simulating a dynamic system derived from a second-order Taylor approximation. The difference between these methods is not trivial; it concerns the numerical stability and theoretical consistency of the simulation. A rigorous analysis reveals why one method may fail while the other succeeds.\n\nThe model for the state variable $k_t$, representing the deviation of capital from its steady state, is given by the second-order approximation:\n$$\nk_{t+1} = h\\,k_t + r\\,\\sigma\\,\\varepsilon_{t+1} + \\frac{1}{2}H\\,k_t^2 + \\frac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 + N\\,k_t\\,(\\sigma\\,\\varepsilon_{t+1})\n$$\nwhere $k_0 = 0$ and $\\varepsilon_t \\sim \\mathcal{N}(0,1)$.\n\nThe first simulation method, termed \"direct iteration,\" implements this equation recursively:\n$$\nk_{t+1}^{\\text{dir}} = h\\,k_t^{\\text{dir}} + r\\,\\sigma\\,\\varepsilon_{t+1} + \\frac{1}{2}H\\,(k_t^{\\text{dir}})^2 + \\frac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 + N\\,k_t^{\\text{dir}}\\,(\\sigma\\,\\varepsilon_{t+1})\n$$\nThis approach is seemingly straightforward but contains a fundamental flaw. The original approximation is a Taylor series truncated at the second order. This means any terms of third order or higher have been discarded. In the direct iteration, the state variable $k_t^{\\text{dir}}$ itself contains first- and second-order terms accumulated from previous periods. When this variable is squared in the term $\\frac{1}{2}H\\,(k_t^{\\text{dir}})^2$, spurious terms of third and fourth order are generated and fed back into the system. For instance, if one conceptually separates $k_t^{\\text{dir}}$ into its first-order component $k_t^{(1)}$ and second-order component $k_t^{(2)}$, then $(k_t^{\\text{dir}})^2 = (k_t^{(1)} + k_t^{(2)})^2 = (k_t^{(1)})^2 + 2k_t^{(1)}k_t^{(2)} + (k_t^{(2)})^2$. The term $2k_t^{(1)}k_t^{(2)}$ is of third order, and $(k_t^{(2)})^2$ is of fourth order. These terms are inconsistent with the original approximation and can accumulate, leading to explosive, non-stationary behavior that is an artifact of the simulation method, not a property of the model. This instability is most pronounced when the persistence parameter $h$ is close to $1$ and the quadratic feedback coefficient $H$ is large.\n\nThe second method, \"order-consistent simulation\" or \"pruned simulation,\" is designed explicitly to prevent this contamination by higher-order terms. It maintains the integrity of the second-order approximation at each step. This is achieved by separating the evolution of the first-order and second-order components of the solution.\nThe first-order component, $z_t$, follows the linear part of the model:\n$$\nz_{t+1} = h\\,z_t + r\\,\\sigma\\,\\varepsilon_{t+1}\n$$\nThe second-order correction, $w_{t+1}$, is computed using only the first-order state $z_t$ in the nonlinear terms:\n$$\nw_{t+1} = H\\,z_t^2 + M\\,(\\sigma\\,\\varepsilon_{t+1})^2 + 2\\,N\\,z_t\\,(\\sigma\\,\\varepsilon_{t+1})\n$$\nThe full second-order state is then assembled:\n$$\nk_{t+1}^{\\text{oc}} = z_{t+1} + \\frac{1}{2}w_{t+1}\n$$\nBy construction, this procedure ensures that no terms of order higher than two are ever introduced into the dynamics of $k_t^{\\text{oc}}$. The simulation path remains consistent with the underlying Taylor approximation, thereby providing a stable and theoretically correct trajectory, provided the original dynamic system is locally stable.\n\nThe task is to implement both simulation schemes for a given set of parameters $(h, r, H, M, N, \\sigma, T)$, using a fixed random seed $s = 2025$ to generate the same shock sequence $\\{\\varepsilon_t\\}_{t=1}^T$ for both simulations. A path is \"divergent\" if it becomes non-finite or its absolute value exceeds a bound $B = 10^6$. We must identify cases where direct iteration diverges while the order-consistent simulation remains bounded.\n\nThe algorithm proceeds as follows:\n$1$. Initialize the random number generator with the specified seed $s = 2025$.\n$2$. For each parameter set provided in the test suite:\n    a. Extract the parameters $h, r, H, M, N, \\sigma,$ and the horizon $T$.\n    b. Generate a sequence of $T$ standard normal random shocks. This sequence will be used for both simulations to ensure a fair comparison.\n    c. Perform the direct iteration simulation. Initialize $k_0^{\\text{dir}} = 0.0$. For each time step $t$ from $0$ to $T-1$, compute $k_{t+1}^{\\text{dir}}$. After each computation, check if `not isfinite`$(k_{t+1}^{\\text{dir}})$ or if $|k_{t+1}^{\\text{dir}}| > B$. If the condition is met, flag this path as divergent and terminate the simulation for this method.\n    d. Perform the order-consistent simulation. Initialize $z_0 = 0.0$. For each time step $t$ from $0$ to $T-1$, compute $z_{t+1}$, $w_{t+1}$, and subsequently $k_{t+1}^{\\text{oc}}$. Check for divergence using the same criterion as above. If divergence occurs, flag this path as divergent and terminate.\n    e. After both simulations are complete, evaluate the condition: is the direct path flagged as divergent AND the order-consistent path is NOT flagged as divergent? If true, the result for this test case is $1$. Otherwise, it is $0$.\n$3$. Collect the results for all test cases and format them into the specified output string.\nThis procedure will correctly diagnose the numerical instability inherent in the naive direct iteration method versus the robustness of the order-consistent approach.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by simulating two different perturbation methods and comparing their stability.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple contains: (h, r, H, M, N, sigma, T)\n    test_cases = [\n        (0.95, 0.8, 1.2, 0.8, 0.6, 0.6, 20000),  # Case A\n        (0.95, 0.8, 1.2, 0.8, 0.6, 0.0, 1000),   # Case B\n        (0.90, 0.3, 0.05, 0.02, 0.01, 0.2, 5000),  # Case C\n    ]\n\n    # Parameters for simulation.\n    seed = 2025\n    bound = 1e6\n\n    # Initialize the random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    results = []\n\n    for h, r, H, M, N, sigma, T in test_cases:\n        # Generate the same shock sequence for both simulations for a fair comparison.\n        shocks = rng.standard_normal(T)\n        \n        # --- Simulation 1: Direct Iteration ---\n        direct_diverged = False\n        k_dir = 0.0\n        for t in range(T):\n            eps = shocks[t]\n            sigma_eps = sigma * eps\n            \n            # Direct iteration formula\n            k_dir_next = (h * k_dir + r * sigma_eps +\n                          0.5 * H * k_dir**2 +\n                          0.5 * M * sigma_eps**2 +\n                          N * k_dir * sigma_eps)\n\n            # Check for divergence\n            if not np.isfinite(k_dir_next) or abs(k_dir_next) > bound:\n                direct_diverged = True\n                break\n            \n            k_dir = k_dir_next\n\n        # --- Simulation 2: Order-Consistent Iteration ---\n        oc_diverged = False\n        z = 0.0\n        for t in range(T):\n            eps = shocks[t]\n            sigma_eps = sigma * eps\n            \n            # First-order component\n            z_next = h * z + r * sigma_eps\n            \n            # Second-order correction\n            w_next = H * z**2 + M * sigma_eps**2 + 2 * N * z * sigma_eps\n            \n            # Assembled state\n            k_oc_next = z_next + 0.5 * w_next\n            \n            # Check for divergence\n            if not np.isfinite(k_oc_next) or abs(k_oc_next) > bound:\n                oc_diverged = True\n                break\n            \n            z = z_next\n            \n        # --- Evaluate the condition ---\n        # Output 1 if direct diverges and order-consistent remains bounded; otherwise 0.\n        if direct_diverged and not oc_diverged:\n            results.append(1)\n        else:\n            results.append(0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"}]}