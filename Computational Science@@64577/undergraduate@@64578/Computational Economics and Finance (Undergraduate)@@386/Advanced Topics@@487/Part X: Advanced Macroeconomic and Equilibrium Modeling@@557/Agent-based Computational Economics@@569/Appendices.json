{"hands_on_practices": [{"introduction": "This first exercise grounds us in the fundamentals of agent-based modeling: defining an agent's environment and its decision-making process. We will model a supply chain network where buyers must choose suppliers based on a utility function that balances price, reliability, and network distance [@problem_id:2370582]. This practice provides a concrete application of utility maximization and demonstrates how to integrate graph theory algorithms, like shortest-path finding, to quantify spatial or network-based costs in economic decisions.", "id": "2370582", "problem": "Consider a system in Agent-Based Computational Economics (ACE) where two types of agents, buyers and suppliers, are embedded as nodes in a directed graph. Let there be $N$ buyers and $M$ suppliers. Index buyers by $i \\in \\{0,1,\\dots,N-1\\}$ and suppliers by local indices $j \\in \\{0,1,\\dots,M-1\\}$, which correspond to global node indices $N+j$. The directed graph is given by a set of nodes $V = \\{0,1,\\dots,N+M-1\\}$ and directed edges $E \\subseteq V \\times V$. An edge $(u,v) \\in E$ means there is a directed link from node $u$ to node $v$.\n\nEach supplier $j$ has a price $p_j \\in \\mathbb{R}$ and a reliability $r_j \\in [0,1]$. Each buyer $i$ can choose at most one supplier $j$. The buyer’s utility from choosing supplier $j$ is defined as\n$$\nU_{ij} = -\\alpha \\, p_j + \\beta \\, r_j - \\gamma \\, d(i,N+j),\n$$\nwhere $\\alpha > 0$, $\\beta > 0$, $\\gamma > 0$ are fixed weights, and $d(i,N+j)$ is the length (counted in the number of edges) of the shortest directed path from buyer node $i$ to supplier node $N+j$ in the graph. If no directed path exists, define $d(i,N+j) = +\\infty$ and, by convention, $U_{ij} = -\\infty$. Each buyer $i$ is assumed to be a deterministic utility maximizer. Ties are broken by selecting the smallest-index supplier $j$. If all suppliers are infeasible for buyer $i$ (no paths), the buyer chooses nothing, which must be represented by the integer $-1$.\n\nYour task is to implement a program that, for a given set of test cases, computes for each buyer the chosen supplier index $j \\in \\{0,1,\\dots,M-1\\}$ following the rule above, or $-1$ if none is reachable.\n\nFundamental base for this problem includes the definition of utility maximization in microeconomics, the definition of a directed graph and shortest path distance, and the assumption that agents choose actions that maximize their utility.\n\nTest suite. Use the following four test cases, which cover a general case, infeasibility, tie-breaking, and a case where network distance differentials drive the choices. For each test, all variables are specified precisely.\n\n- Test $1$:\n  - $N = 3$, $M = 2$. Buyers: $\\{0,1,2\\}$. Suppliers: $\\{3,4\\}$.\n  - Directed edges $E = \\{(0,3),(0,1),(1,4),(2,1),(1,2),(2,3)\\}$.\n  - Prices $p = (10,12)$, reliabilities $r = (0.9,0.95)$.\n  - Weights $(\\alpha,\\beta,\\gamma) = (1,2,0.5)$.\n\n- Test $2$:\n  - $N = 2$, $M = 2$. Buyers: $\\{0,1\\}$. Suppliers: $\\{2,3\\}$.\n  - Directed edges $E = \\{(0,2)\\}$.\n  - Prices $p = (5,1)$, reliabilities $r = (0.5,0.9)$.\n  - Weights $(\\alpha,\\beta,\\gamma) = (1,1,1)$.\n\n- Test $3$:\n  - $N = 1$, $M = 3$. Buyer: $\\{0\\}$. Suppliers: $\\{1,2,3\\}$.\n  - Directed edges $E = \\{(0,1),(0,2),(0,3)\\}$.\n  - Prices $p = (2,2,2)$, reliabilities $r = (0.8,0.8,0.8)$.\n  - Weights $(\\alpha,\\beta,\\gamma) = (1,1,0.2)$.\n\n- Test $4$:\n  - $N = 2$, $M = 2$. Buyers: $\\{0,1\\}$. Suppliers: $\\{2,3\\}$.\n  - Directed edges $E = \\{(0,1),(1,2),(0,3)\\}$.\n  - Prices $p = (9,8)$, reliabilities $r = (0.9,0.9)$.\n  - Weights $(\\alpha,\\beta,\\gamma) = (1,1,1)$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets. Each inner list corresponds to one test case and contains the chosen supplier indices for all buyers, ordered by buyer index, with $-1$ indicating no feasible supplier. For example, a valid output format is $[[\\dots],[\\dots],[\\dots],[\\dots]]$ with no extra text.", "solution": "We model the formation of a buyer–supplier network in Agent-Based Computational Economics (ACE) using utility-maximizing agents on a directed graph. The fundamental elements are: (i) utility maximization from microeconomics, (ii) shortest path distance in a directed graph, and (iii) a deterministic tie-breaking rule ensuring a unique choice when utilities are equal.\n\n1. Utility-based choice. By assumption, each buyer $i$ evaluates every supplier $j \\in \\{0,1,\\dots,M-1\\}$ according to\n$$\nU_{ij} = -\\alpha \\, p_j + \\beta \\, r_j - \\gamma \\, d(i,N+j),\n$$\nwhere $p_j$ and $r_j$ are supplier attributes, and $d(i,N+j)$ is the shortest path distance in the directed graph. This is a linear additively separable utility in observed attributes with positive weights $\\alpha,\\beta,\\gamma$ reflecting marginal effects. If there is no path from $i$ to $N+j$, then $d(i,N+j)=+\\infty$ and we set $U_{ij}=-\\infty$, making such suppliers infeasible. Each buyer chooses the supplier $j$ that maximizes $U_{ij}$. If several suppliers tie for the maximum, the smallest index $j$ is selected. If all are infeasible, the buyer chooses none, represented by $-1$.\n\n2. Shortest path computation. On a directed graph with node set $V=\\{0,1,\\dots,N+M-1\\}$ and edge set $E\\subseteq V\\times V$, the shortest path distance $d(u,v)$ is defined as the minimum number of directed edges along any path from $u$ to $v$. Since all edges have unit length in this model, breadth-first search (BFS) starting from node $u$ computes $d(u,\\cdot)$ in $\\mathcal{O}(|V|+|E|)$. If BFS never reaches $v$, then $d(u,v)=+\\infty$.\n\n3. Algorithm. For each test case: for each buyer $i$, run BFS to obtain $d(i,\\cdot)$ and extract $d(i,N+j)$ for all suppliers $j$. Compute $U_{ij}$ for all feasible $j$ and pick the maximizing $j$ (breaking ties by smallest $j$). If all $U_{ij}=-\\infty$, return $-1$ for that buyer. Aggregate the choices per test case.\n\nWe now apply this to the four specified tests, computing distances and utilities.\n\nTest $1$: $N=3$, $M=2$, buyers $\\{0,1,2\\}$, suppliers $\\{3,4\\}$, edges $E=\\{(0,3),(0,1),(1,4),(2,1),(1,2),(2,3)\\}$, prices $p=(10,12)$, reliabilities $r=(0.9,0.95)$, weights $(\\alpha,\\beta,\\gamma)=(1,2,0.5)$.\n\n- Distances from buyer $0$: $d(0,3)=1$ (edge $(0,3)$), $d(0,4)=2$ (path $0 \\to 1 \\to 4$).\n- Distances from buyer $1$: $d(1,3)=2$ (path $1 \\to 2 \\to 3$), $d(1,4)=1$ (edge $(1,4)$).\n- Distances from buyer $2$: $d(2,3)=1$ (edge $(2,3)$), $d(2,4)=2$ (path $2 \\to 1 \\to 4$).\n\nUtilities:\n- Buyer $0$: $U_{0,0}=-1\\cdot 10+2\\cdot 0.9-0.5\\cdot 1=-10+1.8-0.5=-8.7$, $U_{0,1}=-1\\cdot 12+2\\cdot 0.95-0.5\\cdot 2=-12+1.9-1=-11.1$. Choose $j=0$.\n- Buyer $1$: $U_{1,0}=-10+1.8-1=-9.2$, $U_{1,1}=-12+1.9-0.5=-10.6$. Choose $j=0$.\n- Buyer $2$: $U_{2,0}=-10+1.8-0.5=-8.7$, $U_{2,1}=-12+1.9-1=-11.1$. Choose $j=0$.\n\nResult for Test $1$: $[0,0,0]$.\n\nTest $2$: $N=2$, $M=2$, buyers $\\{0,1\\}$, suppliers $\\{2,3\\}$, edges $E=\\{(0,2)\\}$, prices $p=(5,1)$, reliabilities $r=(0.5,0.9)$, weights $(1,1,1)$.\n\n- Distances from buyer $0$: $d(0,2)=1$, $d(0,3)=+\\infty$ (no path).\n- Distances from buyer $1$: $d(1,2)=+\\infty$, $d(1,3)=+\\infty$ (no outgoing edges from $1$ and no incoming paths).\n\nUtilities:\n- Buyer $0$: $U_{0,0}=-1\\cdot 5+1\\cdot 0.5-1\\cdot 1=-5+0.5-1=-5.5$, $U_{0,1}=-\\infty$. Choose $j=0$.\n- Buyer $1$: both infeasible, choose $-1$.\n\nResult for Test $2$: $[0,-1]$.\n\nTest $3$: $N=1$, $M=3$, buyer $\\{0\\}$, suppliers $\\{1,2,3\\}$, edges $E=\\{(0,1),(0,2),(0,3)\\}$, prices $p=(2,2,2)$, reliabilities $r=(0.8,0.8,0.8)$, weights $(1,1,0.2)$.\n\n- Distances: $d(0,1)=1$, $d(0,2)=1$, $d(0,3)=1$.\n- Utilities: for each $j \\in \\{0,1,2\\}$, $U_{0,j}=-1\\cdot 2+1\\cdot 0.8-0.2\\cdot 1=-2+0.8-0.2=-1.4$; exact tie among all suppliers. By rule, choose the smallest $j=0$.\n\nResult for Test $3$: $[0]$.\n\nTest $4$: $N=2$, $M=2$, buyers $\\{0,1\\}$, suppliers $\\{2,3\\}$, edges $E=\\{(0,1),(1,2),(0,3)\\}$, prices $p=(9,8)$, reliabilities $r=(0.9,0.9)$, weights $(1,1,1)$.\n\n- Distances from buyer $0$: $d(0,2)=2$ (path $0 \\to 1 \\to 2$), $d(0,3)=1$ (edge $0 \\to 3$).\n- Distances from buyer $1$: $d(1,2)=1$ (edge $1 \\to 2$), $d(1,3)=+\\infty$ (no path).\n- Utilities:\n  - Buyer $0$: $U_{0,0}=-1\\cdot 9+1\\cdot 0.9-1\\cdot 2=-9+0.9-2=-10.1$, $U_{0,1}=-1\\cdot 8+1\\cdot 0.9-1\\cdot 1=-8+0.9-1=-8.1$. Choose $j=1$.\n  - Buyer $1$: $U_{1,0}=-9+0.9-1=-9.1$, $U_{1,1}=-\\infty$. Choose $j=0$.\n\nResult for Test $4$: $[1,0]$.\n\nCollecting the results in order of the tests, the overall output is the single line list of lists\n$$\n[[0,0,0],[0,-1],[0],[1,0]].\n$$\nThis corresponds exactly to applying utility maximization with graph-based distance costs, enforcing feasibility and deterministic tie-breaking, and is consistent with rational agent choice on a directed network.", "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef bfs_shortest_distances(num_nodes, edges, start):\n    \"\"\"\n    Compute shortest path distances (in number of edges) from 'start' to all nodes\n    in a directed graph with 'num_nodes' nodes and a list of directed 'edges'.\n    Returns a list of distances where unreachable nodes have value None.\n    \"\"\"\n    adj = [[] for _ in range(num_nodes)]\n    for u, v in edges:\n        adj[u].append(v)\n    dist = [None] * num_nodes\n    q = deque()\n    dist[start] = 0\n    q.append(start)\n    while q:\n        u = q.popleft()\n        for v in adj[u]:\n            if dist[v] is None:\n                dist[v] = dist[u] + 1\n                q.append(v)\n    return dist\n\ndef choose_suppliers(N, M, edges, prices, reliabilities, alpha, beta, gamma):\n    \"\"\"\n    For given graph and supplier attributes, compute chosen supplier index per buyer.\n    Buyers are nodes 0..N-1, suppliers are nodes N..N+M-1 mapping from local j=0..M-1 to global N+j.\n    Returns a list of length N with chosen supplier indices in local indexing, or -1 if none reachable.\n    \"\"\"\n    num_nodes = N + M\n    results = []\n    for i in range(N):\n        dist = bfs_shortest_distances(num_nodes, edges, i)\n        best_j = -1\n        best_u = float('-inf')\n        for j in range(M):\n            gnode = N + j\n            d = dist[gnode]\n            if d is None:\n                u = float('-inf')\n            else:\n                u = -alpha * prices[j] + beta * reliabilities[j] - gamma * d\n            if u > best_u or (u == best_u and u != float('-inf') and j < best_j):\n                best_u = u\n                best_j = j if u != float('-inf') else best_j\n        # If best_u remains -inf, best_j may be -1 as initialized\n        results.append(best_j if best_u != float('-inf') else -1)\n    return results\n\ndef solve():\n    # Define the test cases as specified in the problem statement.\n    test_cases = [\n        {\n            \"N\": 3,\n            \"M\": 2,\n            \"edges\": [(0,3),(0,1),(1,4),(2,1),(1,2),(2,3)],\n            \"prices\": [10.0, 12.0],\n            \"reliabilities\": [0.9, 0.95],\n            \"alpha\": 1.0, \"beta\": 2.0, \"gamma\": 0.5\n        },\n        {\n            \"N\": 2,\n            \"M\": 2,\n            \"edges\": [(0,2)],\n            \"prices\": [5.0, 1.0],\n            \"reliabilities\": [0.5, 0.9],\n            \"alpha\": 1.0, \"beta\": 1.0, \"gamma\": 1.0\n        },\n        {\n            \"N\": 1,\n            \"M\": 3,\n            \"edges\": [(0,1),(0,2),(0,3)],\n            \"prices\": [2.0, 2.0, 2.0],\n            \"reliabilities\": [0.8, 0.8, 0.8],\n            \"alpha\": 1.0, \"beta\": 1.0, \"gamma\": 0.2\n        },\n        {\n            \"N\": 2,\n            \"M\": 2,\n            \"edges\": [(0,1),(1,2),(0,3)],\n            \"prices\": [9.0, 8.0],\n            \"reliabilities\": [0.9, 0.9],\n            \"alpha\": 1.0, \"beta\": 1.0, \"gamma\": 1.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        M = case[\"M\"]\n        edges = case[\"edges\"]\n        prices = case[\"prices\"]\n        reliabilities = case[\"reliabilities\"]\n        alpha = case[\"alpha\"]\n        beta = case[\"beta\"]\n        gamma = case[\"gamma\"]\n        choice = choose_suppliers(N, M, edges, prices, reliabilities, alpha, beta, gamma)\n        results.append(choice)\n\n    # Build exact required output format: a single line \"[[...],[...],...]\"\n    inner_lists = []\n    for lst in results:\n        inner = \"[\" + \",\".join(str(x) for x in lst) + \"]\"\n        inner_lists.append(inner)\n    print(\"[\" + \",\".join(inner_lists) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"}, {"introduction": "Moving from static individual choices to dynamic strategic interactions, this practice explores the \"tragedy of the anti-commons.\" You will simulate a scenario where multiple agents, each holding exclusion rights over a resource, set access prices that collectively lead to its underutilization [@problem_id:2370580]. This hands-on problem demonstrates how to model game-theoretic situations and use iterative best-response dynamics to compute the system's Nash Equilibrium, a foundational concept in understanding strategic interdependencies.", "id": "2370580", "problem": "Consider an agent-based environment that captures the \"tragedy of the anti-commons\" in which multiple agents have rights of exclusion over a single resource. There are $N$ exclusion-rights holders (agents) indexed by $i \\in \\{1,\\dots,N\\}$. In each notional period, a representative user values the resource at a random amount $V$ drawn independently from a uniform distribution on $[0,1]$. The user can access the resource only if she can cover the sum of the agents' access prices and a per-agent transaction friction cost. The friction cost is non-negative and denoted by $\\kappa \\ge 0$; it is borne by the user and does not accrue to agents.\n\nFundamental base:\n- Expected demand equals the probability that the willingness-to-pay exceeds the total burden. Under $V \\sim \\mathrm{Uniform}[0,1]$, the demand function is $D(P) = \\mathbb{P}(V \\ge P) = \\max(1 - P, 0)$ for total burden $P \\in [0,1]$ and $D(P)=0$ for $P \\ge 1$.\n- Each agent posts a nonnegative access price $p_i \\ge 0$. Let $P_{\\text{prices}} \\equiv \\sum_{i=1}^N p_i$ and $P_{\\text{total}} \\equiv P_{\\text{prices}} + N\\kappa$.\n\nAgent-based price update rule:\n- Agents are myopic revenue maximizers who take others' current prices as given and update via relaxed best responses. Given others' prices, agent $i$ chooses $p_i$ to maximize its expected revenue $p_i \\cdot D\\big(P_{\\text{total}}\\big)$, where $P_{\\text{total}} = N\\kappa + p_i + \\sum_{j \\ne i} p_j$. With relaxation parameter $\\beta \\in (0,1]$, the update is $p_i \\leftarrow (1-\\beta)\\,p_i + \\beta \\cdot \\arg\\max_{p \\ge 0}\\; p \\cdot D\\!\\left(N\\kappa + p + \\sum_{j \\ne i} p_j\\right)$.\n- The process iterates sequentially over agents until convergence.\n\nYour task:\n1. Implement a simulation of the above agent-based learning dynamics. Start from $p_i = 0$ for all $i$.\n2. In each iteration (a sweep over agents), update each agent's price once using the relaxed best-response rule.\n3. Stop when the maximum absolute change across all $p_i$ within a sweep is below a given tolerance $\\varepsilon$, or when a maximum number of iterations is reached.\n4. After stopping, compute:\n   - The long-run utilization rate $u \\equiv D(P_{\\text{total}}) = \\max(1 - P_{\\text{total}}, 0)$. Report $u$ as a decimal (not a percentage).\n   - The unconditional mean realized revenue $R \\equiv u \\cdot P_{\\text{prices}}$ (this is the total payment received by agents averaged over periods, counting zero when no access occurs).\n\nNumerical and algorithmic details to enforce:\n- Use $D(P) = \\max(1 - P, 0)$.\n- Use the exact best response for the scalar concave problem in the update rule. Do not discretize the price space.\n- Use a convergence tolerance $\\varepsilon$ and a maximum iteration cap $\\text{max\\_iter}$.\n- Round $u$ and $R$ to $6$ decimal places in the final reported output.\n- If $P_{\\text{total}} \\ge 1$, then $u = 0$ and $R = 0$ by definition.\n\nTest suite:\nRun your program on the following parameter sets $(N,\\kappa,\\beta,\\varepsilon,\\text{max\\_iter})$:\n- Case $1$: $(N=\\;1,\\;\\kappa=\\;0.0,\\;\\beta=\\;1.0,\\;\\varepsilon=\\;10^{-12},\\;\\text{max\\_iter}=\\;10000)$.\n- Case $2$: $(N=\\;2,\\;\\kappa=\\;0.0,\\;\\beta=\\;1.0,\\;\\varepsilon=\\;10^{-12},\\;\\text{max\\_iter}=\\;10000)$.\n- Case $3$: $(N=\\;5,\\;\\kappa=\\;0.05,\\;\\beta=\\;1.0,\\;\\varepsilon=\\;10^{-12},\\;\\text{max\\_iter}=\\;10000)$.\n- Case $4$: $(N=\\;10,\\;\\kappa=\\;0.10,\\;\\beta=\\;1.0,\\;\\varepsilon=\\;10^{-12},\\;\\text{max\\_iter}=\\;10000)$.\n- Case $5$: $(N=\\;12,\\;\\kappa=\\;0.10,\\;\\beta=\\;1.0,\\;\\varepsilon=\\;10^{-12},\\;\\text{max\\_iter}=\\;10000)$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results for the five cases as a comma-separated list enclosed in square brackets, where each case's result is itself a two-element list $[u,R]$ with both entries rounded to $6$ decimals. For example, the overall format must look like:\n\"[[u_1,R_1],[u_2,R_2],[u_3,R_3],[u_4,R_4],[u_5,R_5]]\"\nwith no additional text before or after.", "solution": "The problem presented is a well-posed exercise in agent-based computational economics, specifically modeling the \"tragedy of the anti-commons\". The model is scientifically grounded and internally consistent, permitting a direct computational solution. We shall first derive the agent's optimal behavior and then describe the simulation algorithm to find the equilibrium of the system.\n\nThe core of the problem lies in determining the best-response function for each agent. An agent $i$ seeks to choose its price $p_i \\ge 0$ to maximize its own expected revenue, $\\pi_i$, given the prices of all other agents, $\\mathbf{p}_{-i} = \\{p_j\\}_{j \\ne i}$. The agent is myopic, meaning it does not consider the future reactions of other agents to its current price choice.\n\nThe agent's revenue is the product of its price and the probability that a user purchases access. The user's total cost, or burden, is the sum of all prices plus the total transaction friction: $P_{\\text{total}} = \\sum_{j=1}^N p_j + N\\kappa$. Let $S_{-i} = \\sum_{j \\ne i} p_j$ be the sum of prices set by all other agents. The total burden can then be written from agent $i$'s perspective as $P_{\\text{total}} = p_i + S_{-i} + N\\kappa$.\n\nThe demand function is given by the probability that the user's valuation $V$, drawn from a $\\mathrm{Uniform}[0,1]$ distribution, exceeds the total burden: $D(P_{\\text{total}}) = \\mathbb{P}(V \\ge P_{\\text{total}}) = \\max(0, 1 - P_{\\text{total}})$.\n\nAgent $i$'s optimization problem is thus:\n$$ \\max_{p_i \\ge 0} \\pi_i(p_i) = p_i \\cdot D(p_i + S_{-i} + N\\kappa) $$\n$$ \\max_{p_i \\ge 0} \\pi_i(p_i) = p_i \\cdot \\max(0, 1 - (p_i + S_{-i} + N\\kappa)) $$\n\nLet us analyze this objective function. If the fixed part of the cost, $S_{-i} + N\\kappa$, is greater than or equal to $1$, then for any $p_i > 0$, the total burden $P_{\\text{total}}$ will be strictly greater than $1$. This results in zero demand, $D(P_{\\text{total}}) = 0$, and thus zero revenue, $\\pi_i = 0$. If $p_i = 0$, revenue is also $0$. Therefore, if $S_{-i} + N\\kappa \\ge 1$, any non-negative price $p_i$ yields zero revenue, and the best response is simply $p_i = 0$.\n\nNow, consider the case where $S_{-i} + N\\kappa < 1$. For the demand to be positive, we must have $p_i + S_{-i} + N\\kappa < 1$, which implies $p_i < 1 - S_{-i} - N\\kappa$. In this range, the objective function is:\n$$ \\pi_i(p_i) = p_i (1 - S_{-i} - N\\kappa - p_i) $$\nThis is a quadratic function of $p_i$, representing a downward-opening parabola: $\\pi_i(p_i) = -p_i^2 + (1 - S_{-i} - N\\kappa)p_i$. The maximizer of this function can be found by setting its derivative with respect to $p_i$ to zero:\n$$ \\frac{\\partial \\pi_i}{\\partial p_i} = 1 - S_{-i} - N\\kappa - 2p_i = 0 $$\nSolving for $p_i$ yields the unconstrained optimal price:\n$$ p_i^* = \\frac{1 - S_{-i} - N\\kappa}{2} $$\nSince we are in the case where $1 - S_{-i} - N\\kappa > 0$, this price $p_i^*$ is positive. This unconstrained maximum is the solution as long as it satisfies the non-negativity constraint $p_i \\ge 0$, which it does.\n\nCombining both cases, the best-response function, $\\mathrm{BR}_i(\\mathbf{p}_{-i})$, which gives agent $i$'s optimal price given the others' prices, is:\n$$ \\mathrm{BR}_i(\\mathbf{p}_{-i}) = \\max\\left(0, \\frac{1 - N\\kappa - \\sum_{j \\ne i} p_j}{2}\\right) $$\nThis expression provides the exact best response required by the problem statement.\n\nThe simulation implements an iterative process to find the Nash Equilibrium of this pricing game. The state of the system at any time is the vector of prices $\\mathbf{p} = (p_1, \\dots, p_N)$. The process starts with initial prices $p_i = 0$ for all $i \\in \\{1, \\dots, N\\}$.\n\nIn each iteration, or sweep, the agents update their prices sequentially. For an agent $i$, the new price $p_i'$ is calculated using the relaxed best-response rule:\n$$ p_i' = (1-\\beta)p_i + \\beta \\cdot \\mathrm{BR}_i(\\mathbf{p}_{-i}) $$\nHere, $p_i$ is the agent's price from the previous iteration, and $\\mathbf{p}_{-i}$ contains the most recently updated prices of agents $j<i$ and the previous-iteration prices of agents $j>i$. This is a Gauss-Seidel type update scheme. The relaxation parameter $\\beta \\in (0,1]$ controls the step size towards the best response. For $\\beta = 1$, the agent fully adopts the new best-response price.\n\nThe simulation proceeds for a maximum of $\\text{max\\_iter}$ iterations. It terminates earlier if the prices converge. Convergence is achieved when the maximum absolute change in any agent's price during a full sweep is less than a specified tolerance $\\varepsilon$:\n$$ \\max_{i \\in \\{1,\\dots,N\\}} |p_i' - p_i| < \\varepsilon $$\n\nUpon termination, let the final price vector be $\\mathbf{p}^{\\text{final}}$. The aggregate metrics are computed as follows:\n1.  The final sum of prices is $P_{\\text{prices}} = \\sum_{i=1}^N p_i^{\\text{final}}$.\n2.  The final total burden is $P_{\\text{total}} = P_{\\text{prices}} + N\\kappa$.\n3.  The long-run utilization rate is $u = D(P_{\\text{total}}) = \\max(0, 1 - P_{\\text{total}})$.\n4.  The unconditional mean realized revenue is $R = u \\cdot P_{\\text{prices}}$.\n\nThe results for $u$ and $R$ are then rounded to $6$ decimal places as required. The provided code implements this logic for each of the specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate(N, kappa, beta, epsilon, max_iter):\n    \"\"\"\n    Simulates the agent-based price setting in an anti-commons environment.\n\n    Args:\n        N (int): Number of agents.\n        kappa (float): Per-agent transaction friction cost.\n        beta (float): Relaxation parameter for price updates.\n        epsilon (float): Convergence tolerance.\n        max_iter (int): Maximum number of iterations.\n\n    Returns:\n        tuple: A tuple containing the utilization rate (u) and total revenue (R).\n    \"\"\"\n    # Initialize prices p_i = 0 for all i.\n    prices = np.zeros(N, dtype=np.float64)\n    \n    for iteration in range(max_iter):\n        old_prices = prices.copy()\n        max_change = 0.0\n        \n        # Sequentially update each agent's price.\n        for i in range(N):\n            # Sum of other agents' prices. This uses updated prices for j < i\n            # and old prices for j > i, which is a Gauss-Seidel update.\n            S_minus_i = np.sum(prices) - prices[i]\n            \n            # Calculate the best response for agent i.\n            numerator = 1.0 - N * kappa - S_minus_i\n            best_response = max(0.0, numerator / 2.0)\n            \n            # Apply the relaxed best-response update rule.\n            new_price = (1.0 - beta) * prices[i] + beta * best_response\n            \n            # Update the agent's price in the vector for the current iteration.\n            prices[i] = new_price\n            \n        # Check for convergence after a full sweep over all agents.\n        # The problem asks for checking convergence based on changes within a sweep.\n        # old_prices store the state before the sweep, prices store state after.\n        max_change = np.max(np.abs(prices - old_prices))\n        \n        if max_change < epsilon:\n            break\n            \n    # Calculate final metrics after convergence or max iterations.\n    P_prices = np.sum(prices)\n    P_total = P_prices + N * kappa\n    \n    # Utilization rate u\n    u = max(0.0, 1.0 - P_total)\n    \n    # Mean realized revenue R\n    R = u * P_prices\n    \n    return u, R\n\ndef solve():\n    \"\"\"\n    Runs the simulation for all test cases and prints the results in the required format.\n    \"\"\"\n    # Test suite: (N, kappa, beta, epsilon, max_iter)\n    test_cases = [\n        (1, 0.0, 1.0, 1e-12, 10000),   # Case 1\n        (2, 0.0, 1.0, 1e-12, 10000),   # Case 2\n        (5, 0.05, 1.0, 1e-12, 10000),  # Case 3\n        (10, 0.10, 1.0, 1e-12, 10000), # Case 4\n        (12, 0.10, 1.0, 1e-12, 10000)  # Case 5\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N, kappa, beta, epsilon, max_iter = case\n        u, R = simulate(N, kappa, beta, epsilon, max_iter)\n        \n        # Round final results to 6 decimal places.\n        u_rounded = round(u, 6)\n        R_rounded = round(R, 6)\n        \n        all_results.append(f\"[{u_rounded},{R_rounded}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n\n```"}, {"introduction": "Our final practice delves into the core of what makes agent-based economics a unique paradigm: bounded rationality and emergent phenomena. We will implement a variation of the classic \"El Farol Bar\" problem, where agents use reinforcement learning to decide whether to attend a venue with limited capacity, now with the added complexity of coordinating coalitions [@problem_id:2370498]. This simulation illustrates how simple, adaptive learning rules at the individual level can generate complex, system-wide attendance patterns, and how communication structures can fundamentally alter these emergent outcomes.", "id": "2370498", "problem": "You are asked to implement and analyze an agent-based model of the El Farol Bar problem in which agents may be organized into coalitions that can coordinate their actions with a given probability of successful intra-coalition communication. The model must be simulated for a fixed number of discrete periods, with well-defined agent behavior, coalition activation, and payoff-based learning. All randomness must be made reproducible by explicit seeding of the pseudo-random number generator.\n\nModel definition:\n- There are $N$ agents indexed by $i \\in \\{0,1,\\dots,N-1\\}$ and a bar with capacity $C \\in \\mathbb{N}$. Time proceeds in discrete periods $t=0,1,\\dots,T-1$.\n- Each agent $i$ chooses an action $a_i(t) \\in \\{0,1\\}$ each period, where $a_i(t)=1$ denotes attending and $a_i(t)=0$ denotes staying home. Let the aggregate attendance be $A(t)=\\sum_{i=0}^{N-1} a_i(t)$.\n- Agents are partitioned exogenously into disjoint coalitions $g \\in \\mathcal{G}$ that form a complete partition of the agent set. A coalition $g$ has size $|g| \\ge 1$. Coalitions with $|g|=1$ are singletons. For each coalition $g$ with $|g| \\ge 2$, define its quota $q_g = \\left\\lfloor C \\cdot \\frac{|g|}{N} \\right\\rfloor$. For singletons with $|g|=1$, no coordination is ever performed and no quota is applied.\n- Each agent $i$ maintains two attractions (propensities), $A_i^{\\text{att}}(t)$ for attending and $A_i^{\\text{stay}}(t)$ for staying, initialized at $A_i^{\\text{att}}(0)=0$ and $A_i^{\\text{stay}}(0)=0$. Define parameters $\\rho \\in (0,1)$ (recency) and $\\lambda > 0$ (learning step size).\n- Private intention phase: At the beginning of each period $t$, each agent forms a private intention $b_i(t) \\in \\{0,1\\}$ based on the attractions: if $A_i^{\\text{att}}(t) > A_i^{\\text{stay}}(t)$ then $b_i(t)=1$, if $A_i^{\\text{att}}(t) < A_i^{\\text{stay}}(t)$ then $b_i(t)=0$, and if $A_i^{\\text{att}}(t)=A_i^{\\text{stay}}(t)$ then $b_i(t)$ is chosen as a fair Bernoulli coin flip. Ties and all coin flips must use the specified pseudo-random generator and seed for reproducibility.\n- Coalition activation and coordination: For each coalition $g$ with $|g|\\ge 2$, an independent Bernoulli trial with success probability $p_{\\text{comm}} \\in [0,1]$ determines whether $g$ is active at period $t$. If inactive, all members take their private intentions as final actions. If active at period $t$, the coalition observes the vector of private intentions $\\{b_i(t): i \\in g\\}$ and applies the following downward-adjustment rule to produce the final actions $\\{a_i(t): i \\in g\\}$:\n  1. Let $S_g(t)=\\sum_{i \\in g} b_i(t)$ be the number of members intending to attend.\n  2. If $S_g(t) \\le q_g$, then $a_i(t)=b_i(t)$ for all $i \\in g$.\n  3. If $S_g(t) > q_g$, then among the subset $\\{i \\in g: b_i(t)=1\\}$, select exactly $q_g$ members to attend, choosing those with the largest values of $\\Delta_i(t)=A_i^{\\text{att}}(t)-A_i^{\\text{stay}}(t)$; ties in $\\Delta_i(t)$ are broken by choosing the smaller agent index first. Set $a_i(t)=1$ for the selected $q_g$ members and $a_i(t)=0$ for the remaining members of this subset. For agents with $b_i(t)=0$, set $a_i(t)=0$.\n- For any singleton coalition $g$ with $|g|=1$, the final action is $a_i(t)=b_i(t)$ for its sole member $i$.\n- Payoff and learning: After all coalitions resolve, aggregate attendance $A(t)=\\sum_i a_i(t)$ is realized. Each agent’s period payoff $u_i(t)$ is\n  $$u_i(t)=\\begin{cases}\n  1 & \\text{if } a_i(t)=1 \\text{ and } A(t) \\le C,\\\\\n  1 & \\text{if } a_i(t)=0 \\text{ and } A(t) > C,\\\\\n  0 & \\text{otherwise.}\n  \\end{cases}$$\n  Attractions update as follows:\n  $$A_i^{\\text{att}}(t+1)=\\begin{cases}\n  (1-\\rho)\\,A_i^{\\text{att}}(t) + \\lambda\\,u_i(t) & \\text{if } a_i(t)=1,\\\\\n  (1-\\rho)\\,A_i^{\\text{att}}(t) & \\text{if } a_i(t)=0,\n  \\end{cases}$$\n  $$A_i^{\\text{stay}}(t+1)=\\begin{cases}\n  (1-\\rho)\\,A_i^{\\text{stay}}(t) + \\lambda\\,u_i(t) & \\text{if } a_i(t)=0,\\\\\n  (1-\\rho)\\,A_i^{\\text{stay}}(t) & \\text{if } a_i(t)=1.\n  \\end{cases}$$\n\nMeasurement definitions:\n- For a given horizon $T$ and a tail window length $H$ with $1 \\le H \\le T$, define the trailing averages over periods $t \\in \\{T-H, T-H+1, \\dots, T-1\\}$:\n  1. The mean attendance gap $\\bar{G} = \\frac{1}{H}\\sum_{t=T-H}^{T-1} \\left( A(t) - C \\right)$.\n  2. The overcrowding frequency $\\bar{O} = \\frac{1}{H}\\sum_{t=T-H}^{T-1} \\mathbf{1}\\{A(t) > C\\}$, expressed as a decimal in $[0,1]$.\n  3. The average per-period coordination flip share $\\bar{F} = \\frac{1}{H}\\sum_{t=T-H}^{T-1} \\left( \\frac{1}{N} \\sum_{i=0}^{N-1} \\mathbf{1}\\{a_i(t) \\ne b_i(t)\\} \\right)$, i.e., the average fraction of agents whose final action differs from their private intention due to coalition coordination.\n\nRandomness and reproducibility:\n- All randomness, including tie-breaking in intentions and coalition activation, must be generated by a pseudo-random number generator seeded as specified for each test case. Use the given seed exactly as the initialization seed for the random number generator in that test case.\n\nTest suite:\nImplement the simulation and compute $(\\bar{G},\\bar{O},\\bar{F})$ for each of the following four parameter sets. In each case, report the results computed over the last $H$ periods, in the order specified.\n\n- Case $1$: $N=51$, $C=25$, $T=2000$, $H=500$, $\\rho=0.01$, $\\lambda=0.2$, coalition sizes given by the list with $51$ entries all equal to $1$ (every agent is a singleton), $p_{\\text{comm}}=0.5$, seed $=42$.\n- Case $2$: $N=51$, $C=25$, $T=2000$, $H=500$, $\\rho=0.01$, $\\lambda=0.2$, coalition sizes given by the list $[3,3,3,3,3,3,3,30]$ (in order of increasing agent index), $p_{\\text{comm}}=1.0$, seed $=43$.\n- Case $3$: $N=51$, $C=25$, $T=2000$, $H=500$, $\\rho=0.01$, $\\lambda=0.2$, coalition sizes given by the list $[3,3,3,3,3,3,3,30]$, $p_{\\text{comm}}=0.0$, seed $=44$.\n- Case $4$: $N=51$, $C=25$, $T=2000$, $H=500$, $\\rho=0.01$, $\\lambda=0.2$, coalition sizes given by the list with ten entries equal to $5$ followed by one entry equal to $1$ (i.e., $[5,5,5,5,5,5,5,5,5,5,1]$), $p_{\\text{comm}}=0.8$, seed $=45$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must itself be a list of three floating-point numbers $[\\bar{G},\\bar{O},\\bar{F}]$, in the same order as the test cases above. For example, the overall output format must be\n$[[g_1,o_1,f_1],[g_2,o_2,f_2],[g_3,o_3,f_3],[g_4,o_4,f_4]]$,\nwhere each $g_k$, $o_k$, and $f_k$ is reported as a decimal number.", "solution": "The problem statement has been rigorously validated and is determined to be well-posed, scientifically grounded within the domain of agent-based computational economics, and internally consistent. All parameters, behavioral rules, and an objective evaluation criterion are specified unambiguously. I will therefore proceed with a complete solution.\n\nThe problem requires the implementation of a discrete-time agent-based simulation model. The system state is defined by the attractions of $N$ agents, which evolve over $T$ periods according to their actions and resulting payoffs. The core of the solution is a computational algorithm that precisely executes the model's dynamics. The design is structured into three main phases: initialization, the main simulation loop, and final measurement.\n\nFirst, an initialization phase establishes the simulation environment. This involves setting up the $N$ agents and partitioning them into disjoint coalitions $\\mathcal{G}$ according to the specified list of coalition sizes. For each coalition $g \\in \\mathcal{G}$ of size $|g| \\ge 2$, a coordination quota $q_g = \\lfloor C \\cdot \\frac{|g|}{N} \\rfloor$ is pre-calculated, where $C$ is the bar capacity. Each agent $i$ is initialized with zero attraction for attending and staying, $A_i^{\\text{att}}(0)=0$ and $A_i^{\\text{stay}}(0)=0$. A pseudo-random number generator is seeded as specified for each test case to ensure reproducibility of all stochastic events.\n\nSecond, the main simulation loop iterates from time $t=0$ to $t=T-1$. Each period $t$ comprises a sequence of steps derived directly from the problem definition:\n\n1.  **Private Intention Formation**: Each agent $i$ forms a private intention $b_i(t) \\in \\{0,1\\}$ to either attend ($1$) or stay home ($0$). This decision is based on a comparison of their current attractions. If $A_i^{\\text{att}}(t) > A_i^{\\text{stay}}(t)$, the intention is $b_i(t)=1$. If $A_i^{\\text{att}}(t) < A_i^{\\text{stay}}(t)$, the intention is $b_i(t)=0$. In the case of a tie, $A_i^{\\text{att}}(t) = A_i^{\\text{stay}}(t)$, the intention $b_i(t)$ is determined by a fair coin flip using the seeded random number generator.\n\n2.  **Coalition Coordination**: The final action $a_i(t)$ is determined. For agents in singleton coalitions ($|g|=1$), the final action is always their private intention, $a_i(t) = b_i(t)$. For each non-singleton coalition $g$ ($|g| \\ge 2$), a Bernoulli trial with success probability $p_{\\text{comm}}$ determines if the coalition is active for coordination. If inactive, all members $i \\in g$ set $a_i(t) = b_i(t)$. If active, the sum of intentions $S_g(t) = \\sum_{i \\in g} b_i(t)$ is compared to the coalition's quota $q_g$. If $S_g(t) \\le q_g$, no coordination is needed and $a_i(t)=b_i(t)$ for all $i \\in g$. However, if $S_g(t) > q_g$, a downward-adjustment rule is applied. Among the $S_g(t)$ members intending to attend, exactly $q_g$ are chosen to attend. The selection criterion is based on sorting these members first in descending order of their attraction difference $\\Delta_i(t) = A_i^{\\text{att}}(t) - A_i^{\\text{stay}}(t)$, and then in ascending order of their agent index $i$ to break ties. These $q_g$ agents have their final action set to $a_i(t)=1$. The remaining $S_g(t) - q_g$ members who intended to attend are \"flipped\" to have a final action of $a_i(t)=0$. Agents who initially intended to stay ($b_i(t)=0$) maintain their action $a_i(t)=0$.\n\n3.  **Payoff and Learning**: Once all final actions are determined, the aggregate attendance $A(t) = \\sum_{i=0}^{N-1} a_i(t)$ is computed. Each agent $i$ receives a payoff $u_i(t)=1$ for a \"correct\" decision (attending a non-overcrowded bar, or staying home from an overcrowded one) and $u_i(t)=0$ otherwise. Subsequently, attractions are updated using the specified Roth-Erev learning rule. For an agent $i$ who chose action $a_i(t) \\in \\{0, 1\\}$, the chosen action's attraction is updated via $A_i^{\\text{chosen}}(t+1) = (1-\\rho)A_i^{\\text{chosen}}(t) + \\lambda u_i(t)$, while the unchosen action's attraction is updated via $A_i^{\\text{unchosen}}(t+1) = (1-\\rho)A_i^{\\text{unchosen}}(t)$. Here, $\\rho$ is the recency parameter and $\\lambda$ is the learning step size.\n\nThird, after the simulation completes, the final analysis is performed. The required metrics—mean attendance gap $\\bar{G}$, overcrowding frequency $\\bar{O}$, and average coordination flip share $\\bar{F}$—are calculated by averaging their respective time series over the final $H$ periods of the simulation, from $t=T-H$ to $t=T-1$. The implementation uses vectorized operations provided by the NumPy library for efficiency in computations involving agent state arrays.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(N, C, T, H, rho, lambda_param, p_comm, coalition_sizes, seed):\n    \"\"\"\n    Implements and simulates the described agent-based El Farol Bar model with coalitions.\n    \"\"\"\n    # Initialize the pseudo-random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # 1. Initialization\n    # Construct coalition structure: a list of lists of agent indices.\n    coalitions = []\n    # Store quotas for non-singleton coalitions, indexed by coalition index.\n    quotas = {}\n    agent_idx_counter = 0\n    for g_idx, size in enumerate(coalition_sizes):\n        members = list(range(agent_idx_counter, agent_idx_counter + size))\n        coalitions.append(members)\n        if size >= 2:\n            # Per the problem, quota is floor(C * |g| / N).\n            quotas[g_idx] = int(C * size / N)\n        agent_idx_counter += size\n\n    # Agent state variables initialized to 0.\n    attractions = np.zeros(N, dtype=float)\n    stays = np.zeros(N, dtype=float)\n\n    # Data structures for storing tail-end history for final metrics.\n    attendance_history = []\n    flips_history = []\n\n    # 2. Main Simulation Loop\n    for t in range(T):\n        # 2a. Private Intention Phase\n        deltas = attractions - stays\n        intentions = np.zeros(N, dtype=int)\n        intentions[deltas > 0] = 1\n        \n        # Resolve ties with a fair coin flip.\n        tie_indices = np.where(deltas == 0)[0]\n        if len(tie_indices) > 0:\n            intentions[tie_indices] = rng.integers(0, 2, size=len(tie_indices))\n        \n        # Final actions start as intentions; may be modified by coordination.\n        actions = intentions.copy()\n\n        # 2b. Coalition Coordination Phase\n        for g_idx, g_members in enumerate(coalitions):\n            # Singleton coalitions (|g|=1) do not coordinate.\n            if len(g_members) < 2:\n                continue\n\n            # Bernoulli trial for coalition activation.\n            is_active = rng.random() < p_comm\n            if not is_active:\n                continue\n\n            # Active coalition coordination logic.\n            member_intentions = intentions[g_members]\n            S_g = np.sum(member_intentions)\n            q_g = quotas[g_idx]\n\n            if S_g > q_g:\n                # Identify members who intended to attend.\n                intending_member_local_indices = np.where(member_intentions == 1)[0]\n                global_intending_indices = [g_members[i] for i in intending_member_local_indices]\n                \n                # Create a list of candidates to be sorted.\n                candidates = []\n                for agent_idx in global_intending_indices:\n                    candidates.append((deltas[agent_idx], agent_idx))\n                \n                # Sort: 1st key descending delta, 2nd key ascending agent index.\n                candidates.sort(key=lambda x: (-x[0], x[1]))\n                \n                # The agents beyond the quota are 'flipped' to stay home.\n                for _, agent_idx in candidates[q_g:]:\n                    actions[agent_idx] = 0\n\n        # 2c. Payoff and Learning\n        A_t = np.sum(actions)\n        \n        payoffs = np.zeros(N, dtype=float)\n        actions_mask = (actions == 1) # Boolean mask for agents who attended.\n        \n        if A_t <= C:  # Bar not crowded: attenders get payoff 1.\n            payoffs[actions_mask] = 1.0\n        else:  # Bar crowded: stayers get payoff 1.\n            payoffs[~actions_mask] = 1.0\n\n        # Update attractions for t+1 using vectorized operations.\n        # First, apply the recency discount to all.\n        attractions = (1 - rho) * attractions\n        stays = (1 - rho) * stays\n\n        # Then, add the reinforcement term for the chosen action.\n        attractions[actions_mask] += lambda_param * payoffs[actions_mask]\n        stays[~actions_mask] += lambda_param * payoffs[~actions_mask]\n\n        # 2d. Data Recording for Tail Averages\n        if t >= T - H:\n            attendance_history.append(A_t)\n            flips_history.append(np.sum(actions != intentions))\n\n    # 3. Final Metrics Calculation\n    attendance_history = np.array(attendance_history, dtype=float)\n    flips_history = np.array(flips_history, dtype=float)\n\n    mean_gap = np.mean(attendance_history - C)\n    overcrowding_freq = np.mean(attendance_history > C)\n    mean_flip_share = np.mean(flips_history / N)\n\n    return [mean_gap, overcrowding_freq, mean_flip_share]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: All agents are singletons.\n        {'N': 51, 'C': 25, 'T': 2000, 'H': 500, 'rho': 0.01, 'lambda_param': 0.2, \n         'coalition_sizes': [1] * 51, 'p_comm': 0.5, 'seed': 42},\n        # Case 2: Coalitions, full communication.\n        {'N': 51, 'C': 25, 'T': 2000, 'H': 500, 'rho': 0.01, 'lambda_param': 0.2,\n         'coalition_sizes': [3,3,3,3,3,3,3,30], 'p_comm': 1.0, 'seed': 43},\n        # Case 3: Coalitions, no communication.\n        {'N': 51, 'C': 25, 'T': 2000, 'H': 500, 'rho': 0.01, 'lambda_param': 0.2,\n         'coalition_sizes': [3,3,3,3,3,3,3,30], 'p_comm': 0.0, 'seed': 44},\n        # Case 4: Another coalition structure, partial communication.\n        {'N': 51, 'C': 25, 'T': 2000, 'H': 500, 'rho': 0.01, 'lambda_param': 0.2,\n         'coalition_sizes': [5]*10 + [1], 'p_comm': 0.8, 'seed': 45},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(**params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\nsolve()\n```"}]}