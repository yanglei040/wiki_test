{"hands_on_practices": [{"introduction": "The theory of the firm offers a classic application for constrained optimization. This exercise moves beyond simply finding an optimal production plan; it delves into the economic meaning behind the mathematics. By solving a firm's cost-minimization problem, you will use the Karush-Kuhn-Tucker (KKT) conditions to uncover the significance of the Lagrange multiplier, transforming it from an abstract variable into a concrete measure of shadow price [@problem_id:2384397].", "id": "2384397", "problem": "A competitive firm uses two inputs $x_1$ and $x_2$ with input prices $w_1$ and $w_2$ to produce output $y$ according to the production function $f(x_1,x_2) = x_1^{1/2} x_2^{1/2}$. The firm must meet a production quota of at least $q_0$ units. The firm chooses inputs to minimize total cost subject to meeting the quota. Suppose $w_1 = \\$\\,4$ per unit, $w_2 = \\$\\,1$ per unit, and $q_0 = 10$ units of output.\n\nFormulate the cost minimization problem and its Lagrangian with a single inequality constraint, derive the first-order necessary conditions using the Karush-Kuhn-Tucker (KKT) conditions, and solve for the optimal inputs and the associated Lagrange multiplier. Use the dual variable (Lagrange multiplier) at the optimum to estimate the change in the firmâ€™s minimal total cost if the production quota increases from $q_0$ to $q_0 + 1$ (that is, by one unit). Express your final answer in dollars. Provide a single numerical value; no rounding is required.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extract Givens.\n- Production function: $f(x_1,x_2) = x_1^{1/2} x_2^{1/2}$\n- Inputs: $x_1$, $x_2$\n- Input prices: $w_1 = 4$ dollars per unit, $w_2 = 1$ dollar per unit\n- Production quota: at least $q_0 = 10$ units\n- Objective: Minimize total cost, $C = w_1 x_1 + w_2 x_2$.\n- Task: Formulate the cost minimization problem and its Lagrangian, derive the first-order necessary conditions using the Karush-Kuhn-Tucker (KKT) conditions, solve for the optimal inputs and the Lagrange multiplier, and use the multiplier to estimate the change in minimal cost for a unit increase in the quota.\n\nStep 2: Validate Using Extracted Givens.\n- **Scientifically Grounded:** The problem is a standard exercise in microeconomic theory, specifically the theory of the firm. It uses a Cobb-Douglas production function, a canonical model in economics. All concepts are well-established. This is scientifically sound.\n- **Well-Posed:** The problem is a constrained optimization problem. The objective function is linear (and thus convex), and the constraint function $g(x_1, x_2) = x_1^{1/2} x_2^{1/2}$ is quasiconcave, which defines a convex upper-level set. This structure ensures a well-posed minimization problem with a unique solution.\n- **Objective:** The problem is stated with precise, unambiguous mathematical and economic terms.\n\nStep 3: Verdict and Action.\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed with the solution.\n\nThe firm's problem is to minimize its total cost, $C(x_1, x_2) = w_1 x_1 + w_2 x_2$, subject to the constraint that its output, $y = f(x_1, x_2)$, is at least the quota amount $q_0$. The non-negativity of inputs, $x_1 \\ge 0$ and $x_2 \\ge 0$, is implicitly required by the form of the production function.\n\nSubstituting the given values, the optimization problem is:\n$$\n\\text{Minimize } C(x_1, x_2) = 4x_1 + x_2\n$$\n$$\n\\text{Subject to } x_1^{1/2} x_2^{1/2} \\ge 10\n$$\n\nTo apply the Karush-Kuhn-Tucker (KKT) framework, we write the constraint in the standard form $g(x) \\le 0$.\nThe constraint $x_1^{1/2} x_2^{1/2} \\ge 10$ is equivalent to $10 - x_1^{1/2} x_2^{1/2} \\le 0$.\n\nThe Lagrangian function, $\\mathcal{L}$, is constructed as the objective function plus the Lagrange multiplier, $\\lambda$, times the constraint function:\n$$\n\\mathcal{L}(x_1, x_2, \\lambda) = 4x_1 + x_2 + \\lambda(10 - x_1^{1/2} x_2^{1/2})\n$$\n\nThe KKT conditions for an optimal solution $(x_1^*, x_2^*, \\lambda^*)$ are:\n1.  First-order conditions (stationarity): The partial derivatives of the Lagrangian with respect to the choice variables must be zero.\n    $$\n    \\frac{\\partial \\mathcal{L}}{\\partial x_1} = 4 - \\lambda \\left( \\frac{1}{2} x_1^{-1/2} x_2^{1/2} \\right) = 0\n    $$\n    $$\n    \\frac{\\partial \\mathcal{L}}{\\partial x_2} = 1 - \\lambda \\left( \\frac{1}{2} x_1^{1/2} x_2^{-1/2} \\right) = 0\n    $$\n2.  Primal feasibility: The solution must satisfy the original constraint.\n    $$\n    10 - x_1^{1/2} x_2^{1/2} \\le 0 \\quad \\text{or} \\quad x_1^{1/2} x_2^{1/2} \\ge 10\n    $$\n3.  Dual feasibility: The Lagrange multiplier associated with a `less than or equal to` inequality constraint in a minimization problem must be non-negative.\n    $$\n    \\lambda \\ge 0\n    $$\n4.  Complementary slackness: At the optimum, either the constraint is binding or the multiplier is zero (or both).\n    $$\n    \\lambda (10 - x_1^{1/2} x_2^{1/2}) = 0\n    $$\n\nWe now solve this system of conditions.\nFrom the first-order conditions, assuming $x_1 > 0$ and $x_2 > 0$:\n$$\n4 = \\frac{\\lambda}{2} \\sqrt{\\frac{x_2}{x_1}} \\quad (1)\n$$\n$$\n1 = \\frac{\\lambda}{2} \\sqrt{\\frac{x_1}{x_2}} \\quad (2)\n$$\nThe right-hand sides are positive, which implies that $\\lambda$ must be strictly positive ($\\lambda > 0$). If $\\lambda$ were zero, the first-order conditions would require $4=0$ and $1=0$, which is absurd.\nSince $\\lambda > 0$, the complementary slackness condition $\\lambda (10 - x_1^{1/2} x_2^{1/2}) = 0$ implies that the constraint must be binding:\n$$\n10 - x_1^{1/2} x_2^{1/2} = 0 \\implies x_1^{1/2} x_2^{1/2} = 10 \\quad (3)\n$$\nNow, we can solve for the relationship between $x_1$ and $x_2$ by dividing equation $(1)$ by equation $(2)$:\n$$\n\\frac{4}{1} = \\frac{\\frac{\\lambda}{2} \\sqrt{\\frac{x_2}{x_1}}}{\\frac{\\lambda}{2} \\sqrt{\\frac{x_1}{x_2}}} = \\frac{\\sqrt{x_2}}{\\sqrt{x_1}} \\cdot \\frac{\\sqrt{x_2}}{\\sqrt{x_1}} = \\frac{x_2}{x_1}\n$$\nThis gives the firm's optimal input expansion path: $x_2 = 4x_1$.\n\nSubstitute this relationship into the binding constraint, equation $(3)$:\n$$\n\\sqrt{x_1 (4x_1)} = 10\n$$\n$$\n\\sqrt{4x_1^2} = 10\n$$\n$$\n2x_1 = 10\n$$\nSolving for $x_1$ gives the optimal quantity for the first input:\n$$\nx_1^* = 5\n$$\nNow, we find the optimal quantity for the second input:\n$$\nx_2^* = 4x_1^* = 4(5) = 20\n$$\nThe optimal input bundle is $(x_1^*, x_2^*) = (5, 20)$.\n\nFinally, we solve for the Lagrange multiplier, $\\lambda^*$, using equation $(2)$ and the optimal inputs:\n$$\n1 = \\frac{\\lambda^*}{2} \\sqrt{\\frac{x_1^*}{x_2^*}} = \\frac{\\lambda^*}{2} \\sqrt{\\frac{5}{20}} = \\frac{\\lambda^*}{2} \\sqrt{\\frac{1}{4}} = \\frac{\\lambda^*}{2} \\cdot \\frac{1}{2} = \\frac{\\lambda^*}{4}\n$$\nThis yields:\n$$\n\\lambda^* = 4\n$$\nThe optimal Lagrange multiplier is $\\lambda^*=4$. We confirm that $\\lambda^* \\ge 0$, satisfying the dual feasibility condition.\n\nThe economic interpretation of the Lagrange multiplier $\\lambda^*$ in a cost minimization context is the marginal cost of the constraint. It represents the rate at which the firm's minimum cost changes with respect to a relaxation of the production quota, $q_0$.\nThat is, $\\lambda^* = \\frac{dC^*(q_0)}{dq_0}$, where $C^*$ is the minimized cost.\n\nThe problem asks to estimate the change in the minimal total cost if the production quota increases by one unit, from $q_0 = 10$ to $q_0' = 11$. This change, $\\Delta q_0$, is $11 - 10 = 1$.\nUsing a first-order linear approximation, the change in minimum cost, $\\Delta C^*$, is:\n$$\n\\Delta C^* \\approx \\lambda^* \\cdot \\Delta q_0\n$$\nSubstituting the calculated values:\n$$\n\\Delta C^* \\approx 4 \\cdot 1 = 4\n$$\nThe estimated increase in the firm's minimal total cost is $4$ dollars.\nThe initial minimum cost is $C^* = 4x_1^* + x_2^* = 4(5) + 20 = 20 + 20 = 40$. The new estimated minimum cost would be $40+4=44$.", "answer": "$$\\boxed{4}$$"}, {"introduction": "We now shift our focus from production to finance, applying a similar optimization logic to portfolio construction. The goal is to find the Global Minimum Variance (GMV) portfolio, a cornerstone concept of Modern Portfolio Theory. This practice [@problem_id:2384386] is designed to challenge your intuition and highlight the critical role of asset correlation, revealing how minimizing risk can sometimes lead to surprising investment strategies.", "id": "2384386", "problem": "Consider two risky assets, labeled asset $A$ and asset $B$. Their annualized standard deviations are $\\sigma_A = 0.20$ and $\\sigma_B = 0.50$, respectively. The correlation between their returns is $\\rho = 0.95$. The investor can take any real-valued portfolio weights $(w_A, w_B)$ satisfying $w_A + w_B = 1$; short selling is allowed. The portfolio variance is $w^{\\top} \\Sigma w$, where $\\Sigma$ is the covariance matrix with entries $\\Sigma_{11} = \\sigma_A^2$, $\\Sigma_{22} = \\sigma_B^2$, and $\\Sigma_{12} = \\Sigma_{21} = \\rho \\sigma_A \\sigma_B$.\n\nDefine the Global Minimum Variance portfolio as the full-investment portfolio $(w_A, w_B)$ that minimizes $w^{\\top} \\Sigma w$ subject to $w_A + w_B = 1$.\n\nWhat is the weight on asset $B$ (the higher-variance asset) in the Global Minimum Variance portfolio? Round your answer to four significant figures. Express your answer as a pure number (no units).", "solution": "The problem statement is subjected to validation and is found to be valid. It presents a standard, well-posed constrained optimization problem from the field of Modern Portfolio Theory, a core component of computational finance. All data and conditions are provided, are scientifically sound, and are consistent.\n\nThe objective is to find the portfolio weights $(w_A, w_B)$ that minimize the portfolio variance, $V$, subject to the constraint that the portfolio is fully invested. The portfolio variance for two assets, $A$ and $B$, is given by the quadratic form:\n$$V(w_A, w_B) = w_A^2 \\sigma_A^2 + w_B^2 \\sigma_B^2 + 2 w_A w_B \\rho \\sigma_A \\sigma_B$$\nwhere $w_A$ and $w_B$ are the weights of asset $A$ and asset $B$, respectively. The weights are subject to the linear constraint:\n$$w_A + w_B = 1$$\nThis constraint allows us to reduce the problem to an unconstrained optimization of a single variable. By substituting $w_A = 1 - w_B$ into the variance equation, we express the variance $V$ as a function of only $w_B$:\n$$V(w_B) = (1 - w_B)^2 \\sigma_A^2 + w_B^2 \\sigma_B^2 + 2 (1 - w_B) w_B \\rho \\sigma_A \\sigma_B$$\nTo find the value of $w_B$ that minimizes this variance, we must find the critical point by taking the first derivative of $V(w_B)$ with respect to $w_B$ and setting it to zero. This is a straightforward application of differential calculus.\n$$\\frac{d V}{d w_B} = \\frac{d}{d w_B} \\left[ (1 - 2w_B + w_B^2)\\sigma_A^2 + w_B^2 \\sigma_B^2 + (2w_B - 2w_B^2)\\rho \\sigma_A \\sigma_B \\right]$$\nApplying the power rule for differentiation term by term yields:\n$$\\frac{d V}{d w_B} = (-2 + 2w_B)\\sigma_A^2 + 2w_B \\sigma_B^2 + (2 - 4w_B)\\rho \\sigma_A \\sigma_B$$\nSetting the derivative to zero locates the extremum:\n$$(-2 + 2w_B)\\sigma_A^2 + 2w_B \\sigma_B^2 + (2 - 4w_B)\\rho \\sigma_A \\sigma_B = 0$$\nWe now solve for $w_B$ by grouping terms containing $w_B$:\n$$2w_B\\sigma_A^2 - 2\\sigma_A^2 + 2w_B \\sigma_B^2 + 2\\rho \\sigma_A \\sigma_B - 4w_B\\rho \\sigma_A \\sigma_B = 0$$\n$$w_B(2\\sigma_A^2 + 2\\sigma_B^2 - 4\\rho \\sigma_A \\sigma_B) = 2\\sigma_A^2 - 2\\rho \\sigma_A \\sigma_B$$\nDividing by $2$ simplifies the expression:\n$$w_B(\\sigma_A^2 + \\sigma_B^2 - 2\\rho \\sigma_A \\sigma_B) = \\sigma_A^2 - \\rho \\sigma_A \\sigma_B$$\nIsolating $w_B$ provides the general formula for the weight of asset $B$ in the Global Minimum Variance portfolio:\n$$w_B = \\frac{\\sigma_A^2 - \\rho \\sigma_A \\sigma_B}{\\sigma_A^2 + \\sigma_B^2 - 2\\rho \\sigma_A \\sigma_B}$$\nThe second derivative, $\\frac{d^2 V}{d w_B^2} = 2(\\sigma_A^2 + \\sigma_B^2 - 2\\rho \\sigma_A \\sigma_B)$, is positive since $|\\rho| < 1$, which confirms that the identified critical point is a global minimum.\n\nNow, we substitute the provided numerical values: $\\sigma_A = 0.20$, $\\sigma_B = 0.50$, and $\\rho = 0.95$.\nFirst, we compute the variances and the covariance:\n$$\\sigma_A^2 = (0.20)^2 = 0.04$$\n$$\\sigma_B^2 = (0.50)^2 = 0.25$$\n$$\\text{Cov}(A,B) = \\rho \\sigma_A \\sigma_B = (0.95)(0.20)(0.50) = 0.095$$\nSubstituting these values into the derived formula for $w_B$:\n$$w_B = \\frac{0.04 - 0.095}{0.04 + 0.25 - 2(0.095)}$$\n$$w_B = \\frac{-0.055}{0.29 - 0.19}$$\n$$w_B = \\frac{-0.055}{0.10} = -0.55$$\nThe problem requires the answer to be rounded to four significant figures. Therefore, the weight on asset $B$ is $-0.5500$. The negative value signifies a short position in asset $B$, which is permitted by the problem statement. Consequently, the weight in asset A is $w_A = 1 - w_B = 1 - (-0.55) = 1.55$.", "answer": "$$\n\\boxed{-0.5500}\n$$"}, {"introduction": "Having solved optimization problems analytically, we now look 'under the hood' at the algorithms that power computational economics and finance. This hands-on coding exercise [@problem_id:2384404] contrasts two fundamental methods: the first-order gradient descent and the second-order Newton's method. You will discover how the geometry of the objective function, captured by the Hessian matrix's condition number $\\kappa(\\mathbf{Q})$, dramatically affects convergence speed and reveals the power and efficiency of second-order information.", "id": "2384404", "problem": "Consider the maximization of a concave quadratic utility function in a finite-dimensional Euclidean space. Let the utility be given by $u(\\mathbf{x}) = \\mathbf{b}^{\\top}\\mathbf{x} - \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x}$, where $\\mathbf{x} \\in \\mathbb{R}^{n}$, $\\mathbf{b} \\in \\mathbb{R}^{n}$, and $\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite. This utility is strictly concave, and its negative defines a convex minimization problem. Define the convex objective $f(\\mathbf{x}) = -u(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x}$. The Hessian of $f$ equals $\\mathbf{Q}$, and the condition number of the Hessian with respect to the Euclidean norm is $\\kappa(\\mathbf{Q}) = \\lambda_{\\max}(\\mathbf{Q})/\\lambda_{\\min}(\\mathbf{Q})$, where $\\lambda_{\\max}$ and $\\lambda_{\\min}$ denote the largest and smallest eigenvalues, respectively. You will compare the convergence behavior of two algorithms that solve $\\min_{\\mathbf{x}} f(\\mathbf{x})$: gradient descent with backtracking line search and Newtonâ€™s method with backtracking line search.\n\nStarting only from core definitions in multivariate calculus and convex analysis (the gradient as the vector of partial derivatives, the Hessian as the Jacobian of the gradient, the first-order optimality condition for unconstrained convex minimization, and the Armijo sufficient decrease condition), derive the necessary analytic expressions to implement both algorithms for the quadratic $f(\\mathbf{x})$ described above. Implement both algorithms as follows:\n\n- Gradient descent with backtracking: at iterate $\\mathbf{x}_{k}$, compute a descent direction using the negative gradient and perform backtracking line search satisfying the Armijo sufficient decrease condition to select a step length. Update the iterate and repeat until convergence.\n- Newtonâ€™s method with backtracking: at iterate $\\mathbf{x}_{k}$, compute a Newton direction by solving a linear system defined by the Hessian and the gradient, and perform backtracking line search satisfying the Armijo sufficient decrease condition to select a step length. Update the iterate and repeat until convergence.\n\nUse the following shared parameters for both methods:\n- Armijo parameter $c_{1} = 10^{-4}$,\n- backtracking contraction factor $\\tau = \\tfrac{1}{2}$,\n- initial trial step length $\\alpha_{0} = 1$,\n- stopping tolerance based on the Euclidean norm of the gradient: stop when $\\lVert \\nabla f(\\mathbf{x}_{k}) \\rVert_{2} \\le \\varepsilon$ with $\\varepsilon = 10^{-6}$,\n- maximum number of iterations for gradient descent equal to $200{,}000$, and for Newtonâ€™s method equal to $1{,}000$.\n\nTest Suite. Run both methods on the following four test cases, each specified by $(\\mathbf{Q}, \\mathbf{b}, \\mathbf{x}_{0})$, where $\\mathbf{x}_{0}$ is the starting point.\n\n- Case $1$ (boundary optimality, poorly conditioned but trivial): \n  $$\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 100 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}.$$\n- Case $2$ (ill-conditioned, moderate): \n  $$\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 100 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}.$$\n- Case $3$ (ill-conditioned, stronger): \n  $$\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 500 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}.$$\n- Case $4$ (ill-conditioned, stronger still): \n  $$\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2000 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}.$$\n\nFor each case, run both algorithms until the stopping criterion is met or the iteration limit is reached. For each case, return the ordered pair of iteration counts $[\\text{iters\\_GD}, \\text{iters\\_Newton}]$, where $\\text{iters\\_GD}$ is the number of iterations used by gradient descent and $\\text{iters\\_Newton}$ is the number of iterations used by Newtonâ€™s method.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one sublist per test case in the same order as above. For example, the output format must be \n$$[\\,[\\text{iters\\_GD}^{(1)},\\text{iters\\_Newton}^{(1)}],\\,[\\text{iters\\_GD}^{(2)},\\text{iters\\_Newton}^{(2)}],\\,[\\text{iters\\_GD}^{(3)},\\text{iters\\_Newton}^{(3)}],\\,[\\text{iters\\_GD}^{(4)},\\text{iters\\_Newton}^{(4)}]\\,].$$\nAll numbers in the output must be integers, and no additional text should be printed.", "solution": "The problem statement presented is subjected to validation.\n\n**Step 1: Extract Givens**\n\n- **Objective Function:** Minimize $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x}$, where $\\mathbf{x}, \\mathbf{b} \\in \\mathbb{R}^{n}$ and $\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$ is a symmetric positive definite matrix.\n- **Algorithms:** Gradient descent and Newton's method, both with backtracking line search.\n- **Line Search Parameters:**\n    - Armijo sufficient decrease parameter: $c_{1} = 10^{-4}$.\n    - Contraction factor: $\\tau = \\tfrac{1}{2}$.\n    - Initial step length: $\\alpha_{0} = 1$.\n- **Termination Conditions:**\n    - Stopping tolerance on gradient norm: $\\lVert \\nabla f(\\mathbf{x}_{k}) \\rVert_{2} \\le \\varepsilon = 10^{-6}$.\n    - Maximum iterations for gradient descent: $200,000$.\n    - Maximum iterations for Newton's method: $1,000$.\n- **Test Cases:** Four cases are provided, each defined by a tuple $(\\mathbf{Q}, \\mathbf{b}, \\mathbf{x}_{0})$.\n    1.  $\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 100 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$.\n    2.  $\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 100 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}$.\n    3.  $\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 500 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}$.\n    4.  $\\mathbf{Q} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2000 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in numerical convex optimization, comparing the performance of first-order and second-order methods on a convex quadratic function. All parameters, initial conditions, and matrices are explicitly defined. The matrices $\\mathbf{Q}$ are symmetric and, having positive diagonal entries, are positive definite, ensuring the strict convexity of $f(\\mathbf{x})$ and the existence of a unique minimizer. Case $1$ is a trivial boundary case where the starting point is the solution, which is a valid test for any correct implementation. The problem is complete, consistent, and scientifically sound.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A solution will be provided.\n\n**Derivation and Algorithm Design**\n\nThe objective is to find $\\mathbf{x}^* = \\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^n} f(\\mathbf{x})$, where $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x}$.\n\n**First and Second Derivatives**\nTo apply gradient-based optimization methods, we first derive the gradient and Hessian of $f(\\mathbf{x})$. Using elementary rules of matrix calculus:\nThe gradient of $f(\\mathbf{x})$ is the vector of its partial derivatives, $\\nabla f(\\mathbf{x}) = \\left[ \\frac{\\partial f}{\\partial x_i} \\right]_{i=1}^n$.\n$$\n\\nabla f(\\mathbf{x}) = \\nabla \\left( \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x} \\right) = \\tfrac{1}{2}(\\mathbf{Q} + \\mathbf{Q}^{\\top})\\mathbf{x} - \\mathbf{b}\n$$\nSince $\\mathbf{Q}$ is symmetric, $\\mathbf{Q} = \\mathbf{Q}^{\\top}$, which simplifies the gradient to:\n$$\n\\nabla f(\\mathbf{x}) = \\mathbf{Q}\\mathbf{x} - \\mathbf{b}\n$$\nThe Hessian of $f(\\mathbf{x})$ is the matrix of second-order partial derivatives, $\\nabla^2 f(\\mathbf{x}) = \\left[ \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} \\right]_{i,j=1}^n$. It is the Jacobian of the gradient:\n$$\n\\nabla^2 f(\\mathbf{x}) = \\nabla (\\mathbf{Q}\\mathbf{x} - \\mathbf{b}) = \\mathbf{Q}\n$$\nThe Hessian is constant and equal to the matrix $\\mathbf{Q}$. Since $\\mathbf{Q}$ is positive definite, $f(\\mathbf{x})$ is a strictly convex function.\n\n**Optimality Condition**\nFor an unconstrained convex optimization problem, the first-order necessary and sufficient condition for a point $\\mathbf{x}^*$ to be a global minimizer is that the gradient vanishes:\n$$\n\\nabla f(\\mathbf{x}^*) = \\mathbf{Q}\\mathbf{x}^* - \\mathbf{b} = \\mathbf{0}\n$$\nSince $\\mathbf{Q}$ is invertible, the unique solution is given by $\\mathbf{x}^* = \\mathbf{Q}^{-1}\\mathbf{b}$. Our task is to find this solution iteratively.\n\n**Iterative Algorithms**\nBoth algorithms follow the update rule $\\mathbf{x}_{k+1} = \\mathbf{x}_{k} + \\alpha_k \\mathbf{p}_k$, where $\\mathbf{p}_k$ is a search direction and $\\alpha_k > 0$ is a step length determined by a line search.\n\n**1. Gradient Descent with Backtracking Line Search**\n- **Search Direction:** The direction of steepest descent is the negative gradient:\n  $$\n  \\mathbf{p}_k = -\\nabla f(\\mathbf{x}_k) = -(\\mathbf{Q}\\mathbf{x}_k - \\mathbf{b}) = \\mathbf{b} - \\mathbf{Q}\\mathbf{x}_k\n  $$\n- **Line Search:** The step length $\\alpha_k$ is found using backtracking. Starting with an initial trial step $\\alpha = \\alpha_0$, we iteratively reduce it by a factor $\\tau$ until the Armijo sufficient decrease condition is satisfied:\n  $$\n  f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) \\le f(\\mathbf{x}_k) + c_1 \\alpha \\nabla f(\\mathbf{x}_k)^{\\top} \\mathbf{p}_k\n  $$\n  Substituting $\\mathbf{p}_k = -\\nabla f(\\mathbf{x}_k)$, the condition becomes:\n  $$\n  f(\\mathbf{x}_k - \\alpha \\nabla f(\\mathbf{x}_k)) \\le f(\\mathbf{x}_k) - c_1 \\alpha \\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2^2\n  $$\nThe algorithm proceeds by generating a sequence of iterates $\\{\\mathbf{x}_k\\}$ until $\\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2 \\le \\varepsilon$. The convergence rate of gradient descent is known to degrade as the condition number $\\kappa(\\mathbf{Q})$ increases.\n\n**2. Newton's Method with Backtracking Line Search**\n- **Search Direction:** Newton's method uses a second-order approximation of the function. The Newton direction $\\mathbf{p}_k^{\\text{N}}$ is found by solving the linear system:\n  $$\n  \\nabla^2 f(\\mathbf{x}_k) \\mathbf{p}_k^{\\text{N}} = -\\nabla f(\\mathbf{x}_k)\n  $$\n  For our quadratic objective, this becomes:\n  $$\n  \\mathbf{Q} \\mathbf{p}_k^{\\text{N}} = -(\\mathbf{Q}\\mathbf{x}_k - \\mathbf{b})\n  $$\n  Solving for $\\mathbf{p}_k^{\\text{N}}$ yields:\n  $$\n  \\mathbf{p}_k^{\\text{N}} = -\\mathbf{Q}^{-1}(\\mathbf{Q}\\mathbf{x}_k - \\mathbf{b}) = \\mathbf{Q}^{-1}\\mathbf{b} - \\mathbf{x}_k = \\mathbf{x}^* - \\mathbf{x}_k\n  $$\n  The Newton direction points directly from the current iterate to the exact minimizer.\n- **Line Search:** The line search is performed as in gradient descent. Let's analyze the Armijo condition for the initial trial step $\\alpha=1$:\n  $$\n  f(\\mathbf{x}_k + \\mathbf{p}_k^{\\text{N}}) \\le f(\\mathbf{x}_k) + c_1 \\nabla f(\\mathbf{x}_k)^{\\top} \\mathbf{p}_k^{\\text{N}}\n  $$\n  The Taylor expansion of $f(\\mathbf{x}_k + \\alpha\\mathbf{p}_k^{\\text{N}})$ around $\\mathbf{x}_k$ is exact up to the second order for a quadratic function:\n  $$\n  f(\\mathbf{x}_k + \\alpha\\mathbf{p}_k^{\\text{N}}) = f(\\mathbf{x}_k) + \\alpha \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} + \\frac{1}{2}\\alpha^2 (\\mathbf{p}_k^{\\text{N}})^{\\top}\\mathbf{Q}\\mathbf{p}_k^{\\text{N}}\n  $$\n  Substituting $\\mathbf{Q}\\mathbf{p}_k^{\\text{N}} = -\\nabla f(\\mathbf{x}_k)$:\n  $$\n  f(\\mathbf{x}_k + \\alpha\\mathbf{p}_k^{\\text{N}}) = f(\\mathbf{x}_k) + \\alpha \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} - \\frac{1}{2}\\alpha^2 \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}}\n  $$\n  The Armijo condition becomes:\n  $$\n  f(\\mathbf{x}_k) + \\alpha \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} - \\frac{1}{2}\\alpha^2 \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} \\le f(\\mathbf{x}_k) + c_1 \\alpha \\nabla f(\\mathbf{x}_k)^{\\top} \\mathbf{p}_k^{\\text{N}}\n  $$\n  Since $\\mathbf{p}_k^{\\text{N}}$ is a descent direction, $\\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} = -(\\mathbf{p}_k^{\\text{N}})^{\\top}\\mathbf{Q}\\mathbf{p}_k^{\\text{N}} < 0$. We can divide by this negative term, reversing the inequality:\n  $$\n  1 - \\frac{1}{2}\\alpha \\ge c_1 \\implies \\alpha \\le 2(1-c_1)\n  $$\n  With $c_1=10^{-4}$, the condition is $\\alpha \\le 2(1 - 10^{-4}) = 1.9998$. Since the initial trial step is $\\alpha_0 = 1$, which is less than $1.9998$, the step $\\alpha_k=1$ will always be accepted.\n  The update is $\\mathbf{x}_{k+1} = \\mathbf{x}_k + 1 \\cdot (\\mathbf{x}^* - \\mathbf{x}_k) = \\mathbf{x}^*$.\n  Thus, Newton's method with the specified backtracking parameters will converge to the exact solution in a single iteration for any starting point other than the optimum itself.\n\n**Implementation Summary**\nThe implementation will consist of two functions, one for each algorithm. Each function will iteratively update the solution vector $\\mathbf{x}$ according to its specific rule and perform backtracking line search to determine the step size. The loop terminates when the Euclidean norm of the gradient is below the tolerance $\\varepsilon$ or the maximum number of iterations is reached.\nFor Case $1$, since $\\mathbf{x}_0 = \\mathbf{0}$ and $\\mathbf{b} = \\mathbf{0}$, the initial gradient $\\nabla f(\\mathbf{x}_0) = \\mathbf{Q}\\mathbf{0} - \\mathbf{0} = \\mathbf{0}$. The stopping condition is satisfied at the start, so both algorithms will report $0$ iterations.\nFor Cases $2$, $3$, and $4$, Newton's method is expected to take $1$ iteration, while gradient descent is expected to take a large number of iterations that increases with the condition number of $\\mathbf{Q}$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the number of iterations required by Gradient Descent and Newton's Method\n    for a series of test cases on a convex quadratic objective function.\n    \"\"\"\n\n    def objective_function(x, Q, b):\n        \"\"\"Computes the value of f(x) = 0.5*x.T*Q*x - b.T*x.\"\"\"\n        return 0.5 * x.T @ Q @ x - b.T @ x\n\n    def gradient(x, Q, b):\n        \"\"\"Computes the gradient of f(x).\"\"\"\n        return Q @ x - b\n\n    def gradient_descent(Q, b, x0, c1, tau, alpha0, tol, max_iter):\n        \"\"\"\n        Performs gradient descent with backtracking line search.\n        \n        Returns the number of iterations.\n        \"\"\"\n        x = np.copy(x0).astype(float)\n        iters = 0\n        \n        while iters < max_iter:\n            grad = gradient(x, Q, b)\n            \n            if np.linalg.norm(grad) <= tol:\n                return iters\n            \n            p = -grad  # Descent direction\n            \n            # Backtracking line search\n            alpha = alpha0\n            f_x = objective_function(x, Q, b)\n            grad_p_dot = grad.T @ p\n            \n            while True:\n                x_new = x + alpha * p\n                f_x_new = objective_function(x_new, Q, b)\n                if f_x_new <= f_x + c1 * alpha * grad_p_dot:\n                    break\n                alpha *= tau\n            \n            x = x + alpha * p\n            iters += 1\n            \n        return iters\n\n    def newton_method(Q, b, x0, c1, tau, alpha0, tol, max_iter):\n        \"\"\"\n        Performs Newton's method with backtracking line search.\n\n        Returns the number of iterations.\n        \"\"\"\n        x = np.copy(x0).astype(float)\n        iters = 0\n        \n        while iters < max_iter:\n            grad = gradient(x, Q, b)\n\n            if np.linalg.norm(grad) <= tol:\n                return iters\n            \n            # Newton direction: solve H*p = -g, where H = Q\n            p = np.linalg.solve(Q, -grad)\n            \n            # Backtracking line search\n            alpha = alpha0\n            f_x = objective_function(x, Q, b)\n            grad_p_dot = grad.T @ p\n            \n            while True:\n                x_new = x + alpha * p\n                f_x_new = objective_function(x_new, Q, b)\n                if f_x_new <= f_x + c1 * alpha * grad_p_dot:\n                    break\n                alpha *= tau\n            \n            x = x + alpha * p\n            iters += 1\n            \n        return iters\n\n    # Shared parameters\n    C1 = 1e-4\n    TAU = 0.5\n    ALPHA0 = 1.0\n    TOL = 1e-6\n    MAX_ITER_GD = 200000\n    MAX_ITER_NEWTON = 1000\n\n    # Test suite\n    test_cases = [\n        # Case 1\n        (np.array([[1, 0], [0, 100]]), np.array([0, 0]), np.array([0, 0])),\n        # Case 2\n        (np.array([[1, 0], [0, 100]]), np.array([1, 1]), np.array([10, -10])),\n        # Case 3\n        (np.array([[1, 0], [0, 500]]), np.array([1, 1]), np.array([10, -10])),\n        # Case 4\n        (np.array([[1, 0], [0, 2000]]), np.array([1, 1]), np.array([10, -10])),\n    ]\n\n    results = []\n    for Q, b, x0 in test_cases:\n        iters_gd = gradient_descent(Q, b, x0, C1, TAU, ALPHA0, TOL, MAX_ITER_GD)\n        iters_newton = newton_method(Q, b, x0, C1, TAU, ALPHA0, TOL, MAX_ITER_NEWTON)\n        results.append([iters_gd, iters_newton])\n\n    # Format the output string as required\n    formatted_results = [f\"[{gd},{nm}]\" for gd, nm in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"}]}