{"hands_on_practices": [{"introduction": "Trust-region methods work by solving a sequence of simpler subproblems. This first exercise breaks down the most fundamental of these: the one-dimensional trust-region subproblem. Here, we will explore the core decision-making process of the algorithm by minimizing a simple quadratic model within a constrained interval, which is our \"trust region\" [@problem_id:2224504]. This practice will help you build intuition for when the optimal step is the unconstrained minimum of the model versus when it is limited by the trust-region boundary.", "id": "2224504", "problem": "In the context of unconstrained optimization, trust-region methods iteratively approximate a complex function with a simpler model function $m(p)$ around the current point. The next step $p$ is then determined by solving the trust-region subproblem, which involves minimizing this model within a \"trust region\" of radius $\\Delta > 0$, where the model is believed to be a reliable approximation of the original function. The subproblem is formally stated as:\n$$\n\\min_{p} m(p) \\quad \\text{subject to} \\quad \\|p\\| \\le \\Delta\n$$\nConsider a one-dimensional optimization scenario where the model function for a step $p \\in \\mathbb{R}$ is a quadratic given by:\n$$\nm(p) = g p + \\frac{1}{2} H p^2 + c\n$$\nwith a gradient term $g = 2$, a Hessian term $H = 6$, and an arbitrary constant $c$. The step is constrained by a trust-region radius of $\\Delta = 0.1$.\n\nDetermine the optimal step $p$ that solves this one-dimensional trust-region subproblem. Provide your answer as an exact decimal number.\n\n", "solution": "We must minimize the quadratic model $m(p) = g p + \\frac{1}{2} H p^{2} + c$ subject to the trust-region constraint $|p| \\le \\Delta$, with given values $g=2$, $H=6$, and $\\Delta=0.1$. The constant $c$ does not affect the minimizer and can be ignored.\n\nConsider the Lagrangian for the trust-region subproblem:\n$$\n\\mathcal{L}(p,\\lambda) = g p + \\frac{1}{2} H p^{2} + \\lambda \\left(p^{2} - \\Delta^{2}\\right),\n$$\nwith $\\lambda \\ge 0$. The Karush-Kuhn-Tucker conditions are:\n1. Stationarity: \n$$\n\\frac{\\partial \\mathcal{L}}{\\partial p} = g + H p + 2 \\lambda p = 0.\n$$\n2. Primal feasibility: $|p| \\le \\Delta$.\n3. Dual feasibility: $\\lambda \\ge 0$.\n4. Complementary slackness: $\\lambda \\left(p^{2} - \\Delta^{2}\\right) = 0$.\n\nCase 1 (interior solution): If $|p| < \\Delta$, then $\\lambda = 0$ and stationarity gives\n$$\ng + H p = 0 \\quad \\Rightarrow \\quad p_{u} = -\\frac{g}{H}.\n$$\nFor $g=2$ and $H=6$, this gives $p_{u} = -\\frac{2}{6} = -\\frac{1}{3}$. Check feasibility: $|p_{u}| = \\frac{1}{3} > 0.1 = \\Delta$, so the interior solution is infeasible.\n\nCase 2 (boundary solution): Then $p^{2} = \\Delta^{2}$, so $p = \\pm \\Delta$. Stationarity becomes\n$$\ng + H p + 2 \\lambda p = 0 \\quad \\Rightarrow \\quad (H + 2 \\lambda) p = -g.\n$$\nSince $H + 2 \\lambda \\ge 0$, the sign of $p$ must match the sign of $-g$. With $g = 2 > 0$, we must take $p = -\\Delta = -0.1$. To verify dual feasibility, solve for $\\lambda$:\n$$\n(H + 2 \\lambda)(-\\Delta) = -g \\quad \\Rightarrow \\quad (H + 2 \\lambda)\\Delta = g \\quad \\Rightarrow \\quad 2 \\lambda = \\frac{g}{\\Delta} - H.\n$$\nSubstituting $g=2$, $\\Delta=0.1$, and $H=6$ gives\n$$\n2 \\lambda = \\frac{2}{0.1} - 6 = 20 - 6 = 14 \\quad \\Rightarrow \\quad \\lambda = 7 \\ge 0,\n$$\nwhich satisfies dual feasibility and complementary slackness.\n\nTherefore, the optimal trust-region step is the boundary step in the negative gradient direction:\n$$\np^{\\star} = -\\Delta = -0.1.\n$$", "answer": "$$\\boxed{-0.1}$$"}, {"introduction": "Having grasped the basic concept in one dimension, we now move to a more practical scenario in computational finance: portfolio optimization in two dimensions. This exercise introduces the dogleg method, an elegant and efficient way to approximate the solution to the trust-region subproblem by tracing a path between the steepest-descent direction (the Cauchy point) and the full Newton step [@problem_id:2444773]. By working through a concrete financial example, you will gain a deeper, more visual understanding of how this popular method navigates the optimization landscape to find a robust step.", "id": "2444773", "problem": "Consider a two-asset meanâ€“variance objective used in computational finance. Let the unconstrained objective in weights $w \\in \\mathbb{R}^{2}$ be\n$$\nf(w) \\;=\\; \\frac{\\gamma}{2}\\, w^{\\top} \\Sigma \\, w \\;-\\; \\mu^{\\top} w,\n$$\nwith risk-aversion parameter $\\gamma = 2$, expected excess returns $\\mu = \\begin{pmatrix}0.5 \\\\ 0.2\\end{pmatrix}$, and a symmetric positive definite matrix\n$$\n\\Sigma \\;=\\; \\begin{pmatrix}2 & 1 \\\n$$4pt] 1 & 3\\end{pmatrix}.\n$$\nAt the current iterate $w^{0} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$, consider the second-order model\n$$\nm(s) \\;=\\; f(w^{0}) \\;+\\; \\nabla f(w^{0})^{\\top} s \\;+\\; \\frac{1}{2}\\, s^{\\top} \\nabla^{2} f(w^{0}) \\, s,\n$$\nand an Euclidean trust region $\\{\\, s \\in \\mathbb{R}^{2} : \\|s\\|_{2} \\le \\Delta \\,\\}$ with radius $\\Delta = 0.11$. Using the dogleg trust-region strategy applied to $m(s)$, determine the unique scalar $\\tau \\in [0,1]$ such that the dogleg step lies exactly on the trust-region boundary when the Cauchy point is strictly inside the trust region and the full Newton step is strictly outside it.\n\nGive your final value of $\\tau$ as a decimal number rounded to four significant figures.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Objective function: $f(w) = \\frac{\\gamma}{2} w^{\\top} \\Sigma w - \\mu^{\\top} w$, for $w \\in \\mathbb{R}^{2}$.\n- Risk-aversion parameter: $\\gamma = 2$.\n- Expected excess returns: $\\mu = \\begin{pmatrix} 0.5 \\\\ 0.2 \\end{pmatrix}$.\n- Covariance matrix: $\\Sigma = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}$.\n- Current iterate: $w^{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n- Quadratic model: $m(s) = f(w^{0}) + \\nabla f(w^{0})^{\\top} s + \\frac{1}{2} s^{\\top} \\nabla^{2} f(w^{0}) s$.\n- Trust region: $\\{ s \\in \\mathbb{R}^{2} : \\|s\\|_{2} \\le \\Delta \\}$.\n- Trust-region radius: $\\Delta = 0.11$.\n- Method: Dogleg trust-region strategy.\n- Conditions: The Cauchy point is strictly inside the trust region and the full Newton step is strictly outside it.\n- Objective: Find the unique scalar $\\tau \\in [0,1]$ such that the dogleg step lies on the trust-region boundary.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, rooted in the standard theory of numerical optimization and its application to computational finance (mean-variance optimization). The matrix $\\Sigma$ is symmetric. Its eigenvalues are the roots of $(\\lambda-2)(\\lambda-3) - 1 = 0$, which is $\\lambda^2 - 5\\lambda + 5 = 0$. The roots are $\\lambda = \\frac{5 \\pm \\sqrt{5}}{2}$, which are both positive, so $\\Sigma$ is positive definite as required for a covariance matrix. The problem is well-posed, providing all necessary data and constraints to determine a unique solution for $\\tau$. The language is objective and precise. No flaws are identified.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be derived.\n\n**Derivation of Solution**\nThe dogleg method constructs a path to approximate the minimizer of the quadratic model $m(s)$. This requires the gradient and Hessian of the objective function $f(w)$ at the current iterate $w^0$.\n\nThe objective function is $f(w) = \\frac{\\gamma}{2} w^{\\top} \\Sigma w - \\mu^{\\top} w$.\nThe gradient is $\\nabla f(w) = \\gamma \\Sigma w - \\mu$.\nThe Hessian is $\\nabla^2 f(w) = \\gamma \\Sigma$.\n\nAt the iterate $w^0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, the gradient $g$ and Hessian $B$ of the model are:\n$$\ng = \\nabla f(w^0) = \\gamma \\Sigma w^0 - \\mu = -\\mu = -\\begin{pmatrix} 0.5 \\\\ 0.2 \\end{pmatrix} = \\begin{pmatrix} -0.5 \\\\ -0.2 \\end{pmatrix}\n$$\n$$\nB = \\nabla^2 f(w^0) = \\gamma \\Sigma = 2 \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} = \\begin{pmatrix} 4 & 2 \\\\ 2 & 6 \\end{pmatrix}\n$$\nThe quadratic model is $m(s) = g^{\\top}s + \\frac{1}{2}s^{\\top}B s$, since $f(w^0) = 0$.\n\nThe dogleg path is constructed using two points: the Cauchy point $s_C$ and the Newton step $s_N$.\n\nFirst, we find the unconstrained Cauchy step, $s_{UC}$, which minimizes $m(s)$ along the steepest descent direction $-g$:\n$$\ns_{UC} = -\\alpha g, \\quad \\text{where} \\quad \\alpha = \\frac{g^{\\top}g}{g^{\\top}Bg}\n$$\nWe compute the necessary scalars:\n$$\ng^{\\top}g = (-0.5)^2 + (-0.2)^2 = 0.25 + 0.04 = 0.29\n$$\n$$\ng^{\\top}Bg = \\begin{pmatrix} -0.5 & -0.2 \\end{pmatrix} \\begin{pmatrix} 4 & 2 \\\\ 2 & 6 \\end{pmatrix} \\begin{pmatrix} -0.5 \\\\ -0.2 \\end{pmatrix} = \\begin{pmatrix} -0.5 & -0.2 \\end{pmatrix} \\begin{pmatrix} -2.4 \\\\ -2.2 \\end{pmatrix} = 1.2 + 0.44 = 1.64\n$$\nSo, $\\alpha = \\frac{0.29}{1.64} = \\frac{29}{164}$.\nThe unconstrained Cauchy step is:\n$$\ns_{UC} = -\\frac{29}{164} \\begin{pmatrix} -0.5 \\\\ -0.2 \\end{pmatrix} = \\frac{29}{164} \\begin{pmatrix} 0.5 \\\\ 0.2 \\end{pmatrix}\n$$\nThe squared norm of $s_{UC}$ is $\\|s_{UC}\\|^2_2 = \\alpha^2 (g^{\\top}g) = (\\frac{29}{164})^2 (0.29) = \\frac{243.89}{26896} \\approx 0.00906796$.\nThus, $\\|s_{UC}\\|_2 \\approx \\sqrt{0.00906796} \\approx 0.095226$. Since $\\|s_{UC}\\|_2 < \\Delta = 0.11$, the condition that the Cauchy point is strictly inside the trust region is satisfied. The Cauchy point is $s_C = s_{UC}$.\n\nNext, we compute the Newton step, $s_N$, which is the unconstrained minimizer of $m(s)$.\n$$\ns_N = -B^{-1}g\n$$\nThe inverse of $B$ is:\n$$\nB^{-1} = \\frac{1}{4 \\cdot 6 - 2 \\cdot 2} \\begin{pmatrix} 6 & -2 \\\\ -2 & 4 \\end{pmatrix} = \\frac{1}{20} \\begin{pmatrix} 6 & -2 \\\\ -2 & 4 \\end{pmatrix} = \\begin{pmatrix} 0.3 & -0.1 \\\\ -0.1 & 0.2 \\end{pmatrix}\n$$\n$$\ns_N = -\\begin{pmatrix} 0.3 & -0.1 \\\\ -0.1 & 0.2 \\end{pmatrix} \\begin{pmatrix} -0.5 \\\\ -0.2 \\end{pmatrix} = -\\begin{pmatrix} -0.15+0.02 \\\\ 0.05-0.04 \\end{pmatrix} = -\\begin{pmatrix} -0.13 \\\\ 0.01 \\end{pmatrix} = \\begin{pmatrix} 0.13 \\\\ -0.01 \\end{pmatrix}\n$$\nThe squared norm of $s_N$ is $\\|s_N\\|^2_2 = (0.13)^2 + (-0.01)^2 = 0.0169 + 0.0001 = 0.017$.\nThus, $\\|s_N\\|_2 = \\sqrt{0.017} \\approx 0.13038$. Since $\\|s_N\\|_2 > \\Delta = 0.11$, the condition that the Newton step is strictly outside the trust region is satisfied.\n\nThe dogleg step, $s_D$, is the point on the path from the origin to $s_C$ and then to $s_N$ that lies on the trust-region boundary. Given that $\\|s_C\\|_2 < \\Delta$ and $\\|s_N\\|_2 > \\Delta$, the step $s_D$ must lie on the line segment connecting $s_C$ and $s_N$. We can parameterize any point on this segment as $s(\\tau) = s_C + \\tau(s_N - s_C)$ for a scalar $\\tau \\in [0,1]$.\nWe need to find the specific $\\tau$ such that $\\|s(\\tau)\\|_2 = \\Delta$. Squaring both sides:\n$$\n\\|s_C + \\tau(s_N - s_C)\\|_2^2 = \\Delta^2\n$$\nExpanding this gives a quadratic equation in $\\tau$:\n$$\n\\|s_N - s_C\\|_2^2 \\tau^2 + 2 s_C^{\\top}(s_N - s_C) \\tau + (\\|s_C\\|_2^2 - \\Delta^2) = 0\n$$\nLet the coefficients be $a$, $b$, and $c$. We compute them using high-precision values:\n$d_1 = \\|s_C\\|_2^2 = (\\frac{29}{164})^2 (0.29) \\approx 0.0090679655$\n$d_3 = \\|s_N\\|_2^2 = 0.017$\n$d_2 = s_C^{\\top}s_N = \\left(\\frac{29}{164}\\begin{pmatrix} 0.5 \\\\ 0.2 \\end{pmatrix}\\right)^{\\top} \\begin{pmatrix} 0.13 \\\\ -0.01 \\end{pmatrix} = \\frac{29}{164}(0.5 \\cdot 0.13 + 0.2 \\cdot (-0.01)) = \\frac{29}{164}(0.065-0.002) = \\frac{29 \\cdot 0.063}{164} \\approx 0.0111402439$\n\nThe coefficients of the quadratic equation $a\\tau^2+b\\tau+c=0$ are:\n$a = \\|s_N - s_C\\|_2^2 = \\|s_N\\|_2^2 - 2 s_C^{\\top}s_N + \\|s_C\\|_2^2 = d_3 - 2d_2 + d_1$\n$a \\approx 0.017 - 2(0.0111402439) + 0.0090679655 \\approx 0.0037874777$\n$b = 2 s_C^{\\top}(s_N - s_C) = 2(s_C^{\\top}s_N - \\|s_C\\|_2^2) = 2(d_2 - d_1)$\n$b \\approx 2(0.0111402439 - 0.0090679655) \\approx 0.0041445568$\n$c = \\|s_C\\|_2^2 - \\Delta^2 = d_1 - (0.11)^2$\n$c \\approx 0.0090679655 - 0.0121 = -0.0030320345$\n\nWe solve for $\\tau$ using the quadratic formula $\\tau = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$b^2 - 4ac \\approx (0.0041445568)^2 - 4(0.0037874777)(-0.0030320345) \\approx 1.717734 \\times 10^{-5} + 4.593721 \\times 10^{-5} = 6.311455 \\times 10^{-5}$\n$\\sqrt{b^2 - 4ac} \\approx 0.007944466$\n$$\n\\tau = \\frac{-0.0041445568 \\pm 0.007944466}{2(0.0037874777)} = \\frac{-0.0041445568 \\pm 0.007944466}{0.0075749554}\n$$\nWe require $\\tau \\in [0,1]$, so we take the positive root:\n$$\n\\tau = \\frac{-0.0041445568 + 0.007944466}{0.0075749554} = \\frac{0.0037999092}{0.0075749554} \\approx 0.501641\n$$\nRounding to four significant figures, we get $\\tau \\approx 0.5016$.", "answer": "$$\n\\boxed{0.5016}\n$$"}, {"introduction": "Solving the subproblem is only one part of the trust-region algorithm; the other crucial part is adapting the size of the trust region itself. This final practice focuses on this adaptive mechanism, which is the key to the method's robustness [@problem_id:2444749]. You will evaluate how well our quadratic model predicted the actual function's behavior by calculating the acceptance ratio $\\rho_k$, and based on this \"reality check,\" decide whether to shrink or expand the trust-region radius $\\Delta_k$ for the next iteration. This process prevents the algorithm from taking poor steps when the model is not a good local approximation to the true objective function.", "id": "2444749", "problem": "Consider a calibration subproblem that arises in Maximum Likelihood Estimation (MLE) for a binary choice model in computational finance. Let the per-observation negative log-likelihood for a Bernoulli outcome be modeled as a function of a single scalar index $x$ by\n$$\nf(x) \\;=\\; \\ln\\!\\big(1+\\exp(x)\\big) \\;-\\; \\bar{y}\\,x,\n$$\nwhere $\\bar{y}\\in(0,1)$ is the sample mean of observed outcomes. At trust-region iteration $k$, suppose the current iterate is $x_k = 0$, and the sample mean is $\\bar{y} = 0.51$. The trust-region quadratic model about $x_k$ is\n$$\nm_k(p) \\;=\\; f(x_k) \\;+\\; g_k\\,p \\;+\\; \\tfrac{1}{2}\\,B_k\\,p^2,\n$$\nwith gradient $g_k = \\nabla f(x_k)$ and a symmetric Hessian approximation $B_k$. Assume $B_k = 0.01$, which severely underestimates the true curvature at $x_k$. The trust-region radius is $\\delta_k = 1$, and the step used is the Cauchy point along the negative gradient direction, namely in one dimension\n$$\np_k \\;=\\; \\delta_k\\,\\mathrm{sign}(-g_k).\n$$\nDefine the trust-region acceptance ratio\n$$\n\\rho_k \\;=\\; \\frac{f(x_k) - f(x_k + p_k)}{m_k(0) - m_k(p_k)}.\n$$\nThe trust-region radius update policy is\n- if $\\rho_k < 0$, set $\\delta_{k+1} = 0.1\\,\\delta_k$,\n- if $0 \\le \\rho_k < 0.25$, set $\\delta_{k+1} = 0.5\\,\\delta_k$,\n- if $\\rho_k \\ge 0.25$, set $\\delta_{k+1} = 2\\,\\delta_k$.\n\nCompute $\\delta_{k+1}$. Express your final answer as a pure number. No rounding is required.", "solution": "The problem requires the computation of the next trust-region radius, $\\delta_{k+1}$, based on the current iteration's data and a specified update rule. This requires the calculation of the trust-region acceptance ratio, $\\rho_k$.\n\nThe acceptance ratio is defined as:\n$$\n\\rho_k \\;=\\; \\frac{f(x_k) - f(x_k + p_k)}{m_k(0) - m_k(p_k)}\n$$\nThis ratio compares the actual reduction in the objective function, $ared_k = f(x_k) - f(x_k + p_k)$, to the predicted reduction from the quadratic model, $pred_k = m_k(0) - m_k(p_k)$. We must compute these two quantities.\n\nFirst, let us determine the quantities related to the current iterate $x_k=0$. The objective function is given by:\n$$\nf(x) \\;=\\; \\ln(1+\\exp(x)) - \\bar{y}x\n$$\nWith the sample mean $\\bar{y} = 0.51$, the function is:\n$$\nf(x) \\;=\\; \\ln(1+\\exp(x)) - 0.51x\n$$\nAt the current iterate $x_k=0$, the function value is:\n$$\nf(x_k) = f(0) = \\ln(1+\\exp(0)) - 0.51(0) = \\ln(1+1) = \\ln(2)\n$$\nTo find the step $p_k$, we first compute the gradient $g_k = \\nabla f(x_k) = f'(x_k)$. The derivative of $f(x)$ is:\n$$\nf'(x) = \\frac{d}{dx} \\left( \\ln(1+\\exp(x)) - 0.51x \\right) = \\frac{\\exp(x)}{1+\\exp(x)} - 0.51\n$$\nEvaluating the gradient at $x_k=0$:\n$$\ng_k = f'(0) = \\frac{\\exp(0)}{1+\\exp(0)} - 0.51 = \\frac{1}{1+1} - 0.51 = 0.5 - 0.51 = -0.01\n$$\nThe step $p_k$ is given as the Cauchy point, which for this one-dimensional problem is specified as $p_k = \\delta_k\\,\\mathrm{sign}(-g_k)$. With the trust-region radius $\\delta_k=1$:\n$$\np_k = 1 \\cdot \\mathrm{sign}(-(-0.01)) = \\mathrm{sign}(0.01) = 1\n$$\nThe new point is $x_k + p_k = 0 + 1 = 1$.\n\nNow, we compute the actual reduction, $ared_k = f(x_k) - f(x_k + p_k)$. We have $f(x_k) = \\ln(2)$. The function value at the new point is:\n$$\nf(x_k + p_k) = f(1) = \\ln(1+\\exp(1)) - 0.51(1) = \\ln(1+e) - 0.51\n$$\nThe actual reduction is:\n$$\nared_k = \\ln(2) - \\left( \\ln(1+e) - 0.51 \\right) = \\ln(2) - \\ln(1+e) + 0.51\n$$\nNext, we compute the predicted reduction, $pred_k = m_k(0) - m_k(p_k)$. The quadratic model is:\n$$\nm_k(p) = f(x_k) + g_k p + \\frac{1}{2} B_k p^2\n$$\nAt $p=0$, we have $m_k(0) = f(x_k)$. The predicted reduction is therefore:\n$$\npred_k = m_k(0) - m_k(p_k) = f(x_k) - \\left( f(x_k) + g_k p_k + \\frac{1}{2} B_k p_k^2 \\right) = -g_k p_k - \\frac{1}{2} B_k p_k^2\n$$\nUsing the values $g_k = -0.01$, $p_k=1$, and the given Hessian approximation $B_k=0.01$:\n$$\npred_k = -(-0.01)(1) - \\frac{1}{2}(0.01)(1)^2 = 0.01 - 0.005 = 0.005\n$$\nThe acceptance ratio is:\n$$\n\\rho_k = \\frac{ared_k}{pred_k} = \\frac{\\ln(2) - \\ln(1+e) + 0.51}{0.005}\n$$\nTo apply the trust-region radius update rule, we must determine which range $\\rho_k$ falls into. This requires determining the sign of the numerator, $N = \\ln(2) - \\ln(1+e) + 0.51$.\nThe denominator $0.005$ is positive. The sign of $\\rho_k$ is the sign of $N$.\nWe can rewrite the numerator as $N = \\ln\\left(\\frac{2}{1+e}\\right) + 0.51$.\nLet us establish bounds for the terms. We know $e \\approx 2.718$.\nThus, $1+e \\approx 3.718$.\nThe term $\\ln(2) \\approx 0.693$.\nThe term $\\ln(1+e) = \\ln(1+\\exp(1)) > \\ln(1+2.7) = \\ln(3.7)$. Since $e < 3.7 < e^2$, we have $1 = \\ln(e) < \\ln(3.7) < 2$. More precisely, $\\ln(3.7) \\approx 1.308$.\nSo, $\\ln(2) - \\ln(1+e)$ is approximately $0.693 - 1.308 = -0.615$.\nThe numerator is $N \\approx -0.615 + 0.51 = -0.105$. The numerator is negative.\nA more formal argument: We wish to prove $f(1) > f(0)$, which is equivalent to $ared_k < 0$. This means we must show $\\ln(1+e) - 0.51 > \\ln(2)$, or $\\ln\\left(\\frac{1+e}{2}\\right) > 0.51$. This is equivalent to $\\frac{1+e}{2} > \\exp(0.51)$.\nUsing the known bounds $2.71 < e < 2.72$, we have $3.71 < 1+e < 3.72$, so $1.855 < \\frac{1+e}{2} < 1.86$.\nFor the other side, using the inequality $e^x < \\frac{1}{1-x}$ for $x \\in (0,1)$, we have $\\exp(0.51) < \\frac{1}{1-0.51} = \\frac{1}{0.49} \\approx 2.04$. This bound is not tight enough.\nUsing $e^x > 1+x$, we have $e^{0.51} > 1.51$.\nLet us use a tighter bound from Taylor series: $e^x \\approx 1+x+\\frac{x^2}{2}$.\n$e^{0.51} \\approx 1 + 0.51 + \\frac{0.51^2}{2} = 1.51 + \\frac{0.2601}{2} = 1.51+0.13005 = 1.64005$.\nThe value of $\\frac{1+e}{2} \\approx 1.859$ is clearly greater than $1.64$.\nHence, $f(1) > f(0)$, which implies that the actual reduction $ared_k = f(0)-f(1)$ is negative.\nSince $ared_k < 0$ and $pred_k = 0.005 > 0$, the ratio $\\rho_k = \\frac{ared_k}{pred_k}$ is negative.\n\nThe trust-region radius update policy is:\n- if $\\rho_k < 0$, set $\\delta_{k+1} = 0.1\\,\\delta_k$,\n- if $0 \\le \\rho_k < 0.25$, set $\\delta_{k+1} = 0.5\\,\\delta_k$,\n- if $\\rho_k \\ge 0.25$, set $\\delta_{k+1} = 2\\,\\delta_k$.\n\nAs we have established that $\\rho_k < 0$, the first rule applies.\nGiven $\\delta_k = 1$, the new radius is:\n$$\n\\delta_{k+1} = 0.1 \\cdot \\delta_k = 0.1 \\cdot 1 = 0.1\n$$\nThe problem is now solved. The next trust-region radius is $0.1$.", "answer": "$$\n\\boxed{0.1}\n$$"}]}