{"hands_on_practices": [{"introduction": "Before diving into complex coding, it's crucial to build intuition for how MCMC samplers behave. The efficiency of a Metropolis-Hastings algorithm hinges on a delicate balance, primarily governed by the proposal step size. This exercise asks you to think critically about the consequences of poorly chosen step sizes, a common pitfall in practice ([@problem_id:2408760]). Understanding the relationship between step size, acceptance rate, and autocorrelation is fundamental to diagnosing the performance of your chains and ensuring your posterior estimates are reliable.", "id": "2408760", "problem": "Consider Bayesian estimation of a scalar structural parameter $\\theta$ in a likelihood-based asset-pricing model with a proper posterior density $\\pi(\\theta)$ that is unimodal and roughly bell-shaped. You run a random-walk Metropolis Markov chain Monte Carlo (MCMC) algorithm with symmetric Gaussian proposals,\n$$\n\\theta' \\,=\\, \\theta_t \\,+\\, \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, s^2),\n$$\nand acceptance probability\n$$\n\\alpha(\\theta_t,\\theta') \\,=\\, \\min\\!\\left\\{\\,1,\\, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)} \\,\\right\\}.\n$$\nFor two separate long runs of length $T$ under stationarity, you choose (i) a proposal scale $s$ that is too large relative to the posterior curvature, and (ii) a proposal scale $s$ that is too small relative to the posterior curvature. Let $\\rho(k)$ denote the lag-$k$ autocorrelation function (ACF) of the Markov chain $\\{\\theta_t\\}_{t=1}^T$, defined by\n$$\n\\rho(k) \\,=\\, \\frac{\\mathrm{Cov}(\\theta_t, \\theta_{t+k})}{\\mathrm{Var}(\\theta_t)}, \\quad k \\in \\{1,2,\\ldots\\}.\n$$\nWhich statement best characterizes the qualitative behavior of the empirical ACF and acceptance rates across these two regimes, and the resulting implications for effective sample size?\n\nA. In both regimes, $\\rho(1)$ is large and positive with slow decay in $k$, but the acceptance rates differ: with $s$ too large, acceptance is very low and the chain exhibits repeated states; with $s$ too small, acceptance is very high but successive states are very close. In both cases, the integrated autocorrelation time is large and the effective sample size is small, improving only at intermediate $s$.\n\nB. With $s$ too large, the chain frequently bounces back and forth, yielding negative $\\rho(1)$; with $s$ too small, most moves are accepted, so $\\rho(k) \\approx 0$ for all $k \\ge 1$ and the effective sample size is maximized.\n\nC. The ACF decays fastest when $s$ is extremely large because large jumps decorrelate the chain, and acceptance is high in that case, leading to the largest effective sample size.\n\nD. For a stationary run, the ACF $\\rho(k)$ is invariant to the choice of $s$; only the burn-in length is affected by $s$.\n\nE. With symmetric proposals, the acceptance rate equals $0.5$ for any $s$, implying that any observed differences in $\\rho(k)$ across choices of $s$ are due to Monte Carlo error rather than step-size selection.", "solution": "The problem asks for a qualitative analysis of a random-walk Metropolis (RWM) algorithm's performance under two extreme choices for the proposal scale, $s$. The performance is to be characterized by the acceptance rate, the autocorrelation function (ACF) of the generated chain, and the resulting effective sample size (ESS).\n\nThe objective of any Markov chain Monte Carlo (MCMC) algorithm is to generate a sequence of draws $\\{\\theta_t\\}_{t=1}^T$ whose distribution converges to a target distribution, in this case the posterior $\\pi(\\theta)$. For the estimates derived from this chain (e.g., the posterior mean $\\frac{1}{T}\\sum_{t=1}^T \\theta_t$) to be precise, we require a large effective sample size. The ESS is defined as\n$$\n\\text{ESS} = \\frac{T}{1 + 2\\sum_{k=1}^{\\infty} \\rho(k)} = \\frac{T}{\\tau}\n$$\nwhere $T$ is the nominal sample size and $\\tau = 1 + 2\\sum_{k=1}^{\\infty} \\rho(k)$ is the integrated autocorrelation time (IAT). To maximize ESS for a fixed chain length $T$, one must minimize the IAT. This is achieved when the autocorrelations $\\rho(k)$ are small and decay to zero rapidly as the lag $k$ increases. The efficiency of the sampler is thus inversely related to the persistence in the chain.\n\nThe RWM algorithm uses a proposal $\\theta' = \\theta_t + \\varepsilon$ with $\\varepsilon \\sim \\mathcal{N}(0, s^2)$. The parameter $s$ is a crucial tuning parameter that governs the algorithm's efficiency. Let us analyze the two specified regimes.\n\nCase (i): The proposal scale $s$ is too large.\nIn this regime, the proposed jump $\\varepsilon$ is large. Since the target posterior $\\pi(\\theta)$ is unimodal and bell-shaped, it concentrates its mass in a relatively small region around the mode. A large jump from the current state $\\theta_t$ (which, under stationarity, is likely in a region of high posterior density) will very probably land the proposal $\\theta'$ in the tails of the distribution, where $\\pi(\\theta')$ is very small.\nConsequently, the acceptance ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ will be much less than $1$. The acceptance probability $\\alpha(\\theta_t, \\theta') = \\min\\{1, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)}\\}$ will therefore be very low.\nMost proposals are rejected, which means the chain remains at its current state for many consecutive iterations: $\\theta_{t+1} = \\theta_t$. This behavior—getting \"stuck\"—induces extremely high positive correlation between consecutive states. Thus, the lag-$1$ autocorrelation $\\rho(1)$ will be very close to $1$, and the entire ACF $\\rho(k)$ will decay exceedingly slowly. This leads to a very large IAT and a very small ESS. The chain explores the posterior space very inefficiently.\n\nCase (ii): The proposal scale $s$ is too small.\nIn this regime, the proposed jump $\\varepsilon$ is small. The proposal $\\theta'$ will be very close to the current state $\\theta_t$. As long as the posterior density $\\pi(\\theta)$ is continuous (which is a standard assumption), $\\pi(\\theta')$ will be very close to $\\pi(\\theta_t)$.\nThe acceptance ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ will be very close to $1$. The acceptance probability $\\alpha(\\theta_t, \\theta')$ will therefore be very high, approaching $1$ as $s \\to 0$.\nAlthough most proposals are accepted, each step is minuscule. The chain moves through the parameter space like a slow diffusion process. $\\theta_{t+1}$ will be only marginally different from $\\theta_t$. This again implies that consecutive states are highly correlated. The lag-$1$ autocorrelation $\\rho(1)$ will again be very close to $1$, and the ACF $\\rho(k)$ will decay very slowly. This also leads to a large IAT and a small ESS. The chain explores the posterior space very inefficiently, but for a different reason than in Case (i).\n\nIn summary, both extremes of the proposal scale $s$ are detrimental to sampling efficiency. The highest efficiency (minimal IAT, maximal ESS) is achieved for an intermediate value of $s$ that balances the acceptance rate and the step size, allowing the chain to explore the full support of the posterior distribution effectively. Optimal acceptance rates are known to be approximately $0.44$ for one-dimensional problems like this one.\n\nNow, we evaluate the provided options.\n\nA. In both regimes, $\\rho(1)$ is large and positive with slow decay in $k$, but the acceptance rates differ: with $s$ too large, acceptance is very low and the chain exhibits repeated states; with $s$ too small, acceptance is very high but successive states are very close. In both cases, the integrated autocorrelation time is large and the effective sample size is small, improving only at intermediate $s$.\nThis statement accurately summarizes the behavior in both regimes as derived above. It correctly identifies high positive autocorrelation as the common pathology, but correctly distinguishes the mechanisms: low acceptance and getting stuck for large $s$, and high acceptance but tiny steps for small $s$. It correctly concludes that both scenarios lead to poor ESS, which is optimized at an intermediate $s$. This statement is consistent with the theory of MCMC.\nVerdict: **Correct**.\n\nB. With $s$ too large, the chain frequently bounces back and forth, yielding negative $\\rho(1)$; with $s$ too small, most moves are accepted, so $\\rho(k) \\approx 0$ for all $k \\ge 1$ and the effective sample size is maximized.\nThis statement is incorrect on multiple grounds. First, for RWM, large $s$ does not lead to \"bouncing back and forth\" and negative $\\rho(1)$. It leads to rejections and staying put, which produces high *positive* autocorrelation. Negative autocorrelation is more characteristic of other samplers, like Gibbs or HMC with specific parameterizations. Second, for small $s$, the chain moves slowly, so $\\theta_t$ and $\\theta_{t+k}$ are highly correlated for small $k$, meaning $\\rho(k)$ is close to $1$, not $0$. This minimizes, not maximizes, the effective sample size.\nVerdict: **Incorrect**.\n\nC. The ACF decays fastest when $s$ is extremely large because large jumps decorrelate the chain, and acceptance is high in that case, leading to the largest effective sample size.\nThis statement is factually wrong. When $s$ is extremely large, the acceptance rate is extremely *low*, not high. While a successful large jump is decorrelating, the chain's behavior is dominated by the far more frequent event of rejection. The result is a slow-mixing chain with an ACF that decays very slowly, not fastest. This leads to the smallest, not largest, ESS.\nVerdict: **Incorrect**.\n\nD. For a stationary run, the ACF $\\rho(k)$ is invariant to the choice of $s$; only the burn-in length is affected by $s$.\nThis is fundamentally incorrect. The proposal scale $s$ defines the transition kernel of the Markov chain. While the stationary distribution $\\pi(\\theta)$ is invariant to $s$ (by construction of the M-H algorithm), the dynamic properties of the chain, such as its rate of convergence and its autocorrelation structure under stationarity, are critically dependent on $s$. Tuning $s$ is precisely the exercise of optimizing these dynamic properties, which are measured by the ACF.\nVerdict: **Incorrect**.\n\nE. With symmetric proposals, the acceptance rate equals $0.5$ for any $s$, implying that any observed differences in $\\rho(k)$ across choices of $s$ are due to Monte Carlo error rather than step-size selection.\nThis statement is false. The acceptance rate is not a constant $0.5$. It is a function of the proposal scale $s$ via the ratio $\\pi(\\theta')/\\pi(\\theta_t)$. There is a well-known theoretical literature on optimal acceptance rates, which are not $0.5$ (e.g., $\\approx 0.234$ in high dimensions, $\\approx 0.44$ in one dimension), but these are *targets* to be achieved by *tuning* $s$, not fixed constants. Observed differences in $\\rho(k)$ are a direct and real consequence of the choice of $s$.\nVerdict: **Incorrect**.\n\nBased on this rigorous analysis, only option A provides a correct and complete description of the phenomenon.", "answer": "$$\\boxed{A}$$"}, {"introduction": "Now let's move from theory to a complete, hands-on application. A common task in data analysis is to assess whether a sequence of observations is independent or exhibits serial correlation. This practice guides you through using MCMC to perform a Bayesian test for first-order autocorrelation ([@problem_id:2408736]). You will implement a Gibbs sampler, a particularly efficient type of MCMC algorithm, to estimate the posterior distribution of the autoregressive parameter $\\rho$ and use its credible interval to evaluate the evidence for dependence.", "id": "2408736", "problem": "A financial computing system produces sequences of real-valued pseudo-random numbers to be used in simulation-based asset pricing. To assess whether a given sequence is compatible with independence in the sense of having no first-order linear dependence, consider the zero-intercept Autoregressive model of order one (AR(1)) on the centered series. Let the observed sequence be denoted by $\\{y_t\\}_{t=1}^{T}$, and define the centered series $\\{x_t\\}_{t=1}^{T}$ by $x_t = y_t - \\bar{y}$, where $\\bar{y} = T^{-1}\\sum_{t=1}^{T} y_t$. The AR(1) model is\n$$\nx_t = \\rho\\, x_{t-1} + \\varepsilon_t,\\quad \\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2),\\quad t=2,\\dots,T,\n$$\nwith the stationarity restriction $|\\rho|<1$. Assume the following prior specification: $\\rho$ has a uniform prior density on $(-1,1)$ and $\\sigma^2$ has an Inverse-Gamma prior with shape $a_0=2$ and scale $b_0=1$.\n\nFor each data sequence below, treat $\\{y_t\\}_{t=1}^{T}$ as observed data. Using the model and priors above, approximate the posterior distribution of $\\rho$ and decide whether the central credible interval with probability mass $0.99$ for $\\rho$ contains $0$. For each sequence, output a boolean indicating whether $0$ lies within the equal-tailed credible interval of level $0.99$ for $\\rho$.\n\nTest suite (each sequence must be generated internally by your program exactly as specified):\n\n- Case 1 (independence benchmark):\n  - Length $T=400$.\n  - Data-generating process: $y_t \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)$.\n  - Pseudorandom seed: set to the integer $12345$ before generating the sequence.\n\n- Case 2 (strong positive linear dependence):\n  - Length $T=600$.\n  - Data-generating process: $y_t = \\rho^\\star y_{t-1} + \\eta_t$ with $\\rho^\\star=0.85$, $\\eta_t \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)$, and $y_1=0$.\n  - Pseudorandom seed: set to the integer $2024$ before generating the sequence.\n\n- Case 3 (weak positive linear dependence with short sample):\n  - Length $T=60$.\n  - Data-generating process: $y_t = \\rho^\\star y_{t-1} + \\eta_t$ with $\\rho^\\star=0.20$, $\\eta_t \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)$, and $y_1=0$.\n  - Pseudorandom seed: set to the integer $7$ before generating the sequence.\n\n- Case 4 (moderate negative linear dependence):\n  - Length $T=500$.\n  - Data-generating process: $y_t = \\rho^\\star y_{t-1} + \\eta_t$ with $\\rho^\\star=-0.60$, $\\eta_t \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)$, and $y_1=0$.\n  - Pseudorandom seed: set to the integer $424242$ before generating the sequence.\n\nRequired final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above. For example, the output must have the form $[b_1,b_2,b_3,b_4]$, where each $b_i$ is either the literal True or False. No additional text or spaces are allowed in the output line.", "solution": "The problem requires a Bayesian analysis of a first-order autoregressive model, AR(1), to test for the presence of serial correlation in a given time series. The analysis must be performed for four distinct data sequences.\n\nThe model is defined for a centered time series $\\{x_t\\}_{t=1}^T$, where $x_t = y_t - \\bar{y}$ and $\\bar{y}$ is the sample mean of the observed series $\\{y_t\\}_{t=1}^T$. The AR(1) specification is:\n$$\nx_t = \\rho x_{t-1} + \\varepsilon_t, \\quad t=2, \\dots, T\n$$\nThe error terms $\\varepsilon_t$ are assumed to be independent and identically distributed as a Normal distribution with mean $0$ and variance $\\sigma^2$, i.e., $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$. The autoregressive parameter $\\rho$ is constrained to the interval $(-1, 1)$ to ensure stationarity.\n\nThe objective is to compute the posterior distribution of $\\rho$ and determine if the value $0$, which corresponds to no linear dependence, is contained within the $99\\%$ equal-tailed credible interval. This requires a full Bayesian specification, including the likelihood of the data and prior distributions for the parameters $\\rho$ and $\\sigma^2$.\n\nThe likelihood function, conditional on the first observation $x_1$, is derived from the Normal distribution of the error terms $\\varepsilon_t = x_t - \\rho x_{t-1}$:\n$$\nL(\\rho, \\sigma^2 | \\mathbf{x}) = \\prod_{t=2}^{T} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x_t - \\rho x_{t-1})^2}{2\\sigma^2} \\right) \\propto (\\sigma^2)^{-(T-1)/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{t=2}^{T} (x_t - \\rho x_{t-1})^2 \\right)\n$$\nThe problem specifies the following prior distributions:\n1.  A uniform prior for $\\rho$ on the interval $(-1, 1)$: $p(\\rho) = \\frac{1}{2} \\mathbb{I}_{(-1,1)}(\\rho)$, where $\\mathbb{I}$ is the indicator function.\n2.  An Inverse-Gamma prior for $\\sigma^2$ with shape parameter $a_0 = 2$ and scale parameter $b_0 = 1$: $p(\\sigma^2) \\sim \\text{Inv-Gamma}(a_0, b_0)$. Its probability density function is $p(\\sigma^2) \\propto (\\sigma^2)^{-(a_0+1)} \\exp(-b_0/\\sigma^2)$.\n\nAssuming prior independence between $\\rho$ and $\\sigma^2$, the joint prior is $p(\\rho, \\sigma^2) = p(\\rho) p(\\sigma^2)$. By Bayes' theorem, the joint posterior distribution is proportional to the product of the likelihood and the joint prior:\n$$\np(\\rho, \\sigma^2 | \\mathbf{x}) \\propto L(\\rho, \\sigma^2 | \\mathbf{x}) p(\\rho) p(\\sigma^2)\n$$\n$$\np(\\rho, \\sigma^2 | \\mathbf{x}) \\propto (\\sigma^2)^{-\\left(\\frac{T-1}{2} + a_0 + 1\\right)} \\exp\\left(-\\frac{1}{\\sigma^2}\\left[b_0 + \\frac{1}{2}\\sum_{t=2}^{T} (x_t - \\rho x_{t-1})^2\\right]\\right) \\mathbb{I}_{(-1,1)}(\\rho)\n$$\nThis joint posterior distribution does not have a simple analytical form from which the marginal posterior of $\\rho$, $p(\\rho|\\mathbf{x})$, can be easily derived. Therefore, a numerical approximation is necessary. A Gibbs sampler, a type of Markov chain Monte Carlo (MCMC) algorithm, is a suitable method. It works by iteratively drawing samples from the full conditional posterior distributions of each parameter.\n\nThe full conditional distribution for $\\sigma^2$ is found by treating all other variables in the joint posterior as constants:\n$$\np(\\sigma^2 | \\rho, \\mathbf{x}) \\propto (\\sigma^2)^{-(a_n+1)} \\exp\\left(-\\frac{b_n}{\\sigma^2}\\right)\n$$\nwhere the updated shape parameter is $a_n = a_0 + \\frac{T-1}{2}$ and the updated scale parameter is $b_n = b_0 + \\frac{1}{2}\\sum_{t=2}^{T} (x_t - \\rho x_{t-1})^2$. This is the kernel of an Inverse-Gamma distribution, so:\n$$\n\\sigma^2 | \\rho, \\mathbf{x} \\sim \\text{Inv-Gamma}(a_n, b_n)\n$$\nThe full conditional distribution for $\\rho$ is found similarly:\n$$\np(\\rho | \\sigma^2, \\mathbf{x}) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{t=2}^{T} (x_t - \\rho x_{t-1})^2\\right) \\mathbb{I}_{(-1,1)}(\\rho)\n$$\nExpanding the sum of squares with respect to $\\rho$ reveals a quadratic form, which is characteristic of a Normal distribution. The expression can be rewritten as:\n$$\np(\\rho | \\sigma^2, \\mathbf{x}) \\propto \\exp\\left(-\\frac{\\sum x_{t-1}^2}{2\\sigma^2} (\\rho - \\hat{\\rho})^2\\right) \\mathbb{I}_{(-1,1)}(\\rho)\n$$\nwhere $\\hat{\\rho} = \\left(\\sum_{t=2}^{T} x_{t-1}^2\\right)^{-1} \\left(\\sum_{t=2}^{T} x_t x_{t-1}\\right)$ is the ordinary least squares estimator of $\\rho$. This shows that the conditional posterior for $\\rho$ is a Normal distribution with mean $\\mu_{\\rho} = \\hat{\\rho}$ and variance $\\sigma_{\\rho}^2 = \\sigma^2 / \\sum_{t=2}^{T} x_{t-1}^2$, truncated to the interval $(-1, 1)$.\n$$\n\\rho | \\sigma^2, \\mathbf{x} \\sim \\mathcal{N}\\left(\\mu_{\\rho}, \\sigma_{\\rho}^2\\right) \\mathbb{I}_{(-1,1)}(\\rho)\n$$\nThe Gibbs sampling algorithm proceeds as follows:\n1.  Initialize the parameters, e.g., $\\rho^{(0)} = 0$ and $(\\sigma^2)^{(0)} = 1$.\n2.  For iteration $i = 1, 2, \\dots, N$:\n    a. Draw a new value for $\\sigma^2$ from its full conditional distribution, using the current value of $\\rho$:\n       $$ (\\sigma^2)^{(i)} \\sim \\text{Inv-Gamma}\\left(a_0 + \\frac{T-1}{2}, b_0 + \\frac{1}{2}\\sum_{t=2}^{T} (x_t - \\rho^{(i-1)} x_{t-1})^2\\right) $$\n    b. Draw a new value for $\\rho$ from its full conditional distribution, using the newly drawn value of $\\sigma^2$:\n       $$ \\rho^{(i)} \\sim \\mathcal{N}\\left(\\hat{\\rho}, \\frac{(\\sigma^2)^{(i)}}{\\sum x_{t-1}^2}\\right) \\mathbb{I}_{(-1,1)}(\\rho) $$\n3.  After a sufficient burn-in period to allow the chain to converge to its stationary distribution, the subsequent samples $\\{\\rho^{(i)}\\}$ are collected as a sample from the marginal posterior distribution $p(\\rho|\\mathbf{x})$.\n4.  The $99\\%$ credible interval for $\\rho$ is constructed by computing the $0.005$ and $0.995$ quantiles of the collected posterior samples.\n5.  Finally, check if the interval $[q_{0.005}, q_{0.995}]$ contains $0$. If $q_{0.005} \\le 0 \\le q_{0.995}$, the result is `True`; otherwise, it is `False`.\n\nThis procedure is applied to each of the four specified test cases. The data for each case is generated using the specified mechanism and random seed, ensuring reproducibility.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import invgamma, truncnorm\n\ndef generate_data(T, process_type, rho_star, seed):\n    \"\"\"\n    Generates time series data based on the specified process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    if process_type == 'iid_normal':\n        y = rng.normal(loc=0, scale=1, size=T)\n    elif process_type == 'ar1':\n        y = np.zeros(T)\n        eta = rng.normal(loc=0, scale=1, size=T)\n        y[0] = 0 # As specified y_1 = 0, which is y[0] in 0-based index\n        for t in range(1, T):\n            y[t] = rho_star * y[t-1] + eta[t]\n    else:\n        raise ValueError(\"Unknown process type\")\n    return y\n\ndef run_gibbs_sampler(y, n_sim, n_burn):\n    \"\"\"\n    Runs a Gibbs sampler for the AR(1) model.\n    \"\"\"\n    T = len(y)\n    # Center the data\n    x = y - np.mean(y)\n    \n    # Pre-compute sums\n    x_lag = x[:-1]\n    x_curr = x[1:]\n    sum_x_lag_sq = np.sum(x_lag**2)\n    sum_x_curr_x_lag = np.sum(x_curr * x_lag)\n    \n    # Prior hyperparameters\n    a0 = 2.0\n    b0 = 1.0\n    \n    # MCMC setup\n    rho_samples = np.zeros(n_sim)\n    \n    # Initial values\n    rho = 0.0\n    \n    # Gibbs sampling loop\n    for i in range(n_sim + n_burn):\n        # 1. Sample sigma^2 from its full conditional (Inverse-Gamma)\n        a_n = a0 + (T - 1) / 2.0\n        sse = np.sum((x_curr - rho * x_lag)**2)\n        b_n = b0 + 0.5 * sse\n        sigma2 = invgamma.rvs(a=a_n, scale=b_n)\n        \n        # 2. Sample rho from its full conditional (Truncated Normal)\n        mu_rho = sum_x_curr_x_lag / sum_x_lag_sq\n        sigma_rho_sq = sigma2 / sum_x_lag_sq\n        sigma_rho = np.sqrt(sigma_rho_sq)\n        \n        # Parameters for scipy's truncnorm\n        a_trunc = (-1 - mu_rho) / sigma_rho\n        b_trunc = (1 - mu_rho) / sigma_rho\n        \n        rho = truncnorm.rvs(a=a_trunc, b=b_trunc, loc=mu_rho, scale=sigma_rho)\n        \n        if i >= n_burn:\n            rho_samples[i - n_burn] = rho\n            \n    return rho_samples\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        {'T': 400, 'type': 'iid_normal', 'rho_star': 0.0, 'seed': 12345},\n        {'T': 600, 'type': 'ar1', 'rho_star': 0.85, 'seed': 2024},\n        {'T': 60, 'type': 'ar1', 'rho_star': 0.20, 'seed': 7},\n        {'T': 500, 'type': 'ar1', 'rho_star': -0.60, 'seed': 424242}\n    ]\n    \n    results = []\n    \n    # MCMC parameters\n    N_SIM = 10000\n    N_BURN = 1000\n    \n    for case in test_cases:\n        # 1. Generate data\n        y = generate_data(T=case['T'], process_type=case['type'], rho_star=case['rho_star'], seed=case['seed'])\n        \n        # 2. Run Gibbs sampler\n        rho_posterior_samples = run_gibbs_sampler(y, n_sim=N_SIM, n_burn=N_BURN)\n        \n        # 3. Compute 99% credible interval\n        lower_bound = np.quantile(rho_posterior_samples, 0.005)\n        upper_bound = np.quantile(rho_posterior_samples, 0.995)\n        \n        # 4. Check if 0 is in the interval\n        is_zero_in_interval = (lower_bound <= 0) and (upper_bound >= 0)\n        results.append(is_zero_in_interval)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "This final practice brings us to a sophisticated and realistic application from computational finance: estimating a key structural parameter from an economic model. We will estimate the coefficient of relative risk aversion, $\\gamma$, a cornerstone of modern asset pricing theory, using the versatile Metropolis-Hastings algorithm ([@problem_id:2408673]). The exercise introduces the important technique of reparameterization (sampling on a log scale) to handle the positivity constraint on $\\gamma$, providing a powerful template for tackling the bespoke, non-linear models frequently encountered in research.", "id": "2408673", "problem": "Write a complete, runnable program that uses Markov chain Monte Carlo (MCMC) to estimate the coefficient of relative risk aversion $ \\gamma $ for a representative agent in a consumption-based asset pricing framework. Begin from the core first-order condition of intertemporal optimization that yields the Euler equation for asset returns under constant relative risk aversion (CRRA) preferences: with stochastic discount factor $ m_{t+1} = \\beta \\left( \\dfrac{C_{t+1}}{C_t} \\right)^{-\\gamma} $, the no-arbitrage condition is $ \\mathbb{E}_t \\left[ m_{t+1} R_{t+1} \\right] = 1 $, where $ \\beta \\in (0,1) $ is a discount factor, $ C_t $ is consumption, and $ R_{t+1} $ is a gross return observable at time $ t+1 $. To connect this condition to finite-sample, noisy data, assume an additive Normal measurement equation for the Euler residuals,\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2),\n$$\nwhere $ G_t = \\dfrac{C_{t+1}}{C_t} $ denotes gross consumption growth and $ \\sigma^2 $ is a known variance parameter. Assume a Gamma prior for $ \\gamma $ with shape $ k $ and scale $ \\theta $, i.e., $ \\gamma \\sim \\text{Gamma}(k,\\theta) $ supported on $ (0,\\infty) $. Use a Metropolis–Hastings algorithm with a random walk on the log-parameter $ z = \\log \\gamma $ to sample from the posterior of $ \\gamma $ given a sample $ \\{(G_t,R_{t+1})\\}_{t=1}^T $. The proposal is $ z' = z + \\eta $ with $ \\eta \\sim \\mathcal{N}(0,s^2) $ on the log scale.\n\nYour program must:\n- Simulate synthetic data $ (G_t, R_{t+1}) $ for each test case using the specified data-generating process (DGP) below.\n- Construct the posterior kernel combining the Gaussian likelihood implied by the measurement equation and the Gamma prior for $ \\gamma $.\n- Run the Metropolis–Hastings sampler in the $ z $-space (equivalently, a log-normal random walk on $ \\gamma $) and compute the posterior mean estimate of $ \\gamma $ after discarding a burn-in.\n- Use only the specified random seeds to ensure reproducibility.\n\nData-generating process (DGP) for each test case:\n- Generate consumption growth $ G_t = \\exp(\\mu_c + \\sigma_c \\epsilon_t) $ with $ \\epsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1) $.\n- Generate measurement error $ \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma_e^2) $.\n- Generate returns by enforcing the noisy Euler equation period-by-period: \n$$\nR_{t+1} = \\frac{1 + \\varepsilon_t}{\\beta \\, G_t^{-\\gamma_{\\text{true}}}}.\n$$\nAll draws must be made with the specified seed for each test case. To ensure deterministic reproducibility, initialize one pseudo-random number generator with the given seed for simulating $ G_t $ and $ R_{t+1} $, and a second pseudo-random number generator with seed shifted by $ +\\,10{,}000 $ for the Metropolis–Hastings proposals. There are no physical units in this problem.\n\nPosterior target in the log-parameter:\n- Define $ z = \\log \\gamma $. The target density in $ z $ is proportional to the Gamma prior density evaluated at $ \\gamma = e^z $ times the Gaussian likelihood of the residuals, times the Jacobian term $ e^z $ induced by the change of variables. You must implement the Metropolis–Hastings acceptance rule based on the log posterior in $ z $.\n\nTest suite:\nFor each of the following three cases, simulate data and run the sampler with the provided settings. Use the exact values below as given.\n\n- Case A (happy path):\n    - Seed $ = 7 $\n    - Sample size $ T = 200 $\n    - True risk aversion $ \\gamma_{\\text{true}} = 2.0 $\n    - Consumption growth parameters $ \\mu_c = 0.01 $, $ \\sigma_c = 0.02 $\n    - Discount factor $ \\beta = 0.99 $\n    - Measurement standard deviation $ \\sigma_e = 0.01 $\n    - Prior on $ \\gamma $: Gamma shape $ k = 2.0 $, scale $ \\theta = 1.0 $\n    - Metropolis–Hastings: chain length $ N = 16000 $, burn-in $ B = 4000 $, log-scale proposal standard deviation $ s = 0.12 $\n\n- Case B (lower risk aversion, noisier data):\n    - Seed $ = 101 $\n    - Sample size $ T = 120 $\n    - True risk aversion $ \\gamma_{\\text{true}} = 0.5 $\n    - Consumption growth parameters $ \\mu_c = 0.005 $, $ \\sigma_c = 0.015 $\n    - Discount factor $ \\beta = 0.99 $\n    - Measurement standard deviation $ \\sigma_e = 0.02 $\n    - Prior on $ \\gamma $: Gamma shape $ k = 1.5 $, scale $ \\theta = 1.0 $\n    - Metropolis–Hastings: chain length $ N = 16000 $, burn-in $ B = 4000 $, log-scale proposal standard deviation $ s = 0.15 $\n\n- Case C (higher risk aversion, heavier-tailed prior):\n    - Seed $ = 2025 $\n    - Sample size $ T = 200 $\n    - True risk aversion $ \\gamma_{\\text{true}} = 5.0 $\n    - Consumption growth parameters $ \\mu_c = 0.01 $, $ \\sigma_c = 0.02 $\n    - Discount factor $ \\beta = 0.99 $\n    - Measurement standard deviation $ \\sigma_e = 0.01 $\n    - Prior on $ \\gamma $: Gamma shape $ k = 2.0 $, scale $ \\theta = 2.0 $\n    - Metropolis–Hastings: chain length $ N = 16000 $, burn-in $ B = 4000 $, log-scale proposal standard deviation $ s = 0.12 $\n\nRequired output:\n- For each case, compute the posterior mean of $ \\gamma $ using the draws retained after burn-in.\n- Round each posterior mean to exactly three decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $ [x_1,x_2,x_3] $).\n\nNo user input is required or allowed. The program must be self-contained and deterministic under the specified seeds and settings. The final outputs are floats. Ensure scientific realism by adhering strictly to the DGP and the Bayesian construction described above.", "solution": "The problem presented is a well-posed exercise in Bayesian estimation for a structural model from computational economics. It is scientifically grounded, internally consistent, and provides all necessary information for a unique, verifiable solution. Thus, we may proceed with the derivation and implementation.\n\nThe fundamental economic relationship is the Euler equation for a representative agent with Constant Relative Risk Aversion (CRRA) preferences. The utility function is $u(C) = \\frac{C^{1-\\gamma}}{1-\\gamma}$, where $\\gamma > 0$ is the coefficient of relative risk aversion. The agent's first-order condition for optimal intertemporal consumption and asset allocation implies the no-arbitrage condition $\\mathbb{E}_t [m_{t+1} R_{t+1}] = 1$, where $R_{t+1}$ is the gross return on an asset and $m_{t+1}$ is the stochastic discount factor (SDF). For CRRA utility, the SDF is given by $m_{t+1} = \\beta \\left( \\frac{C_{t+1}}{C_t} \\right)^{-\\gamma}$, where $\\beta \\in (0,1)$ is the subjective discount factor. Defining gross consumption growth as $G_t = C_{t+1}/C_t$, the condition becomes $\\mathbb{E}_t[\\beta G_t^{-\\gamma} R_{t+1}] = 1$.\n\nTo render this model empirically tractable with a finite sample of noisy data $D = \\{(G_t, R_{t+1})\\}_{t=1}^T$, we adopt the specified measurement equation:\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0, \\sigma_e^2)\n$$\nwhere $\\sigma_e^2$ is the known variance of the Euler equation errors. This specification implies a Gaussian likelihood for the observed data. For a given $\\gamma$, the likelihood of a single observation $(G_t, R_{t+1})$ is the probability density of a Normal random variable with mean $0$ and variance $\\sigma_e^2$ evaluated at the residual $\\varepsilon_t$. The log-likelihood for the entire sample is therefore:\n$$\n\\log L(\\gamma | D) = C_L - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\nwhere $C_L$ is a constant that does not depend on $\\gamma$.\n\nWe are to perform Bayesian inference on $\\gamma$. The prior distribution for $\\gamma$ is specified as a Gamma distribution, $\\gamma \\sim \\text{Gamma}(k,\\theta)$, with probability density function:\n$$\np(\\gamma|k, \\theta) = \\frac{1}{\\Gamma(k)\\theta^k} \\gamma^{k-1} e^{-\\gamma/\\theta}, \\quad \\text{for } \\gamma > 0\n$$\nThe log-prior, up to an additive constant, is:\n$$\n\\log p(\\gamma|k,\\theta) = C_p + (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta}\n$$\nBy Bayes' theorem, the posterior density of $\\gamma$ is proportional to the product of the likelihood and the prior, $p(\\gamma| D) \\propto L(\\gamma|D) p(\\gamma|k,\\theta)$. The log-posterior is thus proportional to the sum of their logarithms:\n$$\n\\log p(\\gamma|D) \\propto (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\n\nThe estimation will be performed using a Metropolis-Hastings algorithm. To accommodate the constraint $\\gamma > 0$, we perform a change of variables to $z = \\log\\gamma \\in (-\\infty, \\infty)$, which implies $\\gamma = e^z$. The posterior density for the transformed parameter $z$ is given by $p(z|D) = p(\\gamma=e^z|D) \\left| \\frac{d\\gamma}{dz} \\right|$. The Jacobian of this transformation is $\\left| \\frac{d(e^z)}{dz} \\right| = e^z$. The log-posterior for $z$ is therefore:\n$$\n\\log p(z|D) \\propto \\log p(\\gamma=e^z|D) + \\log(e^z) = \\log p(\\gamma=e^z|D) + z\n$$\nSubstituting $\\gamma = e^z$ into our expression for the log-posterior of $\\gamma$ and adding the Jacobian term $z$ yields the target log-density for our sampler:\n$$\n\\pi(z) \\equiv \\log p(z|D) \\propto (k-1)z - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-e^z} R_{t+1} - 1 \\right)^2 + z\n$$\nSimplifying, we get the final form of the kernel which we must evaluate:\n$$\n\\pi(z) \\propto kz - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta R_{t+1} G_t^{-e^z} - 1 \\right)^2\n$$\nThe Metropolis-Hastings algorithm with a random-walk proposal is implemented as follows:\n$1$. Initialize the chain at $z^{(0)}$. A reasonable starting point is the logarithm of the prior mean, $z^{(0)} = \\log(k\\theta)$.\n$2$. For each step $i=1, \\dots, N$:\n    a. Propose a new state $z'$ from a symmetric proposal distribution: $z' = z^{(i-1)} + \\eta$, where $\\eta \\sim \\mathcal{N}(0, s^2)$.\n    b. Calculate the acceptance ratio $A = \\frac{p(z'|D)}{p(z^{(i-1)}|D)}$. In log terms, this is $\\log A = \\pi(z') - \\pi(z^{(i-1)})$.\n    c. Accept the proposal (set $z^{(i)} = z'$) with probability $\\alpha = \\min(1, A)$. Otherwise, reject (set $z^{(i)} = z^{(i-1)}$).\n$3$. The resulting sequence $\\{\\gamma^{(i)} = e^{z^{(i)}}\\}_{i=1}^N$ is a set of draws from the posterior distribution of $\\gamma$.\n$4$. After discarding the initial burn-in samples $\\{ \\gamma^{(i)} \\}_{i=1}^B$, the posterior mean of $\\gamma$ is estimated by the sample mean of the remaining draws:\n$$\n\\hat{\\mathbb{E}}[\\gamma|D] = \\frac{1}{N-B} \\sum_{i=B+1}^N \\gamma^{(i)}\n$$\nThis procedure is applied to each of the three test cases, using synthetic data generated according to the specified Data Generating Process and distinct random number generator seeds for data generation and MCMC sampling to ensure reproducibility. The final result is the posterior mean of $\\gamma$ for each case, rounded to the specified precision.", "answer": "```python\nimport numpy as np\n\ndef estimate_gamma(params):\n    \"\"\"\n    Simulates data and estimates the risk aversion coefficient gamma using MCMC.\n    \"\"\"\n    # Unpack parameters for conciseness\n    seed = params['seed']\n    T = params['T']\n    gamma_true = params['gamma_true']\n    mu_c = params['mu_c']\n    sigma_c = params['sigma_c']\n    beta = params['beta']\n    sigma_e = params['sigma_e']\n    k = params['k']\n    theta = params['theta']\n    N = params['N']\n    B = params['B']\n    s = params['s']\n\n    # 1. Data-Generating Process (DGP)\n    # Initialize a dedicated pseudo-random number generator for data simulation\n    rng_dgp = np.random.default_rng(seed)\n    \n    # Generate consumption growth G_t\n    eps_c = rng_dgp.standard_normal(T)\n    G = np.exp(mu_c + sigma_c * eps_c)\n    \n    # Generate returns R_{t+1} from the noisy Euler equation\n    eps_r = rng_dgp.normal(loc=0.0, scale=sigma_e, size=T)\n    R = (1.0 + eps_r) / (beta * G**(-gamma_true))\n\n    # Pre-calculate log(G) for efficiency in the sampler\n    G_log = np.log(G)\n\n    # 2. Define the Log-Posterior Kernel for z = log(gamma)\n    # The kernel is the log-posterior density up to an additive constant.\n    # log p(z|D) is proportional to:\n    # kz - exp(z)/theta - (1/(2*sigma_e^2)) * sum( (beta*R*G**(-exp(z)) - 1)**2 )\n    def log_posterior_kernel(z):\n        # Handle cases where z might lead to numerical instability\n        if np.isneginf(z): # Corresponds to gamma=0, which has zero prior probability\n            return -np.inf\n        \n        gamma = np.exp(z)\n        \n        if np.isinf(gamma): # z is too large, exp(z) overflows\n            return -np.inf\n        \n        # Log-prior for z (from Gamma prior on gamma + Jacobian term)\n        # log_prior is proportional to k*z - exp(z)/theta\n        log_prior = k * z - gamma / theta\n        \n        # Log-likelihood\n        # G**(-gamma) is numerically more stable as exp(-gamma * log(G))\n        residuals = beta * R * np.exp(-gamma * G_log) - 1.0\n        log_likelihood = -0.5 * np.sum(residuals**2) / (sigma_e**2)\n        \n        return log_prior + log_likelihood\n\n    # 3. Metropolis-Hastings Sampler\n    # Initialize a second PRNG for the MCMC proposals, as specified\n    rng_mcmc = np.random.default_rng(seed + 10000)\n    \n    # Sensible initial value from the prior mean\n    z_current = np.log(k * theta)\n    log_post_current = log_posterior_kernel(z_current)\n\n    gamma_chain = np.empty(N)\n\n    for i in range(N):\n        # Propose a new state using a random walk on the log-scale\n        z_proposal = z_current + rng_mcmc.normal(loc=0.0, scale=s)\n        \n        # Evaluate the log posterior at the proposal\n        log_post_proposal = log_posterior_kernel(z_proposal)\n        \n        # Calculate the log of the acceptance ratio\n        log_alpha = log_post_proposal - log_post_current\n        \n        # Accept or reject the proposal\n        if np.log(rng_mcmc.uniform()) < log_alpha:\n            z_current = z_proposal\n            log_post_current = log_post_proposal\n        \n        # Store the current state of the chain (in terms of gamma)\n        gamma_chain[i] = np.exp(z_current)\n\n    # 4. Compute Posterior Mean\n    # Discard the burn-in samples and compute the mean of the rest\n    posterior_mean = np.mean(gamma_chain[B:])\n    \n    return posterior_mean\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        { # Case A\n            \"seed\": 7, \"T\": 200, \"gamma_true\": 2.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        },\n        { # Case B\n            \"seed\": 101, \"T\": 120, \"gamma_true\": 0.5, \"mu_c\": 0.005, \"sigma_c\": 0.015,\n            \"beta\": 0.99, \"sigma_e\": 0.02, \"k\": 1.5, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.15\n        },\n        { # Case C\n            \"seed\": 2025, \"T\": 200, \"gamma_true\": 5.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 2.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = estimate_gamma(case)\n        results.append(result)\n\n    # Format the output as a comma-separated list of floats with 3 decimal places\n    # enclosed in square brackets, with no trailing whitespace.\n    output_str = f\"[{','.join([f'{res:.3f}' for res in results])}]\"\n    print(output_str)\n\nsolve()\n```"}]}