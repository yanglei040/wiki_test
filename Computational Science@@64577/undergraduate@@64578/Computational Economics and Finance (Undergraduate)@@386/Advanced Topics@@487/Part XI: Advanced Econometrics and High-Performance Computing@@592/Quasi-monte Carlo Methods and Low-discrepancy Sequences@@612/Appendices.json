{"hands_on_practices": [{"introduction": "To build a solid foundation, our first practice involves a direct comparison of three fundamental numerical integration techniques. We will evaluate a highly oscillatory function to benchmark the performance of standard Monte Carlo (MC), Quasi-Monte Carlo (QMC) using a Sobol' sequence, and a simple grid-based Riemann sum. This exercise [@problem_id:2424669] provides a stark, practical demonstration of the superior convergence rate of QMC over MC and highlights the potential pitfalls, such as resonance, of using naive deterministic grids for complex integrands.", "id": "2424669", "problem": "Consider the bivariate function $f:[0,1]^2 \\to \\mathbb{R}$ defined by $f(x,y)=\\cos(20\\pi x)+\\cos(20\\pi y)$, where the cosine function is evaluated in radians. The goal is to numerically approximate the integral\n$$I=\\int_0^1\\int_0^1 f(x,y)\\,dx\\,dy,$$\ncompare the absolute integration errors produced by three estimators, and report the results for a prescribed set of sample sizes.\n\nDefine the following three estimators of $I$ for a given sample size $N\\in\\mathbb{N}$:\n- Monte Carlo (MC, Monte Carlo): Draw $N$ independent samples $(X_i,Y_i)$ with $(X_i,Y_i)\\sim \\text{Uniform}([0,1]^2)$ and use the estimator\n$$\\widehat{I}_{\\text{MC},N}=\\frac{1}{N}\\sum_{i=1}^N f(X_i,Y_i).$$\n- Quasi-Monte Carlo (QMC, Quasi-Monte Carlo): Use the first $N$ points $(u_i,v_i)$ from a two-dimensional Sobol low-discrepancy sequence without scrambling on $[0,1]^2$, and use the estimator\n$$\\widehat{I}_{\\text{QMC},N}=\\frac{1}{N}\\sum_{i=1}^N f(u_i,v_i).$$\n- Two-dimensional Riemann sum on a uniform grid: Assume $N=n^2$ with $n\\in\\mathbb{N}$, and form the uniform $n\\times n$ grid of left-endpoint nodes\n$$\\Big\\{\\Big(\\frac{i}{n},\\frac{j}{n}\\Big): i=0,1,\\dots,n-1,\\; j=0,1,\\dots,n-1\\Big\\}.$$\nUse the estimator\n$$\\widehat{I}_{\\text{Grid},N}=\\frac{1}{n^2}\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1} f\\Big(\\frac{i}{n},\\frac{j}{n}\\Big).$$\n\nYour program must:\n- Use the exact value of $I$ implied by the definition of $f$ over $[0,1]^2$ for computing errors.\n- For MC, use a fixed pseudorandom seed $2025$ for reproducibility.\n- For QMC, use the two-dimensional Sobol sequence without scrambling, taking the first $N$ points in order, starting at index $0$.\n- For the grid-based Riemann sum, apply it only when $N$ is a perfect square.\n\nFor each $N$ in the test suite, compute the absolute errors\n$$E_{\\text{MC}}(N)=\\big|\\widehat{I}_{\\text{MC},N}-I\\big|,\\quad E_{\\text{QMC}}(N)=\\big|\\widehat{I}_{\\text{QMC},N}-I\\big|,\\quad E_{\\text{Grid}}(N)=\\big|\\widehat{I}_{\\text{Grid},N}-I\\big|.$$\n\nTest suite:\n- $N\\in\\{1,4,25,100,400\\}$, which corresponds to grid sizes $n\\in\\{1,2,5,10,20\\}$ for the grid estimator.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a list of lists. Each inner list corresponds to one $N$ in the order $N\\in[1,4,25,100,400]$ and contains the three errors in the fixed order $[E_{\\text{MC}}(N),E_{\\text{QMC}}(N),E_{\\text{Grid}}(N)]$.\n- Each floating-point number must be printed with exactly $8$ digits after the decimal point.\n- There must be no spaces anywhere in the printed line.\n- The output therefore has the form of a single Python-style list of lists on one line, with all entries formatted to $8$ decimal places.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and complete. It is a standard exercise in computational mathematics, comparing the performance of Monte Carlo, Quasi-Monte Carlo, and deterministic grid-based numerical integration methods. All provided information is sufficient and consistent for a unique solution. The problem is therefore valid.\n\nThe objective is to compute the absolute integration errors for three different numerical estimators of the integral $I = \\int_0^1\\int_0^1 f(x,y)\\,dx\\,dy$ for the function $f(x,y)=\\cos(20\\pi x)+\\cos(20\\pi y)$.\n\nFirst, we must determine the exact value of the integral $I$. By the linearity of integration, we can separate the integral:\n$$I = \\int_0^1\\int_0^1 \\left(\\cos(20\\pi x)+\\cos(20\\pi y)\\right)\\,dx\\,dy = \\int_0^1\\int_0^1 \\cos(20\\pi x)\\,dx\\,dy + \\int_0^1\\int_0^1 \\cos(20\\pi y)\\,dx\\,dy$$\nLet us evaluate the first term:\n$$ \\int_0^1\\int_0^1 \\cos(20\\pi x)\\,dx\\,dy = \\int_0^1 \\left[ \\frac{\\sin(20\\pi x)}{20\\pi} \\right]_{x=0}^{x=1} \\,dy = \\int_0^1 \\left( \\frac{\\sin(20\\pi \\cdot 1) - \\sin(20\\pi \\cdot 0)}{20\\pi} \\right) \\,dy $$\nSince $\\sin(20\\pi) = 0$ and $\\sin(0) = 0$, the inner integral evaluates to $0$. Thus, the entire first term is $\\int_0^1 0 \\,dy = 0$.\nBy symmetry, the second term is also zero:\n$$ \\int_0^1\\int_0^1 \\cos(20\\pi y)\\,dx\\,dy = \\int_0^1 \\cos(20\\pi y) \\left[ x \\right]_{x=0}^{x=1} \\,dy = \\int_0^1 \\cos(20\\pi y) \\,dy = \\left[ \\frac{\\sin(20\\pi y)}{20\\pi} \\right]_{y=0}^{y=1} = 0 $$\nTherefore, the exact value of the integral is $I = 0 + 0 = 0$. The absolute error of any estimator $\\widehat{I}$ is thus simply its absolute value, $E = |\\widehat{I} - I| = |\\widehat{I}|$.\n\nThe solution procedure involves implementing the three estimators for each sample size $N$ in the set $\\{1, 4, 25, 100, 400\\}$.\n\n1.  **Monte Carlo (MC) Estimator:** For each $N$, we generate $N$ independent random points $(X_i, Y_i)$ uniformly distributed in the unit square $[0,1]^2$. A pseudorandom number generator with a fixed seed of $2025$ is used to ensure reproducibility. The estimate is the sample mean of the function values at these points:\n    $$\\widehat{I}_{\\text{MC},N}=\\frac{1}{N}\\sum_{i=1}^N f(X_i,Y_i)$$\n\n2.  **Quasi-Monte Carlo (QMC) Estimator:** For each $N$, we use the first $N$ points $(u_i,v_i)$ of a two-dimensional Sobol low-discrepancy sequence. These points are generated deterministically and are designed to cover the unit square more evenly than pseudorandom points. To ensure we are using the \"first $N$ points\" for each test case, a single sequence of the maximum required length ($N=400$) is generated, and the appropriate prefix of this sequence is used for each $N$. The estimate is the sample mean:\n    $$\\widehat{I}_{\\text{QMC},N}=\\frac{1}{N}\\sum_{i=1}^N f(u_i,v_i)$$\n\n3.  **Grid-based Riemann Sum Estimator:** This method is applied for $N=n^2$ where $n \\in \\{1, 2, 5, 10, 20\\}$. A uniform $n \\times n$ grid of points $(\\frac{i}{n}, \\frac{j}{n})$ for $i,j \\in \\{0, 1, \\dots, n-1\\}$ is constructed. The estimate is the mean of the function values over this grid:\n    $$\\widehat{I}_{\\text{Grid},N}=\\frac{1}{n^2}\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1} f\\Big(\\frac{i}{n},\\frac{j}{n}\\Big)$$\n    It is important to analyze the behavior of this estimator for the given function. The sum can be simplified:\n    $$\\widehat{I}_{\\text{Grid},N} = \\frac{1}{n^2} \\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1} \\left( \\cos\\left(\\frac{20\\pi i}{n}\\right) + \\cos\\left(\\frac{20\\pi j}{n}\\right) \\right) = \\frac{2}{n}\\sum_{k=0}^{n-1} \\cos\\left(\\frac{20\\pi k}{n}\\right)$$\n    The term $20\\pi/n$ is a multiple of $2\\pi$ if $10/n$ is an integer. This holds for $n \\in \\{1, 2, 5, 10\\}$. For these values, every term $\\cos(20\\pi k/n) = \\cos(2\\pi \\cdot (\\text{integer}) \\cdot k) = 1$. The sum is $n$, and the estimator becomes $\\widehat{I}_{\\text{Grid},N} = \\frac{2}{n} \\cdot n = 2$. The error is $|\\widehat{I}_{\\text{Grid},N}| = 2$.\n    For $n=20$, the argument is $\\cos(\\pi k)$, and the sum $\\sum_{k=0}^{19} \\cos(\\pi k) = 1-1+1-1+\\dots+1-1=0$. The estimator and its error are both $0$. This specific function choice highlights a resonance phenomenon where a uniform grid can perform very poorly or perfectly, depending on its alignment with the function's periodicity.\n\nThe program calculates these three estimates for each $N$, computes the absolute errors, and formats the results as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef solve():\n    \"\"\"\n    Computes and compares absolute integration errors for MC, QMC, and Grid estimators.\n    \"\"\"\n    # The exact value of the integral is I=0.\n    I_exact = 0.0\n\n    # Define the bivariate function to be integrated.\n    def f(x, y):\n        \"\"\"\n        Calculates f(x,y) = cos(20*pi*x) + cos(20*pi*y).\n        x and y can be scalars or numpy arrays.\n        \"\"\"\n        return np.cos(20 * np.pi * x) + np.cos(20 * np.pi * y)\n\n    # Define the test suite for sample sizes N.\n    test_cases = [\n        (1, 1),\n        (4, 2),\n        (25, 5),\n        (100, 10),\n        (400, 20),\n    ]\n\n    seed = 2025\n    rng = np.random.default_rng(seed)\n\n    # Pre-generate all required Sobol points to ensure \"first N\" rule is followed.\n    max_N = test_cases[-1][0]\n    sobol_engine = qmc.Sobol(d=2, scramble=False)\n    all_qmc_points = sobol_engine.random(max_N)\n\n    results = []\n    for N, n in test_cases:\n        # --- 1. Monte Carlo (MC) Estimator ---\n        # Generate N fresh random points for each N.\n        mc_points = rng.random((N, 2))\n        f_values_mc = f(mc_points[:, 0], mc_points[:, 1])\n        I_hat_mc = np.mean(f_values_mc)\n        error_mc = np.abs(I_hat_mc - I_exact)\n\n        # --- 2. Quasi-Monte Carlo (QMC) Estimator ---\n        # Use the first N points from the pre-generated sequence.\n        qmc_points = all_qmc_points[:N]\n        f_values_qmc = f(qmc_points[:, 0], qmc_points[:, 1])\n        I_hat_qmc = np.mean(f_values_qmc)\n        error_qmc = np.abs(I_hat_qmc - I_exact)\n\n        # --- 3. Grid-based Riemann Sum Estimator ---\n        # Generate an n x n grid of left-endpoints.\n        grid_coords = np.arange(n) / n\n        x_grid, y_grid = np.meshgrid(grid_coords, grid_coords)\n        f_values_grid = f(x_grid, y_grid)\n        I_hat_grid = np.mean(f_values_grid)\n        error_grid = np.abs(I_hat_grid - I_exact)\n\n        results.append([error_mc, error_qmc, error_grid])\n\n    # Format the output string according to the specified rules:\n    # A list of lists, with each number formatted to 8 decimal places,\n    # and no spaces in the entire output string.\n    formatted_rows = [\n        f\"[{','.join([f'{err:.8f}' for err in row])}]\"\n        for row in results\n    ]\n    final_output = f\"[{','.join(formatted_rows)}]\"\n\n    print(final_output)\n\nsolve()\n```"}, {"introduction": "After observing the general superiority of QMC, we now explore its potential weaknesses by thinking like an adversary. This practice takes a clever, constructive approach: you will design a \"worst-case\" discontinuous function specifically engineered to make a given Sobol' point set produce a poor estimate. This exercise [@problem_id:2424652] reveals the practical meaning of the Koksma-Hlawka inequality by showing that the integration error for a deterministic point set can be linked to the size of the largest \"gap\" in its coverage, providing deep intuition into the nature of discrepancy.", "id": "2424652", "problem": "You are given the task of constructing, from first principles, a discontinuous payoff function on the unit hypercube that is specifically engineered to cause a poor quasi-Monte Carlo integral estimate for a fixed set of $100$ points from a Sobol sequence. The goal is to formalize a principled construction that exploits the actual point set to produce a large absolute error between the quasi-Monte Carlo estimate and the true integral.\n\nYou must start only from fundamental definitions: a quasi-Monte Carlo estimate approximates an integral over $[0,1]^d$ by the simple average of the integrand evaluated at a deterministic low-discrepancy point set. A Sobol sequence is a deterministic low-discrepancy sequence in $[0,1]^d$. A discontinuous payoff can be modeled as an indicator function of a measurable subset of $[0,1]^d$. No further formulas are to be assumed.\n\nYour program must implement the following construction. For a given dimension $d$ and a specific set of $n=100$ Sobol points $\\{\\boldsymbol{x}_i\\}_{i=1}^{100}\\subset[0,1)^d$:\n1) Consider only the first coordinate of the points. Let $x_{i,1}$ denote the first coordinate of $\\boldsymbol{x}_i$.\n2) Form the sorted list $0 = t_0 < t_1 \\le \\cdots \\le t_{100} < t_{101} = 1$, where $\\{t_1,\\dots,t_{100}\\}$ is the non-decreasing ordering of $\\{x_{i,1}\\}_{i=1}^{100}$ and $t_0=0$, $t_{101}=1$.\n3) Identify the largest open sub-interval $(t_j,t_{j+1})$ that contains no sample first-coordinates in its interior. Define the discontinuous payoff function $f:[0,1]^d\\to\\{0,1\\}$ by\n$$\nf(\\boldsymbol{x}) = \\mathbf{1}\\{\\, t_j < x_1 < t_{j+1} \\,\\},\n$$\nthat is, $f(\\boldsymbol{x})$ is $1$ if and only if the first coordinate $x_1$ lies strictly between $t_j$ and $t_{j+1}$, and $0$ otherwise.\n4) Compute the quasi-Monte Carlo estimate\n$$\n\\hat{I}_n = \\frac{1}{n}\\sum_{i=1}^{n} f(\\boldsymbol{x}_i),\n$$\nand the true integral\n$$\nI = \\int_{[0,1]^d} f(\\boldsymbol{x})\\, d\\boldsymbol{x}.\n$$\nFrom first principles of product measure on hypercubes, $I$ equals the length of the interval $(t_j,t_{j+1})$, i.e., $I = t_{j+1}-t_j$. By construction, no point has first coordinate in the open interval, so $\\hat{I}_n=0$. Therefore, the absolute error is $|I-\\hat{I}_n|=t_{j+1}-t_j$, which is the length of the largest empty gap in the first-coordinate projection.\n\nYour program must:\na) Generate the first $n=100$ points of a Sobol sequence in $\\mathbb{R}^d$ with the specified scrambling and seed, using a standard Sobol generator.\nb) Optionally apply a specified additive mod-$1$ shift $\\boldsymbol{u}\\in[0,1)^d$ (Cranley–Patterson rotation) to all points: $\\boldsymbol{x}_i \\leftarrow (\\boldsymbol{x}_i + \\boldsymbol{u}) \\bmod 1$ when a shift is provided.\nc) Construct $f$ as above from the shifted (or unshifted) points using only their first coordinate.\nd) Output the absolute error $|I-\\hat{I}_n|$ for each test case as a float.\n\nTest suite. For coverage, use the following four test cases which explore unscrambled and scrambled Sobol points, different dimensions, and the presence or absence of an additive shift:\n- Case $1$: $d=5$, unscrambled ($\\text{scramble}=\\text{False}$), no shift.\n- Case $2$: $d=5$, scrambled ($\\text{scramble}=\\text{True}$) with seed $7$, no shift.\n- Case $3$: $d=1$, unscrambled, with shift vector $\\boldsymbol{u}=(0.37)$ applied componentwise modulo $1$.\n- Case $4$: $d=10$, scrambled with seed $123$, with shift vector $\\boldsymbol{u} = (0.10, 0.21, 0.32, 0.43, 0.54, 0.65, 0.76, 0.87, 0.98, 0.09)$ applied componentwise modulo $1$.\n\nFinal output format. Your program should produce a single line of output containing the absolute errors for the four cases, as a comma-separated list enclosed in square brackets, in the order of the cases listed above. For example, an output like\n\"[0.0123,0.0100,0.0175,0.0112]\"\nwould be acceptable. Angles and physical units are not involved, and no additional text should be printed.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of numerical integration and quasi-Monte Carlo (QMC) methods, is well-posed with a clear and deterministic algorithmic procedure, and is expressed in objective, formal language. We will therefore proceed with a complete solution.\n\nThe objective is to construct a pathological, discontinuous integrand $f: [0,1]^d \\to \\{0, 1\\}$ designed to maximize the error of a QMC integral estimate for a given, fixed low-discrepancy point set. The QMC method approximates the integral $I = \\int_{[0,1]^d} f(\\boldsymbol{x}) d\\boldsymbol{x}$ using a finite sum over a deterministic sequence of points $\\{\\boldsymbol{x}_i\\}_{i=1}^n \\subset [0,1)^d$. The estimate, $\\hat{I}_n$, is the sample mean of the function evaluated at these points:\n$$\n\\hat{I}_n = \\frac{1}{n} \\sum_{i=1}^{n} f(\\boldsymbol{x}_i).\n$$\nThe absolute error of this estimation is $|I - \\hat{I}_n|$. The core of the problem is to construct $f$ such that this error is maximized for a given set of $n=100$ Sobol points.\n\nThe chosen form for the function $f$ is an indicator function, $f(\\boldsymbol{x}) = \\mathbf{1}_{A}(\\boldsymbol{x})$, where $A$ is a measurable subset of the unit hypercube $[0,1]^d$. The function takes the value $1$ if $\\boldsymbol{x} \\in A$ and $0$ otherwise.\n\nTo maximize the error, we must simultaneously make the QMC estimate $\\hat{I}_n$ very small and the true integral $I$ very large.\n1.  **Minimizing the QMC Estimate**: The QMC estimate $\\hat{I}_n$ becomes zero if $f(\\boldsymbol{x}_i) = 0$ for all points $\\boldsymbol{x}_i$ in our sequence. This is achieved by defining the set $A$ such that it contains none of the sample points, i.e., $A \\cap \\{\\boldsymbol{x}_i\\}_{i=1}^n = \\emptyset$.\n\n2.  **Maximizing the True Integral**: The true integral is the Lebesgue measure (volume) of the set $A$:\n    $$\n    I = \\int_{[0,1]^d} \\mathbf{1}_{A}(\\boldsymbol{x}) d\\boldsymbol{x} = \\text{Vol}(A).\n    $$\n    To maximize the error $|I - \\hat{I}_n| = |\\text{Vol}(A) - 0| = \\text{Vol}(A)$, we must find the largest possible volume for a set $A$ that contains no points from the Sobol sequence.\n\nThe construction specified in the problem statement provides a simple and effective method for achieving this. It defines the set $A$ as a \"slab\" determined exclusively by the first coordinate, $x_1$:\n$$\nA = \\{ \\boldsymbol{x} = (x_1, \\dots, x_d) \\in [0,1]^d \\mid x_1 \\in (a, b) \\}\n$$\nfor some interval $(a, b) \\subset [0,1]$.\nBy Fubini's theorem, the volume of this set is:\n$$\n\\text{Vol}(A) = \\int_{[0,1]^d} \\mathbf{1}\\{ a < x_1 < b \\} d\\boldsymbol{x} = \\left(\\int_0^1 \\mathbf{1}\\{ a < x_1 < b \\} dx_1\\right) \\prod_{k=2}^d \\left(\\int_0^1 dx_k\\right) = (b-a) \\cdot 1^{d-1} = b-a.\n$$\nThe problem is now reduced to finding an interval $(a, b)$ that contains no first coordinates $\\{x_{i,1}\\}_{i=1}^n$ from the point set and has maximal length $b-a$.\n\nThe procedure is as follows:\n1.  Given the set of $n=100$ Sobol points $\\{\\boldsymbol{x}_i\\}_{i=1}^{100}$. Optionally, these points are shifted by a vector $\\boldsymbol{u}$ such that $\\boldsymbol{x}_i' = (\\boldsymbol{x}_i + \\boldsymbol{u}) \\bmod 1$. We work with the final (possibly shifted) points.\n2.  We extract the first coordinate of each point, yielding a set of values $\\{x_{i,1}\\}_{i=1}^{100}$.\n3.  To find all empty intervals along the first dimension, we sort these coordinates and augment the resulting list with the boundaries of the unit interval, $0$ and $1$. Let this ordered sequence be $0 = t_0 \\le t_1 \\le \\dots \\le t_{100} \\le t_{101} = 1$, where $\\{t_1, \\dots, t_{100}\\}$ are the sorted values of $\\{x_{i,1}\\}_{i=1}^{100}$. Note that the problem text uses a strict inequality $t_0 < t_1$, which holds if no point has a first coordinate of $0$. Our implementation handles potential equality.\n4.  The open intervals $(t_j, t_{j+1})$ for $j=0, \\dots, 100$ represent all the \"gaps\" in the projection of the point set onto the first axis.\n5.  We identify the interval $(t_j, t_{j+1})$ with the maximum length, $\\Delta t_{\\max} = \\max_j (t_{j+1} - t_j)$.\n6.  The pathological function is thus $f(\\boldsymbol{x}) = \\mathbf{1}\\{x_1 \\in (t_j, t_{j+1})\\}$.\n\nWith this function, the QMC estimate is $\\hat{I}_n = \\frac{1}{n} \\sum_{i=1}^n f(\\boldsymbol{x}_i) = 0$, because by construction, the first coordinate $x_{i,1}$ of any point $\\boldsymbol{x}_i$ is one of the boundary points $t_k$ and therefore does not lie in the *open* interval $(t_j, t_{j+1})$.\nThe true integral is $I = \\text{Vol}(A) = t_{j+1} - t_j = \\Delta t_{\\max}$.\nThe absolute error is therefore $|I - \\hat{I}_n| = |\\Delta t_{\\max} - 0| = \\Delta t_{\\max}$.\n\nThe purpose of scrambling and Cranley-Patterson shifting is to improve the uniformity of the point set, which typically reduces the QMC error for \"reasonable\" integrands. These techniques break up the regular patterns of the raw Sobol sequence, which can lead to a reduction in the size of the largest gap, $\\Delta t_{\\max}$. Our analysis demonstrates that for any fixed point set, scrambled or not, this method constructs an integrand for which the QMC estimate performs poorly, and the error is precisely the size of the largest projective gap. The program will compute this value for each specified test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef solve():\n    \"\"\"\n    Constructs a pathological discontinuous function for several Sobol point sets\n    and calculates the resulting quasi-Monte Carlo integration error.\n    \"\"\"\n    N_POINTS = 100\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: d=5, unscrambled, no shift.\n        {'d': 5, 'scramble': False, 'seed': None, 'shift': None},\n        # Case 2: d=5, scrambled with seed 7, no shift.\n        {'d': 5, 'scramble': True, 'seed': 7, 'shift': None},\n        # Case 3: d=1, unscrambled, with shift u=(0.37).\n        {'d': 1, 'scramble': False, 'seed': None, 'shift': np.array([0.37])},\n        # Case 4: d=10, scrambled with seed 123, with shift vector u.\n        {'d': 10, 'scramble': True, 'seed': 123, 'shift': np.array([\n            0.10, 0.21, 0.32, 0.43, 0.54, 0.65, 0.76, 0.87, 0.98, 0.09])}\n    ]\n\n    results = []\n    for case in test_cases:\n        d = case['d']\n        scramble = case['scramble']\n        seed = case['seed']\n        shift = case['shift']\n\n        # a) Generate the first n=100 points of a Sobol sequence.\n        # The Sobol generator is seeded for reproducibility of scrambled sequences.\n        sobol_engine = qmc.Sobol(d=d, scramble=scramble, seed=seed)\n        points = sobol_engine.random(n=N_POINTS)\n\n        # b) Optionally apply an additive mod-1 shift (Cranley–Patterson rotation).\n        if shift is not None:\n            points = (points + shift) % 1\n\n        # c) Construct the pathological function f and compute the error.\n        # The construction focuses on the first coordinate of the points.\n        x1_coords = points[:, 0]\n\n        # Form the sorted list of boundaries t_j, including 0 and 1.\n        # These define the intervals for the indicator function.\n        t = np.concatenate(([0], np.sort(x1_coords), [1]))\n\n        # The true integral I is the length of the largest empty sub-interval\n        # along the first coordinate axis. The QMC estimate I_hat is 0 by construction.\n        # The absolute error |I - I_hat| is therefore a simple maximum difference.\n        gaps = np.diff(t)\n        max_gap = np.max(gaps)\n\n        # d) Output the absolute error.\n        results.append(max_gap)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "The previous exercise demonstrated that any fixed, deterministic point set is vulnerable to a cleverly designed integrand. The solution is to introduce structured randomness, which brings us to the powerful technique of scrambling. In this final practice [@problem_id:2424700], you will implement Owen scrambling on a Sobol' sequence and see its remarkable effect on integrating a discontinuous function, a common challenge in financial applications. This demonstrates how randomized QMC methods retain the superior uniformity of low-discrepancy sequences while restoring the benefits of statistical error analysis and improving robustness.", "id": "2424700", "problem": "You must write a complete, runnable program that compares the performance of Owen-scrambled Sobol’ sequences and unscrambled Sobol’ sequences for estimating the integral of a discontinuous integrand central to computational economics and finance. Consider the integral\n$$\nI(d,\\tau) \\;=\\; \\int_{[0,1]^d} \\mathbf{1}\\!\\left\\{\\sum_{i=1}^{d} u_i \\ge \\tau \\right\\} \\, \\mathrm{d}\\boldsymbol{u},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function, $d \\in \\mathbb{N}$ is the dimension, and $\\tau \\in \\mathbb{R}$ is a threshold. This integral represents the probability that the sum of $d$ independent Uniform$(0,1)$ random variables exceeds $\\tau$, which is a prototypical discontinuous payoff relevant to digital payoffs in asset pricing and risk measures in computational economics and finance. The exact value is\n$$\nI(d,\\tau) \\;=\\; 1 - F_{\\mathrm{IH}}(\\tau; d),\n$$\nwhere $F_{\\mathrm{IH}}(\\cdot; d)$ is the cumulative distribution function of the Irwin–Hall distribution with parameter $d$, given by\n$$\nF_{\\mathrm{IH}}(x; d) \\;=\\;\n\\begin{cases}\n0, & x \\le 0,\\\n$$4pt]\n\\dfrac{1}{d!}\\displaystyle\\sum_{k=0}^{\\lfloor x \\rfloor} (-1)^k \\binom{d}{k} (x - k)^d, & 0 < x < d,\\\n$$10pt]\n1, & x \\ge d.\n\\end{cases}\n$$\n\nFor a given $d$, $\\tau$, and sample size $N \\in \\mathbb{N}$, define the quasi-Monte Carlo estimator\n$$\n\\widehat{I}_N \\;=\\; \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{1}\\!\\left\\{\\sum_{i=1}^{d} u_{n,i} \\ge \\tau \\right\\},\n$$\nwhere $\\{\\boldsymbol{u}_n\\}_{n=1}^{N} \\subset [0,1]^d$ are the first $N$ points of a Sobol’ low-discrepancy sequence. Let $m$ be the smallest integer such that $2^m \\ge N$. In all cases below, use the first $N$ points from a Sobol’ digital net of size $2^m$ in $d$ dimensions.\n\nYour program must, for each test case, compute:\n1. An unscrambled estimate using an unscrambled Sobol’ sequence to obtain $\\widehat{I}_N^{\\mathrm{uns}}$ and its absolute error\n$$\ne_{\\mathrm{uns}} \\;=\\; \\left| \\widehat{I}_N^{\\mathrm{uns}} - I(d,\\tau) \\right|.\n$$\n2. $R$ independent randomized estimates using Owen-scrambled Sobol’ sequences to obtain $\\widehat{I}_{N,r}^{\\mathrm{scr}}$ for $r \\in \\{1,\\dots,R\\}$, each with its own independent randomization, and record the absolute errors\n$$\ne_{\\mathrm{scr},r} \\;=\\; \\left| \\widehat{I}_{N,r}^{\\mathrm{scr}} - I(d,\\tau) \\right|.\n$$\nFor each test case, define the performance ratio\n$$\n\\rho \\;=\\; \\frac{e_{\\mathrm{uns}}}{\\operatorname{median}\\{ e_{\\mathrm{scr},1},\\dots,e_{\\mathrm{scr},R} \\}},\n$$\nso that $\\rho > 1$ numerically demonstrates that the Owen-scrambled estimator attains a smaller typical absolute error than the unscrambled estimator on this discontinuous integrand.\n\nUse the following test suite of parameter values, where $S$ is a base seed and $R$ is the number of independent Owen-scrambled replications. For the $r$-th scrambled replication, use seed $S + r - 1$. For each tuple $\\left(d,\\tau,N,R,S\\right)$ below, compute the corresponding $\\rho$:\n- Test case $1$: $\\left(d,\\tau,N,R,S\\right) = \\left(5,\\,2.5,\\,4093,\\,64,\\,13579\\right)$.\n- Test case $2$: $\\left(d,\\tau,N,R,S\\right) = \\left(10,\\,5.0,\\,16384,\\,32,\\,24680\\right)$.\n- Test case $3$: $\\left(d,\\tau,N,R,S\\right) = \\left(12,\\,9.0,\\,32767,\\,16,\\,112233\\right)$.\n\nYour program must:\n- Compute $I(d,\\tau)$ exactly using the Irwin–Hall cumulative distribution function $F_{\\mathrm{IH}}(\\tau; d)$ given above.\n- For each test case, use the first $N$ points from a Sobol’ digital net of size $2^m$ in $d$ dimensions for both unscrambled and independently Owen-scrambled sequences.\n- For each test case, produce the performance ratio $\\rho$ defined above.\n\nFinal output format:\n- Your program should produce a single line of output containing the three ratios for the test cases as a comma-separated list enclosed in square brackets, in the order of the test cases given above, with each ratio rounded to exactly $6$ digits after the decimal point. For example, an output of the form $\\left[\\rho_1,\\rho_2,\\rho_3\\right]$ must be printed as a single line like $[1.234000,0.987650,1.500000]$.", "solution": "The problem presented is a valid numerical experiment in the domain of quasi-Monte Carlo (QMC) methods, specifically applied to a problem characteristic of computational finance. It requires the comparison of standard Sobol’ sequences against Owen-scrambled Sobol’ sequences for integrating a discontinuous function. The problem is well-posed, scientifically grounded, and all parameters and definitions are provided with sufficient clarity to permit a unique, verifiable solution. We shall proceed with the derivation and implementation of the solution.\n\nThe core objective is to compute a performance ratio, $\\rho$, which quantifies the improvement afforded by Owen scrambling over an unscrambled sequence for a specific discontinuous integral. This ratio is defined as\n$$\n\\rho \\;=\\; \\frac{e_{\\mathrm{uns}}}{\\operatorname{median}\\{ e_{\\mathrm{scr},1},\\dots,e_{\\mathrm{scr},R} \\}},\n$$\nwhere $e_{\\mathrm{uns}}$ is the absolute error of the estimator using an unscrambled Sobol' sequence, and $\\{ e_{\\mathrm{scr},r} \\}_{r=1}^R$ is a set of absolute errors from $R$ independent replications using Owen-scrambled Sobol' sequences. A value of $\\rho > 1$ demonstrates superior performance of the scrambled sequence, as it achieves a smaller median error.\n\nThe step-by-step procedure is as follows:\n\n**Step 1: Computation of the Exact Integral Value**\n\nThe integral to be estimated is\n$$\nI(d,\\tau) \\;=\\; \\int_{[0,1]^d} \\mathbf{1}\\!\\left\\{\\sum_{i=1}^{d} u_i \\ge \\tau \\right\\} \\, \\mathrm{d}\\boldsymbol{u}.\n$$\nThis represents the probability $P(\\sum_{i=1}^d U_i \\ge \\tau)$ where $U_i \\sim \\text{Uniform}(0,1)$ are independent random variables. The sum $\\sum_{i=1}^d U_i$ follows the Irwin–Hall distribution with parameter $d$. The exact value of the integral is given by the survival function of this distribution:\n$$\nI(d,\\tau) \\;=\\; 1 - F_{\\mathrm{IH}}(\\tau; d),\n$$\nwhere $F_{\\mathrm{IH}}(x; d)$ is the cumulative distribution function (CDF) provided in the problem statement. To compute this, we must implement a function for $F_{\\mathrm{IH}}(x;d)$. For a given value $x = \\tau$ and parameter $d$, the function is defined piece-wise. The non-trivial case is for $0 < x < d$:\n$$\nF_{\\mathrm{IH}}(x; d) \\;=\\; \\frac{1}{d!}\\sum_{k=0}^{\\lfloor x \\rfloor} (-1)^k \\binom{d}{k} (x - k)^d.\n$$\nThis sum involves factorials, binomial coefficients, and powers, all of which are standard mathematical functions. For instance, for the test case $(d, \\tau) = (5, 2.5)$, we find $I(5, 2.5) = 1 - F_{\\mathrm{IH}}(2.5; 5) = 1 - 0.5 = 0.5$, which follows from the symmetry of the Irwin-Hall distribution around its mean $d/2 = 2.5$. For the other cases, direct evaluation of the formula is required.\n\n**Step 2: Implementation of the Quasi-Monte Carlo Estimators**\n\nThe QMC estimator for $I(d,\\tau)$ using a point set $\\{\\boldsymbol{u}_n\\}_{n=1}^{N}$ is\n$$\n\\widehat{I}_N \\;=\\; \\frac{1}{N} \\sum_{n=1}^{N} f(\\boldsymbol{u}_n),\n$$\nwhere the integrand is the indicator function $f(\\boldsymbol{u}) = \\mathbf{1}\\{\\sum_{i=1}^{d} u_i \\ge \\tau\\}$. The computation involves summing the components of each point $\\boldsymbol{u}_n$, checking if the sum is greater than or equal to $\\tau$, and averaging the results of this binary check over all $N$ points.\n\nWe must compute two types of estimates:\n\n1.  **Unscrambled Estimate ($\\widehat{I}_N^{\\mathrm{uns}}$):** We generate the first $N$ points of a single $d$-dimensional Sobol' sequence without any scrambling. These points are used to compute the estimate $\\widehat{I}_N^{\\mathrm{uns}}$. The absolute error is then $e_{\\mathrm{uns}} = |\\widehat{I}_N^{\\mathrm{uns}} - I(d, \\tau)|$. A Sobol' sequence generator is configured with `scramble=False`.\n\n2.  **Scrambled Estimates ($\\widehat{I}_{N,r}^{\\mathrm{scr}}$):** We perform $R$ independent replications. For each replication $r \\in \\{1, \\dots, R\\}$, we generate a new set of $N$ points from a $d$-dimensional Sobol' sequence with Owen scrambling enabled. Crucially, each replication must be statistically independent. This is achieved by seeding the random number generator for the scrambling matrices differently for each replication. The problem specifies using a seed of $S + r - 1$ for the $r$-th replication. For each of these $R$ point sets, we compute an estimate $\\widehat{I}_{N,r}^{\\mathrm{scr}}$ and its corresponding absolute error $e_{\\mathrm{scr},r} = |\\widehat{I}_{N,r}^{\\mathrm{scr}} - I(d, \\tau)|$. This procedure yields a sample of $R$ errors $\\{e_{\\mathrm{scr},1}, \\dots, e_{\\mathrm{scr},R}\\}$.\n\n**Step 3: Calculation of the Performance Ratio**\n\nWith the unscrambled error $e_{\\mathrm{uns}}$ and the sample of $R$ scrambled errors $\\{e_{\\mathrm{scr},r}\\}$, we can assess the typical performance of the scrambled estimator. The median of the scrambled errors, $\\operatorname{median}\\{e_{\\mathrm{scr},r}\\}$, provides a robust measure of the central tendency of the error distribution for the randomized QMC method. The final performance ratio $\\rho$ is computed by dividing the single deterministic error of the unscrambled method by this median error.\n\n**Step 4: Algorithmic Procedure for a Single Test Case**\nFor each tuple $(d, \\tau, N, R, S)$:\n1.  Calculate the exact integral value $I_{\\mathrm{exact}} = 1 - F_{\\mathrm{IH}}(\\tau; d)$.\n2.  Generate an unscrambled Sobol' sequence of $N$ points in $d$ dimensions.\n3.  Compute the estimate $\\widehat{I}_N^{\\mathrm{uns}}$ and the error $e_{\\mathrm{uns}} = |\\widehat{I}_N^{\\mathrm{uns}} - I_{\\mathrm{exact}}|$.\n4.  Initialize an empty list for scrambled errors, `errors_scr`.\n5.  Loop $r$ from $1$ to $R$:\n    a.  Set the seed for randomization to $S + r - 1$.\n    b.  Generate an Owen-scrambled Sobol' sequence of $N$ points in $d$ dimensions.\n    c.  Compute the estimate $\\widehat{I}_{N,r}^{\\mathrm{scr}}$ and the error $e_{\\mathrm{scr},r} = |\\widehat{I}_{N,r}^{\\mathrm{scr}} - I_{\\mathrm{exact}}|$.\n    d.  Append $e_{\\mathrm{scr},r}$ to `errors_scr`.\n6.  Calculate the median of the scrambled errors: $m_e = \\operatorname{median}(\\text{errors\\_scr})$.\n7.  Calculate the performance ratio $\\rho = e_{\\mathrm{uns}} / m_e$.\n8.  Store the resulting $\\rho$, formatted to $6$ decimal places.\n\nThis entire process is repeated for all provided test cases. The final output is an ordered list of the computed ratios.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import qmc\nfrom scipy.special import comb\nimport math\n\ndef solve():\n    \"\"\"\n    Main solver function that executes the comparison for all test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (d, tau, N, R, S)\n        (5, 2.5, 4093, 64, 13579),\n        (10, 5.0, 16384, 32, 24680),\n        (12, 9.0, 32767, 16, 112233),\n    ]\n\n    results = []\n    \n    for d, tau, N, R, S in test_cases:\n        # Step 1: Compute the exact integral value using the Irwin-Hall CDF\n        exact_integral_value = 1.0 - irwin_hall_cdf(tau, d)\n\n        # Step 2.1: Compute the unscrambled QMC estimate and its error\n        # Initialize an unscrambled Sobol' sequence generator\n        sampler_unscrambled = qmc.Sobol(d=d, scramble=False)\n        points_unscrambled = sampler_unscrambled.random(n=N)\n        \n        # Compute the estimate\n        integrand_values = (np.sum(points_unscrambled, axis=1) >= tau)\n        i_hat_unscrambled = np.mean(integrand_values)\n\n        # Compute the absolute error\n        e_unscrambled = np.abs(i_hat_unscrambled - exact_integral_value)\n\n        # Step 2.2: Compute R independent scrambled QMC estimates and their errors\n        scrambled_errors = []\n        for r in range(1, R + 1):\n            seed = S + r - 1\n            \n            # Initialize an Owen-scrambled Sobol' sequence generator with a unique seed\n            sampler_scrambled = qmc.Sobol(d=d, scramble=True, seed=seed)\n            points_scrambled = sampler_scrambled.random(n=N)\n            \n            # Compute the estimate\n            integrand_values_scr = (np.sum(points_scrambled, axis=1) >= tau)\n            i_hat_scrambled = np.mean(integrand_values_scr)\n            \n            # Compute and store the absolute error\n            e_scrambled = np.abs(i_hat_scrambled - exact_integral_value)\n            scrambled_errors.append(e_scrambled)\n\n        # Step 3: Calculate the performance ratio\n        median_scrambled_error = np.median(scrambled_errors)\n        \n        # Avoid division by zero, though highly unlikely in this context.\n        if median_scrambled_error == 0:\n            # If median error is 0, scrambling is perfect. \n            # If unscrambled is also 0, ratio is 1. Otherwise, ratio is effectively infinite.\n            # We assign a large number or handle as per problem specific but here we assume it won't happen.\n            rho = np.inf if e_unscrambled > 0 else 1.0\n        else:\n            rho = e_unscrambled / median_scrambled_error\n        \n        results.append(f\"{rho:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\n\ndef irwin_hall_cdf(x, d):\n    \"\"\"\n    Computes the Irwin-Hall cumulative distribution function F_IH(x; d).\n    \n    Args:\n        x (float): The value at which to evaluate the CDF.\n        d (int): The parameter of the distribution (number of uniform variables).\n    \n    Returns:\n        float: The value of the CDF.\n    \"\"\"\n    if x <= 0:\n        return 0.0\n    if x >= d:\n        return 1.0\n    \n    # Formula for 0 < x < d\n    total_sum = 0.0\n    k_max = math.floor(x)\n    \n    for k in range(k_max + 1):\n        # Calculate (-1)^k * C(d, k) * (x - k)^d\n        term = ((-1)**k) * comb(d, k, exact=True) * ((x - k)**d)\n        total_sum += term\n        \n    return total_sum / math.factorial(d)\n\n\nif __name__ == '__main__':\n    solve()\n```"}]}