{"hands_on_practices": [{"introduction": "The Milstein scheme is celebrated for its strong convergence order of $1$, a clear improvement over the Euler-Maruyama method's order of $0.5$. However, does this \"higher-order\" status always translate to better performance? This practice guides you to explore the crucial distinction between strong (pathwise) and weak (in expectation) convergence. By deriving the exact expected values of the numerical schemes, you will discover for yourself under what conditions the added complexity of the Milstein method is unnecessary for calculating expectations, a frequent task in financial pricing [@problem_id:2443108].", "id": "2443108", "problem": "You are given the task of constructing a numerical experiment, from first principles, to assess weak convergence properties of discrete-time approximations for Itô stochastic differential equations (SDEs) in the context of computational economics and finance. Consider a scalar Itô SDE of the form $dX_{t} = a(X_{t})\\,dt + b(X_{t})\\,dW_{t}$ over a fixed horizon $[0,T]$ with $X_{0}=x_{0}$, where $W_{t}$ is a standard Wiener process. A time-stepping method has weak order $p$ if, for sufficiently smooth functionals $\\varphi$, the bias $\\left| \\mathbb{E}[\\varphi(X_{T})] - \\mathbb{E}[\\varphi(\\widehat{X}_{T}^{h})] \\right|$ scales like $\\mathcal{O}(h^{p})$ as $h \\to 0$, where $h$ is the time step and $\\widehat{X}_{T}^{h}$ is the numerical approximation at time $T$. Starting from the Itô calculus foundation and the Itô–Taylor expansion, derive implementable update rules for the Euler–Maruyama method and the Milstein method for scalar SDEs, and then use those updates to compute exact expectations of the discrete-time approximations for the specific models and functionals below, without using Monte Carlo sampling. Your derivation must rely only on the independence and Gaussian moment properties of the Wiener increments and the tower property of conditional expectation.\n\nYou must write a complete, runnable program that:\n- Implements the Euler–Maruyama and Milstein schemes for the test problems below, deriving closed-form expressions for $\\mathbb{E}[\\varphi(\\widehat{X}_{T}^{h})]$ at a fixed terminal time $T$ using conditional expectations and known moments of Gaussian random variables, with no sampling.\n- For each scheme, computes the absolute weak error $\\left| \\mathbb{E}[\\varphi(X_{T})] - \\mathbb{E}[\\varphi(\\widehat{X}_{T}^{h})] \\right|$ for a set of decreasing step sizes $h$.\n- Estimates the observed weak order $p$ by performing a least-squares fit of $\\log(\\text{error})$ versus $\\log(h)$ across the provided step sizes.\n- Quantifies whether the Milstein scheme offers any advantage over Euler–Maruyama for simple expectation calculations by directly comparing their absolute weak errors for the identity functional.\n\nUse only the following models, parameters, and functionals as the test suite. In all items, time horizon is $T = 1.0$.\n\nTest suite:\n- Test $1$ (Geometric Brownian Motion): $dX_{t} = \\mu X_{t}\\,dt + \\sigma X_{t}\\,dW_{t}$ with $x_{0} = 1.0$, $\\mu = 0.05$, $\\sigma = 0.2$, $\\varphi(x)=x$.\n- Test $2$ (Geometric Brownian Motion): same model and parameters as Test $1$ but with $\\varphi(x)=x^{2}$.\n- Test $3$ (Ornstein–Uhlenbeck): $dX_{t} = \\kappa(\\theta - X_{t})\\,dt + \\sigma\\,dW_{t}$ with $x_{0} = 1.0$, $\\kappa = 1.2$, $\\theta = 0.8$, $\\sigma = 0.3$, $\\varphi(x)=x$.\n\nFor each test, use the exact model expectation $\\mathbb{E}[\\varphi(X_{T})]$ obtained from the closed-form solution of the SDE to define the bias. For Geometric Brownian Motion, you must use exact closed-form expressions for the first and second moments. For the Ornstein–Uhlenbeck model, you must use the exact closed-form expression for the mean. Do not use any Monte Carlo approximation anywhere in the program.\n\nStep sizes:\n- Use $N \\in \\{4, 8, 16, 32\\}$ uniform steps so that $h = T/N$.\n\nOutput:\n- For each of the three tests, compute the observed weak order $p$ for Euler–Maruyama and for Milstein using the least-squares slope of $\\log(\\text{error})$ versus $\\log(h)$ across the four $h$ values.\n- Also compute two booleans indicating, respectively, whether the absolute weak errors of Euler–Maruyama and Milstein coincide for Test $1$ across all $h$ within an absolute tolerance of $10^{-12}$, and whether they coincide for Test $3$ across all $h$ within an absolute tolerance of $10^{-12}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$[$observed\\_order\\_Euler\\_Test1, observed\\_order\\_Milstein\\_Test1, observed\\_order\\_Euler\\_Test2, observed\\_order\\_Milstein\\_Test2, observed\\_order\\_Euler\\_Test3, observed\\_order\\_Milstein\\_Test3, equal\\_errors\\_Test1, equal\\_errors\\_Test3$]$.\n- The first six entries must be floating-point numbers, and the last two entries must be booleans.", "solution": "The problem statement presented is a well-posed and scientifically sound exercise in computational finance. It asks for a rigorous, first-principles derivation and implementation of methods to assess the weak convergence of numerical schemes for Itô stochastic differential equations (SDEs). All required parameters, models, and analytical benchmarks are provided, and the problem is free of ambiguity, contradiction, or factual error. Therefore, the problem is deemed valid and a complete solution will be provided.\n\nThe general form of the scalar Itô SDE under consideration is:\n$$\ndX_t = a(X_t) dt + b(X_t) dW_t\n$$\nwith initial condition $X_0 = x_0$ over the time interval $[0, T]$. We are tasked with analyzing the weak error, defined as $\\left| \\mathbb{E}[\\varphi(X_T)] - \\mathbb{E}[\\varphi(\\widehat{X}_T^h)] \\right|$, where $\\widehat{X}_T^h$ is the numerical approximation at time $T$ using a step size $h$. The analysis will be conducted without Monte Carlo simulation, by deriving exact expressions for the expected value of the numerical solution.\n\nFirst, we establish the numerical schemes. The time interval $[0, T]$ is discretized into $N$ steps of size $h = T/N$, with grid points $t_i = ih$. The increment of the Wiener process over $[t_i, t_{i+1}]$ is $\\Delta W_i = W_{t_{i+1}} - W_{t_i} \\sim \\mathcal{N}(0, h)$. We can write $\\Delta W_i = \\sqrt{h} Z_i$, where $Z_i \\sim \\mathcal{N}(0, 1)$ are independent and identically distributed standard normal random variables.\n\nThe Euler-Maruyama (EM) scheme is derived from a first-order truncation of the Itô-Taylor expansion:\n$$\n\\widehat{X}_{i+1}^{\\text{EM}} = \\widehat{X}_i + a(\\widehat{X}_i)h + b(\\widehat{X}_i)\\sqrt{h}Z_i\n$$\n\nThe Milstein scheme includes one additional Itô-Taylor term, which involves a double Wiener integral. The update rule is:\n$$\n\\widehat{X}_{i+1}^{\\text{Mil}} = \\widehat{X}_i + a(\\widehat{X}_i)h + b(\\widehat{X}_i)\\sqrt{h}Z_i + \\frac{1}{2}b(\\widehat{X}_i)b'(\\widehat{X}_i)h(Z_i^2 - 1)\n$$\nwhere $b'(x) = \\frac{db}{dx}$.\n\nTo compute the expectation $\\mathbb{E}[\\varphi(\\widehat{X}_N^h)]$ recursively, we employ the tower property of conditional expectation. Let $m_i[\\psi] = \\mathbb{E}[\\psi(\\widehat{X}_i)]$ for some functional $\\psi$. Then,\n$$\nm_{i+1}[\\psi] = \\mathbb{E}[\\psi(\\widehat{X}_{i+1})] = \\mathbb{E}\\left[\\mathbb{E}[\\psi(\\widehat{X}_{i+1}) | \\mathcal{F}_{t_i}]\\right]\n$$\nwhere $\\mathcal{F}_{t_i}$ is the filtration at time $t_i$. Since $\\widehat{X}_i$ is $\\mathcal{F}_{t_i}$-measurable, the inner expectation is taken with respect to the random variable $Z_i$. This process allows us to derive a recurrence relation for the moments of $\\widehat{X}_i$. We use the moments of a standard normal variable: $\\mathbb{E}[Z_i] = 0$, $\\mathbb{E}[Z_i^2] = 1$, $\\mathbb{E}[Z_i^3] = 0$, and $\\mathbb{E}[Z_i^4] = 3$.\n\nTest $1$: Geometric Brownian Motion (GBM) with $\\varphi(x) = x$.\nThe SDE is $dX_t = \\mu X_t dt + \\sigma X_t dW_t$, with $a(x) = \\mu x$ and $b(x) = \\sigma x$. Thus, $b'(x) = \\sigma$.\nThe exact solution for the mean is $\\mathbb{E}[X_T] = x_0 e^{\\mu T}$.\n\nFor the EM scheme, the update is $\\widehat{X}_{i+1} = \\widehat{X}_i(1 + \\mu h + \\sigma \\sqrt{h}Z_i)$. Let $m_i = \\mathbb{E}[\\widehat{X}_i]$.\n$$\nm_{i+1} = \\mathbb{E}\\left[\\mathbb{E}\\left[\\widehat{X}_i(1 + \\mu h + \\sigma \\sqrt{h}Z_i) | \\mathcal{F}_{t_i}\\right]\\right] = \\mathbb{E}\\left[\\widehat{X}_i(1 + \\mu h)\\right] = (1 + \\mu h)m_i\n$$\nFor the Milstein scheme, the update is $\\widehat{X}_{i+1} = \\widehat{X}_i + \\mu \\widehat{X}_i h + \\sigma \\widehat{X}_i \\sqrt{h}Z_i + \\frac{1}{2}(\\sigma \\widehat{X}_i)\\sigma h(Z_i^2 - 1)$.\n$$\nm_{i+1} = \\mathbb{E}\\left[\\mathbb{E}\\left[\\widehat{X}_i \\left(1 + \\mu h + \\sigma \\sqrt{h}Z_i + \\frac{1}{2}\\sigma^2 h(Z_i^2 - 1)\\right) | \\mathcal{F}_{t_i}\\right]\\right]\n$$\nSince $\\mathbb{E}[Z_i]=0$ and $\\mathbb{E}[Z_i^2-1]=0$, the conditional expectation of the term in parentheses simplifies to $1 + \\mu h$. Thus, $m_{i+1} = (1 + \\mu h)m_i$, which is identical to the EM recurrence.\nFor both schemes, with $m_0 = x_0$, the solution is $\\mathbb{E}[\\widehat{X}_N^h] = x_0(1 + \\mu h)^N$. Consequently, their weak errors are identical for this test case.\n\nTest $2$: GBM with $\\varphi(x) = x^2$.\nThe exact second moment is $\\mathbb{E}[X_T^2] = x_0^2 e^{(2\\mu + \\sigma^2)T}$. Let $m_i^{(2)} = \\mathbb{E}[\\widehat{X}_i^2]$.\n\nFor the EM scheme, we compute $\\mathbb{E}[\\widehat{X}_{i+1}^2 | \\mathcal{F}_{t_i}]$:\n$$\n\\mathbb{E}[(\\widehat{X}_i(1 + \\mu h + \\sigma\\sqrt{h}Z_i))^2 | \\mathcal{F}_{t_i}] = \\widehat{X}_i^2 \\mathbb{E}[(1 + \\mu h)^2 + 2(1 + \\mu h)\\sigma\\sqrt{h}Z_i + \\sigma^2 h Z_i^2] = \\widehat{X}_i^2 ( (1+\\mu h)^2 + \\sigma^2 h )\n$$\nThe recurrence is $m_{i+1}^{(2)} = (1 + 2\\mu h + \\mu^2 h^2 + \\sigma^2 h)m_i^{(2)}$. The final value is $\\mathbb{E}[(\\widehat{X}_N^h)^2] = x_0^2(1 + (2\\mu + \\sigma^2)h + \\mu^2 h^2)^N$.\n\nFor the Milstein scheme, $\\widehat{X}_{i+1} = \\widehat{X}_i( (1+\\mu h - \\frac{1}{2}\\sigma^2h) + \\sigma\\sqrt{h}Z_i + \\frac{1}{2}\\sigma^2 h Z_i^2)$. Let $\\widehat{X}_{i+1} = \\widehat{X}_i(K_0 + K_1 Z_i + K_2 Z_i^2)$.\n$$\n\\mathbb{E}[\\widehat{X}_{i+1}^2 | \\mathcal{F}_{t_i}] = \\widehat{X}_i^2 \\mathbb{E}[(K_0 + K_1 Z_i + K_2 Z_i^2)^2] = \\widehat{X}_i^2 (K_0^2 + K_1^2 \\mathbb{E}[Z_i^2] + K_2^2 \\mathbb{E}[Z_i^4] + 2K_0K_2\\mathbb{E}[Z_i^2])\n$$\nUsing $\\mathbb{E}[Z_i^2]=1$ and $\\mathbb{E}[Z_i^4]=3$, and substituting $K_0=1+\\mu h - \\frac{1}{2}\\sigma^2h$, $K_1=\\sigma\\sqrt{h}$, $K_2=\\frac{1}{2}\\sigma^2h$:\n$$\nm_{i+1}^{(2)} = m_i^{(2)} \\left( (1+\\mu h - \\tfrac{1}{2}\\sigma^2h)^2 + \\sigma^2h + 3(\\tfrac{1}{2}\\sigma^2h)^2 + 2(1+\\mu h - \\tfrac{1}{2}\\sigma^2h)(\\tfrac{1}{2}\\sigma^2h) \\right)\n$$\nExpanding and collecting terms gives the coefficient:\n$1 + (2\\mu + \\sigma^2)h + (\\mu^2 + \\frac{1}{2}\\sigma^4)h^2$.\nSo, $\\mathbb{E}[(\\widehat{X}_N^h)^2] = x_0^2(1 + (2\\mu + \\sigma^2)h + (\\mu^2 + \\frac{1}{2}\\sigma^4)h^2)^N$. The errors for EM and Milstein will differ due to the $\\mathcal{O}(h^2)$ terms.\n\nTest $3$: Ornstein-Uhlenbeck (OU) with $\\varphi(x) = x$.\nThe SDE is $dX_t = \\kappa(\\theta - X_t) dt + \\sigma dW_t$, with $a(x) = \\kappa(\\theta - x)$ and $b(x) = \\sigma$.\nSince $b(x)$ is a constant, $b'(x) = 0$. The Milstein correction term, $\\frac{1}{2}b(x)b'(x)h(Z_i^2-1)$, is zero. Therefore, the Milstein scheme is identical to the Euler-Maruyama scheme for any SDE with additive noise.\nThe exact mean is $\\mathbb{E}[X_T] = x_0 e^{-\\kappa T} + \\theta(1-e^{-\\kappa T})$.\n\nThe common update rule is $\\widehat{X}_{i+1} = \\widehat{X}_i + \\kappa(\\theta - \\widehat{X}_i)h + \\sigma\\sqrt{h}Z_i$. Let $m_i = \\mathbb{E}[\\widehat{X}_i]$.\n$$\nm_{i+1} = \\mathbb{E}[\\widehat{X}_i(1-\\kappa h) + \\kappa\\theta h + \\sigma\\sqrt{h}Z_i] = (1-\\kappa h)m_i + \\kappa\\theta h\n$$\nThis is a linear recurrence relation $m_{i+1} = A m_i + B$ with $A=1-\\kappa h$ and $B=\\kappa\\theta h$. Its solution starting from $m_0=x_0$ is $m_N = A^N m_0 + B \\frac{1-A^N}{1-A}$. Substituting $A$ and $B$ gives:\n$$\n\\mathbb{E}[\\widehat{X}_N^h] = x_0(1-\\kappa h)^N + \\theta(1-(1-\\kappa h)^N)\n$$\nAs EM and Milstein are the same scheme, their weak errors are identical.\n\nWeak Order Estimation.\nThe weak order $p$ is estimated from the relationship $\\log(\\text{error}) \\approx \\log(C) + p \\log(h)$. We perform a linear least-squares regression of $\\log(\\text{error})$ on $\\log(h)$ for the set of step sizes $h \\in \\{T/4, T/8, T/16, T/32\\}$. The slope of the resulting line is the estimated order $p$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes weak convergence orders for Euler-Maruyama and Milstein schemes.\n    \"\"\"\n    # Global parameters\n    T = 1.0\n    Ns = np.array([4, 8, 16, 32])\n    hs = T / Ns\n    log_hs = np.log(hs)\n    abs_tol = 1e-12\n\n    # --- Test Case 1: Geometric Brownian Motion, phi(x)=x ---\n    x0_gbm = 1.0\n    mu = 0.05\n    sigma_gbm = 0.2\n\n    # Exact solution\n    exact_t1 = x0_gbm * np.exp(mu * T)\n\n    errors_em_t1 = []\n    errors_mil_t1 = []\n    \n    for h, N in zip(hs, Ns):\n        # For E[X_N], EM and Milstein recurrences are identical for GBM\n        num_val = x0_gbm * (1 + mu * h)**N\n        error = abs(exact_t1 - num_val)\n        errors_em_t1.append(error)\n        errors_mil_t1.append(error)\n\n    # Convert to numpy arrays for vectorized operations\n    errors_em_t1 = np.array(errors_em_t1)\n    errors_mil_t1 = np.array(errors_mil_t1)\n\n    # Estimate weak order p using polyfit on log-log data\n    # p is the slope (first coefficient)\n    p_em_t1 = np.polyfit(log_hs, np.log(errors_em_t1), 1)[0]\n    p_mil_t1 = np.polyfit(log_hs, np.log(errors_mil_t1), 1)[0]\n    \n    # Check if errors are identical within tolerance\n    equal_errors_t1 = np.allclose(errors_em_t1, errors_mil_t1, rtol=0, atol=abs_tol)\n\n    # --- Test Case 2: Geometric Brownian Motion, phi(x)=x^2 ---\n    # Exact solution for the second moment\n    exact_t2 = x0_gbm**2 * np.exp((2 * mu + sigma_gbm**2) * T)\n\n    errors_em_t2 = []\n    errors_mil_t2 = []\n\n    for h, N in zip(hs, Ns):\n        # Euler-Maruyama E[X_N^2]\n        term_em = 1 + (2 * mu + sigma_gbm**2) * h + mu**2 * h**2\n        num_val_em = x0_gbm**2 * term_em**N\n        errors_em_t2.append(abs(exact_t2 - num_val_em))\n        \n        # Milstein E[X_N^2]\n        term_mil = 1 + (2 * mu + sigma_gbm**2) * h + (mu**2 + 0.5 * sigma_gbm**4) * h**2\n        num_val_mil = x0_gbm**2 * term_mil**N\n        errors_mil_t2.append(abs(exact_t2 - num_val_mil))\n\n    p_em_t2 = np.polyfit(log_hs, np.log(errors_em_t2), 1)[0]\n    p_mil_t2 = np.polyfit(log_hs, np.log(errors_mil_t2), 1)[0]\n\n    # --- Test Case 3: Ornstein-Uhlenbeck, phi(x)=x ---\n    x0_ou = 1.0\n    kappa = 1.2\n    theta = 0.8\n    sigma_ou = 0.3\n\n    # Exact solution\n    exact_t3 = x0_ou * np.exp(-kappa * T) + theta * (1 - np.exp(-kappa * T))\n\n    errors_em_t3 = []\n    errors_mil_t3 = []\n\n    for h, N in zip(hs, Ns):\n        # For OU (additive noise), EM and Milstein schemes are identical\n        term = (1 - kappa * h)**N\n        num_val = term * x0_ou + theta * (1 - term)\n        error = abs(exact_t3 - num_val)\n        errors_em_t3.append(error)\n        errors_mil_t3.append(error)\n\n    errors_em_t3 = np.array(errors_em_t3)\n    errors_mil_t3 = np.array(errors_mil_t3)\n\n    p_em_t3 = np.polyfit(log_hs, np.log(errors_em_t3), 1)[0]\n    p_mil_t3 = np.polyfit(log_hs, np.log(errors_mil_t3), 1)[0]\n    \n    equal_errors_t3 = np.allclose(errors_em_t3, errors_mil_t3, rtol=0, atol=abs_tol)\n\n    # --- Final Output ---\n    results = [\n        p_em_t1, p_mil_t1,\n        p_em_t2, p_mil_t2,\n        p_em_t3, p_mil_t3,\n        equal_errors_t1, equal_errors_t3,\n    ]\n\n    # Format into the required string output\n    # bools will be converted to 'True'/'False'\n    # floats will be converted to their string representation\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"}, {"introduction": "A numerical simulation is only useful if it is stable. For stochastic systems, this often means ensuring that the moments of the solution, like the mean-square value, do not explode over time. This exercise moves from implementation to theoretical analysis, challenging you to derive the precise conditions for mean-square stability of the Milstein scheme for two cornerstone models: the Ornstein-Uhlenbeck process and Geometric Brownian Motion. Understanding these stability boundaries is a critical skill for selecting a valid time step $h$ and producing reliable simulations [@problem_id:2988113].", "id": "2988113", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a standard Brownian motion on a filtered probability space satisfying the usual conditions. Consider two It\\^{o} stochastic differential equations (SDEs) with globally Lipschitz and linearly growing coefficients:\n1) The Ornstein–Uhlenbeck (OU) process defined by\n$$\n\\mathrm{d}X_{t} \\;=\\; -\\lambda X_{t}\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t},\n$$\nwith $\\lambda>0$, $\\sigma>0$, and initial condition $X_{0}$ satisfying $\\mathbb{E}[X_{0}^{2}]<\\infty$.\n2) The geometric Brownian motion (GBM) defined by\n$$\n\\mathrm{d}Y_{t} \\;=\\; \\mu Y_{t}\\,\\mathrm{d}t \\;+\\; \\sigma Y_{t}\\,\\mathrm{d}W_{t},\n$$\nwith $\\mu \\in \\mathbb{R}$, $\\sigma>0$, and initial condition $Y_{0}$ satisfying $\\mathbb{E}[Y_{0}^{2}]<\\infty$.\n\nLet $\\{t_{n}\\}_{n \\geq 0}$ denote a uniform grid with step size $h>0$, $t_{n}=nh$, and let $\\Delta W_{n}:=W_{t_{n+1}}-W_{t_{n}}$. Apply the one-step Milstein scheme to each SDE to obtain numerical approximations $\\{X_{n}\\}_{n \\geq 0}$ for the OU process and $\\{Y_{n}\\}_{n \\geq 0}$ for the GBM, with $X_{0}$ and $Y_{0}$ given.\n\nStarting from first principles of It\\^{o} calculus and the definition of the Milstein method, and using only well-tested facts about Gaussian increments (e.g., $\\mathbb{E}[\\Delta W_{n}]=0$, $\\mathbb{E}[(\\Delta W_{n})^{2}]=h$, $\\mathbb{E}[(\\Delta W_{n})^{3}]=0$, $\\mathbb{E}[(\\Delta W_{n})^{4}]=3h^{2}$), carry out the following:\n- Derive the exact second-moment evolution $\\mathbb{E}[X_{t}^{2}]$ for the OU process, and determine the stationary second-moment bound as $t \\to \\infty$. Derive the second-moment recursion for the Milstein discretization (which, for additive noise, coincides with the Euler–Maruyama scheme), establish the condition on $h$ under which $\\{\\mathbb{E}[X_{n}^{2}]\\}_{n \\geq 0}$ remains uniformly bounded, and determine the largest allowable step size $h_{\\star}^{\\mathrm{OU}}$ for which this uniform boundedness (mean-square dissipativity) holds.\n- Derive the exact second-moment evolution $\\mathbb{E}[Y_{t}^{2}]$ for the GBM and state the parameter regime in which the exact dynamics are mean-square dissipative. For the Milstein scheme applied to the GBM, derive the multiplicative second-moment amplification factor $r(h)$ defined by $\\mathbb{E}[Y_{n+1}^{2}]=r(h)\\,\\mathbb{E}[Y_{n}^{2}]$. From the mean-square dissipativity requirement $r(h)<1$, determine the largest allowable step size $h_{\\star}^{\\mathrm{GBM}}$ as an explicit function of $\\mu$ and $\\sigma$.\n\nExpress your final answer as a single closed-form analytical expression containing both thresholds $h_{\\star}^{\\mathrm{OU}}$ and $h_{\\star}^{\\mathrm{GBM}}$ arranged as a row matrix using the $\\mathrm{pmatrix}$ environment. No numerical approximation or rounding is required, and no units are to be included in the final answer.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in the field of numerical analysis for stochastic differential equations. We proceed with the solution.\n\nThe solution is presented in two parts, one for the Ornstein–Uhlenbeck (OU) process and one for the geometric Brownian motion (GBM), as requested.\n\n### Part 1: Ornstein–Uhlenbeck Process\n\nThe SDE for the OU process is given by:\n$$\n\\mathrm{d}X_{t} = -\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}\n$$\nwhere $\\lambda > 0$, $\\sigma > 0$, and $\\mathbb{E}[X_{0}^{2}] < \\infty$.\n\n**Exact Second-Moment Evolution**\nTo find the evolution of the second moment, $\\mathbb{E}[X_{t}^{2}]$, we apply Itō's lemma to the function $f(x) = x^{2}$. The derivatives are $f'(x)=2x$ and $f''(x)=2$. Itō's lemma states that for a process $X_t$ and a twice-differentiable function $f$,\n$$\n\\mathrm{d}f(X_{t}) = f'(X_{t})\\,\\mathrm{d}X_{t} + \\frac{1}{2}f''(X_{t})\\,(\\mathrm{d}X_{t})^{2}.\n$$\nSubstituting the SDE for $\\mathrm{d}X_{t}$, we get:\n$$\n\\mathrm{d}(X_{t}^{2}) = 2X_{t}(-\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}) + \\frac{1}{2}(2)(-\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t})^{2}.\n$$\nAccording to Itō calculus rules, $(\\mathrm{d}t)^{2}=0$, $\\mathrm{d}t\\,\\mathrm{d}W_{t}=0$, and $(\\mathrm{d}W_{t})^{2}=\\mathrm{d}t$. Thus, the quadratic variation term is $(\\mathrm{d}X_{t})^{2} = \\sigma^{2}(\\mathrm{d}W_{t})^{2} = \\sigma^{2}\\mathrm{d}t$.\nThe expression for $\\mathrm{d}(X_{t}^{2})$ becomes:\n$$\n\\mathrm{d}(X_{t}^{2}) = -2\\lambda X_{t}^{2}\\,\\mathrm{d}t + 2\\sigma X_{t}\\,\\mathrm{d}W_{t} + \\sigma^{2}\\,\\mathrm{d}t.\n$$\nLet $m_{2}(t) = \\mathbb{E}[X_{t}^{2}]$. Taking the expectation of the integral form of the above equation, and noting that the expectation of the Itō integral term is zero (i.e., $\\mathbb{E}[\\int_{0}^{t} 2\\sigma X_{s}\\,\\mathrm{d}W_{s}]=0$ since $X_s$ is adapted), we obtain an ordinary differential equation (ODE) for $m_{2}(t)$:\n$$\n\\frac{\\mathrm{d}m_{2}(t)}{\\mathrm{d}t} = \\mathbb{E}[-2\\lambda X_{t}^{2} + \\sigma^{2}] = -2\\lambda m_{2}(t) + \\sigma^{2}.\n$$\nThis is a first-order linear ODE, $m'_{2}(t) + 2\\lambda m_{2}(t) = \\sigma^{2}$. The solution with initial condition $m_{2}(0) = \\mathbb{E}[X_{0}^{2}]$ is:\n$$\nm_{2}(t) = \\frac{\\sigma^{2}}{2\\lambda} + \\left(\\mathbb{E}[X_{0}^{2}] - \\frac{\\sigma^{2}}{2\\lambda}\\right)\\exp(-2\\lambda t).\n$$\nAs $t \\to \\infty$, since $\\lambda > 0$, the exponential term decays to zero. The stationary second-moment bound is:\n$$\n\\lim_{t \\to \\infty} \\mathbb{E}[X_{t}^{2}] = \\frac{\\sigma^{2}}{2\\lambda}.\n$$\n\n**Milstein Discretization and Mean-Square Stability**\nThe general one-step Milstein scheme for an SDE $\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + b(X_{t})\\,\\mathrm{d}W_{t}$ is:\n$$\nX_{n+1} = X_{n} + a(X_n)h + b(X_n)\\Delta W_n + \\frac{1}{2}b(X_n)b'(X_n)((\\Delta W_n)^2 - h).\n$$\nFor the OU process, we have $a(x) = -\\lambda x$ and $b(x) = \\sigma$. Since $b(x)$ is a constant, its derivative $b'(x) = 0$. Therefore, the Milstein scheme simplifies to the Euler–Maruyama scheme:\n$$\nX_{n+1} = X_{n} - \\lambda X_{n} h + \\sigma \\Delta W_{n} = (1 - \\lambda h)X_{n} + \\sigma \\Delta W_{n}.\n$$\nTo find the second-moment recursion, we square both sides:\n$$\nX_{n+1}^{2} = ((1 - \\lambda h)X_{n} + \\sigma \\Delta W_{n})^{2} = (1 - \\lambda h)^{2}X_{n}^{2} + 2\\sigma(1 - \\lambda h)X_{n}\\Delta W_{n} + \\sigma^{2}(\\Delta W_{n})^{2}.\n$$\nLet $\\mathcal{M}_{n} = \\mathbb{E}[X_{n}^{2}]$. We take the expectation, conditional on the information at time $t_{n}$, denoted by $\\mathcal{F}_{t_{n}}$. Since $X_n$ is $\\mathcal{F}_{t_{n}}$-measurable and $\\Delta W_n$ is independent of $\\mathcal{F}_{t_{n}}$, we use the provided facts $\\mathbb{E}[\\Delta W_{n}] = 0$ and $\\mathbb{E}[(\\Delta W_{n})^{2}] = h$:\n$$\n\\mathbb{E}[X_{n+1}^{2} | \\mathcal{F}_{t_{n}}] = (1 - \\lambda h)^{2}X_{n}^{2} + 2\\sigma(1 - \\lambda h)X_{n}\\mathbb{E}[\\Delta W_{n}] + \\sigma^{2}\\mathbb{E}[(\\Delta W_{n})^{2}] = (1 - \\lambda h)^{2}X_{n}^{2} + \\sigma^{2}h.\n$$\nTaking the full expectation gives the recursion for $\\mathcal{M}_{n}$:\n$$\n\\mathcal{M}_{n+1} = (1 - \\lambda h)^{2}\\mathcal{M}_{n} + \\sigma^{2}h.\n$$\nFor the sequence $\\{\\mathcal{M}_{n}\\}_{n \\ge 0}$ to remain uniformly bounded for any finite initial second moment $\\mathcal{M}_{0}$, the recurrence must be stable. This requires the magnitude of the amplification factor of the homogeneous part to be strictly less than $1$. If the magnitude were equal to $1$, $\\mathcal{M}_{n}$ would grow arithmetically, and thus would not be uniformly bounded. The condition is:\n$$\n|1 - \\lambda h| < 1.\n$$\nThis inequality is equivalent to $-1 < 1 - \\lambda h < 1$.\nThe right-hand side, $1 - \\lambda h < 1$, implies $-\\lambda h < 0$. Since $\\lambda > 0$ and $h > 0$, this is always satisfied.\nThe left-hand side, $-1 < 1 - \\lambda h$, implies $\\lambda h < 2$.\nThus, the condition for uniform boundedness is $h < \\frac{2}{\\lambda}$. The largest allowable step size is the supremum of this set, which is:\n$$\nh_{\\star}^{\\mathrm{OU}} = \\frac{2}{\\lambda}.\n$$\n\n### Part 2: Geometric Brownian Motion\n\nThe SDE for GBM is given by:\n$$\n\\mathrm{d}Y_{t} = \\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t}\n$$\nwhere $\\mu \\in \\mathbb{R}$, $\\sigma > 0$, and $\\mathbb{E}[Y_{0}^{2}] < \\infty$.\n\n**Exact Second-Moment Evolution**\nWe again apply Itō's lemma to $f(y) = y^{2}$, so $f'(y)=2y$ and $f''(y)=2$.\n$$\n\\mathrm{d}(Y_{t}^{2}) = 2Y_{t}(\\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t}) + \\frac{1}{2}(2)(\\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t})^{2}.\n$$\nThe quadratic variation term is $(\\mathrm{d}Y_{t})^{2} = \\sigma^{2}Y_{t}^{2}(\\mathrm{d}W_{t})^{2} = \\sigma^{2}Y_{t}^{2}\\mathrm{d}t$.\nSubstituting this, we get:\n$$\n\\mathrm{d}(Y_{t}^{2}) = 2\\mu Y_{t}^{2}\\,\\mathrm{d}t + 2\\sigma Y_{t}^{2}\\,\\mathrm{d}W_{t} + \\sigma^{2}Y_{t}^{2}\\mathrm{d}t = (2\\mu + \\sigma^{2})Y_{t}^{2}\\,\\mathrm{d}t + 2\\sigma Y_{t}^{2}\\,\\mathrm{d}W_{t}.\n$$\nLet $m_{2}(t) = \\mathbb{E}[Y_{t}^{2}]$. Taking the expectation, the Itō integral term vanishes, and we obtain the ODE:\n$$\n\\frac{\\mathrm{d}m_{2}(t)}{\\mathrm{d}t} = (2\\mu + \\sigma^{2})m_{2}(t).\n$$\nThe solution is $m_{2}(t) = m_{2}(0)\\exp((2\\mu + \\sigma^{2})t)$. For the exact dynamics to be mean-square dissipative, the second moment must decay to zero as $t \\to \\infty$. This requires the exponent to be negative. The parameter regime is:\n$$\n2\\mu + \\sigma^{2} < 0.\n$$\n\n**Milstein Discretization and Mean-Square Stability**\nFor GBM, we have $a(y) = \\mu y$ and $b(y) = \\sigma y$, so $b'(y) = \\sigma$. The Milstein scheme is:\n$$\n\\begin{aligned}\nY_{n+1} &= Y_{n} + \\mu Y_{n}h + \\sigma Y_{n}\\Delta W_{n} + \\frac{1}{2}(\\sigma Y_{n})(\\sigma)((\\Delta W_{n})^{2} - h) \\\\\n&= Y_{n}\\left[1 + \\mu h + \\sigma \\Delta W_{n} + \\frac{1}{2}\\sigma^{2}((\\Delta W_{n})^{2} - h)\\right].\n\\end{aligned}\n$$\nThe problem defines the multiplicative amplification factor $r(h)$ via $\\mathbb{E}[Y_{n+1}^{2}] = r(h)\\mathbb{E}[Y_{n}^{2}]$. By the tower property and independence of $\\Delta W_n$ from $\\mathcal{F}_{t_n}$, we have:\n$$\nr(h) = \\mathbb{E}\\left[\\left(1 + \\mu h - \\frac{1}{2}\\sigma^{2}h + \\sigma\\Delta W_{n} + \\frac{1}{2}\\sigma^{2}(\\Delta W_{n})^{2}\\right)^{2}\\right].\n$$\nLet $C = 1 + \\mu h - \\frac{1}{2}\\sigma^{2}h$ and $Z_{n} = \\Delta W_{n}$. We need to compute $\\mathbb{E}[(C + \\sigma Z_{n} + \\frac{1}{2}\\sigma^{2}Z_{n}^{2})^{2}]$.\nExpanding the square:\n$$\n(C + \\sigma Z_{n} + \\frac{1}{2}\\sigma^{2}Z_{n}^{2})^{2} = C^{2} + \\sigma^{2}Z_{n}^{2} + \\frac{1}{4}\\sigma^{4}Z_{n}^{4} + 2C\\sigma Z_{n} + C\\sigma^{2}Z_{n}^{2} + \\sigma^{3}Z_{n}^{3}.\n$$\nTaking the expectation and using the given moments $\\mathbb{E}[Z_n]=0$, $\\mathbb{E}[Z_n^2]=h$, $\\mathbb{E}[Z_n^3]=0$, $\\mathbb{E}[Z_n^4]=3h^2$:\n$$\n\\begin{aligned}\nr(h) &= \\mathbb{E}[C^{2}] + \\sigma^{2}\\mathbb{E}[Z_{n}^{2}] + \\frac{1}{4}\\sigma^{4}\\mathbb{E}[Z_{n}^{4}] + 2C\\sigma\\mathbb{E}[Z_{n}] + C\\sigma^{2}\\mathbb{E}[Z_{n}^{2}] + \\sigma^{3}\\mathbb{E}[Z_{n}^{3}] \\\\\n&= C^{2} + \\sigma^{2}h + \\frac{1}{4}\\sigma^{4}(3h^{2}) + 0 + C\\sigma^{2}h + 0 \\\\\n&= C^{2} + (1+C)\\sigma^{2}h + \\frac{3}{4}\\sigma^{4}h^{2}.\n\\end{aligned}\n$$\nSubstituting $C = 1 + (\\mu - \\frac{1}{2}\\sigma^{2})h$:\n$C^{2} = (1 + (\\mu - \\frac{1}{2}\\sigma^{2})h)^{2} = 1 + 2(\\mu - \\frac{1}{2}\\sigma^{2})h + (\\mu - \\frac{1}{2}\\sigma^{2})^{2}h^{2}$.\n$1+C = 2 + (\\mu - \\frac{1}{2}\\sigma^{2})h$.\nSo, $(1+C)\\sigma^{2}h = 2\\sigma^{2}h + (\\mu - \\frac{1}{2}\\sigma^{2})\\sigma^{2}h^{2}$.\nSumming all terms for $r(h)$:\n$$\n\\begin{aligned}\nr(h) &= \\left(1 + (2\\mu - \\sigma^{2})h + (\\mu^{2}-\\mu\\sigma^{2}+\\frac{1}{4}\\sigma^{4})h^{2}\\right) + \\left(2\\sigma^{2}h + (\\mu\\sigma^{2}-\\frac{1}{2}\\sigma^{4})h^{2}\\right) + \\frac{3}{4}\\sigma^{4}h^{2} \\\\\n&= 1 + (2\\mu - \\sigma^{2} + 2\\sigma^{2})h + (\\mu^{2}-\\mu\\sigma^{2}+\\frac{1}{4}\\sigma^{4} + \\mu\\sigma^{2}-\\frac{1}{2}\\sigma^{4} + \\frac{3}{4}\\sigma^{4})h^{2} \\\\\n&= 1 + (2\\mu + \\sigma^{2})h + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h^{2}.\n\\end{aligned}\n$$\nThe mean-square dissipativity requirement is $r(h) < 1$:\n$$\n1 + (2\\mu + \\sigma^{2})h + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h^{2} < 1.\n$$\nFor $h > 0$, this simplifies to:\n$$\n(2\\mu + \\sigma^{2}) + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h < 0.\n$$\nFor this inequality to have a solution for $h > 0$, we must have the constant term negative, since the term with $h$ has a positive coefficient $(\\mu^{2} + \\frac{1}{2}\\sigma^{4}) > 0$. This implies $2\\mu + \\sigma^{2} < 0$, which is exactly the dissipativity condition for the continuous SDE.\nUnder this condition, we solve for $h$:\n$$\n(\\mu^{2} + \\frac{1}{2}\\sigma^{4})h < -(2\\mu + \\sigma^{2}).\n$$\n$$\nh < \\frac{-(2\\mu + \\sigma^{2})}{\\mu^{2} + \\frac{1}{2}\\sigma^{4}}.\n$$\nThe largest allowable step size is the supremum of this interval:\n$$\nh_{\\star}^{\\mathrm{GBM}} = \\frac{-(2\\mu + \\sigma^{2})}{\\mu^{2} + \\frac{1}{2}\\sigma^{4}}.\n$$\nThis threshold is valid only in the parameter regime $2\\mu+\\sigma^2 < 0$. Otherwise, no step size $h>0$ can ensure mean-square dissipativity for the Milstein method.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{\\lambda} & \\frac{-(2\\mu + \\sigma^2)}{\\mu^2 + \\frac{1}{2}\\sigma^4}\n\\end{pmatrix}\n}\n$$"}, {"introduction": "Stochastic differential equations can be interpreted in different mathematical frameworks, most commonly those of Itô and Stratonovich. While mathematically equivalent after a drift correction, naively applying an Itô-based solver like the Milstein scheme to a model written in Stratonovich form is a common and serious error. This practice illuminates this critical distinction, tasking you with simulating a process under both the correct (converted Itô) and incorrect (naive Itô) interpretations [@problem_id:3002512]. This will provide a tangible demonstration of the noise-induced drift and solidify your understanding of how to correctly apply numerical methods.", "id": "3002512", "problem": "Consider the scalar stochastic differential equation for a real-valued process $X_t$ with initial value $X_0 = x_0$ and a single Brownian motion $W_t$. Two interpretations of the stochastic integral are commonly used: the Itô interpretation and the Stratonovich interpretation. Both interpretations define valid stochastic models, but they obey different chain rules and lead to different drift terms after conversion. You will investigate how interpreting the same stochastic model as Stratonovich versus Itô produces systematically different numerical trajectories when using a strong order one numerical method (the Milstein method) that is appropriate for Itô equations.\n\nYour tasks are as follows, in sequence, starting from fundamental definitions and well-tested facts:\n\n1) Using the fundamental definitions of the Itô integral and the Stratonovich integral, and the fact that they obey different change-of-variable (chain) rules, derive the drift correction that converts a Stratonovich stochastic differential equation into an Itô stochastic differential equation with the same sample-path law. Your derivation should be based on the Itô formula and the classical chain rule for the Stratonovich integral, and should yield a precise expression for the Itô drift in terms of the Stratonovich drift and the diffusion coefficient.\n\n2) Starting from the Itô-Taylor expansion up to strong order one, derive the explicit one-step update that defines the Milstein method for a scalar Itô stochastic differential equation with drift $a(x)$ and diffusion $b(x)$. Your result should include the dependence on the derivative $b'(x)$ and the Brownian increment $\\Delta W$.\n\n3) Use the result of part 1 to determine how to simulate a Stratonovich model via an Itô integrator: that is, specify which drift must be used in the Milstein step to be consistent with the Stratonovich interpretation.\n\n4) Implement a program that, for each test case described below, constructs two numerical trajectories over the same time grid and driven by the same Brownian increments:\n   - Trajectory S: interpret the model as a Stratonovich stochastic differential equation. Convert it to an equivalent Itô form and integrate it with the Milstein method from part 2.\n   - Trajectory I_mis: treat the same symbolic coefficients as if they defined an Itô stochastic differential equation without performing any conversion, and integrate it with the Milstein method from part 2.\n\nFor each test case, return the scalar difference of the terminal values $X_S(T) - X_{I\\_mis}(T)$, where $X_S(T)$ is the terminal value of Trajectory S and $X_{I\\_mis}(T)$ is the terminal value of Trajectory I\\_mis. To ensure a fair comparison, the two trajectories within a given test case must use exactly the same Brownian increments. No physical units are involved.\n\nYou must use the following test suite. Each test case specifies a functional form for the drift and diffusion, a time horizon, a step count, and a random seed to generate the Brownian increments. All angles, if any, must be treated as dimensionless real numbers.\n\n- Test case A (multiplicative noise; expect a nonzero terminal difference that does not vanish as the step size decreases): Stratonovich drift $\\alpha(x) = \\lambda x$, diffusion $b(x) = \\sigma x$, with parameters $x_0 = 1.0$, $\\lambda = 0.25$, $\\sigma = 1.0$, final time $T = 1.0$, number of steps $N = 2000$, random seed $7$.\n- Test case B (additive noise; boundary case where the interpretations coincide): Stratonovich drift $\\alpha(x) = \\lambda x$, diffusion $b(x) = \\sigma$ (constant), with parameters $x_0 = 1.0$, $\\lambda = 0.25$, $\\sigma = 1.0$, final time $T = 1.0$, number of steps $N = 2000$, random seed $7$.\n- Test case C (multiplicative noise with a much finer grid; demonstrates that the discrepancy persists under refinement): Stratonovich drift $\\alpha(x) = \\lambda x$, diffusion $b(x) = \\sigma x$, with parameters $x_0 = 1.0$, $\\lambda = 0.25$, $\\sigma = 1.0$, final time $T = 1.0$, number of steps $N = 20000$, random seed $12345$.\n\nImplementation details and constraints:\n- For each test case, generate independent and identically distributed Gaussian Brownian increments $\\Delta W_n \\sim \\mathcal{N}(0,h)$ where $h = T/N$, using the specified seed. Use the same increments when integrating Trajectory S and Trajectory I\\_mis for that test case.\n- For Trajectory S, you must first convert the Stratonovich model to the equivalent Itô model and then apply the Milstein method from part 2.\n- For Trajectory I\\_mis, you must directly apply the Milstein method using the given symbolic coefficients as though they defined an Itô model, without conversion.\n- Use double-precision floating point arithmetic.\n\nFinal output format:\n- Your program should produce a single line of output containing the terminal differences for the three test cases, expressed as a comma-separated list enclosed in square brackets and printed as real numbers in standard decimal notation, for example, \"[0.12345,0.0,0.23456]\".\n\nThe only acceptable return type is a single list of three real numbers in the specified format. No other text should be printed.", "solution": "The problem requires a multistep derivation and implementation related to the Itô and Stratonovich interpretations of stochastic differential equations (SDEs) and their numerical solution via the Milstein method.\n\n### Part 1: Derivation of the Itô-Stratonovich Conversion Rule\n\nA scalar Stratonovich SDE is given by:\n$$dX_t = \\alpha(X_t) dt + b(X_t) \\circ dW_t$$\nwhere $\\alpha(x)$ is the Stratonovich drift, $b(x)$ is the diffusion coefficient, $W_t$ is a standard Wiener process, and `$\\circ$` denotes the Stratonovich integral. We seek an equivalent Itô SDE of the form:\n$$dX_t = a(X_t) dt + b(X_t) dW_t$$\nwhere $a(x)$ is the Itô drift and the integral with respect to $dW_t$ is in the Itô sense.\n\nThe fundamental relationship between an Itô differential $b(X_t) dW_t$ and a Stratonovich differential $b(X_t) \\circ dW_t$ is given by:\n$$b(X_t) \\circ dW_t = b(X_t) dW_t + \\frac{1}{2} d[b(X), W]_t$$\nwhere $[b(X), W]_t$ is the quadratic covariation process of $b(X_t)$ and $W_t$.\n\nTo calculate the quadratic covariation, we first express $db(X_t)$ using Itô's lemma. The process $X_t$ itself follows the Itô SDE $dX_t = a(X_t) dt + b(X_t) dW_t$. Applying Itô's lemma to the function $b(x)$ yields:\n$$db(X_t) = b'(X_t) dX_t + \\frac{1}{2} b''(X_t) (dX_t)^2$$\nExpanding this using the rules $(dW_t)^2=dt$, $dt \\cdot dW_t = 0$, and $(dt)^2=0$:\n$$db(X_t) = b'(X_t) [a(X_t) dt + b(X_t) dW_t] + \\frac{1}{2} b''(X_t) [b(X_t) dW_t]^2$$\n$$db(X_t) = [a(X_t)b'(X_t) + \\frac{1}{2}b(X_t)^2 b''(X_t)] dt + [b(X_t)b'(X_t)] dW_t$$\nThe quadratic covariation $d[b(X), W]_t$ is the product of the coefficients of the $dW_t$ terms in the stochastic differentials of $b(X_t)$ and $W_t$, multiplied by $dt$. The differential of $W_t$ is $dW_t = 1 \\cdot dW_t$. Thus:\n$$d[b(X), W]_t = (b(X_t)b'(X_t)) \\cdot (1) \\cdot dt = b(X_t)b'(X_t) dt$$\nSubstituting this back into the conversion formula for the integrals:\n$$b(X_t) \\circ dW_t = b(X_t) dW_t + \\frac{1}{2} b(X_t)b'(X_t) dt$$\nNow, we substitute this expression into the original Stratonovich SDE:\n$$dX_t = \\alpha(X_t) dt + \\left(b(X_t) dW_t + \\frac{1}{2} b(X_t)b'(X_t) dt\\right)$$\nGrouping the $dt$ terms, we get:\n$$dX_t = \\left(\\alpha(X_t) + \\frac{1}{2} b(X_t)b'(X_t)\\right) dt + b(X_t) dW_t$$\nBy comparing this with the target Itô SDE form, we identify the Itô drift $a(x)$ as:\n$$a(x) = \\alpha(x) + \\frac{1}{2} b(x)b'(x)$$\nThis is the required drift correction. The additional term $\\frac{1}{2} b(x)b'(x)$ is often called the Itô-Stratonovich correction term or noise-induced drift.\n\n### Part 2: Derivation of the Milstein Method\n\nThe Milstein method is a numerical scheme for solving an Itô SDE, derived from an Itô-Taylor expansion. Consider the Itô SDE:\n$$dX_t = a(X_t) dt + b(X_t) dW_t$$\nIts integral form over a small time step $h = t_{n+1} - t_n$ is:\n$$X_{t_{n+1}} = X_{t_n} + \\int_{t_n}^{t_{n+1}} a(X_s) ds + \\int_{t_n}^{t_{n+1}} b(X_s) dW_s$$\nTo derive the Milstein method, we expand the integrands $a(X_s)$ and $b(X_s)$ around $X_{t_n}$.\nWe approximate $a(X_s) \\approx a(X_{t_n})$.\nFor $b(X_s)$, we use a first-order Itô-Taylor expansion: $b(X_s) \\approx b(X_{t_n}) + \\mathcal{L}b(X_{t_n})(s-t_n)$, where $\\mathcal{L}$ is the generator of the SDE. More directly, we can write:\n$$b(X_s) \\approx b(X_{t_n}) + b'(X_{t_n})(X_s - X_{t_n})$$\nWe approximate the increment $X_s - X_{t_n}$ by its lowest order term:\n$$X_s - X_{t_n} \\approx \\int_{t_n}^s b(X_{t_n}) dW_u = b(X_{t_n})(W_s - W_{t_n})$$\nSubstituting these approximations back into the integral equation:\n$$X_{t_{n+1}} \\approx X_{t_n} + \\int_{t_n}^{t_{n+1}} a(X_{t_n}) ds + \\int_{t_n}^{t_{n+1}} \\left[ b(X_{t_n}) + b'(X_{t_n})b(X_{t_n})(W_s - W_{t_n}) \\right] dW_s$$\nEvaluating the integrals term by term:\n$$ \\int_{t_n}^{t_{n+1}} a(X_{t_n}) ds = a(X_{t_n}) h $$\n$$ \\int_{t_n}^{t_{n+1}} b(X_{t_n}) dW_s = b(X_{t_n}) \\Delta W_n $$\nwhere $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is the Wiener increment, a random variable with distribution $\\mathcal{N}(0, h)$.\nThe final integral is a double Itô integral:\n$$ \\int_{t_n}^{t_{n+1}} b(X_{t_n})b'(X_{t_n})(W_s - W_{t_n}) dW_s = b(X_{t_n})b'(X_{t_n}) \\int_{t_n}^{t_{n+1}} (W_s - W_{t_n}) dW_s $$\nThis iterated integral has a known value:\n$$ \\int_{t_n}^{t_{n+1}} (W_s - W_{t_n}) dW_s = \\frac{1}{2} \\left[ (\\Delta W_n)^2 - h \\right] $$\nCombining all terms, we obtain the one-step update rule for the Milstein method, where $X_n \\approx X_{t_n}$:\n$$X_{n+1} = X_n + a(X_n)h + b(X_n)\\Delta W_n + \\frac{1}{2} b(X_n)b'(X_n) \\left[ (\\Delta W_n)^2 - h \\right]$$\nThis scheme has a strong order of convergence of $1.0$.\n\n### Part 3: Simulating a Stratonovich Model via an Itô Integrator\n\nTo simulate a Stratonovich SDE using an Itô integrator like the Milstein method, one must first convert the Stratonovich SDE to its mathematically equivalent Itô form.\nGiven the Stratonovich model:\n$$dX_t = \\alpha(X_t) dt + b(X_t) \\circ dW_t$$\nFrom Part $1$, its equivalent Itô form is:\n$$dX_t = \\left(\\alpha(X_t) + \\frac{1}{2} b(X_t)b'(X_t)\\right) dt + b(X_t) dW_t$$\nTo simulate this process, we apply the Milstein method (from Part $2$) to this Itô SDE. We identify the Itô drift as $a(x) = \\alpha(x) + \\frac{1}{2} b(x)b'(x)$ and the diffusion as $b(x)$. Substituting these into the Milstein formula yields the correct update rule for simulating the Stratonovich SDE:\n$$X_{n+1} = X_n + \\left[\\alpha(X_n) + \\frac{1}{2}b(X_n)b'(X_n)\\right]h + b(X_n)\\Delta W_n + \\frac{1}{2} b(X_n)b'(X_n) \\left[ (\\Delta W_n)^2 - h \\right]$$\n\n### Part 4: Numerical Trajectories Specification\n\nThe problem requires constructing two trajectories:\n1.  **Trajectory S**: This correctly simulates the Stratonovich SDE. The numerical scheme uses the derived equivalent Itô drift $a_S(x) = \\alpha(x) + \\frac{1}{2}b(x)b'(x)$. The update rule is:\n    $$X_{n+1}^S = X_n^S + a_S(X_n^S)h + b(X_n^S)\\Delta W_n + \\frac{1}{2} b(X_n^S)b'(X_n^S) ((\\Delta W_n)^2 - h)$$\n2.  **Trajectory I_mis**: This incorrectly treats the symbolic coefficients $(\\alpha, b)$ of the Stratonovich SDE as if they defined an Itô SDE from the outset. The numerical scheme therefore uses the Itô drift $a_{I\\_mis}(x) = \\alpha(x)$ without the crucial correction term. The update rule is:\n    $$X_{n+1}^{I\\_mis} = X_n^{I\\_mis} + a_{I\\_mis}(X_n^{I\\_mis})h + b(X_n^{I\\_mis})\\Delta W_n + \\frac{1}{2} b(X_n^{I\\_mis})b'(X_n^{I\\_mis}) ((\\Delta W_n)^2 - h)$$\n\nThe difference between the two trajectories arises solely from the difference in the drift term used in the integration step. In each step, ignoring higher-order differences in the states $X_n^S$ and $X_n^{I\\_mis}$, the update for $X^S$ has an additional drift component of $\\frac{1}{2}b(X_n)b'(X_n)h$. This systematic difference accumulates over the simulation, leading to a divergence between the paths. If $b'(x) = 0$ (additive noise), the correction term vanishes, and the Itô and Stratonovich interpretations coincide, resulting in identical trajectories.", "answer": "```python\nimport numpy as np\n\n# It is specified that scipy version 1.11.4 is available,\n# but it is not required for this problem.\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # We use 'lam' for the parameter lambda to avoid Python keyword conflict.\n    test_cases = [\n        # Test Case A (multiplicative noise)\n        {\n            'x0': 1.0, 'lam': 0.25, 'sig': 1.0, 'T': 1.0, 'N': 2000, 'seed': 7,\n            'alpha_f': lambda x, lam: lam * x,\n            'b_f': lambda x, sig: sig * x,\n            'b_prime_f': lambda x, sig: sig\n        },\n        # Test Case B (additive noise)\n        {\n            'x0': 1.0, 'lam': 0.25, 'sig': 1.0, 'T': 1.0, 'N': 2000, 'seed': 7,\n            'alpha_f': lambda x, lam: lam * x,\n            'b_f': lambda x, sig: sig, # b(x) is constant\n            'b_prime_f': lambda x, sig: 0.0 # b'(x) is zero\n        },\n        # Test Case C (multiplicative noise, finer grid)\n        {\n            'x0': 1.0, 'lam': 0.25, 'sig': 1.0, 'T': 1.0, 'N': 20000, 'seed': 12345,\n            'alpha_f': lambda x, lam: lam * x,\n            'b_f': lambda x, sig: sig * x,\n            'b_prime_f': lambda x, sig: sig\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Unpack parameters\n        x0, lam, sig, T, N, seed = case['x0'], case['lam'], case['sig'], case['T'], case['N'], case['seed']\n        alpha_f, b_f, b_prime_f = case['alpha_f'], case['b_f'], case['b_prime_f']\n        \n        # Simulation setup\n        h = T / N\n        rng = np.random.default_rng(seed)\n        dw_increments = rng.normal(0.0, np.sqrt(h), N)\n        \n        # --- Trajectory S (Correct Stratonovich simulation via Itô conversion) ---\n        # The Stratonovich SDE: dX = alpha(X)dt + b(X) o dW\n        # has an equivalent Itô SDE: dX = a_S(X)dt + b(X)dW,\n        # where the correct Itô drift is a_S(X) = alpha(X) + 0.5 * b(X) * b'(X).\n        # The Milstein method is applied to this Itô SDE.\n        x_s = x0\n        for n in range(N):\n            alpha_val = alpha_f(x_s, lam)\n            b_val = b_f(x_s, sig)\n            b_prime_val = b_prime_f(x_s, sig)\n            \n            # Correct Itô drift for the equivalent SDE\n            a_s_val = alpha_val + 0.5 * b_val * b_prime_val\n            \n            dw = dw_increments[n]\n            \n            milstein_term = 0.5 * b_val * b_prime_val * (dw**2 - h)\n            x_s += a_s_val * h + b_val * dw + milstein_term\n\n        # --- Trajectory I_mis (Misinformed Itô simulation) ---\n        # The Stratonovich coefficients (alpha, b) are wrongly interpreted\n        # as defining an Itô SDE, dX = alpha(X)dt + b(X)dW.\n        # The Milstein method is applied directly with the incorrect drift `alpha`.\n        x_imis = x0\n        for n in range(N):\n            alpha_val = alpha_f(x_imis, lam)\n            b_val = b_f(x_imis, sig)\n            b_prime_val = b_prime_f(x_imis, sig)\n            \n            # Incorrect Itô drift is taken as alpha\n            a_imis_val = alpha_val\n            \n            dw = dw_increments[n]\n            \n            milstein_term = 0.5 * b_val * b_prime_val * (dw**2 - h)\n            x_imis += a_imis_val * h + b_val * dw + milstein_term\n            \n        # Calculate terminal difference\n        terminal_difference = x_s - x_imis\n        results.append(terminal_difference)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}]}