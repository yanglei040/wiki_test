{"hands_on_practices": [{"introduction": "This first practice grounds our exploration in a fundamental principle of probability: the relationship between a cumulative distribution function (CDF), $F(r)$, and a probability density function (PDF), $f(r)$. You will move from the abstract formula $f(r) = \\frac{d}{dr}F(r)$ to concrete computation by calculating the PDF for distributions commonly used to model asset returns. This exercise solidifies your understanding of the Gaussian, Student's t, and Gaussian mixture models, which are foundational building blocks for the more advanced risk applications we will explore next [@problem_id:2415147].", "id": "2415147", "problem": "Consider three cumulative distribution functions that model the distribution of decimal stock returns. For each specification, let $r$ denote the return and $F(r)$ its cumulative distribution function. Your task is to numerically calculate the derivative $\\frac{d}{dr}F(r)$ at specified points to obtain an estimate of the probability density function $f(r)$.\n\nDefinitions of $F(r)$ for the test suite:\n- Test case $1$ (Gaussian): $F(r) = \\Phi\\!\\left(\\frac{r - \\mu}{\\sigma}\\right)$ with parameters $\\mu = 0.001$ and $\\sigma = 0.02$, where $\\Phi(\\cdot)$ denotes the cumulative distribution function of the standard Normal distribution.\n- Test case $2$ (Student’s $t$): $F(r) = T_{\\nu}\\!\\left(\\frac{r - \\mu}{s}\\right)$ with parameters $\\nu = 5$, $\\mu = 0.0$, and $s = 0.02$, where $T_{\\nu}(\\cdot)$ denotes the cumulative distribution function of the standardized Student’s $t$ distribution with $\\nu$ degrees of freedom.\n- Test case $3$ (Two-component Gaussian mixture): $F(r) = w \\,\\Phi\\!\\left(\\frac{r - 0}{0.015}\\right) + (1-w)\\,\\Phi\\!\\left(\\frac{r - 0}{0.05}\\right)$ with $w = 0.9$.\n\nFor each test case, estimate $f(r) = \\frac{d}{dr}F(r)$ at the following points:\n- Test case $1$ evaluation points: $\\{-0.05, 0.00, 0.05\\}$.\n- Test case $2$ evaluation points: $\\{-0.10, 0.00, 0.10\\}$.\n- Test case $3$ evaluation points: $\\{-0.10, -0.02, 0.00, 0.02, 0.10\\}$.\n\nYour program must:\n- Compute numerical estimates of $f(r)$ at all specified points for each test case by differentiating the provided $F(r)$ with respect to $r$.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as:\n  $[$test case $1$ values in the stated order, then test case $2$ values in the stated order, then test case $3$ values in the stated order$]$.\n- Round each reported value to $6$ decimal places.\n\nNo inputs are provided to the program, and no units are required. The final output should contain only the single line in the format described above.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n\n- **General Task**: Numerically calculate the derivative $\\frac{d}{dr}F(r)$ to estimate the probability density function $f(r)$, where $F(r)$ is a cumulative distribution function (CDF) for decimal stock returns $r$.\n\n- **Test Case 1 (Gaussian)**:\n  - CDF: $F(r) = \\Phi\\!\\left(\\frac{r - \\mu}{\\sigma}\\right)$\n  - Parameters: $\\mu = 0.001$, $\\sigma = 0.02$.\n  - $\\Phi(\\cdot)$ is the standard Normal CDF.\n  - Evaluation points for $r$: $\\{-0.05, 0.00, 0.05\\}$.\n\n- **Test Case 2 (Student’s t)**:\n  - CDF: $F(r) = T_{\\nu}\\!\\left(\\frac{r - \\mu}{s}\\right)$\n  - Parameters: $\\nu = 5$, $\\mu = 0.0$, $s = 0.02$.\n  - $T_{\\nu}(\\cdot)$ is the standardized Student’s $t$ CDF with $\\nu$ degrees of freedom.\n  - Evaluation points for $r$: $\\{-0.10, 0.00, 0.10\\}$.\n\n- **Test Case 3 (Two-component Gaussian mixture)**:\n  - CDF: $F(r) = w \\,\\Phi\\!\\left(\\frac{r - 0}{0.015}\\right) + (1-w)\\,\\Phi\\!\\left(\\frac{r - 0}{0.05}\\right)$\n  - Parameters: $w = 0.9$. Implicitly, this is a mixture of two normal distributions with means $\\mu_1 = 0$, $\\mu_2 = 0$ and standard deviations $\\sigma_1 = 0.015$, $\\sigma_2 = 0.05$.\n  - Evaluation points for $r$: $\\{-0.10, -0.02, 0.00, 0.02, 0.10\\}$.\n\n- **Output Requirement**: A single comma-separated list of all computed derivative values, rounded to $6$ decimal places, ordered by test case and evaluation point, enclosed in square brackets.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded**: The problem is fundamentally sound. It is based on the core principle of probability theory that the probability density function (PDF), $f(x)$, is the derivative of the cumulative distribution function (CDF), $F(x)$, i.e., $f(x) = \\frac{d}{dx}F(x)$. The distributions used—Gaussian, Student's $t$, and Gaussian Mixture—are standard and widely applied models in computational finance for asset returns. The problem is scientifically and mathematically correct.\n2.  **Well-Posed**: The problem is well-posed. For each test case, the function $F(r)$ is explicitly defined with all necessary parameters. The points at which the derivative is to be evaluated are clearly specified. The functions are differentiable everywhere. A unique and meaningful solution exists.\n3.  **Objective**: The problem is stated using precise, unambiguous mathematical language and objective criteria. There are no subjective or opinion-based components.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. It is scientifically grounded, well-posed, objective, and complete. A solution will be provided.\n\n**Methodology**\n\nThe problem requires the numerical evaluation of the derivative of the cumulative distribution function, $F(r)$, to obtain the probability density function, $f(r)$. The fundamental relationship is:\n$$f(r) = \\frac{d}{dr}F(r)$$\nWhile one could employ a numerical approximation scheme, such as the central finite difference method, $f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}$, this is unnecessary and less accurate than the correct analytical approach. For the given standard distributions, the derivatives of the CDFs are known analytical functions—the PDFs themselves. The most rigorous and precise method to \"calculate the derivative\" is to evaluate the corresponding PDF. This is not a circumvention of the problem; it is the correct application of mathematical principles.\n\n**Case 1: Gaussian Distribution**\nThe CDF is given by $F(r) = \\Phi\\left(\\frac{r - \\mu}{\\sigma}\\right)$. Applying the chain rule, the derivative is:\n$$f(r) = \\frac{dF}{dr} = \\frac{d}{dr}\\Phi\\left(\\frac{r - \\mu}{\\sigma}\\right) = \\phi\\left(\\frac{r - \\mu}{\\sigma}\\right) \\cdot \\frac{d}{dr}\\left(\\frac{r - \\mu}{\\sigma}\\right) = \\frac{1}{\\sigma}\\phi\\left(\\frac{r - \\mu}{\\sigma}\\right)$$\nwhere $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2}$ is the PDF of the standard normal distribution. The resulting expression is the PDF of a general normal distribution with mean $\\mu$ and standard deviation $\\sigma$. The parameters are $\\mu = 0.001$ and $\\sigma = 0.02$.\n\n**Case 2: Student’s t-Distribution**\nThe CDF is given by $F(r) = T_{\\nu}\\left(\\frac{r - \\mu}{s}\\right)$. A similar application of the chain rule yields:\n$$f(r) = \\frac{dF}{dr} = \\frac{d}{dr}T_{\\nu}\\left(\\frac{r - \\mu}{s}\\right) = t_{\\nu}\\left(\\frac{r - \\mu}{s}\\right) \\cdot \\frac{1}{s}$$\nwhere $t_{\\nu}(z)$ is the PDF of the standardized Student's $t$-distribution with $\\nu$ degrees of freedom. This is the PDF for a location-scale transformed Student's $t$-distribution. The parameters are $\\nu = 5$, $\\mu = 0.0$, and $s = 0.02$.\n\n**Case 3: Two-component Gaussian Mixture**\nThe CDF is a weighted sum: $F(r) = w_1 F_1(r) + w_2 F_2(r)$, where $F_1(r) = \\Phi\\left(\\frac{r - \\mu_1}{\\sigma_1}\\right)$ and $F_2(r) = \\Phi\\left(\\frac{r - \\mu_2}{\\sigma_2}\\right)$. The derivative of a sum is the sum of the derivatives:\n$$f(r) = \\frac{dF}{dr} = w_1 \\frac{dF_1}{dr} + w_2 \\frac{dF_2}{dr}$$\nUsing the result from the Gaussian case, this becomes:\n$$f(r) = w_1 \\frac{1}{\\sigma_1}\\phi\\left(\\frac{r - \\mu_1}{\\sigma_1}\\right) + w_2 \\frac{1}{\\sigma_2}\\phi\\left(\\frac{r - \\mu_2}{\\sigma_2}\\right)$$\nThis is the PDF of the Gaussian mixture model. The parameters are $w_1 = 0.9$, $w_2 = 1-w_1 = 0.1$, $\\mu_1 = \\mu_2 = 0$, $\\sigma_1 = 0.015$, and $\\sigma_2 = 0.05$.\n\nThe implementation will utilize the `scipy.stats` library, which provides numerically stable and accurate functions for evaluating the PDFs of these standard distributions. This directly and correctly computes the required values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, t\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating the probability density function (PDF) values,\n    which are the derivatives of the given cumulative distribution functions (CDFs).\n    \"\"\"\n    \n    # This list will store all results in the required order.\n    all_results = []\n\n    # --- Test Case 1: Gaussian Distribution ---\n    mu_1 = 0.001\n    sigma_1 = 0.02\n    r_vals_1 = np.array([-0.05, 0.00, 0.05])\n    \n    # The derivative of the Gaussian CDF is the Gaussian PDF.\n    pdf_vals_1 = norm.pdf(r_vals_1, loc=mu_1, scale=sigma_1)\n    all_results.extend(pdf_vals_1)\n\n    # --- Test Case 2: Student’s t-Distribution ---\n    nu_2 = 5\n    mu_2 = 0.0\n    s_2 = 0.02\n    r_vals_2 = np.array([-0.10, 0.00, 0.10])\n    \n    # The derivative of the location-scale t-CDF is the corresponding t-PDF.\n    # The scipy.stats.t.pdf function correctly handles location and scale parameters.\n    pdf_vals_2 = t.pdf(r_vals_2, df=nu_2, loc=mu_2, scale=s_2)\n    all_results.extend(pdf_vals_2)\n\n    # --- Test Case 3: Two-component Gaussian Mixture ---\n    w_3 = 0.9\n    sigma_3_1 = 0.015\n    sigma_3_2 = 0.05\n    mu_3 = 0.0 # Both components are centered at 0\n    r_vals_3 = np.array([-0.10, -0.02, 0.00, 0.02, 0.10])\n    \n    # The PDF of a mixture is the weighted sum of the component PDFs.\n    pdf_vals_3_comp1 = norm.pdf(r_vals_3, loc=mu_3, scale=sigma_3_1)\n    pdf_vals_3_comp2 = norm.pdf(r_vals_3, loc=mu_3, scale=sigma_3_2)\n    pdf_vals_3 = w_3 * pdf_vals_3_comp1 + (1 - w_3) * pdf_vals_3_comp2\n    all_results.extend(pdf_vals_3)\n\n    # Format the final output string as specified.\n    # Each value is rounded to 6 decimal places.\n    output_str = f\"[{','.join([f'{val:.6f}' for val in all_results])}]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```"}, {"introduction": "We now apply our understanding of distributions to a critical risk management task: calculating Value at Risk (VaR). This exercise [@problem_id:2446954] highlights the concept of model risk by contrasting the standard variance-covariance method, which assumes \"thin-tailed\" normal returns, with a more realistic mixture model that explicitly incorporates rare but severe crash events. By comparing the VaR estimates, you will gain a practical appreciation for how model choice can dramatically alter our perception and quantification of extreme financial risk.", "id": "2446954", "problem": "A trader runs a one-day currency carry trade that borrows in a low-yield funding currency and goes long a high-yield target currency. Let $S_t$ denote the spot price of the target currency in units of the funding currency, and let $s_t=\\log S_t$. The trader’s one-day return (in funding-currency units) is approximated by $r=\\Delta s + \\delta/252$, where $\\Delta s = s_{t+1}-s_t$ and $\\delta$ is the annualized interest-rate differential (target minus funding). The portfolio notional is $V=100{,}000{,}000$ monetary units of the funding currency.\n\nAssume the following:\n- The variance-covariance (parametric) method models $\\Delta s$ as normally distributed with zero mean and standard deviation $\\sigma=0.008$ per day. Hence the model-implied one-day return has mean $\\mu=\\delta/252$ and volatility $\\sigma$.\n- The annualized interest-rate differential is $\\delta=0.05$.\n- In reality, the carry trade is exposed to rare crash risk: with probability $p=0.005$ on any given day, there is a sudden depreciation of the target currency causing a return $r=-0.10$ (a $10\\%$ loss); otherwise, with probability $1-p$, returns follow the normal model above with mean $\\mu$ and volatility $\\sigma$.\n\nUsing first principles and the definition of Value at Risk (VaR) as the appropriate quantile of the loss distribution, compute the $99\\%$ one-day VaR under:\n(i) the variance-covariance normal model, and\n(ii) the crash-mixture model described above.\nReport both VaRs in monetary units of the funding currency, and identify the statement that correctly gives both values and explains whether and why the variance-covariance method misses the crash risk.\n\nChoose one:\n- A. Under the normal model, the $99\\%$ VaR is approximately $1.84\\times 10^6$; under the crash-mixture, it increases to approximately $2.04\\times 10^6$. The variance-covariance method misses crash risk because it assumes thin-tailed, symmetric normal returns that understate tail losses in carry trades.\n- B. Under the normal model, the $99\\%$ VaR is approximately $1.86\\times 10^6$; under the crash-mixture, it jumps to approximately $1.00\\times 10^7$ because the crash always sets the $99\\%$ VaR regardless of its probability.\n- C. Under both the normal model and the crash-mixture, the $99\\%$ VaR is approximately $1.84\\times 10^6$; adding a rare crash does not affect VaR at this confidence because the mean is small.\n- D. Under the normal model, the $99\\%$ VaR is approximately $2.04\\times 10^6$; under the crash-mixture, it falls to approximately $1.84\\times 10^6$ because allocating some probability to a remote crash reduces the central tail probability mass.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- One-day currency carry trade return: $r = \\Delta s + \\delta/252$, where $\\Delta s = \\log(S_{t+1}/S_t)$.\n- Portfolio notional: $V = 100{,}000{,}000$ in funding currency.\n- Annualized interest-rate differential: $\\delta = 0.05$.\n- Business days in a year: $252$.\n- Model 1 (Variance-Covariance): $\\Delta s$ is normally distributed with mean $0$ and standard deviation $\\sigma = 0.008$. The return $r$ is thus normally distributed with mean $\\mu = \\delta/252$ and standard deviation $\\sigma = 0.008$.\n- Model 2 (Crash-Mixture): A mixture distribution for the return $r$.\n  - With probability $p = 0.005$, a crash occurs, leading to a return $r_c = -0.10$.\n  - With probability $1-p = 0.995$, the return $r_n$ follows the normal distribution from Model 1, $r_n \\sim N(\\mu, \\sigma^2)$.\n- Task: Compute the $99\\%$ one-day Value at Risk (VaR) under both models. VaR is defined as the appropriate quantile of the loss distribution.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, situated within the standard framework of financial risk management. The use of a normal model (variance-covariance method) and a mixture model to incorporate crash risk are standard textbook examples. The parameters provided ($\\delta$, $\\sigma$, $p$, $V$) are specific and within realistic ranges for currency markets. The problem is well-posed, as all necessary information is provided to compute the required quantities. The language is objective and unambiguous. The problem is self-contained and internally consistent.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. A solution will be derived.\n\n**Derivation of the Solution**\n\nThe Value at Risk (VaR) at a confidence level $c$ is the quantile of the loss distribution corresponding to that level. The $99\\%$ VaR is the value $v$ such that the probability of the loss $L$ exceeding $v$ is $1\\%$. The loss is defined as $L = -rV$. So, we seek $v$ such that $P(L > v) = 0.01$. This is equivalent to finding the $99$-th percentile of the loss distribution.\n\nFirst, we calculate the parameters for the return distribution.\nThe daily mean return is $\\mu = \\frac{\\delta}{252} = \\frac{0.05}{252} \\approx 0.00019841$.\nThe daily volatility of returns is given as $\\sigma = 0.008$.\nThe portfolio notional is $V = 100{,}000{,}000$.\n\n**(i) VaR under the Variance-Covariance (Normal) Model**\n\nUnder this model, the daily return $r$ is normally distributed: $r \\sim N(\\mu, \\sigma^2)$.\nThe loss, $L = -rV$, is also normally distributed.\nThe mean of the loss is $E[L] = E[-rV] = -V\\mu$.\nThe standard deviation of the loss is $\\sigma_L = \\text{StdDev}(-rV) = V\\sigma$.\nSo, $L \\sim N(-V\\mu, (V\\sigma)^2)$.\n\nWe calculate the numerical values:\n$V\\mu = 100{,}000{,}000 \\times \\frac{0.05}{252} \\approx 19{,}841.27$.\n$V\\sigma = 100{,}000{,}000 \\times 0.008 = 800{,}000$.\n\nThe $99\\%$ VaR is the $99$-th percentile of this loss distribution. Let $Z$ be a standard normal variable, $Z \\sim N(0,1)$. The $99$-th percentile of the standard normal distribution is denoted $z_{0.99}$, which is the value such that $P(Z \\le z_{0.99}) = 0.99$. From statistical tables, $z_{0.99} \\approx 2.3263$.\n\nThe VaR is calculated as:\n$$ \\text{VaR}_{0.99}^{(\\text{Normal})} = E[L] + z_{0.99} \\sigma_L = -V\\mu + z_{0.99} V\\sigma $$\n$$ \\text{VaR}_{0.99}^{(\\text{Normal})} \\approx -19{,}841.27 + 2.3263 \\times 800{,}000 $$\n$$ \\text{VaR}_{0.99}^{(\\text{Normal})} \\approx -19{,}841.27 + 1{,}861{,}040 = 1{,}841{,}198.73 $$\nThus, the $99\\%$ VaR under the normal model is approximately $1.84 \\times 10^6$.\n\n**(ii) VaR under the Crash-Mixture Model**\n\nThe loss distribution $L$ is a mixture.\n- With probability $p = 0.005$, a crash occurs. The loss is $L_c = -r_c V = -(-0.10) \\times 100{,}000{,}000 = 10{,}000{,}000$.\n- With probability $1-p = 0.995$, no crash occurs, and the loss $L_n$ follows the normal distribution from part (i), $L_n \\sim N(-V\\mu, (V\\sigma)^2)$.\n\nLet $F_L(v)$ be the cumulative distribution function (CDF) of the total loss $L$. Let $F_{L_n}(v)$ be the CDF of the normal loss component.\nThe CDF of the mixture is $F_L(v) = P(L \\le v) = (1-p) F_{L_n}(v) + p \\cdot H(v - L_c)$, where $H$ is the Heaviside step function. We seek the value $v$ such that $F_L(v)=0.99$.\n\nWe must first determine if the VaR value is less than or greater than the crash loss $L_c = 10^7$. We evaluate the CDF just below $L_c$:\n$$ F_L(L_c^-) = \\lim_{v \\to L_c^-} F_L(v) = (1-p) F_{L_n}(L_c) $$\nThe z-score corresponding to the loss $L_c=10^7$ in the normal distribution component is $z = \\frac{L_c - E[L_n]}{\\sigma_{L_n}} = \\frac{10^7 - (-19841.27)}{800000} \\approx 12.52$. The CDF value for such a large z-score is practically $1$, so $F_{L_n}(L_c) \\approx 1$.\nTherefore, $F_L(L_c^-) \\approx 1-p = 0.995$.\n\nWe are looking for the $99$-th percentile ($0.99$). Since $0.99 < F_L(L_c^-) \\approx 0.995$, the $99\\%$ VaR must be a value $v < L_c$. For any such $v$, the Heaviside function term is zero, so the CDF simplifies to:\n$$ F_L(v) = (1-p) F_{L_n}(v) = 0.995 \\cdot F_{L_n}(v) $$\nWe set this equal to $0.99$:\n$$ 0.995 \\cdot F_{L_n}(v) = 0.99 \\implies F_{L_n}(v) = \\frac{0.99}{0.995} \\approx 0.994975 $$\nWe must find the $99.4975$-th percentile of the normal loss distribution $L_n$. This requires the z-score $z_{0.994975} = \\Phi^{-1}(0.994975)$, where $\\Phi$ is the standard normal CDF. From statistical software or detailed tables, $z_{0.994975} \\approx 2.574$.\n\nThe VaR for the mixture model is then:\n$$ \\text{VaR}_{0.99}^{(\\text{Mixture})} = E[L_n] + z_{0.994975} \\sigma_{L_n} = -V\\mu + z_{0.994975} V\\sigma $$\n$$ \\text{VaR}_{0.99}^{(\\text{Mixture})} \\approx -19{,}841.27 + 2.574 \\times 800{,}000 $$\n$$ \\text{VaR}_{0.99}^{(\\text{Mixture})} \\approx -19{,}841.27 + 2{,}059{,}200 = 2{,}039{,}358.73 $$\nThus, the $99\\%$ VaR under the crash-mixture model is approximately $2.04 \\times 10^6$.\n\n**Evaluation of Options**\n\n- **A. Under the normal model, the $99\\%$ VaR is approximately $1.84\\times 10^6$; under the crash-mixture, it increases to approximately $2.04\\times 10^6$. The variance-covariance method misses crash risk because it assumes thin-tailed, symmetric normal returns that understate tail losses in carry trades.**\n  - The calculated VaR values, $\\$1.84 \\times 10^6$ for the normal model and $\\$2.04 \\times 10^6$ for the mixture model, match our derivations precisely.\n  - The explanation is also correct. The variance-covariance method, based on the normal distribution, does not account for skewness and fat tails (leptokurtosis), which are characteristic of crash risk. Carry trade returns are empirically known to exhibit such features, and the normal model's thin tails lead to a significant underestimation of risk, as demonstrated by the calculation.\n  - **Verdict: Correct.**\n\n- **B. Under the normal model, the $99\\%$ VaR is approximately $1.86\\times 10^6$; under the crash-mixture, it jumps to approximately $1.00\\times 10^7$ because the crash always sets the $99\\%$ VaR regardless of its probability.**\n  - The normal VaR of $\\$1.86 \\times 10^6$ is what one obtains by incorrectly ignoring the positive mean return ($\\mu > 0$).\n  - The mixture VaR is not $\\$1.00 \\times 10^7$. This would only be the case if the confidence level were higher than $99.5\\%$. The assertion that the crash \"always\" sets the VaR is false; it depends on the relationship between the crash probability $p$ and the VaR tail probability $\\alpha=1-c$.\n  - **Verdict: Incorrect.**\n\n- **C. Under both the normal model and the crash-mixture, the $99\\%$ VaR is approximately $1.84\\times 10^6$; adding a rare crash does not affect VaR at this confidence because the mean is small.**\n  - The statement that the mixture model VaR is also $\\$1.84 \\times 10^6$ contradicts our calculation. The VaR demonstrably increases.\n  - The reasoning provided (\"because the mean is small\") is illogical and irrelevant to the effect of the crash component on the VaR.\n  - **Verdict: Incorrect.**\n\n- **D. Under the normal model, the $99\\%$ VaR is approximately $2.04\\times 10^6$; under the crash-mixture, it falls to approximately $1.84\\times 10^6$ because allocating some probability to a remote crash reduces the central tail probability mass.**\n  - This option reverses the calculated VaR values.\n  - The reasoning is fundamentally flawed. Adding a large loss event to the tail of a distribution increases risk and thus cannot decrease the VaR for a given high confidence level.\n  - **Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$"}, {"introduction": "Our final practice delves into the tangible costs of using an oversimplified model for a real-world task: managing the risk of a large trade execution. Here, you will see what happens when a risk budget is set using a Gaussian assumption, while the market's true behavior follows a \"fat-tailed\" Student's t-distribution [@problem_id:2422084]. This exercise demonstrates that failing to account for fat tails is not just a theoretical error, as it can lead to a significant underestimation of risk and a much higher-than-expected chance of large losses.", "id": "2422084", "problem": "A trader must execute a large buy order over a finite horizon divided into $T$ equal-length intervals, indexed by $t \\in \\{1,\\dots,T\\}$. Let the initial mid-price be normalized to $P_0 = 1$. The market volume profile over the intervals is given by strictly positive integers $V_t > 0$. The trader uses a Volume-Weighted Average Price (VWAP) schedule given by\n$$\nx_t \\equiv Q \\cdot \\frac{V_t}{\\sum_{s=1}^{T} V_s},\n$$\nso that $\\sum_{t=1}^{T} x_t = Q$, where $Q > 0$ is the total number of shares to buy.\n\nThe intraday cumulative return up to the end of interval $t$ is modeled as a single-factor process\n$$\nR_t = \\kappa_t \\cdot Z, \\quad \\kappa_t \\equiv \\sqrt{\\frac{t}{T}},\n$$\nwhere $Z$ is a zero-mean random variable representing the horizon return factor. The realized execution price at the end of interval $t$ is\n$$\nP_t = P_0 \\cdot (1 + R_t) + \\eta \\cdot \\frac{x_t}{V_t},\n$$\nwhere $\\eta > 0$ is a temporary impact coefficient, and the execution occurs at price $P_t$ for quantity $x_t$. The implementation shortfall cost (relative to $P_0$) is\n$$\nC \\equiv \\sum_{t=1}^{T} x_t \\cdot (P_t - P_0) = Z \\cdot \\sum_{t=1}^{T} x_t \\kappa_t + \\eta \\cdot \\sum_{t=1}^{T} \\frac{x_t^2}{V_t}.\n$$\nAssume a risk manager calibrates a Value-at-Risk at tail probability level $1-p$ using a Gaussian model in which $Z \\sim \\mathcal{N}(0,\\sigma^2)$ with known $\\sigma > 0$. Under this Gaussian assumption, the VaR budget for the stochastic component of $C$ is\n$$\nB_{\\text{G}} \\equiv z_p \\cdot \\sigma \\cdot W, \\quad \\text{where } z_p \\text{ is the standard normal quantile at level } p \\text{ and } W \\equiv \\sum_{t=1}^{T} x_t \\kappa_t.\n$$\nIn reality, suppose $Z$ is distributed as a Student-$t$ random variable with degrees of freedom $\\nu > 2$ and zero mean, scaled so that $\\mathrm{Var}(Z) = \\sigma^2$. Let $s_\\nu$ denote the scale chosen to match $\\mathrm{Var}(Z)$, so that $Z \\overset{d}{=} s_\\nu \\cdot T_\\nu$, where $T_\\nu$ is a standard Student-$t$ random variable (zero mean, unit scale) and $s_\\nu^2 \\cdot \\frac{\\nu}{\\nu - 2} = \\sigma^2$.\n\nYour task is to, for each test case specified below:\n- Compute the VWAP schedule $\\{x_t\\}_{t=1}^{T}$ and the exposure coefficient $W = \\sum_{t=1}^{T} x_t \\kappa_t$.\n- Compute the Gaussian-calibrated budget $B_{\\text{G}} = z_p \\cdot \\sigma \\cdot W$.\n- Compute the actual exceedance probability under the true Student-$t$ model for the stochastic component, namely\n$$\n\\pi_{\\text{true}} \\equiv \\mathbb{P}\\left( Z \\cdot W > B_{\\text{G}} \\right) = 1 - F_{T_\\nu}\\!\\left( \\frac{B_{\\text{G}}}{W \\cdot s_\\nu} \\right),\n$$\nwhere $F_{T_\\nu}$ is the cumulative distribution function of the standard Student-$t$ distribution with $\\nu$ degrees of freedom, and $s_\\nu = \\sigma \\cdot \\sqrt{\\frac{\\nu - 2}{\\nu}}$.\n- Report the nominal exceedance probability under the Gaussian assumption, $\\pi_{\\text{nom}} \\equiv 1 - p$, as a decimal.\n- Compute the expected implementation shortfall $\\mathbb{E}[C]$, which equals the deterministic impact cost:\n$$\n\\mathbb{E}[C] = \\eta \\cdot \\sum_{t=1}^{T} \\frac{x_t^2}{V_t}.\n$$\n\nAll currency-valued quantities should be expressed in the same normalized currency units consistent with $P_0 = 1$. All probabilities must be expressed as decimals.\n\nTest suite:\n- Case $1$:\n  - $T = 4$\n  - $(V_1,V_2,V_3,V_4) = (300000,200000,200000,300000)$\n  - $Q = 100000$\n  - $\\sigma = 0.015$\n  - $p = 0.99$\n  - $\\nu = 5$\n  - $\\eta = 0.02$\n- Case $2$:\n  - $T = 6$\n  - $(V_1,V_2,V_3,V_4,V_5,V_6) = (100000,100000,100000,100000,100000,500000)$\n  - $Q = 50000$\n  - $\\sigma = 0.01$\n  - $p = 0.95$\n  - $\\nu = 3$\n  - $\\eta = 0.02$\n- Case $3$ (boundary case):\n  - $T = 1$\n  - $(V_1) = (200000)$\n  - $Q = 20000$\n  - $\\sigma = 0.02$\n  - $p = 0.975$\n  - $\\nu = 100$\n  - $\\eta = 0.02$\n\nFinal output format:\n- Your program must produce a single line of output containing the results for all cases concatenated in order, as a comma-separated list enclosed in square brackets.\n- For each case, output four floating-point numbers in the following order: $B_{\\text{G}}$, $\\pi_{\\text{true}}$, $\\pi_{\\text{nom}}$, $\\mathbb{E}[C]$.\n- Round every reported number to $6$ decimal places.\n- Therefore, the output should be of the form\n$$\n[\\;B_{\\text{G}}^{(1)},\\;\\pi_{\\text{true}}^{(1)},\\;\\pi_{\\text{nom}}^{(1)},\\;\\mathbb{E}[C]^{(1)},\\;B_{\\text{G}}^{(2)},\\;\\pi_{\\text{true}}^{(2)},\\;\\pi_{\\text{nom}}^{(2)},\\;\\mathbb{E}[C]^{(2)},\\;B_{\\text{G}}^{(3)},\\;\\pi_{\\text{true}}^{(3)},\\;\\pi_{\\text{nom}}^{(3)},\\;\\mathbb{E}[C]^{(3)}\\;].\n$$", "solution": "The problem requires the calculation of several quantities related to the cost and risk of executing a large trade according to a Volume-Weighted Average Price (VWAP) schedule. The core of the problem lies in comparing risk metrics derived from a Gaussian model assumption against the actual risk under a more realistic Student-$t$ distribution for market returns.\n\nThe validation steps confirm that the problem statement is scientifically grounded, well-posed, objective, and internally consistent. All required parameters and models are explicitly defined, and the test cases provided are valid. Therefore, we proceed to the solution.\n\nThe solution for each test case involves a sequence of calculations, which we outline below. Let the given parameters for a case be $T$, $\\{V_t\\}_{t=1}^T$, $Q$, $\\sigma$, $p$, $\\nu$, and $\\eta$.\n\n**1. VWAP Schedule and Total Volume**\nFirst, we compute the total market volume over the execution horizon:\n$$\nV_{\\text{total}} = \\sum_{s=1}^{T} V_s\n$$\nThe VWAP schedule, which specifies the number of shares $x_t$ to be traded in each interval $t$, is then calculated as:\n$$\nx_t = Q \\cdot \\frac{V_t}{V_{\\text{total}}} \\quad \\text{for } t=1, \\dots, T\n$$\nBy construction, this ensures that the total quantity traded equals the order size, i.e., $\\sum_{t=1}^{T} x_t = Q$.\n\n**2. Exposure Coefficient, $W$**\nThe stochastic component of the implementation shortfall cost is proportional to the a portfolio-weighted cumulative return factor. The weight for the random factor $Z$ is the exposure coefficient $W$. It is defined as the sum of the trade sizes $x_t$ weighted by the time-dependent factor $\\kappa_t$:\n$$\nW = \\sum_{t=1}^{T} x_t \\kappa_t\n$$\nwhere $\\kappa_t$ is defined as $\\kappa_t = \\sqrt{t/T}$. This coefficient aggregates the exposure to the underlying market return factor $Z$ over the entire execution horizon.\n\n**3. Gaussian-Calibrated VaR Budget, $B_{\\text{G}}$**\nThe risk manager assumes the return factor $Z$ follows a Gaussian distribution, $Z \\sim \\mathcal{N}(0,\\sigma^2)$. The stochastic cost is $C_{\\text{stoch}} = Z \\cdot W$. Under the Gaussian assumption, $C_{\\text{stoch}} \\sim \\mathcal{N}(0, (\\sigma W)^2)$. The Value-at-Risk (VaR) at a confidence level $p$ is the loss value that is not expected to be exceeded with probability $p$. The corresponding budget, $B_{\\text{G}}$, is calculated as:\n$$\nB_{\\text{G}} = z_p \\cdot \\sigma \\cdot W\n$$\nwhere $z_p$ is the quantile of the standard normal distribution such that $\\mathbb{P}(Z_{std} \\le z_p) = p$, where $Z_{std} \\sim \\mathcal{N}(0,1)$. This is calculated using the inverse cumulative distribution function (CDF) of the standard normal distribution, often denoted $\\Phi^{-1}(p)$.\n\n**4. Nominal and True Exceedance Probabilities, $\\pi_{\\text{nom}}$ and $\\pi_{\\text{true}}$**\nThe nominal exceedance probability, $\\pi_{\\text{nom}}$, is the probability of the stochastic cost exceeding the budget $B_{\\text{G}}$ under the assumed Gaussian model. By definition of VaR at level $p$, this is:\n$$\n\\pi_{\\text{nom}} = \\mathbb{P}(Z \\cdot W > B_{\\text{G}}) = 1 - p\n$$\nThe problem states that the true distribution of $Z$ is a scaled Student-$t$ distribution, $Z = s_\\nu \\cdot T_\\nu$, where $T_\\nu$ is a standard Student-$t$ random variable with $\\nu$ degrees of freedom. The scale factor $s_\\nu$ is chosen to match the variance, $\\mathrm{Var}(Z) = \\sigma^2$. Since $\\mathrm{Var}(T_\\nu) = \\nu/(\\nu-2)$ for $\\nu > 2$, the scale factor is derived as:\n$$\ns_\\nu^2 \\cdot \\frac{\\nu}{\\nu - 2} = \\sigma^2 \\implies s_\\nu = \\sigma \\sqrt{\\frac{\\nu - 2}{\\nu}}\n$$\nThe true exceedance probability, $\\pi_{\\text{true}}$, is the probability that the stochastic cost exceeds the Gaussian-calibrated budget $B_{\\text{G}}$, but under this true Student-$t$ distribution:\n$$\n\\pi_{\\text{true}} = \\mathbb{P}(Z \\cdot W > B_{\\text{G}}) = \\mathbb{P}\\left(s_\\nu \\cdot T_\\nu \\cdot W > B_{\\text{G}}\\right)\n$$\nAssuming $W > 0$ (which it is, as $x_t > 0$ for all $t$), we can isolate $T_\\nu$:\n$$\n\\pi_{\\text{true}} = \\mathbb{P}\\left(T_\\nu > \\frac{B_{\\text{G}}}{W \\cdot s_\\nu}\\right) = 1 - F_{T_\\nu}\\left(\\frac{B_{\\text{G}}}{W \\cdot s_\\nu}\\right)\n$$\nwhere $F_{T_\\nu}$ is the CDF of the standard Student-$t$ distribution with $\\nu$ degrees of freedom. The argument of the CDF can be simplified:\n$$\n\\frac{B_{\\text{G}}}{W \\cdot s_\\nu} = \\frac{z_p \\cdot \\sigma \\cdot W}{W \\cdot \\sigma \\sqrt{\\frac{\\nu-2}{\\nu}}} = z_p \\sqrt{\\frac{\\nu}{\\nu-2}}\n$$\nThis simplification is computationally advantageous as it is independent of $W$ and $\\sigma$ and avoids potential floating-point inaccuracies.\n\n**5. Expected Implementation Shortfall, $\\mathbb{E}[C]$**\nThe total implementation shortfall is $C = Z \\cdot W + \\eta \\cdot \\sum_{t=1}^{T} \\frac{x_t^2}{V_t}$. Its expectation is calculated by taking the expectation of each term. Since $W$, $\\eta$, $x_t$, and $V_t$ are deterministic and $\\mathbb{E}[Z]=0$:\n$$\n\\mathbb{E}[C] = \\mathbb{E}[Z] \\cdot W + \\eta \\cdot \\sum_{t=1}^{T} \\frac{x_t^2}{V_t} = 0 \\cdot W + \\eta \\cdot \\sum_{t=1}^{T} \\frac{x_t^2}{V_t}\n$$\nThus, the expected cost is purely due to the deterministic temporary market impact:\n$$\n\\mathbb{E}[C] = \\eta \\cdot \\sum_{t=1}^{T} \\frac{x_t^2}{V_t}\n$$\nThis quantity is computed by summing the impact costs over all trading intervals.\n\nThese steps are implemented for each test case to produce the required four output values: $B_{\\text{G}}$, $\\pi_{\\text{true}}$, $\\pi_{\\text{nom}}$, and $\\mathbb{E}[C]$.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm, t\n\ndef solve():\n    \"\"\"\n    Solves the trade execution risk problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"T\": 4, \"V\": [300000, 200000, 200000, 300000], \"Q\": 100000,\n            \"sigma\": 0.015, \"p\": 0.99, \"nu\": 5, \"eta\": 0.02\n        },\n        {\n            \"T\": 6, \"V\": [100000, 100000, 100000, 100000, 100000, 500000], \"Q\": 50000,\n            \"sigma\": 0.01, \"p\": 0.95, \"nu\": 3, \"eta\": 0.02\n        },\n        {\n            \"T\": 1, \"V\": [200000], \"Q\": 20000,\n            \"sigma\": 0.02, \"p\": 0.975, \"nu\": 100, \"eta\": 0.02\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        T = case[\"T\"]\n        V = np.array(case[\"V\"], dtype=float)\n        Q = case[\"Q\"]\n        sigma = case[\"sigma\"]\n        p = case[\"p\"]\n        nu = case[\"nu\"]\n        eta = case[\"eta\"]\n\n        # 1. Compute the VWAP schedule {x_t}\n        V_total = np.sum(V)\n        x = Q * V / V_total\n        \n        # 2. Compute the exposure coefficient W\n        t_indices = np.arange(1, T + 1)\n        kappa = np.sqrt(t_indices / T)\n        W = np.sum(x * kappa)\n        \n        # 3. Compute the Gaussian-calibrated budget B_G\n        z_p = norm.ppf(p)\n        B_G = z_p * sigma * W\n        \n        # 4. Compute nominal and true exceedance probabilities\n        pi_nom = 1.0 - p\n        \n        # The argument for the Student-t CDF can be simplified to avoid\n        # dependency on W and sigma, which improves numerical stability.\n        if nu > 2:\n            t_stat = z_p * np.sqrt(nu / (nu - 2))\n            pi_true = 1.0 - t.cdf(t_stat, df=nu)\n        else:\n            # Variance is undefined for nu <= 2, problem statement guarantees nu > 2.\n            pi_true = np.nan\n\n        # 5. Compute the expected implementation shortfall E[C]\n        E_C = eta * np.sum(np.square(x) / V)\n\n        results.extend([B_G, pi_true, pi_nom, E_C])\n        \n    # Format the final output string with 6 decimal places per value.\n    formatted_results = [f\"{val:.6f}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"}]}