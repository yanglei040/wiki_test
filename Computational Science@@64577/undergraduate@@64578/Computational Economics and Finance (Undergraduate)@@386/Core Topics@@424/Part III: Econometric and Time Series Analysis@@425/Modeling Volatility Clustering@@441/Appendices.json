{"hands_on_practices": [{"introduction": "Before we can apply sophisticated volatility models, it's crucial to understand their fundamental mathematical properties. This first exercise takes us back to the original Autoregressive Conditional Heteroskedasticity (ARCH) model to build this foundation from the ground up. By analytically deriving the unconditional variance, you will see precisely how the model's parameters govern its long-run average volatility and discover the critical role of the stationarity condition [@problem_id:2411107]. This practice sharpens your skills with conditional expectations and provides deep intuition into why these models successfully capture persistent, yet stable, volatility patterns.", "id": "2411107", "problem": "Consider the Autoregressive Conditional Heteroskedasticity (ARCH) model of order $1$ (ARCH$(1)$). Let $\\{\\varepsilon_t\\}$ denote a mean-zero return innovation process defined by $\\varepsilon_t = \\sigma_t z_t$, where $\\{z_t\\}$ are independent and identically distributed (i.i.d.) random variables with $\\mathbb{E}[z_t] = 0$, $\\mathbb{V}\\mathrm{ar}(z_t) = 1$, and $z_t$ is independent of all information dated $t-1$ and earlier. The conditional variance evolves according to $\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\varepsilon_{t-1}^2$, where $\\alpha_0 > 0$ and $0 \\le \\alpha_1 < 1$. Assume the process is covariance stationary.\n\nUsing only the definitions given above and basic properties of conditional expectation and variance, derive the unconditional variance $\\mathbb{V}\\mathrm{ar}(\\varepsilon_t)$ as a closed-form expression in terms of $\\alpha_0$ and $\\alpha_1$. Then, explain briefly in words what this result implies for the behavior of volatility as $\\alpha_1 \\to 1^{-}$.\n\nProvide your final result for the unconditional variance as a single closed-form expression. No numerical evaluation is required.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Model: Autoregressive Conditional Heteroskedasticity of order $1$, denoted as ARCH($1$).\n- Process: A mean-zero return innovation process $\\{\\varepsilon_t\\}$.\n- Definition of innovation: $\\varepsilon_t = \\sigma_t z_t$.\n- Error term properties: $\\{z_t\\}$ are independent and identically distributed (i.i.d.) random variables with $\\mathbb{E}[z_t] = 0$ and $\\mathbb{V}\\mathrm{ar}(z_t) = 1$.\n- Independence condition: $z_t$ is independent of all information dated $t-1$ and earlier, which we denote by the information set $\\mathcal{F}_{t-1}$.\n- Conditional variance evolution: $\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\varepsilon_{t-1}^2$.\n- Parameter constraints: $\\alpha_0 > 0$ and $0 \\le \\alpha_1 < 1$.\n- Stationarity assumption: The process $\\{\\varepsilon_t\\}$ is covariance stationary.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, being a standard derivation in financial econometrics based on the well-established ARCH model. It is well-posed, with sufficient conditions ($\\alpha_0 > 0$, $0 \\le \\alpha_1 < 1$, and covariance stationarity) to ensure a unique, stable solution. The language is objective and precise. The problem does not violate any criteria for invalidity. It is a formalizable, complete, and verifiable mathematical problem.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A solution will be provided.\n\nThe objective is to derive the unconditional variance of the process $\\{\\varepsilon_t\\}$, denoted as $\\mathbb{V}\\mathrm{ar}(\\varepsilon_t)$. The unconditional variance is defined as $\\mathbb{V}\\mathrm{ar}(\\varepsilon_t) = \\mathbb{E}[\\varepsilon_t^2] - (\\mathbb{E}[\\varepsilon_t])^2$.\n\nFirst, we determine the unconditional mean, $\\mathbb{E}[\\varepsilon_t]$. We use the Law of Total Expectation, conditioning on the information set $\\mathcal{F}_{t-1}$:\n$$\n\\mathbb{E}[\\varepsilon_t] = \\mathbb{E}[\\mathbb{E}[\\varepsilon_t | \\mathcal{F}_{t-1}]]\n$$\nThe inner conditional expectation is:\n$$\n\\mathbb{E}[\\varepsilon_t | \\mathcal{F}_{t-1}] = \\mathbb{E}[\\sigma_t z_t | \\mathcal{F}_{t-1}]\n$$\nThe conditional variance $\\sigma_t^2$ is defined as $\\alpha_0 + \\alpha_1 \\varepsilon_{t-1}^2$. Since $\\varepsilon_{t-1}$ is part of the information set $\\mathcal{F}_{t-1}$, $\\sigma_t$ is $\\mathcal{F}_{t-1}$-measurable. Therefore, it can be treated as a constant within the conditional expectation:\n$$\n\\mathbb{E}[\\sigma_t z_t | \\mathcal{F}_{t-1}] = \\sigma_t \\mathbb{E}[z_t | \\mathcal{F}_{t-1}]\n$$\nBy definition, $z_t$ is independent of $\\mathcal{F}_{t-1}$. Thus, $\\mathbb{E}[z_t | \\mathcal{F}_{t-1}] = \\mathbb{E}[z_t] = 0$.\nThis leads to:\n$$\n\\mathbb{E}[\\varepsilon_t | \\mathcal{F}_{t-1}] = \\sigma_t \\cdot 0 = 0\n$$\nSubstituting this back into the Law of Total Expectation:\n$$\n\\mathbb{E}[\\varepsilon_t] = \\mathbb{E}[0] = 0\n$$\nThe process $\\{\\varepsilon_t\\}$ is a zero-mean process. Consequently, its variance simplifies to the second moment:\n$$\n\\mathbb{V}\\mathrm{ar}(\\varepsilon_t) = \\mathbb{E}[\\varepsilon_t^2]\n$$\nWe denote the constant unconditional variance by $\\sigma^2$, a consequence of the covariance stationarity assumption. Thus, $\\sigma^2 = \\mathbb{E}[\\varepsilon_t^2]$.\n\nTo find $\\sigma^2$, we again apply the Law of Total Expectation:\n$$\n\\sigma^2 = \\mathbb{E}[\\varepsilon_t^2] = \\mathbb{E}[\\mathbb{E}[\\varepsilon_t^2 | \\mathcal{F}_{t-1}]]\n$$\nThe inner conditional expectation is the conditional second moment of $\\varepsilon_t$. Given that $\\mathbb{E}[\\varepsilon_t | \\mathcal{F}_{t-1}]=0$, this is also the conditional variance of $\\varepsilon_t$:\n$$\n\\mathbb{E}[\\varepsilon_t^2 | \\mathcal{F}_{t-1}] = \\mathbb{V}\\mathrm{ar}(\\varepsilon_t | \\mathcal{F}_{t-1}) = \\sigma_t^2\n$$\nLet us formally show this:\n$$\n\\mathbb{E}[\\varepsilon_t^2 | \\mathcal{F}_{t-1}] = \\mathbb{E}[(\\sigma_t z_t)^2 | \\mathcal{F}_{t-1}] = \\mathbb{E}[\\sigma_t^2 z_t^2 | \\mathcal{F}_{t-1}]\n$$\nAs $\\sigma_t^2$ is $\\mathcal{F}_{t-1}$-measurable, it comes out of the expectation:\n$$\n\\mathbb{E}[\\sigma_t^2 z_t^2 | \\mathcal{F}_{t-1}] = \\sigma_t^2 \\mathbb{E}[z_t^2 | \\mathcal{F}_{t-1}]\n$$\nDue to the independence of $z_t$ from $\\mathcal{F}_{t-1}$, $\\mathbb{E}[z_t^2 | \\mathcal{F}_{t-1}] = \\mathbb{E}[z_t^2]$. We are given $\\mathbb{V}\\mathrm{ar}(z_t) = 1$ and $\\mathbb{E}[z_t] = 0$. Since $\\mathbb{V}\\mathrm{ar}(z_t) = \\mathbb{E}[z_t^2] - (\\mathbb{E}[z_t])^2$, we have $\\mathbb{E}[z_t^2] = 1 - 0^2 = 1$.\nTherefore:\n$$\n\\mathbb{E}[\\varepsilon_t^2 | \\mathcal{F}_{t-1}] = \\sigma_t^2 \\cdot 1 = \\sigma_t^2\n$$\nNow we substitute this result back into the expression for the unconditional variance:\n$$\n\\sigma^2 = \\mathbb{E}[\\sigma_t^2]\n$$\nUsing the definition of the conditional variance, $\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\varepsilon_{t-1}^2$:\n$$\n\\sigma^2 = \\mathbb{E}[\\alpha_0 + \\alpha_1 \\varepsilon_{t-1}^2]\n$$\nBy the linearity of expectation:\n$$\n\\sigma^2 = \\mathbb{E}[\\alpha_0] + \\mathbb{E}[\\alpha_1 \\varepsilon_{t-1}^2] = \\alpha_0 + \\alpha_1 \\mathbb{E}[\\varepsilon_{t-1}^2]\n$$\nThe assumption of covariance stationarity implies that the unconditional variance is constant over time, so $\\mathbb{V}\\mathrm{ar}(\\varepsilon_{t-1}) = \\mathbb{V}\\mathrm{ar}(\\varepsilon_t) = \\sigma^2$. Since the process is zero-mean, this means $\\mathbb{E}[\\varepsilon_{t-1}^2] = \\sigma^2$. Substituting this into the equation:\n$$\n\\sigma^2 = \\alpha_0 + \\alpha_1 \\sigma^2\n$$\nWe now solve this algebraic equation for $\\sigma^2$:\n$$\n\\sigma^2 - \\alpha_1 \\sigma^2 = \\alpha_0\n$$\n$$\n\\sigma^2 (1 - \\alpha_1) = \\alpha_0\n$$\n$$\n\\sigma^2 = \\frac{\\alpha_0}{1 - \\alpha_1}\n$$\nThis is the closed-form expression for the unconditional variance, $\\mathbb{V}\\mathrm{ar}(\\varepsilon_t)$. The given condition $0 \\le \\alpha_1 < 1$ ensures that the denominator $(1 - \\alpha_1)$ is positive and non-zero, guaranteeing a finite and positive unconditional variance, as required for a stationary process.\n\nRegarding the behavior as $\\alpha_1 \\to 1^{-}$, we analyze the derived expression for $\\sigma^2$. The parameter $\\alpha_1$ represents the persistence of volatility; it measures the extent to which a past shock, $\\varepsilon_{t-1}^2$, influences the current conditional variance, $\\sigma_t^2$. As $\\alpha_1$ approaches $1$ from below, the denominator $(1 - \\alpha_1)$ approaches $0$ from the positive side. Consequently, the unconditional variance $\\sigma^2$ tends to infinity:\n$$\n\\lim_{\\alpha_1 \\to 1^{-}} \\frac{\\alpha_0}{1 - \\alpha_1} = +\\infty\n$$\nThis implies that as the persistence of volatility shocks becomes stronger (i.e., as $\\alpha_1$ gets closer to $1$), the overall, long-run volatility of the process increases without bound. At the limit where $\\alpha_1=1$ (the unit root case, known as Integrated GARCH or IGARCH), the process is no longer covariance stationary, and its unconditional variance is undefined or infinite. In such a scenario, shocks to volatility have a permanent effect on the system's future volatility path.", "answer": "$$\n\\boxed{\\frac{\\alpha_0}{1 - \\alpha_1}}\n$$"}, {"introduction": "With a grasp of the model's long-run properties, we now turn to a key practical application: forecasting. How does our forecast for volatility a month from now differ from our forecast for tomorrow? This exercise explores the term structure of volatility forecasts by comparing the workhorse GARCH($1,1$) model with the widely-used Exponentially Weighted Moving Average (EWMA) model [@problem_id:2411128]. You will discover the critical concept of mean reversion and see how a model's 'memory', determined by parameters like $\\alpha$ and $\\beta$, dictates whether shocks to volatility are temporary or permanentâ€”a distinction with profound implications for risk management.", "id": "2411128", "problem": "Consider a discrete-time asset return process with conditional heteroskedasticity. Let $r_t = \\mu + \\varepsilon_t$, where $\\varepsilon_t = \\sigma_t z_t$, and $\\{z_t\\}$ is an independent and identically distributed sequence with $\\mathbb{E}[z_t] = 0$ and $\\mathbb{V}\\mathrm{ar}(z_t) = 1$. At time $t$, both $\\sigma_t^2$ and $\\varepsilon_t^2$ are observed. Two competing volatility models are used to capture volatility clustering and to produce multi-step ahead variance forecasts:\n- Generalized AutoRegressive Conditional Heteroskedasticity (GARCH)($1,1$): $\\sigma_t^2 = \\omega + \\alpha\\,\\varepsilon_{t-1}^2 + \\beta\\,\\sigma_{t-1}^2$, with $\\omega>0$, $\\alpha\\ge 0$, $\\beta\\ge 0$, and $\\alpha+\\beta<1$.\n- Exponentially Weighted Moving Average (EWMA): $\\sigma_t^2 = \\lambda\\,\\sigma_{t-1}^2 + (1-\\lambda)\\,\\varepsilon_{t-1}^2$, with $0<\\lambda<1$.\n\nLet $\\mathcal{F}_t$ denote the information set at time $t$, and write $\\mathbb{E}_t[\\cdot]$ for $\\mathbb{E}[\\cdot \\mid \\mathcal{F}_t]$. Define the multi-step ahead term structure of conditional variance forecasts as the sequence $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]: h=1,2,3,\\dots\\}$ implied by each model.\n\nWhich statement best characterizes and compares the multi-step ahead term structures under these two models?\n\nA. Under GARCH($1,1$), $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]\\}_{h\\ge 1}$ is mean-reverting and converges geometrically to the unconditional variance $\\bar{\\sigma}^2 = \\omega/(1-\\alpha-\\beta)$; under EWMA, $\\mathbb{E}_t[\\sigma_{t+h}^2] = \\mathbb{E}_t[\\sigma_{t+1}^2]$ for all $h\\ge 2$, so the term structure is flat beyond one step and does not revert to a finite long-run level.\n\nB. Under both GARCH($1,1$) and EWMA, $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]\\}$ converges to the same unconditional variance $\\bar{\\sigma}^2$, with convergence rates determined by $\\alpha+\\beta$ in GARCH and by $\\lambda$ in EWMA.\n\nC. Under EWMA with $0<\\lambda<1$, $\\mathbb{E}_t[\\sigma_{t+h}^2]$ decays to $0$ as $h\\to\\infty$; under GARCH($1,1$) with $\\omega>0$, $\\mathbb{E}_t[\\sigma_{t+h}^2]$ diverges to $+\\infty$ as $h\\to\\infty$.\n\nD. If $\\alpha+\\beta<1$, then under GARCH($1,1$) the sequence $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]\\}$ is constant for all $h\\ge 2$; under EWMA, the sequence strictly increases with $h$ whenever $\\varepsilon_t^2>\\sigma_t^2$ and strictly decreases with $h$ whenever $\\varepsilon_t^2<\\sigma_t^2$.", "solution": "The problem statement is critically evaluated for validity before a solution is attempted.\n\n### Step 1: Extract Givens\nThe givens from the problem statement are:\n- The asset return process is $r_t = \\mu + \\varepsilon_t$.\n- The error term is $\\varepsilon_t = \\sigma_t z_t$.\n- The noise process $\\{z_t\\}$ is independent and identically distributed (i.i.d.) with $\\mathbb{E}[z_t] = 0$ and $\\mathbb{V}\\mathrm{ar}(z_t) = 1$. From this, it follows that $\\mathbb{E}[z_t^2] = \\mathbb{V}\\mathrm{ar}(z_t) + (\\mathbb{E}[z_t])^2 = 1 + 0^2 = 1$.\n- The information set at time $t$ is $\\mathcal{F}_t$. The conditional expectation is $\\mathbb{E}_t[\\cdot] \\equiv \\mathbb{E}[\\cdot \\mid \\mathcal{F}_t]$.\n- At time $t$, $\\sigma_t^2$ and $\\varepsilon_t^2$ are observed, thus they are elements of $\\mathcal{F}_t$.\n- Model 1 is Generalized AutoRegressive Conditional Heteroskedasticity (GARCH)($1,1$):\n  - Equation: $\\sigma_t^2 = \\omega + \\alpha\\,\\varepsilon_{t-1}^2 + \\beta\\,\\sigma_{t-1}^2$.\n  - Parameter constraints: $\\omega>0$, $\\alpha\\ge 0$, $\\beta\\ge 0$, and $\\alpha+\\beta<1$.\n- Model 2 is Exponentially Weighted Moving Average (EWMA):\n  - Equation: $\\sigma_t^2 = \\lambda\\,\\sigma_{t-1}^2 + (1-\\lambda)\\,\\varepsilon_{t-1}^2$.\n  - Parameter constraints: $0<\\lambda<1$.\n- The objective is to analyze the multi-step ahead term structure of conditional variance forecasts, defined as the sequence $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]: h=1,2,3,\\dots\\}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is subjected to validation.\n- **Scientifically Grounded**: The problem describes two fundamental and widely used models in financial econometrics, GARCH and EWMA, for capturing volatility dynamics. The mathematical definitions, parameter constraints, and the underlying stochastic process are standard and correct representations from the literature. The problem is firmly grounded in the principles of time series analysis and computational finance.\n- **Well-Posed**: The question asks for a characterization and comparison of the multi-step ahead conditional variance forecasts. This is a standard and well-defined analytical task for any given time series model. The provided information is sufficient to derive a unique answer.\n- **Objective**: The problem is stated using precise and unambiguous mathematical language. There is no subjective content.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, objective, and self-contained. It is a valid problem requiring a formal derivation. We proceed to the solution.\n\n### Derivation for GARCH($1,1$)\nThe GARCH($1,1$) model for the conditional variance at time $t+1$ is $\\sigma_{t+1}^2 = \\omega + \\alpha\\,\\varepsilon_{t}^2 + \\beta\\,\\sigma_{t}^2$.\nThe $1$-step ahead forecast of the variance, conditional on information at time $t$, is:\n$$ \\mathbb{E}_t[\\sigma_{t+1}^2] = \\mathbb{E}_t[\\omega + \\alpha\\,\\varepsilon_{t}^2 + \\beta\\,\\sigma_{t}^2] $$\nSince $\\varepsilon_t^2$ and $\\sigma_t^2$ are known at time $t$ (i.e., are in $\\mathcal{F}_t$), the expectation is simply the value itself:\n$$ \\mathbb{E}_t[\\sigma_{t+1}^2] = \\sigma_{t+1}^2 = \\omega + \\alpha\\,\\varepsilon_{t}^2 + \\beta\\,\\sigma_{t}^2 $$\nFor the $2$-step ahead forecast ($h=2$):\n$$ \\mathbb{E}_t[\\sigma_{t+2}^2] = \\mathbb{E}_t[\\omega + \\alpha\\,\\varepsilon_{t+1}^2 + \\beta\\,\\sigma_{t+1}^2] = \\omega + \\alpha\\,\\mathbb{E}_t[\\varepsilon_{t+1}^2] + \\beta\\,\\mathbb{E}_t[\\sigma_{t+1}^2] $$\nWe have $\\mathbb{E}_t[\\sigma_{t+1}^2] = \\sigma_{t+1}^2$. We need to evaluate $\\mathbb{E}_t[\\varepsilon_{t+1}^2]$.\nUsing the law of iterated expectations and the definition $\\varepsilon_{t+1} = \\sigma_{t+1} z_{t+1}$:\n$$ \\mathbb{E}_t[\\varepsilon_{t+1}^2] = \\mathbb{E}_t[\\sigma_{t+1}^2 z_{t+1}^2] $$\nSince $\\sigma_{t+1}^2$ is $\\mathcal{F}_t$-measurable, we can factor it out of the conditional expectation:\n$$ \\mathbb{E}_t[\\varepsilon_{t+1}^2] = \\sigma_{t+1}^2 \\mathbb{E}_t[z_{t+1}^2] $$\nBecause $\\{z_t\\}$ is i.i.d. and independent of past information, $\\mathbb{E}_t[z_{t+1}^2] = \\mathbb{E}[z_{t+1}^2] = 1$.\nThus, $\\mathbb{E}_t[\\varepsilon_{t+1}^2] = \\sigma_{t+1}^2$.\nSubstituting this into the expression for $\\mathbb{E}_t[\\sigma_{t+2}^2]$:\n$$ \\mathbb{E}_t[\\sigma_{t+2}^2] = \\omega + \\alpha\\,\\sigma_{t+1}^2 + \\beta\\,\\sigma_{t+1}^2 = \\omega + (\\alpha+\\beta)\\sigma_{t+1}^2 $$\nFor a general horizon $h \\ge 2$, we find a recurrence relation for the forecast. Let $V_{t,h} = \\mathbb{E}_t[\\sigma_{t+h}^2]$.\n$$ V_{t,h} = \\mathbb{E}_t[\\sigma_{t+h}^2] = \\mathbb{E}_t[\\omega + \\alpha\\,\\varepsilon_{t+h-1}^2 + \\beta\\,\\sigma_{t+h-1}^2] = \\omega + \\alpha\\,\\mathbb{E}_t[\\varepsilon_{t+h-1}^2] + \\beta\\,\\mathbb{E}_t[\\sigma_{t+h-1}^2] $$\nUsing the same logic as before, $\\mathbb{E}_t[\\varepsilon_{t+h-1}^2] = \\mathbb{E}_t[\\mathbb{E}_{t+h-2}[\\sigma_{t+h-1}^2 z_{t+h-1}^2]] = \\mathbb{E}_t[\\sigma_{t+h-1}^2 \\mathbb{E}[z_{t+h-1}^2]] = \\mathbb{E}_t[\\sigma_{t+h-1}^2] = V_{t,h-1}$.\nSo, the recurrence relation is:\n$$ V_{t,h} = \\omega + (\\alpha+\\beta)V_{t,h-1} \\quad \\text{for } h \\ge 2 $$\nThe GARCH($1,1$) process is stationary under the condition $\\alpha+\\beta<1$. The unconditional variance, $\\bar{\\sigma}^2 = \\mathbb{E}[\\sigma_t^2]$, is found by taking the unconditional expectation of the GARCH equation: $\\bar{\\sigma}^2 = \\omega + \\alpha \\mathbb{E}[\\varepsilon_{t-1}^2] + \\beta \\mathbb{E}[\\sigma_{t-1}^2] = \\omega + (\\alpha+\\beta)\\bar{\\sigma}^2$. This yields:\n$$ \\bar{\\sigma}^2 = \\frac{\\omega}{1-\\alpha-\\beta} $$\nThis is the long-run mean to which the conditional variance forecasts revert. To see this, we analyze the recurrence relation $V_{t,h} = \\omega + (\\alpha+\\beta)V_{t,h-1}$. Let us write it in terms of deviation from the mean $\\bar{\\sigma}^2$:\n$$ V_{t,h} - \\bar{\\sigma}^2 = \\omega + (\\alpha+\\beta)V_{t,h-1} - \\frac{\\omega}{1-\\alpha-\\beta} = (\\alpha+\\beta)V_{t,h-1} - \\frac{\\omega(\\alpha+\\beta)}{1-\\alpha-\\beta} $$\n$$ V_{t,h} - \\bar{\\sigma}^2 = (\\alpha+\\beta)\\left(V_{t,h-1} - \\frac{\\omega}{1-\\alpha-\\beta}\\right) = (\\alpha+\\beta)(V_{t,h-1} - \\bar{\\sigma}^2) $$\nBy repeated substitution, we get:\n$$ \\mathbb{E}_t[\\sigma_{t+h}^2] - \\bar{\\sigma}^2 = (\\alpha+\\beta)^{h-1}(\\mathbb{E}_t[\\sigma_{t+1}^2] - \\bar{\\sigma}^2) = (\\alpha+\\beta)^{h-1}(\\sigma_{t+1}^2 - \\bar{\\sigma}^2) $$\nSince $0 \\le \\alpha+\\beta < 1$, the term $(\\alpha+\\beta)^{h-1}$ goes to $0$ as $h \\to \\infty$. Therefore, $\\lim_{h \\to \\infty} \\mathbb{E}_t[\\sigma_{t+h}^2] = \\bar{\\sigma}^2$. The convergence is geometric with rate $\\alpha+\\beta$. This is the property of mean reversion.\n\n### Derivation for EWMA\nThe EWMA model is $\\sigma_t^2 = \\lambda\\,\\sigma_{t-1}^2 + (1-\\lambda)\\,\\varepsilon_{t-1}^2$. This model is a special case of GARCH($1,1$) with parameters $\\omega=0$, $\\alpha=1-\\lambda$, and $\\beta=\\lambda$. Importantly, the sum of the autoregressive parameters is $\\alpha+\\beta = (1-\\lambda)+\\lambda = 1$. This corresponds to an Integrated GARCH (IGARCH) model, which is non-stationary and lacks a finite unconditional variance.\n\nLet's derive the term structure of forecasts. The $1$-step ahead forecast is:\n$$ \\mathbb{E}_t[\\sigma_{t+1}^2] = \\mathbb{E}_t[\\lambda\\,\\sigma_t^2 + (1-\\lambda)\\,\\varepsilon_t^2] = \\lambda\\,\\sigma_t^2 + (1-\\lambda)\\,\\varepsilon_t^2 = \\sigma_{t+1}^2 $$\nFor the $2$-step ahead forecast ($h=2$):\n$$ \\mathbb{E}_t[\\sigma_{t+2}^2] = \\mathbb{E}_t[\\lambda\\,\\sigma_{t+1}^2 + (1-\\lambda)\\,\\varepsilon_{t+1}^2] = \\lambda\\,\\mathbb{E}_t[\\sigma_{t+1}^2] + (1-\\lambda)\\,\\mathbb{E}_t[\\varepsilon_{t+1}^2] $$\nAs shown previously, $\\mathbb{E}_t[\\varepsilon_{t+1}^2] = \\sigma_{t+1}^2 = \\mathbb{E}_t[\\sigma_{t+1}^2]$.\n$$ \\mathbb{E}_t[\\sigma_{t+2}^2] = \\lambda\\,\\sigma_{t+1}^2 + (1-\\lambda)\\,\\sigma_{t+1}^2 = (\\lambda + 1 - \\lambda)\\sigma_{t+1}^2 = \\sigma_{t+1}^2 $$\nFor a general horizon $h \\ge 2$, let's assume $\\mathbb{E}_t[\\sigma_{t+h-1}^2] = \\sigma_{t+1}^2$. Then by induction:\n$$ \\mathbb{E}_t[\\sigma_{t+h}^2] = \\mathbb{E}_t[\\lambda\\,\\sigma_{t+h-1}^2 + (1-\\lambda)\\,\\varepsilon_{t+h-1}^2] = \\lambda\\,\\mathbb{E}_t[\\sigma_{t+h-1}^2] + (1-\\lambda)\\,\\mathbb{E}_t[\\varepsilon_{t+h-1}^2] $$\nAgain using $\\mathbb{E}_t[\\varepsilon_{t+h-1}^2] = \\mathbb{E}_t[\\sigma_{t+h-1}^2]$, we get:\n$$ \\mathbb{E}_t[\\sigma_{t+h}^2] = (\\lambda + 1 - \\lambda)\\mathbb{E}_t[\\sigma_{t+h-1}^2] = \\mathbb{E}_t[\\sigma_{t+h-1}^2] $$\nThis proves that the forecast is constant for all horizons:\n$$ \\mathbb{E}_t[\\sigma_{t+h}^2] = \\mathbb{E}_t[\\sigma_{t+h-1}^2] = \\dots = \\mathbb{E}_t[\\sigma_{t+2}^2] = \\sigma_{t+1}^2 $$\nSo, for the EWMA model, $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]\\}_{h \\ge 1}$ is a flat sequence, equal to the $1$-step ahead forecast $\\sigma_{t+1}^2$. The forecast does not revert to any long-run mean, as no such finite mean exists.\n\n### Option-by-Option Analysis\n\nA. Under GARCH($1,1$), $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]\\}_{h\\ge 1}$ is mean-reverting and converges geometrically to the unconditional variance $\\bar{\\sigma}^2 = \\omega/(1-\\alpha-\\beta)$; under EWMA, $\\mathbb{E}_t[\\sigma_{t+h}^2] = \\mathbb{E}_t[\\sigma_{t+1}^2]$ for all $h\\ge 2$, so the term structure is flat beyond one step and does not revert to a finite long-run level.\n- The description for GARCH($1,1$) matches our derivation exactly. The term structure is mean-reverting and converges geometrically to $\\bar{\\sigma}^2$.\n- The description for EWMA also matches our derivation. The term structure is flat, meaning all forecasts for $h \\ge 1$ are identical to the first step forecast. The statement that it does not revert to a finite long-run level is also correct, as it is a unit-root process.\n- Verdict: **Correct**.\n\nB. Under both GARCH($1,1$) and EWMA, $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]\\}$ converges to the same unconditional variance $\\bar{\\sigma}^2$, with convergence rates determined by $\\alpha+\\beta$ in GARCH and by $\\lambda$ in EWMA.\n- This is incorrect. As derived, the EWMA model does not have a finite unconditional variance and its forecast term structure does not converge; it is flat. Only the GARCH($1,1$) model with $\\alpha+\\beta<1$ has a mean-reverting forecast term structure.\n- Verdict: **Incorrect**.\n\nC. Under EWMA with $0<\\lambda<1$, $\\mathbb{E}_t[\\sigma_{t+h}^2]$ decays to $0$ as $h\\to\\infty$; under GARCH($1,1$) with $\\omega>0$, $\\mathbb{E}_t[\\sigma_{t+h}^2]$ diverges to $+\\infty$ as $h\\to\\infty$.\n- The EWMA forecast is constant and equal to $\\sigma_{t+1}^2$, which is strictly positive if there is any volatility. It does not decay to $0$.\n- The GARCH($1,1$) forecast converges to the finite and positive unconditional variance $\\bar{\\sigma}^2 = \\omega/(1-\\alpha-\\beta)$, because $\\omega > 0$. It does not diverge.\n- Verdict: **Incorrect**.\n\nD. If $\\alpha+\\beta<1$, then under GARCH($1,1$) the sequence $\\{\\mathbb{E}_t[\\sigma_{t+h}^2]\\}$ is constant for all $h\\ge 2$; under EWMA, the sequence strictly increases with $h$ whenever $\\varepsilon_t^2>\\sigma_t^2$ and strictly decreases with $h$ whenever $\\varepsilon_t^2<\\sigma_t^2$.\n- The statement for GARCH($1,1$) is false. The sequence is not constant unless $\\sigma_{t+1}^2$ happens to be exactly equal to the long-run mean $\\bar{\\sigma}^2$. It is the EWMA forecast that is constant.\n- The statement for EWMA is false. The forecast sequence is constant for all $h \\ge 1$; it does not depend on the relationship between $\\varepsilon_t^2$ and $\\sigma_t^2$ for its evolution with the horizon $h$.\n- Verdict: **Incorrect**.", "answer": "$$\\boxed{A}$$"}, {"introduction": "Having explored the theoretical properties and forecasting behavior of GARCH models, it's time to put them to work in a complete empirical exercise. This hands-on coding challenge tasks you with investigating a classic financial puzzle: the 'day-of-the-week effect' in stock market volatility [@problem_id:2411105]. You will implement a GARCH model that includes external factors, estimate its parameters using Quasi-Maximum Likelihood, and perform a formal Likelihood Ratio test to arrive at a statistical conclusion. This practice provides a blueprint for how to use volatility models to test economic hypotheses and extract meaningful insights from financial data.", "id": "2411105", "problem": "You are asked to design and implement a complete, runnable program that tests for a \"day-of-the-week effect\" in volatility by incorporating dummy variables into a conditional variance model that captures volatility clustering in financial returns. The base principles to use are: conditional expectation and variance definitions, the observation that many financial return series display time-varying conditional variance (\"volatility clustering\"), and that a Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model is a well-tested way to represent such conditional variance dynamics. Likelihood-based inference (Quasi Maximum Likelihood) under the Gaussian assumption is well-tested and appropriate for estimation, and the Likelihood Ratio test is a standard way to test nested hypotheses.\n\nYour program must do the following for a set of synthetic test cases:\n\n1. Treat the return series $\\{r_t\\}_{t=1}^T$ as mean zero, conditionally heteroskedastic, with conditional variance $\\sigma_t^2$ following a GARCH($1,1$)-type recursion. Incorporate a \"day-of-the-week\" effect as additive dummy variables in the conditional variance equation. Let $D_t$ be a vector of day-of-week indicators for Monday, Tuesday, Thursday, and Friday (Wednesday is the base day and has no indicator). The indicator vector $D_t \\in \\mathbb{R}^4$ is defined as follows using a $5$-day cycle: $D_t = [\\mathbb{1}\\{\\text{Mon}\\}, \\mathbb{1}\\{\\text{Tue}\\}, \\mathbb{1}\\{\\text{Thu}\\}, \\mathbb{1}\\{\\text{Fri}\\}]^\\top$. Days cycle in the fixed order Monday, Tuesday, Wednesday, Thursday, Friday, then repeat; there are no weekends in the simulated index.\n\n2. Define the unrestricted model (with day-of-week effect in volatility) as:\n$$\nr_t = \\sigma_t z_t, \\quad z_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1),\n$$\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2 + \\gamma^\\top D_t,\n$$\nwith parameters $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, $\\alpha + \\beta < 1$, and $\\gamma \\in \\mathbb{R}_+^4$ constrained so that $\\sigma_t^2 > 0$ almost surely. The restricted (null) model sets $\\gamma = 0$ and uses:\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2.\n$$\nThese are standard and well-tested structures for modeling volatility clustering and exogenous variance effects.\n\n3. For each test case, simulate returns from a known data-generating process (DGP) that is of the unrestricted form above with known parameter values $(\\omega, \\alpha, \\beta, \\gamma)$ and a fixed seed for reproducibility. Use a burn-in of $B$ observations and then keep the last $T$ observations for estimation. Initialize $\\sigma_1^2$ with a long-run average value that respects $\\alpha + \\beta < 1$ and the average contribution of $D_t$ across the $5$-day cycle.\n\n4. Estimate the unrestricted and restricted models by maximizing the Gaussian log-likelihood (Quasi Maximum Likelihood). Use any smooth reparameterization that ensures $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, $\\alpha + \\beta < 1$, and $\\gamma \\ge 0$ so that numerical optimization is unconstrained in the raw parameter space, but the constraints hold in the model space. For an observation $t$, the Gaussian log-likelihood contribution is:\n$$\n\\ell_t = -\\tfrac{1}{2}\\left(\\log(2\\pi) + \\log \\sigma_t^2 + \\frac{r_t^2}{\\sigma_t^2}\\right),\n$$\nand the total log-likelihood is $L = \\sum_{t=1}^{T} \\ell_t$.\n\n5. Test the null hypothesis $H_0: \\gamma = 0$ versus the unrestricted alternative using the Likelihood Ratio statistic:\n$$\n\\text{LR} = 2\\left[L_{\\text{unrestricted}} - L_{\\text{restricted}}\\right].\n$$\nUnder standard regularity conditions, and when $H_0$ holds, $\\text{LR}$ is asymptotically distributed as a chi-square with $k$ degrees of freedom, where $k$ is the number of restrictions. Here, $k = 4$. Compute the $p$-value using the chi-square distribution with $4$ degrees of freedom, and reject $H_0$ at level $0.05$ if the $p$-value is less than $0.05$. Express the rejection decision as a boolean.\n\n6. Your program must produce a single line of output containing the boolean results for all test cases as a comma-separated list enclosed in square brackets, for example, \"[True,False,True]\".\n\nTest Suite (all numbers are in decimal units consistent with daily returns; no physical units are involved):\n\n- Common settings: for all test cases, use $T = 2000$ and a burn-in of $B = 500$. The day-of-week pattern begins at $t=1$ as Monday, then Tuesday, Wednesday, Thursday, Friday, and repeats.\n\n- Test Case $1$ (null, moderate persistence):\n  - Seed: $123$.\n  - Parameters: $\\omega = 5 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.90$, $\\gamma = [0, 0, 0, 0]$.\n  - Expected behavior: Do not reject $H_0$ at level $0.05$.\n\n- Test Case $2$ (single strong Monday effect):\n  - Seed: $456$.\n  - Parameters: $\\omega = 5 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.90$, $\\gamma = [2\\times 10^{-5}, 0, 0, 0]$.\n  - Expected behavior: Reject $H_0$ at level $0.05$.\n\n- Test Case $3$ (multiple strong day effects):\n  - Seed: $789$.\n  - Parameters: $\\omega = 5 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.90$, $\\gamma = [2\\times 10^{-5}, 1.5\\times 10^{-5}, 1\\times 10^{-5}, 5\\times 10^{-6}]$.\n  - Expected behavior: Reject $H_0$ at level $0.05$.\n\n- Test Case $4$ (null, high persistence near unit-root):\n  - Seed: $321$.\n  - Parameters: $\\omega = 1 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.94$, $\\gamma = [0, 0, 0, 0]$.\n  - Expected behavior: Do not reject $H_0$ at level $0.05$.\n\nFinal Output Format Requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list of `True` or `False` booleans enclosed in square brackets, in the order of the test cases, for example: \"[False,True,True,False]\".", "solution": "The problem as stated is valid. It is a well-defined exercise in computational econometrics, grounded in established theory of time series analysis and hypothesis testing. The task is to implement a Likelihood Ratio test for the presence of deterministic day-of-the-week effects in the conditional variance specification of a GARCH($1,1$) model. The procedure requires several distinct steps: simulation of synthetic data from a known data-generating process (DGP), estimation of both restricted and unrestricted models via Quasi-Maximum Likelihood (QML), and finally, the computation of the test statistic and its associated p-value to make a decision.\n\nThe core of the problem lies in the GARCH($1,1$) model, which captures the phenomenon of volatility clustering observed in many financial time series. The model for the returns $r_t$ is given by\n$$\nr_t = \\sigma_t z_t, \\quad z_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)\n$$\nwhere $z_t$ is a standard normal innovation and $\\sigma_t^2$ is the conditional variance at time $t$. The problem specifies two nested models for this conditional variance.\n\nThe unrestricted model incorporates day-of-the-week effects through a vector of dummy variables $D_t \\in \\mathbb{R}^4$:\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2 + \\gamma^\\top D_t\n$$\nThe restricted model, which corresponds to the null hypothesis $H_0$, excludes these effects by setting the parameter vector $\\gamma$ to zero:\n$$\nH_0: \\gamma = 0 \\quad \\implies \\quad \\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2\n$$\nThe parameters are constrained to ensure a well-behaved variance process: $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, and for stationarity, $\\alpha + \\beta < 1$. The coefficients for the day-of-the-week effects, $\\gamma$, are constrained to be non-negative, $\\gamma \\ge 0$, to preclude negative variance contributions.\n\nThe algorithmic design proceeds as follows:\n\nFirst, a data generation function is constructed. For each test case, we simulate a time series of length $T+B$ from the unrestricted model using the specified parameters $(\\omega, \\alpha, \\beta, \\gamma)$ and random seed. The day-of-the-week dummies $D_t$ are constructed cyclically. The process is initialized with the unconditional variance, which, under the stationarity assumption, is $E[\\sigma_t^2] = (\\omega + E[\\gamma^\\top D_t]) / (1 - \\alpha - \\beta)$. As the days cycle through a $5$-day week, the expectation $E[\\gamma^\\top D_t]$ is the average effect over the week: $\\frac{1}{5}(\\gamma_1 + \\gamma_2 + \\gamma_3 + \\gamma_4)$, where $\\gamma = [\\gamma_1, \\gamma_2, \\gamma_3, \\gamma_4]^\\top$. The first $B=500$ observations are discarded as a burn-in period to mitigate the influence of initial conditions, leaving a sample of size $T=2000$ for estimation.\n\nSecond, we must define the log-likelihood function for estimation. Assuming Gaussian innovations, the log-likelihood contribution for observation $t$ is:\n$$\n\\ell_t(\\theta) = -\\frac{1}{2}\\left(\\log(2\\pi) + \\log \\sigma_t^2(\\theta) + \\frac{r_t^2}{\\sigma_t^2(\\theta)}\\right)\n$$\nwhere $\\theta$ represents the vector of model parameters. The total log-likelihood is $L(\\theta) = \\sum_{t=1}^T \\ell_t(\\theta)$. The estimation is performed by maximizing this function using a numerical optimizer.\n\nTo handle the parameter constraints during optimization, a reparameterization is employed. The optimizer operates on an unconstrained parameter space, and these parameters are transformed to satisfy the required constraints before being used in the likelihood calculation. Let the unconstrained parameters be $p_i$. A suitable transformation is:\n- $\\omega = \\exp(p_0)$ to ensure $\\omega > 0$.\n- $\\alpha = \\frac{\\exp(p_1)}{1+\\exp(p_1)}$ to ensure $\\alpha \\in (0,1)$.\n- $\\beta = (1-\\alpha) \\times \\frac{\\exp(p_2)}{1+\\exp(p_2)}$ to ensure $\\beta \\in (0, 1-\\alpha)$ and thus $\\alpha+\\beta < 1$.\n- $\\gamma_j = \\exp(p_{2+j})$ for $j \\in \\{1,2,3,4\\}$ to ensure $\\gamma_j > 0$.\n\nThe conditional variance series $\\sigma_t^2(\\theta)$ is computed recursively. We initialize $\\sigma_1^2$ with the model-implied unconditional variance using the current parameter estimates $\\theta$. Then, for $t=2, \\dots, T$, we compute $\\sigma_t^2$ using the GARCH recursion. The optimizer will minimize the negative of the total log-likelihood, $-L(\\theta)$.\n\nThird, for each test case, we perform two estimations. We first fit the restricted model, which has $3$ parameters $(\\omega, \\alpha, \\beta)$, to obtain the maximized log-likelihood $L_{\\text{restricted}}$. We then fit the unrestricted model, with $7$ parameters $(\\omega, \\alpha, \\beta, \\gamma_1, \\gamma_2, \\gamma_3, \\gamma_4)$, to obtain $L_{\\text{unrestricted}}$.\n\nFinally, the Likelihood Ratio (LR) test statistic is computed:\n$$\n\\text{LR} = 2(L_{\\text{unrestricted}} - L_{\\text{restricted}})\n$$\nUnder the null hypothesis $H_0: \\gamma = 0$, this statistic follows an asymptotic chi-square distribution with degrees of freedom equal to the number of restrictions, which is $k=4$. The p-value is calculated as $P(\\chi^2_4 > \\text{LR})$. The null hypothesis is rejected if this p-value is less than the specified significance level of $0.05$. The outcome of this decision for each test case, a boolean value, is then reported.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import chi2\n\ndef generate_data(T, B, seed, omega, alpha, beta, gamma):\n    \"\"\"\n    Generates synthetic returns from a GARCH(1,1) model with day-of-week effects.\n    \"\"\"\n    np.random.seed(seed)\n    total_len = T + B\n    \n    # Create day-of-week dummy variables\n    # D_t = [Mon, Tue, Thu, Fri]\n    dummies = np.zeros((total_len, 4))\n    for t in range(total_len):\n        day_of_week = t % 5  # 0:Mon, 1:Tue, 2:Wed, 3:Thu, 4:Fri\n        if day_of_week == 0:   # Monday\n            dummies[t, 0] = 1.0\n        elif day_of_week == 1: # Tuesday\n            dummies[t, 1] = 1.0\n        elif day_of_week == 3: # Thursday\n            dummies[t, 2] = 1.0\n        elif day_of_week == 4: # Friday\n            dummies[t, 3] = 1.0\n            \n    # Initialize returns and variances\n    returns = np.zeros(total_len)\n    sigma_sq = np.zeros(total_len)\n    \n    # Initial variance is the unconditional variance\n    mean_gamma_effect = np.sum(gamma) / 5.0\n    uncond_var = (omega + mean_gamma_effect) / (1.0 - alpha - beta)\n    \n    # Generate standard normal innovations\n    z = np.random.normal(0.0, 1.0, total_len)\n    \n    # First observation\n    sigma_sq[0] = uncond_var\n    returns[0] = np.sqrt(sigma_sq[0]) * z[0]\n    \n    # Generate the rest of the series\n    for t in range(1, total_len):\n        gamma_effect = np.dot(gamma, dummies[t])\n        sigma_sq[t] = omega + alpha * returns[t-1]**2 + beta * sigma_sq[t-1] + gamma_effect\n        if sigma_sq[t] < 1e-12: # Floor variance to avoid numerical issues\n            sigma_sq[t] = 1e-12\n        returns[t] = np.sqrt(sigma_sq[t]) * z[t]\n        \n    return returns[B:], dummies[B:]\n\ndef neg_log_likelihood(params_unconstrained, returns, dummies, is_unrestricted):\n    \"\"\"\n    Calculates the negative of the GARCH log-likelihood function.\n    \"\"\"\n    T = len(returns)\n    \n    # Reparameterization to enforce constraints\n    omega = np.exp(params_unconstrained[0])\n    alpha_trans = np.exp(params_unconstrained[1])\n    alpha = alpha_trans / (1.0 + alpha_trans)\n    beta_trans = np.exp(params_unconstrained[2])\n    beta = (1.0 - alpha) * (beta_trans / (1.0 + beta_trans))\n\n    if is_unrestricted:\n        gamma = np.exp(params_unconstrained[3:])\n        mean_gamma_effect = np.sum(gamma) / 5.0\n    else:\n        gamma = np.zeros(4)\n        mean_gamma_effect = 0.0\n\n    # Ensure stationarity for unconditional variance calculation\n    if (alpha + beta) >= 1.0:\n        return 1e9 # Penalize non-stationary region\n        \n    # Initialize variance series\n    sigma_sq = np.zeros(T)\n    uncond_var = (omega + mean_gamma_effect) / (1.0 - alpha - beta)\n    \n    # It's standard to initialize with unconditional variance.\n    sigma_sq[0] = uncond_var\n\n    # GARCH recursion\n    for t in range(1, T):\n        gamma_effect = np.dot(gamma, dummies[t])\n        sigma_sq[t] = omega + alpha * returns[t-1]**2 + beta * sigma_sq[t-1] + gamma_effect\n        if sigma_sq[t] < 1e-12:\n            sigma_sq[t] = 1e-12\n\n    # Avoid log(0) or division by zero\n    if np.any(sigma_sq <= 0):\n        return 1e9\n\n    # Log-likelihood calculation\n    log_likelihood = -0.5 * np.sum(np.log(2 * np.pi) + np.log(sigma_sq) + returns**2 / sigma_sq)\n\n    if np.isnan(log_likelihood) or np.isinf(log_likelihood):\n        return 1e9\n\n    return -log_likelihood\n\ndef fit_garch(returns, dummies, is_unrestricted):\n    \"\"\"\n    Fits a GARCH(1,1) model (restricted or unrestricted) using QML.\n    \"\"\"\n    if is_unrestricted:\n        # Initial guess for [log(w), ...log(alpha_trans), ...log(beta_trans), ...log(gamma)]\n        x0 = np.array([-12.0, -2.5, 2.5, -16.0, -16.0, -16.0, -16.0])\n    else:\n        # Initial guess for [log(w), ...log(alpha_trans), ...log(beta_trans)]\n        x0 = np.array([-12.0, -2.5, 2.5])\n    \n    res = minimize(\n        neg_log_likelihood,\n        x0=x0,\n        args=(returns, dummies, is_unrestricted),\n        method='L-BFGS-B'\n    )\n    \n    max_log_likelihood = -res.fun\n    return max_log_likelihood\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {'seed': 123, 'omega': 5e-6, 'alpha': 0.05, 'beta': 0.90, 'gamma_vec': np.array([0.0, 0.0, 0.0, 0.0])},\n        # Test Case 2\n        {'seed': 456, 'omega': 5e-6, 'alpha': 0.05, 'beta': 0.90, 'gamma_vec': np.array([2e-5, 0.0, 0.0, 0.0])},\n        # Test Case 3\n        {'seed': 789, 'omega': 5e-6, 'alpha': 0.05, 'beta': 0.90, 'gamma_vec': np.array([2e-5, 1.5e-5, 1e-5, 5e-6])},\n        # Test Case 4\n        {'seed': 321, 'omega': 1e-6, 'alpha': 0.05, 'beta': 0.94, 'gamma_vec': np.array([0.0, 0.0, 0.0, 0.0])}\n    ]\n    \n    common_settings = {'T': 2000, 'B': 500}\n    results = []\n\n    for case in test_cases:\n        # 1. Generate data\n        returns, dummies = generate_data(\n            T=common_settings['T'],\n            B=common_settings['B'],\n            seed=case['seed'],\n            omega=case['omega'],\n            alpha=case['alpha'],\n            beta=case['beta'],\n            gamma=case['gamma_vec']\n        )\n        \n        # 2. Fit restricted model (H0)\n        logL_restricted = fit_garch(returns, dummies, is_unrestricted=False)\n        \n        # 3. Fit unrestricted model (H1)\n        logL_unrestricted = fit_garch(returns, dummies, is_unrestricted=True)\n        \n        # 4. Perform Likelihood Ratio test\n        LR_statistic = 2 * (logL_unrestricted - logL_restricted)\n        \n        # The LR statistic should be non-negative.\n        if LR_statistic < 0:\n            LR_statistic = 0\n            \n        degrees_of_freedom = 4\n        p_value = chi2.sf(LR_statistic, df=degrees_of_freedom)\n        \n        # 5. Make decision\n        reject_H0 = p_value < 0.05\n        results.append(reject_H0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}]}