## 引言
动态语言以其无与伦比的灵活性和开发效率深受开发者喜爱，但这份灵活性的代价往往是性能的妥协。其核心挑战之一在于动态派发（dynamic dispatch）：在运行时才确定一个方法调用具体执行哪个函数。传统的查找机制（如哈希表查找）开销巨大，成为了性能瓶颈。为了弥合动态语言与静态语言之间的性能鸿沟，一种名为“[内联缓存](@entry_id:750659)”（Inline Caching, IC）的强大[优化技术](@entry_id:635438)应运而生。它基于一个简单的经验观察——程序中的动态调用点在实践中往往只遇到少数几种类型的对象——从而通过在调用点创建专门的快速路径来大幅加速后续调用。

本文旨在全面而深入地剖析[内联缓存](@entry_id:750659)及其演化形态。我们将从其基本工作原理出发，逐步探索其在现代复杂计算系统中的实现细节、性能权衡与跨学科应用。

*   在**“原理与机制”**一章中，我们将揭示[内联缓存](@entry_id:750659)的核心思想，追踪其从单态到多态再到超多态的生命周期，并深入分析其性能模型、与底层硬件的交互，以及在并发和[垃圾回收](@entry_id:637325)等复杂场景下确保正确性的关键挑战。
*   接下来的**“应用与跨学科关联”**一章将视野拓宽，展示[内联缓存](@entry_id:750659)如何被用于优化更复杂的语言特性，如何与编译器中的其他优化协同工作，并揭示其设计哲学如何在数据库、Web服务和区块链等不同领域中得到体现。
*   最后，在**“动手实践”**部分，我们将通过一系列精心设计的问题，引导您将理论知识应用于解决具体的优化和实现难题，从而深化对[内联缓存](@entry_id:750659)技术栈的理解。

通过这趟旅程，您将不仅掌握[内联缓存](@entry_id:750659)的“是什么”和“为什么”，更能体会到它作为一种基础计算原则的深刻内涵与广泛影响。

## 原理与机制

动态语言的灵活性，如在运行时确定对象类型和方法，带来了巨大的开发便利，但同时也给性能带来了挑战。每当执行一个动态派发（例如方法调用 `object.method()`），[运行时系统](@entry_id:754463)必须在执行期间解析出 `method` 到底指向哪个具体的函数实现。一种朴素的实现方式可能是在一个哈希表中根据方法名进行查找，但这对于性能敏感的代码路径来说，开销过于高昂。[内联缓存](@entry_id:750659)（Inline Caching, IC）是一种强大而基础的[优化技术](@entry_id:635438)，旨在将这种动态派发的开销降低到接近静态语言的水平。本章将深入探讨[内联缓存](@entry_id:750659)的原理、其不同[形态的演化](@entry_id:145891)机制、性能考量以及在现代复杂系统中实现的正确性挑战。

### [内联缓存](@entry_id:750659)的核心思想

[内联缓存](@entry_id:750659)的基本思想源于一个经验性观察：在程序执行过程中，尽管一个动态调用点（call site）理论上可以接收任何类型的对象，但在实践中，它往往只接收到一种或少数几种类型的对象。这种现象被称为**调用点类型稳定性**。[内联缓存](@entry_id:750659)利用这一特性，通过在调用点“内联”一段专门化的代码来优化后续的调用。

一个[内联缓存](@entry_id:750659)包含三个关键部分：

1.  **守卫 (Guard)**：这是一段快速执行的代码，用于检查当前接收者对象的类型或“形态”（shape）是否与缓存中记录的类型相符。在现代[虚拟机](@entry_id:756518)中，对象的形态通常由一个称为**[隐藏类](@entry_id:750252) (hidden class)** 或**映射 (map)** 的内部结构来描述。[隐藏类](@entry_id:750252)不仅定义了对象的属性布局（即每个属性在内存中的偏移量），也为[内联缓存](@entry_id:750659)提供了一个高效的、可用于比较的标识符。

2.  **快速路径 (Fast Path)**：如果守卫检查通过，意味着我们遇到了预期的对象类型。此时，执行会转向一段高度优化的、专门化的代码。例如，对于属性访问，快速路径可以直接从预先计算好的内存偏移量加载数据；对于方法调用，它可以直接跳转到目标函数的地址。这避免了通用的、缓慢的查找过程。

3.  **慢速路径 (Slow Path)**：如果守卫检查失败，说明遇到了一个未曾预料到的新类型。此时，执行必须回退到通用的派发机制（例如，[哈希表](@entry_id:266620)查找）来正确完成操作。这个过程不仅成本高昂，更重要的是，它会触发[内联缓存](@entry_id:750659)的更新机制，使其“学习”这个新类型，以便在未来能够快速处理它。

### [内联缓存](@entry_id:750659)的生命周期：从单态到超多态

[内联缓存](@entry_id:750659)并非一成不变，它会随着程序运行动态地演化，以适应调用点观察到的类型[分布](@entry_id:182848)。其生命周期通常包含以下几个状态：

*   **未初始化 (Uninitialized)**：一个调用点最初处于未初始化或“冷”状态。此时，每次执行都会走通用的慢速路径。

*   **单态 (Monomorphic)**：当调用点第一次执行并观察到第一个接收者类型时，[运行时系统](@entry_id:754463)会将其从未初始化状态转换为单态状态。它会生成一个针对该特定类型（例如，[隐藏类](@entry_id:750252) $M_A$）的[内联缓存](@entry_id:750659)（IC）。这个IC的守卫会检查接收者是否为 $M_A$ 类型，如果是，则执行为 $M_A$ 专门生成的快速路径。单态调用点是最高效的，因为它们只需要一次类型检查。

*   **多态 (Polymorphic)**：如果一个已经处于单态的调用点观察到了一个新的、不同的类型（例如 $M_B$），简单的单态缓存守卫就会失败。此时，[运行时系统](@entry_id:754463)会将IC升级为**[多态内联缓存](@entry_id:753568) (Polymorphic Inline Cache, PIC)**。一个PIC[实质](@entry_id:149406)上是一个由多个单态缓存组成的链条，每个缓存对应一个它曾经见过的类型。例如，PIC的守卫逻辑会变成：“如果类型是 $M_A$，走路径A；否则，如果类型是 $M_B$，走路径B；否则，走慢速路径”。PIC的效率随着其支持的类型数量增加而略有下降，因为它需要进行多次检查。

*   **超多态 (Megamorphic)**：当一个PIC中记录的类型数量超过了一个预设的阈值 $\ell$（例如，$\ell=4$），[运行时系统](@entry_id:754463)会认为这个调用点过于“混乱”，类型非常不稳定。继续增加PIC的长度会导致守卫链过长，性能下降，并且增加代码体积。此时，系统会放弃为每个类型生成专门路径的策略，将调用点转换为**超多态**状态。超多态缓存通常使用一种更通用的[数据结构](@entry_id:262134)，如自定义的哈希表，来加速查找。虽然比PIC慢，但它对于处理大量类型的情况提供了一个可预测且比最初的通用慢速路径更优的性能下限。

为了具体理解这个过程，我们可以追踪一个属性访问操作 $r \leftarrow \text{recv}.\,p$ 在一个循环中的执行。假设PIC的容量阈值为 $\ell = 4$，而[即时编译器](@entry_id:750942)（JIT）在调用点执行 $N=6$ 次后触发编译。[@problem_id:3646155]

1.  **第1次迭代**: 遇到类型 $M_A$。调用点从**未初始化**变为**单态**，为 $M_A$ 生成一个IC。
2.  **第2次迭代**: 再次遇到 $M_A$。命中单态IC。
3.  **第3次迭代**: 遇到新类型 $M_B$。IC守卫失败，触发慢速路径。调用点升级为**多态**，PIC现在包含 $M_A$ 和 $M_B$ 的处理路径。
4.  **第4次迭代**: 遇到 $M_A$。命中PIC中对应的路径。
5.  **第5次迭代**: 遇到新类型 $M_C$。PIC扩展，现在包含 $M_A, M_B, M_C$。
6.  **第6次迭代**: 遇到 $M_B$。命中PIC。这是第6次执行，[JIT编译](@entry_id:750967)器在本次迭代后被触发。它会检查此刻PIC的状态，并为已观察到的三种类型 $M_A, M_B, M_C$ 生成优化的内联守卫序列。
7.  **第7次迭代**: 遇到新类型 $M_D$。PIC扩展，达到容量上限4（包含 $M_A, M_B, M_C, M_D$）。
8.  **第8、9次迭代**: 分别遇到 $M_B$ 和 $M_A$，均在PIC中命中。
9.  **第10次迭代**: 遇到新类型 $M_E$。此时观察到的不同类型总数达到5，超过了容量 $\ell=4$。PIC被废弃，调用点转换为**超多态**状态。
10. **后续迭代**: 无论遇到 $M_A$ 还是 $M_B$，都将通过超多态缓存的通用机制进行处理。

这个例子清晰地展示了[内联缓存](@entry_id:750659)如何根据运行时的类型反馈动态地调整其策略，在性能和通用性之间取得平衡。

### [性能优化](@entry_id:753341)与权衡

[内联缓存](@entry_id:750659)的设计和行为深刻影响着动态语言的执行性能。其有效性不仅取决于类型稳定性，还与更深层次的实现细节和[微架构](@entry_id:751960)特性紧密相关。

#### [摊还成本](@entry_id:635175)分析

我们可以通过一个概率模型来量化[内联缓存](@entry_id:750659)的性能收益。假设一个调用点的总访问速率为 $\rho$，而遇到新类型的速率服从泊松过程，其速率为 $\lambda$。每次缓存命中（hit）的成本为 $c_h$，而每次缓存未命中（miss）除了需要走慢速路径（成本 $c_s$），还需要更新缓存（成本 $c_u$），总成本为 $c_s + c_u$。

那么，一次访问是命中的概率是 $p_{hit} = \frac{\rho - \lambda}{\rho}$，是未命中的概率是 $p_{miss} = \frac{\lambda}{\rho}$。因此，该调用点的**期望[摊还成本](@entry_id:635175)**（Expected Amortized Cost）可以表示为命中和未命中成本的加权平均值：
$$ E[\text{Cost}] = p_{hit} \cdot c_h + p_{miss} \cdot (c_s + c_u) = \frac{\rho - \lambda}{\rho} c_h + \frac{\lambda}{\rho} (c_s + c_u) = \frac{c_{h}(\rho - \lambda) + \lambda(c_{s} + c_{u})}{\rho} $$
这个模型 [@problem_id:3646133] 揭示了一个关键点：在[稳态](@entry_id:182458)下，只要新类型的[到达率](@entry_id:271803) $\lambda$ 远小于总访问率 $\rho$，系统的平均成本就主要由低成本的命中事件 $c_h$ 决定。有趣的是，这个[摊还成本](@entry_id:635175)与超多态的阈值 $M$ 无关，因为它描述的是达到阈值前任意时刻的[稳态](@entry_id:182458)行为。

#### [微架构](@entry_id:751960)考量：分支预测

PIC的实现通常是一个线性的条件判断链。这种实现方式与现代CPU的**分支预测**单元会发生有趣的交互。分支预测器会学习每个条件分支（`if-then-else`）的跳转模式，并预测其最可能的结果，以避免昂贵的[流水线停顿](@entry_id:753463)。如果预测错误，即发生**分支预测失败 (branch misprediction)**，则会带来显著的性能损失。

因此，PIC中守卫的顺序至关重要。考虑一个场景：一个PIC已经缓存了 $k$ 个类型，它们的出现概率均等。此时，一个新类型 $T_{k+1}$ 以较高的概率 $\alpha$ 出现。我们有两种策略来更新PIC：在守卫链的**前端插入**新类型的检查，或在**末端追加**。

直觉上，将最可能出现的类型检查放在最前面，可以尽早退出检查链，并使得第一个分支的预测更加准确。通过精确的数学分析 [@problem_id:3646206]，可以证明，一个优化的分支预测器（如[2位饱和计数器](@entry_id:746151)）在[稳态](@entry_id:182458)下的预测失败率等于该分支较少发生的结果的概率。将高频类型 $T_{k+1}$ 的检查放在首位（前端插入策略），虽然可能使得这第一个分支的预测失败率（即 $\min(\alpha, 1-\alpha)$）较高，但它能确保后续检查低频类型的分支被执行的概率降低，从而总体上减少了总的预期预测失败次数。相比之下，末端追加策略将高频检查放在最后，迫使执行流在大多数情况下都要穿越整个低频检查链，导致更高的整体预测失败率。这个例子说明，高效的[JIT编译](@entry_id:750967)器设计必须考虑到目标CPU的[微架构](@entry_id:751960)特性。

#### 适应性策略与稳定性：滞后性

[JIT编译](@entry_id:750967)器通常会根据运行时收集的类型[分布](@entry_id:182848)剖面（profile）来做出优化决策，例如是否要将一个PIC“降级”回更快的单态IC。一个简单的策略可能是：如果最常见的类型（top type）的出现概率 $\hat{p}$ 超过某个阈值 $\theta$（例如 $\theta=0.9$），就切换到单态IC。

然而，如果真实的概率 $p$ 恰好在阈值 $\theta$ 附近波动，那么由于采样的随机性，估计值 $\hat{p}$ 可能会在每次统计窗口中频繁地穿越阈值 $\theta$。这会导致系统在单态和多态之间不停地来回切换，这种现象称为**[抖动](@entry_id:200248) (churn)**。每次切换本身都有不小的开销（[代码生成](@entry_id:747434)、去优化等），频繁的[抖动](@entry_id:200248)会严重损害性能。

为了解决这个问题，可以引入控制理论中的**滞后性 (hysteresis)** 概念 [@problem_id:3646150]。我们不再使用单一阈值 $\theta$，而是定义一个区间 $[\theta_{\text{low}}, \theta_{\text{high}}]$（例如，$\theta_{\text{low}}=\theta-h, \theta_{\text{high}}=\theta+h$）。策略变为：
*   仅当 $\hat{p} > \theta_{\text{high}}$ 时，才从PIC切换到单态IC。
*   仅当 $\hat{p}  \theta_{\text{low}}$ 时，才从单态IC切换到PIC。
*   当 $\theta_{\text{low}} \le \hat{p} \le \theta_{\text{high}}$ 时，保持当前状态不变。

这个“无为”区间有效地抑制了因微小波动引起的[抖动](@entry_id:200248)。通过[概率模型](@entry_id:265150)分析，可以计算出预期的切换概率 $t(h)$ 是滞后半宽度 $h$ 的函数。增加 $h$ 会显著降低切换概率，从而使系统在面对不稳定的类型[分布](@entry_id:182848)时更加鲁棒。例如，要将切换概率降低到$5\%$以下，我们可以计算出所需的最小 $h$ 值，从而为[系统设计](@entry_id:755777)提供定量的指导。

#### 超多态缓存的设计

当一个调用点进入超多态状态时，如何设计其回退机制也是一个[优化问题](@entry_id:266749)。一个常见的选择是使用一个通用的哈希表来存储类型到方法的映射。然而，一个更精妙的策略是结合PIC和哈希表：为最常见的 $K$ 个类型保留一个PIC，对于超出这 $K$ 个的类型，则回退到一个哈希表。

这里的关键问题是如何确定最优的PIC长度 $K^{\star}$。这涉及到一个权衡：增加 $K$ 可以让更多的类型走上更快的PIC路径，但也会增加PIC的[线性搜索](@entry_id:633982)成本和代码体积。我们可以建立一个成本函数 $J(K) = E[T(K)] + \lambda K$，其中 $E[T(K)]$ 是预期的派发时间，$\lambda K$ 是与代码体积相关的惩罚项 [@problem_id:3646198]。通过对这个[成本函数](@entry_id:138681)进行[微分](@entry_id:158718)或差分分析，可以求解出使总成本最小化的最优值 $K^{\star}$。这个过程展示了[JIT编译](@entry_id:750967)器如何利用数学模型来做出复杂的、数据驱动的优化决策。

### 复杂系统中的正确性与实现挑战

在真实的、工业级的[虚拟机](@entry_id:756518)中实现[内联缓存](@entry_id:750659)，除了要考虑性能，还必须面对一系列严峻的正确性挑战，尤其是在并发、垃圾回收和动态[代码优化](@entry_id:747441)等特性的交织作用下。

#### 对象形态的表示与识别

[内联缓存](@entry_id:750659)的守卫依赖于对对象“形态”的快速识别。这个形态描述符（或称键）的设计本身就是一个权衡。一种方法是为每个独一无二的形态（即[隐藏类](@entry_id:750252)）分配一个唯一的、定长的ID。这种方法可以保证没有冲突，但需要一个全局的注册表来管理这些ID（这个过程称为**interning**）。另一种方法是根据形态的属性集和布局计算一个哈希值作为其描述符 [@problem_id:3646166]。这种方法避免了全局同步，但存在**[哈希冲突](@entry_id:270739)**的风险：两个不同的形态可能产生相同的哈希值，这会导致缓存守卫做出错误的判断，是一种潜在的正确性bug。这个风险的大小可以通过经典的“[生日问题](@entry_id:268167)”概率模型来量化，其冲突概率 $P_{coll}$ 是形态数量 $U$ 和哈希位数 $h$ 的函数。选择合适的哈希函数和足够大的哈希空间是降低这种风险的关键。

#### 保证缓存有效性

[内联缓存](@entry_id:750659)本质上是一种基于过去行为的**[推测性优化](@entry_id:755204)**。当过去的假设在未来不再成立时，系统必须有机制来保证程序的正确性。一个典型的挑战来自于**动态布局变更** [@problem_id:3646123]。

考虑这样一种场景：一个[JIT编译](@entry_id:750967)器为了改善[内存局部性](@entry_id:751865)，决定重新[排列](@entry_id:136432)一个[隐藏类](@entry_id:750252) $H_0$ 的字段顺序。这意味着，与 $H_0$ 关联的属性偏移量发生了变化。然而，为了保持兼容性，[隐藏类](@entry_id:750252) $H_0$ 的标识符（即指针地址）本身可能保持不变。此时，一个早先为旧布局生成的IC，其守卫 `object.hidden_class == H_0` 仍然会通过，但它内部硬编码的属性偏移量已经过时了。执行这个IC的快速路径将从错误的内存位置读取数据，导致严重的、难以察觉的程序错误。

为了解决这个问题，必须采用更精密的机制来使失效的缓存无效化：
1.  **版本化 (Versioning)**：为每个[隐藏类](@entry_id:750252)的布局附加一个版本号。IC的守卫不仅要检查[隐藏类](@entry_id:750252)的标识符，还要检查其版本号是否与生成IC时所记录的版本号匹配。当布局发生变化时，版本号递增，导致所有依赖旧布局的IC守卫失效，安全地回退到慢速路径。
2.  **依赖追踪与去优化 (Dependency Tracking and Deoptimization)**：当[JIT编译](@entry_id:750967)器为一个特定的[隐藏类](@entry_id:750252)布局生成优化代码（如IC）时，它会把这段代码注册为该布局的一个“依赖项”。当布局因为任何原因发生变更时，[运行时系统](@entry_id:754463)会遍历所有依赖于旧布局的代码，并立即将其**无效化**或**去优化**，强制它们在下次执行时重新生成。

这两种机制通常结合使用，共同构成了现代[JIT编译](@entry_id:750967)器中保证[推测性优化](@entry_id:755204)正确性的基石。

#### 并发环境下的[原子性](@entry_id:746561)更新

在[多线程](@entry_id:752340)环境中，多个线程可能同时执行同一个调用点，并尝试更新同一个全局的[内联缓存](@entry_id:750659)。直接在原地修改共享的、正在被执行的代码序列是极其危险的，这会引发**补丁竞争 (patch race)**。一个线程可能正在执行一段被另一个线程部分覆写的代码，导致执行未定义指令或访问不一致的数据。

为了安全地更新共享的IC/PIC，必须使用精密的[并发控制](@entry_id:747656)协议 [@problem_id:3646102]：
*   对于**全局IC**，一种常见的正确做法是使用**指针间接 (indirection)**。调用点不直接包含代码，而是包含一个指向代码存根（stub）的指针。更新时，补丁线程首先在新的内存区域完整地构建一个新的、不可变的存根。然后，它使用一个原子的**[比较并交换](@entry_id:747528) (Compare-and-Swap, CAS)** 操作，将共享指针从指向旧存根切换到指向新存根。读取方线程在跳转前加载该指针。CAS操作的[原子性](@entry_id:746561)保证了任何读取方要么看到完整的旧存根，要么看到完整的新存根，绝不会看到中间状态。
*   为了确保一个线程看到新指针的同时也能看到新存根的完整内容（而不是被内存重排序影响的垃圾数据），这些操作必须辅以正确的**内存序 (memory ordering)** 语义，如C++11中的**获取-释放语义 (acquire-release semantics)**。
*   对于**线程局部IC**，虽然不存在与其他线程的竞争，但仍然可能存在与自身（例如，由信号处理器中断）的竞争。一种安全的协议是使用一个状态机（例如，`{cold, patching, hot}`），并通过CAS操作来原子地获取“修改权”（例如，从 `hot` 切换到 `patching`）。当状态为 `patching` 时，任何执行尝试都会被引导到安全的慢速路径，从而避免执行正在被修改的代码。

#### 与垃圾回收器的交互

当[JIT编译](@entry_id:750967)器与一个**移动式[垃圾回收](@entry_id:637325)器 (moving garbage collector)** 一起工作时，挑战变得更加严峻。移动式GC会在整理[内存碎片](@entry_id:635227)[时移](@entry_id:261541)动对象，这会导致指向这些对象的原始指针失效。IC/PIC的存根中通常会硬编码指向堆上对象（如[隐藏类](@entry_id:750252)、方法对象）的指针。如果GC移动了这些对象，而没有更新存根中的指针，那么这些指针就会变成**悬垂指针 (dangling pointers)**，引发[内存安全](@entry_id:751881)问题。

此外，如果GC是**增量式 (incremental)** 或**并发式 (concurrent)** 的，它允许应用程序（mutator）在标记阶段并行运行。这要求mutator在修改对象引用时必须遵守GC的**[写屏障](@entry_id:756777) (write barrier)** 协议，以维护**三色[不变性](@entry_id:140168)**（即确保没有黑色对象直接指向白色对象），防止GC错误地回收活动对象。

为了让IC在这种环境下正确工作 [@problem_id:3646129]，必须采取以下一种或多种策略：
*   **将代码注册为根 (Registering Code as Roots)**：[JIT编译](@entry_id:750967)器必须告知GC所有包含堆指针的已编译代码区域。在GC的重定位阶段，GC会扫描这些“代码根”，并像更新堆中其他指针一样，更新代码中嵌入的指针。
*   **遵守[写屏障](@entry_id:756777)**：当IC的慢速路径逻辑需要更新其在堆上分配的[元数据](@entry_id:275500)（例如，一个记录已见类型的辅助表）时，这个写操作必须触发GC的[写屏障](@entry_id:756777)，以正确维护三色不变性和代际指针（remembered set）。
*   **使用句柄 (Handles)**：作为直接嵌入原始指针的替代方案，IC可以嵌入指向**句柄 (handle)** 的指针。句柄是一个稳定的间接引用，其内容由GC在移动对象时负责更新。IC代码通过句柄加载最新的对象地址。这样，代码本身就不需要被GC修改了，但代价是每次访问都多了一次间接寻址。

### [内联缓存](@entry_id:750659)的安全隐患

令人惊讶的是，像[内联缓存](@entry_id:750659)这样的纯[性能优化](@entry_id:753341)也可能引入安全漏洞。一个典型的例子是**时序[侧信道](@entry_id:754810) (timing side-channel)** 攻击 [@problem_id:3646175]。

问题的根源在于IC的不同状态（单态、多态、超多态）具有显著不同的执行时间。例如，一个单态调用可能耗时 $t_{\text{mono}}=40\,\text{ns}$，而一个超多态调用可能耗时 $t_{\text{mega}}=160\,\text{ns}$。假设一个程序中存在一个秘密比特 $b$，当 $b=0$ 时，某个调用点的接收者类型[分布](@entry_id:182848)使其保持单态；当 $b=1$ 时，类型[分布](@entry_id:182848)使其变为超多态。一个能够精确测量该调用点执行时间的攻击者，只需观察耗时是接近 $40\,\text{ns}$ 还是 $160\,\text{ns}$，就能以极高的准确率推断出秘密比特 $b$ 的值。

为了抵御这种攻击，可以采取**常数时间编程**的原则，努力使操作的执行时间与秘密数据无关。一种直接的缓解措施是**时间填充 (time padding)**。无论实际执行路径是快是慢，都人为地加入一段延迟，使得最终观察到的总时间恒定。例如，可以将所有路径的执行时间都填充到最坏情况下的时间 $t_{\text{mega}}$。这样，无论秘密是$0$还是$1$，外部观察到的时间都是一样的，[侧信道](@entry_id:754810)就被关闭了。当然，这种安全性的提升是以牺牲性能为代价的，因为快速路径也被迫变慢了。其他方法，如部分填充或[随机化](@entry_id:198186)填充，可能无法完全消除[信息泄露](@entry_id:155485)，因为攻击者或许能通过多次测量和统计分析来还原出时间[分布](@entry_id:182848)的差异。这凸显了在设计现代计算系统时，性能、正确性和安全性之间复杂而深刻的相互作用。