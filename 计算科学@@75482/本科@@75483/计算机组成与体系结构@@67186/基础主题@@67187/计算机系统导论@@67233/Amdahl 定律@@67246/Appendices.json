{"hands_on_practices": [{"introduction": "阿姆达尔定律不仅是分析现有系统性能的工具，更是指导未来系统设计的强大准则。在设计一个多核处理器系统时，我们常常面临一个关键问题：为了在给定的核心数量下达到期望的性能提升，我们的应用程序需要多大程度的并行化？这个练习将带你进行一次逆向工程计算，通过一个具体的性能目标[@problem_id:3620143]，来确定程序必须达到的并行化分数，从而为软件优化指明方向。", "problem": "正在设计一个具有$16$个相同核心的共享内存多处理器，用于运行科学计算工作负载。设单核执行时间可分解为一个严格串行部分 $T_{s}$ 和一个可并行部分 $T_{p}$，因此 $T_{1} = T_{s} + T_{p}$。当在$N$个核心上运行时，假设串行部分保持串行，可并行部分理想地在核心之间划分，没有工作损失或负载不平衡，因此多核执行时间为 $T_{N} = T_{s} + T_{p}/N$。定义在$N$个核心上的加速比为 $S(N) = T_{1}/T_{N}$，并将在一个核心上的可并行化分数为 $p = T_{p}/T_{1}$。设计目标是 $S(16) = 10$。仅使用这些定义和假设，推导 $S(N)$、$p$ 和 $N$ 之间的关系，求解实现 $S(16) = 10$ 所需的 $p$ 值，并将 $p$ 精确地以最简分数形式报告（不要四舍五入，不要使用百分号）。\n\n最后，根据你的推导和结果，定性讨论微体系结构上的改变如何能够使类似的工作负载在实践中达到如此高的可并行化分数。提供至少三个具体的改变，并附上简要理由。缩略词在首次使用时应进行定义，例如，同时多线程（Simultaneous Multithreading, SMT）。", "solution": "问题陈述已经过验证，被认为是合理的。这是一个基于计算机体系结构原理，特别是阿姆达尔定律（Amdahl's Law）的适定问题。\n\n按照要求，解答分为三部分。首先，我们推导加速比的一般关系。其次，我们求解所需的可并行化分数的具体值。第三，我们讨论微体系结构方面的影响。\n\n**第一部分：加速比公式的推导**\n\n我们有以下给定的定义：\n单核执行时间为 $T_{1} = T_{s} + T_{p}$，其中 $T_{s}$ 是串行部分，$T_{p}$ 是可并行部分。\n$N$ 个核心上的多核执行时间为 $T_{N} = T_{s} + \\frac{T_{p}}{N}$。\n加速比定义为 $S(N) = \\frac{T_{1}}{T_{N}}$。\n可并行化分数定义为 $p = \\frac{T_{p}}{T_{1}}$。\n\n我们的目标是把 $S(N)$ 表示为 $p$ 和 $N$ 的函数。我们首先用 $T_{1}$ 和 $p$ 来表示 $T_{s}$ 和 $T_{p}$。\n根据可并行化分数的定义，我们有：\n$$T_{p} = p \\cdot T_{1}$$\n工作负载的串行分数，我们称之为 $s$，是剩余的部分。因此，$s = 1 - p$。串行时间部分 $T_s$ 是总单核时间的这一部分：\n$$T_{s} = (1 - p) \\cdot T_{1}$$\n我们可以验证这一点：$T_s + T_p = (1-p)T_1 + pT_1 = T_1 - pT_1 + pT_1 = T_1$，这是一致的。\n\n现在，我们将 $T_{s}$ 和 $T_{p}$ 的表达式代入多核执行时间 $T_{N}$ 的公式中：\n$$T_{N} = ((1 - p) \\cdot T_{1}) + \\frac{p \\cdot T_{1}}{N}$$\n我们可以提出因子 $T_{1}$：\n$$T_{N} = T_{1} \\left( (1 - p) + \\frac{p}{N} \\right)$$\n最后，我们将 $T_{N}$ 的这个表达式代入加速比公式 $S(N)$ 中：\n$$S(N) = \\frac{T_{1}}{T_{1} \\left( (1 - p) + \\frac{p}{N} \\right)}$$\n$T_{1}$ 项被消去，得到了 $S(N)$、$p$ 和 $N$ 之间的一般关系，这就是著名的阿姆达尔定律的公式：\n$$S(N) = \\frac{1}{(1 - p) + \\frac{p}{N}}$$\n\n**第二部分：可并行化分数 $p$ 的计算**\n\n给定的设计目标是，使用 $N=16$ 个核心时必须达到 $S(16) = 10$ 的加速比。我们使用推导出的公式来求解所需的可并行化分数 $p$。\n将 $N=16$ 和 $S(16)=10$ 代入方程：\n$$10 = \\frac{1}{(1 - p) + \\frac{p}{16}}$$\n为了解出 $p$，我们对两边取倒数：\n$$0.1 = (1 - p) + \\frac{p}{16}$$\n现在，我们重新整理各项以分离出 $p$：\n$$0.1 = 1 - p + \\frac{p}{16}$$\n$$p - \\frac{p}{16} = 1 - 0.1$$\n$$p \\left(1 - \\frac{1}{16}\\right) = 0.9$$\n$$p \\left(\\frac{16}{16} - \\frac{1}{16}\\right) = \\frac{9}{10}$$\n$$p \\left(\\frac{15}{16}\\right) = \\frac{9}{10}$$\n现在，我们求解 $p$：\n$$p = \\frac{9}{10} \\cdot \\frac{16}{15}$$\n$$p = \\frac{9 \\cdot 16}{10 \\cdot 15} = \\frac{144}{150}$$\n为了将其表示为最简分数，我们找到分子和分母的最大公约数。两者都可以被 $6$ 整除：\n$$p = \\frac{144 \\div 6}{150 \\div 6} = \\frac{24}{25}$$\n因此，要在 $16$ 个核心上实现 $10$ 倍的加速比，工作负载必须是 $96\\%$ 可并行的。这意味着代码的严格串行部分只能占总单核执行时间的 $1-p = 1 - \\frac{24}{25} = \\frac{1}{25}$，即 $4\\%$。\n\n**第三部分：微体系结构上的改变**\n\n要达到如此高的可并行化分数（$p = 0.96$）是具有挑战性的。该模型假定 $T_p$ 部分可以理想地并行化，并将 $T_s$ 视为一个固定的、不可改变的量。在实践中，有效的串行部分和并行执行的效率都深受处理器微体系结构的影响。以下是三个具体的微体系结构改变，可以帮助工作负载实现更高的有效可并行化分数。\n\n1.  **激进的乱序与推测执行：** 根据定义，串行部分 $T_s$ 在线程级别上是不可并行的。但是，它仍然可以包含指令级并行（Instruction-Level Parallelism, ILP）。一个更强大的乱序执行引擎可以减少这个串行部分所需的墙钟时间。这包括增加关键结构（如重排序缓冲（re-order buffer, ROB））的大小，这使得处理器能够越过阻塞指令，在指令流中看得更远；以及提高分支预测器的准确性（例如，使用 TAGE（TAgged GEometric history length）预测器）。通过在 $T_p$ 保持不变的情况下减少 $T_s$ 的执行时间，比率 $T_s/T_1$ 会降低，这反过来又增加了可并行化分数 $p = 1 - T_s/T_1$。\n\n2.  **用于同步的硬件加速：** 在许多并行算法中，一个重要的串行化来源是同步开销（例如，锁、屏障、原子操作）。这些操作可能迫使除了一个核心之外的所有核心都处于空闲状态，从而有效地延长了执行的串行部分。引入专门的硬件支持可以极大地减少这种开销。例如，硬件事务内存（Hardware Transactional Memory, HTM）允许通常需要锁的代码段以推测方式并行执行。硬件会检测数据冲突，只有在发生冲突时才需要回滚和重试。这可以将串行执行的临界区转换为并行执行。类似地，用于原子内存操作（Atomic Memory Operations, AMOs）的专用硬件单元可以比软件模拟的等效操作快得多地执行这些指令。\n\n3.  **先进的缓存一致性和片上互连：** 模型对于并行部分（$T_p/N$）的理想加速比的假设，意味着所有核心都可以在没有竞争或延迟惩罚的情况下访问数据。这在现实中是不可能的。随着核心数量 $N$ 的增加，内存层次结构中对共享数据的争用成为主要的性能限制因素。一个具有高带宽和低延迟的高性能片上网络（Network-on-Chip, NoC）对于高效的核心间通信至关重要。此外，需要一个复杂的缓存一致性协议来管理共享数据。对于一个 $16$ 核系统，基于目录的协议比基于监听的协议更具可扩展性。像更大、分区的末级缓存（Last-Level Caches, LLCs）或非一致性缓存架构（Non-Uniform Cache Architecture, NUCA）等改进，也可以通过将数据放置在更靠近需要它的核心的位置来减少平均内存访问延迟。这些特性使并行执行更有效率，有助于实际性能接近 $T_p/N$ 的理论理想值。", "answer": "$$\\boxed{\\frac{24}{25}}$$", "id": "3620143"}, {"introduction": "现实世界中的计算任务很少能简单地划分为单个串行和并行部分。更常见的情况是，一个程序会经历多个计算阶段，每个阶段具有不同的并行潜力。本练习[@problem_id:3620142]将阿姆达尔定律扩展到这种更复杂的场景，你需要综合考虑不同阶段的执行时间比例和各自的并行化分数，以推导出整个工作负载的总体加速比。", "problem": "一个计算密集型工作负载在一个同构多核处理器上执行。该工作负载包含三个不同的阶段，分别标记为 A、B 和 C。当在单核上运行时，各阶段的持续时间遵循 $2:5:3$ 的比例。设阶段 A、B 和 C 的单核执行时间分别为 $t_A$、$t_B$ 和 $t_C$，使得 $t_A:t_B:t_C=2:5:3$。每个阶段都有一部分工作可以完美地在多核之间并行化：对于阶段 A，该比例为 $p_A=0.7$；对于阶段 B，为 $p_B=0.9$；对于阶段 C，为 $p_C=0.5$。假设理想化的并行执行具有以下特性：一个阶段的可并行化部分随核心数 $N$ 线性扩展，没有同步或通信开销，且不可并行化部分不会因增加核心而加速。\n\n从加速比 $S(N)$ 的基本定义（单核执行时间与 $N$ 核执行时间之比）出发，并假设在每个阶段内，可并行化和不可并行化部分对总阶段时间的贡献是可加的，推导整个工作负载的总加速比 $S(N)$ 作为核心数 $N$ 的函数的封闭形式表达式。请将最终答案表示为关于 $N$ 的简化解析表达式。无需四舍五入。", "solution": "该问题陈述清晰，具有科学依据，并拥有唯一且有意义的解。这是阿姆达尔定律在多阶段计算工作负载上的直接应用。所有必要的数据和条件都已给出，且没有内部矛盾。\n\n在一个有 $N$ 个核心的处理器上执行一个进程的总体加速比 $S(N)$ 定义为单核执行时间 $T(1)$ 与 $N$ 核执行时间 $T(N)$ 之比。\n$$S(N) = \\frac{T(1)}{T(N)}$$\n总的单核执行时间 $T(1)$ 是单个阶段 A、B 和 C 执行时间之和：\n$$T(1) = t_A + t_B + t_C$$\n问题陈述了这些时间的比例为 $t_A:t_B:t_C = 2:5:3$。设总单核执行时间为参考值 $T(1)$。每个阶段对总单核执行时间的贡献分数可以从这个比例中计算出来。比例各部分之和为 $2+5+3=10$。因此，各阶段的时间分数是：\n$$f_A = \\frac{t_A}{T(1)} = \\frac{2}{10} = 0.2$$\n$$f_B = \\frac{t_B}{T(1)} = \\frac{5}{10} = 0.5$$\n$$f_C = \\frac{t_C}{T(1)} = \\frac{3}{10} = 0.3$$\n所以，我们可以将单核阶段时间表示为 $t_A = 0.2 T(1)$，$t_B = 0.5 T(1)$ 和 $t_C = 0.3 T(1)$。\n\n对于每个阶段 $i$，有一部分 $p_i$ 是可并行的，一部分 $(1-p_i)$ 是串行的。根据问题陈述，串行部分的执行时间不随核心数 $N$ 改变，而可并行化部分的执行时间缩短为原来的 $1/N$。因此，阶段 $i$ 在 $N$ 个核心上的执行时间 $t_i(N)$ 为：\n$$t_i(N) = (1 - p_i)t_i + \\frac{p_i t_i}{N}$$\n\n在 $N$ 个核心上的总执行时间 $T(N)$ 是三个阶段在 $N$ 个核心上执行时间之和：\n$$T(N) = t_A(N) + t_B(N) + t_C(N)$$\n代入每个阶段的 $t_i(N)$ 表达式：\n$$T(N) = \\left((1 - p_A)t_A + \\frac{p_A t_A}{N}\\right) + \\left((1 - p_B)t_B + \\frac{p_B t_B}{N}\\right) + \\left((1 - p_C)t_C + \\frac{p_C t_C}{N}\\right)$$\n我们可以代入分数时间 $t_i = f_i T(1)$：\n$$T(N) = \\left((1 - p_A)f_A T(1) + \\frac{p_A f_A T(1)}{N}\\right) + \\left((1 - p_B)f_B T(1) + \\frac{p_B f_B T(1)}{N}\\right) + \\left((1 - p_C)f_C T(1) + \\frac{p_C f_C T(1)}{N}\\right)$$\n提取公因式 $T(1)$：\n$$T(N) = T(1) \\left[ \\left( f_A(1 - p_A) + \\frac{f_A p_A}{N} \\right) + \\left( f_B(1 - p_B) + \\frac{f_B p_B}{N} \\right) + \\left( f_C(1 - p_C) + \\frac{f_C p_C}{N} \\right) \\right]$$\n那么，总加速比 $S(N)$ 为：\n$$S(N) = \\frac{T(1)}{T(N)} = \\frac{1}{ \\left( f_A(1 - p_A) + \\frac{f_A p_A}{N} \\right) + \\left( f_B(1 - p_B) + \\frac{f_B p_B}{N} \\right) + \\left( f_C(1 - p_C) + \\frac{f_C p_C}{N} \\right) }$$\n通过对与 $N$ 无关的项和与 $1/N$ 成正比的项进行分组，可以重新整理此表达式：\n$$S(N) = \\frac{1}{ [f_A(1 - p_A) + f_B(1 - p_B) + f_C(1 - p_C)] + \\frac{1}{N}[f_A p_A + f_B p_B + f_C p_C] }$$\n现在，我们代入给定的数值：$f_A = 0.2$, $f_B = 0.5$, $f_C = 0.3$，以及 $p_A = 0.7$, $p_B = 0.9$, $p_C = 0.5$。\n\n首先，计算分母中与 $N$ 无关的部分（即总串行分数）：\n$$f_A(1 - p_A) + f_B(1 - p_B) + f_C(1 - p_C) = (0.2)(1 - 0.7) + (0.5)(1 - 0.9) + (0.3)(1 - 0.5)$$\n$$= (0.2)(0.3) + (0.5)(0.1) + (0.3)(0.5) = 0.06 + 0.05 + 0.15 = 0.26$$\n或者，使用分数计算：$\\frac{1}{5}(\\frac{3}{10}) + \\frac{1}{2}(\\frac{1}{10}) + \\frac{3}{10}(\\frac{1}{2}) = \\frac{3}{50} + \\frac{1}{20} + \\frac{3}{20} = \\frac{6}{100} + \\frac{5}{100} + \\frac{15}{100} = \\frac{26}{100}$。\n\n接下来，计算 $1/N$ 项的系数（即总可并行化分数）：\n$$f_A p_A + f_B p_B + f_C p_C = (0.2)(0.7) + (0.5)(0.9) + (0.3)(0.5)$$\n$$= 0.14 + 0.45 + 0.15 = 0.74$$\n或者，使用分数计算：$\\frac{1}{5}(\\frac{7}{10}) + \\frac{1}{2}(\\frac{9}{10}) + \\frac{3}{10}(\\frac{1}{2}) = \\frac{7}{50} + \\frac{9}{20} + \\frac{3}{20} = \\frac{14}{100} + \\frac{45}{100} + \\frac{15}{100} = \\frac{74}{100}$。\n\n将这些值代回 $S(N)$ 的表达式中：\n$$S(N) = \\frac{1}{0.26 + \\frac{0.74}{N}}$$\n为了得到一个简化的有理表达式，我们将分子和分母同乘以 $N$：\n$$S(N) = \\frac{N}{N(0.26 + \\frac{0.74}{N})} = \\frac{N}{0.26N + 0.74}$$\n为了用整数系数表示，我们可以将分子和分母同乘以 $100$：\n$$S(N) = \\frac{100N}{100(0.26N + 0.74)} = \\frac{100N}{26N + 74}$$\n这个分数可以通过将分子和分母同除以它们的最大公约数 $2$ 来简化：\n$$S(N) = \\frac{50N}{13N + 37}$$\n这就是整个工作负载的总加速比作为核心数 $N$ 的函数的最终封闭形式表达式。", "answer": "$$\\boxed{\\frac{50N}{13N + 37}}$$", "id": "3620142"}, {"introduction": "在性能测试中，我们偶尔会观察到“超线性加速”现象，即加速比超过了处理器核心数，这似乎违背了阿姆达尔定律的预测。这个练习[@problem_id:3620139]通过一个精心设计的思想实验来剖析这一现象，揭示其背后的真正原因——通常是由于数据划分带来的缓存局部性改善。通过这个案例，你将学会批判性地审视性能数据，并理解阿姆达尔定律成立的核心假设及其适用边界。", "problem": "一个程序使用固定的算法处理一个大型记录数组，该算法的控制流和数据访问不依赖于线程数。在一个双插槽中央处理器（CPU）的单核上，总运行时间为 $T_1 = 40$ 秒。对此单核运行的周期精确性能分析报告称，$T_1$ 的一部分（比例为 $f_s = 0.10$）是固有的串行部分（初始化、I/O设置以及一个无法并行的归约操作），而其余部分无需改变算法即可进行数据并行执行。该处理器有 $2$ 个插槽；每个插槽有 $8$ 个核心，并配有每插槽大小为 $16$ MiB 的私有末级缓存。动态随机存取存储器（DRAM）的延迟大约为 $100$ 纳秒，而末级缓存的命中延迟大约为 $12$ 纳秒。当程序在单核上运行时，其工作集约为 $24$ MiB，在末级缓存中表现出高未命中率，导致在单核基准测试中，可并行化部分主要受内存停顿的支配。\n\n现在，你使用 $N = 4$ 个线程运行完全相同的源代码，并将线程固定为每个插槽 $2$ 个线程（这样每个插槽大约处理一半的数据）。测得的并行运行时间为 $T_4 = 7.5$ 秒。假设同步开销可忽略不计且负载完全均衡。\n\n仅使用基本定义，如加速比的定义 $S(N) = T_1/T_N$，以及在单位操作成本固定下将运行时间分解为串行和可并行化部分，回答以下问题。哪个选项最能解释为什么测得的加速比超过了将串行/并行分解应用于单核性能分析所预测的值，以及为什么在排除局部性带来的改进后，理想并行性的基本界限仍然适用？\n\nA. 根据单核串行部分的预测加速比约为 $3.08$，而测得的加速比为 $S(4) = 40/7.5 \\approx 5.33$。这种明显的“超线性”行为的出现，是因为将数据划分到不同插槽上，使得每个插槽的工作集从 $24$ MiB 减少到 $12$ MiB，现在可以完全放入 $16$ MiB 的末级缓存中，从而相对于单核基准，大大减少了可并行化部分的内存停顿时间。如果我们保持局部性不变，Amdahl 的理想并行性界限仍然适用：例如，通过在单核基准上使用同样对缓存友好的分块遍历（或者通过扩展问题规模，使得每个插槽的工作集再次超过末级缓存），我们消除了局部性优势，回到了一个最大加速比仅由串行部分限制的范畴。\n\nB. 预测的加速比约为 $3.08$，但测得的加速比 $5.33$ 证明了 Amdahl 定律在带缓存的现代硬件上是错误的。因为缓存是机器的一部分，对于固定的问题规模，随着 $N$ 的增加，加速比没有有意义的上限。\n\nC. 根据单核串行部分的预测加速比过于悲观，因为由于线程间内存延迟的重叠，串行部分本身会随着 $N$ 的增长而减小。如果我们将 $f_s$ 替换为 $f_s/N$，预测将与测量结果相匹配，因此不存在不一致性，缓存局部性也没有特殊作用。\n\nD. 观察到的结果是弱扩展（weak scaling）的一个实例。通过引用 Gustafson 定律，加速比可以合法地超过 Amdahl 的预测和处理器数量，因此不需要涉及缓存效应或排除局部性增益的额外解释。\n\nE. 随着核心数量的增加，总缓存容量的增加在数学上即使在固定问题规模下也会增加并行部分的比例，因此 Amdahl 定律直接允许加速比大于根据单核串行部分预测的值，而无需改变任何假设或基准；不需要对局部性进行特殊处理。", "solution": "我们从基本定义开始。对于 $N$ 个处理单元，加速比定义为\n$$\nS(N) \\equiv \\frac{T_1}{T_N}.\n$$\n设单线程运行时间分解为 $T_1 = T_s + T_p$，其中 $T_s$ 是在固有串行代码中花费的时间，而 $T_p$ 是在单位操作成本固定的情况下可并行化代码中花费的时间。串行部分比例定义为\n$$\nf_s \\equiv \\frac{T_s}{T_1}, \\quad 0 \\le f_s \\le 1.\n$$\n如果可并行化部分在 $N$ 个线程上理想地扩展，而不改变每单位工作的成本，那么在这些固定成本假设下的并行运行时间为\n$$\nT_N = T_s + \\frac{T_p}{N} = f_s T_1 + \\frac{(1-f_s) T_1}{N},\n$$\n这意味着从定义中可以得到众所周知的加速比界限：\n$$\nS(N) = \\frac{T_1}{T_N} = \\frac{1}{f_s + \\frac{1-f_s}{N}}.\n$$\n这个界限基于一个前提，即可并行化区域的单位操作成本不因并行化行为而改变；它只考虑了并发对可并行化部分墙上时间（wall time）的影响。\n\n计算由单核串行部分预测的加速比和测得的加速比。给定 $T_1 = 40$ 秒和 $f_s = 0.10$。当 $N = 4$ 时，\n$$\nS_{\\text{pred}}(4) = \\frac{1}{0.10 + \\frac{0.90}{4}} = \\frac{1}{0.10 + 0.225} = \\frac{1}{0.325} \\approx 3.0769.\n$$\n测得的并行运行时间为 $T_4 = 7.5$ 秒，所以测得的加速比是\n$$\nS_{\\text{meas}}(4) = \\frac{40}{7.5} \\approx 5.3333,\n$$\n这超过了 $S_{\\text{pred}}(4)$ 和处理器数量 $N = 4$（一个“超线性”加速比）。为什么会发生这种情况而与上面推导出的界限不矛盾呢？\n\n该界限假设可并行化部分的单位操作成本不因并行化而改变。在给定的机器和工作负载下，单核基准在一个插槽上处理一个 $24$ MiB 的工作集，而该插槽只有一个 $16$ MiB 的末级缓存。因为 $24$ MiB $> 16$ MiB，末级缓存无法容纳整个工作集，导致高未命中率和频繁的动态随机存取存储器（DRAM）访问，其延迟在 $100$ 纳秒量级。并行运行使用 $N = 4$ 个线程，每个插槽固定 $2$ 个。数据被分区，因此每个插槽大约处理 $12$ MiB。现在 $12$ MiB $< 16$ MiB，所以每个插槽的工作集都能放入其末级缓存中，使得大多数内存访问的延迟减少到大约 $12$ 纳秒。因此，与单线程基准相比，可并行化部分的单位操作成本显著下降。这一变化违反了上述推导中的固定成本假设，最好被解释为局部性的改善，而非纯粹的并行性。结果是，$T_p$ 本身在并行化时缩短了，这使得测得的 $S(4)$ 能够超过在固定成本假设下计算出的界限。\n\n为什么在排除局部性增益后，理想并行性的基本界限仍然适用？如果我们在比较中保持局部性恒定——通过确保单核基准享有与并行运行相同的缓存行为，或者等效地，确保并行运行相对于单核基準不改变未命中率——那么单位操作成本就不会改变，上述推导就适用。有两种等效的方法来强制实现这一点：\n- 在单核基准上使用同样对缓存友好的遍历方式（例如，分块或域分解），使其在可并行化区域的工作集也能放入末级缓存，从而匹配并行执行的局部性；或者\n- 扩展问题规模，使得即使在跨插槽分区后，每个插槽的工作集仍然超过末级缓存（等局部性或等未命中率设置），从而防止在并行情况下单位操作成本下降。\n\n在这种等局部性条件下，从 $T_1$ 到 $T_N$ 的运行时间变化仅由并发引起，加速比受以下公式限制：\n$$\nS(N) = \\frac{1}{f_s + \\frac{1-f_s}{N}},\n$$\n其中 $f_s$ 是在具有相同局部性的基准上测量的。因此，在原始测量中观察到的“额外”加速比可归因于局部性的改善（减少了内存停顿时间），而不是对理想并行性界限的违背；它反映了一个不同的成本模型，而不是串行/并行分解的失效。\n\n逐项分析：\n- 选项 A 陈述了数值比较 $S_{\\text{pred}}(4) \\approx 3.08$ 与 $S_{\\text{meas}}(4) \\approx 5.33$，指出了其机制（数据分区将每个插槽的工作集减少到 $12$ MiB，可以放入 $16$ MiB 的末级缓存，从而减少了内存停顿时间），并正确解释了当通过使单核基准同样具有缓存友好性或确保并行运行不改变未命中率来保持局部性恒定时，Amdahl 的界限仍然适用。这是正确的。\n- 选项 B 声称 Amdahl 定律在现代硬件上是错误的，并且对于固定规模的问题没有有意义的上限。这误解了情况：该界限是在单位操作成本固定的前提下推导出来的，观察到的超额加速比是由于局部性导致的单位操作成本变化，而非纯粹的并行性。这是不正确的。\n- 选项 C 断言串行部分比例 $f_s$ 随着 $N$ 的增长而减小，因为线程间的内存延迟被重叠，实际上是将 $f_s$ 替换为 $f_s/N$。串行部分比例指的是固有不可并行化的工作；可并行化区域中的内存延迟重叠不会将串行工作转化为并行工作。这是一个建模错误。这是不正确的。\n- 选项 D 引用了弱扩展和 Gustafson 定律，但该实验是强扩展（strong scaling），问题规模固定（单核上 $T_1 = 40$ 秒对比四线程上 $T_4 = 7.5$ 秒）。Gustafson 定律不能解释固定问题规模下的超线性加速比，也无法免除对缓存效应的考虑。这是不正确的。\n- 选项 E 暗示总缓存容量的增加直接且“数学上”增加了并行部分的比例，因此 Amdahl 定律直接允许加速比大于根据单核串行部分预测的值，而无需改变任何假设或基准；不需要对局部性进行特殊处理。这是不正确的。\n\n因此，唯一正确的选项是 A。", "answer": "$$\\boxed{A}$$", "id": "3620139"}]}