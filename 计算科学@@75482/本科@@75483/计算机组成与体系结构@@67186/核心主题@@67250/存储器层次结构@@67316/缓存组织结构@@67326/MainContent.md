## 引言
在现代[计算机体系结构](@entry_id:747647)中，处理器速度的飞速增长与主存储器（[主存](@entry_id:751652)）访问延迟的相对停滞形成了一道日益扩大的“性能鸿沟”。为了弥合这一差距，设计者引入了高速、小容量的缓存存储器（Cache Memory），它作为处理器与主存之间的[缓冲层](@entry_id:160164)，存储着最可能被再次访问的数据。对缓存[组织结构](@entry_id:146183)的深刻理解，是掌握计算机系统[性能优化](@entry_id:753341)、编写高效代码乃至洞察系统安全漏洞的关键所在。

本文旨在系统性地剖析缓存[组织结构](@entry_id:146183)的原理、机制及其在现实世界中的广泛影响。我们将从核心的理论基础出发，逐步扩展到跨学科的应用实践。
- 在 **“原理与机制”** 一章中，我们将解构缓存的内部工作方式，从地址如何映射到缓存行，到相联度如何解决冲突，再到写策略和替换策略如何影响性能。
- 接着，在 **“应用与跨学科联系”** 一章中，我们将探讨这些原理如何具体体现在算法设计、高性能计算、[操作系统](@entry_id:752937)乃至系统安全等多个领域，展示理论知识的实践价值。
- 最后，**“动手实践”** 部分提供了一系列精心设计的练习，旨在通过解决实际问题，将你的理论知识转化为可操作的技能。

通过这趟学习之旅，你将构建起一个关于缓存如何设计、运行以及如何围绕其进行优化的完整知识体系。

## 原理与机制

在“引言”章节中，我们已经确立了缓存作为弥合处理器速度与主存延迟之间差距的关键角色。本章将深入探讨缓存工作的核心原理与机制。我们将从单个缓存的组织结构开始，剖析地址如何映射到缓存位置，然后扩展到多级[缓存层次结构](@entry_id:747056)中的复杂交互，并探讨与虚拟内存系统结合时出现的精妙问题。本章的目标是构建一个关于缓存如何设计、如何运行以及其设计选择如何影响整体系统性能的坚实理论基础。

### 缓存的[基本组织](@entry_id:136556)：[地址映射](@entry_id:170087)

计算机系统中的每个字节都有一个唯一的物理地址。当处理器请求某个地址的数据时，缓存硬件必须迅速判断该数据是否存在于缓存中。为了实现这一点，物理地址被划分为三个不同的字段：**标签（Tag）**、**索引（Index）**和**块偏移（Block Offset）**。理解这三个字段是掌握缓存工作原理的第一步。

让我们考虑一个具有以下参数的[组相联缓存](@entry_id:754709)：
- 总数据容量为 $C$ 字节。
- 每个缓存块（或称缓存行）的大小为 $B$ 字节。
- 相联度为 $E$，表示每个组（set）包含 $E$ 个缓存块。

这些参数决定了缓存的内部结构。缓存被组织成 $S$ 个组，其中组的总数可以通过以下基本关系得出：总容量等于组数乘以每组的块数再乘以每个块的大小。

$C = S \times E \times B$

因此，我们可以推导出组数 $S$ 的表达式：

$S = \frac{C}{E \times B}$

现在，我们可以分析一个 $w$ 位的物理地址如何被分解：

1.  **块偏移（Block Offset）**：这个字段用于在缓存块内部定位一个特定的字节。由于每个块包含 $B$ 字节，我们需要足够的位数来寻址这 $B$ 个字节。因此，偏移字段的位数 $o$ 由 $2^o = B$ 决定。通过取以2为底的对数，我们得到：
    $o = \log_2(B)$

2.  **索引（Index）**：这个字段用于选择 $S$ 个组中的某一个。为了唯一地标识 $S$ 个组，索引字段的位数 $i$ 必须满足 $2^i = S$。因此：
    $i = \log_2(S) = \log_2\left(\frac{C}{E \times B}\right)$

3.  **标签（Tag）**：地址中剩余的位构成了标签。当索引字段选定一个组后，该组中的 $E$ 个块都有可能存储着所需的数据。标签的作用就是区分这些可能映射到同一个组的不同主存块。标签与缓存中存储的[元数据](@entry_id:275500)进行比较，以确认是否命中。标签字段的位数 $t$ 是总地址位数减去索引和偏移位数：
    $t = w - i - o$

这个地址分解的过程是所有缓存操作的基础。当处理器发出一个内存请求时，硬件会同时使用地址的这三个部分：索引位指向一个特定的组；然后，该组中所有 $E$ 个有效缓存行的标签将与请求地址的标签位进行并行比较；如果某个标签匹配，即为**缓存命中（cache hit）**，相应的块偏[移位](@entry_id:145848)将用于从该缓存块中选择并返回所需的数据。如果该组中没有标签匹配，则发生**缓存未命中（cache miss）**，需要从下一级存储（如L2缓存或主存）中获取数据。

让我们通过一个具体的例子来巩固这些概念 [@problem_id:3624602]。假设一个系统使用48位物理地址（$w=48$），其[数据缓存](@entry_id:748188)容量为512 KiB（$C = 2^{19}$ 字节），块大小为64字节（$B = 2^6$ 字节），相联度为8路（$E = 2^3$）。

首先，计算组数 $S$：
$S = \frac{C}{E \times B} = \frac{2^{19}}{2^3 \times 2^6} = \frac{2^{19}}{2^9} = 2^{10} = 1024$

接下来，计算各字段的位数：
- 偏移位数 $o = \log_2(B) = \log_2(2^6) = 6$ 位。
- 索引位数 $i = \log_2(S) = \log_2(2^{10}) = 10$ 位。
- 标签位数 $t = w - i - o = 48 - 10 - 6 = 32$ 位。

因此，一个48位的地址将被分解为一个32位的标签，一个10位的索引和一个6位的偏移。

设计参数的改变会影响这种划分。例如，如果我们保持 $C$ 和 $E$ 不变，但将块大小加倍至128字节（$B' = 2^7$ 字节），新的组数 $S'$ 会减半：
$S' = \frac{C}{E \times B'} = \frac{2^{19}}{2^3 \times 2^7} = 2^9 = 512$

这将导致偏[移位](@entry_id:145848)数增加1位（$o' = 7$），而索引位数减少1位（$i' = 9$）。这种权衡关系是缓存设计中的一个核心主题：增加块大小可以更好地利用空间局部性，但也可能因为需要的块更少而减少索引空间，同时增加了未命中时传输数据所需的时间（即未命中惩罚）。

### 相联度的作用：管理缓存冲突

[地址映射](@entry_id:170087)机制揭示了一种潜在的性能问题：如果多个频繁使用的主存块恰好映射到同一个缓存组，它们将会相互驱逐，即使缓存的其他部分可能还有大量空闲空间。这种现象称为**[冲突未命中](@entry_id:747679)（conflict miss）**。**相联度（associativity）**是解决这一问题的关键设计杠杆。

相联度 $E$ 定义了每个组可以容纳多少个缓存块。其范围从 $E=1$（**[直接映射缓存](@entry_id:748451)**）到 $E = C/B$（**[全相联缓存](@entry_id:749625)**）不等。

-   在**[直接映射缓存](@entry_id:748451)**中，每个[主存](@entry_id:751652)块只能映射到唯一的一个缓存位置。这大大简化了硬件设计（无需选择替换哪个块，也无需复杂的标签比较逻辑），但它对[冲突未命中](@entry_id:747679)最为敏感。
-   在**[全相联缓存](@entry_id:749625)**中，任何[主存](@entry_id:751652)块可以存放在缓存中的任何位置。这消除了所有[冲突未命中](@entry_id:747679)，因为只要缓存有空闲位置，块就不会因为索引冲突而被驱逐。然而，硬件实现成本极高，因为每次访问都需要将请求的标签与缓存中所有块的标签进行比较。
-   **[组相联缓存](@entry_id:754709)**是上述两种极端情况的折中，它将缓存分为 $S$ 个组，每个组包含 $E$ 个块。一个主存块映射到一个特定的组，但可以在该组的 $E$ 个位置中自由存放。

让我们通过一个极端的例子来展示相联度的威力 [@problem_id:3624672]。考虑一个访问模式，其步长（stride）恰好等于缓存的总容量 $C$。假设我们循环访问四个不同的块地址：$a_0, a_0+C, a_0+2C, a_0+3C$。根据我们的索引计算公式 $i = (\lfloor A/B \rfloor) \bmod S$，可以证明，当步长为 $C$ 的整数倍时，所有这些地址都会映射到同一个组。

如果缓存是直接映射的（$E=1$），那么每个组只有一个缓存行。访问序列会发生以下情况：
1.  访问 $a_0$：未命中，加载 $a_0$。
2.  访问 $a_0+C$：冲突！$a_0+C$ 映射到同一位置，驱逐 $a_0$ 并加载 $a_0+C$。
3.  访问 $a_0+2C$：冲突！驱逐 $a_0+C$。
4.  访问 $a_0+3C$：冲突！驱逐 $a_0+2C$。
5.  访问 $a_0$：冲突！驱逐 $a_0+3C$。

在这个场景下，每次访问都是一次[冲突未命中](@entry_id:747679)，未命中率高达100%，尽管缓存的容量可能远大于这四个块的总和。这种现象称为**缓存[抖动](@entry_id:200248)（cache thrashing）**。

现在，让我们将相联度提高到 $E=4$。这四个块仍然映射到同一个组，但该组现在有四个位置可以容纳它们。
1.  访问 $a_0$：未命中（[强制性未命中](@entry_id:747599)），加载 $a_0$。组内包含 $\{a_0\}$。
2.  访问 $a_0+C$：未命中（[强制性未命中](@entry_id:747599)），加载 $a_0+C$。组内包含 $\{a_0, a_0+C\}$。
3.  访问 $a_0+2C$：未命中（[强制性未命中](@entry_id:747599)），加载 $a_0+2C$。组内包含 $\{a_0, a_0+C, a_0+2C\}$。
4.  访问 $a_0+3C$：未命中（[强制性未命中](@entry_id:747599)），加载 $a_0+3C$。组内包含 $\{a_0, a_0+C, a_0+2C, a_0+3C\}$。

在最初的四次[强制性未命中](@entry_id:747599)之后，所有四个块都已驻留在缓存中。由于该组的容量（4个块）正好等于[工作集](@entry_id:756753)的大小（4个块），后续的所有访问都将是命中。对于一个包含64次访问的轨迹，总共只有4次未命中，未命中率降至 $4/64 = 1/16$。这个例子戏剧性地说明了相联度是如何通过为冲突块提供额外的“着陆区”来显著降低[冲突未命中](@entry_id:747679)率的。

### 替换策略：选择一个“牺牲品”

当一个[组相联缓存](@entry_id:754709)的组已满，并且此时发生了一次未命中，缓存控制器必须选择该组中的一个现有块来驱逐，以便为新块腾出空间。这个决策过程由**替换策略（replacement policy）**控制。

两种最常见的替换策略是：

-   **[最近最少使用](@entry_id:751225)（Least Recently Used, LRU）**：该策略驱逐在最长时间内未被访问过的块。其基本思想是，最近被访问过的块很可能在不久的将来再次被访问（[时间局部性](@entry_id:755846)），因此应该保留。LRU通常能提供很好的性能，但实现起来较为复杂，因为它需要在每次命中时更新每个组内所有块的“年龄”信息。

-   **先进先出（First-In, First-Out, FIFO）**：该策略驱逐最早进入该组的块，无论其最近是否被访问过。FIFO的实现非常简单，通常只需要一个指向“最老”块的指针。然而，它的性能可能不稳定，因为它可能会驱逐一个刚刚被加载但之后会频繁使用的块。

这两种策略的行为差异虽然微妙，但至关重要。我们可以通过一个精心设计的访问序列来揭示这种差异 [@problem_id:3624641]。考虑一个2路[组相联缓存](@entry_id:754709)（$E=2$）和一个访问序列 $\langle a, b, a, c, a \rangle$，其中所有块都映射到同一个组。

1.  $\langle a, b \rangle$：两次未命中，缓存组被填满，内容为 $\{a, b\}$。对于LRU，访问顺序是 $b$ (最新), $a$ (最旧)。对于FIFO，加载顺序是 $a$ (最早), $b$ (最晚)。
2.  $\langle a \rangle$：命中。对于LRU，这会更新 $a$ 为最新访问的块，访问顺序变为 $a$ (最新), $b$ (最旧)。对于FIFO，命中不影响其加载顺序，状态不变。
3.  $\langle c \rangle$：未命中，需要替换。
    -   **LRU**：选择[最近最少使用](@entry_id:751225)的块 $b$ 进行替换。组内容变为 $\{a, c\}$。
    -   **FIFO**：选择先进先出的块 $a$ 进行替换。组内容变为 $\{b, c\}$。
    此时，两种策略下的缓存内容已经发生了[分歧](@entry_id:193119)。
4.  $\langle a \rangle$：最后一次访问。
    -   **LRU**：组内有 $a$，因此是**命中**。
    -   **FIFO**：组内没有 $a$，因此是**未命中**。

这个长度为5的访问序列是能够区分这两种策略的最短序列。它清晰地展示了LRU如何适应访问模式的变化，而FIFO则机械地遵循加载时间。

### 写策略：处理数据修改

到目前为止，我们主要关注于读操作。当处理器执行写操作时，情况变得更加复杂。缓存必须决定何时以及如何将修改后的数据更新到[主存](@entry_id:751652)中。这由**写策略（write policy）**决定。

主要的写策略有两种：

-   **写直通（Write-Through）**：每次写操作都会同时更新缓存和主存（或下一级缓存）。这种方法的优点是简单，且能保证[主存](@entry_id:751652)始终拥有最新数据，这简化了[多处理器系统](@entry_id:752329)中的一致性问题。其缺点是每次写操作都会引起总线流量，并可能导致处理器等待写操作完成，从而降低性能。

-   **[写回](@entry_id:756770)（Write-Back）**：写操作只更新缓存中的数据块。为了追踪哪些块已被修改，每个缓存行都有一个额外的**[脏位](@entry_id:748480)（dirty bit）**。当一个“脏”块（即被修改过的块）被驱逐时，它才会被[写回](@entry_id:756770)主存。这种策略显著减少了总线流量，因为一个块可能在被驱逐前被多次写入，但只需要一次写回操作。这通常能带来更好的性能，但实现起来更复杂，并且在[多处理器系统](@entry_id:752329)中需要更复杂的一致性协议。

与写策略相关的是**[写分配](@entry_id:756767)策略（write allocation policy）**。当发生写未命中时：
-   **[写分配](@entry_id:756767)（Write-Allocate）**：在写入前，先将相应的块从主存加载到缓存中。这种策略通常与[写回](@entry_id:756770)策略配合使用，因为它利用了写操作通常伴随着读操作的[空间局部性](@entry_id:637083)。
-   **非[写分配](@entry_id:756767)（No-Write-Allocate）**：也称为**写绕过（write-around）**，写操作直接更新[主存](@entry_id:751652)，而不将块加载到缓存中。这通常与写直通策略配合使用，以避免因写操作而污染缓存。

我们可以通过计算**[平均内存访问时间](@entry_id:746603)（Average Memory Access Time, AMAT）**来量化不同写策略的性能影响 [@problem_id:3624658]。AMAT的基本公式是：

$AMAT = \text{命中时间} + \text{未命中率} \times \text{未命中惩罚}$

然而，对于写操作，我们需要更精细地分解各项成本。假设一个系统中，命中时间为2个周期，读写总未命中率为5%，写操作占所有访问的30%。从主存获取一个块需要38个周期，而写回一个脏块同样需要38个周期。在写直通策略下，单次写操作到主存需要31个周期。

-   对于**[写回](@entry_id:756770)**缓存（假设40%的被驱逐块是脏的）：
    内存活动只在未命中时发生。未命中时，需要获取新块（成本38周期）。此外，如果被替换的块是脏的，还需要一次[写回](@entry_id:756770)（额外成本38周期）。
    $AMAT_{WB} = \text{命中时间} + (\text{未命中率} \times \text{取块惩罚}) + (\text{未命中率} \times \text{脏块概率} \times \text{写回惩罚})$
    $AMAT_{WB} = 2 + (0.05 \times 38) + (0.05 \times 0.4 \times 38) = 2 + 1.9 + 0.76 = 4.66$ 周期。

-   对于**写直通**缓存（无[写缓冲](@entry_id:756779)）：
    每次未命中都需要取块（成本38周期）。此外，每次写操作（无论命中与否）都需要访问主存（成本31周期）。
    $AMAT_{WT} = \text{命中时间} + (\text{未命中率} \times \text{取块惩罚}) + (\text{写操作比例} \times \text{写直通惩罚})$
    $AMAT_{WT} = 2 + (0.05 \times 38) + (0.3 \times 31) = 2 + 1.9 + 9.3 = 13.2$ 周期。

这个计算清晰地表明，尽管写回策略更复杂，但在这种典型的参数下，它通过显著减少对[主存](@entry_id:751652)的写访问次数，提供了远优于写直通策略的性能。$\text{AMAT}_{WT} - \text{AMAT}_{WB} = 8.54$ 周期，这是一个巨大的差异。

### 缓存[性能优化](@entry_id:753341)

除了通过调整相联度和写策略来提升性能外，还有许多其他技术可以用来降低未命中率或减少未命中惩罚。

#### 降低未命中惩罚

当未命中发生时，处理器通常会停顿，等待数据从慢速的[主存](@entry_id:751652)中传来。减少这种[停顿](@entry_id:186882)时间对性能至关重要。
标准块传输过程是按顺序从块的起始地址开始发送数据。但处理器通常只需要块中的一个特定字（word）。

-   **提前重启（Early Restart）**：一旦请求的字到达，处理器就立即恢复执行，而块的其余部分在后台继续传输。
-   **关键宇优先（Critical-Word-First）**：这是一种更积极的策略。[内存控制器](@entry_id:167560)被指示首先获取并发送请求的“关键宇”，然后再以环绕的方式传输块的其余部分。

让我们量化这些技术带来的好处 [@problem_id:3624669]。假设一个缓存块包含8个字（$L=8$），获取第一个字的延迟为24个周期（$t_s=24$），之后每2个周期到达一个新字（$t_b=2$）。请求的字在块内的位置 $j \in \{0, 1, ..., 7\}$ 是[均匀分布](@entry_id:194597)的。

-   对于**提前重启**，字的到达时间是 $t_s + j \cdot t_b$。平均[停顿](@entry_id:186882)时间是所有可能位置的[停顿](@entry_id:186882)时间的[期望值](@entry_id:153208)：
    $E[S_{ER}] = t_s + t_b \frac{L-1}{2} = 24 + 2 \times \frac{7}{2} = 31$ 周期。

-   对于**关键宇优先**，请求的字总是第一个到达，因此[停顿](@entry_id:186882)时间恒定为初始延迟 $t_s$：
    $E[S_{CWF}] = t_s = 24$ 周期。

通过采用关键宇优先策略，平均[停顿](@entry_id:186882)时间减少了 $31 - 24 = 7$ 个周期。这表明，通过优化内存总线上的[数据传输](@entry_id:276754)顺序，可以有效地隐藏部分未命中惩罚，从而提升系统性能。

#### 降低未命中率

除了增加相联度，还可以通过其他硬件机制来减少[冲突未命中](@entry_id:747679)。**牺牲缓存（Victim Cache）**就是一个典型的例子。它是一个小型的、通常是全相联的缓存，位于L1缓存和下一级存储之间。它的作用是“接住”从L1缓存中被驱逐出去的块。

其工作机制如下 [@problem_id:3624630]：
1.  当L1缓存未命中时，首先查询牺牲缓存。
2.  如果牺牲缓存命中，说明该块最近刚被从L1驱逐。此时，将该块与L1中驱逐它的块进行交换。这次操作非常快，避免了对主存的访问。
3.  如果牺牲缓存也未命中，则从[主存](@entry_id:751652)中获取新块。新块被放入L1，而被L1驱逐的块则被放入牺牲缓存。

考虑一个导致直接映射L1缓存发生100%[冲突未命中](@entry_id:747679)的访问模式（如前述的步长访问）。如果没有牺牲缓存，未命中率是1。现在，我们增加一个大小为 $V$ 的牺牲缓存来处理一个由 $V+1$ 个冲突块组成的访问序列。

-   在第一轮访问中，所有 $V+1$ 次访问都会在L1和牺牲缓存中未命中，导致[强制性未命中](@entry_id:747599)。这些块被逐一加载到L1，然后被驱逐到牺牲缓存中。在第一轮结束时，L1中有一个块，牺牲缓存中有其余 $V$ 个块。
-   从第二轮开始，每次访问都会在L1中未命中，但会在牺牲缓存中命中。这会将一次代价高昂的主存访问转变为一次快速的L1与牺牲缓存的块交换。

因此，在稳定状态下（$r \ge 2$ 轮访问后），系统的未命中率（需要访问[主存](@entry_id:751652)的比例）从1急剧下降到 $1/r$。例如，仅在两轮访问后（$r=2$），未命中率就降至50%。这表明，牺牲缓存是一种高效的硬件机制，可以用很小的成本显著缓解[冲突未命中](@entry_id:747679)问题。

### 缓存组织的高级主题

现代[处理器架构](@entry_id:753770)中的缓存设计涉及与系统其他部分的复杂交互，尤其是[虚拟内存](@entry_id:177532)和多级[缓存层次结构](@entry_id:747056)。

#### 虚拟索引物理标签（VIPT）缓存与别名问题

为了缩短L1缓存的命中延迟，现代处理器普遍采用**虚拟索[引物](@entry_id:192496)理标签（Virtually Indexed, Physically Tagged, VIPT）**设计。这种设计允许系统使用虚拟地址的索引部分来查找缓存组，与此同时，[地址转换](@entry_id:746280)后备缓冲器（TLB）将[虚拟地址转换](@entry_id:756527)为物理地址。然后，使用转换后的物理地址的标签部分与缓存中找到的标签进行比较。这种并行操作避免了“先TLB查找，再缓存访问”的串行延迟。

然而，VIPT设计引入了一个严重的正确性问题，称为**别名（aliasing）**或**同义词（synonym）**问题。在[虚拟内存](@entry_id:177532)系统中，多个不同的虚拟地址可能映射到同一个物理地址。如果这些虚拟地址“[别名](@entry_id:146322)”在[VIPT缓存](@entry_id:756503)中映射到不同的组，那么同一个物理[数据块](@entry_id:748187)就可能在缓存中存在多个副本，这会导致数据不一致。

为了确保[VIPT缓存](@entry_id:756503)的正确性，必须保证所有映射到同一物理地址的虚拟[地址别名](@entry_id:171264)都访问同一个缓存组。由于物理地址和虚拟地址共享相同的**页偏移（page offset）**位，这是[地址转换](@entry_id:746280)过程中唯一不变的部分。因此，解决方案是确保用于计算缓存索引的所有位都完全来自页偏移。这导出了一个基本的约束条件 [@problem_id:3624628]：

$S \times B \le \text{页面大小}$

即，（组数 $\times$ 块大小）所覆盖的地址空间不能超过一个物理页的大小。换句话说，用于索引和块偏移的总位数不能超过页偏移的位数：$\log_2(S) + \log_2(B) \le \log_2(P)$。

如果违反了这个约束，例如，在一个页面大小为4096字节（$12$位页偏移），缓存块大小为64字节（$6$位块偏移），但有256个组（$8$位索引）的系统中，用于索引的位（地址位6到13）超出了页偏移的范围（地址位0到11）。具体来说，索引位12和13来自虚拟页号（VPN），而不是页偏移。这意味着[操作系统](@entry_id:752937)可以将两个虚拟地址（例如 $0x1000$ 和 $0x2000$）映射到同一个物理页，但由于它们的第12位不同，它们会在[VIPT缓存](@entry_id:756503)中索引到不同的组，从而产生[别名](@entry_id:146322)问题 [@problem_id:3624670] [@problem_id:3624628]。在这种特定配置下，由于有2个索引位来自VPN，同一个物理块可能因[别名](@entry_id:146322)而出现在 $2^2=4$ 个不同的缓存组中。

为了在保持VIPT性能优势的同时解决[别名](@entry_id:146322)问题并改善索引[分布](@entry_id:182848)（减少冲突），可以采用更复杂的**分岸相联缓存（banked-associative cache）**设计。其核心思想是 [@problem_id:3624579]：
1.  使用虚拟地址中位于页偏移内的位进行初步的组索引，这保证了所有[别名](@entry_id:146322)都将访问同一个组。
2.  在TLB返回物理地址后，使用物理地址的高位（来自物理页号）进行一次哈希计算，以选择该组内的特定“岸（bank）”或“路（way）”。
这种两阶段访问方式既保证了正确性（最终决策基于物理地址），又通过哈希物理地址高位来打乱访问模式，减少了冲突，同时保留了VIPT大部分的并行性优势。

#### [多级缓存](@entry_id:752248)与包含/排除策略

现代系统通常采用多级[缓存层次结构](@entry_id:747056)（如L1, L2, L3）。L1缓存小而快，L2缓存更大但稍慢。如何管理这两级缓存之间的关系，对性能有重要影响。主要有两种策略：**包含策略（inclusive）**和**排除策略（exclusive）**。

-   **包含策略**：要求L2缓存必须是L1缓存的超集。也就是说，任何存在于L1中的块也必须存在于L2中。这种策略的优点是简化了多核系统中的一致性维护，因为检查L2就可以知道一个块是否存在于L1。但其缺点是**[有效容量](@entry_id:748806)（effective capacity）**受限于L2的大小。当一个块从L2被驱逐时，也必须从L1中驱逐（如果存在的话）。

-   **排除策略**：要求L1和L2缓存中的内容是[互斥](@entry_id:752349)的。一个块要么在L1，要么在L2，但不能同时存在。这种策略的优点是最大化了**[有效容量](@entry_id:748806)**，其总容量为 $C_{L1} + C_{L2}$。缺点是块在L1和L2之间移动的逻辑更复杂，例如L1未命中但在L2命中时，可能需要进行块交换。

这两种策略的性能差异在处理大型工作集时表现得尤为明显 [@problem_id:3624629]。假设一个工作集的大小（由重用距离 $M$ 表征）为4300个块，而L1容量为512个块，L2容量为4096个块。

-   在**包含**策略下，[有效容量](@entry_id:748806)是L2的容量，即4096个块。由于 $M=4300 > 4096$，工作集无法完全装入[缓存层次结构](@entry_id:747056)。在稳定状态下，每次访问都将导致L2[容量未命中](@entry_id:747112)，需要访问主存。AMAT会非常高，例如，计入所有延迟和L1驱逐时发送的包含目录失效消息的开销后，可能高达137个周期。

-   在**排除**策略下，[有效容量](@entry_id:748806)是 $C_{L1} + C_{L2} = 512 + 4096 = 4608$ 个块。由于 $M=4300  4608$，整个[工作集](@entry_id:756753)可以完全容纳在L1和L2中。在稳定状态下，不会有访问主存的[容量未命中](@entry_id:747112)。每次访问虽然会在L1中未命中（因为 $M > C_{L1}$），但总会在L2中命中。其AMAT主要由L1未命中、L2命中的延迟决定，例如，计入块交换开销后可能只有18个周期。

这个例子表明，在工作集大小介于L2容量和L1+L2总容量之间时，排除策略能提供巨大的性能优势。这使得设计者必须根据预期的工作负载特性来仔细权衡包含与排除策略。

#### 物理现实：存储开销

最后，我们必须认识到，缓存不仅仅是存储数据的阵列。为了实现上述所有功能，还需要大量的**[元数据](@entry_id:275500)（metadata）**，这些元数据同样占用宝贵的芯片面积和功耗。每个缓存行除了存储 $B$ 字节的数据外，还至少需要 [@problem_id:3624580]：
-   $t$ 位的**标签**。
-   1位的**有效位（valid bit）**，指示该行数据是否有效。
-   1位的**[脏位](@entry_id:748480)（dirty bit）**（对于[写回缓存](@entry_id:756768)）。

此外，每个组还需要额外的位来维护替换策略的状态，例如LRU策略需要 $m(E)$ 位。

总的SRAM容量是数据存储和所有这些开销存储的总和。非数据存储（开销）所占的比例可以表示为：

$F = \frac{\text{总开销存储}}{\text{总数据存储} + \text{总开销存储}} = \frac{SE(t + 2) + Sm(E)}{8SEB + SE(t + 2) + Sm(E)}$

通过约去公共因子 $S$，我们得到一个更通用的表达式，它揭示了每个组内部的存储分配情况：

$F = \frac{E(t + 2) + m(E)}{8EB + E(t + 2) + m(E)}$

这个公式提醒我们，缓存设计中的每一个决定，从地址位数（影响 $t$）到相联度（影响 $E$ 和 $m(E)$），再到块大小（影响 $B$），都伴随着实际的硬件成本。一个高性能的缓存设计总是在算法的复杂性、性能的提升和物理实现的开销之间寻求最佳的[平衡点](@entry_id:272705)。