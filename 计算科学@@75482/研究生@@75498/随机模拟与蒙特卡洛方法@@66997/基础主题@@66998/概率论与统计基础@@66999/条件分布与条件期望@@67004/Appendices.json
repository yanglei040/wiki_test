{"hands_on_practices": [{"introduction": "掌握从联合分布推导条件分布是概率论中的一项基本功。这个练习将带你从最基本的定义出发，为在统计学中无处不在的二元正态分布推导其条件密度和条件期望。通过这个推导，你不仅能加深对条件概率密度定义 $f_{X|Y}(x|y) = f_{X,Y}(x,y) / f_Y(y)$ 的理解，还能洞察高斯系统中条件均值之间的线性关系，这构成了卡尔曼滤波器和高斯模型吉布斯采样等算法的理论基石。[@problem_id:3297685]", "problem": "考虑一个联合高斯随机变量对 $(X,Y)$，其均值向量为 $(\\mu_X,\\mu_Y)$，协方差矩阵为\n$$\n\\Sigma = \\begin{pmatrix}\n\\sigma_X^2  \\rho\\sigma_X\\sigma_Y \\\\\n\\rho\\sigma_X\\sigma_Y  \\sigma_Y^2\n\\end{pmatrix}\n$$\n其中 $\\sigma_X>0$, $\\sigma_Y>0$ 且 $|\\rho|1$。在一个用于模拟多维正态分布的马尔可夫链蒙特卡洛 (MCMC) 算法的 Gibbs 步中，需要一个分量在给定另一个分量时的条件分布。请仅从联合高斯密度的定义和通过比率 $f_{X|Y}(x|y) = f_{X,Y}(x,y)/f_Y(y)$ 定义的条件密度出发，并使用标准的线性代数恒等式（用于求协方差矩阵的逆和配方法），推导出对于固定 $y$ 的条件密度 $f_{X|Y}(x|y)$。然后推断出条件期望 $E[X|Y=y]$。\n\n你的推理必须从核心定义和公认事实出发，通过显式的代数推导进行，不得援引任何关于条件正态分布的快捷公式。最终答案必须是 $E[X|Y=y]$ 的一个单一闭式符号表达式。不要提供任何数值近似。", "solution": "该问题是有效的，因为它在科学上以概率论为基础，提法适定（提供了所有必要信息），且表述客观。该任务是多元统计学中的一个标准推导。\n\n设随机向量 $\\mathbf{Z} = \\begin{pmatrix} X \\\\ Y \\end{pmatrix}$ 服从二元正态分布，其均值向量为 $\\mathbf{\\mu} = \\begin{pmatrix} \\mu_X \\\\ \\mu_Y \\end{pmatrix}$，协方差矩阵为 $\\Sigma = \\begin{pmatrix} \\sigma_X^2  \\rho \\sigma_X \\sigma_Y \\\\ \\rho \\sigma_X \\sigma_Y  \\sigma_Y^2 \\end{pmatrix}$。其联合概率密度函数 (PDF) 由下式给出\n$$ f_{\\mathbf{Z}}(\\mathbf{z}) = \\frac{1}{\\sqrt{(2\\pi)^2 \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (\\mathbf{z}-\\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{z}-\\mathbf{\\mu})\\right) $$\n其中 $\\mathbf{z} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$。\n\n首先，我们计算协方差矩阵 $\\Sigma$ 的行列式和逆。行列式为\n$$ \\det(\\Sigma) = (\\sigma_X^2)(\\sigma_Y^2) - (\\rho \\sigma_X \\sigma_Y)^2 = \\sigma_X^2 \\sigma_Y^2 (1-\\rho^2) $$\n条件 $|\\rho|  1$ 确保了 $\\det(\\Sigma) > 0$，因此该矩阵是可逆的。其逆矩阵为\n$$ \\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)} \\begin{pmatrix} \\sigma_Y^2  -\\rho \\sigma_X \\sigma_Y \\\\ -\\rho \\sigma_X \\sigma_Y  \\sigma_X^2 \\end{pmatrix} = \\frac{1}{\\sigma_X^2 \\sigma_Y^2 (1-\\rho^2)} \\begin{pmatrix} \\sigma_Y^2  -\\rho \\sigma_X \\sigma_Y \\\\ -\\rho \\sigma_X \\sigma_Y  \\sigma_X^2 \\end{pmatrix} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1/\\sigma_X^2  -\\rho/(\\sigma_X \\sigma_Y) \\\\ -\\rho/(\\sigma_X \\sigma_Y)  1/\\sigma_Y^2 \\end{pmatrix} $$\n指数中的二次型为 $Q(x,y) = (\\mathbf{z}-\\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{z}-\\mathbf{\\mu})$，展开后为：\n$$ Q(x,y) = \\begin{pmatrix} x-\\mu_X  y-\\mu_Y \\end{pmatrix} \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1/\\sigma_X^2  -\\rho/(\\sigma_X \\sigma_Y) \\\\ -\\rho/(\\sigma_X \\sigma_Y)  1/\\sigma_Y^2 \\end{pmatrix} \\begin{pmatrix} x-\\mu_X \\\\ y-\\mu_Y \\end{pmatrix} $$\n$$ Q(x,y) = \\frac{1}{1-\\rho^2} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] $$\n因此，联合概率密度函数 $f_{X,Y}(x,y)$ 为：\n$$ f_{X,Y}(x,y) = \\frac{1}{2\\pi \\sigma_X \\sigma_Y \\sqrt{1-\\rho^2}} \\exp\\left(-\\frac{1}{2(1-\\rho^2)} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right]\\right) $$\n$Y$ 的边际分布是一个均值为 $\\mu_Y$、方差为 $\\sigma_Y^2$ 的正态分布。其概率密度函数为：\n$$ f_Y(y) = \\frac{1}{\\sqrt{2\\pi \\sigma_Y^2}} \\exp\\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right) = \\frac{1}{\\sigma_Y \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right) $$\n根据定义，条件密度 $f_{X|Y}(x|y)$ 是联合密度与边际密度的比值：\n$$ f_{X|Y}(x|y) = \\frac{f_{X,Y}(x,y)}{f_Y(y)} $$\n条件概率密度函数的常数部分为：\n$$ \\frac{1 / (2\\pi \\sigma_X \\sigma_Y \\sqrt{1-\\rho^2})}{1 / (\\sigma_Y \\sqrt{2\\pi})} = \\frac{\\sigma_Y \\sqrt{2\\pi}}{2\\pi \\sigma_X \\sigma_Y \\sqrt{1-\\rho^2}} = \\frac{1}{\\sigma_X \\sqrt{2\\pi} \\sqrt{1-\\rho^2}} $$\n条件概率密度函数的指数是联合概率密度函数的指数与边际概率密度函数的指数之差：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] - \\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right) $$\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2} \\left\\{ \\frac{1}{1-\\rho^2} \\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] - \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right\\} $$\n我们合并包含 $(y-\\mu_Y)^2$ 的项：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2} \\left\\{ \\frac{1}{1-\\rho^2}\\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} \\right] + \\left(\\frac{1}{1-\\rho^2} - 1\\right)\\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right\\} $$\n由于 $\\frac{1}{1-\\rho^2} - 1 = \\frac{1 - (1-\\rho^2)}{1-\\rho^2} = \\frac{\\rho^2}{1-\\rho^2}$，该表达式变为：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2} \\left\\{ \\frac{1}{1-\\rho^2}\\left[ \\frac{(x-\\mu_X)^2}{\\sigma_X^2} - \\frac{2\\rho(x-\\mu_X)(y-\\mu_Y)}{\\sigma_X\\sigma_Y} + \\rho^2\\frac{(y-\\mu_Y)^2}{\\sigma_Y^2} \\right] \\right\\} $$\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)} \\left[ \\left(\\frac{x-\\mu_X}{\\sigma_X}\\right)^2 - 2\\rho\\left(\\frac{x-\\mu_X}{\\sigma_X}\\right)\\left(\\frac{y-\\mu_Y}{\\sigma_Y}\\right) + \\rho^2\\left(\\frac{y-\\mu_Y}{\\sigma_Y}\\right)^2 \\right] $$\n方括号中的项是一个完全平方式。我们对变量 $x$ 进行配方：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)} \\left( \\frac{x-\\mu_X}{\\sigma_X} - \\rho\\frac{y-\\mu_Y}{\\sigma_Y} \\right)^2 $$\n为了确定均值和方差，我们将此表达式重排为标准形式 $-\\frac{(x-\\mu)^2}{2\\sigma^2}$：\n$$ \\text{Exp}_{X|Y} = -\\frac{1}{2(1-\\rho^2)\\sigma_X^2} \\left( (x-\\mu_X) - \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y) \\right)^2 $$\n$$ \\text{Exp}_{X|Y} = -\\frac{\\left( x - \\left[\\mu_X + \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y)\\right] \\right)^2}{2\\sigma_X^2(1-\\rho^2)} $$\n因此，条件密度 $f_{X|Y}(x|y)$ 为：\n$$ f_{X|Y}(x|y) = \\frac{1}{\\sigma_X \\sqrt{2\\pi(1-\\rho^2)}} \\exp\\left( -\\frac{\\left( x - \\left[\\mu_X + \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y)\\right] \\right)^2}{2\\sigma_X^2(1-\\rho^2)} \\right) $$\n这是关于 $x$ 的正态分布的概率密度函数。通过将其与正态分布PDF的一般形式 $f(z) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(z-\\mu)^2}{2\\sigma^2}\\right)$ 进行比较，我们可以确定条件均值和条件方差。\n条件均值是在给定 $Y=y$ 时 $X$ 的期望：\n$$ E[X|Y=y] = \\mu_{X|Y} = \\mu_X + \\rho\\frac{\\sigma_X}{\\sigma_Y}(y-\\mu_Y) $$\n条件方差为：\n$$ \\text{Var}(X|Y=y) = \\sigma_{X|Y}^2 = \\sigma_X^2(1-\\rho^2) $$\n问题具体要求的是条件期望 $E[X|Y=y]$。根据推导，这就是上面推导出的条件正态分布的均值。", "answer": "$$ \\boxed{\\mu_X + \\rho \\frac{\\sigma_X}{\\sigma_Y}(y - \\mu_Y)} $$", "id": "3297685"}, {"introduction": "计算出条件期望后，我们自然会问：它有什么用？一个关键应用就是改进蒙特卡洛估计量。本练习是著名的 Rao-Blackwell 定理的一次动手实践，它将条件期望与统计学中的“充分性”概念紧密联系起来。通过亲自推导并模拟一个经过 Rao-Blackwell 化的估计量，你将具体地理解到，对充分统计量取条件是如何显著降低估计量方差的，这是高效统计计算的基石之一。[@problem_id:3297654]", "problem": "考虑以下通过条件期望对 Rao–Blackwell (RB) 改进进行的蒙特卡洛 (MC) 研究。设 $\\{Y_i\\}_{i=1}^n$ 为独立同分布随机变量，其中 $Y_i \\sim \\mathrm{Poisson}(\\lambda)$，$\\lambda  0$ 是一个固定但未知的参数。您的目标是使用无偏估计量 $X$ 及其 Rao–Blackwell 化版本 $\\mathbb{E}[X \\mid \\sigma(T)]$ 来估计泛函 $\\theta(\\lambda) = \\mathbb{E}_\\lambda[X] = e^{-\\lambda}$，其中 $T$ 是 $\\lambda$ 的一个充分统计量。任务是从第一性原理推导 $\\mathbb{E}[X \\mid \\sigma(T)]$，然后比较在不同样本量下 $X$ 的 MC 方差与 $\\mathbb{E}[X \\mid \\sigma(T)]$ 的 MC 方差。\n\n定义与设置：\n- 设 $X = \\mathbf{1}\\{Y_1 = 0\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。注意 $\\mathbb{E}_\\lambda[X] = \\mathbb{P}_\\lambda(Y_1 = 0) = e^{-\\lambda}$。\n- 设 $T = \\sum_{i=1}^n Y_i$。使用因子分解定理来证明 $T$ 是 $\\lambda$ 的充分统计量。\n- 使用条件期望的定义，通过将 $X$ 投影到 $\\sigma(T)$上来构造 RB 估计量，即，将 $\\mathbb{E}[X \\mid \\sigma(T)]$ 显式地推导为 $T$ 和 $n$ 的函数。\n\n您的任务：\n1. 从 $(Y_1,\\dots,Y_n)$ 的联合概率质量函数 (PMF) 和充分性的定义出发，证明 $T$ 是 $\\lambda$ 的充分统计量。然后，利用给定 $T=t$ 时 $Y_1$ 的条件分布，推导 $\\mathbb{E}[X \\mid T=t]$ 的封闭形式，进而得到 $\\mathbb{E}[X \\mid \\sigma(T)]$。\n2. 解释为什么 $\\mathbb{E}[X \\mid \\sigma(T)]$ 对于 $\\theta(\\lambda)$ 仍然是无偏的，并（使用 Rao–Blackwell 定理）证明对于任何 $n \\in \\mathbb{N}$ 和 $\\lambda  0$ 都有 $\\mathrm{Var}(\\mathbb{E}[X \\mid \\sigma(T)]) \\le \\mathrm{Var}(X)$。\n3. 实现一个 MC 实验，通过模拟来估计和比较 $\\mathrm{Var}(X)$ 和 $\\mathrm{Var}(\\mathbb{E}[X \\mid \\sigma(T)])$。对于给定的配对 $(\\lambda,n)$，生成 $M$ 个独立同分布的 $(Y_1,\\dots,Y_n)$ 样本，为每个样本计算相应的 $X$ 和 $\\mathbb{E}[X \\mid \\sigma(T)]$，然后计算 $X$ 和 $\\mathbb{E}[X \\mid \\sigma(T)]$ 的无偏 MC 样本方差（使用贝塞尔校正）。报告比率\n$$\nR(\\lambda,n) = \\frac{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(\\mathbb{E}[X \\mid \\sigma(T)])}{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(X)}.\n$$\n4. 对所有测试用例使用以下 MC 设置：$M = 100000$ 以及为确保可复现性而设定的固定随机种子 $0$。\n5. 测试套件：按以下精确顺序计算参数对 $(\\lambda,n)$ 的 $R(\\lambda,n)$：\n   - $(\\lambda,n) = (0.3,1)$，\n   - $(\\lambda,n) = (0.3,2)$，\n   - $(\\lambda,n) = (1.0,5)$，\n   - $(\\lambda,n) = (3.0,10)$，\n   - $(\\lambda,n) = (5.0,25)$。\n6. 最终输出格式：您的程序必须打印单行，其中包含一个 Python 风格的列表，内含按上述顺序排列的五个比率 $[R(\\lambda,n),\\dots]$，每个比率四舍五入到 $6$ 位小数。此问题中没有物理单位、角度或百分比；数值答案必须是实数。\n\n额外要求：\n- 您的程序必须是一个完整的、可运行的脚本，执行 MC 模拟，无需用户输入。\n- 仅使用最终答案部分详述的指定运行时环境和库。", "solution": "该问题被认为是有效的。这是一个在计算统计学领域中表述清晰且具有科学依据的练习，具体通过蒙特卡洛模拟展示了 Rao-Blackwell 定理的应用。所有必要信息，包括模型、估计量、参数和模拟设置，都以清晰一致的方式提供。\n\n解答分为三个部分：\n1. Rao–Blackwell 估计量的推导。\n2. 其性质（无偏性和方差减小）的理论证明。\n3. 用于比较方差的蒙特卡洛模拟的描述。\n\n### 1. Rao–Blackwell 估计量的推导\n\n设 $\\{Y_i\\}_{i=1}^n$ 为独立同分布随机变量，其中 $Y_i \\sim \\mathrm{Poisson}(\\lambda)$。对于 $\\theta(\\lambda) = e^{-\\lambda}$ 的初始估计量是 $X = \\mathbf{1}\\{Y_1 = 0\\}$。Rao–Blackwell 定理指出，如果 $T$ 是 $\\lambda$ 的一个充分统计量，那么估计量 $\\tilde{X} = \\mathbb{E}[X \\mid \\sigma(T)]$ 对于 $\\theta(\\lambda)$ 也是无偏的，并且其方差不大于 $X$ 的方差。\n\n**$T = \\sum_{i=1}^n Y_i$ 的充分性：**\n\n样本 $\\mathbf{Y} = (Y_1, \\dots, Y_n)$ 的联合概率质量函数 (PMF) 由各个独立的泊松 PMF 的乘积给出，因为它们是独立的：\n$$ f(\\mathbf{y}; \\lambda) = \\prod_{i=1}^n \\mathbb{P}(Y_i = y_i) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!} $$\n这可以重写为：\n$$ f(\\mathbf{y}; \\lambda) = \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} $$\n设 $t = \\sum_{i=1}^n y_i$。PMF 可以分解为：\n$$ f(\\mathbf{y}; \\lambda) = \\left( e^{-n\\lambda} \\lambda^t \\right) \\cdot \\left( \\frac{1}{\\prod_{i=1}^n y_i!} \\right) $$\n这是 $g(t; \\lambda)h(\\mathbf{y})$ 的形式，其中 $g(t; \\lambda) = e^{-n\\lambda} \\lambda^t$ 仅通过统计量 $T$ 依赖于数据，而 $h(\\mathbf{y}) = (\\prod_{i=1}^n y_i!)^{-1}$ 不依赖于 $\\lambda$。根据 Fisher-Neyman 因子分解定理，这证明了 $T = \\sum_{i=1}^n Y_i$ 是 $\\lambda$ 的一个充分统计量。\n\n**$\\mathbb{E}[X \\mid T=t]$ 的推导：**\n\nRao-Blackwell 化的估计量 $\\tilde{X}$ 是给定充分统计量 $T$ 时 $X$ 的条件期望。对于给定的观测值 $T=t$，我们有：\n$$ \\mathbb{E}[X \\mid T=t] = \\mathbb{E}[\\mathbf{1}\\{Y_1=0\\} \\mid T=t] = \\mathbb{P}(Y_1=0 \\mid T=t) $$\n使用条件概率的定义：\n$$ \\mathbb{P}(Y_1=0 \\mid \\sum_{i=1}^n Y_i = t) = \\frac{\\mathbb{P}(Y_1=0, \\sum_{i=1}^n Y_i = t)}{\\mathbb{P}(\\sum_{i=1}^n Y_i = t)} $$\n分子中的事件等价于 $\\{Y_1=0 \\text{ and } \\sum_{i=2}^n Y_i = t\\}$。\n独立泊松随机变量之和本身也是一个泊松随机变量。具体来说，$S_k = \\sum_{i=1}^k Y_i \\sim \\mathrm{Poisson}(k\\lambda)$。\n因此，$T = \\sum_{i=1}^n Y_i \\sim \\mathrm{Poisson}(n\\lambda)$，其 PMF 为 $\\mathbb{P}(T=t) = \\frac{e^{-n\\lambda}(n\\lambda)^t}{t!}$。\n分子中的项可以使用独立性来计算：\n$$ \\mathbb{P}(Y_1=0, \\sum_{i=2}^n Y_i = t) = \\mathbb{P}(Y_1=0) \\cdot \\mathbb{P}\\left(\\sum_{i=2}^n Y_i = t\\right) $$\n其中 $\\mathbb{P}(Y_1=0) = e^{-\\lambda}$ 并且 $\\sum_{i=2}^n Y_i \\sim \\mathrm{Poisson}((n-1)\\lambda)$。这在 $n > 1$ 时成立。\n分子是：\n$$ (e^{-\\lambda}) \\cdot \\left( \\frac{e^{-(n-1)\\lambda}((n-1)\\lambda)^t}{t!} \\right) = \\frac{e^{-n\\lambda}((n-1)\\lambda)^t}{t!} $$\n将分子和分母代回条件概率公式：\n$$ \\mathbb{P}(Y_1=0 \\mid T=t) = \\frac{\\frac{e^{-n\\lambda}((n-1)\\lambda)^t}{t!}}{\\frac{e^{-n\\lambda}(n\\lambda)^t}{t!}} = \\frac{((n-1)\\lambda)^t}{(n\\lambda)^t} = \\left(\\frac{n-1}{n}\\right)^t $$\n此推导适用于 $n  1$。对于 $n=1$ 的情况，我们有 $T=Y_1$。估计量是 $\\mathbb{E}[\\mathbf{1}\\{Y_1=0\\} \\mid Y_1=t]$。当 $t=0$ 时为 $1$，当 $t \\ne 0$ 时为 $0$，可以写成 $\\mathbf{1}\\{t=0\\}$。将公式 $\\left(\\frac{n-1}{n}\\right)^t$ 应用于 $n=1$ 会得到 $0^t$，按照惯例，当 $t=0$ 时为 $1$，当 $t>0$ 时为 $0$。因此，该表达式对于 $n=1$ 也成立。\n\n因此，Rao-Blackwell 估计量为 $\\tilde{X} = \\mathbb{E}[X \\mid \\sigma(T)] = \\left(\\frac{n-1}{n}\\right)^T$。\n\n### 2. 估计量的性质\n\n**无偏性：**\n根据全期望定律（或称塔形性质），条件期望的期望等于无条件期望：\n$$ \\mathbb{E}[\\tilde{X}] = \\mathbb{E}\\left[\\mathbb{E}[X \\mid \\sigma(T)]\\right] = \\mathbb{E}[X] $$\n由于原始估计量 $X = \\mathbf{1}\\{Y_1=0\\}$ 对于 $\\theta(\\lambda) = e^{-\\lambda}$ 是无偏的（因为 $\\mathbb{E}[X] = \\mathbb{P}(Y_1=0) = e^{-\\lambda}$），所以 Rao-Blackwell 化的估计量 $\\tilde{X}$ 对于 $\\theta(\\lambda)$ 也是无偏的。\n\n**方差减小：**\n全方差定律表明：\n$$ \\mathrm{Var}(X) = \\mathbb{E}[\\mathrm{Var}(X \\mid T)] + \\mathrm{Var}(\\mathbb{E}[X \\mid T]) $$\n我们的改进估计量的方差是 $\\mathrm{Var}(\\tilde{X}) = \\mathrm{Var}(\\mathbb{E}[X \\mid T])$。项 $\\mathbb{E}[\\mathrm{Var}(X \\mid T)]$ 是条件方差的期望。由于方差总是非负的，$\\mathrm{Var}(X \\mid T) \\ge 0$，因此其期望也是非负的，即 $\\mathbb{E}[\\mathrm{Var}(X \\mid T)] \\ge 0$。\n这意味着：\n$$ \\mathrm{Var}(X) \\ge \\mathrm{Var}(\\mathbb{E}[X \\mid T]) \\quad \\text{或} \\quad \\mathrm{Var}(X) \\ge \\mathrm{Var}(\\tilde{X}) $$\n等号成立当且仅当 $\\mathrm{Var}(X \\mid T) = 0$ 几乎必然成立，这意味着 $X$ 是 $T$ 的函数。在我们的例子中，对于 $n=1$，$T=Y_1$，所以 $X=\\mathbf{1}\\{Y_1=0\\}$ 是 $T$ 的函数。因此对于 $n=1$，$\\mathrm{Var}(X) = \\mathrm{Var}(\\tilde{X})$，方差比为 $1$。对于 $n>1$，$X$ 不是 $T$ 的函数，所以我们期望严格不等式 $\\mathrm{Var}(X)  \\mathrm{Var}(\\tilde{X})$，以及小于 $1$ 的方差比。\n\n### 3. 蒙特卡洛模拟设计\n\n该模拟将针对指定的参数对 $(\\lambda, n)$ 估计并比较 $X$ 和 $\\tilde{X}$ 的方差。\n对于每个参数对 $(\\lambda, n)$ 的过程如下：\n1.  为保证可复现性，将随机数生成器的种子设为 $0$。\n2.  生成 $M=100000$ 个独立的样本 $(Y_1, \\dots, Y_n)$ 的复制，其中每个 $Y_i \\sim \\mathrm{Poisson}(\\lambda)$。这将产生 $M$ 个长度为 $n$ 的向量。\n3.  对于 $M$ 个复制中的每一个：\n    a.  计算原始估计量 $X = \\mathbf{1}\\{Y_1=0\\}$。\n    b.  计算充分统计量 $T = \\sum_{i=1}^n Y_i$。\n    c.  计算 Rao-Blackwell 化的估计量 $\\tilde{X} = \\left(\\frac{n-1}{n}\\right)^T$。\n4.  这将产生两组 $M$ 个样本：$\\{X_j\\}_{j=1}^M$ 和 $\\{\\tilde{X}_j\\}_{j=1}^M$。\n5.  使用无偏估计量（带贝塞尔校正，$ddof=1$）计算样本方差：\n    $$ \\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(X) = \\frac{1}{M-1}\\sum_{j=1}^M (X_j - \\bar{X})^2 \\quad \\text{和} \\quad \\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(\\tilde{X}) = \\frac{1}{M-1}\\sum_{j=1}^M (\\tilde{X}_j - \\bar{\\tilde{X}})^2 $$\n6.  计算比率 $R(\\lambda,n) = \\frac{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(\\tilde{X})}{\\widehat{\\mathrm{Var}}_{\\mathrm{MC}}(X)}$。\n7.  将对以下测试用例重复此过程：\n    - $(\\lambda,n) = (0.3, 1)$\n    - $(\\lambda,n) = (0.3, 2)$\n    - $(\\lambda,n) = (1.0, 5)$\n    - $(\\lambda,n) = (3.0, 10)$\n    - $(\\lambda,n) = (5.0, 25)$\n最终输出将是这些比率的列表，四舍五入到 $6$ 位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Monte Carlo study to compare the variance of an estimator\n    with its Rao-Blackwellized version.\n    \"\"\"\n    # Define simulation parameters as specified in the problem statement.\n    M = 100000\n    SEED = 0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.3, 1),\n        (0.3, 2),\n        (1.0, 5),\n        (3.0, 10),\n        (5.0, 25),\n    ]\n\n    results = []\n\n    # Initialize the random number generator for reproducibility.\n    rng = np.random.default_rng(SEED)\n\n    for lam, n in test_cases:\n        # Generate M independent replicates of n i.i.d. Poisson samples.\n        # The shape of Y_samples will be (M, n).\n        Y_samples = rng.poisson(lam=lam, size=(M, n))\n\n        # Calculate the original estimator X = 1{Y_1 = 0} for each of the M replicates.\n        # This results in a 1D array of length M.\n        x_values = (Y_samples[:, 0] == 0).astype(np.float64)\n\n        # Calculate the sufficient statistic T = sum(Y_i) for each of the M replicates.\n        # This results in a 1D array of length M.\n        t_values = np.sum(Y_samples, axis=1)\n\n        # Calculate the Rao-Blackwellized estimator E[X|T] = ((n-1)/n)^T.\n        # For n=1, the base is 0. np.power(0, 0) correctly evaluates to 1,\n        # which is the value of E[X|T] when T=0. For T>0, np.power(0, T) is 0.\n        # This handles the n=1 case correctly where E[X|T] = 1{T=0}.\n        if n == 1:\n            base = 0.0\n        else:\n            base = (n - 1) / n\n        \n        x_tilde_values = np.power(base, t_values)\n\n        # Calculate the sample variances of the M estimates for both estimators.\n        # ddof=1 provides Bessel's correction for an unbiased estimate of the variance.\n        var_x = np.var(x_values, ddof=1)\n        var_x_tilde = np.var(x_tilde_values, ddof=1)\n\n        # Calculate the ratio of the variances.\n        # For n=1, X and E[X|T] are identical, so their variances are identical\n        # and the ratio is 1.0. For other cases, Var(X) will be non-zero for\n        # the given lambda values.\n        if var_x == 0:\n            # This case occurs if all x_values are identical.\n            # If Var(X) = 0, then X is constant, so Var(E[X|T]) also must be 0.\n            # The ratio should be 1, as E[X|T] = X in this case.\n            ratio = 1.0\n        else:\n            ratio = var_x_tilde / var_x\n\n        results.append(round(ratio, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3297654"}, {"introduction": "条件分布是强大的马尔可夫链蒙特卡洛（MCMC）方法——吉布斯采样——的引擎。然而，一个自然的问题是：任意一组“完整条件分布”都能定义一个有效的联合分布模型吗？本练习将探讨“相容性”（coherence）这一深刻概念，并利用一种巧妙的、基于模拟的诊断方法来检验一组给定的完整条件分布是否与某个联合分布相容。这项高级实践将带你进入 MCMC 方法的前沿，教你如何诊断潜在的模型设定错误，并加深你对吉布斯采样器理论基础的理解。[@problem_id:3297655]", "problem": "给定一个二元随机向量 $X=(X_1,X_2)$ 的全条件分布族，其具有如下线性高斯形式：\n$$\nX_1 \\mid X_2=x_2 \\sim \\mathcal{N}\\big(\\mu_1 + a\\,x_2,\\, s_1^2\\big),\\qquad\nX_2 \\mid X_1=x_1 \\sim \\mathcal{N}\\big(\\mu_2 + b\\,x_1,\\, s_2^2\\big),\n$$\n其中 $a,b\\in\\mathbb{R}$，$s_1^2>0$，$s_2^2>0$ 以及 $\\mu_1,\\mu_2\\in\\mathbb{R}$ 是固定参数。核心问题是这些全条件分布是否是相容的（coherent），也就是说，是否存在某个在 $\\mathbb{R}^2$ 上的联合分布，其条件分布与上述分布族一致。由于精确的解析相容性条件可能非常微妙，你将使用蒙特卡洛模拟，基于不同 Gibbs 扫描顺序下迭代条件的不变性，来经验性地检验相容性的一个必要体现。\n\n使用的基本原理和定义：\n- 对于任意可积函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$，条件期望 $E[f\\mid X_i]$ 是 $f$ 到由 $X_i$ ($i\\in\\{1,2\\}$) 生成的 $\\sigma$-代数上的正交投影。\n- 从状态 $(x_1,x_2)$ 按 $1\\to 2$ 顺序进行的一次扫描两步 Gibbs 更新，包括采样 $X_1'\\sim p(\\cdot\\mid X_2=x_2)$，然后采样 $X_2'\\sim p(\\cdot\\mid X_1=X_1')$。应用于 $f$ 的相应马尔可夫算子是在 $(x_1,x_2)$ 处求值的迭代条件期望 $K_{12}f(x_1,x_2)=E\\left[E\\left[f\\mid X_1\\right]\\mid X_2\\right]$。类似地，对于顺序 $2\\to 1$，$K_{21}f(x_1,x_2)=E\\left[E\\left[f\\mid X_2\\right]\\mid X_1\\right]$。\n- 如果全条件分布是相容的（即，源于 $\\mathbb{R}^2$ 上的某个联合分布 $\\Pi$），那么两种扫描顺序都定义了共享相同平稳分布 $\\Pi$ 的马尔可夫链，并且对于任何可积函数 $f$ 和任一种扫描顺序，其平稳期望都满足 $E_{\\Pi}[f]=E_{\\Pi}[K_{12}f]=E_{\\Pi}[K_{21}f]$。因此，在相容性条件下，一组检验函数的平稳期望对于扫描顺序是不变的。\n\n设计一个蒙特卡洛相容性诊断程序，对于给定的参数集 $(a,b,s_1,s_2,\\mu_1,\\mu_2)$，该程序执行以下操作：\n- 使用给定的全条件分布构建两种 Gibbs 扫描顺序 $1\\to 2$ 和 $2\\to 1$。\n- 对每个链进行 $N_{\\mathrm{burn}}$ 步的预烧（burn-in）模拟，然后收集 $N$ 个预烧后的迭代样本。\n- 对于以下五个检验函数\n$$\nf_1(x_1,x_2)=x_1,\\quad\nf_2(x_1,x_2)=x_2,\\quad\nf_3(x_1,x_2)=x_1x_2,\\quad\nf_4(x_1,x_2)=x_1^2,\\quad\nf_5(x_1,x_2)=x_2^2,\n$$\n计算它们在每种扫描顺序下的平稳期望的蒙特卡洛估计值，以及通过非重叠批次均值（non-overlapping batch means）法计算的蒙特卡洛标准误。使用批次大小为 $B$ 和 $M=\\lfloor N/B\\rfloor$ 个批次。\n- 对每个 $f_k$，计算标准化差异\n$$\nZ_k=\\frac{\\left|\\widehat{E}_{12}[f_k]-\\widehat{E}_{21}[f_k]\\right|}{\\sqrt{\\widehat{\\mathrm{Var}}_{12}(\\bar{f}_k)+\\widehat{\\mathrm{Var}}_{21}(\\bar{f}_k)}},\n$$\n其中 $\\widehat{E}_{12}[f_k]$ 和 $\\widehat{E}_{21}[f_k]$ 分别是来自 $1\\to 2$ 和 $2\\to 1$ 扫描的样本均值，而 $\\widehat{\\mathrm{Var}}(\\bar{f}_k)$ 是它们样本均值的批次均值方差估计量。如果对于一个固定的阈值 $\\tau$，满足 $\\max_{k\\in\\{1,\\dots,5\\}} Z_k \\le \\tau$，则声明该参数集为“经验性相容”（empirically coherent）。\n\n使用固定的模拟设置：\n- 使用 $N_{\\mathrm{burn}}=20000$，$N=120000$，$B=600$ 和 $\\tau=5$。\n- 将两个链都在 $(0,0)$ 处初始化。\n- 使用固定的伪随机数生成器种子，以确保结果完全可复现。\n- 不使用角度；没有需要报告的物理单位。\n\n测试套件：\n为以下四个参数集 $(a,b,s_1,s_2,\\mu_1,\\mu_2)$ 提供结果：\n- 情况 1（相容，源于一个真实的二元正态分布，其均值为 $(m_1,m_2)=(0.5,-0.3)$，方差为 $(v_1,v_2)=(1.5,0.7)$，协方差为 $c=0.6$）：\n$$\na=\\frac{0.6}{0.7},\\quad b=\\frac{0.6}{1.5},\\quad s_1=\\sqrt{1.5-\\frac{0.6^2}{0.7}},\\quad s_2=\\sqrt{0.7-\\frac{0.6^2}{1.5}},\n$$\n$$\n\\mu_1=0.5-a(-0.3),\\quad \\mu_2=-0.3-b(0.5).\n$$\n- 情况 2（通过斜率/方差不匹配故意设置为不相容）：\n$$\na=0.8,\\quad b=0.2,\\quad s_1=1.0,\\quad s_2=\\sqrt{0.9},\\quad \\mu_1=0.0,\\quad \\mu_2=0.0.\n$$\n- 情况 3（通过均值不匹配故意设置为不相容，而其斜率/方差与某个零均值联合分布相容）：\n$$\na=0.25,\\quad b=0.5,\\quad s_1=\\sqrt{0.875},\\quad s_2=\\sqrt{1.75},\\quad \\mu_1=0.6,\\quad \\mu_2=1.5.\n$$\n- 情况 4（相容，接近边界 $ab$ 接近 $1$）：\n$$\na=b=\\sqrt{0.95},\\quad s_1=s_2=\\sqrt{1-0.95},\\quad \\mu_1=0.0,\\quad \\mu_2=0.0.\n$$\n\n你的程序必须为所有四种情况实现上述诊断，并输出单行，其中包含一个含四个布尔值的列表，每个值指示对应的参数集是否根据 $\\max_k Z_k \\le \\tau$ 标准是经验性相容的。格式必须严格为方括号内以逗号分隔的列表，例如 `[True, False, False, True]`。", "solution": "所提供的问题是有效的。它在科学上基于马尔可夫链蒙特卡洛（MCMC）方法和条件概率分布的理论。该问题是适定的（well-posed），提供了所有必要的参数、常数以及待实现算法的完整说明。术语精确，目标明确。\n\n问题的核心是为一组全条件分布的相容性设计一个经验性诊断方法。一组全条件分布 $\\{p(x_i | x_{-i})\\}_{i=1}^d$ 是相容的，如果存在一个联合概率分布 $p(x_1, \\dots, x_d)$，其条件分布正是这些分布。对于给定的线性高斯情况，\n$$\nX_1 \\mid X_2=x_2 \\sim \\mathcal{N}(\\mu_1 + a\\,x_2, s_1^2)\n$$\n$$\nX_2 \\mid X_1=x_1 \\sim \\mathcal{N}(\\mu_2 + b\\,x_1, s_2^2)\n$$\n存在一个联合二元正态分布当且仅当 $ab \\ge 0$，$ab  1$ 且 $as_2^2 = bs_1^2$。如果这些条件成立，那么由这些条件分布构建的 Gibbs 采样器将以相应的联合正态分布作为其唯一的平稳分布 $\\Pi$。这种采样器的一个关键特性是其平稳分布对变量的扫描顺序是不变的。也就是说，按 $X_1 \\to X_2$ 或 $X_2 \\to X_1$ 的顺序更新变量，会产生两个不同的马尔可夫链，但它们共享相同的平稳分布 $\\Pi$。\n\n这种不变性提供了一个强大的诊断工具。如果条件分布是相容的，任何可积检验函数 $f(X_1, X_2)$ 的长期平均值必须与扫描顺序无关，保持相同。令 $E_{12}[f]$ 和 $E_{21}[f]$ 分别表示在 $1 \\to 2$ 和 $2 \\to 1$ 扫描顺序下 $f$ 的平稳期望。相容性意味着 $E_{12}[f] = E_{21}[f] = E_\\Pi[f]$。所提出的诊断方法使用蒙特卡洛模拟来检验这一推论。\n\n该算法按以下步骤进行：\n\n1.  **Gibbs 采样器模拟**：并行运行两个 Gibbs 采样链，每个链对应一种扫描顺序。\n    -   **链 1（顺序 $1 \\to 2$）**：从状态 $(x_1^{(t)}, x_2^{(t)})$，通过采样 $x_{1, \\text{new}} \\sim \\mathcal{N}(\\mu_1 + a\\,x_2^{(t)}, s_1^2)$，然后采样 $x_2^{(t+1)} \\sim \\mathcal{N}(\\mu_2 + b\\,x_{1, \\text{new}}, s_2^2)$，并设置 $x_1^{(t+1)} = x_{1, \\text{new}}$，来生成下一个状态 $(x_1^{(t+1)}, x_2^{(t+1)})$。\n    -   **链 2（顺序 $2 \\to 1$）**：更新过程首先包括采样 $x_{2, \\text{new}} \\sim \\mathcal{N}(\\mu_2 + b\\,x_1^{(t)}, s_2^2)$，然后采样 $x_1^{(t+1)} \\sim \\mathcal{N}(\\mu_1 + a\\,x_{2, \\text{new}}, s_1^2)$，并设置 $x_2^{(t+1)} = x_{2, \\text{new}}$。\n\n    两个链都从 $(x_1^{(0)}, x_2^{(0)}) = (0,0)$ 开始初始化。它们运行 $N_{\\mathrm{burn}} = 20000$ 次迭代以丢弃初始的瞬态样本（预烧期）。随后，从每个链中收集 $N = 120000$ 个样本。\n\n2.  **期望的蒙特卡洛估计**：对于五个检验函数 $f_k$ 中的每一个，以及对于每个链（由扫描顺序 $j \\in \\{12, 21\\}$ 表示），其平稳期望 $E_j[f_k]$ 是通过对 $N$ 个预烧后样本 $\\{(x_{1,j}^{(i)}, x_{2,j}^{(i)})\\}_{i=1}^N$ 计算函数值的样本均值来估计的：\n    $$\n    \\widehat{E}_j[f_k] = \\frac{1}{N} \\sum_{i=1}^{N} f_k(x_{1,j}^{(i)}, x_{2,j}^{(i)})\n    $$\n\n3.  **通过批次均值估计标准误**：来自 MCMC 链的样本内在地是相关的，这使得用于独立同分布（i.i.d.）样本均值的简单方差公式失效。为了获得 $\\widehat{E}_j[f_k]$ 方差的有效估计，采用了非重叠批次均值法（NOBM）。$f_k$ 的 $N$ 个预烧后样本被划分为 $M = \\lfloor N/B \\rfloor = \\lfloor 120000/600 \\rfloor = 200$ 个大小为 $B=600$ 的非重叠批次。对每个批次 $m \\in \\{1, \\dots, M\\}$，计算批次均值 $\\bar{f}_{k,j}^{(m)}$。总样本均值 $\\widehat{E}_j[f_k]$ 的方差则估计为：\n    $$\n    \\widehat{\\mathrm{Var}}_j(\\bar{f}_k) = \\frac{1}{M} \\cdot \\frac{1}{M-1} \\sum_{m=1}^{M} \\left( \\bar{f}_{k,j}^{(m)} - \\widehat{E}_j[f_k] \\right)^2\n    $$\n    该公式计算批次均值的样本方差，并按 $1/M$ 进行缩放。对于足够大的批次大小 $B$，批次均值近似不相关，并且根据中心极限定理，近似服从正态分布。\n\n4.  **标准化差异检验**：对于每个检验函数 $f_k$，计算来自两个链的估计值之间的标准化差异 $Z_k$。这类似于一个双样本 Z 检验：\n    $$\n    Z_k = \\frac{\\left|\\widehat{E}_{12}[f_k] - \\widehat{E}_{21}[f_k]\\right|}{\\sqrt{\\widehat{\\mathrm{Var}}_{12}(\\bar{f}_k) + \\widehat{\\mathrm{Var}}_{21}(\\bar{f}_k)}}\n    $$\n    在相容性的零假设下，$\\widehat{E}_{12}[f_k]$ 和 $\\widehat{E}_{21}[f_k]$ 是同一数量的估计值。它们的差异应该很小，并且 $Z_k$ 统计量应该是近似标准正态随机变量的实现值。$Z_k$ 的大值提供了反对相容性的证据。如果所有检验函数的最大观测差异在统计上不显著，即对于给定的阈值 $\\tau=5$ 满足 $\\max_{k\\in\\{1,\\dots,5\\}} Z_k \\le \\tau$，则该参数集被声明为“经验性相容”（empirically coherent）。\n\n整个过程使用 Python 中的 `numpy` 库来实现数值计算和随机数生成，并使用固定种子以确保可复现性。该诊断方法应用于四个指定的参数集中的每一个，以确定其经验相容性状态。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_gibbs_sampler(params, settings, scan_order, rng):\n    \"\"\"\n    Runs a Gibbs sampler for a given scan order and returns the collected samples.\n    \"\"\"\n    a, b, s1, s2, mu1, mu2 = params\n    N_burn, N = settings['N_burn'], settings['N']\n    x1, x2 = 0.0, 0.0\n\n    # Burn-in phase\n    for _ in range(N_burn):\n        if scan_order == '12':\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n        elif scan_order == '21':\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n\n    # Sample collection phase\n    samples = np.zeros((N, 2))\n    for i in range(N):\n        if scan_order == '12':\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n        elif scan_order == '21':\n            x2 = rng.normal(loc=mu2 + b * x1, scale=s2)\n            x1 = rng.normal(loc=mu1 + a * x2, scale=s1)\n        samples[i, :] = [x1, x2]\n\n    return samples\n\ndef calculate_stats(samples, settings):\n    \"\"\"\n    Computes Monte Carlo estimates and their batch-means variances.\n    \"\"\"\n    N, B = settings['N'], settings['B']\n    M = N // B\n\n    x1_s = samples[:, 0]\n    x2_s = samples[:, 1]\n\n    # Evaluate the five test functions over the samples\n    f_values = [\n        x1_s,\n        x2_s,\n        x1_s * x2_s,\n        x1_s**2,\n        x2_s**2\n    ]\n\n    means = []\n    vars_of_mean = []\n\n    for f_vec in f_values:\n        # Overall sample mean\n        overall_mean = np.mean(f_vec)\n        means.append(overall_mean)\n\n        # Reshape for batching\n        reshaped_f = f_vec.reshape((M, B))\n        batch_means = np.mean(reshaped_f, axis=1)\n\n        # Variance of the sample mean using batch means\n        # This is Var(batch_means) / M\n        var_of_batch_means = np.var(batch_means, ddof=1)\n        var_of_mean = var_of_batch_means / M\n        vars_of_mean.append(var_of_mean)\n\n    return means, vars_of_mean\n\ndef run_coherence_diagnostic(params, settings):\n    \"\"\"\n    Performs the full coherence diagnostic for a single parameter set.\n    \"\"\"\n    rng = np.random.default_rng(settings['seed'])\n\n    # Run sampler for scan order 1-2\n    samples_12 = run_gibbs_sampler(params, settings, '12', rng)\n    means_12, vars_12 = calculate_stats(samples_12, settings)\n\n    # Run sampler for scan order 2-1\n    # Note: re-initialize rng for a fair comparison, although not strictly needed if runs are independent\n    rng = np.random.default_rng(settings['seed'])\n    samples_21 = run_gibbs_sampler(params, settings, '21', rng)\n    means_21, vars_21 = calculate_stats(samples_21, settings)\n\n    Z_scores = []\n    for k in range(5):  # For each of the five test functions\n        numerator = np.abs(means_12[k] - means_21[k])\n        denominator = np.sqrt(vars_12[k] + vars_21[k])\n        \n        if denominator == 0.0:\n            Z_k = 0.0 if numerator == 0.0 else np.inf\n        else:\n            Z_k = numerator / denominator\n        Z_scores.append(Z_k)\n    \n    max_Z = np.max(Z_scores)\n    return max_Z = settings['tau']\n\ndef solve():\n    # Define the fixed simulation settings\n    simulation_settings = {\n        'N_burn': 20000,\n        'N': 120000,\n        'B': 600,\n        'tau': 5.0,\n        'seed': 42 # Fixed seed for reproducibility\n    }\n\n    # Define the test cases from the problem statement.\n    # Case 1 (coherent)\n    c1_v1, c1_v2, c1_c = 1.5, 0.7, 0.6\n    c1_m1, c1_m2 = 0.5, -0.3\n    c1_a = c1_c / c1_v2\n    c1_b = c1_c / c1_v1\n    c1_s1 = np.sqrt(c1_v1 - c1_c**2 / c1_v2)\n    c1_s2 = np.sqrt(c1_v2 - c1_c**2 / c1_v1)\n    c1_mu1 = c1_m1 - c1_a * c1_m2\n    c1_mu2 = c1_m2 - c1_b * c1_m1\n    case1 = (c1_a, c1_b, c1_s1, c1_s2, c1_mu1, c1_mu2)\n\n    # Case 2 (incoherent)\n    case2 = (0.8, 0.2, 1.0, np.sqrt(0.9), 0.0, 0.0)\n\n    # Case 3 (incoherent by problem statement, analytically coherent)\n    case3 = (0.25, 0.5, np.sqrt(0.875), np.sqrt(1.75), 0.6, 1.5)\n\n    # Case 4 (coherent, near boundary)\n    a_b_4 = np.sqrt(0.95)\n    s_4 = np.sqrt(1.0 - 0.95)\n    case4 = (a_b_4, a_b_4, s_4, s_4, 0.0, 0.0)\n\n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for case in test_cases:\n        is_coherent = run_coherence_diagnostic(case, simulation_settings)\n        results.append(is_coherent)\n\n    # Final print statement in the exact required format.\n    # Note: Python's bool `True` will be stringified to 'True', which matches the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3297655"}]}