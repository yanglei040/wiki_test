{"hands_on_practices": [{"introduction": "这个练习是一个基础性训练。我们将从一个平稳ARMA(1,1)过程的定义方程出发，通过第一性原理推导出其有效样本量($n_{\\text{eff}}$)。这个过程将巩固你对模型参数、其自相关结构以及样本均值最终效率之间直接联系的理解。[@problem_id:3304666]", "problem": "考虑一个记为 $X_t$ 的一阶自回归移动平均严格平稳过程，由递推关系 $X_t = \\phi X_{t-1} + \\epsilon_t + \\theta \\epsilon_{t-1}$ 定义，其中 $|\\phi|1$，$\\{\\epsilon_t\\}$ 是一个均值为零、方差为 $\\sigma_{\\epsilon}^{2}$ 的独立同分布白噪声序列，且 $\\phi,\\theta \\in \\mathbb{R}$。设 $X_t$ 的均值为零。对于一个平稳过程，其自协方差函数为 $\\gamma_k = \\operatorname{Cov}(X_t,X_{t+k})$，自相关函数为 $\\rho_k = \\gamma_k/\\gamma_0$。积分自相关时间（IAT）定义为 $\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k$。对于均值的蒙特卡洛估计量 $\\bar{X}_n = \\frac{1}{n}\\sum_{t=1}^{n} X_t$，假设其方差可以写为 $\\operatorname{Var}(\\bar{X}_n) = \\operatorname{Var}(X_t)\\,\\tau_{\\mathrm{int}}/n = \\operatorname{Var}(X_t)/n_{\\mathrm{eff}}$，从而定义了有效样本量 $n_{\\mathrm{eff}}$。\n\n请仅从这些定义和给定的数据生成方程出发，不使用任何关于自回归移动平均过程的预先制定的公式，推导自相关函数 $\\rho_k$ 对所有整数 $k \\geq 1$ 的闭式表达式。然后，用它来获得 $\\tau_{\\mathrm{int}}$ 和 $n_{\\mathrm{eff}}$ 作为 $\\phi$、$\\theta$ 和 $n$ 的函数的闭式表达式。你的最终答案必须是 $\\tau_{\\mathrm{int}}$ 和 $n_{\\mathrm{eff}}$ 的闭式解析表达式；不要代入数值，也不要包含物理单位。如果可以进行任何简化，请给出简化后的形式。最终的方框答案应仅包含 $\\tau_{\\mathrm{int}}$ 和 $n_{\\mathrm{eff}}$ 的表达式（按此顺序），格式为行矩阵。无需四舍五入。", "solution": "这个问题是有效的，因为它具有科学依据、问题明确、客观且自洽。它提出了一个时间序列分析中的标准问题，没有任何事实错误、歧义或矛盾。因此，我们可以开始推导。\n\n目标是为给定的严格平稳 ARMA($1,1$) 过程推导自相关函数 ($\\rho_k$)、积分自相关时间 ($\\tau_{\\mathrm{int}}$) 和有效样本量 ($n_{\\mathrm{eff}}$)：\n$$\nX_t = \\phi X_{t-1} + \\epsilon_t + \\theta \\epsilon_{t-1}\n$$\n其中 $\\{\\epsilon_t\\}$ 是均值为零、方差为 $\\sigma_{\\epsilon}^{2}$ 的白噪声过程，并且 $|\\phi|1$。该过程的均值给定为 $\\operatorname{E}[X_t] = 0$。\n\n首先，我们推导自协方差函数 $\\gamma_k = \\operatorname{Cov}(X_t, X_{t+k}) = \\operatorname{E}[X_t X_{t+k}]$。\n\n**步骤1：计算方差 $\\gamma_0$。**\n方差为 $\\gamma_0 = \\operatorname{Var}(X_t) = \\operatorname{E}[X_t^2]$。使用过程的定义：\n$$\n\\gamma_0 = \\operatorname{E}[(\\phi X_{t-1} + \\epsilon_t + \\theta \\epsilon_{t-1})^2]\n$$\n展开平方并对每一项取期望：\n$$\n\\gamma_0 = \\operatorname{E}[\\phi^2 X_{t-1}^2 + \\epsilon_t^2 + \\theta^2 \\epsilon_{t-1}^2 + 2\\phi X_{t-1}\\epsilon_t + 2\\phi\\theta X_{t-1}\\epsilon_{t-1} + 2\\theta \\epsilon_t\\epsilon_{t-1}]\n$$\n我们利用过程的性质来计算每一项：\n- 根据平稳性，$\\operatorname{E}[X_{t-1}^2] = \\gamma_0$。\n- 根据白噪声的定义，$\\operatorname{E}[\\epsilon_t^2] = \\sigma_{\\epsilon}^2$ 且 $\\operatorname{E}[\\epsilon_{t-1}^2] = \\sigma_{\\epsilon}^2$。\n- $\\epsilon_t$ 与过程的过去值无关，所以 $\\operatorname{E}[X_{t-1}\\epsilon_t] = \\operatorname{E}[X_{t-1}]\\operatorname{E}[\\epsilon_t] = 0$。\n- $\\epsilon_t$ 和 $\\epsilon_{t-1}$ 不相关，所以 $\\operatorname{E}[\\epsilon_t\\epsilon_{t-1}] = 0$。\n- 为了计算 $\\operatorname{E}[X_{t-1}\\epsilon_{t-1}]$，我们代入 $X_{t-1}$ 的定义：\n$$\n\\operatorname{E}[X_{t-1}\\epsilon_{t-1}] = \\operatorname{E}[(\\phi X_{t-2} + \\epsilon_{t-1} + \\theta \\epsilon_{t-2})\\epsilon_{t-1}] = \\phi\\operatorname{E}[X_{t-2}\\epsilon_{t-1}] + \\operatorname{E}[\\epsilon_{t-1}^2] + \\theta\\operatorname{E}[\\epsilon_{t-2}\\epsilon_{t-1}] = 0 + \\sigma_{\\epsilon}^2 + 0 = \\sigma_{\\epsilon}^2\n$$\n将这些结果代回 $\\gamma_0$ 的表达式中：\n$$\n\\gamma_0 = \\phi^2\\gamma_0 + \\sigma_{\\epsilon}^2 + \\theta^2\\sigma_{\\epsilon}^2 + 0 + 2\\phi\\theta\\sigma_{\\epsilon}^2 + 0\n$$\n解出 $\\gamma_0$：\n$$\n\\gamma_0(1-\\phi^2) = \\sigma_{\\epsilon}^2(1 + \\theta^2 + 2\\phi\\theta)\n$$\n$$\n\\gamma_0 = \\sigma_{\\epsilon}^2 \\frac{1 + 2\\phi\\theta + \\theta^2}{1 - \\phi^2}\n$$\n\n**步骤2：计算滞后 $k=1$ 时的自协方差 $\\gamma_1$。**\n$$\n\\gamma_1 = \\operatorname{E}[X_t X_{t+1}] = \\operatorname{E}[X_t (\\phi X_t + \\epsilon_{t+1} + \\theta \\epsilon_t)]\n$$\n$$\n\\gamma_1 = \\phi\\operatorname{E}[X_t^2] + \\operatorname{E}[X_t\\epsilon_{t+1}] + \\theta\\operatorname{E}[X_t\\epsilon_t]\n$$\n- $\\operatorname{E}[X_t^2] = \\gamma_0$。\n- $\\epsilon_{t+1}$ 与 $X_t$ 无关，所以 $\\operatorname{E}[X_t\\epsilon_{t+1}] = 0$。\n- 使用与 $\\operatorname{E}[X_{t-1}\\epsilon_{t-1}]$ 相同的逻辑，我们发现 $\\operatorname{E}[X_t\\epsilon_t] = \\sigma_{\\epsilon}^2$。\n因此：\n$$\n\\gamma_1 = \\phi\\gamma_0 + \\theta\\sigma_{\\epsilon}^2\n$$\n\n**步骤3：计算滞后 $k \\geq 2$ 时的自协方差 $\\gamma_k$。**\n$$\n\\gamma_k = \\operatorname{E}[X_t X_{t+k}] = \\operatorname{E}[X_t (\\phi X_{t+k-1} + \\epsilon_{t+k} + \\theta \\epsilon_{t+k-1})]\n$$\n$$\n\\gamma_k = \\phi\\operatorname{E}[X_t X_{t+k-1}] + \\operatorname{E}[X_t\\epsilon_{t+k}] + \\theta\\operatorname{E}[X_t\\epsilon_{t+k-1}]\n$$\n- $\\operatorname{E}[X_t X_{t+k-1}] = \\gamma_{k-1}$。\n- 对于 $k \\geq 2$，$t+k$ 和 $t+k-1$ 都大于 $t$。因此，$\\epsilon_{t+k}$ 和 $\\epsilon_{t+k-1}$ 与 $X_t$ 无关。这意味着 $\\operatorname{E}[X_t\\epsilon_{t+k}] = 0$ 且 $\\operatorname{E}[X_t\\epsilon_{t+k-1}] = 0$。\n我们得到对于 $k \\geq 2$ 的递推关系：\n$$\n\\gamma_k = \\phi\\gamma_{k-1}\n$$\n\n**步骤4：推导自相关函数 $\\rho_k$。**\n自相关函数为 $\\rho_k = \\gamma_k/\\gamma_0$。\n对于 $k \\geq 2$，我们有 $\\rho_k = \\phi\\rho_{k-1}$。通过归纳，这意味着对于所有 $k \\geq 1$，都有 $\\rho_k = \\phi^{k-1}\\rho_1$。\n现在我们求 $\\rho_1$：\n$$\n\\rho_1 = \\frac{\\gamma_1}{\\gamma_0} = \\frac{\\phi\\gamma_0 + \\theta\\sigma_{\\epsilon}^2}{\\gamma_0} = \\phi + \\frac{\\theta\\sigma_{\\epsilon}^2}{\\gamma_0}\n$$\n代入 $\\gamma_0$ 的表达式：\n$$\n\\rho_1 = \\phi + \\frac{\\theta\\sigma_{\\epsilon}^2}{\\sigma_{\\epsilon}^2 \\frac{1 + 2\\phi\\theta + \\theta^2}{1 - \\phi^2}} = \\phi + \\frac{\\theta(1 - \\phi^2)}{1 + 2\\phi\\theta + \\theta^2}\n$$\n通分：\n$$\n\\rho_1 = \\frac{\\phi(1 + 2\\phi\\theta + \\theta^2) + \\theta(1 - \\phi^2)}{1 + 2\\phi\\theta + \\theta^2} = \\frac{\\phi + 2\\phi^2\\theta + \\phi\\theta^2 + \\theta - \\theta\\phi^2}{1 + 2\\phi\\theta + \\theta^2}\n$$\n$$\n\\rho_1 = \\frac{\\phi + \\theta + \\phi^2\\theta + \\phi\\theta^2}{1 + 2\\phi\\theta + \\theta^2} = \\frac{(\\phi + \\theta)(1 + \\phi\\theta)}{1 + 2\\phi\\theta + \\theta^2}\n$$\n所以，对于 $k \\geq 1$ 的自相关函数为：\n$$\n\\rho_k = \\phi^{k-1} \\left( \\frac{(\\phi + \\theta)(1 + \\phi\\theta)}{1 + 2\\phi\\theta + \\theta^2} \\right)\n$$\n\n**步骤5：推导积分自相关时间 $\\tau_{\\mathrm{int}}$。**\n定义为 $\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k$。\n该和是一个几何级数：\n$$\n\\sum_{k=1}^{\\infty} \\rho_k = \\sum_{k=1}^{\\infty} \\phi^{k-1}\\rho_1 = \\rho_1 \\sum_{j=0}^{\\infty} \\phi^j\n$$\n由于 $|\\phi|1$，级数收敛到 $1/(1-\\phi)$。\n$$\n\\sum_{k=1}^{\\infty} \\rho_k = \\frac{\\rho_1}{1-\\phi}\n$$\n将此代入 $\\tau_{\\mathrm{int}}$ 的定义中：\n$$\n\\tau_{\\mathrm{int}} = 1 + \\frac{2\\rho_1}{1-\\phi} = 1 + \\frac{2}{1-\\phi} \\frac{(\\phi + \\theta)(1 + \\phi\\theta)}{1 + 2\\phi\\theta + \\theta^2}\n$$\n为简化，我们合并各项：\n$$\n\\tau_{\\mathrm{int}} = \\frac{(1-\\phi)(1 + 2\\phi\\theta + \\theta^2) + 2(\\phi + \\theta)(1 + \\phi\\theta)}{(1-\\phi)(1 + 2\\phi\\theta + \\theta^2)}\n$$\n让我们展开分子：\n$$\n(1 - \\phi + 2\\phi\\theta - 2\\phi^2\\theta + \\theta^2 - \\phi\\theta^2) + (2\\phi + 2\\phi^2\\theta + 2\\theta + 2\\phi\\theta^2)\n$$\n$$\n= 1 + (2\\phi\\theta + 2\\theta) + \\theta^2 + (-\\phi+2\\phi) + (-2\\phi^2\\theta+2\\phi^2\\theta) + (-\\phi\\theta^2+2\\phi\\theta^2)\n$$\n$$\n= 1 + 2\\theta + \\theta^2 + \\phi + 2\\phi\\theta + \\phi\\theta^2\n$$\n这可以因式分解为：\n$$\n(1+2\\theta+\\theta^2) + \\phi(1+2\\theta+\\theta^2) = (1+\\phi)(1+2\\theta+\\theta^2) = (1+\\phi)(1+\\theta)^2\n$$\n因此，$\\tau_{\\mathrm{int}}$ 的简化表达式为：\n$$\n\\tau_{\\mathrm{int}} = \\frac{(1+\\phi)(1+\\theta)^2}{(1-\\phi)(1 + 2\\phi\\theta + \\theta^2)}\n$$\n\n**步骤6：推导有效样本量 $n_{\\mathrm{eff}}$。**\n问题定义了 $n_{\\mathrm{eff}} = n / \\tau_{\\mathrm{int}}$。代入 $\\tau_{\\mathrm{int}}$ 的表达式：\n$$\nn_{\\mathrm{eff}} = n \\frac{1}{\\tau_{\\mathrm{int}}} = n \\frac{(1-\\phi)(1 + 2\\phi\\theta + \\theta^2)}{(1+\\phi)(1+\\theta)^2}\n$$\n这些就是所求的闭式表达式。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{(1+\\phi)(1+\\theta)^2}{(1-\\phi)(1 + 2\\phi\\theta + \\theta^2)}  n \\frac{(1-\\phi)(1+2\\phi\\theta+\\theta^2)}{(1+\\phi)(1+\\theta)^2} \\end{pmatrix}}\n$$", "id": "3304666"}, {"introduction": "在我们掌握了计算ESS的方法之后，这个练习将展示我们如何能主动地去提升它。我们将探索一种应用于AR(1)过程的控制变量技术，并展示一个巧妙的变换如何能显著降低自相关性。这个实践突出表明，ESS不仅仅是一个被动的诊断指标，更是我们可以通过巧妙的算法设计来优化的一个量。[@problem_id:3304651]", "problem": "考虑一个平稳的一阶高斯自回归 (AR(1)) 过程 $\\{X_t\\}_{t \\geq 0}$，其均值为零，边际方差为 $\\operatorname{Var}(X_t)=\\sigma^{2}$，对于滞后 $k \\geq 0$，其自相关函数为 $\\rho_{X}(k)=\\rho^{k}$，其中 $|\\rho|1$。在迭代 $t$ 次时的蒙特卡罗估计量是标量 $X_t$。现在，你应用一个使用滞后值 $X_{t-1}$ 的控制变量来构造一个新的估计量序列\n$$\nY_t \\;=\\; s\\,\\big(X_t - \\lambda X_{t-1}\\big),\n$$\n其中选择 $s \\in \\mathbb{R}$ 使得对于所有 $\\lambda \\in \\mathbb{R}$ 的选择，都有 $\\operatorname{Var}(Y_t)=\\operatorname{Var}(X_t)=\\sigma^{2}$。这个控制变量不改变边际方差，但通过 $\\lambda$ 在连续的估计量之间引入相关性，从而改变了时间上的依赖结构。\n\n从自协方差函数和积分自相关时间 (IAT) 的定义出发，并且只使用平稳性和 AR(1) 依赖结构，当选择 $\\lambda$ 等于 AR(1) 系数 $\\rho$ 时，推导有效样本量 (ESS) 改善的闭式因子。将你的最终答案表示为 $\\rho$ 的单个解析函数，记为 $\\mathcal{F}(\\rho)=\\mathcal{E}_{\\text{new}}/\\mathcal{E}_{\\text{old}}$，其中 $\\mathcal{E}_{\\text{old}}$ 是原始序列 $\\{X_t\\}$ 的 ESS，而 $\\mathcal{E}_{\\text{new}}$ 是当 $\\lambda=\\rho$ 时变换后序列 $\\{Y_t\\}$ 的 ESS。", "solution": "该问题要求推导当一个特定的控制变量应用于平稳 AR(1) 过程时，有效样本量 (ESS) 的改善因子。该改善因子定义为比率 $\\mathcal{F}(\\rho) = \\mathcal{E}_{\\text{new}}/\\mathcal{E}_{\\text{old}}$。\n\n对于一个包含 $N$ 个相关样本的序列，其有效样本量 $\\mathcal{E}$ 由 $\\mathcal{E} = N / \\tau$ 给出，其中 $\\tau$ 是积分自相关时间 (IAT)。IAT 用自相关函数 (ACF) $\\rho(k)$ 定义为：\n$$\n\\tau = 1 + 2 \\sum_{k=1}^{\\infty} \\rho(k)\n$$\n因此，改善因子可以表示为原始序列和变换后序列的 IAT 之比：\n$$\n\\mathcal{F}(\\rho) = \\frac{\\mathcal{E}_{\\text{new}}}{\\mathcal{E}_{\\text{old}}} = \\frac{N / \\tau_{\\text{new}}}{N / \\tau_{\\text{old}}} = \\frac{\\tau_{\\text{old}}}{\\tau_{\\text{new}}}\n$$\n我们的任务简化为计算序列 $\\{X_t\\}$ 的 $\\tau_{\\text{old}}$ 和序列 $\\{Y_t\\}$ 的 $\\tau_{\\text{new}}$。\n\n首先，我们计算原始 AR(1) 序列 $\\{X_t\\}$ 的 IAT。问题陈述其 ACF 对于 $k \\geq 0$ 是 $\\rho_X(k) = \\rho^k$。使用 IAT 的定义，我们有：\n$$\n\\tau_{\\text{old}} = \\tau_X = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_X(k) = 1 + 2 \\sum_{k=1}^{\\infty} \\rho^k\n$$\n这个和是一个几何级数。由于 $|\\rho|1$，该级数收敛：\n$$\n\\sum_{k=1}^{\\infty} \\rho^k = \\frac{\\rho}{1-\\rho}\n$$\n将此代入 $\\tau_{\\text{old}}$ 的表达式中，得到：\n$$\n\\tau_{\\text{old}} = 1 + 2 \\frac{\\rho}{1-\\rho} = \\frac{1-\\rho + 2\\rho}{1-\\rho} = \\frac{1+\\rho}{1-\\rho}\n$$\n接下来，我们分析变换后的序列 $\\{Y_t\\}$ 以找到其 IAT，$\\tau_{\\text{new}}$。该序列定义为 $Y_t = s(X_t - \\lambda X_{t-1})$，并特别选择 $\\lambda = \\rho$。\n$$\nY_t = s(X_t - \\rho X_{t-1})\n$$\n一个均值为零、ACF 为 $\\rho_X(k)=\\rho^k$ 的平稳 AR(1) 过程 $\\{X_t\\}$ 由以下随机差分方程定义：\n$$\nX_t = \\rho X_{t-1} + \\epsilon_t\n$$\n其中 $\\{\\epsilon_t\\}$ 是一个不相关的（白噪声）随机变量序列，其均值为零 $\\mathbb{E}[\\epsilon_t]=0$，且方差恒为 $\\operatorname{Var}(\\epsilon_t) = \\sigma_\\epsilon^2$。变量 $\\epsilon_t$ 也与过程的过去值不相关，即对于 $j>0$ 有 $\\operatorname{Cov}(\\epsilon_t, X_{t-j})=0$。\n\n$X_t$ 的方差是 $\\sigma^2$。从定义方程，我们有：\n$$\n\\operatorname{Var}(X_t) = \\operatorname{Var}(\\rho X_{t-1} + \\epsilon_t) = \\rho^2 \\operatorname{Var}(X_{t-1}) + \\operatorname{Var}(\\epsilon_t)\n$$\n由于过程是平稳的，$\\operatorname{Var}(X_t) = \\operatorname{Var}(X_{t-1}) = \\sigma^2$。这得出：\n$$\n\\sigma^2 = \\rho^2 \\sigma^2 + \\sigma_\\epsilon^2 \\implies \\sigma_\\epsilon^2 = \\sigma^2(1-\\rho^2)\n$$\n现在，我们将 AR(1) 过程的定义代入 $Y_t$ 的表达式中：\n$$\nY_t = s(X_t - \\rho X_{t-1}) = s((\\rho X_{t-1} + \\epsilon_t) - \\rho X_{t-1}) = s \\epsilon_t\n$$\n这揭示了变换后的序列 $\\{Y_t\\}$ 只是白噪声新息过程 $\\{\\epsilon_t\\}$ 的一个按比例缩放的版本。问题陈述要求 $\\operatorname{Var}(Y_t) = \\sigma^2$。让我们验证缩放因子 $s$：\n$$\n\\operatorname{Var}(Y_t) = \\operatorname{Var}(s \\epsilon_t) = s^2 \\operatorname{Var}(\\epsilon_t) = s^2 \\sigma^2 (1-\\rho^2)\n$$\n设 $\\operatorname{Var}(Y_t) = \\sigma^2$，我们得到 $s^2 \\sigma^2 (1-\\rho^2) = \\sigma^2$，这意味着 $s^2 = \\frac{1}{1-\\rho^2}$。这证实了这样一个缩放因子 $s$ 的存在。\n\n为了计算 $\\tau_{\\text{new}}$，我们需要序列 $\\{Y_t\\}$ 的 ACF，即 $\\rho_Y(k)$。ACF 定义为 $\\rho_Y(k) = \\frac{\\operatorname{Cov}(Y_t, Y_{t-k})}{\\operatorname{Var}(Y_t)}$。我们先验地知道 $\\operatorname{Var}(Y_t)=\\sigma^2$。对于滞后 $k \\geq 1$ 的自协方差是：\n$$\n\\operatorname{Cov}(Y_t, Y_{t-k}) = \\operatorname{Cov}(s \\epsilon_t, s \\epsilon_{t-k}) = s^2 \\operatorname{Cov}(\\epsilon_t, \\epsilon_{t-k})\n$$\n由于 $\\{\\epsilon_t\\}$ 是一个白噪声过程，其元素在时间上是不相关的。因此，对于任何 $k \\geq 1$：\n$$\n\\operatorname{Cov}(\\epsilon_t, \\epsilon_{t-k}) = 0\n$$\n这意味着对于所有 $k \\ge 1$，都有 $\\operatorname{Cov}(Y_t, Y_{t-k})=0$。因此，序列 $\\{Y_t\\}$ 的 ACF 是：\n$$\n\\rho_Y(k) = \\frac{0}{\\sigma^2} = 0 \\quad \\text{for all } k \\geq 1\n$$\n序列 $\\{Y_t\\}$ 是不相关的。现在我们可以计算其 IAT，$\\tau_{\\text{new}}$：\n$$\n\\tau_{\\text{new}} = \\tau_Y = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_Y(k) = 1 + 2 \\sum_{k=1}^{\\infty} 0 = 1\n$$\n新序列的 IAT 是 $1$，这是理论上的最小值，对应于一个由独立样本组成的序列。\n\n最后，我们计算改善因子 $\\mathcal{F}(\\rho)$：\n$$\n\\mathcal{F}(\\rho) = \\frac{\\tau_{\\text{old}}}{\\tau_{\\text{new}}} = \\frac{\\frac{1+\\rho}{1-\\rho}}{1} = \\frac{1+\\rho}{1-\\rho}\n$$\n这就是有效样本量改善的闭式因子。通过将相关序列 $\\{X_t\\}$ 变换为不相关序列 $\\{Y_t\\}$，当 $\\lambda=\\rho$ 时，控制变量技术在固定样本数 $N$ 的情况下最大化了有效样本量。", "answer": "$$\n\\boxed{\\frac{1+\\rho}{1-\\rho}}\n$$", "id": "3304651"}, {"introduction": "这最后一个练习将我们对ESS的理论理解带入充满计算约束的现实世界。我们将建立一个模型，用以权衡调整MCMC算法所带来的统计效率增益与运行它所需的时间成本。这个练习旨在解决一个终极的实际问题：如何最大化每秒钟产生的有效样本数量，这是任何随机模拟实践者的关键技能。[@problem_id:3304672]", "problem": "考虑一类生成自相关样本的马尔可夫链蒙特卡洛 (MCMC) 算法。对于给定的算法配置，定义一个参数向量 $\\theta$，该向量包含算法步长 $\\varepsilon$ 和在计算硬件上并发执行的并行链数量 $p$。假设每条链都是平稳的，其均值为 $0$，方差为 $\\sigma^2$，且其滞后-$k$ 自相关表示为 $r(k)$。进一步假设，每条链的动力学可以由一阶自回归过程很好地近似，因此存在一个相关系数 $\\rho(\\varepsilon)$，对于所有整数 $k \\ge 0$，满足 $r(k) = \\rho(\\varepsilon)^k$，其中 $0  \\rho(\\varepsilon)  1$。\n\n将每条链的总迭代次数定义为 $N$，并考虑并行运行 $p$ 条独立的链，从而在每次全局迭代（每条链前进一步）中生成的样本总数为 $p$。硬件以非完美扩展的方式并发执行这 $p$ 条链的更新。将每条链的计算时间建模为步长的增函数\n$$\nt_{\\text{chain}}(\\varepsilon) = t_0 + t_1 \\varepsilon^2,\n$$\n其中 $t_0$ 和 $t_1$ 是以秒为单位的正常量。通过一个阿姆达尔式表达式来建模并行加速比\n$$\nS(p) = \\frac{p}{1 + \\kappa (p - 1)},\n$$\n其中 $\\kappa  0$ 量化了不可并行化工作的比例。将额外开销建模为\n$$\n\\text{overhead}(p) = \\eta (p - 1)^2,\n$$\n其中 $\\eta  0$ 以秒/全局迭代为单位。那么，每次全局迭代（每条链并行地前进一步）的总墙上时间成本为\n$$\nc(\\varepsilon,p) = \\frac{t_{\\text{chain}}(\\varepsilon)\\, p}{S(p)} + \\text{overhead}(p),\n$$\n以秒为单位表示。\n\n从第一性原理以及时间序列中自协方差和自相关的核心定义出发，推导一条链在 $N$ 次迭代后实现的有效样本量 (ESS) 作为 $\\rho(\\varepsilon)$ 的函数，并将其扩展到 $p$ 条独立的链。推导必须从样本均值方差（用自协方差函数和自相关函数表示）的定义开始，并逻辑地进行，以确定积分自相关时间和最终的有效样本量。使用该推导构建一个程序，对于下方的每个测试用例，评估目标\n$$\n\\max_{\\varepsilon \\in \\mathcal{E},\\, p \\in \\mathcal{P}} \\frac{\\text{ESS}(\\varepsilon,p)}{c(\\varepsilon,p)},\n$$\n其中 $\\mathcal{E}$ 是候选步长的有限集，$\\mathcal{P}$ 是候选线程数的有限集。$\\rho(\\varepsilon)$ 的参数化由下式给出\n$$\n\\rho(\\varepsilon) = \\exp(-\\alpha \\varepsilon),\n$$\n其中每个测试用例均提供 $\\alpha  0$。\n\n您的程序必须：\n- 使用自相关结构 $r(k) = \\rho(\\varepsilon)^k$ 实现基于推导的 $\\text{ESS}(\\varepsilon,p)$ 公式。\n- 对于提供的测试套件中的每一对 $(\\varepsilon,p)$，计算 $\\text{ESS}(\\varepsilon,p) / c(\\varepsilon,p)$。\n- 选择获得最大比率的最优解 $(\\varepsilon^\\star, p^\\star)$。如果有多对参数达到相同的最大值（在 $10^{-12}$ 的数值容差范围内），则选择 $p$ 最小的那一对；如果仍然持平，则选择 $\\varepsilon$ 最小的那一对。\n- 对于每个测试用例，输出一个列表，其中包含 $[\\varepsilon^\\star, p^\\star, \\text{ESS-per-second}^\\star]$，其中 $\\text{ESS-per-second}^\\star = \\text{ESS}(\\varepsilon^\\star,p^\\star) / c(\\varepsilon^\\star,p^\\star)$ 以样本/秒为单位。报告 $\\varepsilon^\\star$ 时四舍五入到小数点后 $3$ 位，报告 $\\text{ESS-per-second}^\\star$ 时四舍五入到小数点后 $6$ 位。线程数 $p^\\star$ 是一个整数。\n\n物理和数值单位：\n- 时间量 $t_0$、$t_1$ 和 $\\eta$ 的单位是秒。\n- 目标比率 $\\text{ESS}(\\varepsilon,p) / c(\\varepsilon,p)$ 必须以样本/秒（一个浮点数）为单位报告。\n\n角度单位不适用。最终答案中不出现百分比。\n\n测试套件：\n- 用例 $1$ (理想情况):\n    - $N = 10000$, $\\alpha = 3.0$, $t_0 = 1\\times 10^{-4}$, $t_1 = 5\\times 10^{-4}$, $\\kappa = 0.15$, $\\eta = 2\\times 10^{-5}$,\n    - $\\mathcal{E} = \\{0.02, 0.05, 0.10, 0.20, 0.40\\}$,\n    - $\\mathcal{P} = \\{1, 2, 4, 8, 16\\}$。\n- 用例 $2$ (扩展受限且开销高):\n    - $N = 10000$, $\\alpha = 1.0$, $t_0 = 5\\times 10^{-4}$, $t_1 = 1\\times 10^{-4}$, $\\kappa = 0.5$, $\\eta = 1\\times 10^{-4}$,\n    - $\\mathcal{E} = \\{0.01, 0.03, 0.05, 0.10, 0.20, 0.30\\}$,\n    - $\\mathcal{P} = \\{1, 2, 3, 4, 6, 8\\}$。\n- 用例 $3$ (近乎理想的扩展和快速去相关):\n    - $N = 20000$, $\\alpha = 5.0$, $t_0 = 1\\times 10^{-4}$, $t_1 = 1\\times 10^{-4}$, $\\kappa = 0.05$, $\\eta = 5\\times 10^{-6}$,\n    - $\\mathcal{E} = \\{0.05, 0.10, 0.20, 0.40, 0.80\\}$,\n    - $\\mathcal{P} = \\{1, 2, 4, 8, 16, 32\\}$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由逗号分隔的列表，用方括号括起来，没有多余的空格。例如，输出应如下所示\n$$\n[\\,[\\varepsilon_1^\\star,p_1^\\star,\\text{ESSperSec}_1^\\star],\\,[\\varepsilon_2^\\star,p_2^\\star,\\text{ESSperSec}_2^\\star],\\,[\\varepsilon_3^\\star,p_3^\\star,\\text{ESSperSec}_3^\\star]\\,],\n$$\n其中每个内部列表对应一个测试用例，按用例 1、用例 2、用例 3 的顺序排列。", "solution": "**问题验证**\n\n问题陈述已经过评估，并被确定为**有效**。它在科学上基于马尔可夫链蒙特卡洛 (MCMC) 方法、统计时间序列分析和计算性能建模的原理。该问题是适定 (well-posed) 的，具有在有限参数集上最大化的明确定义的目标函数，并包含一个特定的决胜规则以确保解的唯一性。所有必要的参数和模型都已明确提供，问题没有歧义、矛盾或主观内容。\n\n**推导与求解方法**\n\n目标是最大化有效样本量 (ESS) 与计算成本的比率。我们首先按要求从第一性原理推导 ESS 的公式。\n\n设 $\\{X_i\\}_{i=1}^N$ 是来自单个平稳马尔可夫链的 $N$ 个样本序列，其均值为 $\\mathbb{E}[X_i] = 0$，方差为 $\\text{Var}(X_i) = \\sigma^2$。样本均值为 $\\hat{\\mu}_N = \\frac{1}{N}\\sum_{i=1}^N X_i$。\n\n样本均值的方差由下式给出：\n$$ \\text{Var}(\\hat{\\mu}_N) = \\text{Var}\\left(\\frac{1}{N}\\sum_{i=1}^N X_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N \\text{Cov}(X_i, X_j) $$\n对于一个平稳过程，自协方差 $\\gamma(k) = \\text{Cov}(X_i, X_{i+k})$ 仅取决于滞后 $k$。此外，$\\gamma(k) = \\gamma(-k)$ 且 $\\gamma(0) = \\sigma^2$。双重求和可以通过 $k=j-i$ 重新索引：\n$$ \\text{Var}(\\hat{\\mu}_N) = \\frac{1}{N^2} \\sum_{k=-(N-1)}^{N-1} (N-|k|) \\gamma(k) $$\n利用 $\\gamma(k)$ 的对称性并用自相关函数 $r(k) = \\gamma(k)/\\gamma(0)$ 来表示它，我们得到：\n$$ \\text{Var}(\\hat{\\mu}_N) = \\frac{\\sigma^2}{N} \\left[ 1 + 2 \\sum_{k=1}^{N-1} \\left(1-\\frac{k}{N}\\right) r(k) \\right] $$\n当样本数量 $N$ 远大于链的相关长度时，该表达式可以通过用无穷和代替有限和并舍去 $(1-k/N)$ 项来很好地近似：\n$$ \\text{Var}(\\hat{\\mu}_N) \\approx \\frac{\\sigma^2}{N} \\left[ 1 + 2 \\sum_{k=1}^{\\infty} r(k) \\right] $$\n有效样本量 $N_{\\text{eff}}$ 定义为能够在其样本均值中产生相同方差的独立同分布 (i.i.d.) 样本的大小，即 $\\text{Var}(\\hat{\\mu}_{N_{\\text{eff}}}^{\\text{iid}}) = \\sigma^2/N_{\\text{eff}}$。将其与自相关链的方差相等，可得：\n$$ \\frac{\\sigma^2}{N_{\\text{eff}}} = \\frac{\\sigma^2}{N} \\left[ 1 + 2 \\sum_{k=1}^{\\infty} r(k) \\right] $$\n这给出了单条链的 ESS 定义：\n$$ N_{\\text{eff}} = \\frac{N}{1 + 2 \\sum_{k=1}^{\\infty} r(k)} = \\frac{N}{\\tau} $$\n其中 $\\tau = 1 + 2 \\sum_{k=1}^{\\infty} r(k)$ 是积分自相关时间 (IACT)。\n\n问题为链的自相关结构指定了一个 AR(1) 过程，$r(k) = \\rho(\\varepsilon)^k$（对于 $k \\ge 0$），其中 $\\rho(\\varepsilon)$ 是依赖于步长 $\\varepsilon$ 的滞后-1 自相关。给定 $0  \\rho(\\varepsilon)  1$，无穷和是一个收敛的几何级数：\n$$ \\sum_{k=1}^{\\infty} \\rho(\\varepsilon)^k = \\frac{\\rho(\\varepsilon)}{1-\\rho(\\varepsilon)} $$\n将此代入 $\\tau$ 的表达式中：\n$$ \\tau(\\varepsilon) = 1 + 2 \\frac{\\rho(\\varepsilon)}{1-\\rho(\\varepsilon)} = \\frac{1-\\rho(\\varepsilon) + 2\\rho(\\varepsilon)}{1-\\rho(\\varepsilon)} = \\frac{1+\\rho(\\varepsilon)}{1-\\rho(\\varepsilon)} $$\n因此，长度为 $N$ 的单条链的 ESS 为：\n$$ \\text{ESS}_{\\text{single}}(N, \\varepsilon) = \\frac{N}{\\tau(\\varepsilon)} = N \\frac{1-\\rho(\\varepsilon)}{1+\\rho(\\varepsilon)} $$\n由于我们运行 $p$ 条独立的链，总 ESS 是每条链 ESS 的总和。由于假设所有链都具有相同的统计特性，总 ESS 为：\n$$ \\text{ESS}(\\varepsilon, p) = p \\times \\text{ESS}_{\\text{single}}(N, \\varepsilon) = p N \\frac{1-\\rho(\\varepsilon)}{1+\\rho(\\varepsilon)} $$\n\n目标是最大化总 ESS 与每次全局迭代的计算成本 $c(\\varepsilon,p)$ 的比率。问题陈述的目标是最大化 $\\text{ESS}(\\varepsilon,p) / c(\\varepsilon,p)$。尽管 $\\text{ESS}$ 是 $N$ 次迭代的总量，而 $c$ 是每次迭代的成本，但最大化这个量等同于最大化 ESS 的生成速率，因为对于给定的测试用例，因子 $N$ 是恒定的。\n\n要最大化的完整目标函数是：\n$$ f(\\varepsilon, p) = \\frac{\\text{ESS}(\\varepsilon,p)}{c(\\varepsilon,p)} $$\n其中各组成部分由以下公式给出：\n1.  **相关系数**: $\\rho(\\varepsilon) = \\exp(-\\alpha \\varepsilon)$\n2.  **有效样本量**: $\\text{ESS}(\\varepsilon, p) = p N \\frac{1 - \\exp(-\\alpha \\varepsilon)}{1 + \\exp(-\\alpha \\varepsilon)}$\n3.  **每次全局迭代的成本**: $c(\\varepsilon,p) = \\frac{t_{\\text{chain}}(\\varepsilon)\\, p}{S(p)} + \\text{overhead}(p)$，简化为：\n    $$ c(\\varepsilon, p) = (t_0 + t_1 \\varepsilon^2) (1 + \\kappa(p-1)) + \\eta(p-1)^2 $$\n\n程序必须找到一对 $(\\varepsilon^\\star, p^\\star)$，使得对于 $\\varepsilon \\in \\mathcal{E}$ 和 $p \\in \\mathcal{P}$， $f(\\varepsilon, p)$ 最大化，其中 $\\mathcal{E}$ 和 $\\mathcal{P}$ 是为每个测试用例提供的步长和线程数的有限集。\n\n优化通过在笛卡尔积 $\\mathcal{E} \\times \\mathcal{P}$ 中的所有对 $(\\varepsilon, p)$ 上进行网格搜索来执行。对于每一对，我们计算目标函数 $f(\\varepsilon, p)$。在开始搜索之前，候选集 $\\mathcal{E}$ 和 $\\mathcal{P}$ 按升序排序。我们维护当前找到的最佳参数 $(\\varepsilon^\\star, p^\\star)$ 和相应的最大值 $f^\\star$。如果一对新的 $(\\varepsilon,p)$ 的目标值严格大于 $f^\\star$（超过 $10^{-12}$ 的数值容差），它将取代当前的最优值。由于排序后的迭代顺序，首次找到最大值时，它将对应于最小的 $p$，以及在该 $p$ 值下最小的 $\\varepsilon$。任何后续达到相同值的对都将具有更大的 $p$ 或 $\\varepsilon$，因此将被正确忽略，从而满足决胜规则。\n\n每个测试用例的最终输出是一个列表，包含最优步长 $\\varepsilon^\\star$（四舍五入到小数点后 3 位）、最优链数 $p^\\star$（作为整数）以及最大目标值 $f(\\varepsilon^\\star, p^\\star)$（四舍五入到小数点后 6 位）。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the MCMC optimization problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path)\n        {\n            \"N\": 10000, \"alpha\": 3.0, \"t0\": 1e-4, \"t1\": 5e-4, \"kappa\": 0.15, \"eta\": 2e-5,\n            \"E_set\": [0.02, 0.05, 0.10, 0.20, 0.40],\n            \"P_set\": [1, 2, 4, 8, 16]\n        },\n        # Case 2 (limited scaling and high overhead)\n        {\n            \"N\": 10000, \"alpha\": 1.0, \"t0\": 5e-4, \"t1\": 1e-4, \"kappa\": 0.5, \"eta\": 1e-4,\n            \"E_set\": [0.01, 0.03, 0.05, 0.10, 0.20, 0.30],\n            \"P_set\": [1, 2, 3, 4, 6, 8]\n        },\n        # Case 3 (near-ideal scaling and fast decorrelation)\n        {\n            \"N\": 20000, \"alpha\": 5.0, \"t0\": 1e-4, \"t1\": 1e-4, \"kappa\": 0.05, \"eta\": 5e-6,\n            \"E_set\": [0.05, 0.10, 0.20, 0.40, 0.80],\n            \"P_set\": [1, 2, 4, 8, 16, 32]\n        }\n    ]\n\n    results = []\n    \n    TOL = 1e-12\n\n    for case in test_cases:\n        N = case[\"N\"]\n        alpha = case[\"alpha\"]\n        t0 = case[\"t0\"]\n        t1 = case[\"t1\"]\n        kappa = case[\"kappa\"]\n        eta = case[\"eta\"]\n        E_set = sorted(case[\"E_set\"])\n        P_set = sorted(case[\"P_set\"])\n\n        best_eps_star = -1.0\n        best_p_star = -1\n        max_ratio = -1.0\n\n        for p in P_set:\n            for eps in E_set:\n                # Calculate the correlation parameter rho\n                rho = np.exp(-alpha * eps)\n                \n                # Calculate the total Effective Sample Size (ESS)\n                # ESS is calculated for p independent chains, each of length N\n                if abs(1.0 + rho)  1e-15: # Avoid division by zero\n                    ess_factor = (1.0 - rho) / (1.0 + rho)\n                    ess = p * N * ess_factor\n                else: \n                    ess = 0.0\n\n                # Calculate the total wall-time cost per global iteration, c(eps, p)\n                cost_per_iter = (t0 + t1 * eps**2) * (1.0 + kappa * (p - 1.0)) + eta * (p - 1.0)**2\n                \n                # Calculate the objective function: ESS-per-cost-unit\n                if cost_per_iter  1e-15: # Avoid division by zero\n                    current_ratio = ess / cost_per_iter\n                else:\n                    current_ratio = 0.0\n\n                # Apply maximization and tie-breaking rules.\n                # By iterating through p and eps in sorted order, the first time we\n                # find a new maximum, it will be at the combination with the smallest\n                # p, and for that p, the smallest eps. Subsequent ties will be ignored.\n                if current_ratio  max_ratio + TOL:\n                    max_ratio = current_ratio\n                    best_eps_star = eps\n                    best_p_star = p\n        \n        # Format results as specified for the final output\n        # Round eps_star to 3 decimal places\n        # Round ess_per_second_star to 6 decimal places\n        # p_star is an integer\n        formatted_eps = round(best_eps_star, 3)\n        formatted_ratio = round(max_ratio, 6)\n        \n        results.append([formatted_eps, best_p_star, formatted_ratio])\n\n    # Construct the final output string exactly as specified.\n    inner_lists = [f\"[{e},{p},{r}]\" for e, p, r in results]\n    print(f\"[{','.join(inner_lists)}]\")\n\nsolve()\n```", "id": "3304672"}]}