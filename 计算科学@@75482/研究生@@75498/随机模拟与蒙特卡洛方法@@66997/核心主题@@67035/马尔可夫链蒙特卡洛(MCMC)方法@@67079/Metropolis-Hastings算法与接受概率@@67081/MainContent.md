## 引言
Metropolis-Hastings (MH) 算法是现代[计算统计学](@entry_id:144702)和[随机模拟](@entry_id:168869)领域的基石，它为从复杂高维[概率分布](@entry_id:146404)中进行抽样提供了一种通用而强大的解决方案。在许多科学与工程问题中，尤其是在[贝叶斯推断](@entry_id:146958)中，我们感兴趣的目标分布（如[后验分布](@entry_id:145605)）往往形式复杂，其归一化常数难以计算，这使得直接抽样变得不可能。MH算法巧妙地解决了这一知识鸿沟，它构建了一个马尔可夫链，其样本最终会收敛并代表目标分布，而无需知道其归一化形式。

本文旨在系统性地剖析[Metropolis-Hastings算法](@entry_id:146870)。您将学习到：

在“原则与机制”一章中，我们将从细致平稳条件这一第一性原理出发，详细推导MH算法的构造及其核心组件——接受概率，并探讨不同[提议分布](@entry_id:144814)如何影响算法的性能。

接着，在“应用与跨学科联系”一章中，我们将展示该算法如何在统计物理、[全局优化](@entry_id:634460)、[计算生物学](@entry_id:146988)等多个学科中发挥作用，揭示其强大的实践生命力。

最后，“动手实践”部分将通过具体的编程练习，帮助您巩固理论知识，掌握在约束空间和复杂场景下实现和优化MH算法的实用技能。

现在，让我们首先深入其核心，揭示支撑这一强大工具的数学原理和精妙机制。

## 原则与机制

在上一章中，我们介绍了[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）方法的基本思想，即通过构建一个[马尔可夫链](@entry_id:150828)，使其[平稳分布](@entry_id:194199)是我们感兴趣的目标分布 $\pi(x)$，然后通过模拟这条链来生成来自 $\pi(x)$ 的样本。本章我们将深入探讨实现这一目标的最核心和最广泛使用的算法之一：Metropolis-Hastings (MH) 算法。我们将从其基本原理——细致平稳条件出发，系统地推导其构造机制，并探讨不同类型的提议分布如何影响算法的性能和具体形式。

### 核心原理：通过细致平稳条件确保[目标分布](@entry_id:634522)

MCMC 方法成功的关键在于构建一个正确的转移核（Transition Kernel）$P(y|x)$，它描述了从当前状态 $x$ 转移到下一个状态 $y$ 的概率。为了使马尔可夫链的平稳分布为目标分布 $\pi(x)$，一个充分而非必要条件是转移核满足**细致平稳条件**（Detailed Balance Condition），也称为可逆性（Reversibility）。

对于[离散状态空间](@entry_id:146672)（[@problem_id:3355565]），细致平稳条件要求对于任意两个状态 $x$ 和 $y$，状态间双向流动的速率相等：
$$
\pi(x) P(y|x) = \pi(y) P(x|y)
$$
其中，$P(y|x)$ 是从状态 $x$ 转移到状态 $y$ 的概率。对于[连续状态空间](@entry_id:276130)，该条件以[概率密度](@entry_id:175496)的形式表示：
$$
\pi(x) p(y|x) = \pi(y) p(x|y)
$$
其中 $p(y|x)$ 是转移核的密度函数。满足细致平稳条件的[马尔可夫链](@entry_id:150828)，其平稳分布必然是 $\pi(x)$。这个条件为我们设计算法提供了一个明确的、可操作的目标。

### Metropolis-Hastings 的构造方法

Metropolis-Hastings 算法的精妙之处在于，它将复杂的转移过程 $P(y|x)$ 分解为两个更简单的步骤：**提议**（Proposal）和**接受-拒绝**（Acceptance-Rejection）。

1.  **提议**：在当前状态 $x$ 下，我们根据一个**[提议分布](@entry_id:144814)**（Proposal Distribution）$q(y|x)$ 生成一个候选状态 $y$。这个[提议分布](@entry_id:144814)可以是我们根据问题特性设计的任何[分布](@entry_id:182848)。

2.  **接受-拒绝**：计算一个**[接受概率](@entry_id:138494)** $\alpha(x,y) \in [0,1]$。然后，以概率 $\alpha(x,y)$ 接受该提议，即令下一个状态为 $y$；否则，以概率 $1-\alpha(x,y)$ 拒绝该提议，并令下一个状态仍然为 $x$。

综合这两个步骤，对于 $x \neq y$，从 $x$ 转移到 $y$ 的整体转移概率密度为提议概率密度与接受概率的乘积：$p(y|x) = q(y|x)\alpha(x,y)$。现在，我们将此构造代入细致平稳条件中：
$$
\pi(x) q(y|x) \alpha(x,y) = \pi(y) q(x|y) \alpha(y,x)
$$
这个方程是 MH 算法的核心。我们的任务是设计一个接受概率 $\alpha(x,y)$ 来满足这个方程。

### [接受概率](@entry_id:138494)的推导

为了满足上述核心方程，同时尽可能地提高接受率以[增强算法](@entry_id:635795)效率（即让马尔可夫链更快地探索[状态空间](@entry_id:177074)），Metropolis 和 Hastings 提出了一种标准选择。我们可以重排该方程得到：
$$
\frac{\alpha(x,y)}{\alpha(y,x)} = \frac{\pi(y) q(x|y)}{\pi(x) q(y|x)}
$$
为了最大化接受概率（二者均不超过1），一个明智的选择是令 $\alpha(x,y)$ 和 $\alpha(y,x)$ 中较大的一个取值为1。例如，如果比值 $\frac{\pi(y) q(x|y)}{\pi(x) q(y|x)} > 1$，我们可以令 $\alpha(x,y)=1$，此时 $\alpha(y,x) = \frac{\pi(x) q(y|x)}{\pi(y) q(x|y)}  1$。反之亦然。

将这两种情况统一起来，便得到了标准的 **Metropolis-Hastings 接受概率**：
$$
\alpha(x,y) = \min \left( 1, \frac{\pi(y) q(x|y)}{\pi(x) q(y|x)} \right)
$$
这个比值通常被称为 **Metropolis-Hastings 比**。它由两部分组成：
-   **目标密度比**：$\frac{\pi(y)}{\pi(x)}$。这个比值评估了提议状态 $y$ 相对于当前状态 $x$ 在目标分布下的“优劣”。如果 $\pi(y) > \pi(x)$，意味着 $y$ 是一个更高概率的状态，算法会倾向于接受它。
-   **提议密度比（或 Hastings 比）**：$\frac{q(x|y)}{q(y|x)}$。这个比值是对提议分布不对称性的修正。如果从 $x$ 提议 $y$ 的概率 $q(y|x)$ 大于从 $y$ 提议 $x$ 的概率 $q(x|y)$，那么这个修正项就会小于1，从而降低[接受概率](@entry_id:138494)，以补偿这种“不公平”的提议机制。

一个至关重要的优点是，[接受概率](@entry_id:138494)只依赖于目标密度的*比值* $\pi(y)/\pi(x)$。这意味着，即使我们只知道[目标分布](@entry_id:634522)的未归一化形式 $\tilde{\pi}(x)$（即 $\pi(x) = \tilde{\pi}(x)/Z$，其中[归一化常数](@entry_id:752675) $Z$ 未知），我们依然可以精确计算[接受概率](@entry_id:138494)，因为 $Z$ 会在比值中被约去：
$$
\frac{\pi(y)}{\pi(x)} = \frac{\tilde{\pi}(y)/Z}{\tilde{\pi}(x)/Z} = \frac{\tilde{\pi}(y)}{\tilde{\pi}(x)}
$$
这使得 MH 算法在贝叶斯统计等领域极为强大，因为在这些领域中，后验分布的归一化常数（即证据）通常是难以计算的（[@problem_id:3355568]）。

在实际计算中，为了避免因多个小概率相乘导致的数值[下溢](@entry_id:635171)，通常在对数空间中计算接受比。定义对数接受比为：
$$
\ell(x,y) = \ln(\tilde{\pi}(y)) - \ln(\tilde{\pi}(x)) + \ln(q(x|y)) - \ln(q(y|x))
$$
则[接受概率](@entry_id:138494)为 $\alpha(x,y) = \min(1, \exp(\ell(x,y)))$。这种方法在数值上更为稳定（[@problem_id:3355568]）。

### 提议机制的类型及其影响

[提议分布](@entry_id:144814) $q(y|x)$ 的选择对 MH 算法的性能至关重要。不同的选择导致了算法的不同变体，并直接影响[接受概率](@entry_id:138494)的计算。

#### Metropolis 算法：[对称提议分布](@entry_id:755726)

最简单的情况是当提议分布是对称的，即 $q(y|x) = q(x|y)$。这意味着从 $x$ 提议 $y$ 的概率与从 $y$ 提议 $x$ 的概率完全相同。在这种情况下，提议密度比（Hastings 比）恒等于1：
$$
\frac{q(x|y)}{q(y|x)} = 1
$$
于是，接受概率公式简化为：
$$
\alpha(x,y) = \min \left( 1, \frac{\pi(y)}{\pi(x)} \right)
$$
这个特殊情况被称为 **Metropolis 算法**，它是历史上最早提出的版本。一个典型的[对称提议分布](@entry_id:755726)是高斯[随机游走](@entry_id:142620)（Gaussian Random Walk），即 $y$ 从以 $x$ 为中心的正态分布中抽取：$y \sim \mathcal{N}(x, \sigma^2)$。由于正态密度函数中 $(y-x)^2 = (x-y)^2$，所以 $q(y|x) = q(x|y)$（[@problem_id:3355609]）。

#### 一般情况：非[对称提议分布](@entry_id:755726)

当[提议分布](@entry_id:144814)非对称时，必须使用完整的 Metropolis-Hastings 公式。例如，考虑一个在正实数轴上进行采样的问题，我们可以使用对数[随机游走](@entry_id:142620)（Log-Normal Random Walk）作为提议机制。具体而言，$\ln(y)$ 从以 $\ln(x)$ 为中心的正态分布中抽取，即 $\ln(y) \sim \mathcal{N}(\ln(x), \sigma^2)$。这等价于 $y$ 的提议密度为：
$$
q(y|x) = \frac{1}{y\sigma\sqrt{2\pi}} \exp\left(-\frac{(\ln y - \ln x)^2}{2\sigma^2}\right)
$$
要计算反向提议密度 $q(x|y)$，我们只需交换 $x$ 和 $y$：
$$
q(x|y) = \frac{1}{x\sigma\sqrt{2\pi}} \exp\left(-\frac{(\ln x - \ln y)^2}{2\sigma^2}\right)
$$
由于 $(\ln x - \ln y)^2 = (\ln y - \ln x)^2$，指数项可以约去，但分母中的 $1/y$ 和 $1/x$ 因子不能。因此，Hastings 比为：
$$
\frac{q(x|y)}{q(y|x)} = \frac{1/x}{1/y} = \frac{y}{x}
$$
这个不为1的因子必须被包含在接受概率的计算中，否则就会违反细致平稳条件，导致采样结果偏离[目标分布](@entry_id:634522)（[@problem_id:3355569]）。

#### 对称性的微妙之处：边界效应

深刻理解对称性的含义至关重要。一个看似对称的提议机制，在有边界的状态空间中可能会变得不对称。假设我们想在一个有下界（如 $[0, \infty)$）的空间中采样，并使用一个标准的高斯[随机游走](@entry_id:142620) $y' \sim \mathcal{N}(x, \sigma^2)$。由于 $y'$ 可能为负，一个简单的处理方法是：如果 $y'  0$，则重新抽样，直到得到一个非负的提议 $y$。

这种“拒绝-重抽”的策略实际上改变了[提议分布](@entry_id:144814)。新的提议分布 $q(y|x)$ 是一个在 $[0, \infty)$ 上截断的正态分布。其密度为：
$$
q(y|x) = \frac{\frac{1}{\sigma}\varphi\left(\frac{y-x}{\sigma}\right)}{1 - \Phi(-x/\sigma)}, \quad \text{for } y \ge 0
$$
其中 $\varphi(\cdot)$ 和 $\Phi(\cdot)$ 分别是标准正态分布的概率密度函数（PDF）和[累积分布函数](@entry_id:143135)（CDF）。分母 $1 - \Phi(-x/\sigma) = \Phi(x/\sigma)$ 是原始高斯分布落在 $[0, \infty)$ 区间的概率，作为归一化因子。

反向提议密度 $q(x|y)$ 也是一个截断[正态分布](@entry_id:154414)，但其中心在 $y$：
$$
q(x|y) = \frac{\frac{1}{\sigma}\varphi\left(\frac{x-y}{\sigma}\right)}{1-\Phi(-y/\sigma)}, \quad \text{for } x \ge 0
$$
由于分母 $1 - \Phi(-x/\sigma)$ 和 $1-\Phi(-y/\sigma)$ 通常不相等，这个提议分布是**不对称的**！因此，我们必须计算完整的 Hastings 比：
$$
\frac{q(x|y)}{q(y|x)} = \frac{1 - \Phi(-x/\sigma)}{1 - \Phi(-y/\sigma)} = \frac{\Phi(x/\sigma)}{\Phi(y/\sigma)}
$$
忽略这个修正项是 MCMC 实践中一个常见的错误。这个例子（[@problem_id:3355599]）清楚地表明，我们必须仔细考虑[提议分布](@entry_id:144814)在整个有效状态空间上的最终形式。

#### 独立[提议分布](@entry_id:144814)

另一类重要的[提议分布](@entry_id:144814)是**独立[提议分布](@entry_id:144814)**（Independence Sampler），其特点是提议状态 $y$ 的生成完全独立于当前状态 $x$，即 $q(y|x) = q(y)$。此时，接受概率变为：
$$
\alpha(x,y) = \min\left(1, \frac{\pi(y)q(x)}{\pi(x)q(y)}\right)
$$
这种方法如果设计得当（即 $q(y)$ 与 $\pi(y)$ 形状相似），可以实现状态空间中的“长距离跳跃”，从而加速收敛。然而，如果 $q(y)$ 在 $\pi(y)$ 的重要区域取值很小，算法的效率会急剧下降（[@problem_id:3355582]）。

独立提议采样与经典的**接受-拒绝（AR）采样**有着深刻的联系。AR 采样需要一个提议分布 $q(y)$ 和一个常数 $M$，使得对于所有 $y$ 都有 $\pi(y) \le Mq(y)$。AR 算法从 $q(y)$ 中提议一个 $y$，然后以概率 $\pi(y)/(Mq(y))$ 接受它。可以证明，AR 算法的平均接受率恰好是 $1/M$。更有趣的是，如果我们运行一个独立提议 MH 算法，并且其当前状态 $x$ 恰好是使得比率 $\pi(z)/q(z)$ 达到其上确界 $M$ 的点，那么其 MH 接受概率就精确地等于 AR 接受概率 $\pi(y)/(Mq(y))$（[@problem_id:3355579]）。这揭示了不同蒙特卡洛方法之间的内在联系。

### 高级主题：效率、优化与设计

#### 混合提议分布

为了处理更复杂的[目标分布](@entry_id:634522)，例如多峰[分布](@entry_id:182848)（multimodal distribution），我们可以构建**混合提议分布**（Mixture Proposals）。其形式为：
$$
q(y|x) = \sum_{k=1}^m w_k q_k(y|x)
$$
其中 $w_k$ 是混合权重（$\sum w_k=1$），$q_k(y|x)$ 是各个组件[提议分布](@entry_id:144814)。例如，一个组件可以是在当前峰内进行局部探索的[随机游走](@entry_id:142620)，而另一个组件可以是跳跃到其他峰的独立提议。

在计算接受概率时，一个常见的错误是只使用被选中的那个组件 $q_k$ 来计算 Hastings 比。正确的做法是使用完整的混合密度 $q(y|x)$ 和 $q(x|y)$ 进行计算（[@problem_id:3355605]）。
$$
\alpha(x,y) = \min\left(1, \frac{\pi(y) \sum_{k=1}^{m} w_{k} \, q_{k}(x|y)}{\pi(x) \sum_{k=1}^{m} w_{k} \, q_{k}(y|x)}\right)
$$
通过精心设计混合权重 $w_k$ 和组件 $q_k$，可以显著提高算法在复杂问题上的表现。例如，在对一个[双峰分布](@entry_id:166376) $\pi(x) = a f_1(x) + (1-a) f_2(x)$ 进行采样时，若使用一个匹配的独立混合提议 $q(y) = w f_1(y) + (1-w) f_2(y)$，可以计算出算法的期望[接受概率](@entry_id:138494)为 $1-|a-w|$。这个结果表明，为了最大化接受率，[提议分布](@entry_id:144814)的混合权重 $w$ 应当尽可能地接近[目标分布](@entry_id:634522)的混合权重 $a$（[@problem_id:3355605]）。

#### 接受规则的最优性

我们可能会问：标准的 Metropolis [接受概率](@entry_id:138494) $\alpha(r) = \min(1, r)$（其中 $r$ 是 Hastings 比）是唯一的选择吗？答案是否定的。任何满足 $\alpha(r) / \alpha(1/r) = r$ 的函数都可以满足细致平稳条件。例如，**Barker 接受规则** $\alpha_B(r) = r/(1+r)$ 就是另一个有效的选择。

那么，为何 $\min(1,r)$ 成为标准？答案在于效率。**Peskun 排序**理论提供了一个比较不同 MCMC 算法效率的框架。如果一个算法的转移核 $K_1$ Peskun-优于另一个 $K_2$（粗略地说，意味着 $K_1$ 在任何状态下转移到“别处”的概率都更高），那么使用 $K_1$ 得到的估计量的[渐近方差](@entry_id:269933)将不会高于使用 $K_2$ 的。可以证明，对于任何 $r>0$，总有 $\min(1,r) \ge r/(1+r)$。这意味着标准的 Metropolis 规则 Peskun-优于 Barker 规则。因此，前者产生的估计量具有更小的[渐近方差](@entry_id:269933)，是更优的选择。这个结论与[目标分布](@entry_id:634522)的形态（例如，是否是[重尾分布](@entry_id:142737)）无关（[@problem_id:3355571]）。

#### 高维空间中的最优调优

在实践中，尤其是对于[随机游走](@entry_id:142620)提议，[提议分布](@entry_id:144814)的尺度（如高斯[随机游走](@entry_id:142620)中的[方差](@entry_id:200758) $\sigma^2$）是一个需要用户设定的**调优参数**。如果 $\sigma$ 太小，提议的步子太短，接受率会很高，但链的移动非常缓慢，探索效率低下。如果 $\sigma$ 太大，提议的步子太长，经常会跳到目标分布中概率很低的区域，导致接受率极低，链会频繁“卡住”。

在高维空间中，这个问题变得尤为突出，即所谓的“[维度灾难](@entry_id:143920)”。一个著名的理论结果为我们提供了重要的指导。考虑在一个 $d$ 维空间中对标准正态分布 $\mathcal{N}(0, I_d)$ 进行采样，使用一个各向同性的[随机游走](@entry_id:142620)提议 $Y = X + \sigma_d Z$，其中 $Z \sim \mathcal{N}(0, I_d)$。理论分析表明，为了保持合理的接受率，提议的尺度 $\sigma_d$ 必须随着维度 $d$ 的增加而缩放，具体形式为 $\sigma_d = \ell/\sqrt{d}$，其中 $\ell$ 是一个常数。

进一步的分析（[@problem_id:3355576]）表明，当 $d \to \infty$ 时，算法的期望接受概率收敛到一个仅依赖于 $\ell$ 的极限值 $a(\ell) = 2\Phi(-\ell/2)$。为了最大化算法的效率（通常用每一步的期望平方跳跃距离来衡量），需要最大化函数 $\ell^2 a(\ell)$。通过数值求解，可以找到最优的 $\ell^{\star} \approx 2.38$。将此值代入，我们得到最优的极限接受概率为：
$$
a(\ell^{\star}) \approx 0.234
$$
这个“0.234”的结果是一个里程碑式的发现。它为高维 MCMC 实践提供了一个非常有用的“经验法则”：在为高维（近似高斯）[目标分布](@entry_id:634522)调节[随机游走](@entry_id:142620)提议的步长时，我们应该力求达到大约 23.4% 的接受率。这为自动化调优算法提供了理论基础。

本章我们详细阐述了 Metropolis-Hastings 算法的原理与机制，从其核心的细致平稳条件出发，推导了接受概率的计算方法，并探讨了不同提议策略的设计及其对算法性能的影响。理解这些原理是有效应用和发展 MCMC 方法的基石。