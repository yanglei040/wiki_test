{"hands_on_practices": [{"introduction": "在模拟泊松过程时，选择正确的算法至关重要。本练习将引导您探索两种精确模拟均匀泊松过程的核心算法：序列指数生成（SEG）和先计数后排序（CTS）。通过为这两种方法建立计算成本模型，您将学会如何基于过程的期望事件数 $\\lambda T$ 推导出一个实用的算法选择规则，并在效率与实现复杂度之间做出权衡。这个练习不仅关乎模拟的执行，更关乎模拟的设计智慧 [@problem_id:3342349]。", "problem": "你需要研究在区间 $\\left(0,T\\right]$ 上速率为 $\\lambda$ 的齐次泊松过程的两种精确模拟算法，并设计一个混合选择规则，该规则基于一个有原则的计算成本模型来选择更快的算法。然后，你必须在一个蒙特卡洛代理计算成本下验证该混合规则在经验上是最优的。你的程序必须实现这些算法和验证过程，并以要求的格式输出指定测试套件的结果。\n\n模拟齐次泊松过程事件时间的两种方法如下，以纯数学术语表述。\n\n- 顺序指数生成 (Sequential Exponential Generation, SEG)：生成独立的到达间隔时间 $E_1,E_2,\\dots$，其中每个 $E_i \\sim \\text{Exponential}(\\lambda)$，形成累积和 $S_k = \\sum_{i=1}^{k} E_i$，并在第一个索引 $M$ 使得 $S_M  T$ 时停止。事件时间为 $\\{S_k : S_k \\le T\\}$。根据齐次泊松过程的定义，在 $\\left(0,T\\right]$ 内的事件计数 $N_T$ 服从分布 $N_T \\sim \\text{Poisson}(\\lambda T)$，并且生成的指数分布随机变量的数量几乎必然等于 $M = N_T + 1$。\n\n- 计数后排序 (Count-Then-Sort, CTS)：生成 $N \\sim \\text{Poisson}(\\lambda T)$，然后生成 $N$ 个独立的均匀分布随机变量 $U_1,\\dots,U_N \\overset{\\text{iid}}{\\sim} \\text{Uniform}(0,T)$，并将它们排序以获得有序的事件时间。\n\n为了以一种与机器无关的方式比较计算性能，使用一个代理成本模型，该模型通过代表硬件性能和实现效率的可调常量来计算基本运算。\n\n- SEG 代理成本：将一次运行的成本建模为 $C_{\\text{SEG}} = c_s \\cdot M = c_s \\cdot (N_T + 1)$，其中 $c_s  0$ 是一个抽象常量，它聚合了采样一个指数随机变量、更新部分和以及比较的每步成本。\n\n- CTS 代理成本：将一次运行的成本建模为 $C_{\\text{CTS}} = c_P + c_U \\cdot N + a \\cdot N \\log_2(\\max\\{N,1\\}) + b \\cdot N$，其中 $c_P \\ge 0$ 模拟了抽取一个泊松随机数的固定开销，$c_U \\ge 0$ 模拟了单位均匀采样的成本，$a \\ge 0$ 模拟了排序的主要 $O(N \\log N)$ 成本（以 $2$ 为底的对数），$b \\ge 0$ 捕捉了线性时间排序开销，例如元素移动。当 $N \\in \\{0,1\\}$ 时，定义 $N \\log_2(\\max\\{N,1\\})$ 项为 $0$。\n\n从 $N_T \\sim \\text{Poisson}(\\lambda T)$ 的特征和指数到达间隔构造出发，推导一个仅依赖于乘积 $\\mu = \\lambda T$ 和常量 $c_s, c_P, c_U, a, b$ 的期望成本近似。使用近似 $\\mathbb{E}[N_T] \\approx \\mu$ 和 $\\mathbb{E}[N_T \\log_2(N_T)] \\approx \\mu \\log_2(\\max\\{\\mu,1\\})$ 来获得期望成本的一阶经验法则：\n$$\n\\bar{C}_{\\text{SEG}}(\\mu) \\approx c_s \\cdot (\\mu + 1), \\quad\n\\bar{C}_{\\text{CTS}}(\\mu) \\approx c_P + c_U \\cdot \\mu + a \\cdot \\mu \\log_2(\\max\\{\\mu,1\\}) + b \\cdot \\mu.\n$$\n提出一个混合规则，选择具有较小近似期望成本的算法。这在 $\\mu$ 和硬件常量中定义了一个相变：对于小的 $\\mu$ 和昂贵的排序，SEG 可能更受青睐；对于较大的 $\\mu$ 和快速排序以及廉价的均匀生成，CTS 可能更受青睐，特别是当 $c_s$ 相对于 $a$ 较大时。\n\n经验验证协议。对于测试套件中的每个参数集，使用固定的种子执行 $R$ 次蒙特卡洛重复实验，以消除输出格式中的随机性。在每次重复实验中，抽取 $N \\sim \\text{Poisson}(\\mu)$ 并评估代理成本：\n$$\nC_{\\text{SEG}} = c_s \\cdot (N + 1), \\quad\nC_{\\text{CTS}} = c_P + c_U \\cdot N + a \\cdot N \\log_2(\\max\\{N,1\\}) + b \\cdot N.\n$$\n在 $R$ 次重复实验上取平均以获得经验均值 $\\hat{C}_{\\text{SEG}}$ 和 $\\hat{C}_{\\text{CTS}}$。将经验上最优的方法定义为具有较小经验均值成本的方法（若结果相同则选择 SEG）。通过为每个测试用例返回一个布尔值来验证混合规则，该布尔值为真当且仅当混合选择与经验上最优的方法相匹配。\n\n测试套件。使用以下五个参数集，通过改变 $\\mu = \\lambda T$ 和硬件常量来探索相变。对于每种情况，使用 $R = 200000$ 次重复实验和相同的固定随机种子。\n\n- 情况 1：$\\lambda = 0.001$, $T = 50.0$, $c_s = 1.0$, $c_P = 5.0$, $c_U = 1.0$, $a = 1.0$, $b = 0.0$。\n\n- 情况 2：$\\lambda = 1.0$, $T = 1.0$, $c_s = 1.0$, $c_P = 5.0$, $c_U = 1.0$, $a = 0.5$, $b = 0.0$。\n\n- 情况 3：$\\lambda = 2.0$, $T = 10.0$, $c_s = 1.0$, $c_P = 5.0$, $c_U = 1.0$, $a = 2.0$, $b = 0.0$。\n\n- 情况 4：$\\lambda = 2.0$, $T = 10.0$, $c_s = 1.0$, $c_P = 2.0$, $c_U = 0.2$, $a = 0.05$, $b = 0.0$。\n\n- 情况 5：$\\lambda = 100.0$, $T = 10.0$, $c_s = 10.0$, $c_P = 2.0$, $c_U = 0.2$, $a = 0.02$, $b = 0.0$。\n\n你的任务。实现一个程序，该程序：\n\n- 根据每个情况的近似期望成本计算混合选择。\n\n- 使用每个情况 $R = 200000$ 次重复实验进行经验验证，为伪随机数生成器使用固定种子，以使输出是确定性的。\n\n- 为每个情况返回一个布尔值，指示混合选择是否等于经验上最优的选择。\n\n最终输出格式。你的程序应生成一行输出，其中包含五个布尔值，形式为方括号内以逗号分隔的列表，例如，$[\\text{True},\\text{False},\\text{True},\\text{True},\\text{True}]$。结果的顺序必须遵循上面列出的情况 1 到 5。输出中不允许有其他文本。", "solution": "该问题要求分析在区间 $(0, T]$ 上以恒定速率 $\\lambda  0$ 模拟齐次泊松过程的两种算法：顺序指数生成 (SEG) 和计数后排序 (CTS)。目标是基于理论成本模型开发一个混合选择规则，并通过蒙特卡洛模拟获得的经验成本评估来验证该规则。\n\n区间 $(0, T]$ 内的事件数 $N_T$ 服从泊松分布，其均值为 $\\mu = \\lambda T$，即 $N_T \\sim \\text{Poisson}(\\mu)$。这个随机变量对于两种算法的计算成本都至关重要。\n\n首先，我们形式化理论成本模型和混合选择规则。问题为单次模拟运行提供了代理成本函数：\n- 对于 SEG，成本为 $C_{\\text{SEG}} = c_s \\cdot (N_T + 1)$，其中 $N_T$ 是该次运行中实现的事件数。成本与生成的指数随机变量的数量成正比，即 $N_T + 1$。\n- 对于 CTS，成本为 $C_{\\text{CTS}} = c_P + c_U \\cdot N_T + a \\cdot N_T \\log_2(\\max\\{N_T,1\\}) + b \\cdot N_T$。此成本包含一个用于采样泊松随机数的固定部分 $c_P$，一个用于采样 $N_T$ 个均匀随机变量的线性部分，以及一个用于排序它们的拟线性部分，该部分由 $N \\log N$ 项主导。常量 $c_s, c_P, c_U, a, b$ 是非负的，并取决于具体的计算环境。\n\n为了推导一个独立于单次随机结果的选择规则，我们比较两种算法的期望成本。\nSEG 的期望成本可以精确计算：\n$$\n\\mathbb{E}[C_{\\text{SEG}}] = \\mathbb{E}[c_s \\cdot (N_T + 1)] = c_s \\cdot (\\mathbb{E}[N_T] + 1) = c_s(\\mu + 1)\n$$\n我们将其定义为理论成本估计 $\\bar{C}_{\\text{SEG}}(\\mu) = c_s(\\mu + 1)$。\n\nCTS 的期望成本为：\n$$\n\\mathbb{E}[C_{\\text{CTS}}] = \\mathbb{E}[c_P + c_U N_T + a N_T \\log_2(\\max\\{N_T,1\\}) + b N_T] \\\\\n= c_P + (c_U + b)\\mathbb{E}[N_T] + a\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})] \\\\\n= c_P + (c_U + b)\\mu + a\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})]\n$$\n项 $\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})]$ 没有简单的闭式表达式。问题建议使用基于琴生不等式的一阶近似 $\\mathbb{E}[f(X)] \\approx f(\\mathbb{E}[X])$。应用这个近似，我们得到：\n$$\n\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})] \\approx \\mu \\log_2(\\max\\{\\mu,1\\})\n$$\n由此得出 CTS 的近似期望成本：\n$$\n\\bar{C}_{\\text{CTS}}(\\mu) \\approx c_P + (c_U + b)\\mu + a \\mu \\log_2(\\max\\{\\mu,1\\})\n$$\n混合选择规则是选择具有较低近似期望成本的算法。如果 $\\bar{C}_{\\text{SEG}}(\\mu) \\le \\bar{C}_{\\text{CTS}}(\\mu)$，我们选择 SEG，否则选择 CTS。这纯粹基于参数 $\\mu, c_s, c_P, c_U, a, b$ 建立了一个“混合选择”。\n\n接下来，我们设计经验验证协议。其目的是通过蒙特卡洛方法高精度地估计真实期望成本 $\\mathbb{E}[C_{\\text{SEG}}]$ 和 $\\mathbb{E}[C_{\\text{CTS}}]$，从而确定“经验上最优”的方法。对于每个测试用例，我们执行 $R=200000$ 次重复实验。使用固定的伪随机数生成器种子以确保结果的可复现性。\n每个测试用例的流程如下：\n1. 生成一个包含 $R$ 个独立随机变量的向量 $\\{N_i\\}_{i=1}^R$，其中每个 $N_i \\sim \\text{Poisson}(\\mu)$。\n2. 对于每个 $N_i$，计算每种算法本会产生的成本：\n   - $C_{\\text{SEG}, i} = c_s(N_i + 1)$\n   - $C_{\\text{CTS}, i} = c_P + c_U N_i + a N_i \\log_2(\\max\\{N_i,1\\}) + b N_i$\n3. 计算这些成本的样本均值，它们是真实期望成本的蒙特卡洛估计：\n   - $\\hat{C}_{\\text{SEG}} = \\frac{1}{R} \\sum_{i=1}^R C_{\\text{SEG}, i}$\n   - $\\hat{C}_{\\text{CTS}} = \\frac{1}{R} \\sum_{i=1}^R C_{\\text{CTS}, i}$\n根据大数定律，对于大的 $R$，$\\hat{C}_{\\text{SEG}} \\approx \\mathbb{E}[C_{\\text{SEG}}]$ 且 $\\hat{C}_{\\text{CTS}} \\approx \\mathbb{E}[C_{\\text{CTS}}]$。\n经验上最优的方法通过比较这些样本均值来确定。与问题的平局打破规则一致，如果 $\\hat{C}_{\\text{SEG}} \\le \\hat{C}_{\\text{CTS}}$，我们选择 SEG，否则选择 CTS。\n\n最后，对于每个测试用例，我们将混合选择（预计算）与经验上最优的选择进行比较。`True`的布尔结果表示简单的一阶近似足以做出正确的决策，而`False`则表示被近似忽略的高阶效应足够显著，以至于改变了结果。将使用 `numpy` 实现高效的向量化计算，以处理 $R$ 次重复实验。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Validates a hybrid algorithm selection rule for simulating a homogeneous Poisson process.\n\n    The function iterates through a suite of test cases. For each case, it:\n    1.  Calculates a theoretical choice of algorithm (SEG vs. CTS) based on an\n        approximated expected-cost model.\n    2.  Determines the empirically optimal algorithm by running a Monte Carlo\n        simulation to estimate the average costs of each method.\n    3.  Compares the theoretical choice to the empirical choice and records\n        whether they match.\n\n    The final output is a list of booleans representing the result of this\n    comparison for each test case.\n    \"\"\"\n    \n    # Test suite as defined in the problem statement\n    test_cases = [\n        # Case 1: (lambda, T, c_s, c_P, c_U, a, b)\n        (0.001, 50.0, 1.0, 5.0, 1.0, 1.0, 0.0),\n        # Case 2\n        (1.0, 1.0, 1.0, 5.0, 1.0, 0.5, 0.0),\n        # Case 3\n        (2.0, 10.0, 1.0, 5.0, 1.0, 2.0, 0.0),\n        # Case 4\n        (2.0, 10.0, 1.0, 2.0, 0.2, 0.05, 0.0),\n        # Case 5\n        (100.0, 10.0, 10.0, 2.0, 0.2, 0.02, 0.0),\n    ]\n\n    R = 200000  # Number of Monte Carlo replications\n    SEED = 0 # Fixed seed for deterministic output\n\n    results = []\n\n    for case in test_cases:\n        lambda_rate, T, c_s, c_P, c_U, a, b = case\n        \n        mu = lambda_rate * T\n\n        # Step 1: Hybrid Rule Prediction (Theoretical Choice)\n        c_seg_approx = c_s * (mu + 1)\n        \n        # The term a*mu*log2(max{mu,1}) is zero if mu = 1\n        log_term_approx = 0.0\n        if mu > 1:\n            log_term_approx = a * mu * np.log2(mu)\n        \n        c_cts_approx = c_P + (c_U + b) * mu + log_term_approx\n        \n        hybrid_choice_is_seg = c_seg_approx = c_cts_approx\n\n        # Step 2: Empirical Validation\n        # Use a new random number generator with a fixed seed for each independent case\n        rng = np.random.default_rng(SEED)\n        \n        # Generate R Poisson-distributed samples for the event count N\n        n_samples = rng.poisson(mu, R)\n        \n        # Calculate empirical costs for SEG (vectorized)\n        cost_seg_samples = c_s * (n_samples + 1)\n        \n        # Calculate empirical costs for CTS (vectorized)\n        # The N*log2(max{N,1}) term is 0 for N in {0, 1}.\n        log_term_samples = np.zeros_like(n_samples, dtype=float)\n        mask = n_samples > 1\n        log_term_samples[mask] = n_samples[mask] * np.log2(n_samples[mask])\n        \n        cost_cts_samples = c_P + (c_U + b) * n_samples + a * log_term_samples\n        \n        # Compute the mean costs over R replications\n        c_seg_empirical = np.mean(cost_seg_samples)\n        c_cts_empirical = np.mean(cost_cts_samples)\n        \n        # Step 3: Determine Empirically Optimal Choice\n        # Tie-breaking rule: choose SEG if costs are equal\n        empirical_choice_is_seg = c_seg_empirical = c_cts_empirical\n        \n        # Step 4: Validate Hybrid Rule\n        # The result is True if the theoretical choice matches the empirical one\n        validation_result = (hybrid_choice_is_seg == empirical_choice_is_seg)\n        results.append(validation_result)\n\n    # Print the final list of boolean results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3342349"}, {"introduction": "生成模拟数据仅仅是第一步，验证其正确性是确保模拟结果可靠的关键。本练习将带您深入探讨如何验证模拟产生的到达间隔时间序列是否真正符合均匀泊松过程的核心性质——即服从指数分布。您将使用强大的柯尔莫哥洛夫-斯米尔诺夫（Kolmogorov-Smirnov）拟合优度检验，并学习当分布参数（如率 $\\lambda$）需要从数据本身估计时，如何通过参数自举法（parametric bootstrap）来校准检验并获得有效的 p 值 [@problem_id:3342341]。", "problem": "要求您设计并实现一个有原则的拟合优度程序，通过检验其指数性来评估模拟的到达间隔时间是否源自齐次泊松过程。背景是一个具有恒定速率 $\\lambda  0$ 的齐次泊松过程。该问题的基本依据是齐次泊松过程的定义，即其具有独立且平稳的增量，并且其到达间隔时间是速率为 $\\lambda$ 的独立同分布的指数随机变量。该检验在通过估计的速率进行缩放后，使用 Kolmogorov–Smirnov 统计量，并且速率的校准必须从模拟的到达间隔数据本身进行。\n\n使用的原则：\n- 速率为 $\\lambda$ 的齐次泊松过程的到达间隔时间 $\\{X_i\\}_{i=1}^n$ 是独立同分布的，服从速率为 $\\lambda$ 的指数分布，即其累积分布函数为 $F_{\\lambda}(x) = 1 - e^{-\\lambda x}$（对于 $x \\ge 0$）。\n- Kolmogorov–Smirnov (KS) 统计量通过其绝对差的一致上确界，将经验累积分布函数与假设的累积分布函数进行比较。当假设的累积分布函数被完全指定且没有参数从数据中估计时，KS 统计量是无分布的。\n- 从相同数据中估计 $\\lambda$ 会在原假设下引入经验累积分布函数与假设的累积分布函数之间的依赖关系，这使得直接使用 KS 临界值表变得无效。为解决此问题，应在原假设下使用参数化自助法，其中速率是从数据中校准的。\n\n您的程序必须为每个测试用例实现以下步骤：\n1. 根据指定的数据生成机制，使用提供的速率和分布规范，模拟 $n$ 个到达间隔时间。所有时间都应被视为无量纲的持续时间；不需要进行物理单位转换。\n2. 使用统计上可靠的方法，从模拟的到达间隔时间中校准速率 $\\lambda$。估计必须基于到达间隔样本本身。不得使用任何外部信息或提示。校准后的速率记为 $\\widehat{\\lambda}$，并且必须通过与基于第一性原理的指数族性质一致的方法来计算。\n3. 通过 $\\widehat{\\lambda}$ 进行缩放后，构造用于检验指数性的 Kolmogorov–Smirnov 统计量，步骤如下：\n   - 将到达间隔时间按 $\\widehat{\\lambda}$ 进行缩放，即对 $i = 1, \\ldots, n$ 构造 $Y_i = \\widehat{\\lambda} X_i$。\n   - 定义 $\\{Y_i\\}_{i=1}^n$ 的经验累积分布函数 $\\widehat{F}_n(y)$。\n   - 定义假设的累积分布函数 $F_0(y) = 1 - e^{-y}$，这对应于速率为 $1$ 的指数分布。\n   - 计算 KS 统计量 $D_n = \\sup_{y \\ge 0} \\left| \\widehat{F}_n(y) - F_0(y) \\right|$。\n4. 为获得考虑了从数据中估计速率的有效 $p$ 值，应在指数到达间隔的原假设下实现参数化自助法：\n   - 从速率为 $\\widehat{\\lambda}$ 的指数分布中生成 $B$ 个大小为 $n$ 的自助样本。\n   - 对于每个自助样本，从该样本中重新估计速率 $\\widehat{\\lambda}^{(b)}$，按 $\\widehat{\\lambda}^{(b)}$ 进行缩放，并计算其相对于 $F_0$ 的 KS 统计量 $D_n^{(b)}$。\n   - 自助 $p$ 值是自助统计量大于或等于观测统计量的比例，即 $p = \\frac{1}{B} \\sum_{b=1}^B \\mathbf{1}\\{D_n^{(b)} \\ge D_n\\}$。\n5. 您的程序应生成单行输出，其中包含按测试套件顺序排列的结果，格式为用方括号括起来的逗号分隔列表，每个条目是四舍五入到六位小数的浮点数形式的自助 $p$ 值。\n\n测试套件：\n- 案例 1 (正常路径): 指数到达间隔，真实速率 $\\lambda = 2$，样本大小 $n = 500$，使用 $B = 400$ 次自助法重复。\n- 案例 2 (模型设定错误): Gamma 到达间隔，形状参数 $k = 2$，速率参数 $\\beta = 2 \\lambda$ 以使得均值等于 $1/\\lambda$，真实 $\\lambda = 2$，样本大小 $n = 500$，使用 $B = 400$ 次自助法重复。\n- 案例 3 (小样本边界): 指数到达间隔，真实速率 $\\lambda = 1$，样本大小 $n = 20$，使用 $B = 400$ 次自助法重复。\n- 案例 4 (污染): 指数混合分布，其中以概率 $p = 0.3$ 速率为 $3 \\lambda$，以概率 $1 - p$ 速率为 $\\lambda$，真实 $\\lambda = 3$，样本大小 $n = 500$，使用 $B = 400$ 次自助法重复。\n- 案例 5 (大样本): 指数到达间隔，真实速率 $\\lambda = 5$，样本大小 $n = 2000$，使用 $B = 300$ 次自助法重复。\n\n随机性与可复现性：\n- 每个测试用例使用固定的种子以确保模拟数据和自助法程序的可复现性。五个案例的种子值分别为 $1$、$2$、$3$、$4$ 和 $5$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含上述测试套件的五个自助 $p$ 值，按顺序排列，四舍五入到六位小数，格式为用方括号括起来的逗号分隔列表（例如，“[0.532000,0.041000,0.872000,0.010000,0.619000]”）。", "solution": "验证一个事件时间序列是否源自齐次泊松过程的问题，本质上是一个拟合优度问题。其指导原则是这类过程的一个核心属性：到达间隔时间 $\\{X_i\\}_{i=1}^n$ 是服从指数分布的独立同分布 (i.i.d.) 随机变量。齐次泊松过程由一个恒定的速率参数 $\\lambda  0$ 表征，其到达间隔时间的累积分布函数 (CDF) 为 $F_{\\lambda}(x) = 1 - e^{-\\lambda x}$（对于任意时间 $x \\ge 0$）。任务是设计一个程序，用于检验原假设 $H_0$，即一个给定的 $n$ 个到达间隔时间样本 $\\{X_i\\}_{i=1}^n$ 是从某个未知速率 $\\lambda$ 的指数分布中抽取的。\n\nKolmogorov-Smirnov (KS) 检验是用于检验拟合优度的标准方法。它将数据的经验累积分布函数 (ECDF)，记为 $\\widehat{F}_n(x)$，与假设的累积分布函数 (CDF) $F(x)$ 进行比较。ECDF 定义为样本中小于或等于 $x$ 的比例：$\\widehat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}\\{X_i \\le x\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。KS 检验统计量 $D_n$ 是这两个函数在所有可能的 $x$ 值上的最大绝对差：$D_n = \\sup_{x} |\\widehat{F}_n(x) - F(x)|$。\n\n一个关键的复杂问题在于，速率参数 $\\lambda$ 是未知的，必须从被检验的同一组数据中进行估计。这个过程违反了标准 KS 检验的假设，因为只有当假设的 CDF 被完全指定且不参考数据时，其零分布才是无分布的。当参数被估计时，ECDF 倾向于比它与真实 CDF 更接近于估计的 CDF，这会导致人为地减小检验统计量的值。这种效应使得标准 KS 检验的临界值表失效。\n\n为了构建一个有效的检验，我们首先将问题转换到一个无参数空间。如果 $X_i$ 确实是速率为 $\\lambda$ 的指数分布，那么经过缩放的变量 $Y_i = \\lambda X_i$ 将是速率为 $1$ 的指数分布（即标准指数分布）。由于 $\\lambda$ 未知，我们使用一个从数据中导出的有原则的估计值 $\\widehat{\\lambda}$。指数分布速率参数的最大似然估计 (MLE) 是样本均值的倒数，即 $\\widehat{\\lambda} = 1 / \\overline{X} = n / (\\sum_{i=1}^n X_i)$。然后我们构造缩放后的样本 $\\{Y_i = \\widehat{\\lambda} X_i\\}_{i=1}^n$，并检验它是否服从 CDF 为 $F_0(y) = 1-e^{-y}$ 的标准指数分布。检验统计量变为 $D_n = \\sup_{y \\ge 0} |\\widehat{F}_n(y) - F_0(y)|$，其中 $\\widehat{F}_n(y)$ 是缩放后数据 $\\{Y_i\\}$ 的 ECDF。这是 Lilliefors 检验在指数分布上的一种形式。\n\n这个新统计量 $D_n$ 的零分布仍然不是标准的 KS 分布，因为在缩放过程中使用了估计参数 $\\widehat{\\lambda}$。为了正确评估观测到的 $D_n$ 值的统计显著性，我们必须确定其在原假设下的分布。参数化自助法为此提供了一种稳健的、由计算驱动的方法。该过程通过将我们估计的模型视为真实的数据生成过程来模拟零分布。\n\n算法如下：\n1.  **数据生成与初步分析**：对于给定的测试用例，根据指定的机制生成大小为 $n$ 的主数据样本 $\\{X_i\\}_{i=1}^n$。\n2.  **速率估计**：从此样本中计算速率的 MLE：$\\widehat{\\lambda} = n / \\sum_{i=1}^n X_i$。\n3.  **观测统计量**：缩放数据以获得 $\\{Y_i = \\widehat{\\lambda} X_i\\}_{i=1}^n$，并根据标准指数 CDF 计算观测到的 KS 统计量 $D_n = \\sup_{y \\ge 0} |\\widehat{F}_n(y) - F_0(y)|$。\n4.  **参数化自助法**：为生成检验统计量的零分布，对 $b = 1, \\dots, B$ 执行以下步骤，其中 $B$ 是自助法重复的次数：\n    a. 通过从速率为 $\\widehat{\\lambda}$ 的指数分布中抽取 $n$ 个 i.i.d. 值，生成一个自助样本 $\\{X_i^{(b)}\\}_{i=1}^n$。这在 $H_0$ 为真且我们对速率的最佳估计是正确的假设下，模拟了一个新的数据集。\n    b. 对于这个自助样本，重复整个分析过程：计算其自身的速率估计 $\\widehat{\\lambda}^{(b)} = n / \\sum_{i=1}^n X_i^{(b)}$；缩放其数据以得到 $\\{Y_i^{(b)} = \\widehat{\\lambda}^{(b)} X_i^{(b)}\\}_{i=1}^n$；并计算相应的 KS 统计量 $D_n^{(b)}$。\n5.  **p值计算**：自助统计量的集合 $\\{D_n^{(b)}\\}_{b=1}^B$ 可作为我们检验统计量零分布的经验近似。自助 $p$ 值是这些模拟统计量中大于或等于原始观测统计量的比例：$p = \\frac{1}{B} \\sum_{b=1}^B \\mathbf{1}\\{D_n^{(b)} \\ge D_n\\}$。一个小的 $p$ 值（例如，$ 0.05$）表明观测数据不大可能源自指数分布，从而提供了反对齐次泊松过程假设的证据。\n\n这个过程正确地考虑了参数估计的影响，并提供了一个有效的拟合优度检验。实现将使用 `scipy.stats.kstest` 来计算相对于标准指数分布（'expon'，其速率为 $1$）的 KS 统计量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    def estimate_rate(X):\n        \"\"\"\n        Computes the Maximum Likelihood Estimator (MLE) for the rate parameter\n        of an exponential distribution.\n        \"\"\"\n        # A small epsilon is added to avoid division by zero if mean is zero,\n        # which is practically impossible for non-empty positive-valued data.\n        return 1.0 / (np.mean(X) + np.finfo(float).eps)\n\n    def compute_ks_statistic(X, lambda_hat):\n        \"\"\"\n        Computes the Kolmogorov-Smirnov statistic for exponentiality after\n        scaling by the estimated rate.\n        \"\"\"\n        # Scale the data by the estimated rate.\n        Y = lambda_hat * X\n        # Perform KS test against the standard exponential distribution (rate=1),\n        # which is 'expon' in SciPy. We only need the statistic, not the p-value.\n        statistic, _ = kstest(Y, 'expon')\n        return statistic\n\n    def run_goodness_of_fit_test(case_params):\n        \"\"\"\n        Executes the entire goodness-of-fit procedure for a single test case.\n        \"\"\"\n        case_id = case_params['id']\n        dist_type = case_params['dist_type']\n        params = case_params['params']\n        n = case_params['n']\n        B = case_params['B']\n        seed = case_params['seed']\n\n        # Initialize Random Number Generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Simulate initial data sample\n        if dist_type == 'exponential':\n            true_lambda = params['lambda']\n            X = rng.exponential(scale=1.0/true_lambda, size=n)\n        elif dist_type == 'gamma':\n            k, beta = params['k'], params['beta']\n            X = rng.gamma(shape=k, scale=1.0/beta, size=n)\n        elif dist_type == 'mixture':\n            p, lambda1, lambda2 = params['p'], params['lambda1'], params['lambda2']\n            # With probability p, rate is lambda1; with 1-p, rate is lambda2.\n            rates = np.where(rng.random(size=n)  p, lambda1, lambda2)\n            X = rng.exponential(scale=1.0/rates, size=n)\n        else:\n            raise ValueError(f\"Unknown distribution type: {dist_type}\")\n\n        # 2. Calibrate rate from the data\n        lambda_hat = estimate_rate(X)\n\n        # 3. Compute observed KS statistic\n        D_n_observed = compute_ks_statistic(X, lambda_hat)\n\n        # 4. Perform parametric bootstrap to find the p-value\n        bootstrap_stats = np.zeros(B)\n        for b in range(B):\n            # Generate a bootstrap sample under the null hypothesis (Exp(lambda_hat))\n            X_b = rng.exponential(scale=1.0/lambda_hat, size=n)\n            \n            # Re-estimate rate for the bootstrap sample\n            lambda_hat_b = estimate_rate(X_b)\n            \n            # Compute KS statistic for the bootstrap sample\n            D_n_b = compute_ks_statistic(X_b, lambda_hat_b)\n            bootstrap_stats[b] = D_n_b\n\n        # 5. Calculate bootstrap p-value\n        p_value = np.sum(bootstrap_stats >= D_n_observed) / B\n        \n        return p_value\n\n    # Define the test suite from the problem statement.\n    test_cases = [\n        {'id': 1, 'dist_type': 'exponential', 'params': {'lambda': 2}, 'n': 500, 'B': 400, 'seed': 1},\n        {'id': 2, 'dist_type': 'gamma', 'params': {'k': 2, 'beta': 4}, 'n': 500, 'B': 400, 'seed': 2},\n        {'id': 3, 'dist_type': 'exponential', 'params': {'lambda': 1}, 'n': 20, 'B': 400, 'seed': 3},\n        {'id': 4, 'dist_type': 'mixture', 'params': {'p': 0.3, 'lambda1': 9, 'lambda2': 3}, 'n': 500, 'B': 400, 'seed': 4},\n        {'id': 5, 'dist_type': 'exponential', 'params': {'lambda': 5}, 'n': 2000, 'B': 300, 'seed': 5},\n    ]\n\n    results = []\n    for case in test_cases:\n        p_val = run_goodness_of_fit_test(case)\n        results.append(p_val)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3342341"}, {"introduction": "继验证到达间隔时间的分布之后，我们转向均匀泊松过程的另一个基石特性：独立增量性。本练习将教您如何将这一抽象的理论性质转化为一个具体的、可检验的统计假设，即不相交时间区间内事件计数的协方差为零。您将基于中心极限定理构建一个渐近有效的统计检验，并用它来判断您的模拟器是否成功复现了增量的独立性，从而为您提供又一个验证模拟有效性的有力工具 [@problem_id:3342418]。", "problem": "要求您使用模拟来设计、实现和评估一个针对齐次泊松过程独立增量特性的统计检验。该检验应基于在两个不相交子区间上记录的计数之间的样本协方差。您的程序必须实现以下任务。\n\n1) 基本依据和原假设：从以下定义出发：在原假设下，数据由一个具有恒定速率参数 $\\lambda$ 的齐次泊松过程生成，因此对于任何不相交的时间区间，增量是独立的，并且在长度为 $\\ell$ 的区间上的每个增量都服从均值为 $\\lambda \\ell$ 的泊松分布。您必须基于此推导出为什么在原假设下，一个子区间上的计数与一个不相交子区间上的计数之间的理论协方差为 $0$。\n\n2) 检验的构建：使用从增量计数对的 $n$ 次独立重复中计算出的样本协方差，为两个给定不相交子区间上的增量是独立的原假设构建一个渐近有效的水平为 $\\alpha$ 的检验。您必须通过适当形式的独立同分布观测值的中心极限定理，来证明在原假设下，样本协方差的适当标准化版本的渐近分布。\n\n3) 模拟设计：\n- 对于每次重复 $i \\in \\{1,\\dots,n\\}$，模拟计数对 $(X_i,Y_i)$，其中 $X_i$ 是第一个子区间上的计数，$Y_i$ 是第二个不相交子区间上的计数。\n- 对于齐次泊松情况，使用恒定速率 $\\lambda$ 和区间长度 $\\ell_1$ 和 $\\ell_2$ 来模拟不相交子区间的计数。除了确保不相交性外，不需要总的时间范围长度 $T$；您可以直接为这两个子区间模拟泊松增量。\n- 此外，为了探究检验检测独立增量违规的能力，通过为每次重复引入一个共享的潜在速率来模拟一个在不相交区间上具有依赖性的备择过程。具体来说，对于每次重复，从形状参数为 $a$、速率参数为 $b$ 的 Gamma 分布中独立抽取一个潜在速率 $\\Theta_i$（因此 $\\mathbb{E}[\\Theta_i]=a/b$ 且 $\\mathrm{Var}(\\Theta_i)=a/b^2$），然后，在以 $\\Theta_i$ 为条件下，独立地抽取 $X_i \\mid \\Theta_i \\sim \\mathrm{Poisson}(\\Theta_i \\ell_1)$ 和 $Y_i \\mid \\Theta_i \\sim \\mathrm{Poisson}(\\Theta_i \\ell_2)$。这在边际上产生了正相关的增量。\n\n4) 检验决策：对于每组参数，计算在显著性水平 $\\alpha$ 下的双边决策规则，如果原假设被拒绝，则返回布尔值 $\\mathrm{True}$，否则返回 $\\mathrm{False}$。证明您使用渐近近似的合理性。\n\n5) 数值精度和可复现性：使用固定的随机种子，以使输出可复现。不涉及物理单位。所有角度（如有）均不相关。将所有最终数值答案表示为不带任何百分号的布尔值。\n\n测试套件：\n实现您的程序以评估以下四组参数。每组参数定义了一个数据生成机制和检验参数。\n\n- 案例 A (齐次泊松，均衡长度，典型速率)：$\\lambda = 3.5$, $\\ell_1 = 5.0$, $\\ell_2 = 5.0$, $n = 40000$, $\\alpha = 0.01$。\n- 案例 B (通过 Gamma 混合 Cox 过程的依赖性备择假设)：$a = 2.0$, $b = 1.0$, $\\ell_1 = 5.0$, $\\ell_2 = 5.0$, $n = 20000$, $\\alpha = 0.01$。\n- 案例 C (齐次泊松，极低平均计数)：$\\lambda = 0.05$, $\\ell_1 = 0.25$, $\\ell_2 = 0.25$, $n = 150000$, $\\alpha = 0.01$。\n- 案例 D (齐次泊松，不等长度)：$\\lambda = 2.0$, $\\ell_1 = 1.0$, $\\ell_2 = 9.0$, $n = 40000$, $\\alpha = 0.01$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[True,False,True,False]\"），其中每个条目都是一个布尔值，指示在该案例下是否拒绝独立增量的原假设（拒绝为 $\\mathrm{True}$，不拒绝为 $\\mathrm{False}$）。", "solution": "用户提供的问题已经过分析，并被认为是有效的。它在科学上基于随机过程和统计推断理论，问题提出得当，目标明确，信息充分，并使用了精确、客观的语言。模拟设计和参数值对于该任务是可行且适当的。因此，我们可以着手解决。\n\n该问题要求设计和实现一个针对齐次泊松过程独立增量特性的统计检验。根据要求，解决方案分为四个部分：理论基础、检验构建、模拟设计和决策规则。\n\n### 1. 基本依据和原假设\n\n原假设 $H_0$ 是观测数据由一个具有恒定速率参数 $\\lambda  0$ 的齐次泊松过程生成。这样一个过程 $\\{N(t) : t \\ge 0\\}$ 的一个关键特性是它具有独立增量。这意味着对于任何不相交时间区间的集合 $[t_1, s_1], [t_2, s_2], \\dots, [t_k, s_k]$，代表这些区间内计数的随机变量 $N(s_1) - N(t_1), N(s_2) - N(t_2), \\dots, N(s_k) - N(t_k)$ 是相互独立的。\n\n设 $X$ 是子区间 $[t_a, t_a+\\ell_1]$ 上的计数，$Y$ 是不相交子区间 $[t_b, t_b+\\ell_2]$ 上的计数。在 $H_0$ 下，$X$ 和 $Y$ 是独立的随机变量。此外，对于齐次泊松过程，任何长度为 $\\ell$ 的区间上的计数服从均值为 $\\lambda \\ell$ 的泊松分布。因此，我们有：\n$$\nX \\sim \\mathrm{Poisson}(\\lambda \\ell_1) \\\\\nY \\sim \\mathrm{Poisson}(\\lambda \\ell_2)\n$$\n我们的目标是证明在 $H_0$ 下，$X$ 和 $Y$ 之间的理论协方差为零。协方差定义为：\n$$\n\\mathrm{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n$$\n独立随机变量的一个基本性质是，它们乘积的期望等于它们各自期望的乘积。由于在 $H_0$ 下 $X$ 和 $Y$ 是独立的，因此直接得出：\n$$\n\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y]\n$$\n将此代入协方差的定义中，得到：\n$$\n\\mathrm{Cov}(X, Y) = \\mathbb{E}[X]\\mathbb{E}[Y] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0\n$$\n这证实了对于齐次泊松过程，任何两个不相交区间上计数的协方差为零，这是独立增量特性的直接结果。因此，我们的统计检验将是检验原假设 $H_0: \\mathrm{Cov}(X, Y) = 0$ 与备择假设 $H_1: \\mathrm{Cov}(X, Y) \\neq 0$。\n\n### 2. 检验的构建\n\n为了构建一个渐近有效的水平为 $\\alpha$ 的检验，我们使用一个由 $n$ 次独立重复的计数对组成的样本，记为 $(X_i, Y_i)$，其中 $i = 1, \\dots, n$。每一对都是从 $(X, Y)$ 的联合分布中进行的独立同分布 (i.i.d.) 抽样。\n\n协方差 $\\gamma_{12} = \\mathrm{Cov}(X, Y)$ 的自然估计量是样本协方差。我们使用估计量：\n$$\n\\hat{\\gamma}_{12} = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y}) = \\left(\\frac{1}{n} \\sum_{i=1}^n X_i Y_i\\right) - \\bar{X}\\bar{Y}\n$$\n其中 $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i$ 和 $\\bar{Y} = \\frac{1}{n} \\sum_{i=1}^n Y_i$ 是样本均值。\n\n为了标准化这个估计量，我们需要它的渐近分布。令 $V_i = (X_i - \\mathbb{E}[X])(Y_i - \\mathbb{E}[Y])$。序列 $\\{V_i\\}$ 是独立同分布的。在 $H_0$ 下，$\\mathbb{E}[V_i] = \\mathrm{Cov}(X, Y) = 0$。根据中心极限定理 (CLT)，对于大的 $n$：\n$$\n\\sqrt{n} \\left( \\frac{1}{n} \\sum_{i=1}^n V_i - 0 \\right) \\xrightarrow{d} N(0, \\mathrm{Var}(V_1))\n$$\n其中 $\\xrightarrow{d}$ 表示依分布收敛。在 $H_0$ 下，$V_1$ 的方差是：\n$$\n\\mathrm{Var}(V_1) = \\mathrm{Var}((X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])) = \\mathbb{E}[((X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y]))^2] - (\\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])])^2\n$$\n第二项是 $(\\mathrm{Cov}(X, Y))^2$，在 $H_0$ 下为 $0$。由于在 $H_0$ 下 $X$ 和 $Y$ 是独立的，乘积的期望等于期望的乘积：\n$$\n\\mathrm{Var}(V_1) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] \\cdot \\mathbb{E}[(Y - \\mathbb{E}[Y])^2] = \\mathrm{Var}(X)\\mathrm{Var}(Y)\n$$\n用其一致的样本估计量 $\\bar{X}$ 和 $\\bar{Y}$ 替换未知的总体均值 $\\mathbb{E}[X]$ 和 $\\mathbb{E}[Y]$ 不会改变渐近分布。因此，$\\sqrt{n}\\hat{\\gamma}_{12}$ 具有相同的极限分布：\n$$\n\\sqrt{n} \\hat{\\gamma}_{12} \\xrightarrow{d} N(0, \\mathrm{Var}(X)\\mathrm{Var}(Y))\n$$\n通过用渐近标准差的一致估计量来标准化 $\\hat{\\gamma}_{12}$，可以得到检验统计量 $T$。在 $H_0$ 下，我们知道 $X \\sim \\mathrm{Poisson}(\\lambda \\ell_1)$ 且 $Y \\sim \\mathrm{Poisson}(\\lambda \\ell_2)$。泊松分布的一个性质是其方差等于其均值。因此，$\\mathrm{Var}(X) = \\mathbb{E}[X] = \\lambda \\ell_1$ 且 $\\mathrm{Var}(Y) = \\mathbb{E}[Y] = \\lambda \\ell_2$。\n我们可以使用样本均值来一致地估计这些方差，即 $\\widehat{\\mathrm{Var}}(X) = \\bar{X}$ 和 $\\widehat{\\mathrm{Var}}(Y) = \\bar{Y}$。因此，渐近方差 $\\mathrm{Var}(X)\\mathrm{Var}(Y)$ 的一个一致估计量是 $\\bar{X}\\bar{Y}$。\n\n最终的检验统计量是：\n$$\nT = \\frac{\\sqrt{n} \\hat{\\gamma}_{12}}{\\sqrt{\\bar{X}\\bar{Y}}}\n$$\n在 $H_0$ 下，当 $n \\to \\infty$ 时，$T \\xrightarrow{d} N(0, 1)$。\n\n### 3. 模拟设计\n\n模拟按规定针对两种类型的过程进行：\n\n-   **齐次泊松过程（原假设）：** 对于给定的速率 $\\lambda$ 和区间长度 $\\ell_1$ 和 $\\ell_2$，我们生成 $n$ 对独立同分布的 $(X_i, Y_i)$，其中 $X_i \\sim \\mathrm{Poisson}(\\lambda \\ell_1)$ 和 $Y_i \\sim \\mathrm{Poisson}(\\lambda \\ell_2)$ 是独立抽取的。这正确地模拟了在 $H_0$ 下两个不相交区间中的计数。\n\n-   **Gamma 混合 Cox 过程（备择假设）：** 这个过程引入了依赖性。对于每次重复 $i \\in \\{1, \\dots, n\\}$，从 Gamma 分布中抽取一个共享的潜在速率 $\\Theta_i$，即 $\\Theta_i \\sim \\mathrm{Gamma}(a, b)$。以该速率为条件，计数 $X_i$ 和 $Y_i$ 从泊松分布中独立抽取：$X_i | \\Theta_i \\sim \\mathrm{Poisson}(\\Theta_i \\ell_1)$ 和 $Y_i | \\Theta_i \\sim \\mathrm{Poisson}(\\Theta_i \\ell_2)$。$\\Theta_i$ 的共享随机性在 $X_i$ 和 $Y_i$ 之间引入了正相关，因为 $\\mathrm{Cov}(X_i, Y_i) = \\ell_1 \\ell_2 \\mathrm{Var}(\\Theta_i) = \\ell_1 \\ell_2 (a/b^2)  0$。这个案例用于检验我们的检验在拒绝错误的原假设时的功效（power）。\n\n将使用固定的随机种子以确保所有模拟的可复现性。\n\n### 4. 检验决策\n\n对于每组参数，我们在显著性水平 $\\alpha$ 下执行双边检验。决策规则基于检验统计量 $T$ 的渐近标准正态分布。\n\n设 $z_{q}$ 为标准正态分布的 $q$-分位数。对于水平为 $\\alpha$ 的双边检验，我们找到临界值 $z_{1-\\alpha/2}$。如果观测到的检验统计量的绝对值超过此临界值，则拒绝原假设 $H_0: \\mathrm{Cov}(X, Y) = 0$。\n\n决策规则是：\n$$\n\\text{如果 } |T|  z_{1-\\alpha/2} \\text{，则拒绝 } H_0\n$$\n问题指定了大的样本量（$n \\ge 20000$），这为使用此渐近近似提供了有力的理由。中心极限定理确保了学生化统计量 $T$ 的抽样分布将非常接近 $N(0, 1)$ 分布，使得检验的实际水平（actual size）接近名义水平 $\\alpha$。每个案例的最终输出是一个布尔值：如果拒绝 $H_0$，则为 `True`，否则为 `False`。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Designs, implements, and evaluates a statistical test for the independent \n    increments property of a homogeneous Poisson process.\n    \"\"\"\n\n    # Define the test suite with four parameter sets.\n    test_cases = [\n        {\n            'name': 'Case A', 'type': 'poisson', 'n': 40000, 'alpha': 0.01,\n            'params': {'lambda': 3.5, 'l1': 5.0, 'l2': 5.0}\n        },\n        {\n            'name': 'Case B', 'type': 'gamma_mixed', 'n': 20000, 'alpha': 0.01,\n            'params': {'a': 2.0, 'b': 1.0, 'l1': 5.0, 'l2': 5.0}\n        },\n        {\n            'name': 'Case C', 'type': 'poisson', 'n': 150000, 'alpha': 0.01,\n            'params': {'lambda': 0.05, 'l1': 0.25, 'l2': 0.25}\n        },\n        {\n            'name': 'Case D', 'type': 'poisson', 'n': 40000, 'alpha': 0.01,\n            'params': {'lambda': 2.0, 'l1': 1.0, 'l2': 9.0}\n        }\n    ]\n\n    # Use a fixed random seed for reproducibility.\n    rng = np.random.default_rng(seed=42)\n    results = []\n\n    for case in test_cases:\n        n = case['n']\n        alpha = case['alpha']\n        params = case['params']\n        \n        # --- 3) Simulation Design ---\n        if case['type'] == 'poisson':\n            # Null hypothesis: Homogeneous Poisson process with independent increments.\n            # Directly simulate the counts for the two disjoint subintervals.\n            lam = params['lambda']\n            l1 = params['l1']\n            l2 = params['l2']\n            \n            mean_X = lam * l1\n            mean_Y = lam * l2\n            \n            X = rng.poisson(mean_X, size=n)\n            Y = rng.poisson(mean_Y, size=n)\n\n        elif case['type'] == 'gamma_mixed':\n            # Alternative hypothesis: Dependent increments via a Gamma-mixed Cox process.\n            a = params['a']\n            b = params['b']\n            l1 = params['l1']\n            l2 = params['l2']\n            \n            # The rate parameter b for the Gamma distribution corresponds to scale=1/b in SciPy/NumPy.\n            # Simulate a shared latent rate for each replication.\n            latent_rate_theta = rng.gamma(shape=a, scale=1.0/b, size=n)\n            \n            # Conditionally on the latent rate, simulate the Poisson counts.\n            X = rng.poisson(latent_rate_theta * l1)\n            Y = rng.poisson(latent_rate_theta * l2)\n        \n        # --- 2) Test Construction and 4) Test Decision ---\n        \n        # Compute sample means\n        x_bar = np.mean(X)\n        y_bar = np.mean(Y)\n\n        # Compute sample covariance estimator: E[XY] - E[X]E[Y]\n        # This is the estimator gamma_hat_12 from the solution description.\n        sample_cov = np.mean(X * Y) - x_bar * y_bar\n        \n        # Handle the edge case where a mean is zero, which implies all counts for that\n        # variable were zero. In this case, the sample covariance is guaranteed to be zero.\n        # The test statistic is 0, leading to non-rejection.\n        if x_bar = 0 or y_bar = 0:\n            test_statistic = 0.0\n        else:\n            # Under H0, Var(X) = E[X] and Var(Y) = E[Y]. We estimate Var(X)Var(Y)\n            # with x_bar * y_bar.\n            asymptotic_variance_est = x_bar * y_bar\n            \n            # Compute the asymptotically N(0,1) test statistic T\n            test_statistic = np.sqrt(n) * sample_cov / np.sqrt(asymptotic_variance_est)\n\n        # Find the two-sided critical value from the standard normal distribution\n        critical_value = norm.ppf(1 - alpha / 2.0)\n\n        # The decision rule: reject H0 if |T| > z_{1-alpha/2}\n        reject_null = np.abs(test_statistic) > critical_value\n        results.append(reject_null)\n\n    # Format the final output as a comma-separated list of booleans.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3342418"}]}