{"hands_on_practices": [{"introduction": "在我们使用一个工具之前，首先需要理解它的来源。第一个练习将引导你推导有效样本量最常用的一个公式 [@problem_id:3304977]。这个推导基于一个核心思想：将自归一化重要性采样估计量的方差与一个具有 $N_{\\mathrm{eff}}$ 个独立样本的理想估计量的方差相匹配。通过这个练习，你将巩固 ESS 是衡量权重不均匀性所导致的方差损失的直观理解，并证明 ESS 的一个关键性质——它对权重的整体缩放是不变的。", "problem": "考虑一个目标分布，其在 $\\mathbb{R}^{d}$ 上的密度为 $\\pi(x)$，以及一个被积函数 $h:\\mathbb{R}^{d}\\to\\mathbb{R}$，在分布 $\\pi$ 下具有有限方差。设 $x_{1},\\dots,x_{N}$ 是从一个提议密度 $q(x)$ 中抽取的独立样本，并定义未归一化的重要性权重 $w_{i}=\\pi(x_{i})/q(x_{i})0$。$I=\\mathbb{E}_{\\pi}[h(X)]$ 的自归一化重要性采样（SNIS）估计量为 $\\hat{I}_{\\mathrm{SN}}=\\sum_{i=1}^{N}\\tilde{w}_{i}h(x_{i})$，其中归一化权重为 $\\tilde{w}_{i}=w_{i}/\\sum_{j=1}^{N}w_{j}$。将有效样本量（ESS）定义为数量 $N_{\\mathrm{eff}}$，使得 $\\hat{I}_{\\mathrm{SN}}$ 的方差与 $N_{\\mathrm{eff}}$ 个独立目标样本的等权重平均值的方差相匹配，其含义如下：利用独立同分布随机变量加权平均的方差性质，将 $\\operatorname{Var}(\\hat{I}_{\\mathrm{SN}})$ 用 $\\tilde{w}_{i}$ 表示，并使其等于在分布 $\\pi$ 下 $N_{\\mathrm{eff}}$ 个独立的 $h(X)$ 副本的等权重平均值的方差。推导出 $N_{\\mathrm{eff}}$ 关于未归一化权重 $\\{w_{i}\\}_{i=1}^{N}$ 的显式表达式。\n\n接下来，评估 $N_{\\mathrm{eff}}$ 对未归一化权重缩放的敏感性：对于一个常数 $c0$，考虑缩放后的权重 $w_{i}\\mapsto c\\,w_{i}$，并计算导数 $\\frac{\\mathrm{d}}{\\mathrm{d}c}N_{\\mathrm{eff}}(c\\,w_{1},\\dots,c\\,w_{N})$ 在任意 $c0$ 处的值。\n\n将您的最终答案表示为一个双元素行向量，按顺序包含：用 $\\{w_{i}\\}$ 表示的 $N_{\\mathrm{eff}}$ 的推导表达式，以及 $\\frac{\\mathrm{d}}{\\mathrm{d}c}N_{\\mathrm{eff}}(c\\,w_{1},\\dots,c\\,w_{N})$ 的简化解析表达式。无需四舍五入。", "solution": "该问题提出了两个任务：第一，根据指定的方差匹配条件，为自归一化重要性采样（SNIS）估计量推导有效样本量（$N_{\\mathrm{eff}}$）的表达式；第二，评估此 $N_{\\mathrm{eff}}$对未归一化权重的全局缩放的敏感性。\n\n我们从第一个任务开始：推导 $N_{\\mathrm{eff}}$。\n\n问题将有效样本量 $N_{\\mathrm{eff}}$ 定义为：从目标分布 $\\pi(x)$ 中抽取的独立样本数量，其构成的估计量与 SNIS 估计量 $\\hat{I}_{\\mathrm{SN}}$ 具有相同的方差。\n\n首先，让我们确定基准估计量的方差。对于 $I = \\mathbb{E}_{\\pi}[h(X)]$，一个基于直接从目标分布 $\\pi(x)$ 中抽取的 $N_{\\mathrm{eff}}$ 个独立同分布（i.i.d.）样本 $\\{X'_j\\}_{j=1}^{N_{\\mathrm{eff}}}$ 的理想蒙特卡洛估计量是简单均值 $\\hat{I}_{\\mathrm{MC}} = \\frac{1}{N_{\\mathrm{eff}}} \\sum_{j=1}^{N_{\\mathrm{eff}}} h(X'_j)$。该估计量的方差由下式给出：\n$$\n\\operatorname{Var}(\\hat{I}_{\\mathrm{MC}}) = \\operatorname{Var}\\left(\\frac{1}{N_{\\mathrm{eff}}} \\sum_{j=1}^{N_{\\mathrm{eff}}} h(X'_j)\\right) = \\frac{1}{N_{\\mathrm{eff}}^2} \\sum_{j=1}^{N_{\\mathrm{eff}}} \\operatorname{Var}_{\\pi}(h(X)) = \\frac{N_{\\mathrm{eff}}}{N_{\\mathrm{eff}}^2} \\operatorname{Var}_{\\pi}(h(X)) = \\frac{\\sigma_{\\pi}^2}{N_{\\mathrm{eff}}}\n$$\n其中 $\\sigma_{\\pi}^2 = \\operatorname{Var}_{\\pi}(h(X))$ 是被积函数 $h(X)$ 在目标分布 $\\pi$ 下的方差。\n\n接下来，我们考虑 SNIS 估计量 $\\hat{I}_{\\mathrm{SN}} = \\sum_{i=1}^{N}\\tilde{w}_{i}h(x_{i})$，其中 $x_i$ 是从提议分布 $q(x)$ 中抽取的 i.i.d. 样本，而 $\\tilde{w}_i$ 是归一化的重要性权重。$\\operatorname{Var}(\\hat{I}_{\\mathrm{SN}})$ 的严格推导是复杂的，因为权重 $\\tilde{w}_i$ 本身就是随机变量且相互关联。但是，问题陈述给出了一个具体指令：“利用独立同分布随机变量加权平均的方差性质，将 $\\operatorname{Var}(\\hat{I}_{\\mathrm{SN}})$ 用 $\\tilde{w}_{i}$ 表示”。\n\n这引导我们采用一个常见的启发式模型，在该模型中，通过将归一化权重 $\\tilde{w}_i$ 视为固定的、预先计算好的常数，并假装被平均的随机变量（我们称之为 $Z_i$）是从*目标*分布 $\\pi$ 中抽取的 i.i.d. 样本，来近似估计量的方差。在这个简化模型下，加权和 $\\sum_{i=1}^{N} \\tilde{w}_i Z_i$ 的方差为（其中 $Z_i$ 是独立同分布的，方差为 $\\sigma_{\\pi}^2$）：\n$$\n\\operatorname{Var}\\left(\\sum_{i=1}^{N} \\tilde{w}_i Z_i\\right) = \\sum_{i=1}^{N} \\operatorname{Var}(\\tilde{w}_i Z_i) = \\sum_{i=1}^{N} \\tilde{w}_i^2 \\operatorname{Var}(Z_i) = \\left(\\sum_{i=1}^{N} \\tilde{w}_i^2\\right) \\sigma_{\\pi}^2\n$$\n这就是我们被要求使用的 $\\hat{I}_{\\mathrm{SN}}$ 的方差表达式。\n\n根据问题对 $N_{\\mathrm{eff}}$ 的定义，我们必须使两个方差表达式相等：\n$$\n\\frac{\\sigma_{\\pi}^2}{N_{\\mathrm{eff}}} = \\left(\\sum_{i=1}^{N} \\tilde{w}_i^2\\right) \\sigma_{\\pi}^2\n$$\n假设 $h(x)$ 在分布 $\\pi$ 下不是几乎处处为常数，则有 $\\sigma_{\\pi}^2 > 0$，我们可以用 $\\sigma_{\\pi}^2$ 除以等式两边来求解 $N_{\\mathrm{eff}}$：\n$$\nN_{\\mathrm{eff}} = \\frac{1}{\\sum_{i=1}^{N} \\tilde{w}_i^2}\n$$\n问题要求用未归一化的权重 $w_i = \\pi(x_i)/q(x_i)$ 来表示这个表达式。归一化的权重是 $\\tilde{w}_i = w_i / \\sum_{j=1}^{N} w_j$。将此代入我们关于 $N_{\\mathrm{eff}}$ 的表达式中：\n$$\nN_{\\mathrm{eff}} = \\frac{1}{\\sum_{i=1}^{N} \\left(\\frac{w_i}{\\sum_{j=1}^{N} w_j}\\right)^2} = \\frac{1}{\\frac{\\sum_{i=1}^{N} w_i^2}{\\left(\\sum_{j=1}^{N} w_j\\right)^2}}\n$$\n简化后得到我们答案的第一部分：\n$$\nN_{\\mathrm{eff}} = \\frac{\\left(\\sum_{i=1}^{N} w_i\\right)^2}{\\sum_{i=1}^{N} w_i^2}\n$$\n\n现在进行第二个任务，我们必须评估 $N_{\\mathrm{eff}}$ 对未归一化权重缩放的敏感性。让我们考虑一组缩放后的权重 $w'_i = c w_i$，其中常数 $c > 0$。我们将 $N_{\\mathrm{eff}}(c)$ 定义为使用这些缩放后权重计算的有效样本量：\n$$\nN_{\\mathrm{eff}}(c) = N_{\\mathrm{eff}}(c w_1, \\dots, c w_N) = \\frac{\\left(\\sum_{i=1}^{N} (c w_i)\\right)^2}{\\sum_{i=1}^{N} (c w_i)^2}\n$$\n我们可以从求和中提出常数 $c$：\n$$\nN_{\\mathrm{eff}}(c) = \\frac{\\left(c \\sum_{i=1}^{N} w_i\\right)^2}{\\sum_{i=1}^{N} c^2 w_i^2} = \\frac{c^2 \\left(\\sum_{i=1}^{N} w_i\\right)^2}{c^2 \\sum_{i=1}^{N} w_i^2}\n$$\n因为 $c > 0$，所以有 $c^2 \\neq 0$，因此我们可以消去分子和分母中的 $c^2$ 项：\n$$\nN_{\\mathrm{eff}}(c) = \\frac{\\left(\\sum_{i=1}^{N} w_i\\right)^2}{\\sum_{i=1}^{N} w_i^2}\n$$\n这个表达式与 $N_{\\mathrm{eff}}$ 的原始表达式相同，并且与缩放因子 $c$ 无关。这是预料之中的，因为归一化权重的过程 $\\tilde{w}_i = w_i / \\sum_j w_j$ 内在地消除了任何全局缩放因子。缩放后的归一化权重为 $\\tilde{w}'_i = \\frac{c w_i}{\\sum_j (c w_j)} = \\frac{c w_i}{c \\sum_j w_j} = \\tilde{w}_i$，因此量 $N_{\\mathrm{eff}} = 1/\\sum_i \\tilde{w}_i^2$ 显然是对缩放不变的。\n\n由于 $N_{\\mathrm{eff}}(c)$ 是关于 $c$ 的常数函数，其关于 $c$ 的导数对于任何 $c > 0$都必须为零。\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}c}N_{\\mathrm{eff}}(c\\,w_{1},\\dots,c\\,w_{N}) = \\frac{\\mathrm{d}}{\\mathrm{d}c} \\left( \\frac{\\left(\\sum_{i=1}^{N} w_i\\right)^2}{\\sum_{i=1}^{N} w_i^2} \\right) = 0\n$$\n这就完成了问题的第二部分。我们按照要求将两个结果组合成一个行向量。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\left(\\sum_{i=1}^{N} w_i\\right)^2}{\\sum_{i=1}^{N} w_i^2}  0\n\\end{pmatrix}\n}\n$$", "id": "3304977"}, {"introduction": "有了理论公式，我们如何在现实世界中进行计算呢？这个练习关注一个至关重要的实现细节：在重要性采样等应用中，权重往往具有极大的动态范围，因此通常在对数空间中计算以避免数值溢出或下溢 [@problem_id:3304971]。本练习要求你利用“log-sum-exp”技巧设计一个数值稳定的算法来计算 ESS，这是计算统计学和机器学习领域的一项核心技能。", "problem": "给定一个加权样本集合，其未归一化权重仅通过其自然对数形式给出。设有 $N$ 个样本，索引为 $i \\in \\{1,\\dots,N\\}$，其未归一化的正权重为 $W_i \\in (0,\\infty)$，定义对数权重为 $\\ell_i = \\log W_i \\in \\mathbb{R} \\cup \\{-\\infty\\}$。加权估计量由归一化权重 $w_i = W_i / \\sum_{j=1}^{N} W_j$ 构成，而有效样本量（ESS）是一个量，它使得该加权估计量的方差等于一个具有相同基础样本但权重相等的无权估计量的方差。你的任务是从独立随机变量的方差性质出发，推导出以权重表示的ESS，然后设计一个数值稳定的算法，该算法仅在 $\\ell_i$ 上操作来计算ESS，而不显式生成 $W_i$，并且在 $\\ell_i$ 非常大（正或负）或等于 $-\\infty$ 时不会牺牲数值精度。\n\n在你的推导中使用以下基本依据：\n- 对于具有共同方差 $\\sigma^2$ 的独立、均值为零的随机变量 $Z_i$，其线性组合的方差为 $\\mathrm{Var}\\left(\\sum_{i=1}^{N} a_i Z_i\\right) = \\sigma^2 \\sum_{i=1}^{N} a_i^2$。\n- 对于有 $N$ 个样本的无权平均，权重相等，为 $a_i = 1/N$，产生的方差为 $\\sigma^2 / N$。\n\n基于这些基础，完成以下所有任务：\n1. 从第一性原理出发，推导出有效样本量（ESS）关于权重 $W_i$ 及其归一化版本 $w_i$ 的闭式表达式。不要假设任何快捷公式；展示ESS是如何通过将加权估计量的方差与无权估计量的方差相等而得出的。\n2. 从推导出的表达式出发，展示如何通过在对数域中处理和与积，仅使用对数权重 $\\ell_i$ 来计算ESS。你的推导必须明确展示一个避免对非常大或非常小的数直接进行指数运算的变换。\n3. 解释如果天真地对 $\\ell_i$ 进行指数运算以形成 $W_i$ 时出现的数值不稳定性，包括当 $\\ell_i$ 很大时发生上溢和当 $\\ell_i$ 是很大的负数时发生下溢的情况。提供利用对数域来缓解这些问题的精确数值稳定变换。\n4. 为所有 $\\ell_i = -\\infty$（这意味着所有 $W_i = 0$）的退化情况，指定一个稳健的约定。在此约定下，定义你的程序必须返回的ESS值。\n\n然后，实现一个完整且可运行的程序，该程序：\n- 不消耗任何输入，仅使用下面指定的测试套件。\n- 对于每个测试用例，使用你的数值稳定方法从给定的对数权重列表中计算ESS，该方法不显式生成 $W_i$，也不需要在浮点运算中对 $w_i$ 进行归一化。\n- 生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，其中包含所有测试用例的ESS值，四舍五入到小数点后 $10$ 位。输出格式必须严格为 $[r_1,r_2,\\dots,r_m]$，其中每个 $r_k$ 是小数点后有 $10$ 位数字的十进制字符串。\n\n不涉及物理单位；不涉及角度。所有答案必须按上述规定表示为浮点十进制数。\n\n测试套件（每个案例都是一个对数权重向量）：\n- 案例1（均匀权重）：$\\ell = [0.0, 0.0, 0.0, 0.0, 0.0]$。\n- 案例2（具有层级结构的极大正对数权重）：$\\ell = [1000.0, 999.0, 990.0, 900.0, 800.0]$。\n- 案例3（极大负但相等的对数权重）：$\\ell = [-1000.0, -1000.0, -1000.0]$。\n- 案例4（一个主导权重，其他可忽略）：$\\ell = [0.0, -1000.0, -1000.0, -1000.0]$。\n- 案例5（有限值与负无穷的混合）：$\\ell = [0.0, -\\infty, -\\infty, -10.0]$。\n- 案例6（全为负无穷；退化情况）：$\\ell = [-\\infty, -\\infty, -\\infty]$。\n- 案例7（单个样本）：$\\ell = [123.456]$。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表的结果（例如，$[r_1,r_2,\\dots,r_7]$），其中每个 $r_k$ 是对应案例的ESS，四舍五入到小数点后 $10$ 位。", "solution": "从一组加权样本的对数权重计算其有效样本量（ESS）是计算统计学中的一个标准任务，尤其是在重要性采样和序贯蒙特卡洛方法的背景下。所述问题具有科学依据，是适定的、客观且完整的。我们通过首先从基本原理推导所需表达式，然后设计一个数值稳定的算法来解决该问题。\n\n### 步骤 1：有效样本量（ESS）的推导\n\n我们从问题陈述中列出的基本原理开始。考虑一组 $N$ 个独立同分布、均值为零的随机变量 $Z_i$，每个变量都具有共同方差 $\\mathrm{Var}(Z_i) = \\sigma^2$。\n\n从 $Z_i$ 所抽样的基础分布的均值的加权估计量由 $\\hat{\\mu} = \\sum_{i=1}^{N} w_i Z_i$ 给出，其中 $w_i$ 是归一化权重，满足 $\\sum_{i=1}^{N} w_i = 1$。该估计量的方差使用所提供的独立随机变量线性组合的方差公式 $\\mathrm{Var}\\left(\\sum_{i=1}^{N} a_i Z_i\\right) = \\sigma^2 \\sum_{i=1}^{N} a_i^2$ 来推导。设系数 $a_i = w_i$，我们得到：\n$$ \\mathrm{Var}(\\hat{\\mu}) = \\sigma^2 \\sum_{i=1}^{N} w_i^2 $$\n\n对于一个有 $N_{eff}$ 个样本的标准无权估计量，其权重是均匀的，$a_i = 1/N_{eff}$，其方差为 $\\mathrm{Var}(\\hat{\\mu}_{\\text{unweighted}}) = \\sigma^2 \\sum_{i=1}^{N_{eff}} (1/N_{eff})^2 = \\sigma^2 \\cdot N_{eff} \\cdot (1/N_{eff}^2) = \\sigma^2 / N_{eff}$。\n\n有效样本量（ESS）定义为一个无权估计量需要拥有的样本数量 $n_{eff}$，以使其方差与我们的加权估计量的方差相同。我们记作 $\\mathrm{ESS} = n_{eff}$。因此，我们令两个方差相等：\n$$ \\mathrm{Var}(\\hat{\\mu}) = \\frac{\\sigma^2}{\\mathrm{ESS}} $$\n$$ \\sigma^2 \\sum_{i=1}^{N} w_i^2 = \\frac{\\sigma^2}{\\mathrm{ESS}} $$\n解出ESS，我们得到关于归一化权重 $w_i$ 的第一个所需表达式：\n$$ \\mathrm{ESS} = \\frac{1}{\\sum_{i=1}^{N} w_i^2} $$\n\n归一化权重 $w_i$ 与未归一化的正权重 $W_i$ 通过关系式 $w_i = W_i / S_W$ 相关联，其中 $S_W = \\sum_{j=1}^{N} W_j$ 是未归一化权重的总和。将此代入ESS表达式的分母中得到：\n$$ \\sum_{i=1}^{N} w_i^2 = \\sum_{i=1}^{N} \\left( \\frac{W_i}{\\sum_{j=1}^{N} W_j} \\right)^2 = \\frac{\\sum_{i=1}^{N} W_i^2}{\\left(\\sum_{j=1}^{N} W_j\\right)^2} $$\n将此结果代回ESS的表达式，得到关于未归一化权重 $W_i$ 的闭式表达式：\n$$ \\mathrm{ESS} = \\frac{\\left(\\sum_{j=1}^{N} W_j\\right)^2}{\\sum_{i=1}^{N} W_i^2} $$\n这就完成了第一部分的推导。\n\n### 步骤 2 和 3：从对数权重进行数值稳定的计算\n\n我们已知未归一化权重的自然对数 $\\ell_i = \\log W_i$，这意味着 $W_i = e^{\\ell_i}$。将此代入推导出的ESS公式中，得到：\n$$ \\mathrm{ESS} = \\frac{\\left(\\sum_{i=1}^{N} e^{\\ell_i}\\right)^2}{\\sum_{i=1}^{N} e^{2\\ell_i}} $$\n\n**数值不稳定性：**\n一种天真的实现方法会首先计算权重 $W_i = e^{\\ell_i}$，然后使用该公式。这种方法是数值不稳定的。\n1.  **上溢：** 如果任何 $\\ell_i$ 是大的正数（例如，对于IEEE 754双精度浮点数，$\\ell_i  709.78$），$e^{\\ell_i}$ 的计算将导致上溢（无穷大）。这会污染求和结果，导致不正确或未定义的结果，如 $\\infty/\\infty$。\n2.  **下溢：** 如果任何 $\\ell_i$ 是大的负数（例如，$\\ell_i  -745$），$e^{\\ell_i}$ 将下溢为 $0$。虽然这对于单个权重可能是可接受的，但如果所有权重都很小，它们的和也可能下溢为 $0$，导致除以零的错误。此外，如果权重的动态范围很大，这会导致相对精度的灾难性损失。\n\n**数值稳定变换：**\n为了缓解这些问题，我们采用一种通常称为“log-sum-exp”技巧的标准技术。令 $\\ell_{\\max} = \\max_{i \\in \\{1,\\dots,N\\}} \\ell_i$。我们可以从分子和中提出因子 $e^{\\ell_{\\max}}$，从分母和中提出因子 $e^{2\\ell_{\\max}}$。\n\n令 $S_1 = \\sum_{i=1}^{N} W_i = \\sum_{i=1}^{N} e^{\\ell_i}$ 且 $S_2 = \\sum_{i=1}^{N} W_i^2 = \\sum_{i=1}^{N} e^{2\\ell_i}$。\n我们将 $S_1$ 重写为：\n$$ S_1 = \\sum_{i=1}^{N} e^{\\ell_i - \\ell_{\\max}} e^{\\ell_{\\max}} = e^{\\ell_{\\max}} \\sum_{i=1}^{N} e^{\\ell_i - \\ell_{\\max}} $$\n我们将 $S_2$ 重写为：\n$$ S_2 = \\sum_{i=1}^{N} e^{2\\ell_i - 2\\ell_{\\max}} e^{2\\ell_{\\max}} = e^{2\\ell_{\\max}} \\sum_{i=1}^{N} e^{2(\\ell_i - \\ell_{\\max})} $$\n\n现在，将这些因子化形式代回 ESS 表达式 $\\mathrm{ESS} = S_1^2 / S_2$ 中：\n$$ \\mathrm{ESS} = \\frac{\\left(e^{\\ell_{\\max}} \\sum_{i=1}^{N} e^{\\ell_i - \\ell_{\\max}}\\right)^2}{e^{2\\ell_{\\max}} \\sum_{i=1}^{N} e^{2(\\ell_i - \\ell_{\\max})}} = \\frac{e^{2\\ell_{\\max}} \\left(\\sum_{i=1}^{N} e^{\\ell_i - \\ell_{\\max}}\\right)^2}{e^{2\\ell_{\\max}} \\sum_{i=1}^{N} e^{2(\\ell_i - \\ell_{\\max})}} $$\n$e^{2\\ell_{\\max}}$ 项在代数上被消去，得到最终的数值稳定公式：\n$$ \\mathrm{ESS} = \\frac{\\left(\\sum_{i=1}^{N} e^{\\ell_i - \\ell_{\\max}}\\right)^2}{\\sum_{i=1}^{N} e^{2(\\ell_i - \\ell_{\\max})}} $$\n这个表达式是稳定的，因为指数运算的参数 $\\ell_i - \\ell_{\\max}$ 总是小于或等于 $0$。这可以防止上溢。和中的最大项是 $e^0 = 1$，这为其他相对于一个非常大的数本会下溢的项保留了数值精度。这种变换使我们能够仅通过对数权重的操作来计算ESS，而无需直接生成可能有问题的 $W_i$ 或归一化的 $w_i$ 值。\n\n### 步骤 4：退化情况的约定\n\n当所有对数权重均为负无穷大时，即对于所有 $i \\in \\{1,\\dots,N\\}$ 都有 $\\ell_i = -\\infty$，就会出现退化情况。这对应于所有未归一化权重均为零，$W_i = 0$。\n在这种情况下，权重之和 $\\sum W_i = 0$ 且权重平方和 $\\sum W_i^2 = 0$。ESS 公式变为 $\\mathrm{ESS} = 0^2 / 0$，这是一个不定式。\n\n从统计学的角度来看，一组全为零的权重不提供任何信息，因为没有样本对估计量有贡献。这等效于拥有零个有效样本。因此，最合理且稳健的约定是在这种情况下将ESS定义为 $0$。\n\n在我们的数值稳定算法中，这种情况对应于 $\\ell_{\\max} = -\\infty$。我们必须在进行主要计算之前明确检查此条件，以避免出现 $\\ell_i - \\ell_{\\max} = -\\infty - (-\\infty)$ 的不定式。如果 $\\ell_{\\max} = -\\infty$，算法应返回 $0.0$。对于只有部分而非全部 $\\ell_i$ 为 $-\\infty$ 的情况，稳定公式能正确处理它们：如果 $\\ell_{\\max}$ 是有限的，那么对于一个 $\\ell_i = -\\infty$，项 $\\ell_i - \\ell_{\\max} = -\\infty$，而 $e^{-\\infty}$ 的计算结果为 $0$，从而正确地将该样本从计算中排除。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the effective sample size problem for a predefined test suite.\n    \"\"\"\n\n    def compute_ess(log_weights: np.ndarray) - float:\n        \"\"\"\n        Computes the Effective Sample Size (ESS) from a vector of log-weights\n        using a numerically stable algorithm.\n\n        Args:\n            log_weights: A 1D numpy array of unnormalized log-weights.\n\n        Returns:\n            The calculated ESS as a float.\n        \"\"\"\n        # Ensure input is a numpy array for vectorized operations\n        log_weights = np.asarray(log_weights, dtype=np.float64)\n\n        # Handle the trivial case of a single sample\n        if log_weights.size == 1:\n            return 1.0\n        \n        # Handle the case of an empty set of weights\n        if log_weights.size == 0:\n            return 0.0\n\n        # Find the maximum log-weight\n        max_log_weight = np.max(log_weights)\n\n        # Handle the degenerate case where all log-weights are -inf\n        # This implies all weights are 0, so ESS is 0.\n        if max_log_weight == -np.inf:\n            return 0.0\n\n        # Shift log-weights to prevent overflow/underflow\n        # This is the core of the log-sum-exp trick\n        shifted_log_weights = log_weights - max_log_weight\n        \n        # Calculate the terms for the sums in the stable ESS formula.\n        # Numerator sum's terms: exp(ell_i - ell_max)\n        # Denominator sum's terms: exp(2 * (ell_i - ell_max))\n        # This avoids direct calculation of W_i = exp(ell_i)\n        \n        # Sum of exp(l_i - l_max)\n        s1 = np.sum(np.exp(shifted_log_weights))\n        \n        # Sum of exp(2 * (l_i - l_max)) = sum of (exp(l_i - l_max))^2\n        s2 = np.sum(np.exp(2 * shifted_log_weights))\n        \n        # The terms exp(2 * l_max) from numerator and denominator cancel out\n        # ESS = (sum(W_i))^2 / sum(W_i^2)\n        #     = (exp(l_max) * sum(exp(l_i-l_max)))^2 / (exp(2*l_max) * sum(exp(2*(l_i-l_max))))\n        #     = (sum(exp(l_i-l_max)))^2 / sum(exp(2*(l_i-l_max)))\n        \n        # The denominator s2 cannot be zero if there is at least one finite log-weight,\n        # because the maximum shifted log-weight is 0, making its term exp(0)=1.\n        ess = s1**2 / s2\n        \n        return ess\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([0.0, 0.0, 0.0, 0.0, 0.0]),\n        np.array([1000.0, 999.0, 990.0, 900.0, 800.0]),\n        np.array([-1000.0, -1000.0, -1000.0]),\n        np.array([0.0, -1000.0, -1000.0, -1000.0]),\n        np.array([0.0, -np.inf, -np.inf, -10.0]),\n        np.array([-np.inf, -np.inf, -np.inf]),\n        np.array([123.456])\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_ess(case)\n        # Format to 10 decimal places as specified\n        results.append(f\"{result:.10f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3304971"}, {"introduction": "在对 ESS 建立了坚实的理论和实践基础之后，我们现在可以将其用作一种算法设计工具。最后一个练习将你置于伪边缘马尔可夫链蒙特卡洛（Pseudo-Marginal MCMC）方法的背景下，这是一种功能强大但对参数敏感的算法 [@problem_id:3304999]。你的任务是确定需要多少粒子（particles）来保证似然估计的可靠性，而 ESS 正是平衡计算成本和统计效率的关键诊断指标。这个练习展示了 ESS 如何从一个简单的汇总统计量，转变为算法设计中的一个主动控制参数。", "problem": "考虑一个伪边缘马尔可夫链蒙特卡洛（MCMC）算法，在每次迭代中，该算法使用其似然的一个带噪声的重要性采样估计来评估一个提议的参数值 $X$。具体来说，给定 $X$，抽取 $M$ 个独立的辅助变量 $U^{(1)},\\dots,U^{(M)}$ 并形成权重 $w^{(m)} \\propto L(X,U^{(m)})$，其中无偏似然估计量定义为 $\\hat{L}(X) = \\frac{1}{M} \\sum_{m=1}^{M} w^{(m)}$。假设对于任何固定的 $X$，权重遵循对数正态模型 $w^{(m)} = c(X)\\,\\exp(\\epsilon^{(m)})$，其中 $\\epsilon^{(m)} \\sim \\mathcal{N}(0,\\tau^{2})$，在不同的 $m$ 和迭代中独立，并且 $c(X)0$ 是一个依赖于 $X$ 的确定性尺度因子。\n\n每次迭代，内部重要性权重具有一个有效样本量（ESS），定义为\n$$\nN_{\\mathrm{eff}} = \\frac{\\left(\\sum_{m=1}^{M} w^{(m)}\\right)^{2}}{\\sum_{m=1}^{M} \\left(w^{(m)}\\right)^{2}}.\n$$\n你的目标是：\n1. 每次迭代达到一个目标期望有效样本量 $E\\!\\left[N_{\\mathrm{eff}}\\right] \\geq N_{\\mathrm{eff}}^{\\star}$。\n2. 通过施加设计约束，即似然估计量对数的方差满足 $\\operatorname{Var}\\!\\left(\\ln \\hat{L}(X)\\right) \\leq \\sigma_{\\max}^{2}$，来平衡接受率。\n\n从关于对数正态随机变量的矩和样本和的渐近近似的经过充分检验的定义和事实出发，推导出这两个目标对 $M$ 所隐含的闭式约束。然后，给定 $\\tau^{2} = 1.1$，$N_{\\mathrm{eff}}^{\\star} = 1000$ 和 $\\sigma_{\\max}^{2} = 0.3$，计算同时满足这两个约束的最小整数 $M$。将最终答案表示为单个整数。不需要按有效数字进行四舍五入；报告精确的最小整数。", "solution": "我们从加权样本的有效样本量的定义以及独立同分布随机变量之和的行为开始。\n\n令 $w^{(m)} = c(X)\\,\\exp(\\epsilon^{(m)})$，其中 $\\epsilon^{(m)} \\sim \\mathcal{N}(0,\\tau^{2})$。记 $Y^{(m)} = \\exp(\\epsilon^{(m)})$，因此 $w^{(m)} = c(X) Y^{(m)}$ 且 $Y^{(m)}$ 是独立同分布的对数正态随机变量。$Y^{(m)}$ 的矩为\n$$\nE\\!\\left[Y^{(m)}\\right] = \\exp\\!\\left(\\frac{\\tau^{2}}{2}\\right), \\quad E\\!\\left[\\left(Y^{(m)}\\right)^{2}\\right] = \\exp\\!\\left(2\\tau^{2}\\right), \\quad \\operatorname{Var}\\!\\left(Y^{(m)}\\right) = \\exp\\!\\left(\\tau^{2}\\right)\\left(\\exp\\!\\left(\\tau^{2}\\right) - 1\\right).\n$$\n由于 $w^{(m)} = c(X) Y^{(m)}$，我们有\n$$\nE\\!\\left[w^{(m)}\\right] = c(X) \\exp\\!\\left(\\frac{\\tau^{2}}{2}\\right), \\quad E\\!\\left[\\left(w^{(m)}\\right)^{2}\\right] = c(X)^{2} \\exp\\!\\left(2\\tau^{2}\\right).\n$$\n\n有效样本量约束。根据大数定律，对于较大的 $M$：\n$$\n\\sum_{m=1}^{M} w^{(m)} \\approx M\\,E\\!\\left[w^{(m)}\\right], \\quad \\sum_{m=1}^{M} \\left(w^{(m)}\\right)^{2} \\approx M\\,E\\!\\left[\\left(w^{(m)}\\right)^{2}\\right].\n$$\n因此，\n$$\nE\\!\\left[N_{\\mathrm{eff}}\\right] \\approx \\frac{\\left(M\\,E[w^{(m)}]\\right)^{2}}{M\\,E[(w^{(m)})^{2}]} = M\\,\\frac{\\left(E[w^{(m)}]\\right)^{2}}{E[(w^{(m)})^{2}]}.\n$$\n代入 $w^{(m)}$ 的矩可得\n$$\n\\frac{\\left(E[w^{(m)}]\\right)^{2}}{E[(w^{(m)})^{2}]} = \\frac{\\left(c(X)\\,\\exp(\\tau^{2}/2)\\right)^{2}}{c(X)^{2}\\,\\exp(2\\tau^{2})} = \\exp(-\\tau^{2}),\n$$\n所以\n$$\nE\\!\\left[N_{\\mathrm{eff}}\\right] \\approx M\\,\\exp(-\\tau^{2}).\n$$\n为了达到 $E\\!\\left[N_{\\mathrm{eff}}\\right] \\geq N_{\\mathrm{eff}}^{\\star}$，只需施加\n$$\nM \\geq N_{\\mathrm{eff}}^{\\star}\\,\\exp(\\tau^{2}).\n$$\n\n通过 $\\ln \\hat{L}(X)$ 的方差来平衡接受率。估计量为\n$$\n\\hat{L}(X) = \\frac{1}{M}\\sum_{m=1}^{M} w^{(m)} = c(X)\\,\\bar{Y}, \\quad \\text{其中 } \\bar{Y} = \\frac{1}{M}\\sum_{m=1}^{M} Y^{(m)}.\n$$\n我们使用 delta 方法来近似 $\\operatorname{Var}\\!\\left(\\ln \\hat{L}(X)\\right)$。首先计算 $\\operatorname{Var}(\\bar{Y})$：\n$$\nE[\\bar{Y}] = E[Y^{(1)}] = \\exp\\!\\left(\\frac{\\tau^{2}}{2}\\right), \\quad \\operatorname{Var}(\\bar{Y}) = \\frac{1}{M}\\operatorname{Var}(Y^{(1)}) = \\frac{1}{M}\\exp(\\tau^{2})\\left(\\exp(\\tau^{2}) - 1\\right).\n$$\n令 $g(y) = \\ln y$。对于较大的 $M$，delta 方法给出，\n$$\n\\operatorname{Var}\\!\\left(\\ln \\bar{Y}\\right) \\approx \\left(g'(E[\\bar{Y}])\\right)^{2}\\operatorname{Var}(\\bar{Y}) = \\left(\\frac{1}{E[\\bar{Y}]}\\right)^{2} \\operatorname{Var}(\\bar{Y}) = \\frac{\\operatorname{Var}(\\bar{Y})}{\\left(E[\\bar{Y}]\\right)^{2}}.\n$$\n代入矩，\n$$\n\\operatorname{Var}\\!\\left(\\ln \\bar{Y}\\right) \\approx \\frac{\\frac{1}{M}\\exp(\\tau^{2})\\left(\\exp(\\tau^{2}) - 1\\right)}{\\exp(\\tau^{2})} = \\frac{\\exp(\\tau^{2}) - 1}{M}.\n$$\n因为 $\\hat{L}(X) = c(X)\\,\\bar{Y}$ 且 $c(X)$ 是确定性的，所以 $\\ln \\hat{L}(X) = \\ln c(X) + \\ln \\bar{Y}$，因此\n$$\n\\operatorname{Var}\\!\\left(\\ln \\hat{L}(X)\\right) = \\operatorname{Var}\\!\\left(\\ln \\bar{Y}\\right) \\approx \\frac{\\exp(\\tau^{2}) - 1}{M}.\n$$\n施加 $\\operatorname{Var}\\!\\left(\\ln \\hat{L}(X)\\right) \\leq \\sigma_{\\max}^{2}$ 可得\n$$\n\\frac{\\exp(\\tau^{2}) - 1}{M} \\leq \\sigma_{\\max}^{2} \\quad \\Longrightarrow \\quad M \\geq \\frac{\\exp(\\tau^{2}) - 1}{\\sigma_{\\max}^{2}}.\n$$\n\n结合约束条件。同时满足两个目标的最小整数 $M$ 是\n$$\nM = \\left\\lceil \\max\\left\\{N_{\\mathrm{eff}}^{\\star}\\,\\exp(\\tau^{2}), \\, \\frac{\\exp(\\tau^{2}) - 1}{\\sigma_{\\max}^{2}}\\right\\} \\right\\rceil.\n$$\n\n数值计算。给定 $\\tau^{2} = 1.1$，$N_{\\mathrm{eff}}^{\\star} = 1000$ 和 $\\sigma_{\\max}^{2} = 0.3$：\n$$\n\\exp(1.1) \\approx 3.004166,\n$$\n所以\n$$\nN_{\\mathrm{eff}}^{\\star}\\,\\exp(\\tau^{2}) \\approx 1000 \\times 3.004166 = 3004.166,\n$$\n和\n$$\n\\frac{\\exp(\\tau^{2}) - 1}{\\sigma_{\\max}^{2}} \\approx \\frac{3.004166 - 1}{0.3} = \\frac{2.004166}{0.3} \\approx 6.680553.\n$$\n取最大值并向上取整，\n$$\nM = \\left\\lceil \\max\\{3004.166,\\,6.680553\\} \\right\\rceil = \\left\\lceil 3004.166 \\right\\rceil = 3005.\n$$\n因此，$M = 3005$ 是最小的选择，它既能达到目标期望有效样本量，又将对数似然估计量的方差保持在指定界限内，以维持接受行为。", "answer": "$$\\boxed{3005}$$", "id": "3304999"}]}