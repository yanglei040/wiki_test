{"hands_on_practices": [{"introduction": "任何数值模拟方法的核心都是对连续过程的近似。要深刻理解一种模拟方法的性能，量化其引入的误差是至关重要的第一步。本练习 [@problem_id:3344350] 提供了一个清晰的场景，通过精确计算和比较欧拉-丸山（EM）方法与 Ornstein-Uhlenbeck 过程的精确解在单步内的表现，来量化这种离散化误差。这能让你对模拟误差的来源和特性有一个扎实的、定量的理解。", "problem": "考虑由随机微分方程 (SDE) $dX_{t} = -\\kappa \\left(X_{t} - \\mu \\right) \\, dt + \\sigma \\, dW_{t}$ 定义的 Ornstein–Uhlenbeck (OU) 过程，其中 $\\kappa > 0$ 是均值回归率，$\\mu \\in \\mathbb{R}$ 是长期均值，$\\sigma > 0$ 是扩散系数，$W_{t}$ 是标准维纳过程。您将从 $t = 0$ 开始，在初始条件为 $X_{0} = \\mu$ 的情况下，模拟该过程在长度为 $\\Delta > 0$ 的单个步长上的行为。考虑以下两种单步近似方法：\n\n- 通过求解在 $[0,\\Delta]$ 上的线性 SDE 获得的精确离散化。\n- 由相同的潜在维纳增量驱动以形成强耦合的 Euler–Maruyama 方法。\n\n从 SDE 和 Euler–Maruyama 格式的定义出发，推导单步强均方误差 $E\\!\\left[\\left(X_{\\Delta}^{\\mathrm{EM}} - X_{\\Delta}^{\\mathrm{exact}}\\right)^{2}\\right]$，使其表示为 $\\kappa$、$\\sigma$ 和 $\\Delta$ 的闭式函数，并将其与精确的单步条件方差 $\\operatorname{Var}\\!\\left(X_{\\Delta} \\mid X_{0} = \\mu \\right)$ 进行比较。将相对误差 $R(\\kappa \\Delta)$ 定义为单步强均方误差与 $\\operatorname{Var}\\!\\left(X_{\\Delta} \\mid X_{0} = \\mu \\right)$ 的比值，并提供一个关于 $\\kappa$ 和 $\\Delta$ 的 $R(\\kappa \\Delta)$ 的单一闭式解析表达式。根据此表达式，确定在哪个 $\\kappa \\Delta$ 的区间内相对误差最大。\n\n您的最终答案必须是 $R(\\kappa \\Delta)$ 的单一解析表达式，用 $\\kappa$ 和 $\\Delta$ 表示。无需进行数值四舍五入。", "solution": "Ornstein–Uhlenbeck (OU) 过程遵循线性随机微分方程 $dX_{t} = -\\kappa \\left(X_{t} - \\mu \\right) \\, dt + \\sigma \\, dW_{t}$。对于此类线性 SDE，单步的精确解可以通过积分因子法获得。在区间 $[0,\\Delta]$ 上，初始条件为 $X_{0} = \\mu$ 时，其温和解为\n$$\nX_{\\Delta}^{\\mathrm{exact}} = \\mu + \\sigma \\int_{0}^{\\Delta} \\exp\\!\\left(-\\kappa (\\Delta - s)\\right) \\, dW_{s}.\n$$\n这可以通过令 $Y_{t} = X_{t} - \\mu$（其满足 $dY_{t} = -\\kappa Y_{t} \\, dt + \\sigma \\, dW_{t}$），并应用积分因子 $\\exp(\\kappa t)$ 来得到。\n\n将 Euler–Maruyama 单步格式应用于相同的 SDE，并由相同的维纳增量驱动以实现强耦合，可得\n$$\nX_{\\Delta}^{\\mathrm{EM}} = X_{0} - \\kappa \\left(X_{0} - \\mu\\right) \\Delta + \\sigma \\left(W_{\\Delta} - W_{0}\\right).\n$$\n当 $X_{0} = \\mu$ 时，上式简化为\n$$\nX_{\\Delta}^{\\mathrm{EM}} = \\mu + \\sigma \\left(W_{\\Delta} - W_{0}\\right) = \\mu + \\sigma \\int_{0}^{\\Delta} 1 \\, dW_{s}.\n$$\n因此，在共同驱动 $W$ 下的单步强误差为\n$$\nE_{\\Delta} := X_{\\Delta}^{\\mathrm{EM}} - X_{\\Delta}^{\\mathrm{exact}} = \\sigma \\int_{0}^{\\Delta} \\left(1 - \\exp\\!\\left(-\\kappa (\\Delta - s)\\right)\\right) \\, dW_{s}.\n$$\n根据 Itô 等距定理，单步强均方误差为\n$$\n\\mathrm{MSE}(\\Delta) := E\\!\\left[\\left(E_{\\Delta}\\right)^{2}\\right] = \\sigma^{2} \\int_{0}^{\\Delta} \\left(1 - \\exp\\!\\left(-\\kappa (\\Delta - s)\\right)\\right)^{2} \\, ds.\n$$\n为了计算该积分，进行变量替换 $u = \\Delta - s$，则 $s = \\Delta - u$，$ds = -du$，当 $s$ 从 $0$ 变到 $\\Delta$ 时，$u$ 从 $\\Delta$ 变到 $0$。因此\n$$\n\\int_{0}^{\\Delta} \\left(1 - \\exp\\!\\left(-\\kappa (\\Delta - s)\\right)\\right)^{2} \\, ds\n= \\int_{0}^{\\Delta} \\left(1 - \\exp(-\\kappa u)\\right)^{2} \\, du.\n$$\n展开平方项并逐项积分，\n$$\n\\int_{0}^{\\Delta} \\left(1 - 2 \\exp(-\\kappa u) + \\exp(-2 \\kappa u)\\right) \\, du\n= \\Delta - 2 \\int_{0}^{\\Delta} \\exp(-\\kappa u) \\, du + \\int_{0}^{\\Delta} \\exp(-2 \\kappa u) \\, du.\n$$\n使用 $\\int_{0}^{\\Delta} \\exp(-\\alpha u) \\, du = \\frac{1 - \\exp(-\\alpha \\Delta)}{\\alpha}$（对于 $\\alpha > 0$），我们得到\n$$\n\\int_{0}^{\\Delta} \\left(1 - \\exp(-\\kappa u)\\right)^{2} \\, du\n= \\Delta - \\frac{2 \\left(1 - \\exp(-\\kappa \\Delta)\\right)}{\\kappa}\n+ \\frac{1 - \\exp(-2 \\kappa \\Delta)}{2 \\kappa}.\n$$\n因此，\n$$\n\\mathrm{MSE}(\\Delta) = \\sigma^{2} \\left[ \\Delta - \\frac{2 \\left(1 - \\exp(-\\kappa \\Delta)\\right)}{\\kappa}\n+ \\frac{1 - \\exp(-2 \\kappa \\Delta)}{2 \\kappa} \\right].\n$$\n\n接下来，计算给定 $X_{0} = \\mu$ 时的精确单步条件方差。根据精确解，\n$$\nX_{\\Delta}^{\\mathrm{exact}} - \\mu = \\sigma \\int_{0}^{\\Delta} \\exp\\!\\left(-\\kappa (\\Delta - s)\\right) \\, dW_{s},\n$$\n并根据 Itô 等距定理，\n$$\n\\operatorname{Var}\\!\\left(X_{\\Delta} \\mid X_{0} = \\mu \\right)\n= \\sigma^{2} \\int_{0}^{\\Delta} \\exp\\!\\left(-2 \\kappa (\\Delta - s)\\right) \\, ds\n= \\sigma^{2} \\int_{0}^{\\Delta} \\exp(-2 \\kappa u) \\, du\n= \\sigma^{2} \\frac{1 - \\exp(-2 \\kappa \\Delta)}{2 \\kappa}.\n$$\n\n将相对误差 $R(\\kappa \\Delta)$ 定义为比值\n$$\nR(\\kappa \\Delta) := \\frac{\\mathrm{MSE}(\\Delta)}{\\operatorname{Var}\\!\\left(X_{\\Delta} \\mid X_{0} = \\mu \\right)}.\n$$\n代入上述表达式并化简可得\n$$\nR(\\kappa \\Delta) = \\frac{\\Delta - \\frac{2 \\left(1 - \\exp(-\\kappa \\Delta)\\right)}{\\kappa}\n+ \\frac{1 - \\exp(-2 \\kappa \\Delta)}{2 \\kappa}}{\\frac{1 - \\exp(-2 \\kappa \\Delta)}{2 \\kappa}}\n= \\frac{2 \\kappa \\Delta - 4 \\left(1 - \\exp(-\\kappa \\Delta)\\right) + \\left(1 - \\exp(-2 \\kappa \\Delta)\\right)}{1 - \\exp(-2 \\kappa \\Delta)}.\n$$\n等价地，引入无量纲参数 $\\theta := \\kappa \\Delta$，\n$$\nR(\\theta) = \\frac{2 \\theta - 3 + 4 \\exp(-\\theta) - \\exp(-2 \\theta)}{1 - \\exp(-2 \\theta)}.\n$$\n\n为了确定相对误差最大的区间，考察其极限行为。当 $\\theta \\to 0$ 时，使用展开式 $\\exp(-\\theta) = 1 - \\theta + \\frac{\\theta^{2}}{2} - \\frac{\\theta^{3}}{6} + \\cdots$ 和 $\\exp(-2 \\theta) = 1 - 2 \\theta + 2 \\theta^{2} - \\frac{4}{3} \\theta^{3} + \\cdots$ 可得 $R(\\theta) \\sim \\frac{1}{3} \\theta^{2} \\to 0$。当 $\\theta \\to \\infty$ 时，$\\exp(-\\theta)$ 和 $\\exp(-2 \\theta)$ 趋于零，且 $R(\\theta) \\sim \\frac{2 \\theta - 3}{1} = 2 \\theta - 3$，该式无界增长。因此，当 $\\kappa \\Delta$ 很大时，相对误差最大，也就是说，当时间步长 $\\Delta$ 相对于均值回归时间尺度 $1 / \\kappa$ 较大时。", "answer": "$$\\boxed{\\frac{2 \\kappa \\Delta - 3 + 4 \\exp\\!\\left(-\\kappa \\Delta\\right) - \\exp\\!\\left(-2 \\kappa \\Delta\\right)}{1 - \\exp\\!\\left(-2 \\kappa \\Delta\\right)}}$$", "id": "3344350"}, {"introduction": "离散化误差并不仅仅是理论上的概念，它会对实际应用产生深远影响，尤其是在参数估计中。本练习 [@problem_id:3344342] 设计了一个思想实验，揭示了当使用近似模拟（如 EM 方法）产生的数据，却采用基于精确解的公式来估计模型参数时，会如何引入系统性偏差。这对于任何希望从模拟数据中提取可靠信息的从业者来说，都是一个深刻的教训。", "problem": "考虑由随机微分方程（SDE）$dX_{t} = \\theta (\\mu - X_{t}) \\, dt + \\sigma \\, dW_{t}$ 定义的奥恩斯坦-乌伦贝克（OU）过程，其中 $\\theta > 0$，$\\mu \\in \\mathbb{R}$，$\\sigma > 0$，$W_{t}$ 是一个标准维纳过程。假设使用固定时间步长 $\\Delta > 0$ 的欧拉-丸山（EM）格式来模拟 $\\{X_{n\\Delta}\\}_{n=0}^{N}$，即 $X_{(n+1)\\Delta} = X_{n\\Delta} + \\theta(\\mu - X_{n\\Delta}) \\Delta + \\sigma \\sqrt{\\Delta} \\,\\varepsilon_{n}$，其中 $\\varepsilon_{n}$ 是独立的标准正态随机变量。然后，一位分析师忽略了数据是由欧拉-丸山格式生成的事实，对 $\\{X_{n\\Delta}\\}$ 拟合了一个一阶自回归模型（AR(1)），并通过精确离散化映射 $\\hat{\\theta} = -\\Delta^{-1} \\ln(\\hat{\\varphi})$ 将估计的自回归系数 $\\hat{\\varphi}$ 转换为连续时间的均值回归率。假设样本量 $N$ 任意大，因此可以忽略估计的变异性，并且 $\\hat{\\varphi}$ 收敛于数据生成模型的伪真自回归系数。\n\n仅使用EM格式的基本定义、OU过程的精确离散时间转移以及光滑函数的渐近级数，推导在EM模拟数据上使用精确离散化映射所引起的渐近偏差 $B(\\Delta) = \\hat{\\theta} - \\theta$ 中关于 $\\Delta$ 的首项。请将您的最终结果表示为关于 $\\Delta$ 的首项（即 $B(\\Delta)$ 中 $\\Delta$ 的最小正次幂的系数）的单个闭式解析表达式，用 $\\theta$ 和 $\\Delta$ 表示。不包括单位，也不要四舍五入。", "solution": "该问题要求在估计奥恩斯坦-乌伦贝克（OU）过程的均值回归参数 $\\theta$ 时，当估计基于由欧拉-丸山（EM）格式生成的数据，但参数映射假设为精确离散化时，所产生的渐近偏差的首项。\n\nOU过程由以下随机微分方程（SDE）描述：\n$$dX_{t} = \\theta (\\mu - X_{t}) \\, dt + \\sigma \\, dW_{t}$$\n其中 $\\theta > 0$，$\\mu \\in \\mathbb{R}$，$\\sigma > 0$，$W_{t}$ 是一个标准维纳过程。\n\n问题陈述该过程是使用固定时间步长 $\\Delta > 0$ 的欧拉-丸山格式进行模拟的。其离散时间更新规则由下式给出：\n$$X_{(n+1)\\Delta} = X_{n\\Delta} + \\theta(\\mu - X_{n\\Delta}) \\Delta + \\sigma \\sqrt{\\Delta} \\,\\varepsilon_{n}$$\n其中 $\\varepsilon_{n}$ 是来自标准正态分布的独立随机变量，$\\varepsilon_{n} \\sim N(0, 1)$。\n\n该方程可以重排以凸显其作为一阶自回归模型（AR(1)）的结构：\n$$X_{(n+1)\\Delta} = \\theta\\mu\\Delta + (1 - \\theta\\Delta) X_{n\\Delta} + \\sigma \\sqrt{\\Delta} \\,\\varepsilon_{n}$$\n这是一个形式为 $Y_{n+1} = c + \\phi Y_n + e_{n+1}$ 的标准AR(1)过程，其中 $Y_n = X_{n\\Delta}$，常数项是 $c = \\theta\\mu\\Delta$，自回归系数是 $\\phi = 1 - \\theta\\Delta$，新息项是 $e_{n+1} = \\sigma \\sqrt{\\Delta} \\,\\varepsilon_{n}$。\n\n问题指明样本量 $N$ 任意大，这意味着可以忽略任何统计估计的变异性。一位分析师对模拟数据 $\\{X_{n\\Delta}\\}$ 拟合了一个AR(1)模型。在大样本极限下，估计的自回归系数（记为 $\\hat{\\varphi}$）将收敛到数据生成过程的真实自回归系数。在这种情况下，数据是由EM格式生成的，所以伪真参数是：\n$$\\hat{\\varphi} = 1 - \\theta\\Delta$$\n\n然而，该分析师使用源自OU过程*精确*离散化的映射，将这个估计的系数 $\\hat{\\varphi}$ 转换为连续时间参数的估计值 $\\hat{\\theta}$。OU SDE在时间间隔 $\\Delta$ 上的精确解给出了以下精确的AR(1)表示：\n$$X_{(n+1)\\Delta} = \\mu(1 - e^{-\\theta\\Delta}) + e^{-\\theta\\Delta} X_{n\\Delta} + \\text{噪声项}$$\n从这个精确形式中，连续时间参数 $\\theta$ 与精确离散时间自回归系数 $\\varphi_{\\text{exact}} = e^{-\\theta\\Delta}$ 之间的真实关系是 $\\theta = -\\frac{1}{\\Delta} \\ln(\\varphi_{\\text{exact}})$。\n\n分析师错误地将此映射应用于从EM模拟数据中获得的系数 $\\hat{\\varphi}$：\n$$\\hat{\\theta} = -\\frac{1}{\\Delta} \\ln(\\hat{\\varphi})$$\n代入 $\\hat{\\varphi}$ 的表达式：\n$$\\hat{\\theta} = -\\frac{1}{\\Delta} \\ln(1 - \\theta\\Delta)$$\n渐近偏差定义为 $B(\\Delta) = \\hat{\\theta} - \\theta$。因此，\n$$B(\\Delta) = -\\frac{1}{\\Delta} \\ln(1 - \\theta\\Delta) - \\theta$$\n为了找到小 $\\Delta$ 时偏差的首项，我们对对数项在 $\\Delta = 0$ 附近进行泰勒级数展开。$\\ln(1-x)$ 在 $x=0$ 附近的泰勒级数是：\n$$\\ln(1-x) = -x - \\frac{x^2}{2} - \\frac{x^3}{3} - \\dots = -\\sum_{k=1}^{\\infty} \\frac{x^k}{k}$$\n令 $x = \\theta\\Delta$，我们有：\n$$\\ln(1 - \\theta\\Delta) = -(\\theta\\Delta) - \\frac{(\\theta\\Delta)^2}{2} - \\frac{(\\theta\\Delta)^3}{3} - O(\\Delta^4)$$\n$$\\ln(1 - \\theta\\Delta) = -\\theta\\Delta - \\frac{\\theta^2\\Delta^2}{2} - O(\\Delta^3)$$\n现在我们将此展开式代回 $\\hat{\\theta}$ 的表达式中：\n$$\\hat{\\theta} = -\\frac{1}{\\Delta} \\left( -\\theta\\Delta - \\frac{\\theta^2\\Delta^2}{2} - O(\\Delta^3) \\right)$$\n$$\\hat{\\theta} = \\theta + \\frac{\\theta^2\\Delta}{2} + O(\\Delta^2)$$\n偏差 $B(\\Delta)$ 于是为：\n$$B(\\Delta) = \\hat{\\theta} - \\theta = \\left( \\theta + \\frac{\\theta^2\\Delta}{2} + O(\\Delta^2) \\right) - \\theta$$\n$$B(\\Delta) = \\frac{\\theta^2\\Delta}{2} + O(\\Delta^2)$$\n偏差 $B(\\Delta)$ 展开式中的首项是具有 $\\Delta$ 最小正次幂的项。此项为 $\\frac{\\theta^2\\Delta}{2}$。这代表了小时间步长 $\\Delta$ 时偏差的主要部分。", "answer": "$$\\boxed{\\frac{\\theta^2 \\Delta}{2}}$$", "id": "3344342"}, {"introduction": "本练习将理论付诸实践，解决一个在金融和物理学中常见的计算问题：估计路径极值的概率。你将亲手实现一个朴素的模拟器，并观察其因时间离散化而产生的系统性偏差。更重要的是，你将学习并实施一种基于布朗桥性质的高级修正技术 [@problem_id:3344309]，从而掌握处理离散时间观测与连续路径属性之间差异的关键技能。", "problem": "考虑由以下随机微分方程定义的 Ornstein–Uhlenbeck 过程：$$dX_t=-\\kappa\\left(X_t-\\mu\\right)\\,dt+\\sigma\\,dW_t,$$ 其中 $W_t$ 是标准 Wiener 过程，$\\kappa>0$ 是均值回归率，$\\mu\\in\\mathbb{R}$ 是长期均值，$\\sigma>0$ 是扩散系数。目标是使用蒙特卡洛模拟（Monte Carlo (MC)）估计概率 $$\\mathbb{P}\\!\\left(\\max_{0\\le s\\le T}X_s\\ge b\\right)$$，其中阈值 $b\\in\\mathbb{R}$ 为固定值。您需要讨论通过离散化路径检测越过障碍时，由时间离散化引起的系统性向下偏差，并实现一种修正方法，该方法通过在采样时间之间使用基于原则的穿越概率校正来减少此偏差。您必须从随机模拟的第一性原理出发，并为您选择的算法构建所有必要的推导。\n\n要求：\n\n1.  使用 Euler–Maruyama 方法，在均匀网格 $t_i = i \\Delta t$ ($i=0, \\dots, N$) 上模拟该过程。基于此离散路径，构建一个用于 $\\mathbb{P}(\\max_{0\\le s\\le T}X_s\\ge b)$ 的“粗糙”蒙特卡洛估计量，该估计量仅在离散时间点检查是否穿越障碍。\n2.  实现一个“修正”的蒙特卡洛估计量。对于在离散网格点上从未穿越障碍的模拟路径，该估计量还应考虑其在任意采样间隔 $[t_i, t_{i+1}]$ 内穿越障碍的概率。您需要推导这个基于布朗桥的区间穿越概率公式。\n3.  为进行比较，使用 OU 过程的精确转移律，在比上述粗糙网格精细得多的网格上计算一个高保真度的“参考”估计量。\n4.  编写一个 Python 3 函数 `solve()`，该函数实现这三种估计量，并在一系列预定义的测试用例上运行它们。对于每个测试用例，您的代码应计算并最终打印一个包含三个浮点数的列表：`[p_coarse, p_refined, p_fine]`。", "solution": "该问题要求估计一个 Ornstein-Uhlenbeck (OU) 过程 $X_t$ 在给定时间范围 $[0, T]$ 内超过某个障碍 $b$ 的概率。OU 过程由以下随机微分方程 (SDE) 描述：\n$$dX_t = -\\kappa(X_t - \\mu)dt + \\sigma dW_t, \\quad X_0 = x_0$$\n其中 $\\kappa > 0$ 是均值回归率，$\\mu$ 是长期均值，$\\sigma > 0$ 是波动率，而 $W_t$ 是一个标准 Wiener 过程。我们的任务是使用三种不同的蒙特卡洛 (MC) 方法来估计 $\\mathbb{P}(\\max_{0 \\le s \\le T} X_s \\ge b)$，以凸显并解决离散化偏差问题。时间区间 $[0, T]$ 被离散化为 $N$ 个步长为 $\\Delta t = T/N$ 的步骤，得到时间网格 $t_i = i \\Delta t$，其中 $i = 0, 1, \\dots, N$。\n\n这三种方法是：1) 基于 Euler-Maruyama 模拟的离散时间最大值的粗糙估计量，2) 对该估计量进行修正，以校正网格点之间错过的穿越事件的版本，以及 3) 在精细网格上使用 OU 过程的精确转移律计算的高保真度参考估计量。\n\n**方法 1：通过 Euler-Maruyama 方法的粗糙估计量**\n\nEuler-Maruyama 方法是随机微分方程数值积分的基本方案。将其应用于 OU 过程的 SDE，得到离散时间更新规则：\n$$X_{t_{i+1}} = X_{t_i} - \\kappa(X_{t_i} - \\mu)\\Delta t + \\sigma \\Delta W_i$$\n其中 $\\Delta W_i = W_{t_{i+1}} - W_{t_i}$ 是 Wiener 过程的增量。这些增量是独立同分布的正态随机变量，均值为 0，方差为 $\\Delta t$。我们可以写成 $\\Delta W_i = \\sqrt{\\Delta t} Z_i$，其中 $Z_i \\sim \\mathcal{N}(0, 1)$ 是独立的标准正态随机变量。\n\n模拟过程是生成大量路径，即 $N_{\\text{paths}}$ 条。对于每条路径，我们生成一系列状态 $X_0, X_{t_1}, \\dots, X_{t_N}$。穿越概率的最简单的 MC 估计量是基于仅在这些离散时间点上观察过程的值。我们为每条路径 $j$ 定义一个指示变量：\n$$I_j = \\mathbb{I}\\left(\\max_{0 \\le i \\le N} X_{t_i}^{(j)} \\ge b\\right)$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。粗糙估计量 $\\hat{p}_{\\text{coarse}}$ 是这些指示变量的样本均值：\n$$\\hat{p}_{\\text{coarse}} = \\frac{1}{N_{\\text{paths}}} \\sum_{j=1}^{N_{\\text{paths}}} I_j$$\n\n**离散化偏差分析**\n\n这个粗糙估计量是系统性有偏的。OU 过程的样本路径是连续的。一条路径有可能在两个网格点 $t_i$ 和 $t_{i+1}$ 之间穿过障碍 $b$，然后又回到障碍下方，使得 $X_{t_i} < b$ 且 $X_{t_{i+1}} < b$，但 $\\max_{s \\in [t_i, t_{i+1}]} X_s \\ge b$。在 $t_i$ 点的离散时间最大值检查将无法检测到这种穿越。\n\n形式上，离散时间最大值超过障碍的事件 $E_{\\text{discrete}} = \\{\\max_{0 \\le i \\le N} X_{t_i} \\ge b\\}$，是我们感兴趣的真实事件（即连续时间最大值超过障碍）$E_{\\text{continuous}} = \\{\\max_{0 \\le s \\le T} X_s \\ge b\\}$ 的一个子集。也就是说，$E_{\\text{discrete}} \\subseteq E_{\\text{continuous}}$。这意味着离散事件的概率小于或等于连续事件的概率：\n$$\\mathbb{P}(E_{\\text{discrete}}) \\le \\mathbb{P}(E_{\\text{continuous}})$$\n估计量 $\\hat{p}_{\\text{coarse}}$ 是 $\\mathbb{P}(E_{\\text{discrete}})$ 的一致估计量，而不是 $\\mathbb{P}(E_{\\text{continuous}})$ 的。因此，$\\hat{p}_{\\text{coarse}}$ 系统性地低估了真实的穿越概率，表现出一种向下的偏差，该偏差随着时间步长 $\\Delta t$ 趋近于 0 而减小。\n\n**方法 2：带区间校正的修正估计量**\n\n为了减轻这种偏差，我们可以通过考虑在区间 $[t_i, t_{i+1}]$ 内，给定观测到的端点 $X_{t_i} = u$ 和 $X_{t_{i+1}} = v$ 的条件下，发生穿越的概率来修正估计量。\n\n对于小的时间区间 $\\Delta t$，OU 过程的漂移和扩散系数可以近似为常数。具体来说，我们将 $s \\in [t_i, t_{i+1}]$ 上的过程 $X_s$ 近似为一个具有恒定波动率 $\\sigma$、从 $X_{t_i}=u$ 开始的布朗运动。漂移项 $-\\kappa(X_s-\\mu)$ 是 $dt$ 阶的，而扩散部分 $\\sigma dW_s$ 是 $\\sqrt{dt}$ 阶的。对于小的 $\\Delta t$，路径的局部行为由扩散项主导。这证明了将该过程局部近似为 $Y_s = u + \\sigma(W_s - W_{t_i})$ 是合理的。\n\n我们需要该过程穿越障碍 $b$ 的概率，条件是它从 $Y_{t_i} = u$ 开始，到 $Y_{t_{i+1}} = v$ 结束。这是一个关于布朗桥 (Brownian bridge) 的经典结果。我们来分析过程 $B_\\tau = W_{t_i+\\tau} - W_{t_i}$，其中 $\\tau \\in [0, \\Delta t]$。$B_\\tau$ 是一个从 $B_0=0$ 开始的标准 Wiener 过程。该过程为 $Y_{t_i+\\tau} = u + \\sigma B_\\tau$。端点条件 $Y_{t_{i+1}}=v$ 固定了 Wiener 增量：$B_{\\Delta t} = (v-u)/\\sigma$。穿越事件是 $\\max_{0 \\le \\tau \\le \\Delta t} Y_{t_i+\\tau} \\ge b$，这等价于 $\\max_{0 \\le \\tau \\le \\Delta t} B_\\tau \\ge (b-u)/\\sigma$。\n\n一个标准 Wiener 过程 $B_\\tau$ 在 $[0, T]$ 上的最大值超过一个水平 $a > 0$ 的概率，在 $B_T = x < a$ 的条件下，由以下公式给出：\n$$\\mathbb{P}(\\max_{0 \\le \\tau \\le T} B_\\tau \\ge a \\mid B_T = x) = \\exp\\left(-\\frac{2a(a-x)}{T}\\right)$$\n映射我们的变量，我们有 $T=\\Delta t$，$a = (b-u)/\\sigma$，$x=(v-u)/\\sigma$。我们需要考虑两个端点都低于障碍的情况，即 $u < b$ 且 $v < b$。在这种情况下，$a > 0$ 且 $a-x = (b-u)/\\sigma - (v-u)/\\sigma = (b-v)/\\sigma > 0$。因此，条件穿越概率为：\n$$p_i(u,v) = \\mathbb{P}(\\max_{s \\in [t_i, t_{i+1}]} X_s \\ge b \\mid X_{t_i}=u, X_{t_{i+1}}=v) = \\exp\\left(-\\frac{2(b-u)(b-v)}{\\sigma^2 \\Delta t}\\right)$$\n对于一条在所有离散点都保持在障碍下方的路径，其在任何一个区间内穿越的概率可以通过假设各区间内的穿越是独立的来近似。对于给定的路径，在区间 $i$ 发生穿越的概率是 $p_i(X_{t_i}, X_{t_{i+1}})$。那么，该路径在至少一个区间内发生穿越的概率是 $1 - \\prod_{i=0}^{N-1} (1-p_i')$, 其中 $p_i'$ 是计算出的穿越概率。\n\n修正估计量 $\\hat{p}_{\\text{refined}}$ 通过组合离散穿越和区间穿越来计算。对于每条路径，其总穿越概率 $P_j$ 是：\n$$\nP_j = \\begin{cases} 1 & \\text{if } \\max_{i} X_{t_i}^{(j)} \\ge b \\\\ 1 - \\prod_{i=0}^{N-1}(1 - p_i(X_{t_i}^{(j)}, X_{t_{i+1}}^{(j)})) & \\text{if } \\max_{i} X_{t_i}^{(j)} < b \\end{cases}\n$$\n修正后的估计量是这些单个路径概率的平均值：\n$$\\hat{p}_{\\text{refined}} = \\frac{1}{N_{\\text{paths}}} \\sum_{j=1}^{N_{\\text{paths}}} P_j$$\n\n**方法 3：高保真度参考估计量**\n\n为了获得一个“黄金标准”来评估上述两种方法，我们使用 OU 过程的精确转移律在非常精细的时间网格上进行模拟。精确的更新规则是：\n$$X_{t_{i+1}} = \\mu + (X_{t_i} - \\mu) e^{-\\kappa \\Delta t_{\\text{fine}}} + \\sqrt{\\frac{\\sigma^2}{2\\kappa}(1-e^{-2\\kappa\\Delta t_{\\text{fine}}})} Z_i$$\n我们使用一个比粗糙网格小得多的时间步长 $\\Delta t_{\\text{fine}}$。这显著减少了离散化偏差（无论是由于 Euler-Maruyama 格式引入的弱误差，还是由于离散观测引入的区间穿越问题）。参考估计量 $\\hat{p}_{\\text{fine}}$ 的计算方式与粗糙估计量相同，但使用的是精细网格上的路径：\n$$\\hat{p}_{\\text{fine}} = \\frac{1}{N_{\\text{paths}}} \\sum_{j=1}^{N_{\\text{paths}}} \\mathbb{I}\\left(\\max_{0 \\le i \\le N_{\\text{fine}}} X_{t_i}^{(j)} \\ge b\\right)$$\n通过将 $\\hat{p}_{\\text{coarse}}$ 和 $\\hat{p}_{\\text{refined}}$ 与 $\\hat{p}_{\\text{fine}}$ 进行比较，我们可以量化修正方法的有效性。我们预计 $\\hat{p}_{\\text{coarse}} < \\hat{p}_{\\text{refined}} \\approx \\hat{p}_{\\text{fine}}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Test case A (happy path)\n        {\n            \"params\": {\"kappa\": 1.5, \"mu\": 0.0, \"sigma\": 0.5, \"x0\": 0.0, \"T\": 1.0, \"b\": 1.0},\n            \"coarse_grid\": {\"dt\": 0.05, \"N_paths\": 100000, \"seed\": 42},\n            \"fine_grid\": {\"dt\": 0.005, \"N_paths\": 40000, \"seed\": 1042},\n        },\n        # Test case B (boundary condition)\n        {\n            \"params\": {\"kappa\": 1.0, \"mu\": 0.0, \"sigma\": 0.5, \"x0\": 0.3, \"T\": 1.0, \"b\": 0.3},\n            \"coarse_grid\": {\"dt\": 0.1, \"N_paths\": 100000, \"seed\": 43},\n            \"fine_grid\": {\"dt\": 0.01, \"N_paths\": 40000, \"seed\": 1043},\n        },\n        # Test case C (rare event with coarse sampling)\n        {\n            \"params\": {\"kappa\": 1.5, \"mu\": 0.0, \"sigma\": 0.5, \"x0\": 0.0, \"T\": 1.0, \"b\": 2.0},\n            \"coarse_grid\": {\"dt\": 0.1, \"N_paths\": 100000, \"seed\": 44},\n            \"fine_grid\": {\"dt\": 0.01, \"N_paths\": 40000, \"seed\": 1044},\n        },\n        # Test case D (short horizon with fast mean reversion)\n        {\n            \"params\": {\"kappa\": 4.0, \"mu\": 0.0, \"sigma\": 1.0, \"x0\": -1.0, \"T\": 0.5, \"b\": 0.0},\n            \"coarse_grid\": {\"dt\": 0.05, \"N_paths\": 100000, \"seed\": 45},\n            \"fine_grid\": {\"dt\": 0.005, \"N_paths\": 40000, \"seed\": 1045},\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        p = case[\"params\"]\n        cg = case[\"coarse_grid\"]\n        fg = case[\"fine_grid\"]\n\n        # --- Coarse grid simulations ---\n        rng_coarse = np.random.default_rng(cg[\"seed\"])\n        N_coarse = int(p[\"T\"] / cg[\"dt\"])\n\n        # Generate paths using Euler-Maruyama\n        paths_coarse = np.zeros((cg[\"N_paths\"], N_coarse + 1))\n        paths_coarse[:, 0] = p[\"x0\"]\n        \n        for i in range(N_coarse):\n            Z = rng_coarse.standard_normal(cg[\"N_paths\"])\n            drift = -p[\"kappa\"] * (paths_coarse[:, i] - p[\"mu\"]) * cg[\"dt\"]\n            diffusion = p[\"sigma\"] * np.sqrt(cg[\"dt\"]) * Z\n            paths_coarse[:, i+1] = paths_coarse[:, i] + drift + diffusion\n\n        # --- 1. Coarse Estimator ---\n        max_discrete = np.max(paths_coarse, axis=1)\n        p_coarse = np.mean(max_discrete >= p[\"b\"])\n        results.append(p_coarse)\n\n        # --- 2. Refined Estimator ---\n        # Paths that did not cross at discrete points\n        sub_barrier_paths_mask = max_discrete  p[\"b\"]\n        \n        path_probabilities = (max_discrete >= p[\"b\"]).astype(float)\n\n        # Calculate interval crossing probabilities for these paths\n        if np.any(sub_barrier_paths_mask):\n            sub_barrier_paths = paths_coarse[sub_barrier_paths_mask]\n            u = sub_barrier_paths[:, :-1]\n            v = sub_barrier_paths[:, 1:]\n            \n            # This is p_i(u,v) = exp(-2*(b-u)*(b-v) / (sigma^2 * dt))\n            # Handle potential overflow in exp by clipping exponent for stability\n            exponent = -2.0 * (p[\"b\"] - u) * (p[\"b\"] - v) / (p[\"sigma\"]**2 * cg[\"dt\"])\n            # The exponent is always non-positive since u,v  b\n            p_interval_cross = np.exp(np.maximum(exponent, -700)) # clip to avoid underflow being exactly 0\n            \n            # Probability of at least one crossing for paths that were below barrier at nodes\n            # P_path = 1 - product(1 - p_interval_cross)\n            # Use log-sum-exp trick for numerical stability\n            p_path_cross = 1.0 - np.exp(np.sum(np.log1p(-p_interval_cross), axis=1))\n\n            path_probabilities[sub_barrier_paths_mask] = p_path_cross\n            \n        p_refined = np.mean(path_probabilities)\n        results.append(p_refined)\n        \n        # --- 3. Fine Grid Reference Estimator ---\n        rng_fine = np.random.default_rng(fg[\"seed\"])\n        N_fine = int(p[\"T\"] / fg[\"dt\"])\n\n        # Generate paths using exact transition\n        paths_fine = np.zeros((fg[\"N_paths\"], N_fine + 1))\n        paths_fine[:, 0] = p[\"x0\"]\n        \n        exp_k_dt = np.exp(-p[\"kappa\"] * fg[\"dt\"])\n        # Variance term\n        if p[\"kappa\"] > 1e-9:\n            var = (p[\"sigma\"]**2 / (2 * p[\"kappa\"])) * (1 - np.exp(-2 * p[\"kappa\"] * fg[\"dt\"]))\n        else: # Taylor expansion for small kappa to avoid 0/0\n            var = p[\"sigma\"]**2 * fg[\"dt\"]\n\n        std_dev = np.sqrt(var)\n\n        for i in range(N_fine):\n            Z = rng_fine.standard_normal(fg[\"N_paths\"])\n            mean = p[\"mu\"] + (paths_fine[:, i] - p[\"mu\"]) * exp_k_dt\n            paths_fine[:, i+1] = mean + std_dev * Z\n\n        p_fine = np.mean(np.max(paths_fine, axis=1) >= p[\"b\"])\n        results.append(p_fine)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3344309"}]}