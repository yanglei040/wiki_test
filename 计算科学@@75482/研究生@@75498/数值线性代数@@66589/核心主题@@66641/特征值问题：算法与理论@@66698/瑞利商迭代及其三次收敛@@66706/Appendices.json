{"hands_on_practices": [{"introduction": "瑞利商迭代（RQI）最引人注目的特性之一是其局部三次方收敛速度。但这种惊人的收敛速度究竟从何而来？本练习将通过一个最简单的非平凡例子——一个 $2 \\times 2$ 的厄米矩阵（Hermitian matrix）——来揭示其内在机理。通过符号化的逐步推导，你将亲自得出误差角在每次迭代中的精确更新规律，从而直观地理解误差为何会呈三次方递减，为抽象的理论提供坚实的数学支撑。[@problem_id:3572053]", "problem": "考虑一个 $2 \\times 2$ 的厄米矩阵 (Hermitian matrix) $A$，它具有不同的特征值 $\\lambda_{1}$ 和 $\\lambda_{2}$，以及相关的标准正交特征向量 $v_{1}$ 和 $v_{2}$。设初始向量 $x_{0}$ 是一个在特征基下表示的通用单位向量，$x_{0} = \\cos(\\theta_{0})\\,v_{1} + \\sin(\\theta_{0})\\,v_{2}$，其中 $0  \\theta_{0}  \\pi/2$。定义瑞利商 (Rayleigh quotient) $\\mu(x) = x^{*} A x$。瑞利商迭代 (Rayleigh Quotient Iteration, RQI) 由以下序列给出\n$$\n\\mu_{k} = \\mu(x_{k}), \\quad y_{k} = (A - \\mu_{k} I)^{-1} x_{k}, \\quad x_{k+1} = \\frac{y_{k}}{\\|y_{k}\\|},\n$$\n其中 $I$ 是单位矩阵，$\\|\\cdot\\|$ 表示欧几里得范数。令 $\\theta_{k}$ 表示 $x_{k}$ 与目标特征向量 $v_{1}$ 之间的夹角，因此 $x_{k} = \\cos(\\theta_{k})\\,v_{1} + \\sin(\\theta_{k})\\,v_{2}$。\n\n从 $x_{0}$ 开始，符号化地执行两轮瑞利商迭代以获得 $x_{1}$ 和 $x_{2}$。仅使用厄米矩阵的基本性质、酉对角化以及瑞利商的定义，推导出每一步角度正切的精确更新公式，并验证角度向 $v_{1}$ 的三次收敛性。您的最终任务是以 $\\tan(\\theta_{0})$ 的函数形式，给出 $\\tan(\\theta_{2})$ 的闭式表达式。\n\n请提供 $\\tan(\\theta_{2})$ 的最终表达式。无需四舍五入。", "solution": "问题要求在对一个 $2 \\times 2$ 厄米矩阵 $A$ 执行两次瑞利商迭代 (RQI) 后，$\\tan(\\theta_2)$ 与 $\\tan(\\theta_0)$ 之间的关系。我们将推导一个关于 $\\tan(\\theta_k)$ 的 $\\tan(\\theta_{k+1})$ 的通用递推关系式，然后应用它两次。\n\n设厄米矩阵 $A$ 的标准正交特征向量为 $v_1$ 和 $v_2$，对应于不同的实数特征值 $\\lambda_1$ 和 $\\lambda_2$。因此，我们有 $A v_1 = \\lambda_1 v_1$, $A v_2 = \\lambda_2 v_2$，以及对于 $i,j \\in \\{1, 2\\}$ 有 $v_i^* v_j = \\delta_{ij}$。\n\n在第 $k$ 步的迭代状态由一个单位向量 $x_k$ 给出，它在特征基下表示为：\n$$x_k = \\cos(\\theta_k) v_1 + \\sin(\\theta_k) v_2$$\n其中 $\\theta_k$ 是 $x_k$ 与特征向量 $v_1$ 之间的夹角。沿 $v_2$ 的分量与沿 $v_1$ 的分量之比定义了这个角的正切值，即 $\\tan(\\theta_k) = \\frac{\\sin(\\theta_k)}{\\cos(\\theta_k)}$。初始条件是 $0  \\theta_0  \\pi/2$，这意味着 $\\tan(\\theta_0) > 0$。\n\nRQI 包含三个步骤：\n1.  计算瑞利商：$\\mu_k = \\mu(x_k) = x_k^* A x_k$。\n2.  求解下一个向量（未归一化）：$y_k = (A - \\mu_k I)^{-1} x_k$。\n3.  归一化得到下一个迭代向量：$x_{k+1} = \\frac{y_k}{\\|y_k\\|}$。\n\n让我们对一个通用的步骤 $k$ 符号化地执行这些步骤。\n\n**第1步：计算瑞利商 $\\mu_k$。**\n我们有 $A x_k = A(\\cos(\\theta_k) v_1 + \\sin(\\theta_k) v_2) = \\cos(\\theta_k) (A v_1) + \\sin(\\theta_k) (A v_2) = \\lambda_1 \\cos(\\theta_k) v_1 + \\lambda_2 \\sin(\\theta_k) v_2$。\n$x_k$ 的厄米共轭是 $x_k^* = \\cos(\\theta_k) v_1^* + \\sin(\\theta_k) v_2^*$。\n现在，我们计算 $\\mu_k$：\n$$\\mu_k = x_k^* A x_k = (\\cos(\\theta_k) v_1^* + \\sin(\\theta_k) v_2^*)(\\lambda_1 \\cos(\\theta_k) v_1 + \\lambda_2 \\sin(\\theta_k) v_2)$$\n利用特征向量的标准正交性（$v_1^* v_1 = 1$, $v_2^* v_2 = 1$, $v_1^* v_2 = 0$, $v_2^* v_1 = 0$），表达式简化为：\n$$\\mu_k = \\lambda_1 \\cos^2(\\theta_k) + \\lambda_2 \\sin^2(\\theta_k)$$\n\n**第2步：求解 $y_k$。**\n向量 $y_k$ 是通过将位移矩阵 $(A - \\mu_k I)$ 的逆矩阵作用于 $x_k$ 得到的。这个逆算子的作用在 $A$ 的特征基下最容易描述。对于任意向量 $w = c_1 v_1 + c_2 v_2$，我们有 $(A - \\mu_k I)^{-1} w = \\frac{c_1}{\\lambda_1 - \\mu_k} v_1 + \\frac{c_2}{\\lambda_2 - \\mu_k} v_2$。只要 $\\mu_k$ 不是一个特征值，这个定义就是明确的。如果 $\\mu_k = \\lambda_1$，则 $(\\lambda_1-\\lambda_2)\\sin^2(\\theta_k) = 0$。对于 $\\lambda_1 \\neq \\lambda_2$ 的情况，这意味着 $\\sin(\\theta_k)=0$，所以 $x_k$ 已经是特征向量 $v_1$。迭代将会停止。由于我们从 $\\theta_0 \\in (0, \\pi/2)$ 开始，对于任何有限的 $k$，$x_k$ 都不是特征向量。\n将此应用于 $x_k$：\n$$y_k = (A - \\mu_k I)^{-1} x_k = \\frac{\\cos(\\theta_k)}{\\lambda_1 - \\mu_k} v_1 + \\frac{\\sin(\\theta_k)}{\\lambda_2 - \\mu_k} v_2$$\n\n**第3步：确定 $\\tan(\\theta_{k+1})$。**\n下一个迭代向量 $x_{k+1}$ 与 $y_k$ 成比例。因此，角 $\\theta_{k+1}$ 的正切值由 $y_k$ 中 $v_2$ 和 $v_1$ 的系数之比给出：\n$$\\tan(\\theta_{k+1}) = \\frac{\\sin(\\theta_{k+1})}{\\cos(\\theta_{k+1})} = \\frac{\\text{coeff of } v_2 \\text{ in } y_k}{\\text{coeff of } v_1 \\text{ in } y_k} = \\frac{\\sin(\\theta_k)/(\\lambda_2 - \\mu_k)}{\\cos(\\theta_k)/(\\lambda_1 - \\mu_k)}$$\n$$\\tan(\\theta_{k+1}) = \\tan(\\theta_k) \\left( \\frac{\\lambda_1 - \\mu_k}{\\lambda_2 - \\mu_k} \\right)$$\n\n现在，我们将 $\\mu_k$ 的表达式代入分数中：\n分子是：\n$$\\lambda_1 - \\mu_k = \\lambda_1 - (\\lambda_1 \\cos^2(\\theta_k) + \\lambda_2 \\sin^2(\\theta_k)) = \\lambda_1 (1 - \\cos^2(\\theta_k)) - \\lambda_2 \\sin^2(\\theta_k) = \\lambda_1 \\sin^2(\\theta_k) - \\lambda_2 \\sin^2(\\theta_k) = (\\lambda_1 - \\lambda_2)\\sin^2(\\theta_k)$$\n分母是：\n$$\\lambda_2 - \\mu_k = \\lambda_2 - (\\lambda_1 \\cos^2(\\theta_k) + \\lambda_2 \\sin^2(\\theta_k)) = \\lambda_2 (1 - \\sin^2(\\theta_k)) - \\lambda_1 \\cos^2(\\theta_k) = \\lambda_2 \\cos^2(\\theta_k) - \\lambda_1 \\cos^2(\\theta_k) = (\\lambda_2 - \\lambda_1)\\cos^2(\\theta_k)$$\n这两个表达式的比值是：\n$$\\frac{\\lambda_1 - \\mu_k}{\\lambda_2 - \\mu_k} = \\frac{(\\lambda_1 - \\lambda_2)\\sin^2(\\theta_k)}{(\\lambda_2 - \\lambda_1)\\cos^2(\\theta_k)} = \\frac{(\\lambda_1 - \\lambda_2)\\sin^2(\\theta_k)}{-(\\lambda_1 - \\lambda_2)\\cos^2(\\theta_k)} = -\\frac{\\sin^2(\\theta_k)}{\\cos^2(\\theta_k)} = -\\tan^2(\\theta_k)$$\n\n将此结果代回 $\\tan(\\theta_{k+1})$ 的方程，得到递推关系：\n$$\\tan(\\theta_{k+1}) = \\tan(\\theta_k) (-\\tan^2(\\theta_k)) = -\\tan^3(\\theta_k)$$\n这个针对 $2 \\times 2$ 情况的精确关系式证明了 RQI 的三次收敛性。角度正切的绝对值代表了特征向量近似的误差，它在每次迭代中都会被三次方：$|\\tan(\\theta_{k+1})|=|\\tan(\\theta_k)|^3$。\n\n现在我们从 $x_0$ 开始，应用这个关系式进行两次迭代。\n\n**第一次迭代 ($k=0$):**\n使用 $k=0$ 的递推关系，我们得到 $\\tan(\\theta_1)$：\n$$\\tan(\\theta_1) = -\\tan^3(\\theta_0)$$\n\n**第二次迭代 ($k=1$):**\n现在我们应用 $k=1$ 的递推关系来求 $\\tan(\\theta_2)$：\n$$\\tan(\\theta_2) = -\\tan^3(\\theta_1)$$\n将 $\\tan(\\theta_1)$ 的表达式代入此方程：\n$$\\tan(\\theta_2) = -(\\tan(\\theta_1))^3 = -\\left( -\\tan^3(\\theta_0) \\right)^3$$\n$$\\tan(\\theta_2) = - \\left( (-1)^3 (\\tan^3(\\theta_0))^3 \\right) = - \\left( -1 \\cdot \\tan^{(3 \\times 3)}(\\theta_0) \\right) = - \\left( -\\tan^9(\\theta_0) \\right)$$\n$$\\tan(\\theta_2) = \\tan^9(\\theta_0)$$\n\n这就是 $\\tan(\\theta_2)$ 作为 $\\tan(\\theta_0)$ 函数的最终表达式。\n该计算证实了瑞利商迭代极快的三次收敛性。误差项 $\\tan(\\theta_k)$ 在 $k$ 步之后（符号除外）被提升到 $3^k$ 次幂。两步之后，指数为 $3^2=9$。", "answer": "$$\\boxed{\\tan^{9}(\\theta_{0})}$$", "id": "3572053"}, {"introduction": "理论的理解需要通过实践来巩固。在许多科学与工程领域，特征值问题通常以广义形式 $A \\boldsymbol{x} = \\lambda B \\boldsymbol{x}$ 出现。本练习要求你将瑞利商迭代算法应用于这类更普遍的对称广义特征值问题。你需要从第一性原理出发，使用广义瑞利商和相应的 $B$-范数来驱动迭代，并编写一个完整的程序来求解。这个实践将帮助你把理论知识转化为解决实际问题的代码，并加深对算法在不同范数空间下如何运作的理解。[@problem_id:3265587]", "problem": "实现一个完整、可运行的程序，使用从第一性原理推导出的瑞利商迭代法，为由 $A \\boldsymbol{x} = \\lambda B \\boldsymbol{x}$ 定义的对称广义特征值问题计算近似广义特征值。矩阵对 $(A,B)$ 必须是对称的，其中 $B$ 是对称正定 (SPD) 矩阵。使用广义瑞利商 $R(\\boldsymbol{x}) = \\dfrac{\\boldsymbol{x}^{\\mathsf{T}} A \\boldsymbol{x}}{\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x}}$ 作为驱动迭代的标量。该算法必须从 $R(\\boldsymbol{x})$ 在 $B$-单位球面上的平稳性条件推导得出，而不是源自任何预先提供的快捷公式。\n\n必须使用的基本依据：\n- 对于对称矩阵 $A$ 和对称正定矩阵 $B$，广义特征值问题 $A \\boldsymbol{x} = \\lambda B \\boldsymbol{x}$ 具有实数特征值和一组 $B$-正交归一的特征向量基。\n- 当约束在 $B$-单位球面 $\\{\\boldsymbol{x} \\in \\mathbb{R}^{n} : \\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x} = 1\\}$ 上时，广义瑞利商 $R(\\boldsymbol{x}) = \\dfrac{\\boldsymbol{x}^{\\mathsf{T}} A \\boldsymbol{x}}{\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x}}$ 在广义特征向量处是平稳的。\n- 将牛顿法 (Newton’s method) 应用于该约束流形上的一阶最优性条件，可以为简单特征对产生局部三次收敛的迭代。\n\n您的程序必须：\n- 仅基于上述基本定义和事实实现瑞利商迭代法。\n- 在 $B$-范数下对迭代向量进行归一化，其中 $\\lVert \\boldsymbol{x} \\rVert_{B} = \\sqrt{\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x}}$。\n- 当 2-范数残差 $\\lVert A \\boldsymbol{x} - \\mu B \\boldsymbol{x} \\rVert_{2}$ 低于容差 $\\tau = 10^{-12}$ 或达到最大迭代次数 50 次时终止，以先发生者为准。此处 $\\mu$ 表示当前的广义瑞利商。\n\n测试套件：\n为以下四个测试用例提供结果。在每个用例中，都明确给出了矩阵 $A$、$B$ 和初始向量 $\\boldsymbol{x}_{0}$。所有矩阵都是对称的，且 $B$ 是对称正定的。\n\n- 情况 1 (标量边界情况)：\n  - $A = \\begin{bmatrix} 7 \\end{bmatrix}$， $B = \\begin{bmatrix} 2 \\end{bmatrix}$， $\\boldsymbol{x}_{0} = \\begin{bmatrix} 1 \\end{bmatrix}$。\n\n- 情况 2 (对角广义矩阵对)：\n  - $A = \\mathrm{diag}(2,3,5)$， $B = \\mathrm{diag}(1,4,2)$， $\\boldsymbol{x}_{0} = \\begin{bmatrix} 0.05 \\\\ 0.998 \\\\ 0.05 \\end{bmatrix}$。\n\n- 情况 3 (标准特征值问题作为 $B = I$ 的特例)：\n  - $A = \\begin{bmatrix} 4  1  0 \\\\ 1  3  1 \\\\ 0  1  2 \\end{bmatrix}$， $B = I_{3}$， $\\boldsymbol{x}_{0} = \\begin{bmatrix} 1 \\\\ 0.2 \\\\ -0.1 \\end{bmatrix}$。\n\n- 情况 4 (完全广义的对称非对角矩阵对)：\n  - $A = \\begin{bmatrix} 5  2  0 \\\\ 2  4  1 \\\\ 0  1  3 \\end{bmatrix}$， $B = \\begin{bmatrix} 3  1  0 \\\\ 1  2  0.5 \\\\ 0  0.5  1.5 \\end{bmatrix}$， $\\boldsymbol{x}_{0} = \\begin{bmatrix} 0.3 \\\\ -0.4 \\\\ 0.85 \\end{bmatrix}$。\n\n计算和输出要求：\n- 对于每个用例，从提供的 $\\boldsymbol{x}_{0}$ 开始运行瑞利商迭代，使用容差 $\\tau = 10^{-12}$ 和最大 50 次迭代。\n- 对于每个用例，报告通过广义瑞利商从最后一次迭代计算出的最终近似广义特征值 $\\widehat{\\lambda}$。\n- 将报告的每个 $\\widehat{\\lambda}$ 表示为四舍五入到 12 位小数的浮点数。\n- 您的程序应生成单行输出，其中包含按情况 1 到 4 的顺序排列、用方括号括起来的逗号分隔列表形式的结果；例如，打印的字符串必须具有 $[\\widehat{\\lambda}_{1},\\widehat{\\lambda}_{2},\\widehat{\\lambda}_{3},\\widehat{\\lambda}_{4}]$ 的形式。\n\n不允许外部输入。所有量纲均为无量纲；不包含任何物理单位。不使用角度。不使用百分比。最终输出唯一接受的数据类型是按规定打印的浮点数。", "solution": "该问题要求为对称广义特征值问题 $A \\boldsymbol{x} = \\lambda B \\boldsymbol{x}$ 实现瑞利商迭代法，其中 $A$ 是对称矩阵，$B$ 是对称正定 (SPD) 矩阵。该实现必须从涉及广义瑞利商在 $B$-单位球面上平稳性的第一性原理推导得出。\n\n### 1. 问题验证\n问题陈述已经过验证，被认为是合理、适定且客观的。\n*   **给定条件**：问题提供了所有必要信息：广义特征值问题的形式、矩阵 $A$ 和 $B$ 的性质、广义瑞利商 $R(\\boldsymbol{x})$ 的定义、算法推导的基本原理、具体的算法要求（归一化、终止标准），以及一套完整的 E-suite 测试用例，其中包含明确的矩阵、初始向量和输出格式规则。\n*   **科学依据**：该问题植根于数值线性代数的基本概念。广义对称特征值问题、瑞利商迭代法和牛顿法 (Newton's method) 都是标准且易于理解的主题。$B$ 是对称正定的条件保证了特征值为实数，并存在一组 $B$-正交归一的特征向量基，从而确保了问题的良态性。\n*   **适定性**：该问题是适定的。对于简单特征值，瑞利商迭代法表现出局部三次收敛性，因此给定一个合适的初始猜测，它有望快速收敛到一个唯一的特征对。终止条件是明确的。所提供的测试数据在数值上是有效的；特别是，所有指定的矩阵 $B$ 都被确认为对称正定矩阵。\n*   **结论**：该问题是有效的，可以按陈述求解。\n\n### 2. 广义瑞利商迭代法的推导\n\n问题的核心是找到一个标量 $\\lambda$ 和一个非零向量 $\\boldsymbol{x}$，满足 $A \\boldsymbol{x} = \\lambda B \\boldsymbol{x}$。这可以被表述为一个约束优化问题。广义瑞利商定义为：\n$$ R(\\boldsymbol{x}) = \\frac{\\boldsymbol{x}^{\\mathsf{T}} A \\boldsymbol{x}}{\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x}} $$\n广义特征向量是 $R(\\boldsymbol{x})$ 的平稳点。我们可以通过寻找分子 $\\boldsymbol{x}^{\\mathsf{T}} A \\boldsymbol{x}$ 的平稳点来找到它们，其约束条件是分母为常数，例如 $\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x} = 1$。这个约束定义了“$B$-单位球面”。\n\n我们使用拉格朗日乘数法 (method of Lagrange multipliers)。对于这个约束优化问题，拉格朗日函数 $\\mathcal{L}$ 是：\n$$ \\mathcal{L}(\\boldsymbol{x}, \\lambda) = \\boldsymbol{x}^{\\mathsf{T}} A \\boldsymbol{x} - \\lambda (\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x} - 1) $$\n要使点 $\\boldsymbol{x}$ 成为一个平稳点，拉格朗日函数关于 $\\boldsymbol{x}$ 的梯度必须为零向量：\n$$ \\nabla_{\\boldsymbol{x}} \\mathcal{L}(\\boldsymbol{x}, \\lambda) = \\mathbf{0} $$\n鉴于 $A$ 和 $B$ 是对称的，梯度为 $\\nabla_{\\boldsymbol{x}} (\\boldsymbol{x}^{\\mathsf{T}} A \\boldsymbol{x}) = 2A\\boldsymbol{x}$ 和 $\\nabla_{\\boldsymbol{x}} (\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x}) = 2B\\boldsymbol{x}$。因此，平稳性条件是：\n$$ 2A\\boldsymbol{x} - \\lambda(2B\\boldsymbol{x}) = \\mathbf{0} \\implies A\\boldsymbol{x} = \\lambda B\\boldsymbol{x} $$\n这正是广义特征值问题。拉格朗日乘数 $\\lambda$ 就是广义特征值。通过左乘 $\\boldsymbol{x}^{\\mathsf{T}}$，我们看到在特征向量 $\\boldsymbol{x}$ 处，有 $\\boldsymbol{x}^{\\mathsf{T}}A\\boldsymbol{x} = \\lambda \\boldsymbol{x}^{\\mathsf{T}}B\\boldsymbol{x}$，这证实了 $\\lambda = R(\\boldsymbol{x})$。\n\n瑞利商迭代算法可以通过应用牛顿法来求解由平稳性和约束条件定义的非线性方程组的根来推导：\n$$ F(\\boldsymbol{x}, \\lambda) = \\begin{bmatrix} A\\boldsymbol{x} - \\lambda B\\boldsymbol{x} \\\\ \\frac{1}{2}(\\boldsymbol{x}^{\\mathsf{T}} B \\boldsymbol{x} - 1) \\end{bmatrix} = \\begin{bmatrix} \\mathbf{0} \\\\ 0 \\end{bmatrix} $$\n虽然可以将牛顿法直接应用于这个 $(n+1) \\times (n+1)$ 系统并进行简化，但这会得到与更直观的“位移-反演”观点所产生的相同迭代方案。该观点结合了两个思想：\n1.  瑞利商 $\\mu_k = R(\\boldsymbol{x}_k)$ 为与特征向量近似值 $\\boldsymbol{x}_k$ 对应的特征值提供了一个高度准确的估计。\n2.  带位移 $\\mu_k$ 的反迭代法会快速收敛到其特征值最接近 $\\mu_k$ 的特征向量。\n\n对于广义问题 $A\\boldsymbol{x} = \\lambda B\\boldsymbol{x}$，适当的“位移-反演”算子是 $(A - \\mu B)^{-1}B$。将此算子应用于当前的向量近似值 $\\boldsymbol{x}_k$ 可以得到下一个近似值的方向。\n\n这导出了以下算法。\n\n### 3. 算法步骤\n\n设 $\\boldsymbol{x}_k$ 为第 $k$ 次迭代时的近似特征向量。\n1.  **初始化**：从一个给定的向量 $\\boldsymbol{x}_0$ 开始。根据 $B$-范数对其进行归一化：$\\boldsymbol{x}_0 \\leftarrow \\boldsymbol{x}_0 / \\sqrt{\\boldsymbol{x}_0^{\\mathsf{T}} B \\boldsymbol{x}_0}$。\n2.  **迭代**：对于 $k = 0, 1, 2, \\dots$ 直到达到最大迭代次数：\n    a. **计算特征值估计**：计算广义瑞利商。由于 $\\boldsymbol{x}_k$ 是 $B$-归一化的，$\\boldsymbol{x}_k^{\\mathsf{T}} B \\boldsymbol{x}_k=1$，因此商可以简化为：\n       $$ \\mu_k = \\boldsymbol{x}_k^{\\mathsf{T}} A \\boldsymbol{x}_k $$\n    b. **检查收敛性**：计算残差 $\\boldsymbol{r}_k = A\\boldsymbol{x}_k - \\mu_k B\\boldsymbol{x}_k$。如果其欧几里得范数 $\\lVert\\boldsymbol{r}_k\\rVert_2$ 低于指定的容差 $\\tau$，则迭代收敛。最终的近似特征对为 $(\\mu_k, \\boldsymbol{x}_k)$。\n    c. **求解下一个向量**：通过求解位移后的线性系统来找到下一个（未归一化的）向量 $\\boldsymbol{z}_{k+1}$：\n       $$ (A - \\mu_k B) \\boldsymbol{z}_{k+1} = B \\boldsymbol{x}_k $$\n       当 $\\mu_k$ 接近一个特征值时，矩阵 $A - \\mu_k B$ 变得近乎奇异，这是该方法快速（三次）收敛的根源。\n    d. **归一化**：计算新向量的 $B$-范数 $\\lVert \\boldsymbol{z}_{k+1} \\rVert_B = \\sqrt{\\boldsymbol{z}_{k+1}^{\\mathsf{T}} B \\boldsymbol{z}_{k+1}}$，并将其归一化以获得下一次迭代的向量：\n       $$ \\boldsymbol{x}_{k+1} = \\frac{\\boldsymbol{z}_{k+1}}{\\lVert \\boldsymbol{z}_{k+1} \\rVert_B} $$\n3.  **终止**：如果循环因达到最大迭代次数而结束，则返回最后计算的 $(\\mu_k, \\boldsymbol{x}_k)$ 作为最终近似值。\n\n下面的代码实现了此算法，以解决给定的测试用例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generalized_rayleigh_quotient_iteration(A, B, x0, tol=1e-12, max_iter=50):\n    \"\"\"\n    Computes an eigenpair of the generalized eigenvalue problem Ax = lambda*Bx.\n\n    Args:\n        A (np.ndarray): A symmetric matrix.\n        B (np.ndarray): A symmetric positive definite matrix.\n        x0 (np.ndarray): The initial guess for the eigenvector.\n        tol (float): The tolerance for the residual norm for convergence.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        float: The approximate eigenvalue.\n    \"\"\"\n    x = x0.copy().astype(np.float64)\n\n    # Initial B-normalization of the vector x0\n    try:\n        x_T_B_x = (x.T @ B @ x)[0, 0]\n        norm_B = np.sqrt(x_T_B_x)\n        if norm_B == 0:\n            raise ValueError(\"Initial vector x0 has zero B-norm.\")\n        x = x / norm_B\n    except IndexError: # Handles 1x1 case where result is scalar\n        x_T_B_x = x.T @ B @ x\n        norm_B = np.sqrt(x_T_B_x)\n        if norm_B == 0:\n            raise ValueError(\"Initial vector x0 has zero B-norm.\")\n        x = x / norm_B\n\n\n    mu = 0.0\n    for _ in range(max_iter):\n        # Calculate the generalized Rayleigh quotient.\n        # Since x is B-normalized, x.T @ B @ x is 1.\n        mu_val = (x.T @ A @ x)\n        mu = mu_val[0, 0] if isinstance(mu_val, np.ndarray) and mu_val.ndim > 0 else mu_val\n\n        # Compute the residual vector and check for convergence\n        residual = A @ x - mu * (B @ x)\n        residual_norm = np.linalg.norm(residual)\n\n        if residual_norm  tol:\n            return mu\n\n        # Solve the shifted linear system: (A - mu*B)z = Bx\n        shift_matrix = A - mu * B\n        rhs = B @ x\n        \n        try:\n            # Use np.linalg.solve for numerical stability\n            z = np.linalg.solve(shift_matrix, rhs)\n        except np.linalg.LinAlgError:\n            # If the matrix is singular, mu is an excellent approximation of\n            # an eigenvalue. We can consider this as converged.\n            return mu\n        \n        # Normalize the new vector z in the B-norm\n        try:\n            z_T_B_z = (z.T @ B @ z)[0, 0]\n            norm_B_z = np.sqrt(z_T_B_z)\n        except IndexError: # Handles 1x1 case\n            z_T_B_z = z.T @ B @ z\n            norm_B_z = np.sqrt(z_T_B_z)\n\n        if norm_B_z == 0:\n            # This is unlikely with a non-singular B, but as a safeguard:\n            # it might indicate convergence to a trivial solution,\n            # so we stop and return the current best estimate.\n            return mu\n            \n        x = z / norm_B_z\n\n    # If max_iter is reached, compute the final Rayleigh quotient and return\n    mu_val = (x.T @ A @ x)\n    mu = mu_val[0, 0] if isinstance(mu_val, np.ndarray) and mu_val.ndim > 0 else mu_val\n    return mu\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the generalized Rayleigh quotient iteration.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.array([[7.0]]),\n            \"B\": np.array([[2.0]]),\n            \"x0\": np.array([1.0]),\n        },\n        {\n            \"A\": np.diag([2.0, 3.0, 5.0]),\n            \"B\": np.diag([1.0, 4.0, 2.0]),\n            \"x0\": np.array([0.05, 0.998, 0.05]),\n        },\n        {\n            \"A\": np.array([[4.0, 1.0, 0.0], [1.0, 3.0, 1.0], [0.0, 1.0, 2.0]]),\n            \"B\": np.identity(3),\n            \"x0\": np.array([1.0, 0.2, -0.1]),\n        },\n        {\n            \"A\": np.array([[5.0, 2.0, 0.0], [2.0, 4.0, 1.0], [0.0, 1.0, 3.0]]),\n            \"B\": np.array([[3.0, 1.0, 0.0], [1.0, 2.0, 0.5], [0.0, 0.5, 1.5]]),\n            \"x0\": np.array([0.3, -0.4, 0.85]),\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        B = case[\"B\"]\n        x0 = case[\"x0\"]\n        \n        # Ensure x0 is a column vector for consistent matrix operations\n        x0_col = x0.reshape(-1, 1) if x0.ndim == 1 else x0\n        \n        lambda_approx = generalized_rayleigh_quotient_iteration(A, B, x0_col)\n        \n        # Format the result to 12 decimal places as a string\n        results.append(f\"{lambda_approx:.12f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3265587"}, {"introduction": "我们已经知道瑞利商迭代具有局部三次方收敛性，但一个关键的实际问题是：“局部”究竟是多大的范围？能够实现这种快速收敛的初始猜测向量集合，即所谓的“吸引盆”（basin of attraction），其大小和形状受矩阵谱分布等因素的显著影响。本高级练习将引导你从算法的使用者转变为算法的分析者。你将设计一个数值实验，通过系统地改变初始向量来经验性地描绘三次方收敛的吸引盆，并探究特征值间距等因素如何影响其范围。这个实践旨在培养你的计算思维和数值分析能力，学会如何通过实验来验证理论、探索算法的行为边界。[@problem_id:3572063]", "problem": "考虑一个具有单特征值和标准正交特征基的实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$。瑞利商迭代（RQI）是一种应用于单位球面 $S^{n-1}$ 上瑞利商的 Newton 型方法，在适当条件下，它表现出对某个特征对的局部三阶收敛性。设 $v$ 是 $A$ 的一个真实单位特征向量，初始迭代向量构造于由 $v$ 和一个正交方向 $w$ 张成的大圆上，形式为 $x_0(\\theta_0) = \\cos(\\theta_0) v + \\sin(\\theta_0) w$，其中 $\\theta_0 \\in [0, \\pi/2]$，单位为弧度。定义第 $k$ 次迭代的角度误差为 $e_k = \\arccos(|x_k^\\top v|)$（单位为弧度），其中 $x_k$ 是 $S^{n-1}$ 上的归一化迭代向量。局部收敛阶 $p$ 可以通过经验模型 $e_{k+1} \\approx C e_k^p$ 从三个连续误差中估计得出，方法是消去未知常数 $C$ 以形成\n$$\np_k \\approx \\frac{\\log(e_{k+1}) - \\log(e_k)}{\\log(e_k) - \\log(e_{k-1})}\n$$\n当 $e_{k-1}, e_k, e_{k+1} > 0$ 时。如果迭代收敛到 $v$，并且存在至少两个连续的索引 $k$，使得 $p_k \\in [3 - \\delta, 3 + \\delta]$ 且 $e_{k-1}, e_k, e_{k+1}  \\varepsilon$（其中 $\\delta > 0$ 和 $\\varepsilon > 0$ 是预设的容差），则称初始角 $\\theta_0$ 位于目标特征向量 $v$ 的三阶收敛区域内。本实验将观察到的三阶收敛区域与 $S^{n-1}$ 上的 Newton 盆结构联系起来。\n\n实现一个程序，该程序：\n- 确定性地构造以下测试矩阵并选择目标特征向量 $v$：\n  1. 测试用例 1（维度 $n=3$）：设 $M^{(1)} \\in \\mathbb{R}^{3 \\times 3}$ 定义为 $M^{(1)}_{ij} = \\sin(i + 2j) + 0.1 \\cos(3i - j)$，其中索引 $i,j \\in \\{1,2,3\\}$。通过对 $M^{(1)}$ 进行 $QR$ 分解，计算一个标准正交矩阵 $Q^{(1)}$。定义 $A^{(1)} = Q^{(1)} \\operatorname{diag}(1,3,10) \\left(Q^{(1)}\\right)^\\top$，并选择对应于特征值 $3$ 的 $Q^{(1)}$ 列（即第二列）作为目标特征向量 $v^{(1)}$。选择一个与 $v^{(1)}$ 正交的单位向量作为 $w^{(1)}$，具体为 $Q^{(1)}$ 中按循环顺序的下一列，即第三列。\n  2. 测试用例 2（维度 $n=3$）：重用 $Q^{(1)}$ 来定义 $A^{(2)} = Q^{(1)} \\operatorname{diag}(1, 1.001, 2) \\left(Q^{(1)}\\right)^\\top$，并选择对应于特征值 $1.001$ 的 $Q^{(1)}$ 列（即第二列）作为 $v^{(2)}$。选择 $Q^{(1)}$ 的第三列作为 $w^{(2)}$。\n  3. 测试用例 3（维度 $n=5$）：设 $M^{(3)} \\in \\mathbb{R}^{5 \\times 5}$ 定义为 $M^{(3)}_{ij} = \\sin(0.3 i + 0.7 j) + 0.05 \\cos(i - 2 j)$，其中索引 $i,j \\in \\{1,2,3,4,5\\}$。通过对 $M^{(3)}$ 进行 $QR$ 分解，计算一个标准正交矩阵 $Q^{(3)}$。定义 $A^{(3)} = Q^{(3)} \\operatorname{diag}(0.5, 1.4, 2.0, 4.5, 9.0) \\left(Q^{(3)}\\right)^\\top$，并选择对应于特征值 $2.0$ 的 $Q^{(3)}$ 列（即第三列）作为目标特征向量 $v^{(3)}$。选择 $Q^{(3)}$ 的第四列作为 $w^{(3)}$。\n\n- 对每个测试用例，在区间 $[0, \\pi/2]$（单位为弧度）上以 61 个等距点采样，形成一个初始角度 $\\theta_0$ 的网格，在 $S^{n-1}$ 上构造 $x_0(\\theta_0)$，并运行瑞利商迭代，其定义如下：\n  1. 按给定方式初始化 $x_0$。对于 $k = 0,1,2,\\dots$，直到达到最大迭代次数，计算瑞利商 $\\mu_k = \\frac{x_k^\\top A x_k}{x_k^\\top x_k}$。\n  2. 求解方程 $(A - \\mu_k I) y_k = x_k$ 以得到 $y_k$（使用一个稳定的线性求解器），并设置 $x_{k+1} = \\frac{y_k}{\\|y_k\\|_2}$。\n  3. 记录角度误差 $e_k = \\arccos(|x_k^\\top v|)$（单位为弧度）。\n  4. 当序列在角度上收敛（例如 $e_k  10^{-14}$）或达到 50 次迭代的最大次数时停止。\n\n- 对每个 $\\theta_0$，使用记录的误差 $\\{e_k\\}$ 估计定义的局部阶 $\\{p_k\\}$，如果迭代收敛于 $v$ 且满足上述准则（容差为 $\\delta = 0.3$ 和 $\\varepsilon = 10^{-6}$），则宣布 $\\theta_0$ 位于 $v$ 的三阶收敛区域内。如果 $e_0  \\varepsilon$，则将 $\\theta_0$ 视为平凡三阶收敛。\n\n- 对每个测试用例，计算网格中满足三阶收敛准则的角度的比例（以小数表示）。角度以弧度为单位。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个比例值都四舍五入到三位小数，并按上述测试用例的顺序排列。例如：\"[0.850,0.300,0.000]\"。", "solution": "瑞利商迭代（RQI）是通过将 Newton 方法应用于单位球面 $S^{n-1}$ 上瑞利商的平稳条件推导出来的。对于一个具有单特征值 $\\lambda_1, \\dots, \\lambda_n$ 和标准正交特征基 $Q = [v_1 \\, v_2 \\, \\dots \\, v_n]$ 的实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，瑞利商 $R(x) = \\frac{x^\\top A x}{x^\\top x}$ 在特征向量处取得极值，其值等于相应的特征值。将 Newton 方法应用于 $S^{n-1}$ 上 $R(x)$ 的约束优化，会得到一种迭代方法，该方法在每一步中求解一个移位的线性系统，其移位量等于当前的瑞利商。实际算法如下：\n1. 将 $x_k$ 归一化，使其位于 $S^{n-1}$ 上。\n2. 计算瑞利商 $\\mu_k = \\frac{x_k^\\top A x_k}{x_k^\\top x_k}$。\n3. 求解 $(A - \\mu_k I) y_k = x_k$ 并设置 $x_{k+1} = \\frac{y_k}{\\|y_k\\|_2}$。\n\n对于具有单特征值的实对称矩阵，一个众所周知且可以被严格证明的结论是：如果 $x_k$ 足够接近一个特征向量 $v$，那么迭代将以局部三阶收敛到 $v$ 和相应的特征值。收敛是局部的，并且关键取决于初始向量 $x_0$ 是否位于流形 $S^{n-1}$ 上目标特征对的 Newton 吸引盆内。\n\n为了描绘初始角度如何影响进入三阶收敛区域，我们在由 $v$ 和一个正交单位向量 $w$ 张成的平面内，沿着穿过目标特征向量 $v$ 的 $S^{n-1}$ 上的测地线来参数化初始向量 $x_0(\\theta_0)$。具体来说，我们设置 $x_0(\\theta_0) = \\cos(\\theta_0) v + \\sin(\\theta_0) w$，它描绘了一条从 $\\theta_0 = 0$ 处的 $v$ 到 $\\theta_0 = \\frac{\\pi}{2}$ 处正交方向的大圆弧。\n\n我们通过角度误差 $e_k = \\arccos(|x_k^\\top v|)$ 来量化与目标特征向量 $v$ 的接近程度，并确保 $e_k \\in [0, \\pi/2]$。在局部三阶收敛的情况下，当误差足够小时，误差模型 $e_{k+1} \\approx C e_k^p$（其中 $p \\approx 3$ 且某个常数 $C  0$）成立。使用三个连续误差消去未知常数 $C$ 可得到局部收敛阶的估计量：\n$$\np_k \\approx \\frac{\\log(e_{k+1}) - \\log(e_k)}{\\log(e_k) - \\log(e_{k-1})},\n$$\n在 $e_{k-1}, e_k, e_{k+1} > 0$ 且足够小以至于对数计算在数值上稳定时有效。该估计量是数值分析中用于经验性地确定局部阶的标准方法，无需知道渐近常数。\n\n要断定一个初始角 $\\theta_0$ 位于目标特征向量 $v$ 的三阶收敛区域内，我们既需要它属于吸引盆（即迭代趋向于 $v$），也需要检测到三阶收敛行为。是否属于吸引盆可以通过误差 $e_k$ 趋向于 $0$ 以及最终迭代向量与 $v$ 良好对齐（等价于 $|x_k^\\top v|$ 接近于 $1$）来间接检查。对于三阶收敛的检测，我们施加一个实际准则：必须存在至少两个连续的索引 $k$，使得 $p_k \\in [3 - \\delta, 3 + \\delta]$ 同时 $e_{k-1}, e_k, e_{k+1}  \\varepsilon$，其中容差选择为 $\\delta = 0.3$ 和 $\\varepsilon = 10^{-6}$。这些阈值关注渐近模型适用的局部区域，并提供对早期迭代中瞬态行为的鲁棒性。如果 $\\theta_0$ 平凡地处于解的位置（$e_0  \\varepsilon$），我们将其计为三阶收敛，因为它位于 Newton 盆内且无需迭代。\n\n该测试套件旨在探究特征值分离度和维度如何影响 $S^{n-1}$ 上的 Newton 盆：\n- 测试用例 1 使用 $A^{(1)} = Q^{(1)} \\operatorname{diag}(1,3,10) \\left(Q^{(1)}\\right)^\\top$，其中 $Q^{(1)}$ 通过对确定性矩阵 $M^{(1)}_{ij} = \\sin(i + 2j) + 0.1 \\cos(3i - j)$（对于 $i,j \\in \\{1,2,3\\}$）进行 $QR$ 分解获得。目标特征向量为 $v^{(1)} = Q^{(1)}_{:,2}$，$w^{(1)} = Q^{(1)}_{:,3}$。特征值的清晰分离为目标特征对产生了一个相对较大的盆，因此我们预计大部分角度在经过一些迭代后会进入三阶收敛区域。\n- 测试用例 2 使用 $A^{(2)} = Q^{(1)} \\operatorname{diag}(1, 1.001, 2) \\left(Q^{(1)}\\right)^\\top$，使用相同的 $Q^{(1)}$ 和目标 $v^{(2)} = Q^{(1)}_{:,2}$，$w^{(2)} = Q^{(1)}_{:,3}$。$1$ 和 $1.001$ 的聚集会缩小并扭曲与第二个特征对相关的 Newton 盆，因此沿着所选大圆的初始角度中，应该有更少的角度表现出对 $v^{(2)}$ 的三阶收敛。\n- 测试用例 3 使用 $A^{(3)} = Q^{(3)} \\operatorname{diag}(0.5, 1.4, 2.0, 4.5, 9.0) \\left(Q^{(3)}\\right)^\\top$，其中 $Q^{(3)}$ 来自对 $M^{(3)}_{ij} = \\sin(0.3 i + 0.7 j) + 0.05 \\cos(i - 2 j)$（对于 $i,j \\in \\{1,2,3,4,5\\}$）进行 $QR$ 分解。目标特征向量为 $v^{(3)} = Q^{(3)}_{:,3}$，$w^{(3)} = Q^{(3)}_{:,4}$。这个更高维度的情况考察了 Newton 盆在 $S^{4}$ 上的行为，其特征值中等程度分离；与测试用例 1 和 2 相比，我们预计进入三阶收敛的角度比例将介于两者之间。\n\n算法细节：\n- 初始角度网格设置为 $[0, \\pi/2]$ 弧度内的 61 个等距点。\n- 在每次迭代中，计算瑞利商 $\\mu_k$，然后求解 $(A - \\mu_k I) y_k = x_k$。使用一个鲁棒的线性求解器（必要时采用最小二乘回退方案）来处理移位系统的近奇异性，这种情况可能在接近特征值时发生。迭代向量被重新归一化：$x_{k+1} = y_k / \\|y_k\\|_2$。\n- 记录角度误差序列 $\\{e_k\\}$。在有定义的情况下，使用对数估计量计算局部阶 $\\{p_k\\}$。使用指定的容差检查三阶收敛准则，当且仅当迭代趋向于 $v$ 并且满足该准则时，才将 $\\theta_0$ 计为三阶收敛。如果 $e_0  \\varepsilon$，则无需使用估计量，直接将 $\\theta_0$ 计为三阶收敛。\n\n对于每个测试用例，我们计算满足三阶收敛准则的角度网格的比例。这些比例四舍五入到三位小数，并以“[f1,f2,f3]”的格式单行打印。这通过指示采样弧上有多少部分位于观察到三阶收敛的盆内，提供了沿所选 $S^{n-1}$ 大圆的 Newton 盆结构的定量映射。", "answer": "```python\nimport numpy as np\n\ndef qr_orthonormal(M: np.ndarray) - np.ndarray:\n    # Use QR decomposition to obtain an orthonormal matrix Q\n    Q, R = np.linalg.qr(M)\n    # Ensure deterministic sign convention: make diagonal of R non-negative\n    d = np.sign(np.diag(R))\n    d[d == 0] = 1.0\n    Q = Q * d\n    return Q\n\ndef build_M1():\n    M = np.zeros((3, 3), dtype=float)\n    for i in range(1, 4):\n        for j in range(1, 4):\n            M[i-1, j-1] = np.sin(i + 2*j) + 0.1 * np.cos(3*i - j)\n    return M\n\ndef build_M3():\n    M = np.zeros((5, 5), dtype=float)\n    for i in range(1, 6):\n        for j in range(1, 6):\n            M[i-1, j-1] = np.sin(0.3 * i + 0.7 * j) + 0.05 * np.cos(i - 2*j)\n    return M\n\ndef rqi_errors(A: np.ndarray, v: np.ndarray, x0: np.ndarray, max_iter: int = 50) - list:\n    # Run Rayleigh quotient iteration and return angle errors w.r.t. v\n    x = x0 / np.linalg.norm(x0)\n    errors = []\n    for k in range(max_iter):\n        # Angle error e_k = arccos(|x_k^T v|)\n        dot = float(np.clip(np.abs(np.dot(x, v)), 0.0, 1.0))\n        e_k = float(np.arccos(dot))\n        errors.append(e_k)\n        if e_k  1e-14:\n            break\n        mu = float(np.dot(x, A @ x) / np.dot(x, x))\n        B = A - mu * np.eye(A.shape[0])\n        try:\n            y = np.linalg.solve(B, x)\n        except np.linalg.LinAlgError:\n            # Fallback to least squares if singular or ill-conditioned\n            y = np.linalg.lstsq(B, x, rcond=None)[0]\n        ynorm = np.linalg.norm(y)\n        if ynorm == 0.0 or not np.isfinite(ynorm):\n            # Bail out if numerical failure\n            break\n        x = y / ynorm\n    return errors\n\ndef estimate_orders(errors: list) - list:\n    # Compute local order estimates p_k using three consecutive errors\n    p_est = []\n    # Use only strictly positive errors for logs\n    for k in range(2, len(errors)):\n        e_km1 = errors[k-1]\n        e_km2 = errors[k-2]\n        e_k = errors[k]\n        if e_km2 > 0.0 and e_km1 > 0.0 and e_k > 0.0:\n            num = np.log(e_k) - np.log(e_km1)\n            den = np.log(e_km1) - np.log(e_km2)\n            if den != 0.0 and np.isfinite(num) and np.isfinite(den):\n                p = num / den\n                p_est.append(p)\n            else:\n                p_est.append(np.nan)\n        else:\n            p_est.append(np.nan)\n    return p_est\n\ndef is_cubic(errors: list, delta: float = 0.3, eps: float = 1e-6, min_consecutive: int = 2) - bool:\n    # If trivially at the solution, count as cubic\n    if len(errors) > 0 and errors[0]  eps:\n        return True\n    p_est = estimate_orders(errors)\n    # We need at least indices k with e_{k-1}, e_k, e_{k+1}  eps and p_k near 3\n    valid = []\n    # p_est index corresponds to k in [2, len(errors)-1]\n    for idx, p in enumerate(p_est):\n        k = idx + 2\n        if k  len(errors):\n            e_km2 = errors[k-2]\n            e_km1 = errors[k-1]\n            e_k = errors[k]\n            if e_km2  eps and e_km1  eps and e_k  eps and np.isfinite(p) and abs(p - 3.0) = delta:\n                valid.append(k)\n    # Check for at least min_consecutive consecutive k indices\n    if len(valid) == 0:\n        return False\n    # Count consecutive indices\n    count = 1\n    for i in range(1, len(valid)):\n        if valid[i] == valid[i-1] + 1:\n            count += 1\n            if count >= min_consecutive:\n                return True\n        else:\n            count = 1\n    return False\n\ndef run_case(A: np.ndarray, v: np.ndarray, w: np.ndarray, thetas: np.ndarray) - float:\n    # Compute fraction of angles with cubic convergence to v\n    n_cubic = 0\n    for theta in thetas:\n        x0 = np.cos(theta) * v + np.sin(theta) * w\n        x0 /= np.linalg.norm(x0)\n        errors = rqi_errors(A, v, x0, max_iter=50)\n        if is_cubic(errors, delta=0.3, eps=1e-6, min_consecutive=2):\n            n_cubic += 1\n    return n_cubic / len(thetas)\n\ndef solve():\n    # Build Test Case 1\n    M1 = build_M1()\n    Q1 = qr_orthonormal(M1)\n    A1 = Q1 @ np.diag([1.0, 3.0, 10.0]) @ Q1.T\n    v1 = Q1[:, 1]  # eigenvector for eigenvalue 3\n    w1 = Q1[:, 2]  # orthogonal direction\n\n    # Build Test Case 2 (reuse Q1)\n    A2 = Q1 @ np.diag([1.0, 1.001, 2.0]) @ Q1.T\n    v2 = Q1[:, 1]\n    w2 = Q1[:, 2]\n\n    # Build Test Case 3\n    M3 = build_M3()\n    Q3 = qr_orthonormal(M3)\n    A3 = Q3 @ np.diag([0.5, 1.4, 2.0, 4.5, 9.0]) @ Q3.T\n    v3 = Q3[:, 2]  # eigenvector for eigenvalue 2.0\n    w3 = Q3[:, 3]  # orthogonal direction\n\n    # Angle grid in radians\n    thetas = np.linspace(0.0, np.pi / 2.0, 61)\n\n    # Run cases\n    frac1 = run_case(A1, v1, w1, thetas)\n    frac2 = run_case(A2, v2, w2, thetas)\n    frac3 = run_case(A3, v3, w3, thetas)\n\n    results = [f\"{frac1:.3f}\", f\"{frac2:.3f}\", f\"{frac3:.3f}\"]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3572063"}]}