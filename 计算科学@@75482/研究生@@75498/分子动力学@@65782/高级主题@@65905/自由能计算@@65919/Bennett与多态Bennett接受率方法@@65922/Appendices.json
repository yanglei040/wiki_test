{"hands_on_practices": [{"introduction": "在学习像贝内特接受率（BAR）或多态贝内特接受率（MBAR）这样复杂的计算方法时，通过一个简单的已知案例来验证其行为至关重要，这是一种“合理性检查”。本练习将探讨两个完全相同的热力学状态这一平凡情况，旨在验证这些估计器能否正确地给出零自由能差（$\\Delta f = 0$）和零方差的理论结果。通过这个过程，你将加深对相空间重叠度等关键诊断量物理意义的理解。[@problem_id:3397190]", "problem": "考虑两个热力学状态，标记为 $0$ 和 $1$，每个状态都由逆温 $\\beta$ 下的正则分布定义。约化势为 $u_i(x) = \\beta U_i(x)$，其中 $U_i(x)$ 是状态 $i$ 的势能函数，$x$ 表示相空间中的一个构型。正则密度为 $p_i(x) = Z_i^{-1} \\exp(-u_i(x))$，配分函数为 $Z_i = \\int \\exp(-u_i(x)) \\, dx$，约化自由能为 $f_i = -\\ln Z_i$。自由能差为 $\\Delta f = f_1 - f_0$。\n\n给定一个平凡情况，其中势和温度相同，即对于所有 $x$，都有 $U_0(x) = U_1(x)$，并且两个状态都在相同的逆温 $\\beta$ 下采样。假设从 $p_0(x)$ 中抽取了 $N_0 = 41$ 个独立样本，从 $p_1(x)$ 中抽取了 $N_1 = 59$ 个独立样本。\n\n仅使用上述基本统计力学定义以及 Bennett Acceptance Ratio (BAR) 和 Multistate Bennett Acceptance Ratio (MBAR) 估计量是 $\\Delta f$ 的一致估计量这一事实，完成以下任务：\n\n1. 从第一性原理出发，证明 $p_0(x) = p_1(x)$，因此 $Z_0 = Z_1$，并得出结论：真实的自由能差为 $\\Delta f = 0$。\n\n2. 论证为什么在这种平凡情况下，$\\Delta f$ 的 BAR 估计和 MBAR 估计都恰好返回 $0$，并且估计量方差为零，即给定数据，估计量的输出是非随机常数。\n\n3. 计算以下反映两个状态之间完美重叠的诊断量：\n   - 重叠积分 $O = \\int \\min\\{p_0(x), p_1(x)\\} \\, dx$。\n   - Kullback–Leibler 散度 $D_{\\mathrm{KL}}(p_0 \\Vert p_1) = \\int p_0(x) \\ln\\big(p_0(x)/p_1(x)\\big) \\, dx$。\n   - Bhattacharyya 系数 $B = \\int \\sqrt{p_0(x) p_1(x)} \\, dx$。\n   - Multistate Bennett Acceptance Ratio (MBAR) 有效样本量，定义为 $N_{\\mathrm{eff}} = \\dfrac{\\left(\\sum_{n=1}^{N} w_n\\right)^{2}}{\\sum_{n=1}^{N} w_n^{2}}$，用于权重 $\\{w_n\\}_{n=1}^{N}$。这些权重在对合并的 $N = N_0 + N_1$ 个样本进行重加权时，用于估计任一状态下的期望值。在这种平凡场景中，可以认为这些权重与任一状态在 MBAR 下的重要性权重成正比。\n   - MBAR 权重的变异系数，$\\mathrm{CV}_w = \\dfrac{\\sqrt{\\mathrm{Var}(w)}}{\\mathbb{E}[w]}$，针对相同的合并权重。\n\n将最终答案表示为一个行矩阵，按顺序包含 $\\Delta f$ 的 BAR 估计值、$\\Delta f$ 的 MBAR 估计值、BAR 估计量的方差、重叠积分 $O$、Kullback–Leibler 散度 $D_{\\mathrm{KL}}(p_0 \\Vert p_1)$、Bhattacharyya 系数 $B$、MBAR 有效样本量 $N_{\\mathrm{eff}}$ 和变异系数 $\\mathrm{CV}_w$。\n\n无需四舍五入。所有量均为无量纲量，并应使用自然对数表示，因此约化自由能是无量纲的。", "solution": "### 问题验证\n该问题基于统计力学的基本原理和公认的计算方法，所有定义和概念均为科学合理的标准。问题提供了一套清晰、自洽的条件和一系列具体、可回答的问题，问题的所有部分都存在唯一解。因此，问题是有效的。\n\n### 解答\n\n解答按题目要求分为三个部分进行。\n\n**1. 证明状态相同且自由能差为零**\n\n我们已知两个状态的势能函数对于所有构型 $x$ 都是相同的：\n$$ U_0(x) = U_1(x) $$\n状态 $i$ 的约化势定义为 $u_i(x) = \\beta U_i(x)$。由于两个状态都处于相同的逆温 $\\beta$ 下，因此它们的约化势也直接相同：\n$$ u_0(x) = \\beta U_0(x) = \\beta U_1(x) = u_1(x) $$\n状态 $i$ 的配分函数 $Z_i$ 定义为玻尔兹曼因子在所有构型上的积分：\n$$ Z_i = \\int \\exp(-u_i(x)) \\, dx $$\n因为 $u_0(x) = u_1(x)$，$Z_0$ 和 $Z_1$ 的被积函数是相同的。因此，配分函数必须相等：\n$$ Z_0 = \\int \\exp(-u_0(x)) \\, dx = \\int \\exp(-u_1(x)) \\, dx = Z_1 $$\n状态 $i$ 的正则概率密度由 $p_i(x) = Z_i^{-1} \\exp(-u_i(x))$ 给出。既然我们已经证明了 $u_0(x) = u_1(x)$ 且 $Z_0 = Z_1$，那么这两个状态的概率密度必须相同：\n$$ p_0(x) = \\frac{\\exp(-u_0(x))}{Z_0} = \\frac{\\exp(-u_1(x))}{Z_1} = p_1(x) $$\n最后，约化自由能差 $\\Delta f$ 定义为 $\\Delta f = f_1 - f_0$。使用定义 $f_i = -\\ln Z_i$，我们有：\n$$ \\Delta f = (-\\ln Z_1) - (-\\ln Z_0) = \\ln Z_0 - \\ln Z_1 = \\ln\\left(\\frac{Z_0}{Z_1}\\right) $$\n由于 $Z_0 = Z_1$，它们的比值为 $1$，真实的自由能差为：\n$$ \\Delta f = \\ln(1) = 0 $$\n\n**2. 平凡情况下的 BAR 和 MBAR 估计量**\n\n这一部分的关键在于，由于 $u_0(x) = u_1(x)$，约化势能差 $\\Delta u(x) = u_1(x) - u_0(x)$ 对所有 $x$ 都为零。\n\n**Bennett接受率 (BAR)：**\n自由能差的 BAR 估计值 $\\Delta \\hat{f}$ 通过求解以下隐式方程得到：\n$$ \\sum_{n=1}^{N_1} \\frac{1}{1 + \\frac{N_1}{N_0} \\exp(\\Delta u(x_{1,n}) - \\Delta \\hat{f})} = \\sum_{m=1}^{N_0} \\frac{1}{1 + \\frac{N_0}{N_1} \\exp(-\\Delta u(x_{0,m}) + \\Delta \\hat{f})} $$\n其中 $\\{x_{1,n}\\}$ 是来自状态 $1$ 的样本，$\\{x_{0,m}\\}$ 是来自状态 $0$ 的样本。\n将所有 $x$ 的 $\\Delta u(x)=0$ 代入，方程显著简化：\n$$ \\sum_{n=1}^{N_1} \\frac{1}{1 + \\frac{N_1}{N_0} \\exp(- \\Delta \\hat{f})} = \\sum_{m=1}^{N_0} \\frac{1}{1 + \\frac{N_0}{N_1} \\exp(\\Delta \\hat{f})} $$\n求和号内的项是常数，不依赖于抽取的具体样本。方程变为：\n$$ N_1 \\left( \\frac{1}{1 + \\frac{N_1}{N_0} \\exp(- \\Delta \\hat{f})} \\right) = N_0 \\left( \\frac{1}{1 + \\frac{N_0}{N_1} \\exp(\\Delta \\hat{f})} \\right) $$\n这个方程可以解出 $\\Delta \\hat{f}$。我们可以检验解 $\\Delta \\hat{f} = 0$。如果 $\\Delta \\hat{f} = 0$，那么 $\\exp(-\\Delta \\hat{f}) = 1$ 且 $\\exp(\\Delta \\hat{f}) = 1$。方程变为：\n$$ \\frac{N_1}{1 + \\frac{N_1}{N_0}} = \\frac{N_0}{1 + \\frac{N_0}{N_1}} \\implies \\frac{N_1 N_0}{N_0 + N_1} = \\frac{N_0 N_1}{N_1 + N_0} $$\n这是一个恒等式，证实了 $\\Delta \\hat{f} = 0$ 是唯一解。因为确定 $\\Delta \\hat{f}$ 的方程不涉及随机样本，所以得到的估计量是一个非随机常数。因此，BAR 估计值恰好为 $\\Delta \\hat{f}_{\\mathrm{BAR}} = 0$，其方差也因此为 $0$。\n\n**多态Bennett接受率 (MBAR)：**\nMBAR 方程通过求解以下方程组来确定自由能集合 $\\{f_k\\}$：\n$$ \\exp(-f_k) = \\sum_{i=0}^{1} \\sum_{n=1}^{N_i} \\frac{\\exp(-u_k(x_{i,n}))}{\\sum_{j=0}^{1} N_j \\exp(f_j - u_j(x_{i,n}))}, \\quad k \\in \\{0, 1\\} $$\n设定参考自由能 $f_0=0$，我们求解 $f_1$。由于 $u_0(x)=u_1(x)=u(x)$，关于 $f_1$ 的方程是：\n$$ \\exp(-f_1) = \\sum_{i=0}^{1} \\sum_{n=1}^{N_i} \\frac{\\exp(-u(x_{i,n}))}{N_0 \\exp(f_0 - u(x_{i,n})) + N_1 \\exp(f_1 - u(x_{i,n}))} $$\n代入 $f_0=0$ 并从分母中提出因子 $\\exp(-u(x_{i,n}))$：\n$$ \\exp(-f_1) = \\sum_{i=0}^{1} \\sum_{n=1}^{N_i} \\frac{\\exp(-u(x_{i,n}))}{\\exp(-u(x_{i,n}))(N_0 + N_1 \\exp(f_1))} = \\sum_{i=0}^{1} \\sum_{n=1}^{N_i} \\frac{1}{N_0 + N_1 \\exp(f_1)} $$\n被加数对所有样本都是常数。对所有 $N_0+N_1$ 个样本求和得到：\n$$ \\exp(-f_1) = \\frac{N_0 + N_1}{N_0 + N_1 \\exp(f_1)} $$\n检验解 $f_1=0$ 得到 $\\exp(-0) = \\frac{N_0+N_1}{N_0+N_1\\exp(0)}$，简化为 $1 = \\frac{N_0+N_1}{N_0+N_1} = 1$。这证实了 $\\hat{f}_1=0$ 是唯一解。\n估计的自由能差为 $\\Delta \\hat{f}_{\\mathrm{MBAR}} = \\hat{f}_1 - \\hat{f}_0 = 0 - 0 = 0$。与 BAR 一样，结果与样本无关，因此估计值是一个方差为零的常数。\n\n**3. 诊断量的计算**\n\n- **重叠积分 ($O$)：**\n  $O = \\int \\min\\{p_0(x), p_1(x)\\} \\, dx$。由于 $p_0(x) = p_1(x)$，我们有 $\\min\\{p_0(x), p_1(x)\\} = p_0(x)$。概率密度函数在其定义域上的积分为 $1$。\n  $$ O = \\int p_0(x) \\, dx = 1 $$\n\n- **Kullback–Leibler 散度 ($D_{\\mathrm{KL}}$)：**\n  $D_{\\mathrm{KL}}(p_0 \\Vert p_1) = \\int p_0(x) \\ln\\left(\\frac{p_0(x)}{p_1(x)}\\right) \\, dx$。由于 $p_0(x) = p_1(x)$，比值为 $1$，且 $\\ln(1)=0$。\n  $$ D_{\\mathrm{KL}}(p_0 \\Vert p_1) = \\int p_0(x) \\cdot 0 \\, dx = 0 $$\n\n- **Bhattacharyya 系数 ($B$)：**\n  $B = \\int \\sqrt{p_0(x) p_1(x)} \\, dx$。由于 $p_0(x) = p_1(x)$，被积函数为 $\\sqrt{p_0(x)^2} = p_0(x)$。\n  $$ B = \\int p_0(x) \\, dx = 1 $$\n\n- **MBAR 有效样本量 ($N_{\\mathrm{eff}}$)：**\n  对于一个样本 $x_n$（来自合并的 $N=N_0+N_1$ 个样本集），用于估计任意状态 $k$ 的期望值的 MBAR 权重与 $w_n \\propto (\\sum_j N_j \\exp(f_j - u_j(x_n)))^{-1}$ 成正比。在本例中，$u_0=u_1=u$ 且 $f_0=f_1=0$，因此每个样本的分母简化为 $(N_0+N_1) \\exp(-u(x_n))$。用于估计状态 $k$ 中平均值的完整权重为 $w_{nk} = \\frac{\\exp(-u_k(x_n))}{\\sum_j N_j \\exp(f_j-u_j(x_n))}$。将这些权重归一化以使其总和为 $1$ 来形成平均值，我们发现每个权重的实际值变为一个常数，$w_n = 1/N$，其中 $N=N_0+N_1=41+59=100$。\n  有效样本量定义为 $N_{\\mathrm{eff}} = \\left(\\sum_{n=1}^{N} w_n\\right)^{2} / \\left(\\sum_{n=1}^{N} w_n^{2}\\right)$。\n  当 $w_n = 1/N$ 时：\n  $$ \\sum_{n=1}^{N} w_n = \\sum_{n=1}^{100} \\frac{1}{100} = 100 \\times \\frac{1}{100} = 1 $$\n  $$ \\sum_{n=1}^{N} w_n^2 = \\sum_{n=1}^{100} \\left(\\frac{1}{100}\\right)^2 = 100 \\times \\frac{1}{10000} = \\frac{1}{100} $$\n  $$ N_{\\mathrm{eff}} = \\frac{(1)^2}{1/100} = 100 $$\n  这表明由于重加权而没有样本损失，这与相同分布的预期一致。$N_{\\mathrm{eff}} = N_0+N_1=100$。\n\n- **权重变异系数 ($\\mathrm{CV}_w$)：**\n  $\\mathrm{CV}_w = \\sqrt{\\mathrm{Var}(w)}/\\mathbb{E}[w]$。权重 $\\{w_n\\}_{n=1}^N$ 是一组相同的常数，$w_n = 1/N$。一组常数值的方差为 $0$。\n  $$ \\mathrm{Var}(w) = 0 \\implies \\mathrm{CV}_w = 0 $$\n  这表示所有样本的权重均等，这是完美重叠的标志。\n\n**结果总结**\n- $\\Delta f$ 的 BAR 估计值：$0$\n- $\\Delta f$ 的 MBAR 估计值：$0$\n- BAR 估计量的方差：$0$\n- 重叠积分 $O$：$1$\n- Kullback–Leibler 散度 $D_{\\mathrm{KL}}(p_0 \\Vert p_1)$：$0$\n- Bhattacharyya 系数 $B$：$1$\n- MBAR 有效样本量 $N_{\\mathrm{eff}}$：$100$\n- 变异系数 $\\mathrm{CV}_w$：$0$\n这些值将被组合成最终的答案矩阵。", "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & 0 & 0 & 1 & 0 & 1 & 100 & 0 \\end{pmatrix}}\n$$", "id": "3397190"}, {"introduction": "从理想情况出发，我们现在转向一个更真实的场景，即不同状态之间存在差异。这个动手编程练习将引导你通过数值实验，来探索估计器方差与相空间重叠程度之间的定量关系。通过比较强大的BAR方法与更简单的单向指数平均（FEP）方法，你将具体地理解为何良好的相空间重叠对于高效、可靠的自由能计算至关重要。[@problem_id:3397194]", "problem": "给定一个用于分析分子动力学中自由能估计器统计效率的人工构建的两态平衡模型。该模型完全以简化单位定义，因此最终数值答案中不需要物理单位。您的任务是计算贝内特接受率（BAR）估计器的渐近方差，并将其与单侧指数平均（也称为自由能微扰，FEP）进行比较，作为可调重叠参数的函数。\n\n基本原理和构造：\n- 考虑两个简化势 $u_0(x)$ 和 $u_1(x)$，简化势差定义为 $\\Delta u(x) = u_1(x) - u_0(x)$。\n- 在平衡统计力学（正则系综）中，当从状态 $0$ 和 $1$ 采样时，$\\Delta u$ 的分布通过指数倾斜相关联：\n  $$ P_1(\\Delta u) = \\frac{P_0(\\Delta u)\\, e^{-(\\Delta u - \\Delta f)}}{\\int P_0(\\Delta u)\\, e^{-(\\Delta u - \\Delta f)}\\, d\\Delta u}, $$\n  其中 $\\Delta f$ 是满足以下条件的简化自由能差\n  $$ \\Delta f = -\\log \\mathbb{E}_{0}\\left[ e^{-\\Delta u} \\right], $$\n  且 $\\mathbb{E}_{0}[\\cdot]$ 表示关于 $P_0$ 的期望。\n- 定义一个由 $\\kappa > 0$ 索引的单参数模型族：\n  - 令 $P_0$ 为高斯分布 $P_0(\\Delta u) = \\mathcal{N}(m_0, s^2)$，其中 $s = \\kappa$ 且 $m_0 = s^2/2$。\n  - 使用上述指数倾斜关系和高斯分布的矩生成函数性质，此构造得出 $\\Delta f = 0$，且 $P_1(\\Delta u)$ 变为具有相同方差 $s^2$ 和均值 $m_1 = -s^2/2$ 的高斯分布。因此 $P_1(\\Delta u) = \\mathcal{N}(m_1, s^2)$。\n\n要比较的估计器：\n- 单侧指数平均（自由能微扰，FEP），从状态 $0$ 开始的正向方向：给定从 $P_0$ 中独立抽取的 $n_0$ 个样本 $\\{\\Delta u_i\\}_{i=1}^{n_0}$，估计器为\n  $$ \\widehat{\\Delta f}_{\\text{FEP}} = -\\log \\left( \\frac{1}{n_0} \\sum_{i=1}^{n_0} e^{-\\Delta u_i} \\right). $$\n- 贝内特接受率（BAR）：给定从 $P_0$ 中抽取的 $n_0$ 个样本和从 $P_1$ 中抽取的 $n_1$ 个样本，BAR 通过求解估计方程的唯一根 $C$ 来估计 $\\Delta f$\n  $$ \\frac{1}{n_0}\\sum_{i=1}^{n_0} \\frac{1}{1 + e^{\\Delta u_i - C}} - \\frac{1}{n_1}\\sum_{j=1}^{n_1} \\frac{1}{1 + e^{-(\\Delta u'_j - C)}} = 0, $$\n  其中 $\\{\\Delta u'_j\\}_{j=1}^{n_1}$ 是从 $P_1$ 中独立抽取的样本，然后设置 $\\widehat{\\Delta f}_{\\text{BAR}} = C$。在当前的对称构造中，真值为 $\\Delta f = 0$。\n\n方差分析任务：\n- 从大数定律和中心极限定理出发，并在适当时使用用于样本均值平滑变换的 delta 方法，您必须：\n  1) 推导单侧 FEP 估计器（从状态 $0$ 开始的正向方向）的渐近方差。用方差 $s^2$ 和样本量 $n_0$ 表示，给出一个仅依赖于 $s^2$ 和 $n_0$ 的公式。\n  2) 使用用于估计方程根的 M-估计器理论，推导 BAR 估计器的渐近方差。令 $f(u; C) = \\left(1 + e^{u - C}\\right)^{-1}$。证明在大样本极限下，当 $n_0 = n_1 = n$ 时，方差具有以下形式\n     $$ \\mathrm{Var}(\\widehat{\\Delta f}_{\\text{BAR}}) \\approx \\frac{ \\mathrm{Var}_0\\!\\left[f(\\Delta u; \\Delta f)\\right]/n + \\mathrm{Var}_1\\!\\left[f(\\Delta u; \\Delta f)\\right]/n }{ \\left( \\mathbb{E}_0\\!\\left[ f(\\Delta u; \\Delta f)\\left(1 - f(\\Delta u; \\Delta f)\\right) \\right] + \\mathbb{E}_1\\!\\left[ f(\\Delta u; \\Delta f)\\left(1 - f(\\Delta u; \\Delta f)\\right) \\right] \\right)^2 }, $$\n     其中下标为 $0$ 和 $1$ 的期望和方差分别相对于 $P_0$ 和 $P_1$ 计算，并且在真值 $C = \\Delta f = 0$ 处进行评估。\n- 将此高斯族中的“BAR不稳定性”解释为估计方程的灵敏度消失的条件，即分母\n  $$ D(\\kappa) \\equiv \\mathbb{E}_0\\!\\left[ f(\\Delta u; 0)\\left(1 - f(\\Delta u; 0)\\right) \\right] + \\mathbb{E}_1\\!\\left[ f(\\Delta u; 0)\\left(1 - f(\\Delta u; 0)\\right) \\right] $$\n  在数值上可以忽略不计，导致渐近方差爆炸性增大。出于数值计算目的，当 $D(\\kappa) < 10^{-6}$ 时，声明 BAR 为“不稳定”。\n\n数值程序约束：\n- 所有关于 $\\Delta u$ 且相对于 $P_0$ 和 $P_1$ 的积分都必须使用适用于高斯测度的求积法进行高精度数值计算。高斯-埃尔米特求积法是合适的：对于 $U \\sim \\mathcal{N}(m, s^2)$ 和任意函数 $g$，计算\n  $$ \\mathbb{E}[g(U)] = \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{M} w_i\\, g\\!\\left(m + s\\sqrt{2}\\, x_i\\right), $$\n  其中 $\\{x_i, w_i\\}_{i=1}^{M}$ 是 $M$ 点高斯-埃尔米特节点和权重，并且必须选择足够大的 $M$ 以确保在以下所有测试案例中的数值稳定性。\n\n测试套件：\n- 对两种状态使用相同的样本量：$n_0 = n_1 = n = 10000$。\n- 在以下六个重叠参数 $\\kappa$ 值处进行评估：\n  - $\\kappa = 0.25$\n  - $\\kappa = 0.75$\n  - $\\kappa = 1.50$\n  - $\\kappa = 2.50$\n  - $\\kappa = 4.00$\n  - $\\kappa = 6.00$\n- 对于每个 $\\kappa$，您必须计算：\n  - BAR 的渐近方差，以浮点数形式表示。\n  - 正向单侧 FEP 的渐近方差，以浮点数形式表示。\n  - 一个布尔标志，指示在该 $\\kappa$ 值下 BAR 是否不稳定（如上定义）。\n\n最终输出格式：\n- 您的程序必须输出一行，其中包含一个逗号分隔的 Python 列表，按顺序汇总六个测试案例的结果，每个案例贡献三个条目：$[\\mathrm{Var}_{\\text{BAR}}(\\kappa), \\mathrm{Var}_{\\text{FEP}}(\\kappa), \\text{unstable}(\\kappa), \\dots]$。\n- 在这十八个条目之后，追加另外两个条目：\n  1) 使得 $\\mathrm{Var}_{\\text{BAR}}(\\kappa) > \\mathrm{Var}_{\\text{FEP}}(\\kappa)$ 的最小 $\\kappa$ 值（来自给定的测试集）；如果没有，则输出 $-1$。\n  2) 被标记为不稳定的最小 $\\kappa$ 值（来自给定的测试集）；如果没有，则输出 $-1$。\n- 因此，最终打印的字符串必须是一个长度为 $20$ 的单行 Python 列表。所有浮点数都是无量纲的，必须在输出中四舍五入到六位小数。\n\n您的程序必须是自包含的，不得读取输入，也不得访问任何外部资源。它必须在内部实现高斯-埃尔米特求积法，并遵守在所有指定的 $\\kappa$ 值上的数值稳定性要求。输出必须是指定格式的单行文本（例如，“[..., ...]”）。", "solution": "问题陈述经过了仔细验证，被认为是**有效的**。它在科学上基于统计力学的原理，特别是自由能估计理论。问题设定良好、自包含，并提供了一个清晰、客观的任务，即在一个人工构建但严格定义的高斯模型中，推导和计算两个关键估计器——贝内特接受率（BAR）和自由能微扰（FEP）的统计特性。所有参数、定义和数值约束的规定都明确无误，没有歧义或矛盾。\n\n解决方案分两个阶段进行：理论推导和数值实现。\n\n### 理论推导\n\n该问题要求推导单侧 FEP 估计器和 BAR 估计器的渐近方差。\n\n**1. FEP 估计器的渐近方差**\n\n自由能差 $\\Delta f$ 的正向 FEP 估计器由下式给出：\n$$ \\widehat{\\Delta f}_{\\text{FEP}} = -\\log \\left( \\frac{1}{n_0} \\sum_{i=1}^{n_0} e^{-\\Delta u_i} \\right) $$\n其中样本 $\\{\\Delta u_i\\}$ 是从分布 $P_0(\\Delta u) = \\mathcal{N}(m_0, s^2)$ 中抽取的。问题规定 $s = \\kappa$ 和 $m_0 = s^2/2$。\n\n令 $Y_i = e^{-\\Delta u_i}$。该估计器是样本均值 $\\bar{Y} = \\frac{1}{n_0}\\sum Y_i$ 的函数，具体为 $\\widehat{\\Delta f}_{\\text{FEP}} = g(\\bar{Y})$，其中 $g(y) = -\\log(y)$。真实的自由能为 $\\Delta f = g(\\mathbb{E}_0[Y])$。\n$Y$ 的均值为 $\\mu_Y = \\mathbb{E}_0[e^{-\\Delta u}]$。这是高斯变量 $\\Delta u \\sim \\mathcal{N}(m_0, s^2)$ 在 $t=-1$ 处评估的矩生成函数：\n$$ \\mu_Y = \\mathbb{E}_0[e^{-\\Delta u}] = \\exp\\left(m_0(-1) + \\frac{s^2(-1)^2}{2}\\right) = \\exp\\left(-m_0 + \\frac{s^2}{2}\\right) $$\n代入 $m_0 = s^2/2$，我们发现 $\\mu_Y = \\exp(-s^2/2 + s^2/2) = \\exp(0) = 1$。这证实了问题陈述中 $\\Delta f = -\\log(1) = 0$ 的说法。\n\n使用 delta 方法，$\\widehat{\\Delta f}_{\\text{FEP}}$ 的渐近方差为：\n$$ \\mathrm{Var}(\\widehat{\\Delta f}_{\\text{FEP}}) \\approx [g'(\\mu_Y)]^2 \\mathrm{Var}(\\bar{Y}) = [g'(\\mu_Y)]^2 \\frac{\\mathrm{Var}_0(Y)}{n_0} $$\n由于 $g'(y) = -1/y$，我们有 $g'(1) = -1$。$Y$ 的方差为 $\\mathrm{Var}_0(Y) = \\mathbb{E}_0[Y^2] - (\\mathbb{E}_0[Y])^2$。\n我们需要 $\\mathbb{E}_0[Y^2] = \\mathbb{E}_0[e^{-2\\Delta u}]$，这是在 $t=-2$ 处评估的矩生成函数：\n$$ \\mathbb{E}_0[e^{-2\\Delta u}] = \\exp\\left(m_0(-2) + \\frac{s^2(-2)^2}{2}\\right) = \\exp\\left(-2m_0 + 2s^2\\right) $$\n代入 $m_0 = s^2/2$，我们得到 $\\mathbb{E}_0[e^{-2\\Delta u}] = \\exp(-s^2 + 2s^2) = \\exp(s^2)$。\n因此，$\\mathrm{Var}_0(Y) = \\exp(s^2) - 1^2 = \\exp(s^2) - 1$。\nFEP 估计器的渐近方差为：\n$$ \\mathrm{Var}(\\widehat{\\Delta f}_{\\text{FEP}}) \\approx \\frac{1}{n_0} (\\exp(s^2) - 1) = \\frac{\\exp(\\kappa^2) - 1}{n_0} $$\n这个表达式对于该模型是精确的，并且仅依赖于 $s^2 = \\kappa^2$ 和 $n_0$。\n\n**2. BAR 估计器的渐近方差**\n\n问题给出了在 $n_0 = n_1 = n$ 和真值 $\\Delta f = 0$ 的情况下，BAR 估计器的渐近方差公式：\n$$ \\mathrm{Var}(\\widehat{\\Delta f}_{\\text{BAR}}) \\approx \\frac{ \\mathrm{Var}_0[f(\\Delta u; 0)]/n + \\mathrm{Var}_1[f(\\Delta u; 0)]/n }{ \\left( \\mathbb{E}_0[f(\\Delta u; 0)(1 - f(\\Delta u; 0))] + \\mathbb{E}_1[f(\\Delta u; 0)(1 - f(\\Delta u; 0))] \\right)^2 } $$\n其中 $f(u; 0) = \\sigma(u) = (1 + e^u)^{-1}$。\n该模型是用对称分布构建的：$P_0 = \\mathcal{N}(m_0, s^2)$ 和 $P_1 = \\mathcal{N}(m_1, s^2)$，其中 $m_1 = -m_0 = -s^2/2$。这意味着对于任何函数 $h$，$\\mathbb{E}_1[h(\\Delta u)] = \\mathbb{E}_0[h(-\\Delta u)]$。\n\n这种对称性极大地简化了方差公式的组成部分：\n- 令 $g_3(u) = \\sigma(u)(1-\\sigma(u))$。这个函数是偶函数，$g_3(-u) = g_3(u)$。因此，$\\mathbb{E}_1[g_3(\\Delta u)] = \\mathbb{E}_0[g_3(-\\Delta u)] = \\mathbb{E}_0[g_3(\\Delta u)]$。\n分母的核心 $D(\\kappa)$ 变为 $D(\\kappa) = 2 \\mathbb{E}_0[\\sigma(\\Delta u)(1 - \\sigma(\\Delta u))]$。\n- 对于分子，我们有 $\\mathrm{Var}_1[\\sigma(\\Delta u)] = \\mathbb{E}_1[\\sigma^2(\\Delta u)] - (\\mathbb{E}_1[\\sigma(\\Delta u)])^2$。\n使用关系 $\\sigma(-u) = 1-\\sigma(u)$ 和 $\\sigma^2(-u) = (1-\\sigma(u))^2$，经过代数简化后，我们发现 $\\mathrm{Var}_1[\\sigma(\\Delta u)] = \\mathrm{Var}_0[\\sigma(\\Delta u)]$。\n\n因此，BAR 方差公式简化为：\n$$ \\mathrm{Var}(\\widehat{\\Delta f}_{\\text{BAR}}) \\approx \\frac{ 2 \\mathrm{Var}_0[\\sigma(\\Delta u)]/n }{ \\left( 2 \\mathbb{E}_0[\\sigma(\\Delta u)(1 - \\sigma(\\Delta u))] \\right)^2 } = \\frac{ \\mathrm{Var}_0[\\sigma(\\Delta u)] }{ 2n \\left( \\mathbb{E}_0[\\sigma(\\Delta u)(1 - \\sigma(\\Delta u))] \\right)^2 } $$\n其中 $\\mathrm{Var}_0[\\sigma(\\Delta u)] = \\mathbb{E}_0[\\sigma^2(\\Delta u)] - (\\mathbb{E}_0[\\sigma(\\Delta u)])^2$。\n\n### 数值评估\n\n剩下的任务是计算相对于高斯分布 $P_0 = \\mathcal{N}(m_0, s^2)$ 的期望值 $\\mathbb{E}_0[\\sigma(\\Delta u)]$、$\\mathbb{E}_0[\\sigma^2(\\Delta u)]$ 和 $\\mathbb{E}_0[\\sigma(\\Delta u)(1 - \\sigma(\\Delta u))]$。这通过指定的高斯-埃尔米特求积法来完成。对于一个函数 $g$ 和一个随机变量 $U \\sim \\mathcal{N}(m, s^2)$，期望计算如下：\n$$ \\mathbb{E}[g(U)] = \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{M} w_i\\, g(m + s\\sqrt{2}\\, x_i) $$\n其中 $\\{x_i, w_i\\}_{i=1}^{M}$ 是物理学家的埃尔米特多项式的节点和权重。实现将使用 `numpy.polynomial.hermite.hermgauss` 来获取这些节点和权重。选择足够多的点（$M=200$）以确保在所有 $\\kappa$ 值范围内的数值精度。\n\n最终的计算如下：\n- $\\mathrm{Var}_{\\text{FEP}}$ 是解析计算的。\n- $\\mathrm{Var}_{\\text{BAR}}$ 是使用简化公式和数值计算的期望值来计算的。\n- 如果 $D(\\kappa) = 2 \\mathbb{E}_0[\\sigma(\\Delta u)(1 - \\sigma(\\Delta u))] < 10^{-6}$，则 BAR 不稳定标志设置为 `True`。\n\n一个已知的理论结果是，BAR 估计器的方差小于或等于单侧 FEP 估计器的方差。因此，对于任何 $\\kappa > 0$，条件 $\\mathrm{Var}_{\\text{BAR}}(\\kappa) > \\mathrm{Var}_{\\text{FEP}}(\\kappa)$ 预计不会满足。相应的汇总统计量将是 $-1$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares the asymptotic variances of BAR and FEP estimators\n    for a synthetic Gaussian model.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    # List of overlap parameters kappa to test\n    KAPPAS = [0.25, 0.75, 1.50, 2.50, 4.00, 6.00]\n    # Number of samples from each state\n    N_SAMPLES = 10000\n    # Number of Gauss-Hermite quadrature points for numerical integration\n    N_QUAD_POINTS = 200\n    # Threshold for BAR instability\n    INSTABILITY_THRESHOLD = 1e-6\n\n    def compute_estimator_variances(kappa: float, n: int, M: int) -> tuple[float, float, bool]:\n        \"\"\"\n        Calculates the asymptotic variances for BAR and FEP for a given kappa.\n\n        Args:\n            kappa: The overlap parameter.\n            n: The number of samples (n0=n1=n).\n            M: The number of quadrature points.\n\n        Returns:\n            A tuple containing (Var_BAR, Var_FEP, is_unstable).\n        \"\"\"\n        s = kappa\n        s2 = s**2\n        \n        # --- 1. Asymptotic Variance of FEP (Analytic) ---\n        # Var(FEP_fwd) = (exp(s^2) - 1) / n\n        var_fep = (np.exp(s2) - 1) / n\n\n        # --- 2. Asymptotic Variance of BAR (Numerical Quadrature) ---\n        m0 = s2 / 2.0\n        \n        # Get Gauss-Hermite nodes (x_gh) and weights (w_gh) for the\n        # physicist's weight function exp(-x^2).\n        x_gh, w_gh = np.polynomial.hermite.hermgauss(M)\n\n        # Create the quadrature evaluation points for U ~ N(m0, s^2)\n        # using the transformation u = m0 + s*sqrt(2)*x\n        u_pts = m0 + s * np.sqrt(2.0) * x_gh\n\n        # Define integrand functions (vectorized)\n        # The fermi function f(u;0) = sigma(u)\n        sigma = 1.0 / (1.0 + np.exp(u_pts))\n        # f^2\n        sigma_sq = sigma**2\n        # f(1-f)\n        sigma_1_minus_sigma = sigma * (1.0 - sigma)\n\n        # Compute expectations with respect to P0 using the specified quadrature rule:\n        # E[g(U)] = (1/sqrt(pi)) * sum(w_i * g(m+s*sqrt(2)*x_i))\n        E0_sigma = np.sum(w_gh * sigma) / np.sqrt(np.pi)\n        E0_sigma_sq = np.sum(w_gh * sigma_sq) / np.sqrt(np.pi)\n        E0_sigma_1_minus_sigma = np.sum(w_gh * sigma_1_minus_sigma) / np.sqrt(np.pi)\n\n        # Variance of sigma(Delta u) under P0\n        var0_sigma = E0_sigma_sq - E0_sigma**2\n        \n        # Denominator term D(kappa) and instability check\n        D_kappa = 2.0 * E0_sigma_1_minus_sigma\n        is_unstable = D_kappa < INSTABILITY_THRESHOLD\n        \n        # Asymptotic variance of BAR, using the simplified formula for symmetric systems\n        # Var(BAR) = [2 * Var0(f) / n] / [D_kappa]^2\n        # Use a small epsilon to prevent division by zero for unstable cases.\n        var_bar = (2.0 * var0_sigma / n) / (D_kappa**2 + 1e-30)\n\n        return var_bar, var_fep, is_unstable\n\n    # --- Main Calculation Loop ---\n    all_results = []\n    first_crossover_kappa = -1.0\n    first_unstable_kappa = -1.0\n\n    for kappa in KAPPAS:\n        var_bar, var_fep, is_unstable = compute_estimator_variances(\n            kappa, N_SAMPLES, N_QUAD_POINTS\n        )\n        \n        all_results.append(f\"{var_bar:.6f}\")\n        all_results.append(f\"{var_fep:.6f}\")\n        all_results.append(str(is_unstable))\n        \n        # Check for crossover (Var_BAR > Var_FEP)\n        # Based on theory, this should not happen, so first_crossover_kappa will remain -1.\n        if var_bar > var_fep and first_crossover_kappa == -1.0:\n            first_crossover_kappa = kappa\n        \n        # Check for first occurrence of instability\n        if is_unstable and first_unstable_kappa == -1.0:\n            first_unstable_kappa = kappa\n\n    # --- Final Output Formatting ---\n    all_results.append(str(first_crossover_kappa))\n    all_results.append(str(first_unstable_kappa))\n    \n    final_output_string = f\"[{','.join(all_results)}]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "3397194"}, {"introduction": "作为总结性练习，这项实践要求你从零开始构建一个完整且数值稳定的MBAR求解器。你将不再依赖于现成的软件包，而是从第一性原理出发实现核心算法，并解决浮点数溢出等关键的实际问题——例如使用log-sum-exp技巧和阻尼迭代法来确保收敛。这项练习将彻底巩固你对MBAR方法底层工作原理的理解。[@problem_id:3397216]", "problem": "实现一个用于多态贝内特接受率 (MBAR) 的数值稳定求解器，该求解器适用于根据分子动力学中多个热力学状态抽取的汇总构象来估算无量纲约化自由能。从以下基本原理出发：在正则系综中，一个热力学状态的未归一化目标密度与玻尔兹曼因子 $e^{-u_k(x)}$ 成正比，其中 $u_k(x)$ 是约化势能。给定汇总样本和重要性采样下的最大似然原理，平稳条件定义了一组关于未知约化自由能的自洽方程，求解这些方程时必须满足任意加性常数不影响可观测量的约束。不要假设任何特定于多态贝内特接受率 (MBAR) 或贝内特接受率 (BAR) 的预推导公式；相反，应从汇总数据的似然性和重要性采样的归一化要求出发进行推理。您的实现必须：\n- 将重要性权重的分母视为 log-sum-exp 计算，以避免浮点运算中的下溢和上溢。\n- 强制执行一个锚定约定来固定加性规范自由度，例如 $ \\hat f_0 = 0 $。\n- 当估计值 $ \\hat f_m $ 变化范围很大时，至少包含两种缩放策略以提高数值稳定性：\n  - 在每次迭代时对向量 $ \\hat f $ 进行重新定心（例如，通过将一个分量固定为 $ 0 $）。\n  - 以对数形式对样本计数进行归一化，以移除不相关的全局尺度因子，这些因子只会将所有 $ \\hat f_k $ 平移一个常数，而该常数会被锚定消除。\n- 使用带有收敛容差的阻尼不动点迭代，以确保稳健收敛。\n\n测试构建的数据模型：\n- 考虑在逆温 $ \\beta = 1 $ 下的 $ 1 $ 维谐振子，其势能为 $ U_k(x) = \\tfrac{1}{2} K_k x^2 $，其中 $ K_k $ 是状态 $ k $ 的力常数。那么约化势为 $ u_k(x) = \\beta U_k(x) + c_k = \\tfrac{1}{2} K_k x^2 + c_k $，其中 $ c_k $ 是一个可能因状态而异的恒定偏移。\n- 对于每个热力学状态 $ k $，从该状态对应的平衡分布中抽取 $ N_k $ 个独立样本 $ x $。对于 $ \\beta = 1 $ 下的 $ 1 $ 维谐振子，$ x $ 服从均值为 $ 0 $、方差为 $ \\sigma_k^2 = 1 / K_k $ 的正态分布。\n- 对于每个测试用例，将所有状态的所有样本汇集成一个集合，并为每个汇总构象 $ x $ 和每个状态 $ m $ 计算 $ u_m(x) $，以获得一个形状为 $ K \\times N $ 的矩阵 $ u_{m i} $，其中 $ K $ 是状态数，$ N = \\sum_{k=0}^{K-1} N_k $ 是汇总样本的总数。\n\n算法要求：\n- 设 $ N_k $ 为从状态 $ k $ 抽取的样本数。设 $ \\hat f_k $ 为状态 $ k $ 的约化自由能的当前估计值。将汇总样本索引 $ i $ 的每个样本分母定义为对所有 $ m $ 的项 $ \\log N_m + \\hat f_m - u_m(x_i) $ 进行的稳定 log-sum-exp。使用它来评估重要性权重，并通过汇总数据似然的平稳条件所隐含的不动点方程更新 $ \\hat f_k $。对不动点更新应用阻尼，并重新定心向量 $ \\hat f $ 以在每次迭代时强制 $ \\hat f_0 = 0 $。以对数形式对 $ N_k $ 进行归一化（通过减去 $ \\log \\sum_m N_m $），这样计数中的任何全局乘法因子都只会给所有 $ \\hat f_k $ 带来一个加性常数，而该常数会被锚定移除。\n- 实现一个收敛检查，当所有 $ k $ 的 $ \\hat f_k $ 的最大绝对变化小于一个容差时停止。使用一个合理的默认容差，如 $ 10^{-12} $，以及一个阻尼因子，如 $ 0.5 $。\n\n测试套件：\n使用种子为 $ 12345 $ 的确定性随机数生成器构建以下 $ 4 $ 个测试用例，以便所有结果都是可复现的。对于每个测试用例，按上述规定生成正态变量，并为所有汇总样本和状态构建约化势能矩阵 $ u_{m i} $。然后对每个测试用例运行您的 MBAR 求解器以估计 $ \\hat f_k $，并锚定使得 $ \\hat f_0 = 0 $。对于每个测试用例，报告向量 $ [ \\hat f_0 - \\hat f_0, \\hat f_1 - \\hat f_0, \\ldots, \\hat f_{K-1} - \\hat f_0 ] $，因此第一个条目始终为 $ 0 $。\n\n- 测试用例 $ 1 $ (理想情况): $ K = 3 $, $ (N_0, N_1, N_2) = (200, 150, 150) $, $ (K_0, K_1, K_2) = (1.0, 4.0, 16.0) $, $ (c_0, c_1, c_2) = (0.0, 0.0, 0.0) $。\n- 测试用例 $ 2 $ (不平衡计数和中等偏移): $ K = 3 $, $ (N_0, N_1, N_2) = (400, 10, 10) $, $ (K_0, K_1, K_2) = (1.0, 2.0, 8.0) $, $ (c_0, c_1, c_2) = (0.0, 5.0, 10.0) $。\n- 测试用例 $ 3 $ (极端偏移压力测试): $ K = 2 $, $ (N_0, N_1) = (100, 100) $, $ (K_0, K_1) = (1.0, 1.0) $, $ (c_0, c_1) = (0.0, 500.0) $。\n- 测试用例 $ 4 $ (边界情况): $ K = 1 $, $ (N_0) = (100) $, $ (K_0) = (2.0) $, $ (c_0) = (0.0) $。\n\n角度或物理单位不适用；所有量均为无量纲约化单位。对于数值报告，将每个输出条目四舍五入到 $ 6 $ 位小数。\n\n最终输出格式：\n- 您的程序应生成单行文本，其中包含所有测试用例的锚定自由能的串联，每个测试用例贡献一个列表 $ [ \\hat f_0 - \\hat f_0, \\ldots, \\hat f_{K-1} - \\hat f_0 ] $，并展平打印为一个用方括号括起来的逗号分隔列表。例如，如果测试用例 $ 1 $ 产生 $ [0.0, a, b] $ 而测试用例 $ 2 $ 产生 $ [0.0, c, d] $，则最终输出应为 $ [0.0,a,b,0.0,c,d] $，每个数字四舍五入到 $ 6 $ 位小数。", "solution": "该问题是有效的，因为它在科学上基于统计力学的原理，特别是基于分子模拟数据计算自由能。该问题是良构的，提供了明确的目标、所有必要的数据以及可验证的结构。该问题要求从基本原理出发，实现多态贝内特接受率 (MBAR) 方法。\n\nMBAR 方程的推导源于一个自洽性要求，即从给定热力学状态观测到的样本数量必须与模型的预测数量相匹配。假设有 $K$ 个热力学状态，用 $k$ 索引。从每个状态 $k$ 中，采样 $N_k$ 个构象。所有 $N = \\sum_{k=0}^{K-1} N_k$ 个构象 $\\{x_i\\}_{i=1}^N$ 被汇集在一起。构象 $x_i$ 在状态 $k$ 下的约化势能为 $u_k(x_i)$。状态 $k$ 的未知无量纲约化自由能为 $f_k$。\n\n给定自由能集合 $\\{f_m\\}$，汇总集合中的一个给定构象 $x_i$ 源自状态 $k$ 的概率由后验概率给出：\n$$ P(k | x_i, \\{f_m, N_m\\}) = \\frac{P(x_i | k) P(k)}{\\sum_{m=0}^{K-1} P(x_i | m) P(m)} $$\n给定构象 $x_i$ 来自状态 $k$ 的条件下观测到它的概率与玻尔兹曼因子成正比，$P(x_i | k) \\propto e^{-u_k(x_i)}$。更准确地说，概率密度为 $p_k(x_i) = e^{-u_k(x_i) + f_k}$，其中 $e^{-f_k} = Z_k$ 是使分布归一化的配分函数。从状态 $k$ 抽取样本的先验概率与从中抽取的样本数量成正比，$P(k) \\propto N_k$。将这些代入后验概率公式得到：\n$$ P(k | x_i) = \\frac{N_k e^{-u_k(x_i) + f_k}}{\\sum_{m=0}^{K-1} N_m e^{-u_m(x_i) + f_m}} $$\n自洽性条件要求，来自状态 $k$ 的总样本数 $N_k$ 必须等于整个汇总数据集中每个样本源自状态 $k$ 的概率之和：\n$$ N_k = \\sum_{i=1}^N P(k | x_i) = \\sum_{i=1}^N \\frac{N_k e^{-u_k(x_i) + f_k}}{\\sum_{m=0}^{K-1} N_m e^{-u_m(x_i) + f_m}} $$\n假设 $N_k > 0$，我们可以用 $N_k$ 除以两边并重新整理，得到 $f_k$ 的不动点迭代。设 $f_k^{(t)}$ 为第 $t$ 次迭代的估计值。下一次迭代的估计值 $f_k^{(t+1)}$ 由以下公式给出：\n$$ e^{-f_k^{(t+1)}} = \\sum_{i=1}^N \\frac{e^{-u_k(x_i)}}{\\sum_{m=0}^{K-1} N_m e^{-u_m(x_i) + f_m^{(t)}}} $$\n对两边取自然对数，得到 $f_k$ 的更新规则：\n$$ f_k^{(t+1)} = -\\ln\\left( \\sum_{i=1}^N \\frac{e^{-u_k(x_i)}}{\\sum_{m=0}^{K-1} N_m e^{f_m^{(t)} - u_m(x_i)}} \\right) $$\n为了以数值稳定的方式实现这个方程，所有指数和都使用 log-sum-exp 技巧计算。设 $A_{mi}^{(t)} = \\ln N_m + f_m^{(t)} - u_m(x_i)$。对于样本 $i$，内部求和（分母）的对数为 $L_i^{(t)} = \\text{log-sum-exp}_m(A_{mi}^{(t)})$。更新方程变为：\n$$ f_k^{(t+1)} = -\\text{log-sum-exp}_i \\left( -u_k(x_i) - L_i^{(t)} \\right) $$\n这个迭代过程受一个任意加性常数的影响，因为给所有 $f_m$ 加上一个常数 $C$ 并不会改变方程。这个规范自由度通过锚定一个自由能来固定，例如在迭代的每一步强制 $\\hat f_0 = 0$。这是一种重新定心策略。\n第二种稳定性增强涉及对样本数 $N_k$ 进行归一化。使用归一化计数 $N_k' = N_k / N$ 等效于从所有初始 $\\ln N_k$ 中减去一个常数 $\\ln N$。这使得计算对于所有 $N_k$ 的全局缩放不变，这种平移在任何情况下都会被锚定步骤吸收。\n最后，为确保稳健收敛，使用阻尼更新。如果 $\\hat{f}_{\\text{new}}$ 是从上述方程计算并随后锚定的自由能向量，则下一个迭代值 $\\hat{f}^{(t+1)}$ 计算为新旧估计值的加权平均：\n$$ \\hat{f}^{(t+1)} = (1-\\alpha) \\hat{f}^{(t)} + \\alpha \\hat{f}_{\\text{new}} $$\n其中 $\\alpha \\in (0, 1]$ 是一个阻尼因子。迭代过程持续进行，直到 $\\hat{f}$ 的任何分量的最大绝对变化低于指定的容差 $\\epsilon$。\n\n算法流程如下：\n1.  将所有 $k$ 的自由能估计值 $\\hat{f}_k$ 初始化为 $0$。\n2.  预先计算样本计数的归一化对数 $\\ln(N_k/N)$，处理 $N_k=0$ 的情况。\n3.  进入迭代循环：\n    a. 计算分母的指数矩阵 $A_{mi} = \\ln(N_m/N) + \\hat{f}_m - u_{mi}$。\n    b. 沿状态轴 ($m$) 使用 log-sum-exp 找到每个样本的对数分母 $L_i = \\text{log-sum-exp}_m(A_{mi})$。\n    c. 计算外部和的指数矩阵 $B_{ki} = -u_{ki} - L_i$。\n    d. 沿样本轴 ($i$) 使用 log-sum-exp 找到新的未锚定自由能 $\\hat{f}_{k, \\text{raw}} = -\\text{log-sum-exp}_i(B_{ki})$。\n    e. 通过减去第一个元素来锚定新的估计值：$\\hat{f}_{k, \\text{new}} = \\hat{f}_{k, \\text{raw}} - \\hat{f}_{0, \\text{raw}}$。\n    f. 应用阻尼更新得到新的估计值 $\\hat{f}^{(t+1)}$。\n    g. 通过比较 $\\hat{f}^{(t+1)}$ 和 $\\hat{f}^{(t)}$ 来检查收敛。如果收敛，则退出；否则，继续。\n4.  返回最终的锚定自由能向量 $\\hat{f}$。\n此过程被实现以求解所提供测试用例的自由能。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef mbar_solver(u_kn, N_k, tol=1e-12, alpha=0.5, max_iter=10000):\n    \"\"\"\n    Solves the Multistate Bennett Acceptance Ratio (MBAR) equations for the\n    dimensionless reduced free energies.\n\n    This function implements a numerically stable, damped fixed-point iteration\n    to find the free energies f_k that satisfy the MBAR equations.\n\n    Args:\n        u_kn (np.ndarray): A matrix of shape (K, N) where u_kn[k, n] is the\n                           reduced potential energy of configuration n evaluated\n                           at the potential of state k. K is the number of states\n                           and N is the total number of configurations.\n        N_k (np.ndarray): An array of shape (K,) containing the number of\n                          configurations sampled from each state.\n        tol (float): The convergence tolerance. Iteration stops when the\n                     maximum absolute change in any f_k is less than this value.\n        alpha (float): The damping factor for the fixed-point iteration.\n        max_iter (int): The maximum number of iterations to perform.\n\n    Returns:\n        np.ndarray: An array of shape (K,) containing the estimated reduced free\n                    energies, anchored such that f_0 = 0.\n    \"\"\"\n    K = u_kn.shape[0]\n\n    # Handle trivial cases: one state or no states. The free energy difference\n    # is by definition 0.\n    if K <= 1:\n        return np.zeros(K)\n\n    # Initialize free energies to zero.\n    f_k = np.zeros(K)\n\n    # Calculate normalized log sample counts. This is numerically stable and\n    # handles states with zero samples (N_k=0 -> log(N_k)=-inf).\n    log_N_k = np.full(K, -np.inf)\n    active_states = N_k > 0\n    if np.any(active_states):\n        log_N_k[active_states] = np.log(N_k[active_states])\n    \n    # Normalizing the log-counts makes the solver invariant to global scaling\n    # of sample counts.\n    log_N_norm = log_N_k - logsumexp(log_N_k[active_states])\n\n    for _ in range(max_iter):\n        f_old = f_k.copy()\n        \n        # The argument for the log-sum-exp over states (k) is:\n        # A_kn = log(N_k) + f_k - u_kn\n        # We use broadcasting to efficiently compute this matrix.\n        log_N_f_k = log_N_norm[:, np.newaxis] + f_k[:, np.newaxis]\n        A_kn = log_N_f_k - u_kn\n        \n        # The log of the denominator term, for each configuration n:\n        # log_D_n = log(sum_k exp(A_kn))\n        # This summation is performed over the state index (axis=0).\n        log_D_n = logsumexp(A_kn, axis=0)\n        \n        # The argument for the log-sum-exp over configurations (n) is:\n        # B_kn = -u_kn - log_D_n\n        B_kn = -u_kn - log_D_n[np.newaxis, :]\n        \n        # Solve for the new, un-anchored free energies:\n        # f_new_k = -log(sum_n exp(B_kn))\n        # This summation is performed over the configuration index (axis=1).\n        f_new_k = -logsumexp(B_kn, axis=1)\n        \n        # Enforce anchoring convention f_0 = 0 by re-centering.\n        f_new_anchored = f_new_k - f_new_k[0]\n        \n        # Apply damped update to improve convergence stability.\n        f_k = f_k + alpha * (f_new_anchored - f_k)\n        \n        # Check for convergence.\n        max_abs_change = np.max(np.abs(f_k - f_old))\n        if max_abs_change < tol:\n            break\n            \n    # Final anchor to ensure f_0 is exactly 0.\n    f_k -= f_k[0]\n    return f_k\n\ndef solve():\n    \"\"\"\n    Main function to construct test cases, run the MBAR solver,\n    and print the results in the specified format.\n    \"\"\"\n    test_cases = [\n        # K, (N_counts), (K_springs), (c_offsets)\n        (3, (200, 150, 150), (1.0, 4.0, 16.0), (0.0, 0.0, 0.0)),\n        (3, (400, 10, 10), (1.0, 2.0, 8.0), (0.0, 5.0, 10.0)),\n        (2, (100, 100), (1.0, 1.0), (0.0, 500.0)),\n        (1, (100,), (2.0,), (0.0,)),\n    ]\n\n    rng = np.random.default_rng(seed=12345)\n    all_results = []\n\n    for case in test_cases:\n        K, N_counts, K_springs, c_offsets = case\n        N_counts_arr = np.array(N_counts)\n        \n        # Generate configurations for each state from its equilibrium distribution.\n        x_samples = []\n        if K > 0:\n            for k in range(K):\n                Nk = N_counts_arr[k]\n                if Nk > 0:\n                    Kk = K_springs[k]\n                    # For a 1D harmonic oscillator with beta=1, distribution is\n                    # Normal(0, 1/K_k).\n                    sigma_k = np.sqrt(1.0 / Kk)\n                    samples_k = rng.normal(loc=0.0, scale=sigma_k, size=Nk)\n                    x_samples.append(samples_k)\n        \n        # Pool all configurations into a single dataset.\n        if not x_samples:\n            x_pooled = np.array([])\n        else:\n            x_pooled = np.concatenate(x_samples)\n        \n        # Construct the reduced potential energy matrix u_kn.\n        N_total = x_pooled.shape[0]\n        u_kn = np.zeros((K, N_total))\n        if K > 0 and N_total > 0:\n            for m in range(K):\n                Km = K_springs[m]\n                cm = c_offsets[m]\n                u_kn[m, :] = 0.5 * Km * x_pooled**2 + cm\n        \n        # Run the MBAR solver.\n        f_k_estimated = mbar_solver(u_kn, N_counts_arr)\n        all_results.extend(f_k_estimated)\n\n    # Format the final results as a single comma-separated list.\n    # Each number is rounded to 6 decimal places.\n    formatted_results = [f\"{val:.6f}\" for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3397216"}]}