{"hands_on_practices": [{"introduction": "本练习将作为起点，展示精确动力学对称性的强大预测能力。我们将阐明，通过仅使用少数几个实验数据点来固定 $\\mathrm{SU}(3)$ 哈密顿量的参数，就可以预测其他可观测量，例如基态带中更高能级的能量。这项实践突显了 $\\mathrm{SU}(3)$ 极限所固有的刚性转子结构，并展示了如何利用对称性原理从有限的信息中推断出系统的整体行为 [@problem_id:3556643]。", "problem": "在相互作用玻色子模型 (IBM) 中，考虑玻色子数 $N=10$ 时三阶特殊酉群 (SU(3)) 动力学对称极限的情况。哈密顿量取为\n$\nH \\;=\\; a\\,\\hat{C}_{2}\\!\\left[\\mathrm{SU}(3)\\right] \\;+\\; b\\,\\hat{C}_{2}\\!\\left[\\mathrm{O}(3)\\right],\n$\n其中 $\\hat{C}_{2}\\!\\left[\\mathrm{SU}(3)\\right]$ 和 $\\hat{C}_{2}\\!\\left[\\mathrm{O}(3)\\right]$ 分别是 $\\mathrm{SU}(3)$ 和 $\\mathrm{O}(3)$ 的二次 Casimir 算符。在由 $(\\lambda,\\mu)$ 标记的不可约表示中，$\\hat{C}_{2}\\!\\left[\\mathrm{SU}(3)\\right]$ 的本征值为\n$\nC_{2}(\\lambda,\\mu) \\;=\\; \\lambda^{2} \\,+\\, \\mu^{2} \\,+\\, \\lambda\\,\\mu \\,+\\, 3(\\lambda+\\mu),\n$\n在角动量为 $L$ 的态中，$\\hat{C}_{2}\\!\\left[\\mathrm{O}(3)\\right]$ 的本征值为\n$\nL(L+1).\n$\n在具有 $N$ 个玻色子的 IBM 的 $\\mathrm{SU}(3)$ 极限下，基态带按照 $(\\lambda,\\mu)=(2N,0)$ 变换，而最低的 $\\beta$ 带按照 $(\\lambda,\\mu)=(2N-4,2)$ 变换。假设基态能量 $E(0_{1}^{+})$ 被用作参考基准 $0$，因此对于激发能而言，$H$ 中的任何加性常数都可以忽略。\n\n给定某单个偶偶核的两个实验能级间距：\n- 第一个激发 $2^{+}$ 态的能量为 $E(2_{1}^{+})=0.180~\\mathrm{MeV}$。\n- $\\beta$ 带头的能量为 $E(0_{\\beta}^{+})=1.200~\\mathrm{MeV}$。\n\n仅使用上述定义和已陈述的 IBM $\\mathrm{SU}(3)$ 带的指定，从这两个能级间距确定参数 $a$ 和 $b$，然后预测 $6^{+}$ 基态带态的激发能 $E(6_{1}^{+})$（单位为 MeV）。将你最终的数值预测 $E(6_{1}^{+})$ 四舍五入到四位有效数字。最终能量以 MeV 表示。", "solution": "首先对问题陈述进行严格的验证过程。\n\n**步骤1：提取给定条件**\n- 模型：相互作用玻色子模型 (IBM) 中的三阶特殊酉群 $\\mathrm{SU}(3)$ 动力学对称极限。\n- 玻色子数：$N=10$。\n- 哈密顿量：$H = a\\,\\hat{C}_{2}[\\mathrm{SU}(3)] + b\\,\\hat{C}_{2}[\\mathrm{O}(3)]$。\n- $\\hat{C}_{2}[\\mathrm{SU}(3)]$ 对不可约表示 $(\\lambda,\\mu)$ 的本征值：$C_{2}(\\lambda,\\mu) = \\lambda^{2} + \\mu^{2} + \\lambda\\,\\mu + 3(\\lambda+\\mu)$。\n- $\\hat{C}_{2}[\\mathrm{O}(3)]$ 对角动量为 $L$ 的态的本征值：$L(L+1)$。\n- 基态带不可约表示：$(\\lambda,\\mu)=(2N,0)$。\n- 最低 $\\beta$ 带不可约表示：$(\\lambda,\\mu)=(2N-4,2)$。\n- 能量参考：基态能量 $E(0_{1}^{+})$ 设为 $0$。所有其他能量均为激发能。\n- 实验数据点1：$E(2_{1}^{+}) = 0.180~\\mathrm{MeV}$。\n- 实验数据点2：$E(0_{\\beta}^{+}) = 1.200~\\mathrm{MeV}$。\n- 任务：确定参数 $a$ 和 $b$，并预测激发能 $E(6_{1}^{+})$（单位为 MeV），结果四舍五入到四位有效数字。\n\n**步骤2：使用提取的给定条件进行验证**\n- **科学基础：** 该问题牢固地植根于相互作用玻色子模型，这是原子核结构物理学中一个被广泛接受且成功的理论框架。群论的使用，特别是 $\\mathrm{U}(6) \\supset \\mathrm{SU}(3) \\supset \\mathrm{O}(3)$ 代数链及其相关的 Casimir 算符和量子数，是该领域的标准做法。哈密顿量的形式是 $\\mathrm{SU}(3)$ 动力学对称性的标准形式。基态带和 $\\beta$ 带的不可约表示指定在此极限下是正确的。\n- **适定性：** 问题提供了足够的信息（$N$ 和两个能级）来确定模型哈密顿量中的两个未知参数（$a$，$b$）。问题要求基于这些参数进行特定预测，对此存在唯一解。\n- **客观性：** 问题使用标准的物理学和数学术语以精确、定量的方式陈述。它没有歧义或主观性语言。\n- **自洽性与一致性：** 所有必要的公式和定义都已提供。给定的数值对于一个表现出转动特性的偶偶核来说是物理上合理的。不存在内部矛盾。\n\n**步骤3：结论与行动**\n该问题是有效的，因为它科学上合理、适定、客观且自洽。将提供完整的解答。\n\n由 $\\mathrm{SU}(3)$ 不可约表示 $(\\lambda, \\mu)$ 和角动量 $L$ 表征的一个态的能量本征值，由哈密顿量的期望值给出：\n$$E(\\lambda, \\mu, L) = a C_{2}(\\lambda, \\mu) + b L(L+1)$$\n其中 $C_{2}(\\lambda, \\mu) = \\lambda^{2} + \\mu^{2} + \\lambda\\mu + 3(\\lambda+\\mu)$。\n\n问题陈述，基态能量 $E(0_1^+)$ 是参考能量，因此我们关心的是激发能 $E_{\\mathrm{ex}}$。基态 ($0_1^+$) 属于基态带，其 $\\mathrm{SU}(3)$ 不可约表示为 $(\\lambda_g, \\mu_g) = (2N, 0)$ 且角动量为 $L=0$。当 $N=10$ 时，基态不可约表示为 $(20, 0)$。\n\n基态的能量是：\n$$E(0_1^+) = E(20, 0, 0) = a C_2(20, 0) + b(0)(0+1)$$\n我们来计算基态不可约表示的 Casimir 本征值：\n$$C_2(20, 0) = 20^2 + 0^2 + (20)(0) + 3(20+0) = 400 + 60 = 460$$\n所以，基态能量为 $E(0_1^+) = 460a$。\n\n任何态 $(\\lambda, \\mu, L)$ 的激发能定义为：\n$$E_{\\mathrm{ex}}(\\lambda, \\mu, L) = E(\\lambda, \\mu, L) - E(0_1^+)$$\n$$E_{\\mathrm{ex}}(\\lambda, \\mu, L) = \\left[a C_{2}(\\lambda, \\mu) + b L(L+1)\\right] - a C_2(20, 0)$$\n$$E_{\\mathrm{ex}}(\\lambda, \\mu, L) = a \\left[C_{2}(\\lambda, \\mu) - 460\\right] + b L(L+1)$$\n\n给定了第一个激发态 $2_1^+$ 的能量。该态是基态带的一部分，因此它具有相同的 $(\\lambda, \\mu) = (20, 0)$，但角动量为 $L=2$。其激发能给定为 $E(2_1^+) = 0.180~\\mathrm{MeV}$。\n$$E_{\\mathrm{ex}}(2_1^+) = E_{\\mathrm{ex}}(20, 0, 2) = a \\left[C_{2}(20, 0) - 460\\right] + b (2)(2+1)$$\n$$E_{\\mathrm{ex}}(2_1^+) = a \\left[460 - 460\\right] + 6b = 6b$$\n使用给定的实验值：\n$$6b = 0.180~\\mathrm{MeV} \\implies b = \\frac{0.180}{6}~\\mathrm{MeV} = 0.030~\\mathrm{MeV}$$\n\n接下来，我们给定了 $\\beta$ 带头 $0_\\beta^+$ 的能量。该态是 $\\beta$ 带的最低态 ($L=0$)，其不可约表示为 $(\\lambda_\\beta, \\mu_\\beta) = (2N-4, 2)$。对于 $N=10$，这是 $(16, 2)$。其激发能给定为 $E(0_\\beta^+) = 1.200~\\mathrm{MeV}$。\n$$E_{\\mathrm{ex}}(0_\\beta^+) = E_{\\mathrm{ex}}(16, 2, 0) = a \\left[C_{2}(16, 2) - 460\\right] + b (0)(0+1)$$\n我们必须先计算 $(16, 2)$ 不可约表示的 Casimir 本征值：\n$$C_2(16, 2) = 16^2 + 2^2 + (16)(2) + 3(16+2) = 256 + 4 + 32 + 3(18) = 292 + 54 = 346$$\n现在将此代入能量表达式：\n$$E_{\\mathrm{ex}}(0_\\beta^+) = a \\left[346 - 460\\right] = -114a$$\n使用给定的实验值：\n$$-114a = 1.200~\\mathrm{MeV} \\implies a = -\\frac{1.200}{114}~\\mathrm{MeV} \\approx -0.01053~\\mathrm{MeV}$$\n参数已确定为 $a = -1.200/114~\\mathrm{MeV}$ 和 $b = 0.030~\\mathrm{MeV}$。$a$ 的负号在物理上是正确的，它确保具有较大 Casimir 本征值的不可约表示 $(20,0)$ 对应于基态带。\n\n最后，我们需要预测 $6_1^+$ 态的激发能。该态属于基态带，因此其量子数为 $(\\lambda, \\mu) = (20, 0)$ 和 $L=6$。\n$$E_{\\mathrm{ex}}(6_1^+) = E_{\\mathrm{ex}}(20, 0, 6) = a \\left[C_{2}(20, 0) - 460\\right] + b (6)(6+1)$$\n$$E_{\\mathrm{ex}}(6_1^+) = a \\left[460 - 460\\right] + 42b = 42b$$\n这个预测仅取决于参数 $b$。代入我们求得的 $b$ 值：\n$$E_{\\mathrm{ex}}(6_1^+) = 42 \\times 0.030~\\mathrm{MeV} = 1.26~\\mathrm{MeV}$$\n\n问题要求答案四舍五入到四位有效数字。\n$$E(6_1^+) = 1.260~\\mathrm{MeV}$$\n这个结果与刚性转子的特征能量比一致，这是 $\\mathrm{SU}(3)$ 极限的一个关键特征：\n$$\\frac{E(6_1^+)}{E(2_1^+)} = \\frac{42b}{6b} = 7$$\n$$E(6_1^+) = 7 \\times E(2_1^+) = 7 \\times 0.180~\\mathrm{MeV} = 1.26~\\mathrm{MeV}$$\n四舍五入到四位有效数字得到 $1.260~\\mathrm{MeV}$。", "answer": "$$\\boxed{1.260}$$", "id": "3556643"}, {"introduction": "在精确对称性的概念基础上，本练习将深入探讨序列对称性破缺的后果。我们将从纯 $\\mathrm{U}(5)$ 极限的高度简并能谱出发，展示通过引入子群 $\\mathrm{O}(5)$ 和 $\\mathrm{O}(3)$ 的项，这些简并性如何以可预测的方式被解除。此练习的高潮部分是一项强大的诊断技术：利用模型拟合来检测那些超出标准卡西米尔算符框架的“隐藏”对称性破缺相互作用的存在，从而教授一项在模型验证中至关重要的技能 [@problem_id:3556532]。", "problem": "考虑维度为六的酉群（表示为 $U(6)$）极限下的相互作用玻色子模型 (IBM)，其具有标准的动力学对称链 $U(6) \\supset U(5) \\supset O(5) \\supset O(3)$。相关的自由度是角动量 $L=0$ 的标量 $s$ 玻色子和角动量 $L=2$ 的四极 $d$ 玻色子，总玻色子数 $N$ 是固定的。在 $U(5)$ 动力学对称极限下，态由链量子数 $[N], n_d, \\tau, L$ 标记，其中 $n_d$ 是 $d$ 玻色子的数量，$\\tau$ 是 $O(5)$ seniority，而 $L$ 是总角动量。\n\n基本基础：\n- $d$ 玻色子的数算符 $n_d$ 计算四极玻色子的数量，其本征值为 $n_d$。\n- $O(5)$ 的二次 Casimir 算符在由 $\\tau$ 标记的 $O(5)$ 不可约表示上的本征值为 $\\tau(\\tau+3)$。\n- $O(3)$ 的二次 Casimir 算符在由 $L$ 标记的角动量多重态上的本征值为 $L(L+1)$。\n- 在 $U(5)$ 极限下，为了分类简并模式的目的，哈密顿量可以被建模为这些对易不变量的线性组合，而不失一般性。\n\n低能 $U(5)$ 多重态是那些具有较小 $n_d$ 值的态。使用对称玻色子表示的 $U(5)\\to O(5)\\to O(3)$ 分支规则，低能 $n_d$ 部分允许的 $(\\tau,L)$ 内容为：\n- 对于 $n_d=0$：$\\tau=0$，伴有 $L=0$。\n- 对于 $n_d=1$：$\\tau=1$，伴有 $L=2$。\n- 对于 $n_d=2$：$\\tau=0$，伴有 $L=0$；以及 $\\tau=2$，伴有 $L \\in \\{2,4\\}$。\n- 对于 $n_d=3$：$\\tau=1$，伴有 $L=2$；以及 $\\tau=3$，伴有 $L \\in \\{0,2,3,4,6\\}$。\n\n从这些基本事实出发，解析地推导由一个仅依赖于 $n_d$ 的哈密顿量所蕴含的能谱简并模式，然后展示添加与 $O(5)$ 和 $O(3)$ Casimir 算符成比例的项如何以可预测的方式解除这些简并。您的推导必须从上述基础出发，并且不得假设或陈述超出所列 Casimir 本征值和分支内容的中间快捷公式。最后，以具体的计数总结在所列的低能部分中，每个 $n_d$ 多重态内有多少个不同的 $(\\tau,L)$ 能级是简并的。\n\n然后，在一个完整的、可运行的程序中实现数值验证和诊断。将标记为 $(n_d,\\tau,L)$ 的基态的哈密顿量本征值建模为\n$$\nE(n_d,\\tau,L) = \\epsilon\\, n_d + \\alpha\\, \\tau(\\tau+3) + \\beta\\, L(L+1) + \\zeta\\, n_d\\,\\tau,\n$$\n其中 $\\epsilon$、$\\alpha$、$\\beta$ 和 $\\zeta$ 是实系数。最后一项 $ \\zeta\\, n_d\\,\\tau$ 编码了一个通用的隐藏对称性破缺贡献，该贡献不能表示为上述三个 Casimir 本征值的线性组合。\n\n您的程序必须：\n- 根据上面列出的允许内容，枚举 $n_d \\in \\{0,1,2,3\\}$ 的所有 $(n_d,\\tau,L)$ 态，对于任何 $N \\ge 3$。\n- 在给定的模型参数下，计算每个态的能量 $E(n_d,\\tau,L)$。\n- 在不同的参数集下，数值验证解析预测的简并模式。\n- 通过尝试将计算出的能量进行最小二乘拟合到线性模型\n$$\nE_{\\text{fit}}(n_d,\\tau,L) = a\\, n_d + b\\, \\tau(\\tau+3) + c\\, L(L+1),\n$$\n并报告残差 $||E - E_{\\text{fit}}||_2$ 的欧几里得范数，来诊断隐藏的对称性破缺。非零残差表示存在不能被线性 Casimir 组合所捕获的贡献，因此存在隐藏的对称性破缺项。\n\n所有能量均以无量纲单位处理。\n\n测试套件：\n使用以下参数集，您的程序必须对每个参数集进行评估和报告：\n1. 情况1（纯 $U(5)$ 数算符哈密顿量）：$\\epsilon=1.0$, $\\alpha=0.0$, $\\beta=0.0$, $\\zeta=0.0$。数值验证在每个固定的 $n_d$ 内的所有态都是严格简并的。报告一个布尔值，指示这是否在 $10^{-12}$ 的容差内得到满足。\n2. 情况2（有 $O(5)$ 分裂但无 $O(3)$ 分裂）：$\\epsilon=1.0$, $\\alpha=0.2$, $\\beta=0.0$, $\\zeta=0.0$。数值验证在每个固定的 $(n_d,\\tau)$ 块内的所有态都是严格简并的，并且在相同 $n_d$ 下具有不同 $\\tau$ 的态是分裂的。报告一个布尔值，指示 $(n_d,\\tau)$ 简并是否在 $10^{-12}$ 的容差内成立。\n3. 情况3（包含 $O(3)$ 分裂）：$\\epsilon=1.0$, $\\alpha=0.2$, $\\beta=0.1, \\zeta=0.0$。数值验证不同的 $(n_d,\\tau,L)$ 能级之间没有简并（即，在 $10^{-12}$ 的容差内所有能量都是唯一的）。报告一个布尔值，指示所有能量是否唯一。\n4. 情况4（隐藏对称性破缺诊断）：$\\epsilon=1.0$, $\\alpha=0.0, \\beta=0.0, \\zeta=0.05$。计算对 $E_{\\text{fit}}(n_d,\\tau,L)$ 的最小二乘拟合，并报告残差向量的欧几里得范数（作为一个浮点数）。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个测试用例的结果，形式为方括号括起来的逗号分隔列表（例如，$[r_1,r_2,r_3,r_4]$），其中 $r_1$、$r_2$ 和 $r_3$ 是布尔值，$r_4$ 是一个浮点数。不允许有其他输出。", "solution": "该问题被验证为具有科学依据、提法恰当且客观。所提供的量子数和分支规则构成本次计算的基础，并被视为该问题的定义性条件。\n\n该问题要求对相互作用玻色子模型 (IBM) 的 $U(5)$ 极限下的简并模式进行解析推导，并随后进行数值验证。态由量子数 $(n_d, \\tau, L)$ 标记，其中 $n_d$ 是 $d$-玻色子数，$\\tau$ 是 $O(5)$ seniority，而 $L$ 是角动量。总玻色子数 $N$ 是一个大于或等于 $3$ 的常数。\n\n根据问题规定，对于 $n_d \\in \\{0, 1, 2, 3\\}$，需要考虑的基态为：\n- $n_d=0$：态 $(\\tau, L) = (0, 0)$。一个态。\n- $n_d=1$：态 $(\\tau, L) = (1, 2)$。一个态。\n- $n_d=2$：态 $(\\tau, L) = (0, 0)$ 和 $(\\tau, L) = (2, \\{2, 4\\})$。总共三个态：$(2,0,0), (2,2,2), (2,2,4)$。\n- $n_d=3$：态 $(\\tau, L) = (1, 2)$ 和 $(\\tau, L) = (3, \\{0, 2, 3, 4, 6\\})$。总共六个态：$(3,1,2), (3,3,0), (3,3,2), (3,3,3), (3,3,4), (3,3,6)$。\n\n模型哈密顿量的本征值由以下通用形式给出：\n$$\nE(n_d,\\tau,L) = \\epsilon\\, n_d + \\alpha\\, \\tau(\\tau+3) + \\beta\\, L(L+1)\n$$\n此形式源于一个构造为 $d$-玻色子数算符 $\\hat{n}_d$ 以及群 $O(5)$ 和 $O(3)$ 的二次 Casimir 算符 $\\hat{C}_2(O(5))$ 和 $\\hat{C}_2(O(3))$ 的线性组合的哈密顿量。它们的本征值分别为 $n_d$、$\\tau(\\tau+3)$ 和 $L(L+1)$。\n\n**简并模式的解析推导**\n\n1.  **纯 $U(5)$ 数算符哈密顿量：**\n    设哈密顿量为 $H_1 = \\epsilon \\hat{n}_d$。能量本征值为 $E(n_d, \\tau, L) = \\epsilon n_d$。能量仅依赖于 $d$-玻色子的数量 $n_d$。因此，所有共享相同 $n_d$ 值的态都是简并的，无论其 $\\tau$ 和 $L$ 值如何。\n    -   对于 $n_d=0$，有 $1$ 个态 $(0,0,0)$。这形成一个单态。\n    -   对于 $n_d=1$，有 $1$ 个态 $(1,1,2)$。这形成一个单态。\n    -   对于 $n_d=2$，有 $3$ 个不同的 $(\\tau,L)$ 态：$(2,0,0)$、$(2,2,2)$ 和 $(2,2,4)$。它们的能量均为 $2\\epsilon$，因此是简并的。$(\\tau,L)$ 能级的简并计数为 $3$。\n    -   对于 $n_d=3$，有 $6$ 个不同的 $(\\tau,L)$ 态：$(3,1,2)$、$(3,3,0)$、$(3,3,2)$、$(3,3,3)$、$(3,3,4)$ 和 $(3,3,6)$。它们的能量均为 $3\\epsilon$，并且是简并的。$(\\tau,L)$ 能级的简并计数为 $6$。\n\n2.  **使用 $O(5)$ Casimir 算符解除简并：**\n    设哈密顿量为 $H_2 = \\epsilon \\hat{n}_d + \\alpha \\hat{C}_2(O(5))$。能量本征值为 $E(n_d, \\tau, L) = \\epsilon n_d + \\alpha \\tau(\\tau+3)$。现在能量同时依赖于 $n_d$ 和 $\\tau$。每个 $n_d$ 多重态内的大简并被部分解除。具有共同值对 $(n_d, \\tau)$ 的态仍然是简并的。\n    -   对于 $n_d=2$，态按 $\\tau$ 划分。态 $(2,0,0)$ 的能量为 $2\\epsilon$。两个态 $(2,2,2)$ 和 $(2,2,4)$ 都属于 $\\tau=2$，共享能量 $2\\epsilon + \\alpha(2)(2+3) = 2\\epsilon + 10\\alpha$。因此，$n_d=2$ 多重态的 3 重简并分裂为一个单态（对于 $\\tau=0$）和一个二重态（对于 $\\tau=2$）。\n    -   对于 $n_d=3$，态也按 $\\tau$ 划分。态 $(3,1,2)$ 属于 $\\tau=1$，能量为 $3\\epsilon + \\alpha(1)(1+3) = 3\\epsilon + 4\\alpha$。五个态 $(3,3,0)$、$(3,3,2)$、$(3,3,3)$、$(3,3,4)$ 和 $(3,3,6)$ 都属于 $\\tau=3$，共享能量 $3\\epsilon + \\alpha(3)(3+3) = 3\\epsilon + 18\\alpha$。因此，$n_d=3$ 多重态的 6 重简并分裂为一个单态（对于 $\\tau=1$）和一个五重态（对于 $\\tau=3$）。\n\n3.  **使用 $O(3)$ Casimir 算符完全解除简并：**\n    设哈密顿量为 $H_3 = \\epsilon \\hat{n}_d + \\alpha \\hat{C}_2(O(5)) + \\beta \\hat{C}_2(O(3))$。能量本征值为 $E(n_d, \\tau, L) = \\epsilon n_d + \\alpha \\tau(\\tau+3) + \\beta L(L+1)$。现在能量依赖于标记我们基中每个态的唯一量子数三元组 $(n_d, \\tau, L)$。\n    -   共同 $(n_d, \\tau)$ 多重态内的简并现在被项 $\\beta L(L+1)$ 解除，因为这些多重态内的态具有不同的 $L$ 值。例如，对于 $(n_d, \\tau) = (2,2)$，具有 $L=2$ 和 $L=4$ 的态获得了不同的能量：$E(2,2,2) = 2\\epsilon+10\\alpha+6\\beta$ 和 $E(2,2,4) = 2\\epsilon+10\\alpha+20\\beta$。\n    -   对于通用的、非零的系数 $(\\epsilon, \\alpha, \\beta)$，具有不同 $(n_d, \\tau, L)$ 三元组的态之间将不会有“偶然”简并。11个态中的每一个都将具有唯一的能量。\n\n**诊断隐藏的对称性破缺**\n\n问题引入了一个带有附加项的哈密顿量：\n$$\nE(n_d,\\tau,L) = \\epsilon\\, n_d + \\alpha\\, \\tau(\\tau+3) + \\beta\\, L(L+1) + \\zeta\\, n_d\\,\\tau\n$$\n项 $\\zeta\\, n_d\\,\\tau$ 不是 $U(5) \\supset O(5) \\supset O(3)$ 链的 Casimir 算符本征值的线性组合。它的存在表明存在一个不能被简单 Casimir 形式的哈密顿量所捕获的对称性破缺源。\n\n为了诊断这一点，我们可以使用完整公式（其中 $\\zeta \\neq 0$）计算能量 $E$，然后尝试使用一个省略非 Casimir 项的模型来拟合这些能量：\n$$\nE_{\\text{fit}}(n_d,\\tau,L) = a\\, n_d + b\\, \\tau(\\tau+3) + c\\, L(L+1)\n$$\n这是一个线性最小二乘问题。我们寻求系数 $(a, b, c)$ 以最小化残差平方和 $\\sum_i (E_i - E_{\\text{fit},i})^2$。如果项 $\\zeta\\, n_d\\,\\tau$ 在基态集上与另外三项线性相关，则拟合将是完美的，残差将为零。然而，事实并非如此。残差向量的欧几里得范数 $||E - E_{\\text{fit}}||_2$ 的非零值，为 $\\zeta n_d \\tau$ 项引入的“隐藏”对称性破缺提供了一个定量度量。范数越大，表明偏离纯动力学对称结构的程度越大。\n\n这个解析框架为问题的数值部分提供了清晰、可检验的预测。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the computational nuclear physics problem about the U(5) limit of the IBM.\n    \"\"\"\n    \n    # Define the basis states (nd, tau, L) as per the problem statement.\n    # The set of states for nd=3, tau=3 includes L=2 as specified.\n    states = [\n        (0, 0, 0),  # nd=0\n        (1, 1, 2),  # nd=1\n        (2, 0, 0), (2, 2, 2), (2, 2, 4),  # nd=2\n        (3, 1, 2), (3, 3, 0), (3, 3, 2), (3, 3, 3), (3, 3, 4), (3, 3, 6)  # nd=3\n    ]\n\n    # Define the parameters for the four test cases.\n    test_cases = [\n        {'eps': 1.0, 'alpha': 0.0, 'beta': 0.0, 'zeta': 0.0},  # Case 1\n        {'eps': 1.0, 'alpha': 0.2, 'beta': 0.0, 'zeta': 0.0},  # Case 2\n        {'eps': 1.0, 'alpha': 0.2, 'beta': 0.1, 'zeta': 0.0},  # Case 3\n        {'eps': 1.0, 'alpha': 0.0, 'beta': 0.0, 'zeta': 0.05}  # Case 4\n    ]\n\n    results = []\n    tol = 1e-12\n\n    # --- Case 1: Pure U(5) number-operator Hamiltonian ---\n    params = test_cases[0]\n    energies_c1 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n    \n    degeneracy_nd_holds = True\n    # Group states by nd\n    states_by_nd = {}\n    for i, state in enumerate(states):\n        nd = state[0]\n        if nd not in states_by_nd:\n            states_by_nd[nd] = []\n        states_by_nd[nd].append(energies_c1[i])\n    \n    for nd in states_by_nd:\n        if len(states_by_nd[nd]) > 1:\n            group_energies = np.array(states_by_nd[nd])\n            if np.max(group_energies) - np.min(group_energies) > tol:\n                degeneracy_nd_holds = False\n                break\n    results.append(degeneracy_nd_holds)\n\n    # --- Case 2: O(5)-split without O(3) splitting ---\n    params = test_cases[1]\n    energies_c2 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n\n    degeneracy_nd_tau_holds = True\n    # Group states by (nd, tau)\n    states_by_nd_tau = {}\n    for i, state in enumerate(states):\n        key = (state[0], state[1]) # (nd, tau)\n        if key not in states_by_nd_tau:\n            states_by_nd_tau[key] = []\n        states_by_nd_tau[key].append(energies_c2[i])\n\n    for key in states_by_nd_tau:\n        if len(states_by_nd_tau[key]) > 1:\n            group_energies = np.array(states_by_nd_tau[key])\n            if np.max(group_energies) - np.min(group_energies) > tol:\n                degeneracy_nd_tau_holds = False\n                break\n    results.append(degeneracy_nd_tau_holds)\n\n    # --- Case 3: O(3)-split included ---\n    params = test_cases[2]\n    energies_c3 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n    \n    sorted_energies = np.sort(energies_c3)\n    diffs = np.diff(sorted_energies)\n    all_unique = np.all(diffs > tol)\n    results.append(all_unique)\n\n    # --- Case 4: Hidden symmetry-breaking diagnostic ---\n    params = test_cases[3]\n    energies_c4 = np.array([\n        params['eps'] * nd + \n        params['alpha'] * tau * (tau + 3) + \n        params['beta'] * L * (L + 1) + \n        params['zeta'] * nd * tau \n        for nd, tau, L in states\n    ])\n\n    # Construct the matrix A for the least-squares fit\n    # The columns are nd, tau*(tau+3), and L*(L+1)\n    A = np.zeros((len(states), 3))\n    for i, (nd, tau, L) in enumerate(states):\n        A[i, 0] = nd\n        A[i, 1] = tau * (tau + 3)\n        A[i, 2] = L * (L + 1)\n\n    # Perform the least-squares fit: Ax = y\n    # y is the vector of energies_c4\n    y = energies_c4\n    _, residuals, _, _ = np.linalg.lstsq(A, y, rcond=None)\n    \n    # The problem asks for the Euclidean norm of the residual vector\n    # lstsq returns the sum of squared residuals. We need its square root.\n    residual_norm = np.sqrt(residuals[0])\n    results.append(residual_norm)\n\n    # Print results in the specified single-line format\n    print(f\"[{results[0]},{results[1]},{results[2]},{results[3]}]\")\n\nsolve()\n```", "id": "3556532"}, {"introduction": "这最后一个练习将 $\\mathrm{U}(5)$、$\\mathrm{SU}(3)$ 和 $\\mathrm{O}(6)$ 极限的理论模型与解释真实世界实验数据的实际挑战联系起来。学生将开发一个计算工具——一个简单的分类器——它能从能量和跃迁概率比率中学习每种对称性的特征“指纹”。这项任务涉及训练分类器，并测试其在面对嘈杂或不完整数据时识别正确对称性区域的能力，模拟了实验核物理学家所面临的挑战 [@problem_id:3556636]。", "problem": "您的任务是构建、训练和评估一个分类器，该分类器能够根据有限的光谱和四极跃迁指纹信息，识别相互作用玻色子模型 (IBM) 的动力学对称性体系。这三种体系分别是幺正群极限 $U(5)$（振动）、特殊幺正群极限 $SU(3)$（转动）和正交群极限 $O(6)$（$\\gamma$-软）。目标是完全根据数学上定义的特征和一个对特征向量中的加性噪声和缺失条目具有鲁棒性的概率分类规则来构建此问题。\n\n此问题的根本基础是相互作用玻色子模型 (IBM) 公认的极限行为。在 $U(5)$ 振动极限下，激发态由 $d$-玻色子数 $n_d$ 表征，并遵循能量模式 $E \\propto n_d$。在 $SU(3)$ 转动极限下，能级遵循刚性转子关系 $E(I) \\propto I(I+1)$，其中 $I$ 是角动量。在 $O(6)$ $\\gamma$-软极限下，相关的量子数是 $\\tau$，能量模式为 $E(\\tau) \\propto \\tau(\\tau+3)$，基带中允许的角动量为 $L = 2\\tau$。这些经过充分检验的公式意味着低位激发能存在特征比率，即比率 $R_{42} \\equiv E(4^+_1)/E(2^+_1)$ 和 $R_{62} \\equiv E(6^+_1)/E(2^+_1)$：\n- $U(5)$: $R_{42} = 2.0$, $R_{62} = 3.0$，源于 $E \\propto n_d$，其中 $E(2^+_1)$、$E(4^+_1)$ 和 $E(6^+_1)$ 对应于 $n_d = 1,2,3$。\n- $SU(3)$: $R_{42} = 20/6 \\approx 3.333\\ldots$, $R_{62} = 42/6 = 7.0$，源于 $E(I) \\propto I(I+1)$，其中 $I=2,4,6$。\n- $O(6)$: $R_{42} = 10/4 = 2.5$, $R_{62} = 18/4 = 4.5$，源于 $E(\\tau) \\propto \\tau(\\tau+3)$，其中对于 $L=2,4,6$，$ \\tau=1,2,3$。\n\n此外，约化电四极跃迁几率 $B(E2)$ 也遵循特征极限比率。在相互作用玻色子模型中，电四极算符为 $T(E2)=e_B\\,Q$，其中 $Q$ 是四极算符；选择定则和群论约化决定了带内比率。对于一个 $K=0$ 转子（$SU(3)$ 极限），Alaga 规则给出了代表性比率 $B_{42}/B_{20} = 10/7 \\approx 1.429$ 和 $B_{64}/B_{20} = 18/7 \\approx 2.571$，分别对应于跃迁 $4^+_1 \\rightarrow 2^+_1$、$6^+_1 \\rightarrow 4^+_1$ 和 $2^+_1 \\rightarrow 0^+_1$。对于 $U(5)$ 谐振子，典型比率约为 $B_{42}/B_{20} \\approx 2.0$ 和 $B_{64}/B_{20} \\approx 3.0$，这反映了 $\\Delta n_d = \\pm 1$ 的阶梯结构。$O(6)$ $\\gamma$-软极限产生的比率介于两者之间；为了本分类任务的目的，我们采用 $B_{42}/B_{20} \\approx 1.6$ 和 $B_{64}/B_{20} \\approx 2.4$ 作为大玻色子数下的代表性指纹。\n\n将特征向量定义为四维向量\n$$\n\\mathbf{x} = \\big[ R_{42},\\; R_{62},\\; B_{42}/B_{20},\\; B_{64}/B_{20} \\big].\n$$\n您的程序必须：\n1. 为每个体系生成一个合成训练数据集，方法是从一个以体系指纹均值为中心、具有对角协方差的多元正态分布中采样 $\\mathbf{x}$，以反映有限玻色子数展宽和典型实验变异性。对每个类别使用相同的样本量和相同的类别先验。\n2. 训练一个对角协方差高斯分类器。对于类别 $c$，从合成训练数据中估计均值 $\\boldsymbol{\\mu}_c$ 和对角方差 $\\boldsymbol{\\sigma}^2_c$。对于一个部分分量缺失的测试特征向量 $\\mathbf{x}$，分类器必须仅使用观测到的分量来计算类条件对数似然。如果观测分量的集合为空，决策必须简化为先验比较。\n3. 在一个包含干净数据、含噪数据和不完整数据的测试用例集上评估分类器。噪声必须建模为应用于测试向量每个非缺失分量的加性高斯噪声，且每个测试用例具有指定的标准差。\n\n不需要物理单位，因为所有特征都是无量纲的比率。\n\n用于分类的概率规则是选择使下式最大化的类别 $c$：\n$$\n\\log p(c) + \\sum_{i \\in \\mathcal{O}(\\mathbf{x})} \\left( -\\frac{1}{2}\\log(2\\pi \\sigma_{c,i}^2) - \\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2} \\right),\n$$\n其中 $\\mathcal{O}(\\mathbf{x})$ 是观测到的（非缺失）分量的索引集，$p(c)$ 是类别 $c$ 的先验概率，$\\mu_{c,i}$ 是类别 $c$ 的特征 $i$ 的均值，而 $\\sigma_{c,i}^2$ 是类别 $c$ 的特征 $i$ 的方差。\n\n用于采样的训练分布参数（为保证真实性和类别可分性）：\n- $U(5)$ 均值 $\\boldsymbol{\\mu}_{U5} = [2.0,\\; 3.0,\\; 2.0,\\; 3.0]$，标准差 $\\boldsymbol{\\sigma}_{U5} = [0.04,\\; 0.06,\\; 0.20,\\; 0.30]$。\n- $SU(3)$ 均值 $\\boldsymbol{\\mu}_{SU3} = [3.3333333333,\\; 7.0,\\; 1.429,\\; 2.571]$，标准差 $\\boldsymbol{\\sigma}_{SU3} = [0.03,\\; 0.05,\\; 0.10,\\; 0.12]$。\n- $O(6)$ 均值 $\\boldsymbol{\\mu}_{O6} = [2.5,\\; 4.5,\\; 1.6,\\; 2.4]$，标准差 $\\boldsymbol{\\sigma}_{O6} = [0.05,\\; 0.08,\\; 0.18,\\; 0.25]$。\n\n每个类别使用相同数量的训练样本，并使用相等的先验概率 $p(U(5))=p(SU(3))=p(O(6))$。\n\n测试集。程序必须对以下七个测试用例进行分类。每个测试用例包含一个特征向量 $\\mathbf{x}$、一个噪声标准差 $\\sigma_{\\text{noise}}$ 和一个指示哪些条目缺失（在分类中应被忽略）的缺失模式。噪声必须独立地添加到每个非缺失特征上。在代码中用“非数字” (not-a-number) 标记来表示缺失条目。七个测试用例如下：\n1. 干净的类 $U(5)$ 用例: $\\mathbf{x} = [2.0,\\; 3.0,\\; 2.0,\\; 3.0]$，$\\sigma_{\\text{noise}} = 0.02$，无缺失条目。\n2. 干净的类 $SU(3)$ 用例: $\\mathbf{x} = [3.3333333333,\\; 7.0,\\; 1.429,\\; 2.571]$，$\\sigma_{\\text{noise}} = 0.02$，无缺失条目。\n3. 干净的类 $O(6)$ 用例: $\\mathbf{x} = [2.5,\\; 4.5,\\; 1.6,\\; 2.4]$，$\\sigma_{\\text{noise}} = 0.02$，无缺失条目。\n4. 含噪的 $O(6)$ 边界用例: $\\mathbf{x} = [2.4,\\; 4.4,\\; 1.55,\\; 2.35]$，$\\sigma_{\\text{noise}} = 0.20$，无缺失条目。\n5. 不完整的仅含能量信息的 $SU(3)$ 用例: $\\mathbf{x} = [3.32,\\; 7.01,\\; \\mathrm{缺失},\\; \\mathrm{缺失}]$，$\\sigma_{\\text{noise}} = 0.05$。\n6. 不完整的单特征 $U(5)$ 用例: $\\mathbf{x} = [2.02,\\; \\mathrm{缺失},\\; \\mathrm{缺失},\\; \\mathrm{缺失}]$，$\\sigma_{\\text{noise}} = 0.01$。\n7. 矛盾混合用例（能量为转动型，$B(E2)$ 为振动型）: $\\mathbf{x} = [3.33,\\; 6.99,\\; 2.0,\\; 3.0]$，$\\sigma_{\\text{noise}} = 0.03$，无缺失条目。\n\n类别标签必须按如下方式映射到整数：$U(5) \\mapsto 0$, $SU(3) \\mapsto 1$, $O(6) \\mapsto 2$。\n\n您的程序应产生单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，例如 $[r_1, r_2, \\dots, r_7]$，其中每个 $r_k$ 是测试用例 $k$ 的预测类别标签，为 $\\{0,1,2\\}$ 中的一个整数。\n\n所有计算都是无量纲的；此任务中不需要物理单位或角度。", "solution": "所提出的问题是一项应用于核结构物理学的计算模式识别任务，具体而言，是对相互作用玻色子模型 (IBM) 内的动力学对称性进行分类。该问题在科学上是合理的、定义明确的，并且所有必要的参数和过程都已明确定义。因此，该问题被认为是有效的，可以制定解决方案。\n\n问题的核心是设计一个分类器，对于给定的特征向量 $\\mathbf{x} \\in \\mathbb{R}^4$，能将其分配到三个类别 $c$ 中的一个，这些类别分别对应于动力学对称性 $U(5)$、$SU(3)$ 和 $O(6)$。特征向量 $\\mathbf{x}$ 由四个无量纲的核观测量比率组成：\n$$\n\\mathbf{x} = \\big[ R_{42},\\; R_{62},\\; B_{42}/B_{20},\\; B_{64}/B_{20} \\big]\n$$\n其中 $R_{I'I} \\equiv E(I'_1)/E(I_1)$ 是基态带激发能的比率，而 $B_{I'I}/B_{J'J}$ 是约化电四极 ($E2$) 跃迁几率的比率。\n\n所选择的分类框架是朴素贝叶斯分类器。我们旨在找到使后验概率 $p(c|\\mathbf{x})$ 最大化的类别 $c$。根据贝叶斯定理，这等同于最大化似然 $p(\\mathbf{x}|c)$ 和先验 $p(c)$ 的乘积：\n$$\n\\hat{c} = \\underset{c}{\\arg\\max} \\, p(\\mathbf{x}|c) \\, p(c)\n$$\n为了计算上的稳定性和便利性，我们处理该数量的对数，即对数后验概率：\n$$\n\\hat{c} = \\underset{c}{\\arg\\max} \\, \\left( \\log p(\\mathbf{x}|c) + \\log p(c) \\right)\n$$\n问题指定所有三个类别的先验概率相等，即 $p(U(5)) = p(SU(3)) = p(O(6)) = 1/3$。因此，$\\log p(c)$ 项相对于 $c$ 是一个常数，在最大化过程中可以忽略，问题简化为最大化对数似然 $\\log p(\\mathbf{x}|c)$。\n\n类条件似然 $p(\\mathbf{x}|c)$ 的模型是一个多元高斯分布。朴素贝叶斯分类器中的“朴素”一词对应于这样一个假设：给定类别，特征之间是条件独立的。这意味着高斯分布的协方差矩阵是对角的。因此，似然是每个特征 $x_i$ 的单个高斯概率的乘积：\n$$\np(\\mathbf{x}|c) = \\prod_{i=1}^{4} p(x_i | c) = \\prod_{i=1}^{4} \\frac{1}{\\sqrt{2\\pi \\sigma_{c,i}^2}} \\exp\\left(-\\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2}\\right)\n$$\n其中 $\\mu_{c,i}$ 和 $\\sigma_{c,i}^2$ 分别是类别 $c$ 的特征 $i$ 的均值和方差。\n\n对于一个完整的特征向量 $\\mathbf{x}$，相应的总对数似然为：\n$$\n\\log p(\\mathbf{x}|c) = \\sum_{i=1}^{4} \\left( -\\frac{1}{2}\\log(2\\pi \\sigma_{c,i}^2) - \\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2} \\right)\n$$\n该问题的一个基本要求是稳健地处理缺失的特征值。在这个框架内可以很自然地实现这一点。如果特征向量 $\\mathbf{x}$ 的一个分量 $x_i$ 缺失，其对对数似然和的贡献就被简单地省略。求和仅对观测到的分量集合（表示为 $\\mathcal{O}(\\mathbf{x})$）进行。那么分类规则就是选择使以下分数最大化的类别 $c$：\n$$\nS_c(\\mathbf{x}) = \\log p(c) + \\sum_{i \\in \\mathcal{O}(\\mathbf{x})} \\left( -\\frac{1}{2}\\log(2\\pi \\sigma_{c,i}^2) - \\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2} \\right)\n$$\n这正是问题陈述中提供的公式。\n\n分类器必须首先被训练。训练阶段涉及从训练数据集中估计模型参数——均值 $\\mu_{c,i}$ 和方差 $\\sigma_{c,i}^2$。问题指定该数据集是通过从多元正态分布中为每个类别抽取样本来合成生成的，这些分布的总体均值 $\\boldsymbol{\\mu}_c$ 和标准差 $\\boldsymbol{\\sigma}_c$ 在陈述中已提供。对于高斯分布，均值和方差的最大似然估计 (MLE) 是样本均值和（有偏）样本方差。我们将使用与之密切相关且标准的无偏样本估计量：\n$$\n\\hat{\\mu}_{c,i} = \\frac{1}{N_c} \\sum_{j=1}^{N_c} x_{j,i}^{(c)}\n$$\n$$\n\\hat{\\sigma}_{c,i}^2 = \\frac{1}{N_c-1} \\sum_{j=1}^{N_c} \\left(x_{j,i}^{(c)} - \\hat{\\mu}_{c,i}\\right)^2\n$$\n其中 $N_c$ 是类别 $c$ 的训练样本数，而 $x_{j,i}^{(c)}$ 是该类别第 $j$ 个样本的第 $i$ 个特征。将使用大量的合成样本（$N_c \\approx 10^5$），以确保估计的参数 $\\hat{\\boldsymbol{\\mu}}_c$ 和 $\\hat{\\boldsymbol{\\sigma}}_c^2$ 具有统计鲁棒性，并且是问题中给出的真实分布参数的非常接近的近似值。\n\n实现过程如下：\n1.  **参数定义**：定义三个对称性类别的理想均值和标准差，以及测试用例的规格。\n2.  **训练**：对于每个类别（$U(5)$, $SU(3)$, $O(6)$），通过从具有指定均值和标准差的正态分布中为四个特征中的每一个抽取随机样本，生成一个大型训练数据集（$N_c = 100,000$）。从该数据集中，计算样本均值和方差，并将其存储为分类器的参数。\n3.  **分类**：一个函数实现分类规则。它以测试向量 $\\mathbf{x}$ 作为输入。在分类之前，将具有测试用例特定标准差 $\\sigma_{\\text{noise}}$ 的加性高斯噪声应用于 $\\mathbf{x}$ 的每个非缺失分量。然后，该函数使用训练好的参数计算每个类别的分数 $S_c(\\mathbf{x})$，并通过仅对观测到的特征求和来处理缺失值（表示为 `np.nan`）。得分最高的类别被选为预测标签。\n4.  **评估**：将此过程应用于提供的七个测试用例中的每一个。使用固定的随机种子以确保噪声生成是确定性的，从而产生可复现的结果。最终的整数类别标签（$0$ 代表 $U(5)$，$1$ 代表 $SU(3)$，$2$ 代表 $O(6)$）被收集并格式化为所需的输出字符串。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Builds, trains, and evaluates a Gaussian Naive Bayes classifier for\n    IBM dynamical symmetries.\n    \"\"\"\n    \n    # Use a fixed random seed for reproducibility of training data and test noise\n    rng = np.random.default_rng(seed=0)\n\n    # 1. Define problem parameters\n    \n    # Class mapping\n    CLASS_LABELS = {'U(5)': 0, 'SU(3)': 1, 'O(6)': 2}\n    CLASS_NAMES = {v: k for k, v in CLASS_LABELS.items()}\n    \n    # Training distribution parameters (means and standard deviations)\n    # These are the \"true\" parameters of the underlying physical models.\n    true_params = {\n        CLASS_LABELS['U(5)']: {\n            'mean': np.array([2.0, 3.0, 2.0, 3.0]),\n            'std_dev': np.array([0.04, 0.06, 0.20, 0.30])\n        },\n        CLASS_LABELS['SU(3)']: {\n            'mean': np.array([3.3333333333, 7.0, 1.429, 2.571]),\n            'std_dev': np.array([0.03, 0.05, 0.10, 0.12])\n        },\n        CLASS_LABELS['O(6)']: {\n            'mean': np.array([2.5, 4.5, 1.6, 2.4]),\n            'std_dev': np.array([0.05, 0.08, 0.18, 0.25])\n        }\n    }\n    \n    n_classes = len(CLASS_LABELS)\n    n_features = len(true_params[0]['mean'])\n    \n    # Use equal priors as specified\n    log_priors = np.log([1.0 / n_classes] * n_classes)\n\n    # 2. Train the classifier on synthetic data\n    \n    N_train_per_class = 100000  # Number of synthetic samples per class for training\n    \n    # These will store the parameters estimated from the training data.\n    trained_params = {\n        'means': np.zeros((n_classes, n_features)),\n        'variances': np.zeros((n_classes, n_features))\n    }\n\n    for c in range(n_classes):\n        # Generate synthetic training data\n        means = true_params[c]['mean']\n        stds = true_params[c]['std_dev']\n        \n        # Draw samples for each feature independently\n        training_data = rng.normal(loc=means, scale=stds, size=(N_train_per_class, n_features))\n        \n        # Estimate parameters (mean and variance) from the data\n        # Using unbiased variance estimator with ddof=1\n        trained_params['means'][c, :] = np.mean(training_data, axis=0)\n        trained_params['variances'][c, :] = np.var(training_data, axis=0, ddof=1)\n\n    # 3. Define the classifier function\n    \n    def classify(x_test):\n        \"\"\"\n        Classifies a single feature vector x_test using the trained model.\n        \n        Args:\n            x_test (np.ndarray): A 1D numpy array of features. May contain np.nan.\n\n        Returns:\n            int: The predicted class label (0, 1, or 2).\n        \"\"\"\n        log_posteriors = np.copy(log_priors)\n        \n        for c in range(n_classes):\n            log_likelihood = 0.0\n            \n            for i in range(n_features):\n                # Skip missing features\n                if np.isnan(x_test[i]):\n                    continue\n                \n                # Get trained parameters for this class and feature\n                mu = trained_params['means'][c, i]\n                var = trained_params['variances'][c, i]\n\n                # Calculate log of the Gaussian PDF\n                # log(p(x|c)) = -0.5*log(2*pi*var) - (x-mu)^2 / (2*var)\n                logp_xi_c = -0.5 * np.log(2 * np.pi * var) - ((x_test[i] - mu)**2) / (2 * var)\n                log_likelihood += logp_xi_c\n            \n            log_posteriors[c] += log_likelihood\n            \n        return np.argmax(log_posteriors)\n\n    # 4. Evaluate the classifier on the test suite\n    \n    # Define test cases: (feature_vector, noise_std_dev)\n    # Use np.nan for missing entries\n    test_cases = [\n        (np.array([2.0, 3.0, 2.0, 3.0]), 0.02),\n        (np.array([3.3333333333, 7.0, 1.429, 2.571]), 0.02),\n        (np.array([2.5, 4.5, 1.6, 2.4]), 0.02),\n        (np.array([2.4, 4.4, 1.55, 2.35]), 0.20),\n        (np.array([3.32, 7.01, np.nan, np.nan]), 0.05),\n        (np.array([2.02, np.nan, np.nan, np.nan]), 0.01),\n        (np.array([3.33, 6.99, 2.0, 3.0]), 0.03)\n    ]\n\n    results = []\n    for x_base, noise_std in test_cases:\n        # Create a copy to add noise to\n        x_noisy = np.copy(x_base)\n        \n        # Add independent Gaussian noise to each non-missing feature\n        for i in range(n_features):\n            if not np.isnan(x_noisy[i]):\n                noise = rng.normal(loc=0.0, scale=noise_std)\n                x_noisy[i] += noise\n        \n        # Classify the noisy vector and store the result\n        prediction = classify(x_noisy)\n        results.append(prediction)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3556636"}]}