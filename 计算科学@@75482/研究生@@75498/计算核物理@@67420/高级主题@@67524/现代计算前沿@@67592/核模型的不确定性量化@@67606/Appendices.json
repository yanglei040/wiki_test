{"hands_on_practices": [{"introduction": "复杂的核模型计算成本可能高得令人望而却步，使得大规模不确定性分析变得不切实际。一个强大的解决方案是构建一个“代理模型”（surrogate model）或“模拟器”（emulator）——即对完整模型的快速、解析近似。本实践将指导您构建一种最常见的代理模型，即多项式混沌展开（Polynomial Chaos Expansion, PCE），用以表示一个简化的核模型输出与其不确定参数之间的函数关系，这是高效传播参数不确定性的基础技能 [@problem_id:3610367]。", "problem": "构建一个完整、可运行的程序，该程序为一个作为不确定参数函数的核模型可观测量建立多项式混沌展开（PCE），并通过相对于先验测度的投影来计算展开系数。其背景是计算核物理中的不确定性量化。从基本定义开始：PCE 将一个平方可积的随机可观测量表示为关于其先验概率测度的正交多项式基上的展开，其系数通过使用由该测度诱导的内积进行投影得到。假设不确定参数具有独立的先验，每个先验的支撑集为一个闭区间，并对每个参数使用与均匀概率测度相关的正交多项式族。在多维情况下，使用张量积基并按总阶数进行截断。一致地，将参数视为其支撑区间上的随机变量，并构造一个多维乘积测度。通过在典范区间上使用张量积高斯求积（GQ）对所需投影进行数值近似来实现系数计算。下面给出的可观测量定义是半经验质量公式在物理上合理的简化形式，并针对固定的原子核进行表达。所有表示可观测量或其 PCE 系数的输出都必须以兆电子伏特（MeV）为单位。\n\n通过以下从不确定参数到可观测量的确定性映射来定义一个固定原子核的可观测量：\n- 情况定义使用了标准的半经验质量模型分量：体积能系数、表面能系数和库仑能系数，分别表示为 $a_v$、$a_s$ 和 $a_c$。设 $A$ 为质量数，$Z$ 为质子数。考虑简化的结合能可观测量 $B$，单位为兆电子伏特 (MeV)，由 $B(a_v,a_s,a_c;A,Z) = a_v A - a_s A^{2/3} - a_c Z^2 A^{-1/3}$ 给出，当较少的系数被建模为不确定时，使用其简化形式。\n\n建模和基的假设：\n- 将每个不确定参数视为在其指定区间上独立均匀分布，并对每个参数使用与此均匀概率测度相关的正交多项式基。使用多维张量积基的总阶数截断，即保留所有其分量阶数之和小于或等于指定最大阶数的多重指标。\n- 通过在典范区间上使用张量积高斯求积实现数值投影积分，并应用从参数支撑集到典范区间的适当线性映射。每个维度选择足够数量的求积节点，以积分可观测量和基函数的乘积直至所需的多项式阶数而无混叠。实现必须确保与正交基和先验概率测度一致的正确归一化。\n\n测试套件规范和要求的输出：\n对于每个测试用例，计算并输出 PCE 系数的完整列表，系数按总阶数递增排序，在每个总阶数内，按多重指标的字典序（第一个分量变化最慢）排序。系数必须以 MeV 为单位，作为浮点数报告。\n\n- 测试用例 $1$：一维，固定原子核，质量数 $A=56$，无库仑项。可观测量 $B(a_v;A)=a_v A$。$a_v$ 的先验分布：在 $[14.5,16.5]$ 上均匀分布。最大总阶数 $p=3$。\n\n- 测试用例 $2$：二维，固定原子核，质量数 $A=100$，无库仑项。可观测量 $B(a_v,a_s;A) = a_v A - a_s A^{2/3}$。先验分布：$a_v$ 在 $[14.0,16.0]$ 上均匀分布，$a_s$ 在 $[16.0,18.0]$ 上均匀分布。最大总阶数 $p=2$。\n\n- 测试用例 $3$：三维，固定原子核，质量数 $A=208$，质子数 $Z=82$。可观测量 $B(a_v,a_s,a_c;A,Z) = a_v A - a_s A^{2/3} - a_c Z^2 A^{-1/3}$。先验分布：$a_v$ 在 $[14.0,16.0]$ 上均匀分布，$a_s$ 在 $[16.0,18.0]$ 上均匀分布，$a_c$ 在 $[0.6,0.8]$ 上均匀分布。最大总阶数 $p=2$。\n\n- 测试用例 $4$：用于测试三维情况下常数项投影的边界情况。可观测量和先验分布与测试用例 $3$ 相同，最大总阶数 $p=0$。\n\n输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身也是一个用方括号括起来的逗号分隔列表。例如，如果有 $4$ 个测试用例，最终输出必须看起来像 $[[c_{1,1},c_{1,2},\\dots],[c_{2,1},\\dots],[c_{3,1},\\dots],[c_{4,1},\\dots]]$，不含任何空格。每个 $c_{i,j}$ 是一个以 MeV 为单位的浮点数。\n\n角度单位不适用。所有数值输出均以兆电子伏特（MeV）为单位。", "solution": "任务是为一个简化的核结合能可观测量构建一个多项式混沌展开（PCE），并通过投影计算其展开系数。该问题定义明确，在不确定性量化和核物理学方面有科学依据，并为其解决方案提供了完整的规范。我们首先建立数学框架，然后详细说明数值实现。\n\n### 1. 数学公式化\n\n一个平方可积的随机可观测量 $M(\\mathbf{x})$，它是一个 $d$ 维独立随机参数矢量 $\\mathbf{x} = (x_1, \\dots, x_d)$ 的函数，可以通过多项式混沌展开来表示。假设每个参数 $x_i$ 在已知区间 $[a_i, b_i]$ 上均匀分布，即 $x_i \\sim U(a_i, b_i)$。\n\n为了使用一套标准的多项式基，我们将每个物理参数 $x_i$ 转换为一个在区间 $[-1, 1]$ 上均匀分布的典范随机变量 $\\xi_i$。其对应的概率密度函数为 $\\rho(\\xi_i) = 1/2$，其中 $\\xi_i \\in [-1, 1]$。该仿射变换为：\n$$x_i(\\xi_i) = \\frac{b_i-a_i}{2} \\xi_i + \\frac{a_i+b_i}{2}$$\n现在，可观测量 $M(\\mathbf{x})$ 可以表示为典范变量的函数，即 $\\tilde{M}(\\boldsymbol{\\xi}) = M(\\mathbf{x}(\\boldsymbol{\\xi}))$。\n\n对于在 $[-1, 1]$ 上均匀分布的随机变量，其正交多项式基由缩放后的 Legendre 多项式组成。标准的 Legendre 多项式 $P_k(\\xi)$ 在 $[-1, 1]$ 上关于标准权重函数 $w(\\xi)=1$ 是正交的：$\\int_{-1}^1 P_k(\\xi) P_j(\\xi) d\\xi = \\frac{2}{2k+1}\\delta_{kj}$。\n由我们的概率测度 $\\rho(\\xi)d\\xi$ 诱导的内积为 $\\langle f, g \\rangle = \\int_{-1}^1 f(\\xi) g(\\xi) \\frac{1}{2} d\\xi$。正确归一化的基多项式 $\\Psi_k(\\xi)$ 必须满足 $\\langle \\Psi_k, \\Psi_j \\rangle = \\delta_{kj}$。设 $\\Psi_k(\\xi) = c_k P_k(\\xi)$，我们发现：\n$$\\langle \\Psi_k, \\Psi_j \\rangle = c_k c_j \\int_{-1}^1 P_k(\\xi) P_j(\\xi) \\frac{1}{2} d\\xi = \\frac{c_k c_j}{2} \\frac{2}{2k+1} \\delta_{kj} = \\frac{c_k^2}{2k+1} \\delta_{kj}$$\n为使其等于 $\\delta_{kj}$，我们需要 $c_k = \\sqrt{2k+1}$。因此，一维正交基函数为：\n$$\\Psi_k(\\xi) = \\sqrt{2k+1} P_k(\\xi)$$\n\n对于具有独立参数的 $d$ 维情况，基是由一维基的张量积构成的。一个基函数由一个多重指标 $\\boldsymbol{\\alpha} = (\\alpha_1, \\dots, \\alpha_d) \\in \\mathbb{N}_0^d$ 索引：\n$$\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) = \\prod_{i=1}^d \\Psi_{\\alpha_i}(\\xi_i) = \\prod_{i=1}^d \\sqrt{2\\alpha_i+1} P_{\\alpha_i}(\\xi_i)$$\nPCE 使用总阶数方案进行截断，保留所有其分量阶数之和不超过最大总阶数 $p$ 的基函数：$|\\boldsymbol{\\alpha}| = \\sum_{i=1}^d \\alpha_i \\le p$。可观测量的截断 PCE 为：\n$$\\tilde{M}(\\boldsymbol{\\xi}) \\approx \\sum_{|\\boldsymbol{\\alpha}| \\le p} c_{\\boldsymbol{\\alpha}} \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$$\n\n系数 $c_{\\boldsymbol{\\alpha}}$ 是通过在超立方体 $[-1, 1]^d$ 上，使用由联合概率测度 $\\rho(\\boldsymbol{\\xi})d\\boldsymbol{\\xi} = (1/2)^d d\\boldsymbol{\\xi}$ 诱导的内积，将可观测量投影到每个基函数上得到的：\n$$c_{\\boldsymbol{\\alpha}} = \\langle \\tilde{M}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle = \\int_{[-1, 1]^d} \\tilde{M}(\\boldsymbol{\\xi}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) \\rho(\\boldsymbol{\\xi}) d\\boldsymbol{\\xi} = \\left(\\frac{1}{2}\\right)^d \\int_{[-1, 1]^d} \\tilde{M}(\\boldsymbol{\\xi}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) d\\boldsymbol{\\xi}$$\n\n### 2. 数值实现\n\n$c_{\\boldsymbol{\\alpha}}$ 的多维积分是使用张量积高斯求积 (GQ) 法则进行数值计算的。具体来说，我们使用 Gauss-Legendre 求积。一维 $N_q$ 点 Gauss-Legendre 法则将积分近似为 $\\int_{-1}^1 f(\\xi) d\\xi \\approx \\sum_{j=1}^{N_q} f(\\xi_j) w_j$，其中 $\\xi_j$ 是求积节点，$w_j$ 是相应的权重。$d$ 维的张量积法则是：\n$$\\int_{[-1, 1]^d} g(\\boldsymbol{\\xi}) d\\boldsymbol{\\xi} \\approx \\sum_{j_1=1}^{N_q} \\dots \\sum_{j_d=1}^{N_q} g(\\xi_{j_1}, \\dots, \\xi_{j_d}) \\prod_{k=1}^d w_{j_k}$$\n将此应用于系数积分，我们得到：\n$$c_{\\boldsymbol{\\alpha}} \\approx \\left(\\frac{1}{2}\\right)^d \\sum_{j_1, \\dots, j_d} \\tilde{M}(\\xi_{j_1}, \\dots, \\xi_{j_d}) \\Psi_{\\boldsymbol{\\alpha}}(\\xi_{j_1}, \\dots, \\xi_{j_d}) \\prod_{k=1}^d w_{j_k}$$\n\n为确保精度，求积点数 $N_q$ 必须选择得足够大，以便能精确地积分多项式被积函数 $\\tilde{M}(\\boldsymbol{\\xi}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$。可观测量 $B$ 是其参数 $(a_v, a_s, a_c)$ 的线性函数。由于从 $\\xi_i$ 到 $x_i$ 的映射是线性的，$\\tilde{M}(\\boldsymbol{\\xi})$ 是 $\\boldsymbol{\\xi}$ 中总阶数为 1 的多项式。基函数 $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$ 是总阶数为 $|\\boldsymbol{\\alpha}|$ 的多项式。在任何单维度 $i$ 中，被积函数的最高阶数为 $1 + \\alpha_i$。由于总阶数为 $p$ 的展开中任何 $\\alpha_i$ 的最大值为 $p$，因此在任何一个维度中需要积分的最高多项式阶数为 $1+p$。一个 $N_q$ 点的 Gauss-Legendre 法则可以精确积分最高 $2N_q - 1$ 阶的多项式。因此，我们需要 $2N_q - 1 \\ge p + 1$，简化后为 $N_q \\ge (p+2)/2$。为保证稳健性，我们选择 $N_q = p+1$，这对所有非负的 $p$ 都满足此条件。\n\n总体算法如下：\n1.  对于每个测试用例（维度 $d$、最大阶数 $p$、可观测量 $M$ 和先验分布）：\n2.  生成多重指标集 $\\boldsymbol{\\alpha}$，使得 $|\\boldsymbol{\\alpha}| \\le p$。首先按总阶数 $|\\boldsymbol{\\alpha}|$ 对这些指标排序，然后按字典序排序。\n3.  设置每个维度的求积点数，$N_q = p + 1$。\n4.  获取 $N_q$ 个一维 Gauss-Legendre 节点和权重。\n5.  构建 $d$ 维求积节点网格 $\\boldsymbol{\\xi}^{(j)}$ 和相应的乘积权重 $W^{(j)}$。\n6.  对于网格上的每个节点 $\\boldsymbol{\\xi}^{(j)}$，将其变换到物理参数空间 $\\mathbf{x}^{(j)}$。\n7.  在每个物理网格点上评估模型可观测量 $M(\\mathbf{x}^{(j)})$，以获得模型值的网格。\n8.  对于已排序列表中的每个多重指标 $\\boldsymbol{\\alpha}$：\n    a. 在每个典范网格节点上评估基函数 $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}^{(j)})$。\n    b. 通过对模型值网格和基函数值网格进行逐元素相乘来计算被积函数。\n    c. 通过将被积函数展平后的网格与乘积权重展平后的网格做点积来近似积分。\n    d. 通过将积分结果乘以 $(0.5)^d$ 来计算系数 $c_{\\boldsymbol{\\alpha}}$。\n9.  收集每个测试用例计算出的系数，并按规定格式化输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import legendre, roots_legendre\nimport itertools\n\ndef solve():\n    \"\"\"\n    Computes Polynomial Chaos Expansion coefficients for a simplified nuclear binding energy model.\n    \"\"\"\n\n    def generate_multi_indices(dim, max_degree):\n        \"\"\"\n        Generates multi-indices for a given dimension and maximum total degree.\n        The indices are sorted by total degree, then lexicographically.\n        \"\"\"\n        if dim == 0:\n            if max_degree >= 0:\n                return [()]\n            else:\n                return []\n        \n        if dim == 1:\n            return [(i,) for i in range(max_degree + 1)]\n\n        indices = []\n        for i in range(max_degree + 1):\n            sub_indices = generate_multi_indices(dim - 1, max_degree - i)\n            for sub_index in sub_indices:\n                indices.append((i,) + sub_index)\n        \n        # Sort by total degree, then lexicographically\n        indices.sort(key=lambda idx: (sum(idx), idx))\n        return indices\n\n    def compute_pce_coefficients(model_func, priors, dim, max_degree):\n        \"\"\"\n        Computes the PCE coefficients for a given model, priors, dimension, and max degree.\n        \"\"\"\n        # Step 1: Generate multi-indices\n        multi_indices = generate_multi_indices(dim, max_degree)\n\n        # Step 2: Determine quadrature rule\n        num_quad_points = max_degree + 1\n        nodes_1d, weights_1d = roots_legendre(num_quad_points)\n\n        # Step 3: Construct multi-dimensional quadrature grid\n        # 'ij' indexing creates grids that can be stacked correctly for our purpose.\n        xi_grids = np.meshgrid(*([nodes_1d] * dim), indexing='ij')\n        w_grids = np.meshgrid(*([weights_1d] * dim), indexing='ij')\n\n        # Create a single grid of product weights\n        product_weights_grid = np.prod(np.stack(w_grids, axis=-1), axis=-1)\n\n        # Step 4: Transform canonical nodes to physical parameter space\n        centers = np.array([(p[0] + p[1]) / 2.0 for p in priors])\n        half_widths = np.array([(p[1] - p[0]) / 2.0 for p in priors])\n        \n        physical_params_grid = []\n        for i in range(dim):\n             physical_params_grid.append(centers[i] + half_widths[i] * xi_grids[i])\n\n        # Step 5: Evaluate the model on the grid\n        model_values_grid = model_func(*physical_params_grid)\n\n        # Step 6: Compute coefficients\n        coefficients = []\n        for alpha in multi_indices:\n            # Evaluate the multi-dimensional basis polynomial on the grid\n            basis_values_grid = np.ones_like(model_values_grid)\n            for i in range(dim):\n                degree = alpha[i]\n                # Orthonormal Legendre polynomials: sqrt(2k+1) * P_k(x)\n                poly = legendre(degree)\n                norm_factor = np.sqrt(2 * degree + 1)\n                basis_values_grid *= (norm_factor * poly(xi_grids[i]))\n            \n            # Form the integrand\n            integrand_grid = model_values_grid * basis_values_grid\n            \n            # Approximate the integral using the quadrature rule\n            integral_val = np.sum(integrand_grid * product_weights_grid)\n            \n            # Final coefficient calculation\n            # c_alpha = (1/2)^d * integral\n            c_alpha = (0.5**dim) * integral_val\n            coefficients.append(c_alpha)\n        \n        return coefficients\n\n    # Define test cases\n    # (observable_lambda, priors_list, dimension, max_pce_degree)\n    test_cases = [\n        (lambda a_v: 56.0 * a_v, [(14.5, 16.5)], 1, 3),\n        (lambda a_v, a_s: 100.0 * a_v - (100.0**(2.0/3.0)) * a_s, \n         [(14.0, 16.0), (16.0, 18.0)], 2, 2),\n        (lambda a_v, a_s, a_c: 208.0 * a_v - (208.0**(2.0/3.0)) * a_s - (82.0**2 * 208.0**(-1.0/3.0)) * a_c,\n         [(14.0, 16.0), (16.0, 18.0), (0.6, 0.8)], 3, 2),\n        (lambda a_v, a_s, a_c: 208.0 * a_v - (208.0**(2.0/3.0)) * a_s - (82.0**2 * 208.0**(-1.0/3.0)) * a_c,\n         [(14.0, 16.0), (16.0, 18.0), (0.6, 0.8)], 3, 0),\n    ]\n\n    all_results = []\n    for model, priors, dim, p_max in test_cases:\n        coeffs = compute_pce_coefficients(model, priors, dim, p_max)\n        all_results.append(coeffs)\n    \n    # Format the final output string\n    result_str = \",\".join([f\"[{','.join([f'{c:.15g}' for c in case_coeffs])}]\" for case_coeffs in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3610367"}, {"introduction": "在确定模型结构后，必须使用实验数据来校准其参数。然而，这个过程很容易出现过拟合，特别是当数据包含模型未能捕捉到的隐藏相关性或系统误差时。本练习探讨了交叉验证策略的选择对稳健校准的关键作用，通过比较一种忽略数据结构的朴素方法和一种考虑了核物理中常见系统误差结构的方法，您将学习如何诊断并减轻过拟合，以确保模型预测的可靠性 [@problem_id:3610428]。", "problem": "您的任务是编写一个完整且可运行的程序，比较两种交叉验证方案，用于校准一个预测核结合能残差的线性类能量密度泛函（EDF）代理模型。您的程序必须估计预测风险，并检测“留一核法”（leave-one-nucleus-out）和“留一同位素链法”（leave-one-isotopic-chain-out）方案之间的潜在过拟合差异。\n\n模型和数据生成如下。\n\n1. 基本基础与建模假设：\n   - 假设可观测量是每个原子核的结合能残差，用 $y$ 表示，单位为兆电子伏特（MeV）。假设一个线性代理模型，其特征图是质子数 $Z$ 和中子数 $N$ 的最高二次多项式。对于给定的原子核 $(Z, N)$，定义特征向量\n     $$\\phi(Z,N) = \\begin{bmatrix} 1  Z  N  Z^2  N^2  ZN \\end{bmatrix}^{\\top}.$$\n   - 假设存在加性独立高斯噪声，其均值为零，标准差为 $\\sigma$（单位为 MeV），即 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$。\n   - 数据由一个固定的但未知的线性参数向量 $\\beta^{\\star} \\in \\mathbb{R}^6$，加上一个仅依赖于 $Z$ 的未建模同位素链偏移量 $g(Z)$，以及一个独立噪声 $\\epsilon$ 生成。即，\n     $$ y = \\phi(Z,N)^{\\top} \\beta^{\\star} + g(Z) + \\epsilon.$$\n   - 校准使用岭正则化最小二乘法，并对系数采用高斯先验解释，其中截距项（对应于常数项的第一个分量）不被惩罚。对于给定的正则化强度 $\\lambda \\ge 0$，估计量 $\\hat{\\beta}_{\\lambda}$ 最小化\n     $$ \\sum_{i=1}^{n} \\left(y_i - \\phi(Z_i,N_i)^{\\top}\\beta\\right)^2 + \\lambda \\sum_{j=2}^{6} \\beta_j^2.$$\n\n2. 交叉验证方案与预测风险：\n   - 留一核法交叉验证（LONO-CV）：对于每个数据点 $i$，在其余 $n-1$ 个数据点上拟合 $\\hat{\\beta}_{\\lambda}^{(-i)}$，并计算在预留点 $i$ 上的平方预测误差。$\\lambda$ 的 LONO-CV 预测风险是所有 $n$ 次预留的平方预测误差的平均值。\n   - 留一同位素链法交叉验证（LOICO-CV）：对于由质子数 $Z$ 标识的每个不同同位素链，在不属于该链的所有原子核上进行拟合，然后预测预留的链，并累加该链中所有原子核的平方预测误差。$\\lambda$ 的 LOICO-CV 预测风险是所有预留链中所有平方预测误差的平均值。此处，同位素链定义为具有相同质子数 $Z$ 和不同中子数 $N$ 的原子核集合。\n\n3. 正则化网格与选择：\n   - 考虑以下正则化强度的离散网格\n     $$ \\Lambda = \\{\\, 0,\\, 10^{-6},\\, 10^{-3},\\, 10^{-1},\\, 1,\\, 10 \\,\\}. $$\n   - 对于每种交叉验证方案，选择使相应预测风险最小化的 $\\lambda \\in \\Lambda$。如果在风险值上存在绝对容差 $10^{-12}$ 内的平局，则选择平局中最小的 $\\lambda$。\n\n4. 过拟合检测标准：\n   - 将过拟合检测指标定义为一个布尔值，计算方式如下\n     $$ \\text{overfit\\_detected} = \\left( \\lambda_{\\text{LONO}}^{\\star} = 0 \\right) \\wedge \\left( \\lambda_{\\text{LOICO}}^{\\star} > 0 \\right), $$\n     其中 $\\lambda_{\\text{LONO}}^{\\star}$ 和 $\\lambda_{\\text{LOICO}}^{\\star}$ 分别是 LONO-CV 和 LOICO-CV 下的最优选择。\n\n5. 数据集、真实参数和同位素链偏移量：\n   - 使用以下按 $Z$ 分组为同位素链的原子核集合 $(Z,N)$：\n     - $Z=20$：$N \\in \\{\\, 20,\\, 22,\\, 24,\\, 26 \\,\\}$，\n     - $Z=28$：$N \\in \\{\\, 28,\\, 30,\\, 32,\\, 34 \\,\\}$，\n     - $Z=50$：$N \\in \\{\\, 64,\\, 66,\\, 68,\\, 70 \\,\\}$，\n     - $Z=82$：$N \\in \\{\\, 120,\\, 122,\\, 124,\\, 126 \\,\\}$。\n   - 使用真实参数向量\n     $$ \\beta^{\\star} = \\begin{bmatrix} 5.0  -0.08  -0.10  5.0\\times 10^{-4}  3.0\\times 10^{-4}  2.0\\times 10^{-4} \\end{bmatrix}^{\\top} \\text{ MeV}, $$\n     以及同位素链偏移量\n     $$ g(20)=1.2 \\text{ MeV},\\quad g(28)=-1.0 \\text{ MeV},\\quad g(50)=0.5 \\text{ MeV},\\quad g(82)=-2.0 \\text{ MeV}.$$\n\n6. 测试套件：\n   - 您必须评估三个不同的测试用例，它们仅在噪声水平 $\\sigma$ 和用于生成高斯噪声的随机种子上有所不同。对于每个测试用例 $t \\in \\{1,2,3\\}$，通过使用指定的种子从 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 中独立抽样来生成输出 $y$ 以确保可复现性。使用：\n     - 用例 1：$\\sigma = 0.20$ MeV，随机种子 $123$，\n     - 用例 2：$\\sigma = 0.00$ MeV，随机种子 $456$，\n     - 用例 3：$\\sigma = 2.00$ MeV，随机种子 $789$。\n\n7. 每个测试用例所需的计算和输出：\n   - 对于每个测试用例，计算：\n     - 最优 LONO-CV 预测风险（均方预测误差），单位为兆电子伏特平方，记为 $R_{\\text{LONO}}^{\\star}$，\n     - 最优 LOICO-CV 预测风险（均方预测误差），单位为兆电子伏特平方，记为 $R_{\\text{LOICO}}^{\\star}$，\n     - 相应的最优正则化强度 $\\lambda_{\\text{LONO}}^{\\star}$ 和 $\\lambda_{\\text{LOICO}}^{\\star}$，从网格 $\\Lambda$ 中选取，\n     - 如上定义的过拟合检测布尔值。\n   - 所有风险必须表示为实数，单位为兆电子伏特平方（MeV$^2$）。所有正则化强度必须表示为无单位的实数。布尔值必须是字面量 True 或 False。\n\n8. 最终输出格式：\n   - 您的程序应生成单行输出，其中包含所有三个测试用例的结果，格式为逗号分隔的列表的列表，不含空格，并用一对单独的方括号括起来。对于每个测试用例，输出列表\n     $$ \\left[ R_{\\text{LONO}}^{\\star},\\ R_{\\text{LOICO}}^{\\star},\\ \\lambda_{\\text{LONO}}^{\\star},\\ \\lambda_{\\text{LOICO}}^{\\star},\\ \\text{overfit\\_detected} \\right]. $$\n   - 因此，最终输出应如下所示\n     $$ \\big[ [\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot] \\big], $$\n     其中每个数值条目都打印为标准浮点字面量，布尔值打印为 True 或 False，并且行中任何地方都没有空格。\n\n您的解决方案必须从上述基本假设出发，并精确地实现所定义的两种交叉验证方案。不允许外部输入；所有常量和数据均在此处指定。给定随机种子，程序必须是确定性的。全部逻辑必须嵌入程序中，并且必须完全按照规定生成一行输出。", "solution": "用户提供了一个核物理领域的计算问题，具体聚焦于能量密度泛函（EDF）代理模型的不确定性量化。任务是比较两种交叉验证（CV）方案——留一核法（LONO-CV）和留一同位素链法（LOICO-CV）——用于校准一个线性模型并检测潜在的过拟合。\n\n### 步骤 1：提取给定信息\n- **可观测量**：每个原子核的结合能残差，$y$，单位为兆电子伏特（MeV）。\n- **代理模型**：一个带有 polynomial 特征图的线性模型。\n- **特征向量**：对于原子核 $(Z,N)$，$\\phi(Z,N) = \\begin{bmatrix} 1  Z  N  Z^2  N^2  ZN \\end{bmatrix}^{\\top}$。\n- **数据生成模型**：$y = \\phi(Z,N)^{\\top} \\beta^{\\star} + g(Z) + \\epsilon$。\n- **噪声模型**：$\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$，独立同分布的高斯噪声。\n- **真实参数**：$\\beta^{\\star} = \\begin{bmatrix} 5.0  -0.08  -0.10  5.0\\times 10^{-4}  3.0\\times 10^{-4}  2.0\\times 10^{-4} \\end{bmatrix}^{\\top}$ MeV。\n- **同位素链偏移量**：$g(20)=1.2$ MeV，$g(28)=-1.0$ MeV，$g(50)=0.5$ MeV，$g(82)=-2.0$ MeV。\n- **校准方法**：岭正则化最小二乘法，最小化 $\\sum_{i=1}^{n} (y_i - \\phi(Z_i,N_i)^{\\top}\\beta)^2 + \\lambda \\sum_{j=2}^{6} \\beta_j^2$。截距项 $\\beta_1$ 不被惩罚。\n- **交叉验证方案**：\n    - **LONO-CV**：留一核法交叉验证。风险是所有 $n$ 次预留的平方预测误差的平均值。\n    - **LOICO-CV**：留一同位素链法交叉验证。同位素链是具有相同 $Z$ 的原子核集合。风险是所有预留链的平方预测误差的平均值。\n- **正则化网格**：$\\Lambda = \\{\\, 0,\\, 10^{-6},\\, 10^{-3},\\, 10^{-1},\\, 1,\\, 10 \\,\\}$。\n- **最优 $\\lambda$ 选择**：选择使 CV 风险最小化的 $\\lambda \\in \\Lambda$。若存在平局（风险值在 $10^{-12}$ 的绝对容差内），则选择最小的 $\\lambda$。\n- **过拟合指标**：$\\text{overfit\\_detected} = (\\lambda_{\\text{LONO}}^{\\star} = 0) \\wedge (\\lambda_{\\text{LOICO}}^{\\star} > 0)$。\n- **数据集**：\n    - $Z=20$：$N \\in \\{20, 22, 24, 26\\}$\n    - $Z=28$：$N \\in \\{28, 30, 32, 34\\}$\n    - $Z=50$：$N \\in \\{64, 66, 68, 70\\}$\n    - $Z=82$：$N \\in \\{120, 122, 124, 126\\}$\n- **测试用例**：\n    - 用例 1：$\\sigma = 0.20$ MeV，随机种子 $123$。\n    - 用例 2：$\\sigma = 0.00$ MeV，随机种子 $456$。\n    - 用例 3：$\\sigma = 2.00$ MeV，随机种子 $789$。\n- **要求输出**：对于每个用例，输出一个列表 $[R_{\\text{LONO}}^{\\star}, R_{\\text{LOICO}}^{\\star}, \\lambda_{\\text{LONO}}^{\\star}, \\lambda_{\\text{LOICO}}^{\\star}, \\text{overfit\\_detected}]$，其中 $R$ 是以 MeV$^2$ 为单位的风险。\n- **最终格式**：单行 `[[...],[...],[...]]`，无空格。\n\n### 步骤 2：使用提取的给定信息进行验证\n该问题是在核物理背景下设置的一个定义明确的统计建模和机器学习计算任务。\n- **科学上合理**：该问题使用了能量密度泛函、代理建模和交叉验证等概念，这些都是计算物理中的标准方法。该模型是一个为计算练习指定的简化模型，并非对基础物理的论断。作为一项建模研究，这在科学上是合理的。\n- **定义明确**：所有组件都已指定：数据生成过程、要拟合的模型、优化目标（带无惩罚截距的岭回归）、交叉验证程序、超参数网格以及评估指标。使用随机种子确保了可复现性。该问题允许一个唯一的、可确定性计算的解。\n- **客观性**：问题陈述使用了精确的数学和算法定义，没有歧义或主观语言。\n- **无缺陷**：该问题不违反任何无效性标准。它自成一体、前后一致、数值上可行且结构清晰。所有参数、常数和数据均已提供。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将提供一个解决方案。\n\n### 基于原则的解决方案设计\n\n问题的核心是为一个岭正则化线性模型实现并比较两种交叉验证策略。关键区别在于未建模的系统误差项 $g(Z)$，它在同一同位素链（相同的 $Z$）内的数据点之间引入了相关性。这两种 CV 方案将以不同方式处理这种相关性。\n\n**1. 数据生成和模型设置**\n首先，我们构建包含 $n=16$ 个原子核 $(Z,N)$ 的数据集以及相应的设计矩阵 $\\mathbf{X}$，其中每一行是特征向量 $\\phi(Z,N)^{\\top}$。对于每个测试用例，根据模型 $y_i = \\phi(Z_i, N_i)^{\\top} \\beta^{\\star} + g(Z_i) + \\epsilon_i$ 生成响应向量 $\\mathbf{y}$，使用指定的真实参数 $\\beta^{\\star}$、同位素链偏移量 $g(Z)$、噪声水平 $\\sigma$ 和随机种子。\n\n**2. 岭回归求解器**\n校准需要解决一个岭回归问题，其中截距项 $\\beta_1$ 不进行正则化。需要对 $\\beta \\in \\mathbb{R}^6$ 最小化的目标函数是：\n$$ L(\\beta) = \\|\\mathbf{y} - \\mathbf{X}\\beta\\|_2^2 + \\lambda \\|\\beta_{2:6}\\|_2^2 = (\\mathbf{y} - \\mathbf{X}\\beta)^{\\top}(\\mathbf{y} - \\mathbf{X}\\beta) + \\beta^{\\top}\\mathbf{P}\\beta $$\n其中 $\\mathbf{P}$ 是一个对角惩罚矩阵 $\\mathbf{P} = \\lambda \\cdot \\text{diag}(0, 1, 1, 1, 1, 1)$。\n对 $\\beta$ 求梯度并令其为零，得到正规方程：\n$$ (\\mathbf{X}^{\\top}\\mathbf{X} + \\mathbf{P})\\beta = \\mathbf{X}^{\\top}\\mathbf{y} $$\n对于每个训练折和正则化强度 $\\lambda$，解这个线性系统以求得 $\\hat{\\beta}_{\\lambda}$。为此，我们使用一个稳健的线性代数求解器。\n\n**3. 交叉验证方案**\n目标是为网格 $\\Lambda$ 中的不同 $\\lambda$ 值估计模型的预测风险。\n\n- **留一核法（LONO-CV）**：这是标准的留一法交叉验证。对于 $n$ 个数据点中的每一个，我们在其余 $n-1$ 个点上训练模型，并计算在单个预留点上的平方预测误差。给定 $\\lambda$ 的 LONO-CV 风险是这 $n$ 个平方误差的平均值。\n$$ R_{\\text{LONO}}(\\lambda) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\phi(Z_i, N_i)^{\\top}\\hat{\\beta}_{\\lambda}^{(-i)})^2 $$\n其中 $\\hat{\\beta}_{\\lambda}^{(-i)}$ 是在没有数据点 $i$ 的情况下估计的参数向量。因为每个折的训练集几乎肯定包含与预留点来自相同同位素链的其他原子核，所以该方案允许模型“学习”该链的系统偏移量 $g(Z)$。这可能导致对真实泛化误差的过分乐观估计，可能偏好一个未正则化的、过拟合的模型（$\\lambda=0$）。\n\n- **留一同位素链法（LOICO-CV）**：该方案旨在考虑数据的相关性结构。我们不是预留一个原子核，而是预留属于同一同位素链的所有原子核（即所有具有相同 $Z$ 的原子核）。模型在剩余的链上进行训练，并在整个预留链上进行测试。对每个同位素链重复此过程。给定 $\\lambda$ 的 LOICO-CV 风险是所有 $n$ 个原子核的平方误差的平均值。\n$$ R_{\\text{LOICO}}(\\lambda) = \\frac{1}{n} \\sum_{Z_k \\in \\text{Chains}} \\sum_{i \\in \\text{Chain } Z_k} (y_i - \\phi(Z_i, N_i)^{\\top}\\hat{\\beta}_{\\lambda}^{(-Z_k)})^2 $$\n其中 $\\hat{\\beta}_{\\lambda}^{(-Z_k)}$ 是在没有任何来自质子数为 $Z_k$ 的链的数据的情况下估计的。由于模型在一个其系统偏移量 $g(Z_k)$ 在训练期间完全未见的链上进行测试，这为模型外推到新物理区域（即新的质子数）的能力提供了一个更现实的估计。这很可能会揭示模型的设定错误，并偏好一个非零的 $\\lambda$ 以防止对训练数据中存在的特定偏移量过拟合。\n\n**4. 最优参数选择和过拟合检测**\n对于每种 CV 方案，我们计算每个 $\\lambda \\in \\Lambda$ 的风险。然后我们确定最小风险，并选择对应的 $\\lambda$ 作为最优值（$\\lambda^{\\star}$）。问题指定了一个平局决胜规则：如果多个 $\\lambda$ 值的风险与最小风险的差在 $10^{-12}$ 以内，则选择其中最小的 $\\lambda$。与这个选定的 $\\lambda^{\\star}$ 相关联的风险是最优风险 $R^{\\star}$。\n\n最后，过拟合指标通过两个条件的逻辑与运算计算得出：来自 LONO-CV 的最优 $\\lambda$ 为零，且来自 LOICO-CV 的最优 $\\lambda$ 大于零。这个条件正式地捕捉了这样一种情景：朴素的 CV 方案（LONO）建议不需要正则化，而更稳健的方案（LOICO）正确地识别出需要正则化来改善泛化能力，这是由未建模的系统误差引起的过拟合的经典迹象。\n\n对三个测试用例重复整个过程，改变噪声水平 $\\sigma$ 和随机种子。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that runs the three test cases and prints the final result.\n    \"\"\"\n\n    def phi(Z, N):\n        \"\"\"Constructs the feature vector for a given nucleus (Z, N).\"\"\"\n        return np.array([1, Z, N, Z**2, N**2, Z*N], dtype=float)\n\n    def solve_ridge(X_train, y_train, lambda_reg):\n        \"\"\"\n        Solves ridge regression with a non-penalized intercept.\n        The objective is: ||y - X*beta||^2 + lambda * ||beta[1:]||^2\n        \"\"\"\n        num_features = X_train.shape[1]\n        # Create the penalty matrix P = lambda * diag(0, 1, 1, ...)\n        P = np.diag([0.0] + [lambda_reg] * (num_features - 1))\n        \n        # Solve the normal equations: (X.T*X + P)*beta = X.T*y\n        A = X_train.T @ X_train + P\n        b = X_train.T @ y_train\n        \n        try:\n            beta_hat = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            # Fallback to pseudo-inverse if solve fails (for singular matrices. e.g. when lambda=0 and X is not full rank)\n            # This is generally not expected here but is good practice.\n            A_inv = np.linalg.pinv(A)\n            beta_hat = A_inv @ b\n            \n        return beta_hat\n\n    def select_optimal_lambda(lambdas, risks):\n        \"\"\"\n        Selects the optimal lambda according to the problem's criteria.\n        Chooses the smallest lambda in case of a tie in risk values.\n        \"\"\"\n        tolerance = 1e-12\n        min_risk_val = np.min(risks)\n        \n        # Find all lambdas whose risk is within tolerance of the minimum\n        candidate_lambdas = []\n        for lam, risk in zip(lambdas, risks):\n            if abs(risk - min_risk_val) = tolerance:\n                candidate_lambdas.append(lam)\n        \n        # From the candidates, choose the smallest lambda\n        optimal_lambda = min(candidate_lambdas)\n        \n        # Find the index of this optimal lambda to get its corresponding risk\n        optimal_lambda_index = lambdas.index(optimal_lambda)\n        optimal_risk = risks[optimal_lambda_index]\n        \n        return optimal_risk, optimal_lambda\n\n    def run_case(sigma, seed):\n        \"\"\"\n        Executes the full analysis for a single test case (sigma, seed).\n        \"\"\"\n        # 1. Define constants, data structures, and nuclei\n        nuclei_chains = {\n            20: [20, 22, 24, 26],\n            28: [28, 30, 32, 34],\n            50: [64, 66, 68, 70],\n            82: [120, 122, 124, 126]\n        }\n        nuclei = []\n        for z, ns in nuclei_chains.items():\n            for n in ns:\n                nuclei.append((z, n))\n        \n        num_nuclei = len(nuclei)\n\n        beta_star = np.array([5.0, -0.08, -0.10, 5.0e-4, 3.0e-4, 2.0e-4])\n        g_offsets = {20: 1.2, 28: -1.0, 50: 0.5, 82: -2.0}\n        lambdas = [0.0, 1e-6, 1e-3, 1e-1, 1.0, 10.0]\n\n        # 2. Generate data based on the model\n        rng = np.random.default_rng(seed)\n        X = np.array([phi(z, n) for z, n in nuclei])\n        y = np.zeros(num_nuclei)\n        for i, (z, n) in enumerate(nuclei):\n            true_model_val = X[i, :] @ beta_star\n            chain_offset = g_offsets[z]\n            noise = rng.normal(0, sigma) if sigma > 0 else 0.0\n            y[i] = true_model_val + chain_offset + noise\n\n        # 3. Leave-One-Nucleus-Out Cross-Validation (LONO-CV)\n        lono_risks = []\n        for lam in lambdas:\n            squared_errors = []\n            for i in range(num_nuclei):\n                X_train = np.delete(X, i, axis=0)\n                y_train = np.delete(y, i)\n                X_test_row = X[i, :]\n                y_test_val = y[i]\n                \n                beta_hat = solve_ridge(X_train, y_train, lam)\n                \n                y_pred = X_test_row @ beta_hat\n                squared_errors.append((y_pred - y_test_val)**2)\n            lono_risks.append(np.mean(squared_errors))\n        \n        R_lono_star, lambda_lono_star = select_optimal_lambda(lambdas, lono_risks)\n\n        # 4. Leave-One-Isotopic-Chain-Out Cross-Validation (LOICO-CV)\n        unique_Zs = sorted(nuclei_chains.keys())\n        loico_risks = []\n        for lam in lambdas:\n            all_fold_errors = []\n            for z_out in unique_Zs:\n                test_indices = [i for i, (z, n) in enumerate(nuclei) if z == z_out]\n                train_indices = [i for i, (z, n) in enumerate(nuclei) if z != z_out]\n                \n                X_train, y_train = X[train_indices], y[train_indices]\n                X_test, y_test = X[test_indices], y[test_indices]\n                \n                beta_hat = solve_ridge(X_train, y_train, lam)\n                \n                y_pred = X_test @ beta_hat\n                all_fold_errors.extend((y_pred - y_test)**2)\n            loico_risks.append(np.mean(all_fold_errors))\n            \n        R_loico_star, lambda_loico_star = select_optimal_lambda(lambdas, loico_risks)\n        \n        # 5. Overfitting Detection\n        overfit_detected = (lambda_lono_star == 0.0) and (lambda_loico_star > 0.0)\n        \n        return [R_lono_star, R_loico_star, lambda_lono_star, lambda_loico_star, overfit_detected]\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        (0.20, 123),  # Case 1\n        (0.00, 456),  # Case 2\n        (2.00, 789),  # Case 3\n    ]\n\n    results = []\n    for sigma, seed in test_cases:\n        case_result = run_case(sigma, seed)\n        results.append(case_result)\n\n    # Format the final output string as specified\n    formatted_results = []\n    for res_list in results:\n        str_list = list(map(str, res_list))\n        formatted_results.append(f\"[{','.join(str_list)}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3610428"}, {"introduction": "不确定性量化的最终目标通常是为未来的行动提供指导，这代表了UQ工作流程的顶点：利用量化的不确定性来做出最优决策。在此实践中，您将应用贝叶斯决策理论来确定下一个应测量哪个新原子核，以便在考虑实验成本和风险约束的同时，最大限度地减少关键观测量（如双中子分离能 $S_{2n}$）的预测不确定性。这展示了UQ如何通过为实验设计提供一个理性的框架，从而闭合理论与实验之间的循环 [@problem_id:3610437]。", "problem": "您的任务是编写一个完整、可运行的程序，该程序实现一步贝叶斯决策规则，以选择下一个质量测量，从而在平方误差损失下的简化高斯过程代理模型中，最大化双中子分离能（记为 $S_{2n}$）的预测损失的期望减少量。决策效用必须包括测量成本惩罚和风险预算惩罚。您必须为一组固定的测试用例生成决策。所有数学对象和标量都必须解释为实值，并且提供的所有数值都应被视为精确的输入参数，无需单位转换。\n\n基本原理。请使用以下原则。\n\n- 多变量正态模型的贝叶斯线性高斯更新：如果一个潜向量 $y \\in \\mathbb{R}^M$ 具有先验 $y \\sim \\mathcal{N}(\\mu, K)$，并且我们观测到具有独立高斯噪声方差 $\\tau_i^2$ 的单个分量 $y_i$，那么对于一个索引集 $T$，任何子向量 $y_T$ 的后验协方差为\n$$\n\\Sigma_{T \\mid i} \\;=\\; K_{TT} \\;-\\; K_{T i} \\,\\frac{1}{K_{ii} + \\tau_i^2}\\, K_{iT},\n$$\n由于共轭性，此结果与观测值无关。\n- 平方误差损失下的贝叶斯估计量：对于目标子向量 $y_T$ 和任何确定性预测器 $a \\in \\mathbb{R}^{|T|}$，使用对称半正定权重矩阵 $W \\in \\mathbb{R}^{|T| \\times |T|}$ 的期望加权平方误差为\n$$\n\\mathbb{E}\\left[(y_T - a)^\\top W (y_T - a)\\right] \\;=\\; \\operatorname{tr}\\left(W \\,\\operatorname{Cov}(y_T)\\right) \\;+\\; (\\mathbb{E}[y_T] - a)^\\top W (\\mathbb{E}[y_T] - a).\n$$\n贝叶斯最优选择是 $a = \\mathbb{E}[y_T]$，产生的贝叶斯风险等于 $\\operatorname{tr}\\left(W \\,\\operatorname{Cov}(y_T)\\right)$。\n- 决策论效用：对于在索引 $i$ 处的一次预期测量，将期望损失减少量定义为\n$$\n\\Delta \\mathcal{R}(i) \\;=\\; \\operatorname{tr}\\!\\left(W\\,K_{TT}\\right) \\;-\\; \\operatorname{tr}\\!\\left(W\\,\\Sigma_{T \\mid i}\\right).\n$$\n定义测量成本 $c_i \\ge 0$ 和风险度量\n$$\n\\mathcal{Q}(i) \\;=\\; \\max_{j \\in T} \\left[\\Sigma_{T \\mid i}\\right]_{jj},\n$$\n风险预算为 $R_{\\max} \\ge 0$。对于非负惩罚乘数 $\\lambda_{\\text{cost}}$ 和 $\\lambda_{\\text{risk}}$，效用为\n$$\nU(i) \\;=\\; \\Delta \\mathcal{R}(i) \\;-\\; \\lambda_{\\text{cost}}\\,c_i \\;-\\; \\lambda_{\\text{risk}}\\,\\max\\!\\left(0,\\,\\mathcal{Q}(i) - R_{\\max}\\right).\n$$\n您还必须支持弃权选项，由特殊索引 $-1$ 表示，意为不进行测量。弃权效用定义为 $U(-1) = 0$。\n- 选择规则与平局处理：对于每个测试用例，选择使 $U(i)$ 最大化的索引 $i^\\star \\in \\{-1,0,1,\\dots,M-1\\}$。如果对于所有 $i \\in \\{0,1,\\dots,M-1\\}$，所有的 $U(i)$ 都严格小于 $0$，则选择 $-1$。如果具有相同最大效用的测量索引出现平局，则选择最小的索引。\n\n模型规格。考虑由一个长度为 $M=6$ 的索引网格 $x = [0,1,2,3,4,5]$ 表示的 $M$ 个候选核素的离散链。潜向量 $y$ 收集了该网格上 $S_{2n}$ 的值。使用零均值高斯过程 (GP) 先验，其平方指数核函数为\n$$\nK_{ij} \\;=\\; \\sigma_f^2 \\exp\\!\\left(-\\frac{(x_i - x_j)^2}{2\\ell^2}\\right) \\;+\\; \\sigma_{\\text{nug}}^2 \\,\\delta_{ij},\n$$\n其中振幅 $\\sigma_f  0$，长度尺度 $\\ell  0$，以及一个小的块金项 $\\sigma_{\\text{nug}}^2  0$ 用以确保数值稳定性。在下一次测量之前没有可用于条件化的现有数据。索引 $i$ 处的观测噪声方差为 $\\tau_i^2  0$。预测的目标集为 $T = [2,3,4]$，权重矩阵 $W$ 是对角矩阵，其元素在每个测试用例中给出。所有能量均以兆电子伏 (MeV) 为单位，而损失的单位为 $\\text{MeV}^2$。最终输出是索引列表，无单位。\n\n您的程序必须实现上述效用和选择规则，并为以下测试套件生成结果。对于所有用例，均使用相同的网格 $x = [0,1,2,3,4,5]$ 和目标集 $T = [2,3,4]$。\n\n- 测试用例 $1$ (理想路径，中等相关性和统一低成本):\n  - 核函数超参数: $\\sigma_f = 1.5$, $\\ell = 1.0$, $\\sigma_{\\text{nug}}^2 = 10^{-8}$。\n  - 观测噪声: $\\tau^2 = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05]$。\n  - 权重: $W = \\operatorname{diag}([1.0, 1.0, 2.0])$。\n  - 成本: $c = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]$。\n  - 惩罚: $\\lambda_{\\text{cost}} = 0.05$, $\\lambda_{\\text{risk}} = 0.0$。\n  - 风险预算: $R_{\\max} = 10.0$。\n- 测试用例 $2$ (中心候选者成本主导):\n  - 核函数超参数: $\\sigma_f = 1.5$, $\\ell = 1.0$, $\\sigma_{\\text{nug}}^2 = 10^{-8}$。\n  - 观测噪声: $\\tau^2 = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05]$。\n  - 权重: $W = \\operatorname{diag}([1.0, 1.0, 2.0])$。\n  - 成本: $c = [0.1, 0.1, 0.1, 20.0, 0.1, 0.1]$。\n  - 惩罚: $\\lambda_{\\text{cost}} = 0.05$, $\\lambda_{\\text{risk}} = 0.0$。\n  - 风险预算: $R_{\\max} = 10.0$。\n- 测试用例 $3$ (风险预算紧张且相关长度短):\n  - 核函数超参数: $\\sigma_f = 1.0$, $\\ell = 0.3$, $\\sigma_{\\text{nug}}^2 = 10^{-8}$。\n  - 观测噪声: $\\tau^2 = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]$。\n  - 权重: $W = \\operatorname{diag}([1.0, 1.0, 2.0])$。\n  - 成本: $c = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]$。\n  - 惩罚: $\\lambda_{\\text{cost}} = 0.0$, $\\lambda_{\\text{risk}} = 5.0$。\n  - 风险预算: $R_{\\max} = 0.7$。\n- 测试用例 $4$ (高噪声，成本主导，倾向于弃权):\n  - 核函数超参数: $\\sigma_f = 1.0$, $\\ell = 1.0$, $\\sigma_{\\text{nug}}^2 = 10^{-8}$。\n  - 观测噪声: $\\tau^2 = [1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]$。\n  - 权重: $W = \\operatorname{diag}([1.0, 1.0, 1.0])$。\n  - 成本: $c = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]$。\n  - 惩罚: $\\lambda_{\\text{cost}} = 0.1$, $\\lambda_{\\text{risk}} = 0.0$。\n  - 风险预算: $R_{\\max} = 10.0$。\n\n实现要求。\n\n- 您的代码必须为每个测试用例计算使 $U(i)$ 在 $i \\in \\{0,1,2,3,4,5\\}$ 上最大化的索引 $i^\\star$，并应用上述定义的弃权规则。使用最小索引的平局处理规则。\n- 数值稳定性：在对标量 $K_{ii} + \\tau_i^2$ 求逆时，将其视为精确的标量除法，不要执行任何矩阵求逆。\n- 最终输出格式：您的程序应生成单行输出，包含一个用方括号括起来的、由逗号分隔的整数列表（例如，$[3,2,4,-1]$），其中每个条目是相应测试用例选择的索引，-1 表示弃权。不应打印任何其他文本。", "solution": "该问题在科学和数学上是适定的，提供了一套完整且一致的定义、参数和目标。这是一个贝叶斯最优实验设计领域的标准问题，应用于一个程式化的核物理背景。所有提供的公式都是正确的，所有数值都已指定，从而能够得到唯一且可验证的解。因此，我们可以进行推导和实现。\n\n主要目标是从候选核素的索引集合 $\\{0, 1, \\dots, M-1\\}$ 中选择一个测量索引 $i^\\star$，或者放弃测量（用索引 $-1$ 表示）。该选择必须最大化效用函数 $U(i)$，其定义如下：\n$$\nU(i) \\;=\\; \\Delta \\mathcal{R}(i) \\;-\\; \\lambda_{\\text{cost}}\\,c_i \\;-\\; \\lambda_{\\text{risk}}\\,\\max\\!\\left(0,\\,\\mathcal{Q}(i) - R_{\\max}\\right)\n$$\n对于 $i \\in \\{0, 1, \\dots, M-1\\}$，且 $U(-1) = 0$。选择规则是选择 $i^\\star = \\operatorname{argmax}_{i \\in \\{-1, 0, \\dots, M-1\\}} U(i)$，平局处理规则是选择最小的正索引。\n\n对于给定的测量候选项 $i$，$U(i)$ 的计算涉及三个部分：预测损失的期望减少量 $\\Delta \\mathcal{R}(i)$；测量成本的惩罚项 $\\lambda_{\\text cost} c_i$；以及超出风险预算的惩罚项 $\\lambda_{\\text risk} \\max(0, \\mathcal{Q}(i) - R_{\\max})$。我们将详细说明每个部分的计算。\n\n该模型是一个零均值高斯过程，因此潜向量 $y \\in \\mathbb{R}^M$ 的先验分布是 $\\mathcal{N}(0, K)$，其中 $K$ 是先验协方差矩阵。问题说明没有现有数据，因此任何子向量 $y_T$ 的预测协方差就是其先验协方差 $K_{TT}$。在进行任何测量之前的贝叶斯风险是 $\\mathcal{R}_{\\text{prior}} = \\operatorname{tr}(W K_{TT})$。在索引 $i$ 处进行一次测量后，$y_T$ 的后验协方差由 $\\Sigma_{T \\mid i}$ 给出。后验风险是 $\\mathcal{R}_{\\text{post}}(i) = \\operatorname{tr}(W \\Sigma_{T \\mid i})$。\n\n1.  **期望损失减少量 $\\Delta \\mathcal{R}(i)$**\n\n期望损失减少量是先验和后验贝叶斯风险之差：\n$$\n\\Delta \\mathcal{R}(i) = \\mathcal{R}_{\\text{prior}} - \\mathcal{R}_{\\text{post}}(i) = \\operatorname{tr}(W K_{TT}) - \\operatorname{tr}(W \\Sigma_{T \\mid i})\n$$\n代入后验协方差的表达式 $\\Sigma_{T \\mid i} = K_{TT} - K_{T i} \\frac{1}{K_{ii} + \\tau_i^2} K_{iT}$，我们得到：\n$$\n\\Delta \\mathcal{R}(i) = \\operatorname{tr}(W K_{TT}) - \\operatorname{tr}\\left(W \\left(K_{TT} - K_{T i} \\frac{1}{K_{ii} + \\tau_i^2} K_{iT}\\right)\\right)\n$$\n利用迹算子的线性性质 $\\operatorname{tr}(A-B) = \\operatorname{tr}(A) - \\operatorname{tr}(B)$:\n$$\n\\Delta \\mathcal{R}(i) = \\operatorname{tr}(W K_{TT}) - \\left(\\operatorname{tr}(W K_{TT}) - \\operatorname{tr}\\left(W K_{T i} \\frac{1}{K_{ii} + \\tau_i^2} K_{iT}\\right)\\right)\n$$\n这可以简化为：\n$$\n\\Delta \\mathcal{R}(i) = \\frac{1}{K_{ii} + \\tau_i^2} \\operatorname{tr}\\left(W K_{T i} K_{iT}\\right)\n$$\n项 $W K_{T i} K_{iT}$ 是一个大小为 $|T| \\times |T|$ 的矩阵。我们可以使用迹的循环性质 $\\operatorname{tr}(ABC) = \\operatorname{tr}(CAB)$。令 $A=W$，$B=K_{Ti}$，$C=K_{iT}$。则 $\\operatorname{tr}(W K_{Ti} K_{iT}) = \\operatorname{tr}(K_{iT} W K_{Ti})$。乘积 $K_{iT} W K_{Ti}$ 是一个 $1 \\times 1$ 矩阵（一个标量），其迹就是该标量值本身。由于权重矩阵 $W$ 是对角矩阵，其元素为 $W_{kk}$（对于 $k \\in T$），这个标量积为：\n$$\nK_{iT} W K_{Ti} = \\sum_{j \\in T} \\sum_{k \\in T} K_{ik} W_{kj} K_{ji} = \\sum_{j \\in T} W_{jj} (K_{ij})^2\n$$\n这里我们利用了 $W$ 是对角的以及 $K$ 是对称的 ($K_{ij} = K_{ji}$) 这一事实。损失减少量的最终高效公式为：\n$$\n\\Delta \\mathcal{R}(i) = \\frac{\\sum_{j \\in T} W_{jj} (K_{ij})^2}{K_{ii} + \\tau_i^2}\n$$\n\n2.  **风险惩罚项**\n\n仅当 $\\lambda_{\\text{risk}}  0$ 时，此惩罚项才非零。它依赖于风险度量 $\\mathcal{Q}(i)$，定义为目标集 $T$ 上的最大后验方差：\n$$\n\\mathcal{Q}(i) = \\max_{j \\in T} \\left[\\Sigma_{T \\mid i}\\right]_{jj}\n$$\n后验协方差矩阵 $\\Sigma_{T \\mid i}$ 的对角元素代表各个目标分量的后验方差。对于目标 $j \\in T$，后验方差为：\n$$\n[\\Sigma_{T \\mid i}]_{jj} = K_{jj} - \\frac{(K_{ji})^2}{K_{ii} + \\tau_i^2}\n$$\n注意 $\\Sigma_{T \\mid i}$ 的索引对应于 $T$ 的元素。一个谨慎的实现必须将这些映射回全局索引 $j \\in T$。因此，风险度量为：\n$$\n\\mathcal{Q}(i) = \\max_{j \\in T} \\left( K_{jj} - \\frac{(K_{ji})^2}{K_{ii} + \\tau_i^2} \\right)\n$$\n惩罚项则为 $\\lambda_{\\text{risk}} \\max(0, \\mathcal{Q}(i) - R_{\\max})$。\n\n**算法流程**\n\n对于四个测试用例中的每一个，我们执行以下步骤：\n1.  设置物理和模型参数：网格 $x$、目标索引 $T$、核函数超参数 ($\\sigma_f, \\ell, \\sigma_{\\text{nug}}^2$)、观测噪声方差 $\\tau^2$、权重矩阵对角线 $W_{\\text{diag}}$、测量成本 $c$ 和惩罚参数 ($\\lambda_{\\text{cost}}, \\lambda_{\\text{risk}}, R_{\\max}$)。\n2.  使用平方指数核函数公式 $K_{ij} = \\sigma_f^2 \\exp(-\\frac{(x_i - x_j)^2}{2\\ell^2}) + \\sigma_{\\text{nug}}^2 \\delta_{ij}$ 构建 $M \\times M$ 的先验协方差矩阵 $K$。对于我们的问题，$M=6$。\n3.  遍历每个可能的测量索引 $i \\in \\{0, 1, ..., 5\\}$。\n    a. 计算分母 $d_i = K_{ii} + \\tau_i^2$。\n    b. 使用上面推导的公式计算期望损失减少量 $\\Delta \\mathcal{R}(i)$。\n    c. 计算成本惩罚项 $\\lambda_{\\text{cost}} c_i$。\n    d. 如果 $\\lambda_{\\text{risk}}  0$，计算风险度量 $\\mathcal{Q}(i)$ 和相应的风险惩罚。\n    e. 结合这些项得到总效用 $U(i)$。\n4.  在计算完所有 $i \\in \\{0, 1, ..., 5\\}$ 的 $U(i)$ 后，确定它们中的最大效用 $U_{\\max} = \\max_i U(i)$。\n5.  应用选择规则：\n    a. 如果 $U_{\\max}  0$，则最优选择是弃权，$i^\\star = -1$。\n    b. 否则，找到索引集 $I^\\star = \\{ i \\mid U(i) = U_{\\max} \\}$。最优选择是该集合中最小的索引，$i^\\star = \\min(I^\\star)$。\n6.  测试套件的最终结果是每个用例的 $i^\\star$ 列表。\n\n此流程在以下 Python 程序中实现，遵循指定的环境和输出格式。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the Bayesian decision problem for all test cases.\n    \"\"\"\n\n    # Grid and target set are common to all test cases.\n    x = np.array([0, 1, 2, 3, 4, 5], dtype=float)\n    target_indices = np.array([2, 3, 4])\n\n    test_cases = [\n        # Test case 1 (happy path, moderate correlation and uniform low cost)\n        {\n            \"sigma_f\": 1.5, \"l\": 1.0, \"sigma_nug_sq\": 1e-8,\n            \"tau_sq\": np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05]),\n            \"W_diag\": np.array([1.0, 1.0, 2.0]),\n            \"c\": np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1]),\n            \"lambda_cost\": 0.05, \"lambda_risk\": 0.0, \"R_max\": 10.0\n        },\n        # Test case 2 (cost-dominated for a central candidate)\n        {\n            \"sigma_f\": 1.5, \"l\": 1.0, \"sigma_nug_sq\": 1e-8,\n            \"tau_sq\": np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05]),\n            \"W_diag\": np.array([1.0, 1.0, 2.0]),\n            \"c\": np.array([0.1, 0.1, 0.1, 20.0, 0.1, 0.1]),\n            \"lambda_cost\": 0.05, \"lambda_risk\": 0.0, \"R_max\": 10.0\n        },\n        # Test case 3 (tight risk budget with short correlation length)\n        {\n            \"sigma_f\": 1.0, \"l\": 0.3, \"sigma_nug_sq\": 1e-8,\n            \"tau_sq\": np.array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01]),\n            \"W_diag\": np.array([1.0, 1.0, 2.0]),\n            \"c\": np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n            \"lambda_cost\": 0.0, \"lambda_risk\": 5.0, \"R_max\": 0.7\n        },\n        # Test case 4 (high-noise, cost-dominated, prefer abstain)\n        {\n            \"sigma_f\": 1.0, \"l\": 1.0, \"sigma_nug_sq\": 1e-8,\n            \"tau_sq\": np.array([1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]),\n            \"W_diag\": np.array([1.0, 1.0, 1.0]),\n            \"c\": np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0]),\n            \"lambda_cost\": 0.1, \"lambda_risk\": 0.0, \"R_max\": 10.0\n        }\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = find_optimal_measurement(x, target_indices, case_params)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef find_optimal_measurement(x, target_indices, params):\n    \"\"\"\n    Computes the optimal measurement index for a single test case.\n    \"\"\"\n    M = len(x)\n    \n    # Unpack parameters\n    sigma_f = params[\"sigma_f\"]\n    l = params[\"l\"]\n    sigma_nug_sq = params[\"sigma_nug_sq\"]\n    tau_sq = params[\"tau_sq\"]\n    W_diag = params[\"W_diag\"]\n    c = params[\"c\"]\n    lambda_cost = params[\"lambda_cost\"]\n    lambda_risk = params[\"lambda_risk\"]\n    R_max = params[\"R_max\"]\n\n    # Construct the prior covariance matrix K\n    x_col = x[:, np.newaxis]\n    sq_dist = (x_col - x_col.T)**2\n    K = sigma_f**2 * np.exp(-sq_dist / (2.0 * l**2)) + sigma_nug_sq * np.eye(M)\n\n    utilities = np.zeros(M)\n    for i in range(M):\n        # Denominator for all calculations involving posterior update\n        denominator = K[i, i] + tau_sq[i]\n        \n        # 1. Calculate expected loss reduction, Delta_R(i)\n        # K_Ti is the vector of covariances between target points and candidate point i\n        K_Ti = K[target_indices, i]\n        # This is sum_{j in T} W_jj * (K_ij)^2, efficient with dot product\n        sum_weighted_sq_cov = np.dot(W_diag, K_Ti**2)\n        delta_R_i = sum_weighted_sq_cov / denominator\n\n        # 2. Calculate cost penalty\n        cost_penalty = lambda_cost * c[i]\n\n        # 3. Calculate risk penalty\n        risk_penalty = 0.0\n        if lambda_risk > 0:\n            # Q(i) = max_{j in T} [Sigma_{T|i}]_{jj}\n            # [Sigma_{T|i}]_{jj} = K_jj - (K_ji)^2 / (K_ii + tau_i^2)\n            K_TT_diag = np.diag(K)[target_indices]\n            posterior_variances = K_TT_diag - (K_Ti**2) / denominator\n            Q_i = np.max(posterior_variances)\n            risk_penalty = lambda_risk * max(0.0, Q_i - R_max)\n        \n        # 4. Calculate total utility U(i)\n        utilities[i] = delta_R_i - cost_penalty - risk_penalty\n\n    # 5. Apply selection rule\n    # Find the maximum utility among all non-abstain choices\n    max_utility = np.max(utilities)\n\n    # If the best non-abstain choice has negative utility, abstain (U(-1)=0)\n    if max_utility  0:\n        return -1\n    else:\n        # Find all indices that achieve the maximal utility\n        best_indices = np.where(np.isclose(utilities, max_utility))[0]\n        # Tie-breaking rule: choose the smallest index\n        return int(best_indices[0])\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3610437"}]}