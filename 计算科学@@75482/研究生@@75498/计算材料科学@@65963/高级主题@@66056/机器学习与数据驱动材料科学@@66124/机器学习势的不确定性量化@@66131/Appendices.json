{"hands_on_practices": [{"introduction": "高斯过程 (Gaussian Processes, GPs) 是概率机器学习的基石，为构建能够自然量化不确定性的原子间势提供了一个强大的框架。本练习不仅仅是简单地调用一个高斯过程库。通过从第一性原理出发推导后验方差，并用其评估模型的校准情况，您将对高斯过程如何捕捉不确定性以及如何评估其预测的可靠性有更深刻的理解。[@problem_id:3500259]", "problem": "给定一个用于原子间能量的监督学习设置，其中使用高斯过程（GP）回归模型作为非参数机器学习势（MLP）来模拟密度泛函理论（DFT）的能量。设潜能量函数由$f(\\mathbf{R})$表示，其中$\\mathbf{R}$是构型描述符，训练观测值为$y_i = f(\\mathbf{R}_i) + \\varepsilon_i$，其中$\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma_n^2)$是独立的高斯测量误差。假设一个零均值高斯过程（GP）先验$f \\sim \\mathcal{GP}(0, k(\\cdot,\\cdot))$，其核函数为平方指数核\n$$\nk(\\mathbf{R},\\mathbf{R}') = s^2 \\exp\\left(-\\tfrac{1}{2}\\left\\|\\tfrac{\\mathbf{R}-\\mathbf{R}'}{\\ell}\\right\\|^2\\right),\n$$\n其中$s^2$是信号方差，$\\ell$是特征长度尺度。在此问题中，您将 (i) 推导测试输入处潜函数的GP后验方差，以及 (ii) 通过计算DFT能量在双标准差贝叶斯可信区间内的经验覆盖率来评估校准度。\n\n从基本原理出发：潜训练输出和潜测试输出的先验的联合高斯性，以及观测值的加性高斯噪声模型。使用多元正态条件作用和高斯线性性质，不要使用任何未经证明的简化公式。\n\n您必须实现一个完整、可运行的程序，该程序：\n- 根据提供的核函数和超参数构建格拉姆矩阵。\n- 计算在测试描述符$\\mathbf{R}_*$处，潜函数$f(\\mathbf{R}_*)$的后验均值$\\mu(\\mathbf{R}_*)$和后验方差$\\sigma^2(\\mathbf{R}_*)$。\n- 为计算覆盖率，将密度泛函理论（DFT）能量视为潜函数的无噪声实现。也就是说，在定义$2$-标准差区间时，仅使用潜预测方差（排除观测噪声）。\n- 以小数形式计算每个构型组（块体、表面、缺陷）的经验覆盖率，定义为该组中DFT能量落在$[\\mu(\\mathbf{R}_*) - 2\\sigma(\\mathbf{R}_*), \\mu(\\mathbf{R}_*) + 2\\sigma(\\mathbf{R}_*)]$区间内的测试点的比例。\n- 计算所有组的总覆盖率。\n- 打印一行包含一个方括号括起来的逗号分隔列表，顺序为$[\\text{bulk\\_coverage}, \\text{surface\\_coverage}, \\text{defect\\_coverage}, \\text{overall\\_coverage}]$，其中每个条目四舍五入到三位小数，不含百分号。\n\n所有能量必须以电子伏特（在适當時缩写为$\\text{eV}$）处理和报告。不使用角度。覆盖率值必须表示为四舍五入到三位小数的小数。\n\n使用以下核函数超参数和数据集。描述符是一维且无量纲的（因此将$\\mathbf{R}$写为$R$）。核函数超参数为：\n- 信号方差 $s^2 = 0.25$（单位为$\\text{eV}^2$），\n- 长度尺度 $\\ell = 0.6$（无量纲），\n- 观测噪声标准差 $\\sigma_n = 0.02$（单位为$\\text{eV}$），因此$\\sigma_n^2 = 0.0004$（单位为$\\text{eV}^2$）。\n\n训练数据 $(R_i, E_i)$，其中$E_i$的单位为$\\text{eV}$：\n- $R_{\\text{train}} = [0.00, 0.25, 0.55, 0.90, 1.20, 1.50]$,\n- $E_{\\text{train}} = [1.00000, 0.90625, 0.81025, 0.72100, 0.66400, 0.62500]$.\n\n按构型类别分组的测试套件，其中$R$无量纲，$E$的单位为$\\text{eV}$：\n- 块体: $R_{\\text{bulk}} = [0.10, 0.60, 1.00]$, $E_{\\text{bulk}} = [0.96100, 0.79600, 0.70000]$.\n- 表面: $R_{\\text{surface}} = [1.10, 1.20, 1.60]$, $E_{\\text{surface}} = [0.68100, 0.66400, 0.61600]$.\n- 缺陷: $R_{\\text{defect}} = [1.80, 2.20, 2.60]$, $E_{\\text{defect}} = [0.60400, 0.60400, 0.63600]$.\n\n您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表的结果（例如，$[0.667,0.667,1.000,0.778]$）。这些条目必须按顺序对应于块体、表面、缺陷和总体覆盖率的小数形式，每个都四舍五入到三位小数。不允许有其他输出。", "solution": "该问题是有效的，因为它具有科学依据、适定且客观。它为高斯过程（GP）回归在计算材料科学中的标准应用提供了一套完整且一致的数据和参数。任务定义清晰且计算上是可行的。我们将继续提供解决方案。\n\n问题的核心是，给定一组带噪声的训练观测值，推导由高斯过程建模的潜能量函数$f(R)$的后验分布，然后利用该后验分布评估模型的不确定性校准。\n\n设训练数据为一组$N$个配对$\\{ (R_i, y_i) \\}_{i=1}^N$，其中$R_i$是描述符值，$y_i$是相应的带噪声的能量观测值。我们将训练输入的集合表示为$X = \\{R_1, \\dots, R_N\\}$，训练观测值的向量表示为$\\mathbf{y} = [y_1, \\dots, y_N]^T$。类似地，设测试输入为$M$个新的描述符值，表示为$X_* = \\{R_{*,1}, \\dots, R_{*,M}\\}$，我们希望在这些点上预测潜函数值$\\mathbf{f}_* = [f(R_{*,1}), \\dots, f(R_{*,M})]^T$。\n\n该模型由两个主要部分定义：GP先验和似然。\n\n1.  **GP先验**：假设潜函数$f$具有高斯过程先验，$f \\sim \\mathcal{GP}(m(R), k(R, R'))$。问题指定了零均值先验，因此$m(R) = 0$。核函数是平方指数核：\n    $$\n    k(R, R') = s^2 \\exp\\left(-\\frac{(R-R')^2}{2\\ell^2}\\right)\n    $$\n    其中$s^2$是信号方差，$\\ell$是特征长度尺度。根据GP的定义，任何有限的函数值集合都是联合高斯的。设$\\mathbf{f}$为训练输入$X$处的潜函数值向量。在训练输入$\\mathbf{f}$和测试输入$\\mathbf{f}_*$处的潜值的联合先验分布由下式给出：\n    $$\n    \\begin{pmatrix} \\mathbf{f} \\\\ \\mathbf{f}_* \\end{pmatrix}\n    \\sim \\mathcal{N} \\left(\n        \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix},\n        \\begin{pmatrix} K(X, X)  K(X, X_*) \\\\ K(X_*, X)  K(X_*, X_*) \\end{pmatrix}\n    \\right)\n    $$\n    在这里，$K(A, B)$表示集合$A$和$B$中所有点之间的核函数求值矩阵。为简洁起见，我们使用记号$K = K(X, X)$，$K_* = K(X, X_*)$和$K_{**} = K(X_*, X_*)$。注意$K(X_*, X) = K_*^T$。\n\n2.  **似然**：训练观测值$y_i$通过一个加性、独立、同分布的高斯噪声模型与潜函数值$f(R_i)$相关联：\n    $$\n    y_i = f(R_i) + \\varepsilon_i, \\quad \\text{其中} \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2)\n    $$\n    以向量形式表示为$\\mathbf{y} = \\mathbf{f} + \\boldsymbol{\\varepsilon}$，其中$\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_n^2 I)$，$I$是$N \\times N$的单位矩阵。\n\n从这两个部分，我们推导出后验分布$p(\\mathbf{f}_* | X, \\mathbf{y}, X_*)$。推导过程首先找到可观测值$\\mathbf{y}$和待预测量$\\mathbf{f}_*$的联合分布。由于$\\mathbf{f}$和$\\boldsymbol{\\varepsilon}$是独立的高斯向量，它们的和$\\mathbf{y}$也是高斯的。因此，$(\\mathbf{y}, \\mathbf{f}_*)$的联合分布是一个多元正态分布。其均值为：\n$$\nE\\left[\\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{f}_* \\end{pmatrix}\\right] = \\begin{pmatrix} E[\\mathbf{f} + \\boldsymbol{\\varepsilon}] \\\\ E[\\mathbf{f}_*] \\end{pmatrix} = \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix}\n$$\n协方差矩阵为：\n$$\n\\text{Cov}\\left(\\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{f}_* \\end{pmatrix}\\right) =\n\\begin{pmatrix}\n\\text{Cov}(\\mathbf{y})  \\text{Cov}(\\mathbf{y}, \\mathbf{f}_*) \\\\\n\\text{Cov}(\\mathbf{f}_*, \\mathbf{y})  \\text{Cov}(\\mathbf{f}_*)\n\\end{pmatrix}\n$$\n该矩阵的块为：\n- $\\text{Cov}(\\mathbf{y}) = \\text{Cov}(\\mathbf{f} + \\boldsymbol{\\varepsilon}) = \\text{Cov}(\\mathbf{f}) + \\text{Cov}(\\boldsymbol{\\varepsilon}) = K + \\sigma_n^2 I$.\n- $\\text{Cov}(\\mathbf{f}_*) = K_{**}$.\n- $\\text{Cov}(\\mathbf{y}, \\mathbf{f}_*) = \\text{Cov}(\\mathbf{f} + \\boldsymbol{\\varepsilon}, \\mathbf{f}_*) = \\text{Cov}(\\mathbf{f}, \\mathbf{f}_*) + \\text{Cov}(\\boldsymbol{\\varepsilon}, \\mathbf{f}_*) = K_* + \\mathbf{0} = K_*$.\n- $\\text{Cov}(\\mathbf{f}_*, \\mathbf{y}) = \\text{Cov}(\\mathbf{y}, \\mathbf{f}_*)^T = K_*^T$.\n所以，联合分布为：\n$$\n\\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{f}_* \\end{pmatrix}\n\\sim \\mathcal{N} \\left(\n    \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix},\n    \\begin{pmatrix} K + \\sigma_n^2 I  K_* \\\\ K_*^T  K_{**} \\end{pmatrix}\n\\right)\n$$\n为了找到给定观测值$\\mathbf{y}$后$\\mathbf{f}_*$的后验分布，我们使用多元高斯条件作用的标准法则。对于一个联合高斯分布$\\begin{pmatrix} \\mathbf{a} \\\\ \\mathbf{b} \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} \\boldsymbol{\\mu}_a \\\\ \\boldsymbol{\\mu}_b \\end{pmatrix}, \\begin{pmatrix} \\Sigma_{aa}  \\Sigma_{ab} \\\\ \\Sigma_{ba}  \\Sigma_{bb} \\end{pmatrix} \\right)$，条件分布$p(\\mathbf{b}|\\mathbf{a})$是一个高斯分布，其均值为$\\boldsymbol{\\mu}_{b|a} = \\boldsymbol{\\mu}_b + \\Sigma_{ba} \\Sigma_{aa}^{-1} (\\mathbf{a} - \\boldsymbol{\\mu}_a)$，协方差为$\\Sigma_{b|a} = \\Sigma_{bb} - \\Sigma_{ba} \\Sigma_{aa}^{-1} \\Sigma_{ab}$。\n\n将此应用于我们的情况（其中$\\mathbf{a}=\\mathbf{y}$，$\\mathbf{b}=\\mathbf{f}_*$，且均值为零），后验分布$p(\\mathbf{f}_* | X, \\mathbf{y}, X_*)$是一个高斯分布$\\mathcal{N}(\\boldsymbol{\\mu}_*, \\Sigma_*)$，其中：\n- 后验均值：$\\boldsymbol{\\mu}_* = K_*^T (K + \\sigma_n^2 I)^{-1} \\mathbf{y}$\n- 后验协方差：$\\Sigma_* = K_{**} - K_*^T (K + \\sigma_n^2 I)^{-1} K_*$\n\n对于单个测试点$R_*$，这些表达式得以简化。$K_*$变为一个向量$\\mathbf{k}_* = [k(R_1, R_*), \\dots, k(R_N, R_*)]^T$，$K_{**}$变为标量$k_{**} = k(R_*, R_*)$。潜值$f(R_*)$的后验分布为$\\mathcal{N}(\\mu(R_*), \\sigma^2(R_*))$，其中：\n- 后验均值：$\\mu(R_*) = \\mathbf{k}_*^T (K + \\sigma_n^2 I)^{-1} \\mathbf{y}$\n- 后验方差（潜函数的）：$\\sigma^2(R_*) = k_{**} - \\mathbf{k}_*^T (K + \\sigma_n^2 I)^{-1} \\mathbf{k}_*$\n\n该后验方差$\\sigma^2(R_*)$量化了模型对*潜函数值*$f(R_*)$估计的不确定性，不包括观测噪声。问题要求基于此潜方差建立一个可信区间。$f(R_*)$的一个$2$-标准差可信区间由$[\\mu(R_*) - 2\\sigma(R_*), \\mu(R_*) + 2\\sigma(R_*)]$给出。\n\n然后为每组测试构型计算经验覆盖率。对于给定的一组含有$M$个测试点，我们计算有多少真实的DFT能量$E_{*,j}$落在其对应的可信区间内：\n$$\n\\text{Coverage} = \\frac{1}{M} \\sum_{j=1}^M \\mathbb{I} \\left( E_{*,j} \\in [\\mu(R_{*,j}) - 2\\sigma(R_{*,j}), \\mu(R_{*,j}) + 2\\sigma(R_{*,j})] \\right)\n$$\n其中$\\mathbb{I}(\\cdot)$是指示函数。实现将为'块体'、'表面'和'缺陷'组以及所有测试点的组合计算此值。为了数值稳定性，矩阵求逆$(K + \\sigma_n^2 I)^{-1}$通过求解线性系统来执行，最好是通过Cholesky分解。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import cholesky, cho_solve\n\ndef solve():\n    \"\"\"\n    Computes the empirical coverage of a Gaussian Process regression model\n    for emulating Density Functional Theory (DFT) energies.\n    \"\"\"\n    \n    # 1. Define kernel hyperparameters and dataset as per the problem statement.\n    # All energies are in eV. Descriptor R is dimensionless.\n    s2 = 0.25         # Signal variance, in eV^2\n    ell = 0.6         # Characteristic length scale, dimensionless\n    sigma_n2 = 0.0004 # Observation noise variance, in eV^2\n    \n    # Training data\n    R_train = np.array([0.00, 0.25, 0.55, 0.90, 1.20, 1.50]).reshape(-1, 1)\n    E_train = np.array([1.00000, 0.90625, 0.81025, 0.72100, 0.66400, 0.62500])\n\n    # Test suite grouped by configuration class\n    test_suite = {\n        \"bulk\": (np.array([0.10, 0.60, 1.00]), np.array([0.96100, 0.79600, 0.70000])),\n        \"surface\": (np.array([1.10, 1.20, 1.60]), np.array([0.68100, 0.66400, 0.61600])),\n        \"defect\": (np.array([1.80, 2.20, 2.60]), np.array([0.60400, 0.60400, 0.63600]))\n    }\n\n    # 2. Define the squared-exponential kernel function.\n    def squared_exp_kernel(X1, X2, s2_param, l2_param):\n        \"\"\"\n        Computes the squared-exponential kernel matrix between two sets of 1D inputs.\n        X1: (N, 1) array\n        X2: (M, 1) array\n        Returns: (N, M) kernel matrix\n        \"\"\"\n        # Broadcasting (X1 - X2.T) creates an (N, M) matrix of pairwise differences.\n        sq_dist_matrix = (X1 - X2.T)**2\n        return s2_param * np.exp(-0.5 * sq_dist_matrix / l2_param)\n\n    # 3. Perform one-time pre-computation for the GP model.\n    l2 = ell**2\n    K_train = squared_exp_kernel(R_train, R_train, s2, l2)\n    Ky = K_train + sigma_n2 * np.eye(len(R_train))\n\n    # For numerical stability, use Cholesky decomposition to solve linear systems\n    # involving the inverse of Ky. L is the lower-triangular Cholesky factor.\n    try:\n        L = cholesky(Ky, lower=True)\n    except np.linalg.LinAlgError:\n        # This case should not be reached with the given valid parameters.\n        # Fallback for robustness.\n        print(\"Error: The covariance matrix Ky is not positive definite.\")\n        return\n\n    # Pre-compute alpha = Ky^-1 * y\n    alpha = cho_solve((L, True), E_train)\n\n    # 4. Calculate coverage for each test group and overall.\n    coverages = {}\n    all_R_test = []\n    all_E_test = []\n\n    def calculate_coverage(R_test, E_test):\n        \"\"\"Helper function to compute coverage for a given test set.\"\"\"\n        if len(R_test) == 0:\n            return 0.0\n\n        M = len(R_test)\n        R_test_reshaped = R_test.reshape(-1, 1)\n        \n        # Vectorized prediction for all test points\n        k_star_matrix = squared_exp_kernel(R_train, R_test_reshaped, s2, l2)\n        \n        # Posterior mean\n        mu_star_vector = k_star_matrix.T @ alpha\n        \n        # Posterior variance (of the latent function)\n        # We need the diagonal of K_** - K_*^T Ky^-1 K_*.\n        # diag(K_**): is just s2 for all test points.\n        # diag(K_*^T Ky^-1 K_*): can be computed efficiently.\n        # Let v = Ky^-1 K_*. Then the diagonal is sum(K_* * v, axis=0).\n        v = cho_solve((L, True), k_star_matrix)\n        var_star_vector = s2 - np.sum(k_star_matrix * v, axis=0)\n        \n        # Correct for potential minor numerical precision issues\n        var_star_vector[var_star_vector < 0] = 0\n        sigma_star_vector = np.sqrt(var_star_vector)\n\n        # Define 2-sigma credible intervals\n        lower_bounds = mu_star_vector - 2 * sigma_star_vector\n        upper_bounds = mu_star_vector + 2 * sigma_star_vector\n        \n        # Check which true energies fall within the intervals\n        covered_mask = (E_test >= lower_bounds) & (E_test <= upper_bounds)\n        \n        return np.mean(covered_mask)\n\n    for group_name, (R_group, E_group) in test_suite.items():\n        coverages[group_name] = calculate_coverage(R_group, E_group)\n        all_R_test.append(R_group)\n        all_E_test.append(E_group)\n        \n    # Overall coverage calculation\n    R_overall = np.concatenate(all_R_test)\n    E_overall = np.concatenate(all_E_test)\n    coverages['overall'] = calculate_coverage(R_overall, E_overall)\n    \n    # 5. Format and print the final result.\n    output_values = [\n        round(coverages['bulk'], 3),\n        round(coverages['surface'], 3),\n        round(coverages['defect'], 3),\n        round(coverages['overall'], 3),\n    ]\n\n    # Print in the required format: [val1,val2,val3,val4]\n    print(f\"[{','.join(f'{x:.3f}' for x in output_values)}]\")\n\nsolve()\n```", "id": "3500259"}, {"introduction": "不确定性量化中的一个关键方面是理解不确定性的*来源*。本练习将介绍偶然不确定性 (aleatoric uncertainty，即固有的数据噪声) 和认知不确定性 (epistemic uncertainty，即模型无知) 之间的根本区别。您将通过分析来自不同数据源的残差，实现一个巧妙的假设检验来分离这两种不确定性成分，这项技能对于指导主动学习和提高模型可靠性至关重要。[@problem_id:3500186]", "problem": "给定来自密度泛函理论 (DFT) 的两种标记协议，它们应用于一个固定的机器学习势 (MLP) 架构的相同留出组态。对于每个组态索引 $i \\in \\{1,\\dots,n\\}$，这两种标记协议为相同的原子组态生成标量标签 $y_{1,i}$ 和 $y_{2,i}$，而 MLP 预测一个标量 $\\mu_i$。定义残差 $r_{1,i} = y_{1,i} - \\mu_i$ 和 $r_{2,i} = y_{2,i} - \\mu_i$。假设一个加性随机效应模型，其中残差分解为 $r_{k,i} = e_i + \\varepsilon_{k,i}$（对于 $k \\in \\{1,2\\}$）。这里，$e_i$ 是与 MLP 对组态 $i$ 的预测相关的认知误差分量，而 $\\varepsilon_{k,i}$ 是与第 $k$ 种 DFT 标记协议在组态 $i$ 上的偶然噪声分量。假设 $e_i$ 和 $\\varepsilon_{k,i}$ 在整个留出集上均值为零，$\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 在给定 $i$ 的条件下条件独立，并且 $e_i$ 与每个 $\\varepsilon_{k,i}$ 相互独立。\n\n您的任务是设计并实现一个单边假设检验，以评估在留出集中偶然噪声是否主导认知误差。仅使用方差、协方差和独立性的定义，以一个能清晰比较认知方差与两种标记协议的平均偶然方差的参数来构建假设。仅依赖基本的统计学定义和经过充分检验的程序，从第一性原理推导出一个检验统计量和一个在显著性水平 $\\alpha = 0.05$ 下的决策规则。您可以假定使用非参数配对自举法 (bootstrap) 来量化抽样不确定性。\n\n您编写的程序必须为每个测试用例实现以下流程：\n- 根据提供的参数，使用指定的随机种子和分布，生成留出残差对 $\\{(r_{1,i}, r_{2,i})\\}_{i=1}^n$。\n- 使用生成的残差，仅基于方差和协方差的定义，构建认知方差的估计量以及两种标记协议偶然方差的估计量。\n- 构建一个显著性水平为 $\\alpha = 0.05$ 的单边假设检验，其中零假设的选择应使“偶然噪声主导认知误差”对应于备择假设。使用包含 $B$ 个重抽样样本的配对非参数自举法来评估检验统计量的不确定性，并实现一个决策规则，为每个测试用例返回一个布尔值，指示数据是否在 $\\alpha$ 水平上提供了偶然噪声主导认知误差的充分证据。\n- 在所有情况下，均使用 $B = 2000$ 个自举重抽样样本。\n\n您必须考虑以下测试套件，其中所有随机数生成都必须使用指定的种子以确保确定性。每个测试用例都指定了 $n$ 和 $(e_i, \\varepsilon_{1,i}, \\varepsilon_{2,i})$ 的生成模型，程序必须相应地生成 $r_{k,i} = e_i + \\varepsilon_{k,i}$。\n\n- 用例 A（理想路径，偶然噪声明显占主导）：$n = 800$。$e_i$ 独立抽取自方差为 $\\sigma_{\\mathrm{e}}^2 = 0.05$ 的正态分布，$\\varepsilon_{1,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a1}}^2 = 0.20$ 的正态分布，$\\varepsilon_{2,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a2}}^2 = 0.25$ 的正态分布。使用种子 $s = 10$。\n- 用例 B（认知误差占主导）：$n = 800$。$e_i$ 独立抽取自方差为 $\\sigma_{\\mathrm{e}}^2 = 0.50$ 的正态分布，$\\varepsilon_{1,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a1}}^2 = 0.05$ 的正态分布，$\\varepsilon_{2,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a2}}^2 = 0.05$ 的正态分布。使用种子 $s = 20$。\n- 用例 C（边界情况，量级相当）：$n = 300$。$e_i$ 独立抽取自方差为 $\\sigma_{\\mathrm{e}}^2 = 0.10$ 的正态分布，$\\varepsilon_{1,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a1}}^2 = 0.10$ 的正态分布，$\\varepsilon_{2,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a2}}^2 = 0.10$ 的正态分布。使用种子 $s = 30$。\n- 用例 D（异方差偶然噪声，仍为偶然噪声主导）：$n = 1000$。$e_i$ 独立抽取自方差为 $\\sigma_{\\mathrm{e}}^2 = 0.02$ 的正态分布。对于 $i \\in \\{1,\\dots,n\\}$，$\\varepsilon_{1,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a1},i}^2 = 0.20 \\times \\left(1 + 0.5 \\sin\\left(2\\pi i / n\\right)\\right)$ 的正态分布，$\\varepsilon_{2,i}$ 独立抽取自方差为 $\\sigma_{\\mathrm{a2},i}^2 = 0.18 \\times \\left(1 - 0.5 \\cos\\left(2\\pi i / n\\right)\\right)$ 的正态分布。使用种子 $s = 40$。\n- 用例 E（零偶然噪声）：$n = 500$。$e_i$ 独立抽取自方差为 $\\sigma_{\\mathrm{e}}^2 = 0.10$ 的正态分布。对于所有 $i$，确定性地设置 $\\varepsilon_{1,i} = 0$ 和 $\\varepsilon_{2,i} = 0$。使用种子 $s = 50$。\n- 用例 F（小认知方差下的重尾偶然噪声）：$n = 800$。$e_i$ 独立抽取自方差为 $\\sigma_{\\mathrm{e}}^2 = 0.01$ 的正态分布。$\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 分别独立抽取自自由度为 $\\nu = 3$ 的学生t分布 (Student’s $t$ distribution)，并进行缩放以使方差分别达到 $\\sigma_{\\mathrm{a1}}^2 = 0.25$ 和 $\\sigma_{\\mathrm{a2}}^2 = 0.25$。使用种子 $s = 60$。\n\n对于所有用例，将“偶然噪声主导认知误差”精确地解释为两种标记协议的平均偶然方差大于留出集上的认知方差，并据此设计显著性水平为 $\\alpha = 0.05$ 的单边假设检验。\n\n您的程序应生成单行输出，其中包含六个测试用例的结果，格式为一个由方括号括起来的、以逗号分隔的布尔值列表（例如，$[{\\tt True},{\\tt False},{\\tt True},{\\tt True},{\\tt False},{\\tt True}]$）。当且仅当在显著性水平 $\\alpha = 0.05$ 下，您的检验得出第 $k$ 个用例中偶然噪声主导认知误差的结论时，第 $k$ 个布尔值必须为 ${\\tt True}$，否则为 ${\\tt False}$。不允许任何其他输出。", "solution": "该问题要求设计并实现一个单边假设检验，以根据两种不同标记协议产生的残差，判断机器学习势的偶然噪声是否主导认知误差。对问题陈述的验证确认了其科学基础扎实、定义明确，并包含了进行求解所需的所有必要信息。\n\n我们分析的基础是为标记协议 $k \\in \\{1, 2\\}$ 和组态 $i \\in \\{1, \\dots, n\\}$ 的残差 $r_{k,i}$ 所提供的加性随机效应模型：\n$$r_{k,i} = e_i + \\varepsilon_{k,i}$$\n此处，$e_i$ 是机器学习势在组态 $i$ 上的认知误差，而 $\\varepsilon_{k,i}$ 是来自第 $k$ 种标记协议的偶然噪声。问题陈述了关于这些误差分量的几个关键假设：\n1.  它们在总体上均值为零：$E[e_i] = 0$ 且对于 $k=1,2$ 有 $E[\\varepsilon_{k,i}] = 0$。\n2.  认知误差 $e_i$ 与两个偶然噪声分量 $\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 相互独立。这意味着 $Cov(e_i, \\varepsilon_{k,i}) = 0$。\n3.  两个偶然噪声分量 $\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 在给定组态 $i$ 的条件下是条件独立的。这意味着 $Cov(\\varepsilon_{1,i}, \\varepsilon_{2,i}) = 0$。\n\n令 $\\sigma_e^2 = \\text{Var}(e_i)$、$\\sigma_{a1}^2 = \\text{Var}(\\varepsilon_{1,i})$ 和 $\\sigma_{a2}^2 = \\text{Var}(\\varepsilon_{2,i})$ 分别表示认知误差和偶然误差的总体方差。请注意，对于具有异方差噪声的情况（如用例 D），$\\sigma_{ak}^2$ 表示所有组态的平均方差。利用独立性假设，我们可以推导出每个残差序列的方差及其协方差的表达式。\n\n第一个残差序列的方差为：\n$$\\text{Var}(r_1) = \\text{Var}(e + \\varepsilon_1) = \\text{Var}(e) + \\text{Var}(\\varepsilon_1) + 2\\text{Cov}(e, \\varepsilon_1) = \\sigma_e^2 + \\sigma_{a1}^2$$\n同样，第二个残差序列的方差为：\n$$\\text{Var}(r_2) = \\text{Var}(e + \\varepsilon_2) = \\text{Var}(e) + \\text{Var}(\\varepsilon_2) + 2\\text{Cov}(e, \\varepsilon_2) = \\sigma_e^2 + \\sigma_{a2}^2$$\n两个残差序列之间的协方差为：\n$$\\text{Cov}(r_1, r_2) = \\text{Cov}(e + \\varepsilon_1, e + \\varepsilon_2) = \\text{Cov}(e,e) + \\text{Cov}(e,\\varepsilon_2) + \\text{Cov}(\\varepsilon_1,e) + \\text{Cov}(\\varepsilon_1,\\varepsilon_2)$$\n根据独立性假设，所有交叉项均为零，且 $\\text{Cov}(e,e) = \\text{Var}(e)$。因此：\n$$\\text{Cov}(r_1, r_2) = \\sigma_e^2$$\n这提供了一种从可观测残差的协方差中直接识别认知方差的方法。然后我们可以求解偶然方差：\n$$\\sigma_{a1}^2 = \\text{Var}(r_1) - \\sigma_e^2 = \\text{Var}(r_1) - \\text{Cov}(r_1, r_2)$$\n$$\\sigma_{a2}^2 = \\text{Var}(r_2) - \\sigma_e^2 = \\text{Var}(r_2) - \\text{Cov}(r_1, r_2)$$\n问题将“偶然噪声主导认知误差”定义为平均偶然方差大于认知方差。令 $\\sigma_A^2 = (\\sigma_{a1}^2 + \\sigma_{a2}^2)/2$。该条件为 $\\sigma_A^2 > \\sigma_e^2$。\n\n我们构建一个单边假设检验。备择假设 $H_1$ 对应于我们感兴趣的主张：\n$$H_1: \\sigma_A^2 > \\sigma_e^2$$\n零假设 $H_0$ 是其补集：\n$$H_0: \\sigma_A^2 \\le \\sigma_e^2$$\n为了构建检验，我们定义一个参数 $\\theta = \\sigma_A^2 - \\sigma_e^2$。于是，假设变为 $H_0: \\theta \\le 0$ 对 $H_1: \\theta > 0$。我们用可观测残差的矩来表示 $\\theta$：\n$$\\theta = \\frac{(\\text{Var}(r_1) - \\text{Cov}(r_1, r_2)) + (\\text{Var}(r_2) - \\text{Cov}(r_1, r_2))}{2} - \\text{Cov}(r_1, r_2)$$\n$$\\theta = \\frac{\\text{Var}(r_1) + \\text{Var}(r_2)}{2} - 2\\text{Cov}(r_1, r_2)$$\n我们的检验统计量 $\\hat{\\theta}$ 是 $\\theta$ 的矩估计量，使用从数据对 $\\{(r_{1,i}, r_{2,i})\\}_{i=1}^n$ 计算出的样本统计量得到。令 $\\widehat{\\text{Var}}$ 和 $\\widehat{\\text{Cov}}$ 表示标准无偏样本方差和协方差估计量（分母为 $n-1$）：\n$$\\hat{\\theta} = \\frac{\\widehat{\\text{Var}}(r_1) + \\widehat{\\text{Var}}(r_2)}{2} - 2\\widehat{\\text{Cov}}(r_1, r_2)$$\n$\\hat{\\theta}$ 的一个较大的正值提供了支持 $H_1$ 的证据。我们需要确定观测值 $\\hat{\\theta}_{obs}$ 是否具有统计显著性。我们使用带有 $B=2000$ 个重抽样样本的非参数配对自举法来评估 $\\hat{\\theta}$ 的抽样不确定性。假设检验将在 $\\alpha = 0.05$ 的显著性水平下进行。\n\n对 $H_0: \\theta \\le 0$ 与 $H_1: \\theta > 0$ 的检验可以通过反转 $\\theta$ 的单边置信区间来执行。我们将为 $\\theta$ 构建一个 $(1-\\alpha)$ 的置信下界。如果该下界大于 0，我们则拒绝 $H_0$。使用基本（枢轴）自举法，$\\hat{\\theta} - \\theta$ 的抽样分布可以通过 $\\hat{\\theta}^* - \\hat{\\theta}_{obs}$ 的自举分布来近似，其中 $\\hat{\\theta}^*$ 是在自举样本上计算的统计量。这导出了 $\\theta$ 的一个 $(1-\\alpha)$ 单边置信区间为 $[2\\hat{\\theta}_{obs} - q_{1-\\alpha}, \\infty)$，其中 $q_{1-\\alpha}$ 是自举分布 $\\{\\hat{\\theta}^*_b\\}_{b=1}^B$ 的 $(1-\\alpha)$-分位数。\n\n如果下界大于 $0$，我们拒绝 $H_0$：\n$$2\\hat{\\theta}_{obs} - q_{1-\\alpha} > 0 \\implies 2\\hat{\\theta}_{obs} > q_{1-\\alpha}$$\n对于 $\\alpha=0.05$，决策规则是：如果 $2\\hat{\\theta}_{obs}$ 大于 $\\hat{\\theta}^*$ 的自举分布的第 $95$ 百分位数，则拒绝 $H_0$。如果我们拒绝 $H_0$，我们便得出结论：数据提供了偶然噪声主导认知误差的充分证据。\n\n对于每个测试用例，实现将按以下步骤进行：\n1.  根据指定的分布和随机种子，生成 $n$ 个数据三元组 $(e_i, \\varepsilon_{1,i}, \\varepsilon_{2,i})$。\n2.  计算可观测残差 $r_{1,i} = e_i + \\varepsilon_{1,i}$ 和 $r_{2,i} = e_i + \\varepsilon_{2,i}$。\n3.  从数据对 $(r_{1,i}, r_{2,i})$ 计算观测到的检验统计量 $\\hat{\\theta}_{obs}$。\n4.  生成 $B = 2000$ 个配对自举样本。对于每个自举样本，计算统计量 $\\hat{\\theta}^*_b$。\n5.  确定 $\\{\\hat{\\theta}^*_b\\}$ 经验分布的第 $95$ 百分位数 $q_{0.95}$。\n6.  应用决策规则：如果 $2 \\times \\hat{\\theta}_{obs} > q_{0.95}$，结果为 True；否则为 False。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to run hypothesis tests for all specified cases.\n    \"\"\"\n    test_cases = [\n        {\n            'case_id': 'A', 'n': 800, 'seed': 10, 'model': 'normal',\n            'params': {'var_e': 0.05, 'var_a1': 0.20, 'var_a2': 0.25}\n        },\n        {\n            'case_id': 'B', 'n': 800, 'seed': 20, 'model': 'normal',\n            'params': {'var_e': 0.50, 'var_a1': 0.05, 'var_a2': 0.05}\n        },\n        {\n            'case_id': 'C', 'n': 300, 'seed': 30, 'model': 'normal',\n            'params': {'var_e': 0.10, 'var_a1': 0.10, 'var_a2': 0.10}\n        },\n        {\n            'case_id': 'D', 'n': 1000, 'seed': 40, 'model': 'heteroscedastic',\n            'params': {'var_e': 0.02, 'var_a1_func': lambda i, n: 0.20 * (1 + 0.5 * np.sin(2 * np.pi * (i + 1) / n)),\n                       'var_a2_func': lambda i, n: 0.18 * (1 - 0.5 * np.cos(2 * np.pi * (i + 1) / n))}\n        },\n        {\n            'case_id': 'E', 'n': 500, 'seed': 50, 'model': 'zero_aleatoric',\n            'params': {'var_e': 0.10}\n        },\n        {\n            'case_id': 'F', 'n': 800, 'seed': 60, 'model': 'student_t',\n            'params': {'var_e': 0.01, 'var_a1': 0.25, 'var_a2': 0.25, 'df': 3}\n        },\n    ]\n\n    results = []\n    B = 2000  # Number of bootstrap resamples\n\n    for case in test_cases:\n        rng = np.random.default_rng(case['seed'])\n        n = case['n']\n        params = case['params']\n\n        # Generate error components based on the case model\n        if case['model'] == 'normal':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            eps1 = rng.normal(loc=0, scale=np.sqrt(params['var_a1']), size=n)\n            eps2 = rng.normal(loc=0, scale=np.sqrt(params['var_a2']), size=n)\n        elif case['model'] == 'heteroscedastic':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            indices = np.arange(n)\n            var_a1_i = params['var_a1_func'](indices, n)\n            var_a2_i = params['var_a2_func'](indices, n)\n            eps1 = rng.normal(loc=0, scale=np.sqrt(var_a1_i))\n            eps2 = rng.normal(loc=0, scale=np.sqrt(var_a2_i))\n        elif case['model'] == 'zero_aleatoric':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            eps1 = np.zeros(n)\n            eps2 = np.zeros(n)\n        elif case['model'] == 'student_t':\n            e = rng.normal(loc=0, scale=np.sqrt(params['var_e']), size=n)\n            df = params['df']\n            # Scale standard t-distribution to achieve target variance\n            # Var(c * T_df) = c^2 * df / (df - 2)\n            # c = sqrt(target_var * (df - 2) / df)\n            scale1 = np.sqrt(params['var_a1'] * (df - 2) / df)\n            scale2 = np.sqrt(params['var_a2'] * (df - 2) / df)\n            eps1 = scale1 * rng.standard_t(df, size=n)\n            eps2 = scale2 * rng.standard_t(df, size=n)\n\n        # Compute residuals\n        r1 = e + eps1\n        r2 = e + eps2\n\n        # Perform the hypothesis test\n        decision = perform_hypothesis_test(r1, r2, rng, B)\n        results.append(decision)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef get_theta_hat(r1, r2):\n    \"\"\"\n    Calculates the test statistic theta_hat from a sample of residuals.\n    This function is designed to handle 2D arrays of resamples.\n    \"\"\"\n    n = r1.shape[-1]\n    \n    # Calculate means for each resample\n    mean1 = np.mean(r1, axis=-1, keepdims=True)\n    mean2 = np.mean(r2, axis=-1, keepdims=True)\n\n    # Calculate variances for each resample\n    var1 = np.sum((r1 - mean1)**2, axis=-1) / (n - 1)\n    var2 = np.sum((r2 - mean2)**2, axis=-1) / (n - 1)\n    \n    # Calculate covariances for each resample\n    cov12 = np.sum((r1 - mean1) * (r2 - mean2), axis=-1) / (n - 1)\n    \n    return (var1 + var2) / 2.0 - 2.0 * cov12\n\ndef perform_hypothesis_test(r1, r2, rng, B, alpha=0.05):\n    \"\"\"\n    Performs the one-sided hypothesis test using a paired nonparametric bootstrap.\n    \"\"\"\n    n = len(r1)\n\n    # Calculate observed test statistic\n    theta_obs = get_theta_hat(r1, r2)\n\n    # Generate bootstrap indices\n    bootstrap_indices = rng.integers(0, n, size=(B, n))\n\n    # Create bootstrap resamples\n    r1_resamples = r1[bootstrap_indices]\n    r2_resamples = r2[bootstrap_indices]\n\n    # Calculate test statistic for all bootstrap resamples (vectorized)\n    bootstrap_thetas = get_theta_hat(r1_resamples, r2_resamples)\n\n    # Find the (1-alpha) quantile of the bootstrap distribution\n    q_1_minus_alpha = np.percentile(bootstrap_thetas, 100 * (1 - alpha))\n\n    # Apply the decision rule\n    return 2 * theta_obs > q_1_minus_alpha\n\nsolve()\n```", "id": "3500186"}, {"introduction": "在物理科学应用中，机器学习模型及其不确定性必须与基本的自然法则保持一致。本练习探讨了物理对称性 (如动量守恒和牛顿第三定律) 如何对预测的力协方差矩阵 $\\boldsymbol{\\Sigma}$ 施加严格的代数约束。通过实施一个数值验证测试，您将学会如何判断模型的不确定性估计是否物理上合理，这是构建可信赖的模拟工具的关键一步。[@problem_id:3500194]", "problem": "给定一个概率性机器学习原子间势，对于一个包含 $N$ 个原子的构型，该势会输出一个关于级联力矢量 $\\mathbf{f} \\in \\mathbb{R}^{3N}$ 的高斯预测分布，其均值为 $\\boldsymbol{\\mu} \\in \\mathbb{R}^{3N}$，协方差矩阵为 $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{3N \\times 3N}$。力分量按照原子和笛卡尔坐标轴的顺序排列为 $(F_{1x},F_{1y},F_{1z},F_{2x},\\dots,F_{Nz})$，所有力都以电子伏特每埃（electronvolt per Angstrom）为单位表示，因此每个协方差项的单位是 $(\\text{eV}/\\text{\\AA})^2$。一个源于标量能量的、物理上一致的势必须遵守牛顿第三运动定律和总动量守恒。具体来说，对于任何确定性构型，系统在每个笛卡尔坐标轴上的净力必须为零；对于孤立相互作用的两个原子，它们之间的力必须大小相等、方向相反。在一个高斯预测模型中，这些物理对称性转化为对协方差矩阵的线性代数约束。\n\n从协方差的基本定义以及牛顿第三定律和动量守恒的陈述出发，推导一个数值测试，用于验证预测的力协方差矩阵 $\\boldsymbol{\\Sigma}$ 是否在给定的容差 $\\varepsilon$ 内满足这些约束。您的测试必须检查以下条件：\n\n- 对称性一致性：$\\|\\boldsymbol{\\Sigma} - \\boldsymbol{\\Sigma}^\\top\\|_{\\infty} \\le \\varepsilon$。\n- 容差内的半正定性：最小特征值 $\\lambda_{\\min}(\\boldsymbol{\\Sigma}) \\ge -\\varepsilon$。\n- 动量守恒引起的线性约束：对于每个原子索引 $i \\in \\{1,\\dots,N\\}$ 和笛卡尔坐标轴 $\\alpha,\\beta \\in \\{x,y,z\\}$，协方差必须满足 $\\left|\\sum_{j=1}^{N} \\Sigma_{(i\\alpha),(j\\beta)}\\right| \\le \\varepsilon$。\n- 双原子系统（$N=2$）的成对作用-反作用结构：对于所有 $\\alpha,\\beta \\in \\{x,y,z\\}$，3x3 的协方差块必须与 $\\mathbf{f}_2 = -\\mathbf{f}_1$ 一致，这意味着 $|\\Sigma_{(1\\alpha),(2\\beta)} + \\Sigma_{(1\\alpha),(1\\beta)}| \\le \\varepsilon$、 $|\\Sigma_{(2\\alpha),(1\\beta)} + \\Sigma_{(1\\alpha),(1\\beta)}| \\le \\varepsilon$ 和 $|\\Sigma_{(2\\alpha),(2\\beta)} - \\Sigma_{(1\\alpha),(1\\beta)}| \\le \\varepsilon$。\n\n基于这些推导出的检查，实现一个程序，该程序接受一组固定的测试协方差矩阵和容差，并为每种情况返回一个布尔值，指示是否所有检查都通过。\n\n使用以下测试套件。为清晰起见，分量到索引的映射定义为 $m(i,\\alpha) = 3(i-1) + \\gamma(\\alpha)$，其中在公式中使用从1开始的索引时，$\\gamma(x)=1, \\gamma(y)=2, \\gamma(z)=3$；在代码中，您可以使用从0开始的索引，此时 $\\gamma(x)=0, \\gamma(y)=1, \\gamma(z)=2$。\n\n- 情况1（两个原子，物理上一致）：$N=2$，容差 $\\varepsilon = 10^{-8}$，且\n  $$\n  \\mathbf{C} = \\begin{bmatrix}\n  0.40  0.05  -0.02 \\\\\n  0.05  0.30  0.01 \\\\\n  -0.02  0.01  0.50\n  \\end{bmatrix}, \\quad\n  \\boldsymbol{\\Sigma} = \\begin{bmatrix}\n  \\mathbf{C}  -\\mathbf{C} \\\\\n  -\\mathbf{C}  \\mathbf{C}\n  \\end{bmatrix}.\n  $$\n- 情况2（两个原子，违反作用-反作用耦合）：$N=2$，容差 $\\varepsilon = 10^{-3}$。从情况1开始，对 $(F_{1x},F_{2x})$ 的互协方差项添加一个对称扰动 $\\delta = 2\\times 10^{-2}$，使得 $\\Sigma_{(1x),(2x)} \\leftarrow \\Sigma_{(1x),(2x)} + \\delta$ 且 $\\Sigma_{(2x),(1x)} \\leftarrow \\Sigma_{(2x),(1x)} + \\delta$。\n- 情况3（三个原子，经投影以满足动量守恒）：$N=3$，容差 $\\varepsilon = 10^{-8}$。按如下方式构建 $\\boldsymbol{\\Sigma}$。令 $\\mathbf{v}_x,\\mathbf{v}_y,\\mathbf{v}_z \\in \\mathbb{R}^{9}$ 为三个向量，其在对应所有原子的 $x$, $y$, $z$ 分量的索引处为1，其余位置为0。构成 $\\mathbf{V} = [\\mathbf{v}_x, \\mathbf{v}_y, \\mathbf{v}_z] \\in \\mathbb{R}^{9 \\times 3}$ 和投影算子 $\\mathbf{P} = \\mathbf{I}_{9} - \\mathbf{V}(\\mathbf{V}^\\top \\mathbf{V})^{-1}\\mathbf{V}^\\top$。使用固定的随机种子 $123$，抽取一个稠密矩阵 $\\mathbf{M} \\in \\mathbb{R}^{9 \\times 9}$，其元素为独立的标准正态分布项，并设置 $\\mathbf{G} = \\mathbf{M}\\mathbf{M}^\\top$。定义 $\\boldsymbol{\\Sigma} = \\mathbf{P}\\mathbf{G}\\mathbf{P}^\\top + 10^{-6}\\,\\mathbf{P}$。\n- 情况4（三个原子，沿 $x$ 轴违反动量守恒）：$N=3$，容差 $\\varepsilon = 10^{-6}$。从情况3开始，设置 $\\boldsymbol{\\Sigma} \\leftarrow \\boldsymbol{\\Sigma} + a\\,\\mathbf{v}_x \\mathbf{v}_x^\\top$，其中 $a = 10^{-3}$。\n- 情况5（两个原子，边界容差）：$N=2$，容差 $\\varepsilon = 10^{-5}$。从情况1开始，对 $(F_{1y},F_{2y})$ 的互协方差项添加一个对称扰动 $\\delta = 10^{-5}$，使得 $\\Sigma_{(1y),(2y)} \\leftarrow \\Sigma_{(1y),(2y)} + \\delta$ 且 $\\Sigma_{(2y),(1y)} \\leftarrow \\Sigma_{(2y),(1y)} + \\delta$。\n\n您的程序应为每种情况计算一个布尔值，指示是否所有上述检查都在指定的容差内通过。您的程序应生成单行输出，其中包含用方括号括起来并以逗号分隔的结果列表（例如，`[result1,result2,result3,result4,result5]`）。不应打印任何其他文本。不涉及角度。所有物理量应在适用的情况下以 $(\\text{eV}/\\text{\\AA})$ 和 $(\\text{eV}/\\text{\\AA})^2$ 处理；然而，输出是布尔值，因此是无单位的。", "solution": "对预测的力协方差矩阵 $\\boldsymbol{\\Sigma}$ 进行物理一致性验证，是机器学习原子间势不确定性量化中的关键一步。一个具有物理意义的势必须遵循自然界的基本对称性，这些对称性转化为对其预测分布各阶矩的精确代数约束。本问题要求推导并实现一个数值测试，以验证四个此类约束：对称性、半正定性、动量守恒，以及双原子系统的成对作用-反作用。\n\n我们首先将从相应的物理原理推导每个数值测试的理论依据。力矢量表示为 $\\mathbf{f} \\in \\mathbb{R}^{3N}$，其中 $N$ 是原子数。协方差矩阵 $\\boldsymbol{\\Sigma}$ 的一个元素是 $\\Sigma_{(i\\alpha),(j\\beta)} = \\text{Cov}(F_{i\\alpha}, F_{j\\beta})$，其中 $F_{i\\alpha}$ 是作用在原子 $i \\in \\{1, \\dots, N\\}$ 上沿笛卡尔坐标轴 $\\alpha \\in \\{x,y,z\\}$ 的力分量。\n\n**1. 协方差矩阵的对称性**\n根据定义，协方差算子是对称的：对于任意两个随机变量 $X$ 和 $Y$，有 $\\text{Cov}(X, Y) = \\text{Cov}(Y, X)$。因此，力协方差矩阵必须是对称的，即 $\\Sigma_{(i\\alpha),(j\\beta)} = \\Sigma_{(j\\beta),(i\\alpha)}$。在矩阵表示法中，这写作 $\\boldsymbol{\\Sigma} = \\boldsymbol{\\Sigma}^\\top$。由于数值计算中的有限精度，我们在一个容差 $\\varepsilon > 0$ 内验证此属性。无穷范数 $\\|\\mathbf{A}\\|_{\\infty} = \\max_{i} \\sum_{j} |A_{ij}|$ 用于衡量与完美对称性的偏差。\n数值测试为：\n$$ \\|\\boldsymbol{\\Sigma} - \\boldsymbol{\\Sigma}^\\top\\|_{\\infty} \\le \\varepsilon $$\n\n**2. 半正定性**\n协方差矩阵必须是半正定的。这是随机变量任意线性组合的方差必须为非负这一事实的直接结果。对于一个任意的系数向量 $\\mathbf{a} \\in \\mathbb{R}^{3N}$，标量随机变量 $Z = \\mathbf{a}^\\top \\mathbf{f}$ 的方差由 $\\text{Var}(Z) = \\mathbf{a}^\\top \\boldsymbol{\\Sigma} \\mathbf{a}$ 给出。由于方差不能为负，我们必须有 $\\mathbf{a}^\\top \\boldsymbol{\\Sigma} \\mathbf{a} \\ge 0$ 对所有 $\\mathbf{a}$ 成立。这是半正定矩阵的定义。一个实对称半正定矩阵的关键性质是其所有特征值 $\\lambda_k$ 均为非负。\n在数值上，小的浮点误差可能导致小的负特征值。因此，测试被放宽为检查最小特征值 $\\lambda_{\\min}$ 是否不是“太负”：\n$$ \\lambda_{\\min}(\\boldsymbol{\\Sigma}) \\ge -\\varepsilon $$\n\n**3. 动量守恒**\n一个孤立原子系统的总势能对所有原子位置的统一平移是不变的。根据 Noether 定理，这种对称性意味着总线性动量守恒。对于一个仅依赖于位置的势，这意味着整个系统上的净力必须为零。对于每个笛卡尔坐标轴 $\\alpha \\in \\{x,y,z\\}$，这转化为逐点约束：\n$$ \\sum_{i=1}^{N} F_{i\\alpha} = 0 $$\n在一个概率模型中，这条物理定律必须对力的每一次实现（样本）都成立。如果标量随机变量 $S_\\beta = \\sum_{j=1}^{N} F_{j\\beta}$ 恒等于零，那么它的均值和方差必须为零。此外，它与任何其他随机变量的协方差也必须为零。因此，我们要求任何单个力分量 $F_{i\\alpha}$ 与总力分量 $S_\\beta$ 的协方差对于所有 $i, \\alpha, \\beta$ 都为零：\n$$ \\text{Cov}(F_{i\\alpha}, S_\\beta) = \\text{Cov}\\left(F_{i\\alpha}, \\sum_{j=1}^{N} F_{j\\beta}\\right) = 0 $$\n利用协方差算子的线性性质：\n$$ \\sum_{j=1}^{N} \\text{Cov}(F_{i\\alpha}, F_{j\\beta}) = \\sum_{j=1}^{N} \\Sigma_{(i\\alpha),(j\\beta)} = 0 $$\n这个约束必须对所有 $i \\in \\{1,\\dots,N\\}$ 和所有 $\\alpha, \\beta \\in \\{x,y,z\\}$ 成立。相应的数值测试允许一个小的容差 $\\varepsilon$：\n$$ \\left|\\sum_{j=1}^{N} \\Sigma_{(i\\alpha),(j\\beta)}\\right| \\le \\varepsilon $$\n\n**4. 双原子系统的成对作用-反作用**\n对于一个仅包含两个原子（$N=2$）的孤立系统，牛顿第三定律规定，原子1对原子2施加的力与原子2对原子1施加的力大小相等、方向相反。因此，作用在每个原子上的总力 $\\mathbf{f}_1$ 和 $\\mathbf{f}_2$ 通过 $\\mathbf{f}_2 = -\\mathbf{f}_1$ 相关联。这是一个比动量守恒（$\\mathbf{f}_1 + \\mathbf{f}_2 = \\mathbf{0}$）更强的条件。\n这个关系必须对每个分量 $F_{2\\alpha} = -F_{1\\alpha}$ 在预测分布的每个样本中都成立。这对整个 $6 \\times 6$ 矩阵 $\\boldsymbol{\\Sigma}$ 的 $3 \\times 3$ 协方差块施加了严格的关系。设 $\\mathbf{C}_{ij}$ 为这样一个块，使得 $(\\mathbf{C}_{ij})_{\\alpha\\beta} = \\Sigma_{(i\\alpha),(j\\beta)}$。\n利用协方差的性质：\n-   $\\Sigma_{(1\\alpha),(2\\beta)} = \\text{Cov}(F_{1\\alpha}, F_{2\\beta}) = \\text{Cov}(F_{1\\alpha}, -F_{1\\beta}) = -\\text{Cov}(F_{1\\alpha}, F_{1\\beta}) = -\\Sigma_{(1\\alpha),(1\\beta)}$。\n    这意味着 $\\mathbf{C}_{12} = -\\mathbf{C}_{11}$。数值测试为 $|\\Sigma_{(1\\alpha),(2\\beta)} + \\Sigma_{(1\\alpha),(1\\beta)}| \\le \\varepsilon$。\n-   $\\Sigma_{(2\\alpha),(1\\beta)} = \\text{Cov}(F_{2\\alpha}, F_{1\\beta}) = \\text{Cov}(-F_{1\\alpha}, F_{1\\beta}) = -\\text{Cov}(F_{1\\alpha}, F_{1\\beta}) = -\\Sigma_{(1\\alpha),(1\\beta)}$。\n    这意味着 $\\mathbf{C}_{21} = -\\mathbf{C}_{11}$。数值测试为 $|\\Sigma_{(2\\alpha),(1\\beta)} + \\Sigma_{(1\\alpha),(1\\beta)}| \\le \\varepsilon$。\n-   $\\Sigma_{(2\\alpha),(2\\beta)} = \\text{Cov}(F_{2\\alpha}, F_{2\\beta}) = \\text{Cov}(-F_{1\\alpha}, -F_{1\\beta}) = (-1)(-1)\\text{Cov}(F_{1\\alpha}, F_{1\\beta}) = \\Sigma_{(1\\alpha),(1\\beta)}$。\n    这意味着 $\\mathbf{C}_{22} = \\mathbf{C}_{11}$。数值测试为 $|\\Sigma_{(2\\alpha),(2\\beta)} - \\Sigma_{(1\\alpha),(1\\beta)}| \\le \\varepsilon$。\n\n算法设计包括实现一个函数，该函数顺序执行这四个检查。如果任何检查失败，函数返回 `False`；如果所有检查都通过，则返回 `True`。然后将此函数应用于提供的每个测试用例。", "answer": "```python\nimport numpy as np\n\ndef validate_covariance(N, Sigma, epsilon):\n    \"\"\"\n    Validates a force covariance matrix against physical constraints.\n\n    Args:\n        N (int): The number of atoms.\n        Sigma (np.ndarray): The 3N x 3N covariance matrix.\n        epsilon (float): The numerical tolerance for all checks.\n\n    Returns:\n        bool: True if all checks pass, False otherwise.\n    \"\"\"\n    dim = 3 * N\n    if Sigma.shape != (dim, dim):\n        raise ValueError(\"Sigma dimensions are inconsistent with N.\")\n\n    # 1. Symmetry Check\n    sym_diff = Sigma - Sigma.T\n    norm_inf_sym = np.linalg.norm(sym_diff, ord=np.inf)\n    if not (norm_inf_sym <= epsilon):\n        return False\n\n    # 2. Positive Semidefiniteness Check\n    # Use eigh for symmetric matrices; it is more stable and guarantees real eigenvalues.\n    try:\n        eigvals = np.linalg.eigh(Sigma)[0]\n        min_eig = np.min(eigvals)\n        if not (min_eig >= -epsilon):\n            return False\n    except np.linalg.LinAlgError:\n         # Matrix is not Hermitian or did not converge\n        return False\n\n\n    # 3. Momentum Conservation Check\n    # For each beta, sum of Sigma_i,j over j where j is a beta component must be zero.\n    V = np.zeros((dim, 3))\n    for axis in range(3):\n        V[axis::3, axis] = 1.0\n    \n    # S contains the sums for each row, for each total force component v_x, v_y, v_z\n    S = Sigma @ V\n    max_sum_violation = np.max(np.abs(S))\n    if not (max_sum_violation <= epsilon):\n        return False\n\n    # 4. Pairwise Action-Reaction Check (for N=2 only)\n    if N == 2:\n        C11 = Sigma[0:3, 0:3]\n        C12 = Sigma[0:3, 3:6]\n        C21 = Sigma[3:6, 0:3]\n        C22 = Sigma[3:6, 3:6]\n\n        # Check 1: C12 = -C11\n        if not (np.max(np.abs(C12 + C11)) <= epsilon):\n            return False\n        \n        # Check 2: C21 = -C11\n        if not (np.max(np.abs(C21 + C11)) <= epsilon):\n            return False\n            \n        # Check 3: C22 = C11\n        if not (np.max(np.abs(C22 - C11)) <= epsilon):\n            return False\n\n    return True\n\ndef solve():\n    \"\"\"\n    Main function to construct and validate the test suite of covariance matrices.\n    \"\"\"\n    test_cases = []\n\n    # Case 1: Two atoms, physically consistent\n    C1 = np.array([\n        [0.40, 0.05, -0.02],\n        [0.05, 0.30, 0.01],\n        [-0.02, 0.01, 0.50]\n    ])\n    Sigma1 = np.block([[C1, -C1], [-C1, C1]])\n    test_cases.append({'N': 2, 'Sigma': Sigma1, 'epsilon': 1e-8})\n\n    # Case 2: Two atoms, violated action-reaction coupling\n    Sigma2 = np.copy(Sigma1)\n    delta2 = 2e-2\n    # Indices for (F_1x, F_2x) are 0 and 3\n    Sigma2[0, 3] += delta2\n    Sigma2[3, 0] += delta2\n    test_cases.append({'N': 2, 'Sigma': Sigma2, 'epsilon': 1e-3})\n\n    # Case 3: Three atoms, projected to satisfy momentum conservation\n    N3 = 3\n    dim3 = 3 * N3\n    V3 = np.zeros((dim3, 3))\n    V3[0::3, 0] = 1.  # v_x\n    V3[1::3, 1] = 1.  # v_y\n    V3[2::3, 2] = 1.  # v_z\n    P3 = np.eye(dim3) - V3 @ np.linalg.inv(V3.T @ V3) @ V3.T\n    rng = np.random.default_rng(123)\n    M3 = rng.standard_normal((dim3, dim3))\n    G3 = M3 @ M3.T\n    # P is symmetric, so P.T = P\n    Sigma3 = P3 @ G3 @ P3 + 1e-6 * P3\n    test_cases.append({'N': N3, 'Sigma': Sigma3, 'epsilon': 1e-8})\n\n    # Case 4: Three atoms, violated momentum conservation along x\n    Sigma4 = np.copy(Sigma3)\n    a4 = 1e-3\n    v_x4 = V3[:, 0]\n    Sigma4 += a4 * np.outer(v_x4, v_x4)\n    test_cases.append({'N': N3, 'Sigma': Sigma4, 'epsilon': 1e-6})\n\n    # Case 5: Two atoms, boundary tolerance\n    Sigma5 = np.copy(Sigma1)\n    delta5 = 1e-5\n    # Indices for (F_1y, F_2y) are 1 and 4\n    Sigma5[1, 4] += delta5\n    Sigma5[4, 1] += delta5\n    test_cases.append({'N': 2, 'Sigma': Sigma5, 'epsilon': 1e-5})\n\n    results = []\n    for case in test_cases:\n        result = validate_covariance(case['N'], case['Sigma'], case['epsilon'])\n        results.append(str(result))\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3500194"}]}