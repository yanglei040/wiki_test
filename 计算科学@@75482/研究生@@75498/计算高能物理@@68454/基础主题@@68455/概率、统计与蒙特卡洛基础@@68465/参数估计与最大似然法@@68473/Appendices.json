{"hands_on_practices": [{"introduction": "在高能物理中，设计新实验或评估现有实验的潜力时，一个核心问题是：我们期望的发现灵敏度有多高？为了回答这个问题，我们需要一个标准化的方法来计算预期的统计显著性，以摆脱单个随机实验中泊松波动的具体影响。Asimov 数据集 [@problem_id:3526337] 为此提供了一个强大的理论工具，它将观测数据设为其在特定假设下的期望值，从而能够推导出中位数预期显著性。这项实践将引导你通过解析计算，为一个简单的计数实验推导出这个重要的公式，加深对最大似然检验统计量和实验设计规划的理解。", "problem": "为了搜寻新的高能物理信号，我们进行了一项单仓计数实验。观测到的事件数被建模为一个泊松随机变量，其均值为 $\\nu(\\mu)=\\mu s + b$。其中，$\\mu \\geq 0$ 是用于缩放标称预期信号产额 $s$ 的信号强度参数，而 $b$ 是已知的预期本底产额。对于观测到的计数 $n$，其似然是泊松概率质量函数 $L(n \\mid \\mu)=\\text{Pois}(n \\mid \\mu s + b)$。为了检验发现假设，原假设为 $H_{0}:\\mu=0$，备择假设为 $H_{1}:\\mu>0$。用于发现的单边剖面似然比检验统计量定义为 $q_{0}=-2\\ln\\lambda(0)$，其中 $\\lambda(0)=\\dfrac{L(n \\mid \\mu=0)}{L(n \\mid \\hat{\\mu})}$，而 $\\hat{\\mu}$ 是在物理约束 $\\mu\\geq 0$ 下 $\\mu$ 的最大似然估计。\n\n在此背景下定义阿西莫夫数据集。然后，在信号加本底假设的阿西莫夫假设下（即，数据被视为等于其在 $\\mu=1$ 时的期望值），推导中位预期发现检验统计量 $q_{0}$ 和相应的中位预期显著性 $Z=\\sqrt{q_{0}}$ 作为 $s$ 和 $b$ 的函数的闭式解析表达式。你的最终答案必须是单个闭式表达式，或一对并列的闭式表达式，且不得包含任何数值代入。无需四舍五入。将最终显著性表示为无单位的纯数。", "solution": "问题陈述已经过验证，被认为是科学上可靠、适定、客观和完整的。我们可以开始求解。\n\n该问题要求在信号加本底假设（$\\mu=1$）的阿西莫夫假设下，求出中位预期发现检验统计量 $q_{0}$ 和相应的中位预期显著性 $Z$。推导过程分为四个步骤：（1）定义阿西莫夫数据集，（2）为该数据集找到最大似然估计（$\\hat{\\mu}$），（3）计算检验统计量 $q_{0}$，以及（4）推导显著性 $Z$。\n\n首先，我们定义阿西莫夫数据集。阿西莫夫数据集是一个代表性数据集，其中观测数据被设定为在特定假设下的期望值。对于本问题，该假设是信号强度为 $\\mu=1$ 的信号加本底假设。预期事件数 $\\nu(\\mu)$ 由 $\\nu(\\mu) = \\mu s + b$ 给出。在假设 $\\mu=1$ 下，预期事件计数为 $\\nu(1) = (1)s + b = s+b$。因此，阿西莫夫数据集由单个观测计数 $n_{A} = s+b$ 组成。注意，虽然观测计数必须是整数，但阿西莫夫数据集是一个理论构造，其中 $n_A$ 可以是一个非整数实数，因为泊松概率质量函数可以使用伽马函数推广到非整数参数。\n\n第二，我们确定在给定阿西莫夫观测值 $n = n_{A} = s+b$ 的情况下，信号强度参数 $\\mu$ 的最大似然估计（MLE）$\\hat{\\mu}$。似然函数是泊松概率 $L(n \\mid \\mu) = \\frac{(\\mu s + b)^{n} \\exp(-(\\mu s + b))}{n!}$。使用对数似然函数 $\\ln L$ 更为方便：\n$$ \\ln L(n \\mid \\mu) = n \\ln(\\mu s + b) - (\\mu s + b) - \\ln(n!) $$\n为了找到无约束的最大似然估计 $\\tilde{\\mu}$，我们将 $\\ln L$ 对 $\\mu$ 求导并令其为零：\n$$ \\frac{\\partial}{\\partial \\mu} \\ln L(n \\mid \\mu) = \\frac{ns}{\\mu s + b} - s = 0 $$\n假设 $s>0$，我们可以解出 $\\mu$：\n$$ \\frac{ns}{\\tilde{\\mu} s + b} = s \\implies n = \\tilde{\\mu} s + b \\implies \\tilde{\\mu} = \\frac{n-b}{s} $$\n将阿西莫夫数据 $n = n_{A} = s+b$ 代入此表达式，得到阿西莫夫数据集的无约束最大似然估计：\n$$ \\tilde{\\mu}_{A} = \\frac{(s+b) - b}{s} = \\frac{s}{s} = 1 $$\n问题陈述了物理约束 $\\mu \\geq 0$。因此，有约束的最大似然估计 $\\hat{\\mu}$ 由 $\\hat{\\mu} = \\max(0, \\tilde{\\mu})$ 给出。由于我们发现 $\\tilde{\\mu}_{A}=1$，它大于 $0$，因此阿西莫夫数据集的有约束最大似然估计为 $\\hat{\\mu}_{A} = 1$。\n\n第三，我们计算检验统计量 $q_{0}$。检验统计量定义为 $q_{0} = -2\\ln\\lambda(0)$，其中剖面似然比 $\\lambda(0)$ 由下式给出：\n$$ \\lambda(0) = \\frac{L(n \\mid \\mu=0)}{L(n \\mid \\hat{\\mu})} $$\n我们针对阿西莫夫数据集 $n=n_A=s+b$ 及其对应的最大似然估计 $\\hat{\\mu}=\\hat{\\mu}_A=1$ 来计算此值。\n分子中的似然是在原假设（$H_{0}: \\mu=0$）下计算的：\n$$ L(n_{A} \\mid \\mu=0) = \\text{Pois}(s+b \\mid b) = \\frac{b^{s+b} \\exp(-b)}{(s+b)!} $$\n分母中的似然是在最大似然估计值 $\\hat{\\mu}=1$ 处计算的：\n$$ L(n_{A} \\mid \\hat{\\mu}=1) = \\text{Pois}(s+b \\mid s+b) = \\frac{(s+b)^{s+b} \\exp(-(s+b))}{(s+b)!} $$\n那么，比率 $\\lambda(0)$ 为：\n$$ \\lambda(0) = \\frac{b^{s+b} \\exp(-b)}{(s+b)^{s+b} \\exp(-(s+b))} = \\left(\\frac{b}{s+b}\\right)^{s+b} \\exp(-(b-(s+b))) = \\left(\\frac{b}{s+b}\\right)^{s+b} \\exp(s) $$\n现在，我们通过对此表达式取 $-2\\ln$ 来计算 $q_{0}$：\n$$ q_{0} = -2\\ln\\left[ \\left(\\frac{b}{s+b}\\right)^{s+b} \\exp(s) \\right] = -2 \\left[ (s+b)\\ln\\left(\\frac{b}{s+b}\\right) + s \\right] $$\n利用属性 $\\ln(x/y) = -\\ln(y/x)$，我们可以将其重写为：\n$$ q_{0} = -2 \\left[ -(s+b)\\ln\\left(\\frac{s+b}{b}\\right) + s \\right] = 2(s+b)\\ln\\left(\\frac{s+b}{b}\\right) - 2s $$\n提出因子 $2$ 并重写对数的自变量，得到中位预期检验统计量的最终表达式，通常记为 $q_{0,A}$：\n$$ q_{0} = 2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right] $$\n此表达式在 $s>0$ 和 $b>0$ 时有效。\n\n最后，中位预期显著性 $Z$ 定义为 $Z = \\sqrt{q_{0}}$。对 $q_{0}$ 的表达式取平方根，得到：\n$$ Z = \\sqrt{2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right]} $$\n这就是著名的“阿西莫夫公式”，用于计算简单计数实验的中位显著性。", "answer": "$$ \\boxed{ \\begin{pmatrix} 2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right] & \\sqrt{2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right]} \\end{pmatrix} } $$", "id": "3526337"}, {"introduction": "在实验物理学中，精确测量效率（如触发效率或粒子鉴别效率）是一项基本任务，其结果通常以置信区间的形式呈现。然而，不同的区间构造方法在小样本量或效率接近 $0$ 或 $1$ 的边界情况下，其表现可能大相径庭。这项编码实践 [@problem_id:3526356] 将让你深入研究这个问题，通过计算不同区间（包括精确的 Clopper-Pearson 区间和基于正态近似的区间）的真实“覆盖概率”，来评估它们的性能。这有助于培养对置信区间性质的批判性认识，确保我们报告的测量不确定度是可靠和诚实的。", "problem": "您正在设计一项与高能碰撞实验中的探测器和触发器效率测量相关的计算研究，其中效率通过重复的独立伯努利试验来估计。考虑一个具有未知成功概率 $p \\in (0,1)$ 和固定试验次数 $N \\in \\mathbb{N}$ 的二项数据生成过程。对于任意观测到的成功次数 $k \\in \\{0,1,\\dots,N\\}$，一种置信区间构建方法会生成一个区间 $I(k;N,\\alpha) = [\\ell(k;N,\\alpha), u(k;N,\\alpha)]$，其旨在以名义覆盖概率 $1-\\alpha$ 包含真实的 $p$ 值，其中 $\\alpha \\in (0,1)$ 是显著性水平。我们关注两类区间：\n- 通过反演等尾二项检验获得的精确区间 (Clopper–Pearson)。\n- 源自大样本近似的渐近区间，包括围绕最大似然估计量的正态近似和分数检验反演 (Wilson)。\n\n您的任务是实现一个精确覆盖率计算，并比较这三种方法在小样本情况下的覆盖性质。您的实现必须基于以下基本原理：\n- 二项概率质量函数为 $P(K=k \\mid p,N) = \\binom{N}{k} p^k (1-p)^{N-k}$。\n- 在二项模型下，$p$ 的最大似然估计量是 $\\hat{p} = k/N$。\n- 一个将 $k$ 映射到区间 $I(k;N,\\alpha)$ 的方法的覆盖率，是指当 $K \\sim \\text{Binomial}(N,p)$ 时，$p \\in I(K;N,\\alpha)$ 的概率。该覆盖率可以通过对所有满足 $p \\in I(k;N,\\alpha)$ 的 $k$ 值对应的二项概率进行求和来精确计算，即：\n$$ \\text{Cov}(p;N,\\alpha) = \\sum_{k=0}^{N} \\mathbf{1}\\!\\left\\{ p \\in I(k;N,\\alpha) \\right\\} \\binom{N}{k} p^k (1-p)^{N-k}. $$\n未提供其他公式。您可以使用标准的特殊函数和数值方法来实现任何必要的检验反演或渐近近似。\n\n将以下区间方法实现为 $k$、$N$ 和 $\\alpha$ 的函数：\n- 精确的 Clopper–Pearson 等尾区间，通过反演每个尾部的二项累积分布函数来定义。\n- 渐近 Wald 区间，通过在最大似然估计量 $\\hat{p}$ 周围应用正态近似，并使用观测到的费雪信息作为方差代理来获得。\n- 渐近 Wilson 分数区间，通过反演大样本分数检验来获得。\n\n对于下面定义的每个测试用例，通过如上式所示对 $k \\in \\{0,\\dots,N\\}$ 进行求和，计算每种方法在指定的真实 $p$ 值下的精确频率学派覆盖率。然后报告其保守性或覆盖不足，定义为与名义值的偏差：\n$$ \\Delta(p;N,\\alpha) = \\text{Cov}(p;N,\\alpha) - (1-\\alpha). $$\n正的 $\\Delta$ 表示保守性；负的 $\\Delta$ 表示覆盖不足。所有概率必须表示为小数。将每个报告的偏差四舍五入到六位小数。\n\n测试套件输入 (每个元组为 $(N,p,\\alpha)$):\n- 用例 1: $N=1$, $p=0.5$, $\\alpha=0.32$。\n- 用例 2: $N=5$, $p=0.05$, $\\alpha=0.32$。\n- 用例 3: $N=5$, $p=0.5$, $\\alpha=0.32$。\n- 用例 4: $N=10$, $p=0.5$, $\\alpha=0.05$。\n- 用例 5: $N=10$, $p=0.95$, $\\alpha=0.10$。\n- 用例 6: $N=10$, $p=0.01$, $\\alpha=0.32$。\n\n您的程序必须：\n- 对于每个用例，计算分别对应于 Clopper–Pearson、Wald 和 Wilson 方法的三个偏差 $\\Delta_{\\text{CP}}$、$\\Delta_{\\text{Wald}}$ 和 $\\Delta_{\\text{Wilson}}$。\n- 将每个用例的结果汇总成一个浮点数列表的列表，顺序为每个用例的 $[\\Delta_{\\text{CP}},\\Delta_{\\text{Wald}},\\Delta_{\\text{Wilson}}]$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素本身是对应一个测试用例的三个四舍五入后偏差的方括号逗号分隔列表，不含任何空格。例如：\"[[x11,x12,x13],[x21,x22,x23],...]\"，其中每个 $x_{ij}$ 是一个四舍五入到六位小数的十进制数。", "solution": "该问题要求实现并比较三种不同的二项比例 $p$ 置信区间方法。该比较将通过在一组指定的测试用例上，为每种方法计算精确的频率学派覆盖概率来进行。需要报告的结果是此精确覆盖率与名义覆盖水平 $1-\\alpha$ 之间的偏差。\n\n首先，我们形式化待评估的三种区间构建方法：Clopper-Pearson (精确) 区间、Wald (渐近) 区间和 Wilson (分数) 区间。设 $N$ 为试验次数，$k \\in \\{0, 1, \\dots, N\\}$ 为观测到的成功次数，$\\alpha \\in (0,1)$ 为显著性水平。名义置信水平为 $1-\\alpha$。\n\n**1. Clopper-Pearson (CP) 区间**\nClopper-Pearson 区间是通过反演两个独立的单边二项检验构建的，每个检验的显著性水平均为 $\\alpha/2$。区间 $[\\ell_{CP}, u_{CP}]$ 的端点由以下方程定义：\n$$ P(K \\ge k \\mid p=\\ell_{CP}) = \\sum_{i=k}^{N} \\binom{N}{i} \\ell_{CP}^i (1-\\ell_{CP})^{N-i} = \\frac{\\alpha}{2} $$\n$$ P(K \\le k \\mid p=u_{CP}) = \\sum_{i=0}^{k} \\binom{N}{i} u_{CP}^i (1-u_{CP})^{N-i} = \\frac{\\alpha}{2} $$\n必须求解这些方程以得到 $\\ell_{CP}$ 和 $u_{CP}$。这些和式与正则化不完全贝塔函数有关，而正则化不完全贝塔函数又将它们与贝塔分布的累积分布函数 (CDF) 联系起来。这使得可以使用贝塔分布的分位数 (或百分点函数，PPF) 直接求解端点。\n\n对于 $k \\in \\{1, \\dots, N-1\\}$：\n下界 $\\ell_{CP}$ 是参数为 $(k, N-k+1)$ 的贝塔分布的 $\\alpha/2$ 分位数。\n$$ \\ell_{CP}(k, N, \\alpha) = \\text{Beta.ppf}(\\alpha/2; k, N-k+1) $$\n上界 $u_{CP}$ 是参数为 $(k+1, N-k)$ 的贝塔分布的 $1-\\alpha/2$ 分位数。\n$$ u_{CP}(k, N, \\alpha) = \\text{Beta.ppf}(1-\\alpha/2; k+1, N-k) $$\n对于观测空间的边界存在特殊情况：\n- 如果 $k=0$，则下界为 $\\ell_{CP} = 0$。上界由 $(1-u_{CP})^N = \\alpha/2$ 导出，得出 $u_{CP} = 1 - (\\alpha/2)^{1/N}$。\n- 如果 $k=N$，则上界为 $u_{CP} = 1$。下界由 $\\ell_{CP}^N = \\alpha/2$ 导出，得出 $\\ell_{CP} = (\\alpha/2)^{1/N}$。\n\n根据其构造，Clopper-Pearson 区间保证对所有 $p$ 值都具有至少为 $1-\\alpha$ 的覆盖概率。这一性质使其具有“保守性”。\n\n**2. Wald 区间**\nWald 区间源于对 $p$ 的最大似然估计量 (MLE) $\\hat{p} = k/N$ 的抽样分布的正态近似。对于大的 $N$，中心极限定理表明 $\\hat{p}$ 近似服从均值为 $p$、方差为 $p(1-p)/N$ 的正态分布。Wald 方法通过用 $\\hat{p}$ 替代 $p$ 来估计该方差，即使用“观测到的费雪信息”，得到标准误 $SE = \\sqrt{\\hat{p}(1-\\hat{p})/N}$。\n于是，近似 $1-\\alpha$ 置信区间由下式给出：\n$$ [\\ell_W, u_W] = \\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}} $$\n其中 $z_{\\alpha/2}$ 是来自标准正态分布的临界值，使得 $P(|Z| > z_{\\alpha/2}) = \\alpha$，这对应于 $1-\\alpha/2$ 分位数。这种方法计算简单，但已知在 $N$ 较小或 $p$ 接近 0 或 1 时性能不佳。当 $k=0$ 或 $k=N$ 时会出现一个显著的病态问题，此时 $\\hat{p}$ 分别为 0 或 1。在这些情况下，估计的标准误变为 0，导致零宽度区间 $[0,0]$ 或 $[1,1]$，这通常无法覆盖真实的 $p$。\n\n**3. Wilson (分数) 区间**\nWilson 分数区间也基于正态近似，但它是通过反演分数检验得出的。该检验统计量并未使用 $\\hat{p}$ 替换方差项中的 $p$，而是使用 $p$ 本身的假设值：\n$$ Z(p) = \\frac{\\hat{p}-p}{\\sqrt{p(1-p)/N}} $$\n置信区间是所有使得检验在水平 $\\alpha$ 下不被拒绝的 $p_0$ 值的集合，即 $|Z(p_0)| \\leq z_{\\alpha/2}$。这个条件是关于 $p$ 的一个二次不等式：\n$$ (\\hat{p}-p)^2 \\le z_{\\alpha/2}^2 \\frac{p(1-p)}{N} $$\n求解 $p$ 可得到 Wilson 区间 $[\\ell_{Wils}, u_{Wils}]$ 的端点：\n$$ \\frac{1}{1 + z_{\\alpha/2}^2/N} \\left( \\hat{p} + \\frac{z_{\\alpha/2}^2}{2N} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N} + \\frac{z_{\\alpha/2}^2}{4N^2}} \\right) $$\n该区间比 Wald 区间具有更好的小样本性质。它不围绕 $\\hat{p}$ 对称，并且宽度永不为零，即使在 $k=0$ 或 $k=N$ 时也能生成合理的区间。\n\n**覆盖率计算**\n对于给定的真实参数 $p$，一个区间方法 $I(k;N,\\alpha)$ 的精确频率学派覆盖率是指随机区间 $I(K;N,\\alpha)$ 包含 $p$ 的概率，其中随机变量 $K$ 服从二项分布 $K \\sim \\text{Binomial}(N,p)$。这是通过对所有结果区间覆盖 $p$ 的 $k$ 值的概率进行求和来计算的：\n$$ \\text{Cov}(p;N,\\alpha) = \\sum_{k=0}^{N} \\mathbf{1}\\!\\left\\{ p \\in I(k;N,\\alpha) \\right\\} P(K=k \\mid p,N) $$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，$P(K=k \\mid p,N) = \\binom{N}{k} p^k (1-p)^{N-k}$ 是二项概率质量函数。\n\n对于每个测试用例 $(N, p, \\alpha)$ 和三种区间方法中的每一种，我们都对所有可能的 $k$ 值（从 0到 $N$）执行此求和。我们首先计算给定 $k$ 的区间，然后检查真实的 $p$ 是否位于其中。如果是，我们将相应的二项概率加到一个累加和中，最终得到覆盖率。然后，将与名义值的偏差计算为 $\\Delta = \\text{Cov}(p;N,\\alpha) - (1-\\alpha)$，该值指示了保守性 ($\\Delta > 0$) 或覆盖不足 ($\\Delta < 0$)。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef clopper_pearson_interval(k, N, alpha):\n    \"\"\"\n    Computes the Clopper-Pearson (exact) confidence interval for a binomial proportion.\n    \"\"\"\n    if k == 0:\n        lower = 0.0\n        upper = 1 - (alpha / 2)**(1 / N)\n    elif k == N:\n        lower = (alpha / 2)**(1 / N)\n        upper = 1.0\n    else:\n        lower = stats.beta.ppf(alpha / 2, k, N - k + 1)\n        upper = stats.beta.ppf(1 - alpha / 2, k + 1, N - k)\n    return lower, upper\n\ndef wald_interval(k, N, alpha):\n    \"\"\"\n    Computes the Wald (normal approximation) confidence interval.\n    \"\"\"\n    if N == 0:\n        return 0.0, 1.0\n    p_hat = k / N\n    z = stats.norm.ppf(1 - alpha / 2)\n    se = np.sqrt(p_hat * (1 - p_hat) / N)\n    lower = p_hat - z * se\n    upper = p_hat + z * se\n    return lower, upper\n\ndef wilson_score_interval(k, N, alpha):\n    \"\"\"\n    Computes the Wilson score confidence interval.\n    \"\"\"\n    if N == 0:\n        return 0.0, 1.0\n    p_hat = k / N\n    z = stats.norm.ppf(1 - alpha / 2)\n    z2 = z**2\n    \n    denominator = 1 + z2 / N\n    center = p_hat + z2 / (2 * N)\n    \n    term_under_sqrt = (p_hat * (1 - p_hat) / N) + (z2 / (4 * N**2))\n    half_width = z * np.sqrt(term_under_sqrt)\n    \n    lower = (center - half_width) / denominator\n    upper = (center + half_width) / denominator\n    \n    return lower, upper\n\ndef compute_coverage(N, p, alpha, interval_func):\n    \"\"\"\n    Computes the exact coverage probability for a given interval procedure.\n    \"\"\"\n    coverage = 0.0\n    for k in range(N + 1):\n        lower, upper = interval_func(k, N, alpha)\n        # Add a small epsilon for floating point comparisons at the boundary\n        epsilon = 1e-9\n        if (p >= lower - epsilon) and (p = upper + epsilon):\n            prob = stats.binom.pmf(k, N, p)\n            coverage += prob\n    return coverage\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute deviations.\n    \"\"\"\n    # Test suite input (each tuple is (N, p, alpha))\n    test_cases = [\n        (1, 0.5, 0.32),\n        (5, 0.05, 0.32),\n        (5, 0.5, 0.32),\n        (10, 0.5, 0.05),\n        (10, 0.95, 0.10),\n        (10, 0.01, 0.32),\n    ]\n\n    results = []\n    interval_methods = {\n        'CP': clopper_pearson_interval,\n        'Wald': wald_interval,\n        'Wilson': wilson_score_interval\n    }\n    \n    method_order = ['CP', 'Wald', 'Wilson']\n\n    for N, p, alpha in test_cases:\n        case_results = []\n        nominal_coverage = 1 - alpha\n\n        for method_name in method_order:\n            interval_func = interval_methods[method_name]\n            coverage = compute_coverage(N, p, alpha, interval_func)\n            deviation = coverage - nominal_coverage\n            case_results.append(round(deviation, 6))\n        \n        results.append(case_results)\n\n    # Format the final output string as specified\n    inner_strings = [f\"[{','.join(map(str, row))}]\" for row in results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3526356"}, {"introduction": "在实际的物理分析中，我们使用的模型几乎总是对现实的简化，这种“模型误设”会如何影响我们的测量结果？这项实践 [@problem_id:3526389] 模拟了一个典型的高能物理分析场景：测量一个共振峰的质量。你将构建一个由本征线型（Breit-Wigner分布）和探测器分辨率（高斯函数）卷积而成的 Voigt 分布模型，并研究当分辨率模型不准确时，对质量参数的最大似然估计会产生多大的系统性偏差。这个练习将让你体验从数据生成、无箱似然拟合到系统误差评估的完整流程。", "problem": "考虑一个在高能物理实验中产生的单个共振峰的不变质量测量数据集 $\\{x_i\\}_{i=1}^N$，其中每个测量值 $x_i$ 是受内在线形和探测器分辨率影响的真实共振质量。假设以下基本模型组件，这些组件是该领域的标准，并基于经过充分检验的物理和统计原理：\n\n1. 共振的内在线形由非相对论性 Breit–Wigner 分布描述，该分布对应于位置参数为 $m_0$、标度（半峰全宽的一半）为 $\\gamma = \\Gamma/2$ 的柯西分布，其中 $\\Gamma$ 是自然宽度。归一化的内在概率密度函数为\n$$\nf_{\\mathrm{BW}}(m; m_0, \\gamma) = \\frac{1}{\\pi} \\cdot \\frac{\\gamma}{(m - m_0)^2 + \\gamma^2}.\n$$\n\n2. 探测器分辨率被建模为标准差为 $\\sigma$、均值为零的高斯响应，因此测量质量 $x$ 是从 Breit–Wigner 分布中抽样的真实质量 $m$ 与一个独立的高斯噪声项 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 之和。因此，观测到的 $x$ 的分布是 $f_{\\mathrm{BW}}$ 与高斯分辨率核的卷积：\n$$\nf(x; m, \\sigma, \\gamma) = \\int_{-\\infty}^{\\infty} f_{\\mathrm{BW}}(u; m, \\gamma) \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\!\\left(-\\frac{(x-u)^2}{2\\sigma^2}\\right) \\, du,\n$$\n其中 $m$ 是待估计的共振质量参数，$\\gamma$ 假定为已知。\n\n3. 对于样本 $\\{x_i\\}_{i=1}^N$，在参数 $(m, \\sigma)$ 下的非分组似然函数是每个观测值处的卷积密度之积：\n$$\nL(m, \\sigma) = \\prod_{i=1}^N f(x_i; m, \\sigma, \\gamma),\n$$\n对数似然函数为\n$$\n\\ell(m, \\sigma) = \\sum_{i=1}^N \\log f(x_i; m, \\sigma, \\gamma).\n$$\n\n您的任务：\n\nA. 从上述定义出发，构建非分组似然函数 $L(m,\\sigma)$。将 $f(x; m, \\sigma, \\gamma)$ 的显式归一化形式表达为一个数学上定义良好且其评估在高能物理所有实际参数值下都数值稳定的卷积。您的构建应严格基于卷积的定义和性质以及根据需要使用的已知特殊函数，不得引入任何临时或非标准的近似。\n\nB. 在分辨率模型误设的情况下，实现一个最大似然估计（MLE）$\\hat{m}$：您需要将分辨率模型固定为 $\\sigma_{\\mathrm{model}} = \\sigma_{\\mathrm{true}} + \\Delta\\sigma$，同时保持 $\\gamma$ 已知且恒定，并将 $m$ 作为唯一待通过最大化 $\\ell(m, \\sigma_{\\mathrm{model}})$ 来估计的自由参数。得到的 $\\hat{m}$ 是在误设的分辨率模型下 $m$ 的准最大似然估计（quasi-MLE）。为此一维连续参数使用数值上稳健的优化策略。\n\nC. 对于以下科学上真实且自洽的参数配置测试套件，量化 $\\hat{m}$ 中的偏差，即 $\\hat{m} - m_{\\mathrm{true}}$。在每种情况下，通过从 $f_{\\mathrm{BW}}(u; m_{\\mathrm{true}}, \\gamma)$ 中抽样 $u$ 和独立的 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{true}}^2)$ 来生成合成数据，然后形成 $x = u + \\epsilon$。这种抽样方法与卷积模型完全一致。为了可复现性，请使用指定的随机种子。所有质量必须以 $\\mathrm{GeV}$（在自然单位制中 $c=1$）表示，您的最终输出必须是 $\\mathrm{GeV}$ 为单位的十进制浮点数。\n\n测试套件（每种情况为 $(N, m_{\\mathrm{true}}, \\Gamma, \\sigma_{\\mathrm{true}}, \\Delta\\sigma, \\text{seed})$，其中 $\\gamma=\\Gamma/2$）：\n- 情况1（理想路径，分辨率正确设定）： $(20000, 91.1876, 2.4952, 1.2, 0.0, 31415)$\n- 情况2（中度正向误设）： $(20000, 91.1876, 2.4952, 1.2, +0.3, 27182)$\n- 情况3（中度负向误设）： $(20000, 91.1876, 2.4952, 1.2, -0.3, 16180)$\n- 情况4（小样本，正向误设）： $(500, 91.1876, 2.4952, 1.2, +0.3, 57721)$\n- 情况5（高斯主导区）： $(15000, 125.0, 1.2, 2.0, +0.5, 42424)$\n- 情况6（Breit–Wigner 主导区）： $(15000, 3.1, 0.1, 0.02, -0.01, 99999)$\n\n程序要求：\n\n1. 使用适合柯西分布与高斯分布卷积的数值稳定的特殊函数表示法，实现 $f(x; m, \\sigma, \\gamma)$ 的构建和评估。确保函数被正确归一化。\n\n2. 对于每个测试案例，生成合成数据集，并在误设的分辨率 $\\sigma_{\\mathrm{model}} = \\sigma_{\\mathrm{true}} + \\Delta\\sigma$ 下计算准最大似然估计 $\\hat{m}$。计算偏差 $\\hat{m} - m_{\\mathrm{true}}$，以 $\\mathrm{GeV}$ 为单位的十进制浮点数表示。\n\n3. 最终输出格式：您的程序应生成单行输出，其中包含测试案例的偏差，格式为方括号括起来的逗号分隔列表（例如，`[b1,b2,b3,b4,b5,b6]`），每个 $b_k$ 是以 $\\mathrm{GeV}$ 为单位的十进制浮点数。不应产生任何其他输出。\n\n此问题不涉及角度。不得使用百分比。所有质量必须以 $\\mathrm{GeV}$ 为单位处理和输出。", "solution": "所提出的问题是有效的。它科学上基于高能物理和统计推断的原理，问题定义良好，并为形式化解决方案提供了一套完整且一致的定义和数据。任务是量化当探测器分辨率模型被误设时，共振质量的最大似然估计中的偏差。\n\n### A. 概率密度函数（PDF）的构建\n\n该问题要求为观测到的不变质量 $x$ 构建概率密度函数（PDF）。这个 PDF，记为 $f(x; m, \\sigma, \\gamma)$，是由共振的内在线形与探测器的高斯分辨率函数的卷积得到的。\n\n内在线形是非相对论性 Breit–Wigner 分布，这是一个位置参数为 $m_0$（共振的真实质量，在估计的上下文中我们记为 $m$）、标度参数为 $\\gamma = \\Gamma/2$ 的柯西分布。其 PDF 为：\n$$\nf_{\\mathrm{BW}}(u; m, \\gamma) = \\frac{1}{\\pi} \\frac{\\gamma}{(u - m)^2 + \\gamma^2}\n$$\n\n探测器分辨率是一个均值为 $0$、标准差为 $\\sigma$ 的高斯函数：\n$$\nf_G(\\epsilon; \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{\\epsilon^2}{2\\sigma^2}\\right)\n$$\n\n观测到的测量值 $x$ 是一个从 $f_{\\mathrm{BW}}$ 中抽取的随机变量 $u$ 和一个从 $f_G$ 中抽取的独立随机变量 $\\epsilon$ 的和。因此，$x$ 的 PDF 是这两个分布的卷积：\n$$\nf(x; m, \\sigma, \\gamma) = (f_{\\mathrm{BW}} * f_G)(x) = \\int_{-\\infty}^{\\infty} f_{\\mathrm{BW}}(u; m, \\gamma) f_G(x-u; \\sigma) \\, du\n$$\n代入 PDF 的表达式，得到问题陈述中的显式积分。这个卷积被称为沃伊特轮廓（Voigt profile）。\n\n虽然这个积分可以数值计算，但一种更直接、更稳定的方法是利用其已知的解析形式，该形式使用了 Faddeeva 函数（或复误差函数）$w(z)$。Faddeeva 函数定义为 $w(z) = e^{-z^2} \\text{erfc}(-iz)$，其中 $\\text{erfc}$ 是互补误差函数。\n\nVoigt 轮廓的 PDF 由下式给出：\n$$\nf(x; m, \\sigma, \\gamma) = \\frac{\\text{Re}[w(z)]}{\\sigma \\sqrt{2\\pi}}\n$$\n其中复变量 $z$ 为：\n$$\nz = \\frac{(x-m) + i\\gamma}{\\sigma\\sqrt{2}}\n$$\n此形式是正确归一化的，即 $\\int_{-\\infty}^{\\infty} f(x; m, \\sigma, \\gamma) \\, dx = 1$。使用标准科学库（如 `scipy.special.wofz`，它提供了 $w(z)$ 的实现），该表达式的计算是数值稳定且高效的。后续步骤将使用此解析形式。\n\n### B. 最大似然估计的实现\n\n目标是在给定数据集 $\\{x_i\\}_{i=1}^N$ 和一个可能误设的分辨率模型下，找到质量参数 $m$ 的最大似然估计（MLE），记为 $\\hat{m}$。模型参数是未知质量 $m$、固定的已知宽度 $\\gamma$ 以及一个固定的、可能不正确的分辨率 $\\sigma_{\\mathrm{model}}$。\n\n非分组对数似然函数为：\n$$\n\\ell(m) = \\sum_{i=1}^N \\log f(x_i; m, \\sigma_{\\mathrm{model}}, \\gamma)\n$$\n为了找到 MLE $\\hat{m}$，我们需要找到使 $\\ell(m)$ 最大化的 $m$ 值。这等价于最小化负对数似然函数 $-\\ell(m)$：\n$$\n\\hat{m} = \\arg\\min_m \\left[ -\\sum_{i=1}^N \\log f(x_i; m, \\sigma_{\\mathrm{model}}, \\gamma) \\right]\n$$\n这是一个一维连续优化问题。一个适合此任务的稳健算法是 `scipy.optimize.minimize_scalar`。此函数在给定区间内寻找单变量标量函数的局部最小值。对于沃伊特轮廓的负对数似然函数，全局最小值通常是唯一的，并且可以被可靠地找到。\n\n算法如下：\n1. 定义一个函数，对于给定的 $m$ 值，使用数据集 $\\{x_i\\}$、已知的 $\\gamma$ 和模型分辨率 $\\sigma_{\\mathrm{model}}$ 计算负对数似然 $-\\ell(m)$。\n2. 使用 `scipy.optimize.minimize_scalar` 找到最小化该函数的 $m$ 值。必须提供一个合理的搜索区间，例如 $[m_{\\mathrm{true}} - c, m_{\\mathrm{true}} + c]$（其中 $c$ 为某个常数），以界定搜索空间。\n\n### C. 偏差量化过程\n\n最后的任务是为一系列测试案例量化偏差 $\\hat{m} - m_{\\mathrm{true}}$。每个案例都涉及根据真实的物理过程生成一个合成数据集，然后使用误设的模型应用 MLE 过程。\n\n对于由 $(N, m_{\\mathrm{true}}, \\Gamma, \\sigma_{\\mathrm{true}}, \\Delta\\sigma, \\text{seed})$ 指定的每个测试案例：\n1.  **设置参数**：计算 $\\gamma = \\Gamma/2$ 和模型分辨率 $\\sigma_{\\mathrm{model}} = \\sigma_{\\mathrm{true}} + \\Delta\\sigma$。\n2.  **初始化RNG**：用指定的 `seed` 初始化随机数生成器，以确保可复现性。\n3.  **生成数据**：生成一个合成数据集 $\\{x_i\\}_{i=1}^N$。\n    -   首先，从 Breit-Wigner 分布 $f_{\\mathrm{BW}}(u; m_{\\mathrm{true}}, \\gamma)$ 中抽取 $N$ 个随机值 $\\{u_i\\}$。这可以通过变换标准均匀分布或标准柯西分布的样本来实现。对于一个标准柯西变量 $C$，一个样本由 $u_i = m_{\\mathrm{true}} + \\gamma C_i$ 给出。\n    -   其次，从高斯分布 $\\mathcal{N}(0, \\sigma_{\\mathrm{true}}^2)$ 中抽取 $N$ 个独立的随机噪声值 $\\{\\epsilon_i\\}$。\n    -   最终的观测值为 $x_i = u_i + \\epsilon_i$。\n4.  **估计质量**：将 B 部分的 MLE 过程应用于生成的数据集 $\\{x_i\\}$，使用模型分辨率 $\\sigma_{\\mathrm{model}}$。这将产生准 MLE $\\hat{m}$。\n5.  **计算偏差**：偏差计算为估计质量与真实质量之差：$\\text{Bias} = \\hat{m} - m_{\\mathrm{true}}$。\n\n对所有测试案例重复此过程，并收集所得的偏差。实现将遵循此逻辑以产生所需的输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import wofz\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating bias in resonance mass measurement\n    due to misspecified detector resolution.\n    \"\"\"\n    \n    # Test suite: (N, m_true, Gamma, sigma_true, delta_sigma, seed)\n    test_cases = [\n        # Case 1 (happy path, correctly specified resolution):\n        (20000, 91.1876, 2.4952, 1.2, 0.0, 31415),\n        # Case 2 (moderate positive misspecification):\n        (20000, 91.1876, 2.4952, 1.2, 0.3, 27182),\n        # Case 3 (moderate negative misspecification):\n        (20000, 91.1876, 2.4952, 1.2, -0.3, 16180),\n        # Case 4 (small sample, positive misspecification):\n        (500, 91.1876, 2.4952, 1.2, 0.3, 57721),\n        # Case 5 (Gaussian-dominated regime):\n        (15000, 125.0, 1.2, 2.0, 0.5, 42424),\n        # Case 6 (Breit–Wigner-dominated regime):\n        (15000, 3.1, 0.1, 0.02, -0.01, 99999),\n    ]\n\n    def voigt_pdf(x, m, sigma, gamma):\n        \"\"\"\n        Computes the Voigt profile PDF.\n        The PDF is the convolution of a Cauchy(m, gamma) and a Gaussian(0, sigma).\n        \"\"\"\n        # The Faddeeva function `wofz` provides a fast and stable implementation.\n        # z = (x - m + i*gamma) / (sigma * sqrt(2))\n        z = ((x - m) + 1j * gamma) / (sigma * np.sqrt(2.0))\n        \n        # PDF = Re(wofz(z)) / (sigma * sqrt(2*pi))\n        pdf = np.real(wofz(z)) / (sigma * np.sqrt(2.0 * np.pi))\n        return pdf\n\n    def neg_log_likelihood(m, x_data, sigma, gamma):\n        \"\"\"\n        Computes the negative log-likelihood for the Voigt distribution.\n        \"\"\"\n        pdf_values = voigt_pdf(x_data, m, sigma, gamma)\n        \n        # To avoid issues with log(0), although Voigt is always positive.\n        # A small constant can be added, but np.log handles -inf correctly\n        # and the optimizer will move away from such regions.\n        log_likelihood_sum = np.sum(np.log(pdf_values))\n        \n        # We want to maximize the likelihood, which is equivalent to\n        # minimizing the negative log-likelihood.\n        return -log_likelihood_sum\n\n    results = []\n    \n    for case in test_cases:\n        N, m_true, Gamma, sigma_true, delta_sigma, seed = case\n        \n        # Initialize the random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n        \n        # Calculate derived parameters\n        gamma = Gamma / 2.0\n        sigma_model = sigma_true + delta_sigma\n\n        # Generate synthetic data\n        # 1. Sample from a standard Cauchy distribution and scale/shift.\n        # u ~ Breit-Wigner(m_true, gamma)\n        u_samples = m_true + gamma * rng.standard_cauchy(N)\n        \n        # 2. Sample from a Gaussian distribution.\n        # eps ~ Normal(0, sigma_true^2)\n        eps_samples = rng.normal(loc=0.0, scale=sigma_true, size=N)\n        \n        # 3. The observed data is the sum.\n        x_data = u_samples + eps_samples\n\n        # Create the objective function for the optimizer.\n        # It must be a function of a single variable, `m`.\n        objective_func = lambda m: neg_log_likelihood(m, x_data, sigma_model, gamma)\n        \n        # Perform the minimization to find the MLE for m.\n        # A bracket around the true mass is a safe choice.\n        # For the J/psi case (m=3.1), a bracket of +/- 1 is wide but safe.\n        # For all cases, this bracket is sufficient.\n        res = minimize_scalar(\n            objective_func, \n            bracket=(m_true - 1.0, m_true + 1.0),\n            method='brent'\n        )\n        \n        m_hat = res.x\n        \n        # Calculate the bias\n        bias = m_hat - m_true\n        results.append(bias)\n\n    # Format the final output as specified.\n    print(f\"[{','.join(f'{b:.8f}' for b in results)}]\")\n\nsolve()\n```", "id": "3526389"}]}