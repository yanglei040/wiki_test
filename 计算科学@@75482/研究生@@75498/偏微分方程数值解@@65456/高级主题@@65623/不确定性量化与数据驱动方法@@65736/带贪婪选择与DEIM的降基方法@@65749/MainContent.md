## 引言
在科学与工程的众多领域，从结构力学到[流体动力学](@entry_id:136788)，从金融建模到[生物系统](@entry_id:272986)仿真，[参数化](@entry_id:272587)的[偏微分方程](@entry_id:141332)（PDEs）是描述复杂物理现象的核心数学工具。然而，高保真度的[数值模拟](@entry_id:137087)，如有限元法，往往导致维度极高的代数系统，其求解计算成本巨大。当面临需要对不同参数进行成千上万次求解的“多查询”场景（如[设计优化](@entry_id:748326)、[实时控制](@entry_id:754131)或[不确定性量化](@entry_id:138597)）时，这种计算瓶颈，即所谓的“维数灾难”，使得传统[模拟方法](@entry_id:751987)变得不切实际。[模型降阶](@entry_id:171175)（Model Order Reduction）正是为了应对这一挑战而生，其目标是创建计算成本极低但能保持高精度的代理模型。

本文聚焦于一类强大且应用广泛的[模型降阶](@entry_id:171175)技术：带贪婪[选择算法](@entry_id:637237)和[离散经验插值法](@entry_id:748503)（DEIM）的约化基方法。这种方法不仅能将数小时的计算时间压缩至毫秒级，还提供了严格的误差界，保证了计算结果的可靠性。通过本文的学习，您将深入理解这一前沿数值方法的全貌。第一章“原理与机制”将从基本概念入手，系统阐述[Galerkin投影](@entry_id:145611)、[离线-在线分解](@entry_id:177117)、贪婪算法和DEIM[超约化](@entry_id:163369)的数学原理。第二章“应用与[交叉](@entry_id:147634)学科联系”将展示这些技术如何在瞬态问题、非线性系统和面向目标的仿真中发挥作用，并探讨其与数据科学、优化理论等领域的深刻联系。最后，在“动手实践”部分，您将通过具体的编程练习，将理论知识转化为解决实际问题的能力。

## 原理与机制

本章旨在深入探讨约化基（Reduced Basis, RB）方法的核心原理与关键机制。我们将从一个典型的高维[参数化偏微分方程](@entry_id:753165)（PDE）模型出发，阐述为何需要[模型降阶](@entry_id:171175)。随后，我们将系统地介绍约化基方法的基本框架，即通过[Galerkin投影](@entry_id:145611)将高维问题转化为低维问题。本章的重点将集中在实现高效计算的两个核心技术上：用于构建紧凑且精确的约化空间的**贪婪算法**（greedy algorithm），以及用于处理[非线性](@entry_id:637147)或非仿射问题的**[离散经验插值法](@entry_id:748503)**（Discrete Empirical Interpolation Method, DEIM）。我们将通过严谨的数学推导和具体的计算分析，揭示这些方法如何协同工作，从而在保证精度的前提下，实现对复杂系统的高效、实时仿真。

### 从高维模型到降阶需求

许多科学与工程问题都可以被描述为依赖于一组参数 $\mu \in \mathcal{M} \subset \mathbb{R}^p$ 的[偏微分方程](@entry_id:141332)。在[变分形式](@entry_id:166033)下，这类问题通常可以写作：对于每一个参数 $\mu$，求解状态变量 $u(\mu) \in V$，使得对于所有测试函数 $v \in V$，均有：

$a(u(\mu), v; \mu) = f(v; \mu)$

这里，$V$ 是定义在物理域 $\Omega$ 上的一个合适的[Hilbert空间](@entry_id:261193)（例如，$V = H_0^1(\Omega)$），$a(\cdot, \cdot; \mu)$ 是一个依赖于参数的[双线性形式](@entry_id:746794)，$f(\cdot; \mu)$ 是一个依赖于参数的线性泛函。为了保证问题的**[适定性](@entry_id:148590)**（well-posedness），即解的存在性、唯一性和稳定性，我们通常要求双线性形式 $a(\cdot, \cdot; \mu)$ 满足一定的条件。根据著名的[Lax-Milgram定理](@entry_id:137966)，如果 $a(\cdot, \cdot; \mu)$ 是**连续的**（有界的）并且是**强制的**（coercive），同时 $f(\cdot; \mu)$ 是连续的，那么对于每一个参数 $\mu$，上述[变分问题](@entry_id:756445)都存在唯一的解。[@problem_id:3438766]

在实际计算中，我们通常采用[有限元法](@entry_id:749389)（Finite Element Method, FEM）等离散化技术，在 $V$ 的一个高维[子空间](@entry_id:150286) $V_h \subset V$（维度为 $N$，通常很大）中求解该问题。这会将[变分问题](@entry_id:756445)转化为一个大规模的线性代数系统：

$A(\mu) \mathbf{u}(\mu) = \mathbf{b}(\mu)$

其中，$\mathbf{u}(\mu) \in \mathbb{R}^N$ 是解在有限元基下的系数向量，$A(\mu) \in \mathbb{R}^{N \times N}$ 是[刚度矩阵](@entry_id:178659)，$\mathbf{b}(\mu) \in \mathbb{R}^N$ 是[载荷向量](@entry_id:635284)。我们称这个高维离散模型为**[全阶模型](@entry_id:171001)**（Full Order Model, FOM）。

对于许多应用场景，如优化、控制或不确定性量化，我们需要针对参数域 $\mathcal{M}$ 中的大量不同参数值反复求解该FOM。由于 $N$ 通常非常大（可达 $10^6$ 甚至更高），即使求解一次FOM的计算成本可以接受，进行成千上万次求解也是不现实的。这就是所谓的“[维数灾难](@entry_id:143920)”。模型降阶（Model Order Reduction, MOR）方法的目标，正是在于构建一个计算成本极低但精度足够高的**代理模型**，以替代昂贵的FOM，从而实现实时或近实时的参数查询。

### 约化基方法：[Galerkin投影](@entry_id:145611)

约化基（RB）方法的核心思想是，尽管FOM的解空间 $V_h$ 维度很高，但由所有参数 $\mu \in \mathcal{M}$ 对应的解构成的**解[流形](@entry_id:153038)**（solution manifold）$\mathcal{S} = \{u(\mu) | \mu \in \mathcal{M}\}$ 通常可以被一个低维的[线性子空间](@entry_id:151815)很好地近似。

RB方法首先构建一个低维的**约化基空间**（reduced basis space）$V_r = \mathrm{span}\{\xi_1, \dots, \xi_r\}$，其中 $r \ll N$。这些[基函数](@entry_id:170178) $\xi_i$ 通常是FOM在某些精心挑选的参数点下的解，即“快照”（snapshots）。然后，我们在这个低维空间中寻找一个近似解 $u_r(\mu) \in V_r$。这意味着 $u_r(\mu)$ 可以表示为[基函数](@entry_id:170178)的线性组合：

$u_r(\mu) = \sum_{j=1}^r c_j(\mu) \xi_j$

其中 $c(\mu) = [c_1(\mu), \dots, c_r(\mu)]^T \in \mathbb{R}^r$ 是待定的约化坐标。

为了确定这些系数，RB方法采用**[Galerkin投影](@entry_id:145611)**。它要求近似解 $u_r(\mu)$ 满足原[变分问题](@entry_id:756445)在约化空间 $V_r$ 上的投影，即对于所有的测试函数 $v \in V_r$，均有：

$a(u_r(\mu), v; \mu) = f(v; \mu)$

由于 $v$ 可以是任意一个[基函数](@entry_id:170178) $\xi_i$，我们将 $u_r(\mu)$ 的表达式和 $v = \xi_i$ 代入上式，得到一个关于约化坐标 $c(\mu)$ 的 $r \times r$ [线性系统](@entry_id:147850)：

$\sum_{j=1}^r a(\xi_j, \xi_i; \mu) c_j(\mu) = f(\xi_i; \mu), \quad i=1, \dots, r$

这个系统可以写成紧凑的矩阵形式 [@problem_id:3438829]：

$A_r(\mu) c(\mu) = b_r(\mu)$

其中，**约化[刚度矩阵](@entry_id:178659)** $A_r(\mu) \in \mathbb{R}^{r \times r}$ 和**约化[载荷向量](@entry_id:635284)** $b_r(\mu) \in \mathbb{R}^r$ 的分量分别为：

$(A_r(\mu))_{ij} = a(\xi_j, \xi_i; \mu)$
$(b_r(\mu))_i = f(\xi_i; \mu)$

如果我们将FOM的矩阵 $A(\mu)$、[载荷向量](@entry_id:635284) $b(\mu)$ 和由[基函数](@entry_id:170178)系数向量构成的矩阵 $\Xi \in \mathbb{R}^{N \times r}$ 联系起来，那么约化系统可以更直观地表示为：

$A_r(\mu) = \Xi^T A(\mu) \Xi$
$b_r(\mu) = \Xi^T b(\mu)$

由于 $r \ll N$，求解这个 $r \times r$ 的小系统非常迅速。然而，这是否意味着我们已经实现了高效计算？答案取决于我们如何构造 $A_r(\mu)$ 和 $b_r(\mu)$。如果为了得到它们，我们仍然需要先构造 $N \times N$ 的矩阵 $A(\mu)$，那么计算瓶颈依然存在。

### 实现实时计算的关键：[离线-在线分解](@entry_id:177117)

为了真正实现计算加速，RB方法引入了**离线-在线**（offline-online）计算策略。这种策略的核心是**[仿射参数](@entry_id:260625)依赖性**（affine parametric dependence）。

假设[双线性形式](@entry_id:746794)和线性泛函可以分解为参数相关部分和参数无关部分的乘[积之和](@entry_id:266697)，即：

$a(u, v; \mu) = \sum_{q=1}^{Q_a} \theta_q^a(\mu) a_q(u, v)$
$f(v; \mu) = \sum_{q=1}^{Q_f} \theta_q^f(\mu) f_q(v)$

其中，$\theta_q(\mu)$ 是只依赖于参数 $\mu$ 的标量函数，$a_q(u,v)$ 和 $f_q(v)$ 是与参数无关的双线性形式和[线性泛函](@entry_id:276136)。这种结构使得FOM的矩阵和向量也具有仿射分解形式 [@problem_id:3438771]：

$A(\mu) = \sum_{q=1}^{Q_a} \theta_q^a(\mu) A_q, \quad b(\mu) = \sum_{q=1}^{Q_f} \theta_q^f(\mu) b_q$

将这个分解代入约化系统的表达式，我们得到：

$A_r(\mu) = \Xi^T \left( \sum_{q=1}^{Q_a} \theta_q^a(\mu) A_q \right) \Xi = \sum_{q=1}^{Q_a} \theta_q^a(\mu) (\Xi^T A_q \Xi)$
$b_r(\mu) = \Xi^T \left( \sum_{q=1}^{Q_f} \theta_q^f(\mu) b_q \right) = \sum_{q=1}^{Q_f} \theta_q^f(\mu) (\Xi^T b_q)$

这个结构完美地分离了计算任务 [@problem_id:3438829]：

- **离线阶段（Offline Stage）**：这是一个耗时但只需执行一次的预计算阶段。在此阶段，我们构造约化基 $\Xi$，并计算并存储所有与参数无关的小矩阵和向量：$A_{r,q} = \Xi^T A_q \Xi \in \mathbb{R}^{r \times r}$ 和 $b_{r,q} = \Xi^T b_q \in \mathbb{R}^r$。这个阶段的计算成本依赖于高维 $N$，但它是参数独立的。

- **在线阶段（Online Stage）**：对于任何给定的新参数 $\mu$，我们可以极其快速地组装并求解约化系统。只需计算标量系数 $\theta_q(\mu)$，然后通过简单的[线性组合](@entry_id:154743)得到 $A_r(\mu)$ 和 $b_r(\mu)$，其成本仅为 $\mathcal{O}(Q_a r^2 + Q_f r)$。求解 $r \times r$ 系统的成本约为 $\mathcal{O}(r^3)$。重要的是，**在线阶段的计算成本完全独立于高维模型的维度 $N$**。

然而，许多实际问题（如涉及变化的几何形状、[非线性](@entry_id:637147)材料属性等）并不天然具有这种仿射结构。这就是引入[超约化](@entry_id:163369)（hyper-reduction）方法，如DEIM，的动机。我们将在后续章节深入探讨。

### 构建[最优基](@entry_id:752971)：贪婪算法与误差估计

一个成功的RB方法的关键在于如何构建一个“好”的约化基空间 $V_r$。一个好的基空间应该能够用尽可能少的[基函数](@entry_id:170178)（即尽可能小的 $r$）来精确地近似整个解[流形](@entry_id:153038)。

#### 目标：控制最差情况误差

有两种主流的基构建策略：**[本征正交分解](@entry_id:165074)**（Proper Orthogonal Decomposition, POD）和**贪婪算法**。POD是一种数据驱动的方法，它从一组预先计算的快照中提取一个基，使得该基在平均意义下对这些快照的近似误差最小（即最小化均方投影误差）。相比之下，贪婪算法是一种目标驱动的、更符合RB方法精神的策略。它不追求平均最优，而是致力于控制**最差情况误差**。在每一步，它都试图找到当前基近似得最差的那个参数点，并将对应的信息加入到基中，从而系统性地降低整个参数域上的最大误差。理论上，贪婪算法的[收敛速度](@entry_id:636873)可以媲美解[流形](@entry_id:153038)的**Kolmogorov n-width**，后者刻画了用n维[线性子空间](@entry_id:151815)逼近该[流形](@entry_id:153038)的理论最优误差 [@problem_id:3438816]。

#### [后验误差估计](@entry_id:167288)：可靠的精度保证

为了实现贪婪算法，我们必须能够快速评估当前约化基 $V_r$ 对任意参数 $\mu$ 的近似精度。直接计算真实误差 $u(\mu) - u_r(\mu)$ 是不可行的，因为它需要求解昂贵的FOM。因此，我们需要一个**[后验误差估计](@entry_id:167288)器**（a posteriori error estimator）$\Delta_r(\mu)$，它是一个可以快速计算的量，并且能为真实误差提供一个可靠的上界。

对于对称、强制的[双线性形式](@entry_id:746794)，一个经典而强大的[误差估计](@entry_id:141578)器是基于**残差**（residual）的。残差泛函 $R_r(v; \mu)$ 定义为近似解 $u_r(\mu)$ 在多大程度上未能满足原始[变分方程](@entry_id:635018)：

$R_r(v; \mu) := f(v; \mu) - a(u_r(\mu), v; \mu)$

真实误差 $e_r(\mu) = u(\mu) - u_r(\mu)$ 与残差之间存在着深刻的联系。利用[双线性形式](@entry_id:746794)的强制性和连续性，可以推导出如下的误差-残差关系 [@problem_id:3438793]：

$\|u(\mu) - u_r(\mu)\|_{a(\mu)} = \|R_r(\cdot; \mu)\|_{a(\mu)^*} \le \frac{1}{\sqrt{\alpha(\mu)}} \|R_r(\cdot; \mu)\|_{V'}$

其中，$\|v\|_{a(\mu)} = \sqrt{a(v,v;\mu)}$ 是与问题相关的**能量范数**，它定义了一个等价于原始空间范数 $\| \cdot \|_V$ 的范数。$\alpha(\mu)$ 是强制性常数，$\|\cdot\|_{V'}$ 是 $V$ 的[对偶空间](@entry_id:146945)范数。这个关系表明，误差的[能量范数](@entry_id:274966)恰好等于残差在[能量范数](@entry_id:274966)对偶下的范数。

这为我们提供了一个可计算的误差上界：

$\|u(\mu) - u_r(\mu)\|_V \le \frac{\|R_r(\cdot; \mu)\|_{V'}}{\alpha_{\text{LB}}(\mu)} =: \Delta_r(\mu)$

这里，$\alpha_{\text{LB}}(\mu)$ 是强制性常数的一个可在线快速计算的**下界**。这个估计器 $\Delta_r(\mu)$ 是“可靠的”，因为它为真实误差提供了一个严格的数学[上界](@entry_id:274738)。同时，如果它也是“高效的”（即[上界](@entry_id:274738)与真实误差的比值不过大），那么它就可以作为真实误差的有效代理。为了使 $\Delta_r(\mu)$ 可以在线高效计算，[残差范数](@entry_id:754273)的计算也需要利用仿射分解。

#### 贪婪[选择算法](@entry_id:637237)

有了高效可靠的[后验误差估计](@entry_id:167288)器，贪婪算法的流程就变得清晰了 [@problem_id:3438772] [@problem_id:3438829]：

1.  选择一个足够大的有限**[训练集](@entry_id:636396)** $\mathcal{M}_{\text{train}} \subset \mathcal{M}$。
2.  初始化：选择第一个参数 $\mu_1 \in \mathcal{M}_{\text{train}}$，计算FOM解 $u(\mu_1)$，并构建初始基空间 $V_1 = \mathrm{span}\{u(\mu_1)/\| u(\mu_1) \|_V\}$。令 $r=1$。
3.  **迭代**：当 $r < r_{\max}$ 且误差不满足要求时：
    a.  **寻找最差参数**：在训练集上寻找使当前[误差估计](@entry_id:141578)器最大的参数：
        $\mu_{r+1} = \arg\max_{\mu \in \mathcal{M}_{\text{train}}} \Delta_r(\mu)$
    b.  **计算快照**：求解对应于 $\mu_{r+1}$ 的FOM解 $u(\mu_{r+1})$。
    c.  **扩充基空间**：对 $u(\mu_{r+1})$ 进行[Gram-Schmidt正交化](@entry_id:143035)，将其正交于现有基的分量加入到基空间中，得到 $V_{r+1}$。
    d.  $r \leftarrow r+1$。

这个过程确保了每一步都针对性地改进模型在当前最薄弱环节的表现，从而高效地构建出一个对整个参[数域](@entry_id:155558)都具有良好逼近能力的约化基。

### [超约化](@entry_id:163369)：[离散经验插值法](@entry_id:748503) (DEIM)

前面我们看到，[离线-在线分解](@entry_id:177117)的高效性依赖于算子的[仿射参数](@entry_id:260625)依赖性。对于非仿射或[非线性](@entry_id:637147)问题，例如，当FOM系统包含一个[非线性](@entry_id:637147)项 $n(u(\mu))$ 时，约化残差的计算会涉及到 $V^T n(V c(\mu))$ 这样的项。即使 $c(\mu)$ 已知，计算 $V c(\mu)$ 得到一个 $N$ 维向量，然后逐点计算[非线性](@entry_id:637147)函数 $n(\cdot)$，最后再投影回 $r$ 维空间，整个过程的计算复杂度仍然与高维 $N$ 相关，这就破坏了在线阶段的效率。

**[离散经验插值法](@entry_id:748503)（DEIM）**是一种强大的**[超约化](@entry_id:163369)**（hyper-reduction）技术，专门用于解决这一瓶颈。

#### 核心思想与数学表述

DEIM的核心思想是，[非线性](@entry_id:637147)项 $n(u)$ 产生的向量通常也位于一个低维[子空间](@entry_id:150286)中。因此，我们可以用一个低维基来近似它。DEIM通过两个步骤实现这一目标 [@problem_id:3438802]：

1.  **[子空间](@entry_id:150286)表示**：首先，通过对[非线性](@entry_id:637147)项的快照（即在贪婪算法过程中计算出的 $n(u(\mu_i))$）进行POD，我们构建一个低维的**[正交基](@entry_id:264024)** $U \in \mathbb{R}^{N \times m}$（其中 $m \ll N$）。任何[非线性](@entry_id:637147)向量 $n(u)$ 都可以被近似地表示为：
    $n(u) \approx U \tilde{c}$
    其中 $\tilde{c} \in \mathbb{R}^m$ 是待定系数。

2.  **插值确定系数**：为了快速确定系数 $\tilde{c}$，DEIM避免了计算成本高昂的 $L_2$ 投影（即 $U^T n(u)$）。取而代之，它要求近似值在 $m$ 个精心挑选的**插值点**（或索引）上与原始向量完全相等。设这些索引由一个选择矩阵 $P \in \mathbb{R}^{N \times m}$ 表示（$P$ 的列是单位向量），插值条件为：
    $P^T (U \tilde{c}) = P^T n(u)$

这个条件给出了一个 $m \times m$ 的小系统 $(P^T U) \tilde{c} = P^T n(u)$。如果矩阵 $P^T U$ 可逆，我们就可以解出系数：
$\tilde{c} = (P^T U)^{-1} P^T n(u)$

将此系数代回[子空间](@entry_id:150286)表示，我们得到最终的DEIM近似：

$n(u) \approx U (P^T U)^{-1} P^T n(u)$

插值点的选择至关重要，它通过一个贪婪算法来完成，以保证 $P^T U$ 是良态的。这个DEIM算子 $M_{\text{DEIM}} = U (P^T U)^{-1} P^T$ 是一个**斜投影算子**（oblique projector），它将[向量投影](@entry_id:147046)到由 $U$ 张成的空间上，沿着由 $P^T$ 定义的核空间进行投影 [@problem_id:3438802]。

#### 在约化基框架中的集成

DEIM完美地融入了RB方法的离线-在线框架中。以一个包含[非线性](@entry_id:637147)项的半线性问题为例，假设在牛顿法求解约化系统时，需要计算约化残差和[雅可比矩阵](@entry_id:264467)的[非线性](@entry_id:637147)部分 [@problem_id:3438806]。

-   **约化残差**：$g_n(a) = V^T n(Va)$。使用DEIM近似 $n(Va)$：
    $g_n(a) \approx V^T [U (P^T U)^{-1} P^T n(Va)] = [V^T U (P^T U)^{-1}] [P^T n(Va)]$

-   **约化[雅可比](@entry_id:264467)**：$J_n(a) = V^T \frac{\partial n}{\partial u}|_{u=Va} V$。类似地，[雅可比矩阵](@entry_id:264467) $\frac{\partial n}{\partial u}$ 也可以通过DEIM或其变体进行近似。

在线计算时，我们不再需要计算完整的 $N$ 维向量 $n(Va)$。我们只需要计算其在 $m$ 个DEIM插值点上的值，即 $P^T n(Va)$。这部分的计算成本只与 $m$ 和 $r$ 相关。然后，通过与离线预计算好的小矩阵 $V^T U (P^T U)^{-1}$ 相乘，即可得到约化后的[非线性](@entry_id:637147)项。整个在线过程的计算复杂度从依赖 $N$ 降低到只依赖于 $r$ 和 $m$ [@problem_id:3438802] [@problem_id:3438806]。

#### 计算复杂性分析：从 $\mathcal{O}(N)$ 到 $\mathcal{O}(m)$

DEIM带来的计算增益是巨大的。考虑一个简单的逐点[非线性](@entry_id:637147)函数 $f(u) = (\varphi(u_1), \dots, \varphi(u_N))^T$。

-   **无DEIM**：组装约化残差 $V^T f(Va)$ 需要：(1) 计算 $u = Va$（成本 $\mathcal{O}(Nr)$），(2) 评估 $f(u)$（成本 $\mathcal{O}(N)$），(3) 计算 $V^T f(u)$（成本 $\mathcal{O}(Nr)$）。总成本由 $\mathcal{O}(N)$ 主导。

-   **有DEIM**：组装近似的约化残差需要：(1) 计算插值点处的 $u$ 分量 $P^T V a$（可离线预计算 $P^T V$），(2) 评估 $m$ 个[非线性](@entry_id:637147)函数值 $P^T f(Va)$（成本 $\mathcal{O}(m)$），(3) 乘以离线计算好的矩阵（成本 $\mathcal{O}(rm)$）。总在线成本由 $\mathcal{O}(m+rm)$ 主导。

在一个具体的计算问题中，可以推导出，对于这类[非线性](@entry_id:637147)项，使用DEIM所带来的在线计算加速比恰好为 $N/m$ [@problem_id:3438825]。考虑到 $N$ 通常是 $10^6$ 级别，而 $m$ 可能只有几十或几百，这意味着DEIM可以带来数千甚至数万倍的加速。

#### DEIM的稳定性与正则化

DEIM的成功依赖于小矩阵 $P^T U$ 的良态性。它的逆范数 $\|(P^T U)^{-1}\|$ 被称为DEIM的**稳定性常数**，它会放大近似误差。如果标准的DEIM贪婪算法选出的插值点导致 $P^T U$ 病态，就需要采取正则化策略。

常用的稳定化方法包括 [@problem_id:3438801]：

-   **更鲁棒的索引选择**：使用更先进的[数值线性代数](@entry_id:144418)工具，如基于秩启示QR分解（rank-revealing QR factorization）的算法来选择插值点，以期直接得到一个更良态的 $P^T U$ 矩阵。

-   **[过采样](@entry_id:270705)与最小二乘（LS-DEIM）**：选择 $s > m$ 个插值点，然后求解一个 $s \times m$ 的[超定系统](@entry_id:151204)的[最小二乘解](@entry_id:152054)来确定系数 $\tilde{c}$。这通常能显著提高稳定性，因为利用了更多的信息。

-   **[吉洪诺夫正则化](@entry_id:140094)（Tikhonov Regularization）**：在求解系数的（可能是超定的）[线性系统](@entry_id:147850)时，加入一个正则项 $\lambda^2 \|\tilde{c}\|^2$。这保证了即使原始系统病态或奇异，求解过程也是稳定的，其稳定性由正则化参数 $\lambda$ 控制。

这些先进的变体使得DEIM成为一个在实践中非常鲁棒和灵活的工具，它不仅是理论上的一个漂亮想法，更是实现对复杂非线性系统进行[模型降阶](@entry_id:171175)的基石。同时，当使用这些近似方法时，为了维持RB方法的“认证”特性，必须仔细推导包含DEIM近似误差的后验[误差界](@entry_id:139888)，确保整个计算过程的可靠性 [@problem_id:3438816]。