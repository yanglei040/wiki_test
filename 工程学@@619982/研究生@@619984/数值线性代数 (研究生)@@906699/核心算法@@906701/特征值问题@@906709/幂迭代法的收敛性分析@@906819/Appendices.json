{
        "hands_on_practices": [
            {
                "introduction": "我们从最简单的情景开始：将幂迭代应用于一个对角矩阵。这种理想化的设定剥离了诸如特征向量非正交性等复杂因素，使我们能够直接观察到各个分量如何根据其对应的特征值进行相对缩放，从而驱动收敛。这个练习 [@problem_id:3541831] 旨在建立关于收敛速率和有限步收敛条件的根本性直觉。",
                "problem": "考虑一个形如 $A = \\mathrm{diag}(\\lambda_1,\\dots,\\lambda_n)$ 的矩阵 $A \\in \\mathbb{C}^{n \\times n}$，以及由 $y_{k+1} = A x_k$ 和 $x_{k+1} = y_{k+1} / \\lVert y_{k+1} \\rVert_2$（对于 $k \\ge 0$）定义的幂迭代法，其中 $x_0 \\in \\mathbb{C}^n$ 是一个给定的非零初始向量。假设使用精确算术。在此设定下，$A$ 的特征向量是标准基向量，每个坐标在 $A$ 的作用下独立演化。定义以下概念：\n\n- 有限步收敛（到特征向量方向）：存在一个有限的 $K$，使得 $x_K$ 是 $A$ 的一个归一化特征向量，并且对于所有 $k \\ge K$，$x_k$ 保持在该特征向量方向上（允许模为1的复相位翻转，或者在实数情况下，符号改变）。\n- 在容差 $\\varepsilon \\in (0,1)$ 下有效消除次优势分量：对于一个指定的索引 $j^\\star$，它满足 $|\\lambda_{j^\\star}| = \\max\\{|\\lambda_i| : x_0^{(i)} \\ne 0\\}$ 且 $x_0^{(j^\\star)} \\ne 0$，归一化迭代向量 $x_k$ 满足 $\\max_{i \\ne j^\\star} \\left| x_k^{(i)} / x_k^{(j^\\star)} \\right| \\le \\varepsilon$。\n\n选择所有正确的陈述。\n\nA. 最多一次迭代内发生有限步收敛的充分必要条件是，$x_0$ 的支撑集（support）恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$（因此 $x_0$ 的所有其他非零项都位于索引 $i$ 处，其中 $\\lambda_i = 0$）。在这种情况下，$x_1$ 是方向为 $e_j$ 的一个归一化特征向量（相差一个模为1的复相位），并且对于所有 $k \\ge 1$，$x_k$ 保持在该方向上。\n\nB. 如果 $x_0$ 的非零项仅出现在 $|\\lambda_i|$ 达到 $\\{|\\lambda_1|,\\dots,|\\lambda_n|\\}$ 中最大值的索引处，并且至少有两个这样的项是非零的，那么归一化迭代向量 $x_k$ 必然在有限步内收敛到一个单一坐标向量。\n\nC. 假设 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$ 且 $x_0^{(1)} \\ne 0$。那么对于任何 $\\varepsilon \\in (0,1)$，使得 $\\max_{i \\ge 2} \\left| x_k^{(i)} / x_k^{(1)} \\right| \\le \\varepsilon$ 成立的最小 $k$ 是满足下式的最小整数 $k$：\n$$\nk \\;\\ge\\; \\max_{\\substack{i \\ge 2 \\\\ x_0^{(i)} \\ne 0}} \\frac{\\log\\!\\left( \\dfrac{|x_0^{(i)}|}{\\varepsilon\\,|x_0^{(1)}|} \\right)}{\\log\\!\\left( \\dfrac{|\\lambda_1|}{|\\lambda_i|} \\right)} \\,.\n$$\n\nD. 如果使用 $\\ell_{\\infty}$ 范数而不是 $\\ell_2$ 范数进行归一化，也就是说，$x_{k+1} = A x_k / \\lVert A x_k \\rVert_{\\infty}$，那么对于任何固定的容差 $\\varepsilon \\in (0,1)$，只要 $x_0^{(1)} \\ne 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$，达到 $\\max_{i \\ge 2} |x_k^{(i)}| \\le \\varepsilon$ 所需的迭代次数就与 $x_0$ 无关。\n\nE. 如果 $x_0$ 在索引 $j$ 处恰好有一个非零坐标，那么无论 $\\lambda_j$ 的值是多少，归一化序列都满足 $x_k = e_j$ 对于所有 $k \\ge 0$（也就是说，幂迭代法立即实现有限步收敛）。\n\nF. 即使 $x_0^{(1)} = 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$，归一化最终会产生一个非零的第一坐标，所以 $x_k$ 会在有限步内收敛到主特征向量方向 $e_1$。",
                "solution": "用户希望我分析对角矩阵 $A \\in \\mathbb{C}^{n \\times n}$ 的幂迭代法的收敛性质。\n\n问题陈述定义了一个对角矩阵 $A = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_n)$，以及从一个非零向量 $x_0 \\in \\mathbb{C}^n$ 开始的幂迭代序列 $y_{k+1} = A x_k$, $x_{k+1} = y_{k+1} / \\lVert y_{k+1} \\rVert_2$。分析需要在精确算术的假设下进行。$A$ 的特征向量是标准基向量 $e_i \\in \\mathbb{C}^n$，对应的特征值为 $\\lambda_i$。\n\n让我们建立迭代向量 $x_k$ 的一般形式。经过 $k$ 步后的未归一化向量与 $A^k x_0$ 成比例。由于 $A$ 是对角矩阵，所以 $A^k = \\mathrm{diag}(\\lambda_1^k, \\dots, \\lambda_n^k)$。未归一化向量的第 $i$ 个分量是 $(\\lambda_i)^k x_0^{(i)}$。\n归一化向量 $x_k$ 的分量为：\n$$\nx_k^{(i)} = \\frac{\\lambda_i^k x_0^{(i)}}{\\sqrt{\\sum_{j=1}^n |\\lambda_j^k x_0^{(j)}|^2}}\n$$\n只要每一步的分母非零，该公式就有效。如果对于某个 $k$，$A^k x_0 = 0$，则迭代终止。\n\n现在，我们来分析每个陈述。\n\n**A. 最多一次迭代内发生有限步收敛的充分必要条件是 $x_0$ 的支撑集恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$（因此 $x_0$ 的所有其他非零项都位于索引 $i$ 处，其中 $\\lambda_i = 0$）。在这种情况下，$x_1$ 是方向为 $e_j$ 的一个归一化特征向量（相差一个模为1的复相位），并且对于所有 $k \\ge 1$， $x_k$ 保持在该方向上。**\n\n我们来证明这个“当且仅当”陈述的两个方向。\n\n($\\Rightarrow$) “仅当”部分：假设有限步收敛在最多一次迭代内发生。这意味着 $x_0$ 或 $x_1$ 是 $A$ 的一个归一化特征向量。一个特征向量必须具有 $c e_j$ 的形式，其中 $j$ 是某个索引，$c$ 是一个模为1的复标量。\n*   情况1：$K=0$。$x_0 = c e_j$，对于某个 $j$ 且 $|c|=1$。为了使序列在 $k \\ge 1$ 时有定义，我们必须有 $y_1 = A x_0 \\ne 0$。$A x_0 = A (c e_j) = c \\lambda_j e_j$。要使其非零，我们需要 $\\lambda_j \\ne 0$。在这种情况下，$x_0$ 的支撑集是 $\\{j\\}$，且 $\\lambda_j \\ne 0$。这满足了 $x_0$ 的支撑集恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$ 的条件。\n*   情况2：$K=1$。$x_1$ 是一个归一化特征向量，所以 $x_1 = c e_j$ 对于某个 $j$ 且 $|c|=1$，并且 $x_0$ 不是一个特征向量。要使 $x_1$ 在 $e_j$ 的方向上，未归一化的向量 $y_1 = A x_0$ 也必须在 $e_j$ 的方向上。这意味着对于所有 $i \\ne j$，$(A x_0)^{(i)} = 0$，并且 $(A x_0)^{(j)} \\ne 0$。\n    *   $(A x_0)^{(j)} = \\lambda_j x_0^{(j)} \\ne 0$ 意味着 $\\lambda_j \\ne 0$ 且 $x_0^{(j)} \\ne 0$。\n    *   对于任何 $i \\ne j$，$(A x_0)^{(i)} = \\lambda_i x_0^{(i)} = 0$。这意味着对于任何 $i \\ne j$，如果 $x_0^{(i)} \\ne 0$，则必须有 $\\lambda_i=0$。\n    这正是选项中陈述的条件：$x_0^{(i)} \\ne 0$ 的索引集合（即 $x_0$ 的支撑集）恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$。\n\n($\\Leftarrow$) “如果”部分：假设 $x_0$ 的支撑集恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$。设 $S = \\{i \\mid x_0^{(i)} \\ne 0 \\text{ and } \\lambda_i=0\\}$。$x_0$ 的支撑集是 $S \\cup \\{j\\}$。\n我们来计算 $y_1 = A x_0$。\n*   对于 $i=j$，$y_1^{(j)} = \\lambda_j x_0^{(j)}$。由于 $\\lambda_j \\ne 0$ 且 $x_0^{(j)} \\ne 0$，此分量非零。\n*   对于任何其他索引 $i \\ne j$：如果 $x_0^{(i)}=0$，则 $y_1^{(i)} = \\lambda_i \\cdot 0 = 0$。如果 $x_0^{(i)} \\ne 0$，则根据假设 $\\lambda_i=0$，所以 $y_1^{(i)} = 0 \\cdot x_0^{(i)} = 0$。\n所以，$y_1$ 只有一个非零分量，在索引 $j$ 处。$y_1 = (\\lambda_j x_0^{(j)}) e_j$。由于 $y_1 \\ne 0$，我们可以归一化它。\n$x_1 = \\frac{y_1}{\\lVert y_1 \\rVert_2} = \\frac{\\lambda_j x_0^{(j)}}{|\\lambda_j x_0^{(j)}|} e_j$。\n标量乘数 $\\frac{\\lambda_j x_0^{(j)}}{|\\lambda_j x_0^{(j)}|}$ 是一个模为1的复数。因此，$x_1$ 是一个归一化特征向量。对于任何 $k \\ge 1$，$x_k$ 都是一个特征向量。例如，$y_2 = A x_1 = \\lambda_j x_1$，它是 $e_j$ 的一个非零倍数。归一化后得到 $x_2$，它也是 $e_j$ 的倍数（可能具有不同的相位）。对于所有 $k \\ge 1$，方向是稳定的。\n该陈述成立。\n\n结论：**正确**。\n\n**B. 如果 $x_0$ 的非零项仅出现在 $|\\lambda_i|$ 达到 $\\{|\\lambda_1|,\\dots,|\\lambda_n|\\}$ 中最大值的索引处，并且至少有两个这样的项是非零的，那么归一化迭代向量 $x_k$ 必然在有限步内收敛到一个单一坐标向量。**\n\n设 $\\rho = \\max_i |\\lambda_i|$。设 $S = \\{i \\mid |\\lambda_i| = \\rho\\}$。假设 $x_0$ 的支撑集是 $S$ 的一个子集，并且 $|\\mathrm{supp}(x_0)| \\ge 2$。\n迭代向量 $x_k$ 的分量 $x_k^{(i)}$ 与 $\\lambda_i^k x_0^{(i)}$ 成比例。对于任意两个索引 $i, j \\in \\mathrm{supp}(x_0)$，分量的比值为：\n$$\n\\frac{x_k^{(i)}}{x_k^{(j)}} = \\frac{\\lambda_i^k x_0^{(i)}}{\\lambda_j^k x_0^{(j)}}\n$$\n其模的比值为：\n$$\n\\left| \\frac{x_k^{(i)}}{x_k^{(j)}} \\right| = \\frac{|\\lambda_i|^k |x_0^{(i)}|}{|\\lambda_j|^k |x_0^{(j)}|} = \\frac{\\rho^k |x_0^{(i)}|}{\\rho^k |x_0^{(j)}|} = \\frac{|x_0^{(i)}|}{|x_0^{(j)}|}\n$$\n这个比值对所有 $k$ 都是恒定的。如果 $x_0$ 在索引 $i$ 和 $j$ 处有非零分量，那么对于所有 $k$，$x_k$ 也将在这些索引处有非零分量。对于所有 $k$，$x_k$ 的支撑集与 $x_0$ 的支撑集相同。由于 $x_0$ 的支撑集至少包含两个索引，因此对于所有 $k$，$x_k$ 的支撑集也将至少包含两个索引。所以，$x_k$ 永远不能变成一个单一坐标向量（其支撑集大小为1）。有限步收敛到单一坐标向量是不可能的。该序列甚至可能不会收敛到一个单一向量，因为相位 $e^{i\\arg(\\lambda_i)k}$ 可能导致向量在环面上循环或游走。\n\n结论：**不正确**。\n\n**C. 假设 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$ 且 $x_0^{(1)} \\ne 0$。那么对于任何 $\\varepsilon \\in (0,1)$，使得 $\\max_{i \\ge 2} \\left| x_k^{(i)} / x_k^{(1)} \\right| \\le \\varepsilon$ 成立的最小 $k$ 是满足... [不等式] 的最小整数 $k$。**\n\n我们关心比率 $\\left| x_k^{(i)} / x_k^{(1)} \\right|$ (对于 $i \\ge 2$)。\n如前所示，归一化因子在分量比率中被抵消：\n$$\n\\frac{x_k^{(i)}}{x_k^{(1)}} = \\frac{\\lambda_i^k x_0^{(i)}}{\\lambda_1^k x_0^{(1)}} = \\left(\\frac{\\lambda_i}{\\lambda_1}\\right)^k \\frac{x_0^{(i)}}{x_0^{(1)}}\n$$\n取模：\n$$\n\\left| \\frac{x_k^{(i)}}{x_k^{(1)}} \\right| = \\left| \\frac{\\lambda_i}{\\lambda_1} \\right|^k \\left| \\frac{x_0^{(i)}}{x_0^{(1)}} \\right|\n$$\n我们希望对于所有 $i \\ge 2$，这个值小于或等于 $\\varepsilon$。我们只需要考虑 $x_0^{(i)} \\ne 0$ 的索引 $i$，因为否则该比率为0。\n对于每个这样的 $i$，我们要求：\n$$\n\\left| \\frac{\\lambda_i}{\\lambda_1} \\right|^k \\left| \\frac{x_0^{(i)}}{x_0^{(1)}} \\right| \\le \\varepsilon\n$$\n重新排列并取自然对数：\n$$\nk \\log\\left(\\left| \\frac{\\lambda_i}{\\lambda_1} \\right|\\right) \\le \\log\\left(\\varepsilon \\left| \\frac{x_0^{(1)}}{x_0^{(i)}} \\right|\\right)\n$$\n由于 $|\\lambda_1|  |\\lambda_i|$，项 $\\log(|\\lambda_i|/|\\lambda_1|)$ 是负的。用它相除会反转不等号：\n$$\nk \\ge \\frac{\\log\\left(\\varepsilon \\left| \\frac{x_0^{(1)}}{x_0^{(i)}} \\right|\\right)}{\\log\\left(\\left| \\frac{\\lambda_i}{\\lambda_1} \\right|\\right)}\n$$\n让我们重写对数的参数以匹配提供的公式。\n分子：$\\log\\left(\\varepsilon \\frac{|x_0^{(1)}|}{|x_0^{(i)}|}\\right) = - \\log\\left(\\frac{1}{\\varepsilon} \\frac{|x_0^{(i)}|}{|x_0^{(1)}|}\\right) = - \\log\\left(\\frac{|x_0^{(i)}|}{\\varepsilon|x_0^{(1)}|}\\right)$。\n分母：$\\log\\left(\\frac{|\\lambda_i|}{|\\lambda_1|}\\right) = -\\log\\left(\\frac{|\\lambda_1|}{|\\lambda_i|}\\right)$。\n代入这些得到：\n$$\nk \\ge \\frac{-\\log\\left(\\frac{|x_0^{(i)}|}{\\varepsilon|x_0^{(1)}|}\\right)}{-\\log\\left(\\frac{|\\lambda_1|}{|\\lambda_i|}\\right)} = \\frac{\\log\\left(\\frac{|x_0^{(i)}|}{\\varepsilon|x_0^{(1)}|}\\right)}{\\log\\left(\\frac{|\\lambda_1|}{|\\lambda_i|}\\right)}\n$$\n这个不等式必须对所有 $x_0^{(i)} \\ne 0$ 的 $i \\ge 2$ 成立。因此，$k$ 必须大于或等于这些下界的最大值。\n$$\nk \\ge \\max_{\\substack{i \\ge 2 \\\\ x_0^{(i)} \\ne 0}} \\frac{\\log\\left( \\dfrac{|x_0^{(i)}|}{\\varepsilon\\,|x_0^{(1)}|} \\right)}{\\log\\left( \\dfrac{|\\lambda_1|}{|\\lambda_i|} \\right)}\n$$\n最小整数 $k$ 是满足此不等式的最小整数，这与选项的措辞一致。\n\n结论：**正确**。\n\n**D. 如果使用 $\\ell_{\\infty}$ 范数而不是 $\\ell_2$ 范数进行归一化，也就是说，$x_{k+1} = A x_k / \\lVert A x_k \\rVert_{\\infty}$，那么对于任何固定的容差 $\\varepsilon \\in (0,1)$，只要 $x_0^{(1)} \\ne 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$，达到 $\\max_{i \\ge 2} |x_k^{(i)}| \\le \\varepsilon$ 所需的迭代次数就与 $x_0$ 无关。**\n\n使用 $\\ell_{\\infty}$ 归一化，第 $k$ 次迭代是 $x_k = \\frac{A^k x_0}{\\lVert A^k x_0 \\rVert_{\\infty}}$。分量为：\n$$\nx_k^{(i)} = \\frac{\\lambda_i^k x_0^{(i)}}{\\max_{j} |\\lambda_j^k x_0^{(j)}|}\n$$\n条件是 $\\max_{i \\ge 2} |x_k^{(i)}| \\le \\varepsilon$。对于一个特定的 $i \\ge 2$，我们想要：\n$$\n|x_k^{(i)}| = \\frac{|\\lambda_i|^k |x_0^{(i)}|}{\\max_{j} |\\lambda_j^k x_0^{(j)}|} \\le \\varepsilon\n$$\n因为 $|\\lambda_1|$ 是严格占优的，对于足够大的 $k$，项 $|\\lambda_1^k x_0^{(1)}|$ 将在分母的最大值中占主导地位。我们假设 $k$ 足够大，使得 $\\lVert A^k x_0 \\rVert_{\\infty} = |\\lambda_1^k x_0^{(1)}| = |\\lambda_1|^k |x_0^{(1)}|$。那么对于 $i \\ge 2$ 的条件变为：\n$$\n\\frac{|\\lambda_i|^k |x_0^{(i)}|}{|\\lambda_1|^k |x_0^{(1)}|} = \\left(\\frac{|\\lambda_i|}{|\\lambda_1|}\\right)^k \\frac{|x_0^{(i)}|}{|x_0^{(1)}|} \\le \\varepsilon\n$$\n解出 $k$ 得到一个依赖于比率 $|x_0^{(i)}|/|x_0^{(1)}|$ 的下界。由于这个比率取决于初始向量 $x_0$，所需的迭代次数也将取决于 $x_0$。例如，一个更大的初始分量比 $|x_0^{(i)}|/|x_0^{(1)}|$ 将需要更多的迭代才能使该项衰减到 $\\varepsilon$ 以下。该陈述是错误的。\n\n结论：**不正确**。\n\n**E. 如果 $x_0$ 在索引 $j$ 处恰好有一个非零坐标，那么无论 $\\lambda_j$ 的值是多少，归一化序列都满足 $x_k = e_j$ 对于所有 $k \\ge 0$（也就是说，幂迭代法立即实现有限步收敛）。**\n\n设 $x_0 = c e_j$，其中 $c \\in \\mathbb{C}$ 是某个非零标量。该陈述声称对于所有 $k \\ge 0$，$x_k = e_j$。对于 $k=0$ 的声明意味着 $x_0 = e_j$，所以我们必须有 $c=1$。我们假设 $x_0=e_j$。\n该陈述声称这“无论 $\\lambda_j$ 的值是多少”都成立。\n*   情况1：$\\lambda_j=0$。那么 $y_1 = A x_0 = A e_j = \\lambda_j e_j = 0$。范数 $\\lVert y_1 \\rVert_2 = 0$，并且 $x_1$ 没有定义。序列无法继续，所以该声明失败。\n*   情况2：$\\lambda_j \\ne 0$。那么 $y_1 = \\lambda_j e_j$。范数是 $\\lVert y_1 \\rVert_2 = |\\lambda_j|$。下一个迭代是 $x_1 = \\frac{y_1}{\\lVert y_1 \\rVert_2} = \\frac{\\lambda_j e_j}{|\\lambda_j|}$。要使 $x_1$ 等于 $e_j$，我们必须有 $\\lambda_j / |\\lambda_j| = 1$。这仅在 $\\lambda_j$ 是一个正实数时才成立。如果 $\\lambda_j$ 是负数，或一个非实复数，则 $x_1 \\ne e_j$。例如，如果 $\\lambda_j=-2$，则 $x_1 = -e_j$。\n由于该陈述必须对任何 $\\lambda_j$ 都成立，而我们已经找到了反例，所以该陈述是错误的。\n\n结论：**不正确**。\n\n**F. 即使 $x_0^{(1)} = 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$，归一化最终会产生一个非零的第一坐标，所以 $x_k$ 会在有限步内收敛到主特征向量方向 $e_1$。**\n\n问题陈述我们假设使用精确算术。\n我们来检查迭代向量的第一个分量。给定 $x_0^{(1)}=0$。\n第一个未归一化的迭代向量是 $y_1 = A x_0$。它的第一个分量是 $y_1^{(1)} = \\lambda_1 x_0^{(1)} = \\lambda_1 \\cdot 0 = 0$。\n第一个归一化的迭代向量是 $x_1 = y_1 / \\lVert y_1 \\rVert_2$。它的第一个分量是 $x_1^{(1)} = y_1^{(1)} / \\lVert y_1 \\rVert_2 = 0 / \\lVert y_1 \\rVert_2 = 0$（假设 $y_1 \\ne 0$，否则迭代停止，但 $x_1^{(1)}$ 仍然是 $0$ 或未定义，而不是非零）。\n通过归纳法，如果我们假设 $x_k^{(1)}=0$，那么 $y_{k+1}^{(1)} = \\lambda_1 x_k^{(1)} = 0$，这意味着 $x_{k+1}^{(1)}=0$。\n由于 $x_0^{(1)}=0$，第一个分量 $x_k^{(1)}$ 对于所有 $k \\ge 0$ 都保持为0。在精确算术中，一个零分量不能自发地变成非零。迭代被限制在由 $\\{e_2, \\dots, e_n\\}$ 张成的子空间内。因此，迭代不能收敛到 $e_1$ 的方向。该陈述是错误的。\n\n结论：**不正确**。\n\n结论总结：\nA：正确\nB：不正确\nC：正确\nD：不正确\nE：不正确\nF：不正确\n\n正确的陈述是 A 和 C。",
                "answer": "$$\\boxed{AC}$$",
                "id": "3541831"
            },
            {
                "introduction": "从理想到实践，我们必须选择衡量收敛的指标。两个常见的度量标准是瑞利商的稳定性和迭代向量与特征向量方向的趋近程度。本练习 [@problem_id:3541815] 通过精心构建的例子揭示，这两个指标的收敛速度可能存在巨大差异，这对于设计稳健的停止准则是至关重要的洞见。",
                "problem": "考虑应用于实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的幂迭代法，该矩阵的特征值为 $\\lambda_1  \\lambda_2 \\ge \\cdots \\ge \\lambda_n$，对应的标准正交特征向量为 $v_1, v_2, \\ldots, v_n$。令 $x_k \\in \\mathbb{R}^n$ 为归一化迭代向量，瑞利商为 $\\rho_k = x_k^\\top A x_k$，主角 $\\theta_k \\in [0,\\pi/2]$ 为一维子空间 $\\operatorname{span}\\{x_k\\}$ 与主导特征空间 $\\mathcal{E}_1 = \\operatorname{span}\\{v_1\\}$ 之间的夹角。你可以假定一些基本的线性代数事实，例如实对称矩阵的谱定理以及瑞利商和主角的定义。\n\n选择所有正确构造了显式场景的选项，在这些场景中，瑞利商 $\\rho_k$ 看起来已收敛而主角 $\\theta_k$ 却没有（反之亦然），并且这些选项正确地阐述了幂迭代法中停止准则的几何原因和合理推论。\n\nA. 取 $n=2$，$A = \\operatorname{diag}(1, 1 - 10^{-8})$，以及 $x_0 = \\frac{1}{\\sqrt{2}}(1,1)^\\top$。此时 $\\rho_0$ 与 $\\lambda_1$ 的偏差仅为 $5 \\cdot 10^{-9}$，而主角 $\\theta_0$ 等于 $\\pi/4$。这说明当最大特征值紧密聚集时，$\\rho_k$ 可能看起来已收敛，即使 $\\theta_k$ 并不小。因此，一个仅基于 $\\rho_k$ 稳定性的停止准则可能会过早终止；建议监测角度的代理指标（例如，子空间间隙）或残差范数。\n\nB. 取 $n=2$，$A = \\operatorname{diag}(10^6, 0)$，以及 $x_0 = (\\cos \\theta, \\sin \\theta)^\\top$，其中 $\\theta = 10^{-2}$ (弧度)。此时 $\\theta_0$ 很小，但 $\\rho_0$ 比 $\\lambda_1$ 低估了大约 $100$，因此即使方向已经基本收敛，一个要求特征值绝对误差很小的停止准则也可能会运行更长时间。这说明大的谱隙会使得 $\\rho_k$ 在绝对值上滞后，而 $\\theta_k$ 已经非常小了；一个基于角度或残差的准则能更忠实地反映子空间的收敛。\n\nC. 对于实对称矩阵 $A$，量 $|\\rho_k - \\lambda_1|$ 与 $\\sin \\theta_k$ 是一致等价的，即存在一个与谱无关的常数 $C  0$ 使得对于所有单位向量 $x_k$ 都有 $C^{-1} |\\rho_k - \\lambda_1| \\le \\sin \\theta_k \\le C |\\rho_k - \\lambda_1|$。因此，$\\rho_k$ 的收敛总是意味着 $\\theta_k$ 的收敛，反之亦然，且收敛速率相当，这与谱隙无关。\n\nD. 在 $n=2$ 且 $A = \\operatorname{diag}(1, 1 - 10^{-8})$ 的情况下，任何满足 $|\\rho(x) - \\lambda_1| \\le 10^{-9}$ 的单位向量 $x$ 都必须服从 $\\theta \\le 10^{-4}$。因此，当瑞利商与最大特征值的差在 $10^{-9}$ 以内时，即使在特征值聚集的情况下，主角也必然很小。\n\n选择所有适用的选项。",
                "solution": "用户提供的问题陈述已经过验证，并被认为是合理的。这是一个在数值线性代数领域内定义明确、有科学依据的问题。其语言是客观的，所提供的信息在内部是一致的，并且足以进行严格的分析。因此，我们可以着手求解。\n\n这个问题的核心在于，对于一个实对称矩阵 $A$ 的单位向量 $x$，其瑞利商 $\\rho(x) = x^\\top A x$ 与该向量相对于主导特征向量 $v_1$ 的主角 $\\theta$ 之间的关系。设 $A \\in \\mathbb{R}^{n \\times n}$ 的特征值为 $\\lambda_1  \\lambda_2 \\ge \\cdots \\ge \\lambda_n$，其对应的标准正交特征基为 $\\{v_1, v_2, \\ldots, v_n\\}$。\n\n任何单位向量 $x \\in \\mathbb{R}^n$ 都可以在这个特征基中表示为 $x = \\sum_{i=1}^n c_i v_i$，其中 $\\sum_{i=1}^n c_i^2 = 1$。$x$ 与主导特征向量 $v_1$ 之间的主角 $\\theta$ 由 $\\cos \\theta = |x^\\top v_1| = |c_1|$ 定义。由于 $\\theta \\in [0, \\pi/2]$，我们有 $\\cos \\theta \\ge 0$。关系式 $\\cos^2 \\theta + \\sin^2 \\theta = 1$ 给出 $\\sin^2 \\theta = 1 - c_1^2 = \\sum_{i=2}^n c_i^2$。\n\n$x$ 的瑞利商为：\n$$ \\rho(x) = x^\\top A x = \\left(\\sum_{i=1}^n c_i v_i\\right)^\\top A \\left(\\sum_{j=1}^n c_j v_j\\right) = \\left(\\sum_{i=1}^n c_i v_i\\right)^\\top \\left(\\sum_{j=1}^n c_j \\lambda_j v_j\\right) $$\n由于特征向量的标准正交性 ($v_i^\\top v_j = \\delta_{ij}$)，上式可简化为：\n$$ \\rho(x) = \\sum_{i=1}^n c_i^2 \\lambda_i = c_1^2 \\lambda_1 + \\sum_{i=2}^n c_i^2 \\lambda_i $$\n瑞利商作为 $\\lambda_1$ 的近似值的误差为：\n$$ \\lambda_1 - \\rho(x) = \\lambda_1 - \\left(c_1^2 \\lambda_1 + \\sum_{i=2}^n c_i^2 \\lambda_i\\right) = (1 - c_1^2)\\lambda_1 - \\sum_{i=2}^n c_i^2 \\lambda_i $$\n代入 $1 - c_1^2 = \\sum_{i=2}^n c_i^2$，我们得到基本关系式：\n$$ \\lambda_1 - \\rho(x) = \\left(\\sum_{i=2}^n c_i^2\\right)\\lambda_1 - \\sum_{i=2}^n c_i^2 \\lambda_i = \\sum_{i=2}^n c_i^2 (\\lambda_1 - \\lambda_i) $$\n使用 $\\sin^2 \\theta = \\sum_{i=2}^n c_i^2$：\n$$ \\lambda_1 - \\rho(x) = \\sum_{i=2}^n c_i^2 (\\lambda_1 - \\lambda_i) $$\n由于 $\\lambda_1  \\lambda_2 \\ge \\cdots \\ge \\lambda_n$，我们有 $(\\lambda_1 - \\lambda_2) \\ge (\\lambda_1 - \\lambda_i)$ 对于 $i \\ge 2$，但我们也有 $(\\lambda_1 - \\lambda_i) \\ge (\\lambda_1 - \\lambda_n)$。这使我们能够对误差进行界定：\n$$ (\\lambda_1 - \\lambda_2) \\sum_{i=2}^n c_i^2 \\le \\lambda_1 - \\rho(x) \\le (\\lambda_1 - \\lambda_n) \\sum_{i=2}^n c_i^2 $$\n这就得到了联系瑞利商误差和角度的著名不等式：\n$$ (\\lambda_1 - \\lambda_2) \\sin^2 \\theta \\le \\lambda_1 - \\rho(x) \\le (\\lambda_1 - \\lambda_n) \\sin^2 \\theta $$\n注意，由于 $\\lambda_1$ 是最大特征值，$\\rho(x) \\le \\lambda_1$，所以 $\\lambda_1 - \\rho(x) = |\\rho(x) - \\lambda_1|$。这个不等式是评估各个选项的核心。\n\n### 选项评估\n\n**选项 A：**\n- **场景：** $n=2$，$A = \\operatorname{diag}(1, 1 - 10^{-8})$，$x_0 = \\frac{1}{\\sqrt{2}}(1,1)^\\top$。\n- **分析：** 我们有 $\\lambda_1 = 1$ 其 $v_1 = (1, 0)^\\top$ 以及 $\\lambda_2 = 1 - 10^{-8}$ 其 $v_2 = (0, 1)^\\top$。初始向量是 $x_0 = \\frac{1}{\\sqrt{2}}v_1 + \\frac{1}{\\sqrt{2}}v_2$。\n- **主角 $\\theta_0$**：$v_1$ 的系数是 $c_1 = 1/\\sqrt{2}$。因此，$\\cos \\theta_0 = |c_1| = 1/\\sqrt{2}$，这给出 $\\theta_0 = \\pi/4$。这是正确的。\n- **瑞利商 $\\rho_0$**：对于一个 $2 \\times 2$ 的情况，该不等式变为等式：$\\lambda_1 - \\rho_0 = (\\lambda_1 - \\lambda_2) \\sin^2 \\theta_0$。\n  谱隙为 $\\lambda_1 - \\lambda_2 = 1 - (1 - 10^{-8}) = 10^{-8}$。\n  我们有 $\\sin^2 \\theta_0 = \\sin^2(\\pi/4) = (1/\\sqrt{2})^2 = 1/2$。\n  因此，偏差为 $\\lambda_1 - \\rho_0 = (10^{-8})(1/2) = 5 \\cdot 10^{-9}$。这也是正确的。\n- **结论：** 该场景表明，在一个非常小的谱隙 ($10^{-8}$)下，瑞利商误差 ($5 \\cdot 10^{-9}$) 可以非常小，暗示已经收敛，而向量却是最大程度地未对准 ($\\theta_0 = \\pi/4$)。认为在特征值聚集的情况下，仅基于 $\\rho_k$ 的停止准则是具有误导性的，这个理由是合理的，并且是数值方法中的一个标准警示原则。监控其他量的建议是恰当的。\n- **结论：** **正确**。\n\n**选项 B：**\n- **场景：** $n=2$，$A = \\operatorname{diag}(10^6, 0)$，$x_0 = (\\cos \\theta, \\sin \\theta)^\\top$，其中 $\\theta = 10^{-2}$ 弧度。\n- **分析：** 我们有 $\\lambda_1 = 10^6$ 其 $v_1 = (1, 0)^\\top$ 以及 $\\lambda_2 = 0$ 其 $v_2 = (0, 1)^\\top$。初始向量 $x_0$ 与 $v_1$ 形成一个角度 $\\theta_0 = \\theta = 10^{-2}$。这个角度很小 ($\\approx 0.57^\\circ$)。\n- **瑞利商 $\\rho_0$**：使用与选项A中相同的等式，$\\lambda_1 - \\rho_0 = (\\lambda_1 - \\lambda_2) \\sin^2 \\theta_0$。\n  谱隙很大：$\\lambda_1 - \\lambda_2 = 10^6 - 0 = 10^6$。\n  角度是 $\\theta_0 = 10^{-2}$。对于小角度，$\\sin \\theta_0 \\approx \\theta_0$。\n  偏差为 $\\lambda_1 - \\rho_0 = 10^6 \\sin^2(10^{-2}) \\approx 10^6 (10^{-2})^2 = 10^6 \\cdot 10^{-4} = 100$。所以 $\\rho_0$ 比 $\\lambda_1$ 低估了大约 $100$。这是正确的。\n- **结论：** 这个场景正确地展示了相反的情况：一个大的谱隙意味着即使主角很小，瑞利商的绝对误差也可能很大。向量在方向上已几乎收敛，但基于特征值绝对误差小的停止准则将需要更多次迭代。这个理由是合理的。\n- **结论：** **正确**。\n\n**选项 C：**\n- **陈述：** 量 $|\\rho_k - \\lambda_1|$ 与 $\\sin \\theta_k$ 是一致等价的，即存在一个与谱无关的常数 $C  0$ 使得 $C^{-1} |\\rho_k - \\lambda_1| \\le \\sin \\theta_k \\le C |\\rho_k - \\lambda_1|$。\n- **分析：** 这个陈述是不正确的，主要有两个原因。\n  1. 关系是在 $|\\rho_k - \\lambda_1|$ 与 $\\sin^2 \\theta_k$ 之间，而不是 $\\sin \\theta_k$。具体来说， $|\\rho_k - \\lambda_1| = O(\\sin^2 \\theta_k)$。对于小的 $\\theta_k$，这意味着瑞利商的收敛相对于角度的收敛是二次的，这与所提出的线性关系有根本的不同。\n  2. 基本不等式 $(\\lambda_1 - \\lambda_2) \\sin^2 \\theta \\le |\\rho(x) - \\lambda_1| \\le (\\lambda_1 - \\lambda_n) \\sin^2 \\theta$ 表明，比例“常数”是 $(\\lambda_1 - \\lambda_2)$ 和 $(\\lambda_1 - \\lambda_n)$。这些量，即谱隙，明确地依赖于矩阵 $A$ 的谱。选项 A 和 B 为谱无关常数这一说法提供了明确的反例。\n- **结论：** **不正确**。\n\n**选项 D：**\n- **场景：** $n=2$，$A = \\operatorname{diag}(1, 1 - 10^{-8})$。其主张是，任何单位向量 $x$，若满足 $|\\rho(x) - \\lambda_1| \\le 10^{-9}$，则其角度 $\\theta$ 必须 $\\le 10^{-4}$。\n- **分析：** 对于这个矩阵，我们有关系式 $|\\rho(x) - \\lambda_1| = (\\lambda_1-\\lambda_2)\\sin^2\\theta = 10^{-8} \\sin^2\\theta$。\n  条件 $|\\rho(x) - \\lambda_1| \\le 10^{-9}$ 转化为：\n  $$ 10^{-8} \\sin^2\\theta \\le 10^{-9} $$\n  $$ \\sin^2\\theta \\le \\frac{10^{-9}}{10^{-8}} = 0.1 $$\n  取平方根，我们发现 $\\sin\\theta \\le \\sqrt{0.1} \\approx 0.316$。由于 $\\theta \\in [0, \\pi/2]$，这意味着 $\\theta \\le \\arcsin(\\sqrt{0.1}) \\approx 0.3217$ 弧度。\n  该陈述声称 $\\theta$ 必须小于或等于 $10^{-4}$。然而，我们的计算表明 $\\theta$ 可以大到约 $0.3217$ 弧度，这远大于 $10^{-4}$。例如，一个角度为 $\\theta = 0.3$ 弧度的向量具有 $|\\rho(x) - \\lambda_1| = 10^{-8} \\sin^2(0.3) \\approx 8.73 \\cdot 10^{-10}$，这满足条件 $\\le 10^{-9}$。然而，$0.3 \\gg 10^{-4}$。\n- **结论：** 这个论点在数学上是错误的。当特征值紧密聚集时，小的瑞利商误差并不能保证角度也极小。这个选项与选项A的结论相矛盾。\n- **结论：** **不正确**。",
                "answer": "$$\\boxed{AB}$$",
                "id": "3541815"
            },
            {
                "introduction": "经典的收敛速率 $\\lvert \\lambda_2 / \\lambda_1 \\rvert$ 描述了算法的渐近行为，但在实践中所需的迭代次数可能远多于此，尤其对于非正规矩阵。本练习 [@problem_id:3541827] 提供了一个动手实践的数值实验，展示了病态的特征向量基（即巨大的 $\\kappa(V)$）如何急剧放大初始向量中的非主导分量，导致在理论收敛速率生效前出现漫长的预渐近阶段。这强调了渐近速率与实际性能之间的关键区别。",
                "problem": "考虑用于可对角化矩阵的经典幂迭代法。设实矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 可对角化为 $A = V \\Lambda V^{-1}$，其中 $V$ 是满列秩矩阵，其列为 $A$ 的右特征向量，$\\Lambda = \\mathrm{diag}(\\lambda_1,\\dots,\\lambda_n)$ 包含特征值，其排序满足 $|\\lambda_1|  |\\lambda_2| \\ge \\cdots \\ge |\\lambda_n| \\ge 0$。定义幂迭代为 $x_{k+1} = A x_k / \\|A x_k\\|_2$，其中 $k \\in \\mathbb{N}$，从一个非零向量 $x_0 \\in \\mathbb{R}^n$ 开始。设 $V$ 在谱范数下的条件数为 $\\kappa_2(V) = \\|V\\|_2 \\cdot \\|V^{-1}\\|_2$，其中 $\\|\\cdot\\|_2$ 是由欧几里得向量范数诱导的矩阵范数。奇异值分解 (SVD) 是指将一个实矩阵分解为 $U \\Sigma W^\\top$ 的形式，其中 $\\Sigma$ 的对角元是奇异值；$\\kappa_2(V)$ 等于 $V$ 的最大奇异值与最小奇异值之比。幂迭代的经典渐近理论指出，在精确计算中，第 $k$ 次迭代的向量 $x_k$ 会趋向于主右特征向量的方向，其收敛速率由 $|\\lambda_2 / \\lambda_1|$ 决定。然而，在实践中，达到一个有效近似所需的迭代次数取决于初始向量 $x_0$ 在特征向量基下的展开，而这又对 $V$ 的条件数敏感。您的任务是构造具有大谱隙 $|\\lambda_2 / \\lambda_1| \\ll 1$ 但具有非常大的 $\\kappa_2(V)$ 的矩阵，并评估幂迭代需要多少步才能使在特征向量基下度量的非主导分量变得可以忽略不计。\n\n请使用以下精确的设置，该设置仅从基本定义和事实出发。对于每个测试，您必须执行归一化的幂迭代 $x_{k+1} = A x_k / \\|A x_k\\|_2$。在第 $k$ 次迭代时，通过计算系数向量 $c^{(k)} = V^{-1} x_k \\in \\mathbb{R}^n$ 将 $x_k$ 在特征向量基下展开。定义主导系数的大小为 $d^{(k)} = |c^{(k)}_1|$，最差污染分量的大小为 $t^{(k)} = \\max_{j \\ge 2} |c^{(k)}_j|$。当双正交污染比 $r^{(k)} = t^{(k)} / d^{(k)}$ 满足 $r^{(k)} \\le \\tau$（容差 $\\tau = 10^{-8}$）时，或达到 $10,000$ 次迭代上限时，宣布收敛。此处任何角度量的单位都无关紧要，因为判据完全由无量纲的 $r^{(k)}$ 定义。\n\n按如下方式构建测试套件。在每个测试中，取主特征值为 $\\lambda_1 = 1$，并令所有其余特征值等于相同的值 $\\lambda_2 = \\cdots = \\lambda_n = \\alpha$，其中 $\\alpha = 10^{-3}$。取 $\\varepsilon = 10^{-150}$。设 $v_1, \\dots, v_n$ 表示 $V$ 的列。对于初始向量，所有测试在标准坐标系下均使用相同的具体选择：$x_0$ 是单位归一化的向量，其前两个分量分别为 $1 - \\varepsilon$ 和 $\\varepsilon$，其余所有分量均为 $0$。该初始向量与 $V$ 无关，并在标准基中指定；不要从特征向量构造 $x_0$。\n\n指定四个覆盖不同方面的测试用例：\n\n- 测试 A（良态，二维）：取 $n = 2$ 和 $V = I_2$（$2 \\times 2$ 单位矩阵），因此 $\\kappa_2(V) = 1$。使用 $\\Lambda = \\mathrm{diag}(1, \\alpha)$ 构造 $A = V \\Lambda V^{-1}$，并从指定的 $x_0$ 开始运行幂迭代。\n\n- 测试 B（病态，二维）：取 $n = 2$ 并定义 $V$ 的前两列几乎共线，$v_1 = e_1$ 和 $v_2 = e_1 + \\varepsilon e_2$。使用与测试 A 中相同的 $\\Lambda$ 构造 $A = V \\Lambda V^{-1}$。此 $V$ 可逆，且其 $\\kappa_2(V)$ 的数量级为 $1/\\varepsilon$。从与测试 A 中相同的 $x_0$ 开始运行幂迭代。\n\n- 测试 C（良态，五维）：取 $n = 5$ 和 $V = I_5$（$5 \\times 5$ 单位矩阵），因此 $\\kappa_2(V) = 1$。令 $\\Lambda = \\mathrm{diag}(1, \\alpha, \\alpha, \\alpha, \\alpha)$，并从与上述相同的 $x_0$（用零填充至长度 5）开始运行幂迭代。\n\n- 测试 D（病态，五维）：取 $n = 5$ 并定义 $V$，$v_1 = e_1$，$v_2 = e_1 + \\varepsilon e_2$，对于 $j \\in \\{3,4,5\\}$，$v_j = e_j$。使用与测试 C 中相同的 $\\Lambda$ 构造 $A = V \\Lambda V^{-1}$。此 $V$ 可逆，且其 $\\kappa_2(V)$ 的数量级为 $1/\\varepsilon$。从与上述相同的 $x_0$（作适当填充）开始运行幂迭代。\n\n对于每个测试，计算满足 $r^{(k)} \\le \\tau$ 的最小整数 $k \\ge 0$，如果在此上限内未达到，则返回 $10,000$。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[resultA,resultB,resultC,resultD]”），列表中的每个条目是对应测试 A、B、C、D 的整数迭代次数。不应打印任何其他文本。所有计算都在纯数学范畴内，不涉及任何物理单位；所有报告的整数都是无单位的。",
                "solution": "用户提供的问题陈述已经过验证，被认为是科学上可靠、适定、客观和完整的。该问题描述了一个数值实验，旨在研究幂迭代法在特征向量基的不同条件数情况下的收敛行为。该设置是合理的，并基于数值线性代数的既定原则。因此，我们可以着手解决问题。\n\n任务是确定对于四个不同的矩阵，需要多少次幂迭代（记为 $k$）才能满足特定的收敛判据。幂迭代由序列 $x_{k+1} = A x_k / \\|A x_k\\|_2$ 定义，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个可对角化矩阵，$A = V \\Lambda V^{-1}$，$x_0$ 是一个起始向量。\n\n收敛性在特征向量基中进行度量。在每次迭代 $k$ 中，当前向量 $x_k$ 表示为特征向量 $v_j$（$V$ 的列）的线性组合：$x_k = \\sum_{j=1}^n c^{(k)}_j v_j$。系数向量由 $c^{(k)} = V^{-1} x_k$ 给出。收敛判据基于“双正交污染比”，定义为 $r^{(k)} = t^{(k)} / d^{(k)}$，其中 $d^{(k)} = |c^{(k)}_1|$ 是对应于主特征向量的系数的大小，而 $t^{(k)} = \\max_{j \\ge 2} |c^{(k)}_j|$ 是所有其他“污染”系数中的最大值。当 $r^{(k)} \\le \\tau$（容差 $\\tau = 10^{-8}$）时，宣布收敛。最大迭代次数上限为 $10,000$。\n\n分析过程是为每个测试用例构建指定的矩阵和初始向量，然后模拟迭代过程。进行解析检验有助于预测结果。让我们来分析系数比 $r^{(k)}$ 的演变。\n从 $x_{k+1} = A x_k / \\|A x_k\\|_2$ 出发，我们可以找到系数的变换规律：\n$c^{(k+1)} = V^{-1} x_{k+1} = V^{-1} \\frac{A x_k}{\\|A x_k\\|_2} = \\frac{V^{-1} (V \\Lambda V^{-1}) x_k}{\\|A x_k\\|_2} = \\frac{\\Lambda (V^{-1} x_k)}{\\|A x_k\\|_2} = \\frac{\\Lambda c^{(k)}}{\\|A x_k\\|_2}$。\n两个系数 $c^{(k+1)}_j$ 和 $c^{(k+1)}_1$ 之间的比值为：\n$$ \\frac{c^{(k+1)}_j}{c^{(k+1)}_1} = \\frac{\\lambda_j c^{(k)}_j / \\|A x_k\\|_2}{\\lambda_1 c^{(k)}_1 / \\|A x_k\\|_2} = \\frac{\\lambda_j}{\\lambda_1} \\frac{c^{(k)}_j}{c^{(k)}_1} $$\n这表明在每一步中，任何污染系数与主导系数的比值都会乘以相应的特征值比。通过归纳法，我们得到：\n$$ \\frac{c^{(k)}_j}{c^{(k)}_1} = \\left(\\frac{\\lambda_j}{\\lambda_1}\\right)^k \\frac{c^{(0)}_j}{c^{(0)}_1} $$\n取绝对值并对 $j \\ge 2$ 取最大值：\n$$ r^{(k)} = \\frac{\\max_{j \\ge 2} |c^{(k)}_j|}{|c^{(k)}_1|} = \\max_{j \\ge 2} \\left| \\left(\\frac{\\lambda_j}{\\lambda_1}\\right)^k \\frac{c^{(0)}_j}{c^{(0)}_1} \\right| $$\n在这个问题中，所有非主导特征值都相等，$\\lambda_2 = \\dots = \\lambda_n = \\alpha$。因此，这可以简化为：\n$$ r^{(k)} = \\left|\\frac{\\alpha}{\\lambda_1}\\right|^k \\max_{j \\ge 2} \\left| \\frac{c^{(0)}_j}{c^{(0)}_1} \\right| = \\left|\\frac{\\alpha}{\\lambda_1}\\right|^k r^{(0)} $$\n因此，迭代次数由初始污染比 $r^{(0)}$ 和谱隙决定。参数为 $\\lambda_1 = 1$，$\\alpha = 10^{-3}$，$\\varepsilon = 10^{-150}$，以及 $\\tau = 10^{-8}$。\n\n初始向量是 $x'_0$ 的归一化，其中 $x'_0$ 的前两个分量是 $1-\\varepsilon$ 和 $\\varepsilon$，其余为零。由于 $\\varepsilon$ 极小，$\\|x'_0\\|_2 \\approx 1$，所以 $x_0 \\approx x'_0$。\n\n**测试 A 和 C（良态情况）**\n对于测试 A（$n=2$）和测试 C（$n=5$），特征向量基是标准基，$V=I_n$。因此 $V^{-1}=I_n$。\n初始系数向量为 $c^{(0)} = V^{-1} x_0 = x_0$。\n对于 $n=5$，$x_0$ 是 $[1-\\varepsilon, \\varepsilon, 0, 0, 0]^\\top$ 的归一化。归一化因子接近 $1$。\n$c^{(0)}_1 \\approx 1-\\varepsilon$，$c^{(0)}_2 \\approx \\varepsilon$，并且 $c^{(0)}_{j2}=0$。\n初始主导系数的大小为 $d^{(0)} = |c^{(0)}_1| \\approx 1-\\varepsilon$。\n最差污染分量的大小为 $t^{(0)} = \\max(|c^{(0)}_2|, |c^{(0)}_3|, \\dots) = \\varepsilon$。\n初始比率为 $r^{(0)} = t^{(0)}/d^{(0)} \\approx \\varepsilon/(1-\\varepsilon) \\approx 10^{-150}$。\n由于 $r^{(0)} \\approx 10^{-150} \\le 10^{-8} = \\tau$，收敛条件在开始时（$k=0$）即已满足。测试 A 和测试 C 的结果都是 $0$。\n\n**测试 B 和 D（病态情况）**\n对于测试 B（$n=2$），特征向量矩阵为 $V = \\begin{pmatrix} 1  1 \\\\ 0  \\varepsilon \\end{pmatrix}$。其逆矩阵为 $V^{-1} = \\begin{pmatrix} 1  -1/\\varepsilon \\\\ 0  1/\\varepsilon \\end{pmatrix}$。\n初始向量为 $x_0 \\approx [1-\\varepsilon, \\varepsilon]^\\top$。初始系数向量为：\n$$ c^{(0)} = V^{-1} x_0 \\approx \\begin{pmatrix} 1  -1/\\varepsilon \\\\ 0  1/\\varepsilon \\end{pmatrix} \\begin{pmatrix} 1-\\varepsilon \\\\ \\varepsilon \\end{pmatrix} = \\begin{pmatrix} (1-\\varepsilon) - 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -\\varepsilon \\\\ 1 \\end{pmatrix} $$\n初始大小为 $d^{(0)} \\approx \\varepsilon$ 和 $t^{(0)} \\approx 1$。\n初始比率为 $r^{(0)} = t^{(0)}/d^{(0)} \\approx 1/\\varepsilon = 10^{150}$，这是一个非常大的数。\n对于测试 D（$n=5$），矩阵 $V$ 和 $V^{-1}$ 具有影响前两个分量的相同的 $2 \\times 2$ 块结构，在其他部分则为单位矩阵。对 $c^{(0)}$ 的分析对于前两个分量保持不变，其他分量为零。因此，$r^{(0)} \\approx 10^{150}$ 在这里也适用。\n\n我们需要找到这些情况下迭代的次数 $k$。使用推导出的 $r^{(k)}$ 公式：\n$$ r^{(k)} = \\left|\\frac{\\alpha}{\\lambda_1}\\right|^k r^{(0)} \\le \\tau $$\n$$ (10^{-3})^k \\cdot 10^{150} \\le 10^{-8} $$\n$$ 10^{-3k} \\le 10^{-158} $$\n两边取以 10 为底的对数：\n$$ -3k \\le -158 $$\n$$ k \\ge \\frac{158}{3} \\approx 52.667 $$\n满足此条件的最小整数 $k$ 是 $53$。这个结果对测试 B 和测试 D 都应该成立。\n\n最终的程序将以数值方式执行幂迭代，以验证这些解析预测。测试 A、B、C 和 D 的结果预计分别为 $0$、$53$、$0$ 和 $53$。",
                "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_power_iteration(n, V, Lambda, x0_unnormalized, tau, max_iter):\n    \"\"\"\n    Performs the power iteration for a given test case.\n\n    Args:\n        n (int): The dimension of the matrix.\n        V (np.ndarray): The eigenvector matrix.\n        Lambda (np.ndarray): The diagonal eigenvalue matrix.\n        x0_unnormalized (np.ndarray): The unnormalized initial vector.\n        tau (float): The convergence tolerance.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: The number of iterations to converge, or max_iter if not converged.\n    \"\"\"\n    # Construct the matrix A and pre-compute the inverse of V\n    A = V @ Lambda @ np.linalg.inv(V)\n    V_inv = np.linalg.inv(V)\n\n    # Normalize the initial vector x_0\n    norm_x0 = np.linalg.norm(x0_unnormalized)\n    if norm_x0 == 0:\n        # This case should not occur with the problem's setup\n        return max_iter\n    x_k = x0_unnormalized / norm_x0\n\n    for k in range(max_iter):  # Loop from k = 0 to 9999\n        # 1. Expand x_k in the eigenvector basis to get coefficients c_k\n        c_k = V_inv @ x_k\n        \n        # 2. Compute dominant and contaminating magnitudes\n        d_k = np.abs(c_k[0])\n\n        # Avoid division by zero if dominant component is negligible.\n        # Given the problem setup, d_k will be small but non-zero.\n        if d_k  np.finfo(np.float64).tiny:\n            # Contamination is effectively infinite; continue iterating.\n            pass\n        else:\n            t_k = np.max(np.abs(c_k[1:]))\n            r_k = t_k / d_k\n            \n            # 3. Check for convergence\n            if r_k = tau:\n                return k\n        \n        # 4. Perform the next power iteration step\n        x_next = A @ x_k\n        norm_next = np.linalg.norm(x_next)\n        \n        if norm_next == 0:\n            # This can happen if A is singular and x_k is in its null space.\n            # A is invertible in all test cases, so this is unexpected.\n            return max_iter\n            \n        x_k = x_next / norm_next\n        \n    # If the loop completes without converging, return the cap value\n    # Check one last time at the max_iter limit\n    c_k = V_inv @ x_k\n    d_k = np.abs(c_k[0])\n    if d_k  np.finfo(np.float64).tiny:\n        return max_iter\n    t_k = np.max(np.abs(c_k[1:]))\n    r_k = t_k / d_k\n    if r_k = tau:\n        return max_iter\n    else:\n        return max_iter # The problem asks to return 10000 if not converged. Let's return the max_iter cap.\n    \ndef solve():\n    \"\"\"\n    Sets up and runs the four test cases as specified in the problem statement.\n    \"\"\"\n    # Define common parameters\n    alpha = 1.0e-3\n    epsilon = 1.0e-150\n    tau = 1.0e-8\n    max_iter = 10000\n\n    results = []\n    \n    # Use float64 for all computations\n    dtype = np.float64\n\n    # --- Test Case A ---\n    n_A = 2\n    V_A = np.identity(n_A, dtype=dtype)\n    Lambda_A = np.diag(np.array([1.0, alpha], dtype=dtype))\n    x0_un_A = np.zeros(n_A, dtype=dtype)\n    x0_un_A[0] = 1.0 - epsilon\n    x0_un_A[1] = epsilon\n    results.append(run_power_iteration(n_A, V_A, Lambda_A, x0_un_A, tau, max_iter))\n\n    # --- Test Case B ---\n    n_B = 2\n    V_B = np.array([[1.0, 1.0], [0.0, epsilon]], dtype=dtype)\n    Lambda_B = np.diag(np.array([1.0, alpha], dtype=dtype))\n    x0_un_B = np.zeros(n_B, dtype=dtype)\n    x0_un_B[0] = 1.0 - epsilon\n    x0_un_B[1] = epsilon\n    results.append(run_power_iteration(n_B, V_B, Lambda_B, x0_un_B, tau, max_iter))\n\n    # --- Test Case C ---\n    n_C = 5\n    V_C = np.identity(n_C, dtype=dtype)\n    Lambda_C = np.diag(np.array([1.0, alpha, alpha, alpha, alpha], dtype=dtype))\n    x0_un_C = np.zeros(n_C, dtype=dtype)\n    x0_un_C[0] = 1.0 - epsilon\n    x0_un_C[1] = epsilon\n    results.append(run_power_iteration(n_C, V_C, Lambda_C, x0_un_C, tau, max_iter))\n\n    # --- Test Case D ---\n    n_D = 5\n    V_D = np.identity(n_D, dtype=dtype)\n    V_D[0, 1] = 1.0\n    V_D[1, 1] = epsilon\n    Lambda_D = np.diag(np.array([1.0, alpha, alpha, alpha, alpha], dtype=dtype))\n    x0_un_D = np.zeros(n_D, dtype=dtype)\n    x0_un_D[0] = 1.0 - epsilon\n    x0_un_D[1] = epsilon\n    results.append(run_power_iteration(n_D, V_D, Lambda_D, x0_un_D, tau, max_iter))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```",
                "id": "3541827"
            }
        ]
    }