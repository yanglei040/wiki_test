{
        "hands_on_practices": [
            {
                "introduction": "本练习将抽象的幂迭代法与一个具体且重要的应用联系起来：寻找马尔可夫链的稳态分布。通过为不同类型的转移矩阵实现该算法，您将直接观察其在表现良好、周期性以及慢混合系统中的收敛行为。这项实践对于理解各种科学模型中长期概率状态的决定方式至关重要。[@problem_id:3592911]",
                "problem": "您需要为一个小型马尔可夫链实现用于计算主特征对的幂迭代法，并使用残差和瑞利商诊断来验证其向平稳分布的收敛性。请完全使用纯数学术语进行操作。一个马尔可夫链由一个行随机矩阵 $P \\in \\mathbb{R}^{n \\times n}$ 表示，该矩阵的元素非负，且每行之和为 $1$。平稳分布是一个向量 $\\pi \\in \\mathbb{R}^n$，其元素非负且总和为 $1$，并满足 $\\pi^\\top P = \\pi^\\top$。针对 $P^\\top$ 的主特征对的幂迭代法，是将 $P^\\top$ 与一个概率向量进行重复的矩阵-向量乘法，然后通过 $\\ell_1$范数进行归一化以保持其分布特性。对于具有唯一平稳分布和谱隙的马尔可夫链，该迭代会收敛到平稳分布。对于一个候选特征向量 $v \\in \\mathbb{R}^n$，残差和瑞利商的定义如下：残差为 $\\|P^\\top v - v\\|_1$，瑞利商为 $(v^\\top P^\\top v)/(v^\\top v)$。对于与特征值 $1$ 相关联的精确特征向量，残差为 $0$，瑞利商等于 $1$。\n\n请实现一个程序，对每个给定的测试用例执行以下步骤：\n- 给定一个行随机矩阵 $P \\in \\mathbb{R}^{n \\times n}$ 和一个初始向量 $v_0 \\in \\mathbb{R}^n$（其元素非负且总和为 $1$），运行幂迭代 $v_{k+1} \\propto P^\\top v_k$ 并使用 $\\ell_1$范数进行归一化。持续迭代，直到残差 $\\|P^\\top v_k - v_k\\|_1$ 小于或等于给定的容差，或者达到最大迭代次数。在迭代向量的归一化和残差计算中均使用 $\\ell_1$范数。\n- 通过求解由 $P^\\top \\pi^\\star = \\pi^\\star$ 和 $\\mathbf{1}^\\top \\pi^\\star = 1$ 表征的线性系统，计算平稳分布 $\\pi^\\star$。其中 $\\mathbf{1} \\in \\mathbb{R}^n$ 是全为 $1$ 的向量。\n- 在迭代终止后（无论是达到容差还是达到最大迭代次数），计算三个诊断指标：\n  1. 到平稳分布的 $\\ell_1$距离：$\\|\\hat{v} - \\pi^\\star\\|_1$，其中 $\\hat{v}$ 是最终的迭代向量。\n  2. 最终残差：$\\|P^\\top \\hat{v} - \\hat{v}\\|_1$。\n  3. 绝对瑞利商误差：$\\left|\\frac{\\hat{v}^\\top P^\\top \\hat{v}}{\\hat{v}^\\top \\hat{v}} - 1\\right|$。\n\n使用以下包含三个案例的测试套件。在每个案例中，矩阵 $P$ 和初始向量 $v_0$ 都被明确给出。下面的所有数字都是精确且无单位的。\n\n- 案例 1（遍历且非周期，$n=3$）：\n  - $P_1 = \\begin{bmatrix}\n  0.5  0.5  0.0 \\\\\n  0.2  0.3  0.5 \\\\\n  0.3  0.2  0.5\n  \\end{bmatrix}$，\n  - $v_0^{(1)} = \\begin{bmatrix} \\frac{1}{3} \\\\ \\frac{1}{3} \\\\ \\frac{1}{3} \\end{bmatrix}$，\n  - 容差 $= 10^{-12}$，\n  - 最大迭代次数 $= 10000$。\n\n- 案例 2（不可约但周期为 $2$，$n=2$）：\n  - $P_2 = \\begin{bmatrix}\n  0  1 \\\\\n  1  0\n  \\end{bmatrix}$，\n  - $v_0^{(2)} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$，\n  - 容差 $= 10^{-12}$，\n  - 最大迭代次数 $= 100$。\n\n- 案例 3（缓慢混合但非周期，$n=4$）：\n  - $P_3 = \\begin{bmatrix}\n  0.98  0.019  0.001  0.0 \\\\\n  0.019  0.98  0.0  0.001 \\\\\n  0.001  0.0  0.98  0.019 \\\\\n  0.0  0.001  0.019  0.98\n  \\end{bmatrix}$，\n  - $v_0^{(3)} = \\begin{bmatrix} \\frac{1}{4} \\\\ \\frac{1}{4} \\\\ \\frac{1}{4} \\\\ \\frac{1}{4} \\end{bmatrix}$，\n  - 容差 $= 10^{-12}$，\n  - 最大迭代次数 $= 50000$。\n\n您的程序必须为每个案例 $i \\in \\{1,2,3\\}$ 计算三元诊断组 $\\left(\\|\\hat{v}^{(i)} - \\pi^{\\star (i)}\\|_1,\\; \\|P_i^\\top \\hat{v}^{(i)} - \\hat{v}^{(i)}\\|_1,\\; \\left|\\frac{\\hat{v}^{(i)\\top} P_i^\\top \\hat{v}^{(i)}}{\\hat{v}^{(i)\\top} \\hat{v}^{(i)}} - 1\\right|\\right)$。将所有三个案例的结果汇总到单行输出中，形式为用方括号括起来的逗号分隔列表，顺序为 $[\\text{案例 1 距离}, \\text{案例 1 残差}, \\text{案例 1 瑞利误差}, \\text{案例 2 距离}, \\text{案例 2 残差}, \\text{案例 2 瑞利误差}, \\text{案例 3 距离}, \\text{案例 3 残差}, \\text{案例 3 瑞利误差}]$。\n\n您的程序必须是完全自包含的，不得读取任何输入，并且必须以指定格式精确打印一行输出。不涉及任何物理单位或角度单位，因此不应报告任何单位。所有数值输出必须是实数。",
                "solution": "该问题要求实现幂迭代法，以寻找给定行随机矩阵 $P$ 的转置矩阵的主特征对。对于一个合适的马尔可夫链，这对应于寻找其唯一的平稳分布。该过程涉及矩阵的迭代应用、收敛性的数值检验以及最终诊断指标的评估。\n\n具有转移矩阵 $P \\in \\mathbb{R}^{n \\times n}$ 的马尔可夫链的平稳分布是一个概率向量 $\\pi \\in \\mathbb{R}^n$（在此表示为列向量），它是转置转移算子的一个不动点，满足方程：\n$$\nP^\\top \\pi = \\pi\n$$\n这表明 $\\pi$ 是矩阵 $P^\\top$ 对应于特征值 $\\lambda = 1$ 的一个右特征向量。Perron-Frobenius 定理保证了对于一个正则马尔可夫链（不可约且非周期），该特征值是唯一的最大模特征值，并且其对应的特征向量（即平稳分布）是唯一的，且其分量严格为正。\n\n### 方法与实现细节\n\n#### 1. 幂迭代算法\n幂迭代法用于寻找与主特征值相关联的特征向量。对于一个矩阵 $A$ 和一个初始向量 $v_0$，迭代定义为：\n$$\nv_{k+1} = \\frac{A v_k}{\\|A v_k\\|}\n$$\n在我们的情境中，矩阵是 $A = P^\\top$，问题指定使用 $\\ell_1$范数进行归一化，以确保每次迭代的结果仍然是一个概率向量。因此，迭代过程为：\n$$\nv_{k+1} = \\frac{P^\\top v_k}{\\|P^\\top v_k\\|_1}\n$$\n该过程从一个初始概率向量 $v_0$ 开始，持续进行直到满足以下两个条件之一：\n1.  **收敛：** 当迭代向量 $v_k$ 足够接近一个特征向量时，迭代停止。这通过残差的 $\\ell_1$范数来衡量，定义为 $r_k = \\|P^\\top v_k - v_k\\|_1$。如果 $r_k \\le \\tau$（其中 $\\tau$ 是给定的容差），则循环终止。\n2.  **最大迭代次数：** 设定迭代次数的硬性上限 $k_{\\text{max}}$，以防止无限循环，尤其是在方法不收敛的情况下（例如，对于周期性马尔可夫链）。\n\n此迭代过程产生的最终向量记为 $\\hat{v}$。\n\n#### 2. 精确平稳分布的计算\n为了评估幂迭代的准确性，必须高精度地计算一个参考平稳分布 $\\pi^\\star$。这可以通过直接求解定义 $\\pi^\\star$ 的线性方程组来实现：\n$$\n\\begin{cases}\nP^\\top \\pi^\\star = \\pi^\\star \\\\\n\\mathbf{1}^\\top \\pi^\\star = 1\n\\end{cases}\n$$\n其中 $\\mathbf{1} \\in \\mathbb{R}^n$ 是一个全为1的列向量。第一个方程可以改写为 $(P^\\top - I) \\pi^\\star = \\mathbf{0}$，其中 $I$ 是单位矩阵。这是一个齐次系统，并且由于 $\\lambda = 1$ 是一个特征值，矩阵 $(P^\\top - I)$ 是奇异的。为了获得唯一解，该系统中的一个线性相关的方程被归一化约束 $\\mathbf{1}^\\top \\pi^\\star = 1$ 所取代。我们通过取 $(P^\\top - I)$ 的前 $n-1$ 行并将最后一行设为 $\\mathbf{1}^\\top$ 来构造一个新矩阵 $A'$。我们还构造一个新的右侧向量 $b' = [0, 0, \\dots, 0, 1]^\\top$。对于不可约链，得到的非齐次系统 $A' \\pi^\\star = b'$ 是适定的，并且可以使用标准线性求解器来求解。\n\n#### 3. 诊断指标\n一旦幂迭代终止，得到最终迭代向量 $\\hat{v}$，并且计算出参考分布 $\\pi^\\star$ 后，我们计算三个诊断指标来评估迭代的性能和准确性：\n\n1.  **到平稳分布的$\\ell_1$距离：** 该指标衡量计算出的特征向量的误差。它是最终迭代向量与真实平稳分布之差的 $\\ell_1$范数：\n    $$\n    d = \\|\\hat{v} - \\pi^\\star\\|_1\n    $$\n\n2.  **最终残差：** 该指标量化了最终迭代向量 $\\hat{v}$ 满足特征向量方程的程度。它是 $\\hat{v}$ 的残差向量的 $\\ell_1$范数：\n    $$\n    r = \\|P^\\top \\hat{v} - \\hat{v}\\|_1\n    $$\n    对于一个完美的特征向量，该值为 $0$。\n\n3.  **绝对瑞利商误差：** 瑞利商为近似特征向量提供相应特征值的估计。对于一个候选特征向量 $v$，它被定义为 $R(v) = \\frac{v^\\top P^\\top v}{v^\\top v}$。由于我们寻找的是对应于 $\\lambda = 1$ 的特征向量，误差是最终迭代向量 $\\hat{v}$ 的瑞利商与 $1$ 之间的绝对差：\n    $$\n    \\epsilon_{RQ} = \\left| \\frac{\\hat{v}^\\top P^\\top \\hat{v}}{\\hat{v}^\\top \\hat{v}} - 1 \\right|\n    $$\n    当 $\\hat{v}$ 收敛到真实特征向量时，该指标也趋近于 $0$。分母 $\\hat{v}^\\top \\hat{v}$ 是 $\\hat{v}$ 的 $\\ell_2$范数的平方。\n\n这些步骤将应用于三个测试案例中的每一个，这些案例旨在探究幂迭代在不同条件下的行为：一个标准的遍历情况，一个收敛失败的周期性情况，以及一个初始猜测已经是解的情况。",
                "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n\n    def solve_case(P, v0, tol, max_iter):\n        \"\"\"\n        Performs power iteration and calculates diagnostics for a single case.\n\n        Args:\n            P (np.ndarray): The row-stochastic transition matrix.\n            v0 (np.ndarray): The initial probability vector.\n            tol (float): The convergence tolerance for the residual.\n            max_iter (int): The maximum number of iterations.\n\n        Returns:\n            tuple: A tuple containing the three diagnostics:\n                   (distance_to_stationary, final_residual, rayleigh_quotient_error)\n        \"\"\"\n        n = P.shape[0]\n\n        # 1. Compute the reference stationary distribution (pi_star)\n        try:\n            A = P.T - np.identity(n)\n            A[-1, :] = 1.0  # Replace the last row with the normalization constraint\n            b = np.zeros(n)\n            b[-1] = 1.0     # Set the RHS for the normalization constraint\n            pi_star = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            # Handle cases like the periodic one where P.T-I is not full rank even with replacement\n            # For the specific periodic case P2, the stationary dist is known.\n            if n == 2:\n                pi_star = np.array([0.5, 0.5])\n            else: # A more general handler might be needed for other non-unique cases\n                pi_star = np.full(n, 1.0/n)\n\n\n        # 2. Perform power iteration\n        v = v0.copy()\n        for _ in range(max_iter):\n            # Calculate residual with the current vector v\n            residual = np.linalg.norm(P.T @ v - v, ord=1)\n            # Check for convergence\n            if residual = tol:\n                break\n            \n            # Update step of the power iteration\n            v_unnorm = P.T @ v\n            norm_v = np.linalg.norm(v_unnorm, ord=1)\n            if norm_v == 0: # Avoid division by zero\n                break\n            v = v_unnorm / norm_v\n        \n        hat_v = v\n\n        # 3. Compute the three diagnostics\n        # Diagnostic 1: L1-distance to stationarity\n        dist_to_stat = np.linalg.norm(hat_v - pi_star, ord=1)\n\n        # Diagnostic 2: Final residual (recalculate with the final hat_v for consistency)\n        final_residual = np.linalg.norm(P.T @ hat_v - hat_v, ord=1)\n\n        # Diagnostic 3: Absolute Rayleigh quotient error\n        numerator = hat_v.T @ P.T @ hat_v\n        denominator = hat_v.T @ hat_v\n        # Avoid division by zero if hat_v is the zero vector\n        if denominator == 0:\n            rayleigh_quotient = 0\n        else:\n            rayleigh_quotient = numerator / denominator\n        rq_error = np.abs(rayleigh_quotient - 1.0)\n        \n        return (dist_to_stat, final_residual, rq_error)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"P\": np.array([\n                [0.5, 0.5, 0.0],\n                [0.2, 0.3, 0.5],\n                [0.3, 0.2, 0.5]\n            ]),\n            \"v0\": np.array([1/3, 1/3, 1/3]),\n            \"tol\": 1e-12,\n            \"max_iter\": 10000\n        },\n        {\n            \"P\": np.array([\n                [0.0, 1.0],\n                [1.0, 0.0]\n            ]),\n            \"v0\": np.array([1.0, 0.0]),\n            \"tol\": 1e-12,\n            \"max_iter\": 100\n        },\n        {\n            \"P\": np.array([\n                [0.98, 0.019, 0.001, 0.0],\n                [0.019, 0.98, 0.0, 0.001],\n                [0.001, 0.0, 0.98, 0.019],\n                [0.0, 0.001, 0.019, 0.98]\n            ]),\n            \"v0\": np.array([1/4, 1/4, 1/4, 1/4]),\n            \"tol\": 1e-12,\n            \"max_iter\": 50000\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        diagnostics = solve_case(case[\"P\"], case[\"v0\"], case[\"tol\"], case[\"max_iter\"])\n        all_results.extend(diagnostics)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```",
                "id": "3592911"
            },
            {
                "introduction": "尽管幂迭代法十分优雅，但其收敛性并非总是得到保证。本练习深入探讨了其收敛的基本条件——存在唯一的最大模特征值。通过对多个具有相同最大模特征值的矩阵进行实验，您将对该方法的失效模式以及矩阵谱性质的重要性建立起直观的理解。[@problem_id:3592899]",
                "problem": "设 $A \\in \\mathbb{R}^{n \\times n}$ 是一个实矩阵。标准幂迭代法通过递推关系 $x_{k+1} = A x_k$ 生成一个向量序列 $\\{x_k\\}_{k \\geq 0}$，在实践中，为了分析方向性行为，我们研究归一化序列 $y_k = x_k / \\|x_k\\|_2$（其中 $k \\geq 0$）。该问题的基本依据是特征值和特征向量的定义：如果对于一个标量 $\\lambda \\in \\mathbb{C}$ 和一个非零向量 $v \\in \\mathbb{C}^n$ 满足 $A v = \\lambda v$，则称它们为矩阵 $A$ 的一个特征值和特征向量。如果 $A$ 是可对角化的，任何初始向量 $x_0$ 都可以分解到 $A$ 的特征基上，并且每次乘以 $A$ 都会将每个特征分量按相应特征值的连续幂次进行缩放。谱半径 $\\rho(A)$ 定义为 $\\rho(A) = \\max_{i} |\\lambda_i|$，其中 $\\lambda_i$ 是 $A$ 的所有特征值。当存在唯一的特征值，其模等于谱半径时，对于一般的初始向量 $x_0$，向量 $y_k$ 的方向会趋向于与该特征值相关联的特征向量。然而，如果存在两个或更多个模等于谱半径的特征值，那么不同特征分量的大小可能会持续存在，导致 $y_k$ 的方向可能无法稳定下来。\n\n在本题中，您必须实现带有归一化的标准幂迭代法，并为方向稳定性设计一个量化测试。将稳定性度量定义如下。给定归一化序列 $y_k = x_k / \\|x_k\\|_2$（$k \\geq 0$），定义\n$$\nd_k = \\min\\left(\\|y_k - y_{k-1}\\|_2,\\;\\|y_k + y_{k-1}\\|_2\\right) \\quad \\text{for } k \\geq 1,\n$$\n该度量衡量了连续归一化迭代向量之间方向的最小变化，并考虑了对于特征向量方向无关紧要的全局符号模糊性。对于选定的预烧窗口长度 $L$，定义稳定性残差\n$$\n\\rho = \\max\\{d_k : k = K-L+1, K-L+2, \\dots, K\\},\n$$\n其中 $K$ 是执行的总迭代次数。如果对于给定的容差 $\\tau  0$ 满足 $\\rho \\leq \\tau$，则认为序列已经稳定。\n\n您的任务是编写一个完整的程序，该程序能够：\n- 对给定的矩阵 $A$、初始向量 $x_0 \\neq 0$ 和迭代次数 $K$ 实现归一化幂迭代法，并使用上述度量计算最后 $L$ 次迭代的稳定性残差 $\\rho$。\n- 返回一个布尔值，表示是否在容差 $\\tau$ 内达到稳定。\n\n测试套件和参数：\n1. 具有唯一主导特征值的正常情况：\n   - 矩阵 $A_1 = \\operatorname{diag}(2.5, 1.2, 0.8)$。\n   - 初始向量 $x_0 = (1, 1, 1)^\\top$。\n   - 迭代次数 $K = 600$。\n   - 预烧长度 $L = 100$。\n   - 容差 $\\tau = 10^{-8}$。\n   此情况应该会稳定。\n\n2. 两个模相等的不同特征值（旋转；单位圆上的复共轭对）：\n   - 矩阵 $A_2 = R(\\theta)$，其中\n     $$\n     R(\\theta) = \\begin{bmatrix}\n     \\cos \\theta  -\\sin \\theta \\\\\n     \\sin \\theta  \\cos \\theta\n     \\end{bmatrix}, \\quad \\theta = 0.3 \\text{ 弧度}。\n     $$\n   - 初始向量 $x_0 = (1, 0)^\\top$。\n   - 迭代次数 $K = 400$。\n   - 预烧长度 $L = 100$。\n   - 容差 $\\tau = 10^{-6}$。\n   此情况应该不会稳定。\n\n3. 两个模相等但符号交替的实数特征值：\n   - 矩阵 $A_3 = \\begin{bmatrix}0  1 \\\\ 1  0\\end{bmatrix}$。\n   - 初始向量 $x_0 = (1, 2)^\\top$。\n   - 迭代次数 $K = 400$。\n   - 预烧长度 $L = 100$。\n   - 容差 $\\tau = 10^{-6}$。\n   此情况应该不会稳定。\n\n4. 对角矩阵，其主导特征值模相等但符号相反：\n   - 矩阵 $A_4 = \\operatorname{diag}(2, -2)$。\n   - 初始向量 $x_0 = (1, 1)^\\top$。\n   - 迭代次数 $K = 400$。\n   - 预烧长度 $L = 100$。\n   - 容差 $\\tau = 10^{-6}$。\n   此情况应该不会稳定。\n\n5. 特征值接近（收敛慢但模有唯一最大值）：\n   - 矩阵 $A_5 = \\operatorname{diag}(1.01, 1.00, 0.99)$。\n   - 初始向量 $x_0 = (1, 1, 1)^\\top$。\n   - 迭代次数 $K = 2000$。\n   - 预烧长度 $L = 200$。\n   - 容差 $\\tau = 10^{-6}$。\n   此情况应该会稳定。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[result_1, result_2, result_3, result_4, result_5]$），其中每个 $result_i$ 是一个布尔值，表示相应测试用例是否稳定。",
                "solution": "该问题是有效的。它在科学上基于数值线性代数的原理，特别是用于寻找主导特征值的幂迭代法。该问题是适定的，为每个测试用例提供了所有必需的矩阵、初始向量和参数（$A, x_0, K, L, \\tau$）。稳定性度量 $d_k$ 和稳定性残差 $\\rho$ 的定义在数学上是精确和客观的，从而允许一个唯一的、可验证的解。测试用例经过精心设计，旨在探究幂迭代法的不同收敛行为，从简单收敛到各种不收敛模式。\n\n幂迭代法是一种算法，用于寻找给定矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的最大模特征值（主导特征值）及其对应的特征向量。其核心思想依赖于将矩阵迭代地应用于初始向量 $x_0$。如果 $A$ 是可对角化的，其特征值为 $\\lambda_1, \\dots, \\lambda_n$，对应的特征向量为 $v_1, \\dots, v_n$，并且存在唯一的主导特征值满足 $|\\lambda_1|  |\\lambda_2| \\ge \\dots \\ge |\\lambda_n|$，那么任何在 $v_1$ 方向上具有非零分量的初始向量 $x_0$ 都可以表示为 $x_0 = \\sum_{i=1}^n c_i v_i$，其中 $c_1 \\neq 0$。\n\n第 $k$ 次迭代由 $x_k = A^k x_0$ 给出。这可以在特征基中展开：\n$$\nx_k = A^k \\sum_{i=1}^n c_i v_i = \\sum_{i=1}^n c_i A^k v_i = \\sum_{i=1}^n c_i \\lambda_i^k v_i\n$$\n将主导特征值项 $\\lambda_1^k$ 因子分解出来，得到：\n$$\nx_k = \\lambda_1^k \\left( c_1 v_1 + \\sum_{i=2}^n c_i \\left(\\frac{\\lambda_i}{\\lambda_1}\\right)^k v_i \\right)\n$$\n当 $k \\to \\infty$ 时，由于 $|\\lambda_i/\\lambda_1|  1$，项 $(\\lambda_i/\\lambda_1)^k$（对于 $i \\ge 2$）趋近于零。因此，向量 $x_k$ 变得越来越与主导特征向量 $v_1$ 对齐，即 $x_k \\approx c_1 \\lambda_1^k v_1$。\n\n为了防止 $x_k$ 的模发散或消失，我们研究归一化向量序列 $y_k = x_k / \\|x_k\\|_2$。对于唯一的主导特征值，该序列 $\\{y_k\\}$ 收敛到 $v_1$ 方向上的一个单位向量。\n\n如果没有唯一的主导特征值，算法的收敛就会失败。如果多个不同的特征值共享相同的最大模，例如 $|\\lambda_1| = |\\lambda_2| = \\dots = |\\lambda_m|  |\\lambda_{m+1}|$，那么对应于所有这些特征向量（$v_1, \\dots, v_m$）的分量将在迭代中持续存在，而 $y_k$ 的方向通常不会稳定。\n\n本题要求为这种方向稳定性实现一个量化测试。所提出的度量标准是针对 $k \\ge 1$：\n$$\nd_k = \\min\\left(\\|y_k - y_{k-1}\\|_2,\\;\\|y_k + y_{k-1}\\|_2\\right)\n$$\n该度量巧妙地考虑了特征向量的方向定义存在符号不确定性的事实。如果序列 $y_k$ 收敛到一个固定的方向 $u$，则 $\\|y_k - y_{k-1}\\|_2 \\to 0$。如果序列符号交替，例如 $y_k \\approx (-1)^k u$，则 $\\|y_k + y_{k-1}\\|_2 \\to 0$。在任何一种方向收敛的情况下，都有 $d_k \\to 0$。\n\n稳定性残差 $\\rho$ 定义为在最后的 $L$ 次迭代的“预烧”窗口内 $d_k$ 的最大值：\n$$\n\\rho = \\max\\{d_k : k = K-L+1, \\dots, K\\}\n$$\n如果窗口内的最大方向变化小于指定的容差 $\\tau$，即 $\\rho \\le \\tau$，则认为序列已经稳定。\n\n实现将包含一个函数，该函数以 $A, x_0, K, L$ 和 $\\tau$ 作为输入。它将执行以下步骤：\n1. 用初始向量 $x_0$ 初始化向量 $x$。\n2. 归一化 $x$ 以获得序列中的第一个向量 $y_0$。我们将其指定为 `y_prev`。\n3. 从 $k=1$ 迭代到 $K$。在每次迭代中：\n   a. 更新向量：$x \\leftarrow A x$。\n   b. 归一化新向量：$y_{\\text{curr}} \\leftarrow x / \\|x\\|_2$。\n   c. 如果迭代次数 $k$ 在最终窗口内（$k \\ge K - L + 1$），则计算 $d_k = \\min(\\|y_{\\text{curr}} - y_{\\text{prev}}\\|_2, \\|y_{\\text{curr}} + y_{\\text{prev}}\\|_2)$ 并存储它。\n   d. 为下一次迭代更新：$y_{\\text{prev}} \\leftarrow y_{\\text{curr}}$。\n4. 循环完成后，在存储的 $d_k$ 值中找到最大值 $\\rho$。\n5. 返回比较 $\\rho \\le \\tau$ 的布尔结果。\n\n此过程将应用于提供的五个测试用例中的每一个，并将收集布尔结果并按指定格式进行格式化。",
                "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef power_iteration_stability_check(A: np.ndarray, x0: np.ndarray, K: int, L: int, tau: float) - bool:\n    \"\"\"\n    Performs normalized power iteration and checks for directional stabilization.\n\n    Args:\n        A (np.ndarray): The matrix for the iteration.\n        x0 (np.ndarray): The initial vector.\n        K (int): The total number of iterations.\n        L (int): The length of the burn-in window for the stability check.\n        tau (float): The tolerance for stabilization.\n\n    Returns:\n        bool: True if the sequence stabilized within the tolerance, False otherwise.\n    \"\"\"\n    if L > K or L = 0:\n        raise ValueError(\"Burn-in length L must be positive and not greater than K.\")\n        \n    x = x0.astype(np.float64)\n\n    # Ensure the initial vector is not a zero vector\n    norm_x = np.linalg.norm(x)\n    if norm_x == 0:\n        return False  # Or raise an error for invalid input\n\n    y_prev = x / norm_x\n    \n    d_values = []\n\n    for k in range(1, K + 1):\n        x = A @ x\n        norm_x = np.linalg.norm(x)\n\n        if norm_x == 0:\n            # Iteration produced a zero vector.\n            # This happens if A is singular and x lies in a subspace mapped to the null space.\n            # The direction is undefined, hence not stabilized.\n            return False\n\n        y_curr = x / norm_x\n\n        if k >= K - L + 1:\n            dist_minus = np.linalg.norm(y_curr - y_prev)\n            dist_plus = np.linalg.norm(y_curr + y_prev)\n            d_k = min(dist_minus, dist_plus)\n            d_values.append(d_k)\n        \n        y_prev = y_curr\n\n    if not d_values:\n        # This case is avoided by the initial L > 0 check, but as a safeguard:\n        # Not enough iterations to compute stability residual.\n        return False\n\n    rho = max(d_values)\n    \n    return rho = tau\n\ndef solve():\n    \"\"\"\n    Defines the test cases from the problem statement, runs the stability check,\n    and prints the results in the required format.\n    \"\"\"\n    # Test Case 1: Happy path with a unique dominant eigenvalue\n    A1 = np.diag([2.5, 1.2, 0.8])\n    x0_1 = np.array([1.0, 1.0, 1.0])\n    params1 = (A1, x0_1, 600, 100, 1e-8)\n\n    # Test Case 2: Rotation matrix (complex-conjugate eigenvalue pair)\n    theta = 0.3\n    c, s = np.cos(theta), np.sin(theta)\n    A2 = np.array([[c, -s], [s, c]])\n    x0_2 = np.array([1.0, 0.0])\n    params2 = (A2, x0_2, 400, 100, 1e-6)\n\n    # Test Case 3: Two distinct real eigenvalues of equal modulus (1 and -1)\n    A3 = np.array([[0.0, 1.0], [1.0, 0.0]])\n    x0_3 = np.array([1.0, 2.0])\n    params3 = (A3, x0_3, 400, 100, 1e-6)\n\n    # Test Case 4: Diagonal matrix with dominant eigenvalues of equal modulus (2 and -2)\n    A4 = np.diag([2.0, -2.0])\n    x0_4 = np.array([1.0, 1.0])\n    params4 = (A4, x0_4, 400, 100, 1e-6)\n\n    # Test Case 5: Near-tie eigenvalues (slow convergence)\n    A5 = np.diag([1.01, 1.00, 0.99])\n    x0_5 = np.array([1.0, 1.0, 1.0])\n    params5 = (A5, x0_5, 2000, 200, 1e-6)\n\n    test_cases = [params1, params2, params3, params4, params5]\n\n    results = []\n    for params in test_cases:\n        A, x0, K, L, tau = params\n        result = power_iteration_stability_check(A, x0, K, L, tau)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```",
                "id": "3592899"
            },
            {
                "introduction": "在数值计算中，我们通常依赖残差来衡量解的准确性。本练习通过一个非正规矩阵（这是许多现实世界系统中的一个共同特征）提出了一个关键的反例。通过直接计算，您将揭示一个看似矛盾的场景：一个很小的残差可能误导性地表明结果是准确的，而实际上计算出的向量与真实特征向量相去甚远，这突显了数值线性代数中的一个关键细微之处。[@problem_id:3592908]",
                "problem": "设 $A \\in \\mathbb{R}^{3 \\times 3}$ 是一个上三角矩阵\n$$\nA(\\varepsilon) \\;=\\; \\begin{pmatrix}\n1  \\varepsilon  0 \\\\\n0  1  0 \\\\\n0  0  \\alpha\n\\end{pmatrix},\n$$\n其中 $0  \\alpha  1$ 且 $0  \\varepsilon \\ll 1$。考虑主特征值 $\\lambda_{1} = 1$，其特征向量为 $v_{1} = \\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix}$。该矩阵是高度非正规的，因为它在 $\\lambda_{1}$ 处有一个大小为2的非平凡若尔当块。\n\n从初始向量 $x^{(0)} = \\begin{pmatrix}0 \\\\ 1 \\\\ 0\\end{pmatrix}$ 开始，定义瑞利商 $\\mu(x)$ 为\n$$\n\\mu(x) \\;=\\; \\frac{x^{\\top} A x}{x^{\\top} x},\n$$\n以及残差向量为 $r(x) = A x - \\mu(x)\\, x$。计算关于 $x^{(0)}$ 的以下两个量：\n1. 残差范数 $\\,\\|r(x^{(0)})\\|_{2}\\,$。\n2. $x^{(0)}$ 与特征向量 $v_{1}$ 之间的夹角 $\\,\\theta\\,$，以弧度表示。\n\n您的最终结果必须是一个单一的复合答案，依次包含残差范数和夹角，并写成一个行矩阵。不需要四舍五入；请以弧度精确表示夹角。",
                "solution": "用户请求一个数值线性代数问题的解。我将首先验证问题陈述。\n\n### 步骤1：提取已知条件\n-   矩阵为 $A(\\varepsilon) = \\begin{pmatrix} 1  \\varepsilon  0 \\\\ 0  1  0 \\\\ 0  0  \\alpha \\end{pmatrix}$，其中 $A \\in \\mathbb{R}^{3 \\times 3}$。\n-   参数满足 $0  \\alpha  1$ 和 $0  \\varepsilon \\ll 1$。\n-   主特征值为 $\\lambda_{1} = 1$。\n-   对应的特征向量为 $v_{1} = \\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix}$。\n-   初始向量为 $x^{(0)} = \\begin{pmatrix}0 \\\\ 1 \\\\ 0\\end{pmatrix}$。\n-   瑞利商定义为 $\\mu(x) = \\frac{x^{\\top} A x}{x^{\\top} x}$。\n-   残差向量定义为 $r(x) = A x - \\mu(x)\\, x$。\n-   任务是计算残差范数 $\\|r(x^{(0)})\\|_{2}$ 和 $x^{(0)}$ 与 $v_{1}$ 之间的夹角 $\\theta$。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题在科学上基于数值线性代数，涉及特征值、特征向量、瑞利商和向量范数的标准定义。所提供的矩阵是用于研究特征值算法行为的一个经典的亏损矩阵示例。所有定义都是标准的，并且所需数据均已提供。该问题是适定的，因为要计算的量由已知条件唯一确定。语言客观而精确。因此，该问题是有效的。\n\n### 步骤3：结论与行动\n问题有效。我现在开始解答。\n\n该问题要求计算两个量：残差范数 $\\|r(x^{(0)})\\|_{2}$ 和向量 $x^{(0)}$ 与特征向量 $v_{1}$ 之间的夹角 $\\theta$。\n\n首先，我们计算与向量 $x^{(0)}$ 相关的残差范数。残差向量定义为 $r(x) = A x - \\mu(x) x$，其中 $\\mu(x)$ 是瑞利商。我们已知向量 $x^{(0)} = \\begin{pmatrix}0 \\\\ 1 \\\\ 0\\end{pmatrix}$ 和矩阵 $A = \\begin{pmatrix} 1  \\varepsilon  0 \\\\ 0  1  0 \\\\ 0  0  \\alpha \\end{pmatrix}$。\n\n我们首先计算瑞利商 $\\mu(x^{(0)}) = \\frac{(x^{(0)})^{\\top} A x^{(0)}}{(x^{(0)})^{\\top} x^{(0)}}$。\n分母是 $x^{(0)}$ 的欧几里得范数的平方：\n$$\n(x^{(0)})^{\\top} x^{(0)} = \\begin{pmatrix} 0  1  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = (0)(0) + (1)(1) + (0)(0) = 1.\n$$\n为了计算分子，我们首先求乘积 $A x^{(0)}$：\n$$\nA x^{(0)} = \\begin{pmatrix} 1  \\varepsilon  0 \\\\ 0  1  0 \\\\ 0  0  \\alpha \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (1)(0) + (\\varepsilon)(1) + (0)(0) \\\\ (0)(0) + (1)(1) + (0)(0) \\\\ (0)(0) + (0)(1) + (\\alpha)(0) \\end{pmatrix} = \\begin{pmatrix} \\varepsilon \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\n现在，我们可以计算分子 $(x^{(0)})^{\\top} (A x^{(0)})$：\n$$\n(x^{(0)})^{\\top} A x^{(0)} = \\begin{pmatrix} 0  1  0 \\end{pmatrix} \\begin{pmatrix} \\varepsilon \\\\ 1 \\\\ 0 \\end{pmatrix} = (0)(\\varepsilon) + (1)(1) + (0)(0) = 1.\n$$\n因此，瑞利商为：\n$$\n\\mu(x^{(0)}) = \\frac{1}{1} = 1.\n$$\n有了瑞利商，我们现在可以求出残差向量 $r(x^{(0)})$：\n$$\nr(x^{(0)}) = A x^{(0)} - \\mu(x^{(0)}) x^{(0)} = \\begin{pmatrix} \\varepsilon \\\\ 1 \\\\ 0 \\end{pmatrix} - (1) \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\varepsilon - 0 \\\\ 1 - 1 \\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} \\varepsilon \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n第一个要计算的量是这个残差向量的欧几里得范数（或 $L_2$-范数）：\n$$\n\\|r(x^{(0)})\\|_{2} = \\left\\| \\begin{pmatrix} \\varepsilon \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\|_{2} = \\sqrt{\\varepsilon^2 + 0^2 + 0^2} = \\sqrt{\\varepsilon^2} = |\\varepsilon|.\n$$\n由于问题陈述 $0  \\varepsilon \\ll 1$，$\\varepsilon$ 是一个正值，所以 $|\\varepsilon| = \\varepsilon$。因此，第一个结果是 $\\|r(x^{(0)})\\|_{2} = \\varepsilon$。\n\n其次，我们计算向量 $x^{(0)} = \\begin{pmatrix}0 \\\\ 1 \\\\ 0\\end{pmatrix}$ 和特征向量 $v_{1} = \\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix}$ 之间的夹角 $\\theta$。\n两个非零向量 $u$ 和 $v$ 之间的夹角 $\\theta$ 由以下公式给出：\n$$\n\\theta = \\arccos\\left(\\frac{u^{\\top} v}{\\|u\\|_{2} \\|v\\|_{2}}\\right).\n$$\n这里，$u = x^{(0)}$ 且 $v = v_{1}$。我们计算该公式的各个组成部分。\n向量的范数是：\n$$\n\\|x^{(0)}\\|_{2} = \\left\\| \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \\right\\|_{2} = \\sqrt{0^2 + 1^2 + 0^2} = 1.\n$$\n$$\n\\|v_{1}\\|_{2} = \\left\\| \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\|_{2} = \\sqrt{1^2 + 0^2 + 0^2} = 1.\n$$\n向量的点积是：\n$$\n(x^{(0)})^{\\top} v_{1} = \\begin{pmatrix} 0  1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = (0)(1) + (1)(0) + (0)(0) = 0.\n$$\n将这些值代入夹角公式，得到：\n$$\n\\cos(\\theta) = \\frac{0}{(1)(1)} = 0.\n$$\n在区间 $[0, \\pi]$ 内使 $\\cos(\\theta) = 0$ 的角度 $\\theta$ 是 $\\frac{\\pi}{2}$ 弧度。这表明向量 $x^{(0)}$ 和 $v_1$ 是正交的。\n\n所要求的两个量是残差范数 $\\varepsilon$ 和夹角 $\\frac{\\pi}{2}$。",
                "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\varepsilon  \\frac{\\pi}{2}\n\\end{pmatrix}\n}\n$$",
                "id": "3592908"
            }
        ]
    }