{
        "hands_on_practices": [
            {
                "introduction": "Johnson-Lindenstrauss (JL) 引理的许多理论推导都依赖于从正交群上的 Haar 测度中抽取的理想随机正交矩阵。本次实践探讨了随机矩阵理论中的一个基本结论 [@problem_id:3570509]：一个标准高斯矩阵的 QR 分解可以作为生成这种理想随机矩阵的有效方法。通过推导证明两种构造方法在分布上是等价的，你将加深对随机投影理论基础的理解。",
                "problem": "考虑一个 Johnson–Lindenstrauss 嵌入，其定义为映射 $F_{W} : \\mathbb{R}^{d} \\to \\mathbb{R}^{k}$，由 $F_{W}(x) = \\sqrt{\\frac{d}{k}} S W x$ 给出，其中 $S \\in \\mathbb{R}^{k \\times d}$ 是选择前 $k$ 个坐标的坐标投影算子，而 $W \\in \\mathrm{O}(d)$ 是一个正交矩阵。考虑了 $W$ 的两种构造方法：\n- 一个从 $\\mathrm{O}(d)$ 上的哈尔测度中抽取的矩阵 $U$，其中哈尔测度是紧拓扑群 $\\mathrm{O}(d)$ 上唯一的左不变概率测度。\n- 一个通过对随机高斯矩阵 $G \\in \\mathbb{R}^{d \\times d}$ 进行 $\\mathrm{QR}$ 分解得到的矩阵 $Q$。该高斯矩阵的元素 $G_{ij} \\sim \\mathcal{N}(0,1)$ 是独立的。即 $G = QR$，其中按照惯例，$R$ 是上三角矩阵且对角线元素严格为正。\n\n设 $v \\in \\mathbb{R}^{d}$ 是一个固定的非零向量，为向量 $v$ 定义映射 $F_{W}$ 的平方失真比 $D_{W}$ 为 $D_{W} = \\frac{\\|F_{W}(v)\\|_{2}^{2}}{\\|v\\|_{2}^{2}}$。令 $\\mathcal{L}(Q)$ 表示 $Q$ 的分布，令 $\\mu_{\\mathrm{Haar}}$ 表示 $\\mathrm{O}(d)$ 上的哈尔概率测度。定义与哈尔测度的全变差为 $\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mathbb{P}(Q \\in B) - \\mu_{\\mathrm{Haar}}(B) \\right|$，其中上确界取自 $\\mathrm{O}(d)$ 的所有波莱尔子集 $B$。定义两种构造方法之间的期望失真偏差为 $\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}]$。\n\n从多元正态分布的旋转不变性和哈尔测度的定义性质出发，推导 $\\Delta$ 和 $\\beta$ 的闭式表达式。以包含 $\\Delta$ 和 $\\beta$（按此顺序）的行矩阵形式提供您的最终答案。不需要四舍五入。此问题不涉及物理单位。",
                "solution": "用户希望我验证问题陈述，如果有效，则提供解决方案。\n\n### 步骤1：提取已知条件\n- **映射：** $F_{W} : \\mathbb{R}^{d} \\to \\mathbb{R}^{k}$，定义为 $F_{W}(x) = \\sqrt{\\frac{d}{k}} S W x$。\n- **$S$：** 一个 $k \\times d$ 矩阵，表示选择前 $k$ 个坐标的坐标投影算子。\n- **$W$：** 一个正交矩阵，$W \\in \\mathrm{O}(d)$。\n- **构造U：** 从正交群 $\\mathrm{O}(d)$ 上的哈尔测度 $\\mu_{\\mathrm{Haar}}$ 中抽取的矩阵 $U$。\n- **构造Q：** 通过对一个随机高斯矩阵 $G \\in \\mathbb{R}^{d \\times d}$ 进行 $\\mathrm{QR}$ 分解得到的矩阵 $Q$。该高斯矩阵具有独立同分布的元素 $G_{ij} \\sim \\mathcal{N}(0,1)$。分解为 $G = QR$，其中 $R$ 是对角线元素严格为正的上三角矩阵。\n- **向量 $v$：** $\\mathbb{R}^{d}$ 中的一个固定的非零向量。\n- **平方失真比：** $D_{W} = \\frac{\\|F_{W}(v)\\|_{2}^{2}}{\\|v\\|_{2}^{2}}$。\n- **全变差：** $\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mathbb{P}(Q \\in B) - \\mu_{\\mathrm{Haar}}(B) \\right|$，其中上确界取自 $\\mathrm{O}(d)$ 的所有波莱尔子集 $B$。\n- **期望失真偏差：** $\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}]$。\n- **任务：** 从多元正态分布的旋转不变性和哈尔测度的性质出发，推导 $\\Delta$ 和 $\\beta$ 的闭式表达式。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题在随机矩阵理论和数值线性代数这一数学领域内是良定义的。\n- **科学基础：** 所提出的概念——$\\mathrm{O}(d)$ 上的哈尔测度、高斯矩阵的QR分解、全变差距离以及Johnson-Lindenstrauss嵌入——都是标准的、严格定义的数学对象和理论。关于 $Q$ 的分布与哈尔测度相关的假设是随机矩阵理论中的一个基石性成果。\n- **良构性：** 该问题要求计算两个良定义的量，即 $\\Delta$ 和 $\\beta$。从特定原理（旋转不变性）出发的指令为推导提供了清晰的路径。\n- **客观性：** 问题陈述由形式化的数学定义构成，没有歧义或主观性语言。\n- **完整性与一致性：** 所有必要的定义都已提供。关于 $R$ 具有严格为正的对角线元素的规定确保了QR分解的唯一性，这是论证中的一个关键细节。\n\n该问题没有缺陷。它提出的情景虽然最终答案很简单，但需要基于基本原理进行严格的推导，从而检验对高斯随机矩阵与哈尔测度之间关系的理解。这个设置并非无关紧要或故作高深，而是在该领域构建基于证明的问题的一种标准方式。\n\n### 步骤3：结论与行动\n该问题是**有效的**。将提供完整的推导过程。\n\n### 推导\n\n解决方案需要推导 $\\Delta$ 和 $\\beta$ 的值。这取决于确定矩阵 $Q$ 的概率分布。\n\n**第1部分：$\\Delta$ 的推导**\n\n量 $\\Delta$ 是 $Q$ 的分布与 $\\mathrm{O}(d)$ 上的哈尔测度之间的全变差距离。我们将证明这两个分布是相同的，这意味着 $\\Delta=0$。\n\n设 $G$ 是一个 $d \\times d$ 矩阵，其元素 $G_{ij}$ 是独立同分布的标准正态随机变量，$G_{ij} \\sim \\mathcal{N}(0,1)$。$G$ 元素们的联合概率密度函数由下式给出\n$$p(G) = \\prod_{i,j=1}^{d} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{G_{ij}^2}{2}\\right) = (2\\pi)^{-d^2/2} \\exp\\left(-\\frac{1}{2} \\sum_{i,j=1}^{d} G_{ij}^2\\right)$$\n这可以用弗罗贝尼乌斯范数或迹来表示：\n$$p(G) = (2\\pi)^{-d^2/2} \\exp\\left(-\\frac{1}{2} \\|G\\|_{\\mathrm{F}}^2\\right) = (2\\pi)^{-d^2/2} \\exp\\left(-\\frac{1}{2} \\mathrm{Tr}(G^T G)\\right)$$\n该分布的一个关键性质是其旋转不变性。设 $H \\in \\mathrm{O}(d)$ 是任意一个固定的正交矩阵。考虑随机矩阵 $G' = HG$。指数中的迹项变换如下：\n$$\\mathrm{Tr}((HG)^T(HG)) = \\mathrm{Tr}(G^T H^T H G) = \\mathrm{Tr}(G^T I G) = \\mathrm{Tr}(G^T G)$$\n这里我们使用了正交矩阵的性质 $H^T H = I$。由于变换 $G \\to HG$ 是一个线性变换，其变量替换的雅可比行列式为常数，$| \\det(H) |^d = (\\pm 1)^d = 1$。因此，$G'$ 的概率密度与 $G$ 的相同。这意味着 $G$ 的分布在正交变换下是左不变的：对于任何固定的 $H \\in \\mathrm{O}(d)$，随机矩阵 $HG$ 与 $G$ 具有相同的分布。我们将其记为 $HG \\sim G$。\n\n现在，设 $G = QR$ 是 $G$ 的唯一QR分解，其中 $Q \\in \\mathrm{O}(d)$，$R$ 是一个对角线元素严格为正的上三角矩阵。对于几乎所有的矩阵 $G$（具体来说，对于任何可逆的 $G$），这个分解是唯一的。\n由于 $HG \\sim G$，那么 $HG$ 的唯一QR因子必须与 $G$ 的QR因子具有相同的联合分布。设 $HG$ 的QR分解为 $HG = Q'R'$。那么我们有 $(Q', R') \\sim (Q, R)$。\n\n我们也可以通过代数方法找到 $(Q', R')$ 和 $(Q, R)$ 之间的关系。我们有 $HG = (HQ)R$。由于 $H$ 和 $Q$ 都在 $\\mathrm{O}(d)$ 中，它们的乘积 $HQ$ 也在 $\\mathrm{O}(d)$ 中。矩阵 $R$ 是对角线元素严格为正的上三角矩阵。因此，$(HQ)R$ 是矩阵 $HG$ 的一个有效的QR分解。根据此分解的唯一性，我们必然有：\n$$Q' = HQ \\quad \\text{和} \\quad R' = R$$\n将分布等式 $(Q', R') \\sim (Q, R)$ 与代数恒等式 $Q' = HQ$ 结合，我们推断出 $Q$ 的分布必须满足：\n$$Q \\sim HQ \\quad \\text{对于所有固定的 } H \\in \\mathrm{O}(d)$$\n这个性质是随机矩阵 $Q$ 概率分布的左不变性的定义。在紧拓扑群（如 $\\mathrm{O}(d)$）上的哈尔测度 $\\mu_{\\mathrm{Haar}}$ 是唯一的左不变概率测度。因此，$Q$ 的分布（我们可以表示为 $\\mathcal{L}(Q)$）必须是哈尔测度：\n$$\\mathcal{L}(Q) = \\mu_{\\mathrm{Haar}}$$\n现在我们可以计算 $\\Delta$。根据定义，\n$$\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mathbb{P}(Q \\in B) - \\mu_{\\mathrm{Haar}}(B) \\right|$$\n由于控制 $Q$ 的概率测度恰好是 $\\mu_{\\mathrm{Haar}}$，对于任何波莱尔集 $B$，我们有 $\\mathbb{P}(Q \\in B) = \\mu_{\\mathrm{Haar}}(B)$。\n$$\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mu_{\\mathrm{Haar}}(B) - \\mu_{\\mathrm{Haar}}(B) \\right| = \\sup_{B \\subset \\mathrm{O}(d)} |0| = 0$$\n\n**第2部分：$\\beta$ 的推导**\n\n期望失真偏差定义为 $\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}]$。\n根据定义，随机矩阵 $U$ 是从哈尔测度 $\\mu_{\\mathrm{Haar}}$ 中抽取的。在第1部分中，我们证明了随机矩阵 $Q$ 也服从哈尔测度，即 $\\mathcal{L}(Q) = \\mu_{\\mathrm{Haar}}$。\n这意味着 $Q$ 和 $U$ 是同分布的随机矩阵。\n\n平方失真比 $D_W$ 是矩阵 $W$ 的一个函数：\n$$D_{W} = \\frac{\\|F_{W}(v)\\|_{2}^{2}}{\\|v\\|_{2}^{2}}$$\n如果两个随机变量 $X$ 和 $Y$ 是同分布的，那么对于任何良定义的函数 $g$，$g(X)$ 和 $g(Y)$ 的期望值相等：$\\mathbb{E}[g(X)] = \\mathbb{E}[g(Y)]$。在我们的例子中，随机变量是矩阵 $Q$ 和 $U$，函数是 $D_W$。由于 $Q \\sim U$，因此可得：\n$$\\mathbb{E}[D_{Q}] = \\mathbb{E}[D_{U}]$$\n因此，期望失真偏差 $\\beta$ 为：\n$$\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}] = 0$$\n\n为完整起见，我们也可以计算这些期望的值。设 $W$ 是一个哈尔分布的正交矩阵。\n$$\\mathbb{E}[D_W] = \\mathbb{E}\\left[\\frac{\\|\\sqrt{\\frac{d}{k}} S W v\\|_{2}^{2}}{\\|v\\|_{2}^{2}}\\right] = \\frac{d}{k \\|v\\|_{2}^{2}} \\mathbb{E}[\\|S W v\\|_{2}^{2}]$$\n设向量 $y = Wv$。由于 $W$ 是哈尔分布的正交矩阵，且 $v$ 是一个固定向量，向量 $y$ 在 $\\mathbb{R}^d$ 中半径为 $\\|v\\|_2$ 的球面上均匀分布。这是旋转对称性的一个结果。设 $y = (y_1, y_2, \\dots, y_d)^T$。\n我们有 $\\|y\\|_2^2 = \\|Wv\\|_2^2 = v^T W^T W v = v^T v = \\|v\\|_2^2$。\n矩阵 $S$ 选择前 $k$ 个坐标，所以 $\\|Sy\\|_2^2 = \\sum_{i=1}^k y_i^2$。\n根据球面上均匀分布的对称性，每个分量平方的期望值是相同的：对于所有 $i=1, \\dots, d$，都有 $\\mathbb{E}[y_i^2] = c$。\n我们有 $\\sum_{i=1}^d \\mathbb{E}[y_i^2] = \\mathbb{E}\\left[\\sum_{i=1}^d y_i^2\\right] = \\mathbb{E}[\\|y\\|_2^2] = \\mathbb{E}[\\|v\\|_2^2] = \\|v\\|_2^2$。\n所以，$d \\cdot c = \\|v\\|_2^2$，这得出 $c = \\frac{\\|v\\|_2^2}{d}$。\n那么，我们需要的期望是：\n$$\\mathbb{E}[\\|S W v\\|_{2}^{2}] = \\mathbb{E}[\\|Sy\\|_2^2] = \\mathbb{E}\\left[\\sum_{i=1}^k y_i^2\\right] = \\sum_{i=1}^k \\mathbb{E}[y_i^2] = k \\cdot c = k \\frac{\\|v\\|_2^2}{d}$$\n将此代回 $\\mathbb{E}[D_W]$ 的表达式中：\n$$\\mathbb{E}[D_W] = \\frac{d}{k \\|v\\|_{2}^{2}} \\left( k \\frac{\\|v\\|_2^2}{d} \\right) = 1$$\n因此，$\\mathbb{E}[D_Q] = \\mathbb{E}[D_U] = 1$，这证实了它们的差值 $\\beta$ 为 $0$。\n\n**结论：**\n全变差 $\\Delta$ 为 $0$，因为从标准高斯矩阵的QR分解中得到的正交因子 $Q$ 的分布恰好是 $\\mathrm{O}(d)$ 上的哈尔测度。期望失真偏差 $\\beta$ 为 $0$，因为随机矩阵 $Q$ 和 $U$ 是同分布的，导致对这些矩阵的任何函数（包括失真比）的期望都相同。\n\n最终答案将是包含 $\\Delta$ 和 $\\beta$ 的行矩阵。",
                "answer": "$$\\boxed{\\begin{pmatrix} 0  0 \\end{pmatrix}}$$",
                "id": "3570509"
            },
            {
                "introduction": "尽管密集的随机投影具有很强的理论保证，但其计算成本可能很高，尤其是在处理超高维数据时。本次实践将探究一种计算效率极高的替代方案：稀疏投影 [@problem_id:3570496]。通过构建一个特定的“对抗性”点集，你将揭示稀疏映射的潜在失效模式，并推导出保证其稳健性的最小稀疏度，从而深刻理解算法设计中效率与准确性之间的关键权衡。",
                "problem": "设 $d \\in \\mathbb{N}$，$m \\in \\mathbb{N}$，且 $2 \\leq n \\leq d$。考虑从 $\\mathbb{R}^{d}$到 $\\mathbb{R}^{m}$ 的两类线性映射：\n\n- 一种稀疏 CountSketch 风格的映射 $R \\in \\mathbb{R}^{m \\times d}$，其中每一列恰好有 $s \\in \\mathbb{N}$ 个非零项。对于每一列 $j \\in \\{1,\\dots,d\\}$，$s$ 个非零行的索引是从 $\\{1,\\dots,m\\}$ 中独立地、无放回地均匀选择的，并且相应的值是独立的 Rademacher 符号除以 $\\sqrt{s}$，即每个非零项以各 $1/2$ 的概率等于 $\\pm 1/\\sqrt{s}$。\n\n- 一种稠密高斯映射 $G \\in \\mathbb{R}^{m \\times d}$，其元素 $G_{ij} \\sim \\mathcal{N}(0,1/m)$ 是独立同分布的。\n\n定义对抗点集 $V \\subset \\mathbb{R}^{d}$ 为\n$$\nV \\;=\\; \\{\\, v_{i}^{+}, v_{i}^{-} \\,:\\, i \\in \\{2,\\dots,n\\}\\,\\}, \\quad v_{i}^{\\pm} \\;=\\; e_{1} \\pm e_{i},\n$$\n其中 $e_{k}$ 表示 $\\mathbb{R}^{d}$ 中的第 $k$ 个标准基向量。\n\n对于一个失真参数 $\\varepsilon \\in (0,1/2)$，如果对于所有 $v \\in V$ 都满足以下条件，我们就说线性映射 $A:\\mathbb{R}^{d}\\to\\mathbb{R}^{m}$ 在失真 $\\varepsilon$ 内保持 $V$ 中向量的平方范数：\n$$\n\\left|\\, \\|A v\\|_{2}^{2} - \\|v\\|_{2}^{2} \\,\\right| \\;\\leq\\; \\varepsilon \\,\\|v\\|_{2}^{2}.\n$$\n\n从概率论和线性代数的第一性原理出发，并且只使用经过充分检验的集中不等式工具（例如，用于超几何/二项变量的 Chernoff 界，用于 Rademacher 和的 Berry–Esseen 或 Hoeffding 不等式，以及 Paley–Zygmund 不等式），完成以下任务：\n\n1. 通过分析内积 $\\langle R e_{1}, R e_{i} \\rangle$ 及其对 $\\|R v_{i}^{\\pm}\\|_{2}^{2}$ 的影响，并与相应的高斯情况作对比，构建并论证一个显式机制，说明在相同的嵌入维度 $m$ 下，$R$为何可能比 $G$ 在 $V$ 上产生更大的失真。\n\n2. 通过量化 $R$ 的第 1 列和第 $i$ 列中 $s$ 个非零项的支撑集之间的重叠 $K$，以及在 $K$ 条件下的带符号重叠的波动，推导最小列稀疏度 $s^{\\star} = s^{\\star}(n,m,\\varepsilon)$ 的渐近表达式，使得对于稀疏映射 $R$，其在失真 $\\varepsilon$ 内保持 $V$ 中所有向量的平方范数的概率至少为二分之一。你的推导应追踪 $n$、$m$ 和 $\\varepsilon$ 中的指数率项，并且只要最终的率被正确捕捉，你可以忽略对数内的绝对常数因子。\n\n3. 最后给出一个 $s^{\\star}(n,m,\\varepsilon)$ 的闭式解析表达式，该表达式清晰地分离了其对 $n$、$m$ 和 $\\varepsilon$ 的依赖关系。你的答案必须是关于 $n$、$m$ 和 $\\varepsilon$ 的单个解析表达式。无需进行数值计算。\n\n答案格式：只提供 $s^{\\star}(n,m,\\varepsilon)$ 的表达式，并充分化简。无需四舍五入。不要包含单位。",
                "solution": "该问题要求分析一种稀疏的 CountSketch 风格随机投影 $R \\in \\mathbb{R}^{m \\times d}$，并将其保持特定向量集 $V = \\{e_1 \\pm e_i : i=2,\\dots,n\\}$ 范数的能力与稠密高斯投影 $G \\in \\mathbb{R}^{m \\times d}$ 进行比较。我们需要推导 $R$ 满足给定失真标准所需的最小列稀疏度 $s^{\\star}$。\n\n首先，我们确定集合 $V$ 中向量的范数。对于任意 $v_i^{\\pm} = e_1 \\pm e_i$，其中 $e_k$ 是第 $k$ 个标准基向量，其欧几里得范数的平方为：\n$$\n\\|v_i^{\\pm}\\|_2^2 = \\|e_1 \\pm e_i\\|_2^2 = \\langle e_1 \\pm e_i, e_1 \\pm e_i \\rangle = \\|e_1\\|_2^2 \\pm 2\\langle e_1, e_i \\rangle + \\|e_i\\|_2^2\n$$\n由于标准基向量是标准正交的，对于所有 $k$ 有 $\\|e_k\\|_2^2 = 1$，且对于 $j \\neq k$ 有 $\\langle e_j, e_k \\rangle = 0$。因此，\n$$\n\\|v_i^{\\pm}\\|_2^2 = 1 \\pm 2(0) + 1 = 2\n$$\n所以，对于 $V$ 中的任意向量 $v$，其平方范数为 $\\|v\\|_2^2=2$。\n\n对于线性映射 $A: \\mathbb{R}^{d} \\to \\mathbb{R}^{m}$ 的失真条件给出如下：\n$$\n\\left|\\, \\|A v\\|_{2}^{2} - \\|v\\|_{2}^{2} \\,\\right| \\leq \\varepsilon \\,\\|v\\|_{2}^{2}\n$$\n代入 $\\|v\\|_2^2 = 2$，这变为：\n$$\n\\left|\\, \\|A v\\|_{2}^{2} - 2 \\,\\right| \\leq 2\\varepsilon\n$$\n我们来分析当 $v = v_i^{\\pm} = e_1 \\pm e_i$ 时 $\\|Av\\|_2^2$ 这一项。设 $c_j = Ae_j$ 表示矩阵 $A$ 的第 $j$ 列。那么 $Av = A(e_1 \\pm e_i) = Ae_1 \\pm Ae_i = c_1 \\pm c_i$。\n$$\n\\|Av\\|_2^2 = \\|c_1 \\pm c_i\\|_2^2 = \\|c_1\\|_2^2 + \\|c_i\\|_2^2 \\pm 2\\langle c_1, c_i \\rangle\n$$\n因此，失真条件为：\n$$\n\\left|\\, (\\|c_1\\|_2^2 + \\|c_i\\|_2^2 \\pm 2\\langle c_1, c_i \\rangle) - 2 \\,\\right| \\leq 2\\varepsilon\n$$\n\n**1. 稀疏映射产生更大失真的机制**\n\n我们现在比较稀疏映射 $R$ 和稠密映射 $G$ 的失真项的行为。\n\n对于稀疏映射 $R \\in \\mathbb{R}^{m \\times d}$，每一列 $c_j = Re_j$ 恰好有 $s$ 个非零项，每个非零项的值为 $\\pm 1/\\sqrt{s}$。因此，任何一列的平方范数是固定的：\n$$\n\\|c_j\\|_2^2 = \\sum_{k=1}^{s} \\left(\\pm \\frac{1}{\\sqrt{s}}\\right)^2 = s \\cdot \\frac{1}{s} = 1\n$$\n对于映射 $R$，失真条件显著简化为：\n$$\n\\left|\\, (1 + 1 \\pm 2\\langle Re_1, Re_i \\rangle) - 2 \\,\\right| \\leq 2\\varepsilon\n$$\n$$\n\\left|\\, \\pm 2\\langle Re_1, Re_i \\rangle \\,\\right| \\leq 2\\varepsilon\n$$\n$$\n|\\langle Re_1, Re_i \\rangle| \\leq \\varepsilon\n$$\n对于稀疏映射 $R$，保持集合 $V$ 的范数完全取决于控制第 1 列与其它列 $i \\in \\{2,\\dots,n\\}$ 之间内积的大小。\n\n对于稠密高斯映射 $G \\in \\mathbb{R}^{m \\times d}$，其元素为 $G_{kj} \\sim \\mathcal{N}(0, 1/m)$。设 $c_j = Ge_j$。平方范数 $\\|c_j\\|_2^2 = \\sum_{k=1}^m G_{kj}^2$ 是一个随机变量。其期望为 $E[\\|c_j\\|_2^2] = \\sum_{k=1}^m E[G_{kj}^2] = \\sum_{k=1}^m (1/m) = 1$。变量 $m\\|c_j\\|_2^2$ 服从卡方分布 $\\chi_m^2$，该分布紧密集中在其均值 $m$ 附近。类似地，内积 $\\langle c_1, c_i \\rangle = \\sum_{k=1}^m G_{k1}G_{ki}$ 是独立同分布随机变量的和，均值为 0，方差为 $1/m^2$，因此 $E[\\langle c_1, c_i \\rangle]=0$ 且 $\\text{Var}(\\langle c_1, c_i \\rangle) = m \\cdot (1/m^2) = 1/m$。对于 $G$，失真来自三个波动的项：$(\\|c_1\\|_2^2-1)$、$(\\|c_i\\|_2^2-1)$ 和 $\\langle c_1, c_i \\rangle$。这些都是表现良好、近似高斯的变量，其方差为 $1/m$ 的量级。\n\n$R$ 可能产生更大失真的显式机制在于内积 $\\langle Re_1, Re_i \\rangle$ 的结构。设 $S_j \\subset \\{1, \\dots, m\\}$ 是 $R$ 的第 $j$ 列具有非零项的行索引集合，因此 $|S_j|=s$。内积仅在这些支撑集的交集上非零：\n$$\n\\langle Re_1, Re_i \\rangle = \\sum_{k \\in S_1 \\cap S_i} R_{k1} R_{ki}\n$$\n设 $K = |S_1 \\cap S_i|$ 是这个随机重叠的大小。对于每个 $k \\in S_1 \\cap S_i$，项 $R_{k1}R_{ki} = (\\pm 1/\\sqrt{s})(\\pm 1/\\sqrt{s}) = (1/s) \\cdot \\rho_k$，其中 $\\rho_k$ 是两个独立的 Rademacher 随机变量的乘积，其本身也是一个 Rademacher 变量。所以，\n$$\n\\langle Re_1, Re_i \\rangle = \\frac{1}{s}\\sum_{k=1}^K \\rho_k = \\frac{Z_K}{s}\n$$\n其中 $Z_K$ 是 $K$ 个独立同分布的 Rademacher 变量之和。关键点在于 $K$ 是一个随机变量。它服从超几何分布，因为它代表从 $m$ 个元素的总体中无放回地抽取 $s$ 个项目（第 1 列的行），然后再抽取 $s$ 个项目（第 $i$ 列的行）时共同抽中的项目数。因此，$\\langle Re_1, Re_i \\rangle$ 的分布是以 $K$ 为条件的混合分布。$K$ 的偶然一次大波动可能导致求和项数远超平均值，从而产生高斯情况下不存在的内积的重尾分布。这使得在相同的嵌入维度 $m$ 下，$R$ 产生较大内積值（从而产生较大失真）的可能性比 $G$ 更高。\n\n**2. 最小稀疏度 $s^{\\star}$ 的推导**\n\n我们需要找到最小稀疏度 $s=s^{\\star}$，使得 $R$ 以至少 $1/2$ 的概率保持 $V$ 中所有向量的范数。这要求对于所有 $i \\in \\{2, \\dots, n\\}$，都有 $|\\langle Re_1, Re_i \\rangle| \\leq \\varepsilon$。设 $F_i$ 为失败事件 $|\\langle Re_1, Re_i \\rangle| > \\varepsilon$。根据并集界，总失败概率为 $P(\\cup_{i=2}^n F_i) \\leq \\sum_{i=2}^n P(F_i)$。由于对称性，所有的 $P(F_i)$ 都相等。所以我们需要 $(n-1) P(F_2) \\le 1/2$，即 $P(F_2) \\le \\frac{1}{2(n-1)}$。\n\n失败条件是 $|\\frac{Z_K}{s}| > \\varepsilon$，即 $|Z_K| > s\\varepsilon$。\n我们来分析导致这种失败的原因。给定重叠 $K$，$Z_K$ 是 $K$ 个 Rademacher 变量的和，因此 $E[Z_K|K]=0$ 且 $\\text{Var}(Z_K|K)=K$。$Z_K$ 的“典型”量级是 $\\sqrt{K}$。当典型量级与阈值相当时，即 $\\sqrt{K} \\approx s\\varepsilon$ 时，失败条件 $|Z_K| > s\\varepsilon$ 变得很可能发生。这定义了一个临界重叠大小：\n$$\nK_{crit} = (s\\varepsilon)^2\n$$\n如果随机重叠 $K$恰好大于或等于 $K_{crit}$，失败的条件概率 $P(|Z_K| > s\\varepsilon | K \\ge K_{crit})$ 会变得显著（一个不依赖于问题参数的常数）。因此，总失败概率主要由重叠达到临界大小时的这个罕见事件的概率所主导：\n$$\nP(F_2) \\approx P(K \\ge K_{crit}) = P(K \\ge s^2\\varepsilon^2)\n$$\n为确保嵌入以高概率成功，我们必须使这个事件足够罕见。我们需要对 $K$ 的尾概率进行界定。$K$ 的分布是超几何分布 Hypergeometric($N=m, K_{pop}=s, n_{draw}=s$)。对于 $m \\gg s$ 的情况，这可以很好地用二项分布 $B(s, p=s/m)$ 来近似，因为为第 $i$ 列选择特定行的概率是 $s/m$。\n\n我们使用 Chernoff 界来界定二项分布的上尾。对于一个随机变量 $X \\sim B(N, p)$，观测到至少 $k$ 次成功的概率有上界 $P(X \\ge k) \\le \\exp(-N \\cdot D_{KL}(k/N || p))$，其中 $D_{KL}(q||p) = q\\ln(q/p) + (1-q)\\ln\\left(\\frac{1-q}{1-p}\\right)$ 是 Kullback-Leibler 散度。\n这里，$N=s$，$k=K_{crit}=s^2\\varepsilon^2$，且 $p=s/m$。成功的分数是 $q=k/N = s^2\\varepsilon^2/s = s\\varepsilon^2$。我们必须满足条件 $q \\le 1$，即 $s\\varepsilon^2 \\le 1$。\n我们要求 $P(K \\ge s^2\\varepsilon^2) \\le \\frac{1}{2(n-1)}$。这导致不等式：\n$$\n\\exp(-s \\cdot D_{KL}(s\\varepsilon^2 || s/m)) \\le \\frac{1}{2(n-1)}\n$$\n对两边取自然对数：\n$$\n-s \\cdot D_{KL}(s\\varepsilon^2 || s/m) \\le -\\ln(2(n-1))\n$$\n$$\ns \\cdot D_{KL}(s\\varepsilon^2 || s/m) \\ge \\ln(2(n-1))\n$$\n在我们感兴趣的范围内，当 $s$ 很小时稀疏性是有效的，因此 $p=s/m$ 很小。失真参数 $\\varepsilon$ 也很小。我们感兴趣的情况是，所需的重叠数 $q=s\\varepsilon^2$ 远大于期望的重叠数 $p=s/m$。这对应于条件 $m\\varepsilon^2 \\gg 1$，这在 Johnson-Lindenstrauss 结果中是典型情况。\n在这种情况下（$q \\gg p$，且两者都很小），KL 散度可以由其主导项近似：\n$$\nD_{KL}(q||p) \\approx q\\ln(q/p)\n$$\n将此近似代入我们的不等式：\n$$\ns \\cdot \\left( (s\\varepsilon^2) \\ln\\left(\\frac{s\\varepsilon^2}{s/m}\\right) \\right) \\ge \\ln(2(n-1))\n$$\n$$\ns^2 \\varepsilon^2 \\ln(m\\varepsilon^2) \\ge \\ln(2(n-1))\n$$\n根据题目要求，我们追踪指数率项，并且对于大的 $n$ 可以忽略对数内的常数因子。因此，$\\ln(2(n-1)) \\approx \\ln(n)$。\n$$\ns^2 \\varepsilon^2 \\ln(m\\varepsilon^2) \\gtrsim \\ln(n)\n$$\n求解最小稀疏度 $s = s^{\\star}$：\n$$\ns^2 \\gtrsim \\frac{\\ln(n)}{\\varepsilon^2 \\ln(m\\varepsilon^2)}\n$$\n$$\ns^{\\star} \\approx \\frac{\\sqrt{\\ln(n)}}{\\varepsilon\\sqrt{\\ln(m\\varepsilon^2)}}\n$$\n\n**3. $s^{\\star}(n, m, \\varepsilon)$ 的闭式解析表达式**\n\n基于以上的渐近推导，能够清晰分离其对 $n$、$m$ 和 $\\varepsilon$ 依赖关系的最小列稀疏度 $s^{\\star}$ 是：\n$$\ns^{\\star}(n, m, \\varepsilon) = \\frac{1}{\\varepsilon} \\sqrt{\\frac{\\ln(n)}{\\ln(m\\varepsilon^2)}}\n$$\n这个表达式捕捉了稀疏度随点数 $n$、嵌入维度 $m$ 和失真 $\\varepsilon$ 变化的所需尺度关系。",
                "answer": "$$\\boxed{\\frac{1}{\\varepsilon} \\sqrt{\\frac{\\ln(n)}{\\ln(m\\varepsilon^{2})}}}$$",
                "id": "3570496"
            },
            {
                "introduction": "在实际应用中，有时将降维过程分阶段进行会更有利。本次实践研究了顺序组合两个独立的 Johnson-Lindenstrauss (JL) 投影所带来的后果 [@problem_id:3570516]。你将首先推导出复合投影的总畸变是如何由各阶段的畸变参数决定的，然后解决一个实际的设计优化问题：如何在满足总体误差预算的同时，通过优化各阶段的参数来最小化总计算成本。",
                "problem": "令 $\\mathcal{X} \\subset \\mathbb{R}^{d}$ 为一个包含 $m$ 个点的有限集，并令 $v = x - y$ 表示对于 $x,y \\in \\mathcal{X}$ 的任意差分向量。考虑两个独立的随机线性映射 $R_{1} \\in \\mathbb{R}^{k_{1} \\times d}$ 和 $R_{2} \\in \\mathbb{R}^{k_{2} \\times k_{1}}$，其元素分别是经过 $1/\\sqrt{k_{1}}$ 和 $1/\\sqrt{k_{2}}$ 缩放的独立同分布的标准正态随机变量。根据 $\\chi^{2}$ 随机变量的集中性和标准的亚高斯尾部界，对于任意固定的 $v \\in \\mathbb{R}^{d}$ 和任意 $\\varepsilon \\in (0,1)$，存在一个绝对常数 $C>0$ 使得\n$$\n\\mathbb{P}\\!\\left(\\left|\\|R v\\|^{2} - \\|v\\|^{2}\\right| \\geq \\varepsilon \\|v\\|^{2}\\right) \\leq 2 \\exp\\!\\big(-C k \\varepsilon^{2}\\big),\n$$\n其中 $R$ 是一个元素如上所述的随机矩阵，$k$ 是其行维度。随后，通过对所有 $\\binom{m}{2}$ 个差分向量应用联合界，可得到 Johnson–Lindenstrauss (JL) 引理，从而得出通常的维度规定 $k \\geq C \\varepsilon^{-2} \\ln(m/\\delta)$，以至少 $1 - \\delta$ 的概率将所有成对平方距离保持在 $(1 \\pm \\varepsilon)$ 的因子范围内。\n\n现在，顺序应用 $R_{1}$ 和 $R_{2}$，通过 $P = R_{2} R_{1}$ 将 $\\mathcal{X}$ 嵌入到 $\\mathbb{R}^{k_{2}}$ 中，其中 $R_{1}$ 的参数为 $(\\varepsilon_{1}, \\delta_{1}, k_{1})$，$R_{2}$ 的参数为 $(\\varepsilon_{2}, \\delta_{2}, k_{2})$，如上所述。从上述基本集中界出发（而不是使用任何专门的复合公式），推导该复合映射的总平方距离失真参数 $\\varepsilon_{\\mathrm{tot}}$ 关于 $\\varepsilon_{1}$ 和 $\\varepsilon_{2}$ 的精确表达式，以及用 $\\delta_{1}$ 和 $\\delta_{2}$ 表示的失效概率界。\n\n接下来，你需要设计一个两阶段方案，该方案受总平方距离失真预算 $\\varepsilon \\in (0,1)$ 和总失效概率预算 $\\delta \\in (0,1)$ 的约束。假设存在以下科学上真实的设计约束：\n- 这两个阶段是独立的，它们的失效概率被均等分配，即 $\\delta_{1} = \\delta_{2} = \\delta/2$。\n- 为减少不平衡，各阶段的失真选择为相等，即 $\\varepsilon_{1} = \\varepsilon_{2}$。\n- 每个阶段的维度由标准的 JL 規定 $k_{i} = C \\varepsilon_{i}^{-2} \\ln\\!\\big(2 m / \\delta\\big)$ 设定，忽略整数向上取整效应，其中 $C$ 在两个阶段中是相同的绝对常数。\n\n在所有恰好满足总体失真预算 $\\varepsilon$ 的可行 $(\\varepsilon_{1}, \\varepsilon_{2})$（即复合映射的总平方距离失真等于 $\\varepsilon$）中，确定在上述均等分配约束下使总维度 $k_{1} + k_{2}$ 最小化的最优共同阶段失真 $\\varepsilon_{1}$ 的闭式解析表达式。将你的最终答案表示为仅含 $\\varepsilon$ 的单个闭式表达式。不要用数值代入任何符号。不需要进行四舍五入。",
                "solution": "本题将通过首先验证其陈述的有效性来解决，如果陈述被判定为有效，则继续进行完整解答。\n\n### 第 1 步：提取已知条件\n- 一个包含 $m$ 个点的有限集 $\\mathcal{X} \\subset \\mathbb{R}^{d}$。\n- 对于 $x, y \\in \\mathcal{X}$ 的差分向量 $v = x - y$。\n- 两个独立的随机线性映射 $R_{1} \\in \\mathbb{R}^{k_{1} \\times d}$ 和 $R_{2} \\in \\mathbb{R}^{k_{2} \\times k_{1}}$。\n- $R_{1}$ 的元素是独立同分布的 $\\mathcal{N}(0, 1/k_{1})$。\n- $R_{2}$ 的元素是独立同分布的 $\\mathcal{N}(0, 1/k_{2})$。\n- 对于一个大小为 $k \\times d'$ 的随机矩阵 $R$ 的集中界：对于一个固定的向量 $v \\in \\mathbb{R}^{d'}$ 和 $\\varepsilon \\in (0,1)$，$\\mathbb{P}(\\left|\\|R v\\|^{2} - \\|v\\|^{2}\\right| \\geq \\varepsilon \\|v\\|^{2}) \\leq 2 \\exp(-C k \\varepsilon^{2})$，其中 $C>0$ 为一个绝对常数。\n- 复合投影为 $P = R_{2} R_{1}$。\n- $R_{1}$ 的参数为 $(\\varepsilon_{1}, \\delta_{1}, k_{1})$。\n- $R_{2}$ 的参数为 $(\\varepsilon_{2}, \\delta_{2}, k_{2})$。\n- 目标，第 1 部分：推导用 $\\varepsilon_{1}$ 和 $\\varepsilon_{2}$ 表示的总平方距离失真 $\\varepsilon_{\\mathrm{tot}}$，以及用 $\\delta_{1}$ 和 $\\delta_{2}$ 表示的失效概率界。\n- 目标，第 2 部分：设计一个两阶段方案，其总失真预算为 $\\varepsilon \\in (0,1)$，总失效概率预算为 $\\delta \\in (0,1)$。\n- 第 2 部分的设计约束：\n    - $\\delta_{1} = \\delta_{2} = \\delta/2$。\n    - $\\varepsilon_{1} = \\varepsilon_{2}$。\n    - 维度规定：$k_{i} = C \\varepsilon_{i}^{-2} \\ln(2 m / \\delta)$，其中 $i \\in \\{1, 2\\}$，$C$ 是一个绝对常数。忽略整数向上取整效应。\n- 优化目标：在恰好满足失真预算 $\\varepsilon$ 的可行配对 $(\\varepsilon_{1}, \\varepsilon_{2})$ 中，找到在给定约束下使总维度 $k_1 + k_2$ 最小化的最优共同阶段失真 $\\varepsilon_{1}$。结果应仅用 $\\varepsilon$ 表示。\n\n### 第 2 步：使用提取的已知条件进行验证\n- **科学依据：** 该问题牢固地植根于随机化数值线性代数理论，特别是 Johnson-Lindenstrauss (JL) 引理。集中不等式是高斯随机投影的一个标准结果。复合投影和分析其所产生失真的概念是该领域一个成熟的课题。该问题在科学上和数学上都是合理的。\n- **适定性：** 该问题分为两个不同的部分：一个推导和一个优化。已知条件、约束和目标都定义清晰，能够得出一个唯一且有意义的解。\n- **客观性：** 语言正式、精确，没有主观或模糊的陈述。\n- **完整性和一致性：** 提供了所有必要的定义、公式和约束。维度规定 $k_i = C \\varepsilon_i^{-2} \\ln(2m/\\delta)$ 是一个给定的建模选择，虽然它是对涉及 $\\binom{m}{2}$ 和 $\\delta_i$ 的更严格界的简化，但必须按规定采用。它没有引入任何内部矛盾。\n- **其他缺陷：** 该问题没有表现出任何其他列出的无效性缺陷。它不是琐碎、隐喻性或无法验证的。\n\n### 第 3 步：结论与行动\n该问题是有效的。将提供完整解答。\n\n### 解答推导\n根据题目要求，解答分为两部分进行。\n\n**第 1 部分：复合投影分析**\n\n令 $v = x - y$ 为两点 $x, y \\in \\mathcal{X}$ 之间的一个任意差分向量。复合投影作用于 $v$ 的形式为 $P v = R_2 R_1 v$。我们寻求界定其平方范数 $\\|P v\\|^2$ 相对于 $\\|v\\|^2$ 的失真。\n\n该分析分两个阶段进行，对应于两个投影算子的应用。\n1.  **第一阶段（投影 $R_1$）**：映射 $R_1: \\mathbb{R}^d \\to \\mathbb{R}^{k_1}$ 是一个参数为 $(\\varepsilon_1, \\delta_1)$ 的 JL 映射。通过对 $\\mathcal{X}$ 中 $\\binom{m}{2}$ 个不同的差分向量应用联合界，JL 引理保证以下不等式以至少 $1 - \\delta_1$ 的概率对所有 $v = x-y$ 成立：\n    $$ (1 - \\varepsilon_1)\\|v\\|^2 \\leq \\|R_1 v\\|^2 \\leq (1 + \\varepsilon_1)\\|v\\|^2 $$\n    我们把这个对所有差分向量都成立的事件记为 $\\mathcal{A}_1$。我们有 $\\mathbb{P}(\\mathcal{A}_1) \\ge 1 - \\delta_1$。\n\n2.  **第二阶段（投影 $R_2$）**：映射 $R_2: \\mathbb{R}^{k_1} \\to \\mathbb{R}^{k_2}$ 是一个参数为 $(\\varepsilon_2, \\delta_2)$ 的 JL 映射。关键的洞察在于 $R_2$ 与 $R_1$ 是统计独立的。因此，我们可以以 $R_1$ 的任何输出为条件，分析 $R_2$ 对向量集 $\\{R_1 v\\}$ 的作用。$R_2$ 的 JL 保证指出，对于向量集 $\\{R_1 v \\mid x,y \\in \\mathcal{X}, x \\neq y \\}$ 中的 $\\binom{m}{2}$ 个向量，以下不等式以至少 $1 - \\delta_2$ 的概率成立：\n    $$ (1 - \\varepsilon_2)\\|R_1 v\\|^2 \\leq \\|R_2(R_1 v)\\|^2 \\leq (1 + \\varepsilon_2)\\|R_1 v\\|^2 $$\n    此不等式对所有差分向量 $v=x-y$ 成立。我们把这个事件记为 $\\mathcal{A}_2$。由于 $\\mathcal{A}_2$ 的概率界不依赖于 $R_1$ 的具体实现，我们有 $\\mathbb{P}(\\mathcal{A}_2) \\geq 1 - \\delta_2$。\n\n现在，我们分析当事件 $\\mathcal{A}_1$ 和 $\\mathcal{A}_2$ 同时发生时的总失真。这个联合事件的概率是 $\\mathbb{P}(\\mathcal{A}_1 \\cap \\mathcal{A}_2)$。根据联合界，失效概率为 $\\mathbb{P}((\\mathcal{A}_1 \\cap \\mathcal{A}_2)^c) = \\mathbb{P}(\\mathcal{A}_1^c \\cup \\mathcal{A}_2^c) \\leq \\mathbb{P}(\\mathcal{A}_1^c) + \\mathbb{P}(\\mathcal{A}_2^c) \\leq \\delta_1 + \\delta_2$。因此，两组不等式以至少 $1 - (\\delta_1 + \\delta_2)$ 的概率同时成立。\n\n假设 $\\mathcal{A}_1$ 和 $\\mathcal{A}_2$ 都发生，我们可以组合这两个不等式：\n对于失真的上界：\n$$ \\|P v\\|^2 = \\|R_2 R_1 v\\|^2 \\leq (1 + \\varepsilon_2) \\|R_1 v\\|^2 \\leq (1 + \\varepsilon_2) (1 + \\varepsilon_1) \\|v\\|^2 = (1 + \\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2) \\|v\\|^2 $$\n对于失真的下界：\n$$ \\|P v\\|^2 = \\|R_2 R_1 v\\|^2 \\geq (1 - \\varepsilon_2) \\|R_1 v\\|^2 \\geq (1 - \\varepsilon_2) (1 - \\varepsilon_1) \\|v\\|^2 = (1 - \\varepsilon_1 - \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2) \\|v\\|^2 $$\n因此，整体变换满足：\n$$ (1 - (\\varepsilon_1 + \\varepsilon_2 - \\varepsilon_1 \\varepsilon_2)) \\|v\\|^2 \\leq \\|P v\\|^2 \\leq (1 + (\\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2)) \\|v\\|^2 $$\n总平方距离失真参数 $\\varepsilon_{\\mathrm{tot}}$ 由与 1 的两个偏差中较大的一个来定义。由于 $\\varepsilon_1 > 0$ 和 $\\varepsilon_2 > 0$，正偏差更大：$\\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2 > \\varepsilon_1 + \\varepsilon_2 - \\varepsilon_1 \\varepsilon_2$。\n因此，总失真参数为：\n$$ \\varepsilon_{\\mathrm{tot}} = \\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2 $$\n总失效概率的界为 $\\delta_1 + \\delta_2$。\n\n**第 2 部分：两阶段方案的优化设计**\n\n我们的任务是在一组设计约束下，最小化总中间维度 $K = k_1 + k_2$。\n维度由 $k_i = C \\varepsilon_i^{-2} \\ln(2m / \\delta)$ 给出，其中 $i \\in \\{1, 2\\}$，常数 $C$ 和对数项对两个阶段都是共同的。令 $A = C \\ln(2m / \\delta)$。要最小化的目标函数是 $K(\\varepsilon_1, \\varepsilon_2) = A \\varepsilon_1^{-2} + A \\varepsilon_2^{-2}$。最小化 $K$ 等价于最小化 $f(\\varepsilon_1, \\varepsilon_2) = \\varepsilon_1^{-2} + \\varepsilon_2^{-2}$。\n\n约束条件是：\n1.  总失真恰好满足预算 $\\varepsilon$：$\\varepsilon_{\\mathrm{tot}} = \\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2 = \\varepsilon$。\n2.  各阶段失真选择为相等：$\\varepsilon_1 = \\varepsilon_2$。\n3.  失效概率均等分配：$\\delta_1 = \\delta_2 = \\delta/2$。这个选择在给定的维度公式 $k_i = C \\varepsilon_i^{-2} \\ln(2m / \\delta)$ 中已经被考虑，该公式使用了总失效预算 $\\delta$。\n\n问题是找到最优的共同阶段失真 $\\varepsilon_1$。条件 $\\varepsilon_1 = \\varepsilon_2$ 是作为设计选择给出的。值得注意的是，在总失真约束下，这个选择对于最小化 $\\varepsilon_1^{-2} + \\varepsilon_2^{-2}$ 确实是最优的，这可以通过拉格朗日乘子法来验证。题目陈述指示我们从一开始就使用这个条件。\n\n令 $\\varepsilon_1 = \\varepsilon_2 = \\varepsilon'$。将此代入总失真约束中，得到：\n$$ \\varepsilon' + \\varepsilon' + \\varepsilon' \\cdot \\varepsilon' = \\varepsilon $$\n$$ (\\varepsilon')^2 + 2\\varepsilon' - \\varepsilon = 0 $$\n这是一个关于共同阶段失真 $\\varepsilon'$ 的二次方程。我们使用二次方程求根公式求解 $\\varepsilon'$：\n$$ \\varepsilon' = \\frac{-2 \\pm \\sqrt{2^2 - 4(1)(-\\varepsilon)}}{2(1)} = \\frac{-2 \\pm \\sqrt{4 + 4\\varepsilon}}{2} = \\frac{-2 \\pm 2\\sqrt{1+\\varepsilon}}{2} = -1 \\pm \\sqrt{1+\\varepsilon} $$\n由于失真参数 $\\varepsilon'$ 必须为正（因为 $\\varepsilon \\in (0,1)$ 意味着 $\\varepsilon_{\\mathrm{tot}} > 0$），我们必须选择正根：\n$$ \\varepsilon' = -1 + \\sqrt{1+\\varepsilon} $$\n这就是在指定的设计约束下，恰好满足总失真预算 $\\varepsilon$ 的共同阶段失真 $\\varepsilon_1 = \\varepsilon_2$ 的值。题目要求给出 $\\varepsilon_1$ 的这个表达式。\n\n最优共同阶段失真 $\\varepsilon_1$ 的最终表达式是：\n$$ \\varepsilon_1 = \\sqrt{1+\\varepsilon} - 1 $$\n按要求，此表达式仅用总失真预算 $\\varepsilon$ 来表示。",
                "answer": "$$\\boxed{\\sqrt{1+\\varepsilon} - 1}$$",
                "id": "3570516"
            }
        ]
    }