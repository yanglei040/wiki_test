{
        "hands_on_practices": [
            {
                "introduction": "经典格拉姆-施密特（CGS）和修正格拉姆-施密特（MGS）方法在理论上的稳定性差异在实践中表现得尤为明显。第一个练习 [@problem_id:2419987] 提供了一个直接的计算比较，要求你实现这两种算法，并在一个经过特殊设计的、包含近共线列向量的矩阵上进行测试。通过测量最终的正交性误差，你将对为何 MGS 在几乎所有实际数值应用中都是首选方案获得切实的理解。",
                "problem": "给定一个在实向量空间中构造的近似共线的列向量集合族。对于给定的整数 $n \\ge k \\ge 1$ 和实数参数 $\\epsilon \\ge 0$，定义 $\\mathbb{R}^n$ 的标准基 $\\{e_1,\\dots,e_n\\}$，并构造一个 $n \\times k$ 矩阵 $A = [a_1,\\dots,a_k]$，其列向量为\n- $a_1 = e_1$，\n- 对于 $2 \\le j \\le k$，$a_j = e_1 + \\epsilon^{\\,j-1} e_j$。\n所有计算都要求在双精度浮点算术中执行。\n\n任务:\n1. 使用上面定义的矩阵 $A$，对 $A$ 的列向量进行标准正交化，得到两个结果：\n   - 一个使用经典格拉姆-施密特（CGS）方法，得到矩阵 $Q^{(c)} \\in \\mathbb{R}^{n \\times k}$，\n   - 一个使用修正格拉姆-施密特（MGS）方法，得到矩阵 $Q^{(m)} \\in \\mathbb{R}^{n \\times k}$。\n   对于这两种方法，如果用于归一化某列的范数为零，则 $Q$ 中对应的列向量必须设置为零向量。\n2. 对于任意 $Q \\in \\mathbb{R}^{n \\times k}$，其正交性误差定义如下。设 $q_j$ 表示 $Q$ 的第 $j$ 列，设 $\\delta = 10^{-14}$，并定义索引集 $J = \\{ j \\in \\{1,\\dots,k\\} : \\|q_j\\|_2 > \\delta \\}$。设 $r = |J|$，并设 $Q_J \\in \\mathbb{R}^{n \\times r}$ 是一个子矩阵，它只包含 $Q$ 中由 $J$ 索引的列（按 $j$ 的升序排列）。定义\n   $$E(Q) = \\begin{cases}\n   \\left\\| Q_J^{\\mathsf{T}} Q_J - I_r \\right\\|_F,  r \\ge 1, \\\\\n   0,  r = 0,\n   \\end{cases}$$\n   其中 $\\|\\cdot\\|_F$ 表示弗罗贝尼乌斯范数，$I_r$ 是 $r \\times r$ 的单位矩阵。\n3. 对于下面测试套件中的每个测试用例，从 $(n,k,\\epsilon)$ 构造 $A$，计算 $Q^{(c)}$ 和 $Q^{(m)}$，然后计算正交性误差对 $\\big(E(Q^{(c)}), E(Q^{(m)})\\big)$。\n\n测试套件:\n- 用例 1 (理想情况): $(n,k,\\epsilon) = (6, 3, 10^{-8})$。\n- 用例 2 (边界情况，除一个方向外完全共线): $(n,k,\\epsilon) = (6, 3, 0)$。\n- 用例 3 (更深的近似共线性链): $(n,k,\\epsilon) = (10, 8, 10^{-12})$。\n- 用例 4 (边缘情况，扰动接近机器精度): $(n,k,\\epsilon) = (6, 5, 10^{-16})$。\n\n最终输出格式:\n- 你的程序必须生成单行输出，其中包含一个 Python 风格的浮点数列表的列表作为结果：\n  $$\\big[ [E(Q^{(c)}_1), E(Q^{(m)}_1)], [E(Q^{(c)}_2), E(Q^{(m)}_2)], [E(Q^{(c)}_3), E(Q^{(m)}_3)], [E(Q^{(c)}_4), E(Q^{(m)}_4)] \\big],$$\n  其中下标表示测试用例编号。数字应以标准十进制或科学记数法打印，不带任何附加文本。程序不得读取任何输入，且必须能直接运行。",
                "solution": "所提出的问题陈述已经过验证，并被认为是有效的。这是一个计算工程和数值线性代数中的适定问题，旨在展示经典格拉姆-施密特（CGS）和修正格拉姆-施密特（MGS）标准正交化算法的不同数值稳定性。该问题具有科学依据、自洽，并且其所有组成部分都经过了严格定义。\n\n任务是比较将 CGS 和 MGS 应用于一组近似共线的向量时正交性的损失情况。共线程度由参数 $\\epsilon$ 控制。对于较小的 $\\epsilon$，这些向量在数值上变得难以区分，这暴露了数值不稳定算法的弱点。\n\n首先，我们为给定的整数 $n \\ge k \\ge 1$ 和实数参数 $\\epsilon \\ge 0$ 定义矩阵 $A \\in \\mathbb{R}^{n \\times k}$。其列向量 $a_j$（$j=1, \\dots, k$）的构造如下：\n- $a_1 = e_1$\n- $a_j = e_1 + \\epsilon^{j-1} e_j$ for $2 \\le j \\le k$\n其中 $\\{e_1, \\dots, e_n\\}$ 是 $\\mathbb{R}^n$ 的标准基。当 $\\epsilon \\to 0$ 时，对于 $j \\ge 2$ 的向量 $a_j$ 会趋近于 $a_1$，从而产生一组近似线性相关的向量。这种构造对标准正交化算法提出了严峻的考验。所有计算都在标准的双精度浮点算术中执行，其中机器ε大约为 $\\epsilon_{mach} \\approx 2.22 \\times 10^{-16}$。\n\n两种标准正交化算法如下：\n\n**经典格拉姆-施密特（CGS）**\nCGS 算法从输入向量 $\\{a_1, \\dots, a_k\\}$ 生成一组标准正交向量 $\\{q_1, \\dots, q_k\\}$。对于每个向量 $a_j$，它会减去该向量在先前已计算出的标准正交向量 $\\{q_1, \\dots, q_{j-1}\\}$ 方向上的所有分量。该过程定义为：\n1. 初始化 $v_j = a_j$。\n2. 计算投影和：$v_j = a_j - \\sum_{i=1}^{j-1} (q_i^{\\mathsf{T}} a_j) q_i$。\n3. 归一化：$q_j = v_j / \\|v_j\\|_2$。\n\nCGS 的数值不稳定性源于步骤 2。项 $(q_i^{\\mathsf{T}} a_j)$ 是使用原始向量 $a_j$ 计算的。如果 $a_j$ 与由 $\\{q_1, \\dots, q_{j-1}\\}$ 张成的子空间近似平行，那么向量 $v_j$ 将是一个大向量减去另一个几乎相同的大向量的结果。这个操作被称为灾难性抵消，会导致相对精度的大量损失。计算得到的向量 $\\hat{v}_j$ 可能仍然含有与 $\\{q_1, \\dots, q_{j-1}\\}$ 平行的显著分量，这意味着最终的向量集 $\\{\\hat{q}_1, \\dots, \\hat{q}_k\\}$ 未能保持正交性。\n\n**修正格拉姆-施密特（MGS）**\nMGS 算法是对 CGS 计算的一种重新排列，在数值上更为稳定。MGS 不是将单个向量 $a_j$ 投影到所有先前的 $q_i$ 上，而是取每个新的标准正交向量 $q_j$，并立即从所有后续向量 $\\{a_{j+1}, \\dots, a_k\\}$ 中移除其分量。\n该过程为：\n1. 对所有 $j=1, \\dots, k$，初始化 $v_j = a_j$。\n2. 对于 $j=1, \\dots, k$：\n   a. 归一化当前向量：$q_j = v_j / \\|v_j\\|_2$。\n   b. 将所有后续向量与新的 $q_j$ 正交化：对于 $l = j+1, \\dots, k$，有 $v_l = v_l - (q_j^{\\mathsf{T}} v_l) q_j$。\n\n这个过程在数学上与 CGS 等价，但在有限精度计算中表现截然不同。通过在每一步都对向量 $v_l$ 进行正交化，MGS 有效地执行了正交性的迭代修正，从而防止了 CGS 中出现的误差累积。作为投影基准的向量 $v_l$ 已经与 $\\{q_1, \\dots, q_{j-1}\\}$ 正交，这使得计算更加稳健。\n\n对于这两种算法，问题规定，如果要归一化的向量范数 $\\|v_j\\|_2$ 为零，则结果列 $q_j$ 应为零向量。在浮点环境中，我们通过检查范数是否低于一个小的容差（例如 $10^{-20}$）来实现这一点，以稳健地处理因舍入误差而导致数学上为零但在数值上非零的值。\n\n**正交性误差度量**\n标准正交化的质量由正交性误差 $E(Q)$ 来衡量。给定一个矩阵 $Q \\in \\mathbb{R}^{n \\times k}$，我们首先滤除所有零列或接近零的列。我们定义一个索引集 $J = \\{ j \\in \\{1,\\dots,k\\} : \\|q_j\\|_2 > \\delta \\}$，容差为 $\\delta = 10^{-14}$。如果 $r = |J|$ 是不可忽略列的数量，我们从这些列中构成一个子矩阵 $Q_J \\in \\mathbb{R}^{n \\times r}$。误差是 $Q_J^{\\mathsf{T}} Q_J$ 与单位矩阵 $I_r$ 偏差的弗罗贝尼乌斯范数：\n$$\nE(Q) = \\begin{cases}\n   \\left\\| Q_J^{\\mathsf{T}} Q_J - I_r \\right\\|_F,  r \\ge 1, \\\\\n   0,  r = 0.\n\\end{cases}\n$$\n对于 $Q_J$ 中一组完美的标准正交列，该误差将为 $0$。\n\n**测试用例分析**\n- **用例 1: $(n, k, \\epsilon) = (6, 3, 10^{-8})$**。在此用例中，$\\epsilon = 10^{-8}$。向量 $a_2$ 与 $a_1$ 很接近，而 $a_3$ 则极其接近，因为它的扰动是 $\\epsilon^2 = 10^{-16}$，这已处于双精度的极限。$\\epsilon=10^{-8}$ 的值大约是 $\\sqrt{\\epsilon_{mach}}$，这是一个已知的阈值，当 $\\epsilon$ 小于此值时 CGS 会开始显著失去正交性。我们预计 CGS 会有明显的误差，而 MGS 应该能保持准确。\n- **用例 2: $(n, k, \\epsilon) = (6, 3, 0)$**。当 $\\epsilon=0$ 时，列向量完全共线：$A = [e_1, e_1, e_1]$。两种算法都应该能正确识别出线性相关性，生成 $Q = [e_1, 0, 0, \\dots]$。由于只有一个列向量非零，两种方法得到的误差 $E(Q)$ 都应该为 $0$。\n- **用例 3: $(n, k, \\epsilon) = (10, 8, 10^{-12})$**。扰动项 $\\epsilon^{j-1}$ 会迅速变得比机器精度还小。对于 $j=3$，$\\epsilon^2 = 10^{-24}$，因此 $a_3$ 在计算上将与 $e_1$ 完全相同。矩阵 $A$ 在数值上将是 $[e_1, e_1 + 10^{-12}e_2, e_1, e_1, \\dots]$。由于误差传播，CGS 将遭受严重的正交性损失。MGS 将正确地将 $a_2$ 与 $a_1$ 正交化，然后会发现所有后续向量都在 $q_1$ 的张成空间内，从而产生零向量。MGS 的误差应该很小，而 CGS 的误差将会很大。\n- **用例 4: $(n, k, \\epsilon) = (6, 5, 10^{-16})$**。在此用例中，$\\epsilon$ 本身就处于机器精度的水平。向量 $a_2 = e_1 + 10^{-16} e_2$ 几乎无法与 $a_1$ 区分。对于 $j \\ge 3$ 的所有后续向量 $a_j$ 在数值上将与 $e_1$ 相同。这是一个极端情况，预计 CGS 会完全失效，产生的列向量将远非正交。MGS 应该能优雅地处理这种情况，产生两个标准正交向量和随后的零向量，从而得到一个非常低的误差。\n\n实现将遵循这些原则，为每个测试用例计算指定的误差对。",
                "answer": "```python\nimport numpy as np\n\ndef build_A(n, k, epsilon):\n    \"\"\"\n    Constructs the n x k matrix A with nearly collinear columns.\n    \n    Args:\n        n (int): Number of rows.\n        k (int): Number of columns.\n        epsilon (float): Parameter controlling collinearity.\n    \n    Returns:\n        np.ndarray: The n x k matrix A.\n    \"\"\"\n    A = np.zeros((n, k), dtype=np.float64)\n    # a_1 = e_1\n    A[0, 0] = 1.0\n    # a_j = e_1 + epsilon^(j-1) * e_j for j >= 2\n    for j in range(1, k):\n        A[0, j] = 1.0\n        if j  n:\n            A[j, j] = epsilon**j\n    return A\n\ndef classical_gram_schmidt(A):\n    \"\"\"\n    Orthonormalizes the columns of A using the Classical Gram-Schmidt method.\n    \n    Args:\n        A (np.ndarray): The matrix to orthonormalize.\n    \n    Returns:\n        np.ndarray: The matrix Q with orthonormal columns.\n    \"\"\"\n    n, k = A.shape\n    Q = np.zeros((n, k), dtype=np.float64)\n    # A small tolerance to check for zero norm\n    norm_tol = 1e-20 \n    \n    for j in range(k):\n        v = A[:, j].copy()\n        for i in range(j):\n            # CGS projects the original vector A[:, j] onto each q_i\n            proj_coeff = np.dot(Q[:, i].T, A[:, j])\n            v -= proj_coeff * Q[:, i]\n        \n        norm_v = np.linalg.norm(v)\n        if norm_v > norm_tol:\n            Q[:, j] = v / norm_v\n        # If norm_v is too small, Q[:, j] remains a zero vector.\n            \n    return Q\n\ndef modified_gram_schmidt(A):\n    \"\"\"\n    Orthonormalizes the columns of A using the Modified Gram-Schmidt method.\n    \n    Args:\n        A (np.ndarray): The matrix to orthonormalize.\n    \n    Returns:\n        np.ndarray: The matrix Q with orthonormal columns.\n    \"\"\"\n    V = A.copy()\n    n, k = V.shape\n    Q = np.zeros((n, k), dtype=np.float64)\n    # A small tolerance to check for zero norm\n    norm_tol = 1e-20\n\n    for j in range(k):\n        norm_v = np.linalg.norm(V[:, j])\n        if norm_v > norm_tol:\n            Q[:, j] = V[:, j] / norm_v\n            # MGS orthogonalizes all subsequent vectors against the new q_j\n            for l in range(j + 1, k):\n                proj_coeff = np.dot(Q[:, j].T, V[:, l])\n                V[:, l] -= proj_coeff * Q[:, j]\n        # If norm_v is too small, Q[:, j] remains zero and no orthogonalization\n        # is performed against it.\n            \n    return Q\n\ndef orthogonality_error(Q):\n    \"\"\"\n    Calculates the orthogonality error E(Q) as defined in the problem.\n    \n    Args:\n        Q (np.ndarray): The matrix with putatively orthonormal columns.\n        \n    Returns:\n        float: The orthogonality error.\n    \"\"\"\n    n, k = Q.shape\n    delta = 1e-14\n    \n    J = [j for j in range(k) if np.linalg.norm(Q[:, j]) > delta]\n    r = len(J)\n    \n    if r == 0:\n        return 0.0\n    \n    Q_J = Q[:, J]\n    \n    I_r = np.identity(r, dtype=np.float64)\n    error_matrix = Q_J.T @ Q_J - I_r\n    \n    return np.linalg.norm(error_matrix, 'fro')\n\ndef solve():\n    \"\"\"\n    Runs the full test suite and prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        (6, 3, 1e-8),      # Case 1\n        (6, 3, 0.0),       # Case 2\n        (10, 8, 1e-12),    # Case 3\n        (6, 5, 1e-16),     # Case 4\n    ]\n\n    all_results = []\n    for n, k, epsilon in test_cases:\n        A = build_A(n, k, epsilon)\n        \n        Q_cgs = classical_gram_schmidt(A)\n        Q_mgs = modified_gram_schmidt(A)\n        \n        error_cgs = orthogonality_error(Q_cgs)\n        error_mgs = orthogonality_error(Q_mgs)\n        \n        all_results.append([error_cgs, error_mgs])\n\n    # The final print statement must follow the exact specified format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```",
                "id": "2419987"
            },
            {
                "introduction": "在确立了经典格拉姆-施密特（CGS）方法的失效之后，我们现在来探讨其失效的精确机制。这个练习 [@problem_id:3237762] 将引导你对一个精心挑选的病态矩阵进行一阶误差分析。通过应用一个简化的浮点误差模型，你将从解析上推导出正交性的损失并非微小扰动，而是一个量级为 $O(1)$ 的灾难性误差，从而直接将矩阵的条件数与算法的崩溃联系起来。",
                "problem": "考虑一个三列矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$，其列向量由机器精度 $\\epsilon_{mach}  0$ 定义如下\n$$\na_{1} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad\na_{2} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 + \\epsilon_{mach} \\end{pmatrix}, \\quad\na_{3} = \\begin{pmatrix} 1 \\\\ 1 - \\epsilon_{mach} \\\\ 1 \\end{pmatrix},\n$$\n且令 $A = [\\,a_{1}\\; a_{2}\\; a_{3}\\,]$。该矩阵 $A$ 近乎秩亏，因此其谱条件数 $\\kappa_{2}(A)$ 的数量级为 $1/\\epsilon_{mach}$。\n\n在采用最近舍入的标准浮点模型下，对矩阵 $A$ 应用经典格拉姆-施密特 (CGS) 过程。在此模型中，任何基本算术运算或点积表示为 $\\operatorname{fl}(x \\circ y) = (x \\circ y)(1 + \\delta)$，其中 $|\\delta| \\leq \\epsilon_{mach}$；任何标量-向量积表示为 $\\operatorname{fl}(\\alpha x) = (\\alpha x)(1 + \\delta)$，其中 $|\\delta| \\leq \\epsilon_{mach}$。我们只关注 CGS 正交化的第一步，即 $a_{2}$ 相对 $a_{1}$ 正交化以产生第二个基向量。假设：\n- 唯一对结果有实质性影响的舍入误差出现在计算点积 $r_{12} = q_{1}^{\\mathsf{T}} a_{2}$ 和标量-向量积 $r_{12} q_{1}$ 时，\n- 这两个相对误差的大小和符号均相等，即 $\\epsilon_{mach}$，\n- 所有其他步骤在主阶上可视为精确，且\n- 高于 $\\epsilon_{mach}$ 阶的项可以忽略。\n\n在这些假设下，计算前两个计算出的 CGS 向量之间正交性损失的主阶大小，量化为 $|q_{1}^{\\mathsf{T}} \\widehat{q}_{2}|$，其中 $q_{1}$ 是由 $a_{1}$ 归一化得到的第一个列向量，而 $\\widehat{q}_{2}$ 是如上所述，在浮点运算中使用 CGS 将 $a_{2}$ 相对 $q_{1}$ 正交化后得到的归一化向量。请提供一个单一的精确表达式作为最终答案。无需舍入。",
                "solution": "用户希望我分析对于一个给定的近秩亏矩阵 $A$，在经典格拉姆-施密特 (CGS) 过程的第一步中正交性的损失。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件**\n- 一个矩阵 $A = [\\,a_{1}\\; a_{2}\\; a_{3}\\,] \\in \\mathbb{R}^{3 \\times 3}$。\n- 列向量：\n$$\na_{1} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad\na_{2} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 + \\epsilon_{mach} \\end{pmatrix}, \\quad\na_{3} = \\begin{pmatrix} 1 \\\\ 1 - \\epsilon_{mach} \\\\ 1 \\end{pmatrix},\n$$\n其中 $\\epsilon_{mach}  0$ 是机器精度。\n- 谱条件数 $\\kappa_{2}(A)$ 的数量级为 $1/\\epsilon_{mach}$。\n- 浮点模型：\n    - $\\operatorname{fl}(x \\circ y) = (x \\circ y)(1 + \\delta)$，其中 $|\\delta| \\leq \\epsilon_{mach}$。\n    - $\\operatorname{fl}(\\alpha x) = (\\alpha x)(1 + \\delta)$，其中 $|\\delta| \\leq \\epsilon_{mach}$。\n- 针对第一次正交化步骤（$a_2$ 相对 $q_1$）的特定误差假设：\n    - 点积计算有特定误差：$\\hat{r}_{12} = \\operatorname{fl}(q_{1}^{\\mathsf{T}} a_{2}) = (q_{1}^{\\mathsf{T}} a_{2})(1 + \\delta_{1})$，其中 $\\delta_{1} = \\epsilon_{mach}$。\n    - 标量-向量积有特定误差：$\\operatorname{fl}(\\hat{r}_{12} q_{1}) = (\\hat{r}_{12} q_{1})(1 + \\delta_{2})$，其中 $\\delta_{2} = \\epsilon_{mach}$。\n- 简化假设：\n    - 所有其他步骤在主阶上可视为精确。\n    - 高于 $\\epsilon_{mach}$ 阶的项（即 $o(\\epsilon_{mach})$）可以忽略。\n- 任务是计算正交性损失的主阶大小，由 $|q_{1}^{\\mathsf{T}} \\widehat{q}_{2}|$ 给出。\n\n**1.2. 使用提取的已知条件进行验证**\n- **科学性：** 该问题是数值线性代数中的一个标准练习。它探讨了经典格拉姆-施密特过程在应用于近线性相关向量时众所周知的数值不稳定性。所用的模型和假设是一阶误差分析的典型形式。\n- **适定性：** 问题提供了所有必要的数据和清晰的计算模型，以确定所求量的唯一值。\n- **客观性：** 问题以精确、形式化的数学语言陈述，没有任何主观性。\n\n**1.3. 结论与行动**\n该问题是有效的。将提供详细的解答。\n\n### 步骤 2：求解\n\n目标是计算 $|q_{1}^{\\mathsf{T}} \\widehat{q}_{2}|$，其中 $q_1$ 是精确的归一化第一个向量，$\\widehat{q}_{2}$ 是计算出的第二个标准正交向量。\n\n**2.1. 计算第一个标准正交向量 $q_1$**\n第一个向量 $a_1$ 由下式给出\n$$ a_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $$\n其欧几里得范数为 $\\|a_1\\|_2 = \\sqrt{1^2 + 1^2 + 1^2} = \\sqrt{3}$。\n第一个标准正交向量 $q_1$ 通过归一化 $a_1$ 得到：\n$$ q_1 = \\frac{a_1}{\\|a_1\\|_2} = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $$\n根据问题假设“所有其他步骤可视为精确”，我们认为 $q_1$ 是精确计算的。\n\n**2.2. 第二个向量的浮点 CGS**\nCGS 过程将 $a_2$ 相对 $q_1$ 正交化，产生一个向量 $\\hat{v}_2$，然后将其归一化得到 $\\widehat{q}_{2}$。\n计算出的未归一化向量是 $\\hat{v}_2 = a_2 - \\hat{p}_2$，其中 $\\hat{p}_2$ 是 $a_2$ 在 $q_1$ 上的计算投影。\n$\\hat{p}_2$ 的计算涉及两个带有指定舍入误差的步骤：\n1.  计算投影系数：$\\hat{r}_{12} = \\operatorname{fl}(q_{1}^{\\mathsf{T}} a_{2})$。\n2.  计算投影向量：$\\hat{p}_2 = \\operatorname{fl}(\\hat{r}_{12} q_{1})$。\n\n使用给定的误差模型，其中 $\\delta_1 = \\delta_2 = \\epsilon_{mach}$：\n$$ \\hat{r}_{12} = (q_1^{\\mathsf{T}} a_2)(1 + \\epsilon_{mach}) $$\n$$ \\hat{p}_2 = \\hat{r}_{12} q_1 (1 + \\epsilon_{mach}) $$\n将 $\\hat{r}_{12}$ 的表达式代入 $\\hat{p}_2$ 的表达式中：\n$$ \\hat{p}_2 = (q_1^{\\mathsf{T}} a_2)(1 + \\epsilon_{mach}) q_1 (1 + \\epsilon_{mach}) = (q_1^{\\mathsf{T}} a_2)(1 + \\epsilon_{mach})^2 q_1 $$\n展开 $(1 + \\epsilon_{mach})^2 = 1 + 2\\epsilon_{mach} + \\epsilon_{mach}^2$。由于我们忽略高于 $\\epsilon_{mach}$ 阶的项，我们将其近似为 $1 + 2\\epsilon_{mach}$。\n$$ \\hat{p}_2 \\approx (q_1^{\\mathsf{T}} a_2)(1 + 2\\epsilon_{mach}) q_1 $$\n计算出的未归一化向量 $\\hat{v}_2$ 于是为：\n$$ \\hat{v}_2 = a_2 - \\hat{p}_2 \\approx a_2 - (q_1^{\\mathsf{T}} a_2)(1 + 2\\epsilon_{mach}) q_1 $$\n\n**2.3. 计算正交性的损失**\n正交性的损失由 $|q_1^{\\mathsf{T}} \\widehat{q}_2|$ 量化。由于 $\\widehat{q}_2 = \\hat{v}_2 / \\|\\hat{v}_2\\|_2$，我们有：\n$$ |q_1^{\\mathsf{T}} \\widehat{q}_2| = \\left|q_1^{\\mathsf{T}} \\frac{\\hat{v}_2}{\\|\\hat{v}_2\\|_2}\\right| = \\frac{|q_1^{\\mathsf{T}} \\hat{v}_2|}{\\|\\hat{v}_2\\|_2} $$\n我们需要计算主阶上的分子 $|q_1^{\\mathsf{T}} \\hat{v}_2|$ 和分母 $\\|\\hat{v}_2\\|_2$。\n\n**分子：**\n取 $\\hat{v}_2$ 与 $q_1$ 的点积：\n$$ q_1^{\\mathsf{T}} \\hat{v}_2 \\approx q_1^{\\mathsf{T}} \\left( a_2 - (q_1^{\\mathsf{T}} a_2)(1 + 2\\epsilon_{mach}) q_1 \\right) $$\n$$ q_1^{\\mathsf{T}} \\hat{v}_2 \\approx q_1^{\\mathsf{T}} a_2 - (q_1^{\\mathsf{T}} a_2)(1 + 2\\epsilon_{mach}) (q_1^{\\mathsf{T}} q_1) $$\n因为 $q_1$ 是单位向量，所以 $q_1^{\\mathsf{T}} q_1 = 1$。\n$$ q_1^{\\mathsf{T}} \\hat{v}_2 \\approx q_1^{\\mathsf{T}} a_2 - (q_1^{\\mathsf{T}} a_2)(1 + 2\\epsilon_{mach}) = q_1^{\\mathsf{T}} a_2 - q_1^{\\mathsf{T}} a_2 - 2\\epsilon_{mach}(q_1^{\\mathsf{T}} a_2) $$\n$$ q_1^{\\mathsf{T}} \\hat{v}_2 \\approx -2\\epsilon_{mach}(q_1^{\\mathsf{T}} a_2) $$\n我们来计算 $q_1^{\\mathsf{T}} a_2$：\n$$ q_1^{\\mathsf{T}} a_2 = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 + \\epsilon_{mach} \\end{pmatrix} = \\frac{1}{\\sqrt{3}}(1 + 1 + 1 + \\epsilon_{mach}) = \\frac{3 + \\epsilon_{mach}}{\\sqrt{3}} $$\n在 $\\epsilon_{mach}$ 的主阶上，$q_1^{\\mathsf{T}} a_2 \\approx \\frac{3}{\\sqrt{3}} = \\sqrt{3}$。\n将此代入 $q_1^{\\mathsf{T}} \\hat{v}_2$ 的表达式中：\n$$ q_1^{\\mathsf{T}} \\hat{v}_2 \\approx -2\\epsilon_{mach} \\left(\\frac{3 + \\epsilon_{mach}}{\\sqrt{3}}\\right) = -\\frac{6\\epsilon_{mach}}{\\sqrt{3}} - \\frac{2\\epsilon_{mach}^2}{\\sqrt{3}} $$\n主阶项是 $-2\\sqrt{3}\\epsilon_{mach}$。因此，其大小为：\n$$ |q_1^{\\mathsf{T}} \\hat{v}_2| \\approx 2\\sqrt{3}\\epsilon_{mach} $$\n\n**分母：**\n我们需要求 $\\|\\hat{v}_2\\|_2$。让我们重新整理 $\\hat{v}_2$ 的表达式：\n$$ \\hat{v}_2 \\approx a_2 - (q_1^{\\mathsf{T}} a_2)q_1 - 2\\epsilon_{mach}(q_1^{\\mathsf{T}} a_2)q_1 $$\n第一部分 $v_2 = a_2 - (q_1^{\\mathsf{T}} a_2)q_1$ 是 $a_2$ 相对于 $q_1$ 的精确正交分量。第二部分 $-2\\epsilon_{mach}(q_1^{\\mathsf{T}} a_2)q_1$ 与 $q_1$ 平行。由于这两个分量是正交的，我们可以使用勾股定理来求范数：\n$$ \\|\\hat{v}_2\\|_2^2 \\approx \\|v_2\\|_2^2 + \\|-2\\epsilon_{mach}(q_1^{\\mathsf{T}} a_2)q_1\\|_2^2 $$\n首先，我们计算 $v_2$：\n$$ v_2 = a_2 - (q_1^{\\mathsf{T}} a_2)q_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1+\\epsilon_{mach} \\end{pmatrix} - \\frac{3+\\epsilon_{mach}}{3} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1+\\epsilon_{mach} \\end{pmatrix} - \\begin{pmatrix} 1+\\frac{\\epsilon_{mach}}{3} \\\\ 1+\\frac{\\epsilon_{mach}}{3} \\\\ 1+\\frac{\\epsilon_{mach}}{3} \\end{pmatrix} = \\begin{pmatrix} -\\frac{\\epsilon_{mach}}{3} \\\\ -\\frac{\\epsilon_{mach}}{3} \\\\ \\frac{2\\epsilon_{mach}}{3} \\end{pmatrix} $$\n$v_2$ 的范数是：\n$$ \\|v_2\\|_2 = \\sqrt{\\left(-\\frac{\\epsilon_{mach}}{3}\\right)^2 + \\left(-\\frac{\\epsilon_{mach}}{3}\\right)^2 + \\left(\\frac{2\\epsilon_{mach}}{3}\\right)^2} = \\frac{\\epsilon_{mach}}{3}\\sqrt{1+1+4} = \\frac{\\sqrt{6}}{3}\\epsilon_{mach} $$\n所以，$\\|v_2\\|_2^2 = \\frac{6}{9}\\epsilon_{mach}^2 = \\frac{2}{3}\\epsilon_{mach}^2$。\n接下来，第二部分的范数：\n$$ \\|-2\\epsilon_{mach}(q_1^{\\mathsf{T}} a_2)q_1\\|_2 = 2\\epsilon_{mach} |q_1^{\\mathsf{T}} a_2| \\|q_1\\|_2 = 2\\epsilon_{mach} \\frac{3+\\epsilon_{mach}}{\\sqrt{3}} $$\n主阶上，这是 $2\\epsilon_{mach} \\frac{3}{\\sqrt{3}} = 2\\sqrt{3}\\epsilon_{mach}$。\n其范数的平方是 $(2\\sqrt{3}\\epsilon_{mach})^2 = 12\\epsilon_{mach}^2$。\n现在，我们求 $\\|\\hat{v}_2\\|_2^2$：\n$$ \\|\\hat{v}_2\\|_2^2 \\approx \\|v_2\\|_2^2 + (2\\sqrt{3}\\epsilon_{mach})^2 = \\frac{2}{3}\\epsilon_{mach}^2 + 12\\epsilon_{mach}^2 = \\left(\\frac{2+36}{3}\\right)\\epsilon_{mach}^2 = \\frac{38}{3}\\epsilon_{mach}^2 $$\n取平方根得到范数：\n$$ \\|\\hat{v}_2\\|_2 \\approx \\sqrt{\\frac{38}{3}}\\epsilon_{mach} = \\frac{\\sqrt{114}}{3}\\epsilon_{mach} $$\n\n**最终比率：**\n最后，我们计算正交性损失的主阶大小：\n$$ |q_1^{\\mathsf{T}} \\widehat{q}_2| = \\frac{|q_1^{\\mathsf{T}} \\hat{v}_2|}{\\|\\hat{v}_2\\|_2} \\approx \\frac{2\\sqrt{3}\\epsilon_{mach}}{\\frac{\\sqrt{114}}{3}\\epsilon_{mach}} $$\n$\\epsilon_{mach}$ 项相互抵消。\n$$ |q_1^{\\mathsf{T}} \\widehat{q}_2| \\approx \\frac{2\\sqrt{3}}{\\frac{\\sqrt{114}}{3}} = \\frac{6\\sqrt{3}}{\\sqrt{114}} $$\n简化表达式：\n$$ \\frac{6\\sqrt{3}}{\\sqrt{114}} = \\frac{6\\sqrt{3}}{\\sqrt{3 \\cdot 38}} = \\frac{6\\sqrt{3}}{\\sqrt{3}\\sqrt{38}} = \\frac{6}{\\sqrt{38}} $$\n这个值是 $O(1)$ 数量级的，这与 CGS 对于近线性相关向量的已知行为是一致的，其正交性损失与 $\\kappa_2(A)\\epsilon_{mach} \\sim (1/\\epsilon_{mach})\\epsilon_{mach} \\sim 1$ 成正比。",
                "answer": "$$ \\boxed{\\frac{6}{\\sqrt{38}}} $$",
                "id": "3237762"
            },
            {
                "introduction": "在确立了修正格拉姆-施密特（MGS）方法的优越性之后，我们现在来探讨其数值稳定性的一个更细微的方面：它对列序的敏感性。这个练习 [@problem_id:3557033] 表明，MGS 中舍入误差的累积并非一成不变，它会受到向量处理顺序的显著影响。通过对一个病态矩阵的列进行不同的排列组合进行实验，你将发现策略性的排序（即列主元策略的前身）如何能够帮助更好地保持正交性。",
                "problem": "你需要研究在使用修正的 Gram-Schmidt (MGS) 算法时，正交性的敏感度如何随列排序和部分条件数的演进而变化。请从以下基本概念出发：修正的 Gram-Schmidt (MGS) 算法通过迭代地将当前列投影到先前已构建的标准正交向量上，减去这些投影，然后进行归一化，从而对矩阵进行标准正交化；浮点舍入模型假设实数上的任何基本算术运算都遵循 $ \\mathrm{fl}(x \\circ y) = (x \\circ y)(1 + \\delta) $，其中 $ |\\delta| \\le u $，$u$ 是单位舍入；矩阵 $A$ 的奇异值分解 (SVD) 为 $ A = U \\Sigma V^{\\mathsf{T}} $，其 2-范数条件数定义为 $ \\kappa_2(A) = \\sigma_{\\max}(A) / \\sigma_{\\min}(A) $，其中 $ \\sigma_{\\max}(A) $ 和 $ \\sigma_{\\min}(A) $ 分别是 $A$ 的最大和最小奇异值。\n\n构建一个高瘦矩阵 $ A \\in \\mathbb{R}^{n \\times m} $，其中 $ n = 100 $ 且 $ m = 6 $，具体如下。设 $ G \\in \\mathbb{R}^{n \\times m} $ 的元素为独立标准正态分布，使用固定的伪随机种子 $ 0 $ 确定性地生成。通过 $ c_1 = G_{:,1} $，$ c_2 = c_1 + \\varepsilon_1 G_{:,2} $，$ c_3 = G_{:,3} $，$ c_4 = c_3 + \\varepsilon_2 G_{:,4} $，$ c_5 = G_{:,5} $，$ c_6 = G_{:,6} $ 来定义 $A$ 的列 $ c_1, c_2, \\dots, c_6 $，其中 $ \\varepsilon_1 = 10^{-12} $ 且 $ \\varepsilon_2 = 10^{-8} $。这些构造产生了两个近共线对 $ (c_1, c_2) $ 和 $ (c_3, c_4) $，其近相关程度不同。\n\n实现修正的 Gram-Schmidt (MGS) 算法，为给定列排序的 $A$ 计算标准正交基 $ Q \\in \\mathbb{R}^{n \\times m} $ 和上三角矩阵 $ R \\in \\mathbb{R}^{m \\times m} $。为了数值鲁棒性，如果在任何步骤中计算出的对角线元素 $ R_{jj} $ 为 $0$（表示在浮点运算中存在精确相关性），则将 $Q$ 的第 $j$ 列设置为零向量。将 $Q$ 的正交性缺陷定义为弗罗贝尼乌斯范数 $ d(Q) = \\| Q^{\\mathsf{T}} Q - I_m \\|_F $，其中 $ I_m $ 是 $ m \\times m $ 的单位矩阵，$ \\| \\cdot \\|_F $ 表示弗罗贝尼乌斯范数。此外，对于给定的列排列 $ \\pi $，定义部分条件数序列为 $ \\kappa_k = \\kappa_2\\!\\left(A_{:, \\pi(1:k)}\\right) $，$k = 1, 2, \\dots, m$，即在给定排序下前 $k$ 列子矩阵的条件数。\n\n你的程序必须：\n- 根据上述规范构造 $A$。\n- 对于每个指定的列排列，对排列后的列使用 MGS 计算 $Q$，然后计算正交性缺陷 $ d(Q) $。\n- 使用以下列排列的测试套件，每个排列表示为 $ \\{1,2,3,4,5,6\\} $ 的一个排序 $ \\pi $：\n  1. 恒等排序 $ \\pi_1 = [1,2,3,4,5,6] $（两个近共线对都出现在早期）。\n  2. 排序 $ \\pi_2 = [3,4,5,6,1,2] $（两个近共线对都出现在晚期）。\n  3. 交错排序 $ \\pi_3 = [1,3,2,4,5,6] $（每个近共线向量与其配对向量之间有间隔）。\n  4. 逆序排序 $ \\pi_4 = [6,5,4,3,2,1] $（将较弱的近相关性置于较强的之前，并反转整体进程）。\n- 对于每个排列，仅输出正交性缺陷 $ d(Q) $，格式为浮点数。\n\n覆盖性设计：\n- 恒等排序是一个一般情况，严重的近相关性出现在早期。\n- 晚期放置排序旨在探究推迟处理严重的近相关性是否能减少正交性的累积损失。\n- 交错排序旨在探究将近相关列与独立列混合的效果。\n- 逆序排序旨在探究一个边界情况，其中部分条件数的演进过程被翻转。\n\n最终输出格式：\n你的程序应生成一行输出，其中包含四个测试用例的正交性缺陷，格式为方括号内以逗号分隔的列表，顺序为 $ [d(Q_{\\pi_1}), d(Q_{\\pi_2}), d(Q_{\\pi_3}), d(Q_{\\pi_4})] $。例如，如果计算出的缺陷为 $ a $, $ b $, $ c $, 和 $ d $，则程序必须打印行 $ [a,b,c,d] $。不涉及物理单位或角度单位；所有输出都是无量纲的浮点数。",
                "solution": "所提供的问题是数值线性代数领域中一个有效的数值实验。它具有科学依据、问题适定且客观。所有必要的参数和定义都已提供，任务是实现一个标准算法（修正的 Gram-Schmidt）和一个标准诊断工具（正交性缺陷），以研究一个众所周知的现象：在存在近线性相关时，Gram-Schmidt 过程对列排序的敏感性。\n\n该问题旨在分析对于一个特殊构造的病态矩阵，在使用修正的 Gram-Schmidt (MGS) 算法时，正交性的损失作为列排序的函数如何变化。矩阵 $A \\in \\mathbb{R}^{n \\times m}$（维度为 $n = 100$ 和 $m = 6$）被设计为含有两对近共线列向量，$(c_1, c_2)$ 和 $(c_3, c_4)$，其严重程度不同。这是通过定义 $c_2 = c_1 + \\varepsilon_1 G_{:,2}$ 和 $c_4 = c_3 + \\varepsilon_2 G_{:,4}$ 实现的，其中 $G$ 是一个标准正态随机变量矩阵，参数 $\\varepsilon_1 = 10^{-12}$ 和 $\\varepsilon_2 = 10^{-8}$ 控制近共线性。由于 $\\varepsilon_1 \\ll \\varepsilon_2$，对 $(c_1, c_2)$ 的共线性远强于对 $(c_3, c_4)$，因此构成了更严重的病态源。\n\n任务的核心是实现修正的 Gram-Schmidt (MGS) 算法，为 $A$ 的各种列排序计算 $QR$ 分解。MGS 算法将矩阵 $A = [a_1, a_2, \\dots, a_m]$ 分解为一个标准正交矩阵 $Q = [q_1, q_2, \\dots, q_m]$ 和一个上三角矩阵 $R=\\{r_{ij}\\}$。该算法定义如下：\n初始化 $v_j = a_j$，$j=1, \\dots, m$。\n对于 $i = 1, \\dots, m$：\n$1$. 归一化当前向量：$r_{ii} = \\|v_i\\|_2$。如果 $r_{ii}$ 非零，则 $q_i = v_i / r_{ii}$。否则，该向量已在前述向量的生成空间中，根据问题规定将 $q_i$ 设为零。\n$2$. 将所有后续向量与新计算出的 $q_i$ 正交化。对于 $j = i+1, \\dots, m$：\n$$ r_{ij} = q_i^{\\mathsf{T}} v_j $$\n$$ v_j \\leftarrow v_j - r_{ij} q_i $$\nMGS 的一个关键特性是，在步骤 $i$ 中对向量 $v_j$ 进行正交化时，使用的是已经与 $q_1, \\dots, q_{i-1}$ 正交化过的 $v_j$ 版本。与经典 Gram-Schmidt (CGS) 算法相比，此特性使 MGS 具有更优的数值稳定性，尽管其鲁棒性不如基于 Householder 变换的方法。\n\n在以单位舍入 $u$ 为特征的有限精度算术中，计算出的矩阵 $Q$ 不会是完全正交的。正交性的损失通过缺陷度量 $d(Q) = \\| Q^{\\mathsf{T}} Q - I_m \\|_F$ 来量化，其中 $I_m$ 是 $m \\times m$ 的单位矩阵，$\\| \\cdot \\|_F$ 是弗罗贝尼乌斯范数。理论分析预测 $\\| Q^{\\mathsf{T}} Q - I_m \\|$ 的上界为一个与 $u \\cdot \\kappa_2(A)$ 成正比的量，其中 $\\kappa_2(A)$ 是 $A$ 的 2-范数条件数。\n\n该实验研究了四种不同的列排列 $\\pi_1, \\pi_2, \\pi_3, \\pi_4$，以理解病态列的排序如何影响最终的正交性。其关键思想是，舍入误差的累积对前导子矩阵的条件数 $\\kappa_k = \\kappa_2(A_{:, \\pi(1:k)})$ 很敏感。\n- $\\pi_1 = [1,2,3,4,5,6]$: 此排序首先处理条件最恶劣的对 $(c_1, c_2)$。子矩阵 $[c_1, c_2]$ 的条件数非常大，约为 $1/\\varepsilon_1$ 的量级。这预计会在第二步引入大的正交性损失，该损失随后会传播并污染后续计算，导致最大的总体缺陷。\n- $\\pi_2 = [3,4,5,6,1,2]$: 此排序推迟了对病态的处理，将最严重的对放在最后处理。初始的子矩阵是良态的。与 $c_1$ 和 $c_2$ 的近相关性相关的大误差仅在计算 $Q$ 的最后两列时才被引入。与 $\\pi_1$ 相比，这应导致正交性缺陷显著减小。\n- $\\pi_3 = [1,3,2,4,5,6]$: 此排序交错了相关的对。向量 $c_2$ 对 $q_1$（源自 $c_1$）和 $q_3$（源自 $c_3$）进行正交化。在使 $c_2$ 与 $c_1$ 正交时发生的灾难性抵消是主要的误差源。与一个独立向量交错并不能从根本上改变以下事实：$c_2$ 中与 $c_1$ 正交的信息被 $\\varepsilon_1$ 缩放，因此被舍入误差所淹没。预期的缺陷应该很大，与 $\\pi_1$ 的缺陷相当。\n- $\\pi_4 = [6,5,4,3,2,1]$: 此排序反转了列的顺序。它首先处理良态列，然后是 $(c_4, c_3)$ 对，最后是 $(c_2, c_1)$ 对。与 $\\pi_2$ 类似，这种策略延迟了对条件最恶劣列的处理，预计会产生较低的正交性缺陷。\n\n实现将使用固定的伪随机种子 $0$ 来构造矩阵 $A$ 以保证可复现性。对于指定的 4 个排列中的每一个，将对 $A$ 的列进行重排，应用 MGS 算法，并计算所得 $Q$ 矩阵的正交性缺陷。",
                "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Investigates the sensitivity of orthogonality in Modified Gram-Schmidt (MGS)\n    as a function of column ordering for an ill-conditioned matrix.\n    \"\"\"\n    # 1. Define problem parameters\n    n = 100\n    m = 6\n    eps1 = 1e-12\n    eps2 = 1e-8\n    seed = 0\n\n    # 2. Construct the matrix A\n    # Use a deterministic random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n    G = rng.standard_normal((n, m))\n    \n    A = np.zeros((n, m), dtype=float)\n    # Column 1\n    A[:, 0] = G[:, 0]\n    # Column 2 (nearly collinear with Column 1)\n    A[:, 1] = A[:, 0] + eps1 * G[:, 1]\n    # Column 3\n    A[:, 2] = G[:, 2]\n    # Column 4 (nearly collinear with Column 3)\n    A[:, 3] = A[:, 2] + eps2 * G[:, 3]\n    # Column 5\n    A[:, 4] = G[:, 4]\n    # Column 6\n    A[:, 5] = G[:, 5]\n\n    def modified_gram_schmidt(A_in: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Computes the QR factorization of a matrix A using the\n        Modified Gram-Schmidt algorithm.\n\n        Args:\n            A_in: The input matrix of shape (n, m).\n\n        Returns:\n            A tuple (Q, R) where Q is an n x m orthonormal matrix and\n            R is an m x m upper-triangular matrix.\n        \"\"\"\n        V = A_in.copy()\n        n_rows, n_cols = V.shape\n        Q = np.zeros((n_rows, n_cols), dtype=float)\n        R = np.zeros((n_cols, n_cols), dtype=float)\n\n        for i in range(n_cols):\n            # Compute the norm of the current vector\n            r_ii = np.linalg.norm(V[:, i])\n            R[i, i] = r_ii\n            \n            # Normalize to get the i-th orthonormal vector q_i\n            # Handle the case of a zero vector for robustness.\n            if r_ii > 0.0:\n                Q[:, i] = V[:, i] / r_ii\n            else:\n                Q[:, i] = 0.0\n            \n            # Orthogonalize all subsequent vectors against q_i\n            for j in range(i + 1, n_cols):\n                r_ij = Q[:, i].T @ V[:, j]\n                R[i, j] = r_ij\n                V[:, j] = V[:, j] - r_ij * Q[:, i]\n        \n        return Q, R\n\n    # 3. Define test cases (column permutations)\n    # Permutations are 1-based as per the problem description.\n    permutations = [\n        [1, 2, 3, 4, 5, 6],  # pi_1: Identity ordering\n        [3, 4, 5, 6, 1, 2],  # pi_2: Late near-dependence\n        [1, 3, 2, 4, 5, 6],  # pi_3: Interleaved near-dependence\n        [6, 5, 4, 3, 2, 1],  # pi_4: Reverse ordering\n    ]\n\n    results = []\n    # 4. Execute test cases and compute orthogonality defects\n    for perm in permutations:\n        # Convert 1-based permutation to 0-based indices for numpy\n        perm_indices = [p - 1 for p in perm]\n        A_permuted = A[:, perm_indices]\n        \n        Q, _ = modified_gram_schmidt(A_permuted)\n        \n        # Calculate the orthogonality defect: d(Q) = || Q^T Q - I_m ||_F\n        identity_m = np.eye(m)\n        defect_matrix = Q.T @ Q - identity_m\n        defect = np.linalg.norm(defect_matrix, 'fro')\n        results.append(defect)\n\n    # 5. Print the final results in the specified format\n    # Using scientific notation for consistent floating-point representation.\n    print(f\"[{','.join(f'{r:.10e}' for r in results)}]\")\n\nsolve()\n```",
                "id": "3557033"
            }
        ]
    }