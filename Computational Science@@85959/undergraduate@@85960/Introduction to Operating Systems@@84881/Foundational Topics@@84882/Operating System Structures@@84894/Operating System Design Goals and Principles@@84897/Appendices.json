{"hands_on_practices": [{"introduction": "Operating system schedulers constantly navigate the trade-off between responsiveness and overall system throughput. This practice challenges you to quantify this balance by analyzing how adjusting the preemption granularity, or time slice $\\Delta$, in a round-robin scheduler impacts performance [@problem_id:3664864]. By modeling task behavior and context-switching overhead, you will derive the optimal tuning parameter that enhances user experience while adhering to a strict efficiency budget, providing a concrete understanding of this core design tension.", "problem": "An Operating System (OS) designer is tuning preemption granularity for a round-robin scheduler to balance responsiveness and throughput, two core design goals. Consider a single Central Processing Unit (CPU) with $n$ interactive tasks. Each task alternates between CPU bursts and input/output waits. Assume CPU burst durations are independent and identically distributed with an exponential distribution of mean $\\beta$; that is, if $B$ denotes a burst duration, then $B \\sim \\text{Exp}(\\lambda)$ with $\\lambda = 1/\\beta$. A context switch incurs a fixed overhead of $\\sigma$ seconds of CPU time. The current time slice is $\\Delta$.\n\nFundamental base:\n- Throughput is defined as the fraction of CPU time devoted to useful work, modeled here as the ratio of expected useful work time per scheduling slot to the total slot time (useful work plus overhead).\n- Responsiveness for interactive tasks is modeled as the expected time a just-ready task waits until it next receives CPU time in round-robin, which equals the sum of the other $(n-1)$ tasks’ expected slot times.\n\nThe designer plans to reduce the time slice to $\\Delta' = \\Delta / r$ by a factor $r > 1$ to improve User Experience (UX). To avoid harming throughput, the designer imposes a hard budget on scheduler overhead: the fraction of time spent in context switch overhead must not exceed a target $\\alpha \\in (0,1)$. In other words, with the new time slice $\\Delta'$, the overhead fraction must be at most $\\alpha$.\n\nUsing only the above fundamental definitions and the exponential burst model, derive the largest reduction factor $r^{\\star}$ such that:\n1. Responsiveness (expected wait for a task to get CPU) strictly improves when moving from $\\Delta$ to $\\Delta' = \\Delta / r$.\n2. Throughput under $\\Delta'$ satisfies the overhead budget (overhead fraction $\\leq \\alpha$).\n\nExpress your final answer as a single closed-form analytic expression for $r^{\\star}$ in terms of $\\Delta$, $\\beta$, $\\sigma$, and $\\alpha$. If feasibility depends on parameter ranges, incorporate any necessary existence conditions into your derivation, but the final answer must be the expression for $r^{\\star}$ itself. No numerical approximation is required, and no units should be included in the final answer.", "solution": "The problem is to find the largest reduction factor $r^{\\star}$ for a scheduler's time slice, such that responsiveness improves and a constraint on scheduler overhead is met. The analysis proceeds by formalizing the given definitions for responsiveness and throughput, deriving the constraints on $r$, and solving for the maximum permissible value.\n\nFirst, we model the CPU usage within a single scheduling slot for a given time slice $\\delta$. Let $B$ be the random variable representing the CPU burst duration, with $B \\sim \\text{Exp}(\\lambda)$ where $\\lambda = 1/\\beta$. The useful work performed by a task in its slot is the minimum of its burst duration and the allotted time slice, $U(\\delta) = \\min(B, \\delta)$.\n\nThe expected useful work time, $E[U(\\delta)]$, can be calculated as follows. The probability density function (PDF) of $B$ is $f_B(t) = \\lambda e^{-\\lambda t}$ for $t \\ge 0$.\n$$ E[U(\\delta)] = E[\\min(B, \\delta)] = \\int_0^\\infty \\min(t, \\delta) f_B(t) \\,dt $$\n$$ E[U(\\delta)] = \\int_0^\\delta t (\\lambda e^{-\\lambda t}) \\,dt + \\int_\\delta^\\infty \\delta (\\lambda e^{-\\lambda t}) \\,dt $$\nIntegrating the first term by parts and evaluating the second integral yields:\n$$ E[U(\\delta)] = \\left( \\frac{1}{\\lambda}(1 - e^{-\\lambda\\delta}) - \\delta e^{-\\lambda\\delta} \\right) + \\left( \\delta e^{-\\lambda\\delta} \\right) = \\frac{1}{\\lambda}(1 - e^{-\\lambda\\delta}) $$\nSubstituting $\\lambda = 1/\\beta$, we get:\n$$ E[U(\\delta)] = \\beta(1 - e^{-\\delta/\\beta}) $$\n\nA context switch with overhead $\\sigma$ occurs at the end of each scheduling slot. The total time for a slot is the sum of the useful work time and the overhead, $S(\\delta) = U(\\delta) + \\sigma$. The expected total slot time is:\n$$ E[S(\\delta)] = E[U(\\delta)] + \\sigma = \\beta(1 - e^{-\\delta/\\beta}) + \\sigma $$\n\nNow, let's analyze the two conditions for the new time slice $\\Delta' = \\Delta/r$, where $r > 1$.\n\n**Condition 1: Responsiveness must strictly improve.**\nResponsiveness is defined as the expected wait time for a task, which is the sum of the expected slot times of the other $n-1$ tasks. Let $W(\\delta)$ be the responsiveness for a time slice $\\delta$.\n$$ W(\\delta) = (n-1)E[S(\\delta)] $$\nThe condition is $W(\\Delta') < W(\\Delta)$, which means $W(\\Delta/r) < W(\\Delta)$. Assuming there is more than one task ($n>1$), this simplifies to:\n$$ E[S(\\Delta/r)] < E[S(\\Delta)] $$\nLet's examine the function $g(\\delta) = E[S(\\delta)] = \\beta(1 - e^{-\\delta/\\beta}) + \\sigma$. Its derivative with respect to $\\delta$ is:\n$$ g'(\\delta) = \\frac{d}{d\\delta} \\left[ \\beta(1 - e^{-\\delta/\\beta}) + \\sigma \\right] = \\beta \\left(-e^{-\\delta/\\beta}\\right) \\left(-\\frac{1}{\\beta}\\right) = e^{-\\delta/\\beta} $$\nSince $\\delta > 0$ and $\\beta > 0$, $g'(\\delta)$ is always positive. Thus, $g(\\delta)$ is a strictly increasing function of $\\delta$.\nThe inequality $g(\\Delta/r) < g(\\Delta)$ is therefore satisfied if and only if $\\Delta/r < \\Delta$. Since $\\Delta > 0$, this is equivalent to $1/r < 1$, which means $r > 1$. The problem statement specifies $r>1$, so this condition is automatically satisfied by any reduction of the time slice.\n\n**Condition 2: The overhead fraction must not exceed $\\alpha$.**\nThe fraction of time spent in context switch overhead is the ratio of the expected overhead per slot to the expected total CPU time per slot. The total CPU time is the sum of useful work and overhead.\n$$ O_f(\\delta) = \\frac{E[\\text{overhead}]}{E[\\text{useful work}] + E[\\text{overhead}]} = \\frac{\\sigma}{E[U(\\delta)] + \\sigma} $$\nSubstituting the expression for $E[U(\\delta)]$:\n$$ O_f(\\delta) = \\frac{\\sigma}{\\beta(1 - e^{-\\delta/\\beta}) + \\sigma} $$\nThe condition is that for the new time slice $\\Delta' = \\Delta/r$, this overhead fraction must be at most $\\alpha$:\n$$ O_f(\\Delta/r) \\le \\alpha $$\n$$ \\frac{\\sigma}{\\beta(1 - e^{-(\\Delta/r)/\\beta}) + \\sigma} \\le \\alpha $$\nSince all terms are positive, we can rearrange the inequality:\n$$ \\sigma \\le \\alpha \\left( \\beta(1 - e^{-\\Delta/(r\\beta)}) + \\sigma \\right) $$\n$$ \\sigma(1-\\alpha) \\le \\alpha\\beta(1 - e^{-\\Delta/(r\\beta)}) $$\nGiven $\\alpha \\in (0,1)$, both $\\alpha$ and $1-\\alpha$ are positive. Also $\\beta > 0$. We can divide by $\\alpha\\beta$:\n$$ \\frac{\\sigma(1-\\alpha)}{\\alpha\\beta} \\le 1 - e^{-\\Delta/(r\\beta)} $$\nFor this inequality to be solvable for real $r$, the left side must be less than $1$, since $e^{-x} > 0$. This imposes a condition on the parameters: $\\sigma(1-\\alpha) / (\\alpha\\beta) < 1$. Assuming this holds:\n$$ e^{-\\Delta/(r\\beta)} \\le 1 - \\frac{\\sigma(1-\\alpha)}{\\alpha\\beta} $$\nThe right-hand side is positive. Taking the natural logarithm of both sides:\n$$ -\\frac{\\Delta}{r\\beta} \\le \\ln\\left(1 - \\frac{\\sigma(1-\\alpha)}{\\alpha\\beta}\\right) $$\nMultiplying by $-1$ reverses the inequality:\n$$ \\frac{\\Delta}{r\\beta} \\ge -\\ln\\left(1 - \\frac{\\sigma(1-\\alpha)}{\\alpha\\beta}\\right) = \\ln\\left(\\frac{1}{1 - \\frac{\\sigma(1-\\alpha)}{\\alpha\\beta}}\\right) = \\ln\\left(\\frac{\\alpha\\beta}{\\alpha\\beta - \\sigma(1-\\alpha)}\\right) $$\nThe argument of the logarithm is greater than $1$ since $\\sigma(1-\\alpha) > 0$, so the logarithm is positive. We can now solve for $r$:\n$$ \\frac{1}{r} \\ge \\frac{\\beta}{\\Delta} \\ln\\left(\\frac{\\alpha\\beta}{\\alpha\\beta - \\sigma(1-\\alpha)}\\right) $$\n$$ r \\le \\frac{\\Delta}{\\beta \\ln\\left(\\frac{\\alpha\\beta}{\\alpha\\beta - \\sigma(1-\\alpha)}\\right)} $$\nThis gives the upper bound for $r$. The problem asks for the largest reduction factor, $r^{\\star}$, which is this upper bound.\n$$ r^{\\star} = \\frac{\\Delta}{\\beta \\ln\\left(\\frac{\\alpha\\beta}{\\alpha\\beta - \\sigma(1-\\alpha)}\\right)} $$\nThe final expression for the largest reduction factor $r^{\\star}$ is derived solely from the overhead budget constraint, as the responsiveness constraint is satisfied by any $r>1$.", "answer": "$$\\boxed{\\frac{\\Delta}{\\beta \\ln\\left(\\frac{\\alpha\\beta}{\\alpha\\beta - \\sigma(1-\\alpha)}\\right)}}$$", "id": "3664864"}, {"introduction": "A primary goal of an operating system is to manage memory efficiently, but overloading this resource can lead to a severe performance degradation known as thrashing. This hands-on problem uses the working set model to simulate a scenario where the collective memory demand of active processes exceeds the system's capacity [@problem_id:3664899]. Your task is to identify the onset of thrashing based on a given policy and determine the minimal corrective action, illustrating a crucial mechanism for maintaining system health and throughput.", "problem": "A multiprogrammed system with Random Access Memory (RAM) of size $R$ is running $n$ processes. Under the working set model, each process $i$ has a working set $W_i(\\Delta)$ within a window of the most recent $ \\Delta $ memory references; the size of this set is $|W_i|$, measured in pages or an equivalent memory unit. Thrashing is the operating condition in which the system spends a disproportionately large fraction of time handling page faults rather than executing useful work; in practical terms, this is observed when the aggregate resident memory demanded by the active working sets cannot be satisfied by the available physical memory.\n\nStarting from these principles, derive a threshold condition, expressed as an inequality involving $R$ and $\\{|W_i|\\}_{i=1}^{n}$, that marks the onset of thrashing under the working set model in steady state, assuming that each page in a working set must be resident to maintain a low page fault frequency. Then apply this condition to the following concrete scenario and determine a minimal corrective action consistent with common operating system design goals, such as maintaining throughput while preventing thrashing:\n\n- Physical RAM: $R = 16$ GiB.\n- Number of processes: $n = 7$.\n- Working set sizes in GiB: $|W_1| = 2.5$, $|W_2| = 3.0$, $|W_3| = 4.5$, $|W_4| = 1.0$, $|W_5| = 5.5$, $|W_6| = 2.0$, $|W_7| = 1.5$.\n- The operating system employs a safety headroom policy: to reduce the risk of thrashing and to accommodate short-term fluctuations, it aims to keep a free-memory headroom fraction $\\beta$ of RAM, where $\\beta = 0.2$. That is, it targets an aggregate active working set no larger than $(1 - \\beta) R$.\n\nTasks:\n1. Using only the definitions above, derive the symbolic threshold inequality that delineates the onset of thrashing in terms of $R$ and $\\{|W_i|\\}$.\n2. For the given $R$ and $\\{|W_i|\\}$, compute the total working set demand and determine whether the system is thrashing.\n3. If the system is thrashing, determine the minimal number of processes that the operating system must suspend (choose processes to suspend so as to minimize the count) so that the sum of the remaining active working set sizes does not exceed the safety target $(1 - \\beta) R$. Break ties by suspending processes with the largest $|W_i|$ values first, consistent with minimizing the number of suspensions for a given reduction.\n4. Report only the minimal number of processes to suspend as your final answer. Do not include units. No rounding instruction is necessary for this integer result. Express intermediate memory quantities in GiB as needed, but the final answer must be a pure number.", "solution": "### 1. Symbolic Threshold Inequality\n\nThe problem states that for low page fault frequency, each page in an active process's working set must be resident in memory. The total memory demand, $D_{total}$, is the sum of the working set sizes of all $n$ active processes:\n$$\nD_{total} = \\sum_{i=1}^{n} |W_i|\n$$\nThe operating system's policy is to maintain a free-memory headroom of fraction $\\beta$, so the target memory capacity available for working sets is $R_{target} = (1 - \\beta)R$. The system enters a thrashing state, according to this policy, when the total demand exceeds this target capacity. The threshold inequality is:\n$$\n\\sum_{i=1}^{n} |W_i| > (1 - \\beta)R\n$$\n\n### 2. System State Analysis\n\nWe apply the inequality using the given values:\n- Physical RAM: $R = 16$ GiB\n- Headroom fraction: $\\beta = 0.2$\n- Working set sizes: $\\{2.5, 3.0, 4.5, 1.0, 5.5, 2.0, 1.5\\}$ GiB\n\nFirst, calculate the total working set demand, $D_{total}$:\n$$\nD_{total} = 2.5 + 3.0 + 4.5 + 1.0 + 5.5 + 2.0 + 1.5 = 20.0 \\text{ GiB}\n$$\nNext, calculate the target memory capacity, $R_{target}$:\n$$\nR_{target} = (1 - 0.2) \\times 16 \\text{ GiB} = 0.8 \\times 16 \\text{ GiB} = 12.8 \\text{ GiB}\n$$\nWe then check the thrashing condition:\n$$\nD_{total} \\stackrel{?}{>} R_{target} \\implies 20.0 \\text{ GiB} > 12.8 \\text{ GiB}\n$$\nThe condition is true. The system is in a thrashing state according to its policy and requires corrective action.\n\n### 3. Determination of Minimal Corrective Action\n\nThe system must suspend processes to reduce the total memory demand to at most $R_{target}$. The required reduction in memory demand, $\\Delta D_{req}$, is:\n$$\n\\Delta D_{req} = D_{total} - R_{target} = 20.0 \\text{ GiB} - 12.8 \\text{ GiB} = 7.2 \\text{ GiB}\n$$\nTo suspend the minimal number of processes, we should use a greedy strategy: suspend processes with the largest working set sizes first. This is the optimal approach for minimizing the count of suspended processes to achieve a target memory reduction.\n\nFirst, sort the processes in descending order of their working set sizes:\n1.  Process 5: $|W_5| = 5.5$ GiB\n2.  Process 3: $|W_3| = 4.5$ GiB\n3.  Process 2: $|W_2| = 3.0$ GiB\n4.  Process 1: $|W_1| = 2.5$ GiB\n5.  Process 6: $|W_6| = 2.0$ GiB\n6.  Process 7: $|W_7| = 1.5$ GiB\n7.  Process 4: $|W_4| = 1.0$ GiB\n\nNow, we cumulatively sum the sizes of the working sets of the processes we suspend until the total freed memory meets or exceeds the required reduction of $7.2$ GiB.\n\n-   **Suspend 1st process (Process 5):**\n    -   Total memory freed = $5.5$ GiB.\n    -   This is insufficient, as $5.5  7.2$.\n\n-   **Suspend 2nd process (Process 3):**\n    -   Total memory freed = $5.5 \\text{ GiB} + 4.5 \\text{ GiB} = 10.0$ GiB.\n    -   This is sufficient, as $10.0 \\ge 7.2$.\n\nBy suspending two processes (the ones with working set sizes $5.5$ GiB and $4.5$ GiB), the total memory demand is reduced by $10.0$ GiB. The new demand becomes $20.0 - 10.0 = 10.0$ GiB, which is safely below the target of $12.8$ GiB. Suspending only one process is not enough.\n\nTherefore, the minimal number of processes to suspend is 2.", "answer": "$$\n\\boxed{2}\n$$", "id": "3664899"}, {"introduction": "As processor core counts increase, the design of the scheduler's run queue becomes critical to system scalability. This practice contrasts two fundamental approaches: a single, shared global queue versus distributed, per-core queues [@problem_id:3664851]. By modeling the performance trade-offs—contention for the global queue versus the overhead of load balancing in the per-core design—you will determine the crossover point where one architecture outperforms the other, gaining insight into the challenges of parallel systems design.", "problem": "An Operating System (OS) designer is evaluating two scheduler run-queue designs on a symmetric multiprocessor with $n$ identical cores under a saturated workload (the ready queue is never empty). Each job has a deterministic execution time of $s$ seconds. The designer’s goal is to reason from first principles about the scalability of queueing overheads as functions of $n$ and to determine when a per-core design dominates a global-queue design in terms of expected scheduler-induced latency per job.\n\nDesign A (global run queue): A single First-In First-Out (FIFO) run queue is protected by a lock. Each dequeue operation enters a critical section of fixed duration $c$ seconds. Under saturation, each core repeatedly acquires the lock, dequeues one job, executes it for $s$ seconds, and repeats. Model the lock as a single-server queue with Markovian arrivals and Markovian service times (M/M/1), where the service rate is $1/c$ and the arrival rate equals the aggregate rate of dequeue attempts. Assume stability is maintained only when the arrival rate is strictly less than the service rate.\n\nDesign B (per-core run queues): Each core has its own private run queue with local enqueue/dequeue cost $c_{\\ell}$ per job and no lock contention in the common case. Occasional load balancing occurs via work stealing: with probability $p(n)$ per job, a core performs a stealing attempt that costs $d$ seconds. For the purpose of this model, assume $p(n) = \\kappa / n$ with a constant $\\kappa \\in (0,1)$, reflecting that, under saturation, the fraction of jobs requiring cross-core movement decreases with $n$.\n\nFor both designs, define the scheduler-induced overhead per job as the expected time spent in queueing and scheduling activities excluding the job’s own execution time $s$. Using the M/M/1 stability condition and expected time-in-system for Design A’s lock, and the given per-job local and stealing costs for Design B, derive the overhead functions of $n$ for each design. Then, for the parameter values\n- $s = 5.0 \\times 10^{-4}\\,\\mathrm{s}$,\n- $c = 2.0 \\times 10^{-6}\\,\\mathrm{s}$,\n- $c_{\\ell} = 2.0 \\times 10^{-7}\\,\\mathrm{s}$,\n- $d = 1.5 \\times 10^{-5}\\,\\mathrm{s}$,\n- $\\kappa = 0.8$,\ndetermine the smallest integer $n \\geq 1$ for which the per-core design’s expected scheduler-induced overhead per job is less than or equal to the global-queue design’s expected scheduler-induced overhead per job. If the lock in Design A would be unstable for that $n$, report the smallest $n$ that meets both the dominance and stability conditions. Provide your final answer as a single integer (number of cores). No rounding instruction is needed because an integer is required. Express any intermediate quantities in seconds using $\\mathrm{s}$.", "solution": "### Derivation of Overhead Functions\n\n**Design A: Global Run Queue Overhead, $O_A(n)$**\n\nThe scheduler-induced overhead per job, $O_A(n)$, is the total time a core spends waiting for and acquiring the lock. In the M/M/1 model, this is the expected time spent in the system, $W$.\n\nThe service rate of the lock server is $\\mu = 1/c$.\nUnder a saturated workload, each of the $n$ cores attempts to dequeue a new job immediately after finishing the previous one. A standard approximation for the aggregate arrival rate $\\lambda$ is to consider the rate at which cores would complete jobs in the absence of contention, which is $1/s$ per core. Thus, the aggregate arrival rate is $\\lambda = n/s$.\n\nThe M/M/1 queue is stable only if $\\lambda  \\mu$, which implies $n/s  1/c$, or $n  s/c$.\nFor a stable system, the expected overhead per job is:\n$$ O_A(n) = W = \\frac{1}{\\mu - \\lambda} = \\frac{1}{\\frac{1}{c} - \\frac{n}{s}} = \\frac{cs}{s - cn} $$\n\n**Design B: Per-Core Run Queue Overhead, $O_B(n)$**\n\nThe overhead for the per-core design is the sum of the constant local cost and the probabilistic work-stealing cost.\n1.  The local dequeue cost is $c_{\\ell}$ per job.\n2.  A work-stealing attempt, costing $d$, occurs with probability $p(n) = \\kappa/n$.\n\nThe expected overhead per job, $O_B(n)$, is:\n$$ O_B(n) = c_{\\ell} + p(n) \\cdot d = c_{\\ell} + \\frac{\\kappa d}{n} $$\n\n### Comparison and Calculation\n\nThe goal is to find the smallest integer $n \\ge 1$ such that $O_B(n) \\le O_A(n)$, while also satisfying the stability condition for Design A.\n\n**1. Stability Limit for Design A**\n\nUsing the given parameters: $s = 5.0 \\times 10^{-4}\\,\\mathrm{s}$ and $c = 2.0 \\times 10^{-6}\\,\\mathrm{s}$.\n$$ n  \\frac{s}{c} = \\frac{5.0 \\times 10^{-4}}{2.0 \\times 10^{-6}} = 250 $$\nDesign A is stable for $n  250$. We must search for a solution in the range $n \\in [1, 249]$.\n\n**2. Find Crossover Point**\n\nWe must solve the inequality $O_B(n) \\le O_A(n)$:\n$$ c_{\\ell} + \\frac{\\kappa d}{n} \\le \\frac{cs}{s - cn} $$\nSubstitute the given parameter values:\n- $c_{\\ell} = 2.0 \\times 10^{-7}\\,\\mathrm{s}$\n- $d = 1.5 \\times 10^{-5}\\,\\mathrm{s}$\n- $\\kappa = 0.8$\n$$ 2.0 \\times 10^{-7} + \\frac{0.8 \\cdot (1.5 \\times 10^{-5})}{n} \\le \\frac{(2.0 \\times 10^{-6})(5.0 \\times 10^{-4})}{5.0 \\times 10^{-4} - (2.0 \\times 10^{-6})n} $$\n$$ 2.0 \\times 10^{-7} + \\frac{1.2 \\times 10^{-5}}{n} \\le \\frac{1.0 \\times 10^{-9}}{5.0 \\times 10^{-4} - 2.0 \\times 10^{-6}n} $$\nWe can solve this by evaluating the two functions for integer values of $n$. For small $n$, the term $1/n$ makes $O_B(n)$ large, while $O_A(n)$ is close to $c$. As $n$ increases, $O_B(n)$ decreases while $O_A(n)$ increases due to contention. We are looking for the point where $O_B(n)$ drops below $O_A(n)$.\n\nLet's test integer values of $n$:\n-   **For $n=6$**:\n    -   $O_A(6) = \\frac{1.0 \\times 10^{-9}}{5.0 \\times 10^{-4} - 6 \\cdot (2.0 \\times 10^{-6})} = \\frac{1.0 \\times 10^{-9}}{4.88 \\times 10^{-4}} \\approx 2.049 \\times 10^{-6}\\,\\mathrm{s}$\n    -   $O_B(6) = 2.0 \\times 10^{-7} + \\frac{1.2 \\times 10^{-5}}{6} = 2.0 \\times 10^{-7} + 2.0 \\times 10^{-6} = 2.2 \\times 10^{-6}\\,\\mathrm{s}$\n    -   At $n=6$, $O_B(6) > O_A(6)$. The global queue is still more efficient.\n\n-   **For $n=7$**:\n    -   $O_A(7) = \\frac{1.0 \\times 10^{-9}}{5.0 \\times 10^{-4} - 7 \\cdot (2.0 \\times 10^{-6})} = \\frac{1.0 \\times 10^{-9}}{4.86 \\times 10^{-4}} \\approx 2.058 \\times 10^{-6}\\,\\mathrm{s}$\n    -   $O_B(7) = 2.0 \\times 10^{-7} + \\frac{1.2 \\times 10^{-5}}{7} \\approx 2.0 \\times 10^{-7} + 1.714 \\times 10^{-6} = 1.914 \\times 10^{-6}\\,\\mathrm{s}$\n    -   At $n=7$, $O_B(7)  O_A(7)$. The per-core design has become more efficient.\n\nSince the condition is not met for $n=6$ but is met for $n=7$, the smallest integer number of cores for which the per-core design's overhead is less than or equal to the global-queue's is $n=7$. This value is well within the stability limit of $n250$.", "answer": "$$\n\\boxed{7}\n$$", "id": "3664851"}]}