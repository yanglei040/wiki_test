{"hands_on_practices": [{"introduction": "The Wilkinson shift is elegantly defined from the eigenvalues of the trailing $2 \\times 2$ submatrix. However, a direct application of the quadratic formula can lead to catastrophic cancellation in finite-precision arithmetic, a critical failure point in numerical computation. This exercise [@problem_id:3283423] challenges you to not only derive the standard formula but also to analyze its numerical instability and, most importantly, to construct a robust alternative that avoids this pitfall. Mastering this technique is fundamental to writing high-quality numerical code.", "problem": "Consider the trailing $2 \\times 2$ block that determines the shift in the orthogonal-triangular (QR) algorithm with shifts:\n$$\nB \\;=\\; \\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}.\n$$\nThe Wilkinson shift is defined as the eigenvalue of $B$ that is closer (in absolute difference) to the bottom-right entry $c$. Starting only from the characteristic polynomial definition $\\det(B - \\lambda I) = 0$ and the quadratic formula, do the following:\n\n1) Derive the two eigenvalues of $B$ in terms of $a$, $b$, and $c$, and identify which branch corresponds to the eigenvalue that is closer to $c$ as a function of the sign of $d = \\tfrac{a - c}{2}$. Explain why, when $|d| \\gg |b|$ and $d > 0$, directly computing the eigenvalue closer to $c$ using a naive quadratic-formula expression exhibits catastrophic cancellation.\n\n2) By purely algebraic manipulation of the characteristic equation and identities implied by it, derive a numerically stable, closed-form expression for the eigenvalue closer to $c$ that avoids subtracting nearly equal numbers.\n\n3) Using your stable expression, evaluate the Wilkinson shift for the specific trailing block\n$$\nB \\;=\\; \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}.\n$$\nProvide your final numerical value as a decimal rounded to ten significant figures.\n\nYour final answer must be a single real number (no units).", "solution": "The user has posed a three-part problem concerning the Wilkinson shift used in the QR algorithm for finding eigenvalues of a symmetric matrix. I will first validate the problem statement and then proceed to solve it step-by-step.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   The matrix in question is a $2 \\times 2$ symmetric block: $B = \\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}$.\n-   The Wilkinson shift is defined as the eigenvalue of $B$ that is closer to $c$.\n-   A helper variable is defined: $d = \\frac{a - c}{2}$.\n-   The derivation must start from the characteristic polynomial $\\det(B - \\lambda I) = 0$ and the quadratic formula.\n-   Part 1: Derive the eigenvalues of $B$, identify the one closer to $c$ as a function of $\\operatorname{sgn}(d)$, and explain the catastrophic cancellation that occurs in the naive calculation when $|d| \\gg |b|$ and $d > 0$.\n-   Part 2: Derive a numerically stable, closed-form expression for the Wilkinson shift.\n-   Part 3: Evaluate the Wilkinson shift for the specific matrix $B = \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}$ and provide the result rounded to ten significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is a standard, fundamental topic in numerical linear algebra. The Wilkinson shift, the QR algorithm, and the analysis of numerical stability (specifically, catastrophic cancellation) are all well-established concepts. The matrix is symmetric, ensuring real eigenvalues, which is consistent with the context.\n-   **Well-Posed:** The problem is clearly stated with a sequence of logical tasks leading to a unique mathematical derivation and a specific numerical result. All necessary definitions and data are provided.\n-   **Objective:** The language is formal, precise, and free of any subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, scientifically sound problem in numerical analysis. I will now proceed with a full solution.\n\n### Part 1: Eigenvalue Derivation and Cancellation Analysis\n\nThe eigenvalues $\\lambda$ of the matrix $B$ are the roots of the characteristic polynomial, given by $\\det(B - \\lambda I) = 0$.\n$$\n\\det\\left(\\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix} - \\lambda \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\right) = \\det\\begin{pmatrix} a - \\lambda & b \\\\ b & c - \\lambda \\end{pmatrix} = 0\n$$\nExpanding the determinant gives the quadratic equation:\n$$\n(a - \\lambda)(c - \\lambda) - b^2 = 0\n$$\n$$\n\\lambda^2 - (a+c)\\lambda + (ac - b^2) = 0\n$$\nUsing the quadratic formula to solve for $\\lambda$:\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{(a+c)^2 - 4(ac - b^2)}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{a^2 + 2ac + c^2 - 4ac + 4b^2}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{a^2 - 2ac + c^2 + 4b^2}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{(a-c)^2 + 4b^2}}{2}\n$$\nIntroducing the given variable $d = \\frac{a-c}{2}$, we have $a-c = 2d$. We also note that $\\frac{a+c}{2} = \\frac{(c+2d)+c}{2} = c+d$. Substituting these into the expression for $\\lambda$:\n$$\n\\lambda = \\frac{a+c}{2} \\pm \\frac{\\sqrt{4d^2 + 4b^2}}{2} = (c+d) \\pm \\sqrt{d^2+b^2}\n$$\nThe two eigenvalues are $\\lambda_1 = c+d+\\sqrt{d^2+b^2}$ and $\\lambda_2 = c+d-\\sqrt{d^2+b^2}$.\n\nThe Wilkinson shift is the eigenvalue closer to $c$. We must compare the distances $|\\lambda_1 - c|$ and $|\\lambda_2 - c|$.\n$$\n|\\lambda_1 - c| = |d + \\sqrt{d^2+b^2}|\n$$\n$$\n|\\lambda_2 - c| = |d - \\sqrt{d^2+b^2}|\n$$\nSince $b^2 \\ge 0$, we have $\\sqrt{d^2+b^2} \\ge \\sqrt{d^2} = |d|$. The smaller distance corresponds to the expression where $d$ and $\\sqrt{d^2+b^2}$ are subtracted. This depends on the sign of $d$.\n-   If $d > 0$, then $|d - \\sqrt{d^2+b^2}| = \\sqrt{d^2+b^2}-d$ is smaller than $|d + \\sqrt{d^2+b^2}| = d+\\sqrt{d^2+b^2}$. The closer eigenvalue is $\\lambda_2$.\n-   If $d < 0$, then $|d + \\sqrt{d^2+b^2}| = \\sqrt{d^2+b^2}-|d|$ is smaller than $|d - \\sqrt{d^2+b^2}| = |d|+\\sqrt{d^2+b^2}$. The closer eigenvalue is $\\lambda_1$.\n-   If $d = 0$, both eigenvalues are equidistant from $c$. By convention (e.g., as in the original work by Wilkinson), one may choose a specific branch.\n\nWe can unify this choice using the sign function, $\\operatorname{sgn}(d)$, where we define $\\operatorname{sgn}(0)=1$. The term with the smaller magnitude is always $d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$. Thus, the Wilkinson shift, $\\mu$, is given by:\n$$\n\\mu = c + \\left(d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right)\n$$\n\nNow, consider the case where $|d| \\gg |b|$ and $d>0$. The Wilkinson shift is $\\mu = c+d-\\sqrt{d^2+b^2}$.\nIn this regime, $\\sqrt{d^2+b^2} = d\\sqrt{1+(b/d)^2}$. Using a binomial approximation, since $(b/d)^2$ is very small:\n$$\n\\sqrt{d^2+b^2} \\approx d\\left(1 + \\frac{1}{2}\\left(\\frac{b}{d}\\right)^2\\right) = d + \\frac{b^2}{2d}\n$$\nThe value of $\\sqrt{d^2+b^2}$ is very close to $d$. When the expression $\\mu = c + (d - \\sqrt{d^2+b^2})$ is evaluated in finite-precision arithmetic, the subtraction $d - \\sqrt{d^2+b^2}$ involves two nearly equal numbers. This leads to a massive loss of significant figures in the result, an effect known as catastrophic cancellation. The computed result for the shift will have very low relative accuracy.\n\n### Part 2: Derivation of a Numerically Stable Expression\n\nTo avoid the catastrophic cancellation in $d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$, we can use an algebraic manipulation based on \"rationalizing the numerator\".\nLet the term causing instability be $T = d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$. We multiply and divide by its conjugate, $d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$.\n$$\nT = \\frac{\\left(d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right) \\left(d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\n$$\nT = \\frac{d^2 - (\\operatorname{sgn}(d))^2(d^2+b^2)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\nSince $(\\operatorname{sgn}(d))^2=1$ for $d \\neq 0$:\n$$\nT = \\frac{d^2 - (d^2+b^2)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}} = \\frac{-b^2}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\nThe denominator, $d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$, involves the addition of two terms with the same sign ($d$ and $\\operatorname{sgn}(d)\\sqrt{...}$), thus avoiding cancellation.\nSubstituting this stable expression for $T$ back into the formula for the shift $\\mu = c+T$, we get the numerically stable form:\n$$\n\\mu = c - \\frac{b^2}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\n\n### Part 3: Numerical Evaluation\n\nWe are given the matrix:\n$$\nB = \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}\n$$\nThe parameters are $a = 10^8$, $b = 10^{-4}$, and $c = 10^{-8}$.\nFirst, we compute $d$.\n$$\nd = \\frac{a-c}{2} = \\frac{10^8 - 10^{-8}}{2} = 5 \\times 10^7 - 5 \\times 10^{-9}\n$$\nSince $d > 0$, $\\operatorname{sgn}(d) = 1$. The stable formula for the Wilkinson shift $\\mu$ is:\n$$\n\\mu = c - \\frac{b^2}{d + \\sqrt{d^2+b^2}}\n$$\nWe have the values:\n$c = 10^{-8}$\n$b^2 = (10^{-4})^2 = 10^{-8}$\n\nThe problem is now to evaluate $\\mu = 10^{-8} - \\frac{10^{-8}}{d + \\sqrt{d^2+10^{-8}}}$ with high precision.\nLet's compute the denominator $D = d + \\sqrt{d^2+b^2}$.\n$d = 49999999.999999995$\n$d^2 = (49999999.999999995)^2 \\approx 2.5 \\times 10^{15}$\n$b^2 = 10^{-8}$\nThe term $\\sqrt{d^2+b^2}$ is very close to $d$. Using a high-precision calculator, we find:\n$d+\\sqrt{d^2+b^2} \\approx 99999999.99999999000000001...$\nWhich is approximately $10^8 - 10^{-8}$. Let's compute the fraction:\n$$\n\\frac{b^2}{d + \\sqrt{d^2+b^2}} = \\frac{10^{-8}}{99999999.999999990...} \\approx \\frac{10^{-8}}{10^8} = 10^{-16}\n$$\nSo, a first approximation of the shift is $\\mu \\approx 10^{-8} - 10^{-16} = 0.0000000099999999$.\nTo achieve the required ten significant figures, a more precise calculation is necessary. Using a computational tool with sufficient precision (e.g., Python's `Decimal` library with a precision of 50 digits), we can evaluate the stable expression:\n$\\mu = c - \\frac{b^2}{d+\\sqrt{d^2+b^2}}$\nThis yields the value:\n$\\mu \\approx 0.000000009999999899999999...$\nIn scientific notation, this is $9.999999899999999... \\times 10^{-9}$.\n\nTo round this to ten significant figures, we examine the first eleven significant digits: $9.999999899$. The eleventh digit is $9$, which is $\\ge 5$, so we must round up the tenth digit.\nThe tenth significant digit is $9$. Rounding it up results in $0$ and a carry-over to the ninth digit.\nThe ninth significant digit is $8$. Adding the carry-over makes it $9$.\nThe rounded value to ten significant figures is $9.99999990 \\times 10^{-9}$.\nAs a decimal, this is $0.00000000999999990$.", "answer": "$$\n\\boxed{0.00000000999999990}\n$$", "id": "3283423"}, {"introduction": "With a stable method for computing the Wilkinson shift in hand, the crucial question becomes: what is the payoff? This hands-on coding practice [@problem_id:3283557] is designed to provide a definitive answer by pitting the Wilkinson shift against simpler strategies. By implementing and comparing the convergence rates on matrices with challenging clustered eigenvalues, you will empirically verify the theoretical power of this advanced shifting technique, which often delivers cubic convergence for symmetric matrices.", "problem": "Let $A \\in \\mathbb{R}^{n \\times n}$ be a real, symmetric matrix. The orthogonal-triangular (QR) factorization of a square matrix $M$ is defined by $M = Q R$ with $Q$ orthogonal and $R$ upper triangular. The shifted QR iteration for approximating eigenvalues of $A$ constructs a sequence of similar matrices via the update $A^{(k+1)} = R^{(k)} Q^{(k)} + \\mu_k I$, where $A^{(k)} - \\mu_k I = Q^{(k)} R^{(k)}$ and $I$ is the identity matrix. Because similarity transformations preserve eigenvalues, this process aims to reduce off-diagonal entries while maintaining the spectrum. Deflation occurs when the magnitude of the subdiagonal entry $|a^{(k)}_{m,m-1}|$ of the active trailing principal submatrix is sufficiently small, at which point the trailing eigenvalue is considered converged and the iteration continues on the remaining leading principal submatrix. The rate at which deflation occurs depends strongly on the choice of the shift $\\mu_k$.\n\nDesign matrices with clustered eigenvalues and compare the convergence rates, measured by the total number of QR iterations required for complete deflation, for the following three shift strategies applied to the trailing active principal submatrix of size $m$ at each step:\n- No shift: $\\mu_k = 0$.\n- Single Rayleigh shift: $\\mu_k = \\rho(e_m) = e_m^\\top A^{(k)} e_m = a^{(k)}_{m,m}$, where $e_m$ is the $m$-th standard basis vector.\n- Wilkinson’s shift: $\\mu_k$ is the eigenvalue of the trailing $2 \\times 2$ block $\\begin{bmatrix} a^{(k)}_{m-1,m-1} & a^{(k)}_{m-1,m} \\\\ a^{(k)}_{m-1,m} & a^{(k)}_{m,m} \\end{bmatrix}$ that is closer to $a^{(k)}_{m,m}$.\n\nStarting from the fundamental facts that similarity transformations preserve eigenvalues, the QR factorization exists for full rank square matrices, and for symmetric matrices real eigenvalues exist and orthogonal similarity preserves symmetry, implement the following:\n1. Construct an orthogonal matrix $Q$ deterministically for a given $n$ by taking the $Q$ factor from the QR factorization of the matrix $M$ with entries $m_{i,j} = \\sin(i+j)$ for $i,j \\in \\{1,\\dots,n\\}$.\n2. Form $A = Q \\Lambda Q^\\top$, where $\\Lambda = \\operatorname{diag}(\\lambda_1,\\dots,\\lambda_n)$ and the $\\lambda_i$ are specified to produce eigenvalue clusters.\n3. Apply the shifted QR iteration to $A$ for each of the three shift strategies. At each iteration on the active size $m$, compute $A_m - \\mu I_m = Q R$ and update $A_m \\leftarrow R Q + \\mu I_m$, where $I_m$ is the identity of size $m$. Check for deflation by testing $|a_{m,m-1}| \\le \\tau$, where $\\tau$ is a fixed tolerance. When deflation occurs, set $a_{m,m-1} = a_{m-1,m} = 0$ and reduce $m \\leftarrow m-1$. Continue until all eigenvalues have deflated or a maximum iteration count is reached. Use absolute tolerance $\\tau = 10^{-12}$ and maximum iterations $N_{\\text{max}} = 10000$.\n\nTest Suite:\n- Case $1$ ($n=8$): $\\lambda = [1.000, 1.001, 1.002, 2.000, 2.001, 3.000, 4.000, 5.000]$.\n- Case $2$ ($n=8$): $\\lambda = [1.5000, 1.5001, 1.5002, 1.5003, 2.0000, 2.0001, 3.0000, 3.00005]$.\n- Case $3$ ($n=3$): $\\lambda = [1.0000000, 1.0000001, 2.0000000]$.\n\nFor each case, report the total number of QR iterations needed for complete deflation under the three strategies, in the order: no shift, Rayleigh shift, Wilkinson’s shift. If complete deflation is not achieved within $N_{\\text{max}}$ iterations, report the total iterations actually performed.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of lists with no spaces, where each inner list corresponds to one test case and contains three integers in the order specified. For example, the output should look like $[[n_1^{\\text{none}},n_1^{\\text{rayleigh}},n_1^{\\text{wilkinson}}],[n_2^{\\text{none}},n_2^{\\text{rayleigh}},n_2^{\\text{wilkinson}}],[n_3^{\\text{none}},n_3^{\\text{rayleigh}},n_3^{\\text{wilkinson}}]]$.", "solution": "The user has provided a well-defined problem in numerical linear algebra. The task is to implement the shifted QR algorithm for finding eigenvalues of a symmetric matrix and to compare the convergence performance of three different shift strategies: no shift, Rayleigh quotient shift, and Wilkinson's shift.\n\nThe problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique, verifiable solution. It addresses a fundamental concept in scientific computing—the impact of shift strategies on the convergence rate of an iterative eigensolver. The test cases, featuring matrices with clustered eigenvalues, are designed to prominently display the theoretical differences in performance between the chosen strategies. Therefore, the problem is valid and a solution will be provided.\n\nThe solution will be developed following these principles:\n1.  **Matrix Construction**: A symmetric matrix $A \\in \\mathbb{R}^{n \\times n}$ with a predefined set of real eigenvalues $\\Lambda = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_n)$ is constructed via a similarity transformation $A = Q \\Lambda Q^\\top$. The orthogonal matrix $Q$ is generated deterministically from the QR factorization of a matrix $M$ with entries $m_{ij} = \\sin(i+j)$, ensuring reproducibility. This construction guarantees that $A$ is symmetric and its eigenvalues are precisely the specified $\\lambda_i$.\n\n2.  **Shifted QR Iteration**: The core of the algorithm is the iterative generation of a sequence of matrices $\\{A^{(k)}\\}$, starting with $A^{(0)} = A$, that are all orthogonally similar to $A$ and thus share the same eigenvalues. The sequence is designed to converge to a diagonal matrix (or a block-diagonal form from which eigenvalues can be easily extracted). The update rule for a given shift $\\mu_k$ is:\n    1.  Perform a QR factorization of the shifted matrix: $A^{(k)} - \\mu_k I = Q^{(k)} R^{(k)}$.\n    2.  Update the matrix by reversing the order of multiplication and adding back the shift: $A^{(k+1)} = R^{(k)} Q^{(k)} + \\mu_k I$.\n\n    This process constitutes a similarity transformation, as $R^{(k)} = (Q^{(k)})^\\top (A^{(k)} - \\mu_k I)$, so $A^{(k+1)} = (Q^{(k)})^\\top (A^{(k)} - \\mu_k I) Q^{(k)} + \\mu_k I = (Q^{(k)})^\\top A^{(k)} Q^{(k)}$. For a symmetric $A^{(k)}$, the resulting $A^{(k+1)}$ is also symmetric.\n\n3.  **Deflation**: The algorithm's efficiency stems from a process called deflation. For symmetric matrices, the QR iteration tends to cause the last subdiagonal element of the active matrix, $a^{(k)}_{m,m-1}$, to converge to zero. When its magnitude $|a^{(k)}_{m,m-1}|$ falls below a specified tolerance $\\tau$ (here, $\\tau=10^{-12}$), the corresponding last diagonal element $a^{(k)}_{m,m}$ is considered a converged eigenvalue. This eigenvalue is \"deflated\" from the problem by setting the subdiagonal entry to zero ($a_{m,m-1} \\leftarrow 0, a_{m-1,m} \\leftarrow 0$) and reducing the size of the active submatrix for subsequent iterations from $m$ to $m-1$. The process continues until all eigenvalues are found (i.e., $m=1$).\n\n4.  **Shift Strategies**: The convergence rate is critically dependent on the choice of the shift $\\mu_k$ at each step. We will implement and compare three strategies applied to the trailing active principal submatrix of size $m$.\n\n    *   **No Shift**: $\\mu_k = 0$. This is the unshifted QR algorithm. Its convergence is generally linear and can be prohibitively slow, especially for matrices with eigenvalues of similar magnitude or in clusters.\n\n    *   **Rayleigh Quotient Shift**: $\\mu_k = a^{(k)}_{m,m}$. This shift uses the bottom-right element of the active submatrix as the current best estimate for an eigenvalue. This strategy typically achieves quadratic convergence for well-separated eigenvalues but can perform poorly in certain cases, such as the presence of nearly identical eigenvalues.\n\n    *   **Wilkinson's Shift**: This is a more robust strategy for symmetric matrices. The shift $\\mu_k$ is chosen as one of the two eigenvalues of the trailing $2 \\times 2$ submatrix:\n        $$\n        B = \\begin{bmatrix} a^{(k)}_{m-1,m-1} & a^{(k)}_{m-1,m} \\\\ a^{(k)}_{m-1,m} & a^{(k)}_{m,m} \\end{bmatrix}\n        $$\n        Specifically, $\\mu_k$ is the eigenvalue of $B$ that is closer to $a^{(k)}_{m,m}$. Let $\\alpha = a^{(k)}_{m-1,m-1}$, $\\beta = a^{(k)}_{m-1,m}$, and $\\omega = a^{(k)}_{m,m}$. The two eigenvalues of $B$ are given by $\\lambda = \\omega + \\delta \\pm \\sqrt{\\delta^2 + \\beta^2}$, where $\\delta = (\\alpha - \\omega)/2$. The shift that is closer to $\\omega$ is found to be:\n        $$\n        \\mu_k = \\omega + \\delta - \\operatorname{sgn}(\\delta) \\sqrt{\\delta^2 + \\beta^2}\n        $$\n        where $\\operatorname{sgn}(\\delta)$ is defined as $1$ if $\\delta \\ge 0$ and $-1$ if $\\delta < 0$. This choice guarantees convergence, which is typically cubic for symmetric matrices, making it exceptionally effective even for matrices with pathologically close eigenvalues.\n\nThe implementation will apply these three strategies to a set of test matrices with clustered eigenvalues. The total number of QR updates required for complete deflation (or until a maximum iteration limit of $N_{\\text{max}} = 10000$ is reached) will be recorded for each strategy, providing a quantitative comparison of their performance.", "answer": "```python\nimport numpy as np\n\ndef run_qr_algorithm(A_orig, shift_strategy, tol, max_iter):\n    \"\"\"\n    Applies the shifted QR algorithm to find the eigenvalues of a symmetric matrix.\n\n    Args:\n        A_orig (np.ndarray): The initial symmetric matrix.\n        shift_strategy (str): The shift strategy ('none', 'rayleigh', 'wilkinson').\n        tol (float): The tolerance for deflation.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: The total number of iterations performed.\n    \"\"\"\n    A = np.copy(A_orig)\n    n = A.shape[0]\n    m = n\n    iterations = 0\n\n    while m > 1:\n        if iterations >= max_iter:\n            break\n\n        # Check for deflation: if a subdiagonal element is close to zero,\n        # reduce the size of the active submatrix.\n        # Check |a_{m, m-1}|, which in 0-based indexing is |A[m-1, m-2]|.\n        if np.abs(A[m-1, m-2]) <= tol:\n            # Explicitly set to zero as per problem description.\n            A[m-1, m-2] = 0.0\n            A[m-2, m-1] = 0.0\n            m -= 1\n            continue\n\n        # Select the shift mu based on the chosen strategy.\n        # The shift is calculated from the current active submatrix of size m.\n        mu = 0.0\n        if shift_strategy == 'rayleigh':\n            # Rayleigh quotient shift: mu = a_{m,m}\n            mu = A[m-1, m-1]\n        elif shift_strategy == 'wilkinson':\n            # Wilkinson's shift: eigenvalue of trailing 2x2 block\n            # closer to a_{m,m}.\n            if m > 1:\n                alpha = A[m-2, m-2]\n                beta = A[m-2, m-1]\n                omega = A[m-1, m-1]\n\n                delta = (alpha - omega) / 2.0\n                \n                # Use sgn(delta) = 1 for delta >= 0 as is standard.\n                sign_delta = 1.0 if delta >= 0 else -1.0\n                \n                # This form is numerically stable and gives the eigenvalue closer to omega.\n                mu = omega + delta - sign_delta * np.sqrt(delta**2 + beta**2)\n\n        # Perform one step of the shifted QR iteration on the active submatrix.\n        active_A = A[:m, :m]\n        I_m = np.identity(m)\n        \n        Q, R = np.linalg.qr(active_A - mu * I_m)\n        \n        # Update the active submatrix.\n        A[:m, :m] = R @ Q + mu * I_m\n        \n        iterations += 1\n        \n    return iterations\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, np.array([1.000, 1.001, 1.002, 2.000, 2.001, 3.000, 4.000, 5.000])),\n        (8, np.array([1.5000, 1.5001, 1.5002, 1.5003, 2.0000, 2.0001, 3.0000, 3.00005])),\n        (3, np.array([1.0000000, 1.0000001, 2.0000000]))\n    ]\n\n    tol = 1e-12\n    max_iter = 10000\n    shift_strategies = ['none', 'rayleigh', 'wilkinson']\n    \n    all_results = []\n\n    for n, lambdas in test_cases:\n        # Step 1: Construct the orthogonal matrix Q deterministically.\n        # M_ij = sin(i+j) for i,j in {1,...,n}.\n        # In 0-based indexing for numpy, this corresponds to sin((i_0+1) + (j_0+1)).\n        indices = np.arange(1, n + 1)\n        M = np.sin(indices[:, None] + indices)\n        Q, _ = np.linalg.qr(M)\n\n        # Step 2: Form the symmetric matrix A = Q * Lambda * Q^T.\n        Lambda = np.diag(lambdas)\n        A = Q @ Lambda @ Q.T\n        \n        case_results = []\n        for strategy in shift_strategies:\n            iters = run_qr_algorithm(A, strategy, tol, max_iter)\n            case_results.append(iters)\n        \n        all_results.append(case_results)\n\n    # Format the final output string as specified.\n    output_str = f\"[{','.join([f'[{c[0]},{c[1]},{c[2]}]' for c in all_results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3283557"}, {"introduction": "A major advantage of the QR algorithm for tridiagonal matrices is its low computational cost per iteration. An explicit application of a shift would destroy this structure, turning the matrix dense and negating the efficiency gains. This practice [@problem_id:3598770] guides you through the implementation of the \"implicit QR step,\" an elegant procedure that uses a sequence of Givens rotations to \"chase a bulge\" down the diagonal, applying the shift's effects while preserving the vital tridiagonal form.", "problem": "Consider a real symmetric tridiagonal matrix $A \\in \\mathbb{R}^{n \\times n}$ with diagonal entries $d_1,\\dots,d_n$ and sub/super-diagonal entries $e_1,\\dots,e_{n-1}$, so that $A$ has the form\n$$\nA=\n\\begin{bmatrix}\nd_1 & e_1 & 0 & \\cdots & 0 \\\\\ne_1 & d_2 & e_2 & \\ddots & \\vdots \\\\\n0 & e_2 & d_3 & \\ddots & 0 \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & e_{n-1} \\\\\n0 & \\cdots & 0 & e_{n-1} & d_n\n\\end{bmatrix}.\n$$\nIn the orthogonal-triangular (QR) factorization, for a given matrix $B$ one seeks an orthogonal matrix $Q$ and an upper-triangular matrix $R$ such that $B=QR$. The implicit shifted QR iteration on a symmetric tridiagonal matrix $A$ proceeds by forming $B = A - \\mu I$, performing a QR factorization $B = QR$, and updating $A$ by the orthogonal similarity $A \\gets RQ + \\mu I$. When the shift $\\mu$ is chosen based on the trailing $2 \\times 2$ principal submatrix, it is called the Wilkinson shift. The sequence of similarity transformations can be carried out implicitly and efficiently using plane rotations (Givens rotations) so that the tridiagonal structure is preserved after the bulge introduced by the shift is chased down to the bottom in $n-1$ steps.\n\nStarting from the following fundamental bases:\n- The definition of the orthogonal-triangular (QR) factorization $B=QR$, where $Q^\\top Q = I$ and $R$ is upper triangular.\n- The fact that for symmetric $A$, the QR algorithm with orthogonal similarities preserves symmetry.\n- The definition of a Givens rotation in the plane spanned by the standard basis vectors $e_k$ and $e_{k+1}$, which annihilates the second component of a $2$-vector.\n- The characterization of the Wilkinson shift as a choice of $\\mu$ equal to one eigenvalue of the trailing $2\\times 2$ principal submatrix of $A$ that is closest to the bottom-right element.\n\nYour tasks are:\n1. Derive the expression for the Wilkinson shift $\\mu$ from the trailing $2\\times 2$ principal submatrix of $A$ by appealing to the eigenvalue formula of a real symmetric $2\\times 2$ matrix and a choice that mitigates catastrophic cancellation.\n2. Explain, from first principles, how introducing the shift $\\mu$ creates a bulge when using a Givens rotation computed from the first column of $A - \\mu I$, and how a sequence of $n-1$ Givens rotations, each applied as an orthogonal similarity, chases the bulge down to restore tridiagonal form.\n3. Implement a program that, for each provided test matrix, performs one implicit shifted QR step on $A$ with the Wilkinson shift using a sequence of Givens rotations that restores tridiagonal form after $n-1$ steps. Validate correctness by also computing the explicit QR step $A_{\\mathrm{exp}} = RQ + \\mu I$ using a dense QR factorization of $A - \\mu I$, and report the Frobenius norm of the difference $\\|A_{\\mathrm{implicit}} - A_{\\mathrm{exp}}\\|_F$ for each test case.\n\nUse the following test suite of parameter values, each specified by its diagonal list $[d_1,\\dots,d_n]$ and its sub/super-diagonal list $[e_1,\\dots,e_{n-1}]$:\n- Test case $1$ (general case, $n=6$): $d=[4.0,\\,1.5,\\,3.2,\\,2.8,\\,5.5,\\,6.1]$, $e=[0.7,\\,-1.0,\\,0.5,\\,0.3,\\,-0.8]$.\n- Test case $2$ (boundary case, $n=2$): $d=[1.0,\\,2.0]$, $e=[0.5]$.\n- Test case $3$ (near-multiple trailing eigenvalues, $n=5$): $d=[1.2,\\,-0.3,\\,0.1,\\,1.0,\\,1.0000001]$, $e=[0.01,\\,0.0,\\,0.02,\\,1\\times 10^{-8}]$.\n- Test case $4$ (larger structured case, $n=10$): $d=[1.0,\\,2.0,\\,3.0,\\,4.0,\\,5.0,\\,6.0,\\,7.0,\\,8.0,\\,9.0,\\,10.0]$, $e=[0.5,\\,-0.4,\\,0.3,\\,-0.2,\\,0.1,\\,-0.05,\\,0.04,\\,-0.03,\\,0.02]$.\n- Test case $5$ (diagonal matrix edge case, $n=5$): $d=[2.0,\\,3.0,\\,5.0,\\,7.0,\\,11.0]$, $e=[0.0,\\,0.0,\\,0.0,\\,0.0]$.\n\nAngle units for any rotation computations are implicit in the trigonometric parameterization of Givens rotations and need not be reported; all internal calculations are in radians as per standard numerical linear algebra conventions. No physical units are involved.\n\nYour program must:\n- Construct $A$ from $d$ and $e$.\n- Compute the Wilkinson shift $\\mu$ using the trailing $2\\times 2$ block of $A$.\n- Perform one implicit shifted QR step using Givens rotations to chase the bulge and restore tridiagonal form after $n-1$ steps, yielding $A_{\\mathrm{implicit}}$.\n- Compute the explicit QR step via a dense QR factorization of $A - \\mu I$ to obtain $A_{\\mathrm{exp}}$.\n- For each test case, compute the Frobenius norm $\\|A_{\\mathrm{implicit}} - A_{\\mathrm{exp}}\\|_F$ as a floating-point number.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_k$ is the floating-point Frobenius norm for the $k$-th test case.", "solution": "The user-provided problem is assessed to be valid. It is a well-posed, scientifically grounded, and objective problem in the field of numerical linear algebra. It requests the derivation, explanation, and implementation of a core algorithm, the implicit QR step with Wilkinson's shift for symmetric tridiagonal matrices. All data and definitions required for the solution are provided.\n\n### 1. Derivation of the Wilkinson Shift\n\nThe Wilkinson shift, $\\mu$, is one of the two eigenvalues of the trailing $2 \\times 2$ principal submatrix of the symmetric tridiagonal matrix $A$. This submatrix, let's call it $A_{sub}$, is given by:\n$$\nA_{sub} = \n\\begin{bmatrix}\nd_{n-1} & e_{n-1} \\\\\ne_{n-1} & d_n\n\\end{bmatrix}\n$$\nThe eigenvalues $\\lambda$ of $A_{sub}$ are the roots of its characteristic polynomial, $\\det(A_{sub} - \\lambda I) = 0$.\n$$\n\\det \\begin{bmatrix}\nd_{n-1} - \\lambda & e_{n-1} \\\\\ne_{n-1} & d_n - \\lambda\n\\end{bmatrix} = 0\n$$\n$$\n(d_{n-1} - \\lambda)(d_n - \\lambda) - e_{n-1}^2 = 0\n$$\n$$\n\\lambda^2 - (d_{n-1} + d_n)\\lambda + (d_{n-1}d_n - e_{n-1}^2) = 0\n$$\nThis is a quadratic equation for $\\lambda$. Using the quadratic formula, the roots are:\n$$\n\\lambda = \\frac{(d_{n-1} + d_n) \\pm \\sqrt{(d_{n-1} + d_n)^2 - 4(d_{n-1}d_n - e_{n-1}^2)}}{2}\n$$\nSimplifying the discriminant:\n$$\n(d_{n-1}^2 + 2d_{n-1}d_n + d_n^2) - 4d_{n-1}d_n + 4e_{n-1}^2 = d_{n-1}^2 - 2d_{n-1}d_n + d_n^2 + 4e_{n-1}^2 = (d_{n-1} - d_n)^2 + (2e_{n-1})^2\n$$\nThe eigenvalues are therefore:\n$$\n\\lambda = \\frac{d_{n-1} + d_n}{2} \\pm \\frac{\\sqrt{(d_{n-1} - d_n)^2 + 4e_{n-1}^2}}{2} = \\frac{d_{n-1} + d_n}{2} \\pm \\sqrt{\\left(\\frac{d_{n-1} - d_n}{2}\\right)^2 + e_{n-1}^2}\n$$\nLet's define a helper variable $\\delta = \\frac{d_{n-1} - d_n}{2}$. The two eigenvalues are:\n$$\n\\lambda_1, \\lambda_2 = d_n + \\delta \\pm \\sqrt{\\delta^2 + e_{n-1}^2}\n$$\nThe Wilkinson shift $\\mu$ is defined as the eigenvalue that is closer to $d_n$. The distances of the eigenvalues from $d_n$ are $|\\lambda_1 - d_n| = |\\delta + \\sqrt{\\delta^2 + e_{n-1}^2}|$ and $|\\lambda_2 - d_n| = |\\delta - \\sqrt{\\delta^2 + e_{n-1}^2}|$. Since $\\sqrt{\\delta^2 + e_{n-1}^2} \\geq |\\delta|$, the term with the smaller magnitude is the one where $\\delta$ and the square root term are subtracted. This corresponds to choosing the sign opposite to the sign of $\\delta$. Thus, the shift $\\mu$ is the eigenvalue such that:\n$$\n\\mu - d_n = \\delta - \\mathrm{sign}(\\delta) \\sqrt{\\delta^2 + e_{n-1}^2}\n$$\nSo, the shift is:\n$$\n\\mu = d_n + \\delta - \\mathrm{sign}(\\delta) \\sqrt{\\delta^2 + e_{n-1}^2}\n$$\nA special case arises if $\\delta=0$, where by convention we can choose either sign. `numpy.sign(0)` is $0$, which would lead to an incorrect shift of $\\mu=d_n$. A robust implementation uses `copysign` or handles this case explicitly.\n\nA direct computation of this formula can suffer from catastrophic cancellation if $|\\delta| \\gg |e_{n-1}|$, as we would be subtracting two nearly equal large numbers. A more numerically stable formula is derived by exploiting Vieta's formulas. For a quadratic equation $x^2 - (r_1+r_2)x + r_1 r_2 = 0$, $r_1 = (r_1r_2)/r_2$. Let $x = \\lambda - d_n$. The characteristic equation becomes $x^2 - 2\\delta x - e_{n-1}^2 = 0$. The product of the roots is $(\\mu-d_n)(\\lambda_{other}-d_n) = -e_{n-1}^2$. The root we want is $\\mu-d_n$. The other root is $\\lambda_{other}-d_n = \\delta + \\mathrm{sign}(\\delta)\\sqrt{\\delta^2 + e_{n-1}^2}$. Therefore, we can write:\n$$\n\\mu - d_n = \\frac{-e_{n-1}^2}{\\lambda_{other}-d_n} = \\frac{-e_{n-1}^2}{\\delta + \\mathrm{sign}(\\delta)\\sqrt{\\delta^2 + e_{n-1}^2}}\n$$\nThis gives the final, numerically superior formula for the Wilkinson shift:\n$$\n\\mu = d_n - \\frac{e_{n-1}^2}{\\delta + \\mathrm{sign}(\\delta)\\sqrt{\\delta^2 + e_{n-1}^2}}\n$$\nThis form avoids catastrophic cancellation and is robust even when $e_{n-1}$ is small. If $e_{n-1}=0$, $\\mu=d_n$, which is correct as $d_n$ is then a decoupled eigenvalue. If $\\delta=0$, the denominator is $\\sqrt{e_{n-1}^2}=|e_{n-1}|$, so $\\mu = d_n - |e_{n-1}|$, which is one of the eigenvalues.\n\n### 2. Implicit QR Step and Bulge Chasing\n\nThe implicit shifted QR step for a symmetric tridiagonal matrix $A$ computes the similarity transformation $A_{new} = Q^T A Q$, where $A - \\mu I = QR$, without explicitly forming the matrix $Q$. The process relies on the Implicit Q Theorem, which states that if an orthogonal matrix $G$ is constructed such that $G^T A G$ is tridiagonal and the first column of $G$ is the same as the first column of $Q$, then $G$ is essentially $Q$ (up to signs of columns). The process unfolds in $n-1$ steps using Givens rotations.\n\n1.  **Shift Introduction and Initial Rotation:**\n    An explicit QR step would first form $B = A - \\mu I$. The first column of $B$ is $[d_1 - \\mu, e_1, 0, \\dots, 0]^T$. The first orthogonal matrix in the QR factorization, $Q_1$, is chosen to zero out the second element of this column vector. For the implicit step, we only need to compute the parameters of this rotation. We find a Givens rotation $G_1$ in the $(1,2)$ plane (acting on rows/columns $1$ and $2$) with parameters $(c,s)$ such that:\n    $$\n    \\begin{bmatrix} c & s \\\\ -s & c \\end{bmatrix}\n    \\begin{bmatrix} d_1 - \\mu \\\\ e_1 \\end{bmatrix} =\n    \\begin{bmatrix} * \\\\ 0 \\end{bmatrix}\n    $$\n    The matrix $G_1$ has the same first column as the full orthogonal matrix $Q$ would have.\n\n2.  **Bulge Creation:**\n    This rotation is immediately applied to $A$ as a similarity transformation: $A^{(1)} = G_1^T A G_1$. Let's analyze the fill-in. $A$ is tridiagonal, so $A_{1,3} = A_{3,1} = 0$.\n    - The left multiplication $G_1^T A$ mixes rows $1$ and $2$. The element at position $(1,3)$ of $G_1^T A$ becomes $c A_{1,3} + s A_{2,3} = c \\cdot 0 + s \\cdot e_2 = s e_2$.\n    - The subsequent right multiplication by $G_1$ mixes columns $1$ and $2$. This does not affect column $3$.\n    - Thus, the resulting matrix $A^{(1)}$ has a new non-zero entry at position $(1,3)$. By symmetry, $A^{(1)}_{3,1}$ is also non-zero. This unwanted entry outside the tridiagonal band is called a \"bulge\".\n    $$\n    A^{(1)} = G_1^T A G_1 = \\begin{bmatrix} * & * & \\mathbf{se_2} & 0 & \\cdots \\\\ * & * & * & * & \\cdots \\\\ \\mathbf{se_2} & * & * & e_3 & \\cdots \\\\ 0 & * & e_3 & d_4 & \\cdots \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix}\n    $$\n\n3.  **Bulge Chasing:**\n    The tridiagonal form must be restored. This is achieved by \"chasing\" the bulge down and out of the matrix through a sequence of $n-2$ additional Givens rotations.\n    - **Step $k=1$ (Chase 1):** The matrix $A^{(1)}$ has a bulge at $(1,3)$ (and $(3,1)$). To remove it, we design a Givens rotation $G_2$ in the $(2,3)$ plane. $G_2$ is chosen to zero out the bulge. We form $G_2$ from the elements in the first column of $A^{(1)}$, specifically the vector $(A^{(1)}_{2,1}, A^{(1)}_{3,1})^T$.\n    - We apply the similarity transformation $A^{(2)} = G_2^T A^{(1)} G_2$.\n    - The left multiplication $G_2^T A^{(1)}$ is designed to zero out $A^{(1)}_{3,1}$. The right multiplication $A^{(1)}G_2$ does not affect the first column, so $A^{(2)}_{3,1}$ remains zero. By symmetry, $A^{(2)}_{1,3}$ is also zero.\n    - However, this transformation moves the bulge. The original matrix $A$ had a non-zero $A_{3,4}=e_3$. The matrix $A^{(1)}$ still has $A^{(1)}_{3,4} = e_3$, as $G_1$ did not affect this entry. The transformation $G_2^T A^{(1)}$ mixes rows $2$ and $3$. The new entry $A^{(2)}_{2,4}$ becomes a linear combination of $A^{(1)}_{2,4}=0$ and $A^{(1)}_{3,4}=e_3$, and is thus non-zero. The bulge has been \"chased\" from $(1,3)$ to $(2,4)$.\n\n4.  **General Chase Step:**\n    This process is iterated. For $k = 1, \\dots, n-2$, we have a matrix $A^{(k)}$ with a bulge at position $(k-1, k+1)$. We construct a Givens rotation $G_{k+1}$ in the $(k,k+1)$ plane, with parameters determined by the vector $(A^{(k)}_{k, k-1}, A^{(k)}_{k+1, k-1})^T$, to annihilate the bulge at $(k+1, k-1)$. The similarity transformation $A^{(k+1)} = G_{k+1}^T A^{(k)} G_{k+1}$ eliminates this bulge but creates a new one at $(k, k+2)$.\n\n5.  **Termination:**\n    After a total of $n-1$ rotations ($G_1, \\dots, G_{n-1}$), the bulge is chased to position $(n-2, n)$ and then chased off the matrix entirely by the final rotation $G_{n-1}$ in the $(n-1, n)$ plane. The resulting matrix, $A_{new} = G_{n-1}^T \\dots G_1^T A G_1 \\dots G_{n-1}$, is tridiagonal and is orthogonally similar to the original matrix $A$. This completes one implicit QR step.\n\n### 3. Implementation\nThe implementation will follow the logic derived above.\n- A function will construct the dense matrix $A_k$ for each test case $k$.\n- The Wilkinson shift $\\mu$ will be computed using the numerically stable formula.\n- $A_{\\mathrm{implicit}}$ will be computed by initializing $A_k$ and applying the sequence of $n-1$ Givens similarity transformations, starting with the shift-induced rotation and followed by the $n-2$ bulge-chasing rotations.\n- $A_{\\mathrm{exp}}$ will be computed by forming $B = A_k - \\mu I$, finding its dense QR factorization $B=QR$ using `scipy.linalg.qr`, and then forming $A_{\\mathrm{exp}} = RQ + \\mu I.\n- The Frobenius norm of the difference, $\\|A_{\\mathrm{implicit}} - A_{\\mathrm{exp}}\\|_F$, will be computed and reported for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import qr\n\ndef solve():\n    \"\"\"\n    Solves the problem of performing one implicit shifted QR step on several\n    tridiagonal matrices and validating the result against an explicit QR step.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (general case, n=6)\n        {'d': [4.0, 1.5, 3.2, 2.8, 5.5, 6.1], 'e': [0.7, -1.0, 0.5, 0.3, -0.8]},\n        # Test case 2 (boundary case, n=2)\n        {'d': [1.0, 2.0], 'e': [0.5]},\n        # Test case 3 (near-multiple trailing eigenvalues, n=5)\n        {'d': [1.2, -0.3, 0.1, 1.0, 1.0000001], 'e': [0.01, 0.0, 0.02, 1e-8]},\n        # Test case 4 (larger structured case, n=10)\n        {'d': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0], 'e': [0.5, -0.4, 0.3, -0.2, 0.1, -0.05, 0.04, -0.03, 0.02]},\n        # Test case 5 (diagonal matrix edge case, n=5)\n        {'d': [2.0, 3.0, 5.0, 7.0, 11.0], 'e': [0.0, 0.0, 0.0, 0.0]},\n    ]\n    \n    results = []\n\n    for case in test_cases:\n        d = np.array(case['d'], dtype=float)\n        e = np.array(case['e'], dtype=float)\n        n = len(d)\n        \n        # Construct the full tridiagonal matrix A\n        A = np.diag(d) + np.diag(e, k=1) + np.diag(e, k=-1)\n\n        # Handle trivial n < 2 case, though not in tests\n        if n < 2:\n            results.append(0.0)\n            continue\n            \n        # 1. Compute Wilkinson shift mu\n        d_n = d[-1]\n        d_n_minus_1 = d[-2]\n        e_n_minus_1 = e[-1]\n\n        if e_n_minus_1 == 0.0:\n            mu = d_n\n        else:\n            delta = (d_n_minus_1 - d_n) / 2.0\n            sign_delta = np.copysign(1.0, delta) if delta != 0.0 else 1.0\n            discriminant_sqrt = np.sqrt(delta**2 + e_n_minus_1**2)\n            # Numerically stable formula for the Wilkinson shift\n            mu = d_n - (e_n_minus_1**2) / (delta + sign_delta * discriminant_sqrt)\n\n        # 2. Perform one implicit shifted QR step\n        A_implicit = A.copy()\n        \n        # Helper to apply Givens rotation as a similarity transformation\n        def apply_givens_similarity(M, c, s, k):\n            # Rotates rows k and k+1\n            row1 = M[k, :].copy()\n            row2 = M[k+1, :].copy()\n            M[k, :] = c * row1 + s * row2\n            M[k+1, :] = -s * row1 + c * row2\n            \n            # Rotates columns k and k+1\n            col1 = M[:, k].copy()\n            col2 = M[:, k+1].copy()\n            M[:, k] = c * col1 + s * col2\n            M[:, k+1] = -s * col1 + c * col2\n            \n        # Helper to compute Givens rotation parameters\n        def get_givens_params(a, b):\n            if b == 0.0:\n                return 1.0, 0.0\n            else:\n                r = np.hypot(a, b)\n                return a / r, b / r\n\n        # Introduction of the bulge\n        x = A_implicit[0, 0] - mu\n        y = A_implicit[1, 0] \n        c, s = get_givens_params(x, y)\n        apply_givens_similarity(A_implicit, c, s, 0)\n\n        # Bulge chasing\n        for k in range(n - 2):\n            # The bulge is at (k, k+2) and (k+2, k).\n            # We choose G_k+1 in plane (k+1, k+2) to zero out the bulge.\n            # The rotation is defined by column k.\n            x = A_implicit[k+1, k]\n            y = A_implicit[k+2, k]\n            \n            c, s = get_givens_params(x, y)\n            apply_givens_similarity(A_implicit, c, s, k + 1)\n            \n        # 3. Perform one explicit shifted QR step\n        A_exp = A.copy()\n        Id = np.identity(n)\n        B = A_exp - mu * Id\n        Q, R = qr(B)\n        A_exp = R @ Q + mu * Id\n\n        # 4. Compute and store the Frobenius norm of the difference\n        diff_norm = np.linalg.norm(A_implicit - A_exp, 'fro')\n        results.append(diff_norm)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```", "id": "3598770"}]}