{"hands_on_practices": [{"introduction": "This first practice establishes the fundamental link between a tensor's component representation and its intrinsic spectral properties. By deriving and calculating the principal invariants ($I_1, I_2, I_3$) directly from the tensor's components, you will verify that they correspond precisely to the elementary symmetric polynomials of the tensor's eigenvalues [@problem_id:3601958]. This exercise underscores why invariants provide a coordinate-independent pathway to understanding the principal values of stress or strain.", "problem": "A second-order real symmetric tensor in computational solid mechanics admits an orthogonal spectral decomposition and possesses three principal invariants that can be expressed in terms of the coefficients of its characteristic polynomial. Starting from the characteristic polynomial $p_{\\boldsymbol{A}}(\\lambda)=\\det(\\lambda \\boldsymbol{I}-\\boldsymbol{A})$ and the fundamental relation between its coefficients and the elementary symmetric polynomials in the eigenvalues, derive the definitions of the principal invariants $I_1$, $I_2$, and $I_3$ for a real symmetric tensor. Then, for the specific tensor\n$$\n\\boldsymbol{A}=\\begin{pmatrix}2&-1&0\\\\-1&2&0\\\\0&0&3\\end{pmatrix},\n$$\ncompute the values of $I_1$, $I_2$, and $I_3$ using tensor operations, and independently obtain the eigenvalues of $\\boldsymbol{A}$ to verify that $I_1$ equals the sum of the eigenvalues, $I_2$ equals the sum of the pairwise products of the eigenvalues, and $I_3$ equals the product of the eigenvalues. Provide your final numerical values for $(I_1,I_2,I_3)$ as a single row matrix. No rounding is required.", "solution": "The problem requires the derivation of the principal invariants of a second-order real symmetric tensor, the calculation of these invariants for a specific tensor using tensor operations, and the verification of these values using the tensor's eigenvalues. The entire process must be validated and presented with rigorous mathematical formalism.\n\nThe problem statement is valid. It is scientifically grounded in the principles of linear algebra and continuum mechanics, well-posed with all necessary information provided, and stated with objective, formal language. It is a standard problem in the study of tensor analysis.\n\nLet $\\boldsymbol{A}$ be a second-order real symmetric tensor in a $3$-dimensional Euclidean space. Its components in a given orthonormal basis are represented by a $3 \\times 3$ symmetric matrix. The eigenvalues of $\\boldsymbol{A}$, denoted by $\\lambda_1, \\lambda_2, \\lambda_3$, are the roots of the characteristic polynomial $p_{\\boldsymbol{A}}(\\lambda)$. As per the problem definition, the characteristic polynomial is $p_{\\boldsymbol{A}}(\\lambda) = \\det(\\lambda \\boldsymbol{I} - \\boldsymbol{A})$, where $\\boldsymbol{I}$ is the second-order identity tensor.\n\nLet the matrix representation of $\\boldsymbol{A}$ be\n$$\n\\boldsymbol{A} = \\begin{pmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{31} & A_{32} & A_{33} \\end{pmatrix}\n$$\nwhere $A_{ij} = A_{ji}$ due to symmetry.\n\nThe characteristic equation is $\\det(\\lambda \\boldsymbol{I} - \\boldsymbol{A}) = 0$.\n$$\n\\det\\begin{pmatrix} \\lambda - A_{11} & -A_{12} & -A_{13} \\\\ -A_{21} & \\lambda - A_{22} & -A_{23} \\\\ -A_{31} & -A_{32} & \\lambda - A_{33} \\end{pmatrix} = 0\n$$\nExpanding the determinant yields a cubic polynomial in $\\lambda$:\n$p_{\\boldsymbol{A}}(\\lambda) = \\lambda^3 - (A_{11} + A_{22} + A_{33})\\lambda^2 + \\left( (A_{11}A_{22} - A_{12}A_{21}) + (A_{22}A_{33} - A_{23}A_{32}) + (A_{33}A_{11} - A_{13}A_{31}) \\right)\\lambda - \\det(\\boldsymbol{A})$.\n\nSince $\\lambda_1, \\lambda_2, \\lambda_3$ are the roots of this polynomial, it can also be written in factored form:\n$p_{\\boldsymbol{A}}(\\lambda) = (\\lambda - \\lambda_1)(\\lambda - \\lambda_2)(\\lambda - \\lambda_3) = \\lambda^3 - (\\lambda_1 + \\lambda_2 + \\lambda_3)\\lambda^2 + (\\lambda_1\\lambda_2 + \\lambda_2\\lambda_3 + \\lambda_3\\lambda_1)\\lambda - \\lambda_1\\lambda_2\\lambda_3$.\n\nBy comparing the coefficients of the powers of $\\lambda$ in both expressions, we can define the three principal invariants ($I_1, I_2, I_3$) of the tensor $\\boldsymbol{A}$. These invariants are independent of the coordinate system chosen.\nThe first principal invariant, $I_1$, is the coefficient of $-\\lambda^2$:\n$I_1 = A_{11} + A_{22} + A_{33} = \\text{tr}(\\boldsymbol{A}) = \\lambda_1 + \\lambda_2 + \\lambda_3$.\n\nThe second principal invariant, $I_2$, is the coefficient of $\\lambda$:\n$I_2 = (A_{11}A_{22} - A_{12}^2) + (A_{22}A_{33} - A_{23}^2) + (A_{33}A_{11} - A_{13}^2) = \\lambda_1\\lambda_2 + \\lambda_2\\lambda_3 + \\lambda_3\\lambda_1$.\nThis is the sum of the principal minors of $\\boldsymbol{A}$. A more convenient expression for $I_2$ can be derived:\n$I_2 = \\frac{1}{2} [(\\text{tr}(\\boldsymbol{A}))^2 - \\text{tr}(\\boldsymbol{A}^2)]$.\n\nThe third principal invariant, $I_3$, is the negative of the constant term:\n$I_3 = \\det(\\boldsymbol{A}) = \\lambda_1\\lambda_2\\lambda_3$.\n\nNow, we apply these definitions to the specific tensor provided:\n$$\n\\boldsymbol{A}=\\begin{pmatrix}2&-1&0\\\\-1&2&0\\\\0&0&3\\end{pmatrix}\n$$\n\nFirst, we compute the invariants using tensor operations.\nThe first invariant $I_1$ is the trace of $\\boldsymbol{A}$:\n$I_1 = \\text{tr}(\\boldsymbol{A}) = 2 + 2 + 3 = 7$.\n\nTo compute the second invariant $I_2$, we first need $\\boldsymbol{A}^2$:\n$$\n\\boldsymbol{A}^2 = \\boldsymbol{A}\\boldsymbol{A} = \\begin{pmatrix}2&-1&0\\\\-1&2&0\\\\0&0&3\\end{pmatrix} \\begin{pmatrix}2&-1&0\\\\-1&2&0\\\\0&0&3\\end{pmatrix} = \\begin{pmatrix} (2)(2)+(-1)(-1) & (2)(-1)+(-1)(2) & 0 \\\\ (-1)(2)+(2)(-1) & (-1)(-1)+(2)(2) & 0 \\\\ 0 & 0 & (3)(3) \\end{pmatrix} = \\begin{pmatrix}5&-4&0\\\\-4&5&0\\\\0&0&9\\end{pmatrix}\n$$\nThe trace of $\\boldsymbol{A}^2$ is:\n$\\text{tr}(\\boldsymbol{A}^2) = 5 + 5 + 9 = 19$.\nNow, we can compute $I_2$:\n$I_2 = \\frac{1}{2}[(\\text{tr}(\\boldsymbol{A}))^2 - \\text{tr}(\\boldsymbol{A}^2)] = \\frac{1}{2}[7^2 - 19] = \\frac{1}{2}[49 - 19] = \\frac{1}{2}[30] = 15$.\n\nThe third invariant $I_3$ is the determinant of $\\boldsymbol{A}$:\n$I_3 = \\det(\\boldsymbol{A}) = \\det\\begin{pmatrix}2&-1&0\\\\-1&2&0\\\\0&0&3\\end{pmatrix}$.\nExpanding along the third row:\n$I_3 = 3 \\times \\det\\begin{pmatrix}2&-1\\\\-1&2\\end{pmatrix} = 3 \\times ((2)(2) - (-1)(-1)) = 3 \\times (4 - 1) = 3 \\times 3 = 9$.\n\nSo, from tensor operations, the invariants are $(I_1, I_2, I_3) = (7, 15, 9)$.\n\nNext, we independently compute the eigenvalues of $\\boldsymbol{A}$ by solving the characteristic equation $\\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I}) = 0$.\n$$\n\\det\\begin{pmatrix}2-\\lambda&-1&0\\\\-1&2-\\lambda&0\\\\0&0&3-\\lambda\\end{pmatrix} = 0\n$$\nExpanding along the third row:\n$(3-\\lambda) \\det\\begin{pmatrix}2-\\lambda&-1\\\\-1&2-\\lambda\\end{pmatrix} = 0$.\nThis gives one eigenvalue immediately: $\\lambda_3 = 3$.\nThe remaining eigenvalues are roots of the $2 \\times 2$ determinant:\n$(2-\\lambda)^2 - (-1)(-1) = 0$\n$(2-\\lambda)^2 - 1 = 0$\n$(2-\\lambda)^2 = 1$\n$2-\\lambda = \\pm 1$.\nThis yields two eigenvalues:\n$2 - \\lambda = 1 \\implies \\lambda_1 = 1$.\n$2 - \\lambda = -1 \\implies \\lambda_2 = 3$.\nThe set of eigenvalues of $\\boldsymbol{A}$ is $\\{\\lambda_1, \\lambda_2, \\lambda_3\\} = \\{1, 3, 3\\}$.\n\nFinally, we verify that these eigenvalues satisfy the invariant relations:\nSum of eigenvalues: $\\lambda_1 + \\lambda_2 + \\lambda_3 = 1 + 3 + 3 = 7$. This equals $I_1$.\nSum of pairwise products of eigenvalues: $\\lambda_1\\lambda_2 + \\lambda_1\\lambda_3 + \\lambda_2\\lambda_3 = (1)(3) + (1)(3) + (3)(3) = 3 + 3 + 9 = 15$. This equals $I_2$.\nProduct of eigenvalues: $\\lambda_1\\lambda_2\\lambda_3 = (1)(3)(3) = 9$. This equals $I_3$.\n\nThe verification is successful. The values of the principal invariants computed via tensor operations are consistent with the values derived from the eigenvalues. The final numerical values are $(I_1, I_2, I_3) = (7, 15, 9)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 7 & 15 & 9 \\end{pmatrix}}\n$$", "id": "3601958"}, {"introduction": "Building on the concept of principal values, this exercise guides you through the complete spectral decomposition of a symmetric tensor. You will compute the principal values and their corresponding orthogonal principal directions, which form the eigenbasis of the tensor [@problem_id:3602003]. This practice extends the theory to a practical application in solid mechanics: calculating the second invariant of the deviatoric stress, $J_2$, a key parameter in plasticity theory.", "problem": "Consider the second-order symmetric tensor (represented as a matrix in an orthonormal basis)\n$$\n\\boldsymbol{A}=\\begin{pmatrix}4&2&0\\\\2&3&0\\\\0&0&1\\end{pmatrix}.\n$$\nStarting from the definitions that principal values are the eigenvalues of a symmetric tensor, principal directions are the corresponding unit eigenvectors, and that a real symmetric tensor admits a spectral decomposition into an orthonormal eigenbasis, perform the following:\n\n1. Determine the principal values (eigenvalues) and corresponding principal directions (unit eigenvectors) of $\\boldsymbol{A}$ explicitly, and verify the mutual orthogonality of the eigenvectors.\n\n2. Construct the spectral decomposition\n$$\n\\boldsymbol{A}=\\sum_{i=1}^{3}\\lambda_{i}\\,\\boldsymbol{n}_{i}\\otimes\\boldsymbol{n}_{i},\n$$\nwhere $\\lambda_{i}$ are the principal values and $\\boldsymbol{n}_{i}$ are the associated orthonormal principal directions.\n\n3. Using the spectral representation, form the deviatoric part $\\boldsymbol{s}=\\boldsymbol{A}-\\tfrac{1}{3}\\operatorname{tr}(\\boldsymbol{A})\\boldsymbol{I}$, and compute the second invariant of the deviatoric part defined by\n$$\nJ_{2}=\\tfrac{1}{2}\\,\\boldsymbol{s}:\\boldsymbol{s}.\n$$\n\nReport $J_{2}$ as your final answer. Express the final answer as an exact value; do not round. No units are required.", "solution": "The problem is well-posed and scientifically grounded in the fields of linear algebra and continuum mechanics. All definitions and data provided are standard, self-contained, and consistent. The problem is valid and can be solved as stated.\n\nThe solution proceeds in three parts as requested by the problem statement.\n\n### 1. Principal Values and Principal Directions\n\nThe principal values (eigenvalues) $\\lambda$ of the tensor $\\boldsymbol{A}$ are the roots of the characteristic equation $\\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I}) = 0$.\n\n$$\n\\det\\begin{pmatrix}4-\\lambda & 2 & 0\\\\2 & 3-\\lambda & 0\\\\0 & 0 & 1-\\lambda\\end{pmatrix} = 0\n$$\n\nExpanding the determinant along the third row gives:\n$$\n(1-\\lambda) \\det\\begin{pmatrix}4-\\lambda & 2\\\\2 & 3-\\lambda\\end{pmatrix} = 0\n$$\n$$\n(1-\\lambda) [(4-\\lambda)(3-\\lambda) - (2)(2)] = 0\n$$\n$$\n(1-\\lambda) (\\lambda^2 - 7\\lambda + 12 - 4) = 0\n$$\n$$\n(1-\\lambda) (\\lambda^2 - 7\\lambda + 8) = 0\n$$\n\nThis equation yields three principal values. One is immediately apparent:\n$$\n\\lambda_1 = 1\n$$\nThe other two are roots of the quadratic equation $\\lambda^2 - 7\\lambda + 8 = 0$, which are found using the quadratic formula:\n$$\n\\lambda = \\frac{-(-7) \\pm \\sqrt{(-7)^2 - 4(1)(8)}}{2(1)} = \\frac{7 \\pm \\sqrt{49 - 32}}{2} = \\frac{7 \\pm \\sqrt{17}}{2}\n$$\nLet us order the principal values as:\n$$\n\\lambda_1 = 1, \\quad \\lambda_2 = \\frac{7+\\sqrt{17}}{2}, \\quad \\lambda_3 = \\frac{7-\\sqrt{17}}{2}\n$$\n\nThe principal directions $\\boldsymbol{n}_i$ are the unit eigenvectors corresponding to each eigenvalue $\\lambda_i$, found by solving $(\\boldsymbol{A} - \\lambda_i\\boldsymbol{I})\\boldsymbol{n}_i = \\boldsymbol{0}$.\n\nFor $\\lambda_1 = 1$:\n$$\n(\\boldsymbol{A} - 1\\boldsymbol{I})\\boldsymbol{n}_1 = \\begin{pmatrix}3 & 2 & 0\\\\2 & 2 & 0\\\\0 & 0 & 0\\end{pmatrix}\\begin{pmatrix}n_{11}\\\\n_{12}\\\\n_{13}\\end{pmatrix} = \\begin{pmatrix}0\\\\0\\\\0\\end{pmatrix}\n$$\nThe system of equations $3n_{11} + 2n_{12} = 0$ and $2n_{11} + 2n_{12} = 0$ implies $n_{11} = 0$ and $n_{12} = 0$. Thus, the eigenvector is of the form $(0, 0, c)$. The unit eigenvector is:\n$$\n\\boldsymbol{n}_1 = \\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}\n$$\n\nFor $\\lambda_2 = \\frac{7+\\sqrt{17}}{2}$:\nThe eigenvector $\\boldsymbol{n}_2$ must have its third component equal to zero, i.e., $n_{23}=0$, because the problem for $\\lambda_2$ is confined to the upper-left $2 \\times 2$ sub-block. We solve:\n$$\n\\left(4 - \\frac{7+\\sqrt{17}}{2}\\right)n_{21} + 2n_{22} = 0 \\implies \\left(\\frac{1-\\sqrt{17}}{2}\\right)n_{21} + 2n_{22} = 0\n$$\nAn unnormalized eigenvector $\\boldsymbol{v}_2$ can be chosen as $\\boldsymbol{v}_2 = \\begin{pmatrix}2 \\\\ \\frac{\\sqrt{17}-1}{2} \\\\ 0\\end{pmatrix}$. The squared norm is $\\|\\boldsymbol{v}_2\\|^2 = 2^2 + \\left(\\frac{\\sqrt{17}-1}{2}\\right)^2 = 4 + \\frac{17 - 2\\sqrt{17} + 1}{4} = \\frac{16 + 18 - 2\\sqrt{17}}{4} = \\frac{34 - 2\\sqrt{17}}{4} = \\frac{17-\\sqrt{17}}{2}$.\nThe unit eigenvector is $\\boldsymbol{n}_2 = \\frac{\\boldsymbol{v}_2}{\\|\\boldsymbol{v}_2\\|}$:\n$$\n\\boldsymbol{n}_2 = \\sqrt{\\frac{2}{17-\\sqrt{17}}}\\begin{pmatrix}2\\\\\\frac{\\sqrt{17}-1}{2}\\\\0\\end{pmatrix}\n$$\n\nFor $\\lambda_3 = \\frac{7-\\sqrt{17}}{2}$:\nSimilarly, $n_{33}=0$. We solve:\n$$\n\\left(4 - \\frac{7-\\sqrt{17}}{2}\\right)n_{31} + 2n_{32} = 0 \\implies \\left(\\frac{1+\\sqrt{17}}{2}\\right)n_{31} + 2n_{32} = 0\n$$\nAn unnormalized eigenvector $\\boldsymbol{v}_3$ can be chosen as $\\boldsymbol{v}_3 = \\begin{pmatrix}2 \\\\ -\\frac{1+\\sqrt{17}}{2} \\\\ 0\\end{pmatrix}$. The squared norm is $\\|\\boldsymbol{v}_3\\|^2 = 2^2 + \\left(-\\frac{1+\\sqrt{17}}{2}\\right)^2 = 4 + \\frac{1 + 2\\sqrt{17} + 17}{4} = \\frac{16 + 18 + 2\\sqrt{17}}{4} = \\frac{34 + 2\\sqrt{17}}{4} = \\frac{17+\\sqrt{17}}{2}$.\nThe unit eigenvector is $\\boldsymbol{n}_3 = \\frac{\\boldsymbol{v}_3}{\\|\\boldsymbol{v}_3\\|}$:\n$$\n\\boldsymbol{n}_3 = \\sqrt{\\frac{2}{17+\\sqrt{17}}}\\begin{pmatrix}2\\\\-\\frac{1+\\sqrt{17}}{2}\\\\0\\end{pmatrix}\n$$\n\nVerification of orthogonality:\n$$\n\\boldsymbol{n}_1 \\cdot \\boldsymbol{n}_2 = (0)(n_{21}) + (0)(n_{22}) + (1)(0) = 0\n$$\n$$\n\\boldsymbol{n}_1 \\cdot \\boldsymbol{n}_3 = (0)(n_{31}) + (0)(n_{32}) + (1)(0) = 0\n$$\n$$\n\\boldsymbol{v}_2 \\cdot \\boldsymbol{v}_3 = (2)(2) + \\left(\\frac{\\sqrt{17}-1}{2}\\right)\\left(-\\frac{\\sqrt{17}+1}{2}\\right) = 4 - \\frac{(\\sqrt{17})^2 - 1^2}{4} = 4 - \\frac{17-1}{4} = 4 - \\frac{16}{4} = 0\n$$\nSince $\\boldsymbol{v}_2 \\cdot \\boldsymbol{v}_3 = 0$, we have $\\boldsymbol{n}_2 \\cdot \\boldsymbol{n}_3 = 0$. The principal directions are mutually orthogonal.\n\n### 2. Spectral Decomposition\n\nThe spectral decomposition of a symmetric tensor $\\boldsymbol{A}$ is given by:\n$$\n\\boldsymbol{A} = \\sum_{i=1}^{3}\\lambda_{i}\\,\\boldsymbol{n}_{i}\\otimes\\boldsymbol{n}_{i}\n$$\nwhere $\\boldsymbol{n}_{i}\\otimes\\boldsymbol{n}_{i}$ are projection operators onto the principal directions. Using the principal values and directions found above:\n$$\n\\boldsymbol{A} = (1) \\boldsymbol{n}_1\\otimes\\boldsymbol{n}_1 + \\left(\\frac{7+\\sqrt{17}}{2}\\right)\\boldsymbol{n}_2\\otimes\\boldsymbol{n}_2 + \\left(\\frac{7-\\sqrt{17}}{2}\\right)\\boldsymbol{n}_3\\otimes\\boldsymbol{n}_3\n$$\nThe projection operators are explicitly:\n$$\n\\boldsymbol{n}_1 \\otimes \\boldsymbol{n}_1 = \\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}\\begin{pmatrix}0 & 0 & 1\\end{pmatrix} = \\begin{pmatrix}0 & 0 & 0\\\\0 & 0 & 0\\\\0 & 0 & 1\\end{pmatrix}\n$$\n$$\n\\boldsymbol{n}_2 \\otimes \\boldsymbol{n}_2 = \\frac{2}{17-\\sqrt{17}} \\begin{pmatrix} 4 & \\sqrt{17}-1 & 0 \\\\ \\sqrt{17}-1 & \\frac{9-\\sqrt{17}}{2} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\n$$\n\\boldsymbol{n}_3 \\otimes \\boldsymbol{n}_3 = \\frac{2}{17+\\sqrt{17}} \\begin{pmatrix} 4 & -(\\sqrt{17}+1) & 0 \\\\ -(\\sqrt{17}+1) & \\frac{9+\\sqrt{17}}{2} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\nThis constitutes the spectral decomposition of $\\boldsymbol{A}$.\n\n### 3. Deviatoric Part and its Second Invariant, $J_2$\n\nThe deviatoric part of $\\boldsymbol{A}$ is $\\boldsymbol{s}=\\boldsymbol{A}-\\tfrac{1}{3}\\operatorname{tr}(\\boldsymbol{A})\\boldsymbol{I}$.\nFirst, we find the trace of $\\boldsymbol{A}$:\n$$\n\\operatorname{tr}(\\boldsymbol{A}) = 4+3+1 = 8\n$$\nThis is also confirmed by the sum of the eigenvalues: $\\sum_{i=1}^3 \\lambda_i = 1 + \\frac{7+\\sqrt{17}}{2} + \\frac{7-\\sqrt{17}}{2} = 1 + \\frac{14}{2} = 8$.\n\nUsing the spectral representation $\\boldsymbol{A} = \\sum_i \\lambda_i \\boldsymbol{n}_i\\otimes\\boldsymbol{n}_i$ and the identity $\\boldsymbol{I} = \\sum_i \\boldsymbol{n}_i\\otimes\\boldsymbol{n}_i$:\n$$\n\\boldsymbol{s} = \\sum_{i=1}^{3}\\lambda_{i}\\,\\boldsymbol{n}_{i}\\otimes\\boldsymbol{n}_{i} - \\frac{8}{3}\\sum_{i=1}^{3}\\boldsymbol{n}_{i}\\otimes\\boldsymbol{n}_{i} = \\sum_{i=1}^{3}\\left(\\lambda_{i} - \\frac{8}{3}\\right)\\boldsymbol{n}_{i}\\otimes\\boldsymbol{n}_{i}\n$$\nThis shows that $\\boldsymbol{s}$ has the same principal directions as $\\boldsymbol{A}$, and its principal values (eigenvalues), denoted $\\lambda'_i$, are:\n$$\n\\lambda'_1 = \\lambda_1 - \\frac{8}{3} = 1 - \\frac{8}{3} = -\\frac{5}{3}\n$$\n$$\n\\lambda'_2 = \\lambda_2 - \\frac{8}{3} = \\frac{7+\\sqrt{17}}{2} - \\frac{8}{3} = \\frac{3(7+\\sqrt{17}) - 2(8)}{6} = \\frac{21+3\\sqrt{17}-16}{6} = \\frac{5+3\\sqrt{17}}{6}\n$$\n$$\n\\lambda'_3 = \\lambda_3 - \\frac{8}{3} = \\frac{7-\\sqrt{17}}{2} - \\frac{8}{3} = \\frac{3(7-\\sqrt{17}) - 2(8)}{6} = \\frac{21-3\\sqrt{17}-16}{6} = \\frac{5-3\\sqrt{17}}{6}\n$$\nThe second invariant of the deviatoric part is $J_{2}=\\tfrac{1}{2}\\boldsymbol{s}:\\boldsymbol{s}$. The double-dot product $\\boldsymbol{s}:\\boldsymbol{s}$ is the trace of $\\boldsymbol{s}^2$, which in terms of the eigenvalues of $\\boldsymbol{s}$ is $\\operatorname{tr}(\\boldsymbol{s}^2) = \\sum_{i=1}^3 (\\lambda'_i)^2$.\n$$\n\\boldsymbol{s}:\\boldsymbol{s} = (\\lambda'_1)^2 + (\\lambda'_2)^2 + (\\lambda'_3)^2\n$$\nWe compute the squares of the eigenvalues of $\\boldsymbol{s}$:\n$$\n(\\lambda'_1)^2 = \\left(-\\frac{5}{3}\\right)^2 = \\frac{25}{9}\n$$\n$$\n(\\lambda'_2)^2 = \\left(\\frac{5+3\\sqrt{17}}{6}\\right)^2 = \\frac{25 + 30\\sqrt{17} + 9(17)}{36} = \\frac{25 + 153 + 30\\sqrt{17}}{36} = \\frac{178+30\\sqrt{17}}{36}\n$$\n$$\n(\\lambda'_3)^2 = \\left(\\frac{5-3\\sqrt{17}}{6}\\right)^2 = \\frac{25 - 30\\sqrt{17} + 9(17)}{36} = \\frac{25 + 153 - 30\\sqrt{17}}{36} = \\frac{178-30\\sqrt{17}}{36}\n$$\nSumming these values:\n$$\n\\sum_{i=1}^3 (\\lambda'_i)^2 = \\frac{25}{9} + \\frac{178+30\\sqrt{17}}{36} + \\frac{178-30\\sqrt{17}}{36} = \\frac{100}{36} + \\frac{178+178}{36} = \\frac{100+356}{36} = \\frac{456}{36}\n$$\nSimplifying the fraction:\n$$\n\\frac{456}{36} = \\frac{114}{9} = \\frac{38}{3}\n$$\nFinally, we compute $J_2$:\n$$\nJ_2 = \\frac{1}{2} \\sum_{i=1}^3 (\\lambda'_i)^2 = \\frac{1}{2}\\left(\\frac{38}{3}\\right) = \\frac{19}{3}\n$$\nAlternatively, $J_2$ can be computed from the invariants of $\\boldsymbol{A}$. Let $I_1 = \\operatorname{tr}(\\boldsymbol{A}) = 8$ and $I_2 = \\frac{1}{2}[\\operatorname{tr}(\\boldsymbol{A})^2 - \\operatorname{tr}(\\boldsymbol{A}^2)]$.\nFrom the matrix components, $I_2 = (4)(3)-(2)^2 + (4)(1)-(0)^2 + (3)(1)-(0)^2 = 8+4+3=15$.\nThe relation is $J_2 = \\frac{1}{3}I_1^2 - I_2$.\n$$\nJ_2 = \\frac{1}{3}(8)^2 - 15 = \\frac{64}{3} - \\frac{45}{3} = \\frac{19}{3}\n$$\nThis confirms the result obtained from the spectral representation.", "answer": "$$\\boxed{\\frac{19}{3}}$$", "id": "3602003"}, {"introduction": "This final exercise moves from direct computation to a conceptual analysis of the stability of the spectral decomposition, a critical topic in computational mechanics. By examining a symmetric tensor with a repeated eigenvalue that is subjected to a small perturbation, you will investigate the continuity of the resulting principal values and directions [@problem_id:3601962]. This thought experiment reveals the potential for ill-conditioning and discontinuity in principal directions near degenerate states, a vital consideration for robust numerical algorithms.", "problem": "Consider a real symmetric second-order tensor (represented by a symmetric matrix) $\\boldsymbol{A} \\in \\mathbb{R}^{3 \\times 3}$ modeling a Cauchy stress state in a homogeneous solid, with two repeated principal values. Let $\\boldsymbol{A}$ be given by\n$$\n\\boldsymbol{A} = \\mathrm{diag}(1,\\,1,\\,2),\n$$\nso the in-plane principal stresses are equal. Consider a symmetric perturbation $\\boldsymbol{E}$ that introduces shear coupling in the in-plane directions,\n$$\n\\boldsymbol{E} = \\begin{bmatrix}\n0 & 1 & 0 \\\\\n1 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{bmatrix},\n$$\nand define the perturbed tensor\n$$\n\\boldsymbol{A}(\\epsilon) = \\boldsymbol{A} + \\epsilon \\boldsymbol{E},\n$$\nfor $\\epsilon \\in \\mathbb{R}$. The spectral decomposition of a real symmetric tensor provides an orthonormal basis of eigenvectors and real eigenvalues (principal values), and the min–max characterization of eigenvalues (Courant–Fischer theorem) relates each eigenvalue to extrema of the Rayleigh quotient $r(\\boldsymbol{x};\\boldsymbol{A}) = \\boldsymbol{x}^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{x}$ over subspaces.\n\nStarting from these foundational facts, analyze the eigenstructure of $\\boldsymbol{A}(\\epsilon)$ and the behavior as $\\epsilon \\to 0$. In particular:\n\n- Use the block structure of the in-plane $2 \\times 2$ submatrix to determine the principal values and principal directions of $\\boldsymbol{A}(\\epsilon)$ for small $\\epsilon$ with $\\epsilon \\neq 0$, and establish whether the principal values are continuous functions of $\\epsilon$ at $\\epsilon=0$.\n- Discuss the uniqueness and continuity of principal directions at $\\epsilon = 0$ where $\\boldsymbol{A}$ has a repeated principal value. Explain whether tracking a specific principal direction is well-conditioned or can exhibit discontinuities as $\\epsilon \\to 0$.\n\nSelect all statements that are correct:\n\nA. For the chosen perturbation, the two repeated principal values at $\\epsilon = 0$ split into $1+\\epsilon$ and $1-\\epsilon$, and these principal values depend continuously on $\\epsilon$; moreover, by sorting eigenvalues in nonincreasing order, the corresponding principal direction associated with the middle eigenvalue switches discontinuously between $(\\boldsymbol{e}_1+\\boldsymbol{e}_2)/\\sqrt{2}$ for $\\epsilon>0$ and $(\\boldsymbol{e}_1-\\boldsymbol{e}_2)/\\sqrt{2}$ for $\\epsilon<0$.\n\nB. The principal values of any real symmetric tensor field are discontinuous functions of $\\epsilon$ whenever the perturbation contains off-diagonal terms.\n\nC. For real symmetric tensors, the spectral decomposition exists only if all eigenvalues are distinct; if an eigenvalue is repeated, no orthonormal eigenbasis can be constructed.\n\nD. At $\\epsilon=0$, the eigenspace associated with the repeated eigenvalue in $\\boldsymbol{A}$ is two-dimensional; hence, eigenvector directions within that subspace are not uniquely determined, and tracking a specific eigenvector direction as a function of $\\epsilon$ can be ill-conditioned and noncontinuous at $\\epsilon=0$.\n\nE. Because $\\boldsymbol{A}(\\epsilon)$ is symmetric for all $\\epsilon$, every eigenvector component is a continuous function of $\\epsilon$, possibly after fixing a sign convention; therefore, no directional discontinuity can occur across $\\epsilon=0$.", "solution": "The user wants me to validate the problem statement and, if valid, solve the problem by analyzing the eigenstructure of the perturbed tensor $\\boldsymbol{A}(\\epsilon)$.\n\n### Step 1: Extract Givens\n- A real symmetric second-order tensor $\\boldsymbol{A} \\in \\mathbb{R}^{3 \\times 3}$.\n- $\\boldsymbol{A} = \\mathrm{diag}(1,\\,1,\\,2)$.\n- A symmetric perturbation $\\boldsymbol{E} = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$.\n- A perturbed tensor $\\boldsymbol{A}(\\epsilon) = \\boldsymbol{A} + \\epsilon \\boldsymbol{E}$ for $\\epsilon \\in \\mathbb{R}$.\n- The context is the spectral decomposition of real symmetric tensors, the Courant-Fischer theorem, and the analysis of the eigenstructure of $\\boldsymbol{A}(\\epsilon)$ as $\\epsilon \\to 0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is validated against the required criteria.\n\n- **Scientifically Grounded**: The problem is a standard exercise in the perturbation theory of linear operators, specifically for symmetric matrices with repeated eigenvalues. This is a fundamental and well-established topic in linear algebra, with direct applications in physics and engineering, including computational solid mechanics (e.g., analyzing stress tensors). All principles mentioned are standard. The problem is scientifically sound.\n- **Well-Posed**: The tensors $\\boldsymbol{A}$ and $\\boldsymbol{E}$ are given explicitly. The perturbed tensor $\\boldsymbol{A}(\\epsilon)$ is uniquely defined. The questions posed—to find the eigenvalues and eigenvectors of $\\boldsymbol{A}(\\epsilon)$ and analyze their continuity at $\\epsilon=0$—are precise mathematical tasks with a definite solution. The non-uniqueness of eigenvectors at $\\epsilon=0$ is a key feature to be investigated, not a flaw making the problem ill-posed.\n- **Objective**: The problem is stated using precise, objective mathematical language. It is free of ambiguity, subjectivity, or opinion.\n- **Flaw Check**:\n    1.  **Scientific Unsoundness**: None.\n    2.  **Non-Formalizable or Irrelevant**: The problem is perfectly formalizable within linear algebra and is relevant to the topic of spectral decomposition.\n    3.  **Incomplete or Contradictory Setup**: All necessary information is provided.\n    4.  **Unrealistic or Infeasible**: The tensors are mathematically and physically plausible representations.\n    5.  **Ill-Posed or Poorly Structured**: The problem is well-structured. The potential ill-conditioning of eigenvector tracking is the subject of the analysis.\n    6.  **Pseudo-Profound, Trivial, or Tautological**: The problem addresses a non-trivial concept (behavior near eigenvalue degeneracy) and requires careful analysis.\n    7.  **Outside Scientific Verifiability**: All claims can be verified by direct calculation.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. The solution will now be derived.\n\n### Derivation of Eigenstructure\n\nThe perturbed tensor $\\boldsymbol{A}(\\epsilon)$ is given by:\n$$\n\\boldsymbol{A}(\\epsilon) = \\boldsymbol{A} + \\epsilon \\boldsymbol{E} = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 2 \\end{bmatrix} + \\epsilon \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & \\epsilon & 0 \\\\ \\epsilon & 1 & 0 \\\\ 0 & 0 & 2 \\end{bmatrix}\n$$\nThis matrix is block-diagonal. Its eigenvalues are the eigenvalues of its diagonal blocks.\n\n1.  The bottom-right $1 \\times 1$ block is $[2]$. This gives one principal value (eigenvalue) $\\lambda_3 = 2$ for all $\\epsilon$. The corresponding principal direction (eigenvector) is $\\boldsymbol{v}_3 = [0, 0, 1]^\\top$.\n\n2.  The top-left $2 \\times 2$ block is $\\boldsymbol{A}_{12}(\\epsilon) = \\begin{bmatrix} 1 & \\epsilon \\\\ \\epsilon & 1 \\end{bmatrix}$. We find its eigenvalues by solving the characteristic equation $\\det(\\boldsymbol{A}_{12}(\\epsilon) - \\lambda \\boldsymbol{I}) = 0$:\n$$\n\\det \\begin{bmatrix} 1-\\lambda & \\epsilon \\\\ \\epsilon & 1-\\lambda \\end{bmatrix} = (1-\\lambda)^2 - \\epsilon^2 = 0\n$$\nThis yields $(1-\\lambda)^2 = \\epsilon^2$, so $1-\\lambda = \\pm \\epsilon$. The two eigenvalues are:\n$$\n\\lambda_1(\\epsilon) = 1 + \\epsilon\n$$\n$$\n\\lambda_2(\\epsilon) = 1 - \\epsilon\n$$\nThe set of three principal values of $\\boldsymbol{A}(\\epsilon)$ is $\\{1+\\epsilon, 1-\\epsilon, 2\\}$.\n\nAs $\\epsilon \\to 0$, we have $\\lambda_1(\\epsilon) \\to 1$ and $\\lambda_2(\\epsilon) \\to 1$. The eigenvalues of $\\boldsymbol{A}(0) = \\mathrm{diag}(1,1,2)$ are $\\{1, 1, 2\\}$, as expected. Since $\\lambda_1(\\epsilon)$, $\\lambda_2(\\epsilon)$, and $\\lambda_3=2$ are all elementary functions of $\\epsilon$ that are continuous everywhere, the principal values are indeed continuous functions of $\\epsilon$ at $\\epsilon=0$.\n\nNow, we find the principal directions (eigenvectors) for the $2 \\times 2$ block for $\\epsilon \\neq 0$.\n\n- For $\\lambda_1 = 1+\\epsilon$:\n$$\n(\\boldsymbol{A}_{12}(\\epsilon) - (1+\\epsilon)\\boldsymbol{I})\\boldsymbol{x} = \\begin{bmatrix} -\\epsilon & \\epsilon \\\\ \\epsilon & -\\epsilon \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n$$\nThis leads to the equation $-\\epsilon x_1 + \\epsilon x_2 = 0$, which for $\\epsilon \\neq 0$ simplifies to $x_1 = x_2$. The normalized eigenvector is $[1/\\sqrt{2}, 1/\\sqrt{2}]^\\top$. The corresponding principal direction in $\\mathbb{R}^3$ is $\\boldsymbol{v}_1 = [1/\\sqrt{2}, 1/\\sqrt{2}, 0]^\\top$.\n\n- For $\\lambda_2 = 1-\\epsilon$:\n$$\n(\\boldsymbol{A}_{12}(\\epsilon) - (1-\\epsilon)\\boldsymbol{I})\\boldsymbol{x} = \\begin{bmatrix} \\epsilon & \\epsilon \\\\ \\epsilon & \\epsilon \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n$$\nThis leads to the equation $\\epsilon x_1 + \\epsilon x_2 = 0$, which for $\\epsilon \\neq 0$ simplifies to $x_1 = -x_2$. The normalized eigenvector is $[1/\\sqrt{2}, -1/\\sqrt{2}]^\\top$. The corresponding principal direction in $\\mathbb{R}^3$ is $\\boldsymbol{v}_2 = [1/\\sqrt{2}, -1/\\sqrt{2}, 0]^\\top$.\n\n### Analysis of Continuity\n\nThe principal values are continuous. Let's analyze the principal directions. The problem with tracking principal directions arises when eigenvalues are repeated, as they are at $\\epsilon=0$. At this point, the eigenspace for $\\lambda = 1$ is the entire $xy$-plane, and any vector in this plane is an eigenvector. There is no unique principal direction.\n\nTo \"track\" a direction, we must adopt a consistent ordering rule for the eigenvalues, such as the standard non-increasing order: $\\lambda_{(1)} \\ge \\lambda_{(2)} \\ge \\lambda_{(3)}$.\n\n- **Case 1: $\\epsilon > 0$**\nThe principal values are $1+\\epsilon$, $1-\\epsilon$, and $2$.\nThe sorted order is $\\lambda_{(1)} = 2$, $\\lambda_{(2)} = 1+\\epsilon$, $\\lambda_{(3)} = 1-\\epsilon$.\nThe principal direction for the middle eigenvalue $\\lambda_{(2)}=1+\\epsilon$ is $\\boldsymbol{v}_{(2)} = [1/\\sqrt{2}, 1/\\sqrt{2}, 0]^\\top$.\n\n- **Case 2: $\\epsilon < 0$**\nThe principal values are $1+\\epsilon$, $1-\\epsilon$, and $2$. Since $\\epsilon$ is negative, $1-\\epsilon > 1+\\epsilon$.\nThe sorted order is $\\lambda_{(1)} = 2$, $\\lambda_{(2)} = 1-\\epsilon$, $\\lambda_{(3)} = 1+\\epsilon$.\nThe principal direction for the middle eigenvalue $\\lambda_{(2)}=1-\\epsilon$ is $\\boldsymbol{v}_{(2)} = [1/\\sqrt{2}, -1/\\sqrt{2}, 0]^\\top$.\n\nNow, let's examine the limit as $\\epsilon \\to 0$:\n$$\n\\lim_{\\epsilon \\to 0^+} \\boldsymbol{v}_{(2)}(\\epsilon) = [1/\\sqrt{2}, 1/\\sqrt{2}, 0]^\\top = (\\boldsymbol{e}_1+\\boldsymbol{e}_2)/\\sqrt{2}\n$$\n$$\n\\lim_{\\epsilon \\to 0^-} \\boldsymbol{v}_{(2)}(\\epsilon) = [1/\\sqrt{2}, -1/\\sqrt{2}, 0]^\\top = (\\boldsymbol{e}_1-\\boldsymbol{e}_2)/\\sqrt{2}\n$$\nThe left-hand and right-hand limits are different. Therefore, the principal direction associated with the middle eigenvalue is discontinuous at $\\epsilon=0$.\n\n### Option-by-Option Analysis\n\n**A. For the chosen perturbation, the two repeated principal values at $\\epsilon = 0$ split into $1+\\epsilon$ and $1-\\epsilon$, and these principal values depend continuously on $\\epsilon$; moreover, by sorting eigenvalues in nonincreasing order, the corresponding principal direction associated with the middle eigenvalue switches discontinuously between $(\\boldsymbol{e}_1+\\boldsymbol{e}_2)/\\sqrt{2}$ for $\\epsilon>0$ and $(\\boldsymbol{e}_1-\\boldsymbol{e}_2)/\\sqrt{2}$ for $\\epsilon<0$.**\n- The repeated principal value $1$ at $\\epsilon=0$ splits into $1+\\epsilon$ and $1-\\epsilon$. This is correct.\n- These are linear functions of $\\epsilon$ and are therefore continuous. This is correct.\n- For $\\epsilon > 0$, the middle eigenvalue is $1+\\epsilon$, whose principal direction is $(\\boldsymbol{e}_1+\\boldsymbol{e}_2)/\\sqrt{2}$. This is correct.\n- For $\\epsilon < 0$, the middle eigenvalue is $1-\\epsilon$, whose principal direction is $(\\boldsymbol{e}_1-\\boldsymbol{e}_2)/\\sqrt{2}$. This is correct.\n- As shown in the derivation, the limit of this principal direction as $\\epsilon \\to 0$ depends on the sign of $\\epsilon$, resulting in a discontinuity at $\\epsilon=0$. This is correct.\n- The entire statement is an accurate summary of the derived results.\n**Verdict: Correct**\n\n**B. The principal values of any real symmetric tensor field are discontinuous functions of $\\epsilon$ whenever the perturbation contains off-diagonal terms.**\n- This is a general statement that is demonstrably false. In this very problem, the principal values are $\\lambda(\\epsilon)=1+\\epsilon$, $\\lambda(\\epsilon)=1-\\epsilon$, and $\\lambda(\\epsilon)=2$, all of which are continuous functions of $\\epsilon$. In general, eigenvalues of a matrix whose entries depend continuously on a parameter $\\epsilon$ are themselves continuous functions of $\\epsilon$. This is a standard result of matrix analysis, as eigenvalues are roots of the characteristic polynomial, whose coefficients are continuous functions of the matrix entries.\n**Verdict: Incorrect**\n\n**C. For real symmetric tensors, the spectral decomposition exists only if all eigenvalues are distinct; if an eigenvalue is repeated, no orthonormal eigenbasis can be constructed.**\n- This contradicts the Spectral Theorem for real symmetric matrices. This theorem guarantees the existence of an orthonormal basis of eigenvectors for any real symmetric matrix, regardless of eigenvalue multiplicities. If an eigenvalue has a geometric multiplicity of $k > 1$, its eigenspace is $k$-dimensional, and one can always construct an orthonormal basis for this subspace (e.g., via the Gram-Schmidt procedure). For $\\boldsymbol{A}(0)=\\mathrm{diag}(1,1,2)$, the standard basis $\\{\\boldsymbol{e}_1, \\boldsymbol{e}_2, \\boldsymbol{e}_3\\}$ is a trivial example of such an orthonormal eigenbasis.\n**Verdict: Incorrect**\n\n**D. At $\\epsilon=0$, the eigenspace associated with the repeated eigenvalue in $\\boldsymbol{A}$ is two-dimensional; hence, eigenvector directions within that subspace are not uniquely determined, and tracking a specific eigenvector direction as a function of $\\epsilon$ can be ill-conditioned and noncontinuous at $\\epsilon=0$.**\n- At $\\epsilon=0$, $\\boldsymbol{A}(0) = \\mathrm{diag}(1,1,2)$. The repeated eigenvalue is $\\lambda=1$. The eigenspace is the solution to $(\\boldsymbol{A}(0)-\\boldsymbol{I})\\boldsymbol{x}=0$, which gives $x_3=0$. This is the $xy$-plane, a two-dimensional space. This part is correct.\n- Within this two-dimensional space, any non-zero vector is an eigenvector, so the direction is not unique. This is correct.\n- The analysis above shows that if one attempts to track an eigenvector by sorting eigenvalues, the direction is indeed noncontinuous at $\\epsilon=0$. This is a canonical example of eigenvector tracking being ill-conditioned at a point of eigenvalue degeneracy. The statement accurately describes this situation.\n**Verdict: Correct**\n\n**E. Because $\\boldsymbol{A}(\\epsilon)$ is symmetric for all $\\epsilon$, every eigenvector component is a continuous function of $\\epsilon$, possibly after fixing a sign convention; therefore, no directional discontinuity can occur across $\\epsilon=0$.**\n- The premise that $\\boldsymbol{A}(\\epsilon)$ is symmetric is true. However, the conclusion that eigenvectors must be continuous is false. While symmetry guarantees the existence of an eigenbasis for each $\\epsilon$, it does not guarantee continuity of the individual eigenvectors as $\\epsilon$ varies, especially across points of degeneracy. Our explicit calculation for option A demonstrates a discontinuity that is not a mere sign flip but a rotation by $90^\\circ$ in the $xy$-plane. The statement makes an invalid inference.\n**Verdict: Incorrect**\n\nSummary of Correct Statements: A and D.", "answer": "$$\\boxed{\\text{AD}}$$", "id": "3601962"}]}