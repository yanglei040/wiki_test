{"hands_on_practices": [{"introduction": "A core application of Chebyshev node sets is in numerical quadrature, particularly for evaluating integrals that arise in the weak formulation of differential equations. The choice between Chebyshev-Gauss and Chebyshev-Gauss-Lobatto nodes is not arbitrary; it directly impacts the degree of polynomial for which the quadrature is exact. This practice provides a hands-on calculation to demonstrate this crucial difference, showing how one rule can yield an exact result while the other produces an approximation error for the same number of nodes [@problem_id:3369345].", "problem": "Consider the tensor-product quadrature that arises when assembling modal mass terms in Discontinuous Galerkin (DG) formulations on the square domain $[-1,1] \\times [-1,1]$ using Chebyshev families. Let the weighted two-dimensional integral\n$$\nI \\;=\\; \\int_{-1}^{1} \\int_{-1}^{1} \\frac{x^{4} \\, y^{2}}{\\sqrt{1-x^{2}}\\,\\sqrt{1-y^{2}}} \\, dx \\, dy\n$$\nbe approximated by two distinct tensor-product rules constructed from one-dimensional Chebyshev nodes:\n\n- The Chebyshev Gauss tensor-product rule in each dimension, built from the roots of the Chebyshev polynomial $T_{n}$, with $n_{x} = n_{y} = 3$.\n- The Chebyshev Gauss–Lobatto tensor-product rule in each dimension, built from the extrema of $T_{n}$ including endpoints, with $n_{x} = n_{y} = 3$.\n\nUse the transformation $x = \\cos(\\theta)$ and $y = \\cos(\\phi)$ together with the induced measure to formulate and evaluate both one-dimensional rules and their two-dimensional tensor products. Then compute the difference between the two tensor-product approximations for $I$, defined as the Chebyshev Gauss–Lobatto approximation minus the Chebyshev Gauss approximation. Express angles in radians. Provide your final answer as a single closed-form analytic expression; no numerical rounding is required.", "solution": "The problem requires the evaluation of a two-dimensional weighted integral using two different tensor-product quadrature schemes based on Chebyshev polynomials, and then finding the difference between the two approximations.\n\nThe integral is given by:\n$$\nI = \\int_{-1}^{1} \\int_{-1}^{1} \\frac{x^{4} y^{2}}{\\sqrt{1-x^{2}}\\sqrt{1-y^{2}}} \\, dx \\, dy\n$$\nThis is a weighted integral of the function $f(x, y) = x^4 y^2$ with the Chebyshev weight function $w(z) = (1-z^2)^{-1/2}$. Due to the tensor-product nature of the domain, integrand, and weight function, the integral can be separated:\n$$\nI = \\left( \\int_{-1}^{1} \\frac{x^4}{\\sqrt{1-x^2}} \\, dx \\right) \\left( \\int_{-1}^{1} \\frac{y^2}{\\sqrt{1-y^2}} \\, dy \\right)\n$$\nWe use the suggested transformation $z = \\cos(\\alpha)$, for which $dz = -\\sin(\\alpha) d\\alpha$ and $\\sqrt{1-z^2} = \\sin(\\alpha)$ for $\\alpha \\in [0, \\pi]$. The integral in one dimension transforms as:\n$$\n\\int_{-1}^{1} \\frac{g(z)}{\\sqrt{1-z^2}} \\, dz = \\int_{\\pi}^{0} \\frac{g(\\cos\\alpha)}{\\sin\\alpha} (-\\sin\\alpha \\, d\\alpha) = \\int_{0}^{\\pi} g(\\cos\\alpha) \\, d\\alpha\n$$\nApplying this to our specific integrals, we get:\n$$\nI_x = \\int_{0}^{\\pi} \\cos^4(\\theta) \\, d\\theta \\quad \\text{and} \\quad I_y = \\int_{0}^{\\pi} \\cos^2(\\phi) \\, d\\phi\n$$\nThe total integral is $I = I_x I_y$. We will now approximate $I_x$ and $I_y$ using the two specified quadrature rules.\n\n**1. Chebyshev Gauss (CG) Quadrature**\nThe $n$-point Chebyshev Gauss quadrature rule is exact for polynomials of degree up to $2n-1$. For this problem, $n = 3$, so the rule is exact for polynomials up to degree $2(3)-1 = 5$.\nThe quadrature formula for the transformed integral is $\\int_{0}^{\\pi} h(\\alpha) \\, d\\alpha \\approx \\sum_{j=1}^{n} w_j h(\\alpha_j)$.\nThe nodes $\\alpha_j$ are the angular positions corresponding to the roots of $T_n(x)$, given by $\\alpha_j = \\frac{(2j-1)\\pi}{2n}$. The weights are uniform, $w_j = \\frac{\\pi}{n}$.\nFor $n=3$, the nodes are $\\alpha_1 = \\frac{\\pi}{6}$, $\\alpha_2 = \\frac{3\\pi}{6} = \\frac{\\pi}{2}$, and $\\alpha_3 = \\frac{5\\pi}{6}$. The weight is $w_j = \\frac{\\pi}{3}$.\n\nThe approximation for $I_x$, denoted $I_x^{\\text{CG}}$, is:\n$$\nI_x^{\\text{CG}} = \\frac{\\pi}{3} \\left[ \\cos^4\\left(\\frac{\\pi}{6}\\right) + \\cos^4\\left(\\frac{\\pi}{2}\\right) + \\cos^4\\left(\\frac{5\\pi}{6}\\right) \\right]\n$$\nSince $\\cos(\\pi/6) = \\sqrt{3}/2$, $\\cos(\\pi/2)=0$, and $\\cos(5\\pi/6) = -\\sqrt{3}/2$:\n$$\nI_x^{\\text{CG}} = \\frac{\\pi}{3} \\left[ \\left(\\frac{\\sqrt{3}}{2}\\right)^4 + 0^4 + \\left(-\\frac{\\sqrt{3}}{2}\\right)^4 \\right] = \\frac{\\pi}{3} \\left[ \\frac{9}{16} + 0 + \\frac{9}{16} \\right] = \\frac{\\pi}{3} \\left( \\frac{18}{16} \\right) = \\frac{3\\pi}{8}\n$$\nThe integrand $x^4$ (a polynomial of degree $4$) is integrated exactly by the $3$-point rule (degree of precision $5$).\n\nThe approximation for $I_y$, denoted $I_y^{\\text{CG}}$, is:\n$$\nI_y^{\\text{CG}} = \\frac{\\pi}{3} \\left[ \\cos^2\\left(\\frac{\\pi}{6}\\right) + \\cos^2\\left(\\frac{\\pi}{2}\\right) + \\cos^2\\left(\\frac{5\\pi}{6}\\right) \\right] = \\frac{\\pi}{3} \\left[ \\left(\\frac{\\sqrt{3}}{2}\\right)^2 + 0^2 + \\left(-\\frac{\\sqrt{3}}{2}\\right)^2 \\right] = \\frac{\\pi}{3} \\left[ \\frac{3}{4} + \\frac{3}{4} \\right] = \\frac{\\pi}{3} \\left(\\frac{3}{2}\\right) = \\frac{\\pi}{2}\n$$\nThe integrand $y^2$ (a polynomial of degree $2$) is also integrated exactly.\nThe 2D Chebyshev Gauss approximation is $I^{\\text{CG}} = I_x^{\\text{CG}} \\cdot I_y^{\\text{CG}} = \\frac{3\\pi}{8} \\cdot \\frac{\\pi}{2} = \\frac{3\\pi^2}{16}$.\n\n**2. Chebyshev Gauss–Lobatto (CGL) Quadrature**\nThe $n$-point CGL rule uses nodes at the extrema of the Chebyshev polynomial $T_{n-1}(x)$. It is exact for polynomials of degree up to $2n-3$. For $n=3$, the rule is based on the extrema of $T_2(x) = 2x^2-1$ and is exact for polynomials up to degree $2(3)-3 = 3$.\nThe nodes $\\alpha_j$ are given by $\\alpha_j = \\frac{j\\pi}{n-1}$ for $j=0, 1, \\dots, n-1$.\nFor $n=3$, the nodes are $\\alpha_0=0$, $\\alpha_1=\\frac{\\pi}{2}$, and $\\alpha_2=\\pi$.\nThe weights are $w_j = \\frac{\\pi}{n-1}$ for interior points ($j=1, \\dots, n-2$) and $w_j = \\frac{\\pi}{2(n-1)}$ for endpoints ($j=0, n-1$).\nFor $n=3$, the weights are $w_0 = \\frac{\\pi}{4}$, $w_1 = \\frac{\\pi}{2}$, and $w_2 = \\frac{\\pi}{4}$.\n\nThe approximation for $I_x$, denoted $I_x^{\\text{CGL}}$, is:\n$$\nI_x^{\\text{CGL}} = w_0 \\cos^4(\\alpha_0) + w_1 \\cos^4(\\alpha_1) + w_2 \\cos^4(\\alpha_2) = \\frac{\\pi}{4}\\cos^4(0) + \\frac{\\pi}{2}\\cos^4\\left(\\frac{\\pi}{2}\\right) + \\frac{\\pi}{4}\\cos^4(\\pi)\n$$\nSince $\\cos(0)=1$, $\\cos(\\pi/2)=0$, and $\\cos(\\pi)=-1$:\n$$\nI_x^{\\text{CGL}} = \\frac{\\pi}{4}(1)^4 + \\frac{\\pi}{2}(0)^4 + \\frac{\\pi}{4}(-1)^4 = \\frac{\\pi}{4} + 0 + \\frac{\\pi}{4} = \\frac{\\pi}{2}\n$$\nThis approximation is not exact, as the degree of the integrand ($4$) exceeds the degree of precision of the rule ($3$).\n\nThe approximation for $I_y$, denoted $I_y^{\\text{CGL}}$, is:\n$$\nI_y^{\\text{CGL}} = w_0 \\cos^2(\\alpha_0) + w_1 \\cos^2(\\alpha_1) + w_2 \\cos^2(\\alpha_2) = \\frac{\\pi}{4}\\cos^2(0) + \\frac{\\pi}{2}\\cos^2\\left(\\frac{\\pi}{2}\\right) + \\frac{\\pi}{4}\\cos^2(\\pi)\n$$\n$$\nI_y^{\\text{CGL}} = \\frac{\\pi}{4}(1)^2 + \\frac{\\pi}{2}(0)^2 + \\frac{\\pi}{4}(-1)^2 = \\frac{\\pi}{4} + 0 + \\frac{\\pi}{4} = \\frac{\\pi}{2}\n$$\nThis approximation is exact, as the degree of the integrand ($2$) is less than the degree of precision of the rule ($3$).\nThe 2D Chebyshev Gauss–Lobatto approximation is $I^{\\text{CGL}} = I_x^{\\text{CGL}} \\cdot I_y^{\\text{CGL}} = \\frac{\\pi}{2} \\cdot \\frac{\\pi}{2} = \\frac{\\pi^2}{4}$.\n\n**3. Difference between Approximations**\nThe problem asks for the difference $I^{\\text{CGL}} - I^{\\text{CG}}$.\n$$\n\\text{Difference} = \\frac{\\pi^2}{4} - \\frac{3\\pi^2}{16} = \\frac{4\\pi^2}{16} - \\frac{3\\pi^2}{16} = \\frac{\\pi^2}{16}\n$$", "answer": "$$\n\\boxed{\\frac{\\pi^2}{16}}\n$$", "id": "3369345"}, {"introduction": "To be computationally efficient, spectral and discontinuous Galerkin methods rely on a reference element approach, where all computations are mapped from a canonical domain like $[-1,1]$. This practice guides you through the fundamental mechanics of this mapping for an affine transformation [@problem_id:3369302]. By deriving the scaling laws for quadrature weights and differentiation matrices, you will see how physical element operators can be constructed from a single set of reference operators, a cornerstone of practical spectral element codes.", "problem": "Consider a one-dimensional spectral element formulation on the reference interval $[-1,1]$ with nodal Lagrange basis functions defined at either Chebyshev-Gauss nodes or Chebyshev-Gauss-Lobatto nodes. The Chebyshev-Gauss nodes are given by $\\xi_{k}=\\cos\\left(\\frac{2k-1}{2N}\\pi\\right)$ for $k=1,\\dots,N$, and the Chebyshev-Gauss-Lobatto nodes are given by $\\xi_{j}=\\cos\\left(\\frac{j}{N}\\pi\\right)$ for $j=0,\\dots,N$. Let $\\{\\hat{\\ell}_{m}(\\xi)\\}$ denote the associated nodal Lagrange basis on $[-1,1]$, and let $\\{\\hat{w}_{m}\\}$ denote any consistent reference quadrature weights on $[-1,1]$ paired with either choice of nodes so that discrete inner products are approximated by $\\sum_{m}\\hat{w}_{m} f(\\xi_{m})g(\\xi_{m})$. \n\nMap the reference element to a physical element $[a,b]$ via the affine mapping $x=\\frac{b-a}{2}\\,\\xi+\\frac{a+b}{2}$, with the Jacobian defined by $J=\\frac{b-a}{2}$. Define the physical nodal basis $\\{\\ell_{m}(x)\\}$ by pullback of the reference basis, i.e., $\\ell_{m}(x)=\\hat{\\ell}_{m}(\\xi(x))$. Using only the chain rule, the definition of the Jacobian of an affine map, and the standard discrete inner product construction in spectral and Discontinuous Galerkin (DG) methods, complete the following tasks:\n\n1. Starting from the definitions above, determine how the physical-element quadrature weights $\\{w_{m}\\}$ scale with respect to the reference weights $\\{\\hat{w}_{m}\\}$ under the affine mapping.\n\n2. Determine how the physical differentiation matrix $D_{x}$ scales with respect to the reference differentiation matrix $D_{\\xi}$ under the affine mapping, where $D_{\\xi}$ acts on nodal values of a function on $[-1,1]$ to approximate its derivative with respect to $\\xi$.\n\n3. Construct the element-level mass matrix $M_{e}$ and stiffness matrix $K_{e}$ in terms of the reference operators $(\\hat{W},D_{\\xi})$, where $\\hat{W}=\\mathrm{diag}(\\hat{w}_{m})$ is the diagonal matrix of reference quadrature weights. Your construction should use only the affine mapping and the discrete inner-product definitions appropriate for nodal spectral/DG formulations.\n\nFinally, extract and provide the multiplicative scalar $\\alpha$ such that $K_{e}=\\alpha\\,\\hat{K}$, where $\\hat{K}=D_{\\xi}^{\\top}\\hat{W}D_{\\xi}$ is the reference stiffness matrix. Express your final answer as a single closed-form analytic expression in terms of $a$ and $b$ only. No numerical approximation is required.", "solution": "The core of the problem lies in understanding how integrals and derivatives transform under an affine change of coordinates, and how these transformations manifest in the discrete operators used in spectral and Discontinuous Galerkin (DG) methods. The affine mapping from the reference element $\\xi \\in [-1, 1]$ to the physical element $x \\in [a, b]$ is given by\n$$x(\\xi) = \\frac{b-a}{2}\\xi + \\frac{a+b}{2}$$\nThe Jacobian of this transformation, $J$, is a constant representing the scaling of length elements:\n$$J = \\frac{dx}{d\\xi} = \\frac{b-a}{2}$$\nThe inverse relationship for the coordinate is $\\xi(x) = \\frac{2x - (a+b)}{b-a}$, which gives the scaling for derivatives:\n$$\\frac{d\\xi}{dx} = \\frac{2}{b-a} = \\frac{1}{J}$$\n\nWe will now address the three tasks in order.\n\n1. Scaling of Physical Quadrature Weights $\\{w_{m}\\}$\n\nThe physical-element quadrature weights $\\{w_m\\}$ are defined such that they correctly approximate the integral of a function $f(x)$ over the physical element $[a, b]$:\n$$ \\int_{a}^{b} f(x) \\, dx \\approx \\sum_{m} w_m f(x_m) $$\nwhere $x_m = x(\\xi_m)$ are the physical nodes. To find the relationship between $\\{w_m\\}$ and the reference weights $\\{\\hat{w}_m\\}$, we perform a change of variables on the integral from $x$ to $\\xi$.\n$$ \\int_{a}^{b} f(x) \\, dx = \\int_{-1}^{1} f(x(\\xi)) \\frac{dx}{d\\xi} \\, d\\xi = \\int_{-1}^{1} f(x(\\xi)) J \\, d\\xi $$\nNow, we approximate the integral on the reference element using the reference quadrature rule, which states that for a function $g(\\xi)$, $\\int_{-1}^{1} g(\\xi) \\, d\\xi \\approx \\sum_m \\hat{w}_m g(\\xi_m)$. In our case, the integrand is $g(\\xi) = f(x(\\xi)) J$. Applying the quadrature rule gives:\n$$ \\int_{-1}^{1} f(x(\\xi)) J \\, d\\xi \\approx \\sum_{m} \\hat{w}_m \\left( f(x(\\xi_m)) J \\right) $$\nSince $J$ is a constant, we can rewrite this as:\n$$ \\sum_{m} (J \\hat{w}_m) f(x_m) $$\nBy comparing this expression with the definition of the physical quadrature, $\\sum_{m} w_m f(x_m)$, we can directly identify the physical weights:\n$$ w_m = J \\hat{w}_m = \\frac{b-a}{2} \\hat{w}_m $$\nThus, the physical quadrature weights are the reference weights scaled by the Jacobian $J$.\n\n2. Scaling of the Physical Differentiation Matrix $D_{x}$\n\nThe differentiation matrices $D_{\\xi}$ and $D_{x}$ are linear operators that act on the vector of nodal function values to approximate the vector of nodal derivative values. The relationship between these matrices can be derived from the chain rule for differentiation. For any differentiable function $u$, we have:\n$$ \\frac{du}{dx} = \\frac{du}{d\\xi} \\frac{d\\xi}{dx} $$\nSubstituting the expression for $\\frac{d\\xi}{dx}$:\n$$ \\frac{du}{dx} = \\frac{du}{d\\xi} \\left( \\frac{1}{J} \\right) $$\nThis continuous relationship must hold at the discrete level. If $\\mathbf{u}$ is the vector of function values at the nodes, then the vector of derivative values with respect to $x$ at the nodes, which is given by $D_x \\mathbf{u}$, must be equal to $\\frac{1}{J}$ times the vector of derivative values with respect to $\\xi$, which is given by $D_{\\xi} \\mathbf{u}$.\n$$ D_x \\mathbf{u} = \\frac{1}{J} (D_{\\xi} \\mathbf{u}) $$\nSince this must hold for any function $u$ (and thus any nodal vector $\\mathbf{u}$), the matrix relationship is:\n$$ D_x = \\frac{1}{J} D_{\\xi} = \\frac{2}{b-a} D_{\\xi} $$\n\n3. Construction of Mass and Stiffness Matrices ($M_e$ and $K_e$)\n\nThe element mass and stiffness matrices are constructed from discrete inner products of basis functions and their derivatives.\n\nThe element-level mass matrix $M_e$ has entries $(M_e)_{ij}$ given by the inner product $(\\ell_i, \\ell_j)_{L^2([a,b])}$:\n$$ (M_e)_{ij} = \\int_{a}^{b} \\ell_i(x) \\ell_j(x) \\, dx $$\nTransforming to the reference element using $\\ell_i(x) = \\hat{\\ell}_i(\\xi(x))$ and $dx = J\\,d\\xi$:\n$$ (M_e)_{ij} = \\int_{-1}^{1} \\hat{\\ell}_i(\\xi) \\hat{\\ell}_j(\\xi) J \\, d\\xi $$\nUsing the reference quadrature rule, this integral is approximated as:\n$$ (M_e)_{ij} \\approx J \\sum_{m} \\hat{w}_m \\hat{\\ell}_i(\\xi_m) \\hat{\\ell}_j(\\xi_m) $$\nBy the definition of nodal Lagrange basis functions, $\\hat{\\ell}_i(\\xi_m) = \\delta_{im}$, where $\\delta_{im}$ is the Kronecker delta. Therefore, the product $\\hat{\\ell}_i(\\xi_m) \\hat{\\ell}_j(\\xi_m) = \\delta_{im} \\delta_{jm}$. This product is non-zero only if $m=i$ and $m=j$, which requires $i=j$. The sum collapses:\n$$ (M_e)_{ij} \\approx J \\hat{w}_i \\delta_{ij} $$\nThis shows that $M_e$ is a diagonal matrix. In matrix form, using $\\hat{W} = \\mathrm{diag}(\\hat{w}_m)$:\n$$ M_e = J \\hat{W} = \\frac{b-a}{2} \\hat{W} $$\n\nThe element-level stiffness matrix $K_e$ has entries $(K_e)_{ij}$ given by the inner product of the derivatives of the basis functions:\n$$ (K_e)_{ij} = \\int_{a}^{b} \\frac{d\\ell_i(x)}{dx} \\frac{d\\ell_j(x)}{dx} \\, dx $$\nUsing the chain rule, $\\frac{d\\ell_j}{dx} = \\frac{1}{J}\\frac{d\\hat{\\ell}_j}{d\\xi}$. Applying this and the change of integration variable:\n$$ (K_e)_{ij} = \\int_{-1}^{1} \\left( \\frac{1}{J} \\frac{d\\hat{\\ell}_i}{d\\xi} \\right) \\left( \\frac{1}{J} \\frac{d\\hat{\\ell}_j}{d\\xi} \\right) (J \\, d\\xi) = \\frac{1}{J} \\int_{-1}^{1} \\frac{d\\hat{\\ell}_i}{d\\xi} \\frac{d\\hat{\\ell}_j}{d\\xi} \\, d\\xi $$\nApproximating the integral with the reference quadrature rule:\n$$ (K_e)_{ij} \\approx \\frac{1}{J} \\sum_{m} \\hat{w}_m \\left( \\frac{d\\hat{\\ell}_i}{d\\xi} \\Big|_{\\xi=\\xi_m} \\right) \\left( \\frac{d\\hat{\\ell}_j}{d\\xi} \\Big|_{\\xi=\\xi_m} \\right) $$\nThe term $\\frac{d\\hat{\\ell}_j}{d\\xi} |_{\\xi=\\xi_m}$ is the $(m,j)$-th entry of the reference differentiation matrix, $(D_{\\xi})_{mj}$. Therefore, we can write the sum in matrix notation:\n$$ (K_e)_{ij} \\approx \\frac{1}{J} \\sum_{m} (D_{\\xi})_{mi} \\hat{w}_m (D_{\\xi})_{mj} $$\nRecognizing that $\\hat{W} = \\mathrm{diag}(\\hat{w}_m)$, this sum is the $(i,j)$-th entry of the matrix product $D_{\\xi}^{\\top} \\hat{W} D_{\\xi}$.\n$$ (K_e)_{ij} \\approx \\frac{1}{J} (D_{\\xi}^{\\top} \\hat{W} D_{\\xi})_{ij} $$\nThus, the matrix $K_e$ is related to the reference stiffness matrix $\\hat{K} = D_{\\xi}^{\\top} \\hat{W} D_{\\xi}$ as:\n$$ K_e = \\frac{1}{J} \\hat{K} $$\n\nFinally, we are asked to find the multiplicative scalar $\\alpha$ such that $K_e = \\alpha \\hat{K}$. From our derived relationship, we immediately see that:\n$$ \\alpha = \\frac{1}{J} $$\nSubstituting the definition of the Jacobian $J = \\frac{b-a}{2}$:\n$$ \\alpha = \\frac{1}{\\frac{b-a}{2}} = \\frac{2}{b-a} $$\nThis is the required closed-form expression in terms of $a$ and $b$.", "answer": "$$\\boxed{\\frac{2}{b-a}}$$", "id": "3369302"}, {"introduction": "Chebyshev-based methods are renowned for their exponential convergence rates when approximating analytic functions, a property stemming from the optimal clustering of nodes near the endpoints. This exercise provides a crucial counterexample to explore what happens when this smoothness condition is violated, specifically for a function with an algebraic endpoint singularity [@problem_id:3369358]. By analyzing the decay of Chebyshev coefficients, you will derive the resulting algebraic convergence rate and understand why, despite their optimal distribution, the nodes cannot overcome the fundamental smoothness limitations of the function itself.", "problem": "Consider the function $f:[-1,1]\\to\\mathbb{R}$ defined by $f(x)=(1-x)^{\\beta}$ with a fixed exponent $\\beta\\in(0,1)$. Let $T_{n}(x)$ denote the $n$-th Chebyshev polynomial of the first kind, and recall the identity $T_{n}(\\cos\\theta)=\\cos(n\\theta)$ for all $\\theta\\in\\mathbb{R}$. Define the Chebyshev coefficients $\\{a_{n}\\}_{n\\geq 0}$ of $f$ by the standard cosine representation\n$$\na_{n}=\\frac{2}{\\pi}\\int_{0}^{\\pi}f(\\cos\\theta)\\cos(n\\theta)\\,d\\theta,\\quad n\\geq 0,\n$$\nand consider polynomial interpolation of $f$ of degree $N$ on the two canonical clustered node sets on $[-1,1]$:\n- the Chebyshev–Gauss nodes $x_{j}^{\\mathrm{G}}=\\cos\\left(\\frac{(2j+1)\\pi}{2(N+1)}\\right)$ for $j=0,\\dots,N$ (zeros of $T_{N+1}$), and\n- the Chebyshev–Gauss–Lobatto nodes $x_{j}^{\\mathrm{L}}=\\cos\\left(\\frac{j\\pi}{N}\\right)$ for $j=0,\\dots,N$ (zeros of $(1-x^{2})T_{N}'$ including endpoints).\n\nLet $p_{N}^{\\mathrm{G}}$ and $p_{N}^{\\mathrm{L}}$ denote the respective degree-$N$ interpolants of $f$ at these nodes. Starting only from the above definitions, the identity $T_{n}(\\cos\\theta)=\\cos(n\\theta)$, standard asymptotic expansions of smooth functions, and well-tested integral transforms for oscillatory integrals, derive the large-$N$ algebraic convergence rate exponent $p(\\beta)$ such that\n$$\n\\|f-p_{N}^{\\mathrm{G}}\\|_{L^{\\infty}([-1,1])}=\\Theta(N^{-p(\\beta)})\\quad\\text{and}\\quad \\|f-p_{N}^{\\mathrm{L}}\\|_{L^{\\infty}([-1,1])}=\\Theta(N^{-p(\\beta)}),\n$$\nwhere the notation $\\Theta(\\cdot)$ is in the precise sense of two-sided bounds up to $\\beta$-dependent positive constants independent of $N$. Your derivation must explicitly demonstrate that the endpoint singularity at $x=1$ forces algebraic (rather than exponential) convergence by quantifying the decay of $\\{a_{n}\\}$ and propagating this decay to the interpolation error for both node families. Conclude with the analytic expression for $p(\\beta)$, and state whether the clustering difference between Chebyshev–Gauss and Chebyshev–Gauss–Lobatto nodes changes this exponent.\n\nYour final answer must be the closed-form analytic expression for $p(\\beta)$ only. No numerical rounding is required.", "solution": "The objective is to derive the algebraic convergence rate exponent $p(\\beta)$ for the Chebyshev interpolation of the function $f(x) = (1-x)^\\beta$ on $[-1,1]$ for $\\beta \\in (0,1)$. The derivation must proceed by first finding the asymptotic decay rate of the Chebyshev coefficients of $f$ and then using this to determine the error of the degree-$N$ interpolants $p_N^{\\mathrm{G}}$ and $p_N^{\\mathrm{L}}$.\n\nFirst, we analyze the Chebyshev coefficients $\\{a_n\\}_{n\\geq 0}$ of $f(x)$. The problem provides the definition\n$$\na_n = \\frac{2}{\\pi} \\int_0^\\pi f(\\cos\\theta) \\cos(n\\theta) d\\theta, \\quad n \\ge 0.\n$$\nSubstituting $f(x)=(1-x)^\\beta$, we have $f(\\cos\\theta) = (1-\\cos\\theta)^\\beta$. The integral becomes\n$$\na_n = \\frac{2}{\\pi} \\int_0^\\pi (1-\\cos\\theta)^\\beta \\cos(n\\theta) d\\theta.\n$$\nThe convergence rate of the sequence $\\{a_n\\}$ as $n \\to \\infty$ is determined by the smoothness of the function $g(\\theta) = (1-\\cos\\theta)^\\beta$ on the interval $[0, \\pi]$. The function $g(\\theta)$ is analytic for $\\theta \\in (0, \\pi]$. However, at $\\theta=0$ (which corresponds to the point $x=1$), the function has a singularity, since $\\beta$ is not an integer. We analyze the behavior near $\\theta=0$ using the Taylor expansion of $\\cos\\theta$:\n$$\n1-\\cos\\theta = 1 - \\left(1 - \\frac{\\theta^2}{2!} + \\frac{\\theta^4}{4!} - \\dots\\right) = \\frac{\\theta^2}{2} - \\frac{\\theta^4}{24} + \\mathcal{O}(\\theta^6).\n$$\nFor small $\\theta$, we have $(1-\\cos\\theta)^\\beta \\approx \\left(\\frac{\\theta^2}{2}\\right)^\\beta = 2^{-\\beta}\\theta^{2\\beta}$.\nThe asymptotic behavior of an oscillatory integral like the one for $a_n$ is dominated by the contributions from the points of non-analyticity of the non-oscillatory part of the integrand. In this case, the only such point in $[0,\\pi]$ is the endpoint $\\theta=0$. The contribution from the smooth endpoint $\\theta=\\pi$ is negligible, as it decays faster than any inverse power of $n$.\n\nThe asymptotic behavior of the $n$-th Fourier cosine coefficient of a function with an algebraic singularity of the form $|\\theta|^\\alpha$ at $\\theta=0$ is of order $\\mathcal{O}(n^{-(\\alpha+1)})$ for $\\alpha > -1$. Here, the function $g(\\theta)$ behaves as $\\theta^{2\\beta}$, so $\\alpha=2\\beta$. Thus, we expect $|a_n| = \\Theta(n^{-(2\\beta+1)})$.\n\nTo demonstrate this more rigorously, we can use the method of stationary phase, or more accurately, an application of Watson's Lemma for Fourier integrals. We approximate the integral by its behavior near the singularity:\n$$\na_n \\approx \\frac{2}{\\pi} \\int_0^\\epsilon 2^{-\\beta} \\theta^{2\\beta} \\cos(n\\theta) d\\theta\n$$\nfor some small $\\epsilon>0$. Let $u=n\\theta$, so $d\\theta = du/n$. The integral becomes\n$$\na_n \\approx \\frac{2 \\cdot 2^{-\\beta}}{\\pi} \\int_0^{n\\epsilon} \\left(\\frac{u}{n}\\right)^{2\\beta} \\cos(u) \\frac{du}{n} = \\frac{2^{1-\\beta}}{\\pi n^{2\\beta+1}} \\int_0^{n\\epsilon} u^{2\\beta} \\cos(u) du.\n$$\nAs $n \\to \\infty$, the upper limit $n\\epsilon \\to \\infty$. The definite integral $\\int_0^\\infty u^{2\\beta} \\cos(u) du$ converges for $\\beta \\in (0,1)$ (since $2\\beta-1 < 1$) and is a constant independent of $n$. This integral can be related to the Gamma function:\n$$\n\\int_0^\\infty u^{2\\beta} \\cos(u) du = \\text{Re}\\left[ \\int_0^\\infty u^{2\\beta} e^{iu} du \\right] = \\text{Re}\\left[ \\frac{\\Gamma(2\\beta+1)}{( -i )^{2\\beta+1}} \\right] = \\Gamma(2\\beta+1) \\text{Re}\\left[ e^{i\\frac{\\pi}{2}(2\\beta+1)} \\right] = -\\Gamma(2\\beta+1)\\sin(\\pi\\beta).\n$$\nSince $\\beta \\in (0,1)$, $\\sin(\\pi\\beta) \\neq 0$. Therefore, the asymptotic behavior of the coefficients is\n$$\na_n \\sim -\\frac{2^{1-\\beta} \\Gamma(2\\beta+1) \\sin(\\pi\\beta)}{\\pi} n^{-(2\\beta+1)}.\n$$\nThis confirms that $|a_n| = \\Theta(n^{-(2\\beta+1)})$. The algebraic decay is a direct consequence of the singularity at $x=1$.\n\nNext, we relate this coefficient decay to the interpolation error. The error of polynomial interpolation is related to the error of the best uniform polynomial approximation of degree $N$, denoted $p_N^*$. The error of the best approximant is, in turn, bounded by the error of the truncated Chebyshev series, $S_N f(x) = \\sum_{k=0}^N c_k T_k(x)$, where $\\{c_k\\}$ are the standard Chebyshev expansion coefficients. The coefficients $a_n$ given in the problem are $a_n=2c_n$ for $n>0$ and $a_0=c_0$. The asymptotic decay rate is unaffected. The error of the truncated series is\n$$\n\\|f - S_N f\\|_{L^\\infty([-1,1])} = \\left\\| \\sum_{k=N+1}^\\infty c_k T_k \\right\\|_{L^\\infty} \\le \\sum_{k=N+1}^\\infty |c_k|.\n$$\nSince $|c_k| = \\Theta(k^{-(2\\beta+1)})$, this sum behaves as the corresponding integral:\n$$\n\\sum_{k=N+1}^\\infty k^{-(2\\beta+1)} \\approx \\int_{N+1}^\\infty t^{-(2\\beta+1)} dt = \\left[ \\frac{t^{-2\\beta}}{-2\\beta} \\right]_{N+1}^\\infty = \\frac{1}{2\\beta}(N+1)^{-2\\beta}.\n$$\nThus, the best approximation error is $\\|f - p_N^*\\|_{L^\\infty} = \\Theta(N^{-2\\beta})$.\n\nThe interpolation error $\\|f - p_N\\|$ (for either node set) is bounded by $\\|f - p_N\\|_{L^\\infty} \\le (1+\\Lambda_N)\\|f - p_N^*\\|_{L^\\infty}$, where $\\Lambda_N$ is the Lebesgue constant. For both Chebyshev-Gauss and Chebyshev-Gauss-Lobatto nodes, $\\Lambda_N = \\mathcal{O}(\\ln N)$. This gives an upper bound of $\\|f - p_N\\|_{L^\\infty} = \\mathcal{O}(N^{-2\\beta} \\ln N)$, which is not sharp enough to determine the $\\Theta$-rate.\n\nA more precise analysis uses the aliasing formula, which relates the coefficients of the interpolant to the coefficients of the function. Let $p_N^{\\mathrm{L}}$ be the interpolant at the CGL nodes. Its coefficients $\\{b_n\\}$ in the Chebyshev basis are given by $b_n = c_n + \\sum_{k=1}^\\infty (c_{2kN-n} + c_{2kN+n})$ for $n<N$ (with slight modification for $n=0, N$). The error is\n$$\nf - p_N^{\\mathrm{L}} = (f-S_N f) + (S_N f - p_N^{\\mathrm{L}}).\n$$\nThe first term is the truncation error, whose norm is $\\Theta(N^{-2\\beta})$. The second term is the aliasing error:\n$$\nS_N f - p_N^{\\mathrm{L}} = \\sum_{n=0}^N (c_n - b_n) T_n = -\\sum_{n=0}^N T_n \\sum_{k=1}^\\infty (c_{2kN-n} + c_{2kN+n}).\n$$\nThe magnitude of the aliasing error is dominated by the $k=1$ terms and the decay rate of the coefficients $c_m \\sim m^{-(2\\beta+1)}$.\n$$\n\\|S_N f - p_N^{\\mathrm{L}}\\|_{L^\\infty} \\le \\sum_{n=0}^N \\sum_{k=1}^\\infty (|c_{2kN-n}| + |c_{2kN+n}|).\n$$\nThe largest terms in this sum are for $k=1$, contributing $\\sum_{n=0}^N (|c_{2N-n}| + |c_{2N+n}|)$. Let's estimate the size of the first part of this sum:\n$$\n\\sum_{n=0}^N |c_{2N-n}| \\approx C \\sum_{n=0}^N (2N-n)^{-(2\\beta+1)} \\approx C \\int_0^N (2N-t)^{-(2\\beta+1)} dt.\n$$\nLet $u=2N-t$, so $du=-dt$. The integral is $C \\int_{2N}^N u^{-(2\\beta+1)} (-du) = C \\int_N^{2N} u^{-(2\\beta+1)} du = \\Theta(N^{-2\\beta})$.\nA similar calculation shows the sum of $|c_{2N+n}|$ terms is also $\\Theta(N^{-2\\beta})$. Thus, the aliasing error $\\|S_N f - p_N^{\\mathrm{L}}\\|_{L^\\infty}$ is also of order $\\Theta(N^{-2\\beta})$.\nSince both the truncation error and the aliasing error are $\\Theta(N^{-2\\beta})$, their sum, the total interpolation error, is also of this order:\n$$\n\\|f - p_N^{\\mathrm{L}}\\|_{L^\\infty} = \\Theta(N^{-2\\beta}).\n$$\nA similar analysis for the Chebyshev-Gauss nodes $x_j^{\\mathrm{G}}$ leads to the same conclusion. The aliasing formula is different, $b_n = c_n + \\sum_{k=1}^\\infty (-1)^k(c_{2k(N+1)-n} - c_{2k(N+1)+n})$, but the magnitude of the aliasing error is still determined by coefficients with indices of order $\\mathcal{O}(N)$, resulting in an error of $\\Theta(N^{-2\\beta})$.\nThus, we have $\\|f - p_N^{\\mathrm{G}}\\|_{L^\\infty} = \\Theta(N^{-2\\beta})$.\n\nThe problem asks for the exponent $p(\\beta)$ in the relation $\\|f-p_N\\|_{L^\\infty} = \\Theta(N^{-p(\\beta)})$. By comparison with our derived rate, we conclude that $p(\\beta) = 2\\beta$.\nThe clustering of nodes, which is slightly different for Chebyshev-Gauss (interior) and Chebyshev-Gauss-Lobatto (including endpoints), does affect the interpolation process (e.g., the Lebesgue constant, the aliasing formula). However, for functions with algebraic endpoint singularities, this difference does not change the leading-order algebraic convergence rate exponent. The exponent is fundamentally determined by the smoothness of the function being interpolated, which in this case is characterized by $\\beta$.", "answer": "$$\\boxed{2\\beta}$$", "id": "3369358"}]}