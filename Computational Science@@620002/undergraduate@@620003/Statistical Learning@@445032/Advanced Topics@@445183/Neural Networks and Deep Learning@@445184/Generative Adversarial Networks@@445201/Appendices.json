{"hands_on_practices": [{"introduction": "The generative adversarial network (GAN) training process is a delicate adversarial game. If the discriminator becomes too proficient and confident, it can provide vanishingly small gradients to the generator, halting the learning process. This practice [@problem_id:3124540] explores label smoothing, a simple yet effective technique to stabilize this game by preventing the discriminator from becoming overconfident. By deriving the optimal discriminator under this modified objective, you will gain a first-principles understanding of how this technique alters the GAN equilibrium and promotes more stable training.", "problem": "A Generative Adversarial Network (GAN) consists of a generator that induces a model distribution $p_{g}(x)$ over data space and a discriminator that outputs a probability $D(x) \\in (0,1)$ indicating how likely $x$ is drawn from the real data distribution $p_{\\text{data}}(x)$. The discriminator is trained by minimizing binary cross-entropy, equivalently by maximizing the expected log-likelihood of targets over the mixture of real and generated samples. In standard training, real samples have target $1$ and generated samples have target $0$. In label smoothing, the real targets are shifted to a value $s \\in (0,1)$, while fake targets are kept unsmoothed at $t=0$.\n\nAssume the discriminator objective over $x$ is the expected binary cross-entropy formed by sampling from $p_{\\text{data}}(x)$ with target $s$ and from $p_{g}(x)$ with target $t=0$. Work in the continuous setting where $p_{\\text{data}}$ and $p_{g}$ are densities over a common support and integrate expectations with respect to $x$.\n\nUsing only the fundamental definition of binary cross-entropy and the minimax formulation of GANs, derive from first principles:\n\n1) The pointwise optimal discriminator $D^{*}(x)$ under label smoothing with real target $s=0.9$ and fake target $t=0$, expressed in terms of $p_{\\text{data}}(x)$ and $p_{g}(x)$.\n\n2) The maximized discriminator objective at the minimax equilibrium when the generator matches the data, i.e., $p_{g}(x) = p_{\\text{data}}(x)$, under the same label smoothing. Express the equilibrium value as a real number by evaluating the closed-form expression obtained for $s=0.9$ and $t=0$.\n\nProvide your final answer as a two-entry row vector $\\big[D^{*}(x), V^{*}\\big]$, where $V^{*}$ is the equilibrium value. Round the numerical equilibrium value to four significant figures. No units are required.", "solution": "The objective of the discriminator, $D$, is to maximize the value function $V(D,G)$, which represents the log-likelihood of correctly identifying real and generated samples. The training targets are smoothed for real samples to $s$ and are $t$ for generated samples. The objective function is the sum of the expected log-likelihoods over the real data distribution, $p_{\\text{data}}(x)$, and the generator's distribution, $p_g(x)$.\n\nThe log-likelihood for a given sample $x$ with discriminator output $D(x)$ and target label $y$ is given by the binary cross-entropy expression: $y \\ln(D(x)) + (1-y) \\ln(1-D(x))$.\n\nThe total value function $V(D)$ is formulated by integrating over all $x$:\n$$V(D) = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} [s \\ln(D(x)) + (1-s) \\ln(1-D(x))] + \\mathbb{E}_{x \\sim p_g(x)} [t \\ln(D(x)) + (1-t) \\ln(1-D(x))]$$\nIn the continuous setting with densities, this becomes:\n$$V(D) = \\int p_{\\text{data}}(x) [s \\ln(D(x)) + (1-s) \\ln(1-D(x))] dx + \\int p_g(x) [t \\ln(D(x)) + (1-t) \\ln(1-D(x))] dx$$\nTo find the optimal discriminator $D^*(x)$ that maximizes this value for a fixed generator, we can maximize the integrand pointwise for each $x$. Let the integrand be $f(D(x))$:\n$$f(D(x)) = p_{\\text{data}}(x)[s \\ln(D(x)) + (1-s) \\ln(1-D(x))] + p_g(x)[t \\ln(D(x)) + (1-t) \\ln(1-D(x))]$$\nWe collect terms containing $\\ln(D(x))$ and $\\ln(1-D(x))$:\n$$f(D(x)) = [s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)] \\ln(D(x)) + [(1-s) p_{\\text{data}}(x) + (1-t) p_g(x)] \\ln(1-D(x))$$\nThis function is of the form $A \\ln(y) + B \\ln(1-y)$ with $y=D(x)$, where:\n$A = s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)$\n$B = (1-s) p_{\\text{data}}(x) + (1-t) p_g(x)$\n\nTo find the maximum, we compute the derivative with respect to $y$ and set it to $0$:\n$$\\frac{df}{dy} = \\frac{A}{y} - \\frac{B}{1-y} = 0 \\implies A(1-y) = By \\implies y = \\frac{A}{A+B}$$\nSubstituting $A$ and $B$ back, the optimal discriminator $D^*(x)$ is:\n$$D^*(x) = \\frac{s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)}{(s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)) + ((1-s) p_{\\text{data}}(x) + (1-t) p_g(x))}$$\nThe denominator simplifies:\n$$s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x) + p_{\\text{data}}(x) - s \\cdot p_{\\text{data}}(x) + p_g(x) - t \\cdot p_g(x) = p_{\\text{data}}(x) + p_g(x)$$\nThus, the general solution for the optimal discriminator is:\n$$D^*(x) = \\frac{s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)}{p_{\\text{data}}(x) + p_g(x)}$$\n\n**1) Optimal Discriminator under Specific Label Smoothing**\n\nFor the specific case given, the real target is $s=0.9$ and the fake target is $t=0$. Substituting these values into the general formula for $D^*(x)$:\n$$D^*(x) = \\frac{0.9 \\cdot p_{\\text{data}}(x) + 0 \\cdot p_g(x)}{p_{\\text{data}}(x) + p_g(x)} = \\frac{0.9 \\cdot p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}$$\nThis is the expression for the pointwise optimal discriminator.\n\n**2) Maximized Objective at Equilibrium**\n\nAt minimax equilibrium, the generator perfectly mimics the real data distribution, so $p_g(x) = p_{\\text{data}}(x)$. We first find the value of the optimal discriminator at this equilibrium:\n$$D^*_{\\text{eq}}(x) = \\frac{0.9 \\cdot p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_{\\text{data}}(x)} = \\frac{0.9 \\cdot p_{\\text{data}}(x)}{2 \\cdot p_{\\text{data}}(x)} = \\frac{0.9}{2} = 0.45$$\nAt equilibrium, the optimal discriminator outputs a constant probability of $0.45$ regardless of the input $x$.\n\nNext, we evaluate the value function $V(D)$ using $D(x) = D^*_{\\text{eq}}(x) = 0.45$, the equilibrium condition $p_g(x) = p_{\\text{data}}(x)$, and the labels $s=0.9, t=0$. Let the maximized equilibrium value be $V^*$.\n$$V^* = \\int p_{\\text{data}}(x) [0.9 \\ln(0.45) + (1-0.9) \\ln(1-0.45)] dx + \\int p_{\\text{data}}(x) [0 \\ln(0.45) + (1-0) \\ln(1-0.45)] dx$$\n$$V^* = \\int p_{\\text{data}}(x) [0.9 \\ln(0.45) + 0.1 \\ln(0.55)] dx + \\int p_{\\text{data}}(x) [\\ln(0.55)] dx$$\nSince the terms inside the square brackets are constants, they can be factored out of the integrals. We use the fact that $\\int p_{\\text{data}}(x) dx = 1$.\n$$V^* = [0.9 \\ln(0.45) + 0.1 \\ln(0.55)] \\int p_{\\text{data}}(x) dx + [\\ln(0.55)] \\int p_{\\text{data}}(x) dx$$\n$$V^* = (0.9 \\ln(0.45) + 0.1 \\ln(0.55)) \\cdot 1 + \\ln(0.55) \\cdot 1$$\n$$V^* = 0.9 \\ln(0.45) + 0.1 \\ln(0.55) + 1.0 \\ln(0.55)$$\n$$V^* = 0.9 \\ln(0.45) + 1.1 \\ln(0.55)$$\nNow, we compute the numerical value:\n$\\ln(0.45) \\approx -0.7985077$\n$\\ln(0.55) \\approx -0.5978370$\n$$V^* \\approx 0.9 \\times (-0.7985077) + 1.1 \\times (-0.5978370)$$\n$$V^* \\approx -0.71865693 - 0.65762070$$\n$$V^* \\approx -1.37627763$$\nRounding to four significant figures, we get $V^* = -1.376$.\nThe final answer is composed of the expression for $D^*(x)$ and the numerical value for $V^*$.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{0.9 \\cdot p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)} & -1.376 \\end{pmatrix} } $$", "id": "3124540"}, {"introduction": "While GANs are capable of producing highly realistic samples, they often struggle to capture the full diversity of the true data distribution, a failure mode known as mode collapse. This conceptual exercise [@problem_id:3124513] investigates a fundamental mathematical reason for this phenomenon: a topological conflict between the continuous nature of the generator and a data distribution that may exist in separate, disconnected clusters. By applying principles of topology, you will understand why standard GAN architectures can fail and explore alternative designs that can successfully model complex, multi-modal data.", "problem": "Consider a Generative Adversarial Network (GAN) with a generator $G$ and discriminator $D$. Let the latent variable $Z$ be distributed according to a prior $p_Z$ on $\\mathbb{R}^m$, and let the data distribution $p_{\\text{data}}$ be supported on a subset of $\\mathbb{R}^n$. The generator induces a model distribution $p_G$ as the pushforward of $p_Z$ under $G$, written $p_G = G_{\\#} p_Z$. Assume the following foundational facts: (i) the support $\\mathrm{supp}(p)$ of a probability distribution $p$ is the smallest closed set of full measure, equivalently the closure of the set of points whose every open neighborhood has positive probability; (ii) for a continuous mapping $G:\\mathbb{R}^m \\to \\mathbb{R}^n$, the image $G(S)$ of a connected set $S \\subset \\mathbb{R}^m$ is connected, and the closure of a connected set is connected; (iii) if $p_Z$ has full support on $\\mathbb{R}^m$ in the sense that every nonempty open set has positive probability, then the support of $G_{\\#} p_Z$ contains $G(\\mathbb{R}^m)$ and equals its closure. Suppose $p_{\\text{data}}$ is supported on $S_{\\text{data}} = M_1 \\cup M_2$, where $M_1$ and $M_2$ are disjoint, compact, smooth submanifolds of $\\mathbb{R}^n$ (for concreteness, think of $M_1$ and $M_2$ as two well-separated circles in $\\mathbb{R}^2$), making $S_{\\text{data}}$ disconnected. Assume $p_Z$ is a standard Gaussian on $\\mathbb{R}^m$, $G$ is a neural network that is continuous as a function $\\mathbb{R}^m \\to \\mathbb{R}^n$, and training aims to minimize a divergence (for example, Jensen–Shannon divergence $D_{\\mathrm{JSD}}$ or Wasserstein distance $W$) between $p_{\\text{data}}$ and $p_G$.\n\nFrom these bases, reason about the topological constraints on $\\mathrm{supp}(p_G)$ and whether standard training can overcome them. Then evaluate proposed architecture changes to address disconnected supports.\n\nWhich of the following statements are correct?\n\nA. If $G$ is continuous and $p_Z$ has connected support (e.g., full support on $\\mathbb{R}^m$), then $\\mathrm{supp}(p_G)$ is connected (indeed $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$), so $p_G$ cannot exactly match a $p_{\\text{data}}$ whose support $S_{\\text{data}}$ is disconnected.\n\nB. Introducing a discrete latent selector $S \\in \\{1,\\dots,K\\}$, independent of $Z$, and defining $G(Z,S) = G_S(Z)$ where each $G_k$ is continuous, yields $p_G(\\cdot) = \\sum_{k=1}^K \\pi_k \\,(G_k)_{\\#} p_Z$ with support $\\mathrm{supp}(p_G) = \\bigcup_{k=1}^K \\overline{G_k(\\mathbb{R}^m)}$, which can be disconnected and thus can cover disjoint modes like $M_1 \\cup M_2$.\n\nC. Switching the training objective from Jensen–Shannon divergence $D_{\\mathrm{JSD}}$ to Wasserstein distance $W$ allows a single continuous generator with connected latent support to produce a model distribution $p_G$ whose support becomes disconnected during training, thereby removing the topological limitation.\n\nD. Replacing the prior $p_Z$ with a mixture of $2$ Gaussians having distinct means makes $\\mathrm{supp}(p_Z)$ disconnected, and therefore a single continuous generator can exactly represent $p_{\\text{data}}$ with disjoint support.\n\nE. Using a continuous gating function $h:\\mathbb{R}^m \\to \\Delta^{K-1}$ (the $(K-1)$-simplex) and defining $G(\\mathbf{z}) = \\sum_{k=1}^K h_k(\\mathbf{z})\\,G_k(\\mathbf{z})$ produces a support equal to $\\bigcup_{k=1}^K G_k(\\mathbb{R}^m)$ and can represent disconnected supports without introducing any discrete variable.\n\nSelect all that apply.", "solution": "The problem requires an analysis of the topological properties of the support of a distribution generated by a Generative Adversarial Network (GAN) and an evaluation of several proposed modifications to the standard GAN architecture. The core of the problem lies in the conflict between the topological properties of the standard generator mapping and the properties of the target data distribution.\n\nLet us establish the foundational argument based on the givens.\n1.  The latent variable $Z$ is distributed according to $p_Z$, which is a standard Gaussian on $\\mathbb{R}^m$. The support of a standard Gaussian distribution, $\\mathrm{supp}(p_Z)$, is the entire space $\\mathbb{R}^m$.\n2.  The set $\\mathbb{R}^m$ for any dimension $m \\ge 1$ is a path-connected space, and therefore a connected space.\n3.  The generator $G$ is a neural network, which is stated to be a continuous function $G: \\mathbb{R}^m \\to \\mathbb{R}^n$.\n4.  A fundamental theorem in topology, provided as fact (ii), states that the image of a connected set under a continuous map is connected. Therefore, the image of the latent space under the generator, $G(\\mathrm{supp}(p_Z)) = G(\\mathbb{R}^m)$, is a connected subset of $\\mathbb{R}^n$.\n5.  Fact (iii) states that since $p_Z$ has full support on $\\mathbb{R}^m$, the support of the generated distribution $p_G$ is the closure of the image of the generator: $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$.\n6.  Fact (ii) also states that the closure of a connected set is connected. Since $G(\\mathbb{R}^m)$ is connected, its closure $\\overline{G(\\mathbb{R}^m)}$ is also connected.\n7.  Combining these points, the support of the generated distribution, $\\mathrm{supp}(p_G)$, is necessarily a connected set.\n8.  The problem states that the support of the target data distribution, $S_{\\text{data}} = \\mathrm{supp}(p_{\\text{data}})$, is the union of two disjoint sets, $S_{\\text{data}} = M_1 \\cup M_2$. A set that is a union of two non-empty disjoint closed sets (compact sets are closed) is, by definition, disconnected.\n9.  For the generator to perfectly learn the target distribution, we would need $p_G = p_{\\text{data}}$. A necessary condition for this equality is that their supports must be identical: $\\mathrm{supp}(p_G) = \\mathrm{supp}(p_{\\text{data}})$.\n10. This leads to a contradiction: $\\mathrm{supp}(p_G)$ must be connected, while $\\mathrm{supp}(p_{\\text{data}})$ is disconnected. Therefore, it is topologically impossible for a standard GAN with a continuous generator and a connected latent support to exactly model a distribution with a disconnected support.\n\nWith this main conclusion established, let us evaluate each option.\n\n**A. If $G$ is continuous and $p_Z$ has connected support (e.g., full support on $\\mathbb{R}^m$), then $\\mathrm{supp}(p_G)$ is connected (indeed $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$), so $p_G$ cannot exactly match a $p_{\\text{data}}$ whose support $S_{\\text{data}}$ is disconnected.**\n\nThis statement is a precise articulation of the foundational argument derived above. The premises ($G$ is continuous, $\\mathrm{supp}(p_Z)$ is connected) lead directly to the conclusion that $\\mathrm{supp}(p_G)$ is connected, based on the provided facts about continuous maps and closures. Since the target support $S_{\\text{data}}$ is disconnected, the supports cannot match, and thus the distributions cannot be equal. The reasoning is sound and follows directly from the problem statement and standard topological principles.\n\nVerdict: **Correct**.\n\n**B. Introducing a discrete latent selector $S \\in \\{1,\\dots,K\\}$, independent of $Z$, and defining $G(Z,S) = G_S(Z)$ where each $G_k$ is continuous, yields $p_G(\\cdot) = \\sum_{k=1}^K \\pi_k \\,(G_k)_{\\#} p_Z$ with support $\\mathrm{supp}(p_G) = \\bigcup_{k=1}^K \\overline{G_k(\\mathbb{R}^m)}$, which can be disconnected and thus can cover disjoint modes like $M_1 \\cup M_2$.**\n\nThis describes a mixture model generator. The generation process involves first sampling a discrete category $k$ from a categorical distribution with probabilities $\\pi_k = P(S=k)$, and then generating a sample using the corresponding continuous generator $G_k(Z)$. The resulting probability distribution $p_G$ is a mixture of the distributions generated by each \"expert\" generator $G_k$. The overall density (informally) is $p_G = \\sum_{k=1}^K \\pi_k p_{G_k}$, where $p_{G_k}$ is the distribution corresponding to $(G_k)_{\\#} p_Z$.\n\nThe support of a mixture distribution is the union of the supports of its component distributions. For each component $k$, the generator $G_k$ is continuous, so based on our main argument, its support $\\mathrm{supp}((G_k)_{\\#}p_Z)$ is the connected set $\\overline{G_k(\\mathbb{R}^m)}$. The support of the overall distribution $p_G$ is therefore $\\mathrm{supp}(p_G) = \\bigcup_{k=1}^K \\mathrm{supp}((G_k)_{\\#}p_Z) = \\bigcup_{k=1}^K \\overline{G_k(\\mathbb{R}^m)}$.\n\nThe union of connected sets is not necessarily connected. For the target distribution with $S_{\\text{data}} = M_1 \\cup M_2$, we can use $K=2$ generators. We can train $G_1$ such that its image $G_1(\\mathbb{R}^m)$ is close to $M_1$ and $G_2$ such that its image $G_2(\\mathbb{R}^m)$ is close to $M_2$. Since $M_1$ and $M_2$ are disjoint, the supports of the two component distributions, $\\overline{G_1(\\mathbb{R}^m)}$ and $\\overline{G_2(\\mathbb{R}^m)}$, can also be disjoint. Their union is thus a disconnected set, which can successfully match the topology of $S_{\\text{data}}$. The statement correctly describes the mathematical form of the support and its ability to be disconnected.\n\nVerdict: **Correct**.\n\n**C. Switching the training objective from Jensen–Shannon divergence $D_{\\mathrm{JSD}}$ to Wasserstein distance $W$ allows a single continuous generator with connected latent support to produce a model distribution $p_G$ whose support becomes disconnected during training, thereby removing the topological limitation.**\n\nThe choice of divergence or distance measure ($D_{\\mathrm{JSD}}$, $W$, etc.) affects the optimization landscape and the behavior of gradients during training. The Wasserstein distance is particularly useful because it provides non-vanishing gradients even when the supports of the two distributions are disjoint. However, the choice of loss function cannot alter the fundamental topological properties of the generator function $G$. As established, if $G$ is a continuous function and its domain ($\\mathrm{supp}(p_Z) = \\mathbb{R}^m$) is connected, its codomain's image $G(\\mathbb{R}^m)$ and the support $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$ are necessarily connected. This is a property of the function itself, independent of how it is trained. The statement's claim that the support \"becomes disconnected\" is a topological impossibility under the given architectural constraints.\n\nVerdict: **Incorrect**.\n\n**D. Replacing the prior $p_Z$ with a mixture of $2$ Gaussians having distinct means makes $\\mathrm{supp}(p_Z)$ disconnected, and therefore a single continuous generator can exactly represent $p_{\\text{data}}$ with disjoint support.**\n\nThis statement's premise is flawed. A mixture of Gaussian distributions in $\\mathbb{R}^m$, say $p_Z(\\mathbf{z}) = \\alpha_1 \\phi(\\mathbf{z}; \\mu_1, \\Sigma_1) + \\alpha_2 \\phi(\\mathbf{z}; \\mu_2, \\Sigma_2)$, has a probability density function that is a weighted sum of positive functions. Since the Gaussian density $\\phi$ is strictly positive for all inputs in $\\mathbb{R}^m$, the resulting mixture density $p_Z(\\mathbf{z})$ is also strictly positive for all $\\mathbf{z} \\in \\mathbb{R}^m$. According to the definition of support provided (\"the closure of the set of points whose every open neighborhood has positive probability\"), if the density is positive everywhere, the support is the entire space $\\mathbb{R}^m$. The set $\\mathbb{R}^m$ is connected. Therefore, replacing the prior with a Gaussian mixture does *not* make its support disconnected. Since the support of the prior remains connected, the original topological limitation on the support of $p_G$ still holds.\n\nVerdict: **Incorrect**.\n\n**E. Using a continuous gating function $h:\\mathbb{R}^m \\to \\Delta^{K-1}$ (the $(K-1)$-simplex) and defining $G(\\mathbf{z}) = \\sum_{k=1}^K h_k(\\mathbf{z})\\,G_k(\\mathbf{z})$ produces a support equal to $\\bigcup_{k=1}^K G_k(\\mathbb{R}^m)$ and can represent disconnected supports without introducing any discrete variable.**\n\nThis architecture defines a generator $G(\\mathbf{z})$ as a point-wise convex combination of several \"expert\" generators $G_k(\\mathbf{z})$. Each $G_k$ is continuous, and the gating function $h$ is also continuous. The composition, sum, and product of continuous functions are continuous. Therefore, the overall mapping $G: \\mathbb{R}^m \\to \\mathbb{R}^n$ is a single continuous function. We are thus back in the original scenario: a continuous map from a connected latent space $\\mathbb{R}^m$ to the data space $\\mathbb{R}^n$. By the same topological argument, the support of the resulting distribution, $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$, must be a connected set. This architecture cannot generate a distribution with a disconnected support. Furthermore, the statement incorrectly claims that the support is $\\bigcup_{k=1}^K G_k(\\mathbb{R}^m)$. The image of the generator is $G(\\mathbb{R}^m) = \\{ \\sum_{k=1}^K h_k(\\mathbf{z})G_k(\\mathbf{z}) \\mid \\mathbf{z} \\in \\mathbb{R}^m \\}$, which is not the same as the union of the individual images. The continuous convex combinations can create \"bridges\" between otherwise separate regions, reinforcing the connectedness of the total image.\n\nVerdict: **Incorrect**.", "answer": "$$\\boxed{AB}$$", "id": "3124513"}, {"introduction": "The interplay between the generator and discriminator updates is a critical factor in achieving stable GAN training. A widely used heuristic is to update the discriminator ($D$) for $k$ steps for every single update to the generator ($G$). This hands-on computational experiment [@problem_id:3128933] empowers you to investigate this rule empirically. By implementing a simple GAN and its training loop, you will generate a \"phase diagram\" that maps the stability of the training process as a function of $k$, providing concrete insight into the practical dynamics of the GAN training dance.", "problem": "You are given a simplified Generative Adversarial Network (GAN) experiment designed to analyze how alternating $k$ discriminator steps per generator step impacts training stability on a one-dimensional Gaussian dataset. The experiment is grounded in first principles: a Generator $G$ transforms standard normal noise $z \\sim \\mathcal{N}(0,1)$ into $x_g = a z + b$, and a Discriminator $D$ estimates the probability that an input is real via $D(x) = \\sigma(w x + c)$ where $\\sigma$ is the logistic sigmoid function. The real data distribution is $x \\sim \\mathcal{N}(\\mu_r, \\sigma_r^2)$. The Discriminator maximizes the expected log-likelihood of correctly classifying real and fake samples, and the Generator minimizes the non-saturating loss based on the Discriminator's output.\n\nStart from the following fundamental bases and core definitions in deep learning and probability:\n- The objective of Generative Adversarial Networks (GANs) is a two-player minimax game between a Generator and a Discriminator, driven by expected values over data and noise distributions.\n- Gradient-based learning dynamics approximate these expectations using Monte Carlo samples and apply gradient ascent for maximization and gradient descent for minimization.\n- For a linear Generator $G(z) = a z + b$ where $z \\sim \\mathcal{N}(0,1)$, the Generator’s induced distribution is Gaussian with mean $b$ and standard deviation $|a|$.\n- The logistic sigmoid function is $\\sigma(s) = \\frac{1}{1 + e^{-s}}$, and the derivative identities needed for gradients are well tested in statistics and machine learning.\n\nYour tasks:\n1. Formulate the alternating gradient dynamics where the Discriminator parameters $(w,c)$ are updated via gradient ascent on its objective $k$ times for every single gradient descent update of the Generator parameters $(a,b)$ on its non-saturating objective. Use Monte Carlo estimation with a fixed batch size and fixed learning rates for both players. Ensure numerical stability of $\\sigma$ by controlling the input domain.\n2. Define an empirical notion of training stability. Use the following composite criterion: let $d_t = \\sqrt{(\\mu_g(t) - \\mu_r)^2 + (\\sigma_g(t) - \\sigma_r)^2}$ where $\\mu_g(t) = b(t)$ and $\\sigma_g(t) = |a(t)|$ are the Generator’s mean and standard deviation at training step $t$. Define the improvement fraction $I = \\frac{d_0 - d_T}{\\max(d_0, \\epsilon)}$ for a small $\\epsilon$, and define an oscillation index $O = \\frac{\\sum_{t=1}^T \\|\\theta_g(t) - \\theta_g(t-1)\\|_2}{\\|\\theta_g(T) - \\theta_g(0)\\|_2 + \\epsilon}$ where $\\theta_g(t) = [a(t), b(t)]^\\top$. Classify a run as stable if the parameters remain finite and bounded, $I$ exceeds a minimum threshold, and $O$ is below a maximum threshold.\n3. Empirically derive a phase diagram of stability versus $k$ by running the training at several values of $k$ on a simple dataset and reporting whether each run is stable or unstable, encoded as $1$ for stable and $0$ for unstable.\n\nUse the following dataset, training, and evaluation setup:\n- Real data parameters $(\\mu_r, \\sigma_r)$ and schedule parameter $k$ vary per test case.\n- Noise distribution is $z \\sim \\mathcal{N}(0,1)$.\n- Generator is $G(z) = a z + b$ initialized at $a = 0.2$ and $b = 0.0$.\n- Discriminator is $D(x) = \\sigma(w x + c)$ with $(w,c)$ initialized at $(0.0, 0.0)$.\n- Discriminator objective is the expected sum of $\\log D(x)$ over real samples and $\\log(1 - D(G(z)))$ over fake samples; Discriminator uses gradient ascent.\n- Generator objective is the expected value of $- \\log D(G(z))$ (non-saturating); Generator uses gradient descent.\n- Use learning rates $\\alpha_D = 0.05$ and $\\alpha_G = 0.02$, batch size $B = 1024$, and $T = 200$ Generator steps.\n- For numerical stability, clip the sigmoid input $s$ to the interval $[-50, 50]$ before applying $\\sigma(s)$.\n\nDefine the stability classification thresholds and safeguards:\n- Use $\\epsilon = 10^{-8}$ for denominator stabilization.\n- Declare divergence if any parameter magnitude exceeds $100$ or any parameter becomes not-a-number at any point.\n- Use thresholds $I_{\\min} = 0.25$ and $O_{\\max} = 2.5$.\n- A run is stable if it does not diverge, $I \\ge I_{\\min}$, and $O \\le O_{\\max}$.\n\nTest suite:\n- Case $1$: $(\\mu_r, \\sigma_r, k, \\text{seed}) = (0.0, 1.0, 0, 42)$.\n- Case $2$: $(\\mu_r, \\sigma_r, k, \\text{seed}) = (0.0, 1.0, 1, 42)$.\n- Case $3$: $(\\mu_r, \\sigma_r, k, \\text{seed}) = (0.0, 1.0, 5, 42)$.\n- Case $4$: $(\\mu_r, \\sigma_r, k, \\text{seed}) = (2.0, 0.5, 2, 123)$.\n- Case $5$: $(\\mu_r, \\sigma_r, k, \\text{seed}) = (-1.0, 1.5, 10, 7)$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is an integer where $1$ denotes a stable run and $0$ denotes an unstable run.", "solution": "The problem requires an empirical investigation into the training stability of a simplified Generative Adversarial Network (GAN) as a function of the number of discriminator updates, $k$, per generator update. This involves deriving the gradient-based learning dynamics, implementing the simulation, and evaluating the outcome against a specified set of stability criteria.\n\nFirst, we formalize the components of the model. The real data distribution is a one-dimensional Gaussian, $x \\sim \\mathcal{N}(\\mu_r, \\sigma_r^2)$. The Generator, $G$, maps a standard normal noise variable $z \\sim \\mathcal{N}(0,1)$ to a sample $x_g$ via a linear transformation:\n$$G(z) = a z + b$$\nThe parameters of the generator are $\\theta_G = (a, b)$. The distribution induced by the generator is therefore also Gaussian, with mean $\\mu_g = b$ and standard deviation $\\sigma_g = |a|$. The Discriminator, $D$, is a logistic regressor that models the probability of an input $x$ being from the real data distribution:\n$$D(x) = \\sigma(w x + c)$$\nwhere $\\sigma(s) = (1 + e^{-s})^{-1}$ is the logistic sigmoid function. The parameters of the discriminator are $\\theta_D = (w,c)$.\n\nThe training process is a minimax game. The discriminator is trained to maximize the objective function $V_D$, which is the sum of the log-likelihood of correctly classifying real and fake samples:\n$$V_D(\\theta_D, \\theta_G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))]$$\nThe generator is trained to minimize the non-saturating objective function $V_G$, which aims to produce samples that the discriminator classifies as real:\n$$V_G(\\theta_G) = -\\mathbb{E}_{z \\sim p_z(z)}[\\log D(G(z))]$$\n\nTo implement the learning dynamics, we derive the gradients of these objectives with respect to the model parameters. The expectations are approximated using Monte Carlo estimation over a batch of $B$ samples.\n\nThe gradients of the discriminator objective $V_D$ with respect to its parameters $w$ and $c$ are found using the chain rule and the derivative properties of the sigmoid function, specifically $\\frac{d}{ds}\\log \\sigma(s) = 1 - \\sigma(s)$ and $\\frac{d}{ds}\\log(1-\\sigma(s)) = -\\sigma(s)$. The gradients for a batch of real data $\\{x_i\\}_{i=1}^B$ and generated data $\\{x_{g,i}\\}_{i=1}^B$ are:\n$$ \\nabla_w \\hat{V}_D = \\frac{1}{B} \\sum_{i=1}^B \\left( (1 - D(x_i))x_i - D(x_{g,i})x_{g,i} \\right) $$\n$$ \\nabla_c \\hat{V}_D = \\frac{1}{B} \\sum_{i=1}^B \\left( (1 - D(x_i)) - D(x_{g,i}) \\right) $$\nThe discriminator parameters are updated via gradient ascent:\n$$ w \\leftarrow w + \\alpha_D \\nabla_w \\hat{V}_D $$\n$$ c \\leftarrow c + \\alpha_D \\nabla_c \\hat{V}_D $$\n\nThe gradients of the generator's non-saturating objective $V_G$ with respect to its parameters $a$ and $b$ are:\n$$ \\nabla_a V_G = \\frac{\\partial V_G}{\\partial a} = -\\mathbb{E}_z\\left[ \\frac{\\partial}{\\partial a} \\log D(az+b) \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) \\frac{\\partial(w(az+b)+c)}{\\partial a} \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) w z \\right] $$\n$$ \\nabla_b V_G = \\frac{\\partial V_G}{\\partial b} = -\\mathbb{E}_z\\left[ \\frac{\\partial}{\\partial b} \\log D(az+b) \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) \\frac{\\partial(w(az+b)+c)}{\\partial b} \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) w \\right] $$\nApproximating with a batch of noise $\\{z_i\\}_{i=1}^B$, the generator parameters are updated via gradient descent:\n$$ a \\leftarrow a - \\alpha_G \\left( -\\frac{w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) z_i \\right) = a + \\frac{\\alpha_G w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) z_i $$\n$$ b \\leftarrow b - \\alpha_G \\left( -\\frac{w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) \\right) = b + \\frac{\\alpha_G w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) $$\n\nThe complete training algorithm proceeds for $T$ generator steps. In each step $t \\in \\{1, \\dots, T\\}$:\n1.  The discriminator is updated $k$ times. For each discriminator update, a new batch of real data $x \\sim \\mathcal{N}(\\mu_r, \\sigma_r^2)$ and noise $z \\sim \\mathcal{N}(0,1)$ is drawn. The parameters $(w, c)$ are updated using gradient ascent with learning rate $\\alpha_D$.\n2.  The generator is updated once. A new batch of noise $z \\sim \\mathcal{N}(0,1)$ is drawn. The parameters $(a, b)$ are updated using gradient descent on the non-saturating loss with learning rate $\\alpha_G$.\nThroughout the simulation, parameter values are monitored. If any parameter's magnitude exceeds $100$ or becomes non-finite (NaN), the run is terminated and classified as divergent. The input to the sigmoid function is clipped to $[-50, 50]$ to prevent numerical overflow.\n\nUpon completion of $T$ steps, the training run is evaluated for stability. The distance between the generator's distribution parameters $(\\mu_g(t)=b(t), \\sigma_g(t)=|a(t)|)$ and the target real data parameters $(\\mu_r, \\sigma_r)$ is defined as $d_t = \\sqrt{(\\mu_g(t) - \\mu_r)^2 + (\\sigma_g(t) - \\sigma_r)^2}$. Two metrics are calculated:\n1.  The improvement fraction, $I$, measures the relative reduction in distance from the initial state to the final state:\n    $$ I = \\frac{d_0 - d_T}{\\max(d_0, \\epsilon)} $$\n    where $d_0$ and $d_T$ are the distances at step $0$ and $T$, and $\\epsilon = 10^{-8}$ is a small constant for numerical stability. A run must achieve $I \\ge I_{\\min} = 0.25$.\n2.  The oscillation index, $O$, measures the ratio of the total path length of the generator parameters $\\theta_g(t)=[a(t), b(t)]^\\top$ to the net displacement:\n    $$ O = \\frac{\\sum_{t=1}^T \\|\\theta_g(t) - \\theta_g(t-1)\\|_2}{\\|\\theta_g(T) - \\theta_g(0)\\|_2 + \\epsilon} $$\n    A run must have $O \\le O_{\\max} = 2.5$.\n\nA run is classified as stable (output $1$) if and only if it does not diverge, achieves $I \\ge I_{\\min}$, and has $O \\le O_{\\max}$. Otherwise, it is unstable (output $0$). The provided implementation executes this entire procedure for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not required for this problem.\n\ndef solve():\n    \"\"\"\n    Main function to run the GAN stability analysis for all test cases.\n    \"\"\"\n    \n    test_cases = [\n        # (mu_r, sigma_r, k, seed)\n        (0.0, 1.0, 0, 42),\n        (0.0, 1.0, 1, 42),\n        (0.0, 1.0, 5, 42),\n        (2.0, 0.5, 2, 123),\n        (-1.0, 1.5, 10, 7)\n    ]\n\n    results = []\n    for case in test_cases:\n        mu_r, sigma_r, k, seed = case\n        result = run_training_and_evaluate(mu_r, sigma_r, k, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef sigmoid(s):\n    \"\"\"\n    Computes the logistic sigmoid function with input clipping for numerical stability.\n    \"\"\"\n    s_clipped = np.clip(s, -50.0, 50.0)\n    return 1.0 / (1.0 + np.exp(-s_clipped))\n\ndef run_training_and_evaluate(mu_r, sigma_r, k, seed,\n                              a_init=0.2, b_init=0.0,\n                              w_init=0.0, c_init=0.0,\n                              alpha_D=0.05, alpha_G=0.02,\n                              B=1024, T=200,\n                              epsilon=1e-8, divergence_threshold=100.0,\n                              I_min=0.25, O_max=2.5):\n    \"\"\"\n    Simulates the GAN training for one parameter set and evaluates its stability.\n    \"\"\"\n    # Set seed for reproducibility\n    np.random.seed(seed)\n\n    # Initialize parameters\n    a, b = a_init, b_init\n    w, c = w_init, c_init\n\n    # History for stability metrics\n    theta_g_history = [np.array([a, b])]\n    diverged = False\n\n    # Calculate initial distance to target distribution parameters\n    d_0 = np.sqrt((b - mu_r)**2 + (np.abs(a) - sigma_r)**2)\n\n    # Main training loop (T generator steps)\n    for _ in range(T):\n        # --- Discriminator updates (k steps) ---\n        if k > 0:\n            for _ in range(k):\n                # Sample data\n                x_r = np.random.normal(loc=mu_r, scale=sigma_r, size=B)\n                z = np.random.normal(loc=0.0, scale=1.0, size=B)\n                x_g = a * z + b\n\n                # Discriminator predictions\n                d_real = sigmoid(w * x_r + c)\n                d_fake = sigmoid(w * x_g + c)\n                \n                # Discriminator gradients (for maximizing log-likelihood)\n                grad_w = np.mean((1.0 - d_real) * x_r - d_fake * x_g)\n                grad_c = np.mean((1.0 - d_real) - d_fake)\n\n                # Update D parameters via gradient ascent\n                w += alpha_D * grad_w\n                c += alpha_D * grad_c\n\n                # Check for D divergence\n                if not (np.isfinite(w) and np.isfinite(c) and\n                        abs(w) < divergence_threshold and abs(c) < divergence_threshold):\n                    diverged = True\n                    break\n            if diverged:\n                break\n\n        # --- Generator update (1 step) ---\n        z_g = np.random.normal(loc=0.0, scale=1.0, size=B)\n        x_g_g = a * z_g + b\n        d_fake_for_g = sigmoid(w * x_g_g + c)\n\n        # Generator gradients (for minimizing non-saturating loss -log(D(G(z))))\n        grad_V_G_a = -np.mean((1.0 - d_fake_for_g) * w * z_g)\n        grad_V_G_b = -np.mean((1.0 - d_fake_for_g) * w)\n        \n        # Update G parameters via gradient descent\n        a -= alpha_G * grad_V_G_a\n        b -= alpha_G * grad_V_G_b\n\n        # Check for G divergence\n        if not (np.isfinite(a) and np.isfinite(b) and\n                abs(a) < divergence_threshold and abs(b) < divergence_threshold):\n            diverged = True\n            break\n            \n        theta_g_history.append(np.array([a, b]))\n\n    # --- Stability Evaluation ---\n    if diverged:\n        return 0\n\n    a_T, b_T = theta_g_history[-1]\n    \n    # Final distance\n    d_T = np.sqrt((b_T - mu_r)**2 + (np.abs(a_T) - sigma_r)**2)\n    \n    # Improvement Fraction (I)\n    I = (d_0 - d_T) / max(d_0, epsilon)\n\n    # Oscillation Index (O)\n    path_length = np.sum([np.linalg.norm(theta_g_history[t] - theta_g_history[t-1]) for t in range(1, T + 1)])\n    net_displacement = np.linalg.norm(theta_g_history[-1] - theta_g_history[0])\n    O = path_length / (net_displacement + epsilon)\n\n    # Classify as stable (1) or unstable (0)\n    if I >= I_min and O <= O_max:\n        return 1\n    else:\n        return 0\n\nsolve()\n```", "id": "3128933"}]}