{"hands_on_practices": [{"introduction": "This first exercise provides a foundational walkthrough of the recursion tree method for a classic divide-and-conquer recurrence. By analyzing a problem where the work at each level of recursion changes geometrically, you will practice the core skill of summing these costs to find a tight asymptotic bound. This problem [@problem_id:3248716] is essential for understanding how the cost distribution across the tree's levels determines the algorithm's overall efficiency.", "problem": "A divide-and-conquer procedure on an input of size $n$ performs a partitioning step that produces $2$ subproblems, each of size $n/3$, and incurs an additional non-recursive cost proportional to $\\sqrt{n}$ for work outside the recursive calls. Let $T(n)$ denote the total work. Assume $n$ is restricted to powers of $3$ so that the split is exact, and use the base condition $T(1)=\\Theta(1)$. Without invoking any pre-stated theorems, derive from first principles a tight asymptotic expression for $T(n)$ by reasoning about the recursive structure and the aggregate work across levels of recursion. Your final answer must be a single closed-form analytic expression. No rounding is required and no physical units are involved. The recurrence is\n$$\nT(n)=2\\,T\\!\\left(\\frac{n}{3}\\right)+\\sqrt{n}.\n$$\nProvide the final expression in Big-Theta notation as a single analytic expression.", "solution": "The user wants me to solve and provide a solution to the problem stated in the prompt.\n\n### Step 1: Extract Givens\n- Recurrence relation: $T(n) = 2T(n/3) + \\sqrt{n}$\n- Constraint on $n$: $n$ is a power of $3$.\n- Base case: $T(1) = \\Theta(1)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard recurrence relation analysis from the field of computer science (analysis of algorithms).\n- **Scientifically Grounded**: The problem is mathematically well-defined and uses established concepts for analyzing algorithm complexity. It is sound.\n- **Well-Posed**: The recurrence relation, base case, and constraint on $n$ are all provided, forming a complete specification that allows for the derivation of a unique asymptotic solution.\n- **Objective**: The problem is stated using precise, objective mathematical language.\n- **Other Flaws**: The problem does not exhibit any of the other invalidity flags. It is not incomplete, contradictory, unrealistic, ill-posed, or trivial. The instruction to avoid pre-stated theorems is a pedagogical constraint on the method of solution, not a flaw in the problem itself.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n***\n\nWe are asked to find a tight asymptotic expression for $T(n)$ satisfying the recurrence relation $T(n) = 2T(n/3) + \\sqrt{n}$. We will use the recursion tree method to solve this from first principles.\n\nLet us assume the non-recursive cost is $c_1\\sqrt{n}$ for some constant $c_1 > 0$, and the base case is $T(1) = c_2$ for some constant $c_2 > 0$, which is consistent with $T(1) = \\Theta(1)$. The recurrence is $T(n) = 2T(n/3) + c_1\\sqrt{n}$.\n\nWe construct a recursion tree to visualize the work done.\nThe root of the tree represents the initial problem of size $n$. The non-recursive work done at the root is $c_1\\sqrt{n}$. This is level $0$.\nThe root generates $2$ subproblems, each of size $n/3$. These form level $1$ of the tree.\nAt level $i$ of the recursion tree (where the root is at level $0$), we have:\n- Number of nodes (subproblems): $2^i$.\n- Size of each subproblem: $n/3^i$.\n- Work done at each node (non-recursive part): $c_1\\sqrt{n/3^i} = c_1\\frac{\\sqrt{n}}{(\\sqrt{3})^i}$.\n- Total work done across all nodes at level $i$: $W_i = 2^i \\times \\left(c_1\\frac{\\sqrt{n}}{(\\sqrt{3})^i}\\right) = c_1\\sqrt{n}\\left(\\frac{2}{\\sqrt{3}}\\right)^i$.\n\nThe recursion terminates when the subproblem size becomes $1$. Let $d$ be the depth of the tree. This occurs when $n/3^d = 1$, which implies $3^d = n$, so $d = \\log_3(n)$.\n\nThe total work $T(n)$ is the sum of the work done at all levels, from level $0$ to level $d$.\n$$ T(n) = \\sum_{i=0}^{d} W_i $$\nThis sum can be split into the sum of work at the internal nodes (levels $0$ to $d-1$) and the work at the leaf nodes (level $d$).\n\nThe work at the leaf level, $W_d$, corresponds to the base cases.\nAt level $d$, there are $2^d$ nodes, each corresponding to a problem of size $n/3^d = 1$. The work for each is $T(1) = c_2$.\nSo, the total work at the leaves is $W_{leaves} = 2^d \\cdot T(1) = c_2 \\cdot 2^d$.\nSince $d = \\log_3(n)$, we have $2^d = 2^{\\log_3(n)}$. Using the logarithm identity $a^{\\log_b(c)} = c^{\\log_b(a)}$, we get:\n$2^{\\log_3(n)} = n^{\\log_3(2)}$.\nThus, the work at the leaves is $W_{leaves} = c_2 n^{\\log_3(2)}$.\n\nThe work at the internal nodes is the sum from $i=0$ to $d-1$:\n$$ W_{internal} = \\sum_{i=0}^{d-1} W_i = \\sum_{i=0}^{d-1} c_1\\sqrt{n}\\left(\\frac{2}{\\sqrt{3}}\\right)^i = c_1\\sqrt{n} \\sum_{i=0}^{d-1} \\left(\\frac{2}{\\sqrt{3}}\\right)^i $$\nThis is a geometric series with ratio $r = 2/\\sqrt{3}$. Since $4 > 3$, we have $2 > \\sqrt{3}$, so $r > 1$.\nThe sum of a finite geometric series is given by $\\sum_{k=0}^{m-1} r^k = \\frac{r^m - 1}{r - 1}$.\nHere, $m=d$ and $r = 2/\\sqrt{3}$.\n$$ W_{internal} = c_1\\sqrt{n} \\left( \\frac{(2/\\sqrt{3})^d - 1}{2/\\sqrt{3} - 1} \\right) $$\nLet's simplify the constant part: $\\frac{1}{2/\\sqrt{3} - 1} = \\frac{\\sqrt{3}}{2 - \\sqrt{3}}$. Let this constant be $C_3$.\n$$ W_{internal} = c_1 C_3 \\sqrt{n} \\left( \\left(\\frac{2}{\\sqrt{3}}\\right)^d - 1 \\right) $$\nNow, substitute $d = \\log_3(n)$:\n$$ \\left(\\frac{2}{\\sqrt{3}}\\right)^d = \\frac{2^d}{(\\sqrt{3})^d} = \\frac{2^{\\log_3(n)}}{(3^{1/2})^{\\log_3(n)}} = \\frac{n^{\\log_3(2)}}{(3^{\\log_3(n)})^{1/2}} = \\frac{n^{\\log_3(2)}}{n^{1/2}} $$\nSubstituting this back into the expression for $W_{internal}$:\n$$ W_{internal} = c_1 C_3 \\sqrt{n} \\left( \\frac{n^{\\log_3(2)}}{n^{1/2}} - 1 \\right) = c_1 C_3 \\left( \\sqrt{n} \\frac{n^{\\log_3(2)}}{\\sqrt{n}} - \\sqrt{n} \\right) = c_1 C_3 \\left( n^{\\log_3(2)} - \\sqrt{n} \\right) $$\n\nThe total work is $T(n) = W_{internal} + W_{leaves}$.\n$$ T(n) = c_1 C_3 \\left( n^{\\log_3(2)} - \\sqrt{n} \\right) + c_2 n^{\\log_3(2)} $$\n$$ T(n) = (c_1 C_3 + c_2) n^{\\log_3(2)} - c_1 C_3 \\sqrt{n} $$\nTo find the tight asymptotic bound, we compare the terms $n^{\\log_3(2)}$ and $\\sqrt{n} = n^{1/2}$. We need to compare the exponents $\\log_3(2)$ and $1/2$.\nWe have $\\log_3(2) = \\frac{\\ln(2)}{\\ln(3)} \\approx \\frac{0.693}{1.098} \\approx 0.6309$.\nSince $\\log_3(2) > 1/2$, the term $(c_1 C_3 + c_2) n^{\\log_3(2)}$ dominates the term $-c_1 C_3 \\sqrt{n}$ for large $n$.\nThe coefficients $(c_1 C_3 + c_2)$ and $-c_1 C_3$ are constants.\nTherefore, the asymptotic behavior of $T(n)$ is determined by the dominant term:\n$$ T(n) = \\Theta\\left(n^{\\log_3(2)}\\right) $$\nThis concludes the derivation from first principles.", "answer": "$$\\boxed{\\Theta\\left(n^{\\log_{3}(2)}\\right)}$$", "id": "3248716"}, {"introduction": "Building on the fundamentals, this practice explores a more complex divide-and-conquer scenario where the non-recursive work at each step is significant. The recurrence [@problem_id:3265011] exemplifies a case where the cost per level does not decrease geometrically, requiring a more nuanced summation to find an exact solution. This exercise will sharpen your skills in handling recurrences that lead to polylogarithmic factors in the final complexity, a common pattern in advanced algorithms.", "problem": "You are analyzing the running time of a divide-and-conquer algorithm that, on an input of size $n$, splits the problem into $2$ subproblems of size $n/2$ and performs $g(n)$ units of non-recursive work before making the recursive calls. You want the total work across the recursion tree to be on the order of $\\mathcal{O}\\!\\left(n(\\ln n)^{2}\\right)$. Consider the explicit choice $g(n)=n\\ln n$, and define the recurrence\n$$\nT(n)=2\\,T\\!\\left(\\frac{n}{2}\\right)+n\\ln n,\\quad T(1)=0,\n$$\nwith the simplifying assumption that $n$ is a power of $2$. Using the recursion tree method from first principles (count of nodes per level and per-node work), derive an exact closed-form expression for $T(n)$ as a function of $n$. Express your final answer as a single simplified analytic expression in terms of $n$. All logarithms are natural unless a base is indicated. Do not provide asymptotic notation in your final answer.", "solution": "The problem statement will first be subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe verbatim givens extracted from the problem statement are:\n- Recurrence relation: $T(n)=2\\,T\\!\\left(\\frac{n}{2}\\right)+n\\ln n$\n- Base case: $T(1)=0$\n- Assumption: $n$ is a power of $2$.\n- Method: Recursion tree method from first principles.\n- Desired output: An exact closed-form expression for $T(n)$.\n- Logarithm convention: All logarithms are natural logarithms, denoted $\\ln$, unless a base is explicitly indicated.\n\nThe statement also includes a contextual remark that the total work is expected to be of the order $\\mathcal{O}\\!\\left(n(\\ln n)^{2}\\right)$ for the function $g(n)=n\\ln n$. This serves as a guide for an asymptotic check of the final result.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established criteria:\n- **Scientifically Grounded:** The problem is a standard exercise in the analysis of algorithms, a core topic in computer science and discrete mathematics. The recurrence relation is typical of divide-and-conquer algorithms. The objects and operations are mathematically well-defined. The problem is scientifically sound.\n- **Well-Posed:** The problem is well-posed. It provides a linear recurrence relation with constant coefficients, a defined non-homogeneous term ($n\\ln n$), and a necessary base case ($T(1)=0$). The constraint that $n$ is a power of $2$ ensures that the argument to $T$ remains an integer throughout the recursion, simplifying the analysis. These conditions guarantee that a unique, exact solution exists.\n- **Objective:** The problem is stated in precise, formal mathematical language, devoid of any subjectivity, ambiguity, or opinion-based claims.\n\nBased on this analysis, the problem is free of any scientific or logical flaws, is self-contained, and is unambiguously structured. It is therefore deemed **valid**.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will now be derived.\n\nThe problem requires solving the recurrence relation\n$$\nT(n)=2T\\left(\\frac{n}{2}\\right)+n\\ln(n)\n$$\nwith the base case $T(1)=0$, under the assumption that $n$ is a power of $2$. We shall use the recursion tree method as stipulated.\n\nA recursion tree visualizes the cost of the recursive calls. Each node in the tree represents the non-recursive work performed for a particular subproblem size.\nThe root of the tree corresponds to the initial problem of size $n$. The non-recursive work at the root is $n\\ln(n)$. The root has $2$ children, each representing a subproblem of size $n/2$.\n\nLet us analyze the tree level by level. We define the root to be at level $i=0$.\n- **Level $i=0$**: There is $1=2^0$ node, corresponding to the problem of size $n/2^0 = n$. The work at this node is $n\\ln(n)$. The total work at this level is $1 \\cdot n\\ln(n) = n\\ln(n)$.\n- **Level $i=1$**: There are $2=2^1$ nodes, each for a subproblem of size $n/2^1 = n/2$. The work at each of these nodes is $(n/2)\\ln(n/2)$. The total work at this level is $2 \\cdot (n/2)\\ln(n/2) = n\\ln(n/2)$.\n- **Level $i$**: By induction, at depth $i$, there are $2^i$ nodes. Each node corresponds to a subproblem of size $n/2^i$. The non-recursive work performed at each such node is $(n/2^i)\\ln(n/2^i)$. The total work at level $i$ is the product of the number of nodes and the work per node:\n$$\n\\text{Work}_{\\text{level } i} = 2^i \\cdot \\left(\\frac{n}{2^i}\\right) \\ln\\left(\\frac{n}{2^i}\\right) = n \\ln\\left(\\frac{n}{2^i}\\right)\n$$\nThe recursion terminates when the subproblem size becomes $1$. Let $k$ be the depth of the tree where this occurs. We set the subproblem size to $1$:\n$$\n\\frac{n}{2^k} = 1 \\implies n = 2^k \\implies k = \\log_2(n)\n$$\nSince we assume $n$ is a power of $2$, $k$ is an integer. The tree has $k+1$ levels, indexed from $i=0$ to $i=k$. The leaves are at level $k$.\nThe work at the leaf nodes (level $k$) corresponds to the base case $T(1)$. The problem states $T(1)=0$, so the total work at the leaf level is $2^k \\cdot T(1) = n \\cdot 0 = 0$.\n\nThe total work $T(n)$ is the sum of the work performed at all levels from the root down to the level just before the leaves (i.e., from $i=0$ to $i=k-1$).\n$$\nT(n) = \\sum_{i=0}^{k-1} \\text{Work}_{\\text{level } i} = \\sum_{i=0}^{\\log_2(n)-1} n \\ln\\left(\\frac{n}{2^i}\\right)\n$$\nWe can now evaluate this sum.\n$$\nT(n) = n \\sum_{i=0}^{\\log_2(n)-1} \\left[ \\ln(n) - \\ln(2^i) \\right] = n \\sum_{i=0}^{\\log_2(n)-1} \\left[ \\ln(n) - i\\ln(2) \\right]\n$$\nLet's substitute $k=\\log_2(n)$ to simplify notation during the calculation.\n$$\nT(n) = n \\sum_{i=0}^{k-1} (\\ln(n) - i\\ln(2))\n$$\nWe can split the summation into two parts:\n$$\nT(n) = n \\left[ \\sum_{i=0}^{k-1} \\ln(n) - \\sum_{i=0}^{k-1} i\\ln(2) \\right] = n \\left[ \\ln(n) \\sum_{i=0}^{k-1} 1 - \\ln(2) \\sum_{i=0}^{k-1} i \\right]\n$$\nThe first sum is over $k$ terms: $\\sum_{i=0}^{k-1} 1 = k$.\nThe second sum is the sum of an arithmetic series: $\\sum_{i=0}^{k-1} i = \\frac{(k-1)k}{2}$.\nSubstituting these results back into the expression for $T(n)$:\n$$\nT(n) = n \\left[ k\\ln(n) - \\ln(2) \\frac{k(k-1)}{2} \\right]\n$$\nTo obtain the final expression in terms of $n$, we substitute $k = \\log_2(n)$. It is convenient to use the change of base formula, $\\log_2(n) = \\frac{\\ln(n)}{\\ln(2)}$.\n$$\nT(n) = n \\left[ \\frac{\\ln(n)}{\\ln(2)} \\ln(n) - \\frac{\\ln(2)}{2} \\frac{\\ln(n)}{\\ln(2)} \\left(\\frac{\\ln(n)}{\\ln(2)} - 1\\right) \\right]\n$$\n$$\nT(n) = n \\left[ \\frac{(\\ln(n))^2}{\\ln(2)} - \\frac{\\ln(n)}{2} \\left(\\frac{\\ln(n) - \\ln(2)}{\\ln(2)}\\right) \\right]\n$$\nFactor out the common term $\\frac{n}{\\ln(2)}$:\n$$\nT(n) = \\frac{n}{\\ln(2)} \\left[ (\\ln(n))^2 - \\frac{\\ln(n)}{2}(\\ln(n) - \\ln(2)) \\right]\n$$\n$$\nT(n) = \\frac{n}{\\ln(2)} \\left[ (\\ln(n))^2 - \\frac{1}{2}(\\ln(n))^2 + \\frac{1}{2}\\ln(n)\\ln(2) \\right]\n$$\n$$\nT(n) = \\frac{n}{\\ln(2)} \\left[ \\frac{1}{2}(\\ln(n))^2 + \\frac{1}{2}\\ln(n)\\ln(2) \\right]\n$$\nFactoring out $\\frac{1}{2}$ and $\\ln(n)$ from the bracketed term yields:\n$$\nT(n) = \\frac{n}{2\\ln(2)} \\left[ (\\ln(n))^2 + \\ln(n)\\ln(2) \\right] = \\frac{n \\ln(n) (\\ln(n) + \\ln(2))}{2 \\ln(2)}\n$$\nThis is the exact closed-form expression for $T(n)$. The leading term is proportional to $n(\\ln n)^2$, which is consistent with the order of magnitude $\\mathcal{O}(n(\\ln n)^2)$ mentioned in the problem description.\nA check of the base case $T(1)=0$ confirms the result:\n$$\nT(1) = \\frac{1 \\ln(1) (\\ln(1) + \\ln(2))}{2 \\ln(2)} = \\frac{1 \\cdot 0 \\cdot (0 + \\ln(2))}{2 \\ln(2)} = 0\n$$\nThe derivation is complete and the result verified.", "answer": "$$\n\\boxed{\\frac{n \\ln(n) (\\ln(n) + \\ln(2))}{2 \\ln(2)}}\n$$", "id": "3265011"}, {"introduction": "This final practice demonstrates the versatility of recursion analysis by shifting the focus from time complexity to space complexity. You are tasked with modeling the maximum stack memory used by a recursive procedure, which requires reasoning about the call stack's behavior during a depth-first execution. This problem [@problem_id:3265136] provides a powerful insight into how the structure of a recursion tree can be used to analyze resource consumption, not just computational time.", "problem": "Consider a recursive procedure on an input of size $n \\in \\mathbb{N}$, where $n$ is a power of $2$. On each invocation with parameter $m > 1$, the procedure allocates exactly $\\alpha \\,\\ln m$ units of stack memory (where $\\alpha > 0$ is a fixed constant and $\\ln$ denotes the natural logarithm), then makes two recursive calls in depth-first order: first on size $m/2$, and after that call returns, on size $m/4$. The stack frame of size $\\alpha \\,\\ln m$ remains allocated until both recursive calls return. For $m \\leq 1$, the procedure returns immediately and allocates no memory. Ignore any memory overhead not explicitly stated.\n\nUsing only first principles about recursion trees and call stacks in the analysis of algorithms, derive an exact closed-form expression for the maximum instantaneous stack memory $M(n)$ used at any time during the execution on input size $n$. Your analysis must reason from the structural properties of the recursion tree (node labels and depth) and the definition that a callâ€™s stack frame persists until it returns. Express your final answer as a single analytic expression in terms of $n$ and $\\alpha$, using elementary functions, and you may use the fact that $n$ is a power of $2$. Do not use asymptotic notation in your final answer.", "solution": "### Step 1: Extract Givens\n- The input size is $n \\in \\mathbb{N}$, where $n$ is a power of $2$.\n- The recursive procedure is defined for a parameter $m$.\n- For $m > 1$, the procedure allocates $\\alpha \\ln m$ units of stack memory, where $\\alpha > 0$ is a constant.\n- The procedure makes two recursive calls in depth-first order: first on size $m/2$, then on size $m/4$.\n- The stack frame of size $\\alpha \\ln m$ remains allocated until both recursive calls on $m/2$ and $m/4$ return.\n- For $m \\leq 1$, the procedure allocates no memory and returns.\n- The goal is to find the maximum instantaneous stack memory $M(n)$ as an exact closed-form expression in terms of $n$ and $\\alpha$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientifically Grounded:** The problem deals with recursion, call stacks, and algorithmic analysis, which are core concepts in computer science, a formal STEM discipline. The use of logarithms and summations is mathematically sound.\n- **Well-Posed:** The problem statement is clear and self-contained. The constraints ($n$ is a power of $2$, depth-first order) and the memory allocation rule are specified precisely. This structure ensures that a unique, meaningful solution exists.\n- **Objective:** The language is formal and unambiguous. The quantities are defined with mathematical precision (e.g., $\\alpha \\ln m$). There are no subjective or opinion-based elements.\n\nThe problem does not exhibit any of the invalidity flaws. It is a standard problem in the analysis of algorithms.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Derivation of the Solution\nLet $M(m)$ be the maximum instantaneous stack memory used at any time during the execution of the procedure on an input of size $m$. We are asked to find $M(n)$.\n\nThe problem states that for an input $m > 1$, a stack frame of size $\\alpha \\ln m$ is allocated. This frame persists while the procedure makes two sequential, depth-first calls: first to `procedure(m/2)` and then to `procedure(m/4)`.\n\nLet's analyze the memory usage during the execution of `procedure(m)`.\n1.  The frame for `procedure(m)` is pushed onto the stack, consuming $\\alpha \\ln m$ memory.\n2.  The first recursive call, `procedure(m/2)`, is made. During the entire execution of this subproblem, the stack contains the frame for `procedure(m)`. The maximum memory usage during this phase is the sum of the memory for the current frame and the maximum memory required by the subproblem `procedure(m/2)`. This maximum is $\\alpha \\ln m + M(m/2)$.\n3.  After `procedure(m/2)` completes and returns, the second recursive call, `procedure(m/4)`, is made. Similarly, the maximum memory usage during this phase is $\\alpha \\ln m + M(m/4)$.\n\nSince these two phases occur sequentially, the overall maximum memory used during the execution of `procedure(m)` is the maximum of the peak usage in each phase. This gives us the following recurrence relation for $M(m)$:\n$$M(m) = \\alpha \\ln m + \\max\\left( M(m/2), M(m/4) \\right) \\quad \\text{for } m > 1$$\nThe base case is given by the condition for $m \\leq 1$, where no memory is allocated. Thus:\n$$M(m) = 0 \\quad \\text{for } m \\leq 1$$\n\nTo solve the recurrence, we first need to simplify the $\\max$ term. Let's demonstrate that $M(m)$ is a monotonically increasing function of $m$ for $m \\geq 1$.\nBase cases:\n$M(1) = 0$.\n$M(2) = \\alpha \\ln 2 + \\max(M(1), M(1/2)) = \\alpha \\ln 2 + \\max(0, 0) = \\alpha \\ln 2$.\nSince $\\alpha > 0$ and $\\ln 2 > 0$, we have $M(2) > M(1)$.\nNow, let's assume for induction that $M(k) > M(k/2)$ for all powers of two $k$ such that $2 \\leq k  m$.\nWe want to show $M(m) > M(m/2)$. From our inductive hypothesis, since $m/2  m$, we have $M(m/2) > M((m/2)/2) = M(m/4)$.\nTherefore, $\\max(M(m/2), M(m/4)) = M(m/2)$.\nThe recurrence for $m > 2$ becomes:\n$$M(m) = \\alpha \\ln m + M(m/2)$$\nWe must show $M(m) > M(m/2)$. This is immediate:\n$M(m) = M(m/2) + \\alpha \\ln m$. Since $m > 1$ and $\\alpha > 0$, the term $\\alpha \\ln m$ is strictly positive. Thus, $M(m) > M(m/2)$. The induction holds true.\n\nThe simplified recurrence relation for $n > 1$ is:\n$$M(n) = \\alpha \\ln n + M(n/2)$$\nwith the base case $M(1) = 0$. Since $n$ is a power of $2$, let $n=2^k$ for some integer $k \\geq 0$. Note that $k = \\log_2 n$.\nWe can solve the recurrence by unrolling it:\n$$M(n) = M(2^k) = \\alpha \\ln(2^k) + M(2^{k-1})$$\n$$M(2^k) = \\alpha \\ln(2^k) + \\left(\\alpha \\ln(2^{k-1}) + M(2^{k-2})\\right)$$\n$$M(2^k) = \\alpha \\ln(2^k) + \\alpha \\ln(2^{k-1}) + \\alpha \\ln(2^{k-2}) + \\dots + M(2^1)$$\nThe last step is $M(2^1) = M(2) = \\alpha \\ln 2 + M(1) = \\alpha \\ln 2$.\nSo, we have a sum:\n$$M(n) = \\alpha \\left( \\ln(2^k) + \\ln(2^{k-1}) + \\dots + \\ln(2^1) \\right)$$\n$$M(n) = \\alpha \\sum_{i=1}^{k} \\ln(2^i)$$\nUsing the property of logarithms $\\ln(x^y) = y \\ln x$:\n$$M(n) = \\alpha \\sum_{i=1}^{k} i \\ln 2 = \\alpha \\ln 2 \\sum_{i=1}^{k} i$$\nThe sum of the first $k$ integers is given by the formula $\\sum_{i=1}^{k} i = \\frac{k(k+1)}{2}$.\nSubstituting this into our expression for $M(n)$:\n$$M(n) = \\alpha \\ln 2 \\left( \\frac{k(k+1)}{2} \\right)$$\nNow, we must express the result in terms of $n$ and $\\alpha$. We substitute $k = \\log_2 n = \\frac{\\ln n}{\\ln 2}$:\n$$M(n) = \\frac{\\alpha \\ln 2}{2} \\left( \\frac{\\ln n}{\\ln 2} \\right) \\left( \\frac{\\ln n}{\\ln 2} + 1 \\right)$$\n$$M(n) = \\frac{\\alpha \\ln n}{2} \\left( \\frac{\\ln n}{\\ln 2} + 1 \\right)$$\nTo obtain a more compact form, we continue simplifying:\n$$M(n) = \\frac{\\alpha \\ln n}{2} \\left( \\frac{\\ln n + \\ln 2}{\\ln 2} \\right)$$\nUsing the logarithm property $\\ln a + \\ln b = \\ln(ab)$:\n$$M(n) = \\frac{\\alpha (\\ln n) (\\ln(2n))}{2 \\ln 2}$$\nThis is the exact closed-form expression for the maximum instantaneous stack memory.", "answer": "$$\\boxed{\\frac{\\alpha (\\ln n) (\\ln(2n))}{2 \\ln 2}}$$", "id": "3265136"}]}