{"hands_on_practices": [{"introduction": "We begin with a familiar scenario that elegantly transforms into a classic optimization problem. Deciding what to bring on a trip involves balancing an item's usefulness against constraints like luggage space and budget. This exercise [@problem_id:2443405] formalizes this into a Multiple-Choice Knapsack Problem with two constraints—capacity and budget—where for each item, you must choose the single best action among several options. By solving this, you will practice applying the principle of optimality to break a complex, multi-item decision into a manageable sequence of choices, building an optimal solution one item at a time.", "problem": "Consider a finite-horizon choice problem for a traveler facing three mutually exclusive actions for each item: pack in luggage, ship ahead, or buy at the destination, with the option to skip the item. The traveler departs in $D$ days, the trip lasts $T$ days at the destination, and shipping item $i$ has a lead time of $L_i$ days. If an item arrives at the destination with a delay of $d_i = \\max\\{0, L_i - D\\}$ days after the traveler arrives, then its realized utility is discounted by a factor $\\alpha^{d_i}$, where $0 \\le \\alpha \\le 1$. If $d_i \\ge T$, the realized utility is $0$ because the item arrives after the trip ends. Packing consumes luggage weight capacity, while shipping or buying consumes budget. The objective is to maximize total realized utility subject to capacity and budget constraints.\n\nFundamental base: Use the core definitions of utility maximization under constraints and the principle of optimality from Dynamic Programming (DP). Do not assume any shortcut formulas.\n\nFormulation details and assumptions:\n- There are $n$ items indexed by $i \\in \\{1, \\dots, n\\}$. Each item has:\n  - weight $w_i \\in \\mathbb{Z}_{\\ge 0}$,\n  - utility $u_i \\in \\mathbb{R}_{\\ge 0}$,\n  - shipping cost $s_i \\in \\mathbb{Z}_{\\ge 0}$,\n  - buying cost $b_i \\in \\mathbb{Z}_{\\ge 0}$,\n  - lead time $L_i \\in \\mathbb{Z}_{\\ge 0}$.\n- Luggage has capacity $C \\in \\mathbb{Z}_{\\ge 0}$ and the traveler has budget $B \\in \\mathbb{Z}_{\\ge 0}$.\n- For each item $i$, the traveler chooses exactly one of four actions: skip, pack, ship, or buy, subject to feasibility (capacity and budget) and timing.\n- The realized utility contribution of item $i$ under each action is:\n  - skip: $0$,\n  - pack: $u_i$ (consumes $w_i$ units of capacity and $0$ budget),\n  - ship: $u_i \\cdot \\alpha^{d_i}$ if $d_i < T$, else $0$ (consumes $s_i$ units of budget and $0$ capacity),\n  - buy: $u_i$ (consumes $b_i$ units of budget and $0$ capacity).\n- The objective is to choose actions to maximize the sum of realized utilities, subject to total packed weight $\\le C$ and total spending on shipped and bought items $\\le B$.\n\nRequired task:\n- Derive a Dynamic Programming (DP) formulation based on the principle of optimality, and implement an algorithm that computes the optimal total realized utility for given inputs. You must compute the optimal total realized utility (not the action plan) for each test case below. All computed outputs must be rounded to exactly $2$ decimal places.\n\nTest suite:\n- Use discount factor $\\alpha$ as specified in each case. Treat all costs and capacities as integers, and treat utilities as real numbers.\n\n- Case $1$:\n  - $C = 5$, $B = 25$, $D = 2$, $T = 5$, $\\alpha = 0.8$.\n  - Items:\n    - $i=1$: $w_1 = 3$, $u_1 = 20$, $s_1 = 12$, $b_1 = 15$, $L_1 = 1$.\n    - $i=2$: $w_2 = 2$, $u_2 = 18$, $s_2 = 15$, $b_2 = 25$, $L_2 = 3$.\n    - $i=3$: $w_3 = 1$, $u_3 = 6$, $s_3 = 3$, $b_3 = 4$, $L_3 = 2$.\n    - $i=4$: $w_4 = 4$, $u_4 = 30$, $s_4 = 20$, $b_4 = 100$, $L_4 = 5$.\n\n- Case $2$:\n  - $C = 0$, $B = 6$, $D = 1$, $T = 3$, $\\alpha = 0.7$.\n  - Items:\n    - $i=1$: $w_1 = 2$, $u_1 = 14$, $s_1 = 5$, $b_1 = 16$, $L_1 = 1$.\n    - $i=2$: $w_2 = 1$, $u_2 = 5$, $s_2 = 2$, $b_2 = 6$, $L_2 = 2$.\n    - $i=3$: $w_3 = 3$, $u_3 = 12$, $s_3 = 4$, $b_3 = 20$, $L_3 = 3$.\n\n- Case $3$:\n  - $C = 4$, $B = 0$, $D = 2$, $T = 2$, $\\alpha = 0.9$.\n  - Items:\n    - $i=1$: $w_1 = 1$, $u_1 = 4$, $s_1 = 1$, $b_1 = 3$, $L_1 = 2$.\n    - $i=2$: $w_2 = 3$, $u_2 = 16$, $s_2 = 5$, $b_2 = 50$, $L_2 = 1$.\n    - $i=3$: $w_3 = 1$, $u_3 = 2$, $s_3 = 1$, $b_3 = 2$, $L_3 = 3$.\n\n- Case $4$:\n  - $C = 2$, $B = 5$, $D = 1$, $T = 2$, $\\alpha = 0.5$.\n  - Items:\n    - $i=1$: $w_1 = 1$, $u_1 = 6$, $s_1 = 2$, $b_1 = 8$, $L_1 = 5$.\n    - $i=2$: $w_2 = 1$, $u_2 = 3$, $s_2 = 1$, $b_2 = 4$, $L_2 = 1$.\n    - $i=3$: $w_3 = 2$, $u_3 = 5$, $s_3 = 3$, $b_3 = 7$, $L_3 = 4$.\n\nFinal output format:\n- Your program should produce a single line of output containing the optimal total realized utilities for Cases $1$ through $4$, as a comma-separated list enclosed in square brackets, rounded to exactly $2$ decimal places, for example, $[0.00,1.25,3.00,4.50]$.", "solution": "The user-provided problem is first validated to ensure it is self-contained, consistent, and scientifically sound.\n\n### Step 1: Extract Givens\n- **Indices and Counts**:\n  - Number of items: $n$.\n  - Item index: $i \\in \\{1, \\dots, n\\}$.\n- **Global Parameters**:\n  - Departure in $D$ days.\n  - Trip duration: $T$ days.\n  - Luggage capacity: $C \\in \\mathbb{Z}_{\\ge 0}$.\n  - Budget: $B \\in \\mathbb{Z}_{\\ge 0}$.\n  - Shipping utility discount factor: $\\alpha \\in [0, 1]$.\n- **Item-Specific Parameters** (for each item $i$):\n  - Weight: $w_i \\in \\mathbb{Z}_{\\ge 0}$.\n  - Base utility: $u_i \\in \\mathbb{R}_{\\ge 0}$.\n  - Shipping cost: $s_i \\in \\mathbb{Z}_{\\ge 0}$.\n  - Buying cost: $b_i \\in \\mathbb{Z}_{\\ge 0}$.\n  - Shipping lead time: $L_i \\in \\mathbb{Z}_{\\ge 0}$.\n- **Actions and Utility Calculation**:\n  - Actions: skip, pack, ship, buy (mutually exclusive).\n  - Shipping delay: $d_i = \\max\\{0, L_i - D\\}$.\n  - Realized utilities:\n    - skip: $0$.\n    - pack: $u_i$ (consumes $w_i$ capacity).\n    - ship: $u_i \\cdot \\alpha^{d_i}$ if $d_i < T$, else $0$ (consumes $s_i$ budget).\n    - buy: $u_i$ (consumes $b_i$ budget).\n- **Objective**:\n  - Maximize the sum of realized utilities subject to total packed weight $\\le C$ and total spending $\\le B$.\n- **Required Task**:\n  - Derive a Dynamic Programming (DP) formulation.\n  - Implement an algorithm to compute the optimal total realized utility.\n  - Round results to $2$ decimal places.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is a variant of the Multiple-Choice Knapsack Problem (MCKP), a well-established problem in combinatorial optimization. It is mathematically and logically sound, resting on the principles of utility maximization under constraints.\n- **Well-Posedness**: The problem is well-posed. It seeks to maximize a linear objective function over a finite set of discrete choices, subject to linear constraints. An optimal solution value is guaranteed to exist and be unique, though the set of actions to achieve it may not be.\n- **Objectivity**: The problem statement is written in precise, unambiguous mathematical language. All terms are clearly defined.\n- **Completeness and Consistency**: The problem provides all necessary parameters ($n, C, B, D, T, \\alpha$, and properties for each item) for each test case. There are no contradictions in the setup.\n- **Feasibility**: The parameters specified are for a theoretical model and do not involve scientifically implausible or physically impossible conditions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a standard application of dynamic programming to a resource allocation problem. A complete solution will be provided.\n\n### Dynamic Programming Formulation\n\nThis problem can be solved using dynamic programming because it exhibits the property of optimal substructure. The optimal solution for a set of $k$ items can be constructed from the optimal solution for a smaller set of $k-1$ items. We make a decision for the $k$-th item and combine it with the optimal result for the first $k-1$ items given the remaining resources.\n\n**State Definition**\nLet $V_k(c, b)$ be the maximum total realized utility that can be achieved by making decisions for the first $k$ items (i.e., items $1, \\dots, k$), given a remaining luggage capacity of $c$ and a remaining budget of $b$. The state is defined by the number of items considered and the resources available.\n\n**Base Case**\nIf we have considered zero items ($k=0$), no utility has been accumulated. Therefore, for any capacity $c$ and budget $b$:\n$$\nV_0(c, b) = 0\n$$\n\n**Recurrence Relation**\nTo compute $V_k(c, b)$, we consider the decision for item $k$. There are four mutually exclusive choices:\n\n1.  **Skip item $k$**: We gain no utility from item $k$ and use no resources. The total utility is the maximum we could obtain from the first $k-1$ items with the same resources.\n    Utility: $V_{k-1}(c, b)$.\n\n2.  **Pack item $k$**: This is feasible only if $c \\ge w_k$. The utility from this action is $u_k$ plus the maximum utility from the first $k-1$ items with the remaining capacity $c-w_k$ and budget $b$.\n    Utility: $u_k + V_{k-1}(c-w_k, b)$.\n\n3.  **Ship item $k$**: This is feasible only if $b \\ge s_k$. The utility from this action is the pre-calculated realized shipping utility $u_{k, \\text{ship}}$ plus the maximum utility from the first $k-1$ items with capacity $c$ and remaining budget $b-s_k$. The realized shipping utility is given by:\n    $$\n    u_{k, \\text{ship}} = \\begin{cases} u_k \\cdot \\alpha^{\\max\\{0, L_k-D\\}} & \\text{if } \\max\\{0, L_k-D\\} < T \\\\ 0 & \\text{otherwise} \\end{cases}\n    $$\n    Total Utility: $u_{k, \\text{ship}} + V_{k-1}(c, b-s_k)$.\n\n4.  **Buy item $k$**: This is feasible only if $b \\ge b_k$. The utility is $u_k$ plus the maximum utility from the first $k-1$ items with capacity $c$ and remaining budget $b-b_k$.\n    Total Utility: $u_k + V_{k-1}(c, b-b_k)$.\n\nAccording to the principle of optimality, $V_k(c, b)$ is the maximum value achievable across all feasible choices for item $k$. The recurrence relation is therefore:\n$$\nV_k(c, b) = \\max \\begin{cases}\nV_{k-1}(c, b) & \\text{(skip)} \\\\\nu_k + V_{k-1}(c-w_k, b) & \\text{if } c \\ge w_k \\text{ (pack)} \\\\\nu_{k, \\text{ship}} + V_{k-1}(c, b-s_k) & \\text{if } b \\ge s_k \\text{ (ship)} \\\\\nu_k + V_{k-1}(c, b-b_k) & \\text{if } b \\ge b_k \\text{ (buy)}\n\\end{cases}\n$$\nThe `max` function is taken over all choices that are feasible for the given state $(c, b)$.\n\n**Final Answer**\nThe optimal total realized utility for all $n$ items with initial capacity $C$ and budget $B$ is given by $V_n(C, B)$.\n\n### Algorithmic Implementation\n\nA bottom-up (tabular) approach is suitable for implementing this DP recurrence. The state $V_k(c, b)$ depends only on states from the previous stage, $k-1$. This allows for a space optimization where we only need to store the DP table for two consecutive stages, $k-1$ and $k$. Let's call these `dp_prev` and `dp_curr`.\n\nThe algorithm proceeds as follows:\n1.  For each item $k=1, \\dots, n$, pre-calculate its realized shipping utility, $u_{k, \\text{ship}}$.\n2.  Initialize a 2D array, `dp_prev`, of size $(C+1) \\times (B+1)$ to all zeros. This represents the base case $V_0(c, b) = 0$.\n3.  Iterate through each item $k$ from $1$ to $n$:\n    a. Create a new 2D array, `dp_curr`, of size $(C+1) \\times (B+1)$.\n    b. Iterate through each capacity state $c$ from $0$ to $C$.\n    c. Iterate through each budget state $b$ from $0$ to $B$.\n    d. For each state $(c, b)$, calculate the utility for each of the four possible actions for item $k$, using the values stored in `dp_prev` for the subproblems.\n    e. Set `dp_curr[c][b]` to the maximum utility among the feasible actions.\n    f. After filling `dp_curr` for all $(c, b)$, update `dp_prev = dp_curr` to prepare for the next item.\n4.  After iterating through all $n$ items, the final answer is the value at `dp_prev[C][B]`.\n\nThis procedure systematically builds the optimal solution by considering one item at a time, ensuring that at each stage $k$, the table `dp_curr` stores the optimal utilities for items $1, \\dots, k$ for all possible resource levels.", "answer": "```python\nimport numpy as np\n\ndef solve_case(C, B, D, T, alpha, items):\n    \"\"\"\n    Computes the optimal total realized utility for a single test case using dynamic programming.\n\n    This function implements a bottom-up DP approach for the multiple-choice knapsack problem.\n    The state is defined by the available capacity and budget. We iterate through each item,\n    and for each item, we update the DP table to reflect the optimal choices (skip, pack,\n    ship, buy) made so far.\n    \"\"\"\n    \n    # dp_table[c][b] will store the maximum utility for capacity c and budget b.\n    # We use float64 for precision with utility values.\n    dp_table = np.zeros((C + 1, B + 1), dtype=np.float64)\n\n    # Process each item one by one\n    for item in items:\n        w, u, s, b_cost, L = item['w'], item['u'], item['s'], item['b'], item['L']\n\n        # Pre-calculate the realized utility from shipping\n        delay = max(0, L - D)\n        u_ship = 0.0\n        if delay < T:\n            u_ship = u * (alpha ** delay)\n\n        # Create a new DP table for the current stage (after considering this item)\n        # It's initialized with the previous stage's values, representing the 'skip' option.\n        dp_next = dp_table.copy()\n\n        # Update dp_next based on the three other actions: pack, ship, buy.\n        # This requires accessing the previous state's table (dp_table).\n\n        # Option: Pack item\n        if w > 0: # Optimization: only loop if packing consumes resources\n            for c in range(w, C + 1):\n                # The update here is for all budget levels b\n                dp_next[c, :] = np.maximum(dp_next[c, :], u + dp_table[c - w, :])\n\n        # Option: Ship item\n        if s > 0: # Optimization\n            if u_ship > 0:\n                for b_budget in range(s, B + 1):\n                    # The update here is for all capacity levels c\n                    dp_next[:, b_budget] = np.maximum(dp_next[:, b_budget], u_ship + dp_table[:, b_budget - s])\n\n        # Option: Buy item\n        if b_cost > 0: # Optimization\n            for b_budget in range(b_cost, B + 1):\n                # The update here is for all capacity levels c\n                dp_next[:, b_budget] = np.maximum(dp_next[:, b_budget], u + dp_table[:, b_budget - b_cost])\n\n        # Move to the next stage by updating the main DP table\n        dp_table = dp_next\n\n    # The final answer is the max utility achievable with the full capacity C and budget B\n    optimal_utility = dp_table[C, B]\n    \n    return round(optimal_utility, 2)\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the solver for each, printing the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"C\": 5, \"B\": 25, \"D\": 2, \"T\": 5, \"alpha\": 0.8,\n            \"items\": [\n                {'w': 3, 'u': 20, 's': 12, 'b': 15, 'L': 1},\n                {'w': 2, 'u': 18, 's': 15, 'b': 25, 'L': 3},\n                {'w': 1, 'u': 6, 's': 3, 'b': 4, 'L': 2},\n                {'w': 4, 'u': 30, 's': 20, 'b': 100, 'L': 5}\n            ]\n        },\n        {\n            \"C\": 0, \"B\": 6, \"D\": 1, \"T\": 3, \"alpha\": 0.7,\n            \"items\": [\n                {'w': 2, 'u': 14, 's': 5, 'b': 16, 'L': 1},\n                {'w': 1, 'u': 5, 's': 2, 'b': 6, 'L': 2},\n                {'w': 3, 'u': 12, 's': 4, 'b': 20, 'L': 3}\n            ]\n        },\n        {\n            \"C\": 4, \"B\": 0, \"D\": 2, \"T\": 2, \"alpha\": 0.9,\n            \"items\": [\n                {'w': 1, 'u': 4, 's': 1, 'b': 3, 'L': 2},\n                {'w': 3, 'u': 16, 's': 5, 'b': 50, 'L': 1},\n                {'w': 1, 'u': 2, 's': 1, 'b': 2, 'L': 3}\n            ]\n        },\n        {\n            \"C\": 2, \"B\": 5, \"D\": 1, \"T\": 2, \"alpha\": 0.5,\n            \"items\": [\n                {'w': 1, 'u': 6, 's': 2, 'b': 8, 'L': 5},\n                {'w': 1, 'u': 3, 's': 1, 'b': 4, 'L': 1},\n                {'w': 2, 'u': 5, 's': 3, 'b': 7, 'L': 4}\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case[\"C\"], case[\"B\"], case[\"D\"], case[\"T\"], case[\"alpha\"], case[\"items\"])\n        results.append(result)\n\n    # Format output as required: [r1,r2,...] with 2 decimal places.\n    formatted_results = ','.join(f'{r:.2f}' for r in results)\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "2443405"}, {"introduction": "Moving from resource allocation to optimal navigation, this practice explores pathfinding under multiple, competing objectives. While finding the shortest path is a standard problem, real-world logistics often involve minimizing one cost, like energy, while adhering to a strict budget on another, like a consumable resource. This challenge [@problem_id:2443368] requires you to adapt standard search algorithms by applying a core dynamic programming insight: augmenting the definition of a 'state' to include the consumed resource, thereby correctly applying the principle of optimality to a constrained environment.", "problem": "A vehicle must determine an optimal path on a discrete grid to minimize an additive energy criterion subject to a cumulative oxygen resource constraint. All quantities are dimensionless scalars. The environment is a rectangular grid with indices $(i,j)$, where $i \\in \\{0,\\dots,N-1\\}$ and $j \\in \\{0,\\dots,M-1\\}$, and each grid cell has a nonnegative depth value $D_{i,j}$. From any cell $(i,j)$, the vehicle may move in one discrete step to any of its four axis-aligned neighbors $(i \\pm 1,j)$ or $(i,j \\pm 1)$ that remain within the grid. A step from $(i,j)$ to a neighbor $(i',j')$ incurs energy cost $c_{E}(i',j') = \\alpha + \\beta \\, D_{i',j'}$ and oxygen consumption $c_{O}(i',j') = \\mu + \\nu \\, D_{i',j'}$, where $\\alpha,\\beta,\\mu,\\nu$ are given nonnegative parameters. A path is a finite sequence of grid cells $(x_{0},x_{1},\\dots,x_{L})$ with $x_{0} = s$ (start) and $x_{L} = g$ (goal), each $x_{\\ell+1}$ a valid neighbor of $x_{\\ell}$. The objective is to minimize total energy $\\sum_{\\ell=0}^{L-1} c_{E}(x_{\\ell+1})$ subject to the oxygen constraint $\\sum_{\\ell=0}^{L-1} c_{O}(x_{\\ell+1}) \\leq O_{\\max}$, where $O_{\\max}$ is a given nonnegative integer. If no feasible path exists, the instance is infeasible.\n\nFormally, given $D \\in \\mathbb{R}_{\\ge 0}^{N \\times M}$, parameters $\\alpha,\\beta,\\mu,\\nu \\in \\mathbb{R}_{\\ge 0}$, an integer oxygen budget $O_{\\max} \\in \\mathbb{Z}_{\\ge 0}$, and grid coordinates $s=(i_{s},j_{s})$, $g=(i_{g},j_{g})$, compute the minimal energy value\n$$\nE^{\\star} \\;=\\; \\min_{(x_{0},\\dots,x_{L})} \\;\\sum_{\\ell=0}^{L-1} \\big(\\alpha + \\beta \\, D_{x_{\\ell+1}}\\big)\n\\quad\\text{subject to}\\quad x_{0}=s,\\; x_{L}=g,\\; x_{\\ell+1}\\in \\mathcal{N}(x_{\\ell}),\n\\;\\sum_{\\ell=0}^{L-1} \\big(\\mu + \\nu \\, D_{x_{\\ell+1}}\\big) \\le O_{\\max},\n$$\nwhere $\\mathcal{N}(i,j)=\\{(i\\pm 1,j),(i,j\\pm 1)\\}$ intersected with the grid, and $D_{x}$ denotes $D$ evaluated at cell $x$. If no feasible path exists, define $E^{\\star}=+\\infty$.\n\nYour program must solve the instances in the following test suite and output a single line containing the list of minimal energies for each instance, as floats, using $+\\infty$ to denote infeasibility:\n\n- Test case $\\mathbf{A}$:\n  - Grid size $N = 4$, $M = 4$ with depth matrix\n    $$\n    D^{(A)} \\;=\\;\n    \\begin{bmatrix}\n    4 & 3 & 4 & 5\\\\\n    5 & 2 & 2 & 3\\\\\n    6 & 4 & 1 & 2\\\\\n    7 & 5 & 3 & 1\n    \\end{bmatrix}.\n    $$\n  - Parameters: $\\alpha = 1$, $\\beta = 1$, $\\mu = 1$, $\\nu = 0$.\n  - Start $s=(0,0)$, Goal $g=(3,3)$, Oxygen budget $O_{\\max}=7$.\n\n- Test case $\\mathbf{B}$: identical to Test case $\\mathbf{A}$ except oxygen budget $O_{\\max}=6$.\n\n- Test case $\\mathbf{C}$: identical to Test case $\\mathbf{A}$ except oxygen budget $O_{\\max}=5$.\n\n- Test case $\\mathbf{D}$:\n  - Grid size $N = 4$, $M = 4$ with depth matrix\n    $$\n    D^{(D)} \\;=\\;\n    \\begin{bmatrix}\n    5 & 5 & 5 & 5\\\\\n    5 & 1 & 1 & 5\\\\\n    5 & 1 & 5 & 5\\\\\n    5 & 1 & 1 & 1\n    \\end{bmatrix}.\n    $$\n  - Parameters: $\\alpha = 1$, $\\beta = 2$, $\\mu = 1$, $\\nu = 1$.\n  - Start $s=(0,0)$, Goal $g=(3,3)$, Oxygen budget $O_{\\max}=24$.\n\nRequirements for output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $\\mathbf{A},\\mathbf{B},\\mathbf{C},\\mathbf{D}$, for example, $\"[e_{A},e_{B},e_{C},e_{D}]\"$ where each $e_{\\cdot}$ is a floating-point number and infeasibility is represented by $+\\infty$ as the floating-point constant.", "solution": "The user has provided a problem statement that requires validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Grid Environment**: A discrete grid of size $N \\times M$ with cells $(i,j)$ for $i \\in \\{0, \\dots, N-1\\}$ and $j \\in \\{0, \\dots, M-1\\}$. Each cell has a non-negative depth $D_{i,j}$.\n- **Vehicle Dynamics**: Movement is restricted to four axis-aligned neighbors. A step to cell $(i', j')$ incurs an energy cost $c_{E}(i',j') = \\alpha + \\beta D_{i',j'}$ and oxygen cost $c_{O}(i',j') = \\mu + \\nu D_{i',j'}$.\n- **Parameters**: $\\alpha, \\beta, \\mu, \\nu$ are non-negative real numbers.\n- **Objective**: Minimize the total energy $\\sum_{\\ell=0}^{L-1} c_{E}(x_{\\ell+1})$ for a path $(x_0, \\dots, x_L)$ from a start cell $s$ to a goal cell $g$.\n- **Constraint**: The total oxygen consumption must not exceed a given non-negative integer budget $O_{\\max}$, i.e., $\\sum_{\\ell=0}^{L-1} c_{O}(x_{\\ell+1}) \\le O_{\\max}$.\n- **Infeasibility**: If no path satisfying the constraint exists, the minimum energy is defined as $+\\infty$.\n- **Test Cases**: Four specific instances (A, B, C, D) are provided, defining the grid size, depth matrix $D$, cost parameters, start/goal coordinates, and oxygen budget $O_{\\max}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific Grounding**: The problem is a Constrained Shortest Path Problem (CSPP) on a graph. This is a fundamental and well-studied topic in computer science, operations research, and related disciplines. The formulation is mathematically rigorous and based on established principles of discrete optimization. The problem is scientifically sound.\n2.  **Well-Posedness**: The state space (grid) is finite, and all step costs are non-negative due to the non-negativity of parameters and depths. This prevents issues like negative-cost cycles that could make a shortest-path problem ill-posed. For the given test cases, oxygen costs are integers, and the oxygen budget $O_{\\max}$ is an integer, leading to a discrete and finite state space for a dynamic programming approach. A unique minimum energy value exists, or it can be proven that no feasible path exists. The problem is well-posed.\n3.  **Objectivity**: The problem is formulated with precise mathematical definitions and objective, numerical data. It is free from subjective or ambiguous language.\n4.  **Completeness and Consistency**: All required data for solving the problem (grid dimensions, depths, parameters, start/goal, budget) are provided for each test case. There are no contradictions in the problem statement.\n5.  **Realism and Feasibility**: The problem is an abstract optimization model. Its components (grid, costs, constraints) are standard and do not represent any scientifically implausible or physically impossible conditions.\n6.  **Structure**: The problem is well-structured and does not contain circular reasoning or ambiguities. The use of $+\\infty$ for infeasibility is a standard convention.\n7.  **Relevance**: The problem is an application of dynamic programming and is directly related to the principle of optimality, which is a core concept in computational economics for solving sequential decision-making problems under constraints.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Solution Derivation\nThe problem is to find a path in a grid that minimizes one cumulative cost (energy) subject to an upper-bound constraint on a second cumulative cost (oxygen). This is a classic instance of the Constrained Shortest Path Problem. While CSPP is NP-hard in the general case, the integer nature of the oxygen costs in the provided test cases allows for a pseudo-polynomial time solution using dynamic programming, which is an embodiment of the principle of optimality.\n\nThe principle of optimality states that an optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision. In our context, an optimal path to a cell $(i,j)$ with a certain oxygen consumption is composed of an optimal path to a neighboring cell with a correspondingly lower oxygen consumption, followed by a single optimal step.\n\nThis suggests that a state in our system cannot be defined by grid position $(i,j)$ alone. The path taken to reach $(i,j)$ matters because it determines the amount of oxygen consumed. Therefore, we augment the state to include the consumed resource. Let a state be represented by the tuple $(i, j, o)$, signifying that the vehicle is at cell $(i,j)$ having consumed exactly $o$ units of oxygen.\n\nLet $E[i, j, o]$ be the minimum energy required to reach state $(i,j,o)$. Our goal is to compute $\\min_{0 \\le o \\le O_{\\max}} E[i_g, j_g, o]$, where $(i_g, j_g)$ are the coordinates of the goal cell $g$.\n\nWe can solve this problem by adapting Dijkstra's algorithm to find the shortest path on an expanded state-space graph. The nodes of this graph are the states $(i, j, o)$, and the \"length\" of a path is its total energy cost.\n\nThe algorithm proceeds as follows:\n1.  **Initialization**: We use a 3D array, `min_energy[N][M][O_max + 1]`, to store the minimum energy $E[i, j, o]$ for each state. All entries are initialized to $+\\infty$. For the starting cell $s=(i_s, j_s)$, we set `min_energy[i_s][j_s][0] = 0`, as reaching the start requires zero energy and consumes zero oxygen. A priority queue, `pq`, is initialized with the starting state: `(energy=0, i=i_s, j=j_s, oxygen=0)`.\n\n2.  **Iteration**: The algorithm repeatedly extracts the state $(e, i, j, o)$ with the minimum energy $e$ from the priority queue. If this energy $e$ is greater than the already known minimum energy to reach state $(i,j,o)$, we discard it as it represents a suboptimal path. Otherwise, we explore all valid neighbors $(i', j')$ of the cell $(i,j)$.\n\n3.  **State Transition (Relaxation)**: For each neighbor $(i', j')$, we calculate the incremental costs:\n    - Energy cost: $\\Delta E = \\alpha + \\beta D_{i',j'}$\n    - Oxygen cost: $\\Delta O = \\mu + \\nu D_{i',j'}$\n    The new state would be $(i', j', o + \\Delta O)$ with a total energy of $e + \\Delta E$.\n\n4.  **Constraint and Update**: We check if the new total oxygen $o' = o + \\Delta O$ exceeds the budget $O_{\\max}$. If it does, this path is infeasible and is ignored. Otherwise, if the new total energy $e' = e + \\Delta E$ is less than the current value of `min_energy[i'][j'][o']`, we have found a better path to the state $(i', j', o')$. We update `min_energy[i'][j'][o'] = e'$ and add the new state $(e', i', j', o')$ to the priority queue.\n\n5.  **Termination and Result**: The algorithm terminates when the priority queue is empty. The minimum energy to reach the goal cell $g=(i_g, j_g)$ is then the minimum value in `min_energy[i_g][j_g][o]` over all possible oxygen levels $o \\in \\{0, \\dots, O_{\\max}\\}$. If this minimum remains $+\\infty$, it signifies that the goal is unreachable within the given oxygen budget.\n\nThe computational complexity of this algorithm is determined by Dijkstra's algorithm on the expanded state space. The number of states is $N \\times M \\times (O_{\\max} + 1)$, and each state has at most 4 transitions. The complexity is $O(N \\cdot M \\cdot O_{\\max} \\cdot \\log(N \\cdot M \\cdot O_{\\max}))$, which is efficient for the scale of the provided test cases.", "answer": "```python\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Main function to define, solve, and print results for all test cases.\n    \"\"\"\n\n    def solve_case(N, M, D, alpha, beta, mu, nu, s, g, O_max):\n        \"\"\"\n        Solves a single instance of the constrained shortest path problem.\n\n        This function uses a Dijkstra-like algorithm on an expanded state space,\n        where a state is defined by (row, column, oxygen_consumed). The priority\n        queue stores tuples of (energy, row, col, oxygen), ordered by energy.\n        \"\"\"\n        # min_energy[i, j, o] stores the minimum energy to reach cell (i, j)\n        # having consumed exactly 'o' units of oxygen.\n        min_energy = np.full((N, M, O_max + 1), np.inf, dtype=np.float64)\n\n        start_i, start_j = s\n        goal_i, goal_j = g\n\n        # Initial state: at the start cell with 0 energy and 0 oxygen consumed.\n        min_energy[start_i, start_j, 0] = 0.0\n        \n        # Priority queue stores tuples of (energy, i, j, oxygen_consumed).\n        # It's ordered by energy to always expand the path with the lowest energy first.\n        pq = [(0.0, start_i, start_j, 0)]\n\n        while pq:\n            energy, i, j, o = heapq.heappop(pq)\n\n            # If we've already found a better path to this state, skip.\n            if energy > min_energy[i, j, o]:\n                continue\n\n            # Explore the four axis-aligned neighbors.\n            for di, dj in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                ni, nj = i + di, j + dj\n\n                # Check if the neighbor is within the grid boundaries.\n                if 0 <= ni < N and 0 <= nj < M:\n                    # Costs are incurred upon entering the new cell (ni, nj).\n                    energy_step = alpha + beta * D[ni, nj]\n                    oxygen_step = mu + nu * D[ni, nj]\n\n                    # For this problem, oxygen costs are guaranteed to be integers.\n                    oxygen_step_int = int(oxygen_step)\n\n                    new_energy = energy + energy_step\n                    new_oxygen = o + oxygen_step_int\n\n                    # If the path is feasible (within oxygen budget) and improves\n                    # upon a known path to the new state, update and push to queue.\n                    if new_oxygen <= O_max:\n                        if new_energy < min_energy[ni, nj, new_oxygen]:\n                            min_energy[ni, nj, new_oxygen] = new_energy\n                            heapq.heappush(pq, (new_energy, ni, nj, new_oxygen))\n\n        # The final minimum energy is the minimum over all possible oxygen\n        # levels at the goal cell.\n        result = np.min(min_energy[goal_i, goal_j, :])\n        return float(result)\n\n    # Test Case A\n    D_A = np.array([[4, 3, 4, 5], [5, 2, 2, 3], [6, 4, 1, 2], [7, 5, 3, 1]])\n    params_A = (1, 1, 1, 0)\n    s_A, g_A = (0, 0), (3, 3)\n    O_max_A = 7\n    res_A = solve_case(4, 4, D_A, *params_A, s_A, g_A, O_max_A)\n\n    # Test Case B (identical to A, but O_max = 6)\n    O_max_B = 6\n    res_B = solve_case(4, 4, D_A, *params_A, s_A, g_A, O_max_B)\n\n    # Test Case C (identical to A, but O_max = 5)\n    O_max_C = 5\n    res_C = solve_case(4, 4, D_A, *params_A, s_A, g_A, O_max_C)\n\n    # Test Case D\n    D_D = np.array([[5, 5, 5, 5], [5, 1, 1, 5], [5, 1, 5, 5], [5, 1, 1, 1]])\n    params_D = (1, 2, 1, 1)\n    s_D, g_D = (0, 0), (3, 3)\n    O_max_D = 24\n    res_D = solve_case(4, 4, D_D, *params_D, s_D, g_D, O_max_D)\n\n    results = [res_A, res_B, res_C, res_D]\n    \n    # Format the final output as a comma-separated list in brackets.\n    # The `str` function correctly handles `np.inf` by converting it to 'inf'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2443368"}, {"introduction": "Our final practice in this chapter delves into a central topic in computational economics: dynamic pricing. In many markets, a firm's pricing decisions have consequences that ripple into the future, as consumers form 'reference prices' based on past observations. This exercise [@problem_id:2443432] models this phenomenon, where today's price not only determines current profit but also shapes future demand. You will tackle this intertemporal trade-off using backward induction, a powerful technique that solves for the optimal strategy by starting from the final period and working backward in time.", "problem": "A single-product firm sets intertemporal prices to maximize discounted profits when consumers form a reference price based on the last $k$ prices charged by the firm. Time is discrete, with periods indexed by $t \\in \\{1,2,\\ldots,T\\}$. In period $t$, the firm chooses a price $p_t$ from a finite admissible set $\\mathcal{P} = \\{0,1,2,\\ldots,10\\}$. Let the reference price be the simple average of the last $k$ realized prices prior to period $t$, denoted by $r_t = \\frac{1}{k}\\sum_{j=1}^{k} p_{t-j}$, where the pre-sample history $\\left(p_{0},p_{-1},\\ldots,p_{-(k-1)}\\right)$ is given. Demand in period $t$ is\n$$\nq_t = \\max\\left\\{0,\\, a - b\\,p_t + \\gamma\\,(r_t - p_t)\\right\\},\n$$\nand the period profit is\n$$\n\\pi_t = (p_t - c)\\,q_t.\n$$\nThe firm’s objective is to choose the sequence $\\{p_t\\}_{t=1}^T$ to maximize the discounted sum of profits\n$$\n\\sum_{t=1}^{T} \\beta^{t-1}\\,\\pi_t,\n$$\nwhere $a>0$, $b>0$, $\\gamma \\ge 0$, $c \\ge 0$, $T \\in \\mathbb{N}$, $k \\in \\mathbb{N}$, and $\\beta \\in (0,1]$ are given parameters. The state of the system at the start of period $t$ is the ordered $k$-tuple of the last $k$ realized prices $\\left(p_{t-1},p_{t-2},\\ldots,p_{t-k}\\right)$. State transitions are deterministic: after choosing $p_t$, the next state becomes $\\left(p_t,p_{t-1},\\ldots,p_{t-k+1}\\right)$.\n\nAmong multiple profit-maximizing sequences, select the sequence that chooses the smallest admissible price at the earliest period where a tie occurs. Equivalently, at every period $t$ and for every state, if multiple $p_t \\in \\mathcal{P}$ yield the same maximized objective value, select the smallest such $p_t$.\n\nFor each parameterization in the test suite below, compute the optimal price sequence $\\{p_t^\\star\\}_{t=1}^T$. No physical units apply. Your program must output only a single line containing all results aggregated as a list of lists, with each inner list containing the $T$ optimal prices for that test case in temporal order, and with no spaces. For example, the output format must be exactly of the form\n$$\n[[p_1^\\star,\\ldots,p_T^\\star],[\\ldots],\\ldots].\n$$\n\nTest suite:\n- Case $1$ (general case): $T=3$, $k=2$, $a=12$, $b=1.5$, $\\gamma=0.8$, $c=2$, $\\beta=0.95$, initial history $\\left(p_{0},p_{-1}\\right) = (4,6)$, $\\mathcal{P}=\\{0,1,2,\\ldots,10\\}$.\n- Case $2$ (single-period boundary): $T=1$, $k=3$, $a=8$, $b=1$, $\\gamma=0.5$, $c=1$, $\\beta=0.9$, initial history $\\left(p_{0},p_{-1},p_{-2}\\right) = (2,2,2)$, $\\mathcal{P}=\\{0,1,2,\\ldots,10\\}$.\n- Case $3$ (strong reference effect, minimal memory): $T=4$, $k=1$, $a=10$, $b=2$, $\\gamma=2$, $c=3$, $\\beta=0.9$, initial history $\\left(p_{0}\\right) = (5)$, $\\mathcal{P}=\\{0,1,2,\\ldots,10\\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of the three optimal price sequences, each enclosed in square brackets and with no spaces, in the order of the cases above. For example, the required output pattern is\n$$\n[[\\cdot,\\cdot,\\cdot],[\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]].\n$$", "solution": "The problem as stated is valid. It is a well-posed, finite-horizon, deterministic dynamic programming problem from the field of computational economics, free of any scientific or logical flaws. A unique optimal solution exists and can be computed using the principle of optimality.\n\nThe firm's objective is to find a price sequence $\\{p_t\\}_{t=1}^T$ that maximizes the total discounted profit. This problem can be solved using dynamic programming, for which we define the standard components.\n\n1.  **State**: The state of the system at the beginning of period $t$ must encapsulate all information from the past that is relevant for future decisions. In this model, the future profit depends on the next reference price, which in turn depends on the recent price history. Therefore, the state at time $t$ is the ordered $k$-tuple of the last $k$ prices, $S_t = (p_{t-1}, p_{t-2}, \\ldots, p_{t-k})$. The state space is discrete and finite, consisting of $|\\mathcal{P}|^k$ possible states, where $|\\mathcal{P}| = 11$.\n\n2.  **Action**: In each period $t$, the firm chooses an action, which is the price $p_t$. The set of admissible actions is the finite set $\\mathcal{P} = \\{0, 1, 2, \\ldots, 10\\}$.\n\n3.  **Reward Function**: The reward in period $t$ is the profit $\\pi_t$. This profit depends on the current state $S_t$ (which determines the reference price $r_t$) and the chosen action $p_t$. The reference price is $r_t = \\frac{1}{k}\\sum_{j=1}^{k} p_{t-j}$. The profit function is $\\pi_t(S_t, p_t) = (p_t - c)q_t$, where the demand is $q_t = \\max\\{0, a - bp_t + \\gamma(r_t - p_t)\\}$. This can be rewritten as $q_t = \\max\\{0, a + \\gamma r_t - (b+\\gamma)p_t\\}$.\n\n4.  **State Transition**: The system is deterministic. If the state at time $t$ is $S_t = (p_{t-1}, \\ldots, p_{t-k})$ and the firm chooses price $p_t$, the state at time $t+1$ becomes $S_{t+1} = (p_t, p_{t-1}, \\ldots, p_{t-k+1})$.\n\nLet $V_t(S_t)$ be the maximum discounted profit from period $t$ to the end of the horizon $T$, given the state is $S_t$. The principle of optimality is expressed through the Bellman equation:\n$$\nV_t(S_t) = \\max_{p_t \\in \\mathcal{P}} \\left\\{ \\pi_t(S_t, p_t) + \\beta V_{t+1}(S_{t+1}) \\right\\}\n$$\nfor $t=1, \\ldots, T$. The terminal condition is that there are no future profits after period $T$, so $V_{T+1}(S) = 0$ for any state $S$.\n\nThe problem is solved algorithmically using backward induction:\n\n1.  **Initialization (Period $t=T$):** We begin at the final period $T$. For each possible state $S_T = (p_{T-1}, \\ldots, p_{T-k})$, we solve for the optimal price $p_T^*(S_T)$:\n    $$\n    V_T(S_T) = \\max_{p_T \\in \\mathcal{P}} \\{ \\pi_T(S_T, p_T) \\}\n    $$\n    We compute the profit for each $p_T \\in \\mathcal{P}$ and find the price that yields the maximum profit. The tie-breaking rule dictates that we must select the smallest price if multiple prices yield the same maximum value. We store this optimal price in a policy function, $\\Pi_T(S_T) = p_T^*(S_T)$, and the corresponding maximum value in the value function, $V_T(S_T)$. This is done for all possible states in the state space.\n\n2.  **Recursive Step (Periods $t = T-1, \\ldots, 1$):** We step backward one period at a time. For each period $t$ and each state $S_t$, we find the optimal price $p_t^*(S_t)$ by solving the Bellman equation:\n    $$\n    V_t(S_t) = \\max_{p_t \\in \\mathcal{P}} \\left\\{ \\pi_t(S_t, p_t) + \\beta V_{t+1}((p_t, p_{t-1}, \\ldots, p_{t-k+1})) \\right\\}\n    $$\n    For each candidate price $p_t \\in \\mathcal{P}$, we calculate the immediate profit $\\pi_t(S_t, p_t)$ and add the discounted future value $\\beta V_{t+1}(S_{t+1})$, where the future value $V_{t+1}$ has already been computed in the previous step of the induction. The price $p_t$ that maximizes this sum is chosen as the optimal policy $\\Pi_t(S_t)$, again respecting the tie-breaking rule. The maximized sum is stored as $V_t(S_t)$.\n\n3.  **Optimal Path Reconstruction:** After the backward induction is complete, we have the optimal policy $\\Pi_t(S_t)$ for all $t \\in \\{1, \\ldots, T\\}$ and all states $S_t$. To find the optimal price sequence, we perform a forward pass:\n    - Start with the given initial state $S_1 = (p_0, p_{-1}, \\ldots, p_{-(k-1)})$.\n    - The first optimal price is $p_1^* = \\Pi_1(S_1)$.\n    - The state for the next period is $S_2 = (p_1^*, p_0, \\ldots, p_{-(k-2)})$.\n    - The second optimal price is $p_2^* = \\Pi_2(S_2)$.\n    - This process is repeated until $t=T$, yielding the optimal price sequence $\\{p_1^*, p_2^*, \\ldots, p_T^*\\}$.\n\nThis algorithm is implemented by using dictionaries to map state tuples to their values and optimal policies. The finite state space for each period is generated by taking the Cartesian product of the admissible price set $\\mathcal{P}$ with itself $k$ times.", "answer": "```python\nimport numpy as np\nfrom itertools import product\n\ndef solve():\n    \"\"\"\n    Main function to solve the dynamic pricing problem for all test cases\n    and print the results in the specified format.\n    \"\"\"\n\n    def solve_case(T, k, a, b, gamma, c, beta, initial_history):\n        \"\"\"\n        Solves a single instance of the dynamic pricing problem using backward induction.\n        \"\"\"\n        P_set = list(range(11))\n        \n        # The state is a tuple of the last k prices.\n        # Handle k=0 case for generality, though problem states k>=1.\n        all_states = list(product(P_set, repeat=k)) if k > 0 else [()]\n        \n        # V: Value function memoization table, V[t][state] = max_profit\n        # policy: Policy function table, policy[t][state] = optimal_price\n        V = {}\n        policy = {}\n\n        # Initialize value function at the terminal time T+1 to zero.\n        V[T + 1] = {s: 0.0 for s in all_states}\n\n        # Backward induction from T down to 1\n        for t in range(T, 0, -1):\n            V[t] = {}\n            policy[t] = {}\n            for state in all_states:\n                # state = (p_{t-1}, ..., p_{t-k})\n                r_t = np.mean(state) if k > 0 else 0.0\n                \n                # Evaluate the value for each possible price p_t\n                p_values = {}\n                for p_t in P_set:\n                    q_t = max(0, a + gamma * r_t - (b + gamma) * p_t)\n                    profit_t = (p_t - c) * q_t\n                    \n                    next_state = (p_t,) + state[:-1] if k > 0 else ()\n                    \n                    # Bellman equation\n                    value = profit_t + beta * V[t + 1][next_state]\n                    p_values[p_t] = value\n                \n                # Find the maximum value among all possible prices\n                max_value = -float('inf')\n                for p_t in P_set:\n                    if p_values[p_t] > max_value:\n                        max_value = p_values[p_t]\n\n                # Find the smallest price that achieves the maximum value (tie-breaking)\n                best_p = -1\n                for p_t in P_set:\n                    if np.isclose(p_values[p_t], max_value):\n                        best_p = p_t\n                        break\n                \n                V[t][state] = max_value\n                policy[t][state] = best_p\n\n        # Forward pass to reconstruct the optimal price path\n        optimal_path = []\n        current_state = initial_history\n        for t in range(1, T + 1):\n            optimal_p = policy[t][current_state]\n            optimal_path.append(optimal_p)\n            current_state = (optimal_p,) + current_state[:-1] if k > 0 else ()\n\n        return optimal_path\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'T': 3, 'k': 2, 'a': 12, 'b': 1.5, 'gamma': 0.8, 'c': 2, 'beta': 0.95, 'initial_history': (4, 6)},\n        {'T': 1, 'k': 3, 'a': 8, 'b': 1, 'gamma': 0.5, 'c': 1, 'beta': 0.9, 'initial_history': (2, 2, 2)},\n        {'T': 4, 'k': 1, 'a': 10, 'b': 2, 'gamma': 2, 'c': 3, 'beta': 0.9, 'initial_history': (5,)},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = solve_case(**params)\n        results.append(result)\n\n    # Format the output string exactly as required, with no spaces.\n    formatted_results = [f\"[{','.join(map(str, r))}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2443432"}]}