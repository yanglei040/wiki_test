{"hands_on_practices": [{"introduction": "The Generalized Method of Moments (GMM) is a powerful and flexible estimation framework. This first exercise provides a clean, analytical derivation to reveal its core logic: defining a parameter by a set of moment conditions and find the estimate that makes the sample equivalents of these conditions as close to zero as possible. By tackling a unique case involving circular data [@problem_id:2397110], you can focus on the fundamental mechanics of GMM without the typical distractions of linear models, strengthening your grasp of the underlying principles.", "problem": "Consider a setting in computational finance where cyclical behavior is modeled on the unit circle. You observe $T$ independent and identically distributed angles $X_1, X_2, \\ldots, X_T \\in (-\\pi, \\pi]$ that represent the phase of a latent cyclical factor in intraday market activity. The true phase parameter is $\\theta \\in (-\\pi, \\pi]$. The structural moment condition implied by the model is\n$$\n\\mathbb{E}\\!\\left[\\sin(X_t - \\theta)\\right] = 0.\n$$\nUsing the Generalized Method of Moments (GMM) with the identity weighting matrix (a scalar equal to $1$), derive the estimator $\\hat{\\theta}_T$ as a closed-form analytic expression in terms of the sample $\\{X_t\\}_{t=1}^T$. Assume that $\\sum_{t=1}^{T} \\cos(X_t) > 0$ so that the estimator is uniquely pinned down in the principal value range $(-\\pi, \\pi]$. Provide your final answer as a single analytic expression. No rounding is required, and no units are applicable.", "solution": "The problem requires the derivation of a Generalized Method of Moments (GMM) estimator. A rigorous validation of the problem statement is the mandatory first step.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Data**: $T$ independent and identically distributed (i.i.d.) observations of angles, $\\{X_t\\}_{t=1}^T$, where each $X_t \\in (-\\pi, \\pi]$.\n*   **Parameter**: The true parameter is $\\theta \\in (-\\pi, \\pi]$.\n*   **Moment Condition**: The population moment condition is $\\mathbb{E}\\!\\left[\\sin(X_t - \\theta)\\right] = 0$.\n*   **GMM Setup**: The weighting matrix is the identity, which in this scalar case is $W=1$.\n*   **Assumption**: It is given that $\\sum_{t=1}^{T} \\cos(X_t) > 0$.\n*   **Objective**: Derive the estimator $\\hat{\\theta}_T$ as a closed-form analytic expression.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientific Groundedness**: The problem is formulated within the standard framework of econometric estimation (GMM). The moment condition $\\mathbb{E}[\\sin(X_t - \\theta)] = 0$ is a common and valid way to define a central parameter for circular data, such as in the von Mises distribution, where $\\theta$ represents the mean direction. The problem is scientifically sound.\n*   **Well-Posedness**: The problem seeks a unique estimator. The provided assumption, $\\sum_{t=1}^{T} \\cos(X_t) > 0$, is explicitly included to resolve the ambiguity inherent in inverting the tangent function, thereby ensuring a unique solution exists in the specified principal value range. The problem is well-posed.\n*   **Objectivity**: The problem is stated using precise mathematical language and definitions. It is entirely free of subjective or ambiguous terminology.\n*   **Completeness and Consistency**: All information required to derive the estimator is provided: the moment condition, the sample data structure, the estimation framework (GMM with a specified weight matrix), and a critical assumption for uniqueness. The setup is self-contained and free of contradictions.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. It is a well-defined statistical estimation task. I will proceed with the derivation.\n\n### Derivation of the Estimator\n\nThe Generalized Method of Moments (GMM) estimator, $\\hat{\\theta}_T$, is the a value of the parameter $\\theta$ that minimizes the GMM objective function, $J(\\theta)$. This function is a quadratic form of the sample moment conditions.\n\nThe population moment condition is given by $g(\\theta) = \\mathbb{E}[\\sin(X_t - \\theta)] = 0$.\nThe corresponding sample moment condition is its empirical analogue:\n$$\ng_T(\\theta) = \\frac{1}{T} \\sum_{t=1}^{T} \\sin(X_t - \\theta)\n$$\nThe GMM objective function is $J(\\theta) = T \\cdot g_T(\\theta)' W g_T(\\theta)$. In this problem, we have a single moment condition, so $g_T(\\theta)$ is a scalar. The weighting matrix is specified as the identity, so $W=1$. The objective function simplifies to:\n$$\nJ(\\theta) = T \\left( \\frac{1}{T} \\sum_{t=1}^{T} \\sin(X_t - \\theta) \\right)^2 = \\frac{1}{T} \\left( \\sum_{t=1}^{T} \\sin(X_t - \\theta) \\right)^2\n$$\nThe GMM estimator $\\hat{\\theta}_T$ is found by minimizing $J(\\theta)$ with respect to $\\theta$:\n$$\n\\hat{\\theta}_T = \\arg\\min_{\\theta \\in (-\\pi, \\pi]} J(\\theta)\n$$\nSince $J(\\theta)$ is a squared quantity scaled by a positive constant $1/T$, its minimum value is $0$. This minimum is achieved if and only if the term inside the square is zero. Therefore, the minimization problem is equivalent to solving the following equation for $\\theta$:\n$$\n\\sum_{t=1}^{T} \\sin(X_t - \\hat{\\theta}_T) = 0\n$$\nTo solve for $\\hat{\\theta}_T$, we apply the trigonometric identity for the sine of a difference, $\\sin(A - B) = \\sin(A)\\cos(B) - \\cos(A)\\sin(B)$:\n$$\n\\sum_{t=1}^{T} \\left[ \\sin(X_t)\\cos(\\hat{\\theta}_T) - \\cos(X_t)\\sin(\\hat{\\theta}_T) \\right] = 0\n$$\nSince $\\cos(\\hat{\\theta}_T)$ and $\\sin(\\hat{\\theta}_T)$ are constant with respect to the summation index $t$, we can factor them out:\n$$\n\\cos(\\hat{\\theta}_T) \\sum_{t=1}^{T} \\sin(X_t) - \\sin(\\hat{\\theta}_T) \\sum_{t=1}^{T} \\cos(X_t) = 0\n$$\nRearranging the terms, we get:\n$$\n\\sin(\\hat{\\theta}_T) \\sum_{t=1}^{T} \\cos(X_t) = \\cos(\\hat{\\theta}_T) \\sum_{t=1}^{T} \\sin(X_t)\n$$\nLet us define $S_T = \\sum_{t=1}^{T} \\sin(X_t)$ and $C_T = \\sum_{t=1}^{T} \\cos(X_t)$. The equation becomes $\\sin(\\hat{\\theta}_T) C_T = \\cos(\\hat{\\theta}_T) S_T$.\n\nWe must ensure we can divide to isolate $\\hat{\\theta}_T$. The problem states the assumption $C_T = \\sum_{t=1}^{T} \\cos(X_t) > 0$. This implies $C_T \\neq 0$. Furthermore, if $\\cos(\\hat{\\theta}_T) = 0$, the equation would become $\\sin(\\hat{\\theta}_T) C_T = 0$. Since $C_T \\neq 0$, this would require $\\sin(\\hat{\\theta}_T) = 0$, which is impossible as $\\sin(\\theta)$ and $\\cos(\\theta)$ are never simultaneously zero. Thus, $\\cos(\\hat{\\theta}_T) \\neq 0$.\n\nWe can safely divide both sides by $\\cos(\\hat{\\theta}_T)$ and by $C_T$:\n$$\n\\frac{\\sin(\\hat{\\theta}_T)}{\\cos(\\hat{\\theta}_T)} = \\tan(\\hat{\\theta}_T) = \\frac{\\sum_{t=1}^{T} \\sin(X_t)}{\\sum_{t=1}^{T} \\cos(X_t)}\n$$\nThis equation defines the estimator $\\hat{\\theta}_T$. To obtain a unique solution, we must correctly invert the tangent function. The equation $\\sin(\\hat{\\theta}_T) C_T = \\cos(\\hat{\\theta}_T) S_T$ implies that the vector $(\\cos(\\hat{\\theta}_T), \\sin(\\hat{\\theta}_T))$ is parallel to the vector $(C_T, S_T)$. As the magnitude of $(\\cos(\\theta), \\sin(\\theta))$ is $1$, this means $\\cos(\\hat{\\theta}_T)$ must have the same sign as $C_T$.\n\nGiven the explicit assumption $C_T = \\sum_{t=1}^{T} \\cos(X_t) > 0$, we must have $\\cos(\\hat{\\theta}_T) > 0$. This condition restricts the solution for $\\hat{\\theta}_T$ to the interval $(-\\frac{\\pi}{2}, \\frac{\\pi}{2})$. The standard arctangent function, $\\arctan(\\cdot)$, has a principal value range of precisely $(-\\frac{\\pi}{2}, \\frac{\\pi}{2})$. Therefore, the ambiguity is resolved, and the unique GMM estimator is given by:\n$$\n\\hat{\\theta}_T = \\arctan\\left(\\frac{\\sum_{t=1}^{T} \\sin(X_t)}{\\sum_{t=1}^{T} \\cos(X_t)}\\right)\n$$\nThis expression provides the closed-form analytic solution for the estimator $\\hat{\\theta}_T$ in terms of the sample data, as required.", "answer": "$$\n\\boxed{\\arctan\\left(\\frac{\\sum_{t=1}^{T} \\sin(X_t)}{\\sum_{t=1}^{T} \\cos(X_t)}\\right)}\n$$", "id": "2397110"}, {"introduction": "Moving from pure theory to a core application, we now explore how GMM is used to test economic models. This practice [@problem_id:2421339] places you in the role of a quantitative analyst evaluating an asset pricing model based on a Stochastic Discount Factor (SDF). By simulating data from a \"true\" world and then estimating a deliberately misspecified model, you will see firsthand how the GMM objective function—the foundation of the famous J-test of overidentifying restrictions—serves as a powerful tool for detecting model failure.", "problem": "You are given a discrete-time asset-pricing economy with a linear pricing kernel. Let the stochastic discount factor (SDF) be defined by the linear pricing kernel\n$$ m_{t+1} = a - b^{\\prime} f_{t+1}, $$\nwhere $a \\in \\mathbb{R}$, $b \\in \\mathbb{R}^{K}$, and $f_{t+1} \\in \\mathbb{R}^{K}$ is a vector of $K$ economic factors. The fundamental Euler equation of asset pricing states that for any gross return $R_{t+1}$,\n$$ \\mathbb{E}\\left[ m_{t+1} R_{t+1} \\right] = 1. $$\nAssume $K=2$ throughout and assume that the factor vector is Gaussian and independent across time with\n$$ f_{t+1} \\sim \\mathcal{N}(\\mu, \\Sigma), $$\nwhere $\\mu \\in \\mathbb{R}^{2}$ and $\\Sigma \\in \\mathbb{R}^{2 \\times 2}$ is positive definite.\n\nThere are $N$ risky assets with returns given by\n$$ R_{i,t+1} = c_i + d_i^{\\prime} f_{t+1} + u_{i,t+1}, \\quad i \\in \\{1,\\dots,N\\}, $$\nwhere $d_i \\in \\mathbb{R}^{2}$ is the factor loading of asset $i$, $c_i \\in \\mathbb{R}$ is a constant, and $u_{i,t+1} \\sim \\mathcal{N}(0,\\sigma_{u,i}^{2})$ are independent across $i$ and $t$, and independent of $f_{t+1}$. In addition, there is a risk-free asset with constant gross return $R_{f}$. You must determine $c_i$ and $R_f$ such that the Euler equations hold exactly under the true SDF, namely\n$$ \\mathbb{E}\\left[m_{t+1} R_{i,t+1}\\right] = 1 \\quad \\text{for all } i \\in \\{1,\\dots,N\\}, \\quad \\text{and} \\quad \\mathbb{E}\\left[m_{t+1} R_{f}\\right] = 1. $$\nAssume $u_{i,t+1}$ have known standard deviations $\\sigma_{u,i}$ and zero means.\n\nYou must simulate samples $\\{f_{t+1}\\}_{t=1}^{T}$ and $\\{u_{i,t+1}\\}_{t=1,i=1}^{T,N}$, generate $\\{R_{i,t+1}\\}$ and the constant $R_f$, and then attempt to recover the SDF using a deliberately misspecified model. Specifically, estimate parameters $\\theta = (\\alpha,\\beta) \\in \\mathbb{R}^{2}$ of the misspecified SDF\n$$ \\tilde{m}_{t+1}(\\theta) = \\alpha - \\beta \\cdot f_{1,t+1}, $$\nwhich uses only the first true factor $f_{1,t+1}$ and ignores the second true factor. Use the Generalized Method of Moments (GMM) with identity weighting matrix and the moment conditions\n$$ \\mathbb{E}\\left[\\tilde{m}_{t+1}(\\theta) R_{j,t+1}\\right] = 1, \\quad j \\in \\{0,1,\\dots,N\\}, $$\nwhere $j=0$ denotes the risk-free asset with $R_{0,t+1} \\equiv R_{f}$, and $j \\in \\{1,\\dots,N\\}$ denote the $N$ risky assets. Define the sample moments\n$$ g_{T,j}(\\theta) = \\frac{1}{T}\\sum_{t=1}^{T} \\tilde{m}_{t+1}(\\theta) R_{j,t+1} - 1, $$\nand the one-step GMM objective\n$$ J_T(\\theta) = \\sum_{j=0}^{N} \\left[g_{T,j}(\\theta)\\right]^2. $$\nFor each parameter set in the test suite, compute the minimizer $\\hat{\\theta}_T$ of $J_T(\\theta)$ over $\\theta \\in \\mathbb{R}^{2}$ and report the minimized value $J_T(\\hat{\\theta}_T)$.\n\nAll quantities are unitless. Angles are not involved. The outputs must be real numbers.\n\nTest Suite:\nEach test case specifies $(T,N,\\mu,\\Sigma,a,b,\\{d_i\\}_{i=1}^{N},\\{\\sigma_{u,i}\\}_{i=1}^{N},\\text{seed})$. For all cases below, initial prices are normalized implicitly via gross returns, $\\sigma_{u,i}$ are equal across assets and specified by a single standard deviation $\\sigma_u$, and $K=2$. In all cases, determine $R_f$ and $c_i$ endogenously by imposing the Euler equations under the true SDF.\n\n- Case A (happy path misspecification):\n  - $T = 3000$, $N = 6$, $\\text{seed} = 12345$.\n  - $\\mu = \\begin{bmatrix} 0.02 \\\\ 0.01 \\end{bmatrix}$, $\\Sigma = \\begin{bmatrix} 0.04  0.008 \\\\ 0.008  0.01 \\end{bmatrix}$.\n  - $a = 1.0$, $b = \\begin{bmatrix} 0.5 \\\\ 1.0 \\end{bmatrix}$.\n  - $d_1 = \\begin{bmatrix} 0.8 \\\\ 0.2 \\end{bmatrix}$, $d_2 = \\begin{bmatrix} 1.0 \\\\ -0.2 \\end{bmatrix}$, $d_3 = \\begin{bmatrix} -0.5 \\\\ 0.5 \\end{bmatrix}$, $d_4 = \\begin{bmatrix} 0.3 \\\\ 1.2 \\end{bmatrix}$, $d_5 = \\begin{bmatrix} 1.5 \\\\ -0.7 \\end{bmatrix}$, $d_6 = \\begin{bmatrix} -1.0 \\\\ -0.4 \\end{bmatrix}$.\n  - $\\sigma_u = 0.05$.\n\n- Case B (boundary: no price of risk on the omitted factor):\n  - $T = 3000$, $N = 6$, $\\text{seed} = 67890$.\n  - $\\mu = \\begin{bmatrix} 0.02 \\\\ 0.01 \\end{bmatrix}$, $\\Sigma = \\begin{bmatrix} 0.04  0.008 \\\\ 0.008  0.01 \\end{bmatrix}$.\n  - $a = 1.0$, $b = \\begin{bmatrix} 0.5 \\\\ 0.0 \\end{bmatrix}$.\n  - $d_1$ to $d_6$ identical to Case A.\n  - $\\sigma_u = 0.05$.\n\n- Case C (edge: highly correlated true factors):\n  - $T = 800$, $N = 6$, $\\text{seed} = 24680$.\n  - $\\mu = \\begin{bmatrix} 0.015 \\\\ 0.015 \\end{bmatrix}$, $\\Sigma = \\begin{bmatrix} 0.02  0.019 \\\\ 0.019  0.02 \\end{bmatrix}$.\n  - $a = 1.0$, $b = \\begin{bmatrix} 0.8 \\\\ 0.6 \\end{bmatrix}$.\n  - $d_1$ to $d_6$ identical to Case A.\n  - $\\sigma_u = 0.05$.\n\nFor each test case, you must:\n- Simulate $\\{f_{t+1}\\}_{t=1}^{T}$ and $\\{u_{i,t+1}\\}_{t=1,i=1}^{T,N}$ according to the specified parameters and seed.\n- Compute $R_f$ and $\\{c_i\\}$ such that the Euler equations hold exactly under the true SDF.\n- Generate $\\{R_{i,t+1}\\}$ for all risky assets using the specified linear factor structure.\n- Estimate $\\hat{\\theta}_T$ using the misspecified SDF with Generalized Method of Moments (GMM) as defined above, and compute $J_T(\\hat{\\theta}_T)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be ordered as $[J_T(\\hat{\\theta}_T)\\text{ for Case A}, J_T(\\hat{\\theta}_T)\\text{ for Case B}, J_T(\\hat{\\theta}_T)\\text{ for Case C}]$. For example, a syntactically valid output looks like $[x_1,x_2,x_3]$, where each $x_k$ is a real number.", "solution": "The problem presented is subjected to rigorous validation before any attempt at a solution is made.\n\n### Step 1: Extract Givens\nThe problem statement provides the following definitions and parameters:\n- **True Stochastic Discount Factor (SDF)**: $m_{t+1} = a - b^{\\prime} f_{t+1}$, with $a \\in \\mathbb{R}$, $b \\in \\mathbb{R}^{K}$, and number of factors $K=2$.\n- **Economic Factors**: $f_{t+1} \\sim \\mathcal{N}(\\mu, \\Sigma)$, where $f_{t+1} \\in \\mathbb{R}^{2}$, $\\mu \\in \\mathbb{R}^{2}$, and $\\Sigma \\in \\mathbb{R}^{2 \\times 2}$ is positive definite.\n- **Risky Asset Returns**: $R_{i,t+1} = c_i + d_i^{\\prime} f_{t+1} + u_{i,t+1}$ for $i \\in \\{1,\\dots,N\\}$, with $c_i \\in \\mathbb{R}$, $d_i \\in \\mathbb{R}^{2}$.\n- **Idiosyncratic Shocks**: $u_{i,t+1} \\sim \\mathcal{N}(0,\\sigma_{u,i}^{2})$, independent across assets $i$ and time $t$, and independent of $f_{t+1}$.\n- **Risk-Free Asset**: Constant gross return $R_{f}$.\n- **Euler Equations (for data generation)**: $\\mathbb{E}\\left[m_{t+1} R_{i,t+1}\\right] = 1$ and $\\mathbb{E}\\left[m_{t+1} R_{f}\\right] = 1$. These equations must be used to determine $c_i$ and $R_f$.\n- **Misspecified SDF (for estimation)**: $\\tilde{m}_{t+1}(\\theta) = \\alpha - \\beta \\cdot f_{1,t+1}$, where $\\theta = (\\alpha, \\beta) \\in \\mathbb{R}^{2}$.\n- **GMM Moment Conditions**: $\\mathbb{E}\\left[\\tilde{m}_{t+1}(\\theta) R_{j,t+1}\\right] = 1$ for test assets $j \\in \\{0,1,\\dots,N\\}$, where $j=0$ denotes the risk-free asset.\n- **Sample Moments**: $g_{T,j}(\\theta) = \\frac{1}{T}\\sum_{t=1}^{T} \\tilde{m}_{t+1}(\\theta) R_{j,t+1} - 1$.\n- **GMM Objective Function**: $J_T(\\theta) = \\sum_{j=0}^{N} \\left[g_{T,j}(\\theta)\\right]^2$.\n- **Task**: Compute the minimized value $J_T(\\hat{\\theta}_T)$ for three specific test cases (A, B, C) with given parameters ($T, N, \\mu, \\Sigma, a, b, \\{d_i\\}_{i=1}^{N}, \\sigma_u, \\text{seed}$).\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the criteria for validity.\n- **Scientifically Grounded**: The problem is a standard exercise in quantitative finance and econometrics. It employs the fundamental Euler equation of asset pricing, linear factor models, and the Generalized Method of Moments (GMM), all of which are textbook concepts. The setup is scientifically sound.\n- **Well-Posed**: The problem is well-posed. The instructions to determine $R_f$ and $c_i$ from the Euler equations lead to a unique analytical solution. The GMM estimation problem involves minimizing a sum of squares of functions that are linear in the parameters, which is a standard linear least squares problem with a well-defined unique minimizer (assuming the design matrix is full rank, which is overwhelmingly likely with simulated continuous data). All necessary parameters and random number generator seeds are provided, ensuring a reproducible outcome.\n- **Objective**: The problem is stated with mathematical precision and without any subjective or ambiguous language. All quantities are clearly defined.\n\nThe problem exhibits no signs of scientific unsoundness, incompleteness, contradiction, or any other flaws listed in the validation checklist. The parameters are specified for a simulation that is computationally feasible and standard in economic research.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\nThe solution proceeds in three stages:\n1.  Analytical determination of the risk-free rate $R_f$ and the constants $c_i$.\n2.  Simulation of the factor and return data.\n3.  Estimation of the misspecified model's parameters via GMM and calculation of the objective function.\n\n**1. Determination of $R_f$ and $c_i$**\n\nThe constants $R_f$ and $c_i$ must satisfy the Euler equations under the true SDF, $m_{t+1} = a - b'f_{t+1}$.\n\nFor the risk-free asset with return $R_f$:\n$$ \\mathbb{E}[m_{t+1} R_f] = 1 $$\nSince $R_f$ is constant, we have $R_f \\mathbb{E}[m_{t+1}] = 1$. The expectation of the SDF is:\n$$ \\mathbb{E}[m_{t+1}] = \\mathbb{E}[a - b'f_{t+1}] = a - b'\\mathbb{E}[f_{t+1}] = a - b'\\mu $$\nThus, the risk-free rate is:\n$$ R_f = \\frac{1}{a - b'\\mu} $$\n\nFor the $i$-th risky asset with return $R_{i,t+1} = c_i + d_i' f_{t+1} + u_{i,t+1}$:\n$$ \\mathbb{E}[m_{t+1} R_{i,t+1}] = 1 $$\n$$ \\mathbb{E}[(a - b'f_{t+1})(c_i + d_i'f_{t+1} + u_{i,t+1})] = 1 $$\nExpanding the expectation and using the independence of $f_{t+1}$ and $u_{i,t+1}$, and $\\mathbb{E}[u_{i,t+1}]=0$:\n$$ \\mathbb{E}[a c_i + a d_i'f_{t+1} - c_i b'f_{t+1} - (b'f_{t+1})(d_i'f_{t+1})] = 1 $$\nUsing linearity of expectation:\n$$ a c_i + a d_i'\\mathbb{E}[f_{t+1}] - c_i b'\\mathbb{E}[f_{t+1}] - \\mathbb{E}[(b'f_{t+1})(f_{t+1}'d_i)] = 1 $$\nSubstituting $\\mathbb{E}[f_{t+1}]=\\mu$ and $\\mathbb{E}[f_{t+1}f_{t+1}'] = \\Sigma + \\mu\\mu'$:\n$$ c_i(a - b'\\mu) + a d_i'\\mu - b'(\\Sigma + \\mu\\mu')d_i = 1 $$\nSolving for $c_i$:\n$$ c_i(a - b'\\mu) = 1 - a d_i'\\mu + b'\\Sigma d_i + b'\\mu\\mu'd_i $$\nRecognizing that $a-b'\\mu = 1/R_f$ and $b'\\mu\\mu'd_i = (b'\\mu)(\\mu'd_i)$:\n$$ c_i = R_f \\left(1 - a (d_i'\\mu) + b'\\Sigma d_i + (b'\\mu)(\\mu'd_i)\\right) $$\nThese expressions for $R_f$ and $c_i$ allow for the construction of asset returns that are consistent with the true underlying economy.\n\n**2. Data Simulation**\n\nFor each test case with parameters $(T, N, \\mu, \\Sigma, a, b, \\{d_i\\}_{i=1}^{N}, \\sigma_u, \\text{seed})$:\n- A random number generator is initialized with the specified seed.\n- $T$ vectors $\\{f_{t+1}\\}_{t=1}^T$ are drawn from the multivariate normal distribution $\\mathcal{N}(\\mu, \\Sigma)$.\n- For each of the $N$ assets, $T$ idiosyncratic shocks $\\{u_{i,t+1}\\}_{t=1}^T$ are drawn from the normal distribution $\\mathcal{N}(0, \\sigma_u^2)$.\n- The constants $R_f$ and $\\{c_i\\}_{i=1}^N$ are computed using the formulae from the previous step.\n- The time series of risky asset returns $\\{R_{i,t+1}\\}_{t=1,i=1}^{T,N}$ are generated using $R_{i,t+1} = c_i + d_i' f_{t+1} + u_{i,t+1}$.\n\n**3. GMM Estimation**\n\nThe goal is to find $\\hat{\\theta} = (\\hat{\\alpha}, \\hat{\\beta})'$ that minimizes the objective function $J_T(\\theta) = \\sum_{j=0}^{N} [g_{T,j}(\\theta)]^2$. The sample moments are:\n$$ g_{T,j}(\\theta) = \\frac{1}{T}\\sum_{t=1}^{T} (\\alpha - \\beta f_{1,t+1}) R_{j,t+1} - 1 $$\nThis expression is linear in $\\theta = (\\alpha, \\beta)'$. Let us define:\n$$ A_j = \\frac{1}{T}\\sum_{t=1}^{T} R_{j,t+1} \\quad \\text{and} \\quad B_j = \\frac{1}{T}\\sum_{t=1}^{T} f_{1,t+1} R_{j,t+1} $$\nThen, $g_{T,j}(\\theta) = \\alpha A_j - \\beta B_j - 1$.\nThe objective function becomes:\n$$ J_T(\\theta) = \\sum_{j=0}^{N} (\\alpha A_j - \\beta B_j - 1)^2 $$\nThis is a standard linear least squares problem. We wish to find $\\theta$ that best solves the system of $N+1$ linear equations:\n$$ A_j \\alpha - B_j \\beta = 1, \\quad j=0, \\dots, N $$\nIn matrix form, we seek to minimize $\\|X\\theta - y\\|^2_2$, where:\n$$ X = \\begin{pmatrix} A_0  -B_0 \\\\ A_1  -B_1 \\\\ \\vdots  \\vdots \\\\ A_N  -B_N \\end{pmatrix}, \\quad \\theta = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}, \\quad y = \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} $$\nThe matrix $X$ has dimensions $(N+1) \\times 2$, and $y$ is an $(N+1)$-dimensional vector of ones. The quantities $A_j$ and $B_j$ are computed from the simulated data. For the risk-free asset ($j=0$), $R_{0,t+1} = R_f$ is constant.\n\nThe least-squares solution $\\hat{\\theta}_T$ minimizes this objective. The minimized value $J_T(\\hat{\\theta}_T)$ is the sum of squared residuals of this linear regression. This value is computed for each test case.\n\nThe implementation will use `numpy.linalg.lstsq`, which provides an efficient and numerically stable method for solving this problem and directly returns the sum of squared residuals, which is precisely $J_T(\\hat{\\theta}_T)$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the GMM estimation problem for the three specified test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"T\": 3000, \"N\": 6, \"seed\": 12345,\n            \"mu\": np.array([0.02, 0.01]),\n            \"Sigma\": np.array([[0.04, 0.008], [0.008, 0.01]]),\n            \"a\": 1.0, \"b\": np.array([0.5, 1.0]),\n            \"d\": np.array([\n                [0.8, 0.2], [1.0, -0.2], [-0.5, 0.5],\n                [0.3, 1.2], [1.5, -0.7], [-1.0, -0.4]\n            ]),\n            \"sigma_u\": 0.05\n        },\n        {\n            \"name\": \"Case B\",\n            \"T\": 3000, \"N\": 6, \"seed\": 67890,\n            \"mu\": np.array([0.02, 0.01]),\n            \"Sigma\": np.array([[0.04, 0.008], [0.008, 0.01]]),\n            \"a\": 1.0, \"b\": np.array([0.5, 0.0]),\n            \"d\": np.array([\n                [0.8, 0.2], [1.0, -0.2], [-0.5, 0.5],\n                [0.3, 1.2], [1.5, -0.7], [-1.0, -0.4]\n            ]),\n            \"sigma_u\": 0.05\n        },\n        {\n            \"name\": \"Case C\",\n            \"T\": 800, \"N\": 6, \"seed\": 24680,\n            \"mu\": np.array([0.015, 0.015]),\n            \"Sigma\": np.array([[0.02, 0.019], [0.019, 0.02]]),\n            \"a\": 1.0, \"b\": np.array([0.8, 0.6]),\n            \"d\": np.array([\n                [0.8, 0.2], [1.0, -0.2], [-0.5, 0.5],\n                [0.3, 1.2], [1.5, -0.7], [-1.0, -0.4]\n            ]),\n            \"sigma_u\": 0.05\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Unpack parameters\n        T, N, seed = case[\"T\"], case[\"N\"], case[\"seed\"]\n        mu, Sigma = case[\"mu\"], case[\"Sigma\"]\n        a, b = case[\"a\"], case[\"b\"]\n        d_matrices = case[\"d\"]\n        sigma_u = case[\"sigma_u\"]\n\n        rng = np.random.default_rng(seed=seed)\n\n        # 1. Analytical determination of Rf and c_i\n        b_mu = b @ mu\n        Rf = 1.0 / (a - b_mu)\n        \n        c_i = np.zeros(N)\n        for i in range(N):\n            d_i = d_matrices[i]\n            d_i_mu = d_i @ mu\n            b_Sigma_d = b @ Sigma @ d_i\n            c_i[i] = Rf * (1.0 - a * d_i_mu + b_Sigma_d + b_mu * d_i_mu)\n            \n        # 2. Data Simulation\n        # Simulate economic factors f_t+1\n        factors = rng.multivariate_normal(mu, Sigma, size=T)\n        \n        # Simulate idiosyncratic shocks u_i,t+1\n        shocks = rng.normal(0, sigma_u, size=(T, N))\n        \n        # Generate risky asset returns R_i,t+1\n        risky_returns = c_i + factors @ d_matrices.T + shocks\n        \n        # 3. GMM Estimation (as OLS)\n        # Construct the design matrix X and target vector y\n        num_assets_total = N + 1\n        X = np.zeros((num_assets_total, 2))\n        y = np.ones(num_assets_total)\n        \n        f1 = factors[:, 0]\n        \n        # Row for the risk-free asset (j=0)\n        A0 = Rf\n        B0 = Rf * np.mean(f1)\n        X[0, :] = [A0, -B0]\n        \n        # Rows for risky assets (j=1 to N)\n        for j in range(N):\n            R_j = risky_returns[:, j]\n            Aj = np.mean(R_j)\n            Bj = np.mean(f1 * R_j)\n            X[j + 1, :] = [Aj, -Bj]\n            \n        # Solve the linear least squares problem: min ||X*theta - y||^2\n        # The second return value is the sum of squared residuals, which is J_T\n        _, residuals, _, _ = np.linalg.lstsq(X, y, rcond=None)\n        \n        # The value of the GMM objective function at the minimum\n        J_T_minimized = residuals[0]\n        results.append(J_T_minimized)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2421339"}, {"introduction": "While the J-test provides a valuable omnibus check for model misspecification, it can sometimes lack the power to pinpoint specific problems. This advanced simulation exercise [@problem_id:2397116] delves into the art of specification testing by comparing the performance of the J-test against a more targeted \"difference test\" (or D-test). This hands-on comparison will help you understand the crucial trade-offs in hypothesis testing and equip you to design more powerful and informative tests for your own economic questions.", "problem": "You are given a linear instrumental variables environment in which a scalar structural parameter $ \\beta \\in \\mathbb{R} $ is identified by a set of unconditional moments. For each observation $ t \\in \\{1,\\dots,n\\} $, let $ z_{1t}, z_{2t}, z_{3t} \\in \\mathbb{R} $ be instruments, $ x_t \\in \\mathbb{R} $ be a regressor, and $ y_t \\in \\mathbb{R} $ be an outcome. Consider the following data generating process, with all random variables mutually independent unless explicitly linked, and all expectations taken with respect to the joint distribution of the draws:\n- Instruments: $ z_{1t} \\sim \\mathcal{N}(0,1) $, $ z_{2t} \\sim \\mathcal{N}(0,1) $, $ z_{3t} \\sim \\mathcal{N}(0,1) $.\n- First-stage disturbance: $ v_t \\sim \\mathcal{N}(0,1) $.\n- Structural disturbance: $ e_t \\sim \\mathcal{N}(0,1) $.\n- Regressor: $ x_t = z_{1t} + 0.5 z_{3t} + v_t $.\n- Structural error with potential invalidity of $ z_{2t} $: $ u_t = \\delta \\, z_{2t} + e_t $ where $ \\delta \\in \\mathbb{R} $.\n- Outcome: $ y_t = \\beta_0 \\, x_t + u_t $ with true parameter $ \\beta_0 = 1 $.\n\nDefine the $ 3 \\times 1 $ vector of instruments $ Z_t = \\big(z_{1t}, z_{2t}, z_{3t}\\big)^{\\prime} $. For any candidate $ \\beta \\in \\mathbb{R} $, define the $ 3 \\times 1 $ moment function $ g_t(\\beta) = Z_t \\, \\big(y_t - \\beta x_t\\big) $. Let $ \\mathbb{E}[g_t(\\beta)] = 0 $ denote the target moment conditions. When $ \\delta = 0 $, all three instruments are valid for the linear model and the moments are correctly specified. When $ \\delta \\neq 0 $, instrument $ z_{2t} $ is invalid while $ z_{1t} $ and $ z_{3t} $ remain valid.\n\nUsing the Generalized Method of Moments (GMM), define the sample average moment $ \\bar{g}_n(\\beta) = \\frac{1}{n} \\sum_{t=1}^n g_t(\\beta) $ and the GMM criterion $ J_n(\\beta; W) = n \\, \\bar{g}_n(\\beta)^{\\prime} W \\, \\bar{g}_n(\\beta) $ for any symmetric positive definite weighting matrix $ W \\in \\mathbb{R}^{3 \\times 3} $. The efficient GMM weighting matrix is the inverse of the long-run covariance of the moments. Let $ \\widehat{\\beta}_{\\text{full}} $ be the efficient GMM estimator using the full $ 3 \\times 1 $ moment vector $ g_t(\\beta) $ and let $ J_{\\text{full}} = J_n\\big(\\widehat{\\beta}_{\\text{full}}; \\widehat{W}_{\\text{full}}\\big) $ be the minimized criterion value, where $ \\widehat{W}_{\\text{full}} $ is the efficient estimate of the optimal weighting matrix for the full set of moments. Similarly, let $ \\widehat{\\beta}_{\\text{rest}} $ be the efficient GMM estimator using only the restricted $ 2 \\times 1 $ subset of moments corresponding to $ (z_{1t}, z_{3t}) $ and let $ J_{\\text{rest}} = J_n\\big(\\widehat{\\beta}_{\\text{rest}}; \\widehat{W}_{\\text{rest}}\\big) $ be its minimized criterion value, with $ \\widehat{W}_{\\text{rest}} $ the corresponding efficient weight. Define:\n- The overidentifying restrictions test statistic (J-test): $ J_{\\text{full}} $, which under the null has an asymptotic $ \\chi^2 $ distribution with $ 3 - 1 = 2 $ degrees of freedom.\n- The targeted difference test (D-test, also called C-test) for the subset of moments associated with $ z_{2t} $: $ D = J_{\\text{full}} - J_{\\text{rest}} $, which under the null has an asymptotic $ \\chi^2 $ distribution with $ 1 $ degree of freedom.\n\nFor a significance level $ \\alpha = 0.05 $, you must compute, by simulation, the empirical rejection probability (interpreted as empirical power when $ \\delta \\neq 0 $ and as empirical size when $ \\delta = 0 $) of:\n- The J-test using the full set of three moments.\n- The D-test targeting the subset consisting of the moment(s) that involve $ z_{2t} $ by comparing the full set $ \\{z_{1t}, z_{2t}, z_{3t}\\} $ to the restricted set $ \\{z_{1t}, z_{3t}\\} $.\n\nFor each test, a rejection occurs when the corresponding statistic exceeds the $ (1-\\alpha) $ quantile of its reference $ \\chi^2 $ distribution with the specified degrees of freedom.\n\nImplement a simulation using independent and identically distributed draws according to the data generating process above. For reproducibility, use the fixed random seed $ 123456 $. For each parameter tuple $ (n,\\delta,R) $ in the test suite below, generate $ R $ independent samples of size $ n $, compute $ J_{\\text{full}} $ and $ D $ for each replication, record whether each test rejects at level $ \\alpha $, and report the empirical rejection probabilities as the average of the binary rejection indicators across the $ R $ replications.\n\nTest suite:\n- Case $ 1 $: $ (n,\\delta,R) = (400, 0.0, 500) $.\n- Case $ 2 $: $ (n,\\delta,R) = (400, 0.3, 500) $.\n- Case $ 3 $: $ (n,\\delta,R) = (400, 0.6, 500) $.\n- Case $ 4 $: $ (n,\\delta,R) = (120, 0.6, 500) $.\n\nYour program must output a single line that is a comma-separated list enclosed in square brackets, containing, in order, the empirical rejection probabilities for the J-test and the D-test for each case, rounded to three decimal places. The required output format is:\n$ \\big[ p_{J,1}, p_{D,1}, p_{J,2}, p_{D,2}, p_{J,3}, p_{D,3}, p_{J,4}, p_{D,4} \\big] $,\nwhere $ p_{J,i} $ is the empirical rejection probability of the J-test for case $ i $ and $ p_{D,i} $ is the empirical rejection probability of the D-test for case $ i $.", "solution": "The problem as stated constitutes a valid, well-posed exercise in computational econometrics. It is scientifically grounded in the established theory of the Generalized Method of Moments (GMM), providing a complete and consistent specification for a Monte Carlo simulation to evaluate the properties of standard hypothesis tests. I will now proceed with the solution.\n\nThe objective is to compute, by simulation, the empirical size and power of two hypothesis tests—the J-test for overidentifying restrictions and the D-test for a subset of moments—in a linear instrumental variables (IV) setting. We are given a data generating process (DGP) for $R$ replications of samples of size $n$. For each replication, we must estimate the model parameters using GMM and compute the specified test statistics.\n\nThe structural model is given by $y_t = \\beta_0 x_t + u_t$, where the true parameter is $\\beta_0 = 1$. The regressor $x_t$ is endogenous, meaning $\\mathbb{E}[x_t u_t] \\neq 0$, because both $x_t$ and $u_t$ depend on other random variables in a potentially correlated manner. Specifically, $x_t = z_{1t} + 0.5 z_{3t} + v_t$ and $u_t = \\delta z_{2t} + e_t$. The endogeneity arises from the correlation between $x_t$ and $u_t$ when $\\delta \\neq 0$ through the omitted variable $z_{2t}$, or if $v_t$ and $e_t$ were correlated (though here they are specified as independent). The problem specifies three instruments in the vector $Z_t = (z_{1t}, z_{2t}, z_{3t})'$, which are used to form moment conditions. The validity of these instruments depends on the parameter $\\delta$.\n\nThe GMM framework is based on the population moment conditions $\\mathbb{E}[g_t(\\beta_0)] = 0$. For this problem, the $3 \\times 1$ vector of moment functions is $g_t(\\beta) = Z_t (y_t - \\beta x_t)$. When all instruments are valid (i.e., $\\mathbb{E}[Z_t u_t]=0$, which occurs when $\\delta=0$), all three moment conditions hold at the true parameter $\\beta_0=1$. When $\\delta \\neq 0$, the second instrument $z_{2t}$ becomes invalid because $\\mathbb{E}[z_{2t}u_t] = \\mathbb{E}[z_{2t}(\\delta z_{2t} + e_t)] = \\delta \\mathbb{E}[z_{2t}^2] = \\delta \\neq 0$. The moment condition $\\mathbb{E}[z_{2t}(y_t - \\beta_0 x_t)] = 0$ is violated.\n\nThe GMM estimator $\\widehat{\\beta}$ for a given symmetric positive definite weighting matrix $W$ is found by minimizing the quadratic form $J_n(\\beta; W) = n \\, \\bar{g}_n(\\beta)' W \\, \\bar{g}_n(\\beta)$, where $\\bar{g}_n(\\beta) = \\frac{1}{n} \\sum_{t=1}^n g_t(\\beta)$ is the sample analogue of the population moments. For this linear model, the sample moments are $\\bar{g}_n(\\beta) = \\frac{1}{n}(Z'y - Z'x\\beta)$. The GMM estimator has the analytical solution $\\widehat{\\beta}(W) = (x'Z W Z'x)^{-1} (x'Z W Z'y)$.\n\nThe problem requires the use of the efficient GMM estimator, which employs the optimal weighting matrix $W^* = S^{-1}$, where $S = \\mathbb{E}[g_t(\\beta_0) g_t(\\beta_0)']$ is the long-run covariance matrix of the moment functions. Since $S$ is unknown, a two-step procedure is implemented:\n1.  **First Step**: Obtain a consistent estimate of $\\beta$, denoted $\\widehat{\\beta}^{(1)}$, using a suboptimal but valid weighting matrix, such as the identity matrix $W^{(1)}=I$ or the matrix corresponding to the two-stage least squares (2SLS) estimator, $W^{(1)}=(Z'Z/n)^{-1}$. The 2SLS estimator is a conventional choice for this step.\n2.  **Second Step**: Use $\\widehat{\\beta}^{(1)}$ to form residuals $\\widehat{u}_t = y_t - \\widehat{\\beta}^{(1)} x_t$ and construct a consistent estimator of $S$, given by $\\widehat{S} = \\frac{1}{n} \\sum_{t=1}^n Z_t Z_t' \\widehat{u}_t^2$. The estimated optimal weighting matrix is then $\\widehat{W} = \\widehat{S}^{-1}$. The efficient GMM estimator is then computed as $\\widehat{\\beta}_{\\text{GMM}} = (x'Z \\widehat{W} Z'x)^{-1} (x'Z \\widehat{W} Z'y)$.\n\nThe simulation requires calculating two test statistics:\n\n1.  **The J-test statistic**: $J_{\\text{full}} = n \\cdot \\bar{g}_n(\\widehat{\\beta}_{\\text{full}})' \\widehat{W}_{\\text{full}} \\bar{g}_n(\\widehat{\\beta}_{\\text{full}})$. This statistic tests the null hypothesis that all moment conditions are correctly specified. Here, $\\widehat{\\beta}_{\\text{full}}$ and $\\widehat{W}_{\\text{full}}$ are the estimator and optimal weight matrix derived from the full set of $k=3$ instruments. Under the null hypothesis, $J_{\\text{full}}$ follows an asymptotic $\\chi^2$ distribution with $k - m = 3 - 1 = 2$ degrees of freedom, where $m=1$ is the number of estimated parameters. A rejection suggests model misspecification.\n\n2.  **The D-test (or C-test) statistic**: $D = J_{\\text{full}} - J_{\\text{rest}}$. This statistic tests the validity of a specific subset of moment conditions—in this case, the one associated with the instrument $z_{2t}$. It compares the minimized GMM criterion from the full model, $J_{\\text{full}}$, with the minimized criterion from a restricted model, $J_{\\text{rest}}$. The restricted model uses only the subset of instruments assumed to be valid under the alternative, $\\{z_{1t}, z_{3t}\\}$. Accordingly, $J_{\\text{rest}}$ is computed using the two-step efficient GMM procedure with this smaller set of $k_{rest}=2$ instruments. Under the null hypothesis that the additional moment condition (from $z_{2t}$) is valid, the $D$ statistic has an asymptotic $\\chi^2$ distribution with $k - k_{rest} = 3 - 2 = 1$ degree of freedom. This test is often more powerful than the omnibus J-test for detecting failure of the specific moment condition being tested.\n\nThe simulation algorithm proceeds as follows for each parameter tuple $(n, \\delta, R)$:\n1.  Set the random number generator seed to $123456$ for reproducibility.\n2.  Determine the critical values for the tests from the $\\chi^2(2)$ and $\\chi^2(1)$ distributions at the $\\alpha = 0.05$ significance level.\n3.  Initialize rejection counters for both tests to zero.\n4.  Execute a loop for $R=500$ replications. In each replication:\n    a.  Generate a sample of size $n$ from the DGP using the specified value of $\\delta$ and $\\beta_0=1$.\n    b.  Using the full set of instruments $Z=(z_1, z_2, z_3)$, compute the two-step efficient GMM estimator $\\widehat{\\beta}_{\\text{full}}$ and the corresponding J-statistic, $J_{\\text{full}}$.\n    c.  Using the restricted set of instruments $Z_{\\text{rest}}=(z_1, z_3)$, compute the two-step efficient GMM estimator $\\widehat{\\beta}_{\\text{rest}}$ and the corresponding J-statistic, $J_{\\text{rest}}$.\n    d.  Calculate the D-statistic as $D = J_{\\text{full}} - J_{\\text{rest}}$.\n    e.  If $J_{\\text{full}}$ exceeds its critical value, increment the J-test rejection counter.\n    f.  If $D$ exceeds its critical value, increment the D-test rejection counter.\n5.  After the loop, compute the empirical rejection probability for each test by dividing its rejection count by the total number of replications, $R$.\n6.  The results from all four test cases are collected and reported in the specified format. In cases where $\\delta=0$, the rejection probability represents the empirical size of the test. When $\\delta \\neq 0$, it represents the empirical power.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef gmm_solver(y, x, Z):\n    \"\"\"\n    Computes the two-step efficient GMM estimator, J-statistic, and optimal weight matrix.\n\n    Args:\n        y (np.ndarray): Dependent variable, shape (n, 1).\n        x (np.ndarray): Endogenous regressor, shape (n, 1).\n        Z (np.ndarray): Matrix of instruments, shape (n, k).\n\n    Returns:\n        tuple: (J-statistic, GMM beta estimate). Returns (np.nan, np.nan) on failure.\n    \"\"\"\n    n, k = Z.shape\n    if n  k:\n        return np.nan, np.nan\n\n    # Step 1: First-step consistent estimation using 2SLS (W = (Z'Z)^-1)\n    try:\n        ZTZ = Z.T @ Z\n        if np.linalg.matrix_rank(ZTZ)  k:\n            return np.nan, np.nan\n        inv_ZTZ = np.linalg.inv(ZTZ)\n    except np.linalg.LinAlgError:\n        return np.nan, np.nan\n\n    xTZ = x.T @ Z\n    ZTx = Z.T @ x\n    ZTy = Z.T @ y\n\n    den_b1 = (xTZ @ inv_ZTZ @ ZTx)[0, 0]\n    if np.isclose(den_b1, 0):\n        return np.nan, np.nan\n    num_b1 = (xTZ @ inv_ZTZ @ ZTy)[0, 0]\n    beta1 = num_b1 / den_b1\n\n    # Step 2: Form optimal weighting matrix\n    u_hat = y - x * beta1\n    # S_hat = (1/n) * Sum(u_hat_t^2 * Z_t @ Z_t.T)\n    # This is equivalent to (1/n) * Z_with_residuals.T @ Z_with_residuals\n    S_hat = (Z * u_hat).T @ (Z * u_hat) / n\n\n    try:\n        if np.linalg.matrix_rank(S_hat)  k:\n            return np.nan, np.nan\n        W_hat = np.linalg.inv(S_hat)\n    except np.linalg.LinAlgError:\n        return np.nan, np.nan\n\n    # Step 3: Efficient GMM estimator\n    den_b2 = (xTZ @ W_hat @ ZTx)[0, 0]\n    if np.isclose(den_b2, 0):\n        return np.nan, np.nan\n    num_b2 = (xTZ @ W_hat @ ZTy)[0, 0]\n    beta_gmm = num_b2 / den_b2\n\n    # J-statistic calculation\n    g_bar = (ZTy - ZTx * beta_gmm) / n\n    J_stat = n * g_bar.T @ W_hat @ g_bar\n\n    return J_stat[0, 0], beta_gmm\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo simulation for GMM tests.\n    \"\"\"\n    seed = 123456\n    rng = np.random.default_rng(seed)\n    alpha = 0.05\n\n    # Test cases: (n, delta, R)\n    test_cases = [\n        (400, 0.0, 500),\n        (400, 0.3, 500),\n        (400, 0.6, 500),\n        (120, 0.6, 500),\n    ]\n\n    # Chi-squared critical values\n    crit_val_j = chi2.ppf(1 - alpha, df=2)  # Full model: 3 instruments, 1 param - df=2\n    crit_val_d = chi2.ppf(1 - alpha, df=1)  # D-test: 3-2=1 df\n\n    # True parameter value\n    beta_0 = 1.0\n    \n    final_results = []\n\n    for n, delta, R in test_cases:\n        j_reject_count = 0\n        d_reject_count = 0\n\n        for _ in range(R):\n            # 1. Generate data\n            z1 = rng.normal(size=(n, 1))\n            z2 = rng.normal(size=(n, 1))\n            z3 = rng.normal(size=(n, 1))\n            v = rng.normal(size=(n, 1))\n            e = rng.normal(size=(n, 1))\n            \n            Z_full = np.hstack([z1, z2, z3])\n            \n            x = z1 + 0.5 * z3 + v\n            u = delta * z2 + e\n            y = beta_0 * x + u\n\n            # 2. GMM Estimation for the full model\n            J_full, _ = gmm_solver(y, x, Z_full)\n            \n            # 3. GMM Estimation for the restricted model\n            Z_rest = Z_full[:, [0, 2]]\n            J_rest, _ = gmm_solver(y, x, Z_rest)\n\n            # Skip replication if GMM fails (e.g., singular matrix)\n            if np.isnan(J_full) or np.isnan(J_rest):\n                continue\n\n            # 4. Compute D-statistic\n            D = J_full - J_rest\n\n            # 5. Perform tests\n            if J_full  crit_val_j:\n                j_reject_count += 1\n            # Note: D can be negative in finite samples. The test is D  crit,\n            # so a negative value correctly results in non-rejection.\n            if D  crit_val_d:\n                d_reject_count += 1\n\n        # 6. Calculate empirical rejection probabilities\n        p_j = j_reject_count / R\n        p_d = d_reject_count / R\n        \n        final_results.extend([p_j, p_d])\n    \n    # Format and print the final output\n    formatted_results = [f\"{res:.3f}\" for res in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2397116"}]}