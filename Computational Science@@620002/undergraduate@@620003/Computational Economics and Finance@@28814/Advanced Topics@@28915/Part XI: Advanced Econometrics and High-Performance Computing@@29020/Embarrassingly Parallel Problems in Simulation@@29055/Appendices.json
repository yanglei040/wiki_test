{"hands_on_practices": [{"introduction": "An excellent starting point for understanding embarrassingly parallel tasks is the parameter sweep, where a model's outcome is calculated independently for many different input parameters. This exercise applies this concept to a cornerstone of modern macroeconomics: the neoclassical growth model. You will derive the analytical solution for the economy's steady-state capital stock and then write a program to see how this equilibrium changes as you vary fundamental parameters like the discount factor and the depreciation rate, a common form of sensitivity analysis in economic modeling. [@problem_id:2390013]", "problem": "Consider a deterministic, infinite-horizon representative agent economy with a single good used for consumption and investment. Time is discrete, indexed by $t \\in \\{0,1,2,\\dots\\}$. The representative household has preferences over consumption sequences $\\{c_t\\}_{t=0}^{\\infty}$ given by the expected discounted sum $\\sum_{t=0}^{\\infty} \\beta^t u(c_t)$, where $\\beta \\in (0,1)$ is the subjective discount factor and $u(\\cdot)$ is a strictly increasing, strictly concave, twice continuously differentiable utility function. Assume Constant Relative Risk Aversion (CRRA) utility with coefficient $\\sigma > 0$, that is $u(c) = \\frac{c^{1-\\sigma}}{1-\\sigma}$ for $\\sigma \\neq 1$ and $u(c) = \\log c$ for $\\sigma = 1$. Production is competitive with a single firm operating a Cobb–Douglas production technology $y_t = A k_t^{\\alpha} n_t^{1-\\alpha}$ with $A = 1$, $\\alpha \\in (0,1)$, inelastic labor supply $n_t \\equiv 1$, and physical capital $k_t$. Capital depreciates at rate $\\delta \\in [0,1]$. Competitive factor prices equal marginal products: the rental rate of capital is $r_t = \\alpha k_t^{\\alpha - 1}$ and the wage is $w_t = (1 - \\alpha) k_t^{\\alpha}$. The household’s period budget constraint in per-capita terms is $c_t + k_{t+1} = (1 - \\delta) k_t + r_t k_t + w_t$, with $k_{t+1} \\ge 0$ and $c_t \\ge 0$. Assume there is no population growth or technological growth.\n\nStarting from these primitives and definitions alone, and using only first principles (such as the household’s intertemporal optimality condition and the competitive equilibrium conditions), derive the steady-state condition that characterizes the unique positive steady-state capital stock $K$ as a function of the parameters $\\alpha$, $\\beta$, and $\\delta$ under the assumption of no exogenous growth. Then, implement a program that uses this steady-state condition to compute $K$ for a set of parameter pairs $(\\beta,\\delta)$, holding $\\alpha$ fixed.\n\nYour implementation should exploit the fact that each $(\\beta,\\delta)$ pair can be evaluated independently of the others, making the computation an example of an embarrassingly parallel problem in simulation. However, your program must execute sequentially and deterministically, without requiring any user input.\n\nUse the following parameterization for all computations:\n- Capital share: $\\alpha = 0.36$.\n- Productivity: $A = 1$.\n- Labor: $n_t \\equiv 1$.\n- Risk aversion parameter $\\sigma$ is arbitrary but fixed and strictly positive; your final steady-state expression must not depend on $\\sigma$ under the assumptions stated above.\n\nTest suite (compute the steady-state capital stock $K$ for each pair):\n- Case $1$: $(\\beta,\\delta) = (0.96,0.08)$.\n- Case $2$: $(\\beta,\\delta) = (0.96,0.00)$.\n- Case $3$: $(\\beta,\\delta) = (0.96,1.00)$.\n- Case $4$: $(\\beta,\\delta) = (0.99,0.08)$.\n- Case $5$: $(\\beta,\\delta) = (0.90,0.08)$.\n- Case $6$: $(\\beta,\\delta) = (0.99,0.01)$.\n- Case $7$: $(\\beta,\\delta) = (0.95,0.20)$.\n- Case $8$: $(\\beta,\\delta) = (0.999,0.50)$.\n\nScientific realism and feasibility conditions:\n- Assume interior solutions with strictly positive steady-state capital $K > 0$ for valid parameter pairs.\n- If the derived steady-state condition implies nonpositive or undefined $K$ for a parameter pair (for example due to a nonpositive denominator in your derived expression), your program should return a Not-a-Number value for that case.\n\nNumerical and output requirements:\n- Express all numerical answers as unit-free real numbers.\n- Round each reported steady-state capital $K$ to $6$ decimal places.\n- Your program should produce a single line of output containing the results for the test suite, in order, as a comma-separated list enclosed in square brackets, with no spaces. For example: \"[k1,k2,k3,k4,k5,k6,k7,k8]\".", "solution": "The problem statement is evaluated and found to be valid. It is a standard, well-posed problem in modern macroeconomic theory, specifically the analysis of the neoclassical growth model. All required parameters, functional forms, and equilibrium conditions are provided, and there are no internal contradictions or scientific inaccuracies. We proceed with the derivation.\n\nThe objective is to derive the steady-state capital stock, denoted by $K$, for a representative agent economy. This derivation proceeds in three steps: first, establishing the household's intertemporal optimality condition (the Euler equation); second, imposing the steady-state conditions where all per-capita variables are constant; and third, solving the resulting algebraic equation for $K$.\n\nFirst, we formulate the household's dynamic optimization problem. The household chooses a sequence of consumption $\\{c_t\\}_{t=0}^{\\infty}$ and capital $\\{k_{t+1}\\}_{t=0}^{\\infty}$ to maximize its lifetime utility, given by $\\sum_{t=0}^{\\infty} \\beta^t u(c_t)$, subject to a sequence of budget constraints. The budget constraint for period $t$ is $c_t + k_{t+1} = (1 - \\delta) k_t + r_t k_t + w_t$.\n\nIn a competitive equilibrium, factor prices equal their marginal products. Given the Cobb-Douglas production function $y_t = k_t^{\\alpha}$ (since $A=1$ and $n_t=1$), the rental rate of capital is $r_t = \\frac{\\partial y_t}{\\partial k_t} = \\alpha k_t^{\\alpha-1}$, and the wage rate is $w_t = y_t - r_t k_t = k_t^\\alpha - (\\alpha k_t^{\\alpha-1})k_t = (1-\\alpha)k_t^\\alpha$. Substituting these into the household's budget constraint yields $c_t + k_{t+1} = (1 - \\delta) k_t + (\\alpha k_t^{\\alpha-1})k_t + (1-\\alpha)k_t^\\alpha = (1 - \\delta)k_t + \\alpha k_t^\\alpha + (1 - \\alpha)k_t^\\alpha = k_t^\\alpha + (1 - \\delta)k_t$. This is the economy's aggregate resource constraint.\n\nThe household's problem can be solved using dynamic programming. The Bellman equation is:\n$$V(k_t) = \\max_{k_{t+1}} \\left\\{ u(k_t^\\alpha + (1-\\delta)k_t - k_{t+1}) + \\beta V(k_{t+1}) \\right\\}$$\nThe first-order condition with respect to the choice variable $k_{t+1}$ is:\n$ -u'(c_t) \\cdot 1 + \\beta V'(k_{t+1}) = 0 \\Rightarrow u'(c_t) = \\beta V'(k_{t+1}) $\nThe envelope condition, obtained by differentiating the Bellman equation with respect to the state variable $k_t$, is:\n$$V'(k_t) = u'(c_t) \\left( \\frac{\\partial y_t}{\\partial k_t} + 1 - \\delta \\right) = u'(c_t) (\\alpha k_t^{\\alpha-1} + 1 - \\delta)$$\nShifting the envelope condition forward one period in time gives:\n$$V'(k_{t+1}) = u'(c_{t+1}) (\\alpha k_{t+1}^{\\alpha-1} + 1 - \\delta)$$\nSubstituting this expression for $V'(k_{t+1})$ back into the first-order condition yields the Euler equation:\n$$u'(c_t) = \\beta u'(c_{t+1}) (\\alpha k_{t+1}^{\\alpha-1} + 1 - \\delta)$$\nFor the specified Constant Relative Risk Aversion (CRRA) utility function, $u(c) = \\frac{c^{1-\\sigma}}{1-\\sigma}$ (or $u(c)=\\log c$ for $\\sigma=1$), the marginal utility is $u'(c) = c^{-\\sigma}$. The Euler equation becomes:\n$$c_t^{-\\sigma} = \\beta c_{t+1}^{-\\sigma} (\\alpha k_{t+1}^{\\alpha-1} + 1 - \\delta)$$\n\nSecond, we impose the steady-state condition. In a steady state with no exogenous growth, all per-capita variables are constant over time. Thus, $k_t = k_{t+1} = K$ and $c_t = c_{t+1} = C$ for all $t$. Applying these conditions to the Euler equation, we get:\n$$C^{-\\sigma} = \\beta C^{-\\sigma} (\\alpha K^{\\alpha-1} + 1 - \\delta)$$\nSince we assume an interior solution with strictly positive consumption $C > 0$, we can divide both sides by $C^{-\\sigma}$:\n$$1 = \\beta (\\alpha K^{\\alpha-1} + 1 - \\delta)$$\nThis is the fundamental condition that characterizes the steady-state capital stock $K$. Note that the risk-aversion parameter $\\sigma$ has cancelled out, as required by the problem statement.\n\nThird, we solve this algebraic equation for $K$.\n$$\\frac{1}{\\beta} = \\alpha K^{\\alpha-1} + 1 - \\delta$$\nRearranging the terms to isolate $K$:\n$$\\alpha K^{\\alpha-1} = \\frac{1}{\\beta} - (1 - \\delta) = \\frac{1 - \\beta(1-\\delta)}{\\beta} = \\frac{1 - \\beta + \\beta\\delta}{\\beta}$$\n$$K^{\\alpha-1} = \\frac{1 - \\beta + \\beta\\delta}{\\alpha\\beta}$$\nTo solve for $K$, we raise both sides to the power of $\\frac{1}{\\alpha-1}$. This is equivalent to taking the reciprocal of the base and raising it to the power of $\\frac{1}{1-\\alpha}$:\n$$K = \\left( \\frac{\\alpha\\beta}{1 - \\beta + \\beta\\delta} \\right)^{\\frac{1}{1-\\alpha}}$$\nThis is the final expression for the unique positive steady-state capital stock.\n\nFor the computation, we use the given fixed parameter $\\alpha = 0.36$. The exponent is therefore $\\frac{1}{1 - 0.36} = \\frac{1}{0.64} = 1.5625$. The base of the exponentiation is $\\frac{\\alpha\\beta}{1 - \\beta + \\beta\\delta}$. For $K$ to be a positive real number, the base must be positive. Given $\\alpha \\in (0,1)$ and $\\beta \\in (0,1)$, the numerator $\\alpha\\beta$ is always positive. The denominator is $(1-\\beta) + \\beta\\delta$. Since $1-\\beta > 0$ and $\\beta\\delta \\ge 0$ (for $\\delta \\in [0,1]$), the denominator is always strictly positive. Therefore, for all valid parameter pairs provided in the test suite, the steady-state capital stock $K$ is positive and well-defined, and no Not-a-Number results are expected.\n\nThe implementation will apply this formula for each specified pair of $(\\beta, \\delta)$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the steady-state capital stock for a neoclassical growth model\n    for a given set of parameters.\n    \"\"\"\n    \n    # Fixed parameters from the problem statement.\n    # Capital share in production.\n    alpha = 0.36\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple (beta, delta).\n    test_cases = [\n        (0.96, 0.08),   # Case 1\n        (0.96, 0.00),   # Case 2\n        (0.96, 1.00),   # Case 3\n        (0.99, 0.08),   # Case 4\n        (0.90, 0.08),   # Case 5\n        (0.99, 0.01),   # Case 6\n        (0.95, 0.20),   # Case 7\n        (0.999, 0.50),  # Case 8\n    ]\n\n    results = []\n    \n    # The exponent in the final expression for the steady-state capital stock K.\n    exponent = 1.0 / (1.0 - alpha)\n\n    # Iterate through each parameter set (beta, delta)\n    for beta, delta in test_cases:\n        # The steady-state capital stock K is given by the formula:\n        # K = ( (alpha * beta) / (1 - beta + beta * delta) ) ^ (1 / (1 - alpha))\n        \n        # Calculate the denominator of the base.\n        denominator = 1.0 - beta + beta * delta\n        \n        # As reasoned in the solution, the denominator for the given parameter ranges\n        # is always positive. Thus, we do not need to explicitly handle division by zero\n        # or non-positive bases.\n        \n        # Calculate the base of the exponentiation.\n        base = (alpha * beta) / denominator\n        \n        # Calculate the steady-state capital stock K.\n        k_steady_state = np.power(base, exponent)\n        \n        # Round the result to 6 decimal places as required.\n        result_rounded = round(k_steady_state, 6)\n        \n        results.append(result_rounded)\n\n    # Format the final output string as a comma-separated list in brackets.\n    # The map(str, ...) ensures each number is converted to a string before joining.\n    # No spaces are included between the elements, as per the output format requirement.\n    output_string = f\"[{','.join(map(str, results))}]\"\n    \n    # Final print statement in the exact required format.\n    print(output_string)\n\n# Execute the main function.\nsolve()\n```", "id": "2390013"}, {"introduction": "We now move from a deterministic, representative-agent model to a stochastic, multi-agent simulation. This practice explores a classic coordination problem—a bank run—using an agent-based model where depositors' decisions depend on their beliefs about others' actions. Since the outcome depends on random draws of agent characteristics, we must run many independent simulations (or Monte Carlo trials) to understand the system's probabilistic behavior, an ideal task for parallel computation. [@problem_id:2389979]", "problem": "Consider the following simplified threshold model of a bank run. There are $N$ depositors indexed by $i \\in \\{1,\\dots,N\\}$. Each depositor $i$ has a private panic threshold $\\theta_i \\in [0,1]$, drawn independently and identically distributed from a Beta distribution with mean $m \\in (0,1)$ and concentration parameter $\\kappa > 0$. Recall that for a Beta distribution parameterized by shape parameters $\\alpha > 0$ and $\\beta > 0$, the mean equals $\\alpha/(\\alpha+\\beta)$. Therefore, setting $\\alpha = m \\kappa$ and $\\beta = (1-m)\\kappa$ yields a Beta distribution with the desired mean and concentration.\n\nAt any point in time, if the current belief about the fraction of depositors who will withdraw is $f \\in [0,1]$, then each depositor $i$ follows a threshold strategy: withdraw if and only if $\\theta_i \\le f$. This induces an aggregate best-response mapping\n$$\nF_N(f) \\equiv \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\theta_i \\le f\\},\n$$\nwhich is the empirical cumulative distribution function of $\\{\\theta_i\\}_{i=1}^N$ evaluated at $f$. Starting from an initial belief $f_0 \\in [0,1]$, the aggregate belief updates according to the iterative scheme\n$$\nf_{t+1} = F_N(f_t), \\quad t = 0,1,2,\\dots\n$$\nwhich converges in finitely many steps to a fixed point $f^\\star$ satisfying $f^\\star = F_N(f^\\star)$ because $F_N$ maps $[0,1]$ to the discrete grid $\\{0,\\frac{1}{N},\\dots,\\frac{N}{N}\\}$ and is non-decreasing.\n\nYour task is to write a complete, runnable program that performs embarrassingly parallel simulation of this model by running many independent trials. In each trial, draw a fresh set of $\\{\\theta_i\\}_{i=1}^N$ from the specified Beta distribution, iterate the belief dynamics from the specified $f_0$ until convergence to $f^\\star$, record the final fraction $f^\\star$, and then determine whether a \"full run\" event occurred, defined as $f^\\star \\ge 0.95$. All trials are independent and can be processed without inter-trial communication.\n\nImplementation requirements:\n- Use a Pseudo Random Number Generator (PRNG) with a fixed seed for reproducibility as specified in the test suite below. Use the parameterization $\\alpha = m \\kappa$ and $\\beta = (1-m)\\kappa$ for the Beta distribution.\n- Convergence criterion: because $F_N$ maps into $\\{0,\\frac{1}{N},\\dots,\\frac{N}{N}\\}$, update until $f_{t+1} = f_t$ exactly.\n- To capture embarrassingly parallel structure, organize the computation so that trials do not depend on each other; vectorized computation across trials is acceptable.\n\nTest suite. For each of the following independent cases, compute the fraction of trials in which a full run occurs, output as a decimal:\n- Case $1$: $N = 500$, number of trials $T = 3000$, mean $m = 0.60$, concentration $\\kappa = 40$, initial belief $f_0 = 0.20$, PRNG seed $12345$.\n- Case $2$: $N = 500$, number of trials $T = 3000$, mean $m = 0.40$, concentration $\\kappa = 40$, initial belief $f_0 = 0.80$, PRNG seed $67890$.\n- Case $3$: $N = 500$, number of trials $T = 3000$, mean $m = 0.50$, concentration $\\kappa = 10$, initial belief $f_0 = 0.50$, PRNG seed $13579$.\n\nFinal output format. Your program should produce a single line of output containing the three results corresponding to Cases $1$–$3$, formatted as a comma-separated list enclosed in square brackets, with each probability rounded to exactly six decimal places (for example, $[0.123456,0.654321,0.000000]$). No other output should be produced.\n\nNote: There are no physical units or angle units in this problem. All answers must be expressed as decimals.", "solution": "The problem statement has been subjected to validation and is found to be scientifically grounded, well-posed, objective, and complete. All parameters and definitions are provided, and the model described is a standard stylized representation from computational economics. The problem is valid, and a solution will be provided.\n\nThe problem describes a simplified agent-based model of a bank run, a classic example of a coordination game with strategic complementarities. There are $N$ depositors, each characterized by a private panic threshold $\\theta_i$. These thresholds are drawn independently and identically from a Beta distribution specified by a mean $m$ and a concentration parameter $\\kappa$. The shape parameters of the Beta distribution, $\\alpha$ and $\\beta$, are determined by the relations $\\alpha = m \\kappa$ and $\\beta = (1-m)\\kappa$. A higher concentration $\\kappa$ implies that the depositors' thresholds are more tightly clustered around the mean $m$.\n\nThe core of the model is the dynamic evolution of the collective belief, denoted by $f$, which represents the expected fraction of depositors who will withdraw their funds. Each depositor $i$ follows a simple threshold rule: they withdraw if their personal panic threshold $\\theta_i$ is less than or equal to the prevailing belief $f$. This individual behavior aggregates to a macroscopic level. The new fraction of withdrawing depositors, which becomes the belief for the next period, is given by the aggregate best-response function:\n$$\nF_N(f) = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\theta_i \\le f\\}\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. This function is the empirical cumulative distribution function (ECDF) of the drawn thresholds $\\{\\theta_i\\}_{i=1}^N$. The system's dynamics are governed by the iterative map:\n$$\nf_{t+1} = F_N(f_t)\n$$\nstarting from an initial belief $f_0$. Since $F_N$ is a non-decreasing function that maps the interval $[0,1]$ to the finite set of values $\\{0, \\frac{1}{N}, \\frac{2}{N}, \\ldots, 1\\}$, this iterative process is guaranteed to converge to a fixed point $f^\\star$ where $f^\\star = F_N(f^\\star)$ in a finite number of steps. A \"full run\" is said to occur if this equilibrium fraction of withdrawals $f^\\star$ is at or above a critical level, specified as $0.95$.\n\nThe task is to simulate this process for a large number of independent trials, $T$, and to compute the empirical probability of a full run for different parameterizations. The independence of each trial—each with a fresh draw of $\\{\\theta_i\\}_{i=1}^N$—characterizes this as an embarrassingly parallel problem. This structure is ideally suited for vectorized computation, where all $T$ trials can be processed simultaneously rather than sequentially.\n\nThe simulation algorithm for a given test case proceeds as follows:\n\n$1$. **Initialization**: Set the problem parameters: number of depositors $N$, number of trials $T$, Beta distribution mean $m$ and concentration $\\kappa$, initial belief $f_0$, and the seed for the pseudo-random number generator (PRNG) to ensure reproducibility. Calculate the Beta shape parameters $\\alpha = m\\kappa$ and $\\beta = (1-m)\\kappa$.\n\n$2$. **Vectorized Threshold Generation**: Generate a $T \\times N$ matrix of thresholds, which we denote as $\\Theta$. Each row of this matrix corresponds to one trial and contains $N$ independent draws from the Beta$(\\alpha, \\beta)$ distribution.\n\n$3$. **Vectorized Iterative Dynamics**:\n    a. Initialize a vector $\\mathbf{f}$ of length $T$, where each element is set to the initial belief $f_0$. This vector represents the current belief $f_t$ for all $T$ trials simultaneously.\n    b. Enter an iterative loop that continues until the beliefs in all $T$ trials have converged. A maximum iteration count should be included as a safeguard, although convergence is mathematically guaranteed to be rapid.\n    c. In each step of the loop, calculate the next belief vector, $\\mathbf{f}_{\\text{next}}$, for all trials. This is done by applying the aggregate best-response function in a vectorized manner. For each trial $j \\in \\{1, \\dots, T\\}$, the next belief is $f_{t+1}^{(j)} = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\Theta_{ji} \\le f_t^{(j)}\\}$. This operation is performed for all $j$ at once by comparing the threshold matrix $\\Theta$ with the belief vector $\\mathbf{f}$ (appropriately broadcast) and then computing the mean across the depositor axis (axis $1$).\n    d. Check for convergence. If $\\mathbf{f}_{\\text{next}}$ is element-wise identical to $\\mathbf{f}$, it means $f_{t+1}^{(j)} = f_t^{(j)}$ for all trials $j$, and the system has reached a fixed point in every trial. The loop terminates.\n    e. If not converged, update the belief vector: $\\mathbf{f} \\leftarrow \\mathbf{f}_{\\text{next}}$.\n\n$4$. **Outcome Analysis**: After the loop terminates, the vector $\\mathbf{f}$ contains the equilibrium fixed points $f^\\star$ for all $T$ trials. The probability of a full run is estimated by computing the fraction of trials where $f^\\star \\ge 0.95$. This is calculated as the mean of the boolean vector resulting from the comparison $\\mathbf{f} \\ge 0.95$.\n\nThis procedure is repeated for each of the specified test cases. The use of NumPy's vectorized operations allows for an efficient implementation that directly reflects the problem's parallel structure without requiring explicit parallel programming libraries.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the bank run simulation problem for the specified test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: N=500, T=3000, m=0.60, k=40, f0=0.20, seed=12345\n        (500, 3000, 0.60, 40, 0.20, 12345),\n        # Case 2: N=500, T=3000, m=0.40, k=40, f0=0.80, seed=67890\n        (500, 3000, 0.40, 40, 0.80, 67890),\n        # Case 3: N=500, T=3000, m=0.50, k=10, f0=0.50, seed=13579\n        (500, 3000, 0.50, 10, 0.50, 13579),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, T, m, kappa, f0, seed = case\n        \n        # Initialize the pseudo-random number generator with the given seed.\n        rng = np.random.default_rng(seed)\n        \n        # Calculate the shape parameters for the Beta distribution.\n        alpha = m * kappa\n        beta = (1.0 - m) * kappa\n        \n        # In this embarrassingly parallel setup, we can simulate all trials at once.\n        # Generate a TxN matrix of panic thresholds. Each row is a separate trial.\n        thetas = rng.beta(alpha, beta, size=(T, N))\n        \n        # Initialize the belief vector for all T trials.\n        f_current = np.full(T, f0, dtype=float)\n        \n        # Set a practical limit on iterations to prevent any infinite loops,\n        # although convergence is guaranteed. N+2 is more than sufficient.\n        max_iter = N + 2\n        for _ in range(max_iter):\n            # To compute the next belief f_next, we need to compare the current belief f_current\n            # for each trial with the N thresholds for that trial.\n            # f_current[:, np.newaxis] broadcasts the (T,) vector to (T, 1) for comparison\n            # against the (T, N) thetas matrix.\n            # The result of the comparison is a boolean matrix. Taking the mean along axis=1\n            # gives the fraction of depositors who withdraw in each trial.\n            f_next = np.mean(thetas = f_current[:, np.newaxis], axis=1)\n            \n            # Check for convergence. If all trials have converged to a fixed point, break the loop.\n            if np.all(f_next == f_current):\n                break\n            \n            # Update the belief vector for the next iteration.\n            f_current = f_next\n        \n        # The converged beliefs are the fixed points f_star.\n        f_star = f_current\n        \n        # A \"full run\" is defined as f_star >= 0.95.\n        # We calculate the fraction of trials where this occurred.\n        # np.mean on a boolean array counts the True values and divides by the total count.\n        full_run_probability = np.mean(f_star >= 0.95)\n        \n        results.append(full_run_probability)\n\n    # Format the final results as a comma-separated list of strings,\n    # with each number rounded to exactly six decimal places.\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```", "id": "2389979"}, {"introduction": "Our final exercise integrates the parameter sweep and Monte Carlo methods to address a contemporary policy question: the effect of a Universal Basic Income (UBI) on labor supply. You will simulate a population of heterogeneous agents who make optimal labor supply choices under various UBI and tax rate scenarios. This practice showcases a powerful application of embarrassingly parallel computation, where each policy configuration is evaluated through its own set of independent Monte Carlo trials to average out idiosyncratic randomness. [@problem_id:2390040]", "problem": "Consider a simple agent-based labor supply model designed to isolate an embarrassingly parallel parameter sweep over a universal basic income (UBI) and a labor income tax rate. Each agent chooses labor supply to maximize a static utility subject to a linear budget constraint and exogenous income components. The economic environment, distributions, and decision problems are defined as follows.\n\n- Decision variable for each agent is labor supply $l \\in [0,1]$.\n- For a given universal basic income (UBI) amount $y \\ge 0$ and tax rate $\\tau \\in [0,1]$ (expressed as a decimal, not a percentage), agent $i$ with productivity $w_i  0$ and disutility parameter $\\phi_i  0$ has consumption $c$ and period utility:\n  - Budget constraint: $c = (1 - \\tau)\\, w_i\\, l + y + \\varepsilon$.\n  - Utility: $U_i(l; y,\\tau,w_i,\\phi_i,\\varepsilon) = \\log(c) - \\frac{\\phi_i}{2}\\, l^2$.\n- Idiosyncratic productivity $w_i$ and disutility parameter $\\phi_i$ are heterogeneous across agents and are independently and identically distributed draws from lognormal distributions, with parameters for the underlying normal distributions given by $(\\mu_w,\\sigma_w)$ and $(\\mu_\\phi,\\sigma_\\phi)$ respectively. Specifically, $w_i \\sim \\operatorname{Lognormal}(\\mu_w,\\sigma_w^2)$ and $\\phi_i \\sim \\operatorname{Lognormal}(\\mu_\\phi,\\sigma_\\phi^2)$.\n- The shock to non-labor income $\\varepsilon$ is independently and identically distributed across agents and simulation replications, with $\\varepsilon \\sim \\operatorname{Exponential}(\\lambda)$, and mean $\\mathbb{E}[\\varepsilon] = 1/\\lambda$ strictly positive.\n\nFor any given pair $(y,\\tau)$, define the agent’s optimization problem as: choose $l \\in [0,1]$ to maximize $U_i(l; y,\\tau,w_i,\\phi_i,\\varepsilon)$.\n\nMonte Carlo experiment specification:\n- Number of agents: $N = 10000$.\n- Number of shock replications per agent: $K = 16$.\n- Distribution parameters: $\\mu_w = 0$, $\\sigma_w = 0.5$; $\\mu_\\phi = 0$, $\\sigma_\\phi = 0.5$.\n- Exponential shock mean: $\\mathbb{E}[\\varepsilon] = m_\\varepsilon = 0.5$ (hence $\\lambda = 1/m_\\varepsilon$).\n- Treat every $(y,\\tau)$ pair independently so the parameter sweep is embarrassingly parallel. Use independent random number generator seeding for each pair to make results reproducible and independent of evaluation order. Use the base seed $12345$, and for the $j$-th test case (zero-based index), use seed $12345 + j$.\n\nTask:\n- For each $(y,\\tau)$ pair in the test suite below, simulate the economy described above and compute the expected labor supply $\\mathbb{E}[l^\\star(y,\\tau)]$, where $l^\\star(y,\\tau)$ denotes the agent’s optimal labor supply given $(y,\\tau)$, the agent’s type $(w_i,\\phi_i)$, and the draw $\\varepsilon$. The expectation is taken over the joint distribution of agent heterogeneity and shocks, approximated by the Monte Carlo experiment as an average across $N$ agents and $K$ shocks.\n- For each agent and each shock draw, solve the utility maximization problem exactly over $l \\in [0,1]$; do not discretize $l$. If an interior solution exists, use it; otherwise, compare the objective at the boundaries $l=0$ and $l=1$ and select the maximizing value.\n\nTest suite (parameter sweep over UBI $y$ and tax rate $\\tau$):\n1. $(y,\\tau) = (0.0, 0.0)$\n2. $(y,\\tau) = (0.0, 1.0)$\n3. $(y,\\tau) = (1.0, 0.0)$\n4. $(y,\\tau) = (1.0, 0.5)$\n5. $(y,\\tau) = (2.0, 0.8)$\n6. $(y,\\tau) = (3.0, 0.0)$\n7. $(y,\\tau) = (0.0, 0.8)$\n\nFinal output format:\n- Your program must produce a single line with a Python-style list containing the Monte Carlo estimates of $\\mathbb{E}[l^\\star(y,\\tau)]$ for the above test cases in the listed order. Each value must be rounded to exactly $6$ decimal places. For example, a valid output would look like:\n  - $[\\dots]$ where each entry has exactly $6$ digits after the decimal point.\n- There are no physical units or angles involved. The tax rate must be treated as a decimal, not a percentage.\n\nImplementation constraints:\n- The parameter sweep must be treated in an embarrassingly parallel fashion: each $(y,\\tau)$ case is computed independently with its own random seed. The program must be entirely self-contained and require no user input.", "solution": "The problem will first be subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe problem statement provides the following definitions and parameters:\n\n- **Agent Decision Problem**:\n    - Decision variable: labor supply $l \\in [0,1]$.\n    - Budget constraint: $c = (1 - \\tau)\\, w_i\\, l + y + \\varepsilon$.\n    - Utility function: $U_i(l; y,\\tau,w_i,\\phi_i,\\varepsilon) = \\log(c) - \\frac{\\phi_i}{2}\\, l^2$.\n    - Policy variables: universal basic income (UBI) $y \\ge 0$, tax rate $\\tau \\in [0,1]$.\n    - Agent-specific parameters: productivity $w_i  0$, disutility of labor parameter $\\phi_i  0$.\n    - Exogenous shock: non-labor income shock $\\varepsilon$.\n\n- **Stochastic Environment**:\n    - Productivity distribution: $w_i \\sim \\operatorname{Lognormal}(\\mu_w, \\sigma_w^2)$ with $\\mu_w = 0, \\sigma_w = 0.5$.\n    - Disutility parameter distribution: $\\phi_i \\sim \\operatorname{Lognormal}(\\mu_\\phi, \\sigma_\\phi^2)$ with $\\mu_\\phi = 0, \\sigma_\\phi = 0.5$.\n    - Shock distribution: $\\varepsilon \\sim \\operatorname{Exponential}(\\lambda)$ with mean $\\mathbb{E}[\\varepsilon] = m_\\varepsilon = 0.5$, implying $\\lambda = 1/m_\\varepsilon = 2$.\n\n- **Monte Carlo Experiment Specification**:\n    - Number of agents: $N = 10000$.\n    - Number of shock replications per agent: $K = 16$.\n    - Random number generation: Base seed is $12345$. For the $j$-th test case (0-indexed), the seed is $12345 + j$.\n\n- **Task**:\n    - For each given $(y, \\tau)$ pair, compute the expected optimal labor supply $\\mathbb{E}[l^\\star(y,\\tau)]$.\n    - The expectation is approximated by the sample average over $N \\times K$ simulations.\n    - The optimization problem for $l$ must be solved analytically over the continuous domain $[0,1]$.\n\n- **Test Suite**:\n    1. $(y,\\tau) = (0.0, 0.0)$\n    2. $(y,\\tau) = (0.0, 1.0)$\n    3. $(y,\\tau) = (1.0, 0.0)$\n    4. $(y,\\tau) = (1.0, 0.5)$\n    5. $(y,\\tau) = (2.0, 0.8)$\n    6. $(y,\\tau) = (3.0, 0.0)$\n    7. $(y,\\tau) = (0.0, 0.8)$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity against the established criteria.\n\n- **Scientifically Grounded**: The model is a standard, albeit simplified, static labor supply model from microeconomic theory. The use of logarithmic utility for consumption and quadratic disutility for labor is a common and well-understood formulation (e.g., King-Plosser-Rebelo preferences). The distributions chosen (Lognormal for persistent heterogeneity, Exponential for shocks) are standard in computational economics. The problem is firmly grounded in established economic principles.\n\n- **Well-Posed**: The agent's optimization problem is to maximize a continuous utility function over a compact set $l \\in [0,1]$. The utility function's argument $c$ must be positive for $\\log(c)$ to be defined. Given $w_i  0$, $\\phi_i  0$, $y \\ge 0$, $\\tau \\in [0,1]$, $l \\in [0,1]$, and $\\varepsilon$ is a draw from an Exponential distribution (so $\\varepsilon \\ge 0$), the consumption $c = (1-\\tau)w_i l + y + \\varepsilon$ is a sum of non-negative terms. Since $w_i$ and $\\varepsilon$ are drawn from continuous distributions, the probability of them being exactly zero is zero. Thus, $c  0$ is assured almost surely, making the logarithm well-defined. The utility function $U(l)$ is strictly concave in $l$, as it is the sum of a concave function ($\\log(c)$, which is a concave function of a linear function of $l$) and another concave function ($-\\frac{\\phi_i}{2}l^2$). The maximization of a strictly concave function over a compact convex set has a unique solution. The problem is therefore well-posed.\n\n- **Objective**: The problem is specified with mathematical precision. All terms are defined, and parameters are given explicit values. There is no subjective or ambiguous language.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or infeasibility.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be developed.\n\n### Solution Derivation\n\nThe core of the problem is to find the optimal labor supply $l^\\star$ for an agent by solving the following optimization problem for each set of parameters $(y, \\tau, w_i, \\phi_i, \\varepsilon)$:\n$$\n\\max_{l \\in [0,1]} U(l) = \\log((1-\\tau)w_i l + y + \\varepsilon) - \\frac{\\phi_i}{2}l^2\n$$\n\nTo find an interior solution, we compute the first derivative of the utility function with respect to $l$ and set it to zero. This is the first-order condition (FOC).\nLet $W_i \\equiv (1-\\tau)w_i$ be the post-tax wage rate and $Y_{i} \\equiv y + \\varepsilon$ be the non-labor income component. The utility function becomes $U(l) = \\log(W_i l + Y_i) - \\frac{\\phi_i}{2}l^2$. The FOC is:\n$$\n\\frac{\\partial U}{\\partial l} = \\frac{W_i}{W_i l + Y_i} - \\phi_i l = 0\n$$\nThis assumes an interior solution $l \\in (0,1)$. Rearranging the terms gives:\n$$\n\\frac{W_i}{W_i l + Y_i} = \\phi_i l\n$$\n$$\nW_i = \\phi_i l (W_i l + Y_i)\n$$\n$$\nW_i = \\phi_i W_i l^2 + \\phi_i Y_i l\n$$\nThis can be written as a quadratic equation in $l$:\n$$\n(\\phi_i W_i) l^2 + (\\phi_i Y_i) l - W_i = 0\n$$\nThis is of the form $al^2 + bl + c = 0$, with coefficients $a = \\phi_i W_i$, $b = \\phi_i Y_i$, and $c = -W_i$.\n\nA special case arises when $\\tau=1$. In this case, $W_i = (1-1)w_i = 0$. The coefficients of the quadratic equation become ill-defined. We must return to the FOC. If $W_i=0$, the FOC simplifies to $-\\phi_i l = 0$, which implies $l=0$. This is intuitive: if labor income is taxed at $100\\%$, there is no incentive to work. Thus, for $\\tau=1$, the optimal labor supply is $l^\\star = 0$.\n\nFor $\\tau  1$, we have $W_i  0$ (since $w_i  0$). We can solve the quadratic equation for $l$ using the quadratic formula:\n$$\nl_{int} = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{-\\phi_i Y_i \\pm \\sqrt{(\\phi_i Y_i)^2 - 4(\\phi_i W_i)(-W_i)}}{2\\phi_i W_i}\n$$\n$$\nl_{int} = \\frac{-\\phi_i Y_i \\pm \\sqrt{\\phi_i^2 Y_i^2 + 4\\phi_i W_i^2}}{2\\phi_i W_i}\n$$\nSince labor supply $l$ cannot be negative, we must take the positive root:\n$$\nl_{int} = \\frac{-\\phi_i Y_i + \\sqrt{\\phi_i^2 Y_i^2 + 4\\phi_i W_i^2}}{2\\phi_i W_i}\n$$\nThis formula can be simplified for better numerical stability:\n$$\nl_{int} = -\\frac{Y_i}{2W_i} + \\sqrt{\\left(\\frac{Y_i}{2W_i}\\right)^2 + \\frac{1}{\\phi_i}}\n$$\nThis value $l_{int}$ represents the unconstrained optimal labor supply. However, the choice is constrained to the interval $[0,1]$. The utility function is strictly concave, which means that the constrained optimum $l^\\star$ is obtained by simply clamping the unconstrained optimum to the feasible interval:\n- If $l_{int}  0$, the function is decreasing over $[0,1]$, so $l^\\star = 0$.\n- If $l_{int}  1$, the function is increasing over $[0,1]$, so $l^\\star = 1$.\n- If $0 \\le l_{int} \\le 1$, the unconstrained optimum is feasible, so $l^\\star = l_{int}$.\n\nThis can be expressed concisely as $l^\\star = \\max(0, \\min(l_{int}, 1))$.\n\n### Monte Carlo Simulation Algorithm\nFor each test case $(y, \\tau)$, the expected labor supply $\\mathbb{E}[l^\\star]$ is approximated by a sample average over a large number of simulated agents and shocks. The procedure for each test case $(y_j, \\tau_j)$ with index $j$ is as follows:\n\n1.  **Set Seed**: Initialize the random number generator with seed $12345 + j$ to ensure reproducibility and independence across test cases.\n2.  **Generate Heterogeneity**: Draw $N = 10000$ independent values for agent productivity, $\\{w_i\\}_{i=1}^N$, from $\\operatorname{Lognormal}(\\mu_w, \\sigma_w^2)$. Draw $N = 10000$ independent values for the disutility parameter, $\\{\\phi_i\\}_{i=1}^N$, from $\\operatorname{Lognormal}(\\mu_\\phi, \\sigma_\\phi^2)$.\n3.  **Generate Shocks**: For each agent $i$, draw $K = 16$ independent values for the income shock, $\\{\\varepsilon_{ik}\\}_{k=1}^K$, from $\\operatorname{Exponential}(\\lambda)$. This results in a total of $N \\times K$ shocks.\n4.  **Compute Optimal Labor**: For each of the $N \\times K$ combinations of $(w_i, \\phi_i, \\varepsilon_{ik})$:\n    *   If $\\tau_j = 1$, set $l^\\star_{ik} = 0$.\n    *   If $\\tau_j  1$, calculate $W_i = (1-\\tau_j)w_i$ and $Y_{ik} = y_j + \\varepsilon_{ik}$. Then compute the unconstrained optimum $l_{int}$ using the derived formula. Finally, find the constrained optimum $l^\\star_{ik} = \\max(0, \\min(l_{int}, 1))$.\n5.  **Estimate Expectation**: Compute the sample mean of all calculated optimal labor supply values:\n$$\n\\mathbb{E}[l^\\star(y_j, \\tau_j)] \\approx \\frac{1}{N \\cdot K} \\sum_{i=1}^{N} \\sum_{k=1}^{K} l^\\star_{ik}\n$$\nThis process is repeated for each $(y, \\tau)$ pair in the test suite. A vectorized implementation using `numpy` is highly efficient for this task, as it avoids explicit loops over agents and shocks by operating on arrays of random numbers.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the expected labor supply in an agent-based model\n    across a parameter sweep of UBI (y) and tax rate (tau).\n    \"\"\"\n\n    # Monte Carlo experiment specification\n    N_AGENTS = 10000\n    K_SHOCKS = 16\n    \n    # Distribution parameters\n    MU_W, SIGMA_W = 0.0, 0.5\n    MU_PHI, SIGMA_PHI = 0.0, 0.5\n    MEAN_EPSILON = 0.5  # This is the scale parameter 1/lambda for np.random.exponential\n    \n    BASE_SEED = 12345\n\n    # Test suite of (y, tau) pairs\n    test_cases = [\n        (0.0, 0.0),  # case 0\n        (0.0, 1.0),  # case 1\n        (1.0, 0.0),  # case 2\n        (1.0, 0.5),  # case 3\n        (2.0, 0.8),  # case 4\n        (3.0, 0.0),  # case 5\n        (0.0, 0.8),  # case 6\n    ]\n\n    results = []\n\n    for j, (y, tau) in enumerate(test_cases):\n        # Set seed for reproducibility for this specific test case\n        seed = BASE_SEED + j\n        rng = np.random.default_rng(seed)\n\n        # Generate agent heterogeneity parameters (w_i, phi_i)\n        # w_i ~ Lognormal(mu_w, sigma_w^2)\n        w = rng.lognormal(mean=MU_W, sigma=SIGMA_W, size=N_AGENTS)\n        # phi_i ~ Lognormal(mu_phi, sigma_phi^2)\n        phi = rng.lognormal(mean=MU_PHI, sigma=SIGMA_PHI, size=N_AGENTS)\n\n        # Handle the special case of 100% tax rate\n        if tau == 1.0:\n            # If labor income is taxed at 100%, optimal labor is always 0.\n            expected_l_star = 0.0\n        else:\n            # Generate idiosyncratic shocks for each agent and replication\n            # epsilon ~ Exponential(lambda) where mean = 1/lambda\n            # Scale parameter for numpy's exponential is the mean.\n            epsilon = rng.exponential(scale=MEAN_EPSILON, size=(N_AGENTS, K_SHOCKS))\n\n            # Reshape 1D agent-specific arrays to (N_AGENTS, 1) for broadcasting\n            w_bc = w.reshape(-1, 1)\n            phi_bc = phi.reshape(-1, 1)\n\n            # Calculate parameters for the utility maximization problem\n            # W is post-tax wage rate\n            W = (1.0 - tau) * w_bc\n            # Y is non-labor income\n            Y = y + epsilon\n            \n            # Using the simplified and numerically stable formula for the interior solution:\n            # l_int = -Y/(2W) + sqrt((Y/(2W))^2 + 1/phi)\n            Z = Y / (2.0 * W)\n            phi_inv = 1.0 / phi_bc\n            \n            # The calculation is vectorized across all agents and shocks\n            l_int = -Z + np.sqrt(Z**2 + phi_inv)\n            \n            # The optimal labor supply l_star must be in [0, 1].\n            # We clamp the interior solution to this interval.\n            l_star = np.clip(l_int, 0.0, 1.0)\n            \n            # The expectation is the mean over all N_AGENTS*K_SHOCKS simulations\n            expected_l_star = np.mean(l_star)\n        \n        results.append(expected_l_star)\n\n    # Format the results to exactly 6 decimal places as strings\n    formatted_results = [f\"{res:.6f}\" for res in results]\n\n    # Print the final output in the required format\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2390040"}]}