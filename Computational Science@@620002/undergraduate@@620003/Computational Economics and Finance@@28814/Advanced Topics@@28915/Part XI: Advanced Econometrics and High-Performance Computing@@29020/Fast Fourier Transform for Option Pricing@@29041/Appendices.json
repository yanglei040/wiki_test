{"hands_on_practices": [{"introduction": "To begin our hands-on exploration, we first establish a core computational technique: using the Fast Fourier Transform to determine the probability distribution of a sum of random variables. This practice is fundamental, as multi-period asset returns are modeled as such sums. By leveraging the properties of characteristic functions, you will implement an FFT-based method to compute a density function and, in doing so, numerically verify the cornerstone Central Limit Theorem [@problem_id:2392443].", "problem": "You are given independent and identically distributed (i.i.d.) one-period log-returns whose single-period distribution is Laplace with mean $0$ and scale parameter $b$, that is, with density $f_{X}(x) = \\frac{1}{2b}\\exp(-|x|/b)$ and characteristic function $\\varphi_{X}(u) = \\mathbb{E}[e^{iuX}]$. In computational economics and finance, multi-period log-returns for horizon $n$ are the sum $S_{n} = X_{1} + \\cdots + X_{n}$, which is central in pricing and risk measurement. The Fast Fourier Transform (FFT) is a critical tool for efficiently convolving distributions and inverting characteristic functions, which also underpins Fourier-based option valuation. Your task is to use the FFT to compute the probability density of $S_{n}$ and to numerically illustrate the Central Limit Theorem (CLT) by comparing that density to the Gaussian with matched mean and variance.\n\nStarting only from the following foundational facts:\n- The characteristic function of a random variable $X$ is $\\varphi_{X}(u) = \\mathbb{E}[e^{iuX}]$.\n- If $X_{1},\\dots,X_{n}$ are i.i.d., then $\\varphi_{S_{n}}(u) = [\\varphi_{X}(u)]^{n}$ for $S_{n} = \\sum_{k=1}^{n} X_{k}$.\n- The (inverse) Fourier transform representation of the density (when it exists) is\n$$\nf_{S_{n}}(x) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} e^{-iux}\\,\\varphi_{S_{n}}(u)\\,du.\n$$\n- The Discrete Fourier Transform (DFT) and its inverse provide Riemann-sum approximations to integrals of the form above on an evenly spaced grid, and the Fast Fourier Transform (FFT) computes the DFT in $\\mathcal{O}(N\\log N)$ time.\n\nDerive a numerically stable FFT-based algorithm to approximate $f_{S_{n}}(x)$ on an evenly spaced spatial grid $\\{x_{j}\\}_{j=0}^{N-1}$ over a symmetric interval $[-X_{\\max},X_{\\max}]$, by sampling the frequency grid $\\{u_{k}\\}_{k=0}^{N-1}$ over $[-U_{\\max},U_{\\max}]$ with $N$ even and the grid spacings obeying\n$$\n\\Delta x\\,\\Delta u = \\frac{2\\pi}{N},\\quad X_{\\max} = \\frac{N\\Delta x}{2},\\quad U_{\\max} = \\frac{N\\Delta u}{2}.\n$$\nChoose $X_{\\max}$ as a multiple of the standard deviation of $S_{n}$ to control wrap-around aliasing. Then, numerically validate the Central Limit Theorem by comparing your FFT-based density to a Gaussian with mean $0$ and variance $\\sigma^{2} = \\mathrm{Var}(S_{n})$, where for Laplace increments $\\mathrm{Var}(X) = 2b^{2}$ and hence $\\sigma^{2} = 2nb^{2}$.\n\nYour program must:\n- Implement the FFT-based inversion to obtain an approximation to $f_{S_{n}}(x)$ for Laplace($0,b$) increments. Use only the above foundational facts to design the numerical scheme and explicitly construct the frequency and spatial grids satisfying $\\Delta x\\,\\Delta u = \\frac{2\\pi}{N}$, with $N$ a power of $2$.\n- For each test case, compute two diagnostics to quantify the CLT and numerical accuracy:\n    1. The $\\mathcal{L}^{1}$ distance between the FFT density and the Gaussian density with matched variance,\n    $$\n    \\varepsilon_{\\mathrm{L1}} \\approx \\sum_{j=0}^{N-1} \\left| f^{\\mathrm{FFT}}_{S_{n}}(x_{j}) - \\phi_{\\mathcal{N}(0,\\sigma^{2})}(x_{j}) \\right|\\,\\Delta x.\n    $$\n    2. The mass error of the FFT density,\n    $$\n    \\varepsilon_{\\mathrm{mass}} \\approx \\left|\\sum_{j=0}^{N-1} f^{\\mathrm{FFT}}_{S_{n}}(x_{j})\\,\\Delta x - 1\\right|.\n    $$\n- Use $N = 2^{14}$ and select $X_{\\max} = m_{\\sigma}\\,\\sigma$ with $m_{\\sigma} = 12$ for all test cases. Angles in any trigonometric or complex exponentials are in radians.\n\nTest Suite:\nUse the following four parameter sets $(n,b)$:\n- Case $1$: $(n,b) = (1,\\,0.5)$.\n- Case $2$: $(n,b) = (5,\\,0.5)$.\n- Case $3$: $(n,b) = (50,\\,0.5)$.\n- Case $4$: $(n,b) = (2,\\,0.1)$.\n\nFor each case, compute $(\\varepsilon_{\\mathrm{L1}}, \\varepsilon_{\\mathrm{mass}})$ as $2$ floating-point numbers. Your program should produce a single line of output containing all results concatenated in case order, and within each case in the order $(\\varepsilon_{\\mathrm{L1}}, \\varepsilon_{\\mathrm{mass}})$, rounded to six decimal places, as a comma-separated list enclosed in square brackets, for example:\n\"[e11,e12,e21,e22,e31,e32,e41,e42]\".", "solution": "The user-provided problem is assessed to be **valid**. It is scientifically grounded in the principles of probability theory and Fourier analysis, specifically concerning the properties of characteristic functions and their numerical inversion via the Fast Fourier Transform (FFT). The problem is well-posed, with all necessary parameters and constraints provided for a unique numerical solution. The objective is clearly stated and falls within the standard practices of computational finance and quantitative analysis.\n\n### Theoretical Framework and Algorithm Design\n\nThe primary objective is to compute the probability density function (PDF) $f_{S_{n}}(x)$ of the sum of $n$ independent and identically distributed (i.i.d.) random variables, $S_{n} = \\sum_{k=1}^{n} X_{k}$. Each $X_{k}$ follows a Laplace distribution with mean $0$ and scale parameter $b$, denoted as Laplace($0, b$).\n\n**1. Characteristic Function**\n\nThe characteristic function of a single Laplace($0,b$) random variable $X$ is given by $\\varphi_{X}(u) = \\mathbb{E}[e^{iuX}]$. It can be derived from the density $f_X(x) = \\frac{1}{2b}\\exp(-|x|/b)$ as:\n$$\n\\varphi_{X}(u) = \\int_{-\\infty}^{\\infty} e^{iux} \\frac{1}{2b}e^{-|x|/b} dx = \\frac{1}{1 + b^2 u^2}\n$$\nGiven that the variables $X_k$ are i.i.d., the characteristic function of their sum $S_n$ is the product of their individual characteristic functions, which simplifies to:\n$$\n\\varphi_{S_{n}}(u) = [\\varphi_{X}(u)]^n = \\left(\\frac{1}{1 + b^2 u^2}\\right)^n\n$$\n\n**2. Fourier Inversion for the Density**\n\nThe PDF $f_{S_{n}}(x)$ can be recovered from its characteristic function $\\varphi_{S_{n}}(u)$ using the inverse Fourier transform:\n$$\nf_{S_{n}}(x) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} e^{-iux}\\,\\varphi_{S_{n}}(u)\\,du\n$$\n\n**3. Discretization and FFT-based Algorithm**\n\nTo compute this integral numerically, we truncate the integration domain to $[-U_{\\max}, U_{\\max}]$ and approximate the integral with a Riemann sum over a discrete grid. The problem specifies a symmetric spatial grid $\\{x_j\\}$ and frequency grid $\\{u_k\\}$, both of size $N$, centered at zero.\n\nThe grids are defined as:\n- Spatial grid: $x_j = (j - N/2)\\Delta x$ for $j = 0, \\dots, N-1$.\n- Frequency grid: $u_k = (k - N/2)\\Delta u$ for $k = 0, \\dots, N-1$.\n\nThe grid spacings must satisfy the relation $\\Delta x \\Delta u = 2\\pi/N$, which is fundamental for FFT-based Fourier transform approximations. The problem-specified truncation parameters are $X_{\\max} = N\\Delta x/2$ and $U_{\\max} = N\\Delta u/2$. From these, we derive $\\Delta u = \\frac{2\\pi}{N\\Delta x} = \\frac{\\pi}{X_{\\max}}$.\n\nThe discretized approximation of the integral at grid points $x_j$ is:\n$$\nf_{S_{n}}(x_j) \\approx \\frac{1}{2\\pi} \\sum_{k=0}^{N-1} e^{-iu_k x_j}\\,\\varphi_{S_{n}}(u_k)\\,\\Delta u\n$$\nTo relate this sum to the standard Discrete Fourier Transform (DFT), which is efficiently computed by the FFT algorithm, we analyze the exponential term:\n$$\n-iu_k x_j = -i \\left(k - \\frac{N}{2}\\right)\\Delta u \\left(j - \\frac{N}{2}\\right)\\Delta x = -i \\left(k - \\frac{N}{2}\\right)\\left(j - \\frac{N}{2}\\right) \\frac{2\\pi}{N}\n$$\nExpanding this gives:\n$$\n-iu_k x_j = -i\\frac{2\\pi}{N}\\left(kj - \\frac{N}{2}k - \\frac{N}{2}j + \\frac{N^2}{4}\\right)\n$$\nThe exponential term becomes:\n$$\ne^{-iu_k x_j} = e^{-i\\frac{2\\pi}{N}kj} e^{i\\pi k} e^{i\\pi j} e^{-i\\pi\\frac{N}{2}}\n$$\nSince $N=2^{14}$, $N/2=2^{13}$ is an even integer. Therefore, $e^{-i\\pi N/2} = \\cos(-\\pi N/2) + i\\sin(-\\pi N/2) = \\cos(2^{12}\\pi) - i\\sin(2^{12}\\pi) = 1$. The terms $e^{i\\pi k}$ and $e^{i\\pi j}$ are equal to $(-1)^k$ and $(-1)^j$, respectively. The exponential simplifies to:\n$$\ne^{-iu_k x_j} = (-1)^{k+j} e^{-i\\frac{2\\pi}{N}kj}\n$$\nSubstituting this back into the sum, we get:\n$$\nf_{S_{n}}(x_j) \\approx \\frac{\\Delta u}{2\\pi} \\sum_{k=0}^{N-1} (-1)^{k+j} e^{-i\\frac{2\\pi}{N}kj}\\,\\varphi_{S_{n}}(u_k) = \\frac{\\Delta u}{2\\pi} (-1)^j \\sum_{k=0}^{N-1} \\left[(-1)^k \\varphi_{S_{n}}(u_k)\\right] e^{-i\\frac{2\\pi}{N}kj}\n$$\nThe sum is now in the form of a DFT. The `scipy.fft.fft` function computes $F_j = \\sum_{k=0}^{N-1} Y_k e^{-i\\frac{2\\pi}{N}kj}$. By setting $Y_k = (-1)^k \\varphi_{S_{n}}(u_k)$, the density is given by:\n$$\nf^{\\mathrm{FFT}}_{S_{n}}(x_j) = \\frac{\\Delta u}{2\\pi} (-1)^j \\text{Re}\\left(\\text{FFT}\\left[(-1)^k \\varphi_{S_{n}}(u_k)\\right]_j\\right)\n$$\nWe take the real part as the PDF must be real-valued, and any imaginary component is due to numerical floating-point errors.\n\n**4. Central Limit Theorem and Diagnostics**\n\nThe Central Limit Theorem (CLT) states that, under certain conditions, the sum of a large number of i.i.d. random variables will be approximately normally distributed. The mean of $S_n$ is $\\mathbb{E}[S_n] = n\\mathbb{E}[X] = 0$. The variance is $\\mathrm{Var}(S_n) = n\\mathrm{Var}(X) = n(2b^2) = 2nb^2$.\nWe compare our FFT-computed density to the Gaussian PDF $\\phi_{\\mathcal{N}(0,\\sigma^{2})}(x)$ with matched mean $0$ and variance $\\sigma^2 = 2nb^2$:\n$$\n\\phi_{\\mathcal{N}(0,\\sigma^{2})}(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)\n$$\nThe comparison is quantified using two metrics:\n1.  **$\\mathcal{L}^1$ distance**: $\\varepsilon_{\\mathrm{L1}} = \\int |f^{\\mathrm{FFT}}_{S_{n}}(x) - \\phi_{\\mathcal{N}(0,\\sigma^{2})}(x)| dx$, approximated by the sum $\\sum_{j=0}^{N-1} \\left| f^{\\mathrm{FFT}}_{S_{n}}(x_{j}) - \\phi_{\\mathcal{N}(0,\\sigma^{2})}(x_{j}) \\right|\\,\\Delta x$.\n2.  **Mass error**: $\\varepsilon_{\\mathrm{mass}} = |\\int f^{\\mathrm{FFT}}_{S_{n}}(x) dx - 1|$, approximated by $\\left|\\sum_{j=0}^{N-1} f^{\\mathrm{FFT}}_{S_{n}}(x_{j})\\,\\Delta x - 1\\right|$. This metric assesses the numerical accuracy of the FFT inversion (discretization and truncation errors).\n\nThe algorithm is executed for each test case $(n, b)$ to compute these two diagnostics.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import fft\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 0.5),  # Case 1\n        (5, 0.5),  # Case 2\n        (50, 0.5), # Case 3\n        (2, 0.1),  # Case 4\n    ]\n\n    results = []\n    \n    # Numerical parameters\n    N = 2**14\n    m_sigma = 12.0\n\n    for n, b in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        \n        # 1. Calculate variance and set up grid parameters based on it.\n        # Variance of the sum of n i.i.d. Laplace(0, b) variables.\n        sigma_sq = 2.0 * n * b**2\n        sigma = np.sqrt(sigma_sq)\n        \n        # Truncation range for the spatial domain.\n        X_max = m_sigma * sigma\n        \n        # Grid spacing for spatial and frequency domains.\n        # dx: spatial step, du: frequency step.\n        dx = 2.0 * X_max / N\n        du = (2.0 * np.pi) / (N * dx)\n\n        # 2. Create centered spatial and frequency grids.\n        # Indices for grid construction.\n        j_indices = np.arange(N)\n        k_indices = np.arange(N)\n        \n        # x_grid: Spatial points from -X_max to X_max - dx.\n        x_grid = (j_indices - N / 2.0) * dx\n        \n        # u_grid: Frequency points.\n        u_grid = (k_indices - N / 2.0) * du\n\n        # 3. Compute the density using the FFT-based inversion.\n        # Characteristic function of S_n evaluated on the frequency grid.\n        phi_of_u = (1.0 + b**2 * u_grid**2)**(-n)\n        \n        # Prepare the vector for FFT according to the shift theorem.\n        # This handles the centered grids correctly.\n        Y_k = phi_of_u * (-1.0)**k_indices\n        \n        # Perform the Fast Fourier Transform.\n        F_j = fft(Y_k)\n        \n        # Recover the density from the FFT output, applying scaling and shift.\n        # The result must be real, so we take np.real to discard numerical noise.\n        f_fft = (du / (2.0 * np.pi)) * np.real((-1.0)**j_indices * F_j)\n        \n        # 4. Compute the Gaussian PDF for comparison (Central Limit Theorem).\n        # The Gaussian has the same mean (0) and variance (sigma_sq) as S_n.\n        gaussian_pdf = (1.0 / np.sqrt(2.0 * np.pi * sigma_sq)) * np.exp(-x_grid**2 / (2.0 * sigma_sq))\n        \n        # 5. Calculate the diagnostic metrics.\n        # L1 distance between the FFT density and the Gaussian density.\n        # This is a numerical approximation of the L1 integral.\n        eps_L1 = np.sum(np.abs(f_fft - gaussian_pdf)) * dx\n        \n        # Mass error of the FFT density.\n        # This checks if the numerical density integrates to 1.\n        total_mass = np.sum(f_fft) * dx\n        eps_mass = np.abs(total_mass - 1.0)\n        \n        # Append formatted results to the list.\n        results.append(\"{:.6f}\".format(eps_L1))\n        results.append(\"{:.6f}\".format(eps_mass))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2392443"}, {"introduction": "Building on our ability to work in the frequency domain, we now apply the FFT to a quintessential task in derivatives pricing: the calculation of option sensitivities, or \"Greeks.\" This exercise showcases one of the most elegant properties of the Fourier transform—its ability to convert calculus into algebra. You will derive and implement a method to calculate an option's Gamma by performing a simple multiplication in the frequency domain, a technique far more efficient and stable than traditional \"bumping\" methods [@problem_id:2392450].", "problem": "You are asked to verify, by computation, the convergence of the central-difference approximation for the second derivative of the option price with respect to the spot price (the Gamma), towards the derivative computed analytically in the Fourier domain, as the spot bump size tends to zero. Work in a Black–Scholes setting and use the Fast Fourier Transform (FFT) to evaluate the required Fourier integrals.\n\nAssume the following foundational base:\n\n- Under the risk-neutral measure, the discounted asset price is a martingale. In the Black–Scholes model, the log-price $x_t = \\ln S_t$ has dynamics $x_T \\sim \\mathcal{N}\\left(x_0 + (r - q - \\tfrac{1}{2}\\sigma^2)T,\\ \\sigma^2 T\\right)$, where $S_0 = e^{x_0}$, $r$ is the continuously compounded risk-free rate, $q$ is the continuous dividend yield, $\\sigma$ is the volatility, and $T$ is the maturity. The characteristic function of $x_T$ is\n$$\n\\varphi_{x_T}(u) = \\mathbb{E}\\left[e^{i u x_T}\\right] = \\exp\\left( i u \\left( x_0 + (r - q - \\tfrac{1}{2}\\sigma^2)T \\right) - \\tfrac{1}{2}\\sigma^2 u^2 T \\right).\n$$\n- The Carr–Madan damped transform prices European call options by working with the exponentially damped call price $c(k) = e^{\\alpha k} C(K)$, where $k = \\ln K$ and $\\alpha > 0$ is a damping parameter. The Fourier transform of $c(k)$ with respect to $k$ is\n$$\n\\widehat{c}(u) = \\int_{-\\infty}^{\\infty} e^{i u k} c(k)\\, dk\n= e^{-rT}\\,\\frac{\\varphi_{x_T}(u - i(\\alpha + 1))}{\\alpha^2 + \\alpha - u^2 + i u (2\\alpha + 1)}.\n$$\nInversion recovers $c(k)$, and hence $C(K)$, via the inverse Fourier transform, which may be approximated numerically by the Fast Fourier Transform (FFT).\n\nYour tasks:\n\n1) Starting from the above definitions and the differentiation identity with respect to the spot $S$, namely letting $x = \\ln S$ so that\n$$\n\\frac{\\partial}{\\partial S} = \\frac{1}{S}\\frac{\\partial}{\\partial x},\\qquad\n\\Gamma(S) = \\frac{\\partial^2 C}{\\partial S^2}(S) = \\frac{1}{S^2}\\left(\\frac{\\partial^2 C}{\\partial x^2}(x) - \\frac{\\partial C}{\\partial x}(x)\\right),\n$$\nand recognizing that $x$ only enters $\\widehat{c}(u)$ through $\\varphi_{x_T}(u - i(\\alpha + 1)) = \\exp\\left( i(u - i(\\alpha + 1)) x \\right) \\times \\text{(terms independent of }x\\text{)}$, derive the Fourier-domain representation for the Gamma. Conclude that in the Fourier domain the operator $\\tfrac{\\partial}{\\partial x}$ acts as multiplication by $i(u - i(\\alpha + 1))$ on $\\widehat{c}(u)$, and obtain an expression showing that the damped Gamma transform $\\widehat{g}(u)$ associated with $g(k) = e^{\\alpha k}\\,\\Gamma(K)$ is given by a multiplicative factor applied to $\\widehat{c}(u)$. Do not use any formula not derivable from the above base, and show all intermediate reasoning steps.\n\n2) Implement a Fast Fourier Transform (FFT) pricer for European calls under Black–Scholes using the Carr–Madan framework to compute $C(K)$ on a grid of log-strikes $k = \\ln K$. Then implement:\n- The Fourier-domain Gamma at a given strike $K$ using your result from part $1)$, by applying the corresponding multiplicative factor to $\\widehat{c}(u)$ and inverting by FFT to obtain $g(k) = e^{\\alpha k}\\Gamma(K)$ and thus $\\Gamma(K)$.\n- The central-difference Gamma approximation at spot $S_0$ and strike $K$, defined as\n$$\n\\Gamma_{\\Delta S}(S_0;K) = \\frac{C(S_0 + \\Delta S, K) - 2\\,C(S_0, K) + C(S_0 - \\Delta S, K)}{(\\Delta S)^2},\n$$\ncomputed by re-evaluating the Carr–Madan FFT call price at the bumped spots $S_0 \\pm \\Delta S$.\n\n3) Show numerically that as $\\Delta S \\to 0$, the central-difference Gamma converges to the analytical Fourier-domain Gamma derived in part $1)$. To make this test self-contained and reproducible, use the following numerical configuration and test suite:\n\n- Use damping parameter $\\alpha = 1.5$, number of FFT nodes $N = 2^{12}$, Fourier grid spacing $\\eta = 0.25$, and thus log-strike spacing $\\lambda = \\dfrac{2\\pi}{N \\eta}$ and log-strike range centered by $b = \\dfrac{\\pi}{\\eta}$ so that $k_m = -b + m \\lambda$ for $m = 0, 1, \\dots, N-1$.\n- Use Simpson’s rule weights for the Fourier integral discretization.\n- Use linear interpolation to read off values at a given $k = \\ln K$ from the computed grids.\n- For each test case below, evaluate the error list\n$$\nE(\\Delta S) = \\left| \\Gamma_{\\Delta S}(S_0;K) - \\Gamma_{\\text{Fourier}}(S_0;K) \\right|\n$$\nfor the bump sizes $\\Delta S \\in \\{ 2.0,\\ 1.0,\\ 0.5,\\ 0.25 \\}$.\n- Output, for each test case, a boolean indicating whether convergence is observed in the sense that the sequence of relative errors is overall decreasing as $\\Delta S$ halves (allowing for small numerical fluctuations), quantified as: at least two successive decreases across the three halvings and $E(0.25)$ no greater than $0.8 \\times E(2.0)$ when normalized by $\\max\\{|\\Gamma_{\\text{Fourier}}|,\\ 10^{-8}\\}$.\n\nTest suite of model parameters and evaluation points:\n- Case A (at-the-money, moderate maturity): $(S_0, K, T, r, q, \\sigma) = (100.0,\\ 100.0,\\ 0.5,\\ 0.01,\\ 0.0,\\ 0.2)$.\n- Case B (out-of-the-money, one year): $(S_0, K, T, r, q, \\sigma) = (80.0,\\ 120.0,\\ 1.0,\\ 0.0,\\ 0.0,\\ 0.25)$.\n- Case C (near-maturity, slightly out-of-the-money): $(S_0, K, T, r, q, \\sigma) = (100.0,\\ 105.0,\\ 0.05,\\ 0.0,\\ 0.0,\\ 0.3)$.\n\nYour program should produce a single line of output containing the boolean results for the three cases as a comma-separated list enclosed in square brackets (for example, $\\texttt{[True,True,False]}$). No other output should be printed.", "solution": "The problem requires the derivation of the Fourier-domain representation for the option Gamma, its implementation using the Fast Fourier Transform (FFT), and a numerical verification of the convergence of a central-difference approximation to this analytical Gamma. I will address each part in sequence.\n\nThe entire analysis is conducted within the Black-Scholes model, utilizing the Carr-Madan FFT pricing framework.\n\n**Part 1: Derivation of the Fourier-Domain Gamma**\n\nThe goal is to find the Fourier transform of the damped Gamma, denoted $\\widehat{g}(u)$, where $g(k) = e^{\\alpha k} \\Gamma(K)$ and $k = \\ln K$. The Gamma of an option, $\\Gamma$, is the second derivative of its price $C$ with respect to the spot price $S$. The relationship between derivatives with respect to $S$ and the log-price $x = \\ln S$ is given by the chain rule:\n$$ \\frac{\\partial}{\\partial S} = \\frac{\\partial x}{\\partial S} \\frac{\\partial}{\\partial x} = \\frac{1}{S}\\frac{\\partial}{\\partial x} $$\nApplying this twice, we obtain the expression for Gamma provided in the problem statement:\n$$ \\Gamma(S, K) = \\frac{\\partial^2 C}{\\partial S^2} = \\frac{\\partial}{\\partial S}\\left(\\frac{1}{S}\\frac{\\partial C}{\\partial x}\\right) = -\\frac{1}{S^2}\\frac{\\partial C}{\\partial x} + \\frac{1}{S^2}\\frac{\\partial^2 C}{\\partial x^2} = \\frac{1}{S^2}\\left(\\frac{\\partial^2 C}{\\partial x^2} - \\frac{\\partial C}{\\partial x}\\right) $$\nHere, the option price $C$ is a function of both the spot price $S$ and strike price $K$. The Fourier transform method operates on a grid of log-strikes $k = \\ln K$ for a fixed spot price, which we denote $S_0$. Thus, the derivatives are evaluated with respect to the spot price at $S_0$, which corresponds to derivatives with respect to $x_0 = \\ln S_0$.\n$$ \\Gamma(S_0, K) = \\frac{1}{S_0^2}\\left(\\frac{\\partial^2 C}{\\partial x_0^2} - \\frac{\\partial C}{\\partial x_0}\\right) $$\nIn the Carr-Madan framework, the call price is recovered from the inverse Fourier transform of the damped call price transform, $\\widehat{c}(u)$.\n$$ C(S_0, K) = e^{-\\alpha k} c(k) = e^{-\\alpha k} \\mathcal{F}^{-1}[\\widehat{c}(u)](k) = e^{-\\alpha k} \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} e^{-iuk} \\widehat{c}(u) du $$\nThe dependency on $x_0$ is contained entirely within $\\widehat{c}(u)$ through the characteristic function $\\varphi_{x_T}$. The problem states that:\n$$ \\varphi_{x_T}(v) = \\exp\\left( i v x_0 \\right) \\times (\\text{terms independent of } x_0) $$\nwhere $v$ is the argument of the characteristic function. This allows us to easily compute derivatives of $\\varphi_{x_T}$ with respect to $x_0$:\n$$ \\frac{\\partial \\varphi_{x_T}(v)}{\\partial x_0} = (iv) \\varphi_{x_T}(v) $$\n$$ \\frac{\\partial^2 \\varphi_{x_T}(v)}{\\partial x_0^2} = (iv)^2 \\varphi_{x_T}(v) = -v^2 \\varphi_{x_T}(v) $$\nWithin the expression for $\\widehat{c}(u)$, the argument to the characteristic function is $v = u - i(\\alpha+1)$. Since all other terms in $\\widehat{c}(u)$ are independent of $x_0$, the differentiation property passes through:\n$$ \\frac{\\partial \\widehat{c}(u)}{\\partial x_0} = i(u - i(\\alpha+1)) \\widehat{c}(u) $$\n$$ \\frac{\\partial^2 \\widehat{c}(u)}{\\partial x_0^2} = (i(u - i(\\alpha+1)))^2 \\widehat{c}(u) = -(u - i(\\alpha+1))^2 \\widehat{c}(u) $$\nThe derivatives of the call price $C$ with respect to $x_0$ can now be expressed in the Fourier domain. Since differentiation and the inverse Fourier transform are linear operators, they commute:\n$$ \\frac{\\partial C}{\\partial x_0} = e^{-\\alpha k} \\mathcal{F}^{-1}\\left[\\frac{\\partial \\widehat{c}(u)}{\\partial x_0}\\right](k) = e^{-\\alpha k} \\mathcal{F}^{-1}[i(u - i(\\alpha+1)) \\widehat{c}(u)](k) $$\n$$ \\frac{\\partial^2 C}{\\partial x_0^2} = e^{-\\alpha k} \\mathcal{F}^{-1}\\left[\\frac{\\partial^2 \\widehat{c}(u)}{\\partial x_0^2}\\right](k) = e^{-\\alpha k} \\mathcal{F}^{-1}[-(u - i(\\alpha+1))^2 \\widehat{c}(u)](k) $$\nNow, we substitute these into the expression for $\\Gamma(S_0, K)$. The damped Gamma is $g(k) = e^{\\alpha k}\\Gamma(S_0, K)$:\n$$ g(k) = e^{\\alpha k} \\frac{1}{S_0^2} \\left[ \\left(e^{-\\alpha k} \\mathcal{F}^{-1}[-(u - i(\\alpha+1))^2 \\widehat{c}(u)](k)\\right) - \\left(e^{-\\alpha k} \\mathcal{F}^{-1}[i(u - i(\\alpha+1)) \\widehat{c}(u)](k)\\right) \\right] $$\nThe terms $e^{\\alpha k}$ and $e^{-\\alpha k}$ cancel. By linearity of the inverse Fourier transform:\n$$ g(k) = \\frac{1}{S_0^2} \\mathcal{F}^{-1}\\left[ \\left( -(u-i(\\alpha+1))^2 - i(u-i(\\alpha+1)) \\right) \\widehat{c}(u) \\right](k) $$\nTaking the Fourier transform of both sides gives the damped Gamma transform $\\widehat{g}(u)$:\n$$ \\widehat{g}(u) = \\mathcal{F}[g(k)](u) = \\frac{1}{S_0^2} \\left[ -(u-i(\\alpha+1))^2 - i(u-i(\\alpha+1)) \\right] \\widehat{c}(u) $$\nLet's simplify the multiplicative factor. Let $v = u - i(\\alpha+1)$:\n$$ -(v^2) - iv = -(u^2 - (\\alpha+1)^2 - 2iu(\\alpha+1)) - i(u - i(\\alpha+1)) $$\n$$ = -u^2 + (\\alpha+1)^2 + 2iu(\\alpha+1) - iu - (\\alpha+1) $$\n$$ = -u^2 + (\\alpha^2 + 2\\alpha + 1) + i(2u\\alpha + 2u - u) - \\alpha - 1 $$\n$$ = -u^2 + \\alpha^2 + \\alpha + iu(2\\alpha + 1) $$\nThis expression is exactly the denominator of the Carr-Madan formula for $\\widehat{c}(u)$:\n$$ \\widehat{c}(u) = e^{-rT}\\,\\frac{\\varphi_{x_T}(u - i(\\alpha + 1))}{\\alpha^2 + \\alpha - u^2 + i u (2\\alpha + 1)} $$\nSubstituting this back, we obtain a remarkably simple form for $\\widehat{g}(u)$:\n$$ \\widehat{g}(u) = \\frac{1}{S_0^2} \\left( \\alpha^2 + \\alpha - u^2 + iu(2\\alpha+1) \\right) \\left( e^{-rT}\\,\\frac{\\varphi_{x_T}(u - i(\\alpha + 1))}{\\alpha^2 + \\alpha - u^2 + i u (2\\alpha + 1)} \\right) $$\n$$ \\widehat{g}(u) = \\frac{e^{-rT}}{S_0^2} \\varphi_{x_T}(u - i(\\alpha + 1)) $$\nThis is the Fourier-domain representation for the Gamma. The damped Gamma transform $\\widehat{g}(u)$ is obtained by multiplying $\\widehat{c}(u)$ by the factor $\\frac{1}{S_0^2}(\\alpha^2 + \\alpha - u^2 + iu(2\\alpha+1))$.\n\n**Part 2 & 3: Implementation and Numerical Verification**\n\nTo implement the FFT-based calculations and perform the verification, we follow these steps:\n1.  **Grid Setup**: We define the grids for the log-strike $k$ and the Fourier domain variable $u$ as specified.\n    - Number of points $N = 2^{12}$.\n    - Damping parameter $\\alpha = 1.5$.\n    - Fourier grid spacing $\\eta = 0.25$.\n    - Log-strike grid spacing $\\lambda = \\frac{2\\pi}{N \\eta}$.\n    - Log-strike grid: $k_m = -\\frac{\\pi}{\\eta} + m\\lambda$ for $m=0, \\dots, N-1$.\n    - Fourier grid for integration: $u_j = j\\eta$ for $j=0, \\dots, N-1$.\n\n2.  **FFT-based Inversion**: The inverse Fourier transform is approximated as a sum, which is then mapped to a standard FFT algorithm. The call price formula from the one-sided Fourier integral is:\n    $$ C(k) = \\frac{e^{-\\alpha k}}{\\pi} \\text{Re} \\left[ \\int_0^{\\infty} e^{-iuk} \\widehat{c}_{CM}(u) du \\right] $$\n    where $\\widehat{c}_{CM}(u) = e^{-rT} \\frac{\\varphi_{x_T}(u - i(\\alpha+1))}{\\alpha^2+\\alpha-u^2+i(2\\alpha+1)u}$.\n    The integral is discretized using Simpson's rule and evaluated using the FFT:\n    $$ \\int_0^\\infty \\approx \\sum_{j=0}^{N-1} W_j e^{-iu_j k_m} \\widehat{c}_{CM}(u_j) $$\n    where $W_j$ are the Simpson weights. The term $e^{-iu_j k_m} = e^{-i(j\\eta)(-\\pi/\\eta + m\\lambda)} = e^{ij\\pi}e^{-ijm\\eta\\lambda} = (-1)^j e^{-i2\\pi jm/N}$. The sum becomes a standard DFT of the sequence $Y_j = (-1)^j \\widehat{c}_{CM}(u_j) W_j$.\n    The same procedure applies for calculating Gamma, where we replace $\\widehat{c}_{CM}(u)$ with the transform corresponding to the one-sided integral for Gamma, which is $\\frac{1}{S_0^2} e^{-rT} \\varphi_{x_T}(u-i(\\alpha+1))$.\n\n3.  **Numerical Scheme**:\n    - **Simpson's Weights**: For $N=2^{12}$ points (an even number), we have $N-1$ intervals (an odd number). This is not compatible with the standard Simpson's rule which requires an even number of intervals. We use a common adaptation: apply Simpson's rule to the first $N-2$ intervals (first $N-1$ points) and the trapezoidal rule to the last interval. A weights vector that accomplishes this is constructed.\n    - **Gamma Calculation**: We implement two methods:\n        a) **Fourier-Domain Gamma**: Calculate $\\Gamma_{\\text{Fourier}}(S_0, K)$ by performing the FFT inversion of $\\widehat{g}(u)$ derived in Part 1 and interpolating the result at the target log-strike $k = \\ln K$.\n        b) **Central-Difference Gamma**: Calculate $\\Gamma_{\\Delta S}(S_0, K)$ by calling the FFT call pricer three times with spot prices $S_0+\\Delta S$, $S_0$, and $S_0-\\Delta S$, and applying the finite difference formula.\n    - **Convergence Test**: For each test case, we compute the error $E(\\Delta S) = |\\Gamma_{\\Delta S} - \\Gamma_{\\text{Fourier}}|$ for $\\Delta S \\in \\{2.0, 1.0, 0.5, 0.25\\}$. We then check two conditions: (i) the error decreases in at least two successive halvings of $\\Delta S$, and (ii) the final error $E(0.25)$ is at most $80\\%$ of the initial error $E(2.0)$.\n\nThe implementation will be encapsulated into a single Python script as requested.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to perform the derivation, implementation, and verification.\n    \"\"\"\n\n    # 1. Numerical Configuration\n    alpha = 1.5\n    N = 2**12\n    eta = 0.25\n    lambda_ = (2 * np.pi) / (N * eta)\n    b = np.pi / eta\n    k_grid = -b + np.arange(N) * lambda_\n    u_grid = np.arange(N) * eta\n\n    # Simpson's rule weights for an even number of points (N).\n    # This uses Simpson's rule on the first N-1 points and Trapezoidal on the last interval.\n    weights = np.zeros(N)\n    # Simpson weights for first N-1 points (N-2 intervals)\n    weights[0] = 1/3\n    weights[1:N-1:2] = 4/3\n    weights[2:N-2:2] = 2/3\n    weights[N-2] = 1/3 # Last point of the Simpson part\n    # Add trapezoidal for last interval\n    weights[N-2] += 1/2\n    weights[N-1] = 1/2\n    simpson_weights = weights * eta\n\n    def characteristic_function(u, x0, T, r, q, sigma):\n        \"\"\"\n        Calculates the characteristic function of the log-price in the Black-Scholes model.\n        \"\"\"\n        mu = x0 + (r - q - 0.5 * sigma**2) * T\n        return np.exp(1j * u * mu - 0.5 * u**2 * sigma**2 * T)\n\n    def fft_pricer(S0, T, r, q, sigma, is_gamma):\n        \"\"\"\n        A general FFT-based calculator for call prices or Gammas.\n        If is_gamma=False, it computes call prices.\n        If is_gamma=True, it computes Gammas.\n        \"\"\"\n        x0 = np.log(S0)\n        \n        # Argument for the characteristic function in the integrand\n        v = u_grid - 1j * (alpha + 1)\n        \n        phi_val = characteristic_function(v, x0, T, r, q, sigma)\n\n        if not is_gamma:\n            # Carr-Madan integrand for call price transform\n            denominator = alpha**2 + alpha - u_grid**2 + 1j * u_grid * (2*alpha + 1)\n            integrand = (np.exp(-r * T) * phi_val) / denominator\n        else:\n            # Integrand for damped Gamma transform\n            # This follows from the derivation in the solution text\n            integrand = (np.exp(-r * T) / S0**2) * phi_val\n\n        # Apply Simpson's rule weights and prepare for FFT\n        fft_input = integrand * simpson_weights * (-1)**np.arange(N)\n        \n        # Perform FFT\n        fft_output = np.fft.fft(fft_input)\n        \n        # Recover real-space values\n        if not is_gamma:\n            # Damped call prices c(k)\n            damped_values = np.real(fft_output) / np.pi\n            # Undamp to get call prices C(K)\n            values = np.exp(-alpha * k_grid) * damped_values\n        else:\n            # Damped Gammas g(k)\n            damped_values = np.real(fft_output) / np.pi\n            # Undamp to get Gammas Gamma(K)\n            values = np.exp(-alpha * k_grid) * damped_values\n\n        return values\n\n    def get_value_at_K(S0, K, T, r, q, sigma, is_gamma):\n        \"\"\"\n        Gets the price or Gamma at a specific strike K by interpolating the FFT grid.\n        \"\"\"\n        k_target = np.log(K)\n        values_grid = fft_pricer(S0, T, r, q, sigma, is_gamma)\n        # Linear interpolation to find value at the target log-strike\n        return np.interp(k_target, k_grid, values_grid)\n\n    # 2. Test Suite Definition\n    test_cases = [\n        # (S0, K, T, r, q, sigma)\n        (100.0, 100.0, 0.5, 0.01, 0.0, 0.2),   # Case A\n        (80.0, 120.0, 1.0, 0.0, 0.0, 0.25),  # Case B\n        (100.0, 105.0, 0.05, 0.0, 0.0, 0.3),   # Case C\n    ]\n    bump_sizes = np.array([2.0, 1.0, 0.5, 0.25])\n    \n    results = []\n\n    # 3. Main Loop for Verification\n    for case in test_cases:\n        S0, K, T, r, q, sigma = case\n\n        # Calculate the analytical Fourier-domain Gamma\n        gamma_fourier = get_value_at_K(S0, K, T, r, q, sigma, is_gamma=True)\n\n        errors = []\n        for dS in bump_sizes:\n            # Calculate prices for central difference\n            price_up = get_value_at_K(S0 + dS, K, T, r, q, sigma, is_gamma=False)\n            price_mid = get_value_at_K(S0, K, T, r, q, sigma, is_gamma=False)\n            price_down = get_value_at_K(S0 - dS, K, T, r, q, sigma, is_gamma=False)\n            \n            # Calculate central-difference Gamma\n            gamma_cd = (price_up - 2 * price_mid + price_down) / (dS**2)\n            \n            # Calculate and store the absolute error\n            errors.append(np.abs(gamma_cd - gamma_fourier))\n\n        # Check for convergence\n        E = np.array(errors)\n        \n        # Condition 1: At least two successive decreases\n        decrease_1 = E[1]  E[0]\n        decrease_2 = E[2]  E[1]\n        decrease_3 = E[3]  E[2]\n        cond1 = (decrease_1 and decrease_2) or (decrease_2 and decrease_3)\n        \n        # Condition 2: Final error is at most 80% of initial error\n        cond2 = E[3] = 0.8 * E[0]\n        \n        convergence_observed = cond1 and cond2\n        results.append(convergence_observed)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2392450"}, {"introduction": "Our final practice delves into a critical numerical aspect that ensures the accuracy and resolution of our FFT-based methods: zero-padding. While seemingly simple, zero-padding in the frequency domain is the key to interpolating the resulting density onto a finer grid in the log-price domain. Through this exercise, you will investigate how the amount of zero-padding directly impacts the accuracy of the recovered density, particularly in the tails of the distribution—a region of paramount importance for risk assessment [@problem_id:2392491].", "problem": "Consider a frictionless market under the Black–Scholes framework. Let the asset price process under the risk-neutral measure be such that the time-$T$ log-price $X_T = \\ln(S_T)$ is normally distributed with mean $\\mu$ and variance $\\sigma_X^2$, where $S_0 gt; 0$ is the initial price, $r$ is the continuously compounded risk-free rate, $q$ is the continuous dividend yield, and $\\sigma$ is the volatility. Specifically, let\n$$\n\\mu = \\ln(S_0) + (r - q - \\tfrac{1}{2}\\sigma^2)T,\\quad \\sigma_X^2 = \\sigma^2 T.\n$$\nThe characteristic function of $X_T$ is\n$$\n\\varphi_{X_T}(u) = \\mathbb{E}[e^{i u X_T}] = \\exp\\left(i u \\mu - \\tfrac{1}{2}\\sigma_X^2 u^2\\right).\n$$\nThe risk-neutral density of $X_T$ is given by the inverse Fourier transform\n$$\np_{X_T}(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} e^{-i u x}\\, \\varphi_{X_T}(u)\\, du.\n$$\nDefine a uniform frequency grid with spacing $\\Delta u gt; 0$ and a finite truncation at $U_{\\max} = \\Delta u \\cdot \\tfrac{N_{\\mathrm{sig}}}{2}$ determined by an even integer $N_{\\mathrm{sig}}\\ge 2$. Let\n$$\nu_k = u_{\\min} + k\\, \\Delta u,\\quad \\text{for } k=0,1,\\dots,N_{\\mathrm{sig}}-1,\\quad \\text{with } u_{\\min} = - U_{\\max}.\n$$\nLet $f_k = \\varphi_{X_T}(u_k)$ for $k=0,\\dots,N_{\\mathrm{sig}}-1$. For a chosen integer $N_{\\mathrm{tot}} \\ge N_{\\mathrm{sig}}$, define the zero-padded sequence $\\{f_k\\}_{k=0}^{N_{\\mathrm{tot}}-1}$ by setting $f_k = 0$ for $k = N_{\\mathrm{sig}},\\dots,N_{\\mathrm{tot}}-1$. The discrete inversion is to be performed on the uniform log-price grid\n$$\nx_j = j\\, \\Delta x,\\quad \\Delta x = \\frac{2\\pi}{N_{\\mathrm{tot}}\\, \\Delta u},\\quad j=0,1,\\dots,N_{\\mathrm{tot}}-1,\n$$\nby evaluating\n$$\n\\widehat{p}(x_j) = \\frac{\\Delta u}{2\\pi}\\, e^{-i u_{\\min} x_j} \\sum_{k=0}^{N_{\\mathrm{tot}}-1} f_k\\, e^{-i 2\\pi \\frac{j k}{N_{\\mathrm{tot}}}},\n$$\nwhich is the Discrete Fourier Transform (DFT) inversion consistent with the above sampling scheme. Note that $\\widehat{p}(x_j)$ is real-valued in theory; any imaginary component arising in numerical computation should be disregarded.\n\nLet the true density of $X_T$ be the normal density\n$$\np_{\\mathrm{true}}(x) = \\frac{1}{\\sqrt{2\\pi}\\, \\sigma_X} \\exp\\!\\left(-\\frac{(x - \\mu)^2}{2\\sigma_X^2}\\right).\n$$\nDefine the combined two-tail region by the condition $\\lvert x - \\mu \\rvert \\ge \\kappa \\sigma_X$, with $\\kappa = 3$. For a given $N_{\\mathrm{tot}}$, define the tail absolute error as the Riemann-sum approximation to the $L^1$-error over the tails:\n$$\nE(N_{\\mathrm{tot}}) = \\Delta x \\sum_{\\{j: \\lvert x_j - \\mu \\rvert \\ge \\kappa \\sigma_X\\}} \\left| \\operatorname{Re}\\left(\\widehat{p}(x_j)\\right) - p_{\\mathrm{true}}(x_j) \\right|.\n$$\n\nUse the following numerical values:\n- $S_0 = 100$,\n- $r = 0.02$,\n- $q = 0.00$,\n- $\\sigma = 0.20$,\n- $T = 1.0$,\n- $\\Delta u = 0.25$,\n- $N_{\\mathrm{sig}} = 512$,\n- $\\kappa = 3$.\n\nInvestigate the effect of zero-padding length on the accuracy of the recovered risk-neutral density in the tails by computing $E(N_{\\mathrm{tot}})$ for the following test suite of total transform lengths:\n- $N_{\\mathrm{tot}} = 512$ (no zero-padding),\n- $N_{\\mathrm{tot}} = 1024$ (moderate zero-padding),\n- $N_{\\mathrm{tot}} = 4096$ (large zero-padding),\n- $N_{\\mathrm{tot}} = 16384$ (very large zero-padding).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order corresponding to the test suite above, that is, $[E(512),E(1024),E(4096),E(16384)]$. All outputs must be real numbers (floats) with no units.", "solution": "The problem asks to investigate the effect of zero-padding on the accuracy of a density recovered via FFT. The solution involves four main steps: calculating the model parameters, sampling the characteristic function, performing the FFT-based inversion for different padding lengths, and finally computing the error in the tails of the resulting densities.\n\n**1. Model Parameter Calculation**\nFirst, we determine the mean and standard deviation of the log-price $X_T$ under the Black-Scholes model. Given $S_0=100, r=0.02, q=0.00, \\sigma=0.20, T=1.0$:\n- Mean: $\\mu = \\ln(S_0) + (r - q - \\frac{1}{2}\\sigma^2)T = \\ln(100) + (0.02 - 0 - \\frac{1}{2}(0.2)^2) \\times 1.0 = \\ln(100) + (0.02 - 0.02) = \\ln(100) \\approx 4.60517$.\n- Standard Deviation: $\\sigma_X = \\sigma\\sqrt{T} = 0.20\\sqrt{1.0} = 0.20$.\n\n**2. Frequency Domain Discretization and Sampling**\nThe continuous characteristic function $\\varphi_{X_T}(u)$ is sampled on a discrete frequency grid.\n- Grid spacing: $\\Delta u = 0.25$.\n- Number of signal points: $N_{\\mathrm{sig}} = 512$.\n- The frequency grid is $u_k = u_{\\min} + k\\,\\Delta u$ for $k=0, \\dots, N_{\\mathrm{sig}}-1$, where $u_{\\min} = -\\Delta u \\cdot N_{\\mathrm{sig}}/2 = -64$.\nOn this grid, we compute the samples $f_k = \\varphi_{X_T}(u_k) = \\exp(i u_k \\mu - \\frac{1}{2}\\sigma_X^2 u_k^2)$.\n\n**3. Zero-Padding and FFT-based Inversion**\nFor each test case with total transform length $N_{\\mathrm{tot}}$, the sequence $\\{f_k\\}$ is placed into a longer array of size $N_{\\mathrm{tot}}$, with the remaining elements set to zero. This zero-padding effectively interpolates the result in the spatial domain.\n- The spatial grid spacing is determined by the total length: $\\Delta x = \\frac{2\\pi}{N_{\\mathrm{tot}}\\Delta u}$.\n- The spatial grid is $x_j = j \\Delta x$ for $j=0, \\dots, N_{\\mathrm{tot}}-1$.\nThe density is recovered using the specified DFT inversion formula, which can be computed efficiently with an FFT:\n$$ \\widehat{p}(x_j) = \\frac{\\Delta u}{2\\pi}\\, e^{-i u_{\\min} x_j} \\times \\text{FFT}(\\{f_k\\}_{\\text{padded}})_j $$\nThe term $e^{-i u_{\\min} x_j}$ is a phase correction to account for the shifted frequency grid. We take the real part of the result, as the density must be real-valued.\n\n**4. Tail Error Calculation**\nThe accuracy is measured by the $L^1$-error in the distribution's tails, defined by $|x - \\mu| \\ge \\kappa \\sigma_X$, where $\\kappa=3$.\nFor each grid point $x_j$ in the tail region, we compute the absolute difference $|\\operatorname{Re}(\\widehat{p}(x_j)) - p_{\\mathrm{true}}(x_j)|$, where $p_{\\mathrm{true}}$ is the analytical Gaussian PDF. The total tail error $E(N_{\\mathrm{tot}})$ is the Riemann sum of these differences, weighted by $\\Delta x$. This entire procedure is repeated for each value of $N_{\\mathrm{tot}}$ in the test suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the tail error of a recovered risk-neutral density\n    for different levels of zero-padding in an FFT-based inversion.\n    \"\"\"\n    #\n    # === Problem Parameters ===\n    #\n    S0 = 100.0       # Initial asset price\n    r = 0.02         # Risk-free rate\n    q = 0.00         # Dividend yield\n    sigma = 0.20     # Volatility\n    T = 1.0          # Time to maturity in years\n    \n    du = 0.25        # Frequency grid spacing\n    N_sig = 512      # Number of signal points in frequency domain\n    kappa = 3.0      # Tail threshold in standard deviations\n\n    # Test suite for total transform length\n    test_cases_N_tot = [512, 1024, 4096, 16384]\n\n    #\n    # === Step 1: Calculate Log-Price Distribution Parameters ===\n    #\n    mu = np.log(S0) + (r - q - 0.5 * sigma**2) * T\n    sigma_X = sigma * np.sqrt(T)\n\n    #\n    # === Step 2: Setup Frequency Grid and Sample Characteristic Function ===\n    #\n    # The characteristic function is sampled on a grid u_k.\n    # U_max defines the truncation of the Fourier integral.\n    U_max = du * N_sig / 2.0\n    u_min = -U_max\n    # Frequency grid u_k = u_min + k*du for k=0,...,N_sig-1\n    u_grid_sig = u_min + np.arange(N_sig) * du\n    \n    # Characteristic function of Normal(mu, sigma_X^2) distribution\n    # phi(u) = exp(i*u*mu - 0.5*sigma_X^2*u^2)\n    f_sig = np.exp(1j * u_grid_sig * mu - 0.5 * sigma_X**2 * u_grid_sig**2)\n\n    results = []\n    for N_tot in test_cases_N_tot:\n        #\n        # === Step 3: Zero-Padding and Spatial Domain Grid Setup ===\n        #\n        # Zero-pad the characteristic function samples. This interpolates\n        # the resulting density onto a finer spatial grid.\n        f_tot = np.zeros(N_tot, dtype=np.complex128)\n        f_tot[0:N_sig] = f_sig\n\n        # The spatial grid x_j is determined by N_tot and du.\n        # A larger N_tot (more zero-padding) leads to a smaller dx.\n        dx = (2 * np.pi) / (N_tot * du)\n        \n        # As per the problem statement, the grid is x_j = j*dx.\n        # This grid starts at 0 and is not centered.\n        x_grid = np.arange(N_tot) * dx\n\n        #\n        # === Step 4: Density Recovery via FFT ===\n        #\n        # The sum in the problem's formula is a DFT, computed via FFT.\n        fft_f = np.fft.fft(f_tot)\n\n        # Apply the phase correction and scaling factor from the formula.\n        # The phase term e^(-i*u_min*x_j) corrects for the frequency grid shift.\n        phase_correction = np.exp(-1j * u_min * x_grid)\n        p_hat = (du / (2 * np.pi)) * phase_correction * fft_f\n        \n        # The density must be real; numerical noise can create a small imag part.\n        p_hat_real = np.real(p_hat)\n\n        #\n        # === Step 5: Error Calculation ===\n        #\n        # Calculate the true normal density on the same grid for comparison.\n        p_true = norm.pdf(x_grid, loc=mu, scale=sigma_X)\n        \n        # Identify the indices corresponding to the tail regions.\n        # Tail region is where |x - mu| = kappa * sigma_X.\n        tail_mask = np.abs(x_grid - mu) = kappa * sigma_X\n\n        # Calculate the absolute error on the grid points in the tails.\n        abs_error_in_tails = np.abs(p_hat_real[tail_mask] - p_true[tail_mask])\n        \n        # Approximate the L1-error integral using a Riemann sum.\n        E_N_tot = dx * np.sum(abs_error_in_tails)\n        results.append(E_N_tot)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2392491"}]}