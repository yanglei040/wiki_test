{"hands_on_practices": [{"introduction": "Before we can apply any statistical distribution to model real-world phenomena, we must first master its fundamentals. This foundational exercise guides you through a core computational skill: generating random samples from a Generalized Pareto Distribution (GPD) using the inverse transform sampling method [@problem_id:2397442]. You will then implement a series of rigorous statistical checks, comparing empirical quantiles from your generated data to the theoretical quantiles, to validate the correctness of your generator. This practice is essential for building confidence in any simulation-based analysis in finance and economics.", "problem": "A financial institution models excess losses above a high threshold using the Generalized Pareto Distribution (GPD). Let $X$ follow a GPD with shape parameter $\\xi \\in \\mathbb{R}$, scale parameter $\\beta \\in (0,\\infty)$, and location parameter $\\mu \\in \\mathbb{R}$. The cumulative distribution function is defined by\n- for $\\xi \\neq 0$,\n$$\nF(x;\\xi,\\beta,\\mu) \\;=\\; 1 - \\left(1 + \\xi \\frac{x-\\mu}{\\beta}\\right)^{-1/\\xi}\n\\quad \\text{for} \\quad\n\\begin{cases}\nx \\ge \\mu  \\text{if } \\xi \\ge 0, \\\\\n\\mu \\le x \\le \\mu - \\beta/\\xi  \\text{if } \\xi  0,\n\\end{cases}\n$$\n- for $\\xi = 0$,\n$$\nF(x;0,\\beta,\\mu) \\;=\\; 1 - \\exp\\!\\left(-\\frac{x-\\mu}{\\beta}\\right)\n\\quad \\text{for} \\quad x \\ge \\mu.\n$$\n\nYou must write a complete program that generates independent and identically distributed random variates from the above GPD for multiple parameter sets, and then evaluates the resulting samples by comparing empirical quantiles to theoretical quantiles on a fixed probability grid. All computations should be reproducible using the specified seeds. No external data or user input is permitted.\n\nDefinitions and requirements:\n- Let $U$ denote a random variable with the standard continuous uniform distribution on $(0,1)$. The quantile function $F^{-1}(p;\\xi,\\beta,\\mu)$ is defined for $p \\in (0,1)$ as the inverse of $F(\\cdot;\\xi,\\beta,\\mu)$ on its support.\n- For a given probability $p \\in (0,1)$, define the empirical $p$-quantile of a finite sample $x_{1},\\dots,x_{n}$ as follows: sort the sample in nondecreasing order to obtain $x_{(1)} \\le \\dots \\le x_{(n)}$, set $s = (n-1)p$, let $i = \\lfloor s \\rfloor + 1$ and $j = \\lceil s \\rceil + 1$ be integer indices in $\\{1,\\dots,n\\}$, and let $\\lambda = s - \\lfloor s \\rfloor$. The empirical quantile is\n$$\nQ_{\\text{emp}}(p) \\;=\\; (1-\\lambda)\\,x_{(i)} + \\lambda\\,x_{(j)}.\n$$\n- Construct a quantile grid $\\mathcal{P} = \\{0.01, 0.02, \\dots, 0.99\\}$ and a central grid $\\mathcal{P}_{\\text{central}} = \\{0.05, 0.10, \\dots, 0.95\\}$.\n- For a given parameter set and a sample of size $n$, compute the vectors $\\mathbf{Q}_{\\text{th}} = \\big(F^{-1}(p;\\xi,\\beta,\\mu)\\big)_{p \\in \\mathcal{P}}$ and $\\mathbf{Q}_{\\text{emp}} = \\big(Q_{\\text{emp}}(p)\\big)_{p \\in \\mathcal{P}}$. Using these, compute:\n    1. The coefficient of determination $R^2$ between $\\mathbf{Q}_{\\text{th}}$ and $\\mathbf{Q}_{\\text{emp}}$, defined as the squared Pearson correlation coefficient of the two vectors.\n    2. The least-squares slope $b$ and intercept $a$ in the linear model $Q_{\\text{emp}} \\approx a + b\\,Q_{\\text{th}}$ fitted by ordinary least squares.\n    3. The maximum absolute deviation on the central grid, normalized by the scale, $\\Delta_{\\max} = \\max_{p \\in \\mathcal{P}_{\\text{central}}} \\big|Q_{\\text{emp}}(p) - F^{-1}(p;\\xi,\\beta,\\mu)\\big|/\\beta$.\n    4. For $\\xi  0$, the support upper endpoint is $x_{\\max} = \\mu - \\beta/\\xi$. Define the support check as $\\mathbf{1}\\{\\max_{k} x_{k} \\le x_{\\max}\\}$, where $x_{k}$ are the sampled values and $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. For $\\xi \\ge 0$, this check is automatically satisfied.\n\nAcceptance criteria for each parameter set:\n- $R^2 \\ge 0.9995$,\n- $|b - 1| \\le 0.02$,\n- $|a| \\le 0.05\\,\\beta$,\n- $\\Delta_{\\max} \\le 0.12$,\n- the support check holds.\n\nFor each parameter set, output a boolean indicating whether all acceptance criteria are simultaneously satisfied.\n\nTest suite:\n- Case $1$: $(\\xi,\\beta,\\mu,n,\\text{seed}) = (0.25,\\,1.40,\\,0.00,\\,120000,\\,1729)$.\n- Case $2$: $(\\xi,\\beta,\\mu,n,\\text{seed}) = (0.00,\\,2.20,\\,0.50,\\,150000,\\,41041)$.\n- Case $3$: $(\\xi,\\beta,\\mu,n,\\text{seed}) = (-0.35,\\,1.10,\\,-0.30,\\,120000,\\,271828)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the above cases, for example, $[\\text{True},\\text{False},\\text{True}]$ where each entry is a boolean.", "solution": "The problem as stated is subjected to rigorous validation.\n\n**Step 1: Extraction of Givens**\n- **Distribution**: Generalized Pareto Distribution (GPD) with shape parameter $\\xi \\in \\mathbb{R}$, scale parameter $\\beta \\in (0,\\infty)$, and location parameter $\\mu \\in \\mathbb{R}$.\n- **Cumulative Distribution Function (CDF)**:\n  - For $\\xi \\neq 0$: $F(x;\\xi,\\beta,\\mu) = 1 - \\left(1 + \\xi \\frac{x-\\mu}{\\beta}\\right)^{-1/\\xi}$, with support $x \\ge \\mu$ for $\\xi \\ge 0$, and $\\mu \\le x \\le \\mu - \\beta/\\xi$ for $\\xi  0$.\n  - For $\\xi = 0$: $F(x;0,\\beta,\\mu) = 1 - \\exp\\left(-\\frac{x-\\mu}{\\beta}\\right)$, with support $x \\ge \\mu$.\n- **Quantile Function**: $F^{-1}(p;\\xi,\\beta,\\mu)$ is defined as the inverse of the CDF for $p \\in (0,1)$.\n- **Empirical Quantile**: For a sorted sample $x_{(1)} \\le \\dots \\le x_{(n)}$, the empirical $p$-quantile is $Q_{\\text{emp}}(p) = (1-\\lambda)\\,x_{(i)} + \\lambda\\,x_{(j)}$, where $s = (n-1)p$, $i = \\lfloor s \\rfloor + 1$, $j = \\lceil s \\rceil + 1$, and $\\lambda = s - \\lfloor s \\rfloor$.\n- **Probability Grids**: $\\mathcal{P} = \\{0.01, 0.02, \\dots, 0.99\\}$ and $\\mathcal{P}_{\\text{central}} = \\{0.05, 0.10, \\dots, 0.95\\}$.\n- **Required Metrics for Evaluation**:\n    1. Coefficient of determination $R^2$ between theoretical quantiles $\\mathbf{Q}_{\\text{th}}$ and empirical quantiles $\\mathbf{Q}_{\\text{emp}}$ on grid $\\mathcal{P}$.\n    2. Least-squares slope $b$ and intercept $a$ from the linear model $Q_{\\text{emp}} \\approx a + b\\,Q_{\\text{th}}$.\n    3. Maximum normalized absolute deviation $\\Delta_{\\max} = \\max_{p \\in \\mathcal{P}_{\\text{central}}} \\big|Q_{\\text{emp}}(p) - F^{-1}(p)\\big|/\\beta$.\n    4. Support check: For $\\xi  0$, the indicator $\\mathbf{1}\\{\\max_{k} x_{k} \\le \\mu - \\beta/\\xi\\}$; this is satisfied by definition for $\\xi \\ge 0$.\n- **Acceptance Criteria**:\n    1. $R^2 \\ge 0.9995$\n    2. $|b - 1| \\le 0.02$\n    3. $|a| \\le 0.05\\,\\beta$\n    4. $\\Delta_{\\max} \\le 0.12$\n    5. The support check must hold.\n- **Test Cases**:\n    1. $(\\xi,\\beta,\\mu,n,\\text{seed}) = (0.25, 1.40, 0.00, 120000, 1729)$\n    2. $(\\xi,\\beta,\\mu,n,\\text{seed}) = (0.00, 2.20, 0.50, 150000, 41041)$\n    3. $(\\xi,\\beta,\\mu,n,\\text{seed}) = (-0.35, 1.10, -0.30, 120000, 271828)$\n\n**Step 2: Validation of Problem Statement**\nThe problem is assessed against the required criteria.\n- **Scientific Grounding**: The problem is founded on the principles of extreme value theory and computational statistics. The GPD is a standard model in these fields. All definitions, including the CDF and the statistical metrics, are standard and correct.\n- **Well-Posedness**: The problem is well-posed. It requires the implementation of a deterministic algorithm based on pseudo-random number generation with a specified seed. This ensures that a unique and verifiable solution exists. All necessary information is provided.\n- **Objectivity**: The problem is stated in precise mathematical and algorithmic terms, free of subjectivity or ambiguity. The definitions, test cases, and acceptance criteria are specified completely and clearly.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-defined exercise in computational statistics, requiring the implementation of random variate generation, quantile analysis, and statistical validation. A full solution will be provided.\n\n**Methodology**\nThe solution will be constructed based on the principle of inverse transform sampling. For a continuous random variable with CDF $F(x)$, its quantile function is $F^{-1}(p)$. If $U$ is a random variable following the standard uniform distribution on $(0,1)$, then the random variable $X = F^{-1}(U)$ has the CDF $F(x)$.\n\nFirst, we derive the quantile function $F^{-1}(p)$ for the GPD.\nLet $p = F(x)$. We solve for $x$.\n\nCase 1: $\\xi \\neq 0$\n$$ p = 1 - \\left(1 + \\xi \\frac{x-\\mu}{\\beta}\\right)^{-1/\\xi} $$\n$$ 1-p = \\left(1 + \\xi \\frac{x-\\mu}{\\beta}\\right)^{-1/\\xi} $$\n$$ (1-p)^{-\\xi} = 1 + \\xi \\frac{x-\\mu}{\\beta} $$\n$$ (1-p)^{-\\xi} - 1 = \\xi \\frac{x-\\mu}{\\beta} $$\n$$ x - \\mu = \\frac{\\beta}{\\xi} \\left( (1-p)^{-\\xi} - 1 \\right) $$\nThus, the quantile function is:\n$$ F^{-1}(p;\\xi,\\beta,\\mu) = \\mu + \\frac{\\beta}{\\xi} \\left( (1-p)^{-\\xi} - 1 \\right) $$\n\nCase 2: $\\xi = 0$\nThis corresponds to the exponential distribution with scale $\\beta$ and location $\\mu$.\n$$ p = 1 - \\exp\\left(-\\frac{x-\\mu}{\\beta}\\right) $$\n$$ 1-p = \\exp\\left(-\\frac{x-\\mu}{\\beta}\\right) $$\n$$ \\ln(1-p) = -\\frac{x-\\mu}{\\beta} $$\n$$ x - \\mu = -\\beta \\ln(1-p) $$\nThus, the quantile function is:\n$$ F^{-1}(p;0,\\beta,\\mu) = \\mu - \\beta \\ln(1-p) $$\n\nThe program will proceed as follows for each test case:\n1.  Set the random number generator seed for reproducibility.\n2.  Generate a sample of size $n$ from the standard uniform distribution $U(0,1)$.\n3.  Transform this sample into a GPD sample using the appropriate quantile function derived above, based on the value of $\\xi$.\n4.  Construct the probability grids $\\mathcal{P}$ and $\\mathcal{P}_{\\text{central}}$.\n5.  Compute the vector of theoretical quantiles $\\mathbf{Q}_{\\text{th}}$ by applying the quantile function to the probabilities in grid $\\mathcal{P}$.\n6.  Compute the vector of empirical quantiles $\\mathbf{Q}_{\\text{emp}}$ from the generated sample for the same grid $\\mathcal{P}$. The provided formula for $Q_{\\text{emp}}(p)$ corresponds to the standard linear interpolation method, which is available in numerical libraries.\n7.  Calculate the four specified metrics:\n    a. $R^2$: Calculated as the square of the Pearson correlation coefficient between $\\mathbf{Q}_{\\text{th}}$ and $\\mathbf{Q}_{\\text{emp}}$.\n    b. $a, b$: Obtained from an ordinary least squares linear regression of $\\mathbf{Q}_{\\text{emp}}$ on $\\mathbf{Q}_{\\text{th}}$.\n    c. $\\Delta_{\\max}$: Computed by finding the maximum absolute difference between empirical and theoretical quantiles on the central grid $\\mathcal{P}_{\\text{central}}$, and normalizing by $\\beta$.\n    d. Support check: For $\\xi  0$, confirm that all generated variates are less than or equal to the theoretical upper bound of the support, $x_{\\max} = \\mu - \\beta/\\xi$.\n8.  Finally, verify if all five acceptance criteria are met. The result is a single boolean value for each test case.\nThe final output is an aggregation of these boolean results into the specified list format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Validates GPD random variate generation against theoretical properties\n    for a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (xi, beta, mu, n, seed)\n        (0.25, 1.40, 0.00, 120000, 1729),\n        (0.00, 2.20, 0.50, 150000, 41041),\n        (-0.35, 1.10, -0.30, 120000, 271828),\n    ]\n\n    results = []\n    \n    # Define probability grids\n    # P = {0.01, ..., 0.99}\n    p_grid = np.linspace(0.01, 0.99, 99)\n    # P_central = {0.05, ..., 0.95}\n    p_central = np.linspace(0.05, 0.95, 19)\n\n    def gpd_quantile(p, xi, beta, mu):\n        \"\"\"Computes the theoretical quantile for the GPD.\"\"\"\n        if xi == 0:\n            # Handle the case for xi = 0 (Exponential distribution)\n            return mu - beta * np.log(1 - p)\n        else:\n            # Handle the case for xi != 0\n            # Expression ( (1-p)**(-xi) - 1 ) / xi can be written using expm1 for numerical stability\n            # for small xi, as expm1(y)/y - 1 as y-0.\n            # Here y = -xi * log(1-p).\n            return mu + beta * (np.power(1 - p, -xi) - 1) / xi\n\n    for case in test_cases:\n        xi, beta, mu, n, seed = case\n        \n        # 1. Generate random variates using inverse transform sampling\n        np.random.seed(seed)\n        uniform_samples = np.random.uniform(size=n)\n        gpd_samples = gpd_quantile(uniform_samples, xi, beta, mu)\n\n        # 2. Compute theoretical and empirical quantiles\n        q_th = gpd_quantile(p_grid, xi, beta, mu)\n        q_emp = np.quantile(gpd_samples, p_grid, method='linear')\n\n        # 3. Calculate metrics and perform checks\n        \n        # Metric 1: R^2\n        pearson_r, _ = stats.pearsonr(q_th, q_emp)\n        r_squared = pearson_r**2\n        check1 = r_squared = 0.9995\n\n        # Metric 2: OLS slope and intercept\n        lin_reg = stats.linregress(x=q_th, y=q_emp)\n        b, a = lin_reg.slope, lin_reg.intercept\n        check2 = abs(b - 1) = 0.02\n        check3 = abs(a) = 0.05 * beta\n\n        # Metric 3: Maximum absolute deviation on the central grid\n        q_th_central = gpd_quantile(p_central, xi, beta, mu)\n        q_emp_central = np.quantile(gpd_samples, p_central, method='linear')\n        delta_max = np.max(np.abs(q_emp_central - q_th_central)) / beta\n        check4 = delta_max = 0.12\n\n        # Metric 4: Support upper endpoint check\n        if xi  0:\n            support_upper_bound = mu - beta / xi\n            check5 = np.max(gpd_samples) = support_upper_bound\n        else:\n            # For xi = 0, the support is unbounded above, so the check is satisfied\n            check5 = True\n\n        # Combine all checks\n        all_criteria_met = all([check1, check2, check3, check4, check5])\n        results.append(all_criteria_met)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2397442"}, {"introduction": "With a reliable method for working with the GPD, we can now apply it to a critical task in finance: quantifying extreme risk. This practice challenges you to move from theory to application by deriving the formula for Expected Shortfall ($ES_p$), a coherent risk measure that describes the average loss in the worst-case scenarios, using a GPD model for tail losses [@problem_id:2391786]. By building the calculation from first principles and comparing the parametric result to a non-parametric historical average, you will gain a deeper appreciation for the power and practical utility of Extreme Value Theory in risk management.", "problem": "You are given a task grounded in the peaks-over-threshold methodology from Extreme Value Theory (EVT) for risk management in computational economics and finance. Starting from first principles, use the definition of the peaks-over-threshold model and the law of total probability to derive how to compute the Expected Shortfall (ES) at a high level from a Generalized Pareto Distribution (GPD) approximation to threshold exceedances. Then implement a program that, for each test case below, computes two quantities: a parametric EVT Expected Shortfall at level $p$ using a fitted GPD above a fixed threshold, and a non-parametric historical Expected Shortfall defined as the arithmetic mean of the empirical tail beyond the empirical $p$-quantile. Finally, report the difference between the two methods for each test case.\n\nFundamental base to use:\n- For a high threshold $u$, EVT asserts that the conditional distribution of exceedances $Y = X - u$ given $X > u$ is well approximated by a Generalized Pareto Distribution (GPD) with shape parameter $\\xi$ and scale parameter $\\beta$, when $u$ is sufficiently large and the underlying process satisfies standard regularity conditions.\n- The unconditional distribution function satisfies $F(x) = \\mathbb{P}(X \\le x) = F(u) + \\mathbb{P}(X > u)\\,G(x-u)$ for $x \\ge u$, where $G$ is the distribution function of $Y$ and $\\mathbb{P}(X > u) = 1 - F(u)$.\n- The Expected Shortfall (ES) at level $p$ for a loss variable $X$ is defined as $\\mathrm{ES}_p = \\mathbb{E}[X \\mid X > q_p]$ where $q_p$ is the $p$-quantile of $X$.\n\nYour program must:\n- Use the above principles to derive and implement how to compute the parametric EVT $\\mathrm{ES}^{\\mathrm{GPD}}_p$ in terms of the GPD parameters, the threshold $u$, and the empirical exceedance probability above $u$ computed from data. Do not assume any “shortcut” formulas; the required relationships must follow from the given fundamental base.\n- Compute the non-parametric historical $\\mathrm{ES}_p$ as follows. Let $x_{(1)} \\le \\cdots \\le x_{(n)}$ be the order statistics of a sample $\\{x_i\\}_{i=1}^n$. Define $j = \\lceil p n \\rceil$. If $j > n$, set $j = n$. Define the empirical Value-at-Risk (VaR) at level $p$ as $x_{(j)}$. Define the historical Expected Shortfall as the arithmetic mean of $\\{x_{(j)}, x_{(j+1)}, \\ldots, x_{(n)}\\}$.\n- Compare the two by outputting, for each test case, the difference $\\Delta = \\mathrm{ES}^{\\mathrm{GPD}}_p - \\mathrm{ES}^{\\mathrm{hist}}_p$.\n\nAngle or physical units are not involved. Percentages must be expressed as decimals. Use $p = 0.995$ in all test cases. All computations must be performed in floating point and each final result must be rounded to six decimals.\n\nTest suite to implement. For each case, construct the sample deterministically using the specified quantile-function method. Let $p_i = \\dfrac{i}{n+1}$ for $i \\in \\{1,2,\\ldots,n\\}$.\n\n- Case A (happy path, moderately heavy tail):\n  - Sample size $n = 1000$.\n  - Data construction: lognormal sample via the inverse standard normal, $x_i = \\exp\\!\\big(\\mu + \\sigma\\,\\Phi^{-1}(p_i)\\big)$ with $\\mu = 0$ and $\\sigma = 1$, where $\\Phi^{-1}$ denotes the inverse standard normal distribution function.\n  - Threshold $u = 3.5$.\n  - Fitted GPD parameters: shape $\\xi = 0.20$, scale $\\beta = 1.10$.\n\n- Case B (Pareto tail with known GPD mapping):\n  - Sample size $n = 1500$.\n  - Data construction: Pareto Type I with scale $x_{\\min} = 1$ and tail index $\\alpha = 2.5$, generated by $x_i = (1 - p_i)^{-1/\\alpha}$.\n  - Threshold $u = 5$.\n  - Fitted GPD parameters chosen consistently with the Pareto mapping: shape $\\xi = \\dfrac{1}{\\alpha} = 0.4$, scale $\\beta = \\xi \\, u = 2.0$.\n\n- Case C (nearly exponential tail; exact exponential memoryless case):\n  - Sample size $n = 1200$.\n  - Data construction: exponential with mean $1$ using $x_i = -\\ln(1 - p_i)$.\n  - Threshold $u = 2$.\n  - Fitted GPD parameters consistent with exponential tail: shape $\\xi = 0$, scale $\\beta = 1$.\n\n- Case D (edge case near the finite-ES boundary):\n  - Sample size $n = 3000$.\n  - Data construction: heavy Pareto Type I with $x_{\\min} = 1$ and $\\alpha = 1.05$, i.e., $x_i = (1 - p_i)^{-1/\\alpha}$.\n  - Threshold $u = 10$.\n  - Fitted GPD parameters: shape $\\xi = \\dfrac{1}{\\alpha} \\approx 0.95238095$, scale $\\beta = \\xi \\, u \\approx 9.5238095$.\n\nImplementation details and constraints:\n- For the EVT method, estimate $\\widehat{F}(u)$ empirically from the sample as $\\widehat{F}(u) = \\dfrac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{x_i \\le u\\}$ and the exceedance fraction $\\widehat{\\bar{F}}(u) = 1 - \\widehat{F}(u) = \\dfrac{\\#\\{x_i > u\\}}{n}$. Use this empirical exceedance fraction in your EVT computation.\n- If the GPD shape parameter satisfies $\\xi \\ge 1$, then the EVT $\\mathrm{ES}_p$ is not finite. The provided cases keep $\\xi  1$; you should still guard against non-finiteness in your implementation.\n- Use $p = 0.995$ and report each $\\Delta$ rounded to six decimals.\n- Final output format: Your program should produce a single line of output containing the results for Cases A–D as a comma-separated list of four floats enclosed in square brackets (for example, $[0.123456,-0.000321,0.500000,1.234567]$).\n\nYour program must be self-contained, require no input, and must compute all quantities from the above definitions. The final answers must be printed exactly as specified, rounded to six decimals, with no additional text.", "solution": "The problem presented is a valid exercise in computational finance, grounded in the established principles of Extreme Value Theory (EVT). It requires the derivation and comparison of two methods for computing Expected Shortfall (ES): a parametric method based on the Generalized Pareto Distribution (GPD) and a non-parametric historical method. The problem is self-contained, scientifically sound, and provides all necessary data and definitions for a unique solution.\n\nWe will first derive the formula for the parametric Expected Shortfall, $\\mathrm{ES}_p^{\\mathrm{GPD}}$, from the provided fundamental principles. Then, we will outline the computational steps for both the parametric and non-parametric methods, which will inform the structure of the required program.\n\nFirst principles:\n$1$. The loss variable is denoted by $X$.\n$2$. The Expected Shortfall at a confidence level $p$ is defined as $\\mathrm{ES}_p = \\mathbb{E}[X \\mid X > q_p]$, where $q_p$ is the $p$-quantile of $X$, also known as the Value-at-Risk, $\\mathrm{VaR}_p$.\n$3$. For a sufficiently high threshold $u$, the distribution of exceedances $Y = X-u$ conditional on $X > u$ is approximated by a GPD with shape parameter $\\xi$ and scale parameter $\\beta$. The cumulative distribution function (CDF) of the GPD is $G(y) = 1 - (1 + \\xi y/\\beta)^{-1/\\xi}$ for $\\xi \\neq 0$, and $G(y) = 1 - \\exp(-y/\\beta)$ for $\\xi = 0$. The support is $y \\ge 0$ for $\\xi \\ge 0$ and $0 \\le y \\le -\\beta/\\xi$ for $\\xi  0$. We are concerned with cases where ES is finite, which requires $\\xi  1$.\n$4$. The tail probability of $X$ for $x > u$ can be expressed as $\\mathbb{P}(X > x) = \\mathbb{P}(X > u) \\cdot \\mathbb{P}(X > x \\mid X > u)$. Let $\\bar{F}(x) = \\mathbb{P}(Xx)$ be the survival function of $X$. Then for $x > u$, $\\bar{F}(x) = \\bar{F}(u) \\cdot \\bar{G}(x-u)$, where $\\bar{G}$ is the survival function of the GPD.\n\nDerivation of Parametric $\\mathrm{ES}_p^{\\mathrm{GPD}}$:\nThe derivation proceeds in two stages: first, we find an expression for the quantile $q_p$; second, we derive the conditional expectation $\\mathbb{E}[X \\mid X > q_p]$.\n\nStage 1: Calculation of the quantile $q_p$.\nSince we are interested in a high level $p$, we assume $q_p > u$. The quantile $q_p$ is defined by the relation $\\bar{F}(q_p) = 1-p$.\nUsing the tail approximation, we have $1-p = \\bar{F}(u) \\cdot \\bar{G}(q_p - u)$.\nWe must now consider the cases for $\\xi$.\n\nCase $\\xi \\neq 0$:\nThe GPD survival function is $\\bar{G}(y) = (1 + \\xi y/\\beta)^{-1/\\xi}$.\nSubstituting this into the tail probability relation gives:\n$1-p = \\bar{F}(u) \\left(1 + \\frac{\\xi(q_p - u)}{\\beta}\\right)^{-1/\\xi}$\nWe solve for $q_p$:\n$\\left(\\frac{1-p}{\\bar{F}(u)}\\right)^{-\\xi} = 1 + \\frac{\\xi(q_p - u)}{\\beta}$\n$\\frac{\\xi(q_p - u)}{\\beta} = \\left(\\frac{\\bar{F}(u)}{1-p}\\right)^{\\xi} - 1$\n$q_p = u + \\frac{\\beta}{\\xi} \\left[ \\left(\\frac{\\bar{F}(u)}{1-p}\\right)^{\\xi} - 1 \\right]$\nIn practice, $\\bar{F}(u)$ is estimated from the sample of size $n$ by its empirical counterpart, $\\widehat{\\bar{F}}(u) = \\frac{N_u}{n}$, where $N_u$ is the number of observations exceeding $u$.\n\nCase $\\xi = 0$:\nThe GPD survival function is $\\bar{G}(y) = \\exp(-y/\\beta)$.\n$1-p = \\bar{F}(u) \\exp\\left(-\\frac{q_p - u}{\\beta}\\right)$\n$\\ln\\left(\\frac{1-p}{\\bar{F}(u)}\\right) = -\\frac{q_p - u}{\\beta}$\n$q_p = u - \\beta \\ln\\left(\\frac{1-p}{\\bar{F}(u)}\\right) = u + \\beta \\ln\\left(\\frac{\\bar{F}(u)}{1-p}\\right)$\nThis formula is the limit of the $\\xi \\neq 0$ case as $\\xi \\to 0$, since $(a^{\\xi}-1)/\\xi \\to \\ln(a)$.\n\nStage 2: Calculation of the Expected Shortfall $\\mathrm{ES}_p$.\n$\\mathrm{ES}_p = \\mathbb{E}[X \\mid X > q_p]$. We can write this as $\\mathrm{ES}_p = q_p + \\mathbb{E}[X - q_p \\mid X > q_p]$. The term $\\mathbb{E}[X - q_p \\mid X > q_p]$ is the mean excess over the threshold $q_p$.\nA fundamental property of the GPD is its stability under conditioning on a higher threshold. If the distribution of excesses $X-u$ over threshold $u$ is $GPD(\\xi, \\beta)$, then for any $q_p > u$, the distribution of excesses $X-q_p$ over the higher threshold $q_p$ is also a GPD, specifically $GPD(\\xi, \\beta')$, where the new scale parameter is $\\beta' = \\beta + \\xi(q_p - u)$.\n\nThe mean of a $GPD(\\xi, \\beta')$ distribution is $\\frac{\\beta'}{1-\\xi}$, provided $\\xi  1$.\nTherefore, the mean excess over $q_p$ is:\n$\\mathbb{E}[X - q_p \\mid X > q_p] = \\frac{\\beta + \\xi(q_p - u)}{1-\\xi}$ for $\\xi  1$.\nCombining this with the decomposition of $\\mathrm{ES}_p$:\n$\\mathrm{ES}_p = q_p + \\frac{\\beta + \\xi(q_p - u)}{1-\\xi}$\nThis can be simplified:\n$\\mathrm{ES}_p = \\frac{q_p (1-\\xi) + \\beta + \\xi q_p - \\xi u}{1-\\xi} = \\frac{q_p - \\xi q_p + \\beta + \\xi q_p - \\xi u}{1-\\xi} = \\frac{q_p + \\beta - \\xi u}{1-\\xi}$\nThis is our final expression for $\\mathrm{ES}_p^{\\mathrm{GPD}}$ when $\\xi \\neq 0$ and $\\xi  1$.\n\nFor the case $\\xi = 0$, the $GPD(0, \\beta)$ is an exponential distribution with mean $\\beta$. Due to the memoryless property of the exponential distribution, the mean excess over any threshold is simply $\\beta$.\nThus, $\\mathbb{E}[X - q_p \\mid X > q_p] = \\beta$.\nAnd so, $\\mathrm{ES}_p = q_p + \\beta$.\nThis result is also consistent with the limit of the general formula for $\\mathrm{ES}_p$ as $\\xi \\to 0$.\n\nSummary of Parametric ES Calculation Steps:\n1. From the sample data $\\{x_i\\}_{i=1}^n$, calculate the empirical exceedance probability $\\widehat{\\bar{F}}(u) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}\\{x_i > u\\}$.\n2. Using the given GPD parameters $\\xi$ and $\\beta$, confidence level $p$, and threshold $u$, calculate the quantile $q_p$.\n   - If $\\xi \\neq 0$: $q_p = u + \\frac{\\beta}{\\xi} \\left[ \\left(\\frac{\\widehat{\\bar{F}}(u)}{1-p}\\right)^{\\xi} - 1 \\right]$\n   - If $\\xi = 0$: $q_p = u + \\beta \\ln\\left(\\frac{\\widehat{\\bar{F}}(u)}{1-p}\\right)$\n3. Calculate the Expected Shortfall $\\mathrm{ES}_p^{\\mathrm{GPD}}$.\n   - If $\\xi \\neq 0$ and $\\xi1$: $\\mathrm{ES}_p^{\\mathrm{GPD}} = \\frac{q_p + \\beta - \\xi u}{1-\\xi}$\n   - If $\\xi = 0$: $\\mathrm{ES}_p^{\\mathrm{GPD}} = q_p + \\beta$\n   - If $\\xi \\ge 1$: $\\mathrm{ES}_p^{\\mathrm{GPD}}$ is infinite.\n\nCalculation of Non-Parametric Historical $\\mathrm{ES}_p^{\\mathrm{hist}}$:\nThe procedure is explicitly defined in the problem statement.\n1. Generate the sample $\\{x_i\\}_{i=1}^n$.\n2. Sort the sample to obtain the order statistics $x_{(1)} \\le x_{(2)} \\le \\cdots \\le x_{(n)}$.\n3. Compute the index $j = \\lceil p n \\rceil$. The problem notes to cap $j$ at $n$, but this is not necessary for $p1$.\n4. The historical Expected Shortfall is the arithmetic mean of all observations from the $j$-th observation to the last:\n$\\mathrm{ES}^{\\mathrm{hist}}_p = \\frac{1}{n-j+1} \\sum_{k=j}^n x_{(k)}$\n\nFinal Computation:\nFor each test case, we compute $\\mathrm{ES}^{\\mathrm{GPD}}_p$ and $\\mathrm{ES}^{\\mathrm{hist}}_p$ according to these procedures and report the difference $\\Delta = \\mathrm{ES}^{\\mathrm{GPD}}_p - \\mathrm{ES}^{\\mathrm{hist}}_p$, rounded to six decimal places. The implementation will follow these derived steps precisely.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating and comparing parametric EVT Expected Shortfall\n    and non-parametric historical Expected Shortfall for four test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Lognormal\n        {\n            'name': 'A', 'n': 1000, 'p': 0.995, 'u': 3.5,\n            'gpd_xi': 0.20, 'gpd_beta': 1.10,\n            'data_gen': lambda n: np.exp(norm.ppf(np.arange(1, n + 1) / (n + 1)))\n        },\n        # Case B: Pareto Type I (alpha = 2.5)\n        {\n            'name': 'B', 'n': 1500, 'p': 0.995, 'u': 5.0,\n            'gpd_xi': 0.4, 'gpd_beta': 2.0,\n            'data_gen': lambda n: (1 - np.arange(1, n + 1) / (n + 1))**(-1/2.5)\n        },\n        # Case C: Exponential\n        {\n            'name': 'C', 'n': 1200, 'p': 0.995, 'u': 2.0,\n            'gpd_xi': 0.0, 'gpd_beta': 1.0,\n            'data_gen': lambda n: -np.log(1 - np.arange(1, n + 1) / (n + 1))\n        },\n        # Case D: Heavy Pareto (alpha = 1.05)\n        {\n            'name': 'D', 'n': 3000, 'p': 0.995, 'u': 10.0,\n            'alpha': 1.05,\n            # GPD parameters are derived from alpha\n            'gpd_xi': 1 / 1.05, 'gpd_beta': (1 / 1.05) * 10.0,\n            'data_gen': lambda n: (1 - np.arange(1, n + 1) / (n + 1))**(-1/1.05)\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n = case['n']\n        p = case['p']\n        u = case['u']\n        xi = case['gpd_xi']\n        beta = case['gpd_beta']\n        data_gen_func = case['data_gen']\n\n        # 1. Generate the data sample deterministically\n        sample = data_gen_func(n)\n\n        # 2. Calculate the parametric EVT Expected Shortfall (ES_GPD)\n        \n        # Estimate the exceedance probability F_bar(u) empirically\n        n_u = np.sum(sample  u)\n        f_bar_u_hat = n_u / n\n\n        es_gpd = np.nan\n        if xi = 1:\n            # ES is not finite\n            # This path is not taken by the test cases but is included for completeness\n            es_gpd = np.inf\n        else:\n            # Calculate VaR (q_p) first\n            if xi == 0:\n                q_p = u + beta * np.log(f_bar_u_hat / (1 - p))\n                es_gpd = q_p + beta\n            else: # xi != 0\n                term = (f_bar_u_hat / (1 - p))**xi\n                q_p = u + (beta / xi) * (term - 1)\n                es_gpd = (q_p + beta - xi * u) / (1 - xi)\n        \n        # 3. Calculate the non-parametric historical Expected Shortfall (ES_hist)\n        \n        # The sample is already sorted due to the generation method\n        # If not, one would use sample.sort()\n        \n        # Determine the index j\n        j = int(np.ceil(p * n))\n        \n        # Python uses 0-based indexing, so the slice starts at j-1\n        # The tail of the data is from index j-1 to the end\n        tail_data = sample[j-1:]\n        \n        if len(tail_data)  0:\n            es_hist = np.mean(tail_data)\n        else:\n            # Should not happen for p  1\n            es_hist = np.nan if n == 0 else sample[-1]\n\n        # 4. Calculate the difference and round\n        difference = es_gpd - es_hist\n        results.append(round(difference, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2391786"}, {"introduction": "A model is only as good as its assumptions, and in financial modeling, misspecification can lead to disastrous outcomes. This final practice confronts this issue head-on by exploring a crucial real-world scenario: what happens if we select the wrong type of tail model [@problem_id:2391806]? You will quantify the severe underestimation of risk that occurs when an analyst mistakenly assumes a light, exponential-type tail (a GPD with $\\xi=0$) when the data actually follows a heavier, power-law tail ($\\xi>0$). This exercise provides a stark, quantitative demonstration of why correctly diagnosing the tail behavior of asset returns is of paramount importance.", "problem": "A risk manager models portfolio loss exceedances using the Peaks-Over-Threshold framework. Let the portfolio loss be a random variable $L$, and let $u$ be a fixed threshold. Define the exceedance $Y=L-u$ conditional on $L>u$. Assume that conditional on $L>u$, the exceedances $Y$ follow a Generalized Pareto Distribution (GPD) with shape parameter $\\xi$ and scale parameter $\\beta>0$. The cumulative distribution function of $Y$ is\n$$F_Y(y)=1-\\left(1+\\frac{\\xi y}{\\beta}\\right)^{-1/\\xi}\\quad\\text{for }\\xi\\neq 0,\\ y\\ge 0,\\ 1+\\frac{\\xi y}{\\beta}>0,$$\nand\n$$F_Y(y)=1-\\exp\\left(-\\frac{y}{\\beta}\\right)\\quad\\text{for }\\xi=0,\\ y\\ge 0.$$\nLet $p_u=\\mathbb{P}(L>u)$ denote the exceedance probability. For an unconditional probability level $\\alpha\\in(0,1)$ with $\\alpha>1-p_u$, define the unconditional Value at Risk (VaR) at level $\\alpha$ as $\\mathrm{VaR}_\\alpha$, namely the $\\alpha$-quantile of $L$. Define the Expected Shortfall (ES) at level $\\alpha$ as $\\mathrm{ES}_\\alpha=\\mathbb{E}[L\\mid L>\\mathrm{VaR}_\\alpha]$, whenever it is finite.\n\nSuppose the true tail is Fréchet-type with $\\xi=\\xi_{\\text{true}}0$ and $\\xi_{\\text{true}}1$ (so that $\\mathrm{ES}_\\alpha$ is finite), but an analyst misspecifies the tail as Gumbel-type by imposing $\\xi=0$ while using the same $u$, $p_u$, and $\\beta$.\n\nFor each test case below, compute the misspecification ratio\n$$R=\\frac{\\mathrm{ES}_\\alpha^{\\text{mis}}}{\\mathrm{ES}_\\alpha^{\\text{true}}},$$\nwhere $\\mathrm{ES}_\\alpha^{\\text{true}}$ is computed under the true $\\xi_{\\text{true}}0$, and $\\mathrm{ES}_\\alpha^{\\text{mis}}$ is computed under the misspecified $\\xi=0$, both using the same $u$, $p_u$, and $\\beta$. All computations should follow from the definitions above and standard properties of the Generalized Pareto Distribution and conditional exceedances. Express each $R$ as a decimal rounded to $6$ decimal places.\n\nTest suite (each tuple is $(u,p_u,\\beta,\\xi_{\\text{true}},\\alpha)$):\n- Case $1$: $(1.0,0.05,1.5,0.3,0.99)$\n- Case $2$: $(1.0,0.10,0.7,0.05,0.98)$\n- Case $3$: $(0.5,0.02,1.0,0.9,0.999)$\n- Case $4$: $(2.0,0.01,0.8,0.4,0.995)$\n\nYour program must produce a single line of output containing the results for all cases as a comma-separated list enclosed in square brackets, in the same order as the test suite (e.g., $[r_1,r_2,r_3,r_4]$), with each $r_i$ rounded to $6$ decimal places.", "solution": "The problem requires the computation of a misspecification ratio for the Expected Shortfall (ES) risk measure. This is a standard problem in quantitative risk management, requiring a rigorous application of definitions from Extreme Value Theory (EVT). We shall first validate the problem statement and then proceed to derive the necessary formulae.\n\nThe validation steps confirm the problem is scientifically sound, well-posed, and objective.\nGivens are extracted verbatim as required:\n- Portfolio loss is a random variable $L$.\n- Threshold is $u$.\n- Exceedance is $Y=L-u$ conditional on $L>u$.\n- Distribution of $Y$ is Generalized Pareto (GPD) with shape $\\xi$ and scale $\\beta>0$.\n- CDF of $Y$ for $\\xi\\neq 0$: $F_Y(y)=1-\\left(1+\\frac{\\xi y}{\\beta}\\right)^{-1/\\xi}$.\n- CDF of $Y$ for $\\xi=0$: $F_Y(y)=1-\\exp\\left(-\\frac{y}{\\beta}\\right)$.\n- Exceedance probability is $p_u=\\mathbb{P}(L>u)$.\n- Value at Risk is $\\mathrm{VaR}_\\alpha$, the $\\alpha$-quantile of $L$ for $\\alpha \\in (0,1)$ with $\\alpha > 1-p_u$.\n- Expected Shortfall is $\\mathrm{ES}_\\alpha=\\mathbb{E}[L\\mid L>\\mathrm{VaR}_\\alpha]$.\n- True model has a Fréchet-type tail with $\\xi=\\xi_{\\text{true}} \\in (0,1)$.\n- Misspecified model has a Gumbel-type tail with $\\xi=0$.\n- Parameters $u$, $p_u$, and $\\beta$ are invariant.\n- The task is to compute the ratio $R=\\frac{\\mathrm{ES}_\\alpha^{\\text{mis}}}{\\mathrm{ES}_\\alpha^{\\text{true}}}$.\n- Test cases are provided as tuples $(u, p_u, \\beta, \\xi_{\\text{true}}, \\alpha)$.\n\nThe problem is valid. It is a standard application of the Peaks-Over-Threshold (POT) methodology, founded on established mathematical and statistical principles. All definitions and conditions are standard, complete, and consistent. The condition $\\alpha > 1-p_u$ ensures that $\\mathrm{VaR}_\\alpha > u$, placing the quantile in the tail region modeled by the GPD. The condition $\\xi_{\\text{true}}  1$ ensures that the first moment of the GPD, and thus the Expected Shortfall, is finite. We proceed with the solution.\n\nThe derivation proceeds in three stages: first, we derive the general expression for $\\mathrm{VaR}_\\alpha$; second, we derive the general expression for $\\mathrm{ES}_\\alpha$; third, we specialize these expressions for the true and misspecified models and form the ratio.\n\n**1. Derivation of Value at Risk ($\\mathrm{VaR}_\\alpha$)**\n\nThe POT model relates the unconditional tail of $L$ to the conditional distribution of exceedances $Y$. For any loss level $l > u$, the tail probability of $L$ is given by:\n$$ \\mathbb{P}(L > l) = \\mathbb{P}(L > l \\mid L > u) \\cdot \\mathbb{P}(L > u) $$\nThis can be written in terms of the exceedance $Y = L - u$ and its survival function $S_Y(y) = 1 - F_Y(y)$:\n$$ \\mathbb{P}(L > l) = \\mathbb{P}(Y > l - u) \\cdot p_u = S_Y(l-u) \\cdot p_u $$\nBy definition, $\\mathrm{VaR}_\\alpha$ is the value such that $\\mathbb{P}(L > \\mathrm{VaR}_\\alpha) = 1-\\alpha$. We have:\n$$ 1-\\alpha = S_Y(\\mathrm{VaR}_\\alpha - u) \\cdot p_u $$\n$$ S_Y(\\mathrm{VaR}_\\alpha - u) = \\frac{1-\\alpha}{p_u} $$\nLet $y_\\alpha = \\mathrm{VaR}_\\alpha - u$. The value $y_\\alpha$ is the quantile of the GPD corresponding to the probability $q = 1 - \\frac{1-\\alpha}{p_u}$. The inverse CDF (quantile function) of the GPD, $F_Y^{-1}(q) = y$, is:\n$$ y = \\begin{cases} \\frac{\\beta}{\\xi}\\left((1-q)^{-\\xi} - 1\\right)  \\text{if } \\xi \\neq 0 \\\\ -\\beta \\ln(1-q)  \\text{if } \\xi = 0 \\end{cases} $$\nSubstituting $1-q = \\frac{1-\\alpha}{p_u}$ yields the expression for $y_\\alpha$:\n$$ y_\\alpha = \\begin{cases} \\frac{\\beta}{\\xi}\\left(\\left(\\frac{1-\\alpha}{p_u}\\right)^{-\\xi} - 1\\right) = \\frac{\\beta}{\\xi}\\left(\\left(\\frac{p_u}{1-\\alpha}\\right)^{\\xi} - 1\\right)  \\text{if } \\xi \\neq 0 \\\\ -\\beta \\ln\\left(\\frac{1-\\alpha}{p_u}\\right) = \\beta \\ln\\left(\\frac{p_u}{1-\\alpha}\\right)  \\text{if } \\xi = 0 \\end{cases} $$\nFinally, since $\\mathrm{VaR}_\\alpha = u + y_\\alpha$, we obtain the formula for $\\mathrm{VaR}_\\alpha$.\n\n**2. Derivation of Expected Shortfall ($\\mathrm{ES}_\\alpha$)**\n\n$\\mathrm{ES}_\\alpha$ is defined as the conditional expectation $\\mathbb{E}[L \\mid L  \\mathrm{VaR}_\\alpha]$. Since $\\mathrm{VaR}_\\alpha  u$, the condition $L  \\mathrm{VaR}_\\alpha$ implies $L  u$. Therefore, we can express $L$ as $u+Y$:\n$$ \\mathrm{ES}_\\alpha = \\mathbb{E}[u+Y \\mid u+Y  \\mathrm{VaR}_\\alpha] = u + \\mathbb{E}[Y \\mid Y  \\mathrm{VaR}_\\alpha - u] = u + \\mathbb{E}[Y \\mid Y  y_\\alpha]$$\nThe conditional expectation $\\mathbb{E}[Y \\mid Y  y_\\alpha]$ can be written using the mean excess function of the GPD, $e(z) = \\mathbb{E}[Y-z \\mid Y  z]$.\n$$ \\mathbb{E}[Y \\mid Y  y_\\alpha] = y_\\alpha + \\mathbb{E}[Y-y_\\alpha \\mid Y  y_\\alpha] = y_\\alpha + e(y_\\alpha) $$\nThus, $\\mathrm{ES}_\\alpha = u + y_\\alpha + e(y_\\alpha) = \\mathrm{VaR}_\\alpha + e(\\mathrm{VaR}_\\alpha - u)$. The mean excess function for a GPD with $\\xi  1$ is:\n$$ e(z) = \\frac{\\beta + \\xi z}{1-\\xi} $$\nFor the special case $\\xi=0$ (Exponential distribution), this simplifies to $e(z) = \\beta$, consistent with the memoryless property.\nSubstituting this into the expression for $\\mathrm{ES}_\\alpha$:\n$$ \\mathrm{ES}_\\alpha = \\mathrm{VaR}_\\alpha + \\frac{\\beta + \\xi(\\mathrm{VaR}_\\alpha - u)}{1-\\xi} $$\nA simplified expression can be obtained by substituting the derived form of $\\mathrm{VaR}_\\alpha - u = y_\\alpha$:\n$$ \\mathrm{ES}_\\alpha = \\mathrm{VaR}_\\alpha + \\frac{\\beta + \\xi y_\\alpha}{1-\\xi} $$\n\n**3. Specification for True and Misspecified Models**\n\nWe now apply these general formulae to the two scenarios. Let $Z = \\frac{p_u}{1-\\alpha}$.\n\n_True Model:_ $\\xi = \\xi_{\\text{true}} \\in (0, 1)$\n$$ \\mathrm{VaR}_\\alpha^{\\text{true}} = u + \\frac{\\beta}{\\xi_{\\text{true}}}\\left(Z^{\\xi_{\\text{true}}} - 1\\right) $$\n$$ \\mathrm{ES}_\\alpha^{\\text{true}} = \\mathrm{VaR}_\\alpha^{\\text{true}} + \\frac{\\beta + \\xi_{\\text{true}}(\\mathrm{VaR}_\\alpha^{\\text{true}} - u)}{1-\\xi_{\\text{true}}} $$\nSubstituting $\\mathrm{VaR}_\\alpha^{\\text{true}} - u$:\n$$ \\mathrm{ES}_\\alpha^{\\text{true}} = \\mathrm{VaR}_\\alpha^{\\text{true}} + \\frac{\\beta + \\xi_{\\text{true}}\\left(\\frac{\\beta}{\\xi_{\\text{true}}}\\left(Z^{\\xi_{\\text{true}}} - 1\\right)\\right)}{1-\\xi_{\\text{true}}} = \\mathrm{VaR}_\\alpha^{\\text{true}} + \\frac{\\beta + \\beta(Z^{\\xi_{\\text{true}}} - 1)}{1-\\xi_{\\text{true}}} = \\mathrm{VaR}_\\alpha^{\\text{true}} + \\frac{\\beta Z^{\\xi_{\\text{true}}}}{1-\\xi_{\\text{true}}} $$\n\n_Misspecified Model:_ $\\xi = 0$\n$$ \\mathrm{VaR}_\\alpha^{\\text{mis}} = u + \\beta \\ln(Z) $$\n$$ \\mathrm{ES}_\\alpha^{\\text{mis}} = \\mathrm{VaR}_\\alpha^{\\text{mis}} + \\frac{\\beta + 0 \\cdot (\\mathrm{VaR}_\\alpha^{\\text{mis}} - u)}{1-0} = \\mathrm{VaR}_\\alpha^{\\text{mis}} + \\beta $$\n\nThe misspecification ratio $R$ is therefore:\n$$ R = \\frac{\\mathrm{ES}_\\alpha^{\\text{mis}}}{\\mathrm{ES}_\\alpha^{\\text{true}}} = \\frac{u + \\beta \\ln\\left(\\frac{p_u}{1-\\alpha}\\right) + \\beta}{u + \\frac{\\beta}{\\xi_{\\text{true}}}\\left(\\left(\\frac{p_u}{1-\\alpha}\\right)^{\\xi_{\\text{true}}} - 1\\right) + \\frac{\\beta \\left(\\frac{p_u}{1-\\alpha}\\right)^{\\xi_{\\text{true}}}}{1-\\xi_{\\text{true}}}} $$\nThese formulae are implemented to compute the required ratios for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the misspecification ratio R = ES_mis / ES_true for several test cases.\n    \"\"\"\n    # Test cases: (u, p_u, beta, xi_true, alpha)\n    test_cases = [\n        (1.0, 0.05, 1.5, 0.3, 0.99),\n        (1.0, 0.10, 0.7, 0.05, 0.98),\n        (0.5, 0.02, 1.0, 0.9, 0.999),\n        (2.0, 0.01, 0.8, 0.4, 0.995)\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        u, p_u, beta, xi_true, alpha = case\n        \n        # Helper term Z\n        z_factor = p_u / (1 - alpha)\n\n        # --- True Model Calculation (xi = xi_true  0) ---\n        \n        # Power term for true model\n        z_pow_xi = np.power(z_factor, xi_true)\n        \n        # VaR_true\n        var_true = u + (beta / xi_true) * (z_pow_xi - 1)\n        \n        # ES_true\n        # The formula derived is ES_true = VaR_true + (beta * Z^xi_true) / (1 - xi_true)\n        es_true = var_true + (beta * z_pow_xi) / (1 - xi_true)\n\n        # --- Misspecified Model Calculation (xi = 0) ---\n        \n        # VaR_mis\n        # The formula is VaR_mis = u + beta * log(Z)\n        var_mis = u + beta * np.log(z_factor)\n\n        # ES_mis\n        # The formula is ES_mis = VaR_mis + beta\n        es_mis = var_mis + beta\n        \n        # --- Ratio Calculation ---\n        ratio = es_mis / es_true\n        results.append(f\"{ratio:.6f}\") # Format to 6 decimal places\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2391806"}]}