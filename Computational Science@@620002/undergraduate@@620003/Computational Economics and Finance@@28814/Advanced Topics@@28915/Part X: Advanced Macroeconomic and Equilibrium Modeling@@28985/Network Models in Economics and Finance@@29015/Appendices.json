{"hands_on_practices": [{"introduction": "The first step in network analysis is often to transform complex data into a meaningful network representation. This practice guides you through a powerful technique used in finance: converting stock market correlation data into a network backbone using a Minimum Spanning Tree ($MST$). By building and comparing $MSTs$ before and after a hypothetical market crash, you will gain hands-on experience in identifying the core structure of a financial system and observing how it changes under stress [@problem_id:2413946].", "problem": "You are asked to design and implement a program that constructs network representations of a stock market from correlation data and compares pre-crash and post-crash structures using core concepts from network models in economics and finance. You must proceed from fundamental principles and avoid using any ad hoc or unproven shortcuts. Use only the facts that for standardized return vectors, inner products correspond to Pearson product-moment correlation coefficients, and that Euclidean distances induced by inner products form a metric. From this foundation, derive a valid transformation from correlation to a distance that is strictly decreasing in correlation and satisfies the metric axioms, then compute the Minimum Spanning Tree (MST) of the resulting complete weighted graph.\n\nTask specification:\n- Input is implicit and given below as a test suite of correlation matrices. Each matrix $\\boldsymbol{\\rho} = (\\rho_{ij})$ is symmetric with $\\rho_{ii} = 1$ for all $i$, and represents pairwise Pearson product-moment correlation coefficients between assets’ standardized returns in a given regime (before or after a market crash). There is no separate data input; your program must embed and use the matrices provided below.\n- Step $1$: Using only the fundamental facts that for centered, unit-variance vectors the inner product equals their Pearson correlation and that the Euclidean norm induces a metric, derive a valid function $d_{ij}$ of $\\rho_{ij}$ that yields a metric distance on the set of assets and is strictly decreasing in $\\rho_{ij}$. Your program must implement the distance you derive.\n- Step $2$: For each provided correlation matrix, construct the complete weighted graph on the asset set with weights equal to the derived distances $d_{ij}$ between assets $i$ and $j$. Compute the Minimum Spanning Tree (MST) of this graph. Use any correct algorithm such as Kruskal’s algorithm or Prim’s algorithm. To ensure determinism in the presence of exact ties in edge weights, break ties by lexicographic order on unordered pairs $(i,j)$ with $i < j$.\n- Step $3$: For each market in the test suite, compute:\n  - The total MST weight, defined as the sum of the $n-1$ edge weights in the MST for $n$ assets.\n  - The graph diameter of the MST, defined as the maximum number of edges on a shortest path between any two nodes in the MST, i.e., the maximum of unweighted shortest path lengths over all node pairs.\n  - For each market, the number of common edges between the pre-crash MST and the post-crash MST, counting edges as unordered pairs $\\{i,j\\}$ of zero-based indices.\n- Output: For each market, output the tuple $[w_{\\text{pre}}, w_{\\text{post}}, c, \\delta_{\\text{pre}}, \\delta_{\\text{post}}]$, where $w_{\\text{pre}}$ and $w_{\\text{post}}$ are the total MST weights before and after the crash, respectively, each rounded to $6$ decimal places; $c$ is the integer number of common edges; and $\\delta_{\\text{pre}}$ and $\\delta_{\\text{post}}$ are the integer diameters before and after the crash, respectively. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, aggregating all markets in the order given by the test suite, for example: $[[w_{\\text{pre},1}, w_{\\text{post},1}, c_1, \\delta_{\\text{pre},1}, \\delta_{\\text{post},1}],[w_{\\text{pre},2}, w_{\\text{post},2}, c_2, \\delta_{\\text{pre},2}, \\delta_{\\text{post},2}]]$.\n\nTest suite:\n- Market $\\mathcal{A}$ (five assets, indices $0$ to $4$):\n  - Pre-crash correlation matrix $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{A}}$:\n  $$\n  \\begin{bmatrix}\n  1 & 0.82 & 0.31 & 0.27 & 0.14 \\\\\n  0.82 & 1 & 0.24 & 0.33 & 0.12 \\\\\n  0.31 & 0.24 & 1 & 0.78 & 0.58 \\\\\n  0.27 & 0.33 & 0.78 & 1 & 0.52 \\\\\n  0.14 & 0.12 & 0.58 & 0.52 & 1\n  \\end{bmatrix}\n  $$\n  - Post-crash correlation matrix $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{A}}$:\n  $$\n  \\begin{bmatrix}\n  1 & 0.88 & 0.72 & 0.62 & 0.40 \\\\\n  0.88 & 1 & 0.64 & 0.71 & 0.42 \\\\\n  0.72 & 0.64 & 1 & 0.85 & 0.70 \\\\\n  0.62 & 0.71 & 0.85 & 1 & 0.68 \\\\\n  0.40 & 0.42 & 0.70 & 0.68 & 1\n  \\end{bmatrix}\n  $$\n- Market $\\mathcal{B}$ (four assets, indices $0$ to $3$):\n  - Pre-crash correlation matrix $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{B}}$:\n  $$\n  \\begin{bmatrix}\n  1 & 0.60 & -0.20 & 0.10 \\\\\n  0.60 & 1 & 0.05 & -0.25 \\\\\n  -0.20 & 0.05 & 1 & 0.40 \\\\\n  0.10 & -0.25 & 0.40 & 1\n  \\end{bmatrix}\n  $$\n  - Post-crash correlation matrix $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{B}}$:\n  $$\n  \\begin{bmatrix}\n  1 & 0.82 & 0.10 & 0.30 \\\\\n  0.82 & 1 & 0.20 & -0.05 \\\\\n  0.10 & 0.20 & 1 & 0.65 \\\\\n  0.30 & -0.05 & 0.65 & 1\n  \\end{bmatrix}\n  $$\n\nAdditional requirements:\n- Indices are zero-based integers $0,1,2,\\dots$.\n- There are no physical units in this problem.\n- Round $w_{\\text{pre}}$ and $w_{\\text{post}}$ to exactly $6$ decimal places. Report $\\delta_{\\text{pre}}$, $\\delta_{\\text{post}}$, and $c$ as integers with no rounding.\n- Your program must be self-contained and produce exactly one line of output of the form $[[\\cdot],[\\cdot]]$ as specified above, with no extra whitespace beyond commas and brackets and no additional text.", "solution": "The problem statement is evaluated and found to be valid. It is scientifically grounded in the domain of econophysics, well-posed, and objective. It presents a standard, formalizable task based on established principles of network theory applied to financial data. We proceed to the solution.\n\nThe solution is constructed in three stages as specified. First, a distance metric is derived from the correlation coefficient. Second, an algorithm to construct the Minimum Spanning Tree (MST) from this metric is detailed. Third, the procedure for computing the required network properties is described.\n\n**Step 1: Derivation of the Distance Metric**\n\nThe problem requires the derivation of a distance function $d_{ij}$ from a correlation coefficient $\\rho_{ij}$ that satisfies the metric axioms and is strictly decreasing in $\\rho_{ij}$. The derivation must be based on two foundational principles:\n$1$. For a set of assets, there exist corresponding standardized return vectors $\\mathbf{v}_i$ in an inner product space such that they are unit vectors, i.e., $\\|\\mathbf{v}_i\\|^2 = \\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle = \\rho_{ii} = 1$, and their inner product is the Pearson correlation coefficient, $\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$.\n$2$. The Euclidean distance $d(\\mathbf{v}_i, \\mathbf{v}_j) = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|$ induced by the inner product is a valid metric.\n\nWe begin by expanding the squared Euclidean distance between two such vectors, $\\mathbf{v}_i$ and $\\mathbf{v}_j$:\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2\n$$\nBy the definition of the norm induced by an inner product:\n$$\n\\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2 = \\langle \\mathbf{v}_i - \\mathbf{v}_j, \\mathbf{v}_i - \\mathbf{v}_j \\rangle\n$$\nUsing the bilinearity of the inner product, this expands to:\n$$\n\\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle - 2\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle + \\langle \\mathbf{v}_j, \\mathbf{v}_j \\rangle\n$$\nSubstituting the premises $\\|\\mathbf{v}_i\\|^2 = 1$ and $\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$:\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = 1 - 2\\rho_{ij} + 1 = 2(1 - \\rho_{ij})\n$$\nTaking the square root yields the distance function $d_{ij}$ as a function of $\\rho_{ij}$:\n$$\nd_{ij} = \\sqrt{2(1 - \\rho_{ij})}\n$$\nWe must verify that this function $d_{ij}$ is a metric and is strictly decreasing in $\\rho_{ij}$.\n\nVerification of Metric Axioms:\n- **Non-negativity**: Since $\\rho_{ij} \\in [-1, 1]$, the term $1 - \\rho_{ij}$ is in the range $[0, 2]$. Therefore, $d_{ij}$ is real and non-negative. $d_{ij} \\ge 0$.\n- **Identity of Indiscernibles**: $d_{ij} = 0 \\iff 2(1 - \\rho_{ij}) = 0 \\iff \\rho_{ij} = 1$. This corresponds to perfectly correlated assets, which in this vector representation means $\\mathbf{v}_i = \\mathbf{v}_j$. For $i \\neq j$, we assume $\\rho_{ij} < 1$, so $d_{ij} > 0$. Also, $d_{ii} = \\sqrt{2(1 - \\rho_{ii})} = \\sqrt{2(1 - 1)} = 0$.\n- **Symmetry**: The correlation matrix is symmetric, $\\rho_{ij} = \\rho_{ji}$. Thus, $d_{ij} = \\sqrt{2(1 - \\rho_{ij})} = \\sqrt{2(1 - \\rho_{ji})} = d_{ji}$.\n- **Triangle Inequality**: $d_{ik} \\le d_{ij} + d_{jk}$. This inequality holds because $d_{ij}$ is precisely the Euclidean distance between vectors in a Euclidean space, where the triangle inequality is a fundamental property.\n\nVerification of Monotonicity:\nTo confirm that $d_{ij}$ is strictly decreasing in $\\rho_{ij}$, we examine its first derivative with respect to $\\rho$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\rho} \\left( \\sqrt{2(1 - \\rho)} \\right) = -\\frac{1}{\\sqrt{2(1 - \\rho)}}\n$$\nFor $\\rho < 1$, the denominator is real and positive, so the derivative is strictly negative. This confirms that the derived distance $d_{ij}$ is a strictly decreasing function of the correlation $\\rho_{ij}$. The function $d_{ij} = \\sqrt{2(1 - \\rho_{ij})}$ is therefore the correct metric to use.\n\n**Step 2: Minimum Spanning Tree Construction**\n\nFor each correlation matrix $\\boldsymbol{\\rho}$, we construct a complete weighted graph $G = (V, E)$, where the set of vertices $V$ represents the assets, and the weight of the edge between any two vertices $i$ and $j$ is given by the distance $d_{ij}$. The Minimum Spanning Tree (MST) of this graph is a subgraph that connects all vertices with the minimum possible sum of edge weights, containing no cycles.\n\nWe will use Kruskal's algorithm to compute the MST. This algorithm operates as follows:\n$1$. Create a list of all edges in the complete graph, represented as tuples $(w, u, v)$ where $w$ is the weight $d_{uv}$, and $u, v$ are the vertex indices with $u < v$. There are $\\binom{n}{2} = \\frac{n(n-1)}{2}$ such edges for a graph with $n$ assets.\n$2$. Sort this list of edges in ascending order of their weights. To ensure determinism, ties in weights are broken by lexicographical order of the vertex pairs $(u,v)$. For two edges with the same weight, the edge with the lexicographically smaller pair $(u, v)$ is chosen first.\n$3$. Initialize a Disjoint Set Union (DSU) data structure, with each vertex in its own set.\n$4$. Iterate through the sorted list of edges. For each edge $(w, u, v)$:\n    - Check if vertices $u$ and $v$ belong to the same set using the DSU's `find` operation.\n    - If they do not, the edge does not form a cycle. Add this edge to the MST and merge the sets containing $u$ and $v$ using the DSU's `union` operation.\n$5$. The algorithm terminates when $n-1$ edges have been added to the MST.\n\n**Step 3: Computation of Network Properties**\n\nWith the MST constructed for both pre-crash and post-crash regimes of each market, we compute the following properties:\n\n- **Total MST Weight ($w$):** This is the sum of the weights of all edges in the MST. For an MST with edges $E_{\\text{MST}}$, the total weight is $w = \\sum_{\\{i,j\\} \\in E_{\\text{MST}}} d_{ij}$. This value is computed for both pre-crash ($w_{\\text{pre}}$) and post-crash ($w_{\\text{post}}$) MSTs and rounded to $6$ decimal places.\n\n- **MST Diameter ($\\delta$):** The diameter of a tree is the length of the longest shortest path between any two of its nodes. The path length is measured by the number of edges (unweighted). We compute it using the following standard two-pass algorithm:\n    $1$. Construct an adjacency list representation of the MST.\n    $2$. Perform a Breadth-First Search (BFS) starting from an arbitrary node $s$ to find the node $u$ that is farthest from it.\n    $3$. Perform a second BFS starting from node $u$ to find the node $v$ that is farthest from it. The distance from $u$ to $v$ is the diameter of the tree.\n    This is computed for both pre-crash ($\\delta_{\\text{pre}}$) and post-crash ($\\delta_{\\text{post}}$) MSTs.\n\n- **Number of Common Edges ($c$):** This an integer value representing the size of the intersection of the edge sets of the pre-crash MST and the post-crash MST. Edges are treated as unordered pairs of zero-based indices $\\{i, j\\}$. By representing each edge canonically as a tuple $(i, j)$ with $i < j$, we can find the intersection of the two sets of MST edges.\n\nThese steps are systematically applied to the data for each market provided in the test suite to produce the final output.", "answer": "```python\nimport numpy as np\nimport math\n\n# No other libraries are permitted as per instructions.\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It processes each market's pre- and post-crash correlation matrices,\n    computes the required metrics, and prints the formatted result.\n    \"\"\"\n\n    class DSU:\n        \"\"\"A simple Disjoint Set Union data structure for Kruskal's algorithm.\"\"\"\n        def __init__(self, n):\n            self.parent = list(range(n))\n            self.num_sets = n\n\n        def find(self, i):\n            \"\"\"Find the representative of the set containing element i with path compression.\"\"\"\n            if self.parent[i] == i:\n                return i\n            self.parent[i] = self.find(self.parent[i])\n            return self.parent[i]\n\n        def union(self, i, j):\n            \"\"\"Merge the sets containing elements i and j.\"\"\"\n            root_i = self.find(i)\n            root_j = self.find(j)\n            if root_i != root_j:\n                self.parent[root_i] = root_j\n                self.num_sets -= 1\n                return True\n            return False\n\n    def get_mst_diameter(n, mst_edges):\n        \"\"\"\n        Computes the diameter of a tree (given as an MST edge list).\n        The diameter is the longest shortest path between any two nodes.\n        Path length is the number of edges.\n        \"\"\"\n        if n <= 1:\n            return 0\n        \n        adj = [[] for _ in range(n)]\n        for u, v in mst_edges:\n            adj[u].append(v)\n            adj[v].append(u)\n\n        def bfs(start_node):\n            \"\"\"Performs a BFS to find the farthest node and distance from a start node.\"\"\"\n            distances = [-1] * n\n            queue = [(start_node, 0)]\n            distances[start_node] = 0\n            \n            head = 0\n            farthest_node = start_node\n            max_dist = 0\n\n            while head < len(queue):\n                u, dist = queue[head]\n                head += 1\n\n                if dist > max_dist:\n                    max_dist = dist\n                    farthest_node = u\n\n                for v in adj[u]:\n                    if distances[v] == -1:\n                        distances[v] = dist + 1\n                        queue.append((v, dist + 1))\n            \n            return farthest_node, max_dist\n\n        # 1. First BFS from an arbitrary node (0) to find one endpoint of a diameter.\n        node_u, _ = bfs(0)\n        # 2. Second BFS from that endpoint to find the actual diameter.\n        _, diameter = bfs(node_u)\n        \n        return diameter\n\n    def process_correlation_matrix(rho_matrix):\n        \"\"\"\n        Takes a correlation matrix and returns MST properties:\n        total weight, diameter, and the set of edges.\n        \"\"\"\n        n = rho_matrix.shape[0]\n        \n        # Step 1: Derive distance and create a list of edges with weights.\n        # d_ij = sqrt(2 * (1 - rho_ij))\n        # The tie-breaking is handled by sorting on (weight, u, v).\n        edges = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                rho_ij = rho_matrix[i, j]\n                # Defensive check for floating point inaccuracies leading to rho > 1\n                if rho_ij > 1.0:\n                    rho_ij = 1.0\n                dist = math.sqrt(2.0 * (1.0 - rho_ij))\n                edges.append((dist, i, j))\n        \n        # Sort edges: primary key is weight, secondary keys are i then j.\n        edges.sort()\n\n        # Step 2: Compute MST using Kruskal's algorithm.\n        dsu = DSU(n)\n        mst_edges = []\n        mst_weight = 0.0\n        \n        for dist, u, v in edges:\n            if dsu.union(u, v):\n                mst_edges.append((u, v))\n                mst_weight += dist\n                if len(mst_edges) == n - 1:\n                    break\n        \n        # Step 3: Compute MST diameter.\n        mst_diameter = get_mst_diameter(n, mst_edges)\n        \n        # Return canonical representation of edges (sorted tuples) for comparison\n        mst_edge_set = {tuple(sorted(edge)) for edge in mst_edges}\n\n        return mst_weight, mst_diameter, mst_edge_set\n\n    # Test suite provided in the problem description.\n    test_cases = [\n        # Market A\n        {\n            \"name\": \"Market A\",\n            \"pre\": np.array([\n                [1.00, 0.82, 0.31, 0.27, 0.14],\n                [0.82, 1.00, 0.24, 0.33, 0.12],\n                [0.31, 0.24, 1.00, 0.78, 0.58],\n                [0.27, 0.33, 0.78, 1.00, 0.52],\n                [0.14, 0.12, 0.58, 0.52, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.88, 0.72, 0.62, 0.40],\n                [0.88, 1.00, 0.64, 0.71, 0.42],\n                [0.72, 0.64, 1.00, 0.85, 0.70],\n                [0.62, 0.71, 0.85, 1.00, 0.68],\n                [0.40, 0.42, 0.70, 0.68, 1.00]\n            ])\n        },\n        # Market B\n        {\n            \"name\": \"Market B\",\n            \"pre\": np.array([\n                [1.00, 0.60, -0.20, 0.10],\n                [0.60, 1.00, 0.05, -0.25],\n                [-0.20, 0.05, 1.00, 0.40],\n                [0.10, -0.25, 0.40, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.82, 0.10, 0.30],\n                [0.82, 1.00, 0.20, -0.05],\n                [0.10, 0.20, 1.00, 0.65],\n                [0.30, -0.05, 0.65, 1.00]\n            ])\n        }\n    ]\n\n    result_strings = []\n    \n    for market_data in test_cases:\n        w_pre, d_pre, edges_pre = process_correlation_matrix(market_data[\"pre\"])\n        w_post, d_post, edges_post = process_correlation_matrix(market_data[\"post\"])\n        \n        # Calculate number of common edges\n        common_edges_count = len(edges_pre.intersection(edges_post))\n        \n        # Format the result tuple for this market\n        w_pre_str = f\"{w_pre:.6f}\"\n        w_post_str = f\"{w_post:.6f}\"\n        \n        market_result_str = (\n            f\"[{w_pre_str},{w_post_str},{common_edges_count},\"\n            f\"{d_pre},{d_post}]\"\n        )\n        result_strings.append(market_result_str)\n\n    # Print the final output in the exact required format\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2413946"}, {"introduction": "Once a network is defined, we can analyze its resilience and identify critical nodes. This exercise introduces a dynamic stress-testing procedure based on targeted attacks, a common method for assessing systemic risk in financial networks. You will implement an iterative process that progressively removes the most central nodes—as measured by the influential PageRank algorithm—to determine how many failures it takes for the network to fragment [@problem_id:2413880]. This provides practical insight into network robustness and tipping points.", "problem": "Consider a directed, weighted financial network represented by an adjacency matrix $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$ whose entries are $W_{ij}$, where $W_{ij}$ denotes the nonnegative exposure weight from node $i$ to node $j$. Let the set of active nodes at step $t$ be $V_t \\subseteq \\{0,1,\\dots,n-1\\}$ with $|V_t| = m_t$. For any active set $V_t$, define the row-stochastic transition matrix $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$ by\n- for each active node $i \\in V_t$, let $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$,\n- if $s_i^{(t)} > 0$, set $P_{ij}^{(t)} = W_{ij} / s_i^{(t)}$ for $j \\in V_t$,\n- if $s_i^{(t)} = 0$ (a dangling node), set $P_{ij}^{(t)} = 1/m_t$ for all $j \\in V_t$.\n\nFix a damping factor $d \\in (0,1)$. The PageRank vector $\\pi^{(t)} \\in \\mathbb{R}^{m_t}$ at step $t$ is defined as the unique solution to\n$$\n\\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t} + d \\left(P^{(t)}\\right)^\\top \\pi^{(t)},\n$$\nwith the normalization $\\sum_{i \\in V_t} \\pi^{(t)}_i = 1$ and $\\pi^{(t)}_i \\ge 0$ for all $i \\in V_t$.\n\nDefine a stress-testing sequence as follows. Initialize $V_0 = \\{0,1,\\dots,n-1\\}$. At each step $t \\in \\{0,1,2,\\dots\\}$:\n1. Compute $\\pi^{(t)}$ on the subnetwork induced by $V_t$.\n2. Select $v_t \\in \\arg\\max_{i \\in V_t} \\pi^{(t)}_i$; break ties by choosing the smallest index in $\\{0,1,\\dots,n-1\\}$.\n3. Remove the selected node: $V_{t+1} = V_t \\setminus \\{v_t\\}$.\n\nFor any active set $V_t$, define the undirected version of the induced subgraph by placing an undirected edge between $i$ and $j$ if either $W_{ij} > 0$ or $W_{ji} > 0$ with $i,j \\in V_t$. Let $C^{(t)}$ be the size (number of nodes) of the largest weakly connected component of this undirected subgraph, where isolated nodes count as components of size $1$ and the empty graph has component size $0$.\n\nGiven an initial network $(W, n)$, a damping factor $d \\in (0,1)$, and a threshold $\\theta \\in (0,1]$, define the failure time\n$$\nk^\\star = \\min \\left\\{ t \\in \\{0,1,\\dots,n\\} \\,:\\, C^{(t)} \\le \\theta \\cdot n \\right\\}.\n$$\nIf the initial network already satisfies $C^{(0)} \\le \\theta \\cdot n$, then $k^\\star = 0$. The required output for each test case is the integer $k^\\star$.\n\nYour task is to write a program that, for each test case below, computes the corresponding integer $k^\\star$ according to the definitions above. The PageRank centrality must be recomputed on the current active set $V_t$ at each step. Ties in the maximizer set must be resolved by selecting the node with the smallest original index in $\\{0,1,\\dots,n-1\\}$.\n\nTest suite (each case specifies $n$, the nonzero edges of $W$ with unit weights, the damping factor $d$, and the threshold $\\theta$):\n- Case A:\n  - $n = 4$,\n  - Nonzero directed edges with unit weight: $(1,0)$, $(2,0)$, $(3,0)$, and all other entries $0$,\n  - $d = 0.85$,\n  - $\\theta = 0.5$.\n- Case B:\n  - $n = 5$,\n  - Directed cycle with unit weights: $(0,1)$, $(1,2)$, $(2,3)$, $(3,4)$, $(4,0)$,\n  - $d = 0.85$,\n  - $\\theta = 0.6$.\n- Case C:\n  - $n = 6$,\n  - Complete directed network with unit weights on all ordered pairs $(i,j)$ with $i \\ne j$ and zero on the diagonal,\n  - $d = 0.9$,\n  - $\\theta = 0.5$.\n- Case D:\n  - $n = 5$,\n  - Two weakly connected components with unit weights: $(0,1)$, $(1,0)$, $(2,3)$, $(3,4)$, and all other entries $0$,\n  - $d = 0.85$,\n  - $\\theta = 0.8$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list of the four integers $[k_A,k_B,k_C,k_D]$ in the order of the cases A, B, C, D, enclosed in square brackets, for example $[1,2,3,4]$. No additional text should be printed.", "solution": "The problem statement has been validated and is deemed scientifically sound, well-posed, objective, and computationally tractable. It describes a discrete-time node removal process on a directed network, where the node selected for removal at each step is determined by its PageRank centrality. The process terminates when the network's structural integrity, measured by the size of its largest weakly connected component, falls below a specified threshold.\n\nThe solution is a direct simulation of this stress-testing sequence. The simulation proceeds iteratively, from step $t=0$ up to a maximum of $t=n$. At each step $t$, the state of the network is defined by the set of active nodes, $V_t$. The following sequence of computations is performed.\n\nFirst, the primary termination criterion is evaluated. This requires computing $C^{(t)}$, the size of the largest weakly connected component of the subgraph induced by the active nodes $V_t$. An undirected graph is conceptually constructed from the active nodes, where an edge exists between nodes $i, j \\in V_t$ if the original weight matrix $W$ satisfies $W_{ij} > 0$ or $W_{ji} > 0$. The sizes of the connected components of this undirected graph are found using a standard graph traversal algorithm, such as Breadth-First Search (BFS) or Depth-First Search (DFS). The maximum of these sizes is $C^{(t)}$. If $C^{(t)} \\le \\theta \\cdot n$, the process terminates, and the failure time is $k^\\star = t$.\n\nIf the termination condition is not met, the simulation proceeds to identify the next node to be removed. This requires computing the PageRank vector $\\pi^{(t)}$ for the subnetwork induced by $V_t$. Let $m_t = |V_t|$ be the number of active nodes. The row-stochastic transition matrix $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$ is constructed according to the rules provided. For a node $i \\in V_t$ with outgoing links to other nodes in $V_t$, its corresponding row in $P^{(t)}$ is normalized by its out-strength $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$. For a dangling node ($s_i^{(t)}=0$), the corresponding row is a uniform distribution, $P_{ij}^{(t)} = 1/m_t$ for all $j \\in V_t$.\n\nThe PageRank vector $\\pi^{(t)}$ is the solution to the linear system:\n$$\n\\left(I - d \\left(P^{(t)}\\right)^\\top\\right) \\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t}\n$$\nwhere $I$ is the $m_t \\times m_t$ identity matrix, $d \\in (0,1)$ is the damping factor, and $\\mathbf{1}$ is a vector of ones. This system is non-singular and has a unique, non-negative solution for $\\pi^{(t)}$, which can be found numerically using a standard linear equation solver.\n\nNext, the node $v_t$ to be removed is selected. $v_t$ is the node in $V_t$ with the highest PageRank score. Formally, $v_t$ is chosen from the set $\\arg\\max_{i \\in V_t} \\pi^{(t)}_i$. Should multiple nodes share the maximum PageRank score, the tie is broken by selecting the node with the smallest original index from the set $\\{0, 1, \\dots, n-1\\}$.\n\nFinally, the set of active nodes for the next step is updated by removing the selected node: $V_{t+1} = V_t \\setminus \\{v_t\\}$. The simulation then advances to step $t+1$. This entire procedure is repeated for each test case until the corresponding $k^\\star$ is determined.", "answer": "```python\nimport numpy as np\n\ndef get_largest_wcc_size(W, active_nodes):\n    \"\"\"\n    Computes the size of the largest weakly connected component (WCC).\n    An undirected graph is formed on the active_nodes, with an edge (i, j)\n    if W[i,j] > 0 or W[j,i] > 0.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return 0\n\n    # Map from original node index to its index in the active_nodes list (0 to m-1)\n    node_to_idx = {node: i for i, node in enumerate(active_nodes)}\n    \n    # Adjacency list for the undirected version of the subgraph\n    adj = [[] for _ in range(m)]\n    has_edges = False\n    for i in range(m):\n        for j in range(i + 1, m):\n            u, v = active_nodes[i], active_nodes[j]\n            if W[u, v] > 0 or W[v, u] > 0:\n                adj[i].append(j)\n                adj[j].append(i)\n                has_edges = True\n\n    # If no edges, all nodes are isolated components of size 1\n    if not has_edges and m > 0:\n        return 1\n\n    visited = [False] * m\n    max_size = 0\n    for i in range(m):\n        if not visited[i]:\n            current_size = 0\n            q = [i]\n            visited[i] = True\n            head = 0\n            while head < len(q):\n                u_idx = q[head]\n                head += 1\n                current_size += 1\n                for v_idx in adj[u_idx]:\n                    if not visited[v_idx]:\n                        visited[v_idx] = True\n                        q.append(v_idx)\n            max_size = max(max_size, current_size)\n    return max_size\n\ndef compute_pagerank(W_full, active_nodes, d):\n    \"\"\"\n    Computes the PageRank vector for the subgraph induced by active_nodes.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return np.array([])\n\n    # Create the submatrix of W corresponding to active nodes\n    W_sub = W_full[np.ix_(active_nodes, active_nodes)]\n    \n    # Calculate row sums for normalization\n    row_sums = W_sub.sum(axis=1)\n    \n    P = np.zeros((m, m))\n    \n    # Handle non-dangling nodes\n    non_dangling_mask = row_sums > 0\n    if np.any(non_dangling_mask):\n      P[non_dangling_mask] = W_sub[non_dangling_mask] / row_sums[non_dangling_mask, np.newaxis]\n\n    # Handle dangling nodes\n    dangling_mask = ~non_dangling_mask\n    if np.any(dangling_mask):\n        P[dangling_mask] = 1.0 / m\n        \n    # Solve the linear system (I - d*P^T) * pi = (1-d)/m * 1\n    I = np.identity(m)\n    A = I - d * P.T\n    b = (1.0 - d) / m * np.ones(m)\n    \n    pi = np.linalg.solve(A, b)\n    return pi\n\ndef solve_case(n, W, d, theta):\n    \"\"\"\n    Runs the stress-testing simulation for a single test case.\n    \"\"\"\n    active_nodes = list(range(n))\n    threshold_size = theta * n\n    \n    for t in range(n + 1):\n        # 1. Compute largest WCC size C^(t)\n        C_t = get_largest_wcc_size(W, active_nodes)\n        \n        # 2. Check failure condition\n        if C_t <= threshold_size:\n            return t\n        \n        # This part of loop is only executed if failure condition is not met\n        if len(active_nodes) == 0:\n            # Should not happen as C_t=0 would have triggered termination\n            break\n            \n        # 3. Compute PageRank\n        pi = compute_pagerank(W, active_nodes, d)\n        \n        # 4. Select node to remove\n        max_pi = -1.0\n        # Find the maximum PageRank value\n        if pi.size > 0:\n            max_pi = np.max(pi)\n\n        # Find all nodes that achieve this maximum value\n        candidates = []\n        for i, p_val in enumerate(pi):\n            if np.isclose(p_val, max_pi):\n                candidates.append(active_nodes[i])\n        \n        # Tie-break by choosing the smallest original index\n        node_to_remove = min(candidates)\n        \n        # 5. Update active set\n        active_nodes.remove(node_to_remove)\n    \n    return n\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the failure time k* for each.\n    \"\"\"\n    # Case A\n    n_A = 4\n    W_A = np.zeros((n_A, n_A))\n    W_A[1, 0] = 1\n    W_A[2, 0] = 1\n    W_A[3, 0] = 1\n    d_A = 0.85\n    theta_A = 0.5\n    \n    # Case B\n    n_B = 5\n    W_B = np.zeros((n_B, n_B))\n    edges_B = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 0)]\n    for i, j in edges_B:\n        W_B[i, j] = 1\n    d_B = 0.85\n    theta_B = 0.6\n    \n    # Case C\n    n_C = 6\n    W_C = np.ones((n_C, n_C)) - np.identity(n_C)\n    d_C = 0.9\n    theta_C = 0.5\n    \n    # Case D\n    n_D = 5\n    W_D = np.zeros((n_D, n_D))\n    edges_D = [(0, 1), (1, 0), (2, 3), (3, 4)]\n    for i, j in edges_D:\n        W_D[i, j] = 1\n    d_D = 0.85\n    theta_D = 0.8\n\n    test_cases = [\n        (n_A, W_A, d_A, theta_A),\n        (n_B, W_B, d_B, theta_B),\n        (n_C, W_C, d_C, theta_C),\n        (n_D, W_D, d_D, theta_D),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, W, d, theta = case\n        k_star = solve_case(n, W, d, theta)\n        results.append(k_star)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413880"}, {"introduction": "While many models take network structure as given, in reality, networks are formed by the strategic decisions of individual agents. This final practice dives into the fascinating world of network formation games, where the network itself is the outcome of the simulation. You will model agents who weigh the benefits of being centrally located against the costs of forming links, leading to the spontaneous emergence of a stable network structure [@problem_id:2413938]. This exercise illuminates how micro-level incentives can shape macro-level economic and social structures.", "problem": "Consider a static network formation game with a finite set of agents indexed by $N=\\{0,1,\\dots,n-1\\}$. A (simple, undirected) network is represented by a set of unordered links $G \\subseteq \\{\\{i,j\\} \\mid i,j \\in N, i \\neq j\\}$, equivalently by a symmetric adjacency matrix with entries in $\\{0,1\\}$ and zero diagonal. For any network $G$, define the shortest-path distance $d_G(i,j)$ between agents $i$ and $j$ as the minimum number of links on a path connecting $i$ and $j$; if no path exists then $d_G(i,j)=+\\infty$. The degree of agent $i$ in network $G$ is $\\deg_i(G)=|\\{j \\in N \\setminus \\{i\\} \\mid \\{i,j\\} \\in G\\}|$.\n\nEach agent $i$ receives a benefit proportional to its normalized harmonic closeness centrality and pays a linear cost per incident link. Specifically, for parameters $B>0$ and $c>0$, the utility of agent $i$ in network $G$ is\n$$\nu_i(G)=B \\cdot C_i(G)-c \\cdot \\deg_i(G),\n$$\nwhere the normalized harmonic closeness centrality is\n$$\nC_i(G)=\\frac{1}{n-1}\\sum_{\\substack{j \\in N \\\\ j \\neq i}} \\frac{1}{d_G(i,j)},\n$$\nwith the convention that if $d_G(i,j)=+\\infty$ then $\\frac{1}{d_G(i,j)}=0$.\n\nThe game evolves via myopic, pairwise-consent adjustments starting from the empty network $G=\\varnothing$ and proceeds as follows. Consider the ordered list of unordered pairs $(i,j)$ with $0 \\le i < j \\le n-1$ in lexicographic order. A deletion step allows any existing link $\\{i,j\\}\\in G$ to be removed unilaterally if it strictly increases the utility of at least one endpoint; that is, the link $\\{i,j\\}$ is deleted if $u_i(G \\setminus \\{\\{i,j\\}\\})>u_i(G)$ or $u_j(G \\setminus \\{\\{i,j\\}\\})>u_j(G)$. An addition step allows any absent link $\\{i,j\\}\\notin G$ to be added if it weakly increases the utility of both endpoints and strictly increases the utility of at least one endpoint; that is, the link $\\{i,j\\}$ is added if $u_i(G \\cup \\{\\{i,j\\}\\})\\ge u_i(G)$ and $u_j(G \\cup \\{\\{i,j\\}\\})\\ge u_j(G)$ and either $u_i(G \\cup \\{\\{i,j\\}\\})>u_i(G)$ or $u_j(G \\cup \\{\\{i,j\\}\\})>u_j(G)$. In each round, process deletions in lexicographic order, applying the first change that satisfies the stated condition (if any) and then restarting the deletion scan; when no deletion is applicable, process additions in lexicographic order, applying the first change that satisfies the stated condition (if any) and then restarting from deletions. The process terminates when a complete pass over deletions and additions yields no change. The terminal network is pairwise stable under the stated rules.\n\nYour task is to implement a program that, for each parameter triple $(n,B,c)$ in the test suite below, starts from the empty network and executes the above-described adjustment process until termination, and then returns the total number of links in the terminal network, that is, the cardinality $|G|$.\n\nTest suite:\n- Case A (happy path, dense outcome): $(n,B,c)=(4,1.0,0.1)$.\n- Case B (intermediate cost, sparse hub-and-spoke outcome): $(n,B,c)=(6,1.0,0.15)$.\n- Case C (high cost, empty outcome): $(n,B,c)=(5,1.0,0.26)$.\n- Case D (boundary condition at deletion indifference for complete network with $n=5$): $(n,B,c)=(5,1.0,0.125)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets, in the same order as the test suite. For example, the output should look like $[x_A,x_B,x_C,x_D]$, where $x_A=|G|$ for Case A, $x_B=|G|$ for Case B, $x_C=|G|$ for Case C, and $x_D=|G|$ for Case D.", "solution": "The problem requires the simulation of a myopic, pairwise-consent network formation game to find the number of links in the terminal, stable network for several sets of parameters. The validation of the problem statement confirms that it is scientifically grounded in the economic theory of network formation, well-posed, objective, and algorithmically specified in sufficient detail to permit a unique solution. We may therefore proceed with the design and implementation of a computational solution.\n\nThe core of the solution is a deterministic simulation that adheres strictly to the evolutionary dynamics described. Our implementation is structured around the following components:\n\n**1. Network Representation**\nA network $G$ with $n$ agents is represented by an $n \\times n$ symmetric adjacency matrix, denoted also by $G$, where $G_{ij} = 1$ if a link $\\{i,j\\}$ exists, and $G_{ij} = 0$ otherwise. The diagonal entries are always $0$.\n\n**2. Supporting Computations**\nBefore evaluating agent utilities, two primary quantities must be computed from the current network $G$:\n\n- **All-Pairs Shortest Paths (APSP):** The matrix of shortest-path distances, $D$, where $D_{ij} = d_G(i,j)$, is fundamental. We compute this using the Floyd-Warshall algorithm, which is efficiently implemented in the `scipy.sparse.csgraph.shortest_path` function. This function correctly handles disconnected components by assigning an infinite distance.\n\n- **Agent Utility:** For each agent $i \\in N$, its utility $u_i(G)$ is calculated according to the specified formula:\n$$u_i(G) = B \\cdot C_i(G) - c \\cdot \\deg_i(G)$$\nThe degree, $\\deg_i(G) = \\sum_{j=0}^{n-1} G_{ij}$, is the sum of the $i$-th row of the adjacency matrix. The normalized harmonic closeness centrality, $C_i(G)$, is computed as:\n$$C_i(G) = \\frac{1}{n-1}\\sum_{j \\in N, j \\neq i} \\frac{1}{d_G(i,j)}$$\nThis is calculated using the pre-computed APSP matrix $D$. The convention $\\frac{1}{+\\infty} = 0$ is naturally handled by floating-point arithmetic.\n\n**3. Simulation of Network Dynamics**\nThe simulation starts with the empty network $G=\\varnothing$ and proceeds iteratively until a stable state is reached. The process is governed by a main loop that continues as long as any change is made to the network in a full round of deletions and additions.\n\n- **Lexicographic Ordering:** All potential links $\\{i,j\\}$ are considered in lexicographic order of the pair $(i,j)$ where $0 \\le i < j \\le n-1$. This ordered list is pre-computed.\n\n- **Deletion Phase:** The algorithm first attempts to delete links. It enters a sub-loop that scans through all currently existing links. For the first link found that satisfies the deletion criterion—that is, its removal strictly increases the utility of at least one of its endpoints ($u_k(G \\setminus \\{\\{i,j\\}\\}) > u_k(G)$ for $k=i$ or $k=j$)—the link is removed, and the deletion scan is immediately restarted from the beginning of the pair list. This phase completes only when a full scan over all existing links yields no deletions.\n\n- **Addition Phase:** If and only if the deletion phase concludes with no changes, the algorithm proceeds to the addition phase. It performs a single scan through all absent links. The first link found that satisfies the pairwise-consent criterion—that is, its addition weakly increases the utility of both endpoints and strictly increases it for at least one ($u_k(G \\cup \\{\\{i,j\\}\\}) \\ge u_k(G)$ for $k \\in \\{i,j\\}$ and strict inequality for at least one $k$)—is added to the network.\n\n- **Restart and Termination:** If a link is added, the entire process restarts from the deletion phase on the newly modified network. The simulation terminates when a full pass through the deletion phase and the subsequent addition phase results in no modifications to the network structure. The resulting network is pairwise stable under the specified rules.\n\n**4. Final Result**\nFor each parameter triple $(n,B,c)$ provided in the test suite, the simulation is executed, and the total number of links, $|G| = \\frac{1}{2} \\sum_{i,j} G_{ij}$, in the terminal network is calculated and stored. The final output aggregates these results into a single list.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import shortest_path\n\ndef calculate_utility(agent_idx, adj_matrix, B, c, n, distances):\n    \"\"\"Calculates the utility for a single agent.\"\"\"\n    degree = np.sum(adj_matrix[agent_idx])\n    \n    dist_row = distances[agent_idx]\n    \n    # The sum is over j != agent_idx.\n    # We handle division by zero (for d(i,i)=0) and infinity cleanly.\n    with np.errstate(divide='ignore'):\n        inv_distances = 1.0 / dist_row\n    \n    inv_distances[np.isinf(inv_distances)] = 0.0\n    inv_distances[agent_idx] = 0.0 # Exclude self from sum\n    \n    # n-1 is always positive for n>1\n    closeness = np.sum(inv_distances) / (n - 1)\n    \n    utility = B * closeness - c * degree\n    return utility\n\ndef run_simulation(n, B, c):\n    \"\"\"\n    Runs the network formation simulation for a given set of parameters.\n    \"\"\"\n    adj = np.zeros((n, n), dtype=np.int8)\n    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n\n    while True:\n        network_changed_in_round = False\n\n        # --- Deletion Phase ---\n        # A deletion restarts the deletion scan. This is handled by the inner while loop.\n        while True:\n            deletion_made_in_scan = False\n            \n            # Pre-calculate current utilities before scanning for deletions\n            current_distances = shortest_path(csgraph=adj, directed=False)\n            current_utilities = {k: calculate_utility(k, adj, B, c, n, current_distances) for k in range(n)}\n            \n            for i, j in pairs:\n                if adj[i, j] == 1:\n                    # Tentatively delete the link\n                    adj[i, j] = adj[j, i] = 0\n                    \n                    new_distances = shortest_path(csgraph=adj, directed=False)\n                    util_i_new = calculate_utility(i, adj, B, c, n, new_distances)\n                    util_j_new = calculate_utility(j, adj, B, c, n, new_distances)\n                    \n                    # Check deletion condition (strict unilateral improvement)\n                    if util_i_new > current_utilities[i] or util_j_new > current_utilities[j]:\n                        # Deletion is confirmed. The adj matrix is already updated.\n                        network_changed_in_round = True\n                        deletion_made_in_scan = True\n                        break  # Restart deletion scan\n                    else:\n                        # Revert the deletion\n                        adj[i, j] = adj[j, i] = 1\n            \n            if not deletion_made_in_scan:\n                break # Exit deletion phase sub-loop\n\n        # --- Addition Phase ---\n        # An addition restarts the entire process, starting from deletions.\n        # This is handled by the outer while loop.\n        addition_made_in_scan = False\n        \n        # Pre-calculate current utilities before scanning for additions\n        current_distances = shortest_path(csgraph=adj, directed=False)\n        current_utilities = {k: calculate_utility(k, adj, B, c, n, current_distances) for k in range(n)}\n        \n        for i, j in pairs:\n            if adj[i, j] == 0:\n                # Tentatively add the link\n                adj[i, j] = adj[j, i] = 1\n                \n                new_distances = shortest_path(csgraph=adj, directed=False)\n                util_i_new = calculate_utility(i, adj, B, c, n, new_distances)\n                util_j_new = calculate_utility(j, adj, B, c, n, new_distances)\n\n                # Check addition condition (weak bilateral improvement, strict for at least one)\n                if (util_i_new >= current_utilities[i] and util_j_new >= current_utilities[j]) and \\\n                   (util_i_new > current_utilities[i] or util_j_new > current_utilities[j]):\n                    # Addition is confirmed. The adj matrix is already updated.\n                    network_changed_in_round = True\n                    addition_made_in_scan = True\n                    break # Restart entire process from deletions\n                else:\n                    # Revert the addition\n                    adj[i, j] = adj[j, i] = 0\n\n        # --- Termination Check ---\n        if not network_changed_in_round:\n            break # Stable network found\n\n    return int(np.sum(adj) // 2)\n\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        (4, 1.0, 0.1),    # Case A\n        (6, 1.0, 0.15),   # Case B\n        (5, 1.0, 0.26),   # Case C\n        (5, 1.0, 0.125),  # Case D\n    ]\n\n    results = []\n    for params in test_cases:\n        n, B, c = params\n        num_links = run_simulation(n, B, c)\n        results.append(num_links)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413938"}]}