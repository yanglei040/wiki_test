{"hands_on_practices": [{"introduction": "Let's begin with a cornerstone of modern finance: determining the optimal way to consume and invest over a lifetime. This exercise walks you through solving the classic Merton portfolio problem, where the goal is to maximize utility from consumption in a world with one risky and one risk-free asset. By applying the Hamilton-Jacobi-Bellman (HJB) equation, you will derive the famous constant-proportion investment and consumption rules, providing a concrete, computational application of the theory [@problem_id:2414704].", "problem": "Consider an infinite-horizon continuous-time consumption-investment problem. A single representative investor with wealth $w(t)$ chooses at each instant $t \\ge 0$ a nonnegative consumption rate $c(t) \\ge 0$ and a portfolio share $\\theta(t) \\in \\mathbb{R}$ allocated to a risky asset (the remainder is held in a risk-free asset). The risk-free asset earns a constant interest rate $r \\in \\mathbb{R}$, and the risky asset has constant expected return $\\mu \\in \\mathbb{R}$ and volatility $\\sigma &gt; 0$. The investor has Constant Relative Risk Aversion (CRRA) preferences with relative risk aversion parameter $\\gamma > 0$, $\\gamma \\ne 1$, and subjective discount rate $\\rho > 0$. The instantaneous utility of consumption is $u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}$. The wealth process evolves according to the Itô stochastic differential equation\n$$\ndw(t) = \\big((r + \\theta(t)(\\mu - r))\\,w(t) - c(t)\\big)\\,dt + \\theta(t)\\,\\sigma\\,w(t)\\,dB(t),\n$$\nwhere $B(t)$ is a standard Brownian motion. Let $V(w)$ denote the value function. The Hamilton-Jacobi-Bellman (HJB) equation for this problem is\n$$\n0 = \\sup_{c \\ge 0,\\ \\theta \\in \\mathbb{R}} \\left\\{ \\frac{c^{1-\\gamma}}{1-\\gamma} + V'(w)\\big((r + \\theta(\\mu - r))\\,w - c\\big) + \\frac{1}{2} V''(w)\\,\\theta^2 \\sigma^2 w^2 - \\rho V(w) \\right\\}.\n$$\n\nAssume the primitives $(r,\\mu,\\sigma,\\rho,\\gamma)$ are time-invariant, and the optimal policies are stationary and homogeneous in wealth. Define the optimal consumption-wealth ratio $k^\\star := \\frac{c^\\star}{w}$ and the optimal risky share $\\theta^\\star$. For each parameter set below, compute the pair $(k^\\star,\\theta^\\star)$ implied by the HJB optimality conditions, expressed as real numbers. Your program should return the results in the order of the test suite.\n\nTest suite (each tuple is $(\\rho,\\gamma,r,\\mu,\\sigma)$):\n- Test 1: $(0.05,\\,2.0,\\,0.02,\\,0.06,\\,0.2)$\n- Test 2: $(0.04,\\,3.0,\\,0.02,\\,0.02,\\,0.25)$\n- Test 3: $(0.06,\\,0.5,\\,0.01,\\,0.07,\\,0.3)$\n- Test 4: $(0.04,\\,10.0,\\,0.03,\\,0.05,\\,0.2)$\n\nAnswer requirements:\n- For each test, output a list $[k^\\star,\\theta^\\star]$ with both entries rounded to exactly $6$ decimal places.\n- Aggregate the results for all tests into a single line formatted as a comma-separated list enclosed in square brackets. For example, the overall output format must be $[[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4]]$ with each $a_i$ and $b_i$ real numbers rounded to $6$ decimals.", "solution": "The user has presented a problem from continuous-time finance, specifically the Merton's portfolio problem. My task is to validate its scientific and mathematical integrity and, if valid, to derive the solution and implement it computationally.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n-   **Investor Objective**: Maximize expected lifetime utility from consumption.\n-   **Horizon**: Infinite, continuous-time $t \\in [0, \\infty)$.\n-   **State Variable**: Wealth $w(t)$.\n-   **Control Variables**: Consumption rate $c(t) \\ge 0$, portfolio share in risky asset $\\theta(t) \\in \\mathbb{R}$.\n-   **Assets**:\n    -   Risk-free asset with constant rate $r \\in \\mathbb{R}$.\n    -   Risky asset with constant expected return $\\mu \\in \\mathbb{R}$ and volatility $\\sigma > 0$.\n-   **Wealth Dynamics (SDE)**: $dw(t) = \\big((r + \\theta(t)(\\mu - r))\\,w(t) - c(t)\\big)\\,dt + \\theta(t)\\,\\sigma\\,w(t)\\,dB(t)$.\n-   **Preferences**: Constant Relative Risk Aversion (CRRA) utility $u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}$, with relative risk aversion $\\gamma > 0, \\gamma \\ne 1$ and subjective discount rate $\\rho > 0$.\n-   **Value Function and HJB Equation**: The value function is denoted by $V(w)$, and its governing Hamilton-Jacobi-Bellman (HJB) equation is:\n    $$\n    0 = \\sup_{c \\ge 0,\\ \\theta \\in \\mathbb{R}} \\left\\{ \\frac{c^{1-\\gamma}}{1-\\gamma} + V'(w)\\big((r + \\theta(\\mu - r))\\,w - c\\big) + \\frac{1}{2} V''(w)\\,\\theta^2 \\sigma^2 w^2 - \\rho V(w) \\right\\}\n    $$\n-   **Solution Form**: The optimal policies are assumed to be stationary and homogeneous, defining the optimal consumption-wealth ratio $k^\\star := \\frac{c^\\star}{w}$ and the optimal risky share $\\theta^\\star$.\n-   **Test Suite**: A set of four parameter tuples $(\\rho,\\gamma,r,\\mu,\\sigma)$ is provided for computation.\n    -   Test 1: $(0.05,\\,2.0,\\,0.02,\\,0.06,\\,0.2)$\n    -   Test 2: $(0.04,\\,3.0,\\,0.02,\\,0.02,\\,0.25)$\n    -   Test 3: $(0.06,\\,0.5,\\,0.01,\\,0.07,\\,0.3)$\n    -   Test 4: $(0.04,\\,10.0,\\,0.03,\\,0.05,\\,0.2)$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation.\n-   **Scientific Grounding**: The problem is a classic formulation of Merton's portfolio problem, a foundational model in financial economics. It is firmly based on the principles of stochastic calculus, optimal control theory, and microeconomic utility theory. It is scientifically sound.\n-   **Well-Posedness**: The problem is well-posed. For the given CRRA utility function and linear asset dynamics, a unique and stable solution for the optimal controls is known to exist, provided certain transversality conditions are met (which is implicitly assumed).\n-   **Objectivity**: The problem is stated using precise mathematical language, free of any subjective or ambiguous terminology.\n-   **Completeness and Consistency**: All necessary parameters and functional forms are provided. There are no internal contradictions.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is a standard, well-defined problem in mathematical finance. I will now proceed with a full solution.\n\n### Principle-Based Solution Derivation\n\nThe solution is found by solving the HJB equation for the optimal control variables $c$ and $\\theta$. This is achieved by applying the first-order conditions (FOCs) for maximization to the term inside the supremum.\n\n1.  **First-Order Conditions (FOCs)**:\n    We take the partial derivatives of the Hamiltonian with respect to $c$ and $\\theta$ and set them to zero.\n\n    FOC with respect to consumption $c$:\n    $$ \\frac{\\partial}{\\partial c} \\left( \\frac{c^{1-\\gamma}}{1-\\gamma} - V'(w)c \\right) = c^{-\\gamma} - V'(w) = 0 $$\n    $$ \\implies c^\\star(w) = (V'(w))^{-1/\\gamma} $$\n\n    FOC with respect to risky share $\\theta$:\n    $$ \\frac{\\partial}{\\partial \\theta} \\left( V'(w)\\theta(\\mu-r)w + \\frac{1}{2}V''(w)\\theta^2\\sigma^2w^2 \\right) = V'(w)(\\mu-r)w + V''(w)\\theta\\sigma^2w^2 = 0 $$\n    $$ \\implies \\theta^\\star(w) = -\\frac{V'(w)(\\mu-r)w}{V''(w)\\sigma^2w^2} = -\\frac{\\mu-r}{\\sigma^2w} \\frac{V'(w)}{V''(w)} $$\n    The second-order condition requires $V''(w) < 0$, confirming the value function must be concave, which is consistent with risk aversion.\n\n2.  **Value Function Ansatz**:\n    Given the CRRA utility and the scale-invariant nature of the problem, we conjecture a solution for the value function of the form:\n    $$ V(w) = A \\frac{w^{1-\\gamma}}{1-\\gamma} $$\n    for some constant $A > 0$. The derivatives are:\n    $$ V'(w) = A w^{-\\gamma} $$\n    $$ V''(w) = -\\gamma A w^{-\\gamma - 1} $$\n\n3.  **Solving for Optimal Controls**:\n    Substitute the derivatives of the value function into the FOCs for $c^\\star$ and $\\theta^\\star$.\n\n    For the optimal consumption-wealth ratio $k^\\star$:\n    $$ c^\\star(w) = (A w^{-\\gamma})^{-1/\\gamma} = A^{-1/\\gamma}w $$\n    The optimal consumption is a constant fraction of wealth. We define this fraction as $k^\\star$:\n    $$ k^\\star = \\frac{c^\\star}{w} = A^{-1/\\gamma} $$\n\n    For the optimal risky share $\\theta^\\star$:\n    $$ \\theta^\\star = -\\frac{\\mu-r}{\\sigma^2w} \\frac{A w^{-\\gamma}}{-\\gamma A w^{-\\gamma - 1}} = \\frac{\\mu-r}{\\gamma\\sigma^2w} \\frac{w^{-\\gamma}}{w^{-\\gamma-1}} = \\frac{\\mu-r}{\\gamma\\sigma^2w} w = \\frac{\\mu-r}{\\gamma\\sigma^2} $$\n    The optimal risky share $\\theta^\\star$ is a constant, independent of wealth.\n\n4.  **Solving the HJB Equation**:\n    Substitute the optimal controls ($c^\\star = k^\\star w$, $\\theta^\\star$) and the value function ansatz into the HJB equation. After optimization, the HJB is:\n    $$ \\rho V(w) = \\frac{(c^\\star)^{1-\\gamma}}{1-\\gamma} + V'(w)\\left[(r + \\theta^\\star(\\mu-r))w - c^\\star\\right] + \\frac{1}{2}V''(w)(\\theta^\\star)^2\\sigma^2w^2 $$\n    The terms related to the optimal investment portfolio simplify to:\n    $$ V'(w)(r + \\theta^\\star(\\mu-r))w + \\frac{1}{2}V''(w)(\\theta^\\star)^2\\sigma^2w^2 = V'(w)w \\left( r + \\frac{(\\mu-r)^2}{2\\gamma\\sigma^2} \\right) $$\n    The terms related to consumption simplify to:\n    $$ \\frac{(c^\\star)^{1-\\gamma}}{1-\\gamma} - V'(w)c^\\star = \\frac{(k^\\star w)^{1-\\gamma}}{1-\\gamma} - (Aw^{-\\gamma})(k^\\star w) = \\frac{(A^{-1/\\gamma}w)^{1-\\gamma}}{1-\\gamma} - A k^\\star w^{1-\\gamma} $$\n    $$ = \\frac{A^{-(1-\\gamma)/\\gamma}w^{1-\\gamma}}{1-\\gamma} - A (A^{-1/\\gamma}) w^{1-\\gamma} = \\frac{A^{-1/\\gamma} A w^{1-\\gamma}}{1-\\gamma} - A^{1-1/\\gamma} w^{1-\\gamma} = A^{1-1/\\gamma}w^{1-\\gamma}\\left(\\frac{1}{1-\\gamma} - 1\\right) = A^{1-1/\\gamma}w^{1-\\gamma}\\frac{\\gamma}{1-\\gamma} $$\n    Using $k^\\star = A^{-1/\\gamma}$, this is $k^\\star A w^{1-\\gamma} \\frac{\\gamma}{1-\\gamma}$.\n\n    The full HJB equation becomes:\n    $$ \\rho A \\frac{w^{1-\\gamma}}{1-\\gamma} = k^\\star A w^{1-\\gamma} \\frac{\\gamma}{1-\\gamma} + A w^{1-\\gamma} \\left( r + \\frac{(\\mu-r)^2}{2\\gamma\\sigma^2} \\right) $$\n    Divide by $A w^{1-\\gamma}$:\n    $$ \\frac{\\rho}{1-\\gamma} = \\frac{k^\\star \\gamma}{1-\\gamma} + r + \\frac{(\\mu-r)^2}{2\\gamma\\sigma^2} $$\n    Multiply by $(1-\\gamma)$:\n    $$ \\rho = k^\\star \\gamma + (1-\\gamma)\\left( r + \\frac{(\\mu-r)^2}{2\\gamma\\sigma^2} \\right) $$\n    Now, solve for $k^\\star$:\n    $$ k^\\star \\gamma = \\rho - (1-\\gamma)r - \\frac{(1-\\gamma)(\\mu-r)^2}{2\\gamma\\sigma^2} $$\n    $$ k^\\star = \\frac{1}{\\gamma}\\left[ \\rho - (1-\\gamma)r - \\frac{(1-\\gamma)(\\mu-r)^2}{2\\gamma\\sigma^2} \\right] $$\n\n5.  **Final Formulas for Computation**:\n    The optimal constant risky share is:\n    $$ \\theta^\\star = \\frac{\\mu - r}{\\gamma \\sigma^2} $$\n    The optimal constant consumption-wealth ratio is:\n    $$ k^\\star = \\frac{1}{\\gamma}\\left[ \\rho - (1-\\gamma)r - \\frac{(1-\\gamma)(\\mu-r)^2}{2\\gamma\\sigma^2} \\right] $$\n    These formulas are now applied to each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the optimal consumption-wealth ratio (k_star) and\n    risky asset share (theta_star) in the Merton's portfolio problem\n    for a given set of parameters.\n    \"\"\"\n    \n    # Test suite: each tuple is (rho, gamma, r, mu, sigma)\n    test_cases = [\n        (0.05, 2.0, 0.02, 0.06, 0.2),   # Test 1\n        (0.04, 3.0, 0.02, 0.02, 0.25),  # Test 2\n        (0.06, 0.5, 0.01, 0.07, 0.3),   # Test 3\n        (0.04, 10.0, 0.03, 0.05, 0.2),  # Test 4\n    ]\n\n    results = []\n    for case in test_cases:\n        rho, gamma, r, mu, sigma = case\n\n        # Ensure parameters are floats for precision\n        rho, gamma, r, mu, sigma = float(rho), float(gamma), float(r), float(mu), float(sigma)\n\n        # Calculate the optimal risky share theta_star\n        # theta_star = (mu - r) / (gamma * sigma^2)\n        try:\n            theta_star = (mu - r) / (gamma * sigma**2)\n        except ZeroDivisionError:\n            # Handle cases where sigma or gamma are zero, although problem constraints are > 0\n            theta_star = float('nan')\n\n        # Calculate the optimal consumption-wealth ratio k_star\n        # k_star = (1/gamma) * [rho - (1-gamma)*r - ((1-gamma)*(mu-r)^2) / (2*gamma*sigma^2)]\n        mu_minus_r_sq = (mu - r)**2\n        try:\n            term3 = (1 - gamma) * mu_minus_r_sq / (2 * gamma * sigma**2)\n            k_star = (1 / gamma) * (rho - (1 - gamma) * r - term3)\n        except ZeroDivisionError:\n            k_star = float('nan')\n\n        # The problem asks for the pair [k_star, theta_star]\n        results.append([k_star, theta_star])\n\n    # Format the final output string exactly as required.\n    # Each number is rounded to exactly 6 decimal places.\n    formatted_results = []\n    for k, t in results:\n        formatted_results.append(f\"[{k:.6f},{t:.6f}]\")\n    \n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "2414704"}, {"introduction": "Optimal control models gain realism when we introduce constraints, such as the inability to borrow against future income. This thought experiment challenges you to correctly formulate the HJB equation for a consumption-saving problem with a hard borrowing constraint, an important feature of many economic models. Understanding how to handle such state-space boundaries is a critical skill, as it requires modifying the agent's choices at the boundary to ensure the constraints are never violated [@problem_id:2416539].", "problem": "Consider a continuous-time consumption-saving problem with a borrowing constraint in which an agent chooses measurable consumption $c_t \\ge 0$ to maximize the discounted utility\n$$\\int_0^{\\infty} e^{-\\rho t} u(c_t) \\, dt,$$\nwhere $u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}$ for $\\gamma > 0$, $\\gamma \\ne 1$, and $\\rho > 0$. Wealth $x_t$ evolves according to\n$$\\dot{x}_t = r x_t + y - c_t,$$\nwith $x_0 = \\bar{x} \\ge 0$, constant interest rate $r \\ge 0$, and constant income flow $y \\ge 0$. The borrowing constraint requires $x_t \\ge 0$ for all $t \\ge 0$. Let $V(x)$ denote the value function. Using the principle of optimality and the Hamilton-Jacobi-Bellman (HJB) framework, which of the following correctly characterizes the HJB equation in the interior $x > 0$ together with the appropriate boundary condition at the state-constraint boundary $x = 0$?\n\nA. For all $x > 0$,\n$$\\rho V(x) = \\max_{c \\ge 0} \\left\\{ u(c) + V_x(x)\\,(r x + y - c) \\right\\},$$\nand at $x = 0$,\n$$\\rho V(0) = \\max_{0 \\le c \\le y} \\left\\{ u(c) + V_x(0)\\,(y - c) \\right\\}.$$\n\nB. For all $x > 0$,\n$$\\rho V(x) = \\max_{c \\ge 0} \\left\\{ u(c) + V_x(x)\\,(r x + y - c) \\right\\},$$\nand the state-constraint induces a Neumann boundary condition $V_x(0) = u'(y)$.\n\nC. For all $x > 0$,\n$$\\rho V(x) = \\max_{c \\ge 0} \\left\\{ u(c) + V_x(x)\\,(r x + y - c) \\right\\},$$\nand the boundary condition at $x = 0$ is Dirichlet with fixed value\n$$V(0) = \\int_0^{\\infty} e^{-\\rho t} u(y)\\, dt = \\frac{u(y)}{\\rho}.$$\n\nD. The borrowing constraint appears in the HJB through a Lagrange multiplier $\\lambda \\ge 0$ so that, for all $x \\ge 0$,\n$$\\rho V(x) = \\max_{c \\ge 0,\\, \\lambda \\ge 0} \\left\\{ u(c) + V_x(x)\\,(r x + y - c) + \\lambda\\, x \\right\\}, \\quad \\lambda\\, x = 0.$$\n\nE. For all $x > 0$,\n$$\\rho V(x) = \\max_{c \\ge 0} \\left\\{ u(c) + V_x(x)\\,(r x + y - c) \\right\\},$$\nand at $x = 0$ the state-constraint boundary condition is the inequality\n$$\\rho V(0) \\ge \\max_{c \\ge 0} \\left\\{ u(c) + V_x(0)\\,(y - c) \\right\\},$$\nwith no restriction on $c$ at $x = 0$.", "solution": "We start from first principles. The problem is an infinite-horizon deterministic control problem with state $x_t$ and control $c_t$. The objective is\n$$\\max_{c_{\\cdot} \\ge 0} \\int_0^{\\infty} e^{-\\rho t} u(c_t)\\, dt,$$\nsubject to the law of motion\n$$\\dot{x}_t = r x_t + y - c_t, \\quad x_0 = \\bar{x} \\ge 0,$$\nand the state constraint\n$$x_t \\ge 0 \\quad \\text{for all } t \\ge 0.$$\n\nBy the dynamic programming principle, if $V(x)$ denotes the value function, then for small $\\Delta > 0$ and admissible controls over $[0,\\Delta)$,\n$$V(x) = \\max_{c \\in \\mathcal{A}(x)} \\left\\{ \\int_0^{\\Delta} e^{-\\rho t} u(c)\\, dt + e^{-\\rho \\Delta} V\\left(x + \\Delta \\cdot (r x + y - c) + o(\\Delta)\\right) \\right\\},$$\nwhere $\\mathcal{A}(x)$ denotes the set of controls that keep the state feasible over the interval $[0,\\Delta)$ beginning at $x$. Using a first-order expansion and dividing by $\\Delta$, letting $\\Delta \\to 0$, we obtain the Hamilton-Jacobi-Bellman equation\n$$\\rho V(x) = \\max_{c \\in \\mathcal{A}(x)} \\left\\{ u(c) + V_x(x)\\,(r x + y - c) \\right\\}.$$\n\nThe key is to characterize $\\mathcal{A}(x)$:\n- For interior states $x > 0$, feasibility in an infinitesimal interval does not restrict $c$ beyond $c \\ge 0$, so $\\mathcal{A}(x) = \\{ c \\in \\mathbb{R}_+ \\}$.\n- At the boundary $x = 0$, the state constraint requires that the instantaneous drift cannot point outward from the feasible set. Specifically, to avoid violating $x_t \\ge 0$ immediately, we must have $\\dot{x}_t \\ge 0$ at $x = 0$. Therefore, admissible controls at $x = 0$ satisfy\n$$r \\cdot 0 + y - c \\ge 0 \\quad \\Longleftrightarrow \\quad 0 \\le c \\le y.$$\nThus $\\mathcal{A}(0) = [0,y]$.\n\nHence, the correct HJB and boundary characterization are:\n- For all $x > 0$,\n$$\\rho V(x) = \\max_{c \\ge 0} \\left\\{ u(c) + V_x(x)\\,(r x + y - c) \\right\\}.$$\n- At $x = 0$,\n$$\\rho V(0) = \\max_{0 \\le c \\le y} \\left\\{ u(c) + V_x(0)\\,(y - c) \\right\\}.$$\n\nThis matches Option A. Next, we evaluate each option.\n\nOption A: This matches the derivation. The interior HJB uses the unrestricted nonnegativity constraint on $c$, and the boundary condition uses the state-constraint restriction $0 \\le c \\le y$ to prevent immediate exit from the feasible set. Equality holds because the dynamic programming principle applies with the admissible control set adapted to the state. Verdict — Correct.\n\nOption B: It posits $V_x(0) = u'(y)$. This condition would arise only if the optimizer at $x = 0$ chooses $c = y$ as an interior maximizer of $u(c) + V_x(0) (y - c)$, which requires $u'(y) = V_x(0)$ and that $c = y$ is not at a corner. However, whether $c = y$ is optimal at $x = 0$ depends on parameters and the shape of $V$; in general, the optimal choice at the boundary may be $c < y$ to move into the interior (saving) or $c = y$ to remain at the boundary, determined endogenously by $V_x(0)$. Therefore, imposing $V_x(0) = u'(y)$ as a boundary condition is not generally valid. Verdict — Incorrect.\n\nOption C: It fixes $V(0) = \\frac{u(y)}{\\rho}$, which is the value obtained by holding $c_t \\equiv y$ forever. This is not generally optimal under the borrowing constraint; the agent may choose $c_t < y$ for some time to accumulate assets (since $r \\ge 0$) and then consume more later, potentially achieving a higher value than $\\frac{u(y)}{\\rho}$. Conversely, parameter configurations could make $c_t \\equiv y$ optimal. In either case, one cannot a priori impose a Dirichlet boundary value independent of $V_x(0)$. Verdict — Incorrect.\n\nOption D: It introduces the state constraint via a Lagrange multiplier $\\lambda$ in the HJB and includes the complementarity condition $\\lambda x = 0$. In dynamic programming, state constraints are enforced by restricting the admissible control set as a function of the state, not by adding multipliers times the state to the HJB integrand. The term $\\lambda x$ and $\\lambda x = 0$ do not correctly encode the instantaneous feasibility requirement at the boundary; instead, one must restrict $c$ so that the drift points inward when $x = 0$. Verdict — Incorrect.\n\nOption E: It uses an inequality at $x = 0$ but allows maximization over $c \\ge 0$ without the essential restriction $c \\le y$. Allowing $c > y$ at $x = 0$ would imply an outward-pointing drift $\\dot{x} = y - c < 0$, which immediately violates feasibility. The correct admissible set at $x = 0$ is $[0,y]$, and with the dynamic programming principle the equation at the boundary holds with equality using that restricted set. Verdict — Incorrect.\n\nTherefore, the correct choice is Option A.", "answer": "$$\\boxed{A}$$", "id": "2416539"}, {"introduction": "The power of the HJB framework extends far beyond finance, applicable to any problem involving optimal choices over time. In this exercise, we apply these methods to a relatable scenario: a student deciding how to allocate limited study time between two subjects to maximize their final GPA. This problem's linear structure beautifully illustrates how the HJB equation can yield different types of optimal policies, such as \"bang-bang\" controls, and reveals the conditions under which uncertainty becomes irrelevant to the optimal plan [@problem_id:2416576].", "problem": "Consider a student who allocates continuous study time between two subjects, indexed by $i \\in \\{1,2\\}$, over a fixed horizon $[0,T]$. Let $X_i(t)$ denote the student’s understanding in subject $i$ at time $t$, and let $u(t) \\in [0,1]$ denote the fraction of instantaneous study effort devoted to subject $1$ at time $t$ (so subject $2$ receives $1-u(t)$). The dynamics of understanding are modeled as controlled Itô processes\n$$\n\\mathrm{d}X_1(t) = \\left(-b_1 X_1(t) + a_1 u(t)\\right)\\mathrm{d}t + \\sigma_1 \\mathrm{d}W_1(t), \\quad\n\\mathrm{d}X_2(t) = \\left(-b_2 X_2(t) + a_2 \\left(1 - u(t)\\right)\\right)\\mathrm{d}t + \\sigma_2 \\mathrm{d}W_2(t),\n$$\nwhere $W_1(t)$ and $W_2(t)$ are independent standard Brownian motions, $a_1,a_2 \\ge 0$ are learning productivity coefficients, $b_1,b_2 \\ge 0$ are forgetting rates, and $\\sigma_1,\\sigma_2 \\ge 0$ are volatility parameters. The terminal Grade Point Average (GPA) proxy is modeled as a linear payoff\n$$\nG = \\varphi_1 X_1(T) + \\varphi_2 X_2(T),\n$$\nwith weights $\\varphi_1,\\varphi_2 > 0$. The objective is to choose an admissible control $u(\\cdot)$, measurable and adapted to the filtration generated by $(W_1,W_2)$, to maximize the expected terminal GPA $\\mathbb{E}[G]$.\n\nYour task is to write a complete, runnable program that, for each parameter set below, computes the optimal expected terminal GPA $\\sup_{u(\\cdot)\\in[0,1]} \\mathbb{E}[G]$ given the initial state $(X_1(0),X_2(0)) = (x_{10},x_{20})$. Angles do not appear, and there are no physical units; report all numerical answers as floating-point numbers.\n\nUse the following test suite of parameter values. For each test case $k$, the parameters are ordered as\n$(a_1,a_2,b_1,b_2,\\sigma_1,\\sigma_2,\\varphi_1,\\varphi_2,T,x_{10},x_{20})$:\n\n- Test 1 (general case): $(1.0,0.8,0.2,0.3,0.3,0.2,2.0,1.5,2.0,0.5,0.7)$.\n- Test 2 (boundary, zero horizon): $(1.0,1.2,0.1,0.3,0.0,0.0,1.0,1.0,0.0,1.0,2.0)$.\n- Test 3 (tie in marginal effectiveness, identical decay): $(1.0,0.4,0.5,0.5,0.5,0.1,1.0,2.5,3.0,0.0,0.0)$.\n- Test 4 (interior switching in optimal allocation): $(1.0,1.0,0.2,1.0,0.2,0.4,1.0,2.0,2.0,0.0,0.0)$.\n- Test 5 (zero learning in one subject and zero decay in the other): $(0.0,1.0,0.3,0.0,0.7,0.5,1.0,1.0,1.5,0.2,0.1)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[3.141593,2.718282]$), where the $k$-th entry is the optimal expected terminal GPA for Test $k$, each reported as a floating-point number rounded to six decimal places.", "solution": "The problem statement is subjected to validation prior to any attempt at a solution.\n\nStep 1: Extract Givens\n- State variables: $X_1(t)$, $X_2(t)$.\n- Control variable: $u(t) \\in [0,1]$.\n- State dynamics:\n$$\n\\mathrm{d}X_1(t) = \\left(-b_1 X_1(t) + a_1 u(t)\\right)\\mathrm{d}t + \\sigma_1 \\mathrm{d}W_1(t)\n$$\n$$\n\\mathrm{d}X_2(t) = \\left(-b_2 X_2(t) + a_2 \\left(1 - u(t)\\right)\\right)\\mathrm{d}t + \\sigma_2 \\mathrm{d}W_2(t)\n$$\n- $W_1(t), W_2(t)$ are independent standard Brownian motions.\n- Parameters: $a_1, a_2, b_1, b_2, \\sigma_1, \\sigma_2 \\ge 0$, $\\varphi_1, \\varphi_2 > 0$.\n- Time horizon: $[0, T]$.\n- Terminal payoff: $G = \\varphi_1 X_1(T) + \\varphi_2 X_2(T)$.\n- Objective: Maximize $\\mathbb{E}[G]$.\n- Initial state: $(X_1(0), X_2(0)) = (x_{10}, x_{20})$.\n- Test cases: Five distinct parameter sets are provided.\n\nStep 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is a standard stochastic optimal control problem with linear dynamics (controlled Ornstein-Uhlenbeck processes) and a linear objective function. This is a well-established model in financial engineering and economics, known as a Merton-type problem. It is mathematically and scientifically sound.\n- **Well-Posed**: The problem is well-posed. The dynamics are linear, the objective is linear, and the control is constrained to a compact set. Standard existence and uniqueness theorems for such problems apply. The Hamilton-Jacobi-Bellman (HJB) framework is directly applicable.\n- **Objective**: The problem is stated with precise mathematical definitions and without ambiguity or subjective content.\n- **Flaw Analysis**: The problem does not violate any fundamental principles, is not metaphorical, is complete and consistent, is not physically infeasible, is well-structured, and is scientifically verifiable. All specified parameters are in valid ranges.\n\nStep 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\nThe problem is to find an optimal allocation of study time $u(t)$ to maximize the expected terminal GPA. This is a continuous-time stochastic optimal control problem. The standard method for solving such problems is the Hamilton-Jacobi-Bellman (HJB) equation.\n\nLet $V(t, x_1, x_2)$ be the value function, representing the maximum expected terminal GPA, given the state $(X_1(t), X_2(t)) = (x_1, x_2)$.\n$$ V(t, x_1, x_2) = \\sup_{u(\\cdot) \\in [0,1]} \\mathbb{E}_{t,x_1,x_2} \\left[ \\varphi_1 X_1(T) + \\varphi_2 X_2(T) \\right] $$\nThe value function must satisfy the terminal condition given by the payoff function:\n$$ V(T, x_1, x_2) = \\varphi_1 x_1 + \\varphi_2 x_2 $$\nThe HJB equation for this problem is:\n$$ \\frac{\\partial V}{\\partial t} + \\sup_{u \\in [0,1]} \\left\\{ \\left(-b_1 x_1 + a_1 u\\right) \\frac{\\partial V}{\\partial x_1} + \\left(-b_2 x_2 + a_2(1-u)\\right) \\frac{\\partial V}{\\partial x_2} + \\frac{1}{2} \\sigma_1^2 \\frac{\\partial^2 V}{\\partial x_1^2} + \\frac{1}{2} \\sigma_2^2 \\frac{\\partial^2 V}{\\partial x_2^2} \\right\\} = 0 $$\nThe cross-derivative term is absent because the Brownian motions $W_1(t)$ and $W_2(t)$ are independent.\n\nGiven the linear structure of the dynamics and the terminal condition, we propose a linear ansatz for the value function:\n$$ V(t, x_1, x_2) = p_1(t) x_1 + p_2(t) x_2 + q(t) $$\nThe partial derivatives are:\n$$ \\frac{\\partial V}{\\partial t} = p_1'(t) x_1 + p_2'(t) x_2 + q'(t), \\quad \\frac{\\partial V}{\\partial x_1} = p_1(t), \\quad \\frac{\\partial V}{\\partial x_2} = p_2(t), \\quad \\frac{\\partial^2 V}{\\partial x_1^2} = 0, \\quad \\frac{\\partial^2 V}{\\partial x_2^2} = 0 $$\nA crucial observation is that the second derivatives are zero. Consequently, the terms involving $\\sigma_1$ and $\\sigma_2$ vanish from the HJB equation. This implies that the optimal control and the expected value are independent of the volatility parameters, a characteristic of problems with linear objectives (risk neutrality).\n\nSubstituting the derivatives into the HJB equation:\n$$ p_1' x_1 + p_2' x_2 + q' + \\sup_{u \\in [0,1]} \\left\\{ (-b_1 x_1 + a_1 u) p_1 + (-b_2 x_2 + a_2(1-u)) p_2 \\right\\} = 0 $$\nWe can separate the terms containing the control variable $u$:\n$$ (p_1' - b_1 p_1) x_1 + (p_2' - b_2 p_2) x_2 + q' + a_2 p_2 + \\sup_{u \\in [0,1]} \\left\\{ u \\left( a_1 p_1 - a_2 p_2 \\right) \\right\\} = 0 $$\nFor this equation to hold for all $x_1, x_2$, the coefficients of $x_1$ and $x_2$ must be zero. This yields a system of ordinary differential equations (ODEs) for $p_1(t)$ and $p_2(t)$:\n$$ p_1'(t) - b_1 p_1(t) = 0 \\implies p_1'(t) = b_1 p_1(t) $$\n$$ p_2'(t) - b_2 p_2(t) = 0 \\implies p_2'(t) = b_2 p_2(t) $$\nFrom the terminal condition $V(T, x_1, x_2) = \\varphi_1 x_1 + \\varphi_2 x_2$, we obtain the terminal conditions for the ODEs: $p_1(T) = \\varphi_1$ and $p_2(T) = \\varphi_2$. We also set $q(T)=0$.\nSolving these backward-time ODEs gives:\n$$ p_1(t) = \\varphi_1 e^{-b_1(T-t)} $$\n$$ p_2(t) = \\varphi_2 e^{-b_2(T-t)} $$\nThe optimal control $u^*(t)$ is chosen to maximize the term $u(a_1 p_1(t) - a_2 p_2(t))$. This is a linear function of $u \\in [0,1]$. The optimal control is therefore of a \"bang-bang\" nature:\n$$ u^*(t) = \\begin{cases} 1 & \\text{if } a_1 p_1(t) - a_2 p_2(t) > 0 \\\\ 0 & \\text{if } a_1 p_1(t) - a_2 p_2(t) < 0 \\\\ \\text{any } u \\in [0,1] & \\text{if } a_1 p_1(t) - a_2 p_2(t) = 0 \\end{cases} $$\nThe switching function $S(t) = a_1 p_1(t) - a_2 p_2(t)$ determines the allocation. The value of the supremum is $\\max(a_1 p_1(t) - a_2 p_2(t), 0)$.\nThe remaining part of the HJB equation gives the ODE for $q(t)$:\n$$ q'(t) + a_2 p_2(t) + \\max(a_1 p_1(t) - a_2 p_2(t), 0) = 0 $$\nThis simplifies to:\n$$ q'(t) + \\max(a_1 p_1(t), a_2 p_2(t)) = 0 $$\nIntegrating from $t$ to $T$ with $q(T)=0$, we find $q(t)$:\n$$ q(t) = \\int_t^T \\max(a_1 p_1(\\tau), a_2 p_2(\\tau)) d\\tau $$\nThe desired quantity is the value function at time $t=0$, $V(0, x_{10}, x_{20})$:\n$$ V(0, x_{10}, x_{20}) = p_1(0)x_{10} + p_2(0)x_{20} + q(0) $$\nSubstituting the expressions for $p_1(0)$, $p_2(0)$, and $q(0)$:\n$$ \\sup \\mathbb{E}[G] = \\varphi_1 e^{-b_1 T} x_{10} + \\varphi_2 e^{-b_2 T} x_{20} + \\int_0^T \\max\\left(a_1 \\varphi_1 e^{-b_1(T-\\tau)}, a_2 \\varphi_2 e^{-b_2(T-\\tau)}\\right) d\\tau $$\nTo compute the integral, we must find if and where the two functions inside the maximum are equal. Let $f_1(\\tau) = a_1 \\varphi_1 e^{-b_1(T-\\tau)}$ and $f_2(\\tau) = a_2 \\varphi_2 e^{-b_2(T-\\tau)}$. A potential switching time $\\tau^* \\in [0,T]$ exists where $f_1(\\tau^*) = f_2(\\tau^*)$.\nIf $b_1 \\neq b_2$ and $a_1, a_2, \\varphi_1, \\varphi_2 > 0$, this occurs at:\n$$ \\tau^* = T - \\frac{1}{b_1 - b_2} \\ln\\left(\\frac{a_1 \\varphi_1}{a_2 \\varphi_2}\\right) $$\nIf $0 < \\tau^* < T$, the integral is split into two parts. Otherwise, one function dominates over the entire interval $[0,T]$. The integral of each component function is computed analytically. Let $C_i = a_i\\varphi_i$. For $b_i \\neq 0$, the indefinite integral is $\\int C_i e^{-b_i(T-\\tau)} d\\tau = \\frac{C_i}{b_i} e^{-b_i(T-\\tau)}$. For $b_i=0$, the integral is $\\int C_i d\\tau = C_i \\tau$. The overall optimal expected GPA is found by summing the contribution from the initial state and the computed value of the control integral.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the student's optimal study allocation problem for a given set of test cases.\n    \"\"\"\n\n    test_cases = [\n        # (a1, a2, b1, b2, sigma1, sigma2, phi1, phi2, T, x10, x20)\n        (1.0, 0.8, 0.2, 0.3, 0.3, 0.2, 2.0, 1.5, 2.0, 0.5, 0.7),  # Test 1\n        (1.0, 1.2, 0.1, 0.3, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0),  # Test 2\n        (1.0, 0.4, 0.5, 0.5, 0.5, 0.1, 1.0, 2.5, 3.0, 0.0, 0.0),  # Test 3\n        (1.0, 1.0, 0.2, 1.0, 0.2, 0.4, 1.0, 2.0, 2.0, 0.0, 0.0),  # Test 4\n        (0.0, 1.0, 0.3, 0.0, 0.7, 0.5, 1.0, 1.0, 1.5, 0.2, 0.1),  # Test 5\n    ]\n\n    results = []\n    for params in test_cases:\n        result = calculate_optimal_gpa(params)\n        results.append(f\"{result:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_optimal_gpa(params):\n    \"\"\"\n    Calculates the optimal expected GPA for a single set of parameters.\n    The formula is V(0, x10, x20) = p1(0)*x10 + p2(0)*x20 + q(0),\n    where:\n    p1(0) = phi1 * exp(-b1*T)\n    p2(0) = phi2 * exp(-b2*T)\n    q(0) = integral from 0 to T of max(f1(tau), f2(tau)) d(tau)\n    f1(tau) = a1*phi1*exp(-b1*(T-tau))\n    f2(tau) = a2*phi2*exp(-b2*(T-tau))\n    \"\"\"\n    (a1, a2, b1, b2, _, _, phi1, phi2, T, x10, x20) = params\n\n    # Contribution from the initial state\n    initial_gpa = phi1 * np.exp(-b1 * T) * x10 + phi2 * np.exp(-b2 * T) * x20\n\n    if T == 0:\n        return initial_gpa\n\n    # Helper function to compute the definite integral of f_i(tau) from c to d\n    def integrate_f(a, b, phi, T_val, c, d):\n        if d <= c:\n            return 0.0\n        \n        # Marginal effectiveness\n        C = a * phi\n        if C == 0:\n            return 0.0\n\n        if b == 0:\n            return C * (d - c)\n        else:\n            # Integral of C*exp(-b*(T-tau)) dtau is (C/b)*exp(-b*(T-tau))\n            val_at_d = (C / b) * np.exp(-b * (T_val - d))\n            val_at_c = (C / b) * np.exp(-b * (T_val - c))\n            return val_at_d - val_at_c\n\n    # Contribution from the optimal control\n    control_integral = 0.0\n    \n    C1 = a1 * phi1\n    C2 = a2 * phi2\n\n    # If one subject has zero marginal effectiveness, always focus on the other\n    if C1 <= 0:\n        control_integral = integrate_f(a2, b2, phi2, T, 0, T)\n    elif C2 <= 0:\n        control_integral = integrate_f(a1, b1, phi1, T, 0, T)\n    # Case with identical decay rates\n    elif b1 == b2:\n        if C1 >= C2:\n            control_integral = integrate_f(a1, b1, phi1, T, 0, T)\n        else:\n            control_integral = integrate_f(a2, b2, phi2, T, 0, T)\n    # General case with different decay rates\n    else:\n        # Switching time tau_star is where f1(tau) = f2(tau)\n        tau_star = T - np.log(C1 / C2) / (b1 - b2)\n\n        if tau_star <= 0:\n            # Switch is at or before t=0. One function dominates over [0,T].\n            # h(tau) = f1/f2 is monotonic. Sign at tau=0 determines dominance.\n            if b1 > b2:  # h(tau) is increasing. f1>f2 for tau > tau_star.\n                control_integral = integrate_f(a1, b1, phi1, T, 0, T)\n            else:  # b1 < b2, h(tau) is decreasing. f2>f1 for tau > tau_star.\n                control_integral = integrate_f(a2, b2, phi2, T, 0, T)\n        elif tau_star >= T:\n            # Switch is at or after t=T. One function dominates over [0,T].\n            if b1 > b2: # h(tau) is increasing. f2>f1 for tau < tau_star.\n                control_integral = integrate_f(a2, b2, phi2, T, 0, T)\n            else: # b1 < b2, h(tau) is decreasing. f1>f2 for tau < tau_star.\n                control_integral = integrate_f(a1, b1, phi1, T, 0, T)\n        else:\n            # Interior switch at tau_star. Integral is split.\n            if b1 > b2: # h increases, f2>f1 before tau_star, f1>f2 after\n                integ1 = integrate_f(a2, b2, phi2, T, 0, tau_star)\n                integ2 = integrate_f(a1, b1, phi1, T, tau_star, T)\n                control_integral = integ1 + integ2\n            else: # b1 < b2, h decreases, f1>f2 before, f2>f1 after\n                integ1 = integrate_f(a1, b1, phi1, T, 0, tau_star)\n                integ2 = integrate_f(a2, b2, phi2, T, tau_star, T)\n                control_integral = integ1 + integ2\n\n    return initial_gpa + control_integral\n\nif __name__ == '__main__':\n    solve()\n\n```", "id": "2416576"}]}