{"hands_on_practices": [{"introduction": "This exercise provides a foundational understanding of how pipeline interruptions, known as \"bubbles,\" affect instruction flow. By tracking a single bubble, you will develop a clear mental model of its journey through the pipeline and precisely quantify its impact on the completion time of subsequent instructions. This practice is crucial for visualizing the fundamental cost of any pipeline stall before tackling more complex scenarios [@problem_id:3629259].", "problem": "Consider a scalar, in-order, five-stage instruction pipeline with stages Instruction Fetch (IF), Instruction Decode and Register Read (ID), Execute (EX), Memory Access (MEM), and Write Back (WB). Each stage has a latency of exactly one clock cycle, and the pipeline issues at most one instruction per cycle. Assume an infinite stream of mutually independent instructions that imposes no data, structural, or control hazards beyond those described, and that the pipeline registers advance their contents at the end of each cycle.\n\nDefine a bubble as an intentionally inserted empty slot that advances one stage per cycle exactly as a real instruction would, occupying a stage but performing no work in that cycle. At cycle $0$, a single bubble is introduced into IF, so that IF performs no fetch at cycle $0$. Starting at cycle $1$, IF fetches one real instruction per cycle thereafter without interruption.\n\nLet $m \\in \\mathbb{N}$ be the number of consecutive real instructions following the bubble that enter IF beginning at cycle $1$, so that the first of these $m$ instructions is fetched at cycle $1$, the second at cycle $2$, and so on. Consider two scenarios:\n- Baseline scenario $\\mathcal{B}$ with no bubble, in which the pipeline begins fetching real instructions at cycle $0$ and continues to fetch one per cycle.\n- Bubble scenario $\\mathcal{S}$ described above, with the single bubble at cycle $0$ and real instruction fetches beginning at cycle $1$.\n\nFor each instruction $i \\in \\{1,2,\\dots,m\\}$, let $c_i$ denote its completion cycle (the cycle in which it enters WB) in $\\mathcal{B}$, and let $c_i'$ denote its completion cycle in $\\mathcal{S}$. Define the total cycle waste over these $m$ instructions as\n$$\nW(m) \\;=\\; \\sum_{i=1}^{m} \\left( c_i' \\;-\\; c_i \\right),\n$$\nwhich aggregates, across the $m$ instructions, the additional cycles each instruction spends in the system due solely to the presence of the bubble at cycle $0$.\n\nStarting from fundamental definitions of pipeline staging, latency, and advancement per cycle, derive $W(m)$ as a closed-form expression in $m$. Express your final answer as an exact analytic expression. No rounding is required, and no units should be included in the final expression.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- Pipeline: Scalar, in-order, five-stage.\n- Stages: Instruction Fetch (IF), Instruction Decode and Register Read (ID), Execute (EX), Memory Access (MEM), Write Back (WB).\n- Stage Latency: $1$ clock cycle per stage.\n- Issue Rate: At most $1$ instruction per cycle.\n- Instructions: Mutually independent, no data, structural, or control hazards beyond the specified bubble.\n- Pipeline Advancement: Registers advance at the end of each cycle.\n- Bubble: An empty slot that advances one stage per cycle.\n- Scenario $\\mathcal{S}$ (Bubble):\n  - Cycle $0$: Bubble introduced into IF.\n  - Cycle $1$ onwards: IF fetches one real instruction per cycle.\n- Variable $m$: $m \\in \\mathbb{N}$, the number of real instructions fetched, starting at cycle $1$.\n- Scenario $\\mathcal{B}$ (Baseline):\n  - Cycle $0$ onwards: IF fetches one real instruction per cycle.\n- Completion Cycle: The cycle in which an instruction *enters* the WB stage. $c_i$ is the completion cycle for instruction $i$ in $\\mathcal{B}$, and $c_i'$ is the completion cycle for instruction $i$ in $\\mathcal{S}$.\n- Total Cycle Waste: $W(m) = \\sum_{i=1}^{m} (c_i' - c_i)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem describes a classic, idealized instruction pipeline, a fundamental concept in computer organization and architecture. All terms (pipeline stages, latency, bubble, cycle counting) are standard and precisely defined. The two scenarios, $\\mathcal{B}$ and $\\mathcal{S}$, are constructed to isolate a specific effect, and the quantity to be calculated, $W(m)$, is explicitly formulated. The problem is self-contained, logically consistent, and scientifically sound. It is a well-posed problem with a unique, derivable solution.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full solution will be derived.\n\n**Derivation**\n\nThe pipeline has $5$ stages, and each stage takes $1$ clock cycle. The stages are IF, ID, EX, MEM, and WB. An instruction progresses sequentially through these stages. Let $t_{fetch}$ be the cycle in which an instruction is fetched and enters the IF stage.\n\n- The instruction is in the IF stage during cycle $t_{fetch}$.\n- It advances to the ID stage at the end of cycle $t_{fetch}$ and is in ID during cycle $t_{fetch} + 1$.\n- It advances to the EX stage and is in EX during cycle $t_{fetch} + 2$.\n- It advances to the MEM stage and is in MEM during cycle $t_{fetch} + 3$.\n- It advances to the WB stage and is in WB during cycle $t_{fetch} + 4$.\n\nThe problem defines the completion cycle as the cycle in which an instruction *enters* the WB stage. Based on the timing above, the completion cycle $c$ for an instruction fetched at cycle $t_{fetch}$ is given by:\n$$\nc = t_{fetch} + 4\n$$\n\nWe will now apply this relationship to both scenarios for the set of $m$ instructions, indexed from $i=1$ to $m$.\n\n**Baseline Scenario $\\mathcal{B}$**\nIn this scenario, the pipeline begins fetching instructions at cycle $0$ and fetches one instruction per cycle.\n- The first instruction ($i=1$) is fetched at cycle $t_{fetch,1} = 0$.\n- The second instruction ($i=2$) is fetched at cycle $t_{fetch,2} = 1$.\n- The $i$-th instruction is fetched at cycle $t_{fetch,i} = i - 1$.\n\nThe completion cycle for the $i$-th instruction, $c_i$, is therefore:\n$$\nc_i = t_{fetch,i} + 4 = (i - 1) + 4 = i + 3\n$$\n\n**Bubble Scenario $\\mathcal{S}$**\nIn this scenario, a bubble is introduced at cycle $0$. Real instruction fetches begin at cycle $1$.\n- The first instruction ($i=1$) is fetched at cycle $t'_{fetch,1} = 1$.\n- The second instruction ($i=2$) is fetched at cycle $t'_{fetch,2} = 2$.\n- The $i$-th instruction is fetched at cycle $t'_{fetch,i} = i$.\n\nHere, the prime notation (') is used to distinguish fetch cycles and completion cycles in scenario $\\mathcal{S}$ from those in scenario $\\mathcal{B}$. The completion cycle for the $i$-th instruction, $c_i'$, is:\n$$\nc_i' = t'_{fetch,i} + 4 = i + 4\n$$\n\n**Calculation of Total Cycle Waste $W(m)$**\nThe total cycle waste is defined as $W(m) = \\sum_{i=1}^{m} (c_i' - c_i)$. We can first find the difference for a single arbitrary instruction $i$.\n$$\nc_i' - c_i = (i + 4) - (i + 3) = 1\n$$\nThis result demonstrates that each instruction $i \\in \\{1, 2, \\dots, m\\}$ is delayed by exactly one clock cycle in scenario $\\mathcal{S}$ compared to scenario $\\mathcal{B}$. This is a direct consequence of the initial bubble occupying the first available fetch slot at cycle $0$, causing every subsequent instruction to be fetched one cycle later than it would have been in the baseline case.\n\nNow, we can compute the total cycle waste by summing this constant delay over all $m$ instructions:\n$$\nW(m) = \\sum_{i=1}^{m} (c_i' - c_i) = \\sum_{i=1}^{m} 1\n$$\nThe sum of $1$ repeated $m$ times is simply $m$.\n$$\nW(m) = m\n$$\nThis is the final closed-form expression for the total cycle waste.", "answer": "$$\n\\boxed{m}\n$$", "id": "3629259"}, {"introduction": "Building on the concept of a single stall, this practice challenges you to analyze a more realistic scenario involving a mix of different instruction types and potential hazards. You will apply the fundamental performance equation to calculate the overall Cycles Per Instruction ($CPI$) by accounting for data hazards, memory system delays, and branch prediction penalties. This problem demonstrates how to aggregate the effects of various independent performance bottlenecks into a single, comprehensive metric [@problem_id:3629296].", "problem": "A five-stage, in-order, single-issue pipeline executes an instruction stream composed of four instruction classes: arithmetic logic unit (ALU) operations, loads, stores, and conditional branches. The stages are instruction fetch, decode, execute, memory, and write-back. The processor uses separate instruction and data memories, eliminating structural hazards between instruction fetch and data access. Full data forwarding is implemented for ALU results, but a value loaded from memory is only available after the memory stage, so an instruction that immediately follows a load and uses its result cannot be fully resolved by forwarding. Branches are resolved in the execute stage, and a dynamic predictor supplies a direction prediction each cycle. The instruction mix fractions are $f_{ALU}$, $f_{LOAD}$, $f_{STORE}$, and $f_{BR}$, with $f_{ALU} + f_{LOAD} + f_{STORE} + f_{BR} = 1$.\n\nAssume the following well-tested, widely used facts and modeling assumptions:\n- In a fully pipelined, single-issue machine without hazards, the ideal cycles per instruction (CPI) is $1$ because one instruction completes per cycle in steady state.\n- The average CPI equals the ideal baseline plus the expected stall cycles per instruction induced by hazards, where the expectation is taken over the instruction stream. Assume hazard events are independent across instruction classes and that stalls due to different hazard types do not overlap in time.\n- ALU operations incur no stalls because data forwarding eliminates their interlocks in this design.\n- A load followed immediately by an instruction that consumes its result induces exactly $1$ stall cycle. Let $r$ denote the probability that a load is immediately followed by a dependent consumer.\n- The Level-1 (L1) data cache has a miss rate $m$ for loads, and each load miss stalls the pipeline for exactly $L$ additional cycles beyond the hit case.\n- Stores use a write buffer that fully hides write hits and misses for this workload, so stores do not stall the pipeline.\n- The dynamic branch predictor has a misprediction rate $b$ for conditional branches, and each misprediction flushes the pipeline for exactly $C$ cycles, while correctly predicted branches incur no penalty.\n\nFor a particular workload, the instruction mix and microarchitectural parameters are:\n- $f_{ALU} = 0.45$, $f_{LOAD} = 0.25$, $f_{STORE} = 0.10$, $f_{BR} = 0.20$.\n- $r = 0.30$.\n- $m = 0.04$, $L = 12$.\n- $b = 0.10$, $C = 2$.\n\nUsing only the definitions above and first principles of expectation, compute the expected cycles per instruction for this pipeline under these assumptions. Express your final answer as a single real number with no units, and round to four significant figures.", "solution": "The problem asks for the expected Cycles Per Instruction (CPI) for a five-stage pipelined processor. The solution will be derived by applying the principle of expectation to the provided model of pipeline execution, which includes penalties for various hazards.\n\nThe fundamental equation provided for the average CPI is the sum of an ideal CPI and the average number of stall cycles per instruction due to hazards.\n$$\n\\text{CPI} = \\text{CPI}_{\\text{ideal}} + \\Delta\\text{CPI}_{\\text{hazards}}\n$$\nThe problem states that for a fully pipelined machine without hazards, the ideal CPI is $1$.\n$$\n\\text{CPI}_{\\text{ideal}} = 1\n$$\nThe total stall cycles per instruction, $\\Delta\\text{CPI}_{\\text{hazards}}$, is the sum of contributions from each type of hazard. The problem specifies that stalls due to different hazard types do not overlap in time, so their contributions can be summed directly. The potential sources of stalls identified are load-use data hazards, data cache misses, and branch mispredictions. Other instruction types (ALU and stores) are stated to incur no stalls.\n\nThe total stall cycles per instruction is therefore:\n$$\n\\Delta\\text{CPI}_{\\text{hazards}} = \\Delta\\text{CPI}_{\\text{load-use}} + \\Delta\\text{CPI}_{\\text{cache-miss}} + \\Delta\\text{CPI}_{\\text{branch-mispredict}}\n$$\nWe will now calculate each component of the stall penalty. The penalty contributed by a specific event is the product of the frequency of the instruction that can cause the event, the probability of the event occurring for that instruction, and the number of stall cycles incurred by the event.\n\n1.  **Load-Use Data Hazard Stalls ($\\Delta\\text{CPI}_{\\text{load-use}}$)**\n    A load-use hazard occurs when an instruction that depends on the result of a preceding load instruction is executed immediately after it. The problem states that such an event induces exactly $1$ stall cycle.\n    - The fraction of instructions that are loads is $f_{\\text{LOAD}}$.\n    - The probability that a load is immediately followed by a dependent instruction is $r$.\n    - The penalty for this event is $1$ cycle.\n    The expected number of stall cycles per instruction due to this hazard is:\n    $$\n    \\Delta\\text{CPI}_{\\text{load-use}} = f_{\\text{LOAD}} \\times r \\times 1\n    $$\n    Using the given values, $f_{\\text{LOAD}} = 0.25$ and $r = 0.30$:\n    $$\n    \\Delta\\text{CPI}_{\\text{load-use}} = 0.25 \\times 0.30 \\times 1 = 0.075\n    $$\n\n2.  **Data Cache Miss Stalls ($\\Delta\\text{CPI}_{\\text{cache-miss}}$)**\n    A stall occurs when a load instruction misses in the Level-1 (L1) data cache.\n    - The fraction of instructions that are loads is $f_{\\text{LOAD}}$.\n    - The L1 data cache miss rate for loads is $m$.\n    - The penalty for a cache miss is an additional $L$ cycles.\n    The expected number of stall cycles per instruction due to data cache misses is:\n    $$\n    \\Delta\\text{CPI}_{\\text{cache-miss}} = f_{\\text{LOAD}} \\times m \\times L\n    $$\n    Using the given values, $f_{\\text{LOAD}} = 0.25$, $m = 0.04$, and $L = 12$:\n    $$\n    \\Delta\\text{CPI}_{\\text{cache-miss}} = 0.25 \\times 0.04 \\times 12 = 0.01 \\times 12 = 0.12\n    $$\n\n3.  **Branch Misprediction Stalls ($\\Delta\\text{CPI}_{\\text{branch-mispredict}}$)**\n    A stall occurs when the dynamic branch predictor makes an incorrect prediction, causing the pipeline to be flushed.\n    - The fraction of instructions that are conditional branches is $f_{\\text{BR}}$.\n    - The branch misprediction rate is $b$.\n    - The penalty for a misprediction is $C$ cycles.\n    The expected number of stall cycles per instruction due to branch mispredictions is:\n    $$\n    \\Delta\\text{CPI}_{\\text{branch-mispredict}} = f_{\\text{BR}} \\times b \\times C\n    $$\n    Using the given values, $f_{\\text{BR}} = 0.20$, $b = 0.10$, and $C = 2$:\n    $$\n    \\Delta\\text{CPI}_{\\text{branch-mispredict}} = 0.20 \\times 0.10 \\times 2 = 0.02 \\times 2 = 0.04\n    $$\n\nFinally, we sum the ideal CPI and all the stall components to find the total expected CPI.\n$$\n\\text{CPI} = \\text{CPI}_{\\text{ideal}} + \\Delta\\text{CPI}_{\\text{load-use}} + \\Delta\\text{CPI}_{\\text{cache-miss}} + \\Delta\\text{CPI}_{\\text{branch-mispredict}}\n$$\nSubstituting the calculated values:\n$$\n\\text{CPI} = 1 + 0.075 + 0.12 + 0.04\n$$\n$$\n\\text{CPI} = 1 + 0.235\n$$\n$$\n\\text{CPI} = 1.235\n$$\nThe problem requires the answer to be rounded to four significant figures. The calculated value $1.235$ already has four significant figures.", "answer": "$$\\boxed{1.235}$$", "id": "3629296"}, {"introduction": "This final practice moves from analysis to design, exploring a common engineering trade-off in pipeline optimization. By evaluating a proposal to modify the pipeline structure to eliminate a specific hazard, you will weigh the benefits of a lower $CPI$ against the potential costs of a different clock cycle time. Calculating the resulting speedup, as done in this exercise [@problem_id:3629255], provides a concrete method for justifying architectural changes and highlights that performance is a product of both instruction throughput and clock speed.", "problem": "A five-stage in-order pipeline consisting of Instruction Fetch (IF), Instruction Decode and register read (ID), Execute (EX), Memory Access (MEM), and Write Back (WB) is implemented with full data bypassing except for the classic load-use case. The per-stage logic delays are as follows: IF has delay $180\\,\\text{ps}$, ID has delay $170\\,\\text{ps}$, EX has delay $160\\,\\text{ps}$, MEM has delay $360\\,\\text{ps}$, and WB has delay $140\\,\\text{ps}$. Each pipeline register adds a latch overhead of $40\\,\\text{ps}$ to the cycle time. Assume first-level data memory always hits and branch penalties are negligible.\n\nA workload is hazard-dominated: across a long dynamic instruction stream of $N \\gg 1$ instructions, a fraction $f = 0.70$ of instruction boundaries are load-use hazards where a load is immediately followed by a dependent instruction. In the baseline pipeline, even with full bypassing, each such load-use hazard incurs exactly one stall cycle because the loaded data becomes available only at the end of the MEM stage and cannot satisfy the dependent instruction’s EX stage timing without a bubble.\n\nAn enhanced design adds one extra pipeline stage by splitting MEM into two equal logic stages, MEM1 and MEM2, each with half of the MEM logic delay. The latch overhead per stage remains $40\\,\\text{ps}$. The memory is organized so that the loaded value is available by the end of MEM1, enabling correct forwarding to the dependent instruction’s EX stage in the next cycle without any stall. All other aspects of the machine and workload remain unchanged, and there are no new structural hazards.\n\nUsing only first principles such as the definition of Cycles Per Instruction (CPI), the relationship between execution time, CPI, and clock period, and the definition of speedup as a ratio of execution times, derive and compute the overall speedup of the enhanced design over the baseline for this workload. Express the final speedup as a single real number and round your answer to four significant figures.", "solution": "The problem is deemed valid as it is scientifically grounded in the principles of computer architecture, is well-posed with sufficient data for a unique solution, and is expressed in objective, formal language. We can proceed with the analysis.\n\nThe overall speedup of the enhanced design relative to the baseline design is defined as the ratio of their respective execution times. The execution time ($T_{exec}$) for a program is given by the iron law of processor performance:\n$$T_{exec} = N \\times \\text{CPI} \\times T_{clk}$$\nwhere $N$ is the number of dynamic instructions, CPI is the average number of clock cycles per instruction, and $T_{clk}$ is the clock cycle time (or period).\n\nThe speedup ($S$) can therefore be expressed as:\n$$S = \\frac{T_{exec, base}}{T_{exec, enh}} = \\frac{N \\times \\text{CPI}_{base} \\times T_{clk, base}}{N \\times \\text{CPI}_{enh} \\times T_{clk, enh}}$$\nSince the workload is the same for both designs, the number of instructions $N$ is constant and cancels out:\n$$S = \\frac{\\text{CPI}_{base} \\times T_{clk, base}}{\\text{CPI}_{enh} \\times T_{clk, enh}}$$\nTo compute the speedup, we must first determine the clock period and CPI for each design.\n\nFirst, we analyze the baseline design.\nThe clock period ($T_{clk}$) of a pipelined processor is determined by the delay of its slowest stage plus the overhead of the pipeline register (latch). The stage delays for the baseline five-stage pipeline are given as:\n$T_{IF} = 180\\,\\text{ps}$\n$T_{ID} = 170\\,\\text{ps}$\n$T_{EX} = 160\\,\\text{ps}$\n$T_{MEM} = 360\\,\\text{ps}$\n$T_{WB} = 140\\,\\text{ps}$\nThe latch overhead is $T_{latch} = 40\\,\\text{ps}$.\n\nThe clock period for the baseline design, $T_{clk, base}$, is:\n$$T_{clk, base} = \\max(T_{IF}, T_{ID}, T_{EX}, T_{MEM}, T_{WB}) + T_{latch}$$\n$$T_{clk, base} = \\max(180, 170, 160, 360, 140)\\,\\text{ps} + 40\\,\\text{ps}$$\n$$T_{clk, base} = 360\\,\\text{ps} + 40\\,\\text{ps} = 400\\,\\text{ps}$$\n\nNext, we determine the CPI for the baseline design, $\\text{CPI}_{base}$. The CPI is the sum of the ideal CPI (which is $1$ for a pipeline) and the stall cycles per instruction.\n$$\\text{CPI} = 1 + \\text{Stall cycles per instruction}$$\nStalls are caused by load-use hazards. A fraction $f = 0.70$ of instructions are dependent on an immediately preceding load, and each such hazard incurs a $1$-cycle stall.\n$$\\text{Stall cycles per instruction} = (\\text{Fraction of instructions causing stalls}) \\times (\\text{Stalls per occurrence})$$\n$$\\text{Stall cycles per instruction}_{base} = f \\times 1 = 0.70 \\times 1 = 0.70$$\nTherefore, the CPI for the baseline design is:\n$$\\text{CPI}_{base} = 1 + 0.70 = 1.70$$\n\nNow, we analyze the enhanced design.\nThe MEM stage is split into two equal stages, MEM1 and MEM2. The new pipeline has six stages: IF, ID, EX, MEM1, MEM2, WB. The delays are:\n$T_{IF} = 180\\,\\text{ps}$\n$T_{ID} = 170\\,\\text{ps}$\n$T_{EX} = 160\\,\\text{ps}$\n$T_{MEM1} = \\frac{T_{MEM}}{2} = \\frac{360}{2}\\,\\text{ps} = 180\\,\\text{ps}$\n$T_{MEM2} = \\frac{T_{MEM}}{2} = \\frac{360}{2}\\,\\text{ps} = 180\\,\\text{ps}$\n$T_{WB} = 140\\,\\text{ps}$\n\nThe clock period for the enhanced design, $T_{clk, enh}$, is determined by the new set of stage delays and the same latch overhead $T_{latch} = 40\\,\\text{ps}$.\n$$T_{clk, enh} = \\max(180, 170, 160, 180, 180, 140)\\,\\text{ps} + 40\\,\\text{ps}$$\n$$T_{clk, enh} = 180\\,\\text{ps} + 40\\,\\text{ps} = 220\\,\\text{ps}$$\n\nNext, we determine the CPI for the enhanced design, $\\text{CPI}_{enh}$. In this design, the memory is organized such that the loaded value is available by the end of the MEM1 stage, which resolves the load-use hazard without any stalls.\n$$\\text{Stall cycles per instruction}_{enh} = f \\times 0 = 0.70 \\times 0 = 0$$\nTherefore, the CPI for the enhanced design is ideal:\n$$\\text{CPI}_{enh} = 1 + 0 = 1.00$$\n\nFinally, we can compute the overall speedup $S$.\n$$S = \\frac{\\text{CPI}_{base} \\times T_{clk, base}}{\\text{CPI}_{enh} \\times T_{clk, enh}} = \\frac{1.70 \\times 400\\,\\text{ps}}{1.00 \\times 220\\,\\text{ps}}$$\n$$S = \\frac{680}{220} = \\frac{68}{22} = \\frac{34}{11}$$\n$$S \\approx 3.090909...$$\nRounding the result to four significant figures gives:\n$$S = 3.091$$", "answer": "$$\\boxed{3.091}$$", "id": "3629255"}]}