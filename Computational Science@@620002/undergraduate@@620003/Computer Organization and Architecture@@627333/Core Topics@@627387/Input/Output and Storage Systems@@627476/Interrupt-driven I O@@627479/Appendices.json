{"hands_on_practices": [{"introduction": "The foundation of reliable interrupt-driven I/O lies in the correct implementation of the Interrupt Service Routine (ISR), especially when interacting with complex hardware. This exercise focuses on the essential logic for handling a memory-mapped I/O (MMIO) device that uses level-triggered interrupts and has registers with read side effects. Mastering the sequence of operations—including interrupt masking, status checking, data reading, memory ordering, and signaling end-of-interrupt—is critical for preventing subtle bugs like data loss, event duplication, and race conditions that are prevalent in low-level systems programming [@problem_id:3653019].", "problem": "A computer system uses Interrupt Service Routine (ISR) dispatch to process events from a peripheral that exposes Memory-Mapped Input/Output (MMIO) registers. The peripheral implements the following memory-mapped registers with scientifically realistic behavior:\n\n- A data register at address $A_D$ that returns the next event payload on each MMIO read and has a read side effect: each read consumes exactly one event and decrements a pending count $N$ by $1$. If $N=0$, a read of $A_D$ is architecturally undefined and must be avoided.\n- A status register at address $A_S$ whose bit $RDY$ is set if and only if $N>0$; reading $A_S$ has no side effects.\n- An interrupt mask register at address $A_M$ where writing the value $1$ masks the device’s interrupt and writing the value $0$ unmasks it.\n- An End-of-Interrupt register at address $A_E$ where writing the value $1$ sends End-of-Interrupt (EOI) to the interrupt controller.\n\nThe device raises a level-triggered interrupt line while $RDY=1$. The Central Processing Unit (CPU) runs a single-producer/single-consumer driver where the ISR is the producer that enqueues payloads into a ring buffer $Q$ with head index $h$ and tail index $t$, and a user thread is the consumer. The publish step is defined as writing the payload into $Q[h]$ followed by an atomic increment of $h$ with release semantics.\n\nThe architecture’s memory model is relaxed: without explicit barriers, normal memory operations and MMIO operations may be reordered. A barrier $B()$ is available that guarantees all prior MMIO reads complete before any subsequent normal memory stores become visible to other cores or threads. The atomic increment of $h$ has release semantics on normal memory, but does not imply ordering with respect to MMIO without an explicit $B()$.\n\nExactly-once consumption is defined as a one-to-one mapping over time between device events and software enqueues: for every device event that contributes $+1$ to $N$ at time $t$, the ISR eventually enqueues exactly one corresponding payload into $Q$ and publishes it once, with no duplicates and no losses, even if events arrive while the ISR executes.\n\nYou are to reason from first principles about interrupts, MMIO, read side effects, level-triggering, and memory ordering. Consider the following candidate ISRs, expressed as ordered steps, and choose the design that guarantees exactly-once consumption and avoids races, reentrancy hazards, and ordering violations.\n\nOption A:\n- Write $1$ to $A_M$ to mask the device interrupt.\n- While $\\text{mmio\\_read}(A_S)$ indicates $RDY=1$:\n  - Let $d \\leftarrow \\text{mmio\\_read}(A_D)$.\n  - Call $B()$.\n  - Write $d$ into $Q[h]$.\n  - Atomically increment $h$ with release semantics.\n- Write $1$ to $A_E$ to send EOI.\n- Write $0$ to $A_M$ to unmask the device interrupt.\n\nOption B:\n- Write $1$ to $A_E$ to send EOI immediately.\n- Do not mask the device; loop while $\\text{mmio\\_read}(A_S)$ indicates $RDY=1$:\n  - Let $d \\leftarrow \\text{mmio\\_read}(A_D)$.\n  - Write $d$ into $Q[h]$.\n  - Atomically increment $h$ with release semantics.\n  - Call $B()$.\n- Leave the device unmasked throughout.\n\nOption C:\n- Write $1$ to $A_M$ to mask the device interrupt.\n- Read $\\text{mmio\\_read}(A_S)$ once; if $RDY=1$:\n  - Let $d \\leftarrow \\text{mmio\\_read}(A_D)$.\n  - Write $d$ into $Q[h]$.\n  - Atomically increment $h$ with release semantics.\n- Write $1$ to $A_E$ to send EOI.\n- Write $0$ to $A_M$ to unmask the device interrupt.\n\nOption D:\n- Write $1$ to $A_M$ to mask the device interrupt.\n- Read a ready count approximation $c$ from $\\text{mmio\\_read}(A_S)$ (assume $c$ reflects the number of pending events at that instant).\n- For $i$ from $1$ to $c$:\n  - Let $d \\leftarrow \\text{mmio\\_read}(A_D)$.\n  - Write $d$ into $Q[h]$.\n  - Atomically increment $h$ with release semantics.\n- Call $B()$ once after the loop.\n- Write $1$ to $A_E$ to send EOI.\n- Write $0$ to $A_M$ to unmask the device interrupt.\n\nWhich option ensures exactly-once consumption under the stated assumptions and prevents races and ordering violations? Select the single best answer.\n\nA. Option A\n\nB. Option B\n\nC. Option C\n\nD. Option D", "solution": "This problem tests the core principles of writing a robust Interrupt Service Routine (ISR) for a device with level-triggered interrupts, MMIO registers with side effects, and a relaxed memory model. A correct solution must handle all three aspects flawlessly.\n\n### Derivation from First Principles\n\n1.  **Level-Triggered Interrupts**: A level-triggered interrupt line remains asserted as long as the causal condition is true (here, `RDY=1`). If the ISR sends an End-of-Interrupt (EOI) to the controller while the condition is still active, the controller will immediately re-raise the interrupt. This can cause the ISR to re-enter itself infinitely, leading to a stack overflow or live-lock. The correct protocol is to first mask the interrupt source to prevent re-entrancy, then service the device until the interrupt condition is cleared, then send the EOI, and finally unmask the interrupt.\n\n2.  **MMIO Side Effects and Event Draining**: The data register $A_D$ has a read side effect: it consumes an event. It must only be read when the status register $A_S$ indicates `RDY=1`. Since multiple events can be pending when the ISR starts (or can arrive while the ISR is masked), the ISR must loop, repeatedly checking $A_S$ and reading from $A_D$ until the device has no more data. This \"draining loop\" is essential to ensure the `RDY` condition is cleared before the ISR sends EOI.\n\n3.  **Relaxed Memory Ordering**: The problem states that MMIO and memory operations can be reordered. The consumer thread relies on the head pointer $h$ to find new data. For correctness, the data $d$ from the device must be written into the queue $Q[h]$ *before* the consumer is notified by the update to $h$. The barrier $B()$ is provided to enforce this order. It must be placed after the MMIO read of the data and before the stores that make the data available to the consumer (the write to $Q[h]$ and the increment of $h$).\n\n### Analysis of Options\n\n*   **Option A**: This option follows the correct protocol.\n    1.  `Write 1 to A_M`: Masks the interrupt, preventing re-entrancy. Correct.\n    2.  `While mmio_read(A_S) indicates RDY=1`: Drains all pending events by looping until the interrupt condition is cleared. Correct.\n    3.  `Let d - mmio_read(A_D)` followed by `Call B()` followed by `Write d into Q[h]` and `Atomically increment h`: This sequence correctly reads data, then enforces ordering with the barrier, then publishes the data. Correct.\n    4.  `Write 1 to A_E`: Sends EOI after the condition is cleared. Correct.\n    5.  `Write 0 to A_M`: Unmasks for future interrupts. Correct.\n    This design is robust and correct.\n\n*   **Option B**: This option is fatally flawed. It sends EOI immediately. As the `RDY` condition is still true, the interrupt controller will immediately re-raise the interrupt, causing the ISR to re-enter. This will result in a stack overflow. It also fails to mask the interrupt, compounding the re-entrancy hazard.\n\n*   **Option C**: This option is incorrect because it does not loop to drain all pending events. It processes at most one event. If multiple events were pending, `RDY` would remain asserted. When the ISR unmasks the interrupt at the end, the interrupt would fire again immediately, which is inefficient and can starve lower-priority tasks. This fails to guarantee that the interrupt condition is de-asserted before EOI.\n\n*   **Option D**: This option is racy. It reads a count `c` once at the beginning. If new events arrive after `c` is read but while the ISR is still processing the first `c` events, they will not be serviced. The `RDY` line will remain asserted, causing an immediate interrupt upon unmasking, similar to the flaw in Option C. The robust method is to loop on the *current status* of the `RDY` bit, not a stale count.\n\n### Conclusion\nOption A is the only one that correctly implements the complete protocol for handling a level-triggered interrupt from a device with these characteristics on a system with a relaxed memory model. It correctly handles re-entrancy, drains all pending events, and ensures proper memory ordering.", "answer": "$$\\boxed{A}$$", "id": "3653019"}, {"introduction": "For high-performance systems where interrupts arrive at a very high rate, executing all processing within the ISR can lead to excessive CPU overhead and high latency. A common and powerful architectural pattern is to offload the intensive work from the ISR to a separate kernel workqueue. This practice challenges you to analyze such a system, where a minimal ISR only captures event data and a pool of worker threads performs the heavy lifting. You will apply principles of queuing theory and flow conservation to calculate the system's behavior under load, including how a backpressure mechanism manages queue buildup, providing insight into designing scalable and responsive I/O architectures [@problem_id:3652992].", "problem": "A device delivers events that raise interrupts to a central processing unit. The Interrupt Service Routine (ISR; Interrupt Service Routine) performs only minimal work: it acknowledges the device, pushes a descriptor for each event into a lock-free ring shared with a kernel workqueue, and immediately returns. Heavy processing for each descriptor is performed by worker threads in the workqueue, running on dedicated cores. The ISR also implements backpressure: if the ring occupancy reaches a high-water threshold, it issues a device mask to stop further interrupts and events. Due to interconnect and device pipeline, the mask takes effect after a fixed latency. During that latency, the device continues to produce events, and the ISR continues to enqueue descriptors; worker threads keep draining the ring concurrently.\n\nAssume:\n- The device generates a stream of events at a constant average rate of $\\lambda = 2.6 \\times 10^{5} \\ \\text{events/s}$.\n- The workqueue has $W = 5$ identical worker threads. Each descriptor requires a deterministic heavy-processing time of $\\tau = 25 \\ \\mu\\text{s}$ per descriptor on a worker, and workers run on separate cores from the ISR, so their service is not preempted by the ISR.\n- The ring high-water threshold that triggers backpressure is $H = 1800$ descriptors.\n- When the ISR detects that the occupancy has just reached $H$ (i.e., it has transitioned from $H-1$ to $H$), it writes a mask to the device to stop further interrupts and event production. The mask takes effect after a fixed end-to-end latency of $t_{\\text{eff}} = 150 \\ \\mu\\text{s}$, during which the device continues to produce events at rate $\\lambda$, and workers continue to process descriptors at their aggregate rate. Assume no additional in-flight events beyond what arrive during $t_{\\text{eff}}$.\n- The ring capacity is sufficiently large that it does not overflow before backpressure takes effect.\n\nUsing only first principles about flow conservation in queues and rates, compute the total number of pending descriptors in the ring, $N_{\\text{pend}}$, at the instant just before backpressure actually halts further arrivals. Express your final answer as a plain number of descriptors (jobs). No rounding instruction is necessary; give the exact integer value implied by the parameters.", "solution": "The fundamental base is conservation of work in a queue: the instantaneous rate of change of the number of queued items equals the arrival rate minus the service (departure) rate. Let $N(t)$ denote the number of pending descriptors at time $t$. Then, in a fluid approximation valid at the time scales given and under the stated determinism, the rate equation is\n$$\n\\frac{dN(t)}{dt} = \\lambda - \\mu_{\\text{agg}},\n$$\nwhere $\\lambda$ is the constant arrival rate of descriptors from the device while interrupts are enabled, and $\\mu_{\\text{agg}}$ is the aggregate service rate provided by the workqueue.\n\nGiven $W$ identical workers and a per-descriptor processing time $\\tau$, the service rate of one worker is $1/\\tau$, so the aggregate service rate is\n$$\n\\mu_{\\text{agg}} = \\frac{W}{\\tau}.\n$$\nHere, $W = 5$ and $\\tau = 25 \\ \\mu\\text{s} = 25 \\times 10^{-6} \\ \\text{s}$, hence\n$$\n\\mu_{\\text{agg}} = \\frac{5}{25 \\times 10^{-6}} = \\frac{5}{25} \\times 10^{6} = 0.2 \\times 10^{6} = 2.0 \\times 10^{5} \\ \\text{descriptors/s}.\n$$\n\nThe arrival rate is given as $\\lambda = 2.6 \\times 10^{5} \\ \\text{descriptors/s}$. Therefore, while interrupts are enabled, the backlog increases at a constant net rate\n$$\n\\lambda - \\mu_{\\text{agg}} = \\left(2.6 \\times 10^{5}\\right) - \\left(2.0 \\times 10^{5}\\right) = 0.6 \\times 10^{5} = 6.0 \\times 10^{4} \\ \\text{descriptors/s}.\n$$\n\nBy the problem statement, at the instant the ISR detects that the queue has reached the high-water threshold, the occupancy is $H = 1800$ descriptors. The ISR then issues a device mask, which takes a fixed latency $t_{\\text{eff}} = 150 \\ \\mu\\text{s} = 150 \\times 10^{-6} \\ \\text{s}$ to become effective. During this latency, arrivals continue at rate $\\lambda$ and service continues at rate $\\mu_{\\text{agg}}$, so the net increase in occupancy over this latency is the integral of the net rate over the interval of length $t_{\\text{eff}}$:\n$$\n\\Delta N = \\int_{0}^{t_{\\text{eff}}} \\left(\\lambda - \\mu_{\\text{agg}}\\right) \\, dt = \\left(\\lambda - \\mu_{\\text{agg}}\\right) t_{\\text{eff}}.\n$$\n\nSubstituting the values,\n$$\n\\Delta N = \\left(6.0 \\times 10^{4}\\right) \\times \\left(150 \\times 10^{-6}\\right) = 6.0 \\times 150 \\times 10^{4 - 6} = 900 \\times 10^{-2} = 9.\n$$\n\nThus, the occupancy just before the mask takes effect and halts further arrivals is\n$$\nN_{\\text{pend}} = H + \\Delta N = 1800 + 9 = 1809.\n$$\n\nThis value is an exact integer under the given parameters, and it respects the assumption that the ring capacity is sufficiently large, since no capacity was specified to be below $1809$.", "answer": "$$\\boxed{1809}$$", "id": "3652992"}, {"introduction": "Beyond correctness and performance, a critical aspect of embedded systems design is robustness—the ability to detect and recover from faults. An ISR that fails, for instance by entering an infinite loop, can halt the entire system. This practice explores the use of a watchdog timer (WDT) as a hardware-based safety mechanism to detect such software lockups. You will engage in a worst-case timing analysis to calculate a WDT timeout that is safe from false positives yet responsive enough to meet system requirements, and you will evaluate recovery strategies to ensure the system can be restored to a known-good state, a fundamental skill for building dependable systems [@problem_id:3652973].", "problem": "An embedded controller uses interrupt-driven input/output, where a hardware sensor generates periodic interrupts that are serviced by an Interrupt Service Routine (ISR). A Watchdog Timer (WDT) must be periodically serviced (\"kicked\") to indicate liveness; if the WDT is not serviced within a timeout, it triggers a non-maskable event. The current design services the WDT at the end of each successful ISR execution. You are asked to choose a WDT timeout and a safe recovery path to catch ISR lockups without false positives.\n\nThe system exhibits the following well-tested behavioral bounds during normal operation:\n- The sensor generates interrupts with nominal period $T_{irq} = 4.8\\,\\mathrm{ms}$ and positive jitter up to $\\Delta = 0.4\\,\\mathrm{ms}$, so the longest inter-arrival under normal conditions is $T_{irq}^{\\max} = T_{irq} + \\Delta$.\n- Global interrupts may be masked during atomic critical sections for up to $B = 12\\,\\mathrm{ms}$.\n- After interrupts are unmasked, higher-priority activity can delay ISR dispatch by up to $P = 3.0\\,\\mathrm{ms}$, and the dispatcher overhead contributes $S = 0.2\\,\\mathrm{ms}$.\n- The ISR worst-case execution time is $W = 1.1\\,\\mathrm{ms}$.\n- The system timer resolution is $R_t = 0.1\\,\\mathrm{ms}$ and should be included as slack when reasoning about time intervals.\n\nSafety and availability requirements specify that any ISR lockup must be detected and addressed within $T_{\\text{detect}}^{\\max} = 25\\,\\mathrm{ms}$, and recovery must avoid a full system reset, quiesce the device to prevent further data corruption, preserve diagnostic logs, and re-establish normal interrupt-driven operation. Assume the Watchdog Timer can be configured to raise a Non-Maskable Interrupt (NMI) on its first timeout rather than performing an immediate system reset.\n\nFrom first principles, the WDT timeout $T_{wd}$ must be strictly greater than the longest interval between successive WDT services that can occur under non-fault conditions, and less than or equal to $T_{\\text{detect}}^{\\max}$. Which option best meets these constraints?\n\nA. Set $T_{wd} = 8\\,\\mathrm{ms}$; on timeout, immediately reset the entire system.\n\nB. Set $T_{wd} = 15\\,\\mathrm{ms}$; on timeout, simply re-enable global interrupts and return from the fault handler to continue normal operation.\n\nC. Set $T_{wd} = 22\\,\\mathrm{ms}$; on timeout, raise a Non-Maskable Interrupt (NMI) that invokes a fault handler which logs the fault, flushes outbound I/O queues, halts any Direct Memory Access (DMA) engines and places the device into a documented quiescent state, performs a targeted soft reset of only the I/O subsystem, reinstalls and re-enables the ISR, issues a memory barrier before resuming, and then returns to normal operation.\n\nD. Set $T_{wd} = 30\\,\\mathrm{ms}$; on timeout, mask interrupts, spin-wait for the device to clear its status, and then unmask interrupts.", "solution": "The user has tasked me with validating and solving a problem concerning the selection of a Watchdog Timer (WDT) timeout and recovery strategy for an interrupt-driven embedded system.\n\n### Problem Validation\n\nFirst, I must meticulously validate the problem statement.\n\n#### Step 1: Extract Givens\nVerbatim data extracted from the problem statement:\n- **Nominal interrupt period**: $T_{irq} = 4.8\\,\\mathrm{ms}$\n- **Positive interrupt jitter**: $\\Delta = 0.4\\,\\mathrm{ms}$\n- **Longest inter-arrival time**: $T_{irq}^{\\max} = T_{irq} + \\Delta$\n- **Maximum interrupt masking time**: $B = 12\\,\\mathrm{ms}$\n- **Maximum preemption delay by higher-priority tasks**: $P = 3.0\\,\\mathrm{ms}$\n- **Dispatcher overhead**: $S = 0.2\\,\\mathrm{ms}$\n- **Worst-case ISR execution time**: $W = 1.1\\,\\mathrm{ms}$\n- **System timer resolution (slack)**: $R_t = 0.1\\,\\mathrm{ms}$\n- **Maximum allowed detection time for lockup**: $T_{\\text{detect}}^{\\max} = 25\\,\\mathrm{ms}$\n- **WDT servicing point**: At the end of each successful ISR execution.\n- **WDT mechanism**: Can be configured to raise a Non-Maskable Interrupt (NMI).\n- **Recovery requirements**: Must (1) avoid full system reset, (2) quiesce the device, (3) preserve diagnostic logs, and (4) re-establish normal operation.\n- **Core Constraint**: The WDT timeout, $T_{wd}$, must be strictly greater than the longest non-fault interval between WDT services and less than or equal to $T_{\\text{detect}}^{\\max}$.\n\n#### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is based on fundamental and standard principles of real-time systems analysis, including interrupt response time calculation and fault tolerance mechanisms like watchdog timers. All concepts are standard in computer engineering and are internally consistent.\n- **Well-Posed**: The problem is well-posed. It provides all necessary quantitative data to calculate the worst-case time between WDT services. The qualitative requirements for the recovery path are clear and specific, allowing for an objective evaluation of the options.\n- **Objective**: The language is precise, technical, and free of subjectivity.\n\nThe problem passes all validation checks. No flaws were found. It is a standard, solvable problem in embedded systems design.\n\n#### Step 3: Verdict and Action\nThe problem is **valid**. I will proceed to derive the solution.\n\n### Solution Derivation\n\nThe primary task is to determine the valid range for the WDT timeout, $T_{wd}$. This range is defined by a lower and an upper bound.\n\n1.  **Upper Bound for $T_{wd}$**:\n    The problem states that any ISR lockup must be detected within $T_{\\text{detect}}^{\\max} = 25\\,\\mathrm{ms}$. The WDT timeout is the mechanism for this detection. Therefore, the timeout value must be less than or equal to this maximum allowed time.\n    $$T_{wd} \\le 25\\,\\mathrm{ms}$$\n\n2.  **Lower Bound for $T_{wd}$**:\n    The timeout $T_{wd}$ must be strictly greater than the maximum possible time interval between two consecutive services of the WDT under normal (non-fault) conditions. This prevents false positives, where the WDT triggers even though the system is operating correctly. Let this maximum interval be $T_{interval}^{\\max}$.\n\n    The WDT is serviced at the completion of each ISR. We need to find the maximum possible time between the completion of one ISR, say $ISR_n$, and the completion of the next, $ISR_{n+1}$. Let $A_k$ be the arrival time of interrupt $IRQ_k$ and $C_k$ be the completion time of $ISR_k$. The interval is $C_{n+1} - C_n$.\n\n    To maximize this interval, we construct a worst-case scenario:\n    - The interval between the arrival of $IRQ_n$ and $IRQ_{n+1}$ is maximized.\n    - The response time for $ISR_n$ (from $A_n$ to $C_n$) is minimized.\n    - The response time for $ISR_{n+1}$ (from $A_{n+1}$ to $C_{n+1}$) is maximized.\n\n    The interval can be expressed as:\n    $$T_{interval}^{\\max} = (A_{n+1} - A_n)_{\\max} + (C_{n+1} - A_{n+1})_{\\max} - (C_n - A_n)_{\\min}$$\n\n    Let's calculate each term:\n    - **Maximum Inter-arrival Time**: The problem explicitly defines this as $T_{irq}^{\\max} = T_{irq} + \\Delta$.\n      $$T_{irq}^{\\max} = 4.8\\,\\mathrm{ms} + 0.4\\,\\mathrm{ms} = 5.2\\,\\mathrm{ms}$$\n    - **Maximum ISR Response Time ($T_{resp}^{\\max}$)**: This is the sum of the maximum dispatch latency and the worst-case execution time. The maximum latency occurs when the interrupt is masked for the longest duration ($B$), then delayed by higher-priority tasks ($P$), plus the dispatcher overhead ($S$).\n      $$T_{resp}^{\\max} = B + P + S + W$$\n      $$T_{resp}^{\\max} = 12\\,\\mathrm{ms} + 3.0\\,\\mathrm{ms} + 0.2\\,\\mathrm{ms} + 1.1\\,\\mathrm{ms} = 16.3\\,\\mathrm{ms}$$\n    - **Minimum ISR Response Time ($T_{resp}^{\\min}$)**: This occurs with minimum latency (only the dispatcher overhead $S$) and minimum execution time. The best-case execution time is not given; a standard and safe assumption for this analysis is that it is negligible ($W_{\\min} \\approx 0$).\n      $$T_{resp}^{\\min} = S + W_{\\min} \\approx 0.2\\,\\mathrm{ms} + 0\\,\\mathrm{ms} = 0.2\\,\\mathrm{ms}$$\n\n    Now, we compute the maximum interval between WDT services:\n    $$T_{interval}^{\\max} = T_{irq}^{\\max} + T_{resp}^{\\max} - T_{resp}^{\\min}$$\n    $$T_{interval}^{\\max} = 5.2\\,\\mathrm{ms} + 16.3\\,\\mathrm{ms} - 0.2\\,\\mathrm{ms} = 21.3\\,\\mathrm{ms}$$\n\n    Finally, we must add the timer resolution slack $R_t = 0.1\\,\\mathrm{ms}$ to this value to create a safe margin against quantization errors. The WDT timeout must be strictly greater than this result.\n    $$T_{wd} > T_{interval}^{\\max} + R_t = 21.3\\,\\mathrm{ms} + 0.1\\,\\mathrm{ms} = 21.4\\,\\mathrm{ms}$$\n\n3.  **Valid Range for $T_{wd}$**:\n    Combining the lower and upper bounds, we have:\n    $$21.4\\,\\mathrm{ms}  T_{wd} \\le 25\\,\\mathrm{ms}$$\n\n### Option-by-Option Analysis\n\nNow I will evaluate each option based on the derived timeout range and the problem's recovery requirements.\n\n**A. Set $T_{wd} = 8\\,\\mathrm{ms}$; on timeout, immediately reset the entire system.**\n- **Timeout Value**: $T_{wd} = 8\\,\\mathrm{ms}$. This is not in the valid range $(21.4\\,\\mathrm{ms}, 25\\,\\mathrm{ms}]$. A timeout of $8\\,\\mathrm{ms}$ is much shorter than the maximum normal interval of $21.4\\,\\mathrm{ms}$, guaranteeing spurious WDT events and system instability.\n- **Recovery Path**: A full system reset violates the explicit requirement to \"avoid a full system reset\".\n- **Verdict**: **Incorrect**.\n\n**B. Set $T_{wd} = 15\\,\\mathrm{ms}$; on timeout, simply re-enable global interrupts and return from the fault handler to continue normal operation.**\n- **Timeout Value**: $T_{wd} = 15\\,\\mathrm{ms}$. This is not in the valid range $(21.4\\,\\mathrm{ms}, 25\\,\\mathrm{ms}]$. This timeout is too short and will cause false positives.\n- **Recovery Path**: This path is fundamentally unsafe. If the ISR is truly locked (e.g., in an infinite `while(1)` loop), returning from the NMI handler would resume the locked ISR, leading to an immediate re-triggering of the WDT. It does not solve the underlying problem.\n- **Verdict**: **Incorrect**.\n\n**C. Set $T_{wd} = 22\\,\\mathrm{ms}$; on timeout, raise a Non-Maskable Interrupt (NMI) that invokes a fault handler which logs the fault, flushes outbound I/O queues, halts any Direct Memory Access (DMA) engines and places the device into a documented quiescent state, performs a targeted soft reset of only the I/O subsystem, reinstalls and re-enables the ISR, issues a memory barrier before resuming, and then returns to normal operation.**\n- **Timeout Value**: $T_{wd} = 22\\,\\mathrm{ms}$. This value satisfies the derived constraint $21.4\\,\\mathrm{ms}  22\\,\\mathrm{ms} \\le 25\\,\\mathrm{ms}$. It is a safe and valid timeout.\n- **Recovery Path**: This path is a comprehensive and robust implementation of the recovery requirements. It correctly logs diagnostics (\"preserve diagnostic logs\"), brings the I/O to a safe state (\"quiesce the device\"), avoids a catastrophic failure (\"avoid a full system reset\"), and correctly takes steps to resume functionality (\"re-establish normal... operation\"). All aspects of this recovery strategy are sound and align with best practices for fault-tolerant embedded systems.\n- **Verdict**: **Correct**.\n\n**D. Set $T_{wd} = 30\\,\\mathrm{ms}$; on timeout, mask interrupts, spin-wait for the device to clear its status, and then unmask interrupts.**\n- **Timeout Value**: $T_{wd} = 30\\,\\mathrm{ms}$. This violates the upper bound requirement $T_{wd} \\le 25\\,\\mathrm{ms}$. The system would fail to meet its specified maximum detection time for a fault.\n- **Recovery Path**: This path is ill-conceived. Masking interrupts and entering a spin-wait inside a high-priority NMI handler will likely freeze the entire system, preventing any chance of recovery. It is the antithesis of a safe recovery path.\n- **Verdict**: **Incorrect**.", "answer": "$$\\boxed{C}$$", "id": "3652973"}]}