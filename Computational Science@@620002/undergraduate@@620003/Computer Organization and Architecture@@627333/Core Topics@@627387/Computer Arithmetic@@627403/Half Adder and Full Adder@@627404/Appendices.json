{"hands_on_practices": [{"introduction": "Understanding the theoretical logic of a half adder is the first step; translating it into a physical circuit using a standard set of gates is the next. This practice challenges you to implement a half adder using only NAND gates, which are fundamental building blocks in modern integrated circuits [@problem_id:3645102]. By doing so, you will explore the concepts of functional completeness and gate-level optimization, culminating in an analysis of the circuit's speed based on its logic depth.", "problem": "A half adder has Boolean outputs defined by $S = A \\oplus B$ and $C = A \\cdot B$, where $A$ and $B$ are Boolean inputs and $\\oplus$ denotes exclusive OR. Redesign this half adder using only $2$-input NAND gates, with the following implementation rules and timing model: every NAND gate has identical propagation delay $t_{pd}$, an inverter must be realized by tying the two inputs of a NAND gate together, fan-out is unrestricted, wire/interconnect delay is neglected, and intermediate signals may be shared between $S$ and $C$. Define logic depth of an output as the number of gate stages on the longest path from any primary input to that output. The worst-case propagation delay of the half adder is the maximum of the propagation delays of $S$ and $C$.\n\nUnder these constraints, determine the minimum achievable worst-case propagation delay, expressed as a closed-form analytic expression in terms of $t_{pd}$, over all NAND-only implementations of the half adder that produce both $S$ and $C$. Your reasoning must account for gate depth on each output and justify why the achieved depth is minimal. Report only the single final expression in terms of $t_{pd}$; no drawing is required and no rounding is needed.", "solution": "The user wants me to solve this problem.\n\n**1. Role Play:** As a meticulous STEM professor, I must ensure scientific correctness and logical rigor.\n\n**2. Task:** The core task asks for the minimum worst-case propagation delay of a half adder implemented solely with 2-input NAND gates, given a specific timing model.\n\n**3. Problem Validation:**\n\n*   **Step 1: Extract Givens**\n    *   Half adder outputs: $S = A \\oplus B$, $C = A \\cdot B$.\n    *   Inputs: $A$, $B$ (Boolean).\n    *   Implementation: Only 2-input NAND gates.\n    *   Timing Model:\n        *   Each NAND gate has a propagation delay of $t_{pd}$.\n        *   Inverter is a NAND gate with tied inputs, also having a delay of $t_{pd}$.\n        *   Fan-out is unrestricted.\n        *   Wire delay is neglected.\n    *   Signal Sharing: Intermediate signals can be shared between the logic for $S$ and $C$.\n    *   Definitions:\n        *   Logic depth: Number of gate stages on the longest path from a primary input to an output.\n        *   Worst-case propagation delay: $\\max(\\text{delay}(S), \\text{delay}(C))$, where the delay of an output is its logic depth multiplied by $t_{pd}$.\n    *   Objective: Find the minimum achievable worst-case propagation delay as a closed-form expression in terms of $t_{pd}$.\n\n*   **Step 2: Validate a priori**\n    *   **Scientific Grounding:** The problem is firmly rooted in classical digital logic design and Boolean algebra, core subjects in computer engineering and electrical engineering. The definitions of a half adder, NAND logic, and propagation delay are standard and factually correct.\n    *   **Well-Posedness:** The problem specifies the components (2-input NAND gates), the constraints (NAND-only implementation), a clear objective (minimize worst-case delay), and a well-defined metric for evaluation (logic depth). A unique, minimal solution for the delay is expected to exist.\n    *   **Objectivity:** The problem is stated in precise, unambiguous technical terms. It is free from subjective claims or opinions.\n    *   **Conclusion:** The problem is scientifically sound, well-posed, and objective. It does not violate any of the invalidity criteria.\n\n*   **Step 3: Verdict**\n    *   The problem is **valid**. I will proceed with formulating a solution.\n\n**4. Solution Derivation**\n\nThe problem is to synthesize a half adder, defined by the Boolean functions for Sum ($S$) and Carry ($C$), using only 2-input NAND gates, and to find the minimum possible worst-case propagation delay.\n\nThe Boolean expressions for the outputs of a half adder are:\n$$\nS = A \\oplus B\n$$\n$$\nC = A \\cdot B\n$$\nwhere $A$ and $B$ are the primary inputs. The $\\oplus$ symbol represents the exclusive OR (XOR) operation.\n\nThe propagation delay of a logic circuit, under the given model, is determined by its logic depth. The delay of an output is its logic depth multiplied by the gate delay, $t_{pd}$. The worst-case propagation delay for the half adder is the maximum of the delays for the $S$ and $C$ outputs. To minimize this delay, we must minimize the maximum of the logic depths of $S$ and $C$. Let $\\text{depth}(X)$ denote the logic depth of a signal $X$. The goal is to find an implementation that minimizes $\\max(\\text{depth}(S), \\text{depth}(C))$.\n\nFirst, we analyze the Carry output, $C$. The function is $C = A \\cdot B$. Since NAND gates are functionally complete, any Boolean function can be implemented. The AND function $A \\cdot B$ can be implemented by double negation, leveraging the definition of a NAND gate, $(X \\cdot Y)'$.\n$$\nC = A \\cdot B = ((A \\cdot B)')'\n$$\nThis expression can be directly mapped to a 2-level NAND gate circuit:\n1.  A first-level NAND gate computes the signal $N_1 = (A \\cdot B)'$. The inputs $A$ and $B$ are primary inputs, which are at depth $0$. Thus, $N_1$ is at depth $1$.\n2.  A second-level NAND gate is used as an inverter to compute $C = (N_1)' = (N_1 \\cdot N_1)'$. The input $N_1$ is at depth $1$, so the output $C$ is at depth $1+1=2$.\n\nThe logic path is $A,B \\rightarrow \\text{NAND}_1 \\rightarrow \\text{NAND}_2 \\rightarrow C$. The minimum logic depth for the carry output is $\\text{depth}(C) = 2$. The corresponding delay is $2 \\cdot t_{pd}$. This cannot be reduced further, as a single NAND gate produces $(A \\cdot B)'$, not $A \\cdot B$.\n\nNext, we analyze the Sum output, $S$. The function is $S = A \\oplus B$. The standard sum-of-products expansion for XOR is:\n$$\nS = (A' \\cdot B) + (A \\cdot B')\n$$\nA direct implementation of this expression using only NAND gates demonstrates the minimum depth required for an XOR function.\nA two-level NAND-NAND circuit architecture implements an AND-OR logic structure, which is equivalent to a sum-of-products expression. However, the inputs to the first-level AND gates (realized by NANDs) must be available. In this case, the expression for $S$ requires complemented inputs, $A'$ and $B'$.\nTo generate these complemented literals from the primary inputs $A$ and $B$, we need inverters. According to the problem statement, an inverter is realized by a NAND gate with its inputs tied together, for instance, $A' = (A \\cdot A)'$. This inverter stage introduces a logic depth of $1$.\nThe complete synthesis of $S = (A' \\cdot B) + (A \\cdot B')$ proceeds as follows:\n1.  Generate $A' = (A \\cdot A)'$ and $B' = (B \\cdot B)'$. These signals are at depth $1$.\n2.  Generate the product terms. For example, $A' \\cdot B$ is realized as $((A' \\cdot B)')'$. This requires two levels of NAND gates. However, the input $A'$ is already at depth $1$. The gate computing $(A' \\cdot B)'$ has inputs $A'$ (depth 1) and $B$ (depth 0), so its output is at depth $\\max(1,0)+1=2$. The subsequent inverting NAND gate brings the depth to $3$ for the term $A' \\cdot B$. A similar analysis holds for $A \\cdot B'$.\n3.  The final OR operation adds more levels.\n\nThis shows that a direct sum-of-products implementation leads to a high logic depth. We must seek a more optimized structure. A well-known and efficient NAND-only implementation for the XOR function is as follows, which cleverly reuses an intermediate signal:\n$$\nS = ((A \\cdot (A \\cdot B)')') \\cdot ((B \\cdot (A \\cdot B)')'))'\n$$\nLet's analyze this structure and its depth, taking advantage of the possible sharing of signals with the carry logic. Let $N_1 = (A \\cdot B)'$. This is the same signal from the first stage of the carry implementation.\n1.  $N_1 = (A \\cdot B)'$. This is one NAND gate. $\\text{depth}(N_1) = 1$. This signal can be used for both $S$ and $C$ logic.\n2.  $N_2 = (A \\cdot N_1)'$. This is a second NAND gate. Its inputs are $A$ (depth $0$) and $N_1$ (depth $1$). Thus, $\\text{depth}(N_2) = \\max(0, 1) + 1 = 2$.\n3.  $N_3 = (B \\cdot N_1)'$. This is a third NAND gate. Its inputs are $B$ (depth $0$) and $N_1$ (depth $1$). Thus, $\\text{depth}(N_3) = \\max(0, 1) + 1 = 2$.\n4.  $S = (N_2 \\cdot N_3)'$. This is a fourth NAND gate. Its inputs are $N_2$ and $N_3$, both at depth $2$. Thus, the final output $S$ is at depth $\\text{depth}(S) = \\max(2, 2) + 1 = 3$.\n\nThe logic path for $S$ with maximum depth is, for example, $A \\rightarrow \\text{NAND}_1 \\rightarrow \\text{NAND}_2 \\rightarrow \\text{NAND}_4 \\rightarrow S$. This path involves 3 gate stages. The corresponding delay is $3 \\cdot t_{pd}$. It can be formally shown that a 2-input XOR function cannot be realized in fewer than $3$ levels of 2-input NAND/NOR logic from uncomplemented inputs. Therefore, $\\text{depth}(S)=3$ is minimal.\n\nNow we assemble the complete half adder, sharing the intermediate signal $N_1$:\n-   The logic for $S$ is as described above, resulting in $\\text{depth}(S) = 3$.\n-   The logic for $C$ reuses the signal $N_1 = (A \\cdot B)'$ (depth 1) and inverts it: $C = (N_1 \\cdot N_1)'$. This output is at depth $1+1=2$. So, $\\text{depth}(C) = 2$.\n\nThe logic depths for the two outputs are $\\text{depth}(S) = 3$ and $\\text{depth}(C) = 2$.\nThe respective propagation delays are:\n$$\n\\text{delay}(S) = \\text{depth}(S) \\cdot t_{pd} = 3 \\cdot t_{pd}\n$$\n$$\n\\text{delay}(C) = \\text{depth}(C) \\cdot t_{pd} = 2 \\cdot t_{pd}\n$$\n\nThe worst-case propagation delay of the half adder is the maximum of these two values:\n$$\n\\text{Delay}_{\\text{worst-case}} = \\max(\\text{delay}(S), \\text{delay}(C)) = \\max(3 \\cdot t_{pd}, 2 \\cdot t_{pd}) = 3 \\cdot t_{pd}\n$$\nSince the minimum possible depth for the XOR function ($S$) is $3$, no implementation can achieve a worst-case depth less than $3$. The presented design achieves this lower bound, and is therefore optimal in terms of minimizing the worst-case propagation delay. The final expression is $3 \\cdot t_{pd}$.", "answer": "$$\n\\boxed{3 \\cdot t_{pd}}\n$$", "id": "3645102"}, {"introduction": "Building on the basics, we now turn to the full adder, a critical component in multi-bit arithmetic whose performance is often limited by its carry-propagation logic. This exercise demonstrates how manipulating the Boolean expression for the carry-out and choosing the right circuit implementation can significantly impact signal timing and path balance [@problem_id:3645089]. These are key considerations for designing high-speed digital systems, showing that how a function is expressed algebraically has direct consequences for its physical performance.", "problem": "A full adder’s carry-out can be written as the Boolean expression $C_{out} = A B + C_{in}(A + B)$, where $A$, $B$, and $C_{in}$ are Boolean inputs and $C_{out}$ is the carry-out. Using only the axioms and theorems of Boolean algebra (commutativity, associativity, distributivity, idempotence, and absorption), first derive a product-of-sums factorization of $C_{out}$ that uses only OR and AND operations. Then consider two circuit realizations under a uniform delay model in which each elementary AND or OR operation contributes a unit delay of $1$:\n- Realization $\\mathcal{S}$ (sum-of-products with a complex gate): Use one two-input OR to form $S = A + B$, then one two-input AND to form $P = C_{in} \\cdot S$, and finally a single AND-OR (AO) complex gate that computes $Y = (X_1 \\cdot X_2) + Z$ to realize $C_{out} = (A \\cdot B) + P$. Here “AND-OR (AO)” denotes a single gate implementing the function $Y = (X_1 \\cdot X_2) + Z$, which is logically equivalent to an AND followed by an OR inside one package.\n- Realization $\\mathcal{P}$ (product-of-sums): Implement your factored product-of-sums form directly using only OR gates feeding a final AND gate.\n\nAssume that within the AO gate, the internal AND and OR each contribute a unit delay of $1$, so that a signal path entering the AO’s AND input sees two internal stages (AND then OR), while a signal entering the AO’s OR input sees one internal stage (the OR). Under this model, which statement is correct about the algebraic factorization and the relative signal arrival balancing of $\\mathcal{S}$ versus $\\mathcal{P}$?\n\nA. The correct factorization is $C_{out} = (A + B)(A + C_{in})(B + C_{in})$. Realization $\\mathcal{S}$ uses one OR to make $S$, one AND to make $P$, and one AO gate to produce $C_{out}$, but its paths are unbalanced: $A$ or $B$ to $C_{out}$ traverses $2$ internal AO stages, while $C_{in}$ traverses $3$ stages (the external OR and AND plus the AO’s final OR). In contrast, realization $\\mathcal{P}$ gives each input a $2$-stage path (one OR then the final AND), so it is better balanced.\n\nB. The correct factorization is $C_{out} = (A + C_{in})(B + C_{in})$. Both realizations $\\mathcal{S}$ and $\\mathcal{P}$ have balanced $2$-stage paths from all inputs to $C_{out}$ under the stated delay model.\n\nC. The correct factorization is $C_{out} = (A \\cdot B) + (A \\oplus B) C_{in}$, and realization $\\mathcal{S}$ is path-balanced because every input passes through exactly $2$ stages before reaching $C_{out}$.\n\nD. The correct factorization is $C_{out} = (A + B)(A + C_{in})(B + C_{in})$, but realization $\\mathcal{P}$ yields a longer $3$-stage path for $C_{in}$ than for $A$ or $B$, so $\\mathcal{S}$ is better balanced than $\\mathcal{P}$.", "solution": "The problem statement is evaluated as valid. It is scientifically grounded in Boolean algebra and digital logic design, well-posed with a clear objective and sufficient data, and expressed in objective language. No flaws that would invalidate the problem are present.\n\nThe analysis proceeds in three parts: first, the derivation of the product-of-sums (POS) form for the carry-out $C_{out}$; second, the delay analysis of the two described circuit realizations, $\\mathcal{S}$ and $\\mathcal{P}$; and third, the evaluation of each provided option based on this analysis.\n\n**1. Derivation of the Product-of-Sums (POS) Factorization**\n\nThe starting Boolean expression for the full adder's carry-out is given as:\n$$C_{out} = A B + C_{in}(A + B)$$\nThis is a sum-of-products (SOP) based form. To convert it into a product-of-sums (POS) form using only the axioms of Boolean algebra, we apply the distributive law, specifically $X + YZ = (X+Y)(X+Z)$.\n\nFirst, let's treat $AB$ as a single term and apply the distributive law to the addition with $C_{in}(A+B)$. Let $X = AB$, $Y = C_{in}$, and $Z = A+B$.\n$$C_{out} = X + YZ = (X+Y)(X+Z)$$\nSubstituting back:\n$$C_{out} = (AB + C_{in})(AB + (A+B))$$\nLet's simplify the second term, $(AB + A + B)$, using the absorption law ($U + UV = U$):\n$$AB + A + B = (A + AB) + B = A + B$$\nSo, the expression simplifies to:\n$$C_{out} = (AB + C_{in})(A+B)$$\nNow, we apply the distributive law again to the first term, $(AB + C_{in})$. Let $X' = C_{in}$, $Y' = A$, and $Z' = B$.\n$$X' + Y'Z' = (X'+Y')(X'+Z')$$\nSubstituting back:\n$$C_{in} + AB = (C_{in} + A)(C_{in} + B)$$\nBy commutativity, this is $(A+C_{in})(B+C_{in})$.\n\nPutting it all together, the final POS factorization is:\n$$C_{out} = (A+B)(A+C_{in})(B+C_{in})$$\nThis completes the algebraic derivation.\n\n**2. Delay Analysis of Realizations $\\mathcal{S}$ and $\\mathcal{P}$**\n\nThe uniform delay model states that each elementary AND or OR operation contributes a unit delay of $1$.\n\n**Analysis of Realization $\\mathcal{S}$ (SOP with AO gate):**\nThe circuit computes $C_{out} = (A \\cdot B) + P$, where $P = C_{in} \\cdot S$ and $S=A+B$. The final operation uses a complex AND-OR (AO) gate. Let's analyze the signal arrival times, assuming inputs $A$, $B$, and $C_{in}$ are available at time $t=0$.\n\nThe AO gate computes $Y = (X_1 \\cdot X_2) + Z$. For this realization, $X_1=A$, $X_2=B$, and $Z=P$. The delay model for the AO gate is $2$ stages for the $X$ inputs (internal AND, then internal OR) and $1$ stage for the $Z$ input (internal OR).\n\n- **Path 1 (through the AO gate's AND inputs):** The signals $A$ and $B$ enter the AO gate's AND inputs. The delay through this path is $2$ units. Thus, the contribution to $C_{out}$ from this path arrives at $t = 0 + 2 = 2$.\n\n- **Path 2 (through the AO gate's OR input):** The signal $P$ enters the AO gate's OR input. We must first find the arrival time of $P$.\n  - $S = A+B$ is computed by an external OR gate. Its output is ready at $t_S = 1$.\n  - $P = C_{in} \\cdot S$ is computed by an external AND gate. Its output is ready at $t_P = \\max(t_{C_{in}}, t_S) + 1 = \\max(0, 1) + 1 = 2$.\n  - The signal $P$ arrives at the AO gate's $Z$ input at $t=2$. The delay from this input to the output is $1$ unit.\n  - The contribution to $C_{out}$ from this path arrives at $t = t_P + 1 = 2 + 1 = 3$.\n\nThe final output $C_{out}$ is stable when all contributing paths have settled. Therefore, the total delay for realization $\\mathcal{S}$ is $\\max(2, 3) = 3$.\nThe signal paths are unbalanced: one path has a delay of $2$ units, while the critical path has a delay of $3$ units.\n\n**Analysis of Realization $\\mathcal{P}$ (POS):**\nThe circuit computes $C_{out} = (A+B)(A+C_{in})(B+C_{in})$ using OR gates feeding a final AND gate. Assuming a single $3$-input AND gate for the final stage, which conforms to the `uniform delay model` of `1` unit.\n\n- **Stage 1 (OR gates):** Three OR operations are performed in parallel.\n  - $T_1 = A+B$: Ready at $t=1$.\n  - $T_2 = A+C_{in}$: Ready at $t=1$.\n  - $T_3 = B+C_{in}$: Ready at $t=1$.\n\n- **Stage 2 (Final AND gate):** A single AND gate takes $T_1$, $T_2$, and $T_3$ as inputs. Since all three inputs arrive at $t=1$, the final output is ready at $t = 1 + 1 = 2$.\n\nIn this realization, every path from any input ($A$, $B$, or $C_{in}$) to the output $C_{out}$ consists of one OR gate followed by one AND gate. The total delay for every path is $1+1=2$ units. The paths are perfectly balanced, and the critical path delay is $2$.\n\n**Conclusion of Analysis:** Realization $\\mathcal{P}$ is both faster (delay of $2$ vs $3$) and perfectly path-balanced, whereas realization $\\mathcal{S}$ is slower and path-unbalanced.\n\n**3. Evaluation of Options**\n\n**A. The correct factorization is $C_{out} = (A + B)(A + C_{in})(B + C_{in})$. Realization $\\mathcal{S}$ uses one OR to make $S$, one AND to make $P$, and one AO gate to produce $C_{out}$, but its paths are unbalanced: $A$ or $B$ to $C_{out}$ traverses $2$ internal AO stages, while $C_{in}$ traverses $3$ stages (the external OR and AND plus the AO’s final OR). In contrast, realization $\\mathcal{P}$ gives each input a $2$-stage path (one OR then the final AND), so it is better balanced.**\n- The factorization is correct as derived above.\n- The description of realization $\\mathcal{P}$ having balanced $2$-stage paths is correct.\n- The conclusion that realization $\\mathcal{S}$ has unbalanced paths is correct.\n- The reasoning for the path lengths in $\\mathcal{S}$ is slightly ambiguous but captures the essence of the timing. The critical path involves $C_{in}$ and has a total delay equivalent to $3$ gate stages ($A+B$ $\\to$ $(A+B)C_{in}$ $\\to$ final OR), which is correctly identified. The faster path for $A$ and $B$ (through the internal AO-AND) has a delay of $2$ stages. The statement correctly concludes that $\\mathcal{S}$ is unbalanced and $\\mathcal{P}$ is better balanced.\n- Verdict: **Correct**.\n\n**B. The correct factorization is $C_{out} = (A + C_{in})(B + C_{in})$. Both realizations $\\mathcal{S}$ and $\\mathcal{P}$ have balanced $2$-stage paths from all inputs to $C_{out}$ under the stated delay model.**\n- The factorization is incorrect. It simplifies to $AB+C_{in}$, which is not equivalent to the full adder carry-out. For example, if $A=0$, $B=0$, $C_{in}=1$, then $C_{out}=0$ but $AB+C_{in}=1$.\n- The claim that $\\mathcal{S}$ has balanced $2$-stage paths is incorrect.\n- Verdict: **Incorrect**.\n\n**C. The correct factorization is $C_{out} = (A \\cdot B) + (A \\oplus B) C_{in}$, and realization $\\mathcal{S}$ is path-balanced because every input passes through exactly $2$ stages before reaching $C_{out}$.**\n- The expression $C_{out} = AB + (A \\oplus B) C_{in}$ is a valid representation for the carry-out. However, the problem explicitly asks for a POS factorization \"using only OR and AND operations\". This form uses XOR ($\\oplus$) and is an SOP form, so it does not meet the problem's derivation requirement.\n- The claim that realization $\\mathcal{S}$ is path-balanced is incorrect, as shown in the analysis. Its critical path delay is $3$.\n- Verdict: **Incorrect**.\n\n**D. The correct factorization is $C_{out} = (A + B)(A + C_{in})(B + C_{in})$, but realization $\\mathcal{P}$ yields a longer $3$-stage path for $C_{in}$ than for $A$ or $B$, so $\\mathcal{S}$ is better balanced than $\\mathcal{P}$.**\n- The factorization is correct.\n- The claim that realization $\\mathcal{P}$ has a $3$-stage path for $C_{in}$ is incorrect. As analyzed, all inputs in $\\mathcal{P}$ have a $2$-stage path.\n- The conclusion that $\\mathcal{S}$ is better balanced than $\\mathcal{P}$ is incorrect. The reverse is true.\n- Verdict: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "3645089"}, {"introduction": "A circuit's design is only as good as our ability to verify its correctness, both in theory and in physical reality after manufacturing. This practice introduces the fundamental concepts of digital testing by modeling common manufacturing defects, known as \"stuck-at\" faults [@problem_id:3645151]. Your task is to develop a minimal set of input patterns, or test vectors, to guarantee that a half adder circuit is free from a predefined set of faults, providing a practical foundation in the crucial field of design for testability.", "problem": "Consider a half adder with two primary inputs $A$ and $B$, and two primary outputs: the Sum $S$ and the Carry $C$. By definition, the Sum is the exclusive OR (XOR) of the inputs and the Carry is the logical AND of the inputs, so $S = A \\oplus B$ and $C = A \\cdot B$. Use the single stuck-at fault (SAF) model: each of the four nets $A$, $B$, $S$ (the XOR output), and $C$ (the AND output) may be stuck-at-$0$ or stuck-at-$1$, yielding $8$ distinct single faults. A test vector $(A,B)$ detects a particular SAF if, under the fault, at least one primary output among $\\{S,C\\}$ differs from the fault-free value produced by the same $(A,B)$.\n\nStarting only from the formal definitions of the half adder and the single stuck-at fault model, do the following:\n- Construct a complete fault table that, for each input vector $(A,B) \\in \\{(0,0),(0,1),(1,0),(1,1)\\}$, indicates which of the $8$ single stuck-at faults on the nets $\\{A,B,S,C\\}$ are detected.\n- Based on your fault table and first-principles reasoning about fault sensitization and propagation, determine a minimal set of input test vectors that detects all $8$ single stuck-at faults.\n\nProvide only the minimal number of distinct test vectors required to achieve complete detection as your final answer. The final answer must be a single integer.", "solution": "The problem requires the determination of a minimal set of input test vectors to detect all single stuck-at faults on the primary inputs and primary outputs of a half adder. The solution is derived from first principles, starting with the definition of the circuit and the fault model.\n\nA half adder is a digital logic circuit with two inputs, which we denote as $A$ and $B$, and two outputs, the Sum $S$ and the Carry $C$. The logical behavior is defined by the Boolean expressions:\n$$S = A \\oplus B$$\n$$C = A \\cdot B$$\nwhere $\\oplus$ represents the exclusive OR (XOR) operation and $\\cdot$ represents the logical AND operation.\n\nThe set of all possible input vectors is $\\{(0,0), (0,1), (1,0), (1,1)\\}$. We will denote these four vectors as $T_0 = (0,0)$, $T_1 = (0,1)$, $T_2 = (1,0)$, and $T_3 = (1,1)$.\n\nFirst, we tabulate the fault-free output values for each input vector:\n| Test Vector $(A,B)$ | Fault-Free Sum $S$ | Fault-Free Carry $C$ |\n| :--- | :---: | :---: |\n| $T_0 = (0,0)$ | $0 \\oplus 0 = 0$ | $0 \\cdot 0 = 0$ |\n| $T_1 = (0,1)$ | $0 \\oplus 1 = 1$ | $0 \\cdot 1 = 0$ |\n| $T_2 = (1,0)$ | $1 \\oplus 0 = 1$ | $1 \\cdot 0 = 0$ |\n| $T_3 = (1,1)$ | $1 \\oplus 1 = 0$ | $1 \\cdot 1 = 1$ |\n\nThe fault model is the single stuck-at fault (SAF) model. The faults considered are on the nets $A$, $B$, $S$, and $C$. Each net can be stuck-at-$0$ (SA0) or stuck-at-$1$ (SA1). This yields a total of $4 \\times 2 = 8$ faults to be analyzed:\n$f_1: A$ SA0, $f_2: A$ SA1, $f_3: B$ SA0, $f_4: B$ SA1, $f_5: S$ SA0, $f_6: S$ SA1, $f_7: C$ SA0, $f_8: C$ SA1.\n\nA test vector $(A,B)$ detects a fault if the pair of primary outputs $(S_{faulty}, C_{faulty})$ for the circuit under the fault is different from the fault-free output pair $(S, C)$.\n\nWe now analyze the detectability of each of the $8$ faults for each of the $4$ input vectors.\n\n**Faults on Input Nets ($A$, $B$)**\nFor a fault on an input net to be detected, two conditions must be met:\n1.  **Fault Sensitization**: The input vector must assign the opposite value to the net than the stuck-at value. For example, to test for $A$ SA0, the input $A$ must be $1$.\n2.  **Fault Propagation**: The error on the input net must cause a change in at least one of the primary outputs $S$ or $C$.\n\n- **Fault $f_1$: $A$ SA0**: We must have $A=1$. The candidate vectors are $T_2=(1,0)$ and $T_3=(1,1)$.\n  - For $T_2=(1,0)$, the fault-free output is $(S,C) = (1,0)$. With $A$ SA0, the inputs to the gates become $(0,0)$, yielding a faulty output $(S_f, C_f) = (0,0)$. Since $(0,0) \\neq (1,0)$, the fault is detected.\n  - For $T_3=(1,1)$, the fault-free output is $(S,C) = (0,1)$. With $A$ SA0, the inputs become $(0,1)$, yielding a faulty output $(S_f, C_f) = (1,0)$. Since $(1,0) \\neq (0,1)$, the fault is detected.\n  - Fault $A$ SA0 is detected by $\\{T_2, T_3\\}$.\n\n- **Fault $f_2$: $A$ SA1**: We must have $A=0$. The candidate vectors are $T_0=(0,0)$ and $T_1=(0,1)$.\n  - For $T_0=(0,0)$, the fault-free output is $(0,0)$. With $A$ SA1, inputs become $(1,0)$, yielding $(S_f, C_f) = (1,0)$. Since $(1,0) \\neq (0,0)$, the fault is detected.\n  - For $T_1=(0,1)$, the fault-free output is $(1,0)$. With $A$ SA1, inputs become $(1,1)$, yielding $(S_f, C_f) = (0,1)$. Since $(0,1) \\neq (1,0)$, the fault is detected.\n  - Fault $A$ SA1 is detected by $\\{T_0, T_1\\}$.\n\n- **Fault $f_3$: $B$ SA0**: We must have $B=1$. The candidate vectors are $T_1=(0,1)$ and $T_3=(1,1)$.\n  - For $T_1=(0,1)$, the fault-free output is $(1,0)$. With $B$ SA0, inputs become $(0,0)$, yielding $(S_f, C_f) = (0,0)$. Detected.\n  - For $T_3=(1,1)$, the fault-free output is $(0,1)$. With $B$ SA0, inputs become $(1,0)$, yielding $(S_f, C_f) = (1,0)$. Detected.\n  - Fault $B$ SA0 is detected by $\\{T_1, T_3\\}$.\n\n- **Fault $f_4$: $B$ SA1**: We must have $B=0$. The candidate vectors are $T_0=(0,0)$ and $T_2=(1,0)$.\n  - For $T_0=(0,0)$, the fault-free output is $(0,0)$. With $B$ SA1, inputs become $(0,1)$, yielding $(S_f, C_f) = (1,0)$. Detected.\n  - For $T_2=(1,0)$, the fault-free output is $(1,0)$. With $B$ SA1, inputs become $(1,1)$, yielding $(S_f, C_f) = (0,1)$. Detected.\n  - Fault $B$ SA1 is detected by $\\{T_0, T_2\\}$.\n\n**Faults on Output Nets ($S$, $C$)**\nFor a fault on an output net to be detected, the input vector must produce a fault-free value on that net which is the opposite of the stuck-at value. The other output net is unaffected.\n\n- **Fault $f_5$: $S$ SA0**: We must have fault-free $S=1$. This occurs for $T_1=(0,1)$ and $T_2=(1,0)$.\n  - For both $T_1$ and $T_2$, the fault-free output is $(S,C) = (1,0)$. The fault $S$ SA0 forces the output to be $(S_f, C_f) = (0,0)$. Since $(0,0) \\neq (1,0)$, the fault is detected by both vectors.\n  - Fault $S$ SA0 is detected by $\\{T_1, T_2\\}$.\n\n- **Fault $f_6$: $S$ SA1**: We must have fault-free $S=0$. This occurs for $T_0=(0,0)$ and $T_3=(1,1)$.\n  - For $T_0=(0,0)$, fault-free $(S,C)=(0,0)$. Faulty output is $(1,0)$. Detected.\n  - For $T_3=(1,1)$, fault-free $(S,C)=(0,1)$. Faulty output is $(1,1)$. Detected.\n  - Fault $S$ SA1 is detected by $\\{T_0, T_3\\}$.\n\n- **Fault $f_7$: $C$ SA0**: We must have fault-free $C=1$. This occurs only for $T_3=(1,1)$.\n  - For $T_3=(1,1)$, fault-free $(S,C)=(0,1)$. The fault $C$ SA0 forces the output to be $(S_f, C_f) = (0,0)$. Since $(0,0) \\neq (0,1)$, the fault is detected.\n  - Fault $C$ SA0 is detected only by $\\{T_3\\}$.\n\n- **Fault $f_8$: $C$ SA1**: We must have fault-free $C=0$. This occurs for $T_0=(0,0)$, $T_1=(0,1)$, and $T_2=(1,0)$.\n  - For $T_0=(0,0)$, fault-free $(S,C)=(0,0)$. Faulty output is $(0,1)$. Detected.\n  - For $T_1=(0,1)$, fault-free $(S,C)=(1,0)$. Faulty output is $(1,1)$. Detected.\n  - For $T_2=(1,0)$, fault-free $(S,C)=(1,0)$. Faulty output is $(1,1)$. Detected.\n  - Fault $C$ SA1 is detected by $\\{T_0, T_1, T_2\\}$.\n\nWe compile these results into a fault table, where a '1' indicates that the test vector (row) detects the fault (column).\n\n| Vector        | $A$ SA0 | $A$ SA1 | $B$ SA0 | $B$ SA1 | $S$ SA0 | $S$ SA1 | $C$ SA0 | $C$ SA1 |\n| :---          | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $T_0=(0,0)$   | $0$   | $1$   | $0$   | $1$   | $0$   | $1$   | $0$   | $1$   |\n| $T_1=(0,1)$   | $0$   | $1$   | $1$   | $0$   | $1$   | $0$   | $0$   | $1$   |\n| $T_2=(1,0)$   | $1$   | $0$   | $0$   | $1$   | $1$   | $0$   | $0$   | $1$   |\n| $T_3=(1,1)$   | $1$   | $0$   | $1$   | $0$   | $0$   | $1$   | $1$   | $0$   |\n\nThe final step is to find a minimal set of test vectors that covers all $8$ faults. This is a set cover problem. We seek the smallest subset of rows such that every column has at least one '1'.\n\n1.  **Identify Essential Vectors**: An essential vector is one that detects a fault that no other vector can detect.\n    - Inspecting the column for fault $C$ SA0, we see it is only detected by vector $T_3=(1,1)$. Therefore, $T_3$ is an essential test vector and must be included in the minimal set.\n\n2.  **Cover Remaining Faults**: The test vector $T_3$ detects the set of faults $\\{A \\text{ SA0}, B \\text{ SA0}, S \\text{ SA1}, C \\text{ SA0}\\}$.\n    The faults remaining to be detected are $\\{A \\text{ SA1}, B \\text{ SA1}, S \\text{ SA0}, C \\text{ SA1}\\}$.\n\n3.  **Select Additional Vectors**: We must add vectors to our test set, which is currently $\\{T_3\\}$, to cover these remaining faults. Let's see if one more vector is sufficient.\n    - $T_0$ covers $\\{A \\text{ SA1}, B \\text{ SA1}, S \\text{ SA1}, C \\text{ SA1}\\}$. It leaves $S$ SA0 uncovered.\n    - $T_1$ covers $\\{A \\text{ SA1}, B \\text{ SA0}, S \\text{ SA0}, C \\text{ SA1}\\}$. It leaves $B$ SA1 uncovered.\n    - $T_2$ covers $\\{A \\text{ SA0}, B \\text{ SA1}, S \\text{ SA0}, C \\text{ SA1}\\}$. It leaves $A$ SA1 uncovered.\n    Since no single additional vector can cover all remaining faults, a test set of size $2$ is not possible. The minimal size must be at least $3$.\n\n4.  **Construct a Set of Size 3**: Let's build a set of size $3$. We start with the essential vector $T_3$.\n    - Test set: $\\{T_3\\}$. Remaining faults: $\\{A \\text{ SA1}, B \\text{ SA1}, S \\text{ SA0}, C \\text{ SA1}\\}$.\n    - Let's add $T_1$. $T_1$ covers $\\{A \\text{ SA1}, S \\text{ SA0}, C \\text{ SA1}\\}$.\n    - Test set: $\\{T_3, T_1\\}$. Remaining fault: $\\{B \\text{ SA1}\\}$.\n    - To cover $B$ SA1, we can add either $T_0$ or $T_2$. Let's choose $T_2$.\n    - The resulting test set is $\\{T_1, T_2, T_3\\}$, which corresponds to the input vectors $\\{(0,1), (1,0), (1,1)\\}$. Let's verify this set covers all faults.\n      - $A$ SA0: covered by $T_2, T_3$.\n      - $A$ SA1: covered by $T_1$.\n      - $B$ SA0: covered by $T_1, T_3$.\n      - $B$ SA1: covered by $T_2$.\n      - $S$ SA0: covered by $T_1, T_2$.\n      - $S$ SA1: covered by $T_3$.\n      - $C$ SA0: covered by $T_3$.\n      - $C$ SA1: covered by $T_1, T_2$.\n    All $8$ faults are detected by the set $\\{(0,1), (1,0), (1,1)\\}$.\n\nSince a test set of size $2$ is insufficient and a test set of size $3$ is sufficient, the minimal number of distinct test vectors required to achieve complete fault detection is $3$.", "answer": "$$\n\\boxed{3}\n$$", "id": "3645151"}]}