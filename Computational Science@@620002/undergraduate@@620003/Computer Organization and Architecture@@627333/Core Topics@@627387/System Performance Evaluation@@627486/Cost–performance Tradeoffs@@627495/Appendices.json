{"hands_on_practices": [{"introduction": "This first practice explores a fundamental tradeoff at the Instruction Set Architecture (ISA) level. We will quantitatively compare conditional branching, which risks costly pipeline flushes on misprediction, with predicated execution, which avoids this risk at the cost of executing potentially unnecessary instructions. This exercise will help you master the use of expected value to determine the performance crossover point between two competing architectural strategies [@problem_id:3630750].", "problem": "A processor designer must decide when to replace a conditional branch with Instruction Set Architecture (ISA)-level predicated execution. The processor is an in-order, single-issue pipeline in which each decoded instruction (arithmetic or logical operation, comparison, move, or branch) occupies exactly $1$ cycle when it executes, absent stalls. A mispredicted branch incurs an additional pipeline recovery cost of $M$ cycles. The branch instruction itself still consumes $1$ cycle whether the prediction is correct or not. Predicated instructions execute regardless of their predicate value; when the predicate is false, the instruction’s architectural effects are suppressed, but the instruction still consumes its $1$ cycle of execution resources.\n\nConsider a particular conditional region with two paths:\n- The “true” path contains $n_{T}$ data-manipulating instructions.\n- The “false” path contains $n_{F}$ data-manipulating instructions.\n\nA separate compare instruction computes the condition flag for both designs and costs $1$ cycle. With branching, a subsequent branch instruction selects a single path to execute; with predication, the branch is eliminated and both paths’ data instructions are executed as predicated instructions. Let $q$ denote the dynamic probability that the true path is the architecturally correct path, and let $p$ denote the dynamic probability that the branch predictor’s direction prediction is correct on this branch. Assume that $p$ is an empirical predictor accuracy that is independent of $q$ for the purpose of this analysis.\n\nFor a particular workload, suppose $n_{T} = 10$, $n_{F} = 4$, $q = 0.5$, and the misprediction recovery cost is $M = 15$ cycles. Using only first principles of expected value and cycle accounting, derive the predictor accuracy threshold $p^{\\star}$ at which the expected cycle count of branching equals that of predication for one dynamic instance of this conditional region. Express your final $p^{\\star}$ as a decimal rounded to four significant figures. The answer must be a single number with no units.", "solution": "The problem is valid as it is scientifically grounded in the principles of computer architecture, well-posed with all necessary information provided, and objective in its language. We can proceed to derive the predictor accuracy threshold $p^{\\star}$.\n\nThe task is to find the branch predictor accuracy, $p^{\\star}$, at which the expected number of execution cycles for a conditional region is the same for two implementation strategies: conditional branching and predicated execution.\n\nFirst, let us determine the total cycle count for the predicated execution scheme, which we will denote as $C_{\\text{pred}}$.\nAccording to the problem statement, this scheme involves one compare instruction, followed by the execution of all data-manipulating instructions from both the \"true\" and \"false\" paths as predicated instructions. Each instruction, whether its predicate is true or false, consumes $1$ cycle. Therefore, the total cycle count is deterministic and is the sum of the number of instructions executed.\nThe number of instructions includes:\n1.  The compare instruction: $1$ cycle.\n2.  The \"true\" path instructions: $n_T$ cycles.\n3.  The \"false\" path instructions: $n_F$ cycles.\n\nThus, the total cycle count for predicated execution is:\n$$C_{\\text{pred}} = 1 + n_T + n_F$$\n\nNext, we determine the expected cycle count for the conditional branching scheme, which we denote as $E_{\\text{branch}}$.\nThis cost is not deterministic; it depends on which path is taken and whether the branch predictor is correct. The total expected cost is the sum of the expected costs of its constituent parts:\n1.  The compare instruction cost: $1$ cycle, always incurred.\n2.  The branch instruction cost: $1$ cycle, always incurred.\n3.  The cost of executing the instructions on the selected path. The \"true\" path, with $n_T$ instructions, is executed with probability $q$. The \"false\" path, with $n_F$ instructions, is executed with probability $(1-q)$. The expected number of cycles for path execution is therefore $q \\cdot n_T + (1-q) \\cdot n_F$.\n4.  The pipeline recovery cost due to a mispredicted branch. A misprediction occurs with probability $(1-p)$ and incurs an additional penalty of $M$ cycles. The expected penalty is $(1-p) M$.\n\nSumming these components, the total expected cycle count for the branching scheme is:\n$$E_{\\text{branch}} = 1 + 1 + \\left(q \\cdot n_T + (1-q) \\cdot n_F\\right) + (1-p) M$$\n$$E_{\\text{branch}} = 2 + q \\cdot n_T + (1-q) \\cdot n_F + (1-p) M$$\n\nThe problem asks for the predictor accuracy threshold $p^{\\star}$ where the costs are equal. We set $C_{\\text{pred}} = E_{\\text{branch}}$ and solve for $p = p^{\\star}$:\n$$1 + n_T + n_F = 2 + q \\cdot n_T + (1-q) \\cdot n_F + (1-p^{\\star}) M$$\n\nTo solve for $p^{\\star}$, we first isolate the term containing it:\n$$(1-p^{\\star}) M = (1 + n_T + n_F) - (2 + q \\cdot n_T + (1-q) \\cdot n_F)$$\n$$(1-p^{\\star}) M = 1 + n_T + n_F - 2 - q \\cdot n_T - n_F + q \\cdot n_F$$\n$$(1-p^{\\star}) M = n_T - q \\cdot n_T + q \\cdot n_F - 1$$\n$$(1-p^{\\star}) M = n_T(1-q) + q \\cdot n_F - 1$$\n\nNow, we can express $p^{\\star}$:\n$$1 - p^{\\star} = \\frac{n_T(1-q) + q \\cdot n_F - 1}{M}$$\n$$p^{\\star} = 1 - \\frac{n_T(1-q) + q \\cdot n_F - 1}{M}$$\n\nThe problem provides the following specific values: $n_T = 10$, $n_F = 4$, $q = 0.5$, and $M = 15$. We substitute these values into the derived expression for $p^{\\star}$:\n$$p^{\\star} = 1 - \\frac{10(1-0.5) + 4(0.5) - 1}{15}$$\n$$p^{\\star} = 1 - \\frac{10(0.5) + 4(0.5) - 1}{15}$$\n$$p^{\\star} = 1 - \\frac{5 + 2 - 1}{15}$$\n$$p^{\\star} = 1 - \\frac{6}{15}$$\n$$p^{\\star} = 1 - \\frac{2}{5}$$\n$$p^{\\star} = 1 - 0.4$$\n$$p^{\\star} = 0.6$$\n\nThe problem requires the answer as a decimal rounded to four significant figures.\n$$p^{\\star} = 0.6000$$", "answer": "$$\\boxed{0.6000}$$", "id": "3630750"}, {"introduction": "Moving from the ISA to microarchitecture, this problem focuses on the design of a single crucial component: the L1 data cache. You will evaluate different cache replacement policies, balancing their effectiveness in reducing miss rates against their implementation complexity, which impacts circuit delay and silicon area. This practice introduces the concept of a composite objective function, a powerful tool for making design choices when performance, cost, and physical constraints all compete [@problem_id:3630761].", "problem": "A processor uses a Level-1 (L1) data cache that is $8$-way set-associative. The microarchitecture must maintain a single-cycle L1 hit time budget of $t_{L1} = 1.00$ cycles. The baseline tag-compare-and-data-array path without replacement-policy logic has a latency of $0.88$ cycles. Three candidate replacement policies are under consideration: Least Recently Used (LRU), pseudo-Least Recently Used (pLRU), and Re-Reference Interval Prediction (RRIP). Each policy adds a fixed additional logic delay to the baseline path and consumes a different silicon area overhead. The additional logic delays are: LRU adds $0.18$ cycles, pLRU adds $0.07$ cycles, and RRIP adds $0.12$ cycles. Any policy whose total L1 hit time exceeds $t_{L1}$ is disallowed.\n\nOn the target workload, the measured L1 miss rates for these policies (assuming they could be implemented) are: LRU miss rate $0.045$, pLRU miss rate $0.047$, and RRIP miss rate $0.042$. The average L1 miss service time, including all lower-level effects, is $36$ cycles and can be treated as a constant independent of the L1 replacement policy. The silicon area overheads attributable solely to the replacement logic are: LRU area $0.052\\,\\mathrm{mm}^2$, pLRU area $0.019\\,\\mathrm{mm}^2$, and RRIP area $0.037\\,\\mathrm{mm}^2$.\n\nYour goal is to choose a policy under the hit-time constraint and to quantify the cost–performance tradeoff using a single scalar objective that prices area into cycles. Starting from the definition of Average Memory Access Time (AMAT) as the sum of the L1 hit time and the product of the L1 miss rate with the L1 miss service time, define the performance–cost objective as the sum of AMAT and an area-pricing term equal to the product of the replacement-logic area overhead and a pricing factor $\\beta = 1.2\\,\\mathrm{cycles}/\\mathrm{mm}^2$. Only policies that satisfy the timing constraint may be considered.\n\nCompute the minimal value of this objective over the feasible policies and report that minimal value. Round your answer to four significant figures. Express the final objective value in cycles.", "solution": "The problem is valid as it is scientifically grounded in the principles of computer architecture, well-posed with a clear objective and constraints, and free of any ambiguities or contradictions. The task is to select a cache replacement policy from a set of candidates—Least Recently Used (LRU), pseudo-Least Recently Used (pLRU), and Re-Reference Interval Prediction (RRIP)—that minimizes a composite performance–cost objective function, subject to a stringent L1 hit time constraint.\n\nFirst, we must identify the set of feasible policies by checking which ones satisfy the L1 hit time budget. The total L1 hit time for a given policy, $T_{hit}$, is the sum of the baseline path latency, $t_{base}$, and the additional logic delay specific to that policy, $t_{delay}$. The constraint is that this total time must not exceed the L1 hit time budget, $t_{L1}$.\nThe given values are:\nBaseline latency, $t_{base} = 0.88$ cycles.\nL1 hit time budget, $t_{L1} = 1.00$ cycles.\nThe additional delays are $t_{delay, LRU} = 0.18$ cycles, $t_{delay, pLRU} = 0.07$ cycles, and $t_{delay, RRIP} = 0.12$ cycles.\n\nWe evaluate the total hit time for each policy:\n1.  For LRU:\n    $T_{hit, LRU} = t_{base} + t_{delay, LRU} = 0.88 + 0.18 = 1.06$ cycles.\n    Since $1.06 > 1.00$, the LRU policy violates the timing constraint and is therefore disallowed.\n\n2.  For pLRU:\n    $T_{hit, pLRU} = t_{base} + t_{delay, pLRU} = 0.88 + 0.07 = 0.95$ cycles.\n    Since $0.95 \\le 1.00$, the pLRU policy is feasible.\n\n3.  For RRIP:\n    $T_{hit, RRIP} = t_{base} + t_{delay, RRIP} = 0.88 + 0.12 = 1.00$ cycles.\n    Since $1.00 \\le 1.00$, the RRIP policy is feasible.\n\nThe set of feasible policies is thus {pLRU, RRIP}. Our goal is to find which of these two policies minimizes the performance–cost objective function, $O$.\n\nThe objective function $O$ is defined as the sum of the Average Memory Access Time (AMAT) and an area-pricing term.\n$O = \\text{AMAT} + (\\text{Area Overhead}) \\times \\beta$\nThe AMAT itself is defined as:\n$\\text{AMAT} = T_{hit} + (\\text{Miss Rate}) \\times (\\text{Miss Service Time})$\nLet $m$ be the miss rate, $T_{miss}$ be the miss service time, $A$ be the area overhead, and $\\beta$ be the pricing factor. The objective function for a policy $P$ is:\n$O_P = T_{hit, P} + (m_P \\times T_{miss}) + (A_P \\times \\beta)$\n\nThe given constants are:\nMiss service time, $T_{miss} = 36$ cycles.\nArea-pricing factor, $\\beta = 1.2\\,\\mathrm{cycles}/\\mathrm{mm}^2$.\n\nNow, we calculate the objective function value for each feasible policy.\n\nFor pLRU:\nThe specific parameters are $m_{pLRU} = 0.047$ and $A_{pLRU} = 0.019\\,\\mathrm{mm}^2$. The hit time is $T_{hit, pLRU} = 0.95$ cycles.\n$O_{pLRU} = T_{hit, pLRU} + (m_{pLRU} \\times T_{miss}) + (A_{pLRU} \\times \\beta)$\n$O_{pLRU} = 0.95 + (0.047 \\times 36) + (0.019 \\times 1.2)$\n$O_{pLRU} = 0.95 + 1.692 + 0.0228$\n$O_{pLRU} = 2.642 + 0.0228$\n$O_{pLRU} = 2.6648$ cycles.\n\nFor RRIP:\nThe specific parameters are $m_{RRIP} = 0.042$ and $A_{RRIP} = 0.037\\,\\mathrm{mm}^2$. The hit time is $T_{hit, RRIP} = 1.00$ cycles.\n$O_{RRIP} = T_{hit, RRIP} + (m_{RRIP} \\times T_{miss}) + (A_{RRIP} \\times \\beta)$\n$O_{RRIP} = 1.00 + (0.042 \\times 36) + (0.037 \\times 1.2)$\n$O_{RRIP} = 1.00 + 1.512 + 0.0444$\n$O_{RRIP} = 2.512 + 0.0444$\n$O_{RRIP} = 2.5564$ cycles.\n\nFinally, we compare the objective values for the feasible policies to find the minimum.\n$O_{pLRU} = 2.6648$ cycles.\n$O_{RRIP} = 2.5564$ cycles.\nThe minimal value is $\\min(2.6648, 2.5564) = 2.5564$.\n\nThe problem requires the answer to be rounded to four significant figures. The value $2.5564$ rounded to four significant figures is $2.556$.", "answer": "$$\\boxed{2.556}$$", "id": "3630761"}, {"introduction": "This final exercise elevates the analysis to a system-level challenge involving multiple interacting components. You will determine the optimal sizes for L1 and L2 caches to minimize overall memory stall time, working within a fixed silicon budget. This problem requires you to apply calculus for constrained optimization, a critical skill for allocating resources effectively across a complex system like a modern processor [@problem_id:3630783].", "problem": "A single-threaded in-order processor executes a program of $N = 2 \\times 10^{8}$ instructions, with an average of $r = 0.5$ memory references per instruction. The memory hierarchy comprises a level-one (L1) cache of size $S_{1}$ (in kibibytes) and a level-two (L2) cache of size $S_{2}$ (in kibibytes). The following empirically calibrated relationships hold for the cache behavior:\n- The L1 hit latency is $t_{L_{1}}(S_{1}) = t_{1} + b_{1} S_{1}$ with $t_{1} = 2$ cycles and $b_{1} = 0.01$ cycles per kibibyte.\n- The L1 miss rate is $m_{1}(S_{1}) = \\dfrac{a_{1}}{S_{1}}$ with $a_{1} = 3.63$.\n- The L2 hit latency is $t_{L_{2}}(S_{2}) = t_{2} + b_{2} S_{2}$ with $t_{2} = 6$ cycles and $b_{2} = 0.01$ cycles per kibibyte.\n- The L2 miss rate is $m_{2}(S_{2}) = \\dfrac{a_{2}}{S_{2}}$ with $a_{2} = 9$.\n- A miss from the L2 cache incurs an additional main-memory stall of $T_{M} = 100$ cycles.\n\nAssume that each memory reference stalls the pipeline by an amount equal to the realized access latency at the level it hits or misses, and that independent memory references do not overlap in time (no memory-level parallelism). Using the definitions of hit probability and miss probability, the linearity of expectation, and the given functions of $S_{1}$ and $S_{2}$, derive an expression for the expected stall cycles per memory reference. Then, write the total stall cycles over the whole program as a function of $S_{1}$ and $S_{2}$. Subject to the linear cost constraint $C(S_{1}, S_{2}) = c_{1} S_{1} + c_{2} S_{2} \\leq B$ with $c_{1} = 2$, $c_{2} = 1$, and $B = 450$ (cost units), determine the cache sizes $S_{1}$ and $S_{2}$ (in kibibytes) that minimize the total stall cycles. Express your final answer as a row matrix containing the optimal $S_{1}$ and $S_{2}$, in kibibytes. No rounding is required; give exact values.", "solution": "The user-provided problem has been analyzed and is deemed to be valid. It is a well-posed, scientifically grounded, and objective problem in the domain of computer organization and architecture. The task is to solve a constrained optimization problem to find the optimal cache sizes that minimize total memory stall cycles under a given cost constraint.\n\nThe total number of memory references in the program is given by the product of the number of instructions, $N$, and the average number of memory references per instruction, $r$.\n$$N_{mem} = N \\times r = (2 \\times 10^{8}) \\times 0.5 = 1 \\times 10^{8}$$\nThe problem states that each memory reference stalls the pipeline by an amount equal to its realized access latency. The total stall cycles, $T_{stall}$, is the product of the total number of memory references and the expected stall cycles per reference. The expected stall time per reference is equivalent to the Average Memory Access Time (AMAT) for the given memory hierarchy.\n\nThe AMAT for a two-level cache hierarchy is given by the standard formula:\n$$AMAT = (\\text{L1 Hit Time}) + (\\text{L1 Miss Rate}) \\times (\\text{L1 Miss Penalty})$$\nThe L1 Miss Penalty is the time required to service a miss in the L1 cache, which involves accessing the L2 cache.\n$$(\\text{L1 Miss Penalty}) = (\\text{L2 Hit Time}) + (\\text{L2 Miss Rate}) \\times (\\text{L2 Miss Penalty})$$\nFrom the problem statement:\n- L1 Hit Time is the L1 hit latency, $t_{L_{1}}(S_{1})$.\n- L1 Miss Rate is $m_{1}(S_{1})$.\n- L2 Hit Time is the L2 hit latency, $t_{L_{2}}(S_{2})$. Note that this is the latency for a hit in L2, which constitutes the primary component of the L1 miss penalty.\n- L2 Miss Rate, $m_{2}(S_{2})$, is the local miss rate for accesses that reach the L2 cache.\n- L2 Miss Penalty is the additional stall from main memory, $T_{M}$.\n\nLet $E_{stall}(S_{1}, S_{2})$ be the expected stall cycles per memory reference. We can write:\n$$E_{stall}(S_{1}, S_{2}) = t_{L_{1}}(S_{1}) + m_{1}(S_{1}) \\left[ t_{L_{2}}(S_{2}) + m_{2}(S_{2}) T_{M} \\right]$$\nThe total stall cycles for the entire program is:\n$$T_{stall}(S_{1}, S_{2}) = N_{mem} \\times E_{stall}(S_{1}, S_{2})$$\nTo minimize $T_{stall}$, we need to minimize $E_{stall}(S_{1}, S_{2})$, as $N_{mem}$ is a positive constant. Let's define the function to be minimized, $f(S_{1}, S_{2}) = E_{stall}(S_{1}, S_{2})$. Substituting the given empirical relationships:\n$t_{L_{1}}(S_{1}) = t_{1} + b_{1} S_{1}$\n$m_{1}(S_{1}) = \\dfrac{a_{1}}{S_{1}}$\n$t_{L_{2}}(S_{2}) = t_{2} + b_{2} S_{2}$\n$m_{2}(S_{2}) = \\dfrac{a_{2}}{S_{2}}$\n\nThe function $f(S_{1}, S_{2})$ becomes:\n$$f(S_{1}, S_{2}) = (t_{1} + b_{1} S_{1}) + \\frac{a_{1}}{S_{1}} \\left[ (t_{2} + b_{2} S_{2}) + \\left(\\frac{a_{2}}{S_{2}}\\right) T_{M} \\right]$$\nExpanding this expression, we get:\n$$f(S_{1}, S_{2}) = t_{1} + b_{1} S_{1} + \\frac{a_{1} t_{2}}{S_{1}} + \\frac{a_{1} b_{2} S_{2}}{S_{1}} + \\frac{a_{1} a_{2} T_{M}}{S_{1} S_{2}}$$\nWe must minimize this function subject to the cost constraint $C(S_{1}, S_{2}) = c_{1} S_{1} + c_{2} S_{2} \\leq B$, and the physical constraints $S_{1} > 0$ and $S_{2} > 0$. The function $f(S_{1}, S_{2})$ is convex for $S_{1}, S_{2} > 0$, and the constraint defines a convex set. The minimum will either be the unconstrained minimum if it lies within the feasible region, or it will lie on the boundary of the region. As $S_{1} \\to 0$ or $S_{2} \\to 0$, $f(S_{1}, S_{2}) \\to \\infty$, so the minimum cannot be on the axes ($S_{1}=0$ or $S_{2}=0$).\n\nWe first find the unconstrained minimum by setting the partial derivatives of $f(S_{1}, S_{2})$ with respect to $S_{1}$ and $S_{2}$ to zero.\n\nPartial derivative with respect to $S_{1}$:\n$$\\frac{\\partial f}{\\partial S_{1}} = b_{1} - \\frac{a_{1} t_{2}}{S_{1}^{2}} - \\frac{a_{1} b_{2} S_{2}}{S_{1}^{2}} - \\frac{a_{1} a_{2} T_{M}}{S_{1}^{2} S_{2}}$$\nSetting $\\frac{\\partial f}{\\partial S_{1}} = 0$:\n$$b_{1} = \\frac{1}{S_{1}^{2}} \\left( a_{1} t_{2} + a_{1} b_{2} S_{2} + \\frac{a_{1} a_{2} T_{M}}{S_{2}} \\right) \\implies b_{1} S_{1}^{2} = a_{1} \\left( t_{2} + b_{2} S_{2} + \\frac{a_{2} T_{M}}{S_{2}} \\right)$$\n\nPartial derivative with respect to $S_{2}$:\n$$\\frac{\\partial f}{\\partial S_{2}} = \\frac{a_{1} b_{2}}{S_{1}} - \\frac{a_{1} a_{2} T_{M}}{S_{1} S_{2}^{2}}$$\nSetting $\\frac{\\partial f}{\\partial S_{2}} = 0$ (and assuming $S_{1} > 0$):\n$$\\frac{a_{1} b_{2}}{S_{1}} = \\frac{a_{1} a_{2} T_{M}}{S_{1} S_{2}^{2}} \\implies b_{2} = \\frac{a_{2} T_{M}}{S_{2}^{2}} \\implies S_{2}^{2} = \\frac{a_{2} T_{M}}{b_{2}}$$\nThis gives us a value for $S_{2}$ at the critical point:\n$$S_{2} = \\sqrt{\\frac{a_{2} T_{M}}{b_{2}}}$$\nNow, we substitute this relationship back into the equation from the first partial derivative. From $S_{2}^{2} = \\frac{a_{2} T_{M}}{b_{2}}$, we have $a_{2} T_{M} = b_{2} S_{2}^{2}$. Thus, $\\frac{a_{2} T_{M}}{S_{2}} = b_{2} S_{2}$.\nThe equation for $S_1$ becomes:\n$$b_{1} S_{1}^{2} = a_{1} (t_{2} + b_{2} S_{2} + b_{2} S_{2}) = a_{1} (t_{2} + 2 b_{2} S_{2})$$\nWe also have $b_{2} S_{2} = b_{2} \\sqrt{\\frac{a_{2} T_{M}}{b_{2}}} = \\sqrt{a_{2} b_{2} T_{M}}$. Substituting this:\n$$b_{1} S_{1}^{2} = a_{1} (t_{2} + 2 \\sqrt{a_{2} b_{2} T_{M}})$$\nThis gives us the value for $S_{1}$ at the critical point:\n$$S_{1} = \\sqrt{\\frac{a_{1}}{b_{1}} \\left( t_{2} + 2 \\sqrt{a_{2} b_{2} T_{M}} \\right)}$$\nNow, we substitute the given numerical values:\n$t_{1} = 2$, $t_{2} = 6$, $b_{1} = 0.01$, $b_{2} = 0.01$, $a_{1} = 3.63$, $a_{2} = 9$, $T_{M} = 100$.\n$c_{1} = 2$, $c_{2} = 1$, $B = 450$.\n\nFirst, calculate $S_{2}$:\n$$S_{2} = \\sqrt{\\frac{9 \\times 100}{0.01}} = \\sqrt{\\frac{900}{0.01}} = \\sqrt{90000} = 300$$\nSo, the optimal $S_{2}$ for the unconstrained problem is $300$ kibibytes.\n\nNext, calculate the intermediate term $\\sqrt{a_{2} b_{2} T_{M}}$:\n$$\\sqrt{a_{2} b_{2} T_{M}} = \\sqrt{9 \\times 0.01 \\times 100} = \\sqrt{9} = 3$$\nNow, calculate $S_{1}$:\n$$S_{1} = \\sqrt{\\frac{3.63}{0.01} \\left( 6 + 2 \\times 3 \\right)} = \\sqrt{363 \\times (6 + 6)} = \\sqrt{363 \\times 12}$$\n$$S_{1} = \\sqrt{(3 \\times 121) \\times (3 \\times 4)} = \\sqrt{3^{2} \\times 11^{2} \\times 2^{2}} = \\sqrt{(3 \\times 11 \\times 2)^{2}} = 3 \\times 11 \\times 2 = 66$$\nSo, the optimal $S_{1}$ for the unconstrained problem is $66$ kibibytes.\n\nThe unconstrained minimum is at the point ($S_{1}^{*}, S_{2}^{*}$) = ($66$, $300$). We must now verify if this point satisfies the cost constraint $c_{1} S_{1} + c_{2} S_{2} \\leq B$.\n$$C(66, 300) = (2 \\times 66) + (1 \\times 300) = 132 + 300 = 432$$\nThe budget is $B = 450$. Since $432 \\leq 450$, the unconstrained minimum lies within the feasible region defined by the cost constraint. Because the objective function is convex, this point represents the global minimum for the constrained optimization problem.\n\nThus, the cache sizes that minimize the total stall cycles are $S_{1} = 66$ kibibytes and $S_{2} = 300$ kibibytes.", "answer": "$$\\boxed{\\begin{pmatrix} 66 & 300 \\end{pmatrix}}$$", "id": "3630783"}]}