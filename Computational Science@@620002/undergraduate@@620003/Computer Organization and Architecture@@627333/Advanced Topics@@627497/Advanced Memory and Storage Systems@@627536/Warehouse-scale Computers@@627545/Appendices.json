{"hands_on_practices": [{"introduction": "A fundamental challenge in designing any large-scale service is capacity planning: provisioning just enough computational resources to meet performance targets without being wasteful. This exercise introduces queuing theory, the essential mathematical framework used to model and predict the performance of systems with random request arrivals. By working through this problem [@problem_id:3688262], you will apply the standard $\\mathrm{M}/\\mathrm{M}/k$ model to determine the number of CPU cores required to satisfy a Service Level Objective (SLO) and evaluate the performance benefits of introducing specialized accelerators for certain tasks.", "problem": "A Warehouse-Scale Computer (WSC) operates a microservice tier that receives external requests and dispatches them to a pool of identical Central Processing Unit (CPU) cores. To reason about capacity planning, use the following scientifically standard assumptions: request arrivals form a Poisson process with rate $\\lambda$ requests per second, individual service times on any given core are independent and exponentially distributed with mean rate $\\mu$ requests per second per core, and cores serve requests under First-Come-First-Served (FCFS) scheduling. Under these conditions, the general request lane can be modeled as an $\\mathrm{M}/\\mathrm{M}/k$ queue, where $k$ is the number of active general-purpose cores.\n\nThe WSC enforces a Service Level Objective (SLO) on the expected queuing delay $W_q$, defined as the expected time a request waits in the queue before service begins (not including service time). The SLO requires $W_q \\leq W_0$, where $W_0$ is a specified bound in seconds.\n\nBaseline configuration:\n- Arrival rate is $\\lambda = 800$ requests per second.\n- Each general-purpose core has mean service rate $\\mu = 150$ requests per second.\n- The SLO bound is $W_0 = 0.040$ seconds.\n\nSpecialized express-lane configuration:\n- A fraction $p = 0.25$ of arrivals are identified as simple requests and are routed to a separate pool of specialized accelerators (the express lane), leaving the remaining $(1-p)$ of arrivals for the general-purpose cores.\n- There are $m = 2$ identical accelerators, each with mean service rate $\\mu_s = 500$ requests per second.\n- The general-purpose pool remains as an $\\mathrm{M}/\\mathrm{M}/k$ queue serving the remaining arrivals, while the express lane forms an $\\mathrm{M}/\\mathrm{M}/m$ queue serving the offloaded arrivals.\n- The SLO requires that both lanes individually satisfy $W_q \\leq W_0$.\n\nUsing only the above assumptions and definitions, determine:\n1. The minimal integer number of general-purpose cores $k_{\\mathrm{base}}$ needed in the baseline configuration such that the expected queuing delay satisfies $W_q \\leq W_0$.\n2. The minimal integer number of general-purpose cores $k_{\\mathrm{spec}}$ needed in the specialized express-lane configuration such that both the general-purpose lane and the express lane individually satisfy $W_q \\leq W_0$.\n\nFinally, compute the reduction in general-purpose cores due to the specialized express lane, defined as $\\Delta k = k_{\\mathrm{base}} - k_{\\mathrm{spec}}$. Express your final answer as a single integer. All intermediate quantities in your reasoning must be expressed in seconds for time and requests per second for rates. No rounding instructions are necessary for the final integer.", "solution": "The problem statement has been validated and found to be scientifically grounded, well-posed, and objective. It presents a standard performance analysis scenario in computer systems architecture using established principles of queuing theory. All necessary parameters are provided, and the problem is free of contradictions or ambiguities.\n\nThe problem requires the analysis of two queuing systems based on the $\\mathrm{M}/\\mathrm{M}/k$ model. An $\\mathrm{M}/\\mathrm{M}/k$ queue models a system with Poisson arrivals (the first M), exponential service times (the second M), and $k$ parallel servers. The core formulas for analyzing such a system are:\n1.  The offered load, $A$, is the ratio of arrival rate $\\lambda$ to the service rate of a single server $\\mu$: $A = \\frac{\\lambda}{\\mu}$. This represents the expected number of busy servers if there were infinitely many.\n2.  The system is stable only if the total service capacity exceeds the arrival rate, i.e., $k\\mu > \\lambda$. This is equivalent to the condition that the traffic intensity, $\\rho = \\frac{\\lambda}{k\\mu} = \\frac{A}{k}$, must be less than $1$.\n3.  The probability that an arriving request must wait in the queue, $P_q$, is given by the Erlang C formula, denoted $C(k, A)$:\n    $$P_q = C(k, A) = \\frac{\\frac{A^k}{k!(1-\\rho)}}{\\sum_{n=0}^{k-1} \\frac{A^n}{n!} + \\frac{A^k}{k!(1-\\rho)}}$$\n4.  The expected queuing delay, $W_q$, can be calculated using the probability of queuing:\n    $$W_q = \\frac{P_q}{k\\mu - \\lambda}$$\n    For the system to be viable, we must find the smallest integer $k$ such that the stability condition is met and the Service Level Objective (SLO), $W_q \\leq W_0$, is satisfied.\n\n**1. Determine the minimal cores for the baseline configuration, $k_{\\mathrm{base}}$**\n\nIn the baseline configuration, we have:\n-   Arrival rate: $\\lambda = 800$ requests/second.\n-   Mean service rate per core: $\\mu = 150$ requests/second.\n-   SLO bound: $W_0 = 0.040$ seconds.\n\nFirst, we determine the minimum number of cores required for stability:\n$k \\mu > \\lambda \\implies k \\times 150 > 800 \\implies k > \\frac{800}{150} = \\frac{16}{3} \\approx 5.333$.\nThe smallest integer number of cores that ensures stability is $k=6$.\n\nNow, we must verify if $k=6$ satisfies the SLO, $W_q \\leq 0.040$ s. We calculate $W_q$ for $k=6$.\nThe offered load is $A = \\frac{\\lambda}{\\mu} = \\frac{800}{150} = \\frac{16}{3}$.\nThe traffic intensity is $\\rho = \\frac{A}{k} = \\frac{16/3}{6} = \\frac{16}{18} = \\frac{8}{9}$.\n\nWe compute the terms for the Erlang C formula, $C(6, 16/3)$.\nThe sum in the denominator is:\n$$S = \\sum_{n=0}^{k-1} \\frac{A^n}{n!} = \\sum_{n=0}^{5} \\frac{(16/3)^n}{n!} = 1 + \\frac{16}{3} + \\frac{(16/3)^2}{2!} + \\frac{(16/3)^3}{3!} + \\frac{(16/3)^4}{4!} + \\frac{(16/3)^5}{5!}$$\n$$S = 1 + \\frac{16}{3} + \\frac{128}{9} + \\frac{2048}{81} + \\frac{8192}{243} + \\frac{131072}{3645} = \\frac{3645 + 19440 + 51840 + 92160 + 122880 + 131072}{3645} = \\frac{421037}{3645}$$\nThe queuing term in the formula is:\n$$Q = \\frac{A^k}{k!(1-\\rho)} = \\frac{(16/3)^6}{6!(1 - 8/9)} = \\frac{16^6 / 3^6}{720(1/9)} = \\frac{16777216 / 729}{80} = \\frac{16777216}{58320} = \\frac{1048576}{3645}$$\nThe probability of queuing is:\n$$P_q = C(6, 16/3) = \\frac{Q}{S+Q} = \\frac{1048576/3645}{421037/3645 + 1048576/3645} = \\frac{1048576}{1469613}$$\nNow we calculate the expected queuing delay $W_q$:\n$$W_q = \\frac{P_q}{k\\mu - \\lambda} = \\frac{1048576 / 1469613}{6 \\times 150 - 800} = \\frac{1048576 / 1469613}{100} = \\frac{1048576}{146961300} \\approx 0.00714 \\text{ s}$$\nSince $W_q \\approx 0.00714 \\text{ s} \\leq 0.040 \\text{ s}$, the SLO is satisfied for $k=6$. As $W_q$ is a monotonically decreasing function of $k$ for stable systems, and $k=6$ is the minimum integer value for stability, it is also the minimal number of cores that meets the SLO.\nThus, $k_{\\mathrm{base}} = 6$.\n\n**2. Determine the minimal general-purpose cores for the specialized configuration, $k_{\\mathrm{spec}}$**\n\nIn this configuration, the traffic is split.\n\n**Express lane (Accelerators):**\nA fraction $p=0.25$ of arrivals are routed here.\n-   Arrival rate: $\\lambda_s = p \\lambda = 0.25 \\times 800 = 200$ requests/second.\n-   Number of servers: $m=2$.\n-   Service rate per server: $\\mu_s = 500$ requests/second.\n-   The SLO is $W_{q,s} \\leq W_0 = 0.040$ s.\n\nFirst, check stability: $m \\mu_s = 2 \\times 500 = 1000 > \\lambda_s = 200$. The system is stable.\nOffered load: $A_s = \\lambda_s / \\mu_s = 200 / 500 = 0.4$.\nTraffic intensity: $\\rho_s = A_s / m = 0.4 / 2 = 0.2$.\nUsing the Erlang C formula for $m=2$:\n$$P_{q,s} = C(2, 0.4) = \\frac{\\frac{0.4^2}{2!(1-0.2)}}{ \\frac{0.4^0}{0!} + \\frac{0.4^1}{1!} + \\frac{0.4^2}{2!(1-0.2)}} = \\frac{\\frac{0.16}{1.6}}{1 + 0.4 + \\frac{0.16}{1.6}} = \\frac{0.1}{1.4+0.1} = \\frac{0.1}{1.5} = \\frac{1}{15}$$\nThe expected queuing delay is:\n$$W_{q,s} = \\frac{P_{q,s}}{m\\mu_s - \\lambda_s} = \\frac{1/15}{1000 - 200} = \\frac{1/15}{800} = \\frac{1}{12000} \\approx 0.000083 \\text{ s}$$\nSince $W_{q,s} \\ll 0.040$ s, the express lane satisfies the SLO.\n\n**General-purpose lane:**\nThe remaining fraction $(1-p) = 0.75$ of arrivals are routed here.\n-   Arrival rate: $\\lambda_g = (1-p) \\lambda = 0.75 \\times 800 = 600$ requests/second.\n-   Service rate per core: $\\mu = 150$ requests/second.\n-   The number of cores is $k_{\\mathrm{spec}}$, which we need to find.\n-   The SLO is $W_{q,g} \\leq W_0 = 0.040$ s.\n\nStability requires: $k_{\\mathrm{spec}} \\mu > \\lambda_g \\implies k_{\\mathrm{spec}} \\times 150 > 600 \\implies k_{\\mathrm{spec}} > 4$.\nThe minimum integer number of cores for stability is $k_{\\mathrm{spec}}=5$.\n\nWe check if $k_{\\mathrm{spec}}=5$ satisfies the SLO.\nOffered load: $A_g = \\lambda_g / \\mu = 600 / 150 = 4$.\nTraffic intensity: $\\rho_g = A_g / k_{\\mathrm{spec}} = 4 / 5 = 0.8$.\n\nWe compute the terms for the Erlang C formula, $C(5, 4)$.\nThe sum in the denominator:\n$$S_g = \\sum_{n=0}^{4} \\frac{4^n}{n!} = 1 + 4 + \\frac{4^2}{2} + \\frac{4^3}{6} + \\frac{4^4}{24} = 1 + 4 + 8 + \\frac{32}{3} + \\frac{32}{3} = 13 + \\frac{64}{3} = \\frac{103}{3}$$\nThe queuing term:\n$$Q_g = \\frac{A_g^{k_{\\mathrm{spec}}}}{k_{\\mathrm{spec}}!(1-\\rho_g)} = \\frac{4^5}{5!(1-4/5)} = \\frac{1024}{120(1/5)} = \\frac{1024}{24} = \\frac{128}{3}$$\nThe probability of queuing:\n$$P_{q,g} = C(5, 4) = \\frac{Q_g}{S_g+Q_g} = \\frac{128/3}{103/3 + 128/3} = \\frac{128}{231}$$\nThe expected queuing delay is:\n$$W_{q,g} = \\frac{P_{q,g}}{k_{\\mathrm{spec}}\\mu - \\lambda_g} = \\frac{128/231}{5 \\times 150 - 600} = \\frac{128/231}{150} = \\frac{128}{34650} \\approx 0.00369 \\text{ s}$$\nSince $W_{q,g} \\approx 0.00369 \\text{ s} \\leq 0.040 \\text{ s}$, the SLO is met for $k_{\\mathrm{spec}}=5$. This is the minimal integer satisfying stability, so it is the required number of cores.\nThus, $k_{\\mathrm{spec}} = 5$.\n\n**3. Compute the reduction in general-purpose cores, $\\Delta k$**\n\nThe reduction in cores is the difference between the baseline requirement and the specialized configuration requirement.\n$$\\Delta k = k_{\\mathrm{base}} - k_{\\mathrm{spec}} = 6 - 5 = 1$$\nThe introduction of the specialized express lane allows for a reduction of $1$ general-purpose core while satisfying all SLOs.", "answer": "$$\\boxed{1}$$", "id": "3688262"}, {"introduction": "Warehouse-scale computers are not static; they are dynamic systems that undergo constant maintenance and updates to ensure reliability and introduce new features. This practice [@problem_id:3688243] moves from static design to analyzing a system's behavior during a live operational procedure: a rolling update. You will model the transient impact of taking nodes offline and bringing them back online, calculating the resulting degradation in the cache hit ratio, a critical performance metric for many WSC services.", "problem": "A warehouse-scale computer (WSC) operates a cache-sharded, key-addressed service across $N$ homogeneous cache nodes. Keys are assigned to nodes by either Consistent Hashing (CH) or Rendezvous Hashing (RH). Assume the minimal-disruption property holds for both: when a node is removed, only keys that were mapped to that node are remapped; when a node is added, only a fraction of keys proportional to the new node’s share are remapped. The system serves a uniform, independent Poisson stream of read requests with total rate $\\Lambda$ requests per second across $K$ equally popular keys, so each key receives a Poisson process of rate $\\rho = \\Lambda/K$. All caches are fully warm at time $t=0$.\n\nThe cluster performs a rolling update in which exactly one node at a time is taken out of service and then returned after a fixed dwell time. The update proceeds at a constant rate of $u$ nodes per second, so the per-node dwell time is $\\tau = 1/u$ and the total rolling update duration is $T = N \\tau$. When a node is removed, all keys on that node are remapped to other nodes instantly; when the node returns, those keys are remapped back to it. Whenever a key is remapped onto a node whose cache does not yet contain the key, the first access to that key on that node during the subsequent interval incurs exactly one cache miss to fetch and warm the key; subsequent accesses while it remains on that node are cache hits. There is no background warming and no eviction during the interval of interest.\n\nTake the following concrete parameters: $N = 120$, $u = 0.25$ nodes per second, $K = 5 \\times 10^{6}$ keys, and $\\Lambda = 1.5 \\times 10^{6}$ requests per second.\n\nUsing the facts above, and treating both Consistent Hashing (CH) and Rendezvous Hashing (RH) under the minimal-disruption assumption, compute the expected average cache hit ratio over the entire rolling update interval $[0, T]$. Express your final answer as a decimal rounded to four significant figures.", "solution": "We begin from two well-tested facts:\n\n1. Minimal-disruption property for both Consistent Hashing (CH) and Rendezvous Hashing (RH): removing a node remaps exactly those keys assigned to that node; adding or returning a node remaps only the keys that the node will own thereafter.\n\n2. Superposition/splitting properties of a Poisson process: if total requests arrive as a Poisson process at rate $\\Lambda$ spread uniformly over $K$ keys, then each key experiences an independent Poisson process of rate $\\rho = \\Lambda/K$. For a Poisson process of rate $\\rho$, the probability of observing at least one request in an interval of length $\\Delta$ is $1 - \\exp(-\\rho \\Delta)$.\n\nSet the given parameters. The per-node dwell time is $\\tau = 1/u$, so\n$$\n\\tau = \\frac{1}{0.25} = 4 \\text{ s}.\n$$\nThe total rolling update duration is\n$$\nT = N \\tau = 120 \\times 4 = 480 \\text{ s}.\n$$\nThe per-key request rate is\n$$\n\\rho = \\frac{\\Lambda}{K} = \\frac{1.5 \\times 10^{6}}{5 \\times 10^{6}} = 0.3 \\text{ s}^{-1}.\n$$\n\nUnder minimal disruption, when a particular node is removed, exactly the keys that were on it are remapped. Since keys are evenly spread, each node holds a fraction $1/N$ of the keys, i.e., $K/N$ keys. For those $K/N$ keys, while the node is down for $\\tau$ seconds, each key experiences an extra miss if and only if it is requested at least once during that interval. The probability a given key is requested at least once during $\\tau$ is\n$$\np = 1 - \\exp(-\\rho \\tau) = 1 - \\exp(-0.3 \\times 4) = 1 - \\exp(-1.2).\n$$\n\nWhen the node returns after $\\tau$, those same $K/N$ keys are remapped back to it. The cache on that node does not contain those keys, so for each such key there will be one extra miss upon its first request after rejoin. For node $i$ in the sequence ($i = 1, 2, \\dots, N$), it rejoins at time $t = i \\tau$, and the remaining time until the end of the rolling update is\n$$\nT_{\\text{res}}(i) = T - i \\tau = (N - i)\\tau.\n$$\nThe probability that a given key sees at least one request in $T_{\\text{res}}(i)$ is\n$$\nq_i = 1 - \\exp\\!\\big(-\\rho \\, T_{\\text{res}}(i)\\big) = 1 - \\exp\\!\\big(-\\rho (N - i)\\tau\\big).\n$$\n\nBy linearity of expectation, the expected number of extra misses due to the removal window for node $i$ is $(K/N) p$, and due to the rejoin period is $(K/N) q_i$. Summing over all $N$ nodes, the total expected number of extra misses across the entire rolling update is\n$$\nM_{\\text{extra}} = \\sum_{i=1}^{N} \\frac{K}{N}\\, p \\;+\\; \\sum_{i=1}^{N} \\frac{K}{N}\\, q_i \\;=\\; K p \\;+\\; \\frac{K}{N} \\sum_{i=1}^{N} q_i.\n$$\nDefine $r \\equiv \\exp(-\\rho \\tau) = \\exp(-1.2)$. Then $p = 1 - r$, and we can rewrite the average of $q_i$ over $i$ using $j = N - i$:\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} q_i \\;=\\; \\frac{1}{N} \\sum_{j=0}^{N-1} \\big(1 - \\exp(-\\rho j \\tau)\\big) \\;=\\; 1 - \\frac{1}{N} \\sum_{j=0}^{N-1} r^{\\,j}.\n$$\nThe sum $\\sum_{j=0}^{N-1} r^{\\,j}$ is a geometric series:\n$$\n\\sum_{j=0}^{N-1} r^{\\,j} \\;=\\; \\frac{1 - r^{N}}{1 - r}.\n$$\nTherefore,\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} q_i \\;=\\; 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r}.\n$$\nThus\n$$\nM_{\\text{extra}} \\;=\\; K \\left[(1 - r) \\;+\\; 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r}\\right].\n$$\n\nThe total number of requests during the rolling update is\n$$\nR_{\\text{tot}} = \\Lambda T = \\Lambda N \\tau.\n$$\nAssuming the baseline hit ratio absent any remapping would be effectively $1$ over the horizon (all caches begin warm and no other misses occur), the average hit ratio over the rolling update under either CH or RH is\n$$\nH \\;=\\; 1 \\;-\\; \\frac{M_{\\text{extra}}}{R_{\\text{tot}}}\n\\;=\\; 1 \\;-\\; \\frac{K \\left[(1 - r) + 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r}\\right]}{\\Lambda N \\tau}.\n$$\n\nNow substitute the numerical values. First compute $r$:\n$$\nr = \\exp(-1.2) \\approx 0.30119421191220214.\n$$\nThen\n$$\n1 - r \\approx 0.6988057880877979, \\quad r^{N} = \\exp(-1.2 \\times 120) = \\exp(-144) \\approx 5.311092249679095 \\times 10^{-63} \\approx 0 \\text{ for our precision}.\n$$\nHence\n$$\n\\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r} \\approx \\frac{1}{120} \\cdot \\frac{1}{0.6988057880877979} \\approx 0.011926710133396018,\n$$\nand\n$$\n(1 - r) + 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r} \\;\\approx\\; 0.6988057880877979 + 1 - 0.011926710133396018 \\;\\approx\\; 1.686879077954402.\n$$\nTherefore,\n$$\nM_{\\text{extra}} \\approx K \\times 1.686879077954402 \\approx (5 \\times 10^{6}) \\times 1.686879077954402 \\approx 8.43439538977201 \\times 10^{6}.\n$$\nThe total number of requests during the rolling update is\n$$\nR_{\\text{tot}} = \\Lambda N \\tau = (1.5 \\times 10^{6}) \\times 120 \\times 4 = 7.2 \\times 10^{8}.\n$$\nFinally, the average hit ratio is\n$$\nH \\approx 1 - \\frac{8.43439538977201 \\times 10^{6}}{7.2 \\times 10^{8}} \\approx 1 - 0.011714438040795 \\approx 0.988285561959205.\n$$\n\nUnder the assumptions stated, both Consistent Hashing (CH) and Rendezvous Hashing (RH) yield the same minimal-disruption remapping pattern for a single-node rolling update, so the computed $H$ applies to both. Rounding to four significant figures yields\n$$\nH \\approx 0.9883.\n$$", "answer": "$$\\boxed{0.9883}$$", "id": "3688243"}, {"introduction": "While uniform workloads are convenient for initial analysis, real-world traffic in WSCs is almost always skewed, with a small fraction of keys or users receiving a disproportionate amount of traffic. This exercise [@problem_id:3688302] tackles this \"hot spot\" problem by exploring microsharding, a technique to increase parallelism for popular items. You will engage in a classic system design trade-off, balancing the benefits of sharding against its coordination overhead to find the optimal configuration that minimizes tail latency for the most demanding workloads.", "problem": "A large-scale online service deployed in a Warehouse-Scale Computer (WSC) uses plan-state microsharding to mitigate request skew across keys. There are $K$ distinct keys, and the probability that an incoming request targets key $i \\in \\{1,\\dots,K\\}$ follows a Zipf distribution with exponent $\\zeta > 0$, namely $p_i = \\frac{i^{-\\zeta}}{H_{K,\\zeta}}$, where $H_{K,\\zeta} = \\sum_{j=1}^{K} j^{-\\zeta}$ is the generalized harmonic number. The total request arrival process is Poisson with rate $\\lambda$ requests per second. For microsharding, each key is split evenly across $s$ identical microshards, so the requests for key $i$ are split uniformly at random across its $s$ microshards. Each microshard is an independent single-server queue with exponential service times of rate $\\mu$ requests per second (that is, mean service time $1/\\mu$), and the service discipline is first-come, first-served. Each request incurs a deterministic coordination overhead proportional to the microshard fanout, modeled as an additive time penalty $o s$, where $o$ has units of seconds per shard.\n\nAssume tail latency is dominated by the hottest key’s microshard under skew and that the end-to-end $0.99$-quantile latency can be conservatively approximated by the sum of a high-quantile bound on the queueing delay at the hottest microshard and the deterministic coordination overhead. Using only fundamental properties of Poisson arrivals, exponential service, and the Zipf distribution, derive and minimize a tractable analytic proxy for the $0.99$-quantile latency as a function of the microshard count $s$. Express the $s^\\*$ that minimizes this proxy as a closed-form analytical expression in terms of $\\lambda$, $\\mu$, $o$, $K$, and $\\zeta$.\n\nYour final answer must be a single closed-form expression for $s^\\*$ (dimensionless). Do not round or approximate constants such as $\\ln(100)$; leave them in exact symbolic form. No units are required in the final answer.", "solution": "The problem statement will first be validated against the specified criteria.\n\n### Step 1: Extract Givens\n-   Number of distinct keys: $K$\n-   Probability of a request for key $i$: $p_i = \\frac{i^{-\\zeta}}{H_{K,\\zeta}}$, for $i \\in \\{1, \\dots, K\\}$\n-   Zipf exponent: $\\zeta > 0$\n-   Generalized harmonic number: $H_{K,\\zeta} = \\sum_{j=1}^{K} j^{-\\zeta}$\n-   Total request arrival process: Poisson with rate $\\lambda$\n-   Microshard count per key (fanout): $s$\n-   Request splitting per key: Uniformly at random across $s$ microshards\n-   Microshard model: Independent M/M/1 queue (single-server, exponential service)\n-   Service rate per microshard: $\\mu$\n-   Service discipline: First-come, first-served\n-   Coordination overhead: Additive time penalty $o \\cdot s$\n-   Units of $o$: seconds per shard (interpreted as seconds per unit of fanout $s$, making the units of $o$ effectively seconds to ensure dimensional consistency of the total latency expression).\n-   Latency approximation: The end-to-end $0.99$-quantile latency is approximated by the sum of a high-quantile bound on the queueing delay at the hottest microshard and the deterministic coordination overhead.\n-   Objective: Find the optimal microshard count, $s^*$, that minimizes this latency proxy.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It uses standard, non-controversial models from queueing theory (M/M/1 queues, Poisson processes) and probability (Zipf distribution) to represent a common performance optimization problem in large-scale computer systems (WSCs). The setup is a canonical example of analyzing trade-offs between parallelism (reducing queueing delay by increasing $s$) and overhead (coordination cost increases with $s$). The problem is self-contained and provides all necessary information to construct and minimize a latency function. The request to use a \"tractable analytic proxy\" and a \"conservative approximation\" provides clear guidance to apply standard, justifiable simplifications from performance modeling, such as using the sojourn time quantile as an upper bound for the queueing delay quantile. The problem is formalizable, relevant to the specified topic, and does not contain scientific flaws, contradictions, or ambiguities that would render it invalid. A minor ambiguity in the unit description for $o$ is resolved by adopting the only interpretation that yields a dimensionally consistent model, a standard practice in applied mathematical modeling.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\nThe objective is to find the value of the microshard count, $s$, that minimizes a proxy for the $0.99$-quantile end-to-end latency, $L(s)$. The problem states that this latency can be approximated as the sum of two components: a high-quantile bound on the queueing delay at the hottest microshard, $L_{\\text{queue}}(s)$, and the coordination overhead, $L_{\\text{overhead}}(s)$.\n$$L(s) = L_{\\text{queue}}(s) + L_{\\text{overhead}}(s)$$\nThe coordination overhead is given as a linear function of $s$:\n$$L_{\\text{overhead}}(s) = o \\cdot s$$\nNow, we must determine the queueing delay component.\n\nFirst, we identify the \"hottest\" key. The probability of a request targeting key $i$ is $p_i = \\frac{i^{-\\zeta}}{H_{K,\\zeta}}$. Since the exponent $\\zeta > 0$, the function $i^{-\\zeta}$ is monotonically decreasing with $i$. The hottest key is therefore the one with the highest probability, which corresponds to the smallest index, $i=1$.\n\nThe total arrival rate of requests to the system is a Poisson process with rate $\\lambda$. The arrival rate of requests for key $1$ is $\\lambda_1$:\n$$\\lambda_1 = \\lambda \\cdot p_1 = \\lambda \\cdot \\frac{1^{-\\zeta}}{H_{K,\\zeta}} = \\frac{\\lambda}{H_{K,\\zeta}}$$\nThese $\\lambda_1$ requests per second are split uniformly at random across $s$ identical microshards. Due to the properties of a Poisson process, the arrival process to each of these $s$ microshards is also Poisson, with a rate $\\lambda_{\\text{shard}}$:\n$$\\lambda_{\\text{shard}} = \\frac{\\lambda_1}{s} = \\frac{\\lambda}{s H_{K,\\zeta}}$$\nEach microshard is modeled as an M/M/1 queue with arrival rate $\\lambda_{\\text{shard}}$ and service rate $\\mu$. The utilization of the hottest key's microshards, $\\rho$, is given by:\n$$\\rho(s) = \\frac{\\lambda_{\\text{shard}}}{\\mu} = \\frac{\\lambda}{s \\mu H_{K,\\zeta}}$$\nFor the queue to be stable, its utilization must be less than $1$, i.e., $\\rho < 1$, which imposes the constraint $s > \\frac{\\lambda}{\\mu H_{K,\\zeta}}$.\n\nNext, we establish a tractable proxy for the $0.99$-quantile queueing delay. For an M/M/1 queue, the cumulative distribution function of the total time spent in the system (sojourn time), $T_{\\text{sys}}$, is given by $P(T_{\\text{sys}} \\le t) = 1 - \\exp(-(\\mu-\\lambda_{\\text{shard}})t)$. The $p$-quantile of the sojourn time, $t_p$, is found by solving $P(T_{\\text{sys}} \\le t_p) = p$, which yields $t_p = \\frac{-\\ln(1-p)}{\\mu - \\lambda_{\\text{shard}}} = \\frac{-\\ln(1-p)}{\\mu(1-\\rho)}$. Using the sojourn time quantile is a standard conservative approximation for the queueing delay quantile. For the $0.99$-quantile, we set $p=0.99$, and thus $1-p=0.01$.\n$$L_{\\text{queue}}(s) = \\frac{-\\ln(0.01)}{\\mu(1-\\rho(s))} = \\frac{\\ln(100)}{\\mu(1-\\rho(s))}$$\nSubstituting the expression for $\\rho(s)$:\n$$L_{\\text{queue}}(s) = \\frac{\\ln(100)}{\\mu \\left(1 - \\frac{\\lambda}{s \\mu H_{K,\\zeta}}\\right)}$$\n\nNow we can write the full expression for the total latency proxy, $L(s)$:\n$$L(s) = \\frac{\\ln(100)}{\\mu \\left(1 - \\frac{\\lambda}{s \\mu H_{K,\\zeta}}\\right)} + o s$$\nTo simplify minimization, let's define a constant $C = \\frac{\\lambda}{\\mu H_{K,\\zeta}}$. This constant is dimensionless and represents the minimum fanout for queue stability. The latency function becomes:\n$$L(s) = \\frac{\\ln(100)}{\\mu \\left(1 - \\frac{C}{s}\\right)} + o s = \\frac{s \\ln(100)}{\\mu (s-C)} + o s$$\nTo find the optimal fanout $s^*$ that minimizes $L(s)$, we compute the derivative of $L(s)$ with respect to $s$ and set it to zero.\nUsing the quotient rule for the first term:\n$$\\frac{d}{ds} \\left( \\frac{s \\ln(100)}{\\mu (s-C)} \\right) = \\frac{\\ln(100)[\\mu(s-C)] - [s \\ln(100)]\\mu}{[\\mu(s-C)]^2} = \\frac{\\mu \\ln(100)(s-C-s)}{\\mu^2 (s-C)^2} = \\frac{-C \\ln(100)}{\\mu(s-C)^2}$$\nThe derivative of the second term is simply $o$.\n$$\\frac{dL}{ds} = \\frac{-C \\ln(100)}{\\mu(s-C)^2} + o$$\nSetting the derivative to zero to find the critical point $s^*$:\n$$o = \\frac{C \\ln(100)}{\\mu(s^*-C)^2}$$\n$$(s^*-C)^2 = \\frac{C \\ln(100)}{o \\mu}$$\n$$s^* - C = \\sqrt{\\frac{C \\ln(100)}{o \\mu}}$$\nWe take the positive root because the stability condition requires $s > C$.\n$$s^* = C + \\sqrt{\\frac{C \\ln(100)}{o \\mu}}$$\nFinally, we substitute back the expression for $C = \\frac{\\lambda}{\\mu H_{K,\\zeta}}$ to obtain the optimal fanout $s^*$ in terms of the original problem parameters:\n$$s^* = \\frac{\\lambda}{\\mu H_{K,\\zeta}} + \\sqrt{\\frac{\\left(\\frac{\\lambda}{\\mu H_{K,\\zeta}}\\right) \\ln(100)}{o \\mu}} = \\frac{\\lambda}{\\mu H_{K,\\zeta}} + \\sqrt{\\frac{\\lambda \\ln(100)}{o \\mu^2 H_{K,\\zeta}}}$$\nThis expression can be factored slightly for clarity:\n$$s^* = \\frac{\\lambda}{\\mu H_{K,\\zeta}} + \\frac{1}{\\mu} \\sqrt{\\frac{\\lambda \\ln(100)}{o H_{K,\\zeta}}}$$\nThis is the closed-form analytical expression for the optimal microshard count that minimizes the specified latency proxy.", "answer": "$$\\boxed{\\frac{\\lambda}{\\mu H_{K,\\zeta}} + \\frac{1}{\\mu} \\sqrt{\\frac{\\lambda \\ln(100)}{o H_{K,\\zeta}}}}$$", "id": "3688302"}]}