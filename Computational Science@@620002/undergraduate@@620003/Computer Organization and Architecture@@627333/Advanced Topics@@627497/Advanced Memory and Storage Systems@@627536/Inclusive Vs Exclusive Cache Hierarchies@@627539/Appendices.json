{"hands_on_practices": [{"introduction": "The core trade-off between inclusive and exclusive caches is how they utilize the total available cache capacity. An inclusive L2 cache offers benefits for coherence but at the cost of reduced effective capacity, as it must store a copy of everything in the L1. This exercise will help you analyze this capacity trade-off using a concrete workload with distinct hot and cold data sets, allowing you to see firsthand how duplicating data can impact the L2 miss rate [@problem_id:3649269].", "problem": "Consider a two-level data cache hierarchy with an upper cache $L_1$ and a lower cache $L_2$. The $L_2$ implements either the inclusion property ($L_1 \\subseteq L_2$, called an inclusive hierarchy) or the exclusion property (no duplication across levels, called an exclusive hierarchy). Both caches are write-back, use Least Recently Used (LRU) replacement, and are assumed fully associative to isolate pure capacity effects. Let the $L_1$ capacity be $S_1 = 32\\,\\text{KiB}$, the $L_2$ capacity be $S_2 = 256\\,\\text{KiB}$, and the block size be $B = 64\\,\\text{B}$. Assume the workload repeatedly executes rounds, each consisting of: first, repeated accesses to a hot set $H$ of size $\\lvert H \\rvert$ that exactly fits in $L_1$ and remains resident there, and second, a single sequential pass over a cold set $C$ of size $\\lvert C \\rvert$ blocks with no intra-pass temporal reuse. Define the $L_2$ miss rate $M_{L_2}$ as the fraction of $L_1$ misses that also miss in $L_2$. Assume $L_1$ hits do not access $L_2$, and that measurements focus on steady state over many rounds so that startup transients are negligible. You may assume that when $\\lvert C \\rvert$ fits in the available $L_2$ capacity not occupied by duplicates of $H$, the cold-set blocks persist in $L_2$ across rounds; otherwise, they do not persist.\n\nBased only on these facts and definitions, determine which of the following statements about how inclusion versus exclusion affects $M_{L_2}$ are correct. Select all that apply.\n\nA. For $\\lvert C \\rvert = 4000$ blocks, an inclusive $L_2$ duplicates $H$ and leaves insufficient space for $C$, so $M_{L_2}$ for cold accesses is near $1$ in steady state; an exclusive $L_2$ has enough space for $C$, so $M_{L_2}$ for cold accesses is near $0$. Inclusion increases $M_{L_2}$ in this case.\n\nB. For $\\lvert C \\rvert = 3000$ blocks, both inclusive and exclusive $L_2$ retain the entire cold set across rounds, so $M_{L_2}$ for cold accesses is near $0$ in steady state; inclusion does not increase $M_{L_2}$.\n\nC. For $\\lvert C \\rvert = 4096$ blocks, both inclusive and exclusive $L_2$ thrash on $C$ in steady state, so inclusion does not change $M_{L_2}$.\n\nD. For $\\lvert C \\rvert = 3584$ blocks, both inclusive and exclusive $L_2$ retain the cold set across rounds, so $M_{L_2}$ for cold accesses is near $0$ in steady state; inclusion does not increase $M_{L_2}$.\n\nE. Inclusion reduces $M_{L_2}$ for this workload because $H$ is present in $L_2$, allowing $L_2$ to serve hits to $H$ even when $L_1$ hits.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n-   **Cache Hierarchy**: Two-level data cache, upper cache $L_1$ and lower cache $L_2$.\n-   **$L_2$ Policy**: Either inclusive ($L_1 \\subseteq L_2$) or exclusive (no duplication).\n-   **Cache Parameters**: Both caches are write-back, use Least Recently Used (LRU) replacement, and are fully associative.\n-   **Capacities and Block Size**:\n    -   $L_1$ capacity: $S_1 = 32\\,\\text{KiB}$.\n    -   $L_2$ capacity: $S_2 = 256\\,\\text{KiB}$.\n    -   Block size: $B = 64\\,\\text{B}$.\n-   **Workload**: Repeatedly executes rounds. Each round consists of:\n    1.  Repeated accesses to a hot set $H$ of size $\\lvert H \\rvert$ that exactly fits in $L_1$ and remains resident there.\n    2.  A single sequential pass over a cold set $C$ of size $\\lvert C \\rvert$ blocks with no intra-pass temporal reuse.\n-   **Metric**: $L_2$ miss rate, $M_{L_2}$, is the fraction of $L_1$ misses that also miss in $L_2$.\n-   **Assumptions**:\n    1.  $L_1$ hits do not access $L_2$.\n    2.  Measurements focus on steady state; startup transients are negligible.\n    3.  When $\\lvert C \\rvert$ fits in the available $L_2$ capacity not occupied by duplicates of $H$, the cold-set blocks persist in $L_2$ across rounds; otherwise, they do not persist.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the validation criteria.\n\n-   **Scientifically Grounded**: The problem is well-grounded in the principles of computer architecture, specifically cache memory hierarchies. Inclusive and exclusive cache policies are standard, well-defined concepts. The workload, while simplified, is a standard model for analyzing cache performance with a mix of high-locality and streaming data.\n-   **Well-Posed**: The problem is clearly defined. The goal is to compare $M_{L_2}$ for two different cache policies under varying workload parameters. The givens are sufficient to determine the outcome. The assumption about steady-state persistence of set $C$ provides a clear, deterministic rule for the analysis, making the problem solvable.\n-   **Objective**: The problem is stated using precise, quantitative language. \"Hot set\" and \"cold set\" are defined by their access patterns, not subjective labels.\n-   **Completeness and Consistency**: The problem is self-contained. All necessary capacities, sizes, and behaviors are specified. The size of the hot set $H$ is implicitly defined as the capacity of $L_1$. Let's calculate the relevant sizes in blocks.\n    -   $L_1$ capacity in blocks: $S_{1, \\text{blocks}} = S_1 / B = (32 \\times 1024\\,\\text{B}) / (64\\,\\text{B}) = 512$ blocks.\n    -   $L_2$ capacity in blocks: $S_{2, \\text{blocks}} = S_2 / B = (256 \\times 1024\\,\\text{B}) / (64\\,\\text{B}) = 4096$ blocks.\n    -   Hot set size: $\\lvert H \\rvert = S_{1, \\text{blocks}} = 512$ blocks, as it \"exactly fits in $L_1$\".\n    There are no contradictions in the setup.\n-   **No Other Flaws**: The problem is not unrealistic, ill-posed, ambiguous, or trivial. It requires a proper application of the definitions of inclusive and exclusive caches to a capacity-based analysis.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. A rigorous solution can be derived from the provided information.\n\n## Solution Derivation\n\nThe core of the problem is to determine the available capacity in $L_2$ for the cold set $C$ under inclusive and exclusive policies, and then apply the given steady-state rule.\n\nThe workload has two parts:\n1.  Accesses to the hot set $H$. These are all $L_1$ hits. The problem states \"$L_1$ hits do not access $L_2$\". Thus, these accesses do not generate traffic to $L_2$ and do not affect its state or the $M_{L_2}$ metric.\n2.  A sequential pass over the cold set $C$. Since $L_1$ is full with the resident set $H$, every access to a block in $C$ will be an $L_1$ miss. The number of $L_1$ misses per round is therefore $\\lvert C \\rvert$.\nThe $L_2$ miss rate, $M_{L_2}$, is the fraction of these $L_1$ misses that also miss in $L_2$.\n\nThe steady-state behavior is determined by whether the set $C$ can persist in $L_2$ across rounds.\n-   If $C$ persists (i.e., it fits in the available $L_2$ capacity), then after the first round, subsequent accesses to $C$ will be $L_2$ hits. In steady state, $M_{L_2} \\approx 0$.\n-   If $C$ does not persist (i.e., it is larger than the available $L_2$ capacity), then the blocks of $C$ fetched in one round will be evicted before the next. In steady state, every access to a block in $C$ will be an $L_2$ miss, so $M_{L_2} \\approx 1$.\n\nLet's analyze the available $L_2$ capacity for each policy. The total $L_2$ capacity is $S_{2, \\text{blocks}} = 4096$ blocks. The hot set size is $\\lvert H \\rvert = 512$ blocks.\n\n### Inclusive Hierarchy ($L_1 \\subseteq L_2$)\nBy the inclusion property, any block present in $L_1$ must also be present in $L_2$. Since the hot set $H$ is resident in $L_1$, all $\\lvert H \\rvert = 512$ blocks of $H$ must also be resident in $L_2$. These blocks are repeatedly accessed, making them the most recently used, so they will not be evicted from $L_2$ by the sequential scan over $C$.\nThe capacity of $L_2$ available for the cold set $C$ is the total $L_2$ capacity minus the space consumed by the duplicate of $H$:\n$$ \\text{Available } L_2 \\text{ Capacity (Inclusive)} = S_{2, \\text{blocks}} - \\lvert H \\rvert = 4096 - 512 = 3584 \\text{ blocks} $$\nTherefore, for an inclusive hierarchy, $C$ persists if $\\lvert C \\rvert \\le 3584$.\n-   If $\\lvert C \\rvert \\le 3584$, $M_{L_2} \\approx 0$.\n-   If $\\lvert C \\rvert > 3584$, $M_{L_2} \\approx 1$.\n\n### Exclusive Hierarchy\nBy the exclusion property, a block cannot be present in both $L_1$ and $L_2$ simultaneously. The hot set $H$ resides in $L_1$. Therefore, the blocks of $H$ are not in $L_2$. The entire capacity of $L_2$ is available for other data, such as the cold set $C$.\n$$ \\text{Available } L_2 \\text{ Capacity (Exclusive)} = S_{2, \\text{blocks}} = 4096 \\text{ blocks} $$\nTherefore, for an exclusive hierarchy, $C$ persists if $\\lvert C \\rvert \\le 4096$.\n-   If $\\lvert C \\rvert \\le 4096$, $M_{L_2} \\approx 0$.\n-   If $\\lvert C \\rvert > 4096$, $M_{L_2} \\approx 1$.\n\n## Option-by-Option Analysis\n\nNow we evaluate each statement using these derived thresholds.\n\n**A. For $\\lvert C \\rvert = 4000$ blocks, an inclusive $L_2$ duplicates $H$ and leaves insufficient space for $C$, so $M_{L_2}$ for cold accesses is near $1$ in steady state; an exclusive $L_2$ has enough space for $C$, so $M_{L_2}$ for cold accesses is near $0$. Inclusion increases $M_{L_2}$ in this case.**\n-   **Inclusive**: $\\lvert C \\rvert = 4000$. The available capacity is $3584$ blocks. Since $4000 > 3584$, the cold set $C$ does not fit. The blocks of $C$ will not persist, and $L_2$ will thrash. Thus, $M_{L_2} \\approx 1$. The reasoning is correct.\n-   **Exclusive**: $\\lvert C \\rvert = 4000$. The available capacity is $4096$ blocks. Since $4000 \\le 4096$, the cold set $C$ fits. The blocks of $C$ will persist. Thus, $M_{L_2} \\approx 0$. The reasoning is correct.\n-   **Comparison**: Inclusion results in $M_{L_2} \\approx 1$, while exclusion results in $M_{L_2} \\approx 0$. Inclusion clearly increases $M_{L_2}$. The entire statement is correct.\n-   Verdict: **Correct**.\n\n**B. For $\\lvert C \\rvert = 3000$ blocks, both inclusive and exclusive $L_2$ retain the entire cold set across rounds, so $M_{L_2}$ for cold accesses is near $0$ in steady state; inclusion does not increase $M_{L_2}$.**\n-   **Inclusive**: $\\lvert C \\rvert = 3000$. The available capacity is $3584$ blocks. Since $3000 \\le 3584$, $C$ fits and persists. $M_{L_2} \\approx 0$.\n-   **Exclusive**: $\\lvert C \\rvert = 3000$. The available capacity is $4096$ blocks. Since $3000 \\le 4096$, $C$ fits and persists. $M_{L_2} \\approx 0$.\n-   **Comparison**: Both policies result in $M_{L_2} \\approx 0$. Thus, both retain the cold set, and inclusion does not increase $M_{L_2}$ (it remains unchanged at $0$). The statement is correct.\n-   Verdict: **Correct**.\n\n**C. For $\\lvert C \\rvert = 4096$ blocks, both inclusive and exclusive $L_2$ thrash on $C$ in steady state, so inclusion does not change $M_{L_2}$.**\n-   **Inclusive**: $\\lvert C \\rvert = 4096$. The available capacity is $3584$ blocks. Since $4096 > 3584$, an inclusive $L_2$ does not have space for $C$ and will thrash. $M_{L_2} \\approx 1$.\n-   **Exclusive**: $\\lvert C \\rvert = 4096$. The available capacity is $4096$ blocks. Since $4096 \\le 4096$, the cold set $C$ exactly fits and will persist. $M_{L_2} \\approx 0$.\n-   **Comparison**: The statement claims both thrash, which is false. The exclusive $L_2$ does not thrash. Inclusion changes $M_{L_2}$ from approximately $0$ to approximately $1$. The statement is incorrect.\n-   Verdict: **Incorrect**.\n\n**D. For $\\lvert C \\rvert = 3584$ blocks, both inclusive and exclusive $L_2$ retain the cold set across rounds, so $M_{L_2}$ for cold accesses is near $0$ in steady state; inclusion does not increase $M_{L_2}$.**\n-   **Inclusive**: $\\lvert C \\rvert = 3584$. The available capacity is $3584$ blocks. Since $3584 \\le 3584$, $C$ exactly fits and persists. $M_{L_2} \\approx 0$.\n-   **Exclusive**: $\\lvert C \\rvert = 3584$. The available capacity is $4096$ blocks. Since $3584 \\le 4096$, $C$ fits and persists. $M_{L_2} \\approx 0$.\n-   **Comparison**: Both policies result in $M_{L_2} \\approx 0$. Thus, both retain the cold set, and inclusion does not increase $M_{L_2}$. The statement is correct.\n-   Verdict: **Correct**.\n\n**E. Inclusion reduces $M_{L_2}$ for this workload because $H$ is present in $L_2$, allowing $L_2$ to serve hits to $H$ even when $L_1$ hits.**\n-   This statement makes two claims. First, that inclusion *reduces* $M_{L_2}$. Our analysis shows that for this workload, inclusion either increases $M_{L_2}$ (e.g., when $3584 < \\lvert C \\rvert \\le 4096$) or leaves it unchanged (when $\\lvert C \\rvert \\le 3584$ or $\\lvert C \\rvert > 4096$). It never reduces it.\n-   Second, the reasoning given is that \"$L_2$ can serve hits to $H$\". This is explicitly contradicted by the problem assumption that \"$L_1$ hits do not access $L_2$\". Since all accesses to $H$ are $L_1$ hits, the presence of $H$ in $L_2$ provides no benefit for hits. In fact, it is a detriment because it reduces the effective capacity of $L_2$ for the cold stream $C$. The entire premise of this option is flawed.\n-   Verdict: **Incorrect**.", "answer": "$$\\boxed{ABD}$$", "id": "3649269"}, {"introduction": "Beyond simple capacity arguments, we can use mathematical models to predict cache performance more formally. This problem introduces the Independent Reference Model (IRM), a common analytical tool, to explore how the structural difference between an inclusive and exclusive hierarchy affects the local L2 miss rate [@problem_id:3649293]. By working through this analysis, you will connect the abstract concept of reuse distance to concrete performance metrics and see how miss rates are interdependent in a cache hierarchy.", "problem": "A single-core Central Processing Unit (CPU) executes a workload on a two-level cache hierarchy with a first-level cache $L1$ and a second-level cache $L2$. Both caches use Least Recently Used (LRU) replacement, and capacities are expressed in cache lines. The $L1$ capacity is $C_{L1} = 64$ lines and the $L2$ capacity is $C_{L2} = 256$ lines. Consider first a baseline design in which $L2$ is exclusive of $L1$ (no duplicates are kept at $L2$). For this workload, the measured local miss rates are $M_{L1} = 0.5$ and $M_{L2} = 0.0625$.\n\nAssume the Independent Reference Model (IRM) with exponentially distributed reuse distance $D$ with parameter $\\alpha > 0$, meaning that for an LRU cache of capacity $C$ lines, the probability that a reference misses is $\\mathbb{P}(D > C) = \\exp(-\\alpha C)$. Local miss rate at a level is defined as the fraction of accesses to that level that miss.\n\nNow the hierarchy is changed to be inclusive: to maintain inclusion, $L2$ must reserve $C_{L1}$ lines to duplicate all $L1$ contents, leaving only $C_{L2,\\text{unique}} = C_{L2} - C_{L1}$ lines available in $L2$ for data not present in $L1$.\n\nStarting from the definitions of reuse distance and LRU stack behavior, derive the expression for the $L2$ local miss rate in the inclusive design. Then, using the given measurements and capacities, compute the numerical value of the inclusive $L2$ local miss rate. Express your final result as a decimal fraction and round your answer to four significant figures.", "solution": "The problem asks for the local miss rate of an L2 cache in an inclusive hierarchy, given measurements from a baseline exclusive hierarchy and a theoretical model for miss rates.\n\nFirst, we must validate the problem statement.\n\n**Step 1: Extract Givens**\n- CPU: single-core\n- Cache hierarchy: two-level ($L1$, $L2$)\n- Replacement policy: Least Recently Used (LRU)\n- $L1$ capacity: $C_{L1} = 64$ lines\n- $L2$ capacity: $C_{L2} = 256$ lines\n- Baseline design: $L2$ is exclusive of $L1$.\n- Baseline $L1$ local miss rate: $M_{L1} = 0.5$\n- Baseline $L2$ local miss rate (exclusive): $M_{L2} = 0.0625$\n- Workload model: Independent Reference Model (IRM) with reuse distance $D$.\n- Reuse distance distribution: $\\mathbb{P}(D > C) = \\exp(-\\alpha C)$ for an LRU cache of capacity $C$, with $\\alpha > 0$.\n- New design: $L2$ is inclusive of $L1$.\n- Inclusion property stated: $L2$ reserves $C_{L1}$ lines for $L1$ contents, leaving $C_{L2,\\text{unique}} = C_{L2} - C_{L1}$ lines for data not in $L1$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined within the domain of computer architecture and performance modeling. The concepts of inclusive/exclusive caches, LRU replacement, and miss rates are standard. The Independent Reference Model with an exponential reuse distance distribution is a common analytical tool, although a simplification of real-world behavior.\n\nWe must verify the consistency of the provided data with the given model.\nUnder the IRM applied to an LRU cache, the miss rate for a standalone cache of capacity $C$ is given by $\\mathbb{P}(D > C)$.\nThe $L1$ cache is the first point of contact for all memory references, so its local miss rate is modeled directly:\n$M_{L1} = \\mathbb{P}(D > C_{L1}) = \\exp(-\\alpha C_{L1})$\n\nFor the exclusive two-level hierarchy, an access is sent to $L2$ only if it misses $L1$. The local miss rate of $L2$, $M_{L2}$, is the conditional probability that a reference misses $L2$ given that it has missed $L1$. In an exclusive hierarchy where the total unique capacity is $C_{L1} + C_{L2}$, a miss from the entire hierarchy occurs if $D > C_{L1} + C_{L2}$. Thus, the local $L2$ miss rate is:\n$M_{L2, \\text{excl}} = \\mathbb{P}(D > C_{L1} + C_{L2} | D > C_{L1}) = \\frac{\\mathbb{P}((D > C_{L1}+C_{L2}) \\cap (D > C_{L1}))}{\\mathbb{P}(D > C_{L1})}$\nSince $C_{L1}$ and $C_{L2}$ are positive, $C_{L1} + C_{L2} > C_{L1}$, so the event $D > C_{L1} + C_{L2}$ implies $D > C_{L1}$. The intersection is just $D > C_{L1} + C_{L2}$.\n$M_{L2, \\text{excl}} = \\frac{\\mathbb{P}(D > C_{L1} + C_{L2})}{\\mathbb{P}(D > C_{L1})} = \\frac{\\exp(-\\alpha(C_{L1} + C_{L2}))}{\\exp(-\\alpha C_{L1})} = \\exp(-\\alpha C_{L2})$\n\nLet's check if a single value of $\\alpha$ satisfies both given measurements:\nFrom the $L1$ data: $M_{L1} = 0.5$ and $C_{L1} = 64$.\n$0.5 = \\exp(-\\alpha \\cdot 64)$\n$\\ln(0.5) = -64\\alpha \\implies -\\ln(2) = -64\\alpha \\implies \\alpha = \\frac{\\ln(2)}{64}$\n\nFrom the $L2$ data: $M_{L2} = 0.0625$ and $C_{L2} = 256$.\n$0.0625 = \\exp(-\\alpha \\cdot 256)$\nNote that $0.0625 = \\frac{1}{16} = (\\frac{1}{2})^4 = 2^{-4}$.\n$\\ln(2^{-4}) = -256\\alpha \\implies -4\\ln(2) = -256\\alpha \\implies \\alpha = \\frac{4\\ln(2)}{256} = \\frac{\\ln(2)}{64}$\nThe value of $\\alpha$ is consistent for both measurements. The problem is therefore scientifically sound, self-contained, and well-posed.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\n**Solution Derivation**\nThe goal is to find the local miss rate of the $L2$ cache in the inclusive design, which we denote as $M_{L2, \\text{incl}}$.\nIn an inclusive hierarchy, the contents of $L1$ are a strict subset of the contents of $L2$. The entire L1-L2 hierarchy effectively acts as a single large cache of capacity $C_{L2}$ with a faster-hitting portion of size $C_{L1}$.\nAn access hits in $L1$ if its reuse distance $D \\leq C_{L1}$.\nAn access hits in $L2$ (but misses in $L1$) if $C_{L1} < D \\leq C_{L2}$.\nAn access misses the entire hierarchy (a global miss) if $D > C_{L2}$.\nAn $L2$ miss in an inclusive hierarchy is, by definition, a global miss.\n\nThe local miss rate for $L2$ is the probability that a reference misses in $L2$ given that it was an access to $L2$ (i.e., it missed in $L1$).\n$M_{L2, \\text{incl}} = \\mathbb{P}(\\text{miss in } L2 | \\text{miss in } L1)$\nThe event \"miss in $L1$\" corresponds to $D > C_{L1}$.\nThe event \"miss in $L2$\" corresponds to $D > C_{L2}$.\nSo, we need to calculate the conditional probability:\n$M_{L2, \\text{incl}} = \\mathbb{P}(D > C_{L2} | D > C_{L1})$\n\nUsing the definition of conditional probability, $\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}$:\n$M_{L2, \\text{incl}} = \\frac{\\mathbb{P}((D > C_{L2}) \\cap (D > C_{L1}))}{\\mathbb{P}(D > C_{L1})}$\nAs $C_{L2} = 256$ is greater than $C_{L1} = 64$, any reuse distance $D$ greater than $C_{L2}$ is also greater than $C_{L1}$. Therefore, the intersection of the events is simply the event $D > C_{L2}$.\n$M_{L2, \\text{incl}} = \\frac{\\mathbb{P}(D > C_{L2})}{\\mathbb{P}(D > C_{L1})}$\n\nThis is the general expression for the inclusive $L2$ local miss rate under the IRM with LRU policy. The statement regarding $C_{L2,\\text{unique}}$ is a correct description of space allocation within an inclusive L2 cache but does not alter the fact that the total unique data buffered by the hierarchy corresponds to a capacity of $C_{L2}$.\n\nNow, we substitute the exponential distribution model:\n$\\mathbb{P}(D > C_{L2}) = \\exp(-\\alpha C_{L2})$\n$\\mathbb{P}(D > C_{L1}) = \\exp(-\\alpha C_{L1})$\n\nSo, $M_{L2, \\text{incl}} = \\frac{\\exp(-\\alpha C_{L2})}{\\exp(-\\alpha C_{L1})}$.\n\nWe can compute this value. From the analysis during validation, we recognize the terms:\nThe numerator, $\\exp(-\\alpha C_{L2})$, is precisely the expression for the local miss rate of the exclusive L2 cache from the baseline design, given as $M_{L2} = 0.0625$.\nThe denominator, $\\exp(-\\alpha C_{L1})$, is the local miss rate of the L1 cache, given as $M_{L1} = 0.5$.\n\nTherefore, we can calculate the result without explicitly finding $\\alpha$:\n$M_{L2, \\text{incl}} = \\frac{M_{L2, \\text{excl}}}{M_{L1}} = \\frac{0.0625}{0.5}$\n$M_{L2, \\text{incl}} = \\frac{1/16}{1/2} = \\frac{1}{16} \\times 2 = \\frac{2}{16} = \\frac{1}{8}$\n$M_{L2, \\text{incl}} = 0.125$\n\nThe problem requires the final answer to be expressed as a decimal fraction rounded to four significant figures. The number $0.125$ has three significant figures ($1, 2, 5$). To express it with four, we append a trailing zero.\n$M_{L2, \\text{incl}} = 0.1250$.", "answer": "$$\\boxed{0.1250}$$", "id": "3649293"}, {"introduction": "The choice between inclusive and exclusive hierarchies has implications beyond just hit rates and capacity. Maintaining the inclusion property requires specific coherence mechanisms, such as sending invalidation messages from a lower-level cache to an upper-level one. This exercise models a potential race condition that arises from this mechanism, challenging you to calculate the probability of a performance stall and appreciate the subtle complexities of cache coherence protocols [@problem_id:3649215].", "problem": "A single-core Central Processing Unit (CPU) has a private Level $1$ (L$1$) data cache and a private Level $2$ (L$2$) cache. The hierarchy is inclusive: every line present in L$1$ is also present in L$2$, and when L$2$ evicts a line, it issues a back-invalidation to L$1$ for that line. Consider a particular cache line, denoted $X$, which is currently valid in both L$1$ and L$2$. Loads to $X$ that hit in L$1$ have a deterministic service time of $\\tau_{L1} = 5$ cycles.\n\nWhile $X$ is resident and valid in L$2$, evictions of $X$ from L$2$ that trigger back-invalidations to L$1$ can be modeled at the L$1$ as a homogeneous Poisson arrival process for invalidation messages with rate $\\lambda_{i} = 0.03$ per cycle. Assume that the times at which loads to $X$ are issued are independent of the invalidation arrival process, and that just before a load to $X$ begins service in L$1$, $X$ is valid in L$1$.\n\nDefine a stall event as follows: if an invalidation for $X$ arrives at L$1$ at any time during the open interval of the load’s L$1$ service, that is, within $[t, t + \\tau_{L1})$ where $t$ is the load’s L$1$ service start time, the load is squashed and retried, incurring a stall attributed to the inclusive back-invalidation race.\n\nUsing only fundamental definitions of inclusive caches and standard properties of the homogeneous Poisson process, derive from first principles an expression for the stall probability $p_{s}$ that a randomly issued load to $X$ stalls due to this inclusive back-invalidation race, and then compute its numerical value for the given $\\lambda_{i}$ and $\\tau_{L1}$. Round your answer to $4$ significant figures. Express the final result as a decimal fraction with no units. For context, briefly explain why in an exclusive hierarchy (where L$2$ does not maintain copies of lines in L$1$), the same race does not occur.", "solution": "The problem will first be validated against the specified criteria for soundness and completeness.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   System: A single-core Central Processing Unit (CPU).\n-   Cache Hierarchy: A private Level $1$ (L$1$) data cache and a private Level $2$ (L$2$) cache.\n-   Inclusivity: The hierarchy is inclusive, meaning every line present in L$1$ is also present in L$2$. When L$2$ evicts a line, it issues a back-invalidation to L$1$ for that line.\n-   State: A cache line $X$ is currently valid in both L$1$ and L$2$.\n-   L$1$ Service Time: Loads to $X$ that hit in L$1$ have a deterministic service time of $\\tau_{L1} = 5$ cycles.\n-   Invalidation Model: Evictions of $X$ from L$2$ that trigger back-invalidations to L$1$ are modeled as a homogeneous Poisson arrival process at L$1$ with rate $\\lambda_{i} = 0.03$ per cycle.\n-   Assumptions:\n    1.  The times at which loads to $X$ are issued are independent of the invalidation arrival process.\n    2.  Just before a load to $X$ begins service in L$1$, $X$ is valid in L$1$.\n-   Stall Event Definition: An invalidation for $X$ arrives at L$1$ at any time during the open interval of the load’s L$1$ service, $[t, t + \\tau_{L1})$, where $t$ is the load’s L$1$ service start time.\n-   Required Outputs:\n    1.  Derive an expression for the stall probability $p_{s}$ from first principles.\n    2.  Compute the numerical value of $p_{s}$ for the given $\\lambda_{i}$ and $\\tau_{L1}$, rounded to $4$ significant figures.\n    3.  Briefly explain why this race condition does not occur in an exclusive cache hierarchy.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Groundedness**: The problem is grounded in the established principles of computer architecture, specifically the behavior of inclusive cache hierarchies. The concept of a back-invalidation upon an L$2$ eviction is fundamental to maintaining the inclusivity property. The use of a homogeneous Poisson process is a standard and scientifically valid method for modeling random, independent events in system performance analysis.\n-   **Well-Posedness**: The problem is well-posed. It provides all necessary parameters ($\\lambda_{i}$, $\\tau_{L1}$), a clear probabilistic model, and a precise definition of the event of interest (the stall). This allows for the derivation and calculation of a unique, meaningful solution.\n-   **Objectivity**: The language is formal, precise, and free of subjective or ambiguous terminology.\n-   **Completeness and Consistency**: The problem is self-contained and internally consistent. The crucial assumption that line $X$ is valid in L$1$ at the start of the load service isolates the problem to the race condition during the service interval, which is precisely what needs to be analyzed. No essential information is missing, and no constraints are contradictory.\n-   **Realism and Feasibility**: The provided numerical values for L$1$ service time ($\\tau_{L1} = 5$ cycles) and invalidation rate ($\\lambda_{i} = 0.03$ per cycle) are physically plausible for modern processor architectures.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid** as it is scientifically sound, well-posed, and complete. A full solution will be provided.\n\n### Solution Derivation\n\nThe problem asks for the probability of a specific stall event. This event is defined as the arrival of at least one back-invalidation message for cache line $X$ during the time the L$1$ cache is servicing a load to that same line $X$.\n\nLet $N(T)$ be the random variable representing the number of invalidation arrivals in a time interval of duration $T$. The problem states that these arrivals follow a homogeneous Poisson process with a constant rate $\\lambda_{i}$. The probability mass function for a Poisson process gives the probability of observing exactly $k$ events in an interval of duration $T$:\n$$ P(N(T) = k) = \\frac{(\\lambda_{i} T)^{k} \\exp(-\\lambda_{i} T)}{k!} $$\nwhere $k$ is a non-negative integer ($k=0, 1, 2, \\dots$).\n\nThe load to line $X$ has a deterministic service time of $\\tau_{L1}$. The stall event occurs if one or more invalidation messages arrive during this service period. Therefore, the duration of the time interval under consideration is $T = \\tau_{L1}$.\n\nThe stall probability, $p_{s}$, is the probability that the number of invalidation arrivals in the interval of length $\\tau_{L1}$ is greater than or equal to one.\n$$ p_{s} = P(N(\\tau_{L1}) \\ge 1) $$\n\nIt is more direct to first calculate the probability of the complementary event: that zero invalidations arrive during the interval. Using the Poisson probability mass function with $k=0$ and $T=\\tau_{L1}$:\n$$ P(N(\\tau_{L1}) = 0) = \\frac{(\\lambda_{i} \\tau_{L1})^{0} \\exp(-\\lambda_{i} \\tau_{L1})}{0!} $$\n\nBy definition, $x^0 = 1$ for any non-zero $x$, and $0! = 1$. This simplifies the expression to:\n$$ P(N(\\tau_{L1}) = 0) = \\exp(-\\lambda_{i} \\tau_{L1}) $$\n\nThe probability of at least one event is the complement of the probability of zero events. Therefore, the stall probability $p_{s}$ is derived from first principles as:\n$$ p_{s} = 1 - P(N(\\tau_{L1}) = 0) = 1 - \\exp(-\\lambda_{i} \\tau_{L1}) $$\nThis is the analytical expression for the stall probability.\n\nNext, we compute the numerical value using the given parameters:\n-   Invalidation rate: $\\lambda_{i} = 0.03 \\text{ cycle}^{-1}$\n-   L$1$ service time: $\\tau_{L1} = 5 \\text{ cycles}$\n\nThe argument of the exponent is the product $\\lambda_{i} \\tau_{L1}$:\n$$ \\lambda_{i} \\tau_{L1} = (0.03) \\times (5) = 0.15 $$\nThis product is a dimensionless quantity, as required for an exponent.\n\nSubstituting this value into the expression for $p_{s}$:\n$$ p_{s} = 1 - \\exp(-0.15) $$\n\nCalculating the numerical value:\n$$ \\exp(-0.15) \\approx 0.860707976... $$\n$$ p_{s} \\approx 1 - 0.860707976... = 0.139292023... $$\n\nRounding the result to $4$ significant figures, we get:\n$$ p_{s} \\approx 0.1393 $$\n\n### Exclusive Hierarchy Context\n\nThe final part of the problem asks why this race condition does not occur in an exclusive cache hierarchy. An exclusive hierarchy enforces the property that a given cache line can reside in at most one of the caches in the hierarchy (excluding main memory). Specifically, if a line is present in the L$1$ cache, it cannot be simultaneously present in the L$2$ cache.\n\n1.  **Fundamental Premise of the Race**: The described race condition is initiated by an L$2$ cache eviction. The L$2$ cache evicts line $X$, and because the hierarchy is inclusive, it must send a back-invalidation to the L$1$ cache to remove its copy of $X$ and maintain the inclusion property. This invalidation can arrive while L$1$ is servicing a load to $X$, causing a stall.\n\n2.  **Exclusivity Prevents the Trigger**: In an exclusive hierarchy, if line $X$ is valid in the L$1$ cache (as is the case when the load is being serviced), it is, by definition, *not* present in the L$2$ cache. Since line $X$ is not in the L$2$ cache, the L$2$ cache cannot evict it. An L$2$ eviction can only target a line that is resident in L$2$. Therefore, the event that triggers the back-invalidation in the inclusive case—the L$2$ eviction of line $X$—is structurally impossible in an exclusive hierarchy. Consequently, the specific race condition between an L$1$ load access and an L$2$-sourced back-invalidation for the same line cannot occur.", "answer": "$$\\boxed{0.1393}$$", "id": "3649215"}]}