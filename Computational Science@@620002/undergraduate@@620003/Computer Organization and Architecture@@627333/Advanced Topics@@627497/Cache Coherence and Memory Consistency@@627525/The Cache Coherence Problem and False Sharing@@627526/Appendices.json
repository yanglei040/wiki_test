{"hands_on_practices": [{"introduction": "The most direct way to prevent false sharing is to control the memory layout of your data structures. Since coherence protocols operate on entire cache lines, you can eliminate costly, unnecessary invalidations by ensuring that data concurrently accessed by different threads resides on separate cache lines. This practice [@problem_id:3684636] provides a foundational exercise in this technique, guiding you to derive a general formula for the padding required to align array elements to cache line boundaries and quantify the resulting memory overhead.", "problem": "Consider a shared-memory multiprocessor with private caches and a bus-based cache coherence protocol operating at cache-line granularity. Each cache line has size $B$ bytes, and coherence actions (such as invalidation or update) apply to entire cache lines. False sharing arises when two threads write to distinct memory locations that reside in the same cache line, triggering coherence traffic even though the threads do not truly share data at the semantic level. To eliminate false sharing for an array of elements, it is sufficient to ensure that no two distinct elements ever reside in the same cache line.\n\nSuppose an array consists of contiguous elements, each being a structure of size $s$ bytes. To prevent false sharing, we append padding of $p$ bytes to each element so that the stride $t$ between consecutive element starts is $t = s + p$. Assume the allocator returns a base address aligned to the cache line size, i.e., the base address is a multiple of $B$. The goal is to choose padding $p$ minimally such that, for any cache line size $B$, no two distinct elements share any cache line.\n\nStarting from the fundamental definitions that cache coherence operates at cache-line granularity and that alignment to multiples of $B$ places element starts on cache line boundaries, derive a closed-form expression for the minimum padding $p$ in terms of $s$ and $B$ that guarantees no cache line is shared by two distinct elements. Then compute the memory overhead ratio $\\rho$ defined by $\\rho = (s + p)/s$.\n\nExpress your final results as closed-form analytic expressions in terms of $s$ and $B$. No numerical approximation or rounding is required.", "solution": "The problem requires the derivation of a closed-form expression for the minimum padding $p$ needed to prevent false sharing for an array of elements, and the corresponding memory overhead ratio $\\rho$. The elements, each of size $s$ bytes, are to be padded such that the stride $t$ between consecutive elements becomes $t = s + p$. The cache line size is $B$ bytes, and the base address of the array is aligned to a multiple of $B$. The condition to eliminate false sharing is that no two distinct elements share any cache line.\n\nLet the base address of the array be $A_{base}$. The problem states that $A_{base}$ is a multiple of $B$, so $A_{base} = k_0 B$ for some integer $k_0$. We can analyze the memory layout using addresses relative to $A_{base}$, effectively setting the starting address of the array to $0$ without loss of generality.\n\nAn element of size $s$ is padded with $p$ bytes, resulting in a total occupied space or stride of $t = s+p$ bytes between the start of consecutive elements. The address of the start of the $i$-th element (0-indexed) is given by $a_i = i \\cdot t$. The memory occupied by the $i$-th element itself (excluding padding) is the byte range $[a_i, a_i + s - 1]$.\n\nCache coherence operates on cache lines of size $B$. A memory address $x$ resides in the cache line that covers the address range $[B \\cdot \\lfloor x/B \\rfloor, B \\cdot \\lfloor x/B \\rfloor + B - 1]$.\n\nThe condition that no two distinct elements share a cache line must hold for all pairs of elements. It is sufficient to enforce this for any two consecutive elements, say element $i$ and element $i+1$. If this holds for all $i$, then by transitivity, it holds for any two distinct elements.\n\nThe most robust and direct method to guarantee that each element resides in a set of cache lines disjoint from all other elements is to ensure that each element starts on a cache line boundary. Since the base address of the array is already on a cache line boundary, this can be achieved by making the stride $t$ a multiple of the cache line size $B$.\n\nLet us set the stride $t$ to be an integer multiple of $B$, i.e., $t = mB$ for some positive integer $m$. The start address of element $i$ is $a_i = i \\cdot t = i \\cdot mB$. Since $i$ and $m$ are integers, $a_i$ is always a multiple of $B$. Thus, every element begins exactly at the start of a cache line.\n\nNow we must ensure that the data of element $i$ does not extend into the cache line where element $i+1$ begins.\nElement $i$ occupies the address range $[a_i, a_i + s - 1]$.\nElement $i+1$ starts at address $a_{i+1} = a_i + t$.\nThe last byte of element $i$ must be at an address strictly less than the starting address of element $i+1$. This is guaranteed by construction, as $a_i + s - 1 < a_i + s \\le a_i + t = a_{i+1}$ since $p \\ge 0$.\n\nThe crucial condition is that the cache lines occupied by element $i$ do not overlap with those for element $i+1$.\nThe set of cache lines for element $i$ starts with the line containing $a_i$. The last cache line for element $i$ is the one containing address $a_i + s - 1$. The starting address of this last line is $B \\cdot \\lfloor (a_i + s - 1)/B \\rfloor$. The next cache line begins at address $B \\cdot (\\lfloor (a_i + s - 1)/B \\rfloor + 1)$.\nThe start of element $i+1$ is $a_{i+1}$. Since $a_{i+1}$ is a cache line boundary, the requirement is that $a_{i+1}$ must be greater than or equal to the start of the next available cache line after element $i$.\nThat is, $a_{i+1} \\ge B \\cdot (\\lfloor (a_i + s - 1)/B \\rfloor + 1)$.\nSince $a_i$ and $a_{i+1}$ are multiples of $B$, let $a_i = k_i B$ and $a_{i+1} = k_{i+1} B$.\n$k_{i+1} B \\ge B \\cdot (\\lfloor (k_i B + s - 1)/B \\rfloor + 1)$.\n$k_{i+1} \\ge \\lfloor k_i + (s - 1)/B \\rfloor + 1$.\n$k_{i+1} \\ge k_i + \\lfloor (s - 1)/B \\rfloor + 1$.\nUsing $k_{i+1} = a_{i+1}/B = (a_i+t)/B = k_i + t/B$, we get:\n$k_i + t/B \\ge k_i + \\lfloor (s - 1)/B \\rfloor + 1$.\n$t/B \\ge \\lfloor (s - 1)/B \\rfloor + 1$.\n\nFor any integer $s \\ge 1$ and $B > 0$, the identity $\\lceil s/B \\rceil = \\lfloor (s-1)/B \\rfloor + 1$ holds.\nThus, the condition becomes $t/B \\ge \\lceil s/B \\rceil$.\nSince $t$ must be a multiple of $B$, let $t=mB$. Then $m \\ge \\lceil s/B \\rceil$.\nTo minimize padding $p$, we must minimize the stride $t$. This is achieved by choosing the smallest possible integer value for $m$, which is $m_{min} = \\lceil s/B \\rceil$.\n\nThe minimum stride that guarantees no false sharing is therefore:\n$$t_{min} = B \\cdot \\lceil s/B \\rceil$$\nThis stride must also be at least the size of the element itself, $t_{min} \\ge s$.\nSince $\\lceil s/B \\rceil \\ge s/B$, multiplying by $B$ gives $B \\cdot \\lceil s/B \\rceil \\ge s$. So, $t_{min} \\ge s$ is always satisfied.\n\nThe minimum required padding $p$ is the difference between this minimum stride and the element size $s$:\n$$p = t_{min} - s = B \\cdot \\left\\lceil \\frac{s}{B} \\right\\rceil - s$$\n\nThe second part of the problem is to compute the memory overhead ratio $\\rho$, defined as $\\rho = (s+p)/s$.\nSubstituting $s+p = t_{min}$:\n$$\\rho = \\frac{t_{min}}{s} = \\frac{B \\cdot \\lceil s/B \\rceil}{s}$$\n\nThe derived expressions for $p$ and $\\rho$ are in terms of $s$ and $B$ and are in closed form as requested.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nB \\left\\lceil \\frac{s}{B} \\right\\rceil - s & \\frac{B \\left\\lceil \\frac{s}{B} \\right\\rceil}{s}\n\\end{pmatrix}\n}\n$$", "id": "3684636"}, {"introduction": "While understanding memory layout is key to prevention, detecting false sharing in existing code is a crucial diagnostic skill. This practice [@problem_id:3684650] bridges theory and real-world performance analysis by asking you to design an experiment that uses hardware performance counters to definitively identify false sharing. You will learn to recognize the characteristic signature of this issue—a high rate of coherence events like Read-For-Ownership requests ($\\mathrm{L1\\_RFO}$) and Hit-on-Modified ($\\mathrm{HITM}$) responses—by contrasting a problematic workload with a properly padded control.", "problem": "Consider a shared-memory multiprocessor with $k$ symmetric Central Processing Unit (CPU) cores, each with a private Level One (L1) write-back cache and a shared last-level cache. The machine implements the Modified-Exclusive-Shared-Invalid (MESI) cache coherence protocol. Two threads, denoted $T_1$ and $T_2$, run concurrently on different cores. The false sharing phenomenon is defined as simultaneous accesses by multiple threads to distinct memory locations that reside within the same cache line, causing coherence traffic even though no actual data dependency exists.\n\nFundamental base: Under a snooping MESI protocol, a store by a core to an address not currently in the Exclusive or Modified state in its cache triggers a Read For Ownership, i.e., Level One Read For Ownership ($\\mathrm{L1\\_RFO}$), to obtain the line in an exclusive state. If another core holds the line in Modified state, the request observes a Hit on Modified ($\\mathrm{HITM}$) response and the modified data is supplied by the peer core. Snoop Response ($\\mathrm{SNOOP\\_RESP}$) counters classify coherence responses such as invalidations, hits, or hit-modified events. False sharing typically produces ping-ponging of a cache line between cores: frequent invalidations, repeated transitions to Modified, and high rates of $\\mathrm{L1\\_RFO}$ and $\\mathrm{HITM}$ relative to useful memory operations.\n\nYou are tasked with selecting an experimental method and expected counter signatures that best isolate and detect false sharing using performance counters, including $\\mathrm{L1\\_RFO}$, $\\mathrm{HITM}$, and $\\mathrm{SNOOP\\_RESP}$. The experiment should contrast a false sharing scenario with a control that eliminates false sharing. Let the cache line size be $L = 64$ bytes. Assume the workload performs $N$ iterations where each iteration writes an $8$-byte word per thread.\n\nWhich option best describes a scientifically sound experiment and the expected counter behavior that indicates false sharing?\n\nA. Pin $T_1$ and $T_2$ to different cores. Allocate a single array $A$ and assign $T_1$ to update $A[i]$ and $T_2$ to update $A[i+1]$ for each iteration $i$, with $A$ laid out such that $A[i]$ and $A[i+1]$ are distinct $8$-byte words within the same cache line of size $L = 64$. Run for $N$ iterations. Then run a padded version where $A[i]$ and $A[i+1]$ are separated so they fall on different cache lines (e.g., stride or explicit padding of at least $L$ bytes). Expect the false-sharing run to exhibit a large increase in $\\mathrm{L1\\_RFO}$ per store, many invalidation-related $\\mathrm{SNOOP\\_RESP}$ events, and elevated $\\mathrm{HITM}$ responses relative to the padded control. The padded control should show significantly fewer $\\mathrm{L1\\_RFO}$ and $\\mathrm{HITM}$ events per store and lower invalidation-related $\\mathrm{SNOOP\\_RESP}$, with similar last-level cache miss rates between runs.\n\nB. Pin $T_1$ and $T_2$ to different cores. Allocate two arrays $A$ and $B$ aligned so that each element updated by $T_1$ and $T_2$ is placed on different cache lines. Perform only reads (no stores) in both threads for $N$ iterations. Expect a surge of $\\mathrm{HITM}$ events during the read-only run, proving false sharing, and expect the padded control to show higher last-level cache ($\\mathrm{LLC}$) miss rate but lower $\\mathrm{L1\\_RFO}$.\n\nC. Pin $T_1$ and $T_2$ to different cores. Use a single shared counter and have both threads perform atomic increments for $N$ iterations. Expect extremely high $\\mathrm{HITM}$ and $\\mathrm{L1\\_RFO}$, and conclude false sharing. As a control, replace atomic increments with relaxed loads to the same shared counter and expect the counters to drop sharply, validating that elevated $\\mathrm{HITM}$ was due to false sharing.\n\nD. Pin $T_1$ and $T_2$ to simultaneous multithreading (SMT) on the same physical core. Use two local variables in each thread mapped to the same cache line. Expect that false sharing will be detectable primarily via increases in last-level cache ($\\mathrm{LLC}$) misses and decreases in $\\mathrm{HITM}$ relative to a padded control, because SMT threads share the L1 cache and thus coherence traffic is minimized. Conclude false sharing if last-level cache misses rise in the unpadded run.\n\nE. Pin $T_1$ and $T_2$ to different cores. Allocate a shared data structure such that both threads frequently write to the exact same $8$-byte word. Expect large $\\mathrm{L1\\_RFO}$ and $\\mathrm{HITM}$ counts in this run, and conclude that these counter elevations demonstrate false sharing. Use a control where each thread writes to its own independent word within the same cache line; expect little change in $\\mathrm{HITM}$ and $\\mathrm{L1\\_RFO}$, confirming the presence of false sharing in the first run only.\n\nSelect the single best option.", "solution": "A scientifically sound experiment to detect false sharing must compare a scenario that induces the phenomenon against a control scenario that eliminates it, while keeping all other factors constant. The signature of false sharing is a high rate of coherence traffic for writes to logically independent data.\n\n*   **Option A** correctly designs this experiment. The test case has two threads on different cores writing to distinct but adjacent memory locations within the same cache line, a canonical setup for false sharing. The control case properly isolates the variable of interest by using padding to place the data on different cache lines. The expected performance counter signature is also correct: false sharing causes the cache line to \"ping-pong\" between the cores. Each write by a thread to a line held in a modified state by another core will trigger a Read-For-Ownership (RFO) request and a Hit-on-Modified (HITM) response, leading to high counts for $\\mathrm{L1\\_RFO}$ and $\\mathrm{HITM}$ events, which will be absent in the padded control case.\n\n*   **Option B** is incorrect because false sharing is a write-induced phenomenon. A read-only workload allows multiple cores to hold the line in a Shared (S) state without conflict, generating no RFOs or HITMs.\n\n*   **Option C** describes true sharing (contention), not false sharing, because both threads write to the *exact same* memory location. While it generates high coherence traffic, it misidentifies the cause.\n\n*   **Option D** is incorrect because it places threads on the same physical core using SMT. These threads share an L1 cache, so accesses to the same cache line do not trigger the inter-core coherence protocol. This setup cannot be used to measure inter-core false sharing.\n\n*   **Option E** incorrectly defines its cases. The scenario it labels as a test for false sharing (writing to the *same* word) is actually true sharing. The scenario it labels as a control (writing to *different* words on the same line) is actually the canonical false sharing case, and it incorrectly predicts that coherence traffic would not change.\n\nTherefore, Option A provides the only correct experimental design and expected outcome for detecting false sharing.", "answer": "$$\\boxed{A}$$", "id": "3684650"}, {"introduction": "For highly contended data structures, simple padding is often insufficient, and more advanced design patterns are required. This exercise [@problem_id:3684573] explores sharding, a powerful technique for distributing access, but one that introduces its own overhead for data aggregation. You will practice analytical performance modeling to formalize this trade-off, deriving a cost function that balances the reduction in coherence traffic against the cost of merging, and use it to determine the optimal system configuration.", "problem": "A shared counter is incremented concurrently by $N$ identical hardware threads on a multicore processor with a write-invalidate cache coherence protocol. To reduce coherence traffic and false sharing, the counter is sharded into $S$ independent shards, each stored entirely within a single cache line. Threads are partitioned evenly across shards, so each shard is updated by $g = N/S$ threads. Each thread issues increments as an independent Poisson process of rate $r$ increments per second. An increment is an atomic read-modify-write on the shard’s cache line. Assume the following base facts and definitions:\n- Under a write-invalidate protocol, a write to a cache line by a thread incurs a cache-line ownership transfer (and associated stall) if and only if the immediately preceding write to that line was performed by a different thread. Each such transfer incurs a stall cost of $t_b$ core-seconds for the writing core.\n- The superposition of independent Poisson processes of rates $r$ is Poisson with rate equal to the sum of the rates, and the source identity of each event is independent and identically distributed with probability equal to the fraction of the total rate contributed by that source.\n- A dedicated merger thread periodically aggregates the $S$ shards into a single global value every $\\tau$ seconds. To ensure correctness, it pauses all updates while scanning the shards. Scanning and accumulating one shard takes $t_m$ seconds, so each merge pause lasts $S t_m$ seconds. During a pause, all $N$ threads are stalled.\n\nDefine the total cost per wall-second as $T(S) = T_{\\text{coh}}(S) + T_{\\text{merge}}(S)$, where $T_{\\text{coh}}(S)$ is the sum over threads of coherence-induced stall time per wall-second, and $T_{\\text{merge}}(S)$ is the sum over threads of merge-induced stall time per wall-second.\n\nTasks:\n1. Starting from the above definitions and the properties of Poisson superposition, derive $T_{\\text{coh}}(S)$ as a function of $N$, $r$, $t_b$, and $S$ by computing the expected rate (per wall-second) of ownership transfers on one shard with $g = N/S$ writers and then summing over all shards.\n2. Using the merge model, derive $T_{\\text{merge}}(S)$ as a function of $N$, $S$, $t_m$, and $\\tau$.\n3. Let $N \\in \\{1,2,\\dots\\}$ and restrict $S$ to the integer set $\\{1,2,\\dots,N\\}$. With the numeric parameters $N = 32$, $r = 1.0 \\times 10^{6}$ increments per second per thread, $t_b = 80$ nanoseconds, $t_m = 1.0$ microsecond, and $\\tau = 10$ milliseconds, compute the optimal shard count $S^{\\ast}$ that minimizes $T(S)$ over the allowed integer values of $S$.\n\nReport the final answer as the single integer $S^{\\ast}$ with no units.", "solution": "The problem asks for the optimal number of shards, $S^{\\ast}$, that minimizes the total stall cost per second, $T(S) = T_{\\text{coh}}(S) + T_{\\text{merge}}(S)$. We will derive expressions for each cost component and then find the value of $S$ that minimizes their sum.\n\n**1. Derivation of Coherence Cost, $T_{\\text{coh}}(S)$**\n\n-   A single shard is updated by $g = N/S$ threads, each with an increment rate of $r$. The total increment rate on one shard is $R_{\\text{shard}} = g \\cdot r = (N/S)r$.\n-   A coherence stall occurs if consecutive increments on a shard come from different threads. Since each of the $g$ threads is equally likely to perform the next increment, the probability that the next increment comes from the *same* thread as the last one is $1/g$.\n-   The probability that the next increment comes from a *different* thread is therefore $1 - 1/g$.\n-   The rate of coherence-inducing transfers for one shard is $R_{\\text{transfer, shard}} = R_{\\text{shard}} \\times (1 - 1/g) = (N/S)r \\times (1 - S/N) = r(N/S - 1)$.\n-   The stall cost per second for one shard is this rate times the stall cost per transfer, $t_b$: $T_{\\text{coh, shard}} = r t_b (N/S - 1)$.\n-   The total coherence cost for all $S$ shards is $T_{\\text{coh}}(S) = S \\times T_{\\text{coh, shard}} = S \\times r t_b (N/S - 1) = r t_b (N - S)$.\n\n**2. Derivation of Merge Cost, $T_{\\text{merge}}(S)$**\n\n-   A merge occurs every $\\tau$ seconds.\n-   The duration of the merge pause is the time to scan all $S$ shards: $D_{\\text{pause}} = S t_m$.\n-   During this pause, all $N$ threads are stalled. The total stall time per merge cycle is $N \\times D_{\\text{pause}} = N S t_m$ core-seconds.\n-   The merge cost per wall-second is this total stall time averaged over the cycle period $\\tau$: $T_{\\text{merge}}(S) = \\frac{N S t_m}{\\tau}$.\n\n**3. Minimizing the Total Cost Function, $T(S)$**\n\nThe total cost is the sum of the two components:\n$$T(S) = T_{\\text{coh}}(S) + T_{\\text{merge}}(S) = r t_b (N - S) + \\frac{N S t_m}{\\tau}$$\nWe can rearrange this to show its linear dependence on $S$:\n$$T(S) = (N r t_b) + S \\left(\\frac{N t_m}{\\tau} - r t_b\\right)$$\nThis is a linear function of $S$. The optimal value over the integer domain $S \\in \\{1, 2, \\dots, N\\}$ will be at one of the endpoints, $S=1$ or $S=N$, depending on the sign of the slope, $m = \\frac{N t_m}{\\tau} - r t_b$.\n\n-   If $m > 0$, the cost increases with $S$, so $S^{\\ast}=1$.\n-   If $m  0$, the cost decreases with $S$, so $S^{\\ast}=N$.\n\nNow, we plug in the given numerical values:\n-   $N = 32$\n-   $r = 1.0 \\times 10^{6} \\, \\text{s}^{-1}$\n-   $t_b = 80 \\times 10^{-9} \\, \\text{s}$\n-   $t_m = 1.0 \\times 10^{-6} \\, \\text{s}$\n-   $\\tau = 10 \\times 10^{-3} \\, \\text{s}$\n\nCalculate the two terms of the slope:\n-   Merge term: $\\frac{N t_m}{\\tau} = \\frac{32 \\times 1.0 \\times 10^{-6}}{10 \\times 10^{-3}} = \\frac{32 \\times 10^{-6}}{10^{-2}} = 3.2 \\times 10^{-3} = 0.0032$.\n-   Coherence term: $r t_b = (1.0 \\times 10^{6}) \\times (80 \\times 10^{-9}) = 80 \\times 10^{-3} = 0.08$.\n\nThe slope is $m = 0.0032 - 0.08 = -0.0768$.\nSince the slope is negative, the total cost $T(S)$ is minimized by choosing the largest possible value for $S$. Given the domain $S \\in \\{1, 2, \\dots, N\\}$, the optimal value is $S^{\\ast} = N$.\n\nWith $N = 32$, the optimal shard count is $S^{\\ast} = 32$.", "answer": "$$\\boxed{32}$$", "id": "3684573"}]}