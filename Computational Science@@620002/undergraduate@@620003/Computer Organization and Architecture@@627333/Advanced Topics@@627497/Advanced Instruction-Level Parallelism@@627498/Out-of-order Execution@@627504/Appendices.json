{"hands_on_practices": [{"introduction": "This practice will guide you through a cycle-by-cycle simulation of an out-of-order processor. You will first determine the theoretical minimum execution time by analyzing the data dependency graph, known as the critical path. Then, you will simulate the same program on a core with realistic constraints, such as limited issue width and a finite number of functional units, to see how these resource limitations impact the final performance [@problem_id:3662826]. This exercise provides a concrete understanding of how structural hazards create a gap between ideal and actual performance in modern CPUs.", "problem": "Consider an instruction-level dataflow graph that models a straight-line program fragment in an Out-of-Order (OOO) superscalar core. Each node $i$ is an instruction with latency $L_i$ (in cycles), and there is a directed edge $j \\rightarrow i$ if $i$ depends on the result of $j$. Assume that operands not produced by any node (e.g., constants) are ready at cycle $0$. The graph has the following nodes and edges, with latencies:\n- Nodes and latencies:\n  - $I_1$: load, $L_1 = 3$\n  - $I_2$: load, $L_2 = 3$\n  - $I_3$: multiply, $L_3 = 3$\n  - $I_4$: integer add, $L_4 = 1$\n  - $I_5$: integer add, $L_5 = 1$\n  - $I_6$: multiply, $L_6 = 3$\n  - $I_7$: integer add, $L_7 = 1$\n  - $I_8$: store, $L_8 = 1$\n- Directed edges (true dependencies):\n  - $I_1 \\rightarrow I_3$, $I_2 \\rightarrow I_3$, $I_2 \\rightarrow I_5$, $I_3 \\rightarrow I_4$, $I_4 \\rightarrow I_6$, $I_5 \\rightarrow I_6$, $I_6 \\rightarrow I_7$, $I_7 \\rightarrow I_8$\n- All other inputs to $I_4$, $I_5$, and $I_7$ are independent constants ready at cycle $0$. Addresses for $I_1$, $I_2$, and $I_8$ are ready at cycle $0$, and the memory system has no cache misses or conflicts.\n\nArchitecture model (fixed for this problem):\n- The core performs Out-of-Order (OOO) execution with register renaming, unbounded Reservation Stations (RS), and an unbounded Reorder Buffer (ROB).\n- Issue width $W = 2$: at most $2$ instructions can be issued per cycle.\n- Functional units (all fully pipelined):\n  - One load unit (for $I_1$, $I_2$) that can start at most one load per cycle; load latency $3$.\n  - Two identical integer arithmetic logic units (ALUs) for adds (for $I_4$, $I_5$, $I_7$); each has latency $1$ and can accept one new add per cycle.\n  - One multiply unit (for $I_3$, $I_6$) with latency $3$; it can accept one new multiply per cycle.\n  - One store unit (for $I_8$) with latency $1$; it can accept one new store per cycle.\n- Timing semantics: if an instruction starts at cycle $t$ with latency $L$, its result becomes available at the start of cycle $t+L$. A dependent instruction may start at cycle $t+L$ provided a matching functional unit can accept it and the issue width is not exceeded in that cycle.\n- Deterministic tie-breaking: in any cycle, among all ready instructions that could be issued given unit availability, the scheduler selects in increasing instruction index order until the per-cycle issue width is reached.\n\nTask:\n1. Compute the earliest start time $\\operatorname{EST}(I_i)$ for each node $I_i$ using only data dependencies and latencies (i.e., assuming unlimited functional units and unlimited issue width). Then compute the critical-path completion time $T_{\\mathrm{CP}}$ for the final instruction $I_8$ under these dependency-only constraints.\n2. Under the given OOO core constraints, compute the actual scheduled completion time $T_{\\mathrm{OOO}}$ of $I_8$ by simulating cycle-by-cycle issue subject to readiness, functional unit availability, and the issue width. Use the timing semantics and tie-breaking rule exactly as specified.\n3. Let $\\Delta = T_{\\mathrm{OOO}} - T_{\\mathrm{CP}}$. What is the value of $\\Delta$? Express your answer in cycles as a single real number. Do not include any unit label in the final numeric answer. No rounding is required.", "solution": "The user wants me to solve a computer architecture problem involving out-of-order execution.\n\n### Step 1: Extract Givens\n- **Nodes and Latencies ($L_i$)**:\n  - $I_1$: load, $L_1 = 3$ cycles\n  - $I_2$: load, $L_2 = 3$ cycles\n  - $I_3$: multiply, $L_3 = 3$ cycles\n  - $I_4$: integer add, $L_4 = 1$ cycle\n  - $I_5$: integer add, $L_5 = 1$ cycle\n  - $I_6$: multiply, $L_6 = 3$ cycles\n  - $I_7$: integer add, $L_7 = 1$ cycle\n  - $I_8$: store, $L_8 = 1$ cycle\n- **Directed Edges (Dependencies)**:\n  - $I_1 \\rightarrow I_3$, $I_2 \\rightarrow I_3$, $I_2 \\rightarrow I_5$, $I_3 \\rightarrow I_4$, $I_4 \\rightarrow I_6$, $I_5 \\rightarrow I_6$, $I_6 \\rightarrow I_7$, $I_7 \\rightarrow I_8$\n- **Initial Conditions**:\n  - Operands not produced by any node are ready at cycle $0$.\n  - Addresses for $I_1$, $I_2$, and $I_8$ are ready at cycle $0$.\n- **Architecture Model**:\n  - Out-of-Order (OOO) execution, unbounded Reservation Stations (RS) and Reorder Buffer (ROB).\n  - Issue width $W = 2$ instructions per cycle.\n  - Functional Units (all fully pipelined):\n    - $1$ load unit (can start $1$ load/cycle).\n    - $2$ integer ALUs (each can start $1$ add/cycle, total $2$ adds/cycle).\n    - $1$ multiply unit (can start $1$ multiply/cycle).\n    - $1$ store unit (can start $1$ store/cycle).\n- **Timing Semantics**:\n  - Instruction starting at cycle $t$ with latency $L$ makes its result available at the start of cycle $t+L$.\n- **Tie-Breaking Rule**:\n  - Among ready instructions, issue in increasing instruction index order.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in computer architecture, specifically on instruction scheduling in an out-of-order superscalar processor.\n- **Scientifically Grounded**: The problem is based on established principles of computer organization and architecture, including dataflow graphs, critical path analysis, and modeling of OOO execution with resource constraints. All concepts are standard and well-defined.\n- **Well-Posed**: The problem is clearly stated with all necessary parameters (latencies, dependencies, machine model). The deterministic tie-breaking rule ensures a unique solution exists for the scheduling simulation.\n- **Objective**: The language is precise and technical, free of subjectivity or ambiguity.\n\nThe problem is self-contained and internally consistent. It does not violate any scientific principles, is not ill-posed, and is not trivial.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n**Part 1: Critical Path Analysis**\nFirst, we compute the earliest start time, $\\operatorname{EST}(I_i)$, and earliest completion time, $\\operatorname{ECT}(I_i)$, for each instruction, considering only data dependencies. We assume unlimited resources. The $\\operatorname{EST}$ for an instruction is the maximum of the $\\operatorname{ECT}$s of all instructions it depends on. An instruction with no dependencies can start at cycle $0$. The completion time is $\\operatorname{ECT}(I_i) = \\operatorname{EST}(I_i) + L_i$.\n\n- $\\operatorname{EST}(I_1) = 0$. $\\operatorname{ECT}(I_1) = 0 + L_1 = 0 + 3 = 3$.\n- $\\operatorname{EST}(I_2) = 0$. $\\operatorname{ECT}(I_2) = 0 + L_2 = 0 + 3 = 3$.\n- $\\operatorname{EST}(I_3) = \\max(\\operatorname{ECT}(I_1), \\operatorname{ECT}(I_2)) = \\max(3, 3) = 3$. $\\operatorname{ECT}(I_3) = 3 + L_3 = 3 + 3 = 6$.\n- $\\operatorname{EST}(I_5) = \\operatorname{ECT}(I_2) = 3$. $\\operatorname{ECT}(I_5) = 3 + L_5 = 3 + 1 = 4$.\n- $\\operatorname{EST}(I_4) = \\operatorname{ECT}(I_3) = 6$. $\\operatorname{ECT}(I_4) = 6 + L_4 = 6 + 1 = 7$.\n- $\\operatorname{EST}(I_6) = \\max(\\operatorname{ECT}(I_4), \\operatorname{ECT}(I_5)) = \\max(7, 4) = 7$. $\\operatorname{ECT}(I_6) = 7 + L_6 = 7 + 3 = 10$.\n- $\\operatorname{EST}(I_7) = \\operatorname{ECT}(I_6) = 10$. $\\operatorname{ECT}(I_7) = 10 + L_7 = 10 + 1 = 11$.\n- $\\operatorname{EST}(I_8) = \\operatorname{ECT}(I_7) = 11$.\n\nThe critical-path completion time for the final instruction $I_8$ is $T_{\\mathrm{CP}} = \\operatorname{ECT}(I_8) = \\operatorname{EST}(I_8) + L_8 = 11 + 1 = 12$.\n\n**Part 2: OOO Execution Simulation**\nNext, we simulate the execution on the specified OOO core, considering issue width $W=2$ and functional unit constraints. We track the start time `S(i)` and completion time `C(i)` for each instruction $I_i$.\n\n- **Cycle 0**:\n  - Instructions ready with all operands: $I_1, I_2$.\n  - Scheduler considers $I_1$, then $I_2$.\n  - $I_1$ requires the load unit, which is available. Issue $I_1$. $S(I_1)=0$, $C(I_1)=0+3=3$.\n  - $I_2$ requires the load unit. However, the single load unit can only start one instruction per cycle. $I_2$ cannot be issued.\n  - Issued: {$I_1$}.\n\n- **Cycle 1**:\n  - Instruction $I_2$ is still ready.\n  - The load unit is available to start a new operation. Issue $I_2$. $S(I_2)=1$, $C(I_2)=1+3=4$.\n  - Issued: {$I_2$}.\n\n- **Cycles 2-3**:\n  - No instructions are ready. At the start of cycle $3$, $I_1$ completes.\n\n- **Cycle 4**:\n  - At the start of this cycle, $I_2$ completes. Result available from $I_1$ (since cycle $3$) and $I_2$ (now).\n  - $I_3$ becomes ready: its inputs from $I_1$ and $I_2$ are available. Ready time is $\\max(C(I_1), C(I_2)) = \\max(3, 4) = 4$.\n  - $I_5$ becomes ready: its input from $I_2$ is available. Ready time is $C(I_2) = 4$.\n  - Ready queue: {$I_3, I_5$}.\n  - Scheduler considers $I_3$ (needs multiply unit, available) and $I_5$ (needs ALU, available). Both can be issued since $W=2$.\n  - Issue $I_3$: $S(I_3)=4$, $C(I_3)=4+3=7$.\n  - Issue $I_5$: $S(I_5)=4$, $C(I_5)=4+1=5$.\n  - Issued: {$I_3, I_5$}.\n\n- **Cycles 5-6**:\n  - At the start of cycle $5$, $I_5$ completes. No new instructions become ready ($I_6$ is waiting for $I_4$).\n  - No instructions are issued.\n\n- **Cycle 7**:\n  - At the start of this cycle, $I_3$ completes.\n  - $I_4$ becomes ready: its input from $I_3$ is available. Ready time is $C(I_3)=7$.\n  - Issue $I_4$ (needs ALU, available). $S(I_4)=7$, $C(I_4)=7+1=8$.\n  - Issued: {$I_4$}.\n\n- **Cycle 8**:\n  - At the start of this cycle, $I_4$ completes.\n  - $I_6$ becomes ready: its inputs from $I_4$ and $I_5$ are available. Ready time is $\\max(C(I_4), C(I_5)) = \\max(8, 5) = 8$.\n  - Issue $I_6$ (needs multiply unit, available). $S(I_6)=8$, $C(I_6)=8+3=11$.\n  - Issued: {$I_6$}.\n\n- **Cycles 9-10**:\n  - No instructions are issued.\n\n- **Cycle 11**:\n  - At the start of this cycle, $I_6$ completes.\n  - $I_7$ becomes ready: input from $I_6$ is available. Ready time is $C(I_6)=11$.\n  - Issue $I_7$ (needs ALU, available). $S(I_7)=11$, $C(I_7)=11+1=12$.\n  - Issued: {$I_7$}.\n\n- **Cycle 12**:\n  - At the start of this cycle, $I_7$ completes.\n  - $I_8$ becomes ready: input from $I_7$ is available. Ready time is $C(I_7)=12$.\n  - Issue $I_8$ (needs store unit, available). $S(I_8)=12$, $C(I_8)=12+1=13$.\n  - Issued: {$I_8$}.\n\nThe simulation finishes when $I_8$ completes. The actual scheduled completion time is $T_{\\mathrm{OOO}} = C(I_8) = 13$.\n\n**Part 3: Calculation of $\\Delta$**\nThe problem asks for the value of $\\Delta = T_{\\mathrm{OOO}} - T_{\\mathrm{CP}}$.\nUsing the values calculated in the previous parts:\n$T_{\\mathrm{CP}} = 12$\n$T_{\\mathrm{OOO}} = 13$\n$\\Delta = 13 - 12 = 1$.\n\nThe delay is caused by the structural hazard at cycle $0$, where both $I_1$ and $I_2$ compete for the single load unit. This forces $I_2$ to be delayed by one cycle, and this one-cycle delay propagates along the critical path to the final instruction.", "answer": "$$\n\\boxed{1}\n$$", "id": "3662826"}, {"introduction": "Out-of-order execution heavily relies on register renaming to break false data dependencies, which requires a pool of physical registers larger than the architectural register file. This exercise challenges you to think like a CPU designer and determine the minimum number of physical registers needed to prevent performance bottlenecks [@problem_id:3662897]. By analyzing the lifetime of a physical register from allocation to commitment, you will derive a formula that directly links machine performance to this critical hardware resource.", "problem": "Consider a single-threaded loop running on a register-renamed out-of-order core with in-order commit and precise exceptions. The processor implements classic register renaming with a rename map table and a free list of physical registers. On renaming a destination, a new physical register is allocated immediately, and the previously mapped physical register for that architectural name is returned to the free list only when the redefining instruction commits. The commit stage updates the architectural map in order and frees the previous physical mapping upon commit of the redefining instruction, not earlier.\n\nAssume the following steady-state properties of the loop and machine:\n- The loop body has exactly $k$ distinct scalar temporaries, each represented by a unique architectural register and redefined exactly once per iteration.\n- The loop runs at a sustained initiation interval of $1$ iteration per $1$ cycle in steady state (that is, a new iteration begins renaming every $1$ cycle).\n- For each temporary, the time from its rename (new destination allocation) in a given iteration to the in-order commit of the instruction that redefines it in that iteration is a constant $D$ cycles. You may treat $D$ as an integer and the same for all $k$ temporaries.\n- There are no other architectural registers redefined by the loop besides these $k$ temporaries, and you may ignore all other forms of resource contention (for example, assume the reorder buffer and schedulers are sufficiently large so that only the physical register free list can cause a renaming stall).\n\nUsing only the definitions of register renaming, liveness, and in-order commit provided above, derive from first principles the minimal number of physical registers $R_{phys}$ required to guarantee that the rename stage never stalls due to an empty free list while the loop runs in steady state. Express your answer as a closed-form expression in terms of $k$ and $D$. Do not provide an inequality. No numerical rounding is required, and no units are needed in the final expression.", "solution": "The problem requires the derivation of the minimal number of physical registers, $R_{phys}$, to guarantee that a processor's rename stage does not stall. The system is characterized by a loop running in a steady state on an out-of-order core.\n\nThe fundamental principle for solving this problem is to determine the total number of physical registers that are simultaneously in use (allocated and not yet freed) during this steady state. To prevent stalls, the physical register file must be large enough to accommodate all of them. This number can be found by calculating the total lifetime of a physical register and multiplying it by the rate at which registers are allocated.\n\nLet's first establish the rate of allocation. The problem states:\n- The loop body has $k$ distinct scalar temporaries, each redefined once per iteration.\n- The loop runs at a sustained initiation interval of $1$ iteration per $1$ cycle.\nThis means that every cycle, one new iteration begins, and the rename stage must allocate a new physical register for each of the $k$ redefined architectural registers.\nThus, the rate of allocation is $k$ physical registers per cycle.\n\nNext, let's determine the lifetime of a physical register. The lifetime spans from its allocation at the rename stage to its deallocation, when it is returned to the free list. The problem specifies the deallocation rule: \"the previously mapped physical register for that architectural name is returned to the free list only when the redefining instruction commits.\"\n\nConsider a single architectural register, $A$. Let's track the physical registers mapped to it across consecutive iterations.\n- In iteration $i$, let the instruction that redefines $A$ be renamed at cycle $t_i$. At this time, a new physical register, let's call it $P_i$, is allocated for $A$.\n- In the next iteration, $i+1$, the instruction that redefines $A$ is renamed. Since the initiation interval is $1$, this occurs at cycle $t_{i+1} = t_i + 1$. A new physical register, $P_{i+1}$, is allocated for $A$.\n\nNow, let's determine when $P_i$ is freed. According to the rule, $P_i$ (the \"previously mapped physical register\") is freed when the \"redefining instruction\" (the one from iteration $i+1$) commits.\nThe problem states that the time from an instruction's rename to its commit is a constant $D$ cycles. The instruction from iteration $i+1$ was renamed at cycle $t_{i+1}$. Therefore, it commits at cycle $t_{commit} = t_{i+1} + D$.\nSubstituting $t_{i+1} = t_i + 1$:\n$$t_{commit} = (t_i + 1) + D = t_i + D + 1$$\nThis is the cycle at which the physical register $P_i$ is freed.\n\nThe lifetime of the physical register $P_i$ is the duration from its allocation at cycle $t_i$ until it is freed at cycle $t_i + D + 1$. The number of cycles it remains occupied is:\n$$\\text{Lifetime} = (t_i + D + 1) - t_i = D + 1 \\text{ cycles}$$\n\nWe have now established the two necessary components for our calculation:\n$1$. The rate at which physical registers are consumed from the free list is $k$ registers per cycle.\n$2$. The duration for which each a physical register remains consumed is $D+1$ cycles.\n\nIn a steady-state system, the total number of occupied resources is the product of the arrival rate and the service time. This is an application of Little's Law. The total number of simultaneously live physical registers, $N_{live}$, is:\n$$N_{live} = (\\text{registers allocated per cycle}) \\times (\\text{lifetime in cycles})$$\n$$N_{live} = k \\times (D+1)$$\n\nTo guarantee that the rename stage never stalls due to an empty free list, the total number of available physical registers, $R_{phys}$, must be at least this number. The minimal number required is therefore:\n$$R_{phys} = k(D+1)$$\n\nAn alternative derivation confirms this result by considering a snapshot of the machine's state. At any instant, the physical register file must hold the values for the last committed (architectural) state, plus all in-flight (speculative) states.\n- The committed state for the $k$ loop temporaries requires $k$ physical registers.\n- An instruction is in-flight from its rename until its commit. The time from rename to commit is $D$ cycles. With an initiation interval of $1$, there are always $D$ iterations' worth of instructions that have been renamed but have not yet committed. For example, if an instruction renamed at cycle $t$ commits at $t+D$, then at cycle $T$, the instructions renamed at cycles $T-1, T-2, \\ldots, T-D$ are all in-flight.\n- These $D$ in-flight iterations each allocated $k$ physical registers, accounting for $D \\times k$ speculative registers.\nThe total number of occupied registers is the sum of those for the committed state and the speculative states:\n$$R_{phys} = k_{\\text{committed}} + (D \\times k)_{\\text{speculative}} = k + kD = k(D+1)$$\nBoth derivations conclude that the minimal number of physical registers required is $k(D+1)$.", "answer": "$$\\boxed{k(D+1)}$$", "id": "3662897"}, {"introduction": "Maximizing raw performance is no longer the sole goal of processor design; modern CPUs must operate within a strict power budget. This problem explores the concept of energy-aware scheduling, where the processor must intelligently choose which instructions to execute to maximize its Instructions Per Cycle ($IPC$) without exceeding a given power cap [@problem_id:3662901]. You will apply a greedy optimization strategy, prioritizing instructions that offer the most performance \"bang for the buck\" to find the optimal instruction mix, illustrating a fundamental trade-off in contemporary computer architecture.", "problem": "A single-core superscalar out-of-order (OOO) processor executes a steady stream of independent instructions drawn from three classes: integer arithmetic ($\\mathrm{I}$), floating-point arithmetic ($\\mathrm{F}$), and memory ($\\mathrm{M}$). The instruction window is sufficiently large that the processor can always find ready instructions up to per-class readiness limits, and loads hit in the first-level cache so that latency is overlapped by out-of-order execution. Let the peak issue width be $W$, and let the steady-state time-averaged issue rates for the three classes be $r_{\\mathrm{I}}$, $r_{\\mathrm{F}}$, and $r_{\\mathrm{M}}$, measured in instructions per cycle. Assume that these rates can be treated as real-valued variables in steady state.\n\nThe total instructions per cycle (IPC) is defined as $IPC = r_{\\mathrm{I}} + r_{\\mathrm{F}} + r_{\\mathrm{M}}$. The total power is modeled as $P = P_{\\mathrm{static}} + p_{\\mathrm{I}} r_{\\mathrm{I}} + p_{\\mathrm{F}} r_{\\mathrm{F}} + p_{\\mathrm{M}} r_{\\mathrm{M}}$, where $P_{\\mathrm{static}}$ is the static power and $p_{\\mathrm{I}}$, $p_{\\mathrm{F}}$, $p_{\\mathrm{M}}$ are the dynamic power costs per issued instruction for each class. The scheduler is energy-aware and, in each time interval, greedily prioritizes issuing instructions from the class with the largest marginal instructions-per-cycle gained per unit dynamic power consumed, subject to the following constraints:\n- Issue width: $r_{\\mathrm{I}} + r_{\\mathrm{F}} + r_{\\mathrm{M}} \\le W$.\n- Per-class readiness limits: $r_{\\mathrm{I}} \\le R_{\\mathrm{I}}^{\\max}$, $r_{\\mathrm{F}} \\le R_{\\mathrm{F}}^{\\max}$, $r_{\\mathrm{M}} \\le R_{\\mathrm{M}}^{\\max}$.\n- Power cap: $P \\le P_{\\mathrm{cap}}$.\n\nConsider the following parameter values:\n- Peak issue width $W = 10$.\n- Static power $P_{\\mathrm{static}} = 18$ (Watts).\n- Power cap $P_{\\mathrm{cap}} = 30$ (Watts).\n- Dynamic power per issued instruction: $p_{\\mathrm{I}} = 2$ (Watts/instruction-per-cycle), $p_{\\mathrm{F}} = 3$ (Watts/instruction-per-cycle), $p_{\\mathrm{M}} = 6$ (Watts/instruction-per-cycle).\n- Per-class maximum steady-state readiness: $R_{\\mathrm{I}}^{\\max} = 4$, $R_{\\mathrm{F}}^{\\max} = 6$, $R_{\\mathrm{M}}^{\\max} = 6$.\n\nUnder these assumptions and the described energy-aware greedy scheduling, what steady-state $IPC$ does the processor achieve at the power cap? Express your answer as a single number; do not round if the value can be written exactly as a simplified fraction.", "solution": "We start from core definitions. Instructions per cycle is defined as $IPC = r_{\\mathrm{I}} + r_{\\mathrm{F}} + r_{\\mathrm{M}}$, the average number of committed instructions per cycle. In a steady-state superscalar out-of-order processor with sufficient instruction window and independence, the committed rate equals the issued rate under the given constraints, so we can express $IPC$ in terms of the time-averaged issue rates $r_{\\mathrm{I}}$, $r_{\\mathrm{F}}$, and $r_{\\mathrm{M}}$.\n\nPower is modeled by a standard linear decomposition into static and dynamic components, $P = P_{\\mathrm{static}} + P_{\\mathrm{dyn}}$, with the dynamic part modeled as a linear function of activity (issued operations): \n$$\nP = P_{\\mathrm{static}} + p_{\\mathrm{I}} r_{\\mathrm{I}} + p_{\\mathrm{F}} r_{\\mathrm{F}} + p_{\\mathrm{M}} r_{\\mathrm{M}}.\n$$\nThis is a widely used first-order model in computer architecture for dynamic power under fixed frequency and voltage when activity factors are proportional to the number of issued operations.\n\nThe scheduler is specified to be energy-aware and greedy with respect to marginal performance per unit dynamic power. The marginal $IPC$ gain per unit dynamic power for class $\\mathrm{X} \\in \\{\\mathrm{I}, \\mathrm{F}, \\mathrm{M}\\}$ is the ratio of the incremental change in $IPC$ to the incremental change in dynamic power when increasing $r_{\\mathrm{X}}$:\n$$\n\\frac{\\partial(IPC)}{\\partial r_{\\mathrm{X}}} \\Big/ \\frac{\\partial P_{\\mathrm{dyn}}}{\\partial r_{\\mathrm{X}}} = \\frac{1}{p_{\\mathrm{X}}}.\n$$\nSince $\\frac{\\partial(IPC)}{\\partial r_{\\mathrm{X}}} = 1$ for each class and $\\frac{\\partial P_{\\mathrm{dyn}}}{\\partial r_{\\mathrm{X}}} = p_{\\mathrm{X}}$, the scheduler’s greedy policy is to allocate issue rate first to the class with the smallest $p_{\\mathrm{X}}$ (largest $\\frac{1}{p_{\\mathrm{X}}}$), then to the next, and so on, while obeying the constraints on issue width, per-class readiness, and power cap. Because the benefit per unit dynamic power is constant for each class and the decision variables can be treated as continuous (time-averaged rates), this greedy allocation is equivalent to the continuous knapsack solution and is optimal under the stated assumptions.\n\nWe now apply the constraints and given parameters.\n\nFirst, compute the available dynamic power budget under the cap:\n$$\nP_{\\mathrm{dyn}}^{\\max} = P_{\\mathrm{cap}} - P_{\\mathrm{static}} = 30 - 18 = 12.\n$$\n\nOrder classes by increasing $p_{\\mathrm{X}}$ (decreasing $\\frac{1}{p_{\\mathrm{X}}}$):\n- Integer: $p_{\\mathrm{I}} = 2$.\n- Floating-point: $p_{\\mathrm{F}} = 3$.\n- Memory: $p_{\\mathrm{M}} = 6$.\n\nConstraint set:\n- Issue width: $r_{\\mathrm{I}} + r_{\\mathrm{F}} + r_{\\mathrm{M}} \\le 10$.\n- Readiness: $r_{\\mathrm{I}} \\le 4$, $r_{\\mathrm്രF}} \\le 6$, $r_{\\mathrm{M}} \\le 6$.\n- Dynamic power: $2 r_{\\mathrm{I}} + 3 r_{\\mathrm{F}} + 6 r_{\\mathrm{M}} \\le 12$.\n\nGreedy allocation step $1$ (integer class $\\mathrm{I}$):\nAllocate as much as possible to $\\mathrm{I}$, limited by readiness, width, and power. The limiting factors are\n$$\nr_{\\mathrm{I}} \\le R_{\\mathrm{I}}^{\\max} = 4,\\quad r_{\\mathrm{I}} \\le W = 10,\\quad 2 r_{\\mathrm{I}} \\le 12 \\Rightarrow r_{\\mathrm{I}} \\le 6.\n$$\nHence the tightest of these bounds is $r_{\\mathrm{I}} \\le 4$. Allocate $r_{\\mathrm{I}} = 4$. This consumes dynamic power\n$$\nP_{\\mathrm{dyn,I}} = 2 \\cdot 4 = 8,\n$$\nleaving dynamic budget\n$$\nP_{\\mathrm{dyn}}^{\\mathrm{rem}} = 12 - 8 = 4,\n$$\nand issue width remaining\n$$\nW^{\\mathrm{rem}} = 10 - 4 = 6.\n$$\n\nGreedy allocation step $2$ (floating-point class $\\mathrm{F}$):\nAllocate to $\\mathrm{F}$ subject to readiness, remaining width, and remaining dynamic power:\n$$\nr_{\\mathrm{F}} \\le R_{\\mathrm{F}}^{\\max} = 6,\\quad r_{\\mathrm{F}} \\le W^{\\mathrm{rem}} = 6,\\quad 3 r_{\\mathrm{F}} \\le P_{\\mathrm{dyn}}^{\\mathrm{rem}} = 4 \\Rightarrow r_{\\mathrm{F}} \\le \\frac{4}{3}.\n$$\nHence the tightest bound is $r_{\\mathrm{F}} \\le \\frac{4}{3}$. Allocate $r_{\\mathrm{F}} = \\frac{4}{3}$. This uses the remaining dynamic power\n$$\nP_{\\mathrm{dyn,F}} = 3 \\cdot \\frac{4}{3} = 4,\n$$\nso the dynamic budget is fully utilized:\n$$\nP_{\\mathrm{dyn}}^{\\mathrm{rem}} = 4 - 4 = 0.\n$$\n\nGreedy allocation step $3$ (memory class $\\mathrm{M}$):\nNo dynamic power remains, so $r_{\\mathrm{M}} = 0$.\n\nVerify all constraints:\n- Issue width: $r_{\\mathrm{I}} + r_{\\mathrm{F}} + r_{\\mathrm{M}} = 4 + \\frac{4}{3} + 0 = \\frac{16}{3} \\le 10$ is satisfied.\n- Readiness: $r_{\\mathrmI}} = 4 \\le 4$, $r_{\\mathrm{F}} = \\frac{4}{3} \\le 6$, $r_{\\mathrm{M}} = 0 \\le 6$ are satisfied.\n- Power: \n$$\nP = P_{\\mathrm{static}} + 2 r_{\\mathrm{I}} + 3 r_{\\mathrm{F}} + 6 r_{\\mathrm{M}} = 18 + 2 \\cdot 4 + 3 \\cdot \\frac{4}{3} + 6 \\cdot 0 = 18 + 8 + 4 + 0 = 30,\n$$\nso $P = P_{\\mathrm{cap}}$ is satisfied.\n\nTherefore, the steady-state $IPC$ under the specified energy-aware greedy scheduling at the power cap is\n$$\nIPC = r_{\\mathrm{I}} + r_{\\mathrm{F}} + r_{\\mathrm{M}} = 4 + \\frac{4}{3} + 0 = \\frac{16}{3}.\n$$", "answer": "$$\\boxed{\\frac{16}{3}}$$", "id": "3662901"}]}