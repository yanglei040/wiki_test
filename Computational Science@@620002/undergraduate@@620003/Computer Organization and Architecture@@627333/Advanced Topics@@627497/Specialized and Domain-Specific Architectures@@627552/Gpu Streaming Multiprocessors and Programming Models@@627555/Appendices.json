{"hands_on_practices": [{"introduction": "Efficiently transferring data from global memory is paramount for GPU performance. This exercise explores memory coalescing, the process by which a GPU groups individual thread memory requests into larger transactions. By analyzing how access stride affects the number of memory transactions, you will gain a quantitative understanding of bandwidth utilization, a critical first step in optimizing any data-intensive kernel. [@problem_id:3644542]", "problem": "A Graphics Processing Unit (GPU) Streaming Multiprocessor (SM) executes threads in groups of $W$ threads called warps; on contemporary architectures, $W = 32$ for NVIDIA warps. Consider a Single Instruction, Multiple Threads (SIMT) kernel in which each thread performs one $b$-byte global memory load from a linear array. Global memory services loads in aligned segments of size $S$ bytes; a warp’s load request is serviced by one transaction per distinct $S$-byte segment touched by any of the $W$ threads in the warp. Assume the following widely used and experimentally validated architectural facts as the starting point:\n- Global memory transactions for $4$-byte word loads are issued per distinct aligned $S = 128$ byte segment touched by the warp.\n- The base address of the first thread in each warp, denoted $A_0$, is aligned to $S$ bytes.\n- Each thread $t \\in \\{0,1,\\dots,W-1\\}$ in a warp reads the element at index $i_0 + t s$ where $s \\in \\mathbb{N}$ is the stride in elements and $b = 4$ bytes per element, so its address is $A_0 + b s t$.\n\nLet the kernel read $N$ elements in total, where $N$ is a multiple of $W$ so that a whole number of warps is launched. Define the global memory bandwidth utilization of the kernel as the ratio of useful payload bytes actually requested by the threads to the total bytes transferred by the memory system to service those requests, under the above transaction model. Starting from the fundamental definitions above, derive a closed-form expression for:\n1. The number of global memory transactions per warp, as a function of the stride $s$.\n2. The fraction of peak global memory bandwidth achieved by this kernel relative to a perfectly coalesced access pattern (which would yield one transaction per warp).\n\nUse $W = 32$, $b = 4$, and $S = 128$ explicitly in your final expressions. Express your final answer as closed-form analytic expressions in terms of $s$. No rounding is required, and no units should be included in your final expressions.", "solution": "The user wants me to solve a problem about GPU memory access patterns.\n\n### Step 1: Extract Givens\n-   Number of threads per warp, $W = 32$.\n-   Bytes per element, $b = 4$.\n-   Size of an aligned memory segment, $S = 128$ bytes.\n-   A warp's load request is serviced by one transaction per distinct $S$-byte segment touched.\n-   Base address of the first thread in a warp, $A_0$, is aligned to $S$ bytes.\n-   Address accessed by thread $t \\in \\{0, 1, \\dots, W-1\\}$ is $A_t = A_0 + bst$, where $s \\in \\mathbb{N}$ is the stride.\n-   Total elements read, $N$, is a multiple of $W$.\n-   Definition of global memory bandwidth utilization: ratio of useful payload bytes to total bytes transferred.\n-   A perfectly coalesced access pattern results in one transaction per warp.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem describes a simplified but standard and well-established model of GPU global memory coalescing. The parameters ($W=32$, $b=4$, $S=128$) are characteristic of real-world NVIDIA GPU architectures. The concepts of warps, strided access, and memory segments are fundamental to GPU programming and computer architecture. The problem is scientifically sound.\n-   **Well-Posed**: The problem is fully specified. It provides all necessary parameters, definitions, and constraints to mathematically derive the requested quantities. The objectives are clear and a unique solution exists.\n-   **Objective**: The problem is stated in precise, formal, and objective language, free from any subjective or ambiguous terms.\n-   **Completeness and Consistency**: The problem is self-contained. The provided information, such as the alignment of the base address $A_0$, is crucial and sufficient. There are no contradictions in the setup.\n-   **Other Flaws**: The problem is not unrealistic, ill-posed, trivial, or unverifiable. It is a standard and illustrative problem in the field of parallel computer architecture.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the derivation of the solution.\n\n### Derivation\n\nThe solution requires deriving two quantities: the number of memory transactions per warp as a function of stride $s$, and the resulting fraction of peak memory bandwidth.\n\n#### 1. Number of Global Memory Transactions per Warp\n\nLet $T(s)$ be the number of global memory transactions per warp for a given stride $s$. According to the problem statement, a transaction is issued for each distinct $S$-byte memory segment touched by any of the $W$ threads in the warp.\n\nThe memory address accessed by thread $t$ is given by:\n$$A_t = A_0 + bst, \\quad \\text{for } t \\in \\{0, 1, \\dots, W-1\\}$$\nwhere $A_0$ is the base address, $b$ is the size of each element in bytes, $s$ is the access stride in elements, and $t$ is the thread index within the warp.\n\nA memory segment is an $S$-byte aligned block of memory. The index of the segment containing an address $A$ is given by $\\lfloor A/S \\rfloor$. A new transaction is required for each unique segment index accessed by the warp.\n\nThe segment index for thread $t$, let's call it $k_t$, is:\n$$k_t = \\left\\lfloor \\frac{A_t}{S} \\right\\rfloor = \\left\\lfloor \\frac{A_0 + bst}{S} \\right\\rfloor$$\n\nThe problem states that the base address $A_0$ is aligned to $S$ bytes. This means $A_0$ is an integer multiple of $S$, so $A_0 = mS$ for some integer $m$. This simplifies the expression for $k_t$:\n$$k_t = \\left\\lfloor \\frac{mS + bst}{S} \\right\\rfloor = \\left\\lfloor m + \\frac{bst}{S} \\right\\rfloor = m + \\left\\lfloor \\frac{bst}{S} \\right\\rfloor$$\n\nThe number of transactions $T(s)$ is the number of distinct values of $k_t$ for $t \\in \\{0, 1, \\dots, W-1\\}$. Since $m$ is a constant offset for all threads in the warp, counting the distinct values of $k_t$ is equivalent to counting the distinct values of $\\lfloor bst/S \\rfloor$.\n$$T(s) = \\left| \\left\\{ \\left\\lfloor \\frac{bst}{S} \\right\\rfloor \\mid t \\in \\{0, 1, \\dots, W-1\\} \\right\\} \\right|$$\n\nWe are given the specific values $W=32$, $b=4$, and $S=128$. Substituting these into the expression:\n$$T(s) = \\left| \\left\\{ \\left\\lfloor \\frac{4s t}{128} \\right\\rfloor \\mid t \\in \\{0, 1, \\dots, 31\\} \\right\\} \\right| = \\left| \\left\\{ \\left\\lfloor \\frac{st}{32} \\right\\rfloor \\mid t \\in \\{0, 1, \\dots, 31\\} \\right\\} \\right|$$\n\nTo find the size of this set, we analyze the behavior of the sequence $f(t) = \\lfloor st/32 \\rfloor$ for $t \\in \\{0, 1, \\dots, 31\\}$.\nThe values of $f(t)$ are non-negative integers. The minimum value is $f(0) = \\lfloor 0 \\rfloor = 0$. The maximum value is $f(31) = \\lfloor 31s/32 \\rfloor$.\n\nWe consider two cases based on the stride $s$.\n\nCase 1: $1 \\le s < 32$.\nIn this case, the increment in the argument of the floor function between consecutive threads is $s/32 < 1$.\nThe difference between consecutive values in the sequence is:\n$$f(t+1) - f(t) = \\left\\lfloor \\frac{s(t+1)}{32} \\right\\rfloor - \\left\\lfloor \\frac{st}{32} \\right\\rfloor$$\nLet $x = st/32$ and $\\delta = s/32$. The difference is $\\lfloor x+\\delta \\rfloor - \\lfloor x \\rfloor$. Since $0 < \\delta < 1$, this difference can only be $0$ or $1$. This means the sequence of segment indices $f(t)$ does not skip any integer values as $t$ increases. The set of values is the complete range of integers from the minimum to the maximum value.\nTherefore, the number of distinct values is:\n$$T(s) = f(31) - f(0) + 1 = \\left\\lfloor \\frac{31s}{32} \\right\\rfloor - 0 + 1 = \\left\\lfloor \\frac{31s}{32} \\right\\rfloor + 1$$\n\nCase 2: $s \\ge 32$.\nIn this case, the stride in bytes, $bs = 4s$, is greater than or equal to the segment size $S=128$. The increment in the argument of the floor function is $s/32 \\ge 1$.\nThe difference between the segment indices of consecutive threads is:\n$$f(t+1) - f(t) = \\left\\lfloor \\frac{s(t+1)}{32} \\right\\rfloor - \\left\\lfloor \\frac{st}{32} \\right\\rfloor \\ge \\left\\lfloor \\frac{s}{32} \\right\\rfloor \\ge 1$$\nThis shows that $\\lfloor s(t+1)/32 \\rfloor > \\lfloor st/32 \\rfloor$ for all $t$. The segment index is strictly increasing with the thread index $t$. Consequently, each of the $W=32$ threads accesses a unique memory segment.\nTherefore, the number of transactions is:\n$$T(s) = W = 32$$\n\nCombining these two cases, we can find a single closed-form expression.\nFor $1 \\le s < 32$, we found $T(s) = \\lfloor 31s/32 \\rfloor + 1$. Since $s<32$, $31s/32 < 31$, so $\\lfloor 31s/32 \\rfloor \\le 30$. This implies $T(s) \\le 31$.\nFor $s \\ge 32$, $T(s)=32$.\n\nLet's test the expression $\\min(32, \\lfloor 31s/32 \\rfloor + 1)$.\nIf $1 \\le s < 32$, $\\lfloor 31s/32 \\rfloor + 1 \\le 31$, so the minimum is $\\lfloor 31s/32 \\rfloor + 1$. This is correct.\nIf $s = 32$, $\\min(32, \\lfloor 31 \\cdot 32 / 32 \\rfloor + 1) = \\min(32, 31 + 1) = 32$. This is correct.\nIf $s > 32$, $s/32 > 1$. Then $31s/32 = 31 + 31(s-32)/32$.\n$\\lfloor 31s/32 \\rfloor + 1 = 31 + \\lfloor 31(s-32)/32 \\rfloor + 1 = 32 + \\lfloor 31(s-32)/32 \\rfloor$.\nSince $s > 32$, $s-32 \\ge 1$, so the floor term is non-negative. Thus, $\\lfloor 31s/32 \\rfloor + 1 \\ge 32$.\nIn this case, $\\min(32, \\lfloor 31s/32 \\rfloor + 1) = 32$. This is also correct.\n\nSo, the number of transactions per warp is given by:\n$$T(s) = \\min\\left(32, \\left\\lfloor \\frac{31s}{32} \\right\\rfloor + 1\\right)$$\n\n#### 2. Fraction of Peak Global Memory Bandwidth\n\nPeak global memory bandwidth is achieved when the number of transactions per warp is minimized. The minimal number of transactions is $1$, which occurs for a perfectly coalesced access pattern (e.g., for $s=1$, $T(1) = \\lfloor 31/32 \\rfloor + 1 = 1$).\n\nLet $BW(s)$ be the effective bandwidth for a given stride $s$. The bandwidth is the number of useful bytes transferred per unit time.\nUseful payload bytes per warp = $W \\times b = 32 \\times 4 = 128$ bytes.\nTotal bytes transferred per warp = $T(s) \\times S = T(s) \\times 128$ bytes.\nThe time taken to service the requests of a warp is proportional to the number of transactions, i.e., Time $\\propto T(s)$.\nSo, $BW(s) \\propto \\frac{\\text{Useful payload bytes}}{T(s)} = \\frac{Wb}{T(s)}$.\n\nThe peak bandwidth, $BW_{peak}$, corresponds to the minimum number of transactions, $T_{min}=1$.\n$BW_{peak} \\propto \\frac{Wb}{1}$.\n\nThe fraction of peak bandwidth achieved, $F(s)$, is the ratio $BW(s) / BW_{peak}$:\n$$F(s) = \\frac{Wb / T(s)}{Wb / 1} = \\frac{1}{T(s)}$$\n\nSubstituting the expression for $T(s)$:\n$$F(s) = \\frac{1}{\\min\\left(32, \\left\\lfloor \\frac{31s}{32} \\right\\rfloor + 1\\right)}$$\n\nThe final expressions for the two requested quantities are:\n1.  Number of transactions per warp: $\\min\\left(32, \\left\\lfloor \\frac{31s}{32} \\right\\rfloor + 1\\right)$\n2.  Fraction of peak bandwidth: $\\frac{1}{\\min\\left(32, \\left\\lfloor \\frac{31s}{32} \\right\\rfloor + 1\\right)}$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\min\\left(32, \\left\\lfloor \\frac{31s}{32} \\right\\rfloor + 1\\right) & \\frac{1}{\\min\\left(32, \\left\\lfloor \\frac{31s}{32} \\right\\rfloor + 1\\right)}\n\\end{pmatrix}\n}\n$$", "id": "3644542"}, {"introduction": "Once data is loaded onto the Streaming Multiprocessor (SM), its performance is governed by the speed of on-chip shared memory. This practice delves into shared memory bank conflicts, a common performance bottleneck where multiple threads access the same memory bank simultaneously. You will diagnose a bank conflict in a matrix multiplication kernel and implement a classic padding technique to resolve it, learning a fundamental optimization pattern. [@problem_id:3644606]", "problem": "Consider a Graphics Processing Unit (GPU) Streaming Multiprocessor (SM) with Single Instruction Multiple Threads (SIMT) execution. The SM provides programmer-managed shared memory organized into $32$ banks, each bank serving one $4$-byte word per cycle. Assume a warp contains $32$ threads, and that an access by threads in a warp to shared memory is serviced without serialization if, and only if, the requested words map to distinct banks. A $n$-way bank conflict serializes the access into $n$ steps. The bank index for a $4$-byte word at byte address $a$ is given by the well-tested hardware mapping rule $b = \\left\\lfloor \\frac{a}{4} \\right\\rfloor \\bmod 32$.\n\nA general matrix multiply (GEMM) kernel uses shared-memory tiling. Each tile is stored in row-major order as $M \\times K$ single-precision floating-point numbers, with leading dimension $K$ and element indices $(i,j)$ mapped to a linear word index $iK + j$, where $0 \\leq i < M$ and $0 \\leq j < K$. Suppose a warp cooperatively loads one column of the tile at a fixed column index $j$ using thread indices $i = 0,1,\\dots,31$ to cover $32$ rows. For this problem, take $K = 32$ and $M \\geq 32$.\n\nStarting from the definitions above:\n- Derive the condition under which this column-wise access exhibits a $32$-way bank conflict for the original $M \\times K$ layout.\n- Specify a remapped layout that avoids bank conflicts by padding the leading dimension to $K' = K + 1$, and express the corresponding bank index function for the column-wise access under the remapped layout. Briefly argue why this eliminates conflicts for a warp accessing a single column.\n\nAssume the following performance model: a conflict-free warp shared-memory access consumes $1$ cycle. A $n$-way bank conflict adds a penalty of $c$ cycles for each additional serialized step beyond one, so the total cycles for a warp access with an $n$-way conflict is $1 + (n-1)c$. Assume the kernel’s runtime over the relevant phase is dominated by these shared-memory accesses, and all other costs remain unchanged by the remapping.\n\nUnder these assumptions, express the overall speedup factor due to the remapping as a single closed-form analytic expression in terms of $c$. No rounding is required. Provide only the speedup factor as your final answer.", "solution": "The problem shall be validated before a solution is attempted.\n\n**Step 1: Extract Givens**\n- GPU SM with SIMT execution.\n- Shared memory: $32$ banks.\n- Bank service rate: one $4$-byte word per bank per cycle.\n- Warp size: $32$ threads.\n- Conflict-free access condition: requested words map to distinct banks.\n- $n$-way bank conflict: serializes an access into $n$ steps.\n- Bank index mapping rule for a $4$-byte word at byte address $a$: $b = \\left\\lfloor \\frac{a}{4} \\right\\rfloor \\bmod 32$.\n- Kernel context: GEMM using shared-memory tiling.\n- Tile data type: single-precision floating-point numbers ($4$ bytes per number).\n- Tile dimensions and layout: $M \\times K$, row-major order, leading dimension $K$.\n- Linear word index mapping for element $(i,j)$: $iK + j$, where $0 \\leq i < M$ and $0 \\leq j < K$.\n- Specific parameters: $K = 32$, $M \\geq 32$.\n- Access pattern: A warp of $32$ threads cooperatively loads one column at a fixed column index $j$. Thread index $t \\in \\{0, 1, \\dots, 31\\}$ corresponds to row index $i=t$.\n- Padded layout: New leading dimension $K' = K + 1$.\n- Performance model for a warp access:\n  - Conflict-free time ($n=1$): $1$ cycle.\n  - Time with $n$-way conflict: $1 + (n-1)c$ cycles, where $c$ is a penalty constant.\n- Assumption: Kernel runtime is dominated by these shared-memory accesses.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Groundedness**: The problem is well-grounded in the principles of computer architecture and parallel computing, specifically GPU programming models. The concepts of streaming multiprocessors, SIMT, shared memory, bank conflicts, and memory layout padding are standard and fundamental to GPU performance optimization. The model is a correct and common simplification of real hardware behavior.\n- **Well-Posedness**: The problem asks for specific derivations and a final analytical expression based on the given model. All variables and relationships are clearly defined, leading to a unique, stable, and meaningful solution.\n- **Objectivity**: The language is precise and technical, free of subjective or ambiguous terminology.\n- **Completeness and Consistency**: The problem provides all necessary parameters ($32$ banks, $32$ threads/warp, word size, layout rules, performance model) and they are mutually consistent. For instance, the number of threads in a warp matches the number of memory banks, a common feature in many GPU architectures that is central to the problem.\n\n**Step 3: Verdict and Action**\nThe problem is valid, scientifically sound, and well-posed. A solution will be provided.\n\n**Derivation of the Solution**\n\nThe solution proceeds in three parts as requested: analyzing the original memory layout, analyzing the remapped layout, and calculating the speedup.\n\n**Part 1: Analysis of the Original Layout and Bank Conflict Condition**\nA shared memory tile is stored as an $M \\times K$ array of single-precision ($4$-byte) floating-point numbers in row-major order. The leading dimension is $K$. The linear word index for the element at $(i,j)$ is $w_{i,j} = iK + j$. The byte address of this word is $a_{i,j} = 4(iK+j)$.\nThe bank index $b$ is given by the hardware rule:\n$$b = \\left\\lfloor \\frac{a}{4} \\right\\rfloor \\bmod 32 = (iK + j) \\bmod 32$$\nWe consider a warp of $32$ threads, indexed by $t \\in \\{0, 1, \\dots, 31\\}$, loading a single column at a fixed index $j_0$. Thread $t$ accesses the element at row $i=t$. Therefore, thread $t$ accesses the element $(t, j_0)$.\nThe bank index $b_t$ accessed by thread $t$ is:\n$$b_t = (tK + j_0) \\bmod 32$$\nThe problem specifies $K = 32$. Substituting this value, we find the bank index for thread $t$:\n$$b_t = (t \\cdot 32 + j_0) \\bmod 32$$\nUsing the properties of modular arithmetic, specifically $(A+B) \\bmod N = ((A \\bmod N) + (B \\bmod N)) \\bmod N$:\n$$b_t = \\left( (t \\cdot 32) \\bmod 32 + j_0 \\bmod 32 \\right) \\bmod 32$$\nSince $t$ is an integer, $t \\cdot 32$ is always a multiple of $32$, so $(t \\cdot 32) \\bmod 32 = 0$. This simplifies the expression for $b_t$:\n$$b_t = (0 + j_0 \\bmod 32) \\bmod 32 = j_0 \\bmod 32$$\nThis result demonstrates that the bank index accessed by any thread $t$ in the warp is independent of $t$ and is solely determined by the column index $j_0$. All $32$ threads attempt to access memory words that map to the same bank, $j_0 \\bmod 32$. This constitutes a $32$-way bank conflict. The general condition under which this column-wise access pattern causes a $32$-way bank conflict is that the leading dimension $K$ is a multiple of the number of banks, i.e., $K \\bmod 32 = 0$. Given $K=32$, this condition is satisfied.\n\n**Part 2: Analysis of the Remapped Layout**\nTo avoid this bank conflict, the leading dimension is padded. The new leading dimension is $K' = K + 1 = 32 + 1 = 33$. The element $(i,j)$ now maps to the linear word index $w'_{i,j} = iK' + j$.\nThe corresponding bank index function is:\n$$b'_{i,j} = (iK' + j) \\bmod 32$$\nFor the same column-wise access, thread $t$ accesses element $(t, j_0)$, and the bank index $b'_t$ is:\n$$b'_t = (tK' + j_0) \\bmod 32$$\nSubstituting $K' = 33$:\n$$b'_t = (t \\cdot 33 + j_0) \\bmod 32 = (t \\cdot (32 + 1) + j_0) \\bmod 32 = (32t + t + j_0) \\bmod 32$$\nApplying modular arithmetic properties again:\n$$b'_t = \\left( (32t) \\bmod 32 + (t+j_0) \\bmod 32 \\right) \\bmod 32 = (0 + (t+j_0) \\bmod 32) \\bmod 32$$\nThe bank index function for the column-wise access under the remapped layout is therefore:\n$$b'_t = (t + j_0) \\bmod 32$$\nThis remapping eliminates bank conflicts. To demonstrate this, we examine the set of bank indices accessed by the warp's threads for $t = 0, 1, \\dots, 31$. The set of bank indices is $\\{ (0+j_0)\\bmod 32, (1+j_0)\\bmod 32, \\dots, (31+j_0)\\bmod 32 \\}$. The set $\\{0, 1, \\dots, 31\\}$ is a complete residue system modulo $32$. Adding a constant integer $j_0$ to each element of this set and taking the result modulo $32$ yields a permutation of the original set. Thus, the set of accessed bank indices is $\\{0, 1, \\dots, 31\\}$, where each index appears exactly once. Since all $32$ threads access distinct banks, the access is conflict-free.\n\n**Part 3: Calculation of the Speedup Factor**\nThe speedup is the ratio of the execution time of the original (conflicted) access to the new (conflict-free) access.\nLet $T_{old}$ be the time for the original access and $T_{new}$ be the time for the remapped access.\nThe time for a warp access with an $n$-way conflict is $1 + (n-1)c$.\n\nFor the original layout, we established a $32$-way bank conflict, so $n=32$. The time taken is:\n$$T_{old} = 1 + (32-1)c = 1 + 31c$$\nFor the remapped layout, the access is conflict-free. This means the maximum number of threads accessing any single bank is $n=1$. The time taken is:\n$$T_{new} = 1 + (1-1)c = 1$$\nThis is consistent with the problem's statement that a conflict-free access takes $1$ cycle.\n\nThe overall speedup factor is the ratio $\\frac{T_{old}}{T_{new}}$. Since the problem states that kernel runtime is dominated by these accesses, this ratio represents the overall speedup.\n$$\\text{Speedup} = \\frac{T_{old}}{T_{new}} = \\frac{1 + 31c}{1} = 1 + 31c$$\nThis is the final closed-form analytic expression for the speedup factor in terms of $c$.", "answer": "$$\\boxed{1 + 31c}$$", "id": "3644606"}, {"introduction": "A high-performance kernel must balance the rate of computation with the rate of data access from memory. This exercise introduces a simplified roofline performance model to analyze a parallel reduction algorithm. By calculating the compute and memory-access times, you will determine the crossover point where the kernel becomes memory-bound, providing insight into the fundamental performance limitations of your code. [@problem_id:3644608]", "problem": "Consider a Graphics Processing Unit (GPU) Single Streaming Multiprocessor (SM) executing a sum reduction over $N$ $32$-bit floating-point elements. Two CUDA-style kernels are considered:\n- Kernel A uses shared memory to perform a tree reduction that requires synchronization at each halving step, resulting in a compute phase that scales as $\\mathcal{O}(\\log N)$ warp-level steps after per-thread accumulation.\n- Kernel B uses warp shuffle operations to reduce per-thread partial sums, avoiding shared memory and block-wide barriers. Each thread first accumulates its assigned elements via a grid-stride loop into a register, and then performs an intra-warp shuffle reduction followed by a single cross-warp reduction to produce the block’s result.\n\nAssume the following hardware and execution model for the single SM:\n- SM clock frequency is $f = 1.0 \\times 10^{9}$ $\\text{Hz}$ (that is, $1.0$ $\\text{GHz}$).\n- The sustained issue rate for this kernel is $I_{\\text{eff}} = 1$ warp instruction per cycle (that is, one warp-level instruction can be issued per cycle).\n- Warp size is $32$ threads, and the kernel launches a single thread block of size $T = 1024$ threads on the SM, executing to completion before any other blocks are scheduled on this SM.\n- Global memory bandwidth effectively available to this SM is $B = 12.0 \\times 10^{9}$ $\\text{bytes} \\cdot \\text{s}^{-1}$.\n- All global memory loads are fully coalesced, caches are cold, and each element is read exactly once. The output write is a single $4$-byte store and can be included for completeness.\n- Count warp-level instructions for Kernel B as follows:\n  1. Per-element accumulation: each element contributes one addition in its owning thread; at the warp level this corresponds to $\\frac{N}{32}$ warp add instructions executed across the warps.\n  2. Intra-warp reduction: each warp performs $5$ shuffle steps and $5$ additions (offsets $16, 8, 4, 2, 1$), for a total of $10$ warp instructions per warp. With $W = \\frac{T}{32}$ warps, this is $10 W$ warp instructions.\n  3. Cross-warp reduction: one warp reduces the $W$ warp sums using another $5$ shuffle steps and $5$ additions, for an additional $10$ warp instructions.\n\nUse first principles of throughput and the roofline-style reasoning that a kernel is bandwidth-bound when its total time is dominated by data movement rather than instruction issue. Model the total compute time for Kernel B as the total number of warp-level instructions divided by the sustained warp-instruction throughput $I_{\\text{eff}} f$, and the total memory time as the bytes transferred divided by $B$. Under these assumptions, determine the smallest value of $N$ (elements) at which Kernel B becomes bandwidth-bound on this single SM, by solving for $N$ where the compute time equals the memory time. Express $N$ as a pure number of elements and round your final answer to three significant figures.", "solution": "The user wants me to solve the problem as a \"meticulous and exacting professor in the STEM fields,\" which requires a rigorous validation of the problem statement before attempting a solution.\n\n### Step 1: Extract Givens\n- Problem type: GPU performance modeling for a sum reduction kernel.\n- Target kernel: Kernel B, using warp shuffle operations.\n- Input data: $N$ elements, each a $32$-bit float (i.e., $4$ bytes).\n- Hardware and execution model for a single Streaming Multiprocessor (SM):\n    - SM clock frequency: $f = 1.0 \\times 10^{9}$ $\\text{Hz}$.\n    - Sustained warp instruction issue rate: $I_{\\text{eff}} = 1$ warp instruction per cycle.\n    - Warp size: $32$ threads.\n    - Thread block size: $T = 1024$ threads.\n    - A single block of $T$ threads is launched.\n    - Global memory bandwidth for the SM: $B = 12.0 \\times 10^{9}$ $\\text{bytes} \\cdot \\text{s}^{-1}$.\n    - Memory access pattern: All $N$ elements are read once, coalesced, from global memory. Caches are cold.\n    - Output: A single $32$-bit ($4$-byte) result is written to global memory.\n- Instruction counting for Kernel B:\n    - Per-element accumulation: $\\frac{N}{32}$ warp-level add instructions.\n    - Intra-warp reduction: $10$ warp-level instructions per warp.\n    - Cross-warp reduction: $10$ warp-level instructions for the entire block.\n- Objective: Find the smallest value of $N$ for which Kernel B is bandwidth-bound, defined as the point where the compute time equals the memory time ($T_{\\text{compute}} = T_{\\text{memory}}$).\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is critically assessed.\n\n- **Scientific Grounding (Critical):** The problem is well-grounded in the principles of computer architecture and parallel computing. The concepts of GPUs, Streaming Multiprocessors (SMs), warps, warp shuffles, global memory bandwidth, and performance modeling (specifically, a simplified roofline analysis) are standard and fundamental to the field. The provided models for compute and memory time are first-order approximations commonly used for performance estimation.\n- **Well-Posed:** The problem is well-posed. It provides all necessary numerical values and explicit models for the quantities to be calculated ($T_{\\text{compute}}$ and $T_{\\text{memory}}$). The objective is clearly stated: solve the equation $T_{\\text{compute}} = T_{\\text{memory}}$ for the variable $N$. This structure leads to a unique solution.\n- **Objective (Critical):** The problem is stated in precise, objective, and technical language. There are no subjective claims or ambiguities. The instruction counting method is explicitly prescribed, removing any potential for misinterpretation.\n- **Other criteria:** The problem is self-contained, with no missing or contradictory information. The given values ($f$, $B$, etc.) are physically plausible for a GPU architecture. The problem requires a non-trivial application of the given models, making it a valid test of understanding.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is scientifically sound, well-posed, and objective. I will now proceed with the solution.\n\n### Solution Derivation\n\nThe problem requires finding the value of $N$ where the kernel's execution time transitions from being compute-bound to memory-bound. This transition point is defined as the condition where the compute time, $T_{\\text{compute}}$, equals the memory access time, $T_{\\text{memory}}$.\n\n$T_{\\text{compute}} = T_{\\text{memory}}$\n\nFirst, we formulate the expression for the total memory time, $T_{\\text{memory}}$. This is the total number of bytes transferred divided by the available memory bandwidth, $B$. The total data transferred consists of reading $N$ floating-point elements and writing one final floating-point result. Since each element is a $32$-bit float, its size is $4$ bytes.\n\nThe total bytes read are $4N$. The total bytes written are $4$.\n$$ \\text{Bytes}_{\\text{total}} = 4N + 4 = 4(N+1) $$\n\nThe available memory bandwidth is given as $B = 12.0 \\times 10^{9}$ $\\text{bytes} \\cdot \\text{s}^{-1}$.\nThus, the memory time is:\n$$ T_{\\text{memory}} = \\frac{\\text{Bytes}_{\\text{total}}}{B} = \\frac{4(N+1)}{12.0 \\times 10^{9}} \\text{ s} $$\n\nNext, we formulate the expression for the total compute time, $T_{\\text{compute}}$. This is the total number of warp-level instructions executed divided by the sustained warp instruction throughput.\n\nThe total number of warp-level instructions, $I_{\\text{total}}$, is the sum of three components as specified:\n1.  **Per-element accumulation:** Each of the $N$ elements requires one addition. Since a warp consists of $32$ threads, these additions across the entire block correspond to $\\frac{N}{32}$ warp-level addition instructions.\n2.  **Intra-warp reduction:** The kernel launches a single block of $T = 1024$ threads. With a warp size of $32$, the number of warps in the block is $W = \\frac{T}{32} = \\frac{1024}{32} = 32$ warps. Each warp performs an internal reduction costing $10$ warp instructions. The total for this phase is $10 \\times W = 10 \\times 32 = 320$ instructions.\n3.  **Cross-warp reduction:** One warp reduces the $W=32$ partial sums from all warps in the block. This reduction of $32$ values takes $\\log_2(32)=5$ shuffle steps and $5$ additions, for a total of $10$ warp instructions.\n\nSumming these components gives the total number of warp instructions:\n$$ I_{\\text{total}} = \\frac{N}{32} + 320 + 10 = \\frac{N}{32} + 330 $$\n\nThe sustained warp instruction throughput is the product of the issue rate, $I_{\\text{eff}}$, and the clock frequency, $f$.\n$$ \\text{Throughput} = I_{\\text{eff}} \\times f = 1 \\frac{\\text{warp-instr}}{\\text{cycle}} \\times 1.0 \\times 10^{9} \\frac{\\text{cycles}}{\\text{s}} = 1.0 \\times 10^{9} \\frac{\\text{warp-instr}}{\\text{s}} $$\n\nThe compute time is therefore:\n$$ T_{\\text{compute}} = \\frac{I_{\\text{total}}}{\\text{Throughput}} = \\frac{\\frac{N}{32} + 330}{1.0 \\times 10^{9}} \\text{ s} $$\n\nNow, we set $T_{\\text{compute}} = T_{\\text{memory}}$ and solve for $N$.\n$$ \\frac{\\frac{N}{32} + 330}{1.0 \\times 10^{9}} = \\frac{4(N+1)}{12.0 \\times 10^{9}} $$\n\nWe can cancel the $10^{9}$ factor from both denominators.\n$$ \\frac{N}{32} + 330 = \\frac{4(N+1)}{12.0} $$\n$$ \\frac{N}{32} + 330 = \\frac{N+1}{3.0} $$\n\nTo solve for $N$, we clear the denominators by multiplying both sides by a common multiple, such as $3.0 \\times 32 = 96$.\n$$ 96 \\left( \\frac{N}{32} \\right) + 96(330) = 96 \\left( \\frac{N+1}{3.0} \\right) $$\n$$ 3.0N + 31680 = 32(N+1) $$\n$$ 3N + 31680 = 32N + 32 $$\n\nRearranging the terms to isolate $N$:\n$$ 31680 - 32 = 32N - 3N $$\n$$ 31648 = 29N $$\n$$ N = \\frac{31648}{29} \\approx 1091.3103... $$\n\nThe problem asks for the answer to be rounded to three significant figures.\n$$ N \\approx 1090 $$\n\nThus, for a dataset of approximately $1090$ elements, the time spent on computation is equal to the time spent on data movement from global memory. For $N$ greater than this value, the kernel will be memory-bound.", "answer": "$$\\boxed{1090}$$", "id": "3644608"}]}