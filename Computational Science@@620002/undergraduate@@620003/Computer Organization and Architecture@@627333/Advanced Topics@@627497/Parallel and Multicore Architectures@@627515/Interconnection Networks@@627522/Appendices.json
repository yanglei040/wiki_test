{"hands_on_practices": [{"introduction": "The choice of network topology is a fundamental design decision that directly impacts system performance. A key metric for evaluating a topology is the average communication distance, or hop count, between nodes. This exercise [@problem_id:3652325] provides a first-principles approach to calculating this metric for three canonical topologies: the shared bus, the bidirectional ring, and the 2D mesh. By working through this analysis, you will develop a concrete, quantitative understanding of how network structure dictates communication cost and scalability.", "problem": "A multiprocessor system-on-chip employs three alternative interconnection topologies to carry coherence traffic for moving cache lines between sharers: a shared bus, a bidirectional ring, and a two-dimensional mesh Network-on-Chip (NoC). All topologies have the same number of cores, $N = 64$. In the mesh case, cores are laid out on a regular $8 \\times 8$ grid with routers at grid intersections, and cache line data follows dimension-order paths (Manhattan routing) between source and destination. In the ring case, routers are connected in a cycle and data always follows the shorter of the two directions around the ring. In the bus case, all cores attach to a single shared medium. Assume a directory-based cache coherence protocol (DCCP) and that transfers of cache lines from the current owner to a requesting sharer proceed along the shortest path in the topology, without indirections through a home node and without contention or queuing.\n\nDefine the hop count for a transfer as the number of distinct inter-router link segments traversed by the cache line data along the shortest path from source to destination. For the bus, treat the shared medium traversal as a single hop regardless of source and destination attachment points. Suppose two distinct sharers of a given cache line are selected uniformly at random among the $N$ cores, and the line migrates from one to the other. Using only core definitions of these topologies and first-principles counting arguments, compute the average hop count for this migration under each topology: mesh, ring, and bus. Report your three answers in the order mesh, ring, bus. Round each value to four significant figures. No physical units are required; report dimensionless hop counts.", "solution": "The problem asks for the average hop count for a cache line migration between two distinct, randomly chosen cores in a system with $N=64$ cores for three different interconnection topologies: an $8 \\times 8$ two-dimensional mesh, a $64$-node bidirectional ring, and a shared bus.\n\nThe average hop count, $\\bar{H}$, is defined as the sum of all shortest-path hop counts between distinct source-destination pairs, divided by the total number of such pairs. Since the two distinct cores are chosen uniformly at random, there are $N$ choices for the source core and $N-1$ choices for the destination core. The total number of ordered pairs of distinct cores is $N(N-1)$.\n\nThe general formula for the average hop count is:\n$$ \\bar{H} = \\frac{\\sum_{i=1}^{N} \\sum_{j=1, j \\neq i}^{N} H(i, j)}{N(N-1)} $$\nwhere $H(i, j)$ is the hop count from a source core $i$ to a destination core $j$.\n\nWe will now analyze each topology separately.\n\n### 1. Shared Bus Topology\nFor a shared bus, the problem statement specifies that a transfer between any two attachment points constitutes a single hop. Therefore, for any distinct source core $i$ and destination core $j$, the hop count is constant.\n$$ H_{bus}(i, j) = 1 \\quad \\forall i \\neq j $$\nThe sum of hop counts over all distinct pairs is:\n$$ \\sum_{i=1}^{N} \\sum_{j=1, j \\neq i}^{N} H_{bus}(i, j) = \\sum_{i=1}^{N} \\sum_{j=1, j \\neq i}^{N} 1 = N(N-1) $$\nThe average hop count is therefore:\n$$ \\bar{H}_{bus} = \\frac{N(N-1)}{N(N-1)} = 1 $$\nFor $N=64$, the average hop count for the bus is exactly $1$.\n\n### 2. Bidirectional Ring Topology\nIn a bidirectional ring with $N$ cores, we can label the cores from $0$ to $N-1$. The hop count between core $i$ and core $j$ is the length of the shorter path along the ring. The distance in one direction is $|i-j|$, and in the other direction is $N - |i-j|$. Thus, the hop count is:\n$$ H_{ring}(i, j) = \\min(|i-j|, N - |i-j|) $$\nDue to the symmetry of the ring topology, the sum of distances from any given core to all other cores is the same. We can, therefore, calculate this sum for a single source, say core $0$, and then multiply by $N$ to get the total sum over all source cores.\nThe sum of distances from core $0$ to all other cores $j \\in \\{1, 2, \\dots, N-1\\}$ is:\n$$ S_0 = \\sum_{j=1}^{N-1} H_{ring}(0, j) = \\sum_{j=1}^{N-1} \\min(j, N-j) $$\nGiven $N=64$, which is an even number, the maximum shortest-path distance is $N/2 = 32$. This distance is unique to the diametrically opposite node. For all other distances $d < N/2$, there are two nodes at that distance.\nThe sum can be written as:\n$$ S_0 = \\sum_{j=1}^{N/2 - 1} j + \\frac{N}{2} + \\sum_{j=N/2 + 1}^{N-1} (N-j) $$\nThe second summation can be re-indexed. Let $k = N-j$. When $j=N/2+1$, $k=N/2-1$. When $j=N-1$, $k=1$. So, $\\sum_{j=N/2 + 1}^{N-1} (N-j) = \\sum_{k=1}^{N/2-1} k$.\n$$ S_0 = 2 \\sum_{j=1}^{N/2 - 1} j + \\frac{N}{2} $$\nUsing the formula for the sum of the first $m$ integers, $\\sum_{j=1}^{m} j = \\frac{m(m+1)}{2}$:\n$$ S_0 = 2 \\left( \\frac{(\\frac{N}{2}-1)(\\frac{N}{2}-1+1)}{2} \\right) + \\frac{N}{2} = (\\frac{N}{2}-1)\\frac{N}{2} + \\frac{N}{2} = \\frac{N}{2}(\\frac{N}{2}-1+1) = \\left(\\frac{N}{2}\\right)^2 = \\frac{N^2}{4} $$\nThe total sum of hop counts for all distinct pairs is $N \\times S_0 = N \\cdot \\frac{N^2}{4} = \\frac{N^3}{4}$.\nThe average hop count is this total sum divided by the number of pairs, $N(N-1)$:\n$$ \\bar{H}_{ring} = \\frac{N^3/4}{N(N-1)} = \\frac{N^2}{4(N-1)} $$\nFor $N=64$:\n$$ \\bar{H}_{ring} = \\frac{64^2}{4(64-1)} = \\frac{4096}{4 \\times 63} = \\frac{1024}{63} \\approx 16.253968... $$\n\n### 3. 2D Mesh Topology\nThe system has $N=64$ cores arranged in a regular $K \\times K$ grid, where $K = \\sqrt{N} = \\sqrt{64} = 8$. A core's position can be identified by coordinates $(x, y)$, where $x, y \\in \\{0, 1, \\dots, K-1\\}$.\nThe problem specifies Manhattan routing, so the hop count between a source core at $(x_s, y_s)$ and a destination core at $(x_d, y_d)$ is:\n$$ H_{mesh}((x_s, y_s), (x_d, y_d)) = |x_s - x_d| + |y_s - y_d| $$\nThe average hop count is the expectation of this quantity over all distinct source-destination pairs. By the linearity of expectation, this is:\n$$ \\bar{H}_{mesh} = E[|x_s - x_d| + |y_s - y_d|] = E[|x_s - x_d|] + E[|y_s - y_d|] $$\nThe average displacement in the x-dimension, $E[|x_s - x_d|]$, is the total sum of x-displacements divided by the total number of distinct pairs, $N(N-1)$.\n$$ E[|x_s - x_d|] = \\frac{\\sum_{s \\neq d} |x_s - x_d|}{N(N-1)} $$\nThe sum is over all $N(N-1)$ pairs of distinct cores. We can compute the sum over all $N^2$ pairs (including self-pairs) and note that for self-pairs ($s=d$), the displacement $|x_s - x_s|$ is $0$. Thus, the sum over distinct pairs is the same as the sum over all pairs.\n$$ \\sum_{s \\neq d} |x_s - x_d| = \\sum_{s=1}^{N} \\sum_{d=1}^{N} |x_s - x_d| = \\sum_{y_s=0}^{K-1} \\sum_{x_s=0}^{K-1} \\sum_{y_d=0}^{K-1} \\sum_{x_d=0}^{K-1} |x_s - x_d| $$\nWe can rearrange a summation:\n$$ \\sum_{y_s=0}^{K-1} \\sum_{y_d=0}^{K-1} \\left( \\sum_{x_s=0}^{K-1} \\sum_{x_d=0}^{K-1} |x_s - x_d| \\right) $$\nThe outer two sums over $y_s$ and $y_d$ yield a factor of $K^2$. The inner double summation is the total 1D distance sum for a line of $K$ nodes. This sum, for all pairs including self-pairs, is $\\frac{K(K^2-1)}{3}$.\nThus, the total sum of x-displacements is $K^2 \\times \\frac{K(K^2-1)}{3} = \\frac{K^3(K^2-1)}{3}$.\nThe average x-displacement is:\n$$ E[|x_s - x_d|] = \\frac{K^3(K^2-1)/3}{N(N-1)} = \\frac{K^3(K^2-1)/3}{K^2(K^2-1)} = \\frac{K}{3} $$\nBy symmetry, the average y-displacement $E[|y_s - y_d|]$ is also $\\frac{K}{3}$.\nThe average total hop count for the mesh is:\n$$ \\bar{H}_{mesh} = \\frac{K}{3} + \\frac{K}{3} = \\frac{2K}{3} $$\nFor $K=8$:\n$$ \\bar{H}_{mesh} = \\frac{2 \\times 8}{3} = \\frac{16}{3} = 5.333333... $$\n\n### Summary of Results\nThe computed average hop counts are:\n- Mesh: $\\bar{H}_{mesh} = \\frac{16}{3} \\approx 5.3333...$\n- Ring: $\\bar{H}_{ring} = \\frac{1024}{63} \\approx 16.2539...$\n- Bus: $\\bar{H}_{bus} = 1$\n\nRounding each value to four significant figures, as requested:\n- Mesh: $5.333$\n- Ring: $16.25$\n- Bus: $1.000$\n\nThe problem requests the answers in the order: mesh, ring, bus.", "answer": "$$\n\\boxed{\\begin{pmatrix} 5.333 & 16.25 & 1.000 \\end{pmatrix}}\n$$", "id": "3652325"}, {"introduction": "As systems scale to hundreds or thousands of nodes, simple topologies like meshes and rings face limitations. Modern datacenters and high-performance computers often employ hierarchical networks like the folded-Clos topology to provide high, uniform bandwidth. This practice [@problem_id:3652394] challenges you to analyze the pathing characteristics of a folded-Clos network, determining the minimal path length and the number of available redundant paths. You will then apply this knowledge to a practical load-balancing technique, Equal-Cost Multi-Path (ECMP), learning how network architects leverage topological redundancy to improve overall system throughput and resilience.", "problem": "A folded-Clos interconnection network is organized into two switch tiers: an edge tier and a spine tier. Consider a symmetric folded-Clos with the following structure. There are $P$ pods. Each pod contains $E$ edge switches, and each edge switch has $H$ host ports and $S$ uplinks, one to each of the $S$ spine switches. Each spine switch has exactly one downlink to every edge switch in every pod. Hosts connect only to edge switches; there are no direct links between edge switches, and there are no direct links between spine switches. Assume full bisection bandwidth wiring and that all links are identical and unidirectional pairs arranged as full-duplex links. Model the interconnection as an undirected graph where vertices are hosts and switches, and edges are physical links.\n\nUsing only the definition that the length of a path in a graph is the number of edges it contains, and the structural facts given above, do the following for two hosts $h_{s}$ and $h_{d}$ attached to edge switches in different pods:\n1. Derive the minimal link-hop count between $h_{s}$ and $h_{d}$.\n2. Derive the number $m$ of distinct equal-cost minimal paths between $h_{s}$ and $h_{d}$.\n3. Propose an Equal-Cost Multi-Path (ECMP) selection: for each flow identified by a key, compute a $b$-bit hash $h$ that is uniformly distributed over $\\{0,1,\\dots,2^{b}-1\\}$, and choose one of the $m$ minimal paths by selecting a spine index via $h \\bmod m$. For the specific parameters $S=12$ and $b=10$, compute the maximum selection probability that any particular spine is chosen by a single flow under this ECMP-like modulo selection, assuming an ideal uniform hash and that $m$ equals the number you derived in part $2$.\n\nProvide as your final answer only the value of this maximum probability as a reduced fraction. Do not include units. Do not round.", "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and internally consistent. It presents a standard problem in computer network topology analysis and probability theory. All necessary parameters and definitions for a unique solution are provided. We may therefore proceed with the derivation.\n\nThe network is a symmetric folded-Clos with $P$ pods, $E$ edge switches per pod, and $S$ spine switches in total. Each edge switch has $H$ host ports and $S$ uplinks. A source host $h_s$ and a destination host $h_d$ are in different pods. Let $e_s$ be the edge switch connected to $h_s$, and $e_d$ be the edge switch connected to $h_d$. Since the hosts are in different pods, $e_s$ and $e_d$ are in different pods. The network is modeled as an undirected graph, and path length is the number of edges (hops).\n\n1.  Derivation of the minimal link-hop count:\n\nA path from $h_s$ to $h_d$ must traverse the network components.\n-   The first hop is from the host $h_s$ to its connected edge switch $e_s$. This path segment has length $1$.\n-   From $e_s$, the path must go upward to the spine tier, as there are no direct links between edge switches. Let the path go to some spine switch $sp_i$. This path segment, $e_s \\rightarrow sp_i$, has length $1$. The problem states that each edge switch has an uplink to each of the $S$ spine switches, so this link exists.\n-   From the spine switch $sp_i$, the path must go downward to an edge switch, as there are no direct links between spine switches. To reach $h_d$, the path must go to the edge switch $e_d$. The problem states that each spine switch has a downlink to every edge switch. Therefore, the link $sp_i \\rightarrow e_d$ exists. This path segment has length $1$.\n-   The final hop is from the edge switch $e_d$ to the destination host $h_d$. This path segment has length $1$.\n\nThe total constructed path is $h_s \\rightarrow e_s \\rightarrow sp_i \\rightarrow e_d \\rightarrow h_d$. The length of this path is the sum of the lengths of its segments: $1 + 1 + 1 + 1 = 4$.\n\nTo confirm this is the minimal path length, we must show no shorter path exists.\n-   A path of length $1$ or $2$ would imply $h_s$ and $h_d$ are connected to the same switch, but they are in different pods, which means their respective edge switches, $e_s$ and $e_d$, are different and in different pods. This is not possible.\n-   A path of length $3$ could take the form $h_s \\rightarrow e_s \\rightarrow \\text{switch} \\rightarrow h_d$ or $h_s \\rightarrow \\text{switch} \\rightarrow e_d \\rightarrow h_d$. The intermediate switch cannot be a host. If the path is $h_s \\rightarrow e_s \\rightarrow e_d \\rightarrow h_d$, it would require a direct link between edge switches $e_s$ and $e_d$. The problem explicitly states there are \"no direct links between edge switches\". If the path is $h_s \\rightarrow e_s \\rightarrow sp_i \\rightarrow h_d$, it would require a direct link between a spine switch and a host. The problem states \"Hosts connect only to edge switches\". Thus, a path of length $3$ is impossible.\n\nTherefore, the minimal link-hop count between $h_s$ and $h_d$ is $4$.\n\n2.  Derivation of the number of distinct equal-cost minimal paths:\n\nThe minimal path is of the form $h_s \\rightarrow e_s \\rightarrow sp_i \\rightarrow e_d \\rightarrow h_d$. For a given pair of hosts $(h_s, h_d)$, their respective edge switches $(e_s, e_d)$ are fixed. The first hop ($h_s \\rightarrow e_s$) and the last hop ($e_d \\rightarrow h_d$) are therefore unique for any path.\n\nThe variability in the path comes from the choice of the intermediate spine switch, $sp_i$. We need to count how many valid choices exist for $sp_i$.\n-   The link $e_s \\rightarrow sp_i$ must exist. The problem states: \"each edge switch has $S$ uplinks, one to each of the $S$ spine switches.\" This means $e_s$ is connected to all $S$ spine switches.\n-   The link $sp_i \\rightarrow e_d$ must exist. The problem states: \"Each spine switch has exactly one downlink to every edge switch in every pod.\" This means any of the $S$ spine switches is connected to $e_d$.\n\nSince any of the $S$ spine switches provides a valid intermediate hop, there are $S$ distinct paths of minimal length. Each path corresponds to a unique choice of spine switch. Thus, the number of distinct equal-cost minimal paths is $m = S$.\n\n3.  ECMP selection probability calculation:\n\nThe Equal-Cost Multi-Path (ECMP) selection rule is to choose one of the $m$ minimal paths by selecting a spine switch index via $k = h \\bmod m$. The hash $h$ is a $b$-bit integer, a random variable uniformly distributed over the set $\\{0, 1, \\dots, 2^b-1\\}$.\nThe specific parameters are $S=12$ and $b=10$.\n\nFrom part 2, the number of minimal paths is $m=S$. So, for this problem, $m=12$.\nThe total number of possible hash values is $N = 2^b = 2^{10} = 1024$.\nThe spine switch is selected based on the value of $h \\bmod 12$. The possible outcomes are $\\{0, 1, \\dots, 11\\}$.\n\nWe need to find the maximum probability that any particular spine is chosen. Let $P_k$ be the probability that spine $k$ is chosen, where $k \\in \\{0, 1, \\dots, 11\\}$.\n$$P_k = P(h \\bmod 12 = k) = \\frac{|\\{h \\mid 0 \\le h < N \\text{ and } h \\equiv k \\pmod{12}\\}|}{N}$$\nSince the hash value $h$ is uniformly distributed, we need to count how many of the $N=1024$ possible values of $h$ map to each remainder $k$ when divided by $12$.\n\nLet $N = qS + r$, where $q = \\lfloor N/S \\rfloor$ is the quotient and $r = N \\bmod S$ is the remainder, with $0 \\le r < S$.\nFor the given parameters: $N=1024$ and $S=12$.\n$1024 = q \\cdot 12 + r$.\n$1024 \\div 12 = 85$ with a remainder of $4$. So, $q=85$ and $r=4$.\n\nThe $N=1024$ hash values are $\\{0, 1, \\dots, 1023\\}$.\nThe first $qS = 85 \\times 12 = 1020$ hash values (from $0$ to $1019$) are distributed perfectly among the $12$ spine switches, with each spine being selected $q=85$ times.\nThe remaining $r=4$ hash values are $\\{1020, 1021, 1022, 1023\\}$.\nThese hash values, when taken modulo $12$, are $\\{0, 1, 2, 3\\}$.\nSo, the spine switches with indices $0, 1, 2, 3$ are selected one additional time.\n\n-   For $k \\in \\{0, 1, 2, 3\\}$, the number of hash values mapping to $k$ is $q+1 = 85+1 = 86$.\n-   For $k \\in \\{4, 5, \\dots, 11\\}$, the number of hash values mapping to $k$ is $q = 85$.\n\nThe probabilities are:\n-   $P_k = \\frac{86}{1024}$ for $k \\in \\{0, 1, 2, 3\\}$.\n-   $P_k = \\frac{85}{1024}$ for $k \\in \\{4, 5, \\dots, 11\\}$.\n\nThe maximum selection probability is $\\frac{86}{1024}$.\nThis can be expressed generally. The maximum number of hash values that can map to a single spine is $\\lceil N/S \\rceil$.\nFor $N=1024$ and $S=12$, $N/S = 1024/12 = 256/3 \\approx 85.333$.\n$\\lceil 1024/12 \\rceil = 86$.\nThe maximum probability is $\\frac{\\lceil N/S \\rceil}{N} = \\frac{86}{1024}$.\n\nThe final step is to reduce this fraction.\n$86 = 2 \\times 43$.\n$1024 = 2^{10}$.\n$$P_{max} = \\frac{86}{1024} = \\frac{2 \\times 43}{2^{10}} = \\frac{43}{2^9} = \\frac{43}{512}$$\nSince $43$ is a prime number and $512$ is a power of $2$, the fraction is fully reduced.", "answer": "$$\\boxed{\\frac{43}{512}}$$", "id": "3652394"}, {"introduction": "An interconnection network's role extends beyond just performance; it is fundamentally tied to the correctness of the entire system, especially in shared-memory multiprocessors. Different interconnects provide different guarantees about the order in which messages are delivered. This exercise [@problem_id:3652369] presents a scenario that contrasts a totally-ordered bus with a partially-ordered Network-on-Chip (NoC), asking you to reason about how these ordering differences impact the design of a cache coherence protocol. This thought experiment is crucial for understanding why protocols designed for one interconnect may not work correctly on another, highlighting the deep interplay between hardware architecture and system-level correctness.", "problem": "A shared-memory multiprocessor has four cores $C_0$, $C_1$, $C_2$, and $C_3$ and implements cache coherence for a single cache line $X$. Consider two interconnect designs:\n\n- Design B: a single shared bus with a centralized arbiter. Coherence uses snooping with atomic bus requests; the bus arbiter grants one requester at a time, and all caches observe the same sequence of coherence transactions.\n- Design N: a Network-on-Chip (NoC), specifically a $2$-D mesh, with dimension-order routing and per-link First-In First-Out (FIFO) queues. The network interface injects packets independently, and the interconnect does not enforce a single global order on all packets. Coherence uses a directory at the home node for $X$; invalidations and data responses are separate messages.\n\nA timeline of requests is as follows: at time $t_1$, core $C_1$ issues a write to $X$; at time $t_2$, core $C_2$ issues a write to $X$; at time $t_3$, core $C_3$ issues a read to $X$, with $t_1 < t_2 < t_3$. Assume that write requests use a write-invalidate policy and must obtain exclusive ownership before updating $X$, and that $C_0$ initially holds a clean shared copy and main memory has the same value as $C_0$.\n\nUsing fundamental definitions of ordering and coherence, analyze how interconnect-induced ordering affects what values can be observed and what protocol machinery is required to maintain the single-writer, multiple-reader invariant. Select all statements that are correct.\n\nA. On Design B (bus), the combined sequence of coherence requests forms a single total order observed by all caches; a snooping protocol can rely on this serialization to maintain the single-writer, multiple-reader invariant without per-request sequence numbers.\n\nB. On Design N (NoC), per-link FIFO queues guarantee a global total order across the entire network for all packets, so a bus-like snooping protocol can be used unchanged.\n\nC. On Design N (NoC), to preserve coherence under potential message reordering, the protocol must either enforce ordering per-address via mechanisms such as a directory at the home node, acknowledgments and transient states, or introduce additional virtual channels or per-source sequence numbers to prevent reordering-related races.\n\nD. On Design B (bus), if $C_1$ and $C_2$ issue writes to $X$ nearly simultaneously, the bus arbiter’s grant order defines their serialization; $C_3$’s read will observe the value from the later of the two writes if its bus request occurs after both grants, independent of the physical distances to the arbiter.\n\nE. In Design N (NoC), dimension-order routing ensures that all caches observe the same order of requests for the same address, so protocol complexity is reduced compared to bus.\n\nSelect all that apply.", "solution": "Begin from core definitions and widely accepted facts in computer organization and architecture:\n\n- A cache coherence protocol must enforce the single-writer, multiple-reader invariant: at any logical time, either one core holds an exclusive, writable copy of a cache line, or multiple cores hold shared, read-only copies, and writes must be serialized so that readers see a consistent value. This requires that operations on a given line admit a serialization that is consistent with each core’s program order.\n- A shared bus with arbitration acts as a single serialization point: bus requests are granted one at a time, and all observers see the same total order of bus transactions. Snooping protocols leverage this property to implement coherence with simple state transitions, because all caches can agree on the order in which ownership changes, invalidations, and data updates occur.\n- A Network-on-Chip (NoC) with packet switching, per-link FIFO queues, and dimension-order routing does not, in general, provide a single global total order across all packets originating from different sources and traveling along different paths. Even if each link preserves the order of packets traversing that link, differences in path length, contention, and independent injection can cause different observers to see requests for a given address arrive in different orders unless additional ordering mechanisms are enforced.\n\nApply these to the scenario:\n\nFor Design B (bus), suppose $C_1$ requests exclusive ownership at time $t_1$ and $C_2$ at $t_2$, with $t_1 < t_2$. The bus arbiter chooses one requester at a time; the grant order defines a total order for all caches. If $C_1$ is granted first, it broadcasts invalidations, receives acknowledgments implicitly through snooping or via the bus semantics, and then writes the new value to $X$. When $C_2$ subsequently requests ownership, it is serialized after $C_1$, and its write will occur after $C_1$’s. If $C_3$ issues a read at $t_3$ and the bus processes it after both writes are granted and completed, the read is ordered after the later write and thus observes the later value. Physical wire delays to the arbiter do not alter the logical bus serialization: the bus defines a single, globally observed order.\n\nFor Design N (NoC), packets for requests, invalidations, acknowledgments, and data responses traverse separate paths. Per-link FIFO ordering only preserves the order of packets on the same link; it does not create a global total order across all links and sources. Consider $C_1$ and $C_2$ sending requests to the directory home for $X$. If $C_1$’s request travels $3$ hops and $C_2$’s travels $1$ hop, $C_2$’s request can arrive at the directory first even though $t_1 < t_2$. Similarly, invalidations to sharers and data responses to requesters may arrive at different times and in different relative orders to each core because they experience different network congestion. Without additional protocol machinery, a snooping protocol that assumes a single serialization point could fail: a read by $C_3$ might be served by memory before an invalidation has completed, or two writers might transiently believe they both have permission. To prevent such races, directory-based coherence with explicit acknowledgments is used to ensure that a writer obtains exclusive ownership before completing, and that readers are served only after invalidations complete. Additional transient states track in-flight requests and acknowledgments. Designers may also use virtual channels to separate request, response, and acknowledgment traffic, and per-source sequence numbers to prevent reordering across messages that must be processed in order for a given address, thereby increasing protocol complexity relative to a bus-snooping design.\n\nOption-by-option analysis:\n\n- A. This statement is consistent with the bus as a global serialization point. All caches observe the same total order of bus transactions; snooping protocols exploit this, and do not require per-request sequence numbers because the bus defines the order. Verdict: Correct.\n\n- B. Per-link FIFO only guarantees that packets are not reordered on any given link; it does not impose a single global total order across the network. Different paths and sources result in different arrival orders. Consequently, a bus-like snooping protocol cannot be used unchanged on a general NoC without additional ordering or directory mechanisms. Verdict: Incorrect.\n\n- C. This correctly identifies the need for additional ordering and tracking mechanisms in the NoC case. Directory controllers serialize per-address requests, acknowledgments ensure invalidations complete, transient states track in-flight operations, and virtual channels or per-source sequence numbers are used to prevent deadlock and reorder-sensitive races. Verdict: Correct.\n\n- D. On a bus, arbitration defines serialization irrespective of physical distance. If $C_3$’s read is ordered on the bus after both write grants have completed, the read will observe the later write’s value, consistent with the single-writer, multiple-reader invariant and bus serialization. Verdict: Correct.\n\n- E. Dimension-order routing constrains the path a packet takes but does not ensure that all caches observe the same order of requests for the same address, especially when packets originate from different sources and traverse different numbers of hops. Protocol complexity is not reduced compared to bus; it generally increases to handle reordering and distributed serialization. Verdict: Incorrect.\n\nThus, the correct options are A, C, and D.", "answer": "$$\\boxed{ACD}$$", "id": "3652369"}]}