{"hands_on_practices": [{"introduction": "Finite State Machines (FSMs) are the foundation of sequential logic, and they come in two primary flavors: Moore and Mealy machines. The critical distinction between them lies in how they generate their outputs; a Moore machine's output is a function of its current state only, while a Mealy machine's output depends on both the current state and the current input. This practice challenges you to analyze the timing behavior of both FSM types in a practical pattern detection task, revealing the one-cycle latency difference that is a direct consequence of their definitions [@problem_id:3628036].", "problem": "A synchronous serial pattern detector processes a single-bit input stream to detect the binary word `1011`. The detector is clocked with period $T$ and samples input on rising edges. Let $k \\in \\mathbb{Z}$ index rising edges. Define the cycle $k$ as the open interval between rising edges $k$ and $k+1$. Assume the input is synchronous: the bit applied during cycle $k$ is denoted $x[k] \\in \\{0,1\\}$ and is stable throughout cycle $k$ until the next rising edge.\n\nTwo realizations are considered:\n\n- A Mealy finite state machine (FSM): its output $z[k]$ during cycle $k$ is a function of the current state $S[k]$ and the current input $x[k]$.\n- A Moore finite state machine (FSM): its output $y[k]$ during cycle $k$ is a function of the current state $S[k]$ only.\n\nIn both designs, the next state is computed by combinational logic as a function of the current state and current input during cycle $k$ and then registered at rising edge $k+1$: $S[k+1] = f(S[k], x[k])$. The sequence detector allows overlaps (for example, in `10111` there are two detections). Consider three output variants:\n- The raw Mealy output $z[k]$ (unregistered).\n- A registered Mealy output $z_{r}[k]$, formed by passing $z[k-1]$ through a D-type flip-flop (DFF) triggered by the same rising edge, so that $z_{r}[k]$ equals the value of $z[k-1]$ captured at edge $k$.\n- The Moore output $y[k]$ (as a function of the registered state).\n\nSuppose the input presents the subsequence $x[n-3]=1$, $x[n-2]=0$, $x[n-1]=1$, $x[n]=1$, with $x[n-4]=0$, so that the four bits during cycles $n-3$ through $n$ are exactly the target word `1011` and no earlier match straddles these cycles. Neglect propagation delays relative to $T$ except insofar as they determine whether a change occurs within a cycle versus on a later cycle, and assume all logic is hazard-free for this analysis.\n\nWhich of the following timing statements about when the detector outputs first assert (transition to $1$) relative to the last bit $x[n]=1$ are correct?\n\nA. The unregistered Mealy output $z[k]$ can first assert during cycle $n$, while the Moore output $y[k]$ first asserts during cycle $n+1$. If $z[k]$ is registered to form $z_{r}[k]$, then $z_{r}[k]$ first asserts during cycle $n+1$.\n\nB. A synchronous downstream register sampling at rising edges can observe the unregistered Mealy output asserted already at edge $n$, whereas the Moore output requires waiting until edge $n+1$.\n\nC. Both unregistered Mealy and Moore outputs can first assert during cycle $n$ because both depend on signals available immediately after the rising edge at the start of cycle $n$.\n\nD. Registering the Mealy output always adds two full cycles of latency relative to the last input bit, so $z_{r}[k]$ first asserts during cycle $n+2$.", "solution": "The problem statement is a well-defined question in the domain of synchronous digital logic design, specifically concerning the timing characteristics of Mealy and Moore Finite State Machines (FSMs). The definitions provided for the machines, clocking, and input/output behavior are standard and consistent with established theory. The problem is scientifically grounded, well-posed, and objective. It contains all necessary information to derive a unique and verifiable solution. Therefore, the problem is valid.\n\nWe will analyze the timing of the output assertion for the three specified detector implementations: an unregistered Mealy FSM, a Moore FSM, and a registered Mealy FSM. The goal is to detect the sequence `1011`. The final bit of the first occurrence of this sequence is $x[n]=1$, which is present during cycle $n$.\n\nFirst, let's establish the state transition behavior. The state of the FSM at the beginning of cycle $k$ is denoted $S[k]$. This state is the output of a register clocked by the rising edge at the start of cycle $k$. The state transition function is $S[k+1] = f(S[k], x[k])$, where $x[k]$ is the input during cycle $k$.\n\n**1. Unregistered Mealy FSM**\n\nIn a Mealy machine, the output $z[k]$ is a function of the current state $S[k]$ and the current input $x[k]$, i.e., $z[k] = g(S[k], x[k])$. Since this output is generated by combinational logic, its value is available during cycle $k$, after the propagation delays of the state register and the output logic itself.\n\nWe design an FSM to detect `1011`. The states represent the longest suffix of the input stream that is a prefix of `1011`.\n- $S_0$: Empty prefix (reset state).\n- $S_1$: Prefix `1` matched.\n- $S_2$: Prefix `10` matched.\n- $S_3$: Prefix `101` matched.\n\nThe detection of `1011` occurs when the machine is in state $S_3$ and receives an input of $1$. The output logic $g(S,x)$ will be $1$ only for the case where $S=S_3$ and $x=1$.\n\nLet's trace the state transitions for the given input sequence: $x[n-4]=0, x[n-3]=1, x[n-2]=0, x[n-1]=1, x[n]=1$. We assume the FSM is in state $S_0$ prior to this sequence, enforced by $x[n-4]=0$.\n\n-   **Cycle $n-3$**: At rising edge $n-3$, the state is $S[n-3]=S_0$. The input is $x[n-3]=1$.\n    The next state latched at edge $n-2$ is $S[n-2]=f(S_0,1)=S_1$.\n    The Mealy output during this cycle is $z[n-3]=g(S_0,1)=0$.\n\n-   **Cycle $n-2$**: At rising edge $n-2$, the state is $S[n-2]=S_1$. The input is $x[n-2]=0$.\n    The next state latched at edge $n-1$ is $S[n-1]=f(S_1,0)=S_2$.\n    The Mealy output is $z[n-2]=g(S_1,0)=0$.\n\n-   **Cycle $n-1$**: At rising edge $n-1$, the state is $S[n-1]=S_2$. The input is $x[n-1]=1$.\n    The next state latched at edge $n$ is $S[n]=f(S_2,1)=S_3$.\n    The Mealy output is $z[n-1]=g(S_2,1)=0$.\n\n-   **Cycle $n$**: At rising edge $n$, the state is $S[n]=S_3$. The input is $x[n]=1$. The sequence `1011` is now complete.\n    The Mealy output during this cycle is $z[n]=g(S_3,1)=1$.\n    This output asserts to $1$ during cycle $n$, after the state $S[n]$ becomes available and the combinational logic for $g$ computes the result.\n\nThus, the unregistered Mealy output $z[k]$ first asserts during cycle $n$.\n\n**2. Moore FSM**\n\nIn a Moore machine, the output $y[k]$ is a function of the current state $S[k]$ only, i.e., $y[k]=h(S[k])$. The output is stable throughout the entire cycle. To signal detection of a sequence, the FSM must enter a specific state whose associated output is $1$.\n\nFor detecting `1011`, we need an additional state compared to the Mealy FSM, which we'll call $S_4$, to represent that the complete sequence has been received.\n- $S_0, S_1, S_2, S_3$: Same as above, with output $h(S_i)=0$ for $i \\in \\{0, 1, 2, 3\\}$.\n- $S_4$: Sequence `1011` matched. Output $h(S_4)=1$.\n\nLet's trace the state transitions:\n- The state progression up to cycle $n$ is the same as for the Mealy machine: $S[n-3]=S_0$, $S[n-2]=S_1$, $S[n-1]=S_2$, $S[n]=S_3$.\n- **Cycle $n$**: At rising edge $n$, the state is $S[n]=S_3$. The input is $x[n]=1$.\n    The Moore output during this cycle is $y[n]=h(S[n]) = h(S_3) = 0$.\n    The next state, determined by $f(S[n],x[n]) = f(S_3,1)$, is the detection state $S_4$. So, $S[n+1]=S_4$. This state is latched at the rising edge $n+1$.\n\n- **Cycle $n+1$**: At rising edge $n+1$, the state becomes $S[n+1]=S_4$.\n    The Moore output during this cycle is $y[n+1]=h(S[n+1]) = h(S_4) = 1$.\n\nThus, the Moore output $y[k]$ first asserts at the beginning of cycle $n+1$.\n\n**3. Registered Mealy Output**\n\nThe registered Mealy output $z_r[k]$ is defined as the value of $z[k-1]$ captured by a D-type flip-flop at rising edge $k$. This means the value of $z_r$ during cycle $k$ is equal to the value of $z$ during cycle $k-1$. So, $z_r[k] = z[k-1]$.\n\n- We found that the unregistered output $z[k]$ is $0$ for all $k < n$ and $z[n]=1$.\n- To find when $z_r[k]$ first asserts, we can evaluate it for cycles around $n$:\n    - For cycle $n$, $z_r[n] = z[n-1] = 0$.\n    - For cycle $n+1$, $z_r[n+1] = z[n] = 1$.\n\nThus, the registered Mealy output $z_r[k]$ first asserts during cycle $n+1$.\n\n**Summary of Results**\n- Unregistered Mealy output $z[k]$ first asserts during cycle $n$.\n- Moore output $y[k]$ first asserts during cycle $n+1$.\n- Registered Mealy output $z_r[k]$ first asserts during cycle $n+1$.\n\nNow we evaluate the given options.\n\n**A. The unregistered Mealy output $z[k]$ can first assert during cycle $n$, while the Moore output $y[k]$ first asserts during cycle $n+1$. If $z[k]$ is registered to form $z_{r}[k]$, then $z_{r}[k]$ first asserts during cycle $n+1$.**\nThis statement perfectly matches our derived results for all three outputs.\n**Verdict: Correct.**\n\n**B. A synchronous downstream register sampling at rising edges can observe the unregistered Mealy output asserted already at edge $n$, whereas the Moore output requires waiting until edge $n+1$.**\nThe unregistered Mealy output $z[n]$ is generated from $S[n]$ and $x[n]$. The state $S[n]$ is the output of a flip-flop clocked at rising edge $n$. Therefore, $S[n]$ becomes valid only *after* edge $n$. Consequently, $z[n]$ is generated *after* edge $n$, during cycle $n$. For a synchronous register to sample a value at edge $n$, the value must be stable for a setup time *before* edge $n$. At that point, the Mealy output is $z[n-1]=0$. It is impossible to sample the asserted value of $z[n]$ at edge $n$. A downstream register could sample $z[n]=1$ at the next rising edge, which is edge $n+1$.\n**Verdict: Incorrect.**\n\n**C. Both unregistered Mealy and Moore outputs can first assert during cycle $n$ because both depend on signals available immediately after the rising edge at the start of cycle $n$.**\nThis claim is false. As derived above, the Moore output $y[k]$ first asserts during cycle $n+1$, not cycle $n$. The defining characteristic of a Moore machine is that its output depends only on the registered state, which means a change in output that signals the completion of a sequence is delayed by one clock cycle compared to a Mealy machine.\n**Verdict: Incorrect.**\n\n**D. Registering the Mealy output always adds two full cycles of latency relative to the last input bit, so $z_{r}[k]$ first asserts during cycle $n+2$.**\nThe last input bit, $x[n]$, arrives during cycle $n$. The unregistered Mealy output, $z[n]$, asserts within the same cycle. Registering this output using one D-type flip-flop, as described, adds exactly one cycle of latency. As shown in our analysis, $z_r[k]$ asserts during cycle $n+1$, which is one cycle after cycle $n$. A latency of two cycles would imply assertion in cycle $n+2$, which is incorrect.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "3628036"}, {"introduction": "Digital systems must often interface with an imperfect, analog world, where inputs from mechanical switches are prone to \"bouncing\"—producing a rapid series of spurious transitions. This exercise contrasts a simple, memoryless combinational filter with a stateful, sequential debouncing circuit. By analyzing their respective failure modes under a realistic bounce model, you will gain a practical appreciation for why sequential logic is essential for creating robust systems that can reliably interpret noisy, time-dependent signals [@problem_id:3628132].", "problem": "A mechanical push-button produces an asynchronous, glitch-prone signal at a logic input of a synchronous system. Consider two alternative front-end designs to condition this signal before it is consumed by the rest of the system.\n\nDesign C (naive combinational filter): The raw button signal $x(t)$ is fed to a gate that computes $y_{\\mathrm{C}}(t) = x(t) \\land x(t - \\tau_{d})$, where the delay $\\tau_{d}$ is implemented by an inverter chain with $N$ identical stages, each having propagation delay $t_{p}$, so that $\\tau_{d} \\approx N t_{p}$. There is no clocked storage before the system synchronizes $y_{\\mathrm{C}}(t)$ into a flip-flop.\n\nDesign S (sequential counter-based debouncer): The raw signal is first passed through a $2$-flip-flop synchronizer clocked at $f_{\\mathrm{clk}}$, yielding a sampled sequence $x[n]$ at period $T_{\\mathrm{clk}} = 1/f_{\\mathrm{clk}}$. A saturating counter increments by $1$ on each clock when $x[n]$ equals the current candidate value and resets to $0$ upon any sampled change. The debounced output updates to the current sampled value only when the counter reaches an integer threshold $M$, which requires $M$ consecutive identical samples.\n\nAssume the following, which reflect typical but conservative engineering models:\n- The clock frequency is $f_{\\mathrm{clk}} = 100\\,\\mathrm{MHz}$.\n- The combinational delay chain uses $N = 100$ inverters with $t_{p} = 50\\,\\mathrm{ps}$ per inverter, so $\\tau_{d} \\approx 5\\,\\mathrm{ns}$ nominally, with process-voltage-temperature (PVT) variation of $\\pm 30\\%$ on $t_{p}$.\n- On any press, the button contact bounces for up to $T_{b} = 5\\,\\mathrm{ms}$ from the first edge until final settling. During this bounce interval, the waveform may alternate arbitrarily between logic low and high, with the constraint that every continuous plateau of constant level has duration between $t_{\\min} = 20\\,\\mu\\mathrm{s}$ and $t_{\\max} = 1\\,\\mathrm{ms}$. After bouncing, the signal remains at the new state until the next user action.\n\nFrom first principles, a combinational circuit’s output depends only on present inputs and path delays, whereas a sequential circuit’s state depends on past inputs via clocked memory. Sampling an asynchronous signal at a flip-flop presents a risk of metastability if setup or hold constraints are violated. The counter-based debouncer is intended to accept a new state only after observing sufficient consecutive agreement across clocked samples.\n\nWhich of the following statements about failure modes and guarantees is/are correct under the stated models? Select all that apply.\n\nA. For Design C, because $\\tau_{d} \\approx 5\\,\\mathrm{ns}$ while every bounce plateau satisfies $t_{\\min} = 20\\,\\mu\\mathrm{s} \\gg \\tau_{d}$, most bounce plateaus will propagate through as real output pulses, causing multiple spurious transitions during a single press. Moreover, the exact behavior is sensitive to PVT variation of $\\tau_{d}$.\n\nB. For Design S operated at $f_{\\mathrm{clk}} = 100\\,\\mathrm{MHz}$ with $M = 2{,}000$, there exist bounce patterns consistent with the model (for example, two alternating plateaus each of duration at least $20\\,\\mu\\mathrm{s}$) that cause the debounced output to toggle more than once during a single press.\n\nC. With a proper $2$-flip-flop synchronizer preceding the counter in Design S, a sufficient condition to guarantee exactly one output transition per press under the stated bounce model is $M / f_{\\mathrm{clk}} > t_{\\max}$. If this inequality holds, no sampling phase or aliasing can force premature or multiple toggles.\n\nD. Because Design C is memoryless, it cannot generate hazards or runt pulses at its output and therefore reduces the risk of metastability when its output is later sampled by a flip-flop, compared to directly synchronizing the raw input.\n\nE. If Design S is configured so that $M / f_{\\mathrm{clk}} = T_{b}$ while $t_{\\max} \\ll T_{b}$, then premature acceptance of the new state during the bounce interval is still impossible under the model.", "solution": "The problem requires an analysis of two different circuits, one combinational (Design C) and one sequential (Design S), for debouncing a mechanical push-button signal. The analysis must be based on the provided models for the circuits and the button bounce characteristics.\n\nFirst, let's summarize and derive the key parameters for our analysis.\nThe raw input signal $x(t)$ bounces for up to $T_{b} = 5\\,\\mathrm{ms}$. During this bounce period, any stable plateau has a duration in the range $[t_{\\min}, t_{\\max}]$, where $t_{\\min} = 20\\,\\mu\\mathrm{s}$ and $t_{\\max} = 1\\,\\mathrm{ms}$.\nThe system clock for Design S is $f_{\\mathrm{clk}} = 100\\,\\mathrm{MHz}$, which corresponds to a clock period of $T_{\\mathrm{clk}} = 1/f_{\\mathrm{clk}} = 1/(100 \\times 10^6\\,\\mathrm{Hz}) = 10\\,\\mathrm{ns}$.\n\n**Analysis of Design C (Combinational Filter)**\n\nDesign C implements the logic function $y_{\\mathrm{C}}(t) = x(t) \\land x(t - \\tau_{d})$. The delay is nominally $\\tau_{d} = N \\times t_{p} = 100 \\times 50\\,\\mathrm{ps} = 5000\\,\\mathrm{ps} = 5\\,\\mathrm{ns}$. With a $\\pm 30\\%$ PVT variation, $\\tau_d$ can range from $5\\,\\mathrm{ns} \\times (1 - 0.3) = 3.5\\,\\mathrm{ns}$ to $5\\,\\mathrm{ns} \\times (1 + 0.3) = 6.5\\,\\mathrm{ns}$.\n\nThe circuit's behavior is as follows:\n- For the output $y_{\\mathrm{C}}(t)$ to be high ($1$), both $x(t)$ and $x(t - \\tau_{d})$ must be high. This means the input $x(t)$ must have been continuously high for at least the duration $\\tau_{d}$.\n- A rising edge at the input $x(t)$ results in a rising edge at the output $y_{\\mathrm{C}}(t)$ after a delay of $\\tau_{d}$.\n- A falling edge at the input $x(t)$ results in an immediate falling edge at the output $y_{\\mathrm{C}}(t)$ (assuming the AND gate delay is negligible).\n- Consequently, an input pulse of high level with duration $W$ results in an output pulse of duration $W - \\tau_{d}$.\n\nThe minimum duration of any bounce plateau is $t_{\\min} = 20\\,\\mu\\mathrm{s} = 20{,}000\\,\\mathrm{ns}$. Since $t_{\\min} \\gg \\tau_{d}$ (where $\\tau_d \\le 6.5\\,\\mathrm{ns}$), any high-level plateau during the bounce will be much longer than the filter delay $\\tau_d$. Therefore, each high plateau will produce a corresponding high pulse at the output, with a duration just slightly shorter than the input plateau. This means that the circuit fails to filter out the bounces; it merely propagates them, causing multiple spurious transitions at its output for a single button press.\n\n**Analysis of Design S (Sequential Debouncer)**\n\nDesign S samples the input and requires $M$ consecutive identical samples to validate a new state. The time required for this validation is $T_{\\mathrm{debounce}} = M \\times T_{\\mathrm{clk}} = M / f_{\\mathrm{clk}}$.\nTo correctly debounce the signal, $T_{\\mathrm{debounce}}$ must be set such that the counter does not reach its threshold $M$ due to any transient plateau during the bounce period, but does reach it once the signal has settled.\nThe longest possible stable plateau during the bounce period is $t_{\\max} = 1\\,\\mathrm{ms}$. Therefore, a sufficient condition to prevent premature acceptance of a state is to ensure that the required stable time is longer than any possible stable time during a bounce. This gives the condition $T_{\\mathrm{debounce}} > t_{\\max}$.\n\nNow we evaluate each statement.\n\n**A. For Design C, because $\\tau_{d} \\approx 5\\,\\mathrm{ns}$ while every bounce plateau satisfies $t_{\\min} = 20\\,\\mu\\mathrm{s} \\gg \\tau_{d}$, most bounce plateaus will propagate through as real output pulses, causing multiple spurious transitions during a single press. Moreover, the exact behavior is sensitive to PVT variation of $\\tau_{d}$.**\n\nAs established in the analysis of Design C, any high plateau of duration $W$ is converted to a high output pulse of duration $W - \\tau_d$. Since the shortest plateau duration is $t_{\\min}=20\\,\\mu\\mathrm{s}$, and the largest delay is $\\tau_{d}=6.5\\,\\mathrm{ns}$, the shortest output pulse will have a duration of $20\\,\\mu\\mathrm{s} - 6.5\\,\\mathrm{ns}$, which is substantial. The circuit does not filter the sequence of plateaus that constitute the bounce, so it will produce multiple spurious transitions. The first part of the statement is correct.\nThe PVT variation on $\\tau_d$ (from $3.5\\,\\mathrm{ns}$ to $6.5\\,\\mathrm{ns}$) directly affects the duration of the output pulses ($W - \\tau_d$) and the delay of the rising edges. Therefore, the exact timing of the output signal is indeed sensitive to PVT variation. Both parts of the statement are correct.\n\nVerdict: **Correct**.\n\n**B. For Design S operated at $f_{\\mathrm{clk}} = 100\\,\\mathrm{MHz}$ with $M = 2{,}000$, there exist bounce patterns consistent with the model (for example, two alternating plateaus each of duration at least $20\\,\\mu\\mathrm{s}$) that cause the debounced output to toggle more than once during a single press.**\n\nWith $f_{\\mathrm{clk}} = 100\\,\\mathrm{MHz}$ and $M = 2{,}000$, the time required to validate a state is $T_{\\mathrm{debounce}} = M / f_{\\mathrm{clk}} = 2{,}000 / (100 \\times 10^6\\,\\mathrm{Hz}) = 20 \\times 10^{-6}\\,\\mathrm{s} = 20\\,\\mu\\mathrm{s}$.\nThis debounce time is equal to the minimum plateau duration, $t_{\\min} = 20\\,\\mu\\mathrm{s}$.\nConsider a bounce pattern where the signal, initially low, goes high for $25\\,\\mu\\mathrm{s}$, then low for $25\\,\\mu\\mathrm{s}$. This pattern is consistent with the model, as both plateaus have durations between $t_{\\min}$ and $t_{\\max}$.\n1.  When the signal goes high, it remains stable for $25\\,\\mu\\mathrm{s}$. Since $25\\,\\mu\\mathrm{s} > T_{\\mathrm{debounce}} = 20\\,\\mu\\mathrm{s}$, the counter will reach $M$ and the debounced output will switch to high.\n2.  When the signal then goes low, the counter resets and begins counting stable low samples. Since the signal remains low for $25\\,\\mu\\mathrm{s} > T_{\\mathrm{debounce}}$, the counter will again reach $M$, and the debounced output will switch back to low.\nThis sequence results in two toggles of the debounced output during a single press. Therefore, the statement is correct.\n\nVerdict: **Correct**.\n\n**C. With a proper $2$-flip-flop synchronizer preceding the counter in Design S, a sufficient condition to guarantee exactly one output transition per press under the stated bounce model is $M / f_{\\mathrm{clk}} > t_{\\max}$. If this inequality holds, no sampling phase or aliasing can force premature or multiple toggles.**\n\nThe condition is $T_{\\mathrm{debounce}} > t_{\\max}$. Here, $t_{\\max} = 1\\,\\mathrm{ms}$ is the maximum duration any stable plateau can last during the bounce interval.\nIf the time required to validate a state ($T_{\\mathrm{debounce}}$) is strictly greater than the longest possible stable interval during a bounce ($t_{\\max}$), then it is impossible for the counter to ever reach its threshold $M$ during the bounce period. Any sequence of identical samples will be interrupted by a signal change before the count reaches $M$, causing the counter to reset.\nOnce the bounce period (of duration up to $T_b$) is over, the signal settles to its final state and remains there indefinitely. The counter will then begin, complete its count to $M$ after $T_{\\mathrm{debounce}}$, and cause a single, final transition of the debounced output. The synchronizer handles the risk of metastability from sampling the asynchronous input, ensuring the counter logic receives clean samples. This condition is therefore sufficient to guarantee correct debouncing.\n\nVerdict: **Correct**.\n\n**D. Because Design C is memoryless, it cannot generate hazards or runt pulses at its output and therefore reduces the risk of metastability when its output is later sampled by a flip-flop, compared to directly synchronizing the raw input.**\n\nThis statement is flawed. The premise \"Because Design C is memoryless, it cannot generate hazards\" is false. Combinational logic circuits are well-known to be susceptible to hazards (static, dynamic) which are spurious output glitches caused by differing path delays. While this specific circuit might not exhibit a static hazard for a single clean input edge, the general claim about memoryless circuits is false. Furthermore, any real logic gate has finite slew rates, and if input transitions are very fast, the output may not reach full logic levels, creating a runt pulse.\nThe conclusion that it \"reduces the risk of metastability\" is also incorrect. The output of Design C, $y_C(t)$, is still an asynchronous signal. As shown in the analysis for option A, it contains just as many transitions as the bouncing input. The risk of metastability arises when the input to a flip-flop changes within the setup-and-hold time window relative to the clock edge. Since $y_C(t)$ has many edges that are asynchronous to the system clock, the risk of metastability is not reduced compared to synchronizing the raw signal $x(t)$.\n\nVerdict: **Incorrect**.\n\n**E. If Design S is configured so that $M / f_{\\mathrm{clk}} = T_{b}$ while $t_{\\max} \\ll T_{b}$, then premature acceptance of the new state during the bounce interval is still impossible under the model.**\n\nThis statement proposes a specific configuration for Design S. The debounce time is set to $T_{\\mathrm{debounce}} = M / f_{\\mathrm{clk}} = T_b = 5\\,\\mathrm{ms}$.\nThe bounce model specifies that during the bounce interval (which lasts up to $T_b$), any continuous plateau has a duration of at most $t_{\\max} = 1\\,\\mathrm{ms}$.\nFor the debouncer to accept a new state, the input must be stable for $T_{\\mathrm{debounce}} = 5\\,\\mathrm{ms}$.\nHowever, during the entire bounce interval, the signal is guaranteed to change at least once every $t_{\\max} = 1\\,\\mathrm{ms}$. Thus, it is impossible for the signal to be stable for the required $5\\,\\mathrm{ms}$ at any point *during* the bounce.\nThe counter will therefore never reach its threshold $M$ until after the bouncing has ceased completely and the signal is permanently stable. This configuration satisfies the sufficient condition from option C, since $T_{\\mathrm{debounce}} = 5\\,\\mathrm{ms} > t_{\\max} = 1\\,\\mathrm{ms}$. Thus, premature acceptance is indeed impossible.\n\nVerdict: **Correct**.", "answer": "$$\\boxed{ABCE}$$", "id": "3628132"}, {"introduction": "Implementing mathematical functions in hardware often presents a fundamental design trade-off between speed and cost. This problem explores that trade-off by comparing two distinct architectures for approximating the function $f(x) = x^{2}$. You will analyze a fast, parallel, but potentially large combinational approach using a look-up table against a compact, iterative sequential method [@problem_id:3628129]. This practice moves beyond simple logic design into the realm of computer architecture, requiring you to quantitatively evaluate and compare designs based on accuracy, latency, and hardware area.", "problem": "A fixed-point datapath must approximate the real-valued function $f(x) = x^{2}$ for inputs $x \\in [0,1]$ using two alternative architectures: a combinational Look-Up Table (LUT) with piecewise-linear interpolation and a sequential iterative CORDIC-like squarer. The fixed-point format for $x$ uses $b = 16$ fractional bits.\n\nArchitecture C (combinational): The approximation domain $[0,1]$ is partitioned into $N$ uniform segments of width $h = 1/N$. The design stores the endpoint values $y_{k} = (k/N)^{2}$ for $k = 0,1,\\dots,N$ in a memory and performs piecewise-linear interpolation: for $x \\in [k/N,(k+1)/N]$, it computes $y \\approx y_{k} + t \\cdot (y_{k+1} - y_{k})$ where $t \\in [0,1]$ is the local fractional position within the segment. The datapath uses one subtractor to form $(y_{k+1} - y_{k})$, one multiplier to compute $t \\cdot (y_{k+1} - y_{k})$, and one adder to form $y_{k} + (\\cdot)$. Assume single-cycle latency for this combinational path. The stored $y$-values have word width $w_{y} = 16$ bits. Use the area cost model\n- memory area $A_{\\text{mem}} = c_{\\text{mem}} \\times (N+1) \\times w_{y}$,\n- adder/subtractor area $A_{\\text{add}} = c_{\\text{add}} \\times w_{y}$ per unit,\n- multiplier area $A_{\\text{mul}} = c_{\\text{mul}} \\times w_{t} \\times w_{y}$,\nwith $w_{t} = 16$ bits for $t$. The constants are $c_{\\text{mem}} = 1$, $c_{\\text{add}} = 2$, $c_{\\text{mul}} = 6$ (all in the same normalized gate-equivalent units).\n\nArchitecture S (sequential): A CORDIC-like iterative squarer resolves one fractional bit of $x$ per iteration by shift-add operations. After $k$ iterations, the internal representation equals the truncation $\\hat{x}$ of $x$ to $m = k$ fractional bits, and the output is $\\hat{x}^{2}$. The hardware consists of one $w_{y}$-bit adder, two $w_{y}$-bit registers, and control logic with fixed area $A_{\\text{ctrl}} = 64$ in the same units. Use the area cost model\n- adder area $A_{\\text{add}} = c_{\\text{add}} \\times w_{y}$,\n- register area $A_{\\text{reg}} = c_{\\text{reg}} \\times w_{y}$ per register,\nwith $c_{\\text{add}} = 2$, $c_{\\text{reg}} = 0.5$. The sequential latency is $k$ cycles.\n\nStarting from first principles:\n- Derive a worst-case bound on the maximum absolute error of Architecture C over $[0,1]$ in terms of $N$ using only calculus and the definition of piecewise-linear interpolation for $f(x) = x^{2}$.\n- Derive a worst-case bound on the maximum absolute error of Architecture S after $k$ iterations using only the definition of truncation to $m$ bits and algebraic identities for squaring.\nLet $k = 10$. Choose the minimal positive integer $N$ such that the worst-case maximum absolute error of Architecture C does not exceed that of Architecture S over $[0,1]$.\n\nWith this $N$, compute the area of each architecture using the given cost models, compute each architecture’s area-latency product, and then compute the ratio\n$$R \\;=\\; \\frac{\\text{(area-latency product of Architecture C)}}{\\text{(area-latency product of Architecture S)}}.$$\nRound your final ratio $R$ to four significant figures. Express the final answer as a pure number with no units.", "solution": "The problem statement has been validated and is determined to be a well-posed, scientifically grounded problem in digital architecture design and analysis. It is self-contained, objective, and its resolution requires substantive reasoning. We proceed with the solution.\n\nThe problem requires a comparative analysis of two digital architectures for approximating the function $f(x) = x^2$ on the interval $x \\in [0,1]$. We will first derive the worst-case approximation error for each architecture, then use these error bounds to determine a design parameter, and finally compute the area-latency performance metrics for comparison.\n\n**Part 1: Worst-Case Error for Architecture C (Combinational LUT)**\n\nArchitecture C approximates $f(x) = x^2$ using piecewise-linear interpolation. The domain $[0,1]$ is divided into $N$ segments, each of width $h = 1/N$. For an interval $[x_k, x_{k+1}]$, where $x_k = k/N$, the linear approximation $L(x)$ is given by:\n$$L(x) = f(x_k) + \\frac{f(x_{k+1}) - f(x_k)}{x_{k+1} - x_k}(x - x_k)$$\nThe error of this approximation is $E(x) = f(x) - L(x)$. According to the standard error bound for linear interpolation, for a function with a continuous second derivative, the error is given by:\n$$E(x) = \\frac{f''(\\xi)}{2!}(x - x_k)(x - x_{k+1})$$\nfor some $\\xi \\in (x_k, x_{k+1})$.\n\nFor our function $f(x) = x^2$, the derivatives are $f'(x) = 2x$ and $f''(x) = 2$. The second derivative is constant. Thus, the error expression becomes:\n$$E(x) = \\frac{2}{2}(x - x_k)(x - x_{k+1}) = (x-x_k)(x-x_{k+1})$$\nTo find the maximum absolute error within the interval $[x_k, x_{k+1}]$, we must find the maximum magnitude of the quadratic function $g(x) = (x-x_k)(x-x_{k+1})$. This quadratic has roots at $x_k$ and $x_{k+1}$, and its vertex is at the midpoint of the interval, $x = (x_k + x_{k+1})/2$.\nThe location of the maximum error is $x_{mid} = x_k + h/2$.\nThe maximum error magnitude in the interval is:\n$$|E(x_{mid})| = \\left|\\left(x_k + \\frac{h}{2} - x_k\\right)\\left(x_k + \\frac{h}{2} - x_{k+1}\\right)\\right| = \\left|\\left(\\frac{h}{2}\\right)\\left(x_k + \\frac{h}{2} - (x_k+h)\\right)\\right| = \\left|\\left(\\frac{h}{2}\\right)\\left(-\\frac{h}{2}\\right)\\right| = \\frac{h^2}{4}$$\nSince $h=1/N$ and this error magnitude is independent of the specific interval $k$, this is the worst-case error over the entire domain $[0,1]$.\nThe maximum absolute error for Architecture C is:\n$$\\epsilon_C = \\frac{1}{4N^2}$$\n\n**Part 2: Worst-Case Error for Architecture S (Sequential Squarer)**\n\nArchitecture S computes $\\hat{x}^2$, where $\\hat{x}$ is the value of $x$ truncated to $m$ fractional bits. The input $x$ is defined as having $b=16$ fractional bits, but the error analysis depends on the truncation to $m$ bits.\nFor a given $x \\in [0,1]$, $\\hat{x}$ is the largest number of the form $\\sum_{i=1}^m d_i 2^{-i}$ (where $d_i \\in \\{0,1\\}$) such that $\\hat{x} \\le x$. This implies the following relationship:\n$$\\hat{x} \\le x < \\hat{x} + 2^{-m}$$\nThe error in the output is $\\Delta = x^2 - \\hat{x}^2$. Since $x \\ge \\hat{x}$, this error is always non-negative. We want to find its maximum value over all $x \\in [0,1]$.\n$$\\Delta = x^2 - \\hat{x}^2 < (\\hat{x} + 2^{-m})^2 - \\hat{x}^2 = \\hat{x}^2 + 2\\hat{x}2^{-m} + (2^{-m})^2 - \\hat{x}^2 = 2\\hat{x}2^{-m} + 2^{-2m}$$\nThis upper bound on the error, $2\\hat{x}2^{-m} + 2^{-2m}$, is an increasing function of $\\hat{x}$. To find the supremum of the error, we must consider the largest possible value for $\\hat{x}$.\nAs $x$ approaches $1$, $\\hat{x}$ approaches its maximum possible value. For any $x \\in [1-2^{-m}, 1)$, the truncated value is $\\hat{x} = \\sum_{i=1}^m 1 \\cdot 2^{-i} = 1 - 2^{-m}$.\nFor a fixed $\\hat{x}$, the error $x^2 - \\hat{x}^2$ is maximized as $x$ approaches the upper end of its range, i.e., as $x \\to \\hat{x} + 2^{-m}$.\nThe overall maximum error occurs as $x \\to 1$. In this case, $\\hat{x} = 1 - 2^{-m}$. The error is:\n$$\\epsilon_S = \\lim_{x \\to 1^-} (x^2 - \\hat{x}(x)^2) = 1^2 - (1 - 2^{-m})^2 = 1 - (1 - 2 \\cdot 2^{-m} + 2^{-2m}) = 2 \\cdot 2^{-m} - 2^{-2m}$$\nThis can be written as:\n$$\\epsilon_S = 2^{-m+1} - 2^{-2m}$$\n\n**Part 3: Determine the number of segments N**\n\nWe are given that the sequential architecture uses $k=10$ iterations, so $m=k=10$. The error for Architecture S is:\n$$\\epsilon_S = 2^{-10+1} - 2^{-2 \\cdot 10} = 2^{-9} - 2^{-20} = \\frac{1}{512} - \\frac{1}{1048576} = \\frac{2^{11}-1}{2^{20}} = \\frac{2047}{1048576}$$\nWe must find the minimum positive integer $N$ such that the error of Architecture C does not exceed this value:\n$$\\epsilon_C \\le \\epsilon_S \\implies \\frac{1}{4N^2} \\le 2^{-9} - 2^{-20}$$\n$$4N^2 \\ge \\frac{1}{2^{-9} - 2^{-20}} \\implies N^2 \\ge \\frac{1}{4(2^{-9} - 2^{-20})} = \\frac{1}{4} \\frac{2^{20}}{2^{11}-1} = \\frac{2^{18}}{2047}$$\nNumerically, this is:\n$$N^2 \\ge \\frac{262144}{2047} \\approx 128.0625...$$\nTaking the square root:\n$$N \\ge \\sqrt{128.0625...} \\approx 11.316...$$\nSince $N$ must be an integer, the minimal value for $N$ is $12$.\n\n**Part 4: Compute Architecture Areas and Area-Latency Products**\n\nWith $N=12$ and $k=10$, we can now compute the area for each architecture using the provided cost models and parameters: $w_y = 16$, $w_t=16$, $c_{\\text{mem}}=1$, $c_{\\text{add}}=2$, $c_{\\text{mul}}=6$, $c_{\\text{reg}}=0.5$, $A_{\\text{ctrl}}=64$.\n\nArea of Architecture C ($A_C$):\nThe components are one $(N+1) \\times w_y$ memory, one adder, one subtractor, and one multiplier.\n$$A_C = A_{\\text{mem}} + A_{\\text{add}} + A_{\\text{sub}} + A_{\\text{mul}}$$\n$$A_{\\text{mem}} = c_{\\text{mem}} \\times (N+1) \\times w_y = 1 \\times (12+1) \\times 16 = 13 \\times 16 = 208$$\n$$A_{\\text{add}} = c_{\\text{add}} \\times w_y = 2 \\times 16 = 32$$\n$$A_{\\text{sub}} = c_{\\text{add}} \\times w_y = 2 \\times 16 = 32$$\n$$A_{\\text{mul}} = c_{\\text{mul}} \\times w_t \\times w_y = 6 \\times 16 \\times 16 = 1536$$\n$$A_C = 208 + 32 + 32 + 1536 = 1808$$\nThe latency is $L_C = 1$ cycle. The area-latency product for Architecture C is:\n$$P_C = A_C \\times L_C = 1808 \\times 1 = 1808$$\n\nArea of Architecture S ($A_S$):\nThe components are one adder, two registers, and control logic.\n$$A_S = A_{\\text{add}} + 2 \\times A_{\\text{reg}} + A_{\\text{ctrl}}$$\n$$A_{\\text{add}} = c_{\\text{add}} \\times w_y = 2 \\times 16 = 32$$\n$$A_{\\text{reg}} = c_{\\text{reg}} \\times w_y = 0.5 \\times 16 = 8$$\n$$A_S = 32 + 2 \\times 8 + 64 = 32 + 16 + 64 = 112$$\nThe latency is $L_S = k = 10$ cycles. The area-latency product for Architecture S is:\n$$P_S = A_S \\times L_S = 112 \\times 10 = 1120$$\n\n**Part 5: Compute the Ratio R**\n\nThe final step is to compute the ratio of the area-latency products.\n$$R = \\frac{P_C}{P_S} = \\frac{1808}{1120}$$\n$$R = \\frac{180.8}{112} = \\frac{45.2}{28} = \\frac{11.3}{7} \\approx 1.6142857...$$\nRounding to four significant figures, we get $R = 1.614$.", "answer": "$$\\boxed{1.614}$$", "id": "3628129"}]}