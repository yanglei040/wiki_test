{"hands_on_practices": [{"introduction": "To truly grasp lazy evaluation, we must first understand its core mechanism: call-by-need. This practice contrasts call-by-need with its conceptual predecessor, call-by-name, to highlight the critical role of memoization. By tracing the evaluation of a simple expression [@problem_id:3649720], you will quantify the performance difference and build a solid intuition for why sharing results is fundamental to making lazy evaluation practical.", "problem": "Consider the untyped lambda calculus extended with integer literals and binary addition. Expressions are generated by the grammar: $e ::= n \\mid x \\mid \\lambda x.\\,e \\mid e\\ e \\mid e + e$, where $n$ ranges over integer literals and $x$ ranges over variables. Values are $v ::= n \\mid \\lambda x.\\,e$. Addition is strict in both operands and evaluates left-to-right. The small-step semantics for arithmetic are given by the following rules:\n- If $e_{1} \\to e_{1}'$ then $e_{1} + e_{2} \\to e_{1}' + e_{2}$.\n- If $e_{2} \\to e_{2}'$ and $e_{1}$ is a numeric value $n_{1}$, then $n_{1} + e_{2} \\to n_{1} + e_{2}'$.\n- If both operands are numeric values, then $n_{1} + n_{2} \\to n$ where $n$ is the integer sum of $n_{1}$ and $n_{2}$.\n\nTwo call strategies are considered:\n- Call-by-name (substitution-based): $(\\lambda x. M) N \\to M[x := N]$, with no prior evaluation of $N$.\n- Call-by-need (sharing via let-binding): $(\\lambda x. M) E \\to \\mathbf{let}\\ x = E\\ \\mathbf{in}\\ M$, and demand-driven forcing of $x$ evaluates $E$ at most once and updates the binding to the resulting value, after which all occurrences of $x$ use the memoized value.\n\nFix the closed argument expression $E \\equiv (1+1) + (1+1)$, which is not a value and reduces deterministically to the numeric value $4$ under the arithmetic rules above. Consider the program $(\\lambda x. x + x + x) E$, where the syntactic association of addition is left-associative, so $x + x + x$ means $(x + x) + x$.\n\nDefine “one evaluation of $x$” to mean a complete reduction of the bound argument expression $E$ to a numeric value in order to supply a demanded numeric operand at some occurrence of $x$ in the function body; that is, each time an occurrence of $x$ is forced to a numeric value under the small-step rules, it counts as one evaluation of $x$.\n\nUnder the call-by-name and call-by-need strategies described above, evaluate $(\\lambda x. x + x + x) E$ to a numeric value. Compute the number of evaluations of $x$ in the entire run under each strategy. Report your answer as a row matrix $\\begin{pmatrix} c_{\\text{name}} & c_{\\text{need}} \\end{pmatrix}$, where $c_{\\text{name}}$ is the count under call-by-name and $c_{\\text{need}}$ is the count under call-by-need. No rounding is necessary. Explain in your derivation how sharing arises under call-by-need and why it changes the count.", "solution": "The problem requires us to determine the number of times a specific argument expression, $E$, is evaluated when a lambda abstraction is applied to it, under two different evaluation strategies: call-by-name and call-by-need.\n\nThe program is given by $P \\equiv (\\lambda x. x + x + x) E$.\nThe argument expression is $E \\equiv (1+1) + (1+1)$.\nThe body of the lambda abstraction is $M \\equiv x + x + x$, which, due to left-associativity, is equivalent to $(x+x)+x$.\nThe `+` operator is strict, meaning it evaluates its operands before performing the addition. The evaluation order is left-to-right.\n\"One evaluation of $x$\" is defined as the complete reduction of the bound argument expression $E$ to a numeric value, which occurs when an occurrence of $x$ must yield a numeric value for an operation. The expression $E$ itself reduces to the value $4$:\n$E \\equiv (1+1)+(1+1) \\to 2+(1+1) \\to 2+2 \\to 4$.\n\nLet us analyze the evaluation under each strategy.\n\n### Call-by-Name Evaluation\n\nUnder call-by-name, the reduction rule for function application is $(\\lambda x. M) N \\to M[x := N]$. The unevaluated argument expression $N$ is substituted for every occurrence of the formal parameter $x$ in the function body $M$.\n\n$1$. The initial $\\beta$-reduction is:\n$$(\\lambda x. (x+x)+x) ( (1+1) + (1+1) ) \\to ( (x+x)+x )[x := (1+1)+(1+1) ]$$\nThis results in the expression:\n$$(( (1+1)+(1+1) ) + ( (1+1)+(1+1) )) + ( (1+1)+(1+1) )$$\nFor clarity, let's denote the unevaluated expression $(1+1)+(1+1)$ as $E$. The expression to evaluate is $(E + E) + E$.\n\n$2$. The evaluation of $(E+E)+E$ proceeds according to the strict, left-to-right semantics of addition.\nFirst, we must evaluate the left operand of the outermost `+`, which is the subexpression $(E+E)$.\nTo evaluate $(E+E)$, we must first evaluate its left operand, the first $E$. This is the first time a numeric operand is demanded.\n**First evaluation of $x$**: The first occurrence of $E$ is reduced to a value.\n$E \\equiv (1+1)+(1+1) \\to 2+(1+1) \\to 2+2 \\to 4$.\nThe expression becomes $(4 + E) + E$.\n\n$3$. Next, to evaluate the subexpression $(4+E)$, we must evaluate its right operand, the second $E$.\n**Second evaluation of $x$**: The second occurrence of $E$ is reduced to a value. This is a fresh copy of the expression from the substitution.\n$E \\equiv (1+1)+(1+1) \\to 2+(1+1) \\to 2+2 \\to 4$.\nThe expression becomes $(4 + 4) + E$.\n\n$4$. The inner addition can now be performed:\n$(4+4)+E \\to 8+E$.\n\n$5$. Finally, to evaluate $8+E$, we must evaluate its right operand, the third $E$.\n**Third evaluation of $x$**: The third occurrence of $E$ is reduced to a value.\n$E \\equiv (1+1)+(1+1) \\to 2+(1+1) \\to 2+2 \\to 4$.\nThe expression becomes $8+4$.\n\n$6$. The final addition occurs:\n$8+4 \\to 12$.\n\nIn this entire process, the argument expression $E$ was fully evaluated three times, once for each occurrence of $x$ in the function body. Therefore, the count of evaluations for call-by-name is $c_{\\text{name}} = 3$.\n\n### Call-by-Need Evaluation\n\nUnder call-by-need, the argument is not evaluated upon application. Instead, a \"thunk\" (a placeholder for the computation) is created. The evaluation of the argument expression is triggered only when its value is first required. The result is then memoized (cached), and all subsequent uses of the variable will use this cached value, avoiding re-computation.\n\n$1$. The initial reduction step transforms the application into a `let` binding:\n$$(\\lambda x. (x+x)+x) E \\to \\mathbf{let}\\ x = E\\ \\mathbf{in}\\ (x+x)+x$$\nHere, $x$ is bound to a thunk representing the unevaluated expression $E \\equiv (1+1)+(1+1)$.\n\n$2$. The evaluation of the body, $(x+x)+x$, begins. As with call-by-name, the evaluation of the outermost `+` requires the evaluation of its left operand, $(x+x)$.\nTo evaluate $(x+x)$, we must first evaluate its left operand, the first $x$. This is the first time the value of $x$ is demanded (or \"forced\").\n**First and only evaluation of $x$**: The thunk associated with $x$ is evaluated.\n$E \\equiv (1+1)+(1+1) \\to 2+(1+1) \\to 2+2 \\to 4$.\nThe result, $4$, is cached. The binding for $x$ is now updated to the value $4$. This counts as one evaluation.\nThe expression we are evaluating, $(x+x)$, becomes $(4+x)$ with the knowledge that $x$ is now $4$.\n\n$3$. To evaluate the subexpression $(4+x)$, we need the value of its right operand, the second $x$.\nWhen this second occurrence of $x$ is accessed, the call-by-need mechanism finds that the thunk has already been evaluated. It simply retrieves the memoized value, $4$, without re-computing $E$.\nThe expression becomes $(4+4)$.\n\n$4$. The inner addition is performed:\n$4+4 \\to 8$.\nThe overall expression becomes $8+x$.\n\n$5$. To evaluate $8+x$, we need the value of the third $x$.\nAgain, the memoized value $4$ is retrieved directly. No new evaluation of $E$ occurs.\nThe expression becomes $8+4$.\n\n$6$. The final addition is performed:\n$8+4 \\to 12$.\n\nIn this strategy, the expensive computation of $E$ was performed only once, upon the first demand for the value of $x$. All subsequent demands were satisfied by the cached result. This sharing is the core difference from call-by-name. The number of evaluations for call-by-need is $c_{\\text{need}} = 1$.\n\nThe final answer is the pair of counts $(c_{\\text{name}}, c_{\\text{need}})$.\n$c_{\\text{name}} = 3$\n$c_{\\text{need}} = 1$\nThis is represented as the row matrix $\\begin{pmatrix} 3 & 1 \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix} 3 & 1 \\end{pmatrix}}$$", "id": "3649720"}, {"introduction": "While call-by-need's memoization offers significant performance benefits, it introduces subtle complexities when interacting with side effects. This thought experiment [@problem_id:3649688] explores how sharing an effectful computation can break referential transparency, a cornerstone of functional reasoning. By analyzing this counterexample, you will understand why pure functional languages often enforce a strict separation between pure code and side effects, and you will get a glimpse into advanced language features that manage this complexity.", "problem": "Consider a call-by-need (lazy) implementation of a first-order expression language with integers, addition, and a single binding construct. Expressions are given by the grammar $e ::= n \\mid e_1 + e_2 \\mid \\mathbf{let}\\ x = e\\ \\mathbf{in}\\ e' \\mid \\mathsf{tick}()$, where $n \\in \\mathbb{Z}$ is an integer literal and $\\mathsf{tick}()$ is a primitive operation with an effect. The operational intent is:\n- In $\\mathbf{let}\\ x = e\\ \\mathbf{in}\\ e'$, the implementation allocates a thunk for $e$; when $x$ is demanded, the thunk is forced, its result memoized, and all subsequent demands of $x$ read the memoized result (this is call-by-need sharing).\n- The primitive $\\mathsf{tick}()$ appends a distinguished event $\\star$ to a global log $L$ and returns the integer $1$. The observable behavior of an expression is its resulting integer value together with the final log sequence $L$; two expressions are observationally equivalent if they yield the same value and the same log sequence for all initial logs.\n\nA language is referentially transparent if substitution of equals for equals preserves observable behavior in all contexts. A compiler optimization that introduces sharing (for example, common subexpression elimination that rewrites duplicated subexpressions into a single $\\mathbf{let}$-bound thunk) is semantics-preserving in a referentially transparent setting, but may be unsound in the presence of effects.\n\nUsing only the above definitions as the starting point, reason about the following candidate counterexample and remedies. Let $E_1 \\triangleq \\mathsf{tick}() + \\mathsf{tick}()$ and $E_2 \\triangleq \\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$.\n\nSelect all statements that are correct:\n\nA. In the pure sublanguage without $\\mathsf{tick}()$, $E_1$ and $E_2$ would be contextually equivalent. When $\\mathsf{tick}()$’s log is observable, call-by-need sharing causes $E_2$ to emit exactly $1$ tick while $E_1$ emits exactly $2$. Therefore, a compiler that naively rewrites $E_1$ into $E_2$ (or performs equivalent common subexpression elimination) is unsound unless effects are ruled out.\n\nB. Under call-by-need with sharing, evaluating $\\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$ forces the thunk for $x$ independently at each use, causing two ticks; sharing does not change the number of effects in this case.\n\nC. A sufficient constraint to make sharing semantics-preserving is to enforce purity for shared thunks: the bound expression $e$ in $\\mathbf{let}\\ x = e\\ \\mathbf{in}\\ e'$ must be effect-free. An effect system can enforce this by typing $\\mathsf{tick}$ as effectful (for example, with type $\\mathsf{IO}\\ \\mathbb{Z}$), and permitting sharing only for expressions of pure type (for example, of type $\\mathbb{Z}$), or by requiring explicit effect encapsulation.\n\nD. Because call-by-name (no sharing) does not memoize, the difference between $E_1$ and $E_2$ disappears, which implies that common subexpression elimination is safe regardless of effects under any non-strict strategy.\n\nE. Instead of forbidding effects, one can prevent duplication of effectful thunks using a linear or uniqueness type discipline. Under such a constraint, $\\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$ would be rejected because $x$ is used twice, thereby blocking the counterexample and making sharing safe without requiring global purity.", "solution": "### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Language Grammar**: Expressions are defined by $e ::= n \\mid e_1 + e_2 \\mid \\mathbf{let}\\ x = e\\ \\mathbf{in}\\ e' \\mid \\mathsf{tick}()$, where $n \\in \\mathbb{Z}$ is an integer literal.\n-   **Evaluation Strategy**: Call-by-need (lazy) implementation.\n-   **Semantics of $\\mathbf{let}$**: In $\\mathbf{let}\\ x = e\\ \\mathbf{in}\\ e'$, a thunk is allocated for $e$. When $x$ is first demanded, the thunk is forced, its result is memoized, and all subsequent demands for $x$ retrieve the memoized result. This is explicitly defined as call-by-need sharing.\n-   **Semantics of $\\mathsf{tick}()$**: The primitive operation $\\mathsf{tick}()$ appends a distinguished event $\\star$ to a global log $L$ and returns the integer value $1$.\n-   **Observable Behavior**: The outcome of an expression evaluation is the pair of its resulting integer value and the final state of the log sequence $L$.\n-   **Observational Equivalence**: Two expressions are deemed observationally equivalent if they produce the same integer value and the same final log sequence for all possible initial log states.\n-   **Referential Transparency (RT)**: RT holds if substituting an expression with an observationally equivalent one preserves the observable behavior of the enclosing program.\n-   **Optimization Context**: The problem considers common subexpression elimination (CSE), which may rewrite an expression with duplicated subexpressions into a form that uses a single `let`-bound thunk for the common part.\n-   **Candidate Expressions**:\n    -   $E_1 \\triangleq \\mathsf{tick}() + \\mathsf{tick}()$\n    -   $E_2 \\triangleq \\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is a standard theoretical exercise in the domain of programming language semantics and compiler theory. It precisely defines a simple functional language with effects, an evaluation strategy (call-by-need), and a notion of observable behavior. These definitions are internally consistent and grounded in established computer science principles. The question asks for a logical deduction about the properties of the system based on these definitions. The problem is well-posed, as the provided semantics are sufficient to uniquely determine the behavior of the expressions in question. It is objective and contains no scientific or factual unsoundness, non-formalizable concepts, or ambiguities.\n\n**Step 3: Verdict and Action**\nThe problem statement is **valid**. A solution can be derived from the provided definitions.\n\n### Derivation and Analysis\n\nWe first determine the observable behavior of expressions $E_1$ and $E_2$ according to the specified call-by-need semantics. Let the initial log be $L_0$.\n\n**Analysis of $E_1 \\triangleq \\mathsf{tick}() + \\mathsf{tick}()$**\nTo evaluate the sum, its operands must be evaluated. Assuming a standard left-to-right evaluation order for the arguments of the `$+$` operator:\n1.  The left operand, $\\mathsf{tick}()$, is evaluated. This appends $\\star$ to the log, so the log becomes $L_0 \\cdot \\langle\\star\\rangle$. The operation returns the value $1$.\n2.  The right operand, $\\mathsf{tick}()$, is evaluated. This appends another $\\star$ to the log, making it $L_0 \\cdot \\langle\\star, \\star\\rangle$. The operation returns the value $1$.\n3.  The addition $1 + 1$ is performed, yielding the final value $2$.\n\nThe observable behavior of $E_1$ is (value: $2$, final log: $L_0 \\cdot \\langle\\star, \\star\\rangle$). It adds exactly two events to the log.\n\n**Analysis of $E_2 \\triangleq \\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$**\nThe evaluation proceeds according to the call-by-need rules:\n1.  A thunk (a suspended computation) for the expression $\\mathsf{tick}()$ is created and bound to the variable $x$. No evaluation occurs at this stage, and the log remains $L_0$.\n2.  The body of the `let`-expression, $x + x$, is evaluated. This requires evaluating the operands of `$+$`.\n3.  The left operand, $x$, is demanded for the first time. The thunk bound to $x$ is forced (evaluated).\n4.  Evaluating the thunk's expression, $\\mathsf{tick}()$, appends $\\star$ to the log (log becomes $L_0 \\cdot \\langle\\star\\rangle$) and returns the value $1$.\n5.  Crucially, according to the call-by-need specification, this result ($1$) is **memoized**.\n6.  The right operand, $x$, is demanded. Since this is a subsequent demand, the implementation retrieves the memoized result, $1$, without re-evaluating the thunk. No new event is added to the log.\n7.  The addition $1 + 1$ is performed, yielding the final value $2$.\n\nThe observable behavior of $E_2$ is (value: $2$, final log: $L_0 \\cdot \\langle\\star\\rangle$). It adds exactly one event to the log.\n\n**Conclusion on Equivalence**\n$E_1$ and $E_2$ both evaluate to the integer $2$, but they produce different final logs. Therefore, they are not observationally equivalent.\n\n### Option-by-Option Analysis\n\n**A. In the pure sublanguage without $\\mathsf{tick}()$, $E_1$ and $E_2$ would be contextually equivalent. When $\\mathsf{tick}()$’s log is observable, call-by-need sharing causes $E_2$ to emit exactly $1$ tick while $E_1$ emits exactly $2$. Therefore, a compiler that naively rewrites $E_1$ into $E_2$ (or performs equivalent common subexpression elimination) is unsound unless effects are ruled out.**\n\n-   In a pure sublanguage (without $\\mathsf{tick}()$), let's consider an arbitrary pure expression $e_{pure}$ instead of $\\mathsf{tick}()$. The expressions would be $e_{pure} + e_{pure}$ and $\\mathbf{let}\\ x = e_{pure}\\ \\mathbf{in}\\ x + x$. In a pure setting, the only observable is the final value. Both expressions would compute the same value. The number of evaluations does not alter the observable behavior. Thus, they would be contextually equivalent.\n-   The second sentence states that $E_2$ emits one tick while $E_1$ emits two. Our derivation above confirms this is correct.\n-   The conclusion follows directly: since the transformation from an $E_1$-like expression to an $E_2$-like one changes the program's observable behavior, the transformation is unsound (i.e., not semantics-preserving). This is precisely the classic problem of combining sharing with side effects.\n-   **Verdict: Correct.**\n\n**B. Under call-by-need with sharing, evaluating $\\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$ forces the thunk for $x$ independently at each use, causing two ticks; sharing does not change the number of effects in this case.**\n\n-   This statement directly contradicts the problem's definition of call-by-need, which explicitly states that the result of forcing a thunk is \"memoized, and all subsequent demands of $x$ read the memoized result.\"\n-   The behavior described (forcing the thunk at each use) is characteristic of **call-by-name**, a non-strict strategy without memoization. Call-by-need is defined by its use of memoization (sharing) to avoid re-computation.\n-   Our analysis of $E_2$ showed that sharing is the very reason only one tick is produced.\n-   **Verdict: Incorrect.**\n\n**C. A sufficient constraint to make sharing semantics-preserving is to enforce purity for shared thunks: the bound expression $e$ in $\\mathbf{let}\\ x = e\\ \\mathbf{in}\\ e'$ must be effect-free. An effect system can enforce this by typing $\\mathsf{tick}$ as effectful (for example, with type $\\mathsf{IO}\\ \\mathbb{Z}$), and permitting sharing only for expressions of pure type (for example, of type $\\mathbb{Z}$), or by requiring explicit effect encapsulation.**\n\n-   The unsoundness arises because the shared expression $\\mathsf{tick}()$ has an observable side effect. If an expression $e$ is pure (effect-free), evaluating it multiple times is observationally indistinguishable from evaluating it once and reusing the result.\n-   Therefore, if the common subexpression elimination transformation is restricted to only pure expressions, it cannot change the observable behavior of the program.\n-   Using a type and effect system is a standard and robust method for enforcing such a purity distinction. An effectful computation like $\\mathsf{tick}()$ would be given a type that marks it as impure (e.g., $\\mathsf{IO}\\ \\mathbb{Z}$), while pure computations like integer arithmetic would have a pure type (e.g., $\\mathbb{Z}$). The compiler would then permit the sharing optimization only for expressions of a pure type. This is a sufficient condition to restore soundness.\n-   **Verdict: Correct.**\n\n**D. Because call-by-name (no sharing) does not memoize, the difference between $E_1$ and $E_2$ disappears, which implies that common subexpression elimination is safe regardless of effects under any non-strict strategy.**\n\n-   Let's analyze the premise under call-by-name (lazy evaluation without memoization).\n    -   $E_1 \\triangleq \\mathsf{tick}() + \\mathsf{tick}()$: Evaluation still requires evaluating both operands, resulting in two ticks and the value $2$.\n    -   $E_2 \\triangleq \\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$: This is equivalent to substituting the definition of $x$ at each use site, leading to the evaluation of $\\mathsf{tick}() + \\mathsf{tick}()$. This also results in two ticks and the value $2$.\n-   The premise is correct: under call-by-name, $E_1$ and $E_2$ are observationally equivalent.\n-   However, the implication is false. It claims that CSE is safe under *any* non-strict strategy. Call-by-need is also a non-strict strategy, and we have shown that under call-by-need, the transformation is *unsafe*. The safety under one non-strict strategy (call-by-name) does not imply safety under all of them.\n-   **Verdict: Incorrect.**\n\n**E. Instead of forbidding effects, one can prevent duplication of effectful thunks using a linear or uniqueness type discipline. Under such a constraint, $\\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$ would be rejected because $x$ is used twice, thereby blocking the counterexample and making sharing safe without requiring global purity.**\n\n-   This statement proposes an alternative solution based on linear types, where a variable must be used exactly once.\n-   In the expression $\\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x + x$, the variable $x$ is used twice in the body. If $x$ were given a linear type (which would be appropriate for an effectful, non-duplicable resource), a linear type checker would reject this program as ill-typed.\n-   The CSE optimization rewrites $E_1$ to $E_2$. If the target language incorporates a linear type system, this transformation could be guarded by the type checker. The compiler would be allowed to perform CSE only if the resulting `let`-expression is well-typed. In this case, the transformation from $\\mathsf{tick}() + \\mathsf{tick}()$ to $\\mathbf{let}\\ x = \\mathsf{tick}()\\ \\mathbf{in}\\ x+x$ would be disallowed because the latter violates linearity.\n-   This correctly blocks the unsound optimization without requiring that all shared expressions be pure. It controls how effectful bindings are *used* rather than forbidding them from being shared. This is a valid and well-established technique for managing effects safely.\n-   **Verdict: Correct.**", "answer": "$$\\boxed{ACE}$$", "id": "3649688"}, {"introduction": "Lazy evaluation allows for elegant, modular code, such as composing functions in a pipeline. However, this elegance can come at a hidden performance cost known as \"thunk explosion,\" where many intermediate lazy computations are created. This practice [@problem_id:3649726] asks you to model this phenomenon by analyzing the number of thunks allocated in a pipeline of `map` functions and to quantify the dramatic improvements gained from a key compiler optimization called fusion, or deforestation.", "problem": "Consider a pure, first-order functional language with call-by-need (lazy) evaluation. A thunk is a suspended computation that, once forced, memoizes its result so subsequent forces use the cached value. The higher-order function $\\mathrm{map}$ applies a function $f$ to each element of a list, yielding a new list of the same length. In a lazy runtime, constructing the result of $\\mathrm{map}$ typically allocates one thunk per produced element to delay each application $f(x)$ until that element is demanded.\n\nAssume a simplified, scientifically reasonable cost model, grounded in the core definitions of call-by-need and functional list processing:\n- Each application of $\\mathrm{map}\\ f$ to a list of demanded length $d$ allocates exactly $d$ thunks to delay the element-wise applications of $f$. Ignore costs for cons cells or function closures, and assume no sharing or partial evaluation removes these thunks.\n- A pipeline of $k$ successive $\\mathrm{map}$ calls, $\\mathrm{map}\\ f_k \\circ \\mathrm{map}\\ f_{k-1} \\circ \\cdots \\circ \\mathrm{map}\\ f_1$, on an input list of length $n$ (with $0 \\le d \\le n$ outputs demanded) allocates thunks stage-by-stage under non-fused execution.\n- Under a valid fusion (deforestation) transformation that composes the element-wise functions into a single function $h = f_k \\circ f_{k-1} \\circ \\cdots \\circ f_1$ and performs one traversal, the pipeline is replaced by $\\mathrm{map}\\ h$. In this fused execution, only one thunk per demanded output element is allocated when $k > 0$, and zero thunks when $k = 0$ (no $\\mathrm{map}$ calls at all).\n\nStarting from these definitions, derive expressions for the total number of thunk allocations under non-fused and fused execution. Let $T_{\\text{naive}}(n,k,d)$ be the total number of thunks allocated under non-fused execution, and $T_{\\text{fused}}(n,k,d)$ under fused execution. Your derivation should explicitly justify why these expressions follow from the call-by-need semantics and the behavior of $\\mathrm{map}$. Conclude with the asymptotic complexities in terms of $n$ (with $d \\le n$) and $k$.\n\nThen, implement a complete, runnable program that, given several test cases $(n,k,d)$, computes:\n- $T_{\\text{naive}}(n,k,d)$\n- $T_{\\text{fused}}(n,k,d)$\n- The difference $\\Delta(n,k,d) = T_{\\text{naive}}(n,k,d) - T_{\\text{fused}}(n,k,d)$\n\nTest Suite:\nUse the following parameter sets, which cover the happy path, boundary conditions, and significant edge cases. Assume $0 \\le d \\le n$ for all cases.\n1. $(n,k,d) = (0, 5, 0)$\n2. $(n,k,d) = (1, 3, 1)$\n3. $(n,k,d) = (10, 5, 10)$\n4. $(n,k,d) = (1024, 0, 100)$\n5. $(n,k,d) = (1000, 1, 500)$\n6. $(n,k,d) = (65536, 4, 4096)$\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces. For each test case, output the triple $[T_{\\text{naive}},T_{\\text{fused}},\\Delta]$ flattened into the single list in the order of the test cases. For example, the output must look like:\n$[T_{\\text{naive}}^{(1)},T_{\\text{fused}}^{(1)},\\Delta^{(1)},T_{\\text{naive}}^{(2)},T_{\\text{fused}}^{(2)},\\Delta^{(2)},\\ldots]$", "solution": "The problem requires the derivation of cost expressions for thunk allocation in a lazy functional language, both with and without map fusion, based on a simplified cost model. Subsequently, a program must be implemented to compute these costs for a given set of test cases.\n\nThe problem statement has been validated and is found to be scientifically grounded, well-posed, and objective. It is based on established principles of compiler theory and functional programming, specifically lazy evaluation and deforestation. The provided cost model, while a simplification, is explicitly defined and sufficient for a rigorous derivation. Therefore, we proceed with the solution.\n\nLet $n$ be the length of the input list, $k$ be the number of successive $\\mathrm{map}$ calls in a pipeline, and $d$ be the number of elements demanded from the final output list, with the constraint $0 \\le d \\le n$.\n\n### Derivation of $T_{\\text{naive}}(n,k,d)$ (Non-Fused Execution)\n\nIn a non-fused pipeline, the computation is structured as a sequence of nested applications: $\\mathrm{map}\\ f_k (\\mathrm{map}\\ f_{k-1} (\\cdots (\\mathrm{map}\\ f_1\\ \\text{input\\_list})\\cdots))$. This creates $k$ intermediate lists.\n\nThe evaluation model is call-by-need (lazy evaluation), meaning computations are only performed when their results are demanded. When $d$ elements are requested from the final list, this demand propagates backward through the pipeline.\n\n1.  **Stage $k$ (Final Stage)**: To produce $d$ elements of the final output, the consumer must force the first $d$ thunks of the list produced by $\\mathrm{map}\\ f_k$. According to the provided cost model, \"Each application of $\\mathrm{map}\\ f$ to a list of demanded length $d$ allocates exactly $d$ thunks\". Here, the demanded length from the output of $\\mathrm{map}\\ f_k$ is $d$. Therefore, this stage allocates $d$ thunks.\n\n2.  **Demand Propagation**: For $\\mathrm{map}\\ f_k$ to compute its first $d$ values, it must in turn demand the first $d$ elements from its input list, which is the output of the preceding stage, $\\mathrm{map}\\ f_{k-1}$.\n\n3.  **Stage $k-1$**: This stage, $\\mathrm{map}\\ f_{k-1}$, now receives a demand for $d$ of its elements. Applying the same cost model rule, this application of $\\mathrm{map}$ allocates $d$ thunks to represent its $d$ demanded outputs.\n\n4.  **General Stage $i$**: This logic repeats for every stage in the pipeline. Each stage $\\mathrm{map}\\ f_i$ (for $i \\in \\{1, \\dots, k\\}$) must produce $d$ elements to satisfy the demand from stage $i+1$ (or the final consumer, for $i=k$). Consequently, each of the $k$ stages allocates $d$ thunks.\n\nThe total number of thunks allocated, $T_{\\text{naive}}(n,k,d)$, is the sum of the thunks allocated at each of the $k$ stages.\n$$T_{\\text{naive}}(n,k,d) = \\sum_{i=1}^{k} d = kd$$\nNote that the initial list length $n$ is irrelevant to the allocation count, provided $d \\le n$, as lazy evaluation ensures only the demanded portions of the lists are ever processed. If $d=0$ or $k=0$, the formula correctly yields $0$ thunks.\n\n### Derivation of $T_{\\text{fused}}(n,k,d)$ (Fused Execution)\n\nMap fusion, or deforestation, is an optimization that transforms the pipeline of $k$ maps into a single `map` operation. The composed function $h = f_k \\circ f_{k-1} \\circ \\cdots \\circ f_1$ is applied to the input list in one pass. The computation becomes $\\mathrm{map}\\ h\\ \\text{input\\_list}$. The intermediate lists and their associated thunks are eliminated.\n\nThe cost model for fused execution is explicitly defined:\n-   If $k > 0$, there is a single effective $\\mathrm{map}\\ h$ operation. The rule states: \"one thunk per demanded output element is allocated\". Since $d$ elements are demanded, $d$ thunks are allocated.\n-   If $k = 0$, there are no $\\mathrm{map}$ calls. The rule states: \"zero thunks when $k=0$\".\n\nThis leads to the following piecewise definition for $T_{\\text{fused}}(n,k,d)$:\n$$\nT_{\\text{fused}}(n,k,d) = \\begin{cases} d & \\text{if } k > 0 \\\\ 0 & \\text{if } k = 0 \\end{cases}\n$$\n\n### Derivation of the Difference $\\Delta(n,k,d)$\n\nThe difference $\\Delta(n,k,d)$ represents the total number of thunks saved by fusion. It is calculated as $\\Delta(n,k,d) = T_{\\text{naive}}(n,k,d) - T_{\\text{fused}}(n,k,d)$.\n\n-   If $k > 0$:\n    $$\\Delta(n,k,d) = (kd) - d = (k-1)d$$\n-   If $k = 0$:\n    $$\\Delta(n,k,d) = (0 \\cdot d) - 0 = 0$$\nThis correctly shows that fusion provides no benefit for $k=0$ or $k=1$ (as the \"pipeline\" has at most one stage), but for $k \\ge 2$, it saves $(k-1)d$ thunk allocations.\n\n### Asymptotic Complexity\n\nThe complexities are analyzed in terms of the parameters $n$, $k$, and $d$.\n\n-   **Non-Fused Execution**: $T_{\\text{naive}}(n,k,d) = kd$. The complexity is directly proportional to both $k$ and $d$. Thus, the complexity is $O(kd)$.\n-   **Fused Execution**: $T_{\\text{fused}}(n,k,d)$ is either $d$ or $0$. The complexity is independent of $k$ (for $k>0$) and proportional to $d$. Thus, the complexity is $O(d)$.\n\n### Summary of Formulas\n-   Non-fused thunk allocations: $T_{\\text{naive}}(n,k,d) = kd$\n-   Fused thunk allocations: $T_{\\text{fused}}(n,k,d) = d$ if $k>0$, and $0$ if $k=0$.\n-   Thunks saved by fusion: $\\Delta(n,k,d) = (k-1)d$ if $k>0$, and $0$ if $k=0$.", "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n// #include <math.h>\n// #include <complex.h>\n// #include <threads.h>\n// #include <stdatomic.h>\n\n/**\n * @struct TestCase\n * @brief Holds the parameters (n, k, d) for a single test case.\n * @var n The total length of the initial list.\n * @var k The number of map functions in the pipeline.\n * @var d The number of demanded elements from the final list.\n */\ntypedef struct {\n    long long n;\n    long long k;\n    long long d;\n} TestCase;\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {0, 5, 0},\n        {1, 3, 1},\n        {10, 5, 10},\n        {1024, 0, 100},\n        {1000, 1, 500},\n        {65536, 4, 4096}\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    \n    // An array to hold all results for final printing:\n    // For each case, we store T_naive, T_fused, and Delta.\n    long long all_results[num_cases * 3];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i < num_cases; ++i) {\n        long long n = test_cases[i].n;\n        long long k = test_cases[i].k;\n        long long d = test_cases[i].d;\n\n        // Calculate T_naive(n, k, d) = k * d\n        long long t_naive = k * d;\n\n        // Calculate T_fused(n, k, d) = d if k > 0, else 0\n        long long t_fused = (k > 0) ? d : 0;\n\n        // Calculate the difference Delta = t_naive - t_fused\n        long long delta = t_naive - t_fused;\n\n        // Store the results for this test case.\n        all_results[i * 3 + 0] = t_naive;\n        all_results[i * 3 + 1] = t_fused;\n        all_results[i * 3 + 2] = delta;\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    // The format is a single line: [res1,res2,res3,...] with no spaces.\n    printf(\"[\");\n    for (int i = 0; i < num_cases * 3; ++i) {\n        printf(\"%lld\", all_results[i]);\n        if (i < (num_cases * 3 - 1)) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3649726"}]}