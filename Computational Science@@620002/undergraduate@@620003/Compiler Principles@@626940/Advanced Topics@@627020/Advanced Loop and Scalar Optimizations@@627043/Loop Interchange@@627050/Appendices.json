{"hands_on_practices": [{"introduction": "Before a compiler can reorder operations, it must prove that the transformation does not change the program's final result. This is the fundamental principle of semantic preservation. This first exercise challenges you to apply this principle by analyzing a loop nest for data dependencies—flow, anti, and output—and using direction vectors to rigorously determine if a loop interchange is legal [@problem_id:3652959]. Mastering this analysis is the essential first step in understanding any loop optimization.", "problem": "You are analyzing a perfectly nested two-level loop in a compiler that targets Random Access Memory (RAM) with a row-major array layout. The program operates on a two-dimensional array $A$ of size $N \\times N$ where $N \\geq 3$, and the array $A$ is initialized before the loop nest. The loop indices iterate over the following finite, convex iteration space:\n- For the outer loop, $i$ ranges from $1$ to $N-1$.\n- For the inner loop, $j$ ranges from $1$ to $N-1$.\n\nThe loop body performs two writes and one read of $A$ as follows:\n- A write to $A[i][j]$,\n- A write to $A[i][j+1]$,\n- A read from $A[i+1][j]$.\n\nAssume there is no aliasing and no intervening function calls that modify $A$. The semantic meaning of the program depends only on the relative order of memory operations to $A$.\n\nTask: Using the foundational definitions of data dependences (flow, anti, and output) and direction/distance vectors for nested loops, treat the original execution order as lexicographic with $i$ outer and $j$ inner, written as $(i,j)$. Consider interchanging the loops to $(j,i)$ and determine whether semantics are preserved by examining the permuted direction vectors. A loop interchange is legal if and only if, for every dependence direction vector, the first non-equal component after applying the permutation does not indicate that the sink precedes the source (i.e., the leftmost non-equal direction after permutation is not a “$$”).\n\nDefine the legality indicator $L$ by\n$$\nL =\n\\begin{cases}\n1,  \\text{if the interchange from } (i,j) \\text{ to } (j,i) \\text{ preserves semantics},\\\\\n0,  \\text{otherwise.}\n\\end{cases}\n$$\n\nCompute $L$ for this loop nest using only direction/distance vector reasoning as the fundamental base. The answer must be a single real number equal to $0$ or $1$. No renaming transformations (such as value splitting or temporary creation) are allowed. You do not need to provide any rounding, and no physical units apply.", "solution": "The problem requires us to determine the legality of interchanging a perfectly nested two-level loop. The legality is denoted by an indicator variable $L$, where $L=1$ for a legal interchange and $L=0$ otherwise. The legality analysis must be based on data dependence relations formalized using direction vectors.\n\nFirst, let us establish the framework for our analysis. The execution of the loop nest defines a lexicographical order on the set of iteration vectors $(i,j)$. An iteration $(i_1, j_1)$ is executed before an iteration $(i_2, j_2)$, denoted as $(i_1, j_1) \\prec (i_2, j_2)$, if $i_1  i_2$ or ($i_1 = i_2$ and $j_1  j_2$).\n\nA data dependence exists from an operation in iteration $\\vec{I}_1 = (i_1, j_1)$ to an operation in iteration $\\vec{I}_2 = (i_2, j_2)$ if:\n1. Both operations access the same memory location.\n2. At least one of the operations is a write.\n3. The execution order is $\\vec{I}_1 \\prec \\vec{I}_2$.\n\nThe loop body contains three memory operations on a two-dimensional array $A$ of size $N \\times N$:\n- $S_1$: A write to $A[i][j]$.\n- $S_2$: A write to $A[i][j+1]$.\n- $S_3$: A read from $A[i+1][j]$.\n\nThe iteration space is defined by $1 \\le i \\le N-1$ and $1 \\le j \\le N-1$.\n\nA dependence is characterized by a distance vector $\\vec{d} = \\vec{I}_2 - \\vec{I}_1 = (i_2-i_1, j_2-j_1) = (d_i, d_j)$ and a direction vector $\\vec{v} = (\\text{sgn}(d_i), \\text{sgn}(d_j))$, where $\\text{sgn}$ is the signum function. For a dependence to be carried by the loops, the distance vector must be lexicographically positive, i.e., $\\vec{d} \\succ (0,0)$.\n\nWe analyze all possible pairs of operations between two distinct iterations $\\vec{I}_1$ and $\\vec{I}_2$ (where $\\vec{I}_1 \\prec \\vec{I}_2$) to find all loop-carried dependencies.\n\n1.  **Flow dependence (Read-After-Write, RAW):** from a write at $\\vec{I}_1$ to a read at $\\vec{I}_2$.\n    - $S_1(\\vec{I}_1) \\to S_3(\\vec{I}_2)$: `write A[i_1][j_1]` to `read A[i_2+1][j_2]`.\n      For a memory collision, we need $i_1 = i_2+1$ and $j_1 = j_2$. This gives a distance vector $d_i = i_2 - i_1 = -1$. Since $d_i  0$, $\\vec{I}_1$ would execute after $\\vec{I}_2$, which violates the dependence condition $\\vec{I}_1 \\prec \\vec{I}_2$. Thus, no dependence exists.\n    - $S_2(\\vec{I}_1) \\to S_3(\\vec{I}_2)$: `write A[i_1][j_1+1]` to `read A[i_2+1][j_2]`.\n      For a collision, $i_1 = i_2+1$ and $j_1+1 = j_2$. This gives $d_i = i_2 - i_1 = -1$, again violating $\\vec{I}_1 \\prec \\vec{I}_2$. No dependence exists.\n\n2.  **Anti-dependence (Write-After-Read, WAR):** from a read at $\\vec{I}_1$ to a write at $\\vec{I}_2$.\n    - $S_3(\\vec{I}_1) \\to S_1(\\vec{I}_2)$: `read A[i_1+1][j_1]` to `write A[i_2][j_2]`.\n      For a collision, $i_1+1 = i_2$ and $j_1 = j_2$.\n      The distance vector is $\\vec{d} = (i_2-i_1, j_2-j_1) = (1, 0)$.\n      The condition $\\vec{I}_1 \\prec \\vec{I}_2$ is met since $i_2 = i_1+1  i_1$.\n      This dependence exists if there are valid iteration vectors. For $N \\ge 3$, we can choose $i_1=1, j_1=1$, which gives $\\vec{I}_1 = (1,1)$ and $\\vec{I}_2 = (2,1)$. Both are in the iteration space.\n      The direction vector is $\\vec{v}_1 = (\\text{sgn}(1), \\text{sgn}(0)) = (+, =)$.\n\n    - $S_3(\\vec{I}_1) \\to S_2(\\vec{I}_2)$: `read A[i_1+1][j_1]` to `write A[i_2][j_2+1]`.\n      For a collision, $i_1+1 = i_2$ and $j_1 = j_2+1$.\n      The distance vector is $\\vec{d} = (i_2-i_1, j_2-j_1) = (1, -1)$.\n      The condition $\\vec{I}_1 \\prec \\vec{I}_2$ is met since $i_2 = i_1+1  i_1$.\n      This dependence exists if there are valid iteration vectors. We need $1 \\le i_1 \\le N-2$ and $2 \\le j_1 \\le N-1$. For $N \\ge 3$, we can choose $i_1=1, j_1=2$, giving $\\vec{I}_1=(1,2)$ and $\\vec{I}_2=(2,1)$. Both are valid iterations.\n      The direction vector is $\\vec{v}_2 = (\\text{sgn}(1), \\text{sgn}(-1)) = (+, -)$.\n\n3.  **Output dependence (Write-After-Write, WAW):** from a write at $\\vec{I}_1$ to a write at $\\vec{I}_2$.\n    - $S_1(\\vec{I}_1) \\to S_1(\\vec{I}_2)$: `write A[i_1][j_1]` to `write A[i_2][j_2]`. Collision implies $\\vec{I}_1 = \\vec{I}_2$, so no loop-carried dependence.\n    - $S_2(\\vec{I}_1) \\to S_2(\\vec{I}_2)$: `write A[i_1][j_1+1]` to `write A[i_2][j_2+1]`. Collision implies $\\vec{I}_1 = \\vec{I}_2$, so no loop-carried dependence.\n    - $S_1(\\vec{I}_1) \\to S_2(\\vec{I}_2)$: `write A[i_1][j_1]` to `write A[i_2][j_2+1]`.\n      For a collision, $i_1=i_2$ and $j_1=j_2+1$. This gives $d_j = j_2 - j_1 = -1$. Since $d_i=0$, this would require $j_1  j_2$ for a valid dependence, which is contradicted by $j_1  j_2$. No dependence.\n    - $S_2(\\vec{I}_1) \\to S_1(\\vec{I}_2)$: `write A[i_1][j_1+1]` to `write A[i_2][j_2]`.\n      For a collision, $i_1=i_2$ and $j_1+1=j_2$.\n      The distance vector is $\\vec{d} = (i_2-i_1, j_2-j_1) = (0, 1)$.\n      The condition $\\vec{I}_1 \\prec \\vec{I}_2$ is met since $i_1=i_2$ and $j_2 = j_1+1  j_1$.\n      This dependence is valid. For $N \\ge 3$, choose $i_1=1, j_1=1$, giving $\\vec{I}_1=(1,1)$ and $\\vec{I}_2=(1,2)$.\n      The direction vector is $\\vec{v}_3 = (\\text{sgn}(0), \\text{sgn}(1)) = (=, +)$.\n\nThe loop-carried dependencies are summarized by their direction vectors:\n- $\\vec{v}_1 = (+, =)$\n- $\\vec{v}_2 = (+, -)$\n- $\\vec{v}_3 = (=, +)$\n\nAccording to the problem statement, a loop interchange from $(i,j)$ to $(j,i)$ is legal if and only if for every dependence direction vector $\\vec{v} = (v_i, v_j)$, the permuted vector $\\vec{v}' = (v_j, v_i)$ is lexicographically non-negative. A vector is lexicographically negative if its first non-zero component is negative ('-'). This means the transformation is illegal if any permuted direction vector is lexicographically negative.\n\nLet's test our direction vectors:\n1.  For $\\vec{v}_1 = (+, =)$, the permuted vector is $\\vec{v}'_1 = (=, +)$. This is lexicographically positive. This dependence does not prevent interchange.\n2.  For $\\vec{v}_2 = (+, -)$, the permuted vector is $\\vec{v}'_2 = (-, +)$. The first component is negative ('-'). This vector is lexicographically negative. The existence of this dependence makes the loop interchange illegal.\n3.  For $\\vec{v}_3 = (=, +)$, the permuted vector is $\\vec{v}'_3 = (+, =)$. This is lexicographically positive. This dependence does not prevent interchange.\n\nThe presence of the anti-dependence with direction vector $\\vec{v}_2 = (+, -)$ makes the loop interchange from $(i,j)$ to $(j,i)$ illegal. This dependence reverses upon interchange, meaning an operation that was supposed to happen before another would happen after it, violating the program's semantics. For example, the anti-dependence from $\\vec{I}_1=(1,2)$ to $\\vec{I}_2=(2,1)$ ensures that `read A[2][2]` at iteration $(1,2)$ occurs before `write A[2][2]` at iteration $(2,1)$. After interchange, the iteration vectors are $(j,i)$. The read occurs at $(2,1)$ and the write occurs at $(1,2)$. Since $(1,2) \\prec (2,1)$, the write would be executed before the read, which is incorrect.\n\nSince the loop interchange is illegal, the legality indicator $L$ is $0$.", "answer": "$$\\boxed{0}$$", "id": "3652959"}, {"introduction": "A legal transformation is not always a beneficial one. The primary motivation for loop interchange is to improve performance, most often by improving data locality and making better use of the memory hierarchy. This practice moves beyond simple legality to explore the *why* of loop interchange, asking you to construct a quantitative cost model that evaluates the cache performance of a program before and after the transformation [@problem_id:3652895]. By modeling the trade-offs, you will gain a deeper intuition for when this optimization is truly effective.", "problem": "Consider two dense, rectangular, two-dimensional arrays stored in row-major order: an array $A$ of shape $N \\times M$ and an array $B$ of shape $M \\times N$, where $N$ and $M$ are positive integers with $N \\geq 1$ and $M \\geq 1$. In row-major layout, the element $A[i][j]$ resides at address offset $i \\cdot M + j$ from the base of $A$, and $B[j][i]$ resides at address offset $j \\cdot N + i$ from the base of $B$. Consider the nested iteration space $\\{(i,j) \\mid 0 \\leq i \\leq N-1,\\ 0 \\leq j \\leq M-1\\}$ that performs a transpose-like computation: for each $(i,j)$, read $A[i][j]$ and write that value to $B[j][i]$. Loop interchange exchanges the order of iterating $i$ and $j$.\n\nUse the following fundamental base for locality and cost modeling:\n- In row-major order, the dimension associated with the rightmost index is contiguous in memory. Thus, with $i$ outer and $j$ inner, the access to $A[i][j]$ is stride-$1$ in memory (contiguous) while the access to $B[j][i]$ is a stride-$k$ stream with $k = N$. With $j$ outer and $i$ inner (interchanged), the access to $B[j][i]$ becomes stride-$1$ while the access to $A[i][j]$ becomes a stride-$k'$ stream with $k' = M$.\n- A cache line holds $L$ elements (assume $L \\geq 1$ is an integer), and the arrays are sufficiently large that there is no temporal reuse of a cache line once it is evicted; ignore capacity and conflict effects beyond spatial reuse within a line.\n- For reads, a cache hit costs $h_r$ cycles and a cache miss costs $c_r$ cycles, with $c_r \\geq h_r \\geq 0$.\n- For writes, assume a write-allocate, write-back policy: the first write to a cache line that is not present incurs an allocate-and-eventual-write-back cost of $c_{wa}$ cycles; subsequent writes to that same resident line hit at cost $h_w$ cycles, with $c_{wa} \\geq h_w \\geq 0$.\n- For a stride-$1$ stream, there is one miss per $L$ elements, followed by $L-1$ hits. For a stride-$s$ stream with $s \\geq L$, assume every access maps to a different cache line and thus misses.\n\nProvide a concrete example of the two loop orders by identifying which array has stride-$1$ and which has stride-$k$ in each order, and then construct a cost model as follows. Let $C_{\\text{orig}}$ denote the total expected execution cost (in cycles) when $i$ is the outer loop and $j$ is the inner loop, and let $C_{\\text{int}}$ denote the total expected execution cost (in cycles) when $j$ is the outer loop and $i$ is the inner loop (the interchanged order). Under the assumptions above, and further assuming $k = N \\geq L$ and $k' = M \\geq L$, derive a single, fully simplified, closed-form analytic expression for the difference\n$$\\Delta C \\triangleq C_{\\text{int}} - C_{\\text{orig}}$$\nas a function of $N$, $M$, $L$, $c_r$, $h_r$, $c_{wa}$, and $h_w$. Your final answer must be a single analytical expression. If you introduce any auxiliary quantities, they must be algebraically eliminated so that the final expression depends only on $N$, $M$, $L$, $c_r$, $h_r$, $c_{wa}$, and $h_w$. Express the final cost difference in cycles. No rounding is required.", "solution": "The problem will be validated by first extracting all givens, then assessing their scientific soundness, completeness, and objectivity.\n\n### Step 1: Extract Givens\n- **Arrays and Storage**:\n  - Array $A$: dense, rectangular, two-dimensional, shape $N \\times M$.\n  - Array $B$: dense, rectangular, two-dimensional, shape $M \\times N$.\n  - Both arrays stored in row-major order.\n  - $N$ and $M$ are positive integers with $N \\geq 1$ and $M \\geq 1$.\n- **Address Offsets**:\n  - $A[i][j]$ is at address offset $i \\cdot M + j$.\n  - $B[j][i]$ is at address offset $j \\cdot N + i$.\n- **Computation**:\n  - Iteration space: $\\{(i,j) \\mid 0 \\leq i \\leq N-1,\\ 0 \\leq j \\leq M-1\\}$.\n  - Operation: For each $(i,j)$, an element is read from $A[i][j]$ and written to $B[j][i]$.\n- **Loop Orders**:\n  - Original order ($C_{\\text{orig}}$): $i$ is the outer loop, $j$ is the inner loop.\n  - Interchanged order ($C_{\\text{int}}$): $j$ is the outer loop, $i$ is the inner loop.\n- **Locality and Stride**:\n  - Original order: Access to $A[i][j]$ is stride-$1$. Access to $B[j][i]$ is stride-$k$ with $k=N$.\n  - Interchanged order: Access to $B[j][i]$ is stride-$1$. Access to $A[i][j]$ is stride-$k'$ with $k'=M$.\n- **Cache and Cost Model**:\n  - Cache line size: $L$ elements, $L \\geq 1$ is an integer.\n  - Temporal reuse: Assumed to be none for cache lines evicted between outer loop iterations.\n  - Read costs: a cache hit costs $h_r$ cycles; a cache miss costs $c_r$ cycles, with $c_r \\geq h_r \\geq 0$.\n  - Write policy: Write-allocate, write-back.\n  - Write costs: A miss (allocate-and-write-back) costs $c_{wa}$ cycles; a hit costs $h_w$ cycles, with $c_{wa} \\geq h_w \\geq 0$.\n- **Stream Access Cost Assumptions**:\n  - Stride-$1$ stream: one miss per $L$ elements, followed by $L-1$ hits.\n  - Stride-$s$ stream with $s \\geq L$: every access is a miss.\n- **Specific Assumptions for Derivation**:\n  - $k = N \\geq L$.\n  - $k' = M \\geq L$.\n- **Objective**:\n  - Derive a single, fully simplified, closed-form analytic expression for $\\Delta C \\triangleq C_{\\text{int}} - C_{\\text{orig}}$ as a function of $N, M, L, c_r, h_r, c_{wa}, h_w$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined and scientifically sound.\n- **Scientifically Grounded**: The problem is based on fundamental concepts in computer architecture (cache memory, memory layout) and compiler optimizations (loop interchange). The cost model is a standard, simplified abstraction used for performance analysis. The address calculations for row-major order are correct.\n- **Well-Posed**: All necessary constants, variables, and functional relationships are provided to construct a deterministic cost model. The objective is clearly stated, and a unique solution can be derived from the given premises.\n- **Objective**: The problem is stated in precise, technical language, free from subjectivity or ambiguity.\n- **Completeness and Consistency**: The problem is self-contained. The constraints $N \\geq L$ and $M \\geq L$ are specified for the part of the model where they are relevant (high-stride access). There are no contradictions in the provided information.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived as requested.\n\n### Solution Derivation\nThe total cost of computation is the sum of the costs of all memory accesses. There are $N \\cdot M$ iterations, each involving one read from array $A$ and one write to array $B$. The total number of memory accesses is $2 \\cdot N \\cdot M$.\n\nFirst, we identify the access patterns for each loop order as described.\n- **Original loop order**: `for i from 0 to N-1 { for j from 0 to M-1 { B[j][i] = A[i][j]; } }`. The inner loop on $j$ accesses $A[i][0], A[i][1], \\dots, A[i][M-1]$ and $B[0][i], B[1][i], \\dots, B[M-1][i]$. As given, access to $A$ is stride-$1$ and access to $B$ is stride-$N$.\n- **Interchanged loop order**: `for j from 0 to M-1 { for i from 0 to N-1 { B[j][i] = A[i][j]; } }`. The inner loop on $i$ accesses $A[0][j], A[1][j], \\dots, A[N-1][j]$ and $B[j][0], B[j][1], \\dots, B[j][N-1]$. As given, access to $A$ is stride-$M$ and access to $B$ is stride-$1$.\n\nWe now construct the cost models for $C_{\\text{orig}}$ and $C_{\\text{int}}$.\n\n**Cost of the Original Loop Order ($C_{\\text{orig}}$)**\n\n1.  **Read cost from A ($C_{A, \\text{orig}}^{\\text{read}}$)**: The access pattern for $A$ is stride-$1$. According to the model, for every $L$ elements accessed, there is $1$ miss and $L-1$ hits. The total number of elements read is $N \\cdot M$.\n    - Number of misses = $\\frac{N \\cdot M}{L}$.\n    - Number of hits = $N \\cdot M \\cdot (1 - \\frac{1}{L}) = N \\cdot M \\cdot \\frac{L-1}{L}$.\n    - Total read cost: $C_{A, \\text{orig}}^{\\text{read}} = \\left(\\frac{N \\cdot M}{L}\\right) c_r + \\left(N \\cdot M \\cdot \\frac{L-1}{L}\\right) h_r$.\n    - Simplifying: $C_{A, \\text{orig}}^{\\text{read}} = \\frac{N \\cdot M}{L} (c_r + (L-1)h_r) = N \\cdot M \\left( h_r + \\frac{c_r - h_r}{L} \\right)$.\n\n2.  **Write cost to B ($C_{B, \\text{orig}}^{\\text{write}}$)**: The access pattern for $B$ is stride-$N$. We are given the assumption that $N \\geq L$. Therefore, every access to $B$ is a cache miss. Under the write-allocate policy, each miss incurs a cost of $c_{wa}$.\n    - Total write cost: $C_{B, \\text{orig}}^{\\text{write}} = (N \\cdot M) \\cdot c_{wa}$.\n\n3.  **Total original cost ($C_{\\text{orig}}$)**:\n    $$C_{\\text{orig}} = C_{A, \\text{orig}}^{\\text{read}} + C_{B, \\text{orig}}^{\\text{write}} = N \\cdot M \\left( h_r + \\frac{c_r - h_r}{L} \\right) + N \\cdot M \\cdot c_{wa}$$\n    $$C_{\\text{orig}} = N \\cdot M \\left( h_r + c_{wa} + \\frac{c_r - h_r}{L} \\right)$$\n\n**Cost of the Interchanged Loop Order ($C_{\\text{int}}$)**\n\n1.  **Read cost from A ($C_{A, \\text{int}}^{\\text{read}}$)**: The access pattern for $A$ is stride-$M$. We are given the assumption that $M \\geq L$. Therefore, every access to $A$ is a cache miss.\n    - Total read cost: $C_{A, \\text{int}}^{\\text{read}} = (N \\cdot M) \\cdot c_r$.\n\n2.  **Write cost to B ($C_{B, \\text{int}}^{\\text{write}}$)**: The access pattern for $B$ is stride-$1$. This is analogous to the read case for the original loop order, but with write costs. For every $L$ elements written, there is $1$ write miss (costing $c_{wa}$) and $L-1$ write hits (costing $h_w$).\n    - Number of misses = $\\frac{N \\cdot M}{L}$.\n    - Number of hits = $N \\cdot M \\cdot \\frac{L-1}{L}$.\n    - Total write cost: $C_{B, \\text{int}}^{\\text{write}} = \\left(\\frac{N \\cdot M}{L}\\right) c_{wa} + \\left(N \\cdot M \\cdot \\frac{L-1}{L}\\right) h_w$.\n    - Simplifying: $C_{B, \\text{int}}^{\\text{write}} = \\frac{N \\cdot M}{L} (c_{wa} + (L-1)h_w) = N \\cdot M \\left( h_w + \\frac{c_{wa} - h_w}{L} \\right)$.\n\n3.  **Total interchanged cost ($C_{\\text{int}}$)**:\n    $$C_{\\text{int}} = C_{A, \\text{int}}^{\\text{read}} + C_{B, \\text{int}}^{\\text{write}} = N \\cdot M \\cdot c_r + N \\cdot M \\left( h_w + \\frac{c_{wa} - h_w}{L} \\right)$$\n    $$C_{\\text{int}} = N \\cdot M \\left( c_r + h_w + \\frac{c_{wa} - h_w}{L} \\right)$$\n\n**Derivation of the Cost Difference ($\\Delta C$)**\n\nNow, we compute the difference $\\Delta C = C_{\\text{int}} - C_{\\text{orig}}$.\n$$\\Delta C = N \\cdot M \\left( c_r + h_w + \\frac{c_{wa} - h_w}{L} \\right) - N \\cdot M \\left( h_r + c_{wa} + \\frac{c_r - h_r}{L} \\right)$$\nFactor out the common term $N \\cdot M$:\n$$\\frac{\\Delta C}{N \\cdot M} = \\left( c_r + h_w + \\frac{c_{wa}}{L} - \\frac{h_w}{L} \\right) - \\left( h_r + c_{wa} + \\frac{c_r}{L} - \\frac{h_r}{L} \\right)$$\nGroup terms by the cost parameters:\n$$\\frac{\\Delta C}{N \\cdot M} = (c_r - \\frac{c_r}{L}) - (h_r - \\frac{h_r}{L}) - (c_{wa} - \\frac{c_{wa}}{L}) + (h_w - \\frac{h_w}{L})$$\n$$\\frac{\\Delta C}{N \\cdot M} = c_r\\left(1 - \\frac{1}{L}\\right) - h_r\\left(1 - \\frac{1}{L}\\right) - c_{wa}\\left(1 - \\frac{1}{L}\\right) + h_w\\left(1 - \\frac{1}{L}\\right)$$\nFactor out the common term $\\left(1 - \\frac{1}{L}\\right)$:\n$$\\frac{\\Delta C}{N \\cdot M} = \\left(1 - \\frac{1}{L}\\right) (c_r - h_r - c_{wa} + h_w)$$\n$$\\frac{\\Delta C}{N \\cdot M} = \\frac{L-1}{L} (c_r - h_r + h_w - c_{wa})$$\nFinally, multiplying by $N \\cdot M$ yields the fully simplified expression for $\\Delta C$:\n$$\\Delta C = N \\cdot M \\cdot \\frac{L-1}{L} (c_r - h_r + h_w - c_{wa})$$\nThis expression is a function of only the specified variables $N, M, L, c_r, h_r, c_{wa}$, and $h_w$, as required.", "answer": "$$\\boxed{N \\cdot M \\cdot \\frac{L-1}{L} (c_r - h_r + h_w - c_{wa})}$$", "id": "3652895"}, {"introduction": "While direction vectors provide an intuitive way to reason about dependencies, modern optimizing compilers rely on more powerful and systematic frameworks. This final exercise introduces you to the polyhedral model, an algebraic approach that represents loop nests as geometric domains and transformations as affine schedules [@problem_id:3652925]. You will formalize the loop interchange as a new schedule and verify its legality using the mathematical machinery of the model, seeing how these optimizations are automated in practice.", "problem": "Consider the following two-dimensional loop nest that forms a Static Control Part (SCoP) in the polyhedral model:\nfor $i = 2$ to $N$ do\n  for $j = 2$ to $M$ do\n    $S(i,j):\\quad A[i][j] = 3 \\cdot A[i][j-1] - 2 \\cdot A[i-1][j] + B[i-1][j-1]$\nAssume $N \\ge 2$ and $M \\ge 2$, and that the array $B$ is read-only within this SCoP. Using the foundations of the polyhedral model, represent the loop as a polyhedron for the iteration domain, specify the affine access functions for the statement $S$, and derive all intra-statement flow dependence distance vectors on array $A$ that arise due to the reads and writes in $S$. Then, compute an affine schedule that corresponds to interchanging the loops (ordering by $j$ then by $i$), and verify the legality condition expressed as the dependence constraints $D \\cdot \\theta \\ge 0$, where $D$ ranges over the flow dependence distance vectors of $S$ and $\\theta$ is the coefficient vector for the first schedule dimension of the interchange schedule. Finally, provide the closed-form analytic expression of the two-dimensional schedule function that implements the loop interchange as your answer.", "solution": "The problem is valid as it is well-posed, scientifically grounded in the principles of compiler theory (specifically, the polyhedral model), and contains all necessary information to derive a solution.\n\nThe problem asks for an analysis of a given loop nest, determination of its data dependencies, and the formulation and verification of an affine schedule corresponding to loop interchange.\n\nThe loop nest is given by:\nfor $i = 2$ to $N$ do\n  for $j = 2$ to $M$ do\n    $S(i,j):\\quad A[i][j] = 3 \\cdot A[i][j-1] - 2 \\cdot A[i-1][j] + B[i-1][j-1]$\n\nFirst, we represent the iteration domain of the statement $S$ as a polyhedron. The iteration vector is $\\vec{p} = \\begin{pmatrix} i \\\\ j \\end{pmatrix}$. The domain $\\mathcal{D}_S$ is the set of integer points $(i, j)$ satisfying the loop bounds:\n$$ \\mathcal{D}_S = \\{ (i, j) \\in \\mathbb{Z}^2 \\mid 2 \\le i \\le N \\land 2 \\le j \\le M \\} $$\n\nNext, we identify the affine memory access functions for array $A$ within statement $S$. The statement involves one write and two reads to array $A$. Let the iteration vector be $\\vec{p} = (i, j)^T$.\n1.  Write access to $A[i][j]$: The access function is $f_W(\\vec{p}) = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} i \\\\ j \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n2.  Read access to $A[i][j-1]$: The access function is $f_{R1}(\\vec{p}) = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} i \\\\ j \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix}$.\n3.  Read access to $A[i-1][j]$: The access function is $f_{R2}(\\vec{p}) = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} i \\\\ j \\end{pmatrix} + \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}$.\n\nWe now derive the intra-statement flow dependences (Read-After-Write) for array $A$. A flow dependence exists from an iteration $\\vec{p}_w$ to a lexicographically later iteration $\\vec{p}_r$ if a memory location written at $\\vec{p}_w$ is read at $\\vec{p}_r$. The dependence vector is $\\vec{d} = \\vec{p}_r - \\vec{p}_w$.\n\nCase 1: Dependence involving $f_{R1}$.\nThe condition is $f_W(\\vec{p}_w) = f_{R1}(\\vec{p}_r)$. Let $\\vec{p}_w = (i_w, j_w)^T$ and $\\vec{p}_r = (i_r, j_r)^T$.\n$$ \\begin{pmatrix} i_w \\\\ j_w \\end{pmatrix} = \\begin{pmatrix} i_r \\\\ j_r - 1 \\end{pmatrix} $$\nThis implies $i_w = i_r$ and $j_w = j_r - 1$. The dependence vector is $\\vec{d}_1 = \\vec{p}_r - \\vec{p}_w = \\begin{pmatrix} i_r - i_w \\\\ j_r - j_w \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. This dependence is carried by the $j$-loop. As $(0, 1)$ is lexicographically positive, this is a valid flow dependence in the original loop order.\n\nCase 2: Dependence involving $f_{R2}$.\nThe condition is $f_W(\\vec{p}_w) = f_{R2}(\\vec{p}_r)$.\n$$ \\begin{pmatrix} i_w \\\\ j_w \\end{pmatrix} = \\begin{pmatrix} i_r - 1 \\\\ j_r \\end{pmatrix} $$\nThis implies $i_w = i_r - 1$ and $j_w = j_r$. The dependence vector is $\\vec{d}_2 = \\vec{p}_r - \\vec{p}_w = \\begin{pmatrix} i_r - i_w \\\\ j_r - j_w \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. This dependence is carried by the $i$-loop. As $(1, 0)$ is lexicographically positive, this is a valid flow dependence.\n\nThe set of flow dependence distance vectors is $D = \\{ \\vec{d}_1, \\vec{d}_2 \\} = \\{ (0, 1)^T, (1, 0)^T \\}$.\n\nNow, we propose an affine schedule that corresponds to interchanging the loops. The original schedule can be seen as $\\Theta_{orig}(i, j) = (i, j)^T$. A loop interchange corresponds to ordering iterations by $j$ first, then by $i$. A valid affine schedule for this transformation is:\n$$ \\Theta(i, j) = \\begin{pmatrix} j \\\\ i \\end{pmatrix} $$\nThis can be written as a matrix transformation $\\Theta(\\vec{p}) = T\\vec{p}$ where $T = \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix}$ and $\\vec{p} = (i, j)^T$.\n\nTo verify the legality of this transformation, we must check that for every dependence vector $\\vec{d} \\in D$, the transformed dependence vector $T\\vec{d}$ is lexicographically positive ($T\\vec{d} _{lex} \\vec{0}$).\n\nFor $\\vec{d}_1 = (0, 1)^T$:\n$$ T\\vec{d}_1 = \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} $$\nSince $(1, 0)^T$ is lexicographically positive, this dependence is preserved.\n\nFor $\\vec{d}_2 = (1, 0)^T$:\n$$ T\\vec{d}_2 = \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\nSince $(0, 1)^T$ is lexicographically positive, this dependence is also preserved.\n\nBoth dependence vectors result in lexicographically positive time differences under the new schedule, so the loop interchange is a legal transformation.\n\nThe problem also asks to verify the legality condition $D \\cdot \\theta \\ge 0$. Here, $\\theta$ is the coefficient vector for the first schedule dimension. The first dimension of our schedule is $\\theta_1(i, j) = j$, which in the form $c_{11}i + c_{12}j$ corresponds to the coefficient vector $\\vec{\\theta} = (0, 1)^T$. Let's check the dot product for each dependence vector $\\vec{d} \\in D$:\nFor $\\vec{d}_1 = (0, 1)^T$: $\\vec{d}_1 \\cdot \\vec{\\theta} = (0)(0) + (1)(1) = 1$. Since $1  0$, the dependence is carried by this schedule dimension.\nFor $\\vec{d}_2 = (1, 0)^T$: $\\vec{d}_2 \\cdot \\vec{\\theta} = (1)(0) + (0)(1) = 0$. Since the result is $0$, this dependence is not carried by the first dimension and must be carried by a subsequent dimension. The second dimension is $\\theta_2(i, j) = i$, with coefficient vector $\\vec{\\theta}'=(1, 0)^T$. Checking $\\vec{d}_2$ against this: $\\vec{d}_2 \\cdot \\vec{\\theta}' = (1)(1) + (0)(0) = 1  0$. The dependence is satisfied by the second dimension.\nThe full legality condition is satisfied.\n\nThe closed-form analytic expression for the two-dimensional schedule function is $\\Theta(i, j) = (j, i)^T$. The output of this function for a generic iteration $(i, j)$ is the time vector $(j, i)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nj \\\\\ni\n\\end{pmatrix}\n}\n$$", "id": "3652925"}]}