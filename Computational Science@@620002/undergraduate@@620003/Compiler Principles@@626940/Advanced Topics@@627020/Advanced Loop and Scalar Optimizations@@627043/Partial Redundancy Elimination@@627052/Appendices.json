{"hands_on_practices": [{"introduction": "Partial Redundancy Elimination (PRE) is most easily understood through its application to a classic \"diamond\" shaped control-flow pattern. This exercise [@problem_id:3661827] presents such a scenario, where an identical computation appears on two divergent paths that later rejoin. By analyzing the proposed transformation of hoisting the computation, you will explore the fundamental trade-offs of PRE, weighing the benefit of reduced dynamic computations against potential costs like increased static code size and register pressure.", "problem": "You are given a control-flow graph (CFG) with entry block $B_0$ that immediately branches to two disjoint blocks $B_1$ and $B_2$, each of which then flows into a common successor $B_3$. The program within these blocks is described as follows, where all variables denote integer registers and $\\oplus$ denotes bitwise exclusive OR.\n\n- In $B_0$, both operands $x$ and $y$ are defined and neither $x$ nor $y$ is modified in $B_1$, $B_2$, or along the edges from $B_0$ to $B_1$ or $B_2$. The conditional branch in $B_0$ is determined by a predicate $p$:\n  - In $B_0$: $x := \\text{def}_x$, $y := \\text{def}_y$, and then if $p$ branch to $B_1$ else branch to $B_2$.\n- In $B_1$, there is a use of the expression $x \\oplus y$ that assigns to a local name $u$:\n  - In $B_1$: $u := x \\oplus y$; control then goes to $B_3$.\n- In $B_2$, there is a use of the same expression $x \\oplus y$ that assigns to a local name $v$:\n  - In $B_2$: $v := x \\oplus y$; control then goes to $B_3$.\n- In $B_3$, both $u$ and $v$ may be live depending on subsequent uses.\n\nAssume there are no side effects in evaluating $x$, $y$, or $x \\oplus y$, and that the bitwise exclusive OR operator $\\oplus$ is pure (it does not read or write memory beyond its operands and has no observable effects other than producing its result). Consider applying Partial Redundancy Elimination (PRE), where PRE is defined as the optimization that removes computations that are redundant on some but not necessarily all paths by relocating computations to earlier dominating points and inserting compensation code to preserve correctness, based on dataflow properties such as availability, anticipatability, and transparency.\n\nA proposed PRE transformation introduces a temporary $t$ in $B_0$ to compute $t := x \\oplus y$ once, and then replaces the computations in $B_1$ and $B_2$ with moves $u := t$ and $v := t$, respectively.\n\nWhich of the following statements about the correctness and profitability of this PRE transformation are true?\n\nA. Hoisting $t := x \\oplus y$ into $B_0$ is semantically safe under the stated conditions because $x$ and $y$ are available in $B_0$ and the expression $x \\oplus y$ is transparent along all paths from $B_0$ to its uses in $B_1$ and $B_2$.\n\nB. This transformation strictly reduces code size because it replaces two instances of $x \\oplus y$ with one instance in $B_0$ and does not require any additional instructions.\n\nC. This transformation can increase register pressure and code size due to the insertion of the copies $u := t$ and $v := t$; its profitability depends on a cost model comparing the cost of one computation plus copies against the cost of two computations.\n\nD. If either $x$ or $y$ were redefined on one path between $B_0$ and the corresponding use of $x \\oplus y$, PRE would need to insert compensation code or avoid hoisting to preserve correctness, because $x \\oplus y$ would not be transparent along that path.\n\nE. Hoisting $x \\oplus y$ to $B_0$ could change observable behavior if $x \\oplus y$ had side effects; therefore, PRE must be restricted to pure expressions without side effects, which applies to the given $\\oplus$.\n\nSelect all correct options.", "solution": "This problem analyzes a classic \"diamond\" control-flow pattern where an expression is computed on both branches. The expression $x \\oplus y$ is fully anticipatable at the exit of $B_0$, making it a candidate for hoisting. Let's evaluate each statement about the proposed transformation.\n\n**A. Hoisting $t := x \\oplus y$ into $B_0$ is semantically safe...**\nThis statement is **correct**. Semantic safety for hoisting requires two conditions: the operands must be available at the new location, and the computed value must be the same as at the original locations. Here, $x$ and $y$ are defined in $B_0$. The problem states that neither $x$ nor $y$ is modified between $B_0$ and the uses in $B_1$ and $B_2$. This property, called *transparency*, ensures the hoisted value is correct.\n\n**B. This transformation strictly reduces code size...**\nThis statement is **incorrect**. The original program has two computation instructions (`u := x ⊕ y` and `v := x ⊕ y`). The transformed program has one computation (`t := x ⊕ y`) and two copy instructions (`u := t` and `v := t`), for a total of three instructions. The static code size increases from two to three instructions (assuming each operation is a single instruction).\n\n**C. This transformation can increase register pressure and code size...**\nThis statement is **correct**. As established in B, the code size increases. Furthermore, the new temporary variable `t` must be kept alive from its definition in $B_0$ until its uses in $B_1$ and $B_2$. This increases the number of live variables across the branch, raising register pressure. The profitability of this trade-off (one computation and two copies vs. two computations) depends on a compiler's cost model, which weighs execution speed against resource usage.\n\n**D. If either $x$ or $y$ were redefined on one path...**\nThis statement is **correct**. If an operand were redefined, the path would no longer be transparent. A correct PRE algorithm must preserve program semantics. It would detect this and either refrain from hoisting or insert \"compensation code\" (a re-computation of the expression) after the redefinition to ensure the correct value is used.\n\n**E. Hoisting $x \\oplus y$ to $B_0$ could change observable behavior if $x \\oplus y$ had side effects...**\nThis statement is **correct**. Code motion optimizations must not change observable program behavior. If an expression has side effects (like I/O) or can trap (like division by zero), moving it can alter program semantics. Therefore, PRE is generally restricted to *pure* expressions. The problem correctly notes that bitwise XOR is pure, making it a safe candidate for this optimization. This statement accurately describes a fundamental safety constraint of PRE.", "answer": "$$\\boxed{ACDE}$$", "id": "3661827"}, {"introduction": "Real-world programs often contain operations that are not completely safe, such as division, which can cause exceptions. This practice [@problem_id:3661859] extends the basic concept of PRE to handle these unsafe expressions, focusing on the critical need to preserve precise exception semantics. You will reason about how to correctly hoist not just the computation, like `$x/y$`, but also its corresponding safety guard, ensuring that the optimization eliminates redundancy without altering the program's observable behavior.", "problem": "A program in a Control-Flow Graph (CFG) has blocks $B_0 \\rightarrow B_2$ with a conditional split at $B_2$ based on predicate $p$ into two normal-path blocks $B_4$ and $B_5$, both of which can reach a common join block $J$. There is a rare error handler block $E$ that should be reached if and only if $y=0$. The current fragment in both normal-path branches is:\n- In $B_4$: if $y=0$ then goto $E$ else compute $t_1 := x/y$ and use $t_1$; then goto $J$.\n- In $B_5$: if $y=0$ then goto $E$ else compute $t_2 := x/y$ and use $t_2$; then goto $J$.\n\nAssume integer division, where dividing by zero must trigger the error handler $E$ (i.e., the language has precise exception semantics for division by zero and no other side effects on these paths). Also assume that $x$ and $y$ are not modified along the paths $B_2 \\rightarrow B_4$ and $B_2 \\rightarrow B_5$ and are defined before $B_2$, and that $y$ can be zero only on the rare error path. The goal is to apply Partial Redundancy Elimination (PRE) to the expression $x/y$ so that it is computed exactly once on all normal paths, while preserving the program’s original exception behavior and minimizing guard checks.\n\nFrom the fundamental definitions used in compiler optimization:\n- Redundancy of an expression means the expression is computed multiple times along some paths where its operands have not changed.\n- Availability of an expression at a program point means all paths to that point compute the expression, and the operands have not changed since the last computation.\n- Anticipability of an expression at a program point means the expression will be used along all paths from that point before any of its operands are redefined.\n- Dominance in a CFG means a node $D$ dominates a node $N$ if every path from the entry to $N$ goes through $D$.\n- For unsafe expressions (like $x/y$), computing the expression is safe only in regions where a guard guarantees that its evaluation will not raise an exception; otherwise, speculative motion may violate precise exception semantics.\n\nWhich of the following transformations are correct under these principles and meet the stated goals?\n\nA. Introduce a new block $G$ immediately after $B_2$ (so that $G$ dominates both $B_4$ and $B_5$). In $G$, perform a single guard and computation: if $y=0$ then goto $E$ else compute $t := x/y$. Redirect both edges $B_2 \\rightarrow B_4$ and $B_2 \\rightarrow B_5$ through $G$, eliminate the per-branch guards in $B_4$ and $B_5$, and replace $t_1 := x/y$ and $t_2 := x/y$ by uses of $t$. Keep the uses unchanged. No other changes.\n\nB. Insert $t := x/y$ speculatively in $B_2$ without any guard, remove the per-branch guards in $B_4$ and $B_5$, and replace $t_1 := x/y$ and $t_2 := x/y$ by uses of $t$. Leave $E$ reachable only if some later code attempts division-by-zero as before.\n\nC. Insert a guard in a new dominator block $G$ after $B_2$ that sends control to $E$ if $y=0$ and otherwise passes to $B_4$ or $B_5$ unchanged. In addition, precompute $t := x/y$ in $G$ and replace $t_1 := x/y$ and $t_2 := x/y$ by uses of $t$, but retain the original per-branch guards in $B_4$ and $B_5$ to be conservative.\n\nD. Hoist only the guard into a new block $G$ after $B_2$ that sends control to $E$ if $y=0$ and otherwise forwards to $B_4$ and $B_5$, but leave $t_1 := x/y$ in $B_4$ and $t_2 := x/y$ in $B_5$ as they are, with their computations intact.\n\nSelect the option(s) that produce a program that is semantically equivalent to the original (with respect to exception behavior and values), compute $x/y$ exactly once on all normal paths, and minimize the number of guard checks required.", "solution": "The problem asks for the correct Partial Redundancy Elimination (PRE) transformation for an unsafe expression, `$x/y$`, which can cause a division-by-zero exception. The key constraints are to preserve the original, precise exception behavior while eliminating redundant computations and guards.\n\nIn the initial program, both the computation `$x/y$` and its protective guard `if y=0` are duplicated on the two branches ($B_4$ and $B_5$). A successful PRE transformation must eliminate both redundancies.\n\n-   **Unsafe Hoisting**: Simply hoisting the computation `$t := x/y$` to a dominating block (like $B_2$) is incorrect. This is speculative execution and would introduce a new division-by-zero fault on a path where it was previously guarded, violating precise exception semantics.\n-   **Safe Hoisting**: To preserve semantics, the optimization must hoist the guard along with the computation. The correct strategy is to create a new block that dominates both branches, place a single guard there, and on the safe path of that guard, perform the computation once.\n\nLet's evaluate the options based on this principle:\n\n**A. Introduce a new block $G$... perform a single guard and computation...**\nThis option is **correct**. It perfectly describes the safe PRE transformation. A new block $G$ is inserted to dominate $B_4$ and $B_5$. In $G$, a single guard (`if y=0`) preserves the original exception behavior. On the safe path, the computation `$t := x/y$` is performed once. The now-redundant guards and computations in $B_4$ and $B_5$ are eliminated. This meets all goals: it computes `$x/y$` once, preserves exception behavior, and minimizes guard checks to one.\n\n**B. Insert $t := x/y$ speculatively in $B_2$ without any guard...**\nThis option is **incorrect**. This is speculative code motion of an unsafe operation. It removes the guards and will cause the program to crash if it enters $B_2$ with $y=0$, which is a semantic change from the original program.\n\n**C. Insert a guard... precompute $t := x/y$ in $G$... but retain the original per-branch guards...**\nThis option is **incorrect**. While it is semantically safe (it preserves exception behavior and computes `$x/y$` once), it fails to meet the goal of minimizing guard checks. After passing the new guard in $G$, it is known that $y \\ne 0$, so the original guards in $B_4$ and $B_5$ become redundant. Retaining them makes the transformation suboptimal.\n\n**D. Hoist only the guard... but leave $t_1 := x/y$ in $B_4$ and $t_2 := x/y$ in $B_5$...**\nThis option is **incorrect**. It correctly eliminates the redundant guard but fails to eliminate the redundant computation `$x/y$`. This violates the primary goal of applying PRE to the expression, which is to compute it only once.\n\nThus, only option A provides a transformation that is both semantically correct and optimal according to the stated goals.", "answer": "$$\\boxed{A}$$", "id": "3661859"}, {"introduction": "Sometimes, a promising optimization like PRE is blocked by the very structure of the program's control flow. This advanced exercise [@problem_id:3661855] presents a situation where a merge point followed by a conditional branch prevents a safe hoisting of an expression. The challenge invites you to think like a compiler designer and explore a powerful restructuring technique—code cloning, or tail duplication—to untangle the control flow, isolate execution paths, and create an opportunity for PRE where none existed before.", "problem": "A compiler wants to apply partial redundancy elimination (PRE) of the expression $x+y$ in a program that uses Static Single Assignment (SSA) and is represented as a Control Flow Graph (CFG). The program uses integer arithmetic with overflow checks; evaluating $x+y$ may raise an overflow exception and therefore non-speculative PRE is required: the compiler must not introduce evaluation of $x+y$ on control-flow paths where the original program does not evaluate $x+y$.\n\nConsider the following CFG with basic blocks $B_0$, $B_1$, $B_2$, $J$, $S$, $U$, $N$, and $E$:\n\n- $B_0$: initializes $x := a$, $y := b$, then branches on predicate $p$ to $B_1$ or $B_2$.\n- $B_1$: computes $t := x + y$ and then goes to $J$.\n- $B_2$: updates $y := y + 1$ and then goes to $J$.\n- $J$: merges the paths from $B_1$ and $B_2$ with SSA merge functions $\\phi$, producing $x_J := \\phi(x_{B_1}, x_{B_2})$ and $y_J := \\phi(y_{B_1}, y_{B_2})$, then goes to $S$.\n- $S$: branches on predicate $q$ to $U$ (true) or $N$ (false).\n- $U$: computes $u := x_J + y_J$, uses $u$, and then goes to $E$.\n- $N$: performs unrelated work without using $x+y$, then goes to $E$.\n- $E$: exit.\n\nAssumptions:\n- $x$ and $y$ are not modified in $J$, $S$, $U$, or $N$ (except $u$ is defined in $U$ and only used there).\n- The computation $u := x_J + y_J$ in $U$ is the only evaluation of $x+y$ on the $S \\to U$ (true) path; on the $S \\to N$ (false) path there is no evaluation of $x+y$ in the original program.\n- Because $x+y$ may raise an overflow exception, non-speculative PRE must not introduce any new execution of $x+y$ on the $S \\to N$ path.\n\nObservation: On the $B_0 \\to B_1 \\to J \\to S \\to U$ path, the expression $x+y$ is already computed in $B_1$ as $t := x + y$, and along this path $u := x_J + y_J$ is equal to $t$. On the alternative path $B_0 \\to B_2 \\to J \\to S \\to U$, $x+y$ is not computed earlier. Thus, at $U$, $x+y$ is partially redundant: it is available along one incoming path but not the other.\n\nStandard PRE would try to place $x+y$ to make it available along all paths to $U$, enabling the elimination of $u := x_J + y_J$ in $U$. However, because the closest placement that dominates $U$ across both predecessors is at or before $S$ or $J$, moving $x+y$ there would cause its evaluation also when $q$ is false, violating non-speculative constraints.\n\nWhich restructuring, via code cloning (tail duplication), enables a legal PRE placement so that the computation $u := x_J + y_J$ in $U$ becomes fully redundant and can be removed without introducing any new execution of $x+y$ on the $S \\to N$ path?\n\nChoose the best option:\n\nA. Clone the tail that leads to the use: create path-specific copies $J_1, S_1, U_1$ for the $B_1$ path and $J_2, S_2, U_2$ for the $B_2$ path by duplicating $J$ and $S$ and splitting their outgoing $q$-true edges to $U$. Redirect $B_1 \\to J_1 \\to S_1 \\to U_1$ and $B_2 \\to J_2 \\to S_2 \\to U_2$. Insert a computation of $x+y$ only on the $q$-true edge of $S_2$ (just before $U_2$), and reuse $t := x+y$ from $B_1$ along $J_1 \\to S_1 \\to U_1$. Then replace and remove $u := x_J + y_J$ in both $U_1$ and $U_2$. This executes $x+y$ only when $q$ is true and eliminates the $\\phi$-merged operands in the cloned tails.\n\nB. Clone only the join $J$ into $J_1$ and $J_2$, redirect $B_1 \\to J_1$ and $B_2 \\to J_2$, keep $S$ and $U$ shared, and insert $x+y$ at $J_2$ for the $B_2$ path. Remove $u := x_J + y_J$ in $U$.\n\nC. Clone only the predecessor $B_1$ into a new block $B'_1$ that also computes $t := x + y$, keep $J$, $S$, and $U$ unchanged, and rely on the availability of $t$ to remove $u := x_J + y_J$ in $U$.\n\nD. Speculatively hoist $x+y$ to $B_0$ (preheader), delete $u := x_J + y_J$ in $U$, and rely on $x$ and $y$ remaining unchanged until $U$ to ensure correctness without cloning.", "solution": "The central issue is that the control flow merges at block $J$ and then splits at block $S$. This structure prevents hoisting the partially redundant computation `$x+y$` into $J$ or $S$ because doing so would introduce the computation onto the path leading to $N$ ($... \\to J \\to S \\to N$), which originally did not have it. Since `$x+y$` can cause an exception, this speculative execution is illegal.\n\nThe solution is to restructure the control flow using **tail duplication** (code cloning). This technique creates separate paths for the different flows that merge at $J$, thereby untangling them and allowing for path-specific optimization.\n\nLet's analyze the options:\n\n**A. Clone the tail that leads to the use...**\nThis option is **correct**. It describes the proper application of tail duplication.\n1.  **Cloning**: It duplicates the blocks downstream of the merge ($J$, $S$, and their successors on the path to the use, $U$) for each incoming path ($B_1$ and $B_2$). This creates two independent control flow \"tails\".\n2.  **Path from $B_1$**: On the cloned path $B_1 \\to J_1 \\to S_1 \\to U_1$, the value of `$x+y$` computed in $B_1$ is available. The computation in $U_1$ is fully redundant and can be replaced by the value from $B_1$.\n3.  **Path from $B_2$**: On the cloned path $B_2 \\to J_2 \\to S_2 \\to U_2$, the computation is not yet available. To make it available at $U_2$, we insert it. The crucial detail is *where*. By inserting it \"only on the $q$-true edge of $S_2$\", the computation is performed only after the program is committed to the path to $U_2$, not $N$. This respects the non-speculative constraint.\n4.  **Result**: After this transformation, the original computation in $U$ becomes fully redundant on all paths leading to it and can be removed. This achieves the goal of PRE without illegal speculation.\n\n**B. Clone only the join $J$... keep $S$ and $U$ shared...**\nThis option is **incorrect**. If only $J$ is cloned, $S$ becomes the new merge point. Hoisting the computation for the $B_2$ path into its cloned block ($J_2$) would still place it before the split at $S$. The path $B_2 \\to J_2 \\to S \\to N$ would now contain a new, speculative computation, violating the problem's constraint.\n\n**C. Clone only the predecessor $B_1$...**\nThis option is **incorrect**. Cloning a block *before* the merge point does not change the problematic control flow structure *after* the merge point. The fundamental issue of the merge-then-split structure ($J \\to S$) remains, and PRE is still blocked.\n\n**D. Speculatively hoist $x+y$ to $B_0$...**\nThis option is **incorrect**. It directly contradicts the problem's central constraint: \"non-speculative PRE is required\". Hoisting to $B_0$ is the definition of speculative execution in this context, as it introduces the computation on all paths, including those that originally did not have it.\n\nTherefore, tail duplication as described in option A is the correct and necessary restructuring to enable non-speculative PRE in this scenario.", "answer": "$$\\boxed{A}$$", "id": "3661855"}]}