{"hands_on_practices": [{"introduction": "At its core, instruction scheduling is about arranging operations to hide hardware latencies and maximize performance. This first exercise provides a foundational look at this process by examining a simple, single-issue pipeline. You will see how a compiler can leverage an algebraic property—commutativity—to reorder code and cleverly avoid a common performance bottleneck known as a load-use hazard, providing a tangible example of how scheduling directly impacts execution speed [@problem_id:3646541].", "problem": "Consider a single-issue, in-order, five-stage pipeline with full bypassing in the Arithmetic Logic Unit (ALU). The pipeline follows these rules, which reflect standard causes of pipeline hazards grounded in Read After Write (RAW) dependences and fixed producer latencies:\n- Each instruction attempts to issue once per cycle; at most one instruction can issue in any cycle.\n- A load instruction that is immediately followed by a consumer of its destination register incurs exactly one inserted stall cycle (a single bubble) before the consumer, due to the one-cycle load-use latency. If there is at least one intervening independent instruction between the load and its consumer, no stall is incurred.\n- An integer addition has zero-cycle result latency under full bypassing, so an instruction that consumes the result of an integer addition can be scheduled in the immediately subsequent cycle without incurring a stall.\n- There are no other sources of stalls or structural hazards in this problem.\n\nYou are given a basic block that computes the reduction\n$$R_7 \\leftarrow (R_1 + R_4) + (R_2 + R_6),$$\nwhere $+$ denotes integer addition, which is commutative. The following instructions implement this computation, with the indicated dependencies:\n1. $\\mathrm{LD}\\ R_1 \\leftarrow M[\\alpha]$\n2. $\\mathrm{LD}\\ R_2 \\leftarrow M[\\beta]$\n3. $\\mathrm{ADD}\\ R_3 \\leftarrow R_1 + R_4$\n4. $\\mathrm{ADD}\\ R_5 \\leftarrow R_2 + R_6$\n5. $\\mathrm{ADD}\\ R_7 \\leftarrow R_3 + R_5$\n\nBecause $+$ is commutative, the order of producing $R_3$ and $R_5$ is freely permutable, provided data dependences from their respective loads are respected. Consider the following two legal issue orders (both respect the data-dependence graph):\n- Order $\\mathcal{O}_1$: $\\mathrm{LD}\\ R_1$, $\\mathrm{ADD}\\ R_3 \\leftarrow R_1 + R_4$, $\\mathrm{LD}\\ R_2$, $\\mathrm{ADD}\\ R_5 \\leftarrow R_2 + R_6$, $\\mathrm{ADD}\\ R_7 \\leftarrow R_3 + R_5$.\n- Order $\\mathcal{O}_2$: $\\mathrm{LD}\\ R_1$, $\\mathrm{LD}\\ R_2$, $\\mathrm{ADD}\\ R_3 \\leftarrow R_1 + R_4$, $\\mathrm{ADD}\\ R_5 \\leftarrow R_2 + R_6$, $\\mathrm{ADD}\\ R_7 \\leftarrow R_3 + R_5$.\n\nUsing only the foundational concepts of data dependences and producer-to-consumer latencies described above, determine the total number of issue cycles required to execute all five instructions under each order (counting any automatically inserted stall cycles), and then compute the speedup of the better order over the worse order, defined as\n$$S \\equiv \\frac{T_{\\text{worse}}}{T_{\\text{better}}}.$$\n\nExpress the final answer for $S$ as a single simplified fraction. No rounding is required and no units should be provided.", "solution": "To solve this problem, we must simulate the execution of the two instruction orders on the given single-issue, in-order pipeline. The total execution time for each order will be the number of instructions plus the number of stall cycles incurred due to data dependencies and latencies.\n\nThe key pipeline rules are:\n- A load instruction immediately followed by an instruction that uses its result causes a 1-cycle stall.\n- If at least one independent instruction separates the load from its consumer, there is no stall.\n- An `ADD` instruction has a 0-cycle result latency, meaning its result can be used in the very next cycle without a stall.\n\n**Analysis of Order $\\mathcal{O}_1$**\n\nThe issue sequence is: $\\mathrm{LD}\\ R_1$, $\\mathrm{ADD}\\ R_3$, $\\mathrm{LD}\\ R_2$, $\\mathrm{ADD}\\ R_5$, $\\mathrm{ADD}\\ R_7$.\n\nLet's trace the execution cycle by cycle:\n- **Cycle 0:** $\\mathrm{LD}\\ R_1 \\leftarrow M[\\alpha]$ is issued.\n- **Cycle 1:** The pipeline attempts to issue $\\mathrm{ADD}\\ R_3 \\leftarrow R_1 + R_4$. However, this instruction depends on the result of $\\mathrm{LD}\\ R_1$. Because it immediately follows the load, a 1-cycle load-use hazard occurs. The pipeline inserts a stall (bubble).\n- **Cycle 2:** $\\mathrm{ADD}\\ R_3 \\leftarrow R_1 + R_4$ is issued.\n- **Cycle 3:** $\\mathrm{LD}\\ R_2 \\leftarrow M[\\beta]$ is issued.\n- **Cycle 4:** The pipeline attempts to issue $\\mathrm{ADD}\\ R_5 \\leftarrow R_2 + R_6$. This instruction depends on the result of $\\mathrm{LD}\\ R_2$. Again, a 1-cycle load-use hazard occurs, and a stall is inserted.\n- **Cycle 5:** $\\mathrm{ADD}\\ R_5 \\leftarrow R_2 + R_6$ is issued.\n- **Cycle 6:** $\\mathrm{ADD}\\ R_7 \\leftarrow R_3 + R_5$ is issued. It depends on $\\mathrm{ADD}\\ R_3$ and $\\mathrm{ADD}\\ R_5$. Since `ADD` instructions have 0-cycle latency, there are no stalls.\n\nThe total time for order $\\mathcal{O}_1$ is the sum of the 5 instructions and 2 stall cycles.\n$T_1 = 5 + 2 = 7$ cycles.\n\n**Analysis of Order $\\mathcal{O}_2$**\n\nThe issue sequence is: $\\mathrm{LD}\\ R_1$, $\\mathrm{LD}\\ R_2$, $\\mathrm{ADD}\\ R_3$, $\\mathrm{ADD}\\ R_5$, $\\mathrm{ADD}\\ R_7$.\n\nLet's trace this execution:\n- **Cycle 0:** $\\mathrm{LD}\\ R_1 \\leftarrow M[\\alpha]$ is issued.\n- **Cycle 1:** $\\mathrm{LD}\\ R_2 \\leftarrow M[\\beta]$ is issued. This instruction is independent of $\\mathrm{LD}\\ R_1$.\n- **Cycle 2:** $\\mathrm{ADD}\\ R_3 \\leftarrow R_1 + R_4$ is issued. This instruction depends on $\\mathrm{LD}\\ R_1$. However, one instruction ($\\mathrm{LD}\\ R_2$) was placed between the load and its consumer. This separation is sufficient to avoid the load-use stall.\n- **Cycle 3:** $\\mathrm{ADD}\\ R_5 \\leftarrow R_2 + R_6$ is issued. This instruction depends on $\\mathrm{LD}\\ R_2$. Similarly, one instruction ($\\mathrm{ADD}\\ R_3$) separates the load and its use, so no stall is incurred.\n- **Cycle 4:** $\\mathrm{ADD}\\ R_7 \\leftarrow R_3 + R_5$ is issued. There are no stalls from its dependencies on prior `ADD` instructions.\n\nThe total time for order $\\mathcal{O}_2$ is the sum of the 5 instructions and 0 stall cycles.\n$T_2 = 5 + 0 = 5$ cycles.\n\n**Speedup Calculation**\n\nThe better order is $\\mathcal{O}_2$ and the worse order is $\\mathcal{O}_1$.\n- $T_{\\text{worse}} = T_1 = 7$ cycles\n- $T_{\\text{better}} = T_2 = 5$ cycles\n\nThe speedup $S$ is the ratio of the execution times:\n$$S = \\frac{T_{\\text{worse}}}{T_{\\text{better}}} = \\frac{7}{5}$$", "answer": "$$\n\\boxed{\\frac{7}{5}}\n$$", "id": "3646541"}, {"introduction": "Modern processors achieve high performance through superscalar execution, where multiple instructions are issued in a single clock cycle. This introduces a new layer of complexity for the scheduler: it must now manage both data dependencies and finite hardware resources. This practice problem challenges you to schedule a dot product computation on a dual-issue machine, demonstrating the fundamental trade-off between the length of the critical dependency path and the processor's issue width [@problem_id:3646497].", "problem": "A compiler targets a dual-issue pipeline for floating-point arithmetic and must schedule a basic block that computes a dot product of length $4$. The machine model is as follows: the pipeline can issue up to $W=2$ operations per cycle into two symmetric slots, there are no structural hazards beyond the issue width, and the only data hazards are governed by instruction latencies. A floating-point multiply has latency $L_{\\text{mul}}=4$ cycles and a floating-point add has latency $L_{\\text{add}}=1$ cycle. An instruction’s result becomes available exactly $L$ cycles after its issue, where $L$ is that instruction’s latency. All input operands are available at cycle $0$, register renaming eliminates name dependences, and there are no memory operations in the basic block. The compiler may schedule any add or multiply in any slot in any cycle, subject to the above constraints.\n\nThe dot product of vectors $\\{a_k\\}$ and $\\{b_k\\}$ for $k \\in \\{0,1,2,3\\}$ is to be computed as $s = \\sum_{k=0}^{3} a_k b_k$. The basic block to be scheduled consists of four independent multiplies producing partial products and a balanced reduction by three adds to produce the final scalar $s$. Let the four multiplies be denoted $m_0,m_1,m_2,m_3$, the two first-level adds be $a_{01}$ and $a_{23}$, and the final add be $a_f$. The Directed Acyclic Graph (DAG) of the block has edges $m_0 \\rightarrow a_{01}$, $m_1 \\rightarrow a_{01}$, $m_2 \\rightarrow a_{23}$, $m_3 \\rightarrow a_{23}$, and $a_{01} \\rightarrow a_f$, $a_{23} \\rightarrow a_f$, with edge weights equal to the producer instruction’s latency.\n\nStarting from first principles of instruction scheduling on DAGs with resource constraints and fixed latencies, determine a valid schedule that minimizes the completion time (makespan). Identify which cycles are fully packed (both issue slots used) and identify a critical path in the dependency graph. Finally, report the earliest cycle index at which $s$ becomes available, measured from cycle $0$ as the first issue opportunity.\n\nExpress the final answer as the minimal makespan in cycles as an exact integer with no units.", "solution": "The problem requires finding an optimal instruction schedule for a basic block on a dual-issue processor. A valid schedule must satisfy both data dependency constraints, as defined by the Directed Acyclic Graph (DAG), and resource constraints, given by the machine's issue width. The objective is to minimize the makespan, which is the time from the start of execution until the final result is available.\n\nLet $S_i$ be the issue cycle of an instruction $i$, and $L_i$ be its latency. The result of instruction $i$ becomes available at the beginning of cycle $S_i + L_i$. An instruction $j$ that depends on the result of instruction $i$ cannot be issued before this time. The set of instructions consists of four multiplies $\\{m_0, m_1, m_2, m_3\\}$ and three adds $\\{a_{01}, a_{23}, a_f\\}$. The latencies are $L_{\\text{mul}}=4$ and $L_{\\text{add}}=1$. The machine can issue up to $W=2$ instructions per cycle. All inputs are available at cycle $0$.\n\nFirst, we establish a lower bound on the makespan. The makespan is limited by the longest path in the computation's dependency graph, known as the critical path, and by the available hardware resources.\n\n$1$. **Data-Dependency Bound (Critical Path):** The computation is structured as $s = (a_0 b_0 + a_1 b_1) + (a_2 b_2 + a_3 b_3)$. This corresponds to a DAG where multiplies feed first-level adds, which in turn feed a final add. A path from an input to the final result involves one multiply and two adds. For instance, the path involving $m_0$ is $m_0 \\rightarrow a_{01} \\rightarrow a_f$. If these were scheduled without resource constraints, their execution would be serialized by data dependencies. If $m_0$ is issued at cycle $C_0=0$, its result is available at $C_0 + L_{\\text{mul}} = 4$. Then $a_{01}$ can be issued at $C_1=4$, with its result available at $C_1 + L_{\\text{add}} = 5$. Finally, $a_f$ can be issued at $C_2=5$, and the final result $s$ becomes available at $C_2 + L_{\\text{add}} = 6$. Thus, the critical path length of the DAG is $L_{\\text{mul}} + L_{\\text{add}} + L_{\\text{add}} = 4 + 1 + 1 = 6$ cycles. The makespan must therefore be at least $6$ cycles.\n\n$2$. **Resource Bound:** The basic block contains $7$ instructions in total ($4$ multiplies, $3$ adds). With a dual-issue machine ($W=2$), issuing all instructions will take at least $\\lceil \\frac{7}{2} \\rceil = 4$ cycles. Specifically for the multiplies, there are $4$ independent instructions. Issuing them requires at least $\\lceil \\frac{4}{2} \\rceil = 2$ cycles.\n\nWe will construct a schedule using a greedy approach, also known as list scheduling. At each cycle, we identify the set of \"ready\" instructions—those whose data dependencies have been met—and issue up to $W=2$ of them.\n\n**Cycle $0$:**\nThe initial ready set consists of the four multiplies: $\\{m_0, m_1, m_2, m_3\\}$, as their inputs are available.\nWe can issue two of them. Let's issue $m_0$ and $m_1$.\n- **Schedule:** Issue $m_0$, $m_1$.\n- **State:** $m_0, m_1$ are in-flight. Their results will be available at cycle $0 + L_{\\text{mul}} = 4$.\n\n**Cycle $1$:**\nThe ready set now contains the remaining multiplies: $\\{m_2, m_3\\}$.\nWe issue both $m_2$ and $m_3$.\n- **Schedule:** Issue $m_2$, $m_3$.\n- **State:** $m_0, m_1, m_2, m_3$ are in-flight. Results for $m_2, m_3$ will be available at cycle $1 + L_{\\text{mul}} = 5$.\n\n**Cycle $2$ and $3$:**\nNo instructions are ready. The adds $a_{01}$ and $a_{23}$ are waiting for the results of the multiplies. This creates a stall.\n- **Schedule:** Stall (no instructions issued).\n\n**Cycle $4$:**\nThe results from $m_0$ and $m_1$ are now available. This makes instruction $a_{01}$ ready, as both its dependencies are satisfied. The ready set is $\\{a_{01}\\}$.\n- **Schedule:** Issue $a_{01}$. One issue slot is unused.\n- **State:** Result for $a_{01}$ will be available at cycle $4 + L_{\\text{add}} = 5$.\n\n**Cycle $5$:**\nThe results from $m_2$ and $m_3$ become available. This makes instruction $a_{23}$ ready. Also at cycle $5$, the result of $a_{01}$ becomes available. The ready set is $\\{a_{23}\\}$. The other input for the final add $a_f$ is not ready yet.\n- **Schedule:** Issue $a_{23}$. One issue slot is unused.\n- **State:** Result for $a_{23}$ will be available at cycle $5 + L_{\\text{add}} = 6$.\n\n**Cycle $6$:**\nThe result from $a_{23}$ is now available. The result from $a_{01}$ was available from cycle $5$. Both inputs to the final add $a_f$ are now ready. The ready set is $\\{a_f\\}$.\n- **Schedule:** Issue $a_f$. One issue slot is unused.\n- **State:** The final result $s$ will be available at cycle $6 + L_{\\text{add}} = 7$.\n\n**Cycle $7$:**\nThe computation is complete. The result $s$ is available.\n\nThe makespan for this schedule is $7$ cycles. This is longer than the critical path bound of $6$. The reason for this is the resource constraint. The $W=2$ issue width forces the four independent multiplies to be scheduled over two cycles. The multiplies issued in cycle $1$ ($m_2, m_3$) finish one cycle later than those issued in cycle $0$. This one-cycle delay propagates through the dependency chain, delaying $a_{23}$ and subsequently $a_f$, ultimately adding one cycle to the total execution time compared to the theoretical, resource-unconstrained lower bound. No other schedule can do better, because scheduling the four multiplies requires a minimum of two cycles, which inevitably creates a one-cycle stagger in the availability of their results. This stagger cannot be overcome.\n\n**Summary of Analysis:**\n- **Minimal Makespan:** The earliest cycle at which $s$ is available is cycle $7$.\n- **Fully Packed Cycles:** A cycle is fully packed if both issue slots are used. In this schedule, cycle $0$ (issued $m_0, m_1$) and cycle $1$ (issued $m_2, m_3$) are fully packed.\n- **Critical Path:** The critical path of the schedule is the sequence of dependent instructions that determine the makespan. The completion time is determined by the availability of the result of $a_f$ at cycle $7$. This was due to $a_f$ being issued at cycle $6$, which was forced by its latest-arriving input from $a_{23}$ at cycle $6$. The issue of $a_{23}$ at cycle $5$ was forced by its inputs from $m_2$ and $m_3$ becoming available at cycle $5$. The issue of $m_2$ and $m_3$ at cycle $1$ was forced by a resource constraint, as $m_0$ and $m_1$ occupied the issue slots at cycle $0$. Thus, a critical path for the schedule is the chain $m_2 \\rightarrow a_{23} \\rightarrow a_f$ (or $m_3 \\rightarrow a_{23} \\rightarrow a_f$), where the first dependency is a resource-induced one, and the subsequent ones are true data dependencies. The \"critical path in the dependency graph\" can be taken to mean a path in the abstract DAG that becomes critical in the final schedule.\n\nThe final answer requested is the earliest cycle index at which $s$ becomes available. This is the makespan of the optimal schedule.\nFinal Makespan = $7$ cycles.", "answer": "$$\\boxed{7}$$", "id": "3646497"}, {"introduction": "The optimization potential within a single basic block is often limited by control flow. To uncover more instruction-level parallelism, compilers employ global scheduling techniques that rearrange code across branch instructions. This final exercise contrasts traditional local scheduling with a more aggressive superblock scheduling strategy, showing how speculative execution can significantly speed up the most frequent path through the code, even at the cost of performing some extra work on less-common paths [@problem_id:3646565].", "problem": "A compiler back end targets a simple scalar machine and must schedule a region with a hot trace and an off-trace branch. The goal is to contrast local basic-block scheduling with global superblock scheduling on the hot trace and to quantify both the improvement on the hot trace and the overhead experienced on the off-trace path due to speculative motion. The machine model and region are as follows.\n\nMachine model assumptions:\n- Single-issue: at most $1$ instruction can be issued per cycle.\n- Fixed latencies: integer add has latency $1$, integer multiply has latency $2$, load has latency $3$, store has latency $1$, branch has latency $1$.\n- An instruction that uses a value produced by a previous instruction can be issued no earlier than the producer’s issue cycle plus its latency. There are no other structural hazards.\n- All loads in this region are known to be non-faulting and side-effect-free, so they may be speculated before a branch without changing program semantics. Arithmetic instructions have no side effects. The store and branch have their usual side effects and must not be speculated across their dynamic control dependences.\n\nControl-flow region:\n- Block $A$ (entry):\n  - $a_1$: integer add (latency $1$)\n  - $a_2$: integer multiply (latency $2$), depends on the result of $a_1$\n  - $a_3$: conditional branch (latency $1$), depends on the result of $a_2$; goes to $B$ (hot) with probability $p_B$ and to $C$ (off-trace) with probability $1 - p_B$\n- Block $B$ (hot successor of $A$):\n  - $b_1$: load (latency $3$), independent of $A$\n  - $b_2$: integer multiply (latency $2$), depends on the result of $b_1$ and produces value $g$\n- Block $C$ (off-trace successor of $A$):\n  - $c_1$: integer add (latency $1$)\n  - $c_2$: integer multiply (latency $2$), depends on the result of $c_1$ and produces value $g$\n- Block $D$ (join after $B$ and $C$):\n  - $d_1$: store (latency $1$), uses $g$\n\nScheduling rules to apply:\n- Under local basic-block scheduling, each block is scheduled independently; no instruction may move across block boundaries. When executing along a path, if a consumer in a successor block arrives before its producer’s value is ready (due to latency), execution must stall with as many no-operations as needed until the value is ready to issue the consumer.\n- Under global superblock scheduling, treat the hot trace $A \\rightarrow B \\rightarrow D$ as a single scheduling region. You may move instructions from $B$ upward into $A$ before $a_3$, provided dependences are respected and the legality assumptions above hold. You may not move $d_1$ above $a_3$. The off-trace path $A \\rightarrow C \\rightarrow D$ executes any speculated operations placed before $a_3$ even if the branch goes to $C$; these become wasted work on that path.\n\nGiven a hot-branch probability $p_B = 0.8$, do the following:\n- Derive the minimal-cycle schedules along the hot path and the off-trace path under local basic-block scheduling, counting all required stalls arising from intra-block and inter-block dependences as described.\n- Derive the minimal-cycle schedules along the hot path (superblock trace $A \\rightarrow B \\rightarrow D$) and the off-trace path ($A \\rightarrow C \\rightarrow D$) under global superblock scheduling, with speculative motion of $B$’s instructions before the branch $a_3$ where legal, and account for the wasted execution on the off-trace path.\n- From these schedules, compute the expected cycles per region entry for local basic-block scheduling, $E_{\\text{local}}$, and for global superblock scheduling, $E_{\\text{super}}$, using the given $p_B$.\n- Finally, compute the speedup factor defined as $E_{\\text{local}} / E_{\\text{super}}$.\n\nRound your final numerical answer (the speedup factor) to four significant figures. Do not include any units in your answer. Express the branch probability as the decimal $0.8$ when computing expectations.", "solution": "We start from the fundamental definitions of local basic-block scheduling and global superblock scheduling. In both cases, the machine issues at most $1$ instruction per cycle, and a consumer instruction must be issued at least the producer’s issue cycle plus the producer’s latency. Under local scheduling, code motion across block boundaries is disallowed, so inter-block dependences can cause stalls when entering a successor. Under superblock scheduling, code may be motioned upward along the hot trace so long as data dependences and control-dependence legality are maintained; we assume loads and arithmetic are safely speculative before the branch, but the store $d_1$ cannot be hoisted above $a_3$.\n\nStep $1$: Local basic-block schedules and path cycles.\n\n- Block $A$ has $a_1$ (latency $1$), $a_2$ (latency $2$) depends on $a_1$, and $a_3$ (latency $1$) depends on $a_2$. With single issue:\n  - Issue $a_1$ at cycle $1$.\n  - Because $a_2$ depends on $a_1$ and $a_1$ has latency $1$, we can issue $a_2$ at cycle $2$.\n  - $a_3$ depends on $a_2$ which has latency $2$ and was issued at cycle $2$, so $a_3$ can be issued no earlier than cycle $2 + 2 = 4$. Thus, cycle $3$ is a stall, and we issue $a_3$ at cycle $4$.\n  - Therefore, block $A$ occupies cycles $1$ through $4$.\n\n- Block $B$ has $b_1$ (latency $3$) independent and $b_2$ (latency $2$) depends on $b_1$:\n  - Issue $b_1$ at relative cycle $1$ of $B$.\n  - $b_2$ can be issued at relative cycle $1 + 3 = 4$, so relative cycles $2$ and $3$ are stalls.\n  - Thus, $B$ occupies $4$ cycles when entered.\n\n- Block $C$ has $c_1$ (latency $1$) and $c_2$ (latency $2$) depends on $c_1$:\n  - Issue $c_1$ at relative cycle $1$.\n  - Issue $c_2$ at relative cycle $2$ since $1 + 1 = 2$.\n  - Thus, $C$ occupies $2$ cycles when entered.\n\n- Block $D$ has a single store $d_1$ that uses $g$. Under local scheduling, $d_1$ cannot be moved earlier than block $D$, so when entering $D$ from a predecessor, we may need to stall until $g$ is ready.\n\nNow compute total cycles along each path by sequencing these blocks and honoring cross-block readiness for $g$ at $D$.\n\nHot path $A \\rightarrow B \\rightarrow D$:\n- $A$ uses cycles $1$ through $4$; enter $B$ at cycle $5$.\n- In $B$: issue $b_1$ at cycle $5$, stalls at cycles $6$ and $7$, issue $b_2$ at cycle $8$. The result $g$ from $b_2$ (latency $2$) becomes ready at cycle $8 + 2 = 10$.\n- Enter $D$ at cycle $9$ (immediately after finishing $B$). Because $g$ is not ready until cycle $10$, we must stall at cycle $9$ and issue $d_1$ at cycle $10$.\n- The hot path completes at cycle $10$.\n\nCold path $A \\rightarrow C \\rightarrow D$:\n- $A$ uses cycles $1$ through $4$; enter $C$ at cycle $5$.\n- In $C$: issue $c_1$ at cycle $5$, issue $c_2$ at cycle $6$. The result $g$ from $c_2$ (latency $2$) becomes ready at cycle $6 + 2 = 8$.\n- Enter $D$ at cycle $7$. Because $g$ is not ready until cycle $8$, stall at cycle $7$ and issue $d_1$ at cycle $8$.\n- The cold path completes at cycle $8$.\n\nTherefore, under local basic-block scheduling:\n- Hot-path cycles: $10$.\n- Cold-path cycles: $8$.\n\nStep $2$: Global superblock schedule on the hot trace $A \\rightarrow B \\rightarrow D$ and off-trace behavior.\n\nUnder superblock scheduling, we treat the hot trace as a single scheduling region. We may move $B$’s instructions upward before the branch $a_3$ because $b_1$ and $b_2$ are side-effect-free and respect data dependences. We cannot move $d_1$ before $a_3$.\n\nWe choose an order that hides the $3$-cycle latency of $b_1$ under the work in $A$:\n- Issue $b_1$ at cycle $1$ to start the long-latency load early.\n- Issue $a_1$ at cycle $2$.\n- Issue $a_2$ at cycle $3$ (depends on $a_1$ with latency $1$).\n- $b_2$ depends on $b_1$ with latency $3$, so it can be issued at cycle $1 + 3 = 4$. Issue $b_2$ at cycle $4$.\n- $a_3$ depends on $a_2$ (latency $2$) issued at cycle $3$, so $a_3$ can be issued at cycle $3 + 2 = 5$. Issue $a_3$ at cycle $5$.\n- On the hot path (branch to $B$), we proceed to $D$. The value $g$ from $b_2$ (latency $2$) issued at cycle $4$ is ready at cycle $6$, so issue $d_1$ at cycle $6$.\n- On the off-trace path (branch to $C$), we still executed the speculated $b_1$ and $b_2$ before the branch, but then go to $C$ at cycle $6$ and schedule $C$ locally: $c_1$ at cycle $6$, $c_2$ at cycle $7$, then $g$ from $c_2$ (latency $2$) is ready at cycle $9$, so issue $d_1$ at cycle $9$.\n\nThus, under superblock scheduling:\n- Hot-path cycles: completes at cycle $6$.\n- Off-trace path cycles: completes at cycle $9$.\n- The improvement on the hot path relative to local is $10 - 6 = 4$ cycles saved.\n- The compensation overhead manifested as wasted work on the off-trace path is an extra $9 - 8 = 1$ cycle expected on that path.\n\nStep $3$: Expected cycles and speedup with $p_B = 0.8$.\n\nLet $p_B = 0.8$ and $1 - p_B = 0.2$.\n\nLocal expected cycles:\n$$\nE_{\\text{local}} \\;=\\; p_B \\cdot 10 \\;+\\; (1 - p_B) \\cdot 8 \\;=\\; 0.8 \\cdot 10 \\;+\\; 0.2 \\cdot 8 \\;=\\; 8 \\;+\\; 1.6 \\;=\\; 9.6.\n$$\n\nSuperblock expected cycles:\n$$\nE_{\\text{super}} \\;=\\; p_B \\cdot 6 \\;+\\; (1 - p_B) \\cdot 9 \\;=\\; 0.8 \\cdot 6 \\;+\\; 0.2 \\cdot 9 \\;=\\; 4.8 \\;+\\; 1.8 \\;=\\; 6.6.\n$$\n\nSpeedup factor:\n$$\n\\text{Speedup} \\;=\\; \\frac{E_{\\text{local}}}{E_{\\text{super}}} \\;=\\; \\frac{9.6}{6.6} \\;=\\; 1.454545\\ldots\n$$\n\nRounded to four significant figures, the speedup is $1.455$.", "answer": "$$\\boxed{1.455}$$", "id": "3646565"}]}