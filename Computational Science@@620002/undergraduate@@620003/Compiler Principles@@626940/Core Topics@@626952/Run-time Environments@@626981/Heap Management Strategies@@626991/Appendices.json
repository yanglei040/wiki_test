{"hands_on_practices": [{"introduction": "An efficient heap allocator must do more than just find free space; it must manage that space to minimize waste. This exercise explores internal fragmentation, the memory wasted when an allocator provides a block of memory larger than the requested size. By modeling allocation requests with a probability distribution, you will derive a precise mathematical expression for the expected waste caused by size rounding, a common allocation strategy [@problem_id:3644928]. This practice bridges the gap between theoretical probability and practical systems performance, showing how to not only analyze an allocator's behavior but also to design a policy that controls its efficiency.", "problem": "A compiler runtime uses a heap allocator that rounds each request size $S$ (in bytes) up to the nearest multiple of a quantum $q$ (in bytes), so the allocated size is $A = \\lceil S/q \\rceil q$. Assume requests are independent and identically distributed and follow an exponential distribution with variance $\\sigma^{2}$, so the mean is $\\sigma$. Internal fragmentation for a request is $W = A - S$. Using only core definitions of expectation and the exponential probability density function, perform the following:\n\n- Starting from $f_{S}(s) = \\frac{1}{\\sigma} \\exp(-s/\\sigma)$ for $s \\ge 0$, and the definition $\\mathbb{E}[X] = \\int_{0}^{\\infty} x f_{X}(x)\\,dx$, derive a closed-form expression for the expected internal fragmentation $\\mathbb{E}[W]$ as a function of $q$ and $\\sigma$.\n\n- A policy goal is to minimize the effect of request-size variance by keeping the expected internal fragmentation as a fixed fraction $\\gamma \\in (0,\\infty)$ of the mean request size regardless of $\\sigma^{2}$. Propose a quantization policy $q(\\sigma,\\gamma)$ that achieves $\\mathbb{E}[W] = \\gamma \\,\\mathbb{E}[S]$ exactly for all $\\sigma > 0$ by solving for $q$ symbolically in closed form.\n\nGive your final answer as a single analytic expression for $q(\\sigma,\\gamma)$ (in bytes). No numerical approximation or rounding is required.", "solution": "The problem is assessed to be valid as it is scientifically grounded, well-posed, and objective. It provides a self-contained, consistent set of definitions and a clear, formalizable objective.\n\nThe solution proceeds in two parts as requested by the problem statement.\n\nFirst, we derive a closed-form expression for the expected internal fragmentation, $\\mathbb{E}[W]$.\nThe internal fragmentation for a single request of size $S$ is given by $W = A - S$, where $A = \\lceil S/q \\rceil q$ is the allocated size. By the linearity of expectation, the expected internal fragmentation is:\n$$\n\\mathbb{E}[W] = \\mathbb{E}[A - S] = \\mathbb{E}[A] - \\mathbb{E}[S]\n$$\nThe request size $S$ follows an exponential distribution with probability density function $f_{S}(s) = \\frac{1}{\\sigma} \\exp(-s/\\sigma)$ for $s \\ge 0$. The problem states that the mean of this distribution is $\\sigma$, so we have:\n$$\n\\mathbb{E}[S] = \\sigma\n$$\nNext, we must find the expected allocated size, $\\mathbb{E}[A]$. The allocated size $A$ is a function of the random variable $S$: $A(S) = q \\lceil S/q \\rceil$. Its expectation is given by:\n$$\n\\mathbb{E}[A] = \\mathbb{E}[q \\lceil S/q \\rceil] = q \\, \\mathbb{E}[\\lceil S/q \\rceil]\n$$\nLet's define a new discrete random variable $N = \\lceil S/q \\rceil$. This variable represents the number of quanta allocated for a request of size $S$. The possible values for $N$ are the positive integers, $k \\in \\{1, 2, 3, \\ldots\\}$. The probability that $N$ takes a specific value $k$ is the probability that the request size $S$ falls into the interval $((k-1)q, kq]$:\n$$\nP(N=k) = P((k-1)q < S \\le kq) = \\int_{(k-1)q}^{kq} f_S(s) \\, ds\n$$\nSubstituting the PDF of $S$:\n$$\nP(N=k) = \\int_{(k-1)q}^{kq} \\frac{1}{\\sigma} \\exp(-s/\\sigma) \\, ds = \\left[ -\\exp(-s/\\sigma) \\right]_{(k-1)q}^{kq}\n$$\n$$\nP(N=k) = -\\exp(-kq/\\sigma) - (-\\exp(-(k-1)q/\\sigma)) = \\exp(-(k-1)q/\\sigma) - \\exp(-kq/\\sigma)\n$$\nWe can factor this expression:\n$$\nP(N=k) = \\left(1 - \\exp(-q/\\sigma)\\right) \\exp(-(k-1)q/\\sigma)\n$$\nLet $p = 1 - \\exp(-q/\\sigma)$. Then $1-p = \\exp(-q/\\sigma)$. The probability mass function for $N$ becomes:\n$$\nP(N=k) = p(1-p)^{k-1} \\quad \\text{for } k = 1, 2, 3, \\ldots\n$$\nThis is the probability mass function of a geometric distribution defined on the set of positive integers. The expected value of such a distribution is well-known to be $\\mathbb{E}[N] = 1/p$. Therefore:\n$$\n\\mathbb{E}[N] = \\frac{1}{1 - \\exp(-q/\\sigma)}\n$$\nNow we can compute $\\mathbb{E}[A]$:\n$$\n\\mathbb{E}[A] = q \\, \\mathbb{E}[N] = \\frac{q}{1 - \\exp(-q/\\sigma)}\n$$\nFinally, we substitute $\\mathbb{E}[A]$ and $\\mathbb{E}[S]$ back into the expression for $\\mathbb{E}[W]$:\n$$\n\\mathbb{E}[W] = \\frac{q}{1 - \\exp(-q/\\sigma)} - \\sigma\n$$\nThis completes the first part of the problem.\n\nSecond, we find the quantization policy $q(\\sigma, \\gamma)$ that achieves the goal $\\mathbb{E}[W] = \\gamma \\mathbb{E}[S]$.\nThe policy goal is expressed by the equation:\n$$\n\\mathbb{E}[W] = \\gamma \\sigma\n$$\nSubstituting our derived expression for $\\mathbb{E}[W]$:\n$$\n\\frac{q}{1 - \\exp(-q/\\sigma)} - \\sigma = \\gamma \\sigma\n$$\nWe need to solve this equation for $q$. First, we rearrange the terms:\n$$\n\\frac{q}{1 - \\exp(-q/\\sigma)} = \\sigma + \\gamma \\sigma = (1 + \\gamma)\\sigma\n$$\nTo simplify, we introduce the dimensionless variable $z = q/\\sigma$. The equation becomes:\n$$\n\\frac{z\\sigma}{1 - \\exp(-z)} = (1 + \\gamma)\\sigma\n$$\n$$\nz = (1 + \\gamma)(1 - \\exp(-z))\n$$\nThis is a transcendental equation for $z$. To solve it, we rearrange it into a form suitable for the Lambert W function, which is defined by the relation $W(x)\\exp(W(x)) = x$.\n$$\nz = (1 + \\gamma) - (1 + \\gamma)\\exp(-z)\n$$\n$$\nz - (1 + \\gamma) = -(1 + \\gamma)\\exp(-z)\n$$\nMultiply by $\\exp(z)$,\n$$\n(z - (1 + \\gamma))\\exp(z) = -(1 + \\gamma)\n$$\nLet $u = z - (1 + \\gamma)$, which means $z = u + 1 + \\gamma$. Substituting this into the equation:\n$$\nu \\exp(u + 1 + \\gamma) = -(1 + \\gamma)\n$$\n$$\nu \\exp(u) \\exp(1 + \\gamma) = -(1 + \\gamma)\n$$\n$$\nu \\exp(u) = -(1 + \\gamma) \\exp(-(1 + \\gamma))\n$$\nThis equation is of the form $u \\exp(u) = x$, where $x = -(1 + \\gamma)\\exp(-(1 + \\gamma))$. The solution for $u$ is given by the Lambert W function, $u = W(x)$.\nSince $\\gamma \\in (0, \\infty)$, we have $1+\\gamma > 1$. The argument $x$ is of the form $-v \\exp(-v)$ with $v = 1+\\gamma > 1$. For $v>1$, the value of $-v \\exp(-v)$ lies in the interval $(-1/e, 0)$. In this interval, the Lambert W function has two real branches: the principal branch $W_0(x)$ and the lower branch $W_{-1}(x)$.\nThe solutions for $u$ are:\n1.  $u_1 = W_{-1}(-(1 + \\gamma)\\exp(-(1 + \\gamma)))$. For an argument of the form $v\\exp(v)$, if $v \\le -1$, $W_{-1}(v\\exp(v))=v$. Our argument has $-(1+\\gamma) \\le -1$, so $u_1 = -(1+\\gamma)$. This leads to $z = u_1 + (1+\\gamma) = -(1+\\gamma)+(1+\\gamma) = 0$, implying $q=0$. This is a trivial solution that only satisfies the original policy equation if $\\gamma=0$, which is excluded by the problem statement.\n2.  $u_2 = W_0(-(1 + \\gamma)\\exp(-(1 + \\gamma)))$. This corresponds to the non-trivial physical solution. Conventionally, $W_0$ is written as just $W$.\nSo, the physically relevant solution is:\n$$\nu = W(-(1 + \\gamma)\\exp(-(1 + \\gamma)))\n$$\nNow, we solve for $z$:\n$$\nz = u + 1 + \\gamma = 1 + \\gamma + W(-(1 + \\gamma)\\exp(-(1 + \\gamma)))\n$$\nFinally, we substitute back $z=q/\\sigma$ to find the policy $q(\\sigma, \\gamma)$:\n$$\nq(\\sigma, \\gamma) = \\sigma z = \\sigma \\left( 1 + \\gamma + W(-(1 + \\gamma)\\exp(-(1 + \\gamma))) \\right)\n$$\nThis is the required closed-form expression for the quantization policy.", "answer": "$$\n\\boxed{\\sigma \\left( 1 + \\gamma + W\\left(-\\left(1 + \\gamma\\right)\\exp\\left(-\\left(1 + \\gamma\\right)\\right)\\right) \\right)}\n$$", "id": "3644928"}, {"introduction": "Tracing garbage collectors automate memory reclamation, but they are not free; their work consumes CPU cycles. This practice contrasts the two foundational families of tracing algorithms: mark-sweep and semi-space copying, by having you build and analyze a formal cost model [@problem_id:3644886]. Rather than relying on a simple list of pros and cons, you will derive a quantitative relationship that captures their core performance trade-off, revealing how the efficiency of each algorithm depends on the characteristics of the live data, such as the number of objects versus their total size.", "problem": "A managed runtime uses two distinct heap management strategies for reclaiming memory: Mark-Sweep Garbage Collection (GC) and Semi-Space Copying Garbage Collection (GC). The heap at the instant of collection can be modeled as a directed graph of live objects and pointers, called the live object graph. Let the live object graph be denoted by $G = (V,E)$ where $|V|$ is the number of live objects and $|E|$ is the number of live pointer fields among those objects. Assume that every edge in $E$ corresponds to a unique pointer field stored in exactly one object in $V$. For this analysis, ignore the cost of scanning the root set and ignore the sweep of dead memory.\n\nAdopt the following cost model for primitive operations:\n- Setting or testing an object’s mark bit, header flag, or forwarding state during traversal incurs a constant cost of $\\alpha$ per live object visited.\n- Scanning a single pointer field (that is, reading the field and performing the requisite reachability or forwarding check) incurs a constant cost of $\\beta$ per edge scanned.\n- Copying an object’s payload incurs a cost proportional to the number of bytes moved; for an object of payload size $b$ bytes this cost is $\\gamma b$. Assume all live objects have identical payload size $\\bar{b}$ bytes.\n\nUnder this model, and using only graph-theoretic accounting grounded in the definition of reachability and traversal invariants, derive closed-form expressions for the total live set traversal cost of:\n- Mark-Sweep GC, which marks all reachable objects and scans their outgoing pointer fields.\n- Semi-Space Copying GC (for example, Cheney’s algorithm), which evacuates each reachable object exactly once and scans all outgoing pointer fields exactly once.\n\nReport your final answer as the simplified analytic expression for the ratio $R$ of the copying collector’s total live set traversal cost to the mark-sweep collector’s total live set traversal cost, expressed in terms of $|V|$, $|E|$, $\\alpha$, $\\beta$, $\\gamma$, and $\\bar{b}$. Do not include any asymptotic notation. Your final answer should be a single closed-form expression.", "solution": "The problem requires the derivation of an analytical expression for the ratio of the total live set traversal costs of two different garbage collection algorithms: Semi-Space Copying and Mark-Sweep. The analysis will be performed based on the provided cost model and a graph-theoretic representation of the memory heap. Let the live object graph be $G = (V, E)$, where $|V|$ is the number of live objects and $|E|$ is the number of pointers between them. Let $C_{MS}$ be the cost for Mark-Sweep GC and $C_{Copy}$ be the cost for Semi-Space Copying GC.\n\nFirst, we determine the total cost for Mark-Sweep Garbage Collection, $C_{MS}$. The problem describes this process as consisting of two main operations on the live set: marking reachable objects and scanning their pointer fields.\n1.  Marking Cost: The traversal must visit every live object to set its mark bit. There are $|V|$ live objects. The cost per object for this operation is given as $\\alpha$. Therefore, the total cost for marking all $|V|$ objects is $\\alpha |V|$.\n2.  Scanning Cost: The traversal must examine every pointer field within the live objects to discover the full extent of the reachable graph. The total number of such pointer fields is $|E|$. The cost to scan a single pointer is given as $\\beta$. Consequently, the total cost for scanning all pointers is $\\beta |E|$.\n\nThe problem specifies to ignore other costs, such as scanning the root set and sweeping dead memory. Thus, the total live set traversal cost for the Mark-Sweep collector is the sum of the marking and scanning costs:\n$$C_{MS} = \\alpha |V| + \\beta |E|$$\n\nNext, we determine the total cost for Semi-Space Copying Garbage Collection, $C_{Copy}$. This algorithm's cost, according to the provided model, is composed of three components:\n1.  Object State Management Cost: Each live object is visited and processed exactly once. This processing involves checking the object's state (e.g., if it has already been forwarded) and, if it is being evacuated for the first time, setting a forwarding pointer. The model specifies a cost of $\\alpha$ for such operations per object visited. For all $|V|$ live objects, this contributes a total cost of $\\alpha |V|$.\n2.  Object Copying Cost: Each of the $|V|$ live objects is physically copied from its current location (from-space) to a new location (to-space). All objects are assumed to have a uniform payload size of $\\bar{b}$ bytes. The cost of copying is $\\gamma$ per byte. The cost to copy one object is $\\gamma \\bar{b}$. Therefore, the total cost to copy all $|V|$ objects is $\\gamma \\bar{b} |V|$.\n3.  Scanning Cost: Similar to Mark-Sweep, the copying collector must scan all pointer fields of the live objects to update them to point to the new locations in to-space and to find further objects to copy. This involves scanning each of the $|E|$ pointers exactly once. At a cost of $\\beta$ per pointer, the total scanning cost is $\\beta |E|$.\n\nSumming these three components gives the total live set traversal cost for the Semi-Space Copying collector:\n$$C_{Copy} = \\alpha |V| + \\gamma \\bar{b} |V| + \\beta |E|$$\nThis expression can be rearranged by factoring out the common term $|V|$:\n$$C_{Copy} = (\\alpha + \\gamma \\bar{b})|V| + \\beta |E|$$\n\nFinally, the problem asks for the ratio $R$ of the copying collector’s cost to the mark-sweep collector’s cost.\n$$R = \\frac{C_{Copy}}{C_{MS}}$$\nSubstituting the derived expressions for $C_{Copy}$ and $C_{MS}$:\n$$R = \\frac{(\\alpha + \\gamma \\bar{b})|V| + \\beta |E|}{\\alpha |V| + \\beta |E|}$$\nTo simplify this expression, we can separate the numerator into two parts, one of which is identical to the denominator:\n$$R = \\frac{(\\alpha |V| + \\beta |E|) + \\gamma \\bar{b} |V|}{\\alpha |V| + \\beta |E|}$$\nSplitting the fraction yields:\n$$R = \\frac{\\alpha |V| + \\beta |E|}{\\alpha |V| + \\beta |E|} + \\frac{\\gamma \\bar{b} |V|}{\\alpha |V| + \\beta |E|}$$\nThe first term simplifies to $1$, resulting in the final closed-form expression for the ratio:\n$$R = 1 + \\frac{\\gamma \\bar{b} |V|}{\\alpha |V| + \\beta |E|}$$\nThis expression is the simplified analytical result for the requested ratio, expressed in terms of the given parameters $|V|$, $|E|$, $\\alpha$, $\\beta$, $\\gamma$, and $\\bar{b}$.", "answer": "$$\\boxed{1 + \\frac{\\gamma \\bar{b} |V|}{\\alpha |V| + \\beta |E|}}$$", "id": "3644886"}, {"introduction": "Modern garbage collectors employ sophisticated optimizations, with generational collection being one of the most effective. This strategy is based on the \"generational hypothesis\"—that most objects die young. This exercise presents a practical scenario where this hypothesis is violated, leading to a performance pathology known as premature tenuring [@problem_id:3644927]. Your task is to act as a performance engineer: use the system's specifications to diagnose the root cause of the issue and then evaluate modern, compiler-driven mitigation strategies, gaining insight into the dynamic interplay between application behavior and the garbage collector.", "problem": "A managed runtime with a generational copying heap uses the following well-tested facts and core definitions as its allocation and collection base. The young generation consists of Eden and two survivor spaces that are alternated as from-space and to-space during a minor collection. The Garbage Collector (GC) implements the generational hypothesis that most objects die young and therefore performs frequent minor collections that copy live young objects into the to-space and increment an object’s age by $1$. Any live object whose age reaches a tenuring threshold $a_T$ is promoted to the old generation. In addition, to guarantee progress, if the sum of live bytes to be copied would exceed the to-space capacity $C_T$, the collector promotes any remaining survivors to the old generation regardless of age. Old-to-young pointers are tracked by a remembered set and treat the young targets as roots at minor collection time. Assume a single-threaded allocation context with a Thread-Local Allocation Buffer and a Just-In-Time (JIT) compiler that can honor programmer-supplied annotations influencing escape analysis and region placement. Consider the following fixed parameters: Eden capacity $C_E = 8\\,\\mathrm{MB}$, to-space capacity $C_T = 1\\,\\mathrm{MB}$, tenuring threshold $a_T = 10$, per-request context size $s_R = 4\\,\\mathrm{KB}$, and temporary buffer size $s_B = 96\\,\\mathrm{KB}$. Suppose a long-lived cache object $C$ is known to reside in the old generation once created. You are asked to reason from these base definitions and capacities to determine which combination of object graph shape and compiler annotations will both (i) actually cause premature tenuring under the stated policy and (ii) plausibly mitigate it by delaying promotion or bypassing the generational assumption via stack or region allocation. Select the single best option.\n\nA. Object graph: An old-generation cache $C$ holds a vector of $N$ per-request contexts $R_i$ ($1 \\le i \\le N$), each $R_i$ strongly references a single temporary buffer $B_i$ of size $s_B$. During a burst, $N = 12$, so the live young set reachable from $C$ at a minor collection is $\\sum_{i=1}^{12} (s_R + s_B) = 12 \\times (4\\,\\mathrm{KB} + 96\\,\\mathrm{KB}) = 12 \\times 100\\,\\mathrm{KB} = 1200\\,\\mathrm{KB} > C_T$. Compiler annotations: Mark the allocation sites of $B_i$ with `@NoEscape` to assert non-escape from the request handler, enabling stack allocation or scalar replacement, and annotate $R_i$ and $B_i$ with `@Region(\"Request\")` to place them in a request-scoped region reclaimed en masse at request end. This removes old-to-young edges from $C$ to $B_i$ and prevents copying into survivor spaces.\n\nB. Object graph: A chain $Y_1 \\rightarrow Y_2 \\rightarrow \\dots \\rightarrow Y_k$ of $k$ young-only objects, each of size $s_Y = 32\\,\\mathrm{KB}$, no references from old-generation objects, with $k = 20$. The chain is reachable only from the thread’s stack during computation and becomes unreachable after the computation. Compiler annotations: Mark $Y_j$ with `@ForceOldGen` to allocate directly in the old generation to avoid minor collections.\n\nC. Object graph: A single temporary large array `$L$` of size `$s_L = 512\\,\\mathrm{KB}$` created and discarded within a tight loop, with no old-generation references. The heap uses a large-object threshold `$T_L = 256\\,\\mathrm{KB}$` so that objects with `$s \\ge T_L$` are allocated directly in the old generation. Compiler annotations: Mark `$L$` with `@PinYoung` to keep it in the young generation until death.\n\nD. Object graph: Same as option A except the cache $C$ stores weak references to $R_i$ via a `@Weak` annotation on the field type, leaving all else unchanged. Compiler annotations: None beyond `@Weak`; rely on the collector’s weak-reference processing to reduce retention and promotion.", "solution": "The problem statement is first validated for scientific soundness, consistency, and completeness.\n\n### Step 1: Extract Givens\n- **Runtime Environment**: A managed runtime with a generational copying heap.\n- **Heap Structure**:\n    - Young Generation: Consists of Eden and two survivor spaces (from-space and to-space).\n    - Eden Capacity: $C_E = 8\\,\\mathrm{MB}$.\n    - To-space Capacity: $C_T = 1\\,\\mathrm{MB}$.\n- **Garbage Collection (GC) Policy**:\n    - Minor collections are frequent, copying live young objects to to-space.\n    - Object age is incremented by $1$ upon being copied.\n    - Tenuring Threshold: An object is promoted to the old generation if its age reaches $a_T = 10$.\n    - **Premature Tenuring**: If the total size of live young objects to be copied to to-space exceeds $C_T$, remaining survivor objects are promoted to the old generation regardless of their age.\n    - Old-to-young pointers are tracked in a remembered set and serve as roots for minor collections.\n- **Execution and Compilation**:\n    - Single-threaded allocation context with a Thread-Local Allocation Buffer (TLAB).\n    - Just-In-Time (JIT) compiler honors programmer annotations for escape analysis and region placement.\n- **Object Parameters**:\n    - A long-lived cache object $C$ resides in the old generation.\n    - Per-request context size: $s_R = 4\\,\\mathrm{KB}$.\n    - Temporary buffer size: $s_B = 96\\,\\mathrm{KB}$.\n- **Task**: Identify the option describing an object graph and compiler annotations that (i) causes premature tenuring and (ii) plausibly mitigates it.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a standard generational garbage collection scheme, a cornerstone of modern managed runtimes like the Java Virtual Machine (JVM) or the .NET Common Language Runtime (CLR). The concepts presented—such as Eden, survivor spaces, tenuring, remembered sets, and premature promotion due to survivor space overflow—are well-established and textbook material in computer science, specifically in the sub-field of compiler design and runtime systems.\n\n- **Scientifically Grounded**: The model of the GC is a valid and widely used one. The generational hypothesis, escape analysis, and region-based allocation are all grounded in established computer science principles and research.\n- **Well-Posed**: The problem is clearly defined. The condition for premature tenuring is explicitly stated: the sum of live bytes to be copied exceeds $C_T$. The parameters are quantitative, allowing for a direct evaluation of this condition. The task is to evaluate a set of scenarios against this well-defined model. A single best answer can be determined through logical deduction.\n- **Objective**: The problem is stated in precise, technical language, free of subjectivity. The parameters and policies are objective.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is scientifically sound, well-posed, objective, and contains sufficient information to proceed with a solution.\n\n### Derivation of the Correct Answer\n\nThe core of the problem is to identify a scenario that fulfills two conditions:\n(i) **Cause Premature Tenuring**: The total size of the live objects in the young generation that need to be copied during a minor collection must exceed the to-space capacity, $C_T = 1\\,\\mathrm{MB}$. We will use the standard conversion $1\\,\\mathrm{MB} = 1024\\,\\mathrm{KB}$. Thus, $C_T = 1024\\,\\mathrm{KB}$.\n(ii) **Plausible Mitigation**: The proposed compiler annotations must represent a credible and effective strategy for alleviating the issue of premature tenuring.\n\nWe will now analyze each option against these two conditions.\n\n### Option-by-Option Analysis\n\n**A. Object graph: An old-generation cache $C$ holds a vector of $N$ per-request contexts $R_i$ ($1 \\le i \\le N$), each $R_i$ strongly references a single temporary buffer $B_i$ of size $s_B$. During a burst, $N = 12$, so the live young set reachable from $C$ at a minor collection is $\\sum_{i=1}^{12} (s_R + s_B) = 12 \\times (4\\,\\mathrm{KB} + 96\\,\\mathrm{KB}) = 12 \\times 100\\,\\mathrm{KB} = 1200\\,\\mathrm{KB} > C_T$. Compiler annotations: Mark the allocation sites of $B_i$ with `@NoEscape` to assert non-escape from the request handler, enabling stack allocation or scalar replacement, and annotate $R_i$ and $B_i$ with `@Region(\"Request\")` to place them in a request-scoped region reclaimed en masse at request end. This removes old-to-young edges from $C$ to $B_i$ and prevents copying into survivor spaces.**\n\n1.  **Cause Premature Tenuring (i)**:\n    - The object graph places a long-lived cache `$C$` in the old generation. It holds strong references to `$N=12$` young objects, pairs of ($R_i, B_i$).\n    - Because of the old-to-young strong references, the remembered set ensures that all 12 pairs of ($R_i, B_i$) are treated as roots during a minor GC and are thus live.\n    - The total size of this live set is calculated in the problem as $1200\\,\\mathrm{KB}$.\n    - We compare this to the to-space capacity: $C_T = 1\\,\\mathrm{MB} = 1024\\,\\mathrm{KB}$.\n    - Since $1200\\,\\mathrm{KB} > 1024\\,\\mathrm{KB} = C_T$, the set of live objects to be copied exceeds the to-space capacity. This will trigger the premature tenuring policy. Condition (i) is met.\n\n2.  **Plausible Mitigation (ii)**:\n    - The proposed annotations are `@NoEscape` and `@Region`.\n    - `@NoEscape`: This annotation is a hint for escape analysis. If the compiler can prove an object does not escape the current method's scope, it can allocate it on the stack instead of the heap. Stack-allocated objects are automatically reclaimed when the method returns and are never seen by the GC. This would eliminate the objects from the minor GC's live set. This is a highly effective and plausible mitigation strategy.\n    - `@Region(\"Request\")`: This suggests region-based memory management. Objects are allocated into a dedicated memory region that is reclaimed in its entirety when the request is complete. This bypasses the generational GC mechanism (copying, aging, promotion). This is also a valid and effective advanced memory management strategy.\n    - Both proposed mitigations directly address the problem by removing the pressure on the young generation's survivor space. Condition (ii) is met.\n\n**Verdict**: **Correct**. This option accurately describes a scenario that causes premature tenuring and proposes sound, plausible, and effective mitigation techniques.\n\n**B. Object graph: A chain $Y_1 \\rightarrow Y_2 \\rightarrow \\dots \\rightarrow Y_k$ of $k$ young-only objects, each of size $s_Y = 32\\,\\mathrm{KB}$, no references from old-generation objects, with $k = 20$. The chain is reachable only from the thread’s stack during computation and becomes unreachable after the computation. Compiler annotations: Mark $Y_j$ with `@ForceOldGen` to allocate directly in the old generation to avoid minor collections.**\n\n1.  **Cause Premature Tenuring (i)**:\n    - The total size of the live object chain is $S_{live} = k \\times s_Y = 20 \\times 32\\,\\mathrm{KB} = 640\\,\\mathrm{KB}$.\n    - We compare this to the to-space capacity: $C_T = 1024\\,\\mathrm{KB}$.\n    - Since $S_{live} = 640\\,\\mathrm{KB}  1024\\,\\mathrm{KB} = C_T$, the live set fits comfortably within the to-space. Premature tenuring will not be triggered. Condition (i) is not met.\n\n2.  **Plausible Mitigation (ii)**:\n    - The proposed mitigation is `@ForceOldGen`, which allocates objects directly into the old generation. While this would \"mitigate\" pressure on the young generation, it's a solution for a problem that does not exist in this scenario. Furthermore, forcing short-lived (\"young-only\") objects into the old generation is a severe anti-pattern that leads to pollution of the old generation, requiring more frequent and expensive full GCs. It is not a plausible or good mitigation for this object lifecycle.\n\n**Verdict**: **Incorrect**. The scenario does not cause premature tenuring.\n\n**C. Object graph: A single temporary large array `$L$` of size `$s_L = 512\\,\\mathrm{KB}$` created and discarded within a tight loop, with no old-generation references. The heap uses a large-object threshold `$T_L = 256\\,\\mathrm{KB}$` so that objects with `$s \\ge T_L$` are allocated directly in the old generation. Compiler annotations: Mark `$L$` with `@PinYoung` to keep it in the young generation until death.**\n\n1.  **Cause Premature Tenuring (i)**:\n    - This option introduces a new rule: a large-object threshold $T_L = 256\\,\\mathrm{KB}$. The array $L$ has size $s_L = 512\\,\\mathrm{KB}$.\n    - By default, since $s_L > T_L$, the array $L$ would be allocated directly in the old generation's large object space. It would never be in Eden or a survivor space and thus could not trigger premature tenuring during a minor collection.\n    - The annotation `@PinYoung` is proposed to override this default. If we assume the annotation forces the array into the young generation, let's analyze the consequence. At a minor GC, the live set would be this single array of size $S_{live} = 512\\,\\mathrm{KB}$.\n    - We compare this to the to-space capacity: $C_T = 1024\\,\\mathrm{KB}$.\n    - Since $S_{live} = 512\\,\\mathrm{KB}  1024\\,\\mathrm{KB} = C_T$, the live object fits within the to-space. Premature tenuring is not triggered. Condition (i) is not met, either with or without the annotation.\n    - The option's logic is flawed; the annotation is presented as a \"mitigation\", but it is actually what creates the (non-problematic) load on the young generation.\n\n**Verdict**: **Incorrect**. The scenario does not cause premature tenuring, even under the influence of the proposed annotation.\n\n**D. Object graph: Same as option A except the cache $C$ stores weak references to $R_i$ via a `@Weak` annotation on the field type, leaving all else unchanged. Compiler annotations: None beyond `@Weak`; rely on the collector’s weak-reference processing to reduce retention and promotion.**\n\n1.  **Cause Premature Tenuring (i)**:\n    - The graph is the same as A, but the references from the old-generation cache `$C$` to the young-generation objects `$R_i$` are weak.\n    - A weak reference does not keep an object alive. If the only references to the `$R_i$` and `$B_i$` objects are the weak ones from `$C$`, they will be garbage collected during the next minor GC. The live set to be copied would be $0$, and no premature tenuring would occur. In this case, condition (i) is not met.\n    - Alternatively, let's assume the `$R_i$` objects are also strongly-referenced from the stack (e.g., the requests are still active). In this case, they are live. The live set size is again $1200\\,\\mathrm{KB}$, and premature tenuring occurs. Condition (i) is met under this assumption.\n\n2.  **Plausible Mitigation (ii)**:\n    - The mitigation proposed is the use of `@Weak` itself. If we are in the case where premature tenuring occurs (i.e., strong references from the stack exist), the weak references from `$C$` are irrelevant to the liveness of the objects. The objects are live due to the strong references. The GC's weak-reference processing will not \"reduce retention and promotion\" for objects that are strongly reachable. Therefore, the mitigation is ineffective.\n    - If we are in the case where only weak references exist, then the problem of premature tenuring never arose in the first place.\n    - In neither interpretation does the option successfully present a scenario that both causes the problem and is then plausibly mitigated by the proposed mechanism.\n\n**Verdict**: **Incorrect**. The logic is circular and fails to satisfy both conditions simultaneously. The proposed mitigation is either irrelevant or it prevents the problem from occurring at all.\n\n### Conclusion\nOnly Option A correctly presents a scenario where the live set size ($1200\\,\\mathrm{KB}$) exceeds a to-space capacity of $1\\,\\mathrm{MB}$ ($1024\\,\\mathrm{KB}$), thus causing premature tenuring, and proposes a set of standard, effective, and plausible compiler optimizations (escape analysis, region-based allocation) to mitigate the problem.", "answer": "$$\\boxed{A}$$", "id": "3644927"}]}