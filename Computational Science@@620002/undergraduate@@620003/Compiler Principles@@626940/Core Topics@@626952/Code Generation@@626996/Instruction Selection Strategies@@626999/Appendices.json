{"hands_on_practices": [{"introduction": "Effective instruction selection often begins by transforming expensive operations into cheaper equivalents, a technique known as strength reduction. This first practice challenges you to think like an optimizing compiler faced with a multiplication by a constant. You will discover how the binary representation of a number can unlock different, and sometimes surprisingly efficient, instruction sequences using only shifts, additions, and subtractions, providing a tangible example of how low-level data representation directly impacts code performance [@problem_id:3646809].", "problem": "A compiler backend targets an architecture whose instruction set contains three relevant operations with the following semantics and costs:\n- Left shift by an immediate amount: for any register value $v$ and nonnegative integer $p$, the operation returns $v \\ll p$ and costs $c_{s} = 3$ cycles.\n- Addition of two registers: for any register values $u$ and $v$, the operation returns $u + v$ and costs $c_{a} = 5$ cycles.\n- Subtraction of two registers: for any register values $u$ and $v$, the operation returns $u - v$ and costs $c_{a} = 5$ cycles.\n\nAssume unlimited registers and that copying a value between registers has negligible cost. A left shift by $p=0$ is a no-op and incurs zero cost. The compiler must implement the multiplication by a known, fixed integer constant $k$ using only these operations. The target program computes $y = k \\cdot x$ for an input register $x$. The instruction selector is restricted to strategies that form $y$ as a finite linear combination of shifted instances of $x$ with signs, specifically $y = \\sum_{i=1}^{m} s_{i} \\cdot (x \\ll p_{i})$, where each $s_{i} \\in \\{+1,-1\\}$ and each $p_{i}$ is a nonnegative integer. The combination is realized with binary additions and subtractions; no other operation is permitted.\n\nStarting from the foundational facts of binary representation and the identity $x \\ll p = x \\cdot 2^{p}$, derive the minimal-cost instruction sequence under this restriction for the case $k = 1023$. Express the minimal total cost in cycles as a single real-valued number. No rounding is necessary.", "solution": "The problem requires finding the minimal cost to compute $y = k \\cdot x$ for $k = 1023$, using a sequence of shift, add, and subtract operations. The allowed computational structure is $y = \\sum_{i=1}^{m} s_{i} \\cdot (x \\ll p_{i})$, where $s_i \\in \\{+1,-1\\}$. This is equivalent to finding a representation of the constant $k$ of the form $k = \\sum_{i=1}^{m} s_{i} \\cdot 2^{p_{i}}$ that minimizes the total instruction cost.\n\nThe total cost $C$ is the sum of the costs of the shift operations and the costs of the addition/subtraction operations.\nTo compute $y$, we first need to generate $m$ terms of the form $x \\ll p_i$. Then, these $m$ terms must be combined using $m-1$ additions or subtractions.\n\nLet's define the cost function more precisely.\n- The cost of a shift $x \\ll p_i$ is $c_s = 3$ if $p_i > 0$, and $0$ if $p_i = 0$. Let $N_s$ be the number of terms in the sum where $p_i > 0$. The total cost for shifts is $N_s \\cdot c_s$.\n- The cost of combining $m$ terms requires $m-1$ binary operations (additions or subtractions). The cost of each is $c_a = 5$. The total cost for these is $(m-1) \\cdot c_a$.\n\nThe total cost $C$ for a given representation is therefore:\n$$C = N_s \\cdot c_s + (m-1) \\cdot c_a$$\nSubstituting the given costs, $c_s = 3$ and $c_a = 5$:\n$$C = 3N_s + 5(m-1)$$\n\nTo minimize $C$, we must find a representation for $k=1023$ that minimizes $m$ and $N_s$. Since $c_a > c_s$, minimizing $m$ (the number of terms) is the primary factor in reducing the cost.\n\nWe will explore two strategies for representing $k = 1023$.\n\n**Strategy 1: Standard Binary Representation**\n\nFirst, we express $k=1023$ in its standard binary form.\n$1023$ is $2^{10} - 1$. In binary, this is a sequence of ten $1$s: $1111111111_{2}$.\nThis corresponds to the sum:\n$$k = 1023 = \\sum_{i=0}^{9} 1 \\cdot 2^i = 2^9 + 2^8 + 2^7 + 2^6 + 2^5 + 2^4 + 2^3 + 2^2 + 2^1 + 2^0$$\nFor this representation:\n- The number of terms is $m = 10$.\n- The powers $p_i$ are $\\{9, 8, 7, 6, 5, 4, 3, 2, 1, 0\\}$.\n- The number of shifts with $p_i > 0$ is $N_s = 9$. The term $2^0$ corresponds to $x \\ll 0$, which has a cost of $0$.\n- The number of additions required to sum these $10$ terms is $m-1 = 9$.\n\nThe total cost for this strategy, $C_1$, is:\n$$C_1 = 3 \\cdot N_s + 5 \\cdot (m-1) = 3 \\cdot 9 + 5 \\cdot (10-1) = 27 + 5 \\cdot 9 = 27 + 45 = 72$$\nSo, the cost using the standard binary expansion is $72$ cycles.\n\n**Strategy 2: Representation using Subtraction (Non-Adjacent Form)**\n\nA sequence of consecutive $1$s in a binary representation can be simplified using the identity $\\sum_{i=j}^{n-1} 2^i = 2^n - 2^j$.\nFor $k=1023$, which is $\\sum_{i=0}^{9} 2^i$, we have $n=10$ and $j=0$.\n$$k = 1023 = 2^{10} - 2^0 = 1024 - 1$$\nThis is a representation of $k$ as a difference of two powers of $2$.\n$$k = 1 \\cdot 2^{10} + (-1) \\cdot 2^0$$\nFor this representation:\n- The terms are $2^{10}$ and $-2^0$. The number of terms is $m=2$.\n- The powers $p_i$ are $\\{10, 0\\}$.\n- The number of shifts with $p_i > 0$ is $N_s = 1$ (for the $p_1=10$ term). The $p_2=0$ term has zero shift cost.\n- The number of operations to combine these $2$ terms is $m-1 = 1$ (a single subtraction).\n\nThe total cost for this strategy, $C_2$, is:\n$$C_2 = 3 \\cdot N_s + 5 \\cdot (m-1) = 3 \\cdot 1 + 5 \\cdot (2-1) = 3 + 5 = 8$$\nSo, the cost using this more compact representation is $8$ cycles.\n\n**Optimality Analysis**\n\nWe have found two possible costs, $C_1 = 72$ and $C_2 = 8$. The minimal cost found so far is $8$. We must determine if a lower cost is possible.\nThe cost function $C = 3N_s + 5(m-1)$ increases with $m$ and $N_s$. To achieve a minimal cost, we must use the smallest possible values for $m$ and $N_s$.\n\n- A representation with $m=1$ would mean $k$ is a power of $2$. Since $1023$ is not a power of $2$, we must have $m \\ge 2$.\n- The representation $k = 2^{10} - 1$ uses the minimum possible number of terms, $m=2$.\n- With $m=2$, the cost is $C = 3N_s + 5(2-1) = 3N_s + 5$.\n- To represent $1023$, we must have at least one non-zero power of $2$ (i.e. $p_i > 0$), so $N_s \\ge 1$.\n- The representation $2^{10} - 1$ has one non-zero power ($2^{10}$), so $N_s=1$.\nThis configuration ($m=2, N_s=1$) yields a cost of $3 \\cdot 1 + 5 = 8$. This is the minimum possible cost for any representation with $m=2$ terms.\n\nAny representation with $m \\ge 3$ terms would have a cost $C = 3N_s + 5(m-1) \\ge 3 \\cdot N_s + 5(3-1) = 3N_s + 10$. Since $N_s \\ge 1$, this cost would be at least $13$, which is greater than $8$.\n\nTherefore, the representation of $k = 1023$ as $2^{10} - 1$ is optimal, and the minimal cost is $8$ cycles.\n\nThe instruction sequence would be:\n1.  Compute `t_1 = x  10`. Cost: $3$ cycles.\n2.  The value $x$ is `x  0`. Cost: $0$ cycles.\n3.  Compute `y = t_1 - x`. Cost: $5$ cycles.\nTotal cost: $3 + 0 + 5 = 8$ cycles.", "answer": "$$\n\\boxed{8}\n$$", "id": "3646809"}, {"introduction": "Building on the theme of pattern matching, this exercise moves from pure arithmetic to the critical domain of memory access. Compilers spend much of their effort optimizing loops that process data in arrays, where calculating memory addresses is a key overhead. This practice demonstrates how an instruction selector can leverage an architecture's complex addressing modes to fuse several simple IR operations—like scaling an index and adding a base address—into a single, powerful machine instruction, leading to significant performance gains in common code patterns [@problem_id:3646830].", "problem": "A compiler back end must generate target code for a tight loop in an Intermediate Representation (IR) that performs the element-wise update `a[i] = a[i] + k` on a contiguous array of $n$ $64$-bit integers. The Intermediate Representation (IR) uses three-address code with explicit address arithmetic and load/store operations, and the target machine supports a scaled indexed addressing mode.\n\nThe loop body in IR (using temporaries $t_1, t_2, \\dots$) is:\nL:\n$t_1 \\leftarrow i \\times w$\n$t_2 \\leftarrow base\\_a + t_1$\n$t_3 \\leftarrow \\text{load}(t_2)$\n$t_4 \\leftarrow t_3 + k$\n$\\text{store}(t_2, t_4)$\n$i \\leftarrow i + 1$\nif $i  n$ goto L\n\nAssume the following:\n- The element size is $w = 8$ bytes, so `a[i]` resides at address $base\\_a + i \\times w$.\n- The target machine supports a memory operand of the form $[r_b + r_i \\times s]$ in both load and store instructions, where $s \\in \\{1, 2, 4, 8\\}$.\n- The loop index $i$, bound $n$, constant $k$, and base address $base\\_a$ are all kept in registers throughout the loop. Ignore loop setup costs and assume no register spills.\n- The cost model (latency per dynamic instruction) is:\n  - Integer addition or subtraction: $1$ cycle.\n  - Integer multiplication: $3$ cycles.\n  - Compare: $1$ cycle.\n  - Conditional branch (assume always correctly predicted): $1$ cycle.\n  - Load or store (with any legal addressing mode): $4$ cycles each.\n\nConsider two instruction selection strategies:\n- Strategy A (naïve): Materialize $i \\times w$ in a register and then add to $base\\_a$ each iteration to compute the address used by load and store.\n- Strategy B (addressing-mode folding): Use the scaled indexed addressing mode $[base\\_a + i \\times w]$ in both the load and the store, eliminating explicit computation of $i \\times w$ and the separate base addition in the loop body. The loop still increments $i$ by $1$ and performs the compare and branch.\n\nUsing only the assumptions above and starting from the given IR loop, derive the per-iteration dynamic cost for Strategy A and Strategy B, then compute the total cycle savings when processing $n = 4096$ elements with Strategy B instead of Strategy A. Express the final answer as a single exact real number. No rounding is required.", "solution": "We must analyze two instruction selection strategies for a given loop in an Intermediate Representation (IR), calculate their respective per-iteration costs, and determine the total cycle savings for a specific number of iterations. The loop performs $n$ iterations, where $n = 4096$.\n\nLet's denote the cost per iteration for Strategy A as $C_A$ and for Strategy B as $C_B$. The loop body in the IR is:\n1. $t_1 \\leftarrow i \\times w$\n2. $t_2 \\leftarrow base\\_a + t_1$\n3. $t_3 \\leftarrow \\text{load}(t_2)$\n4. $t_4 \\leftarrow t_3 + k$\n5. $\\text{store}(t_2, t_4)$\n6. $i \\leftarrow i + 1$\n7. if $i  n$ goto L\n\nThe machine instruction costs are given as:\n- Integer addition/subtraction: $1$ cycle\n- Integer multiplication: $3$ cycles\n- Compare: $1$ cycle\n- Conditional branch: $1$ cycle\n- Load or store: $4$ cycles\n\nThe element size is $w = 8$ bytes.\n\n**Analysis of Strategy A (Naïve)**\nThis strategy generates a separate machine instruction for each operation in the IR. We analyze the cost of the instructions corresponding to the loop body.\n\n1.  $t_1 \\leftarrow i \\times w$: This translates to a single integer multiplication instruction.\n    Cost: $3$ cycles.\n2.  $t_2 \\leftarrow base\\_a + t_1$: This is an integer addition to compute the final address.\n    Cost: $1$ cycle.\n3.  $t_3 \\leftarrow \\text{load}(t_2)$: A load instruction using the computed address in a register.\n    Cost: $4$ cycles.\n4.  $t_4 \\leftarrow t_3 + k$: The core element-wise addition.\n    Cost: $1$ cycle.\n5.  $\\text{store}(t_2, t_4)$: A store instruction using the same computed address.\n    Cost: $4$ cycles.\n6.  $i \\leftarrow i + 1$: The loop index increment.\n    Cost: $1$ cycle.\n7.  if $i  n$ goto L: This involves a comparison followed by a conditional branch.\n    - Compare $i$ with $n$: $1$ cycle.\n    - Conditional branch: $1$ cycle.\n    Total cost for loop control: $1 + 1 = 2$ cycles.\n\nThe total cost per iteration for Strategy A is the sum of these costs:\n$$ C_A = 3 (\\text{mul}) + 1 (\\text{add}) + 4 (\\text{load}) + 1 (\\text{add}) + 4 (\\text{store}) + 1 (\\text{inc}) + 1 (\\text{cmp}) + 1 (\\text{branch}) $$\n$$ C_A = 16 \\text{ cycles} $$\n\n**Analysis of Strategy B (Addressing-Mode Folding)**\nThis strategy utilizes the target machine's scaled indexed addressing mode, $[r_b + r_i \\times s]$, to combine the address calculation into the load and store instructions. Here, $r_b$ holds $base\\_a$, $r_i$ holds $i$, and the scale factor $s$ is set to the element width $w = 8$. The machine supports $s=8$, so this is a legal optimization.\n\n1.  $t_1 \\leftarrow i \\times w$ and $t_2 \\leftarrow base\\_a + t_1$: These two IR statements are not translated into separate machine instructions. Instead, their functionality is \"folded\" into the addressing mode of the memory operations.\n    Cost: $0$ cycles for explicit instructions.\n2.  $t_3 \\leftarrow \\text{load}(t_2)$: This becomes a single `load` instruction with the complex addressing mode $[base\\_a + i \\times 8]$. The problem states that the cost of a `load` is $4$ cycles, regardless of the addressing mode.\n    Cost: $4$ cycles.\n3.  $t_4 \\leftarrow t_3 + k$: The core element-wise addition remains.\n    Cost: $1$ cycle.\n4.  $\\text{store}(t_2, t_4)$: Similar to the `load`, this becomes a single `store` instruction using the $[base\\_a + i \\times 8]$ addressing mode. The cost is also $4$ cycles.\n    Cost: $4$ cycles.\n5.  $i \\leftarrow i + 1$: The loop index increment is unchanged.\n    Cost: $1$ cycle.\n6.  if $i  n$ goto L: The loop control logic is also unchanged.\n    - Compare $i$ with $n$: $1$ cycle.\n    - Conditional branch: $1$ cycle.\n    Total cost for loop control: $1 + 1 = 2$ cycles.\n\nThe total cost per iteration for Strategy B is the sum of these costs:\n$$ C_B = 4 (\\text{load}) + 1 (\\text{add}) + 4 (\\text{store}) + 1 (\\text{inc}) + 1 (\\text{cmp}) + 1 (\\text{branch}) $$\n$$ C_B = 12 \\text{ cycles} $$\n\n**Calculation of Total Savings**\nThe savings per iteration is the difference between the costs of the two strategies:\n$$ S_{\\text{iter}} = C_A - C_B = 16 - 12 = 4 \\text{ cycles} $$\nThis saving comes from eliminating the explicit `MUL` (cost $3$ cycles) and `ADD` (cost $1$ cycle) instructions used for address calculation in Strategy A.\n\nThe total number of elements to process is $n = 4096$. This corresponds to $4096$ iterations of the loop.\nThe total cycle savings, $S_{\\text{total}}$, is the per-iteration savings multiplied by the number of iterations:\n$$ S_{\\text{total}} = n \\times S_{\\text{iter}} = 4096 \\times 4 $$\n$$ S_{\\text{total}} = 16384 $$\nThe total cycle savings is $16384$.", "answer": "$$\\boxed{16384}$$", "id": "3646830"}, {"introduction": "Truly optimal code generation requires looking beyond individual operations to consider broader resource constraints. This final practice explores the crucial interplay between instruction selection and instruction scheduling when faced with hardware limitations, such as the maximum size of a constant that can be embedded in an instruction. You will navigate a scenario where large constants must be loaded into a limited number of registers, forcing you to reorder instructions to minimize costly memory loads and revealing how compilers must perform non-local reasoning to manage scarce resources effectively [@problem_id:3646810].", "problem": "You are targeting a simple scalar machine and must perform instruction selection for an Intermediate Representation (IR) basic block whose constants exceed the immediate-encoding range. The goal is to minimize the number of extra memory loads introduced solely to materialize large constants. Consider the following target and IR, and then choose the instruction-selection strategy that minimizes the number of literal loads per execution of the block.\n\nTarget machine model and constraints:\n- Immediate-encoding limit: an add-with-immediate instruction `ADDI R_d, R_s, imm` accepts only a signed `imm` in the range $[-2048, 2047]$ (that is, $12$-bit signed).\n- Register-register add `ADD R_d, R_s, R_t` is available and uses only registers.\n- Literal load: `LDRL R_d, [PC+off]` loads a full $32$-bit literal from a pool (Program Counter (PC)-relative). Each `LDRL` counts as exactly one “extra load” for the purpose of this problem.\n- Constant register constraint: the register allocator provides exactly one extra general-purpose register $r_c$ to hold any materialized literal. Any `LDRL` must target $r_c$. At any point, $r_c$ holds at most one literal value; changing the value in $r_c$ requires issuing another `LDRL` (one extra load). No other register may be used to hold a literal without spilling, which is disallowed here.\n- Mapping constraint: each IR addition must be implemented by exactly one machine `ADD` or exactly one machine `ADDI`. You may not decompose a single IR addition into multiple adds to “accumulate” a large constant. Bringing an operand (a large constant) into a register using `LDRL` is allowed, but the IR add itself is still exactly one `ADD` or one `ADDI`.\n- Scheduling: within the basic block, you may reorder instructions if and only if data dependencies are preserved. No algebraic reassociation (such as changing the grouping of additions or creating new constants) is allowed.\n\nIR basic block (three-address code; variables $a,b,c,d$ are live on entry):\n- `t_1 := add(a, 50000)`\n- `t_2 := add(b, 50000)`\n- `t_3 := add(t_1, t_2)`\n- `t_4 := add(c, 70000)`\n- `t_5 := add(t_3, 12)`\n- `t_6 := add(d, 1024)`\n- `t_7 := add(t_6, 50000)`\n\nFacts:\n- The immediates $12$ and $1024$ are within the $12$-bit signed range and thus can use `ADDI` without any literal loads.\n- The immediates $50000$ and $70000$ exceed the $12$-bit signed range and thus cannot be encoded in a single `ADDI`. To supply these to an `ADD`, you must materialize the constant in $r_c$ via `LDRL` and then use `ADD` with $r_c$ as the third operand.\n\nQuestion: Which strategy yields the minimal number of literal loads (i.e., `LDRL` instructions) per execution of the block, under the constraints above?\n\nA. Do not reorder. For every IR addition with a large constant, issue `LDRL r_c, const` immediately before the corresponding `ADD` that uses it.\n\nB. Do not reorder. Hoist and keep $50000$ in $r_c$ for the whole block (loading it once at block entry), using `ADD` wherever $50000$ is needed; when $70000$ is needed, change $r_c$ to $70000$ just before that use and then change $r_c$ back to $50000$ for the later use.\n\nC. Legally reorder independent IR statements to cluster all uses of $50000$ together before the single use of $70000$; keep $50000$ in $r_c$ across that cluster, then switch $r_c$ to $70000$ once for its use.\n\nD. Legally reorder as in option C, but instead hoist and keep $70000$ in $r_c$ and load $50000$ on each of its uses.", "solution": "The problem asks for the instruction-selection strategy that minimizes the number of literal loads (`LDRL` instructions) needed to handle large constants in a given Intermediate Representation (IR) basic block.\n\nFirst, let us formalize the IR and its dependencies. The IR instructions are:\n- `I_1: t_1 := add(a, 50000)`\n- `I_2: t_2 := add(b, 50000)`\n- `I_3: t_3 := add(t_1, t_2)`\n- `I_4: t_4 := add(c, 70000)`\n- `I_5: t_5 := add(t_3, 12)`\n- `I_6: t_6 := add(d, 1024)`\n- `I_7: t_7 := add(t_6, 50000)`\n\nThe data dependencies form a directed acyclic graph (DAG):\n- $I_1 \\rightarrow I_3$ (because $I_3$ uses $t_1$)\n- $I_2 \\rightarrow I_3$ (because $I_3$ uses $t_2$)\n- $I_3 \\rightarrow I_5$ (because $I_5$ uses $t_3$)\n- $I_6 \\rightarrow I_7$ (because $I_7$ uses $t_6$)\nInstruction $I_4$ is independent of all other instructions in the block, as it uses an input variable $c$ and produces a result $t_4$ that is not used within the block.\n\nThe machine constraints state that any immediate value outside the range $[-2048, 2047]$ must be loaded from a literal pool into the dedicated register $r_c$ using an `LDRL` instruction.\n- The constants $12$ and $1024$ are within range and can be encoded in an `ADDI` instruction without an extra load.\n- The constants $50000$ and $70000$ are outside this range. They require an `LDRL` to load the value into $r_c$, followed by an `ADD` instruction that uses $r_c$.\n\nThe large constants are used as follows:\n- The constant $50000$ is used in $I_1$, $I_2$, and $I_7$.\n- The constant $70000$ is used in $I_4$.\n\nThe goal is to minimize the total count of `LDRL` instructions. This can be achieved by intelligently scheduling instructions and managing the contents of the constant register $r_c$. We will now evaluate each proposed strategy.\n\n### Analysis of Option A\n\n**Strategy**: Do not reorder. For every IR addition with a large constant, issue `LDRL r_c, const` immediately before the corresponding `ADD`.\n\nThis is a naive, local strategy that does not attempt to reuse a constant already present in $r_c$. The instruction sequence is fixed as $I_1, I_2, I_3, I_4, I_5, I_6, I_7$.\n\n1.  For $I_1$ (uses $50000$): Issue `LDRL r_c, =50000`. (1 load)\n2.  For $I_2$ (uses $50000$): The strategy dictates issuing an `LDRL` for every use. Issue `LDRL r_c, =50000`. (2 loads)\n3.  $I_3$ has no large constant.\n4.  For $I_4$ (uses $70000$): Issue `LDRL r_c, =70000`. (3 loads)\n5.  $I_5$ and $I_6$ have small immediates.\n6.  For $I_7$ (uses $50000$): Issue `LDRL r_c, =50000`. (4 loads)\n\nTotal literal loads: $4$.\n\n### Analysis of Option B\n\n**Strategy**: Do not reorder. Hoist and keep $50000$ in $r_c$ (loading it once at block entry), but when $70000$ is needed, switch $r_c$ to $70000$, and then switch it back to $50000$ for the final use.\n\nThe instruction sequence is fixed. This strategy attempts to optimize reuse but is constrained by the fixed order.\n\n1.  At block entry: Issue `LDRL r_c, =50000`. (1 load)\n2.  For $I_1$ (uses $50000$): Use $r_c$. No new load.\n3.  For $I_2$ (uses $50000$): Use $r_c$. No new load.\n4.  $I_3$ has no large constant.\n5.  For $I_4$ (uses $70000$): The value in $r_c$ is $50000$. We must switch. Issue `LDRL r_c, =70000`. (2 loads)\n6.  After $I_4$, the strategy requires switching back to $50000$ for the later use in $I_7$. Issue `LDRL r_c, =50000`. (3 loads)\n7.  $I_5$ and $I_6$ have small immediates.\n8.  For $I_7$ (uses $50000$): Use $r_c$, which now holds $50000$. No new load.\n\nTotal literal loads: $3$.\n\n### Analysis of Option C\n\n**Strategy**: Legally reorder IR statements to cluster all uses of $50000$ together before the single use of $70000$. Keep $50000$ in $r_c$ during its uses, then switch to $70000$.\n\nThis strategy combines instruction scheduling with intelligent management of $r_c$. The goal is to perform all computations needing $50000$ before any computation needing $70000$. Since $I_4$ (using $70000$) is independent of the other instruction chains, it can be moved. A legal, reordered schedule is: $I_1, I_2, I_3, I_6, I_7, I_5, I_4$. A simpler one that also achieves the goal:\n1.  `I_1: t_1 := add(a, 50000)`\n2.  `I_2: t_2 := add(b, 50000)`\n3.  `I_6: t_6 := add(d, 1024)`\n4.  `I_7: t_7 := add(t_6, 50000)`\n5.  `I_3: t_3 := add(t_1, t_2)`\n6.  `I_5: t_5 := add(t_3, 12)`\n7.  `I_4: t_4 := add(c, 70000)`\n\nThis schedule is legal as all dependencies are respected. The sequence of large constant uses becomes: $50000$ ($I_1$), $50000$ ($I_2$), $50000$ ($I_7$), and finally $70000$ ($I_4$).\n\n1.  At block entry: Issue `LDRL r_c, =50000`. (1 load)\n2.  For $I_1, I_2, I_7$: Use the value in $r_c$. No new loads.\n3.  For $I_4$ (uses $70000$): The value in $r_c$ is $50000$. We must switch. Issue `LDRL r_c, =70000`. (2 loads)\n\nTotal literal loads: $2$.\n\n### Analysis of Option D\n\n**Strategy**: Legally reorder as in option C, but instead hoist and keep $70000$ and load $50000$ on each of its uses.\n\nThis strategy reorders instructions but makes a poor choice of which constant to prioritize. A legal schedule would place $I_4$ first, followed by the other instructions, respecting their dependencies.\nExample schedule: $I_4, I_1, I_2, I_6, I_7, I_3, I_5$.\n\nThe loading strategy is described as \"hoist and keep $70000$\" (an intelligent, global choice) but \"load $50000$ on each of its uses\" (a naive, local choice). We evaluate the strategy as stated.\n\n1.  At block entry: Hoist the constant for $I_4$. Issue `LDRL r_c, =70000`. (1 load)\n2.  For $I_4$: Use $r_c$.\n3.  For the first use of $50000$ ($I_1$): Strategy says to load on each use. Issue `LDRL r_c, =50000`. (2 loads)\n4.  For the second use of $50000$ ($I_2$): Strategy says to load on each use. Issue `LDRL r_c, =50000`. (3 loads)\n5.  For the third use of $50000$ ($I_7$): Strategy says to load on each use. Issue `LDRL r_c, =50000`. (4 loads)\n\nTotal literal loads: $4$.\nEven if \"load on each use\" were interpreted more charitably as \"load when needed\", this strategy would require loading $70000$ first (1 load), then loading $50000$ for the subsequent uses (1 load), for a total of $2$ loads, same as option C. However, the explicit phrasing \"load ... on each of its uses\" contrasts with the \"hoist and keep\" phrasing and suggests a naive implementation for the non-hoisted constant. This makes the strategy described in D inferior to C. Given the options, C describes the unambiguously optimal approach.\n\n**Conclusion**:\n- Strategy A: $4$ loads\n- Strategy B: $3$ loads\n- Strategy C: $2$ loads\n- Strategy D: $4$ loads\n\nThe minimal number of literal loads is $2$, achieved by strategy C.", "answer": "$$\\boxed{C}$$", "id": "3646810"}]}