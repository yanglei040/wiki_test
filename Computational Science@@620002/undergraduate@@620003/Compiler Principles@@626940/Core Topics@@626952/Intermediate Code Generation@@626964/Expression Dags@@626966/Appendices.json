{"hands_on_practices": [{"introduction": "At its core, a Directed Acyclic Graph (DAG) offers a powerful way to visualize and optimize expressions by eliminating redundant computations. This first exercise provides foundational practice in constructing a DAG from a simple arithmetic expression. By applying the commutative and associative properties of addition and multiplication, you will learn to identify and merge common subexpressions to achieve a maximally shared, and thus more efficient, representation. [@problem_id:3641786]", "problem": "A compiler backend constructs an expression representation for basic blocks using a Directed Acyclic Graph (DAG), where each internal node represents a binary operator and each leaf represents an operand. In this representation, common subexpression elimination (CSE) is performed by ensuring that identical operator applications with identical operand sets are represented by a single shared node. For binary addition and multiplication, use the mathematical facts that addition and multiplication are associative and commutative to canonicalize operand sets when determining node identity; do not use any other algebraic transformations such as distributivity or introduction of numeric constants that are not already present. Assume leaves corresponding to variables are not counted as operations, and only binary addition and binary multiplication nodes are counted as operations.\n\nGiven the expression\n$$\nx\\cdot y + z\\cdot w + x\\cdot y + z\\cdot w + t,\n$$\nconstruct the expression DAG with maximal sharing under the above rules and determine the minimal number of binary operation nodes that remain after CSE. Report, in order, the number of multiplication nodes, the number of addition nodes, and the total number of binary operation nodes. Express your final answer as a row matrix.", "solution": "The problem is valid as it is a well-defined question within the domain of compiler theory, specifically concerning expression representation using Directed Acyclic Graphs (DAGs) and optimization via common subexpression elimination (CSE). The rules for DAG construction and optimization are clearly specified.\n\nThe expression to be represented is:\n$$\nE = x \\cdot y + z \\cdot w + x \\cdot y + z \\cdot w + t\n$$\nThe goal is to construct a DAG with maximal sharing, applying CSE, commutativity, and associativity for addition and multiplication, and to count the minimum number of resulting binary operation nodes. The operator nodes are strictly binary. The variables $x, y, z, w, t$ are leaves and are not counted as operation nodes.\n\nFirst, we identify the multiplication operations. The expression contains two distinct multiplication subexpressions:\n$1$. The subexpression $x \\cdot y$ appears twice. Due to common subexpression elimination, both instances will be represented by a single shared node in the DAG. Let's denote the result of this operation by $N_1 = \\text{node}(\\cdot, x, y)$. This accounts for one multiplication node.\n$2$. The subexpression $z \\cdot w$ also appears twice. Similarly, both instances will be represented by a second shared node. Let's denote its result by $N_2 = \\text{node}(\\cdot, z, w)$. This accounts for a second multiplication node.\n\nThe problem states that commutativity is used to canonicalize operand sets. For example, if the expression contained $y \\cdot x$, it would be treated as identical to $x \\cdot y$. In this problem, the repeated subexpressions are identical, so this rule is straightforwardly applied.\nThere are no other multiplication operations. Therefore, the minimal number of multiplication nodes is $2$.\n\nNext, we analyze the addition operations. After performing the multiplications, the expression can be rewritten in terms of the nodes $N_1$, $N_2$, and the leaf $t$:\n$$\nE = N_1 + N_2 + N_1 + N_2 + t\n$$\nThis is a sum of five terms. The problem states that we can use the associative and commutative properties of addition to rearrange and regroup the terms to maximize sharing (i.e., to create common subexpressions among the additions). The multiset of terms being added is $\\{N_1, N_1, N_2, N_2, t\\}$.\nWe can rearrange and regroup the sum as follows:\n$$\nE = (N_1 + N_2) + (N_1 + N_2) + t\n$$\nThis grouping is optimal because it creates the repeated subexpression $(N_1 + N_2)$. Let's construct the DAG for this addition structure:\n$1$. We create a node for the common subexpression $N_1 + N_2$. Let's call this node $N_3 = \\text{node}(+, N_1, N_2)$. This is our first addition node. The property of commutativity ensures that $N_2 + N_1$ would be represented by the same node.\n$2$. With this new node, the expression becomes $N_3 + N_3 + t$. We must evaluate this using binary additions. We can group this as $(N_3 + N_3) + t$.\n$3$. We create a node for the subexpression $N_3 + N_3$. Let's call this node $N_4 = \\text{node}(+, N_3, N_3)$. Note that this node takes two pointers to the same child node $N_3$. This is our second addition node.\n$4$. Finally, we create the root node of the DAG, which represents the full expression. This node computes the sum of the result of $N_4$ and the leaf $t$. Let this be $N_5 = \\text{node}(+, N_4, t)$. This is our third addition node.\n\nFollowing this construction, we have used three distinct addition nodes: $N_3$, $N_4$, and $N_5$. No other grouping of the five terms can be realized with fewer than three binary addition nodes. For instance, a simple left-associative evaluation without regrouping, such as $(((N_1+N_2)+N_1)+N_2)+t$, would not create any common addition subexpressions and would require four addition nodes.\n\nIn summary:\n- Number of multiplication nodes: $2$ (for $x \\cdot y$ and $z \\cdot w$).\n- Number of addition nodes: $3$ (for $(x \\cdot y + z \\cdot w)$, for adding this subexpression to itself, and for adding $t$).\n- Total number of binary operation nodes: $2 + 3 = 5$.\n\nThe final answer requires these three numbers in order, presented as a row matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  3  5\n\\end{pmatrix}\n}\n$$", "id": "3641786"}, {"introduction": "While algebraic simplification is powerful, real-world programs are complicated by memory operations, which introduce state. This practice problem moves beyond pure arithmetic to explore a critical constraint on common subexpression elimination: memory aliasing. You will analyze a code fragment with an intervening memory write to understand why two syntactically identical load operations cannot always be merged, illustrating the crucial role of alias analysis in ensuring optimization safety. [@problem_id:3641783]", "problem": "Consider two arrays of $32$-bit integers $A$ and $B$, a pointer $P$ that may point into some memory region, and an integer index $i$ that is not modified within the following straight-line fragment. Assume neither $A$ nor $B$ are declared volatile and there are no function calls. The code is in Static Single Assignment (SSA) form, and the final computation is expressed as a Directed Acyclic Graph (DAG), where load nodes are annotated by the address expression and a memory-version token representing the abstract memory state relevant to their alias set.\n\nThe code is:\n$$\n\\begin{aligned}\nt_0 \\leftarrow A[i] \\\\\n*P \\leftarrow v \\\\\nt_1 \\leftarrow A[i] \\\\\nt_2 \\leftarrow B[i] \\\\\nx \\leftarrow t_0 + t_1 + t_2\n\\end{aligned}\n$$\n\nAn alias analysis reports the following facts:\n- $A$ and $B$ are disjoint arrays: $\\mathrm{NoAlias}(A, B)$.\n- The pointer $P$ may refer to the $A$ region but does not refer to the $B$ region: $\\mathrm{MayAlias}(P, A)$ and $\\mathrm{NoAlias}(P, B)$.\n- The index $i$ remains unchanged across the sequence.\n\nUse the following fundamentals to reason about the expression DAG:\n- A Directed Acyclic Graph (DAG) for expressions merges nodes for identical pure computations.\n- A load from memory is treated as a node that depends on the relevant abstract memory version; two loads can be represented by a single shared DAG node if and only if they read the same address expression from the same memory version and there is no intervening store (in program order) that may write to that address according to alias analysis.\n- A store updates the abstract memory version of the alias set(s) it may write to.\n\nUnder these conditions, which statement correctly describes which load nodes in the DAG for $x$ can be shared and which must be distinct?\n\nA. Merge the two $A[i]$ loads into a single DAG node, because the address expressions are identical; keep the $B[i]$ load as a separate node.\n\nB. Keep the two $A[i]$ loads as distinct DAG nodes because the intervening store through $P$ may alias $A$ and thus may update $A[i]$; the $B[i]$ load is a single node unaffected by the store, since $P$ does not alias $B$.\n\nC. All three loads must be distinct DAG nodes, because any intervening store forces a new global memory version regardless of alias information.\n\nD. Merge the $A[i]$ and $B[i]$ loads into a single DAG node because they share the same index $i$; alias results are irrelevant to DAG node sharing for loads.", "solution": "The problem statement is evaluated as valid. It is a well-posed problem grounded in the established principles of compiler design, specifically regarding code optimization through Directed Acyclic Graphs (DAGs) and the use of alias analysis to handle memory operations. The givens are self-contained, consistent, and sufficient to derive a unique solution.\n\nThe core of this problem is to determine which computations are redundant and can be represented by a single node in a DAG. For load operations, this is governed by the principle of Common Subexpression Elimination (CSE), which, in the presence of memory, must be guided by alias analysis.\n\nLet us trace the construction of the DAG for the expression $x \\leftarrow t_0 + t_1 + t_2$, following the provided rules. The key is to track the abstract memory state, or \"version,\" for each relevant alias set. The alias analysis partitions memory into at least two disjoint sets of interest: one containing array $A$ and another containing array $B$. The pointer $P$ may alias the set containing $A$, but not the set containing $B$.\n\nLet $M_A$ be the memory version token for the alias set containing array $A$, and $M_B$ be the memory version token for the alias set containing array $B$.\n\nInitially, before the code fragment executes, let the memory versions be $M_A^{(0)}$ and $M_B^{(0)}$.\n\n1.  **Instruction: $t_0 \\leftarrow A[i]$**\n    This is a load operation. The address is determined by the base of $A$ and the index $i$. A DAG node is created for this load. This node depends on the address expression, which we can denote as $\\mathrm{addr}(A[i])$, and the current memory version for its alias set, $M_A^{(0)}$.\n    The node for this load is $\\mathrm{Load}(\\mathrm{addr}(A[i]), M_A^{(0)})$. The variable $t_0$ is now associated with the value produced by this node.\n\n2.  **Instruction: $*P \\leftarrow v$**\n    This is a store operation. We must consult the alias analysis results to determine its effect on our memory versions.\n    -   $\\mathrm{MayAlias}(P, A)$: The store through pointer $P$ *may* modify a location within the memory region of $A$. Because a modification is possible, a conservative compiler must assume that the memory state for this alias set is changed. Thus, the memory version $M_A$ is updated. Let the new version be $M_A^{(1)}$.\n    -   $\\mathrm{NoAlias}(P, B)$: The store through pointer $P$ *does not* modify any location within the memory region of $B$. The compiler can be certain of this. Therefore, the memory state for $B$ is unaffected, and its version remains $M_B^{(0)}$.\n    After this instruction, the active memory versions are $M_A^{(1)}$ and $M_B^{(0)}$.\n\n3.  **Instruction: $t_1 \\leftarrow A[i]$**\n    This is a second load from the address $\\mathrm{addr}(A[i])$. The rule for sharing DAG nodes for loads is that they must read from the same address and the same memory version.\n    -   The address expression, $\\mathrm{addr}(A[i])$, is identical to the first load.\n    -   However, this load occurs after the store to $*P$. The current memory version for the alias set of $A$ is $M_A^{(1)}$.\n    Therefore, this load is represented by the node $\\mathrm{Load}(\\mathrm{addr}(A[i]), M_A^{(1)})$.\n    Since $M_A^{(1)} \\ne M_A^{(0)}$, this node is distinct from the one created for $t_0$. The two loads from $A[i]$ cannot be merged.\n\n4.  **Instruction: $t_2 \\leftarrow B[i]$**\n    This is a load from address $\\mathrm{addr}(B[i])$.\n    -   The address expression, $\\mathrm{addr}(B[i])$, is different from $\\mathrm{addr}(A[i])$ since $\\mathrm{NoAlias}(A, B)$. Therefore, this load cannot share a node with the loads from $A[i]$ on this basis alone.\n    -   The load depends on the memory version for the alias set of $B$, which is $M_B^{(0)}$. The store to $*P$ did not affect this version.\n    The node for this load is $\\mathrm{Load}(\\mathrm{addr}(B[i]), M_B^{(0)})$.\n\n5.  **Instruction: $x \\leftarrow t_0 + t_1 + t_2$**\n    This expression combines the results of the three loads. The DAG will have operator nodes for addition, taking as input the three distinct load nodes derived above.\n\nIn summary, we require three distinct load nodes in the DAG:\n-   One for $t_0 \\leftarrow A[i]$, dependent on memory version $M_A^{(0)}$.\n-   A second, distinct one for $t_1 \\leftarrow A[i]$, dependent on memory version $M_A^{(1)}$.\n-   A third, distinct one for $t_2 \\leftarrow B[i]$, dependent on a different address and memory version $M_B^{(0)}$.\n\nNow, we evaluate each option based on this derivation.\n\n**A. Merge the two $A[i]$ loads into a single DAG node, because the address expressions are identical; keep the $B[i]$ load as a separate node.**\nThis statement is **Incorrect**. While the address expressions for the two loads from $A[i]$ are indeed identical, this is not a sufficient condition for merging their DAG nodes. The intervening store, $*P \\leftarrow v$, may alias with $A$ ($\\mathrm{MayAlias}(P, A)$), which forces the compiler to assume a change in the memory state for $A$. The first load depends on the memory state *before* the store, and the second load depends on the memory state *after* the store. Since the memory versions are different, the nodes cannot be merged.\n\n**B. Keep the two $A[i]$ loads as distinct DAG nodes because the intervening store through $P$ may alias $A$ and thus may update $A[i]$; the $B[i]$ load is a single node unaffected by the store, since $P$ does not alias $B$.**\nThis statement is **Correct**. It accurately describes the situation. The two loads from $A[i]$ must be represented by distinct nodes because the intervening store $*P \\leftarrow v$ is a \"memory barrier\" for loads from the alias set of $A$, due to the $\\mathrm{MayAlias}(P, A)$ fact. The value of $A[i]$ must be reloaded. The statement also correctly notes that the load from $B[i]$ is unaffected by this specific store, because the alias analysis guarantees no overlap ($\\mathrm{NoAlias}(P, B)$).\n\n**C. All three loads must be distinct DAG nodes, because any intervening store forces a new global memory version regardless of alias information.**\nThis statement is **Incorrect**. While the conclusion that all three loads must be distinct is correct, the reasoning provided is flawed. The statement claims \"any intervening store forces a new global memory version regardless of alias information\". This is false. The entire purpose of fine-grained alias analysis is to *avoid* treating memory as a single monolithic block. Here, the store to $*P$ updates the memory version for $A$'s alias set but *not* for $B$'s alias set. If the rule were as stated in C, alias analysis would be of no use for this optimization.\n\n**D. Merge the $A[i]$ and $B[i]$ loads into a single DAG node because they share the same index $i$; alias results are irrelevant to DAG node sharing for loads.**\nThis statement is **Incorrect**. It is flawed on two fundamental points. First, loads from $A[i]$ and $B[i]$ access different memory addresses because $A$ and $B$ are distinct arrays ($\\mathrm{NoAlias}(A, B)$). DAG nodes for loads can only be shared if the addresses are identical. Sharing an index $i$ is irrelevant. Second, the claim that \"alias results are irrelevant\" is profoundly wrong and contradicts the foundational principles of memory-aware compiler optimizations and the rules given in the problem statement itself. Alias analysis is the critical component that determines whether an intervening store invalidates a prior load.", "answer": "$$\\boxed{B}$$", "id": "3641783"}, {"introduction": "The utility of a DAG extends far beyond just identifying common subexpressions; it is a fundamental structure for guiding code generation. This final exercise demonstrates how the DAG's structure offers flexibility in instruction scheduling through different topological orderings. By analyzing two distinct evaluation strategies for the same expression, you will calculate their resulting register pressure and discover how choosing an optimal order can lead to more efficient code that minimizes register usage. [@problem_id:3641827]", "problem": "You are given the arithmetic expression $E = a \\cdot b + a \\cdot c + a \\cdot d$. Model $E$ as an Expression Directed Acyclic Graph (DAG) where each internal node is a binary operator and each leaf is a variable. A topological order is any linearization of the internal nodes that respects the parent-after-children constraint. Consider a simple load/store machine model in which every binary arithmetic operation requires both operands to be in registers and overwrites one of the operand registers with the result. Variables $a$, $b$, $c$, and $d$ initially reside in memory and must be loaded to registers before use. Internal-node recomputation is disallowed, and spilling temporaries is disallowed; that is, once a temporary for an internal node is computed, it must remain in a register until its last use. Define register pressure as the maximum number of distinct simultaneously live register-resident values at any program point in a straight-line evaluation schedule corresponding to a chosen topological order.\n\nUsing the DAG of $E$, exhibit two distinct valid topological orders of the internal nodes that correspond to two straight-line schedules: one that first computes all products and then performs additions, and another that interleaves additions to accumulate a running sum as products are produced. For each schedule, compute the exact register pressure under the model above, justifying your count from first principles. Finally, determine the minimal possible register pressure over all valid topological orders of the DAG. Express your final answer as an integer.", "solution": "The problem statement is a well-defined exercise in compiler theory, specifically concerning instruction scheduling and register allocation for expression evaluation. The concepts of Directed Acyclic Graphs (DAGs), topological ordering, register pressure, and simplified machine models are standard and form a scientifically grounded basis for the problem. The givens are self-contained, consistent, and sufficient to derive a unique solution. The problem is therefore deemed valid.\n\nThe arithmetic expression is $E = a \\cdot b + a \\cdot c + a \\cdot d$. We model this expression as a DAG. Assuming standard left-to-right associativity for addition, the expression is parsed as $E = ((a \\cdot b) + (a \\cdot c)) + (a \\cdot d)$. The DAG consists of leaf nodes for the variables $a, b, c, d$ and internal nodes for the operators. Notably, the variable $a$ is a common subexpression, shared by three multiplication nodes. The internal nodes are:\n- $N_1 = a \\cdot b$\n- $N_2 = a \\cdot c$\n- $N_3 = a \\cdot d$\n- $N_4 = N_1 + N_2$\n- $N_5 = N_4 + N_3$ (This is the root of the DAG)\n\nThe machine model specified is a load/store architecture where binary operations are of the form `OP R_dest, R_src`, which computes `R_dest \\leftarrow R_dest op R_src`. This means the value in the destination register is overwritten with the result. A value is considered live from its definition (being loaded or computed) until its last use. Register pressure is the maximum number of simultaneously live values that must be held in registers at any point in an evaluation schedule. We are not allowed to spill temporary results to memory.\n\nWe need to analyze two evaluation schedules corresponding to two distinct topological orders of the internal nodes $\\{N_1, N_2, N_3, N_4, N_5\\}$. The dependencies are that $N_1$ and $N_2$ must be evaluated before $N_4$, and $N_4$ and $N_3$ must be evaluated before $N_5$.\n\n**Schedule 1: Compute all products first, then perform additions.**\n\nA valid topological order for this strategy is $(N_1, N_2, N_3, N_4, N_5)$. The corresponding instruction schedule and liveness analysis are as follows. We denote the value of variable $x$ as $x$ and the temporary result of node $N_i$ as $t_i$. The set of live values in registers is tracked at each step.\n\n1. `LOAD R1, a` --- Live values: $\\{a\\}$. Count = $1$. Register $R_1$ holds $a$. We keep $a$ in $R_1$ as it is needed for all three products.\n2. `LOAD R2, b` --- Live values: $\\{a, b\\}$. Count = $2$. $R_1$ has $a$, $R_2$ has $b$.\n3. `MUL R2, R1` --- $R_2 \\leftarrow R_2 \\cdot R_1$ ($b \\cdot a$). Result $t_1$ is in $R_2$. The value $b$ is consumed (last use). Live values: $\\{a, t_1\\}$. Count = $2$. $R_1$ has $a$, $R_2$ has $t_1$.\n4. `LOAD R3, c` --- Live values: $\\{a, t_1, c\\}$. Count = $3$. $R_1(a)$, $R_2(t_1)$, $R_3(c)$.\n5. `MUL R3, R1` --- $R_3 \\leftarrow R_3 \\cdot R_1$ ($c \\cdot a$). Result $t_2$ is in $R_3$. The value $c$ is consumed. Live values: $\\{a, t_1, t_2\\}$. Count = $3$. $R_1(a)$, $R_2(t_1)$, $R_3(t_2)$.\n6. `LOAD R4, d` --- Live values: $\\{a, t_1, t_2, d\\}$. Count = $4$. $R_1(a)$, $R_2(t_1)$, $R_3(t_2)$, $R_4(d)$. **This is the point of maximum pressure.**\n7. `MUL R4, R1` --- $R_4 \\leftarrow R_4 \\cdot R_1$ ($d \\cdot a$). Result $t_3$ is in $R_4$. The values $d$ and $a$ are consumed (this is the last use of $a$). Register $R_1$ is now free. Live values: $\\{t_1, t_2, t_3\\}$. Count = $3$. $R_2(t_1)$, $R_3(t_2)$, $R_4(t_3)$.\n8. `ADD R2, R3` --- $R_2 \\leftarrow R_2 + R_3$ ($t_1 + t_2$). Result $t_4$ is in $R_2$. The values $t_1, t_2$ are consumed. Register $R_3$ is now free. Live values: $\\{t_4, t_3\\}$. Count = $2$. $R_2(t_4)$, $R_4(t_3)$.\n9. `ADD R2, R4` --- $R_2 \\leftarrow R_2 + R_4$ ($t_4 + t_3$). Result $t_5$ (the final result) is in $R_2$. Values $t_4, t_3$ are consumed. Register $R_4$ is now free. Live values: $\\{t_5\\}$. Count = $1$.\n\nThe maximum number of simultaneously live values is $4$. Thus, the register pressure for this schedule is $4$.\n\n**Schedule 2: Interleave additions with products.**\n\nA valid topological order for this strategy is $(N_1, N_2, N_4, N_3, N_5)$. This corresponds to computing $(a \\cdot b + a \\cdot c)$ first, then adding $a \\cdot d$.\n\n1. `LOAD R1, a` --- Live values: $\\{a\\}$. Count = $1$.\n2. `LOAD R2, b` --- Live values: $\\{a, b\\}$. Count = $2$.\n3. `MUL R2, R1` --- Computes $t_1 = b \\cdot a$. Value $b$ is consumed. Live values: $\\{a, t_1\\}$. Count = $2$. $R_1(a)$, $R_2(t_1)$.\n4. `LOAD R3, c` --- Live values: $\\{a, t_1, c\\}$. Count = $3$. $R_1(a)$, $R_2(t_1)$, $R_3(c)$.\n5. `MUL R3, R1` --- Computes $t_2 = c \\cdot a$. Value $c$ is consumed. Live values: $\\{a, t_1, t_2\\}$. Count = $3$. $R_1(a)$, $R_2(t_1)$, $R_3(t_2)$.\n6. `ADD R2, R3` --- Computes $t_4 = t_1 + t_2$. Values $t_1, t_2$ are consumed. Register $R_3$ is freed. Live values: $\\{a, t_4\\}$. Count = $2$. $R_1(a)$, $R_2(t_4)$.\n7. `LOAD R3, d` --- Live values: $\\{a, t_4, d\\}$. Count = $3$. $R_1(a)$, $R_2(t_4)$, $R_3(d)$.\n8. `MUL R3, R1` --- Computes $t_3 = d \\cdot a$. Values $d, a$ are consumed. Register $R_1$ is freed. Live values: $\\{t_4, t_3\\}$. Count = $2$. $R_2(t_4)$, $R_3(t_3)$.\n9. `ADD R2, R3` --- Computes $t_5 = t_4 + t_3$. Values $t_4, t_3$ are consumed. Register $R_3$ is freed. Live values: $\\{t_5\\}$. Count = $1$.\n\nThe maximum number of simultaneously live values in this schedule is $3$. The register pressure for this schedule is $3$.\n\n**Minimal Possible Register Pressure**\n\nWe have demonstrated a schedule with pressure $3$. We now prove that it is impossible to achieve a lower pressure (i.e., pressure $2$).\n\nLet's assume an evaluation can be performed with a maximum of $2$ registers. Consider the evaluation of the first product, say $N_1 = a \\cdot b$. The sequence `LOAD R1, a; LOAD R2, b; MUL R1, R2` could be used, resulting in $t_1$ in $R_1$ and $R_2$ being free. So far, we have used at most $2$ registers. After this, $t_1$ is live and occupies one register, say $R_1$.\n\nTo complete the full expression evaluation, another product must be computed, for instance $N_2 = a \\cdot c$. To compute $N_2$, its operands, $a$ and $c$, must be loaded into registers.\n- $t_1$ is live and must remain in $R_1$ (since spilling is disallowed).\n- We have only one other register available, $R_2$, under our assumption of pressure $2$.\n- We can load one of the operands, say $c$, into $R_2$ with `LOAD R2, c`.\n- At this point, $R_1$ holds $t_1$ and $R_2$ holds $c$. Both registers are occupied.\n- To perform the multiplication $a \\cdot c$, the value of $a$ must also be in a register. However, there are no free registers. The values currently in registers, $t_1$ and $c$, are distinct from $a$ (in the general case).\n\nTherefore, at the point where we have computed one temporary product (which must be kept live) and are about to compute a second product, we require registers for three distinct values simultaneously: the first temporary (e.g., $t_1$), and the two operands for the next product (e.g., $a$ and $c$). This requires a minimum of $3$ registers.\n\nThe assumption that the register pressure can be $2$ leads to a contradiction. Hence, the minimum possible register pressure must be greater than $2$. Since we have explicitly constructed a schedule with a register pressure of $3$, the minimal possible register pressure over all valid topological orders is $3$.", "answer": "$$\n\\boxed{3}\n$$", "id": "3641827"}]}