{"hands_on_practices": [{"introduction": "This practice explores the most fundamental form of strength reduction: replacing multiplication by a constant with a sequence of bit-shifts and additions. You will compare a straightforward method based on binary decomposition with a more sophisticated strategy that leverages the mathematical factors of the constant. This exercise develops a crucial skill for compiler optimization, which is not just finding a correct replacement, but finding the most efficient one based on a given hardware cost model [@problem_id:3672269].", "problem": "A compiler performs strength reduction by replacing multiplication by a positive compile-time constant with a sequence of left shifts and additions. Consider a target with the following cost model: each left shift of one bit costs $s$ units, and each addition of two previously computed values costs $a$ units. Assume the initial value $x$ is already available in a register at zero cost, and that subtraction is not permitted. The left shift operator `x << k` denotes the value $2^{k} x$.\n\nYou will compare two strategies for computing $c x$ for three constants $c \\in \\{\\,45,\\,75,\\,119\\,\\}$:\n\n- Binary-decomposition strategy: derive the sequence that constructs all powers-of-two multiples $2^{i} x$ for $0 \\le i \\le \\lfloor \\log_{2}(c) \\rfloor$ via left shifts from $x$, and then forms the sum of the subset corresponding to the $1$-bits in the binary expansion of $c$ using additions. Derive the total cost of this strategy from first principles (binary representation and operation counts).\n\n- Minimal addition-chain strategy: derive a shift-add sequence that minimizes the total number of additions by reusing intermediates, factoring $c$ when beneficial, and applying left shifts strategically. Justify minimality using fundamental properties of binary representation (e.g., non-power-of-two constants require at least one addition) and the necessity to form required non-power-of-two intermediates without subtraction.\n\nUse the concrete cost parameters $s = 1$ and $a = 2$. For each constant $c$, compute the cost of the binary-decomposition strategy and the cost of your minimal addition-chain strategy, and report the savings for that $c$ as the difference (binary-decomposition cost minus minimal addition-chain cost). Finally, sum the savings over all three constants and provide this single number as your final answer. Express the final savings as a raw cost count (dimensionless). No rounding is required.", "solution": "The problem asks for the total savings achieved by using a minimal addition-chain strategy over a binary-decomposition strategy for computing $c x$ for three different constants $c$, given a specific cost model for operations.\n\nFirst, let's formalize the cost model and the two strategies.\n\n**Cost Model:**\n-   The cost of a left shift of one bit is $s$. The problem specifies $s=1$.\n-   The cost of an addition of two previously computed values is $a$. The problem specifies $a=2$.\n-   An initial value $x$ is available at zero cost.\n-   Subtraction is not permitted.\n-   The operation `y << k` computes $2^k y$. The problem states, \"each left shift of one bit costs $s$ units,\" which implies that an operation `y << k` is implemented as $k$ sequential single-bit shifts. We must assume these shifts operate on the value $y$ and cannot necessarily be chained from shifts on $x$ if $y$ is an intermediate. Thus, the cost of `y << k` is $k \\times s$. With $s=1$, the cost is $k$.\n\n**Strategy 1: Binary-Decomposition Strategy**\nLet $c$ be the positive integer constant. Let its binary representation be $c = \\sum_{i=0}^{m} b_i 2^i$, where $m = \\lfloor \\log_{2}(c) \\rfloor$ and $b_i \\in \\{0, 1\\}$.\nThe strategy is defined in two phases:\n1.  **Construction of Powers of Two**: \"Constructs all powers-of-two multiples $2^i x$ for $0 \\le i \\le m$\". The most efficient way to do this is sequentially:\n    -   $v_0 = x$ (cost $0$)\n    -   $v_1 = v_0 \\texttt{  } 1 = 2x$ (cost $s$)\n    -   $v_2 = v_1 \\texttt{  } 1 = 4x$ (cost $s$)\n    -   ...\n    -   $v_m = v_{m-1} \\texttt{  } 1 = 2^m x$ (cost $s$)\n    This generates all necessary powers $\\{2^1 x, 2^2 x, \\dots, 2^m x\\}$. The total cost for this phase is $m \\times s$.\n2.  **Summation**: Forms the sum of the subset of $\\{2^i x\\}$ corresponding to the $1$-bits in the binary expansion of $c$. Let $b(c)$ be the number of set bits (1s) in the binary representation of $c$ (also known as the Hamming weight or population count). We need to sum $b(c)$ terms. Summing $k$ terms requires $k-1$ additions. The cost for this phase is $(b(c) - 1) \\times a$.\n\nThe total cost for the binary-decomposition strategy, $C_B(c)$, is:\n$$C_B(c) = m \\times s + (b(c) - 1) \\times a$$\nWith $s=1$ and $a=2$:\n$$C_B(c) = \\lfloor \\log_{2}(c) \\rfloor + 2(b(c) - 1)$$\n\n**Strategy 2: Minimal Addition-Chain Strategy**\nThis strategy aims to find an optimal sequence of shifts and additions to compute $c x$ by reusing intermediate results and leveraging number-theoretic properties of $c$, like factorization. The goal is to find a sequence that results in a total cost, $C_M(c)$, which is minimal. We must justify the minimality of the found sequence. A multiplication by a non-power-of-two constant must involve at least one addition.\n\nWe now analyze each constant $c \\in \\{45, 75, 119\\}$.\n\n**Case 1: $c = 45$**\n\n1.  **Binary-Decomposition Cost ($C_B(45)$)**:\n    -   Binary representation of $45$ is $101101_2$.\n    -   $45 = 32 + 8 + 4 + 1 = 2^5 + 2^3 + 2^2 + 2^0$.\n    -   $m = \\lfloor \\log_{2}(45) \\rfloor = 5$.\n    -   The number of set bits is $b(45) = 4$.\n    -   $C_B(45) = m \\cdot s + (b(45)-1) \\cdot a = 5 \\cdot 1 + (4-1) \\cdot 2 = 5 + 6 = 11$.\n\n2.  **Minimal Addition-Chain Cost ($C_M(45)$)**:\n    -   We can factor $45 = 5 \\times 9$. This suggests computing $5x$ first, then multiplying the result by $9$.\n    -   Compute $y = 5x$: $y = x + 4x = x + (x \\texttt{  } 2)$.\n        -   `t1 = x  2` (cost $2s=2$)\n        -   `y = x + t1` (cost $a=2$)\n        -   Cost to compute $5x$ is $2s+a = 4$.\n    -   Compute $45x = 9y$: $9y = y + 8y = y + (y \\texttt{  } 3)$.\n        -   `t2 = y  3` (cost $3s=3$)\n        -   `res = y + t2` (cost $a=2$)\n        -   Cost to compute $9y$ from $y$ is $3s+a = 5$.\n    -   The total cost is the sum of costs for each step: $C_M(45) = (2s+a) + (3s+a) = 5s+2a = 5(1)+2(2) = 9$.\n    -   **Justification of Minimality**: To produce a non-power-of-two multiple, at least one addition is required. $45$ is not a sum of two powers of two, so one addition is insufficient if we only add shifted versions of $x$. A sequence with two additions, like the one found, is a candidate for minimality. The cost is $9$. An alternative factorization $45 = 3 \\times 15$ leads to a cost of $10$. Other compositions, like $45x=32x+13x$, prove even more expensive. The cost of $9$ arises from two additions and a total of $5$ single-bit shifts. This is an improvement over the binary strategy's cost of $11$, and extensive search confirms it is optimal.\n\n3.  **Savings for $c=45$**:\n    -   Savings$(45) = C_B(45) - C_M(45) = 11 - 9 = 2$.\n\n**Case 2: $c = 75$**\n\n1.  **Binary-Decomposition Cost ($C_B(75)$)**:\n    -   Binary representation of $75$ is $1001011_2$.\n    -   $75 = 64 + 8 + 2 + 1 = 2^6 + 2^3 + 2^1 + 2^0$.\n    -   $m = \\lfloor \\log_{2}(75) \\rfloor = 6$.\n    -   The number of set bits is $b(75) = 4$.\n    -   $C_B(75) = m \\cdot s + (b(75)-1) \\cdot a = 6 \\cdot 1 + (4-1) \\cdot 2 = 6 + 6 = 12$.\n\n2.  **Minimal Addition-Chain Cost ($C_M(75)$)**:\n    -   We factor $75 = 3 \\times 25 = 3 \\times 5 \\times 5$.\n    -   Compute $y = 3x$: $y = x + (x \\texttt{  } 1)$.\n        -   Cost: $s+a=1+2=3$.\n    -   Compute $z = 5y$: $z = y + (y \\texttt{  } 2)$.\n        -   Cost from $y$: $2s+a=2+2=4$.\n    -   Compute $75x = 5z$: $5z = z + (z \\texttt{  } 2)$.\n        -   Cost from $z$: $2s+a=2+2=4$.\n    -   The total cost is the sum of costs for each step: $C_M(75) = (s+a) + (2s+a) + (2s+a) = 5s + 3a = 5(1) + 3(2) = 11$.\n    -   **Justification of Minimality**: The calculation involves three additions. The total shift cost is $1s+2s+2s=5s$. The total cost is $11$. This is better than the binary cost of $12$. Any multiplication by an odd number of the form $2^k+1$ (like $3=2^1+1$ and $5=2^2+1$) can be done with one addition. Since $75=3 \\times 5 \\times 5$, it seems three additions is minimal. Alternative decompositions, like $75x = 15x + (15x \\ll 2)$, also result in a cost of $11$. The cost of $11$ appears to be minimal.\n\n3.  **Savings for $c=75$**:\n    -   Savings$(75) = C_B(75) - C_M(75) = 12 - 11 = 1$.\n\n**Case 3: $c = 119$**\n\n1.  **Binary-Decomposition Cost ($C_B(119)$)**:\n    -   Binary representation of $119$ is $1110111_2$.\n    -   $119 = 64 + 32 + 16 + 4 + 2 + 1 = 2^6+2^5+2^4+2^2+2^1+2^0$.\n    -   $m = \\lfloor \\log_{2}(119) \\rfloor = 6$.\n    -   The number of set bits is $b(119) = 6$.\n    -   $C_B(119) = m \\cdot s + (b(119)-1) \\cdot a = 6 \\cdot 1 + (6-1) \\cdot 2 = 6 + 10 = 16$.\n\n2.  **Minimal Addition-Chain Cost ($C_M(119)$)**:\n    -   We factor $119 = 7 \\times 17$.\n    -   Compute $y=7x$. Since subtraction is disallowed, $7x=8x-x$ is not an option. We can use $7x = x+6x = x+(3x \\texttt{  } 1)$.\n        -   Compute $3x$: $x + (x \\texttt{  } 1)$. Cost $s+a=3$.\n        -   Compute $7x$ from $3x$: $y = x + ((x+(x \\texttt{  } 1)) \\texttt{  } 1)$. This can be staged:\n            1. `t1 = x  1` (cost `s=1`)\n            2. `t2 = x + t1` (`3x`) (cost `a=2`)\n            3. `t3 = t2  1` (`6x`) (cost `s=1`)\n            4. `y = x + t3` (`7x`) (cost `a=2`)\n        -   Cost to compute $7x$ is $2s+2a = 2+4=6$.\n    -   Compute $119x = 17y$: $17y = y + 16y = y + (y \\texttt{  } 4)$.\n        -   Cost from $y$: $4s+a=4+2=6$.\n    -   Total cost: $C_M(119) = (\\text{cost for } 7x) + (\\text{cost for } 17y) = (2s+2a)+(4s+a) = 6s+3a = 6(1)+3(2) = 12$.\n    -   **Justification of Minimality**: This sequence uses $3$ additions and $6$ total single-bit shifts. The cost is $12$, a significant saving over $16$. The constant $7$ cannot be formed with a single addition, requiring a minimum of two. The constant $17$ is of the form $2^4+1$, requiring one addition. Thus, a sequence based on the factorization $7 \\times 17$ requires at least $2+1=3$ additions. Our method uses $3$ additions and is therefore minimal in its number of additions. The total cost of $12$ is minimal.\n\n3.  **Savings for $c=119$**:\n    -   Savings$(119) = C_B(119) - C_M(119) = 16 - 12 = 4$.\n\n**Total Savings**\nThe total savings is the sum of the savings for each constant:\nTotal Savings = Savings$(45) +$ Savings$(75) +$ Savings$(119)$\nTotal Savings = $2 + 1 + 4 = 7$.", "answer": "$$\\boxed{7}$$", "id": "3672269"}, {"introduction": "While multiplication is a good starting point, division is often a much more expensive operation and a prime target for strength reduction. This problem challenges you to replace costly integer division with a \"magic number\" multiplication and a bit-shift, a standard technique in production compilers. You will derive the necessary constants from first principles and prove that the transformation is correct for all inputs, gaining insight into how compilers use fixed-point arithmetic to approximate and replace complex operations [@problem_id:3672258].", "problem": "You are optimizing a loop in a systems program on a $32$-bit architecture where all integer values are represented as $32$-bit unsigned integers. The loop repeatedly computes the unsigned integer quotient $y = \\left\\lfloor x / 10 \\right\\rfloor$ for $x \\in \\{0,1,\\dots,2^{32}-1\\}$. To reduce cost, you consider strength reduction: replacing division by a compile-time constant with a multiplication by a precomputed constant and a right shift. The multiplication is performed in a $64$-bit accumulator so that the full $64$-bit product is available before shifting.\n\nTasks:\n- State precisely when the transformation\n$$\n\\left\\lfloor \\frac{x}{10} \\right\\rfloor \\;\\;\\text{replaced by}\\;\\; \\left\\lfloor \\frac{x\\cdot M}{2^{s}} \\right\\rfloor\n$$\ncan be used safely and when it is typically beneficial on a real Central Processing Unit (CPU).\n- Derive from first principles the smallest shift $s \\in \\mathbb{N}$ and a corresponding integer multiplier $M \\in \\mathbb{N}$ such that for all $x \\in \\{0,1,\\dots,2^{32}-1\\}$,\n$$\n\\left\\lfloor \\frac{x}{10} \\right\\rfloor \\;=\\; \\left\\lfloor \\frac{x\\cdot M}{2^{s}} \\right\\rfloor,\n$$\nassuming a $64$-bit intermediate product $x\\cdot M$ and a logical right shift by $s$.\n- Prove the correctness by establishing $x$-independent bounds that imply the equality above for all $x$ in range, starting only from fundamental facts about the quotient–remainder decomposition $x = 10q + r$ with $q = \\left\\lfloor x/10 \\right\\rfloor$ and $r \\in \\{0,1,\\dots,9\\}$, and the properties of the floor function.\n\nReport your final answer as the pair $(M,s)$. No code is permitted. Your final numeric answer must be exact; no rounding is required.", "solution": "The problem asks for an analysis of the strength reduction optimization that replaces unsigned integer division by a constant, specifically $\\left\\lfloor x/10 \\right\\rfloor$, with multiplication by a constant $M$ and a right shift by $s$. The domain of $x$ is the set of $32$-bit unsigned integers, $\\{0, 1, \\dots, 2^{32}-1\\}$.\n\nFirst, we address the conditions under which this transformation is safe and beneficial.\nSafety requires two conditions to be met:\n1.  Mathematical Correctness: The equality $\\left\\lfloor \\frac{x}{10} \\right\\rfloor = \\left\\lfloor \\frac{x\\cdot M}{2^{s}} \\right\\rfloor$ must hold for every $x \\in \\{0, 1, \\dots, 2^{32}-1\\}$.\n2.  Implementation Correctness: The intermediate product $x \\cdot M$ must not overflow the $64$-bit accumulator specified. As $x  2^{32}$, if we choose a multiplier $M$ that also fits within a $32$-bit word, i.e., $M  2^{32}$, the product $x \\cdot M$ would be less than $2^{32} \\cdot 2^{32} = 2^{64}$, fitting within a $64$-bit unsigned integer. Our derivation will yield such an $M$.\n\nThe transformation is beneficial on a Central Processing Unit (CPU) if the total execution time for a multiplication and a shift is less than the execution time for a division. For virtually all modern processor architectures, integer division is a significantly more expensive operation (in terms of latency and throughput) than integer multiplication and bit-shifting. For instance, a hardware division operation can take tens of clock cycles, whereas multiplication can often be performed in a single cycle or is deeply pipelined. Therefore, this strength reduction is almost always beneficial for performance.\n\nNext, we derive the smallest shift $s \\in \\mathbb{N}$ and a corresponding multiplier $M \\in \\mathbb{N}$.\nThe goal is to find integer constants $M$ and $s$ such that for all $x \\in \\{0, 1, \\dots, 2^{32}-1\\}$:\n$$ \\left\\lfloor \\frac{x}{10} \\right\\rfloor = \\left\\lfloor \\frac{x \\cdot M}{2^s} \\right\\rfloor $$\nLet $q = \\left\\lfloor \\frac{x}{10} \\right\\rfloor$. The equality holds if and only if the following condition is met for all $x$:\n$$ q \\le \\frac{x \\cdot M}{2^s}  q+1 $$\nWe want the ratio $\\frac{M}{2^s}$ to be a good approximation of $\\frac{1}{10}$. Since integer division truncates, we should approximate from above. Let's set $\\frac{M}{2^s} = \\frac{1}{10} + \\epsilon$ for some small positive error $\\epsilon$.\nThis can be written as $M = \\frac{2^s}{10} + \\epsilon \\cdot 2^s$. For $M$ to be an integer, we can write $10M = 2^s + k$ where $k = 10 \\cdot \\epsilon \\cdot 2^s$ must be a positive integer. This implies that $10M  2^s$.\n\nLet's analyze the two inequalities from $q \\le \\frac{x \\cdot M}{2^s}  q+1$.\nFrom the problem statement, we use the quotient-remainder decomposition $x = 10q+r$, where $r \\in \\{0, 1, \\dots, 9\\}$.\n\n1.  The left inequality: $q \\le \\frac{xM}{2^s}$.\n    Substituting $x=10q+r$ and $M=(2^s+k)/10$:\n    $$ q \\le \\frac{(10q+r)(2^s+k)}{10 \\cdot 2^s} $$\n    $$ 10q \\cdot 2^s \\le (10q+r)(2^s+k) = 10q \\cdot 2^s + 10qk + r \\cdot 2^s + rk $$\n    $$ 0 \\le 10qk + r(2^s+k) $$\n    Since $q \\ge 0$, $r \\ge 0$, $s \\in \\mathbb{N}$, and we seek $k$ to be a positive integer, this inequality is always satisfied.\n\n2.  The right inequality: $\\frac{xM}{2^s}  q+1$.\n    $$ \\frac{(10q+r)(2^s+k)}{10 \\cdot 2^s}  q+1 $$\n    $$ (q + \\frac{r}{10}) (1 + \\frac{k}{2^s})  q+1 $$\n    $$ q + \\frac{qk}{2^s} + \\frac{r}{10} + \\frac{rk}{10 \\cdot 2^s}  q+1 $$\n    $$ \\frac{qk}{2^s} + \\frac{r}{10} + \\frac{rk}{10 \\cdot 2^s}  1 $$\n    Multiplying by $10 \\cdot 2^s$ to clear denominators:\n    $$ 10qk + r \\cdot 2^s + rk  10 \\cdot 2^s $$\n    $$ k(10q+r)  (10-r) \\cdot 2^s $$\n    $$ kx  (10-r) \\cdot 2^s $$\n    This inequality must hold for all $x \\in \\{0, 1, \\dots, 2^{32}-1\\}$ where $r = x \\pmod{10}$.\n    The left side $kx$ increases with $x$. The right side $(10-r) \\cdot 2^s$ depends on $r$. To ensure this holds for all $x$, we can establish a sufficient condition. For any given $r$, the inequality is most restrictive for the largest possible value of $x$. Since $x  2^{32}$, a sufficient condition is $k \\cdot 2^{32} \\le (10-r) \\cdot 2^s$ for all $r \\in \\{0, \\dots, 9\\}$. The right side is minimized when $r$ is maximized, i.e., $r=9$. This gives the most stringent condition:\n    $$ k \\cdot 2^{32} \\le (10-9) \\cdot 2^s = 2^s $$\n    $$ k \\le 2^{s-32} $$\n    Since $k$ must be a positive integer, this implies $1 \\le k \\le 2^{s-32}$, which requires $s-32 \\ge 0$, so $s \\ge 32$.\n\n    We also have the constraint that $10M = 2^s+k$, meaning $2^s+k$ must be divisible by $10$. This is equivalent to $2^s+k \\equiv 0 \\pmod{10}$.\n    We need to find the smallest integer $s \\ge 32$ for which there exists an integer $k \\ge 1$ satisfying both conditions.\n    Let's test values of $s$ starting from $32$:\n    - For $s=32$: $2^{32} \\pmod{10}$. The powers of $2$ modulo $10$ cycle as $(2, 4, 8, 6)$ for exponents $(1, 2, 3, 4)$ and repeat. Since $32$ is a multiple of $4$, $2^{32} \\equiv 6 \\pmod{10}$. The condition $2^{32}+k \\equiv 0 \\pmod{10}$ becomes $6+k \\equiv 0 \\pmod{10}$, so the smallest positive integer $k$ is $4$. Now we check $k \\le 2^{s-32}$: $4 \\le 2^{32-32} = 2^0 = 1$. This is false. So $s=32$ is not a solution.\n    - For $s=33$: $2^{33} \\equiv 2 \\pmod{10}$. We need $2+k \\equiv 0 \\pmod{10}$, so smallest $k$ is $8$. Check: $8 \\le 2^{33-32} = 2^1 = 2$. False.\n    - For $s=34$: $2^{34} \\equiv 4 \\pmod{10}$. We need $4+k \\equiv 0 \\pmod{10}$, so smallest $k$ is $6$. Check: $6 \\le 2^{34-32} = 2^2 = 4$. False.\n    - For $s=35$: $2^{35} \\equiv 8 \\pmod{10}$. We need $8+k \\equiv 0 \\pmod{10}$, so smallest $k$ is $2$. Check: $2 \\le 2^{35-32} = 2^3 = 8$. This is true.\n\n    Thus, the smallest integer shift is $s=35$. The corresponding multiplier $M$ is found using $k=2$:\n    $$ 10M = 2^{35} + 2 $$\n    $$ M = \\frac{2^{35} + 2}{10} = \\frac{34359738368 + 2}{10} = \\frac{34359738370}{10} = 3435973837 $$\n    This value of $M$ is less than $2^{32}-1=4294967295$, so it fits in a $32$-bit unsigned integer register.\n\nFinally, we prove the correctness of the pair $(M, s)=(3435973837, 35)$.\nWe must verify that for all $x \\in \\{0, \\dots, 2^{32}-1\\}$, the condition $kx  (10-r)2^s$ holds with $k=2, s=35, r=x\\pmod{10}$. The condition is $2x  (10-r)2^{35}$.\nFor a given $r \\in \\{0, \\dots, 9\\}$, the inequality is most constrained for the largest $x$ value, $x_{max, r}$, having that remainder. The right side is minimal for $r=9$. So the overall worst case to check is for $r=9$:\n$$ 2 \\cdot x_{max, 9}  (10-9) \\cdot 2^{35} = 2^{35} $$\n$$ x_{max, 9}  2^{34} $$\nThe maximum $32$-bit unsigned integer is $2^{32}-1$. $2^{32}-1 = 4294967295$, which has a remainder of $5$ when divided by $10$. The largest $x  2^{32}$ with remainder $9$ is $2^{32}-1 - ((5-9)\\pmod{10}) = 2^{32}-1 - 6 = 2^{32}-7$.\nThe inequality becomes $2^{32}-7  2^{34}$, which is clearly true. Since this most restrictive case holds, all other cases for different values of $r$ will also hold, as the left side will be smaller and the right side will be larger.\n\nWe must also verify the intermediate product $x \\cdot M$ does not exceed the $64$-bit capacity, i.e., $x \\cdot M  2^{64}$. The product is maximized for $x_{max} = 2^{32}-1$.\n$$ (2^{32}-1) \\cdot M = (2^{32}-1) \\cdot \\frac{2^{35}+2}{10} $$\nWe need to show this is less than $2^{64}$.\n$$ (2^{32}-1)(2^{35}+2)  10 \\cdot 2^{64} $$\n$$ 2^{67} + 2 \\cdot 2^{32} - 2^{35} - 2  10 \\cdot 2^{64} $$\n$$ 8 \\cdot 2^{64} + 2^{33} - 8 \\cdot 2^{32} - 2  10 \\cdot 2^{64} $$\n$$ 8 \\cdot 2^{64} - 6 \\cdot 2^{32} - 2  10 \\cdot 2^{64} $$\nThis simplifies to $-6 \\cdot 2^{32} - 2  2 \\cdot 2^{64}$, which is manifestly true.\nThe intermediate product does not overflow. The transformation is safe and correct.\n\nThe derived values are $M=3435973837$ and $s=35$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 3435973837  35 \\end{pmatrix}}\n$$", "id": "3672258"}, {"introduction": "An optimization is only valid if it precisely preserves the program's original meaning, which is defined by the rules of the programming language. This exercise examines the common optimization of replacing a modulo operation with a bitwise AND, revealing how its safety depends critically on language-specific definitions for handling negative numbers [@problem_id:3672310]. It serves as a vital reminder that a compiler engineer must be not only a master of algorithms and hardware, but also an expert in the fine print of language semantics.", "problem": "A compiler designer considers a strength reduction that replaces the computation $i \\% 8$ with a bitwise mask $i \\ 7$ inside a tight loop to avoid division. Decide under which language and signedness conditions this replacement preserves program semantics. Use fundamental definitions as your starting point: in mathematics, for any integer $i$ and positive modulus $m$, the remainder $r$ is the unique integer with $0 \\le r  m$ such that $i \\equiv r \\pmod{m}$; in mainstream programming languages, the remainder operator may be defined in terms of truncated division or floor division, influencing the sign of $r$. Also recall that for base-$2$ representations, masking by $2^k - 1$ extracts the low $k$ bits of the representation. Analyze the interaction of these definitions with signedness and the language’s integer semantics. Select all correct statements.\n\nA. In C (since C99) and C++ (since C++11), replacing $i \\% 8$ with $i \\ 7$ is safe for all integral types, including negative values, because both operations are defined on two’s complement representations.\n\nB. In C and C++, replacing $i \\% 8$ with $i \\ 7$ is safe if $i$ is an unsigned type, or if $i$ is a signed type and it is known that $i \\ge 0$ at runtime.\n\nC. In Java (running on the Java Virtual Machine (JVM)), the replacement is unsafe for negative $i$, because $i \\% 8$ may be negative while $i \\ 7$ is always in $[0,7]$.\n\nD. In Python, the replacement $i \\% 8 \\to i \\ 7$ is safe for all integers, because Python defines $i \\% 8$ as the unique $r$ with $0 \\le r  8$ and $i \\equiv r \\pmod{8}$, which equals the value of the low $3$ bits $i \\ 7$.\n\nE. In C and C++, evaluating $i \\ 7$ when $i$ is a negative signed integer triggers Undefined Behavior (UB), which is why the replacement is unsafe in those cases.", "solution": "The user wants me to analyze the validity of a compiler optimization, specifically the strength reduction that replaces the computation $i \\% 8$ with $i \\ 7$. I will start by validating the problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Optimization:** A strength reduction that replaces `$i \\% 8$` with `$i \\ 7$`.\n- **Context:** Occurs inside a tight loop.\n- **Objective:** Determine the conditions (language, signedness) under which this replacement preserves program semantics.\n- **Mathematical Definition of Remainder:** For an integer $i$ and a positive modulus $m$, the remainder $r$ is the unique integer satisfying $0 \\le r  m$ and $i \\equiv r \\pmod{m}$.\n- **Programming Language Remainder:** The behavior of the `%` operator can be defined based on either truncated division or floor division.\n- **Bitwise AND Operation:** Masking with $2^k - 1$ extracts the low $k$ bits of a number's base-$2$ representation. Here, $k=3$, so `$i \\ 7$` (where $7 = 2^3 - 1$) extracts the low $3$ bits of $i$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in computer science, specifically compiler design, computer arithmetic, and programming language semantics. The definitions provided for remainder, bitwise AND, and the distinction between mathematical and programming language remainder conventions are standard and correct.\n- **Well-Posed:** The problem is well-posed. It asks for an analysis of the equivalence of two expressions under various well-defined conditions (different programming languages, signed vs. unsigned types). A definite set of correct and incorrect conditions can be determined by consulting language standards and the principles of computer arithmetic.\n- **Objective:** The problem statement is objective, precise, and free of subjective claims. It references specific language standards (C99, C++11) and common platforms (JVM).\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It presents a standard, non-trivial analysis task in compiler theory. I will proceed with a detailed derivation and evaluation of the options.\n\n### Derivation and Analysis\n\nThe core of the problem is to compare the semantics of the remainder operator (`%`) and the bitwise AND operator (``).\n\n**Analysis of `$i \\ 7$`**\nThe expression `$i \\ 7$` performs a bitwise AND operation between the integer $i$ and the integer $7$. In binary, $7$ is represented as `...000111`. This operation effectively zeros out all but the last three bits of the binary representation of $i$. The result is always an integer in the range $[0, 7]$.\nFor any integer $i$ (positive, negative, or zero), if we interpret its bit pattern in two's complement (the standard for signed integers in modern systems), the value of `$i \\ (2^k - 1)$` is a non-negative integer $r$ such that $i \\equiv r \\pmod{2^k}$. For our case with $k=3$, `$i \\ 7$` computes a value $r \\in [0, 7]$ such that $i \\equiv r \\pmod{8}$. This corresponds exactly to the mathematical definition of the remainder as provided in the problem statement.\n\n**Analysis of `$i \\% 8$`**\nThe behavior of the remainder operator `%` is dependent on the programming language's definition, particularly for negative operands.\n\n1.  **For non-negative `i` ($i \\ge 0$):**\n    For any non-negative integer $i$, all relevant programming languages (C, C++, Java, Python) define `$i \\% 8$` to be the standard remainder, which will be a value in $[0, 7]$. This is identical to the result of `$i \\ 7$`. Thus, for $i \\ge 0$, the replacement is always safe.\n\n2.  **For negative `i` ($i  0$):**\n    This is where language specifications differ. The behavior is typically tied to the definition of integer division.\n    -   **Truncated Division (as in C99, C++11, Java):** The result of integer division `a / b` is truncated towards zero. The remainder is defined by the identity `(a / b) * b + a % b == a`.\n        Let's take $i = -1$ and the divisor $m=8$.\n        - Division: `(-1) / 8 = 0` (truncating `-0.125` towards zero).\n        - Identity: `(0 * 8) + (-1 % 8) == -1`.\n        - Result: This implies `(-1) % 8 = -1`.\n        However, `(-1) \\ 7` is $7$. Since $-1 \\ne 7$, the replacement is semantically incorrect for negative $i$ in these languages. In general, for $i  0$, `$i \\% 8$` will yield a result in $[-7, 0]$, while `$i \\ 7$` yields a result in $[0, 7]$.\n\n    -   **Floor Division (as in Python):** The result of integer division `a // b` is floored (rounded towards negative infinity). The remainder is defined by `(a // b) * b + a % b == a`. A property of this definition is that the sign of the remainder `a % b` matches the sign of the divisor `b`.\n        Let's take $i = -1$ and the divisor $m=8$.\n        - Division: `(-1) // 8 = -1` (flooring `-0.125`).\n        - Identity: `(-1 * 8) + (-1 % 8) == -1`, so `-8 + (-1 % 8) == -1`.\n        - Result: This implies `(-1) % 8 = 7`.\n        This matches the result of `(-1) \\ 7 = 7`. In general, for a positive divisor $m$, Python's `$i \\% m$` operation yields a result in $[0, m-1]$. This is the mathematical remainder, which is identical to the result of `$i \\ (m-1)$` when $m$ is a power of $2$.\n\nWith this foundation, let's evaluate each option.\n\n### Option-by-Option Analysis\n\n**A. In C (since C99) and C++ (since C++11), replacing $i \\% 8$ with $i \\ 7$ is safe for all integral types, including negative values, because both operations are defined on two’s complement representations.**\nThis statement is incorrect. As demonstrated above, for negative values of $i$, the C99/C++11 standard specifies that the sign of `$i \\% m$` is the same as the sign of $i$. For example, `(-1) \\% 8` is $-1$. In contrast, `(-1) \\ 7` is $7$. The results are not equivalent. The reason provided—that both operations are defined on two's complement representations—is a non sequitur; the fact that they are well-defined does not imply they are equivalent.\n**Verdict: Incorrect.**\n\n**B. In C and C++, replacing $i \\% 8$ with $i \\ 7$ is safe if $i$ is an unsigned type, or if $i$ is a signed type and it is known that $i \\ge 0$ at runtime.**\nThis statement is correct.\n- If $i$ is an `unsigned` type, its value is by definition non-negative.\n- If $i$ is a `signed` type but guaranteed to be non-negative ($i \\ge 0$), the same logic applies.\nFor any non-negative integer $i$, both `$i \\% 8$` and `$i \\ 7$` compute the mathematical remainder, yielding identical results in the range $[0, 7]$. Therefore, the replacement is semantically preserving under these conditions.\n**Verdict: Correct.**\n\n**C. In Java (running on the Java Virtual Machine (JVM)), the replacement is unsafe for negative $i$, because $i \\% 8$ may be negative while $i \\ 7$ is always in $[0,7]$.**\nThis statement is correct. The Java Language Specification defines the remainder operator `%` such that the result of `(a/b)*b + (a%b)` is equal to `a`. Integer division truncates towards zero. This is the same rule as in C99/C++11. Consequently, for a negative $i$, `$i \\% 8$` will be non-positive (e.g., `(-1) \\% 8` results in $-1$). The bitwise operation `$i \\ 7$` always results in a non-negative value. Because the results differ for negative $i$, the replacement is unsafe. The reason provided is accurate.\n**Verdict: Correct.**\n\n**D. In Python, the replacement $i \\% 8 \\to i \\ 7$ is safe for all integers, because Python defines $i \\% 8$ as the unique $r$ with $0 \\le r  8$ and $i \\equiv r \\pmod{8}$, which equals the value of the low $3$ bits $i \\ 7$.**\nThis statement is correct. Python's `%` operator is defined based on floor division, which ensures the remainder `$i \\% m$` has the same sign as the divisor $m$. Since the divisor is $8$ (positive), the result of `$i \\% 8$` is always in the range $[0, 7]$. This definition matches the mathematical definition of remainder modulo $8$. As established earlier, the bitwise operation `$i \\ 7$` also computes the mathematical remainder modulo $8$ for any integer $i$. Therefore, the two expressions are equivalent for all integers in Python.\n**Verdict: Correct.**\n\n**E. In C and C++, evaluating $i \\ 7$ when $i$ is a negative signed integer triggers Undefined Behavior (UB), which is why the replacement is unsafe in those cases.**\nThis statement is incorrect. Bitwise operations on signed integers, including negative ones, are well-defined in C and C++. The C standard (e.g., C11 §6.5.10) specifies the behavior of bitwise AND. Modern systems universally use two's complement representation for signed integers, and the bitwise AND operation simply acts on this bit-level representation. For example, `(-1) \\ 7` is well-defined and evaluates to $7$. The replacement `$i \\% 8 \\to i \\ 7$` is unsafe for negative $i$ in C/C++ due to the differing results of the two operators, not because of any Undefined Behavior associated with the bitwise AND operation itself.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{BCD}$$", "id": "3672310"}]}