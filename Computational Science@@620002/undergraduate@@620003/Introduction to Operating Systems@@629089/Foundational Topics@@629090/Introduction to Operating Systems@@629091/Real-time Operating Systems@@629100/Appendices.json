{"hands_on_practices": [{"introduction": "Predictability is the cornerstone of real-time systems. In a time-triggered architecture, this is achieved by creating a static schedule that repeats over a fixed cycle. This exercise [@problem_id:3675995] asks you to determine the length of this fundamental cycle, known as the hyperperiod, for a given set of periodic tasks. Mastering this calculation is the first step in designing any deterministic, table-driven scheduler, as it defines the timeline over which all task executions must be planned.", "problem": "In a Real-Time Operating System (RTOS), consider a single-core processor executing a set of independent, strictly periodic tasks under a Time-Triggered Executive (TTE). Each task $\\tau_i$ has a period $T_i$, a worst-case execution time $C_i$, zero release offset, zero release jitter, and a relative deadline equal to its period. The system tick resolution is $1$ millisecond, and every job is started at an integer multiple of the tick. The task set is:\n- Task $\\tau_A$: $T_A = 12$ milliseconds, $C_A = 3$ milliseconds.\n- Task $\\tau_B$: $T_B = 20$ milliseconds, $C_B = 5$ milliseconds.\n- Task $\\tau_C$: $T_C = 30$ milliseconds, $C_C = 7$ milliseconds.\n- Task $\\tau_D$: $T_D = 50$ milliseconds, $C_D = 10$ milliseconds.\n\nUnder a TTE, a static schedule table is constructed offline that assigns fixed start times to all jobs and repeats identically after a minimal cycle. Starting only from the definitions of periodic tasks and time-triggered scheduling, determine the minimal duration of the repeating cycle of a conflict-free static table for this task set. Express your final answer in milliseconds. Provide the exact integer value; no rounding is required.", "solution": "The problem asks for the minimal duration of a repeating cycle for a static schedule under a Time-Triggered Executive (TTE). The task set is composed of independent, strictly periodic tasks, all with a release offset of zero. This implies a synchronous release of the first job of each task at time $t=0$.\n\nIn such a system, the pattern of all job arrivals repeats over an interval known as the hyperperiod, denoted by $H$. The hyperperiod is the smallest interval of time after which the exact same pattern of job release times recurs. To ensure that a static schedule table can deterministically manage all possible job scheduling scenarios for the lifetime of the system, its length must encompass one full hyperperiod. Therefore, the minimal duration of the repeating cycle for the static schedule is equal to the hyperperiod of the task set.\n\nThe hyperperiod $H$ is mathematically defined as the least common multiple (LCM) of the periods of all tasks in the set. Given the task set $\\{\\tau_A, \\tau_B, \\tau_C, \\tau_D\\}$ with corresponding periods $\\{T_A, T_B, T_C, T_D\\}$, the hyperperiod is calculated as:\n$$H = \\text{lcm}(T_A, T_B, T_C, T_D)$$\nThe provided periods are $T_A = 12$, $T_B = 20$, $T_C = 30$, and $T_D = 50$ milliseconds. We must compute:\n$$H = \\text{lcm}(12, 20, 30, 50)$$\nTo calculate the LCM, we can use the method of prime factorization. We first find the prime factorization of each period:\n\\begin{itemize}\n    \\item $12 = 2 \\times 6 = 2 \\times 2 \\times 3 = 2^2 \\times 3^1$\n    \\item $20 = 2 \\times 10 = 2 \\times 2 \\times 5 = 2^2 \\times 5^1$\n    \\item $30 = 3 \\times 10 = 2^1 \\times 3^1 \\times 5^1$\n    \\item $50 = 5 \\times 10 = 2^1 \\times 5 \\times 5 = 2^1 \\times 5^2$\n\\end{itemize}\nThe LCM is the product of the highest power of each prime factor present in the factorizations. The prime factors are $2$, $3$, and $5$.\n\\begin{itemize}\n    \\item The highest power of the prime factor $2$ is $2^2$.\n    \\item The highest power of the prime factor $3$ is $3^1$.\n    \\item The highest power of the prime factor $5$ is $5^2$.\n\\end{itemize}\nWe multiply these highest powers together to find the hyperperiod $H$:\n$$H = 2^2 \\times 3^1 \\times 5^2$$\n$$H = 4 \\times 3 \\times 25$$\n$$H = 12 \\times 25$$\n$$H = 300$$\nThe minimal duration of the repeating cycle is therefore $300$ milliseconds. The worst-case execution times ($C_i$) are necessary for performing schedulability analysis and constructing the actual schedule table itself, but they do not influence the duration of the fundamental repeating cycle, which is determined solely by the periods.", "answer": "$$\n\\boxed{300}\n$$", "id": "3675995"}, {"introduction": "While time-triggered systems are highly predictable, many real-time applications require the flexibility of priority-driven scheduling. This practice [@problem_id:3675984] moves into that domain, asking you to analyze a system scheduled with the Rate Monotonic (RM) policy. You will derive and apply the foundational technique of Response Time Analysis to calculate how long a task takes to complete amidst interference from higher-priority tasks, a crucial step in proving that all deadlines will be met.", "problem": "Consider a Real-Time Operating System (RTOS) that schedules a set of periodic tasks on a single processor using the Rate Monotonic (RM) fixed-priority policy. Each task $\\tau_i$ is characterized by its period $T_i$, Worst-Case Execution Time (WCET) $C_i$, relative deadline $D_i$, and a blocking term $B_i$ accounting for worst-case priority inversion due to mutually exclusive shared resources. Assume preemptive scheduling, deadlines equal periods ($D_i = T_i$), and that all tasks are released synchronously at time $t = 0$, which defines the worst case for fixed-priority response times.\n\nUsing only the following foundational facts:\n- Under RM, tasks with shorter period have higher static priority.\n- The worst-case response time $R_i$ of a task $\\tau_i$ is the maximum time from the taskâ€™s release to the completion of its instance under worst-case preemptions and blocking.\n- Interference from higher-priority tasks in any interval of length $R$ equals the processor demand of all jobs of higher-priority tasks that can arrive and execute within that interval, and the number of jobs of a periodic task that can arrive in an interval of length $R$ is determined by the properties of periodic arrivals.\n\nDerive from these principles a method that bounds the worst-case response time $R_i$ of a task $\\tau_i$ using its blocking $B_i$, its own execution time $C_i$, and an interference function $I_i(R)$ that accounts for all higher-priority tasks. Then, apply your derived method to the following task set, scheduled under RM, to compute the bound on the response time of $\\tau_3$. Use the given parameters and interpret the processor as work-conserving and non-idle when there is pending work.\n\nTask parameters:\n- $\\tau_1$: $T_1 = 10\\,\\mathrm{ms}, C_1 = 1\\,\\mathrm{ms}, B_1 = 0\\,\\mathrm{ms}$.\n- $\\tau_2$: $T_2 = 15\\,\\mathrm{ms}, C_2 = 2\\,\\mathrm{ms}, B_2 = 0\\,\\mathrm{ms}$.\n- $\\tau_3$: $T_3 = 40\\,\\mathrm{ms}, C_3 = 8\\,\\mathrm{ms}, B_3 = 1\\,\\mathrm{ms}$.\n\nExpress the final response time bound for $\\tau_3$ in milliseconds. If your result is not an integer, round to four significant figures; otherwise, report the exact integer value.", "solution": "The problem requires the derivation of a method to bound the worst-case response time of a periodic task and its application to a specific task set.\n\n**Part 1: Derivation of the Response Time Analysis Method**\n\nLet $\\tau_i$ be a periodic task with Worst-Case Execution Time (WCET) $C_i$, period $T_i$, and worst-case blocking time $B_i$ from lower-priority tasks. We are given that tasks are scheduled on a single processor using a preemptive, fixed-priority Rate Monotonic (RM) policy. Under RM, a task's static priority is inversely proportional to its period; thus, a shorter period $T_i$ implies a higher priority. The worst-case scenario for response time occurs with a synchronous release of all tasks at time $t=0$.\n\nThe worst-case response time $R_i$ for a task $\\tau_i$ is the time elapsed from its release until it completes its execution. During this interval, the processor is busy executing $\\tau_i$ itself, higher-priority tasks that preempt it, or lower-priority tasks that block it. Since the processor is work-conserving, the total time $R_i$ must be equal to the sum of these contributions.\n\nThe components of the response time are:\n1.  The task's own execution time, $C_i$.\n2.  The maximum time the task can be blocked by lower-priority tasks, $B_i$. This blocking can occur once, typically at the beginning of the task's execution.\n3.  The total interference from all higher-priority tasks, denoted as $I_i$.\n\nThus, we can state that the response time $R_i$ is the sum of these three terms:\n$$ R_i = C_i + B_i + I_i $$\n\nThe third foundational fact provided guides the formulation of the interference term $I_i$. The interference on $\\tau_i$ over an interval of length $t$ is the total execution demand of all higher-priority tasks released within that interval. Let $hp(i)$ be the set of all tasks with higher priority than $\\tau_i$.\n\nFor any higher-priority task $\\tau_j \\in hp(i)$ with period $T_j$ and WCET $C_j$, we need to find the maximum number of times it can be released in an interval of length $R_i$. Given synchronous release at $t=0$, jobs of $\\tau_j$ are released at times $0, T_j, 2T_j, \\ldots, k_j T_j$ such that $k_j T_j < R_i$. The number of such releases in the interval $[0, R_i)$ is $\\lfloor R_i/T_j \\rfloor + 1$ if $R_i$ is not a multiple of $T_j$, and $R_i/T_j$ jobs released in $[0, R_i-T_j]$ if it is. A more concise way to express the number of jobs of $\\tau_j$ that can be released and must complete within the busy period of length $R_i$ is given by the ceiling function: $\\lceil \\frac{R_i}{T_j} \\rceil$.\n\nEach of these jobs contributes $C_j$ to the processor demand. Therefore, the total interference from task $\\tau_j$ over the interval $R_i$ is $\\left\\lceil \\frac{R_i}{T_j} \\right\\rceil C_j$. The total interference $I_i$ is the sum of interference from all tasks in $hp(i)$:\n$$ I_i(R_i) = \\sum_{j \\in hp(i)} \\left\\lceil \\frac{R_i}{T_j} \\right\\rceil C_j $$\n\nSubstituting this expression for interference back into the response time equation, we arrive at the following relation for $R_i$:\n$$ R_i = C_i + B_i + \\sum_{j \\in hp(i)} \\left\\lceil \\frac{R_i}{T_j} \\right\\rceil C_j $$\nThis equation defines $R_i$ in terms of itself. It does not have a general closed-form solution. The \"method\" to bound $R_i$ is an iterative procedure to find the smallest value of $R_i$ that satisfies the equation. This is accomplished by forming a recurrence relation:\n$$ R_i^{(k+1)} = C_i + B_i + \\sum_{j \\in hp(i)} \\left\\lceil \\frac{R_i^{(k)}}{T_j} \\right\\rceil C_j $$\nThe iteration starts with an initial guess for the response time. A suitable starting point is the time required with no interference, $R_i^{(0)} = C_i + B_i$. The sequence of values $R_i^{(k)}$ is guaranteed to be non-decreasing. The iteration continues until a fixed point is reached, i.e., $R_i^{(k+1)} = R_i^{(k)}$. This fixed-point value is the worst-case response time $R_i$. If at any point $R_i^{(k)}$ exceeds the task's deadline $D_i$, the task is deemed unschedulable.\n\n**Part 2: Application to the Given Task Set**\n\nThe task parameters are:\n- $\\tau_1$: $T_1 = 10$ ms, $C_1 = 1$ ms, $B_1 = 0$ ms.\n- $\\tau_2$: $T_2 = 15$ ms, $C_2 = 2$ ms, $B_2 = 0$ ms.\n- $\\tau_3$: $T_3 = 40$ ms, $C_3 = 8$ ms, $B_3 = 1$ ms.\n\nUnder the Rate Monotonic (RM) scheduling policy, priorities are assigned based on task periods. A shorter period implies a higher priority.\nSince $T_1 < T_2 < T_3$ ($10 < 15 < 40$), the priority ordering is: Priority$(\\tau_1) >$ Priority$(\\tau_2) >$ Priority$(\\tau_3)$.\n\nWe need to compute the bound on the response time of $\\tau_3$, denoted as $R_3$. The set of tasks with higher priority than $\\tau_3$ is $hp(3) = \\{\\tau_1, \\tau_2\\}$.\n\nUsing the derived formula for $R_3$:\n$$ R_3 = C_3 + B_3 + \\left\\lceil \\frac{R_3}{T_1} \\right\\rceil C_1 + \\left\\lceil \\frac{R_3}{T_2} \\right\\rceil C_2 $$\nSubstituting the given numerical values:\n$$ R_3 = 8 + 1 + \\left\\lceil \\frac{R_3}{10} \\right\\rceil (1) + \\left\\lceil \\frac{R_3}{15} \\right\\rceil (2) $$\n$$ R_3 = 9 + \\left\\lceil \\frac{R_3}{10} \\right\\rceil + 2 \\left\\lceil \\frac{R_3}{15} \\right\\rceil $$\nWe solve this equation iteratively. Let $w_3^{(k)}$ denote the $k$-th iteration for the response time of $\\tau_3$.\nThe initial guess is $w_3^{(0)} = C_3 + B_3 = 8 + 1 = 9$.\n\nIteration 1:\n$$ w_3^{(1)} = 9 + \\left\\lceil \\frac{w_3^{(0)}}{10} \\right\\rceil + 2 \\left\\lceil \\frac{w_3^{(0)}}{15} \\right\\rceil = 9 + \\left\\lceil \\frac{9}{10} \\right\\rceil + 2 \\left\\lceil \\frac{9}{15} \\right\\rceil $$\n$$ w_3^{(1)} = 9 + \\lceil 0.9 \\rceil + 2 \\lceil 0.6 \\rceil = 9 + 1 + 2(1) = 12 $$\n\nIteration 2:\n$$ w_3^{(2)} = 9 + \\left\\lceil \\frac{w_3^{(1)}}{10} \\right\\rceil + 2 \\left\\lceil \\frac{w_3^{(1)}}{15} \\right\\rceil = 9 + \\left\\lceil \\frac{12}{10} \\right\\rceil + 2 \\left\\lceil \\frac{12}{15} \\right\\rceil $$\n$$ w_3^{(2)} = 9 + \\lceil 1.2 \\rceil + 2 \\lceil 0.8 \\rceil = 9 + 2 + 2(1) = 13 $$\n\nIteration 3:\n$$ w_3^{(3)} = 9 + \\left\\lceil \\frac{w_3^{(2)}}{10} \\right\\rceil + 2 \\left\\lceil \\frac{w_3^{(2)}}{15} \\right\\rceil = 9 + \\left\\lceil \\frac{13}{10} \\right\\rceil + 2 \\left\\lceil \\frac{13}{15} \\right\\rceil $$\n$$ w_3^{(3)} = 9 + \\lceil 1.3 \\rceil + 2 \\lceil 0.866... \\rceil = 9 + 2 + 2(1) = 13 $$\n\nSince $w_3^{(3)} = w_3^{(2)} = 13$, the iteration has converged. The fixed point is $13$.\nThe worst-case response time bound for task $\\tau_3$ is $R_3 = 13$ ms. This value is also less than the deadline $D_3 = T_3 = 40$ ms, so the task is schedulable, though this was not required by the problem.\n\nThe final result is an integer, so no rounding is necessary.", "answer": "$$ \\boxed{13} $$", "id": "3675984"}, {"introduction": "In real-world systems, tasks rarely run in complete isolation; they often need to share resources like data buffers or peripherals. Without careful management, this can lead to a hazardous condition called priority inversion, where a high-priority task is blocked by a low-priority one. This practice [@problem_id:3676081] guides you through identifying this problem and applying the Priority Ceiling Protocol to solve it, allowing you to calculate the worst-case blocking time a task may experience.", "problem": "Consider a preemptive fixed-priority uniprocessor scheduler for Real-Time Operating Systems (RTOS), where priorities are assigned by rate monotonic ordering. Three periodic tasks $A$, $B$, and $C$ run on the processor with periods, worst-case execution times (WCETs), and critical-section usage as follows:\n\n- Task $A$: period $T_{A} = 10\\,\\mathrm{ms}$, WCET $C_{A} = 1\\,\\mathrm{ms}$. Within its execution, $A$ locks a shared mutex-protected resource $R_{1}$ for up to $0.80\\,\\mathrm{ms}$.\n- Task $C$: period $T_{C} = 20\\,\\mathrm{ms}$, WCET $C_{C} = 2\\,\\mathrm{ms}$. Within its execution, $C$ locks a different shared resource $R_{2}$ for up to $0.60\\,\\mathrm{ms}$.\n- Task $B$: period $T_{B} = 40\\,\\mathrm{ms}$, WCET $C_{B} = 5\\,\\mathrm{ms}$. Within its execution, $B$ locks $R_{1}$ for up to $1.20\\,\\mathrm{ms}$ and, in a separate non-overlapping segment, locks $R_{2}$ for up to $2.50\\,\\mathrm{ms}$.\n\nAssume that the relative deadline of each task equals its period, and that mutexes provide mutually exclusive access with no busy waiting (i.e., a blocked task is suspended).\n\n1. Explain how priority inversion can occur among $A$, $B$, and $C$ under this setup without any resource access protocol. Your explanation must rely on the fundamental definitions of preemptive fixed-priority scheduling, blocking due to mutual exclusion, and the notion of priority inversion.\n2. Propose a systematic fix using the Priority Ceiling Protocol (PCP) and explain at a conceptual level how it prevents unbounded priority inversion in this scenario. Your explanation must start from the core definitions of resource ceilings and the rule governing when a task is permitted to lock a resource.\n3. Under the Priority Ceiling Protocol (PCP), determine the worst-case blocking time $B_{A}$ experienced by task $A$ due to lower-priority tasks. Base your derivation on first principles from resource ceilings and blocking semantics, not on quoting a pre-packaged bound. Report the final value for $B_{A}$ in milliseconds. Round your answer to three significant figures.", "solution": "The scheduling policy is preemptive fixed-priority, with priorities assigned via rate monotonic ordering. This means a task's priority is inversely proportional to its period. Given the periods $T_{A} = 10\\,\\mathrm{ms}$, $T_{C} = 20\\,\\mathrm{ms}$, and $T_{B} = 40\\,\\mathrm{ms}$, the priority ordering is $P_{A} > P_{C} > P_{B}$, where $P_{i}$ is the priority of task $i$. Task $A$ has the highest priority, $C$ has medium priority, and $B$ has the lowest priority.\n\n1. Explanation of Priority Inversion\n\nPriority inversion is a scenario in which a high-priority task is forced to wait for a lower-priority task to execute. In a preemptive scheduler, a high-priority task should ideally only be delayed by its own computation or by tasks of even higher priority. Blocking on a shared resource held by a lower-priority task is a form of priority inversion. The problem becomes severe when this blocking duration is not bounded or is prolonged by the execution of intermediate-priority tasks.\n\nA specific scenario illustrating this \"unbounded\" priority inversion among tasks $A$, $B$, and $C$ without a resource access protocol is as follows:\n\n- **Time $t_{0}$**: Task $B$ (low priority) begins execution.\n- **Time $t_{1}$**: Task $B$ locks the mutex for resource $R_{1}$.\n- **Time $t_{2}$**: Task $A$ (high priority) becomes ready to run. It preempts task $B$ as $P_{A} > P_{B}$.\n- **Time $t_{3}$**: Task $A$ executes and attempts to lock the mutex for resource $R_{1}$. Since $R_{1}$ is held by task $B$, task $A$ is blocked and suspended. The scheduler gives the CPU back to the highest-priority ready task, which is now task $B$. Task $B$ must execute to release the lock on $R_{1}$.\n- **Time $t_{4}$**: Task $C$ (medium priority) becomes ready to run. Since $P_{C} > P_{B}$, task $C$ preempts task $B$.\n- **From $t_{4}$ onwards**: Task $C$ executes. The high-priority task $A$ remains blocked, waiting for the low-priority task $B$. However, task $B$ cannot execute to release the resource because it is being preempted by the medium-priority task $C$. Task $A$'s waiting time is now dependent on the execution time of task $C$. If other medium-priority tasks were to arrive, they would also preempt $B$, potentially extending $A$'s blocking time indefinitely. This constitutes an unbounded priority inversion.\n\n2. The Priority Ceiling Protocol (PCP) as a Solution\n\nA systematic fix for this problem is the Priority Ceiling Protocol (PCP). It prevents unbounded priority inversion and deadlocks by augmenting the standard mutex mechanism with specific rules based on resource ceilings.\n\nThe core definitions of PCP are:\n- **Priority Ceiling of a Resource**: The priority ceiling of a resource $R_{k}$, denoted $\\mathrm{Ceiling}(R_{k})$, is the priority of the highest-priority task that can ever lock $R_{k}$.\n- **System Ceiling**: At any time $t$, the system ceiling, $\\hat{\\Pi}(t)$, is the maximum of the priority ceilings of all resources currently locked. If no resource is locked, the system ceiling is a special value $\\Omega$ that is lower than any task priority.\n\nFor the given problem, the resource ceilings are:\n- Resource $R_{1}$ is used by tasks $A$ and $B$. Priorities are $P_{A}$ and $P_{B}$. The higher priority is $P_{A}$. Thus, $\\mathrm{Ceiling}(R_{1}) = P_{A}$.\n- Resource $R_{2}$ is used by tasks $C$ and $B$. Priorities are $P_{C}$ and $P_{B}$. The higher priority is $P_{C}$. Thus, $\\mathrm{Ceiling}(R_{2}) = P_{C}$.\n\nPCP employs two key rules:\n- **Locking Rule**: A task $T_{i}$ with priority $P_{i}$ can lock a resource only if its priority $P_{i}$ is strictly greater than the current system ceiling $\\hat{\\Pi}(t)$. If not, $T_{i}$ is blocked (this is called ceiling blocking).\n- **Inheritance Rule**: When a task $T_{i}$ is blocked by a lower-priority task $T_{j}$ (either directly on a resource or via ceiling blocking), $T_{j}$ temporarily inherits the priority of $T_{i}$ and executes at this higher priority until it releases all resources that caused $T_{i}$ (or other higher-priority tasks) to block.\n\nPCP prevents the previously described priority inversion scenario as follows:\n1. Task $B$ locks $R_{1}$. The system ceiling $\\hat{\\Pi}(t)$ becomes $\\mathrm{Ceiling}(R_{1}) = P_{A}$.\n2. Task $A$ preempts $B$, runs, and attempts to lock $R_{1}$. It blocks.\n3. According to the inheritance rule, task $B$ now inherits the priority of task $A$, so it executes with priority $P_{A}$.\n4. Task $C$ becomes ready. It attempts to preempt the currently running task, which is $B$. However, $B$ is now running at priority $P_{A}$, and since $P_{C} < P_{A}$, task $C$ cannot preempt task $B$.\n5. Task $B$ continues to execute at high priority until it releases $R_{1}$. Once $R_{1}$ is released, $B$'s priority reverts to $P_{B}$. Task $A$ is unblocked and, being the highest-priority ready task, immediately preempts $B$ and runs. The blocking of $A$ is limited to the time it takes $B$ to finish its critical section, and is not affected by task $C$.\n\n3. Worst-Case Blocking Time for Task A under PCP\n\nThe worst-case blocking time $B_{i}$ for a task $T_{i}$ under PCP is the duration of at most one critical section of a single lower-priority task. From first principles, a task $T_{i}$ can be blocked either directly by requesting a resource held by a lower-priority task $T_{j}$, or indirectly (ceiling blocking) if it is prevented from executing because $T_{j}$ holds a resource $R_{k}$ whose ceiling is at least as high as $P_i$. The condition for a lower-priority task $T_{j}$ to be able to block $T_{i}$ is that $T_{j}$ uses a resource $R_{k}$ such that $\\mathrm{Ceiling}(R_{k}) \\ge P_{i}$.\n\nWe are interested in the worst-case blocking time for task $A$, $B_{A}$. The priority of task $A$ is $P_{A}$. The lower-priority tasks are $C$ and $B$.\n\n- **Potential blocking from Task $C$ (priority $P_C < P_A$):**\nTask $C$ uses resource $R_{2}$. The ceiling of this resource is $\\mathrm{Ceiling}(R_{2}) = P_{C}$. We check if $\\mathrm{Ceiling}(R_{2}) \\ge P_{A}$. This is false, as $P_{C} < P_{A}$. Therefore, task $C$ holding resource $R_{2}$ cannot cause ceiling blocking for task $A$. Furthermore, since task $A$ never uses $R_{2}$, there can be no direct blocking. Thus, task $C$ cannot block task $A$ under PCP.\n\n- **Potential blocking from Task $B$ (priority $P_B < P_A$):**\nTask $B$ uses resources $R_{1}$ and $R_{2}$. We analyze each case.\n- Usage of $R_{2}$: The ceiling is $\\mathrm{Ceiling}(R_{2}) = P_{C}$. As established, $P_C < P_A$, so task $B$ holding $R_2$ cannot cause ceiling blocking for task $A$. There is no direct blocking as $A$ does not use $R_2$.\n- Usage of $R_{1}$: The ceiling is $\\mathrm{Ceiling}(R_{1}) = P_{A}$. We check if $\\mathrm{Ceiling}(R_{1}) \\ge P_{A}$. This is true. Therefore, if task $B$ holds $R_{1}$, it can block task $A$. This blocking can occur if task $A$ becomes ready and finds that task $B$ has already locked $R_{1}$. Task $A$ would then be blocked for the duration of task $B$'s critical section on $R_{1}$. The worst-case duration for this blocking is the WCET of this critical section, which is given as $1.20\\,\\mathrm{ms}$.\n\nCombining these findings, the only source of blocking for task $A$ is from task $B$ holding resource $R_{1}$. The set of possible blocking durations for task $A$ consists of a single value, the length of task $B$'s critical section on $R_{1}$.\n\nThe worst-case blocking time for task $A$ is the maximum of all possible blocking durations.\n$$ B_{A} = \\max\\{ \\text{length of } CS_{B,R_1} \\} $$\nwhere $ CS_{B,R_1} $ is the critical section of task $B$ on resource $R_1$.\n$$ B_{A} = 1.20\\,\\mathrm{ms} $$\nThe value is already expressed to three significant figures.", "answer": "$$\\boxed{1.20}$$", "id": "3676081"}]}