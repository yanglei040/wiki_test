{"hands_on_practices": [{"introduction": "This practice delves into the tangible costs of using a real-time operating system by quantifying the CPU time consumed by context switching. Understanding this overhead is critical in resource-constrained embedded systems, as every cycle spent by the OS is a cycle not available for your application. By analyzing a hypothetical schedule and accounting for performance variations like cache states, you will develop the essential skill of modeling and calculating the true performance impact of core OS mechanisms [@problem_id:3638732].", "problem": "An embedded controller running a preemptive fixed-priority Real-Time Operating System (RTOS) on a Central Processing Unit (CPU) provides a cycle counter that increments once per core clock cycle. The cycle counter can be read in software immediately before and after a context switch to empirically determine the number of cycles spent in the operating system during a switch of the running thread. Measurements on this platform reveal two repeatable regimes for the per-switch cycle count: a cache-hot path of $c_{h} = 420$ cycles and a cache-cold path of $c_{c} = 900$ cycles. In steady-state operation, the cache-hot path occurs with probability $p_{h} = 0.75$ and the cache-cold path with probability $p_{c} = 0.25$. The CPU clock frequency is $f_{\\mathrm{clk}} = 168 \\times 10^{6}\\ \\mathrm{Hz}$. Assume that each change in the identity of the running task, including transitions to or from the idle task, incurs exactly one context switch whose cost is distributed as above. Ignore all other sources of overhead.\n\nA set of three independent periodic tasks is scheduled by rate-monotonic priority assignment (shorter period implies higher priority). Their periods and worst-case execution times (exclusive of operating system overhead) are:\n- Task $\\tau_{1}$ with period $T_{1} = 2\\,\\mathrm{ms}$ and execution time $C_{1} = 0.2\\,\\mathrm{ms}$,\n- Task $\\tau_{2}$ with period $T_{2} = 5\\,\\mathrm{ms}$ and execution time $C_{2} = 0.7\\,\\mathrm{ms}$,\n- Task $\\tau_{3}$ with period $T_{3} = 10\\,\\mathrm{ms}$ and execution time $C_{3} = 1.6\\,\\mathrm{ms}$.\n\nAssume fully preemptive scheduling, tickless operation (dispatches occur only on job releases that preempt the current task or on job completions), and worst-case synchronous releases at time $t = 0$ for all tasks. The idle task is always ready at the lowest priority.\n\nUsing only the fundamental relationships that (i) time equals cycles divided by frequency and (ii) processor utilization over an interval equals the fraction of that interval spent executing, determine the expected fraction of processor time within one hyperperiod spent performing context switches under the above schedule. Express your final answer as a decimal fraction without a percent sign, and round your answer to four significant figures.", "solution": "The user wants to determine the expected fraction of processor time spent on context switches. This quantity, which we can denote as $U_{sw}$, is defined as the total expected time spent on context switches over a characteristic interval, divided by the duration of that interval. For a set of periodic tasks, the characteristic interval is the hyperperiod, $H$.\n\nThe total expected time for context switches is the product of the number of context switches within the hyperperiod, $N_{sw}$, and the expected time for a single context switch, $E[T_{sw}]$.\n$$U_{sw} = \\frac{N_{sw} \\times E[T_{sw}]}{H}$$\n\nThe solution is structured as follows:\n1.  Calculate the expected time for a single context switch, $E[T_{sw}]$.\n2.  Determine the hyperperiod, $H$.\n3.  Determine the number of context switches, $N_{sw}$, within one hyperperiod by simulating the schedule.\n4.  Combine these values to calculate the final fraction $U_{sw}$.\n\n**1. Expected Time per Context Switch, $E[T_{sw}]$**\n\nThe problem provides the cycle counts for two types of context switches: a cache-hot path ($c_{h}$) and a cache-cold path ($c_{c}$), along with their respective probabilities of occurrence, $p_{h}$ and $p_{c}$.\nGiven values:\n-   $c_{h} = 420$ cycles\n-   $c_{c} = 900$ cycles\n-   $p_{h} = 0.75$\n-   $p_{c} = 0.25$\n\nThe expected number of cycles per context switch, $E[C_{sw}]$, is the weighted average:\n$$E[C_{sw}] = c_{h} p_{h} + c_{c} p_{c}$$\n$$E[C_{sw}] = (420 \\times 0.75) + (900 \\times 0.25) = 315 + 225 = 540 \\text{ cycles}$$\n\nThe CPU clock frequency is given as $f_{\\mathrm{clk}} = 168 \\times 10^{6}\\ \\mathrm{Hz}$. The expected time for a single context switch, $E[T_{sw}]$, is the expected number of cycles divided by the clock frequency:\n$$E[T_{sw}] = \\frac{E[C_{sw}]}{f_{\\mathrm{clk}}} = \\frac{540}{168 \\times 10^{6}} \\text{ s}$$\n\n**2. Hyperperiod, $H$**\n\nThe hyperperiod is the least common multiple (LCM) of the task periods.\nGiven periods:\n-   $T_{1} = 2\\,\\mathrm{ms}$\n-   $T_{2} = 5\\,\\mathrm{ms}$\n-   $T_{3} = 10\\,\\mathrm{ms}$\n\n$$H = \\mathrm{lcm}(T_{1}, T_{2}, T_{3}) = \\mathrm{lcm}(2, 5, 10) = 10\\,\\mathrm{ms}$$\n\n**3. Number of Context Switches in the Hyperperiod, $N_{sw}$**\n\nThe scheduling is rate-monotonic, so priority is assigned inversely to the period: Priority($\\tau_{1}$) > Priority($\\tau_{2}$) > Priority($\\tau_{3}$). The scheduling is preemptive, and all tasks are released synchronously at $t=0$. We must trace the execution over the hyperperiod ($0$ to $10\\,\\mathrm{ms}$) to count the context switches. A context switch occurs each time the identity of the running task changes.\n\n-   $t=0$: All tasks are released. The idle task is preempted by $\\tau_{1}$ (highest priority). **Switch 1**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=0.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 1) completes ($C_{1}=0.2\\,\\mathrm{ms}$). $\\tau_{2}$ is the highest priority ready task. **Switch 2**: $\\tau_{1} \\rightarrow \\tau_{2}$.\n-   $t=0.9\\,\\mathrm{ms}$: $\\tau_{2}$ (job 1) completes ($C_{2}=0.7\\,\\mathrm{ms}$). $\\tau_{3}$ is the highest priority ready task. **Switch 3**: $\\tau_{2} \\rightarrow \\tau_{3}$.\n-   $t=2.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the running task $\\tau_{3}$. **Switch 4**: $\\tau_{3} \\rightarrow \\tau_{1}$.\n-   $t=2.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 2) completes. $\\tau_{3}$ (which was preempted) is the highest priority ready task and resumes. **Switch 5**: $\\tau_{1} \\rightarrow \\tau_{3}$.\n-   $t=2.7\\,\\mathrm{ms}$: $\\tau_{3}$ completes. It ran for $1.1\\,\\mathrm{ms}$ before preemption and $0.5\\,\\mathrm{ms}$ after, totaling $C_{3}=1.6\\,\\mathrm{ms}$. No tasks are ready. The idle task runs. **Switch 6**: $\\tau_{3} \\rightarrow$ Idle.\n-   $t=4.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the idle task. **Switch 7**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=4.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 3) completes. The idle task runs. **Switch 8**: $\\tau_{1} \\rightarrow$ Idle.\n-   $t=5.0\\,\\mathrm{ms}$: A new job of $\\tau_{2}$ is released. It preempts the idle task. **Switch 9**: Idle $\\rightarrow \\tau_{2}$.\n-   $t=5.7\\,\\mathrm{ms}$: $\\tau_{2}$ (job 2) completes. The idle task runs. **Switch 10**: $\\tau_{2} \\rightarrow$ Idle.\n-   $t=6.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the idle task. **Switch 11**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=6.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 4) completes. The idle task runs. **Switch 12**: $\\tau_{1} \\rightarrow$ Idle.\n-   $t=8.0\\,\\mathrm{ms}$: A new job of $\\tau_{1}$ is released. It preempts the idle task. **Switch 13**: Idle $\\rightarrow \\tau_{1}$.\n-   $t=8.2\\,\\mathrm{ms}$: $\\tau_{1}$ (job 5) completes. The idle task runs. **Switch 14**: $\\tau_{1} \\rightarrow$ Idle.\n-   $t=10.0\\,\\mathrm{ms}$: The hyperperiod ends.\n\nThe total number of context switches in one hyperperiod is $N_{sw} = 14$.\n\n**4. Final Calculation**\n\nNow we can calculate the expected fraction of processor time spent on context switches, $U_{sw}$.\n$$U_{sw} = \\frac{N_{sw} \\times E[T_{sw}]}{H} = \\frac{14 \\times \\left(\\frac{540}{168 \\times 10^{6}}\\right)}{10 \\times 10^{-3}}$$\n$$U_{sw} = \\frac{14 \\times 540}{(168 \\times 10^{6}) \\times (10 \\times 10^{-3})} = \\frac{7560}{168 \\times 10^{4}} = \\frac{7560}{1,680,000}$$\nTo simplify the fraction:\n$$U_{sw} = \\frac{756}{168,000}$$\nSince $168 \\times 4.5 = 756$:\n$$U_{sw} = \\frac{4.5}{1000} = 0.0045$$\nThe problem requires the answer to be a decimal fraction rounded to four significant figures.\n$$0.0045 = 4.5 \\times 10^{-3}$$\nTo four significant figures, this is $4.500 \\times 10^{-3}$.", "answer": "$$\\boxed{4.500 \\times 10^{-3}}$$", "id": "3638732"}, {"introduction": "Embedded systems frequently act as a bridge between hardware sensors and software logic, creating classic producer-consumer scenarios where data must be buffered. This exercise challenges you to determine the minimum required buffer size to prevent data loss during a high-intensity burst of messages. You will learn to apply a fundamental analysis technique—tracking cumulative arrivals and completions—to find the maximum queue occupancy, a critical skill for dimensioning system resources and ensuring data integrity [@problem_id:3638790].", "problem": "An embedded microcontroller handles events from a sensor that, under certain operating conditions, emits a finite burst of messages. During any such burst, exactly $B$ messages are produced uniformly over a contiguous time window of length $T_{s}$, with one message every $T_{s}/B$ seconds from the burst start until the burst end. Messages are enqueued in a finite-capacity First-In-First-Out (FIFO) buffer before being consumed by a periodic software task.\n\nThe consumer is a periodic task scheduled on the Central Processing Unit (CPU) with period $T_{p}$. Each job of the consumer task removes exactly one message from the head of the queue and completes it before the next period; no job removes more than one message. In the worst-case phasing, the first message completion by the consumer occurs at time $T_{p}$ after the burst start, and then one completion occurs at each multiple of $T_{p}$. The queue is initially empty at the burst start, and there are no other sources of messages.\n\nUsing only fundamental definitions of cumulative arrivals and completions, and without assuming any unproven queuing formulae, determine the minimal buffer capacity $N$ (expressed as an integer number of messages) that guarantees no message is dropped during the burst. Use the following concrete parameters: $B = 50$, $T_{s} = 220\\,\\mathrm{ms}$, and $T_{p} = 40\\,\\mathrm{ms}$. Express the final buffer capacity as an integer number of messages. No rounding is required beyond the inherent integrality of the answer.", "solution": "The problem asks for the minimal buffer capacity, $N$, required to prevent message loss from a finite burst of arrivals being processed by a periodic consumer task. The minimal capacity must be equal to the maximum number of messages that can simultaneously reside in the queue. This can be determined by analyzing the cumulative number of message arrivals and completions over time.\n\nLet $t=0$ represent the start of the burst event. The problem statement specifies a uniform production of messages over a time window. We model this deterministically.\n\nFirst, we define the cumulative arrival function, $A(t)$, which counts the total number of messages that have arrived in the queue by time $t$. There are $B$ messages in total. The inter-arrival time is constant, given as $T_a = T_s/B$. A standard and consistent interpretation of the problem statement \"one message every $T_s/B$ seconds from the burst start\" is that the $k$-th message arrives at time $t_k = k \\cdot (T_s/B)$ for $k \\in \\{1, 2, \\dots, B\\}$. Thus, the first message arrives at $t_1 = T_s/B$ and the last message arrives at $t_B = B \\cdot (T_s/B) = T_s$. The cumulative arrival function $A(t)$ is a step function defined as:\n$$\nA(t) =\n\\begin{cases}\n0 & \\text{if } t < T_s/B \\\\\n\\lfloor \\frac{t}{T_s/B} \\rfloor = \\lfloor \\frac{tB}{T_s} \\rfloor & \\text{if } T_s/B \\le t \\le T_s \\\\\nB & \\text{if } t > T_s\n\\end{cases}\n$$\n\nNext, we define the cumulative completion function, $C(t)$, which counts the total number of messages consumed by the task by time $t$. The consumer task is periodic with period $T_p$. The problem specifies a worst-case phasing where the first completion occurs at time $T_p$, and subsequent completions occur at every multiple of $T_p$. Therefore, the $j$-th message is completed at time $j \\cdot T_p$. The cumulative completion function $C(t)$ is also a step function:\n$$\nC(t) = \\lfloor \\frac{t}{T_p} \\rfloor, \\quad \\text{for } t \\ge 0\n$$\n\nThe number of messages in the queue at any time $t$, denoted by $Q(t)$, is the difference between the cumulative arrivals and cumulative completions:\n$$\nQ(t) = A(t) - C(t)\n$$\nThe minimal required buffer capacity $N$ is the maximum value of $Q(t)$ over all time $t \\ge 0$.\n$$\nN = \\max_{t \\ge 0} Q(t) = \\max_{t \\ge 0} \\left( A(t) - C(t) \\right)\n$$\nAfter time $t=T_s$, no more messages arrive, so $A(t) = B$ for $t > T_s$. However, the consumer task continues to process messages, so $C(t)$ continues to increase. Consequently, $Q(t)$ will be a non-increasing function for $t > T_s$. Therefore, the maximum queue length must occur at some time $t \\le T_s$ (or at an instant just after $T_s$ before the next service completion).\n\nThe queue length $Q(t)$ can only increase at the discrete time instants when a message arrives. Between any two consecutive arrivals, say $t_k$ and $t_{k+1}$, $A(t)$ is constant, while $C(t)$ is non-decreasing. This means that $Q(t) = A(t) - C(t)$ is non-increasing in any interval $(t_k, t_{k+1})$. Thus, the maximum value of $Q(t)$ must occur at one of the arrival times $t_k$. We can analyze the queue length at the infinitesimally small moment just after each arrival, $t_k^+$.\n\nLet $Q_k$ be the queue length immediately after the $k$-th arrival at time $t_k = k \\frac{T_s}{B}$. At this time, exactly $k$ messages have arrived, so $A(t_k) = k$. The number of completed messages is $C(t_k) = \\lfloor \\frac{t_k}{T_p} \\rfloor$.\nThe queue length is:\n$$\nQ_k = k - \\left\\lfloor \\frac{k T_s/B}{T_p} \\right\\rfloor = k - \\left\\lfloor k \\frac{T_s}{B T_p} \\right\\rfloor \\quad \\text{for } k \\in \\{1, 2, \\dots, B\\}\n$$\nTo find the maximum queue length, we must find the maximum value of $Q_k$ for $k$ from $1$ to $B$. Let us analyze the behavior of $Q_k$ as a function of $k$. Consider the difference $Q_{k+1} - Q_k$:\n$$\nQ_{k+1} - Q_k = \\left( (k+1) - \\left\\lfloor (k+1) \\frac{T_s}{B T_p} \\right\\rfloor \\right) - \\left( k - \\left\\lfloor k \\frac{T_s}{B T_p} \\right\\rfloor \\right)\n$$\n$$\nQ_{k+1} - Q_k = 1 - \\left( \\left\\lfloor k \\frac{T_s}{B T_p} + \\frac{T_s}{B T_p} \\right\\rfloor - \\left\\lfloor k \\frac{T_s}{B T_p} \\right\\rfloor \\right)\n$$\nLet $x = k \\frac{T_s}{B T_p}$ and $\\alpha = \\frac{T_s}{B T_p}$. The difference is $1 - (\\lfloor x+\\alpha \\rfloor - \\lfloor x \\rfloor)$. From the properties of the floor function, we know that $0 \\le \\lfloor x+\\alpha \\rfloor - \\lfloor x \\rfloor \\le \\lceil \\alpha \\rceil$.\nLet's calculate $\\alpha$ with the given parameters: $B = 50$, $T_s = 220\\,\\mathrm{ms}$, and $T_p = 40\\,\\mathrm{ms}$.\n$$\n\\alpha = \\frac{220}{50 \\times 40} = \\frac{220}{2000} = \\frac{11}{100} = 0.11\n$$\nSince $0  \\alpha  1$, the term $\\lfloor x+\\alpha \\rfloor - \\lfloor x \\rfloor$ can be either $0$ or $1$.\nTherefore, $Q_{k+1} - Q_k$ is either $1 - 0 = 1$ or $1 - 1 = 0$. In all cases, $Q_{k+1} \\ge Q_k$.\nThis proves that $Q_k$ is a non-decreasing function of $k$. The maximum value of $Q_k$ will thus occur at the largest value of $k$, which is $k=B$.\n\nThe maximum queue length is $Q_B$:\n$$\nN = Q_B = B - \\left\\lfloor B \\frac{T_s}{B T_p} \\right\\rfloor = B - \\left\\lfloor \\frac{T_s}{T_p} \\right\\rfloor\n$$\nNow, we substitute the given numerical values into this expression:\n$B = 50$\n$T_s = 220\\,\\mathrm{ms}$\n$T_p = 40\\,\\mathrm{ms}$\n$$\nN = 50 - \\left\\lfloor \\frac{220}{40} \\right\\rfloor\n$$\n$$\nN = 50 - \\lfloor 5.5 \\rfloor\n$$\nThe floor of $5.5$ is $5$.\n$$\nN = 50 - 5 = 45\n$$\nThe minimal buffer capacity required to guarantee no message is dropped is $45$ messages. The buffer must be able to hold $45$ messages. This maximum is reached at time $t=T_s=220\\,\\mathrm{ms}$, at which point all $50$ messages have arrived, and $\\lfloor 220/40 \\rfloor = 5$ messages have been completed. The number of messages in the queue is $50-5=45$. After this point, no more messages arrive, and the queue length will only decrease.", "answer": "$$\n\\boxed{45}\n$$", "id": "3638790"}, {"introduction": "In multi-tasking systems, ensuring that all tasks meet their deadlines becomes complex when they must share resources, which can lead to unpredictable delays from blocking. This practice demonstrates how to formally analyze and guarantee timing correctness using the Priority Ceiling Protocol (PCP) and Response-Time Analysis (RTA). You will calculate the maximum blocking a task can experience and use this to determine its worst-case response time, providing a rigorous confirmation of system schedulability [@problem_id:3638756].", "problem": "Consider a single-core embedded controller scheduled under fixed-priority Rate Monotonic Scheduling (RMS). Access to shared resources is controlled by the Priority Ceiling Protocol (PCP). There are four independent periodic tasks $\\tau_1$, $\\tau_2$, $\\tau_3$, and $\\tau_4$. Each task $\\tau_i$ has a period $T_i$, a worst-case execution time $C_i$, and a relative deadline $D_i$; assume $D_i = T_i$ for all $i$. All tasks are released synchronously at time $t = 0$, and there is no release jitter, context-switch overhead, or cache-related preemption delay. Preemptions are allowed. Higher priority corresponds to shorter period.\n\nTask parameters (periods in milliseconds):\n- $\\tau_1$: $T_1 = 10$, $C_1 = 1.5$. Within its execution, $\\tau_1$ executes a single critical section on resource $R_C$ of length $1$.\n- $\\tau_2$: $T_2 = 15$, $C_2 = 2$. $\\tau_2$ performs no shared-resource access.\n- $\\tau_3$: $T_3 = 25$, $C_3 = 4$. Within its execution, $\\tau_3$ executes a single critical section on resource $R_B$ of length $2$.\n- $\\tau_4$: $T_4 = 50$, $C_4 = 15$. Within its execution, $\\tau_4$ executes three disjoint critical sections: on resource $R_A$ of length $5$, on resource $R_B$ of length $1$, and on resource $R_C$ of length $2$.\n\nUnder RMS, the priority order is $\\tau_1 \\succ \\tau_2 \\succ \\tau_3 \\succ \\tau_4$. Under PCP, each resource’s ceiling is the highest task priority among all tasks that use that resource.\n\nUsing only the foundational definitions of RMS interference and the Priority Ceiling Protocol’s blocking property, determine the maximum blocking $B_{\\max}$ that can be incurred by $\\tau_3$ and compute the worst-case response time $R_3$. Then verify whether $R_3 \\le D_3$. Express the final response time in milliseconds and round your final answer to four significant figures.", "solution": "The solution proceeds by first determining the priority ceilings of the shared resources, then calculating the maximum blocking time for task $\\tau_3$, and finally using response-time analysis to find $R_3$.\n\n**Priority Assignment and Resource Ceilings**\nUnder Rate Monotonic Scheduling (RMS), task priority is inversely proportional to its period.\n-   $T_1=10$, $T_2=15$, $T_3=25$, $T_4=50$.\n-   Since $T_1  T_2  T_3  T_4$, the priority ordering is $P(\\tau_1) > P(\\tau_2) > P(\\tau_3) > P(\\tau_4)$. Let $hp(i)$ be the set of tasks with priority higher than $\\tau_i$. So, $hp(3) = \\{\\tau_1, \\tau_2\\}$.\n\nThe Priority Ceiling Protocol (PCP) assigns a priority ceiling to each shared resource, equal to the highest priority of any task that can lock it.\n-   Resource $R_A$ is used by: $\\{\\tau_4\\}$. The ceiling is $C(R_A) = P(\\tau_4)$.\n-   Resource $R_B$ is used by: $\\{\\tau_3, \\tau_4\\}$. The ceiling is $C(R_B) = \\max\\{P(\\tau_3), P(\\tau_4)\\} = P(\\tau_3)$.\n-   Resource $R_C$ is used by: $\\{\\tau_1, \\tau_4\\}$. The ceiling is $C(R_C) = \\max\\{P(\\tau_1), P(\\tau_4)\\} = P(\\tau_1)$.\n\n**Maximum Blocking for $\\tau_3$ ($B_3$)**\nAccording to the Priority Ceiling Protocol, a task $\\tau_i$ can be blocked by a lower-priority task $\\tau_j$ only if $\\tau_j$ is currently holding a resource $R_k$ whose priority ceiling $C(R_k)$ is greater than or equal to the priority of $\\tau_i$. The maximum duration of such blocking is limited to the length of a single critical section of one lower-priority task.\n\nWe need to find the maximum blocking $B_3$ that task $\\tau_3$ can experience. The only task with a lower priority than $\\tau_3$ is $\\tau_4$. We examine the resources used by $\\tau_4$ to see which of its critical sections can cause blocking on $\\tau_3$.\n-   $\\tau_4$ uses $R_A$: Ceiling $C(R_A) = P(\\tau_4)$. Since $P(\\tau_4)  P(\\tau_3)$, this critical section cannot block $\\tau_3$.\n-   $\\tau_4$ uses $R_B$: Ceiling $C(R_B) = P(\\tau_3)$. Since $P(\\tau_3) \\ge P(\\tau_3)$, this critical section can block $\\tau_3$. The duration of this critical section for $\\tau_4$ is $1$ ms.\n-   $\\tau_4$ uses $R_C$: Ceiling $C(R_C) = P(\\tau_1)$. Since $P(\\tau_1) > P(\\tau_3)$, this critical section can block $\\tau_3$. The duration of this critical section for $\\tau_4$ is $2$ ms.\n\nThe maximum blocking time $B_3$ is the maximum duration among all possible blocking critical sections from lower-priority tasks.\n$$ B_3 = \\max\\{1, 2\\} = 2 \\text{ ms} $$\nThis is the value for $B_{\\max}$ incurred by $\\tau_3$.\n\n**Worst-Case Response Time for $\\tau_3$ ($R_3$)**\nThe worst-case response time of a task $\\tau_i$ is given by the following recursive equation, which accounts for its own execution time $C_i$, blocking from lower-priority tasks $B_i$, and interference from higher-priority tasks $\\sum_{j \\in hp(i)} \\left\\lceil \\frac{R_i}{T_j} \\right\\rceil C_j$.\n$$ R_i^{(k+1)} = C_i + B_i + \\sum_{j \\in hp(i)} \\left\\lceil \\frac{R_i^{(k)}}{T_j} \\right\\rceil C_j $$\nFor task $\\tau_3$, the equation is:\n$$ R_3 = C_3 + B_3 + \\left\\lceil \\frac{R_3}{T_1} \\right\\rceil C_1 + \\left\\lceil \\frac{R_3}{T_2} \\right\\rceil C_2 $$\nSubstituting the given values:\n$$ R_3 = 4 + 2 + \\left\\lceil \\frac{R_3}{10} \\right\\rceil (1.5) + \\left\\lceil \\frac{R_3}{15} \\right\\rceil (2) $$\n$$ R_3 = 6 + 1.5 \\left\\lceil \\frac{R_3}{10} \\right\\rceil + 2 \\left\\lceil \\frac{R_3}{15} \\right\\rceil $$\nWe solve this equation iteratively. A suitable initial guess is $R_3^{(0)} = C_3 + B_3 = 4 + 2 = 6$.\n-   Iteration 1:\n    $$ R_3^{(1)} = 6 + 1.5 \\left\\lceil \\frac{6}{10} \\right\\rceil + 2 \\left\\lceil \\frac{6}{15} \\right\\rceil = 6 + 1.5(1) + 2(1) = 6 + 1.5 + 2 = 9.5 $$\n-   Iteration 2:\n    $$ R_3^{(2)} = 6 + 1.5 \\left\\lceil \\frac{9.5}{10} \\right\\rceil + 2 \\left\\lceil \\frac{9.5}{15} \\right\\rceil = 6 + 1.5(1) + 2(1) = 6 + 1.5 + 2 = 9.5 $$\nSince $R_3^{(2)} = R_3^{(1)}$, the iteration has converged. The worst-case response time for $\\tau_3$ is $R_3 = 9.5$ ms.\n\n**Schedulability Verification**\nA task is schedulable if its worst-case response time is less than or equal to its relative deadline. For $\\tau_3$, we must check if $R_3 \\le D_3$.\n-   $R_3 = 9.5$ ms.\n-   $D_3 = T_3 = 25$ ms.\nThe condition $9.5 \\le 25$ is satisfied, so task $\\tau_3$ is schedulable.\n\nThe problem asks for the final response time rounded to four significant figures.\n$$ R_3 = 9.500 \\text{ ms} $$", "answer": "$$\n\\boxed{9.500}\n$$", "id": "3638756"}]}