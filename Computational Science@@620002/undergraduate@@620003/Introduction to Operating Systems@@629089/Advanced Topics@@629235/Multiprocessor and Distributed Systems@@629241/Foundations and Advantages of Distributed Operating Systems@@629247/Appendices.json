{"hands_on_practices": [{"introduction": "One of the primary motivations for building distributed systems is to achieve high availability, a quality that is difficult to guarantee with a single machine. By replicating services across multiple independent nodes, a system can tolerate failures and continue to operate. This exercise [@problem_id:3645021] allows you to quantitatively model this core principle, deriving the precise relationship between the number of replicas and the resulting system availability. You will also explore the critical concept of diminishing returns, a fundamental consideration in the design of any fault-tolerant system.", "problem": "A distributed operating system (DOS) deploys a stateless, read-mostly service as $k$ identical replicas across independent nodes. In a fixed mission window, each node is unavailable with probability $p \\in (0,1)$, independently of all others. The service is considered available if at least $1$ replica is available in the window. Assume no correlated failures and ignore network partitions and request routing latency.\n\nStarting only from the axioms of probability and the definition of independence, do the following:\n\n1. Derive the exact availability $A(k)$ of the service as a function of $k$ and $p$.\n2. Using your expression for $A(k)$, derive the marginal availability gain $\\Delta(k)$ obtained by adding the $k$-th replica, defined as $\\Delta(k) = A(k) - A(k-1)$ for $k \\ge 1$ with the convention that $A(0)=0$. Then, determine the ratio $\\rho(k) = \\frac{\\Delta(k+1)}{\\Delta(k)}$ for $k \\ge 1$ and interpret what this implies about diminishing returns as $k$ increases.\n3. For a concrete system with $p = 0.02$, determine the smallest integer $k$ such that the incremental gain from adding the $k$-th replica falls below a target threshold $\\varepsilon = 1.0 \\times 10^{-6}$, that is, $\\Delta(k) < \\varepsilon$.\n\nReport your final answer as the integer value of $k$ for the parameters $p = 0.02$ and $\\varepsilon = 1.0 \\times 10^{-6}$. No rounding is required beyond the exact integer.", "solution": "The problem statement has been analyzed and is deemed valid. It is scientifically grounded in fundamental probability theory, is well-posed with a clear objective and sufficient data, and is expressed in objective, formal language. We may therefore proceed with the solution.\n\nThe solution is divided into three parts as requested by the problem statement.\n\n### Part 1: Derivation of Service Availability $A(k)$\n\nLet $U_i$ be the event that the $i$-th replica is unavailable during the mission window, for $i \\in \\{1, 2, \\dots, k\\}$. The problem states that the probability of this event is $p$.\n$$P(U_i) = p$$\nThe probability that the $i$-th replica is available, which we denote by the complementary event $U_i^c$, is therefore:\n$$P(U_i^c) = 1 - p$$\nThe service is defined as available if at least one replica is available. It is more straightforward to calculate the probability of the complementary event: the service being unavailable. The service is unavailable if and only if all $k$ replicas are unavailable. This corresponds to the intersection of the events $U_1, U_2, \\dots, U_k$.\n$$P(\\text{Service Unavailable}) = P(U_1 \\cap U_2 \\cap \\dots \\cap U_k)$$\nThe problem specifies that the nodes are independent. Therefore, the events $U_i$ are mutually independent. The probability of their intersection is the product of their individual probabilities:\n$$P(\\text{Service Unavailable}) = \\prod_{i=1}^{k} P(U_i) = \\prod_{i=1}^{k} p = p^k$$\nThe availability of the service, $A(k)$, is the probability that the service is available. This is $1$ minus the probability that it is unavailable.\n$$A(k) = 1 - P(\\text{Service Unavailable})$$\nSubstituting the derived expression gives the exact availability as a function of $k$ and $p$:\n$$A(k) = 1 - p^k$$\n\n### Part 2: Derivation of Marginal Gain $\\Delta(k)$ and Ratio $\\rho(k)$\n\nThe marginal availability gain $\\Delta(k)$ is defined as $\\Delta(k) = A(k) - A(k-1)$ for $k \\ge 1$, with the convention that $A(0) = 0$.\nUsing the expression for $A(k)$:\n$$A(k) = 1 - p^k$$\n$$A(k-1) = 1 - p^{k-1}$$\nSubstituting these into the definition of $\\Delta(k)$:\n$$\\Delta(k) = (1 - p^k) - (1 - p^{k-1}) = 1 - p^k - 1 + p^{k-1} = p^{k-1} - p^k$$\nFactoring out the term $p^{k-1}$:\n$$\\Delta(k) = p^{k-1}(1-p)$$\nThis expression represents the incremental probability of service availability gained by adding the $k$-th replica. It is precisely the probability that the first $k-1$ replicas fail (an event with probability $p^{k-1}$) AND the $k$-th replica is available (an event with probability $1-p$).\n\nNext, we determine the ratio $\\rho(k) = \\frac{\\Delta(k+1)}{\\Delta(k)}$ for $k \\ge 1$.\nFirst, we find the expression for $\\Delta(k+1)$ by substituting $k+1$ for $k$ in the formula for $\\Delta(k)$:\n$$\\Delta(k+1) = p^{(k+1)-1}(1-p) = p^k(1-p)$$\nNow, we form the ratio:\n$$\\rho(k) = \\frac{\\Delta(k+1)}{\\Delta(k)} = \\frac{p^k(1-p)}{p^{k-1}(1-p)}$$\nSince $p \\in (0,1)$, the term $1-p$ is non-zero and can be canceled. We are left with:\n$$\\rho(k) = \\frac{p^k}{p^{k-1}} = p^{k-(k-1)} = p^1 = p$$\nThe ratio $\\rho(k)$ is constant and equal to $p$. Since $p \\in (0,1)$, this implies that the marginal gain from adding a replica is always a fixed fraction $p$ of the marginal gain from the previous replica. This represents a geometric reduction in the marginal gain, which is a classic example of the principle of diminishing returns. Each subsequent replica adds progressively less to the system's overall availability.\n\n### Part 3: Determination of the Minimum Number of Replicas $k$\n\nWe are asked to find the smallest integer $k$ such that the incremental gain $\\Delta(k)$ falls below a threshold $\\varepsilon$. The condition is:\n$$\\Delta(k) < \\varepsilon$$\nSubstituting the expression for $\\Delta(k)$ and the given values $p = 0.02$ and $\\varepsilon = 1.0 \\times 10^{-6}$:\n$$p^{k-1}(1-p) < \\varepsilon$$\n$$(0.02)^{k-1}(1 - 0.02) < 1.0 \\times 10^{-6}$$\n$$(0.02)^{k-1}(0.98) < 10^{-6}$$\nTo solve for $k$, we first isolate the term containing the exponent:\n$$(0.02)^{k-1} < \\frac{10^{-6}}{0.98}$$\nWe now take the natural logarithm ($\\ln$) of both sides. Since the natural logarithm is a strictly increasing function, the direction of the inequality is preserved.\n$$\\ln\\left((0.02)^{k-1}\\right) < \\ln\\left(\\frac{10^{-6}}{0.98}\\right)$$\nUsing the logarithm property $\\ln(a^b) = b\\ln(a)$:\n$$(k-1)\\ln(0.02) < \\ln(10^{-6}) - \\ln(0.98)$$\nTo isolate $(k-1)$, we must divide by $\\ln(0.02)$. It is critical to note that since $0.02 < 1$, the value of $\\ln(0.02)$ is negative. Dividing an inequality by a negative number reverses the direction of the inequality sign.\n$$k-1 > \\frac{\\ln(10^{-6}) - \\ln(0.98)}{\\ln(0.02)}$$\nNow, we can solve for $k$:\n$$k > 1 + \\frac{\\ln(10^{-6}) - \\ln(0.98)}{\\ln(0.02)}$$\nLet's evaluate the expression on the right-hand side:\n$$k > 1 + \\frac{-6\\ln(10) - \\ln(0.98)}{\\ln(0.02)}$$\nUsing computational values, $\\ln(10) \\approx 2.302585$, $\\ln(0.98) \\approx -0.0202027$, and $\\ln(0.02) \\approx -3.912023$.\n$$k > 1 + \\frac{-6(2.302585) - (-0.0202027)}{-3.912023}$$\n$$k > 1 + \\frac{-13.815510 + 0.0202027}{-3.912023}$$\n$$k > 1 + \\frac{-13.7953073}{-3.912023} \\approx 1 + 3.52638$$\n$$k > 4.52638$$\nSince $k$ must be an integer, the smallest integer value of $k$ that satisfies this inequality is $5$.\nTo verify, for $k=5$, the gain is $\\Delta(5) = (0.02)^{4}(0.98) = (1.6 \\times 10^{-7})(0.98) = 1.568 \\times 10^{-7}$, which is less than $\\varepsilon = 1.0 \\times 10^{-6}$.\nFor $k=4$, the gain is $\\Delta(4) = (0.02)^{3}(0.98) = (8.0 \\times 10^{-6})(0.98) = 7.84 \\times 10^{-6}$, which is not less than $\\varepsilon$.\nThus, the smallest integer is indeed $k=5$.", "answer": "$$\\boxed{5}$$", "id": "3645021"}, {"introduction": "Beyond reliability, distributed systems offer the promise of enhanced performance by harnessing a larger pool of resources. A key mechanism for this is process migration, where a distributed operating system can move a task to a less-loaded or more powerful node to speed up its execution. This practice [@problem_id:3644955] guides you through a foundational cost-benefit analysis, challenging you to derive a clear decision rule for when migration is worthwhile. By modeling the trade-off between the fixed overhead of migration and the variable gain from a faster processor, you will develop a quantitative framework for resource management decisions.", "problem": "A Distributed Operating System (DOS) can migrate a compute-bound process from a local node to a remote node to reduce completion time. Let the process have a job size $x$ measured in local central processing unit (CPU) seconds, meaning that if it executes entirely on the local node, it would require $x$ seconds of CPU time at the local processor. The remote node offers a speed ratio $\\rho$ relative to the local node, meaning the remote processor sustains $\\rho$ times the execution rate of the local processor, with $\\rho > 1$. The act of migrating the process to the remote node incurs a one-time network and setup cost $C_{n}$ measured in seconds, which includes state transfer and remote dispatch overheads. Assume there is no overlap between computation and communication, the amount of computation is invariant under migration, and there are no queueing delays at either node.\n\nUsing only the foundational facts that execution time equals work divided by speed and that independent overheads add to completion time, derive a decision rule that guarantees a net completion time reduction by migration. Express your answer as the threshold job size $x^{*}$ in seconds, in closed form as a symbolic expression in terms of $\\rho$ and $C_{n}$, such that migration strictly reduces completion time if and only if $x > x^{*}$. Provide your final answer exactly; do not approximate. Express the threshold in seconds.", "solution": "The problem requires the derivation of a decision rule for process migration in a distributed system. The rule should determine the threshold job size, denoted as $x^*$, above which migrating a process to a remote node strictly reduces its completion time. The derivation will be based on the fundamental principles and variables provided.\n\nFirst, let us formalize the completion times for the two possible execution scenarios: local execution and remote execution.\n\nLet $T_{local}$ be the total completion time if the process executes entirely on the local node. The problem defines the job size $x$ as the CPU time in seconds required for the process on the local node. Therefore, the completion time for local execution is:\n$$T_{local} = x$$\n\nNext, let $T_{remote}$ be the total completion time if the process is migrated to the remote node. This duration comprises two distinct, non-overlapping parts: the migration overhead and the remote computation time.\n\nThe migration cost is a fixed, one-time overhead given as $C_{n}$ seconds.\n\nThe computation time on the remote node depends on the job's work content and the remote processor's speed. Let $W$ represent the total computational work of the process. Since the process requires $x$ seconds on the local processor, we can express the work as $W = S_{local} \\cdot x$, where $S_{local}$ is the execution speed (e.g., instructions per second) of the local processor. The remote processor is faster by a factor of $\\rho$, so its speed is $S_{remote} = \\rho \\cdot S_{local}$. The execution time on the remote node is the work divided by the remote speed:\n$$T_{compute\\_remote} = \\frac{W}{S_{remote}} = \\frac{S_{local} \\cdot x}{\\rho \\cdot S_{local}} = \\frac{x}{\\rho}$$\nThe problem states that there is no overlap between computation and communication. Thus, the total completion time for the remote scenario is the sum of the migration overhead and the remote computation time:\n$$T_{remote} = C_{n} + T_{compute\\_remote} = C_{n} + \\frac{x}{\\rho}$$\n\nMigration is advantageous if and only if the completion time is strictly reduced. This can be expressed with the following inequality:\n$$T_{remote} < T_{local}$$\nSubstituting the derived expressions for $T_{remote}$ and $T_{local}$:\n$$C_{n} + \\frac{x}{\\rho} < x$$\nTo find the threshold job size $x^*$, we must solve this inequality for $x$. We begin by isolating the terms involving $x$:\n$$C_{n} < x - \\frac{x}{\\rho}$$\nFactoring out $x$ from the right-hand side gives:\n$$C_{n} < x \\left(1 - \\frac{1}{\\rho}\\right)$$\nTo simplify the term in the parenthesis, we find a common denominator:\n$$C_{n} < x \\left(\\frac{\\rho - 1}{\\rho}\\right)$$\nThe problem states that the remote node is faster, meaning $\\rho > 1$. This implies that the term $\\rho - 1$ is positive. Since $\\rho$ is also positive, the fraction $\\frac{\\rho-1}{\\rho}$ is a positive quantity. Therefore, we can multiply both sides of the inequality by its reciprocal, $\\frac{\\rho}{\\rho-1}$, without altering the direction of the inequality sign:\n$$C_{n} \\cdot \\frac{\\rho}{\\rho - 1} < x$$\nThis inequality can be rewritten as:\n$$x > C_{n} \\frac{\\rho}{\\rho - 1}$$\nThis expression defines the condition under which migration is beneficial. The problem asks for the threshold job size $x^*$ such that migration is strictly advantageous if and only if $x > x^*$. By comparing our result with this condition, we can identify the expression for $x^*$:\n$$x^* = C_{n} \\frac{\\rho}{\\rho - 1}$$\nThis is the closed-form symbolic expression for the threshold job size. If the job size $x$ is greater than this value, the time saved by the faster remote processor outweighs the fixed cost of migration.", "answer": "$$\\boxed{C_{n} \\frac{\\rho}{\\rho - 1}}$$", "id": "3644955"}, {"introduction": "The benefits of distributed systems do not come for free; they require coordination, which incurs overhead. Ensuring fundamental properties like mutual exclusion—preventing simultaneous access to a shared resource—is more complex than in a centralized system and relies on message passing. This hands-on problem [@problem_id:3645069] focuses on quantifying this overhead for a quorum-based mutual exclusion algorithm. By carefully counting the messages required for a single process to enter and exit its critical section, you will gain a concrete understanding of the communication cost, a critical performance factor in the design of distributed protocols.", "problem": "Consider a distributed operating system that provides mutual exclusion for a shared resource using a quorum-based locking mechanism. A set of $N$ processes is partitioned into overlapping quorums, each quorum being a subset of processes of size $q$, with the property that any two quorums intersect in at least one process. A process that wishes to enter its Critical Section (CS) must obtain a lock from every process in a single quorum. Locks are granted on a first-come-first-served basis, and a process releases all locks held upon exiting its CS.\n\nAssume the following well-tested communication and protocol facts:\n- Communication channels are reliable (no loss or duplication), and messages are delivered in finite time.\n- Each lock acquisition between the requesting process and a quorum member requires exactly two control messages: a request message from the requester and a grant reply message from the quorum member. This constitutes a $2$-message handshake for acquisition.\n- Each lock release between the requester and a quorum member requires exactly two control messages: a release message from the requester and an acknowledgment reply message from the quorum member. This constitutes a $2$-message handshake for release.\n- There is no contention for locks during the interval considered (no other process is attempting to obtain overlapping locks), so no additional messages (such as failure notices, queueing notifications, or relinquish messages) are triggered.\n\nStarting from the definitions of mutual exclusion and quorum intersection, and using the above communication model, derive the total number of control messages exchanged by a single process to complete one CS entry and one CS exit in terms of the quorum size $q$. Do not count any messages other than the described request, grant, release, and acknowledgment control messages. Express your final result as a two-entry row matrix, where the first entry is the message count for CS entry and the second entry is the message count for CS exit. No rounding is required, and no physical units are involved.", "solution": "The problem statement has been validated and is deemed sound, well-posed, and scientifically grounded. It presents a standard model for analyzing the communication cost of a quorum-based distributed mutual exclusion algorithm. We may proceed with the derivation.\n\nThe objective is to determine the number of control messages required for a single process to execute its Critical Section (CS) one time. This involves two distinct phases: entering the CS and exiting the CS. The calculation will be based on the quorum size, denoted by $q$, and the specified message exchange protocol.\n\nFirst, let us analyze the CS entry phase.\nAccording to the problem statement, a process wishing to enter its CS must obtain a lock from every process in a single quorum. The size of this quorum is given as $q$. Therefore, the requesting process must communicate with $q$ distinct processes (the members of its chosen quorum) to acquire the necessary locks.\n\nThe communication protocol for acquiring a single lock from one quorum member is a $2$-message handshake, consisting of:\n1.  A `request` message sent from the requesting process to a quorum member.\n2.  A `grant` reply message sent from the quorum member back to the requesting process.\n\nThus, the total number of messages to acquire one lock from one member is $2$. Since the process must acquire locks from all $q$ members of the quorum, and the 'no contention' assumption implies these requests can be treated independently, the total number of messages for CS entry is the product of the number of quorum members and the number of messages per member.\n\nLet $M_{\\text{entry}}$ be the total number of messages for CS entry.\n$$M_{\\text{entry}} = (\\text{number of quorum members}) \\times (\\text{messages per member for lock acquisition})$$\n$$M_{\\text{entry}} = q \\times 2$$\n$$M_{\\text{entry}} = 2q$$\n\nNext, we analyze the CS exit phase.\nUpon exiting the CS, the process must release all the locks it previously acquired. It holds locks from the same $q$ quorum members.\n\nThe communication protocol for releasing a single lock is also specified as a $2$-message handshake, consisting of:\n1.  A `release` message sent from the process to a quorum member.\n2.  An `acknowledgment` reply message sent from the quorum member back to the process.\n\nThe total number of messages to release one lock to one member is therefore $2$. To exit the CS, the process must release the locks held by all $q$ members of the quorum.\n\nLet $M_{\\text{exit}}$ be the total number of messages for CS exit.\n$$M_{\\text{exit}} = (\\text{number of quorum members}) \\times (\\text{messages per member for lock release})$$\n$$M_{\\text{exit}} = q \\times 2$$\n$$M_{\\text{exit}} = 2q$$\n\nThe problem requires the final result to be expressed as a two-entry row matrix, where the first entry is the message count for CS entry ($M_{\\text{entry}}$) and the second entry is the message count for CS exit ($M_{\\text{exit}}$).\n\nBased on our derivations, the matrix is:\n$$ \\begin{pmatrix} M_{\\text{entry}} & M_{\\text{exit}} \\end{pmatrix} = \\begin{pmatrix} 2q & 2q \\end{pmatrix} $$\nThis result follows directly from the problem's definitions. The information regarding the total number of processes, $N$, and the intersection property of quorums, while fundamental to the correctness of the mutual exclusion algorithm itself, is not required for calculating the message cost for a single, uncontested CS execution, which depends only on the quorum size $q$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2q & 2q\n\\end{pmatrix}\n}\n$$", "id": "3645069"}]}