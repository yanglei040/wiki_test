{"hands_on_practices": [{"introduction": "To use Load-Linked and Store-Conditional (LL/SC) primitives effectively, we must first understand their underlying hardware behavior. This practice guides you through a simulated experiment to probe the \"reservation granule,\" a key concept that explains why an SC operation might fail due to nearby, but not identical, memory writes [@problem_id:3654106]. Understanding this mechanism is the first step toward writing robust and efficient lock-free code.", "problem": "You are asked to formalize the semantics of load-linked and store-conditional primitives using a simplified and scientifically realistic model, and then implement a program that simulates an experiment to infer the monitor scope. The core scientific base you must rely on is the following definition: a load-linked operation sets a reservation on a reservation granule containing an address, and a subsequent store-conditional to that same address will succeed if and only if no store to any byte in that granule has occurred since the reservation was established. The reservation granule size is unknown a priori and is the quantity that determines the monitor scope.\n\nIn this problem, assume the following fundamental model that abstracts common hardware behavior:\n- A memory line has size $L$ bytes.\n- Addresses inside a line are word-aligned with word size $W$ bytes, yielding $n = L / W$ aligned target addresses per line at byte offsets $t_i = i \\cdot W$ for $i \\in \\{0, 1, \\dots, n-1\\}$.\n- A load-linked on a target offset $t_i$ sets a reservation on the reservation granule of size $g$ bytes that contains $t_i$. Define the granule index function $G(x; g) = \\left\\lfloor x / g \\right\\rfloor$.\n- Between the load-linked and store-conditional, an adversary issues a set of interfering stores at byte offsets $S = \\{s_0, s_1, \\dots, s_{m-1}\\}$. An interfering store $s_j$ is considered “in the same line” if and only if $0 \\le s_j < L$; otherwise it is to a different line and does not affect the reservation.\n- Under this model, the store-conditional to $t_i$ fails if and only if there exists at least one interfering store $s_j \\in S$ with $0 \\le s_j < L$ such that $G(s_j; g) = G(t_i; g)$. Otherwise, it succeeds.\n\nYour task is to implement an experiment simulator for a given memory line size $L$, word size $W$, and set $S$ of interfering store offsets. The simulator must iterate over all aligned targets $t_i = i \\cdot W$ for $i \\in \\{0, \\dots, n-1\\}$, determine whether the store-conditional fails under hypothesized reservation granule sizes $g \\in \\{8, 16, 64\\}$ bytes, and count the number of failures across all $n$ targets for each hypothesized $g$.\n\nTest suite:\nYou must hard-code the following test cases, each specified by $(L, W, S)$ with $L$ in bytes, $W$ in bytes, and $S$ a set of byte offsets:\n- Test A: $L = 64$, $W = 8$, $S = \\{16\\}$.\n- Test B: $L = 64$, $W = 4$, $S = \\{80\\}$.\n- Test C: $L = 64$, $W = 16$, $S = \\{31\\}$.\n- Test D: $L = 64$, $W = 64$, $S = \\{8\\}$.\n- Test E: $L = 64$, $W = 4$, $S = \\{4, 20, 36, 52\\}$.\n\nFor each test case, compute the number of store-conditional failures across all $n = L/W$ aligned targets for each $g \\in \\{8, 16, 64\\}$. An interfering store affects the outcome for a target only if it is within the same line, that is, if $0 \\le s_j < L$. The answers for each test case are thus three integers representing the failure counts for $g = 8$, $g = 16$, and $g = 64$, respectively.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the results for all tests concatenated in the order A, B, C, D, E, and, within each test, in the order $g = 8$, then $g = 16$, then $g = 64$. For example, the output format is\n“[a8,a16,a64,b8,b16,b64,c8,c16,c64,d8,d16,d64,e8,e16,e64]”\nwhere each symbol such as $a8$ denotes the integer failure count for the specified test and granule size.\n\nYour solution must be a complete, runnable program that implements this simulation exactly as specified and prints only the single line described above. No user input is required or permitted. All answers are integers; no physical units or angles are involved.", "solution": "The problem has been validated and is determined to be a well-posed, scientifically grounded exercise in modeling a fundamental concept in computer science and operating systems. The provided model for load-linked and store-conditional primitives, while simplified, captures the essential mechanics of reservation-based atomic operations found in many processor architectures. We will now proceed with a formal solution.\n\n### Principle-Based Model Formalization\n\nThe problem is centered on a formal model of how load-linked/store-conditional (LL/SC) operations interact with interfering memory stores. The key elements of this model are:\n\n1.  **Memory Layout**: A memory line is of size $L$ bytes. Accesses are made to word-aligned addresses. With a word size of $W$ bytes, there are $n = L/W$ possible target addresses within the line. These target byte offsets are given by $t_i = i \\cdot W$ for the target index $i \\in \\{0, 1, \\dots, n-1\\}$.\n\n2.  **Reservation Granule**: A `load-linked` operation on a target address $t_i$ establishes a reservation on a \"reservation granule\" of size $g$ bytes. The model defines the granule containing a byte offset $x$ by its index, computed by the function $G(x; g) = \\lfloor x / g \\rfloor$. This corresponds to integer division for non-negative offsets.\n\n3.  **Interference and Failure Condition**: A subsequent `store-conditional` operation to the target address $t_i$ is subject to interference from a set of adversarial stores occurring at byte offsets $S = \\{s_0, s_1, \\dots, s_{m-1}\\}$. A store $s_j$ is considered a potential interference only if it is within the same memory line as the targets, i.e., $0 \\le s_j < L$. The `store-conditional` to $t_i$ fails if and only if at least one such in-line store $s_j$ falls within the same reservation granule as the target $t_i$. Formally, failure occurs if:\n    $$ \\exists s_j \\in S \\text{ such that } (0 \\le s_j < L) \\land (G(s_j; g) = G(t_i; g)) $$\n    Otherwise, the `store-conditional` succeeds.\n\nOur task is to simulate this process for a given test suite, calculating the total number of target addresses for which the `store-conditional` would fail, for each hypothesized granule size $g \\in \\{8, 16, 64\\}$ bytes.\n\n### Algorithmic Solution\n\nThe simulation follows a direct implementation of the model's rules. For each test case defined by $(L, W, S)$ and for each hypothesized granule size $g$, the algorithm is as follows:\n\n1.  Initialize a failure counter for the current test case and granule size to $0$.\n2.  Calculate the number of aligned targets, $n = L/W$.\n3.  Iterate through each target index $i$ from $0$ to $n-1$.\n    a. Determine the target offset $t_i = i \\cdot W$.\n    b. Calculate the granule index for this target: $G_t = \\lfloor t_i / g \\rfloor$.\n    c. Set a flag, `failure_for_this_target`, to false.\n    d. Iterate through each store offset $s_j$ in the set $S$.\n        i. Check if the store is within the line: $0 \\le s_j < L$.\n        ii. If it is, calculate the store's granule index: $G_s = \\lfloor s_j / g \\rfloor$.\n        iii. If $G_s = G_t$, the condition for failure is met. Set `failure_for_this_target` to true and break the inner loop over the stores, as one interference is sufficient.\n    e. If `failure_for_this_target` is true, increment the failure counter.\n4.  After iterating through all targets, the value of the failure counter is the result for the given $(L, W, S, g)$.\n\n### Worked Example: Test Case C\n\nLet's apply this algorithm to Test Case C: $L = 64$, $W = 16$, $S = \\{31\\}$.\n-   Number of targets $n = L/W = 64/16 = 4$.\n-   Target offsets $t_i$: $\\{t_0, t_1, t_2, t_3\\} = \\{0, 16, 32, 48\\}$.\n-   Interfering store $s_0 = 31$. This is in-line, since $0 \\le 31 < 64$. We must check for interference from this store.\n\n**Case 1: Granule Size $g=8$**\n-   Granule index of the store: $G(31; 8) = \\lfloor 31 / 8 \\rfloor = 3$.\n-   Granule indices of the targets:\n    -   $G(t_0; 8) = G(0; 8) = 0$.\n    -   $G(t_1; 8) = G(16; 8) = 2$.\n    -   $G(t_2; 8) = G(32; 8) = 4$.\n    -   $G(t_3; 8) = G(48; 8) = 6$.\n-   The store's granule index ($3$) does not match any of the targets' granule indices ($\\{0, 2, 4, 6\\}$).\n-   Result: **$0$ failures**.\n\n**Case 2: Granule Size $g=16$**\n-   Granule index of the store: $G(31; 16) = \\lfloor 31 / 16 \\rfloor = 1$.\n-   Granule indices of the targets:\n    -   $G(t_0; 16) = G(0; 16) = 0$.\n    -   $G(t_1; 16) = G(16; 16) = 1$. (Match)\n    -   $G(t_2; 16) = G(32; 16) = 2$.\n    -   $G(t_3; 16) = G(48; 16) = 3$.\n-   The store's granule index ($1$) matches the granule index for target $t_1$.\n-   Result: **$1$ failure**.\n\n**Case 3: Granule Size $g=64$**\n-   Granule index of the store: $G(31; 64) = \\lfloor 31 / 64 \\rfloor = 0$.\n-   Granule indices of the targets:\n    -   $G(t_0; 64) = G(0; 64) = 0$. (Match)\n    -   $G(t_1; 64) = G(16; 64) = 0$. (Match)\n    -   $G(t_2; 64) = G(32; 64) = 0$. (Match)\n    -   $G(t_3; 64) = G(48; 64) = 0$. (Match)\n-   The store's granule index ($0$) matches the granule index for all $4$ targets.\n-   Result: **$4$ failures**.\n\nThe computed results for Test Case C are thus $[0, 1, 4]$. By applying this same procedure to all test cases, we obtain the complete set of results.\n\n### Summary of Calculated Results\n\n-   **Test A** ($L=64, W=8, S=\\{16\\}$): $[1, 2, 8]$\n-   **Test B** ($L=64, W=4, S=\\{80\\}$): $[0, 0, 0]$ (store is out of line)\n-   **Test C** ($L=64, W=16, S=\\{31\\}$): $[0, 1, 4]$\n-   **Test D** ($L=64, W=64, S=\\{8\\}$): $[0, 1, 1]$\n-   **Test E** ($L=64, W=4, S=\\{4, 20, 36, 52\\}$): $[8, 16, 16]$\n\nThe final program will concatenate these results in the specified order.", "answer": "```c\n// The complete and compilable C program.\n// Headers adhere to the specified restrictions.\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int L;               // Memory line size in bytes\n    int W;               // Word size in bytes\n    const int* S;        // Pointer to an array of interfering store offsets\n    int s_count;         // Number of elements in the store offset array S\n} TestCase;\n\nint main(void) {\n    // Define the interfering store sets for each test case.\n    static const int S_A[] = {16};\n    static const int S_B[] = {80};\n    static const int S_C[] = {31};\n    static const int S_D[] = {8};\n    static const int S_E[] = {4, 20, 36, 52};\n\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {64, 8,  S_A, sizeof(S_A) / sizeof(S_A[0])}, // Test A\n        {64, 4,  S_B, sizeof(S_B) / sizeof(S_B[0])}, // Test B\n        {64, 16, S_C, sizeof(S_C) / sizeof(S_C[0])}, // Test C\n        {64, 64, S_D, sizeof(S_D) / sizeof(S_D[0])}, // Test D\n        {64, 4,  S_E, sizeof(S_E) / sizeof(S_E[0])}  // Test E\n    };\n    \n    // Define hypothesized reservation granule sizes.\n    const int granule_sizes[] = {8, 16, 64};\n    const int num_granules = sizeof(granule_sizes) / sizeof(granule_sizes[0]);\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases * num_granules];\n    int result_idx = 0;\n\n    // Calculate the result for each test case and each granule size.\n    for (int i = 0; i < num_cases; ++i) {\n        TestCase current_case = test_cases[i];\n        int L = current_case.L;\n        int W = current_case.W;\n        const int* S = current_case.S;\n        int s_count = current_case.s_count;\n\n        for (int j = 0; j < num_granules; ++j) {\n            int g = granule_sizes[j];\n            int failure_count = 0;\n            \n            // Number of aligned targets per line.\n            int n = L / W;\n\n            // Iterate over all aligned targets.\n            for (int k = 0; k < n; ++k) {\n                int target_offset = k * W;\n                int target_granule = target_offset / g;\n                \n                int has_failed = 0; // Using int as boolean as stdbool.h is not specified.\n\n                // Check for interference from any store.\n                for (int m = 0; m < s_count; ++m) {\n                    int store_offset = S[m];\n\n                    // An interfering store must be in the same line.\n                    if (store_offset >= 0 && store_offset < L) {\n                        int store_granule = store_offset / g;\n                        \n                        // Condition for store-conditional failure.\n                        if (store_granule == target_granule) {\n                            has_failed = 1;\n                            break; // One interfering store is sufficient.\n                        }\n                    }\n                }\n\n                if (has_failed) {\n                    failure_count++;\n                }\n            }\n            results[result_idx++] = failure_count;\n        }\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    printf(\"[\");\n    for (int i = 0; i < num_cases * num_granules; ++i) {\n        printf(\"%d\", results[i]);\n        if (i < (num_cases * num_granules - 1)) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3654106"}, {"introduction": "With a grasp of the low-level mechanics, we can now use LL/SC to construct universal atomic operations like Compare-And-Swap (CAS). This exercise involves not only synthesizing the CAS algorithm but also mathematically analyzing its performance by deriving the expected number of retries under contention [@problem_id:3621226]. This bridges the gap between the abstract primitive and its practical application and performance characteristics.", "problem": "Consider a shared-memory multiprocessor with coherent caches that provides Load-Link (LL) and Store-Conditional (SC) instructions with the following architecture-level semantics: an $LL(a)$ reads the current value of address $a$ and establishes a reservation on $a$; a subsequent $SC(a,v)$ writes value $v$ to $a$ only if no conflicting store to $a$ has occurred since the reservation was established, otherwise $SC(a,v)$ fails without writing. A failing $SC$ may also occur spuriously with independent probability $\\sigma \\in [0,1)$ even if no conflicting store occurred. Assume $LL$ has acquire semantics and successful $SC$ has release semantics.\n\nThe software interface exposes Compare-And-Swap (CAS): $CAS(a,e,n)$ atomically reads $a$ and, if the observed value equals $e$, writes $n$; otherwise it leaves $a$ unchanged. It returns the old value read from $a$. You are to synthesize the semantics of $CAS(a,e,n)$ using $LL/SC$ and reason from first principles to establish the minimal correctness constraints required for the synthesized $CAS$ to be linearizable and lock-free under the given architecture model. Your reasoning must start from core definitions of $LL/SC$, $CAS$, linearizability, and lock-freedom; you must not assume any shortcut properties beyond these.\n\nThen, consider $k$ concurrent interfering threads that may store to the same address $a$. Model each interfering thread’s stores to $a$ as an independent Poisson process with rate $\\lambda_i$ for $i \\in \\{1,2,\\dots,k\\}$, and define $\\Lambda = \\sum_{i=1}^{k} \\lambda_i$. Assume an $LL$ followed by its decision logic and the matching $SC$ attempt occupies a deterministic time window of length $\\tau > 0$ between the end of $LL$ and the initiation of $SC$ during which any interfering store to $a$ breaks the reservation. Assume successive $LL/SC$ attempts are separated by independent think times such that interference across attempts is independent and identically distributed, and that the thread invoking $CAS$ only counts as a retry those loop iterations in which $LL$ reads a value equal to $e$ but $SC$ fails (due to reservation conflict or spurious failure). Under this model, derive a closed-form analytic expression for the expected number of retries $\\mathbb{E}[R]$ before the synthesized $CAS$ completes its write (i.e., the expected count of failed $SC$ attempts after an $LL$ that observed $e$ and before the first successful $SC$).\n\nYour final answer must be a single closed-form analytic expression in terms of $\\Lambda$, $\\tau$, and $\\sigma. Do not include any units in your final answer.", "solution": "The posed problem is valid and well-defined, comprising three parts: synthesizing the Compare-And-Swap ($CAS$) atomic primitive using Load-Link/Store-Conditional ($LL/SC$), proving its correctness from first principles, and deriving its performance under a stochastic model.\n\nFirst, we synthesize the semantics of $CAS(a, e, n)$, which atomically reads from memory address $a$, and if the value equals $e$, writes $n$. It returns the value originally read. This can be implemented using $LL/SC$ in a retry loop. The $LL(a)$ instruction reads the value and establishes a reservation. The $SC(a, n)$ instruction attempts to write, succeeding only if the reservation is intact.\n\nThe synthesized algorithm is as follows:\nFunction $CAS(a, e, n)$:\n$1.$ Start an unbounded loop.\n$2.$ Inside the loop, execute $v_{old} \\leftarrow LL(a)$. This reads the current value at address $a$ into a local variable $v_{old}$ and places a reservation on $a$. The $LL$ instruction has acquire semantics.\n$3.$ Compare $v_{old}$ with the expected value $e$.\n$4.$ If $v_{old} \\neq e$, the precondition for the swap is not met. The operation must fail without modifying memory. The reservation is implicitly discarded, and the function returns $v_{old}$.\n$5.$ If $v_{old} = e$, the condition is met. Attempt to atomically write the new value $n$ to address $a$ by executing $SC(a, n)$.\n$6.$ Check the result of the $SC$ instruction. A successful $SC$ has release semantics.\n$7.a.$ If $SC(a, n)$ succeeds, it means no other processor has written to $a$ since the $LL$ (and no spurious failure occurred). The atomic exchange is complete. The function returns $v_{old}$ (which is equal to $e$), and the loop terminates.\n$7.b.$ If $SC(a, n)$ fails, the reservation on $a$ was broken by a conflicting store or a spurious event. The memory at $a$ is not modified by this $SC$. The loop continues to the next iteration, retrying the entire $LL-SC$ sequence.\n\nSecond, we establish the correctness of this synthesis by proving linearizability and lock-freedom.\n\nLinearizability requires that every operation appears to take effect instantaneously at a single, uniquely identifiable \"linearization point\" between its invocation and response.\nFor our synthesized $CAS$:\n- If the $CAS(a, e, n)$ operation is successful (i.e., it writes $n$ to $a$), the linearization point is the instant in time that the successful $SC(a, n)$ instruction is executed by the memory system. At this moment, the state of a in memory atomically changes from $e$ to $n$. The operation returns $e$, which was the value just before this point, conforming to the $CAS$ specification.\n- If the $CAS(a, e, n)$ operation fails because the value read by $LL$ is $v_{old} \\neq e$, no write occurs. The linearization point is the instant that the $LL(a)$ instruction reads the value $v_{old}$. The operation is equivalent to a read, and it returns the value it observed, which is consistent with the $CAS$ specification.\n- A failed $SC$ attempt within the loop does not constitute a complete $CAS$ operation and thus has no linearization point. It is an internal step of an operation that has not yet completed.\nThe acquire semantics on $LL$ and release semantics on a successful $SC$ ensure that these linearization points are correctly ordered with respect to memory operations in other threads, even on systems with relaxed memory consistency models.\n\nLock-freedom guarantees system-wide progress, meaning that in any sufficiently long time interval, at least one active thread will complete its operation.\nConsider multiple threads concurrently executing our synthesized $CAS$ on the same address $a$. If two or more threads execute $LL(a)$ and read the same value $e$, they will all proceed to attempt $SC$. The hardware arbitrates these concurrent $SC$ attempts, guaranteeing that at most one can succeed. The thread whose $SC$ succeeds has completed its $CAS$ operation, thus making progress. All other threads whose $SC$ attempts fail (because their reservation was broken by the successful write) will loop and retry. Because one thread made progress, the system as a whole made progress. A spurious $SC$ failure, which occurs with probability $\\sigma < 1$, causes a thread to retry, but does not indefinitely halt progress. The probability of infinite consecutive spurious failures for a single, unopposed thread is $\\lim_{N \\to \\infty} \\sigma^N = 0$. Therefore, some thread is always guaranteed to eventually succeed, and the algorithm is lock-free.\n\nThird, we derive the expected number of retries, $\\mathbb{E}[R]$. A \"retry\" is defined as a loop iteration where $LL$ reads $e$ but the subsequent $SC$ fails. We are asked for the expected number of such retries before a successful $SC$. This is a classic problem modeled by a geometric distribution. Let $p$ be the probability that an $SC$ attempt succeeds, given the preceding $LL$ read $e$. The number of retries, $R$, is the number of failures before the first success. The random variable $R$ follows a geometric distribution with $P(R = j) = (1-p)^j p$ for $j \\in \\{0, 1, 2, \\dots\\}$. The expectation of a such a random variable is $\\mathbb{E}[R] = \\frac{1-p}{p}$.\n\nOur task reduces to calculating $p$. An $SC$ succeeds if and only if two independent conditions are met:\n$1.$ No conflicting store occurs in the vulnerability window of duration $\\tau$ between the $LL$ and the $SC$.\n$2.$ No spurious failure occurs.\n\nLet $\\mathcal{E}_{conflict}$ be the event of a conflicting store, and $\\mathcal{E}_{spur}$ be the event of a spurious failure. The probability of success is $p = P(\\mathcal{E}_{conflict}^c \\cap \\mathcal{E}_{spur}^c)$.\nThe problem states these events are independent, so $p = P(\\mathcal{E}_{conflict}^c) P(\\mathcal{E}_{spur}^c)$.\n\nThe probability of a spurious failure is given as $\\sigma$. Thus, the probability of no spurious failure is $P(\\mathcal{E}_{spur}^c) = 1 - \\sigma$.\n\nThe conflicting stores from $k$ interfering threads are modeled as a superposition of $k$ independent Poisson processes with rates $\\lambda_i$. The total arrival process of conflicting stores is a single Poisson process with rate $\\Lambda = \\sum_{i=1}^{k} \\lambda_i$.\nA conflict occurs if at least one store event happens in the time window of length $\\tau$. The number of events $N(\\tau)$ in this window follows a Poisson distribution with mean $\\mu = \\Lambda \\tau$. The probability of observing $j$ events is $P(N(\\tau)=j) = \\frac{(\\Lambda \\tau)^j \\exp(-\\Lambda \\tau)}{j!}$.\nThe probability of no conflict, $P(\\mathcal{E}_{conflict}^c)$, is the probability of zero events in the window:\n$$P(\\mathcal{E}_{conflict}^c) = P(N(\\tau)=0) = \\frac{(\\Lambda \\tau)^0 \\exp(-\\Lambda \\tau)}{0!} = \\exp(-\\Lambda \\tau)$$\nCombining these probabilities, the overall success probability for an $SC$ attempt is:\n$$p = P(\\mathcal{E}_{conflict}^c) P(\\mathcal{E}_{spur}^c) = \\exp(-\\Lambda \\tau) (1 - \\sigma)$$\nNow we can compute the expected number of retries, $\\mathbb{E}[R]$:\n$$\\mathbb{E}[R] = \\frac{1-p}{p} = \\frac{1 - (1-\\sigma)\\exp(-\\Lambda \\tau)}{(1-\\sigma)\\exp(-\\Lambda \\tau)}$$\nThis expression can be simplified:\n$$\\mathbb{E}[R] = \\frac{1}{(1-\\sigma)\\exp(-\\Lambda \\tau)} - \\frac{(1-\\sigma)\\exp(-\\Lambda \\tau)}{(1-\\sigma)\\exp(-\\Lambda \\tau)} = \\frac{\\exp(\\Lambda \\tau)}{1-\\sigma} - 1$$\nThis is the final closed-form analytic expression for the expected number of retries.", "answer": "$$\\boxed{\\frac{\\exp(\\Lambda \\tau)}{1-\\sigma} - 1}$$", "id": "3621226"}, {"introduction": "Building on the analysis of retry loops, this final practice addresses a critical performance question: what is the best way to wait between failed attempts? You will model an exponential backoff strategy and use calculus to determine the optimal configuration, revealing important insights about contention management in concurrent systems [@problem_id:3654148]. This exercise demonstrates how theoretical modeling can lead to practical engineering decisions.", "problem": "A multicore system uses load-linked (LL) and store-conditional (SC) primitives to update a single shared memory word. Consider a single thread that repeatedly attempts the update until it succeeds. The interference from other cores that can invalidate the reservation is modeled as a homogeneous Poisson process of conflicting writes with rate $\\lambda$ per second, independent of the thread’s behavior.\n\nEach LL/SC attempt by the thread consists of immediately performing the LL followed by the SC, taking a deterministic time of $s$ seconds from the start of the LL to the end of the SC. The attempt succeeds if and only if no conflicting write occurs during this $s$-second interval; otherwise, the SC fails. On failure of the $i$-th attempt (for $i \\in \\{0,1,2,\\dots\\}$ with the first attempt indexed by $i=0$), the thread waits a backoff time $b(i+1) = c \\cdot 2^{i+1}$ seconds before trying again, where $c \\ge 0$ is a constant parameter to be chosen. The first attempt at $i=0$ incurs no backoff.\n\nAssuming that attempts continue until the first success, and using only fundamental properties of Poisson processes and basic probability, derive the expected total elapsed time from the start of the first attempt until the first successful SC as a function of $c$, $\\lambda$, and $s$. Then determine the value $c^{\\star} \\ge 0$ that minimizes this expected time. Express $c^{\\star}$ in seconds. If the expected time diverges for some parameter ranges, you must account for that in your minimization. No numerical approximations are required, and no rounding is needed.", "solution": "The problem asks for the expected total elapsed time for a thread to successfully update a shared memory word using load-linked (LL) and store-conditional (SC) primitives, and to find the backoff parameter $c$ that minimizes this time. The validation of the problem statement finds it to be scientifically grounded, well-posed, and objective. We may proceed with a formal solution.\n\nLet us begin by defining the parameters of a single LL/SC attempt. An attempt takes a deterministic time $s$. It fails if one or more conflicting writes occur during this interval. The conflicting writes are modeled as a homogeneous Poisson process with rate $\\lambda$. The number of conflicting writes, $N(s)$, in an interval of length $s$ follows a Poisson distribution with mean $\\mu = \\lambda s$.\nThe probability of success for a single attempt, $p$, is the probability of zero conflicting writes occurring in the $s$-second interval:\n$$p = P(N(s)=0) = \\frac{(\\lambda s)^0 \\exp(-\\lambda s)}{0!} = \\exp(-\\lambda s)$$\nThe probability of failure for a single attempt is $q = 1 - p = 1 - \\exp(-\\lambda s)$.\n\nThe thread repeatedly attempts the update until it succeeds. This can be modeled as a sequence of independent Bernoulli trials, each with a success probability of $p$. Let $K$ be the random variable representing the number of failed attempts before the first successful attempt. $K$ follows a geometric distribution with parameter $p$:\n$$P(K=k) = (1-p)^k p = q^k p, \\quad k \\in \\{0, 1, 2, \\dots\\}$$\n\nNow, let's determine the total time elapsed, $T_k$, if the process experiences $k$ failures followed by one success. This corresponds to a total of $k+1$ attempts. Each attempt takes $s$ seconds, so the total time spent executing the LL/SC pairs is $(k+1)s$.\nIn addition, after each of the $k$ failures, the thread waits for a backoff period. The $i$-th failure (for $i=0, 1, \\dots, k-1$) is followed by the $(i+1)$-th attempt, which is preceded by a backoff of $b(i+1) = c \\cdot 2^{i+1}$ seconds. The total backoff time for $k$ failures is the sum of the first $k$ backoff periods:\n$$\\text{Total Backoff Time} = \\sum_{j=1}^{k} b(j) = \\sum_{j=1}^{k} c \\cdot 2^j$$\nNote that this sum is empty (and thus equals $0$) if $k=0$, which is correct as there is no backoff before the first attempt.\nThe total elapsed time for $k$ failures is the sum of the time for the attempts and the backoff periods:\n$$T_k = (k+1)s + \\sum_{j=1}^{k} c \\cdot 2^j$$\n\nThe expected total elapsed time, $E[T]$, is found by summing $T_k$ over all possible values of $k$, weighted by their respective probabilities:\n$$E[T] = \\sum_{k=0}^{\\infty} T_k P(K=k) = \\sum_{k=0}^{\\infty} \\left( (k+1)s + \\sum_{j=1}^{k} c \\cdot 2^j \\right) q^k p$$\nWe can split this expectation into two parts:\n$$E[T] = s \\sum_{k=0}^{\\infty} (k+1) q^k p + c \\sum_{k=0}^{\\infty} \\left( \\sum_{j=1}^{k} 2^j \\right) q^k p$$\n\nThe first term is $s$ times the expected number of trials until the first success in a geometric distribution, which is $1/p$.\n$$s \\sum_{k=0}^{\\infty} (k+1) q^k p = s \\cdot E[K+1] = s \\cdot \\frac{1}{p} = s \\exp(\\lambda s)$$\n\nThe second term involves the backoff costs. Let's analyze the double summation:\n$$c p \\sum_{k=0}^{\\infty} q^k \\sum_{j=1}^{k} 2^j = c p \\sum_{k=1}^{\\infty} q^k \\sum_{j=1}^{k} 2^j$$\nWe can change the order of summation. The sum is over pairs $(j,k)$ such that $1 \\le j \\le k < \\infty$. This is equivalent to summing over $j \\ge 1$ and $k \\ge j$:\n$$c p \\sum_{j=1}^{\\infty} \\sum_{k=j}^{\\infty} q^k 2^j = c p \\sum_{j=1}^{\\infty} 2^j \\left( \\sum_{k=j}^{\\infty} q^k \\right)$$\nThe inner sum is a geometric series: $\\sum_{k=j}^{\\infty} q^k = q^j + q^{j+1} + \\dots = \\frac{q^j}{1-q} = \\frac{q^j}{p}$.\nSubstituting this back, we get:\n$$c p \\sum_{j=1}^{\\infty} 2^j \\left( \\frac{q^j}{p} \\right) = c \\sum_{j=1}^{\\infty} (2q)^j$$\nThis is another geometric series. It converges if and only if its ratio $|2q|$ is less than $1$. Since $q = 1-\\exp(-\\lambda s) \\ge 0$, the condition is $2q < 1$. If convergence holds, the sum is $\\frac{\\text{first term}}{1-\\text{ratio}} = \\frac{2q}{1-2q}$.\nThe condition $2q < 1$ translates to $2(1-\\exp(-\\lambda s)) < 1$, which simplifies to $1 - \\exp(-\\lambda s) < 1/2$, or $\\exp(-\\lambda s) > 1/2$. Taking the natural logarithm of both sides gives $-\\lambda s > \\ln(1/2) = -\\ln(2)$, which implies $\\lambda s < \\ln(2)$.\n\nThus, for $\\lambda s < \\ln(2)$, the expected total elapsed time is:\n$$E[T](c) = \\frac{s}{p} + c \\frac{2q}{1-2q} = s \\exp(\\lambda s) + c \\frac{2(1-\\exp(-\\lambda s))}{1 - 2(1-\\exp(-\\lambda s))} = s \\exp(\\lambda s) + c \\frac{2(1-\\exp(-\\lambda s))}{2\\exp(-\\lambda s) - 1}$$\nThis is the first part of the required derivation.\n\nNow, we must account for the case where the expectation may diverge.\nIf $\\lambda s \\ge \\ln(2)$, then $2q \\ge 1$.\nIf $c > 0$, the terms of the series $c \\sum (2q)^j$ are positive and do not tend to zero, so the series diverges. Since all terms in the original sum for $E[T]$ are non-negative, $E[T]$ diverges to infinity.\nIf $c=0$, the backoff term is zero for all $k$. In this case, $E[T]$ is simply the expectation of the time spent in attempts, which is $s/p = s \\exp(\\lambda s)$, a finite value.\n\nTo summarize the expected time as a function of $c$, $\\lambda$, and $s$ for $c \\ge 0$:\n$$E[T](c) = \\begin{cases} s \\exp(\\lambda s) + c \\frac{2(1-\\exp(-\\lambda s))}{2\\exp(-\\lambda s) - 1} & \\text{if } \\lambda s < \\ln(2) \\\\ s \\exp(\\lambda s) & \\text{if } \\lambda s \\ge \\ln(2) \\text{ and } c=0 \\\\ \\infty & \\text{if } \\lambda s \\ge \\ln(2) \\text{ and } c > 0 \\end{cases}$$\n\nThe second task is to find the value $c^{\\star} \\ge 0$ that minimizes $E[T](c)$. We analyze two cases.\n\nCase 1: $\\lambda s < \\ln(2)$\nIn this regime, $E[T](c)$ is a linear function of $c$. Let's examine the slope:\n$$\\frac{\\partial E[T]}{\\partial c} = \\frac{2(1-\\exp(-\\lambda s))}{2\\exp(-\\lambda s) - 1}$$\nThe numerator, $2(1-\\exp(-\\lambda s))$, is positive since $\\lambda > 0$ and $s > 0$.\nThe denominator, $2\\exp(-\\lambda s) - 1$, is also positive because the condition $\\lambda s < \\ln(2)$ implies $\\exp(-\\lambda s) > 1/2$.\nSince the slope is positive, $E[T](c)$ is a strictly increasing function of $c$ for $c \\ge 0$. The minimum value is therefore achieved at the smallest possible value of $c$, which is $c^{\\star}=0$.\n\nCase 2: $\\lambda s \\ge \\ln(2)$\nIn this regime, the expected time $E[T](c)$ is finite only at a single point in its domain $c \\ge 0$, namely at $c=0$, where $E[T](0) = s \\exp(\\lambda s)$. For any $c > 0$, the expected time is infinite. The minimum finite value of the expected time is thus achieved at $c^{\\star}=0$.\n\nIn both cases, the analysis leads to the same conclusion: the optimal value for the backoff parameter is $c^{\\star} = 0$. This result stems from the problem's key assumption that the interference process is independent of the thread's actions. Waiting does not increase the probability of success for the next attempt, so any time spent in backoff only increases the total expected time. The optimal strategy is to retry immediately upon failure.", "answer": "$$\\boxed{0}$$", "id": "3654148"}]}