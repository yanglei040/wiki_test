{"hands_on_practices": [{"introduction": "Understanding the benefits of threads, such as improved responsiveness and parallelism, must be balanced with their resource costs. While threads are more lightweight than full processes, they are not free. This first exercise makes that cost tangible by focusing on the process's virtual address space, a finite resource that all threads must share. You will learn to calculate the maximum number of threads a system can support within its memory limits, a fundamental skill for designing scalable, high-performance applications. [@problem_id:3688668]", "problem": "A single process in a modern Operating System (OS) maintains one shared virtual address space for all its threads. The OS enforces allocation and protection at the page granularity, and typical thread stacks are reserved as contiguous regions with additional unmapped guard pages to catch overflow. Consider a process whose user-space virtual address space is bounded above by a limit $V$ (bytes). Independent of the number of threads, the process has other non-stack virtual memory mappings summing to $B$ (bytes). Every thread, including the main thread, reserves a stack of size $S$ (bytes) plus $g$ unmapped guard pages of size $p$ (bytes) each, and all stack regions are page-aligned and mutually disjoint. Assume there are no other per-thread virtual memory reservations and ignore minor metadata overhead.\n\nYou are given:\n- $V = 2.5 \\times 2^{30}$ bytes,\n- $B = 900 \\times 2^{20}$ bytes,\n- $S = 8 \\times 2^{20}$ bytes,\n- $g = 3$,\n- $p = 4096$ bytes.\n\nDetermine the maximum safe thread count $T_{\\max}$, including the main thread, such that the total reserved virtual address space does not exceed $V$. Report your answer as an exact integer with no units.", "solution": "The problem asks for the maximum number of threads, $T_{\\max}$, that a process can create without its total reserved virtual address space exceeding a given limit, $V$.\n\nLet $T$ be the number of threads in the process. The total reserved virtual address space, $V_{total}$, is composed of two parts: a fixed-size component for non-stack mappings, $B$, and a variable component that depends on the number of threads.\n\nThe space reserved for each thread consists of its stack, of size $S$, and a set of $g$ guard pages, each of size $p$. The total space reserved per thread, which we can denote as $S_{\\text{thread}}$, is therefore:\n$$ S_{\\text{thread}} = S + g \\cdot p $$\nWith $T$ threads, the total space reserved for all thread-specific structures is:\n$$ T \\cdot S_{\\text{thread}} = T (S + g \\cdot p) $$\nThe total virtual address space reserved by the process is the sum of the non-stack mappings and the total thread-related mappings:\n$$ V_{\\text{total}} = B + T (S + g \\cdot p) $$\nThe problem states that this total reservation must not exceed the upper limit $V$. This constraint is expressed by the following inequality:\n$$ B + T (S + g \\cdot p) \\leq V $$\nTo find the maximum number of threads, we must solve for the maximum integer $T$ that satisfies this inequality. We can rearrange the inequality to isolate $T$:\n$$ T (S + g \\cdot p) \\leq V - B $$\n$$ T \\leq \\frac{V - B}{S + g \\cdot p} $$\nSince the number of threads $T$ must be an integer, the maximum safe thread count, $T_{\\max}$, is the floor of the value on the right-hand side of the inequality:\n$$ T_{\\max} = \\left\\lfloor \\frac{V - B}{S + g \\cdot p} \\right\\rfloor $$\nWe are given the following values:\n- $V = 2.5 \\times 2^{30}$ bytes\n- $B = 900 \\times 2^{20}$ bytes\n- $S = 8 \\times 2^{20}$ bytes\n- $g = 3$\n- $p = 4096 = 2^{12}$ bytes\n\nFirst, we calculate the numerator, which represents the total virtual address space available for thread reservations. It is helpful to express all quantities in a common base unit, such as bytes.\nTo compute $V - B$, we first express $V$ in terms of multiples of $2^{20}$ bytes (mebibytes).\n$$ V = 2.5 \\times 2^{30} \\text{ bytes} = 2.5 \\times 2^{10} \\times 2^{20} \\text{ bytes} = 2.5 \\times 1024 \\times 2^{20} \\text{ bytes} = 2560 \\times 2^{20} \\text{ bytes} $$\nNow we can compute the difference:\n$$ V - B = (2560 \\times 2^{20}) - (900 \\times 2^{20}) = (2560 - 900) \\times 2^{20} = 1660 \\times 2^{20} \\text{ bytes} $$\nIn absolute byte value, this is:\n$$ V - B = 1660 \\times 1,048,576 = 1,740,636,160 \\text{ bytes} $$\nNext, we calculate the denominator, which is the total reservation per thread, $S + g \\cdot p$.\n$$ S = 8 \\times 2^{20} = 8 \\times 1,048,576 = 8,388,608 \\text{ bytes} $$\n$$ g \\cdot p = 3 \\times 4096 = 12,288 \\text{ bytes} $$\nThe total per-thread reservation is:\n$$ S + g \\cdot p = 8,388,608 + 12,288 = 8,400,896 \\text{ bytes} $$\nNow we can substitute these values back into the inequality for $T$:\n$$ T \\leq \\frac{1,740,636,160}{8,400,896} $$\nPerforming the division:\n$$ T \\leq 207.19904... $$\nSince $T$ must be an integer, the maximum value it can take, $T_{\\max}$, is the integer part of this result.\n$$ T_{\\max} = \\lfloor 207.19904... \\rfloor = 207 $$\nTherefore, the maximum safe thread count, including the main thread, is $207$.", "answer": "$$\n\\boxed{207}\n$$", "id": "3688668"}, {"introduction": "Having explored the process-wide budget for threads, we now zoom in on the needs of a single thread. A thread's stack is a critical but finite resource; sizing it too small risks a catastrophic stack overflow, while sizing it too large wastes memory. This problem guides you through a detailed safety analysis for a recursive workload, teaching you to calculate a minimal, safe stack size by accounting for function call overhead, system margins, and hardware page alignment. [@problem_id:3688677]", "problem": "A parallel divide-and-conquer algorithm runs on a multicore machine under an Operating System (OS). Each worker thread executes a recursive routine that halves the problem size until reaching a base case of size $1$. The Random Access Memory (RAM) allocator reserves a fixed per-thread stack of size $S$ bytes, which must be an integer multiple of the page size $p$. The OS attaches non-accessible guard pages totaling $g$ bytes to each thread stack, so only $S - g$ bytes are available for the thread’s execution. The non-recursive baseline usage (thread runtime, scheduler bookkeeping, and per-thread library state) occupies $h$ bytes on the accessible stack. Each recursive call consumes a fixed stack frame of $f$ bytes. To tolerate asynchronous events (e.g., signal handlers and interrupts), a conservative margin of $r$ bytes must be reserved on the accessible stack.\n\nThe algorithm processes $n = 2^{20}$ elements, splitting in half until size $1$, with page size $p = 4096$ bytes, guard total $g = 8192$ bytes, baseline stack usage $h = 32768$ bytes, frame size per recursive call $f = 384$ bytes, and asynchronous margin $r = 24576$ bytes. The Application Binary Interface ensures recursion depth equals the number of halving steps needed to reduce $n$ to $1$.\n\nAssume a fixed total budget of stack memory across all threads; maximizing concurrency means choosing the smallest stack size that is safe, because the number of threads is inversely related to $S$ when the budget is fixed. Use first principles to derive the recursion depth from the halving process and then derive a safety condition on $S$ that prevents stack overflow. From that condition, determine the minimal safe $S$ that satisfies page-size alignment. Express the final stack size in bytes. No rounding is required beyond integral page alignment.", "solution": "The objective is to find the minimal safe per-thread stack size, $S$, that is an integer multiple of the page size $p$.\n\nFirst, we must determine the recursion depth, denoted by $d$. The algorithm starts with a problem of size $n$ and recursively halves it until the size becomes $1$. After $k$ recursive calls, the problem size is $\\frac{n}{2^k}$. The recursion stops at the base case when the size is $1$. Therefore, the depth $d$ must satisfy the equation:\n$$\n\\frac{n}{2^d} = 1\n$$\nSolving for $d$, we get $2^d = n$, which implies $d = \\log_2(n)$. Given $n = 2^{20}$, the recursion depth is:\n$$\nd = \\log_2(2^{20}) = 20\n$$\n\nNext, we establish the safety condition for the stack size. The total memory allocated for a thread's stack is $S$. However, a portion $g$ is used for non-accessible guard pages. Thus, the accessible, or usable, stack space for the thread is $S_{usable} = S - g$.\n\nThe total stack space required for the thread's execution, $U_{req}$, must be less than or equal to the usable stack space. This required space is the sum of three components:\n1. The non-recursive baseline usage, $h$.\n2. The total size of stack frames for all recursive calls, which is the depth $d$ multiplied by the frame size $f$. This is $d \\times f$.\n3. The conservative margin for asynchronous events, $r$.\n\nSo, the total required stack space is:\n$$\nU_{req} = h + d \\times f + r\n$$\nThe safety condition is therefore:\n$$\nU_{req} \\le S_{usable}\n$$\n$$\nh + d \\times f + r \\le S - g\n$$\nTo find the minimum possible stack size $S$, we can solve for $S$:\n$$\nS \\ge h + d \\times f + r + g\n$$\nLet's call the minimum required size, before considering page alignment, $S_{min\\_raw}$. This corresponds to the equality:\n$$\nS_{min\\_raw} = h + d \\times f + r + g\n$$\nSubstituting the given values:\n- $h = 32768$ bytes\n- $d = 20$\n- $f = 384$ bytes\n- $r = 24576$ bytes\n- $g = 8192$ bytes\n\nWe can calculate $S_{min\\_raw}$:\n$$\nS_{min\\_raw} = 32768 + (20 \\times 384) + 24576 + 8192\n$$\n$$\nS_{min\\_raw} = 32768 + 7680 + 24576 + 8192\n$$\n$$\nS_{min\\_raw} = 73216 \\text{ bytes}\n$$\n\nFinally, we apply the constraint that the stack size $S$ must be an integer multiple of the page size $p = 4096$ bytes. This means $S = k \\times p$ for some integer $k$. We need to find the smallest integer $k$ such that $S \\ge S_{min\\_raw}$.\n$$\nk \\times p \\ge S_{min\\_raw}\n$$\n$$\nk \\times 4096 \\ge 73216\n$$\nSolving for $k$:\n$$\nk \\ge \\frac{73216}{4096}\n$$\n$$\nk \\ge 17.875\n$$\nSince $k$ must be an integer, the smallest integer value for $k$ is $18$. The minimal safe stack size $S$ is therefore:\n$$\nS = 18 \\times p = 18 \\times 4096\n$$\n$$\nS = 73728 \\text{ bytes}\n$$\nThis stack size satisfies the safety condition ($73728 \\ge 73216$) and the alignment constraint ($73728$ is a multiple of $4096$).", "answer": "$$\n\\boxed{73728}\n$$", "id": "3688677"}, {"introduction": "Managing resources is only half the battle; ensuring correctness is the other. In concurrent programs, the intuitive assumption that operations execute in the order they are written is often false due to optimizations in compilers and hardware. This practice problem confronts this reality head-on, using a simplified memory model to expose a classic data race. You will explore how these reorderings can lead to incorrect results and how synchronization primitives like memory fences are used to restore order and guarantee program correctness. [@problem_id:3688611]", "problem": "You will model a two-thread program and reason about an outcome using a simplified memory system that captures the core intuition behind thread-level benefits and concurrency pitfalls. The goal is to detect whether a specific concurrency anomaly is possible under different intra-thread ordering constraints and then quantify how inserting fences changes the reachability of that anomaly. The final program must compute these results for a given test suite and print them in the required format.\n\nConsider two threads $T_1$ and $T_2$ operating on shared variables $x$ and $y$ with initial values $x = 0$ and $y = 0$. Thread $T_1$ performs a store to $x$ followed by a load from $y$ that is assigned to register $r_1$. Thread $T_2$ performs a store to $y$ followed by a load from $x$ that is assigned to register $r_2$. We are interested in whether the outcome $r_1 = 0$ and $r_2 = 0$ can occur.\n\nStarting from the following well-tested, foundational definitions:\n- Sequential consistency (Lamport): every execution is equivalent to some interleaving of all threads’ operations that respects the program order of each thread.\n- Store-buffer intuition from widely taught computer architecture: a thread-local buffer can delay the visibility of its stores to other threads until the buffer flushes; reads observe the most recent local buffered value for the same location if present, otherwise the globally visible value.\n\nWe use the following simplified store-buffered model of memory, which preserves scientific realism while remaining computationally tractable:\n- Each thread maintains a local write buffer. A store $W(v,1)$ to a variable $v \\in \\{x,y\\}$ places the value $1$ in the thread’s buffer for $v$; the shared memory for $v$ does not change until the buffer flushes.\n- A read $R(v)$ returns the thread’s buffered value for $v$ if present; otherwise it returns the current shared memory value of $v$.\n- Program order inside a thread is respected: operations occur in the order they are written.\n- A fence flushes the thread’s local buffer to shared memory at the point where it appears.\n- Inter-thread interleaving is arbitrary: the operations of $T_1$ and $T_2$ can be interleaved in any order that maintains each thread’s program order.\n\nUnder this model, the outcome $r_1 = 0$ and $r_2 = 0$ is possible if and only if each thread performs its read before the other thread’s buffered write has been flushed to shared memory. Fences placed between a thread’s store and its subsequent read ensure that thread’s buffered write is flushed before that read, eliminating some or all executions that would otherwise allow the outcome $r_1 = 0$ and $r_2 = 0$.\n\nParameterization:\n- For thread $T_i$ ($i \\in \\{1,2\\}$), let $p_i \\in \\{0,1,2,3\\}$ denote the fence position:\n  - $p_i = 0$: no fence,\n  - $p_i = 1$: fence before the store ($\\text{fence};\\ W;\\ R$),\n  - $p_i = 2$: fence between the store and the read ($W;\\ \\text{fence};\\ R$),\n  - $p_i = 3$: fence after the read ($W;\\ R;\\ \\text{fence}$).\n- A fence flushes only the issuing thread’s buffer at its position in program order.\n- We define a boolean function that returns $1$ if the outcome $r_1 = 0$ and $r_2 = 0$ is reachable under the simplified model and the given $p_1$ and $p_2$, and $0$ otherwise.\n\nTest suite:\n- Case $1$: $p_1 = 0$, $p_2 = 0$. Baseline: no fences.\n- Case $2$: $p_1 = 2$, $p_2 = 2$. Fences placed between each store and read.\n- Case $3$: $p_1 = 2$, $p_2 = 0$. Fence between store and read in $T_1$ only.\n- Case $4$: $p_1 = 3$, $p_2 = 3$. Fences after reads only.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4]$), where each $r_k \\in \\{0,1\\}$ is the boolean described above. No spaces are permitted in the output.\n\nThere are no physical units and no angles involved. All outputs are integers in $\\{0,1\\}$.", "solution": "The problem is well-posed and scientifically sound. It presents a simplified but logically consistent memory model to explore fundamental concepts of thread-level concurrency, program order, and memory fences. The model is a standard pedagogical tool for introducing memory consistency issues in operating systems and computer architecture. All terms are defined, the initial state is specified, and the objective is clear. Thus, a rigorous analysis can be performed.\n\nThe core of the problem is to determine the reachability of the outcome where register $r_1=0$ and register $r_2=0$. Let us formalize the model and analyze the conditions required for this outcome.\n\n**1. Formal Model**\n\n- **State**: The state of the system is a tuple $(M, B_1, B_2)$, where $M$ is the shared memory mapping variables to values, and $B_i$ is the private store buffer for thread $T_i$. Initially, $M(x)=0$, $M(y)=0$, and buffers $B_1, B_2$ are empty.\n- **Operations**:\n    - Store $W_i(v, k)$: Thread $T_i$ writes value $k$ to variable $v$. This updates the local buffer, $B_i(v) \\leftarrow k$.\n    - Load $R_i(v) \\rightarrow r_i$: Thread $T_i$ reads variable $v$ into its register $r_i$. The value read is $B_i(v)$ if it exists; otherwise, it is $M(v)$.\n    - Fence $F_i$: Thread $T_i$ flushes its buffer $B_i$ to shared memory. For every variable $v$ in $B_i$, $M(v) \\leftarrow B_i(v)$, and the entry for $v$ is cleared from $B_i$.\n- **Thread Programs**:\n    - $T_1$: Operates on $x$ and $y$. The base sequence is $W_1(x,1); R_1(y) \\rightarrow r_1$.\n    - $T_2$: Operates on $y$ and $x$. The base sequence is $W_2(y,1); R_2(x) \\rightarrow r_2$.\n- **Execution**: An execution is a total ordering of all operations from all threads that respects the program order within each thread. Let $\\xrightarrow{PO}$ denote program order and $\\xrightarrow{EXE}$ denote the global execution order.\n\n**2. Condition for the Outcome $r_1=0 \\land r_2=0$**\n\nFor the outcome $r_1=0$ to occur, the load $R_1(y)$ must return $0$. Since thread $T_1$ never writes to $y$, its buffer $B_1$ is always empty for $y$. Therefore, $R_1(y)$ always reads from shared memory $M(y)$. The operation $W_2(y,1)$ by thread $T_2$ changes $M(y)$ from $0$ to $1$ only when $T_2$ executes a fence, $F_2$. Thus, for $r_1=0$, the operation $R_1(y)$ must occur before $F_2$ in the global execution order (if $F_2$ exists).\nCondition for $r_1=0$: $R_1(y) \\xrightarrow{EXE} F_2$.\n\nSimilarly, for the outcome $r_2=0$, the load $R_2(x)$ must return $0$. Since $T_2$ never writes to $x$, $R_2(x)$ reads from $M(x)$. The operation $W_1(x,1)$ by $T_1$ changes $M(x)$ to $1$ only upon the execution of $F_1$. Thus, for $r_2=0$, $R_2(x)$ must occur before $F_1$ (if $F_1$ exists).\nCondition for $r_2=0$: $R_2(x) \\xrightarrow{EXE} F_1$.\n\nThe outcome $r_1=0 \\land r_2=0$ is reachable if and only if there exists a valid execution trace satisfying these conditions simultaneously.\n\n**3. General Analysis of Fence Positions**\n\nThe parameter $p_i \\in \\{0, 1, 2, 3\\}$ determines the program order for thread $T_i$. We analyze the critical case $p_i=2$, which places a fence between the store and the load.\n\n- If $p_1=2$, the program order for $T_1$ is $W_1(x,1) \\xrightarrow{PO} F_1 \\xrightarrow{PO} R_1(y)$.\n- If $p_2=2$, the program order for $T_2$ is $W_2(y,1) \\xrightarrow{PO} F_2 \\xrightarrow{PO} R_2(x)$.\n\nLet's analyze the case where both $p_1=2$ and $p_2=2$. For the target outcome to be reachable, we need to satisfy the following ordering constraints:\n1. $R_2(x) \\xrightarrow{EXE} F_1$ (for $r_2=0$)\n2. $F_1 \\xrightarrow{EXE} R_1(y)$ (from $T_1$ program order, since $p_1=2$)\n3. $R_1(y) \\xrightarrow{EXE} F_2$ (for $r_1=0$)\n4. $F_2 \\xrightarrow{EXE} R_2(x)$ (from $T_2$ program order, since $p_2=2$)\n\nCombining these constraints, we find a cycle:\n- From ($1$) and ($2$): $R_2(x) \\xrightarrow{EXE} F_1 \\xrightarrow{EXE} R_1(y) \\implies R_2(x) \\xrightarrow{EXE} R_1(y)$.\n- From ($3$) and ($4$): $R_1(y) \\xrightarrow{EXE} F_2 \\xrightarrow{EXE} R_2(x) \\implies R_1(y) \\xrightarrow{EXE} R_2(x)$.\n\nThe two derived constraints, $R_2(x) \\xrightarrow{EXE} R_1(y)$ and $R_1(y) \\xrightarrow{EXE} R_2(x)$, form a logical contradiction. A total ordering of operations cannot have a cycle. Therefore, when $p_1=2$ and $p_2=2$, the outcome $r_1=0 \\land r_2=0$ is unreachable.\n\nNow, consider any other case, where $p_1 \\neq 2$ or $p_2 \\neq 2$. This means that at least one of the program order constraints ($F_1 \\xrightarrow{PO} R_1(y)$ or $F_2 \\xrightarrow{PO} R_2(x)$) is not present. This breaks the cycle. For all such cases, we can construct a valid execution trace. For example, the following trace works whenever the cycle is broken:\n$W_1(x,1) \\xrightarrow{EXE} W_2(y,1) \\xrightarrow{EXE} R_1(y) \\xrightarrow{EXE} R_2(x) \\xrightarrow{EXE} ...$ (remaining fences, if any).\n- At the time of $R_1(y)$, $F_2$ has not executed (regardless of $p_2$), so $r_1=0$.\n- At the time of $R_2(x)$, $F_1$ has not executed (regardless of $p_1$), so $r_2=0$.\nThis sequence is valid as long as it doesn't violate program order. The problematic POs are $F_1 \\xrightarrow{PO} R_1$ and $F_2 \\xrightarrow{PO} R_2$. As long as at least one of these is not enforced, we can interleave the reads before the problematic fence, allowing the outcome.\n\nTherefore, the general rule is: the outcome $r_1=0 \\land r_2=0$ is reachable if and only if it is not the case that $(p_1=2 \\text{ and } p_2=2)$.\n\n**4. Application to Test Suite**\n\nWe apply this derived rule to the specific test cases.\n\n- **Case 1: $p_1 = 0, p_2 = 0$.**\nThis is not the case $(p_1=2, p_2=2)$. The outcome is reachable. Result: $1$.\n\n- **Case 2: $p_1 = 2, p_2 = 2$.**\nThis is precisely the case that creates an unbreakable dependency cycle. The outcome is unreachable. Result: $0$.\n\n- **Case 3: $p_1 = 2, p_2 = 0$.**\nThis is not the case $(p_1=2, p_2=2)$ because $p_2 \\neq 2$. The outcome is reachable. Result: $1$.\n\n- **Case 4: $p_1 = 3, p_2 = 3$.**\nThis is not the case $(p_1=2, p_2=2)$ because $p_1 \\neq 2$ and $p_2 \\neq 2$. The outcome is reachable. Result: $1$.\n\nThe final sequence of results is $[1, 0, 1, 1]$.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n// A struct to hold the parameters for a single test case.\n// p1 is the fence position for thread T1, p2 for thread T2.\ntypedef struct {\n    int p1;\n    int p2;\n} TestCase;\n\n// This function determines if the outcome r1=0 and r2=0 is reachable\n// for a given pair of fence positions (p1, p2). The logic is derived\n// from analyzing the dependencies created by the fences.\nint is_outcome_reachable(int p1, int p2) {\n    // The outcome r1=0 and r2=0 requires that T1's read of y happens before\n    // T2's write to y is made visible by a fence, and that T2's read of x\n    // happens before T1's write to x is made visible.\n    //\n    // A fence placed between a store and a subsequent load (p=2) creates\n    // a strong ordering constraint within a thread. For T1, p1=2 means\n    // its store to x is guaranteed to be visible to other threads before\n    // its read of y occurs. For T2, p2=2 means its store to y is visible\n    // before its read of x.\n    //\n    // If both threads have p=2, a circular dependency arises:\n    // 1. To get r2=0, T2's read must precede T1's fence.\n    // 2. But T1's fence must precede T1's read (by T1's program order).\n    // 3. To get r1=0, T1's read must precede T2's fence.\n    // 4. But T2's fence must precede T2's read (by T2's program order).\n    // This creates the cycle: T2_read -> T1_fence -> T1_read -> T2_fence -> T2_read.\n    // This cycle is impossible to satisfy in any sequential execution trace.\n    //\n    // In any other configuration of fences (where at least one p is not 2),\n    // this specific cycle of dependencies is broken, and an interleaving\n    // can be constructed that allows the r1=0, r2=0 outcome.\n    if (p1 == 2 && p2 == 2) {\n        return 0; // Unreachable\n    } else {\n        return 1; // Reachable\n    }\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {0, 0}, // Case 1: No fences.\n        {2, 2}, // Case 2: Fence between store and read in both threads.\n        {2, 0}, // Case 3: Fence in T1 only.\n        {3, 3}  // Case 4: Fence after read in both threads.\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases];\n\n    // Calculate the result for each test case using the derived logic.\n    for (int i = 0; i < num_cases; ++i) {\n        results[i] = is_outcome_reachable(test_cases[i].p1, test_cases[i].p2);\n    }\n\n    // Print the results in the EXACT REQUIRED format: [r1,r2,r3,r4]\n    printf(\"[%d,%d,%d,%d]\\n\", results[0], results[1], results[2], results[3]);\n\n    return EXIT_SUCCESS;\n}\n```", "answer": "[1,0,1,1]", "id": "3688611"}]}