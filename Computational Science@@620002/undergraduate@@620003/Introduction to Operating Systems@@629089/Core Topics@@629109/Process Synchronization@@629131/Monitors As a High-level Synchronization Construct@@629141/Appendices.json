{"hands_on_practices": [{"introduction": "Understanding the subtle differences between monitor semantics is essential for writing correct and robust concurrent programs. This first exercise explores the crucial distinction between Hoare-style and Mesa-style monitors, which lies in the behavior of the `signal` operation. By analyzing a classic bounded-buffer problem, you will discover why Mesa-style monitors, the most common implementation, require you to re-check the condition after waking up from a `wait` call, making the `while` loop a non-negotiable pattern for safety [@problem_id:3659620].", "problem": "A monitor implements a bounded buffer with capacity $N$ using a condition variable for producers ($\\texttt{notFull}$) and a condition variable for consumers ($\\texttt{notEmpty}$). Let the monitor state be given by integer variables $count$, $head$, and $tail$, with invariant $0 \\leq count \\leq N$. Under Hoare-style semantics (signal-and-urgent-wait), a thread that executes $\\texttt{signal}(c)$ immediately yields the monitor to some thread waiting on $c$, and that waiting thread runs next inside the monitor; otherwise, if no thread is waiting on $c$, the $\\texttt{signal}$ has no effect. The monitor uses the following pattern inside its procedures:\n- For $\\texttt{put}(x)$: if $count = N$ then $\\texttt{wait}(\\texttt{notFull})$; insert $x$ at position $tail$, update $tail \\leftarrow (tail + 1) \\bmod N$, increment $count \\leftarrow count + 1$, and $\\texttt{signal}(\\texttt{notEmpty})$.\n- For $\\texttt{get}()$: if $count = 0$ then $\\texttt{wait}(\\texttt{notEmpty})$; remove the item at position $head$, update $head \\leftarrow (head + 1) \\bmod N$, decrement $count \\leftarrow count - 1$, and $\\texttt{signal}(\\texttt{notFull})$.\n\nYou are asked to port this monitor to Mesa-style semantics (signal-and-continue), where $\\texttt{signal}(c)$ only makes a waiting thread eligible to run later; the signaling thread continues to execute in the monitor until it exits, and awakened threads must re-acquire the monitor before proceeding. Consider also the common pitfall of guarding $\\texttt{wait}$ by a one-time $\\texttt{if}$ check instead of a re-checking loop.\n\nWhich of the following statements are correct?\n\nA. When converting to Mesa-style semantics, every one-shot guard of the form “if $\\,$predicate$\\,$ then $\\texttt{wait}(c)$” must be replaced by a re-checking loop “while $\\,$predicate$\\,$ do $\\texttt{wait}(c)$”, because a thread awakened by $\\texttt{signal}(c)$ may find that the predicate has become true again by the time it runs.\n\nB. When converting to Mesa-style semantics, it is sufficient to move each $\\texttt{signal}(c)$ inside the body of the guard and place it immediately before $\\texttt{wait}(c)$ (that is, execute $\\texttt{signal}(c)$, then $\\texttt{wait}(c)$), without changing $\\texttt{if}$ to $\\texttt{while}$.\n\nC. Under Hoare-style semantics, guarding $\\texttt{wait}$ with a one-time $\\texttt{if}$ is sound for this monitor because $\\texttt{signal}$ performs a priority handoff: it transfers control inside the monitor to a waiting thread before any other thread can modify the shared state.\n\nD. Under Mesa-style semantics, replacing every $\\texttt{signal}(c)$ by $\\texttt{broadcast}(c)$ while keeping the one-time $\\texttt{if}$ guards is sufficient to preserve safety (no overflow or underflow) without additional changes.\n\nE. Under Mesa-style semantics with one-time $\\texttt{if}$ guards, the following interleaving can violate the invariant $0 \\leq count \\leq N$ by causing overflow: initially $count = N$, a producer $P_1$ calls $\\texttt{put}$, sees $count = N$, and executes $\\texttt{wait}(\\texttt{notFull})$; a consumer $C$ calls $\\texttt{get}$, removes one item so $count \\leftarrow N - 1$, and executes $\\texttt{signal}(\\texttt{notFull})$; before $P_1$ re-acquires the monitor, another producer $P_2$ enters, inserts one item so $count \\leftarrow N$, and exits; then $P_1$ runs, does not re-check the condition (due to the one-time $\\texttt{if}$), inserts another item, making $count \\leftarrow N + 1$.\n\nF. Under Mesa-style semantics with one-time $\\texttt{if}$ guards, the following interleaving can violate the invariant $0 \\leq count \\leq N$ by causing underflow: initially $count = 0$, a consumer $C_1$ calls $\\texttt{get}$, sees $count = 0$, and executes $\\texttt{wait}(\\texttt{notEmpty})$; a producer $P$ calls $\\texttt{put}$, inserts one item so $count \\leftarrow 1$, and executes $\\texttt{signal}(\\texttt{notEmpty})$; before $C_1$ re-acquires the monitor, another consumer $C_2$ enters, removes the item so $count \\leftarrow 0$, and exits; then $C_1$ runs, does not re-check the condition (due to the one-time $\\texttt{if}$), removes from an empty buffer, making $count \\leftarrow -1$.\n\nSelect all that apply.", "solution": "The problem statement has been validated and is a well-posed, standard problem in the study of concurrent programming and operating systems, specifically concerning monitor synchronization. The descriptions of Hoare and Mesa semantics are accurate and sufficient for a rigorous analysis.\n\nThe core of the problem lies in the semantic difference between Hoare-style and Mesa-style signaling on condition variables.\n- **Hoare semantics (signal-and-urgent-wait):** When a thread $T_1$ executes $\\texttt{signal}(c)$, it immediately passes ownership of the monitor lock to a thread $T_2$ that is waiting on the condition variable $c$. $T_2$ resumes execution immediately. This guarantees that the condition for which $T_2$ was waiting, which was established by $T_1$, still holds. No other thread can intervene.\n- **Mesa semantics (signal-and-continue):** When a thread $T_1$ executes $\\texttt{signal}(c)$, it retains ownership of the monitor lock and continues its execution. The signaled thread $T_2$ is merely moved from the condition variable's wait queue to the monitor's entry queue, making it *eligible* to run. It must re-compete for the monitor lock. By the time $T_2$ eventually acquires the lock and resumes execution, the state of the monitor may have been changed by other threads, including $T_1$ itself or other threads that entered the monitor after $T_1$ exited.\n\nBased on these principles, we will evaluate each statement.\n\n**A. When converting to Mesa-style semantics, every one-shot guard of the form “if $\\,$predicate$\\,$ then $\\texttt{wait}(c)$” must be replaced by a re-checking loop “while $\\,$predicate$\\,$ do $\\texttt{wait}(c)$”, because a thread awakened by $\\texttt{signal}(c)$ may find that the predicate has become true again by the time it runs.**\n\nThis statement describes the fundamental requirement for using Mesa-style monitors correctly. In Mesa semantics, a `signal` is only a hint that the condition *might* now be false. Between the time of the signal and the time the waiting thread re-acquires the monitor lock, the state can change. For example, a consumer may signal $\\texttt{notFull}$ when the buffer has one empty slot. Before the awakened producer can run, another producer might acquire the lock and fill that slot. When the first producer finally runs, the buffer is full again. If it used an `if` guard, it would not re-check and would proceed to write to a full buffer, causing an overflow. The `while` loop forces the thread to re-evaluate the predicate after waking up, ensuring it only proceeds when the condition is actually met. This is a canonical practice for robust programming with Mesa-style condition variables.\n\n**Verdict: Correct.**\n\n**B. When converting to Mesa-style semantics, it is sufficient to move each $\\texttt{signal}(c)$ inside the body of the guard and place it immediately before $\\texttt{wait}(c)$ (that is, execute $\\texttt{signal}(c)$, then $\\texttt{wait}(c)$), without changing $\\texttt{if}$ to $\\texttt{while}$.**\n\nThis proposed change fundamentally misunderstands the logic of producer-consumer synchronization. Let's analyze the `put` procedure with this change. The original logic is `if $count = N$ then $\\texttt{wait}(\\texttt{notFull})$`. The proposed change makes this `if $count = N$ then { $\\texttt{signal}(\\texttt{notEmpty})$; $\\texttt{wait}(\\texttt{notFull})$; }`. This is incorrect. A producer finds the buffer is full ($count = N$). It has not added an item, so there is no reason to signal consumers via $\\texttt{signal}(\\texttt{notEmpty})$. Signaling at this point is logically unsound. The purpose of $\\texttt{signal}(\\texttt{notEmpty})$ is to notify a consumer that an item *has been added*. The purpose of $\\texttt{wait}(\\texttt{notFull})$ is for the producer to block until space *becomes available*. Reversing this logic and signaling before waiting on the opposite condition breaks the protocol.\n\n**Verdict: Incorrect.**\n\n**C. Under Hoare-style semantics, guarding $\\texttt{wait}$ with a one-time $\\texttt{if}$ is sound for this monitor because $\\texttt{signal}$ performs a priority handoff: it transfers control inside the monitor to a waiting thread before any other thread can modify the shared state.**\n\nThis is a precise explanation of why `if` guards are sufficient in Hoare-style monitors. When a consumer removes an item, making $count \\leftarrow N-1$, and then executes $\\texttt{signal}(\\texttt{notFull})$, a producer thread waiting on $\\texttt{notFull}$ is immediately awakened and given exclusive access to the monitor. At the instant the producer resumes, the condition it was waiting for (i.e., $count  N$) is guaranteed to be true, as no other thread could have intervened. The \"priority handoff\" is an accurate description of this immediate transfer of control, which preserves the invariant established by the signaler for the benefit of the awakened thread. Therefore, re-checking the condition is redundant.\n\n**Verdict: Correct.**\n\n**D. Under Mesa-style semantics, replacing every $\\texttt{signal}(c)$ by $\\texttt{broadcast}(c)$ while keeping the one-time $\\texttt{if}$ guards is sufficient to preserve safety (no overflow or underflow) without additional changes.**\n\nUsing $\\texttt{broadcast}(c)$ wakes up *all* threads waiting on condition $c$, not just one. If we retain the `if` guard, this change exacerbates the problem. For instance, suppose multiple producers are waiting on $\\texttt{notFull}$. A consumer removes one item and does a $\\texttt{broadcast}(\\texttt{notFull})$. All waiting producers are awakened and placed in the monitor entry queue. One producer, $P_1$, will acquire the lock first, fill the single empty slot, and exit. Then, another awakened producer, $P_2$, will acquire the lock. Because it was guarded by an `if`, $P_2$ will not re-check the buffer state and will proceed as if space is available, causing an overflow. Using `broadcast` without a re-checking `while` loop makes the race condition more severe, as multiple threads will incorrectly assume the condition is favorable.\n\n**Verdict: Incorrect.**\n\n**E. Under Mesa-style semantics with one-time $\\texttt{if}$ guards, the following interleaving can violate the invariant $0 \\leq count \\leq N$ by causing overflow: initially $count = N$, a producer $P_1$ calls $\\texttt{put}$, sees $count = N$, and executes $\\texttt{wait}(\\texttt{notFull})$; a consumer $C$ calls $\\texttt{get}$, removes one item so $count \\leftarrow N - 1$, and executes $\\texttt{signal}(\\texttt{notFull})$; before $P_1$ re-acquires the monitor, another producer $P_2$ enters, inserts one item so $count \\leftarrow N$, and exits; then $P_1$ runs, does not re-check the condition (due to the one-time $\\texttt{if}$), inserts another item, making $count \\leftarrow N + 1$.**\n\nThis scenario is a classic demonstration of the \"stolen wakeup\" or \"barging\" problem in Mesa-style monitors.\n1.  State: $count = N$.\n2.  $P_1$ calls `put`, executes $\\texttt{wait}(\\texttt{notFull})$.\n3.  $C$ calls `get`, decrements $count \\to N-1$, calls $\\texttt{signal}(\\texttt{notFull})$. $P_1$ is now ready to run but doesn't have the lock. $C$ exits.\n4.  Monitor lock is free. A new producer $P_2$ acquires the lock before the awakened $P_1$. This is permissible in Mesa semantics.\n5.  $P_2$ finds $count = N-1  N$, so it inserts an item, increments $count \\to N$, and exits.\n6.  $P_1$ now acquires the lock. It resumes execution *after* its `wait` call. The `if` condition is not re-checked.\n7.  $P_1$ proceeds to insert its item into the now-full buffer, incrementing $count \\to N+1$.\nThis sequence of events is valid under Mesa semantics and directly leads to a violation of the monitor's invariant ($count \\leq N$) by causing a buffer overflow.\n\n**Verdict: Correct.**\n\n**F. Under Mesa-style semantics with one-time $\\texttt{if}$ guards, the following interleaving can violate the invariant $0 \\leq count \\leq N$ by causing underflow: initially $count = 0$, a consumer $C_1$ calls $\\texttt{get}$, sees $count = 0$, and executes $\\texttt{wait}(\\texttt{notEmpty})$; a producer $P$ calls $\\texttt{put}$, inserts one item so $count \\leftarrow 1$, and executes $\\texttt{signal}(\\texttt{notEmpty})$; before $C_1$ re-acquires the monitor, another consumer $C_2$ enters, removes the item so $count \\leftarrow 0$, and exits; then $C_1$ runs, does not re-check the condition (due to the one-time $\\texttt{if}$), removes from an empty buffer, making $count \\leftarrow -1$.**\n\nThis is the symmetric counterpart to the scenario in option E, demonstrating the potential for buffer underflow.\n1.  State: $count = 0$.\n2.  $C_1$ calls `get`, executes $\\texttt{wait}(\\texttt{notEmpty})$.\n3.  $P$ calls `put`, increments $count \\to 1$, calls $\\texttt{signal}(\\texttt{notEmpty})$. $C_1$ is now ready but without the lock. $P$ exits.\n4.  Monitor lock is free. A new consumer $C_2$ acquires the lock before the awakened $C_1$.\n5.  $C_2$ finds $count = 1 > 0$, so it removes an item, decrements $count \\to 0$, and exits.\n6.  $C_1$ now acquires the lock. It resumes execution *after* its `wait` call, without re-checking the condition due to the `if` guard.\n7.  $C_1$ proceeds to remove an item from the now-empty buffer, decrementing $count \\to -1$.\nThis sequence is valid under Mesa semantics and violates the invariant ($count \\geq 0$) by causing a buffer underflow.\n\n**Verdict: Correct.**", "answer": "$$\\boxed{ACEF}$$", "id": "3659620"}, {"introduction": "While basic monitors enforce exclusion on entry, some implementations allow a thread that already holds the monitor lock to re-enter, a feature known as recursivity or re-entrance. While this can simplify certain programming patterns, it introduces subtle complexities, particularly when interacting with condition variables. This practice challenges you to analyze a scenario involving a recursive monitor and identify a critical design flaw in the `wait` operation's implementation that leads to a catastrophic self-deadlock, demonstrating that convenience can sometimes hide dangerous pitfalls [@problem_id:3659623].", "problem": "An Operating System (OS) monitor is a high-level synchronization construct that enforces mutual exclusion on entry to monitor procedures and provides condition variables for waiting and signaling. Consider a monitor $M$ that uses a reentrant (recursive) lock $L$ and a condition variable $c$ with Mesa-style semantics. The semantics to be assumed as the fundamental base are: mutual exclusion on monitor entry, condition variable wait that atomically releases the monitor lock and suspends the caller, condition variable signal that wakes one waiting thread, and re-acquisition of the lock by the waking thread before it returns from wait. In a reentrant lock, each successful entry increments a recursion count $r$ and each exit decrements $r$; the lock is free only when $r = 0$.\n\nSuppose $M$ implements a bounded buffer with procedures $put$ and $get$. A wrapper procedure $wrapGet$ invokes $get$ from within the monitor. The intended interactions are:\n\n- $wrapGet$: enter $M$, perform some operation unrelated to the buffer, call $get$, exit $M$.\n- $get$: enter $M$, if buffer is empty, call $wait(c)$, else remove and return one item.\n\nAssume the following sequence by a thread $T$: $T$ calls $wrapGet$, which enters $M$ and increments $r$ to $1$, then $wrapGet$ calls $get$, which recursively re-enters $M$ and increments $r$ to $2$. Inside $get$, the buffer is empty, so $wait(c)$ is invoked.\n\nWhich of the following statements correctly identifies a case that leads to a self-deadlock for $T$ due to the combination of monitor recursion and condition variables?\n\nA. If $wait(c)$ releases only one level of the recursive lock by decrementing $r$ from $2$ to $1$, then $T$ remains blocked while still holding $M$ at $r  0$, preventing any other thread from entering $M$ to execute a matching $put$ and $signal(c)$; this causes self-deadlock.\n\nB. If $wait(c)$ fully releases the recursive lock by atomically setting $r$ to $0$ and later re-acquires $L$ before returning, then the wrapper call is safe under Mesa semantics and cannot cause self-deadlock in this scenario.\n\nC. Under Hoare-style monitor semantics, immediate transfer upon $signal(c)$ ensures that even if $wait(c)$ releases only one level (leaving $r = 1$), the wrapper is safe and self-deadlock cannot occur.\n\nD. Broadcasting on $c$ from outside $M$ avoids deadlock because signaling and broadcasting on condition variables do not require holding the monitor lock $L$ in any correct monitor design.", "solution": "This problem describes a classic and subtle deadlock scenario arising from the interaction between reentrant locks and condition variables. The setup is plausible and highlights a critical implementation detail in concurrent systems.\n\nA reentrant (or recursive) lock allows a thread that already holds the lock to acquire it again without deadlocking. It does this by maintaining a *recursion count* ($r$) and an *owner thread* identifier.\n- When a thread acquires the lock for the first time, it becomes the owner and the count is set to $1$.\n- Each subsequent acquisition by the same thread increments the count ($r \\to r+1$).\n- Each release (exit) by the owner thread decrements the count ($r \\to r-1$).\n- The lock is only truly released (and made available to other threads) when the count drops to $0$.\n\nThe `wait(c)` operation on a condition variable must atomically release the monitor lock and put the calling thread to sleep. The ambiguity arises in what \"release the monitor lock\" means when the lock is reentrant and the recursion count $r > 1$.\n- **Incorrect Implementation:** If `wait(c)` only decrements the recursion count by one (e.g., from $r=2$ to $r=1$), the calling thread goes to sleep, but it still legally owns the lock. No other thread can acquire the lock because it is not free ($r \\neq 0$). This prevents any other thread from entering the monitor to change the state and signal the condition variable. The waiting thread will never be awakened. This is a self-deadlock.\n- **Correct Implementation:** A correct implementation of `wait(c)` must release the lock *completely*. It should atomically save the current recursion count, set the count to $0$ (making the lock free for others), and then go to sleep. When the thread is awakened and re-acquires the lock, the implementation must restore the original recursion count.\n\nIn the scenario provided, thread $T$ enters monitor $M$ via `wrapGet` (incrementing $r$ to $1$), then calls `get` recursively (incrementing $r$ to $2$), and finally calls `wait(c)`.\n\n**A. If $wait(c)$ releases only one level of the recursive lock by decrementing $r$ from $2$ to $1$, then $T$ remains blocked while still holding $M$ at $r  0$, preventing any other thread from entering $M$ to execute a matching $put$ and $signal(c)$; this causes self-deadlock.**\nThis statement accurately describes the incorrect implementation. By only decrementing $r$ to $1$, thread $T$ goes to sleep while still owning the lock. No other thread (like a producer) can enter the monitor to perform the `put` and `signal` that $T$ is waiting for. This is the definition of a deadlock. This statement is correct.\n\n**B. If $wait(c)$ fully releases the recursive lock by atomically setting $r$ to $0$ and later re-acquires $L$ before returning, then the wrapper call is safe under Mesa semantics and cannot cause self-deadlock in this scenario.**\nThis statement describes the correct implementation. If the lock is fully released ($r \\to 0$), other threads can enter the monitor, and the system can proceed. This implementation avoids the self-deadlock. The statement correctly describes a safe implementation, but the question asks to identify the case that *leads* to deadlock.\n\n**C. Under Hoare-style monitor semantics, immediate transfer upon $signal(c)$ ensures that even if $wait(c)$ releases only one level (leaving $r = 1$), the wrapper is safe and self-deadlock cannot occur.**\nThis is incorrect. Hoare semantics affect what happens *after* a signal, dictating a direct transfer of control. They do not change the fundamental requirement that the lock must be released for a signaling thread to be able to enter the monitor in the first place. If the waiting thread still holds the lock ($r=1$), no other thread can get in to execute the `signal`. The system is still deadlocked before any signal can even happen.\n\n**D. Broadcasting on $c$ from outside $M$ avoids deadlock because signaling and broadcasting on condition variables do not require holding the monitor lock $L$ in any correct monitor design.**\nThis statement is fundamentally false. Signaling or broadcasting on a condition variable *must* be done while holding the monitor lock. This is to prevent a race condition where a thread checks a condition, decides to wait, but before it can execute `wait`, another thread changes the state and signals. The signal would be lost, and the first thread would wait indefinitely. Therefore, signaling from outside the monitor is incorrect and unsafe.\n\nThe only statement that correctly identifies a scenario leading to self-deadlock is A.", "answer": "$$\\boxed{A}$$", "id": "3659623"}, {"introduction": "Monitors are not only for ensuring logical correctness but also for building predictable, high-performance systems. In real-time operating systems, timeliness is paramount, and a notorious problem called \"priority inversion\" can shatter all timing guarantees. This hands-on simulation will guide you through a quantitative analysis of how a low-priority thread holding a monitor lock can indefinitely block a high-priority thread, and then demonstrate how augmenting the monitor with a Priority Ceiling Protocol elegantly solves this issue, restoring predictability to the system [@problem_id:3659607].", "problem": "You are to design and implement a deterministic discrete-event simulator that models a monitor with a condition variable under fixed-priority preemptive scheduling, and then integrate a priority ceiling protocol into the monitor. The objective is to compute, for several scenarios, the blocking duration experienced by a high-priority thread while it waits on a condition inside the monitor, comparing the baseline monitor (no priority ceiling) against a monitor with a priority ceiling. The result must show, in numeric terms, how the priority ceiling prevents priority inversion during the condition wait.\n\nFundamental base and definitions to be used:\n\n- A monitor provides mutual exclusion: at most one thread may execute inside the monitor at a time. Threads enter the monitor to execute critical sections atomically. A condition variable inside the monitor supports wait and signal. In a wait, the calling thread releases the monitor lock and blocks until signaled; in a signal, a waiting thread is marked ready to run and may later re-acquire the monitor lock when it becomes available.\n- Fixed-priority preemptive scheduling: At any time, the scheduler runs the single ready thread with the numerically highest base priority. If a thread with strictly higher priority than the currently running thread becomes ready, it preempts immediately. For ties, assume no preemption is induced by the arrival; the currently running thread continues until completion or a strictly higher-priority arrival.\n- Priority ceiling protocol for monitors: Each monitor has a ceiling equal to the maximum base priority of any thread that may enter that monitor. When a thread enters the monitor, its effective priority is raised to the maximum of its base priority and the monitor’s ceiling. The effective priority remains elevated while the thread holds the monitor. This prevents medium-priority threads from preempting a lower-priority thread that holds the monitor if the ceiling exceeds the medium-priority thread’s base priority.\n\nScenario model:\n\n- There are three threads: a high-priority thread $H$, a medium-priority thread $M$, and a low-priority thread $L$ with base priorities $p_H$, $p_M$, and $p_L$ respectively, where larger numbers mean higher priority.\n- Time is modeled in discrete integer units. At time $t = 0$, thread $H$ enters the monitor, finds a condition false, and calls wait, releasing the monitor and blocking. Thread $L$ then enters the monitor to perform work that will satisfy the condition; its required work takes $d_L$ time units inside the monitor. Thread $M$ performs unrelated work outside the monitor for $d_M$ time units and becomes ready at time $t_M$. The scheduler always runs the ready thread with the numerically highest priority (for baseline: base priority; for priority-ceiling monitor: effective priority while holding the monitor).\n- Under the baseline monitor (no priority ceiling), $L$ runs inside the monitor but may be preempted by $M$ if $M$ arrives before $L$ completes and $p_M  p_L$. Under the priority-ceiling monitor, $L$’s effective priority while holding the monitor becomes $\\max(p_L, p_H)$, so $M$ can only preempt if $p_M  \\max(p_L, p_H)$ while $L$ still has remaining work. When $L$ completes its monitor work, it signals the condition; this makes $H$ ready to re-acquire the monitor. Assume $H$ re-acquires immediately after $L$ exits the monitor; thus, the blocking duration for $H$ is the total time elapsed from $t = 0$ until $L$ completes its monitor work and the monitor becomes available again.\n\nRequired computation:\n\n- For each scenario, compute two quantities:\n  1. The high-priority thread’s blocking duration under the baseline monitor, denoted $B_{\\text{base}}$.\n  2. The high-priority thread’s blocking duration under the priority-ceiling monitor, denoted $B_{\\text{ceil}}$.\n\nFrom the above definitions, you must derive and implement the following deterministic rules:\n\n- Baseline preemption rule: If $t_M  d_L$ and $p_M  p_L$, then $M$ preempts $L$ upon arrival and runs for $d_M$ time units before $L$ resumes. Therefore, $B_{\\text{base}} = d_L + d_M$ in that case; otherwise $B_{\\text{base}} = d_L$.\n- Priority-ceiling preemption rule: The monitor ceiling is $C = \\max(p_H, p_L)$. While $L$ holds the monitor, its effective priority is $p^{\\text{eff}}_L = C$. If $t_M  d_L$ and $p_M  p^{\\text{eff}}_L$, then $M$ preempts; otherwise, no preemption occurs. Therefore, $B_{\\text{ceil}} = d_L + d_M$ only in the rare case $p_M  \\max(p_H, p_L)$ with $t_M  d_L$; otherwise $B_{\\text{ceil}} = d_L$.\n\nTest suite and parameters:\n\nUse the following four scenarios; each must be computed independently:\n\n- Scenario $1$: $p_H = 9$, $p_M = 7$, $p_L = 3$, $d_L = 5$, $d_M = 7$, $t_M = 1$.\n- Scenario $2$: $p_H = 8$, $p_M = 6$, $p_L = 2$, $d_L = 6$, $d_M = 3$, $t_M = 8$.\n- Scenario $3$: $p_H = 10$, $p_M = 9$, $p_L = 1$, $d_L = 0$, $d_M = 100$, $t_M = 1$.\n- Scenario $4$: $p_H = 4$, $p_M = 2$, $p_L = 2$, $d_L = 10$, $d_M = 20$, $t_M = 3$.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order, the pair $(B_{\\text{base}}, B_{\\text{ceil}})$ for Scenario $1$, followed by the pair for Scenario $2$, Scenario $3$, and Scenario $4$. That is, the output must be of the form\n$[B_{\\text{base},1},B_{\\text{ceil},1},B_{\\text{base},2},B_{\\text{ceil},2},B_{\\text{base},3},B_{\\text{ceil},3},B_{\\text{base},4},B_{\\text{ceil},4}]$,\nwhere each $B$ is an integer time unit.", "solution": "The problem requires the design and implementation of a calculation based on a deterministic discrete-event simulation model. The objective is to quantify the blocking duration experienced by a high-priority thread, $H$, under two different monitor implementations: a baseline monitor and a monitor augmented with a priority ceiling protocol. The blocking is caused by a lower-priority thread, $L$, holding a monitor lock that $H$ requires. A medium-priority thread, $M$, may introduce further delay through preemption, a phenomenon known as priority inversion.\n\nThe analysis proceeds by deriving the blocking duration from first principles for each case and then applying these derived formulas to the specific scenarios provided.\n\n**1. System Model and Definitions**\n\nThe system consists of three threads: high-priority $H$, medium-priority $M$, and low-priority $L$, with corresponding base priorities $p_H$, $p_M$, and $p_L$. A higher numerical value implies a higher priority. The scheduling is fixed-priority and preemptive, meaning the ready thread with the strictly highest priority always runs.\n\nAt time $t=0$, thread $H$ attempts to enter a monitor but finds a required condition to be false, causing it to execute a `wait()` operation. This action releases the monitor's mutual exclusion lock and blocks thread $H$. Subsequently, thread $L$ enters the monitor to perform work that will eventually satisfy $H$'s condition. This work requires $d_L$ time units of execution within the monitor.\n\nAn independent thread, $M$, becomes ready to run at time $t_M$ and requires $d_M$ time units of CPU time for its task, which is performed outside the monitor.\n\nThe blocking duration for thread $H$ is defined as the total time elapsed from $t=0$ until thread $L$ completes its work inside the monitor and signals $H$. This duration is contingent on whether thread $M$ can preempt thread $L$.\n\n**2. Analysis of the Baseline Monitor (No Priority Ceiling)**\n\nIn the baseline scenario, threads are scheduled based on their fixed base priorities. Thread $L$ executes inside the monitor with its base priority, $p_L$.\n\nPreemption of $L$ by $M$ can occur under two specific conditions:\n1.  Thread $M$ must become ready while thread $L$ is still executing its critical section. The time required for $L$ to complete its work without preemption is $d_L$. Therefore, $M$ must arrive at a time $t_M  d_L$.\n2.  For the scheduler to preempt $L$ in favor of $M$, $M$'s priority must be strictly greater than $L$'s priority. That is, $p_M  p_L$. The problem specifies that for priority ties, the incumbent thread continues execution.\n\nIf both conditions ($t_M  d_L$ and $p_M  p_L$) are met, thread $M$ preempts thread $L$ at time $t_M$. Thread $M$ runs to completion, consuming $d_M$ time units. Afterward, thread $L$ resumes and completes its remaining work. The total time for $L$ to finish its monitor work is its own execution time, $d_L$, plus the time it was delayed by preemption, $d_M$.\n\nTherefore, the blocking duration for thread $H$ in the baseline case, $B_{\\text{base}}$, is given by:\n$$\nB_{\\text{base}} =\n\\begin{cases}\nd_L + d_M  \\text{if } t_M  d_L \\text{ and } p_M  p_L \\\\\nd_L  \\text{otherwise}\n\\end{cases}\n$$\n\n**3. Analysis of the Monitor with Priority Ceiling Protocol**\n\nThe priority ceiling protocol is designed to prevent such priority inversion. The monitor is assigned a priority ceiling, $C$, equal to the maximum base priority of any thread that can enter it. In this model, threads $H$ and $L$ enter the monitor, so the ceiling is $C = \\max(p_H, p_L)$.\n\nAccording to the protocol, when a thread enters the monitor, its effective priority is raised to the maximum of its base priority and the monitor's ceiling. When thread $L$ holds the monitor lock, its effective priority, $p^{\\text{eff}}_L$, becomes:\n$$ p^{\\text{eff}}_L = \\max(p_L, C) = \\max(p_L, \\max(p_H, p_L)) = \\max(p_H, p_L) $$\nThis priority elevation is maintained as long as $L$ is inside the monitor.\n\nPreemption of $L$ by $M$ now depends on $M$'s priority relative to $L$'s *effective* priority. The conditions for preemption are:\n1.  Thread $M$ must become ready while thread $L$ is still executing: $t_M  d_L$.\n2.  Thread $M$'s priority must be strictly greater than $L$'s effective priority: $p_M  p^{\\text{eff}}_L$, which is $p_M  \\max(p_H, p_L)$.\n\nIf both conditions are met, preemption occurs, and the blocking time includes the delay from $M$'s execution. The blocking duration for $H$ with the priority ceiling protocol, $B_{\\text{ceil}}$, is:\n$$\nB_{\\text{ceil}} =\n\\begin{cases}\nd_L + d_M  \\text{if } t_M  d_L \\text{ and } p_M  \\max(p_H, p_L) \\\\\nd_L  \\text{otherwise}\n\\end{cases}\n$$\nThis protocol effectively prevents preemption by any thread whose priority is not higher than that of the highest-priority thread that uses the monitor, thus bounding the blocking time.\n\n**4. Computation for Scenarios**\n\nThe derived formulas are now applied to the four specified scenarios.\n\n**Scenario 1:** $p_H=9, p_M=7, p_L=3, d_L=5, d_M=7, t_M=1$.\n- **Baseline ($B_{\\text{base}}$):**\n  - Condition $t_M  d_L$: $1  5$ is true.\n  - Condition $p_M  p_L$: $7  3$ is true.\n  - Both conditions are met. Preemption occurs.\n  - $B_{\\text{base}} = d_L + d_M = 5 + 7 = 12$.\n- **Priority Ceiling ($B_{\\text{ceil}}$):**\n  - Effective priority of $L$ is $\\max(p_H, p_L) = \\max(9, 3) = 9$.\n  - Condition $t_M  d_L$: $1  5$ is true.\n  - Condition $p_M  \\max(p_H, p_L)$: $7  9$ is false.\n  - No preemption occurs.\n  - $B_{\\text{ceil}} = d_L = 5$.\n- Result: $(12, 5)$\n\n**Scenario 2:** $p_H=8, p_M=6, p_L=2, d_L=6, d_M=3, t_M=8$.\n- **Baseline ($B_{\\text{base}}$):**\n  - Condition $t_M  d_L$: $8  6$ is false.\n  - Thread $M$ arrives after $L$ has finished. No preemption.\n  - $B_{\\text{base}} = d_L = 6$.\n- **Priority Ceiling ($B_{\\text{ceil}}$):**\n  - Condition $t_M  d_L$: $8  6$ is false.\n  - No preemption.\n  - $B_{\\text{ceil}} = d_L = 6$.\n- Result: $(6, 6)$\n\n**Scenario 3:** $p_H=10, p_M=9, p_L=1, d_L=0, d_M=100, t_M=1$.\n- **Baseline ($B_{\\text{base}}$):**\n  - The work duration $d_L = 0$.\n  - Condition $t_M  d_L$: $1  0$ is false.\n  - Thread $L$ completes its work instantaneously. No preemption is possible.\n  - $B_{\\text{base}} = d_L = 0$.\n- **Priority Ceiling ($B_{\\text{ceil}}$):**\n  - Condition $t_M  d_L$: $1  0$ is false.\n  - No preemption.\n  - $B_{\\text{ceil}} = d_L = 0$.\n- Result: $(0, 0)$\n\n**Scenario 4:** $p_H=4, p_M=2, p_L=2, d_L=10, d_M=20, t_M=3$.\n- **Baseline ($B_{\\text{base}}$):**\n  - Condition $t_M  d_L$: $3  10$ is true.\n  - Condition $p_M  p_L$: $2  2$ is false (priorities are equal, no preemption).\n  - No preemption occurs.\n  - $B_{\\text{base}} = d_L = 10$.\n- **Priority Ceiling ($B_{\\text{ceil}}$):**\n  - Effective priority of $L$ is $\\max(p_H, p_L) = \\max(4, 2) = 4$.\n  - Condition $t_M  d_L$: $3  10$ is true.\n  - Condition $p_M  \\max(p_H, p_L)$: $2  4$ is false.\n  - No preemption occurs.\n  - $B_{\\text{ceil}} = d_L = 10$.\n- Result: $(10, 10)$\n\n**Summary of Results:**\n- Scenario 1: $(B_{\\text{base}}, B_{\\text{ceil}}) = (12, 5)$\n- Scenario 2: $(B_{\\text{base}}, B_{\\text{ceil}}) = (6, 6)$\n- Scenario 3: $(B_{\\text{base}}, B_{\\text{ceil}}) = (0, 0)$\n- Scenario 4: $(B_{\\text{base}}, B_{\\text{ceil}}) = (10, 10)$\n\nThe implementation will encode these calculations into a program that processes the test cases and formats the final results as specified.", "answer": "```c\n// The problem requires specific headers. The problem is a deterministic calculation,\n// so threading and complex number headers are not functionally necessary.\n#include stdio.h\n#include stdlib.h\n#include string.h // Not strictly necessary, but allowed.\n#include math.h   // Not strictly necessary, but allowed.\n\n// This program simulates thread blocking time under two scheduling scenarios,\n// as defined by a deterministic model of priority-based preemption.\n\n/**\n * @brief A structure to hold the parameters for a single test scenario.\n *\n * This struct contains the base priorities for the high, medium, and low-priority\n * threads (pH, pM, pL), the execution durations for the low and medium-priority\n * threads (dL, dM), and the arrival time of the medium-priority thread (tM).\n */\ntypedef struct {\n    int pH;\n    int pM;\n    int pL;\n    int dL;\n    int dM;\n    int tM;\n} TestCase;\n\n/**\n * @brief Utility function to compute the maximum of two integers.\n * @param a The first integer.\n * @param b The second integer.\n * @return The greater of a and b.\n */\nstatic inline int max(int a, int b) {\n    return a  b ? a : b;\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        { .pH=9, .pM=7, .pL=3, .dL=5, .dM=7, .tM=1 },  // Scenario 1\n        { .pH=8, .pM=6, .pL=2, .dL=6, .dM=3, .tM=8 },  // Scenario 2\n        { .pH=10, .pM=9, .pL=1, .dL=0, .dM=100, .tM=1},// Scenario 3\n        { .pH=4, .pM=2, .pL=2, .dL=10, .dM=20, .tM=3}  // Scenario 4\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    // Allocate space for two integer results (B_base, B_ceil) per test case.\n    int results[num_cases * 2];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i  num_cases; ++i) {\n        TestCase tc = test_cases[i];\n        int b_base = 0;\n        int b_ceil = 0;\n\n        // Calculate B_base: blocking time under the baseline monitor.\n        // Preemption occurs if M arrives before L finishes AND M's priority is strictly higher.\n        if (tc.tM  tc.dL  tc.pM  tc.pL) {\n            b_base = tc.dL + tc.dM;\n        } else {\n            b_base = tc.dL;\n        }\n\n        // Calculate B_ceil: blocking time under the priority-ceiling monitor.\n        // The monitor's ceiling is the max priority of any thread that enters it (H and L).\n        int monitor_ceiling = max(tc.pH, tc.pL);\n        // Preemption occurs if M arrives before L finishes AND M's priority is strictly\n        // higher than L's effective priority (which is the ceiling).\n        if (tc.tM  tc.dL  tc.pM  monitor_ceiling) {\n            b_ceil = tc.dL + tc.dM;\n        } else {\n            b_ceil = tc.dL;\n        }\n\n        // Store the computed results.\n        results[i * 2] = b_base;\n        results[i * 2 + 1] = b_ceil;\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    // The format is a single line: [res1,res2,res3,...] with no trailing text or newline.\n    printf(\"[\");\n    for (int i = 0; i  num_cases * 2; ++i) {\n        printf(\"%d\", results[i]);\n        if (i  (num_cases * 2) - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3659607"}]}