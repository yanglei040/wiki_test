{"hands_on_practices": [{"introduction": "The efficiency of an inverted page table is fundamentally linked to the performance of its underlying hash table. To reason about this performance, we can model the system using probability theory. This first exercise [@problem_id:3651017] guides you through a foundational analysis, treating page table entries as 'balls' thrown into 'bins' (the hash buckets), to derive the expected number of empty buckets. This practice is crucial for understanding the relationship between system load, table size, and lookup efficiency, forming the basis for capacity planning and performance tuning.", "problem": "An operating system (OS) uses an Inverted Page Table (IPT) that is organized as a hash table with chaining. The table has $m$ buckets, and there are $n$ active page table entries. Each entry is hashed uniformly and independently into one of the $m$ buckets. The time to locate an entry in a bucket is proportional to the number of entries in that bucket, so bucket occupancy directly affects lookup performance.\n\nStarting from the definitions of probability, indicator random variables, and linearity of expectation, derive the exact expected fraction of buckets that are empty as a function of $m$ and $n$. Then, using a large-system approximation in which $m$ and $n$ are large while the load factor $\\alpha = n/m$ is held constant, derive the asymptotic form of the expected fraction of empty buckets. Finally, suppose the system aims to tune $m$ so that the expected fraction of empty buckets equals a target value $\\theta$ with $0 < \\theta < 1$. Using the asymptotic form, derive a closed-form expression for $m$ in terms of $n$ and $\\theta$.\n\nProvide your final answer as a row matrix with two entries: the first entry is the exact expected fraction of empty buckets as a function of $m$ and $n$, and the second entry is the asymptotic expression for $m$ in terms of $n$ and $\\theta$. No numerical approximation or rounding is required.", "solution": "The problem asks for three related derivations concerning the distribution of entries in an inverted page table, which is modeled as a hash table with chaining. We will address each part in sequence, starting from first principles as requested.\n\nThe setup is a classic \"balls and bins\" problem in probability theory, where $n$ balls (page table entries) are thrown independently and uniformly at random into $m$ bins (buckets).\n\nFirst, we derive the exact expected fraction of empty buckets. Let $X$ be the random variable representing the total number of empty buckets. We want to find the expected fraction, which is $\\frac{E[X]}{m}$. To calculate $E[X]$, we use the method of indicator random variables.\n\nLet $X_i$ be an indicator random variable for the event that bucket $i$ is empty, for $i \\in \\{1, 2, \\dots, m\\}$. By definition:\n$$\nX_i =\n\\begin{cases}\n1 & \\text{if bucket } i \\text{ is empty} \\\\\n0 & \\text{if bucket } i \\text{ is not empty}\n\\end{cases}\n$$\nThe total number of empty buckets is the sum of these indicator variables:\n$$X = \\sum_{i=1}^{m} X_i$$\nBy the linearity of expectation, the expected number of empty buckets is the sum of the expected values of the indicator variables:\n$$E[X] = E\\left[\\sum_{i=1}^{m} X_i\\right] = \\sum_{i=1}^{m} E[X_i]$$\nThe expectation of an indicator random variable is equal to the probability of the event it indicates. Therefore, $E[X_i] = P(\\text{bucket } i \\text{ is empty})$.\n\nLet's calculate this probability. Consider a single page table entry. Since hashing is uniform, the probability that this entry is hashed to any specific bucket $i$ is $\\frac{1}{m}$. Consequently, the probability that this entry is *not* hashed to bucket $i$ is $1 - \\frac{1}{m} = \\frac{m-1}{m}$.\n\nThere are $n$ entries in total, and their hash locations are independent. The event \"bucket $i$ is empty\" occurs if and only if none of the $n$ entries are hashed to bucket $i$. The probability of this compound event is the product of the individual probabilities for each entry:\n$$P(\\text{bucket } i \\text{ is empty}) = \\left(\\frac{m-1}{m}\\right) \\times \\left(\\frac{m-1}{m}\\right) \\times \\dots \\times \\left(\\frac{m-1}{m}\\right) \\quad (n \\text{ times})$$\n$$P(\\text{bucket } i \\text{ is empty}) = \\left(\\frac{m-1}{m}\\right)^n = \\left(1 - \\frac{1}{m}\\right)^n$$\nSo, for any bucket $i$, we have $E[X_i] = \\left(1 - \\frac{1}{m}\\right)^n$.\n\nNow, we can find the expected total number of empty buckets:\n$$E[X] = \\sum_{i=1}^{m} \\left(1 - \\frac{1}{m}\\right)^n = m \\left(1 - \\frac{1}{m}\\right)^n$$\nThe expected fraction of empty buckets is $\\frac{E[X]}{m}$:\n$$\\text{Expected Fraction} = \\frac{m \\left(1 - \\frac{1}{m}\\right)^n}{m} = \\left(1 - \\frac{1}{m}\\right)^n$$\nThis is the first required result.\n\nSecond, we derive the asymptotic form of this fraction in a large-system limit where $m \\to \\infty$ and $n \\to \\infty$ such that the load factor $\\alpha = \\frac{n}{m}$ remains constant. We substitute $n = \\alpha m$ into the expression for the fraction:\n$$\\left(1 - \\frac{1}{m}\\right)^n = \\left(1 - \\frac{1}{m}\\right)^{\\alpha m}$$\nWe evaluate the limit as $m \\to \\infty$:\n$$\\lim_{m \\to \\infty} \\left(1 - \\frac{1}{m}\\right)^{\\alpha m} = \\lim_{m \\to \\infty} \\left[ \\left(1 + \\frac{-1}{m}\\right)^m \\right]^{\\alpha}$$\nWe use the fundamental limit definition of the exponential function, $\\lim_{x \\to \\infty} \\left(1 + \\frac{k}{x}\\right)^x = \\exp(k)$. Here, $x=m$ and $k=-1$.\n$$\\lim_{m \\to \\infty} \\left(1 + \\frac{-1}{m}\\right)^m = \\exp(-1)$$\nTherefore, the asymptotic limit of the fraction is:\n$$\\left[\\exp(-1)\\right]^{\\alpha} = \\exp(-\\alpha) = \\exp\\left(-\\frac{n}{m}\\right)$$\nThe asymptotic form of the expected fraction of empty buckets is $\\exp\\left(-\\frac{n}{m}\\right)$.\n\nThird, we use this asymptotic form to derive an expression for $m$ in terms of $n$ and a target expected fraction of empty buckets, $\\theta$, where $0 < \\theta < 1$. We set the asymptotic fraction equal to $\\theta$:\n$$\\exp\\left(-\\frac{n}{m}\\right) = \\theta$$\nTo solve for $m$, we take the natural logarithm of both sides:\n$$\\ln\\left(\\exp\\left(-\\frac{n}{m}\\right)\\right) = \\ln(\\theta)$$\n$$-\\frac{n}{m} = \\ln(\\theta)$$\nSince $0 < \\theta < 1$, its logarithm $\\ln(\\theta)$ is a non-zero negative number. We can now solve for $m$:\n$$m = -\\frac{n}{\\ln(\\theta)}$$\nThis can also be written as $m = \\frac{n}{\\ln(1/\\theta)}$. The expression is well-defined and positive, as required for a number of buckets. This is the second required result.\n\nThe final answer will be a row matrix containing the exact expected fraction and the derived expression for $m$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\left(1 - \\frac{1}{m}\\right)^n & -\\frac{n}{\\ln(\\theta)}\n\\end{pmatrix}\n}\n$$", "id": "3651017"}, {"introduction": "Our first practice assumed an ideal hash function that distributes entries uniformly. However, the performance guarantees of a hash table can catastrophically fail if the hash function is poorly chosen. This exercise [@problem_id:3651073] presents a hypothetical but illustrative scenario where the hash function depends only on the Process ID, leading to massive collisions. By analyzing this degenerate case, you will see how a simple design flaw can transform an efficient $O(1)$ lookup into a costly $O(n)$ linear search, underscoring the critical importance of hash function quality in system design.", "problem": "A system implements an inverted page table (IPT) that stores exactly one entry per physical frame. A lookup for a virtual address uses a hash-based index into a table of $B$ buckets and resolves collisions by separate chaining. The key for hashing is the ordered pair $\\left(PID, VPN\\right)$, where $PID$ is the Process Identifier (PID) and $VPN$ is the Virtual Page Number (VPN). The system designer mistakenly deploys the poor hash function $h\\left(PID, VPN\\right) = PID \\bmod B$. Let there be $n$ occupied IPT entries at some instant, where $n \\leq B$ is not guaranteed and a single process may occupy multiple frames. Assume no auxiliary acceleration structures such as a Translation Lookaside Buffer (TLB); lookups traverse the chain in a bucket by comparing both $PID$ and $VPN$ fields for equality at each node.\n\nStarting only from the definitions of the inverted page table, hashing with separate chaining, and equality-based key comparison, do the following:\n\n- Derive a necessary and sufficient condition on the set of occupied entries $\\left\\{\\left(PID_{j}, VPN_{j}\\right)\\right\\}_{j=1}^{n}$ and the bucket count $B$ under which all $n$ entries collide into a single bucket when using $h\\left(PID, VPN\\right) = PID \\bmod B$. Your derivation must identify the precise predicate that characterizes this degeneracy.\n- Under that degeneracy, determine the worst-case number of key comparisons performed by a single lookup (whether successful or unsuccessful) as a function of $n$.\n\nProvide only the expression for the worst-case number of comparisons as your final answer, in closed form with no units. If you choose to simplify, do so exactly; no rounding is required.", "solution": "The problem requires a two-part analysis of a hash-based inverted page table with a flawed hash function.\n\n### Part 1: Condition for Maximum Collision\n\nThe hash table has $B$ buckets, and the hash function is $h(PID, VPN) = PID \\bmod B$. All $n$ entries, $\\{(PID_j, VPN_j)\\}_{j=1}^{n}$, collide into a single bucket if and only if they all hash to the same bucket index. Let this common bucket index be some integer $k$, where $0 \\leq k < B$.\n\nFor this to occur, the hash function must produce the same output $k$ for all $n$ entries:\n$$h(PID_j, VPN_j) = k \\quad \\text{for all } j \\in \\{1, 2, \\dots, n\\}$$\n\nSubstituting the definition of the given hash function, we have:\n$$PID_j \\bmod B = k \\quad \\text{for all } j \\in \\{1, 2, \\dots, n\\}$$\n\nThis means that every Process Identifier $PID_j$ in the set of occupied entries must have the same remainder $k$ when divided by $B$. This is the definition of congruence modulo $B$.\n\nTherefore, the necessary and sufficient condition is:\n**There must exist an integer $k \\in \\{0, 1, \\dots, B-1\\}$ such that for all occupied entries $(PID_j, VPN_j)$, the process identifier $PID_j$ satisfies the congruence relation $PID_j \\equiv k \\pmod{B}$.** In other words, all PIDs associated with the $n$ occupied entries must belong to the same congruence class modulo $B$.\n\n### Part 2: Worst-Case Number of Key Comparisons\n\nUnder the degeneracy condition derived above, all $n$ occupied entries are stored in a single linked list (a chain) attached to one bucket. The length of this chain is $n$.\n\nA lookup for a target key $(PID_{target}, VPN_{target})$ proceeds by first computing the bucket index and then traversing the corresponding linked list. During traversal, the stored key at each node is compared against the target key. A single \"key comparison\" involves checking if both the PID and VPN match.\n\nWe must determine the worst-case number of comparisons for any single lookup, whether it is successful or unsuccessful.\n\n**Case A: Successful Lookup**\nA successful lookup finds the target key in the chain. The worst case for a search in a linked list occurs when the target element is the last one in the list. To find it, the algorithm must traverse the entire list, performing a key comparison at each of the $n$ nodes. The first $n-1$ comparisons will fail, and the final comparison at the $n$-th node will succeed. This requires a total of $n$ key comparisons.\n\n**Case B: Unsuccessful Lookup**\nAn unsuccessful lookup occurs when the target key is not present in the IPT. The worst case for an unsuccessful lookup happens when the search is directed to the most populated bucket (the one with the chain of length $n$) and the key is not in that chain. For the lookup to be directed to this chain, the target PID must satisfy $PID_{target} \\bmod B = k$. The algorithm will then traverse the entire linked list of length $n$, performing a key comparison at each of the $n$ nodes. Since the key is not present, all $n$ comparisons will fail. After checking all $n$ entries and reaching the end of the list, the search terminates. This requires a total of $n$ key comparisons.\n\n**Conclusion**\nThe worst-case number of comparisons for a successful lookup is $n$. The worst-case number of comparisons for an unsuccessful lookup is also $n$. Therefore, the overall worst-case number of key comparisons for any single lookup is $n$.", "answer": "$$\\boxed{n}$$", "id": "3651073"}, {"introduction": "Beyond accidental design flaws, modern systems must also defend against malicious adversaries who intentionally trigger worst-case performance. This practice [@problem_id:3651027] explores the security dimension of inverted page tables, contrasting a vulnerable, public hash function with a robust, salted hash function from a universal family. By evaluating the feasibility of a collision-based denial-of-service attack, you will gain insight into cryptographic defenses against algorithmic complexity attacks and learn to reason about residual risks that persist even in a secured system.", "problem": "A system implements an inverted page table (IPT), which stores exactly one entry per physical frame. For address translation, the Operating System (OS) computes a bucket index in a hash table of size $M$ using a hash of the Process Identifier (PID) and the Virtual Page Number (VPN). Collisions are resolved by separate chaining, so the per-lookup cost is proportional to the length of the corresponding bucketâ€™s chain plus constant overhead. Assume the Translation Lookaside Buffer (TLB) covers only a subset of working-set translations and that misses must consult the IPT.\n\nFundamental base assumptions:\n- An inverted page table stores one record per physical frame: $\\langle PID, VPN, \\text{frame metadata} \\rangle$. \n- Under uniform hashing with separate chaining and $K$ keys distributed over $M$ buckets, the load factor is $\\alpha = K/M$ and the expected chain length in a bucket is $\\alpha$. Expected-time lookup is $O(1 + \\alpha)$.\n- A deterministic, public, unsalted hash $h(PID, VPN)$ allows an input-selecting adversary to choose inputs to target specific buckets if preimages can be found cheaply. Introducing a secret per-boot salt $s$ to obtain $h(PID, VPN, s)$ from a $2$-universal family makes bucket assignment of attacker-chosen inputs indistinguishable from random to an adversary that does not know $s$.\n\nConsider the following concrete scenario. The hash table has $M = 2^{20}$ buckets, and collisions are resolved with singly linked lists. The OS caps any single process to at most $K_{\\max} = 2^{18}$ resident pages. A malicious process aims to degrade translation latency by forcing many of its mappings to collide into the same bucket.\n\nTwo configurations are considered:\n\n- Unsalted: the system uses a fixed, public, deterministic function $h(PID, VPN)$.\n- Salted: at each boot, the OS draws a secret $k$-bit salt $s$ uniformly at random (with $k = 64$) and uses $h(PID, VPN, s)$ from a $2$-universal family. The attacker does not know $s$ and cannot directly observe bucket indices; it can only measure its own access latencies.\n\nSelect all statements that are true about the attack feasibility and defenses in this setting:\n\nA. If the system uses the unsalted $h(PID, VPN)$ and it is publicly known and efficiently computable, then for a given $PID$ the adversary can select $K \\le K_{\\max}$ distinct $VPN$ values that map to the same bucket, forcing a chain of length $\\Theta(K)$ and making its own TLB-miss translation cost grow on the order of $K$.\n\nB. With a secret per-boot salt $s$ of $k = 64$ bits and a $2$-universal hash family, an adversary that does not know $s$ cannot bias bucket occupancy beyond random; for its $K \\le K_{\\max}$ pages, the expected chain length it contributes to any bucket is approximately $\\alpha = K/M$, so its expected lookup time remains $O(1)$.\n\nC. Even with a secret salt, the adversary can, by adaptively timing its own accesses, reconstruct the exact salt $s$ in $O(\\log M)$ probes and thereby deterministically create long single-bucket chains within a single boot.\n\nD. Even with salting that enforces uniform hashing, residual risk persists: as the system-wide load factor $\\alpha_{\\text{sys}}$ approaches $1$ or higher due to overall memory pressure, the tail of the chain-length distribution grows and increases worst-case and tail latencies; countermeasures such as limiting per-bucket chain length with an overflow area or a secondary table, or applying move-to-front heuristics, can reduce these tails.\n\nE. Switching to open addressing with probing eliminates the need for any salt because an attacker cannot induce primary clustering without knowing $s$, so the worst-case lookup time becomes a small constant independent of the load factor $\\alpha$.\n\nAssume realistic constant-factor effects from cache behavior, pointer chasing, and TLB behavior, but base your answer on the formal properties above. Provide no extraneous assumptions beyond those stated.", "solution": "This problem requires an analysis of the security and performance of a hash-based inverted page table under two scenarios: one with a vulnerable (unsalted) hash function and one with a robust (salted) hash function.\n\n**Analysis of Option A:**\nThis statement describes a collision attack on an unsalted, public hash function.\n- **Feasibility:** If the hash function $h(PID, VPN)$ is public and deterministic, an adversary knows its own $PID$ and can compute the hash for any $VPN$ it chooses. To force collisions, the adversary selects a target bucket index $b_0$ and then iterates through different $VPN$ values until it finds $K$ values ($VPN_1, \\dots, VPN_K$) such that $h(PID, VPN_i) = b_0$ for all $i$. This is a pre-image attack on a specific bucket, which is feasible for non-cryptographic hashes.\n- **Impact:** By requesting memory mappings for these $K$ virtual pages, the adversary forces the OS to create $K$ entries in the IPT, all of which are placed in the chain for bucket $b_0$. A TLB miss for any of these pages will require traversing this chain. The cost is proportional to the chain's length, which is $K$. Thus, the translation cost for the attacker's own pages becomes $\\Theta(K)$, a significant degradation from the desired $O(1)$ performance.\n- **Conclusion:** Statement A is **Correct**.\n\n**Analysis of Option B:**\nThis statement assesses the effectiveness of a salted, universal hash function.\n- **Mechanism:** A secret salt $s$ makes the hash function $h(PID, VPN, s)$ unpredictable to an adversary who does not know $s$. The properties of a 2-universal family guarantee that the probability of any two distinct inputs colliding is no more than $1/M$, which is the same as for a truly random function.\n- **Impact:** The adversary cannot choose $VPN$s that are guaranteed to collide. From its perspective, each of its $K$ pages is mapped to a bucket chosen uniformly at random. The expected number of pages from the adversary that land in any given bucket is $K/M$. Given $K \\le K_{\\max} = 2^{18}$ and $M = 2^{20}$, this is at most $2^{18}/2^{20} = 0.25$. As long as the overall system load factor is reasonable, the expected lookup time remains $O(1)$. The salt effectively neutralizes the targeted attack.\n- **Conclusion:** Statement B is **Correct**.\n\n**Analysis of Option C:**\nThis statement claims a timing side-channel attack can efficiently recover the secret salt.\n- **Attack:** The attacker can measure access latencies to infer information about collisions. For example, if mapping a new page increases the access time for an existing page, a collision is likely.\n- **Feasibility:** While such timing attacks are theoretically possible, the claim that a 64-bit salt can be recovered in $O(\\log M) \\approx O(20)$ probes is highly implausible. Each timing measurement is a noisy, low-bandwidth signal (e.g., \"the chain is short\" or \"the chain is long\"). Extracting 64 bits of a secret key from ~20 such noisy signals is generally considered cryptanalytically infeasible for a well-designed universal hash family. It would require an astronomical number of carefully chosen probes and sophisticated analysis.\n- **Conclusion:** Statement C is **Incorrect**.\n\n**Analysis of Option D:**\nThis statement describes the \"residual risk\" that persists even with perfect hashing.\n- **Mechanism:** Salting prevents *adversarial* worst-cases but not *stochastic* ones. Even with a perfectly uniform hash function, the distribution of keys into buckets (the \"balls and bins\" problem) results in some buckets having longer chains than average purely by chance. For a hash table with load factor $\\alpha$, the chain lengths follow a Poisson distribution. As the system-wide load factor $\\alpha_{\\text{sys}}$ increases, the mean and variance of this distribution increase, making long chains more probable.\n- **Impact:** This leads to high tail latency for some lookups, which can be detrimental to performance-sensitive applications. The statement correctly identifies this risk and lists standard countermeasures: limiting chain length with overflow areas, using secondary hashing schemes, and applying access-pattern-based optimizations like move-to-front.\n- **Conclusion:** Statement D is **Correct**.\n\n**Analysis of Option E:**\nThis statement proposes open addressing as a salt-free solution with constant-time performance.\n- **Security:** This is incorrect. Open addressing relies on an initial hash to find the first probe slot. If this hash is a public, unsalted function, an attacker can still choose multiple keys that hash to the same initial slot. This causes \"primary clustering\" and long probe sequences, leading to a denial-of-service attack similar to the one against separate chaining. A salt is still necessary to prevent this.\n- **Performance:** This is also incorrect. The performance of all standard open addressing schemes is highly dependent on the load factor $\\alpha$. As $\\alpha$ approaches 1, the expected number of probes for a lookup grows dramatically and approaches infinity. It is not a \"small constant independent of the load factor\".\n- **Conclusion:** Statement E is **Incorrect** on both its security and performance claims.\n\nFinal selection is A, B, and D.", "answer": "$$\\boxed{ABD}$$", "id": "3651027"}]}