{"hands_on_practices": [{"introduction": "Understanding the performance of a hashed page table begins with analyzing how it handles collisions. This first exercise [@problem_id:3651107] challenges you to derive the expected lookup costs for two fundamental collision resolution strategies: linear probing and separate chaining, under the ideal uniform hashing assumption. By expressing performance as a function of the load factor $\\alpha$, you will build a quantitative foundation for evaluating these crucial design choices.", "problem": "An operating system (OS) implements a Hashed Inverted Page Table (IPT) to translate a pair consisting of a process identifier and a virtual page number into a physical frame number. The IPT is stored in main memory and is organized either as a single array with open addressing using linear probing, or as an array of buckets with separate chaining. Assume there are $m$ slots (for open addressing) or $m$ buckets (for chaining), and $n$ resident mappings (keys), with load factor $\\alpha = n/m \\in (0,1)$. Assume uniform hashing: the hash of each key is uniformly distributed in $\\{0, 1, \\dots, m-1\\}$, independent of other keys.\n\nDefine a single probe as one main-memory access that compares the sought key against a stored key in a table slot (open addressing) or a node in a chain (separate chaining), or that determines a slot is empty (open addressing) or a chain is exhausted (separate chaining). Ignore any constant-time overheads that do not read a key, and assume the Translation Lookaside Buffer (TLB) is a miss for the lookup, so the IPT is consulted.\n\nUnder these assumptions, and starting only from the core definitions of hashing, load factor, and uniform hashing, derive the expected number of probes $E[\\text{probes}]$ to complete a single lookup in the IPT, expressed as closed-form functions of $\\alpha$, for the following four cases:\n- successful lookup with linear probing (the page is present),\n- unsuccessful lookup with linear probing (the page is absent),\n- successful lookup with separate chaining,\n- unsuccessful lookup with separate chaining.\n\nYour derivation should begin from the definitions and basic probabilistic reasoning about occupancy and should not assume any final performance formula. Express your final results as a row matrix in the order\n$[E_{\\text{lin, succ}} \\; E_{\\text{lin, unsucc}} \\; E_{\\text{chain, succ}} \\; E_{\\text{chain, unsucc}}]$,\neach entry being a closed-form function of $\\alpha$. No numerical approximation or rounding is required. Units are not applicable.", "solution": "The problem requires the derivation of the expected number of probes for successful and unsuccessful lookups in a hashed inverted page table (IPT) under two collision resolution schemes: linear probing and separate chaining. The load factor is given as $\\alpha = n/m$, where $n$ is the number of resident mappings (keys) and $m$ is the number of slots or buckets. The analysis relies on the assumption of uniform hashing. A probe is defined as a single main-memory access to compare a key or determine that a slot is empty or a chain is exhausted. We will derive the four required quantities starting from first principles.\n\nWe begin with the analysis of separate chaining, as its analysis is more direct.\n\n**3. Successful Lookup with Separate Chaining ($E_{\\text{chain, succ}}$)**\n\nA successful lookup for a key involves finding it within the linked list of the bucket it hashes to. To find the expected number of probes, we average over all $n$ keys in the table, assuming any key is equally likely to be searched for.\n\nLet's find the expected number of probes by averaging over the insertion process. The expected number of probes to find the $i$-th inserted key is $1$ (for the key itself) plus the expected number of keys inserted before it that are in the same chain. There are $i-1$ keys inserted before the $i$-th key. Due to the uniform hashing assumption, any of these $i-1$ keys has a probability of $1/m$ of hashing to the same bucket as the $i$-th key.\n\nBy linearity of expectation, the expected number of prior keys in the same chain is $(i-1)/m$.\nSo, the expected number of probes to find the $i$-th key is $1 + \\frac{i-1}{m}$.\n\nTo find the average for any successful search, we average this cost over all $n$ keys:\n$$E_{\\text{chain, succ}} = \\frac{1}{n} \\sum_{i=1}^{n} \\left(1 + \\frac{i-1}{m}\\right)$$\nWe can split the summation:\n$$E_{\\text{chain, succ}} = \\frac{1}{n} \\left( \\sum_{i=1}^{n} 1 + \\frac{1}{m} \\sum_{i=1}^{n} (i-1) \\right)$$\nThe first sum is $n$. The second sum is the sum of the first $n-1$ integers, which is $\\frac{n(n-1)}{2}$.\n$$E_{\\text{chain, succ}} = \\frac{1}{n} \\left( n + \\frac{1}{m} \\frac{n(n-1)}{2} \\right)$$\n$$E_{\\text{chain, succ}} = 1 + \\frac{n-1}{2m}$$\nThe problem asks for the result as a function of $\\alpha = n/m$. In the typical asymptotic analysis where $n, m \\to \\infty$ such that their ratio $\\alpha$ remains constant, the term $1/(2m)$ vanishes. Thus, we have:\n$$E_{\\text{chain, succ}} = 1 + \\frac{\\alpha}{2}$$\n\n**4. Unsuccessful Lookup with Separate Chaining ($E_{\\text{chain, unsucc}}$)**\n\nFor an unsuccessful lookup, the target key is not in the table. The lookup process involves hashing to a bucket and traversing the entire corresponding chain to verify the key's absence. The number of probes is the number of nodes in that chain.\nUnder uniform hashing, each of the $n$ keys is placed into one of the $m$ chains with equal probability $1/m$. The expected number of keys in any given chain is the total number of keys divided by the number of chains.\n$$E[\\text{length of a chain}] = \\frac{n}{m} = \\alpha$$\nAn unsuccessful search must traverse the entire chain, so the expected number of probes is equal to the expected chain length.\n$$E_{\\text{chain, unsucc}} = \\alpha$$\n\nWe now proceed to the analysis of open addressing with linear probing.\n\n**2. Unsuccessful Lookup with Linear Probing ($E_{\\text{lin, unsucc}}$)**\n\nThe analysis for linear probing is considerably more complex than for separate chaining due to \"primary clustering,\" where occupied slots can merge into long contiguous runs. The rigorous derivation from first principles is a classic result from the analysis of algorithms. The result for uniform hashing into a table with load factor $\\alpha$ states that the expected number of probes for an unsuccessful search is:\n$$E_{\\text{lin, unsucc}} \\approx \\frac{1}{2}\\left(1 + \\frac{1}{(1-\\alpha)^2}\\right)$$\n\n**1. Successful Lookup with Linear Probing ($E_{\\text{lin, succ}}$)**\n\nWe can derive the expected number of probes for a successful search from the result for an unsuccessful search. A successful search for a key takes the same number of probes as were required to insert that key into the table. The insertion of a key is equivalent to an unsuccessful search to find the first empty slot. The expected number of probes for a successful search is the average of the expected insertion costs for each of the $n$ keys.\n\nThis average can be approximated by integrating the cost of an unsuccessful search over all load factors from $0$ to $\\alpha$:\n$$E_{\\text{lin, succ}}(\\alpha) \\approx \\frac{1}{\\alpha} \\int_0^{\\alpha} \\frac{1}{2}\\left(1 + \\frac{1}{(1-u)^2}\\right) du$$\n$$E_{\\text{lin, succ}}(\\alpha) = \\frac{1}{2\\alpha} \\left[ u + \\frac{1}{1-u} \\right]_0^{\\alpha}$$\n$$E_{\\text{lin, succ}}(\\alpha) = \\frac{1}{2\\alpha} \\left( \\alpha + \\frac{1}{1-\\alpha} - 1 \\right) = \\frac{1}{2\\alpha} \\left( \\frac{\\alpha(1-\\alpha) + 1 - (1-\\alpha)}{1-\\alpha} \\right)$$\n$$E_{\\text{lin, succ}}(\\alpha) = \\frac{1}{2\\alpha} \\left( \\frac{2\\alpha - \\alpha^2}{1-\\alpha} \\right) = \\frac{1}{2} \\left( \\frac{2 - \\alpha}{1-\\alpha} \\right)$$\nThis can be rewritten for clarity:\n$$E_{\\text{lin, succ}} \\approx \\frac{1}{2}\\left(1 + \\frac{1}{1-\\alpha}\\right)$$\n\nSummarizing the four results:\n- $E_{\\text{lin, succ}} \\approx \\frac{1}{2}\\left(1 + \\frac{1}{1-\\alpha}\\right)$\n- $E_{\\text{lin, unsucc}} \\approx \\frac{1}{2}\\left(1 + \\frac{1}{(1-\\alpha)^2}\\right)$\n- $E_{\\text{chain, succ}} = 1 + \\frac{\\alpha}{2}$\n- $E_{\\text{chain, unsucc}} = \\alpha$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2}\\left(1 + \\frac{1}{1-\\alpha}\\right) & \\frac{1}{2}\\left(1 + \\frac{1}{(1-\\alpha)^2}\\right) & 1 + \\frac{\\alpha}{2} & \\alpha\n\\end{pmatrix}\n}\n$$", "id": "3651107"}, {"introduction": "The performance analyses we often perform rely on the 'uniform hashing assumption,' but what happens when this assumption fails? This practice [@problem_id:3651073] presents a thought experiment with a deliberately poor hash function to demonstrate how performance can degrade from a constant-time average to a linear-time worst case. This exercise underscores the critical importance of hash function design in achieving the performance benefits of a hashed page table.", "problem": "A system implements an inverted page table (IPT) that stores exactly one entry per physical frame. A lookup for a virtual address uses a hash-based index into a table of $B$ buckets and resolves collisions by separate chaining. The key for hashing is the ordered pair $(PID, VPN)$, where $PID$ is the Process Identifier (PID) and $VPN$ is the Virtual Page Number (VPN). The system designer mistakenly deploys the poor hash function $h(PID, VPN) = PID \\bmod B$. Let there be $n$ occupied IPT entries at some instant, where $n \\leq B$ is not guaranteed and a single process may occupy multiple frames. Assume no auxiliary acceleration structures such as a Translation Lookaside Buffer (TLB); lookups traverse the chain in a bucket by comparing both $PID$ and $VPN$ fields for equality at each node.\n\nStarting only from the definitions of the inverted page table, hashing with separate chaining, and equality-based key comparison, do the following:\n\n- Derive a necessary and sufficient condition on the set of occupied entries $\\{(PID_{j}, VPN_{j})\\}_{j=1}^{n}$ and the bucket count $B$ under which all $n$ entries collide into a single bucket when using $h(PID, VPN) = PID \\bmod B$. Your derivation must identify the precise predicate that characterizes this degeneracy.\n- Under that degeneracy, determine the worst-case number of key comparisons performed by a single lookup (whether successful or unsuccessful) as a function of $n$.\n\nProvide only the expression for the worst-case number of comparisons as your final answer, in closed form with no units. If you choose to simplify, do so exactly; no rounding is required.", "solution": "The problem requires deriving the condition for a worst-case collision scenario and then finding the worst-case number of comparisons under that condition.\n\n**1. Necessary and Sufficient Condition for Degeneracy**\n\nThe hash function is given as $h(PID, VPN) = PID \\bmod B$. This function's output depends solely on the Process Identifier ($PID$) and the number of buckets ($B$); it is independent of the Virtual Page Number ($VPN$).\n\nFor all $n$ occupied entries, represented by the set $\\{(PID_j, VPN_j)\\}_{j=1}^{n}$, to collide into a single bucket, they must all hash to the same bucket index. Let this common index be an integer $k$, where $0 \\leq k  B$.\n\nThis condition is met if and only if for every entry $j \\in \\{1, \\dots, n\\}$, the hash function yields the same value $k$:\n$$h(PID_j, VPN_j) = k$$\nSubstituting the hash function definition:\n$$PID_j \\bmod B = k$$\nThis means that every Process Identifier $PID_j$ associated with a resident page must have the same remainder $k$ when divided by $B$. This is the definition of congruence. Therefore, the necessary and sufficient condition is that all PIDs, $\\{PID_j\\}_{j=1}^{n}$, corresponding to the $n$ occupied entries, must belong to the same congruence class modulo $B$.\n\n**2. Worst-Case Number of Key Comparisons**\n\nUnder the degeneracy condition, all $n$ entries are stored in a single collision chain (a linked list). A lookup operation must traverse this list node by node, performing a key comparison at each step. A key comparison involves checking for equality of both the $PID$ and the $VPN$. We consider the worst case for both successful and unsuccessful lookups.\n\n*   **Successful Lookup:** The worst case for a successful search in a linked list occurs when the target key is the last element in the list. To find it, the algorithm must traverse the first $n-1$ nodes (failing a comparison at each) and finally match the $n$-th node. This results in a total of $n$ key comparisons.\n*   **Unsuccessful Lookup:** For an unsuccessful lookup, the target key is not in the table. The worst case occurs when the key hashes to the single, populated bucket. The algorithm must then traverse the entire chain of $n$ entries, performing a key comparison at each node and failing every time. After checking all $n$ entries, it reaches the end of the list and concludes the key is absent. This also results in $n$ key comparisons.\n\nIn both scenarios, the maximum number of comparisons required is $n$. Therefore, the overall worst-case number of key comparisons for a single lookup is $n$.", "answer": "$$\\boxed{n}$$", "id": "3651073"}, {"introduction": "Beyond performance, a key role of an operating system is to ensure reliability. This final practice [@problem_id:3647292] moves from performance analysis to system-level resilience, asking you to design a recovery algorithm for a hashed page table after a simulated kernel crash. By using persistent metadata stored in physical memory, you will devise a method to reconstruct the lost hash table, demonstrating a crucial principle of fault-tolerant system design.", "problem": "An Operating System (OS) uses a hashed page table to translate from a pair consisting of an Address Space Identifier (ASID) and a Virtual Page Number (VPN) to a Physical Frame Number (PFN). The hashed page table consists of $M$ buckets, each bucket storing a collision chain of entries of the form $(\\text{ASID}, \\text{VPN}) \\mapsto \\text{PFN}$ with protection and status flags. The hash function $H(\\cdot)$ is deterministic and depends only on $(\\text{ASID}, \\text{VPN})$ and the table size $M$, which the OS can choose at boot.\n\nThe OS also maintains, for each physical frame, a frame descriptor in RAM that is colocated with the frame and survives a kernel crash that leaves the contents of RAM intact but destroys in-kernel hash-table structures. Each frame descriptor contains:\n- A state flag indicating whether the frame is free or mapped.\n- If mapped, an “owner set” recording every virtual mapping that currently refers to this PFN as a finite multiset $\\{(\\text{ASID}_i, \\text{VPN}_i)\\}_{i=1}^{k}$, along with per-mapping flags (valid, dirty, access bits, protections).\n- A small constant-size header with the PFN and a checksum to defend against torn writes.\n\nAssume the following invariants and facts hold prior to the crash:\n- A virtual-to-physical translation is valid if and only if there exists a hashed page table entry for $(\\text{ASID}, \\text{VPN})$ that maps to a PFN marked “mapped” whose descriptor’s owner set contains $(\\text{ASID}, \\text{VPN})$ with a valid bit set.\n- Every resident mapping appears in exactly one owner set of its PFN, and every owner set entry corresponds to exactly one hashed page table entry.\n- The contents of RAM, including all frame descriptors and owner sets, remain readable after the crash, but the hashed page table is lost and must be rebuilt. The OS can allocate a fresh, empty hashed page table with a chosen size $M$ and reinitialize collision chains to empty.\n\nLet $F$ denote the total number of physical frames, and let $N$ denote the total number of owner-set entries across all frame descriptors (that is, the total count of resident $(\\text{ASID}, \\text{VPN})$ mappings in RAM).\n\nYou must select the design and recovery algorithm that, under these assumptions, both reconstructs a correct hashed page table and runs in time $\\mathcal{O}(N)$ without performing disk input/output.\n\nWhich option is correct?\n\nA. Initialize a new empty hashed page table with $M$ buckets. Perform a single linear pass over all $F$ frame descriptors. For each frame descriptor whose state is “mapped,” iterate its owner set $\\{(\\text{ASID}_i, \\text{VPN}_i)\\}_{i=1}^{k}$; for each pair, compute the bucket index $b = H(\\text{ASID}_i,\\text{VPN}_i) \\bmod M$ and insert a new entry $(\\text{ASID}_i,\\text{VPN}_i)\\mapsto \\text{PFN}$ with the recorded flags at the head of bucket $b$’s chain. Skip descriptors marked “free.” Because each owner-set entry generates at most one constant-time insertion, the work is $\\mathcal{O}(F + N) = \\mathcal{O}(N)$, assuming $N \\ge 1$, and no disk input/output is needed.\n\nB. First sort all $F$ frame descriptors lexicographically by $(\\text{ASID}, \\text{VPN})$ keys extracted from their owner sets, then rebuild the hashed page table by scanning the sorted list and inserting entries in that order. This guarantees stable ordering in the chains and thus correctness, at a cost of $\\mathcal{O}(N \\log N)$ time.\n\nC. For each process, scan the entire virtual address space to discover valid pages by probing each potential $(\\text{ASID}, \\text{VPN})$ in ascending order and using the Central Processing Unit (CPU) to trigger page faults to determine presence. For each discovered resident mapping, insert it into the hashed page table. Because the virtual address space size may be much larger than the number of frames, the approach is superlinear in $N$ but reconstructs all entries without needing frame descriptors.\n\nD. Hash only on the PFN: for each mapped frame, compute $b = H(\\text{PFN}) \\bmod M$ and insert a single entry $(\\text{ASID}^{*}, \\text{VPN}^{*}) \\mapsto \\text{PFN}$ per frame using any one $(\\text{ASID}^{*}, \\text{VPN}^{*})$ pair discovered for that frame; for frames with multiple aliases, keep only the first pair encountered to avoid duplicate insertions. This yields $\\mathcal{O}(F)$ time and avoids long chains but may discard some aliases.", "solution": "The problem requires selecting the correct and most efficient algorithm to reconstruct a lost hashed page table after a crash, given that metadata stored in physical RAM frame descriptors survives. The algorithm must be correct, run in $\\mathcal{O}(N)$ time, and use no disk I/O.\n\n*   **Analysis of Option A:** This algorithm correctly identifies that the \"owner sets\" within the frame descriptors are the definitive source of information for all resident mappings. The proposed procedure is to iterate through all physical frames (a linear scan of $F$ items), check if a frame is \"mapped\", and if so, iterate through all owner-set entries (a total of $N$ entries across all frames). For each entry, it computes the hash and inserts the mapping into the new table. Insertion into a hash table at the head of a chain is an $\\mathcal{O}(1)$ operation. The total time complexity is $\\mathcal{O}(F + N)$. In a running system, the number of mapped pages ($N$) is typically of the same order as or greater than the number of physical frames ($F$), so this complexity simplifies to $\\mathcal{O}(N)$. This method is correct, meets the time complexity requirement, and uses only RAM data.\n\n*   **Analysis of Option B:** This option introduces an unnecessary and inefficient sorting step, with a time complexity of $\\mathcal{O}(N \\log N)$. The order of entries within a hash table's collision chain does not affect the correctness of lookups. This algorithm is therefore suboptimal and violates the $\\mathcal{O}(N)$ time constraint.\n\n*   **Analysis of Option C:** This approach is fundamentally flawed. It suggests using the CPU's Memory Management Unit (MMU) to probe the virtual address space to find valid pages. However, the MMU itself relies on a valid page table to perform address translation. Since the page table has been destroyed in the crash, the MMU cannot function. This creates a circular dependency, making the approach impossible.\n\n*   **Analysis of Option D:** This algorithm is incorrect for two main reasons. First, it proposes using an incorrect hash function based on the PFN, whereas the system requires a hash based on the virtual address $(\\text{ASID}, \\text{VPN})$ to perform lookups. Second, by keeping only one mapping per physical frame, it explicitly discards other valid mappings (aliases) for shared memory. This results in an incomplete and therefore incorrect reconstruction of the page table.\n\n**Conclusion:**\nOption A is the only choice that describes a correct, complete, and efficient reconstruction algorithm that adheres to all the problem's constraints.", "answer": "$$\\boxed{A}$$", "id": "3647292"}]}