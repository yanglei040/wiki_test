{"hands_on_practices": [{"introduction": "To begin, let's tackle a fundamental design question: how much memory is needed for a bitmap to manage a disk? This exercise explores the direct trade-off between the in-memory size of the bit vector and the total storage capacity it can oversee. Mastering this calculation is the first step in understanding the resource costs and scalability of bitmap-based free-space management. [@problem_id:3624191]", "problem": "An operating system manages free space on a block device using a bit vector (bitmap) in which each disk block is represented by exactly one bit, with a bit value indicating allocated or free. The bit vector is kept in main memory and is constrained to occupy at most $P$ page frames, each of size $P_{s}$ bytes. The disk uses a fixed block size of $B$ bytes. Assume there is no bitmap overhead other than the bit-per-block representation, and every bit in the allocated memory region is usable by the bitmap.\n\nGiven the following parameters: $P = 64$, $P_{s} = 4\\,\\text{KiB}$, and $B = 4\\,\\text{KiB}$, where $1\\,\\text{KiB} = 1024\\,\\text{bytes}$ and $1\\,\\text{GiB} = 2^{30}\\,\\text{bytes}$, determine the maximum disk capacity $S$ that can be fully covered by such a bitmap. Express your final capacity in gibibytes (GiB) and round your answer to $4$ significant figures.", "solution": "The problem statement is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\nThe following data and constraints are explicitly provided in the problem statement:\n- The free-space management scheme is a bit vector (bitmap).\n- Each disk block is represented by exactly $1$ bit in the bitmap.\n- The bitmap is stored in main memory.\n- The maximum number of page frames the bitmap can occupy is $P = 64$.\n- The size of each page frame is $P_s = 4\\,\\text{KiB}$.\n- The size of each disk block is $B = 4\\,\\text{KiB}$.\n- A conversion factor is given: $1\\,\\text{KiB} = 1024\\,\\text{bytes}$.\n- A conversion factor is given: $1\\,\\text{GiB} = 2^{30}\\,\\text{bytes}$.\n- The final answer for the maximum disk capacity, $S$, must be expressed in gibibytes (GiB) and rounded to $4$ significant figures.\n- It is assumed there is no overhead and all allocated memory is usable for the bitmap.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is evaluated against the validation criteria:\n- **Scientifically Grounded**: The problem is a standard exercise in operating systems, dealing with fundamental concepts of memory and disk management (bitmaps, pages, blocks). The principles are sound and well-established.\n- **Well-Posed**: All necessary parameters ($P$, $P_s$, $B$) and conversion factors are specified, allowing for the calculation of a unique solution. The question is clear and unambiguous.\n- **Objective**: The problem is stated in precise, quantitative terms, free from any subjective or speculative language.\n\nThe problem exhibits no flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A full solution will be derived.\n\nThe solution proceeds by first calculating the total available memory for the bitmap, then determining the total number of bits this memory provides, which in turn defines the number of disk blocks that can be managed, and finally calculating the total disk capacity.\n\nFirst, we determine the total memory allocated for the bitmap, $M_{\\text{bitmap}}$. This is the product of the number of page frames, $P$, and the size of each page frame, $P_s$.\n$$M_{\\text{bitmap}} = P \\times P_s$$\nThe given values are $P = 64$ and $P_s = 4\\,\\text{KiB}$. We convert $P_s$ to bytes using the given conversion $1\\,\\text{KiB} = 1024\\,\\text{bytes}$. It is convenient to work with powers of $2$.\n$$P = 64 = 2^6$$\n$$P_s = 4\\,\\text{KiB} = 4 \\times 1024\\,\\text{bytes} = 2^2 \\times 2^{10}\\,\\text{bytes} = 2^{12}\\,\\text{bytes}$$\nSubstituting these into the equation for $M_{\\text{bitmap}}$:\n$$M_{\\text{bitmap}} = 2^6 \\times 2^{12}\\,\\text{bytes} = 2^{18}\\,\\text{bytes}$$\n\nNext, we find the total number of bits, $N_{\\text{bits}}$, available in this memory space. Since $1\\,\\text{byte} = 8\\,\\text{bits}$, or $2^3\\,\\text{bits}$:\n$$N_{\\text{bits}} = M_{\\text{bitmap}} \\times 8\\,\\frac{\\text{bits}}{\\text{byte}}$$\n$$N_{\\text{bits}} = 2^{18}\\,\\text{bytes} \\times 2^3\\,\\frac{\\text{bits}}{\\text{byte}} = 2^{21}\\,\\text{bits}$$\n\nAccording to the problem statement, each disk block is represented by exactly one bit. Therefore, the total number of disk blocks, $N_{\\text{blocks}}$, that can be managed by this bitmap is equal to the total number of bits.\n$$N_{\\text{blocks}} = N_{\\text{bits}} = 2^{21}$$\n\nThe maximum disk capacity, $S$, is the total number of blocks multiplied by the size of each block, $B$. The block size is given as $B = 4\\,\\text{KiB}$.\n$$B = 4\\,\\text{KiB} = 4 \\times 1024\\,\\text{bytes} = 2^2 \\times 2^{10}\\,\\text{bytes} = 2^{12}\\,\\text{bytes}$$\nNow, we can calculate the total capacity $S$ in bytes:\n$$S = N_{\\text{blocks}} \\times B$$\n$$S = 2^{21} \\times 2^{12}\\,\\text{bytes} = 2^{33}\\,\\text{bytes}$$\n\nFinally, the problem requires the capacity to be expressed in gibibytes (GiB), rounded to $4$ significant figures. The conversion factor is $1\\,\\text{GiB} = 2^{30}\\,\\text{bytes}$.\n$$S_{\\text{GiB}} = \\frac{S}{2^{30}\\,\\text{bytes/GiB}} = \\frac{2^{33}\\,\\text{bytes}}{2^{30}\\,\\text{bytes/GiB}}$$\n$$S_{\\text{GiB}} = 2^{33-30}\\,\\text{GiB} = 2^3\\,\\text{GiB} = 8\\,\\text{GiB}$$\n\nThe result is exactly $8\\,\\text{GiB}$. To express this with $4$ significant figures, we write it as $8.000$.", "answer": "$$\\boxed{8.000}$$", "id": "3624191"}, {"introduction": "Beyond initial allocation, a bit vector is a cornerstone of file system integrity. This practice challenges you to design an efficient consistency checker, a tool that every robust file system needs to detect and report critical errors. You will analyze different algorithmic strategies to find one that correctly identifies issues like pointers to free blocks or double allocations within strict time and memory limits, mirroring the real-world constraints faced by OS developers. [@problem_id:3624195]", "problem": "A storage volume uses a free-space bit vector (bitmap) to manage allocation of data blocks. Let there be $M$ data blocks indexed $0$ through $M-1$. The free-space bitmap $B$ is a bit array of length $M$ where $B[b] = 1$ if and only if block $b$ is currently allocated. The inode table lists, for each file, a finite sequence of data block indices. Let $N$ denote the total number of block pointers across all inodes (counting duplicates if they exist due to bugs). By design, a correct file system must satisfy both of the following invariants:\n- For every block index $b$ that appears in any inode’s block list, $B[b] = 1$.\n- No data block is referenced by more than one file (no double allocation), i.e., across all inodes, each block index $b$ appears at most once.\n\nYou are asked to select a checking strategy that, given a read-only snapshot of the inode table and the free-space bitmap $B$, detects violations of the above invariants in time $O(N)$ under a standard unit-cost word RAM model with machine word size of $W$ bits, and using low additional memory. For this problem, “low additional memory” is defined as at most $c \\cdot M$ bits for a small constant $c$ independent of $M$ and $N$, plus $O(1)$ machine words. The checker must not modify any on-disk metadata. It may initialize its own auxiliary structures in time $O\\!\\left(\\frac{M}{W}\\right)$ and may perform at most a linear scan of $B$ if needed.\n\nWhich option below satisfies these requirements and correctly detects both “inode references a block with $B[b] = 0$” and “double allocation” in the stated resource bounds?\n\nA. Perform one pass over all inode block pointers. Maintain an auxiliary “seen” bit vector $S$ of length $M$ bits, initially all zeros. For each encountered block index $b$: read $B[b]$; if $B[b] = 0$, report an error; else if $S[b] = 1$, report a double allocation; else set $S[b] \\leftarrow 1$. Optionally, after the pass, linearly scan $B$ to report allocated-but-unreferenced blocks. Overall time $O\\!\\left(N + \\frac{M}{W}\\right)$ and additional memory $M$ bits.\n\nB. Perform one pass over all inode block pointers, inserting each seen block index $b$ into a dynamic hash set keyed by $b$; if insertion finds $b$ already present, report a double allocation. For each $b$, read $B[b]$ and if $B[b] = 0$, report an error. Overall time is expected $O(N)$, additional memory is proportional to the number of distinct referenced blocks.\n\nC. Extract all inode-referenced block indices into an array of length $N$, then perform an external merge sort of the array by block index. In a subsequent pass over the sorted array, report any duplicates as double allocations. Independently, for each index in the array, verify $B[b] = 1$. Overall time $O\\!\\left(N \\log N\\right)$ plus linear additional disk traffic, with $O(1)$ Random Access Memory (RAM).\n\nD. Perform one pass over all inode block pointers. For each block index $b$, flip the bit $B[b] \\leftarrow 1 - B[b]$ in the on-disk free-space bitmap. If a flipped bit becomes $0$, interpret it as a second reference and report a double allocation; if it was initially $0$, flipping to $1$ reveals an “inode references free block” error on the next encounter. At the end, flip all touched bits back to restore $B$.\n\nE. Perform one pass over all inode block pointers while inserting each $b$ into a Bloom filter configured for constant false positive rate. If insertion indicates the element was already present, report a double allocation. For each $b$, check the Bloom filter’s approximate membership of $b$ in the set $\\{ i \\mid B[i] = 1 \\}$ without consulting $B$ directly, and report an error if not found. Total time $O(N)$ with sublinear memory and no need to read $B$ after initialization.\n\nSelect the single best option that meets the stated correctness and resource constraints.", "solution": "The user wants me to select the single best option that meets the stated correctness and resource constraints.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- A storage volume uses a free-space bit vector (bitmap).\n- There are $M$ data blocks indexed $0$ through $M-1$.\n- The free-space bitmap $B$ is a bit array of length $M$.\n- $B[b] = 1$ if and only if block $b$ is currently allocated.\n- The inode table lists, for each file, a finite sequence of data block indices.\n- $N$ is the total number of block pointers across all inodes.\n- Invariant 1: For every block index $b$ that appears in any inode’s block list, $B[b] = 1$.\n- Invariant 2: No data block is referenced by more than one file (no double allocation).\n- The task is to select a checking strategy that detects violations of both invariants.\n- The checker is given a read-only snapshot of the inode table and the bitmap $B$.\n- Time complexity must be $O(N)$.\n- The computational model is a standard unit-cost word RAM model with machine word size of $W$ bits.\n- Additional memory must be at most $c \\cdot M$ bits for a small constant $c$, plus $O(1)$ machine words.\n- The checker must not modify any on-disk metadata.\n- Auxiliary structures can be initialized in time $O\\!\\left(\\frac{M}{W}\\right)$.\n- At most a linear scan of $B$ is permitted if needed.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is valid.\n- **Scientifically Grounded:** The problem describes a fundamental task in file system consistency checking (analogous to `fsck` in Unix-like systems). The concepts of inodes, block pointers, and free-space bitmaps are standard components of many file system designs. The invariants described are critical for file system integrity.\n- **Well-Posed:** The goal is clearly defined (detect two specific types of errors), and the constraints on time and space complexity ($O(N)$ time, $c \\cdot M$ bits of space) are precise and non-ambiguous. The computational model is specified. A solution can be uniquely determined based on these constraints.\n- **Objective:** The language is technical and precise, with no subjective or ambiguous terminology.\n- **Complete and Consistent Setup:** All necessary information is provided. The definitions of $M$, $N$, $B$, the invariants, and the resource constraints are self-contained and consistent. The allowance for an $O\\!\\left(\\frac{M}{W}\\right)$ initialization phase is a key detail that is consistent with operations on bit vectors of size $M$.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will now proceed with the solution derivation and option analysis.\n\n### Solution Derivation\n\nThe objective is to design an algorithm that verifies two invariants for a set of $N$ block pointers, where blocks are indexed from $0$ to $M-1$.\n1.  **Inode references a free block**: For each block pointer $b$ from an inode, we must verify that $B[b] = 1$.\n2.  **Double allocation**: We must verify that each block pointer $b$ appears at most once across all inode lists.\n\nThe algorithm must operate within a time complexity of $O(N)$ and use additional memory of at most $c \\cdot M$ bits plus a constant number of words.\n\nLet's analyze the requirements. We must process $N$ block pointers. A single linear pass through all pointers is the natural way to achieve $O(N)$ running time. During this pass, for each pointer $b$, we need to perform two checks.\n\n**Checking Invariant 1 ($B[b]=1$):**\nFor each pointer $b$, we need to access the bit $B[b]$ from the free-space bitmap. Since $B$ is a bit array, this is a random access operation that takes $O(1)$ time on a word RAM model. Repeating this for all $N$ pointers takes a total of $O(N)$ time. This fits within the time budget.\n\n**Checking Invariant 2 (No double allocation):**\nTo detect double allocations, we need to remember which block indices we have already seen during our pass over the inode pointers. Let's call the set of previously seen block indices $S_{seen}$. For each new pointer $b$, we must check if $b \\in S_{seen}$. If it is, we have found a double allocation. If it is not, we must add it to the set, i.e., $S_{seen} \\leftarrow S_{seen} \\cup \\{b\\}$, and continue.\n\nThe choice of data structure for $S_{seen}$ is critical for meeting the complexity constraints.\n-   The structure must support insertion and membership testing.\n-   To achieve an overall time of $O(N)$, each of these $N$ operations must take $O(1)$ time (amortized or worst-case).\n-   The space used by the structure must not exceed $c \\cdot M$ bits.\n\nA **bit vector** (or bitmap) is an ideal data structure for this task. We can use an auxiliary bit vector, let's call it $S$, of length $M$, initialized to all zeros. The indices of this vector correspond to the data block indices $0, \\dots, M-1$.\n-   **Initialization:** Set all $M$ bits of $S$ to $0$. This takes $O\\!\\left(\\frac{M}{W}\\right)$ time, which is explicitly permitted by the problem statement.\n-   **Membership test:** To check if a block $b$ has been seen, we read the bit $S[b]$. This is an $O(1)$ operation.\n-   **Insertion:** To mark block $b$ as seen, we set the bit $S[b] \\leftarrow 1$. This is also an $O(1)$ operation.\n-   **Space:** The vector $S$ requires exactly $M$ bits of storage. This fits the memory constraint \"$c \\cdot M$ bits for a small constant $c$\" by taking $c=1$.\n\nCombining these, the complete algorithm is:\n1.  Initialize an auxiliary bit vector $S$ of size $M$ to all zeros. Time: $O\\!\\left(\\frac{M}{W}\\right)$. Space: $M$ bits.\n2.  Iterate through the $N$ block pointers provided by the inode table. For each block index $b$:\n    a. Read $B[b]$. If $B[b] = 0$, report a violation of Invariant 1.\n    b. Read $S[b]$. If $S[b] = 1$, report a violation of Invariant 2 (double allocation).\n    c. Set $S[b] \\leftarrow 1$.\n3.  The main loop (step 2) involves $N$ iterations, each taking $O(1)$ time. Thus, the time for this step is $O(N)$.\n4.  The total time complexity is $O\\!\\left(N + \\frac{M}{W}\\right)$. Since the problem states the checking time should be $O(N)$ and allows for $O\\!\\left(\\frac{M}{W}\\right)$ initialization, this is a valid solution. The total additional memory is $M$ bits for $S$ plus $O(1)$ words for counters and pointers, which satisfies the memory constraint.\n\nThis derived procedure is sound and meets all requirements. We now evaluate the given options against this understanding.\n\n### Option-by-Option Analysis\n\n**A. Perform one pass over all inode block pointers. Maintain an auxiliary “seen” bit vector $S$ of length $M$ bits, initially all zeros. For each encountered block index $b$: read $B[b]$; if $B[b] = 0$, report an error; else if $S[b] = 1$, report a double allocation; else set $S[b] \\leftarrow 1$. Optionally, after the pass, linearly scan $B$ to report allocated-but-unreferenced blocks. Overall time $O\\!\\left(N + \\frac{M}{W}\\right)$ and additional memory $M$ bits.**\n- **Analysis:** This option perfectly describes the algorithm derived above.\n    - **Correctness:** The logic is sound. It checks for inode pointers to free blocks by consulting $B[b]$. It checks for double allocations by using the auxiliary \"seen\" bitmap $S$.\n    - **Time Complexity:** Initialization of the $M$-bit vector $S$ takes $O\\!\\left(\\frac{M}{W}\\right)$ time. The single pass over $N$ pointers takes $O(N)$ time, as each operation inside the loop is $O(1)$. The total time is $O\\!\\left(N + \\frac{M}{W}\\right)$, which meets the problem's requirements.\n    - **Space Complexity:** The auxiliary vector $S$ uses $M$ bits. This satisfies the constraint of \"at most $c \\cdot M$ bits\" with $c=1$.\n    - **Other Constraints:** The checker is read-only with respect to on-disk metadata ($B$ is only read).\n- **Verdict:** Correct.\n\n**B. Perform one pass over all inode block pointers, inserting each seen block index $b$ into a dynamic hash set keyed by $b$; if insertion finds $b$ already present, report a double allocation. For each $b$, read $B[b]$ and if $B[b] = 0$, report an error. Overall time is expected $O(N)$, additional memory is proportional to the number of distinct referenced blocks.**\n- **Analysis:**\n    - **Correctness:** The logic is correct for finding both types of errors.\n    - **Time Complexity:** A hash set provides *expected* $O(1)$ time per operation. The total time is therefore *expected* $O(N)$. However, the worst-case time can be significantly higher, which may not be acceptable for a system verification tool. More importantly, it does not offer a strict $O(N)$ guarantee in the worst case, unlike the bit vector approach.\n    - **Space Complexity:** A hash set stores the block indices themselves. Let $U$ be the number of unique block indices referenced, where $U \\le \\min(N, M)$. The space required is $O(U)$ words. A word is $W$ bits. So space is $O(U \\cdot W)$ bits. The problem requires space to be at most $c \\cdot M$ bits. It is possible for $U \\cdot W$ to be much larger than $M$. For example, consider a system with a large disk, $M = 2^{40}$, and $U = 2^{30}$ unique file blocks. With a $W=64$-bit word size, the hash set would require roughly $O(2^{30} \\cdot 64) = O(2^{36})$ bits of memory. The constraint is $c \\cdot M = c \\cdot 2^{40}$ bits. In this case, it might fit. But consider $M=2^{32}$, $U=2^{30}$, $W=64$. The hash set needs $O(2^{36})$ bits, while the limit is $c \\cdot 2^{32}$ bits, which is a violation for small $c$. As the relationship between $N$, $M$, and $W$ is not fixed, we cannot guarantee the space constraint is met.\n- **Verdict:** Incorrect. The space complexity does not satisfy the specified bound in the general case.\n\n**C. Extract all inode-referenced block indices into an array of length $N$, then perform an external merge sort of the array by block index. In a subsequent pass over the sorted array, report any duplicates as double allocations. Independently, for each index in the array, verify $B[b] = 1$. Overall time $O\\left(N \\log N\\right)$ plus linear additional disk traffic, with $O(1)$ Random Access Memory (RAM).**\n- **Analysis:**\n    - **Correctness:** Sorting the block indices allows for easy detection of duplicates (they will be adjacent) in a subsequent linear scan. Checking $B[b]=1$ for each can also be done. The logic is correct.\n    - **Time Complexity:** The dominant step is sorting the $N$ block indices. An efficient comparison-based sort takes $O(N \\log N)$ time. The problem explicitly requires $O(N)$ time. This option fails to meet the time complexity constraint.\n- **Verdict:** Incorrect.\n\n**D. Perform one pass over all inode block pointers. For each block index $b$, flip the bit $B[b] \\leftarrow 1 - B[b]$ in the on-disk free-space bitmap. If a flipped bit becomes $0$, interpret it as a second reference and report a double allocation; if it was initially $0$, flipping to $1$ reveals an “inode references free block” error on the next encounter. At the end, flip all touched bits back to restore $B$.**\n- **Analysis:**\n    - **Correctness:** The logic is flawed. If an inode references a free block (initial state $B[b]=0$), the algorithm flips it to $1$. The description says this error is revealed \"on the next encounter\", which may never happen if the block is referenced only once. The error should be reported immediately upon finding $B[b]=0$. Furthermore, the interpretation of state changes is backwards: flipping a bit from $1$ to $0$ happens on the *first* encounter of a valid block, not the second.\n    - **Constraint Violation:** The problem states, \"The checker must not modify any on-disk metadata.\" This option proposes modifying the on-disk bitmap $B$ directly. Even though it suggests restoring the bits later, this is a modification of on-disk state, which is explicitly forbidden. This is a critical violation.\n- **Verdict:** Incorrect.\n\n**E. Perform one pass over all inode block pointers while inserting each $b$ into a Bloom filter configured for constant false positive rate. If insertion indicates the element was already present, report a double allocation. For each $b$, check the Bloom filter’s approximate membership of $b$ in the set $\\{ i \\mid B[i] = 1 \\}$ without consulting $B$ directly, and report an error if not found. Total time $O(N)$ with sublinear memory and no need to read $B$ after initialization.**\n- **Analysis:**\n    - **Correctness:** A Bloom filter is a probabilistic data structure. It can produce false positives.\n        -   For double allocation: If inserting $b$ indicates it was \"already present\", this could be a true positive (a double allocation) or a false positive (a hash collision). Reporting a double allocation on this basis would lead to incorrectly flagging valid file systems as corrupt.\n        -   For checking against free blocks: The option suggests checking membership in a Bloom filter representing allocated blocks. A query returning \"not present\" is definitive (no false negatives), correctly identifying a pointer to a free block. However, a query returning \"present\" could be a false positive, causing the check to miss an error where an inode points to a free block whose index happens to falsely test as present in the Bloom filter.\n    - File system verification requires deterministic correctness. Probabilistic data structures that can produce false positives (for double allocation) or lead to false negatives (missing an error, which happens when a false positive masks it) are unsuitable for this task.\n- **Verdict:** Incorrect.\n\n### Conclusion\nOption A provides a correct and deterministic algorithm that satisfies all of the problem's time, space, and operational constraints. The other options are flawed due to violations of complexity bounds (B, C), operational constraints (D), or the fundamental requirement of correctness (D, E).", "answer": "$$\\boxed{A}$$", "id": "3624195"}, {"introduction": "The widespread use of bit vectors is largely due to their exceptional performance, especially when finding free blocks. This exercise offers a deep dive into the microarchitectural details that make bitmap scanning so fast on modern processors, connecting high-level OS concepts to low-level hardware features. By modeling a branchless search loop, you will quantify the speed of this operation and appreciate how hardware and software co-design leads to efficient system performance. [@problem_id:3624118]", "problem": "A file system uses a bit vector (bitmap) to manage free blocks, where a bit value of $0$ denotes a free block and a bit value of $1$ denotes an allocated block. The operating system scans the bitmap to enumerate free blocks by processing machine words of width $64$ bits. To reduce unpredictable branches, a branchless enumeration is implemented using the Bit Manipulation Instructions (BMI) set: Count Trailing Zeros ($\\mathrm{TZCNT}$) and Isolate Lowest Set Bit ($\\mathrm{BLSI}$). For each $64$-bit word $w$, the loop forms $m = \\lnot w$ to mark free bits as set bits, and then repeatedly applies $\\mathrm{BLSI}(m)$ to extract the lowest set bit, uses $\\mathrm{TZCNT}(m)$ to compute its position, and clears that bit from $m$ with a bitwise exclusive-or. Assume that per discovered free bit, exactly one $\\mathrm{BLSI}$, one $\\mathrm{TZCNT}$, and one bitwise exclusive-or occurs, and per $64$-bit word, exactly one load and one bitwise not occur.\n\nModel the microarchitecture as follows, using a steady-state pipeline model in which the cycles per iteration are the maximum of the loop-carried dependency bound and the resource throughput bound:\n- The latency of $\\mathrm{BLSI}$ is $\\ell_{\\mathrm{bl}} = 1$ cycle.\n- The latency of bitwise exclusive-or is $\\ell_{x} = 1$ cycle.\n- The reciprocal throughput of $\\mathrm{BLSI}$ is $\\tau_{\\mathrm{bl}} = 1$ cycle per instruction.\n- The reciprocal throughput of $\\mathrm{TZCNT}$ is $\\tau_{\\mathrm{tz}} = 1$ cycle per instruction.\n- The reciprocal throughput of bitwise exclusive-or is $\\tau_{x} = 0.25$ cycles per instruction.\n- The reciprocal throughput of the $64$-bit load (from Level 1 cache) is $\\tau_{\\mathrm{ld}} = 0.5$ cycles per load.\n- The reciprocal throughput of bitwise not is $\\tau_{\\mathrm{not}} = 0.25$ cycles per instruction.\n\nAssume the fraction of free bits in the bitmap is $p = 0.2$, so the expected number of free bits per $64$-bit word is $64p$. The Central Processing Unit (CPU) frequency is $f = 3.2 \\times 10^{9}$ hertz. Using only the definitions of bit vectors and this pipeline model, derive from first principles the average time per discovered free bit, expressed in nanoseconds, by:\n1. Identifying the loop-carried dependency chain within the per-bit body and computing its latency bound.\n2. Computing the resource throughput bound of the per-bit body.\n3. Combining these to obtain the cycles per discovered free bit for the loop body.\n4. Amortizing the per-word overhead across the expected $64p$ discovered free bits to obtain an average cycles per bit.\n5. Converting cycles per bit to time per bit using $f$.\n\nExpress the final time per bit in nanoseconds and round your answer to four significant figures.", "solution": "The problem asks for the average time per discovered free bit in a bitmap scanning process. The solution is derived from first principles using the provided microarchitectural model, following the five specified steps.\n\nLet $W$ be the word width, given as $W=64$ bits. The bitmap uses a bit value of $0$ to denote a free block and $1$ to denote an allocated block. The algorithm inverts the word $w$ to get a mask $m = \\lnot w$, where set bits ($1$s) correspond to free blocks. The fraction of free bits is $p=0.2$.\n\nThe expected number of free bits per $W$-bit word is $N_{fb}$:\n$$N_{fb} = Wp = 64 \\times 0.2 = 12.8$$\n\nThe analysis proceeds in five steps as mandated.\n\n**1. Loop-Carried Dependency Latency Bound**\nThe inner loop finds and clears one free bit at a time from the mask $m$. Let $m_i$ be the mask at the beginning of the $i$-th iteration of this inner loop. The state for the next iteration, $m_{i+1}$, is computed from $m_i$. The critical path for this state transition involves two operations:\n1. Isolate the lowest set bit: $b_i = \\mathrm{BLSI}(m_i)$.\n2. Clear the lowest set bit from the mask: $m_{i+1} = m_i \\oplus b_i$, where $\\oplus$ denotes the bitwise exclusive-or operation.\n\nThe $\\mathrm{TZCNT}(m_i)$ operation is also performed, but its result (the bit position) is not used to compute $m_{i+1}$, so it does not contribute to the loop-carried dependency chain. The dependency chain is $m_i \\to \\mathrm{BLSI} \\to b_i \\to \\mathrm{XOR} \\to m_{i+1}$.\n\nThe latency of this dependency chain, $L_{dep}$, is the sum of the latencies of the instructions on the chain:\n- Latency of $\\mathrm{BLSI}$: $\\ell_{\\mathrm{bl}} = 1$ cycle.\n- Latency of bitwise exclusive-or: $\\ell_{x} = 1$ cycle.\n\n$$L_{dep} = \\ell_{\\mathrm{bl}} + \\ell_{x} = 1 + 1 = 2 \\text{ cycles}$$\n\n**2. Resource Throughput Bound**\nFor each discovered free bit, the inner loop executes three instructions: one $\\mathrm{BLSI}$, one $\\mathrm{TZCNT}$, and one bitwise exclusive-or. The resource throughput bound, $T_{res}$, is determined by the total demand on the CPU's execution units. In this model, we sum the reciprocal throughputs of the instructions executed in one iteration of the loop body.\n- Reciprocal throughput of $\\mathrm{BLSI}$: $\\tau_{\\mathrm{bl}} = 1$ cycle/instruction.\n- Reciprocal throughput of $\\mathrm{TZCNT}$: $\\tau_{\\mathrm{tz}} = 1$ cycle/instruction.\n- Reciprocal throughput of bitwise exclusive-or: $\\tau_{x} = 0.25$ cycles/instruction.\n\n$$T_{res} = \\tau_{\\mathrm{bl}} + \\tau_{\\mathrm{tz}} + \\tau_{x} = 1 + 1 + 0.25 = 2.25 \\text{ cycles}$$\n\n**3. Cycles per Discovered Free Bit (Loop Body)**\nThe steady-state pipeline model states that the cycles per iteration, $C_{bit}$, is the maximum of the loop-carried dependency bound and the resource throughput bound.\n$$C_{bit} = \\max(L_{dep}, T_{res}) = \\max(2, 2.25) = 2.25 \\text{ cycles}$$\nThis is the number of cycles required to process one free bit within the inner loop.\n\n**4. Average Cycles per Bit with Amortized Overhead**\nEach $64$-bit word requires overhead work before the inner loop begins: one $64$-bit load and one bitwise not operation. The cycle cost of this per-word overhead, $C_{overhead}$, is calculated from the respective reciprocal throughputs:\n- Reciprocal throughput of load: $\\tau_{\\mathrm{ld}} = 0.5$ cycles/load.\n- Reciprocal throughput of bitwise not: $\\tau_{\\mathrm{not}} = 0.25$ cycles/instruction.\n\n$$C_{overhead} = \\tau_{\\mathrm{ld}} + \\tau_{\\mathrm{not}} = 0.5 + 0.25 = 0.75 \\text{ cycles}$$\nThis overhead cost is incurred once per word and must be amortized over the expected number of free bits, $N_{fb} = 12.8$, found in that word. The average number of cycles per discovered free bit, $C_{avg\\_bit}$, is the sum of the inner loop cost and the amortized overhead cost.\n$$C_{avg\\_bit} = C_{bit} + \\frac{C_{overhead}}{N_{fb}} = 2.25 + \\frac{0.75}{12.8}$$\n$$C_{avg\\_bit} = 2.25 + 0.05859375 = 2.30859375 \\text{ cycles}$$\n\n**5. Conversion to Time per Bit**\nThe CPU frequency is given as $f = 3.2 \\times 10^9$ Hz. The duration of a single cycle is $T_{cycle} = 1/f$. The average time per discovered free bit, $T_{avg\\_bit}$, in seconds is:\n$$T_{avg\\_bit} = C_{avg\\_bit} \\times T_{cycle} = \\frac{C_{avg\\_bit}}{f} = \\frac{2.30859375}{3.2 \\times 10^9} \\text{ s}$$\nTo express the result in nanoseconds ($1 \\text{ ns} = 10^{-9} \\text{ s}$), we multiply by $10^9$:\n$$T_{avg\\_bit} (\\text{ns}) = \\frac{2.30859375}{3.2} \\approx 0.721435546875 \\text{ ns}$$\nRounding the final answer to four significant figures gives $0.7214$.", "answer": "$$\\boxed{0.7214}$$", "id": "3624118"}]}