{"hands_on_practices": [{"introduction": "To build a strong foundation, we begin by exploring one of the most fundamental challenges in contiguous allocation: external fragmentation. This exercise presents a thought experiment designed to reveal a worst-case scenario for the simple and intuitive First-Fit algorithm. By tracing the state of memory through a specific adversarial sequence of allocations and deallocations, you will develop a sharp analytical intuition for how placement policies impact memory utilization and why more sophisticated strategies are often necessary in practice [@problem_id:3657317].", "problem": "Consider an operating system that uses contiguous heap allocation with the First Fit policy (First Fit chooses the earliest free hole that is at least as large as the request) and performs immediate coalescing of adjacent free holes upon deallocation. There is no compaction, no allocation metadata overhead, and all allocations are aligned to $1$ byte. The heap initially consists of a single free block of size $M$ bytes.\n\nAn adversary issues $n$ allocation requests into the empty heap, alternating sizes $a$ and $b$, starting with $a$, where $a$ and $b$ are positive integers with $a<b$ and $n \\geq 2$. Assume $M$ is exactly the sum of the $n$ requested sizes so that after the $n$-th allocation the heap has no remaining free space. Immediately after the $n$-th allocation, the adversary frees all blocks whose size is $a$ and leaves all blocks whose size is $b$ allocated. No further operations occur.\n\nUsing only the core definitions of contiguous allocation, First Fit placement, and external fragmentation (free space split into noncontiguous holes by allocated regions), derive an analytic expression for the largest contiguous free hole size $H$ that exists after freeing all size-$a$ blocks, expressed as a function of $a$, $b$, and $n$. Express your final answer in bytes. No rounding is required.", "solution": "The problem will first be validated against the specified criteria before a solution is attempted.\n\n### Step 1: Extract Givens\nThe data, variables, and conditions provided in the problem statement are as follows:\n- The memory allocation is contiguous heap allocation.\n- The placement policy is First Fit: the earliest (lowest address) free hole that is large enough is chosen.\n- Deallocation involves immediate coalescing of adjacent free holes.\n- There is no memory compaction.\n- There is no overhead for allocation metadata.\n- Allocations are aligned to $1$ byte.\n- The heap starts as a single free block of size $M$ bytes.\n- A sequence of $n$ allocation requests is made.\n- The requested sizes alternate between $a$ and $b$, starting with $a$.\n- $a$ and $b$ are positive integers, with the constraint $a < b$.\n- The number of requests $n \\geq 2$.\n- The total heap size $M$ is equal to the sum of all $n$ requested sizes.\n- After all $n$ allocations are complete, all allocated blocks of size $a$ are freed.\n- All allocated blocks of size $b$ remain allocated.\n- The objective is to find an analytic expression for the largest contiguous free hole size, denoted as $H$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is assessed for validity:\n- **Scientifically Grounded and Objective**: The problem is based on fundamental concepts of operating system memory management, specifically contiguous allocation, placement algorithms (First Fit), and fragmentation. These are well-established, formal topics within computer science. The language is precise and objective.\n- **Well-Posed**: The problem is self-contained. All necessary conditions are provided: the initial state of the heap, the allocation algorithm, the exact sequence of requests, the deallocation procedure, and the coalescing rule. The heap size $M$ is defined to be exactly sufficient for all allocations, ensuring the allocation phase is fully determined. The question asks for a single, specific quantity ($H$) that is a direct consequence of the defined process. The constraints $a > 0$, $b > 0$, $a < b$, and $n \\geq 2$ ensure a non-trivial scenario. The problem is not under-specified, over-constrained, or ambiguous.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid as it is a well-posed, scientifically grounded problem in the field of operating systems. A solution will be derived.\n\n### Derivation of the Solution\nThe derivation proceeds by analyzing the state of the heap memory layout after each major phase: the allocation phase and the deallocation phase.\n\n**1. Allocation Phase and Memory Layout**\n\nThe heap begins as a single free block of size $M$ starting at address $0$. The allocation policy is First Fit. The requests are for blocks of alternating sizes, beginning with $a$. The sequence of requested sizes is $a, b, a, b, \\dots$.\n\n- **Request 1 (size $a$)**: The only free block is the entire heap of size $M$. Since $M$ is the sum of all $n$ requests, $M \\geq a$. First Fit allocates a block of size $a$ at the start of the heap (address $0$). The heap state becomes: one allocated block of size $a$, followed by a single free block of size $M-a$.\n\n- **Request 2 (size $b$)**: The only free block is the one of size $M-a$ starting at address $a$. Since $M-a$ is sufficient to hold the remaining $n-1$ requests, it is large enough for size $b$. First Fit allocates a block of size $b$ immediately following the first block. The heap state becomes: allocated block of size $a$, allocated block of size $b$, and a new free block of size $M-a-b$.\n\nThis process continues for all $n$ requests. At each step $k$ (for $1 \\leq k \\leq n$), there is only one free block available, located at the end of the previously allocated blocks. The First Fit algorithm has no choice but to place the new block in this single free hole. Consequently, the $n$ blocks are allocated contiguously from the start of the memory.\n\nSince the total size of all requested blocks is exactly $M$, after the $n$-th allocation, there is no free space left in the heap. The final memory layout consists of $n$ adjacent blocks. The sequence of their sizes is precisely the sequence of requests: $a, b, a, b, \\dots$.\n\nLet $P_i$ be the $i$-th allocated block. The size of $P_i$ is $a$ if $i$ is odd, and $b$ if $i$ is even. The final layout is:\n$[P_1(\\text{size } a)][P_2(\\text{size } b)][P_3(\\text{size } a)][P_4(\\text{size } b)] \\cdots [P_n]$\n\n**2. Deallocation and Coalescing Phase**\n\nImmediately following the allocation phase, all blocks of size $a$ are freed. These are the blocks $P_i$ where $i$ is odd. The blocks of size $b$ (where $i$ is even) remain allocated.\n\nLet us analyze the coalescing rule: \"immediate coalescing of adjacent free holes upon deallocation\". When a block is freed, the system checks its immediate neighbors (lower and higher addresses). If a neighbor is also a free block, they are merged.\n\nConsider an arbitrary block $P_i$ of size $a$ that is being freed. Since its index $i$ must be odd:\n- Its left neighbor is $P_{i-1}$. Since $i$ is odd and $i \\geq 1$, $i-1$ is even. If $i>1$, the block $P_{i-1}$ has size $b$ and remains allocated. If $i=1$, there is no left neighbor (it's the start of the heap).\n- Its right neighbor is $P_{i+1}$. Since $i$ is odd, $i+1$ is even. If $i<n$, the block $P_{i+1}$ has size $b$ and remains allocated. If $i=n$ (which implies $n$ is odd), there is no right neighbor (it's the end of the heap).\n\nIn every case, when a block of size $a$ is freed, its immediate neighbors are either allocated blocks of size $b$ or the boundaries of the heap. No two blocks of size $a$ are ever physically adjacent in the memory layout.\n\nTherefore, when any block of size $a$ is freed, it becomes a free hole. However, it cannot be coalesced with any other free hole because its neighbors are not free. The deallocation of all `a`-sized blocks results in a set of disconnected free holes.\n\nThe final memory map will be a sequence of free holes of size $a$ separated by allocated blocks of size $b$.\n- If $n$ is even, say $n=2k$, the layout is:\n  $[(\\text{free}) a][(\\text{alloc}) b][(\\text{free}) a] \\cdots [(\\text{alloc}) b]$\n  There are $k = n/2$ free holes, each of size $a$.\n- If $n$ is odd, say $n=2k+1$, the layout is:\n  $[(\\text{free}) a][(\\text{alloc}) b] \\cdots [(\\text{alloc}) b][(\\text{free}) a]$\n  There are $k+1 = (n+1)/2$ free holes, each of size $a$.\n\n**3. Largest Contiguous Free Hole Size ($H$)**\n\nThe memory contains one or more free holes. As established, due to the allocated `b`-sized blocks acting as separators, no coalescing occurs between the spaces previously occupied by `a`-sized blocks. Each freed block becomes an independent, contiguous free hole of size $a$.\n\nThe set of all contiguous free holes consists entirely of holes of size $a$. The largest size among them is therefore $a$. The quantity $H$ represents this largest size.\n\nThus, the largest contiguous free hole size is $H = a$. The values of $b$ and $n$ are necessary to define the problem setup and the sequence of events but do not appear in the final expression for $H$.", "answer": "$$\n\\boxed{a}\n$$", "id": "3657317"}, {"introduction": "Moving beyond simple allocation, real-world systems must guarantee data integrity even when facing unexpected power failures or system crashes. This practice delves into the critical issue of crash consistency for free-space metadata, a cornerstone of reliable file system design. You will evaluate several strategies for ordering metadata writes, learning to reason about how failures can lead to storage leaks—a subtle but serious form of corruption—and which protocols can prevent them [@problem_id:3645580].", "problem": "A filesystem (FS) uses a free-space bitmap for tracking data-block availability and inodes with direct block pointers for file-to-block reachability. The storage device provides crash atomicity at an atomicity granularity $g$ bytes: any write whose footprint lies entirely within a single $g$-sized region is either fully persisted or not persisted on a power failure, while writes to distinct $g$-regions may be reordered and only a prefix may persist at the moment of failure. Assume each free-space bit update and each inode pointer update is confined within a single $g$-region. A write ordering barrier ensures that all writes issued before the barrier become durable before any writes issued after the barrier can become durable; barriers do not themselves persist data but constrain relative durability order.\n\nA multi-block allocation of $n$ new data blocks to a single inode performs two classes of metadata updates: setting the $n$ inode pointers to the newly allocated block identifiers, and setting the corresponding $n$ bitmap bits from free to allocated. A power failure may occur at any point during the sequence of writes. Define a free-space safety invariant for crash consistency: for every data block $b$, if the free-space bitmap reports $b$ as allocated, then $b$ must be reachable from the superblock via some durable inode pointer; the violation case where the bitmap reports allocated and no durable pointer exists is a storage leak. The question is which write orders guarantee that the invariant holds for all blocks under any single crash.\n\nWhich of the following write orders avoid leaks under the stated model for any crash point and any $n \\geq 1$?\n\nA. Per-block pointer-then-bit with barriers: for each of the $n$ blocks in sequence, write the inode pointer to $b$, issue a barrier, then write the corresponding bitmap bit to allocated, and issue another barrier before proceeding to the next block.\n\nB. All-bits-first with barrier: set all $n$ bitmap bits to allocated, issue a barrier, then write all $n$ inode pointers.\n\nC. All-pointers-first with barrier: write all $n$ inode pointers, issue a barrier, then set all $n$ bitmap bits to allocated, and issue a barrier.\n\nD. Write-ahead logging (WAL): append $n$ allocation-intent records to a log, each record entirely within a single $g$-region, then append a commit record, all under a barrier that orders the commit after the intents; only after the commit becomes durable are the inode pointers and bitmap bits applied lazily. Recovery replays only intent records that precede a durable commit.\n\nE. Copy-on-write (COW) tree update: write a new version of the inode (and any parent metadata) that references the $n$ blocks, then atomically switch the superblock to point to the new tree via a single $g$-atomic write; only after the superblock switch becomes durable are the corresponding $n$ bitmap bits set to allocated, ordered by barriers.\n\nF. Concurrent unordered writes: issue all $n$ bitmap bit writes and all $n$ inode pointer writes without any barriers, relying on the device to eventually persist all of them.\n\nSelect all that apply.", "solution": "To avoid a storage leak, the filesystem must guarantee that for any data block *b*, the state \"bitmap marks *b* as allocated\" cannot become durable before the state \"an inode pointer to *b* is durable\". Let's denote the inode pointer write as $W_P(b)$ and the bitmap bit write as $W_B(b)$. The invariant requires that if a crash occurs, it is never the case that $W_B(b)$ is durable but $W_P(b)$ is not. A write barrier ensures that all writes issued before it are durable before any writes issued after it can become durable.\n\n*   **A. Per-block pointer-then-bit with barriers**: The order for each block is `write $W_P(b)$; barrier; write $W_B(b)$`. The barrier guarantees that $W_B(b)$ cannot be durable unless $W_P(b)$ is already durable. This order prevents leaks. **Correct.**\n*   **B. All-bits-first with barrier**: The order is `write all $W_B$; barrier; write all $W_P$`. A crash can occur after some or all $W_B$ writes are durable but before the barrier is crossed and any $W_P$ writes are durable. This creates a state where blocks are marked as allocated in the bitmap but have no corresponding pointers, which is a storage leak. **Incorrect.**\n*   **C. All-pointers-first with barrier**: The order is `write all $W_P$; barrier; write all $W_B$`. The barrier guarantees that no $W_B$ write can become durable unless all $W_P$ writes are already durable. If a crash leaves a $W_B(b)$ durable, the corresponding $W_P(b)$ must also be durable. This order prevents leaks. **Correct.**\n*   **D. Write-ahead logging (WAL)**: WAL makes the entire multi-step allocation atomic. The changes to the live bitmap and inode are only applied after the intention is durably recorded in a commit record in the log. On recovery, an incomplete transaction is aborted, and a complete one is replayed to its conclusion. This prevents any intermediate state (like a leak) from becoming permanent. **Correct.**\n*   **E. Copy-on-write (COW) tree update**: This strategy makes the new file data reachable by atomically updating a single pointer in the superblock. The bitmap is only updated *after* this atomic switch is durable (enforced by a barrier). If the bitmap shows a block is allocated, the superblock switch must have completed, meaning the pointer to the block is durable and reachable. This prevents leaks. **Correct.**\n*   **F. Concurrent unordered writes**: Without barriers, the storage device is free to reorder writes. It could make a $W_B(b)$ write durable before the corresponding $W_P(b)$ write. A crash at that moment would cause a storage leak. **Incorrect.**", "answer": "$$\n\\boxed{ACDE}\n$$", "id": "3645580"}, {"introduction": "Modern operating systems are inherently concurrent, with multiple threads competing for resources. This exercise tackles the classic time-of-check-to-time-of-use (TOCTOU) race condition that arises when multiple threads attempt to allocate space from a shared bitmap. You will first design a lock-free solution using atomic operations to ensure correctness, and then apply a probabilistic model to quantify the likelihood of contention, bridging the gap between high-level concurrent design and quantitative performance analysis [@problem_id:3624135].", "problem": "A storage allocator in an operating system uses a bit vector (bitmap) for free-space management. Each bit marks one block: a bit value of $0$ denotes a free block and a bit value of $1$ denotes an allocated block. The bitmap is organized into machine words of $b$ bits per word; in this system, $b = 64$. A thread scans the bitmap to find a contiguous run of $L_{s} = 96$ free bits starting at index $i$. This run spans $W = 2$ $64$-bit words. Because of time-of-check to time-of-use races, after the thread verifies the run is free, another thread may allocate within these words before the first thread updates the bitmap.\n\nPart A (conceptual). Propose a lock-free validation step that the scanning thread can perform to ensure correctness when claiming the run, assuming standard atomic primitives are available, including Compare-And-Swap (CAS). Explain what condition causes the validation to fail and what the thread should do upon failure.\n\nPart B (calculation). Quantify the probability $\\phi$ that the validation fails on the first attempt. Assume the following realistic scenario and stochastic model:\n- The bitmap has $N = 2^{20}$ bits.\n- Other threads concurrently perform allocation attempts modeled as a homogeneous Poisson process. There are $T = 16$ such threads, each initiating allocation attempts at rate $r = 50{,}000$ attempts per second.\n- Each allocation attempt by another thread targets a contiguous run of $L_{a} = 64$ bits, with a start position chosen uniformly at random among all valid start positions in the bitmap. Assume boundary effects are negligible because the run found by the scanning thread is well away from bitmap edges.\n- The hazard window between the scanning thread’s final read of the two words and the start of its first CAS attempt across those words is $\\Delta = 8 \\,\\mu\\mathrm{s}$.\n- Assume nearly all concurrent attempts succeed during this short window, so it suffices to treat any overlapping attempt as causing a modification that changes the value of at least one of the two words.\n\nUnder these assumptions, derive $\\phi$ from first principles. Round your final decimal answer for $\\phi$ to four significant figures. Do not use a percentage sign; express $\\phi$ as a pure decimal without units.", "solution": "The problem is evaluated to be scientifically grounded, well-posed, objective, and internally consistent. All necessary data for a unique solution are provided. The scenario describes a classic time-of-check to time-of-use (TOCTOU) race condition in operating systems, and the request to analyze it using atomic primitives and a stochastic model is a valid and standard exercise in computer systems engineering.\n\nPart A: Lock-Free Validation\nThe core issue is a race condition between the scanning thread's check for free space and its subsequent use (allocation) of that space. A concurrent thread can modify the state of the bitmap words in the interval between the scanning thread's read operations and its write operations. To solve this without traditional locks, the scanning thread must atomically validate that the state has not changed just before it commits its own update. The Compare-And-Swap (CAS) atomic primitive is ideal for this purpose.\n\nThe proposed lock-free validation and update process for the scanning thread is as follows:\n1.  The thread scans the bitmap and identifies a candidate run of $L_s = 96$ free bits. This run spans $W=2$ words, which we will denote as $word_1$ and $word_2$, at memory addresses $addr_1$ and $addr_2$ respectively.\n2.  The thread reads the current values of these two words, let's call them $old\\_val_1$ and $old\\_val_2$. It confirms that these values indeed represent the desired contiguous block of free bits.\n3.  The thread computes the new values, $new\\_val_1$ and $new\\_val_2$, that would result from allocating the $96$-bit run. This involves changing the appropriate $96$ bits from $0$ to $1$.\n4.  To claim the space, the thread performs two sequential CAS operations. A double-word CAS (DCAS) would be ideal as it would make the two-word update atomic, but assuming only single-word CAS is available, the sequence would be:\n    - `success_1 = CAS(addr_1, old_val_1, new_val_1)`\n    - `success_2 = CAS(addr_2, old_val_2, new_val_2)`\n\nThe validation step is implicitly part of the CAS operations. The `CAS(address, expected, new)` operation will only succeed if the current value at `address` is identical to `expected`.\n\nThe validation fails if either `success_1` is false or `success_2` is false. This failure condition occurs precisely when a concurrent thread has modified either $word_1$ or $word_2$ (or both) after the scanning thread read their initial values ($old\\_val_1$ and $old\\_val_2$). The value at the memory location no longer matches the expected value, so the CAS operation fails, correctly signaling that the state has changed and preventing a corrupted allocation.\n\nUpon failure, the thread must take corrective action. If the first CAS fails, the state is unchanged, and the thread can simply restart its scan for a new free block. If the first CAS succeeds but the second fails, the bitmap is left in an intermediate state where one word is updated and the other is not. Attempting to \"roll back\" the first CAS by writing $old\\_val_1$ back is unsafe, as it could overwrite a different, legitimate allocation made by another thread in the interim. The most robust and simplest recovery strategy is to accept that the partial allocation attempt has failed and resource is potentially wasted. The thread should abort the current attempt entirely and **restart the scan from the beginning** or from a new position to find a different free run. The partially claimed space is typically dealt with by system-level garbage collection or by designing allocators to avoid spanning word boundaries for critical allocations.\n\nPart B: Probability of Failure\nWe are asked to quantify the probability $\\phi$ that the validation fails. This failure occurs if at least one of the two target words is modified by a concurrent thread during the hazard window $\\Delta$.\n\nThe concurrent allocation attempts are modeled as a homogeneous Poisson process. The total rate of attempts is the product of the number of concurrent threads, $T$, and the rate per thread, $r$.\n$$ \\lambda_{\\text{total}} = T \\times r $$\nSubstituting the given values, $T=16$ and $r=50{,}000 \\, \\text{s}^{-1}$:\n$$ \\lambda_{\\text{total}} = 16 \\times 50{,}000 \\, \\text{s}^{-1} = 800{,}000 \\, \\text{s}^{-1} = 8 \\times 10^{5} \\, \\text{s}^{-1} $$\n\nNext, we determine the probability, $P_{\\text{conflict}}$, that a single random allocation attempt by another thread conflicts with our target region. Our target region spans $W=2$ words, covering $2 \\times b = 2 \\times 64 = 128$ bits. A concurrent allocation is for a contiguous run of $L_a = 64$ bits. The start position of this allocation is chosen uniformly at random from all valid start positions in the bitmap of size $N = 2^{20}$ bits.\n\nThe number of valid start positions for an allocation of length $L_a$ is $N_{\\text{pos}} = N - L_a + 1$.\nA conflict occurs if the $L_a$-bit range of the concurrent allocation overlaps with our $2b$-bit target range. The number of such conflicting start positions is given by the sum of the lengths of the two intervals minus one.\n$$ N_{\\text{conflict}} = (2b) + L_a - 1 $$\nWith $b=64$ and $L_a=64$:\n$$ N_{\\text{conflict}} = 2 \\times 64 + 64 - 1 = 128 + 64 - 1 = 191 $$\nThe probability of a single attempt causing a conflict is the ratio of conflicting start positions to total possible start positions:\n$$ P_{\\text{conflict}} = \\frac{N_{\\text{conflict}}}{N_{\\text{pos}}} = \\frac{2b + L_a - 1}{N - L_a + 1} $$\nSubstituting values:\n$$ P_{\\text{conflict}} = \\frac{191}{2^{20} - 64 + 1} = \\frac{191}{1,048,576 - 63} = \\frac{191}{1,048,513} $$\n\nThe rate of *conflicting* allocation attempts, $\\lambda_{\\text{conflict}}$, is the total attempt rate multiplied by the conflict probability:\n$$ \\lambda_{\\text{conflict}} = \\lambda_{\\text{total}} \\times P_{\\text{conflict}} = (T \\times r) \\times \\frac{2b + L_a - 1}{N - L_a + 1} $$\n$$ \\lambda_{\\text{conflict}} = 8 \\times 10^5 \\, \\text{s}^{-1} \\times \\frac{191}{1,048,513} \\approx 145.73 \\, \\text{s}^{-1} $$\n\nThe number of conflicting events, $k$, within the hazard window $\\Delta = 8 \\,\\mu\\mathrm{s} = 8 \\times 10^{-6} \\, \\mathrm{s}$ follows a Poisson distribution $P(k) = \\frac{\\mu^k e^{-\\mu}}{k!}$. The mean number of events, $\\mu$, in this interval is:\n$$ \\mu = \\lambda_{\\text{conflict}} \\times \\Delta $$\n$$ \\mu = \\left( (T \\times r) \\frac{2b + L_a - 1}{N - L_a + 1} \\right) \\Delta $$\nSubstituting the numerical values:\n$$ \\mu = \\left( 8 \\times 10^5 \\times \\frac{191}{1,048,513} \\right) \\times 8 \\times 10^{-6} $$\n$$ \\mu = 6.4 \\times \\frac{191}{1,048,513} = \\frac{1222.4}{1,048,513} \\approx 0.001165839 $$\n\nThe validation fails if at least one conflicting event occurs in the window $\\Delta$. The probability of this, $\\phi$, is $P(k \\ge 1)$.\n$$ \\phi = P(k \\ge 1) = 1 - P(k=0) $$\nFor a Poisson distribution, $P(k=0) = \\frac{\\mu^0 e^{-\\mu}}{0!} = e^{-\\mu}$.\n$$ \\phi = 1 - e^{-\\mu} = 1 - \\exp(-\\mu) $$\nSubstituting the value of $\\mu$:\n$$ \\phi = 1 - \\exp(-0.001165839) $$\n$$ \\phi \\approx 1 - 0.998834834 = 0.001165166 $$\nRounding the result to four significant figures, we get:\n$$ \\phi \\approx 0.001165 $$\nIn scientific notation, this is $1.165 \\times 10^{-3}$.", "answer": "$$\\boxed{1.165 \\times 10^{-3}}$$", "id": "3624135"}]}