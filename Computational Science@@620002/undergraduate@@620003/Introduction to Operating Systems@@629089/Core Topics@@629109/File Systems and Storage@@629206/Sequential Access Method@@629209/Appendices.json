{"hands_on_practices": [{"introduction": "Sequential file access involves a fundamental trade-off: many small reads incur high system call overhead, while fewer large reads are generally more efficient. This exercise explores the relationship between this fixed per-call cost, the data transfer rate, and the chosen read size. By working through this problem, you will learn to quantitatively determine an optimal chunk size to ensure that system call overhead does not exceed a desired performance budget [@problem_id:3682197].", "problem": "A program uses the sequential access method to read a large file by repeatedly invoking the operating system’s read system call (syscall) to fetch fixed-size chunks from a storage device. In this model, each chunk of size $B$ bytes is read by one syscall that incurs a fixed overhead of $\\alpha$ nanoseconds, and the data transfer proceeds at a sustained device rate $R$ bytes per second. Assume the following for this workload: no caching or prefetching effects, no overlapping of data transfer with syscall overhead, and a steady sequential stream at the given rate $R$.\n\nLet the target bound on the fraction of the total wall-clock time spent in syscall overhead be $x$, expressed as a decimal between $0$ and $1$. Using only first principles that total time is the sum of constituent times and that sequential access reads adjacent blocks in order with one syscall per block, determine the minimal chunk size $B^{\\star}$ that guarantees the syscall overhead fraction is at most $x$ across the entire read.\n\nUse the following parameters: $\\alpha = 3{,}500$ nanoseconds, $R = 700$ mebibytes per second (MiB/s), and $x = 0.03$. Treat $1$ mebibyte (MiB) as $1{,}048{,}576$ bytes and $1$ kibibyte (KiB) as $1{,}024$ bytes. Express your final chunk size in KiB. Round your answer to four significant figures.", "solution": "The problem asks for the minimal chunk size, denoted as $B^{\\star}$, required to ensure that the fraction of total time spent in system call (syscall) overhead does not exceed a specified value, $x$. The analysis begins from first principles, considering the time taken to read a single chunk of data.\n\nBased on the problem description, the total wall-clock time, $T_{\\text{total}}$, to read one chunk of size $B$ bytes is the sum of the fixed syscall overhead time, $T_{\\text{overhead}}$, and the variable data transfer time, $T_{\\text{transfer}}$. The model assumes these two phases are not overlapped.\n$$T_{\\text{total}} = T_{\\text{overhead}} + T_{\\text{transfer}}$$\nThe syscall overhead is a fixed time per call, given as $\\alpha$.\n$$T_{\\text{overhead}} = \\alpha$$\nThe data transfer time for a chunk of size $B$ bytes at a sustained rate of $R$ bytes per second is given by the ratio of the size to the rate.\n$$T_{\\text{transfer}} = \\frac{B}{R}$$\nSubstituting these into the equation for total time gives:\n$$T_{\\text{total}} = \\alpha + \\frac{B}{R}$$\nThe fraction of the total time spent in syscall overhead, which we can call $f_{\\text{overhead}}$, is the ratio of the overhead time to the total time.\n$$f_{\\text{overhead}} = \\frac{T_{\\text{overhead}}}{T_{\\text{total}}} = \\frac{\\alpha}{\\alpha + \\frac{B}{R}}$$\nThe problem specifies a target bound, requiring this fraction to be at most $x$.\n$$f_{\\text{overhead}} \\le x$$\nSubstituting the expression for $f_{\\text{overhead}}$ yields the inequality:\n$$\\frac{\\alpha}{\\alpha + \\frac{B}{R}} \\le x$$\nTo find the minimal chunk size $B^{\\star}$ that satisfies this condition, we first observe that $f_{\\text{overhead}}$ is a monotonically decreasing function of $B$, as increasing $B$ increases the denominator of the fraction. Therefore, the minimal size $B^{\\star}$ is the one for which the equality holds. For any $B > B^{\\star}$, the inequality will be strictly satisfied. We solve for $B^{\\star}$ by setting the fraction equal to $x$.\n$$\\frac{\\alpha}{\\alpha + \\frac{B^{\\star}}{R}} = x$$\nWe now solve this equation for $B^{\\star}$.\n$$\\alpha = x \\left(\\alpha + \\frac{B^{\\star}}{R}\\right)$$\n$$\\alpha = x\\alpha + x\\frac{B^{\\star}}{R}$$\n$$\\alpha - x\\alpha = x\\frac{B^{\\star}}{R}$$\n$$\\alpha(1 - x) = x\\frac{B^{\\star}}{R}$$\nIsolating $B^{\\star}$ gives the analytical solution:\n$$B^{\\star} = \\frac{\\alpha R (1-x)}{x}$$\nNow, we substitute the given parameter values, ensuring all units are consistent. The standard unit for time will be seconds (s) and for size will be bytes.\nThe given parameters are:\n$\\alpha = 3{,}500 \\text{ ns} = 3{,}500 \\times 10^{-9} \\text{ s}$\n$R = 700 \\text{ MiB/s} = 700 \\times 1{,}048{,}576 \\text{ bytes/s} = 733{,}993{,}200 \\text{ bytes/s}$\n$x = 0.03$\nAlso, $1-x = 1 - 0.03 = 0.97$.\n\nSubstituting these values into the expression for $B^{\\star}$:\n$$B^{\\star} = \\frac{(3{,}500 \\times 10^{-9} \\text{ s}) \\times (733{,}993{,}200 \\text{ bytes/s}) \\times 0.97}{0.03}$$\nFirst, we compute the numerator:\n$$ \\text{Numerator} = (3{,}500 \\times 10^{-9}) \\times 733{,}993{,}200 \\times 0.97 \\text{ bytes}$$\n$$ \\text{Numerator} = 2.5689762 \\times 0.97 \\text{ bytes} \\approx 2.491906914 \\text{ bytes}$$\nNow, we divide by the denominator, $x = 0.03$:\n$$B^{\\star} = \\frac{2.491906914}{0.03} \\text{ bytes} \\approx 83{,}063.5638 \\text{ bytes}$$\nThe problem requires the final answer to be in kibibytes (KiB), rounded to four significant figures. We use the conversion factor $1 \\text{ KiB} = 1{,}024 \\text{ bytes}$.\n$$B^{\\star} \\text{ [in KiB]} = \\frac{83{,}063.5638 \\text{ bytes}}{1{,}024 \\text{ bytes/KiB}} \\approx 81.1167615 \\text{ KiB}$$\nRounding this value to four significant figures, we look at the fifth significant digit. The number is $81.116...$. The fifth digit is $6$, which is $5$ or greater, so we round up the fourth digit.\n$$B^{\\star} \\approx 81.12 \\text{ KiB}$$", "answer": "$$\\boxed{81.12}$$", "id": "3682197"}, {"introduction": "Modern operating systems boost I/O performance by overlapping CPU work with device operations, creating a data pipeline. In such a system, the overall throughput is dictated by the slowest stage, known as the bottleneck. This practice challenges you to model a two-stage I/O pipeline and find the precise buffer size that makes the device the bottleneck, a condition known as saturating the device [@problem_id:3682208].", "problem": "A sequential file reader in user space performs repeated reads of size $B$ bytes from a storage device using the sequential access method. The device has a fixed service latency $L$ (in seconds) per read request and a steady-state transfer bandwidth $r$ (in bytes per second). Each read request induces Central Processing Unit (CPU) overhead of $\\alpha + \\beta B$ cycles in user space, where $\\alpha$ (in cycles) models fixed per-call costs (e.g., system call boundary, buffer management) and $\\beta$ (in cycles per byte) models per-byte costs (e.g., memory copy, checksum). The CPU runs at a fixed clock rate $f$ (in cycles per second). The system uses double buffering with asynchronous Input/Output (I/O), so after warm-up the device transfer and the CPU overhead for different chunks can overlap perfectly in steady state.\n\nUse only the following fundamental base to reason about performance:\n- Definitions of latency and bandwidth: the device service time per chunk is $L + B/r$ seconds.\n- Conversion between cycles and time: CPU time for a chunk is $(\\alpha + \\beta B)/f$ seconds.\n- In a two-stage overlapped pipeline, the sustainable steady-state initiation interval equals the larger of the two stage times.\n\nDefine “saturate the device” to mean that, in steady state, the device stage is the bottleneck (that is, the CPU never delays the pipeline). Among all buffer sizes $B$ that saturate the device, choose the smallest such $B$ to minimize memory footprint and latency amplification. Assume the parameters satisfy $ \\beta/f < 1/r $ and $ \\alpha/f > L $, ensuring that there exists a unique positive buffer size that achieves this boundary.\n\nDerive, from first principles and the above definitions, a closed-form analytic expression for the optimal buffer size $B$ (in bytes) that minimally saturates the device. Express your final answer as a single symbolic expression in terms of $L$, $r$, $\\alpha$, $\\beta$, and $f$. No numerical substitution is required, and no rounding is needed. Do not include units in the final expression.", "solution": "The system described is a two-stage pipeline where CPU processing and device I/O for different data chunks can be performed concurrently. The two stages are:\n1.  The CPU stage, which processes a chunk of size $B$.\n2.  The I/O device stage, which reads a chunk of size $B$.\n\nThe time required for each stage to process one chunk is given. The time for the CPU stage is the number of CPU cycles divided by the CPU clock rate:\n$$T_{CPU} = \\frac{\\alpha + \\beta B}{f}$$\nThe time for the device stage is the sum of the fixed latency and the variable transfer time:\n$$T_{device} = L + \\frac{B}{r}$$\nIn a perfectly overlapped pipeline, the rate at which new chunks can be processed in steady state (the throughput) is determined by the slower of the two stages. The time between the completion of successive chunks, known as the initiation interval $\\tau$, is given by:\n$$\\tau = \\max(T_{CPU}, T_{device})$$\nThe problem defines \"saturating the device\" as the condition where the device stage is the bottleneck. This means the time taken by the device stage is greater than or equal to the time taken by the CPU stage. Formally, this is expressed as:\n$$T_{device} \\geq T_{CPU}$$\nSubstituting the expressions for $T_{device}$ and $T_{CPU}$:\n$$L + \\frac{B}{r} \\geq \\frac{\\alpha + \\beta B}{f}$$\nThe objective is to find the smallest buffer size $B$ that satisfies this condition. The smallest such $B$ will be the one that makes the two sides equal, representing the boundary point where the system transitions from being CPU-bound to device-bound. Any $B$ smaller than this value would result in $T_{CPU} > T_{device}$, making the CPU the bottleneck. Therefore, we solve for $B$ at the equality:\n$$L + \\frac{B}{r} = \\frac{\\alpha + \\beta B}{f}$$\nTo solve for $B$, we first separate the terms involving $B$ from the constant terms.\n$$L + \\frac{B}{r} = \\frac{\\alpha}{f} + \\frac{\\beta B}{f}$$\nRearranging the equation to group terms with $B$ on one side:\n$$\\frac{B}{r} - \\frac{\\beta B}{f} = \\frac{\\alpha}{f} - L$$\nFactor out $B$ from the terms on the left-hand side:\n$$B \\left( \\frac{1}{r} - \\frac{\\beta}{f} \\right) = \\frac{\\alpha}{f} - L$$\nNow, we can isolate $B$ by dividing both sides by the term in the parenthesis.\n$$B = \\frac{\\frac{\\alpha}{f} - L}{\\frac{1}{r} - \\frac{\\beta}{f}}$$\nThe problem supplies two constraints that guarantee a unique, positive solution for $B$.\n1.  The constraint $\\alpha/f > L$ implies that the numerator, $\\frac{\\alpha}{f} - L$, is positive. This means the fixed part of the CPU time per call exceeds the fixed latency of the device.\n2.  The constraint $\\beta/f < 1/r$ implies that the denominator, $\\frac{1}{r} - \\frac{\\beta}{f}$, is also positive. This means the time for the CPU to process one byte is less than the time for the device to transfer one byte.\nSince both the numerator and the denominator are positive, the resulting buffer size $B$ is positive, which is physically required.\n\nTo present the expression in a simplified closed form, we can eliminate the compound fractions by finding a common denominator for the numerator and the denominator of the main fraction.\nThe numerator can be written as:\n$$\\frac{\\alpha}{f} - L = \\frac{\\alpha - Lf}{f}$$\nThe denominator can be written as:\n$$\\frac{1}{r} - \\frac{\\beta}{f} = \\frac{f - r\\beta}{rf}$$\nSubstituting these back into the expression for $B$:\n$$B = \\frac{\\frac{\\alpha - Lf}{f}}{\\frac{f - r\\beta}{rf}}$$\nTo simplify the fraction of fractions, we multiply the numerator by the reciprocal of the denominator:\n$$B = \\left( \\frac{\\alpha - Lf}{f} \\right) \\left( \\frac{rf}{f - r\\beta} \\right)$$\nThe term $f$ cancels out, yielding the final expression:\n$$B = \\frac{r(\\alpha - Lf)}{f - r\\beta}$$\nThis is the closed-form analytic expression for the optimal buffer size $B$ that minimally saturates the storage device.", "answer": "$$\\boxed{\\frac{r(\\alpha - Lf)}{f - r\\beta}}$$", "id": "3682208"}, {"introduction": "High-level file APIs provide a convenient byte-stream abstraction, but beneath this layer, storage devices operate on fixed-size blocks. This final hands-on practice bridges theory and implementation by asking you to build a Sequential Access Method (SAM) from first principles. You will manage a logical cursor, translate byte offsets into physical block addresses, and implement a single-block cache, confronting the core challenges of file system design [@problem_id:3682261].", "problem": "You are asked to implement a Sequential Access Method (SAM) interface over an abstract block device for an educational operating system scenario. The goal is to formalize sequential access over a byte-addressable region that is physically stored on a block device and to map the operations open, next, and rewind to block reads and byte offsets. The block device provides contiguous, fixed-size blocks, and the only permitted access primitive is a block read, which copies an entire block into a cache accessible by the SAM layer.\n\nFundamental base:\n- A block device is an array of blocks of uniform size. If the block size is $B$ bytes and there are $N$ blocks, the device stores $N \\cdot B$ bytes at indices $0$ through $N \\cdot B - 1$.\n- A sequential dataset is a contiguous interval of bytes defined by a start block $S$ and a length $L$ (in bytes), so its valid byte offsets are $p$ with $0 \\le p &lt; L$ relative to the dataset start.\n- The Sequential Access Method (SAM) supports:\n  - open: position the sequential cursor at the beginning of the dataset, i.e., set the current offset to $0$.\n  - next: return the next logical record and advance the cursor.\n  - rewind: reset the cursor to the beginning ($0$), invalidating any cache that depends on the current position.\n- Records are encoded in the dataset as variable-length records with a single-byte length prefix: a record is $1$ byte $\\ell$ (the payload length) followed by $\\ell$ payload bytes. Valid encodings satisfy that the sum over all records of $(1 + \\ell)$ equals $L$.\n\nMapping from byte offsets to the block device:\n- Given a dataset-relative byte offset $p$ with $0 \\le p &lt; L$, the corresponding device block index is\n$$\n\\text{block}(p) = S + \\left\\lfloor \\frac{p}{B} \\right\\rfloor,\n$$\nand the in-block byte offset is\n$$\n\\text{off}(p) = p \\bmod B.\n$$\n- The SAM layer holds a single-block cache. To fetch any byte at offset $p$, compute $\\text{block}(p)$ and $\\text{off}(p)$. If the cache does not currently hold $\\text{block}(p)$, perform exactly one block read of that block into the cache, then return the byte at $\\text{off}(p)$ from the cache. If the cache already holds $\\text{block}(p)$, return the cached byte directly without issuing a new block read.\n- Every block read increments a counter of block read operations. The rewind operation invalidates the cache and resets the block read counter to $0$ for the next pass.\n\nProgram requirements:\n- Implement SAM with the above semantics. The next operation must:\n  - At the current dataset-relative offset $p$, read the length byte $\\ell$ using the mapping rule, then read $\\ell$ payload bytes sequentially, advancing the offset accordingly.\n  - Return a success indicator if a complete record is obtained before exceeding $L$, and a failure indicator if there is no more record (i.e., if $p \\ge L$).\n- To make results purely numeric and reproducible, define the record’s contribution as the sum of its payload byte values. Over a pass, compute the total payload sum and the total number of records. Also count how many block reads occurred during that pass.\n- The only permitted device primitive is a full block read into a cache. No direct per-byte reads from the device memory are allowed except via the cache after a block read.\n\nTest suite:\nConstruct the following four test cases by writing the specified records into the dataset region of a zero-initialized device. Each record is defined as $[\\ell \\mid \\text{payload bytes}]$, meaning a one-byte length $\\ell$ followed by $\\ell$ payload bytes.\n\n- Test case $1$ (happy path with a record crossing a block boundary):\n  - Block size $B = 8$, number of blocks $N = 4$, start block $S = 1$.\n  - Records: $[3 \\mid 1,2,3]$, $[2 \\mid 4,5]$, $[4 \\mid 6,7,8,9]$.\n  - Dataset length $L = 12$ bytes.\n- Test case $2$ (boundary alignment: record ends exactly at block boundary):\n  - Block size $B = 8$, number of blocks $N = 3$, start block $S = 0$.\n  - Records: $[7 \\mid 10,20,30,40,50,60,70]$, $[1 \\mid 255]$.\n  - Dataset length $L = 10$ bytes.\n- Test case $3$ (empty dataset):\n  - Block size $B = 8$, number of blocks $N = 2$, start block $S = 0$.\n  - Records: none.\n  - Dataset length $L = 0$ bytes.\n- Test case $4$ (large record spanning multiple blocks):\n  - Block size $B = 16$, number of blocks $N = 4$, start block $S = 2$.\n  - Records: $[30 \\mid 1,2,3,\\dots,30]$.\n  - Dataset length $L = 31$ bytes.\n\nFor each test case, execute:\n- open,\n- iterate next until end-of-file, computing:\n  - total payload sum over the pass,\n  - number of records,\n  - block read count,\n- rewind,\n- iterate next again to compute a second pass with:\n  - total payload sum over the second pass,\n  - block read count for the second pass.\n\nFinal output specification:\n- Your program should produce a single line of output containing the per-test-case results aggregated as a list of lists. For each test case, output the list $[\\text{sum\\_first}, \\text{count}, \\text{reads\\_first}, \\text{sum\\_second}, \\text{reads\\_second}]$.\n- The overall output must be a single JSON-like list in one line, in the exact format:\n  - Example form: $[[a_1,b_1,c_1,d_1,e_1],[a_2,b_2,c_2,d_2,e_2],[a_3,b_3,c_3,d_3,e_3],[a_4,b_4,c_4,d_4,e_4]]$,\n  - where all $a_i$, $b_i$, $c_i$, $d_i$, $e_i$ are integers.", "solution": "The task is to implement a Sequential Access Method (SAM) on a simulated block device. This requires creating an abstraction layer that provides byte-stream access (`open`, `next`, `rewind`) over a storage medium that is physically organized into fixed-size blocks. The core of the solution involves mapping logical byte offsets to physical block addresses and managing a single-block cache to minimize block read operations.\n\n### Data Structures\n\nTo model the system, we can define the following structures:\n\n1.  **Block Device**: The physical storage medium is represented by an array of blocks. We can model this with a structure containing a pointer to a contiguous memory region, the block size $B$, and the total number of blocks $N$.\n\n2.  **SAM Dataset State**: This structure encapsulates the state of a sequential dataset, including its properties and the current access state. It contains:\n    *   A reference to the underlying `BlockDevice`.\n    *   The dataset parameters: start block $S$ and total length in bytes $L$.\n    *   The current logical position, or cursor, `p`, which is a byte offset relative to the start of the dataset ($0 \\le p < L$).\n    *   A single-block cache and its state: a buffer to hold one block of data and an integer to track the index of the block currently held in the cache. An index of $-1$ can signify an invalid or empty cache.\n    *   A counter for the number of block read operations performed.\n\n### Core Logic: Mapping and Caching\n\nThe fundamental operation is to retrieve a single byte given its dataset-relative offset $p$. This is handled by a helper function that implements the specified mapping and caching logic.\n\n**`read_byte(SAM_Dataset* ds, int p)`**:\nGiven a dataset `ds` and a dataset-relative offset $p$, this function returns the byte value at that position.\n\n1.  **Address Translation**: First, the logical offset $p$ is translated into a physical device address. According to the problem, the device block index and the in-block offset are calculated as:\n    $$\n    \\text{block\\_idx}(p) = S + \\left\\lfloor \\frac{p}{B} \\right\\rfloor\n    $$\n    $$\n    \\text{offset\\_in\\_block}(p) = p \\bmod B\n    $$\n\n2.  **Cache Management**: The function then checks if the required block `block_idx` is already in the cache.\n    *   **Cache Hit**: If `block_idx` equals the cached block index, the block is already loaded. The byte is returned directly from the cache. No block read occurs.\n    *   **Cache Miss**: If `block_idx` is not the currently cached block, a block read must be performed.\n        a. The block read counter is incremented.\n        b. The entire block at `block_idx` is copied from the device's memory into the cache buffer.\n        c. The cached block index is updated to `block_idx`.\n        d. The byte is then returned from the now-updated cache.\n\n### SAM Operations\n\nThe SAM interface functions (`open`, `next`, `rewind`) are implemented using the `read_byte` helper.\n\n1.  **`sam_open(SAM_Dataset* ds)`**: This operation prepares for a pass over the dataset. It simply resets the cursor to the beginning.\n    *   Set `ds->p = 0`.\n    *   Initialize `ds->block_reads = 0`.\n    *   Invalidate the cache by setting `ds->cached_block_index = -1`.\n\n2.  **`sam_rewind(SAM_Dataset* ds)`**: This operation resets the state for a subsequent pass, identical to `sam_open` as per the problem description.\n    *   Set `ds->p = 0`.\n    *   Reset `ds->block_reads = 0`.\n    *   Invalidate the cache by setting `ds->cached_block_index = -1`.\n\n3.  **`sam_next(SAM_Dataset* ds, int* payload_sum)`**: This function reads the next variable-length record.\n    *   **End-of-File Check**: It first checks if the cursor `ds->p` is at or beyond the end of the dataset (`ds->p >= ds->L`). If so, it indicates failure (end-of-file) and returns.\n    *   **Read Length Prefix**: It calls `read_byte(ds, ds->p)` to get the record's length prefix, $\\ell$. The cursor `ds->p` is then incremented.\n    *   **Read Payload**: It enters a loop that iterates $\\ell$ times. In each iteration, it calls `read_byte(ds, ds->p)` to get the next payload byte, adds its value to a running sum for the current record, and increments `ds->p`.\n    *   **Return Value**: The function updates the total payload sum for the pass via the `payload_sum` pointer parameter and returns a success indicator.\n\n### Execution Plan\n\nThe main program will execute the logic for each of the four specified test cases.\n\n1.  **Test Case Setup**: For each test case, allocate memory for the block device and the SAM cache. The device memory is zero-initialized.\n2.  **Data Population**: The record data for the test case is written into the simulated device memory. The data is placed starting at the device byte offset corresponding to the dataset's start block, which is $S \\cdot B$.\n3.  **First Pass**:\n    *   Call `sam_open` to initialize the state.\n    *   Loop, calling `sam_next` until it signals end-of-file.\n    *   Inside the loop, accumulate the total payload sum and increment the record count.\n    *   After the loop, record the final values for `sum_first`, `count`, and `reads_first`.\n4.  **Second Pass**:\n    *   Call `sam_rewind` to reset the state.\n    *   Repeat the `sam_next` loop to re-read the dataset.\n    *   Accumulate the total payload sum for the second pass.\n    *   After the loop, record `sum_second` and `reads_second`.\n5.  **Output Generation**: After processing all test cases, the collected results are printed to standard output in the specified single-line JSON-like format `[[...],[...],...]`.\n6.  **Cleanup**: All dynamically allocated memory is freed for each test case to prevent memory leaks.", "answer": "[[45,3,2,45,2],[535,2,2,535,2],[0,0,0,0,0],[465,1,2,465,2]]", "id": "3682261"}]}