{"hands_on_practices": [{"introduction": "Particle Swarm Optimization (PSO) is a powerful swarm intelligence technique that mimics the collaborative behavior of a flock of birds or a school of fish. This exercise provides a concrete, step-by-step walkthrough of a single PSO iteration, revealing the core mechanics of how particles update their velocity and position based on their own experience and the experience of their neighbors [@problem_id:3589764]. We will also address crucial practical details like parameter normalization and velocity clamping, which are essential for stabilizing the algorithm when applied to complex geophysical inverse problems with parameters of varying scales.", "problem": "A team is using Particle Swarm Optimization (PSO) in a ring neighborhood topology to invert a one-dimensional two-parameter subsurface model for Rayleigh-wave dispersion in a computational geophysics study. The model parameter vector is $x = [V_{s}, H]^{\\top}$, where $V_{s}$ is the shear-wave velocity in $\\mathrm{km/s}$ and $H$ is the layer thickness in $\\mathrm{km}$. To mitigate parameter scale disparity, the algorithm internally uses a normalized parameter $z$ defined by\n$z = D^{-1}(x - x_{\\mathrm{ref}})$,\nwith reference $x_{\\mathrm{ref}} = [2.5, 1.5]^{\\top}$ and $D = \\mathrm{diag}(0.5, 0.5)$, both expressed in the physical units of $x$. The PSO update and velocity clamping are performed entirely in the normalized space and then mapped back to the physical space.\n\nConsider a ring of three particles with the following current positions $x_{i}$, velocities $v_{i}$, personal bests $p_{i}$, and neighborhood bests $n_{i}$, all in the physical space (units as above), where the ring order is $1 \\to 2 \\to 3 \\to 1$:\n- Particle $1$: $x_{1} = [2.2, 1.8]^{\\top}$, $v_{1} = [0.05, -0.02]^{\\top}$, $p_{1} = [2.15, 1.85]^{\\top}$, $n_{1} = [2.95, 1.05]^{\\top}$.\n- Particle $2$: $x_{2} = [2.9, 1.2]^{\\top}$, $v_{2} = [-0.08, 0.04]^{\\top}$, $p_{2} = [2.95, 1.05]^{\\top}$, $n_{2} = [2.35, 1.10]^{\\top}$.\n- Particle $3$: $x_{3} = [2.4, 1.0]^{\\top}$, $v_{3} = [0.02, 0.00]^{\\top}$, $p_{3} = [2.35, 1.10]^{\\top}$, $n_{3} = [2.15, 1.85]^{\\top}$.\n\nThe PSO hyperparameters are inertia weight $w = 0.7$, cognitive acceleration $c_{1} = 1.5$, and social acceleration $c_{2} = 1.2$. Velocity clamping in the normalized space is elementwise with $v_{\\max} = [0.9, 0.9]^{\\top}$. The stochastic multipliers $r_{1}$ and $r_{2}$ are independently drawn for each particle and dimension and are fixed by the following random seeds for this iteration:\n- For particle $1$: $r_{1} = [0.62, 0.15]^{\\top}$, $r_{2} = [0.35, 0.78]^{\\top}$.\n- For particle $2$: $r_{1} = [0.27, 0.91]^{\\top}$, $r_{2} = [0.58, 0.22]^{\\top}$.\n- For particle $3$: $r_{1} = [0.83, 0.40]^{\\top}$, $r_{2} = [0.11, 0.66]^{\\top}$.\n\nCompute the next-iteration velocities $v_{i}^{+}$ and positions $x_{i}^{+}$ in the physical space for all three particles, given that the canonical PSO velocity-position update is applied in the normalized space with the above ring-neighborhood bests and velocity clamping, followed by mapping back to the physical space.\n\nProvide your final result as a single row matrix in the order\n$\\big[v_{1,1}^{+}, v_{1,2}^{+}, x_{1,1}^{+}, x_{1,2}^{+}, v_{2,1}^{+}, v_{2,2}^{+}, x_{2,1}^{+}, x_{2,2}^{+}, v_{3,1}^{+}, v_{3,2}^{+}, x_{3,1}^{+}, x_{3,2}^{+}\\big]$.\nRound all numerical entries to four significant figures. Do not include units in your final boxed answer, but interpret $V_{s}$ in $\\mathrm{km/s}$ and $H$ in $\\mathrm{km}$ throughout the computation.", "solution": "### Step 1: Extract Givens\n- **Model Parameters**: $x = [V_{s}, H]^{\\top}$, where $V_s$ is shear-wave velocity in $\\mathrm{km/s}$ and $H$ is layer thickness in $\\mathrm{km}$.\n- **Normalization Transformation**: $z = D^{-1}(x - x_{\\mathrm{ref}})$.\n- **Reference Vector**: $x_{\\mathrm{ref}} = [2.5, 1.5]^{\\top}$ in physical units.\n- **Scaling Matrix**: $D = \\mathrm{diag}(0.5, 0.5)$ in physical units.\n- **Particle Data (Physical Space)**:\n  - Particle $1$: $x_{1} = [2.2, 1.8]^{\\top}$, $v_{1} = [0.05, -0.02]^{\\top}$, $p_{1} = [2.15, 1.85]^{\\top}$, $n_{1} = [2.95, 1.05]^{\\top}$.\n  - Particle $2$: $x_{2} = [2.9, 1.2]^{\\top}$, $v_{2} = [-0.08, 0.04]^{\\top}$, $p_{2} = [2.95, 1.05]^{\\top}$, $n_{2} = [2.35, 1.10]^{\\top}$.\n  - Particle $3$: $x_{3} = [2.4, 1.0]^{\\top}$, $v_{3} = [0.02, 0.00]^{\\top}$, $p_{3} = [2.35, 1.10]^{\\top}$, $n_{3} = [2.15, 1.85]^{\\top}$.\n- **PSO Hyperparameters**:\n  - Inertia weight: $w = 0.7$.\n  - Cognitive acceleration: $c_{1} = 1.5$.\n  - Social acceleration: $c_{2} = 1.2$.\n- **Velocity Clamping (Normalized Space)**: $v_{\\max} = [0.9, 0.9]^{\\top}$.\n- **Stochastic Multipliers**:\n  - For particle $1$: $r_{1} = [0.62, 0.15]^{\\top}$, $r_{2} = [0.35, 0.78]^{\\top}$.\n  - For particle $2$: $r_{1} = [0.27, 0.91]^{\\top}$, $r_{2} = [0.58, 0.22]^{\\top}$.\n  - For particle $3$: $r_{1} = [0.83, 0.40]^{\\top}$, $r_{2} = [0.11, 0.66]^{\\top}$.\n- **Task**: Compute the next-iteration velocities $v_{i}^{+}$ and positions $x_{i}^{+}$ in the physical space for all three particles. Round the final answer to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard application of the Particle Swarm Optimization (PSO) algorithm to an inverse problem in computational geophysics. All necessary parameters, initial conditions, and algorithmic rules are provided. The values are numerically consistent and do not violate any mathematical or physical principles. The problem specifies that the PSO updates are performed in a normalized space, which is a common technique. The provision of specific neighborhood bests ($n_i$) for each particle is a given condition of the algorithm's state at a particular iteration, and while their pattern might be specific, it does not constitute a contradiction. The problem is self-contained and algorithmically executable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe core of the problem is to apply the PSO update equations in a normalized parameter space and then transform the results back into the physical space.\n\nFirst, we define the transformation equations. Let a vector in the physical space be denoted by a subscript $x$ (e.g., $x_i$, $v_x$) and in the normalized space by a subscript $z$ (e.g., $z_i$, $v_z$).\nThe transformation from physical to normalized space is given by:\n$z = D^{-1}(x - x_{\\mathrm{ref}})$\nThe velocity transformation is found by differentiating the position transformation: $v_z = D^{-1}v_x$.\nGiven $D = \\mathrm{diag}(0.5, 0.5)$, its inverse is $D^{-1} = \\mathrm{diag}(2, 2)$.\nSo, $z = 2(x - x_{\\mathrm{ref}})$ and $v_z = 2v_x$.\n\nThe transformation from normalized to physical space is:\n$x = Dz + x_{\\mathrm{ref}} = 0.5z + x_{\\mathrm{ref}}$\n$v_x = Dv_z = 0.5v_z$\n\nThe canonical PSO update equations in the normalized space are:\n1. Velocity update: $v_{z,i}^{+} = w v_{z,i} + c_{1} (r_{1,i} \\odot (p_{z,i} - z_i)) + c_{2} (r_{2,i} \\odot (n_{z,i} - z_i))$\n2. Velocity clamping: Each component of $v_{z,i}^{+}$ is clamped to the range $[-v_{\\max,j}, v_{\\max,j}]$.\n3. Position update: $z_i^{+} = z_i + v_{z,i}^{+}$\nHere, $\\odot$ denotes element-wise vector multiplication.\n\nWe will now process each particle individually.\n\n**Particle 1**\n\n1.  **Transform to Normalized Space**:\n    $x_{\\mathrm{ref}} = [2.5, 1.5]^{\\top}$.\n    $z_1 = 2(x_1 - x_{\\mathrm{ref}}) = 2([2.2, 1.8]^{\\top} - [2.5, 1.5]^{\\top}) = 2([-0.3, 0.3]^{\\top}) = [-0.6, 0.6]^{\\top}$.\n    $v_{z,1} = 2v_1 = 2([0.05, -0.02]^{\\top}) = [0.1, -0.04]^{\\top}$.\n    $p_{z,1} = 2(p_1 - x_{\\mathrm{ref}}) = 2([2.15, 1.85]^{\\top} - [2.5, 1.5]^{\\top}) = 2([-0.35, 0.35]^{\\top}) = [-0.7, 0.7]^{\\top}$.\n    $n_{z,1} = 2(n_1 - x_{\\mathrm{ref}}) = 2([2.95, 1.05]^{\\top} - [2.5, 1.5]^{\\top}) = 2([0.45, -0.45]^{\\top}) = [0.9, -0.9]^{\\top}$.\n\n2.  **Velocity Update (Normalized Space)**:\n    The cognitive term is $p_{z,1} - z_1 = [-0.7, 0.7]^{\\top} - [-0.6, 0.6]^{\\top} = [-0.1, 0.1]^{\\top}$.\n    The social term is $n_{z,1} - z_1 = [0.9, -0.9]^{\\top} - [-0.6, 0.6]^{\\top} = [1.5, -1.5]^{\\top}$.\n    The un-clamped velocity $v'_{z,1}$ is:\n    $v'_{z,1} = 0.7 [0.1, -0.04]^{\\top} + 1.5 ([0.62, 0.15]^{\\top} \\odot [-0.1, 0.1]^{\\top}) + 1.2 ([0.35, 0.78]^{\\top} \\odot [1.5, -1.5]^{\\top})$\n    $v'_{z,1} = [0.07, -0.028]^{\\top} + 1.5 [-0.062, 0.015]^{\\top} + 1.2 [0.525, -1.17]^{\\top}$\n    $v'_{z,1} = [0.07, -0.028]^{\\top} + [-0.093, 0.0225]^{\\top} + [0.63, -1.404]^{\\top}$\n    $v'_{z,1} = [0.07-0.093+0.63, -0.028+0.0225-1.404]^{\\top} = [0.607, -1.4095]^{\\top}$.\n\n3.  **Velocity Clamping**:\n    $v_{\\max} = [0.9, 0.9]^{\\top}$.\n    $v_{z,1,1}^{+} = 0.607$ (since $|0.607| \\le 0.9$).\n    $v_{z,1,2}^{+} = -0.9$ (since $|-1.4095| > 0.9$).\n    So, the clamped velocity is $v_{z,1}^{+} = [0.607, -0.9]^{\\top}$.\n\n4.  **Position Update (Normalized Space)**:\n    $z_1^{+} = z_1 + v_{z,1}^{+} = [-0.6, 0.6]^{\\top} + [0.607, -0.9]^{\\top} = [0.007, -0.3]^{\\top}$.\n\n5.  **Transform back to Physical Space**:\n    $v_{1}^{+} = 0.5 v_{z,1}^{+} = 0.5 [0.607, -0.9]^{\\top} = [0.3035, -0.45]^{\\top}$.\n    $x_{1}^{+} = 0.5 z_1^{+} + x_{\\mathrm{ref}} = 0.5 [0.007, -0.3]^{\\top} + [2.5, 1.5]^{\\top} = [0.0035, -0.15]^{\\top} + [2.5, 1.5]^{\\top} = [2.5035, 1.35]^{\\top}$.\n\n**Particle 2**\n\n1.  **Transform to Normalized Space**:\n    $z_2 = 2(x_2 - x_{\\mathrm{ref}}) = 2([2.9, 1.2]^{\\top} - [2.5, 1.5]^{\\top}) = 2([0.4, -0.3]^{\\top}) = [0.8, -0.6]^{\\top}$.\n    $v_{z,2} = 2v_2 = 2([-0.08, 0.04]^{\\top}) = [-0.16, 0.08]^{\\top}$.\n    $p_{z,2} = 2(p_2 - x_{\\mathrm{ref}}) = 2([2.95, 1.05]^{\\top} - [2.5, 1.5]^{\\top}) = 2([0.45, -0.45]^{\\top}) = [0.9, -0.9]^{\\top}$.\n    $n_{z,2} = 2(n_2 - x_{\\mathrm{ref}}) = 2([2.35, 1.10]^{\\top} - [2.5, 1.5]^{\\top}) = 2([-0.15, -0.4]^{\\top}) = [-0.3, -0.8]^{\\top}$.\n\n2.  **Velocity Update (Normalized Space)**:\n    The cognitive term is $p_{z,2} - z_2 = [0.9, -0.9]^{\\top} - [0.8, -0.6]^{\\top} = [0.1, -0.3]^{\\top}$.\n    The social term is $n_{z,2} - z_2 = [-0.3, -0.8]^{\\top} - [0.8, -0.6]^{\\top} = [-1.1, -0.2]^{\\top}$.\n    $v'_{z,2} = 0.7 [-0.16, 0.08]^{\\top} + 1.5 ([0.27, 0.91]^{\\top} \\odot [0.1, -0.3]^{\\top}) + 1.2 ([0.58, 0.22]^{\\top} \\odot [-1.1, -0.2]^{\\top})$\n    $v'_{z,2} = [-0.112, 0.056]^{\\top} + 1.5 [0.027, -0.273]^{\\top} + 1.2 [-0.638, -0.044]^{\\top}$\n    $v'_{z,2} = [-0.112, 0.056]^{\\top} + [0.0405, -0.4095]^{\\top} + [-0.7656, -0.0528]^{\\top}$\n    $v'_{z,2} = [-0.112+0.0405-0.7656, 0.056-0.4095-0.0528]^{\\top} = [-0.8371, -0.4063]^{\\top}$.\n\n3.  **Velocity Clamping**:\n    $|v'_{z,2,1}| = 0.8371 \\le 0.9$ and $|v'_{z,2,2}| = 0.4063 \\le 0.9$. No clamping is needed.\n    $v_{z,2}^{+} = [-0.8371, -0.4063]^{\\top}$.\n\n4.  **Position Update (Normalized Space)**:\n    $z_2^{+} = z_2 + v_{z,2}^{+} = [0.8, -0.6]^{\\top} + [-0.8371, -0.4063]^{\\top} = [-0.0371, -1.0063]^{\\top}$.\n\n5.  **Transform back to Physical Space**:\n    $v_{2}^{+} = 0.5 v_{z,2}^{+} = 0.5 [-0.8371, -0.4063]^{\\top} = [-0.41855, -0.20315]^{\\top}$.\n    $x_{2}^{+} = 0.5 z_2^{+} + x_{\\mathrm{ref}} = 0.5 [-0.0371, -1.0063]^{\\top} + [2.5, 1.5]^{\\top} = [-0.01855, -0.50315]^{\\top} + [2.5, 1.5]^{\\top} = [2.48145, 0.99685]^{\\top}$.\n\n**Particle 3**\n\n1.  **Transform to Normalized Space**:\n    $z_3 = 2(x_3 - x_{\\mathrm{ref}}) = 2([2.4, 1.0]^{\\top} - [2.5, 1.5]^{\\top}) = 2([-0.1, -0.5]^{\\top}) = [-0.2, -1.0]^{\\top}$.\n    $v_{z,3} = 2v_3 = 2([0.02, 0.00]^{\\top}) = [0.04, 0.0]^{\\top}$.\n    $p_{z,3} = 2(p_3 - x_{\\mathrm{ref}}) = 2([2.35, 1.10]^{\\top} - [2.5, 1.5]^{\\top}) = 2([-0.15, -0.4]^{\\top}) = [-0.3, -0.8]^{\\top}$.\n    $n_{z,3} = 2(n_3 - x_{\\mathrm{ref}}) = 2([2.15, 1.85]^{\\top} - [2.5, 1.5]^{\\top}) = 2([-0.35, 0.35]^{\\top}) = [-0.7, 0.7]^{\\top}$.\n\n2.  **Velocity Update (Normalized Space)**:\n    The cognitive term is $p_{z,3} - z_3 = [-0.3, -0.8]^{\\top} - [-0.2, -1.0]^{\\top} = [-0.1, 0.2]^{\\top}$.\n    The social term is $n_{z,3} - z_3 = [-0.7, 0.7]^{\\top} - [-0.2, -1.0]^{\\top} = [-0.5, 1.7]^{\\top}$.\n    $v'_{z,3} = 0.7 [0.04, 0.0]^{\\top} + 1.5 ([0.83, 0.40]^{\\top} \\odot [-0.1, 0.2]^{\\top}) + 1.2 ([0.11, 0.66]^{\\top} \\odot [-0.5, 1.7]^{\\top})$\n    $v'_{z,3} = [0.028, 0.0]^{\\top} + 1.5 [-0.083, 0.08]^{\\top} + 1.2 [-0.055, 1.122]^{\\top}$\n    $v'_{z,3} = [0.028, 0.0]^{\\top} + [-0.1245, 0.12]^{\\top} + [-0.066, 1.3464]^{\\top}$\n    $v'_{z,3} = [0.028-0.1245-0.066, 0.0+0.12+1.3464]^{\\top} = [-0.1625, 1.4664]^{\\top}$.\n\n3.  **Velocity Clamping**:\n    $|v'_{z,3,1}| = 0.1625 \\le 0.9$.\n    $|v'_{z,3,2}| = 1.4664 > 0.9$, so it is clamped to $0.9$.\n    $v_{z,3}^{+} = [-0.1625, 0.9]^{\\top}$.\n\n4.  **Position Update (Normalized Space)**:\n    $z_3^{+} = z_3 + v_{z,3}^{+} = [-0.2, -1.0]^{\\top} + [-0.1625, 0.9]^{\\top} = [-0.3625, -0.1]^{\\top}$.\n\n5.  **Transform back to Physical Space**:\n    $v_{3}^{+} = 0.5 v_{z,3}^{+} = 0.5 [-0.1625, 0.9]^{\\top} = [-0.08125, 0.45]^{\\top}$.\n    $x_{3}^{+} = 0.5 z_3^{+} + x_{\\mathrm{ref}} = 0.5 [-0.3625, -0.1]^{\\top} + [2.5, 1.5]^{\\top} = [-0.18125, -0.05]^{\\top} + [2.5, 1.5]^{\\top} = [2.31875, 1.45]^{\\top}$.\n\n**Final Assembly and Rounding**\nWe compile the computed vectors and round each entry to four significant figures.\n\n-   $v_{1}^{+} = [0.3035, -0.45]^{\\top} \\to [0.3035, -0.4500]^{\\top}$\n-   $x_{1}^{+} = [2.5035, 1.35]^{\\top} \\to [2.504, 1.350]^{\\top}$\n-   $v_{2}^{+} = [-0.41855, -0.20315]^{\\top} \\to [-0.4186, -0.2032]^{\\top}$\n-   $x_{2}^{+} = [2.48145, 0.99685]^{\\top} \\to [2.481, 0.9969]^{\\top}$\n-   $v_{3}^{+} = [-0.08125, 0.45]^{\\top} \\to [-0.08125, 0.4500]^{\\top}$\n-   $x_{3}^{+} = [2.31875, 1.45]^{\\top} \\to [2.319, 1.450]^{\\top}$\n\nThe final result is the flattened row matrix of these components.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.3035 & -0.4500 & 2.504 & 1.350 & -0.4186 & -0.2032 & 2.481 & 0.9969 & -0.08125 & 0.4500 & 2.319 & 1.450\n\\end{pmatrix}\n}\n$$", "id": "3589764"}, {"introduction": "Differential Evolution (DE) stands out in the family of evolutionary algorithms for its elegant simplicity and remarkable effectiveness in global optimization. In this practice, you will manually execute one full generation of the \"DE/best/1/bin\" variant, one of the most common DE strategies [@problem_id:3589833]. By calculating the mutant vector, performing binomial crossover, and applying the greedy selection rule, you will gain a hands-on appreciation for how this algorithm efficiently explores the parameter space to locate minima.", "problem": "Consider a toy global inversion subproblem arising in computational geophysics for recovering a two-parameter model vector $x \\in \\mathbb{R}^{2}$ that encodes a simplified pair of normalized subsurface properties (for example, two-layer log-impedances). Assume that at this early optimization stage, the data misfit is already minimized within tolerance so that the regularization dominates the objective. Use the quadratic Tikhonov model norm $J(x) = \\|x\\|_{2}^{2}$ as the scalar objective to be minimized.\n\nYou will perform one generation of the Differential Evolution (DE) algorithm, specifically the \"DE/best/1/bin\" variant. The current population is \n$$\\mathcal{P}^{0} = \\{(0,0), (1,0), (0,1)\\},$$\nwith differential weight $F = 0.8$ and binomial crossover rate $CR = 0.9$. The greedy selection rule is: for each target $x_{i}$, replace $x_{i}$ by its trial vector $u_{i}$ if and only if $J(u_{i}) < J(x_{i})$; otherwise retain $x_{i}$.\n\nFor mutation (DE/best/1), let $x_{\\mathrm{best}}$ be the population member with the smallest objective value under $J$. For each target $x_{i}$, construct the mutant\n$$v_{i} = x_{\\mathrm{best}} + F\\left(x_{r_{1}} - x_{r_{2}}\\right),$$\nwhere $x_{r_{1}}$ and $x_{r_{2}}$ are the two distinct donors drawn deterministically as the two members of the current population that are not equal to the target $x_{i}$, ordered lexicographically such that $x_{r_{1}}$ is the lexicographically smaller of the pair and $x_{r_{2}}$ the larger. This donor choice may include $x_{\\mathrm{best}}$ if it is not the target.\n\nFor binomial crossover, form the trial vector $u_{i}$ componentwise as\n$$u_{i,j} = \n\\begin{cases}\nv_{i,j}, & \\text{if } r_{i,j} \\leq CR \\text{ or } j=j_{\\mathrm{rand}}(i),\\\\\nx_{i,j}, & \\text{otherwise},\n\\end{cases}$$\nwhere $r_{i,j} \\sim \\mathrm{Uniform}(0,1)$ are fixed draws and $j_{\\mathrm{rand}}(i)$ enforces at least one mutant component per trial.\n\nUse the following deterministic random draws and forced indices:\n- For target $x_{i} = (0,0)$, take $j_{\\mathrm{rand}}(i) = 1$ and $(r_{i,1}, r_{i,2}) = (0.10, 0.20)$.\n- For target $x_{i} = (1,0)$, take $j_{\\mathrm{rand}}(i) = 1$ and $(r_{i,1}, r_{i,2}) = (0.10, 0.95)$.\n- For target $x_{i} = (0,1)$, take $j_{\\mathrm{rand}}(i) = 2$ and $(r_{i,1}, r_{i,2}) = (0.95, 0.10)$.\n\nCarry out this single DE generation step explicitly: identify $x_{\\mathrm{best}}$, compute mutants $v_{i}$, compute trial vectors $u_{i}$ via binomial crossover, apply greedy selection against $J(x)=\\|x\\|_{2}^{2}$, and obtain the selected population $\\mathcal{P}^{1}$. Finally, report the single scalar quantity\n$$S = \\sum_{x \\in \\mathcal{P}^{1}} J(x)$$\nas an exact decimal (unitless). No rounding is required, and no units should be included in the reported value.", "solution": "### Step 1: Extract Givens\n-   Objective function to minimize: $J(x) = \\|x\\|_{2}^{2}$ for a model vector $x \\in \\mathbb{R}^{2}$.\n-   Algorithm: One generation of Differential Evolution (DE), \"DE/best/1/bin\" variant.\n-   Initial population: $\\mathcal{P}^{0} = \\{(0,0), (1,0), (0,1)\\}$.\n-   Differential weight: $F = 0.8$.\n-   Binomial crossover rate: $CR = 0.9$.\n-   Selection rule: For a target vector $x_{i}$, it is replaced by its trial vector $u_{i}$ if and only if $J(u_{i}) < J(x_{i})$.\n-   Mutation rule (\"DE/best/1\"): $v_{i} = x_{\\mathrm{best}} + F\\left(x_{r_{1}} - x_{r_{2}}\\right)$, where $x_{\\mathrm{best}}$ is the population member with the lowest objective value.\n-   Donor selection: For a target $x_{i}$, the donors $x_{r_{1}}$ and $x_{r_{2}}$ are the two other distinct members of the population, ordered lexicographically such that $x_{r_{1}}$ is smaller than $x_{r_{2}}$.\n-   Crossover rule (binomial):\n    $$u_{i,j} = \\begin{cases} v_{i,j}, & \\text{if } r_{i,j} \\leq CR \\text{ or } j=j_{\\mathrm{rand}}(i),\\\\ x_{i,j}, & \\text{otherwise}, \\end{cases}$$\n    where $r_{i,j}$ are random draws and $j_{\\mathrm{rand}}(i)$ is a forced index.\n-   Deterministic draws and indices:\n    -   Target $x_{i} = (0,0)$: $j_{\\mathrm{rand}}(i) = 1$, $(r_{i,1}, r_{i,2}) = (0.10, 0.20)$.\n    -   Target $x_{i} = (1,0)$: $j_{\\mathrm{rand}}(i) = 1$, $(r_{i,1}, r_{i,2}) = (0.10, 0.95)$.\n    -   Target $x_{i} = (0,1)$: $j_{\\mathrm{rand}}(i) = 2$, $(r_{i,1}, r_{i,2}) = (0.95, 0.10)$.\n-   Required output: The scalar sum $S = \\sum_{x \\in \\mathcal{P}^{1}} J(x)$, where $\\mathcal{P}^{1}$ is the population after one generation.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as it describes a standard application of a well-known metaheuristic optimization algorithm (Differential Evolution) to a common problem in computational science (Tikhonov-regularized inversion). The objective function is a standard quadratic norm. The problem is well-posed; it provides all necessary parameters, initial conditions, and deterministic rules (including fixed \"random\" numbers and a deterministic donor selection protocol) to compute a unique result. The language is precise and objective. The problem is self-contained and free from internal contradictions. The population size of $3$ is sufficient for the \"DE/best/1\" scheme, which requires a target vector and two distinct donor vectors for mutation.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe solution proceeds by performing one generation of the DE algorithm. Let the initial population be $\\mathcal{P}^{0} = \\{x_1, x_2, x_3\\}$, where $x_1 = (0,0)$, $x_2 = (1,0)$, and $x_3 = (0,1)$. The objective function is $J(x) = x_1^2 + x_2^2$.\n\nFirst, we evaluate the objective function for each member of the initial population:\n$J(x_1) = J(0,0) = 0^2 + 0^2 = 0$.\n$J(x_2) = J(1,0) = 1^2 + 0^2 = 1$.\n$J(x_3) = J(0,1) = 0^2 + 1^2 = 1$.\n\nThe best vector in the population, $x_{\\mathrm{best}}$, is the one with the minimum objective function value. Here, $x_{\\mathrm{best}} = x_1 = (0,0)$, with $J(x_{\\mathrm{best}}) = 0$.\n\nNow, we iterate through each of the three target vectors in $\\mathcal{P}^{0}$ to generate the new population $\\mathcal{P}^{1}$.\n\n**1. Target vector $x_1 = (0,0)$**\n-   **Mutation:** The other two population members are $(0,1)$ and $(1,0)$. Ordered lexicographically, they are $x_{r_1} = (0,1)$ and $x_{r_2} = (1,0)$. The mutant vector $v_1$ is:\n    $$v_1 = x_{\\mathrm{best}} + F(x_{r_1} - x_{r_2}) = (0,0) + 0.8((0,1) - (1,0)) = 0.8(-1, 1) = (-0.8, 0.8)$$\n-   **Crossover:** We form the trial vector $u_1 = (u_{1,1}, u_{1,2})$ from target $x_1=(0,0)$ and mutant $v_1=(-0.8, 0.8)$. The given parameters are $j_{\\mathrm{rand}}(1) = 1$, $(r_{1,1}, r_{1,2})=(0.10, 0.20)$, and $CR=0.9$.\n    -   For component $j=1$: $j=j_{\\mathrm{rand}}(1)$, so we must take the mutant's component: $u_{1,1} = v_{1,1} = -0.8$.\n    -   For component $j=2$: $j \\neq j_{\\mathrm{rand}}(1)$. We check if $r_{1,2} \\leq CR$. Since $0.20 \\leq 0.9$, the condition is met, so we take the mutant's component: $u_{1,2} = v_{1,2} = 0.8$.\n    -   The trial vector is $u_1 = (-0.8, 0.8)$.\n-   **Selection:** We compare $J(u_1)$ with $J(x_1)$.\n    $J(u_1) = (-0.8)^2 + (0.8)^2 = 0.64 + 0.64 = 1.28$.\n    $J(x_1) = 0$.\n    Since $J(u_1) \\not< J(x_1)$ (i.e., $1.28 \\not< 0$), the trial vector $u_1$ is discarded, and $x_1$ is retained. The first member of $\\mathcal{P}^{1}$ is $(0,0)$.\n\n**2. Target vector $x_2 = (1,0)$**\n-   **Mutation:** The other two population members are $(0,0)$ and $(0,1)$. Ordered lexicographically, they are $x_{r_1} = (0,0)$ and $x_{r_2} = (0,1)$. The mutant vector $v_2$ is:\n    $$v_2 = x_{\\mathrm{best}} + F(x_{r_1} - x_{r_2}) = (0,0) + 0.8((0,0) - (0,1)) = 0.8(0, -1) = (0, -0.8)$$\n-   **Crossover:** We form the trial vector $u_2 = (u_{2,1}, u_{2,2})$ from target $x_2=(1,0)$ and mutant $v_2=(0, -0.8)$. The given parameters are $j_{\\mathrm{rand}}(2) = 1$, $(r_{2,1}, r_{2,2})=(0.10, 0.95)$, and $CR=0.9$.\n    -   For component $j=1$: $j=j_{\\mathrm{rand}}(2)$, so we must take the mutant's component: $u_{2,1} = v_{2,1} = 0$.\n    -   For component $j=2$: $j \\neq j_{\\mathrm{rand}}(2)$. We check if $r_{2,2} \\leq CR$. Since $0.95 \\not\\leq 0.9$, the condition is not met, so we take the target's component: $u_{2,2} = x_{2,2} = 0$.\n    -   The trial vector is $u_2 = (0, 0)$.\n-   **Selection:** We compare $J(u_2)$ with $J(x_2)$.\n    $J(u_2) = 0^2 + 0^2 = 0$.\n    $J(x_2) = 1$.\n    Since $J(u_2) < J(x_2)$ (i.e., $0 < 1$), the trial vector $u_2$ replaces $x_2$. The second member of $\\mathcal{P}^{1}$ is $(0,0)$.\n\n**3. Target vector $x_3 = (0,1)$**\n-   **Mutation:** The other two population members are $(0,0)$ and $(1,0)$. Ordered lexicographically, they are $x_{r_1} = (0,0)$ and $x_{r_2} = (1,0)$. The mutant vector $v_3$ is:\n    $$v_3 = x_{\\mathrm{best}} + F(x_{r_1} - x_{r_2}) = (0,0) + 0.8((0,0) - (1,0)) = 0.8(-1, 0) = (-0.8, 0)$$\n-   **Crossover:** We form the trial vector $u_3 = (u_{3,1}, u_{3,2})$ from target $x_3=(0,1)$ and mutant $v_3=(-0.8, 0)$. The given parameters are $j_{\\mathrm{rand}}(3) = 2$, $(r_{3,1}, r_{3,2})=(0.95, 0.10)$, and $CR=0.9$.\n    -   For component $j=1$: $j \\neq j_{\\mathrm{rand}}(3)$. We check if $r_{3,1} \\leq CR$. Since $0.95 \\not\\leq 0.9$, the condition is not met, so we take the target's component: $u_{3,1} = x_{3,1} = 0$.\n    -   For component $j=2$: $j=j_{\\mathrm{rand}}(3)$, so we must take the mutant's component: $u_{3,2} = v_{3,2} = 0$.\n    -   The trial vector is $u_3 = (0, 0)$.\n-   **Selection:** We compare $J(u_3)$ with $J(x_3)$.\n    $J(u_3) = 0^2 + 0^2 = 0$.\n    $J(x_3) = 1$.\n    Since $J(u_3) < J(x_3)$ (i.e., $0 < 1$), the trial vector $u_3$ replaces $x_3$. The third member of $\\mathcal{P}^{1}$ is $(0,0)$.\n\nThe population after one generation is $\\mathcal{P}^{1} = \\{(0,0), (0,0), (0,0)\\}$.\nThe final step is to calculate the sum $S$ of the objective function values for all members of $\\mathcal{P}^{1}$.\n$$S = \\sum_{x \\in \\mathcal{P}^{1}} J(x) = J(0,0) + J(0,0) + J(0,0) = 0 + 0 + 0 = 0$$\nThe final result is required as an exact decimal.", "answer": "$$\\boxed{0.0}$$", "id": "3589833"}, {"introduction": "Ant Colony Optimization (ACO) translates the ingenious foraging strategy of ants into a powerful algorithm for solving combinatorial optimization problems, especially those on graphs. This problem simulates the journey of a single ant finding a path in a discretized medium, a direct analogue to tasks like seismic ray-path selection in tomography [@problem_id:3589781]. You will calculate the probabilistic decisions the ant makes based on pheromone trails and heuristic information, and then update the pheromone levels, demonstrating the positive feedback loop that is central to ACO's success.", "problem": "Consider a ray-path selection subproblem in travel-time tomography where an ant-based metaheuristic is used to approximate least-time paths through a discretized medium. Let the discretized medium be represented by a directed graph with nodes $s$ (source), $a$, $b$, and $g$ (receiver). The available directed edges and their travel times (in seconds) are: $s \\to a$ with $t_{s a} = 2.4$, $s \\to b$ with $t_{s b} = 1.6$, $a \\to g$ with $t_{a g} = 3.0$, and $b \\to g$ with $t_{b g} = 4.2$. Assume no other edges are available, the ant stops upon reaching $g$, and revisiting nodes is disallowed.\n\nAn Ant Colony Optimization (ACO) iteration proceeds as follows. At node $i$, the probability to move to a neighboring node $j \\in \\mathcal{N}(i)$ is given by the normalized product of pheromone and heuristic, using the rule\n$$\np_{i j} \\propto \\tau_{i j}^{\\alpha} \\, \\eta_{i j}^{\\beta},\n$$\nwith local heuristic $\\eta_{i j} = \\frac{1}{t_{i j}}$, and transition probabilities obtained by normalizing over all outgoing edges from $i$. Initially, all pheromones are uniform: $\\tau_{i j} = \\tau_{0}$ for every available edge, where $\\tau_{0} = 0.8$. Use parameters $\\alpha = 1$ and $\\beta = 2$.\n\nA single ant starts at $s$ and uses roulette-wheel sampling to select its next node. The random number used for sampling at $s$ is $u_{1} = 0.28$, drawn from a continuous uniform distribution on $[0, 1]$, and the ant must then continue until it reaches $g$. After the ant completes its path, apply global evaporation and deposition with evaporation coefficient $\\rho = 0.25$ and deposition constant $Q = 1.5$ according to the update rule\n$$\n\\tau_{i j} \\leftarrow\n\\begin{cases}\n(1 - \\rho)\\,\\tau_{i j} + \\dfrac{Q}{T_{\\text{path}}} & \\text{if the edge } (i,j) \\text{ lies on the sampled path}, \\\\\n(1 - \\rho)\\,\\tau_{i j} & \\text{otherwise},\n\\end{cases}\n$$\nwhere $T_{\\text{path}}$ is the total travel time along the sampled path.\n\nStarting from the given initialization and parameters, perform one complete iteration: compute the antâ€™s transition probabilities at $s$, use $u_{1}$ to sample the edge taken from $s$, determine the resulting path and its total travel time $T_{\\text{path}}$, and update all pheromones according to the stated rule. What is the updated pheromone value on edge $s \\to a$ after this single iteration? Express the answer as a single exact number without units.", "solution": "### Step 1: Extract Givens\n- **Nodes**: $s$ (source), $a$, $b$, $g$ (receiver).\n- **Edges and Travel Times**: $s \\to a$ with $t_{sa} = 2.4$ s; $s \\to b$ with $t_{sb} = 1.6$ s; $a \\to g$ with $t_{ag} = 3.0$ s; $b \\to g$ with $t_{bg} = 4.2$ s.\n- **Constraints**: No other edges are available; the ant stops at $g$; revisiting nodes is disallowed.\n- **ACO Transition Rule**: $p_{ij} \\propto \\tau_{ij}^{\\alpha} \\, \\eta_{ij}^{\\beta}$.\n- **Heuristic**: $\\eta_{ij} = \\frac{1}{t_{ij}}$.\n- **Initial Pheromones**: $\\tau_{ij} = \\tau_{0} = 0.8$ for all edges.\n- **ACO Parameters**: $\\alpha = 1$, $\\beta = 2$.\n- **Random Number**: $u_{1} = 0.28$ drawn from $\\mathcal{U}[0, 1]$.\n- **Pheromone Update Rule**:\n$$\n\\tau_{i j} \\leftarrow\n\\begin{cases}\n(1 - \\rho)\\,\\tau_{i j} + \\dfrac{Q}{T_{\\text{path}}} & \\text{if the edge } (i,j) \\text{ lies on the sampled path}, \\\\\n(1 - \\rho)\\,\\tau_{i j} & \\text{otherwise},\n\\end{cases}\n$$\n- **Update Parameters**: Evaporation coefficient $\\rho = 0.25$; deposition constant $Q = 1.5$.\n- **Objective**: Find the updated pheromone value on edge $s \\to a$ after one complete iteration.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n- **Scientifically Grounded**: The problem describes a standard computational procedure, Ant Colony Optimization (ACO), which is a well-established metaheuristic in computer science and operations research. Its application to travel-time tomography is a valid and recognized area of research in computational geophysics. The formulas provided for transition probability and pheromone update are standard in ACO literature.\n- **Well-Posed**: The problem is fully specified. All necessary parameters ($\\alpha$, $\\beta$, $\\rho$, $Q$, $\\tau_0$), initial conditions (graph structure, travel times), and the specific random number ($u_1$) are provided. This setup ensures that a unique, deterministic sequence of calculations leads to a single answer.\n- **Objective**: The problem is stated using precise mathematical and algorithmic language. All quantities are defined, and there are no subjective or ambiguous terms.\n\nThe problem does not violate any of the invalidity criteria. It is a well-defined computational problem grounded in established scientific principles.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A step-by-step solution is now provided.\n\n### Solution Derivation\n\nThe solution requires performing one full iteration of the Ant Colony Optimization algorithm as described.\n\n**1. Calculate Transition Probabilities at Node `s`**\n\nAn ant at node $s$ can move to either node $a$ or node $b$. The probability of choosing an edge $(i, j)$ is proportional to $\\tau_{ij}^{\\alpha} \\eta_{ij}^{\\beta}$. We first calculate this desirability term for each possible move from $s$.\n\nThe parameters are $\\alpha = 1$ and $\\beta = 2$. The initial pheromone is $\\tau_{sa} = \\tau_{sb} = \\tau_0 = 0.8$.\n\nThe heuristic values $\\eta_{ij} = \\frac{1}{t_{ij}}$ are:\n- For edge $s \\to a$: $\\eta_{sa} = \\frac{1}{2.4}$.\n- For edge $s \\to b$: $\\eta_{sb} = \\frac{1}{1.6}$.\n\nNow, we compute the desirability terms:\n- For edge $s \\to a$: $d_{sa} = \\tau_{sa}^{\\alpha} \\eta_{sa}^{\\beta} = (0.8)^{1} \\left(\\frac{1}{2.4}\\right)^{2} = \\frac{0.8}{5.76}$.\n- For edge $s \\to b$: $d_{sb} = \\tau_{sb}^{\\alpha} \\eta_{sb}^{\\beta} = (0.8)^{1} \\left(\\frac{1}{1.6}\\right)^{2} = \\frac{0.8}{2.56}$.\n\nTo find the probabilities, we normalize these values. Let's work with exact fractions for precision.\n$t_{sa} = 2.4 = \\frac{12}{5}$, $t_{sb} = 1.6 = \\frac{8}{5}$, $\\tau_0 = 0.8 = \\frac{4}{5}$.\n$\\eta_{sa} = \\frac{5}{12}$, $\\eta_{sb} = \\frac{5}{8}$.\n\n$d_{sa} = \\left(\\frac{4}{5}\\right)^{1} \\left(\\frac{5}{12}\\right)^{2} = \\frac{4}{5} \\cdot \\frac{25}{144} = \\frac{100}{720} = \\frac{5}{36}$.\n$d_{sb} = \\left(\\frac{4}{5}\\right)^{1} \\left(\\frac{5}{8}\\right)^{2} = \\frac{4}{5} \\cdot \\frac{25}{64} = \\frac{100}{320} = \\frac{5}{16}$.\n\nThe total desirability is the sum $D = d_{sa} + d_{sb}$:\n$D = \\frac{5}{36} + \\frac{5}{16}$. The least common multiple of $36$ and $16$ is $144$.\n$D = \\frac{5 \\cdot 4}{144} + \\frac{5 \\cdot 9}{144} = \\frac{20}{144} + \\frac{45}{144} = \\frac{65}{144}$.\n\nThe transition probabilities are:\n$p_{sa} = \\frac{d_{sa}}{D} = \\frac{5/36}{65/144} = \\frac{5}{36} \\cdot \\frac{144}{65} = \\frac{5}{1} \\cdot \\frac{4}{65} = \\frac{20}{65} = \\frac{4}{13}$.\n$p_{sb} = \\frac{d_{sb}}{D} = \\frac{5/16}{65/144} = \\frac{5}{16} \\cdot \\frac{144}{65} = \\frac{5}{1} \\cdot \\frac{9}{65} = \\frac{45}{65} = \\frac{9}{13}$.\nAs a check, $p_{sa} + p_{sb} = \\frac{4}{13} + \\frac{9}{13} = 1$.\n\n**2. Determine the Ant's Path**\n\nRoulette-wheel selection is used. We establish intervals on $[0, 1]$ for each choice. The interval for $s \\to a$ is $[0, p_{sa})$ and for $s \\to b$ is $[p_{sa}, 1)$.\n$p_{sa} = \\frac{4}{13} \\approx 0.3077$.\nThe given random number is $u_1 = 0.28$.\nSince $u_1 = 0.28  p_{sa} \\approx 0.3077$, the ant selects the edge $s \\to a$.\n\nOnce the ant is at node $a$, the only available forward edge that does not revisit a node is $a \\to g$. Thus, the ant's complete path is $s \\to a \\to g$.\n\n**3. Calculate Total Travel Time of the Path**\n\nThe total travel time for the path $s \\to a \\to g$ is:\n$T_{\\text{path}} = t_{sa} + t_{ag} = 2.4 + 3.0 = 5.4$.\n\n**4. Update Pheromones**\n\nThe final step is to update the pheromone levels on all edges. We are asked for the updated value on edge $s \\to a$, which we denote $\\tau'_{sa}$. Since this edge lies on the sampled path, we use the update rule that includes deposition:\n$\\tau'_{sa} = (1 - \\rho)\\tau_{sa} + \\frac{Q}{T_{\\text{path}}}$.\n\nThe given parameters are $\\rho = 0.25$, $Q = 1.5$, and the initial pheromone is $\\tau_{sa} = 0.8$.\n$1 - \\rho = 1 - 0.25 = 0.75$.\n$T_{\\text{path}} = 5.4$.\n\nSubstituting the values:\n$\\tau'_{sa} = (0.75)(0.8) + \\frac{1.5}{5.4}$.\n\nLet's compute the terms as exact fractions:\n$0.75 = \\frac{3}{4}$, $0.8 = \\frac{4}{5}$.\n$\\frac{1.5}{5.4} = \\frac{15}{54} = \\frac{5}{18}$.\n\nSo, the calculation is:\n$\\tau'_{sa} = \\left(\\frac{3}{4}\\right) \\left(\\frac{4}{5}\\right) + \\frac{5}{18} = \\frac{3}{5} + \\frac{5}{18}$.\n\nTo sum these fractions, we find a common denominator, which is $lcm(5, 18) = 90$.\n$\\tau'_{sa} = \\frac{3 \\cdot 18}{90} + \\frac{5 \\cdot 5}{90} = \\frac{54}{90} + \\frac{25}{90} = \\frac{79}{90}$.\n\nThe number $79$ is prime, so this fraction is irreducible.\n\nThe updated pheromone value on edge $s \\to a$ after this single iteration is $\\frac{79}{90}$.", "answer": "$$\\boxed{\\frac{79}{90}}$$", "id": "3589781"}]}