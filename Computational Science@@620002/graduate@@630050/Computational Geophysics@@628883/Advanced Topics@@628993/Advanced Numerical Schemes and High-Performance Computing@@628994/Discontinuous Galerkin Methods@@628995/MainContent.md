## Introduction
Traditional numerical methods often struggle with the sharp discontinuities inherent in geophysics, such as geological faults or [shock waves](@entry_id:142404). Their requirement for global continuity creates challenges in handling complex geometries and [adaptive meshing](@entry_id:166933). The discontinuous Galerkin (DG) method offers a powerful and flexible alternative, fundamentally changing how we approach these problems. This article provides a comprehensive overview of the DG method, tailored for [computational geophysics](@entry_id:747618). In the upcoming chapters, you will first delve into the foundational "Principles and Mechanisms," understanding how disconnected elements communicate via [numerical fluxes](@entry_id:752791) and how stability is achieved. Next, "Applications and Interdisciplinary Connections" will demonstrate DG's power in modeling complex Earth processes, from [seismic wave propagation](@entry_id:165726) across [non-conforming meshes](@entry_id:752550) to its role in [high-performance computing](@entry_id:169980) and [seismic inversion](@entry_id:161114). Finally, "Hands-On Practices" will solidify your understanding through guided exercises on core DG concepts. We begin by exploring the core philosophy that gives the DG method its distinct advantages.

## Principles and Mechanisms

Imagine you are trying to describe a mountain range. A classical approach, what we might call a "continuous" one, would be to try and drape a single, enormous, perfectly smooth sheet over the entire landscape. This sheet must be continuous everywhere; it cannot have any rips or tears. This is a beautiful idea, but it's incredibly restrictive. What if the mountain has a sharp cliff, a sudden fault line? To capture that, your single sheet would need to bend and stretch in impossibly complex ways. This is the challenge faced by traditional numerical methods like the **continuous Galerkin (CG) [finite element method](@entry_id:136884)**. They build solutions from functions that must be globally continuous, living in a space like $H^1(\Omega)$. This enforced continuity, this "single-sheet" philosophy, makes it difficult to handle the sharp discontinuities common in [geophysics](@entry_id:147342)—faults, material boundaries, or [shock waves](@entry_id:142404)—and complicates things like refining the mesh in one area without affecting the whole world [@problem_id:3584974].

### The Freedom of Disconnection

So, let’s try a different philosophy. Instead of one giant sheet, let's tile the mountain with a mosaic of smaller, independent patches. Each patch is simple—a flat or gently curved polynomial tile. Crucially, we make no demand that the edge of one tile must perfectly meet the edge of its neighbor. There can be gaps, overlaps, or cliffs between them. We have liberated ourselves from the tyranny of continuity.

This is the foundational idea of the **discontinuous Galerkin (DG) method**. We break our problem domain into a collection of elements, and on each element, we build a simple [polynomial approximation](@entry_id:137391) of our solution. The collection of all these "broken" pieces lives in a much larger and more flexible space, aptly named a **broken Sobolev space**, denoted $H^1(\mathcal{T}_h)$ [@problem_id:3584974]. A function in this space is well-behaved *inside* each element, but it is free to jump across the boundaries. This freedom is the source of DG's power. It allows us to easily handle complex geometries, use different polynomial degrees in different elements ([p-adaptivity](@entry_id:138508)), and, as we will see, it provides a natural framework for capturing the physics of discontinuities.

But this freedom comes at a price. A fundamental question immediately arises: if the elements are disconnected, how do they communicate? If a seismic wave is traveling through our model, how does it "know" to leave one element and enter the next? Without some form of communication, our domain would be a silent collection of isolated worlds. The solution to this puzzle is the heart of the DG method.

### How Disconnected Elements Talk: The Numerical Flux

To see how communication is established, let’s consider the simplest meaningful problem: a quantity $u$ being carried along by a constant wind, an advection equation like $u_t + a u_x = 0$ [@problem_id:3584931]. In the DG method, we don't try to solve this equation across the whole domain at once. Instead, we go into a single element, say element $K_i$, and multiply the equation by a [test function](@entry_id:178872) $v_h$ (one of our polynomial building blocks) and integrate over that element:

$$
\int_{K_i} \left( \frac{\partial u_h}{\partial t} + a \frac{\partial u_h}{\partial x} \right) v_h \, dx = 0
$$

The magic happens when we apply **[integration by parts](@entry_id:136350)** (the physicist's best friend!) to the spatial term. This mathematical trick allows us to trade a derivative on the (potentially complicated) solution $u_h$ for a derivative on our nice, simple test function $v_h$. In doing so, it drags out terms evaluated at the element's boundaries:

$$
\int_{K_i} \left( \frac{\partial u_h}{\partial t} v_h - a u_h \frac{\partial v_h}{\partial x} \right) dx + \left[ a u_h v_h \right]_{\text{boundaries of } K_i} = 0
$$

That boundary term, $[a u_h v_h]$, is the **physical flux**—the rate at which the quantity $u$ is being transported across the element's edges. Now, look at an interface between two elements, $K_i$ and $K_{i+1}$. The solution $u_h$ has two values there: the value from the left, $u_h^-$, and the value from the right, $u_h^+$. The physical flux is ambiguous! Which value should we use?

The answer is: neither, and both. We invent a new quantity, the **[numerical flux](@entry_id:145174)**, often denoted $\widehat{a u_h}$ or $f^*$. This numerical flux is a function that takes both the left and right states ($u_h^-$ and $u_h^+$) and prescribes a single, unique value for the flux at that interface. It is the "rule of communication," the protocol for how information is passed between neighboring elements. The entire DG formulation is built by summing up these element-wise equations, with the physical flux at every interface replaced by a chosen [numerical flux](@entry_id:145174) [@problem_id:3584931].

### A Conversation of Fluxes: Choosing Your Messenger

The choice of numerical flux is not arbitrary; it is everything. It determines the stability, accuracy, and physical fidelity of the method. Different choices give the DG scheme entirely different personalities.

**The Naive Democrat: Central Flux**
The simplest idea is to just take the average of the flux from both sides. This is the **central flux**. It seems fair and democratic. However, for wave propagation problems, this democracy leads to anarchy. A pure central flux scheme is **unstable** [@problem_id:3584978]. While it perfectly conserves energy (no energy is artificially added or removed), it provides no mechanism to damp out high-frequency noise or "wiggles" that inevitably arise from the discontinuous representation. These wiggles can grow without bound, destroying the solution.

**The Wise Elder: Upwind Flux**
A much smarter choice is the **[upwind flux](@entry_id:143931)**. This messenger looks at the physics of the problem—the direction the "wind" is blowing (the sign of the advection speed $a$)—and chooses the state from the upwind side. If the wind blows from left to right ($a > 0$), it listens only to the left state, $u_h^-$. This is profoundly physical; information flows *with* the wind. This choice has a remarkable effect. It introduces **[numerical dissipation](@entry_id:141318)** into the system [@problem_id:3584981]. It's like adding a tiny amount of friction that specifically targets the jumps between elements. This friction damps the high-frequency oscillations that plague the central flux, making the scheme stable. Interestingly, this added stability doesn't come for free. The introduction of the dissipative term slightly increases the operator's **[spectral radius](@entry_id:138984)**, which means that for [explicit time-stepping](@entry_id:168157) schemes, the [upwind flux](@entry_id:143931) actually requires a *smaller* [stable time step](@entry_id:755325) (a stricter CFL condition) than the unstable central flux [@problem_id:3584981]. It's a fascinating trade-off between stability and computational constraint.

**The Judge: Penalty Flux (SIPG)**
What about problems where there is no "wind," like [steady-state heat](@entry_id:163341) diffusion described by $-\nabla \cdot (\kappa \nabla u) = f$? There's no upwind direction. Here, we need a different philosophy, embodied by the **Symmetric Interior Penalty Galerkin (SIPG)** method. The idea is to enforce continuity weakly by adding a **penalty term** that punishes jumps in the solution [@problem_id:3584992]. It’s like connecting the discontinuous edges of our solution with a stiff spring. The larger the jump, the more the spring pulls them back. This penalty term, which must be scaled carefully with the mesh size $h$ and polynomial degree $p$ (e.g., as $\frac{\eta \kappa}{h}$), provides the stability that would otherwise be missing. The same philosophy extends beautifully to imposing boundary conditions. Instead of forcing the solution to take a certain value at the boundary (a "strong" imposition), we can weakly encourage it using a similar combination of consistency and penalty terms [@problem_id:3584992].

**The Physicist: Riemann Flux**
For complex systems like the elastodynamic equations, we can be even more sophisticated. At an interface between two different rock types, a seismic wave doesn't just pass through; it partially reflects and partially transmits, with energy partitioned among P- and S-waves. A simple [upwind flux](@entry_id:143931) might stabilize the scheme, but it won't capture this complex physics accurately, leading to spurious, non-physical reflections at [material interfaces](@entry_id:751731). The ultimate messenger is the **Riemann-based flux**. Here, we solve a miniature, localized physical problem—a **Riemann problem**—at every point on the interface. This local solution tells us precisely how the discontinuity should resolve itself into a set of waves traveling away from the interface. By using this physically correct information as our [numerical flux](@entry_id:145174), we build the true physics of [wave reflection and transmission](@entry_id:173339) directly into the numerics. This minimizes spurious reflections far better than a simple penalty or [upwind flux](@entry_id:143931), yielding a much more accurate solution for heterogeneous geophysical media [@problem_id:3584978].

### Taming the Wiggles: Limiters for a Robust Method

The high-order polynomial basis of DG is a double-edged sword. It's fantastic for representing smooth waves accurately with very few grid points. However, when a wave steepens into a shock or a seismic rupture propagates along a fault, these high-order polynomials will desperately try to fit the sharp feature, leading to spurious, non-physical oscillations (the Gibbs phenomenon).

To prevent this, we introduce a **[limiter](@entry_id:751283)**. A [limiter](@entry_id:751283) acts as a "safety inspector" for the solution in each element. If the solution in an element looks smooth and well-behaved, the [limiter](@entry_id:751283) does nothing, preserving the full [high-order accuracy](@entry_id:163460). But if it detects that the solution is becoming oscillatory or developing a sharp front, it intervenes, locally "limiting" the polynomial—often by reducing its slope or curvature—to enforce a monotonicity constraint and prevent overshoots.

A particularly clever example is the **Total Variation Bounded (TVB) [slope limiter](@entry_id:136902)** [@problem_id:3584940]. A simple [limiter](@entry_id:751283) might mistake the top of a smooth hill for a spurious oscillation and flatten it, destroying the accuracy. The TVB limiter avoids this by using a brilliant criterion. It checks if the deviation of the solution at the element's edge from its cell average is smaller than a threshold, typically $M h^2$, where $h$ is the cell size and $M$ is a user-defined parameter. At a smooth extremum, this deviation is naturally very small (of order $h^2$ or higher for a P1 scheme), so the condition is met and the [limiter](@entry_id:751283) stays off. Near a developing shock, the deviation is much larger, the condition fails, and the limiter kicks in to tame the oscillations. It’s a beautifully simple idea that allows the method to be both high-order accurate in smooth regions and robustly non-oscillatory at discontinuities.

### The Unseen Machinery: On Strong, Weak, and Broken Symmetries

Finally, let's peek under the hood at the algebraic structure. You may encounter references to "strong" and "weak" forms of the DG equations. The [weak form](@entry_id:137295), which we derived earlier, moves the derivative from the solution onto the [test function](@entry_id:178872) via [integration by parts](@entry_id:136350). The strong form leaves the derivative on the solution. These two forms look different on paper, but they are intimately related.

In an ideal world—with simple, affine meshes and [quadrature rules](@entry_id:753909) that are exact for all the integrals we need to compute—these two forms are **algebraically identical** [@problem_id:3584947]. This beautiful equivalence is a manifestation of a discrete version of the integration-by-parts formula, often related to the concept of **Summation-By-Parts (SBP)** operators [@problem_id:3584991].

However, in the real world of [computational geophysics](@entry_id:747618), our meshes may be curved to fit complex [geology](@entry_id:142210), and our material properties ($\rho, \lambda, \mu$) can vary continuously. In these cases, our [quadrature rules](@entry_id:753909) are often no longer exact; for example, the integrands involving geometric metric terms or variable coefficients are not simple polynomials [@problem_id:3584984]. This "underintegration" breaks the perfect [discrete symmetry](@entry_id:146994). The weak and strong forms are no longer identical, and this subtle discrepancy can lead to a loss of the very properties, like [energy stability](@entry_id:748991), that we rely on [@problem_id:3584947]. This reveals a deep truth about numerical methods: the elegance of the core principles must always be paired with a rigorous understanding of the practical machinery to ensure that the beautiful theory translates into a robust and reliable simulation tool.