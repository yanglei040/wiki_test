{"hands_on_practices": [{"introduction": "This first practice provides a comprehensive walkthrough of the Method of Lines (MOL) for a parabolic diffusion equation, a model often used for thermal or chemical transport in geophysics. A critical skill in applying MOL is the accurate implementation of boundary conditions, especially non-Dirichlet (flux) types. This exercise will guide you through the 'ghost cell' method, a powerful and intuitive technique for deriving boundary stencils that maintain the overall accuracy of the scheme [@problem_id:3617046]. You will also implement the method of manufactured solutions, a gold standard for verifying the correctness and convergence rate of numerical codes.", "problem": "Consider the one-dimensional diffusion partial differential equation (PDE) for a scalar field $u(x,t)$ on a closed interval $x \\in [0,L]$ and time $t \\ge 0$:\n$$\n\\frac{\\partial u}{\\partial t} = \\kappa \\frac{\\partial^2 u}{\\partial x^2} + s(t),\n$$\nwhere $\\kappa > 0$ is a constant diffusivity and $s(t)$ is a prescribed source term that depends only on time. The boundary conditions are of Neumann type (flux-prescribed):\n$$\n\\frac{\\partial u}{\\partial x}(0,t) = \\alpha, \\quad \\frac{\\partial u}{\\partial x}(L,t) = \\beta,\n$$\nwhere $\\alpha$ and $\\beta$ are given real constants. The initial condition is $u(x,0) = u_0(x)$.\n\nYour task is to use the method of lines (MOL) to discretize space with a second-order accurate central finite difference scheme on a uniform grid and then integrate the resulting system of ordinary differential equations (ODEs) in time. To enforce the Neumann boundary conditions, use ghost cells and derive the second-order accurate modified boundary stencils that replace the standard discrete Laplacian at the boundary nodes.\n\nStarting from core definitions (central differences and Taylor expansions), do the following:\n\n1. Derive the ghost cell formulas implied by the Neumann boundary conditions by requiring that a second-order accurate centered finite difference approximation to the spatial derivative holds at $x=0$ and $x=L$. Express the ghost values $u_{-1}(t)$ and $u_{N}(t)$ in terms of interior values and the given fluxes, where the uniform grid points are $x_i = i h$ for $i=0,1,\\dots,N-1$, with spacing $h = L/(N-1)$, and ghost indices $-1$ and $N$ refer to the fictitious nodes outside the domain at $x=-h$ and $x=L+h$, respectively.\n\n2. Using the standard second-order centered discrete Laplacian,\n$$\n\\left(\\mathcal{D}_{xx} u\\right)_i = \\frac{u_{i+1} - 2 u_i + u_{i-1}}{h^2},\n$$\nderive the modified discrete boundary stencils at $i=0$ and $i=N-1$ that result from substituting your ghost cell formulas from part 1 into the Laplacian. Your final expressions must be purely in terms of grid values $u_0, u_1, \\dots, u_{N-1}$ and the boundary fluxes $\\alpha$ and $\\beta$.\n\n3. Implement the method of lines by assembling the semi-discrete ODE system\n$$\n\\frac{d}{dt}\\, \\mathbf{u}(t) = \\kappa\\, \\mathcal{D}_{xx}\\, \\mathbf{u}(t) + s(t)\\, \\mathbf{1},\n$$\nwhere $\\mathbf{u}(t) = \\left[u_0(t), u_1(t), \\dots, u_{N-1}(t)\\right]^\\top$ and $\\mathbf{1}$ is the vector of ones, using your boundary-modified stencils from part 2. Integrate this ODE system in time using a general-purpose ODE solver.\n\n4. To verify correctness and quantify accuracy, use the method of manufactured solutions. Consider the exact solution\n$$\nu_{\\text{exact}}(x,t) = C_0 + \\alpha\\, x + \\frac{\\beta - \\alpha}{2L}\\, x^2 + \\sin(\\omega t),\n$$\nwith constant $C_0 = 0$ and prescribed angular frequency $\\omega > 0$. Derive the source term $s(t)$ such that $u_{\\text{exact}}(x,t)$ satisfies the PDE with diffusivity $\\kappa$ and Neumann boundary conditions $\\alpha$ and $\\beta$. Use the initial condition $u(x,0) = u_{\\text{exact}}(x,0)$.\n\n5. Implement your solver and compute the discrete root-mean-square (RMS) error at a final time $T$:\n$$\nE_{\\text{RMS}} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1}\\left(u_i(T) - u_{\\text{exact}}(x_i,T)\\right)^2}.\n$$\n\nUse the following test suite of parameter sets. Each test case specifies ($L$, $\\kappa$, $\\alpha$, $\\beta$, $N$, $T$, $\\omega$):\n\n- Test A (general case): $(1.0, 0.5, 0.2, -0.1, 41, 0.5, 2.3)$.\n- Test B (refined grid, same physics as A): $(1.0, 0.5, 0.2, -0.1, 81, 0.5, 2.3)$.\n- Test C (zero-flux symmetry): $(1.5, 0.25, 0.0, 0.0, 50, 1.2, 1.7)$.\n- Test D (short domain, strong opposing fluxes): $(0.1, 0.1, 5.0, -3.0, 21, 0.05, 10.0)$.\n\nNo physical units are required; all quantities are dimensionless. Angles, where applicable, are in radians.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"). Here, each result is the floating-point RMS error $E_{\\text{RMS}}$ for the corresponding test case, in the order A, B, C, D. The program must be a complete, runnable implementation that constructs the semi-discrete operator with your derived Neumann boundary stencils, integrates in time, evaluates the manufactured solution, and outputs the four RMS errors in the specified format.", "solution": "We begin with a one-dimensional diffusion partial differential equation (PDE) with constant diffusivity $\\kappa$ and a time-dependent source term $s(t)$:\n$$\n\\frac{\\partial u}{\\partial t} = \\kappa \\frac{\\partial^2 u}{\\partial x^2} + s(t),\n$$\nfor $x \\in [0,L]$, $t \\ge 0$, with Neumann boundary conditions $\\frac{\\partial u}{\\partial x}(0,t)=\\alpha$ and $\\frac{\\partial u}{\\partial x}(L,t)=\\beta$.\n\nWe construct a uniform spatial grid with $N$ points: $x_i = i h$ for $i=0,1,\\dots,N-1$, where the grid spacing is $h = L/(N-1)$. The method of lines (MOL) dictates that we discretize only in space to obtain a system of ordinary differential equations (ODEs) in time. Let $u_i(t) \\approx u(x_i,t)$.\n\nThe second-order central difference approximation for the second spatial derivative at interior points is\n$$\n\\left(\\mathcal{D}_{xx} u\\right)_i = \\frac{u_{i+1} - 2 u_i + u_{i-1}}{h^2}, \\quad i=1,2,\\dots,N-2.\n$$\nTo achieve second-order accuracy at the boundaries under Neumann conditions, we introduce ghost points $u_{-1}(t)$ and $u_{N}(t)$ located at $x=-h$ and $x=L+h$. We then enforce that the centered first derivative approximation at the boundary locations matches the prescribed fluxes.\n\nSpecifically, we use the second-order centered approximation to the first derivative at $x=0$:\n$$\n\\left.\\frac{\\partial u}{\\partial x}\\right|_{x=0} \\approx \\frac{u_1 - u_{-1}}{2h} = \\alpha.\n$$\nSolving for the ghost value yields\n$$\nu_{-1} = u_1 - 2 h \\alpha.\n$$\nSimilarly, at $x=L$ (located at $i=N-1$), the second-order centered first derivative is\n$$\n\\left.\\frac{\\partial u}{\\partial x}\\right|_{x=L} \\approx \\frac{u_{N} - u_{N-2}}{2h} = \\beta,\n$$\nwhich gives\n$$\nu_{N} = u_{N-2} + 2 h \\beta.\n$$\n\nWe now substitute these ghost values into the standard second-order discrete Laplacian at the boundary nodes. At the left boundary ($i=0$), the discrete Laplacian with a ghost point is\n$$\n\\left(\\mathcal{D}_{xx} u\\right)_0 = \\frac{u_{1} - 2 u_{0} + u_{-1}}{h^2}.\n$$\nUsing $u_{-1} = u_1 - 2 h \\alpha$,\n$$\n\\left(\\mathcal{D}_{xx} u\\right)_0 = \\frac{u_{1} - 2 u_{0} + \\left(u_1 - 2 h \\alpha\\right)}{h^2}\n= \\frac{2 u_1 - 2 u_0}{h^2} - \\frac{2 \\alpha}{h}.\n$$\nThis is the modified boundary stencil at the left boundary. At the right boundary ($i=N-1$),\n$$\n\\left(\\mathcal{D}_{xx} u\\right)_{N-1} = \\frac{u_{N} - 2 u_{N-1} + u_{N-2}}{h^2}.\n$$\nUsing $u_{N} = u_{N-2} + 2 h \\beta$,\n$$\n\\left(\\mathcal{D}_{xx} u\\right)_{N-1} = \\frac{\\left(u_{N-2} + 2 h \\beta\\right) - 2 u_{N-1} + u_{N-2}}{h^2}\n= \\frac{2 u_{N-2} - 2 u_{N-1}}{h^2} + \\frac{2 \\beta}{h}.\n$$\nThese boundary formulas, together with the standard interior stencil, constitute a second-order accurate spatial discretization consistent with the Neumann boundary conditions via ghost cells.\n\nCollecting all nodes, the semi-discrete MOL system is\n$$\n\\frac{d}{dt}\\, u_i(t) = \\kappa \\left(\\mathcal{D}_{xx} u\\right)_i + s(t), \\quad i = 0,1,\\dots,N-1,\n$$\nwith\n$$\n\\left(\\mathcal{D}_{xx} u\\right)_i =\n\\begin{cases}\n\\dfrac{2 u_1 - 2 u_0}{h^2} - \\dfrac{2 \\alpha}{h}, & i = 0,\\\\[1.0em]\n\\dfrac{u_{i+1} - 2 u_i + u_{i-1}}{h^2}, & i = 1,2,\\dots,N-2,\\\\[1.0em]\n\\dfrac{2 u_{N-2} - 2 u_{N-1}}{h^2} + \\dfrac{2 \\beta}{h}, & i = N-1.\n\\end{cases}\n$$\n\nTo verify the implementation, we employ the method of manufactured solutions. Consider\n$$\nu_{\\text{exact}}(x,t) = C_0 + \\alpha\\, x + \\frac{\\beta - \\alpha}{2L}\\, x^2 + \\sin(\\omega t),\n$$\nwith $C_0=0$ and $\\omega>0$. The boundary derivatives are\n$$\n\\left.\\frac{\\partial u_{\\text{exact}}}{\\partial x}\\right|_{x=0} = \\alpha, \\quad\n\\left.\\frac{\\partial u_{\\text{exact}}}{\\partial x}\\right|_{x=L} = \\alpha + \\frac{\\beta - \\alpha}{L} L = \\beta,\n$$\nso the Neumann boundary conditions are satisfied by construction for all $t$. The time derivative and second spatial derivative are\n$$\n\\frac{\\partial u_{\\text{exact}}}{\\partial t} = \\omega \\cos(\\omega t), \\quad\n\\frac{\\partial^2 u_{\\text{exact}}}{\\partial x^2} = \\frac{\\beta - \\alpha}{L}.\n$$\nSubstituting into the PDE\n$$\n\\frac{\\partial u_{\\text{exact}}}{\\partial t} = \\kappa \\frac{\\partial^2 u_{\\text{exact}}}{\\partial x^2} + s(t)\n$$\ngives the required source term\n$$\ns(t) = \\omega \\cos(\\omega t) - \\kappa \\frac{\\beta - \\alpha}{L}.\n$$\nThe initial condition is $u(x,0) = u_{\\text{exact}}(x,0)$.\n\nFor each test case, we integrate the semi-discrete ODE system to time $T$ with a high-accuracy ODE solver. The discrete root-mean-square (RMS) error is computed as\n$$\nE_{\\text{RMS}} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1}\\left(u_i(T) - u_{\\text{exact}}(x_i,T)\\right)^2}.\n$$\n\nThe test suite consists of the following parameter sets ($L, \\kappa, \\alpha, \\beta, N, T, \\omega$):\n\n- Test A: $(1.0, 0.5, 0.2, -0.1, 41, 0.5, 2.3)$,\n- Test B: $(1.0, 0.5, 0.2, -0.1, 81, 0.5, 2.3)$,\n- Test C: $(1.5, 0.25, 0.0, 0.0, 50, 1.2, 1.7)$,\n- Test D: $(0.1, 0.1, 5.0, -3.0, 21, 0.05, 10.0)$.\n\nBecause the spatial discretization is second-order accurate and exactly reproduces quadratic polynomials, and the manufactured solution is quadratic in space, the dominant numerical error in these tests arises from time integration and solver tolerances. By using strict tolerances, the RMS errors should be small and decrease with refined temporal resolution or stricter tolerances. The final program assembles the modified boundary stencils, integrates the ODE system, evaluates $u_{\\text{exact}}$, computes $E_{\\text{RMS}}$ for each test, and prints a single line containing the four RMS errors in the order A, B, C, D as a list formatted like [$e_A,e_B,e_C,e_D$].", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef manufactured_solution(x, t, L, alpha, beta, omega):\n    # u_exact(x,t) = alpha x + ((beta - alpha)/(2L)) x^2 + sin(omega t)\n    return alpha * x + ((beta - alpha) / (2.0 * L)) * x**2 + np.sin(omega * t)\n\ndef source_term(t, kappa, L, alpha, beta, omega):\n    # s(t) = omega cos(omega t) - kappa * (beta - alpha)/L\n    return omega * np.cos(omega * t) - kappa * (beta - alpha) / L\n\ndef mol_rhs_builder(N, L, kappa, alpha, beta, omega):\n    # Build the RHS function f(t, u) = kappa * Dxx(u) + s(t) * 1\n    h = L / (N - 1)\n\n    def rhs(t, u):\n        du = np.empty_like(u)\n\n        # Interior points\n        # Use vectorized central differences where possible\n        # Boundary at i=0 with modified stencil via ghost cell:\n        # Dxx u_0 = (2 u_1 - 2 u_0)/h^2 - 2 alpha / h\n        du[0] = kappa * ((2.0 * u[1] - 2.0 * u[0]) / (h * h) - 2.0 * alpha / h)\n\n        # Interior nodes\n        if N > 2:\n            du[1:-1] = kappa * (u[2:] - 2.0 * u[1:-1] + u[:-2]) / (h * h)\n        # Right boundary i=N-1:\n        # Dxx u_{N-1} = (2 u_{N-2} - 2 u_{N-1})/h^2 + 2 beta / h\n        du[-1] = kappa * ((2.0 * u[-2] - 2.0 * u[-1]) / (h * h) + 2.0 * beta / h)\n\n        # Add source term s(t) uniformly\n        s = source_term(t, kappa, L, alpha, beta, omega)\n        du += s\n\n        return du\n\n    return rhs\n\ndef run_case(L, kappa, alpha, beta, N, T, omega):\n    x = np.linspace(0.0, L, N)\n    u0 = manufactured_solution(x, 0.0, L, alpha, beta, omega)\n\n    rhs = mol_rhs_builder(N, L, kappa, alpha, beta, omega)\n\n    # Integrate in time with strict tolerances\n    sol = solve_ivp(\n        fun=rhs,\n        t_span=(0.0, T),\n        y0=u0,\n        method=\"RK45\",\n        rtol=1e-10,\n        atol=1e-12,\n        dense_output=False\n    )\n\n    uT = sol.y[:, -1]\n    u_exact_T = manufactured_solution(x, T, L, alpha, beta, omega)\n    err = np.sqrt(np.mean((uT - u_exact_T) ** 2))\n    return float(err)\n\ndef solve():\n    # Define the test cases (L, kappa, alpha, beta, N, T, omega)\n    test_cases = [\n        (1.0, 0.5, 0.2, -0.1, 41, 0.5, 2.3),   # Test A\n        (1.0, 0.5, 0.2, -0.1, 81, 0.5, 2.3),   # Test B\n        (1.5, 0.25, 0.0, 0.0, 50, 1.2, 1.7),   # Test C\n        (0.1, 0.1, 5.0, -3.0, 21, 0.05, 10.0), # Test D\n    ]\n\n    results = []\n    for case in test_cases:\n        L, kappa, alpha, beta, N, T, omega = case\n        err = run_case(L, kappa, alpha, beta, N, T, omega)\n        results.append(err)\n\n    # Print as a single line list of comma-separated floats\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3617046"}, {"introduction": "Building on the foundational workflow, this practice explores a more advanced topic: the profound impact of boundary condition implementation on the stability of time integration for wave phenomena. You will compare a classical 'strong' enforcement of Dirichlet conditions with a modern 'weak' penalty-based approach known as the Simultaneous Approximation Term (SAT) method [@problem_id:3617036]. By analyzing the eigenvalues of the resulting spatial discretization matrices, you will gain direct insight into how these choices alter the semi-discrete spectrum and, consequently, the maximum allowable time step dictated by the Courant-Friedrichs-Lewy (CFL) condition.", "problem": "Consider the one-dimensional acoustic wave equation $u_{tt} = c^2 u_{xx}$ on the closed interval $[0,L]$ with homogeneous Dirichlet boundary conditions $u(0,t) = 0$ and $u(L,t) = 0$. The unknown $u(x,t)$ has units of an acoustic displacement, $c$ is the wave speed in meters per second, and $x$ is measured in meters while $t$ is measured in seconds. In computational geophysics, a common semidiscrete approach is the method of lines: discretize the spatial derivative to obtain a finite-dimensional system of ordinary differential equations in time. Stability of the explicit time integrator is governed by the semidiscrete spatial spectrum via the Courant-Friedrichs-Lewy (CFL) condition.\n\nYou will study how two boundary treatments in the spatial discretization alter the semidiscrete spectrum and hence the CFL condition, and then design a penalty-based boundary closure parameter that maximizes the smallest negative eigenvalue of the spatial operator.\n\nSpatial grid and interior discretization:\n- Let $N \\in \\mathbb{N}$ be the number of interior grid points, and define a uniform grid on $(0,L)$ with spacing $h = \\frac{L}{N+1}$ and interior nodes $x_i = i h$ for $i=1,\\dots,N$.\n- For interior points $i=2,\\dots,N-1$, approximate $u_{xx}(x_i,t)$ by the standard second-order central difference stencil:\n$$\nu_{xx}(x_i,t) \\approx \\frac{u_{i-1}(t) - 2 u_i(t) + u_{i+1}(t)}{h^2}.\n$$\n\nTwo boundary closures:\n1) Ghost-point strong Dirichlet elimination (GP-SD):\n- Enforce the boundary conditions strongly by eliminating boundary contributions. This yields the classical discrete Laplacian matrix $\\mathbf{A}_{\\mathrm{GP}} \\in \\mathbb{R}^{N \\times N}$ with entries\n$(\\mathbf{A}_{\\mathrm{GP}})_{i,i} = -\\frac{2}{h^2}, \\quad (\\mathbf{A}_{\\mathrm{GP}})_{i,i+1} = (\\mathbf{A}_{\\mathrm{GP}})_{i+1,i} = \\frac{1}{h^2}, \\quad i=1,\\dots,N-1,$\nand zero otherwise. This corresponds to the symmetric tridiagonal second-difference operator with homogeneous Dirichlet boundary conditions implicitly enforced through elimination of boundary values (interpretable as a \"ghost-point\" approach with strong boundary enforcement).\n\n2) Simultaneous Approximation Term (SAT) penalty boundary closure:\n- Summation-By-Parts (SBP) operators with diagonal norm provide a discrete energy framework. A practical symmetric penalty closure for homogeneous Dirichlet conditions adds a penalty proportional to the boundary values into the semidiscrete operator. In an interior-only formulation compatible with the above grid, one obtains a symmetric penalty-modified operator $\\mathbf{A}_{\\mathrm{SAT}}(\\tau) \\in \\mathbb{R}^{N \\times N}$ defined by\n$$\n\\mathbf{A}_{\\mathrm{SAT}}(\\tau) = \\mathbf{A}_{\\mathrm{GP}} - \\frac{\\tau}{h^2}\\left(\\mathbf{e}_1 \\mathbf{e}_1^\\top + \\mathbf{e}_N \\mathbf{e}_N^\\top\\right),\n$$\nwhere $\\mathbf{e}_1, \\mathbf{e}_N \\in \\mathbb{R}^{N}$ are the first and last canonical basis vectors, and $\\tau \\ge 0$ is a dimensionless penalty parameter. This penalty weakly enforces $u=0$ at the boundaries and is consistent with the energy-stable SBP-SAT framework for second derivative operators with diagonal norm when recast in an interior-only setting. For $\\tau = 0$ it reduces to the GP-SD operator.\n\nCFL and semidiscrete spectrum:\n- The method of lines yields the semidiscrete system $\\mathbf{u}''(t) = c^2 \\mathbf{A}\\, \\mathbf{u}(t)$ for a chosen spatial operator $\\mathbf{A}$ with spectrum contained in $(-\\infty,0]$. Consider the standard explicit second-order central difference time integrator:\n$$\n\\mathbf{u}^{n+1} - 2 \\mathbf{u}^n + \\mathbf{u}^{n-1} = (c \\Delta t)^2 \\mathbf{A}\\, \\mathbf{u}^n,\n$$\nwhere $\\Delta t$ is the time step. For each eigenvalue $\\lambda \\le 0$ of $\\mathbf{A}$, the scalar recurrence is stable if $(c \\Delta t)^2 \\lambda \\in [-4,0]$. Therefore the maximum admissible time step is\n$$\n\\Delta t_{\\max} = \\frac{2}{c \\sqrt{-\\lambda_{\\min}}},\n$$\nwhere $\\lambda_{\\min}$ is the most negative eigenvalue of $\\mathbf{A}$. The nondimensional Courant number is defined as $r = \\frac{c \\Delta t}{h}$, so that\n$$\nr_{\\max} = \\frac{2}{h \\sqrt{-\\lambda_{\\min}}}.\n$$\n\nDesign objective:\n- For the SAT penalty operator $\\mathbf{A}_{\\mathrm{SAT}}(\\tau)$, search over a specified range of $\\tau$ to maximize the smallest negative eigenvalue (the eigenvalue closest to 0 from below), denoted $\\lambda_{\\mathrm{small}}(\\tau) = \\max\\{\\lambda \\in \\mathrm{spec}(\\mathbf{A}_{\\mathrm{SAT}}(\\tau))\\}$. Report the maximizing value $\\tau^\\star$ and compute the corresponding CFL-limited Courant number $r_{\\max}$ using the most negative eigenvalue $\\lambda_{\\min}(\\tau^\\star)$.\n\nTasks:\n- For each test case below, construct $\\mathbf{A}_{\\mathrm{GP}}$ and $\\mathbf{A}_{\\mathrm{SAT}}(\\tau)$, compute their spectra, evaluate $r_{\\max}$ for GP-SD, and perform the design optimization over $\\tau$ for SAT to maximize $\\lambda_{\\mathrm{small}}(\\tau)$ and compute $r_{\\max}$ at $\\tau^\\star$.\n- The Courant number $r_{\\max}$ is dimensionless and must be reported as a floating-point number. The penalty parameter $\\tau^\\star$ is dimensionless and must be reported as a floating-point number. Eigenvalues must be reported as floating-point numbers.\n- The explicit time integrator is in seconds; do not report $\\Delta t$ directly. Report only the Courant number $r_{\\max}$.\n\nTest suite:\n- Use the following test cases $(L, c, N)$ with $L$ in meters, $c$ in meters per second, and $N$ dimensionless:\n    1. $(1.0, 1.5, 64)$\n    2. $(1.0, 0.8, 8)$\n    3. $(2.0, 2.0, 32)$\n    4. $(1.0, 1.2, 3)$\n- For SAT optimization, search $\\tau$ over the discrete set $\\{0.0, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0\\}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output a nested list of eight floating-point numbers in the following order:\n$\n\\big[\nr_{\\max}^{\\mathrm{GP}},\\; r_{\\max}^{\\mathrm{SAT}}(\\tau^\\star),\\; \\tau^\\star,\\; \\lambda_{\\min}^{\\mathrm{GP}},\\; \\lambda_{\\min}^{\\mathrm{SAT}}(\\tau^\\star),\\; \\lambda_{\\mathrm{small}}^{\\mathrm{GP}},\\; \\lambda_{\\mathrm{small}}^{\\mathrm{SAT}}(\\tau^\\star),\\; h\n\\big]\n$\nwhere $h$ is the grid spacing in meters. Aggregate the four per-test-case lists into a single outer list, e.g.,\n$[\\,[\\dots],\\,[\\dots],\\,[\\dots],\\,[\\dots]\\,]$.", "solution": "The user-provided problem is a well-posed exercise in numerical analysis, specifically concerning the application of the method of lines to the one-dimensional acoustic wave equation. All parameters, definitions, and objectives are clearly stated, scientifically sound, and mathematically consistent. The problem is valid and admits a unique, computable solution. We will therefore proceed with a full solution.\n\nThe problem requires an analysis of two spatial discretization schemes for the one-dimensional acoustic wave equation, $u_{tt} = c^2 u_{xx}$, on a domain $x \\in [0,L]$ with homogeneous Dirichlet boundary conditions $u(0,t)=u(L,t)=0$. The analysis is performed within the method of lines framework, where spatial derivatives are discretized first, yielding a system of ordinary differential equations (ODEs) in time, $\\mathbf{u}''(t) = c^2 \\mathbf{A}\\, \\mathbf{u}(t)$. Here, $\\mathbf{u}(t) \\in \\mathbb{R}^N$ is the vector of approximate solutions at $N$ interior grid points, and $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ is the matrix representing the discretized second spatial derivative, $u_{xx}$.\n\nThe stability of the explicit second-order central difference time integration scheme is governed by the Courant-Friedrichs-Lewy (CFL) condition, which relates the time step $\\Delta t$, the wave speed $c$, the spatial grid spacing $h$, and the spectrum of the operator $\\mathbf{A}$. The condition requires that $(c \\Delta t)^2 \\lambda \\in [-4,0]$ for all eigenvalues $\\lambda$ of $\\mathbf{A}$. Since the operators considered are symmetric and negative semi-definite, their eigenvalues are non-positive, $\\lambda \\le 0$. The stability condition is therefore limited by the most negative eigenvalue, $\\lambda_{\\min}$, leading to a maximum stable time step $\\Delta t_{\\max} = \\frac{2}{c \\sqrt{-\\lambda_{\\min}}}$. The corresponding maximum stable Courant number is $r_{\\max} = \\frac{c \\Delta t_{\\max}}{h} = \\frac{2}{h \\sqrt{-\\lambda_{\\min}}}$.\n\nThe spatial grid is uniform with $N$ interior points, defining a grid spacing of $h = \\frac{L}{N+1}$.\n\nWe analyze two definitions for the matrix $\\mathbf{A}$.\n\n1.  **Ghost-point strong Dirichlet (GP-SD) closure:** This method results in the standard symmetric tridiagonal matrix, denoted $\\mathbf{A}_{\\mathrm{GP}}$, which approximates the second derivative. The entries are given by:\n    $$\n    (\\mathbf{A}_{\\mathrm{GP}})_{i,j} = \\frac{1}{h^2} \\begin{cases} -2 & \\text{if } i=j \\\\ 1 & \\text{if } |i-j|=1 \\\\ 0 & \\text{otherwise} \\end{cases}\n    $$\n    The eigenvalues of this matrix are known analytically:\n    $$\n    \\lambda_k(\\mathbf{A}_{\\mathrm{GP}}) = -\\frac{4}{h^2} \\sin^2\\left(\\frac{k \\pi}{2(N+1)}\\right), \\quad k=1, 2, \\ldots, N.\n    $$\n    The smallest (least negative) eigenvalue is $\\lambda_{\\mathrm{small}}^{\\mathrm{GP}} = \\lambda_1$, and the most negative eigenvalue is $\\lambda_{\\min}^{\\mathrm{GP}} = \\lambda_N$.\n\n2.  **Simultaneous Approximation Term (SAT) penalty closure:** This method modifies the GP-SD operator by adding penalty terms that weakly enforce the boundary conditions. The resulting operator, $\\mathbf{A}_{\\mathrm{SAT}}(\\tau)$, is defined as:\n    $$\n    \\mathbf{A}_{\\mathrm{SAT}}(\\tau) = \\mathbf{A}_{\\mathrm{GP}} - \\frac{\\tau}{h^2}\\left(\\mathbf{e}_1 \\mathbf{e}_1^\\top + \\mathbf{e}_N \\mathbf{e}_N^\\top\\right),\n    $$\n    where $\\tau \\ge 0$ is a dimensionless penalty parameter and $\\mathbf{e}_1, \\mathbf{e}_N$ are the first and last canonical basis vectors. This modification only alters the first and last diagonal entries of $\\mathbf{A}_{\\mathrm{GP}}$, making them $(\\mathbf{A}_{\\mathrm{SAT}})_{1,1} = (\\mathbf{A}_{\\mathrm{SAT}})_{N,N} = -\\frac{2+\\tau}{h^2}$.\n\nThe primary objective is a design task: for each test case, we must find the value of $\\tau$ from a specified discrete set, denoted $\\tau^\\star$, that maximizes the smallest (least negative) eigenvalue of $\\mathbf{A}_{\\mathrm{SAT}}(\\tau)$, which we denote $\\lambda_{\\mathrm{small}}(\\tau) = \\max \\mathrm{spec}(\\mathbf{A}_{\\mathrm{SAT}}(\\tau))$.\n\nLet's analyze the effect of the penalty term. The matrix $\\mathbf{P} = \\frac{\\tau}{h^2}(\\mathbf{e}_1\\mathbf{e}_1^\\top + \\mathbf{e}_N\\mathbf{e}_N^\\top)$ is positive semi-definite for $\\tau \\ge 0$. The operator is $\\mathbf{A}_{\\mathrm{SAT}}(\\tau) = \\mathbf{A}_{\\mathrm{GP}} - \\mathbf{P}$. By Weyl's inequality on the eigenvalues of a sum of symmetric matrices, the eigenvalues of $\\mathbf{A}_{\\mathrm{SAT}}(\\tau)$, denoted $\\lambda_k(\\tau)$, are bounded by the eigenvalues of $\\mathbf{A}_{\\mathrm{GP}}$, denoted $\\lambda_k(0)$:\n$$\n\\lambda_k(0) + \\lambda_{\\min}(-\\mathbf{P}) \\le \\lambda_k(\\tau) \\le \\lambda_k(0) + \\lambda_{\\max}(-\\mathbf{P}).\n$$\nThe eigenvalues of $-\\mathbf{P}$ are $-\\frac{\\tau}{h^2}$ with multiplicity $2$ and $0$ with multiplicity $N-2$. Thus, $\\lambda_{\\min}(-\\mathbf{P}) = -\\frac{\\tau}{h^2}$ and $\\lambda_{\\max}(-\\mathbf{P}) = 0$. Applying this to the largest eigenvalue, $\\lambda_{\\mathrm{small}}$, we find:\n$$\n\\lambda_{\\mathrm{small}}^{\\mathrm{GP}} - \\frac{\\tau}{h^2} \\le \\lambda_{\\mathrm{small}}^{\\mathrm{SAT}}(\\tau) \\le \\lambda_{\\mathrm{small}}^{\\mathrm{GP}}.\n$$\nThis inequality demonstrates that for any $\\tau > 0$, the smallest eigenvalue of the SAT operator will be less than or equal to that of the GP-SD operator. The function $\\lambda_{\\mathrm{small}}(\\tau)$ is non-increasing. Consequently, its maximum over $\\tau \\ge 0$ must occur at $\\tau=0$.\n\nTherefore, for all test cases, the optimization procedure is expected to yield $\\tau^\\star = 0$. This implies that the SAT operator at the optimal $\\tau^\\star$ is identical to the GP-SD operator, i.e., $\\mathbf{A}_{\\mathrm{SAT}}(0) = \\mathbf{A}_{\\mathrm{GP}}$, and all their derived quantities will be identical. The algorithm will perform the specified search to numerically confirm this conclusion.\n\nThe solution is implemented by iterating through each test case $(L, c, N)$. For each case:\n1.  Calculate the grid spacing $h = L/(N+1)$.\n2.  Construct the $N \\times N$ matrix $\\mathbf{A}_{\\mathrm{GP}}$.\n3.  Calculate its eigenvalues using numerical linear algebra routines. The minimum and maximum of these eigenvalues give $\\lambda_{\\min}^{\\mathrm{GP}}$ and $\\lambda_{\\mathrm{small}}^{\\mathrm{GP}}$.\n4.  Compute $r_{\\max}^{\\mathrm{GP}} = 2 / (h \\sqrt{-\\lambda_{\\min}^{\\mathrm{GP}}})$.\n5.  Iterate through the specified set of $\\tau$ values. For each $\\tau$:\n    a. Construct the matrix $\\mathbf{A}_{\\mathrm{SAT}}(\\tau)$.\n    b. Compute its eigenvalues and find $\\lambda_{\\mathrm{small}}(\\tau)$.\n6.  Identify $\\tau^\\star$ as the value of $\\tau$ that yielded the largest $\\lambda_{\\mathrm{small}}(\\tau)$.\n7.  Using the spectrum computed for $\\mathbf{A}_{\\mathrm{SAT}}(\\tau^\\star)$, determine $\\lambda_{\\min}^{\\mathrm{SAT}}(\\tau^\\star)$ and $\\lambda_{\\mathrm{small}}^{\\mathrm{SAT}}(\\tau^\\star)$.\n8.  Compute $r_{\\max}^{\\mathrm{SAT}}(\\tau^\\star) = 2 / (h \\sqrt{-\\lambda_{\\min}^{\\mathrm{SAT}}(\\tau^\\star)})$.\n9.  Collect and format the eight required floating-point numbers: $r_{\\max}^{\\mathrm{GP}}$, $r_{\\max}^{\\mathrm{SAT}}(\\tau^\\star)$, $\\tau^\\star$, $\\lambda_{\\min}^{\\mathrm{GP}}$, $\\lambda_{\\min}^{\\mathrm{SAT}}(\\tau^\\star)$, $\\lambda_{\\mathrm{small}}^{\\mathrm{GP}}$, $\\lambda_{\\mathrm{small}}^{\\mathrm{SAT}}(\\tau^\\star)$, and $h$.\n\nThe final output is an aggregation of the results for all test cases into a single list of lists.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite, analyzing GP-SD and SAT\n    discretizations for the 1D wave equation.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Format: (L, c, N)\n    test_cases = [\n        (1.0, 1.5, 64),\n        (1.0, 0.8, 8),\n        (2.0, 2.0, 32),\n        (1.0, 1.2, 3),\n    ]\n\n    # Set of penalty parameters to search over\n    tau_search_set = [0.0, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0]\n\n    all_results = []\n    \n    for case in test_cases:\n        L, c, N = case\n        h = L / (N + 1)\n        h_sq = h**2\n\n        # 1. GP-SD Analysis\n        # Construct the A_GP matrix\n        main_diag_gp = -2.0 / h_sq * np.ones(N)\n        off_diag_gp = 1.0 / h_sq * np.ones(N - 1)\n        A_gp = np.diag(main_diag_gp) + np.diag(off_diag_gp, k=1) + np.diag(off_diag_gp, k=-1)\n\n        # Compute eigenvalues for the symmetric matrix A_GP\n        eigvals_gp = np.linalg.eigvalsh(A_gp)\n        # All eigenvalues are negative or zero, so min() is most negative\n        lambda_min_gp = np.min(eigvals_gp)\n        # max() is least negative (closest to zero)\n        lambda_small_gp = np.max(eigvals_gp)\n        \n        # Calculate r_max for GP-SD\n        if lambda_min_gp < 0:\n            r_max_gp = 2.0 / (h * np.sqrt(-lambda_min_gp))\n        else: # Should not happen for N > 0\n            r_max_gp = np.inf\n            \n        # 2. SAT Optimization\n        best_tau = -1.0\n        max_lambda_small = -np.inf\n        \n        # Variables to store the results for the optimal tau_star\n        lambda_min_sat_star = 0.0\n        lambda_small_sat_star = 0.0\n        r_max_sat_star = 0.0\n\n        for tau in tau_search_set:\n            # Construct the A_SAT(tau) matrix\n            A_sat = np.copy(A_gp)\n            penalty = tau / h_sq\n            A_sat[0, 0] -= penalty\n            A_sat[N - 1, N - 1] -= penalty\n            \n            # Compute eigenvalues for the symmetric matrix A_SAT\n            eigvals_sat = np.linalg.eigvalsh(A_sat)\n            current_lambda_small = np.max(eigvals_sat)\n            \n            # Check if this tau maximizes lambda_small\n            if current_lambda_small > max_lambda_small:\n                max_lambda_small = current_lambda_small\n                best_tau = tau\n                \n                # Store the results for this new best tau\n                lambda_min_sat_star = np.min(eigvals_sat)\n                lambda_small_sat_star = max_lambda_small\n                if lambda_min_sat_star < 0:\n                    r_max_sat_star = 2.0 / (h * np.sqrt(-lambda_min_sat_star))\n                else: # Should not happen\n                    r_max_sat_star = np.inf\n        \n        # Assemble the 8 required values for this test case\n        case_results = [\n            r_max_gp,\n            r_max_sat_star,\n            best_tau,\n            lambda_min_gp,\n            lambda_min_sat_star,\n            lambda_small_gp,\n            lambda_small_sat_star,\n            h,\n        ]\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # Construct the output string manually to match the required format\n    # e.g., [[val1,val2,...],[val1,val2,...]] without extra spaces.\n    outer_list_str = ','.join([f\"[{','.join(map(str, inner_list))}]\" for inner_list in all_results])\n    print(f\"[{outer_list_str}]\")\n\nsolve()\n```", "id": "3617036"}, {"introduction": "Our final practice ventures into the realm of modern high-order methods for hyperbolic conservation laws, which are essential for modeling advection-dominated geophysical phenomena like atmospheric fronts or seismic wave propagation. Standard high-order schemes can introduce spurious, non-physical oscillations near sharp gradients or discontinuities. This exercise introduces the Weighted Essentially Non-Oscillatory (WENO) scheme, a state-of-the-art technique that avoids this issue by adaptively combining information from several local stencils [@problem_id:3617085]. You will perform a hands-on calculation of the core components of the WENO algorithm—the smoothness indicators and nonlinear weights—to understand how it intelligently builds a high-fidelity, non-oscillatory reconstruction.", "problem": "Consider the one-dimensional linear conservation law $\\partial_{t} q(x,t) + \\partial_{x} f\\!\\big(q(x,t)\\big) = 0$ with flux $f(q) = a\\,q$, where $a>0$ is constant, modeling the advection of a dimensionless scalar attribute in a geophysical flow. Using the finite volume Method of Lines (MOL), denote by $Q_{i}(t)$ the cell-average of $q$ over the uniform cell $[x_{i-1/2}, x_{i+1/2}]$, so that the semi-discrete evolution satisfies $\\frac{d Q_{i}}{d t} = -\\frac{1}{\\Delta x}\\big(F_{i+1/2} - F_{i-1/2}\\big)$, where $F_{i+1/2}$ is a consistent numerical flux at the cell face $x_{i+1/2}$. For $a>0$, an upwind consistent choice is $F_{i+1/2} = a\\,q^{-}_{i+1/2}$, where $q^{-}_{i+1/2}$ is the left-biased face value reconstructed from cell averages.\n\nStarting from the conservative formulation above and the requirement of fifth-order accuracy in smooth regions, derive the fifth-order Weighted Essentially Non-Oscillatory (WENO) face values $q^{-}_{i+1/2}$ in a finite volume setting by constructing, on each of the three candidate stencils $\\{i-2,i-1,i\\}$, $\\{i-1,i,i+1\\}$, and $\\{i,i+1,i+2\\}$, a polynomial whose cell-averages match $\\{Q_{j}\\}$ on the cells in the stencil, and then evaluating those polynomials at $x_{i+1/2}$. Use the Jiang–Shu nonlinear weight formulation, with power $p=2$ and a small parameter $\\epsilon>0$, and with linear weights chosen to recover the fifth-order optimal linear scheme in smooth regions.\n\nFor a uniform grid with constant spacing $\\Delta x$, suppose the local cell-averages at time $t=t_{0}$ are\n$Q_{i-2} = 1.000$, $Q_{i-1} = 1.100$, $Q_{i} = 1.200$, $Q_{i+1} = 1.300$, $Q_{i+2} = 1.400$,\nand take the Jiang–Shu linear weights for the left-biased reconstruction at $x_{i+1/2}$ to be $d_{0} = \\frac{1}{10}$, $d_{1} = \\frac{6}{10}$, $d_{2} = \\frac{3}{10}$, with $\\epsilon = 10^{-6}$ and $p=2$.\n\nCarry out the derivation of the candidate face values and the smoothness indicators, compute the nonlinear weights on this data set, and then compute the reconstructed left-biased face value $q^{-}_{i+1/2}$ that would be used in the numerical flux. Express the final answer as a real number and round your result to six significant figures. The variable $q$ is dimensionless; report the final reconstructed face value $q^{-}_{i+1/2}$ with no units.", "solution": "The user-provided problem is critically examined and found to be valid. It is scientifically grounded in the established theory of numerical methods for partial differential equations, specifically the finite volume Weighted Essentially Non-Oscillatory (WENO) method for hyperbolic conservation laws. The problem is well-posed, providing all necessary data, definitions, and constants for a unique and meaningful solution. The language is objective and precise. Therefore, a full solution is warranted.\n\nThe goal is to compute the fifth-order WENO reconstructed value $q^{-}_{i+1/2}$ at the cell interface $x_{i+1/2}$ using the provided cell-average data $\\{Q_j\\}$. The procedure involves several steps: computing candidate reconstructions on smaller stencils, calculating smoothness indicators for these stencils, forming nonlinear weights, and finally combining the candidate reconstructions using these weights.\n\nThe fifth-order reconstruction utilizes a five-point stencil $\\{i-2, i-1, i, i+1, i+2\\}$. This is decomposed into three three-point candidate stencils:\n$S_0 = \\{x_{i-2}, x_{i-1}, x_i\\}$\n$S_1 = \\{x_{i-1}, x_i, x_{i+1}\\}$\n$S_2 = \\{x_i, x_{i+1}, x_{i+2}\\}$\n\n**Step 1: Compute Candidate Face Values**\nFor each stencil $S_k$, a quadratic polynomial $p_k(x)$ is implicitly constructed such that its cell averages match the given $Q_j$ on that stencil. These polynomials are then evaluated at the interface $x_{i+1/2}$ to yield three candidate values for the reconstruction, denoted $q^{(k)}_{i+1/2}$. The standard formulas for these candidate values in terms of the cell averages are:\n$$q^{(0)}_{i+1/2} = \\frac{1}{3}Q_{i-2} - \\frac{7}{6}Q_{i-1} + \\frac{11}{6}Q_{i}$$\n$$q^{(1)}_{i+1/2} = -\\frac{1}{6}Q_{i-1} + \\frac{5}{6}Q_{i} + \\frac{1}{3}Q_{i+1}$$\n$$q^{(2)}_{i+1/2} = \\frac{1}{3}Q_{i} + \\frac{5}{6}Q_{i+1} - \\frac{1}{6}Q_{i+2}$$\nThe given cell-average data is: $Q_{i-2} = 1.000$, $Q_{i-1} = 1.100$, $Q_{i} = 1.200$, $Q_{i+1} = 1.300$, $Q_{i+2} = 1.400$.\nSubstituting these values:\n$q^{(0)}_{i+1/2} = \\frac{1}{3}(1.000) - \\frac{7}{6}(1.100) + \\frac{11}{6}(1.200) = \\frac{2.000 - 7.700 + 13.200}{6} = \\frac{7.500}{6} = 1.250$\n$q^{(1)}_{i+1/2} = -\\frac{1}{6}(1.100) + \\frac{5}{6}(1.200) + \\frac{1}{3}(1.300) = \\frac{-1.100 + 6.000 + 2.600}{6} = \\frac{7.500}{6} = 1.250$\n$q^{(2)}_{i+1/2} = \\frac{1}{3}(1.200) + \\frac{5}{6}(1.300) - \\frac{1}{6}(1.400) = \\frac{2.400 + 6.500 - 1.400}{6} = \\frac{7.500}{6} = 1.250$\nThe data corresponds to cell averages of a linear function $q(x)$, for which all quadratic reconstructions are exact. Thus, all candidate values are identical and equal to the exact value of $q(x)$ at $x_{i+1/2}$.\n\n**Step 2: Compute Smoothness Indicators**\nThe smoothness indicators, $\\beta_k$, measure the regularity of the solution on each stencil $S_k$. For the fifth-order scheme, the Jiang-Shu formulation provides the following expressions:\n$$\\beta_0 = \\frac{13}{12}(Q_{i-2} - 2Q_{i-1} + Q_i)^2 + \\frac{1}{4}(Q_{i-2} - 4Q_{i-1} + 3Q_i)^2$$\n$$\\beta_1 = \\frac{13}{12}(Q_{i-1} - 2Q_i + Q_{i+1})^2 + \\frac{1}{4}(Q_{i-1} - Q_{i+1})^2$$\n$$\\beta_2 = \\frac{13}{12}(Q_i - 2Q_{i+1} + Q_{i+2})^2 + \\frac{1}{4}(3Q_i - 4Q_{i+1} + Q_{i+2})^2$$\nWe compute the necessary differences from the given data:\n$Q_{i-2} - 2Q_{i-1} + Q_i = 1.000 - 2(1.100) + 1.200 = 0$\n$Q_{i-1} - 2Q_i + Q_{i+1} = 1.100 - 2(1.200) + 1.300 = 0$\n$Q_i - 2Q_{i+1} + Q_{i+2} = 1.200 - 2(1.300) + 1.400 = 0$\nThese terms represent second-order differences, which are zero for linear data. For the remaining terms:\n$Q_{i-2} - 4Q_{i-1} + 3Q_i = 1.000 - 4(1.100) + 3(1.200) = 1.000 - 4.400 + 3.600 = 0.200$\n$Q_{i-1} - Q_{i+1} = 1.100 - 1.300 = -0.200$\n$3Q_i - 4Q_{i+1} + Q_{i+2} = 3(1.200) - 4(1.300) + 1.400 = 3.600 - 5.200 + 1.400 = -0.200$\nSubstituting these into the formulas for $\\beta_k$:\n$\\beta_0 = \\frac{13}{12}(0)^2 + \\frac{1}{4}(0.200)^2 = \\frac{1}{4}(0.04) = 0.01$\n$\\beta_1 = \\frac{13}{12}(0)^2 + \\frac{1}{4}(-0.200)^2 = \\frac{1}{4}(0.04) = 0.01$\n$\\beta_2 = \\frac{13}{12}(0)^2 + \\frac{1}{4}(-0.200)^2 = \\frac{1}{4}(0.04) = 0.01$\nThus, all three smoothness indicators are equal: $\\beta_0 = \\beta_1 = \\beta_2 = 0.01$.\n\n**Step 3: Compute Nonlinear Weights**\nThe nonlinear weights $\\omega_k$ are calculated from the smoothness indicators $\\beta_k$, the ideal linear weights $d_k$, a small parameter $\\epsilon$, and a power $p$. The problem gives $d_0 = \\frac{1}{10}$, $d_1 = \\frac{6}{10}$, $d_2 = \\frac{3}{10}$, $\\epsilon = 10^{-6}$, and $p=2$.\nFirst, unnormalized weights $\\alpha_k$ are computed:\n$$\\alpha_k = \\frac{d_k}{(\\epsilon + \\beta_k)^p}$$\nThe normalized weights $\\omega_k$ are then:\n$$\\omega_k = \\frac{\\alpha_k}{\\sum_{j=0}^{2} \\alpha_j}$$\nFor our data, $\\beta_0 = \\beta_1 = \\beta_2 = 0.01$. Let $\\beta = 0.01$. The denominator for each $\\alpha_k$ is the same:\n$(\\epsilon + \\beta)^p = (10^{-6} + 0.01)^2 = (0.010001)^2$.\nSo, we have:\n$\\alpha_0 = \\frac{d_0}{(0.010001)^2} = \\frac{0.1}{(0.010001)^2}$\n$\\alpha_1 = \\frac{d_1}{(0.010001)^2} = \\frac{0.6}{(0.010001)^2}$\n$\\alpha_2 = \\frac{d_2}{(0.010001)^2} = \\frac{0.3}{(0.010001)^2}$\nThe sum is $\\sum_{j=0}^{2} \\alpha_j = \\frac{d_0+d_1+d_2}{(0.010001)^2} = \\frac{0.1+0.6+0.3}{(0.010001)^2} = \\frac{1}{(0.010001)^2}$.\nThe nonlinear weights are:\n$\\omega_0 = \\frac{\\alpha_0}{\\sum \\alpha_j} = \\frac{d_0 / (0.010001)^2}{1 / (0.010001)^2} = d_0 = 0.1$\n$\\omega_1 = \\frac{\\alpha_1}{\\sum \\alpha_j} = \\frac{d_1 / (0.010001)^2}{1 / (0.010001)^2} = d_1 = 0.6$\n$\\omega_2 = \\frac{\\alpha_2}{\\sum \\alpha_j} = \\frac{d_2 / (0.010001)^2}{1 / (0.010001)^2} = d_2 = 0.3$\nThis demonstrates a key property of WENO: in very smooth regions, where the smoothness indicators are nearly equal, the nonlinear weights $\\omega_k$ approach the optimal linear weights $d_k$, thereby recovering the high order of accuracy of the underlying linear scheme.\n\n**Step 4: Compute the Final Reconstructed Value**\nThe final reconstructed value is the weighted average of the candidate values using the nonlinear weights:\n$$q^{-}_{i+1/2} = \\sum_{k=0}^{2} \\omega_k q^{(k)}_{i+1/2}$$\nSubstituting the computed values:\n$$q^{-}_{i+1/2} = \\omega_0 q^{(0)}_{i+1/2} + \\omega_1 q^{(1)}_{i+1/2} + \\omega_2 q^{(2)}_{i+1/2}$$\n$q^{-}_{i+1/2} = (0.1)(1.250) + (0.6)(1.250) + (0.3)(1.250)$\n$q^{-}_{i+1/2} = (0.1 + 0.6 + 0.3) \\times 1.250 = (1.0) \\times 1.250 = 1.250$\nThe result is exactly $1.25$. As required, rounding to six significant figures yields $1.25000$.", "answer": "$$\\boxed{1.25000}$$", "id": "3617085"}]}