{"hands_on_practices": [{"introduction": "A primary motivation for source encoding is improving acquisition efficiency, but how does blending sources affect the final signal-to-noise ratio? This exercise provides the theoretical foundation by analyzing noise propagation in an idealized scenario with perfectly orthogonal codes [@problem_id:3614649]. By deriving the final noise variance, you will build a crucial understanding of the statistical benefits of averaging multiple encoded experiments.", "problem": "A marine seismic acquisition survey uses simultaneous sources with code-based source encoding to accelerate data collection for inversion. At each fixed time sample, the data acquired across experiments can be treated as a linear system. There are $N$ simultaneous sources, and the survey performs $K$ repeated experiments where the sources are modulated by known codes. The linear model at a fixed time sample is\n$$\n\\mathbf{y} = \\mathbf{C}\\,\\mathbf{s} + \\mathbf{n},\n$$\nwhere $\\mathbf{y} \\in \\mathbb{R}^{K}$ collects the measured amplitudes over the $K$ experiments, $\\mathbf{s} \\in \\mathbb{R}^{N}$ collects the unknown true source responses at that time sample, $\\mathbf{C} \\in \\mathbb{R}^{K \\times N}$ is the known code matrix, and $\\mathbf{n} \\in \\mathbb{R}^{K}$ is measurement noise. Assume the following physical and statistical conditions:\n- The code matrix $\\mathbf{C}$ has orthogonal columns with equal energy, and $K \\ge N$. The entries of $\\mathbf{C}$ are $\\pm 1$. Consequently, $\\mathbf{C}^{\\top}\\mathbf{C} = K\\,\\mathbf{I}_{N}$.\n- The noise $\\mathbf{n}$ is zero-mean, white, and independent across experiments with covariance $\\mathbb{E}[\\mathbf{n}\\mathbf{n}^{\\top}] = \\sigma^{2}\\,\\mathbf{I}_{K}$, where $\\sigma^{2}$ is the noise variance per experiment and per time sample.\n- The decoding is performed by solving the linear least squares problem to obtain the estimate\n$$\n\\widehat{\\mathbf{s}} = \\arg\\min_{\\mathbf{z} \\in \\mathbb{R}^{N}} \\|\\mathbf{y} - \\mathbf{C}\\,\\mathbf{z}\\|_{2}^{2},\n$$\nwhich yields the standard normal equations solution $\\widehat{\\mathbf{s}} = (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{y}$.\n- Treat amplitudes as dimensionless so that variances are dimensionless.\n\nUsing only these assumptions and the linearity of expectation and covariance, compute the decoded noise variance for any single source component $\\widehat{s}_{i}$ at the fixed time sample after decoding. Express your final answer as an exact analytic expression in terms of $\\sigma$ and $K$. No numerical rounding is required. The final answer must be a single expression without units.", "solution": "The user wants me to solve a problem from computational geophysics, specifically regarding source encoding in seismic acquisition.\n\n### Step 1: Extract Givens\n- The linear model is $\\mathbf{y} = \\mathbf{C}\\,\\mathbf{s} + \\mathbf{n}$.\n- $\\mathbf{y} \\in \\mathbb{R}^{K}$ is the vector of measured amplitudes over $K$ experiments.\n- $\\mathbf{s} \\in \\mathbb{R}^{N}$ is the vector of unknown true source responses.\n- $\\mathbf{C} \\in \\mathbb{R}^{K \\times N}$ is the known code matrix.\n- $\\mathbf{n} \\in \\mathbb{R}^{K}$ is the measurement noise vector.\n- $N$ is the number of simultaneous sources.\n- $K$ is the number of repeated experiments.\n- The constraint $K \\ge N$ holds.\n- The code matrix $\\mathbf{C}$ has orthogonal columns with equal energy, and its entries are $\\pm 1$. This property is summarized by the equation $\\mathbf{C}^{\\top}\\mathbf{C} = K\\,\\mathbf{I}_{N}$, where $\\mathbf{I}_{N}$ is the $N \\times N$ identity matrix.\n- The noise $\\mathbf{n}$ is zero-mean, i.e., $\\mathbb{E}[\\mathbf{n}] = \\mathbf{0}$.\n- The noise covariance is $\\mathbb{E}[\\mathbf{n}\\mathbf{n}^{\\top}] = \\sigma^{2}\\,\\mathbf{I}_{K}$, where $\\sigma^{2}$ is the noise variance per experiment and $\\mathbf{I}_{K}$ is the $K \\times K$ identity matrix.\n- The estimated source response vector, $\\widehat{\\mathbf{s}}$, is obtained via the linear least squares solution: $\\widehat{\\mathbf{s}} = (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{y}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Groundedness**: The problem is scientifically sound. It describes a standard method for deblending simultaneously acquired seismic data using coded sources. The linear model, least squares estimation, and statistical assumptions about noise are fundamental concepts in signal processing and inverse problems. The properties of the code matrix $\\mathbf{C}$ are consistent with those of matrices used in practice, such as Hadamard matrices.\n- **Well-Posedness**: The problem is well-posed. All required variables and conditions are specified. The condition $\\mathbf{C}^{\\top}\\mathbf{C} = K\\,\\mathbf{I}_{N}$ guarantees that the matrix $\\mathbf{C}^{\\top}\\mathbf{C}$ is invertible (since $K \\neq 0$), ensuring a unique solution for $\\widehat{\\mathbf{s}}$ exists. The objective is to compute a specific, well-defined statistical quantity.\n- **Objectivity**: The problem is stated in precise, objective mathematical language.\n- **Completeness and Consistency**: The problem is self-contained and free of contradictions. The given relationship $\\mathbf{C}^{\\top}\\mathbf{C} = K\\,\\mathbf{I}_{N}$ is consistent with the description of $\\mathbf{C}$ having orthogonal columns with entries of $\\pm 1$. The norm squared of each column vector $\\mathbf{c}_{j}$ is $\\mathbf{c}_{j}^{\\top}\\mathbf{c}_{j} = \\sum_{i=1}^{K} (\\pm 1)^{2} = K$. The orthogonality implies $\\mathbf{c}_{i}^{\\top}\\mathbf{c}_{j} = 0$ for $i \\neq j$. These combine to form $\\mathbf{C}^{\\top}\\mathbf{C} = K\\,\\mathbf{I}_{N}$.\n- **Verdict**: The problem is valid and can be solved as stated.\n\n### Step 3: Derivation\nThe goal is to compute the variance of a single decoded source component, $\\mathrm{Var}(\\widehat{s}_{i})$. This is the $i$-th diagonal entry of the covariance matrix of the vector $\\widehat{\\mathbf{s}}$, denoted $\\mathrm{Cov}(\\widehat{\\mathbf{s}})$.\n\nFirst, we express the estimated source vector $\\widehat{\\mathbf{s}}$ in terms of the true sources $\\mathbf{s}$ and the noise $\\mathbf{n}$. We substitute the linear model $\\mathbf{y} = \\mathbf{C}\\,\\mathbf{s} + \\mathbf{n}$ into the expression for $\\widehat{\\mathbf{s}}$:\n$$\n\\widehat{\\mathbf{s}} = (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}(\\mathbf{C}\\,\\mathbf{s} + \\mathbf{n})\n$$\nUsing the distributive property of matrix multiplication:\n$$\n\\widehat{\\mathbf{s}} = (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{C}\\,\\mathbf{s} + (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n}\n$$\nThe term $(\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{C}$ simplifies to the identity matrix $\\mathbf{I}_{N}$. Thus, the expression becomes:\n$$\n\\widehat{\\mathbf{s}} = \\mathbf{I}_{N}\\,\\mathbf{s} + (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n} = \\mathbf{s} + (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n}\n$$\nThis equation shows that the estimated vector $\\widehat{\\mathbf{s}}$ is the sum of the true signal vector $\\mathbf{s}$ and a term representing the decoded noise. Let's find the expected value of $\\widehat{\\mathbf{s}}$. Since $\\mathbf{s}$ and $\\mathbf{C}$ are deterministic, and the expectation operator is linear:\n$$\n\\mathbb{E}[\\widehat{\\mathbf{s}}] = \\mathbb{E}[\\mathbf{s} + (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n}] = \\mathbf{s} + (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbb{E}[\\mathbf{n}]\n$$\nWe are given that the noise is zero-mean, $\\mathbb{E}[\\mathbf{n}] = \\mathbf{0}$. Therefore:\n$$\n\\mathbb{E}[\\widehat{\\mathbf{s}}] = \\mathbf{s}\n$$\nThis shows that the least squares estimator is unbiased.\n\nNext, we compute the covariance matrix of $\\widehat{\\mathbf{s}}$. The covariance matrix is defined as $\\mathrm{Cov}(\\widehat{\\mathbf{s}}) = \\mathbb{E}[(\\widehat{\\mathbf{s}} - \\mathbb{E}[\\widehat{\\mathbf{s}}])(\\widehat{\\mathbf{s}} - \\mathbb{E}[\\widehat{\\mathbf{s}}])^{\\top}]$.\nSubstituting $\\mathbb{E}[\\widehat{\\mathbf{s}}] = \\mathbf{s}$, we get:\n$$\n\\widehat{\\mathbf{s}} - \\mathbb{E}[\\widehat{\\mathbf{s}}] = (\\mathbf{s} + (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n}) - \\mathbf{s} = (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n}\n$$\nSo the covariance matrix is:\n$$\n\\mathrm{Cov}(\\widehat{\\mathbf{s}}) = \\mathbb{E}\\left[ \\left( (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n} \\right) \\left( (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{n} \\right)^{\\top} \\right]\n$$\nLet's define the matrix $\\mathbf{A} = (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}$. The expression becomes $\\mathbb{E}[(\\mathbf{A}\\mathbf{n})(\\mathbf{A}\\mathbf{n})^{\\top}] = \\mathbb{E}[\\mathbf{A}\\mathbf{n}\\mathbf{n}^{\\top}\\mathbf{A}^{\\top}]$. Since $\\mathbf{A}$ is a constant matrix, we can pull it out of the expectation:\n$$\n\\mathrm{Cov}(\\widehat{\\mathbf{s}}) = \\mathbf{A}\\,\\mathbb{E}[\\mathbf{n}\\mathbf{n}^{\\top}]\\,\\mathbf{A}^{\\top} = \\left( (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top} \\right) \\mathbb{E}[\\mathbf{n}\\mathbf{n}^{\\top}] \\left( (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top} \\right)^{\\top}\n$$\nWe are given that $\\mathbb{E}[\\mathbf{n}\\mathbf{n}^{\\top}] = \\sigma^{2}\\,\\mathbf{I}_{K}$. Substituting this in:\n$$\n\\mathrm{Cov}(\\widehat{\\mathbf{s}}) = \\left( (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top} \\right) (\\sigma^{2}\\,\\mathbf{I}_{K}) \\left( \\mathbf{C}((\\mathbf{C}^{\\top}\\mathbf{C})^{-1})^{\\top} \\right)\n$$\nThe matrix $\\mathbf{C}^{\\top}\\mathbf{C}$ is symmetric, so its inverse is also symmetric, meaning $((\\mathbf{C}^{\\top}\\mathbf{C})^{-1})^{\\top} = (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}$. The expression simplifies to:\n$$\n\\mathrm{Cov}(\\widehat{\\mathbf{s}}) = \\sigma^{2} (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\\mathbf{C}^{\\top}\\mathbf{C}(\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\n$$\nSince $\\mathbf{C}^{\\top}\\mathbf{C}$ is invertible, the product $(\\mathbf{C}^{\\top}\\mathbf{C})(\\mathbf{C}^{\\top}\\mathbf{C})^{-1}$ is the identity matrix $\\mathbf{I}_{N}$.\n$$\n\\mathrm{Cov}(\\widehat{\\mathbf{s}}) = \\sigma^{2} (\\mathbf{C}^{\\top}\\mathbf{C})^{-1} \\mathbf{I}_{N} = \\sigma^{2} (\\mathbf{C}^{\\top}\\mathbf{C})^{-1}\n$$\nNow, we use the specific property of the code matrix, $\\mathbf{C}^{\\top}\\mathbf{C} = K\\,\\mathbf{I}_{N}$. We take the inverse of this expression:\n$$\n(\\mathbf{C}^{\\top}\\mathbf{C})^{-1} = (K\\,\\mathbf{I}_{N})^{-1} = \\frac{1}{K}\\mathbf{I}_{N}^{-1} = \\frac{1}{K}\\mathbf{I}_{N}\n$$\nSubstituting this result into our expression for the covariance matrix:\n$$\n\\mathrm{Cov}(\\widehat{\\mathbf{s}}) = \\sigma^{2} \\left( \\frac{1}{K}\\mathbf{I}_{N} \\right) = \\frac{\\sigma^{2}}{K}\\mathbf{I}_{N}\n$$\nThe variance of a single decoded source component, $\\widehat{s}_{i}$, is the $i$-th diagonal element of the covariance matrix $\\mathrm{Cov}(\\widehat{\\mathbf{s}})$.\n$$\n\\mathrm{Var}(\\widehat{s}_{i}) = [\\mathrm{Cov}(\\widehat{\\mathbf{s}})]_{ii} = \\left[ \\frac{\\sigma^{2}}{K}\\mathbf{I}_{N} \\right]_{ii}\n$$\nSince the $i$-th diagonal element of the identity matrix $\\mathbf{I}_{N}$ is $1$, we have:\n$$\n\\mathrm{Var}(\\widehat{s}_{i}) = \\frac{\\sigma^{2}}{K}\n$$\nThis result is independent of the index $i$, meaning the decoded noise variance is the same for all source components. It is inversely proportional to the number of experiments, $K$, which is an expected result from signal averaging principles.", "answer": "$$\n\\boxed{\\frac{\\sigma^{2}}{K}}\n$$", "id": "3614649"}, {"introduction": "Moving from theory to practice, we now explore how real-world conditions affect the ideal performance of source codes. Perfect orthogonality is a mathematical convenience, but in seismic acquisition, factors like irregular source and receiver geometry introduce time shifts that corrupt this property [@problem_id:3614647]. This hands-on coding exercise challenges you to quantify this degradation by computing the deblending condition number, developing your intuition for how survey design impacts the stability of the final result.", "problem": "You are tasked with building a complete, runnable program that quantifies how irregular spatial shot spacing interacts with deterministic source code orthogonality in simultaneous-source seismic acquisition and computes the resulting deblending condition number. Your program must be based on the following physically and numerically grounded model and definitions.\n\nConsider a one-dimensional marine acquisition line with a single receiver at position $x_r$ and $S$ simultaneously fired sources at positions $\\{x_s^{(i)}\\}_{i=1}^S$. Each source is encoded by a deterministic binary sequence of length $N$ samples, denoted $\\{c_i[n]\\}_{n=0}^{N-1}$, and generated as distinct column vectors from a Walsh–Hadamard matrix of order $N$. The sampling frequency is $f_s$ in Hertz and the constant propagation velocity is $v$ in meters per second. The recorded blended data at the receiver are modeled as a linear superposition of source responses modulated by their codes. To isolate the effect of code orthogonality interacting with geometry, assume each source’s code is shifted in time due to geometric travel-time such that its effective contribution in the deblending system matrix is a time-shifted and window-truncated version of its code.\n\nDefine the integer time-shift for source $i$ as\n$$\nm_i = \\text{round}\\!\\left( \\frac{|x_s^{(i)} - x_r|}{v} f_s \\right),\n$$\ncorresponding to the discrete sample delay induced by travel-time $|x_s^{(i)} - x_r|/v$ seconds. Let $\\mathbf{A} \\in \\mathbb{R}^{N \\times S}$ denote the deblending matrix whose $i$-th column is the code $\\{c_i[n]\\}$ shifted to the right by $m_i$ samples with zero-padding, i.e.,\n$$\na_i[n] = \n\\begin{cases}\n0, & 0 \\le n < m_i, \\\\\nc_i[n - m_i], & m_i \\le n \\le N-1.\n\\end{cases}\n$$\nThe deblending normal matrix (code Gram matrix under geometric shifts) is $\\mathbf{G} = \\mathbf{A}^\\top \\mathbf{A} \\in \\mathbb{R}^{S \\times S}$. The deblending condition number is defined as\n$$\n\\kappa(\\mathbf{G}) = \\frac{\\lambda_{\\max}(\\mathbf{G})}{\\lambda_{\\min}(\\mathbf{G})},\n$$\nwhere $\\lambda_{\\max}(\\mathbf{G})$ and $\\lambda_{\\min}(\\mathbf{G})$ denote the largest and smallest eigenvalues of $\\mathbf{G}$, respectively. A larger $\\kappa(\\mathbf{G})$ indicates poorer stability of deblending due to degraded effective orthogonality of the encoded sources under the induced time shifts.\n\nStarting from the linear superposition principle for wavefields and the definition of deterministic code orthogonality under uniform sampling, derive the computational procedure to form $\\mathbf{A}$, assemble $\\mathbf{G}$, and compute $\\kappa(\\mathbf{G})$ for the following test suite. All distances must be interpreted in meters (m), velocity in meters per second (m/s), and sampling frequency in Hertz (Hz). The outputs (condition numbers) are dimensionless floats.\n\nTest suite parameter sets:\n\n1. Case 1 (baseline regular spacing in the sense of zero geometric delay):\n   - $N = 128$, $f_s = 500$ Hz, $v = 1500$ m/s, $x_r = 0$ m, $S = 8$,\n   - Shot positions $x_s^{(i)}$: all equal to $0$ m for $i = 1, \\dots, 8$.\n\n2. Case 2 (mild irregular spacing producing small but distinct sample delays):\n   - $N = 128$, $f_s = 500$ Hz, $v = 1500$ m/s, $x_r = 0$ m, $S = 8$,\n   - Shot positions $x_s^{(i)} \\in \\{0, 3, 6, 9, 12, 15, 18, 21\\}$ m.\n\n3. Case 3 (strong irregular spacing with one far source causing a large delay and window truncation):\n   - $N = 128$, $f_s = 500$ Hz, $v = 1500$ m/s, $x_r = 0$ m, $S = 8$,\n   - Shot positions $x_s^{(i)} \\in \\{0, 3, 6, 9, 354, 12, 15, 18\\}$ m.\n\n4. Case 4 (increased simultaneous sources with broader irregular delays):\n   - $N = 128$, $f_s = 1000$ Hz, $v = 1500$ m/s, $x_r = 0$ m, $S = 32$,\n   - Shot positions $x_s^{(i)}$ given explicitly by the list\n     $\\{0, 2.0, 1.5, 4.0, 3.5, 7.0, 6.5, 9.0, 10.5, 13.0, 12.5, 16.0, 17.5, 20.0, 22.5, 25.0, 27.5, 30.0, 33.5, 36.0, 38.5, 41.0, 43.5, 46.0, 48.5, 50.0, 52.5, 55.0, 57.5, 60.0, 62.5, 65.0\\}$ m.\n\nImplementation requirements:\n\n- Deterministic codes must be taken as the first $S$ columns of a Walsh–Hadamard matrix of order $N$.\n- Time shifts must be applied as right-shifts with zero-padding and truncation to length $N$ samples.\n- The eigenvalues of $\\mathbf{G}$ must be computed numerically, and the condition number must be evaluated as defined above. If $\\lambda_{\\min}(\\mathbf{G})$ is numerically non-positive due to rounding error, treat the condition number as infinite.\n- Your program must produce a single line of output containing the four condition numbers for the four cases as a comma-separated list enclosed in square brackets. Each condition number must be rounded to six decimal places. For example: \"[1.000000,1.234567,3.210000,5.678901]\".", "solution": "The problem requires the computation of the deblending condition number for several simultaneous-source seismic acquisition scenarios. This number quantifies the numerical stability of separating the signals from individual sources, a process known as deblending. The core of the problem lies in the interaction between the deterministic source codes, which are chosen to be orthogonal, and the acquisition geometry, which introduces time shifts that corrupt this orthogonality.\n\nThe solution will be derived by following these fundamental principles:\n1.  Generation of orthogonal source codes using a Walsh-Hadamard matrix.\n2.  Calculation of geometry-induced time delays for each source.\n3.  Construction of the deblending matrix $\\mathbf{A}$ by applying these time delays to the source codes.\n4.  Formation of the normal matrix $\\mathbf{G} = \\mathbf{A}^\\top \\mathbf{A}$.\n5.  Computation of the condition number $\\kappa(\\mathbf{G})$ from its eigenvalues.\n\n**1. Orthogonal Source Encoding**\nIn simultaneous-source acquisition, each source is modulated by a unique code to enable subsequent separation. Ideal codes are mutually orthogonal. The problem specifies using the columns of a Walsh-Hadamard matrix. A Walsh-Hadamard matrix $\\mathbf{H}_N$ of order $N$ (where $N$ is a power of $2$) is a square matrix with entries of $+1$ and $-1$. Its defining property is that its columns (and rows) are mutually orthogonal. Specifically, for any two distinct columns $\\mathbf{c}_i$ and $\\mathbf{c}_j$, their dot product is zero: $\\mathbf{c}_i^\\top \\mathbf{c}_j = 0$. The squared norm of any column is $\\mathbf{c}_i^\\top \\mathbf{c}_i = N$. This orthogonality is summarized by the matrix equation $\\mathbf{H}_N^\\top \\mathbf{H}_N = N \\mathbf{I}_N$, where $\\mathbf{I}_N$ is the identity matrix of order $N$.\n\nFor this problem, the codes for the $S$ sources are the first $S$ columns of $\\mathbf{H}_N$, denoted $\\{\\mathbf{c}_i\\}_{i=1}^S$. If there were no time delays, the deblending matrix $\\mathbf{A}$ would simply be the matrix $\\mathbf{C} = [\\mathbf{c}_1, \\dots, \\mathbf{c}_S]$. The normal matrix would be $\\mathbf{G} = \\mathbf{C}^\\top \\mathbf{C}$, which is an $S \\times S$ diagonal matrix with all diagonal entries equal to $N$. For such a matrix, $\\lambda_{\\max}(\\mathbf{G}) = \\lambda_{\\min}(\\mathbf{G}) = N$, and the condition number $\\kappa(\\mathbf{G}) = 1$. This represents a perfectly well-conditioned deblending problem.\n\n**2. Geometry-Induced Time Delays**\nThe seismic wave from a source at position $x_s^{(i)}$ travels to a receiver at position $x_r$ at a velocity $v$. The travel time is $\\Delta t_i = |x_s^{(i)} - x_r|/v$. In a digitally sampled system with sampling frequency $f_s$, this continuous time delay corresponds to a discrete shift of $m_i$ samples. As defined in the problem, this integer shift is calculated as:\n$$\nm_i = \\text{round}\\!\\left( \\frac{|x_s^{(i)} - x_r|}{v} f_s \\right)\n$$\n\n**3. The Deblending Matrix $\\mathbf{A}$**\nThe time delay $m_i$ for source $i$ means that its code sequence $\\mathbf{c}_i$ effectively starts $m_i$ samples later in the recorded data trace. This is modeled by constructing a new set of \"effective\" code vectors, $\\{\\mathbf{a}_i\\}_{i=1}^S$, which form the columns of the deblending matrix $\\mathbf{A}$. The vector $\\mathbf{a}_i$ is a right-shifted and truncated version of the original code vector $\\mathbf{c}_i$. The $n$-th element of the $i$-th column of $\\mathbf{A}$ is given by:\n$$\na_i[n] = \n\\begin{cases}\n0, & 0 \\le n < m_i \\\\\nc_i[n - m_i], & m_i \\le n \\le N-1\n\\end{cases}\n$$\nThis operation effectively pads the start of the code with $m_i$ zeros and truncates the end of the code, so the resulting vector $\\mathbf{a}_i$ still has length $N$. If $m_i \\ge N$, the entire vector $\\mathbf{a}_i$ will be zero.\n\n**4. The Normal Matrix $\\mathbf{G}$ and its Condition Number**\nThe deblending normal matrix is defined as $\\mathbf{G} = \\mathbf{A}^\\top \\mathbf{A}$. The element $G_{ij}$ is the dot product of the shifted code vectors: $G_{ij} = \\mathbf{a}_i^\\top \\mathbf{a}_j$. Due to the time shifts, even if $\\mathbf{c}_i^\\top \\mathbf{c}_j = 0$ for $i \\ne j$, the dot product $\\mathbf{a}_i^\\top \\mathbf{a}_j$ will generally be non-zero. These non-zero off-diagonal elements represent the \"cross-talk\" or loss of orthogonality between the sources as measured at the receiver. The diagonal elements $G_{ii} = \\mathbf{a}_i^\\top \\mathbf{a}_i$ represent the energy of the shifted-and-truncated code, which is less than or equal to the original energy $N$.\n\nThe condition number of $\\mathbf{G}$, defined as $\\kappa(\\mathbf{G}) = \\lambda_{\\max}(\\mathbf{G}) / \\lambda_{\\min}(\\mathbf{G})$, measures the stability of the deblending problem. A value of $\\kappa(\\mathbf{G}) = 1$ is ideal. A large condition number signifies that $\\mathbf{G}$ is close to being singular, indicating that small errors in the data can lead to large errors in the separated source signals. This implies an ill-conditioned and numerically unstable deblending problem. If $\\mathbf{G}$ becomes singular, $\\lambda_{\\min}(\\mathbf{G}) = 0$, and the condition number is considered infinite.\n\n**Computational Algorithm**\nThe following steps are implemented for each test case to compute the condition number:\n1.  Obtain the parameters: code length $N$, number of sources $S$, sampling frequency $f_s$, velocity $v$, receiver position $x_r$, and source positions $\\{x_s^{(i)}\\}$.\n2.  Generate the $N \\times N$ Walsh-Hadamard matrix, $\\mathbf{H}_N$. The first $S$ columns are taken as the source codes, forming the $N \\times S$ matrix $\\mathbf{C}$.\n3.  For each source $i=1, \\dots, S$, calculate the integer sample shift $m_i$ using the provided formula.\n4.  Initialize an $N \\times S$ zero matrix for $\\mathbf{A}$.\n5.  For each source $i$, construct its corresponding column $\\mathbf{a}_i$ by shifting the code $\\mathbf{c}_i$ by $m_i$ samples, applying zero-padding and truncation as per the definition. If $m_i < N$, the first $N-m_i$ elements of $\\mathbf{c}_i$ are placed into $\\mathbf{a}_i$ starting at index $m_i$.\n6.  Calculate the $S \\times S$ normal matrix $\\mathbf{G} = \\mathbf{A}^\\top \\mathbf{A}$.\n7.  Compute the eigenvalues of the real symmetric matrix $\\mathbf{G}$.\n8.  Find the maximum eigenvalue, $\\lambda_{\\max}$, and the minimum eigenvalue, $\\lambda_{\\min}$.\n9.  If $\\lambda_{\\min} \\le 0$, the condition number is treated as infinite. Otherwise, it is calculated as $\\kappa(\\mathbf{G}) = \\lambda_{\\max} / \\lambda_{\\min}$.\n10. The final value is rounded to six decimal places.\n\nThis procedure is applied to each of the four test cases specified.\n- Case 1 represents the ideal scenario with zero time shifts ($m_i = 0$ for all $i$), where $\\mathbf{A}=\\mathbf{C}$ and perfect orthogonality is maintained, yielding $\\kappa(\\mathbf{G}) = 1$.\n- Case 2 introduces small, distinct time shifts, causing minor degradation of orthogonality and a condition number slightly greater than $1$.\n- Case 3 includes a source with a large time shift, leading to significant truncation of its code. This is expected to severely impact orthogonality and substantially increase the condition number.\n- Case 4 increases the density of sources ($S=32$), leading to more complex cross-talk interactions and potentially a higher condition number.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import hadamard\n\ndef solve():\n    \"\"\"\n    Computes the deblending condition number for four simultaneous-source\n    seismic acquisition scenarios.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 128, \"fs\": 500, \"v\": 1500, \"xr\": 0, \"S\": 8,\n            \"xs\": np.array([0, 0, 0, 0, 0, 0, 0, 0], dtype=float)\n        },\n        {\n            \"N\": 128, \"fs\": 500, \"v\": 1500, \"xr\": 0, \"S\": 8,\n            \"xs\": np.array([0, 3, 6, 9, 12, 15, 18, 21], dtype=float)\n        },\n        {\n            \"N\": 128, \"fs\": 500, \"v\": 1500, \"xr\": 0, \"S\": 8,\n            \"xs\": np.array([0, 3, 6, 9, 354, 12, 15, 18], dtype=float)\n        },\n        {\n            \"N\": 128, \"fs\": 1000, \"v\": 1500, \"xr\": 0, \"S\": 32,\n            \"xs\": np.array([\n                0, 2.0, 1.5, 4.0, 3.5, 7.0, 6.5, 9.0, 10.5, 13.0, 12.5, 16.0, \n                17.5, 20.0, 22.5, 25.0, 27.5, 30.0, 33.5, 36.0, 38.5, 41.0, \n                43.5, 46.0, 48.5, 50.0, 52.5, 55.0, 57.5, 60.0, 62.5, 65.0\n            ], dtype=float)\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N = case[\"N\"]\n        fs = case[\"fs\"]\n        v = case[\"v\"]\n        xr = case[\"xr\"]\n        S = case[\"S\"]\n        xs = case[\"xs\"]\n\n        # Step 1: Generate Walsh-Hadamard matrix and extract codes\n        # The codes are the first S columns of the Hadamard matrix.\n        H = hadamard(N)\n        C = H[:, :S]\n\n        # Step 2: Calculate integer time shifts for each source\n        shifts_m = np.round(np.abs(xs - xr) / v * fs).astype(int)\n\n        # Step 3: Construct the deblending matrix A by applying shifts\n        A = np.zeros((N, S), dtype=float)\n        for i in range(S):\n            m_i = shifts_m[i]\n            if m_i < N:\n                # The length of the code segment that fits\n                code_len = N - m_i\n                # Get the code for the current source\n                code_i = C[:, i]\n                # Place the truncated code into the shifted position in A\n                A[m_i:, i] = code_i[:code_len]\n        \n        # Step 4: Compute the normal matrix G = A^T * A\n        G = A.T @ A\n\n        # Step 5: Compute eigenvalues of G\n        # eigvalsh is used for real symmetric matrices, it is efficient and returns sorted eigenvalues.\n        eigenvalues = np.linalg.eigvalsh(G)\n        \n        lambda_min = eigenvalues[0]  # Smallest eigenvalue\n        lambda_max = eigenvalues[-1] # Largest eigenvalue\n\n        # Step 6: Calculate the condition number\n        # As per problem, if lambda_min <= 0, treat as infinite.\n        if lambda_min <= 0:\n            cond_num = np.inf\n        else:\n            cond_num = lambda_max / lambda_min\n            \n        results.append(cond_num)\n\n    # Format the results as specified: a list of strings rounded to 6 decimal places.\n    # Handle the case of an infinite condition number.\n    formatted_results = []\n    for r in results:\n        if np.isinf(r):\n            formatted_results.append(\"inf\") \n        else:\n            formatted_results.append(f\"{r:.6f}\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "3614647"}, {"introduction": "Having explored the statistical and geometric aspects of encoding, we now turn to the practical details of numerical implementation. This exercise focuses on how to correctly and efficiently inject multiple encoded sources within a finite-difference time-domain (FDTD) simulation, leveraging the fundamental principle of linear superposition [@problem_id:3614634]. You will analyze whether this common implementation strategy alters the solver's numerical stability, a critical concern for any computational modeling effort.", "problem": "Consider a linear acoustic wave equation in $d$ spatial dimensions for the pressure field $u(\\mathbf{x}, t)$,\n$$\n\\frac{\\partial^2 u}{\\partial t^2}(\\mathbf{x}, t) = c^2(\\mathbf{x}) \\nabla^2 u(\\mathbf{x}, t) + s(\\mathbf{x}, t),\n$$\nwhere $c(\\mathbf{x})$ is the spatially varying wavespeed and $s(\\mathbf{x}, t)$ is a source term. A standard explicit second-order finite-difference time-domain scheme updates the discrete field $u^n_{\\mathbf{i}} \\approx u(\\mathbf{x}_{\\mathbf{i}}, t_n)$ by\n$$\nu^{n+1}_{\\mathbf{i}} = 2 u^{n}_{\\mathbf{i}} - u^{n-1}_{\\mathbf{i}} + \\Delta t^2\\, c^2_{\\mathbf{i}} \\sum_{j=1}^{d} \\frac{u^n_{\\mathbf{i}+\\mathbf{e}_j} - 2 u^n_{\\mathbf{i}} + u^n_{\\mathbf{i}-\\mathbf{e}_j}}{\\Delta x_j^2} + \\Delta t^2\\, s^n_{\\mathbf{i}},\n$$\nwhere $\\Delta t$ is the time step, $\\Delta x_j$ are the grid spacings in each coordinate direction, $\\mathbf{e}_j$ are unit grid offsets, and $s^n_{\\mathbf{i}}$ is the discrete source at time $t_n$.\n\nYou are tasked with implementing simultaneous-source encoding in the time domain for seismic inversion. Suppose there are $K$ physical sources, each with discrete injection $s^{(k),n}_{\\mathbf{i}}$ (for $k = 1, \\dots, K$). A simultaneous encoded source constructs\n$$\ns^n_{\\mathbf{i}} = \\sum_{k=1}^{K} w_k\\, s^{(k),n}_{\\mathbf{i}},\n$$\nwhere $w_k$ are encoding weights (for example, independent Rademacher $\\pm 1$ or Gaussian weights). The computational objective is to inject all $K$ sources per time step without introducing additional checkpointing overhead beyond what is needed for a single encoded shot, and to determine whether this affects the Courant–Friedrichs–Lewy (CFL) stability constraint.\n\nStarting from the linearity of the governing equation and the explicit update scheme, and using a von Neumann analysis for the homogeneous part (with $s \\equiv 0$) on a uniform grid with $\\Delta x_j = h$ and constant speed $c(\\mathbf{x}) \\equiv c$, derive the CFL-like stability condition and assess whether injecting multiple encoded sources at each time step modifies this condition. Your reasoning must proceed from first principles: the linear superposition property, properties of the discrete Laplacian spectrum, and the amplification factor analysis. Assume that $c_{\\max}$ is the maximum wavespeed over the computational domain when $c$ varies, and that the source encoding weights $w_k$ are bounded and time-independent.\n\nWhich option correctly describes both an implementation that injects multiple sources per time step for encoded sources without additional checkpointing and the resulting CFL-like stability constraint?\n\nA. Implement $s^n_{\\mathbf{i}}$ as a per-step sum $s^n_{\\mathbf{i}} = \\sum_{k=1}^{K} w_k\\, s^{(k),n}_{\\mathbf{i}}$ and add it into the same right-hand side as a single-source forcing. No additional checkpointing is required because of linearity and streaming injection. The CFL condition remains $\\Delta t \\le \\dfrac{1}{c_{\\max} \\sqrt{\\sum_{j=1}^{d} \\frac{1}{\\Delta x_j^2}}}$ (for uniform $h$, $\\Delta t \\le \\dfrac{h}{c_{\\max} \\sqrt{d}}$), independent of $K$, provided the forcing is bounded; normalizing $w_k$ (e.g., by $1/\\sqrt{K}$) affects amplitude but not stability.\n\nB. Split each time step into $K$ substeps and inject one source per substep to avoid interference. The CFL bound tightens to $\\Delta t \\le \\dfrac{1}{K}\\, \\dfrac{1}{c_{\\max} \\sqrt{\\sum_{j=1}^{d} \\frac{1}{\\Delta x_j^2}}}$ because $K$ substeps effectively increase the maximum discrete frequency.\n\nC. Because $K$ sources increase the injected energy by approximately a factor of $K$, the CFL bound must be reduced to $\\Delta t \\le \\dfrac{1}{\\sqrt{K}}\\, \\dfrac{1}{c_{\\max} \\sqrt{\\sum_{j=1}^{d} \\frac{1}{\\Delta x_j^2}}}$, and additional checkpointing of $K$ forward states per time step is necessary to maintain stability.\n\nD. Pre-encode sources in the frequency domain and invert to the time domain at each step; the CFL bound is unchanged, but injecting multiple sources per time step requires storing the entire wavefield history to convolve with the encoded frequency content, thus additional checkpointing is unavoidable.\n\nSelect the single best option.", "solution": "The problem statement is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n### Step 1: Extract Givens\n- **Governing Equation**: The linear acoustic wave equation in $d$ spatial dimensions for the pressure field $u(\\mathbf{x}, t)$ is $\\frac{\\partial^2 u}{\\partial t^2}(\\mathbf{x}, t) = c^2(\\mathbf{x}) \\nabla^2 u(\\mathbf{x}, t) + s(\\mathbf{x}, t)$, where $c(\\mathbf{x})$ is the spatially varying wavespeed and $s(\\mathbf{x}, t)$ is a source term.\n- **Discrete Update Scheme**: An explicit second-order finite-difference scheme is given by $u^{n+1}_{\\mathbf{i}} = 2 u^{n}_{\\mathbf{i}} - u^{n-1}_{\\mathbf{i}} + \\Delta t^2\\, c^2_{\\mathbf{i}} \\sum_{j=1}^{d} \\frac{u^n_{\\mathbf{i}+\\mathbf{e}_j} - 2 u^n_{\\mathbf{i}} + u^n_{\\mathbf{i}-\\mathbf{e}_j}}{\\Delta x_j^2} + \\Delta t^2\\, s^n_{\\mathbf{i}}$. Here, $\\Delta t$ is the time step, $\\Delta x_j$ are grid spacings, $\\mathbf{e}_j$ are unit grid offsets, and $u^n_{\\mathbf{i}}$ and $s^n_{\\mathbf{i}}$ are the discrete field and source, respectively.\n- **Simultaneous-Source Encoding**: The encoded source for $K$ physical sources is $s^n_{\\mathbf{i}} = \\sum_{k=1}^{K} w_k\\, s^{(k),n}_{\\mathbf{i}}$, where $w_k$ are bounded, time-independent encoding weights.\n- **Task**: To determine an implementation strategy that injects $K$ sources per time step without additional checkpointing overhead and to assess the effect on the Courant–Friedrichs–Lewy (CFL) stability constraint.\n- **Analysis Assumptions**:\n    1. Linearity of the governing equation and discrete scheme.\n    2. Homogeneous case ($s \\equiv 0$) for von Neumann analysis.\n    3. Uniform grid with $\\Delta x_j = h$ and constant speed $c(\\mathbf{x}) \\equiv c$ for the derivation, extended to variable speed using $c_{\\max}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The acoustic wave equation and its second-order finite-difference discretization are fundamental concepts in computational physics and geophysics. The concept of simultaneous-source encoding is a standard and widely used technique in seismic inversion to reduce computational costs. The use of von Neumann stability analysis is the canonical method for assessing the stability of such numerical schemes.\n\nThe problem is well-posed. It provides all necessary information—the continuous equation, the discrete scheme, the source formulation, and the analytical approach (von Neumann analysis)—to derive a unique and meaningful conclusion regarding the implementation and stability. The language is precise and objective.\n\nThe problem is free of scientific flaws, contradictions, and ambiguities. It represents a standard, non-trivial question in the field of computational wave propagation.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. The solution will be derived from first principles as requested.\n\n### Derivation and Analysis\n\nThe analysis proceeds in two parts: first, addressing the implementation and checkpointing overhead, and second, deriving the stability condition.\n\n**1. Implementation and Checkpointing Overhead**\n\nThe governing partial differential equation is linear. The discrete update scheme is also linear in the field variable $u$ and the source term $s$.\nLet $\\mathcal{L}_{\\Delta}$ be the discrete linear operator representing the finite-difference update scheme. The update can be written abstractly as:\n$$\nu^{n+1} = \\mathcal{L}_{\\Delta}(u^n, u^{n-1}) + \\Delta t^2 s^n\n$$\nwhere $u^n$ represents the entire wavefield at time step $n$. The encoded source is $s^n = \\sum_{k=1}^{K} w_k s^{(k),n}$. Due to the linearity of the system, the solution $u^n$ for the encoded source is the linear superposition of the solutions $u^{(k),n}$ that would result from each individual source $s^{(k),n}$:\n$$\nu^n = \\sum_{k=1}^{K} w_k u^{(k),n}\n$$\nHowever, computationally, one does not need to compute each $u^{(k),n}$ separately. Instead, one can compute the composite source term $s^n_{\\mathbf{i}} = \\sum_{k=1}^K w_k s^{(k),n}_{\\mathbf{i}}$ at each grid point $\\mathbf{i}$ and for each time step $n$. This composite source is then used in a single simulation using the provided update scheme.\n\nFrom a computational workflow perspective, this procedure is identical to a simulation with a single, albeit more complex, source term. A second-order time-stepping scheme requires storing the wavefields at two previous time levels, $u^n$ and $u^{n-1}$, to compute $u^{n+1}$. The use of an encoded source does not change this requirement.\nFor seismic inversion using methods like reverse-time migration or full-waveform inversion, checkpointing is often used to manage the storage cost of the forward-propagated wavefield. Since we are propagating a single encoded wavefield $u$, the checkpointing strategy and associated overhead are exactly the same as for a single-shot experiment. No *additional* checkpointing is required due to the simultaneous injection of $K$ sources.\n\n**2. CFL Stability Condition Derivation**\n\nThe stability of a linear numerical scheme is determined by the behavior of its homogeneous part. The source term, provided it is bounded (as stated in the problem), affects the amplitude of the solution but does not influence the exponential growth or decay characteristic of numerical stability. Therefore, we perform a von Neumann stability analysis on the homogeneous equation ($s^n_{\\mathbf{i}} = 0$).\n\nFor simplicity, we use the specified assumptions: a uniform grid with $\\Delta x_j = h$ for all $j=1, \\dots, d$, and a constant wavespeed $c$. The homogeneous update scheme is:\n$$\nu^{n+1}_{\\mathbf{i}} = 2 u^{n}_{\\mathbf{i}} - u^{n-1}_{\\mathbf{i}} + \\frac{c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} (u^n_{\\mathbf{i}+\\mathbf{e}_j} - 2 u^n_{\\mathbf{i}} + u^n_{\\mathbf{i}-\\mathbf{e}_j})\n$$\nWe seek a single Fourier mode solution of the form $u^n_{\\mathbf{i}} = G^n e^{i \\mathbf{k} \\cdot \\mathbf{x}_{\\mathbf{i}}}$, where $G$ is the amplification factor, $\\mathbf{k}$ is the wavevector, and $\\mathbf{x}_{\\mathbf{i}}$ is the position of grid node $\\mathbf{i}$. Substituting this into the equation and dividing by $e^{i \\mathbf{k} \\cdot \\mathbf{x}_{\\mathbf{i}}}$ yields:\n$$\nG^{n+1} = 2 G^n - G^{n-1} + \\frac{c^2 \\Delta t^2}{h^2} G^n \\sum_{j=1}^{d} (e^{i k_j h} - 2 + e^{-i k_j h})\n$$\nwhere $k_j$ is the $j$-th component of $\\mathbf{k}$. Dividing by $G^{n-1}$ gives a quadratic equation for $G$:\n$$\nG^2 = 2G - 1 + G \\frac{c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} (2 \\cos(k_j h) - 2)\n$$\nUsing the identity $1 - \\cos(\\theta) = 2 \\sin^2(\\theta/2)$, we get:\n$$\nG^2 = 2G - 1 - G \\frac{4 c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} \\sin^2(k_j h / 2)\n$$\nRearranging gives:\n$$\nG^2 - 2 \\left( 1 - \\frac{2 c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} \\sin^2(k_j h / 2) \\right) G + 1 = 0\n$$\nFor the solution to remain bounded, the magnitude of the amplification factor $G$ must not exceed $1$, i.e., $|G| \\le 1$. The quadratic equation for $G$ is of the form $G^2 - 2\\alpha G + 1 = 0$, whose roots have magnitude $1$ if and only if $|\\alpha| \\le 1$. Thus, the stability condition is:\n$$\n\\left| 1 - \\frac{2 c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} \\sin^2(k_j h / 2) \\right| \\le 1\n$$\nThis is equivalent to the two inequalities:\n$$\n-1 \\le 1 - \\frac{2 c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} \\sin^2(k_j h / 2) \\quad \\text{and} \\quad 1 - \\frac{2 c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} \\sin^2(k_j h / 2) \\le 1\n$$\nThe second inequality simplifies to $-\\frac{2 c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} \\sin^2(k_j h / 2) \\le 0$, which is always true. The first inequality provides the constraint:\n$$\n\\frac{c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} \\sin^2(k_j h / 2) \\le 1\n$$\nThis condition must hold for all wavevectors $\\mathbf{k}$. The most restrictive case (the \"worst case\") occurs when the term $\\sum \\sin^2(\\dots)$ is maximized. This happens for the highest frequency modes supported by the grid, where $k_j h = \\pi$, which gives $\\sin^2(k_j h / 2) = \\sin^2(\\pi/2) = 1$ for all $j$. Substituting this into the inequality gives:\n$$\n\\frac{c^2 \\Delta t^2}{h^2} \\sum_{j=1}^{d} (1) \\le 1 \\implies \\frac{c^2 \\Delta t^2 d}{h^2} \\le 1\n$$\nSolving for $\\Delta t$ yields the CFL condition for a uniform grid:\n$$\n\\Delta t \\le \\frac{h}{c \\sqrt{d}}\n$$\nFor a non-uniform grid with spacings $\\Delta x_j$ and a variable wavespeed $c(\\mathbf{x})$, the same analysis leads to the most general and restrictive condition by using the maximum wavespeed $c_{\\max}$:\n$$\n\\Delta t \\le \\frac{1}{c_{\\max} \\sqrt{\\sum_{j=1}^{d} \\frac{1}{\\Delta x_j^2}}}\n$$\nThis derivation confirms that the CFL condition depends only on the properties of the homogeneous numerical operator ($c_{\\max}$, $\\Delta x_j$) and is independent of the source term $s$. Therefore, the number of sources $K$ and their weights $w_k$ do not modify the stability constraint. Normalizing the weights by a factor like $1/\\sqrt{K}$ is a common practice to manage the total energy and variance of the encoded wavefield for the subsequent inversion step, but it is not a requirement for numerical stability.\n\n### Option-by-Option Analysis\n\n**A. Implement $s^n_{\\mathbf{i}}$ as a per-step sum $s^n_{\\mathbf{i}} = \\sum_{k=1}^{K} w_k\\, s^{(k),n}_{\\mathbf{i}}$ and add it into the same right-hand side as a single-source forcing. No additional checkpointing is required because of linearity and streaming injection. The CFL condition remains $\\Delta t \\le \\dfrac{1}{c_{\\max} \\sqrt{\\sum_{j=1}^{d} \\frac{1}{\\Delta x_j^2}}}$ (for uniform $h$, $\\Delta t \\le \\dfrac{h}{c_{\\max} \\sqrt{d}}$), independent of $K$, provided the forcing is bounded; normalizing $w_k$ (e.g., by $1/\\sqrt{K}$) affects amplitude but not stability.**\n\nThis option correctly describes the implementation based on linear superposition. It correctly states that no additional checkpointing is needed. It provides the correct CFL condition, correctly identifying that it is independent of the number of sources $K$. The comment on normalization is also accurate. All parts of this statement are consistent with the derivation from first principles.\n\n**Verdict: Correct**\n\n**B. Split each time step into $K$ substeps and inject one source per substep to avoid interference. The CFL bound tightens to $\\Delta t \\le \\dfrac{1}{K}\\, \\dfrac{1}{c_{\\max} \\sqrt{\\sum_{j=1}^{d} \\frac{1}{\\Delta x_j^2}}}$ because $K$ substeps effectively increase the maximum discrete frequency.**\n\nThis implementation is inefficient and unnecessary due to the linearity of the wave equation. There is no \"interference\" to avoid in a linear system. The stability argument is flawed; splitting the time step $\\Delta t$ into $K$ substeps does not change the CFL limit for the overall step $\\Delta t$ in the way described. The reasoning that this \"increase[s] the maximum discrete frequency\" is incorrect; the maximum frequency is determined by the spatial grid spacing, not the time step.\n\n**Verdict: Incorrect**\n\n**C. Because $K$ sources increase the injected energy by approximately a factor of $K$, the CFL bound must be reduced to $\\Delta t \\le \\dfrac{1}{\\sqrt{K}}\\, \\dfrac{1}{c_{\\max} \\sqrt{\\sum_{j=1}^{d} \\frac{1}{\\Delta x_j^2}}}$, and additional checkpointing of $K$ forward states per time step is necessary to maintain stability.**\n\nThis option incorrectly conflates the magnitude of the solution (related to injected energy) with numerical stability. The CFL condition for a linear scheme is independent of the source amplitude. The factor of $1/\\sqrt{K}$ is arbitrary and not supported by von Neumann analysis. The claim that $K$ forward states must be checkpointed is also false; it negates the entire purpose of simultaneous-source modeling, which is to simulate a single composite wavefield.\n\n**Verdict: Incorrect**\n\n**D. Pre-encode sources in the frequency domain and invert to the time domain at each step; the CFL bound is unchanged, but injecting multiple sources per time step requires storing the entire wavefield history to convolve with the encoded frequency content, thus additional checkpointing is unavoidable.**\n\nThis option describes a confused and incorrect computational procedure. For a time-domain simulation, sources are injected in the time domain. The idea of inverting from the frequency domain \"at each step\" and convolving with the \"entire wavefield history\" is nonsensical for a time-marching scheme. While it correctly states the CFL bound is unchanged, the justification for additional checkpointing is based on a flawed premise.\n\n**Verdict: Incorrect**", "answer": "$$\\boxed{A}$$", "id": "3614634"}]}