{"hands_on_practices": [{"introduction": "To truly grasp the Biconjugate Gradient Stabilized (BiCGSTAB) method, we begin with a hands-on calculation of a single, complete iteration. This exercise ([@problem_id:3616026]) breaks down the algorithm into its fundamental steps, from calculating the step length $\\alpha_1$ to the final stabilization parameter $\\omega_1$. Working through this small-scale example provides a concrete feel for the interplay between the biconjugate gradient (BiCG) part and the stabilizing polynomial smoother.", "problem": "In frequency-domain seismic wavefield modeling, block-structured linear systems arise from discretizations of the acoustic Helmholtz operator. Consider the task of advancing one Krylov-subspace iteration to reduce the residual of a simplified subproblem that captures the algebraic structure of the discretization at a local stencil. Specifically, consider the linear system $A \\mathbf{x} = \\mathbf{b}$ with\n$$\nA=\\begin{pmatrix}3&-1\\\\2&1\\end{pmatrix},\\quad \\mathbf{b}=\\begin{pmatrix}1\\\\0\\end{pmatrix},\n$$\nan initial guess $\\mathbf{x}_0=\\begin{pmatrix}0\\\\0\\end{pmatrix}$, and the shadow residual chosen as $\\tilde{\\mathbf{r}}_0=\\mathbf{r}_0$, where $\\mathbf{r}_0=\\mathbf{b}-A\\mathbf{x}_0$. Use the Biconjugate Gradient Stabilized (BiCGSTAB) method with the standard Euclidean inner product to perform one full iteration starting from $\\mathbf{x}_0$, computing the scalar $\\alpha_1$, the intermediate vectors $\\mathbf{s}_1$ and $\\mathbf{t}_1$, the stabilizing scalar $\\omega_1$, and the updates $\\mathbf{x}_1$ and $\\mathbf{r}_1$ numerically. As a consequence of the Petrov–Galerkin enforcement and residual-norm minimization that underlie the method, the scalars $\\alpha_1$ and $\\omega_1$ are determined uniquely by the initial data. Report the value of the stabilizing scalar $\\omega_1$ as your final answer. Express the final answer in exact form; do not round.", "solution": "The problem requires the computation of the stabilizing scalar $\\omega_1$ after one full iteration of the Biconjugate Gradient Stabilized (BiCGSTAB) method for a given linear system. The problem is well-posed, providing all necessary components: a non-singular matrix $A$, a right-hand side vector $\\mathbf{b}$, an initial guess $\\mathbf{x}_0$, and a definition for the initial shadow residual $\\tilde{\\mathbf{r}}_0$. The BiCGSTAB algorithm is a standard, mathematically sound iterative method for solving non-symmetric linear systems of the form $A\\mathbf{x}=\\mathbf{b}$.\n\nThe given data are:\nThe linear system matrix, $A = \\begin{pmatrix} 3 & -1 \\\\ 2 & 1 \\end{pmatrix}$.\nThe right-hand side vector, $\\mathbf{b} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\nThe initial guess for the solution, $\\mathbf{x}_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\nThe inner product is the standard Euclidean inner product, i.e., for vectors $\\mathbf{u}, \\mathbf{v} \\in \\mathbb{R}^n$, their inner product is $\\mathbf{u}^T \\mathbf{v}$.\n\nThe BiCGSTAB iteration proceeds as follows. We begin by calculating the initial values for the iteration sequence, indexed by $k=0$.\n\nFirst, we compute the initial residual, $\\mathbf{r}_0$:\n$$\n\\mathbf{r}_0 = \\mathbf{b} - A \\mathbf{x}_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 3 & -1 \\\\ 2 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nThe problem specifies that the initial shadow residual, $\\tilde{\\mathbf{r}}_0$, is chosen to be equal to the initial residual, $\\mathbf{r}_0$.\n$$\n\\tilde{\\mathbf{r}}_0 = \\mathbf{r}_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nThe BiCGSTAB algorithm uses an initial search direction $\\mathbf{p}_0$ which is set to $\\mathbf{r}_0$.\n$$\n\\mathbf{p}_0 = \\mathbf{r}_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nWe also compute the scalar $\\rho_0$, which will be used in the first iteration.\n$$\n\\rho_0 = \\tilde{\\mathbf{r}}_0^T \\mathbf{r}_0 = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = (1)(1) + (0)(0) = 1\n$$\nNow we proceed with the first full iteration, corresponding to $k=1$.\n\n1.  Compute the vector $\\mathbf{v}_1$:\n    $$\n    \\mathbf{v}_1 = A \\mathbf{p}_0 = \\begin{pmatrix} 3 & -1 \\\\ 2 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (3)(1) + (-1)(0) \\\\ (2)(1) + (1)(0) \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix}\n    $$\n2.  Compute the scalar $\\alpha_1$. This is the step length along the search direction $\\mathbf{p}_0$.\n    $$\n    \\alpha_1 = \\frac{\\rho_0}{\\tilde{\\mathbf{r}}_0^T \\mathbf{v}_1} = \\frac{1}{\\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix}} = \\frac{1}{(1)(3) + (0)(2)} = \\frac{1}{3}\n    $$\n3.  Compute the intermediate residual vector $\\mathbf{s}_1$:\n    $$\n    \\mathbf{s}_1 = \\mathbf{r}_0 - \\alpha_1 \\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ \\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\end{pmatrix}\n    $$\n4.  Compute the vector $\\mathbf{t}_1$, which is the result of applying the matrix $A$ to $\\mathbf{s}_1$:\n    $$\n    \\mathbf{t}_1 = A \\mathbf{s}_1 = \\begin{pmatrix} 3 & -1 \\\\ 2 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} (3)(0) + (-1)(-\\frac{2}{3}) \\\\ (2)(0) + (1)(-\\frac{2}{3}) \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{2}{3} \\end{pmatrix}\n    $$\n5.  Compute the stabilizing scalar $\\omega_1$. This scalar is chosen to minimize the norm of the new residual $\\mathbf{r}_1$ in a follow-up step.\n    $$\n    \\omega_1 = \\frac{\\mathbf{t}_1^T \\mathbf{s}_1}{\\mathbf{t}_1^T \\mathbf{t}_1}\n    $$\n    First, we calculate the numerator:\n    $$\n    \\mathbf{t}_1^T \\mathbf{s}_1 = \\begin{pmatrix} \\frac{2}{3} & -\\frac{2}{3} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\end{pmatrix} = \\left(\\frac{2}{3}\\right)(0) + \\left(-\\frac{2}{3}\\right)\\left(-\\frac{2}{3}\\right) = \\frac{4}{9}\n    $$\n    Next, we calculate the denominator:\n    $$\n    \\mathbf{t}_1^T \\mathbf{t}_1 = \\begin{pmatrix} \\frac{2}{3} & -\\frac{2}{3} \\end{pmatrix} \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{2}{3} \\end{pmatrix} = \\left(\\frac{2}{3}\\right)^2 + \\left(-\\frac{2}{3}\\right)^2 = \\frac{4}{9} + \\frac{4}{9} = \\frac{8}{9}\n    $$\n    Now we can compute $\\omega_1$:\n    $$\n    \\omega_1 = \\frac{\\frac{4}{9}}{\\frac{8}{9}} = \\frac{4}{8} = \\frac{1}{2}\n    $$\n6.  For completeness, we can compute the updated solution $\\mathbf{x}_1$ and residual $\\mathbf{r}_1$.\n    $$\n    \\mathbf{x}_1 = \\mathbf{x}_0 + \\alpha_1 \\mathbf{p}_0 + \\omega_1 \\mathbf{s}_1 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{3} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\frac{1}{2} \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ -\\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{3} \\end{pmatrix}\n    $$\n    $$\n    \\mathbf{r}_1 = \\mathbf{s}_1 - \\omega_1 \\mathbf{t}_1 = \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\end{pmatrix} - \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{3} \\\\ -\\frac{1}{3} \\end{pmatrix}\n    $$\nThe problem asks for the value of the stabilizing scalar $\\omega_1$. Based on the calculations above, this value is $\\frac{1}{2}$.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "3616026"}, {"introduction": "The power of iterative methods like BiCGSTAB lies in their ability to build an approximate solution within a carefully chosen vector space known as a Krylov subspace. This practice ([@problem_id:3616041]) invites you to construct the basis vectors of such a subspace for a small system. By explicitly calculating these vectors and confirming their linear independence, you will gain insight into the geometric foundation of the algorithm's search for a solution.", "problem": "In the iterative solution of linear systems arising in computational geophysics, the Biconjugate Gradient Stabilized (BiCGSTAB) method constructs Krylov subspaces to accelerate convergence on sparse, nonsymmetric systems. Consider a toy local $3 \\times 3$ block extracted from a finite-volume discretization of an anisotropic diffusion operator, represented by the matrix\n$$\nA=\\begin{pmatrix}\n2 & -1 & 0\\\\\n1 & 3 & -2\\\\\n0 & 1 & 1\n\\end{pmatrix},\n$$\nand suppose the initial residual at the start of a BiCGSTAB iteration is\n$$\n\\mathbf{r}_{0}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix}.\n$$\nStarting from the definition of the Krylov subspace $K_{m}(A,\\mathbf{r}_{0})=\\operatorname{span}\\{\\mathbf{r}_{0},A\\mathbf{r}_{0},\\dots,A^{m-1}\\mathbf{r}_{0}\\}$, do the following:\n- Compute explicitly the vectors that generate $K_{3}(A,\\mathbf{r}_{0})$, namely $\\mathbf{r}_{0}$, $A\\mathbf{r}_{0}$, and $A^{2}\\mathbf{r}_{0}$, and use first principles of linear algebra to assess their linear independence.\n- Assemble the Krylov basis matrix\n$$\nK=\\big[\\mathbf{r}_{0}\\;\\;A\\mathbf{r}_{0}\\;\\;A^{2}\\mathbf{r}_{0}\\big],\n$$\nand use a determinant-based test for linear independence to justify your assessment.\n\nReport as your final answer the numerical value of $\\det(K)$. No rounding is required. No units are associated with the reported quantity.", "solution": "The problem requires the computation of the vectors spanning the Krylov subspace $K_{3}(A,\\mathbf{r}_{0})$ for a given $3 \\times 3$ matrix $A$ and an initial vector $\\mathbf{r}_{0}$, and an assessment of their linear independence.\n\nThe given matrix $A$ and initial residual vector $\\mathbf{r}_{0}$ are:\n$$\nA=\\begin{pmatrix}\n2 & -1 & 0\\\\\n1 & 3 & -2\\\\\n0 & 1 & 1\n\\end{pmatrix}, \\quad \\mathbf{r}_{0}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix}\n$$\n\nThe Krylov subspace $K_{3}(A,\\mathbf{r}_{0})$ is defined as $K_{3}(A,\\mathbf{r}_{0})=\\operatorname{span}\\{\\mathbf{r}_{0}, A\\mathbf{r}_{0}, A^{2}\\mathbf{r}_{0}\\}$. We must first compute the generating vectors $\\mathbf{r}_{0}$, $A\\mathbf{r}_{0}$, and $A^{2}\\mathbf{r}_{0}$.\n\nThe first vector is given as $\\mathbf{r}_{0}$.\nThe second vector, $A\\mathbf{r}_{0}$, is calculated by matrix-vector multiplication:\n$$\nA\\mathbf{r}_{0} = \\begin{pmatrix}\n2 & -1 & 0\\\\\n1 & 3 & -2\\\\\n0 & 1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix}\n= \\begin{pmatrix}\n2(1) + (-1)(0) + 0(1)\\\\\n1(1) + 3(0) + (-2)(1)\\\\\n0(1) + 1(0) + 1(1)\n\\end{pmatrix}\n= \\begin{pmatrix}\n2\\\\\n1-2\\\\\n1\n\\end{pmatrix}\n= \\begin{pmatrix}\n2\\\\\n-1\\\\\n1\n\\end{pmatrix}\n$$\nThe third vector, $A^{2}\\mathbf{r}_{0}$, is computed as $A(A\\mathbf{r}_{0})$:\n$$\nA^{2}\\mathbf{r}_{0} = A(A\\mathbf{r}_{0}) = \\begin{pmatrix}\n2 & -1 & 0\\\\\n1 & 3 & -2\\\\\n0 & 1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2\\\\\n-1\\\\\n1\n\\end{pmatrix}\n= \\begin{pmatrix}\n2(2) + (-1)(-1) + 0(1)\\\\\n1(2) + 3(-1) + (-2)(1)\\\\\n0(2) + 1(-1) + 1(1)\n\\end{pmatrix}\n= \\begin{pmatrix}\n4+1\\\\\n2-3-2\\\\\n-1+1\n\\end{pmatrix}\n= \\begin{pmatrix}\n5\\\\\n-3\\\\\n0\n\\end{pmatrix}\n$$\nThe three vectors that generate $K_{3}(A,\\mathbf{r}_{0})$ are:\n$$\n\\mathbf{r}_{0}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix}, \\quad A\\mathbf{r}_{0}=\\begin{pmatrix}2\\\\-1\\\\1\\end{pmatrix}, \\quad A^{2}\\mathbf{r}_{0}=\\begin{pmatrix}5\\\\-3\\\\0\\end{pmatrix}\n$$\n\nTo assess their linear independence using first principles, we examine the vector equation $c_{1}\\mathbf{r}_{0} + c_{2}A\\mathbf{r}_{0} + c_{3}A^{2}\\mathbf{r}_{0} = \\mathbf{0}$, where $c_{1}, c_{2}, c_{3}$ are scalars and $\\mathbf{0}$ is the zero vector. The vectors are linearly independent if and only if the only solution is the trivial one, $c_{1}=c_{2}=c_{3}=0$.\nThis vector equation expands to the following system of linear equations:\n$$\nc_{1} \\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix} + c_{2} \\begin{pmatrix}2\\\\-1\\\\1\\end{pmatrix} + c_{3} \\begin{pmatrix}5\\\\-3\\\\0\\end{pmatrix} = \\begin{pmatrix}0\\\\0\\\\0\\end{pmatrix}\n$$\n$$\n\\begin{cases}\n1c_{1} + 2c_{2} + 5c_{3} = 0 \\\\\n0c_{1} - 1c_{2} - 3c_{3} = 0 \\\\\n1c_{1} + 1c_{2} + 0c_{3} = 0\n\\end{cases}\n$$\nFrom the second equation, we have $-c_{2} - 3c_{3} = 0$, which implies $c_{2} = -3c_{3}$.\nFrom the third equation, we have $c_{1} + c_{2} = 0$, which implies $c_{1} = -c_{2}$.\nSubstituting $c_{2}=-3c_{3}$ into $c_{1}=-c_{2}$ gives $c_{1} = -(-3c_{3}) = 3c_{3}$.\nNow, we substitute these expressions for $c_{1}$ and $c_{2}$ into the first equation:\n$$\n(3c_{3}) + 2(-3c_{3}) + 5c_{3} = 0\n$$\n$$\n3c_{3} - 6c_{3} + 5c_{3} = 0\n$$\n$$\n2c_{3} = 0 \\implies c_{3} = 0\n$$\nSince $c_{3}=0$, it follows that $c_{2} = -3(0) = 0$ and $c_{1} = 3(0) = 0$.\nThe only solution is $c_{1}=c_{2}=c_{3}=0$. Therefore, according to first principles, the vectors $\\mathbf{r}_{0}$, $A\\mathbf{r}_{0}$, and $A^{2}\\mathbf{r}_{0}$ are linearly independent.\n\nNext, we assemble the Krylov basis matrix $K$ with these vectors as its columns:\n$$\nK = \\big[\\mathbf{r}_{0}\\;\\;A\\mathbf{r}_{0}\\;\\;A^{2}\\mathbf{r}_{0}\\big] = \\begin{pmatrix}\n1 & 2 & 5\\\\\n0 & -1 & -3\\\\\n1 & 1 & 0\n\\end{pmatrix}\n$$\nTo use a determinant-based test for linear independence, we compute the determinant of $K$. A set of $n$ vectors in an $n$-dimensional space is linearly independent if and only if the determinant of the matrix formed by these vectors is non-zero.\nWe can calculate the determinant of $K$ using cofactor expansion along the first column:\n$$\n\\det(K) = (1) \\cdot \\det\\begin{pmatrix}-1 & -3 \\\\ 1 & 0\\end{pmatrix} - (0) \\cdot \\det\\begin{pmatrix}2 & 5 \\\\ 1 & 0\\end{pmatrix} + (1) \\cdot \\det\\begin{pmatrix}2 & 5 \\\\ -1 & -3\\end{pmatrix}\n$$\n$$\n\\det(K) = (1) \\cdot ((-1)(0) - (-3)(1)) - 0 + (1) \\cdot ((2)(-3) - (5)(-1))\n$$\n$$\n\\det(K) = (1) \\cdot (0 + 3) + (1) \\cdot (-6 + 5)\n$$\n$$\n\\det(K) = 3 + (-1) = 2\n$$\nSince $\\det(K) = 2 \\neq 0$, the column vectors of $K$ are linearly independent. This confirms the assessment made using first principles. The numerical value of the determinant is $2$.", "answer": "$$\\boxed{2}$$", "id": "3616041"}, {"introduction": "In practical applications, especially in geophysics, raw iterative methods often converge too slowly. This is where preconditioning becomes essential, transforming the original linear system into one that is easier to solve. This exercise ([@problem_id:3616049]) demonstrates how a right preconditioner, in this case derived from an Incomplete LU factorization, is incorporated into the BiCGSTAB algorithm, providing hands-on experience with a technique crucial for tackling large-scale, realistic problems.", "problem": "A symmetric positive definite linear system arises from a second-order finite-difference discretization of steady one-dimensional diffusion in a three-cell layered Earth model with homogeneous coefficients within each cell. The discrete operator is represented by the matrix\n$$\nA=\\begin{pmatrix}\n4 & -1 & 0\\\\\n-1 & 4 & -1\\\\\n0 & -1 & 3\n\\end{pmatrix},\n$$\nand the right-hand side corresponds to a unit source at the leftmost cell,\n$$\n\\mathbf{b}=\\begin{pmatrix}\n1\\\\\n0\\\\\n0\n\\end{pmatrix}.\n$$\nAn Incomplete Lower-Upper factorization with zero fill (ILU(0)) constructed for use as a right preconditioner is given explicitly by the upper-triangular matrix\n$$\nM=\\begin{pmatrix}\n4 & -1 & 0\\\\\n0 & \\tfrac{15}{4} & -1\\\\\n0 & 0 & \\tfrac{44}{15}\n\\end{pmatrix}.\n$$\nConsider the Biconjugate Gradient Stabilized (BiCGSTAB) method (right-preconditioned) applied to the system with initial guess\n$$\n\\mathbf{x}_{0}=\\begin{pmatrix}\n0\\\\\n0\\\\\n0\n\\end{pmatrix},\n$$\ninitial residual defined by\n$$\n\\mathbf{r}_{0}=\\mathbf{b}-A\\mathbf{x}_{0},\n$$\ninitial search direction\n$$\n\\mathbf{p}_{0}=\\mathbf{r}_{0},\n$$\nand fixed shadow residual chosen as\n$$\n\\hat{\\mathbf{r}}=\\mathbf{r}_{0}.\n$$\nWork with the standard Euclidean inner product. Perform the first BiCGSTAB iteration step starting from these quantities. In doing so, explicitly include:\n- the application of the preconditioner inverse to the initial residual, that is, compute $M^{-1}\\mathbf{r}_{0}$,\n- the matrix-vector product $A\\mathbf{p}_{0}$,\n- and the application of the preconditioner inverse to this product, that is, compute $M^{-1}(A\\mathbf{p}_{0})$.\n\nFrom first principles of the Petrov–Galerkin biorthogonality that define the BiCGSTAB step length, determine the scalar first-step coefficient $\\alpha_{0}$ for this right-preconditioned iteration. Provide the value of $\\alpha_{0}$ as an exact number. The final answer must be a single real number with no units. Do not round.", "solution": "The problem is well-posed and scientifically grounded. It provides all necessary information to perform the first step of the Biconjugate Gradient Stabilized (BiCGSTAB) method for a given linear system with a specified right preconditioner. The context is a standard application in computational science, and the algorithm is a cornerstone of iterative methods for linear systems. The matrices and vectors are well-defined, and the objective is a precise calculation. We proceed to the solution.\n\nThe problem asks for the determination of the first-step coefficient, $\\alpha_0$, from the first principles of the Petrov-Galerkin biorthogonality condition that underlies the BiCGSTAB method. For a right-preconditioned system $A M^{-1} \\mathbf{y} = \\mathbf{b}$, where $\\mathbf{x} = M^{-1} \\mathbf{y}$, the BiCG step seeks an update of the form $\\mathbf{y}_{k+1/2} = \\mathbf{y}_k + \\alpha_k \\mathbf{p}'_k$, where $\\mathbf{p}'_k$ is a search direction for the preconditioned system. The corresponding residual for the preconditioned system is $\\mathbf{r}'_{k+1/2} = \\mathbf{r}'_k - \\alpha_k (A M^{-1}) \\mathbf{p}'_k$. The residuals of the preconditioned system and the original system are identical, i.e., $\\mathbf{r}'_k = \\mathbf{b} - (A M^{-1}) \\mathbf{y}_k = \\mathbf{b} - A (M^{-1} \\mathbf{y}_k) = \\mathbf{b} - A \\mathbf{x}_k = \\mathbf{r}_k$.\n\nThe Petrov-Galerkin condition imposes that the new residual be orthogonal to a shadow residual direction, $\\hat{\\mathbf{r}}'_k$. This gives the condition $\\langle \\mathbf{r}'_{k+1/2}, \\hat{\\mathbf{r}}'_k \\rangle = 0$.\n$$\n\\langle \\mathbf{r}'_k - \\alpha_k (A M^{-1}) \\mathbf{p}'_k, \\hat{\\mathbf{r}}'_k \\rangle = 0\n$$\nSolving for $\\alpha_k$ yields:\n$$\n\\alpha_k = \\frac{\\langle \\mathbf{r}'_k, \\hat{\\mathbf{r}}'_k \\rangle}{\\langle (A M^{-1}) \\mathbf{p}'_k, \\hat{\\mathbf{r}}'_k \\rangle}\n$$\nIn the context of the BiCGSTAB algorithm, the search direction $\\mathbf{p}'_k$ for the preconditioned system corresponds to the unpreconditioned search direction $\\mathbf{p}_k$ from the main algorithm variables; likewise, the shadow residual $\\hat{\\mathbf{r}}'_k$ corresponds to the given shadow residual $\\hat{\\mathbf{r}}$. For the first step ($k=0$), we have $\\mathbf{p}'_0 = \\mathbf{p}_0$ and $\\hat{\\mathbf{r}}'_0 = \\hat{\\mathbf{r}}$. The problem specifies $\\mathbf{p}_0=\\mathbf{r}_0$ and a fixed shadow residual $\\hat{\\mathbf{r}}=\\mathbf{r}_0$. Substituting these into the formula for $\\alpha_0$:\n$$\n\\alpha_0 = \\frac{\\langle \\mathbf{r}_0, \\mathbf{r}_0 \\rangle}{\\langle (A M^{-1}) \\mathbf{r}_0, \\mathbf{r}_0 \\rangle}\n$$\nWe now compute the necessary quantities step-by-step.\n\nThe given matrices and vectors are:\n$$\nA = \\begin{pmatrix} 4 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 3 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad M = \\begin{pmatrix} 4 & -1 & 0 \\\\ 0 & \\frac{15}{4} & -1 \\\\ 0 & 0 & \\frac{44}{15} \\end{pmatrix}\n$$\nThe initial guess is $\\mathbf{x}_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\n\nFirst, we compute the initial residual $\\mathbf{r}_0$:\n$$\n\\mathbf{r}_0 = \\mathbf{b} - A \\mathbf{x}_0 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 4 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nAccording to the problem statement, the initial search direction is $\\mathbf{p}_0 = \\mathbf{r}_0$ and the fixed shadow residual is $\\hat{\\mathbf{r}} = \\mathbf{r}_0$. So, $\\mathbf{p}_0 = \\hat{\\mathbf{r}} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\n\nThe problem requires a number of explicit computations. Let us perform these.\n\n1.  Compute $M^{-1}\\mathbf{r}_0$:\n    We solve the system $M \\mathbf{z}_0 = \\mathbf{r}_0$ for $\\mathbf{z}_0 = M^{-1}\\mathbf{r}_0$.\n    $$\n    \\begin{pmatrix} 4 & -1 & 0 \\\\ 0 & \\frac{15}{4} & -1 \\\\ 0 & 0 & \\frac{44}{15} \\end{pmatrix} \\begin{pmatrix} z_{0,1} \\\\ z_{0,2} \\\\ z_{0,3} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n    $$\n    Using back substitution:\n    From the third row: $\\frac{44}{15} z_{0,3} = 0 \\implies z_{0,3} = 0$.\n    From the second row: $\\frac{15}{4} z_{0,2} - z_{0,3} = 0 \\implies \\frac{15}{4} z_{0,2} = 0 \\implies z_{0,2} = 0$.\n    From the first row: $4 z_{0,1} - z_{0,2} = 1 \\implies 4 z_{0,1} = 1 \\implies z_{0,1} = \\frac{1}{4}$.\n    Thus, $M^{-1}\\mathbf{r}_0 = \\begin{pmatrix} \\frac{1}{4} \\\\ 0 \\\\ 0 \\end{pmatrix}$.\n\n2.  Compute $A \\mathbf{p}_0$:\n    Since $\\mathbf{p}_0 = \\mathbf{r}_0 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$:\n    $$\n    A \\mathbf{p}_0 = \\begin{pmatrix} 4 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ -1 \\\\ 0 \\end{pmatrix}\n    $$\n\n3.  Compute $M^{-1}(A \\mathbf{p}_0)$:\n    We solve the system $M \\mathbf{w} = A \\mathbf{p}_0$ for $\\mathbf{w} = M^{-1}(A \\mathbf{p}_0)$.\n    $$\n    \\begin{pmatrix} 4 & -1 & 0 \\\\ 0 & \\frac{15}{4} & -1 \\\\ 0 & 0 & \\frac{44}{15} \\end{pmatrix} \\begin{pmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ -1 \\\\ 0 \\end{pmatrix}\n    $$\n    Using back substitution:\n    From the third row: $\\frac{44}{15} w_3 = 0 \\implies w_3 = 0$.\n    From the second row: $\\frac{15}{4} w_2 - w_3 = -1 \\implies \\frac{15}{4} w_2 = -1 \\implies w_2 = -\\frac{4}{15}$.\n    From the first row: $4 w_1 - w_2 = 4 \\implies 4 w_1 - (-\\frac{4}{15}) = 4 \\implies 4 w_1 = 4 - \\frac{4}{15} = \\frac{56}{15} \\implies w_1 = \\frac{14}{15}$.\n    Thus, $M^{-1}(A \\mathbf{p}_0) = \\begin{pmatrix} \\frac{14}{15} \\\\ -\\frac{4}{15} \\\\ 0 \\end{pmatrix}$.\n\nNow we proceed with the calculation of $\\alpha_0$. The denominator of $\\alpha_0$ requires the term $\\mathbf{v}_0 = (A M^{-1}) \\mathbf{r}_0$. Let us compute this vector. This is $A$ multiplied by the result from step 1 ($\\mathbf{z}_0=M^{-1}\\mathbf{r}_0$).\n$$\n\\mathbf{v}_0 = A (M^{-1} \\mathbf{r}_0) = \\begin{pmatrix} 4 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 3 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{4} \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 4(\\frac{1}{4}) \\\\ -1(\\frac{1}{4}) \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -\\frac{1}{4} \\\\ 0 \\end{pmatrix}\n$$\nNow we can compute the inner products for the numerator and denominator of $\\alpha_0$. The standard BiCGSTAB formula for the first step length $\\alpha_1$ is $\\frac{\\tilde{\\mathbf{r}}_0^T \\mathbf{r}_0}{\\tilde{\\mathbf{r}}_0^T A M^{-1} \\mathbf{p}_0}$. Given $\\tilde{\\mathbf{r}}_0=\\mathbf{r}_0$ and $\\mathbf{p}_0=\\mathbf{r}_0$, this becomes $\\frac{\\mathbf{r}_0^T \\mathbf{r}_0}{\\mathbf{r}_0^T A M^{-1} \\mathbf{r}_0} = \\frac{\\langle\\mathbf{r}_0, \\mathbf{r}_0\\rangle}{\\langle\\mathbf{r}_0, \\mathbf{v}_0\\rangle}$.\n\nThe numerator is $\\langle \\mathbf{r}_0, \\mathbf{r}_0 \\rangle$:\n$$\n\\langle \\mathbf{r}_0, \\mathbf{r}_0 \\rangle = \\mathbf{r}_0^T \\mathbf{r}_0 = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = 1 \\cdot 1 + 0 \\cdot 0 + 0 \\cdot 0 = 1\n$$\nThe denominator is $\\langle \\mathbf{r}_0, \\mathbf{v}_0 \\rangle$:\n$$\n\\langle \\mathbf{r}_0, \\mathbf{v}_0 \\rangle = \\mathbf{r}_0^T \\mathbf{v}_0 = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -\\frac{1}{4} \\\\ 0 \\end{pmatrix} = 1 \\cdot 1 + 0 \\cdot (-\\frac{1}{4}) + 0 \\cdot 0 = 1\n$$\nFinally, we compute $\\alpha_0$:\n$$\n\\alpha_0 = \\frac{\\langle \\mathbf{r}_0, \\mathbf{r}_0 \\rangle}{\\langle \\mathbf{r}_0, \\mathbf{v}_0 \\rangle} = \\frac{1}{1} = 1\n$$\nThe first-step coefficient $\\alpha_0$ is $1$.", "answer": "$$\n\\boxed{1}\n$$", "id": "3616049"}]}