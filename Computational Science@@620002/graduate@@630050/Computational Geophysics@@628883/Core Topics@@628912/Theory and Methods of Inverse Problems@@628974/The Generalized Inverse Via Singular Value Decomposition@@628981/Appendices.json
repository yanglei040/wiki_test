{"hands_on_practices": [{"introduction": "Understanding the generalized inverse begins with the mechanics of its calculation via Singular Value Decomposition (SVD). This first practice provides a clear, foundational example using a simple rank-deficient matrix. By working through this problem, you will see how the pseudoinverse is constructed by inverting only the non-zero singular values, a core principle for handling singular or ill-conditioned systems. [@problem_id:1049323]", "problem": "Compute the Moore-Penrose pseudoinverse of the matrix $ A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $ using singular value decomposition. Present your answer as a 2x2 matrix.", "solution": "1.  **Singular Value Decomposition of $A$**:  \n    Since $A = \\begin{pmatrix}1 & 0 \\\\ 0 & 0 \\end{pmatrix}$ is already a diagonal matrix, its SVD is straightforward. We can choose the orthogonal matrices $U$ and $V$ to be the identity matrix $I$. The singular value matrix $\\Sigma$ is $A$ itself.\n    $$\n    A = U \\Sigma V^{\\mathsf{T}} \\quad \\text{with} \\quad U = I, \\quad \\Sigma = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\quad V = I\n    $$\n2.  **Form the pseudoinverse of $\\Sigma$**:  \n    To find $\\Sigma^+$, we take the reciprocal of each non-zero singular value and keep the zeros as they are. The only non-zero singular value is $1$, and its reciprocal is $1$.\n    $$\n    \\Sigma^+ = \\begin{pmatrix} 1^{-1} & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n    $$\n3.  **Compute $A^+$**:  \n    Using the formula for the pseudoinverse, $A^+ = V \\Sigma^+ U^{\\mathsf{T}}$:\n    $$\n    A^+ = I \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} I^{\\mathsf{T}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n    $$\nThus, the pseudoinverse of $A$ is $A$ itself.", "answer": "$$\\boxed{\\begin{pmatrix}1 & 0 \\\\ 0 & 0\\end{pmatrix}}$$", "id": "1049323"}, {"introduction": "Beyond simple calculation, it is crucial to understand the fundamental algebraic properties that uniquely define the Moore-Penrose pseudoinverse. This exercise guides you to verify two of the four Penrose axioms for a rank-deficient matrix constructed via its SVD. This demonstrates how the SVD-based definition inherently satisfies the axioms that make the pseudoinverse a consistent and reliable generalization of the matrix inverse. [@problem_id:3404364]", "problem": "Consider a linear inverse problem in three dimensions where observations $\\mathbf{y} \\in \\mathbb{R}^{3}$ are related to the state $\\mathbf{x} \\in \\mathbb{R}^{3}$ by $\\mathbf{y} = A \\mathbf{x} + \\boldsymbol{\\varepsilon}$, with $\\boldsymbol{\\varepsilon}$ denoting observational error. To study rank deficiency and ill-conditioning in the context of the Moore–Penrose pseudoinverse, construct an explicit matrix $A \\in \\mathbb{R}^{3 \\times 3}$ of rank $2$ with a highly ill-conditioned nonzero spectrum by specifying an orthogonal–diagonal–orthogonal factorization as follows.\n\nLet $U \\in \\mathbb{R}^{3 \\times 3}$ and $V \\in \\mathbb{R}^{3 \\times 3}$ be the orthogonal matrices\n$$\nU \\;=\\; \\begin{pmatrix}\n\\frac{3}{5} & 0 & -\\frac{4}{5} \\\\\n0 & 1 & 0 \\\\\n\\frac{4}{5} & 0 & \\frac{3}{5}\n\\end{pmatrix},\n\\qquad\nV \\;=\\; \\begin{pmatrix}\n\\frac{5}{13} & -\\frac{12}{13} & 0 \\\\\n\\frac{12}{13} & \\frac{5}{13} & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix},\n$$\nand let the singular value matrix be\n$$\n\\Sigma \\;=\\; \\operatorname{diag}\\!\\big(3,\\, 10^{-3},\\, 0\\big).\n$$\nDefine $A$ by $A = U \\Sigma V^{\\top}$. Using only the definition of the Moore–Penrose pseudoinverse through the Singular Value Decomposition (SVD), compute $A^{\\dagger}$, and explicitly verify the two Moore–Penrose identities\n$$\nA A^{\\dagger} A \\;=\\; A,\n\\qquad\nA^{\\dagger} A A^{\\dagger} \\;=\\; A^{\\dagger}.\n$$\nThen, compute the scalar\n$$\nS \\;=\\; \\|A A^{\\dagger} A - A\\|_{F}^{2} \\;+\\; \\|A^{\\dagger} A A^{\\dagger} - A^{\\dagger}\\|_{F}^{2},\n$$\nwhere $\\|\\cdot\\|_{F}$ denotes the Frobenius norm. Give your final answer as a single real number. No rounding is required.", "solution": "The problem defines a matrix $A$ via its Singular Value Decomposition (SVD), $A = U \\Sigma V^{\\top}$. The Moore-Penrose pseudoinverse $A^{\\dagger}$ is defined as $A^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top}$.\nThe matrix $\\Sigma^{\\dagger}$ is found by taking the reciprocal of the non-zero singular values in $\\Sigma$ and leaving the zeros in place.\nGiven $\\Sigma = \\operatorname{diag}(3, 10^{-3}, 0)$, the pseudoinverse $\\Sigma^{\\dagger}$ is:\n$$\n\\Sigma^{\\dagger} = \\operatorname{diag}\\left(\\frac{1}{3}, \\frac{1}{10^{-3}}, 0\\right) = \\operatorname{diag}\\left(\\frac{1}{3}, 1000, 0\\right).\n$$\nWe are asked to verify two Moore-Penrose identities and then compute $S$.\n\n1.  **Verification of $A A^{\\dagger} A = A$**:\n    Substitute the SVD expressions for $A$ and $A^{\\dagger}$:\n    $$\n    A A^{\\dagger} A = (U \\Sigma V^{\\top}) (V \\Sigma^{\\dagger} U^{\\top}) (U \\Sigma V^{\\top})\n    $$\n    Since $V$ and $U$ are orthogonal matrices, $V^{\\top}V = I$ and $U^{\\top}U = I$, where $I$ is the identity matrix.\n    $$\n    A A^{\\dagger} A = U \\Sigma (V^{\\top}V) \\Sigma^{\\dagger} (U^{\\top}U) \\Sigma V^{\\top} = U (\\Sigma \\Sigma^{\\dagger} \\Sigma) V^{\\top}\n    $$\n    Now we compute the product $\\Sigma \\Sigma^{\\dagger} \\Sigma$:\n    $$\n    \\Sigma \\Sigma^{\\dagger} = \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 10^{-3} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3} & 0 & 0 \\\\ 0 & 1000 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n    $$\n    $$\n    (\\Sigma \\Sigma^{\\dagger}) \\Sigma = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 10^{-3} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 10^{-3} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\Sigma\n    $$\n    Therefore, $A A^{\\dagger} A = U \\Sigma V^{\\top} = A$. The first identity is verified.\n\n2.  **Verification of $A^{\\dagger} A A^{\\dagger} = A^{\\dagger}$**:\n    Again, substitute the SVD expressions:\n    $$\n    A^{\\dagger} A A^{\\dagger} = (V \\Sigma^{\\dagger} U^{\\top}) (U \\Sigma V^{\\top}) (V \\Sigma^{\\dagger} U^{\\top})\n    $$\n    Using $U^{\\top}U = I$ and $V^{\\top}V = I$:\n    $$\n    A^{\\dagger} A A^{\\dagger} = V \\Sigma^{\\dagger} (U^{\\top}U) \\Sigma (V^{\\top}V) \\Sigma^{\\dagger} U^{\\top} = V (\\Sigma^{\\dagger} \\Sigma \\Sigma^{\\dagger}) U^{\\top}\n    $$\n    Now we compute the product $\\Sigma^{\\dagger} \\Sigma \\Sigma^{\\dagger}$:\n    $$\n    \\Sigma^{\\dagger} \\Sigma = \\begin{pmatrix} \\frac{1}{3} & 0 & 0 \\\\ 0 & 1000 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 10^{-3} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n    $$\n    $$\n    (\\Sigma^{\\dagger} \\Sigma) \\Sigma^{\\dagger} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3} & 0 & 0 \\\\ 0 & 1000 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3} & 0 & 0 \\\\ 0 & 1000 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\Sigma^{\\dagger}\n    $$\n    Therefore, $A^{\\dagger} A A^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top} = A^{\\dagger}$. The second identity is verified.\n\n3.  **Compute the scalar S**:\n    The scalar $S$ is defined as $S = \\|A A^{\\dagger} A - A\\|_{F}^{2} + \\|A^{\\dagger} A A^{\\dagger} - A^{\\dagger}\\|_{F}^{2}$.\n    From our explicit verifications, we have established that:\n    $$\n    A A^{\\dagger} A - A = \\mathbf{0} \\quad \\text{and} \\quad A^{\\dagger} A A^{\\dagger} - A^{\\dagger} = \\mathbf{0}\n    $$\n    where $\\mathbf{0}$ is the $3 \\times 3$ zero matrix.\n    The Frobenius norm of the zero matrix is $0$.\n    Therefore,\n    $$\n    \\|A A^{\\dagger} A - A\\|_{F}^{2} = \\|\\mathbf{0}\\|_{F}^{2} = 0\n    $$\n    $$\n    \\|A^{\\dagger} A A^{\\dagger} - A^{\\dagger}\\|_{F}^{2} = \\|\\mathbf{0}\\|_{F}^{2} = 0\n    $$\n    Substituting these results into the expression for $S$:\n    $$\n    S = 0 + 0 = 0\n    $$\nThe value of the scalar $S$ is $0$. This result is a direct consequence of the fact that the Moore-Penrose pseudoinverse, by definition, must satisfy these two Penrose conditions, regardless of the matrix's conditioning.", "answer": "$$\\boxed{0}$$", "id": "3404364"}, {"introduction": "The true power of the SVD in computational geophysics lies in its ability to provide physical insight into inverse problems. This final practice moves from abstract algebra to a concrete application in a seismic refraction experiment. By analyzing the SVD of a sensitivity matrix, you will learn to diagnose which model parameters are well-constrained by the data and which are not, connecting the mathematical structure of the SVD to the physical reality of model resolution. [@problem_id:3616825]", "problem": "Consider a linearized seismic refraction experiment with a single refracting interface over a half-space. Let the model perturbation vector be $\\delta \\mathbf{m} = [\\delta s_1,\\ \\delta s_2,\\ \\delta z]^\\top$, where $\\delta s_1$ and $\\delta s_2$ are perturbations in the upper-layer and refractor slownesses (seconds per meter), and $\\delta z$ is the perturbation in interface depth (meters). For offsets $x_k$ at large ranges (head-wave regime), the travel-time perturbations $\\delta t_k$ can be approximated by a first-order linearization around a known reference model as\n$$\n\\delta \\mathbf{d} \\approx G \\, \\delta \\mathbf{m},\n$$\nwith $G \\in \\mathbb{R}^{N \\times 3}$ collecting the partial derivatives $\\partial t_k / \\partial m_j$. In a synthetic test with $N=5$ offsets $x_k \\in \\{500,\\ 1000,\\ 1500,\\ 2000,\\ 2500\\}$ meters, suppose the sensitivities are dominated by the refractor slowness through the slope of the travel-time curve and weakly sensitive to the intercept time through depth and upper-layer slowness. Take\n$$\nG = \\begin{bmatrix}\na & x_1 & b \\\\\na & x_2 & b \\\\\na & x_3 & b \\\\\na & x_4 & b \\\\\na & x_5 & b\n\\end{bmatrix},\n$$\nwith $a = 0.02$ seconds, $b = 0.01$ seconds, and $x_k$ as given above. Assume the data are generated by a true perturbation $\\delta \\mathbf{m}_{\\text{true}} = [0,\\ \\delta s_2^{\\star},\\ 0]^\\top$ with $\\delta s_2^{\\star} = 2 \\times 10^{-4}$ seconds per meter, so that $\\delta \\mathbf{d} = G \\, \\delta \\mathbf{m}_{\\text{true}}$.\n\nUsing the definition of the Singular Value Decomposition (SVD) and the generalized inverse (Moore–Penrose pseudoinverse), analyze the relative magnitudes of the singular values and the alignment of the right singular vectors $\\mathbf{v}_i$ of $G$. From this analysis, determine which statement below best describes the behavior of the generalized inverse $G^{+}$ and its physical interpretation in this simple refraction scenario (large-offset head-wave data).\n\nA. Only the component along the leading right singular vector $\\mathbf{v}_1$ aligned with $\\delta s_2$ contributes significantly to $G^{+}$, so $\\delta s_2$ is stably recovered, while $\\delta s_1$ and $\\delta z$ remain poorly resolved due to tiny singular values. This reflects that large-offset head waves primarily constrain the slope (refractor slowness), not the intercept.\n\nB. Because the two constant columns are collinear, the matrix $G$ is exactly rank-$1$, so both $\\delta z$ and $\\delta s_1$ are uniquely recoverable once $\\delta s_2$ is known.\n\nC. The leading right singular vector aligns with the constant columns ($\\delta z$ and $\\delta s_1$), implying that large-offset data primarily constrain the intercept time and not the slope, so $\\delta s_2$ is unresolvable.\n\nD. In the absence of regularization, the generalized inverse amplifies contributions from small singular values more than from the largest one, so estimates of $\\delta s_1$ and $\\delta z$ are more stable than $\\delta s_2$.", "solution": "Let the columns of the sensitivity matrix $G$ be $\\mathbf{g}_1, \\mathbf{g}_2, \\mathbf{g}_3$, corresponding to the model parameters $\\delta s_1, \\delta s_2, \\delta z$.\n$$\nG = \\begin{bmatrix} \\mathbf{g}_1 & \\mathbf{g}_2 & \\mathbf{g}_3 \\end{bmatrix} = \\begin{bmatrix}\n0.02 & 500 & 0.01 \\\\\n0.02 & 1000 & 0.01 \\\\\n0.02 & 1500 & 0.01 \\\\\n0.02 & 2000 & 0.01 \\\\\n0.02 & 2500 & 0.01\n\\end{bmatrix}\n$$\nThe first and third columns are constant vectors, representing the sensitivity to upper-layer slowness $\\delta s_1$ and depth $\\delta z$, respectively. These sensitivities are related to the intercept time of the head wave. The second column represents the sensitivity to the refractor slowness $\\delta s_2$, which is proportional to the offset $x_k$ and relates to the slope of the travel-time curve.\n\n**1. Rank and Column Dependencies**\nWe immediately notice that $\\mathbf{g}_1 = 2 \\mathbf{g}_3$. This means the first and third columns are linearly dependent. The column $\\mathbf{g}_2$ is not a multiple of the others. Therefore, the column space of $G$ is spanned by two vectors (e.g., $\\mathbf{g}_2$ and $\\mathbf{g}_3$), and the rank of $G$ is 2.\nBecause the matrix has 3 columns and rank 2, it has a one-dimensional null space. Any model perturbation vector $\\delta \\mathbf{m}_{null}$ in this null space will produce zero data perturbation ($G \\delta \\mathbf{m}_{null} = \\mathbf{0}$). The null space is defined by $c_1\\mathbf{g}_1 + c_2\\mathbf{g}_2 + c_3\\mathbf{g}_3 = \\mathbf{0}$. Given $\\mathbf{g}_1=2\\mathbf{g}_3$ and the linear independence of $\\mathbf{g}_2$ and $\\mathbf{g}_3$, we must have $c_2=0$ and $2c_1+c_3=0$. A basis vector for the null space is thus $\\delta \\mathbf{m}_{null} = [1, 0, -2]^\\top$. This shows an inherent ambiguity: the data cannot distinguish between a change in $\\delta s_1$ and an opposing change in $\\delta z$ (scaled by -2).\n\n**2. Singular Value Decomposition (SVD) Analysis**\nThe SVD, $G = U \\Sigma V^\\top$, provides insight into which model components are well-determined. The squares of the singular values, $\\sigma_i^2$, are the eigenvalues of $G^\\top G$. The corresponding right singular vectors, $\\mathbf{v}_i$, form an orthonormal basis for the model space.\nLet's compare the \"energy\" or norm of the columns of $G$:\n-   $\\|\\mathbf{g}_1\\|^2 = 5 \\times (0.02)^2 = 0.002$\n-   $\\|\\mathbf{g}_3\\|^2 = 5 \\times (0.01)^2 = 0.0005$\n-   $\\|\\mathbf{g}_2\\|^2 = 500^2(1^2 + 2^2 + 3^2 + 4^2 + 5^2) = 250000(55) = 13,750,000$\n\nThe norm of $\\mathbf{g}_2$ is many orders of magnitude larger than the norms of $\\mathbf{g}_1$ and $\\mathbf{g}_3$. This indicates that the data are overwhelmingly more sensitive to changes in $\\delta s_2$ than to changes in $\\delta s_1$ or $\\delta z$.\nIn the SVD, this vast difference in sensitivity translates to a large separation in singular values:\n-   The largest singular value, $\\sigma_1$, will be associated with the direction of greatest sensitivity, which is the direction of $\\mathbf{g}_2$. Therefore, the first right singular vector, $\\mathbf{v}_1$, will be almost perfectly aligned with the $\\delta s_2$ axis: $\\mathbf{v}_1 \\approx [0, 1, 0]^\\top$. The magnitude will be $\\sigma_1 \\approx \\|\\mathbf{g}_2\\| \\approx 3708$.\n-   Since the rank is 2, there will be a second, much smaller non-zero singular value, $\\sigma_2$. This will be associated with the resolvable combination of $\\delta s_1$ and $\\delta z$. Its magnitude will be on the order of $\\|\\mathbf{g}_1\\|$ and $\\|\\mathbf{g}_3\\|$, so $\\sigma_2$ will be small.\n-   The third singular value, $\\sigma_3$, will be zero, reflecting the rank-deficiency. The corresponding right singular vector $\\mathbf{v}_3$ spans the null space, so $\\mathbf{v}_3 = [1/\\sqrt{5}, 0, -2/\\sqrt{5}]^\\top$.\n\n**3. Interpretation of the Generalized Inverse**\nThe generalized inverse solution is $\\delta \\mathbf{m}_{est} = G^+ \\delta \\mathbf{d} = \\sum_{i=1}^2 \\frac{1}{\\sigma_i} (\\mathbf{u}_i^\\top \\delta \\mathbf{d}) \\mathbf{v}_i$.\n-   The component of the solution along $\\mathbf{v}_1$ (the $\\delta s_2$ direction) is scaled by $1/\\sigma_1$. Since $\\sigma_1$ is very large, this term is small and stable. This means $\\delta s_2$ is well-determined.\n-   The component along $\\mathbf{v}_2$ (a combination of $\\delta s_1$ and $\\delta z$) is scaled by $1/\\sigma_2$. Since $\\sigma_2$ is small, any noise projecting onto $\\mathbf{u}_2$ will be greatly amplified, making this component unstable and poorly resolved.\n-   There is no component along $\\mathbf{v}_3$. The ambiguity between $\\delta s_1$ and $\\delta z$ is completely unresolved by the pseudoinverse.\n\nConclusion: The SVD shows that $\\delta s_2$ is resolved stably, while $\\delta s_1$ and $\\delta z$ are poorly resolved. This matches the physical intuition that long-offset refraction data are excellent for determining refractor slowness (the slope) but poor at uniquely determining the parameters that control the intercept time. This directly supports option A.", "answer": "$$\\boxed{A}$$", "id": "3616825"}]}