{"hands_on_practices": [{"introduction": "The choice of how we parameterize a physical model is not arbitrary and has significant consequences for solving inverse problems. Different parameterizations can make the relationship between model parameters and observed data more or less linear. This hands-on exercise explores this concept by asking you to quantify the degree of nonlinearity for two different parameterizations of an acoustic medium: bulk modulus versus its reciprocal, compressibility [@problem_id:3616719]. By analytically comparing the size of second-order effects to first-order ones, you will gain a deeper appreciation for why certain physical parameterizations are preferred in inversion.", "problem": "Consider one-dimensional acoustic wave propagation in a homogeneous, isotropic medium of constant mass density $\\rho_0$ and bulk modulus $K_0$. In the frequency domain at angular frequency $\\omega$, the scalar pressure field $p(x;\\theta)$ satisfies the Helmholtz-type equation $p''(x) + k^2(\\theta)\\,p(x) = 0$, where $k(\\theta)$ is the wavenumber expressed in terms of a model parameter $\\theta$. For the compressibility parameterization, $\\theta=\\kappa$ with $\\kappa=1/K$, the wavenumber is $k(\\kappa)=\\omega\\sqrt{\\rho_0\\,\\kappa}$; for the bulk-modulus parameterization, $\\theta=K$, it is $k(K)=\\omega\\sqrt{\\rho_0/K}$. A unit-amplitude right-going plane wave is incident at $x=0$, and the forward datum is the complex pressure at $x=L$ for $L>0$, namely $d(\\theta)=p(L;\\theta)=\\exp\\!\\big(i\\,k(\\theta)\\,L\\big)$.\n\nDefine the \"second-order Born metric\" for a parameterization $\\theta$ at the background value $\\theta_0$ under an equal fractional perturbation of amplitude $\\varepsilon$ as\n$$\nM_{\\theta} \\equiv \\left|\\frac{\\frac{1}{2}\\,d''(\\theta_0)\\,\\big(\\delta\\theta\\big)^2}{d'(\\theta_0)\\,\\delta\\theta}\\right|, \\quad \\delta\\theta=\\varepsilon\\,\\theta_0,\\quad 0<\\varepsilon\\ll 1,\n$$\nwhere $d'(\\theta_0)$ and $d''(\\theta_0)$ are the first and second derivatives of $d(\\theta)$ with respect to $\\theta$ evaluated at $\\theta=\\theta_0$. This metric quantifies the relative magnitude of the second-order Born term to the first-order Born term for a given parameterization under the same fractional perturbation.\n\nUsing $K_0$ and $\\kappa_0=1/K_0$ as the background values for the two parameterizations, derive the closed-form expression for the ratio\n$$\n\\mathcal{R} \\equiv \\frac{M_{K}}{M_{\\kappa}}\n$$\nin terms of $L$, $\\omega$, $\\rho_0$, and $K_0$. Express your final answer as a single analytic expression. No numerical evaluation or rounding is required, and no physical units should appear in the final expression.", "solution": "The user has provided a valid problem statement.\n\n**1. Problem Validation**\n\n**Step 1: Extract Givens**\n-   Governing Equation: $p''(x) + k^2(\\theta)\\,p(x) = 0$\n-   Medium Properties: Constant mass density $\\rho_0$, constant bulk modulus $K_0$.\n-   Compressibility Parameterization: $\\theta=\\kappa=1/K$, with wavenumber $k(\\kappa)=\\omega\\sqrt{\\rho_0\\,\\kappa}$.\n-   Bulk-Modulus Parameterization: $\\theta=K$, with wavenumber $k(K)=\\omega\\sqrt{\\rho_0/K}$.\n-   Forward Datum: $d(\\theta)=p(L;\\theta)=\\exp(i\\,k(\\theta)\\,L)$ for $L>0$.\n-   Second-Order Born Metric: $M_{\\theta} \\equiv \\left|\\frac{\\frac{1}{2}\\,d''(\\theta_0)\\,\\big(\\delta\\theta\\big)^2}{d'(\\theta_0)\\,\\delta\\theta}\\right|$.\n-   Perturbation: $\\delta\\theta=\\varepsilon\\,\\theta_0$ for $0<\\varepsilon\\ll 1$.\n-   Background Values: $\\theta_0=K_0$ for the $K$-parameterization and $\\theta_0=\\kappa_0=1/K_0$ for the $\\kappa$-parameterization.\n-   Objective: Derive the expression for the ratio $\\mathcal{R} \\equiv \\frac{M_{K}}{M_{\\kappa}}$ in terms of $L$, $\\omega$, $\\rho_0$, and $K_0$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem uses the standard 1D acoustic wave equation (Helmholtz form) and correct physical definitions for wavenumber and material properties ($K$, $\\kappa$, $\\rho_0$). The analysis of model parameterization through Taylor series expansion (Born approximation context) is a standard technique in computational geophysics and inverse theory. The problem is fundamentally sound.\n-   **Well-Posed:** All necessary definitions, equations, and variables are provided to derive the requested ratio. The task is specific and leads to a unique analytical solution.\n-   **Objective:** The problem is stated in precise mathematical and physical terms, free of subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid as it is scientifically grounded, well-posed, and objective. I will proceed with the solution.\n\n**2. Solution Derivation**\n\nThe objective is to compute the ratio $\\mathcal{R} = M_K / M_\\kappa$. First, we simplify the expression for the metric $M_\\theta$.\n$$\nM_{\\theta} \\equiv \\left|\\frac{\\frac{1}{2}\\,d''(\\theta_0)\\,\\big(\\delta\\theta\\big)^2}{d'(\\theta_0)\\,\\delta\\theta}\\right| = \\left|\\frac{1}{2}\\frac{d''(\\theta_0)}{d'(\\theta_0)}\\delta\\theta\\right|\n$$\nSubstituting $\\delta\\theta=\\varepsilon\\,\\theta_0$, we get:\n$$\nM_{\\theta} = \\frac{\\varepsilon\\,\\theta_0}{2} \\left| \\frac{d''(\\theta_0)}{d'(\\theta_0)} \\right|\n$$\nThe core of the calculation involves the ratio of the second and first derivatives of the data function $d(\\theta) = \\exp(i\\,k(\\theta)\\,L)$. We compute these derivatives generally.\nUsing the chain rule:\n$$\nd'(\\theta) = \\frac{d}{d\\theta}\\exp(i\\,k(\\theta)\\,L) = i\\,L\\,k'(\\theta)\\,\\exp(i\\,k(\\theta)\\,L)\n$$\nDifferentiating a second time using the product rule:\n\\begin{align*}\nd''(\\theta) &= \\frac{d}{d\\theta} \\left[ i\\,L\\,k'(\\theta)\\,\\exp(i\\,k(\\theta)\\,L) \\right] \\\\\n&= i\\,L\\,k''(\\theta)\\,\\exp(i\\,k(\\theta)\\,L) + i\\,L\\,k'(\\theta) \\left[ i\\,L\\,k'(\\theta)\\,\\exp(i\\,k(\\theta)\\,L) \\right] \\\\\n&= \\left[ i\\,L\\,k''(\\theta) + (i\\,L\\,k'(\\theta))^2 \\right] \\exp(i\\,k(\\theta)\\,L) \\\\\n&= \\left[ i\\,L\\,k''(\\theta) - L^2(k'(\\theta))^2 \\right] \\exp(i\\,k(\\theta)\\,L)\n\\end{align*}\nThe ratio of the derivatives is:\n$$\n\\frac{d''(\\theta)}{d'(\\theta)} = \\frac{\\left[ i\\,L\\,k''(\\theta) - L^2(k'(\\theta))^2 \\right] \\exp(i\\,k(\\theta)\\,L)}{i\\,L\\,k'(\\theta)\\,\\exp(i\\,k(\\theta)\\,L)} = \\frac{k''(\\theta)}{k'(\\theta)} - \\frac{L\\,k'(\\theta)}{i} = \\frac{k''(\\theta)}{k'(\\theta)} + i\\,L\\,k'(\\theta)\n$$\nThis general expression will be evaluated for each parameterization at its background value. Let $k_0 = \\omega\\sqrt{\\rho_0/K_0} = \\omega\\sqrt{\\rho_0\\kappa_0}$ be the background wavenumber.\n\n**Bulk-Modulus Parameterization ($\\theta = K$)**\nHere, $\\theta_0=K_0$. The wavenumber is $k(K) = \\omega\\sqrt{\\rho_0} K^{-1/2}$.\nThe derivatives with respect to $K$ are:\n$$\nk'(K) = \\omega\\sqrt{\\rho_0} \\left(-\\frac{1}{2}\\right) K^{-3/2} = -\\frac{1}{2K} \\left(\\omega\\sqrt{\\rho_0} K^{-1/2}\\right) = -\\frac{k(K)}{2K}\n$$\n$$\nk''(K) = \\omega\\sqrt{\\rho_0} \\left(-\\frac{1}{2}\\right) \\left(-\\frac{3}{2}\\right) K^{-5/2} = \\frac{3}{4} \\omega\\sqrt{\\rho_0} K^{-5/2}\n$$\nAt the background $K_0$:\n$$\nk'(K_0) = -\\frac{k_0}{2K_0}\n$$\nThe ratio of the wavenumber derivatives is:\n$$\n\\frac{k''(K_0)}{k'(K_0)} = \\frac{\\frac{3}{4}\\omega\\sqrt{\\rho_0}K_0^{-5/2}}{-\\frac{1}{2}\\omega\\sqrt{\\rho_0}K_0^{-3/2}} = -\\frac{3}{2}K_0^{-1} = -\\frac{3}{2K_0}\n$$\nSubstituting into the general expression for the ratio of data derivatives:\n$$\n\\left.\\frac{d''(K)}{d'(K)}\\right|_{K_0} = \\frac{k''(K_0)}{k'(K_0)} + i\\,L\\,k'(K_0) = -\\frac{3}{2K_0} + i\\,L\\left(-\\frac{k_0}{2K_0}\\right) = -\\frac{1}{2K_0}(3 + i\\,L\\,k_0)\n$$\nNow we compute the metric $M_K$:\n$$\nM_K = \\frac{\\varepsilon\\,K_0}{2} \\left| -\\frac{1}{2K_0}(3 + i\\,L\\,k_0) \\right| = \\frac{\\varepsilon\\,K_0}{4K_0} |3 + i\\,L\\,k_0| = \\frac{\\varepsilon}{4}\\sqrt{3^2 + (L\\,k_0)^2} = \\frac{\\varepsilon}{4}\\sqrt{9 + (L\\,k_0)^2}\n$$\n\n**Compressibility Parameterization ($\\theta = \\kappa$)**\nHere, $\\theta_0 = \\kappa_0 = 1/K_0$. The wavenumber is $k(\\kappa) = \\omega\\sqrt{\\rho_0} \\kappa^{1/2}$.\nThe derivatives with respect to $\\kappa$ are:\n$$\nk'(\\kappa) = \\omega\\sqrt{\\rho_0}\\left(\\frac{1}{2}\\right)\\kappa^{-1/2} = \\frac{1}{2\\kappa}\\left(\\omega\\sqrt{\\rho_0}\\kappa^{1/2}\\right) = \\frac{k(\\kappa)}{2\\kappa}\n$$\n$$\nk''(\\kappa) = \\omega\\sqrt{\\rho_0}\\left(\\frac{1}{2}\\right)\\left(-\\frac{1}{2}\\right)\\kappa^{-3/2} = -\\frac{1}{4}\\omega\\sqrt{\\rho_0}\\kappa^{-3/2}\n$$\nAt the background $\\kappa_0$:\n$$\nk'(\\kappa_0) = \\frac{k_0}{2\\kappa_0}\n$$\nThe ratio of the wavenumber derivatives is:\n$$\n\\frac{k''(\\kappa_0)}{k'(\\kappa_0)} = \\frac{-\\frac{1}{4}\\omega\\sqrt{\\rho_0}\\kappa_0^{-3/2}}{\\frac{1}{2}\\omega\\sqrt{\\rho_0}\\kappa_0^{-1/2}} = -\\frac{1}{2}\\kappa_0^{-1} = -\\frac{1}{2\\kappa_0}\n$$\nSubstituting into the general expression for the ratio of data derivatives:\n$$\n\\left.\\frac{d''(\\kappa)}{d'(\\kappa)}\\right|_{\\kappa_0} = \\frac{k''(\\kappa_0)}{k'(\\kappa_0)} + i\\,L\\,k'(\\kappa_0) = -\\frac{1}{2\\kappa_0} + i\\,L\\left(\\frac{k_0}{2\\kappa_0}\\right) = \\frac{1}{2\\kappa_0}(-1 + i\\,L\\,k_0)\n$$\nNow we compute the metric $M_\\kappa$:\n$$\nM_\\kappa = \\frac{\\varepsilon\\,\\kappa_0}{2}\\left|\\frac{1}{2\\kappa_0}(-1 + i\\,L\\,k_0)\\right| = \\frac{\\varepsilon\\,\\kappa_0}{4\\kappa_0}|-1 + i\\,L\\,k_0| = \\frac{\\varepsilon}{4}\\sqrt{(-1)^2+(L\\,k_0)^2} = \\frac{\\varepsilon}{4}\\sqrt{1 + (L\\,k_0)^2}\n$$\n\n**Final Ratio Calculation**\nFinally, we compute the ratio $\\mathcal{R} = M_K/M_\\kappa$:\n$$\n\\mathcal{R} = \\frac{M_K}{M_\\kappa} = \\frac{\\frac{\\varepsilon}{4}\\sqrt{9 + (L\\,k_0)^2}}{\\frac{\\varepsilon}{4}\\sqrt{1 + (L\\,k_0)^2}} = \\sqrt{\\frac{9 + (L\\,k_0)^2}{1 + (L\\,k_0)^2}}\n$$\nThe problem requires the answer in terms of $L$, $\\omega$, $\\rho_0$, and $K_0$. We substitute the expression for the background wavenumber squared, $(k_0)^2 = \\omega^2 \\rho_0/K_0$.\n$$\n\\mathcal{R} = \\sqrt{\\frac{9 + L^2 \\omega^2 \\frac{\\rho_0}{K_0}}{1 + L^2 \\omega^2 \\frac{\\rho_0}{K_0}}}\n$$\nThis is the final closed-form expression for the ratio.", "answer": "$$\\boxed{\\sqrt{\\frac{9 + L^2 \\omega^2 \\frac{\\rho_0}{K_0}}{1 + L^2 \\omega^2 \\frac{\\rho_0}{K_0}}}}$$", "id": "3616719"}, {"introduction": "For the large-scale inverse problems common in geophysics, we need an efficient method to calculate the sensitivity of our predictions to thousands or millions of model parameters. The adjoint-state method is the cornerstone technique that accomplishes this, allowing us to compute the gradient of a misfit function with respect to all model parameters at a computational cost comparable to just one forward simulation. This practice guides you through the derivation and implementation of the adjoint-state method from first principles for a steady-state electrical resistivity problem [@problem_id:3616704], building a fundamental and widely applicable skill.", "problem": "Consider the scalar elliptic partial differential equation (PDE) $\\,\\nabla\\cdot(\\sigma\\nabla\\phi)=q\\,$ on the unit square domain $\\Omega=[0,1]^2$ with homogeneous Dirichlet boundary conditions $\\,\\phi=0\\,$ on $\\partial\\Omega$. The unknown field is the potential $\\,\\phi(x,y)\\,$, the model parameter is the conductivity $\\,\\sigma(x,y)>0\\,$, and $\\,q(x,y)\\,$ is a prescribed source distribution. Measurements are given by a linear operator $\\,P\\,$ acting on $\\,\\phi\\,$ to produce $\\,d=P\\phi\\,$. Let $\\,r\\,$ denote the data residual vector. The forward problem and model parameterization are posed in the following terms:\n\n- The forward operator maps $\\,\\sigma\\,$ to data $\\,d=P\\phi\\,$, where $\\,\\phi\\,$ solves $\\,\\nabla\\cdot(\\sigma\\nabla\\phi)=q\\,$ with $\\,\\phi=0\\,$ on $\\,\\partial\\Omega$.\n- The Jacobian $\\,J\\,$ is the Fr√©chet derivative of the data mapping with respect to the parameter $\\,\\sigma\\,$, and $\\,J^T r\\,$ denotes the adjoint action on the data residual $\\,r\\,$.\n- You must compute $\\,J^T r\\,$ using the adjoint-state method without resorting to any shortcut formulas. Start from the weak form of the PDE and first principles of the calculus of variations and linear operators, and derive an algorithm to evaluate the action $\\,\\delta\\sigma\\mapsto r^T P\\,\\delta\\phi\\,$ as an $\\,L^2(\\Omega)\\,$ inner product between $\\,J^T r\\,$ and a perturbation $\\,\\delta\\sigma$.\n\nYou will discretize $\\,\\Omega\\,$ using a uniform Cartesian grid of $\\,N\\times N\\,$ points with spacing $\\,h=\\frac{1}{N-1}\\,$ in both directions, enforce $\\,\\phi=0\\,$ on the boundary points, and assemble a symmetric positive definite linear system representing the discrete operator associated with $\\,\\nabla\\cdot(\\sigma\\nabla\\phi)\\,$ using face-centered arithmetic averaging of $\\,\\sigma\\,$. You will implement the following computational tasks:\n\n1. Solve the forward problem to obtain $\\,\\phi\\,$.\n2. Construct the adjoint source from the data residual $\\,r\\,$ in a way consistent with the measurement operator $\\,P\\,$, and solve the adjoint problem to obtain the adjoint field $\\,\\lambda\\,$.\n3. Compute a discrete approximation of the field $\\,J^T r\\,$ over the grid from first principles.\n4. Verify, for a given perturbation $\\,\\delta\\sigma\\,$, that the linearized response identity holds numerically by comparing the scalar quantities $\\,r^T P\\,\\delta\\phi\\,$ and the domain integral $\\,\\int_\\Omega (J^T r)\\,\\delta\\sigma\\,\\mathrm{d}x\\,\\mathrm{d}y\\,$, where $\\,\\delta\\phi\\,$ solves the linearized forward equation induced by $\\,\\delta\\sigma\\,$. Report the absolute mismatch as a floating-point number.\n\nYou must explain how the adjoint sources are constructed from the data residuals $\\,r\\,$, for general linear measurement operators $\\,P\\,$ and for the special case when $\\,P\\,$ samples $\\,\\phi\\,$ at grid points.\n\nYour program must implement the above and produce a single line of output containing the absolute mismatches for the test suite described below as a comma-separated list enclosed in square brackets. Each mismatch must be a floating-point number.\n\nUse the following test suite. All quantities are dimensionless.\n\n- Test Case 1 (baseline, constant conductivity, residual tied to forward data):\n  - Grid size: $\\,N=32$.\n  - Conductivity: $\\,\\sigma(x,y)=1$ everywhere.\n  - Source: a unit point source at the central grid point, i.e., set $\\,q_{i_0,j_0}=1\\,$ with $\\,i_0=j_0=\\lfloor N/2\\rfloor\\,$ and zero elsewhere.\n  - Measurements: $\\,P\\,$ samples $\\,\\phi\\,$ at three interior points with indices $\\,[(\\lfloor N/4\\rfloor,\\lfloor N/4\\rfloor),(\\lfloor N/2\\rfloor,\\lfloor N/3\\rfloor),(\\lfloor 3N/4\\rfloor,\\lfloor 3N/4\\rfloor)]$.\n  - Residual: set $\\,d_{\\text{obs}}=0\\,$ and $\\,r=d_{\\text{obs}}-P\\phi\\,$.\n  - Perturbation: $\\,\\delta\\sigma\\,$ is a small zero-mean random field drawn from a uniform distribution on $\\,[-0.1,0.1]\\,$, with a fixed random seed for reproducibility.\n\n- Test Case 2 (heterogeneous conductivity, prescribed residual):\n  - Grid size: $\\,N=40$.\n  - Conductivity: $\\,\\sigma(x,y)=1+0.5\\sin(2\\pi x)\\sin(2\\pi y)$ evaluated at grid points.\n  - Source: a unit point source at indices $\\,(\\lfloor N/3\\rfloor,\\lfloor N/2\\rfloor)$.\n  - Measurements: $\\,P\\,$ samples $\\,\\phi\\,$ at five interior points with indices $\\,[(\\lfloor N/5\\rfloor,\\lfloor N/5\\rfloor),(\\lfloor 2N/5\\rfloor,\\lfloor 3N/7\\rfloor),(\\lfloor N/2\\rfloor,\\lfloor 2N/3\\rfloor),(\\lfloor 3N/5\\rfloor,\\lfloor 2N/5\\rfloor),(\\lfloor 4N/5\\rfloor,\\lfloor 4N/5\\rfloor)]$.\n  - Residual: $\\,r=[1,-0.5,0.25,-0.25,0.1]^T$.\n  - Perturbation: $\\,\\delta\\sigma\\,$ is a small zero-mean random field drawn from a uniform distribution on $\\,[-0.05,0.05]\\,$, with a fixed random seed for reproducibility.\n\n- Test Case 3 (edge case, zero forward field):\n  - Grid size: $\\,N=24$.\n  - Conductivity: $\\,\\sigma(x,y)=1$ everywhere.\n  - Source: $\\,q=0\\,$ everywhere.\n  - Measurements: a single boundary point at indices $\\, (0,\\lfloor N/2\\rfloor)$.\n  - Residual: $\\,r=[1]^T$.\n  - Perturbation: $\\,\\delta\\sigma\\,$ is a small zero-mean random field drawn from a uniform distribution on $\\,[-0.02,0.02]\\,$, with a fixed random seed for reproducibility.\n\nYour program should produce a single line of output containing the absolute mismatches for the three test cases as a comma-separated list enclosed in square brackets, for example, $\\,[m_1,m_2,m_3]\\,$ where $\\,m_k\\,$ is the mismatch for the $\\,k$-th test case.", "solution": "The problem requires the derivation and implementation of the adjoint-state method to compute the quantity $J^T r$, representing the action of the adjoint of the data sensitivity Jacobian on the data residual vector. The physical model is governed by the scalar elliptic PDE $\\nabla\\cdot(\\sigma\\nabla\\phi)=q$ on the unit square $\\Omega=[0,1]^2$ with homogeneous Dirichlet boundary conditions $\\phi=0$ on $\\partial\\Omega$. We must derive the algorithm from first principles and verify it numerically.\n\nThe core of the method is to find an explicit expression for the field $G = J^T r$ that satisfies the defining relation of the adjoint operator:\n$$\n\\langle r, J \\delta\\sigma \\rangle_{\\text{data}} = \\langle J^T r, \\delta\\sigma \\rangle_{L^2(\\Omega)}\n$$\nwhere $\\delta\\sigma$ is a perturbation in the model parameter (conductivity $\\sigma$), and $J\\delta\\sigma$ is the resulting change in the predicted data. The predicted data $d=P\\phi$ is obtained via a linear measurement operator $P$ acting on the potential field $\\phi$. The change in data is thus $J\\delta\\sigma = P\\delta\\phi$, where $\\delta\\phi$ is the change in the potential. The identity to verify becomes $r^T(P\\delta\\phi) = \\int_\\Omega (J^T r)\\delta\\sigma \\, d\\Omega$.\n\nOur derivation proceeds in three steps:\n1.  **Linearized Forward Equation**: We start from the weak form of the PDE, $\\int_\\Omega \\sigma \\nabla\\phi \\cdot \\nabla v \\, d\\Omega = -\\int_\\Omega q v \\, d\\Omega$ for all suitable test functions $v$. By linearizing this with respect to a perturbation $\\delta\\sigma$, we find the equation governing the corresponding potential perturbation $\\delta\\phi$:\n    $$\n    \\int_\\Omega \\sigma \\nabla\\delta\\phi \\cdot \\nabla v \\, d\\Omega = -\\int_\\Omega \\delta\\sigma \\nabla\\phi \\cdot \\nabla v \\, d\\Omega\n    $$\n2.  **Adjoint Equation**: We introduce an adjoint field $\\lambda$ to relate the term $r^T P\\delta\\phi$ back to the linearized equation. The term $r^T P\\delta\\phi$ can be written as an inner product in the function space, $\\langle P^T r, \\delta\\phi \\rangle = \\int_\\Omega (P^T r) \\delta\\phi \\, d\\Omega$. We define the adjoint field $\\lambda$ as the solution to the adjoint PDE, $\\nabla \\cdot (\\sigma \\nabla \\lambda) = P^T r$, with $\\lambda=0$ on $\\partial\\Omega$. As the differential operator is self-adjoint, this equation has the same form as the forward PDE. Its weak form is $\\int_\\Omega \\sigma \\nabla\\lambda \\cdot \\nabla w \\, d\\Omega = -\\int_\\Omega (P^T r) w \\, d\\Omega$. Choosing the test function $w = \\delta\\phi$, we get:\n    $$\n    -\\int_\\Omega (P^T r) \\delta\\phi \\, d\\Omega = -r^T P\\delta\\phi = \\int_\\Omega \\sigma \\nabla\\lambda \\cdot \\nabla \\delta\\phi \\, d\\Omega\n    $$\n3.  **Identification of $J^T r$**: By choosing the test function $v = \\lambda$ in the linearized forward equation, we get $\\int_\\Omega \\sigma \\nabla\\delta\\phi \\cdot \\nabla \\lambda \\, d\\Omega = -\\int_\\Omega \\delta\\sigma \\nabla\\phi \\cdot \\nabla \\lambda \\, d\\Omega$. The left-hand side is identical to the right-hand side of the adjoint relation derived above. Equating the remaining terms gives:\n    $$\n    -r^T P\\delta\\phi = -\\int_\\Omega (\\nabla\\phi \\cdot \\nabla \\lambda) \\delta\\sigma \\, d\\Omega\n    $$\n    This simplifies to $r^T P\\delta\\phi = \\int_\\Omega (\\nabla\\phi \\cdot \\nabla \\lambda) \\delta\\sigma \\, d\\Omega$. Comparing this with the definition of the adjoint action, we identify the explicit expression for the sought-after field:\n    $$\n    J^T r = \\nabla\\phi \\cdot \\nabla\\lambda\n    $$\nFor point-wise measurements, the adjoint source $P^T r$ becomes a sum of Dirac delta distributions located at the measurement points, weighted by the corresponding residual values. In the discrete setting, this means placing the residual values at the respective grid nodes.\n\nThe following program implements this adjoint-state method. It numerically solves the forward problem for $\\phi$, the adjoint problem for $\\lambda$, and computes $J^T r$ as the dot product of their gradients. It then explicitly calculates both sides of the identity $r^T P\\delta\\phi = \\int (J^T r) \\delta\\sigma \\,d\\Omega$ and reports their absolute difference to verify the correctness of the derivation and implementation. The discretization employs a five-point finite difference scheme on the interior nodes of the grid, resulting in a sparse, symmetric, positive-definite linear system that is solved efficiently.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import lil_matrix, csr_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n\n    def solve_case(N, sigma_func, q_loc, meas_loc_indices, r_val, delta_sigma_dist, seed):\n        \"\"\"\n        Solves a single test case for the adjoint verification problem.\n        \"\"\"\n        h = 1.0 / (N - 1)\n        x = np.linspace(0, 1, N)\n        y = np.linspace(0, 1, N)\n        xx, yy = np.meshgrid(x, y)\n\n        sigma = sigma_func(xx, yy)\n        q_grid = np.zeros((N, N))\n        if q_loc:\n            q_grid[q_loc] = 1.0\n\n        meas_loc_indices = np.array(meas_loc_indices)\n        meas_rows, meas_cols = meas_loc_indices[:, 0], meas_loc_indices[:, 1]\n\n        np.random.seed(seed)\n        delta_sigma = np.random.uniform(delta_sigma_dist[0], delta_sigma_dist[1], size=(N, N))\n        delta_sigma -= np.mean(delta_sigma)\n\n        def build_operator(s_field):\n            \"\"\"Builds the discrete operator B for -div(sigma*grad).\"\"\"\n            n_int = N - 2\n            n_dof = n_int * n_int\n            A = lil_matrix((n_dof, n_dof))\n\n            for i_int in range(n_int):\n                for j_int in range(n_int):\n                    k = i_int * n_int + j_int\n                    i, j = i_int + 1, j_int + 1\n\n                    diag_val = 0.0\n\n                    # East neighbor\n                    s_e = 0.5 * (s_field[i, j] + s_field[i, j + 1])\n                    diag_val += s_e\n                    if j_int < n_int - 1:\n                        A[k, k + 1] = -s_e / h**2\n\n                    # West neighbor\n                    s_w = 0.5 * (s_field[i, j] + s_field[i, j - 1])\n                    diag_val += s_w\n                    if j_int > 0:\n                        A[k, k - 1] = -s_w / h**2\n\n                    # North neighbor\n                    s_n = 0.5 * (s_field[i, j] + s_field[i + 1, j])\n                    diag_val += s_n\n                    if i_int < n_int - 1:\n                        A[k, k + n_int] = -s_n / h**2\n\n                    # South neighbor\n                    s_s = 0.5 * (s_field[i, j] + s_field[i - 1, j])\n                    diag_val += s_s\n                    if i_int > 0:\n                        A[k, k - n_int] = -s_s / h**2\n                        \n                    A[k, k] = diag_val / h**2\n            return csr_matrix(A)\n\n        # 1. Solve forward problem for phi: B*phi = -q\n        B_op = build_operator(sigma)\n        q_interior = q_grid[1:-1, 1:-1].flatten()\n        phi_vec = spsolve(B_op, -q_interior)\n        phi = np.zeros((N, N))\n        phi[1:-1, 1:-1] = phi_vec.reshape((N - 2, N - 2))\n\n        # Define residual r\n        if r_val is None:\n            d_calc = phi[meas_rows, meas_cols]\n            d_obs = 0.0\n            r = d_obs - d_calc\n        else:\n            r = np.array(r_val)\n\n        # 2. Solve adjoint problem for lambda: B*lambda = -q_adj\n        q_adj_grid = np.zeros((N, N))\n        for idx, res_val in zip(meas_loc_indices, r):\n            if 1 <= idx[0] < N - 1 and 1 <= idx[1] < N - 1:\n                q_adj_grid[tuple(idx)] = res_val\n        \n        q_adj_interior = q_adj_grid[1:-1, 1:-1].flatten()\n        lambda_vec = spsolve(B_op, -q_adj_interior)\n        lam = np.zeros((N, N))\n        if q_adj_interior.any(): # Avoid reshaping empty array if all sources are on boundary\n            lam[1:-1, 1:-1] = lambda_vec.reshape((N - 2, N - 2))\n        \n        # 3. Compute J^T r field\n        grad_phi_y, grad_phi_x = np.gradient(phi, h, edge_order=2)\n        grad_lam_y, grad_lam_x = np.gradient(lam, h, edge_order=2)\n        JTr_field = grad_phi_x * grad_lam_x + grad_phi_y * grad_lam_y\n\n        # 4. Verify identity\n        # LHS: r^T P delta_phi\n        # Solve B*delta_phi = -[B(sigma+delta_sigma) - B(sigma)]*phi\n        B_perturbed = build_operator(sigma + delta_sigma)\n        phi_interior_vec = phi[1:-1, 1:-1].flatten()\n        \n        b_lin_vec = - (B_perturbed - B_op) @ phi_interior_vec\n        delta_phi_vec = spsolve(B_op, b_lin_vec)\n        delta_phi = np.zeros((N, N))\n        delta_phi[1:-1, 1:-1] = delta_phi_vec.reshape((N - 2, N - 2))\n        \n        P_delta_phi = delta_phi[meas_rows, meas_cols]\n        lhs = r @ P_delta_phi\n        \n        # RHS: integral of (J^T r) * delta_sigma\n        rhs = np.sum(JTr_field * delta_sigma) * h**2\n        \n        mismatch = np.abs(lhs - rhs)\n        return mismatch\n\n    # Test Case 1\n    N1 = 32\n    case1_params = {\n        'N': N1,\n        'sigma_func': lambda x, y: 1.0 + 0 * x,\n        'q_loc': (N1 // 2, N1 // 2),\n        'meas_loc_indices': [(N1 // 4, N1 // 4), (N1 // 2, N1 // 3), (3 * N1 // 4, 3 * N1 // 4)],\n        'r_val': None,\n        'delta_sigma_dist': (-0.1, 0.1),\n        'seed': 0\n    }\n\n    # Test Case 2\n    N2 = 40\n    case2_params = {\n        'N': N2,\n        'sigma_func': lambda x, y: 1.0 + 0.5 * np.sin(2 * np.pi * x) * np.sin(2 * np.pi * y),\n        'q_loc': (N2 // 3, N2 // 2),\n        'meas_loc_indices': [(N2 // 5, N2 // 5), (2 * N2 // 5, 3 * N2 // 7), (N2 // 2, 2 * N2 // 3), (3 * N2 // 5, 2 * N2 // 5), (4 * N2 // 5, 4 * N2 // 5)],\n        'r_val': [1.0, -0.5, 0.25, -0.25, 0.1],\n        'delta_sigma_dist': (-0.05, 0.05),\n        'seed': 1\n    }\n\n    # Test Case 3\n    N3 = 24\n    case3_params = {\n        'N': N3,\n        'sigma_func': lambda x, y: 1.0 + 0 * x,\n        'q_loc': None,\n        'meas_loc_indices': [(0, N3 // 2)],\n        'r_val': [1.0],\n        'delta_sigma_dist': (-0.02, 0.02),\n        'seed': 2\n    }\n\n    test_cases = [case1_params, case2_params, case3_params]\n    results = []\n    for params in test_cases:\n        mismatch = solve_case(**params)\n        results.append(mismatch)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3616704"}, {"introduction": "In practice, we often transform model parameters to enforce physical constraints, such as using a logarithmic transform to ensure positivity. A crucial requirement is that the sensitivity information, or gradient, remains consistent across these different parameter spaces. This exercise demonstrates how the gradient calculated via the adjoint-state method transforms predictably under such reparameterizations according to the chain rule [@problem_id:3616666]. By numerically verifying this property in the context of a Full Waveform Inversion (FWI) problem, you will confirm this fundamental principle of reparameterization invariance.", "problem": "Consider a one-dimensional frequency-domain acoustic wave propagation model used in Full Waveform Inversion (FWI), where the physical model parameter is squared slowness $m$ and the wavefield $u$ satisfies the equation $$(\\partial_{xx} + \\omega^2 m) u = s,$$ with Dirichlet boundary conditions on a segment of length $L$ discretized into $N$ interior points. The source term is $s$, which is nonzero only at a specified source index, and the data are the sampled wavefield at a specified receiver index. The misfit functional is $$J(m) = \\tfrac{1}{2} \\lVert P u(m) - d_{\\mathrm{obs}} \\rVert^2,$$ where $P$ extracts the wavefield component at the receiver location and $d_{\\mathrm{obs}}$ is a synthetically generated observation from a specified true model $m_{\\mathrm{true}}$. Introduce a nonlinear reparameterization $p = \\log(m)$ so that $m = \\exp(p)$ and $m$ remains positive, which is standard in computational geophysics to enforce physical admissibility.\n\nYour tasks are:\n1. Starting from the forward operator definition, the misfit functional, and the principle of the adjoint-state method, derive the gradient of $J$ with respect to the physical parameter $m$ using only fundamental variational calculus and linear operator properties. Do not assume or state any formula for the final gradient at the outset.\n2. Using the chain rule and the reparameterization $p = \\log(m)$, derive the relationship between the gradients with respect to $m$ and with respect to $p$, and independently derive the gradient with respect to $p$ by differentiating the forward operator with respect to $p$.\n3. Implement a program that, for each test case below, assembles the discrete Helmholtz operator, computes the forward wavefield and the adjoint wavefield, evaluates both the gradient with respect to $p$ obtained via the chain rule transformation of the gradient with respect to $m$ and the gradient with respect to $p$ obtained directly via the adjoint-state method, and reports the relative discrepancy between these two gradients as a single float per test case, defined as $$\\frac{\\lVert \\nabla_p J_{\\mathrm{chain}} - \\nabla_p J_{\\mathrm{direct}} \\rVert_2}{\\lVert \\nabla_p J_{\\mathrm{direct}} \\rVert_2 + \\varepsilon},$$ where $\\varepsilon$ is a small positive number to avoid division by zero.\n4. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3]$), where each $r_i$ is the float relative discrepancy for test case $i$.\n\nUse the following test suite. In all cases, use $\\omega = 2\\pi f$ in radians per second, Dirichlet boundary conditions, a uniform spatial grid with spacing $h = L/(N+1)$, a central-difference discrete second derivative operator $\\partial_{xx} \\approx (u_{i-1} - 2u_i + u_{i+1})/h^2$, a unit-amplitude point source $s$ at the specified source index, and a single receiver at the specified receiver index. For each case, construct $d_{\\mathrm{obs}}$ by solving the forward problem in the true model and sampling at the receiver. Ensure all arrays are constructed exactly as specified.\n\nTest Case $1$ (happy path):\n- Model size: $N = 50$, segment length: $L = 1000$ (meters).\n- Frequency: $f = 10$ (Hertz), so $\\omega = 2\\pi f$ (radians per second).\n- Source index: $i_s = \\lfloor N/4 \\rfloor$, receiver index: $i_r = \\lfloor 3N/4 \\rfloor$.\n- True wave speed: $c_{\\mathrm{true}}$ is piecewise constant, $c_{\\mathrm{true}}(i) = 2000$ (meters per second) for $i \\le \\lfloor N/2 \\rfloor$ and $c_{\\mathrm{true}}(i) = 1800$ (meters per second) for $i > \\lfloor N/2 \\rfloor$; set $m_{\\mathrm{true}}(i) = 1/c_{\\mathrm{true}}(i)^2$ (seconds squared per meters squared).\n- Initial parameterization $p_0$: define $c_0 = 1900$ (meters per second), $m_0 = 1/c_0^2$, and set $$p_0(i) = \\log(m_0) + 0.1 \\sin\\left(\\frac{2\\pi i}{N+1}\\right).$$\n\nTest Case $2$ (boundary behavior with very small $m$):\n- Model size: $N = 50$, segment length: $L = 1000$ (meters).\n- Frequency: $f = 5$ (Hertz), so $\\omega = 2\\pi f$ (radians per second).\n- Source index: $i_s = \\lfloor N/2 \\rfloor - 5$, receiver index: $i_r = 5$.\n- True wave speed: $c_{\\mathrm{true}}(i) = 2500$ (meters per second) for all $i$, and $m_{\\mathrm{true}}(i) = 1/c_{\\mathrm{true}}(i)^2$.\n- Initial parameterization $p_0$: define $c_0 = 4000$ (meters per second), $m_0 = 1/c_0^2$, and set $$p_0(i) = \\log(m_0) - 0.2 \\exp\\left(-\\frac{(i - (N+1)/2)^2}{(0.15N)^2}\\right).$$\n\nTest Case $3$ (strong heterogeneity):\n- Model size: $N = 60$, segment length: $L = 2000$ (meters).\n- Frequency: $f = 15$ (Hertz), so $\\omega = 2\\pi f$ (radians per second).\n- Source index: $i_s = \\lfloor N/3 \\rfloor$, receiver index: $i_r = N - 5$.\n- True wave speed: $$c_{\\mathrm{true}}(i) = 2200 + 200 \\sin\\left(\\frac{4\\pi i}{N+1}\\right)\\quad\\text{(meters per second)},$$ and $m_{\\mathrm{true}}(i) = 1/c_{\\mathrm{true}}(i)^2$.\n- Initial parameterization $p_0$: define a base speed $c_0(i) = 2100 + 250 \\sin\\left(\\frac{6\\pi i}{N+1}\\right)$ (meters per second), set $m_0(i) = 1/c_0(i)^2$, and $$p_0(i) = \\log(m_0(i)) + 0.05 \\sin\\left(\\frac{2\\pi i}{N+1}\\right).$$\n\nYour program must:\n- Construct the discrete operator, solve the forward and adjoint problems, compute both gradients with respect to $p$, and report the relative discrepancy per test case as described above.\n- Produce exactly one line of output that is a comma-separated list enclosed in square brackets, in the order of Test Case $1$, Test Case $2$, Test Case $3$, for example, $[r_1,r_2,r_3]$, where each $r_i$ is a float.", "solution": "The problem requires the derivation of the gradient for a frequency-domain full-waveform inversion problem using two different parameterizations, followed by a numerical implementation to verify the consistency of the derived expressions. The core of the derivation relies on the adjoint-state method, a standard technique in optimization and inverse problems governed by partial differential equations.\n\nThe forward problem is described by the one-dimensional Helmholtz equation on a segment of length $L$:\n$$\n(\\partial_{xx} + \\omega^2 m) u = s\n$$\nwhere $u$ is the complex-valued wavefield, $m$ is the squared slowness (the model parameter), $\\omega = 2\\pi f$ is the angular frequency, and $s$ is the source term. The problem is discretized on a uniform grid with $N$ interior points and grid spacing $h = L/(N+1)$, subject to Dirichlet boundary conditions, $u(0)=u(L)=0$. This leads to a linear system of equations:\n$$\nA(m)u = s\n$$\nwhere $u \\in \\mathbb{C}^N$ is the discrete wavefield, $s \\in \\mathbb{C}^N$ is the discrete source vector, and $A(m) \\in \\mathbb{R}^{N \\times N}$ is the discrete Helmholtz operator. The operator $A(m)$ is given by $A(m) = D_{xx} + \\omega^2 \\text{diag}(m)$, where $D_{xx}$ is the finite-difference matrix for the second derivative. Given the central-difference approximation and Dirichlet boundary conditions, $D_{xx}$ is a real, symmetric, tridiagonal matrix. Since $m$ is a real-valued parameter, $A(m)$ is a real, symmetric matrix.\n\nThe objective is to minimize the misfit functional $J(m)$, defined as the squared $L^2$-norm of the data residual:\n$$\nJ(m) = \\frac{1}{2} \\lVert P u(m) - d_{\\mathrm{obs}} \\rVert_2^2 = \\frac{1}{2} (P u(m) - d_{\\mathrm{obs}})^H (P u(m) - d_{\\mathrm{obs}})\n$$\nwhere $P$ is a linear projection operator that samples the wavefield at receiver locations, $d_{\\mathrm{obs}}$ is the observed data vector, and the superscript $H$ denotes the conjugate transpose.\n\n**1. Gradient with respect to the physical parameter $m$**\n\nWe derive the gradient of $J$ with respect to the model parameter $m$ using the adjoint-state method. We begin by considering a small perturbation $\\delta m$ in the model, which induces a perturbation $\\delta u$ in the wavefield. The first-order variation in the misfit functional, $\\delta J$, is given by its Gateaux derivative:\n$$\n\\delta J = \\text{Re}\\left( (P u - d_{\\mathrm{obs}})^H P \\delta u \\right)\n$$\nLet the data residual be $r = P u - d_{\\mathrm{obs}}$. The expression becomes:\n$$\n\\delta J = \\text{Re}\\left( r^H P \\delta u \\right) = \\text{Re}\\left( (P^H r)^H \\delta u \\right)\n$$\nwhere $P^H$ is the adjoint of the sampling operator $P$. Since $P$ is represented by a real matrix, $P^H = P^T$.\n\nNext, we relate $\\delta u$ to $\\delta m$ by perturbing the forward equation, $A(m)u = s$:\n$$\nA(m+\\delta m)(u+\\delta u) = s\n$$\nExpanding the operator $A(m+\\delta m) = A(m) + \\delta A = A(m) + \\omega^2 \\text{diag}(\\delta m)$, we get:\n$$\n(A(m) + \\omega^2 \\text{diag}(\\delta m))(u + \\delta u) = s\n$$\nExpanding and retaining only first-order terms gives:\n$$\nA(m)u + A(m)\\delta u + \\omega^2 \\text{diag}(\\delta m)u \\approx s\n$$\nSince $A(m)u = s$, this simplifies to:\n$$\nA(m)\\delta u = -\\omega^2 \\text{diag}(\\delta m)u\n$$\nSolving for $\\delta u$ yields $\\delta u = -A(m)^{-1}(\\omega^2 \\text{diag}(\\delta m)u)$.\n\nSubstituting this expression for $\\delta u$ into the variation $\\delta J$:\n$$\n\\delta J = \\text{Re}\\left( (P^H r)^H \\left( -A(m)^{-1}(\\omega^2 \\text{diag}(\\delta m)u) \\right) \\right)\n$$\n$$\n\\delta J = -\\omega^2 \\text{Re}\\left( (P^H r)^H A(m)^{-1} (\\text{diag}(\\delta m)u) \\right)\n$$\nTo avoid computing the inverse $A(m)^{-1}$, we introduce the adjoint field, $v$. Let $v$ be the solution to the adjoint equation:\n$$\nA(m)^H v = P^H r = P^T(Pu - d_{\\text{obs}})\n$$\nSince $A(m)$ is a real symmetric matrix, it is self-adjoint, i.e., $A(m)^H = A(m)$. Thus, the adjoint equation is:\n$$\nA(m)v = P^T(Pu - d_{\\text{obs}})\n$$\nNote that the adjoint operator is the same as the forward operator. The source for the adjoint problem, however, is the data residual projected back into the model space. Using the adjoint field, we can write $A(m)^{-1}P^H r = (A(m)^H)^{-1}P^H r = v$. The expression for $\\delta J$ contains $(P^H r)^H A(m)^{-1}$. We can rewrite this using the property $(X Y)^H = Y^H X^H$ and $A(m)^{-1} = (A(m)^H)^{-1} = ((A(m)^{-1})^H)^{-1}$.\n$$\n(P^H r)^H A(m)^{-1} = (A(m)v)^H A(m)^{-1} = v^H A(m)^H A(m)^{-1} = v^H A(m) A(m)^{-1} = v^H\n$$\nSo, the variation becomes:\n$$\n\\delta J = -\\omega^2 \\text{Re}\\left( v^H (\\text{diag}(\\delta m)u) \\right)\n$$\nWriting this as a sum over the discrete grid points $i$:\n$$\n\\delta J = -\\omega^2 \\text{Re}\\left( \\sum_{i=0}^{N-1} v_i^* (\\delta m_i u_i) \\right) = -\\omega^2 \\sum_{i=0}^{N-1} \\delta m_i \\text{Re}(u_i v_i^*)\n$$\nThe gradient $\\nabla_m J$ is defined by the relation $\\delta J = \\langle \\nabla_m J, \\delta m \\rangle = \\sum_i (\\nabla_m J)_i \\delta m_i$. Comparing the two expressions for $\\delta J$, we identify the gradient with respect to $m$:\n$$\n(\\nabla_m J)_i = -\\omega^2 \\text{Re}(u_i v_i^*)\n$$\nHere, some literature uses an adjoint source of $P^T(Pu-d_{obs})^*$, which leads to a gradient of $(\\nabla_m J)_i = -\\omega^2 \\text{Re}(u_i^* v_i)$. The two forms are equivalent if the definition of the adjoint field $v$ is consistent. We adhere to the formula derived here.\n\n**2. Gradient with respect to the reparameterized variable $p$**\n\nTo enforce the physical constraint $m>0$, a common reparameterization is $p = \\log(m)$, or $m = \\exp(p)$. We now derive the gradient of $J$ with respect to $p$ in two ways.\n\n**Method 1: Chain Rule**\nThe gradient with respect to $p$ can be obtained from the gradient with respect to $m$ using the chain rule:\n$$\n\\nabla_p J = \\left(\\frac{\\partial m}{\\partial p}\\right)^T \\nabla_m J\n$$\nThe reparameterization is element-wise: $m_i = \\exp(p_i)$. The Jacobian matrix $\\frac{\\partial m}{\\partial p}$ is therefore diagonal:\n$$\n\\frac{\\partial m_j}{\\partial p_i} = \\delta_{ij} \\frac{d}{dp_i}(\\exp(p_i)) = \\delta_{ij} \\exp(p_i) = \\delta_{ij} m_i\n$$\nSo, $\\frac{\\partial m}{\\partial p} = \\text{diag}(m)$. The gradient with respect to $p$ is then:\n$$\n(\\nabla_p J)_i = m_i (\\nabla_m J)_i\n$$\nThis is an element-wise product, $\\nabla_p J = m \\odot \\nabla_m J$. Substituting the expression for $\\nabla_m J$:\n$$\n\\nabla_p J_{\\mathrm{chain}} = -m \\odot \\left( \\omega^2 \\text{Re}(u \\odot v^*) \\right)\n$$\nwhere $\\odot$ denotes the element-wise product and $v^*$ is the element-wise conjugate of $v$.\n\n**Method 2: Direct Derivation**\nWe can also derive $\\nabla_p J$ directly by considering $J$ as a function of $p$. The forward problem is $A(p)u = s$ where $A(p) = D_{xx} + \\omega^2 \\text{diag}(\\exp(p))$. The variation analysis proceeds as before up to the point of relating the operator perturbation to the parameter perturbation. The perturbation $\\delta A$ is now due to $\\delta p$:\n$$\n\\delta A = A(p+\\delta p) - A(p) = \\omega^2 \\left( \\text{diag}(\\exp(p+\\delta p)) - \\text{diag}(\\exp(p)) \\right)\n$$\nTo first order, $\\exp(p_i + \\delta p_i) \\approx \\exp(p_i)(1+\\delta p_i) = m_i(1+\\delta p_i)$. Thus, $\\delta m_i \\approx m_i \\delta p_i$.\n$$\n\\delta A \\approx \\omega^2 \\text{diag}(m \\odot \\delta p)\n$$\nThe perturbation in the wavefield is $\\delta u = -A(p)^{-1}(\\delta A)u = -A(p)^{-1}(\\omega^2 \\text{diag}(m \\odot \\delta p)u)$.\nSubstituting this into the expression for $\\delta J$:\n$$\n\\delta J = \\text{Re}\\left( (P^H r)^H \\delta u \\right) = \\text{Re}\\left( v^H A(p) \\delta u \\right)\n$$\n$$\n\\delta J = \\text{Re}\\left( v^H A(p) \\left( -A(p)^{-1}(\\omega^2 \\text{diag}(m \\odot \\delta p)u) \\right) \\right)\n$$\n$$\n\\delta J = -\\omega^2 \\text{Re}\\left( v^H \\text{diag}(m \\odot \\delta p)u \\right)\n$$\nWriting this out as a sum:\n$$\n\\delta J = -\\omega^2 \\text{Re}\\left( \\sum_{i=0}^{N-1} v_i^* (m_i \\delta p_i u_i) \\right) = \\sum_{i=0}^{N-1} \\delta p_i \\left( -\\omega^2 m_i \\text{Re}(u_i v_i^*) \\right)\n$$\nFrom $\\delta J = \\langle \\nabla_p J, \\delta p \\rangle$, we identify the gradient:\n$$\n(\\nabla_p J_{\\mathrm{direct}})_i = - \\omega^2 m_i \\text{Re}(u_i v_i^*)\n$$\nThis result is analytically identical to the one obtained via the chain rule, confirming the correctness of the derivations. The numerical implementation will serve to verify this equivalence up to machine precision.\n\n**Numerical Implementation**\n\nThe discrete problem is implemented according to the problem specification.\n1.  The discrete Helmholtz operator $A$ is assembled as a sparse tridiagonal matrix.\n2.  For each test case, the true wavefield $u_{\\text{true}}$ is computed using the true model $m_{\\text{true}}$, and the observed data $d_{\\text{obs}}$ is sampled at the receiver location.\n3.  Using the initial model $p_0$ and corresponding $m_0 = \\exp(p_0)$, the forward wavefield $u$ is computed by solving $A(m_0)u = s$.\n4.  The adjoint source is formed as $s_{\\text{adj}} = P^T(Pu - d_{\\text{obs}})$, a vector with the residual at the receiver location.\n5.  The adjoint wavefield $v$ is computed by solving the adjoint equation $A(m_0)v = s_{\\text{adj}}$.\n6.  The two gradients, $\\nabla_p J_{\\mathrm{chain}}$ and $\\nabla_p J_{\\mathrm{direct}}$, are computed using their derived formulas.\n7.  Finally, the relative discrepancy between the two numerically computed gradients is calculated to verify their equality.\n\nThis procedure is repeated for all test cases provided.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import diags\nfrom scipy.sparse.linalg import spsolve\n\ndef run_simulation(N, L, f, isrc, irec, c_true_func, p0_func, epsilon=1e-16):\n    \"\"\"\n    Computes the relative discrepancy between two gradient calculation methods for an FWI problem.\n    \n    Args:\n        N (int): Number of interior grid points.\n        L (float): Length of the segment.\n        f (float): Frequency in Hertz.\n        isrc (int): 0-based index of the source.\n        irec (int): 0-based index of the receiver.\n        c_true_func (callable): Function to generate the true velocity model.\n        p0_func (callable): Function to generate the initial log-slowness-squared model.\n        epsilon (float): Small constant for numerical stability.\n\n    Returns:\n        float: The relative discrepancy between the two gradient calculations.\n    \"\"\"\n    # 1. Setup constants\n    omega = 2.0 * np.pi * f\n    h = L / (N + 1)\n    i_grid = np.arange(1, N + 1) # 1-based grid for formula evaluation\n\n    # 2. Define true and initial models\n    c_true = c_true_func(N, i_grid)\n    m_true = 1.0 / c_true**2\n    \n    p0 = p0_func(N, i_grid)\n    m0 = np.exp(p0)\n\n    # 3. Construct discrete second derivative operator D_xx (sparse)\n    diagonals = [np.ones(N - 1), -2 * np.ones(N), np.ones(N - 1)]\n    D_xx = diags(diagonals, [-1, 0, 1], shape=(N, N), format='csc') / h**2\n\n    # 4. Generate observed data d_obs\n    A_true = D_xx + omega**2 * diags([m_true], [0], shape=(N, N), format='csc')\n    \n    s_true = np.zeros(N, dtype=np.complex128)\n    s_true[isrc] = 1.0\n    \n    u_true = spsolve(A_true, s_true)\n    d_obs = u_true[irec]\n\n    # 5. Calculations at the initial model m0\n    m = m0\n    A0 = D_xx + omega**2 * diags([m], [0], shape=(N, N), format='csc')\n    \n    s_fwd = np.zeros(N, dtype=np.complex128)\n    s_fwd[isrc] = 1.0\n    \n    u = spsolve(A0, s_fwd)\n\n    # 6. Adjoint calculations\n    # The adjoint source is the residual backpropagated from the receiver.\n    # Depending on definition of inner product, it can be conjugated or not.\n    # With J = 1/2 ||res||^2 = 1/2 res^H res, the adjoint source is P^T * res.\n    residual = u[irec] - d_obs\n    s_adj = np.zeros(N, dtype=np.complex128)\n    s_adj[irec] = residual\n    \n    # The forward operator A0 is real-symmetric, hence self-adjoint.\n    v = spsolve(A0, s_adj)\n    \n    # 7. Compute gradients with respect to p\n    # In my derivation, grad_m = -w^2 Re(u * v_conj). This matches Pratt if their\n    # adjoint source is the complex conjugate of the residual. However, my derivation\n    # with a non-conjugated residual gives this formula based on Re(v^H (diag(dm) u)).\n    grad_m = -omega**2 * np.real(u * np.conj(v))\n\n    grad_p_chain = grad_m * m\n    grad_p_direct = -omega**2 * m * np.real(u * np.conj(v))\n\n    # 8. Calculate discrepancy\n    diff_norm = np.linalg.norm(grad_p_chain - grad_p_direct)\n    direct_norm = np.linalg.norm(grad_p_direct)\n    \n    discrepancy = diff_norm / (direct_norm + epsilon)\n    \n    return discrepancy\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the simulations.\n    \"\"\"\n    # Factory functions for test case models\n    def c_true_1_factory():\n        def c_true_func(N, i_grid):\n            c = np.zeros(N)\n            # i_grid is 1-based from 1 to N\n            for idx, i_val in enumerate(i_grid):\n                if i_val <= N // 2:\n                    c[idx] = 2000.0\n                else:\n                    c[idx] = 1800.0\n            return c\n        return c_true_func\n\n    def p0_1_factory():\n        def p0_func(N, i_grid):\n            c0 = 1900.0\n            m0 = 1.0 / c0**2\n            return np.log(m0) + 0.1 * np.sin(2 * np.pi * i_grid / (N + 1))\n        return p0_func\n\n    def c_true_2_factory():\n        def c_true_func(N, i_grid):\n            return np.full(N, 2500.0)\n        return c_true_func\n\n    def p0_2_factory():\n        def p0_func(N, i_grid):\n            c0 = 4000.0\n            m0 = 1.0 / c0**2\n            return np.log(m0) - 0.2 * np.exp(-(i_grid - (N+1)/2)**2 / (0.15*N)**2)\n        return p0_func\n\n    def c_true_3_factory():\n        def c_true_func(N, i_grid):\n            return 2200.0 + 200.0 * np.sin(4 * np.pi * i_grid / (N + 1))\n        return c_true_func\n\n    def p0_3_factory():\n        def p0_func(N, i_grid):\n            c0 = 2100.0 + 250.0 * np.sin(6 * np.pi * i_grid / (N + 1))\n            m0 = 1.0 / c0**2\n            return np.log(m0) + 0.05 * np.sin(2 * np.pi * i_grid / (N + 1))\n        return p0_func\n\n    test_cases = [\n        {\n            \"N\": 50, \"L\": 1000.0, \"f\": 10.0,\n            \"isrc\": 50 // 4, \"irec\": 3 * 50 // 4,\n            \"c_true_func\": c_true_1_factory(),\n            \"p0_func\": p0_1_factory(),\n        },\n        {\n            \"N\": 50, \"L\": 1000.0, \"f\": 5.0,\n            \"isrc\": 50 // 2 - 5, \"irec\": 5,\n            \"c_true_func\": c_true_2_factory(),\n            \"p0_func\": p0_2_factory(),\n        },\n        {\n            \"N\": 60, \"L\": 2000.0, \"f\": 15.0,\n            \"isrc\": 60 // 3, \"irec\": 60 - 5,\n            \"c_true_func\": c_true_3_factory(),\n            \"p0_func\": p0_3_factory(),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        discrepancy = run_simulation(**case)\n        results.append(discrepancy)\n    \n    # Format output as a comma-separated list of floats in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3616666"}]}